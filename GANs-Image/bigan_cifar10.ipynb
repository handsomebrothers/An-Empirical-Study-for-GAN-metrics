{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 3)         1731      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,051,267\n",
      "Trainable params: 1,050,883\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 799,908\n",
      "Trainable params: 799,012\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 1.125763, acc: 30.47%] [G loss: 3.417828]\n",
      "epoch:0 step:2 [D loss: 1.979551, acc: 40.62%] [G loss: 4.960042]\n",
      "epoch:0 step:3 [D loss: 0.517309, acc: 79.69%] [G loss: 5.826185]\n",
      "epoch:0 step:4 [D loss: 0.834442, acc: 64.84%] [G loss: 5.790206]\n",
      "epoch:0 step:5 [D loss: 0.344891, acc: 84.38%] [G loss: 5.412471]\n",
      "epoch:0 step:6 [D loss: 0.743025, acc: 60.16%] [G loss: 4.616166]\n",
      "epoch:0 step:7 [D loss: 0.435030, acc: 78.12%] [G loss: 3.797035]\n",
      "epoch:0 step:8 [D loss: 0.350672, acc: 86.72%] [G loss: 3.717617]\n",
      "epoch:0 step:9 [D loss: 0.348214, acc: 84.38%] [G loss: 4.215730]\n",
      "epoch:0 step:10 [D loss: 0.563299, acc: 67.97%] [G loss: 5.673571]\n",
      "epoch:0 step:11 [D loss: 1.143475, acc: 41.41%] [G loss: 7.037165]\n",
      "epoch:0 step:12 [D loss: 0.248244, acc: 86.72%] [G loss: 7.564476]\n",
      "epoch:0 step:13 [D loss: 0.108910, acc: 97.66%] [G loss: 6.433130]\n",
      "epoch:0 step:14 [D loss: 0.087989, acc: 97.66%] [G loss: 4.980158]\n",
      "epoch:0 step:15 [D loss: 0.102026, acc: 98.44%] [G loss: 4.364975]\n",
      "epoch:0 step:16 [D loss: 0.117255, acc: 97.66%] [G loss: 3.988045]\n",
      "epoch:0 step:17 [D loss: 0.234838, acc: 91.41%] [G loss: 4.246737]\n",
      "epoch:0 step:18 [D loss: 0.320031, acc: 87.50%] [G loss: 5.009624]\n",
      "epoch:0 step:19 [D loss: 1.883829, acc: 48.44%] [G loss: 6.612900]\n",
      "epoch:0 step:20 [D loss: 0.462310, acc: 79.69%] [G loss: 6.408083]\n",
      "epoch:0 step:21 [D loss: 0.134844, acc: 94.53%] [G loss: 5.715882]\n",
      "epoch:0 step:22 [D loss: 0.050558, acc: 100.00%] [G loss: 4.944889]\n",
      "epoch:0 step:23 [D loss: 0.070087, acc: 97.66%] [G loss: 4.518745]\n",
      "epoch:0 step:24 [D loss: 0.077863, acc: 97.66%] [G loss: 4.097683]\n",
      "epoch:0 step:25 [D loss: 0.148611, acc: 96.09%] [G loss: 4.172495]\n",
      "epoch:0 step:26 [D loss: 0.141792, acc: 96.09%] [G loss: 4.459770]\n",
      "epoch:0 step:27 [D loss: 0.226653, acc: 92.97%] [G loss: 5.925275]\n",
      "epoch:0 step:28 [D loss: 0.123367, acc: 96.88%] [G loss: 5.556888]\n",
      "epoch:0 step:29 [D loss: 0.071286, acc: 99.22%] [G loss: 5.000486]\n",
      "epoch:0 step:30 [D loss: 0.163455, acc: 95.31%] [G loss: 5.425089]\n",
      "epoch:0 step:31 [D loss: 0.237856, acc: 90.62%] [G loss: 5.030625]\n",
      "epoch:0 step:32 [D loss: 0.077624, acc: 98.44%] [G loss: 5.092815]\n",
      "epoch:0 step:33 [D loss: 0.240698, acc: 92.19%] [G loss: 5.933407]\n",
      "epoch:0 step:34 [D loss: 0.143918, acc: 96.09%] [G loss: 6.768303]\n",
      "epoch:0 step:35 [D loss: 0.456081, acc: 78.12%] [G loss: 10.502627]\n",
      "epoch:0 step:36 [D loss: 0.288759, acc: 89.06%] [G loss: 13.268789]\n",
      "epoch:0 step:37 [D loss: 0.049386, acc: 98.44%] [G loss: 11.909435]\n",
      "epoch:0 step:38 [D loss: 0.037946, acc: 99.22%] [G loss: 8.313583]\n",
      "epoch:0 step:39 [D loss: 0.201056, acc: 92.19%] [G loss: 7.151083]\n",
      "epoch:0 step:40 [D loss: 0.048681, acc: 99.22%] [G loss: 6.690950]\n",
      "epoch:0 step:41 [D loss: 0.059132, acc: 98.44%] [G loss: 4.686246]\n",
      "epoch:0 step:42 [D loss: 0.342649, acc: 89.06%] [G loss: 6.977578]\n",
      "epoch:0 step:43 [D loss: 0.029370, acc: 100.00%] [G loss: 6.710721]\n",
      "epoch:0 step:44 [D loss: 0.029158, acc: 99.22%] [G loss: 6.594275]\n",
      "epoch:0 step:45 [D loss: 0.037317, acc: 99.22%] [G loss: 6.861382]\n",
      "epoch:0 step:46 [D loss: 0.125449, acc: 94.53%] [G loss: 7.370247]\n",
      "epoch:0 step:47 [D loss: 0.457686, acc: 84.38%] [G loss: 15.243812]\n",
      "epoch:0 step:48 [D loss: 0.073277, acc: 96.88%] [G loss: 16.201601]\n",
      "epoch:0 step:49 [D loss: 0.485576, acc: 85.94%] [G loss: 16.319660]\n",
      "epoch:0 step:50 [D loss: 0.149353, acc: 92.97%] [G loss: 14.380449]\n",
      "epoch:0 step:51 [D loss: 0.098794, acc: 97.66%] [G loss: 12.931963]\n",
      "epoch:0 step:52 [D loss: 0.179230, acc: 94.53%] [G loss: 9.887278]\n",
      "epoch:0 step:53 [D loss: 0.103562, acc: 95.31%] [G loss: 7.137594]\n",
      "epoch:0 step:54 [D loss: 0.132595, acc: 96.88%] [G loss: 6.227810]\n",
      "epoch:0 step:55 [D loss: 0.049619, acc: 99.22%] [G loss: 5.834720]\n",
      "epoch:0 step:56 [D loss: 0.235879, acc: 90.62%] [G loss: 5.165590]\n",
      "epoch:0 step:57 [D loss: 0.035413, acc: 100.00%] [G loss: 4.937955]\n",
      "epoch:0 step:58 [D loss: 0.053557, acc: 98.44%] [G loss: 4.639347]\n",
      "epoch:0 step:59 [D loss: 0.180973, acc: 91.41%] [G loss: 4.857001]\n",
      "epoch:0 step:60 [D loss: 0.294013, acc: 91.41%] [G loss: 7.120148]\n",
      "epoch:0 step:61 [D loss: 0.239308, acc: 90.62%] [G loss: 8.116325]\n",
      "epoch:0 step:62 [D loss: 0.189223, acc: 92.19%] [G loss: 9.416895]\n",
      "epoch:0 step:63 [D loss: 0.063183, acc: 98.44%] [G loss: 10.059360]\n",
      "epoch:0 step:64 [D loss: 0.099618, acc: 96.09%] [G loss: 6.858755]\n",
      "epoch:0 step:65 [D loss: 0.086623, acc: 97.66%] [G loss: 5.677126]\n",
      "epoch:0 step:66 [D loss: 0.095347, acc: 97.66%] [G loss: 5.920606]\n",
      "epoch:0 step:67 [D loss: 0.016153, acc: 100.00%] [G loss: 5.753379]\n",
      "epoch:0 step:68 [D loss: 0.045911, acc: 99.22%] [G loss: 5.521904]\n",
      "epoch:0 step:69 [D loss: 0.028505, acc: 100.00%] [G loss: 5.041848]\n",
      "epoch:0 step:70 [D loss: 0.028894, acc: 100.00%] [G loss: 5.228949]\n",
      "epoch:0 step:71 [D loss: 0.132395, acc: 94.53%] [G loss: 4.930715]\n",
      "epoch:0 step:72 [D loss: 0.060654, acc: 98.44%] [G loss: 6.083208]\n",
      "epoch:0 step:73 [D loss: 0.079330, acc: 98.44%] [G loss: 6.648988]\n",
      "epoch:0 step:74 [D loss: 0.088895, acc: 96.88%] [G loss: 6.985229]\n",
      "epoch:0 step:75 [D loss: 0.139238, acc: 96.09%] [G loss: 5.967279]\n",
      "epoch:0 step:76 [D loss: 0.081388, acc: 98.44%] [G loss: 6.128246]\n",
      "epoch:0 step:77 [D loss: 0.062369, acc: 98.44%] [G loss: 6.088274]\n",
      "epoch:0 step:78 [D loss: 0.100392, acc: 96.88%] [G loss: 5.730435]\n",
      "epoch:0 step:79 [D loss: 0.079898, acc: 96.88%] [G loss: 5.688094]\n",
      "epoch:0 step:80 [D loss: 0.073842, acc: 98.44%] [G loss: 5.004786]\n",
      "epoch:0 step:81 [D loss: 0.061485, acc: 98.44%] [G loss: 4.515625]\n",
      "epoch:0 step:82 [D loss: 0.067444, acc: 99.22%] [G loss: 4.736938]\n",
      "epoch:0 step:83 [D loss: 0.327917, acc: 85.94%] [G loss: 8.998720]\n",
      "epoch:0 step:84 [D loss: 0.059719, acc: 97.66%] [G loss: 7.936093]\n",
      "epoch:0 step:85 [D loss: 0.133009, acc: 96.09%] [G loss: 8.075682]\n",
      "epoch:0 step:86 [D loss: 0.035718, acc: 99.22%] [G loss: 8.561054]\n",
      "epoch:0 step:87 [D loss: 0.038042, acc: 99.22%] [G loss: 6.719712]\n",
      "epoch:0 step:88 [D loss: 0.032279, acc: 99.22%] [G loss: 6.361728]\n",
      "epoch:0 step:89 [D loss: 0.034190, acc: 98.44%] [G loss: 6.325789]\n",
      "epoch:0 step:90 [D loss: 0.060151, acc: 97.66%] [G loss: 5.756360]\n",
      "epoch:0 step:91 [D loss: 0.046852, acc: 98.44%] [G loss: 5.410809]\n",
      "epoch:0 step:92 [D loss: 0.034456, acc: 100.00%] [G loss: 4.548897]\n",
      "epoch:0 step:93 [D loss: 0.046337, acc: 99.22%] [G loss: 4.938650]\n",
      "epoch:0 step:94 [D loss: 0.061294, acc: 99.22%] [G loss: 5.015570]\n",
      "epoch:0 step:95 [D loss: 0.118879, acc: 96.88%] [G loss: 6.035103]\n",
      "epoch:0 step:96 [D loss: 0.018534, acc: 100.00%] [G loss: 6.643360]\n",
      "epoch:0 step:97 [D loss: 0.080512, acc: 97.66%] [G loss: 6.387573]\n",
      "epoch:0 step:98 [D loss: 0.086809, acc: 95.31%] [G loss: 6.481314]\n",
      "epoch:0 step:99 [D loss: 0.054709, acc: 98.44%] [G loss: 6.569388]\n",
      "epoch:0 step:100 [D loss: 0.017147, acc: 100.00%] [G loss: 6.271694]\n",
      "epoch:0 step:101 [D loss: 0.067245, acc: 98.44%] [G loss: 5.172000]\n",
      "epoch:0 step:102 [D loss: 0.472692, acc: 85.16%] [G loss: 8.311485]\n",
      "epoch:0 step:103 [D loss: 0.076831, acc: 97.66%] [G loss: 9.083315]\n",
      "epoch:0 step:104 [D loss: 0.087080, acc: 98.44%] [G loss: 5.935871]\n",
      "epoch:0 step:105 [D loss: 0.051199, acc: 99.22%] [G loss: 5.441936]\n",
      "epoch:0 step:106 [D loss: 0.064419, acc: 98.44%] [G loss: 5.898776]\n",
      "epoch:0 step:107 [D loss: 0.066098, acc: 99.22%] [G loss: 6.513810]\n",
      "epoch:0 step:108 [D loss: 0.053050, acc: 99.22%] [G loss: 4.763002]\n",
      "epoch:0 step:109 [D loss: 0.049168, acc: 98.44%] [G loss: 5.274343]\n",
      "epoch:0 step:110 [D loss: 0.135217, acc: 94.53%] [G loss: 6.199765]\n",
      "epoch:0 step:111 [D loss: 0.129737, acc: 95.31%] [G loss: 10.179651]\n",
      "epoch:0 step:112 [D loss: 0.070497, acc: 99.22%] [G loss: 10.921328]\n",
      "epoch:0 step:113 [D loss: 0.095836, acc: 99.22%] [G loss: 10.253296]\n",
      "epoch:0 step:114 [D loss: 0.182665, acc: 93.75%] [G loss: 11.578194]\n",
      "epoch:0 step:115 [D loss: 0.300322, acc: 87.50%] [G loss: 8.864012]\n",
      "epoch:0 step:116 [D loss: 0.255991, acc: 96.09%] [G loss: 11.451786]\n",
      "epoch:0 step:117 [D loss: 0.014260, acc: 100.00%] [G loss: 13.615664]\n",
      "epoch:0 step:118 [D loss: 0.019480, acc: 100.00%] [G loss: 13.333241]\n",
      "epoch:0 step:119 [D loss: 0.036596, acc: 100.00%] [G loss: 11.982473]\n",
      "epoch:0 step:120 [D loss: 0.029631, acc: 100.00%] [G loss: 10.964036]\n",
      "epoch:0 step:121 [D loss: 0.040275, acc: 100.00%] [G loss: 9.134676]\n",
      "epoch:0 step:122 [D loss: 0.036891, acc: 100.00%] [G loss: 7.608221]\n",
      "epoch:0 step:123 [D loss: 0.201814, acc: 92.97%] [G loss: 9.968075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:124 [D loss: 0.029537, acc: 100.00%] [G loss: 10.354588]\n",
      "epoch:0 step:125 [D loss: 0.033013, acc: 99.22%] [G loss: 10.506847]\n",
      "epoch:0 step:126 [D loss: 0.040469, acc: 97.66%] [G loss: 10.076322]\n",
      "epoch:0 step:127 [D loss: 0.013000, acc: 100.00%] [G loss: 7.502301]\n",
      "epoch:0 step:128 [D loss: 0.068632, acc: 97.66%] [G loss: 6.317908]\n",
      "epoch:0 step:129 [D loss: 0.047729, acc: 99.22%] [G loss: 5.223455]\n",
      "epoch:0 step:130 [D loss: 0.027421, acc: 100.00%] [G loss: 6.204920]\n",
      "epoch:0 step:131 [D loss: 0.019635, acc: 100.00%] [G loss: 6.177033]\n",
      "epoch:0 step:132 [D loss: 0.522573, acc: 82.81%] [G loss: 8.658902]\n",
      "epoch:0 step:133 [D loss: 0.028768, acc: 100.00%] [G loss: 7.759007]\n",
      "epoch:0 step:134 [D loss: 0.018985, acc: 100.00%] [G loss: 7.094817]\n",
      "epoch:0 step:135 [D loss: 0.025468, acc: 100.00%] [G loss: 4.997373]\n",
      "epoch:0 step:136 [D loss: 0.008116, acc: 100.00%] [G loss: 5.668641]\n",
      "epoch:0 step:137 [D loss: 0.009404, acc: 100.00%] [G loss: 5.697718]\n",
      "epoch:0 step:138 [D loss: 0.011625, acc: 100.00%] [G loss: 5.262450]\n",
      "epoch:0 step:139 [D loss: 0.020090, acc: 99.22%] [G loss: 5.692142]\n",
      "epoch:0 step:140 [D loss: 0.053031, acc: 97.66%] [G loss: 5.172439]\n",
      "epoch:0 step:141 [D loss: 0.047165, acc: 99.22%] [G loss: 4.622797]\n",
      "epoch:0 step:142 [D loss: 0.224841, acc: 89.84%] [G loss: 4.082585]\n",
      "epoch:0 step:143 [D loss: 1.830511, acc: 46.09%] [G loss: 6.919042]\n",
      "epoch:0 step:144 [D loss: 0.066212, acc: 97.66%] [G loss: 6.884204]\n",
      "epoch:0 step:145 [D loss: 0.351798, acc: 88.28%] [G loss: 7.381031]\n",
      "epoch:0 step:146 [D loss: 0.215654, acc: 89.84%] [G loss: 7.131309]\n",
      "epoch:0 step:147 [D loss: 0.386395, acc: 89.06%] [G loss: 5.287930]\n",
      "epoch:0 step:148 [D loss: 0.025819, acc: 99.22%] [G loss: 6.610154]\n",
      "epoch:0 step:149 [D loss: 0.083107, acc: 96.88%] [G loss: 6.913838]\n",
      "epoch:0 step:150 [D loss: 0.094818, acc: 96.88%] [G loss: 5.387240]\n",
      "epoch:0 step:151 [D loss: 0.087320, acc: 98.44%] [G loss: 4.298548]\n",
      "epoch:0 step:152 [D loss: 0.095128, acc: 96.09%] [G loss: 4.686189]\n",
      "epoch:0 step:153 [D loss: 0.260617, acc: 89.06%] [G loss: 4.569853]\n",
      "epoch:0 step:154 [D loss: 0.094730, acc: 97.66%] [G loss: 4.508725]\n",
      "epoch:0 step:155 [D loss: 0.075072, acc: 96.09%] [G loss: 4.213375]\n",
      "epoch:0 step:156 [D loss: 0.196514, acc: 92.97%] [G loss: 4.153088]\n",
      "epoch:0 step:157 [D loss: 0.079693, acc: 97.66%] [G loss: 4.037467]\n",
      "epoch:0 step:158 [D loss: 1.075237, acc: 59.38%] [G loss: 8.502041]\n",
      "epoch:0 step:159 [D loss: 0.389197, acc: 92.97%] [G loss: 8.083200]\n",
      "epoch:0 step:160 [D loss: 0.077963, acc: 98.44%] [G loss: 6.818752]\n",
      "epoch:0 step:161 [D loss: 0.056300, acc: 98.44%] [G loss: 7.388226]\n",
      "epoch:0 step:162 [D loss: 0.046111, acc: 100.00%] [G loss: 5.053472]\n",
      "epoch:0 step:163 [D loss: 0.048090, acc: 99.22%] [G loss: 5.705300]\n",
      "epoch:0 step:164 [D loss: 0.109398, acc: 97.66%] [G loss: 5.038185]\n",
      "epoch:0 step:165 [D loss: 0.108290, acc: 96.09%] [G loss: 5.409643]\n",
      "epoch:0 step:166 [D loss: 0.103878, acc: 96.88%] [G loss: 5.787556]\n",
      "epoch:0 step:167 [D loss: 0.097013, acc: 96.88%] [G loss: 5.217265]\n",
      "epoch:0 step:168 [D loss: 0.267766, acc: 88.28%] [G loss: 6.990627]\n",
      "epoch:0 step:169 [D loss: 0.044410, acc: 98.44%] [G loss: 6.117137]\n",
      "epoch:0 step:170 [D loss: 0.044239, acc: 99.22%] [G loss: 6.481933]\n",
      "epoch:0 step:171 [D loss: 0.055310, acc: 99.22%] [G loss: 5.024537]\n",
      "epoch:0 step:172 [D loss: 0.030488, acc: 100.00%] [G loss: 5.223770]\n",
      "epoch:0 step:173 [D loss: 0.017344, acc: 100.00%] [G loss: 5.167418]\n",
      "epoch:0 step:174 [D loss: 0.118083, acc: 95.31%] [G loss: 6.346931]\n",
      "epoch:0 step:175 [D loss: 0.030964, acc: 99.22%] [G loss: 5.623664]\n",
      "epoch:0 step:176 [D loss: 0.025855, acc: 100.00%] [G loss: 5.487555]\n",
      "epoch:0 step:177 [D loss: 0.048621, acc: 98.44%] [G loss: 5.882227]\n",
      "epoch:0 step:178 [D loss: 0.030966, acc: 100.00%] [G loss: 5.781503]\n",
      "epoch:0 step:179 [D loss: 0.064614, acc: 98.44%] [G loss: 5.780024]\n",
      "epoch:0 step:180 [D loss: 0.080874, acc: 97.66%] [G loss: 7.027184]\n",
      "epoch:0 step:181 [D loss: 0.091131, acc: 98.44%] [G loss: 7.506063]\n",
      "epoch:0 step:182 [D loss: 0.155255, acc: 95.31%] [G loss: 7.394897]\n",
      "epoch:0 step:183 [D loss: 0.142801, acc: 97.66%] [G loss: 6.832120]\n",
      "epoch:0 step:184 [D loss: 0.041726, acc: 99.22%] [G loss: 7.333134]\n",
      "epoch:0 step:185 [D loss: 0.089118, acc: 99.22%] [G loss: 5.300824]\n",
      "epoch:0 step:186 [D loss: 0.143465, acc: 93.75%] [G loss: 7.340662]\n",
      "epoch:0 step:187 [D loss: 0.776579, acc: 77.34%] [G loss: 10.188950]\n",
      "epoch:0 step:188 [D loss: 0.048751, acc: 99.22%] [G loss: 10.205242]\n",
      "epoch:0 step:189 [D loss: 0.096186, acc: 96.09%] [G loss: 9.041958]\n",
      "epoch:0 step:190 [D loss: 0.184968, acc: 96.09%] [G loss: 6.444455]\n",
      "epoch:0 step:191 [D loss: 0.053169, acc: 97.66%] [G loss: 5.545468]\n",
      "epoch:0 step:192 [D loss: 0.043980, acc: 98.44%] [G loss: 6.515408]\n",
      "epoch:0 step:193 [D loss: 0.028826, acc: 100.00%] [G loss: 5.308323]\n",
      "epoch:0 step:194 [D loss: 0.048683, acc: 100.00%] [G loss: 5.813986]\n",
      "epoch:0 step:195 [D loss: 0.052522, acc: 99.22%] [G loss: 5.661112]\n",
      "epoch:0 step:196 [D loss: 0.082245, acc: 98.44%] [G loss: 5.639723]\n",
      "epoch:0 step:197 [D loss: 1.219167, acc: 53.12%] [G loss: 13.084044]\n",
      "epoch:0 step:198 [D loss: 0.186434, acc: 92.97%] [G loss: 13.828657]\n",
      "epoch:0 step:199 [D loss: 0.070933, acc: 98.44%] [G loss: 12.171281]\n",
      "epoch:0 step:200 [D loss: 0.318285, acc: 89.84%] [G loss: 7.245539]\n",
      "epoch:0 step:201 [D loss: 0.085046, acc: 96.09%] [G loss: 5.637724]\n",
      "epoch:0 step:202 [D loss: 0.047033, acc: 98.44%] [G loss: 5.576383]\n",
      "epoch:0 step:203 [D loss: 0.025540, acc: 100.00%] [G loss: 5.167528]\n",
      "epoch:0 step:204 [D loss: 0.056727, acc: 98.44%] [G loss: 5.409996]\n",
      "epoch:0 step:205 [D loss: 0.085246, acc: 97.66%] [G loss: 5.204213]\n",
      "epoch:0 step:206 [D loss: 0.184722, acc: 93.75%] [G loss: 6.416061]\n",
      "epoch:0 step:207 [D loss: 0.210378, acc: 90.62%] [G loss: 5.287394]\n",
      "epoch:0 step:208 [D loss: 0.068401, acc: 98.44%] [G loss: 4.238853]\n",
      "epoch:0 step:209 [D loss: 0.060638, acc: 100.00%] [G loss: 3.993365]\n",
      "epoch:0 step:210 [D loss: 0.191220, acc: 92.19%] [G loss: 4.512266]\n",
      "epoch:0 step:211 [D loss: 0.115168, acc: 96.09%] [G loss: 4.213059]\n",
      "epoch:0 step:212 [D loss: 1.701680, acc: 46.88%] [G loss: 6.704355]\n",
      "epoch:0 step:213 [D loss: 0.560999, acc: 92.19%] [G loss: 8.370162]\n",
      "epoch:0 step:214 [D loss: 0.377479, acc: 84.38%] [G loss: 7.834648]\n",
      "epoch:0 step:215 [D loss: 0.142297, acc: 94.53%] [G loss: 7.206376]\n",
      "epoch:0 step:216 [D loss: 0.092764, acc: 98.44%] [G loss: 6.710178]\n",
      "epoch:0 step:217 [D loss: 0.080328, acc: 99.22%] [G loss: 7.191257]\n",
      "epoch:0 step:218 [D loss: 0.114519, acc: 96.88%] [G loss: 6.549425]\n",
      "epoch:0 step:219 [D loss: 0.248981, acc: 90.62%] [G loss: 6.502558]\n",
      "epoch:0 step:220 [D loss: 0.175083, acc: 92.97%] [G loss: 6.511443]\n",
      "epoch:0 step:221 [D loss: 0.772814, acc: 64.84%] [G loss: 13.022467]\n",
      "epoch:0 step:222 [D loss: 0.887008, acc: 76.56%] [G loss: 14.831223]\n",
      "epoch:0 step:223 [D loss: 0.505011, acc: 87.50%] [G loss: 10.485487]\n",
      "epoch:0 step:224 [D loss: 0.080143, acc: 100.00%] [G loss: 7.278646]\n",
      "epoch:0 step:225 [D loss: 0.152652, acc: 93.75%] [G loss: 6.669320]\n",
      "epoch:0 step:226 [D loss: 0.046903, acc: 100.00%] [G loss: 6.661177]\n",
      "epoch:0 step:227 [D loss: 0.054387, acc: 99.22%] [G loss: 6.297541]\n",
      "epoch:0 step:228 [D loss: 0.083077, acc: 98.44%] [G loss: 5.147758]\n",
      "epoch:0 step:229 [D loss: 0.126205, acc: 95.31%] [G loss: 5.244415]\n",
      "epoch:0 step:230 [D loss: 0.145275, acc: 96.09%] [G loss: 4.606997]\n",
      "epoch:0 step:231 [D loss: 0.133382, acc: 98.44%] [G loss: 4.032637]\n",
      "epoch:0 step:232 [D loss: 0.660021, acc: 74.22%] [G loss: 4.771518]\n",
      "epoch:0 step:233 [D loss: 0.194280, acc: 92.97%] [G loss: 6.230824]\n",
      "epoch:0 step:234 [D loss: 0.479841, acc: 76.56%] [G loss: 7.192809]\n",
      "epoch:0 step:235 [D loss: 0.438465, acc: 79.69%] [G loss: 7.966382]\n",
      "epoch:0 step:236 [D loss: 0.294685, acc: 86.72%] [G loss: 8.535357]\n",
      "epoch:0 step:237 [D loss: 0.292580, acc: 90.62%] [G loss: 8.004795]\n",
      "epoch:0 step:238 [D loss: 0.228169, acc: 90.62%] [G loss: 8.132925]\n",
      "epoch:0 step:239 [D loss: 0.182174, acc: 93.75%] [G loss: 7.296251]\n",
      "epoch:0 step:240 [D loss: 0.818943, acc: 67.19%] [G loss: 6.990324]\n",
      "epoch:0 step:241 [D loss: 0.697706, acc: 71.09%] [G loss: 7.667850]\n",
      "epoch:0 step:242 [D loss: 0.493720, acc: 82.03%] [G loss: 6.764086]\n",
      "epoch:0 step:243 [D loss: 0.129477, acc: 95.31%] [G loss: 6.521213]\n",
      "epoch:0 step:244 [D loss: 0.292015, acc: 87.50%] [G loss: 5.665710]\n",
      "epoch:0 step:245 [D loss: 0.246825, acc: 92.19%] [G loss: 5.694342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:246 [D loss: 0.410401, acc: 81.25%] [G loss: 5.120560]\n",
      "epoch:0 step:247 [D loss: 0.107949, acc: 97.66%] [G loss: 4.422062]\n",
      "epoch:0 step:248 [D loss: 0.114924, acc: 96.88%] [G loss: 4.290256]\n",
      "epoch:0 step:249 [D loss: 0.257575, acc: 90.62%] [G loss: 3.456339]\n",
      "epoch:0 step:250 [D loss: 0.582929, acc: 75.00%] [G loss: 4.057846]\n",
      "epoch:0 step:251 [D loss: 0.369617, acc: 86.72%] [G loss: 4.524366]\n",
      "epoch:0 step:252 [D loss: 0.314731, acc: 85.94%] [G loss: 3.776088]\n",
      "epoch:0 step:253 [D loss: 0.555812, acc: 70.31%] [G loss: 4.215684]\n",
      "epoch:0 step:254 [D loss: 0.215031, acc: 93.75%] [G loss: 4.896338]\n",
      "epoch:0 step:255 [D loss: 0.643550, acc: 71.88%] [G loss: 4.475292]\n",
      "epoch:0 step:256 [D loss: 0.669115, acc: 66.41%] [G loss: 4.896208]\n",
      "epoch:0 step:257 [D loss: 0.803855, acc: 66.41%] [G loss: 6.539287]\n",
      "epoch:0 step:258 [D loss: 0.691430, acc: 80.47%] [G loss: 5.808708]\n",
      "epoch:0 step:259 [D loss: 0.824583, acc: 65.62%] [G loss: 5.470138]\n",
      "epoch:0 step:260 [D loss: 0.157656, acc: 96.88%] [G loss: 6.742141]\n",
      "epoch:0 step:261 [D loss: 0.131820, acc: 96.88%] [G loss: 5.591585]\n",
      "epoch:0 step:262 [D loss: 0.214798, acc: 91.41%] [G loss: 5.563048]\n",
      "epoch:0 step:263 [D loss: 0.797033, acc: 58.59%] [G loss: 5.046659]\n",
      "epoch:0 step:264 [D loss: 0.185675, acc: 92.97%] [G loss: 5.509253]\n",
      "epoch:0 step:265 [D loss: 0.068161, acc: 100.00%] [G loss: 5.785410]\n",
      "epoch:0 step:266 [D loss: 0.087145, acc: 99.22%] [G loss: 4.417336]\n",
      "epoch:0 step:267 [D loss: 0.775646, acc: 73.44%] [G loss: 3.622318]\n",
      "epoch:0 step:268 [D loss: 0.056678, acc: 99.22%] [G loss: 5.914301]\n",
      "epoch:0 step:269 [D loss: 0.308229, acc: 90.62%] [G loss: 5.498012]\n",
      "epoch:0 step:270 [D loss: 0.201364, acc: 93.75%] [G loss: 5.825740]\n",
      "epoch:0 step:271 [D loss: 0.048176, acc: 98.44%] [G loss: 4.867254]\n",
      "epoch:0 step:272 [D loss: 0.208094, acc: 93.75%] [G loss: 4.338357]\n",
      "epoch:0 step:273 [D loss: 0.188653, acc: 92.97%] [G loss: 4.854320]\n",
      "epoch:0 step:274 [D loss: 0.164812, acc: 92.19%] [G loss: 4.562435]\n",
      "epoch:0 step:275 [D loss: 0.151794, acc: 95.31%] [G loss: 4.660357]\n",
      "epoch:0 step:276 [D loss: 0.157429, acc: 95.31%] [G loss: 5.378090]\n",
      "epoch:0 step:277 [D loss: 0.177542, acc: 94.53%] [G loss: 5.086630]\n",
      "epoch:0 step:278 [D loss: 0.355660, acc: 85.16%] [G loss: 4.316884]\n",
      "epoch:0 step:279 [D loss: 0.129237, acc: 98.44%] [G loss: 4.808093]\n",
      "epoch:0 step:280 [D loss: 0.431515, acc: 82.81%] [G loss: 5.417568]\n",
      "epoch:0 step:281 [D loss: 0.614838, acc: 74.22%] [G loss: 4.773042]\n",
      "epoch:0 step:282 [D loss: 0.427386, acc: 83.59%] [G loss: 5.713031]\n",
      "epoch:0 step:283 [D loss: 0.190857, acc: 93.75%] [G loss: 4.366808]\n",
      "epoch:0 step:284 [D loss: 0.277895, acc: 89.06%] [G loss: 4.737682]\n",
      "epoch:0 step:285 [D loss: 0.467956, acc: 81.25%] [G loss: 4.102973]\n",
      "epoch:0 step:286 [D loss: 0.637224, acc: 77.34%] [G loss: 3.477578]\n",
      "epoch:0 step:287 [D loss: 0.263253, acc: 92.97%] [G loss: 4.050121]\n",
      "epoch:0 step:288 [D loss: 1.001678, acc: 46.88%] [G loss: 5.196263]\n",
      "epoch:0 step:289 [D loss: 0.702359, acc: 66.41%] [G loss: 5.962251]\n",
      "epoch:0 step:290 [D loss: 0.100474, acc: 100.00%] [G loss: 6.087760]\n",
      "epoch:0 step:291 [D loss: 0.283655, acc: 88.28%] [G loss: 5.987267]\n",
      "epoch:0 step:292 [D loss: 0.552506, acc: 72.66%] [G loss: 4.029279]\n",
      "epoch:0 step:293 [D loss: 0.256519, acc: 87.50%] [G loss: 5.546437]\n",
      "epoch:0 step:294 [D loss: 0.261254, acc: 92.19%] [G loss: 6.176521]\n",
      "epoch:0 step:295 [D loss: 0.253672, acc: 89.06%] [G loss: 6.148058]\n",
      "epoch:0 step:296 [D loss: 0.098368, acc: 97.66%] [G loss: 5.870356]\n",
      "epoch:0 step:297 [D loss: 0.086926, acc: 98.44%] [G loss: 4.881657]\n",
      "epoch:0 step:298 [D loss: 0.141553, acc: 95.31%] [G loss: 5.289458]\n",
      "epoch:0 step:299 [D loss: 0.100013, acc: 98.44%] [G loss: 4.228674]\n",
      "epoch:0 step:300 [D loss: 0.241610, acc: 92.97%] [G loss: 3.822317]\n",
      "epoch:0 step:301 [D loss: 0.123184, acc: 96.88%] [G loss: 5.182375]\n",
      "epoch:0 step:302 [D loss: 0.088653, acc: 97.66%] [G loss: 5.496635]\n",
      "epoch:0 step:303 [D loss: 0.499304, acc: 84.38%] [G loss: 4.419085]\n",
      "epoch:0 step:304 [D loss: 0.233096, acc: 90.62%] [G loss: 5.181057]\n",
      "epoch:0 step:305 [D loss: 0.253429, acc: 86.72%] [G loss: 4.877499]\n",
      "epoch:0 step:306 [D loss: 0.244022, acc: 93.75%] [G loss: 4.864299]\n",
      "epoch:0 step:307 [D loss: 0.241762, acc: 89.06%] [G loss: 4.371769]\n",
      "epoch:0 step:308 [D loss: 0.168085, acc: 93.75%] [G loss: 3.771847]\n",
      "epoch:0 step:309 [D loss: 0.547664, acc: 71.88%] [G loss: 3.752230]\n",
      "epoch:0 step:310 [D loss: 0.534261, acc: 77.34%] [G loss: 3.438062]\n",
      "epoch:0 step:311 [D loss: 1.168056, acc: 57.03%] [G loss: 3.336143]\n",
      "epoch:0 step:312 [D loss: 1.098845, acc: 58.59%] [G loss: 4.349574]\n",
      "epoch:0 step:313 [D loss: 0.962473, acc: 65.62%] [G loss: 5.032025]\n",
      "epoch:0 step:314 [D loss: 0.172122, acc: 92.97%] [G loss: 5.488875]\n",
      "epoch:0 step:315 [D loss: 0.570384, acc: 71.09%] [G loss: 4.893060]\n",
      "epoch:0 step:316 [D loss: 0.196549, acc: 95.31%] [G loss: 4.508846]\n",
      "epoch:0 step:317 [D loss: 0.197529, acc: 93.75%] [G loss: 5.416261]\n",
      "epoch:0 step:318 [D loss: 0.237960, acc: 92.19%] [G loss: 4.915036]\n",
      "epoch:0 step:319 [D loss: 0.554377, acc: 78.91%] [G loss: 4.146286]\n",
      "epoch:0 step:320 [D loss: 0.386388, acc: 82.03%] [G loss: 4.387238]\n",
      "epoch:0 step:321 [D loss: 0.179261, acc: 92.19%] [G loss: 6.185449]\n",
      "epoch:0 step:322 [D loss: 0.193731, acc: 96.88%] [G loss: 5.794153]\n",
      "epoch:0 step:323 [D loss: 0.105745, acc: 99.22%] [G loss: 4.353293]\n",
      "epoch:0 step:324 [D loss: 0.267384, acc: 92.97%] [G loss: 5.294980]\n",
      "epoch:0 step:325 [D loss: 0.751921, acc: 73.44%] [G loss: 4.364548]\n",
      "epoch:0 step:326 [D loss: 0.326150, acc: 89.84%] [G loss: 4.610483]\n",
      "epoch:0 step:327 [D loss: 0.232345, acc: 89.84%] [G loss: 5.152530]\n",
      "epoch:0 step:328 [D loss: 0.151791, acc: 96.88%] [G loss: 4.882457]\n",
      "epoch:0 step:329 [D loss: 0.196077, acc: 94.53%] [G loss: 4.953442]\n",
      "epoch:0 step:330 [D loss: 0.231331, acc: 95.31%] [G loss: 3.724495]\n",
      "epoch:0 step:331 [D loss: 0.217583, acc: 92.97%] [G loss: 4.863509]\n",
      "epoch:0 step:332 [D loss: 0.229902, acc: 90.62%] [G loss: 4.367007]\n",
      "epoch:0 step:333 [D loss: 0.481086, acc: 78.12%] [G loss: 4.117237]\n",
      "epoch:0 step:334 [D loss: 0.222241, acc: 92.19%] [G loss: 5.704649]\n",
      "epoch:0 step:335 [D loss: 0.136686, acc: 96.88%] [G loss: 5.543793]\n",
      "epoch:0 step:336 [D loss: 0.238977, acc: 90.62%] [G loss: 5.661346]\n",
      "epoch:0 step:337 [D loss: 0.901115, acc: 57.03%] [G loss: 4.060839]\n",
      "epoch:0 step:338 [D loss: 0.203957, acc: 94.53%] [G loss: 5.460331]\n",
      "epoch:0 step:339 [D loss: 0.594923, acc: 72.66%] [G loss: 5.617964]\n",
      "epoch:0 step:340 [D loss: 1.168773, acc: 60.16%] [G loss: 4.560661]\n",
      "epoch:0 step:341 [D loss: 0.332966, acc: 84.38%] [G loss: 5.579448]\n",
      "epoch:0 step:342 [D loss: 0.325259, acc: 85.94%] [G loss: 5.091116]\n",
      "epoch:0 step:343 [D loss: 0.320458, acc: 89.84%] [G loss: 4.732997]\n",
      "epoch:0 step:344 [D loss: 0.117886, acc: 97.66%] [G loss: 3.965655]\n",
      "epoch:0 step:345 [D loss: 0.120202, acc: 97.66%] [G loss: 4.183781]\n",
      "epoch:0 step:346 [D loss: 0.082303, acc: 99.22%] [G loss: 4.657797]\n",
      "epoch:0 step:347 [D loss: 0.256685, acc: 90.62%] [G loss: 4.522989]\n",
      "epoch:0 step:348 [D loss: 0.168050, acc: 92.97%] [G loss: 3.483935]\n",
      "epoch:0 step:349 [D loss: 0.308393, acc: 92.19%] [G loss: 3.778475]\n",
      "epoch:0 step:350 [D loss: 0.087157, acc: 98.44%] [G loss: 4.144693]\n",
      "epoch:0 step:351 [D loss: 0.302210, acc: 89.06%] [G loss: 3.714305]\n",
      "epoch:0 step:352 [D loss: 0.091800, acc: 98.44%] [G loss: 4.677395]\n",
      "epoch:0 step:353 [D loss: 0.055680, acc: 100.00%] [G loss: 4.698809]\n",
      "epoch:0 step:354 [D loss: 0.186045, acc: 94.53%] [G loss: 3.754432]\n",
      "epoch:0 step:355 [D loss: 0.077419, acc: 98.44%] [G loss: 4.133752]\n",
      "epoch:0 step:356 [D loss: 0.109736, acc: 97.66%] [G loss: 4.140886]\n",
      "epoch:0 step:357 [D loss: 0.085694, acc: 98.44%] [G loss: 4.388775]\n",
      "epoch:0 step:358 [D loss: 0.282911, acc: 89.84%] [G loss: 3.122842]\n",
      "epoch:0 step:359 [D loss: 0.601514, acc: 78.12%] [G loss: 4.250114]\n",
      "epoch:0 step:360 [D loss: 0.351950, acc: 86.72%] [G loss: 3.204152]\n",
      "epoch:0 step:361 [D loss: 0.071323, acc: 99.22%] [G loss: 4.491982]\n",
      "epoch:0 step:362 [D loss: 0.441287, acc: 90.62%] [G loss: 4.675001]\n",
      "epoch:0 step:363 [D loss: 0.405169, acc: 82.81%] [G loss: 3.949948]\n",
      "epoch:0 step:364 [D loss: 0.276810, acc: 89.06%] [G loss: 3.599540]\n",
      "epoch:0 step:365 [D loss: 0.278381, acc: 90.62%] [G loss: 3.708093]\n",
      "epoch:0 step:366 [D loss: 0.354727, acc: 87.50%] [G loss: 2.992967]\n",
      "epoch:0 step:367 [D loss: 0.382982, acc: 84.38%] [G loss: 2.380979]\n",
      "epoch:0 step:368 [D loss: 0.631068, acc: 69.53%] [G loss: 2.500213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:369 [D loss: 1.528971, acc: 39.84%] [G loss: 2.707026]\n",
      "epoch:0 step:370 [D loss: 1.410633, acc: 47.66%] [G loss: 3.932113]\n",
      "epoch:0 step:371 [D loss: 0.739432, acc: 65.62%] [G loss: 4.992472]\n",
      "epoch:0 step:372 [D loss: 0.374567, acc: 85.16%] [G loss: 5.926351]\n",
      "epoch:0 step:373 [D loss: 0.312218, acc: 85.16%] [G loss: 5.370813]\n",
      "epoch:0 step:374 [D loss: 0.156886, acc: 94.53%] [G loss: 4.590927]\n",
      "epoch:0 step:375 [D loss: 0.216592, acc: 94.53%] [G loss: 3.799736]\n",
      "epoch:0 step:376 [D loss: 0.197673, acc: 95.31%] [G loss: 3.738423]\n",
      "epoch:0 step:377 [D loss: 0.414929, acc: 82.81%] [G loss: 2.740924]\n",
      "epoch:0 step:378 [D loss: 0.312044, acc: 85.94%] [G loss: 3.235407]\n",
      "epoch:0 step:379 [D loss: 0.153891, acc: 96.88%] [G loss: 3.472560]\n",
      "epoch:0 step:380 [D loss: 0.142549, acc: 96.88%] [G loss: 3.441485]\n",
      "epoch:0 step:381 [D loss: 0.494627, acc: 81.25%] [G loss: 2.852092]\n",
      "epoch:0 step:382 [D loss: 0.472171, acc: 76.56%] [G loss: 2.908238]\n",
      "epoch:0 step:383 [D loss: 0.373702, acc: 82.81%] [G loss: 3.538456]\n",
      "epoch:0 step:384 [D loss: 0.312721, acc: 87.50%] [G loss: 2.477333]\n",
      "epoch:0 step:385 [D loss: 0.313448, acc: 88.28%] [G loss: 2.966530]\n",
      "epoch:0 step:386 [D loss: 0.465593, acc: 75.00%] [G loss: 2.389558]\n",
      "epoch:0 step:387 [D loss: 0.240561, acc: 92.19%] [G loss: 2.659191]\n",
      "epoch:0 step:388 [D loss: 1.528574, acc: 43.75%] [G loss: 2.932617]\n",
      "epoch:0 step:389 [D loss: 0.469923, acc: 82.81%] [G loss: 3.012253]\n",
      "epoch:0 step:390 [D loss: 0.230472, acc: 92.19%] [G loss: 3.176970]\n",
      "epoch:0 step:391 [D loss: 0.546913, acc: 81.25%] [G loss: 3.151873]\n",
      "epoch:0 step:392 [D loss: 0.345644, acc: 87.50%] [G loss: 3.634143]\n",
      "epoch:0 step:393 [D loss: 0.418025, acc: 90.62%] [G loss: 2.930745]\n",
      "epoch:0 step:394 [D loss: 0.419468, acc: 79.69%] [G loss: 2.609367]\n",
      "epoch:0 step:395 [D loss: 0.552507, acc: 76.56%] [G loss: 2.469231]\n",
      "epoch:0 step:396 [D loss: 0.989374, acc: 53.91%] [G loss: 2.023751]\n",
      "epoch:0 step:397 [D loss: 1.173066, acc: 39.84%] [G loss: 2.641908]\n",
      "epoch:0 step:398 [D loss: 0.303308, acc: 86.72%] [G loss: 2.827770]\n",
      "epoch:0 step:399 [D loss: 0.126385, acc: 95.31%] [G loss: 3.664596]\n",
      "epoch:0 step:400 [D loss: 0.108314, acc: 96.88%] [G loss: 4.089347]\n",
      "epoch:0 step:401 [D loss: 0.392282, acc: 85.16%] [G loss: 2.741173]\n",
      "epoch:0 step:402 [D loss: 0.587729, acc: 71.09%] [G loss: 1.917326]\n",
      "epoch:0 step:403 [D loss: 0.618703, acc: 68.75%] [G loss: 2.180877]\n",
      "epoch:0 step:404 [D loss: 0.627467, acc: 75.78%] [G loss: 2.365611]\n",
      "epoch:0 step:405 [D loss: 1.457545, acc: 28.91%] [G loss: 2.403517]\n",
      "epoch:0 step:406 [D loss: 0.649838, acc: 71.88%] [G loss: 2.817528]\n",
      "epoch:0 step:407 [D loss: 0.170803, acc: 93.75%] [G loss: 4.020283]\n",
      "epoch:0 step:408 [D loss: 0.194971, acc: 92.19%] [G loss: 3.904341]\n",
      "epoch:0 step:409 [D loss: 0.601902, acc: 68.75%] [G loss: 3.791163]\n",
      "epoch:0 step:410 [D loss: 0.571504, acc: 73.44%] [G loss: 3.480777]\n",
      "epoch:0 step:411 [D loss: 0.885422, acc: 60.16%] [G loss: 3.336730]\n",
      "epoch:0 step:412 [D loss: 1.004579, acc: 57.03%] [G loss: 3.158360]\n",
      "epoch:0 step:413 [D loss: 0.448459, acc: 83.59%] [G loss: 3.327410]\n",
      "epoch:0 step:414 [D loss: 0.204842, acc: 95.31%] [G loss: 4.184209]\n",
      "epoch:0 step:415 [D loss: 0.197701, acc: 92.97%] [G loss: 3.694359]\n",
      "epoch:0 step:416 [D loss: 0.423120, acc: 82.03%] [G loss: 2.780293]\n",
      "epoch:0 step:417 [D loss: 0.331969, acc: 89.06%] [G loss: 3.339055]\n",
      "epoch:0 step:418 [D loss: 0.182662, acc: 97.66%] [G loss: 2.717385]\n",
      "epoch:0 step:419 [D loss: 0.113017, acc: 99.22%] [G loss: 3.294886]\n",
      "epoch:0 step:420 [D loss: 0.069117, acc: 99.22%] [G loss: 4.047189]\n",
      "epoch:0 step:421 [D loss: 0.367229, acc: 86.72%] [G loss: 2.397421]\n",
      "epoch:0 step:422 [D loss: 0.202712, acc: 95.31%] [G loss: 2.816080]\n",
      "epoch:0 step:423 [D loss: 0.490796, acc: 74.22%] [G loss: 2.419456]\n",
      "epoch:0 step:424 [D loss: 0.492388, acc: 70.31%] [G loss: 2.213823]\n",
      "epoch:0 step:425 [D loss: 0.221443, acc: 94.53%] [G loss: 3.352513]\n",
      "epoch:0 step:426 [D loss: 0.288045, acc: 92.19%] [G loss: 2.722421]\n",
      "epoch:0 step:427 [D loss: 0.192200, acc: 96.88%] [G loss: 3.050587]\n",
      "epoch:0 step:428 [D loss: 0.368420, acc: 85.94%] [G loss: 3.899784]\n",
      "epoch:0 step:429 [D loss: 0.163107, acc: 96.88%] [G loss: 2.939806]\n",
      "epoch:0 step:430 [D loss: 0.026353, acc: 100.00%] [G loss: 5.651937]\n",
      "epoch:0 step:431 [D loss: 0.182708, acc: 96.09%] [G loss: 5.293994]\n",
      "epoch:0 step:432 [D loss: 0.059928, acc: 100.00%] [G loss: 3.737419]\n",
      "epoch:0 step:433 [D loss: 0.666586, acc: 67.19%] [G loss: 2.658534]\n",
      "epoch:0 step:434 [D loss: 0.555303, acc: 78.12%] [G loss: 2.373999]\n",
      "epoch:0 step:435 [D loss: 0.642854, acc: 60.94%] [G loss: 2.598266]\n",
      "epoch:0 step:436 [D loss: 0.545941, acc: 85.94%] [G loss: 1.969104]\n",
      "epoch:0 step:437 [D loss: 0.803557, acc: 60.16%] [G loss: 1.723352]\n",
      "epoch:0 step:438 [D loss: 0.279545, acc: 92.19%] [G loss: 2.730202]\n",
      "epoch:0 step:439 [D loss: 0.187308, acc: 97.66%] [G loss: 2.769549]\n",
      "epoch:0 step:440 [D loss: 1.154070, acc: 41.41%] [G loss: 2.405275]\n",
      "epoch:0 step:441 [D loss: 0.495514, acc: 76.56%] [G loss: 3.744426]\n",
      "epoch:0 step:442 [D loss: 0.512557, acc: 78.91%] [G loss: 3.403279]\n",
      "epoch:0 step:443 [D loss: 0.879043, acc: 51.56%] [G loss: 3.159555]\n",
      "epoch:0 step:444 [D loss: 0.653297, acc: 64.06%] [G loss: 5.115183]\n",
      "epoch:0 step:445 [D loss: 0.878807, acc: 64.84%] [G loss: 3.885726]\n",
      "epoch:0 step:446 [D loss: 0.767948, acc: 69.53%] [G loss: 3.422467]\n",
      "epoch:0 step:447 [D loss: 0.502658, acc: 75.00%] [G loss: 2.734381]\n",
      "epoch:0 step:448 [D loss: 0.772164, acc: 63.28%] [G loss: 3.017306]\n",
      "epoch:0 step:449 [D loss: 0.609787, acc: 71.09%] [G loss: 3.609920]\n",
      "epoch:0 step:450 [D loss: 0.776207, acc: 71.88%] [G loss: 3.736149]\n",
      "epoch:0 step:451 [D loss: 0.782185, acc: 60.94%] [G loss: 2.185962]\n",
      "epoch:0 step:452 [D loss: 0.449020, acc: 81.25%] [G loss: 2.610373]\n",
      "epoch:0 step:453 [D loss: 0.462986, acc: 78.91%] [G loss: 2.900050]\n",
      "epoch:0 step:454 [D loss: 1.191281, acc: 49.22%] [G loss: 2.116511]\n",
      "epoch:0 step:455 [D loss: 0.349101, acc: 80.47%] [G loss: 3.462214]\n",
      "epoch:0 step:456 [D loss: 0.531566, acc: 77.34%] [G loss: 3.194807]\n",
      "epoch:0 step:457 [D loss: 0.698398, acc: 56.25%] [G loss: 2.090292]\n",
      "epoch:0 step:458 [D loss: 0.953079, acc: 50.78%] [G loss: 2.598747]\n",
      "epoch:0 step:459 [D loss: 1.272744, acc: 36.72%] [G loss: 3.857944]\n",
      "epoch:0 step:460 [D loss: 0.823936, acc: 61.72%] [G loss: 4.968077]\n",
      "epoch:0 step:461 [D loss: 0.723306, acc: 62.50%] [G loss: 5.193748]\n",
      "epoch:0 step:462 [D loss: 0.528492, acc: 78.91%] [G loss: 5.124964]\n",
      "epoch:0 step:463 [D loss: 0.487126, acc: 78.91%] [G loss: 4.176433]\n",
      "epoch:0 step:464 [D loss: 0.349323, acc: 85.94%] [G loss: 3.763692]\n",
      "epoch:0 step:465 [D loss: 0.358694, acc: 82.03%] [G loss: 3.820565]\n",
      "epoch:0 step:466 [D loss: 0.215542, acc: 96.09%] [G loss: 3.643539]\n",
      "epoch:0 step:467 [D loss: 0.269204, acc: 92.19%] [G loss: 3.609456]\n",
      "epoch:0 step:468 [D loss: 0.233929, acc: 93.75%] [G loss: 3.983703]\n",
      "epoch:0 step:469 [D loss: 0.217252, acc: 92.19%] [G loss: 3.299232]\n",
      "epoch:0 step:470 [D loss: 0.267638, acc: 91.41%] [G loss: 3.046869]\n",
      "epoch:0 step:471 [D loss: 0.205089, acc: 92.19%] [G loss: 3.461814]\n",
      "epoch:0 step:472 [D loss: 0.178700, acc: 94.53%] [G loss: 3.640126]\n",
      "epoch:0 step:473 [D loss: 0.260598, acc: 89.84%] [G loss: 4.171495]\n",
      "epoch:0 step:474 [D loss: 0.442840, acc: 82.03%] [G loss: 4.165558]\n",
      "epoch:0 step:475 [D loss: 0.498448, acc: 78.91%] [G loss: 3.664374]\n",
      "epoch:0 step:476 [D loss: 0.964512, acc: 52.34%] [G loss: 3.119755]\n",
      "epoch:0 step:477 [D loss: 0.575827, acc: 72.66%] [G loss: 3.276002]\n",
      "epoch:0 step:478 [D loss: 0.846418, acc: 52.34%] [G loss: 3.687004]\n",
      "epoch:0 step:479 [D loss: 0.766563, acc: 63.28%] [G loss: 2.895982]\n",
      "epoch:0 step:480 [D loss: 0.522700, acc: 79.69%] [G loss: 3.184455]\n",
      "epoch:0 step:481 [D loss: 0.520134, acc: 72.66%] [G loss: 3.908850]\n",
      "epoch:0 step:482 [D loss: 1.774503, acc: 34.38%] [G loss: 2.669853]\n",
      "epoch:0 step:483 [D loss: 0.633348, acc: 80.47%] [G loss: 3.428713]\n",
      "epoch:0 step:484 [D loss: 0.648549, acc: 62.50%] [G loss: 2.700858]\n",
      "epoch:0 step:485 [D loss: 0.465181, acc: 78.91%] [G loss: 2.599644]\n",
      "epoch:0 step:486 [D loss: 1.192293, acc: 42.97%] [G loss: 2.504856]\n",
      "epoch:0 step:487 [D loss: 0.572960, acc: 71.09%] [G loss: 2.958431]\n",
      "epoch:0 step:488 [D loss: 0.580001, acc: 74.22%] [G loss: 2.979660]\n",
      "epoch:0 step:489 [D loss: 0.743854, acc: 69.53%] [G loss: 2.665631]\n",
      "epoch:0 step:490 [D loss: 0.384414, acc: 83.59%] [G loss: 3.330206]\n",
      "epoch:0 step:491 [D loss: 0.598835, acc: 65.62%] [G loss: 2.743230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:492 [D loss: 0.233357, acc: 93.75%] [G loss: 3.801201]\n",
      "epoch:0 step:493 [D loss: 0.333306, acc: 85.94%] [G loss: 3.071179]\n",
      "epoch:0 step:494 [D loss: 0.296496, acc: 88.28%] [G loss: 3.415472]\n",
      "epoch:0 step:495 [D loss: 0.399198, acc: 86.72%] [G loss: 3.433309]\n",
      "epoch:0 step:496 [D loss: 0.536397, acc: 80.47%] [G loss: 3.310033]\n",
      "epoch:0 step:497 [D loss: 0.428620, acc: 82.03%] [G loss: 3.375839]\n",
      "epoch:0 step:498 [D loss: 0.360897, acc: 85.16%] [G loss: 3.529752]\n",
      "epoch:0 step:499 [D loss: 0.764253, acc: 67.19%] [G loss: 3.048304]\n",
      "epoch:0 step:500 [D loss: 0.639717, acc: 63.28%] [G loss: 3.217674]\n",
      "epoch:0 step:501 [D loss: 0.597039, acc: 75.78%] [G loss: 3.223451]\n",
      "epoch:0 step:502 [D loss: 0.382832, acc: 83.59%] [G loss: 3.988022]\n",
      "epoch:0 step:503 [D loss: 0.617135, acc: 67.97%] [G loss: 3.259859]\n",
      "epoch:0 step:504 [D loss: 0.741038, acc: 59.38%] [G loss: 2.768860]\n",
      "epoch:0 step:505 [D loss: 0.796939, acc: 61.72%] [G loss: 3.363848]\n",
      "epoch:0 step:506 [D loss: 0.498974, acc: 77.34%] [G loss: 3.654107]\n",
      "epoch:0 step:507 [D loss: 0.740070, acc: 65.62%] [G loss: 2.774024]\n",
      "epoch:0 step:508 [D loss: 0.570397, acc: 75.00%] [G loss: 2.999306]\n",
      "epoch:0 step:509 [D loss: 0.345521, acc: 90.62%] [G loss: 4.189466]\n",
      "epoch:0 step:510 [D loss: 0.260316, acc: 90.62%] [G loss: 3.542459]\n",
      "epoch:0 step:511 [D loss: 0.474011, acc: 80.47%] [G loss: 3.159275]\n",
      "epoch:0 step:512 [D loss: 0.286055, acc: 85.94%] [G loss: 2.663798]\n",
      "epoch:0 step:513 [D loss: 0.293970, acc: 89.84%] [G loss: 3.686367]\n",
      "epoch:0 step:514 [D loss: 0.465060, acc: 75.78%] [G loss: 2.812748]\n",
      "epoch:0 step:515 [D loss: 0.472147, acc: 74.22%] [G loss: 2.365781]\n",
      "epoch:0 step:516 [D loss: 0.267876, acc: 92.19%] [G loss: 2.573150]\n",
      "epoch:0 step:517 [D loss: 0.212044, acc: 95.31%] [G loss: 2.611337]\n",
      "epoch:0 step:518 [D loss: 0.452054, acc: 81.25%] [G loss: 2.110901]\n",
      "epoch:0 step:519 [D loss: 1.174133, acc: 36.72%] [G loss: 1.767164]\n",
      "epoch:0 step:520 [D loss: 0.418014, acc: 83.59%] [G loss: 2.562963]\n",
      "epoch:0 step:521 [D loss: 0.415323, acc: 85.94%] [G loss: 2.503356]\n",
      "epoch:0 step:522 [D loss: 0.285421, acc: 92.19%] [G loss: 2.758993]\n",
      "epoch:0 step:523 [D loss: 0.512806, acc: 82.81%] [G loss: 2.342425]\n",
      "epoch:0 step:524 [D loss: 0.455721, acc: 78.12%] [G loss: 4.197827]\n",
      "epoch:0 step:525 [D loss: 0.489783, acc: 78.12%] [G loss: 2.144625]\n",
      "epoch:0 step:526 [D loss: 0.275318, acc: 93.75%] [G loss: 2.942784]\n",
      "epoch:0 step:527 [D loss: 0.959752, acc: 46.09%] [G loss: 2.090070]\n",
      "epoch:0 step:528 [D loss: 0.922565, acc: 53.12%] [G loss: 2.047813]\n",
      "epoch:0 step:529 [D loss: 1.740877, acc: 21.88%] [G loss: 3.254365]\n",
      "epoch:0 step:530 [D loss: 1.143678, acc: 53.91%] [G loss: 3.438538]\n",
      "epoch:0 step:531 [D loss: 1.335540, acc: 50.78%] [G loss: 2.260352]\n",
      "epoch:0 step:532 [D loss: 0.454073, acc: 78.91%] [G loss: 2.867466]\n",
      "epoch:0 step:533 [D loss: 0.665800, acc: 70.31%] [G loss: 2.485460]\n",
      "epoch:0 step:534 [D loss: 0.258464, acc: 88.28%] [G loss: 3.061499]\n",
      "epoch:0 step:535 [D loss: 0.377767, acc: 87.50%] [G loss: 2.510693]\n",
      "epoch:0 step:536 [D loss: 0.403420, acc: 83.59%] [G loss: 2.391694]\n",
      "epoch:0 step:537 [D loss: 0.799465, acc: 58.59%] [G loss: 1.969980]\n",
      "epoch:0 step:538 [D loss: 0.319485, acc: 91.41%] [G loss: 2.483569]\n",
      "epoch:0 step:539 [D loss: 0.243719, acc: 95.31%] [G loss: 2.293932]\n",
      "epoch:0 step:540 [D loss: 0.198300, acc: 92.19%] [G loss: 2.475344]\n",
      "epoch:0 step:541 [D loss: 0.236797, acc: 96.09%] [G loss: 2.334665]\n",
      "epoch:0 step:542 [D loss: 0.259166, acc: 94.53%] [G loss: 2.262263]\n",
      "epoch:0 step:543 [D loss: 0.449128, acc: 83.59%] [G loss: 1.642799]\n",
      "epoch:0 step:544 [D loss: 0.312380, acc: 91.41%] [G loss: 2.310566]\n",
      "epoch:0 step:545 [D loss: 0.493038, acc: 76.56%] [G loss: 2.744542]\n",
      "epoch:0 step:546 [D loss: 0.908339, acc: 53.12%] [G loss: 2.766022]\n",
      "epoch:0 step:547 [D loss: 0.733499, acc: 67.19%] [G loss: 2.124323]\n",
      "epoch:0 step:548 [D loss: 0.119150, acc: 94.53%] [G loss: 2.838554]\n",
      "epoch:0 step:549 [D loss: 0.352599, acc: 85.94%] [G loss: 2.920857]\n",
      "epoch:0 step:550 [D loss: 0.305764, acc: 89.84%] [G loss: 2.244541]\n",
      "epoch:0 step:551 [D loss: 0.471207, acc: 80.47%] [G loss: 2.410240]\n",
      "epoch:0 step:552 [D loss: 0.142702, acc: 96.88%] [G loss: 3.301573]\n",
      "epoch:0 step:553 [D loss: 0.482648, acc: 73.44%] [G loss: 3.400882]\n",
      "epoch:0 step:554 [D loss: 0.482932, acc: 82.81%] [G loss: 2.696498]\n",
      "epoch:0 step:555 [D loss: 0.804663, acc: 57.03%] [G loss: 2.385959]\n",
      "epoch:0 step:556 [D loss: 0.142143, acc: 98.44%] [G loss: 3.518824]\n",
      "epoch:0 step:557 [D loss: 0.188962, acc: 94.53%] [G loss: 3.479021]\n",
      "epoch:0 step:558 [D loss: 0.735436, acc: 64.84%] [G loss: 3.007175]\n",
      "epoch:0 step:559 [D loss: 0.276815, acc: 83.59%] [G loss: 2.721127]\n",
      "epoch:0 step:560 [D loss: 0.451841, acc: 82.03%] [G loss: 2.629419]\n",
      "epoch:0 step:561 [D loss: 1.085694, acc: 44.53%] [G loss: 1.972527]\n",
      "epoch:0 step:562 [D loss: 0.786548, acc: 55.47%] [G loss: 2.223344]\n",
      "epoch:0 step:563 [D loss: 0.996066, acc: 47.66%] [G loss: 1.733544]\n",
      "epoch:0 step:564 [D loss: 0.943299, acc: 49.22%] [G loss: 2.609709]\n",
      "epoch:0 step:565 [D loss: 0.623609, acc: 67.19%] [G loss: 2.472156]\n",
      "epoch:0 step:566 [D loss: 0.318013, acc: 88.28%] [G loss: 2.684754]\n",
      "epoch:0 step:567 [D loss: 0.688689, acc: 64.06%] [G loss: 2.489261]\n",
      "epoch:0 step:568 [D loss: 0.397309, acc: 85.16%] [G loss: 1.946135]\n",
      "epoch:0 step:569 [D loss: 0.450900, acc: 82.81%] [G loss: 1.784862]\n",
      "epoch:0 step:570 [D loss: 0.560869, acc: 74.22%] [G loss: 2.105983]\n",
      "epoch:0 step:571 [D loss: 0.568127, acc: 64.84%] [G loss: 2.542394]\n",
      "epoch:0 step:572 [D loss: 0.449787, acc: 74.22%] [G loss: 2.145448]\n",
      "epoch:0 step:573 [D loss: 0.143502, acc: 98.44%] [G loss: 3.220412]\n",
      "epoch:0 step:574 [D loss: 1.073117, acc: 38.28%] [G loss: 1.434697]\n",
      "epoch:0 step:575 [D loss: 0.112517, acc: 100.00%] [G loss: 2.758565]\n",
      "epoch:0 step:576 [D loss: 0.206594, acc: 93.75%] [G loss: 2.658274]\n",
      "epoch:0 step:577 [D loss: 0.346720, acc: 86.72%] [G loss: 2.668233]\n",
      "epoch:0 step:578 [D loss: 0.357442, acc: 85.94%] [G loss: 2.350856]\n",
      "epoch:0 step:579 [D loss: 0.317532, acc: 85.94%] [G loss: 2.694142]\n",
      "epoch:0 step:580 [D loss: 0.603613, acc: 67.19%] [G loss: 2.458757]\n",
      "epoch:0 step:581 [D loss: 0.215918, acc: 92.19%] [G loss: 3.325776]\n",
      "epoch:0 step:582 [D loss: 0.314875, acc: 92.97%] [G loss: 2.830270]\n",
      "epoch:0 step:583 [D loss: 0.112971, acc: 99.22%] [G loss: 3.405997]\n",
      "epoch:0 step:584 [D loss: 0.191098, acc: 96.88%] [G loss: 2.944615]\n",
      "epoch:0 step:585 [D loss: 0.654485, acc: 63.28%] [G loss: 2.349151]\n",
      "epoch:0 step:586 [D loss: 0.940412, acc: 55.47%] [G loss: 2.833423]\n",
      "epoch:0 step:587 [D loss: 0.465365, acc: 76.56%] [G loss: 1.846263]\n",
      "epoch:0 step:588 [D loss: 0.713604, acc: 60.94%] [G loss: 2.652750]\n",
      "epoch:0 step:589 [D loss: 0.581139, acc: 69.53%] [G loss: 2.231194]\n",
      "epoch:0 step:590 [D loss: 0.875663, acc: 53.12%] [G loss: 3.079249]\n",
      "epoch:0 step:591 [D loss: 0.261660, acc: 87.50%] [G loss: 4.960968]\n",
      "epoch:0 step:592 [D loss: 0.643473, acc: 70.31%] [G loss: 3.602415]\n",
      "epoch:0 step:593 [D loss: 0.310824, acc: 91.41%] [G loss: 5.293565]\n",
      "epoch:0 step:594 [D loss: 0.638381, acc: 70.31%] [G loss: 4.096934]\n",
      "epoch:0 step:595 [D loss: 0.248186, acc: 93.75%] [G loss: 4.217113]\n",
      "epoch:0 step:596 [D loss: 0.499217, acc: 78.12%] [G loss: 2.446576]\n",
      "epoch:0 step:597 [D loss: 0.177427, acc: 97.66%] [G loss: 3.352990]\n",
      "epoch:0 step:598 [D loss: 0.367553, acc: 78.91%] [G loss: 2.616029]\n",
      "epoch:0 step:599 [D loss: 0.263783, acc: 93.75%] [G loss: 2.674162]\n",
      "epoch:0 step:600 [D loss: 0.117818, acc: 99.22%] [G loss: 3.005374]\n",
      "epoch:0 step:601 [D loss: 0.435666, acc: 82.03%] [G loss: 2.309466]\n",
      "epoch:0 step:602 [D loss: 0.175760, acc: 97.66%] [G loss: 3.038332]\n",
      "epoch:0 step:603 [D loss: 0.226303, acc: 92.97%] [G loss: 2.373436]\n",
      "epoch:0 step:604 [D loss: 0.368222, acc: 86.72%] [G loss: 2.242049]\n",
      "epoch:0 step:605 [D loss: 0.144650, acc: 96.09%] [G loss: 2.302948]\n",
      "epoch:0 step:606 [D loss: 0.194001, acc: 95.31%] [G loss: 3.059111]\n",
      "epoch:0 step:607 [D loss: 0.172174, acc: 96.09%] [G loss: 2.365357]\n",
      "epoch:0 step:608 [D loss: 0.161481, acc: 96.88%] [G loss: 2.922055]\n",
      "epoch:0 step:609 [D loss: 0.254769, acc: 93.75%] [G loss: 2.993330]\n",
      "epoch:0 step:610 [D loss: 0.192000, acc: 93.75%] [G loss: 2.611386]\n",
      "epoch:0 step:611 [D loss: 0.433355, acc: 83.59%] [G loss: 2.191578]\n",
      "epoch:0 step:612 [D loss: 0.293224, acc: 90.62%] [G loss: 2.435179]\n",
      "epoch:0 step:613 [D loss: 0.304120, acc: 87.50%] [G loss: 2.555494]\n",
      "epoch:0 step:614 [D loss: 0.074401, acc: 100.00%] [G loss: 3.730338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:615 [D loss: 0.500863, acc: 70.31%] [G loss: 2.727933]\n",
      "epoch:0 step:616 [D loss: 0.109098, acc: 98.44%] [G loss: 3.812376]\n",
      "epoch:0 step:617 [D loss: 0.221367, acc: 92.19%] [G loss: 2.534993]\n",
      "epoch:0 step:618 [D loss: 0.230982, acc: 96.09%] [G loss: 2.712810]\n",
      "epoch:0 step:619 [D loss: 0.580899, acc: 66.41%] [G loss: 2.402942]\n",
      "epoch:0 step:620 [D loss: 0.843516, acc: 53.12%] [G loss: 1.709960]\n",
      "epoch:0 step:621 [D loss: 0.269300, acc: 93.75%] [G loss: 2.645591]\n",
      "epoch:0 step:622 [D loss: 1.005638, acc: 42.97%] [G loss: 1.875516]\n",
      "epoch:0 step:623 [D loss: 0.750050, acc: 55.47%] [G loss: 1.885409]\n",
      "epoch:0 step:624 [D loss: 0.875195, acc: 60.16%] [G loss: 2.565210]\n",
      "epoch:0 step:625 [D loss: 0.580424, acc: 76.56%] [G loss: 2.114796]\n",
      "epoch:0 step:626 [D loss: 1.349491, acc: 40.62%] [G loss: 2.301813]\n",
      "epoch:0 step:627 [D loss: 0.865037, acc: 57.81%] [G loss: 2.800819]\n",
      "epoch:0 step:628 [D loss: 1.102959, acc: 46.88%] [G loss: 2.682558]\n",
      "epoch:0 step:629 [D loss: 0.948672, acc: 57.03%] [G loss: 3.296997]\n",
      "epoch:0 step:630 [D loss: 0.529644, acc: 69.53%] [G loss: 4.181722]\n",
      "epoch:0 step:631 [D loss: 0.422153, acc: 82.81%] [G loss: 3.536796]\n",
      "epoch:0 step:632 [D loss: 0.348516, acc: 87.50%] [G loss: 3.567475]\n",
      "epoch:0 step:633 [D loss: 0.261662, acc: 88.28%] [G loss: 4.048996]\n",
      "epoch:0 step:634 [D loss: 0.179003, acc: 91.41%] [G loss: 3.531996]\n",
      "epoch:0 step:635 [D loss: 0.328532, acc: 85.94%] [G loss: 2.768954]\n",
      "epoch:0 step:636 [D loss: 0.282185, acc: 88.28%] [G loss: 3.113503]\n",
      "epoch:0 step:637 [D loss: 0.246345, acc: 91.41%] [G loss: 3.784943]\n",
      "epoch:0 step:638 [D loss: 0.140783, acc: 96.09%] [G loss: 2.932345]\n",
      "epoch:0 step:639 [D loss: 0.152599, acc: 96.88%] [G loss: 3.457488]\n",
      "epoch:0 step:640 [D loss: 0.196970, acc: 92.97%] [G loss: 3.498675]\n",
      "epoch:0 step:641 [D loss: 0.443920, acc: 78.91%] [G loss: 2.750801]\n",
      "epoch:0 step:642 [D loss: 0.061365, acc: 97.66%] [G loss: 3.297657]\n",
      "epoch:0 step:643 [D loss: 0.194696, acc: 93.75%] [G loss: 3.142915]\n",
      "epoch:0 step:644 [D loss: 0.425591, acc: 78.91%] [G loss: 2.768764]\n",
      "epoch:0 step:645 [D loss: 0.226910, acc: 92.19%] [G loss: 2.893531]\n",
      "epoch:0 step:646 [D loss: 0.205057, acc: 94.53%] [G loss: 3.350712]\n",
      "epoch:0 step:647 [D loss: 0.172037, acc: 95.31%] [G loss: 2.798075]\n",
      "epoch:0 step:648 [D loss: 0.179245, acc: 94.53%] [G loss: 3.191080]\n",
      "epoch:0 step:649 [D loss: 0.049792, acc: 100.00%] [G loss: 3.875689]\n",
      "epoch:0 step:650 [D loss: 0.541311, acc: 75.00%] [G loss: 2.225650]\n",
      "epoch:0 step:651 [D loss: 0.086584, acc: 98.44%] [G loss: 3.453252]\n",
      "epoch:0 step:652 [D loss: 0.884025, acc: 51.56%] [G loss: 2.220774]\n",
      "epoch:0 step:653 [D loss: 0.747425, acc: 69.53%] [G loss: 2.268261]\n",
      "epoch:0 step:654 [D loss: 0.164187, acc: 96.09%] [G loss: 3.267708]\n",
      "epoch:0 step:655 [D loss: 1.294961, acc: 35.94%] [G loss: 1.647203]\n",
      "epoch:0 step:656 [D loss: 2.035130, acc: 15.62%] [G loss: 2.632083]\n",
      "epoch:0 step:657 [D loss: 1.646267, acc: 46.88%] [G loss: 2.169030]\n",
      "epoch:0 step:658 [D loss: 1.359661, acc: 30.47%] [G loss: 1.512912]\n",
      "epoch:0 step:659 [D loss: 0.894506, acc: 49.22%] [G loss: 1.583100]\n",
      "epoch:0 step:660 [D loss: 0.421582, acc: 83.59%] [G loss: 1.980006]\n",
      "epoch:0 step:661 [D loss: 1.111914, acc: 46.88%] [G loss: 2.333879]\n",
      "epoch:0 step:662 [D loss: 1.781995, acc: 14.84%] [G loss: 1.491508]\n",
      "epoch:0 step:663 [D loss: 0.582987, acc: 68.75%] [G loss: 1.998315]\n",
      "epoch:0 step:664 [D loss: 1.415306, acc: 28.91%] [G loss: 2.007099]\n",
      "epoch:0 step:665 [D loss: 1.025860, acc: 45.31%] [G loss: 2.184448]\n",
      "epoch:0 step:666 [D loss: 0.406923, acc: 80.47%] [G loss: 3.092705]\n",
      "epoch:0 step:667 [D loss: 0.339429, acc: 86.72%] [G loss: 3.528061]\n",
      "epoch:0 step:668 [D loss: 0.382545, acc: 81.25%] [G loss: 2.952404]\n",
      "epoch:0 step:669 [D loss: 0.280402, acc: 90.62%] [G loss: 3.272847]\n",
      "epoch:0 step:670 [D loss: 0.581158, acc: 72.66%] [G loss: 2.360746]\n",
      "epoch:0 step:671 [D loss: 0.435749, acc: 82.81%] [G loss: 2.582282]\n",
      "epoch:0 step:672 [D loss: 0.259212, acc: 93.75%] [G loss: 3.790613]\n",
      "epoch:0 step:673 [D loss: 0.326583, acc: 82.81%] [G loss: 3.148263]\n",
      "epoch:0 step:674 [D loss: 0.521889, acc: 74.22%] [G loss: 2.533869]\n",
      "epoch:0 step:675 [D loss: 0.431176, acc: 87.50%] [G loss: 2.895616]\n",
      "epoch:0 step:676 [D loss: 0.643037, acc: 61.72%] [G loss: 2.617213]\n",
      "epoch:0 step:677 [D loss: 0.335195, acc: 89.06%] [G loss: 2.731493]\n",
      "epoch:0 step:678 [D loss: 0.489168, acc: 75.78%] [G loss: 2.710247]\n",
      "epoch:0 step:679 [D loss: 0.248971, acc: 94.53%] [G loss: 2.955192]\n",
      "epoch:0 step:680 [D loss: 0.542391, acc: 71.88%] [G loss: 2.232518]\n",
      "epoch:0 step:681 [D loss: 0.393625, acc: 85.16%] [G loss: 2.914901]\n",
      "epoch:0 step:682 [D loss: 0.982192, acc: 37.50%] [G loss: 1.569914]\n",
      "epoch:0 step:683 [D loss: 0.641319, acc: 62.50%] [G loss: 2.092855]\n",
      "epoch:0 step:684 [D loss: 0.361912, acc: 89.84%] [G loss: 2.605970]\n",
      "epoch:0 step:685 [D loss: 0.521908, acc: 71.88%] [G loss: 2.247864]\n",
      "epoch:0 step:686 [D loss: 0.490587, acc: 78.12%] [G loss: 2.294843]\n",
      "epoch:0 step:687 [D loss: 0.939837, acc: 38.28%] [G loss: 1.720485]\n",
      "epoch:0 step:688 [D loss: 0.305827, acc: 95.31%] [G loss: 2.266711]\n",
      "epoch:0 step:689 [D loss: 0.508323, acc: 79.69%] [G loss: 2.475872]\n",
      "epoch:0 step:690 [D loss: 0.700652, acc: 59.38%] [G loss: 2.150710]\n",
      "epoch:0 step:691 [D loss: 0.528890, acc: 78.12%] [G loss: 2.263901]\n",
      "epoch:0 step:692 [D loss: 0.381729, acc: 85.94%] [G loss: 2.773457]\n",
      "epoch:0 step:693 [D loss: 0.546907, acc: 67.97%] [G loss: 2.381967]\n",
      "epoch:0 step:694 [D loss: 0.300623, acc: 90.62%] [G loss: 2.864589]\n",
      "epoch:0 step:695 [D loss: 0.573400, acc: 69.53%] [G loss: 2.061645]\n",
      "epoch:0 step:696 [D loss: 1.115970, acc: 28.12%] [G loss: 1.713006]\n",
      "epoch:0 step:697 [D loss: 0.334772, acc: 88.28%] [G loss: 2.714309]\n",
      "epoch:0 step:698 [D loss: 0.486241, acc: 78.91%] [G loss: 2.596503]\n",
      "epoch:0 step:699 [D loss: 0.481694, acc: 73.44%] [G loss: 1.792273]\n",
      "epoch:0 step:700 [D loss: 0.415472, acc: 82.03%] [G loss: 2.545153]\n",
      "epoch:0 step:701 [D loss: 0.611648, acc: 67.97%] [G loss: 1.932609]\n",
      "epoch:0 step:702 [D loss: 0.331450, acc: 90.62%] [G loss: 2.899040]\n",
      "epoch:0 step:703 [D loss: 0.863176, acc: 49.22%] [G loss: 1.834024]\n",
      "epoch:0 step:704 [D loss: 0.781334, acc: 53.91%] [G loss: 2.623438]\n",
      "epoch:0 step:705 [D loss: 0.574153, acc: 70.31%] [G loss: 2.050585]\n",
      "epoch:0 step:706 [D loss: 0.749808, acc: 60.16%] [G loss: 1.689430]\n",
      "epoch:0 step:707 [D loss: 0.498659, acc: 73.44%] [G loss: 2.517291]\n",
      "epoch:0 step:708 [D loss: 0.302670, acc: 90.62%] [G loss: 2.679396]\n",
      "epoch:0 step:709 [D loss: 0.624436, acc: 63.28%] [G loss: 1.900655]\n",
      "epoch:0 step:710 [D loss: 0.538825, acc: 78.12%] [G loss: 1.846148]\n",
      "epoch:0 step:711 [D loss: 0.802830, acc: 57.03%] [G loss: 1.544189]\n",
      "epoch:0 step:712 [D loss: 0.734863, acc: 56.25%] [G loss: 1.740333]\n",
      "epoch:0 step:713 [D loss: 0.293830, acc: 88.28%] [G loss: 2.534692]\n",
      "epoch:0 step:714 [D loss: 0.888369, acc: 48.44%] [G loss: 1.547004]\n",
      "epoch:0 step:715 [D loss: 0.583411, acc: 71.88%] [G loss: 2.435678]\n",
      "epoch:0 step:716 [D loss: 0.752580, acc: 64.84%] [G loss: 2.491223]\n",
      "epoch:0 step:717 [D loss: 0.428161, acc: 79.69%] [G loss: 2.059985]\n",
      "epoch:0 step:718 [D loss: 0.634565, acc: 67.97%] [G loss: 1.885386]\n",
      "epoch:0 step:719 [D loss: 0.578503, acc: 73.44%] [G loss: 2.423955]\n",
      "epoch:0 step:720 [D loss: 0.531367, acc: 72.66%] [G loss: 2.178734]\n",
      "epoch:0 step:721 [D loss: 0.948792, acc: 47.66%] [G loss: 2.285816]\n",
      "epoch:0 step:722 [D loss: 0.591892, acc: 69.53%] [G loss: 3.004728]\n",
      "epoch:0 step:723 [D loss: 0.499498, acc: 76.56%] [G loss: 3.942840]\n",
      "epoch:0 step:724 [D loss: 0.481522, acc: 79.69%] [G loss: 3.862136]\n",
      "epoch:0 step:725 [D loss: 0.697191, acc: 67.97%] [G loss: 2.913224]\n",
      "epoch:0 step:726 [D loss: 0.625092, acc: 71.09%] [G loss: 2.590622]\n",
      "epoch:0 step:727 [D loss: 0.233741, acc: 93.75%] [G loss: 3.573347]\n",
      "epoch:0 step:728 [D loss: 0.659468, acc: 67.97%] [G loss: 2.715186]\n",
      "epoch:0 step:729 [D loss: 0.678900, acc: 68.75%] [G loss: 2.209148]\n",
      "epoch:0 step:730 [D loss: 0.562946, acc: 74.22%] [G loss: 1.799209]\n",
      "epoch:0 step:731 [D loss: 0.483768, acc: 82.03%] [G loss: 2.374884]\n",
      "epoch:0 step:732 [D loss: 0.434523, acc: 82.03%] [G loss: 2.367426]\n",
      "epoch:0 step:733 [D loss: 0.536642, acc: 75.00%] [G loss: 1.988217]\n",
      "epoch:0 step:734 [D loss: 0.405380, acc: 85.94%] [G loss: 1.694287]\n",
      "epoch:0 step:735 [D loss: 0.256861, acc: 90.62%] [G loss: 2.104274]\n",
      "epoch:0 step:736 [D loss: 0.383809, acc: 84.38%] [G loss: 2.163182]\n",
      "epoch:0 step:737 [D loss: 0.627821, acc: 64.84%] [G loss: 1.664011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:738 [D loss: 0.628650, acc: 71.09%] [G loss: 1.466345]\n",
      "epoch:0 step:739 [D loss: 0.490047, acc: 72.66%] [G loss: 1.864558]\n",
      "epoch:0 step:740 [D loss: 0.637495, acc: 63.28%] [G loss: 1.977572]\n",
      "epoch:0 step:741 [D loss: 0.422662, acc: 82.81%] [G loss: 1.990795]\n",
      "epoch:0 step:742 [D loss: 1.056256, acc: 47.66%] [G loss: 1.437917]\n",
      "epoch:0 step:743 [D loss: 0.305440, acc: 85.16%] [G loss: 2.456446]\n",
      "epoch:0 step:744 [D loss: 0.777095, acc: 58.59%] [G loss: 1.707332]\n",
      "epoch:0 step:745 [D loss: 0.842925, acc: 50.78%] [G loss: 2.078422]\n",
      "epoch:0 step:746 [D loss: 1.229781, acc: 31.25%] [G loss: 1.598567]\n",
      "epoch:0 step:747 [D loss: 0.564521, acc: 64.84%] [G loss: 2.156147]\n",
      "epoch:0 step:748 [D loss: 0.769213, acc: 52.34%] [G loss: 1.864809]\n",
      "epoch:0 step:749 [D loss: 0.540191, acc: 81.25%] [G loss: 2.000611]\n",
      "epoch:0 step:750 [D loss: 0.411405, acc: 82.81%] [G loss: 2.240894]\n",
      "epoch:0 step:751 [D loss: 0.580835, acc: 76.56%] [G loss: 2.360573]\n",
      "epoch:0 step:752 [D loss: 0.514087, acc: 82.81%] [G loss: 2.329279]\n",
      "epoch:0 step:753 [D loss: 1.161276, acc: 39.84%] [G loss: 2.103149]\n",
      "epoch:0 step:754 [D loss: 0.987814, acc: 39.06%] [G loss: 2.023457]\n",
      "epoch:0 step:755 [D loss: 0.567511, acc: 67.19%] [G loss: 3.017829]\n",
      "epoch:0 step:756 [D loss: 0.494906, acc: 78.12%] [G loss: 2.732911]\n",
      "epoch:0 step:757 [D loss: 0.570191, acc: 71.88%] [G loss: 3.052082]\n",
      "epoch:0 step:758 [D loss: 0.514565, acc: 77.34%] [G loss: 3.106433]\n",
      "epoch:0 step:759 [D loss: 0.552944, acc: 70.31%] [G loss: 3.029660]\n",
      "epoch:0 step:760 [D loss: 0.412083, acc: 82.81%] [G loss: 3.350393]\n",
      "epoch:0 step:761 [D loss: 0.583438, acc: 75.00%] [G loss: 2.924973]\n",
      "epoch:0 step:762 [D loss: 0.549840, acc: 74.22%] [G loss: 3.047335]\n",
      "epoch:0 step:763 [D loss: 0.614643, acc: 74.22%] [G loss: 2.754290]\n",
      "epoch:0 step:764 [D loss: 0.492884, acc: 75.78%] [G loss: 2.815674]\n",
      "epoch:0 step:765 [D loss: 0.358774, acc: 87.50%] [G loss: 2.971510]\n",
      "epoch:0 step:766 [D loss: 0.335390, acc: 88.28%] [G loss: 2.966252]\n",
      "epoch:0 step:767 [D loss: 0.416834, acc: 85.16%] [G loss: 2.862242]\n",
      "epoch:0 step:768 [D loss: 0.240246, acc: 95.31%] [G loss: 3.284986]\n",
      "epoch:0 step:769 [D loss: 0.326200, acc: 89.06%] [G loss: 2.211102]\n",
      "epoch:0 step:770 [D loss: 0.198716, acc: 98.44%] [G loss: 2.756056]\n",
      "epoch:0 step:771 [D loss: 0.339308, acc: 89.84%] [G loss: 2.801793]\n",
      "epoch:0 step:772 [D loss: 0.171358, acc: 92.97%] [G loss: 2.873506]\n",
      "epoch:0 step:773 [D loss: 0.181050, acc: 98.44%] [G loss: 2.909094]\n",
      "epoch:0 step:774 [D loss: 0.366636, acc: 87.50%] [G loss: 2.361736]\n",
      "epoch:0 step:775 [D loss: 0.271598, acc: 92.97%] [G loss: 2.353883]\n",
      "epoch:0 step:776 [D loss: 0.317973, acc: 96.09%] [G loss: 2.474622]\n",
      "epoch:0 step:777 [D loss: 0.220895, acc: 96.09%] [G loss: 2.280022]\n",
      "epoch:0 step:778 [D loss: 0.435145, acc: 85.16%] [G loss: 2.379546]\n",
      "epoch:0 step:779 [D loss: 1.097761, acc: 32.03%] [G loss: 1.219242]\n",
      "epoch:0 step:780 [D loss: 1.458895, acc: 11.72%] [G loss: 0.954000]\n",
      "epoch:0 step:781 [D loss: 0.142463, acc: 99.22%] [G loss: 2.260922]\n",
      "epoch:1 step:782 [D loss: 0.291449, acc: 96.88%] [G loss: 2.530390]\n",
      "epoch:1 step:783 [D loss: 0.726067, acc: 54.69%] [G loss: 1.925222]\n",
      "epoch:1 step:784 [D loss: 0.300506, acc: 85.16%] [G loss: 1.650606]\n",
      "epoch:1 step:785 [D loss: 1.110271, acc: 37.50%] [G loss: 1.459610]\n",
      "epoch:1 step:786 [D loss: 0.744457, acc: 62.50%] [G loss: 1.350782]\n",
      "epoch:1 step:787 [D loss: 0.350073, acc: 90.62%] [G loss: 2.219914]\n",
      "epoch:1 step:788 [D loss: 1.022324, acc: 46.09%] [G loss: 1.858147]\n",
      "epoch:1 step:789 [D loss: 0.538600, acc: 76.56%] [G loss: 1.868251]\n",
      "epoch:1 step:790 [D loss: 0.881569, acc: 57.03%] [G loss: 1.442320]\n",
      "epoch:1 step:791 [D loss: 0.729390, acc: 54.69%] [G loss: 1.958906]\n",
      "epoch:1 step:792 [D loss: 0.389799, acc: 85.94%] [G loss: 1.882957]\n",
      "epoch:1 step:793 [D loss: 1.230208, acc: 32.03%] [G loss: 1.262881]\n",
      "epoch:1 step:794 [D loss: 0.621975, acc: 65.62%] [G loss: 2.001274]\n",
      "epoch:1 step:795 [D loss: 0.488082, acc: 73.44%] [G loss: 2.264980]\n",
      "epoch:1 step:796 [D loss: 0.568276, acc: 68.75%] [G loss: 3.064981]\n",
      "epoch:1 step:797 [D loss: 0.716863, acc: 64.84%] [G loss: 2.850541]\n",
      "epoch:1 step:798 [D loss: 0.940166, acc: 44.53%] [G loss: 2.669988]\n",
      "epoch:1 step:799 [D loss: 0.802405, acc: 57.81%] [G loss: 2.747567]\n",
      "epoch:1 step:800 [D loss: 0.573448, acc: 67.97%] [G loss: 3.074624]\n",
      "epoch:1 step:801 [D loss: 0.556168, acc: 75.00%] [G loss: 3.402913]\n",
      "epoch:1 step:802 [D loss: 0.582167, acc: 64.84%] [G loss: 3.075812]\n",
      "epoch:1 step:803 [D loss: 0.451772, acc: 81.25%] [G loss: 3.481364]\n",
      "epoch:1 step:804 [D loss: 0.522598, acc: 75.00%] [G loss: 3.064563]\n",
      "epoch:1 step:805 [D loss: 0.343475, acc: 85.94%] [G loss: 2.883284]\n",
      "epoch:1 step:806 [D loss: 0.207998, acc: 90.62%] [G loss: 3.301443]\n",
      "epoch:1 step:807 [D loss: 0.208508, acc: 95.31%] [G loss: 3.606277]\n",
      "epoch:1 step:808 [D loss: 0.240062, acc: 94.53%] [G loss: 2.958220]\n",
      "epoch:1 step:809 [D loss: 0.462763, acc: 76.56%] [G loss: 2.589897]\n",
      "epoch:1 step:810 [D loss: 0.398556, acc: 79.69%] [G loss: 2.561565]\n",
      "epoch:1 step:811 [D loss: 0.197227, acc: 92.97%] [G loss: 2.868800]\n",
      "epoch:1 step:812 [D loss: 0.189025, acc: 95.31%] [G loss: 2.784267]\n",
      "epoch:1 step:813 [D loss: 0.672778, acc: 68.75%] [G loss: 2.550235]\n",
      "epoch:1 step:814 [D loss: 0.182699, acc: 93.75%] [G loss: 2.493674]\n",
      "epoch:1 step:815 [D loss: 0.501914, acc: 78.12%] [G loss: 2.694951]\n",
      "epoch:1 step:816 [D loss: 0.964326, acc: 44.53%] [G loss: 1.759505]\n",
      "epoch:1 step:817 [D loss: 0.300358, acc: 90.62%] [G loss: 2.038531]\n",
      "epoch:1 step:818 [D loss: 0.307707, acc: 89.84%] [G loss: 2.254910]\n",
      "epoch:1 step:819 [D loss: 0.332072, acc: 86.72%] [G loss: 2.329959]\n",
      "epoch:1 step:820 [D loss: 0.101532, acc: 98.44%] [G loss: 3.033259]\n",
      "epoch:1 step:821 [D loss: 0.462444, acc: 78.12%] [G loss: 2.656159]\n",
      "epoch:1 step:822 [D loss: 0.250458, acc: 92.97%] [G loss: 2.172454]\n",
      "epoch:1 step:823 [D loss: 0.271491, acc: 89.84%] [G loss: 2.804705]\n",
      "epoch:1 step:824 [D loss: 0.275555, acc: 89.84%] [G loss: 2.108535]\n",
      "epoch:1 step:825 [D loss: 0.512465, acc: 78.91%] [G loss: 2.036994]\n",
      "epoch:1 step:826 [D loss: 0.482640, acc: 75.78%] [G loss: 2.210124]\n",
      "epoch:1 step:827 [D loss: 0.137313, acc: 97.66%] [G loss: 2.773541]\n",
      "epoch:1 step:828 [D loss: 0.680932, acc: 65.62%] [G loss: 1.677073]\n",
      "epoch:1 step:829 [D loss: 0.131037, acc: 99.22%] [G loss: 2.702579]\n",
      "epoch:1 step:830 [D loss: 0.350762, acc: 85.16%] [G loss: 3.240205]\n",
      "epoch:1 step:831 [D loss: 0.711488, acc: 61.72%] [G loss: 1.624990]\n",
      "epoch:1 step:832 [D loss: 0.209419, acc: 94.53%] [G loss: 2.606685]\n",
      "epoch:1 step:833 [D loss: 0.998186, acc: 39.84%] [G loss: 2.013863]\n",
      "epoch:1 step:834 [D loss: 0.616846, acc: 64.06%] [G loss: 2.604566]\n",
      "epoch:1 step:835 [D loss: 0.504729, acc: 74.22%] [G loss: 2.135865]\n",
      "epoch:1 step:836 [D loss: 0.534348, acc: 69.53%] [G loss: 2.979020]\n",
      "epoch:1 step:837 [D loss: 2.571770, acc: 13.28%] [G loss: 2.523363]\n",
      "epoch:1 step:838 [D loss: 0.518427, acc: 75.78%] [G loss: 3.909618]\n",
      "epoch:1 step:839 [D loss: 0.326082, acc: 87.50%] [G loss: 3.220502]\n",
      "epoch:1 step:840 [D loss: 0.446081, acc: 78.12%] [G loss: 2.933980]\n",
      "epoch:1 step:841 [D loss: 0.601626, acc: 74.22%] [G loss: 2.439453]\n",
      "epoch:1 step:842 [D loss: 0.467132, acc: 76.56%] [G loss: 2.641958]\n",
      "epoch:1 step:843 [D loss: 0.637384, acc: 73.44%] [G loss: 2.166977]\n",
      "epoch:1 step:844 [D loss: 0.586056, acc: 66.41%] [G loss: 2.575586]\n",
      "epoch:1 step:845 [D loss: 0.642634, acc: 67.19%] [G loss: 2.370460]\n",
      "epoch:1 step:846 [D loss: 0.779292, acc: 53.91%] [G loss: 2.669449]\n",
      "epoch:1 step:847 [D loss: 0.337288, acc: 90.62%] [G loss: 2.800717]\n",
      "epoch:1 step:848 [D loss: 0.469072, acc: 78.91%] [G loss: 2.546354]\n",
      "epoch:1 step:849 [D loss: 0.421844, acc: 82.81%] [G loss: 2.483284]\n",
      "epoch:1 step:850 [D loss: 0.453662, acc: 74.22%] [G loss: 2.579022]\n",
      "epoch:1 step:851 [D loss: 0.579245, acc: 72.66%] [G loss: 2.310042]\n",
      "epoch:1 step:852 [D loss: 0.441817, acc: 83.59%] [G loss: 3.619376]\n",
      "epoch:1 step:853 [D loss: 0.521766, acc: 80.47%] [G loss: 2.247706]\n",
      "epoch:1 step:854 [D loss: 0.430861, acc: 83.59%] [G loss: 2.369281]\n",
      "epoch:1 step:855 [D loss: 0.505914, acc: 75.78%] [G loss: 2.539822]\n",
      "epoch:1 step:856 [D loss: 0.231867, acc: 93.75%] [G loss: 2.682584]\n",
      "epoch:1 step:857 [D loss: 0.312476, acc: 92.19%] [G loss: 2.429947]\n",
      "epoch:1 step:858 [D loss: 0.312083, acc: 91.41%] [G loss: 3.058006]\n",
      "epoch:1 step:859 [D loss: 0.199207, acc: 97.66%] [G loss: 2.978135]\n",
      "epoch:1 step:860 [D loss: 0.284197, acc: 93.75%] [G loss: 2.901632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:861 [D loss: 0.174002, acc: 97.66%] [G loss: 3.421014]\n",
      "epoch:1 step:862 [D loss: 0.551293, acc: 78.12%] [G loss: 2.693973]\n",
      "epoch:1 step:863 [D loss: 0.352291, acc: 88.28%] [G loss: 2.803695]\n",
      "epoch:1 step:864 [D loss: 0.287956, acc: 88.28%] [G loss: 3.006020]\n",
      "epoch:1 step:865 [D loss: 0.485128, acc: 71.09%] [G loss: 2.371019]\n",
      "epoch:1 step:866 [D loss: 0.313844, acc: 87.50%] [G loss: 3.328740]\n",
      "epoch:1 step:867 [D loss: 0.246669, acc: 94.53%] [G loss: 2.357322]\n",
      "epoch:1 step:868 [D loss: 0.152917, acc: 99.22%] [G loss: 2.820827]\n",
      "epoch:1 step:869 [D loss: 0.378308, acc: 86.72%] [G loss: 2.711905]\n",
      "epoch:1 step:870 [D loss: 0.840314, acc: 49.22%] [G loss: 2.102899]\n",
      "epoch:1 step:871 [D loss: 0.399760, acc: 87.50%] [G loss: 2.327820]\n",
      "epoch:1 step:872 [D loss: 0.454505, acc: 77.34%] [G loss: 2.247572]\n",
      "epoch:1 step:873 [D loss: 0.320807, acc: 89.84%] [G loss: 2.075746]\n",
      "epoch:1 step:874 [D loss: 0.609898, acc: 64.06%] [G loss: 1.622747]\n",
      "epoch:1 step:875 [D loss: 0.333062, acc: 85.94%] [G loss: 2.057426]\n",
      "epoch:1 step:876 [D loss: 0.545074, acc: 69.53%] [G loss: 2.022331]\n",
      "epoch:1 step:877 [D loss: 0.327850, acc: 86.72%] [G loss: 2.381393]\n",
      "epoch:1 step:878 [D loss: 0.448384, acc: 77.34%] [G loss: 2.104610]\n",
      "epoch:1 step:879 [D loss: 0.421607, acc: 79.69%] [G loss: 1.695181]\n",
      "epoch:1 step:880 [D loss: 0.487773, acc: 79.69%] [G loss: 2.191863]\n",
      "epoch:1 step:881 [D loss: 0.642302, acc: 64.06%] [G loss: 1.504759]\n",
      "epoch:1 step:882 [D loss: 0.496001, acc: 80.47%] [G loss: 1.494234]\n",
      "epoch:1 step:883 [D loss: 0.206422, acc: 98.44%] [G loss: 2.204867]\n",
      "epoch:1 step:884 [D loss: 0.952864, acc: 50.78%] [G loss: 2.242129]\n",
      "epoch:1 step:885 [D loss: 1.076359, acc: 49.22%] [G loss: 1.959651]\n",
      "epoch:1 step:886 [D loss: 0.724524, acc: 60.94%] [G loss: 2.217431]\n",
      "epoch:1 step:887 [D loss: 0.685583, acc: 60.16%] [G loss: 2.472305]\n",
      "epoch:1 step:888 [D loss: 1.218151, acc: 31.25%] [G loss: 2.573859]\n",
      "epoch:1 step:889 [D loss: 0.449995, acc: 84.38%] [G loss: 3.951611]\n",
      "epoch:1 step:890 [D loss: 0.646157, acc: 69.53%] [G loss: 3.599278]\n",
      "epoch:1 step:891 [D loss: 0.514811, acc: 72.66%] [G loss: 3.432113]\n",
      "epoch:1 step:892 [D loss: 0.811514, acc: 63.28%] [G loss: 2.757680]\n",
      "epoch:1 step:893 [D loss: 0.479508, acc: 84.38%] [G loss: 2.978921]\n",
      "epoch:1 step:894 [D loss: 0.162050, acc: 96.88%] [G loss: 2.827126]\n",
      "epoch:1 step:895 [D loss: 0.236400, acc: 94.53%] [G loss: 2.532990]\n",
      "epoch:1 step:896 [D loss: 0.245713, acc: 92.97%] [G loss: 2.610558]\n",
      "epoch:1 step:897 [D loss: 0.225335, acc: 92.19%] [G loss: 2.822371]\n",
      "epoch:1 step:898 [D loss: 0.175905, acc: 98.44%] [G loss: 2.924496]\n",
      "epoch:1 step:899 [D loss: 0.605965, acc: 66.41%] [G loss: 2.238818]\n",
      "epoch:1 step:900 [D loss: 0.282981, acc: 88.28%] [G loss: 2.410013]\n",
      "epoch:1 step:901 [D loss: 0.362142, acc: 85.16%] [G loss: 2.301000]\n",
      "epoch:1 step:902 [D loss: 0.190535, acc: 96.09%] [G loss: 2.479141]\n",
      "epoch:1 step:903 [D loss: 0.290195, acc: 88.28%] [G loss: 2.440273]\n",
      "epoch:1 step:904 [D loss: 0.551667, acc: 78.91%] [G loss: 1.673373]\n",
      "epoch:1 step:905 [D loss: 0.755792, acc: 62.50%] [G loss: 1.740553]\n",
      "epoch:1 step:906 [D loss: 0.326392, acc: 85.94%] [G loss: 2.216403]\n",
      "epoch:1 step:907 [D loss: 1.029624, acc: 49.22%] [G loss: 2.304071]\n",
      "epoch:1 step:908 [D loss: 0.764296, acc: 60.94%] [G loss: 2.325492]\n",
      "epoch:1 step:909 [D loss: 0.442818, acc: 78.91%] [G loss: 1.924755]\n",
      "epoch:1 step:910 [D loss: 0.604483, acc: 71.09%] [G loss: 2.126914]\n",
      "epoch:1 step:911 [D loss: 0.589057, acc: 67.19%] [G loss: 2.339147]\n",
      "epoch:1 step:912 [D loss: 0.582997, acc: 68.75%] [G loss: 2.226399]\n",
      "epoch:1 step:913 [D loss: 0.466924, acc: 71.88%] [G loss: 2.144401]\n",
      "epoch:1 step:914 [D loss: 0.815581, acc: 46.09%] [G loss: 1.699403]\n",
      "epoch:1 step:915 [D loss: 0.169328, acc: 98.44%] [G loss: 2.292310]\n",
      "epoch:1 step:916 [D loss: 0.660437, acc: 62.50%] [G loss: 2.277257]\n",
      "epoch:1 step:917 [D loss: 0.159058, acc: 96.88%] [G loss: 3.342208]\n",
      "epoch:1 step:918 [D loss: 0.443322, acc: 78.12%] [G loss: 2.578314]\n",
      "epoch:1 step:919 [D loss: 0.224142, acc: 89.84%] [G loss: 2.604930]\n",
      "epoch:1 step:920 [D loss: 0.188935, acc: 97.66%] [G loss: 3.074920]\n",
      "epoch:1 step:921 [D loss: 0.409546, acc: 85.94%] [G loss: 2.916050]\n",
      "epoch:1 step:922 [D loss: 0.143350, acc: 98.44%] [G loss: 3.562900]\n",
      "epoch:1 step:923 [D loss: 0.145253, acc: 98.44%] [G loss: 2.876898]\n",
      "epoch:1 step:924 [D loss: 0.130721, acc: 97.66%] [G loss: 3.436629]\n",
      "epoch:1 step:925 [D loss: 0.175918, acc: 98.44%] [G loss: 3.404792]\n",
      "epoch:1 step:926 [D loss: 0.415592, acc: 76.56%] [G loss: 4.215002]\n",
      "epoch:1 step:927 [D loss: 0.100911, acc: 98.44%] [G loss: 3.254276]\n",
      "epoch:1 step:928 [D loss: 0.113049, acc: 96.09%] [G loss: 3.561709]\n",
      "epoch:1 step:929 [D loss: 0.143329, acc: 96.09%] [G loss: 3.279775]\n",
      "epoch:1 step:930 [D loss: 0.143460, acc: 96.09%] [G loss: 3.967406]\n",
      "epoch:1 step:931 [D loss: 0.196241, acc: 94.53%] [G loss: 3.721980]\n",
      "epoch:1 step:932 [D loss: 0.138008, acc: 98.44%] [G loss: 3.011598]\n",
      "epoch:1 step:933 [D loss: 0.481670, acc: 75.78%] [G loss: 2.509185]\n",
      "epoch:1 step:934 [D loss: 0.108584, acc: 99.22%] [G loss: 3.149124]\n",
      "epoch:1 step:935 [D loss: 0.116165, acc: 99.22%] [G loss: 3.584475]\n",
      "epoch:1 step:936 [D loss: 0.315303, acc: 88.28%] [G loss: 2.665700]\n",
      "epoch:1 step:937 [D loss: 0.229917, acc: 90.62%] [G loss: 3.481861]\n",
      "epoch:1 step:938 [D loss: 0.301716, acc: 90.62%] [G loss: 2.675735]\n",
      "epoch:1 step:939 [D loss: 0.473484, acc: 79.69%] [G loss: 2.675325]\n",
      "epoch:1 step:940 [D loss: 0.422632, acc: 82.81%] [G loss: 2.889780]\n",
      "epoch:1 step:941 [D loss: 0.415573, acc: 82.03%] [G loss: 2.837540]\n",
      "epoch:1 step:942 [D loss: 0.300946, acc: 89.06%] [G loss: 2.474195]\n",
      "epoch:1 step:943 [D loss: 0.238218, acc: 93.75%] [G loss: 2.990299]\n",
      "epoch:1 step:944 [D loss: 0.649102, acc: 59.38%] [G loss: 2.839212]\n",
      "epoch:1 step:945 [D loss: 0.776334, acc: 53.91%] [G loss: 2.544003]\n",
      "epoch:1 step:946 [D loss: 0.505722, acc: 77.34%] [G loss: 3.321810]\n",
      "epoch:1 step:947 [D loss: 0.397959, acc: 82.81%] [G loss: 3.278197]\n",
      "epoch:1 step:948 [D loss: 0.276419, acc: 92.19%] [G loss: 4.080785]\n",
      "epoch:1 step:949 [D loss: 0.399108, acc: 84.38%] [G loss: 3.415536]\n",
      "epoch:1 step:950 [D loss: 0.517803, acc: 75.78%] [G loss: 3.465559]\n",
      "epoch:1 step:951 [D loss: 0.369024, acc: 82.03%] [G loss: 4.201381]\n",
      "epoch:1 step:952 [D loss: 0.255997, acc: 91.41%] [G loss: 3.797500]\n",
      "epoch:1 step:953 [D loss: 0.379829, acc: 86.72%] [G loss: 4.109421]\n",
      "epoch:1 step:954 [D loss: 0.516629, acc: 70.31%] [G loss: 2.924774]\n",
      "epoch:1 step:955 [D loss: 0.340436, acc: 85.16%] [G loss: 3.766987]\n",
      "epoch:1 step:956 [D loss: 0.271607, acc: 92.97%] [G loss: 3.140739]\n",
      "epoch:1 step:957 [D loss: 0.292197, acc: 87.50%] [G loss: 3.588624]\n",
      "epoch:1 step:958 [D loss: 0.256605, acc: 94.53%] [G loss: 3.629342]\n",
      "epoch:1 step:959 [D loss: 0.176507, acc: 97.66%] [G loss: 4.145950]\n",
      "epoch:1 step:960 [D loss: 0.146085, acc: 98.44%] [G loss: 3.986877]\n",
      "epoch:1 step:961 [D loss: 0.178278, acc: 96.09%] [G loss: 3.940332]\n",
      "epoch:1 step:962 [D loss: 0.413349, acc: 82.03%] [G loss: 2.600516]\n",
      "epoch:1 step:963 [D loss: 0.128591, acc: 97.66%] [G loss: 2.856105]\n",
      "epoch:1 step:964 [D loss: 0.157515, acc: 98.44%] [G loss: 3.294985]\n",
      "epoch:1 step:965 [D loss: 0.254135, acc: 95.31%] [G loss: 2.880804]\n",
      "epoch:1 step:966 [D loss: 0.739510, acc: 60.16%] [G loss: 2.307840]\n",
      "epoch:1 step:967 [D loss: 0.304631, acc: 91.41%] [G loss: 2.480322]\n",
      "epoch:1 step:968 [D loss: 0.103463, acc: 100.00%] [G loss: 3.792582]\n",
      "epoch:1 step:969 [D loss: 0.136144, acc: 98.44%] [G loss: 3.180490]\n",
      "epoch:1 step:970 [D loss: 0.349221, acc: 91.41%] [G loss: 2.986273]\n",
      "epoch:1 step:971 [D loss: 0.105275, acc: 98.44%] [G loss: 3.046050]\n",
      "epoch:1 step:972 [D loss: 0.094813, acc: 99.22%] [G loss: 3.003950]\n",
      "epoch:1 step:973 [D loss: 0.205211, acc: 94.53%] [G loss: 2.752121]\n",
      "epoch:1 step:974 [D loss: 0.128533, acc: 97.66%] [G loss: 2.798921]\n",
      "epoch:1 step:975 [D loss: 0.292115, acc: 92.19%] [G loss: 2.716303]\n",
      "epoch:1 step:976 [D loss: 0.304129, acc: 91.41%] [G loss: 2.062587]\n",
      "epoch:1 step:977 [D loss: 0.685865, acc: 63.28%] [G loss: 2.393893]\n",
      "epoch:1 step:978 [D loss: 0.107937, acc: 96.09%] [G loss: 2.947767]\n",
      "epoch:1 step:979 [D loss: 0.137206, acc: 98.44%] [G loss: 2.980512]\n",
      "epoch:1 step:980 [D loss: 0.475687, acc: 77.34%] [G loss: 1.967228]\n",
      "epoch:1 step:981 [D loss: 0.260263, acc: 91.41%] [G loss: 1.868215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:982 [D loss: 0.195906, acc: 93.75%] [G loss: 2.494264]\n",
      "epoch:1 step:983 [D loss: 0.605523, acc: 71.88%] [G loss: 2.002455]\n",
      "epoch:1 step:984 [D loss: 0.275195, acc: 90.62%] [G loss: 1.828883]\n",
      "epoch:1 step:985 [D loss: 0.228343, acc: 94.53%] [G loss: 2.210436]\n",
      "epoch:1 step:986 [D loss: 0.294019, acc: 89.06%] [G loss: 2.510739]\n",
      "epoch:1 step:987 [D loss: 1.689226, acc: 30.47%] [G loss: 1.457831]\n",
      "epoch:1 step:988 [D loss: 0.654998, acc: 65.62%] [G loss: 1.551267]\n",
      "epoch:1 step:989 [D loss: 0.324524, acc: 88.28%] [G loss: 2.289939]\n",
      "epoch:1 step:990 [D loss: 0.502854, acc: 75.78%] [G loss: 2.322217]\n",
      "epoch:1 step:991 [D loss: 0.264747, acc: 92.19%] [G loss: 2.067266]\n",
      "epoch:1 step:992 [D loss: 0.476161, acc: 77.34%] [G loss: 2.363104]\n",
      "epoch:1 step:993 [D loss: 0.951968, acc: 40.62%] [G loss: 1.758047]\n",
      "epoch:1 step:994 [D loss: 1.010758, acc: 52.34%] [G loss: 2.108657]\n",
      "epoch:1 step:995 [D loss: 0.728632, acc: 65.62%] [G loss: 2.596276]\n",
      "epoch:1 step:996 [D loss: 2.513395, acc: 7.03%] [G loss: 1.551906]\n",
      "epoch:1 step:997 [D loss: 1.757268, acc: 33.59%] [G loss: 1.843534]\n",
      "epoch:1 step:998 [D loss: 0.828653, acc: 56.25%] [G loss: 2.524165]\n",
      "epoch:1 step:999 [D loss: 0.947312, acc: 47.66%] [G loss: 3.334935]\n",
      "epoch:1 step:1000 [D loss: 0.344902, acc: 85.94%] [G loss: 3.952162]\n",
      "epoch:1 step:1001 [D loss: 0.367779, acc: 85.94%] [G loss: 3.471415]\n",
      "epoch:1 step:1002 [D loss: 0.155814, acc: 98.44%] [G loss: 3.733680]\n",
      "epoch:1 step:1003 [D loss: 0.127787, acc: 96.88%] [G loss: 3.292210]\n",
      "epoch:1 step:1004 [D loss: 0.131035, acc: 98.44%] [G loss: 3.212089]\n",
      "epoch:1 step:1005 [D loss: 0.097444, acc: 99.22%] [G loss: 2.864009]\n",
      "epoch:1 step:1006 [D loss: 0.505456, acc: 71.09%] [G loss: 2.894557]\n",
      "epoch:1 step:1007 [D loss: 0.187219, acc: 92.97%] [G loss: 3.458862]\n",
      "epoch:1 step:1008 [D loss: 0.192188, acc: 94.53%] [G loss: 2.960580]\n",
      "epoch:1 step:1009 [D loss: 0.078356, acc: 100.00%] [G loss: 3.435768]\n",
      "epoch:1 step:1010 [D loss: 0.072139, acc: 99.22%] [G loss: 3.955439]\n",
      "epoch:1 step:1011 [D loss: 0.304811, acc: 84.38%] [G loss: 3.627348]\n",
      "epoch:1 step:1012 [D loss: 0.173217, acc: 93.75%] [G loss: 3.032251]\n",
      "epoch:1 step:1013 [D loss: 0.112515, acc: 96.88%] [G loss: 2.966042]\n",
      "epoch:1 step:1014 [D loss: 0.206731, acc: 92.97%] [G loss: 3.024811]\n",
      "epoch:1 step:1015 [D loss: 0.074796, acc: 100.00%] [G loss: 3.174363]\n",
      "epoch:1 step:1016 [D loss: 0.152279, acc: 96.88%] [G loss: 3.313558]\n",
      "epoch:1 step:1017 [D loss: 0.113470, acc: 99.22%] [G loss: 3.070478]\n",
      "epoch:1 step:1018 [D loss: 0.146488, acc: 96.88%] [G loss: 3.444074]\n",
      "epoch:1 step:1019 [D loss: 0.170049, acc: 96.09%] [G loss: 2.483125]\n",
      "epoch:1 step:1020 [D loss: 0.250124, acc: 90.62%] [G loss: 2.712067]\n",
      "epoch:1 step:1021 [D loss: 0.412781, acc: 85.16%] [G loss: 2.350644]\n",
      "epoch:1 step:1022 [D loss: 0.092649, acc: 100.00%] [G loss: 3.054203]\n",
      "epoch:1 step:1023 [D loss: 0.457941, acc: 73.44%] [G loss: 2.987556]\n",
      "epoch:1 step:1024 [D loss: 0.295887, acc: 84.38%] [G loss: 2.374450]\n",
      "epoch:1 step:1025 [D loss: 0.192393, acc: 94.53%] [G loss: 2.813377]\n",
      "epoch:1 step:1026 [D loss: 0.268162, acc: 89.84%] [G loss: 2.556747]\n",
      "epoch:1 step:1027 [D loss: 0.516762, acc: 71.88%] [G loss: 1.569394]\n",
      "epoch:1 step:1028 [D loss: 1.325410, acc: 47.66%] [G loss: 1.062987]\n",
      "epoch:1 step:1029 [D loss: 0.302215, acc: 88.28%] [G loss: 2.544722]\n",
      "epoch:1 step:1030 [D loss: 0.667343, acc: 71.09%] [G loss: 1.438332]\n",
      "epoch:1 step:1031 [D loss: 0.423910, acc: 85.94%] [G loss: 1.938550]\n",
      "epoch:1 step:1032 [D loss: 0.363298, acc: 79.69%] [G loss: 1.803710]\n",
      "epoch:1 step:1033 [D loss: 0.501750, acc: 70.31%] [G loss: 2.230113]\n",
      "epoch:1 step:1034 [D loss: 0.292974, acc: 92.19%] [G loss: 2.850738]\n",
      "epoch:1 step:1035 [D loss: 0.070043, acc: 98.44%] [G loss: 3.094680]\n",
      "epoch:1 step:1036 [D loss: 0.091871, acc: 100.00%] [G loss: 3.279014]\n",
      "epoch:1 step:1037 [D loss: 0.172826, acc: 92.97%] [G loss: 2.468177]\n",
      "epoch:1 step:1038 [D loss: 0.466572, acc: 73.44%] [G loss: 2.504111]\n",
      "epoch:1 step:1039 [D loss: 0.366254, acc: 84.38%] [G loss: 1.705826]\n",
      "epoch:1 step:1040 [D loss: 0.343861, acc: 90.62%] [G loss: 2.205514]\n",
      "epoch:1 step:1041 [D loss: 0.495787, acc: 81.25%] [G loss: 1.579746]\n",
      "epoch:1 step:1042 [D loss: 0.941574, acc: 36.72%] [G loss: 1.240861]\n",
      "epoch:1 step:1043 [D loss: 0.427075, acc: 82.03%] [G loss: 1.813589]\n",
      "epoch:1 step:1044 [D loss: 0.032512, acc: 99.22%] [G loss: 3.759499]\n",
      "epoch:1 step:1045 [D loss: 0.876743, acc: 46.88%] [G loss: 1.784072]\n",
      "epoch:1 step:1046 [D loss: 0.539346, acc: 64.06%] [G loss: 2.170894]\n",
      "epoch:1 step:1047 [D loss: 0.080303, acc: 98.44%] [G loss: 4.234965]\n",
      "epoch:1 step:1048 [D loss: 0.529657, acc: 65.62%] [G loss: 2.820749]\n",
      "epoch:1 step:1049 [D loss: 0.187970, acc: 91.41%] [G loss: 1.754846]\n",
      "epoch:1 step:1050 [D loss: 0.560808, acc: 74.22%] [G loss: 2.071485]\n",
      "epoch:1 step:1051 [D loss: 0.728597, acc: 58.59%] [G loss: 1.762138]\n",
      "epoch:1 step:1052 [D loss: 0.224957, acc: 93.75%] [G loss: 2.700379]\n",
      "epoch:1 step:1053 [D loss: 0.410694, acc: 82.03%] [G loss: 2.170729]\n",
      "epoch:1 step:1054 [D loss: 0.435512, acc: 82.81%] [G loss: 2.012381]\n",
      "epoch:1 step:1055 [D loss: 0.136091, acc: 96.88%] [G loss: 2.391956]\n",
      "epoch:1 step:1056 [D loss: 1.606971, acc: 17.19%] [G loss: 1.630261]\n",
      "epoch:1 step:1057 [D loss: 0.147133, acc: 97.66%] [G loss: 2.948220]\n",
      "epoch:1 step:1058 [D loss: 0.882287, acc: 53.91%] [G loss: 3.203829]\n",
      "epoch:1 step:1059 [D loss: 0.298740, acc: 88.28%] [G loss: 3.595361]\n",
      "epoch:1 step:1060 [D loss: 0.212593, acc: 93.75%] [G loss: 4.395001]\n",
      "epoch:1 step:1061 [D loss: 0.310565, acc: 90.62%] [G loss: 2.341286]\n",
      "epoch:1 step:1062 [D loss: 0.269039, acc: 91.41%] [G loss: 2.000174]\n",
      "epoch:1 step:1063 [D loss: 0.434771, acc: 79.69%] [G loss: 2.745166]\n",
      "epoch:1 step:1064 [D loss: 0.400010, acc: 85.16%] [G loss: 2.054767]\n",
      "epoch:1 step:1065 [D loss: 0.549615, acc: 70.31%] [G loss: 1.821601]\n",
      "epoch:1 step:1066 [D loss: 0.263419, acc: 88.28%] [G loss: 1.693498]\n",
      "epoch:1 step:1067 [D loss: 0.129587, acc: 96.09%] [G loss: 3.517147]\n",
      "epoch:1 step:1068 [D loss: 0.395899, acc: 89.06%] [G loss: 2.496674]\n",
      "epoch:1 step:1069 [D loss: 0.044724, acc: 100.00%] [G loss: 4.345792]\n",
      "epoch:1 step:1070 [D loss: 0.071827, acc: 100.00%] [G loss: 3.548664]\n",
      "epoch:1 step:1071 [D loss: 0.411601, acc: 83.59%] [G loss: 2.906659]\n",
      "epoch:1 step:1072 [D loss: 0.684210, acc: 59.38%] [G loss: 3.013514]\n",
      "epoch:1 step:1073 [D loss: 0.153183, acc: 94.53%] [G loss: 5.342731]\n",
      "epoch:1 step:1074 [D loss: 1.183285, acc: 51.56%] [G loss: 1.981586]\n",
      "epoch:1 step:1075 [D loss: 0.083652, acc: 96.88%] [G loss: 2.752949]\n",
      "epoch:1 step:1076 [D loss: 0.122513, acc: 97.66%] [G loss: 3.231313]\n",
      "epoch:1 step:1077 [D loss: 0.383356, acc: 84.38%] [G loss: 3.932016]\n",
      "epoch:1 step:1078 [D loss: 0.209705, acc: 92.97%] [G loss: 3.974892]\n",
      "epoch:1 step:1079 [D loss: 0.029306, acc: 100.00%] [G loss: 4.085868]\n",
      "epoch:1 step:1080 [D loss: 0.461859, acc: 78.91%] [G loss: 2.639933]\n",
      "epoch:1 step:1081 [D loss: 0.876004, acc: 58.59%] [G loss: 1.341166]\n",
      "epoch:1 step:1082 [D loss: 0.468944, acc: 78.12%] [G loss: 3.216850]\n",
      "epoch:1 step:1083 [D loss: 0.633485, acc: 67.97%] [G loss: 3.652783]\n",
      "epoch:1 step:1084 [D loss: 0.139886, acc: 97.66%] [G loss: 4.103362]\n",
      "epoch:1 step:1085 [D loss: 1.333269, acc: 50.00%] [G loss: 3.603091]\n",
      "epoch:1 step:1086 [D loss: 0.108782, acc: 97.66%] [G loss: 1.995460]\n",
      "epoch:1 step:1087 [D loss: 0.817459, acc: 56.25%] [G loss: 2.490053]\n",
      "epoch:1 step:1088 [D loss: 1.020733, acc: 48.44%] [G loss: 2.439758]\n",
      "epoch:1 step:1089 [D loss: 1.321421, acc: 50.78%] [G loss: 3.694964]\n",
      "epoch:1 step:1090 [D loss: 0.649625, acc: 64.06%] [G loss: 3.550629]\n",
      "epoch:1 step:1091 [D loss: 1.209051, acc: 50.78%] [G loss: 2.829106]\n",
      "epoch:1 step:1092 [D loss: 0.398207, acc: 78.91%] [G loss: 3.936065]\n",
      "epoch:1 step:1093 [D loss: 0.335923, acc: 89.06%] [G loss: 3.240942]\n",
      "epoch:1 step:1094 [D loss: 0.403595, acc: 82.03%] [G loss: 3.506371]\n",
      "epoch:1 step:1095 [D loss: 0.849473, acc: 64.84%] [G loss: 2.554018]\n",
      "epoch:1 step:1096 [D loss: 0.486420, acc: 74.22%] [G loss: 2.894041]\n",
      "epoch:1 step:1097 [D loss: 0.415998, acc: 82.03%] [G loss: 2.939855]\n",
      "epoch:1 step:1098 [D loss: 0.519381, acc: 75.00%] [G loss: 2.821460]\n",
      "epoch:1 step:1099 [D loss: 0.399212, acc: 81.25%] [G loss: 3.157399]\n",
      "epoch:1 step:1100 [D loss: 0.865854, acc: 62.50%] [G loss: 2.697495]\n",
      "epoch:1 step:1101 [D loss: 0.514222, acc: 78.91%] [G loss: 2.990424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1102 [D loss: 0.410460, acc: 80.47%] [G loss: 3.108497]\n",
      "epoch:1 step:1103 [D loss: 0.140142, acc: 97.66%] [G loss: 4.119760]\n",
      "epoch:1 step:1104 [D loss: 0.239562, acc: 94.53%] [G loss: 3.795425]\n",
      "epoch:1 step:1105 [D loss: 0.347116, acc: 87.50%] [G loss: 2.656650]\n",
      "epoch:1 step:1106 [D loss: 0.530359, acc: 78.91%] [G loss: 1.903244]\n",
      "epoch:1 step:1107 [D loss: 0.209003, acc: 93.75%] [G loss: 2.860396]\n",
      "epoch:1 step:1108 [D loss: 0.564149, acc: 70.31%] [G loss: 2.404385]\n",
      "epoch:1 step:1109 [D loss: 0.308788, acc: 88.28%] [G loss: 2.388883]\n",
      "epoch:1 step:1110 [D loss: 0.188164, acc: 96.09%] [G loss: 2.999435]\n",
      "epoch:1 step:1111 [D loss: 0.285446, acc: 90.62%] [G loss: 2.891716]\n",
      "epoch:1 step:1112 [D loss: 0.535854, acc: 71.88%] [G loss: 1.767912]\n",
      "epoch:1 step:1113 [D loss: 0.378722, acc: 86.72%] [G loss: 2.263734]\n",
      "epoch:1 step:1114 [D loss: 0.313194, acc: 87.50%] [G loss: 2.018370]\n",
      "epoch:1 step:1115 [D loss: 0.391235, acc: 80.47%] [G loss: 1.900576]\n",
      "epoch:1 step:1116 [D loss: 1.054395, acc: 35.16%] [G loss: 1.247795]\n",
      "epoch:1 step:1117 [D loss: 0.218074, acc: 96.09%] [G loss: 1.625070]\n",
      "epoch:1 step:1118 [D loss: 0.801227, acc: 55.47%] [G loss: 1.397544]\n",
      "epoch:1 step:1119 [D loss: 0.582111, acc: 64.06%] [G loss: 2.159062]\n",
      "epoch:1 step:1120 [D loss: 0.921213, acc: 54.69%] [G loss: 2.272222]\n",
      "epoch:1 step:1121 [D loss: 1.144639, acc: 32.03%] [G loss: 0.726239]\n",
      "epoch:1 step:1122 [D loss: 0.828043, acc: 39.84%] [G loss: 1.302732]\n",
      "epoch:1 step:1123 [D loss: 0.762590, acc: 63.28%] [G loss: 1.290654]\n",
      "epoch:1 step:1124 [D loss: 1.105748, acc: 44.53%] [G loss: 1.541295]\n",
      "epoch:1 step:1125 [D loss: 1.418101, acc: 14.06%] [G loss: 1.367785]\n",
      "epoch:1 step:1126 [D loss: 0.834578, acc: 50.78%] [G loss: 1.657577]\n",
      "epoch:1 step:1127 [D loss: 1.429890, acc: 9.38%] [G loss: 1.350970]\n",
      "epoch:1 step:1128 [D loss: 0.807451, acc: 45.31%] [G loss: 1.555389]\n",
      "epoch:1 step:1129 [D loss: 0.862360, acc: 45.31%] [G loss: 1.642977]\n",
      "epoch:1 step:1130 [D loss: 0.696377, acc: 60.16%] [G loss: 1.832319]\n",
      "epoch:1 step:1131 [D loss: 0.847470, acc: 47.66%] [G loss: 2.395134]\n",
      "epoch:1 step:1132 [D loss: 0.509836, acc: 78.12%] [G loss: 1.719661]\n",
      "epoch:1 step:1133 [D loss: 0.344136, acc: 88.28%] [G loss: 2.013433]\n",
      "epoch:1 step:1134 [D loss: 0.213295, acc: 95.31%] [G loss: 2.612511]\n",
      "epoch:1 step:1135 [D loss: 0.429767, acc: 82.03%] [G loss: 1.797954]\n",
      "epoch:1 step:1136 [D loss: 0.463969, acc: 82.03%] [G loss: 1.765299]\n",
      "epoch:1 step:1137 [D loss: 0.241887, acc: 96.88%] [G loss: 2.186139]\n",
      "epoch:1 step:1138 [D loss: 0.372876, acc: 88.28%] [G loss: 2.061311]\n",
      "epoch:1 step:1139 [D loss: 0.175772, acc: 97.66%] [G loss: 1.971331]\n",
      "epoch:1 step:1140 [D loss: 0.703935, acc: 62.50%] [G loss: 1.486301]\n",
      "epoch:1 step:1141 [D loss: 1.004759, acc: 50.00%] [G loss: 1.851677]\n",
      "epoch:1 step:1142 [D loss: 0.078122, acc: 100.00%] [G loss: 2.353506]\n",
      "epoch:1 step:1143 [D loss: 0.498351, acc: 77.34%] [G loss: 1.445307]\n",
      "epoch:1 step:1144 [D loss: 0.078506, acc: 99.22%] [G loss: 2.621842]\n",
      "epoch:1 step:1145 [D loss: 0.141619, acc: 97.66%] [G loss: 2.501087]\n",
      "epoch:1 step:1146 [D loss: 0.598263, acc: 65.62%] [G loss: 2.372723]\n",
      "epoch:1 step:1147 [D loss: 0.208766, acc: 92.97%] [G loss: 1.735758]\n",
      "epoch:1 step:1148 [D loss: 0.801254, acc: 55.47%] [G loss: 1.397719]\n",
      "epoch:1 step:1149 [D loss: 0.322853, acc: 90.62%] [G loss: 1.631510]\n",
      "epoch:1 step:1150 [D loss: 0.248123, acc: 92.19%] [G loss: 2.187420]\n",
      "epoch:1 step:1151 [D loss: 0.947378, acc: 39.84%] [G loss: 1.630999]\n",
      "epoch:1 step:1152 [D loss: 0.248584, acc: 96.88%] [G loss: 1.842864]\n",
      "epoch:1 step:1153 [D loss: 0.688394, acc: 64.84%] [G loss: 1.167483]\n",
      "epoch:1 step:1154 [D loss: 3.311221, acc: 21.88%] [G loss: 0.212078]\n",
      "epoch:1 step:1155 [D loss: 0.530968, acc: 75.78%] [G loss: 1.569030]\n",
      "epoch:1 step:1156 [D loss: 0.449816, acc: 76.56%] [G loss: 2.036501]\n",
      "epoch:1 step:1157 [D loss: 0.451063, acc: 74.22%] [G loss: 1.530360]\n",
      "epoch:1 step:1158 [D loss: 0.935333, acc: 39.06%] [G loss: 1.649393]\n",
      "epoch:1 step:1159 [D loss: 0.663996, acc: 64.84%] [G loss: 1.272833]\n",
      "epoch:1 step:1160 [D loss: 1.702940, acc: 11.72%] [G loss: 0.992325]\n",
      "epoch:1 step:1161 [D loss: 0.686215, acc: 60.94%] [G loss: 1.256578]\n",
      "epoch:1 step:1162 [D loss: 0.939885, acc: 43.75%] [G loss: 1.508044]\n",
      "epoch:1 step:1163 [D loss: 0.570320, acc: 67.97%] [G loss: 1.930489]\n",
      "epoch:1 step:1164 [D loss: 1.618326, acc: 11.72%] [G loss: 1.333110]\n",
      "epoch:1 step:1165 [D loss: 0.823850, acc: 48.44%] [G loss: 1.771219]\n",
      "epoch:1 step:1166 [D loss: 1.372172, acc: 17.97%] [G loss: 1.654261]\n",
      "epoch:1 step:1167 [D loss: 0.628945, acc: 74.22%] [G loss: 2.141454]\n",
      "epoch:1 step:1168 [D loss: 1.322876, acc: 32.03%] [G loss: 1.727995]\n",
      "epoch:1 step:1169 [D loss: 0.475237, acc: 76.56%] [G loss: 2.469577]\n",
      "epoch:1 step:1170 [D loss: 0.638541, acc: 66.41%] [G loss: 2.500869]\n",
      "epoch:1 step:1171 [D loss: 1.126898, acc: 57.03%] [G loss: 2.342593]\n",
      "epoch:1 step:1172 [D loss: 0.390601, acc: 83.59%] [G loss: 2.983361]\n",
      "epoch:1 step:1173 [D loss: 0.355942, acc: 89.06%] [G loss: 2.923290]\n",
      "epoch:1 step:1174 [D loss: 0.343279, acc: 88.28%] [G loss: 2.517600]\n",
      "epoch:1 step:1175 [D loss: 0.325993, acc: 90.62%] [G loss: 2.627035]\n",
      "epoch:1 step:1176 [D loss: 0.321740, acc: 89.06%] [G loss: 2.337597]\n",
      "epoch:1 step:1177 [D loss: 0.163958, acc: 97.66%] [G loss: 2.727851]\n",
      "epoch:1 step:1178 [D loss: 0.235850, acc: 94.53%] [G loss: 2.560193]\n",
      "epoch:1 step:1179 [D loss: 0.183853, acc: 99.22%] [G loss: 2.918568]\n",
      "epoch:1 step:1180 [D loss: 0.203190, acc: 96.88%] [G loss: 2.850238]\n",
      "epoch:1 step:1181 [D loss: 0.210039, acc: 96.88%] [G loss: 2.716256]\n",
      "epoch:1 step:1182 [D loss: 0.890436, acc: 52.34%] [G loss: 2.044559]\n",
      "epoch:1 step:1183 [D loss: 0.493944, acc: 79.69%] [G loss: 2.102866]\n",
      "epoch:1 step:1184 [D loss: 0.435813, acc: 84.38%] [G loss: 2.174674]\n",
      "epoch:1 step:1185 [D loss: 0.260381, acc: 89.84%] [G loss: 2.254446]\n",
      "epoch:1 step:1186 [D loss: 0.472938, acc: 82.03%] [G loss: 1.609437]\n",
      "epoch:1 step:1187 [D loss: 0.224056, acc: 96.09%] [G loss: 1.848483]\n",
      "epoch:1 step:1188 [D loss: 0.419086, acc: 82.81%] [G loss: 1.903554]\n",
      "epoch:1 step:1189 [D loss: 0.433981, acc: 79.69%] [G loss: 1.673833]\n",
      "epoch:1 step:1190 [D loss: 0.600430, acc: 67.97%] [G loss: 1.400769]\n",
      "epoch:1 step:1191 [D loss: 0.900429, acc: 35.16%] [G loss: 1.344423]\n",
      "epoch:1 step:1192 [D loss: 1.602575, acc: 10.16%] [G loss: 0.608155]\n",
      "epoch:1 step:1193 [D loss: 0.628841, acc: 70.31%] [G loss: 1.181800]\n",
      "epoch:1 step:1194 [D loss: 1.504662, acc: 25.78%] [G loss: 1.052354]\n",
      "epoch:1 step:1195 [D loss: 1.024608, acc: 35.94%] [G loss: 1.054535]\n",
      "epoch:1 step:1196 [D loss: 1.045893, acc: 37.50%] [G loss: 1.583099]\n",
      "epoch:1 step:1197 [D loss: 0.652248, acc: 60.94%] [G loss: 1.766637]\n",
      "epoch:1 step:1198 [D loss: 0.557752, acc: 71.88%] [G loss: 1.671125]\n",
      "epoch:1 step:1199 [D loss: 0.543386, acc: 65.62%] [G loss: 1.496507]\n",
      "epoch:1 step:1200 [D loss: 1.027698, acc: 32.03%] [G loss: 1.703902]\n",
      "epoch:1 step:1201 [D loss: 0.785202, acc: 50.78%] [G loss: 1.363688]\n",
      "epoch:1 step:1202 [D loss: 0.742005, acc: 50.00%] [G loss: 1.899922]\n",
      "epoch:1 step:1203 [D loss: 0.634061, acc: 66.41%] [G loss: 2.171837]\n",
      "epoch:1 step:1204 [D loss: 0.520901, acc: 78.91%] [G loss: 1.970874]\n",
      "epoch:1 step:1205 [D loss: 0.870643, acc: 41.41%] [G loss: 1.589044]\n",
      "epoch:1 step:1206 [D loss: 0.551364, acc: 74.22%] [G loss: 2.050872]\n",
      "epoch:1 step:1207 [D loss: 0.454327, acc: 81.25%] [G loss: 1.665819]\n",
      "epoch:1 step:1208 [D loss: 0.593072, acc: 65.62%] [G loss: 1.972663]\n",
      "epoch:1 step:1209 [D loss: 0.817444, acc: 47.66%] [G loss: 1.804973]\n",
      "epoch:1 step:1210 [D loss: 0.375698, acc: 85.94%] [G loss: 2.115258]\n",
      "epoch:1 step:1211 [D loss: 0.877027, acc: 44.53%] [G loss: 1.958314]\n",
      "epoch:1 step:1212 [D loss: 0.752534, acc: 57.03%] [G loss: 2.226440]\n",
      "epoch:1 step:1213 [D loss: 0.362765, acc: 91.41%] [G loss: 2.270815]\n",
      "epoch:1 step:1214 [D loss: 0.789514, acc: 54.69%] [G loss: 1.706425]\n",
      "epoch:1 step:1215 [D loss: 0.792071, acc: 50.78%] [G loss: 1.401668]\n",
      "epoch:1 step:1216 [D loss: 0.460208, acc: 75.00%] [G loss: 2.270723]\n",
      "epoch:1 step:1217 [D loss: 0.735117, acc: 51.56%] [G loss: 2.217539]\n",
      "epoch:1 step:1218 [D loss: 1.061666, acc: 50.78%] [G loss: 1.167142]\n",
      "epoch:1 step:1219 [D loss: 0.818463, acc: 47.66%] [G loss: 2.073777]\n",
      "epoch:1 step:1220 [D loss: 0.545357, acc: 71.09%] [G loss: 2.039451]\n",
      "epoch:1 step:1221 [D loss: 0.741380, acc: 54.69%] [G loss: 1.845922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1222 [D loss: 0.746948, acc: 55.47%] [G loss: 1.807449]\n",
      "epoch:1 step:1223 [D loss: 0.989166, acc: 39.84%] [G loss: 1.748945]\n",
      "epoch:1 step:1224 [D loss: 0.718712, acc: 60.16%] [G loss: 2.030209]\n",
      "epoch:1 step:1225 [D loss: 0.721639, acc: 56.25%] [G loss: 2.020546]\n",
      "epoch:1 step:1226 [D loss: 0.731227, acc: 59.38%] [G loss: 1.978117]\n",
      "epoch:1 step:1227 [D loss: 0.564076, acc: 70.31%] [G loss: 2.480178]\n",
      "epoch:1 step:1228 [D loss: 0.660384, acc: 59.38%] [G loss: 2.275450]\n",
      "epoch:1 step:1229 [D loss: 0.633497, acc: 64.06%] [G loss: 2.188854]\n",
      "epoch:1 step:1230 [D loss: 1.044492, acc: 39.06%] [G loss: 1.915635]\n",
      "epoch:1 step:1231 [D loss: 0.643051, acc: 67.97%] [G loss: 2.659629]\n",
      "epoch:1 step:1232 [D loss: 0.595541, acc: 66.41%] [G loss: 2.091630]\n",
      "epoch:1 step:1233 [D loss: 0.526795, acc: 73.44%] [G loss: 2.494639]\n",
      "epoch:1 step:1234 [D loss: 0.454014, acc: 81.25%] [G loss: 2.463258]\n",
      "epoch:1 step:1235 [D loss: 0.699302, acc: 60.16%] [G loss: 1.906450]\n",
      "epoch:1 step:1236 [D loss: 0.438369, acc: 82.81%] [G loss: 2.513956]\n",
      "epoch:1 step:1237 [D loss: 0.459000, acc: 83.59%] [G loss: 1.965117]\n",
      "epoch:1 step:1238 [D loss: 0.725667, acc: 56.25%] [G loss: 1.978500]\n",
      "epoch:1 step:1239 [D loss: 0.629161, acc: 61.72%] [G loss: 2.233510]\n",
      "epoch:1 step:1240 [D loss: 0.659889, acc: 64.06%] [G loss: 2.172543]\n",
      "epoch:1 step:1241 [D loss: 0.586778, acc: 67.97%] [G loss: 2.016025]\n",
      "epoch:1 step:1242 [D loss: 0.444352, acc: 83.59%] [G loss: 2.187774]\n",
      "epoch:1 step:1243 [D loss: 0.799571, acc: 47.66%] [G loss: 2.191675]\n",
      "epoch:1 step:1244 [D loss: 0.514222, acc: 72.66%] [G loss: 1.872001]\n",
      "epoch:1 step:1245 [D loss: 0.918641, acc: 41.41%] [G loss: 1.425036]\n",
      "epoch:1 step:1246 [D loss: 0.668814, acc: 60.16%] [G loss: 1.974582]\n",
      "epoch:1 step:1247 [D loss: 0.691059, acc: 55.47%] [G loss: 1.926704]\n",
      "epoch:1 step:1248 [D loss: 0.774398, acc: 54.69%] [G loss: 2.052714]\n",
      "epoch:1 step:1249 [D loss: 0.639155, acc: 61.72%] [G loss: 1.949383]\n",
      "epoch:1 step:1250 [D loss: 0.628485, acc: 65.62%] [G loss: 2.161463]\n",
      "epoch:1 step:1251 [D loss: 0.760599, acc: 63.28%] [G loss: 1.679634]\n",
      "epoch:1 step:1252 [D loss: 0.543154, acc: 72.66%] [G loss: 1.952544]\n",
      "epoch:1 step:1253 [D loss: 0.595147, acc: 73.44%] [G loss: 2.361683]\n",
      "epoch:1 step:1254 [D loss: 0.373655, acc: 83.59%] [G loss: 2.282083]\n",
      "epoch:1 step:1255 [D loss: 0.469766, acc: 80.47%] [G loss: 2.064169]\n",
      "epoch:1 step:1256 [D loss: 0.251000, acc: 93.75%] [G loss: 2.793832]\n",
      "epoch:1 step:1257 [D loss: 0.303187, acc: 92.97%] [G loss: 2.346904]\n",
      "epoch:1 step:1258 [D loss: 0.333172, acc: 88.28%] [G loss: 1.994742]\n",
      "epoch:1 step:1259 [D loss: 0.375542, acc: 89.06%] [G loss: 1.983413]\n",
      "epoch:1 step:1260 [D loss: 0.963257, acc: 37.50%] [G loss: 1.473940]\n",
      "epoch:1 step:1261 [D loss: 0.645808, acc: 67.97%] [G loss: 1.831684]\n",
      "epoch:1 step:1262 [D loss: 0.665816, acc: 59.38%] [G loss: 2.135002]\n",
      "epoch:1 step:1263 [D loss: 0.569406, acc: 69.53%] [G loss: 2.286021]\n",
      "epoch:1 step:1264 [D loss: 0.610569, acc: 64.84%] [G loss: 2.196751]\n",
      "epoch:1 step:1265 [D loss: 0.768219, acc: 55.47%] [G loss: 2.114290]\n",
      "epoch:1 step:1266 [D loss: 0.467245, acc: 78.91%] [G loss: 1.955613]\n",
      "epoch:1 step:1267 [D loss: 0.690470, acc: 64.06%] [G loss: 2.216758]\n",
      "epoch:1 step:1268 [D loss: 0.636126, acc: 62.50%] [G loss: 2.322407]\n",
      "epoch:1 step:1269 [D loss: 0.567971, acc: 70.31%] [G loss: 2.207323]\n",
      "epoch:1 step:1270 [D loss: 0.686243, acc: 63.28%] [G loss: 2.185381]\n",
      "epoch:1 step:1271 [D loss: 0.625436, acc: 66.41%] [G loss: 1.913360]\n",
      "epoch:1 step:1272 [D loss: 0.777744, acc: 49.22%] [G loss: 1.772225]\n",
      "epoch:1 step:1273 [D loss: 0.495614, acc: 74.22%] [G loss: 1.935923]\n",
      "epoch:1 step:1274 [D loss: 0.777580, acc: 53.12%] [G loss: 2.100060]\n",
      "epoch:1 step:1275 [D loss: 0.426067, acc: 85.16%] [G loss: 2.102763]\n",
      "epoch:1 step:1276 [D loss: 0.497252, acc: 82.03%] [G loss: 2.371693]\n",
      "epoch:1 step:1277 [D loss: 0.579162, acc: 71.09%] [G loss: 1.640582]\n",
      "epoch:1 step:1278 [D loss: 0.659540, acc: 63.28%] [G loss: 1.760848]\n",
      "epoch:1 step:1279 [D loss: 0.868084, acc: 50.00%] [G loss: 1.860517]\n",
      "epoch:1 step:1280 [D loss: 0.850918, acc: 44.53%] [G loss: 1.346127]\n",
      "epoch:1 step:1281 [D loss: 0.740034, acc: 54.69%] [G loss: 1.908592]\n",
      "epoch:1 step:1282 [D loss: 0.725193, acc: 55.47%] [G loss: 1.862288]\n",
      "epoch:1 step:1283 [D loss: 0.786084, acc: 52.34%] [G loss: 1.702114]\n",
      "epoch:1 step:1284 [D loss: 0.795020, acc: 44.53%] [G loss: 1.945724]\n",
      "epoch:1 step:1285 [D loss: 0.696900, acc: 58.59%] [G loss: 1.564919]\n",
      "epoch:1 step:1286 [D loss: 0.890074, acc: 44.53%] [G loss: 1.703667]\n",
      "epoch:1 step:1287 [D loss: 0.768781, acc: 50.00%] [G loss: 1.762497]\n",
      "epoch:1 step:1288 [D loss: 0.763674, acc: 48.44%] [G loss: 1.829089]\n",
      "epoch:1 step:1289 [D loss: 0.650232, acc: 62.50%] [G loss: 1.707934]\n",
      "epoch:1 step:1290 [D loss: 0.671653, acc: 60.94%] [G loss: 1.874544]\n",
      "epoch:1 step:1291 [D loss: 0.704306, acc: 62.50%] [G loss: 2.025716]\n",
      "epoch:1 step:1292 [D loss: 0.685553, acc: 60.94%] [G loss: 1.843976]\n",
      "epoch:1 step:1293 [D loss: 0.714690, acc: 60.16%] [G loss: 1.949252]\n",
      "epoch:1 step:1294 [D loss: 0.620475, acc: 69.53%] [G loss: 1.824838]\n",
      "epoch:1 step:1295 [D loss: 0.962740, acc: 31.25%] [G loss: 1.612315]\n",
      "epoch:1 step:1296 [D loss: 0.729722, acc: 57.81%] [G loss: 1.884386]\n",
      "epoch:1 step:1297 [D loss: 0.432883, acc: 83.59%] [G loss: 2.304488]\n",
      "epoch:1 step:1298 [D loss: 0.415456, acc: 84.38%] [G loss: 2.697362]\n",
      "epoch:1 step:1299 [D loss: 0.493077, acc: 81.25%] [G loss: 2.400270]\n",
      "epoch:1 step:1300 [D loss: 1.161687, acc: 31.25%] [G loss: 1.736694]\n",
      "epoch:1 step:1301 [D loss: 0.536162, acc: 75.78%] [G loss: 2.129478]\n",
      "epoch:1 step:1302 [D loss: 0.357151, acc: 89.06%] [G loss: 2.496348]\n",
      "epoch:1 step:1303 [D loss: 0.642842, acc: 70.31%] [G loss: 1.599147]\n",
      "epoch:1 step:1304 [D loss: 0.568990, acc: 68.75%] [G loss: 2.139043]\n",
      "epoch:1 step:1305 [D loss: 0.735061, acc: 57.03%] [G loss: 1.698406]\n",
      "epoch:1 step:1306 [D loss: 0.340779, acc: 89.06%] [G loss: 1.921505]\n",
      "epoch:1 step:1307 [D loss: 0.849476, acc: 50.00%] [G loss: 1.599175]\n",
      "epoch:1 step:1308 [D loss: 0.431696, acc: 80.47%] [G loss: 2.443532]\n",
      "epoch:1 step:1309 [D loss: 0.451552, acc: 80.47%] [G loss: 2.509011]\n",
      "epoch:1 step:1310 [D loss: 0.621528, acc: 65.62%] [G loss: 2.278365]\n",
      "epoch:1 step:1311 [D loss: 0.501779, acc: 75.78%] [G loss: 2.413275]\n",
      "epoch:1 step:1312 [D loss: 0.474242, acc: 81.25%] [G loss: 2.580782]\n",
      "epoch:1 step:1313 [D loss: 0.512777, acc: 75.78%] [G loss: 2.441292]\n",
      "epoch:1 step:1314 [D loss: 0.320073, acc: 91.41%] [G loss: 2.739064]\n",
      "epoch:1 step:1315 [D loss: 0.613908, acc: 66.41%] [G loss: 2.585092]\n",
      "epoch:1 step:1316 [D loss: 0.558754, acc: 74.22%] [G loss: 2.685071]\n",
      "epoch:1 step:1317 [D loss: 0.360239, acc: 80.47%] [G loss: 2.556637]\n",
      "epoch:1 step:1318 [D loss: 0.263397, acc: 91.41%] [G loss: 2.632469]\n",
      "epoch:1 step:1319 [D loss: 0.588047, acc: 67.97%] [G loss: 2.378771]\n",
      "epoch:1 step:1320 [D loss: 0.353285, acc: 89.06%] [G loss: 2.120933]\n",
      "epoch:1 step:1321 [D loss: 0.597653, acc: 69.53%] [G loss: 2.538140]\n",
      "epoch:1 step:1322 [D loss: 0.323882, acc: 89.06%] [G loss: 2.633348]\n",
      "epoch:1 step:1323 [D loss: 0.622434, acc: 63.28%] [G loss: 2.757817]\n",
      "epoch:1 step:1324 [D loss: 0.657536, acc: 61.72%] [G loss: 2.139314]\n",
      "epoch:1 step:1325 [D loss: 0.663579, acc: 57.03%] [G loss: 2.080669]\n",
      "epoch:1 step:1326 [D loss: 0.462856, acc: 76.56%] [G loss: 2.161893]\n",
      "epoch:1 step:1327 [D loss: 0.714648, acc: 50.78%] [G loss: 1.957670]\n",
      "epoch:1 step:1328 [D loss: 0.292032, acc: 91.41%] [G loss: 2.529051]\n",
      "epoch:1 step:1329 [D loss: 0.559887, acc: 67.19%] [G loss: 2.007879]\n",
      "epoch:1 step:1330 [D loss: 0.836033, acc: 50.00%] [G loss: 1.867868]\n",
      "epoch:1 step:1331 [D loss: 0.163296, acc: 95.31%] [G loss: 2.650847]\n",
      "epoch:1 step:1332 [D loss: 0.300119, acc: 93.75%] [G loss: 2.361410]\n",
      "epoch:1 step:1333 [D loss: 1.495983, acc: 15.62%] [G loss: 1.140939]\n",
      "epoch:1 step:1334 [D loss: 0.800759, acc: 54.69%] [G loss: 1.394649]\n",
      "epoch:1 step:1335 [D loss: 0.764480, acc: 60.94%] [G loss: 1.380558]\n",
      "epoch:1 step:1336 [D loss: 0.615214, acc: 64.84%] [G loss: 2.013103]\n",
      "epoch:1 step:1337 [D loss: 0.866503, acc: 53.12%] [G loss: 1.423582]\n",
      "epoch:1 step:1338 [D loss: 1.063122, acc: 29.69%] [G loss: 1.360518]\n",
      "epoch:1 step:1339 [D loss: 0.688927, acc: 60.94%] [G loss: 1.914219]\n",
      "epoch:1 step:1340 [D loss: 0.802968, acc: 56.25%] [G loss: 1.573125]\n",
      "epoch:1 step:1341 [D loss: 1.025667, acc: 33.59%] [G loss: 1.806058]\n",
      "epoch:1 step:1342 [D loss: 0.570898, acc: 72.66%] [G loss: 2.409482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1343 [D loss: 0.643039, acc: 62.50%] [G loss: 1.971416]\n",
      "epoch:1 step:1344 [D loss: 1.232692, acc: 35.94%] [G loss: 1.631843]\n",
      "epoch:1 step:1345 [D loss: 0.584139, acc: 68.75%] [G loss: 2.405751]\n",
      "epoch:1 step:1346 [D loss: 0.479152, acc: 77.34%] [G loss: 2.510675]\n",
      "epoch:1 step:1347 [D loss: 0.659259, acc: 62.50%] [G loss: 2.328610]\n",
      "epoch:1 step:1348 [D loss: 0.417125, acc: 81.25%] [G loss: 2.790247]\n",
      "epoch:1 step:1349 [D loss: 0.528726, acc: 73.44%] [G loss: 2.341266]\n",
      "epoch:1 step:1350 [D loss: 0.732050, acc: 57.81%] [G loss: 2.084253]\n",
      "epoch:1 step:1351 [D loss: 0.391585, acc: 86.72%] [G loss: 2.360819]\n",
      "epoch:1 step:1352 [D loss: 0.404433, acc: 82.03%] [G loss: 2.312738]\n",
      "epoch:1 step:1353 [D loss: 0.279033, acc: 92.19%] [G loss: 2.489448]\n",
      "epoch:1 step:1354 [D loss: 0.565289, acc: 75.00%] [G loss: 2.306949]\n",
      "epoch:1 step:1355 [D loss: 0.339196, acc: 87.50%] [G loss: 2.410212]\n",
      "epoch:1 step:1356 [D loss: 0.774401, acc: 57.03%] [G loss: 1.571381]\n",
      "epoch:1 step:1357 [D loss: 0.359606, acc: 75.78%] [G loss: 1.915629]\n",
      "epoch:1 step:1358 [D loss: 0.726197, acc: 59.38%] [G loss: 2.047150]\n",
      "epoch:1 step:1359 [D loss: 0.434013, acc: 81.25%] [G loss: 2.247505]\n",
      "epoch:1 step:1360 [D loss: 0.221418, acc: 91.41%] [G loss: 2.307211]\n",
      "epoch:1 step:1361 [D loss: 0.503841, acc: 74.22%] [G loss: 1.946376]\n",
      "epoch:1 step:1362 [D loss: 0.648273, acc: 61.72%] [G loss: 1.938406]\n",
      "epoch:1 step:1363 [D loss: 0.470112, acc: 80.47%] [G loss: 1.679361]\n",
      "epoch:1 step:1364 [D loss: 0.973622, acc: 39.84%] [G loss: 1.317217]\n",
      "epoch:1 step:1365 [D loss: 0.406765, acc: 82.03%] [G loss: 1.561831]\n",
      "epoch:1 step:1366 [D loss: 0.322496, acc: 90.62%] [G loss: 2.187452]\n",
      "epoch:1 step:1367 [D loss: 0.913362, acc: 53.12%] [G loss: 1.680281]\n",
      "epoch:1 step:1368 [D loss: 0.506825, acc: 80.47%] [G loss: 2.157681]\n",
      "epoch:1 step:1369 [D loss: 0.465542, acc: 82.81%] [G loss: 2.459529]\n",
      "epoch:1 step:1370 [D loss: 0.386348, acc: 85.94%] [G loss: 2.280687]\n",
      "epoch:1 step:1371 [D loss: 0.596481, acc: 76.56%] [G loss: 1.875075]\n",
      "epoch:1 step:1372 [D loss: 1.030146, acc: 36.72%] [G loss: 1.624473]\n",
      "epoch:1 step:1373 [D loss: 0.735109, acc: 58.59%] [G loss: 2.341570]\n",
      "epoch:1 step:1374 [D loss: 1.138650, acc: 42.97%] [G loss: 1.779618]\n",
      "epoch:1 step:1375 [D loss: 0.449205, acc: 79.69%] [G loss: 2.605637]\n",
      "epoch:1 step:1376 [D loss: 0.714139, acc: 60.16%] [G loss: 1.999857]\n",
      "epoch:1 step:1377 [D loss: 0.333561, acc: 85.94%] [G loss: 2.901712]\n",
      "epoch:1 step:1378 [D loss: 0.506094, acc: 74.22%] [G loss: 2.350152]\n",
      "epoch:1 step:1379 [D loss: 0.306792, acc: 91.41%] [G loss: 3.100443]\n",
      "epoch:1 step:1380 [D loss: 0.378709, acc: 84.38%] [G loss: 2.513109]\n",
      "epoch:1 step:1381 [D loss: 0.523899, acc: 75.00%] [G loss: 1.895478]\n",
      "epoch:1 step:1382 [D loss: 0.429315, acc: 81.25%] [G loss: 2.261582]\n",
      "epoch:1 step:1383 [D loss: 0.284109, acc: 89.06%] [G loss: 2.209544]\n",
      "epoch:1 step:1384 [D loss: 0.830460, acc: 43.75%] [G loss: 1.950442]\n",
      "epoch:1 step:1385 [D loss: 0.438206, acc: 78.91%] [G loss: 2.481385]\n",
      "epoch:1 step:1386 [D loss: 0.329463, acc: 90.62%] [G loss: 1.845280]\n",
      "epoch:1 step:1387 [D loss: 0.293946, acc: 91.41%] [G loss: 2.253268]\n",
      "epoch:1 step:1388 [D loss: 0.403631, acc: 79.69%] [G loss: 1.894167]\n",
      "epoch:1 step:1389 [D loss: 0.622821, acc: 62.50%] [G loss: 1.632463]\n",
      "epoch:1 step:1390 [D loss: 0.796561, acc: 50.00%] [G loss: 2.001260]\n",
      "epoch:1 step:1391 [D loss: 0.548565, acc: 71.09%] [G loss: 2.497401]\n",
      "epoch:1 step:1392 [D loss: 0.421423, acc: 85.94%] [G loss: 2.461273]\n",
      "epoch:1 step:1393 [D loss: 0.581939, acc: 71.09%] [G loss: 1.911840]\n",
      "epoch:1 step:1394 [D loss: 0.553610, acc: 71.09%] [G loss: 2.113195]\n",
      "epoch:1 step:1395 [D loss: 0.599619, acc: 66.41%] [G loss: 2.120681]\n",
      "epoch:1 step:1396 [D loss: 0.619563, acc: 71.88%] [G loss: 2.103037]\n",
      "epoch:1 step:1397 [D loss: 0.748838, acc: 54.69%] [G loss: 2.414078]\n",
      "epoch:1 step:1398 [D loss: 0.539057, acc: 71.88%] [G loss: 2.698497]\n",
      "epoch:1 step:1399 [D loss: 0.405289, acc: 76.56%] [G loss: 2.066114]\n",
      "epoch:1 step:1400 [D loss: 0.640171, acc: 61.72%] [G loss: 2.420568]\n",
      "epoch:1 step:1401 [D loss: 0.307292, acc: 89.84%] [G loss: 2.444007]\n",
      "epoch:1 step:1402 [D loss: 0.532477, acc: 78.12%] [G loss: 2.021226]\n",
      "epoch:1 step:1403 [D loss: 0.300678, acc: 90.62%] [G loss: 2.519963]\n",
      "epoch:1 step:1404 [D loss: 0.924436, acc: 39.84%] [G loss: 1.799301]\n",
      "epoch:1 step:1405 [D loss: 0.654059, acc: 64.84%] [G loss: 1.862107]\n",
      "epoch:1 step:1406 [D loss: 0.449203, acc: 73.44%] [G loss: 2.245133]\n",
      "epoch:1 step:1407 [D loss: 0.958244, acc: 42.97%] [G loss: 2.083544]\n",
      "epoch:1 step:1408 [D loss: 0.883225, acc: 50.00%] [G loss: 1.918697]\n",
      "epoch:1 step:1409 [D loss: 0.710551, acc: 59.38%] [G loss: 2.086620]\n",
      "epoch:1 step:1410 [D loss: 0.624220, acc: 66.41%] [G loss: 2.245599]\n",
      "epoch:1 step:1411 [D loss: 0.969547, acc: 36.72%] [G loss: 2.081606]\n",
      "epoch:1 step:1412 [D loss: 0.701842, acc: 60.94%] [G loss: 2.247428]\n",
      "epoch:1 step:1413 [D loss: 0.937133, acc: 39.84%] [G loss: 2.074790]\n",
      "epoch:1 step:1414 [D loss: 0.618567, acc: 68.75%] [G loss: 2.635028]\n",
      "epoch:1 step:1415 [D loss: 0.750234, acc: 53.91%] [G loss: 2.167160]\n",
      "epoch:1 step:1416 [D loss: 0.569606, acc: 69.53%] [G loss: 2.621541]\n",
      "epoch:1 step:1417 [D loss: 0.450472, acc: 77.34%] [G loss: 2.637760]\n",
      "epoch:1 step:1418 [D loss: 0.596912, acc: 64.84%] [G loss: 2.756760]\n",
      "epoch:1 step:1419 [D loss: 0.406167, acc: 85.16%] [G loss: 3.152509]\n",
      "epoch:1 step:1420 [D loss: 0.472079, acc: 77.34%] [G loss: 2.916385]\n",
      "epoch:1 step:1421 [D loss: 0.506502, acc: 77.34%] [G loss: 3.111064]\n",
      "epoch:1 step:1422 [D loss: 0.392099, acc: 80.47%] [G loss: 3.346403]\n",
      "epoch:1 step:1423 [D loss: 0.667194, acc: 64.84%] [G loss: 2.655395]\n",
      "epoch:1 step:1424 [D loss: 0.579787, acc: 67.19%] [G loss: 2.976889]\n",
      "epoch:1 step:1425 [D loss: 0.514154, acc: 77.34%] [G loss: 2.839329]\n",
      "epoch:1 step:1426 [D loss: 0.935993, acc: 43.75%] [G loss: 2.164266]\n",
      "epoch:1 step:1427 [D loss: 0.581193, acc: 73.44%] [G loss: 3.049720]\n",
      "epoch:1 step:1428 [D loss: 0.394042, acc: 85.94%] [G loss: 2.585390]\n",
      "epoch:1 step:1429 [D loss: 0.485137, acc: 71.09%] [G loss: 2.709006]\n",
      "epoch:1 step:1430 [D loss: 0.282471, acc: 91.41%] [G loss: 3.489475]\n",
      "epoch:1 step:1431 [D loss: 0.282137, acc: 87.50%] [G loss: 3.036166]\n",
      "epoch:1 step:1432 [D loss: 0.299707, acc: 92.97%] [G loss: 2.809589]\n",
      "epoch:1 step:1433 [D loss: 0.167470, acc: 96.88%] [G loss: 2.961088]\n",
      "epoch:1 step:1434 [D loss: 0.122471, acc: 99.22%] [G loss: 2.638912]\n",
      "epoch:1 step:1435 [D loss: 0.270604, acc: 93.75%] [G loss: 3.068313]\n",
      "epoch:1 step:1436 [D loss: 0.474617, acc: 78.91%] [G loss: 2.257821]\n",
      "epoch:1 step:1437 [D loss: 0.635477, acc: 67.19%] [G loss: 2.064541]\n",
      "epoch:1 step:1438 [D loss: 0.197700, acc: 97.66%] [G loss: 2.348809]\n",
      "epoch:1 step:1439 [D loss: 0.216404, acc: 95.31%] [G loss: 2.876294]\n",
      "epoch:1 step:1440 [D loss: 0.370635, acc: 81.25%] [G loss: 2.755307]\n",
      "epoch:1 step:1441 [D loss: 0.222277, acc: 93.75%] [G loss: 2.375887]\n",
      "epoch:1 step:1442 [D loss: 0.173253, acc: 96.88%] [G loss: 3.227286]\n",
      "epoch:1 step:1443 [D loss: 0.117808, acc: 97.66%] [G loss: 3.718606]\n",
      "epoch:1 step:1444 [D loss: 0.074519, acc: 100.00%] [G loss: 3.490529]\n",
      "epoch:1 step:1445 [D loss: 0.231658, acc: 92.97%] [G loss: 2.677235]\n",
      "epoch:1 step:1446 [D loss: 0.046551, acc: 100.00%] [G loss: 3.804818]\n",
      "epoch:1 step:1447 [D loss: 1.005828, acc: 44.53%] [G loss: 1.987890]\n",
      "epoch:1 step:1448 [D loss: 0.313268, acc: 86.72%] [G loss: 2.492534]\n",
      "epoch:1 step:1449 [D loss: 0.256466, acc: 93.75%] [G loss: 2.936550]\n",
      "epoch:1 step:1450 [D loss: 0.563303, acc: 73.44%] [G loss: 2.035903]\n",
      "epoch:1 step:1451 [D loss: 0.213678, acc: 91.41%] [G loss: 2.981698]\n",
      "epoch:1 step:1452 [D loss: 0.940735, acc: 40.62%] [G loss: 3.011055]\n",
      "epoch:1 step:1453 [D loss: 0.447004, acc: 78.91%] [G loss: 2.091578]\n",
      "epoch:1 step:1454 [D loss: 0.350114, acc: 87.50%] [G loss: 2.039882]\n",
      "epoch:1 step:1455 [D loss: 1.122664, acc: 46.88%] [G loss: 2.390489]\n",
      "epoch:1 step:1456 [D loss: 1.003476, acc: 46.88%] [G loss: 2.868421]\n",
      "epoch:1 step:1457 [D loss: 1.068850, acc: 42.19%] [G loss: 3.469305]\n",
      "epoch:1 step:1458 [D loss: 0.675595, acc: 64.84%] [G loss: 3.042751]\n",
      "epoch:1 step:1459 [D loss: 0.181558, acc: 96.09%] [G loss: 3.757526]\n",
      "epoch:1 step:1460 [D loss: 0.241370, acc: 91.41%] [G loss: 2.620690]\n",
      "epoch:1 step:1461 [D loss: 0.267307, acc: 92.19%] [G loss: 2.945184]\n",
      "epoch:1 step:1462 [D loss: 0.209185, acc: 93.75%] [G loss: 2.429201]\n",
      "epoch:1 step:1463 [D loss: 0.413882, acc: 83.59%] [G loss: 1.948401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1464 [D loss: 0.177956, acc: 97.66%] [G loss: 2.541274]\n",
      "epoch:1 step:1465 [D loss: 0.173612, acc: 96.88%] [G loss: 2.486052]\n",
      "epoch:1 step:1466 [D loss: 0.109124, acc: 99.22%] [G loss: 3.073800]\n",
      "epoch:1 step:1467 [D loss: 0.600063, acc: 71.09%] [G loss: 1.771420]\n",
      "epoch:1 step:1468 [D loss: 0.188609, acc: 96.88%] [G loss: 2.285462]\n",
      "epoch:1 step:1469 [D loss: 0.355166, acc: 87.50%] [G loss: 2.412077]\n",
      "epoch:1 step:1470 [D loss: 0.145773, acc: 95.31%] [G loss: 2.335001]\n",
      "epoch:1 step:1471 [D loss: 0.736762, acc: 61.72%] [G loss: 1.875654]\n",
      "epoch:1 step:1472 [D loss: 0.181832, acc: 95.31%] [G loss: 2.212407]\n",
      "epoch:1 step:1473 [D loss: 0.654833, acc: 68.75%] [G loss: 2.043192]\n",
      "epoch:1 step:1474 [D loss: 0.281135, acc: 92.19%] [G loss: 2.355381]\n",
      "epoch:1 step:1475 [D loss: 0.235885, acc: 94.53%] [G loss: 2.291332]\n",
      "epoch:1 step:1476 [D loss: 0.529016, acc: 67.97%] [G loss: 2.457932]\n",
      "epoch:1 step:1477 [D loss: 0.561784, acc: 78.12%] [G loss: 1.962459]\n",
      "epoch:1 step:1478 [D loss: 0.349720, acc: 89.84%] [G loss: 1.970441]\n",
      "epoch:1 step:1479 [D loss: 0.178799, acc: 95.31%] [G loss: 2.345510]\n",
      "epoch:1 step:1480 [D loss: 0.755276, acc: 55.47%] [G loss: 2.237068]\n",
      "epoch:1 step:1481 [D loss: 0.302207, acc: 89.06%] [G loss: 2.117068]\n",
      "epoch:1 step:1482 [D loss: 0.978184, acc: 46.88%] [G loss: 1.926748]\n",
      "epoch:1 step:1483 [D loss: 1.002625, acc: 46.09%] [G loss: 2.002873]\n",
      "epoch:1 step:1484 [D loss: 1.002285, acc: 39.84%] [G loss: 2.109424]\n",
      "epoch:1 step:1485 [D loss: 1.053142, acc: 38.28%] [G loss: 2.719544]\n",
      "epoch:1 step:1486 [D loss: 0.537267, acc: 64.84%] [G loss: 2.919682]\n",
      "epoch:1 step:1487 [D loss: 0.307511, acc: 89.06%] [G loss: 2.384238]\n",
      "epoch:1 step:1488 [D loss: 0.500887, acc: 82.03%] [G loss: 2.576236]\n",
      "epoch:1 step:1489 [D loss: 0.467191, acc: 78.12%] [G loss: 2.203968]\n",
      "epoch:1 step:1490 [D loss: 0.434310, acc: 85.16%] [G loss: 2.047881]\n",
      "epoch:1 step:1491 [D loss: 0.280241, acc: 95.31%] [G loss: 2.460657]\n",
      "epoch:1 step:1492 [D loss: 1.707055, acc: 15.62%] [G loss: 1.766019]\n",
      "epoch:1 step:1493 [D loss: 0.729219, acc: 50.00%] [G loss: 1.862424]\n",
      "epoch:1 step:1494 [D loss: 0.897534, acc: 50.00%] [G loss: 2.059175]\n",
      "epoch:1 step:1495 [D loss: 0.680224, acc: 61.72%] [G loss: 2.597822]\n",
      "epoch:1 step:1496 [D loss: 0.743966, acc: 58.59%] [G loss: 2.347404]\n",
      "epoch:1 step:1497 [D loss: 0.665088, acc: 60.16%] [G loss: 2.406455]\n",
      "epoch:1 step:1498 [D loss: 0.505729, acc: 72.66%] [G loss: 2.739858]\n",
      "epoch:1 step:1499 [D loss: 0.704386, acc: 55.47%] [G loss: 2.188812]\n",
      "epoch:1 step:1500 [D loss: 0.625742, acc: 61.72%] [G loss: 2.319451]\n",
      "epoch:1 step:1501 [D loss: 0.754514, acc: 53.91%] [G loss: 2.031796]\n",
      "epoch:1 step:1502 [D loss: 1.029741, acc: 29.69%] [G loss: 1.946863]\n",
      "epoch:1 step:1503 [D loss: 0.492458, acc: 77.34%] [G loss: 2.278639]\n",
      "epoch:1 step:1504 [D loss: 0.795494, acc: 46.88%] [G loss: 1.921778]\n",
      "epoch:1 step:1505 [D loss: 0.255634, acc: 94.53%] [G loss: 2.825388]\n",
      "epoch:1 step:1506 [D loss: 0.326195, acc: 92.19%] [G loss: 2.801534]\n",
      "epoch:1 step:1507 [D loss: 0.660159, acc: 67.97%] [G loss: 1.857019]\n",
      "epoch:1 step:1508 [D loss: 0.894445, acc: 46.88%] [G loss: 1.639006]\n",
      "epoch:1 step:1509 [D loss: 0.448001, acc: 78.91%] [G loss: 2.414726]\n",
      "epoch:1 step:1510 [D loss: 0.504819, acc: 75.78%] [G loss: 1.945245]\n",
      "epoch:1 step:1511 [D loss: 0.724997, acc: 62.50%] [G loss: 1.716722]\n",
      "epoch:1 step:1512 [D loss: 0.542571, acc: 78.12%] [G loss: 2.221408]\n",
      "epoch:1 step:1513 [D loss: 0.595068, acc: 67.19%] [G loss: 1.964430]\n",
      "epoch:1 step:1514 [D loss: 0.633741, acc: 65.62%] [G loss: 2.033191]\n",
      "epoch:1 step:1515 [D loss: 0.656259, acc: 60.94%] [G loss: 1.780423]\n",
      "epoch:1 step:1516 [D loss: 0.561844, acc: 72.66%] [G loss: 2.129516]\n",
      "epoch:1 step:1517 [D loss: 0.645933, acc: 66.41%] [G loss: 1.755876]\n",
      "epoch:1 step:1518 [D loss: 0.688427, acc: 60.94%] [G loss: 1.880016]\n",
      "epoch:1 step:1519 [D loss: 0.672116, acc: 62.50%] [G loss: 1.772948]\n",
      "epoch:1 step:1520 [D loss: 0.499709, acc: 78.12%] [G loss: 1.819367]\n",
      "epoch:1 step:1521 [D loss: 0.759082, acc: 57.03%] [G loss: 1.958406]\n",
      "epoch:1 step:1522 [D loss: 0.813545, acc: 49.22%] [G loss: 1.922078]\n",
      "epoch:1 step:1523 [D loss: 0.930321, acc: 37.50%] [G loss: 1.601617]\n",
      "epoch:1 step:1524 [D loss: 0.849132, acc: 34.38%] [G loss: 1.541425]\n",
      "epoch:1 step:1525 [D loss: 1.042148, acc: 28.91%] [G loss: 1.651720]\n",
      "epoch:1 step:1526 [D loss: 0.970910, acc: 32.81%] [G loss: 1.460606]\n",
      "epoch:1 step:1527 [D loss: 0.812506, acc: 43.75%] [G loss: 1.836214]\n",
      "epoch:1 step:1528 [D loss: 0.696908, acc: 55.47%] [G loss: 1.985529]\n",
      "epoch:1 step:1529 [D loss: 0.851745, acc: 46.88%] [G loss: 1.723517]\n",
      "epoch:1 step:1530 [D loss: 0.818279, acc: 46.09%] [G loss: 1.791889]\n",
      "epoch:1 step:1531 [D loss: 0.732296, acc: 52.34%] [G loss: 1.964414]\n",
      "epoch:1 step:1532 [D loss: 0.849823, acc: 39.06%] [G loss: 1.583942]\n",
      "epoch:1 step:1533 [D loss: 0.558347, acc: 78.12%] [G loss: 1.987302]\n",
      "epoch:1 step:1534 [D loss: 0.743482, acc: 55.47%] [G loss: 1.876018]\n",
      "epoch:1 step:1535 [D loss: 0.890191, acc: 31.25%] [G loss: 1.663512]\n",
      "epoch:1 step:1536 [D loss: 0.689499, acc: 57.81%] [G loss: 1.936095]\n",
      "epoch:1 step:1537 [D loss: 0.777090, acc: 51.56%] [G loss: 1.786740]\n",
      "epoch:1 step:1538 [D loss: 0.708947, acc: 54.69%] [G loss: 1.976705]\n",
      "epoch:1 step:1539 [D loss: 0.533118, acc: 78.91%] [G loss: 2.139749]\n",
      "epoch:1 step:1540 [D loss: 0.594803, acc: 66.41%] [G loss: 2.170714]\n",
      "epoch:1 step:1541 [D loss: 0.682289, acc: 63.28%] [G loss: 1.944277]\n",
      "epoch:1 step:1542 [D loss: 0.596441, acc: 66.41%] [G loss: 1.846317]\n",
      "epoch:1 step:1543 [D loss: 0.652384, acc: 62.50%] [G loss: 2.044334]\n",
      "epoch:1 step:1544 [D loss: 0.671978, acc: 63.28%] [G loss: 1.813412]\n",
      "epoch:1 step:1545 [D loss: 0.855605, acc: 38.28%] [G loss: 1.573522]\n",
      "epoch:1 step:1546 [D loss: 0.757036, acc: 47.66%] [G loss: 1.778932]\n",
      "epoch:1 step:1547 [D loss: 0.654803, acc: 63.28%] [G loss: 2.035085]\n",
      "epoch:1 step:1548 [D loss: 0.395141, acc: 89.06%] [G loss: 2.072742]\n",
      "epoch:1 step:1549 [D loss: 0.710828, acc: 50.00%] [G loss: 2.078034]\n",
      "epoch:1 step:1550 [D loss: 0.876828, acc: 50.00%] [G loss: 1.752140]\n",
      "epoch:1 step:1551 [D loss: 0.622002, acc: 67.19%] [G loss: 1.882894]\n",
      "epoch:1 step:1552 [D loss: 0.907601, acc: 35.16%] [G loss: 1.748474]\n",
      "epoch:1 step:1553 [D loss: 0.526083, acc: 72.66%] [G loss: 1.896274]\n",
      "epoch:1 step:1554 [D loss: 0.609855, acc: 72.66%] [G loss: 1.790418]\n",
      "epoch:1 step:1555 [D loss: 0.783251, acc: 51.56%] [G loss: 1.727252]\n",
      "epoch:1 step:1556 [D loss: 0.573409, acc: 73.44%] [G loss: 2.125292]\n",
      "epoch:1 step:1557 [D loss: 0.740559, acc: 46.09%] [G loss: 1.852423]\n",
      "epoch:1 step:1558 [D loss: 0.640649, acc: 64.84%] [G loss: 1.722400]\n",
      "epoch:1 step:1559 [D loss: 0.643537, acc: 67.97%] [G loss: 1.910826]\n",
      "epoch:1 step:1560 [D loss: 0.689039, acc: 43.75%] [G loss: 1.798430]\n",
      "epoch:1 step:1561 [D loss: 0.339317, acc: 94.53%] [G loss: 2.134140]\n",
      "epoch:1 step:1562 [D loss: 0.827644, acc: 42.19%] [G loss: 1.672688]\n",
      "epoch:2 step:1563 [D loss: 0.821198, acc: 50.00%] [G loss: 1.545665]\n",
      "epoch:2 step:1564 [D loss: 0.708765, acc: 62.50%] [G loss: 1.947650]\n",
      "epoch:2 step:1565 [D loss: 0.793746, acc: 43.75%] [G loss: 1.853076]\n",
      "epoch:2 step:1566 [D loss: 0.943542, acc: 42.19%] [G loss: 1.755002]\n",
      "epoch:2 step:1567 [D loss: 0.571795, acc: 70.31%] [G loss: 1.868118]\n",
      "epoch:2 step:1568 [D loss: 0.770972, acc: 49.22%] [G loss: 2.139443]\n",
      "epoch:2 step:1569 [D loss: 0.615839, acc: 67.19%] [G loss: 2.324155]\n",
      "epoch:2 step:1570 [D loss: 0.817842, acc: 42.97%] [G loss: 1.932495]\n",
      "epoch:2 step:1571 [D loss: 0.467559, acc: 82.81%] [G loss: 2.585892]\n",
      "epoch:2 step:1572 [D loss: 0.697687, acc: 65.62%] [G loss: 2.558823]\n",
      "epoch:2 step:1573 [D loss: 0.445130, acc: 82.03%] [G loss: 2.747474]\n",
      "epoch:2 step:1574 [D loss: 0.482736, acc: 74.22%] [G loss: 2.341632]\n",
      "epoch:2 step:1575 [D loss: 0.498310, acc: 77.34%] [G loss: 2.393791]\n",
      "epoch:2 step:1576 [D loss: 0.405496, acc: 89.84%] [G loss: 2.459174]\n",
      "epoch:2 step:1577 [D loss: 0.385784, acc: 91.41%] [G loss: 2.425183]\n",
      "epoch:2 step:1578 [D loss: 0.649757, acc: 61.72%] [G loss: 2.198564]\n",
      "epoch:2 step:1579 [D loss: 0.353377, acc: 88.28%] [G loss: 2.462323]\n",
      "epoch:2 step:1580 [D loss: 0.411650, acc: 87.50%] [G loss: 2.539330]\n",
      "epoch:2 step:1581 [D loss: 0.274190, acc: 93.75%] [G loss: 2.315543]\n",
      "epoch:2 step:1582 [D loss: 0.584968, acc: 68.75%] [G loss: 1.855512]\n",
      "epoch:2 step:1583 [D loss: 0.340268, acc: 88.28%] [G loss: 2.332874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1584 [D loss: 0.369932, acc: 83.59%] [G loss: 1.858195]\n",
      "epoch:2 step:1585 [D loss: 0.381011, acc: 85.94%] [G loss: 2.514185]\n",
      "epoch:2 step:1586 [D loss: 0.181282, acc: 96.09%] [G loss: 2.579182]\n",
      "epoch:2 step:1587 [D loss: 0.358319, acc: 89.84%] [G loss: 1.915030]\n",
      "epoch:2 step:1588 [D loss: 1.743611, acc: 7.81%] [G loss: 1.382822]\n",
      "epoch:2 step:1589 [D loss: 1.075992, acc: 42.97%] [G loss: 1.553359]\n",
      "epoch:2 step:1590 [D loss: 0.540189, acc: 71.09%] [G loss: 1.743154]\n",
      "epoch:2 step:1591 [D loss: 0.388317, acc: 77.34%] [G loss: 1.909354]\n",
      "epoch:2 step:1592 [D loss: 1.154479, acc: 30.47%] [G loss: 2.013334]\n",
      "epoch:2 step:1593 [D loss: 0.659389, acc: 65.62%] [G loss: 1.972055]\n",
      "epoch:2 step:1594 [D loss: 0.629983, acc: 64.84%] [G loss: 2.142622]\n",
      "epoch:2 step:1595 [D loss: 0.867657, acc: 50.78%] [G loss: 2.007180]\n",
      "epoch:2 step:1596 [D loss: 0.760139, acc: 51.56%] [G loss: 1.970451]\n",
      "epoch:2 step:1597 [D loss: 1.278544, acc: 19.53%] [G loss: 1.557433]\n",
      "epoch:2 step:1598 [D loss: 0.951370, acc: 40.62%] [G loss: 1.300403]\n",
      "epoch:2 step:1599 [D loss: 0.880209, acc: 46.09%] [G loss: 1.519927]\n",
      "epoch:2 step:1600 [D loss: 0.575285, acc: 71.09%] [G loss: 1.808529]\n",
      "epoch:2 step:1601 [D loss: 0.555970, acc: 73.44%] [G loss: 1.753393]\n",
      "epoch:2 step:1602 [D loss: 0.681111, acc: 56.25%] [G loss: 1.958755]\n",
      "epoch:2 step:1603 [D loss: 0.562544, acc: 67.19%] [G loss: 1.811233]\n",
      "epoch:2 step:1604 [D loss: 0.765458, acc: 53.91%] [G loss: 1.847400]\n",
      "epoch:2 step:1605 [D loss: 0.513963, acc: 74.22%] [G loss: 1.865753]\n",
      "epoch:2 step:1606 [D loss: 1.241268, acc: 20.31%] [G loss: 1.276511]\n",
      "epoch:2 step:1607 [D loss: 0.906228, acc: 45.31%] [G loss: 1.745698]\n",
      "epoch:2 step:1608 [D loss: 0.603311, acc: 65.62%] [G loss: 2.053814]\n",
      "epoch:2 step:1609 [D loss: 0.958214, acc: 46.09%] [G loss: 1.483277]\n",
      "epoch:2 step:1610 [D loss: 0.638207, acc: 66.41%] [G loss: 2.002157]\n",
      "epoch:2 step:1611 [D loss: 0.476251, acc: 82.03%] [G loss: 2.600770]\n",
      "epoch:2 step:1612 [D loss: 0.512062, acc: 75.78%] [G loss: 1.923258]\n",
      "epoch:2 step:1613 [D loss: 0.402534, acc: 87.50%] [G loss: 2.118549]\n",
      "epoch:2 step:1614 [D loss: 0.979745, acc: 41.41%] [G loss: 1.609860]\n",
      "epoch:2 step:1615 [D loss: 0.444524, acc: 81.25%] [G loss: 1.974772]\n",
      "epoch:2 step:1616 [D loss: 0.696090, acc: 54.69%] [G loss: 1.844137]\n",
      "epoch:2 step:1617 [D loss: 0.418282, acc: 87.50%] [G loss: 2.469702]\n",
      "epoch:2 step:1618 [D loss: 1.410306, acc: 32.81%] [G loss: 1.255355]\n",
      "epoch:2 step:1619 [D loss: 0.378269, acc: 91.41%] [G loss: 2.149300]\n",
      "epoch:2 step:1620 [D loss: 0.448767, acc: 82.03%] [G loss: 1.765192]\n",
      "epoch:2 step:1621 [D loss: 0.282074, acc: 95.31%] [G loss: 1.930409]\n",
      "epoch:2 step:1622 [D loss: 0.497672, acc: 75.78%] [G loss: 1.678526]\n",
      "epoch:2 step:1623 [D loss: 0.532603, acc: 75.78%] [G loss: 1.648051]\n",
      "epoch:2 step:1624 [D loss: 0.621372, acc: 63.28%] [G loss: 1.339393]\n",
      "epoch:2 step:1625 [D loss: 0.434391, acc: 79.69%] [G loss: 1.622246]\n",
      "epoch:2 step:1626 [D loss: 0.537093, acc: 75.78%] [G loss: 1.643749]\n",
      "epoch:2 step:1627 [D loss: 0.771998, acc: 50.00%] [G loss: 1.427921]\n",
      "epoch:2 step:1628 [D loss: 0.424178, acc: 82.81%] [G loss: 1.490416]\n",
      "epoch:2 step:1629 [D loss: 0.865111, acc: 48.44%] [G loss: 1.508969]\n",
      "epoch:2 step:1630 [D loss: 0.870524, acc: 49.22%] [G loss: 1.448903]\n",
      "epoch:2 step:1631 [D loss: 0.666660, acc: 60.16%] [G loss: 1.210728]\n",
      "epoch:2 step:1632 [D loss: 0.644996, acc: 60.16%] [G loss: 1.612850]\n",
      "epoch:2 step:1633 [D loss: 0.996098, acc: 51.56%] [G loss: 2.092472]\n",
      "epoch:2 step:1634 [D loss: 1.078285, acc: 33.59%] [G loss: 1.333063]\n",
      "epoch:2 step:1635 [D loss: 0.532342, acc: 75.78%] [G loss: 1.894632]\n",
      "epoch:2 step:1636 [D loss: 1.247675, acc: 21.88%] [G loss: 1.240730]\n",
      "epoch:2 step:1637 [D loss: 1.103536, acc: 27.34%] [G loss: 1.248795]\n",
      "epoch:2 step:1638 [D loss: 0.685374, acc: 59.38%] [G loss: 1.499673]\n",
      "epoch:2 step:1639 [D loss: 1.003819, acc: 29.69%] [G loss: 1.236531]\n",
      "epoch:2 step:1640 [D loss: 0.666244, acc: 54.69%] [G loss: 1.521302]\n",
      "epoch:2 step:1641 [D loss: 0.566705, acc: 70.31%] [G loss: 1.696222]\n",
      "epoch:2 step:1642 [D loss: 0.788553, acc: 51.56%] [G loss: 1.927026]\n",
      "epoch:2 step:1643 [D loss: 1.100225, acc: 23.44%] [G loss: 1.285290]\n",
      "epoch:2 step:1644 [D loss: 0.505785, acc: 78.12%] [G loss: 1.694632]\n",
      "epoch:2 step:1645 [D loss: 0.760140, acc: 57.03%] [G loss: 2.600138]\n",
      "epoch:2 step:1646 [D loss: 1.750105, acc: 15.62%] [G loss: 1.628635]\n",
      "epoch:2 step:1647 [D loss: 0.417966, acc: 82.81%] [G loss: 2.882003]\n",
      "epoch:2 step:1648 [D loss: 0.343081, acc: 90.62%] [G loss: 2.937711]\n",
      "epoch:2 step:1649 [D loss: 0.464001, acc: 82.81%] [G loss: 2.395643]\n",
      "epoch:2 step:1650 [D loss: 0.259675, acc: 92.19%] [G loss: 3.009079]\n",
      "epoch:2 step:1651 [D loss: 0.435276, acc: 82.03%] [G loss: 2.547440]\n",
      "epoch:2 step:1652 [D loss: 0.470740, acc: 82.81%] [G loss: 2.179679]\n",
      "epoch:2 step:1653 [D loss: 0.386545, acc: 85.94%] [G loss: 2.365850]\n",
      "epoch:2 step:1654 [D loss: 0.378819, acc: 89.84%] [G loss: 2.270191]\n",
      "epoch:2 step:1655 [D loss: 0.297759, acc: 91.41%] [G loss: 2.204467]\n",
      "epoch:2 step:1656 [D loss: 0.365206, acc: 85.94%] [G loss: 2.622969]\n",
      "epoch:2 step:1657 [D loss: 0.392780, acc: 83.59%] [G loss: 2.087620]\n",
      "epoch:2 step:1658 [D loss: 0.397567, acc: 85.16%] [G loss: 2.189754]\n",
      "epoch:2 step:1659 [D loss: 0.208879, acc: 96.88%] [G loss: 2.513318]\n",
      "epoch:2 step:1660 [D loss: 0.363468, acc: 88.28%] [G loss: 2.561076]\n",
      "epoch:2 step:1661 [D loss: 0.462908, acc: 82.03%] [G loss: 2.185776]\n",
      "epoch:2 step:1662 [D loss: 0.739534, acc: 53.91%] [G loss: 1.682657]\n",
      "epoch:2 step:1663 [D loss: 0.508032, acc: 75.00%] [G loss: 1.494699]\n",
      "epoch:2 step:1664 [D loss: 0.273224, acc: 93.75%] [G loss: 2.390117]\n",
      "epoch:2 step:1665 [D loss: 0.565018, acc: 71.88%] [G loss: 2.376984]\n",
      "epoch:2 step:1666 [D loss: 0.618213, acc: 62.50%] [G loss: 1.869459]\n",
      "epoch:2 step:1667 [D loss: 0.611264, acc: 66.41%] [G loss: 1.676854]\n",
      "epoch:2 step:1668 [D loss: 0.281495, acc: 94.53%] [G loss: 1.987836]\n",
      "epoch:2 step:1669 [D loss: 0.757083, acc: 59.38%] [G loss: 1.998821]\n",
      "epoch:2 step:1670 [D loss: 0.632611, acc: 66.41%] [G loss: 2.035873]\n",
      "epoch:2 step:1671 [D loss: 0.689607, acc: 60.94%] [G loss: 1.643482]\n",
      "epoch:2 step:1672 [D loss: 0.519877, acc: 75.00%] [G loss: 1.722135]\n",
      "epoch:2 step:1673 [D loss: 1.190369, acc: 39.06%] [G loss: 1.791152]\n",
      "epoch:2 step:1674 [D loss: 0.452808, acc: 78.91%] [G loss: 2.036016]\n",
      "epoch:2 step:1675 [D loss: 1.125136, acc: 25.78%] [G loss: 1.871576]\n",
      "epoch:2 step:1676 [D loss: 0.644983, acc: 62.50%] [G loss: 2.497300]\n",
      "epoch:2 step:1677 [D loss: 0.778260, acc: 56.25%] [G loss: 2.096205]\n",
      "epoch:2 step:1678 [D loss: 0.854319, acc: 43.75%] [G loss: 2.664719]\n",
      "epoch:2 step:1679 [D loss: 0.908945, acc: 42.97%] [G loss: 2.609763]\n",
      "epoch:2 step:1680 [D loss: 1.085783, acc: 42.97%] [G loss: 2.718252]\n",
      "epoch:2 step:1681 [D loss: 0.352188, acc: 87.50%] [G loss: 3.931132]\n",
      "epoch:2 step:1682 [D loss: 0.395212, acc: 84.38%] [G loss: 2.279116]\n",
      "epoch:2 step:1683 [D loss: 0.599703, acc: 67.19%] [G loss: 2.063594]\n",
      "epoch:2 step:1684 [D loss: 0.583633, acc: 67.19%] [G loss: 2.266970]\n",
      "epoch:2 step:1685 [D loss: 0.975452, acc: 35.16%] [G loss: 2.034219]\n",
      "epoch:2 step:1686 [D loss: 1.003146, acc: 39.06%] [G loss: 1.768835]\n",
      "epoch:2 step:1687 [D loss: 0.478209, acc: 76.56%] [G loss: 3.296671]\n",
      "epoch:2 step:1688 [D loss: 1.077095, acc: 38.28%] [G loss: 2.109225]\n",
      "epoch:2 step:1689 [D loss: 0.413159, acc: 80.47%] [G loss: 2.758000]\n",
      "epoch:2 step:1690 [D loss: 0.952635, acc: 44.53%] [G loss: 2.218793]\n",
      "epoch:2 step:1691 [D loss: 0.551174, acc: 74.22%] [G loss: 1.864688]\n",
      "epoch:2 step:1692 [D loss: 0.487554, acc: 77.34%] [G loss: 2.195835]\n",
      "epoch:2 step:1693 [D loss: 0.702567, acc: 60.16%] [G loss: 2.865901]\n",
      "epoch:2 step:1694 [D loss: 0.793401, acc: 53.12%] [G loss: 1.927353]\n",
      "epoch:2 step:1695 [D loss: 0.294554, acc: 93.75%] [G loss: 2.306778]\n",
      "epoch:2 step:1696 [D loss: 0.421045, acc: 82.81%] [G loss: 2.482339]\n",
      "epoch:2 step:1697 [D loss: 0.842673, acc: 47.66%] [G loss: 1.807001]\n",
      "epoch:2 step:1698 [D loss: 0.288243, acc: 91.41%] [G loss: 2.462853]\n",
      "epoch:2 step:1699 [D loss: 0.597034, acc: 73.44%] [G loss: 2.093261]\n",
      "epoch:2 step:1700 [D loss: 0.292436, acc: 91.41%] [G loss: 2.455631]\n",
      "epoch:2 step:1701 [D loss: 0.438501, acc: 82.03%] [G loss: 2.273150]\n",
      "epoch:2 step:1702 [D loss: 0.665368, acc: 62.50%] [G loss: 2.302063]\n",
      "epoch:2 step:1703 [D loss: 0.737379, acc: 53.91%] [G loss: 2.259319]\n",
      "epoch:2 step:1704 [D loss: 0.945104, acc: 36.72%] [G loss: 1.781766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1705 [D loss: 1.023825, acc: 38.28%] [G loss: 1.890564]\n",
      "epoch:2 step:1706 [D loss: 0.550382, acc: 70.31%] [G loss: 2.274669]\n",
      "epoch:2 step:1707 [D loss: 0.645427, acc: 67.19%] [G loss: 2.134107]\n",
      "epoch:2 step:1708 [D loss: 0.527681, acc: 75.00%] [G loss: 2.272651]\n",
      "epoch:2 step:1709 [D loss: 0.568476, acc: 71.88%] [G loss: 2.505519]\n",
      "epoch:2 step:1710 [D loss: 0.778869, acc: 49.22%] [G loss: 1.934867]\n",
      "epoch:2 step:1711 [D loss: 0.440554, acc: 78.12%] [G loss: 2.428271]\n",
      "epoch:2 step:1712 [D loss: 0.512106, acc: 76.56%] [G loss: 1.952880]\n",
      "epoch:2 step:1713 [D loss: 0.763893, acc: 52.34%] [G loss: 2.097866]\n",
      "epoch:2 step:1714 [D loss: 0.477010, acc: 82.03%] [G loss: 2.301983]\n",
      "epoch:2 step:1715 [D loss: 0.289155, acc: 89.06%] [G loss: 2.659015]\n",
      "epoch:2 step:1716 [D loss: 0.415476, acc: 82.03%] [G loss: 2.358571]\n",
      "epoch:2 step:1717 [D loss: 0.851641, acc: 54.69%] [G loss: 2.712738]\n",
      "epoch:2 step:1718 [D loss: 0.240409, acc: 92.19%] [G loss: 2.393785]\n",
      "epoch:2 step:1719 [D loss: 0.186150, acc: 95.31%] [G loss: 2.863855]\n",
      "epoch:2 step:1720 [D loss: 0.231031, acc: 91.41%] [G loss: 2.948922]\n",
      "epoch:2 step:1721 [D loss: 0.172415, acc: 97.66%] [G loss: 2.843148]\n",
      "epoch:2 step:1722 [D loss: 0.190761, acc: 96.88%] [G loss: 3.003617]\n",
      "epoch:2 step:1723 [D loss: 0.295025, acc: 89.84%] [G loss: 2.244099]\n",
      "epoch:2 step:1724 [D loss: 0.233711, acc: 96.09%] [G loss: 2.243844]\n",
      "epoch:2 step:1725 [D loss: 0.338820, acc: 89.84%] [G loss: 2.023369]\n",
      "epoch:2 step:1726 [D loss: 0.455766, acc: 77.34%] [G loss: 2.020710]\n",
      "epoch:2 step:1727 [D loss: 0.196681, acc: 92.97%] [G loss: 2.068539]\n",
      "epoch:2 step:1728 [D loss: 0.067791, acc: 100.00%] [G loss: 3.242037]\n",
      "epoch:2 step:1729 [D loss: 0.542294, acc: 78.91%] [G loss: 1.866730]\n",
      "epoch:2 step:1730 [D loss: 0.236498, acc: 96.88%] [G loss: 2.205378]\n",
      "epoch:2 step:1731 [D loss: 0.293272, acc: 92.19%] [G loss: 1.983159]\n",
      "epoch:2 step:1732 [D loss: 0.350980, acc: 86.72%] [G loss: 2.099882]\n",
      "epoch:2 step:1733 [D loss: 0.191405, acc: 96.88%] [G loss: 2.896288]\n",
      "epoch:2 step:1734 [D loss: 0.333290, acc: 85.94%] [G loss: 2.431411]\n",
      "epoch:2 step:1735 [D loss: 0.557340, acc: 72.66%] [G loss: 1.583663]\n",
      "epoch:2 step:1736 [D loss: 0.219626, acc: 96.88%] [G loss: 2.210251]\n",
      "epoch:2 step:1737 [D loss: 0.383469, acc: 84.38%] [G loss: 1.992854]\n",
      "epoch:2 step:1738 [D loss: 0.958961, acc: 45.31%] [G loss: 1.929831]\n",
      "epoch:2 step:1739 [D loss: 0.619358, acc: 61.72%] [G loss: 2.526306]\n",
      "epoch:2 step:1740 [D loss: 0.364155, acc: 85.16%] [G loss: 2.229284]\n",
      "epoch:2 step:1741 [D loss: 0.434931, acc: 75.00%] [G loss: 1.626840]\n",
      "epoch:2 step:1742 [D loss: 0.155305, acc: 96.88%] [G loss: 2.257479]\n",
      "epoch:2 step:1743 [D loss: 0.737982, acc: 55.47%] [G loss: 1.827720]\n",
      "epoch:2 step:1744 [D loss: 0.894991, acc: 45.31%] [G loss: 2.084091]\n",
      "epoch:2 step:1745 [D loss: 0.517265, acc: 77.34%] [G loss: 1.950928]\n",
      "epoch:2 step:1746 [D loss: 1.507341, acc: 10.94%] [G loss: 2.387144]\n",
      "epoch:2 step:1747 [D loss: 0.151342, acc: 97.66%] [G loss: 2.565445]\n",
      "epoch:2 step:1748 [D loss: 0.226918, acc: 92.19%] [G loss: 2.960871]\n",
      "epoch:2 step:1749 [D loss: 0.808278, acc: 51.56%] [G loss: 2.025092]\n",
      "epoch:2 step:1750 [D loss: 0.522959, acc: 75.00%] [G loss: 2.354784]\n",
      "epoch:2 step:1751 [D loss: 0.469102, acc: 79.69%] [G loss: 2.229119]\n",
      "epoch:2 step:1752 [D loss: 0.718838, acc: 60.16%] [G loss: 1.897728]\n",
      "epoch:2 step:1753 [D loss: 0.357627, acc: 85.94%] [G loss: 2.462235]\n",
      "epoch:2 step:1754 [D loss: 0.327398, acc: 89.84%] [G loss: 2.607516]\n",
      "epoch:2 step:1755 [D loss: 0.498854, acc: 78.12%] [G loss: 2.327102]\n",
      "epoch:2 step:1756 [D loss: 0.598752, acc: 64.84%] [G loss: 1.920593]\n",
      "epoch:2 step:1757 [D loss: 0.294896, acc: 93.75%] [G loss: 2.258589]\n",
      "epoch:2 step:1758 [D loss: 0.082004, acc: 100.00%] [G loss: 3.380032]\n",
      "epoch:2 step:1759 [D loss: 0.902501, acc: 52.34%] [G loss: 2.944719]\n",
      "epoch:2 step:1760 [D loss: 0.727217, acc: 57.03%] [G loss: 2.293229]\n",
      "epoch:2 step:1761 [D loss: 0.893483, acc: 51.56%] [G loss: 1.585852]\n",
      "epoch:2 step:1762 [D loss: 0.573014, acc: 67.19%] [G loss: 2.061826]\n",
      "epoch:2 step:1763 [D loss: 0.371736, acc: 86.72%] [G loss: 2.401152]\n",
      "epoch:2 step:1764 [D loss: 0.394374, acc: 83.59%] [G loss: 2.425884]\n",
      "epoch:2 step:1765 [D loss: 0.709273, acc: 56.25%] [G loss: 1.729147]\n",
      "epoch:2 step:1766 [D loss: 0.739587, acc: 49.22%] [G loss: 1.835552]\n",
      "epoch:2 step:1767 [D loss: 0.913256, acc: 39.84%] [G loss: 1.620285]\n",
      "epoch:2 step:1768 [D loss: 0.590026, acc: 67.97%] [G loss: 2.307546]\n",
      "epoch:2 step:1769 [D loss: 0.415275, acc: 81.25%] [G loss: 2.204875]\n",
      "epoch:2 step:1770 [D loss: 0.699514, acc: 57.81%] [G loss: 2.127383]\n",
      "epoch:2 step:1771 [D loss: 0.531483, acc: 72.66%] [G loss: 2.588108]\n",
      "epoch:2 step:1772 [D loss: 0.710155, acc: 59.38%] [G loss: 2.689910]\n",
      "epoch:2 step:1773 [D loss: 1.157559, acc: 45.31%] [G loss: 1.755879]\n",
      "epoch:2 step:1774 [D loss: 0.406104, acc: 83.59%] [G loss: 2.726892]\n",
      "epoch:2 step:1775 [D loss: 0.731273, acc: 53.91%] [G loss: 1.535772]\n",
      "epoch:2 step:1776 [D loss: 0.326135, acc: 89.06%] [G loss: 2.209799]\n",
      "epoch:2 step:1777 [D loss: 0.448882, acc: 78.91%] [G loss: 2.200033]\n",
      "epoch:2 step:1778 [D loss: 0.617592, acc: 69.53%] [G loss: 2.403952]\n",
      "epoch:2 step:1779 [D loss: 0.896574, acc: 38.28%] [G loss: 1.705423]\n",
      "epoch:2 step:1780 [D loss: 0.520377, acc: 75.78%] [G loss: 2.388990]\n",
      "epoch:2 step:1781 [D loss: 0.563680, acc: 72.66%] [G loss: 2.368681]\n",
      "epoch:2 step:1782 [D loss: 0.261406, acc: 94.53%] [G loss: 2.553543]\n",
      "epoch:2 step:1783 [D loss: 0.855812, acc: 44.53%] [G loss: 1.774859]\n",
      "epoch:2 step:1784 [D loss: 0.472199, acc: 74.22%] [G loss: 3.424097]\n",
      "epoch:2 step:1785 [D loss: 0.800919, acc: 57.81%] [G loss: 2.398235]\n",
      "epoch:2 step:1786 [D loss: 1.177244, acc: 17.97%] [G loss: 2.469027]\n",
      "epoch:2 step:1787 [D loss: 0.311499, acc: 89.06%] [G loss: 3.018251]\n",
      "epoch:2 step:1788 [D loss: 0.449377, acc: 82.81%] [G loss: 3.035335]\n",
      "epoch:2 step:1789 [D loss: 1.117273, acc: 29.69%] [G loss: 2.160992]\n",
      "epoch:2 step:1790 [D loss: 0.400824, acc: 88.28%] [G loss: 3.093399]\n",
      "epoch:2 step:1791 [D loss: 0.531080, acc: 75.78%] [G loss: 2.107316]\n",
      "epoch:2 step:1792 [D loss: 0.521565, acc: 67.19%] [G loss: 2.708182]\n",
      "epoch:2 step:1793 [D loss: 0.976693, acc: 45.31%] [G loss: 1.667047]\n",
      "epoch:2 step:1794 [D loss: 0.987542, acc: 48.44%] [G loss: 1.843353]\n",
      "epoch:2 step:1795 [D loss: 0.718526, acc: 60.94%] [G loss: 1.919766]\n",
      "epoch:2 step:1796 [D loss: 0.922477, acc: 41.41%] [G loss: 1.540075]\n",
      "epoch:2 step:1797 [D loss: 1.251733, acc: 18.75%] [G loss: 1.958959]\n",
      "epoch:2 step:1798 [D loss: 0.701475, acc: 57.81%] [G loss: 2.113683]\n",
      "epoch:2 step:1799 [D loss: 0.756654, acc: 52.34%] [G loss: 1.690956]\n",
      "epoch:2 step:1800 [D loss: 0.645078, acc: 63.28%] [G loss: 2.206475]\n",
      "epoch:2 step:1801 [D loss: 0.661631, acc: 60.94%] [G loss: 2.274908]\n",
      "epoch:2 step:1802 [D loss: 0.910856, acc: 32.81%] [G loss: 1.726676]\n",
      "epoch:2 step:1803 [D loss: 0.696930, acc: 57.81%] [G loss: 2.155781]\n",
      "epoch:2 step:1804 [D loss: 0.716565, acc: 62.50%] [G loss: 2.345785]\n",
      "epoch:2 step:1805 [D loss: 0.759180, acc: 51.56%] [G loss: 2.049979]\n",
      "epoch:2 step:1806 [D loss: 1.199830, acc: 21.09%] [G loss: 1.799457]\n",
      "epoch:2 step:1807 [D loss: 0.702549, acc: 54.69%] [G loss: 2.425247]\n",
      "epoch:2 step:1808 [D loss: 0.806640, acc: 49.22%] [G loss: 2.064053]\n",
      "epoch:2 step:1809 [D loss: 0.864228, acc: 39.84%] [G loss: 2.337602]\n",
      "epoch:2 step:1810 [D loss: 0.752947, acc: 60.16%] [G loss: 2.251876]\n",
      "epoch:2 step:1811 [D loss: 0.595775, acc: 73.44%] [G loss: 2.486559]\n",
      "epoch:2 step:1812 [D loss: 0.658367, acc: 64.06%] [G loss: 2.065398]\n",
      "epoch:2 step:1813 [D loss: 0.563307, acc: 71.88%] [G loss: 2.441519]\n",
      "epoch:2 step:1814 [D loss: 0.698266, acc: 56.25%] [G loss: 2.575279]\n",
      "epoch:2 step:1815 [D loss: 0.577138, acc: 67.97%] [G loss: 2.357849]\n",
      "epoch:2 step:1816 [D loss: 0.442989, acc: 82.81%] [G loss: 3.524863]\n",
      "epoch:2 step:1817 [D loss: 0.747369, acc: 46.88%] [G loss: 2.095417]\n",
      "epoch:2 step:1818 [D loss: 0.689596, acc: 61.72%] [G loss: 2.454323]\n",
      "epoch:2 step:1819 [D loss: 0.821159, acc: 43.75%] [G loss: 2.219238]\n",
      "epoch:2 step:1820 [D loss: 0.516841, acc: 78.91%] [G loss: 2.383794]\n",
      "epoch:2 step:1821 [D loss: 0.635176, acc: 55.47%] [G loss: 2.231799]\n",
      "epoch:2 step:1822 [D loss: 0.876479, acc: 42.97%] [G loss: 1.877779]\n",
      "epoch:2 step:1823 [D loss: 0.594235, acc: 66.41%] [G loss: 2.171417]\n",
      "epoch:2 step:1824 [D loss: 0.563650, acc: 69.53%] [G loss: 2.246428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1825 [D loss: 0.816050, acc: 50.78%] [G loss: 1.997033]\n",
      "epoch:2 step:1826 [D loss: 0.588826, acc: 68.75%] [G loss: 2.504973]\n",
      "epoch:2 step:1827 [D loss: 0.492555, acc: 75.78%] [G loss: 2.525379]\n",
      "epoch:2 step:1828 [D loss: 0.740143, acc: 53.12%] [G loss: 2.225055]\n",
      "epoch:2 step:1829 [D loss: 0.958953, acc: 40.62%] [G loss: 1.850176]\n",
      "epoch:2 step:1830 [D loss: 0.621051, acc: 65.62%] [G loss: 2.248043]\n",
      "epoch:2 step:1831 [D loss: 0.813480, acc: 43.75%] [G loss: 1.876700]\n",
      "epoch:2 step:1832 [D loss: 0.393212, acc: 89.84%] [G loss: 2.546278]\n",
      "epoch:2 step:1833 [D loss: 0.429262, acc: 81.25%] [G loss: 2.669285]\n",
      "epoch:2 step:1834 [D loss: 0.728498, acc: 56.25%] [G loss: 2.366158]\n",
      "epoch:2 step:1835 [D loss: 0.798208, acc: 50.78%] [G loss: 1.919297]\n",
      "epoch:2 step:1836 [D loss: 0.719392, acc: 58.59%] [G loss: 2.100581]\n",
      "epoch:2 step:1837 [D loss: 0.597777, acc: 69.53%] [G loss: 2.131063]\n",
      "epoch:2 step:1838 [D loss: 0.501083, acc: 76.56%] [G loss: 3.129382]\n",
      "epoch:2 step:1839 [D loss: 0.450825, acc: 82.03%] [G loss: 2.862047]\n",
      "epoch:2 step:1840 [D loss: 0.563889, acc: 71.88%] [G loss: 2.799482]\n",
      "epoch:2 step:1841 [D loss: 0.644489, acc: 62.50%] [G loss: 2.119596]\n",
      "epoch:2 step:1842 [D loss: 0.315138, acc: 92.19%] [G loss: 3.337496]\n",
      "epoch:2 step:1843 [D loss: 0.631168, acc: 68.75%] [G loss: 2.629699]\n",
      "epoch:2 step:1844 [D loss: 0.593126, acc: 68.75%] [G loss: 2.363543]\n",
      "epoch:2 step:1845 [D loss: 0.430264, acc: 86.72%] [G loss: 2.140891]\n",
      "epoch:2 step:1846 [D loss: 0.311690, acc: 92.97%] [G loss: 2.686394]\n",
      "epoch:2 step:1847 [D loss: 0.428981, acc: 87.50%] [G loss: 2.396144]\n",
      "epoch:2 step:1848 [D loss: 0.993207, acc: 37.50%] [G loss: 1.769561]\n",
      "epoch:2 step:1849 [D loss: 0.705137, acc: 59.38%] [G loss: 1.762600]\n",
      "epoch:2 step:1850 [D loss: 0.846184, acc: 48.44%] [G loss: 1.391585]\n",
      "epoch:2 step:1851 [D loss: 0.982709, acc: 31.25%] [G loss: 1.589881]\n",
      "epoch:2 step:1852 [D loss: 0.231432, acc: 96.88%] [G loss: 2.797880]\n",
      "epoch:2 step:1853 [D loss: 0.711801, acc: 59.38%] [G loss: 1.795986]\n",
      "epoch:2 step:1854 [D loss: 0.459116, acc: 80.47%] [G loss: 2.154335]\n",
      "epoch:2 step:1855 [D loss: 0.245987, acc: 96.09%] [G loss: 3.358741]\n",
      "epoch:2 step:1856 [D loss: 0.492005, acc: 81.25%] [G loss: 2.097165]\n",
      "epoch:2 step:1857 [D loss: 0.797310, acc: 43.75%] [G loss: 1.957951]\n",
      "epoch:2 step:1858 [D loss: 0.686455, acc: 60.94%] [G loss: 1.909012]\n",
      "epoch:2 step:1859 [D loss: 1.225807, acc: 16.41%] [G loss: 1.830065]\n",
      "epoch:2 step:1860 [D loss: 0.666982, acc: 62.50%] [G loss: 2.699546]\n",
      "epoch:2 step:1861 [D loss: 0.499827, acc: 79.69%] [G loss: 2.990346]\n",
      "epoch:2 step:1862 [D loss: 0.955311, acc: 35.94%] [G loss: 2.300903]\n",
      "epoch:2 step:1863 [D loss: 0.694212, acc: 60.16%] [G loss: 2.479136]\n",
      "epoch:2 step:1864 [D loss: 0.467366, acc: 74.22%] [G loss: 2.524644]\n",
      "epoch:2 step:1865 [D loss: 0.422210, acc: 88.28%] [G loss: 3.152788]\n",
      "epoch:2 step:1866 [D loss: 0.481690, acc: 72.66%] [G loss: 3.203814]\n",
      "epoch:2 step:1867 [D loss: 0.288911, acc: 92.19%] [G loss: 2.712069]\n",
      "epoch:2 step:1868 [D loss: 0.374650, acc: 86.72%] [G loss: 2.440716]\n",
      "epoch:2 step:1869 [D loss: 0.611592, acc: 67.19%] [G loss: 1.963957]\n",
      "epoch:2 step:1870 [D loss: 0.251603, acc: 96.09%] [G loss: 2.633996]\n",
      "epoch:2 step:1871 [D loss: 0.479948, acc: 81.25%] [G loss: 2.566698]\n",
      "epoch:2 step:1872 [D loss: 0.853887, acc: 42.97%] [G loss: 2.061740]\n",
      "epoch:2 step:1873 [D loss: 0.131576, acc: 99.22%] [G loss: 2.640719]\n",
      "epoch:2 step:1874 [D loss: 0.364607, acc: 88.28%] [G loss: 2.699112]\n",
      "epoch:2 step:1875 [D loss: 0.334828, acc: 91.41%] [G loss: 2.094506]\n",
      "epoch:2 step:1876 [D loss: 0.503342, acc: 77.34%] [G loss: 1.903420]\n",
      "epoch:2 step:1877 [D loss: 0.625095, acc: 64.06%] [G loss: 2.231692]\n",
      "epoch:2 step:1878 [D loss: 0.621647, acc: 71.09%] [G loss: 1.611012]\n",
      "epoch:2 step:1879 [D loss: 1.036159, acc: 32.03%] [G loss: 1.619885]\n",
      "epoch:2 step:1880 [D loss: 0.279985, acc: 92.19%] [G loss: 2.505343]\n",
      "epoch:2 step:1881 [D loss: 0.860874, acc: 50.00%] [G loss: 1.684273]\n",
      "epoch:2 step:1882 [D loss: 0.746442, acc: 56.25%] [G loss: 2.307540]\n",
      "epoch:2 step:1883 [D loss: 0.671673, acc: 60.94%] [G loss: 1.965944]\n",
      "epoch:2 step:1884 [D loss: 0.727451, acc: 64.06%] [G loss: 2.530735]\n",
      "epoch:2 step:1885 [D loss: 0.852320, acc: 46.09%] [G loss: 2.118182]\n",
      "epoch:2 step:1886 [D loss: 0.884584, acc: 42.97%] [G loss: 2.434398]\n",
      "epoch:2 step:1887 [D loss: 0.675483, acc: 60.16%] [G loss: 2.341620]\n",
      "epoch:2 step:1888 [D loss: 0.488469, acc: 83.59%] [G loss: 2.689423]\n",
      "epoch:2 step:1889 [D loss: 0.446287, acc: 78.91%] [G loss: 2.906889]\n",
      "epoch:2 step:1890 [D loss: 0.497724, acc: 76.56%] [G loss: 2.763260]\n",
      "epoch:2 step:1891 [D loss: 0.316078, acc: 89.84%] [G loss: 2.418431]\n",
      "epoch:2 step:1892 [D loss: 0.439724, acc: 77.34%] [G loss: 2.247278]\n",
      "epoch:2 step:1893 [D loss: 0.337855, acc: 91.41%] [G loss: 2.475318]\n",
      "epoch:2 step:1894 [D loss: 0.148027, acc: 99.22%] [G loss: 1.980867]\n",
      "epoch:2 step:1895 [D loss: 0.210645, acc: 94.53%] [G loss: 2.772215]\n",
      "epoch:2 step:1896 [D loss: 0.333170, acc: 89.06%] [G loss: 2.347837]\n",
      "epoch:2 step:1897 [D loss: 0.341033, acc: 91.41%] [G loss: 2.476564]\n",
      "epoch:2 step:1898 [D loss: 0.536044, acc: 77.34%] [G loss: 2.157550]\n",
      "epoch:2 step:1899 [D loss: 1.087147, acc: 34.38%] [G loss: 1.557122]\n",
      "epoch:2 step:1900 [D loss: 1.457628, acc: 25.78%] [G loss: 1.401143]\n",
      "epoch:2 step:1901 [D loss: 0.860099, acc: 50.78%] [G loss: 1.969138]\n",
      "epoch:2 step:1902 [D loss: 0.748860, acc: 50.78%] [G loss: 1.954341]\n",
      "epoch:2 step:1903 [D loss: 0.476148, acc: 75.78%] [G loss: 2.328975]\n",
      "epoch:2 step:1904 [D loss: 0.667882, acc: 60.16%] [G loss: 2.322082]\n",
      "epoch:2 step:1905 [D loss: 0.797420, acc: 53.12%] [G loss: 1.843423]\n",
      "epoch:2 step:1906 [D loss: 0.810278, acc: 46.88%] [G loss: 1.909091]\n",
      "epoch:2 step:1907 [D loss: 0.481542, acc: 79.69%] [G loss: 2.603649]\n",
      "epoch:2 step:1908 [D loss: 0.611807, acc: 65.62%] [G loss: 2.747999]\n",
      "epoch:2 step:1909 [D loss: 0.521278, acc: 75.78%] [G loss: 2.560143]\n",
      "epoch:2 step:1910 [D loss: 0.501506, acc: 76.56%] [G loss: 2.891198]\n",
      "epoch:2 step:1911 [D loss: 0.651906, acc: 62.50%] [G loss: 2.553065]\n",
      "epoch:2 step:1912 [D loss: 0.706891, acc: 57.03%] [G loss: 3.388197]\n",
      "epoch:2 step:1913 [D loss: 0.466771, acc: 82.03%] [G loss: 2.538782]\n",
      "epoch:2 step:1914 [D loss: 0.571673, acc: 68.75%] [G loss: 2.977697]\n",
      "epoch:2 step:1915 [D loss: 0.437123, acc: 82.03%] [G loss: 2.571837]\n",
      "epoch:2 step:1916 [D loss: 0.495201, acc: 81.25%] [G loss: 2.329460]\n",
      "epoch:2 step:1917 [D loss: 0.809762, acc: 48.44%] [G loss: 1.668780]\n",
      "epoch:2 step:1918 [D loss: 0.522713, acc: 76.56%] [G loss: 2.044476]\n",
      "epoch:2 step:1919 [D loss: 0.466596, acc: 77.34%] [G loss: 1.913472]\n",
      "epoch:2 step:1920 [D loss: 0.473918, acc: 78.91%] [G loss: 2.268384]\n",
      "epoch:2 step:1921 [D loss: 0.610710, acc: 71.88%] [G loss: 1.931284]\n",
      "epoch:2 step:1922 [D loss: 0.670517, acc: 61.72%] [G loss: 1.897809]\n",
      "epoch:2 step:1923 [D loss: 0.257359, acc: 96.88%] [G loss: 2.718300]\n",
      "epoch:2 step:1924 [D loss: 0.415486, acc: 87.50%] [G loss: 2.372891]\n",
      "epoch:2 step:1925 [D loss: 0.537338, acc: 69.53%] [G loss: 2.163615]\n",
      "epoch:2 step:1926 [D loss: 0.776823, acc: 50.00%] [G loss: 1.726447]\n",
      "epoch:2 step:1927 [D loss: 0.420724, acc: 81.25%] [G loss: 2.144596]\n",
      "epoch:2 step:1928 [D loss: 0.857763, acc: 48.44%] [G loss: 1.974234]\n",
      "epoch:2 step:1929 [D loss: 0.588530, acc: 68.75%] [G loss: 2.297285]\n",
      "epoch:2 step:1930 [D loss: 0.542388, acc: 71.88%] [G loss: 2.661848]\n",
      "epoch:2 step:1931 [D loss: 0.761271, acc: 52.34%] [G loss: 2.229709]\n",
      "epoch:2 step:1932 [D loss: 1.033150, acc: 28.91%] [G loss: 2.387892]\n",
      "epoch:2 step:1933 [D loss: 0.621556, acc: 62.50%] [G loss: 2.507761]\n",
      "epoch:2 step:1934 [D loss: 0.531861, acc: 75.00%] [G loss: 2.346922]\n",
      "epoch:2 step:1935 [D loss: 0.577913, acc: 75.78%] [G loss: 2.119098]\n",
      "epoch:2 step:1936 [D loss: 1.417158, acc: 14.06%] [G loss: 1.689988]\n",
      "epoch:2 step:1937 [D loss: 0.851581, acc: 45.31%] [G loss: 2.146778]\n",
      "epoch:2 step:1938 [D loss: 0.779304, acc: 50.78%] [G loss: 2.378155]\n",
      "epoch:2 step:1939 [D loss: 0.359076, acc: 89.84%] [G loss: 2.728223]\n",
      "epoch:2 step:1940 [D loss: 0.546157, acc: 74.22%] [G loss: 2.850030]\n",
      "epoch:2 step:1941 [D loss: 0.749786, acc: 47.66%] [G loss: 1.945499]\n",
      "epoch:2 step:1942 [D loss: 1.096050, acc: 36.72%] [G loss: 2.137058]\n",
      "epoch:2 step:1943 [D loss: 0.900314, acc: 42.97%] [G loss: 1.847571]\n",
      "epoch:2 step:1944 [D loss: 0.799738, acc: 47.66%] [G loss: 1.786296]\n",
      "epoch:2 step:1945 [D loss: 1.031166, acc: 31.25%] [G loss: 2.048667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1946 [D loss: 0.742415, acc: 62.50%] [G loss: 2.367635]\n",
      "epoch:2 step:1947 [D loss: 0.896398, acc: 44.53%] [G loss: 1.787573]\n",
      "epoch:2 step:1948 [D loss: 0.576707, acc: 68.75%] [G loss: 2.600117]\n",
      "epoch:2 step:1949 [D loss: 1.228442, acc: 17.97%] [G loss: 1.766784]\n",
      "epoch:2 step:1950 [D loss: 0.618478, acc: 68.75%] [G loss: 2.197540]\n",
      "epoch:2 step:1951 [D loss: 0.771837, acc: 46.88%] [G loss: 2.212283]\n",
      "epoch:2 step:1952 [D loss: 0.529051, acc: 77.34%] [G loss: 2.391872]\n",
      "epoch:2 step:1953 [D loss: 0.713398, acc: 53.12%] [G loss: 2.132418]\n",
      "epoch:2 step:1954 [D loss: 0.540784, acc: 76.56%] [G loss: 2.198838]\n",
      "epoch:2 step:1955 [D loss: 1.008224, acc: 36.72%] [G loss: 1.597659]\n",
      "epoch:2 step:1956 [D loss: 0.775339, acc: 46.88%] [G loss: 2.384048]\n",
      "epoch:2 step:1957 [D loss: 0.654957, acc: 64.84%] [G loss: 2.461039]\n",
      "epoch:2 step:1958 [D loss: 0.793914, acc: 49.22%] [G loss: 2.307566]\n",
      "epoch:2 step:1959 [D loss: 0.558155, acc: 71.09%] [G loss: 2.441966]\n",
      "epoch:2 step:1960 [D loss: 0.896302, acc: 36.72%] [G loss: 1.822656]\n",
      "epoch:2 step:1961 [D loss: 0.510071, acc: 79.69%] [G loss: 2.465210]\n",
      "epoch:2 step:1962 [D loss: 0.682170, acc: 57.81%] [G loss: 2.314205]\n",
      "epoch:2 step:1963 [D loss: 0.902530, acc: 41.41%] [G loss: 2.223935]\n",
      "epoch:2 step:1964 [D loss: 0.708470, acc: 58.59%] [G loss: 2.058728]\n",
      "epoch:2 step:1965 [D loss: 0.651022, acc: 65.62%] [G loss: 2.440592]\n",
      "epoch:2 step:1966 [D loss: 0.740174, acc: 56.25%] [G loss: 1.710877]\n",
      "epoch:2 step:1967 [D loss: 0.599658, acc: 71.09%] [G loss: 2.230053]\n",
      "epoch:2 step:1968 [D loss: 0.356406, acc: 92.97%] [G loss: 2.283234]\n",
      "epoch:2 step:1969 [D loss: 0.233867, acc: 93.75%] [G loss: 2.338080]\n",
      "epoch:2 step:1970 [D loss: 0.720406, acc: 53.91%] [G loss: 2.436360]\n",
      "epoch:2 step:1971 [D loss: 0.575648, acc: 65.62%] [G loss: 2.747962]\n",
      "epoch:2 step:1972 [D loss: 0.648309, acc: 61.72%] [G loss: 2.856678]\n",
      "epoch:2 step:1973 [D loss: 0.630043, acc: 70.31%] [G loss: 3.734365]\n",
      "epoch:2 step:1974 [D loss: 0.449048, acc: 82.03%] [G loss: 3.711489]\n",
      "epoch:2 step:1975 [D loss: 0.401057, acc: 88.28%] [G loss: 3.481232]\n",
      "epoch:2 step:1976 [D loss: 0.240566, acc: 92.19%] [G loss: 3.575244]\n",
      "epoch:2 step:1977 [D loss: 0.472834, acc: 77.34%] [G loss: 2.817459]\n",
      "epoch:2 step:1978 [D loss: 0.705037, acc: 64.06%] [G loss: 2.277237]\n",
      "epoch:2 step:1979 [D loss: 0.453263, acc: 80.47%] [G loss: 2.251214]\n",
      "epoch:2 step:1980 [D loss: 0.828095, acc: 49.22%] [G loss: 1.672126]\n",
      "epoch:2 step:1981 [D loss: 0.962616, acc: 34.38%] [G loss: 1.892714]\n",
      "epoch:2 step:1982 [D loss: 0.819620, acc: 48.44%] [G loss: 2.054728]\n",
      "epoch:2 step:1983 [D loss: 0.716371, acc: 55.47%] [G loss: 1.978859]\n",
      "epoch:2 step:1984 [D loss: 0.810505, acc: 51.56%] [G loss: 2.143003]\n",
      "epoch:2 step:1985 [D loss: 0.796353, acc: 53.12%] [G loss: 1.882087]\n",
      "epoch:2 step:1986 [D loss: 1.060958, acc: 30.47%] [G loss: 2.305685]\n",
      "epoch:2 step:1987 [D loss: 1.168237, acc: 25.00%] [G loss: 1.705477]\n",
      "epoch:2 step:1988 [D loss: 0.622139, acc: 64.06%] [G loss: 1.869068]\n",
      "epoch:2 step:1989 [D loss: 0.531932, acc: 77.34%] [G loss: 2.459010]\n",
      "epoch:2 step:1990 [D loss: 0.747988, acc: 51.56%] [G loss: 2.392948]\n",
      "epoch:2 step:1991 [D loss: 0.891564, acc: 41.41%] [G loss: 2.077437]\n",
      "epoch:2 step:1992 [D loss: 1.064901, acc: 30.47%] [G loss: 2.112854]\n",
      "epoch:2 step:1993 [D loss: 0.572783, acc: 75.00%] [G loss: 2.566197]\n",
      "epoch:2 step:1994 [D loss: 0.652657, acc: 60.16%] [G loss: 2.610729]\n",
      "epoch:2 step:1995 [D loss: 0.769257, acc: 50.00%] [G loss: 2.527517]\n",
      "epoch:2 step:1996 [D loss: 0.754798, acc: 54.69%] [G loss: 2.282979]\n",
      "epoch:2 step:1997 [D loss: 0.730745, acc: 57.81%] [G loss: 2.042265]\n",
      "epoch:2 step:1998 [D loss: 0.723181, acc: 56.25%] [G loss: 2.239542]\n",
      "epoch:2 step:1999 [D loss: 0.610958, acc: 65.62%] [G loss: 2.780477]\n",
      "epoch:2 step:2000 [D loss: 0.572386, acc: 74.22%] [G loss: 2.464725]\n",
      "epoch:2 step:2001 [D loss: 0.427214, acc: 85.16%] [G loss: 2.328753]\n",
      "epoch:2 step:2002 [D loss: 0.791150, acc: 50.78%] [G loss: 1.965952]\n",
      "epoch:2 step:2003 [D loss: 0.332481, acc: 90.62%] [G loss: 2.789351]\n",
      "epoch:2 step:2004 [D loss: 0.397367, acc: 88.28%] [G loss: 2.553687]\n",
      "epoch:2 step:2005 [D loss: 0.648194, acc: 64.84%] [G loss: 2.169693]\n",
      "epoch:2 step:2006 [D loss: 0.478635, acc: 79.69%] [G loss: 1.884689]\n",
      "epoch:2 step:2007 [D loss: 0.504151, acc: 75.78%] [G loss: 2.106568]\n",
      "epoch:2 step:2008 [D loss: 0.713762, acc: 54.69%] [G loss: 1.783327]\n",
      "epoch:2 step:2009 [D loss: 0.903893, acc: 41.41%] [G loss: 2.078561]\n",
      "epoch:2 step:2010 [D loss: 1.017821, acc: 42.19%] [G loss: 1.451453]\n",
      "epoch:2 step:2011 [D loss: 0.654389, acc: 68.75%] [G loss: 2.174262]\n",
      "epoch:2 step:2012 [D loss: 0.666272, acc: 63.28%] [G loss: 1.740313]\n",
      "epoch:2 step:2013 [D loss: 0.864877, acc: 39.84%] [G loss: 1.856328]\n",
      "epoch:2 step:2014 [D loss: 0.665728, acc: 59.38%] [G loss: 2.534832]\n",
      "epoch:2 step:2015 [D loss: 0.625578, acc: 67.19%] [G loss: 1.622770]\n",
      "epoch:2 step:2016 [D loss: 0.731244, acc: 58.59%] [G loss: 1.796172]\n",
      "epoch:2 step:2017 [D loss: 0.866064, acc: 51.56%] [G loss: 2.215858]\n",
      "epoch:2 step:2018 [D loss: 0.448036, acc: 78.12%] [G loss: 2.410229]\n",
      "epoch:2 step:2019 [D loss: 0.613821, acc: 64.84%] [G loss: 2.289655]\n",
      "epoch:2 step:2020 [D loss: 0.778301, acc: 53.12%] [G loss: 2.628706]\n",
      "epoch:2 step:2021 [D loss: 0.918938, acc: 39.06%] [G loss: 2.317196]\n",
      "epoch:2 step:2022 [D loss: 0.680456, acc: 61.72%] [G loss: 2.153067]\n",
      "epoch:2 step:2023 [D loss: 0.748646, acc: 60.16%] [G loss: 2.251480]\n",
      "epoch:2 step:2024 [D loss: 0.681282, acc: 55.47%] [G loss: 2.157910]\n",
      "epoch:2 step:2025 [D loss: 0.501858, acc: 79.69%] [G loss: 2.458450]\n",
      "epoch:2 step:2026 [D loss: 0.523388, acc: 70.31%] [G loss: 2.838127]\n",
      "epoch:2 step:2027 [D loss: 0.649630, acc: 59.38%] [G loss: 2.614121]\n",
      "epoch:2 step:2028 [D loss: 0.622686, acc: 66.41%] [G loss: 2.153590]\n",
      "epoch:2 step:2029 [D loss: 0.846845, acc: 42.97%] [G loss: 1.979137]\n",
      "epoch:2 step:2030 [D loss: 0.722346, acc: 55.47%] [G loss: 1.717040]\n",
      "epoch:2 step:2031 [D loss: 0.730169, acc: 56.25%] [G loss: 2.201012]\n",
      "epoch:2 step:2032 [D loss: 0.353350, acc: 92.19%] [G loss: 3.249207]\n",
      "epoch:2 step:2033 [D loss: 0.491868, acc: 78.91%] [G loss: 2.765428]\n",
      "epoch:2 step:2034 [D loss: 0.651765, acc: 63.28%] [G loss: 2.223425]\n",
      "epoch:2 step:2035 [D loss: 0.900291, acc: 40.62%] [G loss: 1.976976]\n",
      "epoch:2 step:2036 [D loss: 0.897134, acc: 37.50%] [G loss: 2.242484]\n",
      "epoch:2 step:2037 [D loss: 1.033319, acc: 29.69%] [G loss: 1.782255]\n",
      "epoch:2 step:2038 [D loss: 0.644038, acc: 60.16%] [G loss: 2.160092]\n",
      "epoch:2 step:2039 [D loss: 0.840449, acc: 41.41%] [G loss: 1.796491]\n",
      "epoch:2 step:2040 [D loss: 0.975474, acc: 32.03%] [G loss: 1.686503]\n",
      "epoch:2 step:2041 [D loss: 0.832043, acc: 44.53%] [G loss: 1.744566]\n",
      "epoch:2 step:2042 [D loss: 0.788378, acc: 52.34%] [G loss: 1.921979]\n",
      "epoch:2 step:2043 [D loss: 0.458410, acc: 85.94%] [G loss: 2.409608]\n",
      "epoch:2 step:2044 [D loss: 0.633091, acc: 59.38%] [G loss: 1.967594]\n",
      "epoch:2 step:2045 [D loss: 0.523880, acc: 81.25%] [G loss: 1.926126]\n",
      "epoch:2 step:2046 [D loss: 0.665107, acc: 63.28%] [G loss: 1.915439]\n",
      "epoch:2 step:2047 [D loss: 0.709636, acc: 60.16%] [G loss: 1.985730]\n",
      "epoch:2 step:2048 [D loss: 0.427329, acc: 85.16%] [G loss: 2.504975]\n",
      "epoch:2 step:2049 [D loss: 0.831876, acc: 52.34%] [G loss: 2.170939]\n",
      "epoch:2 step:2050 [D loss: 0.752404, acc: 50.78%] [G loss: 1.754664]\n",
      "epoch:2 step:2051 [D loss: 0.315094, acc: 89.84%] [G loss: 2.090202]\n",
      "epoch:2 step:2052 [D loss: 0.357307, acc: 92.19%] [G loss: 1.760915]\n",
      "epoch:2 step:2053 [D loss: 0.378475, acc: 86.72%] [G loss: 2.114527]\n",
      "epoch:2 step:2054 [D loss: 0.947548, acc: 29.69%] [G loss: 1.572309]\n",
      "epoch:2 step:2055 [D loss: 0.454439, acc: 78.12%] [G loss: 1.828001]\n",
      "epoch:2 step:2056 [D loss: 0.551993, acc: 73.44%] [G loss: 1.977832]\n",
      "epoch:2 step:2057 [D loss: 0.489879, acc: 81.25%] [G loss: 1.904533]\n",
      "epoch:2 step:2058 [D loss: 0.894154, acc: 39.06%] [G loss: 2.222687]\n",
      "epoch:2 step:2059 [D loss: 1.373838, acc: 23.44%] [G loss: 2.233478]\n",
      "epoch:2 step:2060 [D loss: 0.612217, acc: 64.06%] [G loss: 2.706684]\n",
      "epoch:2 step:2061 [D loss: 0.578911, acc: 70.31%] [G loss: 2.229521]\n",
      "epoch:2 step:2062 [D loss: 0.953213, acc: 32.81%] [G loss: 1.854249]\n",
      "epoch:2 step:2063 [D loss: 0.567950, acc: 70.31%] [G loss: 2.512288]\n",
      "epoch:2 step:2064 [D loss: 0.682644, acc: 60.16%] [G loss: 2.210714]\n",
      "epoch:2 step:2065 [D loss: 0.526260, acc: 76.56%] [G loss: 2.252537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2066 [D loss: 0.615828, acc: 65.62%] [G loss: 2.301438]\n",
      "epoch:2 step:2067 [D loss: 0.751310, acc: 51.56%] [G loss: 2.200452]\n",
      "epoch:2 step:2068 [D loss: 0.451657, acc: 81.25%] [G loss: 2.566457]\n",
      "epoch:2 step:2069 [D loss: 0.533920, acc: 69.53%] [G loss: 2.457398]\n",
      "epoch:2 step:2070 [D loss: 0.673124, acc: 57.81%] [G loss: 2.223861]\n",
      "epoch:2 step:2071 [D loss: 0.763615, acc: 55.47%] [G loss: 1.517868]\n",
      "epoch:2 step:2072 [D loss: 0.625613, acc: 59.38%] [G loss: 2.362051]\n",
      "epoch:2 step:2073 [D loss: 1.016236, acc: 27.34%] [G loss: 1.702605]\n",
      "epoch:2 step:2074 [D loss: 0.615556, acc: 64.06%] [G loss: 1.863999]\n",
      "epoch:2 step:2075 [D loss: 0.386873, acc: 89.84%] [G loss: 2.729710]\n",
      "epoch:2 step:2076 [D loss: 0.596306, acc: 68.75%] [G loss: 2.384115]\n",
      "epoch:2 step:2077 [D loss: 1.022873, acc: 33.59%] [G loss: 2.004303]\n",
      "epoch:2 step:2078 [D loss: 0.858140, acc: 46.88%] [G loss: 2.393602]\n",
      "epoch:2 step:2079 [D loss: 0.610252, acc: 70.31%] [G loss: 2.441218]\n",
      "epoch:2 step:2080 [D loss: 0.743059, acc: 56.25%] [G loss: 2.593491]\n",
      "epoch:2 step:2081 [D loss: 0.443815, acc: 85.94%] [G loss: 2.517041]\n",
      "epoch:2 step:2082 [D loss: 0.420561, acc: 85.16%] [G loss: 2.637517]\n",
      "epoch:2 step:2083 [D loss: 0.458501, acc: 78.91%] [G loss: 2.392587]\n",
      "epoch:2 step:2084 [D loss: 0.616851, acc: 67.97%] [G loss: 2.192033]\n",
      "epoch:2 step:2085 [D loss: 0.530105, acc: 69.53%] [G loss: 1.776651]\n",
      "epoch:2 step:2086 [D loss: 0.609163, acc: 65.62%] [G loss: 2.390959]\n",
      "epoch:2 step:2087 [D loss: 0.456257, acc: 83.59%] [G loss: 1.838413]\n",
      "epoch:2 step:2088 [D loss: 0.256190, acc: 96.09%] [G loss: 2.324213]\n",
      "epoch:2 step:2089 [D loss: 0.357521, acc: 89.84%] [G loss: 2.222506]\n",
      "epoch:2 step:2090 [D loss: 0.408783, acc: 86.72%] [G loss: 1.716892]\n",
      "epoch:2 step:2091 [D loss: 0.442128, acc: 83.59%] [G loss: 1.656630]\n",
      "epoch:2 step:2092 [D loss: 0.439003, acc: 83.59%] [G loss: 1.952382]\n",
      "epoch:2 step:2093 [D loss: 0.518913, acc: 75.78%] [G loss: 1.343024]\n",
      "epoch:2 step:2094 [D loss: 0.349622, acc: 89.06%] [G loss: 1.805492]\n",
      "epoch:2 step:2095 [D loss: 0.336971, acc: 89.84%] [G loss: 1.894897]\n",
      "epoch:2 step:2096 [D loss: 0.548084, acc: 73.44%] [G loss: 1.888151]\n",
      "epoch:2 step:2097 [D loss: 1.052702, acc: 30.47%] [G loss: 1.463249]\n",
      "epoch:2 step:2098 [D loss: 0.623213, acc: 68.75%] [G loss: 1.745302]\n",
      "epoch:2 step:2099 [D loss: 0.415952, acc: 85.94%] [G loss: 2.415795]\n",
      "epoch:2 step:2100 [D loss: 1.171982, acc: 16.41%] [G loss: 2.711983]\n",
      "epoch:2 step:2101 [D loss: 0.702138, acc: 58.59%] [G loss: 3.050744]\n",
      "epoch:2 step:2102 [D loss: 0.463810, acc: 78.12%] [G loss: 3.170142]\n",
      "epoch:2 step:2103 [D loss: 0.528558, acc: 76.56%] [G loss: 2.579851]\n",
      "epoch:2 step:2104 [D loss: 0.591854, acc: 65.62%] [G loss: 2.307810]\n",
      "epoch:2 step:2105 [D loss: 0.539951, acc: 77.34%] [G loss: 1.707962]\n",
      "epoch:2 step:2106 [D loss: 0.750095, acc: 49.22%] [G loss: 1.522773]\n",
      "epoch:2 step:2107 [D loss: 0.572417, acc: 75.00%] [G loss: 1.488080]\n",
      "epoch:2 step:2108 [D loss: 1.000904, acc: 32.03%] [G loss: 1.702081]\n",
      "epoch:2 step:2109 [D loss: 1.021225, acc: 31.25%] [G loss: 1.406171]\n",
      "epoch:2 step:2110 [D loss: 0.744818, acc: 54.69%] [G loss: 1.578568]\n",
      "epoch:2 step:2111 [D loss: 0.728372, acc: 60.16%] [G loss: 1.843554]\n",
      "epoch:2 step:2112 [D loss: 0.956908, acc: 35.94%] [G loss: 1.780309]\n",
      "epoch:2 step:2113 [D loss: 0.813611, acc: 46.09%] [G loss: 1.734200]\n",
      "epoch:2 step:2114 [D loss: 0.881045, acc: 43.75%] [G loss: 1.561455]\n",
      "epoch:2 step:2115 [D loss: 0.826689, acc: 46.88%] [G loss: 1.970276]\n",
      "epoch:2 step:2116 [D loss: 0.495451, acc: 82.03%] [G loss: 2.201136]\n",
      "epoch:2 step:2117 [D loss: 0.465137, acc: 79.69%] [G loss: 2.487339]\n",
      "epoch:2 step:2118 [D loss: 0.690550, acc: 58.59%] [G loss: 2.615530]\n",
      "epoch:2 step:2119 [D loss: 0.676287, acc: 58.59%] [G loss: 2.173549]\n",
      "epoch:2 step:2120 [D loss: 0.513837, acc: 75.78%] [G loss: 2.077431]\n",
      "epoch:2 step:2121 [D loss: 0.756486, acc: 50.78%] [G loss: 2.007572]\n",
      "epoch:2 step:2122 [D loss: 0.594228, acc: 70.31%] [G loss: 1.887048]\n",
      "epoch:2 step:2123 [D loss: 0.530094, acc: 76.56%] [G loss: 2.224891]\n",
      "epoch:2 step:2124 [D loss: 0.880673, acc: 43.75%] [G loss: 1.789689]\n",
      "epoch:2 step:2125 [D loss: 1.049984, acc: 29.69%] [G loss: 1.320255]\n",
      "epoch:2 step:2126 [D loss: 0.720407, acc: 55.47%] [G loss: 1.847464]\n",
      "epoch:2 step:2127 [D loss: 0.743627, acc: 53.12%] [G loss: 2.236328]\n",
      "epoch:2 step:2128 [D loss: 0.676291, acc: 63.28%] [G loss: 1.922271]\n",
      "epoch:2 step:2129 [D loss: 0.470698, acc: 78.91%] [G loss: 2.381561]\n",
      "epoch:2 step:2130 [D loss: 0.696284, acc: 60.94%] [G loss: 1.872038]\n",
      "epoch:2 step:2131 [D loss: 0.935871, acc: 41.41%] [G loss: 1.394720]\n",
      "epoch:2 step:2132 [D loss: 0.855964, acc: 38.28%] [G loss: 1.977215]\n",
      "epoch:2 step:2133 [D loss: 0.703828, acc: 54.69%] [G loss: 1.731607]\n",
      "epoch:2 step:2134 [D loss: 0.784865, acc: 53.91%] [G loss: 1.747501]\n",
      "epoch:2 step:2135 [D loss: 0.560745, acc: 75.00%] [G loss: 2.300750]\n",
      "epoch:2 step:2136 [D loss: 0.702403, acc: 58.59%] [G loss: 1.990639]\n",
      "epoch:2 step:2137 [D loss: 0.792846, acc: 51.56%] [G loss: 2.459869]\n",
      "epoch:2 step:2138 [D loss: 0.779039, acc: 56.25%] [G loss: 1.881896]\n",
      "epoch:2 step:2139 [D loss: 0.665458, acc: 59.38%] [G loss: 2.129213]\n",
      "epoch:2 step:2140 [D loss: 0.497878, acc: 78.91%] [G loss: 2.017204]\n",
      "epoch:2 step:2141 [D loss: 0.789627, acc: 45.31%] [G loss: 1.769107]\n",
      "epoch:2 step:2142 [D loss: 0.696053, acc: 57.03%] [G loss: 1.543087]\n",
      "epoch:2 step:2143 [D loss: 0.681400, acc: 56.25%] [G loss: 1.852869]\n",
      "epoch:2 step:2144 [D loss: 0.583667, acc: 60.94%] [G loss: 1.706731]\n",
      "epoch:2 step:2145 [D loss: 0.521631, acc: 77.34%] [G loss: 1.865161]\n",
      "epoch:2 step:2146 [D loss: 0.367988, acc: 92.19%] [G loss: 2.069993]\n",
      "epoch:2 step:2147 [D loss: 0.820721, acc: 51.56%] [G loss: 1.674673]\n",
      "epoch:2 step:2148 [D loss: 0.780337, acc: 43.75%] [G loss: 1.475347]\n",
      "epoch:2 step:2149 [D loss: 0.444280, acc: 82.81%] [G loss: 1.931320]\n",
      "epoch:2 step:2150 [D loss: 0.565905, acc: 69.53%] [G loss: 1.669716]\n",
      "epoch:2 step:2151 [D loss: 0.652453, acc: 65.62%] [G loss: 2.189544]\n",
      "epoch:2 step:2152 [D loss: 0.739804, acc: 57.03%] [G loss: 2.087903]\n",
      "epoch:2 step:2153 [D loss: 0.740991, acc: 52.34%] [G loss: 1.472763]\n",
      "epoch:2 step:2154 [D loss: 0.479466, acc: 73.44%] [G loss: 1.728146]\n",
      "epoch:2 step:2155 [D loss: 1.316837, acc: 17.19%] [G loss: 1.357815]\n",
      "epoch:2 step:2156 [D loss: 0.793377, acc: 54.69%] [G loss: 1.879107]\n",
      "epoch:2 step:2157 [D loss: 0.969700, acc: 28.12%] [G loss: 1.658664]\n",
      "epoch:2 step:2158 [D loss: 0.800501, acc: 54.69%] [G loss: 1.977377]\n",
      "epoch:2 step:2159 [D loss: 0.958570, acc: 44.53%] [G loss: 2.509408]\n",
      "epoch:2 step:2160 [D loss: 0.473308, acc: 78.91%] [G loss: 3.058511]\n",
      "epoch:2 step:2161 [D loss: 0.525161, acc: 78.91%] [G loss: 1.941383]\n",
      "epoch:2 step:2162 [D loss: 0.529311, acc: 68.75%] [G loss: 2.910809]\n",
      "epoch:2 step:2163 [D loss: 0.709452, acc: 60.16%] [G loss: 2.128704]\n",
      "epoch:2 step:2164 [D loss: 0.623179, acc: 67.19%] [G loss: 2.210463]\n",
      "epoch:2 step:2165 [D loss: 0.689978, acc: 60.16%] [G loss: 2.036460]\n",
      "epoch:2 step:2166 [D loss: 1.101418, acc: 31.25%] [G loss: 1.626127]\n",
      "epoch:2 step:2167 [D loss: 0.762737, acc: 46.88%] [G loss: 1.914470]\n",
      "epoch:2 step:2168 [D loss: 0.646559, acc: 59.38%] [G loss: 2.297902]\n",
      "epoch:2 step:2169 [D loss: 0.841055, acc: 46.88%] [G loss: 1.846876]\n",
      "epoch:2 step:2170 [D loss: 0.765436, acc: 53.12%] [G loss: 1.850422]\n",
      "epoch:2 step:2171 [D loss: 0.756275, acc: 50.78%] [G loss: 1.851012]\n",
      "epoch:2 step:2172 [D loss: 0.662107, acc: 61.72%] [G loss: 1.413890]\n",
      "epoch:2 step:2173 [D loss: 0.522597, acc: 78.91%] [G loss: 1.844240]\n",
      "epoch:2 step:2174 [D loss: 0.567172, acc: 67.19%] [G loss: 1.415245]\n",
      "epoch:2 step:2175 [D loss: 0.583060, acc: 65.62%] [G loss: 2.078810]\n",
      "epoch:2 step:2176 [D loss: 0.644494, acc: 67.19%] [G loss: 1.372074]\n",
      "epoch:2 step:2177 [D loss: 0.724991, acc: 57.81%] [G loss: 1.666891]\n",
      "epoch:2 step:2178 [D loss: 0.763554, acc: 52.34%] [G loss: 1.715769]\n",
      "epoch:2 step:2179 [D loss: 0.977029, acc: 29.69%] [G loss: 1.559196]\n",
      "epoch:2 step:2180 [D loss: 0.389072, acc: 89.06%] [G loss: 2.272395]\n",
      "epoch:2 step:2181 [D loss: 0.630405, acc: 62.50%] [G loss: 1.989066]\n",
      "epoch:2 step:2182 [D loss: 0.647052, acc: 64.84%] [G loss: 2.667500]\n",
      "epoch:2 step:2183 [D loss: 0.477867, acc: 79.69%] [G loss: 2.692801]\n",
      "epoch:2 step:2184 [D loss: 0.293438, acc: 95.31%] [G loss: 3.216806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2185 [D loss: 0.630251, acc: 64.06%] [G loss: 2.589525]\n",
      "epoch:2 step:2186 [D loss: 0.505374, acc: 76.56%] [G loss: 2.222529]\n",
      "epoch:2 step:2187 [D loss: 0.676007, acc: 60.16%] [G loss: 2.630470]\n",
      "epoch:2 step:2188 [D loss: 0.723171, acc: 54.69%] [G loss: 2.033201]\n",
      "epoch:2 step:2189 [D loss: 0.858257, acc: 45.31%] [G loss: 1.605727]\n",
      "epoch:2 step:2190 [D loss: 0.634603, acc: 69.53%] [G loss: 2.058457]\n",
      "epoch:2 step:2191 [D loss: 0.615985, acc: 67.19%] [G loss: 2.414373]\n",
      "epoch:2 step:2192 [D loss: 0.794988, acc: 51.56%] [G loss: 1.909026]\n",
      "epoch:2 step:2193 [D loss: 0.577575, acc: 68.75%] [G loss: 2.261580]\n",
      "epoch:2 step:2194 [D loss: 0.912059, acc: 30.47%] [G loss: 1.385242]\n",
      "epoch:2 step:2195 [D loss: 0.620067, acc: 67.97%] [G loss: 2.297523]\n",
      "epoch:2 step:2196 [D loss: 0.655151, acc: 56.25%] [G loss: 1.749015]\n",
      "epoch:2 step:2197 [D loss: 0.711611, acc: 53.12%] [G loss: 1.687576]\n",
      "epoch:2 step:2198 [D loss: 0.968479, acc: 32.03%] [G loss: 1.633366]\n",
      "epoch:2 step:2199 [D loss: 0.907714, acc: 28.91%] [G loss: 1.919401]\n",
      "epoch:2 step:2200 [D loss: 0.629250, acc: 66.41%] [G loss: 1.788354]\n",
      "epoch:2 step:2201 [D loss: 0.771399, acc: 46.09%] [G loss: 1.778030]\n",
      "epoch:2 step:2202 [D loss: 0.799770, acc: 48.44%] [G loss: 1.609266]\n",
      "epoch:2 step:2203 [D loss: 0.600588, acc: 68.75%] [G loss: 1.831677]\n",
      "epoch:2 step:2204 [D loss: 0.623959, acc: 68.75%] [G loss: 1.904386]\n",
      "epoch:2 step:2205 [D loss: 0.587010, acc: 65.62%] [G loss: 1.748672]\n",
      "epoch:2 step:2206 [D loss: 0.576054, acc: 71.09%] [G loss: 1.981194]\n",
      "epoch:2 step:2207 [D loss: 0.873861, acc: 46.88%] [G loss: 1.323689]\n",
      "epoch:2 step:2208 [D loss: 0.821359, acc: 40.62%] [G loss: 1.784588]\n",
      "epoch:2 step:2209 [D loss: 0.799199, acc: 46.09%] [G loss: 1.886531]\n",
      "epoch:2 step:2210 [D loss: 0.828636, acc: 43.75%] [G loss: 1.472748]\n",
      "epoch:2 step:2211 [D loss: 0.981529, acc: 28.91%] [G loss: 1.522066]\n",
      "epoch:2 step:2212 [D loss: 0.628874, acc: 62.50%] [G loss: 1.479123]\n",
      "epoch:2 step:2213 [D loss: 0.696948, acc: 53.12%] [G loss: 1.772209]\n",
      "epoch:2 step:2214 [D loss: 0.811427, acc: 52.34%] [G loss: 1.579639]\n",
      "epoch:2 step:2215 [D loss: 0.729364, acc: 49.22%] [G loss: 1.636253]\n",
      "epoch:2 step:2216 [D loss: 0.699286, acc: 57.81%] [G loss: 1.794586]\n",
      "epoch:2 step:2217 [D loss: 0.678301, acc: 57.81%] [G loss: 1.913753]\n",
      "epoch:2 step:2218 [D loss: 1.192798, acc: 21.09%] [G loss: 1.498093]\n",
      "epoch:2 step:2219 [D loss: 0.613019, acc: 64.84%] [G loss: 2.033948]\n",
      "epoch:2 step:2220 [D loss: 0.463491, acc: 83.59%] [G loss: 2.076845]\n",
      "epoch:2 step:2221 [D loss: 0.701482, acc: 59.38%] [G loss: 1.758169]\n",
      "epoch:2 step:2222 [D loss: 0.913709, acc: 35.16%] [G loss: 1.477604]\n",
      "epoch:2 step:2223 [D loss: 0.651579, acc: 59.38%] [G loss: 1.949301]\n",
      "epoch:2 step:2224 [D loss: 0.730502, acc: 56.25%] [G loss: 1.850763]\n",
      "epoch:2 step:2225 [D loss: 0.677209, acc: 59.38%] [G loss: 1.809625]\n",
      "epoch:2 step:2226 [D loss: 0.830203, acc: 42.97%] [G loss: 1.523001]\n",
      "epoch:2 step:2227 [D loss: 0.620067, acc: 71.88%] [G loss: 1.943106]\n",
      "epoch:2 step:2228 [D loss: 0.606078, acc: 70.31%] [G loss: 1.947168]\n",
      "epoch:2 step:2229 [D loss: 0.731031, acc: 52.34%] [G loss: 1.953057]\n",
      "epoch:2 step:2230 [D loss: 0.793525, acc: 44.53%] [G loss: 1.653822]\n",
      "epoch:2 step:2231 [D loss: 0.714002, acc: 53.91%] [G loss: 1.922575]\n",
      "epoch:2 step:2232 [D loss: 0.914800, acc: 31.25%] [G loss: 1.435986]\n",
      "epoch:2 step:2233 [D loss: 0.980538, acc: 28.91%] [G loss: 2.056574]\n",
      "epoch:2 step:2234 [D loss: 0.673955, acc: 62.50%] [G loss: 1.739640]\n",
      "epoch:2 step:2235 [D loss: 0.536728, acc: 78.91%] [G loss: 2.063100]\n",
      "epoch:2 step:2236 [D loss: 0.484331, acc: 86.72%] [G loss: 2.012635]\n",
      "epoch:2 step:2237 [D loss: 0.705514, acc: 57.81%] [G loss: 2.020533]\n",
      "epoch:2 step:2238 [D loss: 0.867627, acc: 32.81%] [G loss: 1.585169]\n",
      "epoch:2 step:2239 [D loss: 0.493736, acc: 83.59%] [G loss: 1.916866]\n",
      "epoch:2 step:2240 [D loss: 0.624356, acc: 66.41%] [G loss: 1.554505]\n",
      "epoch:2 step:2241 [D loss: 0.686780, acc: 58.59%] [G loss: 1.785776]\n",
      "epoch:2 step:2242 [D loss: 0.560062, acc: 61.72%] [G loss: 1.534604]\n",
      "epoch:2 step:2243 [D loss: 0.586468, acc: 65.62%] [G loss: 2.007476]\n",
      "epoch:2 step:2244 [D loss: 0.594764, acc: 67.97%] [G loss: 1.992863]\n",
      "epoch:2 step:2245 [D loss: 0.368427, acc: 85.16%] [G loss: 1.937367]\n",
      "epoch:2 step:2246 [D loss: 0.528509, acc: 72.66%] [G loss: 1.457915]\n",
      "epoch:2 step:2247 [D loss: 0.910818, acc: 35.16%] [G loss: 1.442805]\n",
      "epoch:2 step:2248 [D loss: 0.895845, acc: 39.06%] [G loss: 1.820148]\n",
      "epoch:2 step:2249 [D loss: 0.590369, acc: 64.84%] [G loss: 1.912515]\n",
      "epoch:2 step:2250 [D loss: 0.742933, acc: 58.59%] [G loss: 2.027738]\n",
      "epoch:2 step:2251 [D loss: 0.763589, acc: 53.12%] [G loss: 1.865731]\n",
      "epoch:2 step:2252 [D loss: 0.650462, acc: 62.50%] [G loss: 2.238453]\n",
      "epoch:2 step:2253 [D loss: 0.565158, acc: 72.66%] [G loss: 2.215621]\n",
      "epoch:2 step:2254 [D loss: 1.125911, acc: 11.72%] [G loss: 2.040142]\n",
      "epoch:2 step:2255 [D loss: 0.450118, acc: 84.38%] [G loss: 2.408934]\n",
      "epoch:2 step:2256 [D loss: 0.280571, acc: 96.88%] [G loss: 2.468081]\n",
      "epoch:2 step:2257 [D loss: 0.781618, acc: 48.44%] [G loss: 1.820552]\n",
      "epoch:2 step:2258 [D loss: 0.854430, acc: 39.06%] [G loss: 1.809330]\n",
      "epoch:2 step:2259 [D loss: 0.876782, acc: 40.62%] [G loss: 1.522376]\n",
      "epoch:2 step:2260 [D loss: 0.564552, acc: 75.78%] [G loss: 2.068954]\n",
      "epoch:2 step:2261 [D loss: 0.851085, acc: 41.41%] [G loss: 1.722786]\n",
      "epoch:2 step:2262 [D loss: 0.661042, acc: 66.41%] [G loss: 1.606608]\n",
      "epoch:2 step:2263 [D loss: 0.621329, acc: 62.50%] [G loss: 1.608546]\n",
      "epoch:2 step:2264 [D loss: 0.409400, acc: 89.84%] [G loss: 2.374341]\n",
      "epoch:2 step:2265 [D loss: 0.339924, acc: 91.41%] [G loss: 2.421838]\n",
      "epoch:2 step:2266 [D loss: 1.016344, acc: 46.09%] [G loss: 2.218613]\n",
      "epoch:2 step:2267 [D loss: 0.450153, acc: 85.16%] [G loss: 2.090505]\n",
      "epoch:2 step:2268 [D loss: 0.990166, acc: 29.69%] [G loss: 1.843083]\n",
      "epoch:2 step:2269 [D loss: 0.845752, acc: 44.53%] [G loss: 1.749148]\n",
      "epoch:2 step:2270 [D loss: 0.667130, acc: 57.03%] [G loss: 1.976647]\n",
      "epoch:2 step:2271 [D loss: 0.774893, acc: 45.31%] [G loss: 2.038926]\n",
      "epoch:2 step:2272 [D loss: 0.549981, acc: 75.00%] [G loss: 2.267865]\n",
      "epoch:2 step:2273 [D loss: 0.596118, acc: 64.84%] [G loss: 1.991244]\n",
      "epoch:2 step:2274 [D loss: 0.693040, acc: 60.16%] [G loss: 2.048732]\n",
      "epoch:2 step:2275 [D loss: 0.624735, acc: 66.41%] [G loss: 2.057528]\n",
      "epoch:2 step:2276 [D loss: 0.764568, acc: 52.34%] [G loss: 1.796200]\n",
      "epoch:2 step:2277 [D loss: 0.552882, acc: 75.78%] [G loss: 2.223798]\n",
      "epoch:2 step:2278 [D loss: 0.720766, acc: 59.38%] [G loss: 1.800680]\n",
      "epoch:2 step:2279 [D loss: 0.453653, acc: 75.00%] [G loss: 2.156932]\n",
      "epoch:2 step:2280 [D loss: 0.688226, acc: 53.12%] [G loss: 1.867802]\n",
      "epoch:2 step:2281 [D loss: 0.631548, acc: 67.19%] [G loss: 2.026003]\n",
      "epoch:2 step:2282 [D loss: 0.737448, acc: 50.78%] [G loss: 1.798413]\n",
      "epoch:2 step:2283 [D loss: 0.580299, acc: 64.06%] [G loss: 1.766091]\n",
      "epoch:2 step:2284 [D loss: 0.719698, acc: 57.81%] [G loss: 2.013731]\n",
      "epoch:2 step:2285 [D loss: 0.642286, acc: 64.84%] [G loss: 2.552580]\n",
      "epoch:2 step:2286 [D loss: 0.693046, acc: 63.28%] [G loss: 2.225138]\n",
      "epoch:2 step:2287 [D loss: 0.901220, acc: 35.94%] [G loss: 1.804606]\n",
      "epoch:2 step:2288 [D loss: 0.677199, acc: 57.81%] [G loss: 2.261101]\n",
      "epoch:2 step:2289 [D loss: 0.830417, acc: 39.84%] [G loss: 1.957061]\n",
      "epoch:2 step:2290 [D loss: 0.288081, acc: 94.53%] [G loss: 2.390764]\n",
      "epoch:2 step:2291 [D loss: 0.514512, acc: 81.25%] [G loss: 2.276423]\n",
      "epoch:2 step:2292 [D loss: 0.679174, acc: 53.91%] [G loss: 2.049820]\n",
      "epoch:2 step:2293 [D loss: 0.472303, acc: 78.91%] [G loss: 2.294389]\n",
      "epoch:2 step:2294 [D loss: 0.426515, acc: 85.94%] [G loss: 2.468010]\n",
      "epoch:2 step:2295 [D loss: 0.682531, acc: 57.81%] [G loss: 2.013664]\n",
      "epoch:2 step:2296 [D loss: 0.564160, acc: 71.88%] [G loss: 2.141519]\n",
      "epoch:2 step:2297 [D loss: 0.932877, acc: 35.16%] [G loss: 1.490340]\n",
      "epoch:2 step:2298 [D loss: 0.595926, acc: 67.19%] [G loss: 1.948645]\n",
      "epoch:2 step:2299 [D loss: 0.457120, acc: 82.03%] [G loss: 1.961594]\n",
      "epoch:2 step:2300 [D loss: 0.667441, acc: 61.72%] [G loss: 1.877915]\n",
      "epoch:2 step:2301 [D loss: 0.700624, acc: 56.25%] [G loss: 1.717414]\n",
      "epoch:2 step:2302 [D loss: 0.657924, acc: 60.94%] [G loss: 1.966497]\n",
      "epoch:2 step:2303 [D loss: 0.723592, acc: 53.12%] [G loss: 1.596937]\n",
      "epoch:2 step:2304 [D loss: 0.741842, acc: 50.00%] [G loss: 1.869799]\n",
      "epoch:2 step:2305 [D loss: 0.741642, acc: 51.56%] [G loss: 1.754431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2306 [D loss: 1.071771, acc: 25.00%] [G loss: 1.478619]\n",
      "epoch:2 step:2307 [D loss: 0.665595, acc: 57.03%] [G loss: 1.869963]\n",
      "epoch:2 step:2308 [D loss: 0.528049, acc: 78.12%] [G loss: 2.020853]\n",
      "epoch:2 step:2309 [D loss: 0.930490, acc: 34.38%] [G loss: 1.553026]\n",
      "epoch:2 step:2310 [D loss: 0.781470, acc: 48.44%] [G loss: 1.669765]\n",
      "epoch:2 step:2311 [D loss: 0.564780, acc: 74.22%] [G loss: 1.691526]\n",
      "epoch:2 step:2312 [D loss: 0.695191, acc: 53.12%] [G loss: 1.582697]\n",
      "epoch:2 step:2313 [D loss: 0.987478, acc: 37.50%] [G loss: 1.424683]\n",
      "epoch:2 step:2314 [D loss: 0.608403, acc: 68.75%] [G loss: 1.789729]\n",
      "epoch:2 step:2315 [D loss: 0.637470, acc: 57.03%] [G loss: 2.249135]\n",
      "epoch:2 step:2316 [D loss: 0.484352, acc: 78.91%] [G loss: 1.655927]\n",
      "epoch:2 step:2317 [D loss: 0.697675, acc: 57.81%] [G loss: 2.095035]\n",
      "epoch:2 step:2318 [D loss: 0.780870, acc: 45.31%] [G loss: 1.599085]\n",
      "epoch:2 step:2319 [D loss: 0.707217, acc: 55.47%] [G loss: 1.889396]\n",
      "epoch:2 step:2320 [D loss: 0.790154, acc: 49.22%] [G loss: 1.996529]\n",
      "epoch:2 step:2321 [D loss: 0.610232, acc: 62.50%] [G loss: 2.169776]\n",
      "epoch:2 step:2322 [D loss: 0.780543, acc: 43.75%] [G loss: 1.637957]\n",
      "epoch:2 step:2323 [D loss: 0.593899, acc: 67.97%] [G loss: 1.721827]\n",
      "epoch:2 step:2324 [D loss: 0.773322, acc: 42.19%] [G loss: 1.443397]\n",
      "epoch:2 step:2325 [D loss: 0.963018, acc: 25.78%] [G loss: 1.775084]\n",
      "epoch:2 step:2326 [D loss: 0.590043, acc: 67.19%] [G loss: 1.458557]\n",
      "epoch:2 step:2327 [D loss: 0.783264, acc: 46.09%] [G loss: 1.637811]\n",
      "epoch:2 step:2328 [D loss: 0.540013, acc: 75.78%] [G loss: 1.695782]\n",
      "epoch:2 step:2329 [D loss: 0.607575, acc: 72.66%] [G loss: 1.804998]\n",
      "epoch:2 step:2330 [D loss: 0.794972, acc: 46.09%] [G loss: 1.671992]\n",
      "epoch:2 step:2331 [D loss: 0.569035, acc: 73.44%] [G loss: 1.704019]\n",
      "epoch:2 step:2332 [D loss: 0.547461, acc: 76.56%] [G loss: 1.514084]\n",
      "epoch:2 step:2333 [D loss: 1.209867, acc: 23.44%] [G loss: 1.103822]\n",
      "epoch:2 step:2334 [D loss: 0.460066, acc: 80.47%] [G loss: 1.644788]\n",
      "epoch:2 step:2335 [D loss: 0.902633, acc: 44.53%] [G loss: 1.745108]\n",
      "epoch:2 step:2336 [D loss: 0.867800, acc: 41.41%] [G loss: 2.090618]\n",
      "epoch:2 step:2337 [D loss: 0.522566, acc: 72.66%] [G loss: 2.151804]\n",
      "epoch:2 step:2338 [D loss: 0.739056, acc: 60.16%] [G loss: 2.234931]\n",
      "epoch:2 step:2339 [D loss: 0.557140, acc: 73.44%] [G loss: 1.932107]\n",
      "epoch:2 step:2340 [D loss: 0.830037, acc: 48.44%] [G loss: 1.435456]\n",
      "epoch:2 step:2341 [D loss: 0.778181, acc: 53.91%] [G loss: 1.807974]\n",
      "epoch:2 step:2342 [D loss: 0.927527, acc: 36.72%] [G loss: 1.655660]\n",
      "epoch:2 step:2343 [D loss: 1.043289, acc: 23.44%] [G loss: 1.629182]\n",
      "epoch:3 step:2344 [D loss: 0.939798, acc: 42.97%] [G loss: 1.981687]\n",
      "epoch:3 step:2345 [D loss: 0.609541, acc: 70.31%] [G loss: 1.820593]\n",
      "epoch:3 step:2346 [D loss: 0.602565, acc: 69.53%] [G loss: 1.651521]\n",
      "epoch:3 step:2347 [D loss: 0.578170, acc: 68.75%] [G loss: 2.256081]\n",
      "epoch:3 step:2348 [D loss: 0.654176, acc: 63.28%] [G loss: 1.967385]\n",
      "epoch:3 step:2349 [D loss: 0.703124, acc: 57.03%] [G loss: 1.923300]\n",
      "epoch:3 step:2350 [D loss: 0.599073, acc: 66.41%] [G loss: 1.932931]\n",
      "epoch:3 step:2351 [D loss: 0.790652, acc: 49.22%] [G loss: 1.761948]\n",
      "epoch:3 step:2352 [D loss: 0.584445, acc: 74.22%] [G loss: 1.932457]\n",
      "epoch:3 step:2353 [D loss: 0.798747, acc: 45.31%] [G loss: 1.933444]\n",
      "epoch:3 step:2354 [D loss: 0.592670, acc: 66.41%] [G loss: 1.777293]\n",
      "epoch:3 step:2355 [D loss: 0.505830, acc: 74.22%] [G loss: 2.058429]\n",
      "epoch:3 step:2356 [D loss: 0.649863, acc: 61.72%] [G loss: 2.086205]\n",
      "epoch:3 step:2357 [D loss: 0.634113, acc: 60.94%] [G loss: 2.017311]\n",
      "epoch:3 step:2358 [D loss: 0.766254, acc: 48.44%] [G loss: 1.942477]\n",
      "epoch:3 step:2359 [D loss: 0.462017, acc: 82.81%] [G loss: 2.509217]\n",
      "epoch:3 step:2360 [D loss: 0.664908, acc: 60.94%] [G loss: 2.201655]\n",
      "epoch:3 step:2361 [D loss: 0.821910, acc: 44.53%] [G loss: 1.607675]\n",
      "epoch:3 step:2362 [D loss: 0.745960, acc: 56.25%] [G loss: 1.651355]\n",
      "epoch:3 step:2363 [D loss: 0.887858, acc: 39.84%] [G loss: 1.407760]\n",
      "epoch:3 step:2364 [D loss: 0.798862, acc: 44.53%] [G loss: 1.554690]\n",
      "epoch:3 step:2365 [D loss: 0.919684, acc: 32.81%] [G loss: 1.577784]\n",
      "epoch:3 step:2366 [D loss: 0.782875, acc: 46.09%] [G loss: 1.653303]\n",
      "epoch:3 step:2367 [D loss: 0.885502, acc: 31.25%] [G loss: 1.392647]\n",
      "epoch:3 step:2368 [D loss: 0.715901, acc: 55.47%] [G loss: 1.770943]\n",
      "epoch:3 step:2369 [D loss: 0.671451, acc: 65.62%] [G loss: 1.667342]\n",
      "epoch:3 step:2370 [D loss: 0.735431, acc: 46.88%] [G loss: 1.936459]\n",
      "epoch:3 step:2371 [D loss: 0.707637, acc: 53.91%] [G loss: 2.042253]\n",
      "epoch:3 step:2372 [D loss: 0.578254, acc: 71.09%] [G loss: 1.901049]\n",
      "epoch:3 step:2373 [D loss: 0.450804, acc: 85.94%] [G loss: 2.155453]\n",
      "epoch:3 step:2374 [D loss: 0.611735, acc: 64.84%] [G loss: 1.944603]\n",
      "epoch:3 step:2375 [D loss: 0.750222, acc: 46.88%] [G loss: 1.735598]\n",
      "epoch:3 step:2376 [D loss: 0.768612, acc: 47.66%] [G loss: 1.961392]\n",
      "epoch:3 step:2377 [D loss: 0.590556, acc: 71.09%] [G loss: 2.173536]\n",
      "epoch:3 step:2378 [D loss: 0.541667, acc: 71.09%] [G loss: 2.142848]\n",
      "epoch:3 step:2379 [D loss: 0.760608, acc: 52.34%] [G loss: 1.974447]\n",
      "epoch:3 step:2380 [D loss: 0.615680, acc: 66.41%] [G loss: 2.050832]\n",
      "epoch:3 step:2381 [D loss: 0.577233, acc: 70.31%] [G loss: 1.978155]\n",
      "epoch:3 step:2382 [D loss: 0.715714, acc: 53.12%] [G loss: 2.034774]\n",
      "epoch:3 step:2383 [D loss: 0.587777, acc: 76.56%] [G loss: 1.893213]\n",
      "epoch:3 step:2384 [D loss: 0.672941, acc: 60.16%] [G loss: 1.653128]\n",
      "epoch:3 step:2385 [D loss: 0.586035, acc: 70.31%] [G loss: 1.901102]\n",
      "epoch:3 step:2386 [D loss: 0.481105, acc: 82.03%] [G loss: 1.884967]\n",
      "epoch:3 step:2387 [D loss: 0.576098, acc: 67.97%] [G loss: 1.598283]\n",
      "epoch:3 step:2388 [D loss: 0.483041, acc: 75.78%] [G loss: 2.099933]\n",
      "epoch:3 step:2389 [D loss: 0.437497, acc: 82.81%] [G loss: 2.054786]\n",
      "epoch:3 step:2390 [D loss: 0.687398, acc: 64.06%] [G loss: 1.814187]\n",
      "epoch:3 step:2391 [D loss: 0.796673, acc: 47.66%] [G loss: 1.487579]\n",
      "epoch:3 step:2392 [D loss: 0.572338, acc: 69.53%] [G loss: 1.506661]\n",
      "epoch:3 step:2393 [D loss: 0.413367, acc: 82.03%] [G loss: 1.574593]\n",
      "epoch:3 step:2394 [D loss: 0.414710, acc: 82.03%] [G loss: 1.736238]\n",
      "epoch:3 step:2395 [D loss: 0.461040, acc: 81.25%] [G loss: 1.761242]\n",
      "epoch:3 step:2396 [D loss: 0.521029, acc: 78.91%] [G loss: 1.360515]\n",
      "epoch:3 step:2397 [D loss: 0.600199, acc: 69.53%] [G loss: 1.501240]\n",
      "epoch:3 step:2398 [D loss: 1.018337, acc: 34.38%] [G loss: 1.205367]\n",
      "epoch:3 step:2399 [D loss: 1.051800, acc: 30.47%] [G loss: 1.267701]\n",
      "epoch:3 step:2400 [D loss: 0.932546, acc: 38.28%] [G loss: 1.235258]\n",
      "epoch:3 step:2401 [D loss: 0.785631, acc: 47.66%] [G loss: 1.152358]\n",
      "epoch:3 step:2402 [D loss: 0.892179, acc: 39.06%] [G loss: 1.416885]\n",
      "epoch:3 step:2403 [D loss: 0.809734, acc: 50.00%] [G loss: 1.460007]\n",
      "epoch:3 step:2404 [D loss: 0.685913, acc: 57.03%] [G loss: 1.389331]\n",
      "epoch:3 step:2405 [D loss: 0.644147, acc: 63.28%] [G loss: 1.313526]\n",
      "epoch:3 step:2406 [D loss: 0.798701, acc: 50.78%] [G loss: 1.563203]\n",
      "epoch:3 step:2407 [D loss: 0.449234, acc: 78.91%] [G loss: 1.512080]\n",
      "epoch:3 step:2408 [D loss: 0.684009, acc: 61.72%] [G loss: 1.843197]\n",
      "epoch:3 step:2409 [D loss: 0.919860, acc: 38.28%] [G loss: 1.790609]\n",
      "epoch:3 step:2410 [D loss: 1.333995, acc: 29.69%] [G loss: 1.589489]\n",
      "epoch:3 step:2411 [D loss: 0.591280, acc: 70.31%] [G loss: 1.969823]\n",
      "epoch:3 step:2412 [D loss: 0.676304, acc: 53.12%] [G loss: 1.787028]\n",
      "epoch:3 step:2413 [D loss: 0.860587, acc: 43.75%] [G loss: 1.487188]\n",
      "epoch:3 step:2414 [D loss: 0.699752, acc: 57.81%] [G loss: 1.666139]\n",
      "epoch:3 step:2415 [D loss: 1.038112, acc: 27.34%] [G loss: 1.370319]\n",
      "epoch:3 step:2416 [D loss: 0.661058, acc: 59.38%] [G loss: 1.483628]\n",
      "epoch:3 step:2417 [D loss: 0.762254, acc: 48.44%] [G loss: 1.737721]\n",
      "epoch:3 step:2418 [D loss: 0.944227, acc: 28.91%] [G loss: 1.719962]\n",
      "epoch:3 step:2419 [D loss: 0.822466, acc: 43.75%] [G loss: 1.582578]\n",
      "epoch:3 step:2420 [D loss: 0.477941, acc: 83.59%] [G loss: 1.752749]\n",
      "epoch:3 step:2421 [D loss: 0.564542, acc: 71.09%] [G loss: 1.809525]\n",
      "epoch:3 step:2422 [D loss: 0.746251, acc: 57.03%] [G loss: 1.690727]\n",
      "epoch:3 step:2423 [D loss: 0.641828, acc: 66.41%] [G loss: 1.742538]\n",
      "epoch:3 step:2424 [D loss: 0.789768, acc: 45.31%] [G loss: 1.542352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2425 [D loss: 0.940769, acc: 35.94%] [G loss: 1.621704]\n",
      "epoch:3 step:2426 [D loss: 0.618769, acc: 69.53%] [G loss: 2.076362]\n",
      "epoch:3 step:2427 [D loss: 0.907878, acc: 37.50%] [G loss: 1.641140]\n",
      "epoch:3 step:2428 [D loss: 0.719727, acc: 53.12%] [G loss: 1.690661]\n",
      "epoch:3 step:2429 [D loss: 0.546453, acc: 74.22%] [G loss: 1.770559]\n",
      "epoch:3 step:2430 [D loss: 0.711248, acc: 56.25%] [G loss: 1.707345]\n",
      "epoch:3 step:2431 [D loss: 0.748588, acc: 44.53%] [G loss: 1.779732]\n",
      "epoch:3 step:2432 [D loss: 0.851603, acc: 35.94%] [G loss: 1.847466]\n",
      "epoch:3 step:2433 [D loss: 0.873714, acc: 43.75%] [G loss: 1.541199]\n",
      "epoch:3 step:2434 [D loss: 0.631257, acc: 66.41%] [G loss: 1.804758]\n",
      "epoch:3 step:2435 [D loss: 0.642339, acc: 57.03%] [G loss: 2.086405]\n",
      "epoch:3 step:2436 [D loss: 0.657664, acc: 66.41%] [G loss: 2.106010]\n",
      "epoch:3 step:2437 [D loss: 0.588807, acc: 64.84%] [G loss: 2.346555]\n",
      "epoch:3 step:2438 [D loss: 0.464389, acc: 80.47%] [G loss: 2.078255]\n",
      "epoch:3 step:2439 [D loss: 0.720405, acc: 56.25%] [G loss: 1.854570]\n",
      "epoch:3 step:2440 [D loss: 0.394158, acc: 89.06%] [G loss: 1.941312]\n",
      "epoch:3 step:2441 [D loss: 0.604849, acc: 67.19%] [G loss: 1.519332]\n",
      "epoch:3 step:2442 [D loss: 0.606240, acc: 71.88%] [G loss: 1.748760]\n",
      "epoch:3 step:2443 [D loss: 0.444758, acc: 84.38%] [G loss: 1.830298]\n",
      "epoch:3 step:2444 [D loss: 0.504068, acc: 83.59%] [G loss: 1.704624]\n",
      "epoch:3 step:2445 [D loss: 0.618290, acc: 62.50%] [G loss: 1.749382]\n",
      "epoch:3 step:2446 [D loss: 0.943622, acc: 36.72%] [G loss: 1.306807]\n",
      "epoch:3 step:2447 [D loss: 0.404314, acc: 89.84%] [G loss: 1.884297]\n",
      "epoch:3 step:2448 [D loss: 0.541755, acc: 72.66%] [G loss: 1.683617]\n",
      "epoch:3 step:2449 [D loss: 0.611991, acc: 66.41%] [G loss: 1.416940]\n",
      "epoch:3 step:2450 [D loss: 0.460555, acc: 75.78%] [G loss: 1.613142]\n",
      "epoch:3 step:2451 [D loss: 0.362706, acc: 93.75%] [G loss: 1.976842]\n",
      "epoch:3 step:2452 [D loss: 0.593459, acc: 63.28%] [G loss: 1.371114]\n",
      "epoch:3 step:2453 [D loss: 0.979045, acc: 50.00%] [G loss: 1.620526]\n",
      "epoch:3 step:2454 [D loss: 0.719579, acc: 62.50%] [G loss: 1.117735]\n",
      "epoch:3 step:2455 [D loss: 0.883578, acc: 50.00%] [G loss: 1.708040]\n",
      "epoch:3 step:2456 [D loss: 0.565630, acc: 71.09%] [G loss: 1.796090]\n",
      "epoch:3 step:2457 [D loss: 0.670601, acc: 62.50%] [G loss: 1.388953]\n",
      "epoch:3 step:2458 [D loss: 1.556286, acc: 8.59%] [G loss: 1.038830]\n",
      "epoch:3 step:2459 [D loss: 0.993617, acc: 27.34%] [G loss: 1.322636]\n",
      "epoch:3 step:2460 [D loss: 0.710768, acc: 58.59%] [G loss: 1.921353]\n",
      "epoch:3 step:2461 [D loss: 0.399099, acc: 89.84%] [G loss: 1.804790]\n",
      "epoch:3 step:2462 [D loss: 0.964387, acc: 32.03%] [G loss: 1.443535]\n",
      "epoch:3 step:2463 [D loss: 0.692834, acc: 60.16%] [G loss: 2.187780]\n",
      "epoch:3 step:2464 [D loss: 0.737353, acc: 55.47%] [G loss: 1.820913]\n",
      "epoch:3 step:2465 [D loss: 0.504652, acc: 71.88%] [G loss: 2.192816]\n",
      "epoch:3 step:2466 [D loss: 1.107479, acc: 18.75%] [G loss: 1.636179]\n",
      "epoch:3 step:2467 [D loss: 0.585707, acc: 66.41%] [G loss: 2.264613]\n",
      "epoch:3 step:2468 [D loss: 0.560607, acc: 73.44%] [G loss: 2.123078]\n",
      "epoch:3 step:2469 [D loss: 0.704149, acc: 59.38%] [G loss: 1.629150]\n",
      "epoch:3 step:2470 [D loss: 0.655339, acc: 62.50%] [G loss: 1.709939]\n",
      "epoch:3 step:2471 [D loss: 0.935312, acc: 31.25%] [G loss: 1.780096]\n",
      "epoch:3 step:2472 [D loss: 0.620625, acc: 63.28%] [G loss: 1.938221]\n",
      "epoch:3 step:2473 [D loss: 0.629981, acc: 63.28%] [G loss: 1.537008]\n",
      "epoch:3 step:2474 [D loss: 0.549086, acc: 75.00%] [G loss: 1.698782]\n",
      "epoch:3 step:2475 [D loss: 0.964480, acc: 26.56%] [G loss: 1.584622]\n",
      "epoch:3 step:2476 [D loss: 0.665580, acc: 64.06%] [G loss: 1.760806]\n",
      "epoch:3 step:2477 [D loss: 0.593563, acc: 67.19%] [G loss: 1.684957]\n",
      "epoch:3 step:2478 [D loss: 0.730077, acc: 55.47%] [G loss: 2.111539]\n",
      "epoch:3 step:2479 [D loss: 0.722228, acc: 57.81%] [G loss: 1.598936]\n",
      "epoch:3 step:2480 [D loss: 0.756571, acc: 50.00%] [G loss: 1.767033]\n",
      "epoch:3 step:2481 [D loss: 0.800105, acc: 46.09%] [G loss: 1.534104]\n",
      "epoch:3 step:2482 [D loss: 0.645297, acc: 62.50%] [G loss: 1.700366]\n",
      "epoch:3 step:2483 [D loss: 0.728422, acc: 50.00%] [G loss: 1.598245]\n",
      "epoch:3 step:2484 [D loss: 0.792947, acc: 46.09%] [G loss: 1.606972]\n",
      "epoch:3 step:2485 [D loss: 0.669188, acc: 57.03%] [G loss: 1.749170]\n",
      "epoch:3 step:2486 [D loss: 0.513382, acc: 78.12%] [G loss: 1.945039]\n",
      "epoch:3 step:2487 [D loss: 0.602877, acc: 71.09%] [G loss: 1.592375]\n",
      "epoch:3 step:2488 [D loss: 0.957619, acc: 28.12%] [G loss: 1.170915]\n",
      "epoch:3 step:2489 [D loss: 0.653166, acc: 61.72%] [G loss: 1.563525]\n",
      "epoch:3 step:2490 [D loss: 0.758760, acc: 57.81%] [G loss: 1.640275]\n",
      "epoch:3 step:2491 [D loss: 0.726494, acc: 54.69%] [G loss: 1.763418]\n",
      "epoch:3 step:2492 [D loss: 0.861646, acc: 51.56%] [G loss: 1.226831]\n",
      "epoch:3 step:2493 [D loss: 0.611120, acc: 63.28%] [G loss: 1.198665]\n",
      "epoch:3 step:2494 [D loss: 0.891616, acc: 42.97%] [G loss: 1.297960]\n",
      "epoch:3 step:2495 [D loss: 0.843441, acc: 39.84%] [G loss: 1.335250]\n",
      "epoch:3 step:2496 [D loss: 0.818839, acc: 43.75%] [G loss: 1.635355]\n",
      "epoch:3 step:2497 [D loss: 0.746435, acc: 50.00%] [G loss: 1.416363]\n",
      "epoch:3 step:2498 [D loss: 1.113778, acc: 22.66%] [G loss: 1.437641]\n",
      "epoch:3 step:2499 [D loss: 0.595815, acc: 68.75%] [G loss: 1.618732]\n",
      "epoch:3 step:2500 [D loss: 0.712222, acc: 51.56%] [G loss: 1.445391]\n",
      "epoch:3 step:2501 [D loss: 0.722199, acc: 52.34%] [G loss: 1.563028]\n",
      "epoch:3 step:2502 [D loss: 0.898531, acc: 33.59%] [G loss: 1.595873]\n",
      "epoch:3 step:2503 [D loss: 0.648575, acc: 67.97%] [G loss: 1.938294]\n",
      "epoch:3 step:2504 [D loss: 0.766922, acc: 54.69%] [G loss: 1.991669]\n",
      "epoch:3 step:2505 [D loss: 0.662675, acc: 63.28%] [G loss: 2.013059]\n",
      "epoch:3 step:2506 [D loss: 0.652341, acc: 66.41%] [G loss: 2.215168]\n",
      "epoch:3 step:2507 [D loss: 0.663743, acc: 62.50%] [G loss: 2.178710]\n",
      "epoch:3 step:2508 [D loss: 0.518305, acc: 78.12%] [G loss: 2.558612]\n",
      "epoch:3 step:2509 [D loss: 0.701114, acc: 50.78%] [G loss: 2.202055]\n",
      "epoch:3 step:2510 [D loss: 0.502820, acc: 83.59%] [G loss: 2.352449]\n",
      "epoch:3 step:2511 [D loss: 0.528533, acc: 78.12%] [G loss: 2.280524]\n",
      "epoch:3 step:2512 [D loss: 0.421038, acc: 87.50%] [G loss: 2.092183]\n",
      "epoch:3 step:2513 [D loss: 0.335529, acc: 92.97%] [G loss: 2.473222]\n",
      "epoch:3 step:2514 [D loss: 0.507245, acc: 82.81%] [G loss: 2.070223]\n",
      "epoch:3 step:2515 [D loss: 0.637840, acc: 67.97%] [G loss: 1.884160]\n",
      "epoch:3 step:2516 [D loss: 0.344954, acc: 89.84%] [G loss: 2.102035]\n",
      "epoch:3 step:2517 [D loss: 0.354927, acc: 95.31%] [G loss: 2.005559]\n",
      "epoch:3 step:2518 [D loss: 0.445466, acc: 88.28%] [G loss: 1.760901]\n",
      "epoch:3 step:2519 [D loss: 0.377649, acc: 89.06%] [G loss: 2.134504]\n",
      "epoch:3 step:2520 [D loss: 0.292569, acc: 95.31%] [G loss: 2.191857]\n",
      "epoch:3 step:2521 [D loss: 0.492182, acc: 82.03%] [G loss: 1.469201]\n",
      "epoch:3 step:2522 [D loss: 0.596569, acc: 71.09%] [G loss: 1.766991]\n",
      "epoch:3 step:2523 [D loss: 0.799591, acc: 58.59%] [G loss: 1.288646]\n",
      "epoch:3 step:2524 [D loss: 0.573528, acc: 65.62%] [G loss: 1.677652]\n",
      "epoch:3 step:2525 [D loss: 0.687630, acc: 58.59%] [G loss: 1.750921]\n",
      "epoch:3 step:2526 [D loss: 0.800611, acc: 48.44%] [G loss: 1.670862]\n",
      "epoch:3 step:2527 [D loss: 0.809012, acc: 49.22%] [G loss: 1.240310]\n",
      "epoch:3 step:2528 [D loss: 0.566811, acc: 70.31%] [G loss: 1.841924]\n",
      "epoch:3 step:2529 [D loss: 0.394339, acc: 90.62%] [G loss: 1.820501]\n",
      "epoch:3 step:2530 [D loss: 0.606111, acc: 65.62%] [G loss: 1.346133]\n",
      "epoch:3 step:2531 [D loss: 0.491019, acc: 81.25%] [G loss: 1.756586]\n",
      "epoch:3 step:2532 [D loss: 0.874829, acc: 42.19%] [G loss: 1.589554]\n",
      "epoch:3 step:2533 [D loss: 0.914963, acc: 35.94%] [G loss: 1.307312]\n",
      "epoch:3 step:2534 [D loss: 0.875363, acc: 38.28%] [G loss: 1.454679]\n",
      "epoch:3 step:2535 [D loss: 0.718058, acc: 56.25%] [G loss: 1.454696]\n",
      "epoch:3 step:2536 [D loss: 0.957582, acc: 32.03%] [G loss: 1.414626]\n",
      "epoch:3 step:2537 [D loss: 0.551867, acc: 77.34%] [G loss: 1.487238]\n",
      "epoch:3 step:2538 [D loss: 0.873464, acc: 37.50%] [G loss: 1.470310]\n",
      "epoch:3 step:2539 [D loss: 0.706480, acc: 57.03%] [G loss: 1.667827]\n",
      "epoch:3 step:2540 [D loss: 0.708580, acc: 57.03%] [G loss: 1.693558]\n",
      "epoch:3 step:2541 [D loss: 0.713053, acc: 58.59%] [G loss: 1.606795]\n",
      "epoch:3 step:2542 [D loss: 1.089289, acc: 26.56%] [G loss: 1.384139]\n",
      "epoch:3 step:2543 [D loss: 0.921422, acc: 43.75%] [G loss: 1.589938]\n",
      "epoch:3 step:2544 [D loss: 0.825907, acc: 42.97%] [G loss: 1.908724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2545 [D loss: 0.950895, acc: 37.50%] [G loss: 1.648680]\n",
      "epoch:3 step:2546 [D loss: 0.811146, acc: 53.91%] [G loss: 1.860011]\n",
      "epoch:3 step:2547 [D loss: 0.809535, acc: 41.41%] [G loss: 2.025527]\n",
      "epoch:3 step:2548 [D loss: 1.049504, acc: 29.69%] [G loss: 1.738544]\n",
      "epoch:3 step:2549 [D loss: 0.895855, acc: 40.62%] [G loss: 1.420743]\n",
      "epoch:3 step:2550 [D loss: 0.570509, acc: 76.56%] [G loss: 1.769660]\n",
      "epoch:3 step:2551 [D loss: 0.645928, acc: 65.62%] [G loss: 2.106962]\n",
      "epoch:3 step:2552 [D loss: 0.573155, acc: 70.31%] [G loss: 1.687945]\n",
      "epoch:3 step:2553 [D loss: 0.516815, acc: 82.81%] [G loss: 1.754307]\n",
      "epoch:3 step:2554 [D loss: 0.566096, acc: 67.19%] [G loss: 1.485519]\n",
      "epoch:3 step:2555 [D loss: 0.417853, acc: 82.81%] [G loss: 1.719406]\n",
      "epoch:3 step:2556 [D loss: 0.529206, acc: 72.66%] [G loss: 1.518392]\n",
      "epoch:3 step:2557 [D loss: 0.317960, acc: 92.19%] [G loss: 2.172145]\n",
      "epoch:3 step:2558 [D loss: 0.327043, acc: 92.97%] [G loss: 1.824463]\n",
      "epoch:3 step:2559 [D loss: 0.344760, acc: 92.19%] [G loss: 1.994162]\n",
      "epoch:3 step:2560 [D loss: 0.655600, acc: 60.94%] [G loss: 1.469949]\n",
      "epoch:3 step:2561 [D loss: 0.593598, acc: 65.62%] [G loss: 2.022741]\n",
      "epoch:3 step:2562 [D loss: 0.473681, acc: 81.25%] [G loss: 1.656199]\n",
      "epoch:3 step:2563 [D loss: 0.318806, acc: 89.06%] [G loss: 1.946695]\n",
      "epoch:3 step:2564 [D loss: 0.542477, acc: 74.22%] [G loss: 1.504258]\n",
      "epoch:3 step:2565 [D loss: 0.625823, acc: 59.38%] [G loss: 1.998078]\n",
      "epoch:3 step:2566 [D loss: 0.522691, acc: 77.34%] [G loss: 1.530679]\n",
      "epoch:3 step:2567 [D loss: 0.926477, acc: 29.69%] [G loss: 1.401853]\n",
      "epoch:3 step:2568 [D loss: 0.407194, acc: 90.62%] [G loss: 1.654908]\n",
      "epoch:3 step:2569 [D loss: 0.504016, acc: 79.69%] [G loss: 1.938024]\n",
      "epoch:3 step:2570 [D loss: 1.086908, acc: 21.88%] [G loss: 1.290253]\n",
      "epoch:3 step:2571 [D loss: 0.708917, acc: 53.12%] [G loss: 1.801966]\n",
      "epoch:3 step:2572 [D loss: 0.550315, acc: 73.44%] [G loss: 2.310843]\n",
      "epoch:3 step:2573 [D loss: 0.533832, acc: 76.56%] [G loss: 1.957369]\n",
      "epoch:3 step:2574 [D loss: 0.651708, acc: 57.81%] [G loss: 1.742057]\n",
      "epoch:3 step:2575 [D loss: 0.888426, acc: 45.31%] [G loss: 1.631707]\n",
      "epoch:3 step:2576 [D loss: 0.491292, acc: 82.81%] [G loss: 1.914453]\n",
      "epoch:3 step:2577 [D loss: 0.784384, acc: 52.34%] [G loss: 1.696121]\n",
      "epoch:3 step:2578 [D loss: 0.434884, acc: 83.59%] [G loss: 1.760342]\n",
      "epoch:3 step:2579 [D loss: 0.835191, acc: 39.06%] [G loss: 1.562921]\n",
      "epoch:3 step:2580 [D loss: 0.641660, acc: 62.50%] [G loss: 1.889291]\n",
      "epoch:3 step:2581 [D loss: 0.489639, acc: 78.12%] [G loss: 2.159926]\n",
      "epoch:3 step:2582 [D loss: 0.180381, acc: 98.44%] [G loss: 2.354774]\n",
      "epoch:3 step:2583 [D loss: 0.783637, acc: 47.66%] [G loss: 1.769432]\n",
      "epoch:3 step:2584 [D loss: 0.270395, acc: 93.75%] [G loss: 2.330212]\n",
      "epoch:3 step:2585 [D loss: 0.516196, acc: 79.69%] [G loss: 2.033254]\n",
      "epoch:3 step:2586 [D loss: 0.560075, acc: 67.97%] [G loss: 1.895402]\n",
      "epoch:3 step:2587 [D loss: 0.470319, acc: 75.00%] [G loss: 1.691211]\n",
      "epoch:3 step:2588 [D loss: 0.361895, acc: 91.41%] [G loss: 1.932290]\n",
      "epoch:3 step:2589 [D loss: 0.747594, acc: 55.47%] [G loss: 1.422707]\n",
      "epoch:3 step:2590 [D loss: 0.449374, acc: 86.72%] [G loss: 1.606790]\n",
      "epoch:3 step:2591 [D loss: 0.389533, acc: 89.84%] [G loss: 1.768586]\n",
      "epoch:3 step:2592 [D loss: 0.569391, acc: 72.66%] [G loss: 1.539025]\n",
      "epoch:3 step:2593 [D loss: 1.085689, acc: 25.00%] [G loss: 1.385165]\n",
      "epoch:3 step:2594 [D loss: 0.626554, acc: 58.59%] [G loss: 1.762364]\n",
      "epoch:3 step:2595 [D loss: 0.657110, acc: 67.97%] [G loss: 1.869643]\n",
      "epoch:3 step:2596 [D loss: 0.689227, acc: 53.12%] [G loss: 1.774790]\n",
      "epoch:3 step:2597 [D loss: 0.567349, acc: 75.78%] [G loss: 1.938896]\n",
      "epoch:3 step:2598 [D loss: 0.744766, acc: 54.69%] [G loss: 1.867516]\n",
      "epoch:3 step:2599 [D loss: 0.433988, acc: 79.69%] [G loss: 1.652647]\n",
      "epoch:3 step:2600 [D loss: 0.744498, acc: 50.78%] [G loss: 2.254563]\n",
      "epoch:3 step:2601 [D loss: 0.691574, acc: 53.12%] [G loss: 1.895643]\n",
      "epoch:3 step:2602 [D loss: 0.629333, acc: 64.06%] [G loss: 2.308527]\n",
      "epoch:3 step:2603 [D loss: 0.778610, acc: 49.22%] [G loss: 1.925548]\n",
      "epoch:3 step:2604 [D loss: 0.427022, acc: 85.16%] [G loss: 2.408132]\n",
      "epoch:3 step:2605 [D loss: 0.585254, acc: 71.09%] [G loss: 2.130881]\n",
      "epoch:3 step:2606 [D loss: 0.726649, acc: 58.59%] [G loss: 2.301019]\n",
      "epoch:3 step:2607 [D loss: 0.726738, acc: 50.00%] [G loss: 2.314404]\n",
      "epoch:3 step:2608 [D loss: 0.697499, acc: 57.81%] [G loss: 2.056030]\n",
      "epoch:3 step:2609 [D loss: 0.559396, acc: 73.44%] [G loss: 2.018193]\n",
      "epoch:3 step:2610 [D loss: 0.992262, acc: 28.91%] [G loss: 1.341137]\n",
      "epoch:3 step:2611 [D loss: 0.787619, acc: 49.22%] [G loss: 1.789216]\n",
      "epoch:3 step:2612 [D loss: 0.874760, acc: 37.50%] [G loss: 1.592870]\n",
      "epoch:3 step:2613 [D loss: 0.844145, acc: 44.53%] [G loss: 1.722652]\n",
      "epoch:3 step:2614 [D loss: 0.721344, acc: 58.59%] [G loss: 1.394918]\n",
      "epoch:3 step:2615 [D loss: 0.874291, acc: 34.38%] [G loss: 1.603963]\n",
      "epoch:3 step:2616 [D loss: 0.838723, acc: 39.84%] [G loss: 1.773668]\n",
      "epoch:3 step:2617 [D loss: 0.730028, acc: 60.94%] [G loss: 1.350034]\n",
      "epoch:3 step:2618 [D loss: 0.651755, acc: 66.41%] [G loss: 1.978384]\n",
      "epoch:3 step:2619 [D loss: 0.612798, acc: 66.41%] [G loss: 1.501449]\n",
      "epoch:3 step:2620 [D loss: 0.948521, acc: 32.03%] [G loss: 1.637623]\n",
      "epoch:3 step:2621 [D loss: 0.766678, acc: 50.78%] [G loss: 1.484214]\n",
      "epoch:3 step:2622 [D loss: 0.676272, acc: 57.81%] [G loss: 1.656639]\n",
      "epoch:3 step:2623 [D loss: 0.823869, acc: 42.19%] [G loss: 1.477150]\n",
      "epoch:3 step:2624 [D loss: 0.882482, acc: 38.28%] [G loss: 1.273250]\n",
      "epoch:3 step:2625 [D loss: 0.419071, acc: 88.28%] [G loss: 2.215884]\n",
      "epoch:3 step:2626 [D loss: 0.926836, acc: 37.50%] [G loss: 1.648382]\n",
      "epoch:3 step:2627 [D loss: 0.672328, acc: 58.59%] [G loss: 1.538292]\n",
      "epoch:3 step:2628 [D loss: 0.733546, acc: 48.44%] [G loss: 1.569953]\n",
      "epoch:3 step:2629 [D loss: 0.700303, acc: 54.69%] [G loss: 1.595378]\n",
      "epoch:3 step:2630 [D loss: 0.654915, acc: 63.28%] [G loss: 1.577824]\n",
      "epoch:3 step:2631 [D loss: 0.789779, acc: 50.00%] [G loss: 1.788401]\n",
      "epoch:3 step:2632 [D loss: 0.752218, acc: 48.44%] [G loss: 1.487460]\n",
      "epoch:3 step:2633 [D loss: 0.746737, acc: 50.00%] [G loss: 1.603492]\n",
      "epoch:3 step:2634 [D loss: 1.227286, acc: 11.72%] [G loss: 1.167725]\n",
      "epoch:3 step:2635 [D loss: 0.784829, acc: 45.31%] [G loss: 1.762902]\n",
      "epoch:3 step:2636 [D loss: 0.735395, acc: 53.12%] [G loss: 1.647191]\n",
      "epoch:3 step:2637 [D loss: 0.889946, acc: 28.12%] [G loss: 1.331823]\n",
      "epoch:3 step:2638 [D loss: 0.739802, acc: 50.00%] [G loss: 1.836358]\n",
      "epoch:3 step:2639 [D loss: 0.863700, acc: 36.72%] [G loss: 1.595722]\n",
      "epoch:3 step:2640 [D loss: 0.669257, acc: 61.72%] [G loss: 1.622295]\n",
      "epoch:3 step:2641 [D loss: 0.899173, acc: 35.94%] [G loss: 1.355042]\n",
      "epoch:3 step:2642 [D loss: 0.808142, acc: 36.72%] [G loss: 1.706073]\n",
      "epoch:3 step:2643 [D loss: 0.598622, acc: 69.53%] [G loss: 1.651932]\n",
      "epoch:3 step:2644 [D loss: 0.684401, acc: 59.38%] [G loss: 1.786459]\n",
      "epoch:3 step:2645 [D loss: 0.658979, acc: 63.28%] [G loss: 1.561795]\n",
      "epoch:3 step:2646 [D loss: 0.625743, acc: 69.53%] [G loss: 1.670891]\n",
      "epoch:3 step:2647 [D loss: 0.590461, acc: 68.75%] [G loss: 1.875016]\n",
      "epoch:3 step:2648 [D loss: 0.803236, acc: 49.22%] [G loss: 1.754218]\n",
      "epoch:3 step:2649 [D loss: 0.710145, acc: 53.91%] [G loss: 1.914519]\n",
      "epoch:3 step:2650 [D loss: 0.859630, acc: 35.16%] [G loss: 1.630045]\n",
      "epoch:3 step:2651 [D loss: 0.668789, acc: 54.69%] [G loss: 2.019397]\n",
      "epoch:3 step:2652 [D loss: 0.670942, acc: 56.25%] [G loss: 1.761750]\n",
      "epoch:3 step:2653 [D loss: 0.541895, acc: 79.69%] [G loss: 1.960180]\n",
      "epoch:3 step:2654 [D loss: 0.553281, acc: 69.53%] [G loss: 1.949996]\n",
      "epoch:3 step:2655 [D loss: 0.769601, acc: 47.66%] [G loss: 1.819589]\n",
      "epoch:3 step:2656 [D loss: 0.899039, acc: 28.91%] [G loss: 1.493652]\n",
      "epoch:3 step:2657 [D loss: 0.749376, acc: 49.22%] [G loss: 1.772620]\n",
      "epoch:3 step:2658 [D loss: 0.955075, acc: 39.06%] [G loss: 1.803008]\n",
      "epoch:3 step:2659 [D loss: 0.592276, acc: 69.53%] [G loss: 2.000832]\n",
      "epoch:3 step:2660 [D loss: 0.719071, acc: 51.56%] [G loss: 1.630955]\n",
      "epoch:3 step:2661 [D loss: 0.724537, acc: 53.91%] [G loss: 1.658803]\n",
      "epoch:3 step:2662 [D loss: 0.883604, acc: 33.59%] [G loss: 1.259462]\n",
      "epoch:3 step:2663 [D loss: 0.770385, acc: 48.44%] [G loss: 1.709867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2664 [D loss: 0.595449, acc: 69.53%] [G loss: 1.703493]\n",
      "epoch:3 step:2665 [D loss: 0.626298, acc: 66.41%] [G loss: 1.709411]\n",
      "epoch:3 step:2666 [D loss: 0.555760, acc: 75.78%] [G loss: 1.834267]\n",
      "epoch:3 step:2667 [D loss: 0.585216, acc: 67.97%] [G loss: 1.865329]\n",
      "epoch:3 step:2668 [D loss: 0.760720, acc: 44.53%] [G loss: 1.953758]\n",
      "epoch:3 step:2669 [D loss: 0.603247, acc: 65.62%] [G loss: 1.857975]\n",
      "epoch:3 step:2670 [D loss: 0.635064, acc: 58.59%] [G loss: 2.018915]\n",
      "epoch:3 step:2671 [D loss: 0.634091, acc: 62.50%] [G loss: 1.910730]\n",
      "epoch:3 step:2672 [D loss: 0.764876, acc: 45.31%] [G loss: 1.784620]\n",
      "epoch:3 step:2673 [D loss: 0.773735, acc: 47.66%] [G loss: 1.937068]\n",
      "epoch:3 step:2674 [D loss: 0.495183, acc: 79.69%] [G loss: 2.081459]\n",
      "epoch:3 step:2675 [D loss: 0.519470, acc: 75.78%] [G loss: 1.956806]\n",
      "epoch:3 step:2676 [D loss: 0.617953, acc: 65.62%] [G loss: 1.624826]\n",
      "epoch:3 step:2677 [D loss: 0.544821, acc: 67.97%] [G loss: 1.717034]\n",
      "epoch:3 step:2678 [D loss: 0.550670, acc: 75.00%] [G loss: 1.909075]\n",
      "epoch:3 step:2679 [D loss: 0.467625, acc: 76.56%] [G loss: 1.939669]\n",
      "epoch:3 step:2680 [D loss: 0.649245, acc: 58.59%] [G loss: 2.135152]\n",
      "epoch:3 step:2681 [D loss: 1.127849, acc: 28.12%] [G loss: 1.971080]\n",
      "epoch:3 step:2682 [D loss: 0.513550, acc: 76.56%] [G loss: 2.326948]\n",
      "epoch:3 step:2683 [D loss: 0.373794, acc: 87.50%] [G loss: 2.157072]\n",
      "epoch:3 step:2684 [D loss: 0.656828, acc: 57.81%] [G loss: 1.792044]\n",
      "epoch:3 step:2685 [D loss: 0.476521, acc: 79.69%] [G loss: 1.927512]\n",
      "epoch:3 step:2686 [D loss: 0.613202, acc: 69.53%] [G loss: 1.996319]\n",
      "epoch:3 step:2687 [D loss: 0.768259, acc: 48.44%] [G loss: 1.702680]\n",
      "epoch:3 step:2688 [D loss: 0.671665, acc: 58.59%] [G loss: 1.737214]\n",
      "epoch:3 step:2689 [D loss: 0.764996, acc: 48.44%] [G loss: 2.302048]\n",
      "epoch:3 step:2690 [D loss: 0.660252, acc: 57.81%] [G loss: 2.307043]\n",
      "epoch:3 step:2691 [D loss: 0.789027, acc: 50.00%] [G loss: 2.047170]\n",
      "epoch:3 step:2692 [D loss: 0.533618, acc: 75.00%] [G loss: 2.622748]\n",
      "epoch:3 step:2693 [D loss: 0.965035, acc: 42.19%] [G loss: 2.299625]\n",
      "epoch:3 step:2694 [D loss: 0.614166, acc: 66.41%] [G loss: 2.306918]\n",
      "epoch:3 step:2695 [D loss: 0.526128, acc: 71.09%] [G loss: 2.344646]\n",
      "epoch:3 step:2696 [D loss: 0.454027, acc: 83.59%] [G loss: 2.588510]\n",
      "epoch:3 step:2697 [D loss: 0.463560, acc: 79.69%] [G loss: 2.050998]\n",
      "epoch:3 step:2698 [D loss: 0.464236, acc: 79.69%] [G loss: 1.682723]\n",
      "epoch:3 step:2699 [D loss: 0.697317, acc: 61.72%] [G loss: 1.679738]\n",
      "epoch:3 step:2700 [D loss: 0.561092, acc: 67.19%] [G loss: 1.842688]\n",
      "epoch:3 step:2701 [D loss: 0.638485, acc: 67.97%] [G loss: 1.702347]\n",
      "epoch:3 step:2702 [D loss: 0.704452, acc: 60.94%] [G loss: 1.336178]\n",
      "epoch:3 step:2703 [D loss: 0.723963, acc: 60.94%] [G loss: 1.690946]\n",
      "epoch:3 step:2704 [D loss: 0.617401, acc: 66.41%] [G loss: 1.795149]\n",
      "epoch:3 step:2705 [D loss: 0.732902, acc: 57.03%] [G loss: 1.480879]\n",
      "epoch:3 step:2706 [D loss: 0.522671, acc: 78.12%] [G loss: 1.831403]\n",
      "epoch:3 step:2707 [D loss: 0.896328, acc: 32.81%] [G loss: 1.671523]\n",
      "epoch:3 step:2708 [D loss: 0.842603, acc: 49.22%] [G loss: 2.198893]\n",
      "epoch:3 step:2709 [D loss: 0.817985, acc: 50.78%] [G loss: 1.782557]\n",
      "epoch:3 step:2710 [D loss: 0.709429, acc: 52.34%] [G loss: 1.945765]\n",
      "epoch:3 step:2711 [D loss: 0.627948, acc: 63.28%] [G loss: 2.262582]\n",
      "epoch:3 step:2712 [D loss: 0.558703, acc: 70.31%] [G loss: 2.166941]\n",
      "epoch:3 step:2713 [D loss: 0.494952, acc: 78.12%] [G loss: 2.418937]\n",
      "epoch:3 step:2714 [D loss: 0.420735, acc: 79.69%] [G loss: 2.066540]\n",
      "epoch:3 step:2715 [D loss: 0.674768, acc: 60.16%] [G loss: 2.059896]\n",
      "epoch:3 step:2716 [D loss: 0.558060, acc: 71.09%] [G loss: 2.566411]\n",
      "epoch:3 step:2717 [D loss: 0.624623, acc: 64.84%] [G loss: 2.282253]\n",
      "epoch:3 step:2718 [D loss: 0.518579, acc: 75.78%] [G loss: 2.534468]\n",
      "epoch:3 step:2719 [D loss: 0.339052, acc: 89.84%] [G loss: 2.180977]\n",
      "epoch:3 step:2720 [D loss: 0.418770, acc: 85.16%] [G loss: 2.253048]\n",
      "epoch:3 step:2721 [D loss: 0.484624, acc: 79.69%] [G loss: 1.814713]\n",
      "epoch:3 step:2722 [D loss: 0.271116, acc: 95.31%] [G loss: 2.141224]\n",
      "epoch:3 step:2723 [D loss: 0.701887, acc: 54.69%] [G loss: 1.688806]\n",
      "epoch:3 step:2724 [D loss: 0.453922, acc: 81.25%] [G loss: 1.800634]\n",
      "epoch:3 step:2725 [D loss: 0.687658, acc: 60.94%] [G loss: 1.919386]\n",
      "epoch:3 step:2726 [D loss: 0.476297, acc: 81.25%] [G loss: 1.834389]\n",
      "epoch:3 step:2727 [D loss: 0.542626, acc: 80.47%] [G loss: 2.057571]\n",
      "epoch:3 step:2728 [D loss: 0.656934, acc: 60.94%] [G loss: 2.011122]\n",
      "epoch:3 step:2729 [D loss: 0.588123, acc: 61.72%] [G loss: 1.651746]\n",
      "epoch:3 step:2730 [D loss: 0.970568, acc: 44.53%] [G loss: 1.800133]\n",
      "epoch:3 step:2731 [D loss: 0.951996, acc: 28.12%] [G loss: 1.430888]\n",
      "epoch:3 step:2732 [D loss: 0.639472, acc: 63.28%] [G loss: 1.579602]\n",
      "epoch:3 step:2733 [D loss: 0.696620, acc: 58.59%] [G loss: 2.155529]\n",
      "epoch:3 step:2734 [D loss: 1.308784, acc: 30.47%] [G loss: 1.733550]\n",
      "epoch:3 step:2735 [D loss: 0.849931, acc: 40.62%] [G loss: 2.063796]\n",
      "epoch:3 step:2736 [D loss: 0.514530, acc: 73.44%] [G loss: 2.127986]\n",
      "epoch:3 step:2737 [D loss: 0.597363, acc: 67.97%] [G loss: 1.627885]\n",
      "epoch:3 step:2738 [D loss: 0.629629, acc: 62.50%] [G loss: 1.642059]\n",
      "epoch:3 step:2739 [D loss: 0.867268, acc: 35.94%] [G loss: 1.559498]\n",
      "epoch:3 step:2740 [D loss: 0.954953, acc: 32.81%] [G loss: 1.570991]\n",
      "epoch:3 step:2741 [D loss: 0.696824, acc: 57.81%] [G loss: 1.521686]\n",
      "epoch:3 step:2742 [D loss: 0.656663, acc: 61.72%] [G loss: 1.929420]\n",
      "epoch:3 step:2743 [D loss: 0.777573, acc: 49.22%] [G loss: 1.804273]\n",
      "epoch:3 step:2744 [D loss: 0.639141, acc: 61.72%] [G loss: 1.916686]\n",
      "epoch:3 step:2745 [D loss: 0.821222, acc: 39.84%] [G loss: 1.644673]\n",
      "epoch:3 step:2746 [D loss: 0.881289, acc: 37.50%] [G loss: 1.701692]\n",
      "epoch:3 step:2747 [D loss: 0.554462, acc: 71.88%] [G loss: 2.051507]\n",
      "epoch:3 step:2748 [D loss: 0.896631, acc: 38.28%] [G loss: 1.729554]\n",
      "epoch:3 step:2749 [D loss: 0.632921, acc: 64.84%] [G loss: 1.948591]\n",
      "epoch:3 step:2750 [D loss: 0.613556, acc: 67.19%] [G loss: 2.169462]\n",
      "epoch:3 step:2751 [D loss: 0.711214, acc: 53.91%] [G loss: 1.904282]\n",
      "epoch:3 step:2752 [D loss: 0.692058, acc: 59.38%] [G loss: 2.142347]\n",
      "epoch:3 step:2753 [D loss: 0.637449, acc: 67.19%] [G loss: 1.937245]\n",
      "epoch:3 step:2754 [D loss: 0.789699, acc: 45.31%] [G loss: 2.068854]\n",
      "epoch:3 step:2755 [D loss: 0.777787, acc: 44.53%] [G loss: 2.141227]\n",
      "epoch:3 step:2756 [D loss: 0.510172, acc: 79.69%] [G loss: 2.277328]\n",
      "epoch:3 step:2757 [D loss: 0.618621, acc: 69.53%] [G loss: 2.087068]\n",
      "epoch:3 step:2758 [D loss: 0.502432, acc: 77.34%] [G loss: 2.149456]\n",
      "epoch:3 step:2759 [D loss: 0.607984, acc: 67.19%] [G loss: 2.043941]\n",
      "epoch:3 step:2760 [D loss: 0.553509, acc: 71.09%] [G loss: 1.871000]\n",
      "epoch:3 step:2761 [D loss: 0.497333, acc: 81.25%] [G loss: 1.856706]\n",
      "epoch:3 step:2762 [D loss: 0.571797, acc: 69.53%] [G loss: 1.842781]\n",
      "epoch:3 step:2763 [D loss: 0.455603, acc: 82.03%] [G loss: 2.075918]\n",
      "epoch:3 step:2764 [D loss: 0.794711, acc: 46.88%] [G loss: 1.369561]\n",
      "epoch:3 step:2765 [D loss: 0.371777, acc: 92.19%] [G loss: 2.063109]\n",
      "epoch:3 step:2766 [D loss: 0.680481, acc: 58.59%] [G loss: 1.546543]\n",
      "epoch:3 step:2767 [D loss: 0.748571, acc: 53.12%] [G loss: 1.396799]\n",
      "epoch:3 step:2768 [D loss: 0.586011, acc: 70.31%] [G loss: 1.635120]\n",
      "epoch:3 step:2769 [D loss: 1.018562, acc: 28.12%] [G loss: 1.168076]\n",
      "epoch:3 step:2770 [D loss: 0.668347, acc: 59.38%] [G loss: 1.294533]\n",
      "epoch:3 step:2771 [D loss: 0.534730, acc: 75.00%] [G loss: 1.657714]\n",
      "epoch:3 step:2772 [D loss: 0.613535, acc: 70.31%] [G loss: 1.736647]\n",
      "epoch:3 step:2773 [D loss: 0.478810, acc: 80.47%] [G loss: 2.376446]\n",
      "epoch:3 step:2774 [D loss: 0.499862, acc: 79.69%] [G loss: 1.762427]\n",
      "epoch:3 step:2775 [D loss: 0.319041, acc: 92.19%] [G loss: 2.139726]\n",
      "epoch:3 step:2776 [D loss: 1.392311, acc: 16.41%] [G loss: 1.027604]\n",
      "epoch:3 step:2777 [D loss: 1.204312, acc: 28.91%] [G loss: 1.072588]\n",
      "epoch:3 step:2778 [D loss: 0.916666, acc: 38.28%] [G loss: 1.357775]\n",
      "epoch:3 step:2779 [D loss: 0.661426, acc: 65.62%] [G loss: 1.541106]\n",
      "epoch:3 step:2780 [D loss: 1.119098, acc: 22.66%] [G loss: 1.217071]\n",
      "epoch:3 step:2781 [D loss: 0.647736, acc: 67.19%] [G loss: 1.586078]\n",
      "epoch:3 step:2782 [D loss: 0.537292, acc: 76.56%] [G loss: 1.530428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2783 [D loss: 0.874308, acc: 45.31%] [G loss: 1.509010]\n",
      "epoch:3 step:2784 [D loss: 1.013389, acc: 29.69%] [G loss: 1.180819]\n",
      "epoch:3 step:2785 [D loss: 0.857433, acc: 35.16%] [G loss: 1.715314]\n",
      "epoch:3 step:2786 [D loss: 0.711649, acc: 57.03%] [G loss: 1.845608]\n",
      "epoch:3 step:2787 [D loss: 0.878017, acc: 41.41%] [G loss: 1.905875]\n",
      "epoch:3 step:2788 [D loss: 0.661508, acc: 60.94%] [G loss: 1.856516]\n",
      "epoch:3 step:2789 [D loss: 1.117138, acc: 35.16%] [G loss: 1.845941]\n",
      "epoch:3 step:2790 [D loss: 0.791378, acc: 45.31%] [G loss: 1.895967]\n",
      "epoch:3 step:2791 [D loss: 0.532283, acc: 76.56%] [G loss: 2.252621]\n",
      "epoch:3 step:2792 [D loss: 0.670249, acc: 57.81%] [G loss: 2.190870]\n",
      "epoch:3 step:2793 [D loss: 0.392362, acc: 85.16%] [G loss: 2.224411]\n",
      "epoch:3 step:2794 [D loss: 0.404722, acc: 87.50%] [G loss: 2.585357]\n",
      "epoch:3 step:2795 [D loss: 0.419531, acc: 82.81%] [G loss: 2.109128]\n",
      "epoch:3 step:2796 [D loss: 0.517934, acc: 72.66%] [G loss: 2.081654]\n",
      "epoch:3 step:2797 [D loss: 0.357380, acc: 88.28%] [G loss: 1.971886]\n",
      "epoch:3 step:2798 [D loss: 0.273627, acc: 91.41%] [G loss: 1.884411]\n",
      "epoch:3 step:2799 [D loss: 0.438872, acc: 85.16%] [G loss: 1.924094]\n",
      "epoch:3 step:2800 [D loss: 0.787959, acc: 60.16%] [G loss: 2.145155]\n",
      "epoch:3 step:2801 [D loss: 0.370941, acc: 89.84%] [G loss: 1.846951]\n",
      "epoch:3 step:2802 [D loss: 0.414071, acc: 78.91%] [G loss: 1.619548]\n",
      "epoch:3 step:2803 [D loss: 0.755776, acc: 52.34%] [G loss: 1.286737]\n",
      "epoch:3 step:2804 [D loss: 0.389076, acc: 86.72%] [G loss: 1.724526]\n",
      "epoch:3 step:2805 [D loss: 0.389857, acc: 84.38%] [G loss: 1.718411]\n",
      "epoch:3 step:2806 [D loss: 0.527685, acc: 69.53%] [G loss: 1.513023]\n",
      "epoch:3 step:2807 [D loss: 1.021080, acc: 46.88%] [G loss: 1.460898]\n",
      "epoch:3 step:2808 [D loss: 0.518776, acc: 73.44%] [G loss: 1.628213]\n",
      "epoch:3 step:2809 [D loss: 0.393552, acc: 88.28%] [G loss: 1.682237]\n",
      "epoch:3 step:2810 [D loss: 0.697736, acc: 57.03%] [G loss: 1.454392]\n",
      "epoch:3 step:2811 [D loss: 0.639204, acc: 61.72%] [G loss: 1.659324]\n",
      "epoch:3 step:2812 [D loss: 0.314310, acc: 90.62%] [G loss: 1.791203]\n",
      "epoch:3 step:2813 [D loss: 0.602550, acc: 68.75%] [G loss: 1.520439]\n",
      "epoch:3 step:2814 [D loss: 0.626875, acc: 64.84%] [G loss: 1.535367]\n",
      "epoch:3 step:2815 [D loss: 1.249713, acc: 16.41%] [G loss: 0.908639]\n",
      "epoch:3 step:2816 [D loss: 1.061895, acc: 26.56%] [G loss: 1.381985]\n",
      "epoch:3 step:2817 [D loss: 1.123189, acc: 39.84%] [G loss: 1.606857]\n",
      "epoch:3 step:2818 [D loss: 0.982054, acc: 34.38%] [G loss: 1.515879]\n",
      "epoch:3 step:2819 [D loss: 0.750450, acc: 50.00%] [G loss: 1.712975]\n",
      "epoch:3 step:2820 [D loss: 0.700374, acc: 60.94%] [G loss: 1.831587]\n",
      "epoch:3 step:2821 [D loss: 0.602185, acc: 64.06%] [G loss: 2.241622]\n",
      "epoch:3 step:2822 [D loss: 0.694020, acc: 58.59%] [G loss: 1.767817]\n",
      "epoch:3 step:2823 [D loss: 0.725609, acc: 53.12%] [G loss: 1.868611]\n",
      "epoch:3 step:2824 [D loss: 0.708634, acc: 48.44%] [G loss: 1.934722]\n",
      "epoch:3 step:2825 [D loss: 0.979983, acc: 37.50%] [G loss: 2.012562]\n",
      "epoch:3 step:2826 [D loss: 0.716697, acc: 52.34%] [G loss: 1.962837]\n",
      "epoch:3 step:2827 [D loss: 0.562264, acc: 75.00%] [G loss: 1.904852]\n",
      "epoch:3 step:2828 [D loss: 0.589887, acc: 71.09%] [G loss: 2.012177]\n",
      "epoch:3 step:2829 [D loss: 0.655003, acc: 64.06%] [G loss: 2.087028]\n",
      "epoch:3 step:2830 [D loss: 0.510490, acc: 77.34%] [G loss: 2.101823]\n",
      "epoch:3 step:2831 [D loss: 0.497442, acc: 82.81%] [G loss: 1.980217]\n",
      "epoch:3 step:2832 [D loss: 0.744802, acc: 50.00%] [G loss: 1.602015]\n",
      "epoch:3 step:2833 [D loss: 0.591592, acc: 68.75%] [G loss: 1.942947]\n",
      "epoch:3 step:2834 [D loss: 0.481813, acc: 78.91%] [G loss: 2.191331]\n",
      "epoch:3 step:2835 [D loss: 0.662624, acc: 63.28%] [G loss: 1.705884]\n",
      "epoch:3 step:2836 [D loss: 0.422254, acc: 86.72%] [G loss: 1.973185]\n",
      "epoch:3 step:2837 [D loss: 0.788928, acc: 45.31%] [G loss: 1.375383]\n",
      "epoch:3 step:2838 [D loss: 0.550180, acc: 74.22%] [G loss: 1.328805]\n",
      "epoch:3 step:2839 [D loss: 0.575893, acc: 71.88%] [G loss: 1.487408]\n",
      "epoch:3 step:2840 [D loss: 0.502749, acc: 82.03%] [G loss: 1.816750]\n",
      "epoch:3 step:2841 [D loss: 0.451004, acc: 88.28%] [G loss: 1.926324]\n",
      "epoch:3 step:2842 [D loss: 0.521091, acc: 78.12%] [G loss: 1.817918]\n",
      "epoch:3 step:2843 [D loss: 0.679744, acc: 60.94%] [G loss: 1.289538]\n",
      "epoch:3 step:2844 [D loss: 0.886383, acc: 48.44%] [G loss: 1.458550]\n",
      "epoch:3 step:2845 [D loss: 0.738044, acc: 53.91%] [G loss: 1.404337]\n",
      "epoch:3 step:2846 [D loss: 0.807732, acc: 46.88%] [G loss: 1.102302]\n",
      "epoch:3 step:2847 [D loss: 0.895618, acc: 36.72%] [G loss: 1.256250]\n",
      "epoch:3 step:2848 [D loss: 0.594181, acc: 68.75%] [G loss: 1.524622]\n",
      "epoch:3 step:2849 [D loss: 0.517446, acc: 78.91%] [G loss: 1.405433]\n",
      "epoch:3 step:2850 [D loss: 0.636793, acc: 62.50%] [G loss: 1.613300]\n",
      "epoch:3 step:2851 [D loss: 1.233653, acc: 12.50%] [G loss: 1.224135]\n",
      "epoch:3 step:2852 [D loss: 0.788834, acc: 53.12%] [G loss: 1.941340]\n",
      "epoch:3 step:2853 [D loss: 0.580468, acc: 71.88%] [G loss: 1.879045]\n",
      "epoch:3 step:2854 [D loss: 0.756181, acc: 52.34%] [G loss: 2.059769]\n",
      "epoch:3 step:2855 [D loss: 0.710621, acc: 54.69%] [G loss: 1.797475]\n",
      "epoch:3 step:2856 [D loss: 0.576275, acc: 69.53%] [G loss: 1.840192]\n",
      "epoch:3 step:2857 [D loss: 0.975345, acc: 27.34%] [G loss: 1.645247]\n",
      "epoch:3 step:2858 [D loss: 0.589817, acc: 74.22%] [G loss: 2.088846]\n",
      "epoch:3 step:2859 [D loss: 0.574571, acc: 72.66%] [G loss: 1.959916]\n",
      "epoch:3 step:2860 [D loss: 0.839466, acc: 43.75%] [G loss: 1.912951]\n",
      "epoch:3 step:2861 [D loss: 0.908381, acc: 42.19%] [G loss: 1.782051]\n",
      "epoch:3 step:2862 [D loss: 0.970547, acc: 25.78%] [G loss: 1.602895]\n",
      "epoch:3 step:2863 [D loss: 0.679081, acc: 60.16%] [G loss: 2.194238]\n",
      "epoch:3 step:2864 [D loss: 0.600751, acc: 70.31%] [G loss: 2.065690]\n",
      "epoch:3 step:2865 [D loss: 0.604030, acc: 64.84%] [G loss: 1.811109]\n",
      "epoch:3 step:2866 [D loss: 0.614303, acc: 69.53%] [G loss: 1.830821]\n",
      "epoch:3 step:2867 [D loss: 0.872536, acc: 39.84%] [G loss: 1.695926]\n",
      "epoch:3 step:2868 [D loss: 0.460991, acc: 87.50%] [G loss: 2.029544]\n",
      "epoch:3 step:2869 [D loss: 0.823585, acc: 40.62%] [G loss: 1.837837]\n",
      "epoch:3 step:2870 [D loss: 0.551686, acc: 71.09%] [G loss: 2.481392]\n",
      "epoch:3 step:2871 [D loss: 0.624538, acc: 64.06%] [G loss: 2.093636]\n",
      "epoch:3 step:2872 [D loss: 0.368594, acc: 87.50%] [G loss: 1.963506]\n",
      "epoch:3 step:2873 [D loss: 0.474623, acc: 85.16%] [G loss: 1.998536]\n",
      "epoch:3 step:2874 [D loss: 0.795563, acc: 42.19%] [G loss: 1.616828]\n",
      "epoch:3 step:2875 [D loss: 0.807148, acc: 43.75%] [G loss: 1.578779]\n",
      "epoch:3 step:2876 [D loss: 0.649330, acc: 60.16%] [G loss: 1.713015]\n",
      "epoch:3 step:2877 [D loss: 0.934978, acc: 28.12%] [G loss: 1.397533]\n",
      "epoch:3 step:2878 [D loss: 0.798982, acc: 44.53%] [G loss: 1.676109]\n",
      "epoch:3 step:2879 [D loss: 0.648602, acc: 62.50%] [G loss: 1.822224]\n",
      "epoch:3 step:2880 [D loss: 0.973096, acc: 44.53%] [G loss: 1.280174]\n",
      "epoch:3 step:2881 [D loss: 0.700369, acc: 54.69%] [G loss: 1.691659]\n",
      "epoch:3 step:2882 [D loss: 0.597107, acc: 66.41%] [G loss: 1.805343]\n",
      "epoch:3 step:2883 [D loss: 0.867387, acc: 38.28%] [G loss: 1.469226]\n",
      "epoch:3 step:2884 [D loss: 0.663847, acc: 60.16%] [G loss: 1.898295]\n",
      "epoch:3 step:2885 [D loss: 0.900171, acc: 33.59%] [G loss: 1.548027]\n",
      "epoch:3 step:2886 [D loss: 0.660652, acc: 61.72%] [G loss: 1.905079]\n",
      "epoch:3 step:2887 [D loss: 0.583100, acc: 70.31%] [G loss: 1.865700]\n",
      "epoch:3 step:2888 [D loss: 0.773201, acc: 46.88%] [G loss: 1.612442]\n",
      "epoch:3 step:2889 [D loss: 0.734179, acc: 48.44%] [G loss: 1.787078]\n",
      "epoch:3 step:2890 [D loss: 0.730444, acc: 50.00%] [G loss: 1.793441]\n",
      "epoch:3 step:2891 [D loss: 0.741740, acc: 50.78%] [G loss: 1.544963]\n",
      "epoch:3 step:2892 [D loss: 0.694513, acc: 54.69%] [G loss: 1.932995]\n",
      "epoch:3 step:2893 [D loss: 0.491679, acc: 75.78%] [G loss: 2.213742]\n",
      "epoch:3 step:2894 [D loss: 0.624266, acc: 65.62%] [G loss: 1.708737]\n",
      "epoch:3 step:2895 [D loss: 0.827815, acc: 39.06%] [G loss: 1.484090]\n",
      "epoch:3 step:2896 [D loss: 0.819668, acc: 45.31%] [G loss: 1.607833]\n",
      "epoch:3 step:2897 [D loss: 0.689038, acc: 58.59%] [G loss: 1.824904]\n",
      "epoch:3 step:2898 [D loss: 0.590641, acc: 75.00%] [G loss: 1.908239]\n",
      "epoch:3 step:2899 [D loss: 0.828068, acc: 43.75%] [G loss: 1.872864]\n",
      "epoch:3 step:2900 [D loss: 0.704523, acc: 53.91%] [G loss: 1.943050]\n",
      "epoch:3 step:2901 [D loss: 0.612998, acc: 64.84%] [G loss: 1.944333]\n",
      "epoch:3 step:2902 [D loss: 0.724388, acc: 53.91%] [G loss: 1.930712]\n",
      "epoch:3 step:2903 [D loss: 0.764839, acc: 53.12%] [G loss: 1.676250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2904 [D loss: 0.677089, acc: 57.81%] [G loss: 1.906537]\n",
      "epoch:3 step:2905 [D loss: 0.592711, acc: 71.88%] [G loss: 1.962224]\n",
      "epoch:3 step:2906 [D loss: 0.654484, acc: 63.28%] [G loss: 1.681083]\n",
      "epoch:3 step:2907 [D loss: 0.599919, acc: 64.84%] [G loss: 1.827286]\n",
      "epoch:3 step:2908 [D loss: 0.633719, acc: 66.41%] [G loss: 2.154204]\n",
      "epoch:3 step:2909 [D loss: 0.736633, acc: 53.12%] [G loss: 1.826960]\n",
      "epoch:3 step:2910 [D loss: 0.577234, acc: 64.84%] [G loss: 1.847889]\n",
      "epoch:3 step:2911 [D loss: 0.499032, acc: 79.69%] [G loss: 1.865214]\n",
      "epoch:3 step:2912 [D loss: 0.639947, acc: 61.72%] [G loss: 1.567020]\n",
      "epoch:3 step:2913 [D loss: 0.623660, acc: 64.84%] [G loss: 1.498616]\n",
      "epoch:3 step:2914 [D loss: 0.615582, acc: 69.53%] [G loss: 1.973146]\n",
      "epoch:3 step:2915 [D loss: 0.680331, acc: 61.72%] [G loss: 2.015666]\n",
      "epoch:3 step:2916 [D loss: 0.508466, acc: 78.12%] [G loss: 1.851360]\n",
      "epoch:3 step:2917 [D loss: 0.922972, acc: 38.28%] [G loss: 1.861208]\n",
      "epoch:3 step:2918 [D loss: 0.661569, acc: 58.59%] [G loss: 1.706159]\n",
      "epoch:3 step:2919 [D loss: 0.548115, acc: 70.31%] [G loss: 1.934125]\n",
      "epoch:3 step:2920 [D loss: 0.687568, acc: 57.03%] [G loss: 1.751773]\n",
      "epoch:3 step:2921 [D loss: 0.574082, acc: 70.31%] [G loss: 1.910844]\n",
      "epoch:3 step:2922 [D loss: 0.792292, acc: 49.22%] [G loss: 1.659587]\n",
      "epoch:3 step:2923 [D loss: 0.705147, acc: 54.69%] [G loss: 1.785599]\n",
      "epoch:3 step:2924 [D loss: 0.611329, acc: 70.31%] [G loss: 2.248303]\n",
      "epoch:3 step:2925 [D loss: 0.638986, acc: 62.50%] [G loss: 1.828795]\n",
      "epoch:3 step:2926 [D loss: 0.639960, acc: 68.75%] [G loss: 2.097660]\n",
      "epoch:3 step:2927 [D loss: 0.881686, acc: 39.84%] [G loss: 1.592706]\n",
      "epoch:3 step:2928 [D loss: 0.797364, acc: 42.19%] [G loss: 1.906079]\n",
      "epoch:3 step:2929 [D loss: 0.646534, acc: 61.72%] [G loss: 1.833744]\n",
      "epoch:3 step:2930 [D loss: 0.690080, acc: 60.94%] [G loss: 1.810642]\n",
      "epoch:3 step:2931 [D loss: 0.605463, acc: 66.41%] [G loss: 2.173714]\n",
      "epoch:3 step:2932 [D loss: 0.726644, acc: 50.78%] [G loss: 1.948160]\n",
      "epoch:3 step:2933 [D loss: 0.580355, acc: 67.97%] [G loss: 1.830065]\n",
      "epoch:3 step:2934 [D loss: 0.556693, acc: 74.22%] [G loss: 1.704927]\n",
      "epoch:3 step:2935 [D loss: 0.647726, acc: 63.28%] [G loss: 1.802491]\n",
      "epoch:3 step:2936 [D loss: 0.601202, acc: 71.09%] [G loss: 1.778290]\n",
      "epoch:3 step:2937 [D loss: 0.594849, acc: 71.09%] [G loss: 2.012865]\n",
      "epoch:3 step:2938 [D loss: 0.743876, acc: 44.53%] [G loss: 1.800347]\n",
      "epoch:3 step:2939 [D loss: 0.859371, acc: 39.06%] [G loss: 1.665603]\n",
      "epoch:3 step:2940 [D loss: 0.647093, acc: 57.03%] [G loss: 2.007742]\n",
      "epoch:3 step:2941 [D loss: 0.545959, acc: 71.88%] [G loss: 2.130445]\n",
      "epoch:3 step:2942 [D loss: 0.717519, acc: 50.00%] [G loss: 1.674006]\n",
      "epoch:3 step:2943 [D loss: 0.715424, acc: 48.44%] [G loss: 1.930787]\n",
      "epoch:3 step:2944 [D loss: 0.674032, acc: 57.81%] [G loss: 1.983012]\n",
      "epoch:3 step:2945 [D loss: 0.650846, acc: 65.62%] [G loss: 2.122709]\n",
      "epoch:3 step:2946 [D loss: 0.658877, acc: 60.94%] [G loss: 1.852242]\n",
      "epoch:3 step:2947 [D loss: 0.922321, acc: 37.50%] [G loss: 1.727605]\n",
      "epoch:3 step:2948 [D loss: 0.740848, acc: 53.12%] [G loss: 1.603635]\n",
      "epoch:3 step:2949 [D loss: 0.759744, acc: 46.88%] [G loss: 1.777968]\n",
      "epoch:3 step:2950 [D loss: 0.727015, acc: 46.09%] [G loss: 1.804297]\n",
      "epoch:3 step:2951 [D loss: 0.723141, acc: 58.59%] [G loss: 1.636036]\n",
      "epoch:3 step:2952 [D loss: 0.777992, acc: 43.75%] [G loss: 1.578112]\n",
      "epoch:3 step:2953 [D loss: 0.890293, acc: 31.25%] [G loss: 1.539369]\n",
      "epoch:3 step:2954 [D loss: 0.759246, acc: 54.69%] [G loss: 1.798882]\n",
      "epoch:3 step:2955 [D loss: 0.692084, acc: 58.59%] [G loss: 1.676902]\n",
      "epoch:3 step:2956 [D loss: 0.983331, acc: 30.47%] [G loss: 1.988876]\n",
      "epoch:3 step:2957 [D loss: 0.729524, acc: 54.69%] [G loss: 1.719147]\n",
      "epoch:3 step:2958 [D loss: 0.615185, acc: 69.53%] [G loss: 1.942432]\n",
      "epoch:3 step:2959 [D loss: 0.762099, acc: 50.00%] [G loss: 1.570877]\n",
      "epoch:3 step:2960 [D loss: 0.744104, acc: 49.22%] [G loss: 2.167714]\n",
      "epoch:3 step:2961 [D loss: 0.673220, acc: 60.16%] [G loss: 1.751263]\n",
      "epoch:3 step:2962 [D loss: 0.715786, acc: 58.59%] [G loss: 1.585565]\n",
      "epoch:3 step:2963 [D loss: 0.631686, acc: 67.19%] [G loss: 1.791623]\n",
      "epoch:3 step:2964 [D loss: 0.639633, acc: 67.97%] [G loss: 1.952766]\n",
      "epoch:3 step:2965 [D loss: 0.603987, acc: 71.88%] [G loss: 2.015386]\n",
      "epoch:3 step:2966 [D loss: 0.897600, acc: 31.25%] [G loss: 1.826453]\n",
      "epoch:3 step:2967 [D loss: 0.680759, acc: 64.06%] [G loss: 1.973047]\n",
      "epoch:3 step:2968 [D loss: 0.556306, acc: 74.22%] [G loss: 2.006751]\n",
      "epoch:3 step:2969 [D loss: 0.828766, acc: 34.38%] [G loss: 1.743286]\n",
      "epoch:3 step:2970 [D loss: 0.856312, acc: 39.84%] [G loss: 1.579779]\n",
      "epoch:3 step:2971 [D loss: 0.853275, acc: 36.72%] [G loss: 1.583289]\n",
      "epoch:3 step:2972 [D loss: 0.632803, acc: 67.19%] [G loss: 1.911305]\n",
      "epoch:3 step:2973 [D loss: 0.736374, acc: 52.34%] [G loss: 1.664727]\n",
      "epoch:3 step:2974 [D loss: 0.770357, acc: 49.22%] [G loss: 1.683223]\n",
      "epoch:3 step:2975 [D loss: 0.866076, acc: 25.00%] [G loss: 1.407269]\n",
      "epoch:3 step:2976 [D loss: 0.744578, acc: 49.22%] [G loss: 2.011020]\n",
      "epoch:3 step:2977 [D loss: 0.561941, acc: 71.88%] [G loss: 1.859415]\n",
      "epoch:3 step:2978 [D loss: 0.714374, acc: 53.91%] [G loss: 1.802504]\n",
      "epoch:3 step:2979 [D loss: 0.788527, acc: 43.75%] [G loss: 1.621407]\n",
      "epoch:3 step:2980 [D loss: 0.775461, acc: 47.66%] [G loss: 1.541441]\n",
      "epoch:3 step:2981 [D loss: 0.895027, acc: 28.12%] [G loss: 1.621084]\n",
      "epoch:3 step:2982 [D loss: 0.824157, acc: 35.94%] [G loss: 1.617563]\n",
      "epoch:3 step:2983 [D loss: 0.833476, acc: 32.03%] [G loss: 1.626750]\n",
      "epoch:3 step:2984 [D loss: 0.707679, acc: 56.25%] [G loss: 1.753894]\n",
      "epoch:3 step:2985 [D loss: 0.633335, acc: 64.84%] [G loss: 1.624366]\n",
      "epoch:3 step:2986 [D loss: 0.784007, acc: 43.75%] [G loss: 1.480691]\n",
      "epoch:3 step:2987 [D loss: 0.666664, acc: 62.50%] [G loss: 1.834226]\n",
      "epoch:3 step:2988 [D loss: 0.545926, acc: 73.44%] [G loss: 1.677907]\n",
      "epoch:3 step:2989 [D loss: 0.912545, acc: 28.91%] [G loss: 1.655571]\n",
      "epoch:3 step:2990 [D loss: 0.677135, acc: 58.59%] [G loss: 1.781425]\n",
      "epoch:3 step:2991 [D loss: 0.623159, acc: 64.06%] [G loss: 1.643463]\n",
      "epoch:3 step:2992 [D loss: 0.954038, acc: 23.44%] [G loss: 1.517863]\n",
      "epoch:3 step:2993 [D loss: 0.752149, acc: 49.22%] [G loss: 1.891480]\n",
      "epoch:3 step:2994 [D loss: 0.584130, acc: 73.44%] [G loss: 1.819163]\n",
      "epoch:3 step:2995 [D loss: 0.594107, acc: 69.53%] [G loss: 2.031477]\n",
      "epoch:3 step:2996 [D loss: 0.581684, acc: 72.66%] [G loss: 2.111102]\n",
      "epoch:3 step:2997 [D loss: 0.718267, acc: 55.47%] [G loss: 1.777848]\n",
      "epoch:3 step:2998 [D loss: 0.618995, acc: 59.38%] [G loss: 1.693847]\n",
      "epoch:3 step:2999 [D loss: 0.758982, acc: 42.97%] [G loss: 1.704093]\n",
      "epoch:3 step:3000 [D loss: 0.636183, acc: 57.81%] [G loss: 1.876991]\n",
      "epoch:3 step:3001 [D loss: 0.582313, acc: 72.66%] [G loss: 1.892034]\n",
      "epoch:3 step:3002 [D loss: 0.712718, acc: 53.12%] [G loss: 1.763815]\n",
      "epoch:3 step:3003 [D loss: 0.764448, acc: 49.22%] [G loss: 1.542950]\n",
      "epoch:3 step:3004 [D loss: 0.836762, acc: 40.62%] [G loss: 1.717425]\n",
      "epoch:3 step:3005 [D loss: 0.605248, acc: 67.97%] [G loss: 1.905642]\n",
      "epoch:3 step:3006 [D loss: 0.630423, acc: 64.84%] [G loss: 2.008240]\n",
      "epoch:3 step:3007 [D loss: 0.734263, acc: 53.91%] [G loss: 1.866780]\n",
      "epoch:3 step:3008 [D loss: 0.577846, acc: 75.78%] [G loss: 1.949044]\n",
      "epoch:3 step:3009 [D loss: 0.629714, acc: 71.88%] [G loss: 1.878839]\n",
      "epoch:3 step:3010 [D loss: 0.749139, acc: 57.81%] [G loss: 1.599817]\n",
      "epoch:3 step:3011 [D loss: 0.552885, acc: 77.34%] [G loss: 2.012368]\n",
      "epoch:3 step:3012 [D loss: 0.623955, acc: 61.72%] [G loss: 1.747022]\n",
      "epoch:3 step:3013 [D loss: 0.569754, acc: 69.53%] [G loss: 1.678721]\n",
      "epoch:3 step:3014 [D loss: 0.771656, acc: 51.56%] [G loss: 1.734655]\n",
      "epoch:3 step:3015 [D loss: 0.750421, acc: 51.56%] [G loss: 1.654996]\n",
      "epoch:3 step:3016 [D loss: 0.671180, acc: 61.72%] [G loss: 2.011982]\n",
      "epoch:3 step:3017 [D loss: 0.470211, acc: 82.03%] [G loss: 2.031439]\n",
      "epoch:3 step:3018 [D loss: 0.697683, acc: 58.59%] [G loss: 1.730253]\n",
      "epoch:3 step:3019 [D loss: 0.649407, acc: 60.94%] [G loss: 1.809545]\n",
      "epoch:3 step:3020 [D loss: 0.515460, acc: 79.69%] [G loss: 2.124947]\n",
      "epoch:3 step:3021 [D loss: 0.622523, acc: 67.19%] [G loss: 1.730551]\n",
      "epoch:3 step:3022 [D loss: 0.591380, acc: 69.53%] [G loss: 1.628964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3023 [D loss: 0.492534, acc: 77.34%] [G loss: 1.954075]\n",
      "epoch:3 step:3024 [D loss: 0.722765, acc: 55.47%] [G loss: 1.890398]\n",
      "epoch:3 step:3025 [D loss: 0.563374, acc: 74.22%] [G loss: 1.864412]\n",
      "epoch:3 step:3026 [D loss: 0.695220, acc: 57.81%] [G loss: 1.929039]\n",
      "epoch:3 step:3027 [D loss: 0.649303, acc: 64.84%] [G loss: 1.626711]\n",
      "epoch:3 step:3028 [D loss: 0.644740, acc: 62.50%] [G loss: 1.709277]\n",
      "epoch:3 step:3029 [D loss: 0.726928, acc: 57.03%] [G loss: 1.697314]\n",
      "epoch:3 step:3030 [D loss: 0.476887, acc: 82.81%] [G loss: 2.024308]\n",
      "epoch:3 step:3031 [D loss: 0.695506, acc: 58.59%] [G loss: 1.860546]\n",
      "epoch:3 step:3032 [D loss: 0.971684, acc: 21.09%] [G loss: 1.592216]\n",
      "epoch:3 step:3033 [D loss: 0.747254, acc: 46.09%] [G loss: 1.812767]\n",
      "epoch:3 step:3034 [D loss: 0.708557, acc: 53.91%] [G loss: 1.847705]\n",
      "epoch:3 step:3035 [D loss: 0.784946, acc: 46.09%] [G loss: 1.980111]\n",
      "epoch:3 step:3036 [D loss: 0.736142, acc: 50.78%] [G loss: 1.856017]\n",
      "epoch:3 step:3037 [D loss: 0.508069, acc: 79.69%] [G loss: 2.254506]\n",
      "epoch:3 step:3038 [D loss: 0.623166, acc: 67.97%] [G loss: 1.924667]\n",
      "epoch:3 step:3039 [D loss: 0.771367, acc: 39.84%] [G loss: 1.707453]\n",
      "epoch:3 step:3040 [D loss: 0.671337, acc: 59.38%] [G loss: 2.038161]\n",
      "epoch:3 step:3041 [D loss: 0.638863, acc: 67.19%] [G loss: 2.020697]\n",
      "epoch:3 step:3042 [D loss: 0.534477, acc: 76.56%] [G loss: 1.765029]\n",
      "epoch:3 step:3043 [D loss: 0.594116, acc: 74.22%] [G loss: 1.864382]\n",
      "epoch:3 step:3044 [D loss: 0.561383, acc: 77.34%] [G loss: 1.891252]\n",
      "epoch:3 step:3045 [D loss: 0.729731, acc: 57.81%] [G loss: 1.490946]\n",
      "epoch:3 step:3046 [D loss: 0.589135, acc: 62.50%] [G loss: 1.722520]\n",
      "epoch:3 step:3047 [D loss: 0.550869, acc: 74.22%] [G loss: 1.632543]\n",
      "epoch:3 step:3048 [D loss: 0.561033, acc: 67.97%] [G loss: 2.002166]\n",
      "epoch:3 step:3049 [D loss: 0.633900, acc: 67.97%] [G loss: 1.624964]\n",
      "epoch:3 step:3050 [D loss: 0.549606, acc: 75.00%] [G loss: 1.666387]\n",
      "epoch:3 step:3051 [D loss: 0.803858, acc: 46.09%] [G loss: 1.515178]\n",
      "epoch:3 step:3052 [D loss: 0.860625, acc: 44.53%] [G loss: 1.442387]\n",
      "epoch:3 step:3053 [D loss: 0.689436, acc: 57.03%] [G loss: 1.687917]\n",
      "epoch:3 step:3054 [D loss: 0.457947, acc: 82.03%] [G loss: 1.854913]\n",
      "epoch:3 step:3055 [D loss: 0.727839, acc: 51.56%] [G loss: 1.398757]\n",
      "epoch:3 step:3056 [D loss: 0.877815, acc: 33.59%] [G loss: 1.468652]\n",
      "epoch:3 step:3057 [D loss: 0.674800, acc: 64.84%] [G loss: 1.841460]\n",
      "epoch:3 step:3058 [D loss: 0.614749, acc: 63.28%] [G loss: 1.720287]\n",
      "epoch:3 step:3059 [D loss: 0.620258, acc: 67.19%] [G loss: 1.598645]\n",
      "epoch:3 step:3060 [D loss: 0.692395, acc: 55.47%] [G loss: 1.665680]\n",
      "epoch:3 step:3061 [D loss: 0.752610, acc: 53.91%] [G loss: 1.504368]\n",
      "epoch:3 step:3062 [D loss: 0.678523, acc: 57.03%] [G loss: 1.894475]\n",
      "epoch:3 step:3063 [D loss: 0.557463, acc: 67.97%] [G loss: 1.942059]\n",
      "epoch:3 step:3064 [D loss: 0.788951, acc: 48.44%] [G loss: 1.720572]\n",
      "epoch:3 step:3065 [D loss: 0.702844, acc: 57.81%] [G loss: 1.778940]\n",
      "epoch:3 step:3066 [D loss: 0.724806, acc: 52.34%] [G loss: 2.182094]\n",
      "epoch:3 step:3067 [D loss: 0.712818, acc: 54.69%] [G loss: 1.749664]\n",
      "epoch:3 step:3068 [D loss: 0.877838, acc: 37.50%] [G loss: 1.877402]\n",
      "epoch:3 step:3069 [D loss: 0.699588, acc: 57.81%] [G loss: 2.067869]\n",
      "epoch:3 step:3070 [D loss: 0.882331, acc: 34.38%] [G loss: 1.626241]\n",
      "epoch:3 step:3071 [D loss: 0.629766, acc: 66.41%] [G loss: 1.952475]\n",
      "epoch:3 step:3072 [D loss: 0.606879, acc: 67.19%] [G loss: 2.045208]\n",
      "epoch:3 step:3073 [D loss: 0.695414, acc: 56.25%] [G loss: 1.939816]\n",
      "epoch:3 step:3074 [D loss: 0.649134, acc: 60.94%] [G loss: 2.066810]\n",
      "epoch:3 step:3075 [D loss: 0.538570, acc: 79.69%] [G loss: 2.096087]\n",
      "epoch:3 step:3076 [D loss: 0.580965, acc: 67.97%] [G loss: 1.838783]\n",
      "epoch:3 step:3077 [D loss: 0.661159, acc: 56.25%] [G loss: 1.970624]\n",
      "epoch:3 step:3078 [D loss: 0.777359, acc: 46.88%] [G loss: 1.530070]\n",
      "epoch:3 step:3079 [D loss: 0.494232, acc: 79.69%] [G loss: 1.743908]\n",
      "epoch:3 step:3080 [D loss: 0.570688, acc: 71.88%] [G loss: 1.811075]\n",
      "epoch:3 step:3081 [D loss: 0.486317, acc: 79.69%] [G loss: 2.021822]\n",
      "epoch:3 step:3082 [D loss: 0.466264, acc: 77.34%] [G loss: 2.163644]\n",
      "epoch:3 step:3083 [D loss: 0.679687, acc: 57.03%] [G loss: 1.627963]\n",
      "epoch:3 step:3084 [D loss: 0.628880, acc: 63.28%] [G loss: 1.669059]\n",
      "epoch:3 step:3085 [D loss: 0.477685, acc: 87.50%] [G loss: 1.931127]\n",
      "epoch:3 step:3086 [D loss: 0.825598, acc: 44.53%] [G loss: 1.776949]\n",
      "epoch:3 step:3087 [D loss: 0.605985, acc: 67.97%] [G loss: 1.786880]\n",
      "epoch:3 step:3088 [D loss: 0.764855, acc: 45.31%] [G loss: 1.662056]\n",
      "epoch:3 step:3089 [D loss: 0.609540, acc: 67.19%] [G loss: 1.849795]\n",
      "epoch:3 step:3090 [D loss: 0.947059, acc: 35.94%] [G loss: 1.445220]\n",
      "epoch:3 step:3091 [D loss: 0.800374, acc: 45.31%] [G loss: 1.833712]\n",
      "epoch:3 step:3092 [D loss: 0.705741, acc: 57.81%] [G loss: 1.819193]\n",
      "epoch:3 step:3093 [D loss: 0.741883, acc: 48.44%] [G loss: 1.573973]\n",
      "epoch:3 step:3094 [D loss: 0.940708, acc: 38.28%] [G loss: 1.851063]\n",
      "epoch:3 step:3095 [D loss: 0.695822, acc: 57.03%] [G loss: 1.654696]\n",
      "epoch:3 step:3096 [D loss: 0.646290, acc: 63.28%] [G loss: 1.946755]\n",
      "epoch:3 step:3097 [D loss: 0.523128, acc: 78.91%] [G loss: 2.214036]\n",
      "epoch:3 step:3098 [D loss: 0.685043, acc: 64.06%] [G loss: 1.869680]\n",
      "epoch:3 step:3099 [D loss: 0.663969, acc: 62.50%] [G loss: 1.746206]\n",
      "epoch:3 step:3100 [D loss: 0.619025, acc: 66.41%] [G loss: 1.889684]\n",
      "epoch:3 step:3101 [D loss: 0.726152, acc: 53.12%] [G loss: 1.805458]\n",
      "epoch:3 step:3102 [D loss: 0.721653, acc: 51.56%] [G loss: 1.784294]\n",
      "epoch:3 step:3103 [D loss: 0.506479, acc: 78.91%] [G loss: 1.962476]\n",
      "epoch:3 step:3104 [D loss: 0.668450, acc: 59.38%] [G loss: 1.891248]\n",
      "epoch:3 step:3105 [D loss: 0.757861, acc: 52.34%] [G loss: 1.843459]\n",
      "epoch:3 step:3106 [D loss: 0.954294, acc: 32.03%] [G loss: 1.690254]\n",
      "epoch:3 step:3107 [D loss: 0.773891, acc: 44.53%] [G loss: 1.629923]\n",
      "epoch:3 step:3108 [D loss: 0.759956, acc: 42.97%] [G loss: 1.681968]\n",
      "epoch:3 step:3109 [D loss: 0.665540, acc: 54.69%] [G loss: 1.788225]\n",
      "epoch:3 step:3110 [D loss: 0.696332, acc: 52.34%] [G loss: 1.735857]\n",
      "epoch:3 step:3111 [D loss: 0.715317, acc: 53.91%] [G loss: 1.721267]\n",
      "epoch:3 step:3112 [D loss: 0.776419, acc: 50.78%] [G loss: 1.615737]\n",
      "epoch:3 step:3113 [D loss: 0.739574, acc: 50.78%] [G loss: 1.821562]\n",
      "epoch:3 step:3114 [D loss: 0.687552, acc: 60.94%] [G loss: 1.849682]\n",
      "epoch:3 step:3115 [D loss: 0.696138, acc: 58.59%] [G loss: 1.695880]\n",
      "epoch:3 step:3116 [D loss: 0.761144, acc: 47.66%] [G loss: 1.716737]\n",
      "epoch:3 step:3117 [D loss: 0.757276, acc: 44.53%] [G loss: 1.774359]\n",
      "epoch:3 step:3118 [D loss: 0.612331, acc: 70.31%] [G loss: 2.054689]\n",
      "epoch:3 step:3119 [D loss: 0.745036, acc: 50.00%] [G loss: 1.725549]\n",
      "epoch:3 step:3120 [D loss: 0.990391, acc: 28.12%] [G loss: 1.684489]\n",
      "epoch:3 step:3121 [D loss: 0.648401, acc: 60.16%] [G loss: 1.738922]\n",
      "epoch:3 step:3122 [D loss: 0.797192, acc: 47.66%] [G loss: 1.795980]\n",
      "epoch:3 step:3123 [D loss: 0.752088, acc: 51.56%] [G loss: 1.824854]\n",
      "epoch:3 step:3124 [D loss: 0.607081, acc: 71.09%] [G loss: 1.784951]\n",
      "epoch:4 step:3125 [D loss: 0.876019, acc: 32.81%] [G loss: 1.713519]\n",
      "epoch:4 step:3126 [D loss: 0.685411, acc: 57.03%] [G loss: 1.894730]\n",
      "epoch:4 step:3127 [D loss: 0.661042, acc: 60.16%] [G loss: 1.933293]\n",
      "epoch:4 step:3128 [D loss: 0.526743, acc: 78.12%] [G loss: 2.205482]\n",
      "epoch:4 step:3129 [D loss: 0.611658, acc: 64.06%] [G loss: 2.030916]\n",
      "epoch:4 step:3130 [D loss: 0.570944, acc: 67.97%] [G loss: 2.198115]\n",
      "epoch:4 step:3131 [D loss: 0.677796, acc: 58.59%] [G loss: 1.837398]\n",
      "epoch:4 step:3132 [D loss: 0.476971, acc: 81.25%] [G loss: 1.994966]\n",
      "epoch:4 step:3133 [D loss: 0.567145, acc: 69.53%] [G loss: 1.859094]\n",
      "epoch:4 step:3134 [D loss: 0.745211, acc: 53.91%] [G loss: 1.668732]\n",
      "epoch:4 step:3135 [D loss: 0.402427, acc: 91.41%] [G loss: 1.814382]\n",
      "epoch:4 step:3136 [D loss: 0.659271, acc: 64.84%] [G loss: 1.812524]\n",
      "epoch:4 step:3137 [D loss: 0.668530, acc: 60.16%] [G loss: 1.579671]\n",
      "epoch:4 step:3138 [D loss: 1.152485, acc: 17.97%] [G loss: 1.382346]\n",
      "epoch:4 step:3139 [D loss: 0.744234, acc: 48.44%] [G loss: 1.616582]\n",
      "epoch:4 step:3140 [D loss: 0.688475, acc: 56.25%] [G loss: 1.740889]\n",
      "epoch:4 step:3141 [D loss: 0.615559, acc: 64.84%] [G loss: 1.686404]\n",
      "epoch:4 step:3142 [D loss: 0.640827, acc: 64.84%] [G loss: 1.753258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3143 [D loss: 0.710845, acc: 56.25%] [G loss: 1.605674]\n",
      "epoch:4 step:3144 [D loss: 0.803761, acc: 38.28%] [G loss: 1.494700]\n",
      "epoch:4 step:3145 [D loss: 0.770241, acc: 50.00%] [G loss: 1.545398]\n",
      "epoch:4 step:3146 [D loss: 0.637569, acc: 66.41%] [G loss: 1.777769]\n",
      "epoch:4 step:3147 [D loss: 0.722993, acc: 52.34%] [G loss: 1.601081]\n",
      "epoch:4 step:3148 [D loss: 0.728647, acc: 49.22%] [G loss: 1.562701]\n",
      "epoch:4 step:3149 [D loss: 0.937605, acc: 38.28%] [G loss: 1.681419]\n",
      "epoch:4 step:3150 [D loss: 0.729822, acc: 49.22%] [G loss: 1.665726]\n",
      "epoch:4 step:3151 [D loss: 0.753211, acc: 53.12%] [G loss: 1.682692]\n",
      "epoch:4 step:3152 [D loss: 0.832470, acc: 40.62%] [G loss: 1.640553]\n",
      "epoch:4 step:3153 [D loss: 0.548793, acc: 76.56%] [G loss: 1.953262]\n",
      "epoch:4 step:3154 [D loss: 0.734878, acc: 48.44%] [G loss: 1.737482]\n",
      "epoch:4 step:3155 [D loss: 0.722323, acc: 52.34%] [G loss: 1.668650]\n",
      "epoch:4 step:3156 [D loss: 0.623465, acc: 65.62%] [G loss: 1.820899]\n",
      "epoch:4 step:3157 [D loss: 0.569190, acc: 68.75%] [G loss: 1.847856]\n",
      "epoch:4 step:3158 [D loss: 0.609442, acc: 65.62%] [G loss: 2.002867]\n",
      "epoch:4 step:3159 [D loss: 0.592393, acc: 74.22%] [G loss: 1.828253]\n",
      "epoch:4 step:3160 [D loss: 0.561880, acc: 74.22%] [G loss: 1.883464]\n",
      "epoch:4 step:3161 [D loss: 0.712498, acc: 47.66%] [G loss: 1.789532]\n",
      "epoch:4 step:3162 [D loss: 0.780466, acc: 50.00%] [G loss: 1.742642]\n",
      "epoch:4 step:3163 [D loss: 0.613814, acc: 65.62%] [G loss: 1.866212]\n",
      "epoch:4 step:3164 [D loss: 0.515106, acc: 83.59%] [G loss: 1.812751]\n",
      "epoch:4 step:3165 [D loss: 0.518391, acc: 82.03%] [G loss: 2.039683]\n",
      "epoch:4 step:3166 [D loss: 0.809045, acc: 48.44%] [G loss: 1.776333]\n",
      "epoch:4 step:3167 [D loss: 0.736203, acc: 53.12%] [G loss: 1.692704]\n",
      "epoch:4 step:3168 [D loss: 0.740840, acc: 57.03%] [G loss: 1.631517]\n",
      "epoch:4 step:3169 [D loss: 0.612520, acc: 60.94%] [G loss: 2.090304]\n",
      "epoch:4 step:3170 [D loss: 0.735620, acc: 51.56%] [G loss: 1.917165]\n",
      "epoch:4 step:3171 [D loss: 0.750188, acc: 51.56%] [G loss: 1.561555]\n",
      "epoch:4 step:3172 [D loss: 0.821157, acc: 39.84%] [G loss: 1.481780]\n",
      "epoch:4 step:3173 [D loss: 0.585925, acc: 71.09%] [G loss: 1.899127]\n",
      "epoch:4 step:3174 [D loss: 0.749834, acc: 50.78%] [G loss: 2.013224]\n",
      "epoch:4 step:3175 [D loss: 0.723178, acc: 57.81%] [G loss: 1.939499]\n",
      "epoch:4 step:3176 [D loss: 0.555211, acc: 67.19%] [G loss: 1.887033]\n",
      "epoch:4 step:3177 [D loss: 0.718113, acc: 55.47%] [G loss: 1.698707]\n",
      "epoch:4 step:3178 [D loss: 0.596150, acc: 66.41%] [G loss: 1.904306]\n",
      "epoch:4 step:3179 [D loss: 0.793578, acc: 38.28%] [G loss: 1.661909]\n",
      "epoch:4 step:3180 [D loss: 0.661163, acc: 61.72%] [G loss: 1.989536]\n",
      "epoch:4 step:3181 [D loss: 0.495542, acc: 82.81%] [G loss: 1.596632]\n",
      "epoch:4 step:3182 [D loss: 0.575599, acc: 68.75%] [G loss: 1.707941]\n",
      "epoch:4 step:3183 [D loss: 0.789264, acc: 55.47%] [G loss: 1.611179]\n",
      "epoch:4 step:3184 [D loss: 0.708238, acc: 51.56%] [G loss: 1.657438]\n",
      "epoch:4 step:3185 [D loss: 0.807651, acc: 36.72%] [G loss: 1.480775]\n",
      "epoch:4 step:3186 [D loss: 0.521596, acc: 68.75%] [G loss: 1.878884]\n",
      "epoch:4 step:3187 [D loss: 0.602563, acc: 67.19%] [G loss: 1.732024]\n",
      "epoch:4 step:3188 [D loss: 0.554417, acc: 76.56%] [G loss: 1.851133]\n",
      "epoch:4 step:3189 [D loss: 0.513502, acc: 75.78%] [G loss: 2.002903]\n",
      "epoch:4 step:3190 [D loss: 0.692773, acc: 55.47%] [G loss: 2.002795]\n",
      "epoch:4 step:3191 [D loss: 0.931201, acc: 35.94%] [G loss: 1.564820]\n",
      "epoch:4 step:3192 [D loss: 0.619130, acc: 70.31%] [G loss: 1.968555]\n",
      "epoch:4 step:3193 [D loss: 0.549687, acc: 69.53%] [G loss: 1.911633]\n",
      "epoch:4 step:3194 [D loss: 0.847059, acc: 42.97%] [G loss: 1.661970]\n",
      "epoch:4 step:3195 [D loss: 0.794385, acc: 42.19%] [G loss: 1.661621]\n",
      "epoch:4 step:3196 [D loss: 0.849144, acc: 40.62%] [G loss: 1.589164]\n",
      "epoch:4 step:3197 [D loss: 0.721628, acc: 51.56%] [G loss: 1.611738]\n",
      "epoch:4 step:3198 [D loss: 0.752727, acc: 50.78%] [G loss: 1.635499]\n",
      "epoch:4 step:3199 [D loss: 0.805906, acc: 36.72%] [G loss: 1.557530]\n",
      "epoch:4 step:3200 [D loss: 0.814375, acc: 44.53%] [G loss: 1.487948]\n",
      "epoch:4 step:3201 [D loss: 0.794806, acc: 46.88%] [G loss: 1.635198]\n",
      "epoch:4 step:3202 [D loss: 0.554992, acc: 74.22%] [G loss: 1.790301]\n",
      "epoch:4 step:3203 [D loss: 0.614815, acc: 67.97%] [G loss: 1.908531]\n",
      "epoch:4 step:3204 [D loss: 0.622457, acc: 65.62%] [G loss: 1.915350]\n",
      "epoch:4 step:3205 [D loss: 0.670235, acc: 57.81%] [G loss: 1.739559]\n",
      "epoch:4 step:3206 [D loss: 0.782827, acc: 40.62%] [G loss: 1.749873]\n",
      "epoch:4 step:3207 [D loss: 0.898586, acc: 28.91%] [G loss: 1.613257]\n",
      "epoch:4 step:3208 [D loss: 0.886476, acc: 35.16%] [G loss: 1.641572]\n",
      "epoch:4 step:3209 [D loss: 0.516971, acc: 78.12%] [G loss: 1.915692]\n",
      "epoch:4 step:3210 [D loss: 0.662616, acc: 59.38%] [G loss: 1.765415]\n",
      "epoch:4 step:3211 [D loss: 0.763648, acc: 45.31%] [G loss: 1.801762]\n",
      "epoch:4 step:3212 [D loss: 0.782539, acc: 42.19%] [G loss: 1.672717]\n",
      "epoch:4 step:3213 [D loss: 0.611757, acc: 63.28%] [G loss: 1.939579]\n",
      "epoch:4 step:3214 [D loss: 0.668119, acc: 54.69%] [G loss: 1.725843]\n",
      "epoch:4 step:3215 [D loss: 0.771378, acc: 52.34%] [G loss: 1.745326]\n",
      "epoch:4 step:3216 [D loss: 0.690421, acc: 57.81%] [G loss: 1.737449]\n",
      "epoch:4 step:3217 [D loss: 0.625303, acc: 69.53%] [G loss: 2.040800]\n",
      "epoch:4 step:3218 [D loss: 0.559916, acc: 69.53%] [G loss: 1.938955]\n",
      "epoch:4 step:3219 [D loss: 0.693266, acc: 60.16%] [G loss: 1.727639]\n",
      "epoch:4 step:3220 [D loss: 0.745730, acc: 50.00%] [G loss: 1.773009]\n",
      "epoch:4 step:3221 [D loss: 0.770371, acc: 46.09%] [G loss: 1.745442]\n",
      "epoch:4 step:3222 [D loss: 0.714529, acc: 54.69%] [G loss: 1.816151]\n",
      "epoch:4 step:3223 [D loss: 0.646031, acc: 63.28%] [G loss: 1.860615]\n",
      "epoch:4 step:3224 [D loss: 0.645559, acc: 66.41%] [G loss: 1.841621]\n",
      "epoch:4 step:3225 [D loss: 0.517188, acc: 73.44%] [G loss: 1.907879]\n",
      "epoch:4 step:3226 [D loss: 0.619985, acc: 70.31%] [G loss: 1.810791]\n",
      "epoch:4 step:3227 [D loss: 0.840330, acc: 35.16%] [G loss: 1.622301]\n",
      "epoch:4 step:3228 [D loss: 0.729676, acc: 48.44%] [G loss: 1.877824]\n",
      "epoch:4 step:3229 [D loss: 0.646254, acc: 61.72%] [G loss: 1.780369]\n",
      "epoch:4 step:3230 [D loss: 0.577716, acc: 72.66%] [G loss: 1.784820]\n",
      "epoch:4 step:3231 [D loss: 0.916542, acc: 34.38%] [G loss: 1.716365]\n",
      "epoch:4 step:3232 [D loss: 0.687790, acc: 51.56%] [G loss: 1.837954]\n",
      "epoch:4 step:3233 [D loss: 0.742273, acc: 46.88%] [G loss: 1.659762]\n",
      "epoch:4 step:3234 [D loss: 0.769860, acc: 47.66%] [G loss: 1.745713]\n",
      "epoch:4 step:3235 [D loss: 0.659987, acc: 61.72%] [G loss: 1.667782]\n",
      "epoch:4 step:3236 [D loss: 0.668631, acc: 60.94%] [G loss: 1.609498]\n",
      "epoch:4 step:3237 [D loss: 0.663811, acc: 64.06%] [G loss: 1.919135]\n",
      "epoch:4 step:3238 [D loss: 0.730554, acc: 50.78%] [G loss: 1.917601]\n",
      "epoch:4 step:3239 [D loss: 0.606953, acc: 72.66%] [G loss: 1.711604]\n",
      "epoch:4 step:3240 [D loss: 0.658430, acc: 60.94%] [G loss: 1.757442]\n",
      "epoch:4 step:3241 [D loss: 0.825631, acc: 42.97%] [G loss: 1.753727]\n",
      "epoch:4 step:3242 [D loss: 0.732834, acc: 52.34%] [G loss: 1.997214]\n",
      "epoch:4 step:3243 [D loss: 0.702570, acc: 54.69%] [G loss: 1.958999]\n",
      "epoch:4 step:3244 [D loss: 0.588581, acc: 70.31%] [G loss: 1.675774]\n",
      "epoch:4 step:3245 [D loss: 0.729068, acc: 50.00%] [G loss: 1.759821]\n",
      "epoch:4 step:3246 [D loss: 0.645345, acc: 64.84%] [G loss: 1.785630]\n",
      "epoch:4 step:3247 [D loss: 0.695547, acc: 59.38%] [G loss: 1.610684]\n",
      "epoch:4 step:3248 [D loss: 0.616362, acc: 69.53%] [G loss: 2.009495]\n",
      "epoch:4 step:3249 [D loss: 0.753483, acc: 45.31%] [G loss: 1.470070]\n",
      "epoch:4 step:3250 [D loss: 0.872013, acc: 39.06%] [G loss: 1.602958]\n",
      "epoch:4 step:3251 [D loss: 0.773062, acc: 45.31%] [G loss: 1.714524]\n",
      "epoch:4 step:3252 [D loss: 0.600839, acc: 67.97%] [G loss: 1.957599]\n",
      "epoch:4 step:3253 [D loss: 0.615012, acc: 64.84%] [G loss: 1.996715]\n",
      "epoch:4 step:3254 [D loss: 0.854306, acc: 45.31%] [G loss: 1.451714]\n",
      "epoch:4 step:3255 [D loss: 0.687125, acc: 60.16%] [G loss: 1.832051]\n",
      "epoch:4 step:3256 [D loss: 0.541616, acc: 78.12%] [G loss: 1.976436]\n",
      "epoch:4 step:3257 [D loss: 0.595297, acc: 68.75%] [G loss: 1.819944]\n",
      "epoch:4 step:3258 [D loss: 0.675488, acc: 57.81%] [G loss: 1.860122]\n",
      "epoch:4 step:3259 [D loss: 0.805828, acc: 49.22%] [G loss: 1.659549]\n",
      "epoch:4 step:3260 [D loss: 0.717992, acc: 53.12%] [G loss: 2.045521]\n",
      "epoch:4 step:3261 [D loss: 0.681774, acc: 57.03%] [G loss: 1.604187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3262 [D loss: 0.724971, acc: 51.56%] [G loss: 1.978273]\n",
      "epoch:4 step:3263 [D loss: 0.549240, acc: 72.66%] [G loss: 1.936442]\n",
      "epoch:4 step:3264 [D loss: 0.677028, acc: 55.47%] [G loss: 1.857970]\n",
      "epoch:4 step:3265 [D loss: 0.716760, acc: 49.22%] [G loss: 1.775697]\n",
      "epoch:4 step:3266 [D loss: 0.635284, acc: 64.06%] [G loss: 1.809615]\n",
      "epoch:4 step:3267 [D loss: 0.682256, acc: 60.16%] [G loss: 1.663350]\n",
      "epoch:4 step:3268 [D loss: 0.766876, acc: 46.09%] [G loss: 1.755909]\n",
      "epoch:4 step:3269 [D loss: 0.645049, acc: 60.94%] [G loss: 1.948733]\n",
      "epoch:4 step:3270 [D loss: 0.488607, acc: 76.56%] [G loss: 1.805401]\n",
      "epoch:4 step:3271 [D loss: 0.809011, acc: 45.31%] [G loss: 1.992577]\n",
      "epoch:4 step:3272 [D loss: 0.593036, acc: 68.75%] [G loss: 1.975876]\n",
      "epoch:4 step:3273 [D loss: 0.600141, acc: 67.19%] [G loss: 2.041164]\n",
      "epoch:4 step:3274 [D loss: 0.698966, acc: 54.69%] [G loss: 1.595105]\n",
      "epoch:4 step:3275 [D loss: 0.637691, acc: 65.62%] [G loss: 1.749444]\n",
      "epoch:4 step:3276 [D loss: 0.691639, acc: 60.94%] [G loss: 1.742760]\n",
      "epoch:4 step:3277 [D loss: 0.648042, acc: 59.38%] [G loss: 1.672294]\n",
      "epoch:4 step:3278 [D loss: 0.603880, acc: 64.84%] [G loss: 1.449064]\n",
      "epoch:4 step:3279 [D loss: 0.432914, acc: 82.03%] [G loss: 1.782466]\n",
      "epoch:4 step:3280 [D loss: 0.725525, acc: 51.56%] [G loss: 1.383999]\n",
      "epoch:4 step:3281 [D loss: 0.743280, acc: 52.34%] [G loss: 1.765221]\n",
      "epoch:4 step:3282 [D loss: 0.682363, acc: 60.94%] [G loss: 1.421141]\n",
      "epoch:4 step:3283 [D loss: 0.659855, acc: 64.06%] [G loss: 1.456101]\n",
      "epoch:4 step:3284 [D loss: 0.710773, acc: 54.69%] [G loss: 1.449890]\n",
      "epoch:4 step:3285 [D loss: 0.608719, acc: 67.19%] [G loss: 1.629022]\n",
      "epoch:4 step:3286 [D loss: 0.814267, acc: 47.66%] [G loss: 1.654438]\n",
      "epoch:4 step:3287 [D loss: 0.791381, acc: 43.75%] [G loss: 1.494907]\n",
      "epoch:4 step:3288 [D loss: 0.866162, acc: 27.34%] [G loss: 1.487176]\n",
      "epoch:4 step:3289 [D loss: 0.673743, acc: 57.81%] [G loss: 1.595220]\n",
      "epoch:4 step:3290 [D loss: 0.769438, acc: 42.97%] [G loss: 1.732089]\n",
      "epoch:4 step:3291 [D loss: 0.694143, acc: 58.59%] [G loss: 1.908522]\n",
      "epoch:4 step:3292 [D loss: 0.651088, acc: 63.28%] [G loss: 1.813396]\n",
      "epoch:4 step:3293 [D loss: 0.655292, acc: 59.38%] [G loss: 1.911164]\n",
      "epoch:4 step:3294 [D loss: 0.621944, acc: 63.28%] [G loss: 1.922396]\n",
      "epoch:4 step:3295 [D loss: 0.810037, acc: 39.84%] [G loss: 1.841478]\n",
      "epoch:4 step:3296 [D loss: 0.663549, acc: 60.16%] [G loss: 1.944623]\n",
      "epoch:4 step:3297 [D loss: 0.681096, acc: 56.25%] [G loss: 1.576878]\n",
      "epoch:4 step:3298 [D loss: 0.614622, acc: 66.41%] [G loss: 2.207020]\n",
      "epoch:4 step:3299 [D loss: 0.590952, acc: 75.00%] [G loss: 1.911257]\n",
      "epoch:4 step:3300 [D loss: 0.787924, acc: 48.44%] [G loss: 1.862449]\n",
      "epoch:4 step:3301 [D loss: 0.600817, acc: 75.00%] [G loss: 2.124022]\n",
      "epoch:4 step:3302 [D loss: 0.626710, acc: 66.41%] [G loss: 1.870029]\n",
      "epoch:4 step:3303 [D loss: 0.575487, acc: 71.09%] [G loss: 2.370521]\n",
      "epoch:4 step:3304 [D loss: 0.705162, acc: 57.81%] [G loss: 1.965180]\n",
      "epoch:4 step:3305 [D loss: 0.534628, acc: 74.22%] [G loss: 2.508744]\n",
      "epoch:4 step:3306 [D loss: 0.635969, acc: 63.28%] [G loss: 2.228635]\n",
      "epoch:4 step:3307 [D loss: 0.571728, acc: 76.56%] [G loss: 1.989481]\n",
      "epoch:4 step:3308 [D loss: 0.809467, acc: 42.97%] [G loss: 2.149606]\n",
      "epoch:4 step:3309 [D loss: 0.659303, acc: 58.59%] [G loss: 1.918357]\n",
      "epoch:4 step:3310 [D loss: 0.579957, acc: 70.31%] [G loss: 2.004631]\n",
      "epoch:4 step:3311 [D loss: 0.670758, acc: 59.38%] [G loss: 1.890335]\n",
      "epoch:4 step:3312 [D loss: 0.556301, acc: 75.00%] [G loss: 2.171234]\n",
      "epoch:4 step:3313 [D loss: 0.589088, acc: 70.31%] [G loss: 1.990453]\n",
      "epoch:4 step:3314 [D loss: 0.662691, acc: 63.28%] [G loss: 1.602084]\n",
      "epoch:4 step:3315 [D loss: 0.613460, acc: 67.19%] [G loss: 1.810908]\n",
      "epoch:4 step:3316 [D loss: 0.549447, acc: 75.00%] [G loss: 1.746080]\n",
      "epoch:4 step:3317 [D loss: 0.652067, acc: 53.12%] [G loss: 2.170456]\n",
      "epoch:4 step:3318 [D loss: 0.577896, acc: 75.00%] [G loss: 1.899559]\n",
      "epoch:4 step:3319 [D loss: 0.662464, acc: 57.81%] [G loss: 1.667363]\n",
      "epoch:4 step:3320 [D loss: 0.344492, acc: 92.19%] [G loss: 1.834495]\n",
      "epoch:4 step:3321 [D loss: 0.674750, acc: 53.12%] [G loss: 1.618633]\n",
      "epoch:4 step:3322 [D loss: 0.756048, acc: 53.12%] [G loss: 1.642016]\n",
      "epoch:4 step:3323 [D loss: 0.436984, acc: 75.78%] [G loss: 1.923595]\n",
      "epoch:4 step:3324 [D loss: 0.459062, acc: 82.81%] [G loss: 1.671310]\n",
      "epoch:4 step:3325 [D loss: 0.580727, acc: 74.22%] [G loss: 1.661758]\n",
      "epoch:4 step:3326 [D loss: 0.749075, acc: 51.56%] [G loss: 1.622626]\n",
      "epoch:4 step:3327 [D loss: 0.817107, acc: 40.62%] [G loss: 1.334675]\n",
      "epoch:4 step:3328 [D loss: 0.795380, acc: 39.06%] [G loss: 1.481184]\n",
      "epoch:4 step:3329 [D loss: 0.854849, acc: 47.66%] [G loss: 1.601536]\n",
      "epoch:4 step:3330 [D loss: 0.709377, acc: 55.47%] [G loss: 1.597095]\n",
      "epoch:4 step:3331 [D loss: 0.488856, acc: 87.50%] [G loss: 1.765943]\n",
      "epoch:4 step:3332 [D loss: 1.008618, acc: 27.34%] [G loss: 1.631017]\n",
      "epoch:4 step:3333 [D loss: 0.753412, acc: 45.31%] [G loss: 1.408165]\n",
      "epoch:4 step:3334 [D loss: 0.826020, acc: 40.62%] [G loss: 1.395759]\n",
      "epoch:4 step:3335 [D loss: 0.884496, acc: 33.59%] [G loss: 1.567697]\n",
      "epoch:4 step:3336 [D loss: 0.683322, acc: 53.12%] [G loss: 1.687351]\n",
      "epoch:4 step:3337 [D loss: 0.772212, acc: 47.66%] [G loss: 1.818266]\n",
      "epoch:4 step:3338 [D loss: 0.641424, acc: 63.28%] [G loss: 1.527416]\n",
      "epoch:4 step:3339 [D loss: 0.666244, acc: 67.97%] [G loss: 1.944811]\n",
      "epoch:4 step:3340 [D loss: 0.650972, acc: 64.84%] [G loss: 1.724200]\n",
      "epoch:4 step:3341 [D loss: 0.720753, acc: 56.25%] [G loss: 1.696740]\n",
      "epoch:4 step:3342 [D loss: 0.704125, acc: 60.16%] [G loss: 1.704803]\n",
      "epoch:4 step:3343 [D loss: 0.725933, acc: 54.69%] [G loss: 1.615999]\n",
      "epoch:4 step:3344 [D loss: 0.884031, acc: 32.03%] [G loss: 1.519239]\n",
      "epoch:4 step:3345 [D loss: 0.914726, acc: 34.38%] [G loss: 1.493303]\n",
      "epoch:4 step:3346 [D loss: 0.702408, acc: 54.69%] [G loss: 1.662365]\n",
      "epoch:4 step:3347 [D loss: 0.586275, acc: 75.00%] [G loss: 1.796354]\n",
      "epoch:4 step:3348 [D loss: 0.741952, acc: 48.44%] [G loss: 1.574335]\n",
      "epoch:4 step:3349 [D loss: 0.597131, acc: 69.53%] [G loss: 1.881852]\n",
      "epoch:4 step:3350 [D loss: 0.820996, acc: 42.19%] [G loss: 1.846076]\n",
      "epoch:4 step:3351 [D loss: 0.840872, acc: 34.38%] [G loss: 1.561326]\n",
      "epoch:4 step:3352 [D loss: 0.699719, acc: 53.91%] [G loss: 1.666632]\n",
      "epoch:4 step:3353 [D loss: 0.596379, acc: 74.22%] [G loss: 2.068422]\n",
      "epoch:4 step:3354 [D loss: 0.733173, acc: 54.69%] [G loss: 1.644686]\n",
      "epoch:4 step:3355 [D loss: 0.601631, acc: 71.09%] [G loss: 1.884615]\n",
      "epoch:4 step:3356 [D loss: 0.922157, acc: 40.62%] [G loss: 1.822435]\n",
      "epoch:4 step:3357 [D loss: 0.712293, acc: 54.69%] [G loss: 1.693262]\n",
      "epoch:4 step:3358 [D loss: 0.732000, acc: 51.56%] [G loss: 1.588530]\n",
      "epoch:4 step:3359 [D loss: 0.812681, acc: 39.06%] [G loss: 1.719292]\n",
      "epoch:4 step:3360 [D loss: 0.777090, acc: 52.34%] [G loss: 1.734603]\n",
      "epoch:4 step:3361 [D loss: 0.671861, acc: 58.59%] [G loss: 1.703263]\n",
      "epoch:4 step:3362 [D loss: 0.595374, acc: 73.44%] [G loss: 1.961340]\n",
      "epoch:4 step:3363 [D loss: 0.553949, acc: 72.66%] [G loss: 2.076071]\n",
      "epoch:4 step:3364 [D loss: 0.716034, acc: 57.03%] [G loss: 1.654911]\n",
      "epoch:4 step:3365 [D loss: 0.804305, acc: 39.06%] [G loss: 1.694082]\n",
      "epoch:4 step:3366 [D loss: 0.676707, acc: 53.91%] [G loss: 1.966247]\n",
      "epoch:4 step:3367 [D loss: 0.771190, acc: 51.56%] [G loss: 1.714718]\n",
      "epoch:4 step:3368 [D loss: 0.667438, acc: 60.94%] [G loss: 1.695259]\n",
      "epoch:4 step:3369 [D loss: 0.777687, acc: 50.78%] [G loss: 1.869255]\n",
      "epoch:4 step:3370 [D loss: 0.716483, acc: 54.69%] [G loss: 1.538645]\n",
      "epoch:4 step:3371 [D loss: 0.713613, acc: 54.69%] [G loss: 1.754343]\n",
      "epoch:4 step:3372 [D loss: 0.668300, acc: 60.16%] [G loss: 1.852322]\n",
      "epoch:4 step:3373 [D loss: 0.766995, acc: 43.75%] [G loss: 1.695149]\n",
      "epoch:4 step:3374 [D loss: 0.793473, acc: 37.50%] [G loss: 1.698352]\n",
      "epoch:4 step:3375 [D loss: 0.792107, acc: 42.19%] [G loss: 1.700899]\n",
      "epoch:4 step:3376 [D loss: 0.682152, acc: 56.25%] [G loss: 1.854068]\n",
      "epoch:4 step:3377 [D loss: 0.759610, acc: 48.44%] [G loss: 1.719044]\n",
      "epoch:4 step:3378 [D loss: 0.727449, acc: 51.56%] [G loss: 1.728102]\n",
      "epoch:4 step:3379 [D loss: 0.670116, acc: 57.81%] [G loss: 1.794577]\n",
      "epoch:4 step:3380 [D loss: 0.653721, acc: 60.16%] [G loss: 1.812212]\n",
      "epoch:4 step:3381 [D loss: 0.859292, acc: 32.03%] [G loss: 1.550540]\n",
      "epoch:4 step:3382 [D loss: 0.809951, acc: 38.28%] [G loss: 1.735482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3383 [D loss: 0.436346, acc: 90.62%] [G loss: 2.074173]\n",
      "epoch:4 step:3384 [D loss: 0.719592, acc: 48.44%] [G loss: 1.648318]\n",
      "epoch:4 step:3385 [D loss: 0.711813, acc: 50.00%] [G loss: 1.598573]\n",
      "epoch:4 step:3386 [D loss: 0.638955, acc: 68.75%] [G loss: 1.765654]\n",
      "epoch:4 step:3387 [D loss: 0.890783, acc: 33.59%] [G loss: 1.645202]\n",
      "epoch:4 step:3388 [D loss: 0.746693, acc: 50.00%] [G loss: 1.794265]\n",
      "epoch:4 step:3389 [D loss: 0.630853, acc: 60.16%] [G loss: 1.991364]\n",
      "epoch:4 step:3390 [D loss: 0.735822, acc: 52.34%] [G loss: 2.028293]\n",
      "epoch:4 step:3391 [D loss: 0.923272, acc: 29.69%] [G loss: 1.704157]\n",
      "epoch:4 step:3392 [D loss: 0.684092, acc: 55.47%] [G loss: 1.647179]\n",
      "epoch:4 step:3393 [D loss: 0.771806, acc: 43.75%] [G loss: 1.914864]\n",
      "epoch:4 step:3394 [D loss: 0.556522, acc: 78.12%] [G loss: 1.924075]\n",
      "epoch:4 step:3395 [D loss: 0.597717, acc: 71.88%] [G loss: 1.830818]\n",
      "epoch:4 step:3396 [D loss: 0.697637, acc: 53.12%] [G loss: 1.893084]\n",
      "epoch:4 step:3397 [D loss: 0.677711, acc: 63.28%] [G loss: 1.748496]\n",
      "epoch:4 step:3398 [D loss: 0.762402, acc: 46.09%] [G loss: 1.603344]\n",
      "epoch:4 step:3399 [D loss: 0.760055, acc: 44.53%] [G loss: 1.716505]\n",
      "epoch:4 step:3400 [D loss: 0.715779, acc: 52.34%] [G loss: 1.635266]\n",
      "epoch:4 step:3401 [D loss: 0.884487, acc: 40.62%] [G loss: 1.734486]\n",
      "epoch:4 step:3402 [D loss: 0.529418, acc: 76.56%] [G loss: 2.122395]\n",
      "epoch:4 step:3403 [D loss: 0.772276, acc: 47.66%] [G loss: 1.541329]\n",
      "epoch:4 step:3404 [D loss: 0.686489, acc: 55.47%] [G loss: 1.823017]\n",
      "epoch:4 step:3405 [D loss: 0.577597, acc: 70.31%] [G loss: 1.870682]\n",
      "epoch:4 step:3406 [D loss: 0.703508, acc: 54.69%] [G loss: 1.779311]\n",
      "epoch:4 step:3407 [D loss: 0.652208, acc: 61.72%] [G loss: 1.469839]\n",
      "epoch:4 step:3408 [D loss: 0.606021, acc: 72.66%] [G loss: 1.446846]\n",
      "epoch:4 step:3409 [D loss: 0.751143, acc: 47.66%] [G loss: 1.661108]\n",
      "epoch:4 step:3410 [D loss: 0.708569, acc: 57.81%] [G loss: 1.650378]\n",
      "epoch:4 step:3411 [D loss: 0.612960, acc: 68.75%] [G loss: 1.817374]\n",
      "epoch:4 step:3412 [D loss: 0.633023, acc: 64.84%] [G loss: 1.703788]\n",
      "epoch:4 step:3413 [D loss: 0.818498, acc: 42.19%] [G loss: 1.679647]\n",
      "epoch:4 step:3414 [D loss: 0.774243, acc: 43.75%] [G loss: 1.790937]\n",
      "epoch:4 step:3415 [D loss: 0.652474, acc: 56.25%] [G loss: 2.054501]\n",
      "epoch:4 step:3416 [D loss: 0.680233, acc: 57.81%] [G loss: 1.674727]\n",
      "epoch:4 step:3417 [D loss: 0.718318, acc: 49.22%] [G loss: 1.718182]\n",
      "epoch:4 step:3418 [D loss: 0.716960, acc: 48.44%] [G loss: 1.579349]\n",
      "epoch:4 step:3419 [D loss: 0.573285, acc: 71.09%] [G loss: 1.776310]\n",
      "epoch:4 step:3420 [D loss: 0.635003, acc: 64.84%] [G loss: 1.953792]\n",
      "epoch:4 step:3421 [D loss: 0.822257, acc: 41.41%] [G loss: 1.929105]\n",
      "epoch:4 step:3422 [D loss: 0.711103, acc: 53.91%] [G loss: 1.687678]\n",
      "epoch:4 step:3423 [D loss: 0.640142, acc: 67.19%] [G loss: 1.927386]\n",
      "epoch:4 step:3424 [D loss: 0.703598, acc: 51.56%] [G loss: 1.817113]\n",
      "epoch:4 step:3425 [D loss: 0.742842, acc: 50.78%] [G loss: 1.889713]\n",
      "epoch:4 step:3426 [D loss: 0.624816, acc: 67.19%] [G loss: 1.589710]\n",
      "epoch:4 step:3427 [D loss: 0.518528, acc: 75.78%] [G loss: 1.872031]\n",
      "epoch:4 step:3428 [D loss: 0.684313, acc: 60.16%] [G loss: 1.661903]\n",
      "epoch:4 step:3429 [D loss: 0.661704, acc: 57.03%] [G loss: 1.393527]\n",
      "epoch:4 step:3430 [D loss: 0.799114, acc: 42.97%] [G loss: 1.484949]\n",
      "epoch:4 step:3431 [D loss: 0.526415, acc: 78.12%] [G loss: 1.816975]\n",
      "epoch:4 step:3432 [D loss: 0.523355, acc: 78.12%] [G loss: 1.617944]\n",
      "epoch:4 step:3433 [D loss: 0.619042, acc: 59.38%] [G loss: 1.947624]\n",
      "epoch:4 step:3434 [D loss: 0.701122, acc: 58.59%] [G loss: 1.764953]\n",
      "epoch:4 step:3435 [D loss: 0.941343, acc: 28.12%] [G loss: 1.491227]\n",
      "epoch:4 step:3436 [D loss: 0.820914, acc: 42.19%] [G loss: 1.546231]\n",
      "epoch:4 step:3437 [D loss: 0.824044, acc: 41.41%] [G loss: 1.557221]\n",
      "epoch:4 step:3438 [D loss: 0.796768, acc: 45.31%] [G loss: 1.682471]\n",
      "epoch:4 step:3439 [D loss: 1.025952, acc: 21.09%] [G loss: 1.467624]\n",
      "epoch:4 step:3440 [D loss: 0.565300, acc: 72.66%] [G loss: 1.758715]\n",
      "epoch:4 step:3441 [D loss: 0.721896, acc: 48.44%] [G loss: 1.706260]\n",
      "epoch:4 step:3442 [D loss: 0.755143, acc: 48.44%] [G loss: 1.458609]\n",
      "epoch:4 step:3443 [D loss: 0.646257, acc: 60.16%] [G loss: 1.729799]\n",
      "epoch:4 step:3444 [D loss: 0.675714, acc: 59.38%] [G loss: 1.506909]\n",
      "epoch:4 step:3445 [D loss: 0.655471, acc: 63.28%] [G loss: 1.677785]\n",
      "epoch:4 step:3446 [D loss: 0.604849, acc: 64.84%] [G loss: 1.749479]\n",
      "epoch:4 step:3447 [D loss: 0.685663, acc: 50.78%] [G loss: 1.751312]\n",
      "epoch:4 step:3448 [D loss: 0.702779, acc: 57.81%] [G loss: 1.789728]\n",
      "epoch:4 step:3449 [D loss: 0.704312, acc: 56.25%] [G loss: 1.590887]\n",
      "epoch:4 step:3450 [D loss: 0.753911, acc: 46.88%] [G loss: 1.630499]\n",
      "epoch:4 step:3451 [D loss: 0.708573, acc: 52.34%] [G loss: 1.849985]\n",
      "epoch:4 step:3452 [D loss: 0.541992, acc: 80.47%] [G loss: 1.887063]\n",
      "epoch:4 step:3453 [D loss: 0.647742, acc: 64.06%] [G loss: 1.649869]\n",
      "epoch:4 step:3454 [D loss: 0.736458, acc: 52.34%] [G loss: 1.704546]\n",
      "epoch:4 step:3455 [D loss: 0.761085, acc: 43.75%] [G loss: 1.790190]\n",
      "epoch:4 step:3456 [D loss: 0.471212, acc: 80.47%] [G loss: 1.936847]\n",
      "epoch:4 step:3457 [D loss: 0.863120, acc: 32.81%] [G loss: 1.757389]\n",
      "epoch:4 step:3458 [D loss: 0.612308, acc: 69.53%] [G loss: 1.839754]\n",
      "epoch:4 step:3459 [D loss: 0.594430, acc: 70.31%] [G loss: 1.754494]\n",
      "epoch:4 step:3460 [D loss: 0.662111, acc: 60.94%] [G loss: 1.788514]\n",
      "epoch:4 step:3461 [D loss: 0.708614, acc: 54.69%] [G loss: 1.868873]\n",
      "epoch:4 step:3462 [D loss: 0.642236, acc: 60.94%] [G loss: 1.886660]\n",
      "epoch:4 step:3463 [D loss: 0.926929, acc: 19.53%] [G loss: 1.443383]\n",
      "epoch:4 step:3464 [D loss: 0.564826, acc: 71.88%] [G loss: 2.087873]\n",
      "epoch:4 step:3465 [D loss: 0.665690, acc: 62.50%] [G loss: 1.794055]\n",
      "epoch:4 step:3466 [D loss: 0.397256, acc: 87.50%] [G loss: 1.975987]\n",
      "epoch:4 step:3467 [D loss: 0.494508, acc: 78.91%] [G loss: 1.767143]\n",
      "epoch:4 step:3468 [D loss: 0.586537, acc: 68.75%] [G loss: 1.870175]\n",
      "epoch:4 step:3469 [D loss: 0.532449, acc: 73.44%] [G loss: 1.521111]\n",
      "epoch:4 step:3470 [D loss: 0.821037, acc: 52.34%] [G loss: 1.796488]\n",
      "epoch:4 step:3471 [D loss: 0.812610, acc: 44.53%] [G loss: 1.704774]\n",
      "epoch:4 step:3472 [D loss: 0.663877, acc: 57.81%] [G loss: 1.595642]\n",
      "epoch:4 step:3473 [D loss: 0.587930, acc: 70.31%] [G loss: 1.900422]\n",
      "epoch:4 step:3474 [D loss: 0.704353, acc: 55.47%] [G loss: 1.745521]\n",
      "epoch:4 step:3475 [D loss: 1.045831, acc: 35.94%] [G loss: 1.051147]\n",
      "epoch:4 step:3476 [D loss: 0.554705, acc: 71.88%] [G loss: 1.621825]\n",
      "epoch:4 step:3477 [D loss: 0.655859, acc: 55.47%] [G loss: 1.803665]\n",
      "epoch:4 step:3478 [D loss: 0.865693, acc: 34.38%] [G loss: 1.220280]\n",
      "epoch:4 step:3479 [D loss: 0.981893, acc: 17.19%] [G loss: 1.261331]\n",
      "epoch:4 step:3480 [D loss: 0.647268, acc: 64.84%] [G loss: 1.354974]\n",
      "epoch:4 step:3481 [D loss: 0.795107, acc: 40.62%] [G loss: 1.622048]\n",
      "epoch:4 step:3482 [D loss: 0.580291, acc: 61.72%] [G loss: 1.354108]\n",
      "epoch:4 step:3483 [D loss: 0.704923, acc: 52.34%] [G loss: 1.278209]\n",
      "epoch:4 step:3484 [D loss: 0.636984, acc: 59.38%] [G loss: 1.354192]\n",
      "epoch:4 step:3485 [D loss: 0.585488, acc: 69.53%] [G loss: 1.699226]\n",
      "epoch:4 step:3486 [D loss: 0.582563, acc: 72.66%] [G loss: 1.381188]\n",
      "epoch:4 step:3487 [D loss: 0.532954, acc: 76.56%] [G loss: 1.681795]\n",
      "epoch:4 step:3488 [D loss: 0.690060, acc: 57.03%] [G loss: 1.608286]\n",
      "epoch:4 step:3489 [D loss: 0.792994, acc: 46.88%] [G loss: 1.756901]\n",
      "epoch:4 step:3490 [D loss: 0.949712, acc: 29.69%] [G loss: 1.447731]\n",
      "epoch:4 step:3491 [D loss: 0.778036, acc: 44.53%] [G loss: 1.440568]\n",
      "epoch:4 step:3492 [D loss: 0.757392, acc: 52.34%] [G loss: 1.830551]\n",
      "epoch:4 step:3493 [D loss: 0.531331, acc: 78.12%] [G loss: 1.842148]\n",
      "epoch:4 step:3494 [D loss: 0.633716, acc: 64.06%] [G loss: 2.066786]\n",
      "epoch:4 step:3495 [D loss: 0.738013, acc: 50.00%] [G loss: 1.788669]\n",
      "epoch:4 step:3496 [D loss: 0.678274, acc: 57.03%] [G loss: 1.562021]\n",
      "epoch:4 step:3497 [D loss: 1.079815, acc: 15.62%] [G loss: 1.352905]\n",
      "epoch:4 step:3498 [D loss: 0.427639, acc: 86.72%] [G loss: 1.860255]\n",
      "epoch:4 step:3499 [D loss: 0.676816, acc: 60.16%] [G loss: 1.675264]\n",
      "epoch:4 step:3500 [D loss: 0.577160, acc: 68.75%] [G loss: 1.765865]\n",
      "epoch:4 step:3501 [D loss: 0.770663, acc: 45.31%] [G loss: 1.465308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3502 [D loss: 0.680222, acc: 59.38%] [G loss: 1.716175]\n",
      "epoch:4 step:3503 [D loss: 0.544668, acc: 79.69%] [G loss: 1.876957]\n",
      "epoch:4 step:3504 [D loss: 0.607798, acc: 66.41%] [G loss: 1.761809]\n",
      "epoch:4 step:3505 [D loss: 0.625167, acc: 70.31%] [G loss: 1.647472]\n",
      "epoch:4 step:3506 [D loss: 0.717450, acc: 57.81%] [G loss: 1.638005]\n",
      "epoch:4 step:3507 [D loss: 0.640334, acc: 61.72%] [G loss: 1.764734]\n",
      "epoch:4 step:3508 [D loss: 0.772166, acc: 48.44%] [G loss: 1.619607]\n",
      "epoch:4 step:3509 [D loss: 0.801483, acc: 45.31%] [G loss: 1.562491]\n",
      "epoch:4 step:3510 [D loss: 0.610879, acc: 70.31%] [G loss: 1.748297]\n",
      "epoch:4 step:3511 [D loss: 0.597787, acc: 66.41%] [G loss: 2.024959]\n",
      "epoch:4 step:3512 [D loss: 0.677186, acc: 62.50%] [G loss: 1.407580]\n",
      "epoch:4 step:3513 [D loss: 0.667257, acc: 59.38%] [G loss: 1.677456]\n",
      "epoch:4 step:3514 [D loss: 0.352237, acc: 89.84%] [G loss: 1.986921]\n",
      "epoch:4 step:3515 [D loss: 0.637815, acc: 65.62%] [G loss: 1.686875]\n",
      "epoch:4 step:3516 [D loss: 0.618266, acc: 64.84%] [G loss: 1.559631]\n",
      "epoch:4 step:3517 [D loss: 0.371286, acc: 94.53%] [G loss: 1.873249]\n",
      "epoch:4 step:3518 [D loss: 0.485506, acc: 82.81%] [G loss: 1.710780]\n",
      "epoch:4 step:3519 [D loss: 0.635007, acc: 64.06%] [G loss: 1.649342]\n",
      "epoch:4 step:3520 [D loss: 0.689611, acc: 52.34%] [G loss: 1.620973]\n",
      "epoch:4 step:3521 [D loss: 0.824078, acc: 46.09%] [G loss: 1.215959]\n",
      "epoch:4 step:3522 [D loss: 0.723637, acc: 53.91%] [G loss: 1.645536]\n",
      "epoch:4 step:3523 [D loss: 0.899253, acc: 38.28%] [G loss: 1.689995]\n",
      "epoch:4 step:3524 [D loss: 0.687949, acc: 55.47%] [G loss: 1.991382]\n",
      "epoch:4 step:3525 [D loss: 0.443759, acc: 86.72%] [G loss: 1.792804]\n",
      "epoch:4 step:3526 [D loss: 0.800978, acc: 45.31%] [G loss: 1.692577]\n",
      "epoch:4 step:3527 [D loss: 0.654826, acc: 61.72%] [G loss: 1.842098]\n",
      "epoch:4 step:3528 [D loss: 0.681326, acc: 62.50%] [G loss: 1.406976]\n",
      "epoch:4 step:3529 [D loss: 0.650056, acc: 61.72%] [G loss: 1.452039]\n",
      "epoch:4 step:3530 [D loss: 0.914027, acc: 34.38%] [G loss: 1.592281]\n",
      "epoch:4 step:3531 [D loss: 0.623023, acc: 64.06%] [G loss: 2.278600]\n",
      "epoch:4 step:3532 [D loss: 0.600198, acc: 73.44%] [G loss: 1.897085]\n",
      "epoch:4 step:3533 [D loss: 0.660340, acc: 60.94%] [G loss: 1.744591]\n",
      "epoch:4 step:3534 [D loss: 0.652030, acc: 63.28%] [G loss: 1.746074]\n",
      "epoch:4 step:3535 [D loss: 0.854453, acc: 52.34%] [G loss: 1.837842]\n",
      "epoch:4 step:3536 [D loss: 0.615396, acc: 60.94%] [G loss: 1.883970]\n",
      "epoch:4 step:3537 [D loss: 0.806086, acc: 52.34%] [G loss: 1.577939]\n",
      "epoch:4 step:3538 [D loss: 0.767108, acc: 40.62%] [G loss: 1.935439]\n",
      "epoch:4 step:3539 [D loss: 0.774462, acc: 52.34%] [G loss: 1.841537]\n",
      "epoch:4 step:3540 [D loss: 0.643559, acc: 60.94%] [G loss: 1.952757]\n",
      "epoch:4 step:3541 [D loss: 0.596173, acc: 71.09%] [G loss: 1.969175]\n",
      "epoch:4 step:3542 [D loss: 0.499390, acc: 75.78%] [G loss: 1.828313]\n",
      "epoch:4 step:3543 [D loss: 0.582354, acc: 75.00%] [G loss: 1.684339]\n",
      "epoch:4 step:3544 [D loss: 0.616216, acc: 66.41%] [G loss: 1.919044]\n",
      "epoch:4 step:3545 [D loss: 0.636544, acc: 61.72%] [G loss: 1.431190]\n",
      "epoch:4 step:3546 [D loss: 0.494917, acc: 80.47%] [G loss: 1.658583]\n",
      "epoch:4 step:3547 [D loss: 0.416142, acc: 83.59%] [G loss: 1.501479]\n",
      "epoch:4 step:3548 [D loss: 0.964206, acc: 31.25%] [G loss: 1.506039]\n",
      "epoch:4 step:3549 [D loss: 0.662014, acc: 59.38%] [G loss: 1.685517]\n",
      "epoch:4 step:3550 [D loss: 0.951418, acc: 30.47%] [G loss: 1.549059]\n",
      "epoch:4 step:3551 [D loss: 0.660434, acc: 60.94%] [G loss: 1.218780]\n",
      "epoch:4 step:3552 [D loss: 0.596239, acc: 69.53%] [G loss: 1.761143]\n",
      "epoch:4 step:3553 [D loss: 0.632566, acc: 65.62%] [G loss: 1.888256]\n",
      "epoch:4 step:3554 [D loss: 0.476770, acc: 82.81%] [G loss: 2.258589]\n",
      "epoch:4 step:3555 [D loss: 0.518789, acc: 79.69%] [G loss: 1.776281]\n",
      "epoch:4 step:3556 [D loss: 0.471684, acc: 82.03%] [G loss: 1.776341]\n",
      "epoch:4 step:3557 [D loss: 1.095607, acc: 17.19%] [G loss: 1.260963]\n",
      "epoch:4 step:3558 [D loss: 0.926111, acc: 42.97%] [G loss: 1.333392]\n",
      "epoch:4 step:3559 [D loss: 0.920675, acc: 39.84%] [G loss: 1.650118]\n",
      "epoch:4 step:3560 [D loss: 0.870365, acc: 39.06%] [G loss: 1.597215]\n",
      "epoch:4 step:3561 [D loss: 0.802160, acc: 46.09%] [G loss: 1.928212]\n",
      "epoch:4 step:3562 [D loss: 0.765972, acc: 52.34%] [G loss: 1.722566]\n",
      "epoch:4 step:3563 [D loss: 0.770594, acc: 48.44%] [G loss: 1.678704]\n",
      "epoch:4 step:3564 [D loss: 0.711491, acc: 52.34%] [G loss: 1.896812]\n",
      "epoch:4 step:3565 [D loss: 0.821315, acc: 46.09%] [G loss: 1.614993]\n",
      "epoch:4 step:3566 [D loss: 0.758651, acc: 51.56%] [G loss: 1.968313]\n",
      "epoch:4 step:3567 [D loss: 0.572682, acc: 64.06%] [G loss: 2.120433]\n",
      "epoch:4 step:3568 [D loss: 0.581551, acc: 68.75%] [G loss: 1.831420]\n",
      "epoch:4 step:3569 [D loss: 0.682373, acc: 52.34%] [G loss: 1.762936]\n",
      "epoch:4 step:3570 [D loss: 0.700564, acc: 57.81%] [G loss: 2.027858]\n",
      "epoch:4 step:3571 [D loss: 0.502945, acc: 82.03%] [G loss: 1.919995]\n",
      "epoch:4 step:3572 [D loss: 0.589012, acc: 69.53%] [G loss: 1.458602]\n",
      "epoch:4 step:3573 [D loss: 0.670309, acc: 61.72%] [G loss: 1.810529]\n",
      "epoch:4 step:3574 [D loss: 0.565893, acc: 73.44%] [G loss: 1.792922]\n",
      "epoch:4 step:3575 [D loss: 0.668299, acc: 60.94%] [G loss: 1.881744]\n",
      "epoch:4 step:3576 [D loss: 0.844304, acc: 38.28%] [G loss: 1.524693]\n",
      "epoch:4 step:3577 [D loss: 0.640757, acc: 64.84%] [G loss: 1.585274]\n",
      "epoch:4 step:3578 [D loss: 0.764847, acc: 51.56%] [G loss: 1.328147]\n",
      "epoch:4 step:3579 [D loss: 0.534486, acc: 80.47%] [G loss: 1.654867]\n",
      "epoch:4 step:3580 [D loss: 0.490144, acc: 81.25%] [G loss: 1.662043]\n",
      "epoch:4 step:3581 [D loss: 0.771218, acc: 46.88%] [G loss: 1.560011]\n",
      "epoch:4 step:3582 [D loss: 0.718162, acc: 55.47%] [G loss: 1.759512]\n",
      "epoch:4 step:3583 [D loss: 1.052078, acc: 12.50%] [G loss: 1.117776]\n",
      "epoch:4 step:3584 [D loss: 0.908944, acc: 21.09%] [G loss: 1.450816]\n",
      "epoch:4 step:3585 [D loss: 0.602226, acc: 68.75%] [G loss: 1.458901]\n",
      "epoch:4 step:3586 [D loss: 0.592334, acc: 73.44%] [G loss: 1.470212]\n",
      "epoch:4 step:3587 [D loss: 0.934535, acc: 23.44%] [G loss: 1.386267]\n",
      "epoch:4 step:3588 [D loss: 0.971422, acc: 18.75%] [G loss: 1.357872]\n",
      "epoch:4 step:3589 [D loss: 0.610720, acc: 73.44%] [G loss: 1.684819]\n",
      "epoch:4 step:3590 [D loss: 0.777868, acc: 46.88%] [G loss: 1.796222]\n",
      "epoch:4 step:3591 [D loss: 0.765469, acc: 46.09%] [G loss: 1.712500]\n",
      "epoch:4 step:3592 [D loss: 0.604969, acc: 71.09%] [G loss: 1.755785]\n",
      "epoch:4 step:3593 [D loss: 0.672361, acc: 60.94%] [G loss: 1.689790]\n",
      "epoch:4 step:3594 [D loss: 0.605587, acc: 71.88%] [G loss: 1.814288]\n",
      "epoch:4 step:3595 [D loss: 0.685692, acc: 57.03%] [G loss: 1.910768]\n",
      "epoch:4 step:3596 [D loss: 0.735263, acc: 51.56%] [G loss: 1.813924]\n",
      "epoch:4 step:3597 [D loss: 0.637348, acc: 57.03%] [G loss: 1.903150]\n",
      "epoch:4 step:3598 [D loss: 0.890310, acc: 44.53%] [G loss: 1.534201]\n",
      "epoch:4 step:3599 [D loss: 0.669530, acc: 55.47%] [G loss: 1.863827]\n",
      "epoch:4 step:3600 [D loss: 0.611592, acc: 66.41%] [G loss: 1.980485]\n",
      "epoch:4 step:3601 [D loss: 0.745695, acc: 46.88%] [G loss: 1.867212]\n",
      "epoch:4 step:3602 [D loss: 0.592286, acc: 68.75%] [G loss: 2.196988]\n",
      "epoch:4 step:3603 [D loss: 0.777169, acc: 43.75%] [G loss: 1.791922]\n",
      "epoch:4 step:3604 [D loss: 0.735822, acc: 53.12%] [G loss: 1.623019]\n",
      "epoch:4 step:3605 [D loss: 0.701577, acc: 57.81%] [G loss: 1.864167]\n",
      "epoch:4 step:3606 [D loss: 0.608726, acc: 71.09%] [G loss: 1.663910]\n",
      "epoch:4 step:3607 [D loss: 0.951677, acc: 25.00%] [G loss: 1.352547]\n",
      "epoch:4 step:3608 [D loss: 0.715140, acc: 51.56%] [G loss: 1.623306]\n",
      "epoch:4 step:3609 [D loss: 0.880920, acc: 29.69%] [G loss: 1.544869]\n",
      "epoch:4 step:3610 [D loss: 0.814635, acc: 37.50%] [G loss: 1.677825]\n",
      "epoch:4 step:3611 [D loss: 0.669562, acc: 65.62%] [G loss: 1.660390]\n",
      "epoch:4 step:3612 [D loss: 0.935585, acc: 25.78%] [G loss: 1.323550]\n",
      "epoch:4 step:3613 [D loss: 0.770344, acc: 44.53%] [G loss: 1.667090]\n",
      "epoch:4 step:3614 [D loss: 0.637708, acc: 64.06%] [G loss: 2.051764]\n",
      "epoch:4 step:3615 [D loss: 0.827016, acc: 36.72%] [G loss: 1.550501]\n",
      "epoch:4 step:3616 [D loss: 0.763598, acc: 48.44%] [G loss: 1.667152]\n",
      "epoch:4 step:3617 [D loss: 0.587349, acc: 70.31%] [G loss: 1.755564]\n",
      "epoch:4 step:3618 [D loss: 0.690809, acc: 53.91%] [G loss: 1.653990]\n",
      "epoch:4 step:3619 [D loss: 0.740721, acc: 56.25%] [G loss: 1.602458]\n",
      "epoch:4 step:3620 [D loss: 0.582837, acc: 67.19%] [G loss: 1.882817]\n",
      "epoch:4 step:3621 [D loss: 0.799621, acc: 39.84%] [G loss: 1.561002]\n",
      "epoch:4 step:3622 [D loss: 0.803618, acc: 48.44%] [G loss: 1.554144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3623 [D loss: 1.002455, acc: 17.19%] [G loss: 1.348308]\n",
      "epoch:4 step:3624 [D loss: 0.780273, acc: 50.78%] [G loss: 1.516530]\n",
      "epoch:4 step:3625 [D loss: 0.621455, acc: 67.19%] [G loss: 1.816768]\n",
      "epoch:4 step:3626 [D loss: 0.767785, acc: 47.66%] [G loss: 1.434118]\n",
      "epoch:4 step:3627 [D loss: 0.517579, acc: 78.91%] [G loss: 2.083839]\n",
      "epoch:4 step:3628 [D loss: 0.783711, acc: 42.19%] [G loss: 1.651791]\n",
      "epoch:4 step:3629 [D loss: 0.640960, acc: 67.19%] [G loss: 1.521420]\n",
      "epoch:4 step:3630 [D loss: 0.754017, acc: 52.34%] [G loss: 1.628128]\n",
      "epoch:4 step:3631 [D loss: 0.667741, acc: 57.03%] [G loss: 1.636277]\n",
      "epoch:4 step:3632 [D loss: 0.726135, acc: 48.44%] [G loss: 1.662995]\n",
      "epoch:4 step:3633 [D loss: 0.681115, acc: 57.03%] [G loss: 1.634639]\n",
      "epoch:4 step:3634 [D loss: 0.832112, acc: 29.69%] [G loss: 1.502674]\n",
      "epoch:4 step:3635 [D loss: 0.657061, acc: 61.72%] [G loss: 1.829927]\n",
      "epoch:4 step:3636 [D loss: 0.754215, acc: 40.62%] [G loss: 1.568036]\n",
      "epoch:4 step:3637 [D loss: 0.759511, acc: 49.22%] [G loss: 1.644737]\n",
      "epoch:4 step:3638 [D loss: 0.657141, acc: 60.94%] [G loss: 1.880478]\n",
      "epoch:4 step:3639 [D loss: 0.659244, acc: 58.59%] [G loss: 1.795043]\n",
      "epoch:4 step:3640 [D loss: 0.569190, acc: 74.22%] [G loss: 1.668887]\n",
      "epoch:4 step:3641 [D loss: 0.690678, acc: 57.81%] [G loss: 1.644794]\n",
      "epoch:4 step:3642 [D loss: 0.869204, acc: 28.91%] [G loss: 1.348805]\n",
      "epoch:4 step:3643 [D loss: 0.957234, acc: 26.56%] [G loss: 1.433726]\n",
      "epoch:4 step:3644 [D loss: 0.762128, acc: 43.75%] [G loss: 1.677964]\n",
      "epoch:4 step:3645 [D loss: 0.715145, acc: 57.81%] [G loss: 1.919169]\n",
      "epoch:4 step:3646 [D loss: 0.665350, acc: 56.25%] [G loss: 1.595644]\n",
      "epoch:4 step:3647 [D loss: 0.811150, acc: 35.16%] [G loss: 1.517689]\n",
      "epoch:4 step:3648 [D loss: 0.687404, acc: 57.81%] [G loss: 1.728406]\n",
      "epoch:4 step:3649 [D loss: 0.670251, acc: 52.34%] [G loss: 1.583994]\n",
      "epoch:4 step:3650 [D loss: 0.821750, acc: 45.31%] [G loss: 1.804547]\n",
      "epoch:4 step:3651 [D loss: 0.775670, acc: 42.19%] [G loss: 1.805142]\n",
      "epoch:4 step:3652 [D loss: 0.646519, acc: 61.72%] [G loss: 1.672382]\n",
      "epoch:4 step:3653 [D loss: 0.720035, acc: 47.66%] [G loss: 1.781671]\n",
      "epoch:4 step:3654 [D loss: 0.834608, acc: 40.62%] [G loss: 1.767017]\n",
      "epoch:4 step:3655 [D loss: 0.556868, acc: 74.22%] [G loss: 1.870479]\n",
      "epoch:4 step:3656 [D loss: 0.763904, acc: 44.53%] [G loss: 1.806866]\n",
      "epoch:4 step:3657 [D loss: 0.641831, acc: 62.50%] [G loss: 1.730602]\n",
      "epoch:4 step:3658 [D loss: 0.596084, acc: 70.31%] [G loss: 1.726053]\n",
      "epoch:4 step:3659 [D loss: 0.667644, acc: 63.28%] [G loss: 1.863397]\n",
      "epoch:4 step:3660 [D loss: 0.675812, acc: 59.38%] [G loss: 1.728135]\n",
      "epoch:4 step:3661 [D loss: 0.724831, acc: 53.91%] [G loss: 1.738047]\n",
      "epoch:4 step:3662 [D loss: 0.780391, acc: 39.06%] [G loss: 1.648311]\n",
      "epoch:4 step:3663 [D loss: 0.616156, acc: 67.97%] [G loss: 1.721171]\n",
      "epoch:4 step:3664 [D loss: 0.787143, acc: 42.19%] [G loss: 1.691765]\n",
      "epoch:4 step:3665 [D loss: 0.628089, acc: 69.53%] [G loss: 1.780007]\n",
      "epoch:4 step:3666 [D loss: 0.808397, acc: 40.62%] [G loss: 1.540294]\n",
      "epoch:4 step:3667 [D loss: 0.771238, acc: 42.97%] [G loss: 1.683262]\n",
      "epoch:4 step:3668 [D loss: 0.627309, acc: 64.84%] [G loss: 1.891954]\n",
      "epoch:4 step:3669 [D loss: 0.759820, acc: 52.34%] [G loss: 1.755364]\n",
      "epoch:4 step:3670 [D loss: 0.573168, acc: 71.09%] [G loss: 1.755637]\n",
      "epoch:4 step:3671 [D loss: 0.703509, acc: 58.59%] [G loss: 1.737169]\n",
      "epoch:4 step:3672 [D loss: 0.554420, acc: 75.00%] [G loss: 2.037113]\n",
      "epoch:4 step:3673 [D loss: 0.741531, acc: 53.91%] [G loss: 1.682525]\n",
      "epoch:4 step:3674 [D loss: 0.700090, acc: 55.47%] [G loss: 2.224212]\n",
      "epoch:4 step:3675 [D loss: 0.719103, acc: 54.69%] [G loss: 1.604818]\n",
      "epoch:4 step:3676 [D loss: 0.839992, acc: 37.50%] [G loss: 1.654115]\n",
      "epoch:4 step:3677 [D loss: 0.825372, acc: 41.41%] [G loss: 1.422947]\n",
      "epoch:4 step:3678 [D loss: 0.710038, acc: 47.66%] [G loss: 1.729334]\n",
      "epoch:4 step:3679 [D loss: 0.821068, acc: 33.59%] [G loss: 1.415304]\n",
      "epoch:4 step:3680 [D loss: 0.711396, acc: 50.00%] [G loss: 1.543011]\n",
      "epoch:4 step:3681 [D loss: 0.680770, acc: 55.47%] [G loss: 1.733399]\n",
      "epoch:4 step:3682 [D loss: 0.767877, acc: 46.88%] [G loss: 1.702781]\n",
      "epoch:4 step:3683 [D loss: 0.663312, acc: 57.03%] [G loss: 1.508600]\n",
      "epoch:4 step:3684 [D loss: 0.802477, acc: 35.16%] [G loss: 1.431348]\n",
      "epoch:4 step:3685 [D loss: 0.705696, acc: 57.03%] [G loss: 1.532153]\n",
      "epoch:4 step:3686 [D loss: 0.804994, acc: 39.84%] [G loss: 1.475366]\n",
      "epoch:4 step:3687 [D loss: 0.895012, acc: 27.34%] [G loss: 1.393777]\n",
      "epoch:4 step:3688 [D loss: 0.787661, acc: 42.19%] [G loss: 1.433785]\n",
      "epoch:4 step:3689 [D loss: 0.749744, acc: 48.44%] [G loss: 1.440741]\n",
      "epoch:4 step:3690 [D loss: 0.774746, acc: 41.41%] [G loss: 1.489633]\n",
      "epoch:4 step:3691 [D loss: 0.725010, acc: 48.44%] [G loss: 1.606647]\n",
      "epoch:4 step:3692 [D loss: 0.745100, acc: 53.91%] [G loss: 1.628604]\n",
      "epoch:4 step:3693 [D loss: 0.712347, acc: 47.66%] [G loss: 1.546729]\n",
      "epoch:4 step:3694 [D loss: 0.701124, acc: 47.66%] [G loss: 1.775919]\n",
      "epoch:4 step:3695 [D loss: 0.771569, acc: 42.97%] [G loss: 1.638737]\n",
      "epoch:4 step:3696 [D loss: 0.598868, acc: 67.19%] [G loss: 1.630954]\n",
      "epoch:4 step:3697 [D loss: 0.762319, acc: 47.66%] [G loss: 1.528090]\n",
      "epoch:4 step:3698 [D loss: 0.684146, acc: 60.16%] [G loss: 1.763671]\n",
      "epoch:4 step:3699 [D loss: 0.829067, acc: 42.97%] [G loss: 1.589621]\n",
      "epoch:4 step:3700 [D loss: 0.658001, acc: 67.97%] [G loss: 1.755622]\n",
      "epoch:4 step:3701 [D loss: 0.677666, acc: 53.91%] [G loss: 1.698932]\n",
      "epoch:4 step:3702 [D loss: 0.762901, acc: 46.88%] [G loss: 1.613043]\n",
      "epoch:4 step:3703 [D loss: 0.729696, acc: 53.91%] [G loss: 1.551194]\n",
      "epoch:4 step:3704 [D loss: 0.731534, acc: 52.34%] [G loss: 1.854613]\n",
      "epoch:4 step:3705 [D loss: 0.685518, acc: 57.03%] [G loss: 1.722534]\n",
      "epoch:4 step:3706 [D loss: 0.583853, acc: 74.22%] [G loss: 1.728242]\n",
      "epoch:4 step:3707 [D loss: 0.626185, acc: 65.62%] [G loss: 1.635106]\n",
      "epoch:4 step:3708 [D loss: 0.822845, acc: 37.50%] [G loss: 1.624478]\n",
      "epoch:4 step:3709 [D loss: 0.821903, acc: 34.38%] [G loss: 1.289403]\n",
      "epoch:4 step:3710 [D loss: 0.651407, acc: 62.50%] [G loss: 1.657800]\n",
      "epoch:4 step:3711 [D loss: 0.840589, acc: 35.16%] [G loss: 1.382785]\n",
      "epoch:4 step:3712 [D loss: 0.881220, acc: 28.12%] [G loss: 1.436430]\n",
      "epoch:4 step:3713 [D loss: 0.670203, acc: 60.16%] [G loss: 1.543579]\n",
      "epoch:4 step:3714 [D loss: 0.707867, acc: 57.81%] [G loss: 1.605052]\n",
      "epoch:4 step:3715 [D loss: 0.706660, acc: 54.69%] [G loss: 1.681589]\n",
      "epoch:4 step:3716 [D loss: 0.764040, acc: 39.06%] [G loss: 1.566510]\n",
      "epoch:4 step:3717 [D loss: 0.640075, acc: 67.19%] [G loss: 1.579590]\n",
      "epoch:4 step:3718 [D loss: 0.815352, acc: 39.06%] [G loss: 1.552190]\n",
      "epoch:4 step:3719 [D loss: 0.735239, acc: 50.00%] [G loss: 1.648762]\n",
      "epoch:4 step:3720 [D loss: 0.652428, acc: 63.28%] [G loss: 1.760069]\n",
      "epoch:4 step:3721 [D loss: 0.791043, acc: 39.84%] [G loss: 1.655898]\n",
      "epoch:4 step:3722 [D loss: 0.659070, acc: 62.50%] [G loss: 1.718976]\n",
      "epoch:4 step:3723 [D loss: 0.695793, acc: 51.56%] [G loss: 1.581983]\n",
      "epoch:4 step:3724 [D loss: 0.779278, acc: 39.84%] [G loss: 1.563751]\n",
      "epoch:4 step:3725 [D loss: 0.736468, acc: 50.78%] [G loss: 1.608189]\n",
      "epoch:4 step:3726 [D loss: 0.661060, acc: 67.97%] [G loss: 1.641791]\n",
      "epoch:4 step:3727 [D loss: 0.741660, acc: 46.88%] [G loss: 1.485037]\n",
      "epoch:4 step:3728 [D loss: 0.761666, acc: 45.31%] [G loss: 1.550038]\n",
      "epoch:4 step:3729 [D loss: 0.671954, acc: 55.47%] [G loss: 1.694186]\n",
      "epoch:4 step:3730 [D loss: 0.686162, acc: 62.50%] [G loss: 1.938297]\n",
      "epoch:4 step:3731 [D loss: 0.730844, acc: 47.66%] [G loss: 1.633379]\n",
      "epoch:4 step:3732 [D loss: 0.660801, acc: 64.84%] [G loss: 1.587264]\n",
      "epoch:4 step:3733 [D loss: 0.749169, acc: 44.53%] [G loss: 1.640843]\n",
      "epoch:4 step:3734 [D loss: 0.904877, acc: 29.69%] [G loss: 1.364345]\n",
      "epoch:4 step:3735 [D loss: 0.733490, acc: 46.09%] [G loss: 1.525333]\n",
      "epoch:4 step:3736 [D loss: 0.582706, acc: 66.41%] [G loss: 1.477759]\n",
      "epoch:4 step:3737 [D loss: 0.646036, acc: 63.28%] [G loss: 1.396586]\n",
      "epoch:4 step:3738 [D loss: 0.852510, acc: 35.94%] [G loss: 1.450152]\n",
      "epoch:4 step:3739 [D loss: 0.755712, acc: 43.75%] [G loss: 1.678674]\n",
      "epoch:4 step:3740 [D loss: 0.539443, acc: 72.66%] [G loss: 1.756603]\n",
      "epoch:4 step:3741 [D loss: 0.814682, acc: 38.28%] [G loss: 1.626633]\n",
      "epoch:4 step:3742 [D loss: 0.676292, acc: 60.16%] [G loss: 1.635821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3743 [D loss: 0.693392, acc: 55.47%] [G loss: 1.584462]\n",
      "epoch:4 step:3744 [D loss: 0.761457, acc: 48.44%] [G loss: 1.486855]\n",
      "epoch:4 step:3745 [D loss: 0.631827, acc: 64.06%] [G loss: 1.634723]\n",
      "epoch:4 step:3746 [D loss: 0.720210, acc: 47.66%] [G loss: 1.427421]\n",
      "epoch:4 step:3747 [D loss: 0.865016, acc: 28.91%] [G loss: 1.565924]\n",
      "epoch:4 step:3748 [D loss: 0.619812, acc: 69.53%] [G loss: 1.784393]\n",
      "epoch:4 step:3749 [D loss: 0.697694, acc: 52.34%] [G loss: 1.565037]\n",
      "epoch:4 step:3750 [D loss: 0.705023, acc: 52.34%] [G loss: 1.543512]\n",
      "epoch:4 step:3751 [D loss: 0.716339, acc: 46.88%] [G loss: 1.706249]\n",
      "epoch:4 step:3752 [D loss: 0.801405, acc: 38.28%] [G loss: 1.568748]\n",
      "epoch:4 step:3753 [D loss: 0.802279, acc: 46.09%] [G loss: 1.463485]\n",
      "epoch:4 step:3754 [D loss: 0.698190, acc: 53.91%] [G loss: 1.633207]\n",
      "epoch:4 step:3755 [D loss: 0.723114, acc: 50.00%] [G loss: 1.618852]\n",
      "epoch:4 step:3756 [D loss: 0.626532, acc: 65.62%] [G loss: 1.579261]\n",
      "epoch:4 step:3757 [D loss: 0.814636, acc: 33.59%] [G loss: 1.513066]\n",
      "epoch:4 step:3758 [D loss: 0.712312, acc: 51.56%] [G loss: 1.548600]\n",
      "epoch:4 step:3759 [D loss: 0.794467, acc: 43.75%] [G loss: 1.576809]\n",
      "epoch:4 step:3760 [D loss: 0.770112, acc: 47.66%] [G loss: 1.435851]\n",
      "epoch:4 step:3761 [D loss: 0.735906, acc: 49.22%] [G loss: 1.455795]\n",
      "epoch:4 step:3762 [D loss: 0.754171, acc: 46.09%] [G loss: 1.536597]\n",
      "epoch:4 step:3763 [D loss: 0.639461, acc: 60.94%] [G loss: 1.728156]\n",
      "epoch:4 step:3764 [D loss: 0.729504, acc: 45.31%] [G loss: 1.640464]\n",
      "epoch:4 step:3765 [D loss: 0.698347, acc: 51.56%] [G loss: 1.647317]\n",
      "epoch:4 step:3766 [D loss: 0.598166, acc: 67.97%] [G loss: 1.655287]\n",
      "epoch:4 step:3767 [D loss: 0.813525, acc: 34.38%] [G loss: 1.531477]\n",
      "epoch:4 step:3768 [D loss: 0.711626, acc: 53.12%] [G loss: 1.840573]\n",
      "epoch:4 step:3769 [D loss: 0.846292, acc: 26.56%] [G loss: 1.461991]\n",
      "epoch:4 step:3770 [D loss: 0.832432, acc: 39.06%] [G loss: 1.348195]\n",
      "epoch:4 step:3771 [D loss: 0.793506, acc: 39.84%] [G loss: 1.451569]\n",
      "epoch:4 step:3772 [D loss: 0.665417, acc: 60.16%] [G loss: 1.633088]\n",
      "epoch:4 step:3773 [D loss: 0.706947, acc: 55.47%] [G loss: 1.426202]\n",
      "epoch:4 step:3774 [D loss: 0.734299, acc: 45.31%] [G loss: 1.552201]\n",
      "epoch:4 step:3775 [D loss: 0.721701, acc: 50.00%] [G loss: 1.600438]\n",
      "epoch:4 step:3776 [D loss: 0.690660, acc: 53.12%] [G loss: 1.571355]\n",
      "epoch:4 step:3777 [D loss: 0.722243, acc: 54.69%] [G loss: 1.662378]\n",
      "epoch:4 step:3778 [D loss: 0.686268, acc: 57.81%] [G loss: 1.599910]\n",
      "epoch:4 step:3779 [D loss: 0.643491, acc: 64.06%] [G loss: 1.836745]\n",
      "epoch:4 step:3780 [D loss: 0.760495, acc: 48.44%] [G loss: 1.615244]\n",
      "epoch:4 step:3781 [D loss: 0.698542, acc: 51.56%] [G loss: 1.681709]\n",
      "epoch:4 step:3782 [D loss: 0.686364, acc: 57.81%] [G loss: 1.578178]\n",
      "epoch:4 step:3783 [D loss: 0.549488, acc: 78.12%] [G loss: 1.648877]\n",
      "epoch:4 step:3784 [D loss: 0.678968, acc: 52.34%] [G loss: 1.551084]\n",
      "epoch:4 step:3785 [D loss: 0.651544, acc: 61.72%] [G loss: 1.584871]\n",
      "epoch:4 step:3786 [D loss: 0.743121, acc: 45.31%] [G loss: 1.456885]\n",
      "epoch:4 step:3787 [D loss: 0.649593, acc: 68.75%] [G loss: 1.524318]\n",
      "epoch:4 step:3788 [D loss: 0.733584, acc: 53.91%] [G loss: 1.440430]\n",
      "epoch:4 step:3789 [D loss: 0.839699, acc: 28.12%] [G loss: 1.321527]\n",
      "epoch:4 step:3790 [D loss: 0.662347, acc: 62.50%] [G loss: 1.588301]\n",
      "epoch:4 step:3791 [D loss: 0.624947, acc: 67.19%] [G loss: 1.658227]\n",
      "epoch:4 step:3792 [D loss: 0.727196, acc: 50.00%] [G loss: 1.569458]\n",
      "epoch:4 step:3793 [D loss: 0.696936, acc: 51.56%] [G loss: 1.488231]\n",
      "epoch:4 step:3794 [D loss: 0.731516, acc: 46.09%] [G loss: 1.380484]\n",
      "epoch:4 step:3795 [D loss: 1.026918, acc: 29.69%] [G loss: 1.505716]\n",
      "epoch:4 step:3796 [D loss: 0.745231, acc: 42.19%] [G loss: 1.422538]\n",
      "epoch:4 step:3797 [D loss: 0.710855, acc: 50.00%] [G loss: 1.517079]\n",
      "epoch:4 step:3798 [D loss: 0.745806, acc: 50.00%] [G loss: 1.677477]\n",
      "epoch:4 step:3799 [D loss: 0.715255, acc: 53.12%] [G loss: 1.733498]\n",
      "epoch:4 step:3800 [D loss: 0.748775, acc: 46.88%] [G loss: 1.633067]\n",
      "epoch:4 step:3801 [D loss: 0.680296, acc: 57.03%] [G loss: 1.692120]\n",
      "epoch:4 step:3802 [D loss: 0.625498, acc: 65.62%] [G loss: 1.803589]\n",
      "epoch:4 step:3803 [D loss: 0.778018, acc: 40.62%] [G loss: 1.601644]\n",
      "epoch:4 step:3804 [D loss: 0.645713, acc: 64.84%] [G loss: 1.739707]\n",
      "epoch:4 step:3805 [D loss: 0.630798, acc: 64.84%] [G loss: 1.687278]\n",
      "epoch:4 step:3806 [D loss: 0.787555, acc: 46.09%] [G loss: 1.557432]\n",
      "epoch:4 step:3807 [D loss: 0.789681, acc: 35.94%] [G loss: 1.470839]\n",
      "epoch:4 step:3808 [D loss: 0.596328, acc: 78.91%] [G loss: 1.579860]\n",
      "epoch:4 step:3809 [D loss: 0.595919, acc: 71.88%] [G loss: 1.634395]\n",
      "epoch:4 step:3810 [D loss: 0.701528, acc: 57.81%] [G loss: 1.782833]\n",
      "epoch:4 step:3811 [D loss: 0.662919, acc: 62.50%] [G loss: 1.706907]\n",
      "epoch:4 step:3812 [D loss: 0.736336, acc: 46.09%] [G loss: 1.404926]\n",
      "epoch:4 step:3813 [D loss: 0.571325, acc: 71.88%] [G loss: 1.624888]\n",
      "epoch:4 step:3814 [D loss: 0.609081, acc: 70.31%] [G loss: 1.498370]\n",
      "epoch:4 step:3815 [D loss: 0.716065, acc: 50.00%] [G loss: 1.639982]\n",
      "epoch:4 step:3816 [D loss: 0.653514, acc: 66.41%] [G loss: 1.590080]\n",
      "epoch:4 step:3817 [D loss: 0.720907, acc: 53.12%] [G loss: 1.493924]\n",
      "epoch:4 step:3818 [D loss: 0.711777, acc: 52.34%] [G loss: 1.575980]\n",
      "epoch:4 step:3819 [D loss: 0.781511, acc: 39.06%] [G loss: 1.513007]\n",
      "epoch:4 step:3820 [D loss: 0.819551, acc: 39.84%] [G loss: 1.542607]\n",
      "epoch:4 step:3821 [D loss: 0.710316, acc: 55.47%] [G loss: 1.494357]\n",
      "epoch:4 step:3822 [D loss: 0.786521, acc: 39.84%] [G loss: 1.431442]\n",
      "epoch:4 step:3823 [D loss: 0.701004, acc: 57.03%] [G loss: 1.320106]\n",
      "epoch:4 step:3824 [D loss: 0.719990, acc: 53.91%] [G loss: 1.483840]\n",
      "epoch:4 step:3825 [D loss: 0.662370, acc: 60.16%] [G loss: 1.393166]\n",
      "epoch:4 step:3826 [D loss: 0.710722, acc: 50.78%] [G loss: 1.508254]\n",
      "epoch:4 step:3827 [D loss: 0.751577, acc: 46.09%] [G loss: 1.640111]\n",
      "epoch:4 step:3828 [D loss: 0.694184, acc: 52.34%] [G loss: 1.589330]\n",
      "epoch:4 step:3829 [D loss: 0.825388, acc: 38.28%] [G loss: 1.536350]\n",
      "epoch:4 step:3830 [D loss: 0.856070, acc: 35.94%] [G loss: 1.424974]\n",
      "epoch:4 step:3831 [D loss: 0.675265, acc: 59.38%] [G loss: 1.524769]\n",
      "epoch:4 step:3832 [D loss: 0.781571, acc: 45.31%] [G loss: 1.558936]\n",
      "epoch:4 step:3833 [D loss: 0.728833, acc: 56.25%] [G loss: 1.570079]\n",
      "epoch:4 step:3834 [D loss: 0.682613, acc: 57.81%] [G loss: 1.961272]\n",
      "epoch:4 step:3835 [D loss: 0.846775, acc: 45.31%] [G loss: 1.614049]\n",
      "epoch:4 step:3836 [D loss: 0.726261, acc: 49.22%] [G loss: 1.741537]\n",
      "epoch:4 step:3837 [D loss: 0.753766, acc: 46.88%] [G loss: 1.643986]\n",
      "epoch:4 step:3838 [D loss: 0.673290, acc: 62.50%] [G loss: 1.718795]\n",
      "epoch:4 step:3839 [D loss: 0.727367, acc: 53.91%] [G loss: 1.600340]\n",
      "epoch:4 step:3840 [D loss: 0.626084, acc: 67.97%] [G loss: 1.674828]\n",
      "epoch:4 step:3841 [D loss: 0.706174, acc: 53.91%] [G loss: 1.412719]\n",
      "epoch:4 step:3842 [D loss: 0.821833, acc: 28.91%] [G loss: 1.517919]\n",
      "epoch:4 step:3843 [D loss: 0.658091, acc: 67.19%] [G loss: 1.683114]\n",
      "epoch:4 step:3844 [D loss: 0.710449, acc: 53.12%] [G loss: 1.647391]\n",
      "epoch:4 step:3845 [D loss: 0.777475, acc: 38.28%] [G loss: 1.490234]\n",
      "epoch:4 step:3846 [D loss: 0.666667, acc: 71.09%] [G loss: 1.681451]\n",
      "epoch:4 step:3847 [D loss: 0.776211, acc: 46.09%] [G loss: 1.627271]\n",
      "epoch:4 step:3848 [D loss: 0.633716, acc: 62.50%] [G loss: 1.736821]\n",
      "epoch:4 step:3849 [D loss: 0.620231, acc: 66.41%] [G loss: 1.691115]\n",
      "epoch:4 step:3850 [D loss: 0.675728, acc: 60.16%] [G loss: 1.678541]\n",
      "epoch:4 step:3851 [D loss: 0.688500, acc: 59.38%] [G loss: 1.806359]\n",
      "epoch:4 step:3852 [D loss: 0.758267, acc: 46.88%] [G loss: 1.640103]\n",
      "epoch:4 step:3853 [D loss: 0.801826, acc: 40.62%] [G loss: 1.580801]\n",
      "epoch:4 step:3854 [D loss: 0.654748, acc: 64.84%] [G loss: 1.525638]\n",
      "epoch:4 step:3855 [D loss: 0.553843, acc: 75.78%] [G loss: 1.676544]\n",
      "epoch:4 step:3856 [D loss: 0.827302, acc: 35.94%] [G loss: 1.477340]\n",
      "epoch:4 step:3857 [D loss: 0.543070, acc: 82.03%] [G loss: 1.773227]\n",
      "epoch:4 step:3858 [D loss: 0.748323, acc: 46.88%] [G loss: 1.554753]\n",
      "epoch:4 step:3859 [D loss: 0.779748, acc: 53.91%] [G loss: 1.711946]\n",
      "epoch:4 step:3860 [D loss: 0.702533, acc: 58.59%] [G loss: 1.633688]\n",
      "epoch:4 step:3861 [D loss: 0.669803, acc: 60.16%] [G loss: 1.537813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3862 [D loss: 0.624789, acc: 68.75%] [G loss: 1.758613]\n",
      "epoch:4 step:3863 [D loss: 0.716209, acc: 49.22%] [G loss: 1.646844]\n",
      "epoch:4 step:3864 [D loss: 0.717105, acc: 53.91%] [G loss: 1.500631]\n",
      "epoch:4 step:3865 [D loss: 0.677186, acc: 55.47%] [G loss: 1.566331]\n",
      "epoch:4 step:3866 [D loss: 0.855790, acc: 35.16%] [G loss: 1.375189]\n",
      "epoch:4 step:3867 [D loss: 0.675093, acc: 66.41%] [G loss: 1.742637]\n",
      "epoch:4 step:3868 [D loss: 0.768091, acc: 39.84%] [G loss: 1.348939]\n",
      "epoch:4 step:3869 [D loss: 0.680765, acc: 53.91%] [G loss: 1.500820]\n",
      "epoch:4 step:3870 [D loss: 0.760401, acc: 44.53%] [G loss: 1.506279]\n",
      "epoch:4 step:3871 [D loss: 0.687555, acc: 59.38%] [G loss: 1.749838]\n",
      "epoch:4 step:3872 [D loss: 0.753674, acc: 46.09%] [G loss: 1.453024]\n",
      "epoch:4 step:3873 [D loss: 0.783342, acc: 43.75%] [G loss: 1.477294]\n",
      "epoch:4 step:3874 [D loss: 0.758882, acc: 46.09%] [G loss: 1.581526]\n",
      "epoch:4 step:3875 [D loss: 0.905209, acc: 23.44%] [G loss: 1.392150]\n",
      "epoch:4 step:3876 [D loss: 0.730605, acc: 48.44%] [G loss: 1.526775]\n",
      "epoch:4 step:3877 [D loss: 0.756244, acc: 43.75%] [G loss: 1.555897]\n",
      "epoch:4 step:3878 [D loss: 0.772235, acc: 42.19%] [G loss: 1.542181]\n",
      "epoch:4 step:3879 [D loss: 0.777508, acc: 38.28%] [G loss: 1.480527]\n",
      "epoch:4 step:3880 [D loss: 0.766451, acc: 49.22%] [G loss: 1.617916]\n",
      "epoch:4 step:3881 [D loss: 0.617118, acc: 60.94%] [G loss: 1.685565]\n",
      "epoch:4 step:3882 [D loss: 0.664443, acc: 64.84%] [G loss: 1.724183]\n",
      "epoch:4 step:3883 [D loss: 0.706563, acc: 46.09%] [G loss: 1.598173]\n",
      "epoch:4 step:3884 [D loss: 0.749633, acc: 50.00%] [G loss: 1.680150]\n",
      "epoch:4 step:3885 [D loss: 0.765098, acc: 41.41%] [G loss: 1.616890]\n",
      "epoch:4 step:3886 [D loss: 0.618366, acc: 65.62%] [G loss: 1.649696]\n",
      "epoch:4 step:3887 [D loss: 0.770752, acc: 46.88%] [G loss: 1.544273]\n",
      "epoch:4 step:3888 [D loss: 0.853833, acc: 30.47%] [G loss: 1.476789]\n",
      "epoch:4 step:3889 [D loss: 0.681083, acc: 54.69%] [G loss: 1.665450]\n",
      "epoch:4 step:3890 [D loss: 0.596933, acc: 74.22%] [G loss: 1.563199]\n",
      "epoch:4 step:3891 [D loss: 0.763736, acc: 42.19%] [G loss: 1.643002]\n",
      "epoch:4 step:3892 [D loss: 0.642025, acc: 63.28%] [G loss: 1.652925]\n",
      "epoch:4 step:3893 [D loss: 0.734892, acc: 45.31%] [G loss: 1.604099]\n",
      "epoch:4 step:3894 [D loss: 0.671511, acc: 56.25%] [G loss: 1.720807]\n",
      "epoch:4 step:3895 [D loss: 0.687853, acc: 57.81%] [G loss: 1.680274]\n",
      "epoch:4 step:3896 [D loss: 0.717755, acc: 49.22%] [G loss: 1.642318]\n",
      "epoch:4 step:3897 [D loss: 0.659727, acc: 59.38%] [G loss: 1.836484]\n",
      "epoch:4 step:3898 [D loss: 0.742119, acc: 46.09%] [G loss: 1.628942]\n",
      "epoch:4 step:3899 [D loss: 0.759430, acc: 42.19%] [G loss: 1.744712]\n",
      "epoch:4 step:3900 [D loss: 0.738047, acc: 49.22%] [G loss: 1.593963]\n",
      "epoch:4 step:3901 [D loss: 0.841809, acc: 35.16%] [G loss: 1.588200]\n",
      "epoch:4 step:3902 [D loss: 0.767600, acc: 42.97%] [G loss: 1.579618]\n",
      "epoch:4 step:3903 [D loss: 0.687421, acc: 55.47%] [G loss: 1.620640]\n",
      "epoch:4 step:3904 [D loss: 0.842941, acc: 31.25%] [G loss: 1.460709]\n",
      "epoch:4 step:3905 [D loss: 0.661627, acc: 58.59%] [G loss: 1.724430]\n",
      "epoch:5 step:3906 [D loss: 0.779713, acc: 38.28%] [G loss: 1.474309]\n",
      "epoch:5 step:3907 [D loss: 0.786730, acc: 44.53%] [G loss: 1.747507]\n",
      "epoch:5 step:3908 [D loss: 0.704170, acc: 60.94%] [G loss: 1.586013]\n",
      "epoch:5 step:3909 [D loss: 0.681384, acc: 55.47%] [G loss: 1.689748]\n",
      "epoch:5 step:3910 [D loss: 0.749268, acc: 48.44%] [G loss: 1.725629]\n",
      "epoch:5 step:3911 [D loss: 0.539392, acc: 69.53%] [G loss: 1.519783]\n",
      "epoch:5 step:3912 [D loss: 0.658822, acc: 62.50%] [G loss: 1.497462]\n",
      "epoch:5 step:3913 [D loss: 0.663697, acc: 64.06%] [G loss: 1.660835]\n",
      "epoch:5 step:3914 [D loss: 0.672399, acc: 58.59%] [G loss: 1.500948]\n",
      "epoch:5 step:3915 [D loss: 0.578758, acc: 75.78%] [G loss: 1.764853]\n",
      "epoch:5 step:3916 [D loss: 0.599739, acc: 69.53%] [G loss: 1.777625]\n",
      "epoch:5 step:3917 [D loss: 0.742344, acc: 43.75%] [G loss: 1.559767]\n",
      "epoch:5 step:3918 [D loss: 0.601699, acc: 69.53%] [G loss: 1.798909]\n",
      "epoch:5 step:3919 [D loss: 0.803886, acc: 40.62%] [G loss: 1.425496]\n",
      "epoch:5 step:3920 [D loss: 0.733142, acc: 47.66%] [G loss: 1.454036]\n",
      "epoch:5 step:3921 [D loss: 0.648024, acc: 60.16%] [G loss: 1.510452]\n",
      "epoch:5 step:3922 [D loss: 0.478770, acc: 88.28%] [G loss: 1.685705]\n",
      "epoch:5 step:3923 [D loss: 0.765559, acc: 42.19%] [G loss: 1.548096]\n",
      "epoch:5 step:3924 [D loss: 0.691688, acc: 58.59%] [G loss: 1.490891]\n",
      "epoch:5 step:3925 [D loss: 0.719896, acc: 50.78%] [G loss: 1.582120]\n",
      "epoch:5 step:3926 [D loss: 0.692269, acc: 53.91%] [G loss: 1.358208]\n",
      "epoch:5 step:3927 [D loss: 0.710154, acc: 57.81%] [G loss: 1.568530]\n",
      "epoch:5 step:3928 [D loss: 0.636918, acc: 64.84%] [G loss: 1.659802]\n",
      "epoch:5 step:3929 [D loss: 0.799763, acc: 37.50%] [G loss: 1.424307]\n",
      "epoch:5 step:3930 [D loss: 0.722745, acc: 53.12%] [G loss: 1.610980]\n",
      "epoch:5 step:3931 [D loss: 0.762913, acc: 35.16%] [G loss: 1.509586]\n",
      "epoch:5 step:3932 [D loss: 0.745153, acc: 48.44%] [G loss: 1.566427]\n",
      "epoch:5 step:3933 [D loss: 0.722698, acc: 48.44%] [G loss: 1.676429]\n",
      "epoch:5 step:3934 [D loss: 0.674499, acc: 59.38%] [G loss: 1.763289]\n",
      "epoch:5 step:3935 [D loss: 0.532151, acc: 85.94%] [G loss: 1.699372]\n",
      "epoch:5 step:3936 [D loss: 0.676972, acc: 65.62%] [G loss: 1.667761]\n",
      "epoch:5 step:3937 [D loss: 0.688934, acc: 60.16%] [G loss: 1.676567]\n",
      "epoch:5 step:3938 [D loss: 0.648093, acc: 54.69%] [G loss: 1.674461]\n",
      "epoch:5 step:3939 [D loss: 0.773491, acc: 36.72%] [G loss: 1.567252]\n",
      "epoch:5 step:3940 [D loss: 0.804219, acc: 35.94%] [G loss: 1.700373]\n",
      "epoch:5 step:3941 [D loss: 0.624154, acc: 67.97%] [G loss: 1.576677]\n",
      "epoch:5 step:3942 [D loss: 0.637777, acc: 64.06%] [G loss: 1.722611]\n",
      "epoch:5 step:3943 [D loss: 0.744869, acc: 48.44%] [G loss: 1.559345]\n",
      "epoch:5 step:3944 [D loss: 0.745162, acc: 46.09%] [G loss: 1.475880]\n",
      "epoch:5 step:3945 [D loss: 0.709943, acc: 48.44%] [G loss: 1.422741]\n",
      "epoch:5 step:3946 [D loss: 0.786661, acc: 46.88%] [G loss: 1.561526]\n",
      "epoch:5 step:3947 [D loss: 0.642110, acc: 60.94%] [G loss: 1.579322]\n",
      "epoch:5 step:3948 [D loss: 0.706135, acc: 55.47%] [G loss: 1.668235]\n",
      "epoch:5 step:3949 [D loss: 0.609849, acc: 71.88%] [G loss: 1.577715]\n",
      "epoch:5 step:3950 [D loss: 0.500872, acc: 79.69%] [G loss: 1.865798]\n",
      "epoch:5 step:3951 [D loss: 0.652101, acc: 58.59%] [G loss: 1.561299]\n",
      "epoch:5 step:3952 [D loss: 0.675245, acc: 58.59%] [G loss: 1.675521]\n",
      "epoch:5 step:3953 [D loss: 0.754530, acc: 47.66%] [G loss: 1.666240]\n",
      "epoch:5 step:3954 [D loss: 0.818358, acc: 39.84%] [G loss: 1.578883]\n",
      "epoch:5 step:3955 [D loss: 0.894975, acc: 23.44%] [G loss: 1.377886]\n",
      "epoch:5 step:3956 [D loss: 0.675649, acc: 63.28%] [G loss: 1.506592]\n",
      "epoch:5 step:3957 [D loss: 0.605009, acc: 69.53%] [G loss: 1.598184]\n",
      "epoch:5 step:3958 [D loss: 0.792135, acc: 35.94%] [G loss: 1.313247]\n",
      "epoch:5 step:3959 [D loss: 0.681906, acc: 56.25%] [G loss: 1.709905]\n",
      "epoch:5 step:3960 [D loss: 0.746868, acc: 46.09%] [G loss: 1.338368]\n",
      "epoch:5 step:3961 [D loss: 0.754431, acc: 39.84%] [G loss: 1.477581]\n",
      "epoch:5 step:3962 [D loss: 0.755599, acc: 44.53%] [G loss: 1.469408]\n",
      "epoch:5 step:3963 [D loss: 0.752660, acc: 44.53%] [G loss: 1.556295]\n",
      "epoch:5 step:3964 [D loss: 0.663198, acc: 53.91%] [G loss: 1.633332]\n",
      "epoch:5 step:3965 [D loss: 0.756139, acc: 42.97%] [G loss: 1.445337]\n",
      "epoch:5 step:3966 [D loss: 0.556925, acc: 68.75%] [G loss: 1.562808]\n",
      "epoch:5 step:3967 [D loss: 0.546469, acc: 77.34%] [G loss: 1.614560]\n",
      "epoch:5 step:3968 [D loss: 0.641688, acc: 58.59%] [G loss: 1.525855]\n",
      "epoch:5 step:3969 [D loss: 0.663200, acc: 55.47%] [G loss: 1.338365]\n",
      "epoch:5 step:3970 [D loss: 0.742916, acc: 50.00%] [G loss: 1.539820]\n",
      "epoch:5 step:3971 [D loss: 0.729762, acc: 49.22%] [G loss: 1.514131]\n",
      "epoch:5 step:3972 [D loss: 0.561617, acc: 78.91%] [G loss: 1.534628]\n",
      "epoch:5 step:3973 [D loss: 0.645029, acc: 64.84%] [G loss: 1.575987]\n",
      "epoch:5 step:3974 [D loss: 0.731984, acc: 53.91%] [G loss: 1.449064]\n",
      "epoch:5 step:3975 [D loss: 0.577547, acc: 78.12%] [G loss: 1.595881]\n",
      "epoch:5 step:3976 [D loss: 0.988760, acc: 22.66%] [G loss: 1.352461]\n",
      "epoch:5 step:3977 [D loss: 0.696904, acc: 49.22%] [G loss: 1.641315]\n",
      "epoch:5 step:3978 [D loss: 0.612988, acc: 68.75%] [G loss: 1.661554]\n",
      "epoch:5 step:3979 [D loss: 0.677584, acc: 55.47%] [G loss: 1.723804]\n",
      "epoch:5 step:3980 [D loss: 0.593017, acc: 67.97%] [G loss: 1.730310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:3981 [D loss: 1.036543, acc: 10.94%] [G loss: 1.565004]\n",
      "epoch:5 step:3982 [D loss: 0.707089, acc: 47.66%] [G loss: 1.463903]\n",
      "epoch:5 step:3983 [D loss: 0.701310, acc: 53.12%] [G loss: 1.714601]\n",
      "epoch:5 step:3984 [D loss: 0.682963, acc: 61.72%] [G loss: 1.632427]\n",
      "epoch:5 step:3985 [D loss: 0.727153, acc: 48.44%] [G loss: 1.587083]\n",
      "epoch:5 step:3986 [D loss: 0.599461, acc: 70.31%] [G loss: 1.772822]\n",
      "epoch:5 step:3987 [D loss: 0.742974, acc: 54.69%] [G loss: 1.672078]\n",
      "epoch:5 step:3988 [D loss: 0.727934, acc: 46.88%] [G loss: 1.685519]\n",
      "epoch:5 step:3989 [D loss: 0.686955, acc: 59.38%] [G loss: 1.613884]\n",
      "epoch:5 step:3990 [D loss: 0.628250, acc: 70.31%] [G loss: 1.995064]\n",
      "epoch:5 step:3991 [D loss: 0.742060, acc: 53.12%] [G loss: 1.653720]\n",
      "epoch:5 step:3992 [D loss: 0.563940, acc: 78.12%] [G loss: 1.729210]\n",
      "epoch:5 step:3993 [D loss: 0.758037, acc: 47.66%] [G loss: 1.574652]\n",
      "epoch:5 step:3994 [D loss: 0.624001, acc: 66.41%] [G loss: 1.623837]\n",
      "epoch:5 step:3995 [D loss: 0.655072, acc: 60.16%] [G loss: 1.516156]\n",
      "epoch:5 step:3996 [D loss: 0.701436, acc: 52.34%] [G loss: 1.590983]\n",
      "epoch:5 step:3997 [D loss: 0.656459, acc: 60.94%] [G loss: 1.549736]\n",
      "epoch:5 step:3998 [D loss: 0.732307, acc: 45.31%] [G loss: 1.620819]\n",
      "epoch:5 step:3999 [D loss: 0.777496, acc: 44.53%] [G loss: 1.618611]\n",
      "epoch:5 step:4000 [D loss: 0.651128, acc: 62.50%] [G loss: 1.575139]\n",
      "epoch:5 step:4001 [D loss: 0.672604, acc: 57.81%] [G loss: 1.489092]\n",
      "epoch:5 step:4002 [D loss: 0.744079, acc: 50.78%] [G loss: 1.454659]\n",
      "epoch:5 step:4003 [D loss: 0.680571, acc: 58.59%] [G loss: 1.492981]\n",
      "epoch:5 step:4004 [D loss: 0.663531, acc: 67.19%] [G loss: 1.671068]\n",
      "epoch:5 step:4005 [D loss: 0.687850, acc: 60.16%] [G loss: 1.635538]\n",
      "epoch:5 step:4006 [D loss: 0.654595, acc: 64.06%] [G loss: 1.665715]\n",
      "epoch:5 step:4007 [D loss: 0.697646, acc: 57.81%] [G loss: 1.454656]\n",
      "epoch:5 step:4008 [D loss: 0.741485, acc: 45.31%] [G loss: 1.600772]\n",
      "epoch:5 step:4009 [D loss: 0.673943, acc: 54.69%] [G loss: 1.354561]\n",
      "epoch:5 step:4010 [D loss: 0.766889, acc: 42.19%] [G loss: 1.651080]\n",
      "epoch:5 step:4011 [D loss: 0.642735, acc: 65.62%] [G loss: 1.677737]\n",
      "epoch:5 step:4012 [D loss: 0.649575, acc: 64.06%] [G loss: 1.910666]\n",
      "epoch:5 step:4013 [D loss: 1.026415, acc: 19.53%] [G loss: 1.664319]\n",
      "epoch:5 step:4014 [D loss: 0.701522, acc: 53.91%] [G loss: 1.540716]\n",
      "epoch:5 step:4015 [D loss: 0.741566, acc: 45.31%] [G loss: 1.657824]\n",
      "epoch:5 step:4016 [D loss: 0.718763, acc: 51.56%] [G loss: 1.588682]\n",
      "epoch:5 step:4017 [D loss: 0.760623, acc: 47.66%] [G loss: 1.523903]\n",
      "epoch:5 step:4018 [D loss: 0.711458, acc: 52.34%] [G loss: 1.730246]\n",
      "epoch:5 step:4019 [D loss: 0.514981, acc: 79.69%] [G loss: 1.922577]\n",
      "epoch:5 step:4020 [D loss: 0.616638, acc: 68.75%] [G loss: 1.774839]\n",
      "epoch:5 step:4021 [D loss: 0.639872, acc: 63.28%] [G loss: 1.522329]\n",
      "epoch:5 step:4022 [D loss: 0.731153, acc: 53.91%] [G loss: 1.702947]\n",
      "epoch:5 step:4023 [D loss: 0.676673, acc: 62.50%] [G loss: 1.673967]\n",
      "epoch:5 step:4024 [D loss: 0.611524, acc: 71.88%] [G loss: 1.711291]\n",
      "epoch:5 step:4025 [D loss: 0.666774, acc: 62.50%] [G loss: 1.697978]\n",
      "epoch:5 step:4026 [D loss: 0.649253, acc: 58.59%] [G loss: 1.747510]\n",
      "epoch:5 step:4027 [D loss: 0.602879, acc: 75.78%] [G loss: 1.719137]\n",
      "epoch:5 step:4028 [D loss: 0.630883, acc: 64.06%] [G loss: 1.727356]\n",
      "epoch:5 step:4029 [D loss: 0.612687, acc: 67.97%] [G loss: 1.766834]\n",
      "epoch:5 step:4030 [D loss: 0.826514, acc: 34.38%] [G loss: 1.520895]\n",
      "epoch:5 step:4031 [D loss: 0.647110, acc: 61.72%] [G loss: 1.802490]\n",
      "epoch:5 step:4032 [D loss: 0.690651, acc: 60.94%] [G loss: 1.754767]\n",
      "epoch:5 step:4033 [D loss: 0.662626, acc: 52.34%] [G loss: 1.670217]\n",
      "epoch:5 step:4034 [D loss: 0.581344, acc: 78.91%] [G loss: 1.702496]\n",
      "epoch:5 step:4035 [D loss: 0.676942, acc: 55.47%] [G loss: 1.616055]\n",
      "epoch:5 step:4036 [D loss: 0.732638, acc: 52.34%] [G loss: 1.587684]\n",
      "epoch:5 step:4037 [D loss: 0.791769, acc: 35.94%] [G loss: 1.590189]\n",
      "epoch:5 step:4038 [D loss: 0.652025, acc: 65.62%] [G loss: 1.721241]\n",
      "epoch:5 step:4039 [D loss: 0.739107, acc: 42.19%] [G loss: 1.686457]\n",
      "epoch:5 step:4040 [D loss: 0.611912, acc: 71.88%] [G loss: 2.040723]\n",
      "epoch:5 step:4041 [D loss: 0.601726, acc: 70.31%] [G loss: 1.717052]\n",
      "epoch:5 step:4042 [D loss: 0.804261, acc: 41.41%] [G loss: 1.524901]\n",
      "epoch:5 step:4043 [D loss: 0.670530, acc: 57.81%] [G loss: 1.813711]\n",
      "epoch:5 step:4044 [D loss: 0.699355, acc: 48.44%] [G loss: 1.669501]\n",
      "epoch:5 step:4045 [D loss: 0.562462, acc: 75.00%] [G loss: 1.847279]\n",
      "epoch:5 step:4046 [D loss: 0.631757, acc: 68.75%] [G loss: 1.524308]\n",
      "epoch:5 step:4047 [D loss: 0.650988, acc: 66.41%] [G loss: 1.606309]\n",
      "epoch:5 step:4048 [D loss: 0.634803, acc: 63.28%] [G loss: 1.913586]\n",
      "epoch:5 step:4049 [D loss: 0.570712, acc: 70.31%] [G loss: 1.553362]\n",
      "epoch:5 step:4050 [D loss: 0.609506, acc: 66.41%] [G loss: 1.858862]\n",
      "epoch:5 step:4051 [D loss: 0.700668, acc: 57.81%] [G loss: 1.523650]\n",
      "epoch:5 step:4052 [D loss: 0.733068, acc: 47.66%] [G loss: 1.680784]\n",
      "epoch:5 step:4053 [D loss: 0.621349, acc: 66.41%] [G loss: 1.924058]\n",
      "epoch:5 step:4054 [D loss: 0.887313, acc: 29.69%] [G loss: 1.621120]\n",
      "epoch:5 step:4055 [D loss: 0.863418, acc: 33.59%] [G loss: 1.505076]\n",
      "epoch:5 step:4056 [D loss: 0.710677, acc: 46.09%] [G loss: 1.489958]\n",
      "epoch:5 step:4057 [D loss: 0.767784, acc: 44.53%] [G loss: 1.391236]\n",
      "epoch:5 step:4058 [D loss: 0.791590, acc: 36.72%] [G loss: 1.469676]\n",
      "epoch:5 step:4059 [D loss: 0.774587, acc: 48.44%] [G loss: 1.754104]\n",
      "epoch:5 step:4060 [D loss: 0.662280, acc: 57.81%] [G loss: 1.825084]\n",
      "epoch:5 step:4061 [D loss: 0.832917, acc: 32.81%] [G loss: 1.491408]\n",
      "epoch:5 step:4062 [D loss: 0.482123, acc: 78.91%] [G loss: 1.629466]\n",
      "epoch:5 step:4063 [D loss: 0.670027, acc: 53.12%] [G loss: 1.481640]\n",
      "epoch:5 step:4064 [D loss: 0.663616, acc: 60.94%] [G loss: 1.706267]\n",
      "epoch:5 step:4065 [D loss: 0.696738, acc: 54.69%] [G loss: 1.468192]\n",
      "epoch:5 step:4066 [D loss: 0.734749, acc: 46.88%] [G loss: 1.624767]\n",
      "epoch:5 step:4067 [D loss: 0.675042, acc: 60.16%] [G loss: 1.587365]\n",
      "epoch:5 step:4068 [D loss: 0.725229, acc: 48.44%] [G loss: 1.614290]\n",
      "epoch:5 step:4069 [D loss: 0.684721, acc: 57.81%] [G loss: 1.622820]\n",
      "epoch:5 step:4070 [D loss: 0.762257, acc: 38.28%] [G loss: 1.555113]\n",
      "epoch:5 step:4071 [D loss: 1.129809, acc: 13.28%] [G loss: 1.322658]\n",
      "epoch:5 step:4072 [D loss: 0.517854, acc: 83.59%] [G loss: 1.705597]\n",
      "epoch:5 step:4073 [D loss: 0.759703, acc: 46.88%] [G loss: 1.693618]\n",
      "epoch:5 step:4074 [D loss: 0.746688, acc: 43.75%] [G loss: 1.579101]\n",
      "epoch:5 step:4075 [D loss: 0.716631, acc: 50.00%] [G loss: 1.673960]\n",
      "epoch:5 step:4076 [D loss: 0.635283, acc: 61.72%] [G loss: 1.610916]\n",
      "epoch:5 step:4077 [D loss: 0.689110, acc: 53.12%] [G loss: 1.657039]\n",
      "epoch:5 step:4078 [D loss: 0.705583, acc: 53.12%] [G loss: 1.612686]\n",
      "epoch:5 step:4079 [D loss: 0.658304, acc: 57.03%] [G loss: 1.821445]\n",
      "epoch:5 step:4080 [D loss: 0.664955, acc: 58.59%] [G loss: 1.827560]\n",
      "epoch:5 step:4081 [D loss: 0.631773, acc: 67.97%] [G loss: 1.689532]\n",
      "epoch:5 step:4082 [D loss: 0.726458, acc: 51.56%] [G loss: 1.585602]\n",
      "epoch:5 step:4083 [D loss: 0.674998, acc: 56.25%] [G loss: 1.515283]\n",
      "epoch:5 step:4084 [D loss: 0.774813, acc: 42.97%] [G loss: 1.532423]\n",
      "epoch:5 step:4085 [D loss: 0.731550, acc: 46.88%] [G loss: 1.539652]\n",
      "epoch:5 step:4086 [D loss: 0.672256, acc: 60.16%] [G loss: 1.604446]\n",
      "epoch:5 step:4087 [D loss: 0.682629, acc: 57.81%] [G loss: 1.596657]\n",
      "epoch:5 step:4088 [D loss: 0.534781, acc: 78.12%] [G loss: 1.890538]\n",
      "epoch:5 step:4089 [D loss: 0.834729, acc: 32.81%] [G loss: 1.656494]\n",
      "epoch:5 step:4090 [D loss: 0.493976, acc: 84.38%] [G loss: 1.794084]\n",
      "epoch:5 step:4091 [D loss: 0.659119, acc: 58.59%] [G loss: 2.004223]\n",
      "epoch:5 step:4092 [D loss: 0.560965, acc: 78.91%] [G loss: 1.726269]\n",
      "epoch:5 step:4093 [D loss: 0.635555, acc: 64.84%] [G loss: 1.708242]\n",
      "epoch:5 step:4094 [D loss: 0.748368, acc: 47.66%] [G loss: 1.659104]\n",
      "epoch:5 step:4095 [D loss: 0.761447, acc: 42.19%] [G loss: 1.696495]\n",
      "epoch:5 step:4096 [D loss: 0.607791, acc: 67.97%] [G loss: 1.613702]\n",
      "epoch:5 step:4097 [D loss: 0.624892, acc: 65.62%] [G loss: 1.339380]\n",
      "epoch:5 step:4098 [D loss: 0.642595, acc: 60.16%] [G loss: 1.842495]\n",
      "epoch:5 step:4099 [D loss: 0.632591, acc: 67.97%] [G loss: 1.554796]\n",
      "epoch:5 step:4100 [D loss: 0.767698, acc: 40.62%] [G loss: 1.339374]\n",
      "epoch:5 step:4101 [D loss: 1.040707, acc: 10.94%] [G loss: 1.173793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4102 [D loss: 0.690175, acc: 61.72%] [G loss: 1.990769]\n",
      "epoch:5 step:4103 [D loss: 0.624936, acc: 65.62%] [G loss: 1.578643]\n",
      "epoch:5 step:4104 [D loss: 0.712838, acc: 55.47%] [G loss: 1.614967]\n",
      "epoch:5 step:4105 [D loss: 0.697325, acc: 59.38%] [G loss: 1.392010]\n",
      "epoch:5 step:4106 [D loss: 0.791337, acc: 39.84%] [G loss: 1.557558]\n",
      "epoch:5 step:4107 [D loss: 0.940493, acc: 22.66%] [G loss: 1.422051]\n",
      "epoch:5 step:4108 [D loss: 0.745491, acc: 49.22%] [G loss: 1.619498]\n",
      "epoch:5 step:4109 [D loss: 0.685151, acc: 57.03%] [G loss: 1.513723]\n",
      "epoch:5 step:4110 [D loss: 0.948308, acc: 27.34%] [G loss: 1.467442]\n",
      "epoch:5 step:4111 [D loss: 0.630911, acc: 63.28%] [G loss: 1.885685]\n",
      "epoch:5 step:4112 [D loss: 0.735813, acc: 49.22%] [G loss: 1.757152]\n",
      "epoch:5 step:4113 [D loss: 0.617084, acc: 65.62%] [G loss: 1.762422]\n",
      "epoch:5 step:4114 [D loss: 0.701297, acc: 57.81%] [G loss: 1.814040]\n",
      "epoch:5 step:4115 [D loss: 0.744838, acc: 45.31%] [G loss: 1.447559]\n",
      "epoch:5 step:4116 [D loss: 0.733057, acc: 51.56%] [G loss: 1.433858]\n",
      "epoch:5 step:4117 [D loss: 0.604757, acc: 69.53%] [G loss: 1.641945]\n",
      "epoch:5 step:4118 [D loss: 0.761257, acc: 49.22%] [G loss: 1.545975]\n",
      "epoch:5 step:4119 [D loss: 0.677582, acc: 64.84%] [G loss: 1.573714]\n",
      "epoch:5 step:4120 [D loss: 0.669398, acc: 57.03%] [G loss: 1.567326]\n",
      "epoch:5 step:4121 [D loss: 0.670482, acc: 64.06%] [G loss: 1.520978]\n",
      "epoch:5 step:4122 [D loss: 0.721584, acc: 54.69%] [G loss: 1.743825]\n",
      "epoch:5 step:4123 [D loss: 0.684180, acc: 57.81%] [G loss: 1.479819]\n",
      "epoch:5 step:4124 [D loss: 0.751799, acc: 43.75%] [G loss: 1.718481]\n",
      "epoch:5 step:4125 [D loss: 0.661005, acc: 57.81%] [G loss: 1.546272]\n",
      "epoch:5 step:4126 [D loss: 0.692534, acc: 57.81%] [G loss: 1.693593]\n",
      "epoch:5 step:4127 [D loss: 0.729509, acc: 48.44%] [G loss: 1.667875]\n",
      "epoch:5 step:4128 [D loss: 0.797559, acc: 44.53%] [G loss: 1.552479]\n",
      "epoch:5 step:4129 [D loss: 0.543629, acc: 85.16%] [G loss: 1.564773]\n",
      "epoch:5 step:4130 [D loss: 0.903138, acc: 25.78%] [G loss: 1.320698]\n",
      "epoch:5 step:4131 [D loss: 0.792472, acc: 38.28%] [G loss: 1.491408]\n",
      "epoch:5 step:4132 [D loss: 0.568807, acc: 82.03%] [G loss: 1.590291]\n",
      "epoch:5 step:4133 [D loss: 0.517282, acc: 85.16%] [G loss: 1.831068]\n",
      "epoch:5 step:4134 [D loss: 0.723912, acc: 53.91%] [G loss: 1.603914]\n",
      "epoch:5 step:4135 [D loss: 0.779436, acc: 37.50%] [G loss: 1.500132]\n",
      "epoch:5 step:4136 [D loss: 0.689011, acc: 61.72%] [G loss: 1.573498]\n",
      "epoch:5 step:4137 [D loss: 0.762402, acc: 44.53%] [G loss: 1.655191]\n",
      "epoch:5 step:4138 [D loss: 0.727957, acc: 55.47%] [G loss: 1.594265]\n",
      "epoch:5 step:4139 [D loss: 0.698860, acc: 48.44%] [G loss: 1.650124]\n",
      "epoch:5 step:4140 [D loss: 0.637490, acc: 61.72%] [G loss: 1.859839]\n",
      "epoch:5 step:4141 [D loss: 0.654229, acc: 61.72%] [G loss: 1.937842]\n",
      "epoch:5 step:4142 [D loss: 0.659110, acc: 63.28%] [G loss: 1.743491]\n",
      "epoch:5 step:4143 [D loss: 0.647552, acc: 63.28%] [G loss: 1.614268]\n",
      "epoch:5 step:4144 [D loss: 0.596311, acc: 69.53%] [G loss: 1.896566]\n",
      "epoch:5 step:4145 [D loss: 0.581393, acc: 66.41%] [G loss: 1.791741]\n",
      "epoch:5 step:4146 [D loss: 0.708945, acc: 51.56%] [G loss: 1.643429]\n",
      "epoch:5 step:4147 [D loss: 0.662361, acc: 62.50%] [G loss: 1.457214]\n",
      "epoch:5 step:4148 [D loss: 0.754984, acc: 46.88%] [G loss: 1.418932]\n",
      "epoch:5 step:4149 [D loss: 0.479973, acc: 89.84%] [G loss: 1.722264]\n",
      "epoch:5 step:4150 [D loss: 0.813720, acc: 36.72%] [G loss: 1.406064]\n",
      "epoch:5 step:4151 [D loss: 0.597109, acc: 68.75%] [G loss: 1.593057]\n",
      "epoch:5 step:4152 [D loss: 0.629753, acc: 67.97%] [G loss: 1.529965]\n",
      "epoch:5 step:4153 [D loss: 0.800793, acc: 36.72%] [G loss: 1.578956]\n",
      "epoch:5 step:4154 [D loss: 0.741788, acc: 45.31%] [G loss: 1.854904]\n",
      "epoch:5 step:4155 [D loss: 0.768382, acc: 47.66%] [G loss: 1.950745]\n",
      "epoch:5 step:4156 [D loss: 0.596039, acc: 68.75%] [G loss: 1.925918]\n",
      "epoch:5 step:4157 [D loss: 0.808420, acc: 45.31%] [G loss: 1.635488]\n",
      "epoch:5 step:4158 [D loss: 0.876691, acc: 28.12%] [G loss: 1.667572]\n",
      "epoch:5 step:4159 [D loss: 0.853375, acc: 35.16%] [G loss: 1.548892]\n",
      "epoch:5 step:4160 [D loss: 0.763002, acc: 43.75%] [G loss: 1.639264]\n",
      "epoch:5 step:4161 [D loss: 0.544537, acc: 75.00%] [G loss: 1.996201]\n",
      "epoch:5 step:4162 [D loss: 0.680486, acc: 55.47%] [G loss: 1.569926]\n",
      "epoch:5 step:4163 [D loss: 0.724402, acc: 51.56%] [G loss: 1.810112]\n",
      "epoch:5 step:4164 [D loss: 0.728510, acc: 55.47%] [G loss: 1.613887]\n",
      "epoch:5 step:4165 [D loss: 0.643531, acc: 65.62%] [G loss: 1.742949]\n",
      "epoch:5 step:4166 [D loss: 0.674527, acc: 61.72%] [G loss: 1.475086]\n",
      "epoch:5 step:4167 [D loss: 0.553637, acc: 75.78%] [G loss: 1.749257]\n",
      "epoch:5 step:4168 [D loss: 0.918091, acc: 28.91%] [G loss: 1.551940]\n",
      "epoch:5 step:4169 [D loss: 0.741031, acc: 50.78%] [G loss: 1.560630]\n",
      "epoch:5 step:4170 [D loss: 0.591118, acc: 73.44%] [G loss: 1.798528]\n",
      "epoch:5 step:4171 [D loss: 0.618170, acc: 68.75%] [G loss: 1.797981]\n",
      "epoch:5 step:4172 [D loss: 0.814669, acc: 29.69%] [G loss: 1.585547]\n",
      "epoch:5 step:4173 [D loss: 0.680713, acc: 60.94%] [G loss: 1.628952]\n",
      "epoch:5 step:4174 [D loss: 0.440782, acc: 85.16%] [G loss: 1.784327]\n",
      "epoch:5 step:4175 [D loss: 0.491812, acc: 80.47%] [G loss: 1.780572]\n",
      "epoch:5 step:4176 [D loss: 0.579706, acc: 74.22%] [G loss: 2.086424]\n",
      "epoch:5 step:4177 [D loss: 0.428443, acc: 92.97%] [G loss: 1.978474]\n",
      "epoch:5 step:4178 [D loss: 0.925480, acc: 24.22%] [G loss: 1.430336]\n",
      "epoch:5 step:4179 [D loss: 0.696975, acc: 55.47%] [G loss: 1.650203]\n",
      "epoch:5 step:4180 [D loss: 0.856501, acc: 39.84%] [G loss: 1.415500]\n",
      "epoch:5 step:4181 [D loss: 0.685573, acc: 56.25%] [G loss: 1.574688]\n",
      "epoch:5 step:4182 [D loss: 1.293279, acc: 3.91%] [G loss: 1.095463]\n",
      "epoch:5 step:4183 [D loss: 0.688571, acc: 58.59%] [G loss: 1.555458]\n",
      "epoch:5 step:4184 [D loss: 0.804458, acc: 37.50%] [G loss: 1.395777]\n",
      "epoch:5 step:4185 [D loss: 0.692242, acc: 53.12%] [G loss: 1.687142]\n",
      "epoch:5 step:4186 [D loss: 0.698295, acc: 50.00%] [G loss: 1.527741]\n",
      "epoch:5 step:4187 [D loss: 0.829368, acc: 39.84%] [G loss: 1.258827]\n",
      "epoch:5 step:4188 [D loss: 0.707690, acc: 57.81%] [G loss: 1.518299]\n",
      "epoch:5 step:4189 [D loss: 0.845343, acc: 30.47%] [G loss: 1.539678]\n",
      "epoch:5 step:4190 [D loss: 0.707915, acc: 50.00%] [G loss: 1.566157]\n",
      "epoch:5 step:4191 [D loss: 0.755630, acc: 40.62%] [G loss: 1.456043]\n",
      "epoch:5 step:4192 [D loss: 0.650864, acc: 56.25%] [G loss: 1.476333]\n",
      "epoch:5 step:4193 [D loss: 0.725754, acc: 53.12%] [G loss: 1.592867]\n",
      "epoch:5 step:4194 [D loss: 0.664083, acc: 60.94%] [G loss: 1.447715]\n",
      "epoch:5 step:4195 [D loss: 0.534759, acc: 77.34%] [G loss: 1.606634]\n",
      "epoch:5 step:4196 [D loss: 0.814150, acc: 37.50%] [G loss: 1.488141]\n",
      "epoch:5 step:4197 [D loss: 0.843522, acc: 28.12%] [G loss: 1.447825]\n",
      "epoch:5 step:4198 [D loss: 0.647057, acc: 63.28%] [G loss: 1.611386]\n",
      "epoch:5 step:4199 [D loss: 0.685392, acc: 57.81%] [G loss: 1.580370]\n",
      "epoch:5 step:4200 [D loss: 0.811775, acc: 34.38%] [G loss: 1.601772]\n",
      "epoch:5 step:4201 [D loss: 0.676135, acc: 56.25%] [G loss: 1.525941]\n",
      "epoch:5 step:4202 [D loss: 0.699836, acc: 46.09%] [G loss: 1.680173]\n",
      "epoch:5 step:4203 [D loss: 0.817236, acc: 32.03%] [G loss: 1.419869]\n",
      "epoch:5 step:4204 [D loss: 0.613787, acc: 69.53%] [G loss: 1.636826]\n",
      "epoch:5 step:4205 [D loss: 0.805895, acc: 35.94%] [G loss: 1.442079]\n",
      "epoch:5 step:4206 [D loss: 0.655203, acc: 67.19%] [G loss: 1.623555]\n",
      "epoch:5 step:4207 [D loss: 0.772833, acc: 50.78%] [G loss: 1.433691]\n",
      "epoch:5 step:4208 [D loss: 0.638713, acc: 64.06%] [G loss: 1.640903]\n",
      "epoch:5 step:4209 [D loss: 0.679454, acc: 55.47%] [G loss: 1.600808]\n",
      "epoch:5 step:4210 [D loss: 0.768801, acc: 46.09%] [G loss: 1.550593]\n",
      "epoch:5 step:4211 [D loss: 0.548587, acc: 77.34%] [G loss: 1.473398]\n",
      "epoch:5 step:4212 [D loss: 0.824926, acc: 30.47%] [G loss: 1.403754]\n",
      "epoch:5 step:4213 [D loss: 0.672277, acc: 68.75%] [G loss: 1.680431]\n",
      "epoch:5 step:4214 [D loss: 0.719356, acc: 48.44%] [G loss: 1.473633]\n",
      "epoch:5 step:4215 [D loss: 0.731273, acc: 44.53%] [G loss: 1.623685]\n",
      "epoch:5 step:4216 [D loss: 0.699366, acc: 52.34%] [G loss: 1.578272]\n",
      "epoch:5 step:4217 [D loss: 0.684896, acc: 54.69%] [G loss: 1.666450]\n",
      "epoch:5 step:4218 [D loss: 0.673826, acc: 60.16%] [G loss: 1.526944]\n",
      "epoch:5 step:4219 [D loss: 0.734587, acc: 45.31%] [G loss: 1.504283]\n",
      "epoch:5 step:4220 [D loss: 0.663051, acc: 57.03%] [G loss: 1.687553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4221 [D loss: 0.642878, acc: 65.62%] [G loss: 1.463750]\n",
      "epoch:5 step:4222 [D loss: 0.685553, acc: 56.25%] [G loss: 1.474570]\n",
      "epoch:5 step:4223 [D loss: 0.709126, acc: 48.44%] [G loss: 1.566636]\n",
      "epoch:5 step:4224 [D loss: 0.730335, acc: 51.56%] [G loss: 1.350332]\n",
      "epoch:5 step:4225 [D loss: 0.752346, acc: 47.66%] [G loss: 1.580045]\n",
      "epoch:5 step:4226 [D loss: 0.695809, acc: 49.22%] [G loss: 1.668976]\n",
      "epoch:5 step:4227 [D loss: 0.802091, acc: 42.19%] [G loss: 1.520267]\n",
      "epoch:5 step:4228 [D loss: 0.693576, acc: 59.38%] [G loss: 1.457856]\n",
      "epoch:5 step:4229 [D loss: 0.720880, acc: 53.12%] [G loss: 1.435364]\n",
      "epoch:5 step:4230 [D loss: 0.618024, acc: 67.19%] [G loss: 1.683774]\n",
      "epoch:5 step:4231 [D loss: 0.774176, acc: 42.97%] [G loss: 1.577517]\n",
      "epoch:5 step:4232 [D loss: 0.688460, acc: 55.47%] [G loss: 1.711743]\n",
      "epoch:5 step:4233 [D loss: 0.690427, acc: 56.25%] [G loss: 1.587064]\n",
      "epoch:5 step:4234 [D loss: 0.729183, acc: 48.44%] [G loss: 1.632900]\n",
      "epoch:5 step:4235 [D loss: 0.738204, acc: 44.53%] [G loss: 1.639655]\n",
      "epoch:5 step:4236 [D loss: 0.643211, acc: 65.62%] [G loss: 1.650381]\n",
      "epoch:5 step:4237 [D loss: 0.624282, acc: 67.19%] [G loss: 1.787774]\n",
      "epoch:5 step:4238 [D loss: 0.731165, acc: 48.44%] [G loss: 1.689498]\n",
      "epoch:5 step:4239 [D loss: 0.673837, acc: 57.81%] [G loss: 1.697826]\n",
      "epoch:5 step:4240 [D loss: 0.753956, acc: 43.75%] [G loss: 1.607930]\n",
      "epoch:5 step:4241 [D loss: 0.716809, acc: 56.25%] [G loss: 1.539688]\n",
      "epoch:5 step:4242 [D loss: 0.747619, acc: 40.62%] [G loss: 1.745720]\n",
      "epoch:5 step:4243 [D loss: 0.883991, acc: 32.81%] [G loss: 1.713371]\n",
      "epoch:5 step:4244 [D loss: 0.800153, acc: 35.94%] [G loss: 1.340414]\n",
      "epoch:5 step:4245 [D loss: 0.723915, acc: 55.47%] [G loss: 1.687274]\n",
      "epoch:5 step:4246 [D loss: 0.745538, acc: 50.78%] [G loss: 1.613268]\n",
      "epoch:5 step:4247 [D loss: 0.683481, acc: 55.47%] [G loss: 1.691979]\n",
      "epoch:5 step:4248 [D loss: 0.750368, acc: 52.34%] [G loss: 1.680920]\n",
      "epoch:5 step:4249 [D loss: 0.466663, acc: 85.16%] [G loss: 1.786265]\n",
      "epoch:5 step:4250 [D loss: 0.521421, acc: 82.81%] [G loss: 1.720162]\n",
      "epoch:5 step:4251 [D loss: 0.753577, acc: 49.22%] [G loss: 1.495562]\n",
      "epoch:5 step:4252 [D loss: 0.763026, acc: 49.22%] [G loss: 1.393281]\n",
      "epoch:5 step:4253 [D loss: 0.717988, acc: 50.00%] [G loss: 1.665267]\n",
      "epoch:5 step:4254 [D loss: 0.683794, acc: 60.94%] [G loss: 1.457502]\n",
      "epoch:5 step:4255 [D loss: 0.868707, acc: 32.81%] [G loss: 1.387483]\n",
      "epoch:5 step:4256 [D loss: 0.704511, acc: 53.91%] [G loss: 1.409538]\n",
      "epoch:5 step:4257 [D loss: 0.793762, acc: 39.06%] [G loss: 1.478176]\n",
      "epoch:5 step:4258 [D loss: 0.868247, acc: 24.22%] [G loss: 1.463885]\n",
      "epoch:5 step:4259 [D loss: 0.746442, acc: 42.97%] [G loss: 1.572794]\n",
      "epoch:5 step:4260 [D loss: 0.890832, acc: 30.47%] [G loss: 1.499426]\n",
      "epoch:5 step:4261 [D loss: 0.684940, acc: 54.69%] [G loss: 1.709875]\n",
      "epoch:5 step:4262 [D loss: 0.647895, acc: 56.25%] [G loss: 1.545779]\n",
      "epoch:5 step:4263 [D loss: 0.634391, acc: 66.41%] [G loss: 1.643237]\n",
      "epoch:5 step:4264 [D loss: 0.608655, acc: 74.22%] [G loss: 1.626734]\n",
      "epoch:5 step:4265 [D loss: 0.703401, acc: 53.12%] [G loss: 1.620242]\n",
      "epoch:5 step:4266 [D loss: 0.826739, acc: 33.59%] [G loss: 1.554185]\n",
      "epoch:5 step:4267 [D loss: 0.729100, acc: 53.12%] [G loss: 1.466823]\n",
      "epoch:5 step:4268 [D loss: 0.723492, acc: 46.88%] [G loss: 1.559498]\n",
      "epoch:5 step:4269 [D loss: 0.776570, acc: 42.19%] [G loss: 1.570536]\n",
      "epoch:5 step:4270 [D loss: 0.633101, acc: 64.06%] [G loss: 1.737195]\n",
      "epoch:5 step:4271 [D loss: 0.685205, acc: 53.91%] [G loss: 1.617524]\n",
      "epoch:5 step:4272 [D loss: 0.759601, acc: 42.97%] [G loss: 1.507801]\n",
      "epoch:5 step:4273 [D loss: 0.694316, acc: 61.72%] [G loss: 1.419392]\n",
      "epoch:5 step:4274 [D loss: 0.714114, acc: 47.66%] [G loss: 1.653400]\n",
      "epoch:5 step:4275 [D loss: 0.652375, acc: 59.38%] [G loss: 1.776248]\n",
      "epoch:5 step:4276 [D loss: 0.719256, acc: 46.09%] [G loss: 1.551206]\n",
      "epoch:5 step:4277 [D loss: 0.691995, acc: 54.69%] [G loss: 1.609027]\n",
      "epoch:5 step:4278 [D loss: 0.899255, acc: 21.09%] [G loss: 1.345689]\n",
      "epoch:5 step:4279 [D loss: 0.603205, acc: 69.53%] [G loss: 1.459584]\n",
      "epoch:5 step:4280 [D loss: 0.655327, acc: 56.25%] [G loss: 1.501104]\n",
      "epoch:5 step:4281 [D loss: 0.652569, acc: 63.28%] [G loss: 1.517979]\n",
      "epoch:5 step:4282 [D loss: 0.709998, acc: 51.56%] [G loss: 1.409348]\n",
      "epoch:5 step:4283 [D loss: 0.790790, acc: 32.81%] [G loss: 1.413361]\n",
      "epoch:5 step:4284 [D loss: 0.532164, acc: 92.19%] [G loss: 1.438658]\n",
      "epoch:5 step:4285 [D loss: 0.654344, acc: 60.16%] [G loss: 1.619362]\n",
      "epoch:5 step:4286 [D loss: 0.739701, acc: 52.34%] [G loss: 1.524441]\n",
      "epoch:5 step:4287 [D loss: 0.658864, acc: 62.50%] [G loss: 1.452915]\n",
      "epoch:5 step:4288 [D loss: 0.675490, acc: 57.03%] [G loss: 1.491726]\n",
      "epoch:5 step:4289 [D loss: 0.793752, acc: 34.38%] [G loss: 1.427210]\n",
      "epoch:5 step:4290 [D loss: 0.899380, acc: 18.75%] [G loss: 1.367249]\n",
      "epoch:5 step:4291 [D loss: 0.718964, acc: 42.19%] [G loss: 1.502885]\n",
      "epoch:5 step:4292 [D loss: 0.841106, acc: 34.38%] [G loss: 1.458335]\n",
      "epoch:5 step:4293 [D loss: 0.619317, acc: 68.75%] [G loss: 1.635271]\n",
      "epoch:5 step:4294 [D loss: 0.618240, acc: 69.53%] [G loss: 1.719024]\n",
      "epoch:5 step:4295 [D loss: 0.759310, acc: 48.44%] [G loss: 1.583031]\n",
      "epoch:5 step:4296 [D loss: 0.757168, acc: 44.53%] [G loss: 1.579992]\n",
      "epoch:5 step:4297 [D loss: 0.718542, acc: 55.47%] [G loss: 1.446062]\n",
      "epoch:5 step:4298 [D loss: 0.730990, acc: 47.66%] [G loss: 1.457305]\n",
      "epoch:5 step:4299 [D loss: 0.636662, acc: 66.41%] [G loss: 1.575794]\n",
      "epoch:5 step:4300 [D loss: 0.716078, acc: 54.69%] [G loss: 1.720110]\n",
      "epoch:5 step:4301 [D loss: 0.678562, acc: 53.91%] [G loss: 1.626611]\n",
      "epoch:5 step:4302 [D loss: 0.614740, acc: 69.53%] [G loss: 1.688927]\n",
      "epoch:5 step:4303 [D loss: 0.737572, acc: 49.22%] [G loss: 1.621274]\n",
      "epoch:5 step:4304 [D loss: 0.798117, acc: 37.50%] [G loss: 1.513756]\n",
      "epoch:5 step:4305 [D loss: 0.681875, acc: 57.03%] [G loss: 1.606280]\n",
      "epoch:5 step:4306 [D loss: 0.586372, acc: 77.34%] [G loss: 1.512977]\n",
      "epoch:5 step:4307 [D loss: 0.783465, acc: 46.88%] [G loss: 1.773259]\n",
      "epoch:5 step:4308 [D loss: 0.755230, acc: 42.19%] [G loss: 1.683189]\n",
      "epoch:5 step:4309 [D loss: 0.715630, acc: 48.44%] [G loss: 1.665139]\n",
      "epoch:5 step:4310 [D loss: 0.799389, acc: 37.50%] [G loss: 1.553669]\n",
      "epoch:5 step:4311 [D loss: 0.715950, acc: 51.56%] [G loss: 1.501059]\n",
      "epoch:5 step:4312 [D loss: 0.723763, acc: 48.44%] [G loss: 1.497065]\n",
      "epoch:5 step:4313 [D loss: 0.697438, acc: 57.03%] [G loss: 1.535135]\n",
      "epoch:5 step:4314 [D loss: 0.705423, acc: 53.12%] [G loss: 1.589286]\n",
      "epoch:5 step:4315 [D loss: 0.497862, acc: 84.38%] [G loss: 1.698415]\n",
      "epoch:5 step:4316 [D loss: 0.869422, acc: 30.47%] [G loss: 1.604496]\n",
      "epoch:5 step:4317 [D loss: 0.769454, acc: 44.53%] [G loss: 1.662153]\n",
      "epoch:5 step:4318 [D loss: 0.806514, acc: 39.06%] [G loss: 1.545535]\n",
      "epoch:5 step:4319 [D loss: 0.741982, acc: 46.88%] [G loss: 1.449225]\n",
      "epoch:5 step:4320 [D loss: 0.677935, acc: 57.03%] [G loss: 1.562783]\n",
      "epoch:5 step:4321 [D loss: 0.606304, acc: 64.06%] [G loss: 1.518807]\n",
      "epoch:5 step:4322 [D loss: 0.688835, acc: 50.00%] [G loss: 1.543702]\n",
      "epoch:5 step:4323 [D loss: 0.719734, acc: 46.09%] [G loss: 1.705420]\n",
      "epoch:5 step:4324 [D loss: 0.759473, acc: 39.06%] [G loss: 1.527704]\n",
      "epoch:5 step:4325 [D loss: 0.733186, acc: 50.00%] [G loss: 1.469031]\n",
      "epoch:5 step:4326 [D loss: 0.685492, acc: 60.94%] [G loss: 1.674577]\n",
      "epoch:5 step:4327 [D loss: 0.752089, acc: 40.62%] [G loss: 1.593498]\n",
      "epoch:5 step:4328 [D loss: 0.664427, acc: 63.28%] [G loss: 1.531118]\n",
      "epoch:5 step:4329 [D loss: 0.986233, acc: 28.12%] [G loss: 1.528261]\n",
      "epoch:5 step:4330 [D loss: 0.785691, acc: 41.41%] [G loss: 1.735404]\n",
      "epoch:5 step:4331 [D loss: 0.655638, acc: 63.28%] [G loss: 1.723910]\n",
      "epoch:5 step:4332 [D loss: 0.722437, acc: 44.53%] [G loss: 1.538700]\n",
      "epoch:5 step:4333 [D loss: 0.744528, acc: 43.75%] [G loss: 1.629324]\n",
      "epoch:5 step:4334 [D loss: 0.783363, acc: 35.16%] [G loss: 1.498201]\n",
      "epoch:5 step:4335 [D loss: 0.788699, acc: 35.16%] [G loss: 1.408109]\n",
      "epoch:5 step:4336 [D loss: 0.819369, acc: 30.47%] [G loss: 1.434204]\n",
      "epoch:5 step:4337 [D loss: 0.679423, acc: 61.72%] [G loss: 1.781987]\n",
      "epoch:5 step:4338 [D loss: 0.739800, acc: 50.00%] [G loss: 1.591740]\n",
      "epoch:5 step:4339 [D loss: 0.689347, acc: 56.25%] [G loss: 1.431086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4340 [D loss: 0.706888, acc: 53.91%] [G loss: 1.607909]\n",
      "epoch:5 step:4341 [D loss: 0.681396, acc: 51.56%] [G loss: 1.641338]\n",
      "epoch:5 step:4342 [D loss: 0.793006, acc: 39.84%] [G loss: 1.464247]\n",
      "epoch:5 step:4343 [D loss: 0.713981, acc: 52.34%] [G loss: 1.593792]\n",
      "epoch:5 step:4344 [D loss: 0.720685, acc: 56.25%] [G loss: 1.630283]\n",
      "epoch:5 step:4345 [D loss: 0.697602, acc: 53.12%] [G loss: 1.546309]\n",
      "epoch:5 step:4346 [D loss: 0.865554, acc: 21.88%] [G loss: 1.380542]\n",
      "epoch:5 step:4347 [D loss: 0.693310, acc: 53.12%] [G loss: 1.520781]\n",
      "epoch:5 step:4348 [D loss: 0.634254, acc: 67.19%] [G loss: 1.595643]\n",
      "epoch:5 step:4349 [D loss: 0.845834, acc: 28.91%] [G loss: 1.509161]\n",
      "epoch:5 step:4350 [D loss: 0.709673, acc: 56.25%] [G loss: 1.559845]\n",
      "epoch:5 step:4351 [D loss: 0.688249, acc: 57.81%] [G loss: 1.642678]\n",
      "epoch:5 step:4352 [D loss: 0.706088, acc: 60.16%] [G loss: 1.615070]\n",
      "epoch:5 step:4353 [D loss: 0.627127, acc: 68.75%] [G loss: 1.578174]\n",
      "epoch:5 step:4354 [D loss: 0.810218, acc: 36.72%] [G loss: 1.405935]\n",
      "epoch:5 step:4355 [D loss: 0.670337, acc: 57.81%] [G loss: 1.621381]\n",
      "epoch:5 step:4356 [D loss: 0.741834, acc: 40.62%] [G loss: 1.643536]\n",
      "epoch:5 step:4357 [D loss: 0.652493, acc: 57.81%] [G loss: 1.596228]\n",
      "epoch:5 step:4358 [D loss: 0.721811, acc: 56.25%] [G loss: 1.698578]\n",
      "epoch:5 step:4359 [D loss: 0.561399, acc: 75.78%] [G loss: 1.563186]\n",
      "epoch:5 step:4360 [D loss: 0.624036, acc: 68.75%] [G loss: 1.671698]\n",
      "epoch:5 step:4361 [D loss: 0.722440, acc: 50.78%] [G loss: 1.505260]\n",
      "epoch:5 step:4362 [D loss: 0.678913, acc: 54.69%] [G loss: 1.546285]\n",
      "epoch:5 step:4363 [D loss: 0.759817, acc: 45.31%] [G loss: 1.404977]\n",
      "epoch:5 step:4364 [D loss: 0.779398, acc: 38.28%] [G loss: 1.448307]\n",
      "epoch:5 step:4365 [D loss: 0.685681, acc: 56.25%] [G loss: 1.731315]\n",
      "epoch:5 step:4366 [D loss: 0.546684, acc: 79.69%] [G loss: 1.598961]\n",
      "epoch:5 step:4367 [D loss: 0.682923, acc: 60.94%] [G loss: 1.604831]\n",
      "epoch:5 step:4368 [D loss: 0.639282, acc: 64.84%] [G loss: 1.692525]\n",
      "epoch:5 step:4369 [D loss: 0.668008, acc: 55.47%] [G loss: 1.588625]\n",
      "epoch:5 step:4370 [D loss: 0.763341, acc: 42.97%] [G loss: 1.574650]\n",
      "epoch:5 step:4371 [D loss: 0.679232, acc: 60.16%] [G loss: 1.578038]\n",
      "epoch:5 step:4372 [D loss: 0.610731, acc: 68.75%] [G loss: 1.720909]\n",
      "epoch:5 step:4373 [D loss: 0.803795, acc: 39.84%] [G loss: 1.455598]\n",
      "epoch:5 step:4374 [D loss: 0.729879, acc: 49.22%] [G loss: 1.519027]\n",
      "epoch:5 step:4375 [D loss: 0.612191, acc: 75.78%] [G loss: 1.558888]\n",
      "epoch:5 step:4376 [D loss: 0.754998, acc: 41.41%] [G loss: 1.533190]\n",
      "epoch:5 step:4377 [D loss: 0.646047, acc: 67.19%] [G loss: 1.527768]\n",
      "epoch:5 step:4378 [D loss: 0.744776, acc: 41.41%] [G loss: 1.623180]\n",
      "epoch:5 step:4379 [D loss: 0.877696, acc: 22.66%] [G loss: 1.285643]\n",
      "epoch:5 step:4380 [D loss: 0.791511, acc: 42.97%] [G loss: 1.570602]\n",
      "epoch:5 step:4381 [D loss: 0.642355, acc: 64.06%] [G loss: 1.480276]\n",
      "epoch:5 step:4382 [D loss: 0.782690, acc: 38.28%] [G loss: 1.425946]\n",
      "epoch:5 step:4383 [D loss: 0.727325, acc: 52.34%] [G loss: 1.750840]\n",
      "epoch:5 step:4384 [D loss: 0.805642, acc: 39.06%] [G loss: 1.478146]\n",
      "epoch:5 step:4385 [D loss: 0.764641, acc: 42.19%] [G loss: 1.632450]\n",
      "epoch:5 step:4386 [D loss: 0.628790, acc: 67.19%] [G loss: 1.744159]\n",
      "epoch:5 step:4387 [D loss: 0.925700, acc: 22.66%] [G loss: 1.531210]\n",
      "epoch:5 step:4388 [D loss: 0.793777, acc: 46.09%] [G loss: 1.464501]\n",
      "epoch:5 step:4389 [D loss: 0.713664, acc: 50.78%] [G loss: 1.575537]\n",
      "epoch:5 step:4390 [D loss: 0.766735, acc: 45.31%] [G loss: 1.569861]\n",
      "epoch:5 step:4391 [D loss: 0.683441, acc: 50.78%] [G loss: 1.813682]\n",
      "epoch:5 step:4392 [D loss: 0.747650, acc: 46.09%] [G loss: 1.509437]\n",
      "epoch:5 step:4393 [D loss: 0.712026, acc: 49.22%] [G loss: 1.526541]\n",
      "epoch:5 step:4394 [D loss: 0.788233, acc: 42.97%] [G loss: 1.589773]\n",
      "epoch:5 step:4395 [D loss: 0.671114, acc: 59.38%] [G loss: 1.604233]\n",
      "epoch:5 step:4396 [D loss: 0.732376, acc: 51.56%] [G loss: 1.563461]\n",
      "epoch:5 step:4397 [D loss: 0.702526, acc: 52.34%] [G loss: 1.525180]\n",
      "epoch:5 step:4398 [D loss: 0.618749, acc: 73.44%] [G loss: 1.808699]\n",
      "epoch:5 step:4399 [D loss: 0.780634, acc: 42.19%] [G loss: 1.534511]\n",
      "epoch:5 step:4400 [D loss: 0.594517, acc: 75.78%] [G loss: 1.739987]\n",
      "epoch:5 step:4401 [D loss: 0.650828, acc: 60.94%] [G loss: 1.489317]\n",
      "epoch:5 step:4402 [D loss: 0.641897, acc: 65.62%] [G loss: 1.662949]\n",
      "epoch:5 step:4403 [D loss: 0.775038, acc: 42.19%] [G loss: 1.552704]\n",
      "epoch:5 step:4404 [D loss: 0.845721, acc: 32.81%] [G loss: 1.471172]\n",
      "epoch:5 step:4405 [D loss: 0.669229, acc: 66.41%] [G loss: 1.535215]\n",
      "epoch:5 step:4406 [D loss: 0.666454, acc: 60.16%] [G loss: 1.435035]\n",
      "epoch:5 step:4407 [D loss: 0.607837, acc: 69.53%] [G loss: 1.395449]\n",
      "epoch:5 step:4408 [D loss: 0.726778, acc: 53.91%] [G loss: 1.565957]\n",
      "epoch:5 step:4409 [D loss: 0.798211, acc: 37.50%] [G loss: 1.405987]\n",
      "epoch:5 step:4410 [D loss: 0.704121, acc: 50.00%] [G loss: 1.466041]\n",
      "epoch:5 step:4411 [D loss: 0.669752, acc: 57.81%] [G loss: 1.570975]\n",
      "epoch:5 step:4412 [D loss: 0.837779, acc: 28.12%] [G loss: 1.330578]\n",
      "epoch:5 step:4413 [D loss: 0.713950, acc: 51.56%] [G loss: 1.564751]\n",
      "epoch:5 step:4414 [D loss: 0.786363, acc: 39.06%] [G loss: 1.494477]\n",
      "epoch:5 step:4415 [D loss: 0.851505, acc: 30.47%] [G loss: 1.380005]\n",
      "epoch:5 step:4416 [D loss: 0.726263, acc: 53.12%] [G loss: 1.662944]\n",
      "epoch:5 step:4417 [D loss: 0.696376, acc: 54.69%] [G loss: 1.692188]\n",
      "epoch:5 step:4418 [D loss: 0.680374, acc: 59.38%] [G loss: 1.511836]\n",
      "epoch:5 step:4419 [D loss: 0.681933, acc: 53.91%] [G loss: 1.623552]\n",
      "epoch:5 step:4420 [D loss: 0.840532, acc: 28.12%] [G loss: 1.338483]\n",
      "epoch:5 step:4421 [D loss: 0.631769, acc: 64.84%] [G loss: 1.503529]\n",
      "epoch:5 step:4422 [D loss: 0.675636, acc: 58.59%] [G loss: 1.726933]\n",
      "epoch:5 step:4423 [D loss: 0.738867, acc: 53.91%] [G loss: 1.616886]\n",
      "epoch:5 step:4424 [D loss: 0.778225, acc: 39.06%] [G loss: 1.455032]\n",
      "epoch:5 step:4425 [D loss: 0.756547, acc: 47.66%] [G loss: 1.613727]\n",
      "epoch:5 step:4426 [D loss: 0.655357, acc: 59.38%] [G loss: 1.680964]\n",
      "epoch:5 step:4427 [D loss: 0.703234, acc: 49.22%] [G loss: 1.605117]\n",
      "epoch:5 step:4428 [D loss: 0.599207, acc: 75.00%] [G loss: 1.667655]\n",
      "epoch:5 step:4429 [D loss: 0.842114, acc: 26.56%] [G loss: 1.551459]\n",
      "epoch:5 step:4430 [D loss: 0.767126, acc: 37.50%] [G loss: 1.577879]\n",
      "epoch:5 step:4431 [D loss: 0.643478, acc: 64.06%] [G loss: 1.675412]\n",
      "epoch:5 step:4432 [D loss: 0.763841, acc: 46.09%] [G loss: 1.448724]\n",
      "epoch:5 step:4433 [D loss: 0.731081, acc: 42.19%] [G loss: 1.577270]\n",
      "epoch:5 step:4434 [D loss: 0.668136, acc: 59.38%] [G loss: 1.545259]\n",
      "epoch:5 step:4435 [D loss: 0.698859, acc: 55.47%] [G loss: 1.754530]\n",
      "epoch:5 step:4436 [D loss: 0.811040, acc: 36.72%] [G loss: 1.449974]\n",
      "epoch:5 step:4437 [D loss: 0.619127, acc: 72.66%] [G loss: 1.826904]\n",
      "epoch:5 step:4438 [D loss: 0.684533, acc: 52.34%] [G loss: 1.624761]\n",
      "epoch:5 step:4439 [D loss: 0.614637, acc: 72.66%] [G loss: 1.616651]\n",
      "epoch:5 step:4440 [D loss: 0.680073, acc: 57.81%] [G loss: 1.647557]\n",
      "epoch:5 step:4441 [D loss: 0.705415, acc: 49.22%] [G loss: 1.656139]\n",
      "epoch:5 step:4442 [D loss: 0.719317, acc: 49.22%] [G loss: 1.668748]\n",
      "epoch:5 step:4443 [D loss: 0.735503, acc: 55.47%] [G loss: 1.524496]\n",
      "epoch:5 step:4444 [D loss: 0.642447, acc: 62.50%] [G loss: 1.589489]\n",
      "epoch:5 step:4445 [D loss: 0.723961, acc: 43.75%] [G loss: 1.528194]\n",
      "epoch:5 step:4446 [D loss: 0.618343, acc: 67.97%] [G loss: 1.583322]\n",
      "epoch:5 step:4447 [D loss: 0.747013, acc: 46.88%] [G loss: 1.589704]\n",
      "epoch:5 step:4448 [D loss: 0.652006, acc: 57.81%] [G loss: 1.673214]\n",
      "epoch:5 step:4449 [D loss: 0.607574, acc: 70.31%] [G loss: 1.441963]\n",
      "epoch:5 step:4450 [D loss: 0.665479, acc: 63.28%] [G loss: 1.598991]\n",
      "epoch:5 step:4451 [D loss: 0.695603, acc: 50.78%] [G loss: 1.485063]\n",
      "epoch:5 step:4452 [D loss: 0.695696, acc: 59.38%] [G loss: 1.463678]\n",
      "epoch:5 step:4453 [D loss: 0.697951, acc: 60.16%] [G loss: 1.541236]\n",
      "epoch:5 step:4454 [D loss: 0.771379, acc: 41.41%] [G loss: 1.436389]\n",
      "epoch:5 step:4455 [D loss: 0.749410, acc: 42.97%] [G loss: 1.573916]\n",
      "epoch:5 step:4456 [D loss: 0.575100, acc: 78.91%] [G loss: 1.715294]\n",
      "epoch:5 step:4457 [D loss: 0.818597, acc: 38.28%] [G loss: 1.397277]\n",
      "epoch:5 step:4458 [D loss: 0.919894, acc: 31.25%] [G loss: 1.439616]\n",
      "epoch:5 step:4459 [D loss: 0.669524, acc: 57.03%] [G loss: 1.662441]\n",
      "epoch:5 step:4460 [D loss: 0.703797, acc: 52.34%] [G loss: 1.586536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4461 [D loss: 0.713967, acc: 52.34%] [G loss: 1.510579]\n",
      "epoch:5 step:4462 [D loss: 0.653460, acc: 63.28%] [G loss: 1.542182]\n",
      "epoch:5 step:4463 [D loss: 0.708270, acc: 46.09%] [G loss: 1.644536]\n",
      "epoch:5 step:4464 [D loss: 0.706243, acc: 53.12%] [G loss: 1.628686]\n",
      "epoch:5 step:4465 [D loss: 0.675581, acc: 57.81%] [G loss: 1.569695]\n",
      "epoch:5 step:4466 [D loss: 0.666568, acc: 57.03%] [G loss: 1.757354]\n",
      "epoch:5 step:4467 [D loss: 0.716102, acc: 50.78%] [G loss: 1.586073]\n",
      "epoch:5 step:4468 [D loss: 0.583662, acc: 71.88%] [G loss: 1.515165]\n",
      "epoch:5 step:4469 [D loss: 0.694964, acc: 51.56%] [G loss: 1.561527]\n",
      "epoch:5 step:4470 [D loss: 0.702453, acc: 53.12%] [G loss: 1.559187]\n",
      "epoch:5 step:4471 [D loss: 0.706186, acc: 48.44%] [G loss: 1.423837]\n",
      "epoch:5 step:4472 [D loss: 0.798082, acc: 40.62%] [G loss: 1.499519]\n",
      "epoch:5 step:4473 [D loss: 0.803545, acc: 41.41%] [G loss: 1.535038]\n",
      "epoch:5 step:4474 [D loss: 0.705194, acc: 50.78%] [G loss: 1.538293]\n",
      "epoch:5 step:4475 [D loss: 0.580466, acc: 68.75%] [G loss: 1.707645]\n",
      "epoch:5 step:4476 [D loss: 0.669086, acc: 61.72%] [G loss: 1.502195]\n",
      "epoch:5 step:4477 [D loss: 0.644055, acc: 57.81%] [G loss: 1.681471]\n",
      "epoch:5 step:4478 [D loss: 0.753215, acc: 42.97%] [G loss: 1.443316]\n",
      "epoch:5 step:4479 [D loss: 0.750679, acc: 45.31%] [G loss: 1.701274]\n",
      "epoch:5 step:4480 [D loss: 0.725537, acc: 48.44%] [G loss: 1.685777]\n",
      "epoch:5 step:4481 [D loss: 0.737101, acc: 46.09%] [G loss: 1.614637]\n",
      "epoch:5 step:4482 [D loss: 0.782154, acc: 39.84%] [G loss: 1.478731]\n",
      "epoch:5 step:4483 [D loss: 0.604324, acc: 70.31%] [G loss: 1.701526]\n",
      "epoch:5 step:4484 [D loss: 0.756303, acc: 43.75%] [G loss: 1.612574]\n",
      "epoch:5 step:4485 [D loss: 0.749342, acc: 42.19%] [G loss: 1.712310]\n",
      "epoch:5 step:4486 [D loss: 0.676781, acc: 54.69%] [G loss: 1.727698]\n",
      "epoch:5 step:4487 [D loss: 0.648830, acc: 63.28%] [G loss: 1.459835]\n",
      "epoch:5 step:4488 [D loss: 0.746336, acc: 37.50%] [G loss: 1.565991]\n",
      "epoch:5 step:4489 [D loss: 0.678323, acc: 62.50%] [G loss: 1.651639]\n",
      "epoch:5 step:4490 [D loss: 0.624647, acc: 73.44%] [G loss: 1.588353]\n",
      "epoch:5 step:4491 [D loss: 0.620121, acc: 67.19%] [G loss: 1.665231]\n",
      "epoch:5 step:4492 [D loss: 0.803299, acc: 42.19%] [G loss: 1.657260]\n",
      "epoch:5 step:4493 [D loss: 0.679182, acc: 56.25%] [G loss: 1.723307]\n",
      "epoch:5 step:4494 [D loss: 0.722498, acc: 45.31%] [G loss: 1.485818]\n",
      "epoch:5 step:4495 [D loss: 0.623871, acc: 67.19%] [G loss: 1.597078]\n",
      "epoch:5 step:4496 [D loss: 0.744959, acc: 44.53%] [G loss: 1.528024]\n",
      "epoch:5 step:4497 [D loss: 0.740402, acc: 42.19%] [G loss: 1.710852]\n",
      "epoch:5 step:4498 [D loss: 0.703430, acc: 52.34%] [G loss: 1.577531]\n",
      "epoch:5 step:4499 [D loss: 0.686234, acc: 57.03%] [G loss: 1.620719]\n",
      "epoch:5 step:4500 [D loss: 0.814820, acc: 32.81%] [G loss: 1.543371]\n",
      "epoch:5 step:4501 [D loss: 0.782492, acc: 41.41%] [G loss: 1.560094]\n",
      "epoch:5 step:4502 [D loss: 0.637114, acc: 64.84%] [G loss: 1.641812]\n",
      "epoch:5 step:4503 [D loss: 0.794312, acc: 28.91%] [G loss: 1.461494]\n",
      "epoch:5 step:4504 [D loss: 0.689834, acc: 50.78%] [G loss: 1.495810]\n",
      "epoch:5 step:4505 [D loss: 0.791991, acc: 41.41%] [G loss: 1.718534]\n",
      "epoch:5 step:4506 [D loss: 0.697312, acc: 50.78%] [G loss: 1.706176]\n",
      "epoch:5 step:4507 [D loss: 0.628153, acc: 66.41%] [G loss: 1.615419]\n",
      "epoch:5 step:4508 [D loss: 0.742040, acc: 44.53%] [G loss: 1.406687]\n",
      "epoch:5 step:4509 [D loss: 0.814869, acc: 36.72%] [G loss: 1.548753]\n",
      "epoch:5 step:4510 [D loss: 0.700573, acc: 52.34%] [G loss: 1.677265]\n",
      "epoch:5 step:4511 [D loss: 0.780561, acc: 42.19%] [G loss: 1.599919]\n",
      "epoch:5 step:4512 [D loss: 0.794566, acc: 36.72%] [G loss: 1.565739]\n",
      "epoch:5 step:4513 [D loss: 0.720966, acc: 45.31%] [G loss: 1.536430]\n",
      "epoch:5 step:4514 [D loss: 0.774780, acc: 43.75%] [G loss: 1.581909]\n",
      "epoch:5 step:4515 [D loss: 0.686203, acc: 51.56%] [G loss: 1.459197]\n",
      "epoch:5 step:4516 [D loss: 0.771511, acc: 42.97%] [G loss: 1.462312]\n",
      "epoch:5 step:4517 [D loss: 0.712975, acc: 49.22%] [G loss: 1.522533]\n",
      "epoch:5 step:4518 [D loss: 0.687877, acc: 56.25%] [G loss: 1.563457]\n",
      "epoch:5 step:4519 [D loss: 0.786437, acc: 38.28%] [G loss: 1.431702]\n",
      "epoch:5 step:4520 [D loss: 0.665799, acc: 60.16%] [G loss: 1.626164]\n",
      "epoch:5 step:4521 [D loss: 0.779350, acc: 35.94%] [G loss: 1.507320]\n",
      "epoch:5 step:4522 [D loss: 0.740247, acc: 44.53%] [G loss: 1.617314]\n",
      "epoch:5 step:4523 [D loss: 0.760190, acc: 46.88%] [G loss: 1.595907]\n",
      "epoch:5 step:4524 [D loss: 0.796251, acc: 41.41%] [G loss: 1.611713]\n",
      "epoch:5 step:4525 [D loss: 0.698913, acc: 57.81%] [G loss: 1.684630]\n",
      "epoch:5 step:4526 [D loss: 0.664871, acc: 60.16%] [G loss: 1.674599]\n",
      "epoch:5 step:4527 [D loss: 0.730162, acc: 50.78%] [G loss: 1.486508]\n",
      "epoch:5 step:4528 [D loss: 0.642651, acc: 62.50%] [G loss: 1.702546]\n",
      "epoch:5 step:4529 [D loss: 0.663406, acc: 66.41%] [G loss: 1.556389]\n",
      "epoch:5 step:4530 [D loss: 0.664930, acc: 59.38%] [G loss: 1.672145]\n",
      "epoch:5 step:4531 [D loss: 0.633098, acc: 67.19%] [G loss: 1.701617]\n",
      "epoch:5 step:4532 [D loss: 0.676242, acc: 53.91%] [G loss: 1.726350]\n",
      "epoch:5 step:4533 [D loss: 0.687264, acc: 56.25%] [G loss: 1.613406]\n",
      "epoch:5 step:4534 [D loss: 0.686148, acc: 56.25%] [G loss: 1.686981]\n",
      "epoch:5 step:4535 [D loss: 0.706914, acc: 52.34%] [G loss: 1.554395]\n",
      "epoch:5 step:4536 [D loss: 0.720259, acc: 52.34%] [G loss: 1.670022]\n",
      "epoch:5 step:4537 [D loss: 0.704427, acc: 46.88%] [G loss: 1.571460]\n",
      "epoch:5 step:4538 [D loss: 0.826675, acc: 35.16%] [G loss: 1.584296]\n",
      "epoch:5 step:4539 [D loss: 0.667079, acc: 59.38%] [G loss: 1.653485]\n",
      "epoch:5 step:4540 [D loss: 0.785121, acc: 38.28%] [G loss: 1.614250]\n",
      "epoch:5 step:4541 [D loss: 0.620071, acc: 74.22%] [G loss: 1.654088]\n",
      "epoch:5 step:4542 [D loss: 0.751467, acc: 48.44%] [G loss: 1.538934]\n",
      "epoch:5 step:4543 [D loss: 0.639702, acc: 64.84%] [G loss: 1.650090]\n",
      "epoch:5 step:4544 [D loss: 0.709317, acc: 46.09%] [G loss: 1.597348]\n",
      "epoch:5 step:4545 [D loss: 0.730359, acc: 49.22%] [G loss: 1.421525]\n",
      "epoch:5 step:4546 [D loss: 0.686222, acc: 50.78%] [G loss: 1.561333]\n",
      "epoch:5 step:4547 [D loss: 0.776998, acc: 35.94%] [G loss: 1.464286]\n",
      "epoch:5 step:4548 [D loss: 0.648994, acc: 58.59%] [G loss: 1.681685]\n",
      "epoch:5 step:4549 [D loss: 0.805258, acc: 34.38%] [G loss: 1.589778]\n",
      "epoch:5 step:4550 [D loss: 0.807879, acc: 34.38%] [G loss: 1.378645]\n",
      "epoch:5 step:4551 [D loss: 0.770898, acc: 45.31%] [G loss: 1.490742]\n",
      "epoch:5 step:4552 [D loss: 0.714586, acc: 46.88%] [G loss: 1.658553]\n",
      "epoch:5 step:4553 [D loss: 0.761060, acc: 44.53%] [G loss: 1.519979]\n",
      "epoch:5 step:4554 [D loss: 0.752436, acc: 43.75%] [G loss: 1.596177]\n",
      "epoch:5 step:4555 [D loss: 0.694047, acc: 53.12%] [G loss: 1.560857]\n",
      "epoch:5 step:4556 [D loss: 0.563133, acc: 79.69%] [G loss: 1.946498]\n",
      "epoch:5 step:4557 [D loss: 0.680042, acc: 52.34%] [G loss: 1.550927]\n",
      "epoch:5 step:4558 [D loss: 0.591200, acc: 78.91%] [G loss: 1.740781]\n",
      "epoch:5 step:4559 [D loss: 0.677021, acc: 60.16%] [G loss: 1.666134]\n",
      "epoch:5 step:4560 [D loss: 0.695011, acc: 56.25%] [G loss: 1.683292]\n",
      "epoch:5 step:4561 [D loss: 0.848337, acc: 32.81%] [G loss: 1.437006]\n",
      "epoch:5 step:4562 [D loss: 0.717284, acc: 48.44%] [G loss: 1.668811]\n",
      "epoch:5 step:4563 [D loss: 0.791015, acc: 35.94%] [G loss: 1.488257]\n",
      "epoch:5 step:4564 [D loss: 0.745564, acc: 49.22%] [G loss: 1.610547]\n",
      "epoch:5 step:4565 [D loss: 0.827114, acc: 32.81%] [G loss: 1.530930]\n",
      "epoch:5 step:4566 [D loss: 0.670522, acc: 57.03%] [G loss: 1.618412]\n",
      "epoch:5 step:4567 [D loss: 0.655110, acc: 63.28%] [G loss: 1.782013]\n",
      "epoch:5 step:4568 [D loss: 0.709076, acc: 52.34%] [G loss: 1.657430]\n",
      "epoch:5 step:4569 [D loss: 0.727602, acc: 45.31%] [G loss: 1.715116]\n",
      "epoch:5 step:4570 [D loss: 0.663912, acc: 61.72%] [G loss: 1.624055]\n",
      "epoch:5 step:4571 [D loss: 0.672119, acc: 53.12%] [G loss: 1.605331]\n",
      "epoch:5 step:4572 [D loss: 0.847157, acc: 24.22%] [G loss: 1.371832]\n",
      "epoch:5 step:4573 [D loss: 0.751346, acc: 40.62%] [G loss: 1.487083]\n",
      "epoch:5 step:4574 [D loss: 0.666004, acc: 60.94%] [G loss: 1.712125]\n",
      "epoch:5 step:4575 [D loss: 0.623965, acc: 70.31%] [G loss: 1.647165]\n",
      "epoch:5 step:4576 [D loss: 0.802233, acc: 37.50%] [G loss: 1.568777]\n",
      "epoch:5 step:4577 [D loss: 0.823222, acc: 30.47%] [G loss: 1.487866]\n",
      "epoch:5 step:4578 [D loss: 0.485124, acc: 71.88%] [G loss: 1.502694]\n",
      "epoch:5 step:4579 [D loss: 0.700675, acc: 53.91%] [G loss: 1.553615]\n",
      "epoch:5 step:4580 [D loss: 0.658724, acc: 58.59%] [G loss: 1.733915]\n",
      "epoch:5 step:4581 [D loss: 0.602333, acc: 69.53%] [G loss: 1.440114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4582 [D loss: 0.618926, acc: 64.06%] [G loss: 1.657563]\n",
      "epoch:5 step:4583 [D loss: 0.658953, acc: 64.06%] [G loss: 1.669675]\n",
      "epoch:5 step:4584 [D loss: 0.634157, acc: 66.41%] [G loss: 1.729786]\n",
      "epoch:5 step:4585 [D loss: 0.730275, acc: 51.56%] [G loss: 1.411752]\n",
      "epoch:5 step:4586 [D loss: 0.592552, acc: 77.34%] [G loss: 1.615932]\n",
      "epoch:5 step:4587 [D loss: 0.704716, acc: 59.38%] [G loss: 1.683301]\n",
      "epoch:5 step:4588 [D loss: 0.704095, acc: 53.91%] [G loss: 1.612542]\n",
      "epoch:5 step:4589 [D loss: 0.722745, acc: 49.22%] [G loss: 1.518118]\n",
      "epoch:5 step:4590 [D loss: 0.661505, acc: 62.50%] [G loss: 1.742840]\n",
      "epoch:5 step:4591 [D loss: 0.797490, acc: 35.94%] [G loss: 1.544991]\n",
      "epoch:5 step:4592 [D loss: 0.896809, acc: 22.66%] [G loss: 1.474030]\n",
      "epoch:5 step:4593 [D loss: 0.716780, acc: 50.78%] [G loss: 1.638711]\n",
      "epoch:5 step:4594 [D loss: 0.688447, acc: 55.47%] [G loss: 1.569367]\n",
      "epoch:5 step:4595 [D loss: 0.680390, acc: 57.81%] [G loss: 1.548823]\n",
      "epoch:5 step:4596 [D loss: 0.670570, acc: 59.38%] [G loss: 1.470870]\n",
      "epoch:5 step:4597 [D loss: 0.906013, acc: 33.59%] [G loss: 1.490026]\n",
      "epoch:5 step:4598 [D loss: 0.732744, acc: 44.53%] [G loss: 1.582617]\n",
      "epoch:5 step:4599 [D loss: 0.633416, acc: 62.50%] [G loss: 1.630816]\n",
      "epoch:5 step:4600 [D loss: 0.668295, acc: 54.69%] [G loss: 1.734248]\n",
      "epoch:5 step:4601 [D loss: 0.837359, acc: 36.72%] [G loss: 1.441759]\n",
      "epoch:5 step:4602 [D loss: 0.850043, acc: 28.91%] [G loss: 1.272194]\n",
      "epoch:5 step:4603 [D loss: 0.754005, acc: 40.62%] [G loss: 1.500510]\n",
      "epoch:5 step:4604 [D loss: 0.641338, acc: 64.84%] [G loss: 1.736177]\n",
      "epoch:5 step:4605 [D loss: 0.761800, acc: 38.28%] [G loss: 1.518275]\n",
      "epoch:5 step:4606 [D loss: 0.624246, acc: 63.28%] [G loss: 1.549820]\n",
      "epoch:5 step:4607 [D loss: 0.758373, acc: 43.75%] [G loss: 1.523174]\n",
      "epoch:5 step:4608 [D loss: 0.735837, acc: 46.88%] [G loss: 1.626330]\n",
      "epoch:5 step:4609 [D loss: 0.811889, acc: 33.59%] [G loss: 1.314485]\n",
      "epoch:5 step:4610 [D loss: 0.723635, acc: 53.91%] [G loss: 1.575490]\n",
      "epoch:5 step:4611 [D loss: 0.741541, acc: 46.09%] [G loss: 1.550644]\n",
      "epoch:5 step:4612 [D loss: 0.695659, acc: 55.47%] [G loss: 1.413846]\n",
      "epoch:5 step:4613 [D loss: 0.814645, acc: 29.69%] [G loss: 1.420932]\n",
      "epoch:5 step:4614 [D loss: 0.671409, acc: 60.94%] [G loss: 1.675709]\n",
      "epoch:5 step:4615 [D loss: 0.694720, acc: 53.91%] [G loss: 1.516264]\n",
      "epoch:5 step:4616 [D loss: 0.701233, acc: 52.34%] [G loss: 1.575872]\n",
      "epoch:5 step:4617 [D loss: 0.514019, acc: 84.38%] [G loss: 1.839976]\n",
      "epoch:5 step:4618 [D loss: 0.711283, acc: 48.44%] [G loss: 1.625297]\n",
      "epoch:5 step:4619 [D loss: 0.700181, acc: 53.12%] [G loss: 1.503166]\n",
      "epoch:5 step:4620 [D loss: 0.654707, acc: 64.84%] [G loss: 1.674131]\n",
      "epoch:5 step:4621 [D loss: 0.712538, acc: 54.69%] [G loss: 1.616884]\n",
      "epoch:5 step:4622 [D loss: 0.607388, acc: 73.44%] [G loss: 1.750859]\n",
      "epoch:5 step:4623 [D loss: 0.715635, acc: 50.78%] [G loss: 1.634300]\n",
      "epoch:5 step:4624 [D loss: 0.693001, acc: 53.91%] [G loss: 1.637337]\n",
      "epoch:5 step:4625 [D loss: 0.677870, acc: 56.25%] [G loss: 1.561907]\n",
      "epoch:5 step:4626 [D loss: 0.736620, acc: 43.75%] [G loss: 1.518147]\n",
      "epoch:5 step:4627 [D loss: 0.693000, acc: 57.81%] [G loss: 1.602871]\n",
      "epoch:5 step:4628 [D loss: 0.687358, acc: 56.25%] [G loss: 1.614602]\n",
      "epoch:5 step:4629 [D loss: 0.760648, acc: 38.28%] [G loss: 1.493122]\n",
      "epoch:5 step:4630 [D loss: 0.689729, acc: 53.12%] [G loss: 1.555966]\n",
      "epoch:5 step:4631 [D loss: 0.858413, acc: 27.34%] [G loss: 1.322520]\n",
      "epoch:5 step:4632 [D loss: 0.836331, acc: 31.25%] [G loss: 1.511717]\n",
      "epoch:5 step:4633 [D loss: 0.754158, acc: 42.19%] [G loss: 1.554636]\n",
      "epoch:5 step:4634 [D loss: 0.692235, acc: 56.25%] [G loss: 1.418249]\n",
      "epoch:5 step:4635 [D loss: 0.764756, acc: 41.41%] [G loss: 1.537773]\n",
      "epoch:5 step:4636 [D loss: 0.697328, acc: 51.56%] [G loss: 1.473639]\n",
      "epoch:5 step:4637 [D loss: 0.851553, acc: 32.81%] [G loss: 1.455903]\n",
      "epoch:5 step:4638 [D loss: 0.748779, acc: 46.88%] [G loss: 1.601586]\n",
      "epoch:5 step:4639 [D loss: 0.717702, acc: 51.56%] [G loss: 1.513511]\n",
      "epoch:5 step:4640 [D loss: 0.717611, acc: 49.22%] [G loss: 1.542637]\n",
      "epoch:5 step:4641 [D loss: 0.741489, acc: 46.09%] [G loss: 1.534367]\n",
      "epoch:5 step:4642 [D loss: 0.721025, acc: 51.56%] [G loss: 1.594621]\n",
      "epoch:5 step:4643 [D loss: 0.698944, acc: 57.03%] [G loss: 1.550011]\n",
      "epoch:5 step:4644 [D loss: 0.741570, acc: 45.31%] [G loss: 1.615518]\n",
      "epoch:5 step:4645 [D loss: 0.776841, acc: 40.62%] [G loss: 1.543196]\n",
      "epoch:5 step:4646 [D loss: 0.665376, acc: 60.16%] [G loss: 1.653073]\n",
      "epoch:5 step:4647 [D loss: 0.726699, acc: 46.09%] [G loss: 1.682214]\n",
      "epoch:5 step:4648 [D loss: 0.719018, acc: 50.00%] [G loss: 1.551844]\n",
      "epoch:5 step:4649 [D loss: 0.781106, acc: 39.84%] [G loss: 1.547872]\n",
      "epoch:5 step:4650 [D loss: 0.592343, acc: 72.66%] [G loss: 1.671316]\n",
      "epoch:5 step:4651 [D loss: 0.686388, acc: 57.03%] [G loss: 1.723745]\n",
      "epoch:5 step:4652 [D loss: 0.727827, acc: 46.09%] [G loss: 1.723765]\n",
      "epoch:5 step:4653 [D loss: 0.712660, acc: 50.78%] [G loss: 1.629561]\n",
      "epoch:5 step:4654 [D loss: 0.761267, acc: 43.75%] [G loss: 1.594711]\n",
      "epoch:5 step:4655 [D loss: 0.738277, acc: 44.53%] [G loss: 1.680802]\n",
      "epoch:5 step:4656 [D loss: 0.798230, acc: 29.69%] [G loss: 1.480211]\n",
      "epoch:5 step:4657 [D loss: 0.733210, acc: 41.41%] [G loss: 1.577933]\n",
      "epoch:5 step:4658 [D loss: 0.670067, acc: 67.19%] [G loss: 1.575564]\n",
      "epoch:5 step:4659 [D loss: 0.663308, acc: 57.81%] [G loss: 1.714004]\n",
      "epoch:5 step:4660 [D loss: 0.743470, acc: 42.97%] [G loss: 1.478087]\n",
      "epoch:5 step:4661 [D loss: 0.669352, acc: 64.84%] [G loss: 1.649553]\n",
      "epoch:5 step:4662 [D loss: 0.630600, acc: 66.41%] [G loss: 1.556195]\n",
      "epoch:5 step:4663 [D loss: 0.689108, acc: 56.25%] [G loss: 1.761138]\n",
      "epoch:5 step:4664 [D loss: 0.738819, acc: 46.09%] [G loss: 1.497556]\n",
      "epoch:5 step:4665 [D loss: 0.668612, acc: 62.50%] [G loss: 1.773393]\n",
      "epoch:5 step:4666 [D loss: 0.791214, acc: 35.94%] [G loss: 1.441679]\n",
      "epoch:5 step:4667 [D loss: 0.674610, acc: 64.84%] [G loss: 1.698982]\n",
      "epoch:5 step:4668 [D loss: 0.726559, acc: 54.69%] [G loss: 1.655743]\n",
      "epoch:5 step:4669 [D loss: 0.643649, acc: 63.28%] [G loss: 1.529544]\n",
      "epoch:5 step:4670 [D loss: 0.751535, acc: 42.97%] [G loss: 1.548848]\n",
      "epoch:5 step:4671 [D loss: 0.621189, acc: 63.28%] [G loss: 1.638938]\n",
      "epoch:5 step:4672 [D loss: 0.703746, acc: 50.00%] [G loss: 1.590325]\n",
      "epoch:5 step:4673 [D loss: 0.704276, acc: 52.34%] [G loss: 1.564911]\n",
      "epoch:5 step:4674 [D loss: 0.741298, acc: 49.22%] [G loss: 1.439733]\n",
      "epoch:5 step:4675 [D loss: 0.664746, acc: 60.94%] [G loss: 1.670647]\n",
      "epoch:5 step:4676 [D loss: 0.772791, acc: 40.62%] [G loss: 1.541224]\n",
      "epoch:5 step:4677 [D loss: 0.644867, acc: 60.16%] [G loss: 1.650076]\n",
      "epoch:5 step:4678 [D loss: 0.667697, acc: 57.03%] [G loss: 1.628963]\n",
      "epoch:5 step:4679 [D loss: 0.696102, acc: 52.34%] [G loss: 1.613019]\n",
      "epoch:5 step:4680 [D loss: 0.762472, acc: 41.41%] [G loss: 1.565191]\n",
      "epoch:5 step:4681 [D loss: 0.674693, acc: 60.94%] [G loss: 1.682580]\n",
      "epoch:5 step:4682 [D loss: 0.819899, acc: 31.25%] [G loss: 1.349350]\n",
      "epoch:5 step:4683 [D loss: 0.775798, acc: 35.94%] [G loss: 1.619884]\n",
      "epoch:5 step:4684 [D loss: 0.812087, acc: 35.94%] [G loss: 1.627311]\n",
      "epoch:5 step:4685 [D loss: 0.830652, acc: 29.69%] [G loss: 1.387548]\n",
      "epoch:5 step:4686 [D loss: 0.670748, acc: 60.94%] [G loss: 1.613755]\n",
      "epoch:6 step:4687 [D loss: 0.696747, acc: 54.69%] [G loss: 1.575342]\n",
      "epoch:6 step:4688 [D loss: 0.675585, acc: 57.03%] [G loss: 1.612540]\n",
      "epoch:6 step:4689 [D loss: 0.804440, acc: 37.50%] [G loss: 1.521341]\n",
      "epoch:6 step:4690 [D loss: 0.640971, acc: 67.97%] [G loss: 1.550663]\n",
      "epoch:6 step:4691 [D loss: 0.711446, acc: 49.22%] [G loss: 1.546191]\n",
      "epoch:6 step:4692 [D loss: 0.683221, acc: 51.56%] [G loss: 1.665047]\n",
      "epoch:6 step:4693 [D loss: 0.559581, acc: 79.69%] [G loss: 1.561520]\n",
      "epoch:6 step:4694 [D loss: 0.666676, acc: 56.25%] [G loss: 1.434482]\n",
      "epoch:6 step:4695 [D loss: 0.701966, acc: 60.16%] [G loss: 1.549964]\n",
      "epoch:6 step:4696 [D loss: 0.741077, acc: 48.44%] [G loss: 1.502325]\n",
      "epoch:6 step:4697 [D loss: 0.700148, acc: 48.44%] [G loss: 1.438034]\n",
      "epoch:6 step:4698 [D loss: 0.685422, acc: 50.78%] [G loss: 1.502151]\n",
      "epoch:6 step:4699 [D loss: 0.490516, acc: 80.47%] [G loss: 1.506522]\n",
      "epoch:6 step:4700 [D loss: 0.773707, acc: 41.41%] [G loss: 1.541172]\n",
      "epoch:6 step:4701 [D loss: 0.707632, acc: 47.66%] [G loss: 1.371948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4702 [D loss: 0.669679, acc: 57.81%] [G loss: 1.538655]\n",
      "epoch:6 step:4703 [D loss: 0.688482, acc: 58.59%] [G loss: 1.567004]\n",
      "epoch:6 step:4704 [D loss: 0.710031, acc: 42.19%] [G loss: 1.440964]\n",
      "epoch:6 step:4705 [D loss: 0.588117, acc: 75.00%] [G loss: 1.435461]\n",
      "epoch:6 step:4706 [D loss: 0.573736, acc: 76.56%] [G loss: 1.498558]\n",
      "epoch:6 step:4707 [D loss: 0.814722, acc: 32.81%] [G loss: 1.402978]\n",
      "epoch:6 step:4708 [D loss: 0.740127, acc: 46.09%] [G loss: 1.538556]\n",
      "epoch:6 step:4709 [D loss: 0.886159, acc: 25.78%] [G loss: 1.441515]\n",
      "epoch:6 step:4710 [D loss: 0.724369, acc: 42.97%] [G loss: 1.556891]\n",
      "epoch:6 step:4711 [D loss: 0.983554, acc: 17.19%] [G loss: 1.288391]\n",
      "epoch:6 step:4712 [D loss: 0.652742, acc: 62.50%] [G loss: 1.578440]\n",
      "epoch:6 step:4713 [D loss: 0.726151, acc: 47.66%] [G loss: 1.654083]\n",
      "epoch:6 step:4714 [D loss: 0.620061, acc: 67.19%] [G loss: 1.733521]\n",
      "epoch:6 step:4715 [D loss: 0.781584, acc: 38.28%] [G loss: 1.553861]\n",
      "epoch:6 step:4716 [D loss: 0.756830, acc: 41.41%] [G loss: 1.542769]\n",
      "epoch:6 step:4717 [D loss: 0.695429, acc: 56.25%] [G loss: 1.617276]\n",
      "epoch:6 step:4718 [D loss: 0.698829, acc: 53.12%] [G loss: 1.609803]\n",
      "epoch:6 step:4719 [D loss: 0.642847, acc: 67.97%] [G loss: 1.598658]\n",
      "epoch:6 step:4720 [D loss: 0.675083, acc: 54.69%] [G loss: 1.513548]\n",
      "epoch:6 step:4721 [D loss: 0.626927, acc: 63.28%] [G loss: 1.642626]\n",
      "epoch:6 step:4722 [D loss: 0.601810, acc: 64.84%] [G loss: 1.585653]\n",
      "epoch:6 step:4723 [D loss: 0.606309, acc: 71.09%] [G loss: 1.678827]\n",
      "epoch:6 step:4724 [D loss: 0.705327, acc: 53.12%] [G loss: 1.484843]\n",
      "epoch:6 step:4725 [D loss: 0.784741, acc: 46.88%] [G loss: 1.452252]\n",
      "epoch:6 step:4726 [D loss: 0.771231, acc: 40.62%] [G loss: 1.423907]\n",
      "epoch:6 step:4727 [D loss: 0.616532, acc: 67.97%] [G loss: 1.528404]\n",
      "epoch:6 step:4728 [D loss: 0.704645, acc: 53.91%] [G loss: 1.508156]\n",
      "epoch:6 step:4729 [D loss: 0.661961, acc: 60.94%] [G loss: 1.649686]\n",
      "epoch:6 step:4730 [D loss: 0.637305, acc: 64.84%] [G loss: 1.519045]\n",
      "epoch:6 step:4731 [D loss: 0.591879, acc: 75.00%] [G loss: 1.633164]\n",
      "epoch:6 step:4732 [D loss: 0.658817, acc: 57.81%] [G loss: 1.422220]\n",
      "epoch:6 step:4733 [D loss: 0.646107, acc: 60.16%] [G loss: 1.576999]\n",
      "epoch:6 step:4734 [D loss: 0.718770, acc: 46.09%] [G loss: 1.457091]\n",
      "epoch:6 step:4735 [D loss: 1.048584, acc: 9.38%] [G loss: 1.291442]\n",
      "epoch:6 step:4736 [D loss: 0.804130, acc: 37.50%] [G loss: 1.430193]\n",
      "epoch:6 step:4737 [D loss: 0.704958, acc: 52.34%] [G loss: 1.282997]\n",
      "epoch:6 step:4738 [D loss: 0.664524, acc: 60.94%] [G loss: 1.570798]\n",
      "epoch:6 step:4739 [D loss: 0.737306, acc: 53.12%] [G loss: 1.406077]\n",
      "epoch:6 step:4740 [D loss: 0.708657, acc: 59.38%] [G loss: 1.556368]\n",
      "epoch:6 step:4741 [D loss: 0.729284, acc: 39.84%] [G loss: 1.441390]\n",
      "epoch:6 step:4742 [D loss: 0.819031, acc: 28.12%] [G loss: 1.605552]\n",
      "epoch:6 step:4743 [D loss: 0.724523, acc: 42.97%] [G loss: 1.517222]\n",
      "epoch:6 step:4744 [D loss: 0.789317, acc: 39.06%] [G loss: 1.542236]\n",
      "epoch:6 step:4745 [D loss: 0.611701, acc: 70.31%] [G loss: 1.668682]\n",
      "epoch:6 step:4746 [D loss: 0.679456, acc: 57.03%] [G loss: 1.750930]\n",
      "epoch:6 step:4747 [D loss: 0.712340, acc: 49.22%] [G loss: 1.462456]\n",
      "epoch:6 step:4748 [D loss: 0.749430, acc: 44.53%] [G loss: 1.541367]\n",
      "epoch:6 step:4749 [D loss: 0.766341, acc: 28.91%] [G loss: 1.506106]\n",
      "epoch:6 step:4750 [D loss: 0.712967, acc: 46.88%] [G loss: 1.607268]\n",
      "epoch:6 step:4751 [D loss: 0.712566, acc: 51.56%] [G loss: 1.536851]\n",
      "epoch:6 step:4752 [D loss: 0.635407, acc: 70.31%] [G loss: 1.574583]\n",
      "epoch:6 step:4753 [D loss: 0.862486, acc: 23.44%] [G loss: 1.373405]\n",
      "epoch:6 step:4754 [D loss: 0.671672, acc: 55.47%] [G loss: 1.614659]\n",
      "epoch:6 step:4755 [D loss: 0.640660, acc: 64.06%] [G loss: 1.638359]\n",
      "epoch:6 step:4756 [D loss: 0.662123, acc: 67.97%] [G loss: 1.695050]\n",
      "epoch:6 step:4757 [D loss: 0.765275, acc: 46.88%] [G loss: 1.338126]\n",
      "epoch:6 step:4758 [D loss: 0.630845, acc: 72.66%] [G loss: 1.583058]\n",
      "epoch:6 step:4759 [D loss: 0.687699, acc: 53.12%] [G loss: 1.703004]\n",
      "epoch:6 step:4760 [D loss: 0.688214, acc: 57.81%] [G loss: 1.613418]\n",
      "epoch:6 step:4761 [D loss: 0.667007, acc: 57.03%] [G loss: 1.788632]\n",
      "epoch:6 step:4762 [D loss: 0.701756, acc: 53.91%] [G loss: 1.417604]\n",
      "epoch:6 step:4763 [D loss: 0.721277, acc: 50.78%] [G loss: 1.398540]\n",
      "epoch:6 step:4764 [D loss: 0.715709, acc: 56.25%] [G loss: 1.395369]\n",
      "epoch:6 step:4765 [D loss: 0.728492, acc: 45.31%] [G loss: 1.463698]\n",
      "epoch:6 step:4766 [D loss: 0.651587, acc: 60.16%] [G loss: 1.396345]\n",
      "epoch:6 step:4767 [D loss: 0.713033, acc: 51.56%] [G loss: 1.476825]\n",
      "epoch:6 step:4768 [D loss: 0.714780, acc: 51.56%] [G loss: 1.463592]\n",
      "epoch:6 step:4769 [D loss: 0.838996, acc: 29.69%] [G loss: 1.562434]\n",
      "epoch:6 step:4770 [D loss: 0.664046, acc: 57.03%] [G loss: 1.549258]\n",
      "epoch:6 step:4771 [D loss: 0.627716, acc: 71.88%] [G loss: 1.676754]\n",
      "epoch:6 step:4772 [D loss: 0.766677, acc: 36.72%] [G loss: 1.676040]\n",
      "epoch:6 step:4773 [D loss: 0.712283, acc: 48.44%] [G loss: 1.574805]\n",
      "epoch:6 step:4774 [D loss: 0.714320, acc: 50.00%] [G loss: 1.541324]\n",
      "epoch:6 step:4775 [D loss: 0.586023, acc: 73.44%] [G loss: 1.610001]\n",
      "epoch:6 step:4776 [D loss: 0.851837, acc: 30.47%] [G loss: 1.439758]\n",
      "epoch:6 step:4777 [D loss: 0.662851, acc: 56.25%] [G loss: 1.581679]\n",
      "epoch:6 step:4778 [D loss: 0.727986, acc: 51.56%] [G loss: 1.529598]\n",
      "epoch:6 step:4779 [D loss: 0.727845, acc: 47.66%] [G loss: 1.587403]\n",
      "epoch:6 step:4780 [D loss: 0.683743, acc: 56.25%] [G loss: 1.526844]\n",
      "epoch:6 step:4781 [D loss: 0.699076, acc: 51.56%] [G loss: 1.544631]\n",
      "epoch:6 step:4782 [D loss: 0.678337, acc: 53.91%] [G loss: 1.665974]\n",
      "epoch:6 step:4783 [D loss: 0.689397, acc: 56.25%] [G loss: 1.589139]\n",
      "epoch:6 step:4784 [D loss: 0.723798, acc: 48.44%] [G loss: 1.461995]\n",
      "epoch:6 step:4785 [D loss: 0.669055, acc: 58.59%] [G loss: 1.730617]\n",
      "epoch:6 step:4786 [D loss: 0.668229, acc: 60.94%] [G loss: 1.655222]\n",
      "epoch:6 step:4787 [D loss: 0.646830, acc: 60.94%] [G loss: 1.681780]\n",
      "epoch:6 step:4788 [D loss: 0.779107, acc: 39.84%] [G loss: 1.469015]\n",
      "epoch:6 step:4789 [D loss: 0.593870, acc: 70.31%] [G loss: 1.695783]\n",
      "epoch:6 step:4790 [D loss: 0.750640, acc: 45.31%] [G loss: 1.613973]\n",
      "epoch:6 step:4791 [D loss: 0.643224, acc: 65.62%] [G loss: 1.757783]\n",
      "epoch:6 step:4792 [D loss: 0.652878, acc: 65.62%] [G loss: 1.584738]\n",
      "epoch:6 step:4793 [D loss: 0.744687, acc: 54.69%] [G loss: 1.596748]\n",
      "epoch:6 step:4794 [D loss: 0.845500, acc: 22.66%] [G loss: 1.655610]\n",
      "epoch:6 step:4795 [D loss: 0.649795, acc: 64.84%] [G loss: 1.621647]\n",
      "epoch:6 step:4796 [D loss: 0.628489, acc: 65.62%] [G loss: 1.669697]\n",
      "epoch:6 step:4797 [D loss: 0.713018, acc: 53.12%] [G loss: 1.473322]\n",
      "epoch:6 step:4798 [D loss: 0.769160, acc: 44.53%] [G loss: 1.462066]\n",
      "epoch:6 step:4799 [D loss: 0.631802, acc: 71.09%] [G loss: 1.559394]\n",
      "epoch:6 step:4800 [D loss: 0.663181, acc: 64.06%] [G loss: 1.546103]\n",
      "epoch:6 step:4801 [D loss: 0.617153, acc: 69.53%] [G loss: 1.602002]\n",
      "epoch:6 step:4802 [D loss: 0.661840, acc: 57.03%] [G loss: 1.550920]\n",
      "epoch:6 step:4803 [D loss: 0.805851, acc: 42.19%] [G loss: 1.593487]\n",
      "epoch:6 step:4804 [D loss: 0.771312, acc: 37.50%] [G loss: 1.547729]\n",
      "epoch:6 step:4805 [D loss: 0.654672, acc: 63.28%] [G loss: 1.679388]\n",
      "epoch:6 step:4806 [D loss: 0.637806, acc: 65.62%] [G loss: 1.591630]\n",
      "epoch:6 step:4807 [D loss: 0.701495, acc: 53.12%] [G loss: 1.798644]\n",
      "epoch:6 step:4808 [D loss: 0.669633, acc: 56.25%] [G loss: 1.714365]\n",
      "epoch:6 step:4809 [D loss: 0.663639, acc: 60.94%] [G loss: 1.599694]\n",
      "epoch:6 step:4810 [D loss: 0.797825, acc: 36.72%] [G loss: 1.475079]\n",
      "epoch:6 step:4811 [D loss: 0.831061, acc: 35.94%] [G loss: 1.494958]\n",
      "epoch:6 step:4812 [D loss: 0.749404, acc: 43.75%] [G loss: 1.488318]\n",
      "epoch:6 step:4813 [D loss: 0.719481, acc: 52.34%] [G loss: 1.680543]\n",
      "epoch:6 step:4814 [D loss: 0.667247, acc: 60.94%] [G loss: 1.708764]\n",
      "epoch:6 step:4815 [D loss: 0.699171, acc: 52.34%] [G loss: 1.552944]\n",
      "epoch:6 step:4816 [D loss: 0.716492, acc: 47.66%] [G loss: 1.519773]\n",
      "epoch:6 step:4817 [D loss: 0.713289, acc: 50.78%] [G loss: 1.635905]\n",
      "epoch:6 step:4818 [D loss: 0.774352, acc: 35.16%] [G loss: 1.463736]\n",
      "epoch:6 step:4819 [D loss: 0.677443, acc: 59.38%] [G loss: 1.740548]\n",
      "epoch:6 step:4820 [D loss: 0.747704, acc: 42.19%] [G loss: 1.576391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4821 [D loss: 0.812565, acc: 29.69%] [G loss: 1.588717]\n",
      "epoch:6 step:4822 [D loss: 0.742394, acc: 39.06%] [G loss: 1.722714]\n",
      "epoch:6 step:4823 [D loss: 0.801688, acc: 32.81%] [G loss: 1.497100]\n",
      "epoch:6 step:4824 [D loss: 0.542785, acc: 80.47%] [G loss: 1.757843]\n",
      "epoch:6 step:4825 [D loss: 0.666036, acc: 61.72%] [G loss: 1.577703]\n",
      "epoch:6 step:4826 [D loss: 0.685632, acc: 55.47%] [G loss: 1.660651]\n",
      "epoch:6 step:4827 [D loss: 0.657058, acc: 59.38%] [G loss: 1.800614]\n",
      "epoch:6 step:4828 [D loss: 0.703292, acc: 47.66%] [G loss: 1.567722]\n",
      "epoch:6 step:4829 [D loss: 0.779122, acc: 41.41%] [G loss: 1.555841]\n",
      "epoch:6 step:4830 [D loss: 0.695978, acc: 52.34%] [G loss: 1.688838]\n",
      "epoch:6 step:4831 [D loss: 0.732280, acc: 46.88%] [G loss: 1.646416]\n",
      "epoch:6 step:4832 [D loss: 0.697528, acc: 54.69%] [G loss: 1.569528]\n",
      "epoch:6 step:4833 [D loss: 0.674384, acc: 57.03%] [G loss: 1.641178]\n",
      "epoch:6 step:4834 [D loss: 0.680539, acc: 53.91%] [G loss: 1.564570]\n",
      "epoch:6 step:4835 [D loss: 0.708026, acc: 53.91%] [G loss: 1.579239]\n",
      "epoch:6 step:4836 [D loss: 0.716853, acc: 49.22%] [G loss: 1.530108]\n",
      "epoch:6 step:4837 [D loss: 0.751983, acc: 45.31%] [G loss: 1.540303]\n",
      "epoch:6 step:4838 [D loss: 0.611142, acc: 65.62%] [G loss: 1.589154]\n",
      "epoch:6 step:4839 [D loss: 0.765508, acc: 43.75%] [G loss: 1.463036]\n",
      "epoch:6 step:4840 [D loss: 0.733444, acc: 50.00%] [G loss: 1.658064]\n",
      "epoch:6 step:4841 [D loss: 0.618225, acc: 72.66%] [G loss: 1.635633]\n",
      "epoch:6 step:4842 [D loss: 0.863620, acc: 28.12%] [G loss: 1.573767]\n",
      "epoch:6 step:4843 [D loss: 0.780592, acc: 35.16%] [G loss: 1.574503]\n",
      "epoch:6 step:4844 [D loss: 0.716406, acc: 52.34%] [G loss: 1.604402]\n",
      "epoch:6 step:4845 [D loss: 0.736835, acc: 41.41%] [G loss: 1.739687]\n",
      "epoch:6 step:4846 [D loss: 0.706884, acc: 52.34%] [G loss: 1.467846]\n",
      "epoch:6 step:4847 [D loss: 0.720024, acc: 48.44%] [G loss: 1.623799]\n",
      "epoch:6 step:4848 [D loss: 0.661615, acc: 59.38%] [G loss: 1.748419]\n",
      "epoch:6 step:4849 [D loss: 0.737553, acc: 44.53%] [G loss: 1.468056]\n",
      "epoch:6 step:4850 [D loss: 0.758384, acc: 42.97%] [G loss: 1.524014]\n",
      "epoch:6 step:4851 [D loss: 0.471945, acc: 75.00%] [G loss: 1.508043]\n",
      "epoch:6 step:4852 [D loss: 0.969392, acc: 21.88%] [G loss: 1.366903]\n",
      "epoch:6 step:4853 [D loss: 0.770833, acc: 44.53%] [G loss: 1.547824]\n",
      "epoch:6 step:4854 [D loss: 0.701657, acc: 52.34%] [G loss: 1.620330]\n",
      "epoch:6 step:4855 [D loss: 0.740407, acc: 51.56%] [G loss: 1.526828]\n",
      "epoch:6 step:4856 [D loss: 0.722009, acc: 47.66%] [G loss: 1.707535]\n",
      "epoch:6 step:4857 [D loss: 0.692831, acc: 53.91%] [G loss: 1.634426]\n",
      "epoch:6 step:4858 [D loss: 0.774742, acc: 35.94%] [G loss: 1.515391]\n",
      "epoch:6 step:4859 [D loss: 0.781270, acc: 31.25%] [G loss: 1.495178]\n",
      "epoch:6 step:4860 [D loss: 0.651268, acc: 59.38%] [G loss: 1.563119]\n",
      "epoch:6 step:4861 [D loss: 0.631915, acc: 67.19%] [G loss: 1.566813]\n",
      "epoch:6 step:4862 [D loss: 0.712796, acc: 50.00%] [G loss: 1.413953]\n",
      "epoch:6 step:4863 [D loss: 0.704520, acc: 50.78%] [G loss: 1.587458]\n",
      "epoch:6 step:4864 [D loss: 0.860359, acc: 25.78%] [G loss: 1.355555]\n",
      "epoch:6 step:4865 [D loss: 0.712484, acc: 55.47%] [G loss: 1.512290]\n",
      "epoch:6 step:4866 [D loss: 0.714979, acc: 45.31%] [G loss: 1.450891]\n",
      "epoch:6 step:4867 [D loss: 0.709094, acc: 47.66%] [G loss: 1.464647]\n",
      "epoch:6 step:4868 [D loss: 0.629126, acc: 66.41%] [G loss: 1.619616]\n",
      "epoch:6 step:4869 [D loss: 0.730797, acc: 48.44%] [G loss: 1.532032]\n",
      "epoch:6 step:4870 [D loss: 0.724979, acc: 50.00%] [G loss: 1.521319]\n",
      "epoch:6 step:4871 [D loss: 0.786526, acc: 39.06%] [G loss: 1.509611]\n",
      "epoch:6 step:4872 [D loss: 0.723268, acc: 57.03%] [G loss: 1.583694]\n",
      "epoch:6 step:4873 [D loss: 0.753370, acc: 46.09%] [G loss: 1.520992]\n",
      "epoch:6 step:4874 [D loss: 0.662109, acc: 57.81%] [G loss: 1.495316]\n",
      "epoch:6 step:4875 [D loss: 0.634065, acc: 66.41%] [G loss: 1.621469]\n",
      "epoch:6 step:4876 [D loss: 0.691752, acc: 53.12%] [G loss: 1.579033]\n",
      "epoch:6 step:4877 [D loss: 0.622234, acc: 64.84%] [G loss: 1.643695]\n",
      "epoch:6 step:4878 [D loss: 0.642117, acc: 58.59%] [G loss: 1.517777]\n",
      "epoch:6 step:4879 [D loss: 0.703871, acc: 57.03%] [G loss: 1.542587]\n",
      "epoch:6 step:4880 [D loss: 0.745458, acc: 47.66%] [G loss: 1.540943]\n",
      "epoch:6 step:4881 [D loss: 0.813416, acc: 35.16%] [G loss: 1.482527]\n",
      "epoch:6 step:4882 [D loss: 0.783304, acc: 48.44%] [G loss: 1.533151]\n",
      "epoch:6 step:4883 [D loss: 0.645527, acc: 62.50%] [G loss: 1.567976]\n",
      "epoch:6 step:4884 [D loss: 0.533130, acc: 78.12%] [G loss: 1.702024]\n",
      "epoch:6 step:4885 [D loss: 0.737102, acc: 46.09%] [G loss: 1.602350]\n",
      "epoch:6 step:4886 [D loss: 0.578661, acc: 75.00%] [G loss: 1.590538]\n",
      "epoch:6 step:4887 [D loss: 0.674813, acc: 57.03%] [G loss: 1.598305]\n",
      "epoch:6 step:4888 [D loss: 0.924710, acc: 31.25%] [G loss: 1.385059]\n",
      "epoch:6 step:4889 [D loss: 0.660034, acc: 62.50%] [G loss: 1.711819]\n",
      "epoch:6 step:4890 [D loss: 0.662926, acc: 60.94%] [G loss: 1.675527]\n",
      "epoch:6 step:4891 [D loss: 0.953286, acc: 23.44%] [G loss: 1.272982]\n",
      "epoch:6 step:4892 [D loss: 0.732705, acc: 50.00%] [G loss: 1.541234]\n",
      "epoch:6 step:4893 [D loss: 0.621147, acc: 66.41%] [G loss: 1.549303]\n",
      "epoch:6 step:4894 [D loss: 0.639081, acc: 65.62%] [G loss: 1.540498]\n",
      "epoch:6 step:4895 [D loss: 0.638637, acc: 65.62%] [G loss: 1.600358]\n",
      "epoch:6 step:4896 [D loss: 0.658616, acc: 57.81%] [G loss: 1.351754]\n",
      "epoch:6 step:4897 [D loss: 0.719001, acc: 47.66%] [G loss: 1.478758]\n",
      "epoch:6 step:4898 [D loss: 0.663908, acc: 61.72%] [G loss: 1.601910]\n",
      "epoch:6 step:4899 [D loss: 0.695820, acc: 52.34%] [G loss: 1.597468]\n",
      "epoch:6 step:4900 [D loss: 0.777425, acc: 40.62%] [G loss: 1.612853]\n",
      "epoch:6 step:4901 [D loss: 0.643544, acc: 60.94%] [G loss: 1.533209]\n",
      "epoch:6 step:4902 [D loss: 0.635977, acc: 63.28%] [G loss: 1.663836]\n",
      "epoch:6 step:4903 [D loss: 0.724108, acc: 47.66%] [G loss: 1.474264]\n",
      "epoch:6 step:4904 [D loss: 0.672088, acc: 53.91%] [G loss: 1.527611]\n",
      "epoch:6 step:4905 [D loss: 0.674727, acc: 59.38%] [G loss: 1.633620]\n",
      "epoch:6 step:4906 [D loss: 0.666131, acc: 67.19%] [G loss: 1.471174]\n",
      "epoch:6 step:4907 [D loss: 0.604912, acc: 71.09%] [G loss: 1.521738]\n",
      "epoch:6 step:4908 [D loss: 0.688829, acc: 59.38%] [G loss: 1.509660]\n",
      "epoch:6 step:4909 [D loss: 0.671929, acc: 57.81%] [G loss: 1.547209]\n",
      "epoch:6 step:4910 [D loss: 0.589860, acc: 71.09%] [G loss: 1.585979]\n",
      "epoch:6 step:4911 [D loss: 0.765982, acc: 40.62%] [G loss: 1.491538]\n",
      "epoch:6 step:4912 [D loss: 0.821627, acc: 36.72%] [G loss: 1.294431]\n",
      "epoch:6 step:4913 [D loss: 0.575836, acc: 82.03%] [G loss: 1.517238]\n",
      "epoch:6 step:4914 [D loss: 0.650456, acc: 61.72%] [G loss: 1.527111]\n",
      "epoch:6 step:4915 [D loss: 0.702385, acc: 53.91%] [G loss: 1.296529]\n",
      "epoch:6 step:4916 [D loss: 0.966577, acc: 19.53%] [G loss: 1.303112]\n",
      "epoch:6 step:4917 [D loss: 0.768853, acc: 39.06%] [G loss: 1.402800]\n",
      "epoch:6 step:4918 [D loss: 0.708888, acc: 53.12%] [G loss: 1.593919]\n",
      "epoch:6 step:4919 [D loss: 0.731439, acc: 45.31%] [G loss: 1.467363]\n",
      "epoch:6 step:4920 [D loss: 0.761721, acc: 39.06%] [G loss: 1.553589]\n",
      "epoch:6 step:4921 [D loss: 0.687498, acc: 52.34%] [G loss: 1.689399]\n",
      "epoch:6 step:4922 [D loss: 0.968698, acc: 14.84%] [G loss: 1.441715]\n",
      "epoch:6 step:4923 [D loss: 0.687205, acc: 54.69%] [G loss: 1.656994]\n",
      "epoch:6 step:4924 [D loss: 0.673903, acc: 58.59%] [G loss: 1.564406]\n",
      "epoch:6 step:4925 [D loss: 0.765000, acc: 45.31%] [G loss: 1.638066]\n",
      "epoch:6 step:4926 [D loss: 0.721083, acc: 60.16%] [G loss: 1.445334]\n",
      "epoch:6 step:4927 [D loss: 0.730135, acc: 42.97%] [G loss: 1.566977]\n",
      "epoch:6 step:4928 [D loss: 0.756280, acc: 45.31%] [G loss: 1.546506]\n",
      "epoch:6 step:4929 [D loss: 0.655221, acc: 65.62%] [G loss: 1.598061]\n",
      "epoch:6 step:4930 [D loss: 0.632553, acc: 68.75%] [G loss: 1.582536]\n",
      "epoch:6 step:4931 [D loss: 0.809326, acc: 35.94%] [G loss: 1.445141]\n",
      "epoch:6 step:4932 [D loss: 0.561699, acc: 79.69%] [G loss: 1.645316]\n",
      "epoch:6 step:4933 [D loss: 0.683030, acc: 52.34%] [G loss: 1.590006]\n",
      "epoch:6 step:4934 [D loss: 0.746780, acc: 41.41%] [G loss: 1.483759]\n",
      "epoch:6 step:4935 [D loss: 0.631444, acc: 65.62%] [G loss: 1.557269]\n",
      "epoch:6 step:4936 [D loss: 0.600354, acc: 67.97%] [G loss: 1.628686]\n",
      "epoch:6 step:4937 [D loss: 0.666654, acc: 57.81%] [G loss: 1.440006]\n",
      "epoch:6 step:4938 [D loss: 0.561275, acc: 84.38%] [G loss: 1.637433]\n",
      "epoch:6 step:4939 [D loss: 0.760902, acc: 43.75%] [G loss: 1.637351]\n",
      "epoch:6 step:4940 [D loss: 0.748206, acc: 41.41%] [G loss: 1.378176]\n",
      "epoch:6 step:4941 [D loss: 0.890999, acc: 21.09%] [G loss: 1.530312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4942 [D loss: 0.804430, acc: 37.50%] [G loss: 1.602169]\n",
      "epoch:6 step:4943 [D loss: 0.709456, acc: 51.56%] [G loss: 1.361961]\n",
      "epoch:6 step:4944 [D loss: 0.688359, acc: 52.34%] [G loss: 1.481939]\n",
      "epoch:6 step:4945 [D loss: 0.730254, acc: 47.66%] [G loss: 1.465208]\n",
      "epoch:6 step:4946 [D loss: 0.622621, acc: 69.53%] [G loss: 1.541326]\n",
      "epoch:6 step:4947 [D loss: 0.702492, acc: 49.22%] [G loss: 1.571370]\n",
      "epoch:6 step:4948 [D loss: 0.689510, acc: 53.91%] [G loss: 1.599410]\n",
      "epoch:6 step:4949 [D loss: 0.775540, acc: 46.09%] [G loss: 1.452980]\n",
      "epoch:6 step:4950 [D loss: 0.899212, acc: 22.66%] [G loss: 1.522945]\n",
      "epoch:6 step:4951 [D loss: 0.694419, acc: 50.78%] [G loss: 1.464721]\n",
      "epoch:6 step:4952 [D loss: 0.709512, acc: 51.56%] [G loss: 1.562759]\n",
      "epoch:6 step:4953 [D loss: 0.886630, acc: 22.66%] [G loss: 1.313203]\n",
      "epoch:6 step:4954 [D loss: 0.651006, acc: 65.62%] [G loss: 1.595673]\n",
      "epoch:6 step:4955 [D loss: 0.707965, acc: 52.34%] [G loss: 1.669095]\n",
      "epoch:6 step:4956 [D loss: 0.652918, acc: 64.06%] [G loss: 1.545281]\n",
      "epoch:6 step:4957 [D loss: 0.759339, acc: 40.62%] [G loss: 1.598893]\n",
      "epoch:6 step:4958 [D loss: 0.761499, acc: 40.62%] [G loss: 1.545439]\n",
      "epoch:6 step:4959 [D loss: 0.690892, acc: 65.62%] [G loss: 1.521890]\n",
      "epoch:6 step:4960 [D loss: 0.610598, acc: 70.31%] [G loss: 1.415212]\n",
      "epoch:6 step:4961 [D loss: 0.692873, acc: 58.59%] [G loss: 1.379008]\n",
      "epoch:6 step:4962 [D loss: 0.623154, acc: 66.41%] [G loss: 1.399238]\n",
      "epoch:6 step:4963 [D loss: 1.006629, acc: 8.59%] [G loss: 1.293956]\n",
      "epoch:6 step:4964 [D loss: 0.695452, acc: 51.56%] [G loss: 1.485230]\n",
      "epoch:6 step:4965 [D loss: 0.784791, acc: 40.62%] [G loss: 1.423075]\n",
      "epoch:6 step:4966 [D loss: 0.706537, acc: 53.12%] [G loss: 1.599892]\n",
      "epoch:6 step:4967 [D loss: 0.647734, acc: 57.81%] [G loss: 1.575271]\n",
      "epoch:6 step:4968 [D loss: 0.782566, acc: 33.59%] [G loss: 1.455083]\n",
      "epoch:6 step:4969 [D loss: 0.585987, acc: 76.56%] [G loss: 1.647010]\n",
      "epoch:6 step:4970 [D loss: 0.666352, acc: 70.31%] [G loss: 1.440046]\n",
      "epoch:6 step:4971 [D loss: 0.629652, acc: 69.53%] [G loss: 1.628140]\n",
      "epoch:6 step:4972 [D loss: 0.691405, acc: 60.16%] [G loss: 1.485994]\n",
      "epoch:6 step:4973 [D loss: 0.579989, acc: 73.44%] [G loss: 1.586954]\n",
      "epoch:6 step:4974 [D loss: 0.714961, acc: 50.78%] [G loss: 1.492668]\n",
      "epoch:6 step:4975 [D loss: 0.684485, acc: 57.03%] [G loss: 1.634082]\n",
      "epoch:6 step:4976 [D loss: 0.692738, acc: 55.47%] [G loss: 1.386576]\n",
      "epoch:6 step:4977 [D loss: 0.831401, acc: 31.25%] [G loss: 1.281014]\n",
      "epoch:6 step:4978 [D loss: 0.739201, acc: 45.31%] [G loss: 1.534314]\n",
      "epoch:6 step:4979 [D loss: 0.652013, acc: 66.41%] [G loss: 1.609679]\n",
      "epoch:6 step:4980 [D loss: 0.726282, acc: 44.53%] [G loss: 1.421426]\n",
      "epoch:6 step:4981 [D loss: 0.669850, acc: 60.94%] [G loss: 1.472499]\n",
      "epoch:6 step:4982 [D loss: 0.750698, acc: 46.88%] [G loss: 1.480117]\n",
      "epoch:6 step:4983 [D loss: 0.782617, acc: 40.62%] [G loss: 1.340847]\n",
      "epoch:6 step:4984 [D loss: 0.659828, acc: 59.38%] [G loss: 1.486548]\n",
      "epoch:6 step:4985 [D loss: 0.601628, acc: 68.75%] [G loss: 1.605561]\n",
      "epoch:6 step:4986 [D loss: 0.823652, acc: 32.03%] [G loss: 1.446925]\n",
      "epoch:6 step:4987 [D loss: 0.630788, acc: 69.53%] [G loss: 1.696464]\n",
      "epoch:6 step:4988 [D loss: 0.696897, acc: 57.03%] [G loss: 1.453028]\n",
      "epoch:6 step:4989 [D loss: 0.704223, acc: 53.91%] [G loss: 1.429942]\n",
      "epoch:6 step:4990 [D loss: 0.647184, acc: 67.19%] [G loss: 1.557778]\n",
      "epoch:6 step:4991 [D loss: 0.771074, acc: 42.97%] [G loss: 1.556291]\n",
      "epoch:6 step:4992 [D loss: 0.714704, acc: 53.91%] [G loss: 1.433715]\n",
      "epoch:6 step:4993 [D loss: 0.818417, acc: 32.81%] [G loss: 1.423854]\n",
      "epoch:6 step:4994 [D loss: 0.745593, acc: 50.00%] [G loss: 1.534728]\n",
      "epoch:6 step:4995 [D loss: 0.684729, acc: 55.47%] [G loss: 1.659010]\n",
      "epoch:6 step:4996 [D loss: 0.717546, acc: 52.34%] [G loss: 1.521018]\n",
      "epoch:6 step:4997 [D loss: 0.627590, acc: 71.88%] [G loss: 1.756526]\n",
      "epoch:6 step:4998 [D loss: 0.628530, acc: 65.62%] [G loss: 1.552944]\n",
      "epoch:6 step:4999 [D loss: 0.632978, acc: 60.94%] [G loss: 1.699999]\n",
      "epoch:6 step:5000 [D loss: 0.706721, acc: 60.94%] [G loss: 1.529108]\n",
      "epoch:6 step:5001 [D loss: 0.657993, acc: 62.50%] [G loss: 1.632544]\n",
      "epoch:6 step:5002 [D loss: 0.649302, acc: 62.50%] [G loss: 1.714242]\n",
      "epoch:6 step:5003 [D loss: 0.720714, acc: 46.88%] [G loss: 1.520238]\n",
      "epoch:6 step:5004 [D loss: 0.620453, acc: 67.97%] [G loss: 1.723740]\n",
      "epoch:6 step:5005 [D loss: 0.798400, acc: 35.94%] [G loss: 1.445205]\n",
      "epoch:6 step:5006 [D loss: 0.713762, acc: 54.69%] [G loss: 1.672958]\n",
      "epoch:6 step:5007 [D loss: 0.653750, acc: 61.72%] [G loss: 1.584974]\n",
      "epoch:6 step:5008 [D loss: 0.663004, acc: 60.16%] [G loss: 1.733217]\n",
      "epoch:6 step:5009 [D loss: 0.582545, acc: 75.78%] [G loss: 1.569110]\n",
      "epoch:6 step:5010 [D loss: 0.637680, acc: 69.53%] [G loss: 1.631246]\n",
      "epoch:6 step:5011 [D loss: 0.746581, acc: 37.50%] [G loss: 1.549981]\n",
      "epoch:6 step:5012 [D loss: 0.765282, acc: 42.19%] [G loss: 1.510335]\n",
      "epoch:6 step:5013 [D loss: 0.665220, acc: 64.84%] [G loss: 1.554121]\n",
      "epoch:6 step:5014 [D loss: 0.686748, acc: 51.56%] [G loss: 1.665760]\n",
      "epoch:6 step:5015 [D loss: 0.654418, acc: 59.38%] [G loss: 1.698004]\n",
      "epoch:6 step:5016 [D loss: 0.686050, acc: 56.25%] [G loss: 1.678661]\n",
      "epoch:6 step:5017 [D loss: 0.960463, acc: 12.50%] [G loss: 1.265692]\n",
      "epoch:6 step:5018 [D loss: 0.618728, acc: 70.31%] [G loss: 1.602197]\n",
      "epoch:6 step:5019 [D loss: 0.727403, acc: 43.75%] [G loss: 1.361264]\n",
      "epoch:6 step:5020 [D loss: 0.666307, acc: 60.16%] [G loss: 1.617824]\n",
      "epoch:6 step:5021 [D loss: 0.694174, acc: 52.34%] [G loss: 1.388228]\n",
      "epoch:6 step:5022 [D loss: 0.634844, acc: 64.84%] [G loss: 1.510144]\n",
      "epoch:6 step:5023 [D loss: 0.629590, acc: 70.31%] [G loss: 1.463969]\n",
      "epoch:6 step:5024 [D loss: 1.081631, acc: 10.16%] [G loss: 1.340655]\n",
      "epoch:6 step:5025 [D loss: 0.808869, acc: 49.22%] [G loss: 1.569130]\n",
      "epoch:6 step:5026 [D loss: 0.694407, acc: 49.22%] [G loss: 1.552743]\n",
      "epoch:6 step:5027 [D loss: 0.712394, acc: 50.00%] [G loss: 1.610766]\n",
      "epoch:6 step:5028 [D loss: 0.761837, acc: 42.19%] [G loss: 1.456377]\n",
      "epoch:6 step:5029 [D loss: 0.775427, acc: 41.41%] [G loss: 1.550950]\n",
      "epoch:6 step:5030 [D loss: 0.741264, acc: 48.44%] [G loss: 1.411754]\n",
      "epoch:6 step:5031 [D loss: 0.686709, acc: 47.66%] [G loss: 1.629844]\n",
      "epoch:6 step:5032 [D loss: 0.778221, acc: 41.41%] [G loss: 1.475871]\n",
      "epoch:6 step:5033 [D loss: 0.701507, acc: 53.91%] [G loss: 1.592765]\n",
      "epoch:6 step:5034 [D loss: 0.757779, acc: 46.88%] [G loss: 1.581822]\n",
      "epoch:6 step:5035 [D loss: 0.704491, acc: 47.66%] [G loss: 1.520299]\n",
      "epoch:6 step:5036 [D loss: 0.869630, acc: 26.56%] [G loss: 1.506826]\n",
      "epoch:6 step:5037 [D loss: 0.665259, acc: 61.72%] [G loss: 1.602074]\n",
      "epoch:6 step:5038 [D loss: 0.740329, acc: 41.41%] [G loss: 1.727691]\n",
      "epoch:6 step:5039 [D loss: 0.693248, acc: 48.44%] [G loss: 1.677435]\n",
      "epoch:6 step:5040 [D loss: 0.648193, acc: 61.72%] [G loss: 1.577253]\n",
      "epoch:6 step:5041 [D loss: 0.715710, acc: 50.78%] [G loss: 1.466493]\n",
      "epoch:6 step:5042 [D loss: 0.667273, acc: 63.28%] [G loss: 1.633834]\n",
      "epoch:6 step:5043 [D loss: 0.723291, acc: 41.41%] [G loss: 1.514677]\n",
      "epoch:6 step:5044 [D loss: 0.762493, acc: 41.41%] [G loss: 1.592554]\n",
      "epoch:6 step:5045 [D loss: 0.819306, acc: 35.16%] [G loss: 1.544792]\n",
      "epoch:6 step:5046 [D loss: 0.728016, acc: 52.34%] [G loss: 1.639494]\n",
      "epoch:6 step:5047 [D loss: 0.762083, acc: 43.75%] [G loss: 1.478010]\n",
      "epoch:6 step:5048 [D loss: 0.671125, acc: 62.50%] [G loss: 1.456258]\n",
      "epoch:6 step:5049 [D loss: 0.574580, acc: 78.12%] [G loss: 1.637987]\n",
      "epoch:6 step:5050 [D loss: 0.643121, acc: 64.06%] [G loss: 1.602626]\n",
      "epoch:6 step:5051 [D loss: 0.687616, acc: 51.56%] [G loss: 1.606846]\n",
      "epoch:6 step:5052 [D loss: 0.690912, acc: 53.12%] [G loss: 1.526854]\n",
      "epoch:6 step:5053 [D loss: 0.755518, acc: 48.44%] [G loss: 1.552549]\n",
      "epoch:6 step:5054 [D loss: 0.712693, acc: 55.47%] [G loss: 1.450523]\n",
      "epoch:6 step:5055 [D loss: 0.602247, acc: 73.44%] [G loss: 1.607629]\n",
      "epoch:6 step:5056 [D loss: 0.775336, acc: 37.50%] [G loss: 1.567098]\n",
      "epoch:6 step:5057 [D loss: 0.618752, acc: 71.09%] [G loss: 1.618975]\n",
      "epoch:6 step:5058 [D loss: 0.650074, acc: 68.75%] [G loss: 1.746232]\n",
      "epoch:6 step:5059 [D loss: 0.901738, acc: 26.56%] [G loss: 1.286652]\n",
      "epoch:6 step:5060 [D loss: 0.650892, acc: 63.28%] [G loss: 1.642275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5061 [D loss: 0.780736, acc: 35.94%] [G loss: 1.500759]\n",
      "epoch:6 step:5062 [D loss: 0.594674, acc: 73.44%] [G loss: 1.731806]\n",
      "epoch:6 step:5063 [D loss: 0.689967, acc: 58.59%] [G loss: 1.564035]\n",
      "epoch:6 step:5064 [D loss: 0.646927, acc: 67.97%] [G loss: 1.526749]\n",
      "epoch:6 step:5065 [D loss: 0.764372, acc: 46.09%] [G loss: 1.660030]\n",
      "epoch:6 step:5066 [D loss: 0.599675, acc: 69.53%] [G loss: 1.670336]\n",
      "epoch:6 step:5067 [D loss: 0.706875, acc: 52.34%] [G loss: 1.598548]\n",
      "epoch:6 step:5068 [D loss: 0.653246, acc: 66.41%] [G loss: 1.743185]\n",
      "epoch:6 step:5069 [D loss: 0.728389, acc: 42.19%] [G loss: 1.477938]\n",
      "epoch:6 step:5070 [D loss: 0.749753, acc: 47.66%] [G loss: 1.644267]\n",
      "epoch:6 step:5071 [D loss: 0.749102, acc: 39.06%] [G loss: 1.518559]\n",
      "epoch:6 step:5072 [D loss: 0.763808, acc: 44.53%] [G loss: 1.540348]\n",
      "epoch:6 step:5073 [D loss: 0.694749, acc: 56.25%] [G loss: 1.606324]\n",
      "epoch:6 step:5074 [D loss: 0.739176, acc: 51.56%] [G loss: 1.437918]\n",
      "epoch:6 step:5075 [D loss: 0.781324, acc: 41.41%] [G loss: 1.466372]\n",
      "epoch:6 step:5076 [D loss: 0.699870, acc: 53.91%] [G loss: 1.487935]\n",
      "epoch:6 step:5077 [D loss: 0.770574, acc: 40.62%] [G loss: 1.523726]\n",
      "epoch:6 step:5078 [D loss: 0.779389, acc: 29.69%] [G loss: 1.486759]\n",
      "epoch:6 step:5079 [D loss: 0.796505, acc: 35.94%] [G loss: 1.482249]\n",
      "epoch:6 step:5080 [D loss: 0.663303, acc: 65.62%] [G loss: 1.624713]\n",
      "epoch:6 step:5081 [D loss: 0.714516, acc: 49.22%] [G loss: 1.592299]\n",
      "epoch:6 step:5082 [D loss: 0.643759, acc: 64.06%] [G loss: 1.604126]\n",
      "epoch:6 step:5083 [D loss: 0.777921, acc: 37.50%] [G loss: 1.457948]\n",
      "epoch:6 step:5084 [D loss: 0.766408, acc: 39.84%] [G loss: 1.486781]\n",
      "epoch:6 step:5085 [D loss: 0.710214, acc: 48.44%] [G loss: 1.597366]\n",
      "epoch:6 step:5086 [D loss: 0.575771, acc: 72.66%] [G loss: 1.611783]\n",
      "epoch:6 step:5087 [D loss: 0.703703, acc: 53.12%] [G loss: 1.589177]\n",
      "epoch:6 step:5088 [D loss: 0.755727, acc: 42.19%] [G loss: 1.422879]\n",
      "epoch:6 step:5089 [D loss: 0.759109, acc: 46.88%] [G loss: 1.505924]\n",
      "epoch:6 step:5090 [D loss: 0.710405, acc: 53.12%] [G loss: 1.614268]\n",
      "epoch:6 step:5091 [D loss: 0.752380, acc: 42.97%] [G loss: 1.500551]\n",
      "epoch:6 step:5092 [D loss: 0.676587, acc: 57.81%] [G loss: 1.764311]\n",
      "epoch:6 step:5093 [D loss: 0.728561, acc: 48.44%] [G loss: 1.549559]\n",
      "epoch:6 step:5094 [D loss: 0.700062, acc: 55.47%] [G loss: 1.578910]\n",
      "epoch:6 step:5095 [D loss: 0.685154, acc: 53.91%] [G loss: 1.776095]\n",
      "epoch:6 step:5096 [D loss: 0.794294, acc: 35.94%] [G loss: 1.523605]\n",
      "epoch:6 step:5097 [D loss: 0.842466, acc: 35.94%] [G loss: 1.490173]\n",
      "epoch:6 step:5098 [D loss: 0.638719, acc: 67.19%] [G loss: 1.670046]\n",
      "epoch:6 step:5099 [D loss: 0.580217, acc: 75.78%] [G loss: 1.654696]\n",
      "epoch:6 step:5100 [D loss: 0.657449, acc: 64.84%] [G loss: 1.582118]\n",
      "epoch:6 step:5101 [D loss: 0.677536, acc: 62.50%] [G loss: 1.648056]\n",
      "epoch:6 step:5102 [D loss: 0.695883, acc: 53.12%] [G loss: 1.591147]\n",
      "epoch:6 step:5103 [D loss: 0.686151, acc: 60.94%] [G loss: 1.639483]\n",
      "epoch:6 step:5104 [D loss: 0.696597, acc: 56.25%] [G loss: 1.513598]\n",
      "epoch:6 step:5105 [D loss: 0.692918, acc: 54.69%] [G loss: 1.604267]\n",
      "epoch:6 step:5106 [D loss: 0.754304, acc: 42.19%] [G loss: 1.542558]\n",
      "epoch:6 step:5107 [D loss: 0.794855, acc: 37.50%] [G loss: 1.538050]\n",
      "epoch:6 step:5108 [D loss: 0.661667, acc: 66.41%] [G loss: 1.630330]\n",
      "epoch:6 step:5109 [D loss: 0.654575, acc: 53.12%] [G loss: 1.561407]\n",
      "epoch:6 step:5110 [D loss: 0.932941, acc: 32.81%] [G loss: 1.334406]\n",
      "epoch:6 step:5111 [D loss: 0.662539, acc: 53.91%] [G loss: 1.648240]\n",
      "epoch:6 step:5112 [D loss: 0.726839, acc: 42.97%] [G loss: 1.575741]\n",
      "epoch:6 step:5113 [D loss: 0.686115, acc: 55.47%] [G loss: 1.426262]\n",
      "epoch:6 step:5114 [D loss: 0.707476, acc: 43.75%] [G loss: 1.559058]\n",
      "epoch:6 step:5115 [D loss: 0.631597, acc: 60.16%] [G loss: 1.722262]\n",
      "epoch:6 step:5116 [D loss: 0.795673, acc: 39.84%] [G loss: 1.466264]\n",
      "epoch:6 step:5117 [D loss: 0.798135, acc: 29.69%] [G loss: 1.328765]\n",
      "epoch:6 step:5118 [D loss: 0.629348, acc: 71.09%] [G loss: 1.592008]\n",
      "epoch:6 step:5119 [D loss: 0.724220, acc: 46.09%] [G loss: 1.527785]\n",
      "epoch:6 step:5120 [D loss: 0.801234, acc: 35.94%] [G loss: 1.488342]\n",
      "epoch:6 step:5121 [D loss: 0.706229, acc: 46.88%] [G loss: 1.476705]\n",
      "epoch:6 step:5122 [D loss: 0.759325, acc: 36.72%] [G loss: 1.529770]\n",
      "epoch:6 step:5123 [D loss: 0.756831, acc: 43.75%] [G loss: 1.307883]\n",
      "epoch:6 step:5124 [D loss: 0.726607, acc: 50.78%] [G loss: 1.449678]\n",
      "epoch:6 step:5125 [D loss: 0.726810, acc: 45.31%] [G loss: 1.570126]\n",
      "epoch:6 step:5126 [D loss: 0.696937, acc: 47.66%] [G loss: 1.451356]\n",
      "epoch:6 step:5127 [D loss: 0.913894, acc: 19.53%] [G loss: 1.387313]\n",
      "epoch:6 step:5128 [D loss: 0.808298, acc: 33.59%] [G loss: 1.438171]\n",
      "epoch:6 step:5129 [D loss: 0.681055, acc: 58.59%] [G loss: 1.494140]\n",
      "epoch:6 step:5130 [D loss: 0.704825, acc: 55.47%] [G loss: 1.314147]\n",
      "epoch:6 step:5131 [D loss: 0.707299, acc: 53.91%] [G loss: 1.463758]\n",
      "epoch:6 step:5132 [D loss: 0.717557, acc: 50.00%] [G loss: 1.438083]\n",
      "epoch:6 step:5133 [D loss: 0.759872, acc: 41.41%] [G loss: 1.431984]\n",
      "epoch:6 step:5134 [D loss: 0.712172, acc: 51.56%] [G loss: 1.583649]\n",
      "epoch:6 step:5135 [D loss: 0.758620, acc: 35.94%] [G loss: 1.567272]\n",
      "epoch:6 step:5136 [D loss: 0.696835, acc: 54.69%] [G loss: 1.579642]\n",
      "epoch:6 step:5137 [D loss: 0.687497, acc: 52.34%] [G loss: 1.606897]\n",
      "epoch:6 step:5138 [D loss: 0.661716, acc: 58.59%] [G loss: 1.624584]\n",
      "epoch:6 step:5139 [D loss: 0.667583, acc: 60.94%] [G loss: 1.570553]\n",
      "epoch:6 step:5140 [D loss: 0.612322, acc: 76.56%] [G loss: 1.543772]\n",
      "epoch:6 step:5141 [D loss: 0.662740, acc: 64.06%] [G loss: 1.543828]\n",
      "epoch:6 step:5142 [D loss: 0.623948, acc: 69.53%] [G loss: 1.625547]\n",
      "epoch:6 step:5143 [D loss: 0.656447, acc: 64.84%] [G loss: 1.621113]\n",
      "epoch:6 step:5144 [D loss: 0.645838, acc: 60.16%] [G loss: 1.642879]\n",
      "epoch:6 step:5145 [D loss: 0.647666, acc: 67.97%] [G loss: 1.475208]\n",
      "epoch:6 step:5146 [D loss: 0.595158, acc: 77.34%] [G loss: 1.538523]\n",
      "epoch:6 step:5147 [D loss: 0.648212, acc: 61.72%] [G loss: 1.618218]\n",
      "epoch:6 step:5148 [D loss: 0.673528, acc: 59.38%] [G loss: 1.693622]\n",
      "epoch:6 step:5149 [D loss: 0.659330, acc: 60.94%] [G loss: 1.583054]\n",
      "epoch:6 step:5150 [D loss: 0.740169, acc: 46.09%] [G loss: 1.557007]\n",
      "epoch:6 step:5151 [D loss: 0.715969, acc: 50.00%] [G loss: 1.608633]\n",
      "epoch:6 step:5152 [D loss: 0.627594, acc: 69.53%] [G loss: 1.629857]\n",
      "epoch:6 step:5153 [D loss: 0.671233, acc: 58.59%] [G loss: 1.602704]\n",
      "epoch:6 step:5154 [D loss: 0.712842, acc: 55.47%] [G loss: 1.587772]\n",
      "epoch:6 step:5155 [D loss: 0.634197, acc: 60.94%] [G loss: 1.643664]\n",
      "epoch:6 step:5156 [D loss: 0.651957, acc: 67.19%] [G loss: 1.680639]\n",
      "epoch:6 step:5157 [D loss: 0.714883, acc: 50.00%] [G loss: 1.408618]\n",
      "epoch:6 step:5158 [D loss: 0.869876, acc: 23.44%] [G loss: 1.419202]\n",
      "epoch:6 step:5159 [D loss: 0.759747, acc: 42.97%] [G loss: 1.689354]\n",
      "epoch:6 step:5160 [D loss: 0.862005, acc: 23.44%] [G loss: 1.435096]\n",
      "epoch:6 step:5161 [D loss: 0.685928, acc: 57.03%] [G loss: 1.532155]\n",
      "epoch:6 step:5162 [D loss: 0.689101, acc: 55.47%] [G loss: 1.503252]\n",
      "epoch:6 step:5163 [D loss: 0.616748, acc: 70.31%] [G loss: 1.591101]\n",
      "epoch:6 step:5164 [D loss: 0.664277, acc: 59.38%] [G loss: 1.615294]\n",
      "epoch:6 step:5165 [D loss: 0.626891, acc: 65.62%] [G loss: 1.695166]\n",
      "epoch:6 step:5166 [D loss: 0.737841, acc: 44.53%] [G loss: 1.559099]\n",
      "epoch:6 step:5167 [D loss: 0.739766, acc: 43.75%] [G loss: 1.578261]\n",
      "epoch:6 step:5168 [D loss: 0.827610, acc: 35.16%] [G loss: 1.330309]\n",
      "epoch:6 step:5169 [D loss: 0.637695, acc: 65.62%] [G loss: 1.610304]\n",
      "epoch:6 step:5170 [D loss: 0.662015, acc: 61.72%] [G loss: 1.514781]\n",
      "epoch:6 step:5171 [D loss: 0.610867, acc: 73.44%] [G loss: 1.610115]\n",
      "epoch:6 step:5172 [D loss: 0.667923, acc: 58.59%] [G loss: 1.407277]\n",
      "epoch:6 step:5173 [D loss: 0.775100, acc: 43.75%] [G loss: 1.513636]\n",
      "epoch:6 step:5174 [D loss: 0.702415, acc: 54.69%] [G loss: 1.494398]\n",
      "epoch:6 step:5175 [D loss: 0.769937, acc: 36.72%] [G loss: 1.442160]\n",
      "epoch:6 step:5176 [D loss: 0.733341, acc: 48.44%] [G loss: 1.511990]\n",
      "epoch:6 step:5177 [D loss: 0.806562, acc: 35.16%] [G loss: 1.365203]\n",
      "epoch:6 step:5178 [D loss: 0.712923, acc: 56.25%] [G loss: 1.582641]\n",
      "epoch:6 step:5179 [D loss: 0.806830, acc: 34.38%] [G loss: 1.478066]\n",
      "epoch:6 step:5180 [D loss: 0.745587, acc: 46.88%] [G loss: 1.556919]\n",
      "epoch:6 step:5181 [D loss: 0.708488, acc: 53.12%] [G loss: 1.514914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5182 [D loss: 0.688420, acc: 57.03%] [G loss: 1.596496]\n",
      "epoch:6 step:5183 [D loss: 0.746866, acc: 39.84%] [G loss: 1.578566]\n",
      "epoch:6 step:5184 [D loss: 0.790684, acc: 33.59%] [G loss: 1.531955]\n",
      "epoch:6 step:5185 [D loss: 0.697795, acc: 53.91%] [G loss: 1.587281]\n",
      "epoch:6 step:5186 [D loss: 0.768854, acc: 41.41%] [G loss: 1.553081]\n",
      "epoch:6 step:5187 [D loss: 0.649923, acc: 61.72%] [G loss: 1.483505]\n",
      "epoch:6 step:5188 [D loss: 0.652351, acc: 60.94%] [G loss: 1.588853]\n",
      "epoch:6 step:5189 [D loss: 0.635319, acc: 71.09%] [G loss: 1.604839]\n",
      "epoch:6 step:5190 [D loss: 0.756779, acc: 36.72%] [G loss: 1.561275]\n",
      "epoch:6 step:5191 [D loss: 0.727847, acc: 47.66%] [G loss: 1.635343]\n",
      "epoch:6 step:5192 [D loss: 0.648844, acc: 67.19%] [G loss: 1.640976]\n",
      "epoch:6 step:5193 [D loss: 0.658059, acc: 60.16%] [G loss: 1.659934]\n",
      "epoch:6 step:5194 [D loss: 0.706714, acc: 53.12%] [G loss: 1.601866]\n",
      "epoch:6 step:5195 [D loss: 0.703196, acc: 60.16%] [G loss: 1.679039]\n",
      "epoch:6 step:5196 [D loss: 0.614753, acc: 67.19%] [G loss: 1.617546]\n",
      "epoch:6 step:5197 [D loss: 0.730397, acc: 48.44%] [G loss: 1.560696]\n",
      "epoch:6 step:5198 [D loss: 0.564302, acc: 77.34%] [G loss: 1.487071]\n",
      "epoch:6 step:5199 [D loss: 0.508586, acc: 87.50%] [G loss: 1.618826]\n",
      "epoch:6 step:5200 [D loss: 0.753851, acc: 46.88%] [G loss: 1.538209]\n",
      "epoch:6 step:5201 [D loss: 0.546844, acc: 72.66%] [G loss: 1.346901]\n",
      "epoch:6 step:5202 [D loss: 0.616080, acc: 65.62%] [G loss: 1.461659]\n",
      "epoch:6 step:5203 [D loss: 0.673360, acc: 60.16%] [G loss: 1.552245]\n",
      "epoch:6 step:5204 [D loss: 0.810947, acc: 39.84%] [G loss: 1.308838]\n",
      "epoch:6 step:5205 [D loss: 0.797960, acc: 33.59%] [G loss: 1.169525]\n",
      "epoch:6 step:5206 [D loss: 0.679078, acc: 61.72%] [G loss: 1.561162]\n",
      "epoch:6 step:5207 [D loss: 0.670064, acc: 57.81%] [G loss: 1.351228]\n",
      "epoch:6 step:5208 [D loss: 0.660518, acc: 62.50%] [G loss: 1.428056]\n",
      "epoch:6 step:5209 [D loss: 0.737391, acc: 47.66%] [G loss: 1.290614]\n",
      "epoch:6 step:5210 [D loss: 0.667139, acc: 61.72%] [G loss: 1.526304]\n",
      "epoch:6 step:5211 [D loss: 0.734179, acc: 50.78%] [G loss: 1.396388]\n",
      "epoch:6 step:5212 [D loss: 0.594602, acc: 69.53%] [G loss: 1.531114]\n",
      "epoch:6 step:5213 [D loss: 0.733463, acc: 51.56%] [G loss: 1.295823]\n",
      "epoch:6 step:5214 [D loss: 0.757566, acc: 39.06%] [G loss: 1.312179]\n",
      "epoch:6 step:5215 [D loss: 0.664340, acc: 63.28%] [G loss: 1.381937]\n",
      "epoch:6 step:5216 [D loss: 0.671976, acc: 58.59%] [G loss: 1.423760]\n",
      "epoch:6 step:5217 [D loss: 0.785763, acc: 39.84%] [G loss: 1.405699]\n",
      "epoch:6 step:5218 [D loss: 0.608376, acc: 71.09%] [G loss: 1.566800]\n",
      "epoch:6 step:5219 [D loss: 0.620706, acc: 61.72%] [G loss: 1.435967]\n",
      "epoch:6 step:5220 [D loss: 0.704995, acc: 55.47%] [G loss: 1.505585]\n",
      "epoch:6 step:5221 [D loss: 0.875406, acc: 21.09%] [G loss: 1.585290]\n",
      "epoch:6 step:5222 [D loss: 0.772066, acc: 32.81%] [G loss: 1.558749]\n",
      "epoch:6 step:5223 [D loss: 0.654473, acc: 57.03%] [G loss: 1.656269]\n",
      "epoch:6 step:5224 [D loss: 0.816806, acc: 36.72%] [G loss: 1.553279]\n",
      "epoch:6 step:5225 [D loss: 0.740786, acc: 50.78%] [G loss: 1.650736]\n",
      "epoch:6 step:5226 [D loss: 0.680731, acc: 57.81%] [G loss: 1.652436]\n",
      "epoch:6 step:5227 [D loss: 0.639994, acc: 61.72%] [G loss: 1.860115]\n",
      "epoch:6 step:5228 [D loss: 0.824565, acc: 31.25%] [G loss: 1.539732]\n",
      "epoch:6 step:5229 [D loss: 0.682152, acc: 61.72%] [G loss: 1.522214]\n",
      "epoch:6 step:5230 [D loss: 0.618584, acc: 71.88%] [G loss: 1.593206]\n",
      "epoch:6 step:5231 [D loss: 0.695623, acc: 57.81%] [G loss: 1.568109]\n",
      "epoch:6 step:5232 [D loss: 0.791858, acc: 49.22%] [G loss: 1.641431]\n",
      "epoch:6 step:5233 [D loss: 0.645837, acc: 64.06%] [G loss: 1.563424]\n",
      "epoch:6 step:5234 [D loss: 0.685780, acc: 60.16%] [G loss: 1.542527]\n",
      "epoch:6 step:5235 [D loss: 0.576998, acc: 77.34%] [G loss: 1.657309]\n",
      "epoch:6 step:5236 [D loss: 0.678349, acc: 53.12%] [G loss: 1.482259]\n",
      "epoch:6 step:5237 [D loss: 0.553273, acc: 77.34%] [G loss: 1.427139]\n",
      "epoch:6 step:5238 [D loss: 0.470379, acc: 87.50%] [G loss: 1.600522]\n",
      "epoch:6 step:5239 [D loss: 0.610845, acc: 65.62%] [G loss: 1.311154]\n",
      "epoch:6 step:5240 [D loss: 0.448004, acc: 86.72%] [G loss: 1.549645]\n",
      "epoch:6 step:5241 [D loss: 0.452947, acc: 82.81%] [G loss: 1.397520]\n",
      "epoch:6 step:5242 [D loss: 0.634459, acc: 60.16%] [G loss: 1.536270]\n",
      "epoch:6 step:5243 [D loss: 0.515632, acc: 85.94%] [G loss: 1.458699]\n",
      "epoch:6 step:5244 [D loss: 0.653172, acc: 65.62%] [G loss: 1.402018]\n",
      "epoch:6 step:5245 [D loss: 0.716076, acc: 56.25%] [G loss: 1.481360]\n",
      "epoch:6 step:5246 [D loss: 1.032579, acc: 17.97%] [G loss: 1.465202]\n",
      "epoch:6 step:5247 [D loss: 0.735710, acc: 53.91%] [G loss: 1.377585]\n",
      "epoch:6 step:5248 [D loss: 0.801047, acc: 35.16%] [G loss: 1.420041]\n",
      "epoch:6 step:5249 [D loss: 0.633014, acc: 70.31%] [G loss: 1.479512]\n",
      "epoch:6 step:5250 [D loss: 0.779248, acc: 38.28%] [G loss: 1.433507]\n",
      "epoch:6 step:5251 [D loss: 0.834944, acc: 28.12%] [G loss: 1.388877]\n",
      "epoch:6 step:5252 [D loss: 0.803445, acc: 43.75%] [G loss: 1.477186]\n",
      "epoch:6 step:5253 [D loss: 0.895011, acc: 35.16%] [G loss: 1.573939]\n",
      "epoch:6 step:5254 [D loss: 0.773095, acc: 45.31%] [G loss: 1.449409]\n",
      "epoch:6 step:5255 [D loss: 0.644872, acc: 58.59%] [G loss: 1.666868]\n",
      "epoch:6 step:5256 [D loss: 0.606846, acc: 67.97%] [G loss: 1.812450]\n",
      "epoch:6 step:5257 [D loss: 0.735717, acc: 50.78%] [G loss: 1.576443]\n",
      "epoch:6 step:5258 [D loss: 0.662316, acc: 60.94%] [G loss: 1.691359]\n",
      "epoch:6 step:5259 [D loss: 0.737260, acc: 49.22%] [G loss: 1.573297]\n",
      "epoch:6 step:5260 [D loss: 0.810072, acc: 36.72%] [G loss: 1.415059]\n",
      "epoch:6 step:5261 [D loss: 0.816571, acc: 32.81%] [G loss: 1.386356]\n",
      "epoch:6 step:5262 [D loss: 0.847826, acc: 35.94%] [G loss: 1.534592]\n",
      "epoch:6 step:5263 [D loss: 0.600691, acc: 71.09%] [G loss: 1.575022]\n",
      "epoch:6 step:5264 [D loss: 0.694560, acc: 51.56%] [G loss: 1.643216]\n",
      "epoch:6 step:5265 [D loss: 0.683763, acc: 58.59%] [G loss: 1.529459]\n",
      "epoch:6 step:5266 [D loss: 0.680746, acc: 57.81%] [G loss: 1.558140]\n",
      "epoch:6 step:5267 [D loss: 0.689209, acc: 57.81%] [G loss: 1.602546]\n",
      "epoch:6 step:5268 [D loss: 0.586311, acc: 71.09%] [G loss: 1.421236]\n",
      "epoch:6 step:5269 [D loss: 0.664423, acc: 58.59%] [G loss: 1.468940]\n",
      "epoch:6 step:5270 [D loss: 0.551324, acc: 71.09%] [G loss: 1.357261]\n",
      "epoch:6 step:5271 [D loss: 0.688214, acc: 57.03%] [G loss: 1.414721]\n",
      "epoch:6 step:5272 [D loss: 0.712185, acc: 48.44%] [G loss: 1.503660]\n",
      "epoch:6 step:5273 [D loss: 0.801284, acc: 35.94%] [G loss: 1.351964]\n",
      "epoch:6 step:5274 [D loss: 0.706876, acc: 54.69%] [G loss: 1.465818]\n",
      "epoch:6 step:5275 [D loss: 0.686559, acc: 53.12%] [G loss: 1.334634]\n",
      "epoch:6 step:5276 [D loss: 0.640389, acc: 61.72%] [G loss: 1.290224]\n",
      "epoch:6 step:5277 [D loss: 0.619099, acc: 68.75%] [G loss: 1.598134]\n",
      "epoch:6 step:5278 [D loss: 0.737732, acc: 44.53%] [G loss: 1.379282]\n",
      "epoch:6 step:5279 [D loss: 0.710372, acc: 54.69%] [G loss: 1.539202]\n",
      "epoch:6 step:5280 [D loss: 0.744323, acc: 42.19%] [G loss: 1.446972]\n",
      "epoch:6 step:5281 [D loss: 0.744489, acc: 42.97%] [G loss: 1.585589]\n",
      "epoch:6 step:5282 [D loss: 0.846716, acc: 28.12%] [G loss: 1.468566]\n",
      "epoch:6 step:5283 [D loss: 0.629085, acc: 66.41%] [G loss: 1.524445]\n",
      "epoch:6 step:5284 [D loss: 0.806110, acc: 35.94%] [G loss: 1.420366]\n",
      "epoch:6 step:5285 [D loss: 0.685343, acc: 56.25%] [G loss: 1.471677]\n",
      "epoch:6 step:5286 [D loss: 0.696257, acc: 50.78%] [G loss: 1.492015]\n",
      "epoch:6 step:5287 [D loss: 0.689047, acc: 52.34%] [G loss: 1.441856]\n",
      "epoch:6 step:5288 [D loss: 0.657359, acc: 60.16%] [G loss: 1.665317]\n",
      "epoch:6 step:5289 [D loss: 0.795627, acc: 38.28%] [G loss: 1.464460]\n",
      "epoch:6 step:5290 [D loss: 0.676039, acc: 52.34%] [G loss: 1.536929]\n",
      "epoch:6 step:5291 [D loss: 0.710889, acc: 55.47%] [G loss: 1.528146]\n",
      "epoch:6 step:5292 [D loss: 0.687363, acc: 49.22%] [G loss: 1.522803]\n",
      "epoch:6 step:5293 [D loss: 0.717235, acc: 52.34%] [G loss: 1.526451]\n",
      "epoch:6 step:5294 [D loss: 0.817363, acc: 28.91%] [G loss: 1.375118]\n",
      "epoch:6 step:5295 [D loss: 0.635628, acc: 64.06%] [G loss: 1.513560]\n",
      "epoch:6 step:5296 [D loss: 0.874516, acc: 22.66%] [G loss: 1.415291]\n",
      "epoch:6 step:5297 [D loss: 0.798411, acc: 31.25%] [G loss: 1.332808]\n",
      "epoch:6 step:5298 [D loss: 0.737074, acc: 43.75%] [G loss: 1.464103]\n",
      "epoch:6 step:5299 [D loss: 0.772704, acc: 44.53%] [G loss: 1.649987]\n",
      "epoch:6 step:5300 [D loss: 0.747141, acc: 45.31%] [G loss: 1.431274]\n",
      "epoch:6 step:5301 [D loss: 0.692483, acc: 51.56%] [G loss: 1.584425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5302 [D loss: 0.625376, acc: 66.41%] [G loss: 1.564087]\n",
      "epoch:6 step:5303 [D loss: 0.583616, acc: 69.53%] [G loss: 1.731581]\n",
      "epoch:6 step:5304 [D loss: 0.658231, acc: 60.94%] [G loss: 1.454856]\n",
      "epoch:6 step:5305 [D loss: 0.668189, acc: 63.28%] [G loss: 1.429470]\n",
      "epoch:6 step:5306 [D loss: 0.692139, acc: 56.25%] [G loss: 1.467789]\n",
      "epoch:6 step:5307 [D loss: 0.711850, acc: 51.56%] [G loss: 1.595192]\n",
      "epoch:6 step:5308 [D loss: 0.697967, acc: 50.78%] [G loss: 1.564641]\n",
      "epoch:6 step:5309 [D loss: 0.700416, acc: 46.88%] [G loss: 1.541016]\n",
      "epoch:6 step:5310 [D loss: 0.696908, acc: 55.47%] [G loss: 1.609851]\n",
      "epoch:6 step:5311 [D loss: 0.633896, acc: 67.19%] [G loss: 1.518784]\n",
      "epoch:6 step:5312 [D loss: 0.729635, acc: 46.88%] [G loss: 1.459430]\n",
      "epoch:6 step:5313 [D loss: 0.719974, acc: 53.12%] [G loss: 1.670958]\n",
      "epoch:6 step:5314 [D loss: 0.692437, acc: 50.00%] [G loss: 1.578531]\n",
      "epoch:6 step:5315 [D loss: 0.664908, acc: 60.16%] [G loss: 1.638551]\n",
      "epoch:6 step:5316 [D loss: 0.596675, acc: 74.22%] [G loss: 1.466155]\n",
      "epoch:6 step:5317 [D loss: 0.729380, acc: 46.88%] [G loss: 1.625803]\n",
      "epoch:6 step:5318 [D loss: 0.787682, acc: 38.28%] [G loss: 1.272245]\n",
      "epoch:6 step:5319 [D loss: 0.901089, acc: 22.66%] [G loss: 1.403547]\n",
      "epoch:6 step:5320 [D loss: 0.667364, acc: 61.72%] [G loss: 1.509829]\n",
      "epoch:6 step:5321 [D loss: 0.705923, acc: 54.69%] [G loss: 1.541692]\n",
      "epoch:6 step:5322 [D loss: 0.619514, acc: 67.97%] [G loss: 1.688312]\n",
      "epoch:6 step:5323 [D loss: 0.765759, acc: 42.19%] [G loss: 1.337673]\n",
      "epoch:6 step:5324 [D loss: 0.728053, acc: 50.78%] [G loss: 1.359749]\n",
      "epoch:6 step:5325 [D loss: 0.810183, acc: 34.38%] [G loss: 1.502639]\n",
      "epoch:6 step:5326 [D loss: 0.762473, acc: 42.19%] [G loss: 1.419052]\n",
      "epoch:6 step:5327 [D loss: 0.704686, acc: 50.00%] [G loss: 1.598271]\n",
      "epoch:6 step:5328 [D loss: 0.623683, acc: 64.84%] [G loss: 1.595880]\n",
      "epoch:6 step:5329 [D loss: 0.731000, acc: 46.88%] [G loss: 1.467972]\n",
      "epoch:6 step:5330 [D loss: 0.673068, acc: 60.16%] [G loss: 1.645373]\n",
      "epoch:6 step:5331 [D loss: 0.749441, acc: 45.31%] [G loss: 1.420591]\n",
      "epoch:6 step:5332 [D loss: 0.812055, acc: 34.38%] [G loss: 1.433982]\n",
      "epoch:6 step:5333 [D loss: 0.701364, acc: 55.47%] [G loss: 1.457017]\n",
      "epoch:6 step:5334 [D loss: 0.790228, acc: 42.97%] [G loss: 1.495490]\n",
      "epoch:6 step:5335 [D loss: 0.683404, acc: 54.69%] [G loss: 1.474007]\n",
      "epoch:6 step:5336 [D loss: 0.712964, acc: 43.75%] [G loss: 1.479931]\n",
      "epoch:6 step:5337 [D loss: 0.641525, acc: 68.75%] [G loss: 1.726657]\n",
      "epoch:6 step:5338 [D loss: 0.742831, acc: 42.19%] [G loss: 1.466542]\n",
      "epoch:6 step:5339 [D loss: 0.668038, acc: 59.38%] [G loss: 1.544320]\n",
      "epoch:6 step:5340 [D loss: 0.708361, acc: 46.88%] [G loss: 1.518896]\n",
      "epoch:6 step:5341 [D loss: 0.696310, acc: 53.91%] [G loss: 1.566012]\n",
      "epoch:6 step:5342 [D loss: 0.813054, acc: 32.03%] [G loss: 1.372537]\n",
      "epoch:6 step:5343 [D loss: 0.696808, acc: 49.22%] [G loss: 1.685380]\n",
      "epoch:6 step:5344 [D loss: 0.641007, acc: 62.50%] [G loss: 1.517781]\n",
      "epoch:6 step:5345 [D loss: 0.663363, acc: 60.16%] [G loss: 1.531122]\n",
      "epoch:6 step:5346 [D loss: 0.635984, acc: 68.75%] [G loss: 1.595176]\n",
      "epoch:6 step:5347 [D loss: 0.738898, acc: 44.53%] [G loss: 1.500813]\n",
      "epoch:6 step:5348 [D loss: 0.808108, acc: 30.47%] [G loss: 1.540580]\n",
      "epoch:6 step:5349 [D loss: 0.644958, acc: 65.62%] [G loss: 1.589936]\n",
      "epoch:6 step:5350 [D loss: 0.756607, acc: 46.09%] [G loss: 1.578600]\n",
      "epoch:6 step:5351 [D loss: 0.773866, acc: 39.06%] [G loss: 1.421843]\n",
      "epoch:6 step:5352 [D loss: 0.615793, acc: 70.31%] [G loss: 1.477852]\n",
      "epoch:6 step:5353 [D loss: 0.609658, acc: 65.62%] [G loss: 1.487832]\n",
      "epoch:6 step:5354 [D loss: 0.614274, acc: 73.44%] [G loss: 1.465571]\n",
      "epoch:6 step:5355 [D loss: 0.577845, acc: 78.12%] [G loss: 1.575414]\n",
      "epoch:6 step:5356 [D loss: 0.805562, acc: 31.25%] [G loss: 1.349421]\n",
      "epoch:6 step:5357 [D loss: 0.618037, acc: 73.44%] [G loss: 1.505013]\n",
      "epoch:6 step:5358 [D loss: 0.742655, acc: 41.41%] [G loss: 1.303001]\n",
      "epoch:6 step:5359 [D loss: 0.765682, acc: 42.97%] [G loss: 1.499286]\n",
      "epoch:6 step:5360 [D loss: 0.759934, acc: 42.97%] [G loss: 1.478622]\n",
      "epoch:6 step:5361 [D loss: 0.709942, acc: 47.66%] [G loss: 1.576958]\n",
      "epoch:6 step:5362 [D loss: 0.808422, acc: 33.59%] [G loss: 1.535828]\n",
      "epoch:6 step:5363 [D loss: 0.603104, acc: 73.44%] [G loss: 1.644228]\n",
      "epoch:6 step:5364 [D loss: 0.629252, acc: 67.97%] [G loss: 1.586312]\n",
      "epoch:6 step:5365 [D loss: 0.739613, acc: 42.19%] [G loss: 1.581975]\n",
      "epoch:6 step:5366 [D loss: 0.692300, acc: 53.91%] [G loss: 1.600324]\n",
      "epoch:6 step:5367 [D loss: 0.678366, acc: 60.16%] [G loss: 1.633802]\n",
      "epoch:6 step:5368 [D loss: 0.763688, acc: 47.66%] [G loss: 1.541651]\n",
      "epoch:6 step:5369 [D loss: 0.671818, acc: 57.03%] [G loss: 1.585960]\n",
      "epoch:6 step:5370 [D loss: 0.623350, acc: 69.53%] [G loss: 1.638898]\n",
      "epoch:6 step:5371 [D loss: 0.686461, acc: 54.69%] [G loss: 1.528238]\n",
      "epoch:6 step:5372 [D loss: 0.659080, acc: 60.94%] [G loss: 1.625168]\n",
      "epoch:6 step:5373 [D loss: 0.645869, acc: 64.06%] [G loss: 1.542395]\n",
      "epoch:6 step:5374 [D loss: 0.629469, acc: 72.66%] [G loss: 1.610521]\n",
      "epoch:6 step:5375 [D loss: 0.700318, acc: 60.16%] [G loss: 1.543574]\n",
      "epoch:6 step:5376 [D loss: 0.720588, acc: 46.09%] [G loss: 1.429466]\n",
      "epoch:6 step:5377 [D loss: 0.673537, acc: 63.28%] [G loss: 1.607644]\n",
      "epoch:6 step:5378 [D loss: 0.716791, acc: 50.78%] [G loss: 1.643699]\n",
      "epoch:6 step:5379 [D loss: 0.664910, acc: 60.94%] [G loss: 1.577667]\n",
      "epoch:6 step:5380 [D loss: 0.637158, acc: 66.41%] [G loss: 1.623164]\n",
      "epoch:6 step:5381 [D loss: 0.723939, acc: 47.66%] [G loss: 1.444031]\n",
      "epoch:6 step:5382 [D loss: 0.715929, acc: 49.22%] [G loss: 1.579116]\n",
      "epoch:6 step:5383 [D loss: 0.599980, acc: 75.00%] [G loss: 1.582123]\n",
      "epoch:6 step:5384 [D loss: 0.716572, acc: 50.00%] [G loss: 1.523822]\n",
      "epoch:6 step:5385 [D loss: 0.795076, acc: 32.03%] [G loss: 1.540078]\n",
      "epoch:6 step:5386 [D loss: 0.660218, acc: 63.28%] [G loss: 1.653148]\n",
      "epoch:6 step:5387 [D loss: 0.553632, acc: 71.09%] [G loss: 1.531656]\n",
      "epoch:6 step:5388 [D loss: 0.643996, acc: 65.62%] [G loss: 1.553392]\n",
      "epoch:6 step:5389 [D loss: 0.736332, acc: 39.84%] [G loss: 1.514562]\n",
      "epoch:6 step:5390 [D loss: 0.794601, acc: 43.75%] [G loss: 1.534773]\n",
      "epoch:6 step:5391 [D loss: 0.746729, acc: 36.72%] [G loss: 1.626147]\n",
      "epoch:6 step:5392 [D loss: 0.848348, acc: 25.78%] [G loss: 1.369250]\n",
      "epoch:6 step:5393 [D loss: 0.733855, acc: 43.75%] [G loss: 1.564259]\n",
      "epoch:6 step:5394 [D loss: 0.752159, acc: 45.31%] [G loss: 1.508011]\n",
      "epoch:6 step:5395 [D loss: 0.728607, acc: 44.53%] [G loss: 1.436509]\n",
      "epoch:6 step:5396 [D loss: 0.614997, acc: 68.75%] [G loss: 1.562826]\n",
      "epoch:6 step:5397 [D loss: 0.748293, acc: 42.97%] [G loss: 1.452286]\n",
      "epoch:6 step:5398 [D loss: 0.670686, acc: 53.91%] [G loss: 1.608799]\n",
      "epoch:6 step:5399 [D loss: 0.702264, acc: 50.78%] [G loss: 1.586368]\n",
      "epoch:6 step:5400 [D loss: 0.664390, acc: 61.72%] [G loss: 1.454065]\n",
      "epoch:6 step:5401 [D loss: 0.644380, acc: 65.62%] [G loss: 1.610430]\n",
      "epoch:6 step:5402 [D loss: 0.761258, acc: 40.62%] [G loss: 1.562672]\n",
      "epoch:6 step:5403 [D loss: 0.616408, acc: 74.22%] [G loss: 1.697226]\n",
      "epoch:6 step:5404 [D loss: 0.623367, acc: 69.53%] [G loss: 1.504215]\n",
      "epoch:6 step:5405 [D loss: 0.493632, acc: 90.62%] [G loss: 1.761883]\n",
      "epoch:6 step:5406 [D loss: 0.685397, acc: 58.59%] [G loss: 1.548446]\n",
      "epoch:6 step:5407 [D loss: 0.840343, acc: 27.34%] [G loss: 1.472811]\n",
      "epoch:6 step:5408 [D loss: 0.713912, acc: 46.09%] [G loss: 1.624098]\n",
      "epoch:6 step:5409 [D loss: 0.646328, acc: 62.50%] [G loss: 1.693773]\n",
      "epoch:6 step:5410 [D loss: 0.701307, acc: 51.56%] [G loss: 1.520194]\n",
      "epoch:6 step:5411 [D loss: 0.719871, acc: 46.09%] [G loss: 1.712400]\n",
      "epoch:6 step:5412 [D loss: 0.727194, acc: 43.75%] [G loss: 1.435048]\n",
      "epoch:6 step:5413 [D loss: 0.775086, acc: 41.41%] [G loss: 1.561884]\n",
      "epoch:6 step:5414 [D loss: 0.708195, acc: 50.78%] [G loss: 1.696038]\n",
      "epoch:6 step:5415 [D loss: 0.773170, acc: 38.28%] [G loss: 1.590968]\n",
      "epoch:6 step:5416 [D loss: 0.692214, acc: 57.03%] [G loss: 1.559706]\n",
      "epoch:6 step:5417 [D loss: 0.643642, acc: 61.72%] [G loss: 1.596281]\n",
      "epoch:6 step:5418 [D loss: 0.697793, acc: 55.47%] [G loss: 1.526063]\n",
      "epoch:6 step:5419 [D loss: 0.640385, acc: 68.75%] [G loss: 1.530546]\n",
      "epoch:6 step:5420 [D loss: 0.669484, acc: 57.03%] [G loss: 1.617298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5421 [D loss: 0.706562, acc: 48.44%] [G loss: 1.470807]\n",
      "epoch:6 step:5422 [D loss: 0.787645, acc: 33.59%] [G loss: 1.570781]\n",
      "epoch:6 step:5423 [D loss: 0.698652, acc: 52.34%] [G loss: 1.573268]\n",
      "epoch:6 step:5424 [D loss: 0.656382, acc: 63.28%] [G loss: 1.714497]\n",
      "epoch:6 step:5425 [D loss: 0.656172, acc: 60.94%] [G loss: 1.580099]\n",
      "epoch:6 step:5426 [D loss: 0.689465, acc: 50.00%] [G loss: 1.415234]\n",
      "epoch:6 step:5427 [D loss: 0.630079, acc: 65.62%] [G loss: 1.553022]\n",
      "epoch:6 step:5428 [D loss: 0.723359, acc: 46.09%] [G loss: 1.538338]\n",
      "epoch:6 step:5429 [D loss: 0.825979, acc: 33.59%] [G loss: 1.563876]\n",
      "epoch:6 step:5430 [D loss: 0.613187, acc: 72.66%] [G loss: 1.543845]\n",
      "epoch:6 step:5431 [D loss: 0.757996, acc: 38.28%] [G loss: 1.621937]\n",
      "epoch:6 step:5432 [D loss: 0.667510, acc: 55.47%] [G loss: 1.559491]\n",
      "epoch:6 step:5433 [D loss: 0.733868, acc: 50.00%] [G loss: 1.620034]\n",
      "epoch:6 step:5434 [D loss: 0.748230, acc: 43.75%] [G loss: 1.454830]\n",
      "epoch:6 step:5435 [D loss: 0.765728, acc: 45.31%] [G loss: 1.519115]\n",
      "epoch:6 step:5436 [D loss: 0.784483, acc: 33.59%] [G loss: 1.614447]\n",
      "epoch:6 step:5437 [D loss: 0.780800, acc: 32.81%] [G loss: 1.555626]\n",
      "epoch:6 step:5438 [D loss: 0.602850, acc: 75.00%] [G loss: 1.696086]\n",
      "epoch:6 step:5439 [D loss: 0.668034, acc: 62.50%] [G loss: 1.643192]\n",
      "epoch:6 step:5440 [D loss: 0.737641, acc: 53.12%] [G loss: 1.493360]\n",
      "epoch:6 step:5441 [D loss: 0.687453, acc: 53.12%] [G loss: 1.573468]\n",
      "epoch:6 step:5442 [D loss: 0.838988, acc: 26.56%] [G loss: 1.602658]\n",
      "epoch:6 step:5443 [D loss: 0.732386, acc: 49.22%] [G loss: 1.579903]\n",
      "epoch:6 step:5444 [D loss: 0.721410, acc: 57.03%] [G loss: 1.519242]\n",
      "epoch:6 step:5445 [D loss: 0.778160, acc: 37.50%] [G loss: 1.536479]\n",
      "epoch:6 step:5446 [D loss: 0.753030, acc: 46.88%] [G loss: 1.602829]\n",
      "epoch:6 step:5447 [D loss: 0.665789, acc: 57.81%] [G loss: 1.618561]\n",
      "epoch:6 step:5448 [D loss: 0.685119, acc: 55.47%] [G loss: 1.430336]\n",
      "epoch:6 step:5449 [D loss: 0.867873, acc: 25.78%] [G loss: 1.497680]\n",
      "epoch:6 step:5450 [D loss: 0.752094, acc: 41.41%] [G loss: 1.396251]\n",
      "epoch:6 step:5451 [D loss: 0.718334, acc: 46.09%] [G loss: 1.440637]\n",
      "epoch:6 step:5452 [D loss: 0.531467, acc: 83.59%] [G loss: 1.755420]\n",
      "epoch:6 step:5453 [D loss: 0.688480, acc: 49.22%] [G loss: 1.469082]\n",
      "epoch:6 step:5454 [D loss: 0.687962, acc: 60.94%] [G loss: 1.436831]\n",
      "epoch:6 step:5455 [D loss: 0.687444, acc: 57.03%] [G loss: 1.593704]\n",
      "epoch:6 step:5456 [D loss: 0.677287, acc: 58.59%] [G loss: 1.419636]\n",
      "epoch:6 step:5457 [D loss: 0.998971, acc: 15.62%] [G loss: 1.336578]\n",
      "epoch:6 step:5458 [D loss: 0.749878, acc: 44.53%] [G loss: 1.645733]\n",
      "epoch:6 step:5459 [D loss: 0.591521, acc: 71.09%] [G loss: 1.533325]\n",
      "epoch:6 step:5460 [D loss: 0.637697, acc: 68.75%] [G loss: 1.621169]\n",
      "epoch:6 step:5461 [D loss: 0.746678, acc: 45.31%] [G loss: 1.416089]\n",
      "epoch:6 step:5462 [D loss: 0.598511, acc: 71.88%] [G loss: 1.509402]\n",
      "epoch:6 step:5463 [D loss: 0.754831, acc: 43.75%] [G loss: 1.567755]\n",
      "epoch:6 step:5464 [D loss: 0.665327, acc: 60.16%] [G loss: 1.572179]\n",
      "epoch:6 step:5465 [D loss: 0.957474, acc: 22.66%] [G loss: 1.309295]\n",
      "epoch:6 step:5466 [D loss: 0.960709, acc: 23.44%] [G loss: 1.114436]\n",
      "epoch:6 step:5467 [D loss: 0.742032, acc: 41.41%] [G loss: 1.538225]\n",
      "epoch:7 step:5468 [D loss: 0.685539, acc: 60.94%] [G loss: 1.663762]\n",
      "epoch:7 step:5469 [D loss: 0.711108, acc: 49.22%] [G loss: 1.485865]\n",
      "epoch:7 step:5470 [D loss: 0.699520, acc: 53.91%] [G loss: 1.437728]\n",
      "epoch:7 step:5471 [D loss: 0.594337, acc: 64.84%] [G loss: 1.531657]\n",
      "epoch:7 step:5472 [D loss: 0.720378, acc: 46.88%] [G loss: 1.326763]\n",
      "epoch:7 step:5473 [D loss: 0.643512, acc: 67.97%] [G loss: 1.546839]\n",
      "epoch:7 step:5474 [D loss: 0.740411, acc: 47.66%] [G loss: 1.541438]\n",
      "epoch:7 step:5475 [D loss: 0.688487, acc: 53.91%] [G loss: 1.595664]\n",
      "epoch:7 step:5476 [D loss: 0.902605, acc: 22.66%] [G loss: 1.510926]\n",
      "epoch:7 step:5477 [D loss: 0.618405, acc: 65.62%] [G loss: 1.630154]\n",
      "epoch:7 step:5478 [D loss: 0.595282, acc: 75.00%] [G loss: 1.645599]\n",
      "epoch:7 step:5479 [D loss: 0.737814, acc: 50.00%] [G loss: 1.487930]\n",
      "epoch:7 step:5480 [D loss: 0.682156, acc: 53.12%] [G loss: 1.614292]\n",
      "epoch:7 step:5481 [D loss: 0.617166, acc: 71.09%] [G loss: 1.593854]\n",
      "epoch:7 step:5482 [D loss: 0.656116, acc: 67.19%] [G loss: 1.534653]\n",
      "epoch:7 step:5483 [D loss: 0.574255, acc: 72.66%] [G loss: 1.683457]\n",
      "epoch:7 step:5484 [D loss: 0.499265, acc: 84.38%] [G loss: 1.573977]\n",
      "epoch:7 step:5485 [D loss: 0.563497, acc: 75.00%] [G loss: 1.551225]\n",
      "epoch:7 step:5486 [D loss: 0.556461, acc: 80.47%] [G loss: 1.535932]\n",
      "epoch:7 step:5487 [D loss: 0.491215, acc: 89.06%] [G loss: 1.650226]\n",
      "epoch:7 step:5488 [D loss: 0.626774, acc: 69.53%] [G loss: 1.456363]\n",
      "epoch:7 step:5489 [D loss: 0.475655, acc: 94.53%] [G loss: 1.456660]\n",
      "epoch:7 step:5490 [D loss: 0.645808, acc: 60.94%] [G loss: 1.239410]\n",
      "epoch:7 step:5491 [D loss: 0.504122, acc: 89.84%] [G loss: 1.552503]\n",
      "epoch:7 step:5492 [D loss: 0.401615, acc: 94.53%] [G loss: 1.863047]\n",
      "epoch:7 step:5493 [D loss: 0.565081, acc: 67.19%] [G loss: 1.668622]\n",
      "epoch:7 step:5494 [D loss: 0.725154, acc: 51.56%] [G loss: 1.500906]\n",
      "epoch:7 step:5495 [D loss: 0.478627, acc: 74.22%] [G loss: 1.287777]\n",
      "epoch:7 step:5496 [D loss: 0.493531, acc: 82.03%] [G loss: 1.467392]\n",
      "epoch:7 step:5497 [D loss: 0.811942, acc: 50.00%] [G loss: 1.705992]\n",
      "epoch:7 step:5498 [D loss: 0.918198, acc: 31.25%] [G loss: 1.473777]\n",
      "epoch:7 step:5499 [D loss: 0.588192, acc: 69.53%] [G loss: 1.450272]\n",
      "epoch:7 step:5500 [D loss: 0.484655, acc: 79.69%] [G loss: 1.579499]\n",
      "epoch:7 step:5501 [D loss: 0.763213, acc: 41.41%] [G loss: 1.563541]\n",
      "epoch:7 step:5502 [D loss: 0.975561, acc: 18.75%] [G loss: 1.313967]\n",
      "epoch:7 step:5503 [D loss: 0.698073, acc: 60.16%] [G loss: 1.397634]\n",
      "epoch:7 step:5504 [D loss: 0.630520, acc: 67.19%] [G loss: 1.596399]\n",
      "epoch:7 step:5505 [D loss: 0.670348, acc: 56.25%] [G loss: 1.693846]\n",
      "epoch:7 step:5506 [D loss: 0.548600, acc: 79.69%] [G loss: 1.587519]\n",
      "epoch:7 step:5507 [D loss: 0.401353, acc: 92.19%] [G loss: 1.649715]\n",
      "epoch:7 step:5508 [D loss: 0.881397, acc: 32.81%] [G loss: 1.558336]\n",
      "epoch:7 step:5509 [D loss: 0.583041, acc: 71.88%] [G loss: 1.790538]\n",
      "epoch:7 step:5510 [D loss: 0.787749, acc: 39.06%] [G loss: 1.569673]\n",
      "epoch:7 step:5511 [D loss: 0.846201, acc: 26.56%] [G loss: 1.318993]\n",
      "epoch:7 step:5512 [D loss: 0.665041, acc: 61.72%] [G loss: 1.650859]\n",
      "epoch:7 step:5513 [D loss: 0.691555, acc: 53.12%] [G loss: 1.766211]\n",
      "epoch:7 step:5514 [D loss: 0.561583, acc: 73.44%] [G loss: 1.492084]\n",
      "epoch:7 step:5515 [D loss: 0.735889, acc: 48.44%] [G loss: 1.837349]\n",
      "epoch:7 step:5516 [D loss: 0.789213, acc: 47.66%] [G loss: 1.702189]\n",
      "epoch:7 step:5517 [D loss: 0.924639, acc: 27.34%] [G loss: 1.653352]\n",
      "epoch:7 step:5518 [D loss: 0.641351, acc: 67.19%] [G loss: 1.727967]\n",
      "epoch:7 step:5519 [D loss: 0.746242, acc: 45.31%] [G loss: 1.487660]\n",
      "epoch:7 step:5520 [D loss: 0.680797, acc: 53.12%] [G loss: 1.798745]\n",
      "epoch:7 step:5521 [D loss: 0.719064, acc: 51.56%] [G loss: 1.700997]\n",
      "epoch:7 step:5522 [D loss: 0.677110, acc: 59.38%] [G loss: 1.641907]\n",
      "epoch:7 step:5523 [D loss: 1.066352, acc: 10.94%] [G loss: 1.493737]\n",
      "epoch:7 step:5524 [D loss: 0.698865, acc: 51.56%] [G loss: 1.534288]\n",
      "epoch:7 step:5525 [D loss: 0.668198, acc: 64.06%] [G loss: 1.545199]\n",
      "epoch:7 step:5526 [D loss: 0.609500, acc: 69.53%] [G loss: 1.740832]\n",
      "epoch:7 step:5527 [D loss: 0.533599, acc: 76.56%] [G loss: 1.771463]\n",
      "epoch:7 step:5528 [D loss: 0.486312, acc: 75.00%] [G loss: 1.502367]\n",
      "epoch:7 step:5529 [D loss: 0.727342, acc: 48.44%] [G loss: 1.512016]\n",
      "epoch:7 step:5530 [D loss: 0.527061, acc: 79.69%] [G loss: 1.520504]\n",
      "epoch:7 step:5531 [D loss: 0.476487, acc: 85.94%] [G loss: 1.600400]\n",
      "epoch:7 step:5532 [D loss: 0.470412, acc: 88.28%] [G loss: 1.732713]\n",
      "epoch:7 step:5533 [D loss: 0.672474, acc: 58.59%] [G loss: 1.582721]\n",
      "epoch:7 step:5534 [D loss: 0.673528, acc: 57.81%] [G loss: 1.223881]\n",
      "epoch:7 step:5535 [D loss: 0.435497, acc: 82.03%] [G loss: 1.398611]\n",
      "epoch:7 step:5536 [D loss: 0.778782, acc: 51.56%] [G loss: 1.410417]\n",
      "epoch:7 step:5537 [D loss: 0.758503, acc: 46.88%] [G loss: 1.412887]\n",
      "epoch:7 step:5538 [D loss: 0.586200, acc: 68.75%] [G loss: 1.459472]\n",
      "epoch:7 step:5539 [D loss: 0.738175, acc: 44.53%] [G loss: 1.177433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5540 [D loss: 0.697364, acc: 57.03%] [G loss: 1.361660]\n",
      "epoch:7 step:5541 [D loss: 0.640772, acc: 64.06%] [G loss: 1.362370]\n",
      "epoch:7 step:5542 [D loss: 0.837447, acc: 33.59%] [G loss: 1.422596]\n",
      "epoch:7 step:5543 [D loss: 0.724385, acc: 51.56%] [G loss: 1.398817]\n",
      "epoch:7 step:5544 [D loss: 0.691648, acc: 60.94%] [G loss: 1.720103]\n",
      "epoch:7 step:5545 [D loss: 0.446792, acc: 89.84%] [G loss: 1.812821]\n",
      "epoch:7 step:5546 [D loss: 0.688107, acc: 59.38%] [G loss: 1.738884]\n",
      "epoch:7 step:5547 [D loss: 0.604703, acc: 70.31%] [G loss: 2.050571]\n",
      "epoch:7 step:5548 [D loss: 0.806972, acc: 39.06%] [G loss: 1.513258]\n",
      "epoch:7 step:5549 [D loss: 0.707722, acc: 53.12%] [G loss: 1.826656]\n",
      "epoch:7 step:5550 [D loss: 0.749467, acc: 44.53%] [G loss: 1.605767]\n",
      "epoch:7 step:5551 [D loss: 0.699527, acc: 53.91%] [G loss: 1.680511]\n",
      "epoch:7 step:5552 [D loss: 0.481773, acc: 89.06%] [G loss: 1.809651]\n",
      "epoch:7 step:5553 [D loss: 0.691113, acc: 56.25%] [G loss: 1.728470]\n",
      "epoch:7 step:5554 [D loss: 0.680783, acc: 51.56%] [G loss: 1.733672]\n",
      "epoch:7 step:5555 [D loss: 0.903156, acc: 21.88%] [G loss: 1.603953]\n",
      "epoch:7 step:5556 [D loss: 0.727809, acc: 54.69%] [G loss: 1.730776]\n",
      "epoch:7 step:5557 [D loss: 0.830544, acc: 32.03%] [G loss: 1.432804]\n",
      "epoch:7 step:5558 [D loss: 0.568323, acc: 75.00%] [G loss: 1.602898]\n",
      "epoch:7 step:5559 [D loss: 0.579175, acc: 71.09%] [G loss: 1.834119]\n",
      "epoch:7 step:5560 [D loss: 0.656609, acc: 61.72%] [G loss: 1.722971]\n",
      "epoch:7 step:5561 [D loss: 0.678972, acc: 57.03%] [G loss: 1.769047]\n",
      "epoch:7 step:5562 [D loss: 0.720558, acc: 53.91%] [G loss: 1.466564]\n",
      "epoch:7 step:5563 [D loss: 0.581478, acc: 72.66%] [G loss: 1.627289]\n",
      "epoch:7 step:5564 [D loss: 0.716335, acc: 50.78%] [G loss: 1.531444]\n",
      "epoch:7 step:5565 [D loss: 0.758715, acc: 35.94%] [G loss: 1.393171]\n",
      "epoch:7 step:5566 [D loss: 0.822594, acc: 39.06%] [G loss: 1.357234]\n",
      "epoch:7 step:5567 [D loss: 0.720703, acc: 49.22%] [G loss: 1.368592]\n",
      "epoch:7 step:5568 [D loss: 0.638016, acc: 61.72%] [G loss: 1.456052]\n",
      "epoch:7 step:5569 [D loss: 0.434726, acc: 82.03%] [G loss: 1.652834]\n",
      "epoch:7 step:5570 [D loss: 0.833428, acc: 30.47%] [G loss: 1.097767]\n",
      "epoch:7 step:5571 [D loss: 0.731124, acc: 50.00%] [G loss: 1.660888]\n",
      "epoch:7 step:5572 [D loss: 0.662158, acc: 60.94%] [G loss: 1.496390]\n",
      "epoch:7 step:5573 [D loss: 0.636954, acc: 68.75%] [G loss: 1.565162]\n",
      "epoch:7 step:5574 [D loss: 0.816031, acc: 46.88%] [G loss: 1.351729]\n",
      "epoch:7 step:5575 [D loss: 0.742744, acc: 43.75%] [G loss: 1.508408]\n",
      "epoch:7 step:5576 [D loss: 0.763984, acc: 42.19%] [G loss: 1.474739]\n",
      "epoch:7 step:5577 [D loss: 0.548621, acc: 81.25%] [G loss: 1.687782]\n",
      "epoch:7 step:5578 [D loss: 0.907981, acc: 25.00%] [G loss: 1.444355]\n",
      "epoch:7 step:5579 [D loss: 0.692853, acc: 56.25%] [G loss: 1.687552]\n",
      "epoch:7 step:5580 [D loss: 0.657627, acc: 62.50%] [G loss: 1.586134]\n",
      "epoch:7 step:5581 [D loss: 0.735291, acc: 50.00%] [G loss: 1.452017]\n",
      "epoch:7 step:5582 [D loss: 0.721591, acc: 46.09%] [G loss: 1.560077]\n",
      "epoch:7 step:5583 [D loss: 0.726365, acc: 56.25%] [G loss: 1.518869]\n",
      "epoch:7 step:5584 [D loss: 0.523090, acc: 69.53%] [G loss: 1.691636]\n",
      "epoch:7 step:5585 [D loss: 0.623630, acc: 69.53%] [G loss: 1.507125]\n",
      "epoch:7 step:5586 [D loss: 0.594854, acc: 69.53%] [G loss: 1.568737]\n",
      "epoch:7 step:5587 [D loss: 0.750563, acc: 39.84%] [G loss: 1.476089]\n",
      "epoch:7 step:5588 [D loss: 0.685568, acc: 53.91%] [G loss: 1.530302]\n",
      "epoch:7 step:5589 [D loss: 0.722562, acc: 46.09%] [G loss: 1.779979]\n",
      "epoch:7 step:5590 [D loss: 0.546280, acc: 82.03%] [G loss: 1.632826]\n",
      "epoch:7 step:5591 [D loss: 0.629887, acc: 60.94%] [G loss: 1.783380]\n",
      "epoch:7 step:5592 [D loss: 0.748194, acc: 42.19%] [G loss: 1.425977]\n",
      "epoch:7 step:5593 [D loss: 0.780514, acc: 40.62%] [G loss: 1.357156]\n",
      "epoch:7 step:5594 [D loss: 0.816487, acc: 28.12%] [G loss: 1.383386]\n",
      "epoch:7 step:5595 [D loss: 0.538946, acc: 82.03%] [G loss: 1.587170]\n",
      "epoch:7 step:5596 [D loss: 0.639596, acc: 64.84%] [G loss: 1.635164]\n",
      "epoch:7 step:5597 [D loss: 0.795187, acc: 49.22%] [G loss: 1.249228]\n",
      "epoch:7 step:5598 [D loss: 0.648160, acc: 63.28%] [G loss: 1.541387]\n",
      "epoch:7 step:5599 [D loss: 0.602136, acc: 71.09%] [G loss: 1.633208]\n",
      "epoch:7 step:5600 [D loss: 0.751253, acc: 46.88%] [G loss: 1.519750]\n",
      "epoch:7 step:5601 [D loss: 0.816939, acc: 34.38%] [G loss: 1.705319]\n",
      "epoch:7 step:5602 [D loss: 0.605962, acc: 67.97%] [G loss: 1.655051]\n",
      "epoch:7 step:5603 [D loss: 0.631144, acc: 64.06%] [G loss: 1.588545]\n",
      "epoch:7 step:5604 [D loss: 0.641192, acc: 71.09%] [G loss: 1.654590]\n",
      "epoch:7 step:5605 [D loss: 0.868325, acc: 26.56%] [G loss: 1.615472]\n",
      "epoch:7 step:5606 [D loss: 0.630391, acc: 69.53%] [G loss: 1.745679]\n",
      "epoch:7 step:5607 [D loss: 0.699466, acc: 57.81%] [G loss: 1.590714]\n",
      "epoch:7 step:5608 [D loss: 0.638931, acc: 60.94%] [G loss: 1.599261]\n",
      "epoch:7 step:5609 [D loss: 0.780423, acc: 30.47%] [G loss: 1.630744]\n",
      "epoch:7 step:5610 [D loss: 0.630510, acc: 59.38%] [G loss: 1.493278]\n",
      "epoch:7 step:5611 [D loss: 0.496609, acc: 86.72%] [G loss: 1.755299]\n",
      "epoch:7 step:5612 [D loss: 0.584394, acc: 72.66%] [G loss: 1.624061]\n",
      "epoch:7 step:5613 [D loss: 0.643794, acc: 60.16%] [G loss: 1.634841]\n",
      "epoch:7 step:5614 [D loss: 0.593405, acc: 72.66%] [G loss: 1.524593]\n",
      "epoch:7 step:5615 [D loss: 0.541730, acc: 77.34%] [G loss: 1.695845]\n",
      "epoch:7 step:5616 [D loss: 0.709076, acc: 51.56%] [G loss: 1.598744]\n",
      "epoch:7 step:5617 [D loss: 0.644444, acc: 69.53%] [G loss: 1.493697]\n",
      "epoch:7 step:5618 [D loss: 0.681556, acc: 58.59%] [G loss: 1.467753]\n",
      "epoch:7 step:5619 [D loss: 0.758442, acc: 39.06%] [G loss: 1.622414]\n",
      "epoch:7 step:5620 [D loss: 0.750145, acc: 46.09%] [G loss: 1.404530]\n",
      "epoch:7 step:5621 [D loss: 0.800286, acc: 39.84%] [G loss: 1.638062]\n",
      "epoch:7 step:5622 [D loss: 0.650135, acc: 63.28%] [G loss: 1.557297]\n",
      "epoch:7 step:5623 [D loss: 0.622826, acc: 67.19%] [G loss: 1.503548]\n",
      "epoch:7 step:5624 [D loss: 0.472330, acc: 82.81%] [G loss: 1.613922]\n",
      "epoch:7 step:5625 [D loss: 0.736607, acc: 52.34%] [G loss: 1.332849]\n",
      "epoch:7 step:5626 [D loss: 0.763985, acc: 50.00%] [G loss: 1.793845]\n",
      "epoch:7 step:5627 [D loss: 0.973450, acc: 13.28%] [G loss: 1.201579]\n",
      "epoch:7 step:5628 [D loss: 0.699747, acc: 51.56%] [G loss: 1.791741]\n",
      "epoch:7 step:5629 [D loss: 0.345898, acc: 92.97%] [G loss: 1.709041]\n",
      "epoch:7 step:5630 [D loss: 0.506887, acc: 85.94%] [G loss: 1.592512]\n",
      "epoch:7 step:5631 [D loss: 0.310948, acc: 98.44%] [G loss: 1.886589]\n",
      "epoch:7 step:5632 [D loss: 0.416999, acc: 95.31%] [G loss: 1.690553]\n",
      "epoch:7 step:5633 [D loss: 1.191238, acc: 3.91%] [G loss: 1.302264]\n",
      "epoch:7 step:5634 [D loss: 0.710760, acc: 53.12%] [G loss: 1.605753]\n",
      "epoch:7 step:5635 [D loss: 0.620012, acc: 65.62%] [G loss: 1.678437]\n",
      "epoch:7 step:5636 [D loss: 0.659344, acc: 55.47%] [G loss: 1.384238]\n",
      "epoch:7 step:5637 [D loss: 0.750513, acc: 43.75%] [G loss: 1.710782]\n",
      "epoch:7 step:5638 [D loss: 0.696864, acc: 51.56%] [G loss: 1.838610]\n",
      "epoch:7 step:5639 [D loss: 0.658801, acc: 59.38%] [G loss: 1.597262]\n",
      "epoch:7 step:5640 [D loss: 0.847836, acc: 29.69%] [G loss: 1.239865]\n",
      "epoch:7 step:5641 [D loss: 0.711102, acc: 55.47%] [G loss: 1.743324]\n",
      "epoch:7 step:5642 [D loss: 0.646336, acc: 62.50%] [G loss: 1.719808]\n",
      "epoch:7 step:5643 [D loss: 0.630994, acc: 66.41%] [G loss: 1.581566]\n",
      "epoch:7 step:5644 [D loss: 0.641031, acc: 58.59%] [G loss: 1.613214]\n",
      "epoch:7 step:5645 [D loss: 0.728552, acc: 47.66%] [G loss: 1.345448]\n",
      "epoch:7 step:5646 [D loss: 0.526607, acc: 76.56%] [G loss: 1.460904]\n",
      "epoch:7 step:5647 [D loss: 0.505057, acc: 80.47%] [G loss: 1.631293]\n",
      "epoch:7 step:5648 [D loss: 0.565871, acc: 75.00%] [G loss: 1.613807]\n",
      "epoch:7 step:5649 [D loss: 0.646677, acc: 60.94%] [G loss: 1.571944]\n",
      "epoch:7 step:5650 [D loss: 0.756832, acc: 53.91%] [G loss: 1.609934]\n",
      "epoch:7 step:5651 [D loss: 0.664822, acc: 59.38%] [G loss: 1.527305]\n",
      "epoch:7 step:5652 [D loss: 0.683397, acc: 55.47%] [G loss: 1.364595]\n",
      "epoch:7 step:5653 [D loss: 0.440752, acc: 78.12%] [G loss: 1.572580]\n",
      "epoch:7 step:5654 [D loss: 0.506799, acc: 85.94%] [G loss: 1.719998]\n",
      "epoch:7 step:5655 [D loss: 0.697580, acc: 52.34%] [G loss: 1.574175]\n",
      "epoch:7 step:5656 [D loss: 0.743205, acc: 52.34%] [G loss: 1.566528]\n",
      "epoch:7 step:5657 [D loss: 0.669340, acc: 60.94%] [G loss: 1.592283]\n",
      "epoch:7 step:5658 [D loss: 0.589525, acc: 77.34%] [G loss: 1.582669]\n",
      "epoch:7 step:5659 [D loss: 0.562253, acc: 65.62%] [G loss: 1.495585]\n",
      "epoch:7 step:5660 [D loss: 0.449493, acc: 90.62%] [G loss: 1.726892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5661 [D loss: 0.842940, acc: 32.81%] [G loss: 1.435564]\n",
      "epoch:7 step:5662 [D loss: 0.888541, acc: 27.34%] [G loss: 1.253297]\n",
      "epoch:7 step:5663 [D loss: 1.093364, acc: 32.03%] [G loss: 0.892857]\n",
      "epoch:7 step:5664 [D loss: 0.601926, acc: 73.44%] [G loss: 1.769778]\n",
      "epoch:7 step:5665 [D loss: 0.713777, acc: 53.91%] [G loss: 1.704292]\n",
      "epoch:7 step:5666 [D loss: 0.611801, acc: 75.00%] [G loss: 1.549549]\n",
      "epoch:7 step:5667 [D loss: 0.691350, acc: 53.12%] [G loss: 1.655186]\n",
      "epoch:7 step:5668 [D loss: 0.759379, acc: 42.97%] [G loss: 1.479033]\n",
      "epoch:7 step:5669 [D loss: 1.062978, acc: 19.53%] [G loss: 1.349074]\n",
      "epoch:7 step:5670 [D loss: 0.651714, acc: 67.97%] [G loss: 1.807213]\n",
      "epoch:7 step:5671 [D loss: 0.650047, acc: 59.38%] [G loss: 1.571363]\n",
      "epoch:7 step:5672 [D loss: 1.167856, acc: 14.06%] [G loss: 1.236348]\n",
      "epoch:7 step:5673 [D loss: 0.600536, acc: 72.66%] [G loss: 1.694537]\n",
      "epoch:7 step:5674 [D loss: 0.645261, acc: 61.72%] [G loss: 1.580073]\n",
      "epoch:7 step:5675 [D loss: 0.663680, acc: 57.81%] [G loss: 1.606055]\n",
      "epoch:7 step:5676 [D loss: 0.718000, acc: 51.56%] [G loss: 1.307268]\n",
      "epoch:7 step:5677 [D loss: 0.836270, acc: 26.56%] [G loss: 1.219927]\n",
      "epoch:7 step:5678 [D loss: 0.664739, acc: 58.59%] [G loss: 1.623417]\n",
      "epoch:7 step:5679 [D loss: 0.519609, acc: 86.72%] [G loss: 1.795376]\n",
      "epoch:7 step:5680 [D loss: 0.399380, acc: 78.91%] [G loss: 1.538427]\n",
      "epoch:7 step:5681 [D loss: 0.506543, acc: 76.56%] [G loss: 1.382591]\n",
      "epoch:7 step:5682 [D loss: 0.716800, acc: 51.56%] [G loss: 1.377602]\n",
      "epoch:7 step:5683 [D loss: 0.721889, acc: 50.00%] [G loss: 1.276099]\n",
      "epoch:7 step:5684 [D loss: 0.435699, acc: 90.62%] [G loss: 1.568787]\n",
      "epoch:7 step:5685 [D loss: 0.739272, acc: 43.75%] [G loss: 1.198424]\n",
      "epoch:7 step:5686 [D loss: 0.631695, acc: 69.53%] [G loss: 1.328222]\n",
      "epoch:7 step:5687 [D loss: 0.800175, acc: 30.47%] [G loss: 1.337890]\n",
      "epoch:7 step:5688 [D loss: 0.784361, acc: 42.19%] [G loss: 1.472111]\n",
      "epoch:7 step:5689 [D loss: 0.749843, acc: 53.91%] [G loss: 1.304679]\n",
      "epoch:7 step:5690 [D loss: 0.691719, acc: 54.69%] [G loss: 1.477396]\n",
      "epoch:7 step:5691 [D loss: 0.439646, acc: 91.41%] [G loss: 1.598293]\n",
      "epoch:7 step:5692 [D loss: 0.727179, acc: 51.56%] [G loss: 1.317892]\n",
      "epoch:7 step:5693 [D loss: 0.813634, acc: 38.28%] [G loss: 1.029142]\n",
      "epoch:7 step:5694 [D loss: 0.678920, acc: 56.25%] [G loss: 1.739610]\n",
      "epoch:7 step:5695 [D loss: 0.738516, acc: 45.31%] [G loss: 1.432469]\n",
      "epoch:7 step:5696 [D loss: 0.894793, acc: 17.19%] [G loss: 1.251655]\n",
      "epoch:7 step:5697 [D loss: 0.910554, acc: 17.97%] [G loss: 1.375795]\n",
      "epoch:7 step:5698 [D loss: 0.700990, acc: 55.47%] [G loss: 1.601306]\n",
      "epoch:7 step:5699 [D loss: 0.765836, acc: 46.09%] [G loss: 1.597822]\n",
      "epoch:7 step:5700 [D loss: 0.676623, acc: 60.16%] [G loss: 1.547763]\n",
      "epoch:7 step:5701 [D loss: 0.821015, acc: 30.47%] [G loss: 1.568228]\n",
      "epoch:7 step:5702 [D loss: 0.713442, acc: 48.44%] [G loss: 1.823656]\n",
      "epoch:7 step:5703 [D loss: 0.822573, acc: 48.44%] [G loss: 1.544648]\n",
      "epoch:7 step:5704 [D loss: 0.687353, acc: 54.69%] [G loss: 1.763727]\n",
      "epoch:7 step:5705 [D loss: 0.563487, acc: 78.12%] [G loss: 1.711699]\n",
      "epoch:7 step:5706 [D loss: 0.576637, acc: 75.78%] [G loss: 1.654711]\n",
      "epoch:7 step:5707 [D loss: 0.611441, acc: 64.06%] [G loss: 1.489100]\n",
      "epoch:7 step:5708 [D loss: 0.478558, acc: 88.28%] [G loss: 1.715878]\n",
      "epoch:7 step:5709 [D loss: 0.514751, acc: 82.81%] [G loss: 1.389886]\n",
      "epoch:7 step:5710 [D loss: 0.700985, acc: 55.47%] [G loss: 1.531525]\n",
      "epoch:7 step:5711 [D loss: 0.395497, acc: 95.31%] [G loss: 1.856068]\n",
      "epoch:7 step:5712 [D loss: 0.633255, acc: 63.28%] [G loss: 1.434228]\n",
      "epoch:7 step:5713 [D loss: 0.427953, acc: 89.84%] [G loss: 1.594210]\n",
      "epoch:7 step:5714 [D loss: 0.727421, acc: 53.91%] [G loss: 1.492682]\n",
      "epoch:7 step:5715 [D loss: 0.785791, acc: 46.88%] [G loss: 1.214913]\n",
      "epoch:7 step:5716 [D loss: 0.564087, acc: 78.91%] [G loss: 1.459245]\n",
      "epoch:7 step:5717 [D loss: 0.609465, acc: 61.72%] [G loss: 1.333588]\n",
      "epoch:7 step:5718 [D loss: 0.861050, acc: 35.94%] [G loss: 1.407333]\n",
      "epoch:7 step:5719 [D loss: 0.624174, acc: 65.62%] [G loss: 1.472569]\n",
      "epoch:7 step:5720 [D loss: 0.980559, acc: 17.97%] [G loss: 1.227110]\n",
      "epoch:7 step:5721 [D loss: 0.896246, acc: 30.47%] [G loss: 1.084806]\n",
      "epoch:7 step:5722 [D loss: 0.699617, acc: 52.34%] [G loss: 1.242228]\n",
      "epoch:7 step:5723 [D loss: 0.603363, acc: 71.09%] [G loss: 1.480870]\n",
      "epoch:7 step:5724 [D loss: 0.837678, acc: 24.22%] [G loss: 1.162047]\n",
      "epoch:7 step:5725 [D loss: 0.673561, acc: 55.47%] [G loss: 1.499912]\n",
      "epoch:7 step:5726 [D loss: 0.815119, acc: 34.38%] [G loss: 1.320950]\n",
      "epoch:7 step:5727 [D loss: 0.603822, acc: 72.66%] [G loss: 1.763941]\n",
      "epoch:7 step:5728 [D loss: 0.537271, acc: 72.66%] [G loss: 1.911053]\n",
      "epoch:7 step:5729 [D loss: 0.553037, acc: 76.56%] [G loss: 1.650726]\n",
      "epoch:7 step:5730 [D loss: 1.001942, acc: 25.78%] [G loss: 1.116788]\n",
      "epoch:7 step:5731 [D loss: 0.594315, acc: 69.53%] [G loss: 1.516742]\n",
      "epoch:7 step:5732 [D loss: 0.697751, acc: 50.00%] [G loss: 1.440867]\n",
      "epoch:7 step:5733 [D loss: 0.764073, acc: 39.84%] [G loss: 1.279629]\n",
      "epoch:7 step:5734 [D loss: 0.911716, acc: 33.59%] [G loss: 1.318212]\n",
      "epoch:7 step:5735 [D loss: 0.610346, acc: 74.22%] [G loss: 1.435654]\n",
      "epoch:7 step:5736 [D loss: 0.644847, acc: 65.62%] [G loss: 1.414011]\n",
      "epoch:7 step:5737 [D loss: 0.803798, acc: 42.97%] [G loss: 1.416554]\n",
      "epoch:7 step:5738 [D loss: 0.704899, acc: 48.44%] [G loss: 1.476679]\n",
      "epoch:7 step:5739 [D loss: 0.745996, acc: 46.88%] [G loss: 1.477673]\n",
      "epoch:7 step:5740 [D loss: 0.703032, acc: 54.69%] [G loss: 1.525802]\n",
      "epoch:7 step:5741 [D loss: 0.634851, acc: 62.50%] [G loss: 1.480331]\n",
      "epoch:7 step:5742 [D loss: 0.748055, acc: 39.84%] [G loss: 1.373732]\n",
      "epoch:7 step:5743 [D loss: 0.753815, acc: 37.50%] [G loss: 1.371023]\n",
      "epoch:7 step:5744 [D loss: 0.929667, acc: 28.12%] [G loss: 1.240814]\n",
      "epoch:7 step:5745 [D loss: 0.681628, acc: 53.12%] [G loss: 1.436877]\n",
      "epoch:7 step:5746 [D loss: 0.672372, acc: 60.94%] [G loss: 1.419723]\n",
      "epoch:7 step:5747 [D loss: 0.595085, acc: 75.00%] [G loss: 1.534814]\n",
      "epoch:7 step:5748 [D loss: 0.732714, acc: 48.44%] [G loss: 1.636961]\n",
      "epoch:7 step:5749 [D loss: 0.838263, acc: 24.22%] [G loss: 1.416139]\n",
      "epoch:7 step:5750 [D loss: 0.689659, acc: 49.22%] [G loss: 1.512983]\n",
      "epoch:7 step:5751 [D loss: 0.596534, acc: 74.22%] [G loss: 1.485010]\n",
      "epoch:7 step:5752 [D loss: 0.439128, acc: 89.06%] [G loss: 1.813257]\n",
      "epoch:7 step:5753 [D loss: 0.768756, acc: 44.53%] [G loss: 1.550397]\n",
      "epoch:7 step:5754 [D loss: 0.682531, acc: 53.12%] [G loss: 1.496188]\n",
      "epoch:7 step:5755 [D loss: 0.673868, acc: 60.94%] [G loss: 1.389200]\n",
      "epoch:7 step:5756 [D loss: 0.763293, acc: 39.84%] [G loss: 1.507910]\n",
      "epoch:7 step:5757 [D loss: 0.604794, acc: 77.34%] [G loss: 1.578240]\n",
      "epoch:7 step:5758 [D loss: 0.733222, acc: 45.31%] [G loss: 1.456677]\n",
      "epoch:7 step:5759 [D loss: 0.675373, acc: 60.16%] [G loss: 1.493739]\n",
      "epoch:7 step:5760 [D loss: 0.609368, acc: 74.22%] [G loss: 1.510312]\n",
      "epoch:7 step:5761 [D loss: 0.623144, acc: 66.41%] [G loss: 1.662938]\n",
      "epoch:7 step:5762 [D loss: 0.574322, acc: 75.78%] [G loss: 1.753332]\n",
      "epoch:7 step:5763 [D loss: 0.681289, acc: 59.38%] [G loss: 1.652270]\n",
      "epoch:7 step:5764 [D loss: 0.681055, acc: 55.47%] [G loss: 1.683537]\n",
      "epoch:7 step:5765 [D loss: 0.769438, acc: 40.62%] [G loss: 1.544599]\n",
      "epoch:7 step:5766 [D loss: 0.703382, acc: 51.56%] [G loss: 1.660278]\n",
      "epoch:7 step:5767 [D loss: 0.798077, acc: 37.50%] [G loss: 1.492083]\n",
      "epoch:7 step:5768 [D loss: 0.792042, acc: 32.81%] [G loss: 1.568806]\n",
      "epoch:7 step:5769 [D loss: 0.583979, acc: 75.78%] [G loss: 1.678696]\n",
      "epoch:7 step:5770 [D loss: 0.751471, acc: 41.41%] [G loss: 1.547314]\n",
      "epoch:7 step:5771 [D loss: 0.688883, acc: 53.91%] [G loss: 1.563071]\n",
      "epoch:7 step:5772 [D loss: 0.757119, acc: 37.50%] [G loss: 1.676409]\n",
      "epoch:7 step:5773 [D loss: 0.714476, acc: 50.78%] [G loss: 1.563805]\n",
      "epoch:7 step:5774 [D loss: 0.797938, acc: 32.81%] [G loss: 1.450104]\n",
      "epoch:7 step:5775 [D loss: 0.514709, acc: 82.03%] [G loss: 1.628477]\n",
      "epoch:7 step:5776 [D loss: 0.654534, acc: 62.50%] [G loss: 1.597898]\n",
      "epoch:7 step:5777 [D loss: 0.813260, acc: 31.25%] [G loss: 1.494303]\n",
      "epoch:7 step:5778 [D loss: 0.703540, acc: 52.34%] [G loss: 1.493954]\n",
      "epoch:7 step:5779 [D loss: 0.664203, acc: 60.16%] [G loss: 1.708928]\n",
      "epoch:7 step:5780 [D loss: 0.543030, acc: 77.34%] [G loss: 1.612272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5781 [D loss: 0.693745, acc: 57.81%] [G loss: 1.511410]\n",
      "epoch:7 step:5782 [D loss: 1.006758, acc: 19.53%] [G loss: 1.324360]\n",
      "epoch:7 step:5783 [D loss: 0.725429, acc: 47.66%] [G loss: 1.597142]\n",
      "epoch:7 step:5784 [D loss: 0.940288, acc: 16.41%] [G loss: 1.529498]\n",
      "epoch:7 step:5785 [D loss: 0.750382, acc: 45.31%] [G loss: 1.668436]\n",
      "epoch:7 step:5786 [D loss: 0.769095, acc: 38.28%] [G loss: 1.381645]\n",
      "epoch:7 step:5787 [D loss: 0.696195, acc: 55.47%] [G loss: 1.507557]\n",
      "epoch:7 step:5788 [D loss: 0.548855, acc: 74.22%] [G loss: 1.746677]\n",
      "epoch:7 step:5789 [D loss: 0.554627, acc: 69.53%] [G loss: 1.472163]\n",
      "epoch:7 step:5790 [D loss: 0.682448, acc: 55.47%] [G loss: 1.629033]\n",
      "epoch:7 step:5791 [D loss: 0.646677, acc: 64.06%] [G loss: 1.469094]\n",
      "epoch:7 step:5792 [D loss: 0.514919, acc: 91.41%] [G loss: 1.619179]\n",
      "epoch:7 step:5793 [D loss: 0.538583, acc: 85.94%] [G loss: 1.633395]\n",
      "epoch:7 step:5794 [D loss: 0.653529, acc: 68.75%] [G loss: 1.489674]\n",
      "epoch:7 step:5795 [D loss: 0.824027, acc: 35.94%] [G loss: 1.437468]\n",
      "epoch:7 step:5796 [D loss: 0.793799, acc: 38.28%] [G loss: 1.536488]\n",
      "epoch:7 step:5797 [D loss: 0.904878, acc: 23.44%] [G loss: 1.586238]\n",
      "epoch:7 step:5798 [D loss: 0.760997, acc: 42.19%] [G loss: 1.431695]\n",
      "epoch:7 step:5799 [D loss: 0.595153, acc: 71.09%] [G loss: 1.759867]\n",
      "epoch:7 step:5800 [D loss: 0.726304, acc: 44.53%] [G loss: 1.655000]\n",
      "epoch:7 step:5801 [D loss: 0.873841, acc: 31.25%] [G loss: 1.725326]\n",
      "epoch:7 step:5802 [D loss: 0.473064, acc: 83.59%] [G loss: 1.764072]\n",
      "epoch:7 step:5803 [D loss: 0.787241, acc: 42.19%] [G loss: 1.698541]\n",
      "epoch:7 step:5804 [D loss: 0.751549, acc: 43.75%] [G loss: 1.603078]\n",
      "epoch:7 step:5805 [D loss: 0.921551, acc: 23.44%] [G loss: 1.685508]\n",
      "epoch:7 step:5806 [D loss: 0.772836, acc: 41.41%] [G loss: 1.496360]\n",
      "epoch:7 step:5807 [D loss: 0.757152, acc: 49.22%] [G loss: 1.590091]\n",
      "epoch:7 step:5808 [D loss: 0.548431, acc: 74.22%] [G loss: 1.806215]\n",
      "epoch:7 step:5809 [D loss: 0.712403, acc: 47.66%] [G loss: 1.587545]\n",
      "epoch:7 step:5810 [D loss: 0.706628, acc: 57.03%] [G loss: 1.551451]\n",
      "epoch:7 step:5811 [D loss: 0.667841, acc: 60.94%] [G loss: 1.581989]\n",
      "epoch:7 step:5812 [D loss: 0.746904, acc: 47.66%] [G loss: 1.518132]\n",
      "epoch:7 step:5813 [D loss: 0.713258, acc: 46.09%] [G loss: 1.474003]\n",
      "epoch:7 step:5814 [D loss: 0.651031, acc: 64.06%] [G loss: 1.554215]\n",
      "epoch:7 step:5815 [D loss: 0.710232, acc: 50.78%] [G loss: 1.631138]\n",
      "epoch:7 step:5816 [D loss: 0.744021, acc: 39.84%] [G loss: 1.481881]\n",
      "epoch:7 step:5817 [D loss: 0.867762, acc: 31.25%] [G loss: 1.497405]\n",
      "epoch:7 step:5818 [D loss: 0.791033, acc: 38.28%] [G loss: 1.405473]\n",
      "epoch:7 step:5819 [D loss: 0.693608, acc: 53.12%] [G loss: 1.524945]\n",
      "epoch:7 step:5820 [D loss: 0.724320, acc: 48.44%] [G loss: 1.430738]\n",
      "epoch:7 step:5821 [D loss: 0.707966, acc: 50.00%] [G loss: 1.432131]\n",
      "epoch:7 step:5822 [D loss: 0.725537, acc: 46.09%] [G loss: 1.629418]\n",
      "epoch:7 step:5823 [D loss: 0.714316, acc: 47.66%] [G loss: 1.439453]\n",
      "epoch:7 step:5824 [D loss: 0.713491, acc: 49.22%] [G loss: 1.518565]\n",
      "epoch:7 step:5825 [D loss: 0.382474, acc: 77.34%] [G loss: 1.684408]\n",
      "epoch:7 step:5826 [D loss: 0.837749, acc: 25.00%] [G loss: 1.465585]\n",
      "epoch:7 step:5827 [D loss: 0.662732, acc: 57.81%] [G loss: 1.553286]\n",
      "epoch:7 step:5828 [D loss: 0.775140, acc: 39.06%] [G loss: 1.473265]\n",
      "epoch:7 step:5829 [D loss: 0.631554, acc: 66.41%] [G loss: 1.581214]\n",
      "epoch:7 step:5830 [D loss: 0.733123, acc: 49.22%] [G loss: 1.490785]\n",
      "epoch:7 step:5831 [D loss: 0.684166, acc: 56.25%] [G loss: 1.754166]\n",
      "epoch:7 step:5832 [D loss: 0.719372, acc: 46.09%] [G loss: 1.669718]\n",
      "epoch:7 step:5833 [D loss: 0.759212, acc: 37.50%] [G loss: 1.609810]\n",
      "epoch:7 step:5834 [D loss: 0.636569, acc: 61.72%] [G loss: 1.613545]\n",
      "epoch:7 step:5835 [D loss: 0.752864, acc: 39.84%] [G loss: 1.495714]\n",
      "epoch:7 step:5836 [D loss: 0.682307, acc: 50.00%] [G loss: 1.501781]\n",
      "epoch:7 step:5837 [D loss: 0.589875, acc: 76.56%] [G loss: 1.694947]\n",
      "epoch:7 step:5838 [D loss: 0.637809, acc: 70.31%] [G loss: 1.704559]\n",
      "epoch:7 step:5839 [D loss: 0.681083, acc: 54.69%] [G loss: 1.681718]\n",
      "epoch:7 step:5840 [D loss: 0.925238, acc: 28.91%] [G loss: 1.291929]\n",
      "epoch:7 step:5841 [D loss: 0.708960, acc: 47.66%] [G loss: 1.525648]\n",
      "epoch:7 step:5842 [D loss: 0.709850, acc: 47.66%] [G loss: 1.537866]\n",
      "epoch:7 step:5843 [D loss: 0.674949, acc: 56.25%] [G loss: 1.646924]\n",
      "epoch:7 step:5844 [D loss: 0.713141, acc: 50.78%] [G loss: 1.503247]\n",
      "epoch:7 step:5845 [D loss: 0.682446, acc: 60.16%] [G loss: 1.625673]\n",
      "epoch:7 step:5846 [D loss: 0.638614, acc: 67.97%] [G loss: 1.665943]\n",
      "epoch:7 step:5847 [D loss: 0.555573, acc: 74.22%] [G loss: 1.591176]\n",
      "epoch:7 step:5848 [D loss: 0.696666, acc: 50.78%] [G loss: 1.606830]\n",
      "epoch:7 step:5849 [D loss: 0.622937, acc: 66.41%] [G loss: 1.561987]\n",
      "epoch:7 step:5850 [D loss: 0.673715, acc: 60.16%] [G loss: 1.495109]\n",
      "epoch:7 step:5851 [D loss: 0.782165, acc: 35.94%] [G loss: 1.542912]\n",
      "epoch:7 step:5852 [D loss: 0.721283, acc: 44.53%] [G loss: 1.463810]\n",
      "epoch:7 step:5853 [D loss: 0.610544, acc: 74.22%] [G loss: 1.540217]\n",
      "epoch:7 step:5854 [D loss: 0.695391, acc: 55.47%] [G loss: 1.697377]\n",
      "epoch:7 step:5855 [D loss: 0.707852, acc: 54.69%] [G loss: 1.485057]\n",
      "epoch:7 step:5856 [D loss: 0.687856, acc: 56.25%] [G loss: 1.607818]\n",
      "epoch:7 step:5857 [D loss: 0.634023, acc: 62.50%] [G loss: 1.580352]\n",
      "epoch:7 step:5858 [D loss: 0.826088, acc: 27.34%] [G loss: 1.399577]\n",
      "epoch:7 step:5859 [D loss: 0.706853, acc: 54.69%] [G loss: 1.607130]\n",
      "epoch:7 step:5860 [D loss: 0.814602, acc: 28.12%] [G loss: 1.306079]\n",
      "epoch:7 step:5861 [D loss: 0.586796, acc: 72.66%] [G loss: 1.475837]\n",
      "epoch:7 step:5862 [D loss: 0.744564, acc: 45.31%] [G loss: 1.430738]\n",
      "epoch:7 step:5863 [D loss: 0.730399, acc: 46.09%] [G loss: 1.599947]\n",
      "epoch:7 step:5864 [D loss: 0.644165, acc: 62.50%] [G loss: 1.602983]\n",
      "epoch:7 step:5865 [D loss: 0.689941, acc: 54.69%] [G loss: 1.656562]\n",
      "epoch:7 step:5866 [D loss: 0.601368, acc: 72.66%] [G loss: 1.564716]\n",
      "epoch:7 step:5867 [D loss: 0.653734, acc: 65.62%] [G loss: 1.696712]\n",
      "epoch:7 step:5868 [D loss: 0.667977, acc: 60.16%] [G loss: 1.539519]\n",
      "epoch:7 step:5869 [D loss: 0.714257, acc: 49.22%] [G loss: 1.554976]\n",
      "epoch:7 step:5870 [D loss: 0.749625, acc: 45.31%] [G loss: 1.577820]\n",
      "epoch:7 step:5871 [D loss: 0.629169, acc: 72.66%] [G loss: 1.658722]\n",
      "epoch:7 step:5872 [D loss: 0.590073, acc: 75.00%] [G loss: 1.616054]\n",
      "epoch:7 step:5873 [D loss: 0.629199, acc: 65.62%] [G loss: 1.585328]\n",
      "epoch:7 step:5874 [D loss: 0.754487, acc: 43.75%] [G loss: 1.544803]\n",
      "epoch:7 step:5875 [D loss: 0.677531, acc: 54.69%] [G loss: 1.550606]\n",
      "epoch:7 step:5876 [D loss: 0.628887, acc: 70.31%] [G loss: 1.632475]\n",
      "epoch:7 step:5877 [D loss: 0.709841, acc: 50.00%] [G loss: 1.455398]\n",
      "epoch:7 step:5878 [D loss: 0.955601, acc: 21.88%] [G loss: 1.556221]\n",
      "epoch:7 step:5879 [D loss: 0.726821, acc: 47.66%] [G loss: 1.713422]\n",
      "epoch:7 step:5880 [D loss: 0.718425, acc: 52.34%] [G loss: 1.600654]\n",
      "epoch:7 step:5881 [D loss: 0.681273, acc: 57.03%] [G loss: 1.575316]\n",
      "epoch:7 step:5882 [D loss: 0.650981, acc: 64.06%] [G loss: 1.720913]\n",
      "epoch:7 step:5883 [D loss: 0.647534, acc: 58.59%] [G loss: 1.685288]\n",
      "epoch:7 step:5884 [D loss: 0.691321, acc: 57.03%] [G loss: 1.596450]\n",
      "epoch:7 step:5885 [D loss: 0.707584, acc: 53.12%] [G loss: 1.482064]\n",
      "epoch:7 step:5886 [D loss: 0.744956, acc: 39.84%] [G loss: 1.503555]\n",
      "epoch:7 step:5887 [D loss: 0.689301, acc: 57.81%] [G loss: 1.549985]\n",
      "epoch:7 step:5888 [D loss: 0.758937, acc: 43.75%] [G loss: 1.509753]\n",
      "epoch:7 step:5889 [D loss: 0.667691, acc: 57.81%] [G loss: 1.738792]\n",
      "epoch:7 step:5890 [D loss: 0.693444, acc: 54.69%] [G loss: 1.552182]\n",
      "epoch:7 step:5891 [D loss: 0.757735, acc: 49.22%] [G loss: 1.602507]\n",
      "epoch:7 step:5892 [D loss: 0.785334, acc: 37.50%] [G loss: 1.520560]\n",
      "epoch:7 step:5893 [D loss: 0.727660, acc: 42.97%] [G loss: 1.541686]\n",
      "epoch:7 step:5894 [D loss: 0.713727, acc: 47.66%] [G loss: 1.521658]\n",
      "epoch:7 step:5895 [D loss: 0.834540, acc: 25.00%] [G loss: 1.517961]\n",
      "epoch:7 step:5896 [D loss: 0.672289, acc: 60.16%] [G loss: 1.598519]\n",
      "epoch:7 step:5897 [D loss: 0.737877, acc: 42.97%] [G loss: 1.518013]\n",
      "epoch:7 step:5898 [D loss: 0.826421, acc: 24.22%] [G loss: 1.323177]\n",
      "epoch:7 step:5899 [D loss: 0.752181, acc: 46.88%] [G loss: 1.486415]\n",
      "epoch:7 step:5900 [D loss: 0.692786, acc: 53.12%] [G loss: 1.653238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5901 [D loss: 0.704080, acc: 51.56%] [G loss: 1.613973]\n",
      "epoch:7 step:5902 [D loss: 0.646376, acc: 54.69%] [G loss: 1.494728]\n",
      "epoch:7 step:5903 [D loss: 0.707330, acc: 49.22%] [G loss: 1.555789]\n",
      "epoch:7 step:5904 [D loss: 0.703826, acc: 50.00%] [G loss: 1.426253]\n",
      "epoch:7 step:5905 [D loss: 0.690340, acc: 52.34%] [G loss: 1.505703]\n",
      "epoch:7 step:5906 [D loss: 0.672473, acc: 58.59%] [G loss: 1.585618]\n",
      "epoch:7 step:5907 [D loss: 0.702239, acc: 47.66%] [G loss: 1.504219]\n",
      "epoch:7 step:5908 [D loss: 0.816582, acc: 29.69%] [G loss: 1.447198]\n",
      "epoch:7 step:5909 [D loss: 0.752354, acc: 44.53%] [G loss: 1.482258]\n",
      "epoch:7 step:5910 [D loss: 0.579026, acc: 75.00%] [G loss: 1.594794]\n",
      "epoch:7 step:5911 [D loss: 0.786254, acc: 39.84%] [G loss: 1.474675]\n",
      "epoch:7 step:5912 [D loss: 0.619729, acc: 67.97%] [G loss: 1.452518]\n",
      "epoch:7 step:5913 [D loss: 0.752455, acc: 46.09%] [G loss: 1.656963]\n",
      "epoch:7 step:5914 [D loss: 0.713070, acc: 49.22%] [G loss: 1.514068]\n",
      "epoch:7 step:5915 [D loss: 0.637116, acc: 70.31%] [G loss: 1.597434]\n",
      "epoch:7 step:5916 [D loss: 0.689195, acc: 55.47%] [G loss: 1.672074]\n",
      "epoch:7 step:5917 [D loss: 0.598319, acc: 68.75%] [G loss: 1.696461]\n",
      "epoch:7 step:5918 [D loss: 0.718961, acc: 46.88%] [G loss: 1.576219]\n",
      "epoch:7 step:5919 [D loss: 0.712416, acc: 47.66%] [G loss: 1.477488]\n",
      "epoch:7 step:5920 [D loss: 0.780764, acc: 46.88%] [G loss: 1.495687]\n",
      "epoch:7 step:5921 [D loss: 0.599368, acc: 75.78%] [G loss: 1.564958]\n",
      "epoch:7 step:5922 [D loss: 0.717879, acc: 47.66%] [G loss: 1.621659]\n",
      "epoch:7 step:5923 [D loss: 0.697590, acc: 53.12%] [G loss: 1.595232]\n",
      "epoch:7 step:5924 [D loss: 0.686481, acc: 56.25%] [G loss: 1.620203]\n",
      "epoch:7 step:5925 [D loss: 0.701800, acc: 51.56%] [G loss: 1.597724]\n",
      "epoch:7 step:5926 [D loss: 0.702674, acc: 49.22%] [G loss: 1.618592]\n",
      "epoch:7 step:5927 [D loss: 0.688159, acc: 56.25%] [G loss: 1.573311]\n",
      "epoch:7 step:5928 [D loss: 0.666930, acc: 60.94%] [G loss: 1.667325]\n",
      "epoch:7 step:5929 [D loss: 0.582528, acc: 75.78%] [G loss: 1.578097]\n",
      "epoch:7 step:5930 [D loss: 0.579230, acc: 74.22%] [G loss: 1.626470]\n",
      "epoch:7 step:5931 [D loss: 0.517805, acc: 82.81%] [G loss: 1.745176]\n",
      "epoch:7 step:5932 [D loss: 0.619146, acc: 71.09%] [G loss: 1.637274]\n",
      "epoch:7 step:5933 [D loss: 0.606145, acc: 73.44%] [G loss: 1.720172]\n",
      "epoch:7 step:5934 [D loss: 0.732802, acc: 44.53%] [G loss: 1.630271]\n",
      "epoch:7 step:5935 [D loss: 0.717722, acc: 50.78%] [G loss: 1.469843]\n",
      "epoch:7 step:5936 [D loss: 0.710123, acc: 46.88%] [G loss: 1.681879]\n",
      "epoch:7 step:5937 [D loss: 0.677122, acc: 66.41%] [G loss: 1.522148]\n",
      "epoch:7 step:5938 [D loss: 0.686132, acc: 56.25%] [G loss: 1.511679]\n",
      "epoch:7 step:5939 [D loss: 0.607430, acc: 70.31%] [G loss: 1.625040]\n",
      "epoch:7 step:5940 [D loss: 0.630427, acc: 67.19%] [G loss: 1.594882]\n",
      "epoch:7 step:5941 [D loss: 0.803160, acc: 41.41%] [G loss: 1.349206]\n",
      "epoch:7 step:5942 [D loss: 0.736420, acc: 50.78%] [G loss: 1.635849]\n",
      "epoch:7 step:5943 [D loss: 0.653085, acc: 57.81%] [G loss: 1.520314]\n",
      "epoch:7 step:5944 [D loss: 0.625937, acc: 64.84%] [G loss: 1.358631]\n",
      "epoch:7 step:5945 [D loss: 0.731143, acc: 43.75%] [G loss: 1.475425]\n",
      "epoch:7 step:5946 [D loss: 0.823968, acc: 32.03%] [G loss: 1.273517]\n",
      "epoch:7 step:5947 [D loss: 0.694139, acc: 50.00%] [G loss: 1.563673]\n",
      "epoch:7 step:5948 [D loss: 0.778345, acc: 38.28%] [G loss: 1.528475]\n",
      "epoch:7 step:5949 [D loss: 0.840377, acc: 33.59%] [G loss: 1.388819]\n",
      "epoch:7 step:5950 [D loss: 0.751648, acc: 40.62%] [G loss: 1.378370]\n",
      "epoch:7 step:5951 [D loss: 0.675658, acc: 58.59%] [G loss: 1.527947]\n",
      "epoch:7 step:5952 [D loss: 0.645541, acc: 67.19%] [G loss: 1.527199]\n",
      "epoch:7 step:5953 [D loss: 0.690042, acc: 55.47%] [G loss: 1.540636]\n",
      "epoch:7 step:5954 [D loss: 0.676338, acc: 56.25%] [G loss: 1.633261]\n",
      "epoch:7 step:5955 [D loss: 0.818597, acc: 33.59%] [G loss: 1.419775]\n",
      "epoch:7 step:5956 [D loss: 0.664430, acc: 59.38%] [G loss: 1.540796]\n",
      "epoch:7 step:5957 [D loss: 0.706915, acc: 58.59%] [G loss: 1.613885]\n",
      "epoch:7 step:5958 [D loss: 0.683313, acc: 57.81%] [G loss: 1.577658]\n",
      "epoch:7 step:5959 [D loss: 0.717430, acc: 50.78%] [G loss: 1.478860]\n",
      "epoch:7 step:5960 [D loss: 0.727172, acc: 49.22%] [G loss: 1.571648]\n",
      "epoch:7 step:5961 [D loss: 0.827899, acc: 29.69%] [G loss: 1.369472]\n",
      "epoch:7 step:5962 [D loss: 0.643439, acc: 64.06%] [G loss: 1.507701]\n",
      "epoch:7 step:5963 [D loss: 0.684376, acc: 55.47%] [G loss: 1.489651]\n",
      "epoch:7 step:5964 [D loss: 0.707711, acc: 50.78%] [G loss: 1.627336]\n",
      "epoch:7 step:5965 [D loss: 0.720688, acc: 46.88%] [G loss: 1.610074]\n",
      "epoch:7 step:5966 [D loss: 0.825475, acc: 30.47%] [G loss: 1.514052]\n",
      "epoch:7 step:5967 [D loss: 0.834301, acc: 30.47%] [G loss: 1.388236]\n",
      "epoch:7 step:5968 [D loss: 0.590861, acc: 78.91%] [G loss: 1.532289]\n",
      "epoch:7 step:5969 [D loss: 0.560775, acc: 75.00%] [G loss: 1.476312]\n",
      "epoch:7 step:5970 [D loss: 0.632427, acc: 70.31%] [G loss: 1.625262]\n",
      "epoch:7 step:5971 [D loss: 0.763473, acc: 46.09%] [G loss: 1.521376]\n",
      "epoch:7 step:5972 [D loss: 0.848844, acc: 26.56%] [G loss: 1.368825]\n",
      "epoch:7 step:5973 [D loss: 0.673124, acc: 59.38%] [G loss: 1.610670]\n",
      "epoch:7 step:5974 [D loss: 0.748256, acc: 40.62%] [G loss: 1.575605]\n",
      "epoch:7 step:5975 [D loss: 0.595408, acc: 76.56%] [G loss: 1.673301]\n",
      "epoch:7 step:5976 [D loss: 0.635318, acc: 67.97%] [G loss: 1.699752]\n",
      "epoch:7 step:5977 [D loss: 0.729152, acc: 42.19%] [G loss: 1.580359]\n",
      "epoch:7 step:5978 [D loss: 0.751972, acc: 48.44%] [G loss: 1.519267]\n",
      "epoch:7 step:5979 [D loss: 0.551116, acc: 70.31%] [G loss: 1.573647]\n",
      "epoch:7 step:5980 [D loss: 0.699513, acc: 50.00%] [G loss: 1.619789]\n",
      "epoch:7 step:5981 [D loss: 0.653988, acc: 62.50%] [G loss: 1.668828]\n",
      "epoch:7 step:5982 [D loss: 0.698494, acc: 55.47%] [G loss: 1.547571]\n",
      "epoch:7 step:5983 [D loss: 0.673036, acc: 63.28%] [G loss: 1.530821]\n",
      "epoch:7 step:5984 [D loss: 0.672440, acc: 54.69%] [G loss: 1.551955]\n",
      "epoch:7 step:5985 [D loss: 0.808219, acc: 31.25%] [G loss: 1.395018]\n",
      "epoch:7 step:5986 [D loss: 0.677567, acc: 53.91%] [G loss: 1.373505]\n",
      "epoch:7 step:5987 [D loss: 0.503752, acc: 89.84%] [G loss: 1.630539]\n",
      "epoch:7 step:5988 [D loss: 0.716325, acc: 50.78%] [G loss: 1.577209]\n",
      "epoch:7 step:5989 [D loss: 0.700507, acc: 48.44%] [G loss: 1.519138]\n",
      "epoch:7 step:5990 [D loss: 0.630980, acc: 65.62%] [G loss: 1.541668]\n",
      "epoch:7 step:5991 [D loss: 0.745862, acc: 46.88%] [G loss: 1.641468]\n",
      "epoch:7 step:5992 [D loss: 0.775272, acc: 35.16%] [G loss: 1.487740]\n",
      "epoch:7 step:5993 [D loss: 0.820495, acc: 32.03%] [G loss: 1.404250]\n",
      "epoch:7 step:5994 [D loss: 0.603315, acc: 72.66%] [G loss: 1.582551]\n",
      "epoch:7 step:5995 [D loss: 0.760911, acc: 42.19%] [G loss: 1.582310]\n",
      "epoch:7 step:5996 [D loss: 0.573928, acc: 77.34%] [G loss: 1.683267]\n",
      "epoch:7 step:5997 [D loss: 0.713816, acc: 51.56%] [G loss: 1.517613]\n",
      "epoch:7 step:5998 [D loss: 0.696883, acc: 54.69%] [G loss: 1.479053]\n",
      "epoch:7 step:5999 [D loss: 0.693086, acc: 55.47%] [G loss: 1.670440]\n",
      "epoch:7 step:6000 [D loss: 0.710898, acc: 44.53%] [G loss: 1.508273]\n",
      "epoch:7 step:6001 [D loss: 0.761239, acc: 41.41%] [G loss: 1.581598]\n",
      "epoch:7 step:6002 [D loss: 0.709068, acc: 51.56%] [G loss: 1.557606]\n",
      "epoch:7 step:6003 [D loss: 0.729398, acc: 43.75%] [G loss: 1.554693]\n",
      "epoch:7 step:6004 [D loss: 0.803621, acc: 29.69%] [G loss: 1.585593]\n",
      "epoch:7 step:6005 [D loss: 0.728470, acc: 43.75%] [G loss: 1.586302]\n",
      "epoch:7 step:6006 [D loss: 0.669602, acc: 55.47%] [G loss: 1.557835]\n",
      "epoch:7 step:6007 [D loss: 0.674590, acc: 60.16%] [G loss: 1.613787]\n",
      "epoch:7 step:6008 [D loss: 0.569465, acc: 79.69%] [G loss: 1.615364]\n",
      "epoch:7 step:6009 [D loss: 0.801724, acc: 35.94%] [G loss: 1.474339]\n",
      "epoch:7 step:6010 [D loss: 0.689663, acc: 51.56%] [G loss: 1.483272]\n",
      "epoch:7 step:6011 [D loss: 0.678664, acc: 62.50%] [G loss: 1.608155]\n",
      "epoch:7 step:6012 [D loss: 0.702659, acc: 52.34%] [G loss: 1.707797]\n",
      "epoch:7 step:6013 [D loss: 0.738033, acc: 53.12%] [G loss: 1.596249]\n",
      "epoch:7 step:6014 [D loss: 0.734272, acc: 49.22%] [G loss: 1.524258]\n",
      "epoch:7 step:6015 [D loss: 0.700265, acc: 53.12%] [G loss: 1.657782]\n",
      "epoch:7 step:6016 [D loss: 0.535312, acc: 81.25%] [G loss: 1.623714]\n",
      "epoch:7 step:6017 [D loss: 0.674643, acc: 59.38%] [G loss: 1.509333]\n",
      "epoch:7 step:6018 [D loss: 0.604318, acc: 77.34%] [G loss: 1.551271]\n",
      "epoch:7 step:6019 [D loss: 0.645565, acc: 68.75%] [G loss: 1.487573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6020 [D loss: 0.731793, acc: 49.22%] [G loss: 1.438725]\n",
      "epoch:7 step:6021 [D loss: 0.705971, acc: 57.03%] [G loss: 1.574551]\n",
      "epoch:7 step:6022 [D loss: 0.680387, acc: 61.72%] [G loss: 1.425714]\n",
      "epoch:7 step:6023 [D loss: 0.661385, acc: 58.59%] [G loss: 1.659208]\n",
      "epoch:7 step:6024 [D loss: 0.722163, acc: 53.12%] [G loss: 1.591212]\n",
      "epoch:7 step:6025 [D loss: 0.713360, acc: 49.22%] [G loss: 1.427980]\n",
      "epoch:7 step:6026 [D loss: 0.595458, acc: 74.22%] [G loss: 1.565885]\n",
      "epoch:7 step:6027 [D loss: 0.708100, acc: 54.69%] [G loss: 1.470109]\n",
      "epoch:7 step:6028 [D loss: 0.751616, acc: 48.44%] [G loss: 1.553268]\n",
      "epoch:7 step:6029 [D loss: 0.698153, acc: 48.44%] [G loss: 1.566567]\n",
      "epoch:7 step:6030 [D loss: 0.582460, acc: 60.94%] [G loss: 1.415618]\n",
      "epoch:7 step:6031 [D loss: 0.686202, acc: 56.25%] [G loss: 1.548386]\n",
      "epoch:7 step:6032 [D loss: 0.759911, acc: 46.09%] [G loss: 1.419018]\n",
      "epoch:7 step:6033 [D loss: 0.632266, acc: 67.97%] [G loss: 1.530582]\n",
      "epoch:7 step:6034 [D loss: 1.023998, acc: 11.72%] [G loss: 1.504698]\n",
      "epoch:7 step:6035 [D loss: 0.542506, acc: 82.03%] [G loss: 1.692885]\n",
      "epoch:7 step:6036 [D loss: 0.719494, acc: 44.53%] [G loss: 1.453636]\n",
      "epoch:7 step:6037 [D loss: 0.677262, acc: 55.47%] [G loss: 1.697653]\n",
      "epoch:7 step:6038 [D loss: 0.599729, acc: 67.97%] [G loss: 1.502554]\n",
      "epoch:7 step:6039 [D loss: 0.687302, acc: 53.12%] [G loss: 1.615668]\n",
      "epoch:7 step:6040 [D loss: 0.703991, acc: 49.22%] [G loss: 1.620012]\n",
      "epoch:7 step:6041 [D loss: 0.782342, acc: 41.41%] [G loss: 1.400235]\n",
      "epoch:7 step:6042 [D loss: 0.636293, acc: 66.41%] [G loss: 1.516376]\n",
      "epoch:7 step:6043 [D loss: 0.643545, acc: 67.97%] [G loss: 1.690800]\n",
      "epoch:7 step:6044 [D loss: 0.652829, acc: 65.62%] [G loss: 1.573812]\n",
      "epoch:7 step:6045 [D loss: 0.571243, acc: 78.91%] [G loss: 1.639458]\n",
      "epoch:7 step:6046 [D loss: 0.704826, acc: 50.78%] [G loss: 1.605963]\n",
      "epoch:7 step:6047 [D loss: 0.706237, acc: 54.69%] [G loss: 1.491212]\n",
      "epoch:7 step:6048 [D loss: 0.455651, acc: 94.53%] [G loss: 1.727628]\n",
      "epoch:7 step:6049 [D loss: 0.712075, acc: 49.22%] [G loss: 1.466491]\n",
      "epoch:7 step:6050 [D loss: 0.555838, acc: 79.69%] [G loss: 1.480802]\n",
      "epoch:7 step:6051 [D loss: 0.696776, acc: 55.47%] [G loss: 1.451639]\n",
      "epoch:7 step:6052 [D loss: 0.593205, acc: 67.19%] [G loss: 1.366891]\n",
      "epoch:7 step:6053 [D loss: 0.936380, acc: 43.75%] [G loss: 1.520501]\n",
      "epoch:7 step:6054 [D loss: 0.606116, acc: 62.50%] [G loss: 1.681403]\n",
      "epoch:7 step:6055 [D loss: 0.665478, acc: 64.84%] [G loss: 1.741659]\n",
      "epoch:7 step:6056 [D loss: 0.732706, acc: 46.88%] [G loss: 1.455148]\n",
      "epoch:7 step:6057 [D loss: 0.659840, acc: 63.28%] [G loss: 1.657981]\n",
      "epoch:7 step:6058 [D loss: 0.567176, acc: 78.12%] [G loss: 1.872534]\n",
      "epoch:7 step:6059 [D loss: 0.791184, acc: 45.31%] [G loss: 1.564756]\n",
      "epoch:7 step:6060 [D loss: 0.597606, acc: 71.88%] [G loss: 1.607502]\n",
      "epoch:7 step:6061 [D loss: 0.687593, acc: 56.25%] [G loss: 1.669992]\n",
      "epoch:7 step:6062 [D loss: 0.720086, acc: 52.34%] [G loss: 1.626414]\n",
      "epoch:7 step:6063 [D loss: 0.788902, acc: 34.38%] [G loss: 1.557592]\n",
      "epoch:7 step:6064 [D loss: 0.460978, acc: 95.31%] [G loss: 1.730058]\n",
      "epoch:7 step:6065 [D loss: 0.642096, acc: 64.84%] [G loss: 1.534356]\n",
      "epoch:7 step:6066 [D loss: 0.729131, acc: 51.56%] [G loss: 1.693492]\n",
      "epoch:7 step:6067 [D loss: 0.670219, acc: 56.25%] [G loss: 1.607139]\n",
      "epoch:7 step:6068 [D loss: 0.623557, acc: 67.19%] [G loss: 1.640981]\n",
      "epoch:7 step:6069 [D loss: 0.671229, acc: 53.91%] [G loss: 1.578152]\n",
      "epoch:7 step:6070 [D loss: 0.778522, acc: 30.47%] [G loss: 1.426050]\n",
      "epoch:7 step:6071 [D loss: 0.715823, acc: 53.12%] [G loss: 1.370080]\n",
      "epoch:7 step:6072 [D loss: 0.619683, acc: 61.72%] [G loss: 1.623045]\n",
      "epoch:7 step:6073 [D loss: 0.663170, acc: 65.62%] [G loss: 1.767545]\n",
      "epoch:7 step:6074 [D loss: 0.714387, acc: 49.22%] [G loss: 1.419516]\n",
      "epoch:7 step:6075 [D loss: 0.708767, acc: 53.12%] [G loss: 1.527668]\n",
      "epoch:7 step:6076 [D loss: 0.782395, acc: 41.41%] [G loss: 1.422433]\n",
      "epoch:7 step:6077 [D loss: 0.741517, acc: 45.31%] [G loss: 1.512264]\n",
      "epoch:7 step:6078 [D loss: 0.739216, acc: 46.88%] [G loss: 1.562002]\n",
      "epoch:7 step:6079 [D loss: 0.633850, acc: 66.41%] [G loss: 1.554270]\n",
      "epoch:7 step:6080 [D loss: 1.033795, acc: 16.41%] [G loss: 1.233915]\n",
      "epoch:7 step:6081 [D loss: 0.758940, acc: 42.97%] [G loss: 1.513899]\n",
      "epoch:7 step:6082 [D loss: 0.685287, acc: 51.56%] [G loss: 1.652579]\n",
      "epoch:7 step:6083 [D loss: 0.778054, acc: 30.47%] [G loss: 1.522439]\n",
      "epoch:7 step:6084 [D loss: 0.688186, acc: 57.03%] [G loss: 1.679732]\n",
      "epoch:7 step:6085 [D loss: 0.686216, acc: 50.78%] [G loss: 1.446307]\n",
      "epoch:7 step:6086 [D loss: 0.806915, acc: 37.50%] [G loss: 1.480792]\n",
      "epoch:7 step:6087 [D loss: 0.733860, acc: 41.41%] [G loss: 1.540141]\n",
      "epoch:7 step:6088 [D loss: 0.639616, acc: 67.97%] [G loss: 1.596722]\n",
      "epoch:7 step:6089 [D loss: 0.776569, acc: 41.41%] [G loss: 1.521187]\n",
      "epoch:7 step:6090 [D loss: 0.716072, acc: 47.66%] [G loss: 1.633739]\n",
      "epoch:7 step:6091 [D loss: 0.699565, acc: 50.78%] [G loss: 1.524848]\n",
      "epoch:7 step:6092 [D loss: 0.522897, acc: 70.31%] [G loss: 1.681030]\n",
      "epoch:7 step:6093 [D loss: 0.662936, acc: 59.38%] [G loss: 1.522429]\n",
      "epoch:7 step:6094 [D loss: 0.609537, acc: 67.97%] [G loss: 1.674831]\n",
      "epoch:7 step:6095 [D loss: 0.479144, acc: 85.94%] [G loss: 1.882602]\n",
      "epoch:7 step:6096 [D loss: 0.677483, acc: 50.78%] [G loss: 1.610558]\n",
      "epoch:7 step:6097 [D loss: 0.578548, acc: 74.22%] [G loss: 1.617835]\n",
      "epoch:7 step:6098 [D loss: 0.541821, acc: 73.44%] [G loss: 1.629095]\n",
      "epoch:7 step:6099 [D loss: 0.736431, acc: 53.12%] [G loss: 1.374668]\n",
      "epoch:7 step:6100 [D loss: 0.878791, acc: 28.91%] [G loss: 1.410838]\n",
      "epoch:7 step:6101 [D loss: 0.547728, acc: 75.78%] [G loss: 1.551438]\n",
      "epoch:7 step:6102 [D loss: 0.573621, acc: 75.78%] [G loss: 1.323497]\n",
      "epoch:7 step:6103 [D loss: 0.796099, acc: 42.19%] [G loss: 1.211265]\n",
      "epoch:7 step:6104 [D loss: 0.706936, acc: 60.94%] [G loss: 1.521153]\n",
      "epoch:7 step:6105 [D loss: 1.090283, acc: 12.50%] [G loss: 1.112511]\n",
      "epoch:7 step:6106 [D loss: 0.811863, acc: 31.25%] [G loss: 1.474332]\n",
      "epoch:7 step:6107 [D loss: 0.803350, acc: 34.38%] [G loss: 1.436470]\n",
      "epoch:7 step:6108 [D loss: 0.731002, acc: 46.09%] [G loss: 1.461058]\n",
      "epoch:7 step:6109 [D loss: 0.728163, acc: 45.31%] [G loss: 1.422769]\n",
      "epoch:7 step:6110 [D loss: 0.769952, acc: 44.53%] [G loss: 1.543758]\n",
      "epoch:7 step:6111 [D loss: 0.556033, acc: 81.25%] [G loss: 1.845491]\n",
      "epoch:7 step:6112 [D loss: 0.881201, acc: 24.22%] [G loss: 1.472834]\n",
      "epoch:7 step:6113 [D loss: 0.772675, acc: 38.28%] [G loss: 1.532910]\n",
      "epoch:7 step:6114 [D loss: 0.649107, acc: 63.28%] [G loss: 1.704963]\n",
      "epoch:7 step:6115 [D loss: 0.647318, acc: 62.50%] [G loss: 1.645310]\n",
      "epoch:7 step:6116 [D loss: 0.745096, acc: 44.53%] [G loss: 1.695314]\n",
      "epoch:7 step:6117 [D loss: 0.727107, acc: 50.78%] [G loss: 1.555299]\n",
      "epoch:7 step:6118 [D loss: 0.426747, acc: 93.75%] [G loss: 1.870152]\n",
      "epoch:7 step:6119 [D loss: 0.511280, acc: 82.03%] [G loss: 1.752313]\n",
      "epoch:7 step:6120 [D loss: 0.554049, acc: 80.47%] [G loss: 1.740340]\n",
      "epoch:7 step:6121 [D loss: 0.629608, acc: 68.75%] [G loss: 1.621279]\n",
      "epoch:7 step:6122 [D loss: 0.642905, acc: 67.97%] [G loss: 1.791625]\n",
      "epoch:7 step:6123 [D loss: 0.845617, acc: 34.38%] [G loss: 1.420800]\n",
      "epoch:7 step:6124 [D loss: 0.566666, acc: 79.69%] [G loss: 1.798861]\n",
      "epoch:7 step:6125 [D loss: 0.582018, acc: 71.09%] [G loss: 1.525550]\n",
      "epoch:7 step:6126 [D loss: 0.720922, acc: 51.56%] [G loss: 1.552123]\n",
      "epoch:7 step:6127 [D loss: 0.784398, acc: 39.06%] [G loss: 1.478085]\n",
      "epoch:7 step:6128 [D loss: 0.748927, acc: 48.44%] [G loss: 1.496155]\n",
      "epoch:7 step:6129 [D loss: 0.685339, acc: 53.12%] [G loss: 1.657858]\n",
      "epoch:7 step:6130 [D loss: 0.651839, acc: 64.06%] [G loss: 1.646108]\n",
      "epoch:7 step:6131 [D loss: 0.490017, acc: 79.69%] [G loss: 1.667444]\n",
      "epoch:7 step:6132 [D loss: 0.562722, acc: 70.31%] [G loss: 1.391085]\n",
      "epoch:7 step:6133 [D loss: 0.796700, acc: 46.88%] [G loss: 1.431548]\n",
      "epoch:7 step:6134 [D loss: 0.751468, acc: 44.53%] [G loss: 1.580455]\n",
      "epoch:7 step:6135 [D loss: 0.627111, acc: 68.75%] [G loss: 1.675565]\n",
      "epoch:7 step:6136 [D loss: 0.603195, acc: 71.09%] [G loss: 1.590689]\n",
      "epoch:7 step:6137 [D loss: 0.708382, acc: 49.22%] [G loss: 1.314100]\n",
      "epoch:7 step:6138 [D loss: 0.560239, acc: 78.12%] [G loss: 1.893926]\n",
      "epoch:7 step:6139 [D loss: 0.761266, acc: 44.53%] [G loss: 1.323143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6140 [D loss: 0.734747, acc: 49.22%] [G loss: 1.479158]\n",
      "epoch:7 step:6141 [D loss: 0.625424, acc: 67.97%] [G loss: 1.593779]\n",
      "epoch:7 step:6142 [D loss: 0.689676, acc: 52.34%] [G loss: 1.556458]\n",
      "epoch:7 step:6143 [D loss: 0.782109, acc: 35.16%] [G loss: 1.426928]\n",
      "epoch:7 step:6144 [D loss: 0.603831, acc: 69.53%] [G loss: 1.588750]\n",
      "epoch:7 step:6145 [D loss: 0.621297, acc: 69.53%] [G loss: 1.456565]\n",
      "epoch:7 step:6146 [D loss: 0.699439, acc: 54.69%] [G loss: 1.437209]\n",
      "epoch:7 step:6147 [D loss: 0.697699, acc: 53.12%] [G loss: 1.597105]\n",
      "epoch:7 step:6148 [D loss: 0.552316, acc: 82.03%] [G loss: 1.677162]\n",
      "epoch:7 step:6149 [D loss: 0.940961, acc: 28.12%] [G loss: 1.414898]\n",
      "epoch:7 step:6150 [D loss: 0.787320, acc: 33.59%] [G loss: 1.478010]\n",
      "epoch:7 step:6151 [D loss: 0.640614, acc: 63.28%] [G loss: 1.614536]\n",
      "epoch:7 step:6152 [D loss: 0.729469, acc: 48.44%] [G loss: 1.516847]\n",
      "epoch:7 step:6153 [D loss: 0.622776, acc: 68.75%] [G loss: 1.793165]\n",
      "epoch:7 step:6154 [D loss: 0.825486, acc: 27.34%] [G loss: 1.349051]\n",
      "epoch:7 step:6155 [D loss: 0.594398, acc: 77.34%] [G loss: 1.706504]\n",
      "epoch:7 step:6156 [D loss: 0.765013, acc: 38.28%] [G loss: 1.544575]\n",
      "epoch:7 step:6157 [D loss: 0.687616, acc: 60.16%] [G loss: 1.496502]\n",
      "epoch:7 step:6158 [D loss: 0.589261, acc: 75.78%] [G loss: 1.648733]\n",
      "epoch:7 step:6159 [D loss: 1.050746, acc: 35.94%] [G loss: 1.618880]\n",
      "epoch:7 step:6160 [D loss: 0.689469, acc: 51.56%] [G loss: 1.673273]\n",
      "epoch:7 step:6161 [D loss: 0.696809, acc: 54.69%] [G loss: 1.803248]\n",
      "epoch:7 step:6162 [D loss: 0.599530, acc: 73.44%] [G loss: 1.626105]\n",
      "epoch:7 step:6163 [D loss: 0.744856, acc: 42.19%] [G loss: 1.525933]\n",
      "epoch:7 step:6164 [D loss: 0.614008, acc: 69.53%] [G loss: 1.384875]\n",
      "epoch:7 step:6165 [D loss: 0.650928, acc: 66.41%] [G loss: 1.445256]\n",
      "epoch:7 step:6166 [D loss: 0.604819, acc: 71.09%] [G loss: 1.606813]\n",
      "epoch:7 step:6167 [D loss: 0.682893, acc: 57.81%] [G loss: 1.519184]\n",
      "epoch:7 step:6168 [D loss: 0.505317, acc: 79.69%] [G loss: 1.613350]\n",
      "epoch:7 step:6169 [D loss: 0.757809, acc: 44.53%] [G loss: 1.600821]\n",
      "epoch:7 step:6170 [D loss: 0.778853, acc: 38.28%] [G loss: 1.665919]\n",
      "epoch:7 step:6171 [D loss: 0.956700, acc: 8.59%] [G loss: 1.255871]\n",
      "epoch:7 step:6172 [D loss: 0.656911, acc: 57.81%] [G loss: 1.638179]\n",
      "epoch:7 step:6173 [D loss: 0.750685, acc: 48.44%] [G loss: 1.527095]\n",
      "epoch:7 step:6174 [D loss: 0.728640, acc: 47.66%] [G loss: 1.505492]\n",
      "epoch:7 step:6175 [D loss: 0.698085, acc: 49.22%] [G loss: 1.632276]\n",
      "epoch:7 step:6176 [D loss: 0.709190, acc: 53.91%] [G loss: 1.509145]\n",
      "epoch:7 step:6177 [D loss: 0.644659, acc: 67.19%] [G loss: 1.526565]\n",
      "epoch:7 step:6178 [D loss: 0.751283, acc: 41.41%] [G loss: 1.465878]\n",
      "epoch:7 step:6179 [D loss: 0.750694, acc: 46.09%] [G loss: 1.610868]\n",
      "epoch:7 step:6180 [D loss: 0.676142, acc: 57.03%] [G loss: 1.665230]\n",
      "epoch:7 step:6181 [D loss: 0.709392, acc: 50.78%] [G loss: 1.625817]\n",
      "epoch:7 step:6182 [D loss: 0.766552, acc: 40.62%] [G loss: 1.536311]\n",
      "epoch:7 step:6183 [D loss: 0.418941, acc: 85.94%] [G loss: 1.942420]\n",
      "epoch:7 step:6184 [D loss: 0.649100, acc: 68.75%] [G loss: 1.597812]\n",
      "epoch:7 step:6185 [D loss: 0.743842, acc: 46.09%] [G loss: 1.491156]\n",
      "epoch:7 step:6186 [D loss: 0.462965, acc: 91.41%] [G loss: 1.722918]\n",
      "epoch:7 step:6187 [D loss: 0.492237, acc: 81.25%] [G loss: 1.536635]\n",
      "epoch:7 step:6188 [D loss: 0.699707, acc: 56.25%] [G loss: 1.271718]\n",
      "epoch:7 step:6189 [D loss: 0.656068, acc: 60.94%] [G loss: 1.507456]\n",
      "epoch:7 step:6190 [D loss: 1.096718, acc: 17.19%] [G loss: 1.559880]\n",
      "epoch:7 step:6191 [D loss: 0.855964, acc: 42.19%] [G loss: 1.471904]\n",
      "epoch:7 step:6192 [D loss: 0.702578, acc: 57.81%] [G loss: 1.684727]\n",
      "epoch:7 step:6193 [D loss: 0.647672, acc: 58.59%] [G loss: 1.562062]\n",
      "epoch:7 step:6194 [D loss: 0.509853, acc: 68.75%] [G loss: 1.776008]\n",
      "epoch:7 step:6195 [D loss: 0.610203, acc: 71.88%] [G loss: 1.441275]\n",
      "epoch:7 step:6196 [D loss: 0.559968, acc: 79.69%] [G loss: 1.514742]\n",
      "epoch:7 step:6197 [D loss: 0.451843, acc: 91.41%] [G loss: 1.790659]\n",
      "epoch:7 step:6198 [D loss: 0.530630, acc: 79.69%] [G loss: 1.389043]\n",
      "epoch:7 step:6199 [D loss: 0.662525, acc: 57.03%] [G loss: 1.430166]\n",
      "epoch:7 step:6200 [D loss: 0.768684, acc: 50.00%] [G loss: 1.554130]\n",
      "epoch:7 step:6201 [D loss: 0.769498, acc: 41.41%] [G loss: 1.523903]\n",
      "epoch:7 step:6202 [D loss: 0.730887, acc: 42.97%] [G loss: 1.491068]\n",
      "epoch:7 step:6203 [D loss: 0.776846, acc: 41.41%] [G loss: 1.473849]\n",
      "epoch:7 step:6204 [D loss: 0.741125, acc: 45.31%] [G loss: 1.731308]\n",
      "epoch:7 step:6205 [D loss: 0.730566, acc: 47.66%] [G loss: 1.625290]\n",
      "epoch:7 step:6206 [D loss: 0.651399, acc: 61.72%] [G loss: 1.723796]\n",
      "epoch:7 step:6207 [D loss: 0.720944, acc: 46.88%] [G loss: 1.595560]\n",
      "epoch:7 step:6208 [D loss: 0.573001, acc: 79.69%] [G loss: 1.859441]\n",
      "epoch:7 step:6209 [D loss: 0.597066, acc: 75.78%] [G loss: 1.640335]\n",
      "epoch:7 step:6210 [D loss: 0.615364, acc: 63.28%] [G loss: 1.722979]\n",
      "epoch:7 step:6211 [D loss: 0.703144, acc: 51.56%] [G loss: 1.586632]\n",
      "epoch:7 step:6212 [D loss: 0.632739, acc: 57.81%] [G loss: 1.736636]\n",
      "epoch:7 step:6213 [D loss: 0.590414, acc: 75.78%] [G loss: 1.694702]\n",
      "epoch:7 step:6214 [D loss: 0.456988, acc: 89.84%] [G loss: 1.826015]\n",
      "epoch:7 step:6215 [D loss: 0.611649, acc: 71.09%] [G loss: 1.629649]\n",
      "epoch:7 step:6216 [D loss: 0.802365, acc: 39.06%] [G loss: 1.492376]\n",
      "epoch:7 step:6217 [D loss: 0.705540, acc: 57.81%] [G loss: 1.669321]\n",
      "epoch:7 step:6218 [D loss: 0.588600, acc: 70.31%] [G loss: 1.482422]\n",
      "epoch:7 step:6219 [D loss: 0.540678, acc: 82.03%] [G loss: 1.792540]\n",
      "epoch:7 step:6220 [D loss: 0.770259, acc: 40.62%] [G loss: 1.503212]\n",
      "epoch:7 step:6221 [D loss: 0.654465, acc: 64.84%] [G loss: 1.416639]\n",
      "epoch:7 step:6222 [D loss: 0.878645, acc: 25.00%] [G loss: 1.381281]\n",
      "epoch:7 step:6223 [D loss: 0.786197, acc: 50.00%] [G loss: 1.531985]\n",
      "epoch:7 step:6224 [D loss: 0.706230, acc: 49.22%] [G loss: 1.586526]\n",
      "epoch:7 step:6225 [D loss: 0.669197, acc: 57.03%] [G loss: 1.581441]\n",
      "epoch:7 step:6226 [D loss: 0.728130, acc: 47.66%] [G loss: 1.549989]\n",
      "epoch:7 step:6227 [D loss: 0.972190, acc: 19.53%] [G loss: 1.572482]\n",
      "epoch:7 step:6228 [D loss: 0.706410, acc: 53.91%] [G loss: 1.531392]\n",
      "epoch:7 step:6229 [D loss: 0.715713, acc: 52.34%] [G loss: 1.562634]\n",
      "epoch:7 step:6230 [D loss: 0.903764, acc: 25.00%] [G loss: 1.511860]\n",
      "epoch:7 step:6231 [D loss: 0.777934, acc: 34.38%] [G loss: 1.495164]\n",
      "epoch:7 step:6232 [D loss: 0.779879, acc: 43.75%] [G loss: 1.538625]\n",
      "epoch:7 step:6233 [D loss: 0.507925, acc: 81.25%] [G loss: 1.644042]\n",
      "epoch:7 step:6234 [D loss: 0.602332, acc: 69.53%] [G loss: 1.617403]\n",
      "epoch:7 step:6235 [D loss: 0.578494, acc: 75.00%] [G loss: 1.794904]\n",
      "epoch:7 step:6236 [D loss: 0.618009, acc: 60.94%] [G loss: 1.407144]\n",
      "epoch:7 step:6237 [D loss: 0.571399, acc: 77.34%] [G loss: 1.615294]\n",
      "epoch:7 step:6238 [D loss: 0.764430, acc: 42.97%] [G loss: 1.514649]\n",
      "epoch:7 step:6239 [D loss: 0.680798, acc: 56.25%] [G loss: 1.670038]\n",
      "epoch:7 step:6240 [D loss: 0.734633, acc: 46.88%] [G loss: 1.708626]\n",
      "epoch:7 step:6241 [D loss: 0.657580, acc: 63.28%] [G loss: 1.521767]\n",
      "epoch:7 step:6242 [D loss: 0.601056, acc: 74.22%] [G loss: 1.931146]\n",
      "epoch:7 step:6243 [D loss: 0.564558, acc: 77.34%] [G loss: 1.686014]\n",
      "epoch:7 step:6244 [D loss: 0.828017, acc: 38.28%] [G loss: 1.525692]\n",
      "epoch:7 step:6245 [D loss: 0.749583, acc: 50.78%] [G loss: 1.536959]\n",
      "epoch:7 step:6246 [D loss: 0.868256, acc: 37.50%] [G loss: 1.630607]\n",
      "epoch:7 step:6247 [D loss: 0.864374, acc: 21.88%] [G loss: 1.433989]\n",
      "epoch:7 step:6248 [D loss: 0.547752, acc: 80.47%] [G loss: 1.658232]\n",
      "epoch:8 step:6249 [D loss: 0.623143, acc: 64.84%] [G loss: 1.653628]\n",
      "epoch:8 step:6250 [D loss: 0.464265, acc: 89.84%] [G loss: 1.732621]\n",
      "epoch:8 step:6251 [D loss: 0.712151, acc: 53.12%] [G loss: 1.651111]\n",
      "epoch:8 step:6252 [D loss: 0.595202, acc: 72.66%] [G loss: 1.720852]\n",
      "epoch:8 step:6253 [D loss: 0.701111, acc: 52.34%] [G loss: 1.548731]\n",
      "epoch:8 step:6254 [D loss: 0.650815, acc: 60.94%] [G loss: 1.797951]\n",
      "epoch:8 step:6255 [D loss: 0.665580, acc: 61.72%] [G loss: 1.881153]\n",
      "epoch:8 step:6256 [D loss: 0.551345, acc: 78.91%] [G loss: 1.805927]\n",
      "epoch:8 step:6257 [D loss: 0.759997, acc: 49.22%] [G loss: 1.590291]\n",
      "epoch:8 step:6258 [D loss: 0.709250, acc: 53.91%] [G loss: 1.743751]\n",
      "epoch:8 step:6259 [D loss: 0.549873, acc: 75.00%] [G loss: 1.632221]\n",
      "epoch:8 step:6260 [D loss: 0.641170, acc: 61.72%] [G loss: 1.406489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6261 [D loss: 0.618574, acc: 67.97%] [G loss: 1.717702]\n",
      "epoch:8 step:6262 [D loss: 0.691446, acc: 57.81%] [G loss: 1.732923]\n",
      "epoch:8 step:6263 [D loss: 0.600583, acc: 64.06%] [G loss: 1.353322]\n",
      "epoch:8 step:6264 [D loss: 0.677446, acc: 60.16%] [G loss: 1.681314]\n",
      "epoch:8 step:6265 [D loss: 0.652319, acc: 68.75%] [G loss: 1.823041]\n",
      "epoch:8 step:6266 [D loss: 0.514356, acc: 69.53%] [G loss: 1.964420]\n",
      "epoch:8 step:6267 [D loss: 0.680917, acc: 56.25%] [G loss: 1.880050]\n",
      "epoch:8 step:6268 [D loss: 0.719109, acc: 49.22%] [G loss: 1.620505]\n",
      "epoch:8 step:6269 [D loss: 0.780053, acc: 35.94%] [G loss: 1.520891]\n",
      "epoch:8 step:6270 [D loss: 0.657100, acc: 64.84%] [G loss: 1.670164]\n",
      "epoch:8 step:6271 [D loss: 0.759863, acc: 50.00%] [G loss: 1.465103]\n",
      "epoch:8 step:6272 [D loss: 0.568105, acc: 75.78%] [G loss: 1.497128]\n",
      "epoch:8 step:6273 [D loss: 0.680128, acc: 53.91%] [G loss: 1.782094]\n",
      "epoch:8 step:6274 [D loss: 0.704035, acc: 52.34%] [G loss: 1.512569]\n",
      "epoch:8 step:6275 [D loss: 0.789261, acc: 32.81%] [G loss: 1.298156]\n",
      "epoch:8 step:6276 [D loss: 0.625492, acc: 69.53%] [G loss: 1.484889]\n",
      "epoch:8 step:6277 [D loss: 0.630788, acc: 67.97%] [G loss: 1.685131]\n",
      "epoch:8 step:6278 [D loss: 0.696492, acc: 52.34%] [G loss: 1.444285]\n",
      "epoch:8 step:6279 [D loss: 0.633937, acc: 66.41%] [G loss: 1.587625]\n",
      "epoch:8 step:6280 [D loss: 0.545067, acc: 78.12%] [G loss: 1.528700]\n",
      "epoch:8 step:6281 [D loss: 0.838590, acc: 34.38%] [G loss: 1.393161]\n",
      "epoch:8 step:6282 [D loss: 0.626452, acc: 66.41%] [G loss: 1.533959]\n",
      "epoch:8 step:6283 [D loss: 0.690117, acc: 57.81%] [G loss: 1.525189]\n",
      "epoch:8 step:6284 [D loss: 0.721562, acc: 47.66%] [G loss: 1.411854]\n",
      "epoch:8 step:6285 [D loss: 0.558891, acc: 81.25%] [G loss: 1.566902]\n",
      "epoch:8 step:6286 [D loss: 0.770248, acc: 44.53%] [G loss: 1.397147]\n",
      "epoch:8 step:6287 [D loss: 0.870236, acc: 30.47%] [G loss: 1.375958]\n",
      "epoch:8 step:6288 [D loss: 0.698196, acc: 50.78%] [G loss: 1.610662]\n",
      "epoch:8 step:6289 [D loss: 0.668371, acc: 59.38%] [G loss: 1.796813]\n",
      "epoch:8 step:6290 [D loss: 0.738723, acc: 49.22%] [G loss: 1.564097]\n",
      "epoch:8 step:6291 [D loss: 0.800664, acc: 35.16%] [G loss: 1.680833]\n",
      "epoch:8 step:6292 [D loss: 0.685205, acc: 55.47%] [G loss: 1.484697]\n",
      "epoch:8 step:6293 [D loss: 0.635819, acc: 67.97%] [G loss: 1.788001]\n",
      "epoch:8 step:6294 [D loss: 0.798296, acc: 44.53%] [G loss: 1.365710]\n",
      "epoch:8 step:6295 [D loss: 0.665758, acc: 57.81%] [G loss: 1.526137]\n",
      "epoch:8 step:6296 [D loss: 0.741296, acc: 50.00%] [G loss: 1.482438]\n",
      "epoch:8 step:6297 [D loss: 0.819655, acc: 39.06%] [G loss: 1.505497]\n",
      "epoch:8 step:6298 [D loss: 0.725557, acc: 42.97%] [G loss: 1.551038]\n",
      "epoch:8 step:6299 [D loss: 0.724268, acc: 48.44%] [G loss: 1.541307]\n",
      "epoch:8 step:6300 [D loss: 0.669803, acc: 57.03%] [G loss: 1.605792]\n",
      "epoch:8 step:6301 [D loss: 0.609340, acc: 71.09%] [G loss: 1.478418]\n",
      "epoch:8 step:6302 [D loss: 0.719288, acc: 50.00%] [G loss: 1.598679]\n",
      "epoch:8 step:6303 [D loss: 0.826473, acc: 40.62%] [G loss: 1.530760]\n",
      "epoch:8 step:6304 [D loss: 0.837766, acc: 31.25%] [G loss: 1.543077]\n",
      "epoch:8 step:6305 [D loss: 0.676280, acc: 57.03%] [G loss: 1.567330]\n",
      "epoch:8 step:6306 [D loss: 0.648986, acc: 57.81%] [G loss: 1.407958]\n",
      "epoch:8 step:6307 [D loss: 0.701765, acc: 48.44%] [G loss: 1.609112]\n",
      "epoch:8 step:6308 [D loss: 0.647281, acc: 58.59%] [G loss: 1.680496]\n",
      "epoch:8 step:6309 [D loss: 0.533739, acc: 66.41%] [G loss: 1.621296]\n",
      "epoch:8 step:6310 [D loss: 0.542623, acc: 76.56%] [G loss: 1.694695]\n",
      "epoch:8 step:6311 [D loss: 0.597056, acc: 71.88%] [G loss: 1.692472]\n",
      "epoch:8 step:6312 [D loss: 0.574741, acc: 78.12%] [G loss: 1.605236]\n",
      "epoch:8 step:6313 [D loss: 0.766542, acc: 49.22%] [G loss: 1.654022]\n",
      "epoch:8 step:6314 [D loss: 0.508701, acc: 85.16%] [G loss: 1.733837]\n",
      "epoch:8 step:6315 [D loss: 0.745812, acc: 47.66%] [G loss: 1.487879]\n",
      "epoch:8 step:6316 [D loss: 0.496943, acc: 86.72%] [G loss: 1.754742]\n",
      "epoch:8 step:6317 [D loss: 0.668992, acc: 53.91%] [G loss: 1.670557]\n",
      "epoch:8 step:6318 [D loss: 0.599755, acc: 67.19%] [G loss: 1.717798]\n",
      "epoch:8 step:6319 [D loss: 1.044890, acc: 18.75%] [G loss: 1.399515]\n",
      "epoch:8 step:6320 [D loss: 0.658525, acc: 57.03%] [G loss: 1.613651]\n",
      "epoch:8 step:6321 [D loss: 0.642240, acc: 57.81%] [G loss: 1.706494]\n",
      "epoch:8 step:6322 [D loss: 0.573405, acc: 77.34%] [G loss: 1.674985]\n",
      "epoch:8 step:6323 [D loss: 0.487520, acc: 85.16%] [G loss: 1.955572]\n",
      "epoch:8 step:6324 [D loss: 0.690196, acc: 56.25%] [G loss: 1.720729]\n",
      "epoch:8 step:6325 [D loss: 0.782236, acc: 35.16%] [G loss: 1.612203]\n",
      "epoch:8 step:6326 [D loss: 0.530430, acc: 77.34%] [G loss: 1.470532]\n",
      "epoch:8 step:6327 [D loss: 0.488673, acc: 82.81%] [G loss: 1.453871]\n",
      "epoch:8 step:6328 [D loss: 0.746863, acc: 37.50%] [G loss: 1.568793]\n",
      "epoch:8 step:6329 [D loss: 0.617901, acc: 74.22%] [G loss: 1.621858]\n",
      "epoch:8 step:6330 [D loss: 0.827521, acc: 39.84%] [G loss: 1.446670]\n",
      "epoch:8 step:6331 [D loss: 0.732401, acc: 47.66%] [G loss: 1.587849]\n",
      "epoch:8 step:6332 [D loss: 0.749983, acc: 45.31%] [G loss: 1.373638]\n",
      "epoch:8 step:6333 [D loss: 0.735243, acc: 51.56%] [G loss: 1.666313]\n",
      "epoch:8 step:6334 [D loss: 0.672035, acc: 57.03%] [G loss: 1.667800]\n",
      "epoch:8 step:6335 [D loss: 0.723200, acc: 45.31%] [G loss: 1.659844]\n",
      "epoch:8 step:6336 [D loss: 0.775802, acc: 45.31%] [G loss: 1.536533]\n",
      "epoch:8 step:6337 [D loss: 0.804076, acc: 40.62%] [G loss: 1.488535]\n",
      "epoch:8 step:6338 [D loss: 0.927974, acc: 30.47%] [G loss: 1.302734]\n",
      "epoch:8 step:6339 [D loss: 0.803361, acc: 43.75%] [G loss: 1.670033]\n",
      "epoch:8 step:6340 [D loss: 0.741161, acc: 42.19%] [G loss: 1.541144]\n",
      "epoch:8 step:6341 [D loss: 0.745334, acc: 42.97%] [G loss: 1.631333]\n",
      "epoch:8 step:6342 [D loss: 0.554155, acc: 77.34%] [G loss: 1.634636]\n",
      "epoch:8 step:6343 [D loss: 0.599491, acc: 71.88%] [G loss: 1.518389]\n",
      "epoch:8 step:6344 [D loss: 0.762066, acc: 42.97%] [G loss: 1.416934]\n",
      "epoch:8 step:6345 [D loss: 0.828994, acc: 33.59%] [G loss: 1.423365]\n",
      "epoch:8 step:6346 [D loss: 0.700276, acc: 52.34%] [G loss: 1.376673]\n",
      "epoch:8 step:6347 [D loss: 0.686663, acc: 54.69%] [G loss: 1.571364]\n",
      "epoch:8 step:6348 [D loss: 0.474752, acc: 85.16%] [G loss: 1.656921]\n",
      "epoch:8 step:6349 [D loss: 0.702032, acc: 55.47%] [G loss: 1.441425]\n",
      "epoch:8 step:6350 [D loss: 0.745416, acc: 47.66%] [G loss: 1.461793]\n",
      "epoch:8 step:6351 [D loss: 0.774384, acc: 38.28%] [G loss: 1.422407]\n",
      "epoch:8 step:6352 [D loss: 0.682164, acc: 60.16%] [G loss: 1.534845]\n",
      "epoch:8 step:6353 [D loss: 0.754372, acc: 42.97%] [G loss: 1.558457]\n",
      "epoch:8 step:6354 [D loss: 0.525978, acc: 85.16%] [G loss: 1.719604]\n",
      "epoch:8 step:6355 [D loss: 0.721511, acc: 52.34%] [G loss: 1.757488]\n",
      "epoch:8 step:6356 [D loss: 0.995238, acc: 42.97%] [G loss: 1.500960]\n",
      "epoch:8 step:6357 [D loss: 0.610197, acc: 64.06%] [G loss: 1.834132]\n",
      "epoch:8 step:6358 [D loss: 0.626827, acc: 62.50%] [G loss: 1.536399]\n",
      "epoch:8 step:6359 [D loss: 0.669010, acc: 64.06%] [G loss: 1.536751]\n",
      "epoch:8 step:6360 [D loss: 0.650988, acc: 69.53%] [G loss: 1.491328]\n",
      "epoch:8 step:6361 [D loss: 0.787094, acc: 31.25%] [G loss: 1.525871]\n",
      "epoch:8 step:6362 [D loss: 0.682409, acc: 57.03%] [G loss: 1.871146]\n",
      "epoch:8 step:6363 [D loss: 0.707322, acc: 55.47%] [G loss: 1.550281]\n",
      "epoch:8 step:6364 [D loss: 0.663073, acc: 56.25%] [G loss: 1.629525]\n",
      "epoch:8 step:6365 [D loss: 0.714612, acc: 51.56%] [G loss: 1.394805]\n",
      "epoch:8 step:6366 [D loss: 0.736069, acc: 47.66%] [G loss: 1.395821]\n",
      "epoch:8 step:6367 [D loss: 0.740472, acc: 49.22%] [G loss: 1.547228]\n",
      "epoch:8 step:6368 [D loss: 0.622033, acc: 68.75%] [G loss: 1.406034]\n",
      "epoch:8 step:6369 [D loss: 0.744766, acc: 46.88%] [G loss: 1.639728]\n",
      "epoch:8 step:6370 [D loss: 0.796777, acc: 33.59%] [G loss: 1.414036]\n",
      "epoch:8 step:6371 [D loss: 0.532335, acc: 77.34%] [G loss: 1.758422]\n",
      "epoch:8 step:6372 [D loss: 0.688505, acc: 51.56%] [G loss: 1.611006]\n",
      "epoch:8 step:6373 [D loss: 0.679117, acc: 57.03%] [G loss: 1.695974]\n",
      "epoch:8 step:6374 [D loss: 0.780108, acc: 52.34%] [G loss: 1.236233]\n",
      "epoch:8 step:6375 [D loss: 0.686230, acc: 53.12%] [G loss: 1.521030]\n",
      "epoch:8 step:6376 [D loss: 0.493556, acc: 90.62%] [G loss: 1.674222]\n",
      "epoch:8 step:6377 [D loss: 0.799968, acc: 46.88%] [G loss: 1.544580]\n",
      "epoch:8 step:6378 [D loss: 0.866443, acc: 27.34%] [G loss: 1.497840]\n",
      "epoch:8 step:6379 [D loss: 0.757694, acc: 46.88%] [G loss: 1.640653]\n",
      "epoch:8 step:6380 [D loss: 0.603397, acc: 71.09%] [G loss: 1.732457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6381 [D loss: 0.532430, acc: 89.06%] [G loss: 1.614523]\n",
      "epoch:8 step:6382 [D loss: 0.831385, acc: 28.91%] [G loss: 1.422353]\n",
      "epoch:8 step:6383 [D loss: 0.437398, acc: 78.91%] [G loss: 1.998520]\n",
      "epoch:8 step:6384 [D loss: 0.662895, acc: 58.59%] [G loss: 1.702707]\n",
      "epoch:8 step:6385 [D loss: 0.573895, acc: 74.22%] [G loss: 1.608586]\n",
      "epoch:8 step:6386 [D loss: 0.606967, acc: 70.31%] [G loss: 1.765613]\n",
      "epoch:8 step:6387 [D loss: 0.479761, acc: 81.25%] [G loss: 1.645139]\n",
      "epoch:8 step:6388 [D loss: 0.502458, acc: 86.72%] [G loss: 1.616531]\n",
      "epoch:8 step:6389 [D loss: 0.465040, acc: 83.59%] [G loss: 1.583855]\n",
      "epoch:8 step:6390 [D loss: 0.684265, acc: 55.47%] [G loss: 1.438580]\n",
      "epoch:8 step:6391 [D loss: 0.628092, acc: 66.41%] [G loss: 1.402814]\n",
      "epoch:8 step:6392 [D loss: 0.546815, acc: 70.31%] [G loss: 1.810448]\n",
      "epoch:8 step:6393 [D loss: 0.797924, acc: 44.53%] [G loss: 1.620244]\n",
      "epoch:8 step:6394 [D loss: 0.706193, acc: 50.00%] [G loss: 1.653348]\n",
      "epoch:8 step:6395 [D loss: 0.674288, acc: 58.59%] [G loss: 1.548681]\n",
      "epoch:8 step:6396 [D loss: 0.861884, acc: 32.03%] [G loss: 1.498943]\n",
      "epoch:8 step:6397 [D loss: 0.624214, acc: 67.97%] [G loss: 1.483488]\n",
      "epoch:8 step:6398 [D loss: 0.601045, acc: 69.53%] [G loss: 1.594548]\n",
      "epoch:8 step:6399 [D loss: 0.610862, acc: 78.91%] [G loss: 1.588134]\n",
      "epoch:8 step:6400 [D loss: 0.779069, acc: 37.50%] [G loss: 1.543117]\n",
      "epoch:8 step:6401 [D loss: 0.762972, acc: 39.06%] [G loss: 1.580762]\n",
      "epoch:8 step:6402 [D loss: 0.692565, acc: 57.03%] [G loss: 1.532340]\n",
      "epoch:8 step:6403 [D loss: 0.689431, acc: 53.91%] [G loss: 1.642854]\n",
      "epoch:8 step:6404 [D loss: 0.580509, acc: 69.53%] [G loss: 1.462886]\n",
      "epoch:8 step:6405 [D loss: 0.686396, acc: 59.38%] [G loss: 1.472947]\n",
      "epoch:8 step:6406 [D loss: 0.716549, acc: 50.78%] [G loss: 1.630560]\n",
      "epoch:8 step:6407 [D loss: 0.651302, acc: 57.03%] [G loss: 1.648668]\n",
      "epoch:8 step:6408 [D loss: 0.842562, acc: 36.72%] [G loss: 1.359957]\n",
      "epoch:8 step:6409 [D loss: 0.745647, acc: 48.44%] [G loss: 1.617146]\n",
      "epoch:8 step:6410 [D loss: 0.538469, acc: 73.44%] [G loss: 1.865885]\n",
      "epoch:8 step:6411 [D loss: 0.599686, acc: 75.78%] [G loss: 1.563931]\n",
      "epoch:8 step:6412 [D loss: 0.601429, acc: 71.88%] [G loss: 1.592103]\n",
      "epoch:8 step:6413 [D loss: 0.558333, acc: 74.22%] [G loss: 1.640085]\n",
      "epoch:8 step:6414 [D loss: 0.756614, acc: 51.56%] [G loss: 1.386869]\n",
      "epoch:8 step:6415 [D loss: 0.811465, acc: 38.28%] [G loss: 1.745752]\n",
      "epoch:8 step:6416 [D loss: 0.727891, acc: 51.56%] [G loss: 1.611380]\n",
      "epoch:8 step:6417 [D loss: 0.658926, acc: 63.28%] [G loss: 1.524693]\n",
      "epoch:8 step:6418 [D loss: 0.729679, acc: 51.56%] [G loss: 1.663859]\n",
      "epoch:8 step:6419 [D loss: 0.718486, acc: 53.91%] [G loss: 1.470967]\n",
      "epoch:8 step:6420 [D loss: 0.774202, acc: 41.41%] [G loss: 1.529058]\n",
      "epoch:8 step:6421 [D loss: 0.863313, acc: 18.75%] [G loss: 1.379997]\n",
      "epoch:8 step:6422 [D loss: 0.551940, acc: 79.69%] [G loss: 1.560406]\n",
      "epoch:8 step:6423 [D loss: 0.684783, acc: 57.81%] [G loss: 1.631378]\n",
      "epoch:8 step:6424 [D loss: 0.679025, acc: 60.94%] [G loss: 1.684631]\n",
      "epoch:8 step:6425 [D loss: 0.579581, acc: 74.22%] [G loss: 1.709072]\n",
      "epoch:8 step:6426 [D loss: 0.720190, acc: 51.56%] [G loss: 1.509508]\n",
      "epoch:8 step:6427 [D loss: 0.800387, acc: 31.25%] [G loss: 1.508656]\n",
      "epoch:8 step:6428 [D loss: 0.620548, acc: 67.97%] [G loss: 1.577640]\n",
      "epoch:8 step:6429 [D loss: 0.636747, acc: 69.53%] [G loss: 1.704273]\n",
      "epoch:8 step:6430 [D loss: 0.764896, acc: 42.97%] [G loss: 1.701775]\n",
      "epoch:8 step:6431 [D loss: 0.551974, acc: 79.69%] [G loss: 1.716599]\n",
      "epoch:8 step:6432 [D loss: 0.869135, acc: 28.12%] [G loss: 1.448483]\n",
      "epoch:8 step:6433 [D loss: 0.786145, acc: 37.50%] [G loss: 1.406704]\n",
      "epoch:8 step:6434 [D loss: 0.677822, acc: 63.28%] [G loss: 1.700828]\n",
      "epoch:8 step:6435 [D loss: 0.565511, acc: 70.31%] [G loss: 1.561178]\n",
      "epoch:8 step:6436 [D loss: 0.525818, acc: 82.81%] [G loss: 1.625676]\n",
      "epoch:8 step:6437 [D loss: 0.822288, acc: 36.72%] [G loss: 1.534865]\n",
      "epoch:8 step:6438 [D loss: 0.727530, acc: 52.34%] [G loss: 1.482926]\n",
      "epoch:8 step:6439 [D loss: 0.439126, acc: 90.62%] [G loss: 1.500444]\n",
      "epoch:8 step:6440 [D loss: 0.659445, acc: 65.62%] [G loss: 1.655934]\n",
      "epoch:8 step:6441 [D loss: 0.668194, acc: 53.12%] [G loss: 1.612981]\n",
      "epoch:8 step:6442 [D loss: 0.606903, acc: 75.00%] [G loss: 1.575035]\n",
      "epoch:8 step:6443 [D loss: 0.681893, acc: 53.12%] [G loss: 1.506842]\n",
      "epoch:8 step:6444 [D loss: 0.854268, acc: 32.03%] [G loss: 1.303970]\n",
      "epoch:8 step:6445 [D loss: 0.684037, acc: 55.47%] [G loss: 1.370200]\n",
      "epoch:8 step:6446 [D loss: 0.666676, acc: 57.03%] [G loss: 1.490963]\n",
      "epoch:8 step:6447 [D loss: 0.772603, acc: 42.97%] [G loss: 1.588289]\n",
      "epoch:8 step:6448 [D loss: 0.633716, acc: 65.62%] [G loss: 1.780087]\n",
      "epoch:8 step:6449 [D loss: 0.584116, acc: 75.78%] [G loss: 1.815356]\n",
      "epoch:8 step:6450 [D loss: 0.764911, acc: 45.31%] [G loss: 1.563464]\n",
      "epoch:8 step:6451 [D loss: 0.758901, acc: 41.41%] [G loss: 1.479747]\n",
      "epoch:8 step:6452 [D loss: 0.614712, acc: 67.97%] [G loss: 1.594340]\n",
      "epoch:8 step:6453 [D loss: 0.820159, acc: 46.09%] [G loss: 1.312135]\n",
      "epoch:8 step:6454 [D loss: 0.536593, acc: 75.00%] [G loss: 1.542385]\n",
      "epoch:8 step:6455 [D loss: 0.670283, acc: 60.94%] [G loss: 1.829433]\n",
      "epoch:8 step:6456 [D loss: 0.543269, acc: 83.59%] [G loss: 1.718077]\n",
      "epoch:8 step:6457 [D loss: 0.643598, acc: 64.06%] [G loss: 1.563658]\n",
      "epoch:8 step:6458 [D loss: 0.682754, acc: 53.91%] [G loss: 1.722667]\n",
      "epoch:8 step:6459 [D loss: 0.551296, acc: 82.81%] [G loss: 1.714892]\n",
      "epoch:8 step:6460 [D loss: 0.706091, acc: 55.47%] [G loss: 1.733749]\n",
      "epoch:8 step:6461 [D loss: 0.732778, acc: 44.53%] [G loss: 1.437786]\n",
      "epoch:8 step:6462 [D loss: 0.667863, acc: 56.25%] [G loss: 1.604267]\n",
      "epoch:8 step:6463 [D loss: 0.766251, acc: 43.75%] [G loss: 1.603761]\n",
      "epoch:8 step:6464 [D loss: 0.639259, acc: 67.19%] [G loss: 1.837015]\n",
      "epoch:8 step:6465 [D loss: 0.666883, acc: 57.03%] [G loss: 1.243904]\n",
      "epoch:8 step:6466 [D loss: 0.453084, acc: 92.19%] [G loss: 1.925325]\n",
      "epoch:8 step:6467 [D loss: 0.592278, acc: 64.06%] [G loss: 1.998335]\n",
      "epoch:8 step:6468 [D loss: 0.757921, acc: 46.09%] [G loss: 1.510426]\n",
      "epoch:8 step:6469 [D loss: 0.623931, acc: 71.88%] [G loss: 1.713489]\n",
      "epoch:8 step:6470 [D loss: 0.650505, acc: 62.50%] [G loss: 1.823213]\n",
      "epoch:8 step:6471 [D loss: 0.655222, acc: 65.62%] [G loss: 1.684044]\n",
      "epoch:8 step:6472 [D loss: 0.828400, acc: 30.47%] [G loss: 1.603059]\n",
      "epoch:8 step:6473 [D loss: 0.796609, acc: 39.06%] [G loss: 1.376291]\n",
      "epoch:8 step:6474 [D loss: 0.747284, acc: 44.53%] [G loss: 1.596287]\n",
      "epoch:8 step:6475 [D loss: 0.700381, acc: 52.34%] [G loss: 1.365024]\n",
      "epoch:8 step:6476 [D loss: 0.823665, acc: 35.94%] [G loss: 1.431944]\n",
      "epoch:8 step:6477 [D loss: 0.709263, acc: 53.12%] [G loss: 1.552920]\n",
      "epoch:8 step:6478 [D loss: 0.654414, acc: 57.03%] [G loss: 1.588850]\n",
      "epoch:8 step:6479 [D loss: 0.606259, acc: 76.56%] [G loss: 1.564532]\n",
      "epoch:8 step:6480 [D loss: 1.205046, acc: 13.28%] [G loss: 1.332535]\n",
      "epoch:8 step:6481 [D loss: 0.575386, acc: 78.91%] [G loss: 1.685935]\n",
      "epoch:8 step:6482 [D loss: 0.877489, acc: 25.00%] [G loss: 1.703681]\n",
      "epoch:8 step:6483 [D loss: 0.604914, acc: 61.72%] [G loss: 1.914334]\n",
      "epoch:8 step:6484 [D loss: 0.881730, acc: 26.56%] [G loss: 1.676270]\n",
      "epoch:8 step:6485 [D loss: 0.651533, acc: 59.38%] [G loss: 1.701455]\n",
      "epoch:8 step:6486 [D loss: 0.599264, acc: 74.22%] [G loss: 1.480744]\n",
      "epoch:8 step:6487 [D loss: 0.527547, acc: 82.03%] [G loss: 1.785078]\n",
      "epoch:8 step:6488 [D loss: 0.779204, acc: 34.38%] [G loss: 1.591249]\n",
      "epoch:8 step:6489 [D loss: 0.600458, acc: 71.88%] [G loss: 1.601727]\n",
      "epoch:8 step:6490 [D loss: 0.622095, acc: 67.19%] [G loss: 1.750245]\n",
      "epoch:8 step:6491 [D loss: 0.532617, acc: 81.25%] [G loss: 1.540121]\n",
      "epoch:8 step:6492 [D loss: 0.709364, acc: 50.00%] [G loss: 1.666012]\n",
      "epoch:8 step:6493 [D loss: 0.697005, acc: 53.12%] [G loss: 1.518681]\n",
      "epoch:8 step:6494 [D loss: 0.668928, acc: 63.28%] [G loss: 1.745310]\n",
      "epoch:8 step:6495 [D loss: 0.728714, acc: 46.88%] [G loss: 1.655752]\n",
      "epoch:8 step:6496 [D loss: 0.820098, acc: 39.06%] [G loss: 1.605600]\n",
      "epoch:8 step:6497 [D loss: 0.725645, acc: 46.88%] [G loss: 1.442782]\n",
      "epoch:8 step:6498 [D loss: 0.641048, acc: 70.31%] [G loss: 1.479732]\n",
      "epoch:8 step:6499 [D loss: 0.464899, acc: 89.06%] [G loss: 1.649471]\n",
      "epoch:8 step:6500 [D loss: 0.740453, acc: 46.88%] [G loss: 1.470871]\n",
      "epoch:8 step:6501 [D loss: 0.739475, acc: 45.31%] [G loss: 1.486945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6502 [D loss: 0.842389, acc: 30.47%] [G loss: 1.375685]\n",
      "epoch:8 step:6503 [D loss: 0.799781, acc: 36.72%] [G loss: 1.437746]\n",
      "epoch:8 step:6504 [D loss: 0.880088, acc: 37.50%] [G loss: 1.419495]\n",
      "epoch:8 step:6505 [D loss: 0.836168, acc: 28.12%] [G loss: 1.410270]\n",
      "epoch:8 step:6506 [D loss: 0.818913, acc: 44.53%] [G loss: 1.564388]\n",
      "epoch:8 step:6507 [D loss: 0.634512, acc: 67.97%] [G loss: 1.830065]\n",
      "epoch:8 step:6508 [D loss: 0.575058, acc: 69.53%] [G loss: 1.848536]\n",
      "epoch:8 step:6509 [D loss: 0.709772, acc: 52.34%] [G loss: 1.632610]\n",
      "epoch:8 step:6510 [D loss: 0.640010, acc: 67.97%] [G loss: 1.870870]\n",
      "epoch:8 step:6511 [D loss: 0.860089, acc: 33.59%] [G loss: 1.615416]\n",
      "epoch:8 step:6512 [D loss: 0.742151, acc: 48.44%] [G loss: 1.488693]\n",
      "epoch:8 step:6513 [D loss: 0.659791, acc: 60.94%] [G loss: 1.497151]\n",
      "epoch:8 step:6514 [D loss: 0.651279, acc: 62.50%] [G loss: 1.665962]\n",
      "epoch:8 step:6515 [D loss: 0.903398, acc: 21.09%] [G loss: 1.537351]\n",
      "epoch:8 step:6516 [D loss: 0.549824, acc: 81.25%] [G loss: 1.595305]\n",
      "epoch:8 step:6517 [D loss: 0.543109, acc: 79.69%] [G loss: 1.723919]\n",
      "epoch:8 step:6518 [D loss: 0.831818, acc: 26.56%] [G loss: 1.588486]\n",
      "epoch:8 step:6519 [D loss: 0.640131, acc: 65.62%] [G loss: 1.660115]\n",
      "epoch:8 step:6520 [D loss: 0.556611, acc: 81.25%] [G loss: 1.694202]\n",
      "epoch:8 step:6521 [D loss: 0.651693, acc: 65.62%] [G loss: 1.750094]\n",
      "epoch:8 step:6522 [D loss: 0.673588, acc: 57.03%] [G loss: 1.526556]\n",
      "epoch:8 step:6523 [D loss: 0.706406, acc: 51.56%] [G loss: 1.586827]\n",
      "epoch:8 step:6524 [D loss: 0.755782, acc: 42.19%] [G loss: 1.591675]\n",
      "epoch:8 step:6525 [D loss: 0.989623, acc: 15.62%] [G loss: 1.401549]\n",
      "epoch:8 step:6526 [D loss: 0.690734, acc: 56.25%] [G loss: 1.475843]\n",
      "epoch:8 step:6527 [D loss: 0.720756, acc: 46.09%] [G loss: 1.486196]\n",
      "epoch:8 step:6528 [D loss: 0.684511, acc: 56.25%] [G loss: 1.501935]\n",
      "epoch:8 step:6529 [D loss: 0.627861, acc: 68.75%] [G loss: 1.647763]\n",
      "epoch:8 step:6530 [D loss: 0.741022, acc: 51.56%] [G loss: 1.346785]\n",
      "epoch:8 step:6531 [D loss: 0.719788, acc: 46.88%] [G loss: 1.496847]\n",
      "epoch:8 step:6532 [D loss: 0.524507, acc: 86.72%] [G loss: 1.487776]\n",
      "epoch:8 step:6533 [D loss: 0.720433, acc: 51.56%] [G loss: 1.570892]\n",
      "epoch:8 step:6534 [D loss: 0.736430, acc: 49.22%] [G loss: 1.419132]\n",
      "epoch:8 step:6535 [D loss: 0.635663, acc: 67.19%] [G loss: 1.619152]\n",
      "epoch:8 step:6536 [D loss: 0.770871, acc: 39.06%] [G loss: 1.625176]\n",
      "epoch:8 step:6537 [D loss: 0.694385, acc: 50.78%] [G loss: 1.630311]\n",
      "epoch:8 step:6538 [D loss: 0.658403, acc: 64.06%] [G loss: 1.633054]\n",
      "epoch:8 step:6539 [D loss: 0.676403, acc: 55.47%] [G loss: 1.582454]\n",
      "epoch:8 step:6540 [D loss: 0.629430, acc: 60.16%] [G loss: 1.528801]\n",
      "epoch:8 step:6541 [D loss: 0.664301, acc: 63.28%] [G loss: 1.617000]\n",
      "epoch:8 step:6542 [D loss: 0.571676, acc: 82.03%] [G loss: 1.674162]\n",
      "epoch:8 step:6543 [D loss: 0.690333, acc: 52.34%] [G loss: 1.619929]\n",
      "epoch:8 step:6544 [D loss: 0.618193, acc: 67.97%] [G loss: 1.653832]\n",
      "epoch:8 step:6545 [D loss: 0.726993, acc: 50.78%] [G loss: 1.567809]\n",
      "epoch:8 step:6546 [D loss: 0.682784, acc: 51.56%] [G loss: 1.556005]\n",
      "epoch:8 step:6547 [D loss: 0.682106, acc: 55.47%] [G loss: 1.715952]\n",
      "epoch:8 step:6548 [D loss: 0.771835, acc: 40.62%] [G loss: 1.523895]\n",
      "epoch:8 step:6549 [D loss: 0.712263, acc: 51.56%] [G loss: 1.746333]\n",
      "epoch:8 step:6550 [D loss: 0.633954, acc: 71.88%] [G loss: 1.655274]\n",
      "epoch:8 step:6551 [D loss: 0.744372, acc: 35.94%] [G loss: 1.476382]\n",
      "epoch:8 step:6552 [D loss: 0.599029, acc: 65.62%] [G loss: 1.534493]\n",
      "epoch:8 step:6553 [D loss: 0.635316, acc: 61.72%] [G loss: 1.673662]\n",
      "epoch:8 step:6554 [D loss: 0.651915, acc: 65.62%] [G loss: 1.735881]\n",
      "epoch:8 step:6555 [D loss: 0.689138, acc: 52.34%] [G loss: 1.386761]\n",
      "epoch:8 step:6556 [D loss: 0.539296, acc: 87.50%] [G loss: 1.692397]\n",
      "epoch:8 step:6557 [D loss: 0.688692, acc: 50.78%] [G loss: 1.264194]\n",
      "epoch:8 step:6558 [D loss: 0.694804, acc: 59.38%] [G loss: 1.475381]\n",
      "epoch:8 step:6559 [D loss: 0.537987, acc: 85.16%] [G loss: 1.687160]\n",
      "epoch:8 step:6560 [D loss: 0.574392, acc: 79.69%] [G loss: 1.727715]\n",
      "epoch:8 step:6561 [D loss: 0.843901, acc: 26.56%] [G loss: 1.521002]\n",
      "epoch:8 step:6562 [D loss: 0.664177, acc: 60.94%] [G loss: 1.623072]\n",
      "epoch:8 step:6563 [D loss: 0.833076, acc: 26.56%] [G loss: 1.376420]\n",
      "epoch:8 step:6564 [D loss: 0.646843, acc: 62.50%] [G loss: 1.675682]\n",
      "epoch:8 step:6565 [D loss: 0.655287, acc: 57.81%] [G loss: 1.551964]\n",
      "epoch:8 step:6566 [D loss: 0.740133, acc: 53.12%] [G loss: 1.467169]\n",
      "epoch:8 step:6567 [D loss: 0.785784, acc: 32.03%] [G loss: 1.611281]\n",
      "epoch:8 step:6568 [D loss: 0.817090, acc: 33.59%] [G loss: 1.384859]\n",
      "epoch:8 step:6569 [D loss: 0.629789, acc: 67.19%] [G loss: 1.635853]\n",
      "epoch:8 step:6570 [D loss: 0.559156, acc: 73.44%] [G loss: 1.511267]\n",
      "epoch:8 step:6571 [D loss: 0.633736, acc: 62.50%] [G loss: 1.760428]\n",
      "epoch:8 step:6572 [D loss: 0.631189, acc: 61.72%] [G loss: 1.509663]\n",
      "epoch:8 step:6573 [D loss: 0.640797, acc: 63.28%] [G loss: 1.717265]\n",
      "epoch:8 step:6574 [D loss: 0.503436, acc: 84.38%] [G loss: 1.902344]\n",
      "epoch:8 step:6575 [D loss: 0.679068, acc: 64.06%] [G loss: 1.842561]\n",
      "epoch:8 step:6576 [D loss: 0.651030, acc: 66.41%] [G loss: 1.554492]\n",
      "epoch:8 step:6577 [D loss: 0.798146, acc: 40.62%] [G loss: 1.500077]\n",
      "epoch:8 step:6578 [D loss: 0.909203, acc: 26.56%] [G loss: 1.541924]\n",
      "epoch:8 step:6579 [D loss: 0.580409, acc: 78.91%] [G loss: 1.455726]\n",
      "epoch:8 step:6580 [D loss: 0.695763, acc: 52.34%] [G loss: 1.526114]\n",
      "epoch:8 step:6581 [D loss: 0.674700, acc: 59.38%] [G loss: 1.713608]\n",
      "epoch:8 step:6582 [D loss: 0.630594, acc: 64.06%] [G loss: 1.597505]\n",
      "epoch:8 step:6583 [D loss: 0.651448, acc: 62.50%] [G loss: 1.630982]\n",
      "epoch:8 step:6584 [D loss: 0.583357, acc: 71.09%] [G loss: 1.542190]\n",
      "epoch:8 step:6585 [D loss: 0.703870, acc: 52.34%] [G loss: 1.640004]\n",
      "epoch:8 step:6586 [D loss: 1.068943, acc: 10.94%] [G loss: 1.305120]\n",
      "epoch:8 step:6587 [D loss: 0.709260, acc: 50.78%] [G loss: 1.592463]\n",
      "epoch:8 step:6588 [D loss: 0.740540, acc: 42.19%] [G loss: 1.484703]\n",
      "epoch:8 step:6589 [D loss: 0.555894, acc: 80.47%] [G loss: 1.660526]\n",
      "epoch:8 step:6590 [D loss: 0.735684, acc: 47.66%] [G loss: 1.589493]\n",
      "epoch:8 step:6591 [D loss: 0.790471, acc: 47.66%] [G loss: 1.302773]\n",
      "epoch:8 step:6592 [D loss: 0.621707, acc: 69.53%] [G loss: 1.424362]\n",
      "epoch:8 step:6593 [D loss: 0.668073, acc: 57.81%] [G loss: 1.756130]\n",
      "epoch:8 step:6594 [D loss: 0.602030, acc: 68.75%] [G loss: 1.412705]\n",
      "epoch:8 step:6595 [D loss: 0.443312, acc: 83.59%] [G loss: 1.474326]\n",
      "epoch:8 step:6596 [D loss: 0.518532, acc: 85.94%] [G loss: 1.659616]\n",
      "epoch:8 step:6597 [D loss: 0.509873, acc: 67.97%] [G loss: 1.335661]\n",
      "epoch:8 step:6598 [D loss: 1.157703, acc: 14.84%] [G loss: 1.317301]\n",
      "epoch:8 step:6599 [D loss: 0.740582, acc: 47.66%] [G loss: 1.787120]\n",
      "epoch:8 step:6600 [D loss: 0.686417, acc: 59.38%] [G loss: 1.539172]\n",
      "epoch:8 step:6601 [D loss: 0.821763, acc: 27.34%] [G loss: 1.511861]\n",
      "epoch:8 step:6602 [D loss: 0.731312, acc: 47.66%] [G loss: 1.573893]\n",
      "epoch:8 step:6603 [D loss: 0.815050, acc: 31.25%] [G loss: 1.572235]\n",
      "epoch:8 step:6604 [D loss: 0.694445, acc: 60.16%] [G loss: 1.774503]\n",
      "epoch:8 step:6605 [D loss: 0.658782, acc: 62.50%] [G loss: 1.599143]\n",
      "epoch:8 step:6606 [D loss: 0.627376, acc: 69.53%] [G loss: 2.037594]\n",
      "epoch:8 step:6607 [D loss: 0.722761, acc: 47.66%] [G loss: 1.595291]\n",
      "epoch:8 step:6608 [D loss: 0.575134, acc: 66.41%] [G loss: 1.694483]\n",
      "epoch:8 step:6609 [D loss: 0.700829, acc: 53.12%] [G loss: 1.563478]\n",
      "epoch:8 step:6610 [D loss: 0.715729, acc: 51.56%] [G loss: 1.731397]\n",
      "epoch:8 step:6611 [D loss: 0.642671, acc: 68.75%] [G loss: 1.824120]\n",
      "epoch:8 step:6612 [D loss: 0.611480, acc: 67.97%] [G loss: 1.760113]\n",
      "epoch:8 step:6613 [D loss: 0.483395, acc: 78.12%] [G loss: 1.871494]\n",
      "epoch:8 step:6614 [D loss: 0.595548, acc: 71.88%] [G loss: 1.526599]\n",
      "epoch:8 step:6615 [D loss: 0.625584, acc: 66.41%] [G loss: 1.531105]\n",
      "epoch:8 step:6616 [D loss: 0.806185, acc: 44.53%] [G loss: 1.480992]\n",
      "epoch:8 step:6617 [D loss: 0.531788, acc: 85.16%] [G loss: 1.609207]\n",
      "epoch:8 step:6618 [D loss: 0.757339, acc: 42.97%] [G loss: 1.292373]\n",
      "epoch:8 step:6619 [D loss: 0.568967, acc: 75.78%] [G loss: 1.592426]\n",
      "epoch:8 step:6620 [D loss: 0.862298, acc: 23.44%] [G loss: 1.555153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6621 [D loss: 1.274175, acc: 7.81%] [G loss: 0.901898]\n",
      "epoch:8 step:6622 [D loss: 0.634905, acc: 65.62%] [G loss: 1.763393]\n",
      "epoch:8 step:6623 [D loss: 0.620443, acc: 69.53%] [G loss: 1.979663]\n",
      "epoch:8 step:6624 [D loss: 0.715552, acc: 58.59%] [G loss: 1.694646]\n",
      "epoch:8 step:6625 [D loss: 0.610207, acc: 60.16%] [G loss: 1.652308]\n",
      "epoch:8 step:6626 [D loss: 0.978616, acc: 12.50%] [G loss: 1.374322]\n",
      "epoch:8 step:6627 [D loss: 0.644330, acc: 60.94%] [G loss: 1.497444]\n",
      "epoch:8 step:6628 [D loss: 0.573010, acc: 82.03%] [G loss: 1.703735]\n",
      "epoch:8 step:6629 [D loss: 0.513893, acc: 86.72%] [G loss: 1.862384]\n",
      "epoch:8 step:6630 [D loss: 0.709580, acc: 53.12%] [G loss: 1.680969]\n",
      "epoch:8 step:6631 [D loss: 0.761911, acc: 46.88%] [G loss: 1.484287]\n",
      "epoch:8 step:6632 [D loss: 0.738614, acc: 48.44%] [G loss: 1.672757]\n",
      "epoch:8 step:6633 [D loss: 0.734449, acc: 50.00%] [G loss: 1.656087]\n",
      "epoch:8 step:6634 [D loss: 0.603556, acc: 66.41%] [G loss: 1.618412]\n",
      "epoch:8 step:6635 [D loss: 0.738891, acc: 39.06%] [G loss: 1.665991]\n",
      "epoch:8 step:6636 [D loss: 0.817852, acc: 24.22%] [G loss: 1.416422]\n",
      "epoch:8 step:6637 [D loss: 0.613484, acc: 70.31%] [G loss: 1.701755]\n",
      "epoch:8 step:6638 [D loss: 0.676169, acc: 56.25%] [G loss: 1.793328]\n",
      "epoch:8 step:6639 [D loss: 0.797902, acc: 36.72%] [G loss: 1.477707]\n",
      "epoch:8 step:6640 [D loss: 0.675398, acc: 63.28%] [G loss: 1.662605]\n",
      "epoch:8 step:6641 [D loss: 0.615115, acc: 70.31%] [G loss: 1.639822]\n",
      "epoch:8 step:6642 [D loss: 0.603370, acc: 72.66%] [G loss: 1.740347]\n",
      "epoch:8 step:6643 [D loss: 0.597903, acc: 70.31%] [G loss: 1.544518]\n",
      "epoch:8 step:6644 [D loss: 0.669080, acc: 57.03%] [G loss: 1.748835]\n",
      "epoch:8 step:6645 [D loss: 0.770899, acc: 37.50%] [G loss: 1.409485]\n",
      "epoch:8 step:6646 [D loss: 0.755631, acc: 40.62%] [G loss: 1.760746]\n",
      "epoch:8 step:6647 [D loss: 0.640438, acc: 63.28%] [G loss: 1.665900]\n",
      "epoch:8 step:6648 [D loss: 0.503133, acc: 87.50%] [G loss: 1.766906]\n",
      "epoch:8 step:6649 [D loss: 0.662650, acc: 60.16%] [G loss: 1.578651]\n",
      "epoch:8 step:6650 [D loss: 0.702482, acc: 53.12%] [G loss: 1.499882]\n",
      "epoch:8 step:6651 [D loss: 0.637623, acc: 64.06%] [G loss: 1.571252]\n",
      "epoch:8 step:6652 [D loss: 0.587555, acc: 76.56%] [G loss: 1.807511]\n",
      "epoch:8 step:6653 [D loss: 0.774932, acc: 46.88%] [G loss: 1.788249]\n",
      "epoch:8 step:6654 [D loss: 0.581250, acc: 74.22%] [G loss: 1.631656]\n",
      "epoch:8 step:6655 [D loss: 0.724722, acc: 46.09%] [G loss: 1.543822]\n",
      "epoch:8 step:6656 [D loss: 0.633513, acc: 60.16%] [G loss: 1.558284]\n",
      "epoch:8 step:6657 [D loss: 0.582148, acc: 75.00%] [G loss: 1.731921]\n",
      "epoch:8 step:6658 [D loss: 0.701497, acc: 51.56%] [G loss: 1.548359]\n",
      "epoch:8 step:6659 [D loss: 0.852689, acc: 27.34%] [G loss: 1.625715]\n",
      "epoch:8 step:6660 [D loss: 0.664676, acc: 60.16%] [G loss: 1.568742]\n",
      "epoch:8 step:6661 [D loss: 0.701507, acc: 53.12%] [G loss: 1.462208]\n",
      "epoch:8 step:6662 [D loss: 0.706454, acc: 54.69%] [G loss: 1.448611]\n",
      "epoch:8 step:6663 [D loss: 0.655083, acc: 60.16%] [G loss: 1.512797]\n",
      "epoch:8 step:6664 [D loss: 0.718877, acc: 45.31%] [G loss: 1.702945]\n",
      "epoch:8 step:6665 [D loss: 0.511565, acc: 73.44%] [G loss: 1.790166]\n",
      "epoch:8 step:6666 [D loss: 0.582955, acc: 71.88%] [G loss: 1.538716]\n",
      "epoch:8 step:6667 [D loss: 0.768525, acc: 49.22%] [G loss: 1.496003]\n",
      "epoch:8 step:6668 [D loss: 0.492599, acc: 84.38%] [G loss: 1.785605]\n",
      "epoch:8 step:6669 [D loss: 0.742578, acc: 46.09%] [G loss: 1.461788]\n",
      "epoch:8 step:6670 [D loss: 0.582708, acc: 75.00%] [G loss: 1.585894]\n",
      "epoch:8 step:6671 [D loss: 0.650404, acc: 64.06%] [G loss: 1.518466]\n",
      "epoch:8 step:6672 [D loss: 0.827386, acc: 35.16%] [G loss: 1.442065]\n",
      "epoch:8 step:6673 [D loss: 0.599379, acc: 71.88%] [G loss: 1.743174]\n",
      "epoch:8 step:6674 [D loss: 0.675542, acc: 60.94%] [G loss: 1.625070]\n",
      "epoch:8 step:6675 [D loss: 0.764310, acc: 37.50%] [G loss: 1.723751]\n",
      "epoch:8 step:6676 [D loss: 0.637961, acc: 67.19%] [G loss: 1.905732]\n",
      "epoch:8 step:6677 [D loss: 0.726553, acc: 47.66%] [G loss: 1.591614]\n",
      "epoch:8 step:6678 [D loss: 0.551883, acc: 77.34%] [G loss: 1.703748]\n",
      "epoch:8 step:6679 [D loss: 0.764047, acc: 38.28%] [G loss: 1.512635]\n",
      "epoch:8 step:6680 [D loss: 0.711452, acc: 46.09%] [G loss: 1.629956]\n",
      "epoch:8 step:6681 [D loss: 0.838628, acc: 30.47%] [G loss: 1.509433]\n",
      "epoch:8 step:6682 [D loss: 0.808225, acc: 42.19%] [G loss: 1.360315]\n",
      "epoch:8 step:6683 [D loss: 0.654856, acc: 60.94%] [G loss: 1.494615]\n",
      "epoch:8 step:6684 [D loss: 0.814839, acc: 42.19%] [G loss: 1.539970]\n",
      "epoch:8 step:6685 [D loss: 0.799514, acc: 32.03%] [G loss: 1.313690]\n",
      "epoch:8 step:6686 [D loss: 0.590950, acc: 72.66%] [G loss: 1.657575]\n",
      "epoch:8 step:6687 [D loss: 0.617690, acc: 67.19%] [G loss: 1.589715]\n",
      "epoch:8 step:6688 [D loss: 0.740769, acc: 49.22%] [G loss: 1.504393]\n",
      "epoch:8 step:6689 [D loss: 0.609663, acc: 74.22%] [G loss: 1.682416]\n",
      "epoch:8 step:6690 [D loss: 0.697494, acc: 49.22%] [G loss: 1.610850]\n",
      "epoch:8 step:6691 [D loss: 0.726272, acc: 43.75%] [G loss: 1.643582]\n",
      "epoch:8 step:6692 [D loss: 0.635610, acc: 65.62%] [G loss: 1.561090]\n",
      "epoch:8 step:6693 [D loss: 0.790147, acc: 32.03%] [G loss: 1.566850]\n",
      "epoch:8 step:6694 [D loss: 0.479102, acc: 69.53%] [G loss: 1.593696]\n",
      "epoch:8 step:6695 [D loss: 0.594723, acc: 80.47%] [G loss: 1.512370]\n",
      "epoch:8 step:6696 [D loss: 0.622125, acc: 67.19%] [G loss: 1.686416]\n",
      "epoch:8 step:6697 [D loss: 0.566176, acc: 79.69%] [G loss: 1.669778]\n",
      "epoch:8 step:6698 [D loss: 0.479868, acc: 88.28%] [G loss: 1.809895]\n",
      "epoch:8 step:6699 [D loss: 0.669302, acc: 55.47%] [G loss: 1.773037]\n",
      "epoch:8 step:6700 [D loss: 0.700965, acc: 55.47%] [G loss: 1.508034]\n",
      "epoch:8 step:6701 [D loss: 0.568469, acc: 70.31%] [G loss: 1.602939]\n",
      "epoch:8 step:6702 [D loss: 0.809483, acc: 38.28%] [G loss: 1.440960]\n",
      "epoch:8 step:6703 [D loss: 0.688556, acc: 53.91%] [G loss: 1.786303]\n",
      "epoch:8 step:6704 [D loss: 0.625946, acc: 67.97%] [G loss: 1.666381]\n",
      "epoch:8 step:6705 [D loss: 0.589118, acc: 70.31%] [G loss: 1.367782]\n",
      "epoch:8 step:6706 [D loss: 0.573429, acc: 78.12%] [G loss: 1.676706]\n",
      "epoch:8 step:6707 [D loss: 0.556051, acc: 80.47%] [G loss: 1.574686]\n",
      "epoch:8 step:6708 [D loss: 0.632336, acc: 66.41%] [G loss: 1.805109]\n",
      "epoch:8 step:6709 [D loss: 0.547029, acc: 82.03%] [G loss: 1.577160]\n",
      "epoch:8 step:6710 [D loss: 0.624041, acc: 67.19%] [G loss: 1.660777]\n",
      "epoch:8 step:6711 [D loss: 0.707460, acc: 52.34%] [G loss: 1.722693]\n",
      "epoch:8 step:6712 [D loss: 0.742759, acc: 49.22%] [G loss: 1.663493]\n",
      "epoch:8 step:6713 [D loss: 0.659184, acc: 64.84%] [G loss: 1.657754]\n",
      "epoch:8 step:6714 [D loss: 0.597667, acc: 75.00%] [G loss: 1.652033]\n",
      "epoch:8 step:6715 [D loss: 0.623448, acc: 65.62%] [G loss: 1.871237]\n",
      "epoch:8 step:6716 [D loss: 0.603359, acc: 71.09%] [G loss: 1.645544]\n",
      "epoch:8 step:6717 [D loss: 0.571870, acc: 75.78%] [G loss: 1.782985]\n",
      "epoch:8 step:6718 [D loss: 0.727603, acc: 53.12%] [G loss: 1.399968]\n",
      "epoch:8 step:6719 [D loss: 0.878754, acc: 24.22%] [G loss: 1.593858]\n",
      "epoch:8 step:6720 [D loss: 0.922379, acc: 31.25%] [G loss: 1.690621]\n",
      "epoch:8 step:6721 [D loss: 0.772104, acc: 46.09%] [G loss: 1.745591]\n",
      "epoch:8 step:6722 [D loss: 0.695757, acc: 55.47%] [G loss: 1.530065]\n",
      "epoch:8 step:6723 [D loss: 0.528214, acc: 78.91%] [G loss: 2.078272]\n",
      "epoch:8 step:6724 [D loss: 0.508704, acc: 88.28%] [G loss: 1.924216]\n",
      "epoch:8 step:6725 [D loss: 0.638045, acc: 62.50%] [G loss: 1.731459]\n",
      "epoch:8 step:6726 [D loss: 0.570695, acc: 71.09%] [G loss: 1.580459]\n",
      "epoch:8 step:6727 [D loss: 0.850345, acc: 27.34%] [G loss: 1.298264]\n",
      "epoch:8 step:6728 [D loss: 0.551366, acc: 79.69%] [G loss: 1.817064]\n",
      "epoch:8 step:6729 [D loss: 0.563065, acc: 78.91%] [G loss: 1.588994]\n",
      "epoch:8 step:6730 [D loss: 0.749067, acc: 51.56%] [G loss: 1.931524]\n",
      "epoch:8 step:6731 [D loss: 0.808242, acc: 44.53%] [G loss: 1.643840]\n",
      "epoch:8 step:6732 [D loss: 0.807472, acc: 41.41%] [G loss: 1.568744]\n",
      "epoch:8 step:6733 [D loss: 0.692207, acc: 57.03%] [G loss: 1.585409]\n",
      "epoch:8 step:6734 [D loss: 0.481968, acc: 88.28%] [G loss: 1.937498]\n",
      "epoch:8 step:6735 [D loss: 0.536917, acc: 76.56%] [G loss: 1.744668]\n",
      "epoch:8 step:6736 [D loss: 0.934840, acc: 25.00%] [G loss: 1.242564]\n",
      "epoch:8 step:6737 [D loss: 0.762435, acc: 45.31%] [G loss: 1.314791]\n",
      "epoch:8 step:6738 [D loss: 0.643911, acc: 61.72%] [G loss: 1.776086]\n",
      "epoch:8 step:6739 [D loss: 0.704664, acc: 51.56%] [G loss: 1.509184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6740 [D loss: 0.784207, acc: 42.97%] [G loss: 1.699776]\n",
      "epoch:8 step:6741 [D loss: 0.724791, acc: 53.12%] [G loss: 1.717541]\n",
      "epoch:8 step:6742 [D loss: 0.857528, acc: 28.12%] [G loss: 1.357588]\n",
      "epoch:8 step:6743 [D loss: 0.651349, acc: 68.75%] [G loss: 1.665492]\n",
      "epoch:8 step:6744 [D loss: 0.550244, acc: 75.78%] [G loss: 2.081200]\n",
      "epoch:8 step:6745 [D loss: 0.596874, acc: 70.31%] [G loss: 1.585162]\n",
      "epoch:8 step:6746 [D loss: 0.594488, acc: 69.53%] [G loss: 1.903078]\n",
      "epoch:8 step:6747 [D loss: 0.721099, acc: 48.44%] [G loss: 1.820051]\n",
      "epoch:8 step:6748 [D loss: 0.842449, acc: 35.94%] [G loss: 1.454010]\n",
      "epoch:8 step:6749 [D loss: 0.588874, acc: 78.12%] [G loss: 1.669398]\n",
      "epoch:8 step:6750 [D loss: 0.496423, acc: 85.16%] [G loss: 1.559893]\n",
      "epoch:8 step:6751 [D loss: 0.643617, acc: 64.84%] [G loss: 1.844959]\n",
      "epoch:8 step:6752 [D loss: 0.670389, acc: 56.25%] [G loss: 1.673406]\n",
      "epoch:8 step:6753 [D loss: 0.798799, acc: 37.50%] [G loss: 1.393278]\n",
      "epoch:8 step:6754 [D loss: 0.781017, acc: 46.88%] [G loss: 1.790731]\n",
      "epoch:8 step:6755 [D loss: 0.451694, acc: 78.12%] [G loss: 1.605365]\n",
      "epoch:8 step:6756 [D loss: 0.656212, acc: 62.50%] [G loss: 1.646172]\n",
      "epoch:8 step:6757 [D loss: 0.641661, acc: 61.72%] [G loss: 1.727260]\n",
      "epoch:8 step:6758 [D loss: 0.548902, acc: 78.91%] [G loss: 1.654571]\n",
      "epoch:8 step:6759 [D loss: 0.601870, acc: 73.44%] [G loss: 1.775478]\n",
      "epoch:8 step:6760 [D loss: 0.511387, acc: 86.72%] [G loss: 1.668348]\n",
      "epoch:8 step:6761 [D loss: 0.800219, acc: 35.94%] [G loss: 1.418303]\n",
      "epoch:8 step:6762 [D loss: 0.675911, acc: 56.25%] [G loss: 1.882019]\n",
      "epoch:8 step:6763 [D loss: 0.918457, acc: 25.78%] [G loss: 1.392056]\n",
      "epoch:8 step:6764 [D loss: 0.853870, acc: 35.94%] [G loss: 1.649286]\n",
      "epoch:8 step:6765 [D loss: 0.693887, acc: 55.47%] [G loss: 1.683735]\n",
      "epoch:8 step:6766 [D loss: 0.681415, acc: 53.12%] [G loss: 1.602273]\n",
      "epoch:8 step:6767 [D loss: 0.699435, acc: 48.44%] [G loss: 1.468368]\n",
      "epoch:8 step:6768 [D loss: 0.658593, acc: 58.59%] [G loss: 1.618068]\n",
      "epoch:8 step:6769 [D loss: 0.506765, acc: 82.81%] [G loss: 1.916561]\n",
      "epoch:8 step:6770 [D loss: 0.763824, acc: 43.75%] [G loss: 1.548917]\n",
      "epoch:8 step:6771 [D loss: 0.772154, acc: 40.62%] [G loss: 1.488314]\n",
      "epoch:8 step:6772 [D loss: 0.708678, acc: 46.09%] [G loss: 1.963240]\n",
      "epoch:8 step:6773 [D loss: 0.708564, acc: 56.25%] [G loss: 1.652439]\n",
      "epoch:8 step:6774 [D loss: 1.084440, acc: 9.38%] [G loss: 1.471072]\n",
      "epoch:8 step:6775 [D loss: 0.810288, acc: 37.50%] [G loss: 1.527889]\n",
      "epoch:8 step:6776 [D loss: 0.674537, acc: 59.38%] [G loss: 1.728594]\n",
      "epoch:8 step:6777 [D loss: 0.677722, acc: 60.16%] [G loss: 1.787159]\n",
      "epoch:8 step:6778 [D loss: 0.894286, acc: 30.47%] [G loss: 1.536706]\n",
      "epoch:8 step:6779 [D loss: 0.730925, acc: 50.00%] [G loss: 1.354752]\n",
      "epoch:8 step:6780 [D loss: 0.719742, acc: 53.91%] [G loss: 1.789260]\n",
      "epoch:8 step:6781 [D loss: 0.533753, acc: 75.00%] [G loss: 1.701070]\n",
      "epoch:8 step:6782 [D loss: 0.660738, acc: 58.59%] [G loss: 1.621692]\n",
      "epoch:8 step:6783 [D loss: 0.628545, acc: 62.50%] [G loss: 1.736636]\n",
      "epoch:8 step:6784 [D loss: 0.533418, acc: 80.47%] [G loss: 1.477041]\n",
      "epoch:8 step:6785 [D loss: 0.586466, acc: 71.09%] [G loss: 1.839998]\n",
      "epoch:8 step:6786 [D loss: 0.862862, acc: 35.16%] [G loss: 1.578027]\n",
      "epoch:8 step:6787 [D loss: 0.801686, acc: 39.06%] [G loss: 1.751267]\n",
      "epoch:8 step:6788 [D loss: 0.608989, acc: 67.97%] [G loss: 1.552864]\n",
      "epoch:8 step:6789 [D loss: 0.554831, acc: 73.44%] [G loss: 1.596334]\n",
      "epoch:8 step:6790 [D loss: 0.587431, acc: 72.66%] [G loss: 1.732542]\n",
      "epoch:8 step:6791 [D loss: 0.915541, acc: 26.56%] [G loss: 1.369058]\n",
      "epoch:8 step:6792 [D loss: 0.551272, acc: 79.69%] [G loss: 1.745898]\n",
      "epoch:8 step:6793 [D loss: 0.500119, acc: 86.72%] [G loss: 1.644200]\n",
      "epoch:8 step:6794 [D loss: 0.673030, acc: 57.03%] [G loss: 1.779789]\n",
      "epoch:8 step:6795 [D loss: 0.423603, acc: 94.53%] [G loss: 1.907369]\n",
      "epoch:8 step:6796 [D loss: 0.605965, acc: 64.06%] [G loss: 1.666233]\n",
      "epoch:8 step:6797 [D loss: 0.818885, acc: 37.50%] [G loss: 1.463730]\n",
      "epoch:8 step:6798 [D loss: 0.656209, acc: 58.59%] [G loss: 1.681797]\n",
      "epoch:8 step:6799 [D loss: 0.619060, acc: 67.19%] [G loss: 1.679159]\n",
      "epoch:8 step:6800 [D loss: 0.893783, acc: 37.50%] [G loss: 1.346601]\n",
      "epoch:8 step:6801 [D loss: 0.797993, acc: 36.72%] [G loss: 1.396760]\n",
      "epoch:8 step:6802 [D loss: 0.562798, acc: 70.31%] [G loss: 1.917046]\n",
      "epoch:8 step:6803 [D loss: 0.722091, acc: 50.78%] [G loss: 1.664222]\n",
      "epoch:8 step:6804 [D loss: 0.737898, acc: 42.97%] [G loss: 1.586823]\n",
      "epoch:8 step:6805 [D loss: 0.637547, acc: 65.62%] [G loss: 1.560505]\n",
      "epoch:8 step:6806 [D loss: 0.731579, acc: 48.44%] [G loss: 1.418954]\n",
      "epoch:8 step:6807 [D loss: 0.559853, acc: 75.78%] [G loss: 1.699198]\n",
      "epoch:8 step:6808 [D loss: 0.549251, acc: 76.56%] [G loss: 1.475861]\n",
      "epoch:8 step:6809 [D loss: 0.740756, acc: 49.22%] [G loss: 1.670253]\n",
      "epoch:8 step:6810 [D loss: 0.558448, acc: 79.69%] [G loss: 1.581099]\n",
      "epoch:8 step:6811 [D loss: 0.802987, acc: 35.16%] [G loss: 1.404428]\n",
      "epoch:8 step:6812 [D loss: 0.801965, acc: 46.09%] [G loss: 1.620275]\n",
      "epoch:8 step:6813 [D loss: 0.639021, acc: 56.25%] [G loss: 1.544756]\n",
      "epoch:8 step:6814 [D loss: 0.866535, acc: 30.47%] [G loss: 1.535803]\n",
      "epoch:8 step:6815 [D loss: 0.696696, acc: 56.25%] [G loss: 1.872173]\n",
      "epoch:8 step:6816 [D loss: 0.553282, acc: 78.12%] [G loss: 1.644515]\n",
      "epoch:8 step:6817 [D loss: 0.500397, acc: 87.50%] [G loss: 1.680745]\n",
      "epoch:8 step:6818 [D loss: 0.425112, acc: 95.31%] [G loss: 2.039078]\n",
      "epoch:8 step:6819 [D loss: 0.734133, acc: 47.66%] [G loss: 1.533987]\n",
      "epoch:8 step:6820 [D loss: 0.536250, acc: 81.25%] [G loss: 1.922716]\n",
      "epoch:8 step:6821 [D loss: 0.719665, acc: 49.22%] [G loss: 1.634851]\n",
      "epoch:8 step:6822 [D loss: 0.716072, acc: 47.66%] [G loss: 1.613237]\n",
      "epoch:8 step:6823 [D loss: 0.753649, acc: 48.44%] [G loss: 1.515936]\n",
      "epoch:8 step:6824 [D loss: 0.711968, acc: 53.91%] [G loss: 1.610125]\n",
      "epoch:8 step:6825 [D loss: 0.395872, acc: 87.50%] [G loss: 1.675879]\n",
      "epoch:8 step:6826 [D loss: 0.674898, acc: 57.03%] [G loss: 1.521059]\n",
      "epoch:8 step:6827 [D loss: 0.749378, acc: 46.09%] [G loss: 1.539413]\n",
      "epoch:8 step:6828 [D loss: 0.543963, acc: 73.44%] [G loss: 1.759100]\n",
      "epoch:8 step:6829 [D loss: 0.565576, acc: 77.34%] [G loss: 1.598926]\n",
      "epoch:8 step:6830 [D loss: 0.784538, acc: 39.84%] [G loss: 1.496238]\n",
      "epoch:8 step:6831 [D loss: 0.710367, acc: 53.91%] [G loss: 1.617538]\n",
      "epoch:8 step:6832 [D loss: 0.823875, acc: 31.25%] [G loss: 1.533121]\n",
      "epoch:8 step:6833 [D loss: 0.661191, acc: 62.50%] [G loss: 1.884483]\n",
      "epoch:8 step:6834 [D loss: 0.707207, acc: 49.22%] [G loss: 1.888507]\n",
      "epoch:8 step:6835 [D loss: 0.695332, acc: 55.47%] [G loss: 1.650217]\n",
      "epoch:8 step:6836 [D loss: 0.720711, acc: 49.22%] [G loss: 1.700059]\n",
      "epoch:8 step:6837 [D loss: 0.801464, acc: 44.53%] [G loss: 1.574090]\n",
      "epoch:8 step:6838 [D loss: 0.895044, acc: 35.16%] [G loss: 1.852442]\n",
      "epoch:8 step:6839 [D loss: 0.672203, acc: 60.94%] [G loss: 1.708617]\n",
      "epoch:8 step:6840 [D loss: 0.617879, acc: 71.09%] [G loss: 1.632555]\n",
      "epoch:8 step:6841 [D loss: 0.633302, acc: 64.06%] [G loss: 1.645041]\n",
      "epoch:8 step:6842 [D loss: 0.688963, acc: 60.94%] [G loss: 1.576157]\n",
      "epoch:8 step:6843 [D loss: 0.665990, acc: 57.03%] [G loss: 1.687852]\n",
      "epoch:8 step:6844 [D loss: 0.706436, acc: 50.00%] [G loss: 1.860249]\n",
      "epoch:8 step:6845 [D loss: 0.577340, acc: 76.56%] [G loss: 2.176540]\n",
      "epoch:8 step:6846 [D loss: 0.726882, acc: 50.00%] [G loss: 1.442603]\n",
      "epoch:8 step:6847 [D loss: 0.684473, acc: 53.12%] [G loss: 1.464627]\n",
      "epoch:8 step:6848 [D loss: 0.685659, acc: 55.47%] [G loss: 1.705329]\n",
      "epoch:8 step:6849 [D loss: 0.698477, acc: 56.25%] [G loss: 1.806418]\n",
      "epoch:8 step:6850 [D loss: 0.686593, acc: 57.81%] [G loss: 1.564939]\n",
      "epoch:8 step:6851 [D loss: 0.564055, acc: 75.00%] [G loss: 1.679465]\n",
      "epoch:8 step:6852 [D loss: 0.838625, acc: 34.38%] [G loss: 1.670175]\n",
      "epoch:8 step:6853 [D loss: 0.695257, acc: 50.78%] [G loss: 1.930381]\n",
      "epoch:8 step:6854 [D loss: 0.816495, acc: 30.47%] [G loss: 1.890190]\n",
      "epoch:8 step:6855 [D loss: 0.707581, acc: 55.47%] [G loss: 1.662112]\n",
      "epoch:8 step:6856 [D loss: 0.510434, acc: 80.47%] [G loss: 1.738446]\n",
      "epoch:8 step:6857 [D loss: 0.618006, acc: 66.41%] [G loss: 1.898906]\n",
      "epoch:8 step:6858 [D loss: 0.657737, acc: 60.94%] [G loss: 1.472288]\n",
      "epoch:8 step:6859 [D loss: 0.474886, acc: 85.94%] [G loss: 1.617555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6860 [D loss: 0.771142, acc: 42.19%] [G loss: 1.581818]\n",
      "epoch:8 step:6861 [D loss: 0.625991, acc: 65.62%] [G loss: 1.639289]\n",
      "epoch:8 step:6862 [D loss: 0.882361, acc: 19.53%] [G loss: 1.284712]\n",
      "epoch:8 step:6863 [D loss: 0.793205, acc: 51.56%] [G loss: 1.516137]\n",
      "epoch:8 step:6864 [D loss: 1.075188, acc: 14.84%] [G loss: 1.272226]\n",
      "epoch:8 step:6865 [D loss: 0.615317, acc: 65.62%] [G loss: 1.760716]\n",
      "epoch:8 step:6866 [D loss: 0.798265, acc: 42.19%] [G loss: 1.553751]\n",
      "epoch:8 step:6867 [D loss: 0.830045, acc: 40.62%] [G loss: 1.355110]\n",
      "epoch:8 step:6868 [D loss: 0.866046, acc: 26.56%] [G loss: 1.366101]\n",
      "epoch:8 step:6869 [D loss: 0.659551, acc: 62.50%] [G loss: 2.051038]\n",
      "epoch:8 step:6870 [D loss: 0.754104, acc: 42.97%] [G loss: 1.778720]\n",
      "epoch:8 step:6871 [D loss: 0.593702, acc: 69.53%] [G loss: 1.672114]\n",
      "epoch:8 step:6872 [D loss: 0.681484, acc: 57.03%] [G loss: 1.546136]\n",
      "epoch:8 step:6873 [D loss: 0.601705, acc: 68.75%] [G loss: 1.668339]\n",
      "epoch:8 step:6874 [D loss: 0.619624, acc: 66.41%] [G loss: 1.682575]\n",
      "epoch:8 step:6875 [D loss: 0.790507, acc: 35.94%] [G loss: 1.554049]\n",
      "epoch:8 step:6876 [D loss: 0.644399, acc: 65.62%] [G loss: 1.643579]\n",
      "epoch:8 step:6877 [D loss: 0.572594, acc: 75.00%] [G loss: 1.634295]\n",
      "epoch:8 step:6878 [D loss: 0.625013, acc: 70.31%] [G loss: 1.623249]\n",
      "epoch:8 step:6879 [D loss: 0.582988, acc: 72.66%] [G loss: 1.578723]\n",
      "epoch:8 step:6880 [D loss: 1.108603, acc: 12.50%] [G loss: 1.305461]\n",
      "epoch:8 step:6881 [D loss: 0.947278, acc: 18.75%] [G loss: 1.551706]\n",
      "epoch:8 step:6882 [D loss: 0.647179, acc: 64.84%] [G loss: 1.606751]\n",
      "epoch:8 step:6883 [D loss: 0.541893, acc: 82.03%] [G loss: 1.700923]\n",
      "epoch:8 step:6884 [D loss: 0.715241, acc: 48.44%] [G loss: 1.591426]\n",
      "epoch:8 step:6885 [D loss: 0.910629, acc: 25.78%] [G loss: 1.382338]\n",
      "epoch:8 step:6886 [D loss: 0.769875, acc: 35.16%] [G loss: 1.591563]\n",
      "epoch:8 step:6887 [D loss: 0.835028, acc: 34.38%] [G loss: 1.613629]\n",
      "epoch:8 step:6888 [D loss: 0.615137, acc: 68.75%] [G loss: 1.823063]\n",
      "epoch:8 step:6889 [D loss: 0.730511, acc: 49.22%] [G loss: 1.600478]\n",
      "epoch:8 step:6890 [D loss: 0.607780, acc: 75.00%] [G loss: 2.000014]\n",
      "epoch:8 step:6891 [D loss: 0.364013, acc: 80.47%] [G loss: 2.026473]\n",
      "epoch:8 step:6892 [D loss: 0.745849, acc: 42.19%] [G loss: 1.671863]\n",
      "epoch:8 step:6893 [D loss: 0.661506, acc: 65.62%] [G loss: 1.578245]\n",
      "epoch:8 step:6894 [D loss: 0.769567, acc: 42.19%] [G loss: 1.551231]\n",
      "epoch:8 step:6895 [D loss: 0.665963, acc: 55.47%] [G loss: 1.876797]\n",
      "epoch:8 step:6896 [D loss: 0.578129, acc: 77.34%] [G loss: 1.435293]\n",
      "epoch:8 step:6897 [D loss: 0.845767, acc: 34.38%] [G loss: 1.308213]\n",
      "epoch:8 step:6898 [D loss: 0.676097, acc: 59.38%] [G loss: 1.697356]\n",
      "epoch:8 step:6899 [D loss: 0.721121, acc: 50.78%] [G loss: 1.688321]\n",
      "epoch:8 step:6900 [D loss: 0.683556, acc: 53.12%] [G loss: 1.592930]\n",
      "epoch:8 step:6901 [D loss: 0.805136, acc: 41.41%] [G loss: 1.554139]\n",
      "epoch:8 step:6902 [D loss: 0.669939, acc: 58.59%] [G loss: 1.807575]\n",
      "epoch:8 step:6903 [D loss: 0.730303, acc: 50.78%] [G loss: 1.440194]\n",
      "epoch:8 step:6904 [D loss: 0.837743, acc: 28.12%] [G loss: 1.506296]\n",
      "epoch:8 step:6905 [D loss: 0.625901, acc: 66.41%] [G loss: 1.600846]\n",
      "epoch:8 step:6906 [D loss: 0.753808, acc: 39.06%] [G loss: 1.452731]\n",
      "epoch:8 step:6907 [D loss: 0.683089, acc: 57.81%] [G loss: 1.688288]\n",
      "epoch:8 step:6908 [D loss: 0.615087, acc: 68.75%] [G loss: 1.466901]\n",
      "epoch:8 step:6909 [D loss: 0.792088, acc: 35.94%] [G loss: 1.543440]\n",
      "epoch:8 step:6910 [D loss: 0.536697, acc: 85.94%] [G loss: 1.703177]\n",
      "epoch:8 step:6911 [D loss: 0.684180, acc: 57.03%] [G loss: 1.633141]\n",
      "epoch:8 step:6912 [D loss: 0.550185, acc: 81.25%] [G loss: 1.737299]\n",
      "epoch:8 step:6913 [D loss: 0.607081, acc: 67.19%] [G loss: 1.756137]\n",
      "epoch:8 step:6914 [D loss: 0.610399, acc: 69.53%] [G loss: 1.568934]\n",
      "epoch:8 step:6915 [D loss: 0.654373, acc: 60.16%] [G loss: 1.521648]\n",
      "epoch:8 step:6916 [D loss: 0.704428, acc: 56.25%] [G loss: 1.512268]\n",
      "epoch:8 step:6917 [D loss: 0.579372, acc: 69.53%] [G loss: 1.715027]\n",
      "epoch:8 step:6918 [D loss: 0.774747, acc: 45.31%] [G loss: 1.353383]\n",
      "epoch:8 step:6919 [D loss: 0.553418, acc: 82.81%] [G loss: 1.866541]\n",
      "epoch:8 step:6920 [D loss: 0.831910, acc: 27.34%] [G loss: 1.332642]\n",
      "epoch:8 step:6921 [D loss: 0.732217, acc: 50.00%] [G loss: 1.548776]\n",
      "epoch:8 step:6922 [D loss: 0.684840, acc: 64.06%] [G loss: 1.652383]\n",
      "epoch:8 step:6923 [D loss: 0.563922, acc: 81.25%] [G loss: 1.643302]\n",
      "epoch:8 step:6924 [D loss: 0.662449, acc: 61.72%] [G loss: 1.675889]\n",
      "epoch:8 step:6925 [D loss: 0.558971, acc: 83.59%] [G loss: 1.737838]\n",
      "epoch:8 step:6926 [D loss: 0.673355, acc: 60.16%] [G loss: 1.564160]\n",
      "epoch:8 step:6927 [D loss: 0.800694, acc: 31.25%] [G loss: 1.301117]\n",
      "epoch:8 step:6928 [D loss: 0.515704, acc: 91.41%] [G loss: 1.638058]\n",
      "epoch:8 step:6929 [D loss: 0.615355, acc: 67.19%] [G loss: 1.676761]\n",
      "epoch:8 step:6930 [D loss: 0.886048, acc: 40.62%] [G loss: 1.528920]\n",
      "epoch:8 step:6931 [D loss: 0.711268, acc: 53.91%] [G loss: 1.539054]\n",
      "epoch:8 step:6932 [D loss: 0.699265, acc: 51.56%] [G loss: 1.588631]\n",
      "epoch:8 step:6933 [D loss: 0.700928, acc: 53.12%] [G loss: 1.588148]\n",
      "epoch:8 step:6934 [D loss: 0.617779, acc: 68.75%] [G loss: 1.668631]\n",
      "epoch:8 step:6935 [D loss: 0.800135, acc: 32.81%] [G loss: 1.510402]\n",
      "epoch:8 step:6936 [D loss: 0.722306, acc: 48.44%] [G loss: 1.594068]\n",
      "epoch:8 step:6937 [D loss: 0.726876, acc: 42.97%] [G loss: 1.545683]\n",
      "epoch:8 step:6938 [D loss: 0.723150, acc: 53.12%] [G loss: 1.607638]\n",
      "epoch:8 step:6939 [D loss: 0.575207, acc: 69.53%] [G loss: 1.647578]\n",
      "epoch:8 step:6940 [D loss: 0.965793, acc: 29.69%] [G loss: 1.545596]\n",
      "epoch:8 step:6941 [D loss: 0.646741, acc: 57.03%] [G loss: 1.680079]\n",
      "epoch:8 step:6942 [D loss: 0.506244, acc: 82.81%] [G loss: 1.860914]\n",
      "epoch:8 step:6943 [D loss: 0.721237, acc: 53.91%] [G loss: 1.541187]\n",
      "epoch:8 step:6944 [D loss: 0.686837, acc: 55.47%] [G loss: 1.664605]\n",
      "epoch:8 step:6945 [D loss: 0.574867, acc: 76.56%] [G loss: 1.906799]\n",
      "epoch:8 step:6946 [D loss: 0.595707, acc: 72.66%] [G loss: 1.672640]\n",
      "epoch:8 step:6947 [D loss: 0.499465, acc: 83.59%] [G loss: 1.592202]\n",
      "epoch:8 step:6948 [D loss: 0.597339, acc: 77.34%] [G loss: 1.544360]\n",
      "epoch:8 step:6949 [D loss: 0.632546, acc: 69.53%] [G loss: 1.690497]\n",
      "epoch:8 step:6950 [D loss: 0.623044, acc: 69.53%] [G loss: 1.694365]\n",
      "epoch:8 step:6951 [D loss: 0.505097, acc: 85.16%] [G loss: 1.786461]\n",
      "epoch:8 step:6952 [D loss: 0.835889, acc: 28.91%] [G loss: 1.406650]\n",
      "epoch:8 step:6953 [D loss: 0.437736, acc: 94.53%] [G loss: 1.802549]\n",
      "epoch:8 step:6954 [D loss: 0.378792, acc: 95.31%] [G loss: 1.768635]\n",
      "epoch:8 step:6955 [D loss: 0.671721, acc: 62.50%] [G loss: 1.660558]\n",
      "epoch:8 step:6956 [D loss: 0.797587, acc: 33.59%] [G loss: 1.640628]\n",
      "epoch:8 step:6957 [D loss: 0.669679, acc: 56.25%] [G loss: 1.723458]\n",
      "epoch:8 step:6958 [D loss: 0.534984, acc: 70.31%] [G loss: 1.548132]\n",
      "epoch:8 step:6959 [D loss: 0.649691, acc: 55.47%] [G loss: 1.513713]\n",
      "epoch:8 step:6960 [D loss: 0.543766, acc: 78.12%] [G loss: 1.608698]\n",
      "epoch:8 step:6961 [D loss: 0.654306, acc: 58.59%] [G loss: 1.625659]\n",
      "epoch:8 step:6962 [D loss: 0.508049, acc: 80.47%] [G loss: 1.561696]\n",
      "epoch:8 step:6963 [D loss: 0.723057, acc: 52.34%] [G loss: 1.138318]\n",
      "epoch:8 step:6964 [D loss: 0.787274, acc: 50.78%] [G loss: 1.951623]\n",
      "epoch:8 step:6965 [D loss: 0.634115, acc: 65.62%] [G loss: 1.796440]\n",
      "epoch:8 step:6966 [D loss: 0.793535, acc: 34.38%] [G loss: 1.606181]\n",
      "epoch:8 step:6967 [D loss: 0.639588, acc: 66.41%] [G loss: 1.692167]\n",
      "epoch:8 step:6968 [D loss: 0.705333, acc: 48.44%] [G loss: 1.532187]\n",
      "epoch:8 step:6969 [D loss: 0.817673, acc: 32.81%] [G loss: 1.635281]\n",
      "epoch:8 step:6970 [D loss: 0.645434, acc: 61.72%] [G loss: 1.646899]\n",
      "epoch:8 step:6971 [D loss: 1.202605, acc: 35.16%] [G loss: 1.816721]\n",
      "epoch:8 step:6972 [D loss: 0.544564, acc: 73.44%] [G loss: 1.908540]\n",
      "epoch:8 step:6973 [D loss: 0.502977, acc: 84.38%] [G loss: 1.858274]\n",
      "epoch:8 step:6974 [D loss: 0.737352, acc: 50.00%] [G loss: 1.494979]\n",
      "epoch:8 step:6975 [D loss: 0.679466, acc: 56.25%] [G loss: 1.808403]\n",
      "epoch:8 step:6976 [D loss: 0.704437, acc: 54.69%] [G loss: 1.654438]\n",
      "epoch:8 step:6977 [D loss: 0.432681, acc: 80.47%] [G loss: 1.909177]\n",
      "epoch:8 step:6978 [D loss: 0.318444, acc: 95.31%] [G loss: 1.790251]\n",
      "epoch:8 step:6979 [D loss: 0.471330, acc: 89.84%] [G loss: 1.440540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6980 [D loss: 0.858079, acc: 44.53%] [G loss: 1.610338]\n",
      "epoch:8 step:6981 [D loss: 0.664141, acc: 58.59%] [G loss: 1.490497]\n",
      "epoch:8 step:6982 [D loss: 0.572822, acc: 74.22%] [G loss: 1.605353]\n",
      "epoch:8 step:6983 [D loss: 0.684607, acc: 52.34%] [G loss: 1.517347]\n",
      "epoch:8 step:6984 [D loss: 0.743575, acc: 42.97%] [G loss: 1.337314]\n",
      "epoch:8 step:6985 [D loss: 0.339197, acc: 100.00%] [G loss: 1.667002]\n",
      "epoch:8 step:6986 [D loss: 0.513284, acc: 88.28%] [G loss: 1.716743]\n",
      "epoch:8 step:6987 [D loss: 0.432466, acc: 92.97%] [G loss: 1.752496]\n",
      "epoch:8 step:6988 [D loss: 0.943795, acc: 21.88%] [G loss: 1.127840]\n",
      "epoch:8 step:6989 [D loss: 0.809117, acc: 50.00%] [G loss: 1.716186]\n",
      "epoch:8 step:6990 [D loss: 0.612916, acc: 59.38%] [G loss: 1.713074]\n",
      "epoch:8 step:6991 [D loss: 0.464034, acc: 73.44%] [G loss: 1.662677]\n",
      "epoch:8 step:6992 [D loss: 0.678920, acc: 58.59%] [G loss: 1.626064]\n",
      "epoch:8 step:6993 [D loss: 0.680027, acc: 53.91%] [G loss: 1.558185]\n",
      "epoch:8 step:6994 [D loss: 0.671148, acc: 59.38%] [G loss: 1.727486]\n",
      "epoch:8 step:6995 [D loss: 0.822530, acc: 33.59%] [G loss: 1.747297]\n",
      "epoch:8 step:6996 [D loss: 0.673913, acc: 59.38%] [G loss: 1.727489]\n",
      "epoch:8 step:6997 [D loss: 0.829209, acc: 42.97%] [G loss: 1.664486]\n",
      "epoch:8 step:6998 [D loss: 0.579268, acc: 64.84%] [G loss: 1.836862]\n",
      "epoch:8 step:6999 [D loss: 0.863945, acc: 32.03%] [G loss: 1.512007]\n",
      "epoch:8 step:7000 [D loss: 0.652557, acc: 57.81%] [G loss: 1.640905]\n",
      "epoch:8 step:7001 [D loss: 0.632824, acc: 67.19%] [G loss: 1.721319]\n",
      "epoch:8 step:7002 [D loss: 0.772897, acc: 40.62%] [G loss: 1.567888]\n",
      "epoch:8 step:7003 [D loss: 0.620659, acc: 55.47%] [G loss: 1.944974]\n",
      "epoch:8 step:7004 [D loss: 0.884611, acc: 42.97%] [G loss: 1.507944]\n",
      "epoch:8 step:7005 [D loss: 0.565347, acc: 71.09%] [G loss: 1.533268]\n",
      "epoch:8 step:7006 [D loss: 0.564255, acc: 78.12%] [G loss: 1.794834]\n",
      "epoch:8 step:7007 [D loss: 0.674407, acc: 59.38%] [G loss: 1.662199]\n",
      "epoch:8 step:7008 [D loss: 0.750433, acc: 42.19%] [G loss: 1.565116]\n",
      "epoch:8 step:7009 [D loss: 0.756987, acc: 49.22%] [G loss: 1.618933]\n",
      "epoch:8 step:7010 [D loss: 0.619783, acc: 58.59%] [G loss: 1.344280]\n",
      "epoch:8 step:7011 [D loss: 0.792002, acc: 46.09%] [G loss: 1.505933]\n",
      "epoch:8 step:7012 [D loss: 0.724834, acc: 56.25%] [G loss: 1.482027]\n",
      "epoch:8 step:7013 [D loss: 0.754218, acc: 41.41%] [G loss: 1.573939]\n",
      "epoch:8 step:7014 [D loss: 0.458103, acc: 90.62%] [G loss: 1.760414]\n",
      "epoch:8 step:7015 [D loss: 0.396217, acc: 93.75%] [G loss: 1.724277]\n",
      "epoch:8 step:7016 [D loss: 0.690267, acc: 55.47%] [G loss: 1.563680]\n",
      "epoch:8 step:7017 [D loss: 0.658900, acc: 60.94%] [G loss: 2.026950]\n",
      "epoch:8 step:7018 [D loss: 0.558350, acc: 82.81%] [G loss: 1.622449]\n",
      "epoch:8 step:7019 [D loss: 1.084998, acc: 10.94%] [G loss: 1.549489]\n",
      "epoch:8 step:7020 [D loss: 0.571621, acc: 75.78%] [G loss: 1.713935]\n",
      "epoch:8 step:7021 [D loss: 0.427764, acc: 95.31%] [G loss: 1.847026]\n",
      "epoch:8 step:7022 [D loss: 0.538797, acc: 77.34%] [G loss: 1.830759]\n",
      "epoch:8 step:7023 [D loss: 0.604702, acc: 69.53%] [G loss: 1.725320]\n",
      "epoch:8 step:7024 [D loss: 0.606896, acc: 71.88%] [G loss: 1.750365]\n",
      "epoch:8 step:7025 [D loss: 1.046852, acc: 14.06%] [G loss: 1.477970]\n",
      "epoch:8 step:7026 [D loss: 0.787293, acc: 36.72%] [G loss: 1.730091]\n",
      "epoch:8 step:7027 [D loss: 0.791960, acc: 39.06%] [G loss: 1.607902]\n",
      "epoch:8 step:7028 [D loss: 0.765229, acc: 48.44%] [G loss: 1.562187]\n",
      "epoch:8 step:7029 [D loss: 0.760399, acc: 48.44%] [G loss: 1.622909]\n",
      "epoch:9 step:7030 [D loss: 0.631481, acc: 66.41%] [G loss: 1.589289]\n",
      "epoch:9 step:7031 [D loss: 0.545496, acc: 73.44%] [G loss: 1.784667]\n",
      "epoch:9 step:7032 [D loss: 0.767454, acc: 46.88%] [G loss: 1.547772]\n",
      "epoch:9 step:7033 [D loss: 0.482740, acc: 79.69%] [G loss: 1.654696]\n",
      "epoch:9 step:7034 [D loss: 0.830935, acc: 32.03%] [G loss: 1.425736]\n",
      "epoch:9 step:7035 [D loss: 0.496687, acc: 89.06%] [G loss: 1.756427]\n",
      "epoch:9 step:7036 [D loss: 0.708076, acc: 54.69%] [G loss: 1.646962]\n",
      "epoch:9 step:7037 [D loss: 0.741058, acc: 50.00%] [G loss: 1.690309]\n",
      "epoch:9 step:7038 [D loss: 0.590542, acc: 69.53%] [G loss: 1.644325]\n",
      "epoch:9 step:7039 [D loss: 0.876917, acc: 24.22%] [G loss: 1.859218]\n",
      "epoch:9 step:7040 [D loss: 0.667501, acc: 52.34%] [G loss: 1.710526]\n",
      "epoch:9 step:7041 [D loss: 0.717023, acc: 50.00%] [G loss: 1.488887]\n",
      "epoch:9 step:7042 [D loss: 0.441425, acc: 85.94%] [G loss: 1.784277]\n",
      "epoch:9 step:7043 [D loss: 0.641492, acc: 62.50%] [G loss: 1.659534]\n",
      "epoch:9 step:7044 [D loss: 0.798567, acc: 35.94%] [G loss: 1.425057]\n",
      "epoch:9 step:7045 [D loss: 0.651284, acc: 64.84%] [G loss: 1.592474]\n",
      "epoch:9 step:7046 [D loss: 0.589985, acc: 66.41%] [G loss: 1.590933]\n",
      "epoch:9 step:7047 [D loss: 0.696407, acc: 50.78%] [G loss: 1.557358]\n",
      "epoch:9 step:7048 [D loss: 0.706926, acc: 56.25%] [G loss: 1.453595]\n",
      "epoch:9 step:7049 [D loss: 0.669232, acc: 53.91%] [G loss: 1.429705]\n",
      "epoch:9 step:7050 [D loss: 0.627271, acc: 57.81%] [G loss: 1.272415]\n",
      "epoch:9 step:7051 [D loss: 0.431504, acc: 85.94%] [G loss: 1.911757]\n",
      "epoch:9 step:7052 [D loss: 0.865270, acc: 27.34%] [G loss: 1.441901]\n",
      "epoch:9 step:7053 [D loss: 0.567619, acc: 74.22%] [G loss: 2.017172]\n",
      "epoch:9 step:7054 [D loss: 0.488881, acc: 87.50%] [G loss: 1.684931]\n",
      "epoch:9 step:7055 [D loss: 0.397747, acc: 93.75%] [G loss: 2.087038]\n",
      "epoch:9 step:7056 [D loss: 0.651144, acc: 58.59%] [G loss: 1.457008]\n",
      "epoch:9 step:7057 [D loss: 0.720103, acc: 47.66%] [G loss: 1.519503]\n",
      "epoch:9 step:7058 [D loss: 0.598124, acc: 69.53%] [G loss: 1.536574]\n",
      "epoch:9 step:7059 [D loss: 0.619514, acc: 65.62%] [G loss: 1.722271]\n",
      "epoch:9 step:7060 [D loss: 0.910709, acc: 25.78%] [G loss: 1.408114]\n",
      "epoch:9 step:7061 [D loss: 0.621688, acc: 62.50%] [G loss: 1.735601]\n",
      "epoch:9 step:7062 [D loss: 0.433023, acc: 88.28%] [G loss: 1.820139]\n",
      "epoch:9 step:7063 [D loss: 0.650645, acc: 59.38%] [G loss: 1.830040]\n",
      "epoch:9 step:7064 [D loss: 0.854291, acc: 31.25%] [G loss: 1.520359]\n",
      "epoch:9 step:7065 [D loss: 0.761343, acc: 45.31%] [G loss: 1.642800]\n",
      "epoch:9 step:7066 [D loss: 0.656695, acc: 58.59%] [G loss: 1.803491]\n",
      "epoch:9 step:7067 [D loss: 0.669607, acc: 61.72%] [G loss: 2.293463]\n",
      "epoch:9 step:7068 [D loss: 0.390859, acc: 77.34%] [G loss: 1.734154]\n",
      "epoch:9 step:7069 [D loss: 0.557640, acc: 82.03%] [G loss: 1.772143]\n",
      "epoch:9 step:7070 [D loss: 0.636233, acc: 57.81%] [G loss: 1.861522]\n",
      "epoch:9 step:7071 [D loss: 0.547959, acc: 78.12%] [G loss: 1.688129]\n",
      "epoch:9 step:7072 [D loss: 1.169287, acc: 12.50%] [G loss: 1.592929]\n",
      "epoch:9 step:7073 [D loss: 0.619790, acc: 69.53%] [G loss: 1.490698]\n",
      "epoch:9 step:7074 [D loss: 0.791875, acc: 49.22%] [G loss: 1.450271]\n",
      "epoch:9 step:7075 [D loss: 0.449177, acc: 92.19%] [G loss: 1.716295]\n",
      "epoch:9 step:7076 [D loss: 0.598480, acc: 67.97%] [G loss: 1.407680]\n",
      "epoch:9 step:7077 [D loss: 0.659847, acc: 59.38%] [G loss: 1.668223]\n",
      "epoch:9 step:7078 [D loss: 0.740505, acc: 46.88%] [G loss: 1.657955]\n",
      "epoch:9 step:7079 [D loss: 1.262025, acc: 3.12%] [G loss: 1.482996]\n",
      "epoch:9 step:7080 [D loss: 0.502415, acc: 85.16%] [G loss: 1.497219]\n",
      "epoch:9 step:7081 [D loss: 0.727136, acc: 53.91%] [G loss: 1.703981]\n",
      "epoch:9 step:7082 [D loss: 0.686671, acc: 60.16%] [G loss: 1.621864]\n",
      "epoch:9 step:7083 [D loss: 0.907885, acc: 33.59%] [G loss: 1.322338]\n",
      "epoch:9 step:7084 [D loss: 0.643178, acc: 64.06%] [G loss: 1.634207]\n",
      "epoch:9 step:7085 [D loss: 1.060402, acc: 11.72%] [G loss: 1.388556]\n",
      "epoch:9 step:7086 [D loss: 0.588748, acc: 76.56%] [G loss: 1.555382]\n",
      "epoch:9 step:7087 [D loss: 0.646911, acc: 60.16%] [G loss: 1.580551]\n",
      "epoch:9 step:7088 [D loss: 0.647765, acc: 66.41%] [G loss: 1.704209]\n",
      "epoch:9 step:7089 [D loss: 0.587647, acc: 74.22%] [G loss: 1.790487]\n",
      "epoch:9 step:7090 [D loss: 0.701746, acc: 48.44%] [G loss: 1.641946]\n",
      "epoch:9 step:7091 [D loss: 0.753766, acc: 47.66%] [G loss: 1.636972]\n",
      "epoch:9 step:7092 [D loss: 0.605986, acc: 67.19%] [G loss: 1.796529]\n",
      "epoch:9 step:7093 [D loss: 0.691646, acc: 52.34%] [G loss: 1.666603]\n",
      "epoch:9 step:7094 [D loss: 0.824260, acc: 39.06%] [G loss: 1.553344]\n",
      "epoch:9 step:7095 [D loss: 0.627545, acc: 67.19%] [G loss: 1.857479]\n",
      "epoch:9 step:7096 [D loss: 0.704258, acc: 53.91%] [G loss: 1.511113]\n",
      "epoch:9 step:7097 [D loss: 0.548412, acc: 78.91%] [G loss: 1.558557]\n",
      "epoch:9 step:7098 [D loss: 0.573229, acc: 71.09%] [G loss: 1.553405]\n",
      "epoch:9 step:7099 [D loss: 0.579814, acc: 68.75%] [G loss: 1.801354]\n",
      "epoch:9 step:7100 [D loss: 0.989178, acc: 16.41%] [G loss: 1.469692]\n",
      "epoch:9 step:7101 [D loss: 0.721385, acc: 50.78%] [G loss: 1.340676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7102 [D loss: 0.630057, acc: 60.94%] [G loss: 1.793205]\n",
      "epoch:9 step:7103 [D loss: 0.670320, acc: 56.25%] [G loss: 1.643616]\n",
      "epoch:9 step:7104 [D loss: 0.613362, acc: 66.41%] [G loss: 1.762859]\n",
      "epoch:9 step:7105 [D loss: 0.707366, acc: 55.47%] [G loss: 1.527569]\n",
      "epoch:9 step:7106 [D loss: 0.578655, acc: 75.78%] [G loss: 1.945256]\n",
      "epoch:9 step:7107 [D loss: 0.758852, acc: 47.66%] [G loss: 1.513620]\n",
      "epoch:9 step:7108 [D loss: 0.632976, acc: 62.50%] [G loss: 1.605347]\n",
      "epoch:9 step:7109 [D loss: 0.512754, acc: 84.38%] [G loss: 1.854332]\n",
      "epoch:9 step:7110 [D loss: 0.680528, acc: 58.59%] [G loss: 1.723554]\n",
      "epoch:9 step:7111 [D loss: 0.774232, acc: 37.50%] [G loss: 1.446467]\n",
      "epoch:9 step:7112 [D loss: 0.762296, acc: 38.28%] [G loss: 1.622913]\n",
      "epoch:9 step:7113 [D loss: 0.980284, acc: 32.03%] [G loss: 1.173147]\n",
      "epoch:9 step:7114 [D loss: 0.577245, acc: 71.88%] [G loss: 1.678893]\n",
      "epoch:9 step:7115 [D loss: 0.615905, acc: 67.97%] [G loss: 1.613376]\n",
      "epoch:9 step:7116 [D loss: 0.728803, acc: 44.53%] [G loss: 1.788685]\n",
      "epoch:9 step:7117 [D loss: 0.893894, acc: 28.12%] [G loss: 1.343520]\n",
      "epoch:9 step:7118 [D loss: 0.564363, acc: 80.47%] [G loss: 1.574443]\n",
      "epoch:9 step:7119 [D loss: 0.818472, acc: 31.25%] [G loss: 1.601449]\n",
      "epoch:9 step:7120 [D loss: 0.542028, acc: 73.44%] [G loss: 1.486479]\n",
      "epoch:9 step:7121 [D loss: 0.692740, acc: 47.66%] [G loss: 1.468679]\n",
      "epoch:9 step:7122 [D loss: 0.567411, acc: 79.69%] [G loss: 1.702559]\n",
      "epoch:9 step:7123 [D loss: 0.687605, acc: 56.25%] [G loss: 1.276045]\n",
      "epoch:9 step:7124 [D loss: 0.550060, acc: 80.47%] [G loss: 1.690180]\n",
      "epoch:9 step:7125 [D loss: 0.501332, acc: 75.78%] [G loss: 1.581825]\n",
      "epoch:9 step:7126 [D loss: 0.544392, acc: 77.34%] [G loss: 1.701434]\n",
      "epoch:9 step:7127 [D loss: 0.506618, acc: 90.62%] [G loss: 1.964003]\n",
      "epoch:9 step:7128 [D loss: 0.706346, acc: 52.34%] [G loss: 1.534267]\n",
      "epoch:9 step:7129 [D loss: 0.554030, acc: 75.78%] [G loss: 1.707539]\n",
      "epoch:9 step:7130 [D loss: 0.721774, acc: 44.53%] [G loss: 1.703543]\n",
      "epoch:9 step:7131 [D loss: 0.644240, acc: 59.38%] [G loss: 1.619809]\n",
      "epoch:9 step:7132 [D loss: 0.687467, acc: 55.47%] [G loss: 1.752774]\n",
      "epoch:9 step:7133 [D loss: 0.865807, acc: 27.34%] [G loss: 1.422871]\n",
      "epoch:9 step:7134 [D loss: 0.760890, acc: 40.62%] [G loss: 1.566743]\n",
      "epoch:9 step:7135 [D loss: 0.687767, acc: 52.34%] [G loss: 1.955144]\n",
      "epoch:9 step:7136 [D loss: 0.809112, acc: 46.09%] [G loss: 1.842406]\n",
      "epoch:9 step:7137 [D loss: 0.884401, acc: 33.59%] [G loss: 1.569734]\n",
      "epoch:9 step:7138 [D loss: 0.710324, acc: 50.00%] [G loss: 1.749838]\n",
      "epoch:9 step:7139 [D loss: 0.557364, acc: 75.78%] [G loss: 1.426075]\n",
      "epoch:9 step:7140 [D loss: 0.733693, acc: 42.19%] [G loss: 1.449871]\n",
      "epoch:9 step:7141 [D loss: 0.763514, acc: 47.66%] [G loss: 1.597835]\n",
      "epoch:9 step:7142 [D loss: 0.715360, acc: 50.78%] [G loss: 1.669668]\n",
      "epoch:9 step:7143 [D loss: 0.844532, acc: 34.38%] [G loss: 1.516438]\n",
      "epoch:9 step:7144 [D loss: 0.692675, acc: 58.59%] [G loss: 1.673123]\n",
      "epoch:9 step:7145 [D loss: 0.773783, acc: 39.06%] [G loss: 1.662257]\n",
      "epoch:9 step:7146 [D loss: 0.824235, acc: 36.72%] [G loss: 1.665875]\n",
      "epoch:9 step:7147 [D loss: 0.660396, acc: 66.41%] [G loss: 1.647567]\n",
      "epoch:9 step:7148 [D loss: 0.697326, acc: 53.91%] [G loss: 1.837622]\n",
      "epoch:9 step:7149 [D loss: 0.761091, acc: 39.84%] [G loss: 1.514875]\n",
      "epoch:9 step:7150 [D loss: 0.597098, acc: 71.88%] [G loss: 1.641394]\n",
      "epoch:9 step:7151 [D loss: 0.672332, acc: 59.38%] [G loss: 1.542385]\n",
      "epoch:9 step:7152 [D loss: 0.539041, acc: 84.38%] [G loss: 1.712658]\n",
      "epoch:9 step:7153 [D loss: 0.824935, acc: 40.62%] [G loss: 1.654792]\n",
      "epoch:9 step:7154 [D loss: 0.882643, acc: 22.66%] [G loss: 1.508511]\n",
      "epoch:9 step:7155 [D loss: 0.746632, acc: 41.41%] [G loss: 1.509943]\n",
      "epoch:9 step:7156 [D loss: 0.697363, acc: 53.91%] [G loss: 1.585686]\n",
      "epoch:9 step:7157 [D loss: 0.649061, acc: 62.50%] [G loss: 1.578102]\n",
      "epoch:9 step:7158 [D loss: 0.731107, acc: 50.00%] [G loss: 1.631887]\n",
      "epoch:9 step:7159 [D loss: 0.826169, acc: 32.03%] [G loss: 1.558622]\n",
      "epoch:9 step:7160 [D loss: 0.654327, acc: 59.38%] [G loss: 1.689310]\n",
      "epoch:9 step:7161 [D loss: 0.784557, acc: 37.50%] [G loss: 1.644572]\n",
      "epoch:9 step:7162 [D loss: 0.638671, acc: 64.06%] [G loss: 1.777864]\n",
      "epoch:9 step:7163 [D loss: 0.721735, acc: 51.56%] [G loss: 1.511076]\n",
      "epoch:9 step:7164 [D loss: 0.833563, acc: 29.69%] [G loss: 1.468415]\n",
      "epoch:9 step:7165 [D loss: 0.679020, acc: 57.81%] [G loss: 1.847096]\n",
      "epoch:9 step:7166 [D loss: 0.605765, acc: 67.19%] [G loss: 1.634372]\n",
      "epoch:9 step:7167 [D loss: 0.597872, acc: 71.09%] [G loss: 1.719834]\n",
      "epoch:9 step:7168 [D loss: 0.684880, acc: 57.81%] [G loss: 1.589908]\n",
      "epoch:9 step:7169 [D loss: 0.725978, acc: 45.31%] [G loss: 1.559049]\n",
      "epoch:9 step:7170 [D loss: 0.629978, acc: 66.41%] [G loss: 1.628224]\n",
      "epoch:9 step:7171 [D loss: 0.863390, acc: 28.12%] [G loss: 1.455040]\n",
      "epoch:9 step:7172 [D loss: 0.671856, acc: 64.06%] [G loss: 1.564389]\n",
      "epoch:9 step:7173 [D loss: 0.649463, acc: 67.97%] [G loss: 1.647566]\n",
      "epoch:9 step:7174 [D loss: 0.748761, acc: 50.78%] [G loss: 1.725579]\n",
      "epoch:9 step:7175 [D loss: 0.707180, acc: 52.34%] [G loss: 1.573376]\n",
      "epoch:9 step:7176 [D loss: 0.619262, acc: 69.53%] [G loss: 1.602523]\n",
      "epoch:9 step:7177 [D loss: 0.657754, acc: 61.72%] [G loss: 1.687715]\n",
      "epoch:9 step:7178 [D loss: 0.794302, acc: 46.09%] [G loss: 1.516844]\n",
      "epoch:9 step:7179 [D loss: 0.696751, acc: 55.47%] [G loss: 1.688263]\n",
      "epoch:9 step:7180 [D loss: 0.672792, acc: 60.94%] [G loss: 1.510852]\n",
      "epoch:9 step:7181 [D loss: 0.711687, acc: 55.47%] [G loss: 1.406377]\n",
      "epoch:9 step:7182 [D loss: 0.668669, acc: 56.25%] [G loss: 1.653535]\n",
      "epoch:9 step:7183 [D loss: 0.507403, acc: 82.81%] [G loss: 1.696927]\n",
      "epoch:9 step:7184 [D loss: 0.703532, acc: 47.66%] [G loss: 1.456763]\n",
      "epoch:9 step:7185 [D loss: 0.628906, acc: 69.53%] [G loss: 1.766633]\n",
      "epoch:9 step:7186 [D loss: 0.592483, acc: 78.91%] [G loss: 1.571097]\n",
      "epoch:9 step:7187 [D loss: 0.719586, acc: 49.22%] [G loss: 1.509830]\n",
      "epoch:9 step:7188 [D loss: 0.572979, acc: 78.12%] [G loss: 1.795122]\n",
      "epoch:9 step:7189 [D loss: 0.767621, acc: 38.28%] [G loss: 1.672553]\n",
      "epoch:9 step:7190 [D loss: 0.690310, acc: 60.16%] [G loss: 1.524662]\n",
      "epoch:9 step:7191 [D loss: 0.624178, acc: 69.53%] [G loss: 1.724721]\n",
      "epoch:9 step:7192 [D loss: 0.692097, acc: 53.12%] [G loss: 1.589057]\n",
      "epoch:9 step:7193 [D loss: 0.556317, acc: 79.69%] [G loss: 1.567329]\n",
      "epoch:9 step:7194 [D loss: 0.701189, acc: 56.25%] [G loss: 1.521124]\n",
      "epoch:9 step:7195 [D loss: 0.563313, acc: 68.75%] [G loss: 1.569767]\n",
      "epoch:9 step:7196 [D loss: 0.635009, acc: 64.84%] [G loss: 1.659822]\n",
      "epoch:9 step:7197 [D loss: 0.713556, acc: 49.22%] [G loss: 1.629886]\n",
      "epoch:9 step:7198 [D loss: 0.609155, acc: 69.53%] [G loss: 1.500135]\n",
      "epoch:9 step:7199 [D loss: 0.713844, acc: 48.44%] [G loss: 1.571978]\n",
      "epoch:9 step:7200 [D loss: 0.606316, acc: 67.19%] [G loss: 1.487824]\n",
      "epoch:9 step:7201 [D loss: 0.488439, acc: 78.91%] [G loss: 1.872051]\n",
      "epoch:9 step:7202 [D loss: 0.807426, acc: 32.81%] [G loss: 1.305146]\n",
      "epoch:9 step:7203 [D loss: 0.643263, acc: 61.72%] [G loss: 1.561521]\n",
      "epoch:9 step:7204 [D loss: 0.637594, acc: 67.19%] [G loss: 1.635902]\n",
      "epoch:9 step:7205 [D loss: 0.761069, acc: 43.75%] [G loss: 1.723489]\n",
      "epoch:9 step:7206 [D loss: 0.655073, acc: 58.59%] [G loss: 1.580592]\n",
      "epoch:9 step:7207 [D loss: 0.637662, acc: 56.25%] [G loss: 1.369463]\n",
      "epoch:9 step:7208 [D loss: 0.771882, acc: 43.75%] [G loss: 1.498792]\n",
      "epoch:9 step:7209 [D loss: 0.892903, acc: 25.78%] [G loss: 1.298469]\n",
      "epoch:9 step:7210 [D loss: 0.727256, acc: 50.78%] [G loss: 1.807080]\n",
      "epoch:9 step:7211 [D loss: 0.750849, acc: 44.53%] [G loss: 1.582877]\n",
      "epoch:9 step:7212 [D loss: 0.427137, acc: 91.41%] [G loss: 1.662213]\n",
      "epoch:9 step:7213 [D loss: 0.607691, acc: 58.59%] [G loss: 1.413608]\n",
      "epoch:9 step:7214 [D loss: 0.779391, acc: 49.22%] [G loss: 1.554685]\n",
      "epoch:9 step:7215 [D loss: 0.613045, acc: 64.84%] [G loss: 1.607510]\n",
      "epoch:9 step:7216 [D loss: 0.580242, acc: 77.34%] [G loss: 1.556490]\n",
      "epoch:9 step:7217 [D loss: 0.624459, acc: 64.84%] [G loss: 1.623298]\n",
      "epoch:9 step:7218 [D loss: 0.491328, acc: 83.59%] [G loss: 1.518456]\n",
      "epoch:9 step:7219 [D loss: 0.753892, acc: 44.53%] [G loss: 1.469615]\n",
      "epoch:9 step:7220 [D loss: 0.651377, acc: 60.94%] [G loss: 1.605129]\n",
      "epoch:9 step:7221 [D loss: 0.706492, acc: 50.00%] [G loss: 1.593829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7222 [D loss: 0.716510, acc: 51.56%] [G loss: 1.466966]\n",
      "epoch:9 step:7223 [D loss: 0.524140, acc: 80.47%] [G loss: 1.609820]\n",
      "epoch:9 step:7224 [D loss: 0.758255, acc: 46.88%] [G loss: 1.399285]\n",
      "epoch:9 step:7225 [D loss: 0.900343, acc: 25.78%] [G loss: 1.408146]\n",
      "epoch:9 step:7226 [D loss: 0.788885, acc: 36.72%] [G loss: 1.493716]\n",
      "epoch:9 step:7227 [D loss: 0.694869, acc: 53.12%] [G loss: 1.538226]\n",
      "epoch:9 step:7228 [D loss: 0.783550, acc: 35.94%] [G loss: 1.590276]\n",
      "epoch:9 step:7229 [D loss: 0.544584, acc: 82.81%] [G loss: 1.644063]\n",
      "epoch:9 step:7230 [D loss: 0.701759, acc: 57.03%] [G loss: 1.568190]\n",
      "epoch:9 step:7231 [D loss: 0.694482, acc: 53.91%] [G loss: 1.390729]\n",
      "epoch:9 step:7232 [D loss: 0.723151, acc: 46.88%] [G loss: 1.625831]\n",
      "epoch:9 step:7233 [D loss: 0.527494, acc: 64.84%] [G loss: 1.476239]\n",
      "epoch:9 step:7234 [D loss: 0.765931, acc: 53.12%] [G loss: 1.239827]\n",
      "epoch:9 step:7235 [D loss: 0.806449, acc: 36.72%] [G loss: 1.533118]\n",
      "epoch:9 step:7236 [D loss: 0.802774, acc: 39.84%] [G loss: 1.546925]\n",
      "epoch:9 step:7237 [D loss: 0.508530, acc: 86.72%] [G loss: 1.641610]\n",
      "epoch:9 step:7238 [D loss: 0.646203, acc: 60.16%] [G loss: 1.529408]\n",
      "epoch:9 step:7239 [D loss: 0.722274, acc: 50.78%] [G loss: 1.451710]\n",
      "epoch:9 step:7240 [D loss: 0.697360, acc: 53.12%] [G loss: 1.542617]\n",
      "epoch:9 step:7241 [D loss: 0.540804, acc: 77.34%] [G loss: 1.612804]\n",
      "epoch:9 step:7242 [D loss: 0.695202, acc: 49.22%] [G loss: 1.643706]\n",
      "epoch:9 step:7243 [D loss: 0.588276, acc: 80.47%] [G loss: 1.605461]\n",
      "epoch:9 step:7244 [D loss: 0.597792, acc: 64.84%] [G loss: 1.578367]\n",
      "epoch:9 step:7245 [D loss: 0.796785, acc: 35.94%] [G loss: 1.476973]\n",
      "epoch:9 step:7246 [D loss: 0.736633, acc: 46.09%] [G loss: 1.599405]\n",
      "epoch:9 step:7247 [D loss: 0.627491, acc: 66.41%] [G loss: 1.525808]\n",
      "epoch:9 step:7248 [D loss: 0.632437, acc: 67.97%] [G loss: 1.461046]\n",
      "epoch:9 step:7249 [D loss: 0.612503, acc: 71.88%] [G loss: 1.569921]\n",
      "epoch:9 step:7250 [D loss: 0.640635, acc: 64.06%] [G loss: 1.681884]\n",
      "epoch:9 step:7251 [D loss: 0.694947, acc: 55.47%] [G loss: 1.622779]\n",
      "epoch:9 step:7252 [D loss: 0.685677, acc: 54.69%] [G loss: 1.625374]\n",
      "epoch:9 step:7253 [D loss: 0.733669, acc: 47.66%] [G loss: 1.433397]\n",
      "epoch:9 step:7254 [D loss: 0.671903, acc: 53.91%] [G loss: 1.762208]\n",
      "epoch:9 step:7255 [D loss: 0.634730, acc: 60.16%] [G loss: 1.579184]\n",
      "epoch:9 step:7256 [D loss: 0.587510, acc: 75.00%] [G loss: 1.575465]\n",
      "epoch:9 step:7257 [D loss: 0.738811, acc: 44.53%] [G loss: 1.458222]\n",
      "epoch:9 step:7258 [D loss: 0.650632, acc: 58.59%] [G loss: 1.668037]\n",
      "epoch:9 step:7259 [D loss: 0.591649, acc: 73.44%] [G loss: 1.709721]\n",
      "epoch:9 step:7260 [D loss: 0.666859, acc: 59.38%] [G loss: 1.750369]\n",
      "epoch:9 step:7261 [D loss: 0.967626, acc: 23.44%] [G loss: 1.388767]\n",
      "epoch:9 step:7262 [D loss: 0.654503, acc: 57.03%] [G loss: 1.559865]\n",
      "epoch:9 step:7263 [D loss: 0.888257, acc: 25.00%] [G loss: 1.557893]\n",
      "epoch:9 step:7264 [D loss: 0.679523, acc: 52.34%] [G loss: 1.745813]\n",
      "epoch:9 step:7265 [D loss: 0.728534, acc: 48.44%] [G loss: 1.773217]\n",
      "epoch:9 step:7266 [D loss: 0.686238, acc: 58.59%] [G loss: 1.840199]\n",
      "epoch:9 step:7267 [D loss: 0.581146, acc: 75.00%] [G loss: 1.705188]\n",
      "epoch:9 step:7268 [D loss: 0.610985, acc: 68.75%] [G loss: 1.679617]\n",
      "epoch:9 step:7269 [D loss: 0.622029, acc: 67.97%] [G loss: 1.543989]\n",
      "epoch:9 step:7270 [D loss: 0.648014, acc: 62.50%] [G loss: 1.793182]\n",
      "epoch:9 step:7271 [D loss: 0.789487, acc: 41.41%] [G loss: 1.697759]\n",
      "epoch:9 step:7272 [D loss: 0.673745, acc: 53.91%] [G loss: 1.656605]\n",
      "epoch:9 step:7273 [D loss: 0.622048, acc: 61.72%] [G loss: 1.802507]\n",
      "epoch:9 step:7274 [D loss: 0.722587, acc: 50.00%] [G loss: 1.503924]\n",
      "epoch:9 step:7275 [D loss: 0.716197, acc: 53.91%] [G loss: 1.506911]\n",
      "epoch:9 step:7276 [D loss: 0.951859, acc: 21.09%] [G loss: 1.289026]\n",
      "epoch:9 step:7277 [D loss: 0.726379, acc: 45.31%] [G loss: 1.609517]\n",
      "epoch:9 step:7278 [D loss: 0.943588, acc: 13.28%] [G loss: 1.544561]\n",
      "epoch:9 step:7279 [D loss: 0.526774, acc: 80.47%] [G loss: 1.776026]\n",
      "epoch:9 step:7280 [D loss: 0.717658, acc: 50.00%] [G loss: 1.575912]\n",
      "epoch:9 step:7281 [D loss: 0.469431, acc: 75.00%] [G loss: 1.481187]\n",
      "epoch:9 step:7282 [D loss: 1.006623, acc: 8.59%] [G loss: 1.291080]\n",
      "epoch:9 step:7283 [D loss: 0.862571, acc: 27.34%] [G loss: 1.298127]\n",
      "epoch:9 step:7284 [D loss: 0.685757, acc: 61.72%] [G loss: 1.732994]\n",
      "epoch:9 step:7285 [D loss: 0.588763, acc: 73.44%] [G loss: 1.658630]\n",
      "epoch:9 step:7286 [D loss: 0.611661, acc: 69.53%] [G loss: 1.564999]\n",
      "epoch:9 step:7287 [D loss: 0.748425, acc: 49.22%] [G loss: 1.507286]\n",
      "epoch:9 step:7288 [D loss: 0.757998, acc: 39.84%] [G loss: 1.395811]\n",
      "epoch:9 step:7289 [D loss: 0.670161, acc: 61.72%] [G loss: 1.756573]\n",
      "epoch:9 step:7290 [D loss: 0.756246, acc: 42.19%] [G loss: 1.609134]\n",
      "epoch:9 step:7291 [D loss: 0.732837, acc: 52.34%] [G loss: 1.649327]\n",
      "epoch:9 step:7292 [D loss: 0.779433, acc: 44.53%] [G loss: 1.467978]\n",
      "epoch:9 step:7293 [D loss: 0.649324, acc: 60.94%] [G loss: 1.518118]\n",
      "epoch:9 step:7294 [D loss: 0.760226, acc: 35.16%] [G loss: 1.591159]\n",
      "epoch:9 step:7295 [D loss: 0.765806, acc: 36.72%] [G loss: 1.526510]\n",
      "epoch:9 step:7296 [D loss: 0.809004, acc: 34.38%] [G loss: 1.356001]\n",
      "epoch:9 step:7297 [D loss: 0.686156, acc: 56.25%] [G loss: 1.518157]\n",
      "epoch:9 step:7298 [D loss: 0.614527, acc: 72.66%] [G loss: 1.604490]\n",
      "epoch:9 step:7299 [D loss: 0.691064, acc: 52.34%] [G loss: 1.470662]\n",
      "epoch:9 step:7300 [D loss: 0.762857, acc: 42.97%] [G loss: 1.478780]\n",
      "epoch:9 step:7301 [D loss: 0.684257, acc: 56.25%] [G loss: 1.527879]\n",
      "epoch:9 step:7302 [D loss: 0.699358, acc: 49.22%] [G loss: 1.484451]\n",
      "epoch:9 step:7303 [D loss: 0.668267, acc: 55.47%] [G loss: 1.529587]\n",
      "epoch:9 step:7304 [D loss: 0.725687, acc: 50.00%] [G loss: 1.528021]\n",
      "epoch:9 step:7305 [D loss: 0.740409, acc: 48.44%] [G loss: 1.467919]\n",
      "epoch:9 step:7306 [D loss: 0.779320, acc: 37.50%] [G loss: 1.307533]\n",
      "epoch:9 step:7307 [D loss: 0.752522, acc: 48.44%] [G loss: 1.522777]\n",
      "epoch:9 step:7308 [D loss: 0.622093, acc: 70.31%] [G loss: 1.465390]\n",
      "epoch:9 step:7309 [D loss: 0.724832, acc: 45.31%] [G loss: 1.535926]\n",
      "epoch:9 step:7310 [D loss: 0.611826, acc: 72.66%] [G loss: 1.704958]\n",
      "epoch:9 step:7311 [D loss: 0.827014, acc: 21.88%] [G loss: 1.457103]\n",
      "epoch:9 step:7312 [D loss: 0.675936, acc: 57.81%] [G loss: 1.506286]\n",
      "epoch:9 step:7313 [D loss: 0.585787, acc: 73.44%] [G loss: 1.605676]\n",
      "epoch:9 step:7314 [D loss: 0.679461, acc: 59.38%] [G loss: 1.651556]\n",
      "epoch:9 step:7315 [D loss: 0.453286, acc: 85.94%] [G loss: 1.513157]\n",
      "epoch:9 step:7316 [D loss: 0.721196, acc: 46.09%] [G loss: 1.559112]\n",
      "epoch:9 step:7317 [D loss: 0.671226, acc: 57.03%] [G loss: 1.544801]\n",
      "epoch:9 step:7318 [D loss: 0.707143, acc: 57.03%] [G loss: 1.558827]\n",
      "epoch:9 step:7319 [D loss: 0.674907, acc: 61.72%] [G loss: 1.691634]\n",
      "epoch:9 step:7320 [D loss: 0.704574, acc: 53.12%] [G loss: 1.569929]\n",
      "epoch:9 step:7321 [D loss: 0.713737, acc: 50.78%] [G loss: 1.603515]\n",
      "epoch:9 step:7322 [D loss: 0.604139, acc: 74.22%] [G loss: 1.529881]\n",
      "epoch:9 step:7323 [D loss: 0.751579, acc: 39.84%] [G loss: 1.446348]\n",
      "epoch:9 step:7324 [D loss: 0.627947, acc: 71.88%] [G loss: 1.661713]\n",
      "epoch:9 step:7325 [D loss: 0.739003, acc: 44.53%] [G loss: 1.585013]\n",
      "epoch:9 step:7326 [D loss: 0.786651, acc: 42.19%] [G loss: 1.436964]\n",
      "epoch:9 step:7327 [D loss: 0.599065, acc: 67.97%] [G loss: 1.768597]\n",
      "epoch:9 step:7328 [D loss: 0.613650, acc: 67.19%] [G loss: 1.616372]\n",
      "epoch:9 step:7329 [D loss: 0.890090, acc: 19.53%] [G loss: 1.479437]\n",
      "epoch:9 step:7330 [D loss: 0.704691, acc: 54.69%] [G loss: 1.629992]\n",
      "epoch:9 step:7331 [D loss: 0.603491, acc: 73.44%] [G loss: 1.715374]\n",
      "epoch:9 step:7332 [D loss: 0.709575, acc: 47.66%] [G loss: 1.566510]\n",
      "epoch:9 step:7333 [D loss: 0.720932, acc: 52.34%] [G loss: 1.495382]\n",
      "epoch:9 step:7334 [D loss: 0.836569, acc: 28.91%] [G loss: 1.418579]\n",
      "epoch:9 step:7335 [D loss: 0.737256, acc: 51.56%] [G loss: 1.429196]\n",
      "epoch:9 step:7336 [D loss: 0.719119, acc: 53.91%] [G loss: 1.588761]\n",
      "epoch:9 step:7337 [D loss: 0.692369, acc: 57.03%] [G loss: 1.653608]\n",
      "epoch:9 step:7338 [D loss: 0.721817, acc: 49.22%] [G loss: 1.551331]\n",
      "epoch:9 step:7339 [D loss: 0.679171, acc: 56.25%] [G loss: 1.658548]\n",
      "epoch:9 step:7340 [D loss: 0.647247, acc: 61.72%] [G loss: 1.455028]\n",
      "epoch:9 step:7341 [D loss: 0.679203, acc: 57.81%] [G loss: 1.737437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7342 [D loss: 0.726870, acc: 50.00%] [G loss: 1.505392]\n",
      "epoch:9 step:7343 [D loss: 0.783242, acc: 39.84%] [G loss: 1.335839]\n",
      "epoch:9 step:7344 [D loss: 0.727072, acc: 43.75%] [G loss: 1.471624]\n",
      "epoch:9 step:7345 [D loss: 0.637165, acc: 61.72%] [G loss: 1.549886]\n",
      "epoch:9 step:7346 [D loss: 0.813800, acc: 33.59%] [G loss: 1.348502]\n",
      "epoch:9 step:7347 [D loss: 0.765030, acc: 45.31%] [G loss: 1.527670]\n",
      "epoch:9 step:7348 [D loss: 0.819717, acc: 32.03%] [G loss: 1.523201]\n",
      "epoch:9 step:7349 [D loss: 0.795019, acc: 39.06%] [G loss: 1.507018]\n",
      "epoch:9 step:7350 [D loss: 0.709507, acc: 52.34%] [G loss: 1.538960]\n",
      "epoch:9 step:7351 [D loss: 0.721068, acc: 51.56%] [G loss: 1.521587]\n",
      "epoch:9 step:7352 [D loss: 0.718639, acc: 42.97%] [G loss: 1.581591]\n",
      "epoch:9 step:7353 [D loss: 0.753496, acc: 48.44%] [G loss: 1.472763]\n",
      "epoch:9 step:7354 [D loss: 0.713232, acc: 46.88%] [G loss: 1.555490]\n",
      "epoch:9 step:7355 [D loss: 0.655735, acc: 62.50%] [G loss: 1.572099]\n",
      "epoch:9 step:7356 [D loss: 0.736395, acc: 47.66%] [G loss: 1.632239]\n",
      "epoch:9 step:7357 [D loss: 0.750626, acc: 41.41%] [G loss: 1.573952]\n",
      "epoch:9 step:7358 [D loss: 0.707878, acc: 49.22%] [G loss: 1.578365]\n",
      "epoch:9 step:7359 [D loss: 0.796950, acc: 36.72%] [G loss: 1.593488]\n",
      "epoch:9 step:7360 [D loss: 0.780820, acc: 35.16%] [G loss: 1.457571]\n",
      "epoch:9 step:7361 [D loss: 0.591279, acc: 78.91%] [G loss: 1.675612]\n",
      "epoch:9 step:7362 [D loss: 0.701602, acc: 53.91%] [G loss: 1.676866]\n",
      "epoch:9 step:7363 [D loss: 0.642587, acc: 70.31%] [G loss: 1.675543]\n",
      "epoch:9 step:7364 [D loss: 0.678424, acc: 58.59%] [G loss: 1.623110]\n",
      "epoch:9 step:7365 [D loss: 0.614692, acc: 72.66%] [G loss: 1.660715]\n",
      "epoch:9 step:7366 [D loss: 0.699261, acc: 53.12%] [G loss: 1.469722]\n",
      "epoch:9 step:7367 [D loss: 0.748974, acc: 43.75%] [G loss: 1.626892]\n",
      "epoch:9 step:7368 [D loss: 0.895235, acc: 17.97%] [G loss: 1.239468]\n",
      "epoch:9 step:7369 [D loss: 0.570338, acc: 79.69%] [G loss: 1.441251]\n",
      "epoch:9 step:7370 [D loss: 0.624680, acc: 67.19%] [G loss: 1.522846]\n",
      "epoch:9 step:7371 [D loss: 0.634838, acc: 67.19%] [G loss: 1.551454]\n",
      "epoch:9 step:7372 [D loss: 0.760406, acc: 41.41%] [G loss: 1.539650]\n",
      "epoch:9 step:7373 [D loss: 0.625235, acc: 67.19%] [G loss: 1.606293]\n",
      "epoch:9 step:7374 [D loss: 0.707355, acc: 52.34%] [G loss: 1.424294]\n",
      "epoch:9 step:7375 [D loss: 0.753562, acc: 46.09%] [G loss: 1.463218]\n",
      "epoch:9 step:7376 [D loss: 0.598302, acc: 70.31%] [G loss: 1.377498]\n",
      "epoch:9 step:7377 [D loss: 0.760935, acc: 39.06%] [G loss: 1.517297]\n",
      "epoch:9 step:7378 [D loss: 0.656552, acc: 60.94%] [G loss: 1.502698]\n",
      "epoch:9 step:7379 [D loss: 0.620703, acc: 60.16%] [G loss: 1.538528]\n",
      "epoch:9 step:7380 [D loss: 0.776681, acc: 33.59%] [G loss: 1.328520]\n",
      "epoch:9 step:7381 [D loss: 0.764620, acc: 41.41%] [G loss: 1.545327]\n",
      "epoch:9 step:7382 [D loss: 0.570607, acc: 80.47%] [G loss: 1.556866]\n",
      "epoch:9 step:7383 [D loss: 0.723983, acc: 44.53%] [G loss: 1.398178]\n",
      "epoch:9 step:7384 [D loss: 0.803407, acc: 28.12%] [G loss: 1.265657]\n",
      "epoch:9 step:7385 [D loss: 0.665324, acc: 56.25%] [G loss: 1.622637]\n",
      "epoch:9 step:7386 [D loss: 0.700041, acc: 49.22%] [G loss: 1.350037]\n",
      "epoch:9 step:7387 [D loss: 0.645088, acc: 64.84%] [G loss: 1.708200]\n",
      "epoch:9 step:7388 [D loss: 0.714173, acc: 57.03%] [G loss: 1.386252]\n",
      "epoch:9 step:7389 [D loss: 0.707203, acc: 51.56%] [G loss: 1.544281]\n",
      "epoch:9 step:7390 [D loss: 0.692796, acc: 52.34%] [G loss: 1.582906]\n",
      "epoch:9 step:7391 [D loss: 0.747878, acc: 42.19%] [G loss: 1.543751]\n",
      "epoch:9 step:7392 [D loss: 0.684112, acc: 46.88%] [G loss: 1.532177]\n",
      "epoch:9 step:7393 [D loss: 0.647507, acc: 61.72%] [G loss: 1.765221]\n",
      "epoch:9 step:7394 [D loss: 0.658388, acc: 58.59%] [G loss: 1.647002]\n",
      "epoch:9 step:7395 [D loss: 0.571003, acc: 75.00%] [G loss: 1.583168]\n",
      "epoch:9 step:7396 [D loss: 0.768956, acc: 39.06%] [G loss: 1.530594]\n",
      "epoch:9 step:7397 [D loss: 0.720707, acc: 50.00%] [G loss: 1.501597]\n",
      "epoch:9 step:7398 [D loss: 0.594752, acc: 77.34%] [G loss: 1.645465]\n",
      "epoch:9 step:7399 [D loss: 0.642175, acc: 66.41%] [G loss: 1.649979]\n",
      "epoch:9 step:7400 [D loss: 0.636772, acc: 64.84%] [G loss: 1.750039]\n",
      "epoch:9 step:7401 [D loss: 0.598576, acc: 74.22%] [G loss: 1.678805]\n",
      "epoch:9 step:7402 [D loss: 0.841850, acc: 42.97%] [G loss: 1.326146]\n",
      "epoch:9 step:7403 [D loss: 0.668074, acc: 59.38%] [G loss: 1.664646]\n",
      "epoch:9 step:7404 [D loss: 0.593844, acc: 74.22%] [G loss: 1.572743]\n",
      "epoch:9 step:7405 [D loss: 0.647049, acc: 60.16%] [G loss: 1.738408]\n",
      "epoch:9 step:7406 [D loss: 0.647640, acc: 60.94%] [G loss: 1.595878]\n",
      "epoch:9 step:7407 [D loss: 0.682598, acc: 55.47%] [G loss: 1.780303]\n",
      "epoch:9 step:7408 [D loss: 0.569705, acc: 76.56%] [G loss: 1.742126]\n",
      "epoch:9 step:7409 [D loss: 0.762008, acc: 39.84%] [G loss: 1.555019]\n",
      "epoch:9 step:7410 [D loss: 0.634771, acc: 68.75%] [G loss: 1.741373]\n",
      "epoch:9 step:7411 [D loss: 0.646757, acc: 64.84%] [G loss: 1.686086]\n",
      "epoch:9 step:7412 [D loss: 0.588639, acc: 75.00%] [G loss: 1.513471]\n",
      "epoch:9 step:7413 [D loss: 0.592622, acc: 72.66%] [G loss: 1.605994]\n",
      "epoch:9 step:7414 [D loss: 0.591776, acc: 74.22%] [G loss: 1.413883]\n",
      "epoch:9 step:7415 [D loss: 0.687234, acc: 58.59%] [G loss: 1.469392]\n",
      "epoch:9 step:7416 [D loss: 0.562061, acc: 73.44%] [G loss: 1.573195]\n",
      "epoch:9 step:7417 [D loss: 0.679150, acc: 53.12%] [G loss: 1.260414]\n",
      "epoch:9 step:7418 [D loss: 0.439840, acc: 88.28%] [G loss: 1.621554]\n",
      "epoch:9 step:7419 [D loss: 0.630916, acc: 64.84%] [G loss: 1.550445]\n",
      "epoch:9 step:7420 [D loss: 0.891274, acc: 20.31%] [G loss: 1.473834]\n",
      "epoch:9 step:7421 [D loss: 0.836906, acc: 32.03%] [G loss: 1.610636]\n",
      "epoch:9 step:7422 [D loss: 0.740636, acc: 50.00%] [G loss: 1.463384]\n",
      "epoch:9 step:7423 [D loss: 0.609310, acc: 66.41%] [G loss: 1.785235]\n",
      "epoch:9 step:7424 [D loss: 0.756053, acc: 40.62%] [G loss: 1.547476]\n",
      "epoch:9 step:7425 [D loss: 0.714350, acc: 47.66%] [G loss: 1.586696]\n",
      "epoch:9 step:7426 [D loss: 0.703627, acc: 51.56%] [G loss: 1.466793]\n",
      "epoch:9 step:7427 [D loss: 0.742411, acc: 49.22%] [G loss: 1.536297]\n",
      "epoch:9 step:7428 [D loss: 0.647441, acc: 66.41%] [G loss: 1.811286]\n",
      "epoch:9 step:7429 [D loss: 0.734755, acc: 45.31%] [G loss: 1.547793]\n",
      "epoch:9 step:7430 [D loss: 0.428750, acc: 88.28%] [G loss: 1.774444]\n",
      "epoch:9 step:7431 [D loss: 0.838274, acc: 32.81%] [G loss: 1.506498]\n",
      "epoch:9 step:7432 [D loss: 0.552411, acc: 78.12%] [G loss: 1.612732]\n",
      "epoch:9 step:7433 [D loss: 0.584912, acc: 75.00%] [G loss: 1.545571]\n",
      "epoch:9 step:7434 [D loss: 0.586516, acc: 74.22%] [G loss: 1.560732]\n",
      "epoch:9 step:7435 [D loss: 0.604540, acc: 64.06%] [G loss: 1.537046]\n",
      "epoch:9 step:7436 [D loss: 0.578411, acc: 72.66%] [G loss: 1.732288]\n",
      "epoch:9 step:7437 [D loss: 0.611615, acc: 69.53%] [G loss: 1.587576]\n",
      "epoch:9 step:7438 [D loss: 0.390972, acc: 95.31%] [G loss: 1.956861]\n",
      "epoch:9 step:7439 [D loss: 0.618946, acc: 63.28%] [G loss: 2.006762]\n",
      "epoch:9 step:7440 [D loss: 1.080829, acc: 16.41%] [G loss: 1.575953]\n",
      "epoch:9 step:7441 [D loss: 0.514301, acc: 82.81%] [G loss: 1.742214]\n",
      "epoch:9 step:7442 [D loss: 0.553385, acc: 82.03%] [G loss: 1.630161]\n",
      "epoch:9 step:7443 [D loss: 0.567486, acc: 76.56%] [G loss: 1.858454]\n",
      "epoch:9 step:7444 [D loss: 0.417125, acc: 89.84%] [G loss: 1.850403]\n",
      "epoch:9 step:7445 [D loss: 0.607540, acc: 64.84%] [G loss: 1.775857]\n",
      "epoch:9 step:7446 [D loss: 0.520640, acc: 78.12%] [G loss: 1.700589]\n",
      "epoch:9 step:7447 [D loss: 0.511131, acc: 79.69%] [G loss: 1.465399]\n",
      "epoch:9 step:7448 [D loss: 0.404441, acc: 93.75%] [G loss: 1.672805]\n",
      "epoch:9 step:7449 [D loss: 0.668403, acc: 61.72%] [G loss: 1.755917]\n",
      "epoch:9 step:7450 [D loss: 1.013139, acc: 14.06%] [G loss: 1.453060]\n",
      "epoch:9 step:7451 [D loss: 0.731481, acc: 50.00%] [G loss: 1.529713]\n",
      "epoch:9 step:7452 [D loss: 0.686833, acc: 58.59%] [G loss: 1.390257]\n",
      "epoch:9 step:7453 [D loss: 0.703599, acc: 54.69%] [G loss: 1.375269]\n",
      "epoch:9 step:7454 [D loss: 0.500099, acc: 78.12%] [G loss: 1.575049]\n",
      "epoch:9 step:7455 [D loss: 0.673190, acc: 60.94%] [G loss: 1.620110]\n",
      "epoch:9 step:7456 [D loss: 0.823603, acc: 31.25%] [G loss: 1.134478]\n",
      "epoch:9 step:7457 [D loss: 0.606549, acc: 71.88%] [G loss: 1.674628]\n",
      "epoch:9 step:7458 [D loss: 0.745411, acc: 52.34%] [G loss: 1.810088]\n",
      "epoch:9 step:7459 [D loss: 0.731789, acc: 47.66%] [G loss: 1.709934]\n",
      "epoch:9 step:7460 [D loss: 0.770183, acc: 42.97%] [G loss: 1.270588]\n",
      "epoch:9 step:7461 [D loss: 0.487261, acc: 78.91%] [G loss: 1.914998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7462 [D loss: 0.551076, acc: 85.16%] [G loss: 1.683454]\n",
      "epoch:9 step:7463 [D loss: 0.881936, acc: 28.91%] [G loss: 1.519418]\n",
      "epoch:9 step:7464 [D loss: 0.780745, acc: 39.84%] [G loss: 1.486088]\n",
      "epoch:9 step:7465 [D loss: 0.846807, acc: 34.38%] [G loss: 1.354951]\n",
      "epoch:9 step:7466 [D loss: 0.800550, acc: 32.81%] [G loss: 1.474433]\n",
      "epoch:9 step:7467 [D loss: 0.721250, acc: 44.53%] [G loss: 1.660980]\n",
      "epoch:9 step:7468 [D loss: 0.671135, acc: 59.38%] [G loss: 1.610555]\n",
      "epoch:9 step:7469 [D loss: 0.737527, acc: 43.75%] [G loss: 1.726474]\n",
      "epoch:9 step:7470 [D loss: 0.617854, acc: 69.53%] [G loss: 1.854080]\n",
      "epoch:9 step:7471 [D loss: 0.718634, acc: 52.34%] [G loss: 1.718964]\n",
      "epoch:9 step:7472 [D loss: 0.567823, acc: 79.69%] [G loss: 1.656748]\n",
      "epoch:9 step:7473 [D loss: 0.755948, acc: 40.62%] [G loss: 1.717071]\n",
      "epoch:9 step:7474 [D loss: 0.792897, acc: 34.38%] [G loss: 1.377417]\n",
      "epoch:9 step:7475 [D loss: 0.518478, acc: 77.34%] [G loss: 1.580163]\n",
      "epoch:9 step:7476 [D loss: 0.616491, acc: 72.66%] [G loss: 1.617009]\n",
      "epoch:9 step:7477 [D loss: 0.556667, acc: 75.00%] [G loss: 1.539363]\n",
      "epoch:9 step:7478 [D loss: 0.396913, acc: 95.31%] [G loss: 1.718017]\n",
      "epoch:9 step:7479 [D loss: 0.607986, acc: 70.31%] [G loss: 1.659418]\n",
      "epoch:9 step:7480 [D loss: 0.627784, acc: 64.06%] [G loss: 1.682360]\n",
      "epoch:9 step:7481 [D loss: 0.770590, acc: 39.84%] [G loss: 1.412933]\n",
      "epoch:9 step:7482 [D loss: 0.838484, acc: 30.47%] [G loss: 1.635645]\n",
      "epoch:9 step:7483 [D loss: 0.662498, acc: 64.06%] [G loss: 1.611165]\n",
      "epoch:9 step:7484 [D loss: 0.605468, acc: 77.34%] [G loss: 1.588081]\n",
      "epoch:9 step:7485 [D loss: 0.692753, acc: 53.12%] [G loss: 1.445828]\n",
      "epoch:9 step:7486 [D loss: 0.821400, acc: 34.38%] [G loss: 1.402311]\n",
      "epoch:9 step:7487 [D loss: 0.604540, acc: 67.19%] [G loss: 1.723233]\n",
      "epoch:9 step:7488 [D loss: 0.635991, acc: 67.19%] [G loss: 1.632111]\n",
      "epoch:9 step:7489 [D loss: 0.498072, acc: 71.09%] [G loss: 1.512585]\n",
      "epoch:9 step:7490 [D loss: 0.680749, acc: 59.38%] [G loss: 1.490462]\n",
      "epoch:9 step:7491 [D loss: 0.655897, acc: 66.41%] [G loss: 1.784616]\n",
      "epoch:9 step:7492 [D loss: 0.735782, acc: 46.09%] [G loss: 2.011662]\n",
      "epoch:9 step:7493 [D loss: 0.541011, acc: 80.47%] [G loss: 1.816703]\n",
      "epoch:9 step:7494 [D loss: 0.704500, acc: 50.78%] [G loss: 1.490431]\n",
      "epoch:9 step:7495 [D loss: 0.535170, acc: 86.72%] [G loss: 2.070061]\n",
      "epoch:9 step:7496 [D loss: 0.776459, acc: 36.72%] [G loss: 1.524816]\n",
      "epoch:9 step:7497 [D loss: 0.497607, acc: 75.78%] [G loss: 1.610397]\n",
      "epoch:9 step:7498 [D loss: 0.652471, acc: 60.94%] [G loss: 1.718475]\n",
      "epoch:9 step:7499 [D loss: 0.664402, acc: 62.50%] [G loss: 1.518567]\n",
      "epoch:9 step:7500 [D loss: 0.650850, acc: 63.28%] [G loss: 1.530441]\n",
      "epoch:9 step:7501 [D loss: 0.577037, acc: 67.19%] [G loss: 1.740508]\n",
      "epoch:9 step:7502 [D loss: 0.810364, acc: 32.03%] [G loss: 1.692304]\n",
      "epoch:9 step:7503 [D loss: 0.739452, acc: 46.88%] [G loss: 1.445953]\n",
      "epoch:9 step:7504 [D loss: 0.609886, acc: 60.94%] [G loss: 1.785903]\n",
      "epoch:9 step:7505 [D loss: 0.706111, acc: 57.81%] [G loss: 1.684588]\n",
      "epoch:9 step:7506 [D loss: 0.737435, acc: 45.31%] [G loss: 1.474696]\n",
      "epoch:9 step:7507 [D loss: 0.462369, acc: 76.56%] [G loss: 1.920174]\n",
      "epoch:9 step:7508 [D loss: 0.772233, acc: 45.31%] [G loss: 1.628453]\n",
      "epoch:9 step:7509 [D loss: 0.607733, acc: 67.19%] [G loss: 1.682792]\n",
      "epoch:9 step:7510 [D loss: 0.861081, acc: 24.22%] [G loss: 1.369606]\n",
      "epoch:9 step:7511 [D loss: 0.717733, acc: 48.44%] [G loss: 1.616094]\n",
      "epoch:9 step:7512 [D loss: 0.749677, acc: 43.75%] [G loss: 1.448335]\n",
      "epoch:9 step:7513 [D loss: 0.844748, acc: 34.38%] [G loss: 1.530717]\n",
      "epoch:9 step:7514 [D loss: 0.765856, acc: 40.62%] [G loss: 1.576247]\n",
      "epoch:9 step:7515 [D loss: 0.729178, acc: 51.56%] [G loss: 1.621975]\n",
      "epoch:9 step:7516 [D loss: 0.804840, acc: 38.28%] [G loss: 1.474777]\n",
      "epoch:9 step:7517 [D loss: 0.881909, acc: 28.91%] [G loss: 1.417506]\n",
      "epoch:9 step:7518 [D loss: 0.707840, acc: 55.47%] [G loss: 1.384559]\n",
      "epoch:9 step:7519 [D loss: 0.668267, acc: 60.94%] [G loss: 1.772217]\n",
      "epoch:9 step:7520 [D loss: 0.769263, acc: 42.19%] [G loss: 1.608645]\n",
      "epoch:9 step:7521 [D loss: 0.686542, acc: 56.25%] [G loss: 1.491627]\n",
      "epoch:9 step:7522 [D loss: 0.716600, acc: 53.12%] [G loss: 1.617724]\n",
      "epoch:9 step:7523 [D loss: 0.785446, acc: 29.69%] [G loss: 1.559755]\n",
      "epoch:9 step:7524 [D loss: 0.532749, acc: 82.03%] [G loss: 1.524627]\n",
      "epoch:9 step:7525 [D loss: 0.735979, acc: 46.09%] [G loss: 1.576482]\n",
      "epoch:9 step:7526 [D loss: 0.551278, acc: 77.34%] [G loss: 1.529781]\n",
      "epoch:9 step:7527 [D loss: 0.730812, acc: 46.09%] [G loss: 1.677601]\n",
      "epoch:9 step:7528 [D loss: 0.776784, acc: 39.06%] [G loss: 1.495333]\n",
      "epoch:9 step:7529 [D loss: 0.625681, acc: 65.62%] [G loss: 1.543144]\n",
      "epoch:9 step:7530 [D loss: 0.538577, acc: 85.16%] [G loss: 1.577526]\n",
      "epoch:9 step:7531 [D loss: 0.762855, acc: 41.41%] [G loss: 1.399884]\n",
      "epoch:9 step:7532 [D loss: 0.571323, acc: 76.56%] [G loss: 1.663296]\n",
      "epoch:9 step:7533 [D loss: 0.776001, acc: 40.62%] [G loss: 1.564835]\n",
      "epoch:9 step:7534 [D loss: 0.852374, acc: 25.00%] [G loss: 1.274922]\n",
      "epoch:9 step:7535 [D loss: 0.699741, acc: 60.16%] [G loss: 1.776082]\n",
      "epoch:9 step:7536 [D loss: 0.678202, acc: 59.38%] [G loss: 1.639515]\n",
      "epoch:9 step:7537 [D loss: 0.695065, acc: 54.69%] [G loss: 1.675552]\n",
      "epoch:9 step:7538 [D loss: 0.697409, acc: 53.12%] [G loss: 1.803662]\n",
      "epoch:9 step:7539 [D loss: 0.724540, acc: 49.22%] [G loss: 1.517429]\n",
      "epoch:9 step:7540 [D loss: 0.714330, acc: 50.00%] [G loss: 1.543396]\n",
      "epoch:9 step:7541 [D loss: 0.532404, acc: 78.91%] [G loss: 1.822035]\n",
      "epoch:9 step:7542 [D loss: 0.770584, acc: 41.41%] [G loss: 1.540869]\n",
      "epoch:9 step:7543 [D loss: 0.910003, acc: 30.47%] [G loss: 1.447344]\n",
      "epoch:9 step:7544 [D loss: 0.774129, acc: 42.97%] [G loss: 1.429636]\n",
      "epoch:9 step:7545 [D loss: 0.670111, acc: 59.38%] [G loss: 1.537724]\n",
      "epoch:9 step:7546 [D loss: 0.550953, acc: 78.12%] [G loss: 1.682516]\n",
      "epoch:9 step:7547 [D loss: 0.657581, acc: 64.84%] [G loss: 1.542336]\n",
      "epoch:9 step:7548 [D loss: 0.690592, acc: 52.34%] [G loss: 1.484889]\n",
      "epoch:9 step:7549 [D loss: 0.640441, acc: 66.41%] [G loss: 1.658285]\n",
      "epoch:9 step:7550 [D loss: 0.581636, acc: 75.78%] [G loss: 1.727003]\n",
      "epoch:9 step:7551 [D loss: 0.766187, acc: 35.94%] [G loss: 1.532493]\n",
      "epoch:9 step:7552 [D loss: 0.687822, acc: 53.12%] [G loss: 1.616310]\n",
      "epoch:9 step:7553 [D loss: 0.777452, acc: 35.94%] [G loss: 1.537752]\n",
      "epoch:9 step:7554 [D loss: 0.754894, acc: 37.50%] [G loss: 1.367401]\n",
      "epoch:9 step:7555 [D loss: 0.872031, acc: 23.44%] [G loss: 1.450737]\n",
      "epoch:9 step:7556 [D loss: 0.671447, acc: 61.72%] [G loss: 1.703684]\n",
      "epoch:9 step:7557 [D loss: 0.734923, acc: 50.00%] [G loss: 1.548644]\n",
      "epoch:9 step:7558 [D loss: 0.688618, acc: 51.56%] [G loss: 1.517561]\n",
      "epoch:9 step:7559 [D loss: 0.910397, acc: 22.66%] [G loss: 1.696470]\n",
      "epoch:9 step:7560 [D loss: 0.762482, acc: 39.06%] [G loss: 1.452423]\n",
      "epoch:9 step:7561 [D loss: 0.635422, acc: 64.06%] [G loss: 1.750436]\n",
      "epoch:9 step:7562 [D loss: 0.651291, acc: 60.16%] [G loss: 1.454973]\n",
      "epoch:9 step:7563 [D loss: 0.736223, acc: 51.56%] [G loss: 1.456340]\n",
      "epoch:9 step:7564 [D loss: 0.601701, acc: 72.66%] [G loss: 1.748572]\n",
      "epoch:9 step:7565 [D loss: 0.552782, acc: 86.72%] [G loss: 1.601174]\n",
      "epoch:9 step:7566 [D loss: 0.612075, acc: 72.66%] [G loss: 1.819963]\n",
      "epoch:9 step:7567 [D loss: 0.689815, acc: 53.91%] [G loss: 1.701183]\n",
      "epoch:9 step:7568 [D loss: 0.658147, acc: 64.06%] [G loss: 1.616218]\n",
      "epoch:9 step:7569 [D loss: 0.670559, acc: 59.38%] [G loss: 1.652372]\n",
      "epoch:9 step:7570 [D loss: 0.621204, acc: 67.97%] [G loss: 1.728724]\n",
      "epoch:9 step:7571 [D loss: 0.496543, acc: 72.66%] [G loss: 1.967628]\n",
      "epoch:9 step:7572 [D loss: 0.573749, acc: 78.12%] [G loss: 1.580151]\n",
      "epoch:9 step:7573 [D loss: 0.731071, acc: 53.12%] [G loss: 1.720490]\n",
      "epoch:9 step:7574 [D loss: 0.710830, acc: 55.47%] [G loss: 1.630278]\n",
      "epoch:9 step:7575 [D loss: 0.764002, acc: 49.22%] [G loss: 1.483944]\n",
      "epoch:9 step:7576 [D loss: 0.572729, acc: 75.00%] [G loss: 1.657582]\n",
      "epoch:9 step:7577 [D loss: 0.608287, acc: 61.72%] [G loss: 1.502704]\n",
      "epoch:9 step:7578 [D loss: 0.921227, acc: 21.88%] [G loss: 1.391019]\n",
      "epoch:9 step:7579 [D loss: 0.677144, acc: 59.38%] [G loss: 1.865242]\n",
      "epoch:9 step:7580 [D loss: 0.728310, acc: 53.91%] [G loss: 1.698677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7581 [D loss: 0.761748, acc: 52.34%] [G loss: 1.307263]\n",
      "epoch:9 step:7582 [D loss: 0.840640, acc: 32.81%] [G loss: 1.316813]\n",
      "epoch:9 step:7583 [D loss: 0.653797, acc: 63.28%] [G loss: 1.659974]\n",
      "epoch:9 step:7584 [D loss: 0.711972, acc: 46.88%] [G loss: 1.426039]\n",
      "epoch:9 step:7585 [D loss: 0.763230, acc: 39.06%] [G loss: 1.597258]\n",
      "epoch:9 step:7586 [D loss: 0.724241, acc: 47.66%] [G loss: 1.647524]\n",
      "epoch:9 step:7587 [D loss: 0.737102, acc: 50.00%] [G loss: 1.436107]\n",
      "epoch:9 step:7588 [D loss: 0.723800, acc: 47.66%] [G loss: 1.549035]\n",
      "epoch:9 step:7589 [D loss: 0.702687, acc: 51.56%] [G loss: 1.651744]\n",
      "epoch:9 step:7590 [D loss: 0.608995, acc: 73.44%] [G loss: 1.512504]\n",
      "epoch:9 step:7591 [D loss: 0.736410, acc: 44.53%] [G loss: 1.448375]\n",
      "epoch:9 step:7592 [D loss: 0.713370, acc: 46.09%] [G loss: 1.824039]\n",
      "epoch:9 step:7593 [D loss: 0.506881, acc: 77.34%] [G loss: 1.513186]\n",
      "epoch:9 step:7594 [D loss: 0.561679, acc: 71.09%] [G loss: 1.358462]\n",
      "epoch:9 step:7595 [D loss: 0.675309, acc: 55.47%] [G loss: 1.414686]\n",
      "epoch:9 step:7596 [D loss: 0.791698, acc: 38.28%] [G loss: 1.578146]\n",
      "epoch:9 step:7597 [D loss: 0.700899, acc: 54.69%] [G loss: 1.556365]\n",
      "epoch:9 step:7598 [D loss: 0.637981, acc: 68.75%] [G loss: 1.500403]\n",
      "epoch:9 step:7599 [D loss: 0.561351, acc: 72.66%] [G loss: 1.667747]\n",
      "epoch:9 step:7600 [D loss: 0.863894, acc: 19.53%] [G loss: 1.332911]\n",
      "epoch:9 step:7601 [D loss: 0.588774, acc: 73.44%] [G loss: 1.735100]\n",
      "epoch:9 step:7602 [D loss: 0.722424, acc: 46.88%] [G loss: 1.556077]\n",
      "epoch:9 step:7603 [D loss: 0.740224, acc: 49.22%] [G loss: 1.530531]\n",
      "epoch:9 step:7604 [D loss: 0.642596, acc: 60.94%] [G loss: 1.359032]\n",
      "epoch:9 step:7605 [D loss: 0.786590, acc: 33.59%] [G loss: 1.561818]\n",
      "epoch:9 step:7606 [D loss: 0.723393, acc: 51.56%] [G loss: 1.451593]\n",
      "epoch:9 step:7607 [D loss: 0.713779, acc: 53.12%] [G loss: 1.814305]\n",
      "epoch:9 step:7608 [D loss: 0.611783, acc: 68.75%] [G loss: 1.819910]\n",
      "epoch:9 step:7609 [D loss: 0.728854, acc: 43.75%] [G loss: 1.640914]\n",
      "epoch:9 step:7610 [D loss: 0.711642, acc: 49.22%] [G loss: 1.639932]\n",
      "epoch:9 step:7611 [D loss: 0.678955, acc: 63.28%] [G loss: 1.582253]\n",
      "epoch:9 step:7612 [D loss: 0.642747, acc: 61.72%] [G loss: 1.726737]\n",
      "epoch:9 step:7613 [D loss: 0.735724, acc: 44.53%] [G loss: 1.465637]\n",
      "epoch:9 step:7614 [D loss: 0.665792, acc: 60.16%] [G loss: 1.810341]\n",
      "epoch:9 step:7615 [D loss: 0.642066, acc: 60.16%] [G loss: 1.707751]\n",
      "epoch:9 step:7616 [D loss: 0.658408, acc: 61.72%] [G loss: 1.709601]\n",
      "epoch:9 step:7617 [D loss: 0.690438, acc: 57.81%] [G loss: 1.751804]\n",
      "epoch:9 step:7618 [D loss: 0.813081, acc: 28.12%] [G loss: 1.576287]\n",
      "epoch:9 step:7619 [D loss: 0.665631, acc: 57.81%] [G loss: 1.494777]\n",
      "epoch:9 step:7620 [D loss: 0.623618, acc: 67.97%] [G loss: 1.636869]\n",
      "epoch:9 step:7621 [D loss: 0.666462, acc: 60.94%] [G loss: 1.573924]\n",
      "epoch:9 step:7622 [D loss: 0.607664, acc: 67.97%] [G loss: 1.635065]\n",
      "epoch:9 step:7623 [D loss: 0.741674, acc: 46.88%] [G loss: 1.627689]\n",
      "epoch:9 step:7624 [D loss: 0.685755, acc: 59.38%] [G loss: 1.525790]\n",
      "epoch:9 step:7625 [D loss: 0.786031, acc: 40.62%] [G loss: 1.528853]\n",
      "epoch:9 step:7626 [D loss: 0.785634, acc: 43.75%] [G loss: 1.618681]\n",
      "epoch:9 step:7627 [D loss: 0.612566, acc: 67.19%] [G loss: 1.870142]\n",
      "epoch:9 step:7628 [D loss: 0.747307, acc: 50.00%] [G loss: 1.517719]\n",
      "epoch:9 step:7629 [D loss: 0.589628, acc: 67.19%] [G loss: 1.438044]\n",
      "epoch:9 step:7630 [D loss: 0.741071, acc: 45.31%] [G loss: 1.573293]\n",
      "epoch:9 step:7631 [D loss: 0.785087, acc: 37.50%] [G loss: 1.493864]\n",
      "epoch:9 step:7632 [D loss: 0.751933, acc: 47.66%] [G loss: 1.453272]\n",
      "epoch:9 step:7633 [D loss: 0.614062, acc: 71.88%] [G loss: 1.838708]\n",
      "epoch:9 step:7634 [D loss: 0.559600, acc: 68.75%] [G loss: 1.482237]\n",
      "epoch:9 step:7635 [D loss: 0.970783, acc: 14.84%] [G loss: 1.651443]\n",
      "epoch:9 step:7636 [D loss: 0.631276, acc: 59.38%] [G loss: 1.900724]\n",
      "epoch:9 step:7637 [D loss: 0.699058, acc: 52.34%] [G loss: 1.475700]\n",
      "epoch:9 step:7638 [D loss: 0.775201, acc: 36.72%] [G loss: 1.380269]\n",
      "epoch:9 step:7639 [D loss: 0.884097, acc: 20.31%] [G loss: 1.251369]\n",
      "epoch:9 step:7640 [D loss: 0.665877, acc: 59.38%] [G loss: 1.743054]\n",
      "epoch:9 step:7641 [D loss: 0.725805, acc: 45.31%] [G loss: 1.471312]\n",
      "epoch:9 step:7642 [D loss: 0.729871, acc: 42.97%] [G loss: 1.548289]\n",
      "epoch:9 step:7643 [D loss: 0.812570, acc: 32.81%] [G loss: 1.387420]\n",
      "epoch:9 step:7644 [D loss: 0.789824, acc: 35.94%] [G loss: 1.522851]\n",
      "epoch:9 step:7645 [D loss: 0.874842, acc: 26.56%] [G loss: 1.457093]\n",
      "epoch:9 step:7646 [D loss: 0.760887, acc: 38.28%] [G loss: 1.684312]\n",
      "epoch:9 step:7647 [D loss: 0.791948, acc: 31.25%] [G loss: 1.336315]\n",
      "epoch:9 step:7648 [D loss: 0.803995, acc: 30.47%] [G loss: 1.469952]\n",
      "epoch:9 step:7649 [D loss: 0.614655, acc: 71.09%] [G loss: 1.610479]\n",
      "epoch:9 step:7650 [D loss: 0.635834, acc: 64.84%] [G loss: 1.641081]\n",
      "epoch:9 step:7651 [D loss: 0.685129, acc: 59.38%] [G loss: 1.733398]\n",
      "epoch:9 step:7652 [D loss: 0.744294, acc: 46.88%] [G loss: 1.562586]\n",
      "epoch:9 step:7653 [D loss: 0.613415, acc: 68.75%] [G loss: 1.511324]\n",
      "epoch:9 step:7654 [D loss: 0.720217, acc: 56.25%] [G loss: 1.703215]\n",
      "epoch:9 step:7655 [D loss: 0.700750, acc: 54.69%] [G loss: 1.771574]\n",
      "epoch:9 step:7656 [D loss: 0.640218, acc: 64.84%] [G loss: 1.609207]\n",
      "epoch:9 step:7657 [D loss: 0.693807, acc: 57.03%] [G loss: 1.495184]\n",
      "epoch:9 step:7658 [D loss: 0.648591, acc: 59.38%] [G loss: 1.501452]\n",
      "epoch:9 step:7659 [D loss: 0.803247, acc: 30.47%] [G loss: 1.553928]\n",
      "epoch:9 step:7660 [D loss: 0.689544, acc: 52.34%] [G loss: 1.530733]\n",
      "epoch:9 step:7661 [D loss: 0.758247, acc: 40.62%] [G loss: 1.554448]\n",
      "epoch:9 step:7662 [D loss: 0.770285, acc: 38.28%] [G loss: 1.535414]\n",
      "epoch:9 step:7663 [D loss: 0.706949, acc: 50.00%] [G loss: 1.509454]\n",
      "epoch:9 step:7664 [D loss: 0.719025, acc: 50.78%] [G loss: 1.611443]\n",
      "epoch:9 step:7665 [D loss: 0.688903, acc: 52.34%] [G loss: 1.619144]\n",
      "epoch:9 step:7666 [D loss: 0.786365, acc: 34.38%] [G loss: 1.376068]\n",
      "epoch:9 step:7667 [D loss: 0.724790, acc: 47.66%] [G loss: 1.398345]\n",
      "epoch:9 step:7668 [D loss: 0.772363, acc: 39.84%] [G loss: 1.489492]\n",
      "epoch:9 step:7669 [D loss: 0.629016, acc: 64.84%] [G loss: 1.670941]\n",
      "epoch:9 step:7670 [D loss: 0.627943, acc: 71.09%] [G loss: 1.606884]\n",
      "epoch:9 step:7671 [D loss: 0.587717, acc: 63.28%] [G loss: 1.630879]\n",
      "epoch:9 step:7672 [D loss: 0.478444, acc: 84.38%] [G loss: 1.879835]\n",
      "epoch:9 step:7673 [D loss: 0.566050, acc: 82.81%] [G loss: 1.553386]\n",
      "epoch:9 step:7674 [D loss: 0.739929, acc: 41.41%] [G loss: 1.635296]\n",
      "epoch:9 step:7675 [D loss: 0.671719, acc: 59.38%] [G loss: 1.552062]\n",
      "epoch:9 step:7676 [D loss: 0.713659, acc: 52.34%] [G loss: 1.629949]\n",
      "epoch:9 step:7677 [D loss: 0.810936, acc: 30.47%] [G loss: 1.464737]\n",
      "epoch:9 step:7678 [D loss: 0.845108, acc: 26.56%] [G loss: 1.525336]\n",
      "epoch:9 step:7679 [D loss: 0.671369, acc: 60.94%] [G loss: 1.735809]\n",
      "epoch:9 step:7680 [D loss: 0.588634, acc: 78.91%] [G loss: 1.650784]\n",
      "epoch:9 step:7681 [D loss: 0.691194, acc: 55.47%] [G loss: 1.564945]\n",
      "epoch:9 step:7682 [D loss: 0.622600, acc: 75.78%] [G loss: 1.583080]\n",
      "epoch:9 step:7683 [D loss: 0.624683, acc: 72.66%] [G loss: 1.572289]\n",
      "epoch:9 step:7684 [D loss: 0.694441, acc: 53.12%] [G loss: 1.517675]\n",
      "epoch:9 step:7685 [D loss: 0.719086, acc: 50.78%] [G loss: 1.584378]\n",
      "epoch:9 step:7686 [D loss: 0.582449, acc: 77.34%] [G loss: 1.640819]\n",
      "epoch:9 step:7687 [D loss: 0.607215, acc: 67.19%] [G loss: 1.544523]\n",
      "epoch:9 step:7688 [D loss: 0.635674, acc: 64.06%] [G loss: 1.626798]\n",
      "epoch:9 step:7689 [D loss: 0.862492, acc: 15.62%] [G loss: 1.368963]\n",
      "epoch:9 step:7690 [D loss: 0.766622, acc: 39.06%] [G loss: 1.450498]\n",
      "epoch:9 step:7691 [D loss: 0.671461, acc: 60.16%] [G loss: 1.598779]\n",
      "epoch:9 step:7692 [D loss: 0.643313, acc: 65.62%] [G loss: 1.569207]\n",
      "epoch:9 step:7693 [D loss: 0.720356, acc: 49.22%] [G loss: 1.612262]\n",
      "epoch:9 step:7694 [D loss: 0.686717, acc: 57.03%] [G loss: 1.682496]\n",
      "epoch:9 step:7695 [D loss: 0.602390, acc: 75.00%] [G loss: 1.742969]\n",
      "epoch:9 step:7696 [D loss: 0.761446, acc: 34.38%] [G loss: 1.380298]\n",
      "epoch:9 step:7697 [D loss: 0.657038, acc: 60.94%] [G loss: 1.701303]\n",
      "epoch:9 step:7698 [D loss: 0.677158, acc: 56.25%] [G loss: 1.556905]\n",
      "epoch:9 step:7699 [D loss: 0.716401, acc: 46.88%] [G loss: 1.553686]\n",
      "epoch:9 step:7700 [D loss: 0.737643, acc: 50.78%] [G loss: 1.684997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7701 [D loss: 0.797293, acc: 36.72%] [G loss: 1.355302]\n",
      "epoch:9 step:7702 [D loss: 0.625025, acc: 67.19%] [G loss: 1.438442]\n",
      "epoch:9 step:7703 [D loss: 0.509992, acc: 89.84%] [G loss: 1.744607]\n",
      "epoch:9 step:7704 [D loss: 0.646270, acc: 67.97%] [G loss: 1.696475]\n",
      "epoch:9 step:7705 [D loss: 0.664292, acc: 61.72%] [G loss: 1.623620]\n",
      "epoch:9 step:7706 [D loss: 0.554202, acc: 87.50%] [G loss: 1.574870]\n",
      "epoch:9 step:7707 [D loss: 0.654048, acc: 62.50%] [G loss: 1.593009]\n",
      "epoch:9 step:7708 [D loss: 0.683502, acc: 57.81%] [G loss: 1.556239]\n",
      "epoch:9 step:7709 [D loss: 0.555509, acc: 87.50%] [G loss: 1.620814]\n",
      "epoch:9 step:7710 [D loss: 0.646584, acc: 67.97%] [G loss: 1.591562]\n",
      "epoch:9 step:7711 [D loss: 0.824704, acc: 34.38%] [G loss: 1.384393]\n",
      "epoch:9 step:7712 [D loss: 0.797966, acc: 30.47%] [G loss: 1.608003]\n",
      "epoch:9 step:7713 [D loss: 0.709132, acc: 46.88%] [G loss: 1.432614]\n",
      "epoch:9 step:7714 [D loss: 0.554709, acc: 82.03%] [G loss: 1.750014]\n",
      "epoch:9 step:7715 [D loss: 0.718328, acc: 52.34%] [G loss: 1.516173]\n",
      "epoch:9 step:7716 [D loss: 0.577975, acc: 73.44%] [G loss: 1.580896]\n",
      "epoch:9 step:7717 [D loss: 0.697354, acc: 53.91%] [G loss: 1.620805]\n",
      "epoch:9 step:7718 [D loss: 0.644795, acc: 62.50%] [G loss: 1.616915]\n",
      "epoch:9 step:7719 [D loss: 0.627491, acc: 75.00%] [G loss: 1.583289]\n",
      "epoch:9 step:7720 [D loss: 0.685817, acc: 53.12%] [G loss: 1.500881]\n",
      "epoch:9 step:7721 [D loss: 1.166451, acc: 21.09%] [G loss: 1.413488]\n",
      "epoch:9 step:7722 [D loss: 0.647095, acc: 60.94%] [G loss: 1.807021]\n",
      "epoch:9 step:7723 [D loss: 0.673721, acc: 50.00%] [G loss: 1.770193]\n",
      "epoch:9 step:7724 [D loss: 0.678933, acc: 57.03%] [G loss: 1.728988]\n",
      "epoch:9 step:7725 [D loss: 0.618940, acc: 71.09%] [G loss: 1.574361]\n",
      "epoch:9 step:7726 [D loss: 0.560847, acc: 78.91%] [G loss: 1.504092]\n",
      "epoch:9 step:7727 [D loss: 0.587556, acc: 75.00%] [G loss: 1.782460]\n",
      "epoch:9 step:7728 [D loss: 0.649787, acc: 66.41%] [G loss: 1.764389]\n",
      "epoch:9 step:7729 [D loss: 0.563538, acc: 79.69%] [G loss: 1.701807]\n",
      "epoch:9 step:7730 [D loss: 0.721682, acc: 48.44%] [G loss: 1.679110]\n",
      "epoch:9 step:7731 [D loss: 0.576628, acc: 73.44%] [G loss: 1.733652]\n",
      "epoch:9 step:7732 [D loss: 0.652393, acc: 63.28%] [G loss: 1.697909]\n",
      "epoch:9 step:7733 [D loss: 0.591000, acc: 69.53%] [G loss: 1.443656]\n",
      "epoch:9 step:7734 [D loss: 0.617189, acc: 66.41%] [G loss: 1.835258]\n",
      "epoch:9 step:7735 [D loss: 0.654194, acc: 65.62%] [G loss: 1.586782]\n",
      "epoch:9 step:7736 [D loss: 0.653409, acc: 64.84%] [G loss: 1.655508]\n",
      "epoch:9 step:7737 [D loss: 0.522956, acc: 76.56%] [G loss: 1.795441]\n",
      "epoch:9 step:7738 [D loss: 0.764692, acc: 46.88%] [G loss: 1.545860]\n",
      "epoch:9 step:7739 [D loss: 0.575378, acc: 77.34%] [G loss: 1.617440]\n",
      "epoch:9 step:7740 [D loss: 0.708606, acc: 48.44%] [G loss: 1.433072]\n",
      "epoch:9 step:7741 [D loss: 0.671152, acc: 60.16%] [G loss: 1.512843]\n",
      "epoch:9 step:7742 [D loss: 0.661241, acc: 57.03%] [G loss: 1.353672]\n",
      "epoch:9 step:7743 [D loss: 0.662280, acc: 63.28%] [G loss: 1.636442]\n",
      "epoch:9 step:7744 [D loss: 0.853178, acc: 31.25%] [G loss: 1.399935]\n",
      "epoch:9 step:7745 [D loss: 0.474213, acc: 87.50%] [G loss: 1.666134]\n",
      "epoch:9 step:7746 [D loss: 0.543485, acc: 82.81%] [G loss: 1.705884]\n",
      "epoch:9 step:7747 [D loss: 0.834713, acc: 29.69%] [G loss: 1.535074]\n",
      "epoch:9 step:7748 [D loss: 0.610459, acc: 71.09%] [G loss: 1.635737]\n",
      "epoch:9 step:7749 [D loss: 0.501701, acc: 77.34%] [G loss: 1.636912]\n",
      "epoch:9 step:7750 [D loss: 0.786610, acc: 29.69%] [G loss: 1.484182]\n",
      "epoch:9 step:7751 [D loss: 0.780324, acc: 42.97%] [G loss: 1.609709]\n",
      "epoch:9 step:7752 [D loss: 0.842153, acc: 26.56%] [G loss: 1.802573]\n",
      "epoch:9 step:7753 [D loss: 0.708574, acc: 50.00%] [G loss: 1.657627]\n",
      "epoch:9 step:7754 [D loss: 0.678820, acc: 60.94%] [G loss: 1.825522]\n",
      "epoch:9 step:7755 [D loss: 0.781993, acc: 29.69%] [G loss: 1.485071]\n",
      "epoch:9 step:7756 [D loss: 0.753362, acc: 47.66%] [G loss: 1.502273]\n",
      "epoch:9 step:7757 [D loss: 0.659135, acc: 60.16%] [G loss: 1.584678]\n",
      "epoch:9 step:7758 [D loss: 0.720767, acc: 50.00%] [G loss: 1.565011]\n",
      "epoch:9 step:7759 [D loss: 0.731431, acc: 46.09%] [G loss: 1.527814]\n",
      "epoch:9 step:7760 [D loss: 0.507749, acc: 75.00%] [G loss: 1.697117]\n",
      "epoch:9 step:7761 [D loss: 0.736282, acc: 49.22%] [G loss: 1.530760]\n",
      "epoch:9 step:7762 [D loss: 0.774250, acc: 36.72%] [G loss: 1.496896]\n",
      "epoch:9 step:7763 [D loss: 0.752179, acc: 43.75%] [G loss: 1.638053]\n",
      "epoch:9 step:7764 [D loss: 0.550419, acc: 81.25%] [G loss: 1.746199]\n",
      "epoch:9 step:7765 [D loss: 0.565532, acc: 80.47%] [G loss: 1.649374]\n",
      "epoch:9 step:7766 [D loss: 0.708745, acc: 55.47%] [G loss: 1.678983]\n",
      "epoch:9 step:7767 [D loss: 0.612284, acc: 67.19%] [G loss: 1.771440]\n",
      "epoch:9 step:7768 [D loss: 0.748387, acc: 41.41%] [G loss: 1.603071]\n",
      "epoch:9 step:7769 [D loss: 0.800772, acc: 30.47%] [G loss: 1.506474]\n",
      "epoch:9 step:7770 [D loss: 0.595977, acc: 78.12%] [G loss: 1.607734]\n",
      "epoch:9 step:7771 [D loss: 0.669683, acc: 60.16%] [G loss: 1.610644]\n",
      "epoch:9 step:7772 [D loss: 0.625194, acc: 67.97%] [G loss: 1.689234]\n",
      "epoch:9 step:7773 [D loss: 0.647287, acc: 64.84%] [G loss: 1.510739]\n",
      "epoch:9 step:7774 [D loss: 0.592054, acc: 78.12%] [G loss: 1.553857]\n",
      "epoch:9 step:7775 [D loss: 0.617614, acc: 70.31%] [G loss: 1.755729]\n",
      "epoch:9 step:7776 [D loss: 0.668337, acc: 64.84%] [G loss: 1.751303]\n",
      "epoch:9 step:7777 [D loss: 0.653545, acc: 67.19%] [G loss: 1.721267]\n",
      "epoch:9 step:7778 [D loss: 0.721822, acc: 51.56%] [G loss: 1.416247]\n",
      "epoch:9 step:7779 [D loss: 1.000254, acc: 11.72%] [G loss: 1.495809]\n",
      "epoch:9 step:7780 [D loss: 0.863342, acc: 24.22%] [G loss: 1.245432]\n",
      "epoch:9 step:7781 [D loss: 0.670685, acc: 57.81%] [G loss: 1.728304]\n",
      "epoch:9 step:7782 [D loss: 0.635469, acc: 67.19%] [G loss: 1.727829]\n",
      "epoch:9 step:7783 [D loss: 0.567676, acc: 84.38%] [G loss: 1.602471]\n",
      "epoch:9 step:7784 [D loss: 0.593921, acc: 69.53%] [G loss: 1.579204]\n",
      "epoch:9 step:7785 [D loss: 0.846739, acc: 28.91%] [G loss: 1.477371]\n",
      "epoch:9 step:7786 [D loss: 0.739952, acc: 43.75%] [G loss: 1.492058]\n",
      "epoch:9 step:7787 [D loss: 0.575866, acc: 78.12%] [G loss: 1.687270]\n",
      "epoch:9 step:7788 [D loss: 0.725875, acc: 50.78%] [G loss: 1.523657]\n",
      "epoch:9 step:7789 [D loss: 0.802715, acc: 36.72%] [G loss: 1.469397]\n",
      "epoch:9 step:7790 [D loss: 0.742963, acc: 47.66%] [G loss: 1.489486]\n",
      "epoch:9 step:7791 [D loss: 0.516845, acc: 89.06%] [G loss: 1.592289]\n",
      "epoch:9 step:7792 [D loss: 0.666295, acc: 56.25%] [G loss: 1.582726]\n",
      "epoch:9 step:7793 [D loss: 0.864482, acc: 25.00%] [G loss: 1.239277]\n",
      "epoch:9 step:7794 [D loss: 0.673880, acc: 61.72%] [G loss: 1.623486]\n",
      "epoch:9 step:7795 [D loss: 0.637858, acc: 64.84%] [G loss: 1.529173]\n",
      "epoch:9 step:7796 [D loss: 0.525601, acc: 71.09%] [G loss: 1.819103]\n",
      "epoch:9 step:7797 [D loss: 0.669983, acc: 60.16%] [G loss: 1.694072]\n",
      "epoch:9 step:7798 [D loss: 0.695133, acc: 48.44%] [G loss: 1.774917]\n",
      "epoch:9 step:7799 [D loss: 0.518981, acc: 81.25%] [G loss: 1.675968]\n",
      "epoch:9 step:7800 [D loss: 0.808150, acc: 42.19%] [G loss: 1.601998]\n",
      "epoch:9 step:7801 [D loss: 0.744721, acc: 43.75%] [G loss: 1.666808]\n",
      "epoch:9 step:7802 [D loss: 0.542455, acc: 80.47%] [G loss: 1.782511]\n",
      "epoch:9 step:7803 [D loss: 0.492829, acc: 84.38%] [G loss: 1.709496]\n",
      "epoch:9 step:7804 [D loss: 0.736299, acc: 50.78%] [G loss: 1.633442]\n",
      "epoch:9 step:7805 [D loss: 0.690151, acc: 59.38%] [G loss: 1.652731]\n",
      "epoch:9 step:7806 [D loss: 0.797841, acc: 39.84%] [G loss: 1.454633]\n",
      "epoch:9 step:7807 [D loss: 0.623404, acc: 66.41%] [G loss: 1.551998]\n",
      "epoch:9 step:7808 [D loss: 0.711007, acc: 53.12%] [G loss: 1.720010]\n",
      "epoch:9 step:7809 [D loss: 0.859078, acc: 23.44%] [G loss: 1.319401]\n",
      "epoch:9 step:7810 [D loss: 0.708194, acc: 46.09%] [G loss: 1.594153]\n",
      "epoch:10 step:7811 [D loss: 0.702027, acc: 52.34%] [G loss: 1.566865]\n",
      "epoch:10 step:7812 [D loss: 0.654501, acc: 58.59%] [G loss: 1.713734]\n",
      "epoch:10 step:7813 [D loss: 0.835473, acc: 28.12%] [G loss: 1.516309]\n",
      "epoch:10 step:7814 [D loss: 0.700502, acc: 50.78%] [G loss: 1.402164]\n",
      "epoch:10 step:7815 [D loss: 0.692045, acc: 45.31%] [G loss: 1.699542]\n",
      "epoch:10 step:7816 [D loss: 0.649550, acc: 64.84%] [G loss: 1.762023]\n",
      "epoch:10 step:7817 [D loss: 0.592281, acc: 76.56%] [G loss: 1.659961]\n",
      "epoch:10 step:7818 [D loss: 0.698896, acc: 55.47%] [G loss: 1.489335]\n",
      "epoch:10 step:7819 [D loss: 0.560602, acc: 76.56%] [G loss: 1.747979]\n",
      "epoch:10 step:7820 [D loss: 0.636758, acc: 64.84%] [G loss: 1.434677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7821 [D loss: 0.679474, acc: 60.94%] [G loss: 1.649626]\n",
      "epoch:10 step:7822 [D loss: 0.476709, acc: 71.09%] [G loss: 1.706631]\n",
      "epoch:10 step:7823 [D loss: 0.649219, acc: 61.72%] [G loss: 1.629420]\n",
      "epoch:10 step:7824 [D loss: 0.544694, acc: 82.81%] [G loss: 1.453511]\n",
      "epoch:10 step:7825 [D loss: 0.722414, acc: 47.66%] [G loss: 1.501029]\n",
      "epoch:10 step:7826 [D loss: 0.667665, acc: 60.16%] [G loss: 1.440558]\n",
      "epoch:10 step:7827 [D loss: 0.704443, acc: 54.69%] [G loss: 1.570646]\n",
      "epoch:10 step:7828 [D loss: 0.623743, acc: 71.88%] [G loss: 1.635374]\n",
      "epoch:10 step:7829 [D loss: 0.630364, acc: 64.84%] [G loss: 1.692973]\n",
      "epoch:10 step:7830 [D loss: 0.594922, acc: 72.66%] [G loss: 1.737022]\n",
      "epoch:10 step:7831 [D loss: 0.623849, acc: 69.53%] [G loss: 1.607252]\n",
      "epoch:10 step:7832 [D loss: 0.630306, acc: 67.97%] [G loss: 1.673562]\n",
      "epoch:10 step:7833 [D loss: 0.508291, acc: 82.03%] [G loss: 1.816404]\n",
      "epoch:10 step:7834 [D loss: 0.593766, acc: 73.44%] [G loss: 1.636101]\n",
      "epoch:10 step:7835 [D loss: 0.721682, acc: 52.34%] [G loss: 1.672107]\n",
      "epoch:10 step:7836 [D loss: 0.663352, acc: 58.59%] [G loss: 1.626716]\n",
      "epoch:10 step:7837 [D loss: 0.787626, acc: 37.50%] [G loss: 1.700126]\n",
      "epoch:10 step:7838 [D loss: 0.442034, acc: 83.59%] [G loss: 2.089910]\n",
      "epoch:10 step:7839 [D loss: 0.789840, acc: 48.44%] [G loss: 1.766487]\n",
      "epoch:10 step:7840 [D loss: 0.781730, acc: 42.97%] [G loss: 1.622981]\n",
      "epoch:10 step:7841 [D loss: 0.588580, acc: 74.22%] [G loss: 1.687005]\n",
      "epoch:10 step:7842 [D loss: 0.582245, acc: 62.50%] [G loss: 1.759203]\n",
      "epoch:10 step:7843 [D loss: 0.799967, acc: 42.97%] [G loss: 1.616809]\n",
      "epoch:10 step:7844 [D loss: 0.725790, acc: 44.53%] [G loss: 1.627326]\n",
      "epoch:10 step:7845 [D loss: 0.624138, acc: 65.62%] [G loss: 1.468231]\n",
      "epoch:10 step:7846 [D loss: 0.679578, acc: 57.03%] [G loss: 1.754196]\n",
      "epoch:10 step:7847 [D loss: 0.706042, acc: 51.56%] [G loss: 1.977027]\n",
      "epoch:10 step:7848 [D loss: 0.413403, acc: 82.03%] [G loss: 1.564024]\n",
      "epoch:10 step:7849 [D loss: 0.705020, acc: 49.22%] [G loss: 1.716526]\n",
      "epoch:10 step:7850 [D loss: 0.698695, acc: 52.34%] [G loss: 1.957681]\n",
      "epoch:10 step:7851 [D loss: 0.619123, acc: 66.41%] [G loss: 1.631371]\n",
      "epoch:10 step:7852 [D loss: 0.646716, acc: 65.62%] [G loss: 1.557827]\n",
      "epoch:10 step:7853 [D loss: 0.746118, acc: 43.75%] [G loss: 1.635742]\n",
      "epoch:10 step:7854 [D loss: 0.972514, acc: 36.72%] [G loss: 1.071651]\n",
      "epoch:10 step:7855 [D loss: 0.858336, acc: 38.28%] [G loss: 1.478789]\n",
      "epoch:10 step:7856 [D loss: 0.662944, acc: 59.38%] [G loss: 1.507798]\n",
      "epoch:10 step:7857 [D loss: 0.785003, acc: 40.62%] [G loss: 1.410983]\n",
      "epoch:10 step:7858 [D loss: 0.766214, acc: 29.69%] [G loss: 1.550452]\n",
      "epoch:10 step:7859 [D loss: 0.681263, acc: 58.59%] [G loss: 1.632963]\n",
      "epoch:10 step:7860 [D loss: 0.654674, acc: 60.94%] [G loss: 1.704563]\n",
      "epoch:10 step:7861 [D loss: 0.757393, acc: 46.88%] [G loss: 1.640002]\n",
      "epoch:10 step:7862 [D loss: 0.734264, acc: 47.66%] [G loss: 1.680124]\n",
      "epoch:10 step:7863 [D loss: 0.606974, acc: 67.19%] [G loss: 1.843890]\n",
      "epoch:10 step:7864 [D loss: 0.717854, acc: 49.22%] [G loss: 1.677088]\n",
      "epoch:10 step:7865 [D loss: 0.738186, acc: 47.66%] [G loss: 1.598412]\n",
      "epoch:10 step:7866 [D loss: 0.896354, acc: 17.19%] [G loss: 1.400943]\n",
      "epoch:10 step:7867 [D loss: 0.928761, acc: 12.50%] [G loss: 1.443968]\n",
      "epoch:10 step:7868 [D loss: 0.689203, acc: 60.16%] [G loss: 1.648492]\n",
      "epoch:10 step:7869 [D loss: 0.617806, acc: 68.75%] [G loss: 1.602876]\n",
      "epoch:10 step:7870 [D loss: 0.728690, acc: 49.22%] [G loss: 1.513401]\n",
      "epoch:10 step:7871 [D loss: 0.635776, acc: 64.84%] [G loss: 1.595958]\n",
      "epoch:10 step:7872 [D loss: 0.793076, acc: 35.16%] [G loss: 1.537160]\n",
      "epoch:10 step:7873 [D loss: 0.620335, acc: 64.06%] [G loss: 1.596206]\n",
      "epoch:10 step:7874 [D loss: 0.536698, acc: 74.22%] [G loss: 1.693467]\n",
      "epoch:10 step:7875 [D loss: 0.734122, acc: 45.31%] [G loss: 1.585531]\n",
      "epoch:10 step:7876 [D loss: 0.554680, acc: 78.91%] [G loss: 1.662102]\n",
      "epoch:10 step:7877 [D loss: 0.685537, acc: 53.12%] [G loss: 1.760278]\n",
      "epoch:10 step:7878 [D loss: 0.694304, acc: 56.25%] [G loss: 1.568964]\n",
      "epoch:10 step:7879 [D loss: 0.515952, acc: 78.91%] [G loss: 1.914582]\n",
      "epoch:10 step:7880 [D loss: 0.761936, acc: 41.41%] [G loss: 1.486686]\n",
      "epoch:10 step:7881 [D loss: 1.087598, acc: 15.62%] [G loss: 1.375082]\n",
      "epoch:10 step:7882 [D loss: 0.544331, acc: 76.56%] [G loss: 1.432808]\n",
      "epoch:10 step:7883 [D loss: 0.809270, acc: 45.31%] [G loss: 1.573674]\n",
      "epoch:10 step:7884 [D loss: 0.836642, acc: 35.16%] [G loss: 1.462319]\n",
      "epoch:10 step:7885 [D loss: 0.746426, acc: 42.19%] [G loss: 1.611246]\n",
      "epoch:10 step:7886 [D loss: 0.626989, acc: 67.97%] [G loss: 1.575879]\n",
      "epoch:10 step:7887 [D loss: 0.728535, acc: 48.44%] [G loss: 1.598338]\n",
      "epoch:10 step:7888 [D loss: 0.550948, acc: 77.34%] [G loss: 1.469609]\n",
      "epoch:10 step:7889 [D loss: 0.618701, acc: 67.19%] [G loss: 1.756646]\n",
      "epoch:10 step:7890 [D loss: 0.760985, acc: 42.19%] [G loss: 1.464181]\n",
      "epoch:10 step:7891 [D loss: 0.754192, acc: 43.75%] [G loss: 1.500102]\n",
      "epoch:10 step:7892 [D loss: 0.692504, acc: 53.91%] [G loss: 1.586814]\n",
      "epoch:10 step:7893 [D loss: 0.767219, acc: 42.97%] [G loss: 1.406836]\n",
      "epoch:10 step:7894 [D loss: 0.844554, acc: 39.06%] [G loss: 1.384207]\n",
      "epoch:10 step:7895 [D loss: 0.729717, acc: 50.78%] [G loss: 1.622474]\n",
      "epoch:10 step:7896 [D loss: 0.602992, acc: 71.09%] [G loss: 1.543598]\n",
      "epoch:10 step:7897 [D loss: 0.664400, acc: 58.59%] [G loss: 1.649112]\n",
      "epoch:10 step:7898 [D loss: 0.700808, acc: 54.69%] [G loss: 1.676597]\n",
      "epoch:10 step:7899 [D loss: 0.674095, acc: 60.16%] [G loss: 1.681657]\n",
      "epoch:10 step:7900 [D loss: 0.640318, acc: 59.38%] [G loss: 1.449853]\n",
      "epoch:10 step:7901 [D loss: 0.748964, acc: 45.31%] [G loss: 1.603997]\n",
      "epoch:10 step:7902 [D loss: 0.606869, acc: 71.09%] [G loss: 1.550946]\n",
      "epoch:10 step:7903 [D loss: 0.693835, acc: 53.91%] [G loss: 1.851762]\n",
      "epoch:10 step:7904 [D loss: 0.724229, acc: 46.09%] [G loss: 1.606213]\n",
      "epoch:10 step:7905 [D loss: 0.665714, acc: 60.94%] [G loss: 1.564770]\n",
      "epoch:10 step:7906 [D loss: 0.540155, acc: 67.19%] [G loss: 1.387414]\n",
      "epoch:10 step:7907 [D loss: 0.732330, acc: 43.75%] [G loss: 1.549460]\n",
      "epoch:10 step:7908 [D loss: 0.786034, acc: 38.28%] [G loss: 1.311158]\n",
      "epoch:10 step:7909 [D loss: 0.732219, acc: 46.09%] [G loss: 1.564729]\n",
      "epoch:10 step:7910 [D loss: 0.662898, acc: 60.94%] [G loss: 1.652343]\n",
      "epoch:10 step:7911 [D loss: 0.750281, acc: 44.53%] [G loss: 1.458538]\n",
      "epoch:10 step:7912 [D loss: 0.685538, acc: 60.16%] [G loss: 1.443707]\n",
      "epoch:10 step:7913 [D loss: 0.761721, acc: 37.50%] [G loss: 1.687935]\n",
      "epoch:10 step:7914 [D loss: 0.734489, acc: 46.09%] [G loss: 1.593284]\n",
      "epoch:10 step:7915 [D loss: 0.550069, acc: 80.47%] [G loss: 1.661921]\n",
      "epoch:10 step:7916 [D loss: 0.669061, acc: 55.47%] [G loss: 1.566827]\n",
      "epoch:10 step:7917 [D loss: 0.634573, acc: 64.06%] [G loss: 1.522466]\n",
      "epoch:10 step:7918 [D loss: 0.830778, acc: 32.81%] [G loss: 1.679182]\n",
      "epoch:10 step:7919 [D loss: 0.598512, acc: 64.84%] [G loss: 1.695394]\n",
      "epoch:10 step:7920 [D loss: 0.785061, acc: 40.62%] [G loss: 1.628455]\n",
      "epoch:10 step:7921 [D loss: 0.797745, acc: 33.59%] [G loss: 1.567088]\n",
      "epoch:10 step:7922 [D loss: 0.679154, acc: 62.50%] [G loss: 1.599061]\n",
      "epoch:10 step:7923 [D loss: 0.684821, acc: 60.16%] [G loss: 1.523394]\n",
      "epoch:10 step:7924 [D loss: 0.540582, acc: 87.50%] [G loss: 1.606560]\n",
      "epoch:10 step:7925 [D loss: 0.703204, acc: 57.81%] [G loss: 1.695140]\n",
      "epoch:10 step:7926 [D loss: 0.533483, acc: 83.59%] [G loss: 1.689282]\n",
      "epoch:10 step:7927 [D loss: 0.878750, acc: 28.91%] [G loss: 1.341244]\n",
      "epoch:10 step:7928 [D loss: 0.678680, acc: 58.59%] [G loss: 1.555745]\n",
      "epoch:10 step:7929 [D loss: 0.633682, acc: 69.53%] [G loss: 1.943377]\n",
      "epoch:10 step:7930 [D loss: 0.679496, acc: 53.91%] [G loss: 1.772503]\n",
      "epoch:10 step:7931 [D loss: 0.575790, acc: 66.41%] [G loss: 1.611677]\n",
      "epoch:10 step:7932 [D loss: 0.736197, acc: 48.44%] [G loss: 1.539797]\n",
      "epoch:10 step:7933 [D loss: 0.587294, acc: 78.12%] [G loss: 1.646549]\n",
      "epoch:10 step:7934 [D loss: 0.614854, acc: 74.22%] [G loss: 1.786166]\n",
      "epoch:10 step:7935 [D loss: 0.508405, acc: 78.12%] [G loss: 1.322672]\n",
      "epoch:10 step:7936 [D loss: 0.818561, acc: 37.50%] [G loss: 1.398488]\n",
      "epoch:10 step:7937 [D loss: 0.709780, acc: 51.56%] [G loss: 1.494744]\n",
      "epoch:10 step:7938 [D loss: 0.689174, acc: 48.44%] [G loss: 1.647790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7939 [D loss: 0.584595, acc: 71.09%] [G loss: 1.710232]\n",
      "epoch:10 step:7940 [D loss: 0.810455, acc: 43.75%] [G loss: 1.613753]\n",
      "epoch:10 step:7941 [D loss: 0.694385, acc: 52.34%] [G loss: 1.606830]\n",
      "epoch:10 step:7942 [D loss: 0.785334, acc: 34.38%] [G loss: 1.584535]\n",
      "epoch:10 step:7943 [D loss: 0.733242, acc: 42.19%] [G loss: 1.371410]\n",
      "epoch:10 step:7944 [D loss: 0.781209, acc: 48.44%] [G loss: 1.437993]\n",
      "epoch:10 step:7945 [D loss: 0.618915, acc: 67.19%] [G loss: 1.677996]\n",
      "epoch:10 step:7946 [D loss: 0.565142, acc: 82.81%] [G loss: 1.652991]\n",
      "epoch:10 step:7947 [D loss: 0.647556, acc: 63.28%] [G loss: 1.506124]\n",
      "epoch:10 step:7948 [D loss: 0.673504, acc: 53.91%] [G loss: 1.810815]\n",
      "epoch:10 step:7949 [D loss: 0.633943, acc: 64.06%] [G loss: 1.563411]\n",
      "epoch:10 step:7950 [D loss: 0.552667, acc: 72.66%] [G loss: 1.628169]\n",
      "epoch:10 step:7951 [D loss: 0.808074, acc: 32.03%] [G loss: 1.601936]\n",
      "epoch:10 step:7952 [D loss: 0.777788, acc: 32.81%] [G loss: 1.443638]\n",
      "epoch:10 step:7953 [D loss: 0.717836, acc: 46.09%] [G loss: 1.851140]\n",
      "epoch:10 step:7954 [D loss: 0.613565, acc: 71.09%] [G loss: 1.658681]\n",
      "epoch:10 step:7955 [D loss: 0.629287, acc: 63.28%] [G loss: 1.458751]\n",
      "epoch:10 step:7956 [D loss: 0.643759, acc: 64.06%] [G loss: 1.709640]\n",
      "epoch:10 step:7957 [D loss: 0.657294, acc: 60.94%] [G loss: 1.686073]\n",
      "epoch:10 step:7958 [D loss: 0.680571, acc: 57.81%] [G loss: 1.589772]\n",
      "epoch:10 step:7959 [D loss: 0.792613, acc: 32.03%] [G loss: 1.517831]\n",
      "epoch:10 step:7960 [D loss: 0.773717, acc: 35.94%] [G loss: 1.387986]\n",
      "epoch:10 step:7961 [D loss: 0.758080, acc: 37.50%] [G loss: 1.484395]\n",
      "epoch:10 step:7962 [D loss: 0.713309, acc: 50.00%] [G loss: 1.566476]\n",
      "epoch:10 step:7963 [D loss: 0.674571, acc: 58.59%] [G loss: 1.554499]\n",
      "epoch:10 step:7964 [D loss: 0.677768, acc: 50.78%] [G loss: 1.565382]\n",
      "epoch:10 step:7965 [D loss: 0.602529, acc: 60.94%] [G loss: 1.616439]\n",
      "epoch:10 step:7966 [D loss: 0.653162, acc: 67.19%] [G loss: 1.651779]\n",
      "epoch:10 step:7967 [D loss: 0.759394, acc: 42.97%] [G loss: 1.479379]\n",
      "epoch:10 step:7968 [D loss: 0.613168, acc: 69.53%] [G loss: 1.582726]\n",
      "epoch:10 step:7969 [D loss: 0.658874, acc: 60.94%] [G loss: 1.605737]\n",
      "epoch:10 step:7970 [D loss: 0.777241, acc: 47.66%] [G loss: 1.342992]\n",
      "epoch:10 step:7971 [D loss: 0.708273, acc: 47.66%] [G loss: 1.506513]\n",
      "epoch:10 step:7972 [D loss: 0.434919, acc: 92.19%] [G loss: 1.659306]\n",
      "epoch:10 step:7973 [D loss: 0.504400, acc: 83.59%] [G loss: 1.545905]\n",
      "epoch:10 step:7974 [D loss: 0.592795, acc: 78.12%] [G loss: 1.520996]\n",
      "epoch:10 step:7975 [D loss: 0.803895, acc: 35.94%] [G loss: 1.546858]\n",
      "epoch:10 step:7976 [D loss: 0.672776, acc: 54.69%] [G loss: 1.432424]\n",
      "epoch:10 step:7977 [D loss: 0.723311, acc: 46.88%] [G loss: 1.500679]\n",
      "epoch:10 step:7978 [D loss: 0.724939, acc: 46.09%] [G loss: 1.515102]\n",
      "epoch:10 step:7979 [D loss: 0.746647, acc: 45.31%] [G loss: 1.316999]\n",
      "epoch:10 step:7980 [D loss: 0.863907, acc: 25.78%] [G loss: 1.472482]\n",
      "epoch:10 step:7981 [D loss: 0.703757, acc: 53.91%] [G loss: 1.535966]\n",
      "epoch:10 step:7982 [D loss: 0.438982, acc: 89.84%] [G loss: 1.645170]\n",
      "epoch:10 step:7983 [D loss: 0.881333, acc: 24.22%] [G loss: 1.503982]\n",
      "epoch:10 step:7984 [D loss: 0.558529, acc: 77.34%] [G loss: 1.338485]\n",
      "epoch:10 step:7985 [D loss: 0.682308, acc: 54.69%] [G loss: 1.734354]\n",
      "epoch:10 step:7986 [D loss: 0.649407, acc: 65.62%] [G loss: 1.685001]\n",
      "epoch:10 step:7987 [D loss: 0.637442, acc: 65.62%] [G loss: 1.361132]\n",
      "epoch:10 step:7988 [D loss: 1.072465, acc: 4.69%] [G loss: 1.200499]\n",
      "epoch:10 step:7989 [D loss: 0.718099, acc: 50.78%] [G loss: 1.720838]\n",
      "epoch:10 step:7990 [D loss: 0.791812, acc: 35.94%] [G loss: 1.522649]\n",
      "epoch:10 step:7991 [D loss: 0.667364, acc: 63.28%] [G loss: 1.713537]\n",
      "epoch:10 step:7992 [D loss: 0.708520, acc: 57.81%] [G loss: 1.605217]\n",
      "epoch:10 step:7993 [D loss: 0.716738, acc: 51.56%] [G loss: 1.714940]\n",
      "epoch:10 step:7994 [D loss: 0.928087, acc: 24.22%] [G loss: 1.564469]\n",
      "epoch:10 step:7995 [D loss: 0.676247, acc: 57.03%] [G loss: 1.462260]\n",
      "epoch:10 step:7996 [D loss: 0.554923, acc: 78.12%] [G loss: 1.707514]\n",
      "epoch:10 step:7997 [D loss: 0.633218, acc: 66.41%] [G loss: 1.715536]\n",
      "epoch:10 step:7998 [D loss: 0.681289, acc: 59.38%] [G loss: 1.757123]\n",
      "epoch:10 step:7999 [D loss: 0.580715, acc: 75.00%] [G loss: 1.791532]\n",
      "epoch:10 step:8000 [D loss: 0.666394, acc: 60.94%] [G loss: 1.675940]\n",
      "epoch:10 step:8001 [D loss: 0.488792, acc: 82.03%] [G loss: 1.696928]\n",
      "epoch:10 step:8002 [D loss: 0.654223, acc: 64.84%] [G loss: 1.575838]\n",
      "epoch:10 step:8003 [D loss: 0.580841, acc: 78.12%] [G loss: 1.807614]\n",
      "epoch:10 step:8004 [D loss: 0.681310, acc: 57.81%] [G loss: 1.690788]\n",
      "epoch:10 step:8005 [D loss: 0.714638, acc: 52.34%] [G loss: 1.470005]\n",
      "epoch:10 step:8006 [D loss: 0.950608, acc: 22.66%] [G loss: 1.131027]\n",
      "epoch:10 step:8007 [D loss: 0.603102, acc: 74.22%] [G loss: 1.674933]\n",
      "epoch:10 step:8008 [D loss: 0.642524, acc: 65.62%] [G loss: 1.533544]\n",
      "epoch:10 step:8009 [D loss: 0.693483, acc: 53.12%] [G loss: 1.718486]\n",
      "epoch:10 step:8010 [D loss: 0.714426, acc: 52.34%] [G loss: 1.591068]\n",
      "epoch:10 step:8011 [D loss: 0.628838, acc: 66.41%] [G loss: 1.601681]\n",
      "epoch:10 step:8012 [D loss: 1.067255, acc: 8.59%] [G loss: 1.221331]\n",
      "epoch:10 step:8013 [D loss: 0.737913, acc: 51.56%] [G loss: 1.500163]\n",
      "epoch:10 step:8014 [D loss: 0.632661, acc: 62.50%] [G loss: 1.622034]\n",
      "epoch:10 step:8015 [D loss: 0.938090, acc: 32.03%] [G loss: 1.134556]\n",
      "epoch:10 step:8016 [D loss: 0.757388, acc: 46.88%] [G loss: 1.532279]\n",
      "epoch:10 step:8017 [D loss: 0.723869, acc: 47.66%] [G loss: 1.675075]\n",
      "epoch:10 step:8018 [D loss: 0.547465, acc: 89.06%] [G loss: 1.565693]\n",
      "epoch:10 step:8019 [D loss: 0.548480, acc: 85.94%] [G loss: 1.667624]\n",
      "epoch:10 step:8020 [D loss: 0.825491, acc: 24.22%] [G loss: 1.430621]\n",
      "epoch:10 step:8021 [D loss: 0.709524, acc: 53.91%] [G loss: 1.516712]\n",
      "epoch:10 step:8022 [D loss: 0.668962, acc: 56.25%] [G loss: 1.619416]\n",
      "epoch:10 step:8023 [D loss: 0.731344, acc: 44.53%] [G loss: 1.468920]\n",
      "epoch:10 step:8024 [D loss: 0.614628, acc: 70.31%] [G loss: 1.587859]\n",
      "epoch:10 step:8025 [D loss: 0.665558, acc: 57.03%] [G loss: 1.490862]\n",
      "epoch:10 step:8026 [D loss: 0.603755, acc: 67.97%] [G loss: 1.788365]\n",
      "epoch:10 step:8027 [D loss: 0.797469, acc: 28.12%] [G loss: 1.538326]\n",
      "epoch:10 step:8028 [D loss: 0.661391, acc: 60.16%] [G loss: 1.613074]\n",
      "epoch:10 step:8029 [D loss: 0.650239, acc: 65.62%] [G loss: 1.667434]\n",
      "epoch:10 step:8030 [D loss: 0.723466, acc: 45.31%] [G loss: 1.711509]\n",
      "epoch:10 step:8031 [D loss: 0.696953, acc: 51.56%] [G loss: 1.426598]\n",
      "epoch:10 step:8032 [D loss: 0.713685, acc: 55.47%] [G loss: 1.657493]\n",
      "epoch:10 step:8033 [D loss: 0.610176, acc: 72.66%] [G loss: 1.752561]\n",
      "epoch:10 step:8034 [D loss: 0.488593, acc: 84.38%] [G loss: 1.633002]\n",
      "epoch:10 step:8035 [D loss: 0.551021, acc: 83.59%] [G loss: 1.814247]\n",
      "epoch:10 step:8036 [D loss: 0.793803, acc: 32.03%] [G loss: 1.486772]\n",
      "epoch:10 step:8037 [D loss: 0.653659, acc: 57.81%] [G loss: 1.655652]\n",
      "epoch:10 step:8038 [D loss: 0.664286, acc: 54.69%] [G loss: 1.837284]\n",
      "epoch:10 step:8039 [D loss: 0.579727, acc: 74.22%] [G loss: 1.595271]\n",
      "epoch:10 step:8040 [D loss: 0.749637, acc: 37.50%] [G loss: 1.441728]\n",
      "epoch:10 step:8041 [D loss: 0.670045, acc: 60.16%] [G loss: 1.590811]\n",
      "epoch:10 step:8042 [D loss: 0.804043, acc: 32.03%] [G loss: 1.394875]\n",
      "epoch:10 step:8043 [D loss: 0.706519, acc: 54.69%] [G loss: 1.486826]\n",
      "epoch:10 step:8044 [D loss: 0.790249, acc: 32.81%] [G loss: 1.622010]\n",
      "epoch:10 step:8045 [D loss: 0.661477, acc: 61.72%] [G loss: 1.647442]\n",
      "epoch:10 step:8046 [D loss: 0.593078, acc: 71.88%] [G loss: 1.730762]\n",
      "epoch:10 step:8047 [D loss: 0.692779, acc: 53.91%] [G loss: 1.680038]\n",
      "epoch:10 step:8048 [D loss: 0.649597, acc: 60.16%] [G loss: 1.712106]\n",
      "epoch:10 step:8049 [D loss: 0.541211, acc: 83.59%] [G loss: 1.860440]\n",
      "epoch:10 step:8050 [D loss: 0.615293, acc: 72.66%] [G loss: 1.691327]\n",
      "epoch:10 step:8051 [D loss: 0.606596, acc: 73.44%] [G loss: 1.853206]\n",
      "epoch:10 step:8052 [D loss: 0.811883, acc: 39.06%] [G loss: 1.474300]\n",
      "epoch:10 step:8053 [D loss: 0.601616, acc: 76.56%] [G loss: 1.610494]\n",
      "epoch:10 step:8054 [D loss: 0.574739, acc: 68.75%] [G loss: 1.711203]\n",
      "epoch:10 step:8055 [D loss: 0.729834, acc: 46.88%] [G loss: 1.649750]\n",
      "epoch:10 step:8056 [D loss: 0.781018, acc: 44.53%] [G loss: 1.609157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8057 [D loss: 0.820403, acc: 34.38%] [G loss: 1.671060]\n",
      "epoch:10 step:8058 [D loss: 0.721906, acc: 49.22%] [G loss: 1.531827]\n",
      "epoch:10 step:8059 [D loss: 0.725194, acc: 43.75%] [G loss: 1.342369]\n",
      "epoch:10 step:8060 [D loss: 0.579809, acc: 78.12%] [G loss: 1.650895]\n",
      "epoch:10 step:8061 [D loss: 0.754350, acc: 46.88%] [G loss: 1.698614]\n",
      "epoch:10 step:8062 [D loss: 0.495715, acc: 78.12%] [G loss: 1.538332]\n",
      "epoch:10 step:8063 [D loss: 0.771352, acc: 36.72%] [G loss: 1.585977]\n",
      "epoch:10 step:8064 [D loss: 0.799893, acc: 31.25%] [G loss: 1.454042]\n",
      "epoch:10 step:8065 [D loss: 0.720276, acc: 46.88%] [G loss: 1.719091]\n",
      "epoch:10 step:8066 [D loss: 0.720032, acc: 45.31%] [G loss: 1.622150]\n",
      "epoch:10 step:8067 [D loss: 0.642321, acc: 62.50%] [G loss: 1.362067]\n",
      "epoch:10 step:8068 [D loss: 0.635231, acc: 66.41%] [G loss: 1.511560]\n",
      "epoch:10 step:8069 [D loss: 0.712001, acc: 50.78%] [G loss: 1.398438]\n",
      "epoch:10 step:8070 [D loss: 0.659200, acc: 60.94%] [G loss: 1.855242]\n",
      "epoch:10 step:8071 [D loss: 0.562690, acc: 76.56%] [G loss: 1.576617]\n",
      "epoch:10 step:8072 [D loss: 0.690634, acc: 53.12%] [G loss: 1.493488]\n",
      "epoch:10 step:8073 [D loss: 0.918144, acc: 20.31%] [G loss: 1.368919]\n",
      "epoch:10 step:8074 [D loss: 0.623029, acc: 68.75%] [G loss: 1.612134]\n",
      "epoch:10 step:8075 [D loss: 0.677081, acc: 60.16%] [G loss: 1.561487]\n",
      "epoch:10 step:8076 [D loss: 0.643829, acc: 64.06%] [G loss: 1.593184]\n",
      "epoch:10 step:8077 [D loss: 0.993936, acc: 21.09%] [G loss: 1.266739]\n",
      "epoch:10 step:8078 [D loss: 0.663761, acc: 60.94%] [G loss: 1.751834]\n",
      "epoch:10 step:8079 [D loss: 0.656689, acc: 60.94%] [G loss: 1.624612]\n",
      "epoch:10 step:8080 [D loss: 0.718565, acc: 45.31%] [G loss: 1.378813]\n",
      "epoch:10 step:8081 [D loss: 0.609007, acc: 75.00%] [G loss: 1.547547]\n",
      "epoch:10 step:8082 [D loss: 0.580698, acc: 75.00%] [G loss: 1.687653]\n",
      "epoch:10 step:8083 [D loss: 0.681988, acc: 59.38%] [G loss: 1.631338]\n",
      "epoch:10 step:8084 [D loss: 0.773203, acc: 43.75%] [G loss: 1.544139]\n",
      "epoch:10 step:8085 [D loss: 0.668720, acc: 61.72%] [G loss: 1.720405]\n",
      "epoch:10 step:8086 [D loss: 0.663414, acc: 60.94%] [G loss: 1.559703]\n",
      "epoch:10 step:8087 [D loss: 1.227234, acc: 5.47%] [G loss: 1.329682]\n",
      "epoch:10 step:8088 [D loss: 0.753346, acc: 51.56%] [G loss: 1.568144]\n",
      "epoch:10 step:8089 [D loss: 0.740411, acc: 44.53%] [G loss: 1.606876]\n",
      "epoch:10 step:8090 [D loss: 0.632819, acc: 65.62%] [G loss: 1.651392]\n",
      "epoch:10 step:8091 [D loss: 0.573819, acc: 76.56%] [G loss: 1.575695]\n",
      "epoch:10 step:8092 [D loss: 0.794885, acc: 40.62%] [G loss: 1.497920]\n",
      "epoch:10 step:8093 [D loss: 0.633989, acc: 66.41%] [G loss: 1.707167]\n",
      "epoch:10 step:8094 [D loss: 0.638263, acc: 66.41%] [G loss: 1.714452]\n",
      "epoch:10 step:8095 [D loss: 0.591691, acc: 74.22%] [G loss: 1.783337]\n",
      "epoch:10 step:8096 [D loss: 0.677540, acc: 57.03%] [G loss: 1.810295]\n",
      "epoch:10 step:8097 [D loss: 0.681996, acc: 54.69%] [G loss: 1.646860]\n",
      "epoch:10 step:8098 [D loss: 0.782510, acc: 33.59%] [G loss: 1.606150]\n",
      "epoch:10 step:8099 [D loss: 0.655326, acc: 61.72%] [G loss: 1.569207]\n",
      "epoch:10 step:8100 [D loss: 0.690998, acc: 54.69%] [G loss: 1.435542]\n",
      "epoch:10 step:8101 [D loss: 0.755916, acc: 42.97%] [G loss: 1.398430]\n",
      "epoch:10 step:8102 [D loss: 0.693964, acc: 54.69%] [G loss: 1.545269]\n",
      "epoch:10 step:8103 [D loss: 0.673829, acc: 58.59%] [G loss: 1.549331]\n",
      "epoch:10 step:8104 [D loss: 0.566096, acc: 79.69%] [G loss: 1.526800]\n",
      "epoch:10 step:8105 [D loss: 0.655677, acc: 56.25%] [G loss: 1.855127]\n",
      "epoch:10 step:8106 [D loss: 0.729023, acc: 43.75%] [G loss: 1.472059]\n",
      "epoch:10 step:8107 [D loss: 0.685129, acc: 54.69%] [G loss: 1.710980]\n",
      "epoch:10 step:8108 [D loss: 0.687932, acc: 55.47%] [G loss: 1.645575]\n",
      "epoch:10 step:8109 [D loss: 0.606998, acc: 70.31%] [G loss: 1.751411]\n",
      "epoch:10 step:8110 [D loss: 0.622311, acc: 62.50%] [G loss: 1.635194]\n",
      "epoch:10 step:8111 [D loss: 0.771885, acc: 39.84%] [G loss: 1.578385]\n",
      "epoch:10 step:8112 [D loss: 0.590309, acc: 74.22%] [G loss: 1.542396]\n",
      "epoch:10 step:8113 [D loss: 0.683550, acc: 57.03%] [G loss: 1.588937]\n",
      "epoch:10 step:8114 [D loss: 0.733042, acc: 42.19%] [G loss: 1.597524]\n",
      "epoch:10 step:8115 [D loss: 0.797507, acc: 35.94%] [G loss: 1.598522]\n",
      "epoch:10 step:8116 [D loss: 0.674942, acc: 57.03%] [G loss: 1.611756]\n",
      "epoch:10 step:8117 [D loss: 0.699054, acc: 53.91%] [G loss: 1.564679]\n",
      "epoch:10 step:8118 [D loss: 0.527857, acc: 85.16%] [G loss: 1.766123]\n",
      "epoch:10 step:8119 [D loss: 0.644671, acc: 61.72%] [G loss: 1.488101]\n",
      "epoch:10 step:8120 [D loss: 0.653641, acc: 65.62%] [G loss: 1.558792]\n",
      "epoch:10 step:8121 [D loss: 0.726223, acc: 46.88%] [G loss: 1.650515]\n",
      "epoch:10 step:8122 [D loss: 0.577979, acc: 75.00%] [G loss: 1.746529]\n",
      "epoch:10 step:8123 [D loss: 0.686730, acc: 58.59%] [G loss: 1.521930]\n",
      "epoch:10 step:8124 [D loss: 0.747806, acc: 46.88%] [G loss: 1.503934]\n",
      "epoch:10 step:8125 [D loss: 0.858192, acc: 38.28%] [G loss: 1.272683]\n",
      "epoch:10 step:8126 [D loss: 0.671412, acc: 56.25%] [G loss: 1.715853]\n",
      "epoch:10 step:8127 [D loss: 0.690136, acc: 51.56%] [G loss: 1.633971]\n",
      "epoch:10 step:8128 [D loss: 0.599870, acc: 77.34%] [G loss: 1.706650]\n",
      "epoch:10 step:8129 [D loss: 0.655687, acc: 59.38%] [G loss: 1.723179]\n",
      "epoch:10 step:8130 [D loss: 0.909042, acc: 24.22%] [G loss: 1.421762]\n",
      "epoch:10 step:8131 [D loss: 0.627353, acc: 66.41%] [G loss: 1.846393]\n",
      "epoch:10 step:8132 [D loss: 0.661464, acc: 59.38%] [G loss: 1.791034]\n",
      "epoch:10 step:8133 [D loss: 0.547734, acc: 81.25%] [G loss: 1.658726]\n",
      "epoch:10 step:8134 [D loss: 0.531903, acc: 85.16%] [G loss: 1.666011]\n",
      "epoch:10 step:8135 [D loss: 0.658457, acc: 62.50%] [G loss: 1.605958]\n",
      "epoch:10 step:8136 [D loss: 0.678573, acc: 53.91%] [G loss: 1.526875]\n",
      "epoch:10 step:8137 [D loss: 0.490931, acc: 78.91%] [G loss: 1.428195]\n",
      "epoch:10 step:8138 [D loss: 0.646669, acc: 64.84%] [G loss: 1.660109]\n",
      "epoch:10 step:8139 [D loss: 0.717272, acc: 53.91%] [G loss: 1.594312]\n",
      "epoch:10 step:8140 [D loss: 0.842386, acc: 26.56%] [G loss: 1.515696]\n",
      "epoch:10 step:8141 [D loss: 0.783144, acc: 39.84%] [G loss: 1.365234]\n",
      "epoch:10 step:8142 [D loss: 0.627628, acc: 72.66%] [G loss: 1.643058]\n",
      "epoch:10 step:8143 [D loss: 0.558998, acc: 76.56%] [G loss: 1.704778]\n",
      "epoch:10 step:8144 [D loss: 0.642600, acc: 59.38%] [G loss: 1.559397]\n",
      "epoch:10 step:8145 [D loss: 0.771119, acc: 46.09%] [G loss: 1.475899]\n",
      "epoch:10 step:8146 [D loss: 0.682159, acc: 55.47%] [G loss: 1.494808]\n",
      "epoch:10 step:8147 [D loss: 0.695987, acc: 52.34%] [G loss: 1.604974]\n",
      "epoch:10 step:8148 [D loss: 0.887751, acc: 17.97%] [G loss: 1.385921]\n",
      "epoch:10 step:8149 [D loss: 0.746932, acc: 42.97%] [G loss: 1.500674]\n",
      "epoch:10 step:8150 [D loss: 0.769694, acc: 36.72%] [G loss: 1.528461]\n",
      "epoch:10 step:8151 [D loss: 0.687692, acc: 49.22%] [G loss: 1.558677]\n",
      "epoch:10 step:8152 [D loss: 0.794321, acc: 42.19%] [G loss: 1.447974]\n",
      "epoch:10 step:8153 [D loss: 0.740286, acc: 45.31%] [G loss: 1.542960]\n",
      "epoch:10 step:8154 [D loss: 0.760557, acc: 39.84%] [G loss: 1.462583]\n",
      "epoch:10 step:8155 [D loss: 0.587655, acc: 75.78%] [G loss: 1.571046]\n",
      "epoch:10 step:8156 [D loss: 0.768058, acc: 36.72%] [G loss: 1.508213]\n",
      "epoch:10 step:8157 [D loss: 0.574421, acc: 78.91%] [G loss: 1.703021]\n",
      "epoch:10 step:8158 [D loss: 0.594790, acc: 72.66%] [G loss: 1.763491]\n",
      "epoch:10 step:8159 [D loss: 0.675348, acc: 59.38%] [G loss: 1.467134]\n",
      "epoch:10 step:8160 [D loss: 0.830071, acc: 35.16%] [G loss: 1.648353]\n",
      "epoch:10 step:8161 [D loss: 0.770875, acc: 31.25%] [G loss: 1.494136]\n",
      "epoch:10 step:8162 [D loss: 0.674867, acc: 59.38%] [G loss: 1.662290]\n",
      "epoch:10 step:8163 [D loss: 0.754119, acc: 41.41%] [G loss: 1.511606]\n",
      "epoch:10 step:8164 [D loss: 0.577798, acc: 75.78%] [G loss: 1.441229]\n",
      "epoch:10 step:8165 [D loss: 0.700781, acc: 51.56%] [G loss: 1.517298]\n",
      "epoch:10 step:8166 [D loss: 0.655905, acc: 62.50%] [G loss: 1.441514]\n",
      "epoch:10 step:8167 [D loss: 0.724544, acc: 49.22%] [G loss: 1.527665]\n",
      "epoch:10 step:8168 [D loss: 0.587339, acc: 75.00%] [G loss: 1.540247]\n",
      "epoch:10 step:8169 [D loss: 0.813563, acc: 29.69%] [G loss: 1.448071]\n",
      "epoch:10 step:8170 [D loss: 0.674482, acc: 59.38%] [G loss: 1.483313]\n",
      "epoch:10 step:8171 [D loss: 0.785349, acc: 31.25%] [G loss: 1.398681]\n",
      "epoch:10 step:8172 [D loss: 0.665570, acc: 67.97%] [G loss: 1.808960]\n",
      "epoch:10 step:8173 [D loss: 0.722609, acc: 46.09%] [G loss: 1.659878]\n",
      "epoch:10 step:8174 [D loss: 0.562261, acc: 77.34%] [G loss: 1.612828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8175 [D loss: 0.729835, acc: 46.88%] [G loss: 1.596198]\n",
      "epoch:10 step:8176 [D loss: 0.766955, acc: 46.88%] [G loss: 1.741580]\n",
      "epoch:10 step:8177 [D loss: 0.648669, acc: 65.62%] [G loss: 1.659849]\n",
      "epoch:10 step:8178 [D loss: 0.700083, acc: 53.12%] [G loss: 1.405309]\n",
      "epoch:10 step:8179 [D loss: 0.645484, acc: 63.28%] [G loss: 1.558038]\n",
      "epoch:10 step:8180 [D loss: 0.731414, acc: 49.22%] [G loss: 1.517756]\n",
      "epoch:10 step:8181 [D loss: 0.622722, acc: 65.62%] [G loss: 1.662802]\n",
      "epoch:10 step:8182 [D loss: 0.551550, acc: 84.38%] [G loss: 1.443153]\n",
      "epoch:10 step:8183 [D loss: 0.993453, acc: 20.31%] [G loss: 1.217705]\n",
      "epoch:10 step:8184 [D loss: 0.633321, acc: 66.41%] [G loss: 1.861679]\n",
      "epoch:10 step:8185 [D loss: 0.845426, acc: 24.22%] [G loss: 1.438880]\n",
      "epoch:10 step:8186 [D loss: 0.609468, acc: 68.75%] [G loss: 1.608904]\n",
      "epoch:10 step:8187 [D loss: 0.728113, acc: 48.44%] [G loss: 1.554479]\n",
      "epoch:10 step:8188 [D loss: 0.784769, acc: 40.62%] [G loss: 1.657252]\n",
      "epoch:10 step:8189 [D loss: 0.532774, acc: 85.16%] [G loss: 1.776464]\n",
      "epoch:10 step:8190 [D loss: 0.712064, acc: 48.44%] [G loss: 1.628168]\n",
      "epoch:10 step:8191 [D loss: 0.618420, acc: 71.09%] [G loss: 1.636112]\n",
      "epoch:10 step:8192 [D loss: 0.585949, acc: 78.12%] [G loss: 1.764785]\n",
      "epoch:10 step:8193 [D loss: 0.611367, acc: 67.19%] [G loss: 1.548993]\n",
      "epoch:10 step:8194 [D loss: 0.704692, acc: 49.22%] [G loss: 1.681896]\n",
      "epoch:10 step:8195 [D loss: 0.692394, acc: 57.03%] [G loss: 1.498609]\n",
      "epoch:10 step:8196 [D loss: 0.655260, acc: 58.59%] [G loss: 1.694353]\n",
      "epoch:10 step:8197 [D loss: 0.782444, acc: 42.19%] [G loss: 1.421085]\n",
      "epoch:10 step:8198 [D loss: 0.618628, acc: 64.06%] [G loss: 1.374647]\n",
      "epoch:10 step:8199 [D loss: 0.611187, acc: 72.66%] [G loss: 1.671904]\n",
      "epoch:10 step:8200 [D loss: 0.700610, acc: 53.91%] [G loss: 1.629634]\n",
      "epoch:10 step:8201 [D loss: 0.853656, acc: 36.72%] [G loss: 1.373857]\n",
      "epoch:10 step:8202 [D loss: 0.607225, acc: 75.00%] [G loss: 1.710545]\n",
      "epoch:10 step:8203 [D loss: 0.818835, acc: 34.38%] [G loss: 1.364290]\n",
      "epoch:10 step:8204 [D loss: 0.580387, acc: 77.34%] [G loss: 1.460082]\n",
      "epoch:10 step:8205 [D loss: 0.598495, acc: 74.22%] [G loss: 1.584953]\n",
      "epoch:10 step:8206 [D loss: 0.646705, acc: 67.97%] [G loss: 1.726523]\n",
      "epoch:10 step:8207 [D loss: 0.487322, acc: 85.16%] [G loss: 1.687487]\n",
      "epoch:10 step:8208 [D loss: 0.602652, acc: 66.41%] [G loss: 1.578678]\n",
      "epoch:10 step:8209 [D loss: 0.690668, acc: 60.16%] [G loss: 1.475147]\n",
      "epoch:10 step:8210 [D loss: 0.601912, acc: 71.09%] [G loss: 1.826719]\n",
      "epoch:10 step:8211 [D loss: 0.551180, acc: 83.59%] [G loss: 1.550434]\n",
      "epoch:10 step:8212 [D loss: 0.580454, acc: 68.75%] [G loss: 1.722884]\n",
      "epoch:10 step:8213 [D loss: 0.604670, acc: 70.31%] [G loss: 1.450088]\n",
      "epoch:10 step:8214 [D loss: 0.756146, acc: 46.88%] [G loss: 1.542876]\n",
      "epoch:10 step:8215 [D loss: 0.452154, acc: 89.06%] [G loss: 1.894979]\n",
      "epoch:10 step:8216 [D loss: 0.700050, acc: 51.56%] [G loss: 1.910161]\n",
      "epoch:10 step:8217 [D loss: 0.831934, acc: 33.59%] [G loss: 1.542994]\n",
      "epoch:10 step:8218 [D loss: 0.682099, acc: 53.91%] [G loss: 1.655463]\n",
      "epoch:10 step:8219 [D loss: 0.508926, acc: 73.44%] [G loss: 1.855410]\n",
      "epoch:10 step:8220 [D loss: 0.671981, acc: 58.59%] [G loss: 1.784058]\n",
      "epoch:10 step:8221 [D loss: 0.513436, acc: 77.34%] [G loss: 1.772538]\n",
      "epoch:10 step:8222 [D loss: 0.729077, acc: 55.47%] [G loss: 1.711193]\n",
      "epoch:10 step:8223 [D loss: 0.527606, acc: 84.38%] [G loss: 1.986682]\n",
      "epoch:10 step:8224 [D loss: 0.801921, acc: 35.94%] [G loss: 1.464549]\n",
      "epoch:10 step:8225 [D loss: 0.611987, acc: 68.75%] [G loss: 1.902515]\n",
      "epoch:10 step:8226 [D loss: 0.722676, acc: 50.00%] [G loss: 1.793496]\n",
      "epoch:10 step:8227 [D loss: 0.739554, acc: 50.00%] [G loss: 1.865763]\n",
      "epoch:10 step:8228 [D loss: 0.482101, acc: 85.16%] [G loss: 1.490224]\n",
      "epoch:10 step:8229 [D loss: 0.650975, acc: 58.59%] [G loss: 1.492145]\n",
      "epoch:10 step:8230 [D loss: 1.012258, acc: 25.00%] [G loss: 1.378345]\n",
      "epoch:10 step:8231 [D loss: 0.587204, acc: 75.78%] [G loss: 1.693885]\n",
      "epoch:10 step:8232 [D loss: 0.294263, acc: 97.66%] [G loss: 1.707621]\n",
      "epoch:10 step:8233 [D loss: 0.746510, acc: 49.22%] [G loss: 1.490169]\n",
      "epoch:10 step:8234 [D loss: 0.889827, acc: 31.25%] [G loss: 1.309983]\n",
      "epoch:10 step:8235 [D loss: 0.809951, acc: 42.97%] [G loss: 1.463924]\n",
      "epoch:10 step:8236 [D loss: 0.707768, acc: 50.00%] [G loss: 1.739201]\n",
      "epoch:10 step:8237 [D loss: 0.638148, acc: 60.16%] [G loss: 1.575141]\n",
      "epoch:10 step:8238 [D loss: 0.756026, acc: 42.97%] [G loss: 1.637736]\n",
      "epoch:10 step:8239 [D loss: 0.721753, acc: 48.44%] [G loss: 1.723150]\n",
      "epoch:10 step:8240 [D loss: 1.040644, acc: 16.41%] [G loss: 1.226527]\n",
      "epoch:10 step:8241 [D loss: 0.714032, acc: 47.66%] [G loss: 1.363542]\n",
      "epoch:10 step:8242 [D loss: 0.784899, acc: 37.50%] [G loss: 1.518842]\n",
      "epoch:10 step:8243 [D loss: 0.518914, acc: 88.28%] [G loss: 1.617138]\n",
      "epoch:10 step:8244 [D loss: 0.829803, acc: 26.56%] [G loss: 1.427755]\n",
      "epoch:10 step:8245 [D loss: 0.618980, acc: 71.09%] [G loss: 1.616769]\n",
      "epoch:10 step:8246 [D loss: 0.513888, acc: 74.22%] [G loss: 1.575329]\n",
      "epoch:10 step:8247 [D loss: 0.844629, acc: 25.00%] [G loss: 1.393842]\n",
      "epoch:10 step:8248 [D loss: 0.681039, acc: 59.38%] [G loss: 1.780288]\n",
      "epoch:10 step:8249 [D loss: 0.478594, acc: 88.28%] [G loss: 1.550491]\n",
      "epoch:10 step:8250 [D loss: 0.755858, acc: 40.62%] [G loss: 1.500015]\n",
      "epoch:10 step:8251 [D loss: 0.710497, acc: 46.88%] [G loss: 1.621260]\n",
      "epoch:10 step:8252 [D loss: 0.584826, acc: 67.19%] [G loss: 1.520508]\n",
      "epoch:10 step:8253 [D loss: 0.525745, acc: 78.91%] [G loss: 1.720567]\n",
      "epoch:10 step:8254 [D loss: 0.653654, acc: 64.06%] [G loss: 2.023208]\n",
      "epoch:10 step:8255 [D loss: 0.755679, acc: 45.31%] [G loss: 1.623746]\n",
      "epoch:10 step:8256 [D loss: 0.763099, acc: 42.97%] [G loss: 1.439066]\n",
      "epoch:10 step:8257 [D loss: 0.790849, acc: 36.72%] [G loss: 1.526924]\n",
      "epoch:10 step:8258 [D loss: 0.623942, acc: 71.88%] [G loss: 1.527554]\n",
      "epoch:10 step:8259 [D loss: 0.593154, acc: 71.09%] [G loss: 1.679541]\n",
      "epoch:10 step:8260 [D loss: 0.689267, acc: 56.25%] [G loss: 1.575123]\n",
      "epoch:10 step:8261 [D loss: 0.544245, acc: 77.34%] [G loss: 1.768725]\n",
      "epoch:10 step:8262 [D loss: 0.682802, acc: 56.25%] [G loss: 1.661434]\n",
      "epoch:10 step:8263 [D loss: 0.646988, acc: 64.06%] [G loss: 1.602523]\n",
      "epoch:10 step:8264 [D loss: 0.671929, acc: 62.50%] [G loss: 1.552795]\n",
      "epoch:10 step:8265 [D loss: 0.572016, acc: 72.66%] [G loss: 1.700061]\n",
      "epoch:10 step:8266 [D loss: 0.590064, acc: 64.84%] [G loss: 1.651867]\n",
      "epoch:10 step:8267 [D loss: 0.704619, acc: 50.78%] [G loss: 1.699242]\n",
      "epoch:10 step:8268 [D loss: 0.562208, acc: 82.03%] [G loss: 1.620224]\n",
      "epoch:10 step:8269 [D loss: 0.653566, acc: 60.16%] [G loss: 1.571808]\n",
      "epoch:10 step:8270 [D loss: 0.665893, acc: 64.06%] [G loss: 1.630761]\n",
      "epoch:10 step:8271 [D loss: 0.534665, acc: 84.38%] [G loss: 1.553119]\n",
      "epoch:10 step:8272 [D loss: 0.440716, acc: 86.72%] [G loss: 1.691775]\n",
      "epoch:10 step:8273 [D loss: 0.497000, acc: 70.31%] [G loss: 1.623986]\n",
      "epoch:10 step:8274 [D loss: 0.627664, acc: 71.88%] [G loss: 1.556525]\n",
      "epoch:10 step:8275 [D loss: 0.779506, acc: 43.75%] [G loss: 1.796651]\n",
      "epoch:10 step:8276 [D loss: 0.520465, acc: 83.59%] [G loss: 1.637070]\n",
      "epoch:10 step:8277 [D loss: 0.643629, acc: 70.31%] [G loss: 1.568280]\n",
      "epoch:10 step:8278 [D loss: 0.530537, acc: 85.16%] [G loss: 1.841502]\n",
      "epoch:10 step:8279 [D loss: 0.487914, acc: 89.84%] [G loss: 1.646182]\n",
      "epoch:10 step:8280 [D loss: 0.554605, acc: 80.47%] [G loss: 1.594499]\n",
      "epoch:10 step:8281 [D loss: 0.679024, acc: 62.50%] [G loss: 1.582716]\n",
      "epoch:10 step:8282 [D loss: 1.023033, acc: 14.06%] [G loss: 1.359644]\n",
      "epoch:10 step:8283 [D loss: 0.929805, acc: 25.78%] [G loss: 1.588509]\n",
      "epoch:10 step:8284 [D loss: 0.805039, acc: 46.88%] [G loss: 1.659428]\n",
      "epoch:10 step:8285 [D loss: 0.635596, acc: 63.28%] [G loss: 1.621348]\n",
      "epoch:10 step:8286 [D loss: 0.568070, acc: 85.16%] [G loss: 1.649768]\n",
      "epoch:10 step:8287 [D loss: 0.469236, acc: 86.72%] [G loss: 1.644029]\n",
      "epoch:10 step:8288 [D loss: 0.622387, acc: 69.53%] [G loss: 1.701985]\n",
      "epoch:10 step:8289 [D loss: 0.737997, acc: 46.88%] [G loss: 1.522516]\n",
      "epoch:10 step:8290 [D loss: 0.726536, acc: 49.22%] [G loss: 2.045969]\n",
      "epoch:10 step:8291 [D loss: 0.622232, acc: 70.31%] [G loss: 1.494205]\n",
      "epoch:10 step:8292 [D loss: 0.869864, acc: 27.34%] [G loss: 1.537256]\n",
      "epoch:10 step:8293 [D loss: 0.584079, acc: 68.75%] [G loss: 1.837081]\n",
      "epoch:10 step:8294 [D loss: 0.648360, acc: 63.28%] [G loss: 1.550914]\n",
      "epoch:10 step:8295 [D loss: 0.739298, acc: 43.75%] [G loss: 1.610117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8296 [D loss: 0.803052, acc: 41.41%] [G loss: 1.677126]\n",
      "epoch:10 step:8297 [D loss: 0.768812, acc: 39.84%] [G loss: 1.590700]\n",
      "epoch:10 step:8298 [D loss: 0.708526, acc: 50.00%] [G loss: 1.459918]\n",
      "epoch:10 step:8299 [D loss: 0.561386, acc: 78.12%] [G loss: 1.613876]\n",
      "epoch:10 step:8300 [D loss: 0.541233, acc: 77.34%] [G loss: 1.655723]\n",
      "epoch:10 step:8301 [D loss: 0.565356, acc: 73.44%] [G loss: 1.876908]\n",
      "epoch:10 step:8302 [D loss: 0.792093, acc: 40.62%] [G loss: 1.471464]\n",
      "epoch:10 step:8303 [D loss: 0.567966, acc: 77.34%] [G loss: 1.521203]\n",
      "epoch:10 step:8304 [D loss: 0.725997, acc: 48.44%] [G loss: 1.298854]\n",
      "epoch:10 step:8305 [D loss: 0.541483, acc: 81.25%] [G loss: 1.746298]\n",
      "epoch:10 step:8306 [D loss: 0.588914, acc: 72.66%] [G loss: 1.610656]\n",
      "epoch:10 step:8307 [D loss: 0.550931, acc: 78.91%] [G loss: 1.781321]\n",
      "epoch:10 step:8308 [D loss: 0.748325, acc: 39.84%] [G loss: 1.718495]\n",
      "epoch:10 step:8309 [D loss: 0.784368, acc: 39.06%] [G loss: 1.382758]\n",
      "epoch:10 step:8310 [D loss: 0.912693, acc: 18.75%] [G loss: 1.335075]\n",
      "epoch:10 step:8311 [D loss: 0.615609, acc: 69.53%] [G loss: 1.420066]\n",
      "epoch:10 step:8312 [D loss: 0.679997, acc: 57.81%] [G loss: 1.511986]\n",
      "epoch:10 step:8313 [D loss: 0.660116, acc: 60.94%] [G loss: 1.517136]\n",
      "epoch:10 step:8314 [D loss: 0.696700, acc: 55.47%] [G loss: 1.674077]\n",
      "epoch:10 step:8315 [D loss: 0.719998, acc: 51.56%] [G loss: 1.270808]\n",
      "epoch:10 step:8316 [D loss: 0.551790, acc: 73.44%] [G loss: 1.709474]\n",
      "epoch:10 step:8317 [D loss: 0.701501, acc: 52.34%] [G loss: 1.685037]\n",
      "epoch:10 step:8318 [D loss: 0.776787, acc: 38.28%] [G loss: 1.454412]\n",
      "epoch:10 step:8319 [D loss: 0.757643, acc: 42.19%] [G loss: 1.570120]\n",
      "epoch:10 step:8320 [D loss: 0.533999, acc: 78.91%] [G loss: 1.746904]\n",
      "epoch:10 step:8321 [D loss: 0.689788, acc: 57.81%] [G loss: 1.636809]\n",
      "epoch:10 step:8322 [D loss: 0.909099, acc: 30.47%] [G loss: 1.437825]\n",
      "epoch:10 step:8323 [D loss: 0.838774, acc: 39.06%] [G loss: 1.666880]\n",
      "epoch:10 step:8324 [D loss: 0.710789, acc: 56.25%] [G loss: 1.705024]\n",
      "epoch:10 step:8325 [D loss: 0.677814, acc: 58.59%] [G loss: 2.184852]\n",
      "epoch:10 step:8326 [D loss: 0.544660, acc: 83.59%] [G loss: 1.852694]\n",
      "epoch:10 step:8327 [D loss: 0.729173, acc: 45.31%] [G loss: 1.666651]\n",
      "epoch:10 step:8328 [D loss: 0.723872, acc: 44.53%] [G loss: 1.517933]\n",
      "epoch:10 step:8329 [D loss: 0.966201, acc: 29.69%] [G loss: 1.160293]\n",
      "epoch:10 step:8330 [D loss: 0.556859, acc: 77.34%] [G loss: 1.559303]\n",
      "epoch:10 step:8331 [D loss: 0.608092, acc: 70.31%] [G loss: 1.776203]\n",
      "epoch:10 step:8332 [D loss: 0.755374, acc: 37.50%] [G loss: 1.538590]\n",
      "epoch:10 step:8333 [D loss: 0.677851, acc: 61.72%] [G loss: 1.434727]\n",
      "epoch:10 step:8334 [D loss: 0.811174, acc: 35.94%] [G loss: 1.667781]\n",
      "epoch:10 step:8335 [D loss: 0.736445, acc: 45.31%] [G loss: 1.498633]\n",
      "epoch:10 step:8336 [D loss: 0.900968, acc: 20.31%] [G loss: 1.548718]\n",
      "epoch:10 step:8337 [D loss: 0.777693, acc: 35.94%] [G loss: 1.498836]\n",
      "epoch:10 step:8338 [D loss: 0.641926, acc: 66.41%] [G loss: 1.577467]\n",
      "epoch:10 step:8339 [D loss: 0.559640, acc: 82.81%] [G loss: 1.582849]\n",
      "epoch:10 step:8340 [D loss: 0.953410, acc: 16.41%] [G loss: 1.441334]\n",
      "epoch:10 step:8341 [D loss: 0.668421, acc: 57.81%] [G loss: 1.629253]\n",
      "epoch:10 step:8342 [D loss: 0.712217, acc: 53.12%] [G loss: 1.496993]\n",
      "epoch:10 step:8343 [D loss: 0.660192, acc: 63.28%] [G loss: 1.531338]\n",
      "epoch:10 step:8344 [D loss: 0.619355, acc: 70.31%] [G loss: 1.614691]\n",
      "epoch:10 step:8345 [D loss: 0.763239, acc: 43.75%] [G loss: 1.614535]\n",
      "epoch:10 step:8346 [D loss: 0.639358, acc: 58.59%] [G loss: 1.483418]\n",
      "epoch:10 step:8347 [D loss: 0.742169, acc: 41.41%] [G loss: 1.527878]\n",
      "epoch:10 step:8348 [D loss: 0.605563, acc: 67.97%] [G loss: 1.552419]\n",
      "epoch:10 step:8349 [D loss: 0.628038, acc: 62.50%] [G loss: 1.583983]\n",
      "epoch:10 step:8350 [D loss: 0.651484, acc: 61.72%] [G loss: 1.678036]\n",
      "epoch:10 step:8351 [D loss: 0.643955, acc: 66.41%] [G loss: 1.564008]\n",
      "epoch:10 step:8352 [D loss: 0.498251, acc: 83.59%] [G loss: 1.653804]\n",
      "epoch:10 step:8353 [D loss: 0.479355, acc: 85.16%] [G loss: 1.870278]\n",
      "epoch:10 step:8354 [D loss: 0.772504, acc: 47.66%] [G loss: 1.558126]\n",
      "epoch:10 step:8355 [D loss: 0.499686, acc: 90.62%] [G loss: 2.046080]\n",
      "epoch:10 step:8356 [D loss: 0.607069, acc: 58.59%] [G loss: 1.711239]\n",
      "epoch:10 step:8357 [D loss: 0.595192, acc: 68.75%] [G loss: 2.137267]\n",
      "epoch:10 step:8358 [D loss: 0.651770, acc: 63.28%] [G loss: 1.546404]\n",
      "epoch:10 step:8359 [D loss: 0.668102, acc: 60.16%] [G loss: 1.632550]\n",
      "epoch:10 step:8360 [D loss: 0.702086, acc: 47.66%] [G loss: 1.857605]\n",
      "epoch:10 step:8361 [D loss: 0.550122, acc: 81.25%] [G loss: 1.882411]\n",
      "epoch:10 step:8362 [D loss: 0.701454, acc: 53.12%] [G loss: 1.382126]\n",
      "epoch:10 step:8363 [D loss: 0.778845, acc: 42.19%] [G loss: 1.341778]\n",
      "epoch:10 step:8364 [D loss: 0.655909, acc: 63.28%] [G loss: 1.758718]\n",
      "epoch:10 step:8365 [D loss: 0.745332, acc: 41.41%] [G loss: 1.510121]\n",
      "epoch:10 step:8366 [D loss: 0.700509, acc: 59.38%] [G loss: 1.639105]\n",
      "epoch:10 step:8367 [D loss: 0.520894, acc: 82.03%] [G loss: 1.971186]\n",
      "epoch:10 step:8368 [D loss: 0.546621, acc: 65.62%] [G loss: 1.776013]\n",
      "epoch:10 step:8369 [D loss: 0.437529, acc: 92.97%] [G loss: 1.779041]\n",
      "epoch:10 step:8370 [D loss: 0.826862, acc: 32.81%] [G loss: 1.877600]\n",
      "epoch:10 step:8371 [D loss: 0.589331, acc: 71.09%] [G loss: 2.110728]\n",
      "epoch:10 step:8372 [D loss: 0.508723, acc: 79.69%] [G loss: 1.845851]\n",
      "epoch:10 step:8373 [D loss: 0.686476, acc: 60.16%] [G loss: 1.510521]\n",
      "epoch:10 step:8374 [D loss: 0.798481, acc: 49.22%] [G loss: 1.616775]\n",
      "epoch:10 step:8375 [D loss: 0.827126, acc: 32.03%] [G loss: 1.537006]\n",
      "epoch:10 step:8376 [D loss: 0.809266, acc: 39.06%] [G loss: 1.449372]\n",
      "epoch:10 step:8377 [D loss: 0.669010, acc: 57.03%] [G loss: 1.520476]\n",
      "epoch:10 step:8378 [D loss: 0.605103, acc: 68.75%] [G loss: 1.774079]\n",
      "epoch:10 step:8379 [D loss: 0.610952, acc: 67.19%] [G loss: 1.810246]\n",
      "epoch:10 step:8380 [D loss: 0.637737, acc: 61.72%] [G loss: 1.622237]\n",
      "epoch:10 step:8381 [D loss: 0.581541, acc: 57.03%] [G loss: 1.425377]\n",
      "epoch:10 step:8382 [D loss: 0.567869, acc: 83.59%] [G loss: 1.763060]\n",
      "epoch:10 step:8383 [D loss: 0.560573, acc: 75.78%] [G loss: 1.636298]\n",
      "epoch:10 step:8384 [D loss: 0.690728, acc: 57.03%] [G loss: 1.541255]\n",
      "epoch:10 step:8385 [D loss: 0.692285, acc: 57.81%] [G loss: 1.552581]\n",
      "epoch:10 step:8386 [D loss: 0.718391, acc: 53.12%] [G loss: 1.674350]\n",
      "epoch:10 step:8387 [D loss: 0.638690, acc: 60.94%] [G loss: 1.430700]\n",
      "epoch:10 step:8388 [D loss: 0.631322, acc: 67.97%] [G loss: 1.859046]\n",
      "epoch:10 step:8389 [D loss: 0.648780, acc: 56.25%] [G loss: 1.791346]\n",
      "epoch:10 step:8390 [D loss: 0.717787, acc: 51.56%] [G loss: 1.740832]\n",
      "epoch:10 step:8391 [D loss: 0.692102, acc: 57.03%] [G loss: 1.931183]\n",
      "epoch:10 step:8392 [D loss: 0.857748, acc: 28.91%] [G loss: 1.383486]\n",
      "epoch:10 step:8393 [D loss: 0.743878, acc: 46.09%] [G loss: 1.453883]\n",
      "epoch:10 step:8394 [D loss: 0.861037, acc: 28.91%] [G loss: 1.602588]\n",
      "epoch:10 step:8395 [D loss: 0.714644, acc: 54.69%] [G loss: 1.604697]\n",
      "epoch:10 step:8396 [D loss: 0.678582, acc: 54.69%] [G loss: 1.846364]\n",
      "epoch:10 step:8397 [D loss: 0.639990, acc: 64.06%] [G loss: 1.932398]\n",
      "epoch:10 step:8398 [D loss: 0.647741, acc: 60.16%] [G loss: 1.959624]\n",
      "epoch:10 step:8399 [D loss: 0.694480, acc: 52.34%] [G loss: 1.592252]\n",
      "epoch:10 step:8400 [D loss: 0.649297, acc: 64.06%] [G loss: 1.698257]\n",
      "epoch:10 step:8401 [D loss: 0.767664, acc: 39.84%] [G loss: 1.566875]\n",
      "epoch:10 step:8402 [D loss: 0.656504, acc: 60.16%] [G loss: 1.975415]\n",
      "epoch:10 step:8403 [D loss: 0.662217, acc: 57.03%] [G loss: 1.611565]\n",
      "epoch:10 step:8404 [D loss: 0.647124, acc: 54.69%] [G loss: 1.780255]\n",
      "epoch:10 step:8405 [D loss: 0.730797, acc: 46.09%] [G loss: 1.661362]\n",
      "epoch:10 step:8406 [D loss: 0.740248, acc: 45.31%] [G loss: 1.600272]\n",
      "epoch:10 step:8407 [D loss: 0.695290, acc: 46.88%] [G loss: 1.573522]\n",
      "epoch:10 step:8408 [D loss: 0.620835, acc: 72.66%] [G loss: 1.678245]\n",
      "epoch:10 step:8409 [D loss: 0.694549, acc: 54.69%] [G loss: 1.469338]\n",
      "epoch:10 step:8410 [D loss: 0.660242, acc: 60.16%] [G loss: 1.860356]\n",
      "epoch:10 step:8411 [D loss: 0.609125, acc: 64.84%] [G loss: 1.831596]\n",
      "epoch:10 step:8412 [D loss: 0.672373, acc: 53.12%] [G loss: 1.641287]\n",
      "epoch:10 step:8413 [D loss: 0.642047, acc: 64.84%] [G loss: 1.554566]\n",
      "epoch:10 step:8414 [D loss: 0.746312, acc: 43.75%] [G loss: 1.720466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8415 [D loss: 0.585454, acc: 73.44%] [G loss: 1.474814]\n",
      "epoch:10 step:8416 [D loss: 0.727302, acc: 47.66%] [G loss: 1.888496]\n",
      "epoch:10 step:8417 [D loss: 0.567447, acc: 78.12%] [G loss: 1.797340]\n",
      "epoch:10 step:8418 [D loss: 0.619794, acc: 67.19%] [G loss: 1.525559]\n",
      "epoch:10 step:8419 [D loss: 0.792316, acc: 32.03%] [G loss: 1.493449]\n",
      "epoch:10 step:8420 [D loss: 0.638675, acc: 64.84%] [G loss: 1.534035]\n",
      "epoch:10 step:8421 [D loss: 0.629308, acc: 67.19%] [G loss: 1.559313]\n",
      "epoch:10 step:8422 [D loss: 0.593888, acc: 76.56%] [G loss: 1.522539]\n",
      "epoch:10 step:8423 [D loss: 0.886270, acc: 24.22%] [G loss: 1.568820]\n",
      "epoch:10 step:8424 [D loss: 0.838743, acc: 35.94%] [G loss: 1.297860]\n",
      "epoch:10 step:8425 [D loss: 0.621720, acc: 66.41%] [G loss: 1.500961]\n",
      "epoch:10 step:8426 [D loss: 1.213938, acc: 5.47%] [G loss: 1.447227]\n",
      "epoch:10 step:8427 [D loss: 0.795328, acc: 41.41%] [G loss: 1.749397]\n",
      "epoch:10 step:8428 [D loss: 0.757747, acc: 46.09%] [G loss: 1.500763]\n",
      "epoch:10 step:8429 [D loss: 0.729363, acc: 49.22%] [G loss: 1.544728]\n",
      "epoch:10 step:8430 [D loss: 0.628498, acc: 68.75%] [G loss: 1.794053]\n",
      "epoch:10 step:8431 [D loss: 0.721297, acc: 46.09%] [G loss: 1.598178]\n",
      "epoch:10 step:8432 [D loss: 0.590836, acc: 71.88%] [G loss: 1.967736]\n",
      "epoch:10 step:8433 [D loss: 0.661527, acc: 64.84%] [G loss: 1.695094]\n",
      "epoch:10 step:8434 [D loss: 0.599880, acc: 71.88%] [G loss: 1.434291]\n",
      "epoch:10 step:8435 [D loss: 0.670089, acc: 59.38%] [G loss: 1.699859]\n",
      "epoch:10 step:8436 [D loss: 0.681077, acc: 55.47%] [G loss: 1.902119]\n",
      "epoch:10 step:8437 [D loss: 0.784603, acc: 38.28%] [G loss: 1.498341]\n",
      "epoch:10 step:8438 [D loss: 0.649729, acc: 58.59%] [G loss: 1.849449]\n",
      "epoch:10 step:8439 [D loss: 0.717680, acc: 50.78%] [G loss: 1.467205]\n",
      "epoch:10 step:8440 [D loss: 0.736043, acc: 44.53%] [G loss: 1.585859]\n",
      "epoch:10 step:8441 [D loss: 0.589014, acc: 68.75%] [G loss: 1.615743]\n",
      "epoch:10 step:8442 [D loss: 1.004739, acc: 25.78%] [G loss: 1.280491]\n",
      "epoch:10 step:8443 [D loss: 0.807996, acc: 34.38%] [G loss: 1.757301]\n",
      "epoch:10 step:8444 [D loss: 0.671135, acc: 63.28%] [G loss: 1.507418]\n",
      "epoch:10 step:8445 [D loss: 0.527452, acc: 82.81%] [G loss: 1.569789]\n",
      "epoch:10 step:8446 [D loss: 0.640960, acc: 65.62%] [G loss: 1.732564]\n",
      "epoch:10 step:8447 [D loss: 1.014498, acc: 9.38%] [G loss: 1.361636]\n",
      "epoch:10 step:8448 [D loss: 0.850937, acc: 25.78%] [G loss: 1.503080]\n",
      "epoch:10 step:8449 [D loss: 0.844020, acc: 25.00%] [G loss: 1.351880]\n",
      "epoch:10 step:8450 [D loss: 0.705568, acc: 56.25%] [G loss: 1.495229]\n",
      "epoch:10 step:8451 [D loss: 0.576473, acc: 75.00%] [G loss: 1.570562]\n",
      "epoch:10 step:8452 [D loss: 0.669819, acc: 60.94%] [G loss: 1.573506]\n",
      "epoch:10 step:8453 [D loss: 0.698952, acc: 54.69%] [G loss: 1.766936]\n",
      "epoch:10 step:8454 [D loss: 0.635899, acc: 72.66%] [G loss: 1.776097]\n",
      "epoch:10 step:8455 [D loss: 0.725148, acc: 50.78%] [G loss: 1.581170]\n",
      "epoch:10 step:8456 [D loss: 0.720087, acc: 51.56%] [G loss: 1.546676]\n",
      "epoch:10 step:8457 [D loss: 0.605985, acc: 67.19%] [G loss: 1.682708]\n",
      "epoch:10 step:8458 [D loss: 0.680330, acc: 57.81%] [G loss: 1.644373]\n",
      "epoch:10 step:8459 [D loss: 0.854530, acc: 23.44%] [G loss: 1.292136]\n",
      "epoch:10 step:8460 [D loss: 0.752572, acc: 42.97%] [G loss: 1.637568]\n",
      "epoch:10 step:8461 [D loss: 0.507810, acc: 88.28%] [G loss: 1.935088]\n",
      "epoch:10 step:8462 [D loss: 0.716589, acc: 51.56%] [G loss: 1.641889]\n",
      "epoch:10 step:8463 [D loss: 0.648090, acc: 60.94%] [G loss: 1.835997]\n",
      "epoch:10 step:8464 [D loss: 0.766828, acc: 39.06%] [G loss: 1.891302]\n",
      "epoch:10 step:8465 [D loss: 0.493084, acc: 92.97%] [G loss: 1.911940]\n",
      "epoch:10 step:8466 [D loss: 0.873863, acc: 38.28%] [G loss: 1.588195]\n",
      "epoch:10 step:8467 [D loss: 0.567405, acc: 75.78%] [G loss: 1.796315]\n",
      "epoch:10 step:8468 [D loss: 0.670899, acc: 60.94%] [G loss: 1.633799]\n",
      "epoch:10 step:8469 [D loss: 0.607642, acc: 72.66%] [G loss: 1.639035]\n",
      "epoch:10 step:8470 [D loss: 0.833355, acc: 28.12%] [G loss: 1.418946]\n",
      "epoch:10 step:8471 [D loss: 0.744583, acc: 50.00%] [G loss: 1.507937]\n",
      "epoch:10 step:8472 [D loss: 0.647428, acc: 64.84%] [G loss: 1.733159]\n",
      "epoch:10 step:8473 [D loss: 0.581038, acc: 71.88%] [G loss: 1.504491]\n",
      "epoch:10 step:8474 [D loss: 0.728633, acc: 49.22%] [G loss: 1.631556]\n",
      "epoch:10 step:8475 [D loss: 0.759284, acc: 39.84%] [G loss: 1.548527]\n",
      "epoch:10 step:8476 [D loss: 0.488266, acc: 74.22%] [G loss: 1.532248]\n",
      "epoch:10 step:8477 [D loss: 0.866053, acc: 21.88%] [G loss: 1.553760]\n",
      "epoch:10 step:8478 [D loss: 0.642878, acc: 64.06%] [G loss: 1.473469]\n",
      "epoch:10 step:8479 [D loss: 0.701851, acc: 53.12%] [G loss: 1.279908]\n",
      "epoch:10 step:8480 [D loss: 0.792875, acc: 36.72%] [G loss: 1.289584]\n",
      "epoch:10 step:8481 [D loss: 0.518407, acc: 83.59%] [G loss: 1.711588]\n",
      "epoch:10 step:8482 [D loss: 0.792906, acc: 39.06%] [G loss: 1.275428]\n",
      "epoch:10 step:8483 [D loss: 0.820356, acc: 33.59%] [G loss: 1.451558]\n",
      "epoch:10 step:8484 [D loss: 0.610023, acc: 74.22%] [G loss: 1.745283]\n",
      "epoch:10 step:8485 [D loss: 0.688909, acc: 53.91%] [G loss: 1.530031]\n",
      "epoch:10 step:8486 [D loss: 0.561828, acc: 78.91%] [G loss: 1.553401]\n",
      "epoch:10 step:8487 [D loss: 0.507371, acc: 84.38%] [G loss: 1.685227]\n",
      "epoch:10 step:8488 [D loss: 0.604881, acc: 72.66%] [G loss: 1.497915]\n",
      "epoch:10 step:8489 [D loss: 0.540489, acc: 62.50%] [G loss: 1.387919]\n",
      "epoch:10 step:8490 [D loss: 0.725605, acc: 55.47%] [G loss: 1.427925]\n",
      "epoch:10 step:8491 [D loss: 0.635849, acc: 67.19%] [G loss: 1.760671]\n",
      "epoch:10 step:8492 [D loss: 1.055104, acc: 26.56%] [G loss: 1.245326]\n",
      "epoch:10 step:8493 [D loss: 0.668593, acc: 58.59%] [G loss: 1.340563]\n",
      "epoch:10 step:8494 [D loss: 0.494665, acc: 89.84%] [G loss: 1.635214]\n",
      "epoch:10 step:8495 [D loss: 0.538751, acc: 88.28%] [G loss: 1.542874]\n",
      "epoch:10 step:8496 [D loss: 0.668928, acc: 54.69%] [G loss: 1.420051]\n",
      "epoch:10 step:8497 [D loss: 0.660621, acc: 56.25%] [G loss: 1.415571]\n",
      "epoch:10 step:8498 [D loss: 0.697149, acc: 58.59%] [G loss: 1.614785]\n",
      "epoch:10 step:8499 [D loss: 0.437660, acc: 90.62%] [G loss: 1.784452]\n",
      "epoch:10 step:8500 [D loss: 0.728326, acc: 50.78%] [G loss: 1.325467]\n",
      "epoch:10 step:8501 [D loss: 0.624753, acc: 64.84%] [G loss: 1.565601]\n",
      "epoch:10 step:8502 [D loss: 1.093021, acc: 7.81%] [G loss: 1.292619]\n",
      "epoch:10 step:8503 [D loss: 0.670983, acc: 57.81%] [G loss: 1.669463]\n",
      "epoch:10 step:8504 [D loss: 0.525771, acc: 80.47%] [G loss: 1.667453]\n",
      "epoch:10 step:8505 [D loss: 0.510340, acc: 81.25%] [G loss: 1.489369]\n",
      "epoch:10 step:8506 [D loss: 0.601271, acc: 68.75%] [G loss: 1.592965]\n",
      "epoch:10 step:8507 [D loss: 0.709315, acc: 59.38%] [G loss: 1.734590]\n",
      "epoch:10 step:8508 [D loss: 0.558881, acc: 79.69%] [G loss: 1.645642]\n",
      "epoch:10 step:8509 [D loss: 0.623732, acc: 63.28%] [G loss: 1.701917]\n",
      "epoch:10 step:8510 [D loss: 0.782211, acc: 38.28%] [G loss: 1.378628]\n",
      "epoch:10 step:8511 [D loss: 0.635295, acc: 69.53%] [G loss: 1.682289]\n",
      "epoch:10 step:8512 [D loss: 0.941532, acc: 32.03%] [G loss: 1.241498]\n",
      "epoch:10 step:8513 [D loss: 0.939941, acc: 18.75%] [G loss: 1.438083]\n",
      "epoch:10 step:8514 [D loss: 1.082954, acc: 9.38%] [G loss: 1.242830]\n",
      "epoch:10 step:8515 [D loss: 0.586149, acc: 71.88%] [G loss: 1.786784]\n",
      "epoch:10 step:8516 [D loss: 0.703148, acc: 48.44%] [G loss: 1.603409]\n",
      "epoch:10 step:8517 [D loss: 0.727272, acc: 47.66%] [G loss: 1.484472]\n",
      "epoch:10 step:8518 [D loss: 0.651190, acc: 59.38%] [G loss: 1.526870]\n",
      "epoch:10 step:8519 [D loss: 0.697667, acc: 53.91%] [G loss: 1.663548]\n",
      "epoch:10 step:8520 [D loss: 0.706013, acc: 60.16%] [G loss: 1.677054]\n",
      "epoch:10 step:8521 [D loss: 0.691067, acc: 60.94%] [G loss: 1.540172]\n",
      "epoch:10 step:8522 [D loss: 0.702291, acc: 53.91%] [G loss: 1.704206]\n",
      "epoch:10 step:8523 [D loss: 0.669206, acc: 58.59%] [G loss: 1.707984]\n",
      "epoch:10 step:8524 [D loss: 0.510760, acc: 84.38%] [G loss: 1.555732]\n",
      "epoch:10 step:8525 [D loss: 0.741538, acc: 45.31%] [G loss: 1.566741]\n",
      "epoch:10 step:8526 [D loss: 0.567732, acc: 75.78%] [G loss: 1.943942]\n",
      "epoch:10 step:8527 [D loss: 0.668706, acc: 61.72%] [G loss: 1.691324]\n",
      "epoch:10 step:8528 [D loss: 0.623015, acc: 64.06%] [G loss: 1.816967]\n",
      "epoch:10 step:8529 [D loss: 0.578214, acc: 80.47%] [G loss: 1.673999]\n",
      "epoch:10 step:8530 [D loss: 0.669394, acc: 57.81%] [G loss: 1.608583]\n",
      "epoch:10 step:8531 [D loss: 0.732627, acc: 46.09%] [G loss: 1.486630]\n",
      "epoch:10 step:8532 [D loss: 0.487707, acc: 80.47%] [G loss: 1.906892]\n",
      "epoch:10 step:8533 [D loss: 0.633112, acc: 68.75%] [G loss: 1.541566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8534 [D loss: 0.647495, acc: 64.06%] [G loss: 1.478230]\n",
      "epoch:10 step:8535 [D loss: 0.662955, acc: 60.94%] [G loss: 1.675830]\n",
      "epoch:10 step:8536 [D loss: 0.794231, acc: 38.28%] [G loss: 1.329903]\n",
      "epoch:10 step:8537 [D loss: 0.576098, acc: 78.91%] [G loss: 1.743326]\n",
      "epoch:10 step:8538 [D loss: 0.583096, acc: 64.06%] [G loss: 1.653494]\n",
      "epoch:10 step:8539 [D loss: 0.580238, acc: 71.88%] [G loss: 1.391569]\n",
      "epoch:10 step:8540 [D loss: 0.717017, acc: 52.34%] [G loss: 1.617174]\n",
      "epoch:10 step:8541 [D loss: 0.708792, acc: 48.44%] [G loss: 1.452940]\n",
      "epoch:10 step:8542 [D loss: 0.774076, acc: 44.53%] [G loss: 1.538114]\n",
      "epoch:10 step:8543 [D loss: 0.683602, acc: 57.81%] [G loss: 1.538426]\n",
      "epoch:10 step:8544 [D loss: 0.743106, acc: 42.97%] [G loss: 1.482234]\n",
      "epoch:10 step:8545 [D loss: 0.719693, acc: 46.09%] [G loss: 1.448862]\n",
      "epoch:10 step:8546 [D loss: 0.794192, acc: 39.06%] [G loss: 1.386560]\n",
      "epoch:10 step:8547 [D loss: 0.670990, acc: 60.16%] [G loss: 1.701205]\n",
      "epoch:10 step:8548 [D loss: 0.601694, acc: 74.22%] [G loss: 1.606925]\n",
      "epoch:10 step:8549 [D loss: 0.711040, acc: 54.69%] [G loss: 1.583042]\n",
      "epoch:10 step:8550 [D loss: 0.723546, acc: 54.69%] [G loss: 1.314047]\n",
      "epoch:10 step:8551 [D loss: 0.581918, acc: 74.22%] [G loss: 1.611568]\n",
      "epoch:10 step:8552 [D loss: 0.712283, acc: 56.25%] [G loss: 1.529196]\n",
      "epoch:10 step:8553 [D loss: 0.614491, acc: 71.09%] [G loss: 1.730577]\n",
      "epoch:10 step:8554 [D loss: 0.563931, acc: 63.28%] [G loss: 1.429079]\n",
      "epoch:10 step:8555 [D loss: 0.613712, acc: 67.97%] [G loss: 1.604916]\n",
      "epoch:10 step:8556 [D loss: 0.536788, acc: 84.38%] [G loss: 1.879667]\n",
      "epoch:10 step:8557 [D loss: 0.618060, acc: 64.84%] [G loss: 1.723844]\n",
      "epoch:10 step:8558 [D loss: 0.526449, acc: 85.16%] [G loss: 1.875091]\n",
      "epoch:10 step:8559 [D loss: 0.855014, acc: 29.69%] [G loss: 1.531828]\n",
      "epoch:10 step:8560 [D loss: 0.971750, acc: 11.72%] [G loss: 1.472280]\n",
      "epoch:10 step:8561 [D loss: 0.904762, acc: 16.41%] [G loss: 1.285702]\n",
      "epoch:10 step:8562 [D loss: 0.770317, acc: 44.53%] [G loss: 1.524894]\n",
      "epoch:10 step:8563 [D loss: 0.634075, acc: 63.28%] [G loss: 1.514691]\n",
      "epoch:10 step:8564 [D loss: 0.631310, acc: 60.16%] [G loss: 1.746575]\n",
      "epoch:10 step:8565 [D loss: 0.577257, acc: 67.19%] [G loss: 1.702050]\n",
      "epoch:10 step:8566 [D loss: 0.739318, acc: 50.00%] [G loss: 1.238432]\n",
      "epoch:10 step:8567 [D loss: 0.660151, acc: 57.81%] [G loss: 1.531829]\n",
      "epoch:10 step:8568 [D loss: 0.621271, acc: 70.31%] [G loss: 1.589767]\n",
      "epoch:10 step:8569 [D loss: 0.679239, acc: 56.25%] [G loss: 1.710671]\n",
      "epoch:10 step:8570 [D loss: 0.826922, acc: 27.34%] [G loss: 1.419138]\n",
      "epoch:10 step:8571 [D loss: 0.840153, acc: 34.38%] [G loss: 1.470214]\n",
      "epoch:10 step:8572 [D loss: 0.691771, acc: 49.22%] [G loss: 1.526867]\n",
      "epoch:10 step:8573 [D loss: 0.717782, acc: 51.56%] [G loss: 1.433078]\n",
      "epoch:10 step:8574 [D loss: 0.857804, acc: 23.44%] [G loss: 1.253213]\n",
      "epoch:10 step:8575 [D loss: 0.632452, acc: 67.97%] [G loss: 1.606073]\n",
      "epoch:10 step:8576 [D loss: 0.691562, acc: 53.12%] [G loss: 1.558180]\n",
      "epoch:10 step:8577 [D loss: 0.669903, acc: 58.59%] [G loss: 1.594440]\n",
      "epoch:10 step:8578 [D loss: 0.672926, acc: 60.16%] [G loss: 1.673949]\n",
      "epoch:10 step:8579 [D loss: 0.762533, acc: 41.41%] [G loss: 1.482291]\n",
      "epoch:10 step:8580 [D loss: 0.672274, acc: 57.81%] [G loss: 1.442678]\n",
      "epoch:10 step:8581 [D loss: 0.874137, acc: 29.69%] [G loss: 1.547140]\n",
      "epoch:10 step:8582 [D loss: 0.542301, acc: 82.03%] [G loss: 1.619055]\n",
      "epoch:10 step:8583 [D loss: 0.648420, acc: 64.06%] [G loss: 1.562722]\n",
      "epoch:10 step:8584 [D loss: 0.673463, acc: 57.03%] [G loss: 1.579469]\n",
      "epoch:10 step:8585 [D loss: 0.749710, acc: 42.19%] [G loss: 1.538462]\n",
      "epoch:10 step:8586 [D loss: 0.609300, acc: 74.22%] [G loss: 1.554988]\n",
      "epoch:10 step:8587 [D loss: 0.837087, acc: 27.34%] [G loss: 1.477329]\n",
      "epoch:10 step:8588 [D loss: 0.796749, acc: 35.16%] [G loss: 1.570735]\n",
      "epoch:10 step:8589 [D loss: 0.845758, acc: 24.22%] [G loss: 1.493801]\n",
      "epoch:10 step:8590 [D loss: 0.823901, acc: 20.31%] [G loss: 1.356288]\n",
      "epoch:10 step:8591 [D loss: 0.760071, acc: 45.31%] [G loss: 1.447946]\n",
      "epoch:11 step:8592 [D loss: 0.674987, acc: 53.91%] [G loss: 1.703890]\n",
      "epoch:11 step:8593 [D loss: 0.681009, acc: 49.22%] [G loss: 1.537781]\n",
      "epoch:11 step:8594 [D loss: 0.643556, acc: 67.19%] [G loss: 1.557963]\n",
      "epoch:11 step:8595 [D loss: 0.693182, acc: 51.56%] [G loss: 1.543778]\n",
      "epoch:11 step:8596 [D loss: 0.757852, acc: 43.75%] [G loss: 1.590963]\n",
      "epoch:11 step:8597 [D loss: 0.659848, acc: 59.38%] [G loss: 1.647258]\n",
      "epoch:11 step:8598 [D loss: 0.648772, acc: 68.75%] [G loss: 1.600063]\n",
      "epoch:11 step:8599 [D loss: 0.653086, acc: 57.03%] [G loss: 1.638554]\n",
      "epoch:11 step:8600 [D loss: 0.747908, acc: 40.62%] [G loss: 1.519798]\n",
      "epoch:11 step:8601 [D loss: 0.592449, acc: 76.56%] [G loss: 1.656470]\n",
      "epoch:11 step:8602 [D loss: 0.564458, acc: 82.03%] [G loss: 1.829434]\n",
      "epoch:11 step:8603 [D loss: 0.719327, acc: 48.44%] [G loss: 1.478707]\n",
      "epoch:11 step:8604 [D loss: 0.756125, acc: 43.75%] [G loss: 1.513551]\n",
      "epoch:11 step:8605 [D loss: 0.526109, acc: 88.28%] [G loss: 1.848117]\n",
      "epoch:11 step:8606 [D loss: 0.657275, acc: 64.06%] [G loss: 1.598692]\n",
      "epoch:11 step:8607 [D loss: 0.494873, acc: 67.19%] [G loss: 1.608292]\n",
      "epoch:11 step:8608 [D loss: 0.664502, acc: 57.81%] [G loss: 1.740256]\n",
      "epoch:11 step:8609 [D loss: 0.647522, acc: 60.94%] [G loss: 1.597465]\n",
      "epoch:11 step:8610 [D loss: 0.746447, acc: 47.66%] [G loss: 1.431062]\n",
      "epoch:11 step:8611 [D loss: 0.591830, acc: 72.66%] [G loss: 1.861972]\n",
      "epoch:11 step:8612 [D loss: 0.605646, acc: 75.00%] [G loss: 1.621648]\n",
      "epoch:11 step:8613 [D loss: 0.581989, acc: 82.03%] [G loss: 1.685812]\n",
      "epoch:11 step:8614 [D loss: 0.563935, acc: 65.62%] [G loss: 1.824336]\n",
      "epoch:11 step:8615 [D loss: 0.667263, acc: 60.16%] [G loss: 1.666458]\n",
      "epoch:11 step:8616 [D loss: 0.693922, acc: 53.12%] [G loss: 1.621921]\n",
      "epoch:11 step:8617 [D loss: 0.724867, acc: 42.19%] [G loss: 1.671769]\n",
      "epoch:11 step:8618 [D loss: 0.649703, acc: 61.72%] [G loss: 1.540094]\n",
      "epoch:11 step:8619 [D loss: 0.560454, acc: 80.47%] [G loss: 1.633758]\n",
      "epoch:11 step:8620 [D loss: 0.767210, acc: 35.94%] [G loss: 1.491234]\n",
      "epoch:11 step:8621 [D loss: 0.742641, acc: 48.44%] [G loss: 1.519056]\n",
      "epoch:11 step:8622 [D loss: 0.783830, acc: 39.84%] [G loss: 1.515546]\n",
      "epoch:11 step:8623 [D loss: 0.755047, acc: 39.84%] [G loss: 1.436566]\n",
      "epoch:11 step:8624 [D loss: 0.586017, acc: 74.22%] [G loss: 1.682539]\n",
      "epoch:11 step:8625 [D loss: 0.699481, acc: 51.56%] [G loss: 1.603694]\n",
      "epoch:11 step:8626 [D loss: 0.804262, acc: 36.72%] [G loss: 1.646060]\n",
      "epoch:11 step:8627 [D loss: 0.718700, acc: 45.31%] [G loss: 1.607080]\n",
      "epoch:11 step:8628 [D loss: 0.692175, acc: 54.69%] [G loss: 1.717317]\n",
      "epoch:11 step:8629 [D loss: 0.536874, acc: 78.12%] [G loss: 1.797516]\n",
      "epoch:11 step:8630 [D loss: 0.671732, acc: 58.59%] [G loss: 1.661241]\n",
      "epoch:11 step:8631 [D loss: 0.610957, acc: 68.75%] [G loss: 1.564351]\n",
      "epoch:11 step:8632 [D loss: 0.561783, acc: 81.25%] [G loss: 1.691401]\n",
      "epoch:11 step:8633 [D loss: 0.600452, acc: 67.97%] [G loss: 1.564994]\n",
      "epoch:11 step:8634 [D loss: 0.906464, acc: 25.78%] [G loss: 1.386961]\n",
      "epoch:11 step:8635 [D loss: 0.793982, acc: 35.16%] [G loss: 1.318854]\n",
      "epoch:11 step:8636 [D loss: 0.661408, acc: 60.94%] [G loss: 1.750643]\n",
      "epoch:11 step:8637 [D loss: 0.559539, acc: 77.34%] [G loss: 1.686938]\n",
      "epoch:11 step:8638 [D loss: 0.825581, acc: 32.81%] [G loss: 1.362096]\n",
      "epoch:11 step:8639 [D loss: 0.577274, acc: 75.78%] [G loss: 1.519028]\n",
      "epoch:11 step:8640 [D loss: 0.751999, acc: 47.66%] [G loss: 1.648024]\n",
      "epoch:11 step:8641 [D loss: 0.676928, acc: 57.81%] [G loss: 1.640810]\n",
      "epoch:11 step:8642 [D loss: 0.686650, acc: 57.81%] [G loss: 1.754876]\n",
      "epoch:11 step:8643 [D loss: 0.726579, acc: 48.44%] [G loss: 1.738540]\n",
      "epoch:11 step:8644 [D loss: 0.577786, acc: 74.22%] [G loss: 1.785957]\n",
      "epoch:11 step:8645 [D loss: 0.666928, acc: 60.16%] [G loss: 1.496759]\n",
      "epoch:11 step:8646 [D loss: 0.495856, acc: 85.94%] [G loss: 1.648996]\n",
      "epoch:11 step:8647 [D loss: 1.238801, acc: 1.56%] [G loss: 1.100746]\n",
      "epoch:11 step:8648 [D loss: 0.707536, acc: 53.91%] [G loss: 1.478395]\n",
      "epoch:11 step:8649 [D loss: 0.642034, acc: 65.62%] [G loss: 1.614264]\n",
      "epoch:11 step:8650 [D loss: 0.607144, acc: 71.09%] [G loss: 1.784710]\n",
      "epoch:11 step:8651 [D loss: 0.613847, acc: 70.31%] [G loss: 1.573344]\n",
      "epoch:11 step:8652 [D loss: 0.541255, acc: 82.03%] [G loss: 1.735727]\n",
      "epoch:11 step:8653 [D loss: 0.688091, acc: 60.16%] [G loss: 1.444896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8654 [D loss: 0.632614, acc: 64.06%] [G loss: 1.724386]\n",
      "epoch:11 step:8655 [D loss: 0.619368, acc: 68.75%] [G loss: 1.774944]\n",
      "epoch:11 step:8656 [D loss: 0.672907, acc: 52.34%] [G loss: 1.607149]\n",
      "epoch:11 step:8657 [D loss: 0.451578, acc: 84.38%] [G loss: 1.793690]\n",
      "epoch:11 step:8658 [D loss: 1.023466, acc: 15.62%] [G loss: 1.216847]\n",
      "epoch:11 step:8659 [D loss: 0.559030, acc: 82.81%] [G loss: 1.827466]\n",
      "epoch:11 step:8660 [D loss: 0.543845, acc: 81.25%] [G loss: 1.679170]\n",
      "epoch:11 step:8661 [D loss: 0.585358, acc: 65.62%] [G loss: 1.714051]\n",
      "epoch:11 step:8662 [D loss: 1.015383, acc: 9.38%] [G loss: 1.382965]\n",
      "epoch:11 step:8663 [D loss: 0.904689, acc: 39.06%] [G loss: 1.512415]\n",
      "epoch:11 step:8664 [D loss: 0.633037, acc: 57.03%] [G loss: 1.636791]\n",
      "epoch:11 step:8665 [D loss: 0.630413, acc: 61.72%] [G loss: 1.599207]\n",
      "epoch:11 step:8666 [D loss: 0.690781, acc: 58.59%] [G loss: 1.778755]\n",
      "epoch:11 step:8667 [D loss: 0.791593, acc: 37.50%] [G loss: 1.464941]\n",
      "epoch:11 step:8668 [D loss: 0.622408, acc: 67.19%] [G loss: 1.513970]\n",
      "epoch:11 step:8669 [D loss: 0.765914, acc: 51.56%] [G loss: 1.678233]\n",
      "epoch:11 step:8670 [D loss: 0.657665, acc: 62.50%] [G loss: 1.615817]\n",
      "epoch:11 step:8671 [D loss: 0.601131, acc: 69.53%] [G loss: 1.641148]\n",
      "epoch:11 step:8672 [D loss: 0.631554, acc: 60.94%] [G loss: 1.575425]\n",
      "epoch:11 step:8673 [D loss: 0.663702, acc: 57.81%] [G loss: 1.369117]\n",
      "epoch:11 step:8674 [D loss: 0.549489, acc: 74.22%] [G loss: 1.711864]\n",
      "epoch:11 step:8675 [D loss: 0.894819, acc: 29.69%] [G loss: 1.405097]\n",
      "epoch:11 step:8676 [D loss: 0.494102, acc: 86.72%] [G loss: 1.727793]\n",
      "epoch:11 step:8677 [D loss: 0.617814, acc: 64.84%] [G loss: 1.778893]\n",
      "epoch:11 step:8678 [D loss: 0.641252, acc: 68.75%] [G loss: 1.572494]\n",
      "epoch:11 step:8679 [D loss: 0.739241, acc: 47.66%] [G loss: 1.546118]\n",
      "epoch:11 step:8680 [D loss: 0.631216, acc: 61.72%] [G loss: 1.533172]\n",
      "epoch:11 step:8681 [D loss: 0.813832, acc: 32.03%] [G loss: 1.508008]\n",
      "epoch:11 step:8682 [D loss: 0.705467, acc: 49.22%] [G loss: 1.497131]\n",
      "epoch:11 step:8683 [D loss: 0.724213, acc: 46.88%] [G loss: 1.451494]\n",
      "epoch:11 step:8684 [D loss: 0.653840, acc: 59.38%] [G loss: 1.576951]\n",
      "epoch:11 step:8685 [D loss: 0.664040, acc: 63.28%] [G loss: 1.501786]\n",
      "epoch:11 step:8686 [D loss: 0.834452, acc: 38.28%] [G loss: 1.461864]\n",
      "epoch:11 step:8687 [D loss: 0.683571, acc: 57.81%] [G loss: 1.526993]\n",
      "epoch:11 step:8688 [D loss: 0.718077, acc: 46.88%] [G loss: 1.702566]\n",
      "epoch:11 step:8689 [D loss: 0.571299, acc: 71.09%] [G loss: 1.685506]\n",
      "epoch:11 step:8690 [D loss: 0.620397, acc: 71.88%] [G loss: 1.812747]\n",
      "epoch:11 step:8691 [D loss: 0.678338, acc: 57.03%] [G loss: 1.498597]\n",
      "epoch:11 step:8692 [D loss: 0.746817, acc: 46.09%] [G loss: 1.466297]\n",
      "epoch:11 step:8693 [D loss: 0.467295, acc: 76.56%] [G loss: 1.766385]\n",
      "epoch:11 step:8694 [D loss: 0.756044, acc: 42.97%] [G loss: 1.611274]\n",
      "epoch:11 step:8695 [D loss: 0.740559, acc: 46.09%] [G loss: 1.443513]\n",
      "epoch:11 step:8696 [D loss: 0.708766, acc: 57.03%] [G loss: 1.554337]\n",
      "epoch:11 step:8697 [D loss: 0.525817, acc: 81.25%] [G loss: 1.579024]\n",
      "epoch:11 step:8698 [D loss: 0.822364, acc: 31.25%] [G loss: 1.379704]\n",
      "epoch:11 step:8699 [D loss: 0.765750, acc: 46.88%] [G loss: 1.734756]\n",
      "epoch:11 step:8700 [D loss: 0.627114, acc: 67.97%] [G loss: 1.707093]\n",
      "epoch:11 step:8701 [D loss: 0.656391, acc: 69.53%] [G loss: 1.402426]\n",
      "epoch:11 step:8702 [D loss: 0.856989, acc: 24.22%] [G loss: 1.399278]\n",
      "epoch:11 step:8703 [D loss: 0.595335, acc: 73.44%] [G loss: 1.626629]\n",
      "epoch:11 step:8704 [D loss: 0.724485, acc: 44.53%] [G loss: 1.557972]\n",
      "epoch:11 step:8705 [D loss: 0.522363, acc: 89.84%] [G loss: 1.651517]\n",
      "epoch:11 step:8706 [D loss: 0.780042, acc: 39.06%] [G loss: 1.439278]\n",
      "epoch:11 step:8707 [D loss: 0.786744, acc: 40.62%] [G loss: 1.716276]\n",
      "epoch:11 step:8708 [D loss: 0.614736, acc: 67.97%] [G loss: 1.624320]\n",
      "epoch:11 step:8709 [D loss: 0.686826, acc: 56.25%] [G loss: 1.755858]\n",
      "epoch:11 step:8710 [D loss: 0.635422, acc: 67.19%] [G loss: 1.679336]\n",
      "epoch:11 step:8711 [D loss: 0.689860, acc: 51.56%] [G loss: 1.613808]\n",
      "epoch:11 step:8712 [D loss: 0.577626, acc: 78.12%] [G loss: 1.767565]\n",
      "epoch:11 step:8713 [D loss: 0.670963, acc: 57.03%] [G loss: 1.898079]\n",
      "epoch:11 step:8714 [D loss: 0.533570, acc: 81.25%] [G loss: 1.806032]\n",
      "epoch:11 step:8715 [D loss: 0.500976, acc: 77.34%] [G loss: 1.893150]\n",
      "epoch:11 step:8716 [D loss: 0.535533, acc: 79.69%] [G loss: 1.716455]\n",
      "epoch:11 step:8717 [D loss: 0.699946, acc: 53.91%] [G loss: 1.364963]\n",
      "epoch:11 step:8718 [D loss: 0.670451, acc: 59.38%] [G loss: 1.561390]\n",
      "epoch:11 step:8719 [D loss: 0.568156, acc: 71.09%] [G loss: 1.938499]\n",
      "epoch:11 step:8720 [D loss: 0.423382, acc: 87.50%] [G loss: 1.718609]\n",
      "epoch:11 step:8721 [D loss: 0.760975, acc: 53.91%] [G loss: 1.439571]\n",
      "epoch:11 step:8722 [D loss: 0.591318, acc: 74.22%] [G loss: 1.784989]\n",
      "epoch:11 step:8723 [D loss: 0.620485, acc: 67.19%] [G loss: 1.564517]\n",
      "epoch:11 step:8724 [D loss: 0.671658, acc: 58.59%] [G loss: 1.370244]\n",
      "epoch:11 step:8725 [D loss: 0.469268, acc: 89.06%] [G loss: 1.709607]\n",
      "epoch:11 step:8726 [D loss: 0.982371, acc: 27.34%] [G loss: 1.270304]\n",
      "epoch:11 step:8727 [D loss: 0.828831, acc: 37.50%] [G loss: 1.500685]\n",
      "epoch:11 step:8728 [D loss: 0.777711, acc: 43.75%] [G loss: 1.520833]\n",
      "epoch:11 step:8729 [D loss: 0.566042, acc: 73.44%] [G loss: 1.792748]\n",
      "epoch:11 step:8730 [D loss: 0.643285, acc: 63.28%] [G loss: 1.692785]\n",
      "epoch:11 step:8731 [D loss: 0.594399, acc: 71.09%] [G loss: 1.708483]\n",
      "epoch:11 step:8732 [D loss: 0.745507, acc: 42.97%] [G loss: 1.508886]\n",
      "epoch:11 step:8733 [D loss: 0.745035, acc: 41.41%] [G loss: 1.502645]\n",
      "epoch:11 step:8734 [D loss: 0.695189, acc: 57.81%] [G loss: 1.486416]\n",
      "epoch:11 step:8735 [D loss: 0.646685, acc: 65.62%] [G loss: 1.566476]\n",
      "epoch:11 step:8736 [D loss: 0.699421, acc: 50.00%] [G loss: 1.614081]\n",
      "epoch:11 step:8737 [D loss: 0.706533, acc: 49.22%] [G loss: 1.701776]\n",
      "epoch:11 step:8738 [D loss: 0.746266, acc: 43.75%] [G loss: 1.719944]\n",
      "epoch:11 step:8739 [D loss: 0.421119, acc: 79.69%] [G loss: 1.948403]\n",
      "epoch:11 step:8740 [D loss: 0.760609, acc: 45.31%] [G loss: 1.688797]\n",
      "epoch:11 step:8741 [D loss: 0.638690, acc: 64.84%] [G loss: 1.540132]\n",
      "epoch:11 step:8742 [D loss: 0.624558, acc: 71.88%] [G loss: 1.558792]\n",
      "epoch:11 step:8743 [D loss: 0.628363, acc: 66.41%] [G loss: 1.636168]\n",
      "epoch:11 step:8744 [D loss: 0.690697, acc: 53.12%] [G loss: 1.739909]\n",
      "epoch:11 step:8745 [D loss: 0.511381, acc: 88.28%] [G loss: 1.955573]\n",
      "epoch:11 step:8746 [D loss: 0.722749, acc: 55.47%] [G loss: 1.495403]\n",
      "epoch:11 step:8747 [D loss: 0.509566, acc: 80.47%] [G loss: 1.744025]\n",
      "epoch:11 step:8748 [D loss: 0.582807, acc: 78.12%] [G loss: 1.699800]\n",
      "epoch:11 step:8749 [D loss: 0.861243, acc: 22.66%] [G loss: 1.499533]\n",
      "epoch:11 step:8750 [D loss: 0.547678, acc: 75.00%] [G loss: 1.548513]\n",
      "epoch:11 step:8751 [D loss: 0.943066, acc: 42.97%] [G loss: 1.346241]\n",
      "epoch:11 step:8752 [D loss: 0.705152, acc: 51.56%] [G loss: 1.534763]\n",
      "epoch:11 step:8753 [D loss: 0.569316, acc: 72.66%] [G loss: 1.835509]\n",
      "epoch:11 step:8754 [D loss: 0.790506, acc: 33.59%] [G loss: 1.623518]\n",
      "epoch:11 step:8755 [D loss: 0.834300, acc: 25.78%] [G loss: 1.697246]\n",
      "epoch:11 step:8756 [D loss: 0.689157, acc: 57.81%] [G loss: 1.582547]\n",
      "epoch:11 step:8757 [D loss: 0.762005, acc: 50.00%] [G loss: 1.689553]\n",
      "epoch:11 step:8758 [D loss: 0.773462, acc: 44.53%] [G loss: 1.771240]\n",
      "epoch:11 step:8759 [D loss: 0.596429, acc: 72.66%] [G loss: 1.877944]\n",
      "epoch:11 step:8760 [D loss: 0.698506, acc: 50.00%] [G loss: 1.427508]\n",
      "epoch:11 step:8761 [D loss: 0.506035, acc: 69.53%] [G loss: 1.694896]\n",
      "epoch:11 step:8762 [D loss: 0.827226, acc: 32.03%] [G loss: 1.728914]\n",
      "epoch:11 step:8763 [D loss: 0.706001, acc: 47.66%] [G loss: 1.690058]\n",
      "epoch:11 step:8764 [D loss: 0.933938, acc: 17.97%] [G loss: 1.252761]\n",
      "epoch:11 step:8765 [D loss: 0.641527, acc: 65.62%] [G loss: 1.587689]\n",
      "epoch:11 step:8766 [D loss: 0.501708, acc: 84.38%] [G loss: 1.850942]\n",
      "epoch:11 step:8767 [D loss: 0.632567, acc: 67.19%] [G loss: 1.686041]\n",
      "epoch:11 step:8768 [D loss: 0.733510, acc: 42.97%] [G loss: 1.654984]\n",
      "epoch:11 step:8769 [D loss: 0.749538, acc: 42.97%] [G loss: 1.755711]\n",
      "epoch:11 step:8770 [D loss: 0.482802, acc: 85.16%] [G loss: 1.765080]\n",
      "epoch:11 step:8771 [D loss: 0.642414, acc: 64.06%] [G loss: 1.667356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8772 [D loss: 0.693597, acc: 52.34%] [G loss: 1.579754]\n",
      "epoch:11 step:8773 [D loss: 0.596583, acc: 72.66%] [G loss: 1.676107]\n",
      "epoch:11 step:8774 [D loss: 0.616641, acc: 67.97%] [G loss: 1.599640]\n",
      "epoch:11 step:8775 [D loss: 0.725354, acc: 49.22%] [G loss: 1.664463]\n",
      "epoch:11 step:8776 [D loss: 0.818137, acc: 29.69%] [G loss: 1.424487]\n",
      "epoch:11 step:8777 [D loss: 0.619610, acc: 66.41%] [G loss: 1.740177]\n",
      "epoch:11 step:8778 [D loss: 0.604813, acc: 70.31%] [G loss: 1.698931]\n",
      "epoch:11 step:8779 [D loss: 0.551293, acc: 78.91%] [G loss: 1.993056]\n",
      "epoch:11 step:8780 [D loss: 0.512042, acc: 85.16%] [G loss: 1.737697]\n",
      "epoch:11 step:8781 [D loss: 0.678126, acc: 58.59%] [G loss: 1.611039]\n",
      "epoch:11 step:8782 [D loss: 0.570783, acc: 80.47%] [G loss: 1.787206]\n",
      "epoch:11 step:8783 [D loss: 0.691795, acc: 57.03%] [G loss: 1.605429]\n",
      "epoch:11 step:8784 [D loss: 0.576233, acc: 70.31%] [G loss: 1.625720]\n",
      "epoch:11 step:8785 [D loss: 0.693927, acc: 53.12%] [G loss: 1.634826]\n",
      "epoch:11 step:8786 [D loss: 0.798846, acc: 34.38%] [G loss: 1.602222]\n",
      "epoch:11 step:8787 [D loss: 0.840179, acc: 46.88%] [G loss: 1.242453]\n",
      "epoch:11 step:8788 [D loss: 0.566209, acc: 72.66%] [G loss: 1.782552]\n",
      "epoch:11 step:8789 [D loss: 0.602476, acc: 71.88%] [G loss: 1.807375]\n",
      "epoch:11 step:8790 [D loss: 0.723876, acc: 42.97%] [G loss: 1.417774]\n",
      "epoch:11 step:8791 [D loss: 0.625023, acc: 62.50%] [G loss: 1.560225]\n",
      "epoch:11 step:8792 [D loss: 0.515476, acc: 87.50%] [G loss: 1.891725]\n",
      "epoch:11 step:8793 [D loss: 0.800286, acc: 43.75%] [G loss: 1.745132]\n",
      "epoch:11 step:8794 [D loss: 0.674968, acc: 62.50%] [G loss: 1.685846]\n",
      "epoch:11 step:8795 [D loss: 0.733255, acc: 44.53%] [G loss: 1.564089]\n",
      "epoch:11 step:8796 [D loss: 1.080300, acc: 20.31%] [G loss: 1.217572]\n",
      "epoch:11 step:8797 [D loss: 0.689208, acc: 55.47%] [G loss: 1.472945]\n",
      "epoch:11 step:8798 [D loss: 0.736138, acc: 44.53%] [G loss: 1.555978]\n",
      "epoch:11 step:8799 [D loss: 0.724852, acc: 50.00%] [G loss: 1.634665]\n",
      "epoch:11 step:8800 [D loss: 0.561820, acc: 71.09%] [G loss: 1.521882]\n",
      "epoch:11 step:8801 [D loss: 0.806289, acc: 25.78%] [G loss: 1.588373]\n",
      "epoch:11 step:8802 [D loss: 0.557565, acc: 82.81%] [G loss: 1.597070]\n",
      "epoch:11 step:8803 [D loss: 0.679491, acc: 60.16%] [G loss: 1.622027]\n",
      "epoch:11 step:8804 [D loss: 0.750291, acc: 39.06%] [G loss: 1.414886]\n",
      "epoch:11 step:8805 [D loss: 0.594608, acc: 71.88%] [G loss: 1.506359]\n",
      "epoch:11 step:8806 [D loss: 0.746414, acc: 40.62%] [G loss: 1.428333]\n",
      "epoch:11 step:8807 [D loss: 0.757979, acc: 37.50%] [G loss: 1.673218]\n",
      "epoch:11 step:8808 [D loss: 0.812129, acc: 37.50%] [G loss: 1.353067]\n",
      "epoch:11 step:8809 [D loss: 0.675797, acc: 57.81%] [G loss: 1.634734]\n",
      "epoch:11 step:8810 [D loss: 0.570374, acc: 81.25%] [G loss: 1.796851]\n",
      "epoch:11 step:8811 [D loss: 0.614258, acc: 66.41%] [G loss: 1.663141]\n",
      "epoch:11 step:8812 [D loss: 0.614491, acc: 71.09%] [G loss: 1.511928]\n",
      "epoch:11 step:8813 [D loss: 0.586948, acc: 77.34%] [G loss: 1.675612]\n",
      "epoch:11 step:8814 [D loss: 0.704535, acc: 55.47%] [G loss: 1.489522]\n",
      "epoch:11 step:8815 [D loss: 0.667239, acc: 60.94%] [G loss: 1.447653]\n",
      "epoch:11 step:8816 [D loss: 0.801209, acc: 39.84%] [G loss: 1.387203]\n",
      "epoch:11 step:8817 [D loss: 0.934229, acc: 21.09%] [G loss: 1.359711]\n",
      "epoch:11 step:8818 [D loss: 0.597653, acc: 76.56%] [G loss: 1.586175]\n",
      "epoch:11 step:8819 [D loss: 0.620046, acc: 66.41%] [G loss: 1.625955]\n",
      "epoch:11 step:8820 [D loss: 0.763513, acc: 40.62%] [G loss: 1.515027]\n",
      "epoch:11 step:8821 [D loss: 0.634038, acc: 67.19%] [G loss: 1.504995]\n",
      "epoch:11 step:8822 [D loss: 0.579079, acc: 75.78%] [G loss: 1.608026]\n",
      "epoch:11 step:8823 [D loss: 0.793797, acc: 35.94%] [G loss: 1.427569]\n",
      "epoch:11 step:8824 [D loss: 0.520290, acc: 89.84%] [G loss: 1.682018]\n",
      "epoch:11 step:8825 [D loss: 0.890172, acc: 17.97%] [G loss: 1.654709]\n",
      "epoch:11 step:8826 [D loss: 0.542338, acc: 75.78%] [G loss: 1.929741]\n",
      "epoch:11 step:8827 [D loss: 0.609231, acc: 69.53%] [G loss: 1.746407]\n",
      "epoch:11 step:8828 [D loss: 0.510055, acc: 89.06%] [G loss: 1.726019]\n",
      "epoch:11 step:8829 [D loss: 0.601974, acc: 77.34%] [G loss: 1.649234]\n",
      "epoch:11 step:8830 [D loss: 0.699551, acc: 58.59%] [G loss: 1.512154]\n",
      "epoch:11 step:8831 [D loss: 0.730438, acc: 50.78%] [G loss: 1.386911]\n",
      "epoch:11 step:8832 [D loss: 0.550749, acc: 78.12%] [G loss: 1.775114]\n",
      "epoch:11 step:8833 [D loss: 0.717626, acc: 50.00%] [G loss: 1.528246]\n",
      "epoch:11 step:8834 [D loss: 0.706123, acc: 52.34%] [G loss: 1.568957]\n",
      "epoch:11 step:8835 [D loss: 0.647942, acc: 62.50%] [G loss: 1.727558]\n",
      "epoch:11 step:8836 [D loss: 0.852313, acc: 25.78%] [G loss: 1.717205]\n",
      "epoch:11 step:8837 [D loss: 0.505159, acc: 76.56%] [G loss: 1.898094]\n",
      "epoch:11 step:8838 [D loss: 0.621039, acc: 59.38%] [G loss: 1.848124]\n",
      "epoch:11 step:8839 [D loss: 0.665472, acc: 57.03%] [G loss: 1.575898]\n",
      "epoch:11 step:8840 [D loss: 0.534442, acc: 83.59%] [G loss: 1.828571]\n",
      "epoch:11 step:8841 [D loss: 0.508132, acc: 88.28%] [G loss: 1.960384]\n",
      "epoch:11 step:8842 [D loss: 0.806105, acc: 46.09%] [G loss: 1.530394]\n",
      "epoch:11 step:8843 [D loss: 0.778967, acc: 39.06%] [G loss: 1.594503]\n",
      "epoch:11 step:8844 [D loss: 0.793660, acc: 42.97%] [G loss: 1.475643]\n",
      "epoch:11 step:8845 [D loss: 0.726583, acc: 40.62%] [G loss: 1.440047]\n",
      "epoch:11 step:8846 [D loss: 0.716361, acc: 50.78%] [G loss: 1.561780]\n",
      "epoch:11 step:8847 [D loss: 0.687321, acc: 55.47%] [G loss: 1.507514]\n",
      "epoch:11 step:8848 [D loss: 0.765772, acc: 42.19%] [G loss: 1.696768]\n",
      "epoch:11 step:8849 [D loss: 0.732706, acc: 43.75%] [G loss: 1.647319]\n",
      "epoch:11 step:8850 [D loss: 0.699887, acc: 50.00%] [G loss: 1.726669]\n",
      "epoch:11 step:8851 [D loss: 0.519419, acc: 85.16%] [G loss: 1.717021]\n",
      "epoch:11 step:8852 [D loss: 0.596806, acc: 61.72%] [G loss: 1.672119]\n",
      "epoch:11 step:8853 [D loss: 0.452366, acc: 86.72%] [G loss: 1.743337]\n",
      "epoch:11 step:8854 [D loss: 0.806457, acc: 36.72%] [G loss: 1.352314]\n",
      "epoch:11 step:8855 [D loss: 0.603626, acc: 73.44%] [G loss: 1.472857]\n",
      "epoch:11 step:8856 [D loss: 0.654216, acc: 64.06%] [G loss: 1.707257]\n",
      "epoch:11 step:8857 [D loss: 0.483179, acc: 89.84%] [G loss: 1.748192]\n",
      "epoch:11 step:8858 [D loss: 1.126095, acc: 10.16%] [G loss: 1.363555]\n",
      "epoch:11 step:8859 [D loss: 0.658125, acc: 67.97%] [G loss: 1.511047]\n",
      "epoch:11 step:8860 [D loss: 0.651182, acc: 62.50%] [G loss: 1.590242]\n",
      "epoch:11 step:8861 [D loss: 0.613929, acc: 66.41%] [G loss: 1.515658]\n",
      "epoch:11 step:8862 [D loss: 0.745391, acc: 46.09%] [G loss: 1.614822]\n",
      "epoch:11 step:8863 [D loss: 0.770733, acc: 43.75%] [G loss: 1.477533]\n",
      "epoch:11 step:8864 [D loss: 0.710465, acc: 46.09%] [G loss: 1.584583]\n",
      "epoch:11 step:8865 [D loss: 0.609189, acc: 60.94%] [G loss: 1.487135]\n",
      "epoch:11 step:8866 [D loss: 0.534611, acc: 85.94%] [G loss: 1.610554]\n",
      "epoch:11 step:8867 [D loss: 0.675593, acc: 58.59%] [G loss: 1.587526]\n",
      "epoch:11 step:8868 [D loss: 0.891007, acc: 48.44%] [G loss: 1.150626]\n",
      "epoch:11 step:8869 [D loss: 0.619284, acc: 65.62%] [G loss: 1.712899]\n",
      "epoch:11 step:8870 [D loss: 0.712752, acc: 50.00%] [G loss: 1.798258]\n",
      "epoch:11 step:8871 [D loss: 0.505996, acc: 82.81%] [G loss: 1.616339]\n",
      "epoch:11 step:8872 [D loss: 0.625709, acc: 61.72%] [G loss: 1.640780]\n",
      "epoch:11 step:8873 [D loss: 0.624087, acc: 62.50%] [G loss: 1.433822]\n",
      "epoch:11 step:8874 [D loss: 0.681787, acc: 53.91%] [G loss: 1.663392]\n",
      "epoch:11 step:8875 [D loss: 0.719276, acc: 52.34%] [G loss: 1.471983]\n",
      "epoch:11 step:8876 [D loss: 0.494863, acc: 90.62%] [G loss: 1.906756]\n",
      "epoch:11 step:8877 [D loss: 0.648652, acc: 61.72%] [G loss: 1.741572]\n",
      "epoch:11 step:8878 [D loss: 0.812957, acc: 30.47%] [G loss: 1.473940]\n",
      "epoch:11 step:8879 [D loss: 0.735785, acc: 47.66%] [G loss: 1.668247]\n",
      "epoch:11 step:8880 [D loss: 0.701080, acc: 53.12%] [G loss: 1.524995]\n",
      "epoch:11 step:8881 [D loss: 0.661079, acc: 65.62%] [G loss: 1.560834]\n",
      "epoch:11 step:8882 [D loss: 0.677245, acc: 58.59%] [G loss: 1.423109]\n",
      "epoch:11 step:8883 [D loss: 0.794908, acc: 33.59%] [G loss: 1.648630]\n",
      "epoch:11 step:8884 [D loss: 0.544809, acc: 78.91%] [G loss: 1.821486]\n",
      "epoch:11 step:8885 [D loss: 0.495960, acc: 87.50%] [G loss: 1.591524]\n",
      "epoch:11 step:8886 [D loss: 0.456189, acc: 88.28%] [G loss: 1.798005]\n",
      "epoch:11 step:8887 [D loss: 0.630826, acc: 75.00%] [G loss: 1.690920]\n",
      "epoch:11 step:8888 [D loss: 0.801268, acc: 36.72%] [G loss: 1.644582]\n",
      "epoch:11 step:8889 [D loss: 0.767922, acc: 46.09%] [G loss: 1.473379]\n",
      "epoch:11 step:8890 [D loss: 0.494094, acc: 86.72%] [G loss: 1.858093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8891 [D loss: 0.990386, acc: 17.19%] [G loss: 1.420627]\n",
      "epoch:11 step:8892 [D loss: 0.773754, acc: 45.31%] [G loss: 1.475685]\n",
      "epoch:11 step:8893 [D loss: 0.615031, acc: 67.97%] [G loss: 1.641452]\n",
      "epoch:11 step:8894 [D loss: 0.682573, acc: 56.25%] [G loss: 1.506950]\n",
      "epoch:11 step:8895 [D loss: 0.800965, acc: 38.28%] [G loss: 1.402376]\n",
      "epoch:11 step:8896 [D loss: 0.741744, acc: 48.44%] [G loss: 1.591061]\n",
      "epoch:11 step:8897 [D loss: 0.496845, acc: 89.84%] [G loss: 1.728138]\n",
      "epoch:11 step:8898 [D loss: 0.866398, acc: 26.56%] [G loss: 1.391183]\n",
      "epoch:11 step:8899 [D loss: 0.637755, acc: 67.97%] [G loss: 1.723079]\n",
      "epoch:11 step:8900 [D loss: 0.630097, acc: 66.41%] [G loss: 1.456222]\n",
      "epoch:11 step:8901 [D loss: 0.672695, acc: 57.03%] [G loss: 1.494931]\n",
      "epoch:11 step:8902 [D loss: 0.828179, acc: 28.12%] [G loss: 1.396815]\n",
      "epoch:11 step:8903 [D loss: 0.674695, acc: 50.00%] [G loss: 1.625102]\n",
      "epoch:11 step:8904 [D loss: 0.653386, acc: 63.28%] [G loss: 1.650172]\n",
      "epoch:11 step:8905 [D loss: 0.732332, acc: 47.66%] [G loss: 1.558724]\n",
      "epoch:11 step:8906 [D loss: 0.776255, acc: 51.56%] [G loss: 1.531156]\n",
      "epoch:11 step:8907 [D loss: 0.500498, acc: 88.28%] [G loss: 1.684076]\n",
      "epoch:11 step:8908 [D loss: 0.842906, acc: 38.28%] [G loss: 1.703807]\n",
      "epoch:11 step:8909 [D loss: 0.490183, acc: 89.06%] [G loss: 1.896700]\n",
      "epoch:11 step:8910 [D loss: 0.797251, acc: 34.38%] [G loss: 1.598382]\n",
      "epoch:11 step:8911 [D loss: 0.815678, acc: 22.66%] [G loss: 1.407867]\n",
      "epoch:11 step:8912 [D loss: 0.615444, acc: 71.09%] [G loss: 1.513667]\n",
      "epoch:11 step:8913 [D loss: 0.712172, acc: 50.78%] [G loss: 1.516457]\n",
      "epoch:11 step:8914 [D loss: 0.717661, acc: 53.12%] [G loss: 1.598819]\n",
      "epoch:11 step:8915 [D loss: 0.571518, acc: 75.00%] [G loss: 1.560252]\n",
      "epoch:11 step:8916 [D loss: 0.690422, acc: 54.69%] [G loss: 1.438937]\n",
      "epoch:11 step:8917 [D loss: 0.505207, acc: 79.69%] [G loss: 1.670952]\n",
      "epoch:11 step:8918 [D loss: 0.735647, acc: 42.19%] [G loss: 1.512094]\n",
      "epoch:11 step:8919 [D loss: 0.738298, acc: 40.62%] [G loss: 1.471017]\n",
      "epoch:11 step:8920 [D loss: 0.914072, acc: 18.75%] [G loss: 1.359973]\n",
      "epoch:11 step:8921 [D loss: 0.786455, acc: 37.50%] [G loss: 1.582777]\n",
      "epoch:11 step:8922 [D loss: 0.781418, acc: 43.75%] [G loss: 1.494194]\n",
      "epoch:11 step:8923 [D loss: 0.596253, acc: 67.19%] [G loss: 1.679589]\n",
      "epoch:11 step:8924 [D loss: 0.685905, acc: 55.47%] [G loss: 1.492103]\n",
      "epoch:11 step:8925 [D loss: 0.690501, acc: 58.59%] [G loss: 1.752478]\n",
      "epoch:11 step:8926 [D loss: 0.685086, acc: 53.91%] [G loss: 1.810689]\n",
      "epoch:11 step:8927 [D loss: 0.605405, acc: 68.75%] [G loss: 1.489564]\n",
      "epoch:11 step:8928 [D loss: 0.744007, acc: 47.66%] [G loss: 1.518667]\n",
      "epoch:11 step:8929 [D loss: 0.860243, acc: 30.47%] [G loss: 1.489117]\n",
      "epoch:11 step:8930 [D loss: 0.692649, acc: 53.91%] [G loss: 1.483438]\n",
      "epoch:11 step:8931 [D loss: 0.685204, acc: 59.38%] [G loss: 1.521835]\n",
      "epoch:11 step:8932 [D loss: 0.678063, acc: 59.38%] [G loss: 1.539335]\n",
      "epoch:11 step:8933 [D loss: 0.626988, acc: 71.88%] [G loss: 1.648921]\n",
      "epoch:11 step:8934 [D loss: 0.618563, acc: 71.88%] [G loss: 1.510878]\n",
      "epoch:11 step:8935 [D loss: 0.542572, acc: 86.72%] [G loss: 1.893528]\n",
      "epoch:11 step:8936 [D loss: 0.721404, acc: 53.91%] [G loss: 1.664405]\n",
      "epoch:11 step:8937 [D loss: 0.613452, acc: 70.31%] [G loss: 1.466934]\n",
      "epoch:11 step:8938 [D loss: 0.654096, acc: 63.28%] [G loss: 1.751049]\n",
      "epoch:11 step:8939 [D loss: 0.592811, acc: 60.16%] [G loss: 1.519938]\n",
      "epoch:11 step:8940 [D loss: 0.621479, acc: 72.66%] [G loss: 1.550616]\n",
      "epoch:11 step:8941 [D loss: 0.677280, acc: 56.25%] [G loss: 1.410788]\n",
      "epoch:11 step:8942 [D loss: 0.616566, acc: 61.72%] [G loss: 1.655114]\n",
      "epoch:11 step:8943 [D loss: 0.659024, acc: 61.72%] [G loss: 1.781987]\n",
      "epoch:11 step:8944 [D loss: 0.787461, acc: 35.94%] [G loss: 1.389183]\n",
      "epoch:11 step:8945 [D loss: 0.622822, acc: 68.75%] [G loss: 1.500476]\n",
      "epoch:11 step:8946 [D loss: 0.740547, acc: 42.97%] [G loss: 1.587811]\n",
      "epoch:11 step:8947 [D loss: 0.620216, acc: 70.31%] [G loss: 1.636622]\n",
      "epoch:11 step:8948 [D loss: 0.519696, acc: 82.03%] [G loss: 1.596679]\n",
      "epoch:11 step:8949 [D loss: 0.594505, acc: 75.00%] [G loss: 1.521428]\n",
      "epoch:11 step:8950 [D loss: 0.697540, acc: 54.69%] [G loss: 1.542394]\n",
      "epoch:11 step:8951 [D loss: 0.647411, acc: 58.59%] [G loss: 1.636510]\n",
      "epoch:11 step:8952 [D loss: 0.714514, acc: 50.00%] [G loss: 1.482533]\n",
      "epoch:11 step:8953 [D loss: 0.665068, acc: 60.16%] [G loss: 1.645387]\n",
      "epoch:11 step:8954 [D loss: 0.724097, acc: 53.12%] [G loss: 1.700492]\n",
      "epoch:11 step:8955 [D loss: 0.556211, acc: 79.69%] [G loss: 1.589243]\n",
      "epoch:11 step:8956 [D loss: 0.705553, acc: 53.91%] [G loss: 1.568762]\n",
      "epoch:11 step:8957 [D loss: 0.658874, acc: 60.16%] [G loss: 1.819057]\n",
      "epoch:11 step:8958 [D loss: 0.714430, acc: 50.78%] [G loss: 1.550144]\n",
      "epoch:11 step:8959 [D loss: 0.790541, acc: 36.72%] [G loss: 1.701298]\n",
      "epoch:11 step:8960 [D loss: 0.669412, acc: 51.56%] [G loss: 1.550923]\n",
      "epoch:11 step:8961 [D loss: 0.739418, acc: 45.31%] [G loss: 1.463025]\n",
      "epoch:11 step:8962 [D loss: 0.723376, acc: 46.88%] [G loss: 1.775193]\n",
      "epoch:11 step:8963 [D loss: 0.706776, acc: 50.78%] [G loss: 1.788178]\n",
      "epoch:11 step:8964 [D loss: 0.829136, acc: 47.66%] [G loss: 1.288344]\n",
      "epoch:11 step:8965 [D loss: 0.397594, acc: 94.53%] [G loss: 1.672559]\n",
      "epoch:11 step:8966 [D loss: 0.595223, acc: 75.00%] [G loss: 1.570385]\n",
      "epoch:11 step:8967 [D loss: 0.555338, acc: 81.25%] [G loss: 1.521249]\n",
      "epoch:11 step:8968 [D loss: 0.620926, acc: 65.62%] [G loss: 1.610170]\n",
      "epoch:11 step:8969 [D loss: 0.905776, acc: 25.00%] [G loss: 1.419213]\n",
      "epoch:11 step:8970 [D loss: 0.463712, acc: 95.31%] [G loss: 1.817433]\n",
      "epoch:11 step:8971 [D loss: 0.831856, acc: 28.12%] [G loss: 1.574744]\n",
      "epoch:11 step:8972 [D loss: 0.670193, acc: 55.47%] [G loss: 1.750058]\n",
      "epoch:11 step:8973 [D loss: 0.650440, acc: 62.50%] [G loss: 1.698090]\n",
      "epoch:11 step:8974 [D loss: 0.761702, acc: 42.97%] [G loss: 1.413784]\n",
      "epoch:11 step:8975 [D loss: 0.639530, acc: 62.50%] [G loss: 1.709629]\n",
      "epoch:11 step:8976 [D loss: 0.692918, acc: 55.47%] [G loss: 1.412620]\n",
      "epoch:11 step:8977 [D loss: 0.597603, acc: 71.88%] [G loss: 1.675833]\n",
      "epoch:11 step:8978 [D loss: 0.670672, acc: 60.94%] [G loss: 1.734858]\n",
      "epoch:11 step:8979 [D loss: 0.627882, acc: 62.50%] [G loss: 1.360643]\n",
      "epoch:11 step:8980 [D loss: 0.440209, acc: 93.75%] [G loss: 1.643127]\n",
      "epoch:11 step:8981 [D loss: 0.778242, acc: 44.53%] [G loss: 1.686583]\n",
      "epoch:11 step:8982 [D loss: 0.743950, acc: 46.09%] [G loss: 1.650678]\n",
      "epoch:11 step:8983 [D loss: 0.879363, acc: 25.00%] [G loss: 1.470832]\n",
      "epoch:11 step:8984 [D loss: 0.722797, acc: 49.22%] [G loss: 1.441779]\n",
      "epoch:11 step:8985 [D loss: 0.486306, acc: 93.75%] [G loss: 1.766172]\n",
      "epoch:11 step:8986 [D loss: 0.553347, acc: 70.31%] [G loss: 1.743250]\n",
      "epoch:11 step:8987 [D loss: 0.673260, acc: 58.59%] [G loss: 1.735908]\n",
      "epoch:11 step:8988 [D loss: 0.619519, acc: 70.31%] [G loss: 1.681264]\n",
      "epoch:11 step:8989 [D loss: 0.694027, acc: 52.34%] [G loss: 1.729231]\n",
      "epoch:11 step:8990 [D loss: 0.477251, acc: 88.28%] [G loss: 1.719367]\n",
      "epoch:11 step:8991 [D loss: 0.569895, acc: 78.91%] [G loss: 1.799847]\n",
      "epoch:11 step:8992 [D loss: 0.651716, acc: 60.94%] [G loss: 1.671987]\n",
      "epoch:11 step:8993 [D loss: 0.810474, acc: 37.50%] [G loss: 1.511964]\n",
      "epoch:11 step:8994 [D loss: 0.757306, acc: 40.62%] [G loss: 1.493222]\n",
      "epoch:11 step:8995 [D loss: 0.638990, acc: 65.62%] [G loss: 1.513237]\n",
      "epoch:11 step:8996 [D loss: 0.643791, acc: 69.53%] [G loss: 2.008166]\n",
      "epoch:11 step:8997 [D loss: 0.654044, acc: 62.50%] [G loss: 1.678816]\n",
      "epoch:11 step:8998 [D loss: 0.705267, acc: 50.78%] [G loss: 1.575630]\n",
      "epoch:11 step:8999 [D loss: 0.711568, acc: 54.69%] [G loss: 1.643954]\n",
      "epoch:11 step:9000 [D loss: 0.579836, acc: 73.44%] [G loss: 1.718033]\n",
      "epoch:11 step:9001 [D loss: 0.703286, acc: 50.00%] [G loss: 1.576091]\n",
      "epoch:11 step:9002 [D loss: 1.197287, acc: 8.59%] [G loss: 1.660407]\n",
      "epoch:11 step:9003 [D loss: 0.711410, acc: 48.44%] [G loss: 1.767196]\n",
      "epoch:11 step:9004 [D loss: 0.507132, acc: 85.94%] [G loss: 1.756275]\n",
      "epoch:11 step:9005 [D loss: 0.706340, acc: 54.69%] [G loss: 1.852338]\n",
      "epoch:11 step:9006 [D loss: 0.740449, acc: 50.78%] [G loss: 1.757717]\n",
      "epoch:11 step:9007 [D loss: 0.839066, acc: 38.28%] [G loss: 1.428559]\n",
      "epoch:11 step:9008 [D loss: 0.581145, acc: 76.56%] [G loss: 1.951234]\n",
      "epoch:11 step:9009 [D loss: 0.578732, acc: 73.44%] [G loss: 1.654549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9010 [D loss: 0.683125, acc: 52.34%] [G loss: 1.698153]\n",
      "epoch:11 step:9011 [D loss: 0.922978, acc: 17.19%] [G loss: 1.501363]\n",
      "epoch:11 step:9012 [D loss: 0.639748, acc: 62.50%] [G loss: 1.770817]\n",
      "epoch:11 step:9013 [D loss: 0.594588, acc: 73.44%] [G loss: 1.752791]\n",
      "epoch:11 step:9014 [D loss: 0.668391, acc: 64.06%] [G loss: 1.667441]\n",
      "epoch:11 step:9015 [D loss: 0.914084, acc: 45.31%] [G loss: 1.449076]\n",
      "epoch:11 step:9016 [D loss: 0.587125, acc: 72.66%] [G loss: 1.938691]\n",
      "epoch:11 step:9017 [D loss: 0.696096, acc: 45.31%] [G loss: 1.695918]\n",
      "epoch:11 step:9018 [D loss: 0.782252, acc: 33.59%] [G loss: 1.495802]\n",
      "epoch:11 step:9019 [D loss: 0.619143, acc: 68.75%] [G loss: 1.547712]\n",
      "epoch:11 step:9020 [D loss: 0.536073, acc: 81.25%] [G loss: 1.973264]\n",
      "epoch:11 step:9021 [D loss: 0.848031, acc: 27.34%] [G loss: 1.476493]\n",
      "epoch:11 step:9022 [D loss: 0.582774, acc: 57.81%] [G loss: 1.397119]\n",
      "epoch:11 step:9023 [D loss: 0.609053, acc: 70.31%] [G loss: 1.696133]\n",
      "epoch:11 step:9024 [D loss: 0.728236, acc: 54.69%] [G loss: 1.667754]\n",
      "epoch:11 step:9025 [D loss: 0.757014, acc: 42.97%] [G loss: 1.451752]\n",
      "epoch:11 step:9026 [D loss: 0.574708, acc: 72.66%] [G loss: 1.447644]\n",
      "epoch:11 step:9027 [D loss: 0.538689, acc: 71.88%] [G loss: 1.622573]\n",
      "epoch:11 step:9028 [D loss: 0.905987, acc: 17.97%] [G loss: 1.313308]\n",
      "epoch:11 step:9029 [D loss: 0.693469, acc: 49.22%] [G loss: 1.708813]\n",
      "epoch:11 step:9030 [D loss: 0.751025, acc: 39.84%] [G loss: 1.442473]\n",
      "epoch:11 step:9031 [D loss: 0.629938, acc: 70.31%] [G loss: 1.549598]\n",
      "epoch:11 step:9032 [D loss: 0.659673, acc: 57.03%] [G loss: 1.305042]\n",
      "epoch:11 step:9033 [D loss: 0.579621, acc: 75.00%] [G loss: 1.473945]\n",
      "epoch:11 step:9034 [D loss: 0.422511, acc: 92.97%] [G loss: 1.631088]\n",
      "epoch:11 step:9035 [D loss: 0.829911, acc: 35.16%] [G loss: 1.555642]\n",
      "epoch:11 step:9036 [D loss: 0.579040, acc: 75.00%] [G loss: 1.582388]\n",
      "epoch:11 step:9037 [D loss: 0.726903, acc: 47.66%] [G loss: 1.499794]\n",
      "epoch:11 step:9038 [D loss: 0.794391, acc: 45.31%] [G loss: 1.556359]\n",
      "epoch:11 step:9039 [D loss: 0.646477, acc: 61.72%] [G loss: 1.716631]\n",
      "epoch:11 step:9040 [D loss: 0.595821, acc: 61.72%] [G loss: 1.908793]\n",
      "epoch:11 step:9041 [D loss: 0.599493, acc: 72.66%] [G loss: 1.560052]\n",
      "epoch:11 step:9042 [D loss: 0.650035, acc: 58.59%] [G loss: 1.808582]\n",
      "epoch:11 step:9043 [D loss: 0.640937, acc: 68.75%] [G loss: 1.886373]\n",
      "epoch:11 step:9044 [D loss: 0.866428, acc: 23.44%] [G loss: 1.529758]\n",
      "epoch:11 step:9045 [D loss: 0.674967, acc: 56.25%] [G loss: 1.758137]\n",
      "epoch:11 step:9046 [D loss: 0.778254, acc: 40.62%] [G loss: 1.505137]\n",
      "epoch:11 step:9047 [D loss: 0.777564, acc: 32.81%] [G loss: 1.670223]\n",
      "epoch:11 step:9048 [D loss: 0.708397, acc: 55.47%] [G loss: 1.584032]\n",
      "epoch:11 step:9049 [D loss: 0.565838, acc: 76.56%] [G loss: 1.789361]\n",
      "epoch:11 step:9050 [D loss: 0.601994, acc: 70.31%] [G loss: 1.861263]\n",
      "epoch:11 step:9051 [D loss: 0.553704, acc: 77.34%] [G loss: 1.806261]\n",
      "epoch:11 step:9052 [D loss: 0.667218, acc: 60.16%] [G loss: 1.761306]\n",
      "epoch:11 step:9053 [D loss: 0.476284, acc: 79.69%] [G loss: 2.091465]\n",
      "epoch:11 step:9054 [D loss: 0.559290, acc: 78.91%] [G loss: 1.765397]\n",
      "epoch:11 step:9055 [D loss: 0.541635, acc: 86.72%] [G loss: 1.680937]\n",
      "epoch:11 step:9056 [D loss: 0.661613, acc: 57.81%] [G loss: 1.630277]\n",
      "epoch:11 step:9057 [D loss: 0.564376, acc: 79.69%] [G loss: 2.105611]\n",
      "epoch:11 step:9058 [D loss: 0.691201, acc: 53.12%] [G loss: 1.672950]\n",
      "epoch:11 step:9059 [D loss: 0.565929, acc: 76.56%] [G loss: 1.545427]\n",
      "epoch:11 step:9060 [D loss: 0.493291, acc: 92.97%] [G loss: 1.744991]\n",
      "epoch:11 step:9061 [D loss: 0.818839, acc: 32.81%] [G loss: 1.417268]\n",
      "epoch:11 step:9062 [D loss: 0.577049, acc: 65.62%] [G loss: 1.543454]\n",
      "epoch:11 step:9063 [D loss: 0.674957, acc: 52.34%] [G loss: 1.600835]\n",
      "epoch:11 step:9064 [D loss: 0.508884, acc: 75.00%] [G loss: 1.896360]\n",
      "epoch:11 step:9065 [D loss: 0.720414, acc: 47.66%] [G loss: 1.338121]\n",
      "epoch:11 step:9066 [D loss: 0.553759, acc: 69.53%] [G loss: 1.714936]\n",
      "epoch:11 step:9067 [D loss: 0.620806, acc: 63.28%] [G loss: 1.801454]\n",
      "epoch:11 step:9068 [D loss: 0.705530, acc: 52.34%] [G loss: 1.434269]\n",
      "epoch:11 step:9069 [D loss: 0.595310, acc: 73.44%] [G loss: 1.865327]\n",
      "epoch:11 step:9070 [D loss: 0.773993, acc: 32.03%] [G loss: 1.595654]\n",
      "epoch:11 step:9071 [D loss: 0.605538, acc: 71.88%] [G loss: 1.706475]\n",
      "epoch:11 step:9072 [D loss: 0.815934, acc: 33.59%] [G loss: 1.468543]\n",
      "epoch:11 step:9073 [D loss: 0.815461, acc: 42.97%] [G loss: 1.562430]\n",
      "epoch:11 step:9074 [D loss: 0.781509, acc: 42.19%] [G loss: 1.760227]\n",
      "epoch:11 step:9075 [D loss: 0.670236, acc: 56.25%] [G loss: 1.579858]\n",
      "epoch:11 step:9076 [D loss: 0.658473, acc: 62.50%] [G loss: 1.448263]\n",
      "epoch:11 step:9077 [D loss: 0.673473, acc: 60.94%] [G loss: 1.689718]\n",
      "epoch:11 step:9078 [D loss: 0.598861, acc: 72.66%] [G loss: 1.721519]\n",
      "epoch:11 step:9079 [D loss: 0.746011, acc: 44.53%] [G loss: 1.430212]\n",
      "epoch:11 step:9080 [D loss: 0.656435, acc: 57.81%] [G loss: 1.158446]\n",
      "epoch:11 step:9081 [D loss: 0.537168, acc: 77.34%] [G loss: 1.829481]\n",
      "epoch:11 step:9082 [D loss: 0.896139, acc: 36.72%] [G loss: 1.353968]\n",
      "epoch:11 step:9083 [D loss: 0.627132, acc: 71.88%] [G loss: 1.608740]\n",
      "epoch:11 step:9084 [D loss: 0.690065, acc: 51.56%] [G loss: 1.754467]\n",
      "epoch:11 step:9085 [D loss: 0.937387, acc: 17.19%] [G loss: 1.224474]\n",
      "epoch:11 step:9086 [D loss: 0.696091, acc: 56.25%] [G loss: 1.492366]\n",
      "epoch:11 step:9087 [D loss: 0.588133, acc: 71.88%] [G loss: 1.839690]\n",
      "epoch:11 step:9088 [D loss: 0.553633, acc: 61.72%] [G loss: 1.763045]\n",
      "epoch:11 step:9089 [D loss: 0.775034, acc: 48.44%] [G loss: 1.823237]\n",
      "epoch:11 step:9090 [D loss: 0.811631, acc: 48.44%] [G loss: 1.731458]\n",
      "epoch:11 step:9091 [D loss: 0.721543, acc: 50.78%] [G loss: 1.326648]\n",
      "epoch:11 step:9092 [D loss: 0.734359, acc: 52.34%] [G loss: 1.498086]\n",
      "epoch:11 step:9093 [D loss: 0.700541, acc: 55.47%] [G loss: 1.638731]\n",
      "epoch:11 step:9094 [D loss: 0.358906, acc: 88.28%] [G loss: 1.815984]\n",
      "epoch:11 step:9095 [D loss: 0.794780, acc: 39.06%] [G loss: 1.617672]\n",
      "epoch:11 step:9096 [D loss: 0.699450, acc: 50.00%] [G loss: 1.839961]\n",
      "epoch:11 step:9097 [D loss: 0.718801, acc: 58.59%] [G loss: 1.742967]\n",
      "epoch:11 step:9098 [D loss: 0.638207, acc: 63.28%] [G loss: 1.668269]\n",
      "epoch:11 step:9099 [D loss: 0.622263, acc: 65.62%] [G loss: 1.629948]\n",
      "epoch:11 step:9100 [D loss: 0.832567, acc: 30.47%] [G loss: 1.426344]\n",
      "epoch:11 step:9101 [D loss: 0.733939, acc: 46.88%] [G loss: 1.567662]\n",
      "epoch:11 step:9102 [D loss: 0.583642, acc: 78.91%] [G loss: 1.492749]\n",
      "epoch:11 step:9103 [D loss: 0.741256, acc: 44.53%] [G loss: 1.582531]\n",
      "epoch:11 step:9104 [D loss: 0.811827, acc: 31.25%] [G loss: 1.401408]\n",
      "epoch:11 step:9105 [D loss: 0.773420, acc: 42.19%] [G loss: 1.704988]\n",
      "epoch:11 step:9106 [D loss: 0.592101, acc: 73.44%] [G loss: 1.530265]\n",
      "epoch:11 step:9107 [D loss: 0.736660, acc: 49.22%] [G loss: 1.619086]\n",
      "epoch:11 step:9108 [D loss: 0.727954, acc: 47.66%] [G loss: 1.773468]\n",
      "epoch:11 step:9109 [D loss: 0.565144, acc: 76.56%] [G loss: 1.688296]\n",
      "epoch:11 step:9110 [D loss: 0.887573, acc: 30.47%] [G loss: 1.305539]\n",
      "epoch:11 step:9111 [D loss: 0.575326, acc: 79.69%] [G loss: 1.854797]\n",
      "epoch:11 step:9112 [D loss: 0.646112, acc: 64.06%] [G loss: 1.657767]\n",
      "epoch:11 step:9113 [D loss: 0.719245, acc: 46.88%] [G loss: 1.576866]\n",
      "epoch:11 step:9114 [D loss: 0.673343, acc: 54.69%] [G loss: 1.525342]\n",
      "epoch:11 step:9115 [D loss: 0.711897, acc: 55.47%] [G loss: 1.553538]\n",
      "epoch:11 step:9116 [D loss: 0.610025, acc: 67.19%] [G loss: 1.709266]\n",
      "epoch:11 step:9117 [D loss: 0.896791, acc: 26.56%] [G loss: 1.737988]\n",
      "epoch:11 step:9118 [D loss: 0.540918, acc: 78.12%] [G loss: 1.665805]\n",
      "epoch:11 step:9119 [D loss: 0.784062, acc: 39.06%] [G loss: 1.454091]\n",
      "epoch:11 step:9120 [D loss: 0.719404, acc: 52.34%] [G loss: 1.554577]\n",
      "epoch:11 step:9121 [D loss: 0.818687, acc: 30.47%] [G loss: 1.600398]\n",
      "epoch:11 step:9122 [D loss: 0.620793, acc: 57.81%] [G loss: 1.415272]\n",
      "epoch:11 step:9123 [D loss: 0.576729, acc: 76.56%] [G loss: 1.527001]\n",
      "epoch:11 step:9124 [D loss: 0.853359, acc: 25.78%] [G loss: 1.338146]\n",
      "epoch:11 step:9125 [D loss: 0.745636, acc: 52.34%] [G loss: 1.578575]\n",
      "epoch:11 step:9126 [D loss: 0.618805, acc: 70.31%] [G loss: 1.607897]\n",
      "epoch:11 step:9127 [D loss: 0.605486, acc: 71.88%] [G loss: 1.666965]\n",
      "epoch:11 step:9128 [D loss: 0.690121, acc: 50.00%] [G loss: 1.696234]\n",
      "epoch:11 step:9129 [D loss: 0.784018, acc: 37.50%] [G loss: 1.562706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9130 [D loss: 0.780183, acc: 36.72%] [G loss: 1.431232]\n",
      "epoch:11 step:9131 [D loss: 0.711015, acc: 47.66%] [G loss: 1.639068]\n",
      "epoch:11 step:9132 [D loss: 0.630983, acc: 64.84%] [G loss: 1.775445]\n",
      "epoch:11 step:9133 [D loss: 0.589999, acc: 63.28%] [G loss: 1.755501]\n",
      "epoch:11 step:9134 [D loss: 0.611146, acc: 71.09%] [G loss: 1.587349]\n",
      "epoch:11 step:9135 [D loss: 0.717819, acc: 52.34%] [G loss: 1.513010]\n",
      "epoch:11 step:9136 [D loss: 0.787493, acc: 45.31%] [G loss: 1.535206]\n",
      "epoch:11 step:9137 [D loss: 0.723376, acc: 54.69%] [G loss: 1.565564]\n",
      "epoch:11 step:9138 [D loss: 0.557901, acc: 76.56%] [G loss: 1.433669]\n",
      "epoch:11 step:9139 [D loss: 0.585442, acc: 73.44%] [G loss: 1.633942]\n",
      "epoch:11 step:9140 [D loss: 0.570166, acc: 75.78%] [G loss: 1.537278]\n",
      "epoch:11 step:9141 [D loss: 0.652498, acc: 60.94%] [G loss: 1.696148]\n",
      "epoch:11 step:9142 [D loss: 0.641915, acc: 60.16%] [G loss: 1.759291]\n",
      "epoch:11 step:9143 [D loss: 0.805394, acc: 28.12%] [G loss: 1.475943]\n",
      "epoch:11 step:9144 [D loss: 0.810844, acc: 39.84%] [G loss: 1.323624]\n",
      "epoch:11 step:9145 [D loss: 0.777944, acc: 49.22%] [G loss: 1.443319]\n",
      "epoch:11 step:9146 [D loss: 0.802140, acc: 32.03%] [G loss: 1.635258]\n",
      "epoch:11 step:9147 [D loss: 0.728183, acc: 46.09%] [G loss: 1.650883]\n",
      "epoch:11 step:9148 [D loss: 0.530628, acc: 82.81%] [G loss: 1.664830]\n",
      "epoch:11 step:9149 [D loss: 0.693587, acc: 54.69%] [G loss: 1.575259]\n",
      "epoch:11 step:9150 [D loss: 0.533689, acc: 77.34%] [G loss: 1.703120]\n",
      "epoch:11 step:9151 [D loss: 0.751812, acc: 39.84%] [G loss: 1.485700]\n",
      "epoch:11 step:9152 [D loss: 0.676733, acc: 58.59%] [G loss: 1.590251]\n",
      "epoch:11 step:9153 [D loss: 0.758471, acc: 35.94%] [G loss: 1.674765]\n",
      "epoch:11 step:9154 [D loss: 0.942070, acc: 16.41%] [G loss: 1.287658]\n",
      "epoch:11 step:9155 [D loss: 0.706933, acc: 49.22%] [G loss: 1.570816]\n",
      "epoch:11 step:9156 [D loss: 0.687158, acc: 54.69%] [G loss: 1.447871]\n",
      "epoch:11 step:9157 [D loss: 0.684317, acc: 53.91%] [G loss: 1.602575]\n",
      "epoch:11 step:9158 [D loss: 0.693658, acc: 50.78%] [G loss: 1.620018]\n",
      "epoch:11 step:9159 [D loss: 0.584935, acc: 82.03%] [G loss: 1.501887]\n",
      "epoch:11 step:9160 [D loss: 0.792587, acc: 34.38%] [G loss: 1.362484]\n",
      "epoch:11 step:9161 [D loss: 0.650565, acc: 58.59%] [G loss: 1.741106]\n",
      "epoch:11 step:9162 [D loss: 0.684671, acc: 53.91%] [G loss: 1.577457]\n",
      "epoch:11 step:9163 [D loss: 0.615300, acc: 70.31%] [G loss: 1.766157]\n",
      "epoch:11 step:9164 [D loss: 0.695655, acc: 53.91%] [G loss: 1.644763]\n",
      "epoch:11 step:9165 [D loss: 0.873524, acc: 23.44%] [G loss: 1.479349]\n",
      "epoch:11 step:9166 [D loss: 0.787148, acc: 32.81%] [G loss: 1.386282]\n",
      "epoch:11 step:9167 [D loss: 0.543562, acc: 82.03%] [G loss: 1.685443]\n",
      "epoch:11 step:9168 [D loss: 0.691376, acc: 52.34%] [G loss: 1.517244]\n",
      "epoch:11 step:9169 [D loss: 0.668322, acc: 57.03%] [G loss: 1.711464]\n",
      "epoch:11 step:9170 [D loss: 0.691185, acc: 54.69%] [G loss: 1.576019]\n",
      "epoch:11 step:9171 [D loss: 0.646659, acc: 62.50%] [G loss: 1.629362]\n",
      "epoch:11 step:9172 [D loss: 0.640506, acc: 68.75%] [G loss: 1.743743]\n",
      "epoch:11 step:9173 [D loss: 0.557460, acc: 80.47%] [G loss: 1.755753]\n",
      "epoch:11 step:9174 [D loss: 0.741431, acc: 45.31%] [G loss: 1.521221]\n",
      "epoch:11 step:9175 [D loss: 0.794465, acc: 32.81%] [G loss: 1.527522]\n",
      "epoch:11 step:9176 [D loss: 0.688580, acc: 55.47%] [G loss: 1.480821]\n",
      "epoch:11 step:9177 [D loss: 0.669776, acc: 57.81%] [G loss: 1.606519]\n",
      "epoch:11 step:9178 [D loss: 0.610817, acc: 72.66%] [G loss: 1.625734]\n",
      "epoch:11 step:9179 [D loss: 0.581047, acc: 75.78%] [G loss: 1.776996]\n",
      "epoch:11 step:9180 [D loss: 0.678464, acc: 58.59%] [G loss: 1.544165]\n",
      "epoch:11 step:9181 [D loss: 0.659339, acc: 62.50%] [G loss: 1.509579]\n",
      "epoch:11 step:9182 [D loss: 0.705925, acc: 50.78%] [G loss: 1.456600]\n",
      "epoch:11 step:9183 [D loss: 0.723648, acc: 46.88%] [G loss: 1.599544]\n",
      "epoch:11 step:9184 [D loss: 0.649714, acc: 61.72%] [G loss: 1.637934]\n",
      "epoch:11 step:9185 [D loss: 0.643090, acc: 60.94%] [G loss: 1.724886]\n",
      "epoch:11 step:9186 [D loss: 0.655308, acc: 64.06%] [G loss: 1.611783]\n",
      "epoch:11 step:9187 [D loss: 0.866903, acc: 18.75%] [G loss: 1.615402]\n",
      "epoch:11 step:9188 [D loss: 0.688473, acc: 55.47%] [G loss: 1.717495]\n",
      "epoch:11 step:9189 [D loss: 0.734930, acc: 43.75%] [G loss: 1.564298]\n",
      "epoch:11 step:9190 [D loss: 0.727277, acc: 44.53%] [G loss: 1.475223]\n",
      "epoch:11 step:9191 [D loss: 0.669213, acc: 50.78%] [G loss: 1.669660]\n",
      "epoch:11 step:9192 [D loss: 0.742075, acc: 38.28%] [G loss: 1.750496]\n",
      "epoch:11 step:9193 [D loss: 0.733351, acc: 50.00%] [G loss: 1.456860]\n",
      "epoch:11 step:9194 [D loss: 0.720155, acc: 48.44%] [G loss: 1.427262]\n",
      "epoch:11 step:9195 [D loss: 0.783526, acc: 35.94%] [G loss: 1.535689]\n",
      "epoch:11 step:9196 [D loss: 0.694702, acc: 56.25%] [G loss: 1.653127]\n",
      "epoch:11 step:9197 [D loss: 0.657915, acc: 58.59%] [G loss: 1.745584]\n",
      "epoch:11 step:9198 [D loss: 0.668199, acc: 59.38%] [G loss: 1.659367]\n",
      "epoch:11 step:9199 [D loss: 0.716198, acc: 53.12%] [G loss: 1.541903]\n",
      "epoch:11 step:9200 [D loss: 0.646279, acc: 60.94%] [G loss: 1.506555]\n",
      "epoch:11 step:9201 [D loss: 0.765183, acc: 43.75%] [G loss: 1.550763]\n",
      "epoch:11 step:9202 [D loss: 0.522667, acc: 81.25%] [G loss: 1.656383]\n",
      "epoch:11 step:9203 [D loss: 0.528511, acc: 89.84%] [G loss: 1.618347]\n",
      "epoch:11 step:9204 [D loss: 0.905543, acc: 32.03%] [G loss: 1.387550]\n",
      "epoch:11 step:9205 [D loss: 0.679478, acc: 50.78%] [G loss: 1.652385]\n",
      "epoch:11 step:9206 [D loss: 0.656569, acc: 59.38%] [G loss: 1.650301]\n",
      "epoch:11 step:9207 [D loss: 0.642197, acc: 62.50%] [G loss: 1.503200]\n",
      "epoch:11 step:9208 [D loss: 0.720462, acc: 53.91%] [G loss: 1.801836]\n",
      "epoch:11 step:9209 [D loss: 0.736832, acc: 41.41%] [G loss: 1.516935]\n",
      "epoch:11 step:9210 [D loss: 0.853782, acc: 22.66%] [G loss: 1.303614]\n",
      "epoch:11 step:9211 [D loss: 0.758788, acc: 39.84%] [G loss: 1.364891]\n",
      "epoch:11 step:9212 [D loss: 0.689097, acc: 58.59%] [G loss: 1.614583]\n",
      "epoch:11 step:9213 [D loss: 0.681834, acc: 51.56%] [G loss: 1.600480]\n",
      "epoch:11 step:9214 [D loss: 0.817361, acc: 26.56%] [G loss: 1.470152]\n",
      "epoch:11 step:9215 [D loss: 0.664900, acc: 58.59%] [G loss: 1.713219]\n",
      "epoch:11 step:9216 [D loss: 0.643080, acc: 62.50%] [G loss: 1.596512]\n",
      "epoch:11 step:9217 [D loss: 0.554696, acc: 85.16%] [G loss: 1.585511]\n",
      "epoch:11 step:9218 [D loss: 0.713717, acc: 45.31%] [G loss: 1.580385]\n",
      "epoch:11 step:9219 [D loss: 0.747993, acc: 40.62%] [G loss: 1.664731]\n",
      "epoch:11 step:9220 [D loss: 0.715975, acc: 46.09%] [G loss: 1.672068]\n",
      "epoch:11 step:9221 [D loss: 0.734537, acc: 44.53%] [G loss: 1.458391]\n",
      "epoch:11 step:9222 [D loss: 0.643369, acc: 65.62%] [G loss: 1.623084]\n",
      "epoch:11 step:9223 [D loss: 0.762032, acc: 46.09%] [G loss: 1.561362]\n",
      "epoch:11 step:9224 [D loss: 0.700807, acc: 55.47%] [G loss: 1.530955]\n",
      "epoch:11 step:9225 [D loss: 0.820047, acc: 33.59%] [G loss: 1.458893]\n",
      "epoch:11 step:9226 [D loss: 0.716212, acc: 51.56%] [G loss: 1.492342]\n",
      "epoch:11 step:9227 [D loss: 0.645336, acc: 60.94%] [G loss: 1.578397]\n",
      "epoch:11 step:9228 [D loss: 0.885086, acc: 25.00%] [G loss: 1.438760]\n",
      "epoch:11 step:9229 [D loss: 0.784026, acc: 33.59%] [G loss: 1.433432]\n",
      "epoch:11 step:9230 [D loss: 0.731732, acc: 44.53%] [G loss: 1.614078]\n",
      "epoch:11 step:9231 [D loss: 0.719963, acc: 50.00%] [G loss: 1.463584]\n",
      "epoch:11 step:9232 [D loss: 0.615729, acc: 71.09%] [G loss: 1.630979]\n",
      "epoch:11 step:9233 [D loss: 0.843743, acc: 26.56%] [G loss: 1.394161]\n",
      "epoch:11 step:9234 [D loss: 0.749742, acc: 42.97%] [G loss: 1.567066]\n",
      "epoch:11 step:9235 [D loss: 0.596988, acc: 70.31%] [G loss: 1.714034]\n",
      "epoch:11 step:9236 [D loss: 0.816830, acc: 35.16%] [G loss: 1.409774]\n",
      "epoch:11 step:9237 [D loss: 0.653806, acc: 61.72%] [G loss: 1.667127]\n",
      "epoch:11 step:9238 [D loss: 0.762161, acc: 39.06%] [G loss: 1.541594]\n",
      "epoch:11 step:9239 [D loss: 0.797028, acc: 28.91%] [G loss: 1.501280]\n",
      "epoch:11 step:9240 [D loss: 0.710323, acc: 49.22%] [G loss: 1.527043]\n",
      "epoch:11 step:9241 [D loss: 0.831375, acc: 27.34%] [G loss: 1.485576]\n",
      "epoch:11 step:9242 [D loss: 0.665605, acc: 63.28%] [G loss: 1.608204]\n",
      "epoch:11 step:9243 [D loss: 0.641599, acc: 66.41%] [G loss: 1.601118]\n",
      "epoch:11 step:9244 [D loss: 0.723135, acc: 50.00%] [G loss: 1.554301]\n",
      "epoch:11 step:9245 [D loss: 0.667187, acc: 56.25%] [G loss: 1.729644]\n",
      "epoch:11 step:9246 [D loss: 0.720439, acc: 43.75%] [G loss: 1.558312]\n",
      "epoch:11 step:9247 [D loss: 0.820813, acc: 40.62%] [G loss: 1.504907]\n",
      "epoch:11 step:9248 [D loss: 0.628071, acc: 67.19%] [G loss: 1.693046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9249 [D loss: 0.676571, acc: 57.03%] [G loss: 1.573329]\n",
      "epoch:11 step:9250 [D loss: 0.701478, acc: 53.91%] [G loss: 1.680303]\n",
      "epoch:11 step:9251 [D loss: 0.746586, acc: 49.22%] [G loss: 1.442719]\n",
      "epoch:11 step:9252 [D loss: 0.709821, acc: 51.56%] [G loss: 1.447055]\n",
      "epoch:11 step:9253 [D loss: 0.635052, acc: 64.06%] [G loss: 1.831469]\n",
      "epoch:11 step:9254 [D loss: 0.676518, acc: 57.81%] [G loss: 1.547648]\n",
      "epoch:11 step:9255 [D loss: 0.600623, acc: 71.09%] [G loss: 1.763258]\n",
      "epoch:11 step:9256 [D loss: 0.728071, acc: 39.06%] [G loss: 1.441532]\n",
      "epoch:11 step:9257 [D loss: 0.503594, acc: 79.69%] [G loss: 1.795642]\n",
      "epoch:11 step:9258 [D loss: 0.685633, acc: 55.47%] [G loss: 1.610204]\n",
      "epoch:11 step:9259 [D loss: 0.610588, acc: 71.09%] [G loss: 1.587885]\n",
      "epoch:11 step:9260 [D loss: 0.743784, acc: 44.53%] [G loss: 1.619993]\n",
      "epoch:11 step:9261 [D loss: 0.806025, acc: 24.22%] [G loss: 1.337679]\n",
      "epoch:11 step:9262 [D loss: 0.622217, acc: 68.75%] [G loss: 1.686974]\n",
      "epoch:11 step:9263 [D loss: 0.794251, acc: 32.03%] [G loss: 1.404012]\n",
      "epoch:11 step:9264 [D loss: 0.793283, acc: 36.72%] [G loss: 1.418472]\n",
      "epoch:11 step:9265 [D loss: 0.711955, acc: 45.31%] [G loss: 1.631382]\n",
      "epoch:11 step:9266 [D loss: 0.553075, acc: 77.34%] [G loss: 1.857581]\n",
      "epoch:11 step:9267 [D loss: 0.691850, acc: 54.69%] [G loss: 1.764470]\n",
      "epoch:11 step:9268 [D loss: 0.573199, acc: 79.69%] [G loss: 1.714498]\n",
      "epoch:11 step:9269 [D loss: 0.589921, acc: 74.22%] [G loss: 1.807690]\n",
      "epoch:11 step:9270 [D loss: 0.661537, acc: 54.69%] [G loss: 1.493429]\n",
      "epoch:11 step:9271 [D loss: 0.510848, acc: 89.84%] [G loss: 1.916988]\n",
      "epoch:11 step:9272 [D loss: 0.646777, acc: 62.50%] [G loss: 1.744815]\n",
      "epoch:11 step:9273 [D loss: 0.872875, acc: 40.62%] [G loss: 1.348109]\n",
      "epoch:11 step:9274 [D loss: 0.730319, acc: 47.66%] [G loss: 1.495180]\n",
      "epoch:11 step:9275 [D loss: 0.693908, acc: 57.03%] [G loss: 1.494322]\n",
      "epoch:11 step:9276 [D loss: 0.495953, acc: 89.84%] [G loss: 1.655116]\n",
      "epoch:11 step:9277 [D loss: 0.704142, acc: 51.56%] [G loss: 1.603927]\n",
      "epoch:11 step:9278 [D loss: 0.729391, acc: 46.09%] [G loss: 1.647974]\n",
      "epoch:11 step:9279 [D loss: 0.684552, acc: 53.91%] [G loss: 1.458821]\n",
      "epoch:11 step:9280 [D loss: 0.613236, acc: 76.56%] [G loss: 1.590877]\n",
      "epoch:11 step:9281 [D loss: 0.716594, acc: 48.44%] [G loss: 1.610284]\n",
      "epoch:11 step:9282 [D loss: 0.712026, acc: 46.88%] [G loss: 1.613925]\n",
      "epoch:11 step:9283 [D loss: 0.830093, acc: 30.47%] [G loss: 1.444698]\n",
      "epoch:11 step:9284 [D loss: 0.574898, acc: 78.12%] [G loss: 1.786802]\n",
      "epoch:11 step:9285 [D loss: 0.636460, acc: 70.31%] [G loss: 1.510334]\n",
      "epoch:11 step:9286 [D loss: 0.650825, acc: 62.50%] [G loss: 1.515334]\n",
      "epoch:11 step:9287 [D loss: 0.761352, acc: 41.41%] [G loss: 1.531728]\n",
      "epoch:11 step:9288 [D loss: 0.591488, acc: 71.88%] [G loss: 1.614642]\n",
      "epoch:11 step:9289 [D loss: 0.705117, acc: 44.53%] [G loss: 1.503371]\n",
      "epoch:11 step:9290 [D loss: 0.717869, acc: 42.97%] [G loss: 1.417467]\n",
      "epoch:11 step:9291 [D loss: 0.586689, acc: 74.22%] [G loss: 1.585672]\n",
      "epoch:11 step:9292 [D loss: 0.788148, acc: 39.84%] [G loss: 1.553886]\n",
      "epoch:11 step:9293 [D loss: 0.728504, acc: 50.78%] [G loss: 1.713596]\n",
      "epoch:11 step:9294 [D loss: 0.859154, acc: 19.53%] [G loss: 1.600500]\n",
      "epoch:11 step:9295 [D loss: 0.729809, acc: 50.00%] [G loss: 1.411660]\n",
      "epoch:11 step:9296 [D loss: 0.772241, acc: 35.94%] [G loss: 1.571906]\n",
      "epoch:11 step:9297 [D loss: 0.717430, acc: 52.34%] [G loss: 1.466384]\n",
      "epoch:11 step:9298 [D loss: 0.475029, acc: 83.59%] [G loss: 1.635403]\n",
      "epoch:11 step:9299 [D loss: 0.632808, acc: 60.16%] [G loss: 1.532759]\n",
      "epoch:11 step:9300 [D loss: 0.621857, acc: 67.97%] [G loss: 1.620710]\n",
      "epoch:11 step:9301 [D loss: 0.698958, acc: 52.34%] [G loss: 1.407477]\n",
      "epoch:11 step:9302 [D loss: 0.706255, acc: 48.44%] [G loss: 1.657469]\n",
      "epoch:11 step:9303 [D loss: 0.629350, acc: 62.50%] [G loss: 1.770067]\n",
      "epoch:11 step:9304 [D loss: 0.677698, acc: 56.25%] [G loss: 1.738637]\n",
      "epoch:11 step:9305 [D loss: 0.552375, acc: 69.53%] [G loss: 1.519977]\n",
      "epoch:11 step:9306 [D loss: 0.632452, acc: 60.16%] [G loss: 1.368989]\n",
      "epoch:11 step:9307 [D loss: 0.590087, acc: 77.34%] [G loss: 1.790239]\n",
      "epoch:11 step:9308 [D loss: 0.762394, acc: 42.97%] [G loss: 1.582036]\n",
      "epoch:11 step:9309 [D loss: 0.688617, acc: 60.16%] [G loss: 1.764322]\n",
      "epoch:11 step:9310 [D loss: 0.625508, acc: 65.62%] [G loss: 1.402175]\n",
      "epoch:11 step:9311 [D loss: 0.673502, acc: 53.12%] [G loss: 1.705055]\n",
      "epoch:11 step:9312 [D loss: 0.562011, acc: 79.69%] [G loss: 1.667648]\n",
      "epoch:11 step:9313 [D loss: 0.712402, acc: 50.00%] [G loss: 1.648891]\n",
      "epoch:11 step:9314 [D loss: 0.704429, acc: 58.59%] [G loss: 1.685297]\n",
      "epoch:11 step:9315 [D loss: 0.583912, acc: 80.47%] [G loss: 1.790473]\n",
      "epoch:11 step:9316 [D loss: 0.711269, acc: 47.66%] [G loss: 1.559917]\n",
      "epoch:11 step:9317 [D loss: 0.686390, acc: 55.47%] [G loss: 1.514292]\n",
      "epoch:11 step:9318 [D loss: 0.750861, acc: 45.31%] [G loss: 1.602052]\n",
      "epoch:11 step:9319 [D loss: 0.512935, acc: 86.72%] [G loss: 1.693774]\n",
      "epoch:11 step:9320 [D loss: 0.464074, acc: 89.84%] [G loss: 1.491380]\n",
      "epoch:11 step:9321 [D loss: 0.540670, acc: 84.38%] [G loss: 1.905216]\n",
      "epoch:11 step:9322 [D loss: 0.720043, acc: 47.66%] [G loss: 1.754659]\n",
      "epoch:11 step:9323 [D loss: 0.853932, acc: 29.69%] [G loss: 1.526541]\n",
      "epoch:11 step:9324 [D loss: 0.650868, acc: 64.06%] [G loss: 1.558460]\n",
      "epoch:11 step:9325 [D loss: 0.685501, acc: 53.91%] [G loss: 1.505583]\n",
      "epoch:11 step:9326 [D loss: 0.691002, acc: 52.34%] [G loss: 1.735770]\n",
      "epoch:11 step:9327 [D loss: 0.585242, acc: 77.34%] [G loss: 1.668703]\n",
      "epoch:11 step:9328 [D loss: 0.841009, acc: 25.00%] [G loss: 1.483980]\n",
      "epoch:11 step:9329 [D loss: 0.661067, acc: 64.84%] [G loss: 1.797655]\n",
      "epoch:11 step:9330 [D loss: 0.659256, acc: 63.28%] [G loss: 1.756409]\n",
      "epoch:11 step:9331 [D loss: 0.651753, acc: 52.34%] [G loss: 1.409118]\n",
      "epoch:11 step:9332 [D loss: 0.484539, acc: 89.06%] [G loss: 1.857407]\n",
      "epoch:11 step:9333 [D loss: 0.553494, acc: 85.16%] [G loss: 1.669633]\n",
      "epoch:11 step:9334 [D loss: 0.753909, acc: 39.84%] [G loss: 1.662720]\n",
      "epoch:11 step:9335 [D loss: 0.662018, acc: 60.94%] [G loss: 1.660130]\n",
      "epoch:11 step:9336 [D loss: 0.520179, acc: 86.72%] [G loss: 1.812187]\n",
      "epoch:11 step:9337 [D loss: 0.576084, acc: 82.03%] [G loss: 1.604537]\n",
      "epoch:11 step:9338 [D loss: 0.676793, acc: 60.94%] [G loss: 1.780599]\n",
      "epoch:11 step:9339 [D loss: 0.585428, acc: 71.09%] [G loss: 2.016093]\n",
      "epoch:11 step:9340 [D loss: 0.765448, acc: 42.97%] [G loss: 1.638862]\n",
      "epoch:11 step:9341 [D loss: 0.717413, acc: 48.44%] [G loss: 1.680984]\n",
      "epoch:11 step:9342 [D loss: 0.845906, acc: 31.25%] [G loss: 1.330644]\n",
      "epoch:11 step:9343 [D loss: 0.685922, acc: 60.16%] [G loss: 1.755317]\n",
      "epoch:11 step:9344 [D loss: 0.681691, acc: 57.81%] [G loss: 1.562303]\n",
      "epoch:11 step:9345 [D loss: 0.718327, acc: 44.53%] [G loss: 1.552942]\n",
      "epoch:11 step:9346 [D loss: 0.672671, acc: 52.34%] [G loss: 1.439844]\n",
      "epoch:11 step:9347 [D loss: 0.673431, acc: 60.16%] [G loss: 1.391204]\n",
      "epoch:11 step:9348 [D loss: 0.777479, acc: 38.28%] [G loss: 1.508795]\n",
      "epoch:11 step:9349 [D loss: 0.595825, acc: 72.66%] [G loss: 1.578877]\n",
      "epoch:11 step:9350 [D loss: 0.710021, acc: 46.09%] [G loss: 1.523501]\n",
      "epoch:11 step:9351 [D loss: 0.614791, acc: 70.31%] [G loss: 1.848564]\n",
      "epoch:11 step:9352 [D loss: 0.680063, acc: 57.03%] [G loss: 1.615339]\n",
      "epoch:11 step:9353 [D loss: 0.594180, acc: 78.12%] [G loss: 1.687097]\n",
      "epoch:11 step:9354 [D loss: 0.672030, acc: 58.59%] [G loss: 1.577770]\n",
      "epoch:11 step:9355 [D loss: 0.737641, acc: 44.53%] [G loss: 1.499656]\n",
      "epoch:11 step:9356 [D loss: 0.690671, acc: 57.03%] [G loss: 1.611865]\n",
      "epoch:11 step:9357 [D loss: 0.574707, acc: 76.56%] [G loss: 1.661084]\n",
      "epoch:11 step:9358 [D loss: 0.512620, acc: 81.25%] [G loss: 1.889408]\n",
      "epoch:11 step:9359 [D loss: 0.508469, acc: 89.84%] [G loss: 1.903709]\n",
      "epoch:11 step:9360 [D loss: 0.892536, acc: 21.88%] [G loss: 1.391294]\n",
      "epoch:11 step:9361 [D loss: 0.712779, acc: 51.56%] [G loss: 1.577441]\n",
      "epoch:11 step:9362 [D loss: 0.996504, acc: 12.50%] [G loss: 1.536641]\n",
      "epoch:11 step:9363 [D loss: 0.689659, acc: 55.47%] [G loss: 1.674631]\n",
      "epoch:11 step:9364 [D loss: 0.630417, acc: 65.62%] [G loss: 1.778075]\n",
      "epoch:11 step:9365 [D loss: 0.631243, acc: 69.53%] [G loss: 1.630390]\n",
      "epoch:11 step:9366 [D loss: 0.825919, acc: 24.22%] [G loss: 1.589964]\n",
      "epoch:11 step:9367 [D loss: 0.737838, acc: 43.75%] [G loss: 1.504967]\n",
      "epoch:11 step:9368 [D loss: 0.660088, acc: 63.28%] [G loss: 1.415872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9369 [D loss: 0.823306, acc: 27.34%] [G loss: 1.512415]\n",
      "epoch:11 step:9370 [D loss: 0.786123, acc: 39.84%] [G loss: 1.396461]\n",
      "epoch:11 step:9371 [D loss: 1.095876, acc: 5.47%] [G loss: 1.099332]\n",
      "epoch:11 step:9372 [D loss: 0.715185, acc: 53.91%] [G loss: 1.638339]\n",
      "epoch:12 step:9373 [D loss: 0.654451, acc: 55.47%] [G loss: 1.540804]\n",
      "epoch:12 step:9374 [D loss: 0.576850, acc: 76.56%] [G loss: 2.029233]\n",
      "epoch:12 step:9375 [D loss: 0.625177, acc: 71.88%] [G loss: 1.707517]\n",
      "epoch:12 step:9376 [D loss: 0.615957, acc: 61.72%] [G loss: 1.686042]\n",
      "epoch:12 step:9377 [D loss: 0.569516, acc: 77.34%] [G loss: 1.645710]\n",
      "epoch:12 step:9378 [D loss: 0.717062, acc: 48.44%] [G loss: 1.657253]\n",
      "epoch:12 step:9379 [D loss: 0.572372, acc: 82.03%] [G loss: 1.803402]\n",
      "epoch:12 step:9380 [D loss: 0.664189, acc: 60.16%] [G loss: 1.390721]\n",
      "epoch:12 step:9381 [D loss: 0.681648, acc: 56.25%] [G loss: 1.586300]\n",
      "epoch:12 step:9382 [D loss: 0.586016, acc: 78.91%] [G loss: 1.627789]\n",
      "epoch:12 step:9383 [D loss: 0.631990, acc: 65.62%] [G loss: 1.853619]\n",
      "epoch:12 step:9384 [D loss: 0.712641, acc: 46.09%] [G loss: 1.653267]\n",
      "epoch:12 step:9385 [D loss: 0.694153, acc: 50.00%] [G loss: 1.571337]\n",
      "epoch:12 step:9386 [D loss: 0.777227, acc: 42.97%] [G loss: 1.596717]\n",
      "epoch:12 step:9387 [D loss: 0.537155, acc: 71.88%] [G loss: 1.603101]\n",
      "epoch:12 step:9388 [D loss: 0.480936, acc: 86.72%] [G loss: 1.669642]\n",
      "epoch:12 step:9389 [D loss: 0.451285, acc: 90.62%] [G loss: 2.011863]\n",
      "epoch:12 step:9390 [D loss: 0.691618, acc: 58.59%] [G loss: 1.806801]\n",
      "epoch:12 step:9391 [D loss: 0.590233, acc: 76.56%] [G loss: 1.694685]\n",
      "epoch:12 step:9392 [D loss: 0.662207, acc: 64.06%] [G loss: 1.614083]\n",
      "epoch:12 step:9393 [D loss: 0.435408, acc: 76.56%] [G loss: 1.773553]\n",
      "epoch:12 step:9394 [D loss: 0.647870, acc: 62.50%] [G loss: 1.611229]\n",
      "epoch:12 step:9395 [D loss: 0.521416, acc: 67.19%] [G loss: 1.410709]\n",
      "epoch:12 step:9396 [D loss: 0.708000, acc: 53.91%] [G loss: 1.525790]\n",
      "epoch:12 step:9397 [D loss: 0.738764, acc: 55.47%] [G loss: 1.678949]\n",
      "epoch:12 step:9398 [D loss: 0.487772, acc: 91.41%] [G loss: 1.622465]\n",
      "epoch:12 step:9399 [D loss: 0.671994, acc: 56.25%] [G loss: 1.539460]\n",
      "epoch:12 step:9400 [D loss: 0.441910, acc: 95.31%] [G loss: 1.813100]\n",
      "epoch:12 step:9401 [D loss: 0.854439, acc: 32.03%] [G loss: 1.588299]\n",
      "epoch:12 step:9402 [D loss: 0.537726, acc: 82.81%] [G loss: 1.581883]\n",
      "epoch:12 step:9403 [D loss: 0.586485, acc: 64.84%] [G loss: 1.452785]\n",
      "epoch:12 step:9404 [D loss: 0.754470, acc: 49.22%] [G loss: 1.561773]\n",
      "epoch:12 step:9405 [D loss: 0.639600, acc: 63.28%] [G loss: 1.779092]\n",
      "epoch:12 step:9406 [D loss: 0.540383, acc: 80.47%] [G loss: 1.746737]\n",
      "epoch:12 step:9407 [D loss: 0.980269, acc: 22.66%] [G loss: 1.321250]\n",
      "epoch:12 step:9408 [D loss: 0.716234, acc: 49.22%] [G loss: 1.500879]\n",
      "epoch:12 step:9409 [D loss: 0.661158, acc: 65.62%] [G loss: 1.531691]\n",
      "epoch:12 step:9410 [D loss: 0.672775, acc: 55.47%] [G loss: 1.594730]\n",
      "epoch:12 step:9411 [D loss: 0.467148, acc: 82.03%] [G loss: 1.751530]\n",
      "epoch:12 step:9412 [D loss: 0.472354, acc: 92.19%] [G loss: 1.848645]\n",
      "epoch:12 step:9413 [D loss: 0.654356, acc: 60.16%] [G loss: 1.921834]\n",
      "epoch:12 step:9414 [D loss: 0.651416, acc: 63.28%] [G loss: 1.915786]\n",
      "epoch:12 step:9415 [D loss: 0.797861, acc: 34.38%] [G loss: 1.637806]\n",
      "epoch:12 step:9416 [D loss: 0.908089, acc: 17.19%] [G loss: 1.277901]\n",
      "epoch:12 step:9417 [D loss: 0.689486, acc: 53.91%] [G loss: 1.754667]\n",
      "epoch:12 step:9418 [D loss: 0.690515, acc: 60.16%] [G loss: 1.602487]\n",
      "epoch:12 step:9419 [D loss: 0.726432, acc: 48.44%] [G loss: 1.674573]\n",
      "epoch:12 step:9420 [D loss: 0.778132, acc: 39.84%] [G loss: 1.595778]\n",
      "epoch:12 step:9421 [D loss: 0.810088, acc: 38.28%] [G loss: 1.760427]\n",
      "epoch:12 step:9422 [D loss: 0.846970, acc: 25.78%] [G loss: 1.669368]\n",
      "epoch:12 step:9423 [D loss: 0.567418, acc: 76.56%] [G loss: 1.609517]\n",
      "epoch:12 step:9424 [D loss: 0.572539, acc: 77.34%] [G loss: 1.755939]\n",
      "epoch:12 step:9425 [D loss: 0.488368, acc: 87.50%] [G loss: 1.749379]\n",
      "epoch:12 step:9426 [D loss: 0.760519, acc: 48.44%] [G loss: 1.526648]\n",
      "epoch:12 step:9427 [D loss: 0.823505, acc: 35.94%] [G loss: 1.329438]\n",
      "epoch:12 step:9428 [D loss: 0.956425, acc: 10.94%] [G loss: 1.532647]\n",
      "epoch:12 step:9429 [D loss: 0.802711, acc: 42.19%] [G loss: 1.351935]\n",
      "epoch:12 step:9430 [D loss: 0.485704, acc: 92.19%] [G loss: 1.488725]\n",
      "epoch:12 step:9431 [D loss: 0.528565, acc: 85.16%] [G loss: 1.766841]\n",
      "epoch:12 step:9432 [D loss: 0.554817, acc: 77.34%] [G loss: 1.741085]\n",
      "epoch:12 step:9433 [D loss: 0.671093, acc: 54.69%] [G loss: 1.507530]\n",
      "epoch:12 step:9434 [D loss: 0.717329, acc: 49.22%] [G loss: 1.414993]\n",
      "epoch:12 step:9435 [D loss: 0.553095, acc: 78.91%] [G loss: 1.545614]\n",
      "epoch:12 step:9436 [D loss: 0.641965, acc: 60.16%] [G loss: 1.644948]\n",
      "epoch:12 step:9437 [D loss: 0.682749, acc: 54.69%] [G loss: 1.679649]\n",
      "epoch:12 step:9438 [D loss: 0.668833, acc: 64.84%] [G loss: 1.628840]\n",
      "epoch:12 step:9439 [D loss: 0.912648, acc: 40.62%] [G loss: 1.585742]\n",
      "epoch:12 step:9440 [D loss: 0.467117, acc: 83.59%] [G loss: 1.692053]\n",
      "epoch:12 step:9441 [D loss: 0.375824, acc: 95.31%] [G loss: 1.789846]\n",
      "epoch:12 step:9442 [D loss: 0.691887, acc: 57.81%] [G loss: 1.513329]\n",
      "epoch:12 step:9443 [D loss: 0.995126, acc: 10.16%] [G loss: 1.293483]\n",
      "epoch:12 step:9444 [D loss: 0.669633, acc: 57.03%] [G loss: 1.244924]\n",
      "epoch:12 step:9445 [D loss: 0.508109, acc: 82.03%] [G loss: 1.707474]\n",
      "epoch:12 step:9446 [D loss: 0.542765, acc: 82.03%] [G loss: 1.717870]\n",
      "epoch:12 step:9447 [D loss: 0.839859, acc: 33.59%] [G loss: 1.546982]\n",
      "epoch:12 step:9448 [D loss: 0.906724, acc: 21.88%] [G loss: 1.395416]\n",
      "epoch:12 step:9449 [D loss: 0.656796, acc: 62.50%] [G loss: 1.725827]\n",
      "epoch:12 step:9450 [D loss: 0.750031, acc: 44.53%] [G loss: 1.525518]\n",
      "epoch:12 step:9451 [D loss: 0.492984, acc: 92.97%] [G loss: 1.678575]\n",
      "epoch:12 step:9452 [D loss: 0.535375, acc: 84.38%] [G loss: 1.756581]\n",
      "epoch:12 step:9453 [D loss: 0.634477, acc: 65.62%] [G loss: 1.467195]\n",
      "epoch:12 step:9454 [D loss: 0.791849, acc: 36.72%] [G loss: 1.575083]\n",
      "epoch:12 step:9455 [D loss: 0.523232, acc: 83.59%] [G loss: 1.704175]\n",
      "epoch:12 step:9456 [D loss: 0.839949, acc: 38.28%] [G loss: 1.259674]\n",
      "epoch:12 step:9457 [D loss: 0.471953, acc: 83.59%] [G loss: 1.599395]\n",
      "epoch:12 step:9458 [D loss: 0.693986, acc: 50.00%] [G loss: 1.860820]\n",
      "epoch:12 step:9459 [D loss: 0.677804, acc: 55.47%] [G loss: 1.757557]\n",
      "epoch:12 step:9460 [D loss: 0.687967, acc: 52.34%] [G loss: 1.456250]\n",
      "epoch:12 step:9461 [D loss: 0.577240, acc: 75.78%] [G loss: 1.510967]\n",
      "epoch:12 step:9462 [D loss: 0.726778, acc: 48.44%] [G loss: 1.573575]\n",
      "epoch:12 step:9463 [D loss: 0.782230, acc: 41.41%] [G loss: 1.621668]\n",
      "epoch:12 step:9464 [D loss: 0.774567, acc: 35.16%] [G loss: 1.761274]\n",
      "epoch:12 step:9465 [D loss: 0.786243, acc: 35.94%] [G loss: 1.556716]\n",
      "epoch:12 step:9466 [D loss: 0.576890, acc: 77.34%] [G loss: 1.728042]\n",
      "epoch:12 step:9467 [D loss: 0.652641, acc: 64.06%] [G loss: 1.612544]\n",
      "epoch:12 step:9468 [D loss: 0.775496, acc: 31.25%] [G loss: 1.523961]\n",
      "epoch:12 step:9469 [D loss: 0.733270, acc: 42.19%] [G loss: 1.548260]\n",
      "epoch:12 step:9470 [D loss: 0.747315, acc: 50.00%] [G loss: 1.671343]\n",
      "epoch:12 step:9471 [D loss: 0.450223, acc: 82.03%] [G loss: 1.824855]\n",
      "epoch:12 step:9472 [D loss: 0.628920, acc: 68.75%] [G loss: 1.926256]\n",
      "epoch:12 step:9473 [D loss: 0.711938, acc: 53.12%] [G loss: 1.583991]\n",
      "epoch:12 step:9474 [D loss: 0.644163, acc: 66.41%] [G loss: 1.713453]\n",
      "epoch:12 step:9475 [D loss: 0.663524, acc: 61.72%] [G loss: 1.684486]\n",
      "epoch:12 step:9476 [D loss: 0.673812, acc: 60.16%] [G loss: 1.622943]\n",
      "epoch:12 step:9477 [D loss: 0.618716, acc: 67.97%] [G loss: 1.570913]\n",
      "epoch:12 step:9478 [D loss: 0.469813, acc: 86.72%] [G loss: 1.665028]\n",
      "epoch:12 step:9479 [D loss: 0.713098, acc: 51.56%] [G loss: 1.503141]\n",
      "epoch:12 step:9480 [D loss: 0.723089, acc: 54.69%] [G loss: 1.679128]\n",
      "epoch:12 step:9481 [D loss: 0.691852, acc: 50.78%] [G loss: 1.618798]\n",
      "epoch:12 step:9482 [D loss: 0.818247, acc: 35.16%] [G loss: 1.511346]\n",
      "epoch:12 step:9483 [D loss: 0.720790, acc: 47.66%] [G loss: 1.331102]\n",
      "epoch:12 step:9484 [D loss: 0.576189, acc: 76.56%] [G loss: 1.424667]\n",
      "epoch:12 step:9485 [D loss: 0.660817, acc: 59.38%] [G loss: 1.562118]\n",
      "epoch:12 step:9486 [D loss: 0.439241, acc: 86.72%] [G loss: 2.087446]\n",
      "epoch:12 step:9487 [D loss: 0.839860, acc: 30.47%] [G loss: 1.487064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9488 [D loss: 0.640622, acc: 66.41%] [G loss: 1.531872]\n",
      "epoch:12 step:9489 [D loss: 0.503284, acc: 89.06%] [G loss: 1.793820]\n",
      "epoch:12 step:9490 [D loss: 0.533136, acc: 85.16%] [G loss: 1.745498]\n",
      "epoch:12 step:9491 [D loss: 0.763856, acc: 48.44%] [G loss: 1.557760]\n",
      "epoch:12 step:9492 [D loss: 0.434049, acc: 88.28%] [G loss: 1.919721]\n",
      "epoch:12 step:9493 [D loss: 0.501876, acc: 83.59%] [G loss: 2.112086]\n",
      "epoch:12 step:9494 [D loss: 0.486270, acc: 77.34%] [G loss: 2.051224]\n",
      "epoch:12 step:9495 [D loss: 0.700262, acc: 52.34%] [G loss: 1.687195]\n",
      "epoch:12 step:9496 [D loss: 0.661462, acc: 60.16%] [G loss: 1.690251]\n",
      "epoch:12 step:9497 [D loss: 0.699733, acc: 53.91%] [G loss: 1.571569]\n",
      "epoch:12 step:9498 [D loss: 0.750059, acc: 42.97%] [G loss: 1.567252]\n",
      "epoch:12 step:9499 [D loss: 0.752458, acc: 43.75%] [G loss: 1.556756]\n",
      "epoch:12 step:9500 [D loss: 0.589761, acc: 67.97%] [G loss: 1.938992]\n",
      "epoch:12 step:9501 [D loss: 0.463192, acc: 89.06%] [G loss: 1.901878]\n",
      "epoch:12 step:9502 [D loss: 0.738073, acc: 45.31%] [G loss: 1.599134]\n",
      "epoch:12 step:9503 [D loss: 0.740712, acc: 46.88%] [G loss: 1.775629]\n",
      "epoch:12 step:9504 [D loss: 0.754618, acc: 44.53%] [G loss: 1.503404]\n",
      "epoch:12 step:9505 [D loss: 0.589946, acc: 74.22%] [G loss: 1.724744]\n",
      "epoch:12 step:9506 [D loss: 0.786300, acc: 36.72%] [G loss: 1.580521]\n",
      "epoch:12 step:9507 [D loss: 0.704856, acc: 48.44%] [G loss: 1.841339]\n",
      "epoch:12 step:9508 [D loss: 0.508650, acc: 89.84%] [G loss: 1.717308]\n",
      "epoch:12 step:9509 [D loss: 0.626549, acc: 64.84%] [G loss: 1.727998]\n",
      "epoch:12 step:9510 [D loss: 0.592476, acc: 77.34%] [G loss: 1.589188]\n",
      "epoch:12 step:9511 [D loss: 0.586346, acc: 74.22%] [G loss: 1.586509]\n",
      "epoch:12 step:9512 [D loss: 0.669150, acc: 56.25%] [G loss: 1.698989]\n",
      "epoch:12 step:9513 [D loss: 0.734097, acc: 50.78%] [G loss: 1.831697]\n",
      "epoch:12 step:9514 [D loss: 0.543149, acc: 76.56%] [G loss: 1.973473]\n",
      "epoch:12 step:9515 [D loss: 0.785842, acc: 35.94%] [G loss: 1.546648]\n",
      "epoch:12 step:9516 [D loss: 0.705919, acc: 53.12%] [G loss: 1.754893]\n",
      "epoch:12 step:9517 [D loss: 0.679322, acc: 58.59%] [G loss: 1.533636]\n",
      "epoch:12 step:9518 [D loss: 0.607509, acc: 68.75%] [G loss: 1.730457]\n",
      "epoch:12 step:9519 [D loss: 0.555479, acc: 75.78%] [G loss: 2.151294]\n",
      "epoch:12 step:9520 [D loss: 0.597905, acc: 74.22%] [G loss: 2.182574]\n",
      "epoch:12 step:9521 [D loss: 0.567891, acc: 65.62%] [G loss: 1.650801]\n",
      "epoch:12 step:9522 [D loss: 0.859821, acc: 31.25%] [G loss: 1.495076]\n",
      "epoch:12 step:9523 [D loss: 0.663914, acc: 57.03%] [G loss: 1.628120]\n",
      "epoch:12 step:9524 [D loss: 0.835228, acc: 25.78%] [G loss: 1.492554]\n",
      "epoch:12 step:9525 [D loss: 0.589048, acc: 75.78%] [G loss: 1.823918]\n",
      "epoch:12 step:9526 [D loss: 0.741559, acc: 53.12%] [G loss: 1.811693]\n",
      "epoch:12 step:9527 [D loss: 0.769216, acc: 44.53%] [G loss: 1.312281]\n",
      "epoch:12 step:9528 [D loss: 0.662022, acc: 57.03%] [G loss: 1.779295]\n",
      "epoch:12 step:9529 [D loss: 0.407755, acc: 82.81%] [G loss: 1.814831]\n",
      "epoch:12 step:9530 [D loss: 0.820152, acc: 37.50%] [G loss: 1.590287]\n",
      "epoch:12 step:9531 [D loss: 0.615319, acc: 67.19%] [G loss: 1.862238]\n",
      "epoch:12 step:9532 [D loss: 1.015005, acc: 14.84%] [G loss: 1.544218]\n",
      "epoch:12 step:9533 [D loss: 0.563280, acc: 81.25%] [G loss: 1.659033]\n",
      "epoch:12 step:9534 [D loss: 0.693482, acc: 54.69%] [G loss: 1.776521]\n",
      "epoch:12 step:9535 [D loss: 0.546428, acc: 77.34%] [G loss: 1.619178]\n",
      "epoch:12 step:9536 [D loss: 0.657405, acc: 60.94%] [G loss: 1.771968]\n",
      "epoch:12 step:9537 [D loss: 0.682406, acc: 54.69%] [G loss: 1.544757]\n",
      "epoch:12 step:9538 [D loss: 0.924792, acc: 24.22%] [G loss: 1.333718]\n",
      "epoch:12 step:9539 [D loss: 0.653622, acc: 55.47%] [G loss: 1.841285]\n",
      "epoch:12 step:9540 [D loss: 0.645904, acc: 63.28%] [G loss: 1.906876]\n",
      "epoch:12 step:9541 [D loss: 0.725919, acc: 47.66%] [G loss: 1.498918]\n",
      "epoch:12 step:9542 [D loss: 0.603655, acc: 74.22%] [G loss: 1.858107]\n",
      "epoch:12 step:9543 [D loss: 0.810810, acc: 35.16%] [G loss: 1.700316]\n",
      "epoch:12 step:9544 [D loss: 0.829620, acc: 28.91%] [G loss: 1.567707]\n",
      "epoch:12 step:9545 [D loss: 1.033727, acc: 7.81%] [G loss: 1.244143]\n",
      "epoch:12 step:9546 [D loss: 0.725222, acc: 46.88%] [G loss: 1.589931]\n",
      "epoch:12 step:9547 [D loss: 0.654763, acc: 64.06%] [G loss: 1.606253]\n",
      "epoch:12 step:9548 [D loss: 0.610532, acc: 64.84%] [G loss: 1.822653]\n",
      "epoch:12 step:9549 [D loss: 0.789095, acc: 26.56%] [G loss: 1.474921]\n",
      "epoch:12 step:9550 [D loss: 0.644640, acc: 67.19%] [G loss: 1.558239]\n",
      "epoch:12 step:9551 [D loss: 0.792757, acc: 36.72%] [G loss: 1.560791]\n",
      "epoch:12 step:9552 [D loss: 0.756224, acc: 45.31%] [G loss: 1.599164]\n",
      "epoch:12 step:9553 [D loss: 0.708268, acc: 59.38%] [G loss: 1.537145]\n",
      "epoch:12 step:9554 [D loss: 0.744838, acc: 40.62%] [G loss: 1.685304]\n",
      "epoch:12 step:9555 [D loss: 0.649390, acc: 63.28%] [G loss: 1.633511]\n",
      "epoch:12 step:9556 [D loss: 0.528550, acc: 62.50%] [G loss: 1.859274]\n",
      "epoch:12 step:9557 [D loss: 0.458342, acc: 85.94%] [G loss: 1.515441]\n",
      "epoch:12 step:9558 [D loss: 0.692336, acc: 48.44%] [G loss: 1.684727]\n",
      "epoch:12 step:9559 [D loss: 0.677010, acc: 59.38%] [G loss: 1.680338]\n",
      "epoch:12 step:9560 [D loss: 0.549904, acc: 82.81%] [G loss: 1.570552]\n",
      "epoch:12 step:9561 [D loss: 0.676905, acc: 51.56%] [G loss: 1.734815]\n",
      "epoch:12 step:9562 [D loss: 0.633916, acc: 64.06%] [G loss: 1.475304]\n",
      "epoch:12 step:9563 [D loss: 0.642949, acc: 67.19%] [G loss: 1.566859]\n",
      "epoch:12 step:9564 [D loss: 0.630888, acc: 67.19%] [G loss: 1.704759]\n",
      "epoch:12 step:9565 [D loss: 0.778417, acc: 36.72%] [G loss: 1.413670]\n",
      "epoch:12 step:9566 [D loss: 0.701237, acc: 58.59%] [G loss: 1.836469]\n",
      "epoch:12 step:9567 [D loss: 0.867915, acc: 25.78%] [G loss: 1.403933]\n",
      "epoch:12 step:9568 [D loss: 0.724573, acc: 51.56%] [G loss: 1.468104]\n",
      "epoch:12 step:9569 [D loss: 0.705029, acc: 48.44%] [G loss: 1.435524]\n",
      "epoch:12 step:9570 [D loss: 0.853266, acc: 22.66%] [G loss: 1.320539]\n",
      "epoch:12 step:9571 [D loss: 0.770328, acc: 37.50%] [G loss: 1.485412]\n",
      "epoch:12 step:9572 [D loss: 0.647210, acc: 61.72%] [G loss: 1.642986]\n",
      "epoch:12 step:9573 [D loss: 0.552176, acc: 81.25%] [G loss: 1.648597]\n",
      "epoch:12 step:9574 [D loss: 0.631983, acc: 62.50%] [G loss: 1.457195]\n",
      "epoch:12 step:9575 [D loss: 0.667467, acc: 55.47%] [G loss: 1.486494]\n",
      "epoch:12 step:9576 [D loss: 0.770801, acc: 43.75%] [G loss: 1.450643]\n",
      "epoch:12 step:9577 [D loss: 0.800344, acc: 50.00%] [G loss: 1.307993]\n",
      "epoch:12 step:9578 [D loss: 0.684388, acc: 57.03%] [G loss: 1.463563]\n",
      "epoch:12 step:9579 [D loss: 0.619037, acc: 72.66%] [G loss: 1.692343]\n",
      "epoch:12 step:9580 [D loss: 0.633632, acc: 65.62%] [G loss: 1.725305]\n",
      "epoch:12 step:9581 [D loss: 0.656959, acc: 64.06%] [G loss: 1.432770]\n",
      "epoch:12 step:9582 [D loss: 0.699856, acc: 51.56%] [G loss: 1.598542]\n",
      "epoch:12 step:9583 [D loss: 0.685939, acc: 56.25%] [G loss: 1.793595]\n",
      "epoch:12 step:9584 [D loss: 0.725666, acc: 50.00%] [G loss: 1.674777]\n",
      "epoch:12 step:9585 [D loss: 0.616051, acc: 64.84%] [G loss: 1.560775]\n",
      "epoch:12 step:9586 [D loss: 0.566267, acc: 76.56%] [G loss: 1.965347]\n",
      "epoch:12 step:9587 [D loss: 0.811772, acc: 25.00%] [G loss: 1.429831]\n",
      "epoch:12 step:9588 [D loss: 0.754596, acc: 42.97%] [G loss: 1.500860]\n",
      "epoch:12 step:9589 [D loss: 0.956733, acc: 12.50%] [G loss: 1.426717]\n",
      "epoch:12 step:9590 [D loss: 0.679309, acc: 54.69%] [G loss: 1.681429]\n",
      "epoch:12 step:9591 [D loss: 0.618800, acc: 71.88%] [G loss: 1.753856]\n",
      "epoch:12 step:9592 [D loss: 0.690821, acc: 58.59%] [G loss: 1.660043]\n",
      "epoch:12 step:9593 [D loss: 0.746608, acc: 38.28%] [G loss: 1.411693]\n",
      "epoch:12 step:9594 [D loss: 0.578327, acc: 74.22%] [G loss: 1.718739]\n",
      "epoch:12 step:9595 [D loss: 0.623519, acc: 65.62%] [G loss: 1.854775]\n",
      "epoch:12 step:9596 [D loss: 0.588053, acc: 76.56%] [G loss: 1.555291]\n",
      "epoch:12 step:9597 [D loss: 0.549822, acc: 83.59%] [G loss: 2.004038]\n",
      "epoch:12 step:9598 [D loss: 0.881180, acc: 22.66%] [G loss: 1.365592]\n",
      "epoch:12 step:9599 [D loss: 0.615875, acc: 68.75%] [G loss: 1.519922]\n",
      "epoch:12 step:9600 [D loss: 0.666688, acc: 57.81%] [G loss: 1.562106]\n",
      "epoch:12 step:9601 [D loss: 0.595246, acc: 75.00%] [G loss: 1.604246]\n",
      "epoch:12 step:9602 [D loss: 0.759736, acc: 41.41%] [G loss: 1.519134]\n",
      "epoch:12 step:9603 [D loss: 0.611100, acc: 65.62%] [G loss: 1.580560]\n",
      "epoch:12 step:9604 [D loss: 0.717753, acc: 54.69%] [G loss: 1.488446]\n",
      "epoch:12 step:9605 [D loss: 0.677336, acc: 58.59%] [G loss: 1.596572]\n",
      "epoch:12 step:9606 [D loss: 0.989229, acc: 19.53%] [G loss: 1.416191]\n",
      "epoch:12 step:9607 [D loss: 0.544159, acc: 82.03%] [G loss: 1.803507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9608 [D loss: 0.658729, acc: 62.50%] [G loss: 1.839171]\n",
      "epoch:12 step:9609 [D loss: 0.610991, acc: 65.62%] [G loss: 1.632024]\n",
      "epoch:12 step:9610 [D loss: 0.705484, acc: 46.88%] [G loss: 1.452458]\n",
      "epoch:12 step:9611 [D loss: 0.631243, acc: 67.19%] [G loss: 1.524012]\n",
      "epoch:12 step:9612 [D loss: 0.794184, acc: 41.41%] [G loss: 1.493047]\n",
      "epoch:12 step:9613 [D loss: 0.470333, acc: 85.16%] [G loss: 1.842574]\n",
      "epoch:12 step:9614 [D loss: 0.619162, acc: 69.53%] [G loss: 1.662298]\n",
      "epoch:12 step:9615 [D loss: 0.722733, acc: 47.66%] [G loss: 1.476784]\n",
      "epoch:12 step:9616 [D loss: 0.462708, acc: 79.69%] [G loss: 1.683550]\n",
      "epoch:12 step:9617 [D loss: 0.762289, acc: 40.62%] [G loss: 1.547152]\n",
      "epoch:12 step:9618 [D loss: 0.642801, acc: 60.94%] [G loss: 1.654867]\n",
      "epoch:12 step:9619 [D loss: 0.504840, acc: 87.50%] [G loss: 1.859201]\n",
      "epoch:12 step:9620 [D loss: 0.837322, acc: 37.50%] [G loss: 1.376778]\n",
      "epoch:12 step:9621 [D loss: 0.732275, acc: 48.44%] [G loss: 1.549900]\n",
      "epoch:12 step:9622 [D loss: 0.603729, acc: 71.09%] [G loss: 1.700618]\n",
      "epoch:12 step:9623 [D loss: 0.581369, acc: 72.66%] [G loss: 1.683330]\n",
      "epoch:12 step:9624 [D loss: 0.748214, acc: 54.69%] [G loss: 1.656456]\n",
      "epoch:12 step:9625 [D loss: 0.786509, acc: 43.75%] [G loss: 1.378175]\n",
      "epoch:12 step:9626 [D loss: 0.948807, acc: 17.97%] [G loss: 1.540348]\n",
      "epoch:12 step:9627 [D loss: 0.713785, acc: 41.41%] [G loss: 1.476844]\n",
      "epoch:12 step:9628 [D loss: 0.728458, acc: 50.78%] [G loss: 1.508932]\n",
      "epoch:12 step:9629 [D loss: 0.650584, acc: 58.59%] [G loss: 1.429159]\n",
      "epoch:12 step:9630 [D loss: 0.757260, acc: 46.88%] [G loss: 1.516679]\n",
      "epoch:12 step:9631 [D loss: 0.705576, acc: 48.44%] [G loss: 1.824337]\n",
      "epoch:12 step:9632 [D loss: 0.664450, acc: 57.03%] [G loss: 1.745666]\n",
      "epoch:12 step:9633 [D loss: 0.566395, acc: 74.22%] [G loss: 1.592272]\n",
      "epoch:12 step:9634 [D loss: 0.574763, acc: 78.12%] [G loss: 1.523326]\n",
      "epoch:12 step:9635 [D loss: 0.777542, acc: 44.53%] [G loss: 1.479115]\n",
      "epoch:12 step:9636 [D loss: 0.660124, acc: 55.47%] [G loss: 1.565506]\n",
      "epoch:12 step:9637 [D loss: 0.765205, acc: 36.72%] [G loss: 1.476283]\n",
      "epoch:12 step:9638 [D loss: 0.516566, acc: 69.53%] [G loss: 1.654402]\n",
      "epoch:12 step:9639 [D loss: 0.759516, acc: 47.66%] [G loss: 1.430824]\n",
      "epoch:12 step:9640 [D loss: 0.692685, acc: 55.47%] [G loss: 1.800519]\n",
      "epoch:12 step:9641 [D loss: 0.547264, acc: 81.25%] [G loss: 1.672732]\n",
      "epoch:12 step:9642 [D loss: 0.917653, acc: 18.75%] [G loss: 1.261779]\n",
      "epoch:12 step:9643 [D loss: 0.677701, acc: 57.81%] [G loss: 1.672846]\n",
      "epoch:12 step:9644 [D loss: 0.628195, acc: 58.59%] [G loss: 1.622792]\n",
      "epoch:12 step:9645 [D loss: 0.722214, acc: 48.44%] [G loss: 1.565629]\n",
      "epoch:12 step:9646 [D loss: 0.471514, acc: 78.91%] [G loss: 1.406230]\n",
      "epoch:12 step:9647 [D loss: 0.479805, acc: 85.94%] [G loss: 1.603808]\n",
      "epoch:12 step:9648 [D loss: 0.646569, acc: 60.94%] [G loss: 1.643696]\n",
      "epoch:12 step:9649 [D loss: 1.290384, acc: 10.94%] [G loss: 1.234794]\n",
      "epoch:12 step:9650 [D loss: 0.624686, acc: 65.62%] [G loss: 1.590666]\n",
      "epoch:12 step:9651 [D loss: 0.490454, acc: 91.41%] [G loss: 1.596459]\n",
      "epoch:12 step:9652 [D loss: 0.582748, acc: 72.66%] [G loss: 1.654995]\n",
      "epoch:12 step:9653 [D loss: 0.614092, acc: 64.84%] [G loss: 1.962345]\n",
      "epoch:12 step:9654 [D loss: 0.919847, acc: 18.75%] [G loss: 1.340140]\n",
      "epoch:12 step:9655 [D loss: 0.634512, acc: 60.16%] [G loss: 1.661641]\n",
      "epoch:12 step:9656 [D loss: 0.678487, acc: 57.03%] [G loss: 1.637068]\n",
      "epoch:12 step:9657 [D loss: 0.447546, acc: 90.62%] [G loss: 1.997094]\n",
      "epoch:12 step:9658 [D loss: 0.806473, acc: 39.06%] [G loss: 1.333152]\n",
      "epoch:12 step:9659 [D loss: 0.726019, acc: 45.31%] [G loss: 1.691649]\n",
      "epoch:12 step:9660 [D loss: 0.902279, acc: 19.53%] [G loss: 1.400715]\n",
      "epoch:12 step:9661 [D loss: 0.870879, acc: 17.19%] [G loss: 1.425532]\n",
      "epoch:12 step:9662 [D loss: 0.564419, acc: 78.91%] [G loss: 1.786608]\n",
      "epoch:12 step:9663 [D loss: 0.670858, acc: 53.91%] [G loss: 1.307395]\n",
      "epoch:12 step:9664 [D loss: 0.853366, acc: 24.22%] [G loss: 1.658436]\n",
      "epoch:12 step:9665 [D loss: 0.699249, acc: 53.91%] [G loss: 1.748050]\n",
      "epoch:12 step:9666 [D loss: 0.737838, acc: 57.81%] [G loss: 1.619977]\n",
      "epoch:12 step:9667 [D loss: 0.604677, acc: 74.22%] [G loss: 1.883484]\n",
      "epoch:12 step:9668 [D loss: 0.594652, acc: 75.78%] [G loss: 1.571153]\n",
      "epoch:12 step:9669 [D loss: 0.684062, acc: 57.03%] [G loss: 1.542237]\n",
      "epoch:12 step:9670 [D loss: 0.713687, acc: 50.00%] [G loss: 1.543724]\n",
      "epoch:12 step:9671 [D loss: 0.705587, acc: 50.00%] [G loss: 1.605479]\n",
      "epoch:12 step:9672 [D loss: 0.606394, acc: 74.22%] [G loss: 1.689661]\n",
      "epoch:12 step:9673 [D loss: 0.696010, acc: 58.59%] [G loss: 1.710451]\n",
      "epoch:12 step:9674 [D loss: 0.664371, acc: 60.16%] [G loss: 1.672951]\n",
      "epoch:12 step:9675 [D loss: 0.737008, acc: 47.66%] [G loss: 1.580832]\n",
      "epoch:12 step:9676 [D loss: 0.682670, acc: 60.16%] [G loss: 1.622501]\n",
      "epoch:12 step:9677 [D loss: 0.608012, acc: 68.75%] [G loss: 1.614502]\n",
      "epoch:12 step:9678 [D loss: 0.549311, acc: 83.59%] [G loss: 1.663613]\n",
      "epoch:12 step:9679 [D loss: 0.814919, acc: 47.66%] [G loss: 1.267864]\n",
      "epoch:12 step:9680 [D loss: 0.712926, acc: 42.19%] [G loss: 1.482623]\n",
      "epoch:12 step:9681 [D loss: 0.562703, acc: 76.56%] [G loss: 1.445894]\n",
      "epoch:12 step:9682 [D loss: 0.544620, acc: 85.94%] [G loss: 1.647832]\n",
      "epoch:12 step:9683 [D loss: 0.629082, acc: 72.66%] [G loss: 1.696611]\n",
      "epoch:12 step:9684 [D loss: 0.706753, acc: 58.59%] [G loss: 1.839176]\n",
      "epoch:12 step:9685 [D loss: 0.435511, acc: 82.81%] [G loss: 1.669853]\n",
      "epoch:12 step:9686 [D loss: 0.707745, acc: 47.66%] [G loss: 1.749069]\n",
      "epoch:12 step:9687 [D loss: 0.602539, acc: 70.31%] [G loss: 1.625901]\n",
      "epoch:12 step:9688 [D loss: 0.484355, acc: 89.84%] [G loss: 1.820265]\n",
      "epoch:12 step:9689 [D loss: 0.772935, acc: 45.31%] [G loss: 1.786702]\n",
      "epoch:12 step:9690 [D loss: 0.457112, acc: 94.53%] [G loss: 1.700036]\n",
      "epoch:12 step:9691 [D loss: 0.678335, acc: 57.81%] [G loss: 1.406050]\n",
      "epoch:12 step:9692 [D loss: 0.798128, acc: 30.47%] [G loss: 1.164323]\n",
      "epoch:12 step:9693 [D loss: 0.667918, acc: 57.81%] [G loss: 1.690715]\n",
      "epoch:12 step:9694 [D loss: 0.560831, acc: 68.75%] [G loss: 1.889063]\n",
      "epoch:12 step:9695 [D loss: 0.662545, acc: 59.38%] [G loss: 1.693079]\n",
      "epoch:12 step:9696 [D loss: 0.608208, acc: 70.31%] [G loss: 1.642244]\n",
      "epoch:12 step:9697 [D loss: 0.688615, acc: 59.38%] [G loss: 1.759527]\n",
      "epoch:12 step:9698 [D loss: 0.586402, acc: 70.31%] [G loss: 1.632628]\n",
      "epoch:12 step:9699 [D loss: 0.577700, acc: 75.00%] [G loss: 1.811661]\n",
      "epoch:12 step:9700 [D loss: 0.542117, acc: 83.59%] [G loss: 2.158890]\n",
      "epoch:12 step:9701 [D loss: 0.681832, acc: 57.03%] [G loss: 1.808546]\n",
      "epoch:12 step:9702 [D loss: 0.762341, acc: 38.28%] [G loss: 1.810117]\n",
      "epoch:12 step:9703 [D loss: 0.821824, acc: 33.59%] [G loss: 1.549669]\n",
      "epoch:12 step:9704 [D loss: 0.629832, acc: 65.62%] [G loss: 1.710569]\n",
      "epoch:12 step:9705 [D loss: 0.632910, acc: 68.75%] [G loss: 1.868670]\n",
      "epoch:12 step:9706 [D loss: 0.665587, acc: 62.50%] [G loss: 1.791245]\n",
      "epoch:12 step:9707 [D loss: 0.733707, acc: 46.09%] [G loss: 1.573613]\n",
      "epoch:12 step:9708 [D loss: 0.805888, acc: 43.75%] [G loss: 1.862337]\n",
      "epoch:12 step:9709 [D loss: 0.765511, acc: 47.66%] [G loss: 1.593592]\n",
      "epoch:12 step:9710 [D loss: 1.127512, acc: 10.94%] [G loss: 1.314283]\n",
      "epoch:12 step:9711 [D loss: 0.750545, acc: 45.31%] [G loss: 1.745106]\n",
      "epoch:12 step:9712 [D loss: 0.709034, acc: 51.56%] [G loss: 1.320329]\n",
      "epoch:12 step:9713 [D loss: 0.761157, acc: 45.31%] [G loss: 1.551756]\n",
      "epoch:12 step:9714 [D loss: 0.688977, acc: 57.03%] [G loss: 1.443423]\n",
      "epoch:12 step:9715 [D loss: 0.664303, acc: 58.59%] [G loss: 1.519583]\n",
      "epoch:12 step:9716 [D loss: 0.688155, acc: 59.38%] [G loss: 1.625180]\n",
      "epoch:12 step:9717 [D loss: 0.523836, acc: 82.81%] [G loss: 1.770952]\n",
      "epoch:12 step:9718 [D loss: 0.765985, acc: 39.84%] [G loss: 1.466659]\n",
      "epoch:12 step:9719 [D loss: 0.711722, acc: 51.56%] [G loss: 1.605420]\n",
      "epoch:12 step:9720 [D loss: 0.557612, acc: 81.25%] [G loss: 1.746531]\n",
      "epoch:12 step:9721 [D loss: 0.710595, acc: 50.78%] [G loss: 1.650655]\n",
      "epoch:12 step:9722 [D loss: 0.796254, acc: 36.72%] [G loss: 1.504552]\n",
      "epoch:12 step:9723 [D loss: 0.802716, acc: 33.59%] [G loss: 1.548023]\n",
      "epoch:12 step:9724 [D loss: 0.753485, acc: 46.88%] [G loss: 1.703665]\n",
      "epoch:12 step:9725 [D loss: 0.658130, acc: 57.81%] [G loss: 1.944534]\n",
      "epoch:12 step:9726 [D loss: 0.678687, acc: 60.94%] [G loss: 1.636955]\n",
      "epoch:12 step:9727 [D loss: 0.663031, acc: 64.06%] [G loss: 1.573666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9728 [D loss: 0.652435, acc: 62.50%] [G loss: 1.399756]\n",
      "epoch:12 step:9729 [D loss: 0.594170, acc: 78.12%] [G loss: 1.643494]\n",
      "epoch:12 step:9730 [D loss: 0.523476, acc: 82.81%] [G loss: 1.606858]\n",
      "epoch:12 step:9731 [D loss: 0.670344, acc: 56.25%] [G loss: 1.389039]\n",
      "epoch:12 step:9732 [D loss: 0.816766, acc: 25.00%] [G loss: 1.491365]\n",
      "epoch:12 step:9733 [D loss: 0.762082, acc: 36.72%] [G loss: 1.448986]\n",
      "epoch:12 step:9734 [D loss: 0.628949, acc: 64.06%] [G loss: 1.605911]\n",
      "epoch:12 step:9735 [D loss: 0.714225, acc: 54.69%] [G loss: 1.870162]\n",
      "epoch:12 step:9736 [D loss: 0.439475, acc: 85.94%] [G loss: 1.876906]\n",
      "epoch:12 step:9737 [D loss: 0.587762, acc: 73.44%] [G loss: 1.588148]\n",
      "epoch:12 step:9738 [D loss: 0.617075, acc: 71.88%] [G loss: 1.630504]\n",
      "epoch:12 step:9739 [D loss: 0.696762, acc: 57.03%] [G loss: 1.466362]\n",
      "epoch:12 step:9740 [D loss: 0.703111, acc: 55.47%] [G loss: 1.613019]\n",
      "epoch:12 step:9741 [D loss: 0.638558, acc: 68.75%] [G loss: 1.614904]\n",
      "epoch:12 step:9742 [D loss: 0.640357, acc: 68.75%] [G loss: 1.676313]\n",
      "epoch:12 step:9743 [D loss: 0.637495, acc: 60.94%] [G loss: 1.616728]\n",
      "epoch:12 step:9744 [D loss: 0.594396, acc: 70.31%] [G loss: 1.417048]\n",
      "epoch:12 step:9745 [D loss: 1.060653, acc: 15.62%] [G loss: 1.322190]\n",
      "epoch:12 step:9746 [D loss: 0.717735, acc: 57.03%] [G loss: 1.621812]\n",
      "epoch:12 step:9747 [D loss: 0.735226, acc: 46.09%] [G loss: 1.570096]\n",
      "epoch:12 step:9748 [D loss: 0.513976, acc: 85.16%] [G loss: 1.764340]\n",
      "epoch:12 step:9749 [D loss: 0.684897, acc: 53.12%] [G loss: 1.711186]\n",
      "epoch:12 step:9750 [D loss: 0.747781, acc: 37.50%] [G loss: 1.311270]\n",
      "epoch:12 step:9751 [D loss: 0.565235, acc: 85.16%] [G loss: 1.782837]\n",
      "epoch:12 step:9752 [D loss: 0.531555, acc: 86.72%] [G loss: 1.732576]\n",
      "epoch:12 step:9753 [D loss: 0.651265, acc: 58.59%] [G loss: 1.674092]\n",
      "epoch:12 step:9754 [D loss: 0.699072, acc: 46.88%] [G loss: 1.527925]\n",
      "epoch:12 step:9755 [D loss: 0.802189, acc: 35.94%] [G loss: 1.379424]\n",
      "epoch:12 step:9756 [D loss: 0.770121, acc: 32.03%] [G loss: 1.660993]\n",
      "epoch:12 step:9757 [D loss: 0.717127, acc: 46.09%] [G loss: 1.403354]\n",
      "epoch:12 step:9758 [D loss: 0.627290, acc: 68.75%] [G loss: 1.680284]\n",
      "epoch:12 step:9759 [D loss: 0.728006, acc: 46.09%] [G loss: 1.626945]\n",
      "epoch:12 step:9760 [D loss: 0.629146, acc: 57.81%] [G loss: 1.387955]\n",
      "epoch:12 step:9761 [D loss: 0.715974, acc: 50.00%] [G loss: 1.687777]\n",
      "epoch:12 step:9762 [D loss: 0.474075, acc: 89.84%] [G loss: 1.719818]\n",
      "epoch:12 step:9763 [D loss: 0.592912, acc: 67.97%] [G loss: 1.606305]\n",
      "epoch:12 step:9764 [D loss: 0.661486, acc: 62.50%] [G loss: 1.971849]\n",
      "epoch:12 step:9765 [D loss: 0.784480, acc: 35.94%] [G loss: 1.559661]\n",
      "epoch:12 step:9766 [D loss: 0.638017, acc: 64.84%] [G loss: 1.732661]\n",
      "epoch:12 step:9767 [D loss: 0.740439, acc: 44.53%] [G loss: 1.765726]\n",
      "epoch:12 step:9768 [D loss: 0.504624, acc: 87.50%] [G loss: 1.698184]\n",
      "epoch:12 step:9769 [D loss: 0.652882, acc: 62.50%] [G loss: 1.518090]\n",
      "epoch:12 step:9770 [D loss: 0.644167, acc: 57.81%] [G loss: 1.394168]\n",
      "epoch:12 step:9771 [D loss: 0.781226, acc: 34.38%] [G loss: 1.467529]\n",
      "epoch:12 step:9772 [D loss: 0.676225, acc: 53.91%] [G loss: 1.788692]\n",
      "epoch:12 step:9773 [D loss: 0.493927, acc: 87.50%] [G loss: 1.691402]\n",
      "epoch:12 step:9774 [D loss: 0.764127, acc: 37.50%] [G loss: 1.400471]\n",
      "epoch:12 step:9775 [D loss: 0.751282, acc: 46.88%] [G loss: 1.682223]\n",
      "epoch:12 step:9776 [D loss: 0.664714, acc: 58.59%] [G loss: 1.643785]\n",
      "epoch:12 step:9777 [D loss: 0.663412, acc: 59.38%] [G loss: 1.629055]\n",
      "epoch:12 step:9778 [D loss: 0.538566, acc: 68.75%] [G loss: 1.395987]\n",
      "epoch:12 step:9779 [D loss: 0.477662, acc: 86.72%] [G loss: 1.592334]\n",
      "epoch:12 step:9780 [D loss: 0.782341, acc: 48.44%] [G loss: 1.524451]\n",
      "epoch:12 step:9781 [D loss: 0.712979, acc: 50.78%] [G loss: 1.637215]\n",
      "epoch:12 step:9782 [D loss: 0.623123, acc: 71.09%] [G loss: 1.690436]\n",
      "epoch:12 step:9783 [D loss: 0.893602, acc: 35.16%] [G loss: 1.458786]\n",
      "epoch:12 step:9784 [D loss: 0.691037, acc: 60.16%] [G loss: 1.484272]\n",
      "epoch:12 step:9785 [D loss: 0.768395, acc: 35.94%] [G loss: 1.618772]\n",
      "epoch:12 step:9786 [D loss: 0.582840, acc: 76.56%] [G loss: 1.601080]\n",
      "epoch:12 step:9787 [D loss: 0.614676, acc: 69.53%] [G loss: 1.603630]\n",
      "epoch:12 step:9788 [D loss: 0.569413, acc: 69.53%] [G loss: 1.744580]\n",
      "epoch:12 step:9789 [D loss: 0.910236, acc: 20.31%] [G loss: 1.573723]\n",
      "epoch:12 step:9790 [D loss: 0.652022, acc: 63.28%] [G loss: 1.514805]\n",
      "epoch:12 step:9791 [D loss: 0.641404, acc: 67.19%] [G loss: 1.526235]\n",
      "epoch:12 step:9792 [D loss: 0.763253, acc: 50.00%] [G loss: 1.381874]\n",
      "epoch:12 step:9793 [D loss: 0.644985, acc: 64.06%] [G loss: 1.894458]\n",
      "epoch:12 step:9794 [D loss: 0.591079, acc: 73.44%] [G loss: 1.504828]\n",
      "epoch:12 step:9795 [D loss: 0.551818, acc: 66.41%] [G loss: 1.633269]\n",
      "epoch:12 step:9796 [D loss: 0.654223, acc: 59.38%] [G loss: 1.785032]\n",
      "epoch:12 step:9797 [D loss: 0.719750, acc: 44.53%] [G loss: 1.652130]\n",
      "epoch:12 step:9798 [D loss: 0.584207, acc: 62.50%] [G loss: 1.894915]\n",
      "epoch:12 step:9799 [D loss: 0.573747, acc: 78.12%] [G loss: 1.712532]\n",
      "epoch:12 step:9800 [D loss: 0.442922, acc: 92.19%] [G loss: 1.769568]\n",
      "epoch:12 step:9801 [D loss: 0.708507, acc: 50.00%] [G loss: 1.723563]\n",
      "epoch:12 step:9802 [D loss: 0.779516, acc: 32.03%] [G loss: 1.500664]\n",
      "epoch:12 step:9803 [D loss: 0.920684, acc: 24.22%] [G loss: 1.379377]\n",
      "epoch:12 step:9804 [D loss: 0.585281, acc: 78.91%] [G loss: 1.656492]\n",
      "epoch:12 step:9805 [D loss: 0.709949, acc: 50.00%] [G loss: 1.824682]\n",
      "epoch:12 step:9806 [D loss: 0.601067, acc: 78.12%] [G loss: 1.651402]\n",
      "epoch:12 step:9807 [D loss: 0.758260, acc: 41.41%] [G loss: 1.420778]\n",
      "epoch:12 step:9808 [D loss: 0.848769, acc: 23.44%] [G loss: 1.493150]\n",
      "epoch:12 step:9809 [D loss: 0.800659, acc: 36.72%] [G loss: 1.566169]\n",
      "epoch:12 step:9810 [D loss: 0.722899, acc: 52.34%] [G loss: 1.742114]\n",
      "epoch:12 step:9811 [D loss: 0.649919, acc: 58.59%] [G loss: 1.634165]\n",
      "epoch:12 step:9812 [D loss: 0.776941, acc: 38.28%] [G loss: 1.418540]\n",
      "epoch:12 step:9813 [D loss: 0.513016, acc: 82.81%] [G loss: 1.804595]\n",
      "epoch:12 step:9814 [D loss: 0.625394, acc: 64.84%] [G loss: 1.948277]\n",
      "epoch:12 step:9815 [D loss: 0.594270, acc: 71.09%] [G loss: 1.566051]\n",
      "epoch:12 step:9816 [D loss: 0.665581, acc: 60.94%] [G loss: 1.737045]\n",
      "epoch:12 step:9817 [D loss: 0.813353, acc: 27.34%] [G loss: 1.522749]\n",
      "epoch:12 step:9818 [D loss: 0.737000, acc: 41.41%] [G loss: 1.644041]\n",
      "epoch:12 step:9819 [D loss: 0.637535, acc: 67.97%] [G loss: 1.553481]\n",
      "epoch:12 step:9820 [D loss: 0.730111, acc: 50.00%] [G loss: 1.724477]\n",
      "epoch:12 step:9821 [D loss: 0.594915, acc: 75.78%] [G loss: 1.634311]\n",
      "epoch:12 step:9822 [D loss: 0.669659, acc: 57.81%] [G loss: 1.677384]\n",
      "epoch:12 step:9823 [D loss: 0.676846, acc: 53.91%] [G loss: 1.553630]\n",
      "epoch:12 step:9824 [D loss: 0.612499, acc: 61.72%] [G loss: 1.507237]\n",
      "epoch:12 step:9825 [D loss: 0.594999, acc: 70.31%] [G loss: 1.927554]\n",
      "epoch:12 step:9826 [D loss: 0.652413, acc: 64.06%] [G loss: 1.564717]\n",
      "epoch:12 step:9827 [D loss: 0.816244, acc: 31.25%] [G loss: 1.583602]\n",
      "epoch:12 step:9828 [D loss: 0.730942, acc: 45.31%] [G loss: 1.562482]\n",
      "epoch:12 step:9829 [D loss: 0.516916, acc: 89.84%] [G loss: 1.704883]\n",
      "epoch:12 step:9830 [D loss: 0.487063, acc: 75.78%] [G loss: 1.512653]\n",
      "epoch:12 step:9831 [D loss: 0.691742, acc: 58.59%] [G loss: 1.411056]\n",
      "epoch:12 step:9832 [D loss: 0.740115, acc: 46.09%] [G loss: 1.654182]\n",
      "epoch:12 step:9833 [D loss: 0.668636, acc: 55.47%] [G loss: 1.619033]\n",
      "epoch:12 step:9834 [D loss: 0.688285, acc: 53.91%] [G loss: 1.627513]\n",
      "epoch:12 step:9835 [D loss: 0.553289, acc: 81.25%] [G loss: 1.610640]\n",
      "epoch:12 step:9836 [D loss: 0.609064, acc: 71.09%] [G loss: 1.627701]\n",
      "epoch:12 step:9837 [D loss: 0.588926, acc: 71.88%] [G loss: 1.525476]\n",
      "epoch:12 step:9838 [D loss: 0.457255, acc: 85.94%] [G loss: 1.919269]\n",
      "epoch:12 step:9839 [D loss: 0.615330, acc: 64.84%] [G loss: 1.717557]\n",
      "epoch:12 step:9840 [D loss: 0.464699, acc: 90.62%] [G loss: 1.703345]\n",
      "epoch:12 step:9841 [D loss: 0.581202, acc: 76.56%] [G loss: 1.558819]\n",
      "epoch:12 step:9842 [D loss: 0.580272, acc: 72.66%] [G loss: 1.635384]\n",
      "epoch:12 step:9843 [D loss: 0.521328, acc: 76.56%] [G loss: 1.347605]\n",
      "epoch:12 step:9844 [D loss: 0.948946, acc: 18.75%] [G loss: 1.372206]\n",
      "epoch:12 step:9845 [D loss: 1.050554, acc: 8.59%] [G loss: 1.435257]\n",
      "epoch:12 step:9846 [D loss: 0.693249, acc: 56.25%] [G loss: 1.417116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9847 [D loss: 0.582145, acc: 72.66%] [G loss: 1.557773]\n",
      "epoch:12 step:9848 [D loss: 0.609882, acc: 74.22%] [G loss: 1.565595]\n",
      "epoch:12 step:9849 [D loss: 0.546060, acc: 81.25%] [G loss: 1.501551]\n",
      "epoch:12 step:9850 [D loss: 0.528996, acc: 84.38%] [G loss: 1.564814]\n",
      "epoch:12 step:9851 [D loss: 0.803536, acc: 31.25%] [G loss: 1.348422]\n",
      "epoch:12 step:9852 [D loss: 0.784057, acc: 36.72%] [G loss: 1.649628]\n",
      "epoch:12 step:9853 [D loss: 0.875213, acc: 21.09%] [G loss: 1.470426]\n",
      "epoch:12 step:9854 [D loss: 1.072776, acc: 14.84%] [G loss: 1.586032]\n",
      "epoch:12 step:9855 [D loss: 0.439996, acc: 94.53%] [G loss: 1.631396]\n",
      "epoch:12 step:9856 [D loss: 0.604389, acc: 70.31%] [G loss: 1.618372]\n",
      "epoch:12 step:9857 [D loss: 0.506201, acc: 85.94%] [G loss: 1.832000]\n",
      "epoch:12 step:9858 [D loss: 0.566888, acc: 68.75%] [G loss: 1.721995]\n",
      "epoch:12 step:9859 [D loss: 0.642401, acc: 68.75%] [G loss: 1.709611]\n",
      "epoch:12 step:9860 [D loss: 0.755819, acc: 36.72%] [G loss: 1.408671]\n",
      "epoch:12 step:9861 [D loss: 0.671670, acc: 64.06%] [G loss: 1.634022]\n",
      "epoch:12 step:9862 [D loss: 0.676293, acc: 56.25%] [G loss: 1.581315]\n",
      "epoch:12 step:9863 [D loss: 0.632525, acc: 67.97%] [G loss: 1.841626]\n",
      "epoch:12 step:9864 [D loss: 0.899058, acc: 29.69%] [G loss: 1.415332]\n",
      "epoch:12 step:9865 [D loss: 0.599407, acc: 65.62%] [G loss: 1.796397]\n",
      "epoch:12 step:9866 [D loss: 0.851923, acc: 22.66%] [G loss: 1.341780]\n",
      "epoch:12 step:9867 [D loss: 0.655011, acc: 55.47%] [G loss: 1.712906]\n",
      "epoch:12 step:9868 [D loss: 0.593750, acc: 76.56%] [G loss: 1.648532]\n",
      "epoch:12 step:9869 [D loss: 0.646527, acc: 66.41%] [G loss: 1.642563]\n",
      "epoch:12 step:9870 [D loss: 0.742693, acc: 50.00%] [G loss: 1.696657]\n",
      "epoch:12 step:9871 [D loss: 0.673240, acc: 57.03%] [G loss: 1.719850]\n",
      "epoch:12 step:9872 [D loss: 0.745471, acc: 43.75%] [G loss: 1.316004]\n",
      "epoch:12 step:9873 [D loss: 0.746432, acc: 45.31%] [G loss: 1.568455]\n",
      "epoch:12 step:9874 [D loss: 0.533337, acc: 78.91%] [G loss: 1.785795]\n",
      "epoch:12 step:9875 [D loss: 0.828776, acc: 31.25%] [G loss: 1.514312]\n",
      "epoch:12 step:9876 [D loss: 0.860783, acc: 26.56%] [G loss: 1.550786]\n",
      "epoch:12 step:9877 [D loss: 0.802503, acc: 35.94%] [G loss: 1.571175]\n",
      "epoch:12 step:9878 [D loss: 0.502905, acc: 89.06%] [G loss: 1.510338]\n",
      "epoch:12 step:9879 [D loss: 0.662187, acc: 53.91%] [G loss: 1.859480]\n",
      "epoch:12 step:9880 [D loss: 0.860368, acc: 25.78%] [G loss: 1.367117]\n",
      "epoch:12 step:9881 [D loss: 0.510041, acc: 78.12%] [G loss: 1.669478]\n",
      "epoch:12 step:9882 [D loss: 0.734132, acc: 48.44%] [G loss: 1.731499]\n",
      "epoch:12 step:9883 [D loss: 0.645661, acc: 60.94%] [G loss: 1.568590]\n",
      "epoch:12 step:9884 [D loss: 0.543559, acc: 71.88%] [G loss: 1.704561]\n",
      "epoch:12 step:9885 [D loss: 0.764696, acc: 49.22%] [G loss: 1.615274]\n",
      "epoch:12 step:9886 [D loss: 0.637379, acc: 70.31%] [G loss: 1.916865]\n",
      "epoch:12 step:9887 [D loss: 0.751082, acc: 44.53%] [G loss: 1.611972]\n",
      "epoch:12 step:9888 [D loss: 0.627328, acc: 64.84%] [G loss: 1.744064]\n",
      "epoch:12 step:9889 [D loss: 0.776979, acc: 32.03%] [G loss: 1.478418]\n",
      "epoch:12 step:9890 [D loss: 0.547606, acc: 76.56%] [G loss: 1.630752]\n",
      "epoch:12 step:9891 [D loss: 0.747166, acc: 46.09%] [G loss: 1.384495]\n",
      "epoch:12 step:9892 [D loss: 0.629079, acc: 62.50%] [G loss: 1.773607]\n",
      "epoch:12 step:9893 [D loss: 0.771305, acc: 53.91%] [G loss: 1.687817]\n",
      "epoch:12 step:9894 [D loss: 0.576743, acc: 80.47%] [G loss: 1.638677]\n",
      "epoch:12 step:9895 [D loss: 0.529476, acc: 90.62%] [G loss: 1.649963]\n",
      "epoch:12 step:9896 [D loss: 0.698225, acc: 53.91%] [G loss: 1.572978]\n",
      "epoch:12 step:9897 [D loss: 0.725263, acc: 43.75%] [G loss: 1.377521]\n",
      "epoch:12 step:9898 [D loss: 0.805124, acc: 29.69%] [G loss: 1.608094]\n",
      "epoch:12 step:9899 [D loss: 0.702032, acc: 53.91%] [G loss: 1.570170]\n",
      "epoch:12 step:9900 [D loss: 0.619951, acc: 67.19%] [G loss: 1.670918]\n",
      "epoch:12 step:9901 [D loss: 0.637461, acc: 60.16%] [G loss: 1.771730]\n",
      "epoch:12 step:9902 [D loss: 0.957268, acc: 10.16%] [G loss: 1.507277]\n",
      "epoch:12 step:9903 [D loss: 0.681376, acc: 57.03%] [G loss: 1.557095]\n",
      "epoch:12 step:9904 [D loss: 0.622326, acc: 64.84%] [G loss: 1.586727]\n",
      "epoch:12 step:9905 [D loss: 0.922498, acc: 10.94%] [G loss: 1.419999]\n",
      "epoch:12 step:9906 [D loss: 0.604668, acc: 71.09%] [G loss: 1.658080]\n",
      "epoch:12 step:9907 [D loss: 0.693480, acc: 52.34%] [G loss: 1.666514]\n",
      "epoch:12 step:9908 [D loss: 0.707007, acc: 53.12%] [G loss: 1.573184]\n",
      "epoch:12 step:9909 [D loss: 0.729494, acc: 43.75%] [G loss: 1.471031]\n",
      "epoch:12 step:9910 [D loss: 0.518724, acc: 77.34%] [G loss: 1.907692]\n",
      "epoch:12 step:9911 [D loss: 0.679396, acc: 58.59%] [G loss: 1.560571]\n",
      "epoch:12 step:9912 [D loss: 0.618913, acc: 69.53%] [G loss: 1.748601]\n",
      "epoch:12 step:9913 [D loss: 0.437812, acc: 94.53%] [G loss: 1.968370]\n",
      "epoch:12 step:9914 [D loss: 0.532328, acc: 85.94%] [G loss: 1.634498]\n",
      "epoch:12 step:9915 [D loss: 0.733111, acc: 51.56%] [G loss: 1.672453]\n",
      "epoch:12 step:9916 [D loss: 0.713273, acc: 48.44%] [G loss: 1.460238]\n",
      "epoch:12 step:9917 [D loss: 0.779950, acc: 35.94%] [G loss: 1.574311]\n",
      "epoch:12 step:9918 [D loss: 0.594774, acc: 74.22%] [G loss: 1.709399]\n",
      "epoch:12 step:9919 [D loss: 0.769564, acc: 39.06%] [G loss: 1.705630]\n",
      "epoch:12 step:9920 [D loss: 0.536794, acc: 85.94%] [G loss: 1.809635]\n",
      "epoch:12 step:9921 [D loss: 0.433157, acc: 85.94%] [G loss: 1.800268]\n",
      "epoch:12 step:9922 [D loss: 0.724284, acc: 53.12%] [G loss: 1.542949]\n",
      "epoch:12 step:9923 [D loss: 0.667698, acc: 60.16%] [G loss: 1.556966]\n",
      "epoch:12 step:9924 [D loss: 0.556845, acc: 67.97%] [G loss: 1.531852]\n",
      "epoch:12 step:9925 [D loss: 0.931341, acc: 14.06%] [G loss: 1.415472]\n",
      "epoch:12 step:9926 [D loss: 0.774692, acc: 40.62%] [G loss: 1.521365]\n",
      "epoch:12 step:9927 [D loss: 0.588796, acc: 74.22%] [G loss: 1.509974]\n",
      "epoch:12 step:9928 [D loss: 0.702993, acc: 48.44%] [G loss: 1.621642]\n",
      "epoch:12 step:9929 [D loss: 0.655116, acc: 61.72%] [G loss: 1.644935]\n",
      "epoch:12 step:9930 [D loss: 0.561553, acc: 71.09%] [G loss: 1.827145]\n",
      "epoch:12 step:9931 [D loss: 0.613701, acc: 69.53%] [G loss: 1.762806]\n",
      "epoch:12 step:9932 [D loss: 0.612265, acc: 69.53%] [G loss: 1.936035]\n",
      "epoch:12 step:9933 [D loss: 0.630070, acc: 64.84%] [G loss: 1.675185]\n",
      "epoch:12 step:9934 [D loss: 0.683783, acc: 57.03%] [G loss: 1.607787]\n",
      "epoch:12 step:9935 [D loss: 0.737902, acc: 48.44%] [G loss: 1.239457]\n",
      "epoch:12 step:9936 [D loss: 0.721786, acc: 52.34%] [G loss: 1.584162]\n",
      "epoch:12 step:9937 [D loss: 0.697636, acc: 56.25%] [G loss: 1.455024]\n",
      "epoch:12 step:9938 [D loss: 0.638914, acc: 60.16%] [G loss: 1.663945]\n",
      "epoch:12 step:9939 [D loss: 0.636814, acc: 60.16%] [G loss: 1.469077]\n",
      "epoch:12 step:9940 [D loss: 0.668401, acc: 57.81%] [G loss: 1.692580]\n",
      "epoch:12 step:9941 [D loss: 0.666929, acc: 59.38%] [G loss: 1.642940]\n",
      "epoch:12 step:9942 [D loss: 0.686559, acc: 53.91%] [G loss: 1.661752]\n",
      "epoch:12 step:9943 [D loss: 0.752521, acc: 34.38%] [G loss: 1.526081]\n",
      "epoch:12 step:9944 [D loss: 0.706003, acc: 48.44%] [G loss: 1.541174]\n",
      "epoch:12 step:9945 [D loss: 0.554234, acc: 66.41%] [G loss: 1.619208]\n",
      "epoch:12 step:9946 [D loss: 1.163039, acc: 4.69%] [G loss: 1.623462]\n",
      "epoch:12 step:9947 [D loss: 0.684164, acc: 55.47%] [G loss: 1.750342]\n",
      "epoch:12 step:9948 [D loss: 0.724269, acc: 48.44%] [G loss: 1.634138]\n",
      "epoch:12 step:9949 [D loss: 0.664092, acc: 64.84%] [G loss: 1.730552]\n",
      "epoch:12 step:9950 [D loss: 0.696835, acc: 53.12%] [G loss: 1.696746]\n",
      "epoch:12 step:9951 [D loss: 0.715582, acc: 49.22%] [G loss: 1.675961]\n",
      "epoch:12 step:9952 [D loss: 0.769997, acc: 38.28%] [G loss: 1.588791]\n",
      "epoch:12 step:9953 [D loss: 0.593868, acc: 73.44%] [G loss: 1.683915]\n",
      "epoch:12 step:9954 [D loss: 0.678906, acc: 59.38%] [G loss: 1.585215]\n",
      "epoch:12 step:9955 [D loss: 0.723557, acc: 46.09%] [G loss: 1.632947]\n",
      "epoch:12 step:9956 [D loss: 0.804573, acc: 30.47%] [G loss: 1.445397]\n",
      "epoch:12 step:9957 [D loss: 0.672287, acc: 60.16%] [G loss: 1.608666]\n",
      "epoch:12 step:9958 [D loss: 0.647725, acc: 64.06%] [G loss: 1.577163]\n",
      "epoch:12 step:9959 [D loss: 0.518145, acc: 84.38%] [G loss: 1.741715]\n",
      "epoch:12 step:9960 [D loss: 0.556957, acc: 73.44%] [G loss: 1.826660]\n",
      "epoch:12 step:9961 [D loss: 0.848501, acc: 21.88%] [G loss: 1.516757]\n",
      "epoch:12 step:9962 [D loss: 0.669253, acc: 61.72%] [G loss: 1.633932]\n",
      "epoch:12 step:9963 [D loss: 0.637696, acc: 66.41%] [G loss: 1.433525]\n",
      "epoch:12 step:9964 [D loss: 0.726271, acc: 53.12%] [G loss: 1.571086]\n",
      "epoch:12 step:9965 [D loss: 0.630700, acc: 66.41%] [G loss: 1.624006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9966 [D loss: 0.643323, acc: 60.94%] [G loss: 1.637582]\n",
      "epoch:12 step:9967 [D loss: 0.727213, acc: 46.09%] [G loss: 1.588745]\n",
      "epoch:12 step:9968 [D loss: 0.761915, acc: 43.75%] [G loss: 1.597556]\n",
      "epoch:12 step:9969 [D loss: 0.445157, acc: 93.75%] [G loss: 1.759170]\n",
      "epoch:12 step:9970 [D loss: 0.678398, acc: 56.25%] [G loss: 1.642184]\n",
      "epoch:12 step:9971 [D loss: 0.710033, acc: 50.00%] [G loss: 1.582622]\n",
      "epoch:12 step:9972 [D loss: 0.689512, acc: 53.12%] [G loss: 1.567935]\n",
      "epoch:12 step:9973 [D loss: 0.662820, acc: 66.41%] [G loss: 1.791537]\n",
      "epoch:12 step:9974 [D loss: 0.553335, acc: 79.69%] [G loss: 1.652380]\n",
      "epoch:12 step:9975 [D loss: 0.624289, acc: 69.53%] [G loss: 1.537735]\n",
      "epoch:12 step:9976 [D loss: 0.746896, acc: 46.88%] [G loss: 1.439343]\n",
      "epoch:12 step:9977 [D loss: 0.675794, acc: 55.47%] [G loss: 1.420787]\n",
      "epoch:12 step:9978 [D loss: 0.872493, acc: 26.56%] [G loss: 1.380818]\n",
      "epoch:12 step:9979 [D loss: 0.715311, acc: 51.56%] [G loss: 1.569718]\n",
      "epoch:12 step:9980 [D loss: 0.684515, acc: 60.94%] [G loss: 1.724061]\n",
      "epoch:12 step:9981 [D loss: 0.833603, acc: 31.25%] [G loss: 1.504884]\n",
      "epoch:12 step:9982 [D loss: 0.752441, acc: 35.94%] [G loss: 1.533807]\n",
      "epoch:12 step:9983 [D loss: 0.618664, acc: 71.09%] [G loss: 1.795399]\n",
      "epoch:12 step:9984 [D loss: 0.650331, acc: 56.25%] [G loss: 1.896323]\n",
      "epoch:12 step:9985 [D loss: 0.812985, acc: 41.41%] [G loss: 1.685120]\n",
      "epoch:12 step:9986 [D loss: 0.689729, acc: 54.69%] [G loss: 1.648263]\n",
      "epoch:12 step:9987 [D loss: 0.682353, acc: 47.66%] [G loss: 1.521278]\n",
      "epoch:12 step:9988 [D loss: 0.692849, acc: 51.56%] [G loss: 1.587495]\n",
      "epoch:12 step:9989 [D loss: 0.644254, acc: 60.16%] [G loss: 1.677632]\n",
      "epoch:12 step:9990 [D loss: 0.725140, acc: 44.53%] [G loss: 1.458100]\n",
      "epoch:12 step:9991 [D loss: 0.868149, acc: 25.00%] [G loss: 1.292189]\n",
      "epoch:12 step:9992 [D loss: 0.703271, acc: 53.91%] [G loss: 1.578939]\n",
      "epoch:12 step:9993 [D loss: 0.589006, acc: 76.56%] [G loss: 1.782453]\n",
      "epoch:12 step:9994 [D loss: 0.620926, acc: 71.88%] [G loss: 1.820062]\n",
      "epoch:12 step:9995 [D loss: 0.786100, acc: 32.81%] [G loss: 1.508671]\n",
      "epoch:12 step:9996 [D loss: 0.697655, acc: 52.34%] [G loss: 1.573782]\n",
      "epoch:12 step:9997 [D loss: 0.640992, acc: 64.84%] [G loss: 1.607020]\n",
      "epoch:12 step:9998 [D loss: 0.729636, acc: 45.31%] [G loss: 1.846236]\n",
      "epoch:12 step:9999 [D loss: 0.611565, acc: 66.41%] [G loss: 1.651337]\n",
      "epoch:12 step:10000 [D loss: 0.622423, acc: 70.31%] [G loss: 1.494964]\n",
      "epoch:12 step:10001 [D loss: 0.781431, acc: 35.16%] [G loss: 1.623809]\n",
      "epoch:12 step:10002 [D loss: 0.608178, acc: 67.97%] [G loss: 1.479127]\n",
      "epoch:12 step:10003 [D loss: 0.814348, acc: 35.16%] [G loss: 1.632771]\n",
      "epoch:12 step:10004 [D loss: 0.686338, acc: 52.34%] [G loss: 1.422850]\n",
      "epoch:12 step:10005 [D loss: 0.571360, acc: 81.25%] [G loss: 1.686722]\n",
      "epoch:12 step:10006 [D loss: 0.690871, acc: 53.12%] [G loss: 1.542402]\n",
      "epoch:12 step:10007 [D loss: 0.875086, acc: 21.88%] [G loss: 1.451263]\n",
      "epoch:12 step:10008 [D loss: 0.646294, acc: 60.94%] [G loss: 1.695069]\n",
      "epoch:12 step:10009 [D loss: 0.654175, acc: 58.59%] [G loss: 1.436706]\n",
      "epoch:12 step:10010 [D loss: 0.682423, acc: 55.47%] [G loss: 1.278835]\n",
      "epoch:12 step:10011 [D loss: 0.590086, acc: 72.66%] [G loss: 1.599699]\n",
      "epoch:12 step:10012 [D loss: 0.690054, acc: 49.22%] [G loss: 1.751702]\n",
      "epoch:12 step:10013 [D loss: 0.611460, acc: 71.88%] [G loss: 1.607991]\n",
      "epoch:12 step:10014 [D loss: 0.771293, acc: 36.72%] [G loss: 1.539329]\n",
      "epoch:12 step:10015 [D loss: 0.640779, acc: 60.94%] [G loss: 1.752814]\n",
      "epoch:12 step:10016 [D loss: 0.590581, acc: 75.00%] [G loss: 1.832561]\n",
      "epoch:12 step:10017 [D loss: 0.696342, acc: 58.59%] [G loss: 1.431146]\n",
      "epoch:12 step:10018 [D loss: 0.587473, acc: 77.34%] [G loss: 1.628797]\n",
      "epoch:12 step:10019 [D loss: 0.659726, acc: 56.25%] [G loss: 1.553494]\n",
      "epoch:12 step:10020 [D loss: 0.661857, acc: 60.16%] [G loss: 1.605059]\n",
      "epoch:12 step:10021 [D loss: 0.854171, acc: 25.00%] [G loss: 1.456810]\n",
      "epoch:12 step:10022 [D loss: 0.665910, acc: 57.03%] [G loss: 1.817704]\n",
      "epoch:12 step:10023 [D loss: 0.548051, acc: 83.59%] [G loss: 1.784880]\n",
      "epoch:12 step:10024 [D loss: 0.637803, acc: 64.84%] [G loss: 1.933430]\n",
      "epoch:12 step:10025 [D loss: 0.667355, acc: 59.38%] [G loss: 1.637408]\n",
      "epoch:12 step:10026 [D loss: 0.561302, acc: 75.78%] [G loss: 1.738543]\n",
      "epoch:12 step:10027 [D loss: 0.640457, acc: 66.41%] [G loss: 1.536433]\n",
      "epoch:12 step:10028 [D loss: 0.916968, acc: 22.66%] [G loss: 1.411579]\n",
      "epoch:12 step:10029 [D loss: 0.733484, acc: 45.31%] [G loss: 1.637542]\n",
      "epoch:12 step:10030 [D loss: 0.656079, acc: 62.50%] [G loss: 1.758659]\n",
      "epoch:12 step:10031 [D loss: 0.630829, acc: 67.19%] [G loss: 1.714197]\n",
      "epoch:12 step:10032 [D loss: 0.535423, acc: 79.69%] [G loss: 1.740692]\n",
      "epoch:12 step:10033 [D loss: 0.674600, acc: 57.81%] [G loss: 1.631424]\n",
      "epoch:12 step:10034 [D loss: 0.707182, acc: 52.34%] [G loss: 1.546091]\n",
      "epoch:12 step:10035 [D loss: 0.666472, acc: 63.28%] [G loss: 1.615941]\n",
      "epoch:12 step:10036 [D loss: 0.708701, acc: 46.88%] [G loss: 1.614783]\n",
      "epoch:12 step:10037 [D loss: 0.696190, acc: 51.56%] [G loss: 1.458015]\n",
      "epoch:12 step:10038 [D loss: 0.546415, acc: 85.16%] [G loss: 1.660923]\n",
      "epoch:12 step:10039 [D loss: 0.488184, acc: 78.12%] [G loss: 1.703374]\n",
      "epoch:12 step:10040 [D loss: 0.636785, acc: 64.06%] [G loss: 1.652480]\n",
      "epoch:12 step:10041 [D loss: 0.606531, acc: 68.75%] [G loss: 1.725232]\n",
      "epoch:12 step:10042 [D loss: 0.939826, acc: 22.66%] [G loss: 1.476080]\n",
      "epoch:12 step:10043 [D loss: 0.722338, acc: 46.88%] [G loss: 1.699398]\n",
      "epoch:12 step:10044 [D loss: 0.622498, acc: 71.09%] [G loss: 1.673296]\n",
      "epoch:12 step:10045 [D loss: 0.606305, acc: 72.66%] [G loss: 1.475417]\n",
      "epoch:12 step:10046 [D loss: 0.599399, acc: 67.97%] [G loss: 1.667018]\n",
      "epoch:12 step:10047 [D loss: 0.586012, acc: 73.44%] [G loss: 1.619320]\n",
      "epoch:12 step:10048 [D loss: 0.546012, acc: 81.25%] [G loss: 1.440200]\n",
      "epoch:12 step:10049 [D loss: 0.666566, acc: 59.38%] [G loss: 1.656412]\n",
      "epoch:12 step:10050 [D loss: 0.629895, acc: 70.31%] [G loss: 1.758368]\n",
      "epoch:12 step:10051 [D loss: 0.547010, acc: 82.03%] [G loss: 1.720058]\n",
      "epoch:12 step:10052 [D loss: 0.489918, acc: 88.28%] [G loss: 1.544917]\n",
      "epoch:12 step:10053 [D loss: 0.693530, acc: 55.47%] [G loss: 1.795332]\n",
      "epoch:12 step:10054 [D loss: 0.869318, acc: 45.31%] [G loss: 1.315496]\n",
      "epoch:12 step:10055 [D loss: 0.762666, acc: 45.31%] [G loss: 1.598662]\n",
      "epoch:12 step:10056 [D loss: 0.629245, acc: 67.97%] [G loss: 1.719280]\n",
      "epoch:12 step:10057 [D loss: 0.685737, acc: 50.78%] [G loss: 1.579370]\n",
      "epoch:12 step:10058 [D loss: 0.704126, acc: 54.69%] [G loss: 1.739682]\n",
      "epoch:12 step:10059 [D loss: 0.689822, acc: 56.25%] [G loss: 1.703912]\n",
      "epoch:12 step:10060 [D loss: 0.616503, acc: 64.84%] [G loss: 1.772881]\n",
      "epoch:12 step:10061 [D loss: 0.464356, acc: 93.75%] [G loss: 1.829459]\n",
      "epoch:12 step:10062 [D loss: 0.781959, acc: 44.53%] [G loss: 1.656824]\n",
      "epoch:12 step:10063 [D loss: 0.412161, acc: 92.19%] [G loss: 2.244517]\n",
      "epoch:12 step:10064 [D loss: 1.070261, acc: 12.50%] [G loss: 1.719549]\n",
      "epoch:12 step:10065 [D loss: 0.611469, acc: 67.19%] [G loss: 1.833171]\n",
      "epoch:12 step:10066 [D loss: 0.480035, acc: 84.38%] [G loss: 1.660324]\n",
      "epoch:12 step:10067 [D loss: 0.666520, acc: 57.03%] [G loss: 1.782587]\n",
      "epoch:12 step:10068 [D loss: 0.737579, acc: 43.75%] [G loss: 1.520600]\n",
      "epoch:12 step:10069 [D loss: 0.518497, acc: 82.03%] [G loss: 1.840665]\n",
      "epoch:12 step:10070 [D loss: 0.565812, acc: 82.03%] [G loss: 1.565231]\n",
      "epoch:12 step:10071 [D loss: 0.634154, acc: 60.94%] [G loss: 1.655579]\n",
      "epoch:12 step:10072 [D loss: 0.500201, acc: 89.06%] [G loss: 1.650790]\n",
      "epoch:12 step:10073 [D loss: 0.539416, acc: 82.03%] [G loss: 1.770431]\n",
      "epoch:12 step:10074 [D loss: 0.538599, acc: 81.25%] [G loss: 1.920963]\n",
      "epoch:12 step:10075 [D loss: 0.685326, acc: 52.34%] [G loss: 1.525499]\n",
      "epoch:12 step:10076 [D loss: 0.636722, acc: 70.31%] [G loss: 1.590121]\n",
      "epoch:12 step:10077 [D loss: 0.742753, acc: 46.88%] [G loss: 1.719226]\n",
      "epoch:12 step:10078 [D loss: 0.896515, acc: 24.22%] [G loss: 1.330412]\n",
      "epoch:12 step:10079 [D loss: 0.682826, acc: 56.25%] [G loss: 1.904107]\n",
      "epoch:12 step:10080 [D loss: 0.676382, acc: 57.03%] [G loss: 1.698365]\n",
      "epoch:12 step:10081 [D loss: 0.696996, acc: 55.47%] [G loss: 1.784936]\n",
      "epoch:12 step:10082 [D loss: 0.756849, acc: 37.50%] [G loss: 1.677970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:10083 [D loss: 0.701327, acc: 56.25%] [G loss: 1.740497]\n",
      "epoch:12 step:10084 [D loss: 0.679267, acc: 53.12%] [G loss: 1.711183]\n",
      "epoch:12 step:10085 [D loss: 0.497832, acc: 82.03%] [G loss: 1.678418]\n",
      "epoch:12 step:10086 [D loss: 0.809330, acc: 36.72%] [G loss: 1.805744]\n",
      "epoch:12 step:10087 [D loss: 0.787080, acc: 35.94%] [G loss: 1.575207]\n",
      "epoch:12 step:10088 [D loss: 0.616623, acc: 72.66%] [G loss: 1.738889]\n",
      "epoch:12 step:10089 [D loss: 0.679468, acc: 58.59%] [G loss: 1.786786]\n",
      "epoch:12 step:10090 [D loss: 0.638485, acc: 65.62%] [G loss: 1.761378]\n",
      "epoch:12 step:10091 [D loss: 0.536772, acc: 86.72%] [G loss: 1.674673]\n",
      "epoch:12 step:10092 [D loss: 0.666441, acc: 58.59%] [G loss: 1.753439]\n",
      "epoch:12 step:10093 [D loss: 0.798743, acc: 37.50%] [G loss: 1.558082]\n",
      "epoch:12 step:10094 [D loss: 0.538590, acc: 80.47%] [G loss: 1.796810]\n",
      "epoch:12 step:10095 [D loss: 0.893982, acc: 27.34%] [G loss: 1.859312]\n",
      "epoch:12 step:10096 [D loss: 0.550019, acc: 80.47%] [G loss: 1.717927]\n",
      "epoch:12 step:10097 [D loss: 0.775995, acc: 45.31%] [G loss: 1.616313]\n",
      "epoch:12 step:10098 [D loss: 0.804820, acc: 34.38%] [G loss: 1.597959]\n",
      "epoch:12 step:10099 [D loss: 0.672664, acc: 58.59%] [G loss: 1.693067]\n",
      "epoch:12 step:10100 [D loss: 0.638254, acc: 67.97%] [G loss: 1.720997]\n",
      "epoch:12 step:10101 [D loss: 0.646577, acc: 60.94%] [G loss: 1.600679]\n",
      "epoch:12 step:10102 [D loss: 0.602102, acc: 67.97%] [G loss: 1.834442]\n",
      "epoch:12 step:10103 [D loss: 0.629146, acc: 64.84%] [G loss: 1.791661]\n",
      "epoch:12 step:10104 [D loss: 0.737594, acc: 49.22%] [G loss: 1.428876]\n",
      "epoch:12 step:10105 [D loss: 0.694977, acc: 60.94%] [G loss: 1.619825]\n",
      "epoch:12 step:10106 [D loss: 0.753728, acc: 42.19%] [G loss: 1.750248]\n",
      "epoch:12 step:10107 [D loss: 0.713053, acc: 50.78%] [G loss: 1.652711]\n",
      "epoch:12 step:10108 [D loss: 0.810402, acc: 35.16%] [G loss: 1.473938]\n",
      "epoch:12 step:10109 [D loss: 0.648532, acc: 64.84%] [G loss: 1.662924]\n",
      "epoch:12 step:10110 [D loss: 0.517302, acc: 85.16%] [G loss: 1.931090]\n",
      "epoch:12 step:10111 [D loss: 0.609803, acc: 69.53%] [G loss: 1.765486]\n",
      "epoch:12 step:10112 [D loss: 0.710995, acc: 51.56%] [G loss: 1.580619]\n",
      "epoch:12 step:10113 [D loss: 0.501573, acc: 87.50%] [G loss: 1.893680]\n",
      "epoch:12 step:10114 [D loss: 0.565919, acc: 79.69%] [G loss: 1.848627]\n",
      "epoch:12 step:10115 [D loss: 0.748782, acc: 42.97%] [G loss: 1.688393]\n",
      "epoch:12 step:10116 [D loss: 0.685095, acc: 55.47%] [G loss: 1.739563]\n",
      "epoch:12 step:10117 [D loss: 0.704617, acc: 53.91%] [G loss: 1.685825]\n",
      "epoch:12 step:10118 [D loss: 0.664438, acc: 60.16%] [G loss: 1.747722]\n",
      "epoch:12 step:10119 [D loss: 0.620093, acc: 69.53%] [G loss: 1.774184]\n",
      "epoch:12 step:10120 [D loss: 0.535402, acc: 85.94%] [G loss: 1.745095]\n",
      "epoch:12 step:10121 [D loss: 0.919620, acc: 25.78%] [G loss: 1.409921]\n",
      "epoch:12 step:10122 [D loss: 0.756527, acc: 41.41%] [G loss: 1.690107]\n",
      "epoch:12 step:10123 [D loss: 0.838925, acc: 41.41%] [G loss: 1.400175]\n",
      "epoch:12 step:10124 [D loss: 0.719617, acc: 52.34%] [G loss: 1.727548]\n",
      "epoch:12 step:10125 [D loss: 0.640995, acc: 64.06%] [G loss: 1.893989]\n",
      "epoch:12 step:10126 [D loss: 0.634177, acc: 71.88%] [G loss: 1.796124]\n",
      "epoch:12 step:10127 [D loss: 0.759889, acc: 32.03%] [G loss: 1.397132]\n",
      "epoch:12 step:10128 [D loss: 0.775095, acc: 42.19%] [G loss: 1.768566]\n",
      "epoch:12 step:10129 [D loss: 0.547125, acc: 80.47%] [G loss: 1.664021]\n",
      "epoch:12 step:10130 [D loss: 0.666461, acc: 57.81%] [G loss: 1.917369]\n",
      "epoch:12 step:10131 [D loss: 0.636009, acc: 60.94%] [G loss: 1.640536]\n",
      "epoch:12 step:10132 [D loss: 0.758691, acc: 46.09%] [G loss: 1.735858]\n",
      "epoch:12 step:10133 [D loss: 0.600132, acc: 71.88%] [G loss: 1.791393]\n",
      "epoch:12 step:10134 [D loss: 0.661385, acc: 60.16%] [G loss: 1.589292]\n",
      "epoch:12 step:10135 [D loss: 0.629170, acc: 64.06%] [G loss: 1.777537]\n",
      "epoch:12 step:10136 [D loss: 0.937022, acc: 10.16%] [G loss: 1.413157]\n",
      "epoch:12 step:10137 [D loss: 0.633873, acc: 64.84%] [G loss: 1.585952]\n",
      "epoch:12 step:10138 [D loss: 0.582346, acc: 74.22%] [G loss: 1.651371]\n",
      "epoch:12 step:10139 [D loss: 0.512933, acc: 83.59%] [G loss: 1.621604]\n",
      "epoch:12 step:10140 [D loss: 0.692772, acc: 52.34%] [G loss: 1.929636]\n",
      "epoch:12 step:10141 [D loss: 0.596634, acc: 71.09%] [G loss: 1.819806]\n",
      "epoch:12 step:10142 [D loss: 0.604828, acc: 66.41%] [G loss: 1.657914]\n",
      "epoch:12 step:10143 [D loss: 0.990545, acc: 32.03%] [G loss: 1.650510]\n",
      "epoch:12 step:10144 [D loss: 0.641932, acc: 70.31%] [G loss: 1.625529]\n",
      "epoch:12 step:10145 [D loss: 0.669559, acc: 52.34%] [G loss: 1.876763]\n",
      "epoch:12 step:10146 [D loss: 0.630365, acc: 64.06%] [G loss: 2.022223]\n",
      "epoch:12 step:10147 [D loss: 0.839892, acc: 35.94%] [G loss: 1.638273]\n",
      "epoch:12 step:10148 [D loss: 0.545172, acc: 80.47%] [G loss: 1.695939]\n",
      "epoch:12 step:10149 [D loss: 0.642845, acc: 58.59%] [G loss: 1.897724]\n",
      "epoch:12 step:10150 [D loss: 0.835641, acc: 38.28%] [G loss: 1.633073]\n",
      "epoch:12 step:10151 [D loss: 0.911976, acc: 25.00%] [G loss: 1.450781]\n",
      "epoch:12 step:10152 [D loss: 0.944872, acc: 21.09%] [G loss: 1.392263]\n",
      "epoch:12 step:10153 [D loss: 0.644654, acc: 64.06%] [G loss: 1.629563]\n",
      "epoch:13 step:10154 [D loss: 0.686626, acc: 53.12%] [G loss: 1.659855]\n",
      "epoch:13 step:10155 [D loss: 0.522115, acc: 76.56%] [G loss: 1.903389]\n",
      "epoch:13 step:10156 [D loss: 0.802289, acc: 39.06%] [G loss: 1.704663]\n",
      "epoch:13 step:10157 [D loss: 0.737792, acc: 43.75%] [G loss: 1.491799]\n",
      "epoch:13 step:10158 [D loss: 0.766191, acc: 44.53%] [G loss: 1.645487]\n",
      "epoch:13 step:10159 [D loss: 0.475641, acc: 85.16%] [G loss: 1.758737]\n",
      "epoch:13 step:10160 [D loss: 0.688937, acc: 55.47%] [G loss: 1.705929]\n",
      "epoch:13 step:10161 [D loss: 0.674057, acc: 55.47%] [G loss: 1.584705]\n",
      "epoch:13 step:10162 [D loss: 0.727971, acc: 46.09%] [G loss: 1.648795]\n",
      "epoch:13 step:10163 [D loss: 0.763326, acc: 41.41%] [G loss: 1.522458]\n",
      "epoch:13 step:10164 [D loss: 0.606729, acc: 73.44%] [G loss: 1.876103]\n",
      "epoch:13 step:10165 [D loss: 0.599064, acc: 65.62%] [G loss: 1.655951]\n",
      "epoch:13 step:10166 [D loss: 0.538397, acc: 76.56%] [G loss: 1.732131]\n",
      "epoch:13 step:10167 [D loss: 0.766715, acc: 43.75%] [G loss: 1.557561]\n",
      "epoch:13 step:10168 [D loss: 0.721910, acc: 46.88%] [G loss: 1.642534]\n",
      "epoch:13 step:10169 [D loss: 0.610012, acc: 70.31%] [G loss: 1.758805]\n",
      "epoch:13 step:10170 [D loss: 0.378505, acc: 93.75%] [G loss: 1.793028]\n",
      "epoch:13 step:10171 [D loss: 0.654105, acc: 62.50%] [G loss: 1.893745]\n",
      "epoch:13 step:10172 [D loss: 0.688264, acc: 60.16%] [G loss: 1.663067]\n",
      "epoch:13 step:10173 [D loss: 0.755982, acc: 39.06%] [G loss: 1.590414]\n",
      "epoch:13 step:10174 [D loss: 0.578438, acc: 70.31%] [G loss: 1.439108]\n",
      "epoch:13 step:10175 [D loss: 0.672458, acc: 60.94%] [G loss: 1.821199]\n",
      "epoch:13 step:10176 [D loss: 0.704792, acc: 51.56%] [G loss: 1.699809]\n",
      "epoch:13 step:10177 [D loss: 0.691484, acc: 58.59%] [G loss: 1.621600]\n",
      "epoch:13 step:10178 [D loss: 0.701610, acc: 56.25%] [G loss: 1.818152]\n",
      "epoch:13 step:10179 [D loss: 0.689609, acc: 53.12%] [G loss: 1.628139]\n",
      "epoch:13 step:10180 [D loss: 0.731153, acc: 46.09%] [G loss: 1.618480]\n",
      "epoch:13 step:10181 [D loss: 0.607456, acc: 77.34%] [G loss: 1.775053]\n",
      "epoch:13 step:10182 [D loss: 0.640255, acc: 58.59%] [G loss: 1.637291]\n",
      "epoch:13 step:10183 [D loss: 0.555773, acc: 86.72%] [G loss: 2.009538]\n",
      "epoch:13 step:10184 [D loss: 0.438230, acc: 89.84%] [G loss: 1.949096]\n",
      "epoch:13 step:10185 [D loss: 0.499393, acc: 89.06%] [G loss: 1.807318]\n",
      "epoch:13 step:10186 [D loss: 0.564852, acc: 75.78%] [G loss: 1.714794]\n",
      "epoch:13 step:10187 [D loss: 0.631302, acc: 61.72%] [G loss: 1.754876]\n",
      "epoch:13 step:10188 [D loss: 0.718758, acc: 47.66%] [G loss: 1.926003]\n",
      "epoch:13 step:10189 [D loss: 0.703024, acc: 52.34%] [G loss: 1.548659]\n",
      "epoch:13 step:10190 [D loss: 0.435730, acc: 92.97%] [G loss: 1.966729]\n",
      "epoch:13 step:10191 [D loss: 0.620764, acc: 67.19%] [G loss: 1.665480]\n",
      "epoch:13 step:10192 [D loss: 0.667169, acc: 62.50%] [G loss: 1.564525]\n",
      "epoch:13 step:10193 [D loss: 0.547558, acc: 76.56%] [G loss: 1.780329]\n",
      "epoch:13 step:10194 [D loss: 0.572646, acc: 75.00%] [G loss: 1.738574]\n",
      "epoch:13 step:10195 [D loss: 0.593778, acc: 77.34%] [G loss: 1.684152]\n",
      "epoch:13 step:10196 [D loss: 1.082987, acc: 19.53%] [G loss: 1.499676]\n",
      "epoch:13 step:10197 [D loss: 0.746692, acc: 46.09%] [G loss: 1.521364]\n",
      "epoch:13 step:10198 [D loss: 0.627234, acc: 61.72%] [G loss: 1.775362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10199 [D loss: 0.679240, acc: 51.56%] [G loss: 1.644133]\n",
      "epoch:13 step:10200 [D loss: 0.713856, acc: 54.69%] [G loss: 1.738187]\n",
      "epoch:13 step:10201 [D loss: 0.652886, acc: 61.72%] [G loss: 1.584601]\n",
      "epoch:13 step:10202 [D loss: 0.921381, acc: 22.66%] [G loss: 1.554912]\n",
      "epoch:13 step:10203 [D loss: 1.039198, acc: 14.06%] [G loss: 1.454705]\n",
      "epoch:13 step:10204 [D loss: 0.632629, acc: 64.06%] [G loss: 1.740208]\n",
      "epoch:13 step:10205 [D loss: 0.557093, acc: 80.47%] [G loss: 1.742072]\n",
      "epoch:13 step:10206 [D loss: 0.537233, acc: 78.12%] [G loss: 1.799929]\n",
      "epoch:13 step:10207 [D loss: 0.704427, acc: 55.47%] [G loss: 1.482916]\n",
      "epoch:13 step:10208 [D loss: 0.720004, acc: 46.88%] [G loss: 1.789259]\n",
      "epoch:13 step:10209 [D loss: 0.912449, acc: 18.75%] [G loss: 1.336085]\n",
      "epoch:13 step:10210 [D loss: 0.791683, acc: 39.06%] [G loss: 1.668906]\n",
      "epoch:13 step:10211 [D loss: 0.522523, acc: 85.94%] [G loss: 1.646996]\n",
      "epoch:13 step:10212 [D loss: 0.347664, acc: 99.22%] [G loss: 2.054019]\n",
      "epoch:13 step:10213 [D loss: 0.474273, acc: 89.84%] [G loss: 1.836961]\n",
      "epoch:13 step:10214 [D loss: 0.610239, acc: 67.19%] [G loss: 1.868195]\n",
      "epoch:13 step:10215 [D loss: 0.439193, acc: 93.75%] [G loss: 1.712544]\n",
      "epoch:13 step:10216 [D loss: 0.711674, acc: 46.88%] [G loss: 1.729850]\n",
      "epoch:13 step:10217 [D loss: 0.551433, acc: 79.69%] [G loss: 1.575316]\n",
      "epoch:13 step:10218 [D loss: 0.572768, acc: 72.66%] [G loss: 1.740007]\n",
      "epoch:13 step:10219 [D loss: 0.515904, acc: 87.50%] [G loss: 1.810958]\n",
      "epoch:13 step:10220 [D loss: 0.710468, acc: 50.00%] [G loss: 1.580862]\n",
      "epoch:13 step:10221 [D loss: 0.621699, acc: 67.97%] [G loss: 1.761233]\n",
      "epoch:13 step:10222 [D loss: 0.630810, acc: 68.75%] [G loss: 1.653829]\n",
      "epoch:13 step:10223 [D loss: 0.700934, acc: 51.56%] [G loss: 1.605286]\n",
      "epoch:13 step:10224 [D loss: 1.275058, acc: 26.56%] [G loss: 1.215505]\n",
      "epoch:13 step:10225 [D loss: 0.749357, acc: 43.75%] [G loss: 1.701764]\n",
      "epoch:13 step:10226 [D loss: 0.538863, acc: 78.91%] [G loss: 1.801908]\n",
      "epoch:13 step:10227 [D loss: 0.524577, acc: 83.59%] [G loss: 1.471627]\n",
      "epoch:13 step:10228 [D loss: 0.712546, acc: 52.34%] [G loss: 1.782753]\n",
      "epoch:13 step:10229 [D loss: 0.576857, acc: 78.91%] [G loss: 2.148536]\n",
      "epoch:13 step:10230 [D loss: 0.745718, acc: 42.19%] [G loss: 1.431166]\n",
      "epoch:13 step:10231 [D loss: 0.696150, acc: 53.91%] [G loss: 2.009829]\n",
      "epoch:13 step:10232 [D loss: 0.698353, acc: 60.94%] [G loss: 1.747330]\n",
      "epoch:13 step:10233 [D loss: 0.495918, acc: 88.28%] [G loss: 1.739709]\n",
      "epoch:13 step:10234 [D loss: 0.752065, acc: 38.28%] [G loss: 1.581608]\n",
      "epoch:13 step:10235 [D loss: 0.541869, acc: 80.47%] [G loss: 1.617249]\n",
      "epoch:13 step:10236 [D loss: 0.487471, acc: 77.34%] [G loss: 1.595089]\n",
      "epoch:13 step:10237 [D loss: 1.084746, acc: 8.59%] [G loss: 1.376943]\n",
      "epoch:13 step:10238 [D loss: 0.649576, acc: 62.50%] [G loss: 1.739253]\n",
      "epoch:13 step:10239 [D loss: 0.641128, acc: 64.84%] [G loss: 1.675323]\n",
      "epoch:13 step:10240 [D loss: 0.455937, acc: 91.41%] [G loss: 1.877843]\n",
      "epoch:13 step:10241 [D loss: 0.859645, acc: 50.00%] [G loss: 1.659604]\n",
      "epoch:13 step:10242 [D loss: 0.529957, acc: 83.59%] [G loss: 1.978112]\n",
      "epoch:13 step:10243 [D loss: 0.759911, acc: 44.53%] [G loss: 1.696081]\n",
      "epoch:13 step:10244 [D loss: 0.666682, acc: 55.47%] [G loss: 1.984283]\n",
      "epoch:13 step:10245 [D loss: 0.608958, acc: 72.66%] [G loss: 1.698012]\n",
      "epoch:13 step:10246 [D loss: 0.475283, acc: 86.72%] [G loss: 1.588231]\n",
      "epoch:13 step:10247 [D loss: 0.717919, acc: 50.00%] [G loss: 1.596099]\n",
      "epoch:13 step:10248 [D loss: 0.577392, acc: 78.12%] [G loss: 1.661582]\n",
      "epoch:13 step:10249 [D loss: 0.601941, acc: 71.88%] [G loss: 1.442726]\n",
      "epoch:13 step:10250 [D loss: 0.589979, acc: 64.84%] [G loss: 1.793482]\n",
      "epoch:13 step:10251 [D loss: 0.694703, acc: 57.81%] [G loss: 1.323330]\n",
      "epoch:13 step:10252 [D loss: 0.375264, acc: 89.84%] [G loss: 2.392188]\n",
      "epoch:13 step:10253 [D loss: 0.617355, acc: 71.09%] [G loss: 1.720528]\n",
      "epoch:13 step:10254 [D loss: 0.812108, acc: 37.50%] [G loss: 1.637362]\n",
      "epoch:13 step:10255 [D loss: 0.451380, acc: 82.81%] [G loss: 1.959284]\n",
      "epoch:13 step:10256 [D loss: 0.447443, acc: 90.62%] [G loss: 1.934703]\n",
      "epoch:13 step:10257 [D loss: 0.841556, acc: 35.16%] [G loss: 1.593529]\n",
      "epoch:13 step:10258 [D loss: 0.440817, acc: 89.84%] [G loss: 1.882425]\n",
      "epoch:13 step:10259 [D loss: 0.652922, acc: 60.16%] [G loss: 1.827491]\n",
      "epoch:13 step:10260 [D loss: 0.613356, acc: 68.75%] [G loss: 2.138758]\n",
      "epoch:13 step:10261 [D loss: 0.940224, acc: 39.84%] [G loss: 1.488815]\n",
      "epoch:13 step:10262 [D loss: 0.511462, acc: 82.03%] [G loss: 1.777801]\n",
      "epoch:13 step:10263 [D loss: 0.709524, acc: 54.69%] [G loss: 1.429730]\n",
      "epoch:13 step:10264 [D loss: 0.757425, acc: 49.22%] [G loss: 1.524964]\n",
      "epoch:13 step:10265 [D loss: 0.575267, acc: 64.06%] [G loss: 1.294931]\n",
      "epoch:13 step:10266 [D loss: 0.922770, acc: 21.88%] [G loss: 1.398190]\n",
      "epoch:13 step:10267 [D loss: 0.710785, acc: 56.25%] [G loss: 1.835918]\n",
      "epoch:13 step:10268 [D loss: 0.633120, acc: 60.94%] [G loss: 1.662189]\n",
      "epoch:13 step:10269 [D loss: 0.469634, acc: 89.84%] [G loss: 1.763391]\n",
      "epoch:13 step:10270 [D loss: 0.705520, acc: 47.66%] [G loss: 1.449283]\n",
      "epoch:13 step:10271 [D loss: 0.704897, acc: 51.56%] [G loss: 1.743000]\n",
      "epoch:13 step:10272 [D loss: 0.604894, acc: 71.09%] [G loss: 1.522710]\n",
      "epoch:13 step:10273 [D loss: 0.762678, acc: 43.75%] [G loss: 1.610802]\n",
      "epoch:13 step:10274 [D loss: 0.701271, acc: 52.34%] [G loss: 1.817868]\n",
      "epoch:13 step:10275 [D loss: 0.747270, acc: 42.97%] [G loss: 1.721789]\n",
      "epoch:13 step:10276 [D loss: 0.567611, acc: 82.81%] [G loss: 1.740118]\n",
      "epoch:13 step:10277 [D loss: 0.607662, acc: 64.84%] [G loss: 1.834803]\n",
      "epoch:13 step:10278 [D loss: 0.789043, acc: 39.06%] [G loss: 1.504840]\n",
      "epoch:13 step:10279 [D loss: 0.768633, acc: 50.00%] [G loss: 1.802315]\n",
      "epoch:13 step:10280 [D loss: 0.690231, acc: 57.03%] [G loss: 1.457816]\n",
      "epoch:13 step:10281 [D loss: 0.664406, acc: 55.47%] [G loss: 1.870696]\n",
      "epoch:13 step:10282 [D loss: 0.695231, acc: 53.91%] [G loss: 1.887500]\n",
      "epoch:13 step:10283 [D loss: 1.098826, acc: 12.50%] [G loss: 1.262316]\n",
      "epoch:13 step:10284 [D loss: 0.749505, acc: 45.31%] [G loss: 1.847176]\n",
      "epoch:13 step:10285 [D loss: 0.521651, acc: 85.94%] [G loss: 1.572302]\n",
      "epoch:13 step:10286 [D loss: 0.619292, acc: 61.72%] [G loss: 1.757683]\n",
      "epoch:13 step:10287 [D loss: 0.650396, acc: 64.06%] [G loss: 1.647545]\n",
      "epoch:13 step:10288 [D loss: 0.618459, acc: 72.66%] [G loss: 1.635103]\n",
      "epoch:13 step:10289 [D loss: 0.604056, acc: 70.31%] [G loss: 1.774023]\n",
      "epoch:13 step:10290 [D loss: 0.530174, acc: 85.94%] [G loss: 1.682364]\n",
      "epoch:13 step:10291 [D loss: 0.541956, acc: 79.69%] [G loss: 1.947573]\n",
      "epoch:13 step:10292 [D loss: 0.329022, acc: 92.19%] [G loss: 2.369411]\n",
      "epoch:13 step:10293 [D loss: 0.571924, acc: 75.78%] [G loss: 1.964672]\n",
      "epoch:13 step:10294 [D loss: 0.671232, acc: 53.12%] [G loss: 1.637457]\n",
      "epoch:13 step:10295 [D loss: 0.605317, acc: 68.75%] [G loss: 1.609776]\n",
      "epoch:13 step:10296 [D loss: 0.750887, acc: 42.19%] [G loss: 1.390850]\n",
      "epoch:13 step:10297 [D loss: 0.480478, acc: 90.62%] [G loss: 1.801830]\n",
      "epoch:13 step:10298 [D loss: 0.699313, acc: 52.34%] [G loss: 1.679365]\n",
      "epoch:13 step:10299 [D loss: 0.640303, acc: 60.94%] [G loss: 1.675543]\n",
      "epoch:13 step:10300 [D loss: 0.720794, acc: 47.66%] [G loss: 1.557984]\n",
      "epoch:13 step:10301 [D loss: 0.627277, acc: 66.41%] [G loss: 1.527803]\n",
      "epoch:13 step:10302 [D loss: 0.529923, acc: 70.31%] [G loss: 1.988749]\n",
      "epoch:13 step:10303 [D loss: 0.832170, acc: 35.94%] [G loss: 1.653147]\n",
      "epoch:13 step:10304 [D loss: 0.386633, acc: 96.88%] [G loss: 2.105027]\n",
      "epoch:13 step:10305 [D loss: 0.627506, acc: 60.94%] [G loss: 1.427384]\n",
      "epoch:13 step:10306 [D loss: 0.580252, acc: 75.78%] [G loss: 1.767648]\n",
      "epoch:13 step:10307 [D loss: 0.672970, acc: 56.25%] [G loss: 1.817493]\n",
      "epoch:13 step:10308 [D loss: 0.484040, acc: 77.34%] [G loss: 1.508816]\n",
      "epoch:13 step:10309 [D loss: 0.557929, acc: 77.34%] [G loss: 2.093191]\n",
      "epoch:13 step:10310 [D loss: 0.662400, acc: 56.25%] [G loss: 1.725135]\n",
      "epoch:13 step:10311 [D loss: 1.005295, acc: 17.19%] [G loss: 1.612220]\n",
      "epoch:13 step:10312 [D loss: 0.540251, acc: 78.12%] [G loss: 1.802380]\n",
      "epoch:13 step:10313 [D loss: 0.972019, acc: 27.34%] [G loss: 1.399775]\n",
      "epoch:13 step:10314 [D loss: 0.664517, acc: 60.16%] [G loss: 1.656271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10315 [D loss: 0.336720, acc: 96.88%] [G loss: 1.918386]\n",
      "epoch:13 step:10316 [D loss: 0.722402, acc: 51.56%] [G loss: 1.695380]\n",
      "epoch:13 step:10317 [D loss: 0.566335, acc: 77.34%] [G loss: 1.629093]\n",
      "epoch:13 step:10318 [D loss: 0.555329, acc: 78.91%] [G loss: 1.688105]\n",
      "epoch:13 step:10319 [D loss: 0.979617, acc: 19.53%] [G loss: 1.378297]\n",
      "epoch:13 step:10320 [D loss: 0.539196, acc: 82.81%] [G loss: 1.946845]\n",
      "epoch:13 step:10321 [D loss: 0.534493, acc: 79.69%] [G loss: 1.649566]\n",
      "epoch:13 step:10322 [D loss: 0.675388, acc: 55.47%] [G loss: 1.650773]\n",
      "epoch:13 step:10323 [D loss: 0.556482, acc: 79.69%] [G loss: 1.754835]\n",
      "epoch:13 step:10324 [D loss: 0.644966, acc: 67.19%] [G loss: 1.869095]\n",
      "epoch:13 step:10325 [D loss: 0.568771, acc: 64.84%] [G loss: 1.596092]\n",
      "epoch:13 step:10326 [D loss: 0.884738, acc: 28.12%] [G loss: 1.283148]\n",
      "epoch:13 step:10327 [D loss: 0.733298, acc: 53.12%] [G loss: 1.787664]\n",
      "epoch:13 step:10328 [D loss: 0.528908, acc: 83.59%] [G loss: 1.804477]\n",
      "epoch:13 step:10329 [D loss: 0.497760, acc: 89.84%] [G loss: 1.816754]\n",
      "epoch:13 step:10330 [D loss: 0.446288, acc: 87.50%] [G loss: 1.989079]\n",
      "epoch:13 step:10331 [D loss: 0.917926, acc: 21.09%] [G loss: 1.573898]\n",
      "epoch:13 step:10332 [D loss: 0.872037, acc: 25.78%] [G loss: 1.494364]\n",
      "epoch:13 step:10333 [D loss: 0.726155, acc: 47.66%] [G loss: 1.614268]\n",
      "epoch:13 step:10334 [D loss: 0.372951, acc: 92.97%] [G loss: 2.344033]\n",
      "epoch:13 step:10335 [D loss: 0.670250, acc: 55.47%] [G loss: 1.847059]\n",
      "epoch:13 step:10336 [D loss: 0.645479, acc: 59.38%] [G loss: 1.653319]\n",
      "epoch:13 step:10337 [D loss: 0.806242, acc: 34.38%] [G loss: 1.367295]\n",
      "epoch:13 step:10338 [D loss: 0.682510, acc: 59.38%] [G loss: 1.729188]\n",
      "epoch:13 step:10339 [D loss: 0.628702, acc: 64.06%] [G loss: 1.834071]\n",
      "epoch:13 step:10340 [D loss: 0.608732, acc: 71.88%] [G loss: 1.623391]\n",
      "epoch:13 step:10341 [D loss: 0.757774, acc: 46.09%] [G loss: 1.628433]\n",
      "epoch:13 step:10342 [D loss: 0.632784, acc: 64.84%] [G loss: 1.572953]\n",
      "epoch:13 step:10343 [D loss: 0.600027, acc: 70.31%] [G loss: 1.861038]\n",
      "epoch:13 step:10344 [D loss: 0.651630, acc: 66.41%] [G loss: 1.679547]\n",
      "epoch:13 step:10345 [D loss: 0.693344, acc: 50.00%] [G loss: 1.957611]\n",
      "epoch:13 step:10346 [D loss: 0.385163, acc: 82.03%] [G loss: 1.855443]\n",
      "epoch:13 step:10347 [D loss: 0.662508, acc: 59.38%] [G loss: 1.669348]\n",
      "epoch:13 step:10348 [D loss: 0.647886, acc: 63.28%] [G loss: 1.839365]\n",
      "epoch:13 step:10349 [D loss: 0.894011, acc: 25.00%] [G loss: 1.189653]\n",
      "epoch:13 step:10350 [D loss: 0.644691, acc: 66.41%] [G loss: 1.732004]\n",
      "epoch:13 step:10351 [D loss: 0.607908, acc: 71.88%] [G loss: 1.562981]\n",
      "epoch:13 step:10352 [D loss: 0.710414, acc: 46.88%] [G loss: 1.779845]\n",
      "epoch:13 step:10353 [D loss: 0.451093, acc: 92.97%] [G loss: 2.016728]\n",
      "epoch:13 step:10354 [D loss: 0.560005, acc: 75.78%] [G loss: 1.944620]\n",
      "epoch:13 step:10355 [D loss: 1.008314, acc: 12.50%] [G loss: 1.751508]\n",
      "epoch:13 step:10356 [D loss: 0.652609, acc: 60.94%] [G loss: 1.566933]\n",
      "epoch:13 step:10357 [D loss: 0.841051, acc: 34.38%] [G loss: 1.410344]\n",
      "epoch:13 step:10358 [D loss: 1.177063, acc: 14.06%] [G loss: 1.240708]\n",
      "epoch:13 step:10359 [D loss: 0.714907, acc: 57.03%] [G loss: 1.642234]\n",
      "epoch:13 step:10360 [D loss: 0.604060, acc: 67.97%] [G loss: 1.624964]\n",
      "epoch:13 step:10361 [D loss: 0.546803, acc: 85.16%] [G loss: 1.847108]\n",
      "epoch:13 step:10362 [D loss: 0.547236, acc: 71.09%] [G loss: 1.617822]\n",
      "epoch:13 step:10363 [D loss: 0.790635, acc: 39.06%] [G loss: 1.410687]\n",
      "epoch:13 step:10364 [D loss: 0.513244, acc: 85.94%] [G loss: 1.970271]\n",
      "epoch:13 step:10365 [D loss: 0.717111, acc: 49.22%] [G loss: 1.796015]\n",
      "epoch:13 step:10366 [D loss: 0.564526, acc: 76.56%] [G loss: 1.710840]\n",
      "epoch:13 step:10367 [D loss: 0.439527, acc: 93.75%] [G loss: 2.056249]\n",
      "epoch:13 step:10368 [D loss: 0.783878, acc: 39.84%] [G loss: 1.649632]\n",
      "epoch:13 step:10369 [D loss: 0.666069, acc: 61.72%] [G loss: 1.767296]\n",
      "epoch:13 step:10370 [D loss: 0.870682, acc: 37.50%] [G loss: 1.497432]\n",
      "epoch:13 step:10371 [D loss: 0.524486, acc: 84.38%] [G loss: 1.970454]\n",
      "epoch:13 step:10372 [D loss: 0.565321, acc: 76.56%] [G loss: 1.935820]\n",
      "epoch:13 step:10373 [D loss: 0.697102, acc: 55.47%] [G loss: 1.778873]\n",
      "epoch:13 step:10374 [D loss: 0.705195, acc: 56.25%] [G loss: 1.502071]\n",
      "epoch:13 step:10375 [D loss: 0.676400, acc: 56.25%] [G loss: 1.784072]\n",
      "epoch:13 step:10376 [D loss: 0.708130, acc: 50.00%] [G loss: 1.580026]\n",
      "epoch:13 step:10377 [D loss: 0.759329, acc: 42.97%] [G loss: 1.641138]\n",
      "epoch:13 step:10378 [D loss: 0.572405, acc: 81.25%] [G loss: 1.646319]\n",
      "epoch:13 step:10379 [D loss: 0.814286, acc: 33.59%] [G loss: 1.437979]\n",
      "epoch:13 step:10380 [D loss: 0.557652, acc: 78.91%] [G loss: 1.604532]\n",
      "epoch:13 step:10381 [D loss: 0.567077, acc: 76.56%] [G loss: 1.615809]\n",
      "epoch:13 step:10382 [D loss: 0.600409, acc: 71.09%] [G loss: 1.631668]\n",
      "epoch:13 step:10383 [D loss: 0.774829, acc: 46.88%] [G loss: 1.569372]\n",
      "epoch:13 step:10384 [D loss: 0.527559, acc: 84.38%] [G loss: 1.842838]\n",
      "epoch:13 step:10385 [D loss: 0.830906, acc: 37.50%] [G loss: 1.284115]\n",
      "epoch:13 step:10386 [D loss: 0.659759, acc: 61.72%] [G loss: 1.811860]\n",
      "epoch:13 step:10387 [D loss: 0.964126, acc: 33.59%] [G loss: 1.637187]\n",
      "epoch:13 step:10388 [D loss: 0.712532, acc: 50.78%] [G loss: 1.649001]\n",
      "epoch:13 step:10389 [D loss: 0.737725, acc: 43.75%] [G loss: 1.742220]\n",
      "epoch:13 step:10390 [D loss: 0.477499, acc: 90.62%] [G loss: 1.837637]\n",
      "epoch:13 step:10391 [D loss: 0.661941, acc: 59.38%] [G loss: 1.579994]\n",
      "epoch:13 step:10392 [D loss: 0.694820, acc: 53.12%] [G loss: 1.601825]\n",
      "epoch:13 step:10393 [D loss: 0.751437, acc: 42.19%] [G loss: 1.738203]\n",
      "epoch:13 step:10394 [D loss: 0.519676, acc: 78.12%] [G loss: 1.588614]\n",
      "epoch:13 step:10395 [D loss: 0.831028, acc: 39.84%] [G loss: 1.777652]\n",
      "epoch:13 step:10396 [D loss: 0.643347, acc: 67.19%] [G loss: 1.497667]\n",
      "epoch:13 step:10397 [D loss: 0.739208, acc: 51.56%] [G loss: 1.691726]\n",
      "epoch:13 step:10398 [D loss: 0.823814, acc: 28.91%] [G loss: 1.526006]\n",
      "epoch:13 step:10399 [D loss: 0.780985, acc: 35.94%] [G loss: 1.590220]\n",
      "epoch:13 step:10400 [D loss: 0.839112, acc: 41.41%] [G loss: 1.480399]\n",
      "epoch:13 step:10401 [D loss: 0.649240, acc: 62.50%] [G loss: 1.745756]\n",
      "epoch:13 step:10402 [D loss: 0.784596, acc: 39.84%] [G loss: 1.667492]\n",
      "epoch:13 step:10403 [D loss: 0.660221, acc: 59.38%] [G loss: 1.771596]\n",
      "epoch:13 step:10404 [D loss: 0.615104, acc: 67.97%] [G loss: 1.710637]\n",
      "epoch:13 step:10405 [D loss: 0.623079, acc: 66.41%] [G loss: 1.703262]\n",
      "epoch:13 step:10406 [D loss: 0.693182, acc: 53.12%] [G loss: 1.661615]\n",
      "epoch:13 step:10407 [D loss: 0.703766, acc: 53.12%] [G loss: 1.541913]\n",
      "epoch:13 step:10408 [D loss: 0.795421, acc: 42.19%] [G loss: 1.680487]\n",
      "epoch:13 step:10409 [D loss: 0.689441, acc: 50.78%] [G loss: 1.743594]\n",
      "epoch:13 step:10410 [D loss: 0.588821, acc: 70.31%] [G loss: 1.593785]\n",
      "epoch:13 step:10411 [D loss: 0.654551, acc: 62.50%] [G loss: 1.770884]\n",
      "epoch:13 step:10412 [D loss: 0.778679, acc: 36.72%] [G loss: 1.580287]\n",
      "epoch:13 step:10413 [D loss: 0.749058, acc: 46.09%] [G loss: 1.820893]\n",
      "epoch:13 step:10414 [D loss: 0.838223, acc: 34.38%] [G loss: 1.535522]\n",
      "epoch:13 step:10415 [D loss: 0.541447, acc: 79.69%] [G loss: 1.685076]\n",
      "epoch:13 step:10416 [D loss: 0.855283, acc: 22.66%] [G loss: 1.474779]\n",
      "epoch:13 step:10417 [D loss: 0.756585, acc: 47.66%] [G loss: 1.485964]\n",
      "epoch:13 step:10418 [D loss: 0.696382, acc: 63.28%] [G loss: 1.737951]\n",
      "epoch:13 step:10419 [D loss: 0.679818, acc: 55.47%] [G loss: 1.824101]\n",
      "epoch:13 step:10420 [D loss: 0.925736, acc: 25.78%] [G loss: 1.463858]\n",
      "epoch:13 step:10421 [D loss: 0.649624, acc: 67.19%] [G loss: 1.500839]\n",
      "epoch:13 step:10422 [D loss: 0.644405, acc: 55.47%] [G loss: 1.506320]\n",
      "epoch:13 step:10423 [D loss: 0.688802, acc: 57.03%] [G loss: 1.636059]\n",
      "epoch:13 step:10424 [D loss: 0.814798, acc: 34.38%] [G loss: 1.400810]\n",
      "epoch:13 step:10425 [D loss: 0.686793, acc: 50.78%] [G loss: 1.785701]\n",
      "epoch:13 step:10426 [D loss: 0.671768, acc: 55.47%] [G loss: 1.657994]\n",
      "epoch:13 step:10427 [D loss: 0.808454, acc: 33.59%] [G loss: 1.649190]\n",
      "epoch:13 step:10428 [D loss: 0.633655, acc: 63.28%] [G loss: 1.604643]\n",
      "epoch:13 step:10429 [D loss: 0.675498, acc: 53.91%] [G loss: 1.523903]\n",
      "epoch:13 step:10430 [D loss: 0.945503, acc: 16.41%] [G loss: 1.574547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10431 [D loss: 0.658449, acc: 57.03%] [G loss: 1.771380]\n",
      "epoch:13 step:10432 [D loss: 0.658516, acc: 60.94%] [G loss: 1.624663]\n",
      "epoch:13 step:10433 [D loss: 0.706584, acc: 52.34%] [G loss: 1.674448]\n",
      "epoch:13 step:10434 [D loss: 0.600811, acc: 72.66%] [G loss: 1.706751]\n",
      "epoch:13 step:10435 [D loss: 0.769299, acc: 35.94%] [G loss: 1.428469]\n",
      "epoch:13 step:10436 [D loss: 0.768711, acc: 34.38%] [G loss: 1.522611]\n",
      "epoch:13 step:10437 [D loss: 0.678296, acc: 57.03%] [G loss: 1.662215]\n",
      "epoch:13 step:10438 [D loss: 0.553675, acc: 83.59%] [G loss: 1.799258]\n",
      "epoch:13 step:10439 [D loss: 0.707738, acc: 50.78%] [G loss: 1.835780]\n",
      "epoch:13 step:10440 [D loss: 0.616238, acc: 63.28%] [G loss: 1.559710]\n",
      "epoch:13 step:10441 [D loss: 0.710002, acc: 49.22%] [G loss: 1.619186]\n",
      "epoch:13 step:10442 [D loss: 0.605430, acc: 66.41%] [G loss: 1.653785]\n",
      "epoch:13 step:10443 [D loss: 0.645854, acc: 60.94%] [G loss: 1.619792]\n",
      "epoch:13 step:10444 [D loss: 0.803772, acc: 36.72%] [G loss: 1.355759]\n",
      "epoch:13 step:10445 [D loss: 0.684067, acc: 54.69%] [G loss: 1.531835]\n",
      "epoch:13 step:10446 [D loss: 0.765776, acc: 37.50%] [G loss: 1.602575]\n",
      "epoch:13 step:10447 [D loss: 0.610222, acc: 66.41%] [G loss: 1.608071]\n",
      "epoch:13 step:10448 [D loss: 0.714111, acc: 46.88%] [G loss: 1.675604]\n",
      "epoch:13 step:10449 [D loss: 0.592321, acc: 73.44%] [G loss: 1.849567]\n",
      "epoch:13 step:10450 [D loss: 0.741459, acc: 42.97%] [G loss: 1.409114]\n",
      "epoch:13 step:10451 [D loss: 0.731008, acc: 41.41%] [G loss: 1.457033]\n",
      "epoch:13 step:10452 [D loss: 0.726123, acc: 50.78%] [G loss: 1.350282]\n",
      "epoch:13 step:10453 [D loss: 0.839071, acc: 30.47%] [G loss: 1.499323]\n",
      "epoch:13 step:10454 [D loss: 0.692668, acc: 57.03%] [G loss: 1.872598]\n",
      "epoch:13 step:10455 [D loss: 0.663475, acc: 57.81%] [G loss: 1.678432]\n",
      "epoch:13 step:10456 [D loss: 0.749598, acc: 41.41%] [G loss: 1.510534]\n",
      "epoch:13 step:10457 [D loss: 0.584515, acc: 76.56%] [G loss: 1.919975]\n",
      "epoch:13 step:10458 [D loss: 0.797787, acc: 35.16%] [G loss: 1.605421]\n",
      "epoch:13 step:10459 [D loss: 0.614235, acc: 74.22%] [G loss: 1.792392]\n",
      "epoch:13 step:10460 [D loss: 0.584930, acc: 65.62%] [G loss: 1.499563]\n",
      "epoch:13 step:10461 [D loss: 0.753478, acc: 39.06%] [G loss: 1.863080]\n",
      "epoch:13 step:10462 [D loss: 0.729226, acc: 42.97%] [G loss: 1.570682]\n",
      "epoch:13 step:10463 [D loss: 0.569272, acc: 83.59%] [G loss: 1.812881]\n",
      "epoch:13 step:10464 [D loss: 0.669558, acc: 57.03%] [G loss: 1.615209]\n",
      "epoch:13 step:10465 [D loss: 0.543386, acc: 75.78%] [G loss: 1.850977]\n",
      "epoch:13 step:10466 [D loss: 0.705670, acc: 50.00%] [G loss: 1.732779]\n",
      "epoch:13 step:10467 [D loss: 0.703360, acc: 53.12%] [G loss: 1.603352]\n",
      "epoch:13 step:10468 [D loss: 0.702668, acc: 57.81%] [G loss: 1.609463]\n",
      "epoch:13 step:10469 [D loss: 0.650383, acc: 59.38%] [G loss: 1.574160]\n",
      "epoch:13 step:10470 [D loss: 0.625983, acc: 62.50%] [G loss: 1.825907]\n",
      "epoch:13 step:10471 [D loss: 0.595452, acc: 76.56%] [G loss: 1.928642]\n",
      "epoch:13 step:10472 [D loss: 0.780082, acc: 38.28%] [G loss: 1.598773]\n",
      "epoch:13 step:10473 [D loss: 0.748429, acc: 49.22%] [G loss: 1.405666]\n",
      "epoch:13 step:10474 [D loss: 0.720847, acc: 51.56%] [G loss: 1.640237]\n",
      "epoch:13 step:10475 [D loss: 0.615439, acc: 66.41%] [G loss: 1.668145]\n",
      "epoch:13 step:10476 [D loss: 0.736098, acc: 45.31%] [G loss: 1.668863]\n",
      "epoch:13 step:10477 [D loss: 0.585356, acc: 75.00%] [G loss: 1.593847]\n",
      "epoch:13 step:10478 [D loss: 0.585636, acc: 70.31%] [G loss: 1.469622]\n",
      "epoch:13 step:10479 [D loss: 0.595216, acc: 72.66%] [G loss: 1.549901]\n",
      "epoch:13 step:10480 [D loss: 0.619913, acc: 66.41%] [G loss: 1.736559]\n",
      "epoch:13 step:10481 [D loss: 0.667049, acc: 58.59%] [G loss: 1.745375]\n",
      "epoch:13 step:10482 [D loss: 0.489588, acc: 89.06%] [G loss: 1.730476]\n",
      "epoch:13 step:10483 [D loss: 0.371751, acc: 92.19%] [G loss: 1.792421]\n",
      "epoch:13 step:10484 [D loss: 0.827886, acc: 33.59%] [G loss: 1.402359]\n",
      "epoch:13 step:10485 [D loss: 0.563140, acc: 67.97%] [G loss: 1.736578]\n",
      "epoch:13 step:10486 [D loss: 0.570604, acc: 78.12%] [G loss: 1.537854]\n",
      "epoch:13 step:10487 [D loss: 0.665318, acc: 57.03%] [G loss: 1.777359]\n",
      "epoch:13 step:10488 [D loss: 0.675738, acc: 56.25%] [G loss: 1.476231]\n",
      "epoch:13 step:10489 [D loss: 0.636484, acc: 60.16%] [G loss: 1.810470]\n",
      "epoch:13 step:10490 [D loss: 0.852756, acc: 31.25%] [G loss: 1.361753]\n",
      "epoch:13 step:10491 [D loss: 0.921068, acc: 23.44%] [G loss: 1.489092]\n",
      "epoch:13 step:10492 [D loss: 0.759503, acc: 39.84%] [G loss: 1.552871]\n",
      "epoch:13 step:10493 [D loss: 0.699104, acc: 53.91%] [G loss: 1.749529]\n",
      "epoch:13 step:10494 [D loss: 0.759118, acc: 46.09%] [G loss: 1.540385]\n",
      "epoch:13 step:10495 [D loss: 0.533701, acc: 76.56%] [G loss: 1.823721]\n",
      "epoch:13 step:10496 [D loss: 0.745974, acc: 40.62%] [G loss: 1.800304]\n",
      "epoch:13 step:10497 [D loss: 0.808820, acc: 38.28%] [G loss: 1.545517]\n",
      "epoch:13 step:10498 [D loss: 0.524451, acc: 83.59%] [G loss: 1.751563]\n",
      "epoch:13 step:10499 [D loss: 0.821636, acc: 32.03%] [G loss: 1.376759]\n",
      "epoch:13 step:10500 [D loss: 0.591187, acc: 76.56%] [G loss: 1.773833]\n",
      "epoch:13 step:10501 [D loss: 0.728161, acc: 45.31%] [G loss: 1.673023]\n",
      "epoch:13 step:10502 [D loss: 0.608613, acc: 67.97%] [G loss: 1.639470]\n",
      "epoch:13 step:10503 [D loss: 0.692149, acc: 54.69%] [G loss: 1.700144]\n",
      "epoch:13 step:10504 [D loss: 0.713937, acc: 50.78%] [G loss: 1.451808]\n",
      "epoch:13 step:10505 [D loss: 0.657331, acc: 63.28%] [G loss: 1.704216]\n",
      "epoch:13 step:10506 [D loss: 0.688441, acc: 57.03%] [G loss: 1.595435]\n",
      "epoch:13 step:10507 [D loss: 0.727535, acc: 53.12%] [G loss: 1.585673]\n",
      "epoch:13 step:10508 [D loss: 0.647297, acc: 60.16%] [G loss: 1.485644]\n",
      "epoch:13 step:10509 [D loss: 0.674686, acc: 57.81%] [G loss: 1.711103]\n",
      "epoch:13 step:10510 [D loss: 0.668910, acc: 57.81%] [G loss: 1.680857]\n",
      "epoch:13 step:10511 [D loss: 0.587825, acc: 71.88%] [G loss: 1.962069]\n",
      "epoch:13 step:10512 [D loss: 0.598671, acc: 69.53%] [G loss: 1.665642]\n",
      "epoch:13 step:10513 [D loss: 0.753989, acc: 37.50%] [G loss: 1.626318]\n",
      "epoch:13 step:10514 [D loss: 0.687950, acc: 54.69%] [G loss: 1.749195]\n",
      "epoch:13 step:10515 [D loss: 0.497825, acc: 89.06%] [G loss: 1.892423]\n",
      "epoch:13 step:10516 [D loss: 0.768321, acc: 46.88%] [G loss: 1.672422]\n",
      "epoch:13 step:10517 [D loss: 0.688082, acc: 57.81%] [G loss: 1.820020]\n",
      "epoch:13 step:10518 [D loss: 0.651793, acc: 58.59%] [G loss: 1.713162]\n",
      "epoch:13 step:10519 [D loss: 0.672201, acc: 54.69%] [G loss: 1.681842]\n",
      "epoch:13 step:10520 [D loss: 0.749443, acc: 43.75%] [G loss: 1.640803]\n",
      "epoch:13 step:10521 [D loss: 0.639961, acc: 67.19%] [G loss: 1.633237]\n",
      "epoch:13 step:10522 [D loss: 0.623756, acc: 73.44%] [G loss: 1.664270]\n",
      "epoch:13 step:10523 [D loss: 0.638442, acc: 69.53%] [G loss: 1.737420]\n",
      "epoch:13 step:10524 [D loss: 0.563287, acc: 72.66%] [G loss: 1.692526]\n",
      "epoch:13 step:10525 [D loss: 0.698990, acc: 57.03%] [G loss: 1.586631]\n",
      "epoch:13 step:10526 [D loss: 1.051097, acc: 8.59%] [G loss: 1.314507]\n",
      "epoch:13 step:10527 [D loss: 0.610772, acc: 71.09%] [G loss: 1.908216]\n",
      "epoch:13 step:10528 [D loss: 0.663320, acc: 60.16%] [G loss: 1.592770]\n",
      "epoch:13 step:10529 [D loss: 0.622070, acc: 67.19%] [G loss: 1.791068]\n",
      "epoch:13 step:10530 [D loss: 0.498216, acc: 75.78%] [G loss: 1.736642]\n",
      "epoch:13 step:10531 [D loss: 0.878869, acc: 24.22%] [G loss: 1.343632]\n",
      "epoch:13 step:10532 [D loss: 0.619766, acc: 67.97%] [G loss: 1.771515]\n",
      "epoch:13 step:10533 [D loss: 0.701725, acc: 57.81%] [G loss: 1.593527]\n",
      "epoch:13 step:10534 [D loss: 0.585946, acc: 74.22%] [G loss: 1.754337]\n",
      "epoch:13 step:10535 [D loss: 0.563323, acc: 75.78%] [G loss: 1.691378]\n",
      "epoch:13 step:10536 [D loss: 0.899636, acc: 23.44%] [G loss: 1.490375]\n",
      "epoch:13 step:10537 [D loss: 0.589088, acc: 75.78%] [G loss: 1.725930]\n",
      "epoch:13 step:10538 [D loss: 0.761091, acc: 41.41%] [G loss: 1.635016]\n",
      "epoch:13 step:10539 [D loss: 0.614117, acc: 70.31%] [G loss: 1.631362]\n",
      "epoch:13 step:10540 [D loss: 0.833472, acc: 31.25%] [G loss: 1.703238]\n",
      "epoch:13 step:10541 [D loss: 0.730634, acc: 46.09%] [G loss: 1.497044]\n",
      "epoch:13 step:10542 [D loss: 0.584136, acc: 78.91%] [G loss: 1.773417]\n",
      "epoch:13 step:10543 [D loss: 0.586695, acc: 74.22%] [G loss: 1.904658]\n",
      "epoch:13 step:10544 [D loss: 0.812348, acc: 40.62%] [G loss: 1.725280]\n",
      "epoch:13 step:10545 [D loss: 0.484991, acc: 87.50%] [G loss: 1.981063]\n",
      "epoch:13 step:10546 [D loss: 0.677751, acc: 53.12%] [G loss: 1.640994]\n",
      "epoch:13 step:10547 [D loss: 0.539942, acc: 81.25%] [G loss: 1.936739]\n",
      "epoch:13 step:10548 [D loss: 0.740596, acc: 48.44%] [G loss: 1.604219]\n",
      "epoch:13 step:10549 [D loss: 0.516290, acc: 78.12%] [G loss: 1.624342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10550 [D loss: 0.731346, acc: 55.47%] [G loss: 1.767809]\n",
      "epoch:13 step:10551 [D loss: 0.747860, acc: 50.78%] [G loss: 1.857852]\n",
      "epoch:13 step:10552 [D loss: 0.702447, acc: 57.03%] [G loss: 1.727189]\n",
      "epoch:13 step:10553 [D loss: 0.633625, acc: 59.38%] [G loss: 1.863474]\n",
      "epoch:13 step:10554 [D loss: 0.614387, acc: 67.97%] [G loss: 1.811912]\n",
      "epoch:13 step:10555 [D loss: 0.801264, acc: 37.50%] [G loss: 1.559337]\n",
      "epoch:13 step:10556 [D loss: 0.641345, acc: 58.59%] [G loss: 1.759970]\n",
      "epoch:13 step:10557 [D loss: 0.508613, acc: 85.16%] [G loss: 1.688717]\n",
      "epoch:13 step:10558 [D loss: 0.599935, acc: 71.09%] [G loss: 1.689836]\n",
      "epoch:13 step:10559 [D loss: 0.652351, acc: 62.50%] [G loss: 1.669563]\n",
      "epoch:13 step:10560 [D loss: 0.666177, acc: 57.03%] [G loss: 1.573071]\n",
      "epoch:13 step:10561 [D loss: 0.521237, acc: 88.28%] [G loss: 1.680913]\n",
      "epoch:13 step:10562 [D loss: 0.670544, acc: 64.84%] [G loss: 1.576220]\n",
      "epoch:13 step:10563 [D loss: 0.793358, acc: 32.03%] [G loss: 1.715537]\n",
      "epoch:13 step:10564 [D loss: 1.042590, acc: 16.41%] [G loss: 1.687614]\n",
      "epoch:13 step:10565 [D loss: 0.732222, acc: 53.91%] [G loss: 1.935830]\n",
      "epoch:13 step:10566 [D loss: 0.789799, acc: 43.75%] [G loss: 1.507774]\n",
      "epoch:13 step:10567 [D loss: 0.619058, acc: 69.53%] [G loss: 1.558986]\n",
      "epoch:13 step:10568 [D loss: 0.656959, acc: 59.38%] [G loss: 1.628305]\n",
      "epoch:13 step:10569 [D loss: 0.728553, acc: 48.44%] [G loss: 1.722808]\n",
      "epoch:13 step:10570 [D loss: 0.566563, acc: 71.09%] [G loss: 1.849619]\n",
      "epoch:13 step:10571 [D loss: 0.625276, acc: 66.41%] [G loss: 1.542592]\n",
      "epoch:13 step:10572 [D loss: 0.595673, acc: 73.44%] [G loss: 1.687752]\n",
      "epoch:13 step:10573 [D loss: 0.733122, acc: 45.31%] [G loss: 1.443857]\n",
      "epoch:13 step:10574 [D loss: 0.699452, acc: 57.81%] [G loss: 1.571581]\n",
      "epoch:13 step:10575 [D loss: 0.562798, acc: 75.78%] [G loss: 1.981378]\n",
      "epoch:13 step:10576 [D loss: 0.679328, acc: 59.38%] [G loss: 1.682178]\n",
      "epoch:13 step:10577 [D loss: 0.803448, acc: 50.00%] [G loss: 1.954735]\n",
      "epoch:13 step:10578 [D loss: 0.574038, acc: 75.00%] [G loss: 1.598435]\n",
      "epoch:13 step:10579 [D loss: 0.889019, acc: 21.88%] [G loss: 1.684934]\n",
      "epoch:13 step:10580 [D loss: 0.772409, acc: 49.22%] [G loss: 1.451195]\n",
      "epoch:13 step:10581 [D loss: 0.669415, acc: 55.47%] [G loss: 1.697406]\n",
      "epoch:13 step:10582 [D loss: 0.607485, acc: 66.41%] [G loss: 1.713468]\n",
      "epoch:13 step:10583 [D loss: 0.754534, acc: 54.69%] [G loss: 1.648654]\n",
      "epoch:13 step:10584 [D loss: 0.858369, acc: 20.31%] [G loss: 1.473684]\n",
      "epoch:13 step:10585 [D loss: 0.639959, acc: 64.84%] [G loss: 1.636761]\n",
      "epoch:13 step:10586 [D loss: 0.502661, acc: 89.06%] [G loss: 1.792846]\n",
      "epoch:13 step:10587 [D loss: 0.742689, acc: 39.84%] [G loss: 1.523436]\n",
      "epoch:13 step:10588 [D loss: 0.648955, acc: 57.03%] [G loss: 1.530806]\n",
      "epoch:13 step:10589 [D loss: 0.761503, acc: 42.19%] [G loss: 1.425625]\n",
      "epoch:13 step:10590 [D loss: 0.604437, acc: 70.31%] [G loss: 1.348193]\n",
      "epoch:13 step:10591 [D loss: 0.778689, acc: 46.88%] [G loss: 1.716018]\n",
      "epoch:13 step:10592 [D loss: 0.714509, acc: 53.12%] [G loss: 1.562336]\n",
      "epoch:13 step:10593 [D loss: 0.720701, acc: 50.78%] [G loss: 1.363604]\n",
      "epoch:13 step:10594 [D loss: 0.789051, acc: 34.38%] [G loss: 1.391608]\n",
      "epoch:13 step:10595 [D loss: 0.570724, acc: 75.00%] [G loss: 1.725718]\n",
      "epoch:13 step:10596 [D loss: 0.658302, acc: 63.28%] [G loss: 1.436708]\n",
      "epoch:13 step:10597 [D loss: 0.653968, acc: 64.06%] [G loss: 1.639478]\n",
      "epoch:13 step:10598 [D loss: 0.824347, acc: 28.12%] [G loss: 1.274584]\n",
      "epoch:13 step:10599 [D loss: 0.766841, acc: 41.41%] [G loss: 1.561460]\n",
      "epoch:13 step:10600 [D loss: 0.703152, acc: 56.25%] [G loss: 1.609856]\n",
      "epoch:13 step:10601 [D loss: 0.652853, acc: 63.28%] [G loss: 1.673707]\n",
      "epoch:13 step:10602 [D loss: 0.782332, acc: 40.62%] [G loss: 1.687936]\n",
      "epoch:13 step:10603 [D loss: 0.600408, acc: 71.88%] [G loss: 1.694142]\n",
      "epoch:13 step:10604 [D loss: 0.683026, acc: 59.38%] [G loss: 1.763612]\n",
      "epoch:13 step:10605 [D loss: 0.725596, acc: 48.44%] [G loss: 1.691510]\n",
      "epoch:13 step:10606 [D loss: 0.638069, acc: 67.19%] [G loss: 1.849436]\n",
      "epoch:13 step:10607 [D loss: 0.653729, acc: 63.28%] [G loss: 1.498826]\n",
      "epoch:13 step:10608 [D loss: 0.671003, acc: 51.56%] [G loss: 1.455734]\n",
      "epoch:13 step:10609 [D loss: 0.628276, acc: 63.28%] [G loss: 1.467263]\n",
      "epoch:13 step:10610 [D loss: 0.597278, acc: 73.44%] [G loss: 1.633158]\n",
      "epoch:13 step:10611 [D loss: 0.648219, acc: 64.06%] [G loss: 1.563315]\n",
      "epoch:13 step:10612 [D loss: 0.578554, acc: 78.91%] [G loss: 1.662870]\n",
      "epoch:13 step:10613 [D loss: 0.537009, acc: 83.59%] [G loss: 1.824766]\n",
      "epoch:13 step:10614 [D loss: 0.570306, acc: 82.03%] [G loss: 1.410453]\n",
      "epoch:13 step:10615 [D loss: 0.766100, acc: 37.50%] [G loss: 1.518857]\n",
      "epoch:13 step:10616 [D loss: 0.721077, acc: 53.12%] [G loss: 1.674864]\n",
      "epoch:13 step:10617 [D loss: 0.681811, acc: 65.62%] [G loss: 1.658749]\n",
      "epoch:13 step:10618 [D loss: 0.773785, acc: 33.59%] [G loss: 1.467862]\n",
      "epoch:13 step:10619 [D loss: 0.814219, acc: 35.94%] [G loss: 1.514291]\n",
      "epoch:13 step:10620 [D loss: 0.503948, acc: 84.38%] [G loss: 1.629044]\n",
      "epoch:13 step:10621 [D loss: 0.713934, acc: 50.78%] [G loss: 1.478279]\n",
      "epoch:13 step:10622 [D loss: 0.611384, acc: 70.31%] [G loss: 1.707805]\n",
      "epoch:13 step:10623 [D loss: 0.712028, acc: 53.12%] [G loss: 1.693282]\n",
      "epoch:13 step:10624 [D loss: 0.716743, acc: 47.66%] [G loss: 1.648839]\n",
      "epoch:13 step:10625 [D loss: 0.624565, acc: 64.06%] [G loss: 1.591351]\n",
      "epoch:13 step:10626 [D loss: 0.920805, acc: 18.75%] [G loss: 1.619959]\n",
      "epoch:13 step:10627 [D loss: 0.904693, acc: 16.41%] [G loss: 1.331298]\n",
      "epoch:13 step:10628 [D loss: 0.771522, acc: 42.97%] [G loss: 1.734382]\n",
      "epoch:13 step:10629 [D loss: 0.578763, acc: 76.56%] [G loss: 1.693694]\n",
      "epoch:13 step:10630 [D loss: 0.808732, acc: 34.38%] [G loss: 1.556919]\n",
      "epoch:13 step:10631 [D loss: 0.588674, acc: 80.47%] [G loss: 1.747955]\n",
      "epoch:13 step:10632 [D loss: 0.623758, acc: 74.22%] [G loss: 1.656556]\n",
      "epoch:13 step:10633 [D loss: 0.641846, acc: 61.72%] [G loss: 1.679814]\n",
      "epoch:13 step:10634 [D loss: 0.418369, acc: 76.56%] [G loss: 1.600527]\n",
      "epoch:13 step:10635 [D loss: 0.918259, acc: 18.75%] [G loss: 1.541429]\n",
      "epoch:13 step:10636 [D loss: 0.630241, acc: 64.06%] [G loss: 1.840406]\n",
      "epoch:13 step:10637 [D loss: 0.676769, acc: 57.81%] [G loss: 1.670334]\n",
      "epoch:13 step:10638 [D loss: 0.730992, acc: 52.34%] [G loss: 1.648085]\n",
      "epoch:13 step:10639 [D loss: 0.815429, acc: 32.81%] [G loss: 1.514489]\n",
      "epoch:13 step:10640 [D loss: 0.676371, acc: 55.47%] [G loss: 1.554011]\n",
      "epoch:13 step:10641 [D loss: 0.659092, acc: 60.94%] [G loss: 1.629784]\n",
      "epoch:13 step:10642 [D loss: 0.688838, acc: 60.94%] [G loss: 1.607699]\n",
      "epoch:13 step:10643 [D loss: 0.559675, acc: 82.03%] [G loss: 1.504890]\n",
      "epoch:13 step:10644 [D loss: 0.604089, acc: 68.75%] [G loss: 1.667001]\n",
      "epoch:13 step:10645 [D loss: 0.830969, acc: 39.06%] [G loss: 1.472073]\n",
      "epoch:13 step:10646 [D loss: 0.646979, acc: 61.72%] [G loss: 1.716985]\n",
      "epoch:13 step:10647 [D loss: 0.680476, acc: 58.59%] [G loss: 1.506908]\n",
      "epoch:13 step:10648 [D loss: 0.712616, acc: 49.22%] [G loss: 1.664393]\n",
      "epoch:13 step:10649 [D loss: 0.561652, acc: 82.81%] [G loss: 1.837418]\n",
      "epoch:13 step:10650 [D loss: 0.632485, acc: 59.38%] [G loss: 1.671897]\n",
      "epoch:13 step:10651 [D loss: 0.764863, acc: 41.41%] [G loss: 1.833994]\n",
      "epoch:13 step:10652 [D loss: 0.901147, acc: 26.56%] [G loss: 1.538403]\n",
      "epoch:13 step:10653 [D loss: 0.703334, acc: 47.66%] [G loss: 1.507257]\n",
      "epoch:13 step:10654 [D loss: 0.798049, acc: 36.72%] [G loss: 1.460357]\n",
      "epoch:13 step:10655 [D loss: 0.561746, acc: 82.81%] [G loss: 1.580272]\n",
      "epoch:13 step:10656 [D loss: 0.729160, acc: 49.22%] [G loss: 1.502279]\n",
      "epoch:13 step:10657 [D loss: 0.633316, acc: 67.97%] [G loss: 1.688415]\n",
      "epoch:13 step:10658 [D loss: 0.750538, acc: 53.91%] [G loss: 1.482978]\n",
      "epoch:13 step:10659 [D loss: 0.628128, acc: 67.97%] [G loss: 1.550844]\n",
      "epoch:13 step:10660 [D loss: 0.626991, acc: 70.31%] [G loss: 1.678813]\n",
      "epoch:13 step:10661 [D loss: 0.745795, acc: 33.59%] [G loss: 1.429514]\n",
      "epoch:13 step:10662 [D loss: 0.676366, acc: 55.47%] [G loss: 1.686024]\n",
      "epoch:13 step:10663 [D loss: 0.661619, acc: 59.38%] [G loss: 1.681343]\n",
      "epoch:13 step:10664 [D loss: 0.645785, acc: 63.28%] [G loss: 1.832580]\n",
      "epoch:13 step:10665 [D loss: 0.727818, acc: 47.66%] [G loss: 1.788581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10666 [D loss: 0.800636, acc: 41.41%] [G loss: 1.468090]\n",
      "epoch:13 step:10667 [D loss: 0.785523, acc: 39.06%] [G loss: 1.608403]\n",
      "epoch:13 step:10668 [D loss: 0.560320, acc: 76.56%] [G loss: 1.650882]\n",
      "epoch:13 step:10669 [D loss: 0.710483, acc: 46.88%] [G loss: 1.620118]\n",
      "epoch:13 step:10670 [D loss: 0.798058, acc: 41.41%] [G loss: 1.525510]\n",
      "epoch:13 step:10671 [D loss: 0.641584, acc: 67.19%] [G loss: 1.731431]\n",
      "epoch:13 step:10672 [D loss: 0.854439, acc: 36.72%] [G loss: 1.259341]\n",
      "epoch:13 step:10673 [D loss: 0.576650, acc: 78.91%] [G loss: 1.849917]\n",
      "epoch:13 step:10674 [D loss: 0.687271, acc: 55.47%] [G loss: 1.676107]\n",
      "epoch:13 step:10675 [D loss: 0.708978, acc: 49.22%] [G loss: 1.630521]\n",
      "epoch:13 step:10676 [D loss: 0.570475, acc: 84.38%] [G loss: 1.751510]\n",
      "epoch:13 step:10677 [D loss: 0.657314, acc: 62.50%] [G loss: 1.636755]\n",
      "epoch:13 step:10678 [D loss: 0.698557, acc: 52.34%] [G loss: 1.486479]\n",
      "epoch:13 step:10679 [D loss: 0.504991, acc: 78.12%] [G loss: 1.601989]\n",
      "epoch:13 step:10680 [D loss: 0.792812, acc: 35.16%] [G loss: 1.464327]\n",
      "epoch:13 step:10681 [D loss: 0.546148, acc: 78.91%] [G loss: 1.639473]\n",
      "epoch:13 step:10682 [D loss: 0.620249, acc: 68.75%] [G loss: 1.731186]\n",
      "epoch:13 step:10683 [D loss: 0.723806, acc: 46.88%] [G loss: 1.502444]\n",
      "epoch:13 step:10684 [D loss: 0.841785, acc: 32.81%] [G loss: 1.479997]\n",
      "epoch:13 step:10685 [D loss: 0.539400, acc: 86.72%] [G loss: 1.524696]\n",
      "epoch:13 step:10686 [D loss: 0.791466, acc: 32.81%] [G loss: 1.594819]\n",
      "epoch:13 step:10687 [D loss: 0.596609, acc: 70.31%] [G loss: 1.824110]\n",
      "epoch:13 step:10688 [D loss: 0.669435, acc: 58.59%] [G loss: 1.389141]\n",
      "epoch:13 step:10689 [D loss: 0.592966, acc: 74.22%] [G loss: 1.613971]\n",
      "epoch:13 step:10690 [D loss: 0.599029, acc: 72.66%] [G loss: 1.623576]\n",
      "epoch:13 step:10691 [D loss: 0.649210, acc: 61.72%] [G loss: 1.519434]\n",
      "epoch:13 step:10692 [D loss: 0.741063, acc: 44.53%] [G loss: 1.585291]\n",
      "epoch:13 step:10693 [D loss: 0.576876, acc: 77.34%] [G loss: 1.715737]\n",
      "epoch:13 step:10694 [D loss: 0.672677, acc: 51.56%] [G loss: 1.765239]\n",
      "epoch:13 step:10695 [D loss: 0.618550, acc: 73.44%] [G loss: 1.509445]\n",
      "epoch:13 step:10696 [D loss: 0.760852, acc: 39.06%] [G loss: 1.543221]\n",
      "epoch:13 step:10697 [D loss: 0.571284, acc: 81.25%] [G loss: 1.510062]\n",
      "epoch:13 step:10698 [D loss: 0.726192, acc: 53.12%] [G loss: 1.598753]\n",
      "epoch:13 step:10699 [D loss: 0.793646, acc: 32.03%] [G loss: 1.677348]\n",
      "epoch:13 step:10700 [D loss: 0.708996, acc: 53.12%] [G loss: 1.621809]\n",
      "epoch:13 step:10701 [D loss: 0.599843, acc: 73.44%] [G loss: 1.658088]\n",
      "epoch:13 step:10702 [D loss: 0.756465, acc: 39.84%] [G loss: 1.663744]\n",
      "epoch:13 step:10703 [D loss: 0.607616, acc: 72.66%] [G loss: 1.681401]\n",
      "epoch:13 step:10704 [D loss: 0.566722, acc: 83.59%] [G loss: 1.770746]\n",
      "epoch:13 step:10705 [D loss: 0.781633, acc: 35.16%] [G loss: 1.442974]\n",
      "epoch:13 step:10706 [D loss: 0.799537, acc: 46.88%] [G loss: 1.498327]\n",
      "epoch:13 step:10707 [D loss: 0.689606, acc: 56.25%] [G loss: 1.462454]\n",
      "epoch:13 step:10708 [D loss: 0.720971, acc: 51.56%] [G loss: 1.748265]\n",
      "epoch:13 step:10709 [D loss: 0.626258, acc: 65.62%] [G loss: 1.686217]\n",
      "epoch:13 step:10710 [D loss: 0.489929, acc: 82.03%] [G loss: 1.767229]\n",
      "epoch:13 step:10711 [D loss: 0.751051, acc: 40.62%] [G loss: 1.592950]\n",
      "epoch:13 step:10712 [D loss: 0.620468, acc: 68.75%] [G loss: 1.814187]\n",
      "epoch:13 step:10713 [D loss: 0.665892, acc: 62.50%] [G loss: 1.587928]\n",
      "epoch:13 step:10714 [D loss: 0.645771, acc: 63.28%] [G loss: 1.767120]\n",
      "epoch:13 step:10715 [D loss: 0.568061, acc: 72.66%] [G loss: 1.693508]\n",
      "epoch:13 step:10716 [D loss: 0.873306, acc: 24.22%] [G loss: 1.359241]\n",
      "epoch:13 step:10717 [D loss: 0.670169, acc: 56.25%] [G loss: 1.662541]\n",
      "epoch:13 step:10718 [D loss: 0.755213, acc: 43.75%] [G loss: 1.563321]\n",
      "epoch:13 step:10719 [D loss: 0.832887, acc: 22.66%] [G loss: 1.476496]\n",
      "epoch:13 step:10720 [D loss: 0.669637, acc: 60.94%] [G loss: 1.677277]\n",
      "epoch:13 step:10721 [D loss: 0.660832, acc: 59.38%] [G loss: 1.617813]\n",
      "epoch:13 step:10722 [D loss: 0.739395, acc: 49.22%] [G loss: 1.503535]\n",
      "epoch:13 step:10723 [D loss: 0.649831, acc: 60.16%] [G loss: 1.640540]\n",
      "epoch:13 step:10724 [D loss: 0.773654, acc: 39.06%] [G loss: 1.574706]\n",
      "epoch:13 step:10725 [D loss: 0.599244, acc: 69.53%] [G loss: 1.766893]\n",
      "epoch:13 step:10726 [D loss: 0.802422, acc: 29.69%] [G loss: 1.660427]\n",
      "epoch:13 step:10727 [D loss: 0.826315, acc: 32.03%] [G loss: 1.567522]\n",
      "epoch:13 step:10728 [D loss: 0.609146, acc: 72.66%] [G loss: 1.537338]\n",
      "epoch:13 step:10729 [D loss: 0.784993, acc: 41.41%] [G loss: 1.497017]\n",
      "epoch:13 step:10730 [D loss: 0.715765, acc: 47.66%] [G loss: 1.805510]\n",
      "epoch:13 step:10731 [D loss: 0.640929, acc: 69.53%] [G loss: 2.080600]\n",
      "epoch:13 step:10732 [D loss: 0.673675, acc: 61.72%] [G loss: 1.675288]\n",
      "epoch:13 step:10733 [D loss: 0.730077, acc: 53.12%] [G loss: 1.813234]\n",
      "epoch:13 step:10734 [D loss: 0.553893, acc: 78.91%] [G loss: 1.741400]\n",
      "epoch:13 step:10735 [D loss: 0.590680, acc: 76.56%] [G loss: 1.713774]\n",
      "epoch:13 step:10736 [D loss: 0.846580, acc: 23.44%] [G loss: 1.396450]\n",
      "epoch:13 step:10737 [D loss: 0.682172, acc: 58.59%] [G loss: 1.398264]\n",
      "epoch:13 step:10738 [D loss: 0.719488, acc: 53.12%] [G loss: 1.800709]\n",
      "epoch:13 step:10739 [D loss: 0.551058, acc: 79.69%] [G loss: 1.631325]\n",
      "epoch:13 step:10740 [D loss: 0.599076, acc: 71.88%] [G loss: 1.645550]\n",
      "epoch:13 step:10741 [D loss: 0.672057, acc: 62.50%] [G loss: 1.598320]\n",
      "epoch:13 step:10742 [D loss: 0.589998, acc: 60.16%] [G loss: 1.580862]\n",
      "epoch:13 step:10743 [D loss: 0.708342, acc: 48.44%] [G loss: 1.598828]\n",
      "epoch:13 step:10744 [D loss: 0.744879, acc: 41.41%] [G loss: 1.601352]\n",
      "epoch:13 step:10745 [D loss: 0.762151, acc: 39.84%] [G loss: 1.538005]\n",
      "epoch:13 step:10746 [D loss: 0.448886, acc: 92.19%] [G loss: 1.978874]\n",
      "epoch:13 step:10747 [D loss: 0.697887, acc: 53.12%] [G loss: 1.734816]\n",
      "epoch:13 step:10748 [D loss: 0.698611, acc: 53.91%] [G loss: 1.693952]\n",
      "epoch:13 step:10749 [D loss: 0.693652, acc: 49.22%] [G loss: 1.891417]\n",
      "epoch:13 step:10750 [D loss: 0.415495, acc: 92.97%] [G loss: 1.911002]\n",
      "epoch:13 step:10751 [D loss: 0.498009, acc: 87.50%] [G loss: 1.781243]\n",
      "epoch:13 step:10752 [D loss: 0.739580, acc: 51.56%] [G loss: 1.490497]\n",
      "epoch:13 step:10753 [D loss: 0.572781, acc: 73.44%] [G loss: 1.653091]\n",
      "epoch:13 step:10754 [D loss: 0.656857, acc: 63.28%] [G loss: 1.697394]\n",
      "epoch:13 step:10755 [D loss: 0.607096, acc: 71.09%] [G loss: 1.604787]\n",
      "epoch:13 step:10756 [D loss: 0.632535, acc: 65.62%] [G loss: 1.671101]\n",
      "epoch:13 step:10757 [D loss: 0.699382, acc: 53.12%] [G loss: 1.813361]\n",
      "epoch:13 step:10758 [D loss: 0.849690, acc: 24.22%] [G loss: 1.700608]\n",
      "epoch:13 step:10759 [D loss: 0.824025, acc: 31.25%] [G loss: 1.626834]\n",
      "epoch:13 step:10760 [D loss: 0.607507, acc: 67.19%] [G loss: 1.716089]\n",
      "epoch:13 step:10761 [D loss: 0.538079, acc: 76.56%] [G loss: 1.588507]\n",
      "epoch:13 step:10762 [D loss: 0.762395, acc: 43.75%] [G loss: 1.442351]\n",
      "epoch:13 step:10763 [D loss: 0.809733, acc: 42.19%] [G loss: 1.392299]\n",
      "epoch:13 step:10764 [D loss: 0.556417, acc: 78.91%] [G loss: 1.690457]\n",
      "epoch:13 step:10765 [D loss: 0.710391, acc: 53.91%] [G loss: 1.668695]\n",
      "epoch:13 step:10766 [D loss: 0.900282, acc: 22.66%] [G loss: 1.362396]\n",
      "epoch:13 step:10767 [D loss: 0.686401, acc: 55.47%] [G loss: 1.522174]\n",
      "epoch:13 step:10768 [D loss: 0.669345, acc: 56.25%] [G loss: 1.664592]\n",
      "epoch:13 step:10769 [D loss: 0.867542, acc: 32.03%] [G loss: 1.445264]\n",
      "epoch:13 step:10770 [D loss: 0.636550, acc: 72.66%] [G loss: 1.746386]\n",
      "epoch:13 step:10771 [D loss: 0.748486, acc: 43.75%] [G loss: 1.423835]\n",
      "epoch:13 step:10772 [D loss: 0.915826, acc: 23.44%] [G loss: 1.432031]\n",
      "epoch:13 step:10773 [D loss: 0.800403, acc: 43.75%] [G loss: 1.608133]\n",
      "epoch:13 step:10774 [D loss: 0.674270, acc: 61.72%] [G loss: 1.595525]\n",
      "epoch:13 step:10775 [D loss: 0.473334, acc: 88.28%] [G loss: 1.684975]\n",
      "epoch:13 step:10776 [D loss: 0.639987, acc: 63.28%] [G loss: 1.666449]\n",
      "epoch:13 step:10777 [D loss: 0.784553, acc: 42.19%] [G loss: 1.614941]\n",
      "epoch:13 step:10778 [D loss: 0.444638, acc: 82.03%] [G loss: 1.969856]\n",
      "epoch:13 step:10779 [D loss: 0.586481, acc: 76.56%] [G loss: 1.655915]\n",
      "epoch:13 step:10780 [D loss: 0.507722, acc: 71.88%] [G loss: 1.692596]\n",
      "epoch:13 step:10781 [D loss: 0.746967, acc: 41.41%] [G loss: 1.702893]\n",
      "epoch:13 step:10782 [D loss: 0.638417, acc: 66.41%] [G loss: 1.809155]\n",
      "epoch:13 step:10783 [D loss: 0.660165, acc: 60.94%] [G loss: 1.508845]\n",
      "epoch:13 step:10784 [D loss: 0.676958, acc: 60.16%] [G loss: 1.681723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10785 [D loss: 0.860343, acc: 19.53%] [G loss: 1.343396]\n",
      "epoch:13 step:10786 [D loss: 0.643848, acc: 58.59%] [G loss: 1.568447]\n",
      "epoch:13 step:10787 [D loss: 0.509472, acc: 82.03%] [G loss: 1.876776]\n",
      "epoch:13 step:10788 [D loss: 0.692853, acc: 56.25%] [G loss: 1.648653]\n",
      "epoch:13 step:10789 [D loss: 0.792615, acc: 35.94%] [G loss: 1.640086]\n",
      "epoch:13 step:10790 [D loss: 0.893789, acc: 21.09%] [G loss: 1.467261]\n",
      "epoch:13 step:10791 [D loss: 0.790233, acc: 35.94%] [G loss: 1.631796]\n",
      "epoch:13 step:10792 [D loss: 0.669329, acc: 63.28%] [G loss: 1.542660]\n",
      "epoch:13 step:10793 [D loss: 0.509386, acc: 82.81%] [G loss: 2.244686]\n",
      "epoch:13 step:10794 [D loss: 0.621944, acc: 69.53%] [G loss: 1.636635]\n",
      "epoch:13 step:10795 [D loss: 0.622534, acc: 67.97%] [G loss: 1.651269]\n",
      "epoch:13 step:10796 [D loss: 0.579915, acc: 74.22%] [G loss: 1.738479]\n",
      "epoch:13 step:10797 [D loss: 0.585159, acc: 75.78%] [G loss: 1.792639]\n",
      "epoch:13 step:10798 [D loss: 0.751441, acc: 46.09%] [G loss: 1.641999]\n",
      "epoch:13 step:10799 [D loss: 0.718663, acc: 53.12%] [G loss: 1.835233]\n",
      "epoch:13 step:10800 [D loss: 0.636552, acc: 63.28%] [G loss: 1.625810]\n",
      "epoch:13 step:10801 [D loss: 0.669973, acc: 56.25%] [G loss: 1.505199]\n",
      "epoch:13 step:10802 [D loss: 0.795208, acc: 39.06%] [G loss: 1.713510]\n",
      "epoch:13 step:10803 [D loss: 0.543150, acc: 83.59%] [G loss: 1.822142]\n",
      "epoch:13 step:10804 [D loss: 0.624519, acc: 65.62%] [G loss: 1.671295]\n",
      "epoch:13 step:10805 [D loss: 0.649145, acc: 61.72%] [G loss: 1.967020]\n",
      "epoch:13 step:10806 [D loss: 0.701542, acc: 49.22%] [G loss: 1.737908]\n",
      "epoch:13 step:10807 [D loss: 0.499419, acc: 81.25%] [G loss: 1.835212]\n",
      "epoch:13 step:10808 [D loss: 0.624771, acc: 60.16%] [G loss: 1.589540]\n",
      "epoch:13 step:10809 [D loss: 0.885232, acc: 26.56%] [G loss: 1.538032]\n",
      "epoch:13 step:10810 [D loss: 0.592963, acc: 71.88%] [G loss: 1.763884]\n",
      "epoch:13 step:10811 [D loss: 0.554942, acc: 77.34%] [G loss: 1.585366]\n",
      "epoch:13 step:10812 [D loss: 0.493971, acc: 87.50%] [G loss: 1.850374]\n",
      "epoch:13 step:10813 [D loss: 0.583749, acc: 60.94%] [G loss: 1.486624]\n",
      "epoch:13 step:10814 [D loss: 0.714927, acc: 48.44%] [G loss: 1.712277]\n",
      "epoch:13 step:10815 [D loss: 0.753472, acc: 39.84%] [G loss: 1.515951]\n",
      "epoch:13 step:10816 [D loss: 0.539654, acc: 85.16%] [G loss: 1.582145]\n",
      "epoch:13 step:10817 [D loss: 0.692287, acc: 53.91%] [G loss: 1.484392]\n",
      "epoch:13 step:10818 [D loss: 0.766865, acc: 34.38%] [G loss: 1.385838]\n",
      "epoch:13 step:10819 [D loss: 0.564670, acc: 81.25%] [G loss: 1.832217]\n",
      "epoch:13 step:10820 [D loss: 0.699068, acc: 52.34%] [G loss: 1.722265]\n",
      "epoch:13 step:10821 [D loss: 0.740379, acc: 46.88%] [G loss: 1.595779]\n",
      "epoch:13 step:10822 [D loss: 0.704228, acc: 52.34%] [G loss: 1.708079]\n",
      "epoch:13 step:10823 [D loss: 0.660715, acc: 53.91%] [G loss: 1.811267]\n",
      "epoch:13 step:10824 [D loss: 0.772897, acc: 31.25%] [G loss: 1.837016]\n",
      "epoch:13 step:10825 [D loss: 0.806669, acc: 26.56%] [G loss: 1.332348]\n",
      "epoch:13 step:10826 [D loss: 0.616459, acc: 68.75%] [G loss: 1.557384]\n",
      "epoch:13 step:10827 [D loss: 0.595050, acc: 74.22%] [G loss: 1.811266]\n",
      "epoch:13 step:10828 [D loss: 0.486727, acc: 87.50%] [G loss: 1.797512]\n",
      "epoch:13 step:10829 [D loss: 0.747793, acc: 48.44%] [G loss: 1.551921]\n",
      "epoch:13 step:10830 [D loss: 0.517564, acc: 89.84%] [G loss: 1.843859]\n",
      "epoch:13 step:10831 [D loss: 0.753153, acc: 40.62%] [G loss: 1.561275]\n",
      "epoch:13 step:10832 [D loss: 0.646473, acc: 65.62%] [G loss: 1.719292]\n",
      "epoch:13 step:10833 [D loss: 0.599280, acc: 78.12%] [G loss: 2.212102]\n",
      "epoch:13 step:10834 [D loss: 0.590715, acc: 73.44%] [G loss: 1.777098]\n",
      "epoch:13 step:10835 [D loss: 1.038520, acc: 42.19%] [G loss: 1.453549]\n",
      "epoch:13 step:10836 [D loss: 0.609250, acc: 61.72%] [G loss: 1.619200]\n",
      "epoch:13 step:10837 [D loss: 0.784681, acc: 37.50%] [G loss: 1.544746]\n",
      "epoch:13 step:10838 [D loss: 0.639015, acc: 61.72%] [G loss: 1.855239]\n",
      "epoch:13 step:10839 [D loss: 0.646807, acc: 67.97%] [G loss: 1.720796]\n",
      "epoch:13 step:10840 [D loss: 0.793610, acc: 43.75%] [G loss: 1.748297]\n",
      "epoch:13 step:10841 [D loss: 0.499224, acc: 80.47%] [G loss: 1.553048]\n",
      "epoch:13 step:10842 [D loss: 0.702427, acc: 47.66%] [G loss: 1.412062]\n",
      "epoch:13 step:10843 [D loss: 0.578729, acc: 76.56%] [G loss: 1.813336]\n",
      "epoch:13 step:10844 [D loss: 0.743488, acc: 43.75%] [G loss: 1.695989]\n",
      "epoch:13 step:10845 [D loss: 1.337764, acc: 3.91%] [G loss: 1.485732]\n",
      "epoch:13 step:10846 [D loss: 0.684994, acc: 58.59%] [G loss: 2.086131]\n",
      "epoch:13 step:10847 [D loss: 0.742320, acc: 50.00%] [G loss: 1.650860]\n",
      "epoch:13 step:10848 [D loss: 0.544358, acc: 86.72%] [G loss: 1.882956]\n",
      "epoch:13 step:10849 [D loss: 0.778009, acc: 37.50%] [G loss: 1.557708]\n",
      "epoch:13 step:10850 [D loss: 0.630972, acc: 66.41%] [G loss: 1.710816]\n",
      "epoch:13 step:10851 [D loss: 0.544097, acc: 82.81%] [G loss: 1.715731]\n",
      "epoch:13 step:10852 [D loss: 0.719741, acc: 52.34%] [G loss: 1.568334]\n",
      "epoch:13 step:10853 [D loss: 0.660557, acc: 56.25%] [G loss: 1.520780]\n",
      "epoch:13 step:10854 [D loss: 0.602970, acc: 67.97%] [G loss: 1.710824]\n",
      "epoch:13 step:10855 [D loss: 0.650625, acc: 60.94%] [G loss: 1.657044]\n",
      "epoch:13 step:10856 [D loss: 0.619537, acc: 70.31%] [G loss: 1.807646]\n",
      "epoch:13 step:10857 [D loss: 0.750865, acc: 45.31%] [G loss: 1.596398]\n",
      "epoch:13 step:10858 [D loss: 0.523128, acc: 90.62%] [G loss: 1.658748]\n",
      "epoch:13 step:10859 [D loss: 0.611210, acc: 65.62%] [G loss: 1.586561]\n",
      "epoch:13 step:10860 [D loss: 0.775428, acc: 42.97%] [G loss: 1.353756]\n",
      "epoch:13 step:10861 [D loss: 0.446998, acc: 87.50%] [G loss: 2.055166]\n",
      "epoch:13 step:10862 [D loss: 0.686131, acc: 53.12%] [G loss: 1.586747]\n",
      "epoch:13 step:10863 [D loss: 0.536698, acc: 81.25%] [G loss: 1.733509]\n",
      "epoch:13 step:10864 [D loss: 0.631442, acc: 64.84%] [G loss: 1.480243]\n",
      "epoch:13 step:10865 [D loss: 0.790653, acc: 36.72%] [G loss: 1.399473]\n",
      "epoch:13 step:10866 [D loss: 0.467548, acc: 92.19%] [G loss: 2.005476]\n",
      "epoch:13 step:10867 [D loss: 0.713973, acc: 53.91%] [G loss: 1.665380]\n",
      "epoch:13 step:10868 [D loss: 0.592179, acc: 74.22%] [G loss: 1.674534]\n",
      "epoch:13 step:10869 [D loss: 0.534518, acc: 83.59%] [G loss: 1.842452]\n",
      "epoch:13 step:10870 [D loss: 0.613367, acc: 69.53%] [G loss: 1.626732]\n",
      "epoch:13 step:10871 [D loss: 0.551914, acc: 81.25%] [G loss: 1.755497]\n",
      "epoch:13 step:10872 [D loss: 0.521870, acc: 87.50%] [G loss: 1.923815]\n",
      "epoch:13 step:10873 [D loss: 0.652820, acc: 62.50%] [G loss: 1.958049]\n",
      "epoch:13 step:10874 [D loss: 0.903854, acc: 16.41%] [G loss: 1.297843]\n",
      "epoch:13 step:10875 [D loss: 0.620132, acc: 74.22%] [G loss: 1.769878]\n",
      "epoch:13 step:10876 [D loss: 1.091865, acc: 20.31%] [G loss: 1.730801]\n",
      "epoch:13 step:10877 [D loss: 0.615847, acc: 70.31%] [G loss: 1.751998]\n",
      "epoch:13 step:10878 [D loss: 0.614591, acc: 71.09%] [G loss: 1.867105]\n",
      "epoch:13 step:10879 [D loss: 0.906510, acc: 23.44%] [G loss: 1.452255]\n",
      "epoch:13 step:10880 [D loss: 0.544528, acc: 74.22%] [G loss: 1.721825]\n",
      "epoch:13 step:10881 [D loss: 0.742445, acc: 50.78%] [G loss: 1.690854]\n",
      "epoch:13 step:10882 [D loss: 0.660729, acc: 61.72%] [G loss: 1.772368]\n",
      "epoch:13 step:10883 [D loss: 0.510490, acc: 87.50%] [G loss: 1.922083]\n",
      "epoch:13 step:10884 [D loss: 0.521526, acc: 81.25%] [G loss: 1.674628]\n",
      "epoch:13 step:10885 [D loss: 0.634516, acc: 63.28%] [G loss: 1.888217]\n",
      "epoch:13 step:10886 [D loss: 0.778097, acc: 41.41%] [G loss: 1.610732]\n",
      "epoch:13 step:10887 [D loss: 0.739462, acc: 42.97%] [G loss: 1.716611]\n",
      "epoch:13 step:10888 [D loss: 0.748493, acc: 42.97%] [G loss: 1.704712]\n",
      "epoch:13 step:10889 [D loss: 0.772326, acc: 39.06%] [G loss: 1.730978]\n",
      "epoch:13 step:10890 [D loss: 0.582889, acc: 65.62%] [G loss: 1.580020]\n",
      "epoch:13 step:10891 [D loss: 0.470404, acc: 88.28%] [G loss: 2.018820]\n",
      "epoch:13 step:10892 [D loss: 0.640887, acc: 62.50%] [G loss: 1.776320]\n",
      "epoch:13 step:10893 [D loss: 0.653290, acc: 60.16%] [G loss: 1.713094]\n",
      "epoch:13 step:10894 [D loss: 0.394273, acc: 96.88%] [G loss: 2.038211]\n",
      "epoch:13 step:10895 [D loss: 0.538853, acc: 82.03%] [G loss: 1.995551]\n",
      "epoch:13 step:10896 [D loss: 0.537452, acc: 80.47%] [G loss: 1.737852]\n",
      "epoch:13 step:10897 [D loss: 0.600796, acc: 62.50%] [G loss: 1.647100]\n",
      "epoch:13 step:10898 [D loss: 0.710352, acc: 53.12%] [G loss: 1.929146]\n",
      "epoch:13 step:10899 [D loss: 0.853551, acc: 31.25%] [G loss: 1.354866]\n",
      "epoch:13 step:10900 [D loss: 0.566267, acc: 74.22%] [G loss: 1.847048]\n",
      "epoch:13 step:10901 [D loss: 0.493203, acc: 89.84%] [G loss: 1.831973]\n",
      "epoch:13 step:10902 [D loss: 0.666169, acc: 61.72%] [G loss: 1.687545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10903 [D loss: 0.562599, acc: 78.12%] [G loss: 1.540017]\n",
      "epoch:13 step:10904 [D loss: 0.951576, acc: 14.84%] [G loss: 1.379781]\n",
      "epoch:13 step:10905 [D loss: 0.396997, acc: 97.66%] [G loss: 1.921015]\n",
      "epoch:13 step:10906 [D loss: 0.669150, acc: 53.12%] [G loss: 1.853417]\n",
      "epoch:13 step:10907 [D loss: 0.624252, acc: 65.62%] [G loss: 1.842117]\n",
      "epoch:13 step:10908 [D loss: 0.776991, acc: 39.84%] [G loss: 1.557903]\n",
      "epoch:13 step:10909 [D loss: 0.708419, acc: 52.34%] [G loss: 1.659045]\n",
      "epoch:13 step:10910 [D loss: 0.707032, acc: 50.00%] [G loss: 1.692560]\n",
      "epoch:13 step:10911 [D loss: 0.695354, acc: 50.78%] [G loss: 1.713126]\n",
      "epoch:13 step:10912 [D loss: 0.763290, acc: 46.88%] [G loss: 1.531705]\n",
      "epoch:13 step:10913 [D loss: 0.709368, acc: 52.34%] [G loss: 1.841144]\n",
      "epoch:13 step:10914 [D loss: 0.527879, acc: 72.66%] [G loss: 1.738251]\n",
      "epoch:13 step:10915 [D loss: 0.775862, acc: 37.50%] [G loss: 1.500875]\n",
      "epoch:13 step:10916 [D loss: 0.629674, acc: 65.62%] [G loss: 1.604534]\n",
      "epoch:13 step:10917 [D loss: 0.660764, acc: 56.25%] [G loss: 1.299841]\n",
      "epoch:13 step:10918 [D loss: 0.688989, acc: 58.59%] [G loss: 1.418300]\n",
      "epoch:13 step:10919 [D loss: 0.699926, acc: 53.12%] [G loss: 1.961955]\n",
      "epoch:13 step:10920 [D loss: 0.450520, acc: 85.94%] [G loss: 2.323808]\n",
      "epoch:13 step:10921 [D loss: 0.487401, acc: 88.28%] [G loss: 1.824950]\n",
      "epoch:13 step:10922 [D loss: 0.662207, acc: 58.59%] [G loss: 1.943520]\n",
      "epoch:13 step:10923 [D loss: 0.706932, acc: 49.22%] [G loss: 1.586392]\n",
      "epoch:13 step:10924 [D loss: 0.868992, acc: 46.88%] [G loss: 1.973948]\n",
      "epoch:13 step:10925 [D loss: 0.532672, acc: 79.69%] [G loss: 2.499477]\n",
      "epoch:13 step:10926 [D loss: 0.462080, acc: 89.06%] [G loss: 2.157948]\n",
      "epoch:13 step:10927 [D loss: 0.493813, acc: 82.03%] [G loss: 1.825965]\n",
      "epoch:13 step:10928 [D loss: 0.767261, acc: 38.28%] [G loss: 1.601128]\n",
      "epoch:13 step:10929 [D loss: 0.396877, acc: 95.31%] [G loss: 2.010699]\n",
      "epoch:13 step:10930 [D loss: 0.460356, acc: 71.88%] [G loss: 1.482943]\n",
      "epoch:13 step:10931 [D loss: 0.813758, acc: 50.00%] [G loss: 1.662002]\n",
      "epoch:13 step:10932 [D loss: 0.773711, acc: 48.44%] [G loss: 1.405400]\n",
      "epoch:13 step:10933 [D loss: 0.889511, acc: 22.66%] [G loss: 1.362654]\n",
      "epoch:13 step:10934 [D loss: 0.861183, acc: 47.66%] [G loss: 1.683114]\n",
      "epoch:14 step:10935 [D loss: 0.645507, acc: 60.94%] [G loss: 1.849624]\n",
      "epoch:14 step:10936 [D loss: 0.565726, acc: 78.91%] [G loss: 1.942490]\n",
      "epoch:14 step:10937 [D loss: 0.702495, acc: 50.78%] [G loss: 1.847759]\n",
      "epoch:14 step:10938 [D loss: 0.615270, acc: 58.59%] [G loss: 1.760617]\n",
      "epoch:14 step:10939 [D loss: 0.625249, acc: 62.50%] [G loss: 1.567858]\n",
      "epoch:14 step:10940 [D loss: 0.678547, acc: 58.59%] [G loss: 1.641917]\n",
      "epoch:14 step:10941 [D loss: 0.619567, acc: 67.19%] [G loss: 1.688086]\n",
      "epoch:14 step:10942 [D loss: 0.948735, acc: 12.50%] [G loss: 1.389496]\n",
      "epoch:14 step:10943 [D loss: 0.561838, acc: 74.22%] [G loss: 1.571296]\n",
      "epoch:14 step:10944 [D loss: 0.824033, acc: 38.28%] [G loss: 1.461308]\n",
      "epoch:14 step:10945 [D loss: 0.649623, acc: 70.31%] [G loss: 1.764698]\n",
      "epoch:14 step:10946 [D loss: 0.883269, acc: 34.38%] [G loss: 1.542218]\n",
      "epoch:14 step:10947 [D loss: 0.771292, acc: 46.88%] [G loss: 1.572527]\n",
      "epoch:14 step:10948 [D loss: 0.563948, acc: 72.66%] [G loss: 1.798506]\n",
      "epoch:14 step:10949 [D loss: 0.722485, acc: 44.53%] [G loss: 1.572204]\n",
      "epoch:14 step:10950 [D loss: 0.595404, acc: 76.56%] [G loss: 1.614230]\n",
      "epoch:14 step:10951 [D loss: 0.597849, acc: 68.75%] [G loss: 2.058964]\n",
      "epoch:14 step:10952 [D loss: 0.666182, acc: 55.47%] [G loss: 1.597697]\n",
      "epoch:14 step:10953 [D loss: 0.608092, acc: 67.97%] [G loss: 1.921091]\n",
      "epoch:14 step:10954 [D loss: 0.521668, acc: 79.69%] [G loss: 1.795638]\n",
      "epoch:14 step:10955 [D loss: 0.718411, acc: 53.12%] [G loss: 1.596923]\n",
      "epoch:14 step:10956 [D loss: 0.565463, acc: 67.97%] [G loss: 1.670182]\n",
      "epoch:14 step:10957 [D loss: 0.828528, acc: 26.56%] [G loss: 1.772964]\n",
      "epoch:14 step:10958 [D loss: 0.792079, acc: 39.06%] [G loss: 1.639785]\n",
      "epoch:14 step:10959 [D loss: 0.334310, acc: 92.97%] [G loss: 1.864958]\n",
      "epoch:14 step:10960 [D loss: 0.547541, acc: 80.47%] [G loss: 1.869563]\n",
      "epoch:14 step:10961 [D loss: 0.639753, acc: 60.94%] [G loss: 1.657620]\n",
      "epoch:14 step:10962 [D loss: 0.486876, acc: 85.16%] [G loss: 1.730040]\n",
      "epoch:14 step:10963 [D loss: 0.680346, acc: 53.12%] [G loss: 1.950842]\n",
      "epoch:14 step:10964 [D loss: 0.319950, acc: 97.66%] [G loss: 2.070339]\n",
      "epoch:14 step:10965 [D loss: 0.694898, acc: 57.81%] [G loss: 1.585887]\n",
      "epoch:14 step:10966 [D loss: 0.635280, acc: 61.72%] [G loss: 1.647343]\n",
      "epoch:14 step:10967 [D loss: 0.591518, acc: 62.50%] [G loss: 1.727180]\n",
      "epoch:14 step:10968 [D loss: 0.701907, acc: 53.91%] [G loss: 1.891057]\n",
      "epoch:14 step:10969 [D loss: 0.932684, acc: 20.31%] [G loss: 1.578691]\n",
      "epoch:14 step:10970 [D loss: 0.479145, acc: 90.62%] [G loss: 1.676981]\n",
      "epoch:14 step:10971 [D loss: 0.746232, acc: 51.56%] [G loss: 1.700421]\n",
      "epoch:14 step:10972 [D loss: 0.658713, acc: 53.91%] [G loss: 2.049419]\n",
      "epoch:14 step:10973 [D loss: 0.731756, acc: 47.66%] [G loss: 1.625911]\n",
      "epoch:14 step:10974 [D loss: 0.677937, acc: 57.81%] [G loss: 2.018314]\n",
      "epoch:14 step:10975 [D loss: 0.688204, acc: 53.91%] [G loss: 1.856793]\n",
      "epoch:14 step:10976 [D loss: 0.631656, acc: 72.66%] [G loss: 1.667669]\n",
      "epoch:14 step:10977 [D loss: 0.798886, acc: 35.16%] [G loss: 1.583321]\n",
      "epoch:14 step:10978 [D loss: 0.799882, acc: 37.50%] [G loss: 1.505466]\n",
      "epoch:14 step:10979 [D loss: 0.670644, acc: 57.81%] [G loss: 1.913511]\n",
      "epoch:14 step:10980 [D loss: 0.550042, acc: 76.56%] [G loss: 1.630730]\n",
      "epoch:14 step:10981 [D loss: 0.805948, acc: 42.97%] [G loss: 1.597063]\n",
      "epoch:14 step:10982 [D loss: 0.545833, acc: 77.34%] [G loss: 1.862310]\n",
      "epoch:14 step:10983 [D loss: 0.717401, acc: 51.56%] [G loss: 1.624854]\n",
      "epoch:14 step:10984 [D loss: 0.754126, acc: 41.41%] [G loss: 1.723645]\n",
      "epoch:14 step:10985 [D loss: 0.541687, acc: 79.69%] [G loss: 1.628277]\n",
      "epoch:14 step:10986 [D loss: 0.541132, acc: 72.66%] [G loss: 1.846835]\n",
      "epoch:14 step:10987 [D loss: 0.542472, acc: 82.03%] [G loss: 1.856047]\n",
      "epoch:14 step:10988 [D loss: 0.722520, acc: 50.78%] [G loss: 1.774878]\n",
      "epoch:14 step:10989 [D loss: 0.523653, acc: 80.47%] [G loss: 1.570988]\n",
      "epoch:14 step:10990 [D loss: 1.098012, acc: 10.94%] [G loss: 1.522515]\n",
      "epoch:14 step:10991 [D loss: 0.625789, acc: 67.19%] [G loss: 1.717427]\n",
      "epoch:14 step:10992 [D loss: 0.829594, acc: 38.28%] [G loss: 1.424541]\n",
      "epoch:14 step:10993 [D loss: 0.343585, acc: 96.88%] [G loss: 1.876295]\n",
      "epoch:14 step:10994 [D loss: 0.483711, acc: 91.41%] [G loss: 1.899563]\n",
      "epoch:14 step:10995 [D loss: 0.615090, acc: 64.84%] [G loss: 1.534820]\n",
      "epoch:14 step:10996 [D loss: 0.818810, acc: 31.25%] [G loss: 1.511659]\n",
      "epoch:14 step:10997 [D loss: 0.665029, acc: 62.50%] [G loss: 1.442190]\n",
      "epoch:14 step:10998 [D loss: 0.617989, acc: 66.41%] [G loss: 1.700926]\n",
      "epoch:14 step:10999 [D loss: 0.851846, acc: 27.34%] [G loss: 1.440239]\n",
      "epoch:14 step:11000 [D loss: 0.494892, acc: 86.72%] [G loss: 1.674122]\n",
      "epoch:14 step:11001 [D loss: 0.746732, acc: 52.34%] [G loss: 1.329919]\n",
      "epoch:14 step:11002 [D loss: 0.659808, acc: 60.94%] [G loss: 1.500741]\n",
      "epoch:14 step:11003 [D loss: 0.795643, acc: 38.28%] [G loss: 1.498040]\n",
      "epoch:14 step:11004 [D loss: 0.743240, acc: 48.44%] [G loss: 1.398516]\n",
      "epoch:14 step:11005 [D loss: 0.787653, acc: 46.09%] [G loss: 1.664069]\n",
      "epoch:14 step:11006 [D loss: 0.714784, acc: 50.78%] [G loss: 1.595285]\n",
      "epoch:14 step:11007 [D loss: 0.596035, acc: 69.53%] [G loss: 1.814059]\n",
      "epoch:14 step:11008 [D loss: 0.719485, acc: 47.66%] [G loss: 1.403169]\n",
      "epoch:14 step:11009 [D loss: 0.873527, acc: 31.25%] [G loss: 1.348434]\n",
      "epoch:14 step:11010 [D loss: 0.574776, acc: 73.44%] [G loss: 2.096635]\n",
      "epoch:14 step:11011 [D loss: 0.622022, acc: 64.84%] [G loss: 1.504229]\n",
      "epoch:14 step:11012 [D loss: 0.676920, acc: 62.50%] [G loss: 1.806804]\n",
      "epoch:14 step:11013 [D loss: 0.462587, acc: 93.75%] [G loss: 2.117748]\n",
      "epoch:14 step:11014 [D loss: 0.447527, acc: 84.38%] [G loss: 2.262882]\n",
      "epoch:14 step:11015 [D loss: 0.682613, acc: 59.38%] [G loss: 1.752446]\n",
      "epoch:14 step:11016 [D loss: 0.495191, acc: 85.94%] [G loss: 1.593402]\n",
      "epoch:14 step:11017 [D loss: 0.653992, acc: 57.81%] [G loss: 1.764678]\n",
      "epoch:14 step:11018 [D loss: 0.761190, acc: 50.78%] [G loss: 1.653377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11019 [D loss: 0.575491, acc: 73.44%] [G loss: 1.922025]\n",
      "epoch:14 step:11020 [D loss: 0.625075, acc: 66.41%] [G loss: 1.872319]\n",
      "epoch:14 step:11021 [D loss: 0.381540, acc: 92.19%] [G loss: 1.896823]\n",
      "epoch:14 step:11022 [D loss: 0.792601, acc: 47.66%] [G loss: 1.317289]\n",
      "epoch:14 step:11023 [D loss: 0.406441, acc: 92.19%] [G loss: 1.950405]\n",
      "epoch:14 step:11024 [D loss: 0.725671, acc: 50.78%] [G loss: 1.490208]\n",
      "epoch:14 step:11025 [D loss: 0.635293, acc: 62.50%] [G loss: 1.642379]\n",
      "epoch:14 step:11026 [D loss: 0.542715, acc: 78.91%] [G loss: 1.665225]\n",
      "epoch:14 step:11027 [D loss: 0.703155, acc: 55.47%] [G loss: 1.648074]\n",
      "epoch:14 step:11028 [D loss: 0.593334, acc: 71.09%] [G loss: 1.666612]\n",
      "epoch:14 step:11029 [D loss: 0.508705, acc: 89.84%] [G loss: 1.830626]\n",
      "epoch:14 step:11030 [D loss: 0.535989, acc: 83.59%] [G loss: 1.885090]\n",
      "epoch:14 step:11031 [D loss: 0.400661, acc: 74.22%] [G loss: 1.721368]\n",
      "epoch:14 step:11032 [D loss: 0.646842, acc: 69.53%] [G loss: 1.942996]\n",
      "epoch:14 step:11033 [D loss: 0.547735, acc: 78.12%] [G loss: 1.675835]\n",
      "epoch:14 step:11034 [D loss: 0.583365, acc: 73.44%] [G loss: 1.388730]\n",
      "epoch:14 step:11035 [D loss: 1.085101, acc: 11.72%] [G loss: 1.310684]\n",
      "epoch:14 step:11036 [D loss: 0.587417, acc: 74.22%] [G loss: 1.760839]\n",
      "epoch:14 step:11037 [D loss: 0.489893, acc: 83.59%] [G loss: 1.809457]\n",
      "epoch:14 step:11038 [D loss: 0.567331, acc: 82.81%] [G loss: 1.573069]\n",
      "epoch:14 step:11039 [D loss: 0.571650, acc: 68.75%] [G loss: 1.734713]\n",
      "epoch:14 step:11040 [D loss: 0.762478, acc: 46.09%] [G loss: 1.472003]\n",
      "epoch:14 step:11041 [D loss: 1.363105, acc: 8.59%] [G loss: 1.261736]\n",
      "epoch:14 step:11042 [D loss: 0.912946, acc: 31.25%] [G loss: 1.556900]\n",
      "epoch:14 step:11043 [D loss: 0.434219, acc: 84.38%] [G loss: 1.513651]\n",
      "epoch:14 step:11044 [D loss: 0.601396, acc: 71.88%] [G loss: 2.064567]\n",
      "epoch:14 step:11045 [D loss: 1.077927, acc: 7.81%] [G loss: 1.349694]\n",
      "epoch:14 step:11046 [D loss: 0.692728, acc: 53.12%] [G loss: 1.743589]\n",
      "epoch:14 step:11047 [D loss: 0.790325, acc: 38.28%] [G loss: 1.596347]\n",
      "epoch:14 step:11048 [D loss: 0.831621, acc: 40.62%] [G loss: 1.548979]\n",
      "epoch:14 step:11049 [D loss: 0.901744, acc: 20.31%] [G loss: 1.587152]\n",
      "epoch:14 step:11050 [D loss: 0.678174, acc: 57.81%] [G loss: 1.577355]\n",
      "epoch:14 step:11051 [D loss: 0.733130, acc: 40.62%] [G loss: 1.588045]\n",
      "epoch:14 step:11052 [D loss: 0.795032, acc: 45.31%] [G loss: 1.610295]\n",
      "epoch:14 step:11053 [D loss: 0.517730, acc: 85.94%] [G loss: 1.605248]\n",
      "epoch:14 step:11054 [D loss: 0.857919, acc: 32.03%] [G loss: 1.440276]\n",
      "epoch:14 step:11055 [D loss: 0.526557, acc: 83.59%] [G loss: 1.838076]\n",
      "epoch:14 step:11056 [D loss: 0.801177, acc: 32.81%] [G loss: 1.792973]\n",
      "epoch:14 step:11057 [D loss: 0.490018, acc: 86.72%] [G loss: 1.958816]\n",
      "epoch:14 step:11058 [D loss: 0.652561, acc: 64.06%] [G loss: 1.849895]\n",
      "epoch:14 step:11059 [D loss: 0.685140, acc: 49.22%] [G loss: 1.629205]\n",
      "epoch:14 step:11060 [D loss: 0.706981, acc: 56.25%] [G loss: 1.528377]\n",
      "epoch:14 step:11061 [D loss: 0.901428, acc: 24.22%] [G loss: 1.480389]\n",
      "epoch:14 step:11062 [D loss: 0.710343, acc: 52.34%] [G loss: 1.796348]\n",
      "epoch:14 step:11063 [D loss: 0.584238, acc: 76.56%] [G loss: 1.727715]\n",
      "epoch:14 step:11064 [D loss: 0.706043, acc: 50.78%] [G loss: 1.415164]\n",
      "epoch:14 step:11065 [D loss: 0.705518, acc: 50.00%] [G loss: 1.601164]\n",
      "epoch:14 step:11066 [D loss: 0.630856, acc: 66.41%] [G loss: 1.573276]\n",
      "epoch:14 step:11067 [D loss: 0.684540, acc: 50.00%] [G loss: 1.727429]\n",
      "epoch:14 step:11068 [D loss: 0.728981, acc: 45.31%] [G loss: 1.463590]\n",
      "epoch:14 step:11069 [D loss: 0.544745, acc: 83.59%] [G loss: 1.845698]\n",
      "epoch:14 step:11070 [D loss: 0.578129, acc: 67.97%] [G loss: 1.661272]\n",
      "epoch:14 step:11071 [D loss: 0.758870, acc: 46.09%] [G loss: 1.695000]\n",
      "epoch:14 step:11072 [D loss: 0.538839, acc: 79.69%] [G loss: 1.859411]\n",
      "epoch:14 step:11073 [D loss: 0.704709, acc: 51.56%] [G loss: 1.597845]\n",
      "epoch:14 step:11074 [D loss: 0.666570, acc: 59.38%] [G loss: 1.569494]\n",
      "epoch:14 step:11075 [D loss: 0.739551, acc: 48.44%] [G loss: 1.448630]\n",
      "epoch:14 step:11076 [D loss: 0.752067, acc: 46.88%] [G loss: 1.744543]\n",
      "epoch:14 step:11077 [D loss: 0.541037, acc: 73.44%] [G loss: 1.691382]\n",
      "epoch:14 step:11078 [D loss: 0.497987, acc: 83.59%] [G loss: 1.720219]\n",
      "epoch:14 step:11079 [D loss: 0.574398, acc: 74.22%] [G loss: 1.954638]\n",
      "epoch:14 step:11080 [D loss: 0.741505, acc: 46.09%] [G loss: 1.696769]\n",
      "epoch:14 step:11081 [D loss: 0.633565, acc: 67.19%] [G loss: 1.755721]\n",
      "epoch:14 step:11082 [D loss: 0.514048, acc: 82.03%] [G loss: 2.037814]\n",
      "epoch:14 step:11083 [D loss: 0.885906, acc: 25.78%] [G loss: 1.395725]\n",
      "epoch:14 step:11084 [D loss: 0.650897, acc: 61.72%] [G loss: 1.638211]\n",
      "epoch:14 step:11085 [D loss: 0.763231, acc: 46.88%] [G loss: 1.603215]\n",
      "epoch:14 step:11086 [D loss: 0.725796, acc: 46.88%] [G loss: 1.426612]\n",
      "epoch:14 step:11087 [D loss: 0.671545, acc: 56.25%] [G loss: 1.460793]\n",
      "epoch:14 step:11088 [D loss: 0.581107, acc: 73.44%] [G loss: 1.814071]\n",
      "epoch:14 step:11089 [D loss: 0.644479, acc: 66.41%] [G loss: 1.733095]\n",
      "epoch:14 step:11090 [D loss: 0.512363, acc: 79.69%] [G loss: 1.575824]\n",
      "epoch:14 step:11091 [D loss: 0.369113, acc: 85.16%] [G loss: 2.107238]\n",
      "epoch:14 step:11092 [D loss: 0.670562, acc: 57.03%] [G loss: 1.919442]\n",
      "epoch:14 step:11093 [D loss: 0.787555, acc: 42.19%] [G loss: 1.899940]\n",
      "epoch:14 step:11094 [D loss: 0.887862, acc: 43.75%] [G loss: 1.307331]\n",
      "epoch:14 step:11095 [D loss: 0.586078, acc: 60.16%] [G loss: 1.918614]\n",
      "epoch:14 step:11096 [D loss: 0.297462, acc: 99.22%] [G loss: 1.994439]\n",
      "epoch:14 step:11097 [D loss: 0.412048, acc: 87.50%] [G loss: 1.535929]\n",
      "epoch:14 step:11098 [D loss: 0.683598, acc: 53.12%] [G loss: 1.799671]\n",
      "epoch:14 step:11099 [D loss: 0.533373, acc: 81.25%] [G loss: 1.830401]\n",
      "epoch:14 step:11100 [D loss: 0.701452, acc: 53.91%] [G loss: 1.232751]\n",
      "epoch:14 step:11101 [D loss: 0.793304, acc: 46.09%] [G loss: 1.793750]\n",
      "epoch:14 step:11102 [D loss: 0.422779, acc: 94.53%] [G loss: 1.749564]\n",
      "epoch:14 step:11103 [D loss: 0.452605, acc: 92.97%] [G loss: 1.615011]\n",
      "epoch:14 step:11104 [D loss: 0.748404, acc: 43.75%] [G loss: 1.627209]\n",
      "epoch:14 step:11105 [D loss: 0.823613, acc: 37.50%] [G loss: 1.566890]\n",
      "epoch:14 step:11106 [D loss: 0.477534, acc: 91.41%] [G loss: 1.907537]\n",
      "epoch:14 step:11107 [D loss: 0.829015, acc: 35.16%] [G loss: 1.303899]\n",
      "epoch:14 step:11108 [D loss: 0.798919, acc: 45.31%] [G loss: 1.564864]\n",
      "epoch:14 step:11109 [D loss: 0.536546, acc: 80.47%] [G loss: 1.972524]\n",
      "epoch:14 step:11110 [D loss: 0.734233, acc: 48.44%] [G loss: 1.718961]\n",
      "epoch:14 step:11111 [D loss: 0.603815, acc: 74.22%] [G loss: 1.495915]\n",
      "epoch:14 step:11112 [D loss: 0.830051, acc: 28.12%] [G loss: 1.322259]\n",
      "epoch:14 step:11113 [D loss: 0.787445, acc: 34.38%] [G loss: 1.642496]\n",
      "epoch:14 step:11114 [D loss: 0.621204, acc: 65.62%] [G loss: 1.582185]\n",
      "epoch:14 step:11115 [D loss: 0.540557, acc: 82.03%] [G loss: 2.246918]\n",
      "epoch:14 step:11116 [D loss: 0.627234, acc: 63.28%] [G loss: 1.504713]\n",
      "epoch:14 step:11117 [D loss: 0.493693, acc: 84.38%] [G loss: 1.700661]\n",
      "epoch:14 step:11118 [D loss: 0.706494, acc: 54.69%] [G loss: 1.745183]\n",
      "epoch:14 step:11119 [D loss: 0.603328, acc: 70.31%] [G loss: 1.528731]\n",
      "epoch:14 step:11120 [D loss: 0.582661, acc: 76.56%] [G loss: 1.764534]\n",
      "epoch:14 step:11121 [D loss: 0.466287, acc: 90.62%] [G loss: 2.384707]\n",
      "epoch:14 step:11122 [D loss: 0.447088, acc: 92.19%] [G loss: 1.747874]\n",
      "epoch:14 step:11123 [D loss: 0.269642, acc: 99.22%] [G loss: 2.093889]\n",
      "epoch:14 step:11124 [D loss: 0.580193, acc: 75.78%] [G loss: 1.583375]\n",
      "epoch:14 step:11125 [D loss: 0.404001, acc: 97.66%] [G loss: 1.803636]\n",
      "epoch:14 step:11126 [D loss: 0.570537, acc: 75.00%] [G loss: 1.758457]\n",
      "epoch:14 step:11127 [D loss: 0.800872, acc: 46.09%] [G loss: 1.853284]\n",
      "epoch:14 step:11128 [D loss: 0.463922, acc: 84.38%] [G loss: 1.609621]\n",
      "epoch:14 step:11129 [D loss: 0.967874, acc: 14.84%] [G loss: 1.671035]\n",
      "epoch:14 step:11130 [D loss: 1.068777, acc: 35.94%] [G loss: 1.079995]\n",
      "epoch:14 step:11131 [D loss: 0.486906, acc: 88.28%] [G loss: 2.336113]\n",
      "epoch:14 step:11132 [D loss: 0.509838, acc: 80.47%] [G loss: 1.741546]\n",
      "epoch:14 step:11133 [D loss: 0.585599, acc: 73.44%] [G loss: 1.791562]\n",
      "epoch:14 step:11134 [D loss: 0.462817, acc: 89.84%] [G loss: 1.831624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11135 [D loss: 0.528485, acc: 85.94%] [G loss: 2.363630]\n",
      "epoch:14 step:11136 [D loss: 1.003803, acc: 17.19%] [G loss: 1.257319]\n",
      "epoch:14 step:11137 [D loss: 0.757739, acc: 46.88%] [G loss: 1.484865]\n",
      "epoch:14 step:11138 [D loss: 0.602481, acc: 58.59%] [G loss: 1.852774]\n",
      "epoch:14 step:11139 [D loss: 0.960611, acc: 26.56%] [G loss: 1.012892]\n",
      "epoch:14 step:11140 [D loss: 0.836566, acc: 46.09%] [G loss: 1.795362]\n",
      "epoch:14 step:11141 [D loss: 0.731903, acc: 45.31%] [G loss: 1.794141]\n",
      "epoch:14 step:11142 [D loss: 0.440776, acc: 89.06%] [G loss: 1.597490]\n",
      "epoch:14 step:11143 [D loss: 0.713322, acc: 49.22%] [G loss: 1.773403]\n",
      "epoch:14 step:11144 [D loss: 0.554843, acc: 71.88%] [G loss: 1.307864]\n",
      "epoch:14 step:11145 [D loss: 0.782535, acc: 40.62%] [G loss: 1.736125]\n",
      "epoch:14 step:11146 [D loss: 0.490877, acc: 74.22%] [G loss: 2.029701]\n",
      "epoch:14 step:11147 [D loss: 0.814717, acc: 34.38%] [G loss: 1.837247]\n",
      "epoch:14 step:11148 [D loss: 0.417360, acc: 93.75%] [G loss: 1.890604]\n",
      "epoch:14 step:11149 [D loss: 0.656841, acc: 59.38%] [G loss: 1.769752]\n",
      "epoch:14 step:11150 [D loss: 0.778415, acc: 40.62%] [G loss: 1.973457]\n",
      "epoch:14 step:11151 [D loss: 0.838259, acc: 32.03%] [G loss: 1.249317]\n",
      "epoch:14 step:11152 [D loss: 0.348145, acc: 96.88%] [G loss: 2.105929]\n",
      "epoch:14 step:11153 [D loss: 0.456464, acc: 91.41%] [G loss: 1.936780]\n",
      "epoch:14 step:11154 [D loss: 0.730744, acc: 51.56%] [G loss: 1.715705]\n",
      "epoch:14 step:11155 [D loss: 0.918943, acc: 23.44%] [G loss: 1.591126]\n",
      "epoch:14 step:11156 [D loss: 0.472664, acc: 92.19%] [G loss: 1.911670]\n",
      "epoch:14 step:11157 [D loss: 0.771751, acc: 37.50%] [G loss: 1.544166]\n",
      "epoch:14 step:11158 [D loss: 0.708707, acc: 50.00%] [G loss: 1.610116]\n",
      "epoch:14 step:11159 [D loss: 0.585017, acc: 78.12%] [G loss: 2.184180]\n",
      "epoch:14 step:11160 [D loss: 1.051363, acc: 22.66%] [G loss: 1.362459]\n",
      "epoch:14 step:11161 [D loss: 0.532438, acc: 85.16%] [G loss: 1.947610]\n",
      "epoch:14 step:11162 [D loss: 0.720352, acc: 43.75%] [G loss: 1.877855]\n",
      "epoch:14 step:11163 [D loss: 0.498735, acc: 90.62%] [G loss: 1.633909]\n",
      "epoch:14 step:11164 [D loss: 0.447940, acc: 64.06%] [G loss: 1.423891]\n",
      "epoch:14 step:11165 [D loss: 0.838243, acc: 46.09%] [G loss: 1.846695]\n",
      "epoch:14 step:11166 [D loss: 0.823596, acc: 44.53%] [G loss: 1.552289]\n",
      "epoch:14 step:11167 [D loss: 0.484809, acc: 96.88%] [G loss: 1.761596]\n",
      "epoch:14 step:11168 [D loss: 0.571197, acc: 71.09%] [G loss: 1.760476]\n",
      "epoch:14 step:11169 [D loss: 0.533895, acc: 85.94%] [G loss: 2.119107]\n",
      "epoch:14 step:11170 [D loss: 0.618887, acc: 69.53%] [G loss: 1.938993]\n",
      "epoch:14 step:11171 [D loss: 0.462778, acc: 84.38%] [G loss: 2.091770]\n",
      "epoch:14 step:11172 [D loss: 0.413042, acc: 94.53%] [G loss: 1.658432]\n",
      "epoch:14 step:11173 [D loss: 0.486691, acc: 91.41%] [G loss: 2.004150]\n",
      "epoch:14 step:11174 [D loss: 0.659356, acc: 62.50%] [G loss: 1.769084]\n",
      "epoch:14 step:11175 [D loss: 0.646459, acc: 61.72%] [G loss: 2.301382]\n",
      "epoch:14 step:11176 [D loss: 0.571762, acc: 75.00%] [G loss: 1.596708]\n",
      "epoch:14 step:11177 [D loss: 0.350942, acc: 90.62%] [G loss: 1.731888]\n",
      "epoch:14 step:11178 [D loss: 0.725206, acc: 50.78%] [G loss: 1.737054]\n",
      "epoch:14 step:11179 [D loss: 0.816351, acc: 35.16%] [G loss: 1.586149]\n",
      "epoch:14 step:11180 [D loss: 0.710667, acc: 51.56%] [G loss: 1.739657]\n",
      "epoch:14 step:11181 [D loss: 0.748612, acc: 43.75%] [G loss: 1.601837]\n",
      "epoch:14 step:11182 [D loss: 0.828928, acc: 36.72%] [G loss: 1.539172]\n",
      "epoch:14 step:11183 [D loss: 0.553538, acc: 81.25%] [G loss: 1.649393]\n",
      "epoch:14 step:11184 [D loss: 0.476114, acc: 84.38%] [G loss: 1.561346]\n",
      "epoch:14 step:11185 [D loss: 0.595140, acc: 67.19%] [G loss: 1.671695]\n",
      "epoch:14 step:11186 [D loss: 0.709432, acc: 50.78%] [G loss: 1.669246]\n",
      "epoch:14 step:11187 [D loss: 0.710926, acc: 53.12%] [G loss: 1.531586]\n",
      "epoch:14 step:11188 [D loss: 0.847905, acc: 28.12%] [G loss: 1.444969]\n",
      "epoch:14 step:11189 [D loss: 0.705824, acc: 51.56%] [G loss: 1.597435]\n",
      "epoch:14 step:11190 [D loss: 0.726546, acc: 53.12%] [G loss: 1.580669]\n",
      "epoch:14 step:11191 [D loss: 0.724678, acc: 44.53%] [G loss: 1.613702]\n",
      "epoch:14 step:11192 [D loss: 0.566560, acc: 72.66%] [G loss: 1.754253]\n",
      "epoch:14 step:11193 [D loss: 0.483706, acc: 83.59%] [G loss: 1.876660]\n",
      "epoch:14 step:11194 [D loss: 0.707555, acc: 53.91%] [G loss: 1.515224]\n",
      "epoch:14 step:11195 [D loss: 0.592274, acc: 72.66%] [G loss: 1.913594]\n",
      "epoch:14 step:11196 [D loss: 0.568748, acc: 78.91%] [G loss: 1.940372]\n",
      "epoch:14 step:11197 [D loss: 0.642085, acc: 60.94%] [G loss: 1.736931]\n",
      "epoch:14 step:11198 [D loss: 0.712051, acc: 51.56%] [G loss: 1.856970]\n",
      "epoch:14 step:11199 [D loss: 0.604922, acc: 72.66%] [G loss: 2.039512]\n",
      "epoch:14 step:11200 [D loss: 0.895118, acc: 33.59%] [G loss: 1.483215]\n",
      "epoch:14 step:11201 [D loss: 0.878718, acc: 44.53%] [G loss: 1.284949]\n",
      "epoch:14 step:11202 [D loss: 0.364249, acc: 98.44%] [G loss: 2.227551]\n",
      "epoch:14 step:11203 [D loss: 0.488549, acc: 89.06%] [G loss: 2.125974]\n",
      "epoch:14 step:11204 [D loss: 0.915660, acc: 35.16%] [G loss: 1.390657]\n",
      "epoch:14 step:11205 [D loss: 0.560590, acc: 73.44%] [G loss: 2.654701]\n",
      "epoch:14 step:11206 [D loss: 0.476158, acc: 83.59%] [G loss: 1.866919]\n",
      "epoch:14 step:11207 [D loss: 0.771672, acc: 44.53%] [G loss: 1.742879]\n",
      "epoch:14 step:11208 [D loss: 0.842798, acc: 25.00%] [G loss: 1.420534]\n",
      "epoch:14 step:11209 [D loss: 0.499775, acc: 86.72%] [G loss: 1.938456]\n",
      "epoch:14 step:11210 [D loss: 0.536636, acc: 82.81%] [G loss: 1.550559]\n",
      "epoch:14 step:11211 [D loss: 0.914903, acc: 48.44%] [G loss: 1.576768]\n",
      "epoch:14 step:11212 [D loss: 0.803213, acc: 50.78%] [G loss: 1.768964]\n",
      "epoch:14 step:11213 [D loss: 0.880015, acc: 34.38%] [G loss: 1.335973]\n",
      "epoch:14 step:11214 [D loss: 0.464073, acc: 78.91%] [G loss: 1.659651]\n",
      "epoch:14 step:11215 [D loss: 0.579056, acc: 71.88%] [G loss: 1.619607]\n",
      "epoch:14 step:11216 [D loss: 0.506544, acc: 78.91%] [G loss: 1.692420]\n",
      "epoch:14 step:11217 [D loss: 0.763427, acc: 48.44%] [G loss: 1.685699]\n",
      "epoch:14 step:11218 [D loss: 0.712883, acc: 47.66%] [G loss: 1.306774]\n",
      "epoch:14 step:11219 [D loss: 0.612835, acc: 69.53%] [G loss: 1.414983]\n",
      "epoch:14 step:11220 [D loss: 0.557675, acc: 62.50%] [G loss: 1.481375]\n",
      "epoch:14 step:11221 [D loss: 0.536281, acc: 85.16%] [G loss: 1.677297]\n",
      "epoch:14 step:11222 [D loss: 1.065428, acc: 11.72%] [G loss: 1.280869]\n",
      "epoch:14 step:11223 [D loss: 0.652698, acc: 57.03%] [G loss: 1.449666]\n",
      "epoch:14 step:11224 [D loss: 0.431972, acc: 94.53%] [G loss: 1.626896]\n",
      "epoch:14 step:11225 [D loss: 0.861679, acc: 28.12%] [G loss: 1.242605]\n",
      "epoch:14 step:11226 [D loss: 1.077808, acc: 8.59%] [G loss: 1.363898]\n",
      "epoch:14 step:11227 [D loss: 0.672649, acc: 55.47%] [G loss: 1.728902]\n",
      "epoch:14 step:11228 [D loss: 0.617850, acc: 76.56%] [G loss: 1.579492]\n",
      "epoch:14 step:11229 [D loss: 0.417485, acc: 93.75%] [G loss: 1.786977]\n",
      "epoch:14 step:11230 [D loss: 0.612960, acc: 72.66%] [G loss: 1.787397]\n",
      "epoch:14 step:11231 [D loss: 0.658681, acc: 60.94%] [G loss: 1.653657]\n",
      "epoch:14 step:11232 [D loss: 0.835840, acc: 27.34%] [G loss: 1.543049]\n",
      "epoch:14 step:11233 [D loss: 0.525599, acc: 86.72%] [G loss: 1.637881]\n",
      "epoch:14 step:11234 [D loss: 0.800323, acc: 32.81%] [G loss: 1.820934]\n",
      "epoch:14 step:11235 [D loss: 0.780264, acc: 40.62%] [G loss: 1.652240]\n",
      "epoch:14 step:11236 [D loss: 0.721904, acc: 51.56%] [G loss: 1.736159]\n",
      "epoch:14 step:11237 [D loss: 0.795055, acc: 39.06%] [G loss: 1.467070]\n",
      "epoch:14 step:11238 [D loss: 0.627411, acc: 68.75%] [G loss: 1.706235]\n",
      "epoch:14 step:11239 [D loss: 0.671630, acc: 56.25%] [G loss: 2.158629]\n",
      "epoch:14 step:11240 [D loss: 0.449350, acc: 88.28%] [G loss: 1.702214]\n",
      "epoch:14 step:11241 [D loss: 0.683912, acc: 46.88%] [G loss: 1.742537]\n",
      "epoch:14 step:11242 [D loss: 0.579525, acc: 76.56%] [G loss: 1.574041]\n",
      "epoch:14 step:11243 [D loss: 0.647965, acc: 60.94%] [G loss: 1.546573]\n",
      "epoch:14 step:11244 [D loss: 0.538495, acc: 81.25%] [G loss: 1.867399]\n",
      "epoch:14 step:11245 [D loss: 0.706583, acc: 47.66%] [G loss: 1.786997]\n",
      "epoch:14 step:11246 [D loss: 0.615821, acc: 71.88%] [G loss: 1.670640]\n",
      "epoch:14 step:11247 [D loss: 0.627391, acc: 60.94%] [G loss: 1.561988]\n",
      "epoch:14 step:11248 [D loss: 0.445021, acc: 90.62%] [G loss: 1.867227]\n",
      "epoch:14 step:11249 [D loss: 0.865403, acc: 44.53%] [G loss: 1.265550]\n",
      "epoch:14 step:11250 [D loss: 0.531964, acc: 75.78%] [G loss: 2.167475]\n",
      "epoch:14 step:11251 [D loss: 0.786528, acc: 35.94%] [G loss: 1.845922]\n",
      "epoch:14 step:11252 [D loss: 0.785386, acc: 50.00%] [G loss: 1.576496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11253 [D loss: 0.585799, acc: 72.66%] [G loss: 1.784299]\n",
      "epoch:14 step:11254 [D loss: 0.919700, acc: 24.22%] [G loss: 1.633265]\n",
      "epoch:14 step:11255 [D loss: 0.492612, acc: 87.50%] [G loss: 1.795103]\n",
      "epoch:14 step:11256 [D loss: 0.627679, acc: 70.31%] [G loss: 1.918351]\n",
      "epoch:14 step:11257 [D loss: 0.693796, acc: 53.12%] [G loss: 1.938791]\n",
      "epoch:14 step:11258 [D loss: 0.539438, acc: 81.25%] [G loss: 1.562260]\n",
      "epoch:14 step:11259 [D loss: 0.595216, acc: 73.44%] [G loss: 1.836666]\n",
      "epoch:14 step:11260 [D loss: 0.708184, acc: 55.47%] [G loss: 1.636721]\n",
      "epoch:14 step:11261 [D loss: 0.514688, acc: 78.91%] [G loss: 1.888214]\n",
      "epoch:14 step:11262 [D loss: 0.502280, acc: 89.06%] [G loss: 1.850508]\n",
      "epoch:14 step:11263 [D loss: 0.690894, acc: 57.03%] [G loss: 1.927919]\n",
      "epoch:14 step:11264 [D loss: 0.756950, acc: 41.41%] [G loss: 1.696582]\n",
      "epoch:14 step:11265 [D loss: 0.611398, acc: 66.41%] [G loss: 1.364079]\n",
      "epoch:14 step:11266 [D loss: 0.477940, acc: 86.72%] [G loss: 2.025796]\n",
      "epoch:14 step:11267 [D loss: 0.689363, acc: 55.47%] [G loss: 1.795272]\n",
      "epoch:14 step:11268 [D loss: 0.940077, acc: 31.25%] [G loss: 1.491082]\n",
      "epoch:14 step:11269 [D loss: 0.762420, acc: 47.66%] [G loss: 1.759875]\n",
      "epoch:14 step:11270 [D loss: 0.617810, acc: 64.06%] [G loss: 1.560071]\n",
      "epoch:14 step:11271 [D loss: 0.710578, acc: 55.47%] [G loss: 1.501527]\n",
      "epoch:14 step:11272 [D loss: 0.630347, acc: 67.19%] [G loss: 1.553687]\n",
      "epoch:14 step:11273 [D loss: 0.871249, acc: 28.12%] [G loss: 1.355785]\n",
      "epoch:14 step:11274 [D loss: 0.524617, acc: 82.03%] [G loss: 2.090685]\n",
      "epoch:14 step:11275 [D loss: 0.665522, acc: 60.16%] [G loss: 1.767477]\n",
      "epoch:14 step:11276 [D loss: 0.699520, acc: 51.56%] [G loss: 1.970811]\n",
      "epoch:14 step:11277 [D loss: 0.504562, acc: 81.25%] [G loss: 1.516615]\n",
      "epoch:14 step:11278 [D loss: 0.629761, acc: 65.62%] [G loss: 1.964594]\n",
      "epoch:14 step:11279 [D loss: 0.691321, acc: 53.91%] [G loss: 1.736089]\n",
      "epoch:14 step:11280 [D loss: 0.779952, acc: 40.62%] [G loss: 1.566572]\n",
      "epoch:14 step:11281 [D loss: 0.502304, acc: 90.62%] [G loss: 1.595440]\n",
      "epoch:14 step:11282 [D loss: 0.659243, acc: 62.50%] [G loss: 1.759578]\n",
      "epoch:14 step:11283 [D loss: 0.663964, acc: 56.25%] [G loss: 1.843652]\n",
      "epoch:14 step:11284 [D loss: 0.697445, acc: 55.47%] [G loss: 1.739671]\n",
      "epoch:14 step:11285 [D loss: 0.654424, acc: 60.16%] [G loss: 1.708445]\n",
      "epoch:14 step:11286 [D loss: 0.688632, acc: 56.25%] [G loss: 2.104380]\n",
      "epoch:14 step:11287 [D loss: 0.569000, acc: 77.34%] [G loss: 1.901651]\n",
      "epoch:14 step:11288 [D loss: 0.595996, acc: 66.41%] [G loss: 1.703356]\n",
      "epoch:14 step:11289 [D loss: 0.593837, acc: 64.06%] [G loss: 1.686200]\n",
      "epoch:14 step:11290 [D loss: 0.873261, acc: 28.91%] [G loss: 1.310552]\n",
      "epoch:14 step:11291 [D loss: 0.719096, acc: 46.09%] [G loss: 1.717348]\n",
      "epoch:14 step:11292 [D loss: 0.556558, acc: 77.34%] [G loss: 1.699509]\n",
      "epoch:14 step:11293 [D loss: 0.765783, acc: 39.84%] [G loss: 1.367762]\n",
      "epoch:14 step:11294 [D loss: 0.759067, acc: 50.00%] [G loss: 1.537088]\n",
      "epoch:14 step:11295 [D loss: 0.759435, acc: 45.31%] [G loss: 1.758834]\n",
      "epoch:14 step:11296 [D loss: 0.643829, acc: 60.16%] [G loss: 1.765891]\n",
      "epoch:14 step:11297 [D loss: 0.611747, acc: 70.31%] [G loss: 2.173760]\n",
      "epoch:14 step:11298 [D loss: 0.617277, acc: 64.84%] [G loss: 1.923870]\n",
      "epoch:14 step:11299 [D loss: 0.628464, acc: 63.28%] [G loss: 1.787976]\n",
      "epoch:14 step:11300 [D loss: 0.678869, acc: 58.59%] [G loss: 1.731855]\n",
      "epoch:14 step:11301 [D loss: 0.571485, acc: 71.09%] [G loss: 1.714039]\n",
      "epoch:14 step:11302 [D loss: 0.478790, acc: 85.94%] [G loss: 1.464525]\n",
      "epoch:14 step:11303 [D loss: 0.465333, acc: 86.72%] [G loss: 1.817658]\n",
      "epoch:14 step:11304 [D loss: 0.557643, acc: 74.22%] [G loss: 1.769693]\n",
      "epoch:14 step:11305 [D loss: 0.648193, acc: 57.81%] [G loss: 1.976863]\n",
      "epoch:14 step:11306 [D loss: 0.795794, acc: 35.16%] [G loss: 1.554174]\n",
      "epoch:14 step:11307 [D loss: 0.932798, acc: 15.62%] [G loss: 1.406038]\n",
      "epoch:14 step:11308 [D loss: 0.557356, acc: 81.25%] [G loss: 1.940216]\n",
      "epoch:14 step:11309 [D loss: 0.851306, acc: 31.25%] [G loss: 1.541085]\n",
      "epoch:14 step:11310 [D loss: 0.692670, acc: 56.25%] [G loss: 1.566631]\n",
      "epoch:14 step:11311 [D loss: 0.831948, acc: 35.94%] [G loss: 1.727635]\n",
      "epoch:14 step:11312 [D loss: 0.822043, acc: 37.50%] [G loss: 1.615473]\n",
      "epoch:14 step:11313 [D loss: 0.567318, acc: 78.91%] [G loss: 2.015642]\n",
      "epoch:14 step:11314 [D loss: 0.518884, acc: 75.78%] [G loss: 1.819275]\n",
      "epoch:14 step:11315 [D loss: 0.494276, acc: 87.50%] [G loss: 1.949961]\n",
      "epoch:14 step:11316 [D loss: 0.742112, acc: 43.75%] [G loss: 2.070105]\n",
      "epoch:14 step:11317 [D loss: 0.670942, acc: 59.38%] [G loss: 1.638405]\n",
      "epoch:14 step:11318 [D loss: 0.740818, acc: 46.09%] [G loss: 1.800914]\n",
      "epoch:14 step:11319 [D loss: 0.859868, acc: 26.56%] [G loss: 1.502573]\n",
      "epoch:14 step:11320 [D loss: 0.647535, acc: 62.50%] [G loss: 1.696360]\n",
      "epoch:14 step:11321 [D loss: 0.393181, acc: 78.91%] [G loss: 1.776066]\n",
      "epoch:14 step:11322 [D loss: 0.713678, acc: 50.78%] [G loss: 1.496698]\n",
      "epoch:14 step:11323 [D loss: 0.545110, acc: 82.03%] [G loss: 1.737363]\n",
      "epoch:14 step:11324 [D loss: 0.488969, acc: 89.06%] [G loss: 1.899835]\n",
      "epoch:14 step:11325 [D loss: 0.907180, acc: 25.78%] [G loss: 1.515385]\n",
      "epoch:14 step:11326 [D loss: 0.727451, acc: 46.88%] [G loss: 1.724521]\n",
      "epoch:14 step:11327 [D loss: 0.720761, acc: 49.22%] [G loss: 1.784842]\n",
      "epoch:14 step:11328 [D loss: 0.583835, acc: 73.44%] [G loss: 1.721577]\n",
      "epoch:14 step:11329 [D loss: 0.790732, acc: 34.38%] [G loss: 1.700279]\n",
      "epoch:14 step:11330 [D loss: 0.603463, acc: 67.19%] [G loss: 1.835439]\n",
      "epoch:14 step:11331 [D loss: 0.736290, acc: 46.09%] [G loss: 1.756382]\n",
      "epoch:14 step:11332 [D loss: 0.638954, acc: 66.41%] [G loss: 2.187786]\n",
      "epoch:14 step:11333 [D loss: 0.594733, acc: 70.31%] [G loss: 1.863266]\n",
      "epoch:14 step:11334 [D loss: 0.554500, acc: 74.22%] [G loss: 2.061267]\n",
      "epoch:14 step:11335 [D loss: 0.544472, acc: 82.81%] [G loss: 2.057564]\n",
      "epoch:14 step:11336 [D loss: 0.735911, acc: 50.78%] [G loss: 1.574792]\n",
      "epoch:14 step:11337 [D loss: 0.664100, acc: 56.25%] [G loss: 1.628773]\n",
      "epoch:14 step:11338 [D loss: 0.491150, acc: 87.50%] [G loss: 1.872040]\n",
      "epoch:14 step:11339 [D loss: 0.684318, acc: 56.25%] [G loss: 1.749517]\n",
      "epoch:14 step:11340 [D loss: 0.643356, acc: 64.84%] [G loss: 1.685150]\n",
      "epoch:14 step:11341 [D loss: 0.789871, acc: 50.00%] [G loss: 1.612676]\n",
      "epoch:14 step:11342 [D loss: 0.625611, acc: 65.62%] [G loss: 1.848120]\n",
      "epoch:14 step:11343 [D loss: 0.640274, acc: 62.50%] [G loss: 1.732395]\n",
      "epoch:14 step:11344 [D loss: 0.671240, acc: 56.25%] [G loss: 1.722759]\n",
      "epoch:14 step:11345 [D loss: 0.772224, acc: 43.75%] [G loss: 1.563423]\n",
      "epoch:14 step:11346 [D loss: 0.585022, acc: 73.44%] [G loss: 1.785393]\n",
      "epoch:14 step:11347 [D loss: 0.709679, acc: 54.69%] [G loss: 1.338033]\n",
      "epoch:14 step:11348 [D loss: 0.631927, acc: 67.97%] [G loss: 1.742603]\n",
      "epoch:14 step:11349 [D loss: 0.491392, acc: 80.47%] [G loss: 1.984733]\n",
      "epoch:14 step:11350 [D loss: 0.696643, acc: 50.78%] [G loss: 1.415628]\n",
      "epoch:14 step:11351 [D loss: 0.509362, acc: 81.25%] [G loss: 1.750995]\n",
      "epoch:14 step:11352 [D loss: 0.646827, acc: 64.84%] [G loss: 1.646571]\n",
      "epoch:14 step:11353 [D loss: 0.451006, acc: 91.41%] [G loss: 1.674309]\n",
      "epoch:14 step:11354 [D loss: 0.735539, acc: 50.00%] [G loss: 1.596756]\n",
      "epoch:14 step:11355 [D loss: 0.574649, acc: 77.34%] [G loss: 1.718478]\n",
      "epoch:14 step:11356 [D loss: 0.333021, acc: 98.44%] [G loss: 2.128175]\n",
      "epoch:14 step:11357 [D loss: 0.393193, acc: 91.41%] [G loss: 1.833936]\n",
      "epoch:14 step:11358 [D loss: 1.182622, acc: 9.38%] [G loss: 1.602691]\n",
      "epoch:14 step:11359 [D loss: 0.520537, acc: 87.50%] [G loss: 1.736092]\n",
      "epoch:14 step:11360 [D loss: 0.639934, acc: 64.84%] [G loss: 1.849442]\n",
      "epoch:14 step:11361 [D loss: 0.766987, acc: 40.62%] [G loss: 1.764845]\n",
      "epoch:14 step:11362 [D loss: 0.652023, acc: 60.16%] [G loss: 1.702920]\n",
      "epoch:14 step:11363 [D loss: 0.743425, acc: 40.62%] [G loss: 1.769980]\n",
      "epoch:14 step:11364 [D loss: 0.462473, acc: 92.97%] [G loss: 1.922570]\n",
      "epoch:14 step:11365 [D loss: 0.926939, acc: 15.62%] [G loss: 1.407341]\n",
      "epoch:14 step:11366 [D loss: 0.689660, acc: 59.38%] [G loss: 2.029471]\n",
      "epoch:14 step:11367 [D loss: 0.419804, acc: 97.66%] [G loss: 1.775407]\n",
      "epoch:14 step:11368 [D loss: 0.549077, acc: 71.88%] [G loss: 1.770006]\n",
      "epoch:14 step:11369 [D loss: 0.651987, acc: 64.84%] [G loss: 1.599001]\n",
      "epoch:14 step:11370 [D loss: 0.463552, acc: 85.94%] [G loss: 1.629244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11371 [D loss: 0.711934, acc: 51.56%] [G loss: 1.676024]\n",
      "epoch:14 step:11372 [D loss: 0.705920, acc: 55.47%] [G loss: 1.912648]\n",
      "epoch:14 step:11373 [D loss: 0.528051, acc: 81.25%] [G loss: 1.563634]\n",
      "epoch:14 step:11374 [D loss: 0.984197, acc: 10.94%] [G loss: 1.471368]\n",
      "epoch:14 step:11375 [D loss: 0.671875, acc: 57.03%] [G loss: 1.635028]\n",
      "epoch:14 step:11376 [D loss: 0.671658, acc: 53.91%] [G loss: 1.703004]\n",
      "epoch:14 step:11377 [D loss: 0.516083, acc: 77.34%] [G loss: 1.699932]\n",
      "epoch:14 step:11378 [D loss: 0.739692, acc: 43.75%] [G loss: 1.697432]\n",
      "epoch:14 step:11379 [D loss: 0.816659, acc: 33.59%] [G loss: 1.134781]\n",
      "epoch:14 step:11380 [D loss: 0.746192, acc: 46.88%] [G loss: 1.833103]\n",
      "epoch:14 step:11381 [D loss: 0.618824, acc: 64.06%] [G loss: 1.922055]\n",
      "epoch:14 step:11382 [D loss: 0.392885, acc: 88.28%] [G loss: 2.055836]\n",
      "epoch:14 step:11383 [D loss: 0.450731, acc: 92.19%] [G loss: 1.977620]\n",
      "epoch:14 step:11384 [D loss: 0.696613, acc: 50.78%] [G loss: 2.020584]\n",
      "epoch:14 step:11385 [D loss: 0.593143, acc: 71.09%] [G loss: 2.047657]\n",
      "epoch:14 step:11386 [D loss: 0.721553, acc: 50.00%] [G loss: 1.622765]\n",
      "epoch:14 step:11387 [D loss: 0.479193, acc: 82.81%] [G loss: 2.001887]\n",
      "epoch:14 step:11388 [D loss: 0.694290, acc: 51.56%] [G loss: 1.675839]\n",
      "epoch:14 step:11389 [D loss: 0.603831, acc: 67.19%] [G loss: 1.570299]\n",
      "epoch:14 step:11390 [D loss: 0.699595, acc: 58.59%] [G loss: 1.893959]\n",
      "epoch:14 step:11391 [D loss: 0.542626, acc: 72.66%] [G loss: 1.793326]\n",
      "epoch:14 step:11392 [D loss: 0.487618, acc: 89.84%] [G loss: 1.892441]\n",
      "epoch:14 step:11393 [D loss: 0.586083, acc: 75.00%] [G loss: 1.707154]\n",
      "epoch:14 step:11394 [D loss: 0.589745, acc: 71.88%] [G loss: 1.953512]\n",
      "epoch:14 step:11395 [D loss: 0.681204, acc: 61.72%] [G loss: 1.726828]\n",
      "epoch:14 step:11396 [D loss: 0.537534, acc: 83.59%] [G loss: 1.611573]\n",
      "epoch:14 step:11397 [D loss: 0.561661, acc: 75.00%] [G loss: 1.626309]\n",
      "epoch:14 step:11398 [D loss: 0.615937, acc: 70.31%] [G loss: 1.809397]\n",
      "epoch:14 step:11399 [D loss: 0.836378, acc: 28.91%] [G loss: 1.418916]\n",
      "epoch:14 step:11400 [D loss: 0.468020, acc: 95.31%] [G loss: 1.852965]\n",
      "epoch:14 step:11401 [D loss: 0.824289, acc: 28.12%] [G loss: 1.726493]\n",
      "epoch:14 step:11402 [D loss: 0.656667, acc: 58.59%] [G loss: 1.714965]\n",
      "epoch:14 step:11403 [D loss: 0.630233, acc: 67.97%] [G loss: 1.868105]\n",
      "epoch:14 step:11404 [D loss: 0.813635, acc: 32.03%] [G loss: 1.517456]\n",
      "epoch:14 step:11405 [D loss: 0.804706, acc: 47.66%] [G loss: 2.005545]\n",
      "epoch:14 step:11406 [D loss: 0.576708, acc: 75.78%] [G loss: 1.825666]\n",
      "epoch:14 step:11407 [D loss: 0.931738, acc: 25.00%] [G loss: 1.608685]\n",
      "epoch:14 step:11408 [D loss: 0.781047, acc: 40.62%] [G loss: 1.641689]\n",
      "epoch:14 step:11409 [D loss: 0.625804, acc: 60.16%] [G loss: 1.835872]\n",
      "epoch:14 step:11410 [D loss: 0.625591, acc: 67.19%] [G loss: 1.704788]\n",
      "epoch:14 step:11411 [D loss: 0.701800, acc: 53.12%] [G loss: 1.595574]\n",
      "epoch:14 step:11412 [D loss: 0.661686, acc: 59.38%] [G loss: 1.779594]\n",
      "epoch:14 step:11413 [D loss: 0.813908, acc: 40.62%] [G loss: 1.560291]\n",
      "epoch:14 step:11414 [D loss: 0.549137, acc: 79.69%] [G loss: 1.738563]\n",
      "epoch:14 step:11415 [D loss: 0.900324, acc: 18.75%] [G loss: 1.410026]\n",
      "epoch:14 step:11416 [D loss: 0.562689, acc: 67.19%] [G loss: 1.804839]\n",
      "epoch:14 step:11417 [D loss: 0.578602, acc: 62.50%] [G loss: 1.714476]\n",
      "epoch:14 step:11418 [D loss: 0.635837, acc: 64.84%] [G loss: 1.825048]\n",
      "epoch:14 step:11419 [D loss: 0.656074, acc: 65.62%] [G loss: 1.755212]\n",
      "epoch:14 step:11420 [D loss: 0.747906, acc: 42.19%] [G loss: 1.761597]\n",
      "epoch:14 step:11421 [D loss: 0.476393, acc: 89.06%] [G loss: 2.152565]\n",
      "epoch:14 step:11422 [D loss: 0.558970, acc: 59.38%] [G loss: 1.427912]\n",
      "epoch:14 step:11423 [D loss: 0.557059, acc: 70.31%] [G loss: 1.569222]\n",
      "epoch:14 step:11424 [D loss: 0.595850, acc: 60.94%] [G loss: 1.924637]\n",
      "epoch:14 step:11425 [D loss: 0.763195, acc: 41.41%] [G loss: 1.527699]\n",
      "epoch:14 step:11426 [D loss: 0.795759, acc: 36.72%] [G loss: 1.478626]\n",
      "epoch:14 step:11427 [D loss: 0.589911, acc: 73.44%] [G loss: 1.649711]\n",
      "epoch:14 step:11428 [D loss: 0.712297, acc: 53.91%] [G loss: 1.524132]\n",
      "epoch:14 step:11429 [D loss: 0.522363, acc: 81.25%] [G loss: 1.626829]\n",
      "epoch:14 step:11430 [D loss: 0.459481, acc: 90.62%] [G loss: 1.981229]\n",
      "epoch:14 step:11431 [D loss: 0.737597, acc: 43.75%] [G loss: 1.761298]\n",
      "epoch:14 step:11432 [D loss: 0.781024, acc: 40.62%] [G loss: 1.828530]\n",
      "epoch:14 step:11433 [D loss: 1.063682, acc: 28.12%] [G loss: 1.590676]\n",
      "epoch:14 step:11434 [D loss: 0.687028, acc: 54.69%] [G loss: 1.687842]\n",
      "epoch:14 step:11435 [D loss: 0.678318, acc: 57.81%] [G loss: 1.855715]\n",
      "epoch:14 step:11436 [D loss: 0.756548, acc: 42.97%] [G loss: 1.860112]\n",
      "epoch:14 step:11437 [D loss: 0.710875, acc: 50.78%] [G loss: 1.563158]\n",
      "epoch:14 step:11438 [D loss: 0.497875, acc: 72.66%] [G loss: 1.759281]\n",
      "epoch:14 step:11439 [D loss: 0.837622, acc: 42.97%] [G loss: 1.257802]\n",
      "epoch:14 step:11440 [D loss: 0.687438, acc: 55.47%] [G loss: 1.670709]\n",
      "epoch:14 step:11441 [D loss: 0.669931, acc: 59.38%] [G loss: 1.806445]\n",
      "epoch:14 step:11442 [D loss: 0.646540, acc: 67.19%] [G loss: 1.605128]\n",
      "epoch:14 step:11443 [D loss: 0.681377, acc: 59.38%] [G loss: 1.747264]\n",
      "epoch:14 step:11444 [D loss: 0.572048, acc: 67.97%] [G loss: 1.773760]\n",
      "epoch:14 step:11445 [D loss: 0.810313, acc: 35.94%] [G loss: 1.557535]\n",
      "epoch:14 step:11446 [D loss: 0.737723, acc: 46.88%] [G loss: 1.708979]\n",
      "epoch:14 step:11447 [D loss: 0.636153, acc: 64.84%] [G loss: 1.713791]\n",
      "epoch:14 step:11448 [D loss: 0.854721, acc: 31.25%] [G loss: 1.652813]\n",
      "epoch:14 step:11449 [D loss: 0.680954, acc: 52.34%] [G loss: 1.496768]\n",
      "epoch:14 step:11450 [D loss: 0.675986, acc: 58.59%] [G loss: 1.793646]\n",
      "epoch:14 step:11451 [D loss: 0.574836, acc: 77.34%] [G loss: 1.768335]\n",
      "epoch:14 step:11452 [D loss: 0.647638, acc: 67.97%] [G loss: 1.391855]\n",
      "epoch:14 step:11453 [D loss: 1.096307, acc: 6.25%] [G loss: 1.378739]\n",
      "epoch:14 step:11454 [D loss: 0.638947, acc: 65.62%] [G loss: 1.845206]\n",
      "epoch:14 step:11455 [D loss: 0.633645, acc: 63.28%] [G loss: 2.026801]\n",
      "epoch:14 step:11456 [D loss: 0.607489, acc: 67.19%] [G loss: 1.641238]\n",
      "epoch:14 step:11457 [D loss: 0.397574, acc: 90.62%] [G loss: 1.819600]\n",
      "epoch:14 step:11458 [D loss: 0.700973, acc: 56.25%] [G loss: 1.673281]\n",
      "epoch:14 step:11459 [D loss: 0.790704, acc: 31.25%] [G loss: 1.402268]\n",
      "epoch:14 step:11460 [D loss: 0.740519, acc: 45.31%] [G loss: 1.617206]\n",
      "epoch:14 step:11461 [D loss: 0.600981, acc: 74.22%] [G loss: 1.692780]\n",
      "epoch:14 step:11462 [D loss: 0.748810, acc: 52.34%] [G loss: 1.627274]\n",
      "epoch:14 step:11463 [D loss: 0.590844, acc: 73.44%] [G loss: 1.775584]\n",
      "epoch:14 step:11464 [D loss: 0.729503, acc: 53.91%] [G loss: 1.606368]\n",
      "epoch:14 step:11465 [D loss: 0.635686, acc: 63.28%] [G loss: 1.539236]\n",
      "epoch:14 step:11466 [D loss: 0.734320, acc: 50.00%] [G loss: 1.913478]\n",
      "epoch:14 step:11467 [D loss: 0.653891, acc: 57.81%] [G loss: 1.538352]\n",
      "epoch:14 step:11468 [D loss: 0.661753, acc: 57.03%] [G loss: 1.737816]\n",
      "epoch:14 step:11469 [D loss: 0.622190, acc: 68.75%] [G loss: 1.531876]\n",
      "epoch:14 step:11470 [D loss: 0.651356, acc: 64.84%] [G loss: 1.581448]\n",
      "epoch:14 step:11471 [D loss: 0.582093, acc: 74.22%] [G loss: 1.745818]\n",
      "epoch:14 step:11472 [D loss: 0.729661, acc: 46.88%] [G loss: 1.812298]\n",
      "epoch:14 step:11473 [D loss: 0.615904, acc: 60.16%] [G loss: 1.732772]\n",
      "epoch:14 step:11474 [D loss: 0.587651, acc: 67.19%] [G loss: 1.527392]\n",
      "epoch:14 step:11475 [D loss: 0.533911, acc: 78.91%] [G loss: 1.775230]\n",
      "epoch:14 step:11476 [D loss: 0.421229, acc: 88.28%] [G loss: 1.632079]\n",
      "epoch:14 step:11477 [D loss: 0.459746, acc: 89.84%] [G loss: 2.022540]\n",
      "epoch:14 step:11478 [D loss: 0.716864, acc: 47.66%] [G loss: 1.503013]\n",
      "epoch:14 step:11479 [D loss: 0.649787, acc: 66.41%] [G loss: 1.808465]\n",
      "epoch:14 step:11480 [D loss: 0.948310, acc: 21.09%] [G loss: 1.798726]\n",
      "epoch:14 step:11481 [D loss: 0.614190, acc: 69.53%] [G loss: 1.767782]\n",
      "epoch:14 step:11482 [D loss: 0.518958, acc: 84.38%] [G loss: 1.550087]\n",
      "epoch:14 step:11483 [D loss: 0.976600, acc: 27.34%] [G loss: 1.677869]\n",
      "epoch:14 step:11484 [D loss: 0.598175, acc: 67.97%] [G loss: 1.989535]\n",
      "epoch:14 step:11485 [D loss: 0.363260, acc: 97.66%] [G loss: 1.922186]\n",
      "epoch:14 step:11486 [D loss: 0.815710, acc: 35.16%] [G loss: 1.373127]\n",
      "epoch:14 step:11487 [D loss: 1.232117, acc: 3.12%] [G loss: 1.221032]\n",
      "epoch:14 step:11488 [D loss: 0.828351, acc: 39.06%] [G loss: 1.505716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11489 [D loss: 0.986198, acc: 12.50%] [G loss: 1.313031]\n",
      "epoch:14 step:11490 [D loss: 0.721482, acc: 50.00%] [G loss: 1.796700]\n",
      "epoch:14 step:11491 [D loss: 0.651828, acc: 57.03%] [G loss: 1.878137]\n",
      "epoch:14 step:11492 [D loss: 0.472529, acc: 84.38%] [G loss: 1.650672]\n",
      "epoch:14 step:11493 [D loss: 0.527890, acc: 80.47%] [G loss: 1.768116]\n",
      "epoch:14 step:11494 [D loss: 0.785473, acc: 40.62%] [G loss: 1.664244]\n",
      "epoch:14 step:11495 [D loss: 0.508972, acc: 85.16%] [G loss: 1.811547]\n",
      "epoch:14 step:11496 [D loss: 0.720156, acc: 53.12%] [G loss: 1.615255]\n",
      "epoch:14 step:11497 [D loss: 0.757801, acc: 45.31%] [G loss: 1.725215]\n",
      "epoch:14 step:11498 [D loss: 0.589838, acc: 71.88%] [G loss: 2.003970]\n",
      "epoch:14 step:11499 [D loss: 0.704331, acc: 54.69%] [G loss: 1.499603]\n",
      "epoch:14 step:11500 [D loss: 0.717734, acc: 46.88%] [G loss: 1.736899]\n",
      "epoch:14 step:11501 [D loss: 0.511704, acc: 85.16%] [G loss: 1.772225]\n",
      "epoch:14 step:11502 [D loss: 0.593109, acc: 71.88%] [G loss: 1.815647]\n",
      "epoch:14 step:11503 [D loss: 0.639471, acc: 71.09%] [G loss: 1.938962]\n",
      "epoch:14 step:11504 [D loss: 0.628949, acc: 64.06%] [G loss: 1.781560]\n",
      "epoch:14 step:11505 [D loss: 0.855079, acc: 23.44%] [G loss: 1.544283]\n",
      "epoch:14 step:11506 [D loss: 0.683608, acc: 57.03%] [G loss: 1.691073]\n",
      "epoch:14 step:11507 [D loss: 0.741942, acc: 46.88%] [G loss: 1.501264]\n",
      "epoch:14 step:11508 [D loss: 0.667554, acc: 65.62%] [G loss: 1.644180]\n",
      "epoch:14 step:11509 [D loss: 0.900115, acc: 23.44%] [G loss: 1.514188]\n",
      "epoch:14 step:11510 [D loss: 0.682374, acc: 57.81%] [G loss: 1.605752]\n",
      "epoch:14 step:11511 [D loss: 0.552392, acc: 80.47%] [G loss: 1.704143]\n",
      "epoch:14 step:11512 [D loss: 0.411324, acc: 96.09%] [G loss: 1.928488]\n",
      "epoch:14 step:11513 [D loss: 0.457684, acc: 89.84%] [G loss: 1.749033]\n",
      "epoch:14 step:11514 [D loss: 0.637104, acc: 60.16%] [G loss: 1.833186]\n",
      "epoch:14 step:11515 [D loss: 0.798139, acc: 42.97%] [G loss: 2.073056]\n",
      "epoch:14 step:11516 [D loss: 0.600420, acc: 68.75%] [G loss: 1.881683]\n",
      "epoch:14 step:11517 [D loss: 0.763206, acc: 49.22%] [G loss: 1.501122]\n",
      "epoch:14 step:11518 [D loss: 0.622502, acc: 64.06%] [G loss: 1.641072]\n",
      "epoch:14 step:11519 [D loss: 0.336685, acc: 97.66%] [G loss: 1.863925]\n",
      "epoch:14 step:11520 [D loss: 0.603245, acc: 72.66%] [G loss: 1.906754]\n",
      "epoch:14 step:11521 [D loss: 0.608480, acc: 66.41%] [G loss: 1.643733]\n",
      "epoch:14 step:11522 [D loss: 0.436802, acc: 90.62%] [G loss: 1.827561]\n",
      "epoch:14 step:11523 [D loss: 0.749889, acc: 46.09%] [G loss: 1.575893]\n",
      "epoch:14 step:11524 [D loss: 0.633070, acc: 70.31%] [G loss: 1.481225]\n",
      "epoch:14 step:11525 [D loss: 0.927541, acc: 21.88%] [G loss: 1.424484]\n",
      "epoch:14 step:11526 [D loss: 0.682878, acc: 59.38%] [G loss: 1.428046]\n",
      "epoch:14 step:11527 [D loss: 0.381730, acc: 92.97%] [G loss: 1.645726]\n",
      "epoch:14 step:11528 [D loss: 0.466075, acc: 86.72%] [G loss: 2.059371]\n",
      "epoch:14 step:11529 [D loss: 0.357405, acc: 94.53%] [G loss: 1.805715]\n",
      "epoch:14 step:11530 [D loss: 0.575358, acc: 75.00%] [G loss: 2.011688]\n",
      "epoch:14 step:11531 [D loss: 0.650321, acc: 57.03%] [G loss: 2.094259]\n",
      "epoch:14 step:11532 [D loss: 0.450573, acc: 96.09%] [G loss: 1.951719]\n",
      "epoch:14 step:11533 [D loss: 0.673524, acc: 60.16%] [G loss: 1.615714]\n",
      "epoch:14 step:11534 [D loss: 0.659750, acc: 57.81%] [G loss: 1.590366]\n",
      "epoch:14 step:11535 [D loss: 0.806784, acc: 29.69%] [G loss: 1.621927]\n",
      "epoch:14 step:11536 [D loss: 0.415622, acc: 82.03%] [G loss: 2.007858]\n",
      "epoch:14 step:11537 [D loss: 0.769764, acc: 46.88%] [G loss: 1.159387]\n",
      "epoch:14 step:11538 [D loss: 0.717355, acc: 53.12%] [G loss: 2.020304]\n",
      "epoch:14 step:11539 [D loss: 0.588966, acc: 74.22%] [G loss: 1.963605]\n",
      "epoch:14 step:11540 [D loss: 0.499062, acc: 85.94%] [G loss: 1.665168]\n",
      "epoch:14 step:11541 [D loss: 0.581878, acc: 67.19%] [G loss: 1.827101]\n",
      "epoch:14 step:11542 [D loss: 0.668440, acc: 58.59%] [G loss: 1.879974]\n",
      "epoch:14 step:11543 [D loss: 0.897702, acc: 30.47%] [G loss: 1.427561]\n",
      "epoch:14 step:11544 [D loss: 0.792474, acc: 38.28%] [G loss: 1.555359]\n",
      "epoch:14 step:11545 [D loss: 0.773222, acc: 45.31%] [G loss: 1.599074]\n",
      "epoch:14 step:11546 [D loss: 0.735676, acc: 57.03%] [G loss: 1.617915]\n",
      "epoch:14 step:11547 [D loss: 0.494457, acc: 76.56%] [G loss: 1.644891]\n",
      "epoch:14 step:11548 [D loss: 0.586418, acc: 59.38%] [G loss: 1.666693]\n",
      "epoch:14 step:11549 [D loss: 0.542686, acc: 81.25%] [G loss: 1.828343]\n",
      "epoch:14 step:11550 [D loss: 0.828592, acc: 42.19%] [G loss: 1.327555]\n",
      "epoch:14 step:11551 [D loss: 0.519589, acc: 79.69%] [G loss: 1.674610]\n",
      "epoch:14 step:11552 [D loss: 0.708143, acc: 48.44%] [G loss: 1.136561]\n",
      "epoch:14 step:11553 [D loss: 0.701369, acc: 50.00%] [G loss: 1.556692]\n",
      "epoch:14 step:11554 [D loss: 0.810058, acc: 44.53%] [G loss: 1.694881]\n",
      "epoch:14 step:11555 [D loss: 0.358451, acc: 95.31%] [G loss: 1.742440]\n",
      "epoch:14 step:11556 [D loss: 0.468499, acc: 80.47%] [G loss: 2.019279]\n",
      "epoch:14 step:11557 [D loss: 0.740502, acc: 52.34%] [G loss: 1.693830]\n",
      "epoch:14 step:11558 [D loss: 0.574247, acc: 75.00%] [G loss: 1.495205]\n",
      "epoch:14 step:11559 [D loss: 0.756461, acc: 44.53%] [G loss: 1.353747]\n",
      "epoch:14 step:11560 [D loss: 0.623094, acc: 65.62%] [G loss: 1.419345]\n",
      "epoch:14 step:11561 [D loss: 0.647332, acc: 64.84%] [G loss: 1.523417]\n",
      "epoch:14 step:11562 [D loss: 0.486325, acc: 88.28%] [G loss: 1.866150]\n",
      "epoch:14 step:11563 [D loss: 0.726239, acc: 52.34%] [G loss: 1.751180]\n",
      "epoch:14 step:11564 [D loss: 0.497674, acc: 84.38%] [G loss: 1.735160]\n",
      "epoch:14 step:11565 [D loss: 0.566426, acc: 82.03%] [G loss: 1.802816]\n",
      "epoch:14 step:11566 [D loss: 1.181126, acc: 4.69%] [G loss: 1.380211]\n",
      "epoch:14 step:11567 [D loss: 0.813137, acc: 30.47%] [G loss: 1.363355]\n",
      "epoch:14 step:11568 [D loss: 0.570818, acc: 80.47%] [G loss: 1.574884]\n",
      "epoch:14 step:11569 [D loss: 0.608364, acc: 71.09%] [G loss: 1.960968]\n",
      "epoch:14 step:11570 [D loss: 0.547187, acc: 75.78%] [G loss: 1.804738]\n",
      "epoch:14 step:11571 [D loss: 1.243762, acc: 7.81%] [G loss: 1.115224]\n",
      "epoch:14 step:11572 [D loss: 0.712086, acc: 51.56%] [G loss: 1.617180]\n",
      "epoch:14 step:11573 [D loss: 0.901662, acc: 22.66%] [G loss: 1.463059]\n",
      "epoch:14 step:11574 [D loss: 0.780654, acc: 45.31%] [G loss: 1.662287]\n",
      "epoch:14 step:11575 [D loss: 0.665504, acc: 61.72%] [G loss: 1.903517]\n",
      "epoch:14 step:11576 [D loss: 0.731708, acc: 46.09%] [G loss: 1.619120]\n",
      "epoch:14 step:11577 [D loss: 0.731307, acc: 50.00%] [G loss: 1.494752]\n",
      "epoch:14 step:11578 [D loss: 0.551954, acc: 75.00%] [G loss: 1.689042]\n",
      "epoch:14 step:11579 [D loss: 0.408614, acc: 72.66%] [G loss: 2.057507]\n",
      "epoch:14 step:11580 [D loss: 0.604221, acc: 67.97%] [G loss: 1.534560]\n",
      "epoch:14 step:11581 [D loss: 0.744030, acc: 44.53%] [G loss: 1.613022]\n",
      "epoch:14 step:11582 [D loss: 0.684620, acc: 58.59%] [G loss: 1.693795]\n",
      "epoch:14 step:11583 [D loss: 0.891792, acc: 23.44%] [G loss: 1.334459]\n",
      "epoch:14 step:11584 [D loss: 0.659664, acc: 57.03%] [G loss: 1.627587]\n",
      "epoch:14 step:11585 [D loss: 0.543106, acc: 82.81%] [G loss: 1.453449]\n",
      "epoch:14 step:11586 [D loss: 0.555014, acc: 81.25%] [G loss: 1.992428]\n",
      "epoch:14 step:11587 [D loss: 0.488527, acc: 85.16%] [G loss: 2.066485]\n",
      "epoch:14 step:11588 [D loss: 0.585190, acc: 72.66%] [G loss: 1.795350]\n",
      "epoch:14 step:11589 [D loss: 0.637493, acc: 64.84%] [G loss: 1.922389]\n",
      "epoch:14 step:11590 [D loss: 0.883828, acc: 33.59%] [G loss: 1.499192]\n",
      "epoch:14 step:11591 [D loss: 0.645545, acc: 65.62%] [G loss: 1.825112]\n",
      "epoch:14 step:11592 [D loss: 0.712491, acc: 52.34%] [G loss: 1.640708]\n",
      "epoch:14 step:11593 [D loss: 0.546410, acc: 78.12%] [G loss: 1.911692]\n",
      "epoch:14 step:11594 [D loss: 0.670119, acc: 56.25%] [G loss: 1.472668]\n",
      "epoch:14 step:11595 [D loss: 0.788731, acc: 36.72%] [G loss: 1.587451]\n",
      "epoch:14 step:11596 [D loss: 0.574418, acc: 76.56%] [G loss: 1.533916]\n",
      "epoch:14 step:11597 [D loss: 0.565680, acc: 78.12%] [G loss: 1.920539]\n",
      "epoch:14 step:11598 [D loss: 0.691166, acc: 56.25%] [G loss: 2.074958]\n",
      "epoch:14 step:11599 [D loss: 0.552476, acc: 79.69%] [G loss: 1.919496]\n",
      "epoch:14 step:11600 [D loss: 0.446932, acc: 88.28%] [G loss: 1.957540]\n",
      "epoch:14 step:11601 [D loss: 0.769584, acc: 41.41%] [G loss: 1.902004]\n",
      "epoch:14 step:11602 [D loss: 0.701203, acc: 58.59%] [G loss: 1.708501]\n",
      "epoch:14 step:11603 [D loss: 0.697131, acc: 54.69%] [G loss: 1.598717]\n",
      "epoch:14 step:11604 [D loss: 0.978929, acc: 16.41%] [G loss: 1.264639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11605 [D loss: 0.503030, acc: 84.38%] [G loss: 1.929139]\n",
      "epoch:14 step:11606 [D loss: 0.645417, acc: 60.16%] [G loss: 1.478767]\n",
      "epoch:14 step:11607 [D loss: 0.544412, acc: 78.12%] [G loss: 1.832195]\n",
      "epoch:14 step:11608 [D loss: 0.732843, acc: 53.91%] [G loss: 1.812052]\n",
      "epoch:14 step:11609 [D loss: 0.558461, acc: 74.22%] [G loss: 1.941855]\n",
      "epoch:14 step:11610 [D loss: 0.691966, acc: 52.34%] [G loss: 1.923198]\n",
      "epoch:14 step:11611 [D loss: 0.555442, acc: 73.44%] [G loss: 1.781914]\n",
      "epoch:14 step:11612 [D loss: 0.579726, acc: 64.84%] [G loss: 1.580273]\n",
      "epoch:14 step:11613 [D loss: 0.581656, acc: 68.75%] [G loss: 1.794834]\n",
      "epoch:14 step:11614 [D loss: 0.484362, acc: 93.75%] [G loss: 2.322908]\n",
      "epoch:14 step:11615 [D loss: 0.510284, acc: 81.25%] [G loss: 2.213923]\n",
      "epoch:14 step:11616 [D loss: 0.934705, acc: 46.09%] [G loss: 1.478006]\n",
      "epoch:14 step:11617 [D loss: 0.752080, acc: 48.44%] [G loss: 1.403260]\n",
      "epoch:14 step:11618 [D loss: 0.987160, acc: 11.72%] [G loss: 1.330152]\n",
      "epoch:14 step:11619 [D loss: 0.571432, acc: 67.19%] [G loss: 1.759515]\n",
      "epoch:14 step:11620 [D loss: 0.642769, acc: 57.81%] [G loss: 1.586540]\n",
      "epoch:14 step:11621 [D loss: 0.869725, acc: 19.53%] [G loss: 1.279501]\n",
      "epoch:14 step:11622 [D loss: 0.621805, acc: 56.25%] [G loss: 1.445228]\n",
      "epoch:14 step:11623 [D loss: 0.699203, acc: 50.78%] [G loss: 1.601050]\n",
      "epoch:14 step:11624 [D loss: 0.698666, acc: 53.12%] [G loss: 1.872925]\n",
      "epoch:14 step:11625 [D loss: 0.586331, acc: 78.91%] [G loss: 1.713120]\n",
      "epoch:14 step:11626 [D loss: 0.820401, acc: 31.25%] [G loss: 1.771719]\n",
      "epoch:14 step:11627 [D loss: 0.571989, acc: 70.31%] [G loss: 1.973212]\n",
      "epoch:14 step:11628 [D loss: 0.672938, acc: 57.03%] [G loss: 1.831739]\n",
      "epoch:14 step:11629 [D loss: 0.704332, acc: 52.34%] [G loss: 1.571030]\n",
      "epoch:14 step:11630 [D loss: 0.716789, acc: 54.69%] [G loss: 1.818640]\n",
      "epoch:14 step:11631 [D loss: 0.432935, acc: 92.19%] [G loss: 1.628769]\n",
      "epoch:14 step:11632 [D loss: 0.701834, acc: 59.38%] [G loss: 1.730361]\n",
      "epoch:14 step:11633 [D loss: 0.760412, acc: 42.97%] [G loss: 1.536651]\n",
      "epoch:14 step:11634 [D loss: 0.688917, acc: 54.69%] [G loss: 1.637147]\n",
      "epoch:14 step:11635 [D loss: 0.737709, acc: 50.00%] [G loss: 1.833704]\n",
      "epoch:14 step:11636 [D loss: 0.677602, acc: 57.03%] [G loss: 1.869993]\n",
      "epoch:14 step:11637 [D loss: 0.636911, acc: 65.62%] [G loss: 1.750072]\n",
      "epoch:14 step:11638 [D loss: 0.701389, acc: 53.12%] [G loss: 1.644289]\n",
      "epoch:14 step:11639 [D loss: 0.525156, acc: 82.81%] [G loss: 2.234447]\n",
      "epoch:14 step:11640 [D loss: 0.664101, acc: 58.59%] [G loss: 1.667574]\n",
      "epoch:14 step:11641 [D loss: 0.658914, acc: 60.94%] [G loss: 1.804359]\n",
      "epoch:14 step:11642 [D loss: 0.639920, acc: 59.38%] [G loss: 1.726339]\n",
      "epoch:14 step:11643 [D loss: 0.620277, acc: 63.28%] [G loss: 1.840865]\n",
      "epoch:14 step:11644 [D loss: 0.617152, acc: 72.66%] [G loss: 1.680899]\n",
      "epoch:14 step:11645 [D loss: 0.866067, acc: 45.31%] [G loss: 1.633077]\n",
      "epoch:14 step:11646 [D loss: 0.800495, acc: 37.50%] [G loss: 1.670596]\n",
      "epoch:14 step:11647 [D loss: 0.582651, acc: 82.81%] [G loss: 2.114122]\n",
      "epoch:14 step:11648 [D loss: 0.669585, acc: 56.25%] [G loss: 1.530525]\n",
      "epoch:14 step:11649 [D loss: 0.589728, acc: 70.31%] [G loss: 1.772689]\n",
      "epoch:14 step:11650 [D loss: 0.598717, acc: 71.09%] [G loss: 1.948585]\n",
      "epoch:14 step:11651 [D loss: 0.490638, acc: 86.72%] [G loss: 1.841162]\n",
      "epoch:14 step:11652 [D loss: 0.765307, acc: 53.12%] [G loss: 1.482141]\n",
      "epoch:14 step:11653 [D loss: 0.603457, acc: 70.31%] [G loss: 1.939915]\n",
      "epoch:14 step:11654 [D loss: 0.763381, acc: 42.97%] [G loss: 1.483353]\n",
      "epoch:14 step:11655 [D loss: 0.796248, acc: 39.06%] [G loss: 1.474126]\n",
      "epoch:14 step:11656 [D loss: 0.540983, acc: 77.34%] [G loss: 1.716947]\n",
      "epoch:14 step:11657 [D loss: 1.161133, acc: 23.44%] [G loss: 1.328552]\n",
      "epoch:14 step:11658 [D loss: 0.812197, acc: 43.75%] [G loss: 1.681848]\n",
      "epoch:14 step:11659 [D loss: 0.602738, acc: 70.31%] [G loss: 2.191633]\n",
      "epoch:14 step:11660 [D loss: 0.666563, acc: 57.03%] [G loss: 1.564667]\n",
      "epoch:14 step:11661 [D loss: 0.795996, acc: 41.41%] [G loss: 1.683405]\n",
      "epoch:14 step:11662 [D loss: 0.597815, acc: 72.66%] [G loss: 1.591121]\n",
      "epoch:14 step:11663 [D loss: 0.630021, acc: 71.09%] [G loss: 1.869257]\n",
      "epoch:14 step:11664 [D loss: 0.753093, acc: 44.53%] [G loss: 1.610856]\n",
      "epoch:14 step:11665 [D loss: 0.733650, acc: 48.44%] [G loss: 1.489960]\n",
      "epoch:14 step:11666 [D loss: 0.778355, acc: 40.62%] [G loss: 1.595182]\n",
      "epoch:14 step:11667 [D loss: 0.623756, acc: 67.97%] [G loss: 1.601913]\n",
      "epoch:14 step:11668 [D loss: 0.719270, acc: 56.25%] [G loss: 1.681807]\n",
      "epoch:14 step:11669 [D loss: 0.621693, acc: 70.31%] [G loss: 1.779474]\n",
      "epoch:14 step:11670 [D loss: 0.623593, acc: 68.75%] [G loss: 1.676281]\n",
      "epoch:14 step:11671 [D loss: 0.650304, acc: 61.72%] [G loss: 1.964648]\n",
      "epoch:14 step:11672 [D loss: 0.570204, acc: 76.56%] [G loss: 1.880573]\n",
      "epoch:14 step:11673 [D loss: 0.715331, acc: 50.78%] [G loss: 1.918117]\n",
      "epoch:14 step:11674 [D loss: 0.864023, acc: 25.78%] [G loss: 1.592299]\n",
      "epoch:14 step:11675 [D loss: 0.612191, acc: 63.28%] [G loss: 1.814976]\n",
      "epoch:14 step:11676 [D loss: 0.681295, acc: 58.59%] [G loss: 1.781420]\n",
      "epoch:14 step:11677 [D loss: 0.614347, acc: 69.53%] [G loss: 1.701400]\n",
      "epoch:14 step:11678 [D loss: 0.823289, acc: 32.03%] [G loss: 1.566864]\n",
      "epoch:14 step:11679 [D loss: 0.452102, acc: 89.06%] [G loss: 2.194621]\n",
      "epoch:14 step:11680 [D loss: 0.772864, acc: 43.75%] [G loss: 1.780241]\n",
      "epoch:14 step:11681 [D loss: 0.567698, acc: 77.34%] [G loss: 2.206967]\n",
      "epoch:14 step:11682 [D loss: 0.503781, acc: 90.62%] [G loss: 1.743995]\n",
      "epoch:14 step:11683 [D loss: 0.768925, acc: 44.53%] [G loss: 1.521233]\n",
      "epoch:14 step:11684 [D loss: 0.793303, acc: 38.28%] [G loss: 1.879420]\n",
      "epoch:14 step:11685 [D loss: 0.925007, acc: 22.66%] [G loss: 1.486605]\n",
      "epoch:14 step:11686 [D loss: 0.453491, acc: 92.19%] [G loss: 1.714520]\n",
      "epoch:14 step:11687 [D loss: 0.730028, acc: 51.56%] [G loss: 1.850240]\n",
      "epoch:14 step:11688 [D loss: 0.568253, acc: 78.12%] [G loss: 1.570524]\n",
      "epoch:14 step:11689 [D loss: 0.933678, acc: 19.53%] [G loss: 1.397914]\n",
      "epoch:14 step:11690 [D loss: 0.886922, acc: 23.44%] [G loss: 1.509299]\n",
      "epoch:14 step:11691 [D loss: 0.480637, acc: 82.81%] [G loss: 2.086487]\n",
      "epoch:14 step:11692 [D loss: 0.692160, acc: 51.56%] [G loss: 1.773065]\n",
      "epoch:14 step:11693 [D loss: 0.531465, acc: 74.22%] [G loss: 1.576313]\n",
      "epoch:14 step:11694 [D loss: 0.617080, acc: 68.75%] [G loss: 1.766556]\n",
      "epoch:14 step:11695 [D loss: 0.730655, acc: 47.66%] [G loss: 1.615202]\n",
      "epoch:14 step:11696 [D loss: 0.523064, acc: 84.38%] [G loss: 1.748410]\n",
      "epoch:14 step:11697 [D loss: 0.545787, acc: 87.50%] [G loss: 1.746076]\n",
      "epoch:14 step:11698 [D loss: 0.697131, acc: 51.56%] [G loss: 1.874417]\n",
      "epoch:14 step:11699 [D loss: 0.676248, acc: 55.47%] [G loss: 1.691639]\n",
      "epoch:14 step:11700 [D loss: 0.608507, acc: 69.53%] [G loss: 1.775824]\n",
      "epoch:14 step:11701 [D loss: 0.411513, acc: 85.16%] [G loss: 1.898789]\n",
      "epoch:14 step:11702 [D loss: 0.548181, acc: 80.47%] [G loss: 1.868666]\n",
      "epoch:14 step:11703 [D loss: 0.663737, acc: 60.16%] [G loss: 1.580781]\n",
      "epoch:14 step:11704 [D loss: 0.496675, acc: 84.38%] [G loss: 2.211543]\n",
      "epoch:14 step:11705 [D loss: 0.948822, acc: 30.47%] [G loss: 1.475375]\n",
      "epoch:14 step:11706 [D loss: 0.443044, acc: 92.97%] [G loss: 1.879856]\n",
      "epoch:14 step:11707 [D loss: 0.503664, acc: 83.59%] [G loss: 1.854226]\n",
      "epoch:14 step:11708 [D loss: 0.679448, acc: 61.72%] [G loss: 1.822900]\n",
      "epoch:14 step:11709 [D loss: 0.724028, acc: 48.44%] [G loss: 1.624292]\n",
      "epoch:14 step:11710 [D loss: 0.524755, acc: 84.38%] [G loss: 1.782611]\n",
      "epoch:14 step:11711 [D loss: 1.040054, acc: 28.91%] [G loss: 1.501167]\n",
      "epoch:14 step:11712 [D loss: 0.823519, acc: 32.81%] [G loss: 1.805749]\n",
      "epoch:14 step:11713 [D loss: 0.880554, acc: 28.91%] [G loss: 1.631937]\n",
      "epoch:14 step:11714 [D loss: 0.723413, acc: 47.66%] [G loss: 1.522828]\n",
      "epoch:14 step:11715 [D loss: 0.451869, acc: 89.06%] [G loss: 1.556655]\n",
      "epoch:15 step:11716 [D loss: 0.535812, acc: 76.56%] [G loss: 1.779617]\n",
      "epoch:15 step:11717 [D loss: 0.606621, acc: 67.97%] [G loss: 1.927279]\n",
      "epoch:15 step:11718 [D loss: 0.832802, acc: 29.69%] [G loss: 1.559777]\n",
      "epoch:15 step:11719 [D loss: 0.696213, acc: 50.00%] [G loss: 1.623642]\n",
      "epoch:15 step:11720 [D loss: 0.650097, acc: 57.03%] [G loss: 1.768056]\n",
      "epoch:15 step:11721 [D loss: 0.605886, acc: 75.00%] [G loss: 1.840260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11722 [D loss: 0.561456, acc: 76.56%] [G loss: 1.606508]\n",
      "epoch:15 step:11723 [D loss: 0.886957, acc: 28.12%] [G loss: 1.452907]\n",
      "epoch:15 step:11724 [D loss: 0.662841, acc: 56.25%] [G loss: 1.962799]\n",
      "epoch:15 step:11725 [D loss: 0.815382, acc: 29.69%] [G loss: 1.626450]\n",
      "epoch:15 step:11726 [D loss: 0.608615, acc: 69.53%] [G loss: 1.851352]\n",
      "epoch:15 step:11727 [D loss: 0.666805, acc: 60.94%] [G loss: 1.249120]\n",
      "epoch:15 step:11728 [D loss: 0.783765, acc: 43.75%] [G loss: 1.559726]\n",
      "epoch:15 step:11729 [D loss: 0.732028, acc: 48.44%] [G loss: 1.798366]\n",
      "epoch:15 step:11730 [D loss: 0.628884, acc: 57.03%] [G loss: 1.652122]\n",
      "epoch:15 step:11731 [D loss: 0.658303, acc: 58.59%] [G loss: 1.596466]\n",
      "epoch:15 step:11732 [D loss: 0.432092, acc: 95.31%] [G loss: 1.926288]\n",
      "epoch:15 step:11733 [D loss: 0.533772, acc: 75.78%] [G loss: 1.673080]\n",
      "epoch:15 step:11734 [D loss: 0.696421, acc: 51.56%] [G loss: 1.510149]\n",
      "epoch:15 step:11735 [D loss: 0.430932, acc: 90.62%] [G loss: 1.548004]\n",
      "epoch:15 step:11736 [D loss: 0.539428, acc: 75.00%] [G loss: 1.944749]\n",
      "epoch:15 step:11737 [D loss: 0.546791, acc: 79.69%] [G loss: 1.999210]\n",
      "epoch:15 step:11738 [D loss: 0.929834, acc: 18.75%] [G loss: 1.801316]\n",
      "epoch:15 step:11739 [D loss: 0.728566, acc: 50.78%] [G loss: 1.688905]\n",
      "epoch:15 step:11740 [D loss: 0.329854, acc: 81.25%] [G loss: 2.072737]\n",
      "epoch:15 step:11741 [D loss: 0.718869, acc: 50.00%] [G loss: 1.927240]\n",
      "epoch:15 step:11742 [D loss: 0.767748, acc: 48.44%] [G loss: 1.906018]\n",
      "epoch:15 step:11743 [D loss: 0.510347, acc: 84.38%] [G loss: 1.759678]\n",
      "epoch:15 step:11744 [D loss: 0.556563, acc: 81.25%] [G loss: 1.718474]\n",
      "epoch:15 step:11745 [D loss: 0.455499, acc: 89.06%] [G loss: 1.616629]\n",
      "epoch:15 step:11746 [D loss: 0.528757, acc: 76.56%] [G loss: 1.680464]\n",
      "epoch:15 step:11747 [D loss: 0.548174, acc: 79.69%] [G loss: 1.705574]\n",
      "epoch:15 step:11748 [D loss: 0.706588, acc: 50.78%] [G loss: 1.541263]\n",
      "epoch:15 step:11749 [D loss: 0.720973, acc: 53.12%] [G loss: 1.756913]\n",
      "epoch:15 step:11750 [D loss: 0.833138, acc: 37.50%] [G loss: 1.774843]\n",
      "epoch:15 step:11751 [D loss: 0.487502, acc: 88.28%] [G loss: 2.151126]\n",
      "epoch:15 step:11752 [D loss: 0.528063, acc: 74.22%] [G loss: 1.811955]\n",
      "epoch:15 step:11753 [D loss: 0.435493, acc: 95.31%] [G loss: 1.715458]\n",
      "epoch:15 step:11754 [D loss: 0.763502, acc: 42.19%] [G loss: 1.510601]\n",
      "epoch:15 step:11755 [D loss: 0.664183, acc: 56.25%] [G loss: 1.685267]\n",
      "epoch:15 step:11756 [D loss: 0.494523, acc: 85.94%] [G loss: 1.761329]\n",
      "epoch:15 step:11757 [D loss: 0.813292, acc: 38.28%] [G loss: 1.819669]\n",
      "epoch:15 step:11758 [D loss: 0.758464, acc: 51.56%] [G loss: 1.769554]\n",
      "epoch:15 step:11759 [D loss: 0.797417, acc: 32.03%] [G loss: 1.673867]\n",
      "epoch:15 step:11760 [D loss: 0.524580, acc: 79.69%] [G loss: 1.812206]\n",
      "epoch:15 step:11761 [D loss: 0.442113, acc: 95.31%] [G loss: 1.525360]\n",
      "epoch:15 step:11762 [D loss: 0.640674, acc: 61.72%] [G loss: 1.776445]\n",
      "epoch:15 step:11763 [D loss: 0.722180, acc: 43.75%] [G loss: 1.555212]\n",
      "epoch:15 step:11764 [D loss: 0.813048, acc: 43.75%] [G loss: 1.606513]\n",
      "epoch:15 step:11765 [D loss: 0.859548, acc: 25.78%] [G loss: 1.542487]\n",
      "epoch:15 step:11766 [D loss: 0.699645, acc: 53.12%] [G loss: 1.763483]\n",
      "epoch:15 step:11767 [D loss: 0.597209, acc: 69.53%] [G loss: 1.905809]\n",
      "epoch:15 step:11768 [D loss: 0.560098, acc: 78.91%] [G loss: 1.651269]\n",
      "epoch:15 step:11769 [D loss: 0.795865, acc: 47.66%] [G loss: 1.529818]\n",
      "epoch:15 step:11770 [D loss: 0.944146, acc: 36.72%] [G loss: 1.617337]\n",
      "epoch:15 step:11771 [D loss: 0.925300, acc: 26.56%] [G loss: 1.671497]\n",
      "epoch:15 step:11772 [D loss: 0.582290, acc: 67.97%] [G loss: 2.071747]\n",
      "epoch:15 step:11773 [D loss: 0.589795, acc: 75.78%] [G loss: 1.556840]\n",
      "epoch:15 step:11774 [D loss: 0.460755, acc: 92.19%] [G loss: 1.929769]\n",
      "epoch:15 step:11775 [D loss: 0.431513, acc: 92.97%] [G loss: 1.771811]\n",
      "epoch:15 step:11776 [D loss: 0.726902, acc: 48.44%] [G loss: 1.560146]\n",
      "epoch:15 step:11777 [D loss: 0.678297, acc: 57.81%] [G loss: 1.612079]\n",
      "epoch:15 step:11778 [D loss: 0.526428, acc: 70.31%] [G loss: 1.797756]\n",
      "epoch:15 step:11779 [D loss: 0.610952, acc: 71.88%] [G loss: 1.771429]\n",
      "epoch:15 step:11780 [D loss: 0.685638, acc: 54.69%] [G loss: 1.501728]\n",
      "epoch:15 step:11781 [D loss: 0.519319, acc: 84.38%] [G loss: 1.882754]\n",
      "epoch:15 step:11782 [D loss: 0.868858, acc: 48.44%] [G loss: 1.205199]\n",
      "epoch:15 step:11783 [D loss: 0.671520, acc: 57.03%] [G loss: 1.789421]\n",
      "epoch:15 step:11784 [D loss: 0.305475, acc: 96.88%] [G loss: 1.778983]\n",
      "epoch:15 step:11785 [D loss: 0.871698, acc: 28.12%] [G loss: 1.304805]\n",
      "epoch:15 step:11786 [D loss: 0.788910, acc: 38.28%] [G loss: 1.466755]\n",
      "epoch:15 step:11787 [D loss: 0.859681, acc: 29.69%] [G loss: 1.473316]\n",
      "epoch:15 step:11788 [D loss: 0.426854, acc: 96.09%] [G loss: 1.653451]\n",
      "epoch:15 step:11789 [D loss: 0.649103, acc: 59.38%] [G loss: 1.766174]\n",
      "epoch:15 step:11790 [D loss: 0.715972, acc: 53.12%] [G loss: 1.595729]\n",
      "epoch:15 step:11791 [D loss: 0.544169, acc: 71.09%] [G loss: 1.948286]\n",
      "epoch:15 step:11792 [D loss: 0.671539, acc: 59.38%] [G loss: 1.628577]\n",
      "epoch:15 step:11793 [D loss: 0.660419, acc: 57.03%] [G loss: 1.421639]\n",
      "epoch:15 step:11794 [D loss: 0.592959, acc: 71.88%] [G loss: 1.907324]\n",
      "epoch:15 step:11795 [D loss: 0.701533, acc: 50.00%] [G loss: 1.753788]\n",
      "epoch:15 step:11796 [D loss: 0.428460, acc: 85.16%] [G loss: 1.663281]\n",
      "epoch:15 step:11797 [D loss: 0.740963, acc: 43.75%] [G loss: 1.679496]\n",
      "epoch:15 step:11798 [D loss: 0.740480, acc: 48.44%] [G loss: 1.727498]\n",
      "epoch:15 step:11799 [D loss: 1.039997, acc: 40.62%] [G loss: 1.233626]\n",
      "epoch:15 step:11800 [D loss: 0.721354, acc: 50.00%] [G loss: 1.706862]\n",
      "epoch:15 step:11801 [D loss: 0.516027, acc: 81.25%] [G loss: 1.843343]\n",
      "epoch:15 step:11802 [D loss: 0.566152, acc: 70.31%] [G loss: 1.890498]\n",
      "epoch:15 step:11803 [D loss: 0.675464, acc: 52.34%] [G loss: 1.476660]\n",
      "epoch:15 step:11804 [D loss: 0.723008, acc: 54.69%] [G loss: 2.006200]\n",
      "epoch:15 step:11805 [D loss: 0.630729, acc: 60.94%] [G loss: 1.677701]\n",
      "epoch:15 step:11806 [D loss: 0.596394, acc: 71.88%] [G loss: 1.747867]\n",
      "epoch:15 step:11807 [D loss: 0.648018, acc: 59.38%] [G loss: 1.884611]\n",
      "epoch:15 step:11808 [D loss: 0.764366, acc: 47.66%] [G loss: 1.621057]\n",
      "epoch:15 step:11809 [D loss: 0.921053, acc: 20.31%] [G loss: 1.273725]\n",
      "epoch:15 step:11810 [D loss: 0.507133, acc: 83.59%] [G loss: 2.050770]\n",
      "epoch:15 step:11811 [D loss: 0.701999, acc: 51.56%] [G loss: 1.534431]\n",
      "epoch:15 step:11812 [D loss: 0.612123, acc: 67.97%] [G loss: 1.628261]\n",
      "epoch:15 step:11813 [D loss: 0.608599, acc: 70.31%] [G loss: 1.486248]\n",
      "epoch:15 step:11814 [D loss: 0.580034, acc: 75.78%] [G loss: 1.774405]\n",
      "epoch:15 step:11815 [D loss: 0.670951, acc: 64.84%] [G loss: 1.851766]\n",
      "epoch:15 step:11816 [D loss: 0.832699, acc: 31.25%] [G loss: 1.429229]\n",
      "epoch:15 step:11817 [D loss: 0.525548, acc: 81.25%] [G loss: 1.761920]\n",
      "epoch:15 step:11818 [D loss: 0.536127, acc: 81.25%] [G loss: 1.935196]\n",
      "epoch:15 step:11819 [D loss: 0.775726, acc: 35.94%] [G loss: 1.851797]\n",
      "epoch:15 step:11820 [D loss: 0.623197, acc: 73.44%] [G loss: 1.820898]\n",
      "epoch:15 step:11821 [D loss: 0.504974, acc: 86.72%] [G loss: 1.887284]\n",
      "epoch:15 step:11822 [D loss: 0.930379, acc: 39.84%] [G loss: 1.840693]\n",
      "epoch:15 step:11823 [D loss: 0.854541, acc: 25.78%] [G loss: 1.617658]\n",
      "epoch:15 step:11824 [D loss: 0.651700, acc: 60.94%] [G loss: 1.589860]\n",
      "epoch:15 step:11825 [D loss: 0.511952, acc: 78.12%] [G loss: 1.928230]\n",
      "epoch:15 step:11826 [D loss: 0.752004, acc: 50.00%] [G loss: 1.184999]\n",
      "epoch:15 step:11827 [D loss: 0.424257, acc: 92.97%] [G loss: 1.824052]\n",
      "epoch:15 step:11828 [D loss: 0.573360, acc: 65.62%] [G loss: 2.013806]\n",
      "epoch:15 step:11829 [D loss: 0.644303, acc: 67.97%] [G loss: 1.679800]\n",
      "epoch:15 step:11830 [D loss: 0.462800, acc: 82.03%] [G loss: 1.707668]\n",
      "epoch:15 step:11831 [D loss: 0.649325, acc: 60.94%] [G loss: 1.681329]\n",
      "epoch:15 step:11832 [D loss: 0.477818, acc: 84.38%] [G loss: 1.614890]\n",
      "epoch:15 step:11833 [D loss: 0.539851, acc: 84.38%] [G loss: 1.717429]\n",
      "epoch:15 step:11834 [D loss: 0.625387, acc: 71.09%] [G loss: 1.901788]\n",
      "epoch:15 step:11835 [D loss: 0.542867, acc: 79.69%] [G loss: 1.873140]\n",
      "epoch:15 step:11836 [D loss: 0.604273, acc: 63.28%] [G loss: 2.128730]\n",
      "epoch:15 step:11837 [D loss: 0.771735, acc: 40.62%] [G loss: 1.805628]\n",
      "epoch:15 step:11838 [D loss: 0.422441, acc: 94.53%] [G loss: 1.942409]\n",
      "epoch:15 step:11839 [D loss: 0.374231, acc: 91.41%] [G loss: 2.257714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11840 [D loss: 0.731948, acc: 50.78%] [G loss: 1.391328]\n",
      "epoch:15 step:11841 [D loss: 0.767316, acc: 43.75%] [G loss: 1.757535]\n",
      "epoch:15 step:11842 [D loss: 0.678862, acc: 56.25%] [G loss: 1.937900]\n",
      "epoch:15 step:11843 [D loss: 0.591185, acc: 69.53%] [G loss: 1.965900]\n",
      "epoch:15 step:11844 [D loss: 0.621074, acc: 71.88%] [G loss: 1.954320]\n",
      "epoch:15 step:11845 [D loss: 0.870117, acc: 25.00%] [G loss: 1.458785]\n",
      "epoch:15 step:11846 [D loss: 0.599756, acc: 72.66%] [G loss: 1.885056]\n",
      "epoch:15 step:11847 [D loss: 0.694660, acc: 50.00%] [G loss: 1.767397]\n",
      "epoch:15 step:11848 [D loss: 0.799637, acc: 43.75%] [G loss: 1.672006]\n",
      "epoch:15 step:11849 [D loss: 0.630590, acc: 63.28%] [G loss: 1.669067]\n",
      "epoch:15 step:11850 [D loss: 0.487010, acc: 82.81%] [G loss: 2.017102]\n",
      "epoch:15 step:11851 [D loss: 0.666243, acc: 57.03%] [G loss: 1.956301]\n",
      "epoch:15 step:11852 [D loss: 0.681725, acc: 53.91%] [G loss: 1.795865]\n",
      "epoch:15 step:11853 [D loss: 0.570903, acc: 70.31%] [G loss: 2.158619]\n",
      "epoch:15 step:11854 [D loss: 0.561495, acc: 75.00%] [G loss: 1.916573]\n",
      "epoch:15 step:11855 [D loss: 0.530632, acc: 73.44%] [G loss: 1.747647]\n",
      "epoch:15 step:11856 [D loss: 0.593435, acc: 71.88%] [G loss: 1.535099]\n",
      "epoch:15 step:11857 [D loss: 0.900877, acc: 22.66%] [G loss: 1.647161]\n",
      "epoch:15 step:11858 [D loss: 0.761891, acc: 41.41%] [G loss: 1.674439]\n",
      "epoch:15 step:11859 [D loss: 0.608628, acc: 69.53%] [G loss: 1.667489]\n",
      "epoch:15 step:11860 [D loss: 0.418909, acc: 87.50%] [G loss: 2.043378]\n",
      "epoch:15 step:11861 [D loss: 0.738844, acc: 50.78%] [G loss: 2.027954]\n",
      "epoch:15 step:11862 [D loss: 0.580264, acc: 75.00%] [G loss: 1.771451]\n",
      "epoch:15 step:11863 [D loss: 0.628989, acc: 67.97%] [G loss: 2.016044]\n",
      "epoch:15 step:11864 [D loss: 0.699192, acc: 57.03%] [G loss: 1.916962]\n",
      "epoch:15 step:11865 [D loss: 0.553629, acc: 58.59%] [G loss: 1.644458]\n",
      "epoch:15 step:11866 [D loss: 0.667217, acc: 66.41%] [G loss: 1.528044]\n",
      "epoch:15 step:11867 [D loss: 0.730610, acc: 49.22%] [G loss: 1.682877]\n",
      "epoch:15 step:11868 [D loss: 0.672293, acc: 56.25%] [G loss: 1.610217]\n",
      "epoch:15 step:11869 [D loss: 0.548559, acc: 79.69%] [G loss: 2.222151]\n",
      "epoch:15 step:11870 [D loss: 0.665862, acc: 62.50%] [G loss: 1.755517]\n",
      "epoch:15 step:11871 [D loss: 0.787556, acc: 39.06%] [G loss: 1.529372]\n",
      "epoch:15 step:11872 [D loss: 0.590418, acc: 72.66%] [G loss: 1.928281]\n",
      "epoch:15 step:11873 [D loss: 0.791343, acc: 38.28%] [G loss: 1.763509]\n",
      "epoch:15 step:11874 [D loss: 0.710614, acc: 49.22%] [G loss: 1.650362]\n",
      "epoch:15 step:11875 [D loss: 0.993366, acc: 10.94%] [G loss: 1.239534]\n",
      "epoch:15 step:11876 [D loss: 0.420089, acc: 91.41%] [G loss: 1.842140]\n",
      "epoch:15 step:11877 [D loss: 0.565360, acc: 76.56%] [G loss: 1.842703]\n",
      "epoch:15 step:11878 [D loss: 0.830351, acc: 32.81%] [G loss: 1.637240]\n",
      "epoch:15 step:11879 [D loss: 0.683739, acc: 59.38%] [G loss: 1.758479]\n",
      "epoch:15 step:11880 [D loss: 0.462706, acc: 92.97%] [G loss: 1.681224]\n",
      "epoch:15 step:11881 [D loss: 0.732819, acc: 53.12%] [G loss: 1.880603]\n",
      "epoch:15 step:11882 [D loss: 0.568609, acc: 75.00%] [G loss: 2.015671]\n",
      "epoch:15 step:11883 [D loss: 0.731893, acc: 50.00%] [G loss: 1.694059]\n",
      "epoch:15 step:11884 [D loss: 0.491548, acc: 89.84%] [G loss: 1.834912]\n",
      "epoch:15 step:11885 [D loss: 0.507601, acc: 79.69%] [G loss: 2.102273]\n",
      "epoch:15 step:11886 [D loss: 0.675152, acc: 53.91%] [G loss: 1.565543]\n",
      "epoch:15 step:11887 [D loss: 0.719552, acc: 51.56%] [G loss: 1.560105]\n",
      "epoch:15 step:11888 [D loss: 0.754796, acc: 49.22%] [G loss: 1.250216]\n",
      "epoch:15 step:11889 [D loss: 0.376098, acc: 93.75%] [G loss: 1.762510]\n",
      "epoch:15 step:11890 [D loss: 0.603774, acc: 62.50%] [G loss: 1.766029]\n",
      "epoch:15 step:11891 [D loss: 0.699235, acc: 53.12%] [G loss: 1.799277]\n",
      "epoch:15 step:11892 [D loss: 0.617627, acc: 64.06%] [G loss: 2.024618]\n",
      "epoch:15 step:11893 [D loss: 0.600252, acc: 74.22%] [G loss: 1.430906]\n",
      "epoch:15 step:11894 [D loss: 0.761885, acc: 47.66%] [G loss: 1.574497]\n",
      "epoch:15 step:11895 [D loss: 0.679251, acc: 50.78%] [G loss: 1.539113]\n",
      "epoch:15 step:11896 [D loss: 0.601158, acc: 75.00%] [G loss: 1.719718]\n",
      "epoch:15 step:11897 [D loss: 0.808749, acc: 32.81%] [G loss: 1.810280]\n",
      "epoch:15 step:11898 [D loss: 0.691419, acc: 53.91%] [G loss: 1.682382]\n",
      "epoch:15 step:11899 [D loss: 0.519201, acc: 75.78%] [G loss: 1.811457]\n",
      "epoch:15 step:11900 [D loss: 0.642525, acc: 60.94%] [G loss: 1.813425]\n",
      "epoch:15 step:11901 [D loss: 0.642478, acc: 64.06%] [G loss: 1.857843]\n",
      "epoch:15 step:11902 [D loss: 0.424576, acc: 93.75%] [G loss: 1.547354]\n",
      "epoch:15 step:11903 [D loss: 0.464905, acc: 85.94%] [G loss: 1.723905]\n",
      "epoch:15 step:11904 [D loss: 0.760635, acc: 51.56%] [G loss: 1.741607]\n",
      "epoch:15 step:11905 [D loss: 0.720322, acc: 53.12%] [G loss: 1.512652]\n",
      "epoch:15 step:11906 [D loss: 0.364921, acc: 96.09%] [G loss: 1.996490]\n",
      "epoch:15 step:11907 [D loss: 0.851108, acc: 20.31%] [G loss: 1.419685]\n",
      "epoch:15 step:11908 [D loss: 0.602413, acc: 72.66%] [G loss: 1.839651]\n",
      "epoch:15 step:11909 [D loss: 0.586343, acc: 75.00%] [G loss: 1.658480]\n",
      "epoch:15 step:11910 [D loss: 0.632119, acc: 65.62%] [G loss: 1.406949]\n",
      "epoch:15 step:11911 [D loss: 0.862513, acc: 38.28%] [G loss: 1.729791]\n",
      "epoch:15 step:11912 [D loss: 0.867217, acc: 44.53%] [G loss: 1.680534]\n",
      "epoch:15 step:11913 [D loss: 0.747181, acc: 45.31%] [G loss: 1.620271]\n",
      "epoch:15 step:11914 [D loss: 0.633370, acc: 59.38%] [G loss: 1.606047]\n",
      "epoch:15 step:11915 [D loss: 0.694206, acc: 54.69%] [G loss: 1.792370]\n",
      "epoch:15 step:11916 [D loss: 0.533093, acc: 89.06%] [G loss: 1.905810]\n",
      "epoch:15 step:11917 [D loss: 0.775098, acc: 40.62%] [G loss: 1.847407]\n",
      "epoch:15 step:11918 [D loss: 0.760080, acc: 40.62%] [G loss: 1.930035]\n",
      "epoch:15 step:11919 [D loss: 0.685767, acc: 50.78%] [G loss: 1.457376]\n",
      "epoch:15 step:11920 [D loss: 0.911677, acc: 29.69%] [G loss: 1.308634]\n",
      "epoch:15 step:11921 [D loss: 0.613076, acc: 67.97%] [G loss: 2.028457]\n",
      "epoch:15 step:11922 [D loss: 0.569750, acc: 74.22%] [G loss: 1.920840]\n",
      "epoch:15 step:11923 [D loss: 0.644642, acc: 60.16%] [G loss: 1.803221]\n",
      "epoch:15 step:11924 [D loss: 0.721519, acc: 45.31%] [G loss: 1.532810]\n",
      "epoch:15 step:11925 [D loss: 0.701702, acc: 51.56%] [G loss: 1.508451]\n",
      "epoch:15 step:11926 [D loss: 0.653099, acc: 64.84%] [G loss: 2.005363]\n",
      "epoch:15 step:11927 [D loss: 0.513298, acc: 85.16%] [G loss: 2.300655]\n",
      "epoch:15 step:11928 [D loss: 0.799972, acc: 32.81%] [G loss: 1.466488]\n",
      "epoch:15 step:11929 [D loss: 0.676098, acc: 56.25%] [G loss: 1.846001]\n",
      "epoch:15 step:11930 [D loss: 0.737999, acc: 41.41%] [G loss: 1.661735]\n",
      "epoch:15 step:11931 [D loss: 0.863010, acc: 23.44%] [G loss: 1.733693]\n",
      "epoch:15 step:11932 [D loss: 0.781940, acc: 39.06%] [G loss: 1.284499]\n",
      "epoch:15 step:11933 [D loss: 0.613755, acc: 70.31%] [G loss: 1.712733]\n",
      "epoch:15 step:11934 [D loss: 0.532795, acc: 82.03%] [G loss: 1.739059]\n",
      "epoch:15 step:11935 [D loss: 0.673625, acc: 57.81%] [G loss: 1.769505]\n",
      "epoch:15 step:11936 [D loss: 0.538244, acc: 83.59%] [G loss: 2.141431]\n",
      "epoch:15 step:11937 [D loss: 0.597263, acc: 69.53%] [G loss: 1.676019]\n",
      "epoch:15 step:11938 [D loss: 0.753975, acc: 42.97%] [G loss: 1.942163]\n",
      "epoch:15 step:11939 [D loss: 0.660009, acc: 57.03%] [G loss: 1.784160]\n",
      "epoch:15 step:11940 [D loss: 0.663027, acc: 59.38%] [G loss: 2.003771]\n",
      "epoch:15 step:11941 [D loss: 0.777249, acc: 41.41%] [G loss: 1.336990]\n",
      "epoch:15 step:11942 [D loss: 0.588347, acc: 73.44%] [G loss: 1.753154]\n",
      "epoch:15 step:11943 [D loss: 0.769859, acc: 39.06%] [G loss: 1.862694]\n",
      "epoch:15 step:11944 [D loss: 0.596580, acc: 75.78%] [G loss: 1.949699]\n",
      "epoch:15 step:11945 [D loss: 1.021913, acc: 10.94%] [G loss: 1.828590]\n",
      "epoch:15 step:11946 [D loss: 0.587777, acc: 74.22%] [G loss: 1.531048]\n",
      "epoch:15 step:11947 [D loss: 0.862519, acc: 28.91%] [G loss: 1.603123]\n",
      "epoch:15 step:11948 [D loss: 0.592164, acc: 68.75%] [G loss: 1.765284]\n",
      "epoch:15 step:11949 [D loss: 0.854268, acc: 35.94%] [G loss: 1.695409]\n",
      "epoch:15 step:11950 [D loss: 0.732761, acc: 48.44%] [G loss: 1.808497]\n",
      "epoch:15 step:11951 [D loss: 0.760003, acc: 48.44%] [G loss: 1.813242]\n",
      "epoch:15 step:11952 [D loss: 0.637397, acc: 60.94%] [G loss: 1.964692]\n",
      "epoch:15 step:11953 [D loss: 0.638407, acc: 65.62%] [G loss: 1.635977]\n",
      "epoch:15 step:11954 [D loss: 0.627015, acc: 66.41%] [G loss: 1.657993]\n",
      "epoch:15 step:11955 [D loss: 0.611971, acc: 67.97%] [G loss: 1.562568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11956 [D loss: 0.575873, acc: 76.56%] [G loss: 1.751354]\n",
      "epoch:15 step:11957 [D loss: 0.534597, acc: 83.59%] [G loss: 2.015406]\n",
      "epoch:15 step:11958 [D loss: 0.469324, acc: 91.41%] [G loss: 1.856066]\n",
      "epoch:15 step:11959 [D loss: 0.812032, acc: 32.03%] [G loss: 1.822253]\n",
      "epoch:15 step:11960 [D loss: 0.737757, acc: 42.19%] [G loss: 1.967168]\n",
      "epoch:15 step:11961 [D loss: 0.537948, acc: 69.53%] [G loss: 2.222903]\n",
      "epoch:15 step:11962 [D loss: 0.803067, acc: 35.94%] [G loss: 1.424178]\n",
      "epoch:15 step:11963 [D loss: 0.702595, acc: 57.03%] [G loss: 1.541627]\n",
      "epoch:15 step:11964 [D loss: 0.796389, acc: 35.16%] [G loss: 1.625664]\n",
      "epoch:15 step:11965 [D loss: 0.705335, acc: 53.91%] [G loss: 1.820133]\n",
      "epoch:15 step:11966 [D loss: 0.773361, acc: 49.22%] [G loss: 1.587361]\n",
      "epoch:15 step:11967 [D loss: 0.510800, acc: 90.62%] [G loss: 2.052739]\n",
      "epoch:15 step:11968 [D loss: 0.890240, acc: 21.09%] [G loss: 1.766952]\n",
      "epoch:15 step:11969 [D loss: 0.796511, acc: 38.28%] [G loss: 2.122020]\n",
      "epoch:15 step:11970 [D loss: 0.470157, acc: 85.94%] [G loss: 1.994524]\n",
      "epoch:15 step:11971 [D loss: 0.846131, acc: 26.56%] [G loss: 1.774199]\n",
      "epoch:15 step:11972 [D loss: 0.846947, acc: 36.72%] [G loss: 1.525503]\n",
      "epoch:15 step:11973 [D loss: 0.483024, acc: 78.91%] [G loss: 1.785144]\n",
      "epoch:15 step:11974 [D loss: 0.794026, acc: 32.81%] [G loss: 1.621125]\n",
      "epoch:15 step:11975 [D loss: 0.727128, acc: 46.88%] [G loss: 1.629506]\n",
      "epoch:15 step:11976 [D loss: 0.508235, acc: 87.50%] [G loss: 1.551324]\n",
      "epoch:15 step:11977 [D loss: 0.530391, acc: 79.69%] [G loss: 1.784976]\n",
      "epoch:15 step:11978 [D loss: 0.743052, acc: 44.53%] [G loss: 1.565854]\n",
      "epoch:15 step:11979 [D loss: 1.023474, acc: 10.94%] [G loss: 1.257521]\n",
      "epoch:15 step:11980 [D loss: 0.656615, acc: 60.94%] [G loss: 1.638248]\n",
      "epoch:15 step:11981 [D loss: 0.684900, acc: 61.72%] [G loss: 1.936358]\n",
      "epoch:15 step:11982 [D loss: 0.747364, acc: 53.12%] [G loss: 1.199983]\n",
      "epoch:15 step:11983 [D loss: 0.584046, acc: 73.44%] [G loss: 2.124439]\n",
      "epoch:15 step:11984 [D loss: 0.727317, acc: 49.22%] [G loss: 1.728529]\n",
      "epoch:15 step:11985 [D loss: 0.759754, acc: 42.19%] [G loss: 1.593392]\n",
      "epoch:15 step:11986 [D loss: 0.836574, acc: 31.25%] [G loss: 1.518225]\n",
      "epoch:15 step:11987 [D loss: 0.747009, acc: 47.66%] [G loss: 1.773079]\n",
      "epoch:15 step:11988 [D loss: 0.730081, acc: 46.88%] [G loss: 1.464392]\n",
      "epoch:15 step:11989 [D loss: 0.663451, acc: 57.81%] [G loss: 1.755894]\n",
      "epoch:15 step:11990 [D loss: 0.756701, acc: 36.72%] [G loss: 1.568956]\n",
      "epoch:15 step:11991 [D loss: 0.765870, acc: 42.19%] [G loss: 1.481946]\n",
      "epoch:15 step:11992 [D loss: 0.698408, acc: 53.91%] [G loss: 1.550866]\n",
      "epoch:15 step:11993 [D loss: 0.725079, acc: 50.78%] [G loss: 1.721084]\n",
      "epoch:15 step:11994 [D loss: 0.768266, acc: 42.19%] [G loss: 1.518378]\n",
      "epoch:15 step:11995 [D loss: 0.571953, acc: 78.12%] [G loss: 1.863668]\n",
      "epoch:15 step:11996 [D loss: 0.669567, acc: 59.38%] [G loss: 1.649751]\n",
      "epoch:15 step:11997 [D loss: 0.521283, acc: 85.16%] [G loss: 1.737664]\n",
      "epoch:15 step:11998 [D loss: 0.701550, acc: 50.00%] [G loss: 1.683820]\n",
      "epoch:15 step:11999 [D loss: 0.724553, acc: 48.44%] [G loss: 1.521573]\n",
      "epoch:15 step:12000 [D loss: 0.624833, acc: 71.09%] [G loss: 1.801663]\n",
      "epoch:15 step:12001 [D loss: 0.619545, acc: 71.09%] [G loss: 1.983287]\n",
      "epoch:15 step:12002 [D loss: 0.712832, acc: 56.25%] [G loss: 1.639366]\n",
      "epoch:15 step:12003 [D loss: 0.612756, acc: 62.50%] [G loss: 2.062344]\n",
      "epoch:15 step:12004 [D loss: 0.586614, acc: 75.78%] [G loss: 1.802054]\n",
      "epoch:15 step:12005 [D loss: 0.848492, acc: 32.81%] [G loss: 1.745586]\n",
      "epoch:15 step:12006 [D loss: 0.734263, acc: 53.12%] [G loss: 1.221193]\n",
      "epoch:15 step:12007 [D loss: 0.683248, acc: 59.38%] [G loss: 1.722217]\n",
      "epoch:15 step:12008 [D loss: 0.606836, acc: 65.62%] [G loss: 1.744913]\n",
      "epoch:15 step:12009 [D loss: 0.743876, acc: 44.53%] [G loss: 1.619861]\n",
      "epoch:15 step:12010 [D loss: 0.424824, acc: 92.19%] [G loss: 1.724621]\n",
      "epoch:15 step:12011 [D loss: 0.601448, acc: 71.88%] [G loss: 1.835925]\n",
      "epoch:15 step:12012 [D loss: 0.729052, acc: 50.78%] [G loss: 1.675142]\n",
      "epoch:15 step:12013 [D loss: 0.767721, acc: 39.84%] [G loss: 1.719959]\n",
      "epoch:15 step:12014 [D loss: 0.665759, acc: 62.50%] [G loss: 1.835218]\n",
      "epoch:15 step:12015 [D loss: 0.730026, acc: 53.91%] [G loss: 1.821496]\n",
      "epoch:15 step:12016 [D loss: 0.746938, acc: 44.53%] [G loss: 1.593381]\n",
      "epoch:15 step:12017 [D loss: 0.459099, acc: 88.28%] [G loss: 2.097239]\n",
      "epoch:15 step:12018 [D loss: 0.568010, acc: 77.34%] [G loss: 1.556712]\n",
      "epoch:15 step:12019 [D loss: 0.382308, acc: 94.53%] [G loss: 1.602788]\n",
      "epoch:15 step:12020 [D loss: 0.569807, acc: 72.66%] [G loss: 1.783970]\n",
      "epoch:15 step:12021 [D loss: 0.518780, acc: 78.91%] [G loss: 1.947086]\n",
      "epoch:15 step:12022 [D loss: 0.760673, acc: 42.97%] [G loss: 1.705398]\n",
      "epoch:15 step:12023 [D loss: 0.576339, acc: 74.22%] [G loss: 1.891225]\n",
      "epoch:15 step:12024 [D loss: 0.850315, acc: 32.03%] [G loss: 1.747182]\n",
      "epoch:15 step:12025 [D loss: 0.736979, acc: 45.31%] [G loss: 2.166085]\n",
      "epoch:15 step:12026 [D loss: 1.008933, acc: 15.62%] [G loss: 1.623915]\n",
      "epoch:15 step:12027 [D loss: 0.448154, acc: 88.28%] [G loss: 1.578910]\n",
      "epoch:15 step:12028 [D loss: 0.774312, acc: 34.38%] [G loss: 1.271939]\n",
      "epoch:15 step:12029 [D loss: 0.276274, acc: 98.44%] [G loss: 1.574496]\n",
      "epoch:15 step:12030 [D loss: 0.991801, acc: 12.50%] [G loss: 1.297333]\n",
      "epoch:15 step:12031 [D loss: 0.610331, acc: 58.59%] [G loss: 1.687043]\n",
      "epoch:15 step:12032 [D loss: 0.567631, acc: 63.28%] [G loss: 1.911132]\n",
      "epoch:15 step:12033 [D loss: 0.622189, acc: 62.50%] [G loss: 1.716329]\n",
      "epoch:15 step:12034 [D loss: 0.678951, acc: 50.78%] [G loss: 1.562115]\n",
      "epoch:15 step:12035 [D loss: 1.114486, acc: 21.09%] [G loss: 1.039007]\n",
      "epoch:15 step:12036 [D loss: 0.662454, acc: 63.28%] [G loss: 1.589965]\n",
      "epoch:15 step:12037 [D loss: 0.647828, acc: 57.03%] [G loss: 1.935409]\n",
      "epoch:15 step:12038 [D loss: 0.524773, acc: 81.25%] [G loss: 1.810690]\n",
      "epoch:15 step:12039 [D loss: 0.704342, acc: 54.69%] [G loss: 1.703958]\n",
      "epoch:15 step:12040 [D loss: 0.541757, acc: 81.25%] [G loss: 1.769159]\n",
      "epoch:15 step:12041 [D loss: 0.508209, acc: 86.72%] [G loss: 1.717957]\n",
      "epoch:15 step:12042 [D loss: 0.562259, acc: 73.44%] [G loss: 2.063682]\n",
      "epoch:15 step:12043 [D loss: 0.470588, acc: 91.41%] [G loss: 2.251100]\n",
      "epoch:15 step:12044 [D loss: 0.611335, acc: 70.31%] [G loss: 1.745718]\n",
      "epoch:15 step:12045 [D loss: 0.675039, acc: 51.56%] [G loss: 1.659536]\n",
      "epoch:15 step:12046 [D loss: 1.004963, acc: 10.94%] [G loss: 1.366810]\n",
      "epoch:15 step:12047 [D loss: 0.446776, acc: 92.19%] [G loss: 1.911836]\n",
      "epoch:15 step:12048 [D loss: 0.493354, acc: 89.06%] [G loss: 1.875881]\n",
      "epoch:15 step:12049 [D loss: 0.593008, acc: 70.31%] [G loss: 2.020171]\n",
      "epoch:15 step:12050 [D loss: 0.773139, acc: 46.09%] [G loss: 1.603746]\n",
      "epoch:15 step:12051 [D loss: 0.705915, acc: 50.78%] [G loss: 1.698161]\n",
      "epoch:15 step:12052 [D loss: 0.654284, acc: 56.25%] [G loss: 1.739200]\n",
      "epoch:15 step:12053 [D loss: 0.775303, acc: 46.88%] [G loss: 2.049736]\n",
      "epoch:15 step:12054 [D loss: 0.565082, acc: 71.09%] [G loss: 1.836751]\n",
      "epoch:15 step:12055 [D loss: 0.712164, acc: 51.56%] [G loss: 1.736958]\n",
      "epoch:15 step:12056 [D loss: 0.519917, acc: 85.94%] [G loss: 1.774359]\n",
      "epoch:15 step:12057 [D loss: 0.535316, acc: 82.81%] [G loss: 1.880538]\n",
      "epoch:15 step:12058 [D loss: 0.671536, acc: 60.94%] [G loss: 1.635398]\n",
      "epoch:15 step:12059 [D loss: 0.456670, acc: 84.38%] [G loss: 1.740037]\n",
      "epoch:15 step:12060 [D loss: 0.561291, acc: 80.47%] [G loss: 2.136255]\n",
      "epoch:15 step:12061 [D loss: 0.764704, acc: 46.88%] [G loss: 1.769155]\n",
      "epoch:15 step:12062 [D loss: 0.700970, acc: 52.34%] [G loss: 1.696394]\n",
      "epoch:15 step:12063 [D loss: 0.640444, acc: 66.41%] [G loss: 1.824549]\n",
      "epoch:15 step:12064 [D loss: 0.609532, acc: 77.34%] [G loss: 1.766353]\n",
      "epoch:15 step:12065 [D loss: 0.679088, acc: 52.34%] [G loss: 1.816660]\n",
      "epoch:15 step:12066 [D loss: 0.826690, acc: 33.59%] [G loss: 1.646926]\n",
      "epoch:15 step:12067 [D loss: 0.546360, acc: 78.12%] [G loss: 1.677314]\n",
      "epoch:15 step:12068 [D loss: 0.602329, acc: 75.00%] [G loss: 1.794648]\n",
      "epoch:15 step:12069 [D loss: 0.586246, acc: 66.41%] [G loss: 1.639000]\n",
      "epoch:15 step:12070 [D loss: 0.769746, acc: 39.84%] [G loss: 1.777492]\n",
      "epoch:15 step:12071 [D loss: 0.863023, acc: 34.38%] [G loss: 1.568440]\n",
      "epoch:15 step:12072 [D loss: 0.473968, acc: 86.72%] [G loss: 1.687076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12073 [D loss: 0.506622, acc: 85.16%] [G loss: 1.724095]\n",
      "epoch:15 step:12074 [D loss: 0.883937, acc: 23.44%] [G loss: 1.686870]\n",
      "epoch:15 step:12075 [D loss: 0.749911, acc: 50.00%] [G loss: 1.256099]\n",
      "epoch:15 step:12076 [D loss: 0.568124, acc: 73.44%] [G loss: 1.777750]\n",
      "epoch:15 step:12077 [D loss: 0.532546, acc: 85.94%] [G loss: 1.804093]\n",
      "epoch:15 step:12078 [D loss: 0.538048, acc: 73.44%] [G loss: 1.749688]\n",
      "epoch:15 step:12079 [D loss: 0.472831, acc: 79.69%] [G loss: 2.129701]\n",
      "epoch:15 step:12080 [D loss: 0.732614, acc: 51.56%] [G loss: 1.979360]\n",
      "epoch:15 step:12081 [D loss: 0.888527, acc: 22.66%] [G loss: 1.357633]\n",
      "epoch:15 step:12082 [D loss: 0.678616, acc: 53.91%] [G loss: 1.504624]\n",
      "epoch:15 step:12083 [D loss: 0.647438, acc: 63.28%] [G loss: 1.620536]\n",
      "epoch:15 step:12084 [D loss: 0.674288, acc: 53.91%] [G loss: 1.644089]\n",
      "epoch:15 step:12085 [D loss: 0.705082, acc: 56.25%] [G loss: 1.621181]\n",
      "epoch:15 step:12086 [D loss: 0.587440, acc: 73.44%] [G loss: 1.729517]\n",
      "epoch:15 step:12087 [D loss: 0.594620, acc: 71.88%] [G loss: 1.576266]\n",
      "epoch:15 step:12088 [D loss: 0.969138, acc: 31.25%] [G loss: 1.325786]\n",
      "epoch:15 step:12089 [D loss: 0.520159, acc: 72.66%] [G loss: 2.266607]\n",
      "epoch:15 step:12090 [D loss: 0.755867, acc: 44.53%] [G loss: 1.863580]\n",
      "epoch:15 step:12091 [D loss: 0.670700, acc: 58.59%] [G loss: 1.835330]\n",
      "epoch:15 step:12092 [D loss: 0.616154, acc: 64.06%] [G loss: 1.992331]\n",
      "epoch:15 step:12093 [D loss: 0.680727, acc: 55.47%] [G loss: 1.535422]\n",
      "epoch:15 step:12094 [D loss: 0.565590, acc: 75.00%] [G loss: 1.966598]\n",
      "epoch:15 step:12095 [D loss: 0.565381, acc: 77.34%] [G loss: 1.884122]\n",
      "epoch:15 step:12096 [D loss: 0.573228, acc: 76.56%] [G loss: 1.758536]\n",
      "epoch:15 step:12097 [D loss: 0.669078, acc: 62.50%] [G loss: 1.923160]\n",
      "epoch:15 step:12098 [D loss: 0.669922, acc: 57.81%] [G loss: 1.655383]\n",
      "epoch:15 step:12099 [D loss: 0.420793, acc: 85.16%] [G loss: 1.912383]\n",
      "epoch:15 step:12100 [D loss: 0.820924, acc: 42.19%] [G loss: 1.453848]\n",
      "epoch:15 step:12101 [D loss: 0.639241, acc: 59.38%] [G loss: 1.668198]\n",
      "epoch:15 step:12102 [D loss: 0.581103, acc: 72.66%] [G loss: 1.622640]\n",
      "epoch:15 step:12103 [D loss: 0.783983, acc: 48.44%] [G loss: 1.281994]\n",
      "epoch:15 step:12104 [D loss: 0.662220, acc: 64.06%] [G loss: 1.656796]\n",
      "epoch:15 step:12105 [D loss: 0.526594, acc: 83.59%] [G loss: 1.831262]\n",
      "epoch:15 step:12106 [D loss: 0.586847, acc: 73.44%] [G loss: 1.806012]\n",
      "epoch:15 step:12107 [D loss: 0.600065, acc: 61.72%] [G loss: 1.945460]\n",
      "epoch:15 step:12108 [D loss: 0.599338, acc: 73.44%] [G loss: 1.828452]\n",
      "epoch:15 step:12109 [D loss: 0.424470, acc: 92.97%] [G loss: 2.454612]\n",
      "epoch:15 step:12110 [D loss: 0.657032, acc: 60.16%] [G loss: 1.548740]\n",
      "epoch:15 step:12111 [D loss: 0.664693, acc: 53.91%] [G loss: 1.829817]\n",
      "epoch:15 step:12112 [D loss: 0.532818, acc: 79.69%] [G loss: 1.618333]\n",
      "epoch:15 step:12113 [D loss: 0.705457, acc: 56.25%] [G loss: 1.539743]\n",
      "epoch:15 step:12114 [D loss: 0.709701, acc: 50.00%] [G loss: 1.947313]\n",
      "epoch:15 step:12115 [D loss: 0.518696, acc: 82.81%] [G loss: 1.870185]\n",
      "epoch:15 step:12116 [D loss: 0.663309, acc: 54.69%] [G loss: 1.664705]\n",
      "epoch:15 step:12117 [D loss: 0.630894, acc: 66.41%] [G loss: 1.778838]\n",
      "epoch:15 step:12118 [D loss: 0.619778, acc: 65.62%] [G loss: 1.656271]\n",
      "epoch:15 step:12119 [D loss: 0.523828, acc: 82.81%] [G loss: 1.990546]\n",
      "epoch:15 step:12120 [D loss: 0.749572, acc: 45.31%] [G loss: 1.548595]\n",
      "epoch:15 step:12121 [D loss: 0.622888, acc: 65.62%] [G loss: 2.035113]\n",
      "epoch:15 step:12122 [D loss: 0.367512, acc: 92.97%] [G loss: 1.821370]\n",
      "epoch:15 step:12123 [D loss: 0.358330, acc: 96.88%] [G loss: 2.196399]\n",
      "epoch:15 step:12124 [D loss: 0.625044, acc: 69.53%] [G loss: 2.054590]\n",
      "epoch:15 step:12125 [D loss: 0.603501, acc: 67.97%] [G loss: 1.995156]\n",
      "epoch:15 step:12126 [D loss: 0.934058, acc: 22.66%] [G loss: 1.329872]\n",
      "epoch:15 step:12127 [D loss: 0.683460, acc: 52.34%] [G loss: 1.865846]\n",
      "epoch:15 step:12128 [D loss: 0.360446, acc: 82.81%] [G loss: 1.739308]\n",
      "epoch:15 step:12129 [D loss: 0.707478, acc: 50.00%] [G loss: 1.669281]\n",
      "epoch:15 step:12130 [D loss: 0.500044, acc: 80.47%] [G loss: 1.815475]\n",
      "epoch:15 step:12131 [D loss: 0.577208, acc: 67.19%] [G loss: 1.738937]\n",
      "epoch:15 step:12132 [D loss: 0.591489, acc: 67.19%] [G loss: 1.749526]\n",
      "epoch:15 step:12133 [D loss: 0.811570, acc: 35.94%] [G loss: 1.673327]\n",
      "epoch:15 step:12134 [D loss: 0.811784, acc: 38.28%] [G loss: 1.460303]\n",
      "epoch:15 step:12135 [D loss: 0.831660, acc: 49.22%] [G loss: 1.260456]\n",
      "epoch:15 step:12136 [D loss: 0.501012, acc: 85.94%] [G loss: 2.010194]\n",
      "epoch:15 step:12137 [D loss: 0.438926, acc: 92.19%] [G loss: 2.100843]\n",
      "epoch:15 step:12138 [D loss: 0.718800, acc: 50.78%] [G loss: 1.417075]\n",
      "epoch:15 step:12139 [D loss: 0.934161, acc: 28.91%] [G loss: 1.636467]\n",
      "epoch:15 step:12140 [D loss: 0.777570, acc: 47.66%] [G loss: 1.383419]\n",
      "epoch:15 step:12141 [D loss: 0.538303, acc: 75.00%] [G loss: 1.746015]\n",
      "epoch:15 step:12142 [D loss: 0.643809, acc: 65.62%] [G loss: 1.828689]\n",
      "epoch:15 step:12143 [D loss: 0.700253, acc: 54.69%] [G loss: 1.626641]\n",
      "epoch:15 step:12144 [D loss: 0.527502, acc: 84.38%] [G loss: 2.106009]\n",
      "epoch:15 step:12145 [D loss: 0.763037, acc: 49.22%] [G loss: 1.905387]\n",
      "epoch:15 step:12146 [D loss: 0.757850, acc: 50.00%] [G loss: 1.260347]\n",
      "epoch:15 step:12147 [D loss: 0.744553, acc: 40.62%] [G loss: 1.834424]\n",
      "epoch:15 step:12148 [D loss: 0.295635, acc: 98.44%] [G loss: 2.505827]\n",
      "epoch:15 step:12149 [D loss: 0.595867, acc: 78.12%] [G loss: 2.340098]\n",
      "epoch:15 step:12150 [D loss: 0.490107, acc: 78.91%] [G loss: 2.087161]\n",
      "epoch:15 step:12151 [D loss: 0.452532, acc: 90.62%] [G loss: 1.785339]\n",
      "epoch:15 step:12152 [D loss: 0.610573, acc: 64.06%] [G loss: 1.631212]\n",
      "epoch:15 step:12153 [D loss: 0.502131, acc: 83.59%] [G loss: 2.017385]\n",
      "epoch:15 step:12154 [D loss: 0.453865, acc: 89.06%] [G loss: 1.951167]\n",
      "epoch:15 step:12155 [D loss: 0.654954, acc: 59.38%] [G loss: 1.614858]\n",
      "epoch:15 step:12156 [D loss: 0.848075, acc: 32.03%] [G loss: 1.608123]\n",
      "epoch:15 step:12157 [D loss: 0.305024, acc: 98.44%] [G loss: 2.060472]\n",
      "epoch:15 step:12158 [D loss: 0.791173, acc: 42.97%] [G loss: 1.670455]\n",
      "epoch:15 step:12159 [D loss: 0.723377, acc: 51.56%] [G loss: 1.634770]\n",
      "epoch:15 step:12160 [D loss: 0.660401, acc: 53.91%] [G loss: 1.566663]\n",
      "epoch:15 step:12161 [D loss: 0.386494, acc: 91.41%] [G loss: 2.138898]\n",
      "epoch:15 step:12162 [D loss: 0.671803, acc: 57.81%] [G loss: 1.872426]\n",
      "epoch:15 step:12163 [D loss: 0.590303, acc: 71.88%] [G loss: 1.837611]\n",
      "epoch:15 step:12164 [D loss: 0.648366, acc: 67.97%] [G loss: 1.720453]\n",
      "epoch:15 step:12165 [D loss: 0.596890, acc: 73.44%] [G loss: 1.505541]\n",
      "epoch:15 step:12166 [D loss: 0.612348, acc: 67.97%] [G loss: 1.795870]\n",
      "epoch:15 step:12167 [D loss: 0.789884, acc: 42.19%] [G loss: 1.967377]\n",
      "epoch:15 step:12168 [D loss: 0.452728, acc: 88.28%] [G loss: 1.732044]\n",
      "epoch:15 step:12169 [D loss: 0.382733, acc: 96.88%] [G loss: 2.088872]\n",
      "epoch:15 step:12170 [D loss: 0.604987, acc: 60.16%] [G loss: 1.734172]\n",
      "epoch:15 step:12171 [D loss: 0.758495, acc: 43.75%] [G loss: 1.533591]\n",
      "epoch:15 step:12172 [D loss: 0.611343, acc: 59.38%] [G loss: 1.837651]\n",
      "epoch:15 step:12173 [D loss: 0.649553, acc: 63.28%] [G loss: 2.126244]\n",
      "epoch:15 step:12174 [D loss: 0.640354, acc: 61.72%] [G loss: 1.939128]\n",
      "epoch:15 step:12175 [D loss: 0.555489, acc: 58.59%] [G loss: 1.648131]\n",
      "epoch:15 step:12176 [D loss: 0.477563, acc: 90.62%] [G loss: 1.786098]\n",
      "epoch:15 step:12177 [D loss: 0.589348, acc: 74.22%] [G loss: 1.633150]\n",
      "epoch:15 step:12178 [D loss: 0.670329, acc: 54.69%] [G loss: 2.300414]\n",
      "epoch:15 step:12179 [D loss: 0.426521, acc: 96.88%] [G loss: 1.960829]\n",
      "epoch:15 step:12180 [D loss: 0.774670, acc: 39.84%] [G loss: 1.388399]\n",
      "epoch:15 step:12181 [D loss: 0.579202, acc: 75.00%] [G loss: 2.021826]\n",
      "epoch:15 step:12182 [D loss: 0.672412, acc: 56.25%] [G loss: 1.730319]\n",
      "epoch:15 step:12183 [D loss: 0.799273, acc: 42.19%] [G loss: 1.660413]\n",
      "epoch:15 step:12184 [D loss: 0.400860, acc: 92.97%] [G loss: 2.274469]\n",
      "epoch:15 step:12185 [D loss: 0.557100, acc: 64.06%] [G loss: 1.335083]\n",
      "epoch:15 step:12186 [D loss: 1.010933, acc: 12.50%] [G loss: 1.621087]\n",
      "epoch:15 step:12187 [D loss: 0.596568, acc: 74.22%] [G loss: 2.121172]\n",
      "epoch:15 step:12188 [D loss: 0.860750, acc: 31.25%] [G loss: 1.643597]\n",
      "epoch:15 step:12189 [D loss: 0.888383, acc: 23.44%] [G loss: 1.521608]\n",
      "epoch:15 step:12190 [D loss: 0.593953, acc: 72.66%] [G loss: 1.753295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12191 [D loss: 0.331260, acc: 94.53%] [G loss: 2.043115]\n",
      "epoch:15 step:12192 [D loss: 0.491647, acc: 76.56%] [G loss: 1.857500]\n",
      "epoch:15 step:12193 [D loss: 0.433943, acc: 92.97%] [G loss: 2.008233]\n",
      "epoch:15 step:12194 [D loss: 0.600488, acc: 71.88%] [G loss: 1.888848]\n",
      "epoch:15 step:12195 [D loss: 0.838746, acc: 38.28%] [G loss: 1.701013]\n",
      "epoch:15 step:12196 [D loss: 0.842010, acc: 32.03%] [G loss: 1.385126]\n",
      "epoch:15 step:12197 [D loss: 0.843114, acc: 30.47%] [G loss: 1.536258]\n",
      "epoch:15 step:12198 [D loss: 0.623683, acc: 62.50%] [G loss: 1.783169]\n",
      "epoch:15 step:12199 [D loss: 0.504439, acc: 84.38%] [G loss: 1.933917]\n",
      "epoch:15 step:12200 [D loss: 0.449674, acc: 85.16%] [G loss: 1.987789]\n",
      "epoch:15 step:12201 [D loss: 0.732432, acc: 53.91%] [G loss: 1.844958]\n",
      "epoch:15 step:12202 [D loss: 0.648257, acc: 57.81%] [G loss: 2.068589]\n",
      "epoch:15 step:12203 [D loss: 0.681599, acc: 55.47%] [G loss: 1.353574]\n",
      "epoch:15 step:12204 [D loss: 0.640116, acc: 63.28%] [G loss: 1.574104]\n",
      "epoch:15 step:12205 [D loss: 0.535755, acc: 82.81%] [G loss: 1.939659]\n",
      "epoch:15 step:12206 [D loss: 0.568421, acc: 69.53%] [G loss: 1.868461]\n",
      "epoch:15 step:12207 [D loss: 0.862764, acc: 50.78%] [G loss: 1.216941]\n",
      "epoch:15 step:12208 [D loss: 0.613004, acc: 64.06%] [G loss: 2.010487]\n",
      "epoch:15 step:12209 [D loss: 0.748296, acc: 45.31%] [G loss: 1.646904]\n",
      "epoch:15 step:12210 [D loss: 0.617055, acc: 68.75%] [G loss: 1.867484]\n",
      "epoch:15 step:12211 [D loss: 0.482143, acc: 85.16%] [G loss: 2.032092]\n",
      "epoch:15 step:12212 [D loss: 0.683329, acc: 57.81%] [G loss: 2.193044]\n",
      "epoch:15 step:12213 [D loss: 0.619495, acc: 65.62%] [G loss: 2.125998]\n",
      "epoch:15 step:12214 [D loss: 0.701365, acc: 53.12%] [G loss: 1.815341]\n",
      "epoch:15 step:12215 [D loss: 0.759976, acc: 41.41%] [G loss: 1.665829]\n",
      "epoch:15 step:12216 [D loss: 0.524549, acc: 82.03%] [G loss: 1.516778]\n",
      "epoch:15 step:12217 [D loss: 0.588516, acc: 76.56%] [G loss: 1.683305]\n",
      "epoch:15 step:12218 [D loss: 0.579483, acc: 81.25%] [G loss: 1.959817]\n",
      "epoch:15 step:12219 [D loss: 0.712566, acc: 51.56%] [G loss: 1.740720]\n",
      "epoch:15 step:12220 [D loss: 0.658244, acc: 59.38%] [G loss: 1.294597]\n",
      "epoch:15 step:12221 [D loss: 0.587131, acc: 78.12%] [G loss: 1.645847]\n",
      "epoch:15 step:12222 [D loss: 0.730365, acc: 40.62%] [G loss: 1.568137]\n",
      "epoch:15 step:12223 [D loss: 0.688752, acc: 50.00%] [G loss: 1.544525]\n",
      "epoch:15 step:12224 [D loss: 0.661599, acc: 55.47%] [G loss: 1.393291]\n",
      "epoch:15 step:12225 [D loss: 0.776299, acc: 38.28%] [G loss: 1.678166]\n",
      "epoch:15 step:12226 [D loss: 0.553797, acc: 78.91%] [G loss: 2.345472]\n",
      "epoch:15 step:12227 [D loss: 0.670218, acc: 61.72%] [G loss: 1.485704]\n",
      "epoch:15 step:12228 [D loss: 0.653103, acc: 60.94%] [G loss: 2.267086]\n",
      "epoch:15 step:12229 [D loss: 0.721745, acc: 49.22%] [G loss: 1.857050]\n",
      "epoch:15 step:12230 [D loss: 0.716269, acc: 54.69%] [G loss: 2.036390]\n",
      "epoch:15 step:12231 [D loss: 0.689697, acc: 53.91%] [G loss: 2.018362]\n",
      "epoch:15 step:12232 [D loss: 0.586930, acc: 71.09%] [G loss: 2.035413]\n",
      "epoch:15 step:12233 [D loss: 0.838371, acc: 35.16%] [G loss: 1.461189]\n",
      "epoch:15 step:12234 [D loss: 1.216720, acc: 2.34%] [G loss: 1.321256]\n",
      "epoch:15 step:12235 [D loss: 0.629176, acc: 65.62%] [G loss: 1.949998]\n",
      "epoch:15 step:12236 [D loss: 0.498980, acc: 84.38%] [G loss: 2.006070]\n",
      "epoch:15 step:12237 [D loss: 0.673219, acc: 58.59%] [G loss: 1.940511]\n",
      "epoch:15 step:12238 [D loss: 0.686674, acc: 60.94%] [G loss: 1.617497]\n",
      "epoch:15 step:12239 [D loss: 0.644352, acc: 67.19%] [G loss: 1.545568]\n",
      "epoch:15 step:12240 [D loss: 0.810499, acc: 32.81%] [G loss: 1.482031]\n",
      "epoch:15 step:12241 [D loss: 0.899003, acc: 19.53%] [G loss: 1.903307]\n",
      "epoch:15 step:12242 [D loss: 0.762643, acc: 42.19%] [G loss: 1.602508]\n",
      "epoch:15 step:12243 [D loss: 0.795216, acc: 46.88%] [G loss: 1.641381]\n",
      "epoch:15 step:12244 [D loss: 0.543184, acc: 80.47%] [G loss: 1.676327]\n",
      "epoch:15 step:12245 [D loss: 0.659865, acc: 59.38%] [G loss: 1.625971]\n",
      "epoch:15 step:12246 [D loss: 0.801937, acc: 33.59%] [G loss: 1.632182]\n",
      "epoch:15 step:12247 [D loss: 0.607370, acc: 68.75%] [G loss: 1.687604]\n",
      "epoch:15 step:12248 [D loss: 0.675629, acc: 57.03%] [G loss: 2.029941]\n",
      "epoch:15 step:12249 [D loss: 0.680534, acc: 56.25%] [G loss: 1.491973]\n",
      "epoch:15 step:12250 [D loss: 0.558856, acc: 73.44%] [G loss: 1.832063]\n",
      "epoch:15 step:12251 [D loss: 0.750986, acc: 47.66%] [G loss: 1.723283]\n",
      "epoch:15 step:12252 [D loss: 0.534293, acc: 83.59%] [G loss: 1.823068]\n",
      "epoch:15 step:12253 [D loss: 0.550537, acc: 78.12%] [G loss: 2.282828]\n",
      "epoch:15 step:12254 [D loss: 0.508608, acc: 67.97%] [G loss: 1.573570]\n",
      "epoch:15 step:12255 [D loss: 0.784409, acc: 33.59%] [G loss: 1.680818]\n",
      "epoch:15 step:12256 [D loss: 0.393527, acc: 95.31%] [G loss: 1.965388]\n",
      "epoch:15 step:12257 [D loss: 0.688485, acc: 52.34%] [G loss: 1.627368]\n",
      "epoch:15 step:12258 [D loss: 0.632084, acc: 70.31%] [G loss: 1.635489]\n",
      "epoch:15 step:12259 [D loss: 0.569852, acc: 76.56%] [G loss: 1.951345]\n",
      "epoch:15 step:12260 [D loss: 0.804699, acc: 32.81%] [G loss: 1.462233]\n",
      "epoch:15 step:12261 [D loss: 0.587901, acc: 60.16%] [G loss: 1.667999]\n",
      "epoch:15 step:12262 [D loss: 0.597951, acc: 74.22%] [G loss: 2.010324]\n",
      "epoch:15 step:12263 [D loss: 0.655848, acc: 57.03%] [G loss: 1.687109]\n",
      "epoch:15 step:12264 [D loss: 0.606711, acc: 68.75%] [G loss: 1.947608]\n",
      "epoch:15 step:12265 [D loss: 0.525636, acc: 82.81%] [G loss: 1.837798]\n",
      "epoch:15 step:12266 [D loss: 0.608722, acc: 73.44%] [G loss: 1.711434]\n",
      "epoch:15 step:12267 [D loss: 0.990571, acc: 21.09%] [G loss: 1.400397]\n",
      "epoch:15 step:12268 [D loss: 0.952229, acc: 25.00%] [G loss: 1.211494]\n",
      "epoch:15 step:12269 [D loss: 0.669425, acc: 57.03%] [G loss: 1.618791]\n",
      "epoch:15 step:12270 [D loss: 0.779966, acc: 42.97%] [G loss: 1.627912]\n",
      "epoch:15 step:12271 [D loss: 0.690421, acc: 51.56%] [G loss: 1.713849]\n",
      "epoch:15 step:12272 [D loss: 0.517994, acc: 83.59%] [G loss: 1.613565]\n",
      "epoch:15 step:12273 [D loss: 0.667963, acc: 61.72%] [G loss: 1.856922]\n",
      "epoch:15 step:12274 [D loss: 0.667381, acc: 57.81%] [G loss: 1.620153]\n",
      "epoch:15 step:12275 [D loss: 0.700868, acc: 60.94%] [G loss: 1.755641]\n",
      "epoch:15 step:12276 [D loss: 0.567277, acc: 73.44%] [G loss: 1.907118]\n",
      "epoch:15 step:12277 [D loss: 0.669469, acc: 59.38%] [G loss: 1.631787]\n",
      "epoch:15 step:12278 [D loss: 0.682632, acc: 57.03%] [G loss: 1.698153]\n",
      "epoch:15 step:12279 [D loss: 0.707586, acc: 53.91%] [G loss: 1.909868]\n",
      "epoch:15 step:12280 [D loss: 0.659946, acc: 56.25%] [G loss: 1.716109]\n",
      "epoch:15 step:12281 [D loss: 0.533974, acc: 77.34%] [G loss: 1.758157]\n",
      "epoch:15 step:12282 [D loss: 0.449139, acc: 93.75%] [G loss: 1.802357]\n",
      "epoch:15 step:12283 [D loss: 0.573918, acc: 78.12%] [G loss: 1.698243]\n",
      "epoch:15 step:12284 [D loss: 0.684841, acc: 54.69%] [G loss: 1.651603]\n",
      "epoch:15 step:12285 [D loss: 0.529375, acc: 85.94%] [G loss: 1.906835]\n",
      "epoch:15 step:12286 [D loss: 0.607035, acc: 70.31%] [G loss: 1.496032]\n",
      "epoch:15 step:12287 [D loss: 0.563890, acc: 79.69%] [G loss: 2.050068]\n",
      "epoch:15 step:12288 [D loss: 0.584158, acc: 77.34%] [G loss: 1.776184]\n",
      "epoch:15 step:12289 [D loss: 0.777712, acc: 45.31%] [G loss: 1.674692]\n",
      "epoch:15 step:12290 [D loss: 0.822236, acc: 28.12%] [G loss: 1.559046]\n",
      "epoch:15 step:12291 [D loss: 0.658033, acc: 59.38%] [G loss: 1.968076]\n",
      "epoch:15 step:12292 [D loss: 0.713010, acc: 52.34%] [G loss: 1.795425]\n",
      "epoch:15 step:12293 [D loss: 0.646912, acc: 60.94%] [G loss: 1.796469]\n",
      "epoch:15 step:12294 [D loss: 0.321874, acc: 93.75%] [G loss: 1.854166]\n",
      "epoch:15 step:12295 [D loss: 0.639153, acc: 67.19%] [G loss: 1.748368]\n",
      "epoch:15 step:12296 [D loss: 0.687433, acc: 57.03%] [G loss: 1.980290]\n",
      "epoch:15 step:12297 [D loss: 0.519568, acc: 74.22%] [G loss: 1.974418]\n",
      "epoch:15 step:12298 [D loss: 0.719301, acc: 50.78%] [G loss: 1.551968]\n",
      "epoch:15 step:12299 [D loss: 0.747352, acc: 51.56%] [G loss: 1.644842]\n",
      "epoch:15 step:12300 [D loss: 0.913104, acc: 20.31%] [G loss: 1.552045]\n",
      "epoch:15 step:12301 [D loss: 0.579540, acc: 71.09%] [G loss: 1.872202]\n",
      "epoch:15 step:12302 [D loss: 0.579335, acc: 80.47%] [G loss: 1.649339]\n",
      "epoch:15 step:12303 [D loss: 0.662696, acc: 56.25%] [G loss: 1.921330]\n",
      "epoch:15 step:12304 [D loss: 0.606062, acc: 75.78%] [G loss: 1.741326]\n",
      "epoch:15 step:12305 [D loss: 0.681071, acc: 62.50%] [G loss: 1.800405]\n",
      "epoch:15 step:12306 [D loss: 0.904714, acc: 21.09%] [G loss: 1.525633]\n",
      "epoch:15 step:12307 [D loss: 0.646670, acc: 61.72%] [G loss: 1.572906]\n",
      "epoch:15 step:12308 [D loss: 0.377724, acc: 95.31%] [G loss: 2.016505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12309 [D loss: 0.693327, acc: 57.03%] [G loss: 1.915447]\n",
      "epoch:15 step:12310 [D loss: 0.710087, acc: 48.44%] [G loss: 1.578338]\n",
      "epoch:15 step:12311 [D loss: 0.831236, acc: 29.69%] [G loss: 1.822112]\n",
      "epoch:15 step:12312 [D loss: 0.602188, acc: 66.41%] [G loss: 1.709043]\n",
      "epoch:15 step:12313 [D loss: 0.534462, acc: 80.47%] [G loss: 1.823503]\n",
      "epoch:15 step:12314 [D loss: 0.727068, acc: 41.41%] [G loss: 1.852092]\n",
      "epoch:15 step:12315 [D loss: 0.574162, acc: 72.66%] [G loss: 2.149307]\n",
      "epoch:15 step:12316 [D loss: 0.506055, acc: 69.53%] [G loss: 2.026684]\n",
      "epoch:15 step:12317 [D loss: 0.496491, acc: 85.16%] [G loss: 1.897980]\n",
      "epoch:15 step:12318 [D loss: 0.788235, acc: 43.75%] [G loss: 1.448662]\n",
      "epoch:15 step:12319 [D loss: 0.481900, acc: 87.50%] [G loss: 1.888282]\n",
      "epoch:15 step:12320 [D loss: 0.669025, acc: 59.38%] [G loss: 1.515777]\n",
      "epoch:15 step:12321 [D loss: 0.623885, acc: 64.06%] [G loss: 1.944318]\n",
      "epoch:15 step:12322 [D loss: 0.576105, acc: 67.97%] [G loss: 1.801511]\n",
      "epoch:15 step:12323 [D loss: 0.727017, acc: 51.56%] [G loss: 1.522852]\n",
      "epoch:15 step:12324 [D loss: 0.702352, acc: 53.91%] [G loss: 1.664365]\n",
      "epoch:15 step:12325 [D loss: 0.935201, acc: 13.28%] [G loss: 1.373819]\n",
      "epoch:15 step:12326 [D loss: 0.536817, acc: 80.47%] [G loss: 1.879651]\n",
      "epoch:15 step:12327 [D loss: 0.546200, acc: 80.47%] [G loss: 1.717873]\n",
      "epoch:15 step:12328 [D loss: 0.478635, acc: 90.62%] [G loss: 2.160601]\n",
      "epoch:15 step:12329 [D loss: 0.603188, acc: 63.28%] [G loss: 1.691677]\n",
      "epoch:15 step:12330 [D loss: 0.512937, acc: 84.38%] [G loss: 2.166303]\n",
      "epoch:15 step:12331 [D loss: 0.895298, acc: 28.91%] [G loss: 1.514901]\n",
      "epoch:15 step:12332 [D loss: 0.613669, acc: 68.75%] [G loss: 1.862810]\n",
      "epoch:15 step:12333 [D loss: 0.807189, acc: 41.41%] [G loss: 1.327142]\n",
      "epoch:15 step:12334 [D loss: 0.879945, acc: 37.50%] [G loss: 1.562644]\n",
      "epoch:15 step:12335 [D loss: 0.717542, acc: 51.56%] [G loss: 1.926280]\n",
      "epoch:15 step:12336 [D loss: 0.882118, acc: 24.22%] [G loss: 1.435940]\n",
      "epoch:15 step:12337 [D loss: 0.768556, acc: 42.97%] [G loss: 1.600971]\n",
      "epoch:15 step:12338 [D loss: 0.705331, acc: 52.34%] [G loss: 1.893745]\n",
      "epoch:15 step:12339 [D loss: 0.564601, acc: 79.69%] [G loss: 1.812685]\n",
      "epoch:15 step:12340 [D loss: 0.792100, acc: 32.81%] [G loss: 1.800333]\n",
      "epoch:15 step:12341 [D loss: 0.477187, acc: 83.59%] [G loss: 1.807100]\n",
      "epoch:15 step:12342 [D loss: 0.665823, acc: 61.72%] [G loss: 1.872909]\n",
      "epoch:15 step:12343 [D loss: 0.615191, acc: 66.41%] [G loss: 2.106077]\n",
      "epoch:15 step:12344 [D loss: 0.649238, acc: 64.84%] [G loss: 1.430392]\n",
      "epoch:15 step:12345 [D loss: 0.612108, acc: 68.75%] [G loss: 1.567623]\n",
      "epoch:15 step:12346 [D loss: 0.509567, acc: 86.72%] [G loss: 1.818520]\n",
      "epoch:15 step:12347 [D loss: 0.798233, acc: 51.56%] [G loss: 1.576102]\n",
      "epoch:15 step:12348 [D loss: 0.845435, acc: 28.12%] [G loss: 1.893566]\n",
      "epoch:15 step:12349 [D loss: 0.513932, acc: 73.44%] [G loss: 1.551879]\n",
      "epoch:15 step:12350 [D loss: 0.563825, acc: 77.34%] [G loss: 1.948133]\n",
      "epoch:15 step:12351 [D loss: 0.456346, acc: 89.84%] [G loss: 2.024990]\n",
      "epoch:15 step:12352 [D loss: 0.725060, acc: 46.09%] [G loss: 2.077661]\n",
      "epoch:15 step:12353 [D loss: 0.886749, acc: 18.75%] [G loss: 1.212070]\n",
      "epoch:15 step:12354 [D loss: 0.408252, acc: 85.16%] [G loss: 1.878596]\n",
      "epoch:15 step:12355 [D loss: 0.746210, acc: 50.00%] [G loss: 2.085000]\n",
      "epoch:15 step:12356 [D loss: 0.570933, acc: 71.09%] [G loss: 2.225276]\n",
      "epoch:15 step:12357 [D loss: 0.646205, acc: 60.94%] [G loss: 1.612939]\n",
      "epoch:15 step:12358 [D loss: 0.451960, acc: 87.50%] [G loss: 1.894989]\n",
      "epoch:15 step:12359 [D loss: 0.545881, acc: 68.75%] [G loss: 1.997519]\n",
      "epoch:15 step:12360 [D loss: 0.653962, acc: 58.59%] [G loss: 1.978288]\n",
      "epoch:15 step:12361 [D loss: 0.800659, acc: 35.94%] [G loss: 1.726026]\n",
      "epoch:15 step:12362 [D loss: 0.759806, acc: 47.66%] [G loss: 1.555211]\n",
      "epoch:15 step:12363 [D loss: 0.719470, acc: 51.56%] [G loss: 1.542884]\n",
      "epoch:15 step:12364 [D loss: 0.665612, acc: 57.81%] [G loss: 1.624002]\n",
      "epoch:15 step:12365 [D loss: 0.737431, acc: 48.44%] [G loss: 1.855206]\n",
      "epoch:15 step:12366 [D loss: 0.359114, acc: 98.44%] [G loss: 2.243987]\n",
      "epoch:15 step:12367 [D loss: 0.398055, acc: 96.88%] [G loss: 1.974088]\n",
      "epoch:15 step:12368 [D loss: 0.686713, acc: 60.94%] [G loss: 2.186598]\n",
      "epoch:15 step:12369 [D loss: 0.725768, acc: 57.81%] [G loss: 1.665379]\n",
      "epoch:15 step:12370 [D loss: 0.425692, acc: 89.84%] [G loss: 1.891137]\n",
      "epoch:15 step:12371 [D loss: 0.859326, acc: 48.44%] [G loss: 1.545342]\n",
      "epoch:15 step:12372 [D loss: 0.426223, acc: 90.62%] [G loss: 2.197582]\n",
      "epoch:15 step:12373 [D loss: 0.678970, acc: 56.25%] [G loss: 2.114849]\n",
      "epoch:15 step:12374 [D loss: 0.567402, acc: 72.66%] [G loss: 1.803613]\n",
      "epoch:15 step:12375 [D loss: 0.663686, acc: 55.47%] [G loss: 1.882181]\n",
      "epoch:15 step:12376 [D loss: 0.667130, acc: 55.47%] [G loss: 1.604647]\n",
      "epoch:15 step:12377 [D loss: 0.526951, acc: 83.59%] [G loss: 2.031851]\n",
      "epoch:15 step:12378 [D loss: 0.568592, acc: 71.88%] [G loss: 1.985493]\n",
      "epoch:15 step:12379 [D loss: 0.769170, acc: 42.97%] [G loss: 1.816165]\n",
      "epoch:15 step:12380 [D loss: 0.537457, acc: 82.03%] [G loss: 2.016519]\n",
      "epoch:15 step:12381 [D loss: 0.524476, acc: 67.19%] [G loss: 1.833008]\n",
      "epoch:15 step:12382 [D loss: 0.455064, acc: 90.62%] [G loss: 2.007625]\n",
      "epoch:15 step:12383 [D loss: 0.512217, acc: 81.25%] [G loss: 2.345997]\n",
      "epoch:15 step:12384 [D loss: 0.669850, acc: 58.59%] [G loss: 1.594840]\n",
      "epoch:15 step:12385 [D loss: 1.015031, acc: 11.72%] [G loss: 1.194697]\n",
      "epoch:15 step:12386 [D loss: 0.630420, acc: 63.28%] [G loss: 1.580828]\n",
      "epoch:15 step:12387 [D loss: 0.737108, acc: 49.22%] [G loss: 1.521288]\n",
      "epoch:15 step:12388 [D loss: 0.686001, acc: 53.91%] [G loss: 1.665954]\n",
      "epoch:15 step:12389 [D loss: 0.737961, acc: 51.56%] [G loss: 1.724720]\n",
      "epoch:15 step:12390 [D loss: 0.497318, acc: 87.50%] [G loss: 1.995325]\n",
      "epoch:15 step:12391 [D loss: 0.714940, acc: 50.78%] [G loss: 1.506660]\n",
      "epoch:15 step:12392 [D loss: 0.634829, acc: 64.06%] [G loss: 1.994324]\n",
      "epoch:15 step:12393 [D loss: 0.555523, acc: 82.03%] [G loss: 2.006245]\n",
      "epoch:15 step:12394 [D loss: 0.619302, acc: 55.47%] [G loss: 1.657668]\n",
      "epoch:15 step:12395 [D loss: 0.431090, acc: 95.31%] [G loss: 1.980342]\n",
      "epoch:15 step:12396 [D loss: 0.464525, acc: 89.06%] [G loss: 1.615722]\n",
      "epoch:15 step:12397 [D loss: 1.344605, acc: 3.91%] [G loss: 1.019446]\n",
      "epoch:15 step:12398 [D loss: 0.956889, acc: 15.62%] [G loss: 1.347001]\n",
      "epoch:15 step:12399 [D loss: 0.776377, acc: 41.41%] [G loss: 1.395331]\n",
      "epoch:15 step:12400 [D loss: 0.639315, acc: 65.62%] [G loss: 1.755596]\n",
      "epoch:15 step:12401 [D loss: 0.833068, acc: 29.69%] [G loss: 1.784716]\n",
      "epoch:15 step:12402 [D loss: 0.592302, acc: 76.56%] [G loss: 1.493618]\n",
      "epoch:15 step:12403 [D loss: 0.741517, acc: 45.31%] [G loss: 1.759667]\n",
      "epoch:15 step:12404 [D loss: 0.500204, acc: 77.34%] [G loss: 1.969101]\n",
      "epoch:15 step:12405 [D loss: 0.524598, acc: 74.22%] [G loss: 1.731814]\n",
      "epoch:15 step:12406 [D loss: 0.616695, acc: 68.75%] [G loss: 1.956431]\n",
      "epoch:15 step:12407 [D loss: 0.936420, acc: 33.59%] [G loss: 1.599664]\n",
      "epoch:15 step:12408 [D loss: 0.588613, acc: 64.06%] [G loss: 1.854761]\n",
      "epoch:15 step:12409 [D loss: 0.654658, acc: 62.50%] [G loss: 1.700531]\n",
      "epoch:15 step:12410 [D loss: 0.585704, acc: 70.31%] [G loss: 1.588983]\n",
      "epoch:15 step:12411 [D loss: 0.825482, acc: 33.59%] [G loss: 1.780057]\n",
      "epoch:15 step:12412 [D loss: 0.648125, acc: 58.59%] [G loss: 1.902618]\n",
      "epoch:15 step:12413 [D loss: 0.525032, acc: 79.69%] [G loss: 1.681501]\n",
      "epoch:15 step:12414 [D loss: 0.604502, acc: 67.19%] [G loss: 1.725562]\n",
      "epoch:15 step:12415 [D loss: 0.788752, acc: 47.66%] [G loss: 1.851608]\n",
      "epoch:15 step:12416 [D loss: 0.515715, acc: 85.94%] [G loss: 1.656741]\n",
      "epoch:15 step:12417 [D loss: 0.486756, acc: 85.94%] [G loss: 1.955925]\n",
      "epoch:15 step:12418 [D loss: 0.717473, acc: 50.78%] [G loss: 1.722929]\n",
      "epoch:15 step:12419 [D loss: 0.856624, acc: 31.25%] [G loss: 1.552729]\n",
      "epoch:15 step:12420 [D loss: 0.550225, acc: 71.09%] [G loss: 1.903383]\n",
      "epoch:15 step:12421 [D loss: 0.646214, acc: 60.16%] [G loss: 1.782422]\n",
      "epoch:15 step:12422 [D loss: 0.713967, acc: 53.91%] [G loss: 2.119190]\n",
      "epoch:15 step:12423 [D loss: 0.701874, acc: 53.12%] [G loss: 1.703415]\n",
      "epoch:15 step:12424 [D loss: 0.628351, acc: 61.72%] [G loss: 1.766365]\n",
      "epoch:15 step:12425 [D loss: 0.630460, acc: 67.19%] [G loss: 1.800699]\n",
      "epoch:15 step:12426 [D loss: 0.653654, acc: 56.25%] [G loss: 1.793492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12427 [D loss: 0.612507, acc: 67.97%] [G loss: 1.578108]\n",
      "epoch:15 step:12428 [D loss: 0.607729, acc: 70.31%] [G loss: 1.964705]\n",
      "epoch:15 step:12429 [D loss: 0.494051, acc: 84.38%] [G loss: 1.817343]\n",
      "epoch:15 step:12430 [D loss: 0.745954, acc: 42.97%] [G loss: 1.655704]\n",
      "epoch:15 step:12431 [D loss: 0.466765, acc: 88.28%] [G loss: 2.029197]\n",
      "epoch:15 step:12432 [D loss: 0.632122, acc: 64.06%] [G loss: 1.656355]\n",
      "epoch:15 step:12433 [D loss: 0.782305, acc: 47.66%] [G loss: 1.841224]\n",
      "epoch:15 step:12434 [D loss: 0.509144, acc: 80.47%] [G loss: 1.893495]\n",
      "epoch:15 step:12435 [D loss: 0.520653, acc: 84.38%] [G loss: 1.676100]\n",
      "epoch:15 step:12436 [D loss: 0.871164, acc: 26.56%] [G loss: 1.663658]\n",
      "epoch:15 step:12437 [D loss: 0.575646, acc: 73.44%] [G loss: 1.713998]\n",
      "epoch:15 step:12438 [D loss: 1.012375, acc: 27.34%] [G loss: 1.874190]\n",
      "epoch:15 step:12439 [D loss: 0.549164, acc: 79.69%] [G loss: 1.778675]\n",
      "epoch:15 step:12440 [D loss: 0.591865, acc: 67.97%] [G loss: 1.968688]\n",
      "epoch:15 step:12441 [D loss: 0.716480, acc: 51.56%] [G loss: 1.417192]\n",
      "epoch:15 step:12442 [D loss: 0.695201, acc: 54.69%] [G loss: 1.691186]\n",
      "epoch:15 step:12443 [D loss: 0.655567, acc: 64.84%] [G loss: 1.827347]\n",
      "epoch:15 step:12444 [D loss: 0.430565, acc: 82.03%] [G loss: 1.630870]\n",
      "epoch:15 step:12445 [D loss: 0.650193, acc: 64.06%] [G loss: 2.195338]\n",
      "epoch:15 step:12446 [D loss: 0.453557, acc: 70.31%] [G loss: 1.628993]\n",
      "epoch:15 step:12447 [D loss: 0.683491, acc: 62.50%] [G loss: 1.564712]\n",
      "epoch:15 step:12448 [D loss: 0.787103, acc: 46.88%] [G loss: 1.508410]\n",
      "epoch:15 step:12449 [D loss: 0.887653, acc: 35.16%] [G loss: 1.587769]\n",
      "epoch:15 step:12450 [D loss: 0.674800, acc: 57.03%] [G loss: 1.587706]\n",
      "epoch:15 step:12451 [D loss: 0.742112, acc: 42.97%] [G loss: 1.648446]\n",
      "epoch:15 step:12452 [D loss: 0.495337, acc: 68.75%] [G loss: 1.825102]\n",
      "epoch:15 step:12453 [D loss: 0.555174, acc: 74.22%] [G loss: 2.054963]\n",
      "epoch:15 step:12454 [D loss: 0.500603, acc: 85.16%] [G loss: 1.848010]\n",
      "epoch:15 step:12455 [D loss: 0.580817, acc: 72.66%] [G loss: 1.559234]\n",
      "epoch:15 step:12456 [D loss: 0.557346, acc: 57.03%] [G loss: 2.123180]\n",
      "epoch:15 step:12457 [D loss: 0.630840, acc: 67.97%] [G loss: 1.535041]\n",
      "epoch:15 step:12458 [D loss: 0.780358, acc: 41.41%] [G loss: 1.733366]\n",
      "epoch:15 step:12459 [D loss: 0.763510, acc: 43.75%] [G loss: 1.514047]\n",
      "epoch:15 step:12460 [D loss: 0.390102, acc: 96.88%] [G loss: 1.930138]\n",
      "epoch:15 step:12461 [D loss: 0.812717, acc: 35.94%] [G loss: 1.483254]\n",
      "epoch:15 step:12462 [D loss: 0.517342, acc: 82.03%] [G loss: 1.866168]\n",
      "epoch:15 step:12463 [D loss: 0.588581, acc: 68.75%] [G loss: 1.893814]\n",
      "epoch:15 step:12464 [D loss: 0.780714, acc: 40.62%] [G loss: 1.612035]\n",
      "epoch:15 step:12465 [D loss: 0.625098, acc: 69.53%] [G loss: 1.762314]\n",
      "epoch:15 step:12466 [D loss: 1.160066, acc: 7.03%] [G loss: 1.247242]\n",
      "epoch:15 step:12467 [D loss: 0.303174, acc: 99.22%] [G loss: 2.170031]\n",
      "epoch:15 step:12468 [D loss: 0.649809, acc: 57.03%] [G loss: 1.648866]\n",
      "epoch:15 step:12469 [D loss: 0.590505, acc: 68.75%] [G loss: 1.632255]\n",
      "epoch:15 step:12470 [D loss: 0.586543, acc: 61.72%] [G loss: 1.773913]\n",
      "epoch:15 step:12471 [D loss: 0.766596, acc: 45.31%] [G loss: 1.707132]\n",
      "epoch:15 step:12472 [D loss: 0.549181, acc: 78.12%] [G loss: 1.640134]\n",
      "epoch:15 step:12473 [D loss: 0.746067, acc: 53.12%] [G loss: 1.754688]\n",
      "epoch:15 step:12474 [D loss: 0.517298, acc: 63.28%] [G loss: 1.527006]\n",
      "epoch:15 step:12475 [D loss: 0.581703, acc: 71.88%] [G loss: 1.592457]\n",
      "epoch:15 step:12476 [D loss: 0.739095, acc: 50.00%] [G loss: 1.509279]\n",
      "epoch:15 step:12477 [D loss: 0.701040, acc: 48.44%] [G loss: 2.018832]\n",
      "epoch:15 step:12478 [D loss: 0.605886, acc: 63.28%] [G loss: 1.735177]\n",
      "epoch:15 step:12479 [D loss: 1.124448, acc: 27.34%] [G loss: 1.215369]\n",
      "epoch:15 step:12480 [D loss: 0.755154, acc: 50.00%] [G loss: 1.723443]\n",
      "epoch:15 step:12481 [D loss: 0.436208, acc: 89.84%] [G loss: 2.135985]\n",
      "epoch:15 step:12482 [D loss: 0.628992, acc: 63.28%] [G loss: 1.868594]\n",
      "epoch:15 step:12483 [D loss: 0.590739, acc: 68.75%] [G loss: 2.097128]\n",
      "epoch:15 step:12484 [D loss: 0.445355, acc: 91.41%] [G loss: 2.242314]\n",
      "epoch:15 step:12485 [D loss: 0.446990, acc: 73.44%] [G loss: 1.973471]\n",
      "epoch:15 step:12486 [D loss: 1.112775, acc: 36.72%] [G loss: 1.430325]\n",
      "epoch:15 step:12487 [D loss: 0.592132, acc: 62.50%] [G loss: 2.024500]\n",
      "epoch:15 step:12488 [D loss: 0.701421, acc: 57.81%] [G loss: 1.945883]\n",
      "epoch:15 step:12489 [D loss: 0.602609, acc: 67.19%] [G loss: 2.079700]\n",
      "epoch:15 step:12490 [D loss: 0.780307, acc: 53.12%] [G loss: 1.979471]\n",
      "epoch:15 step:12491 [D loss: 0.669062, acc: 60.16%] [G loss: 1.843602]\n",
      "epoch:15 step:12492 [D loss: 0.568851, acc: 75.78%] [G loss: 1.527459]\n",
      "epoch:15 step:12493 [D loss: 0.831710, acc: 34.38%] [G loss: 1.916317]\n",
      "epoch:15 step:12494 [D loss: 0.890850, acc: 31.25%] [G loss: 1.494432]\n",
      "epoch:15 step:12495 [D loss: 0.659031, acc: 68.75%] [G loss: 1.323724]\n",
      "epoch:15 step:12496 [D loss: 0.613570, acc: 75.78%] [G loss: 1.645269]\n",
      "epoch:16 step:12497 [D loss: 0.521658, acc: 86.72%] [G loss: 1.865671]\n",
      "epoch:16 step:12498 [D loss: 0.581417, acc: 71.88%] [G loss: 1.586934]\n",
      "epoch:16 step:12499 [D loss: 0.536289, acc: 66.41%] [G loss: 1.885370]\n",
      "epoch:16 step:12500 [D loss: 0.626343, acc: 58.59%] [G loss: 1.291123]\n",
      "epoch:16 step:12501 [D loss: 0.335427, acc: 97.66%] [G loss: 1.987009]\n",
      "epoch:16 step:12502 [D loss: 0.538885, acc: 71.09%] [G loss: 1.789567]\n",
      "epoch:16 step:12503 [D loss: 0.770415, acc: 39.84%] [G loss: 1.781015]\n",
      "epoch:16 step:12504 [D loss: 0.828355, acc: 46.88%] [G loss: 1.552289]\n",
      "epoch:16 step:12505 [D loss: 0.553804, acc: 78.12%] [G loss: 2.269393]\n",
      "epoch:16 step:12506 [D loss: 0.951437, acc: 23.44%] [G loss: 1.615167]\n",
      "epoch:16 step:12507 [D loss: 0.385479, acc: 89.06%] [G loss: 2.046390]\n",
      "epoch:16 step:12508 [D loss: 0.430717, acc: 79.69%] [G loss: 1.864945]\n",
      "epoch:16 step:12509 [D loss: 0.545543, acc: 75.00%] [G loss: 1.808020]\n",
      "epoch:16 step:12510 [D loss: 0.629326, acc: 61.72%] [G loss: 1.776155]\n",
      "epoch:16 step:12511 [D loss: 0.700470, acc: 54.69%] [G loss: 1.855965]\n",
      "epoch:16 step:12512 [D loss: 0.489728, acc: 83.59%] [G loss: 1.887773]\n",
      "epoch:16 step:12513 [D loss: 0.312067, acc: 94.53%] [G loss: 3.095749]\n",
      "epoch:16 step:12514 [D loss: 0.735266, acc: 46.09%] [G loss: 1.829545]\n",
      "epoch:16 step:12515 [D loss: 0.463314, acc: 85.94%] [G loss: 1.791913]\n",
      "epoch:16 step:12516 [D loss: 0.569531, acc: 73.44%] [G loss: 1.645276]\n",
      "epoch:16 step:12517 [D loss: 0.458012, acc: 76.56%] [G loss: 1.699899]\n",
      "epoch:16 step:12518 [D loss: 0.309153, acc: 93.75%] [G loss: 1.927469]\n",
      "epoch:16 step:12519 [D loss: 1.059515, acc: 29.69%] [G loss: 1.343784]\n",
      "epoch:16 step:12520 [D loss: 0.372470, acc: 96.09%] [G loss: 1.890355]\n",
      "epoch:16 step:12521 [D loss: 0.609151, acc: 57.81%] [G loss: 1.776457]\n",
      "epoch:16 step:12522 [D loss: 0.538163, acc: 84.38%] [G loss: 1.655221]\n",
      "epoch:16 step:12523 [D loss: 0.806947, acc: 44.53%] [G loss: 1.439637]\n",
      "epoch:16 step:12524 [D loss: 0.461675, acc: 89.84%] [G loss: 1.765121]\n",
      "epoch:16 step:12525 [D loss: 0.413606, acc: 92.97%] [G loss: 2.031123]\n",
      "epoch:16 step:12526 [D loss: 0.601053, acc: 69.53%] [G loss: 2.130421]\n",
      "epoch:16 step:12527 [D loss: 0.368879, acc: 89.06%] [G loss: 1.535052]\n",
      "epoch:16 step:12528 [D loss: 0.689228, acc: 57.81%] [G loss: 1.867022]\n",
      "epoch:16 step:12529 [D loss: 0.439920, acc: 87.50%] [G loss: 1.855769]\n",
      "epoch:16 step:12530 [D loss: 0.808555, acc: 41.41%] [G loss: 1.743996]\n",
      "epoch:16 step:12531 [D loss: 0.971176, acc: 15.62%] [G loss: 1.558370]\n",
      "epoch:16 step:12532 [D loss: 0.685052, acc: 60.16%] [G loss: 1.830015]\n",
      "epoch:16 step:12533 [D loss: 0.456560, acc: 64.84%] [G loss: 1.843101]\n",
      "epoch:16 step:12534 [D loss: 0.468753, acc: 86.72%] [G loss: 1.802961]\n",
      "epoch:16 step:12535 [D loss: 0.637347, acc: 66.41%] [G loss: 1.651497]\n",
      "epoch:16 step:12536 [D loss: 0.527218, acc: 64.06%] [G loss: 2.446230]\n",
      "epoch:16 step:12537 [D loss: 0.439893, acc: 89.06%] [G loss: 1.710680]\n",
      "epoch:16 step:12538 [D loss: 0.796040, acc: 39.84%] [G loss: 1.688806]\n",
      "epoch:16 step:12539 [D loss: 0.592658, acc: 67.19%] [G loss: 1.739881]\n",
      "epoch:16 step:12540 [D loss: 0.694553, acc: 57.03%] [G loss: 1.363275]\n",
      "epoch:16 step:12541 [D loss: 0.817932, acc: 49.22%] [G loss: 2.018139]\n",
      "epoch:16 step:12542 [D loss: 0.685471, acc: 50.78%] [G loss: 1.625066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12543 [D loss: 0.533720, acc: 81.25%] [G loss: 2.213699]\n",
      "epoch:16 step:12544 [D loss: 0.694306, acc: 52.34%] [G loss: 1.887331]\n",
      "epoch:16 step:12545 [D loss: 0.970629, acc: 17.19%] [G loss: 1.614563]\n",
      "epoch:16 step:12546 [D loss: 0.630637, acc: 66.41%] [G loss: 1.555707]\n",
      "epoch:16 step:12547 [D loss: 0.817472, acc: 45.31%] [G loss: 1.702174]\n",
      "epoch:16 step:12548 [D loss: 0.621356, acc: 64.84%] [G loss: 1.735664]\n",
      "epoch:16 step:12549 [D loss: 0.541538, acc: 78.91%] [G loss: 2.205699]\n",
      "epoch:16 step:12550 [D loss: 0.797169, acc: 38.28%] [G loss: 1.618406]\n",
      "epoch:16 step:12551 [D loss: 0.534474, acc: 80.47%] [G loss: 2.213583]\n",
      "epoch:16 step:12552 [D loss: 0.767658, acc: 44.53%] [G loss: 1.880606]\n",
      "epoch:16 step:12553 [D loss: 0.908009, acc: 27.34%] [G loss: 1.450710]\n",
      "epoch:16 step:12554 [D loss: 0.409532, acc: 95.31%] [G loss: 1.588177]\n",
      "epoch:16 step:12555 [D loss: 0.614018, acc: 67.19%] [G loss: 1.714677]\n",
      "epoch:16 step:12556 [D loss: 0.483756, acc: 82.81%] [G loss: 1.845333]\n",
      "epoch:16 step:12557 [D loss: 0.758503, acc: 43.75%] [G loss: 1.212227]\n",
      "epoch:16 step:12558 [D loss: 0.765473, acc: 42.97%] [G loss: 1.872701]\n",
      "epoch:16 step:12559 [D loss: 0.831000, acc: 31.25%] [G loss: 1.813588]\n",
      "epoch:16 step:12560 [D loss: 0.424850, acc: 91.41%] [G loss: 1.792528]\n",
      "epoch:16 step:12561 [D loss: 0.536925, acc: 86.72%] [G loss: 1.725204]\n",
      "epoch:16 step:12562 [D loss: 0.520832, acc: 80.47%] [G loss: 1.810060]\n",
      "epoch:16 step:12563 [D loss: 1.195348, acc: 2.34%] [G loss: 1.232377]\n",
      "epoch:16 step:12564 [D loss: 0.470421, acc: 82.03%] [G loss: 2.269952]\n",
      "epoch:16 step:12565 [D loss: 0.557140, acc: 79.69%] [G loss: 1.866111]\n",
      "epoch:16 step:12566 [D loss: 0.455515, acc: 82.81%] [G loss: 2.313319]\n",
      "epoch:16 step:12567 [D loss: 1.155005, acc: 7.81%] [G loss: 1.659057]\n",
      "epoch:16 step:12568 [D loss: 0.456767, acc: 90.62%] [G loss: 1.930745]\n",
      "epoch:16 step:12569 [D loss: 0.744300, acc: 53.91%] [G loss: 1.562143]\n",
      "epoch:16 step:12570 [D loss: 0.485972, acc: 82.81%] [G loss: 1.628717]\n",
      "epoch:16 step:12571 [D loss: 0.481518, acc: 80.47%] [G loss: 1.943897]\n",
      "epoch:16 step:12572 [D loss: 0.878691, acc: 48.44%] [G loss: 1.933146]\n",
      "epoch:16 step:12573 [D loss: 1.033334, acc: 12.50%] [G loss: 1.347155]\n",
      "epoch:16 step:12574 [D loss: 0.776773, acc: 43.75%] [G loss: 1.607999]\n",
      "epoch:16 step:12575 [D loss: 0.567355, acc: 75.78%] [G loss: 1.610538]\n",
      "epoch:16 step:12576 [D loss: 0.868061, acc: 28.12%] [G loss: 1.532120]\n",
      "epoch:16 step:12577 [D loss: 0.407843, acc: 89.84%] [G loss: 1.719344]\n",
      "epoch:16 step:12578 [D loss: 0.660034, acc: 57.81%] [G loss: 1.876105]\n",
      "epoch:16 step:12579 [D loss: 0.720463, acc: 50.78%] [G loss: 1.653426]\n",
      "epoch:16 step:12580 [D loss: 0.830366, acc: 32.03%] [G loss: 1.291380]\n",
      "epoch:16 step:12581 [D loss: 0.633684, acc: 63.28%] [G loss: 1.814419]\n",
      "epoch:16 step:12582 [D loss: 0.589216, acc: 59.38%] [G loss: 1.578609]\n",
      "epoch:16 step:12583 [D loss: 0.794485, acc: 46.09%] [G loss: 1.729747]\n",
      "epoch:16 step:12584 [D loss: 0.655785, acc: 56.25%] [G loss: 1.422785]\n",
      "epoch:16 step:12585 [D loss: 0.665387, acc: 55.47%] [G loss: 1.929431]\n",
      "epoch:16 step:12586 [D loss: 0.640526, acc: 60.16%] [G loss: 1.527018]\n",
      "epoch:16 step:12587 [D loss: 0.670714, acc: 60.16%] [G loss: 2.068454]\n",
      "epoch:16 step:12588 [D loss: 0.665980, acc: 64.06%] [G loss: 1.884914]\n",
      "epoch:16 step:12589 [D loss: 0.609729, acc: 69.53%] [G loss: 2.007187]\n",
      "epoch:16 step:12590 [D loss: 0.716837, acc: 49.22%] [G loss: 1.892546]\n",
      "epoch:16 step:12591 [D loss: 0.678209, acc: 54.69%] [G loss: 1.892814]\n",
      "epoch:16 step:12592 [D loss: 0.642702, acc: 57.81%] [G loss: 1.999561]\n",
      "epoch:16 step:12593 [D loss: 0.751838, acc: 53.91%] [G loss: 1.568023]\n",
      "epoch:16 step:12594 [D loss: 0.605488, acc: 67.97%] [G loss: 2.087794]\n",
      "epoch:16 step:12595 [D loss: 0.603416, acc: 70.31%] [G loss: 1.738173]\n",
      "epoch:16 step:12596 [D loss: 0.385124, acc: 93.75%] [G loss: 2.052065]\n",
      "epoch:16 step:12597 [D loss: 0.670082, acc: 56.25%] [G loss: 1.736795]\n",
      "epoch:16 step:12598 [D loss: 0.528584, acc: 80.47%] [G loss: 2.057053]\n",
      "epoch:16 step:12599 [D loss: 0.287029, acc: 96.88%] [G loss: 2.344064]\n",
      "epoch:16 step:12600 [D loss: 0.490155, acc: 79.69%] [G loss: 1.882431]\n",
      "epoch:16 step:12601 [D loss: 0.520573, acc: 82.81%] [G loss: 1.766013]\n",
      "epoch:16 step:12602 [D loss: 0.716093, acc: 55.47%] [G loss: 1.770480]\n",
      "epoch:16 step:12603 [D loss: 0.691891, acc: 53.91%] [G loss: 1.532216]\n",
      "epoch:16 step:12604 [D loss: 0.913952, acc: 48.44%] [G loss: 1.474430]\n",
      "epoch:16 step:12605 [D loss: 0.855877, acc: 50.78%] [G loss: 1.888089]\n",
      "epoch:16 step:12606 [D loss: 0.641959, acc: 64.06%] [G loss: 1.873434]\n",
      "epoch:16 step:12607 [D loss: 0.441519, acc: 89.84%] [G loss: 1.656351]\n",
      "epoch:16 step:12608 [D loss: 0.403181, acc: 89.84%] [G loss: 1.689897]\n",
      "epoch:16 step:12609 [D loss: 0.449605, acc: 87.50%] [G loss: 1.571622]\n",
      "epoch:16 step:12610 [D loss: 0.676841, acc: 57.03%] [G loss: 1.873170]\n",
      "epoch:16 step:12611 [D loss: 0.704094, acc: 53.12%] [G loss: 1.810651]\n",
      "epoch:16 step:12612 [D loss: 0.276291, acc: 93.75%] [G loss: 1.879409]\n",
      "epoch:16 step:12613 [D loss: 0.986215, acc: 22.66%] [G loss: 1.534259]\n",
      "epoch:16 step:12614 [D loss: 0.576048, acc: 71.88%] [G loss: 1.694165]\n",
      "epoch:16 step:12615 [D loss: 0.538309, acc: 75.00%] [G loss: 1.788831]\n",
      "epoch:16 step:12616 [D loss: 0.602148, acc: 67.97%] [G loss: 1.512578]\n",
      "epoch:16 step:12617 [D loss: 0.324759, acc: 98.44%] [G loss: 1.958354]\n",
      "epoch:16 step:12618 [D loss: 0.721887, acc: 49.22%] [G loss: 2.097853]\n",
      "epoch:16 step:12619 [D loss: 0.432210, acc: 86.72%] [G loss: 2.126969]\n",
      "epoch:16 step:12620 [D loss: 0.475875, acc: 86.72%] [G loss: 2.148691]\n",
      "epoch:16 step:12621 [D loss: 0.813522, acc: 35.94%] [G loss: 1.530332]\n",
      "epoch:16 step:12622 [D loss: 0.911050, acc: 35.16%] [G loss: 1.587306]\n",
      "epoch:16 step:12623 [D loss: 0.666413, acc: 53.12%] [G loss: 1.917792]\n",
      "epoch:16 step:12624 [D loss: 0.422544, acc: 92.19%] [G loss: 2.267620]\n",
      "epoch:16 step:12625 [D loss: 0.734441, acc: 46.09%] [G loss: 1.501703]\n",
      "epoch:16 step:12626 [D loss: 0.867583, acc: 31.25%] [G loss: 1.811486]\n",
      "epoch:16 step:12627 [D loss: 0.748369, acc: 52.34%] [G loss: 2.211442]\n",
      "epoch:16 step:12628 [D loss: 0.500085, acc: 79.69%] [G loss: 2.315019]\n",
      "epoch:16 step:12629 [D loss: 0.675245, acc: 56.25%] [G loss: 2.038928]\n",
      "epoch:16 step:12630 [D loss: 0.529330, acc: 68.75%] [G loss: 1.831602]\n",
      "epoch:16 step:12631 [D loss: 0.651346, acc: 58.59%] [G loss: 2.229369]\n",
      "epoch:16 step:12632 [D loss: 0.700925, acc: 57.03%] [G loss: 1.936965]\n",
      "epoch:16 step:12633 [D loss: 0.646815, acc: 61.72%] [G loss: 1.635946]\n",
      "epoch:16 step:12634 [D loss: 0.467674, acc: 87.50%] [G loss: 2.147245]\n",
      "epoch:16 step:12635 [D loss: 0.601614, acc: 73.44%] [G loss: 1.637491]\n",
      "epoch:16 step:12636 [D loss: 0.528839, acc: 67.97%] [G loss: 2.006700]\n",
      "epoch:16 step:12637 [D loss: 0.582758, acc: 75.00%] [G loss: 2.141462]\n",
      "epoch:16 step:12638 [D loss: 0.769303, acc: 46.88%] [G loss: 1.757260]\n",
      "epoch:16 step:12639 [D loss: 0.570229, acc: 64.06%] [G loss: 1.798707]\n",
      "epoch:16 step:12640 [D loss: 0.784254, acc: 42.97%] [G loss: 1.884235]\n",
      "epoch:16 step:12641 [D loss: 0.396907, acc: 92.97%] [G loss: 2.150080]\n",
      "epoch:16 step:12642 [D loss: 0.253192, acc: 97.66%] [G loss: 1.745484]\n",
      "epoch:16 step:12643 [D loss: 0.689341, acc: 57.03%] [G loss: 2.178757]\n",
      "epoch:16 step:12644 [D loss: 0.560388, acc: 73.44%] [G loss: 1.659672]\n",
      "epoch:16 step:12645 [D loss: 0.767677, acc: 42.97%] [G loss: 1.665209]\n",
      "epoch:16 step:12646 [D loss: 0.470056, acc: 71.09%] [G loss: 1.578785]\n",
      "epoch:16 step:12647 [D loss: 0.348700, acc: 86.72%] [G loss: 2.144588]\n",
      "epoch:16 step:12648 [D loss: 0.958371, acc: 26.56%] [G loss: 1.547282]\n",
      "epoch:16 step:12649 [D loss: 0.380966, acc: 92.97%] [G loss: 2.141014]\n",
      "epoch:16 step:12650 [D loss: 0.715803, acc: 53.12%] [G loss: 1.802351]\n",
      "epoch:16 step:12651 [D loss: 0.489107, acc: 88.28%] [G loss: 1.833385]\n",
      "epoch:16 step:12652 [D loss: 0.819086, acc: 28.12%] [G loss: 1.635795]\n",
      "epoch:16 step:12653 [D loss: 0.315704, acc: 93.75%] [G loss: 1.774347]\n",
      "epoch:16 step:12654 [D loss: 0.724798, acc: 55.47%] [G loss: 1.837023]\n",
      "epoch:16 step:12655 [D loss: 0.612682, acc: 66.41%] [G loss: 1.804563]\n",
      "epoch:16 step:12656 [D loss: 0.895821, acc: 28.12%] [G loss: 1.590483]\n",
      "epoch:16 step:12657 [D loss: 0.660475, acc: 54.69%] [G loss: 1.848390]\n",
      "epoch:16 step:12658 [D loss: 0.621469, acc: 64.06%] [G loss: 2.222534]\n",
      "epoch:16 step:12659 [D loss: 0.735160, acc: 50.78%] [G loss: 1.732970]\n",
      "epoch:16 step:12660 [D loss: 0.598211, acc: 72.66%] [G loss: 1.778142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12661 [D loss: 0.671693, acc: 57.03%] [G loss: 1.565834]\n",
      "epoch:16 step:12662 [D loss: 0.735364, acc: 45.31%] [G loss: 1.621784]\n",
      "epoch:16 step:12663 [D loss: 0.651673, acc: 61.72%] [G loss: 1.977741]\n",
      "epoch:16 step:12664 [D loss: 0.539819, acc: 78.91%] [G loss: 2.341333]\n",
      "epoch:16 step:12665 [D loss: 0.601369, acc: 76.56%] [G loss: 2.155440]\n",
      "epoch:16 step:12666 [D loss: 0.573120, acc: 73.44%] [G loss: 1.907359]\n",
      "epoch:16 step:12667 [D loss: 0.553742, acc: 76.56%] [G loss: 1.658540]\n",
      "epoch:16 step:12668 [D loss: 0.589712, acc: 68.75%] [G loss: 1.888535]\n",
      "epoch:16 step:12669 [D loss: 0.912093, acc: 21.88%] [G loss: 1.768998]\n",
      "epoch:16 step:12670 [D loss: 0.631152, acc: 64.06%] [G loss: 1.743775]\n",
      "epoch:16 step:12671 [D loss: 0.623225, acc: 66.41%] [G loss: 2.133969]\n",
      "epoch:16 step:12672 [D loss: 0.649756, acc: 62.50%] [G loss: 2.096419]\n",
      "epoch:16 step:12673 [D loss: 0.530450, acc: 76.56%] [G loss: 1.808573]\n",
      "epoch:16 step:12674 [D loss: 0.707658, acc: 51.56%] [G loss: 1.566266]\n",
      "epoch:16 step:12675 [D loss: 0.714944, acc: 51.56%] [G loss: 1.654095]\n",
      "epoch:16 step:12676 [D loss: 0.684955, acc: 58.59%] [G loss: 1.798839]\n",
      "epoch:16 step:12677 [D loss: 0.570557, acc: 75.78%] [G loss: 1.800057]\n",
      "epoch:16 step:12678 [D loss: 0.754892, acc: 54.69%] [G loss: 1.623015]\n",
      "epoch:16 step:12679 [D loss: 0.698477, acc: 60.94%] [G loss: 1.537107]\n",
      "epoch:16 step:12680 [D loss: 1.028296, acc: 17.97%] [G loss: 1.593742]\n",
      "epoch:16 step:12681 [D loss: 0.733636, acc: 53.12%] [G loss: 1.559684]\n",
      "epoch:16 step:12682 [D loss: 0.735844, acc: 46.88%] [G loss: 1.754274]\n",
      "epoch:16 step:12683 [D loss: 0.403306, acc: 94.53%] [G loss: 2.206651]\n",
      "epoch:16 step:12684 [D loss: 0.835651, acc: 32.03%] [G loss: 1.584172]\n",
      "epoch:16 step:12685 [D loss: 0.485905, acc: 89.84%] [G loss: 2.137144]\n",
      "epoch:16 step:12686 [D loss: 0.560689, acc: 73.44%] [G loss: 1.512204]\n",
      "epoch:16 step:12687 [D loss: 0.357010, acc: 94.53%] [G loss: 1.672595]\n",
      "epoch:16 step:12688 [D loss: 0.632619, acc: 65.62%] [G loss: 1.643842]\n",
      "epoch:16 step:12689 [D loss: 0.625308, acc: 64.84%] [G loss: 1.948646]\n",
      "epoch:16 step:12690 [D loss: 0.464057, acc: 92.19%] [G loss: 1.893068]\n",
      "epoch:16 step:12691 [D loss: 0.691886, acc: 57.03%] [G loss: 1.953304]\n",
      "epoch:16 step:12692 [D loss: 0.880750, acc: 21.09%] [G loss: 1.933661]\n",
      "epoch:16 step:12693 [D loss: 0.860919, acc: 37.50%] [G loss: 1.565696]\n",
      "epoch:16 step:12694 [D loss: 0.719381, acc: 49.22%] [G loss: 1.779261]\n",
      "epoch:16 step:12695 [D loss: 0.881221, acc: 26.56%] [G loss: 1.696719]\n",
      "epoch:16 step:12696 [D loss: 0.636148, acc: 69.53%] [G loss: 2.392952]\n",
      "epoch:16 step:12697 [D loss: 0.485680, acc: 87.50%] [G loss: 2.301799]\n",
      "epoch:16 step:12698 [D loss: 0.558345, acc: 69.53%] [G loss: 2.269780]\n",
      "epoch:16 step:12699 [D loss: 0.653572, acc: 61.72%] [G loss: 1.839142]\n",
      "epoch:16 step:12700 [D loss: 0.813974, acc: 26.56%] [G loss: 1.656932]\n",
      "epoch:16 step:12701 [D loss: 1.074943, acc: 10.94%] [G loss: 1.452249]\n",
      "epoch:16 step:12702 [D loss: 0.770207, acc: 46.88%] [G loss: 1.787868]\n",
      "epoch:16 step:12703 [D loss: 0.673985, acc: 58.59%] [G loss: 1.877385]\n",
      "epoch:16 step:12704 [D loss: 0.495857, acc: 89.06%] [G loss: 2.112524]\n",
      "epoch:16 step:12705 [D loss: 0.439974, acc: 93.75%] [G loss: 1.969299]\n",
      "epoch:16 step:12706 [D loss: 0.942998, acc: 20.31%] [G loss: 1.337526]\n",
      "epoch:16 step:12707 [D loss: 0.532845, acc: 82.81%] [G loss: 1.931734]\n",
      "epoch:16 step:12708 [D loss: 0.604525, acc: 67.97%] [G loss: 1.888141]\n",
      "epoch:16 step:12709 [D loss: 0.563280, acc: 64.06%] [G loss: 2.608802]\n",
      "epoch:16 step:12710 [D loss: 0.486925, acc: 87.50%] [G loss: 2.079474]\n",
      "epoch:16 step:12711 [D loss: 0.495681, acc: 84.38%] [G loss: 1.999378]\n",
      "epoch:16 step:12712 [D loss: 0.583628, acc: 75.78%] [G loss: 2.067415]\n",
      "epoch:16 step:12713 [D loss: 0.745542, acc: 51.56%] [G loss: 1.593456]\n",
      "epoch:16 step:12714 [D loss: 0.614219, acc: 71.88%] [G loss: 1.973050]\n",
      "epoch:16 step:12715 [D loss: 0.429064, acc: 90.62%] [G loss: 1.885304]\n",
      "epoch:16 step:12716 [D loss: 0.697159, acc: 58.59%] [G loss: 1.534369]\n",
      "epoch:16 step:12717 [D loss: 0.813546, acc: 38.28%] [G loss: 1.772670]\n",
      "epoch:16 step:12718 [D loss: 0.524800, acc: 76.56%] [G loss: 2.260745]\n",
      "epoch:16 step:12719 [D loss: 0.669643, acc: 64.84%] [G loss: 2.157994]\n",
      "epoch:16 step:12720 [D loss: 0.801898, acc: 38.28%] [G loss: 1.558764]\n",
      "epoch:16 step:12721 [D loss: 0.593116, acc: 73.44%] [G loss: 2.106928]\n",
      "epoch:16 step:12722 [D loss: 1.132199, acc: 20.31%] [G loss: 1.472645]\n",
      "epoch:16 step:12723 [D loss: 0.754031, acc: 50.78%] [G loss: 1.653753]\n",
      "epoch:16 step:12724 [D loss: 0.680993, acc: 57.03%] [G loss: 1.976444]\n",
      "epoch:16 step:12725 [D loss: 0.471498, acc: 85.16%] [G loss: 2.059146]\n",
      "epoch:16 step:12726 [D loss: 0.613671, acc: 63.28%] [G loss: 1.957954]\n",
      "epoch:16 step:12727 [D loss: 0.618831, acc: 67.19%] [G loss: 1.608289]\n",
      "epoch:16 step:12728 [D loss: 0.584302, acc: 75.00%] [G loss: 1.749313]\n",
      "epoch:16 step:12729 [D loss: 0.591076, acc: 72.66%] [G loss: 1.739959]\n",
      "epoch:16 step:12730 [D loss: 0.936375, acc: 29.69%] [G loss: 1.840232]\n",
      "epoch:16 step:12731 [D loss: 0.645184, acc: 63.28%] [G loss: 1.930633]\n",
      "epoch:16 step:12732 [D loss: 0.910800, acc: 25.78%] [G loss: 1.535404]\n",
      "epoch:16 step:12733 [D loss: 0.695921, acc: 56.25%] [G loss: 1.781636]\n",
      "epoch:16 step:12734 [D loss: 0.515357, acc: 70.31%] [G loss: 1.843727]\n",
      "epoch:16 step:12735 [D loss: 0.827867, acc: 32.81%] [G loss: 1.600317]\n",
      "epoch:16 step:12736 [D loss: 0.811820, acc: 42.19%] [G loss: 1.544817]\n",
      "epoch:16 step:12737 [D loss: 0.518492, acc: 83.59%] [G loss: 2.022220]\n",
      "epoch:16 step:12738 [D loss: 0.445172, acc: 89.84%] [G loss: 1.870094]\n",
      "epoch:16 step:12739 [D loss: 0.784508, acc: 43.75%] [G loss: 1.533104]\n",
      "epoch:16 step:12740 [D loss: 0.541539, acc: 81.25%] [G loss: 1.913553]\n",
      "epoch:16 step:12741 [D loss: 0.694198, acc: 53.91%] [G loss: 1.563410]\n",
      "epoch:16 step:12742 [D loss: 0.662306, acc: 55.47%] [G loss: 1.845602]\n",
      "epoch:16 step:12743 [D loss: 0.808032, acc: 35.94%] [G loss: 1.744443]\n",
      "epoch:16 step:12744 [D loss: 0.685479, acc: 51.56%] [G loss: 1.727273]\n",
      "epoch:16 step:12745 [D loss: 0.445517, acc: 89.84%] [G loss: 1.940065]\n",
      "epoch:16 step:12746 [D loss: 0.358214, acc: 97.66%] [G loss: 2.115475]\n",
      "epoch:16 step:12747 [D loss: 0.633045, acc: 61.72%] [G loss: 2.193859]\n",
      "epoch:16 step:12748 [D loss: 0.565773, acc: 74.22%] [G loss: 2.149142]\n",
      "epoch:16 step:12749 [D loss: 0.821282, acc: 32.03%] [G loss: 1.747318]\n",
      "epoch:16 step:12750 [D loss: 0.685771, acc: 57.81%] [G loss: 1.547543]\n",
      "epoch:16 step:12751 [D loss: 0.563271, acc: 72.66%] [G loss: 2.323569]\n",
      "epoch:16 step:12752 [D loss: 0.572749, acc: 73.44%] [G loss: 1.965634]\n",
      "epoch:16 step:12753 [D loss: 0.890188, acc: 28.12%] [G loss: 1.583898]\n",
      "epoch:16 step:12754 [D loss: 0.704645, acc: 52.34%] [G loss: 1.587720]\n",
      "epoch:16 step:12755 [D loss: 0.889265, acc: 25.78%] [G loss: 1.560346]\n",
      "epoch:16 step:12756 [D loss: 0.638114, acc: 66.41%] [G loss: 1.658017]\n",
      "epoch:16 step:12757 [D loss: 0.722070, acc: 50.00%] [G loss: 1.490255]\n",
      "epoch:16 step:12758 [D loss: 0.526273, acc: 81.25%] [G loss: 2.369308]\n",
      "epoch:16 step:12759 [D loss: 0.598132, acc: 56.25%] [G loss: 2.185524]\n",
      "epoch:16 step:12760 [D loss: 0.822186, acc: 32.81%] [G loss: 1.770997]\n",
      "epoch:16 step:12761 [D loss: 0.743194, acc: 43.75%] [G loss: 1.557002]\n",
      "epoch:16 step:12762 [D loss: 0.909816, acc: 26.56%] [G loss: 1.412939]\n",
      "epoch:16 step:12763 [D loss: 0.727143, acc: 51.56%] [G loss: 1.593990]\n",
      "epoch:16 step:12764 [D loss: 0.573132, acc: 78.91%] [G loss: 2.058187]\n",
      "epoch:16 step:12765 [D loss: 0.720401, acc: 53.91%] [G loss: 1.884619]\n",
      "epoch:16 step:12766 [D loss: 1.046460, acc: 8.59%] [G loss: 1.474492]\n",
      "epoch:16 step:12767 [D loss: 0.583593, acc: 75.78%] [G loss: 1.903096]\n",
      "epoch:16 step:12768 [D loss: 0.570973, acc: 75.00%] [G loss: 2.003218]\n",
      "epoch:16 step:12769 [D loss: 0.687813, acc: 53.91%] [G loss: 1.622195]\n",
      "epoch:16 step:12770 [D loss: 0.655140, acc: 63.28%] [G loss: 1.635919]\n",
      "epoch:16 step:12771 [D loss: 0.766772, acc: 41.41%] [G loss: 1.984669]\n",
      "epoch:16 step:12772 [D loss: 0.728567, acc: 47.66%] [G loss: 1.445284]\n",
      "epoch:16 step:12773 [D loss: 0.928902, acc: 36.72%] [G loss: 1.656593]\n",
      "epoch:16 step:12774 [D loss: 0.406256, acc: 92.97%] [G loss: 2.039120]\n",
      "epoch:16 step:12775 [D loss: 0.574793, acc: 76.56%] [G loss: 1.884024]\n",
      "epoch:16 step:12776 [D loss: 0.694430, acc: 55.47%] [G loss: 2.026803]\n",
      "epoch:16 step:12777 [D loss: 0.596772, acc: 69.53%] [G loss: 1.733583]\n",
      "epoch:16 step:12778 [D loss: 0.486916, acc: 92.97%] [G loss: 1.662997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12779 [D loss: 0.503598, acc: 83.59%] [G loss: 1.976660]\n",
      "epoch:16 step:12780 [D loss: 0.711392, acc: 52.34%] [G loss: 1.524226]\n",
      "epoch:16 step:12781 [D loss: 0.516982, acc: 89.06%] [G loss: 1.540973]\n",
      "epoch:16 step:12782 [D loss: 0.666647, acc: 59.38%] [G loss: 1.749735]\n",
      "epoch:16 step:12783 [D loss: 0.715006, acc: 53.12%] [G loss: 1.515747]\n",
      "epoch:16 step:12784 [D loss: 0.583425, acc: 80.47%] [G loss: 1.723147]\n",
      "epoch:16 step:12785 [D loss: 0.620762, acc: 64.84%] [G loss: 1.540866]\n",
      "epoch:16 step:12786 [D loss: 0.468287, acc: 90.62%] [G loss: 1.679523]\n",
      "epoch:16 step:12787 [D loss: 0.868421, acc: 29.69%] [G loss: 1.590812]\n",
      "epoch:16 step:12788 [D loss: 0.509530, acc: 84.38%] [G loss: 1.771876]\n",
      "epoch:16 step:12789 [D loss: 0.923050, acc: 21.88%] [G loss: 1.542294]\n",
      "epoch:16 step:12790 [D loss: 0.670347, acc: 56.25%] [G loss: 1.993160]\n",
      "epoch:16 step:12791 [D loss: 0.737259, acc: 46.88%] [G loss: 1.649857]\n",
      "epoch:16 step:12792 [D loss: 0.372244, acc: 89.06%] [G loss: 2.063743]\n",
      "epoch:16 step:12793 [D loss: 0.858230, acc: 37.50%] [G loss: 1.438134]\n",
      "epoch:16 step:12794 [D loss: 0.669480, acc: 57.81%] [G loss: 2.019867]\n",
      "epoch:16 step:12795 [D loss: 0.542951, acc: 72.66%] [G loss: 1.866547]\n",
      "epoch:16 step:12796 [D loss: 0.648491, acc: 60.16%] [G loss: 1.637005]\n",
      "epoch:16 step:12797 [D loss: 0.614682, acc: 66.41%] [G loss: 1.862098]\n",
      "epoch:16 step:12798 [D loss: 0.509963, acc: 85.94%] [G loss: 1.675122]\n",
      "epoch:16 step:12799 [D loss: 0.656247, acc: 57.03%] [G loss: 1.488719]\n",
      "epoch:16 step:12800 [D loss: 0.500576, acc: 86.72%] [G loss: 1.888656]\n",
      "epoch:16 step:12801 [D loss: 0.443746, acc: 89.84%] [G loss: 1.978661]\n",
      "epoch:16 step:12802 [D loss: 0.668074, acc: 60.16%] [G loss: 2.286963]\n",
      "epoch:16 step:12803 [D loss: 0.506175, acc: 87.50%] [G loss: 1.876839]\n",
      "epoch:16 step:12804 [D loss: 0.746826, acc: 45.31%] [G loss: 1.852957]\n",
      "epoch:16 step:12805 [D loss: 0.587301, acc: 76.56%] [G loss: 1.935934]\n",
      "epoch:16 step:12806 [D loss: 0.452647, acc: 87.50%] [G loss: 1.744715]\n",
      "epoch:16 step:12807 [D loss: 0.767318, acc: 49.22%] [G loss: 1.791173]\n",
      "epoch:16 step:12808 [D loss: 0.702180, acc: 50.78%] [G loss: 1.611326]\n",
      "epoch:16 step:12809 [D loss: 0.554822, acc: 80.47%] [G loss: 1.909668]\n",
      "epoch:16 step:12810 [D loss: 0.472365, acc: 89.06%] [G loss: 1.886634]\n",
      "epoch:16 step:12811 [D loss: 1.019215, acc: 37.50%] [G loss: 1.473969]\n",
      "epoch:16 step:12812 [D loss: 0.560519, acc: 68.75%] [G loss: 2.177782]\n",
      "epoch:16 step:12813 [D loss: 0.684940, acc: 57.81%] [G loss: 1.554802]\n",
      "epoch:16 step:12814 [D loss: 0.854813, acc: 37.50%] [G loss: 1.921740]\n",
      "epoch:16 step:12815 [D loss: 0.528044, acc: 85.16%] [G loss: 2.058224]\n",
      "epoch:16 step:12816 [D loss: 0.964702, acc: 26.56%] [G loss: 1.600495]\n",
      "epoch:16 step:12817 [D loss: 0.617106, acc: 71.88%] [G loss: 2.052632]\n",
      "epoch:16 step:12818 [D loss: 0.458673, acc: 83.59%] [G loss: 2.513249]\n",
      "epoch:16 step:12819 [D loss: 0.545725, acc: 75.00%] [G loss: 2.139762]\n",
      "epoch:16 step:12820 [D loss: 0.387902, acc: 92.97%] [G loss: 2.011812]\n",
      "epoch:16 step:12821 [D loss: 0.626676, acc: 66.41%] [G loss: 2.062319]\n",
      "epoch:16 step:12822 [D loss: 0.358658, acc: 95.31%] [G loss: 2.056525]\n",
      "epoch:16 step:12823 [D loss: 0.557232, acc: 78.91%] [G loss: 1.887036]\n",
      "epoch:16 step:12824 [D loss: 0.556998, acc: 77.34%] [G loss: 1.870868]\n",
      "epoch:16 step:12825 [D loss: 0.535262, acc: 85.94%] [G loss: 1.837039]\n",
      "epoch:16 step:12826 [D loss: 0.662605, acc: 57.81%] [G loss: 1.766606]\n",
      "epoch:16 step:12827 [D loss: 1.243646, acc: 3.91%] [G loss: 1.095028]\n",
      "epoch:16 step:12828 [D loss: 0.625898, acc: 60.94%] [G loss: 2.052229]\n",
      "epoch:16 step:12829 [D loss: 0.711827, acc: 48.44%] [G loss: 1.399035]\n",
      "epoch:16 step:12830 [D loss: 0.486668, acc: 88.28%] [G loss: 1.916878]\n",
      "epoch:16 step:12831 [D loss: 0.564836, acc: 67.19%] [G loss: 1.417846]\n",
      "epoch:16 step:12832 [D loss: 0.643294, acc: 57.81%] [G loss: 1.997411]\n",
      "epoch:16 step:12833 [D loss: 0.998666, acc: 46.09%] [G loss: 1.626864]\n",
      "epoch:16 step:12834 [D loss: 0.702589, acc: 60.16%] [G loss: 1.854800]\n",
      "epoch:16 step:12835 [D loss: 0.916264, acc: 39.84%] [G loss: 1.462179]\n",
      "epoch:16 step:12836 [D loss: 0.906549, acc: 41.41%] [G loss: 1.705323]\n",
      "epoch:16 step:12837 [D loss: 0.512997, acc: 87.50%] [G loss: 1.780797]\n",
      "epoch:16 step:12838 [D loss: 0.563902, acc: 76.56%] [G loss: 1.966087]\n",
      "epoch:16 step:12839 [D loss: 0.563833, acc: 71.88%] [G loss: 1.981019]\n",
      "epoch:16 step:12840 [D loss: 0.529678, acc: 84.38%] [G loss: 2.117577]\n",
      "epoch:16 step:12841 [D loss: 0.410239, acc: 92.19%] [G loss: 1.971392]\n",
      "epoch:16 step:12842 [D loss: 0.715685, acc: 51.56%] [G loss: 1.831208]\n",
      "epoch:16 step:12843 [D loss: 0.403718, acc: 92.19%] [G loss: 1.972566]\n",
      "epoch:16 step:12844 [D loss: 0.559346, acc: 79.69%] [G loss: 1.967598]\n",
      "epoch:16 step:12845 [D loss: 0.659509, acc: 60.16%] [G loss: 1.842446]\n",
      "epoch:16 step:12846 [D loss: 0.691206, acc: 60.16%] [G loss: 1.958049]\n",
      "epoch:16 step:12847 [D loss: 0.459069, acc: 71.88%] [G loss: 1.666132]\n",
      "epoch:16 step:12848 [D loss: 0.400111, acc: 92.97%] [G loss: 1.803427]\n",
      "epoch:16 step:12849 [D loss: 0.939295, acc: 38.28%] [G loss: 1.641431]\n",
      "epoch:16 step:12850 [D loss: 0.705531, acc: 51.56%] [G loss: 2.060063]\n",
      "epoch:16 step:12851 [D loss: 1.109585, acc: 4.69%] [G loss: 1.569600]\n",
      "epoch:16 step:12852 [D loss: 0.466613, acc: 80.47%] [G loss: 1.815067]\n",
      "epoch:16 step:12853 [D loss: 0.670697, acc: 56.25%] [G loss: 1.462527]\n",
      "epoch:16 step:12854 [D loss: 0.478228, acc: 89.06%] [G loss: 2.225893]\n",
      "epoch:16 step:12855 [D loss: 0.704940, acc: 51.56%] [G loss: 1.384457]\n",
      "epoch:16 step:12856 [D loss: 0.885136, acc: 31.25%] [G loss: 1.568751]\n",
      "epoch:16 step:12857 [D loss: 0.519952, acc: 75.00%] [G loss: 1.605630]\n",
      "epoch:16 step:12858 [D loss: 0.751041, acc: 42.97%] [G loss: 1.811086]\n",
      "epoch:16 step:12859 [D loss: 0.723778, acc: 49.22%] [G loss: 1.580558]\n",
      "epoch:16 step:12860 [D loss: 0.285002, acc: 97.66%] [G loss: 2.126774]\n",
      "epoch:16 step:12861 [D loss: 0.540214, acc: 82.81%] [G loss: 1.814717]\n",
      "epoch:16 step:12862 [D loss: 0.702764, acc: 47.66%] [G loss: 1.494083]\n",
      "epoch:16 step:12863 [D loss: 0.846080, acc: 33.59%] [G loss: 1.381413]\n",
      "epoch:16 step:12864 [D loss: 0.546604, acc: 80.47%] [G loss: 1.854931]\n",
      "epoch:16 step:12865 [D loss: 0.639704, acc: 61.72%] [G loss: 1.850903]\n",
      "epoch:16 step:12866 [D loss: 0.573978, acc: 69.53%] [G loss: 1.703155]\n",
      "epoch:16 step:12867 [D loss: 0.449289, acc: 89.06%] [G loss: 1.762331]\n",
      "epoch:16 step:12868 [D loss: 0.446060, acc: 82.81%] [G loss: 2.028180]\n",
      "epoch:16 step:12869 [D loss: 1.073197, acc: 17.19%] [G loss: 1.339958]\n",
      "epoch:16 step:12870 [D loss: 0.746481, acc: 50.78%] [G loss: 1.992792]\n",
      "epoch:16 step:12871 [D loss: 0.577935, acc: 60.94%] [G loss: 1.785304]\n",
      "epoch:16 step:12872 [D loss: 0.552111, acc: 79.69%] [G loss: 1.749651]\n",
      "epoch:16 step:12873 [D loss: 0.733840, acc: 48.44%] [G loss: 1.943685]\n",
      "epoch:16 step:12874 [D loss: 0.648253, acc: 57.81%] [G loss: 1.185191]\n",
      "epoch:16 step:12875 [D loss: 0.540048, acc: 73.44%] [G loss: 1.997764]\n",
      "epoch:16 step:12876 [D loss: 0.319554, acc: 99.22%] [G loss: 2.192597]\n",
      "epoch:16 step:12877 [D loss: 0.691092, acc: 53.12%] [G loss: 1.899365]\n",
      "epoch:16 step:12878 [D loss: 0.489358, acc: 91.41%] [G loss: 1.885082]\n",
      "epoch:16 step:12879 [D loss: 0.806721, acc: 36.72%] [G loss: 1.494192]\n",
      "epoch:16 step:12880 [D loss: 0.834736, acc: 40.62%] [G loss: 1.632675]\n",
      "epoch:16 step:12881 [D loss: 0.813133, acc: 32.81%] [G loss: 1.740260]\n",
      "epoch:16 step:12882 [D loss: 0.462665, acc: 82.81%] [G loss: 1.735816]\n",
      "epoch:16 step:12883 [D loss: 0.619331, acc: 67.97%] [G loss: 2.139014]\n",
      "epoch:16 step:12884 [D loss: 0.464042, acc: 81.25%] [G loss: 1.672535]\n",
      "epoch:16 step:12885 [D loss: 0.510299, acc: 85.16%] [G loss: 1.643667]\n",
      "epoch:16 step:12886 [D loss: 0.519499, acc: 81.25%] [G loss: 2.124774]\n",
      "epoch:16 step:12887 [D loss: 0.812328, acc: 39.84%] [G loss: 1.763349]\n",
      "epoch:16 step:12888 [D loss: 0.476264, acc: 79.69%] [G loss: 1.871717]\n",
      "epoch:16 step:12889 [D loss: 0.547149, acc: 81.25%] [G loss: 1.888100]\n",
      "epoch:16 step:12890 [D loss: 0.393127, acc: 93.75%] [G loss: 2.120379]\n",
      "epoch:16 step:12891 [D loss: 0.461730, acc: 90.62%] [G loss: 1.691369]\n",
      "epoch:16 step:12892 [D loss: 0.415996, acc: 94.53%] [G loss: 1.981605]\n",
      "epoch:16 step:12893 [D loss: 0.830059, acc: 34.38%] [G loss: 1.639194]\n",
      "epoch:16 step:12894 [D loss: 0.819673, acc: 42.97%] [G loss: 1.980777]\n",
      "epoch:16 step:12895 [D loss: 0.670750, acc: 56.25%] [G loss: 2.216626]\n",
      "epoch:16 step:12896 [D loss: 0.561650, acc: 76.56%] [G loss: 2.043349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12897 [D loss: 0.618260, acc: 67.19%] [G loss: 1.780044]\n",
      "epoch:16 step:12898 [D loss: 0.484279, acc: 88.28%] [G loss: 1.659056]\n",
      "epoch:16 step:12899 [D loss: 0.331224, acc: 89.06%] [G loss: 1.725937]\n",
      "epoch:16 step:12900 [D loss: 0.685467, acc: 59.38%] [G loss: 1.887390]\n",
      "epoch:16 step:12901 [D loss: 0.750279, acc: 47.66%] [G loss: 2.054461]\n",
      "epoch:16 step:12902 [D loss: 0.207523, acc: 97.66%] [G loss: 1.799510]\n",
      "epoch:16 step:12903 [D loss: 0.397362, acc: 94.53%] [G loss: 2.437662]\n",
      "epoch:16 step:12904 [D loss: 0.549364, acc: 82.03%] [G loss: 1.707589]\n",
      "epoch:16 step:12905 [D loss: 0.629662, acc: 65.62%] [G loss: 1.675524]\n",
      "epoch:16 step:12906 [D loss: 0.459828, acc: 82.81%] [G loss: 1.801002]\n",
      "epoch:16 step:12907 [D loss: 1.009324, acc: 17.19%] [G loss: 2.122095]\n",
      "epoch:16 step:12908 [D loss: 0.784255, acc: 43.75%] [G loss: 2.262120]\n",
      "epoch:16 step:12909 [D loss: 0.720353, acc: 53.91%] [G loss: 1.872451]\n",
      "epoch:16 step:12910 [D loss: 0.425192, acc: 74.22%] [G loss: 1.615570]\n",
      "epoch:16 step:12911 [D loss: 0.642736, acc: 62.50%] [G loss: 1.939230]\n",
      "epoch:16 step:12912 [D loss: 0.670590, acc: 55.47%] [G loss: 1.763058]\n",
      "epoch:16 step:12913 [D loss: 0.702502, acc: 58.59%] [G loss: 1.684072]\n",
      "epoch:16 step:12914 [D loss: 0.821211, acc: 36.72%] [G loss: 2.016364]\n",
      "epoch:16 step:12915 [D loss: 0.552759, acc: 73.44%] [G loss: 1.651145]\n",
      "epoch:16 step:12916 [D loss: 0.657345, acc: 55.47%] [G loss: 2.829865]\n",
      "epoch:16 step:12917 [D loss: 0.789101, acc: 48.44%] [G loss: 2.195717]\n",
      "epoch:16 step:12918 [D loss: 0.481135, acc: 91.41%] [G loss: 1.917703]\n",
      "epoch:16 step:12919 [D loss: 0.803419, acc: 35.94%] [G loss: 1.511139]\n",
      "epoch:16 step:12920 [D loss: 1.291966, acc: 23.44%] [G loss: 1.564380]\n",
      "epoch:16 step:12921 [D loss: 0.494418, acc: 82.03%] [G loss: 1.703669]\n",
      "epoch:16 step:12922 [D loss: 0.583659, acc: 71.09%] [G loss: 1.737862]\n",
      "epoch:16 step:12923 [D loss: 0.464686, acc: 77.34%] [G loss: 1.691183]\n",
      "epoch:16 step:12924 [D loss: 0.650778, acc: 67.97%] [G loss: 1.821241]\n",
      "epoch:16 step:12925 [D loss: 0.579841, acc: 76.56%] [G loss: 1.941850]\n",
      "epoch:16 step:12926 [D loss: 0.598904, acc: 75.78%] [G loss: 2.008855]\n",
      "epoch:16 step:12927 [D loss: 0.968373, acc: 32.81%] [G loss: 1.539806]\n",
      "epoch:16 step:12928 [D loss: 0.736592, acc: 48.44%] [G loss: 1.743385]\n",
      "epoch:16 step:12929 [D loss: 0.610474, acc: 65.62%] [G loss: 2.088528]\n",
      "epoch:16 step:12930 [D loss: 0.836895, acc: 36.72%] [G loss: 1.567309]\n",
      "epoch:16 step:12931 [D loss: 0.672177, acc: 57.81%] [G loss: 1.758311]\n",
      "epoch:16 step:12932 [D loss: 0.888575, acc: 25.78%] [G loss: 2.007177]\n",
      "epoch:16 step:12933 [D loss: 0.870436, acc: 39.06%] [G loss: 1.171334]\n",
      "epoch:16 step:12934 [D loss: 0.422075, acc: 95.31%] [G loss: 2.281561]\n",
      "epoch:16 step:12935 [D loss: 0.463981, acc: 73.44%] [G loss: 1.714955]\n",
      "epoch:16 step:12936 [D loss: 0.669656, acc: 57.03%] [G loss: 1.675833]\n",
      "epoch:16 step:12937 [D loss: 0.775575, acc: 50.00%] [G loss: 1.749772]\n",
      "epoch:16 step:12938 [D loss: 0.580851, acc: 68.75%] [G loss: 1.810136]\n",
      "epoch:16 step:12939 [D loss: 0.749449, acc: 52.34%] [G loss: 1.749907]\n",
      "epoch:16 step:12940 [D loss: 0.549585, acc: 67.97%] [G loss: 1.425234]\n",
      "epoch:16 step:12941 [D loss: 0.573144, acc: 73.44%] [G loss: 1.829609]\n",
      "epoch:16 step:12942 [D loss: 0.862190, acc: 25.00%] [G loss: 1.444938]\n",
      "epoch:16 step:12943 [D loss: 0.622084, acc: 67.19%] [G loss: 1.746089]\n",
      "epoch:16 step:12944 [D loss: 0.461598, acc: 78.91%] [G loss: 1.573652]\n",
      "epoch:16 step:12945 [D loss: 0.563191, acc: 78.91%] [G loss: 1.569627]\n",
      "epoch:16 step:12946 [D loss: 0.679138, acc: 58.59%] [G loss: 1.826066]\n",
      "epoch:16 step:12947 [D loss: 0.461087, acc: 94.53%] [G loss: 1.932942]\n",
      "epoch:16 step:12948 [D loss: 0.607415, acc: 76.56%] [G loss: 1.726837]\n",
      "epoch:16 step:12949 [D loss: 0.500311, acc: 85.94%] [G loss: 2.025020]\n",
      "epoch:16 step:12950 [D loss: 0.503222, acc: 80.47%] [G loss: 1.795569]\n",
      "epoch:16 step:12951 [D loss: 0.727968, acc: 56.25%] [G loss: 1.559546]\n",
      "epoch:16 step:12952 [D loss: 0.594430, acc: 72.66%] [G loss: 1.603705]\n",
      "epoch:16 step:12953 [D loss: 0.636460, acc: 58.59%] [G loss: 1.832828]\n",
      "epoch:16 step:12954 [D loss: 0.545324, acc: 85.16%] [G loss: 1.767665]\n",
      "epoch:16 step:12955 [D loss: 0.571928, acc: 78.91%] [G loss: 1.770633]\n",
      "epoch:16 step:12956 [D loss: 0.615047, acc: 63.28%] [G loss: 1.560511]\n",
      "epoch:16 step:12957 [D loss: 0.565358, acc: 75.78%] [G loss: 1.794588]\n",
      "epoch:16 step:12958 [D loss: 0.589073, acc: 70.31%] [G loss: 1.794832]\n",
      "epoch:16 step:12959 [D loss: 0.607401, acc: 66.41%] [G loss: 1.930293]\n",
      "epoch:16 step:12960 [D loss: 0.479738, acc: 85.94%] [G loss: 2.124264]\n",
      "epoch:16 step:12961 [D loss: 0.997597, acc: 16.41%] [G loss: 1.228832]\n",
      "epoch:16 step:12962 [D loss: 0.422200, acc: 89.84%] [G loss: 1.995916]\n",
      "epoch:16 step:12963 [D loss: 0.725478, acc: 46.88%] [G loss: 1.714666]\n",
      "epoch:16 step:12964 [D loss: 0.595365, acc: 75.78%] [G loss: 1.861855]\n",
      "epoch:16 step:12965 [D loss: 0.657589, acc: 59.38%] [G loss: 1.779994]\n",
      "epoch:16 step:12966 [D loss: 0.555052, acc: 67.97%] [G loss: 1.618948]\n",
      "epoch:16 step:12967 [D loss: 0.992738, acc: 19.53%] [G loss: 1.680574]\n",
      "epoch:16 step:12968 [D loss: 0.663491, acc: 53.91%] [G loss: 1.879926]\n",
      "epoch:16 step:12969 [D loss: 0.743964, acc: 49.22%] [G loss: 1.818452]\n",
      "epoch:16 step:12970 [D loss: 0.872509, acc: 24.22%] [G loss: 1.654379]\n",
      "epoch:16 step:12971 [D loss: 0.719895, acc: 53.91%] [G loss: 1.921180]\n",
      "epoch:16 step:12972 [D loss: 0.605034, acc: 64.84%] [G loss: 2.008784]\n",
      "epoch:16 step:12973 [D loss: 0.515150, acc: 82.81%] [G loss: 1.836114]\n",
      "epoch:16 step:12974 [D loss: 0.381077, acc: 98.44%] [G loss: 2.371225]\n",
      "epoch:16 step:12975 [D loss: 0.618425, acc: 64.84%] [G loss: 1.553420]\n",
      "epoch:16 step:12976 [D loss: 0.781783, acc: 33.59%] [G loss: 1.599124]\n",
      "epoch:16 step:12977 [D loss: 0.878987, acc: 17.19%] [G loss: 1.552752]\n",
      "epoch:16 step:12978 [D loss: 0.857965, acc: 28.12%] [G loss: 1.989904]\n",
      "epoch:16 step:12979 [D loss: 0.558112, acc: 65.62%] [G loss: 1.980686]\n",
      "epoch:16 step:12980 [D loss: 0.516134, acc: 85.16%] [G loss: 1.804226]\n",
      "epoch:16 step:12981 [D loss: 0.497224, acc: 86.72%] [G loss: 1.903212]\n",
      "epoch:16 step:12982 [D loss: 0.750600, acc: 46.09%] [G loss: 2.056230]\n",
      "epoch:16 step:12983 [D loss: 0.763340, acc: 45.31%] [G loss: 1.752060]\n",
      "epoch:16 step:12984 [D loss: 0.569439, acc: 67.97%] [G loss: 1.511631]\n",
      "epoch:16 step:12985 [D loss: 0.686510, acc: 55.47%] [G loss: 1.598056]\n",
      "epoch:16 step:12986 [D loss: 0.649382, acc: 61.72%] [G loss: 2.028223]\n",
      "epoch:16 step:12987 [D loss: 0.826198, acc: 31.25%] [G loss: 1.451442]\n",
      "epoch:16 step:12988 [D loss: 0.858997, acc: 31.25%] [G loss: 1.387105]\n",
      "epoch:16 step:12989 [D loss: 0.585207, acc: 76.56%] [G loss: 1.802229]\n",
      "epoch:16 step:12990 [D loss: 0.769353, acc: 45.31%] [G loss: 1.756433]\n",
      "epoch:16 step:12991 [D loss: 0.669349, acc: 60.16%] [G loss: 1.779272]\n",
      "epoch:16 step:12992 [D loss: 0.433478, acc: 94.53%] [G loss: 2.009364]\n",
      "epoch:16 step:12993 [D loss: 0.653647, acc: 62.50%] [G loss: 1.670500]\n",
      "epoch:16 step:12994 [D loss: 0.701519, acc: 52.34%] [G loss: 1.840217]\n",
      "epoch:16 step:12995 [D loss: 0.853130, acc: 18.75%] [G loss: 2.108131]\n",
      "epoch:16 step:12996 [D loss: 0.834638, acc: 41.41%] [G loss: 1.738837]\n",
      "epoch:16 step:12997 [D loss: 0.517034, acc: 76.56%] [G loss: 1.764407]\n",
      "epoch:16 step:12998 [D loss: 0.523419, acc: 81.25%] [G loss: 1.848323]\n",
      "epoch:16 step:12999 [D loss: 0.536278, acc: 82.81%] [G loss: 1.732122]\n",
      "epoch:16 step:13000 [D loss: 0.330277, acc: 96.09%] [G loss: 2.342508]\n",
      "epoch:16 step:13001 [D loss: 0.920713, acc: 21.88%] [G loss: 1.285054]\n",
      "epoch:16 step:13002 [D loss: 0.680470, acc: 56.25%] [G loss: 1.671922]\n",
      "epoch:16 step:13003 [D loss: 0.761306, acc: 41.41%] [G loss: 1.366344]\n",
      "epoch:16 step:13004 [D loss: 0.610710, acc: 64.06%] [G loss: 1.832386]\n",
      "epoch:16 step:13005 [D loss: 0.638809, acc: 60.16%] [G loss: 1.830883]\n",
      "epoch:16 step:13006 [D loss: 0.708491, acc: 44.53%] [G loss: 1.635301]\n",
      "epoch:16 step:13007 [D loss: 0.731021, acc: 49.22%] [G loss: 2.031170]\n",
      "epoch:16 step:13008 [D loss: 0.614685, acc: 65.62%] [G loss: 1.687530]\n",
      "epoch:16 step:13009 [D loss: 0.723804, acc: 49.22%] [G loss: 2.011486]\n",
      "epoch:16 step:13010 [D loss: 0.812854, acc: 39.06%] [G loss: 1.730146]\n",
      "epoch:16 step:13011 [D loss: 0.665643, acc: 57.81%] [G loss: 2.081287]\n",
      "epoch:16 step:13012 [D loss: 0.563911, acc: 82.03%] [G loss: 1.852993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13013 [D loss: 0.712548, acc: 50.00%] [G loss: 1.787784]\n",
      "epoch:16 step:13014 [D loss: 0.647961, acc: 57.81%] [G loss: 1.753338]\n",
      "epoch:16 step:13015 [D loss: 0.895972, acc: 17.97%] [G loss: 1.226366]\n",
      "epoch:16 step:13016 [D loss: 0.532681, acc: 78.91%] [G loss: 2.177900]\n",
      "epoch:16 step:13017 [D loss: 0.525441, acc: 68.75%] [G loss: 2.459789]\n",
      "epoch:16 step:13018 [D loss: 0.801615, acc: 43.75%] [G loss: 1.638223]\n",
      "epoch:16 step:13019 [D loss: 0.634479, acc: 71.09%] [G loss: 2.022875]\n",
      "epoch:16 step:13020 [D loss: 0.618719, acc: 65.62%] [G loss: 2.077705]\n",
      "epoch:16 step:13021 [D loss: 0.849046, acc: 33.59%] [G loss: 1.487129]\n",
      "epoch:16 step:13022 [D loss: 0.556526, acc: 75.00%] [G loss: 2.313365]\n",
      "epoch:16 step:13023 [D loss: 0.733810, acc: 52.34%] [G loss: 1.695850]\n",
      "epoch:16 step:13024 [D loss: 0.785681, acc: 43.75%] [G loss: 1.323172]\n",
      "epoch:16 step:13025 [D loss: 0.628051, acc: 67.19%] [G loss: 1.960162]\n",
      "epoch:16 step:13026 [D loss: 0.551344, acc: 65.62%] [G loss: 1.963271]\n",
      "epoch:16 step:13027 [D loss: 0.700181, acc: 49.22%] [G loss: 1.963793]\n",
      "epoch:16 step:13028 [D loss: 0.464045, acc: 89.06%] [G loss: 1.694110]\n",
      "epoch:16 step:13029 [D loss: 0.968688, acc: 14.84%] [G loss: 1.584332]\n",
      "epoch:16 step:13030 [D loss: 0.449636, acc: 93.75%] [G loss: 2.064698]\n",
      "epoch:16 step:13031 [D loss: 0.694985, acc: 54.69%] [G loss: 1.906449]\n",
      "epoch:16 step:13032 [D loss: 0.560896, acc: 78.12%] [G loss: 1.609291]\n",
      "epoch:16 step:13033 [D loss: 0.462793, acc: 92.97%] [G loss: 2.021645]\n",
      "epoch:16 step:13034 [D loss: 0.655353, acc: 63.28%] [G loss: 1.694953]\n",
      "epoch:16 step:13035 [D loss: 0.682361, acc: 57.03%] [G loss: 1.459521]\n",
      "epoch:16 step:13036 [D loss: 0.760548, acc: 39.06%] [G loss: 1.768117]\n",
      "epoch:16 step:13037 [D loss: 0.586058, acc: 79.69%] [G loss: 1.753239]\n",
      "epoch:16 step:13038 [D loss: 0.695796, acc: 57.03%] [G loss: 1.777274]\n",
      "epoch:16 step:13039 [D loss: 0.516320, acc: 80.47%] [G loss: 1.988735]\n",
      "epoch:16 step:13040 [D loss: 0.597247, acc: 68.75%] [G loss: 1.827700]\n",
      "epoch:16 step:13041 [D loss: 0.529114, acc: 75.78%] [G loss: 2.291738]\n",
      "epoch:16 step:13042 [D loss: 0.694510, acc: 54.69%] [G loss: 1.816035]\n",
      "epoch:16 step:13043 [D loss: 0.551913, acc: 73.44%] [G loss: 2.066095]\n",
      "epoch:16 step:13044 [D loss: 0.495117, acc: 89.06%] [G loss: 1.829601]\n",
      "epoch:16 step:13045 [D loss: 0.453606, acc: 83.59%] [G loss: 1.944660]\n",
      "epoch:16 step:13046 [D loss: 0.664311, acc: 61.72%] [G loss: 2.088429]\n",
      "epoch:16 step:13047 [D loss: 0.282744, acc: 98.44%] [G loss: 2.142475]\n",
      "epoch:16 step:13048 [D loss: 0.815516, acc: 32.03%] [G loss: 1.463439]\n",
      "epoch:16 step:13049 [D loss: 1.117353, acc: 15.62%] [G loss: 1.996150]\n",
      "epoch:16 step:13050 [D loss: 0.412144, acc: 91.41%] [G loss: 2.327321]\n",
      "epoch:16 step:13051 [D loss: 0.591907, acc: 69.53%] [G loss: 1.958531]\n",
      "epoch:16 step:13052 [D loss: 0.665032, acc: 55.47%] [G loss: 2.369148]\n",
      "epoch:16 step:13053 [D loss: 0.629515, acc: 58.59%] [G loss: 1.984113]\n",
      "epoch:16 step:13054 [D loss: 0.683089, acc: 58.59%] [G loss: 2.016178]\n",
      "epoch:16 step:13055 [D loss: 0.466462, acc: 89.84%] [G loss: 1.927328]\n",
      "epoch:16 step:13056 [D loss: 0.754741, acc: 45.31%] [G loss: 1.922879]\n",
      "epoch:16 step:13057 [D loss: 0.406860, acc: 89.84%] [G loss: 2.068017]\n",
      "epoch:16 step:13058 [D loss: 0.511651, acc: 76.56%] [G loss: 2.327364]\n",
      "epoch:16 step:13059 [D loss: 0.595637, acc: 69.53%] [G loss: 1.877325]\n",
      "epoch:16 step:13060 [D loss: 0.708409, acc: 50.78%] [G loss: 2.064871]\n",
      "epoch:16 step:13061 [D loss: 0.743864, acc: 48.44%] [G loss: 1.863045]\n",
      "epoch:16 step:13062 [D loss: 0.765590, acc: 41.41%] [G loss: 1.349226]\n",
      "epoch:16 step:13063 [D loss: 0.787344, acc: 38.28%] [G loss: 1.525628]\n",
      "epoch:16 step:13064 [D loss: 0.650877, acc: 62.50%] [G loss: 1.769485]\n",
      "epoch:16 step:13065 [D loss: 0.670209, acc: 66.41%] [G loss: 2.268857]\n",
      "epoch:16 step:13066 [D loss: 0.471203, acc: 85.94%] [G loss: 1.895683]\n",
      "epoch:16 step:13067 [D loss: 0.755801, acc: 46.09%] [G loss: 2.140526]\n",
      "epoch:16 step:13068 [D loss: 0.540545, acc: 79.69%] [G loss: 1.986299]\n",
      "epoch:16 step:13069 [D loss: 0.493738, acc: 86.72%] [G loss: 2.140974]\n",
      "epoch:16 step:13070 [D loss: 0.841735, acc: 29.69%] [G loss: 1.809387]\n",
      "epoch:16 step:13071 [D loss: 0.783743, acc: 42.97%] [G loss: 1.831845]\n",
      "epoch:16 step:13072 [D loss: 0.591216, acc: 67.97%] [G loss: 2.128161]\n",
      "epoch:16 step:13073 [D loss: 0.389772, acc: 93.75%] [G loss: 2.563514]\n",
      "epoch:16 step:13074 [D loss: 0.422709, acc: 89.84%] [G loss: 2.241540]\n",
      "epoch:16 step:13075 [D loss: 0.374358, acc: 90.62%] [G loss: 2.632531]\n",
      "epoch:16 step:13076 [D loss: 0.759583, acc: 42.97%] [G loss: 1.938308]\n",
      "epoch:16 step:13077 [D loss: 0.353294, acc: 96.88%] [G loss: 1.854177]\n",
      "epoch:16 step:13078 [D loss: 0.602208, acc: 64.84%] [G loss: 2.216317]\n",
      "epoch:16 step:13079 [D loss: 0.581984, acc: 77.34%] [G loss: 1.907011]\n",
      "epoch:16 step:13080 [D loss: 0.643538, acc: 61.72%] [G loss: 1.518279]\n",
      "epoch:16 step:13081 [D loss: 0.736338, acc: 49.22%] [G loss: 1.399578]\n",
      "epoch:16 step:13082 [D loss: 0.710185, acc: 56.25%] [G loss: 2.101626]\n",
      "epoch:16 step:13083 [D loss: 0.436043, acc: 94.53%] [G loss: 1.859180]\n",
      "epoch:16 step:13084 [D loss: 0.794563, acc: 39.84%] [G loss: 1.815530]\n",
      "epoch:16 step:13085 [D loss: 0.828113, acc: 33.59%] [G loss: 1.821916]\n",
      "epoch:16 step:13086 [D loss: 0.667763, acc: 60.16%] [G loss: 2.110940]\n",
      "epoch:16 step:13087 [D loss: 0.701124, acc: 54.69%] [G loss: 1.934862]\n",
      "epoch:16 step:13088 [D loss: 0.656617, acc: 64.06%] [G loss: 2.019584]\n",
      "epoch:16 step:13089 [D loss: 0.648268, acc: 55.47%] [G loss: 1.786435]\n",
      "epoch:16 step:13090 [D loss: 0.601273, acc: 61.72%] [G loss: 1.948780]\n",
      "epoch:16 step:13091 [D loss: 0.732493, acc: 50.00%] [G loss: 1.837397]\n",
      "epoch:16 step:13092 [D loss: 0.613587, acc: 66.41%] [G loss: 1.813549]\n",
      "epoch:16 step:13093 [D loss: 0.670555, acc: 60.94%] [G loss: 2.004393]\n",
      "epoch:16 step:13094 [D loss: 0.391584, acc: 93.75%] [G loss: 2.411006]\n",
      "epoch:16 step:13095 [D loss: 0.853006, acc: 32.03%] [G loss: 1.561863]\n",
      "epoch:16 step:13096 [D loss: 0.499974, acc: 82.81%] [G loss: 1.836769]\n",
      "epoch:16 step:13097 [D loss: 0.835942, acc: 34.38%] [G loss: 1.826658]\n",
      "epoch:16 step:13098 [D loss: 0.800607, acc: 37.50%] [G loss: 2.086595]\n",
      "epoch:16 step:13099 [D loss: 0.871656, acc: 28.12%] [G loss: 1.467432]\n",
      "epoch:16 step:13100 [D loss: 0.640956, acc: 69.53%] [G loss: 2.120342]\n",
      "epoch:16 step:13101 [D loss: 0.731210, acc: 53.91%] [G loss: 2.156936]\n",
      "epoch:16 step:13102 [D loss: 0.605161, acc: 68.75%] [G loss: 2.360211]\n",
      "epoch:16 step:13103 [D loss: 0.683751, acc: 54.69%] [G loss: 2.304386]\n",
      "epoch:16 step:13104 [D loss: 0.500708, acc: 89.06%] [G loss: 2.067047]\n",
      "epoch:16 step:13105 [D loss: 0.985409, acc: 16.41%] [G loss: 1.729076]\n",
      "epoch:16 step:13106 [D loss: 0.711353, acc: 45.31%] [G loss: 1.638804]\n",
      "epoch:16 step:13107 [D loss: 0.654283, acc: 64.06%] [G loss: 1.752958]\n",
      "epoch:16 step:13108 [D loss: 0.618072, acc: 67.19%] [G loss: 1.896036]\n",
      "epoch:16 step:13109 [D loss: 0.586583, acc: 71.09%] [G loss: 1.747137]\n",
      "epoch:16 step:13110 [D loss: 0.610766, acc: 71.09%] [G loss: 1.819597]\n",
      "epoch:16 step:13111 [D loss: 0.775958, acc: 53.12%] [G loss: 2.003520]\n",
      "epoch:16 step:13112 [D loss: 0.870641, acc: 32.81%] [G loss: 1.796538]\n",
      "epoch:16 step:13113 [D loss: 0.451651, acc: 82.03%] [G loss: 2.347408]\n",
      "epoch:16 step:13114 [D loss: 0.633364, acc: 67.19%] [G loss: 1.715771]\n",
      "epoch:16 step:13115 [D loss: 0.429555, acc: 90.62%] [G loss: 1.974297]\n",
      "epoch:16 step:13116 [D loss: 0.766607, acc: 42.19%] [G loss: 1.701063]\n",
      "epoch:16 step:13117 [D loss: 0.635264, acc: 63.28%] [G loss: 1.752016]\n",
      "epoch:16 step:13118 [D loss: 0.609638, acc: 66.41%] [G loss: 1.994924]\n",
      "epoch:16 step:13119 [D loss: 0.720156, acc: 50.00%] [G loss: 1.557998]\n",
      "epoch:16 step:13120 [D loss: 0.902594, acc: 33.59%] [G loss: 1.780441]\n",
      "epoch:16 step:13121 [D loss: 0.568943, acc: 71.09%] [G loss: 1.764060]\n",
      "epoch:16 step:13122 [D loss: 0.468313, acc: 87.50%] [G loss: 2.309272]\n",
      "epoch:16 step:13123 [D loss: 0.823733, acc: 38.28%] [G loss: 1.662829]\n",
      "epoch:16 step:13124 [D loss: 0.665767, acc: 58.59%] [G loss: 1.923942]\n",
      "epoch:16 step:13125 [D loss: 0.511530, acc: 85.94%] [G loss: 1.811407]\n",
      "epoch:16 step:13126 [D loss: 0.703072, acc: 52.34%] [G loss: 1.703457]\n",
      "epoch:16 step:13127 [D loss: 0.726720, acc: 54.69%] [G loss: 1.752496]\n",
      "epoch:16 step:13128 [D loss: 0.734730, acc: 50.78%] [G loss: 1.896629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13129 [D loss: 0.777494, acc: 46.88%] [G loss: 1.803590]\n",
      "epoch:16 step:13130 [D loss: 0.535200, acc: 78.91%] [G loss: 1.933685]\n",
      "epoch:16 step:13131 [D loss: 0.653013, acc: 60.16%] [G loss: 2.024665]\n",
      "epoch:16 step:13132 [D loss: 0.514472, acc: 85.94%] [G loss: 1.835058]\n",
      "epoch:16 step:13133 [D loss: 0.990854, acc: 30.47%] [G loss: 2.037425]\n",
      "epoch:16 step:13134 [D loss: 0.738889, acc: 50.00%] [G loss: 1.547344]\n",
      "epoch:16 step:13135 [D loss: 0.958652, acc: 14.84%] [G loss: 1.629921]\n",
      "epoch:16 step:13136 [D loss: 0.629192, acc: 66.41%] [G loss: 1.809534]\n",
      "epoch:16 step:13137 [D loss: 0.595505, acc: 75.00%] [G loss: 2.024638]\n",
      "epoch:16 step:13138 [D loss: 0.815618, acc: 39.84%] [G loss: 1.641707]\n",
      "epoch:16 step:13139 [D loss: 0.530601, acc: 84.38%] [G loss: 2.054936]\n",
      "epoch:16 step:13140 [D loss: 0.483362, acc: 89.06%] [G loss: 2.082359]\n",
      "epoch:16 step:13141 [D loss: 0.671068, acc: 61.72%] [G loss: 1.895986]\n",
      "epoch:16 step:13142 [D loss: 0.510453, acc: 83.59%] [G loss: 2.170149]\n",
      "epoch:16 step:13143 [D loss: 0.879073, acc: 35.16%] [G loss: 1.529460]\n",
      "epoch:16 step:13144 [D loss: 0.794679, acc: 42.97%] [G loss: 1.468437]\n",
      "epoch:16 step:13145 [D loss: 0.503448, acc: 66.41%] [G loss: 1.720127]\n",
      "epoch:16 step:13146 [D loss: 0.721555, acc: 51.56%] [G loss: 1.580078]\n",
      "epoch:16 step:13147 [D loss: 0.821076, acc: 38.28%] [G loss: 1.819928]\n",
      "epoch:16 step:13148 [D loss: 0.561490, acc: 75.00%] [G loss: 1.995923]\n",
      "epoch:16 step:13149 [D loss: 0.640575, acc: 65.62%] [G loss: 1.734185]\n",
      "epoch:16 step:13150 [D loss: 0.403900, acc: 93.75%] [G loss: 1.977585]\n",
      "epoch:16 step:13151 [D loss: 0.667713, acc: 57.81%] [G loss: 1.847433]\n",
      "epoch:16 step:13152 [D loss: 0.876645, acc: 31.25%] [G loss: 1.498464]\n",
      "epoch:16 step:13153 [D loss: 0.610803, acc: 67.97%] [G loss: 1.848329]\n",
      "epoch:16 step:13154 [D loss: 0.633055, acc: 66.41%] [G loss: 1.928624]\n",
      "epoch:16 step:13155 [D loss: 0.495618, acc: 81.25%] [G loss: 2.166196]\n",
      "epoch:16 step:13156 [D loss: 1.006211, acc: 15.62%] [G loss: 1.456730]\n",
      "epoch:16 step:13157 [D loss: 0.632643, acc: 57.81%] [G loss: 1.926895]\n",
      "epoch:16 step:13158 [D loss: 0.855690, acc: 36.72%] [G loss: 1.691669]\n",
      "epoch:16 step:13159 [D loss: 0.491562, acc: 85.16%] [G loss: 2.058227]\n",
      "epoch:16 step:13160 [D loss: 0.611874, acc: 64.84%] [G loss: 2.054060]\n",
      "epoch:16 step:13161 [D loss: 0.536929, acc: 78.12%] [G loss: 1.818251]\n",
      "epoch:16 step:13162 [D loss: 0.724367, acc: 42.97%] [G loss: 1.951108]\n",
      "epoch:16 step:13163 [D loss: 0.710525, acc: 55.47%] [G loss: 1.455077]\n",
      "epoch:16 step:13164 [D loss: 0.464725, acc: 78.12%] [G loss: 2.118312]\n",
      "epoch:16 step:13165 [D loss: 0.929317, acc: 21.09%] [G loss: 1.599738]\n",
      "epoch:16 step:13166 [D loss: 0.795349, acc: 38.28%] [G loss: 1.272156]\n",
      "epoch:16 step:13167 [D loss: 0.503343, acc: 80.47%] [G loss: 2.330451]\n",
      "epoch:16 step:13168 [D loss: 0.739632, acc: 44.53%] [G loss: 1.524002]\n",
      "epoch:16 step:13169 [D loss: 0.783779, acc: 38.28%] [G loss: 1.786443]\n",
      "epoch:16 step:13170 [D loss: 0.474401, acc: 92.19%] [G loss: 2.359570]\n",
      "epoch:16 step:13171 [D loss: 0.366679, acc: 96.09%] [G loss: 2.117594]\n",
      "epoch:16 step:13172 [D loss: 0.628305, acc: 67.97%] [G loss: 2.001146]\n",
      "epoch:16 step:13173 [D loss: 0.670411, acc: 60.94%] [G loss: 1.991120]\n",
      "epoch:16 step:13174 [D loss: 0.403351, acc: 92.19%] [G loss: 2.092134]\n",
      "epoch:16 step:13175 [D loss: 0.906735, acc: 24.22%] [G loss: 1.812677]\n",
      "epoch:16 step:13176 [D loss: 0.374170, acc: 96.88%] [G loss: 2.222676]\n",
      "epoch:16 step:13177 [D loss: 0.393964, acc: 82.81%] [G loss: 1.756359]\n",
      "epoch:16 step:13178 [D loss: 0.978110, acc: 22.66%] [G loss: 1.555207]\n",
      "epoch:16 step:13179 [D loss: 0.470904, acc: 92.19%] [G loss: 2.342276]\n",
      "epoch:16 step:13180 [D loss: 0.654576, acc: 61.72%] [G loss: 1.399125]\n",
      "epoch:16 step:13181 [D loss: 0.537334, acc: 75.00%] [G loss: 2.458061]\n",
      "epoch:16 step:13182 [D loss: 0.627073, acc: 67.97%] [G loss: 1.696715]\n",
      "epoch:16 step:13183 [D loss: 0.809508, acc: 31.25%] [G loss: 1.559118]\n",
      "epoch:16 step:13184 [D loss: 0.684494, acc: 61.72%] [G loss: 1.849531]\n",
      "epoch:16 step:13185 [D loss: 0.513546, acc: 89.84%] [G loss: 2.137347]\n",
      "epoch:16 step:13186 [D loss: 0.589905, acc: 76.56%] [G loss: 2.093170]\n",
      "epoch:16 step:13187 [D loss: 0.693434, acc: 55.47%] [G loss: 2.039666]\n",
      "epoch:16 step:13188 [D loss: 1.009515, acc: 16.41%] [G loss: 2.114291]\n",
      "epoch:16 step:13189 [D loss: 0.555197, acc: 72.66%] [G loss: 2.219205]\n",
      "epoch:16 step:13190 [D loss: 0.553330, acc: 67.19%] [G loss: 1.695760]\n",
      "epoch:16 step:13191 [D loss: 0.625655, acc: 69.53%] [G loss: 1.865133]\n",
      "epoch:16 step:13192 [D loss: 0.629234, acc: 67.19%] [G loss: 2.108010]\n",
      "epoch:16 step:13193 [D loss: 0.728852, acc: 51.56%] [G loss: 1.739705]\n",
      "epoch:16 step:13194 [D loss: 0.439446, acc: 94.53%] [G loss: 1.895631]\n",
      "epoch:16 step:13195 [D loss: 0.687671, acc: 57.81%] [G loss: 1.728003]\n",
      "epoch:16 step:13196 [D loss: 0.615712, acc: 75.78%] [G loss: 1.511828]\n",
      "epoch:16 step:13197 [D loss: 0.627163, acc: 62.50%] [G loss: 1.828594]\n",
      "epoch:16 step:13198 [D loss: 0.673361, acc: 60.16%] [G loss: 2.050647]\n",
      "epoch:16 step:13199 [D loss: 0.856047, acc: 50.00%] [G loss: 1.389649]\n",
      "epoch:16 step:13200 [D loss: 0.967243, acc: 17.19%] [G loss: 1.546575]\n",
      "epoch:16 step:13201 [D loss: 0.592015, acc: 62.50%] [G loss: 2.255816]\n",
      "epoch:16 step:13202 [D loss: 0.656053, acc: 58.59%] [G loss: 1.881361]\n",
      "epoch:16 step:13203 [D loss: 0.459764, acc: 93.75%] [G loss: 2.064299]\n",
      "epoch:16 step:13204 [D loss: 0.548408, acc: 68.75%] [G loss: 2.245534]\n",
      "epoch:16 step:13205 [D loss: 0.775248, acc: 42.97%] [G loss: 2.262871]\n",
      "epoch:16 step:13206 [D loss: 0.682459, acc: 50.78%] [G loss: 1.430328]\n",
      "epoch:16 step:13207 [D loss: 0.646215, acc: 61.72%] [G loss: 1.893672]\n",
      "epoch:16 step:13208 [D loss: 0.531010, acc: 78.12%] [G loss: 2.338767]\n",
      "epoch:16 step:13209 [D loss: 0.386219, acc: 89.84%] [G loss: 2.323097]\n",
      "epoch:16 step:13210 [D loss: 0.661295, acc: 62.50%] [G loss: 1.947817]\n",
      "epoch:16 step:13211 [D loss: 0.706618, acc: 53.91%] [G loss: 2.003208]\n",
      "epoch:16 step:13212 [D loss: 0.550204, acc: 80.47%] [G loss: 2.377020]\n",
      "epoch:16 step:13213 [D loss: 0.475799, acc: 89.06%] [G loss: 1.870203]\n",
      "epoch:16 step:13214 [D loss: 0.675693, acc: 57.81%] [G loss: 2.235633]\n",
      "epoch:16 step:13215 [D loss: 0.555517, acc: 81.25%] [G loss: 1.663815]\n",
      "epoch:16 step:13216 [D loss: 0.487284, acc: 85.94%] [G loss: 2.591101]\n",
      "epoch:16 step:13217 [D loss: 0.671944, acc: 57.03%] [G loss: 1.761696]\n",
      "epoch:16 step:13218 [D loss: 0.449827, acc: 90.62%] [G loss: 2.236753]\n",
      "epoch:16 step:13219 [D loss: 0.736283, acc: 46.88%] [G loss: 1.888765]\n",
      "epoch:16 step:13220 [D loss: 0.469522, acc: 88.28%] [G loss: 1.960610]\n",
      "epoch:16 step:13221 [D loss: 0.352124, acc: 93.75%] [G loss: 1.858949]\n",
      "epoch:16 step:13222 [D loss: 0.601257, acc: 68.75%] [G loss: 1.751366]\n",
      "epoch:16 step:13223 [D loss: 0.681687, acc: 53.12%] [G loss: 1.944720]\n",
      "epoch:16 step:13224 [D loss: 0.555899, acc: 75.00%] [G loss: 2.045470]\n",
      "epoch:16 step:13225 [D loss: 0.545203, acc: 80.47%] [G loss: 2.172434]\n",
      "epoch:16 step:13226 [D loss: 0.548521, acc: 84.38%] [G loss: 2.276111]\n",
      "epoch:16 step:13227 [D loss: 0.618079, acc: 71.09%] [G loss: 1.905614]\n",
      "epoch:16 step:13228 [D loss: 0.597794, acc: 71.88%] [G loss: 1.756871]\n",
      "epoch:16 step:13229 [D loss: 0.765501, acc: 50.00%] [G loss: 1.893664]\n",
      "epoch:16 step:13230 [D loss: 0.831299, acc: 39.84%] [G loss: 1.747226]\n",
      "epoch:16 step:13231 [D loss: 0.468412, acc: 89.06%] [G loss: 1.806283]\n",
      "epoch:16 step:13232 [D loss: 0.666821, acc: 63.28%] [G loss: 2.276301]\n",
      "epoch:16 step:13233 [D loss: 0.809064, acc: 37.50%] [G loss: 2.042431]\n",
      "epoch:16 step:13234 [D loss: 0.344697, acc: 99.22%] [G loss: 2.450550]\n",
      "epoch:16 step:13235 [D loss: 0.626007, acc: 67.19%] [G loss: 1.757667]\n",
      "epoch:16 step:13236 [D loss: 0.420845, acc: 82.03%] [G loss: 1.877699]\n",
      "epoch:16 step:13237 [D loss: 0.325577, acc: 96.88%] [G loss: 2.101883]\n",
      "epoch:16 step:13238 [D loss: 0.746117, acc: 50.78%] [G loss: 1.840745]\n",
      "epoch:16 step:13239 [D loss: 0.740405, acc: 45.31%] [G loss: 1.687965]\n",
      "epoch:16 step:13240 [D loss: 0.782060, acc: 37.50%] [G loss: 1.731548]\n",
      "epoch:16 step:13241 [D loss: 0.600531, acc: 63.28%] [G loss: 1.966630]\n",
      "epoch:16 step:13242 [D loss: 0.384581, acc: 89.06%] [G loss: 2.192755]\n",
      "epoch:16 step:13243 [D loss: 0.483293, acc: 89.84%] [G loss: 2.260545]\n",
      "epoch:16 step:13244 [D loss: 0.368097, acc: 92.97%] [G loss: 2.051608]\n",
      "epoch:16 step:13245 [D loss: 0.455869, acc: 89.84%] [G loss: 1.784247]\n",
      "epoch:16 step:13246 [D loss: 0.581063, acc: 74.22%] [G loss: 2.048551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13247 [D loss: 0.761209, acc: 48.44%] [G loss: 1.794241]\n",
      "epoch:16 step:13248 [D loss: 0.470261, acc: 83.59%] [G loss: 2.023421]\n",
      "epoch:16 step:13249 [D loss: 0.654180, acc: 53.91%] [G loss: 1.914252]\n",
      "epoch:16 step:13250 [D loss: 0.637772, acc: 57.03%] [G loss: 1.706067]\n",
      "epoch:16 step:13251 [D loss: 0.732950, acc: 52.34%] [G loss: 1.523293]\n",
      "epoch:16 step:13252 [D loss: 1.065009, acc: 18.75%] [G loss: 1.176669]\n",
      "epoch:16 step:13253 [D loss: 0.515324, acc: 82.03%] [G loss: 1.798864]\n",
      "epoch:16 step:13254 [D loss: 0.749046, acc: 48.44%] [G loss: 1.961642]\n",
      "epoch:16 step:13255 [D loss: 0.541190, acc: 78.12%] [G loss: 1.785333]\n",
      "epoch:16 step:13256 [D loss: 0.939295, acc: 29.69%] [G loss: 1.737700]\n",
      "epoch:16 step:13257 [D loss: 0.880160, acc: 26.56%] [G loss: 1.460919]\n",
      "epoch:16 step:13258 [D loss: 0.467447, acc: 77.34%] [G loss: 1.958283]\n",
      "epoch:16 step:13259 [D loss: 0.732787, acc: 57.81%] [G loss: 2.652384]\n",
      "epoch:16 step:13260 [D loss: 1.054264, acc: 10.16%] [G loss: 1.163282]\n",
      "epoch:16 step:13261 [D loss: 0.588329, acc: 71.88%] [G loss: 1.936648]\n",
      "epoch:16 step:13262 [D loss: 0.610230, acc: 60.16%] [G loss: 1.995439]\n",
      "epoch:16 step:13263 [D loss: 0.628562, acc: 64.84%] [G loss: 2.052906]\n",
      "epoch:16 step:13264 [D loss: 0.253444, acc: 99.22%] [G loss: 2.619012]\n",
      "epoch:16 step:13265 [D loss: 0.528464, acc: 71.88%] [G loss: 2.375436]\n",
      "epoch:16 step:13266 [D loss: 0.576167, acc: 74.22%] [G loss: 2.062049]\n",
      "epoch:16 step:13267 [D loss: 0.907629, acc: 29.69%] [G loss: 2.205274]\n",
      "epoch:16 step:13268 [D loss: 0.558839, acc: 77.34%] [G loss: 2.587832]\n",
      "epoch:16 step:13269 [D loss: 0.520206, acc: 80.47%] [G loss: 2.239037]\n",
      "epoch:16 step:13270 [D loss: 0.526874, acc: 82.03%] [G loss: 2.304595]\n",
      "epoch:16 step:13271 [D loss: 0.936513, acc: 27.34%] [G loss: 2.104253]\n",
      "epoch:16 step:13272 [D loss: 0.694635, acc: 57.03%] [G loss: 2.243030]\n",
      "epoch:16 step:13273 [D loss: 0.508969, acc: 77.34%] [G loss: 1.777470]\n",
      "epoch:16 step:13274 [D loss: 0.772119, acc: 39.84%] [G loss: 1.626509]\n",
      "epoch:16 step:13275 [D loss: 0.972364, acc: 16.41%] [G loss: 1.682652]\n",
      "epoch:16 step:13276 [D loss: 0.407149, acc: 90.62%] [G loss: 1.843302]\n",
      "epoch:16 step:13277 [D loss: 0.633427, acc: 67.97%] [G loss: 1.761815]\n",
      "epoch:17 step:13278 [D loss: 0.700470, acc: 54.69%] [G loss: 1.843072]\n",
      "epoch:17 step:13279 [D loss: 0.593298, acc: 69.53%] [G loss: 2.073542]\n",
      "epoch:17 step:13280 [D loss: 0.500782, acc: 70.31%] [G loss: 2.056180]\n",
      "epoch:17 step:13281 [D loss: 0.722472, acc: 46.09%] [G loss: 1.791972]\n",
      "epoch:17 step:13282 [D loss: 0.589680, acc: 64.06%] [G loss: 2.448628]\n",
      "epoch:17 step:13283 [D loss: 0.457856, acc: 91.41%] [G loss: 1.840017]\n",
      "epoch:17 step:13284 [D loss: 0.444967, acc: 89.06%] [G loss: 2.685441]\n",
      "epoch:17 step:13285 [D loss: 0.752537, acc: 49.22%] [G loss: 1.566580]\n",
      "epoch:17 step:13286 [D loss: 0.493775, acc: 83.59%] [G loss: 2.196713]\n",
      "epoch:17 step:13287 [D loss: 0.671651, acc: 60.16%] [G loss: 1.716364]\n",
      "epoch:17 step:13288 [D loss: 0.481132, acc: 85.94%] [G loss: 1.842080]\n",
      "epoch:17 step:13289 [D loss: 0.496500, acc: 85.16%] [G loss: 2.145159]\n",
      "epoch:17 step:13290 [D loss: 0.382926, acc: 78.91%] [G loss: 2.147716]\n",
      "epoch:17 step:13291 [D loss: 0.838083, acc: 45.31%] [G loss: 1.695368]\n",
      "epoch:17 step:13292 [D loss: 0.499762, acc: 86.72%] [G loss: 1.937216]\n",
      "epoch:17 step:13293 [D loss: 0.790738, acc: 41.41%] [G loss: 1.939699]\n",
      "epoch:17 step:13294 [D loss: 0.492552, acc: 82.03%] [G loss: 2.468734]\n",
      "epoch:17 step:13295 [D loss: 0.572041, acc: 67.19%] [G loss: 2.209819]\n",
      "epoch:17 step:13296 [D loss: 0.546886, acc: 77.34%] [G loss: 2.001005]\n",
      "epoch:17 step:13297 [D loss: 0.499579, acc: 84.38%] [G loss: 2.548933]\n",
      "epoch:17 step:13298 [D loss: 0.578977, acc: 74.22%] [G loss: 1.818801]\n",
      "epoch:17 step:13299 [D loss: 0.753507, acc: 49.22%] [G loss: 1.977842]\n",
      "epoch:17 step:13300 [D loss: 0.709008, acc: 49.22%] [G loss: 2.005981]\n",
      "epoch:17 step:13301 [D loss: 0.846801, acc: 32.81%] [G loss: 1.793152]\n",
      "epoch:17 step:13302 [D loss: 0.489101, acc: 82.81%] [G loss: 1.924825]\n",
      "epoch:17 step:13303 [D loss: 0.456114, acc: 82.03%] [G loss: 1.902526]\n",
      "epoch:17 step:13304 [D loss: 0.814505, acc: 41.41%] [G loss: 1.504447]\n",
      "epoch:17 step:13305 [D loss: 0.653587, acc: 60.16%] [G loss: 2.045155]\n",
      "epoch:17 step:13306 [D loss: 0.652435, acc: 64.84%] [G loss: 1.924565]\n",
      "epoch:17 step:13307 [D loss: 0.372022, acc: 82.03%] [G loss: 1.898363]\n",
      "epoch:17 step:13308 [D loss: 0.511567, acc: 82.81%] [G loss: 2.030177]\n",
      "epoch:17 step:13309 [D loss: 0.849384, acc: 40.62%] [G loss: 1.745331]\n",
      "epoch:17 step:13310 [D loss: 0.609555, acc: 70.31%] [G loss: 1.896612]\n",
      "epoch:17 step:13311 [D loss: 0.613724, acc: 70.31%] [G loss: 2.219394]\n",
      "epoch:17 step:13312 [D loss: 0.709420, acc: 55.47%] [G loss: 1.642006]\n",
      "epoch:17 step:13313 [D loss: 0.870713, acc: 37.50%] [G loss: 2.154629]\n",
      "epoch:17 step:13314 [D loss: 0.580168, acc: 74.22%] [G loss: 2.086951]\n",
      "epoch:17 step:13315 [D loss: 0.805353, acc: 42.97%] [G loss: 1.737827]\n",
      "epoch:17 step:13316 [D loss: 0.526731, acc: 67.19%] [G loss: 2.057484]\n",
      "epoch:17 step:13317 [D loss: 0.535569, acc: 78.12%] [G loss: 2.408332]\n",
      "epoch:17 step:13318 [D loss: 0.497913, acc: 85.94%] [G loss: 2.126352]\n",
      "epoch:17 step:13319 [D loss: 0.470763, acc: 84.38%] [G loss: 1.723530]\n",
      "epoch:17 step:13320 [D loss: 0.585540, acc: 66.41%] [G loss: 1.661381]\n",
      "epoch:17 step:13321 [D loss: 0.539630, acc: 78.12%] [G loss: 2.289528]\n",
      "epoch:17 step:13322 [D loss: 0.530087, acc: 80.47%] [G loss: 2.454869]\n",
      "epoch:17 step:13323 [D loss: 0.584697, acc: 60.94%] [G loss: 2.368699]\n",
      "epoch:17 step:13324 [D loss: 0.583966, acc: 64.06%] [G loss: 2.430636]\n",
      "epoch:17 step:13325 [D loss: 0.860756, acc: 31.25%] [G loss: 2.082980]\n",
      "epoch:17 step:13326 [D loss: 0.916943, acc: 26.56%] [G loss: 1.672335]\n",
      "epoch:17 step:13327 [D loss: 0.782322, acc: 39.06%] [G loss: 1.934948]\n",
      "epoch:17 step:13328 [D loss: 0.463457, acc: 89.06%] [G loss: 1.878245]\n",
      "epoch:17 step:13329 [D loss: 0.527778, acc: 82.81%] [G loss: 1.789098]\n",
      "epoch:17 step:13330 [D loss: 0.462894, acc: 85.16%] [G loss: 1.710721]\n",
      "epoch:17 step:13331 [D loss: 0.856710, acc: 39.84%] [G loss: 2.173757]\n",
      "epoch:17 step:13332 [D loss: 0.807614, acc: 32.81%] [G loss: 1.809408]\n",
      "epoch:17 step:13333 [D loss: 0.554810, acc: 75.00%] [G loss: 2.124595]\n",
      "epoch:17 step:13334 [D loss: 0.894904, acc: 37.50%] [G loss: 1.934222]\n",
      "epoch:17 step:13335 [D loss: 0.553939, acc: 72.66%] [G loss: 1.865988]\n",
      "epoch:17 step:13336 [D loss: 0.470472, acc: 85.94%] [G loss: 2.869448]\n",
      "epoch:17 step:13337 [D loss: 0.766412, acc: 49.22%] [G loss: 2.404198]\n",
      "epoch:17 step:13338 [D loss: 0.575940, acc: 67.19%] [G loss: 2.037992]\n",
      "epoch:17 step:13339 [D loss: 0.576342, acc: 73.44%] [G loss: 1.872951]\n",
      "epoch:17 step:13340 [D loss: 1.020233, acc: 16.41%] [G loss: 1.426190]\n",
      "epoch:17 step:13341 [D loss: 0.537580, acc: 75.78%] [G loss: 2.199407]\n",
      "epoch:17 step:13342 [D loss: 0.495299, acc: 85.16%] [G loss: 1.860728]\n",
      "epoch:17 step:13343 [D loss: 0.505019, acc: 79.69%] [G loss: 2.086594]\n",
      "epoch:17 step:13344 [D loss: 0.936543, acc: 43.75%] [G loss: 2.180611]\n",
      "epoch:17 step:13345 [D loss: 0.683460, acc: 53.91%] [G loss: 2.043064]\n",
      "epoch:17 step:13346 [D loss: 0.449061, acc: 85.94%] [G loss: 1.918626]\n",
      "epoch:17 step:13347 [D loss: 0.683544, acc: 55.47%] [G loss: 2.031959]\n",
      "epoch:17 step:13348 [D loss: 0.748080, acc: 49.22%] [G loss: 2.228862]\n",
      "epoch:17 step:13349 [D loss: 0.569614, acc: 76.56%] [G loss: 2.558170]\n",
      "epoch:17 step:13350 [D loss: 0.565419, acc: 67.97%] [G loss: 1.971167]\n",
      "epoch:17 step:13351 [D loss: 0.547828, acc: 71.09%] [G loss: 1.901194]\n",
      "epoch:17 step:13352 [D loss: 0.629739, acc: 63.28%] [G loss: 1.787206]\n",
      "epoch:17 step:13353 [D loss: 0.544972, acc: 78.12%] [G loss: 2.182254]\n",
      "epoch:17 step:13354 [D loss: 0.576688, acc: 68.75%] [G loss: 1.694187]\n",
      "epoch:17 step:13355 [D loss: 0.369657, acc: 88.28%] [G loss: 2.554494]\n",
      "epoch:17 step:13356 [D loss: 0.798116, acc: 48.44%] [G loss: 2.083074]\n",
      "epoch:17 step:13357 [D loss: 0.676452, acc: 57.03%] [G loss: 2.077955]\n",
      "epoch:17 step:13358 [D loss: 0.337591, acc: 96.88%] [G loss: 2.305046]\n",
      "epoch:17 step:13359 [D loss: 0.652636, acc: 61.72%] [G loss: 1.788953]\n",
      "epoch:17 step:13360 [D loss: 0.654501, acc: 65.62%] [G loss: 1.939010]\n",
      "epoch:17 step:13361 [D loss: 1.016936, acc: 27.34%] [G loss: 1.408636]\n",
      "epoch:17 step:13362 [D loss: 0.595571, acc: 71.88%] [G loss: 1.804788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13363 [D loss: 0.619932, acc: 67.97%] [G loss: 1.820282]\n",
      "epoch:17 step:13364 [D loss: 0.723939, acc: 49.22%] [G loss: 1.694310]\n",
      "epoch:17 step:13365 [D loss: 0.557192, acc: 73.44%] [G loss: 1.930519]\n",
      "epoch:17 step:13366 [D loss: 0.683605, acc: 55.47%] [G loss: 2.078393]\n",
      "epoch:17 step:13367 [D loss: 0.683231, acc: 55.47%] [G loss: 1.637594]\n",
      "epoch:17 step:13368 [D loss: 0.600436, acc: 74.22%] [G loss: 1.771781]\n",
      "epoch:17 step:13369 [D loss: 0.875434, acc: 32.03%] [G loss: 1.683975]\n",
      "epoch:17 step:13370 [D loss: 0.615007, acc: 65.62%] [G loss: 1.965809]\n",
      "epoch:17 step:13371 [D loss: 0.501713, acc: 85.94%] [G loss: 1.926888]\n",
      "epoch:17 step:13372 [D loss: 0.762458, acc: 43.75%] [G loss: 1.894886]\n",
      "epoch:17 step:13373 [D loss: 0.625567, acc: 66.41%] [G loss: 1.799933]\n",
      "epoch:17 step:13374 [D loss: 0.578980, acc: 61.72%] [G loss: 2.176136]\n",
      "epoch:17 step:13375 [D loss: 0.793319, acc: 37.50%] [G loss: 1.479687]\n",
      "epoch:17 step:13376 [D loss: 0.263453, acc: 99.22%] [G loss: 2.160970]\n",
      "epoch:17 step:13377 [D loss: 0.636702, acc: 60.94%] [G loss: 1.906428]\n",
      "epoch:17 step:13378 [D loss: 0.969890, acc: 36.72%] [G loss: 1.709709]\n",
      "epoch:17 step:13379 [D loss: 0.755429, acc: 44.53%] [G loss: 1.823067]\n",
      "epoch:17 step:13380 [D loss: 0.646168, acc: 60.16%] [G loss: 1.970793]\n",
      "epoch:17 step:13381 [D loss: 0.641249, acc: 64.06%] [G loss: 2.204506]\n",
      "epoch:17 step:13382 [D loss: 0.523986, acc: 78.12%] [G loss: 2.552208]\n",
      "epoch:17 step:13383 [D loss: 0.519226, acc: 83.59%] [G loss: 1.860841]\n",
      "epoch:17 step:13384 [D loss: 0.896708, acc: 42.19%] [G loss: 1.641701]\n",
      "epoch:17 step:13385 [D loss: 0.768888, acc: 48.44%] [G loss: 1.843929]\n",
      "epoch:17 step:13386 [D loss: 0.755423, acc: 49.22%] [G loss: 1.979628]\n",
      "epoch:17 step:13387 [D loss: 0.655750, acc: 64.84%] [G loss: 1.617558]\n",
      "epoch:17 step:13388 [D loss: 1.051966, acc: 13.28%] [G loss: 1.586931]\n",
      "epoch:17 step:13389 [D loss: 0.796827, acc: 35.94%] [G loss: 1.434192]\n",
      "epoch:17 step:13390 [D loss: 0.619709, acc: 62.50%] [G loss: 1.970922]\n",
      "epoch:17 step:13391 [D loss: 0.414011, acc: 87.50%] [G loss: 1.963957]\n",
      "epoch:17 step:13392 [D loss: 0.472873, acc: 90.62%] [G loss: 2.157014]\n",
      "epoch:17 step:13393 [D loss: 0.693607, acc: 53.91%] [G loss: 2.370153]\n",
      "epoch:17 step:13394 [D loss: 0.549358, acc: 70.31%] [G loss: 2.178033]\n",
      "epoch:17 step:13395 [D loss: 0.462489, acc: 87.50%] [G loss: 2.069684]\n",
      "epoch:17 step:13396 [D loss: 0.398188, acc: 96.88%] [G loss: 2.132833]\n",
      "epoch:17 step:13397 [D loss: 0.704386, acc: 54.69%] [G loss: 2.140489]\n",
      "epoch:17 step:13398 [D loss: 0.446243, acc: 89.06%] [G loss: 2.191732]\n",
      "epoch:17 step:13399 [D loss: 0.594542, acc: 67.97%] [G loss: 1.856419]\n",
      "epoch:17 step:13400 [D loss: 0.502026, acc: 83.59%] [G loss: 2.000417]\n",
      "epoch:17 step:13401 [D loss: 0.629884, acc: 64.84%] [G loss: 1.800652]\n",
      "epoch:17 step:13402 [D loss: 0.702739, acc: 50.78%] [G loss: 1.575960]\n",
      "epoch:17 step:13403 [D loss: 0.828258, acc: 40.62%] [G loss: 1.421697]\n",
      "epoch:17 step:13404 [D loss: 0.801595, acc: 35.94%] [G loss: 1.466219]\n",
      "epoch:17 step:13405 [D loss: 0.793843, acc: 48.44%] [G loss: 2.023320]\n",
      "epoch:17 step:13406 [D loss: 0.398792, acc: 95.31%] [G loss: 1.558840]\n",
      "epoch:17 step:13407 [D loss: 0.890703, acc: 22.66%] [G loss: 1.375147]\n",
      "epoch:17 step:13408 [D loss: 0.756299, acc: 45.31%] [G loss: 1.650996]\n",
      "epoch:17 step:13409 [D loss: 0.720945, acc: 57.81%] [G loss: 1.835765]\n",
      "epoch:17 step:13410 [D loss: 0.719920, acc: 49.22%] [G loss: 1.844924]\n",
      "epoch:17 step:13411 [D loss: 0.743837, acc: 45.31%] [G loss: 2.220854]\n",
      "epoch:17 step:13412 [D loss: 0.455639, acc: 85.94%] [G loss: 2.111684]\n",
      "epoch:17 step:13413 [D loss: 0.554592, acc: 76.56%] [G loss: 2.227226]\n",
      "epoch:17 step:13414 [D loss: 0.656987, acc: 60.16%] [G loss: 1.687300]\n",
      "epoch:17 step:13415 [D loss: 0.744861, acc: 53.91%] [G loss: 1.776342]\n",
      "epoch:17 step:13416 [D loss: 0.644977, acc: 66.41%] [G loss: 2.083592]\n",
      "epoch:17 step:13417 [D loss: 0.639714, acc: 61.72%] [G loss: 1.826741]\n",
      "epoch:17 step:13418 [D loss: 0.695235, acc: 56.25%] [G loss: 2.710716]\n",
      "epoch:17 step:13419 [D loss: 0.668384, acc: 63.28%] [G loss: 1.725026]\n",
      "epoch:17 step:13420 [D loss: 0.814112, acc: 44.53%] [G loss: 1.449814]\n",
      "epoch:17 step:13421 [D loss: 0.397544, acc: 86.72%] [G loss: 1.884814]\n",
      "epoch:17 step:13422 [D loss: 0.597784, acc: 71.88%] [G loss: 2.152824]\n",
      "epoch:17 step:13423 [D loss: 0.655310, acc: 57.03%] [G loss: 2.018879]\n",
      "epoch:17 step:13424 [D loss: 0.543877, acc: 78.91%] [G loss: 2.103327]\n",
      "epoch:17 step:13425 [D loss: 0.279122, acc: 92.97%] [G loss: 2.198279]\n",
      "epoch:17 step:13426 [D loss: 0.451162, acc: 91.41%] [G loss: 1.862318]\n",
      "epoch:17 step:13427 [D loss: 0.668741, acc: 60.16%] [G loss: 1.886225]\n",
      "epoch:17 step:13428 [D loss: 0.625762, acc: 69.53%] [G loss: 2.163369]\n",
      "epoch:17 step:13429 [D loss: 0.485704, acc: 74.22%] [G loss: 1.899348]\n",
      "epoch:17 step:13430 [D loss: 0.459134, acc: 78.12%] [G loss: 1.821619]\n",
      "epoch:17 step:13431 [D loss: 0.401709, acc: 95.31%] [G loss: 2.104228]\n",
      "epoch:17 step:13432 [D loss: 0.412518, acc: 91.41%] [G loss: 1.815887]\n",
      "epoch:17 step:13433 [D loss: 0.652915, acc: 60.94%] [G loss: 1.857019]\n",
      "epoch:17 step:13434 [D loss: 0.552781, acc: 72.66%] [G loss: 1.827736]\n",
      "epoch:17 step:13435 [D loss: 0.716597, acc: 49.22%] [G loss: 1.971428]\n",
      "epoch:17 step:13436 [D loss: 0.467729, acc: 82.81%] [G loss: 1.889671]\n",
      "epoch:17 step:13437 [D loss: 1.191198, acc: 4.69%] [G loss: 1.555532]\n",
      "epoch:17 step:13438 [D loss: 0.519861, acc: 82.03%] [G loss: 1.858291]\n",
      "epoch:17 step:13439 [D loss: 0.255457, acc: 99.22%] [G loss: 2.138378]\n",
      "epoch:17 step:13440 [D loss: 0.392610, acc: 89.06%] [G loss: 2.060930]\n",
      "epoch:17 step:13441 [D loss: 0.883916, acc: 50.00%] [G loss: 1.943103]\n",
      "epoch:17 step:13442 [D loss: 0.712814, acc: 52.34%] [G loss: 2.159478]\n",
      "epoch:17 step:13443 [D loss: 0.445938, acc: 75.78%] [G loss: 2.107153]\n",
      "epoch:17 step:13444 [D loss: 0.667307, acc: 55.47%] [G loss: 1.808330]\n",
      "epoch:17 step:13445 [D loss: 0.833566, acc: 45.31%] [G loss: 1.417373]\n",
      "epoch:17 step:13446 [D loss: 0.465370, acc: 80.47%] [G loss: 1.709147]\n",
      "epoch:17 step:13447 [D loss: 0.551137, acc: 82.03%] [G loss: 1.882419]\n",
      "epoch:17 step:13448 [D loss: 0.463264, acc: 71.09%] [G loss: 1.818753]\n",
      "epoch:17 step:13449 [D loss: 0.485741, acc: 81.25%] [G loss: 2.266703]\n",
      "epoch:17 step:13450 [D loss: 0.746576, acc: 49.22%] [G loss: 1.879054]\n",
      "epoch:17 step:13451 [D loss: 0.501837, acc: 82.81%] [G loss: 1.752514]\n",
      "epoch:17 step:13452 [D loss: 0.672463, acc: 58.59%] [G loss: 1.764876]\n",
      "epoch:17 step:13453 [D loss: 0.845898, acc: 32.81%] [G loss: 1.820793]\n",
      "epoch:17 step:13454 [D loss: 0.402405, acc: 86.72%] [G loss: 2.252800]\n",
      "epoch:17 step:13455 [D loss: 1.066289, acc: 12.50%] [G loss: 1.449773]\n",
      "epoch:17 step:13456 [D loss: 0.620884, acc: 70.31%] [G loss: 1.779724]\n",
      "epoch:17 step:13457 [D loss: 0.507407, acc: 82.81%] [G loss: 2.044450]\n",
      "epoch:17 step:13458 [D loss: 0.457321, acc: 92.19%] [G loss: 1.944318]\n",
      "epoch:17 step:13459 [D loss: 0.531816, acc: 83.59%] [G loss: 1.562337]\n",
      "epoch:17 step:13460 [D loss: 0.728660, acc: 48.44%] [G loss: 1.648199]\n",
      "epoch:17 step:13461 [D loss: 0.721947, acc: 47.66%] [G loss: 1.889582]\n",
      "epoch:17 step:13462 [D loss: 0.595335, acc: 70.31%] [G loss: 1.556077]\n",
      "epoch:17 step:13463 [D loss: 0.672297, acc: 57.81%] [G loss: 1.716629]\n",
      "epoch:17 step:13464 [D loss: 0.376223, acc: 95.31%] [G loss: 2.327059]\n",
      "epoch:17 step:13465 [D loss: 0.529028, acc: 80.47%] [G loss: 1.836387]\n",
      "epoch:17 step:13466 [D loss: 0.408578, acc: 91.41%] [G loss: 2.254615]\n",
      "epoch:17 step:13467 [D loss: 0.905083, acc: 31.25%] [G loss: 1.576528]\n",
      "epoch:17 step:13468 [D loss: 0.319085, acc: 96.09%] [G loss: 2.321000]\n",
      "epoch:17 step:13469 [D loss: 0.568231, acc: 78.12%] [G loss: 1.658307]\n",
      "epoch:17 step:13470 [D loss: 0.485368, acc: 82.81%] [G loss: 2.744572]\n",
      "epoch:17 step:13471 [D loss: 0.489745, acc: 83.59%] [G loss: 1.907354]\n",
      "epoch:17 step:13472 [D loss: 0.719117, acc: 46.88%] [G loss: 1.747464]\n",
      "epoch:17 step:13473 [D loss: 0.653902, acc: 59.38%] [G loss: 1.598945]\n",
      "epoch:17 step:13474 [D loss: 0.668531, acc: 55.47%] [G loss: 2.562622]\n",
      "epoch:17 step:13475 [D loss: 0.718782, acc: 54.69%] [G loss: 1.861885]\n",
      "epoch:17 step:13476 [D loss: 0.473271, acc: 71.88%] [G loss: 2.930760]\n",
      "epoch:17 step:13477 [D loss: 0.693526, acc: 57.03%] [G loss: 1.996853]\n",
      "epoch:17 step:13478 [D loss: 0.441801, acc: 85.16%] [G loss: 2.138327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13479 [D loss: 0.696824, acc: 52.34%] [G loss: 1.886708]\n",
      "epoch:17 step:13480 [D loss: 0.659558, acc: 61.72%] [G loss: 1.549265]\n",
      "epoch:17 step:13481 [D loss: 0.579679, acc: 62.50%] [G loss: 1.796887]\n",
      "epoch:17 step:13482 [D loss: 0.941516, acc: 21.09%] [G loss: 1.582683]\n",
      "epoch:17 step:13483 [D loss: 0.505492, acc: 82.81%] [G loss: 2.178066]\n",
      "epoch:17 step:13484 [D loss: 0.850951, acc: 49.22%] [G loss: 2.020248]\n",
      "epoch:17 step:13485 [D loss: 0.251130, acc: 99.22%] [G loss: 2.702424]\n",
      "epoch:17 step:13486 [D loss: 0.524338, acc: 84.38%] [G loss: 2.386244]\n",
      "epoch:17 step:13487 [D loss: 0.857067, acc: 28.12%] [G loss: 1.497438]\n",
      "epoch:17 step:13488 [D loss: 0.669271, acc: 60.94%] [G loss: 1.775815]\n",
      "epoch:17 step:13489 [D loss: 0.324293, acc: 96.09%] [G loss: 2.398978]\n",
      "epoch:17 step:13490 [D loss: 0.631785, acc: 66.41%] [G loss: 1.709801]\n",
      "epoch:17 step:13491 [D loss: 0.470671, acc: 90.62%] [G loss: 2.010862]\n",
      "epoch:17 step:13492 [D loss: 0.507359, acc: 71.09%] [G loss: 1.504020]\n",
      "epoch:17 step:13493 [D loss: 0.813853, acc: 36.72%] [G loss: 1.744287]\n",
      "epoch:17 step:13494 [D loss: 0.436998, acc: 84.38%] [G loss: 1.866193]\n",
      "epoch:17 step:13495 [D loss: 0.544745, acc: 69.53%] [G loss: 2.089587]\n",
      "epoch:17 step:13496 [D loss: 0.613347, acc: 63.28%] [G loss: 2.145113]\n",
      "epoch:17 step:13497 [D loss: 0.675749, acc: 55.47%] [G loss: 1.930986]\n",
      "epoch:17 step:13498 [D loss: 1.149154, acc: 10.16%] [G loss: 1.418854]\n",
      "epoch:17 step:13499 [D loss: 0.750277, acc: 47.66%] [G loss: 1.520967]\n",
      "epoch:17 step:13500 [D loss: 0.687869, acc: 53.91%] [G loss: 1.699313]\n",
      "epoch:17 step:13501 [D loss: 0.674033, acc: 57.81%] [G loss: 1.694922]\n",
      "epoch:17 step:13502 [D loss: 0.692560, acc: 49.22%] [G loss: 1.872929]\n",
      "epoch:17 step:13503 [D loss: 0.784406, acc: 39.84%] [G loss: 2.246280]\n",
      "epoch:17 step:13504 [D loss: 0.350963, acc: 99.22%] [G loss: 1.958241]\n",
      "epoch:17 step:13505 [D loss: 0.625537, acc: 69.53%] [G loss: 1.866300]\n",
      "epoch:17 step:13506 [D loss: 0.594136, acc: 69.53%] [G loss: 2.248759]\n",
      "epoch:17 step:13507 [D loss: 0.550980, acc: 77.34%] [G loss: 1.893340]\n",
      "epoch:17 step:13508 [D loss: 0.712717, acc: 51.56%] [G loss: 2.122777]\n",
      "epoch:17 step:13509 [D loss: 0.898879, acc: 35.16%] [G loss: 1.685914]\n",
      "epoch:17 step:13510 [D loss: 0.694452, acc: 51.56%] [G loss: 1.940172]\n",
      "epoch:17 step:13511 [D loss: 1.129616, acc: 13.28%] [G loss: 2.054772]\n",
      "epoch:17 step:13512 [D loss: 0.401791, acc: 93.75%] [G loss: 2.068289]\n",
      "epoch:17 step:13513 [D loss: 0.518735, acc: 70.31%] [G loss: 2.519217]\n",
      "epoch:17 step:13514 [D loss: 0.532765, acc: 83.59%] [G loss: 2.241852]\n",
      "epoch:17 step:13515 [D loss: 0.842315, acc: 30.47%] [G loss: 1.722326]\n",
      "epoch:17 step:13516 [D loss: 0.677217, acc: 57.81%] [G loss: 1.807409]\n",
      "epoch:17 step:13517 [D loss: 0.581716, acc: 71.09%] [G loss: 2.049588]\n",
      "epoch:17 step:13518 [D loss: 0.580855, acc: 71.88%] [G loss: 2.308699]\n",
      "epoch:17 step:13519 [D loss: 0.583398, acc: 70.31%] [G loss: 2.051934]\n",
      "epoch:17 step:13520 [D loss: 0.674266, acc: 59.38%] [G loss: 1.982922]\n",
      "epoch:17 step:13521 [D loss: 0.608719, acc: 64.84%] [G loss: 2.408709]\n",
      "epoch:17 step:13522 [D loss: 0.753066, acc: 54.69%] [G loss: 1.879894]\n",
      "epoch:17 step:13523 [D loss: 0.567038, acc: 71.88%] [G loss: 2.156519]\n",
      "epoch:17 step:13524 [D loss: 0.893915, acc: 31.25%] [G loss: 1.907140]\n",
      "epoch:17 step:13525 [D loss: 0.849954, acc: 34.38%] [G loss: 1.825471]\n",
      "epoch:17 step:13526 [D loss: 0.769490, acc: 43.75%] [G loss: 1.421261]\n",
      "epoch:17 step:13527 [D loss: 0.446648, acc: 92.97%] [G loss: 1.992536]\n",
      "epoch:17 step:13528 [D loss: 0.723549, acc: 51.56%] [G loss: 1.996462]\n",
      "epoch:17 step:13529 [D loss: 0.608871, acc: 60.94%] [G loss: 1.533687]\n",
      "epoch:17 step:13530 [D loss: 0.659006, acc: 53.91%] [G loss: 1.725668]\n",
      "epoch:17 step:13531 [D loss: 0.616532, acc: 67.97%] [G loss: 1.714150]\n",
      "epoch:17 step:13532 [D loss: 0.479436, acc: 86.72%] [G loss: 1.967326]\n",
      "epoch:17 step:13533 [D loss: 0.404422, acc: 94.53%] [G loss: 2.190111]\n",
      "epoch:17 step:13534 [D loss: 0.858339, acc: 39.06%] [G loss: 1.644441]\n",
      "epoch:17 step:13535 [D loss: 0.570747, acc: 74.22%] [G loss: 1.776994]\n",
      "epoch:17 step:13536 [D loss: 0.657870, acc: 57.81%] [G loss: 1.783427]\n",
      "epoch:17 step:13537 [D loss: 0.698626, acc: 52.34%] [G loss: 1.679323]\n",
      "epoch:17 step:13538 [D loss: 0.703725, acc: 53.91%] [G loss: 1.689403]\n",
      "epoch:17 step:13539 [D loss: 0.400577, acc: 92.97%] [G loss: 1.993181]\n",
      "epoch:17 step:13540 [D loss: 0.512624, acc: 82.03%] [G loss: 1.848039]\n",
      "epoch:17 step:13541 [D loss: 0.479565, acc: 72.66%] [G loss: 1.558523]\n",
      "epoch:17 step:13542 [D loss: 0.943616, acc: 21.09%] [G loss: 1.304540]\n",
      "epoch:17 step:13543 [D loss: 0.993839, acc: 30.47%] [G loss: 1.431581]\n",
      "epoch:17 step:13544 [D loss: 0.989029, acc: 23.44%] [G loss: 1.446074]\n",
      "epoch:17 step:13545 [D loss: 0.538615, acc: 78.91%] [G loss: 1.524295]\n",
      "epoch:17 step:13546 [D loss: 0.581028, acc: 73.44%] [G loss: 2.248905]\n",
      "epoch:17 step:13547 [D loss: 0.897692, acc: 28.91%] [G loss: 1.370211]\n",
      "epoch:17 step:13548 [D loss: 0.508855, acc: 82.03%] [G loss: 2.326990]\n",
      "epoch:17 step:13549 [D loss: 0.679722, acc: 60.94%] [G loss: 1.963666]\n",
      "epoch:17 step:13550 [D loss: 0.967053, acc: 20.31%] [G loss: 1.673593]\n",
      "epoch:17 step:13551 [D loss: 0.735965, acc: 51.56%] [G loss: 1.822291]\n",
      "epoch:17 step:13552 [D loss: 0.683802, acc: 57.03%] [G loss: 1.919918]\n",
      "epoch:17 step:13553 [D loss: 0.623366, acc: 71.88%] [G loss: 1.528996]\n",
      "epoch:17 step:13554 [D loss: 1.143671, acc: 20.31%] [G loss: 1.536440]\n",
      "epoch:17 step:13555 [D loss: 0.643386, acc: 60.94%] [G loss: 2.012220]\n",
      "epoch:17 step:13556 [D loss: 0.515431, acc: 76.56%] [G loss: 1.881472]\n",
      "epoch:17 step:13557 [D loss: 0.621227, acc: 65.62%] [G loss: 1.941068]\n",
      "epoch:17 step:13558 [D loss: 0.610316, acc: 64.84%] [G loss: 2.159348]\n",
      "epoch:17 step:13559 [D loss: 0.728103, acc: 42.97%] [G loss: 1.902443]\n",
      "epoch:17 step:13560 [D loss: 0.482750, acc: 90.62%] [G loss: 2.028594]\n",
      "epoch:17 step:13561 [D loss: 0.521200, acc: 70.31%] [G loss: 2.210428]\n",
      "epoch:17 step:13562 [D loss: 0.648281, acc: 65.62%] [G loss: 2.140265]\n",
      "epoch:17 step:13563 [D loss: 0.588619, acc: 71.09%] [G loss: 2.780601]\n",
      "epoch:17 step:13564 [D loss: 0.528992, acc: 79.69%] [G loss: 1.999436]\n",
      "epoch:17 step:13565 [D loss: 0.672822, acc: 55.47%] [G loss: 1.875065]\n",
      "epoch:17 step:13566 [D loss: 0.546576, acc: 80.47%] [G loss: 1.845473]\n",
      "epoch:17 step:13567 [D loss: 0.772688, acc: 50.00%] [G loss: 1.944616]\n",
      "epoch:17 step:13568 [D loss: 0.984715, acc: 26.56%] [G loss: 1.604204]\n",
      "epoch:17 step:13569 [D loss: 0.655590, acc: 63.28%] [G loss: 2.136306]\n",
      "epoch:17 step:13570 [D loss: 0.483918, acc: 78.12%] [G loss: 2.020893]\n",
      "epoch:17 step:13571 [D loss: 0.485640, acc: 89.06%] [G loss: 2.063596]\n",
      "epoch:17 step:13572 [D loss: 0.575502, acc: 70.31%] [G loss: 2.038014]\n",
      "epoch:17 step:13573 [D loss: 0.678144, acc: 52.34%] [G loss: 2.048486]\n",
      "epoch:17 step:13574 [D loss: 0.681299, acc: 62.50%] [G loss: 2.003609]\n",
      "epoch:17 step:13575 [D loss: 0.629077, acc: 63.28%] [G loss: 2.052737]\n",
      "epoch:17 step:13576 [D loss: 0.512877, acc: 82.03%] [G loss: 2.412799]\n",
      "epoch:17 step:13577 [D loss: 0.512211, acc: 82.81%] [G loss: 2.151907]\n",
      "epoch:17 step:13578 [D loss: 0.537014, acc: 78.91%] [G loss: 1.823881]\n",
      "epoch:17 step:13579 [D loss: 0.590982, acc: 67.97%] [G loss: 1.941799]\n",
      "epoch:17 step:13580 [D loss: 0.798293, acc: 46.09%] [G loss: 1.822129]\n",
      "epoch:17 step:13581 [D loss: 0.546009, acc: 74.22%] [G loss: 1.946705]\n",
      "epoch:17 step:13582 [D loss: 0.423374, acc: 96.09%] [G loss: 2.426178]\n",
      "epoch:17 step:13583 [D loss: 0.542769, acc: 77.34%] [G loss: 1.852433]\n",
      "epoch:17 step:13584 [D loss: 0.746453, acc: 47.66%] [G loss: 1.777688]\n",
      "epoch:17 step:13585 [D loss: 0.579640, acc: 71.09%] [G loss: 1.864016]\n",
      "epoch:17 step:13586 [D loss: 0.432086, acc: 92.97%] [G loss: 1.870089]\n",
      "epoch:17 step:13587 [D loss: 0.477645, acc: 79.69%] [G loss: 1.611335]\n",
      "epoch:17 step:13588 [D loss: 0.475633, acc: 89.06%] [G loss: 2.096626]\n",
      "epoch:17 step:13589 [D loss: 0.477171, acc: 86.72%] [G loss: 2.307400]\n",
      "epoch:17 step:13590 [D loss: 0.380970, acc: 95.31%] [G loss: 1.635565]\n",
      "epoch:17 step:13591 [D loss: 0.641620, acc: 61.72%] [G loss: 1.882677]\n",
      "epoch:17 step:13592 [D loss: 0.681364, acc: 62.50%] [G loss: 1.966528]\n",
      "epoch:17 step:13593 [D loss: 0.457964, acc: 82.03%] [G loss: 2.039586]\n",
      "epoch:17 step:13594 [D loss: 0.589211, acc: 71.88%] [G loss: 1.521820]\n",
      "epoch:17 step:13595 [D loss: 0.483810, acc: 72.66%] [G loss: 2.072782]\n",
      "epoch:17 step:13596 [D loss: 0.390553, acc: 95.31%] [G loss: 1.795462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13597 [D loss: 0.906532, acc: 29.69%] [G loss: 1.847925]\n",
      "epoch:17 step:13598 [D loss: 0.481486, acc: 82.03%] [G loss: 2.133251]\n",
      "epoch:17 step:13599 [D loss: 0.871421, acc: 36.72%] [G loss: 2.262213]\n",
      "epoch:17 step:13600 [D loss: 0.419659, acc: 91.41%] [G loss: 2.159808]\n",
      "epoch:17 step:13601 [D loss: 0.743239, acc: 44.53%] [G loss: 1.784710]\n",
      "epoch:17 step:13602 [D loss: 0.577867, acc: 71.88%] [G loss: 1.887585]\n",
      "epoch:17 step:13603 [D loss: 0.454861, acc: 91.41%] [G loss: 1.692835]\n",
      "epoch:17 step:13604 [D loss: 0.741675, acc: 52.34%] [G loss: 1.665226]\n",
      "epoch:17 step:13605 [D loss: 0.667443, acc: 58.59%] [G loss: 2.517001]\n",
      "epoch:17 step:13606 [D loss: 0.726356, acc: 50.78%] [G loss: 2.152913]\n",
      "epoch:17 step:13607 [D loss: 0.715506, acc: 47.66%] [G loss: 1.885087]\n",
      "epoch:17 step:13608 [D loss: 0.617330, acc: 53.91%] [G loss: 1.832492]\n",
      "epoch:17 step:13609 [D loss: 0.689371, acc: 58.59%] [G loss: 2.333100]\n",
      "epoch:17 step:13610 [D loss: 0.563316, acc: 72.66%] [G loss: 2.230156]\n",
      "epoch:17 step:13611 [D loss: 0.469482, acc: 89.84%] [G loss: 1.757418]\n",
      "epoch:17 step:13612 [D loss: 0.593943, acc: 76.56%] [G loss: 1.911839]\n",
      "epoch:17 step:13613 [D loss: 0.295682, acc: 94.53%] [G loss: 2.426603]\n",
      "epoch:17 step:13614 [D loss: 0.734245, acc: 53.91%] [G loss: 1.541971]\n",
      "epoch:17 step:13615 [D loss: 0.918031, acc: 24.22%] [G loss: 1.794696]\n",
      "epoch:17 step:13616 [D loss: 0.814405, acc: 49.22%] [G loss: 2.017211]\n",
      "epoch:17 step:13617 [D loss: 0.474884, acc: 89.84%] [G loss: 1.773282]\n",
      "epoch:17 step:13618 [D loss: 0.496301, acc: 85.16%] [G loss: 1.515454]\n",
      "epoch:17 step:13619 [D loss: 0.594836, acc: 72.66%] [G loss: 1.734732]\n",
      "epoch:17 step:13620 [D loss: 0.691413, acc: 51.56%] [G loss: 1.982385]\n",
      "epoch:17 step:13621 [D loss: 0.555134, acc: 74.22%] [G loss: 1.784208]\n",
      "epoch:17 step:13622 [D loss: 0.650764, acc: 65.62%] [G loss: 2.047052]\n",
      "epoch:17 step:13623 [D loss: 0.762720, acc: 48.44%] [G loss: 2.349065]\n",
      "epoch:17 step:13624 [D loss: 0.642431, acc: 64.84%] [G loss: 2.411690]\n",
      "epoch:17 step:13625 [D loss: 0.502901, acc: 67.19%] [G loss: 2.285630]\n",
      "epoch:17 step:13626 [D loss: 0.439414, acc: 91.41%] [G loss: 2.447997]\n",
      "epoch:17 step:13627 [D loss: 0.650131, acc: 60.94%] [G loss: 1.836978]\n",
      "epoch:17 step:13628 [D loss: 0.697122, acc: 54.69%] [G loss: 2.030489]\n",
      "epoch:17 step:13629 [D loss: 0.645595, acc: 57.03%] [G loss: 1.888203]\n",
      "epoch:17 step:13630 [D loss: 0.674688, acc: 59.38%] [G loss: 1.702504]\n",
      "epoch:17 step:13631 [D loss: 0.562355, acc: 77.34%] [G loss: 1.686492]\n",
      "epoch:17 step:13632 [D loss: 0.947735, acc: 17.97%] [G loss: 1.688300]\n",
      "epoch:17 step:13633 [D loss: 0.720933, acc: 51.56%] [G loss: 2.129290]\n",
      "epoch:17 step:13634 [D loss: 0.425245, acc: 87.50%] [G loss: 1.724575]\n",
      "epoch:17 step:13635 [D loss: 0.352302, acc: 96.88%] [G loss: 2.170893]\n",
      "epoch:17 step:13636 [D loss: 0.570058, acc: 68.75%] [G loss: 1.868304]\n",
      "epoch:17 step:13637 [D loss: 0.844988, acc: 35.94%] [G loss: 1.527194]\n",
      "epoch:17 step:13638 [D loss: 0.538753, acc: 78.91%] [G loss: 2.141161]\n",
      "epoch:17 step:13639 [D loss: 0.510465, acc: 82.81%] [G loss: 1.849607]\n",
      "epoch:17 step:13640 [D loss: 0.709293, acc: 52.34%] [G loss: 2.374283]\n",
      "epoch:17 step:13641 [D loss: 0.712713, acc: 52.34%] [G loss: 2.245490]\n",
      "epoch:17 step:13642 [D loss: 0.417511, acc: 85.94%] [G loss: 2.186382]\n",
      "epoch:17 step:13643 [D loss: 0.815718, acc: 51.56%] [G loss: 1.540888]\n",
      "epoch:17 step:13644 [D loss: 0.346271, acc: 98.44%] [G loss: 1.724557]\n",
      "epoch:17 step:13645 [D loss: 0.715563, acc: 53.12%] [G loss: 2.406687]\n",
      "epoch:17 step:13646 [D loss: 0.756639, acc: 50.78%] [G loss: 1.775259]\n",
      "epoch:17 step:13647 [D loss: 0.536437, acc: 72.66%] [G loss: 2.189103]\n",
      "epoch:17 step:13648 [D loss: 0.592192, acc: 70.31%] [G loss: 2.372606]\n",
      "epoch:17 step:13649 [D loss: 0.621088, acc: 62.50%] [G loss: 2.151369]\n",
      "epoch:17 step:13650 [D loss: 1.299910, acc: 3.91%] [G loss: 1.458031]\n",
      "epoch:17 step:13651 [D loss: 0.624391, acc: 67.19%] [G loss: 2.527395]\n",
      "epoch:17 step:13652 [D loss: 0.537168, acc: 60.16%] [G loss: 2.974183]\n",
      "epoch:17 step:13653 [D loss: 0.351938, acc: 93.75%] [G loss: 2.299001]\n",
      "epoch:17 step:13654 [D loss: 1.020502, acc: 25.00%] [G loss: 1.612439]\n",
      "epoch:17 step:13655 [D loss: 0.909376, acc: 32.81%] [G loss: 1.726876]\n",
      "epoch:17 step:13656 [D loss: 0.413729, acc: 92.97%] [G loss: 2.055720]\n",
      "epoch:17 step:13657 [D loss: 0.828014, acc: 35.16%] [G loss: 1.847285]\n",
      "epoch:17 step:13658 [D loss: 0.263466, acc: 98.44%] [G loss: 2.652642]\n",
      "epoch:17 step:13659 [D loss: 0.639960, acc: 66.41%] [G loss: 1.927916]\n",
      "epoch:17 step:13660 [D loss: 0.581478, acc: 76.56%] [G loss: 1.834532]\n",
      "epoch:17 step:13661 [D loss: 0.470619, acc: 84.38%] [G loss: 1.874671]\n",
      "epoch:17 step:13662 [D loss: 0.653582, acc: 57.81%] [G loss: 1.668517]\n",
      "epoch:17 step:13663 [D loss: 0.803646, acc: 44.53%] [G loss: 2.169730]\n",
      "epoch:17 step:13664 [D loss: 0.489876, acc: 82.03%] [G loss: 2.058362]\n",
      "epoch:17 step:13665 [D loss: 0.700381, acc: 53.12%] [G loss: 2.070773]\n",
      "epoch:17 step:13666 [D loss: 0.581374, acc: 70.31%] [G loss: 1.931838]\n",
      "epoch:17 step:13667 [D loss: 0.409954, acc: 94.53%] [G loss: 2.134654]\n",
      "epoch:17 step:13668 [D loss: 0.606063, acc: 58.59%] [G loss: 1.858056]\n",
      "epoch:17 step:13669 [D loss: 0.707109, acc: 59.38%] [G loss: 1.756384]\n",
      "epoch:17 step:13670 [D loss: 0.254404, acc: 97.66%] [G loss: 1.944486]\n",
      "epoch:17 step:13671 [D loss: 0.298686, acc: 98.44%] [G loss: 2.188910]\n",
      "epoch:17 step:13672 [D loss: 0.669221, acc: 57.03%] [G loss: 1.700192]\n",
      "epoch:17 step:13673 [D loss: 0.707800, acc: 56.25%] [G loss: 2.021416]\n",
      "epoch:17 step:13674 [D loss: 0.587908, acc: 79.69%] [G loss: 1.609527]\n",
      "epoch:17 step:13675 [D loss: 0.682837, acc: 55.47%] [G loss: 1.862040]\n",
      "epoch:17 step:13676 [D loss: 0.378650, acc: 89.84%] [G loss: 2.414388]\n",
      "epoch:17 step:13677 [D loss: 0.413476, acc: 89.84%] [G loss: 2.656688]\n",
      "epoch:17 step:13678 [D loss: 0.598820, acc: 76.56%] [G loss: 2.142720]\n",
      "epoch:17 step:13679 [D loss: 0.447776, acc: 91.41%] [G loss: 2.096833]\n",
      "epoch:17 step:13680 [D loss: 0.545893, acc: 71.88%] [G loss: 1.806673]\n",
      "epoch:17 step:13681 [D loss: 0.565301, acc: 75.78%] [G loss: 2.285786]\n",
      "epoch:17 step:13682 [D loss: 0.720406, acc: 53.91%] [G loss: 1.656403]\n",
      "epoch:17 step:13683 [D loss: 0.353147, acc: 97.66%] [G loss: 1.962235]\n",
      "epoch:17 step:13684 [D loss: 0.547212, acc: 78.12%] [G loss: 2.148163]\n",
      "epoch:17 step:13685 [D loss: 0.650783, acc: 60.94%] [G loss: 2.102210]\n",
      "epoch:17 step:13686 [D loss: 0.621762, acc: 62.50%] [G loss: 2.369271]\n",
      "epoch:17 step:13687 [D loss: 0.461579, acc: 73.44%] [G loss: 2.174565]\n",
      "epoch:17 step:13688 [D loss: 1.101463, acc: 35.16%] [G loss: 1.508201]\n",
      "epoch:17 step:13689 [D loss: 0.860483, acc: 47.66%] [G loss: 1.886524]\n",
      "epoch:17 step:13690 [D loss: 0.703134, acc: 53.91%] [G loss: 1.766451]\n",
      "epoch:17 step:13691 [D loss: 0.743411, acc: 47.66%] [G loss: 1.729585]\n",
      "epoch:17 step:13692 [D loss: 0.506838, acc: 85.94%] [G loss: 2.058541]\n",
      "epoch:17 step:13693 [D loss: 0.775823, acc: 43.75%] [G loss: 1.699210]\n",
      "epoch:17 step:13694 [D loss: 0.452839, acc: 84.38%] [G loss: 2.817017]\n",
      "epoch:17 step:13695 [D loss: 0.550073, acc: 78.91%] [G loss: 1.821687]\n",
      "epoch:17 step:13696 [D loss: 0.654400, acc: 57.81%] [G loss: 2.199949]\n",
      "epoch:17 step:13697 [D loss: 0.573232, acc: 70.31%] [G loss: 1.694478]\n",
      "epoch:17 step:13698 [D loss: 0.306333, acc: 96.88%] [G loss: 2.365433]\n",
      "epoch:17 step:13699 [D loss: 0.273122, acc: 99.22%] [G loss: 2.442210]\n",
      "epoch:17 step:13700 [D loss: 0.672216, acc: 56.25%] [G loss: 2.449067]\n",
      "epoch:17 step:13701 [D loss: 0.943610, acc: 41.41%] [G loss: 1.344718]\n",
      "epoch:17 step:13702 [D loss: 0.601746, acc: 67.97%] [G loss: 1.837318]\n",
      "epoch:17 step:13703 [D loss: 0.561978, acc: 68.75%] [G loss: 2.151047]\n",
      "epoch:17 step:13704 [D loss: 0.661795, acc: 57.81%] [G loss: 1.394904]\n",
      "epoch:17 step:13705 [D loss: 0.455388, acc: 90.62%] [G loss: 2.722898]\n",
      "epoch:17 step:13706 [D loss: 0.414408, acc: 92.19%] [G loss: 2.428019]\n",
      "epoch:17 step:13707 [D loss: 0.629877, acc: 64.84%] [G loss: 2.744719]\n",
      "epoch:17 step:13708 [D loss: 0.953259, acc: 29.69%] [G loss: 1.385207]\n",
      "epoch:17 step:13709 [D loss: 0.518736, acc: 79.69%] [G loss: 2.117099]\n",
      "epoch:17 step:13710 [D loss: 0.579252, acc: 69.53%] [G loss: 2.136298]\n",
      "epoch:17 step:13711 [D loss: 0.617691, acc: 60.94%] [G loss: 2.204269]\n",
      "epoch:17 step:13712 [D loss: 0.655795, acc: 63.28%] [G loss: 1.748103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13713 [D loss: 0.677412, acc: 55.47%] [G loss: 1.934788]\n",
      "epoch:17 step:13714 [D loss: 0.598276, acc: 60.16%] [G loss: 1.697656]\n",
      "epoch:17 step:13715 [D loss: 0.572687, acc: 59.38%] [G loss: 2.274324]\n",
      "epoch:17 step:13716 [D loss: 0.678698, acc: 57.81%] [G loss: 1.818331]\n",
      "epoch:17 step:13717 [D loss: 0.707487, acc: 53.12%] [G loss: 1.880397]\n",
      "epoch:17 step:13718 [D loss: 0.579566, acc: 72.66%] [G loss: 1.777281]\n",
      "epoch:17 step:13719 [D loss: 0.702749, acc: 55.47%] [G loss: 1.797822]\n",
      "epoch:17 step:13720 [D loss: 0.452808, acc: 82.81%] [G loss: 2.552459]\n",
      "epoch:17 step:13721 [D loss: 0.839556, acc: 35.16%] [G loss: 2.166883]\n",
      "epoch:17 step:13722 [D loss: 0.511171, acc: 71.88%] [G loss: 2.630084]\n",
      "epoch:17 step:13723 [D loss: 0.478409, acc: 83.59%] [G loss: 2.078227]\n",
      "epoch:17 step:13724 [D loss: 0.677052, acc: 53.91%] [G loss: 1.917547]\n",
      "epoch:17 step:13725 [D loss: 0.729952, acc: 50.78%] [G loss: 2.057522]\n",
      "epoch:17 step:13726 [D loss: 0.498827, acc: 89.06%] [G loss: 1.952693]\n",
      "epoch:17 step:13727 [D loss: 0.683675, acc: 59.38%] [G loss: 1.954489]\n",
      "epoch:17 step:13728 [D loss: 0.548046, acc: 78.12%] [G loss: 1.684667]\n",
      "epoch:17 step:13729 [D loss: 0.559852, acc: 67.97%] [G loss: 2.043042]\n",
      "epoch:17 step:13730 [D loss: 0.650446, acc: 53.91%] [G loss: 2.186839]\n",
      "epoch:17 step:13731 [D loss: 0.484764, acc: 83.59%] [G loss: 2.193399]\n",
      "epoch:17 step:13732 [D loss: 0.570814, acc: 61.72%] [G loss: 2.728021]\n",
      "epoch:17 step:13733 [D loss: 0.736162, acc: 56.25%] [G loss: 1.539517]\n",
      "epoch:17 step:13734 [D loss: 0.543634, acc: 78.12%] [G loss: 2.064698]\n",
      "epoch:17 step:13735 [D loss: 0.545589, acc: 76.56%] [G loss: 1.931117]\n",
      "epoch:17 step:13736 [D loss: 0.595816, acc: 74.22%] [G loss: 1.924675]\n",
      "epoch:17 step:13737 [D loss: 0.770196, acc: 39.84%] [G loss: 1.853833]\n",
      "epoch:17 step:13738 [D loss: 0.595542, acc: 75.00%] [G loss: 2.172295]\n",
      "epoch:17 step:13739 [D loss: 0.801462, acc: 34.38%] [G loss: 1.900771]\n",
      "epoch:17 step:13740 [D loss: 0.345563, acc: 89.06%] [G loss: 1.734517]\n",
      "epoch:17 step:13741 [D loss: 0.524429, acc: 80.47%] [G loss: 2.484620]\n",
      "epoch:17 step:13742 [D loss: 0.845843, acc: 30.47%] [G loss: 1.719489]\n",
      "epoch:17 step:13743 [D loss: 0.494479, acc: 86.72%] [G loss: 2.035890]\n",
      "epoch:17 step:13744 [D loss: 0.847435, acc: 42.19%] [G loss: 1.851033]\n",
      "epoch:17 step:13745 [D loss: 0.490286, acc: 79.69%] [G loss: 1.506659]\n",
      "epoch:17 step:13746 [D loss: 0.259120, acc: 99.22%] [G loss: 2.560070]\n",
      "epoch:17 step:13747 [D loss: 0.983017, acc: 22.66%] [G loss: 1.394128]\n",
      "epoch:17 step:13748 [D loss: 0.726129, acc: 48.44%] [G loss: 1.580953]\n",
      "epoch:17 step:13749 [D loss: 0.598160, acc: 63.28%] [G loss: 2.001909]\n",
      "epoch:17 step:13750 [D loss: 0.729706, acc: 47.66%] [G loss: 1.961458]\n",
      "epoch:17 step:13751 [D loss: 0.656706, acc: 57.81%] [G loss: 1.400748]\n",
      "epoch:17 step:13752 [D loss: 0.643919, acc: 57.03%] [G loss: 2.427747]\n",
      "epoch:17 step:13753 [D loss: 0.774608, acc: 50.78%] [G loss: 2.061445]\n",
      "epoch:17 step:13754 [D loss: 0.525438, acc: 71.88%] [G loss: 1.885093]\n",
      "epoch:17 step:13755 [D loss: 0.565161, acc: 66.41%] [G loss: 2.290652]\n",
      "epoch:17 step:13756 [D loss: 0.831400, acc: 45.31%] [G loss: 1.903234]\n",
      "epoch:17 step:13757 [D loss: 0.628333, acc: 63.28%] [G loss: 2.055439]\n",
      "epoch:17 step:13758 [D loss: 0.657125, acc: 65.62%] [G loss: 1.855797]\n",
      "epoch:17 step:13759 [D loss: 0.957503, acc: 27.34%] [G loss: 1.681165]\n",
      "epoch:17 step:13760 [D loss: 0.509759, acc: 79.69%] [G loss: 2.276818]\n",
      "epoch:17 step:13761 [D loss: 0.834670, acc: 39.84%] [G loss: 1.810115]\n",
      "epoch:17 step:13762 [D loss: 0.423114, acc: 92.19%] [G loss: 2.490913]\n",
      "epoch:17 step:13763 [D loss: 1.008598, acc: 17.97%] [G loss: 1.779084]\n",
      "epoch:17 step:13764 [D loss: 0.587428, acc: 68.75%] [G loss: 2.219295]\n",
      "epoch:17 step:13765 [D loss: 0.688069, acc: 52.34%] [G loss: 1.624232]\n",
      "epoch:17 step:13766 [D loss: 0.517024, acc: 80.47%] [G loss: 1.775558]\n",
      "epoch:17 step:13767 [D loss: 0.579089, acc: 78.91%] [G loss: 2.139039]\n",
      "epoch:17 step:13768 [D loss: 0.774749, acc: 42.19%] [G loss: 1.939639]\n",
      "epoch:17 step:13769 [D loss: 0.716951, acc: 44.53%] [G loss: 2.000335]\n",
      "epoch:17 step:13770 [D loss: 0.577148, acc: 77.34%] [G loss: 1.966333]\n",
      "epoch:17 step:13771 [D loss: 0.468529, acc: 71.88%] [G loss: 1.482617]\n",
      "epoch:17 step:13772 [D loss: 0.713742, acc: 54.69%] [G loss: 2.168702]\n",
      "epoch:17 step:13773 [D loss: 0.629099, acc: 60.16%] [G loss: 1.729237]\n",
      "epoch:17 step:13774 [D loss: 0.532986, acc: 75.78%] [G loss: 1.946470]\n",
      "epoch:17 step:13775 [D loss: 0.636736, acc: 62.50%] [G loss: 2.074976]\n",
      "epoch:17 step:13776 [D loss: 0.660258, acc: 57.81%] [G loss: 1.892979]\n",
      "epoch:17 step:13777 [D loss: 0.928000, acc: 21.09%] [G loss: 1.586681]\n",
      "epoch:17 step:13778 [D loss: 0.670301, acc: 64.84%] [G loss: 2.373808]\n",
      "epoch:17 step:13779 [D loss: 0.639239, acc: 69.53%] [G loss: 1.848396]\n",
      "epoch:17 step:13780 [D loss: 0.698480, acc: 53.91%] [G loss: 1.713761]\n",
      "epoch:17 step:13781 [D loss: 0.448186, acc: 84.38%] [G loss: 2.140222]\n",
      "epoch:17 step:13782 [D loss: 0.959764, acc: 22.66%] [G loss: 1.470690]\n",
      "epoch:17 step:13783 [D loss: 0.644099, acc: 65.62%] [G loss: 1.669092]\n",
      "epoch:17 step:13784 [D loss: 0.863199, acc: 31.25%] [G loss: 1.367134]\n",
      "epoch:17 step:13785 [D loss: 0.691326, acc: 59.38%] [G loss: 1.971152]\n",
      "epoch:17 step:13786 [D loss: 0.567825, acc: 75.78%] [G loss: 1.915368]\n",
      "epoch:17 step:13787 [D loss: 0.773001, acc: 35.94%] [G loss: 1.764450]\n",
      "epoch:17 step:13788 [D loss: 0.423625, acc: 92.97%] [G loss: 1.889495]\n",
      "epoch:17 step:13789 [D loss: 0.793328, acc: 35.16%] [G loss: 1.625671]\n",
      "epoch:17 step:13790 [D loss: 0.603141, acc: 63.28%] [G loss: 2.058985]\n",
      "epoch:17 step:13791 [D loss: 0.655709, acc: 63.28%] [G loss: 1.932619]\n",
      "epoch:17 step:13792 [D loss: 0.647377, acc: 64.06%] [G loss: 1.638672]\n",
      "epoch:17 step:13793 [D loss: 0.470853, acc: 89.84%] [G loss: 1.754187]\n",
      "epoch:17 step:13794 [D loss: 0.549946, acc: 77.34%] [G loss: 2.032858]\n",
      "epoch:17 step:13795 [D loss: 0.572203, acc: 75.00%] [G loss: 1.795249]\n",
      "epoch:17 step:13796 [D loss: 0.622377, acc: 65.62%] [G loss: 2.008993]\n",
      "epoch:17 step:13797 [D loss: 0.675855, acc: 60.16%] [G loss: 1.716856]\n",
      "epoch:17 step:13798 [D loss: 0.392651, acc: 95.31%] [G loss: 2.633780]\n",
      "epoch:17 step:13799 [D loss: 0.850323, acc: 30.47%] [G loss: 1.844492]\n",
      "epoch:17 step:13800 [D loss: 0.536741, acc: 75.78%] [G loss: 2.250079]\n",
      "epoch:17 step:13801 [D loss: 0.484410, acc: 87.50%] [G loss: 2.049857]\n",
      "epoch:17 step:13802 [D loss: 0.655540, acc: 53.91%] [G loss: 1.506617]\n",
      "epoch:17 step:13803 [D loss: 0.775853, acc: 38.28%] [G loss: 1.824342]\n",
      "epoch:17 step:13804 [D loss: 0.551640, acc: 82.03%] [G loss: 1.915469]\n",
      "epoch:17 step:13805 [D loss: 0.770979, acc: 42.19%] [G loss: 1.799941]\n",
      "epoch:17 step:13806 [D loss: 0.474495, acc: 88.28%] [G loss: 2.209612]\n",
      "epoch:17 step:13807 [D loss: 0.434595, acc: 92.19%] [G loss: 2.220778]\n",
      "epoch:17 step:13808 [D loss: 0.799533, acc: 43.75%] [G loss: 1.595364]\n",
      "epoch:17 step:13809 [D loss: 0.766850, acc: 46.09%] [G loss: 1.781572]\n",
      "epoch:17 step:13810 [D loss: 0.862703, acc: 28.91%] [G loss: 1.759742]\n",
      "epoch:17 step:13811 [D loss: 0.639208, acc: 70.31%] [G loss: 1.920829]\n",
      "epoch:17 step:13812 [D loss: 0.870695, acc: 24.22%] [G loss: 1.883428]\n",
      "epoch:17 step:13813 [D loss: 0.712905, acc: 51.56%] [G loss: 2.292174]\n",
      "epoch:17 step:13814 [D loss: 0.419739, acc: 93.75%] [G loss: 1.736636]\n",
      "epoch:17 step:13815 [D loss: 0.585285, acc: 75.00%] [G loss: 2.235333]\n",
      "epoch:17 step:13816 [D loss: 0.951141, acc: 17.97%] [G loss: 1.656627]\n",
      "epoch:17 step:13817 [D loss: 0.742759, acc: 49.22%] [G loss: 1.951381]\n",
      "epoch:17 step:13818 [D loss: 0.701608, acc: 53.12%] [G loss: 1.941182]\n",
      "epoch:17 step:13819 [D loss: 0.596497, acc: 70.31%] [G loss: 1.903092]\n",
      "epoch:17 step:13820 [D loss: 0.415460, acc: 92.97%] [G loss: 1.793933]\n",
      "epoch:17 step:13821 [D loss: 0.713334, acc: 51.56%] [G loss: 1.831345]\n",
      "epoch:17 step:13822 [D loss: 0.446027, acc: 92.19%] [G loss: 2.399373]\n",
      "epoch:17 step:13823 [D loss: 0.845227, acc: 45.31%] [G loss: 2.064414]\n",
      "epoch:17 step:13824 [D loss: 0.689753, acc: 50.78%] [G loss: 2.235418]\n",
      "epoch:17 step:13825 [D loss: 0.543944, acc: 71.09%] [G loss: 2.271591]\n",
      "epoch:17 step:13826 [D loss: 0.611595, acc: 63.28%] [G loss: 1.877222]\n",
      "epoch:17 step:13827 [D loss: 0.394118, acc: 96.09%] [G loss: 2.619052]\n",
      "epoch:17 step:13828 [D loss: 0.363411, acc: 96.09%] [G loss: 2.292683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13829 [D loss: 0.843956, acc: 27.34%] [G loss: 1.809929]\n",
      "epoch:17 step:13830 [D loss: 0.802727, acc: 39.06%] [G loss: 1.511698]\n",
      "epoch:17 step:13831 [D loss: 0.777276, acc: 38.28%] [G loss: 1.785465]\n",
      "epoch:17 step:13832 [D loss: 0.528082, acc: 72.66%] [G loss: 1.775574]\n",
      "epoch:17 step:13833 [D loss: 0.748393, acc: 47.66%] [G loss: 1.639592]\n",
      "epoch:17 step:13834 [D loss: 0.617472, acc: 67.19%] [G loss: 1.897494]\n",
      "epoch:17 step:13835 [D loss: 0.424769, acc: 89.06%] [G loss: 1.807216]\n",
      "epoch:17 step:13836 [D loss: 0.569690, acc: 71.09%] [G loss: 2.043811]\n",
      "epoch:17 step:13837 [D loss: 0.902445, acc: 24.22%] [G loss: 1.751186]\n",
      "epoch:17 step:13838 [D loss: 0.607842, acc: 64.06%] [G loss: 1.723477]\n",
      "epoch:17 step:13839 [D loss: 0.673127, acc: 59.38%] [G loss: 1.765011]\n",
      "epoch:17 step:13840 [D loss: 0.775917, acc: 46.88%] [G loss: 1.720913]\n",
      "epoch:17 step:13841 [D loss: 0.717046, acc: 50.00%] [G loss: 1.901479]\n",
      "epoch:17 step:13842 [D loss: 0.543175, acc: 71.88%] [G loss: 1.940579]\n",
      "epoch:17 step:13843 [D loss: 0.716667, acc: 51.56%] [G loss: 1.846877]\n",
      "epoch:17 step:13844 [D loss: 0.728005, acc: 50.78%] [G loss: 1.700043]\n",
      "epoch:17 step:13845 [D loss: 0.560003, acc: 68.75%] [G loss: 1.974248]\n",
      "epoch:17 step:13846 [D loss: 0.538981, acc: 84.38%] [G loss: 2.201715]\n",
      "epoch:17 step:13847 [D loss: 0.761912, acc: 43.75%] [G loss: 2.108073]\n",
      "epoch:17 step:13848 [D loss: 0.644951, acc: 61.72%] [G loss: 1.598992]\n",
      "epoch:17 step:13849 [D loss: 0.867219, acc: 28.91%] [G loss: 1.944848]\n",
      "epoch:17 step:13850 [D loss: 0.740086, acc: 42.19%] [G loss: 1.751144]\n",
      "epoch:17 step:13851 [D loss: 0.843362, acc: 35.94%] [G loss: 1.720800]\n",
      "epoch:17 step:13852 [D loss: 0.705892, acc: 53.12%] [G loss: 1.532008]\n",
      "epoch:17 step:13853 [D loss: 0.440718, acc: 91.41%] [G loss: 2.260314]\n",
      "epoch:17 step:13854 [D loss: 0.429927, acc: 92.19%] [G loss: 2.119272]\n",
      "epoch:17 step:13855 [D loss: 0.613391, acc: 67.97%] [G loss: 2.154099]\n",
      "epoch:17 step:13856 [D loss: 0.633470, acc: 66.41%] [G loss: 2.089157]\n",
      "epoch:17 step:13857 [D loss: 0.510730, acc: 82.03%] [G loss: 2.057148]\n",
      "epoch:17 step:13858 [D loss: 0.636369, acc: 63.28%] [G loss: 1.960231]\n",
      "epoch:17 step:13859 [D loss: 0.572501, acc: 74.22%] [G loss: 2.142078]\n",
      "epoch:17 step:13860 [D loss: 0.581297, acc: 75.00%] [G loss: 1.998882]\n",
      "epoch:17 step:13861 [D loss: 1.000232, acc: 13.28%] [G loss: 1.522481]\n",
      "epoch:17 step:13862 [D loss: 0.691865, acc: 53.91%] [G loss: 1.602908]\n",
      "epoch:17 step:13863 [D loss: 0.533716, acc: 75.78%] [G loss: 2.302312]\n",
      "epoch:17 step:13864 [D loss: 0.720060, acc: 53.12%] [G loss: 1.639788]\n",
      "epoch:17 step:13865 [D loss: 0.645234, acc: 63.28%] [G loss: 2.147489]\n",
      "epoch:17 step:13866 [D loss: 0.849394, acc: 31.25%] [G loss: 1.978686]\n",
      "epoch:17 step:13867 [D loss: 0.430788, acc: 94.53%] [G loss: 1.693125]\n",
      "epoch:17 step:13868 [D loss: 0.659055, acc: 60.16%] [G loss: 2.351213]\n",
      "epoch:17 step:13869 [D loss: 0.706582, acc: 52.34%] [G loss: 1.891553]\n",
      "epoch:17 step:13870 [D loss: 0.277106, acc: 98.44%] [G loss: 2.658926]\n",
      "epoch:17 step:13871 [D loss: 0.515573, acc: 83.59%] [G loss: 1.701083]\n",
      "epoch:17 step:13872 [D loss: 0.475811, acc: 83.59%] [G loss: 1.691175]\n",
      "epoch:17 step:13873 [D loss: 0.856285, acc: 30.47%] [G loss: 1.727640]\n",
      "epoch:17 step:13874 [D loss: 0.498234, acc: 85.16%] [G loss: 2.382190]\n",
      "epoch:17 step:13875 [D loss: 0.721791, acc: 51.56%] [G loss: 1.959755]\n",
      "epoch:17 step:13876 [D loss: 0.828928, acc: 36.72%] [G loss: 1.580236]\n",
      "epoch:17 step:13877 [D loss: 0.387742, acc: 89.06%] [G loss: 2.131320]\n",
      "epoch:17 step:13878 [D loss: 0.767168, acc: 42.19%] [G loss: 1.760246]\n",
      "epoch:17 step:13879 [D loss: 0.615967, acc: 69.53%] [G loss: 2.000785]\n",
      "epoch:17 step:13880 [D loss: 0.830126, acc: 36.72%] [G loss: 1.688847]\n",
      "epoch:17 step:13881 [D loss: 0.390382, acc: 89.06%] [G loss: 1.839725]\n",
      "epoch:17 step:13882 [D loss: 0.617561, acc: 65.62%] [G loss: 2.495107]\n",
      "epoch:17 step:13883 [D loss: 0.777089, acc: 41.41%] [G loss: 1.873451]\n",
      "epoch:17 step:13884 [D loss: 0.500810, acc: 80.47%] [G loss: 1.877313]\n",
      "epoch:17 step:13885 [D loss: 0.612708, acc: 70.31%] [G loss: 2.006203]\n",
      "epoch:17 step:13886 [D loss: 0.932438, acc: 28.12%] [G loss: 1.896151]\n",
      "epoch:17 step:13887 [D loss: 0.582680, acc: 64.06%] [G loss: 1.471313]\n",
      "epoch:17 step:13888 [D loss: 0.555987, acc: 75.78%] [G loss: 1.897752]\n",
      "epoch:17 step:13889 [D loss: 0.614081, acc: 71.09%] [G loss: 1.757515]\n",
      "epoch:17 step:13890 [D loss: 1.058193, acc: 16.41%] [G loss: 1.586634]\n",
      "epoch:17 step:13891 [D loss: 0.735299, acc: 52.34%] [G loss: 1.785615]\n",
      "epoch:17 step:13892 [D loss: 0.597889, acc: 67.19%] [G loss: 2.119723]\n",
      "epoch:17 step:13893 [D loss: 0.682298, acc: 57.81%] [G loss: 1.914295]\n",
      "epoch:17 step:13894 [D loss: 0.574001, acc: 75.00%] [G loss: 2.409636]\n",
      "epoch:17 step:13895 [D loss: 0.886711, acc: 40.62%] [G loss: 1.717535]\n",
      "epoch:17 step:13896 [D loss: 0.743132, acc: 44.53%] [G loss: 1.496513]\n",
      "epoch:17 step:13897 [D loss: 0.723628, acc: 50.00%] [G loss: 2.024286]\n",
      "epoch:17 step:13898 [D loss: 0.405063, acc: 89.06%] [G loss: 2.340842]\n",
      "epoch:17 step:13899 [D loss: 1.003049, acc: 11.72%] [G loss: 1.999583]\n",
      "epoch:17 step:13900 [D loss: 0.873058, acc: 32.81%] [G loss: 1.827148]\n",
      "epoch:17 step:13901 [D loss: 0.499202, acc: 81.25%] [G loss: 1.864317]\n",
      "epoch:17 step:13902 [D loss: 0.494389, acc: 88.28%] [G loss: 1.724634]\n",
      "epoch:17 step:13903 [D loss: 0.537864, acc: 80.47%] [G loss: 2.523008]\n",
      "epoch:17 step:13904 [D loss: 0.578481, acc: 67.97%] [G loss: 1.707593]\n",
      "epoch:17 step:13905 [D loss: 0.618840, acc: 69.53%] [G loss: 2.592220]\n",
      "epoch:17 step:13906 [D loss: 0.669868, acc: 55.47%] [G loss: 2.000423]\n",
      "epoch:17 step:13907 [D loss: 0.642270, acc: 66.41%] [G loss: 1.967000]\n",
      "epoch:17 step:13908 [D loss: 0.880856, acc: 28.12%] [G loss: 1.846217]\n",
      "epoch:17 step:13909 [D loss: 0.848830, acc: 46.09%] [G loss: 1.649484]\n",
      "epoch:17 step:13910 [D loss: 0.639683, acc: 64.84%] [G loss: 1.874732]\n",
      "epoch:17 step:13911 [D loss: 0.635086, acc: 57.81%] [G loss: 1.968369]\n",
      "epoch:17 step:13912 [D loss: 0.546381, acc: 71.88%] [G loss: 1.645512]\n",
      "epoch:17 step:13913 [D loss: 0.592450, acc: 70.31%] [G loss: 1.894586]\n",
      "epoch:17 step:13914 [D loss: 0.612739, acc: 67.19%] [G loss: 1.791542]\n",
      "epoch:17 step:13915 [D loss: 0.704495, acc: 51.56%] [G loss: 1.867042]\n",
      "epoch:17 step:13916 [D loss: 0.897388, acc: 32.81%] [G loss: 1.855164]\n",
      "epoch:17 step:13917 [D loss: 0.487704, acc: 89.06%] [G loss: 2.410080]\n",
      "epoch:17 step:13918 [D loss: 0.469931, acc: 89.84%] [G loss: 2.044207]\n",
      "epoch:17 step:13919 [D loss: 0.930379, acc: 19.53%] [G loss: 1.417486]\n",
      "epoch:17 step:13920 [D loss: 0.475727, acc: 82.81%] [G loss: 2.421734]\n",
      "epoch:17 step:13921 [D loss: 0.582109, acc: 72.66%] [G loss: 2.599646]\n",
      "epoch:17 step:13922 [D loss: 0.945943, acc: 16.41%] [G loss: 1.781397]\n",
      "epoch:17 step:13923 [D loss: 0.401588, acc: 90.62%] [G loss: 1.889710]\n",
      "epoch:17 step:13924 [D loss: 0.616487, acc: 60.94%] [G loss: 1.748115]\n",
      "epoch:17 step:13925 [D loss: 0.558236, acc: 78.12%] [G loss: 2.266462]\n",
      "epoch:17 step:13926 [D loss: 0.631496, acc: 64.06%] [G loss: 2.153112]\n",
      "epoch:17 step:13927 [D loss: 0.485771, acc: 88.28%] [G loss: 1.868785]\n",
      "epoch:17 step:13928 [D loss: 0.453924, acc: 73.44%] [G loss: 2.407212]\n",
      "epoch:17 step:13929 [D loss: 0.627969, acc: 61.72%] [G loss: 2.112601]\n",
      "epoch:17 step:13930 [D loss: 0.370782, acc: 96.09%] [G loss: 1.731994]\n",
      "epoch:17 step:13931 [D loss: 0.785321, acc: 46.09%] [G loss: 2.065125]\n",
      "epoch:17 step:13932 [D loss: 0.520881, acc: 84.38%] [G loss: 1.752748]\n",
      "epoch:17 step:13933 [D loss: 0.727554, acc: 50.78%] [G loss: 1.908442]\n",
      "epoch:17 step:13934 [D loss: 0.575779, acc: 75.00%] [G loss: 2.257179]\n",
      "epoch:17 step:13935 [D loss: 0.788406, acc: 35.94%] [G loss: 2.274668]\n",
      "epoch:17 step:13936 [D loss: 0.634560, acc: 60.16%] [G loss: 1.990155]\n",
      "epoch:17 step:13937 [D loss: 0.745422, acc: 50.00%] [G loss: 1.483264]\n",
      "epoch:17 step:13938 [D loss: 0.598744, acc: 69.53%] [G loss: 1.842591]\n",
      "epoch:17 step:13939 [D loss: 0.502958, acc: 71.09%] [G loss: 2.088207]\n",
      "epoch:17 step:13940 [D loss: 0.659128, acc: 60.16%] [G loss: 2.143380]\n",
      "epoch:17 step:13941 [D loss: 0.748690, acc: 50.00%] [G loss: 2.047900]\n",
      "epoch:17 step:13942 [D loss: 0.708738, acc: 54.69%] [G loss: 1.558662]\n",
      "epoch:17 step:13943 [D loss: 0.561525, acc: 75.00%] [G loss: 2.637286]\n",
      "epoch:17 step:13944 [D loss: 0.497682, acc: 83.59%] [G loss: 1.851959]\n",
      "epoch:17 step:13945 [D loss: 0.381391, acc: 89.06%] [G loss: 2.344060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13946 [D loss: 0.684313, acc: 56.25%] [G loss: 2.241099]\n",
      "epoch:17 step:13947 [D loss: 0.679127, acc: 62.50%] [G loss: 2.056245]\n",
      "epoch:17 step:13948 [D loss: 0.267845, acc: 97.66%] [G loss: 2.466521]\n",
      "epoch:17 step:13949 [D loss: 0.685791, acc: 53.91%] [G loss: 1.648331]\n",
      "epoch:17 step:13950 [D loss: 0.651337, acc: 57.03%] [G loss: 2.255657]\n",
      "epoch:17 step:13951 [D loss: 0.405828, acc: 89.06%] [G loss: 2.377246]\n",
      "epoch:17 step:13952 [D loss: 0.423048, acc: 89.06%] [G loss: 2.242718]\n",
      "epoch:17 step:13953 [D loss: 0.605154, acc: 68.75%] [G loss: 1.932527]\n",
      "epoch:17 step:13954 [D loss: 0.378249, acc: 96.88%] [G loss: 2.137967]\n",
      "epoch:17 step:13955 [D loss: 0.498796, acc: 78.91%] [G loss: 2.220263]\n",
      "epoch:17 step:13956 [D loss: 0.672881, acc: 58.59%] [G loss: 1.905344]\n",
      "epoch:17 step:13957 [D loss: 0.493618, acc: 78.91%] [G loss: 2.427971]\n",
      "epoch:17 step:13958 [D loss: 0.611628, acc: 67.19%] [G loss: 2.334484]\n",
      "epoch:17 step:13959 [D loss: 0.904469, acc: 47.66%] [G loss: 1.639384]\n",
      "epoch:17 step:13960 [D loss: 0.824351, acc: 31.25%] [G loss: 1.607599]\n",
      "epoch:17 step:13961 [D loss: 0.711807, acc: 54.69%] [G loss: 1.733778]\n",
      "epoch:17 step:13962 [D loss: 0.315896, acc: 96.88%] [G loss: 2.454371]\n",
      "epoch:17 step:13963 [D loss: 0.692410, acc: 57.81%] [G loss: 1.703367]\n",
      "epoch:17 step:13964 [D loss: 0.526109, acc: 80.47%] [G loss: 1.711376]\n",
      "epoch:17 step:13965 [D loss: 0.568349, acc: 74.22%] [G loss: 1.906097]\n",
      "epoch:17 step:13966 [D loss: 0.876155, acc: 36.72%] [G loss: 1.481609]\n",
      "epoch:17 step:13967 [D loss: 0.505700, acc: 82.03%] [G loss: 2.065668]\n",
      "epoch:17 step:13968 [D loss: 0.461052, acc: 90.62%] [G loss: 1.846453]\n",
      "epoch:17 step:13969 [D loss: 1.544960, acc: 12.50%] [G loss: 1.739725]\n",
      "epoch:17 step:13970 [D loss: 0.562701, acc: 67.19%] [G loss: 2.609853]\n",
      "epoch:17 step:13971 [D loss: 0.619218, acc: 68.75%] [G loss: 1.938830]\n",
      "epoch:17 step:13972 [D loss: 0.488500, acc: 83.59%] [G loss: 2.277864]\n",
      "epoch:17 step:13973 [D loss: 0.438380, acc: 75.78%] [G loss: 2.536347]\n",
      "epoch:17 step:13974 [D loss: 0.438665, acc: 84.38%] [G loss: 1.933629]\n",
      "epoch:17 step:13975 [D loss: 0.557728, acc: 72.66%] [G loss: 2.016723]\n",
      "epoch:17 step:13976 [D loss: 0.684698, acc: 59.38%] [G loss: 1.534229]\n",
      "epoch:17 step:13977 [D loss: 0.479998, acc: 81.25%] [G loss: 2.092036]\n",
      "epoch:17 step:13978 [D loss: 0.728090, acc: 55.47%] [G loss: 2.298915]\n",
      "epoch:17 step:13979 [D loss: 0.589150, acc: 73.44%] [G loss: 1.663091]\n",
      "epoch:17 step:13980 [D loss: 0.646855, acc: 58.59%] [G loss: 1.909499]\n",
      "epoch:17 step:13981 [D loss: 0.529643, acc: 81.25%] [G loss: 2.056590]\n",
      "epoch:17 step:13982 [D loss: 0.572726, acc: 65.62%] [G loss: 1.864090]\n",
      "epoch:17 step:13983 [D loss: 0.673415, acc: 60.16%] [G loss: 1.595477]\n",
      "epoch:17 step:13984 [D loss: 0.597022, acc: 72.66%] [G loss: 1.960855]\n",
      "epoch:17 step:13985 [D loss: 0.496441, acc: 87.50%] [G loss: 2.009469]\n",
      "epoch:17 step:13986 [D loss: 0.609028, acc: 67.19%] [G loss: 1.893947]\n",
      "epoch:17 step:13987 [D loss: 0.978930, acc: 19.53%] [G loss: 1.557699]\n",
      "epoch:17 step:13988 [D loss: 0.643652, acc: 62.50%] [G loss: 2.023705]\n",
      "epoch:17 step:13989 [D loss: 0.752021, acc: 45.31%] [G loss: 1.257070]\n",
      "epoch:17 step:13990 [D loss: 0.567695, acc: 71.88%] [G loss: 2.313371]\n",
      "epoch:17 step:13991 [D loss: 0.463899, acc: 67.97%] [G loss: 1.980672]\n",
      "epoch:17 step:13992 [D loss: 0.320699, acc: 96.88%] [G loss: 1.951368]\n",
      "epoch:17 step:13993 [D loss: 0.483928, acc: 72.66%] [G loss: 2.228566]\n",
      "epoch:17 step:13994 [D loss: 0.677814, acc: 63.28%] [G loss: 2.082694]\n",
      "epoch:17 step:13995 [D loss: 0.498943, acc: 82.03%] [G loss: 1.774450]\n",
      "epoch:17 step:13996 [D loss: 0.369487, acc: 80.47%] [G loss: 2.224189]\n",
      "epoch:17 step:13997 [D loss: 0.671970, acc: 56.25%] [G loss: 1.701102]\n",
      "epoch:17 step:13998 [D loss: 0.789288, acc: 43.75%] [G loss: 1.932447]\n",
      "epoch:17 step:13999 [D loss: 0.489219, acc: 80.47%] [G loss: 1.996497]\n",
      "epoch:17 step:14000 [D loss: 0.848821, acc: 42.97%] [G loss: 1.861555]\n",
      "epoch:17 step:14001 [D loss: 0.637588, acc: 64.84%] [G loss: 1.850391]\n",
      "epoch:17 step:14002 [D loss: 0.694999, acc: 56.25%] [G loss: 2.137848]\n",
      "epoch:17 step:14003 [D loss: 0.861996, acc: 34.38%] [G loss: 1.806803]\n",
      "epoch:17 step:14004 [D loss: 0.703496, acc: 53.12%] [G loss: 1.942914]\n",
      "epoch:17 step:14005 [D loss: 0.662192, acc: 61.72%] [G loss: 1.642613]\n",
      "epoch:17 step:14006 [D loss: 0.640005, acc: 64.84%] [G loss: 2.091202]\n",
      "epoch:17 step:14007 [D loss: 0.391057, acc: 87.50%] [G loss: 2.363014]\n",
      "epoch:17 step:14008 [D loss: 0.559241, acc: 69.53%] [G loss: 1.657736]\n",
      "epoch:17 step:14009 [D loss: 0.887198, acc: 26.56%] [G loss: 1.640838]\n",
      "epoch:17 step:14010 [D loss: 0.599894, acc: 62.50%] [G loss: 1.965140]\n",
      "epoch:17 step:14011 [D loss: 0.752677, acc: 45.31%] [G loss: 1.918152]\n",
      "epoch:17 step:14012 [D loss: 0.517156, acc: 80.47%] [G loss: 2.046666]\n",
      "epoch:17 step:14013 [D loss: 0.599085, acc: 67.19%] [G loss: 2.190733]\n",
      "epoch:17 step:14014 [D loss: 0.586300, acc: 65.62%] [G loss: 2.361935]\n",
      "epoch:17 step:14015 [D loss: 0.440957, acc: 88.28%] [G loss: 2.175118]\n",
      "epoch:17 step:14016 [D loss: 0.750238, acc: 52.34%] [G loss: 2.161981]\n",
      "epoch:17 step:14017 [D loss: 0.699674, acc: 54.69%] [G loss: 1.481800]\n",
      "epoch:17 step:14018 [D loss: 0.498967, acc: 69.53%] [G loss: 2.414112]\n",
      "epoch:17 step:14019 [D loss: 0.577793, acc: 78.12%] [G loss: 1.901443]\n",
      "epoch:17 step:14020 [D loss: 0.488480, acc: 85.94%] [G loss: 2.173644]\n",
      "epoch:17 step:14021 [D loss: 0.792901, acc: 42.19%] [G loss: 1.482221]\n",
      "epoch:17 step:14022 [D loss: 0.483833, acc: 87.50%] [G loss: 2.725060]\n",
      "epoch:17 step:14023 [D loss: 0.936981, acc: 25.00%] [G loss: 1.813997]\n",
      "epoch:17 step:14024 [D loss: 0.361325, acc: 92.19%] [G loss: 2.683337]\n",
      "epoch:17 step:14025 [D loss: 0.663927, acc: 62.50%] [G loss: 1.851127]\n",
      "epoch:17 step:14026 [D loss: 0.554727, acc: 73.44%] [G loss: 1.636664]\n",
      "epoch:17 step:14027 [D loss: 0.514600, acc: 79.69%] [G loss: 2.077994]\n",
      "epoch:17 step:14028 [D loss: 0.682170, acc: 58.59%] [G loss: 1.528734]\n",
      "epoch:17 step:14029 [D loss: 0.357066, acc: 94.53%] [G loss: 2.193379]\n",
      "epoch:17 step:14030 [D loss: 0.605993, acc: 60.16%] [G loss: 2.187693]\n",
      "epoch:17 step:14031 [D loss: 0.370902, acc: 93.75%] [G loss: 2.043848]\n",
      "epoch:17 step:14032 [D loss: 0.762032, acc: 48.44%] [G loss: 1.392330]\n",
      "epoch:17 step:14033 [D loss: 0.470691, acc: 79.69%] [G loss: 2.082984]\n",
      "epoch:17 step:14034 [D loss: 0.693979, acc: 54.69%] [G loss: 2.399379]\n",
      "epoch:17 step:14035 [D loss: 0.366258, acc: 92.19%] [G loss: 1.923766]\n",
      "epoch:17 step:14036 [D loss: 0.807601, acc: 39.06%] [G loss: 1.852707]\n",
      "epoch:17 step:14037 [D loss: 0.736669, acc: 49.22%] [G loss: 1.843969]\n",
      "epoch:17 step:14038 [D loss: 0.717946, acc: 55.47%] [G loss: 1.634028]\n",
      "epoch:17 step:14039 [D loss: 0.382620, acc: 76.56%] [G loss: 1.946774]\n",
      "epoch:17 step:14040 [D loss: 0.931478, acc: 28.91%] [G loss: 1.787563]\n",
      "epoch:17 step:14041 [D loss: 0.966679, acc: 21.09%] [G loss: 1.417220]\n",
      "epoch:17 step:14042 [D loss: 0.729416, acc: 52.34%] [G loss: 1.891664]\n",
      "epoch:17 step:14043 [D loss: 0.589724, acc: 72.66%] [G loss: 2.090814]\n",
      "epoch:17 step:14044 [D loss: 0.719923, acc: 52.34%] [G loss: 2.176172]\n",
      "epoch:17 step:14045 [D loss: 0.519119, acc: 81.25%] [G loss: 2.139340]\n",
      "epoch:17 step:14046 [D loss: 0.482332, acc: 79.69%] [G loss: 2.040855]\n",
      "epoch:17 step:14047 [D loss: 0.407289, acc: 75.00%] [G loss: 3.055128]\n",
      "epoch:17 step:14048 [D loss: 0.862700, acc: 29.69%] [G loss: 2.114805]\n",
      "epoch:17 step:14049 [D loss: 0.578652, acc: 65.62%] [G loss: 2.144301]\n",
      "epoch:17 step:14050 [D loss: 0.334310, acc: 95.31%] [G loss: 2.521166]\n",
      "epoch:17 step:14051 [D loss: 0.709033, acc: 53.91%] [G loss: 1.802873]\n",
      "epoch:17 step:14052 [D loss: 0.479871, acc: 78.12%] [G loss: 2.410659]\n",
      "epoch:17 step:14053 [D loss: 0.412939, acc: 90.62%] [G loss: 2.291989]\n",
      "epoch:17 step:14054 [D loss: 0.805311, acc: 43.75%] [G loss: 1.746029]\n",
      "epoch:17 step:14055 [D loss: 0.368352, acc: 96.09%] [G loss: 1.889531]\n",
      "epoch:17 step:14056 [D loss: 0.879687, acc: 31.25%] [G loss: 1.557152]\n",
      "epoch:17 step:14057 [D loss: 1.003755, acc: 19.53%] [G loss: 1.416022]\n",
      "epoch:17 step:14058 [D loss: 0.247639, acc: 99.22%] [G loss: 2.443880]\n",
      "epoch:18 step:14059 [D loss: 0.544777, acc: 67.19%] [G loss: 2.285264]\n",
      "epoch:18 step:14060 [D loss: 0.541095, acc: 74.22%] [G loss: 2.034013]\n",
      "epoch:18 step:14061 [D loss: 0.361023, acc: 88.28%] [G loss: 2.441507]\n",
      "epoch:18 step:14062 [D loss: 0.881821, acc: 45.31%] [G loss: 1.799787]\n",
      "epoch:18 step:14063 [D loss: 0.560516, acc: 76.56%] [G loss: 2.259288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14064 [D loss: 0.604156, acc: 63.28%] [G loss: 2.021036]\n",
      "epoch:18 step:14065 [D loss: 0.537033, acc: 60.94%] [G loss: 2.238793]\n",
      "epoch:18 step:14066 [D loss: 0.561525, acc: 61.72%] [G loss: 2.591453]\n",
      "epoch:18 step:14067 [D loss: 0.393736, acc: 93.75%] [G loss: 2.050220]\n",
      "epoch:18 step:14068 [D loss: 0.510622, acc: 84.38%] [G loss: 1.965968]\n",
      "epoch:18 step:14069 [D loss: 0.403612, acc: 84.38%] [G loss: 2.389226]\n",
      "epoch:18 step:14070 [D loss: 0.747719, acc: 53.12%] [G loss: 2.929596]\n",
      "epoch:18 step:14071 [D loss: 0.530906, acc: 78.12%] [G loss: 1.532544]\n",
      "epoch:18 step:14072 [D loss: 0.369251, acc: 92.97%] [G loss: 1.999244]\n",
      "epoch:18 step:14073 [D loss: 0.488096, acc: 81.25%] [G loss: 2.084939]\n",
      "epoch:18 step:14074 [D loss: 0.677704, acc: 62.50%] [G loss: 2.045487]\n",
      "epoch:18 step:14075 [D loss: 0.655449, acc: 65.62%] [G loss: 2.200052]\n",
      "epoch:18 step:14076 [D loss: 0.642224, acc: 61.72%] [G loss: 2.055707]\n",
      "epoch:18 step:14077 [D loss: 0.563038, acc: 70.31%] [G loss: 1.763191]\n",
      "epoch:18 step:14078 [D loss: 0.478684, acc: 73.44%] [G loss: 1.853999]\n",
      "epoch:18 step:14079 [D loss: 0.338512, acc: 96.88%] [G loss: 2.127802]\n",
      "epoch:18 step:14080 [D loss: 0.706998, acc: 55.47%] [G loss: 2.028054]\n",
      "epoch:18 step:14081 [D loss: 0.625167, acc: 64.06%] [G loss: 1.825219]\n",
      "epoch:18 step:14082 [D loss: 0.469737, acc: 83.59%] [G loss: 1.680428]\n",
      "epoch:18 step:14083 [D loss: 0.411611, acc: 90.62%] [G loss: 2.725564]\n",
      "epoch:18 step:14084 [D loss: 0.503993, acc: 82.03%] [G loss: 1.627190]\n",
      "epoch:18 step:14085 [D loss: 0.703974, acc: 54.69%] [G loss: 1.741830]\n",
      "epoch:18 step:14086 [D loss: 0.666846, acc: 61.72%] [G loss: 1.574399]\n",
      "epoch:18 step:14087 [D loss: 0.706103, acc: 57.03%] [G loss: 1.674788]\n",
      "epoch:18 step:14088 [D loss: 0.370887, acc: 82.81%] [G loss: 1.997754]\n",
      "epoch:18 step:14089 [D loss: 0.792174, acc: 43.75%] [G loss: 1.866990]\n",
      "epoch:18 step:14090 [D loss: 0.523611, acc: 80.47%] [G loss: 2.627230]\n",
      "epoch:18 step:14091 [D loss: 0.541340, acc: 69.53%] [G loss: 1.351412]\n",
      "epoch:18 step:14092 [D loss: 0.745503, acc: 52.34%] [G loss: 2.238897]\n",
      "epoch:18 step:14093 [D loss: 0.418082, acc: 73.44%] [G loss: 1.769981]\n",
      "epoch:18 step:14094 [D loss: 0.983467, acc: 21.09%] [G loss: 1.546917]\n",
      "epoch:18 step:14095 [D loss: 0.951524, acc: 50.00%] [G loss: 1.481865]\n",
      "epoch:18 step:14096 [D loss: 0.526277, acc: 78.12%] [G loss: 1.866995]\n",
      "epoch:18 step:14097 [D loss: 0.524014, acc: 77.34%] [G loss: 1.901590]\n",
      "epoch:18 step:14098 [D loss: 0.462906, acc: 77.34%] [G loss: 1.901603]\n",
      "epoch:18 step:14099 [D loss: 0.760425, acc: 43.75%] [G loss: 2.099391]\n",
      "epoch:18 step:14100 [D loss: 0.571802, acc: 72.66%] [G loss: 1.881104]\n",
      "epoch:18 step:14101 [D loss: 0.668977, acc: 53.12%] [G loss: 1.461304]\n",
      "epoch:18 step:14102 [D loss: 1.306306, acc: 8.59%] [G loss: 1.484872]\n",
      "epoch:18 step:14103 [D loss: 0.733656, acc: 50.78%] [G loss: 1.548358]\n",
      "epoch:18 step:14104 [D loss: 0.487042, acc: 87.50%] [G loss: 1.659917]\n",
      "epoch:18 step:14105 [D loss: 0.821570, acc: 32.81%] [G loss: 1.421554]\n",
      "epoch:18 step:14106 [D loss: 0.965074, acc: 22.66%] [G loss: 1.560349]\n",
      "epoch:18 step:14107 [D loss: 0.645929, acc: 62.50%] [G loss: 1.647749]\n",
      "epoch:18 step:14108 [D loss: 0.751107, acc: 47.66%] [G loss: 2.254626]\n",
      "epoch:18 step:14109 [D loss: 0.934863, acc: 36.72%] [G loss: 1.538277]\n",
      "epoch:18 step:14110 [D loss: 0.359826, acc: 92.19%] [G loss: 2.055011]\n",
      "epoch:18 step:14111 [D loss: 0.515442, acc: 76.56%] [G loss: 2.365827]\n",
      "epoch:18 step:14112 [D loss: 0.859129, acc: 32.03%] [G loss: 2.135251]\n",
      "epoch:18 step:14113 [D loss: 0.712802, acc: 53.91%] [G loss: 2.058634]\n",
      "epoch:18 step:14114 [D loss: 1.193007, acc: 10.94%] [G loss: 1.582842]\n",
      "epoch:18 step:14115 [D loss: 0.640986, acc: 60.94%] [G loss: 1.644217]\n",
      "epoch:18 step:14116 [D loss: 0.478108, acc: 87.50%] [G loss: 2.246610]\n",
      "epoch:18 step:14117 [D loss: 0.668791, acc: 60.16%] [G loss: 2.130878]\n",
      "epoch:18 step:14118 [D loss: 0.479372, acc: 89.84%] [G loss: 1.925034]\n",
      "epoch:18 step:14119 [D loss: 0.466836, acc: 79.69%] [G loss: 2.127676]\n",
      "epoch:18 step:14120 [D loss: 0.452787, acc: 88.28%] [G loss: 2.551449]\n",
      "epoch:18 step:14121 [D loss: 0.536975, acc: 78.91%] [G loss: 2.316021]\n",
      "epoch:18 step:14122 [D loss: 0.362300, acc: 88.28%] [G loss: 1.819796]\n",
      "epoch:18 step:14123 [D loss: 0.474459, acc: 83.59%] [G loss: 2.879504]\n",
      "epoch:18 step:14124 [D loss: 0.628802, acc: 58.59%] [G loss: 1.784869]\n",
      "epoch:18 step:14125 [D loss: 0.862785, acc: 28.91%] [G loss: 1.557636]\n",
      "epoch:18 step:14126 [D loss: 0.452563, acc: 78.12%] [G loss: 1.523505]\n",
      "epoch:18 step:14127 [D loss: 0.414822, acc: 90.62%] [G loss: 1.554665]\n",
      "epoch:18 step:14128 [D loss: 0.505523, acc: 75.00%] [G loss: 1.827037]\n",
      "epoch:18 step:14129 [D loss: 0.934526, acc: 34.38%] [G loss: 1.787608]\n",
      "epoch:18 step:14130 [D loss: 0.383973, acc: 94.53%] [G loss: 2.094501]\n",
      "epoch:18 step:14131 [D loss: 0.665656, acc: 58.59%] [G loss: 1.759940]\n",
      "epoch:18 step:14132 [D loss: 0.554265, acc: 62.50%] [G loss: 2.119186]\n",
      "epoch:18 step:14133 [D loss: 0.828395, acc: 50.78%] [G loss: 1.665353]\n",
      "epoch:18 step:14134 [D loss: 0.491160, acc: 79.69%] [G loss: 1.918014]\n",
      "epoch:18 step:14135 [D loss: 0.760619, acc: 42.19%] [G loss: 1.864484]\n",
      "epoch:18 step:14136 [D loss: 0.436096, acc: 90.62%] [G loss: 2.088113]\n",
      "epoch:18 step:14137 [D loss: 0.463633, acc: 92.19%] [G loss: 1.716763]\n",
      "epoch:18 step:14138 [D loss: 0.335982, acc: 96.88%] [G loss: 2.501353]\n",
      "epoch:18 step:14139 [D loss: 0.537855, acc: 74.22%] [G loss: 1.799554]\n",
      "epoch:18 step:14140 [D loss: 0.355131, acc: 94.53%] [G loss: 2.624544]\n",
      "epoch:18 step:14141 [D loss: 0.561627, acc: 75.78%] [G loss: 2.168164]\n",
      "epoch:18 step:14142 [D loss: 0.584159, acc: 66.41%] [G loss: 2.019735]\n",
      "epoch:18 step:14143 [D loss: 0.417024, acc: 94.53%] [G loss: 1.983553]\n",
      "epoch:18 step:14144 [D loss: 0.578970, acc: 69.53%] [G loss: 2.444490]\n",
      "epoch:18 step:14145 [D loss: 0.594382, acc: 60.94%] [G loss: 2.133133]\n",
      "epoch:18 step:14146 [D loss: 0.897760, acc: 28.12%] [G loss: 2.303818]\n",
      "epoch:18 step:14147 [D loss: 0.712368, acc: 52.34%] [G loss: 2.360546]\n",
      "epoch:18 step:14148 [D loss: 0.811704, acc: 40.62%] [G loss: 1.882830]\n",
      "epoch:18 step:14149 [D loss: 0.426087, acc: 85.94%] [G loss: 2.053975]\n",
      "epoch:18 step:14150 [D loss: 0.659102, acc: 62.50%] [G loss: 1.477905]\n",
      "epoch:18 step:14151 [D loss: 0.552668, acc: 79.69%] [G loss: 2.249121]\n",
      "epoch:18 step:14152 [D loss: 0.785708, acc: 45.31%] [G loss: 2.083321]\n",
      "epoch:18 step:14153 [D loss: 0.351070, acc: 92.97%] [G loss: 2.633016]\n",
      "epoch:18 step:14154 [D loss: 0.747186, acc: 49.22%] [G loss: 1.897018]\n",
      "epoch:18 step:14155 [D loss: 0.389272, acc: 93.75%] [G loss: 2.321886]\n",
      "epoch:18 step:14156 [D loss: 0.428542, acc: 91.41%] [G loss: 1.583339]\n",
      "epoch:18 step:14157 [D loss: 0.301209, acc: 99.22%] [G loss: 2.080468]\n",
      "epoch:18 step:14158 [D loss: 0.529216, acc: 79.69%] [G loss: 2.162622]\n",
      "epoch:18 step:14159 [D loss: 1.075518, acc: 11.72%] [G loss: 1.693649]\n",
      "epoch:18 step:14160 [D loss: 0.632306, acc: 62.50%] [G loss: 2.519777]\n",
      "epoch:18 step:14161 [D loss: 0.687732, acc: 57.81%] [G loss: 1.906690]\n",
      "epoch:18 step:14162 [D loss: 0.376489, acc: 83.59%] [G loss: 2.415736]\n",
      "epoch:18 step:14163 [D loss: 0.303838, acc: 87.50%] [G loss: 2.744618]\n",
      "epoch:18 step:14164 [D loss: 0.650373, acc: 57.81%] [G loss: 2.244718]\n",
      "epoch:18 step:14165 [D loss: 0.825676, acc: 50.00%] [G loss: 1.508260]\n",
      "epoch:18 step:14166 [D loss: 0.788691, acc: 41.41%] [G loss: 2.171645]\n",
      "epoch:18 step:14167 [D loss: 0.561436, acc: 67.19%] [G loss: 1.829970]\n",
      "epoch:18 step:14168 [D loss: 0.720797, acc: 52.34%] [G loss: 2.229680]\n",
      "epoch:18 step:14169 [D loss: 0.617195, acc: 59.38%] [G loss: 2.180370]\n",
      "epoch:18 step:14170 [D loss: 0.393955, acc: 87.50%] [G loss: 1.763829]\n",
      "epoch:18 step:14171 [D loss: 0.329722, acc: 96.88%] [G loss: 2.106621]\n",
      "epoch:18 step:14172 [D loss: 0.907498, acc: 23.44%] [G loss: 1.776559]\n",
      "epoch:18 step:14173 [D loss: 0.717029, acc: 50.78%] [G loss: 2.170636]\n",
      "epoch:18 step:14174 [D loss: 0.828989, acc: 32.81%] [G loss: 2.253844]\n",
      "epoch:18 step:14175 [D loss: 0.559854, acc: 68.75%] [G loss: 2.379360]\n",
      "epoch:18 step:14176 [D loss: 0.338067, acc: 96.09%] [G loss: 2.039688]\n",
      "epoch:18 step:14177 [D loss: 0.394246, acc: 91.41%] [G loss: 2.473650]\n",
      "epoch:18 step:14178 [D loss: 0.646349, acc: 60.16%] [G loss: 2.328687]\n",
      "epoch:18 step:14179 [D loss: 0.407581, acc: 89.84%] [G loss: 2.079927]\n",
      "epoch:18 step:14180 [D loss: 0.598684, acc: 67.19%] [G loss: 2.276773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14181 [D loss: 0.530897, acc: 78.91%] [G loss: 2.204133]\n",
      "epoch:18 step:14182 [D loss: 0.608033, acc: 67.97%] [G loss: 2.198881]\n",
      "epoch:18 step:14183 [D loss: 0.750148, acc: 52.34%] [G loss: 2.143660]\n",
      "epoch:18 step:14184 [D loss: 0.374518, acc: 93.75%] [G loss: 2.084868]\n",
      "epoch:18 step:14185 [D loss: 0.643961, acc: 53.12%] [G loss: 2.100295]\n",
      "epoch:18 step:14186 [D loss: 0.377384, acc: 90.62%] [G loss: 2.664821]\n",
      "epoch:18 step:14187 [D loss: 0.476665, acc: 82.03%] [G loss: 2.204974]\n",
      "epoch:18 step:14188 [D loss: 0.839290, acc: 31.25%] [G loss: 1.537399]\n",
      "epoch:18 step:14189 [D loss: 0.434643, acc: 89.06%] [G loss: 2.297188]\n",
      "epoch:18 step:14190 [D loss: 0.828748, acc: 49.22%] [G loss: 2.009919]\n",
      "epoch:18 step:14191 [D loss: 0.394049, acc: 92.19%] [G loss: 2.045623]\n",
      "epoch:18 step:14192 [D loss: 0.785558, acc: 45.31%] [G loss: 1.939633]\n",
      "epoch:18 step:14193 [D loss: 0.661306, acc: 60.16%] [G loss: 2.086616]\n",
      "epoch:18 step:14194 [D loss: 0.528851, acc: 71.88%] [G loss: 2.017607]\n",
      "epoch:18 step:14195 [D loss: 0.549161, acc: 83.59%] [G loss: 2.271151]\n",
      "epoch:18 step:14196 [D loss: 0.425944, acc: 81.25%] [G loss: 3.136893]\n",
      "epoch:18 step:14197 [D loss: 0.843918, acc: 45.31%] [G loss: 1.628057]\n",
      "epoch:18 step:14198 [D loss: 0.504721, acc: 86.72%] [G loss: 2.481391]\n",
      "epoch:18 step:14199 [D loss: 0.834544, acc: 36.72%] [G loss: 1.466301]\n",
      "epoch:18 step:14200 [D loss: 0.448480, acc: 86.72%] [G loss: 2.315303]\n",
      "epoch:18 step:14201 [D loss: 0.603901, acc: 71.09%] [G loss: 1.869999]\n",
      "epoch:18 step:14202 [D loss: 0.689008, acc: 54.69%] [G loss: 1.941366]\n",
      "epoch:18 step:14203 [D loss: 0.559082, acc: 75.78%] [G loss: 2.495832]\n",
      "epoch:18 step:14204 [D loss: 0.533932, acc: 79.69%] [G loss: 2.228794]\n",
      "epoch:18 step:14205 [D loss: 0.414135, acc: 91.41%] [G loss: 2.007434]\n",
      "epoch:18 step:14206 [D loss: 0.347550, acc: 96.88%] [G loss: 2.454617]\n",
      "epoch:18 step:14207 [D loss: 0.801652, acc: 42.97%] [G loss: 2.058555]\n",
      "epoch:18 step:14208 [D loss: 0.641939, acc: 65.62%] [G loss: 1.844164]\n",
      "epoch:18 step:14209 [D loss: 0.275162, acc: 94.53%] [G loss: 2.350721]\n",
      "epoch:18 step:14210 [D loss: 0.795797, acc: 42.19%] [G loss: 1.696431]\n",
      "epoch:18 step:14211 [D loss: 0.438219, acc: 90.62%] [G loss: 1.997419]\n",
      "epoch:18 step:14212 [D loss: 0.354997, acc: 96.09%] [G loss: 2.500102]\n",
      "epoch:18 step:14213 [D loss: 0.948686, acc: 31.25%] [G loss: 2.038100]\n",
      "epoch:18 step:14214 [D loss: 0.622891, acc: 67.19%] [G loss: 2.254786]\n",
      "epoch:18 step:14215 [D loss: 0.476477, acc: 78.12%] [G loss: 1.968886]\n",
      "epoch:18 step:14216 [D loss: 0.384288, acc: 89.84%] [G loss: 1.785378]\n",
      "epoch:18 step:14217 [D loss: 0.609748, acc: 69.53%] [G loss: 2.231482]\n",
      "epoch:18 step:14218 [D loss: 0.755179, acc: 50.00%] [G loss: 1.936884]\n",
      "epoch:18 step:14219 [D loss: 0.907124, acc: 28.12%] [G loss: 2.053727]\n",
      "epoch:18 step:14220 [D loss: 0.465411, acc: 78.12%] [G loss: 2.176942]\n",
      "epoch:18 step:14221 [D loss: 0.983902, acc: 17.97%] [G loss: 1.938154]\n",
      "epoch:18 step:14222 [D loss: 0.588009, acc: 73.44%] [G loss: 1.876420]\n",
      "epoch:18 step:14223 [D loss: 0.550704, acc: 64.06%] [G loss: 2.343249]\n",
      "epoch:18 step:14224 [D loss: 0.574423, acc: 74.22%] [G loss: 2.199045]\n",
      "epoch:18 step:14225 [D loss: 0.502216, acc: 79.69%] [G loss: 2.834483]\n",
      "epoch:18 step:14226 [D loss: 0.448478, acc: 85.94%] [G loss: 2.749985]\n",
      "epoch:18 step:14227 [D loss: 0.285048, acc: 99.22%] [G loss: 1.939574]\n",
      "epoch:18 step:14228 [D loss: 0.494593, acc: 82.03%] [G loss: 2.896229]\n",
      "epoch:18 step:14229 [D loss: 0.317176, acc: 88.28%] [G loss: 2.659008]\n",
      "epoch:18 step:14230 [D loss: 0.887076, acc: 43.75%] [G loss: 1.705953]\n",
      "epoch:18 step:14231 [D loss: 1.410745, acc: 3.91%] [G loss: 2.300264]\n",
      "epoch:18 step:14232 [D loss: 0.538829, acc: 74.22%] [G loss: 1.349733]\n",
      "epoch:18 step:14233 [D loss: 0.479092, acc: 83.59%] [G loss: 2.300572]\n",
      "epoch:18 step:14234 [D loss: 0.490881, acc: 74.22%] [G loss: 2.902227]\n",
      "epoch:18 step:14235 [D loss: 0.727113, acc: 53.91%] [G loss: 1.814993]\n",
      "epoch:18 step:14236 [D loss: 0.813948, acc: 42.19%] [G loss: 2.070916]\n",
      "epoch:18 step:14237 [D loss: 0.575965, acc: 73.44%] [G loss: 1.823676]\n",
      "epoch:18 step:14238 [D loss: 0.450120, acc: 85.94%] [G loss: 2.356999]\n",
      "epoch:18 step:14239 [D loss: 0.624204, acc: 72.66%] [G loss: 2.214105]\n",
      "epoch:18 step:14240 [D loss: 0.480565, acc: 81.25%] [G loss: 1.767433]\n",
      "epoch:18 step:14241 [D loss: 0.686512, acc: 52.34%] [G loss: 1.873683]\n",
      "epoch:18 step:14242 [D loss: 0.634215, acc: 58.59%] [G loss: 1.694725]\n",
      "epoch:18 step:14243 [D loss: 0.780456, acc: 41.41%] [G loss: 1.806743]\n",
      "epoch:18 step:14244 [D loss: 0.684036, acc: 57.81%] [G loss: 2.255380]\n",
      "epoch:18 step:14245 [D loss: 0.582686, acc: 67.97%] [G loss: 2.939836]\n",
      "epoch:18 step:14246 [D loss: 0.612514, acc: 67.97%] [G loss: 2.009440]\n",
      "epoch:18 step:14247 [D loss: 0.621739, acc: 64.06%] [G loss: 1.948995]\n",
      "epoch:18 step:14248 [D loss: 0.580501, acc: 73.44%] [G loss: 2.357364]\n",
      "epoch:18 step:14249 [D loss: 0.760246, acc: 40.62%] [G loss: 1.793541]\n",
      "epoch:18 step:14250 [D loss: 0.577541, acc: 76.56%] [G loss: 1.785910]\n",
      "epoch:18 step:14251 [D loss: 0.478426, acc: 78.12%] [G loss: 1.990136]\n",
      "epoch:18 step:14252 [D loss: 0.516208, acc: 82.03%] [G loss: 2.374988]\n",
      "epoch:18 step:14253 [D loss: 0.623160, acc: 66.41%] [G loss: 1.374043]\n",
      "epoch:18 step:14254 [D loss: 0.894146, acc: 25.78%] [G loss: 1.698516]\n",
      "epoch:18 step:14255 [D loss: 0.436407, acc: 89.84%] [G loss: 2.166096]\n",
      "epoch:18 step:14256 [D loss: 0.577533, acc: 77.34%] [G loss: 1.862631]\n",
      "epoch:18 step:14257 [D loss: 0.416600, acc: 90.62%] [G loss: 2.177590]\n",
      "epoch:18 step:14258 [D loss: 0.253681, acc: 93.75%] [G loss: 2.735549]\n",
      "epoch:18 step:14259 [D loss: 0.306410, acc: 96.09%] [G loss: 2.410541]\n",
      "epoch:18 step:14260 [D loss: 0.732536, acc: 53.12%] [G loss: 1.884299]\n",
      "epoch:18 step:14261 [D loss: 0.295074, acc: 97.66%] [G loss: 1.893288]\n",
      "epoch:18 step:14262 [D loss: 0.684652, acc: 53.12%] [G loss: 1.492750]\n",
      "epoch:18 step:14263 [D loss: 0.878703, acc: 46.88%] [G loss: 1.410758]\n",
      "epoch:18 step:14264 [D loss: 0.910056, acc: 49.22%] [G loss: 1.906999]\n",
      "epoch:18 step:14265 [D loss: 0.507814, acc: 85.94%] [G loss: 2.004251]\n",
      "epoch:18 step:14266 [D loss: 0.524525, acc: 75.78%] [G loss: 2.261234]\n",
      "epoch:18 step:14267 [D loss: 0.380340, acc: 92.97%] [G loss: 1.988347]\n",
      "epoch:18 step:14268 [D loss: 0.889320, acc: 25.00%] [G loss: 1.559233]\n",
      "epoch:18 step:14269 [D loss: 0.370454, acc: 93.75%] [G loss: 2.547076]\n",
      "epoch:18 step:14270 [D loss: 0.473810, acc: 85.16%] [G loss: 2.403608]\n",
      "epoch:18 step:14271 [D loss: 0.869294, acc: 29.69%] [G loss: 2.075782]\n",
      "epoch:18 step:14272 [D loss: 0.381729, acc: 89.06%] [G loss: 2.379330]\n",
      "epoch:18 step:14273 [D loss: 0.602309, acc: 70.31%] [G loss: 2.099831]\n",
      "epoch:18 step:14274 [D loss: 0.974007, acc: 20.31%] [G loss: 1.358582]\n",
      "epoch:18 step:14275 [D loss: 0.331294, acc: 89.06%] [G loss: 2.064105]\n",
      "epoch:18 step:14276 [D loss: 0.564882, acc: 66.41%] [G loss: 2.489075]\n",
      "epoch:18 step:14277 [D loss: 0.411832, acc: 94.53%] [G loss: 1.818007]\n",
      "epoch:18 step:14278 [D loss: 0.589424, acc: 70.31%] [G loss: 1.876415]\n",
      "epoch:18 step:14279 [D loss: 0.665876, acc: 63.28%] [G loss: 2.671839]\n",
      "epoch:18 step:14280 [D loss: 0.640815, acc: 64.84%] [G loss: 2.623350]\n",
      "epoch:18 step:14281 [D loss: 0.620342, acc: 64.06%] [G loss: 2.059050]\n",
      "epoch:18 step:14282 [D loss: 0.455557, acc: 91.41%] [G loss: 1.602236]\n",
      "epoch:18 step:14283 [D loss: 0.505802, acc: 75.00%] [G loss: 2.080720]\n",
      "epoch:18 step:14284 [D loss: 0.590598, acc: 66.41%] [G loss: 1.516534]\n",
      "epoch:18 step:14285 [D loss: 0.499673, acc: 85.94%] [G loss: 2.393912]\n",
      "epoch:18 step:14286 [D loss: 0.807648, acc: 34.38%] [G loss: 2.008083]\n",
      "epoch:18 step:14287 [D loss: 0.717456, acc: 50.78%] [G loss: 2.131142]\n",
      "epoch:18 step:14288 [D loss: 0.806214, acc: 45.31%] [G loss: 1.948350]\n",
      "epoch:18 step:14289 [D loss: 0.524675, acc: 78.12%] [G loss: 2.119692]\n",
      "epoch:18 step:14290 [D loss: 0.596797, acc: 71.88%] [G loss: 1.972986]\n",
      "epoch:18 step:14291 [D loss: 0.705637, acc: 55.47%] [G loss: 2.000064]\n",
      "epoch:18 step:14292 [D loss: 1.004021, acc: 43.75%] [G loss: 2.182167]\n",
      "epoch:18 step:14293 [D loss: 0.504402, acc: 76.56%] [G loss: 2.796114]\n",
      "epoch:18 step:14294 [D loss: 0.628897, acc: 60.94%] [G loss: 2.102384]\n",
      "epoch:18 step:14295 [D loss: 0.469852, acc: 87.50%] [G loss: 1.881690]\n",
      "epoch:18 step:14296 [D loss: 0.731911, acc: 46.88%] [G loss: 1.630602]\n",
      "epoch:18 step:14297 [D loss: 0.677800, acc: 56.25%] [G loss: 2.060410]\n",
      "epoch:18 step:14298 [D loss: 0.568585, acc: 64.84%] [G loss: 2.099239]\n",
      "epoch:18 step:14299 [D loss: 0.551421, acc: 81.25%] [G loss: 1.882632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14300 [D loss: 0.478964, acc: 86.72%] [G loss: 2.043971]\n",
      "epoch:18 step:14301 [D loss: 0.750941, acc: 44.53%] [G loss: 1.698222]\n",
      "epoch:18 step:14302 [D loss: 0.670890, acc: 57.03%] [G loss: 2.076603]\n",
      "epoch:18 step:14303 [D loss: 0.993201, acc: 17.97%] [G loss: 1.596186]\n",
      "epoch:18 step:14304 [D loss: 0.484434, acc: 88.28%] [G loss: 2.569942]\n",
      "epoch:18 step:14305 [D loss: 0.881574, acc: 27.34%] [G loss: 1.623437]\n",
      "epoch:18 step:14306 [D loss: 0.901082, acc: 28.91%] [G loss: 1.357484]\n",
      "epoch:18 step:14307 [D loss: 0.464068, acc: 86.72%] [G loss: 2.306717]\n",
      "epoch:18 step:14308 [D loss: 0.784169, acc: 42.97%] [G loss: 2.200039]\n",
      "epoch:18 step:14309 [D loss: 0.556499, acc: 75.78%] [G loss: 2.024807]\n",
      "epoch:18 step:14310 [D loss: 0.644993, acc: 63.28%] [G loss: 1.909133]\n",
      "epoch:18 step:14311 [D loss: 1.009126, acc: 32.03%] [G loss: 1.408415]\n",
      "epoch:18 step:14312 [D loss: 0.761055, acc: 44.53%] [G loss: 1.816061]\n",
      "epoch:18 step:14313 [D loss: 0.492220, acc: 85.16%] [G loss: 2.720504]\n",
      "epoch:18 step:14314 [D loss: 0.842493, acc: 32.81%] [G loss: 1.751835]\n",
      "epoch:18 step:14315 [D loss: 0.655010, acc: 59.38%] [G loss: 2.327968]\n",
      "epoch:18 step:14316 [D loss: 0.533840, acc: 83.59%] [G loss: 1.710620]\n",
      "epoch:18 step:14317 [D loss: 0.568926, acc: 70.31%] [G loss: 1.360276]\n",
      "epoch:18 step:14318 [D loss: 0.595628, acc: 68.75%] [G loss: 1.983861]\n",
      "epoch:18 step:14319 [D loss: 0.703373, acc: 54.69%] [G loss: 1.606046]\n",
      "epoch:18 step:14320 [D loss: 0.492713, acc: 84.38%] [G loss: 2.022725]\n",
      "epoch:18 step:14321 [D loss: 0.890867, acc: 34.38%] [G loss: 1.444233]\n",
      "epoch:18 step:14322 [D loss: 0.569221, acc: 67.19%] [G loss: 2.122322]\n",
      "epoch:18 step:14323 [D loss: 0.812997, acc: 47.66%] [G loss: 1.755979]\n",
      "epoch:18 step:14324 [D loss: 0.630957, acc: 68.75%] [G loss: 2.179948]\n",
      "epoch:18 step:14325 [D loss: 1.045595, acc: 19.53%] [G loss: 1.586079]\n",
      "epoch:18 step:14326 [D loss: 0.579850, acc: 64.84%] [G loss: 2.116762]\n",
      "epoch:18 step:14327 [D loss: 0.482011, acc: 91.41%] [G loss: 2.158413]\n",
      "epoch:18 step:14328 [D loss: 0.905253, acc: 34.38%] [G loss: 1.150144]\n",
      "epoch:18 step:14329 [D loss: 0.458827, acc: 89.06%] [G loss: 2.331344]\n",
      "epoch:18 step:14330 [D loss: 0.402793, acc: 89.06%] [G loss: 2.153153]\n",
      "epoch:18 step:14331 [D loss: 0.658125, acc: 57.81%] [G loss: 1.907011]\n",
      "epoch:18 step:14332 [D loss: 0.821342, acc: 41.41%] [G loss: 1.814286]\n",
      "epoch:18 step:14333 [D loss: 0.762952, acc: 44.53%] [G loss: 1.469251]\n",
      "epoch:18 step:14334 [D loss: 0.724220, acc: 48.44%] [G loss: 1.787212]\n",
      "epoch:18 step:14335 [D loss: 0.877404, acc: 39.84%] [G loss: 1.752113]\n",
      "epoch:18 step:14336 [D loss: 0.504499, acc: 80.47%] [G loss: 1.885985]\n",
      "epoch:18 step:14337 [D loss: 0.570625, acc: 72.66%] [G loss: 2.207632]\n",
      "epoch:18 step:14338 [D loss: 0.509424, acc: 81.25%] [G loss: 1.856670]\n",
      "epoch:18 step:14339 [D loss: 0.584611, acc: 70.31%] [G loss: 1.791339]\n",
      "epoch:18 step:14340 [D loss: 0.542412, acc: 75.00%] [G loss: 2.008193]\n",
      "epoch:18 step:14341 [D loss: 0.667245, acc: 57.03%] [G loss: 1.992588]\n",
      "epoch:18 step:14342 [D loss: 0.449809, acc: 92.97%] [G loss: 1.678772]\n",
      "epoch:18 step:14343 [D loss: 0.350540, acc: 95.31%] [G loss: 2.086612]\n",
      "epoch:18 step:14344 [D loss: 0.502118, acc: 85.94%] [G loss: 2.339935]\n",
      "epoch:18 step:14345 [D loss: 0.725307, acc: 54.69%] [G loss: 2.154814]\n",
      "epoch:18 step:14346 [D loss: 0.695812, acc: 52.34%] [G loss: 1.741759]\n",
      "epoch:18 step:14347 [D loss: 0.449000, acc: 93.75%] [G loss: 2.125513]\n",
      "epoch:18 step:14348 [D loss: 0.707948, acc: 54.69%] [G loss: 1.753367]\n",
      "epoch:18 step:14349 [D loss: 1.077696, acc: 13.28%] [G loss: 1.571705]\n",
      "epoch:18 step:14350 [D loss: 0.811701, acc: 36.72%] [G loss: 1.968512]\n",
      "epoch:18 step:14351 [D loss: 0.460681, acc: 86.72%] [G loss: 1.784865]\n",
      "epoch:18 step:14352 [D loss: 0.564651, acc: 74.22%] [G loss: 1.693680]\n",
      "epoch:18 step:14353 [D loss: 0.527011, acc: 76.56%] [G loss: 2.354668]\n",
      "epoch:18 step:14354 [D loss: 0.586243, acc: 75.78%] [G loss: 2.179934]\n",
      "epoch:18 step:14355 [D loss: 0.607580, acc: 71.09%] [G loss: 1.946207]\n",
      "epoch:18 step:14356 [D loss: 0.295889, acc: 95.31%] [G loss: 2.293099]\n",
      "epoch:18 step:14357 [D loss: 0.664969, acc: 59.38%] [G loss: 2.211199]\n",
      "epoch:18 step:14358 [D loss: 0.534154, acc: 80.47%] [G loss: 1.872456]\n",
      "epoch:18 step:14359 [D loss: 0.645263, acc: 60.94%] [G loss: 2.291054]\n",
      "epoch:18 step:14360 [D loss: 0.373379, acc: 95.31%] [G loss: 1.731701]\n",
      "epoch:18 step:14361 [D loss: 0.660150, acc: 57.81%] [G loss: 1.938458]\n",
      "epoch:18 step:14362 [D loss: 0.503211, acc: 83.59%] [G loss: 2.581603]\n",
      "epoch:18 step:14363 [D loss: 0.648169, acc: 57.81%] [G loss: 2.190581]\n",
      "epoch:18 step:14364 [D loss: 0.395531, acc: 91.41%] [G loss: 2.025414]\n",
      "epoch:18 step:14365 [D loss: 0.620451, acc: 65.62%] [G loss: 2.583755]\n",
      "epoch:18 step:14366 [D loss: 0.467589, acc: 87.50%] [G loss: 2.436478]\n",
      "epoch:18 step:14367 [D loss: 0.784278, acc: 43.75%] [G loss: 2.217398]\n",
      "epoch:18 step:14368 [D loss: 0.415774, acc: 83.59%] [G loss: 2.101466]\n",
      "epoch:18 step:14369 [D loss: 0.770477, acc: 39.84%] [G loss: 1.614462]\n",
      "epoch:18 step:14370 [D loss: 0.900821, acc: 27.34%] [G loss: 2.143439]\n",
      "epoch:18 step:14371 [D loss: 0.982121, acc: 21.09%] [G loss: 1.818773]\n",
      "epoch:18 step:14372 [D loss: 0.562600, acc: 75.00%] [G loss: 1.834029]\n",
      "epoch:18 step:14373 [D loss: 1.478850, acc: 2.34%] [G loss: 1.552230]\n",
      "epoch:18 step:14374 [D loss: 0.541440, acc: 82.81%] [G loss: 1.970891]\n",
      "epoch:18 step:14375 [D loss: 0.634661, acc: 59.38%] [G loss: 2.096148]\n",
      "epoch:18 step:14376 [D loss: 0.695242, acc: 51.56%] [G loss: 1.865319]\n",
      "epoch:18 step:14377 [D loss: 0.580991, acc: 67.97%] [G loss: 2.619697]\n",
      "epoch:18 step:14378 [D loss: 0.969808, acc: 39.06%] [G loss: 1.580916]\n",
      "epoch:18 step:14379 [D loss: 0.629311, acc: 56.25%] [G loss: 2.057019]\n",
      "epoch:18 step:14380 [D loss: 0.734815, acc: 46.88%] [G loss: 1.925258]\n",
      "epoch:18 step:14381 [D loss: 0.557829, acc: 73.44%] [G loss: 2.181733]\n",
      "epoch:18 step:14382 [D loss: 0.573744, acc: 72.66%] [G loss: 1.880160]\n",
      "epoch:18 step:14383 [D loss: 0.631975, acc: 63.28%] [G loss: 2.009414]\n",
      "epoch:18 step:14384 [D loss: 0.434163, acc: 86.72%] [G loss: 2.637937]\n",
      "epoch:18 step:14385 [D loss: 0.530951, acc: 73.44%] [G loss: 2.340331]\n",
      "epoch:18 step:14386 [D loss: 0.598020, acc: 66.41%] [G loss: 2.277651]\n",
      "epoch:18 step:14387 [D loss: 0.888442, acc: 23.44%] [G loss: 1.444516]\n",
      "epoch:18 step:14388 [D loss: 0.639189, acc: 67.19%] [G loss: 1.672245]\n",
      "epoch:18 step:14389 [D loss: 0.742980, acc: 54.69%] [G loss: 1.704143]\n",
      "epoch:18 step:14390 [D loss: 0.472957, acc: 89.84%] [G loss: 2.057010]\n",
      "epoch:18 step:14391 [D loss: 0.415999, acc: 89.06%] [G loss: 2.280533]\n",
      "epoch:18 step:14392 [D loss: 0.796717, acc: 46.09%] [G loss: 2.097366]\n",
      "epoch:18 step:14393 [D loss: 0.507043, acc: 78.91%] [G loss: 2.324326]\n",
      "epoch:18 step:14394 [D loss: 0.662330, acc: 55.47%] [G loss: 1.589641]\n",
      "epoch:18 step:14395 [D loss: 0.587557, acc: 66.41%] [G loss: 1.902847]\n",
      "epoch:18 step:14396 [D loss: 0.671280, acc: 58.59%] [G loss: 2.153810]\n",
      "epoch:18 step:14397 [D loss: 0.525222, acc: 79.69%] [G loss: 2.071465]\n",
      "epoch:18 step:14398 [D loss: 0.611853, acc: 66.41%] [G loss: 1.758303]\n",
      "epoch:18 step:14399 [D loss: 0.602461, acc: 69.53%] [G loss: 2.284359]\n",
      "epoch:18 step:14400 [D loss: 0.590190, acc: 73.44%] [G loss: 1.965235]\n",
      "epoch:18 step:14401 [D loss: 0.550425, acc: 60.16%] [G loss: 1.952018]\n",
      "epoch:18 step:14402 [D loss: 0.502174, acc: 83.59%] [G loss: 2.213357]\n",
      "epoch:18 step:14403 [D loss: 0.775151, acc: 52.34%] [G loss: 1.799842]\n",
      "epoch:18 step:14404 [D loss: 0.413595, acc: 95.31%] [G loss: 1.772517]\n",
      "epoch:18 step:14405 [D loss: 0.586517, acc: 65.62%] [G loss: 2.829927]\n",
      "epoch:18 step:14406 [D loss: 0.994524, acc: 27.34%] [G loss: 1.855212]\n",
      "epoch:18 step:14407 [D loss: 0.464457, acc: 88.28%] [G loss: 1.856242]\n",
      "epoch:18 step:14408 [D loss: 0.738920, acc: 48.44%] [G loss: 1.952724]\n",
      "epoch:18 step:14409 [D loss: 0.567131, acc: 75.78%] [G loss: 1.842567]\n",
      "epoch:18 step:14410 [D loss: 0.372030, acc: 97.66%] [G loss: 2.816700]\n",
      "epoch:18 step:14411 [D loss: 0.571171, acc: 70.31%] [G loss: 2.150706]\n",
      "epoch:18 step:14412 [D loss: 0.587187, acc: 71.09%] [G loss: 2.135259]\n",
      "epoch:18 step:14413 [D loss: 0.683547, acc: 60.94%] [G loss: 1.583264]\n",
      "epoch:18 step:14414 [D loss: 0.595191, acc: 75.78%] [G loss: 2.200743]\n",
      "epoch:18 step:14415 [D loss: 0.508228, acc: 83.59%] [G loss: 2.081683]\n",
      "epoch:18 step:14416 [D loss: 0.463499, acc: 82.03%] [G loss: 2.303878]\n",
      "epoch:18 step:14417 [D loss: 0.521053, acc: 79.69%] [G loss: 2.335234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14418 [D loss: 0.583588, acc: 60.16%] [G loss: 2.207984]\n",
      "epoch:18 step:14419 [D loss: 0.711171, acc: 56.25%] [G loss: 2.217804]\n",
      "epoch:18 step:14420 [D loss: 0.648079, acc: 54.69%] [G loss: 2.073289]\n",
      "epoch:18 step:14421 [D loss: 0.535876, acc: 81.25%] [G loss: 2.393636]\n",
      "epoch:18 step:14422 [D loss: 0.502836, acc: 87.50%] [G loss: 2.769079]\n",
      "epoch:18 step:14423 [D loss: 0.591492, acc: 63.28%] [G loss: 1.811736]\n",
      "epoch:18 step:14424 [D loss: 0.512436, acc: 80.47%] [G loss: 2.121647]\n",
      "epoch:18 step:14425 [D loss: 0.546005, acc: 64.06%] [G loss: 2.078811]\n",
      "epoch:18 step:14426 [D loss: 0.386967, acc: 92.97%] [G loss: 2.065234]\n",
      "epoch:18 step:14427 [D loss: 0.542177, acc: 74.22%] [G loss: 1.996207]\n",
      "epoch:18 step:14428 [D loss: 0.643405, acc: 65.62%] [G loss: 1.894188]\n",
      "epoch:18 step:14429 [D loss: 0.524791, acc: 79.69%] [G loss: 2.550776]\n",
      "epoch:18 step:14430 [D loss: 0.452469, acc: 81.25%] [G loss: 1.662740]\n",
      "epoch:18 step:14431 [D loss: 0.828864, acc: 47.66%] [G loss: 1.840577]\n",
      "epoch:18 step:14432 [D loss: 0.356844, acc: 96.88%] [G loss: 2.993822]\n",
      "epoch:18 step:14433 [D loss: 0.409483, acc: 77.34%] [G loss: 1.942658]\n",
      "epoch:18 step:14434 [D loss: 0.702622, acc: 50.78%] [G loss: 1.636745]\n",
      "epoch:18 step:14435 [D loss: 0.530384, acc: 78.91%] [G loss: 1.761411]\n",
      "epoch:18 step:14436 [D loss: 0.676166, acc: 61.72%] [G loss: 1.604807]\n",
      "epoch:18 step:14437 [D loss: 0.269878, acc: 98.44%] [G loss: 2.097622]\n",
      "epoch:18 step:14438 [D loss: 0.802567, acc: 48.44%] [G loss: 1.792715]\n",
      "epoch:18 step:14439 [D loss: 0.484720, acc: 79.69%] [G loss: 2.028521]\n",
      "epoch:18 step:14440 [D loss: 0.534837, acc: 80.47%] [G loss: 2.518456]\n",
      "epoch:18 step:14441 [D loss: 0.689501, acc: 55.47%] [G loss: 2.131531]\n",
      "epoch:18 step:14442 [D loss: 0.386251, acc: 89.84%] [G loss: 2.417156]\n",
      "epoch:18 step:14443 [D loss: 0.362297, acc: 88.28%] [G loss: 2.102196]\n",
      "epoch:18 step:14444 [D loss: 0.520350, acc: 79.69%] [G loss: 2.110473]\n",
      "epoch:18 step:14445 [D loss: 0.456609, acc: 82.03%] [G loss: 2.649028]\n",
      "epoch:18 step:14446 [D loss: 0.660850, acc: 54.69%] [G loss: 1.427280]\n",
      "epoch:18 step:14447 [D loss: 0.340312, acc: 99.22%] [G loss: 2.392423]\n",
      "epoch:18 step:14448 [D loss: 0.403890, acc: 85.94%] [G loss: 2.091243]\n",
      "epoch:18 step:14449 [D loss: 1.167581, acc: 24.22%] [G loss: 1.891372]\n",
      "epoch:18 step:14450 [D loss: 0.325781, acc: 95.31%] [G loss: 1.666289]\n",
      "epoch:18 step:14451 [D loss: 0.653431, acc: 60.16%] [G loss: 1.862795]\n",
      "epoch:18 step:14452 [D loss: 0.503572, acc: 83.59%] [G loss: 2.747437]\n",
      "epoch:18 step:14453 [D loss: 0.641173, acc: 66.41%] [G loss: 2.507355]\n",
      "epoch:18 step:14454 [D loss: 0.515372, acc: 82.03%] [G loss: 2.990245]\n",
      "epoch:18 step:14455 [D loss: 0.432707, acc: 78.12%] [G loss: 1.627500]\n",
      "epoch:18 step:14456 [D loss: 0.651998, acc: 59.38%] [G loss: 2.233839]\n",
      "epoch:18 step:14457 [D loss: 0.419899, acc: 92.19%] [G loss: 2.694512]\n",
      "epoch:18 step:14458 [D loss: 0.581800, acc: 73.44%] [G loss: 2.586964]\n",
      "epoch:18 step:14459 [D loss: 0.454398, acc: 88.28%] [G loss: 2.554030]\n",
      "epoch:18 step:14460 [D loss: 0.586132, acc: 67.97%] [G loss: 1.996967]\n",
      "epoch:18 step:14461 [D loss: 0.631445, acc: 63.28%] [G loss: 2.277309]\n",
      "epoch:18 step:14462 [D loss: 0.710659, acc: 57.03%] [G loss: 2.171613]\n",
      "epoch:18 step:14463 [D loss: 0.573490, acc: 64.84%] [G loss: 1.792498]\n",
      "epoch:18 step:14464 [D loss: 0.437291, acc: 79.69%] [G loss: 2.123317]\n",
      "epoch:18 step:14465 [D loss: 0.579711, acc: 65.62%] [G loss: 2.288326]\n",
      "epoch:18 step:14466 [D loss: 0.335970, acc: 93.75%] [G loss: 2.560466]\n",
      "epoch:18 step:14467 [D loss: 0.467120, acc: 82.81%] [G loss: 3.066582]\n",
      "epoch:18 step:14468 [D loss: 0.353281, acc: 94.53%] [G loss: 3.087189]\n",
      "epoch:18 step:14469 [D loss: 0.381258, acc: 74.22%] [G loss: 3.642506]\n",
      "epoch:18 step:14470 [D loss: 0.424547, acc: 88.28%] [G loss: 2.200577]\n",
      "epoch:18 step:14471 [D loss: 1.096170, acc: 46.88%] [G loss: 1.787830]\n",
      "epoch:18 step:14472 [D loss: 0.570611, acc: 70.31%] [G loss: 1.982648]\n",
      "epoch:18 step:14473 [D loss: 0.677763, acc: 57.81%] [G loss: 2.275026]\n",
      "epoch:18 step:14474 [D loss: 0.926151, acc: 22.66%] [G loss: 2.588946]\n",
      "epoch:18 step:14475 [D loss: 0.373234, acc: 96.09%] [G loss: 2.133595]\n",
      "epoch:18 step:14476 [D loss: 0.708283, acc: 57.03%] [G loss: 1.793841]\n",
      "epoch:18 step:14477 [D loss: 0.490564, acc: 85.16%] [G loss: 2.089965]\n",
      "epoch:18 step:14478 [D loss: 0.474318, acc: 87.50%] [G loss: 2.263780]\n",
      "epoch:18 step:14479 [D loss: 0.493895, acc: 79.69%] [G loss: 2.439611]\n",
      "epoch:18 step:14480 [D loss: 0.315258, acc: 99.22%] [G loss: 2.170308]\n",
      "epoch:18 step:14481 [D loss: 0.659708, acc: 56.25%] [G loss: 2.461086]\n",
      "epoch:18 step:14482 [D loss: 1.531304, acc: 6.25%] [G loss: 1.610139]\n",
      "epoch:18 step:14483 [D loss: 0.361228, acc: 92.19%] [G loss: 2.101734]\n",
      "epoch:18 step:14484 [D loss: 0.535867, acc: 70.31%] [G loss: 1.671479]\n",
      "epoch:18 step:14485 [D loss: 0.812251, acc: 37.50%] [G loss: 1.612517]\n",
      "epoch:18 step:14486 [D loss: 0.370425, acc: 94.53%] [G loss: 2.662199]\n",
      "epoch:18 step:14487 [D loss: 0.722370, acc: 51.56%] [G loss: 2.529676]\n",
      "epoch:18 step:14488 [D loss: 0.462461, acc: 89.06%] [G loss: 1.966864]\n",
      "epoch:18 step:14489 [D loss: 0.790154, acc: 40.62%] [G loss: 1.976601]\n",
      "epoch:18 step:14490 [D loss: 0.606869, acc: 68.75%] [G loss: 2.203295]\n",
      "epoch:18 step:14491 [D loss: 0.353576, acc: 96.88%] [G loss: 2.472218]\n",
      "epoch:18 step:14492 [D loss: 0.510449, acc: 80.47%] [G loss: 2.170188]\n",
      "epoch:18 step:14493 [D loss: 0.595812, acc: 62.50%] [G loss: 2.001917]\n",
      "epoch:18 step:14494 [D loss: 0.910557, acc: 50.00%] [G loss: 1.392630]\n",
      "epoch:18 step:14495 [D loss: 0.989848, acc: 46.09%] [G loss: 1.735846]\n",
      "epoch:18 step:14496 [D loss: 0.359860, acc: 97.66%] [G loss: 1.992937]\n",
      "epoch:18 step:14497 [D loss: 0.643715, acc: 60.94%] [G loss: 1.865182]\n",
      "epoch:18 step:14498 [D loss: 0.799952, acc: 50.00%] [G loss: 2.101147]\n",
      "epoch:18 step:14499 [D loss: 0.772697, acc: 40.62%] [G loss: 1.998434]\n",
      "epoch:18 step:14500 [D loss: 0.714304, acc: 54.69%] [G loss: 2.589902]\n",
      "epoch:18 step:14501 [D loss: 0.624887, acc: 66.41%] [G loss: 2.133249]\n",
      "epoch:18 step:14502 [D loss: 0.834643, acc: 39.06%] [G loss: 2.008966]\n",
      "epoch:18 step:14503 [D loss: 0.503941, acc: 82.81%] [G loss: 1.712852]\n",
      "epoch:18 step:14504 [D loss: 0.705157, acc: 55.47%] [G loss: 2.305869]\n",
      "epoch:18 step:14505 [D loss: 0.548660, acc: 78.91%] [G loss: 2.165914]\n",
      "epoch:18 step:14506 [D loss: 0.782424, acc: 42.19%] [G loss: 1.804395]\n",
      "epoch:18 step:14507 [D loss: 0.393604, acc: 94.53%] [G loss: 2.179174]\n",
      "epoch:18 step:14508 [D loss: 0.796665, acc: 46.88%] [G loss: 1.701687]\n",
      "epoch:18 step:14509 [D loss: 0.598602, acc: 60.16%] [G loss: 2.111883]\n",
      "epoch:18 step:14510 [D loss: 0.606753, acc: 66.41%] [G loss: 3.130362]\n",
      "epoch:18 step:14511 [D loss: 0.869341, acc: 25.78%] [G loss: 2.347041]\n",
      "epoch:18 step:14512 [D loss: 0.564840, acc: 68.75%] [G loss: 2.493503]\n",
      "epoch:18 step:14513 [D loss: 0.707260, acc: 52.34%] [G loss: 1.905251]\n",
      "epoch:18 step:14514 [D loss: 0.884371, acc: 30.47%] [G loss: 2.288095]\n",
      "epoch:18 step:14515 [D loss: 0.613925, acc: 62.50%] [G loss: 1.882010]\n",
      "epoch:18 step:14516 [D loss: 0.232633, acc: 98.44%] [G loss: 2.079685]\n",
      "epoch:18 step:14517 [D loss: 0.423045, acc: 91.41%] [G loss: 2.020630]\n",
      "epoch:18 step:14518 [D loss: 0.886987, acc: 34.38%] [G loss: 1.800713]\n",
      "epoch:18 step:14519 [D loss: 0.620663, acc: 66.41%] [G loss: 1.656618]\n",
      "epoch:18 step:14520 [D loss: 0.502686, acc: 82.81%] [G loss: 2.399377]\n",
      "epoch:18 step:14521 [D loss: 0.597106, acc: 67.97%] [G loss: 2.218872]\n",
      "epoch:18 step:14522 [D loss: 0.206918, acc: 100.00%] [G loss: 3.144481]\n",
      "epoch:18 step:14523 [D loss: 0.592801, acc: 76.56%] [G loss: 2.209507]\n",
      "epoch:18 step:14524 [D loss: 0.602361, acc: 57.81%] [G loss: 2.120908]\n",
      "epoch:18 step:14525 [D loss: 0.730940, acc: 50.00%] [G loss: 1.674845]\n",
      "epoch:18 step:14526 [D loss: 0.647497, acc: 65.62%] [G loss: 1.885701]\n",
      "epoch:18 step:14527 [D loss: 0.366995, acc: 89.84%] [G loss: 2.339581]\n",
      "epoch:18 step:14528 [D loss: 0.566597, acc: 70.31%] [G loss: 2.080020]\n",
      "epoch:18 step:14529 [D loss: 0.862127, acc: 38.28%] [G loss: 1.646327]\n",
      "epoch:18 step:14530 [D loss: 0.444378, acc: 87.50%] [G loss: 1.709927]\n",
      "epoch:18 step:14531 [D loss: 0.902307, acc: 28.91%] [G loss: 1.984850]\n",
      "epoch:18 step:14532 [D loss: 0.686243, acc: 56.25%] [G loss: 1.662479]\n",
      "epoch:18 step:14533 [D loss: 0.504567, acc: 81.25%] [G loss: 1.855692]\n",
      "epoch:18 step:14534 [D loss: 0.571030, acc: 72.66%] [G loss: 1.961769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14535 [D loss: 0.363752, acc: 84.38%] [G loss: 2.602118]\n",
      "epoch:18 step:14536 [D loss: 0.331813, acc: 97.66%] [G loss: 1.998522]\n",
      "epoch:18 step:14537 [D loss: 0.826938, acc: 41.41%] [G loss: 2.475373]\n",
      "epoch:18 step:14538 [D loss: 0.882563, acc: 25.78%] [G loss: 2.076471]\n",
      "epoch:18 step:14539 [D loss: 0.498260, acc: 64.84%] [G loss: 2.421650]\n",
      "epoch:18 step:14540 [D loss: 1.071300, acc: 22.66%] [G loss: 1.853245]\n",
      "epoch:18 step:14541 [D loss: 0.479064, acc: 64.84%] [G loss: 2.789779]\n",
      "epoch:18 step:14542 [D loss: 0.647606, acc: 53.91%] [G loss: 1.895108]\n",
      "epoch:18 step:14543 [D loss: 0.412281, acc: 85.16%] [G loss: 1.859315]\n",
      "epoch:18 step:14544 [D loss: 0.665615, acc: 52.34%] [G loss: 1.861646]\n",
      "epoch:18 step:14545 [D loss: 0.602028, acc: 62.50%] [G loss: 2.170586]\n",
      "epoch:18 step:14546 [D loss: 0.910286, acc: 27.34%] [G loss: 1.425953]\n",
      "epoch:18 step:14547 [D loss: 0.604204, acc: 61.72%] [G loss: 2.211143]\n",
      "epoch:18 step:14548 [D loss: 0.509911, acc: 81.25%] [G loss: 2.106373]\n",
      "epoch:18 step:14549 [D loss: 0.464226, acc: 83.59%] [G loss: 2.397448]\n",
      "epoch:18 step:14550 [D loss: 0.955380, acc: 44.53%] [G loss: 1.729518]\n",
      "epoch:18 step:14551 [D loss: 0.622494, acc: 67.19%] [G loss: 3.039626]\n",
      "epoch:18 step:14552 [D loss: 0.694394, acc: 54.69%] [G loss: 2.110948]\n",
      "epoch:18 step:14553 [D loss: 0.551680, acc: 78.91%] [G loss: 1.640738]\n",
      "epoch:18 step:14554 [D loss: 0.230833, acc: 97.66%] [G loss: 2.616010]\n",
      "epoch:18 step:14555 [D loss: 0.626621, acc: 64.06%] [G loss: 2.176264]\n",
      "epoch:18 step:14556 [D loss: 0.658442, acc: 61.72%] [G loss: 2.685390]\n",
      "epoch:18 step:14557 [D loss: 0.930042, acc: 21.88%] [G loss: 2.154221]\n",
      "epoch:18 step:14558 [D loss: 0.408459, acc: 80.47%] [G loss: 1.789964]\n",
      "epoch:18 step:14559 [D loss: 0.469386, acc: 64.84%] [G loss: 2.733077]\n",
      "epoch:18 step:14560 [D loss: 0.788993, acc: 51.56%] [G loss: 2.212206]\n",
      "epoch:18 step:14561 [D loss: 0.838366, acc: 43.75%] [G loss: 2.403083]\n",
      "epoch:18 step:14562 [D loss: 0.843405, acc: 28.12%] [G loss: 1.569319]\n",
      "epoch:18 step:14563 [D loss: 1.069685, acc: 15.62%] [G loss: 1.775278]\n",
      "epoch:18 step:14564 [D loss: 0.654945, acc: 60.94%] [G loss: 2.149911]\n",
      "epoch:18 step:14565 [D loss: 0.636006, acc: 61.72%] [G loss: 2.001581]\n",
      "epoch:18 step:14566 [D loss: 0.851746, acc: 28.12%] [G loss: 1.792672]\n",
      "epoch:18 step:14567 [D loss: 0.437857, acc: 87.50%] [G loss: 2.770635]\n",
      "epoch:18 step:14568 [D loss: 0.469327, acc: 83.59%] [G loss: 2.359004]\n",
      "epoch:18 step:14569 [D loss: 0.514829, acc: 75.00%] [G loss: 2.247252]\n",
      "epoch:18 step:14570 [D loss: 0.464863, acc: 92.19%] [G loss: 2.426867]\n",
      "epoch:18 step:14571 [D loss: 0.942998, acc: 26.56%] [G loss: 2.063846]\n",
      "epoch:18 step:14572 [D loss: 0.776958, acc: 42.97%] [G loss: 2.176553]\n",
      "epoch:18 step:14573 [D loss: 0.506104, acc: 82.81%] [G loss: 2.055890]\n",
      "epoch:18 step:14574 [D loss: 0.600836, acc: 71.09%] [G loss: 2.326281]\n",
      "epoch:18 step:14575 [D loss: 0.456964, acc: 91.41%] [G loss: 1.947649]\n",
      "epoch:18 step:14576 [D loss: 0.461910, acc: 71.09%] [G loss: 1.866277]\n",
      "epoch:18 step:14577 [D loss: 0.877785, acc: 30.47%] [G loss: 1.621145]\n",
      "epoch:18 step:14578 [D loss: 0.714818, acc: 50.00%] [G loss: 1.880392]\n",
      "epoch:18 step:14579 [D loss: 0.582278, acc: 66.41%] [G loss: 2.179943]\n",
      "epoch:18 step:14580 [D loss: 0.672984, acc: 59.38%] [G loss: 2.317245]\n",
      "epoch:18 step:14581 [D loss: 0.615309, acc: 64.84%] [G loss: 2.225588]\n",
      "epoch:18 step:14582 [D loss: 0.672430, acc: 61.72%] [G loss: 2.132662]\n",
      "epoch:18 step:14583 [D loss: 0.872590, acc: 36.72%] [G loss: 1.751667]\n",
      "epoch:18 step:14584 [D loss: 0.927488, acc: 39.06%] [G loss: 1.982922]\n",
      "epoch:18 step:14585 [D loss: 0.627291, acc: 67.19%] [G loss: 2.166004]\n",
      "epoch:18 step:14586 [D loss: 0.839326, acc: 44.53%] [G loss: 1.894602]\n",
      "epoch:18 step:14587 [D loss: 0.544178, acc: 76.56%] [G loss: 2.173250]\n",
      "epoch:18 step:14588 [D loss: 0.760714, acc: 42.19%] [G loss: 2.253944]\n",
      "epoch:18 step:14589 [D loss: 0.461888, acc: 75.00%] [G loss: 1.738426]\n",
      "epoch:18 step:14590 [D loss: 0.447739, acc: 87.50%] [G loss: 2.459499]\n",
      "epoch:18 step:14591 [D loss: 0.695287, acc: 53.12%] [G loss: 1.517767]\n",
      "epoch:18 step:14592 [D loss: 0.443915, acc: 92.19%] [G loss: 2.017947]\n",
      "epoch:18 step:14593 [D loss: 0.643150, acc: 56.25%] [G loss: 1.895109]\n",
      "epoch:18 step:14594 [D loss: 0.357998, acc: 96.09%] [G loss: 2.100278]\n",
      "epoch:18 step:14595 [D loss: 0.571644, acc: 73.44%] [G loss: 2.255431]\n",
      "epoch:18 step:14596 [D loss: 0.601324, acc: 68.75%] [G loss: 1.869758]\n",
      "epoch:18 step:14597 [D loss: 0.922892, acc: 35.16%] [G loss: 1.751922]\n",
      "epoch:18 step:14598 [D loss: 0.717222, acc: 51.56%] [G loss: 2.537637]\n",
      "epoch:18 step:14599 [D loss: 0.687668, acc: 60.16%] [G loss: 2.254038]\n",
      "epoch:18 step:14600 [D loss: 0.680345, acc: 53.12%] [G loss: 2.006645]\n",
      "epoch:18 step:14601 [D loss: 0.547433, acc: 74.22%] [G loss: 2.767946]\n",
      "epoch:18 step:14602 [D loss: 0.661269, acc: 61.72%] [G loss: 1.963503]\n",
      "epoch:18 step:14603 [D loss: 0.474563, acc: 88.28%] [G loss: 2.090079]\n",
      "epoch:18 step:14604 [D loss: 0.724004, acc: 50.78%] [G loss: 2.289484]\n",
      "epoch:18 step:14605 [D loss: 0.601873, acc: 67.97%] [G loss: 1.892285]\n",
      "epoch:18 step:14606 [D loss: 0.426405, acc: 77.34%] [G loss: 2.088755]\n",
      "epoch:18 step:14607 [D loss: 0.606119, acc: 68.75%] [G loss: 2.700581]\n",
      "epoch:18 step:14608 [D loss: 0.386027, acc: 95.31%] [G loss: 2.106964]\n",
      "epoch:18 step:14609 [D loss: 0.438908, acc: 92.19%] [G loss: 2.477273]\n",
      "epoch:18 step:14610 [D loss: 0.529252, acc: 79.69%] [G loss: 1.545193]\n",
      "epoch:18 step:14611 [D loss: 0.945264, acc: 48.44%] [G loss: 1.832477]\n",
      "epoch:18 step:14612 [D loss: 0.549143, acc: 75.78%] [G loss: 2.281042]\n",
      "epoch:18 step:14613 [D loss: 0.401884, acc: 94.53%] [G loss: 2.155934]\n",
      "epoch:18 step:14614 [D loss: 0.552324, acc: 77.34%] [G loss: 2.447529]\n",
      "epoch:18 step:14615 [D loss: 0.340844, acc: 96.09%] [G loss: 2.595492]\n",
      "epoch:18 step:14616 [D loss: 0.459629, acc: 75.78%] [G loss: 2.122391]\n",
      "epoch:18 step:14617 [D loss: 0.783895, acc: 46.88%] [G loss: 2.602874]\n",
      "epoch:18 step:14618 [D loss: 0.349016, acc: 95.31%] [G loss: 2.355485]\n",
      "epoch:18 step:14619 [D loss: 0.532566, acc: 75.00%] [G loss: 2.172628]\n",
      "epoch:18 step:14620 [D loss: 0.401043, acc: 82.03%] [G loss: 2.230136]\n",
      "epoch:18 step:14621 [D loss: 0.479980, acc: 81.25%] [G loss: 2.141297]\n",
      "epoch:18 step:14622 [D loss: 0.614259, acc: 64.84%] [G loss: 2.103410]\n",
      "epoch:18 step:14623 [D loss: 0.460519, acc: 86.72%] [G loss: 1.534862]\n",
      "epoch:18 step:14624 [D loss: 0.651931, acc: 62.50%] [G loss: 1.666424]\n",
      "epoch:18 step:14625 [D loss: 0.429193, acc: 90.62%] [G loss: 1.972140]\n",
      "epoch:18 step:14626 [D loss: 0.670884, acc: 63.28%] [G loss: 1.480560]\n",
      "epoch:18 step:14627 [D loss: 0.634149, acc: 55.47%] [G loss: 1.969432]\n",
      "epoch:18 step:14628 [D loss: 0.594786, acc: 65.62%] [G loss: 2.343289]\n",
      "epoch:18 step:14629 [D loss: 0.771439, acc: 48.44%] [G loss: 1.740632]\n",
      "epoch:18 step:14630 [D loss: 0.288994, acc: 95.31%] [G loss: 2.555900]\n",
      "epoch:18 step:14631 [D loss: 0.725464, acc: 56.25%] [G loss: 1.717532]\n",
      "epoch:18 step:14632 [D loss: 0.519819, acc: 78.91%] [G loss: 2.287632]\n",
      "epoch:18 step:14633 [D loss: 0.940687, acc: 25.78%] [G loss: 1.859742]\n",
      "epoch:18 step:14634 [D loss: 0.319707, acc: 96.88%] [G loss: 2.130502]\n",
      "epoch:18 step:14635 [D loss: 0.498216, acc: 83.59%] [G loss: 2.173131]\n",
      "epoch:18 step:14636 [D loss: 0.681392, acc: 64.84%] [G loss: 3.088506]\n",
      "epoch:18 step:14637 [D loss: 0.810257, acc: 46.88%] [G loss: 1.688247]\n",
      "epoch:18 step:14638 [D loss: 0.819727, acc: 35.16%] [G loss: 2.002246]\n",
      "epoch:18 step:14639 [D loss: 0.438020, acc: 70.31%] [G loss: 2.278736]\n",
      "epoch:18 step:14640 [D loss: 0.691716, acc: 57.03%] [G loss: 1.886158]\n",
      "epoch:18 step:14641 [D loss: 0.934034, acc: 20.31%] [G loss: 1.687178]\n",
      "epoch:18 step:14642 [D loss: 0.874596, acc: 30.47%] [G loss: 1.810888]\n",
      "epoch:18 step:14643 [D loss: 0.542650, acc: 74.22%] [G loss: 2.264162]\n",
      "epoch:18 step:14644 [D loss: 0.624465, acc: 62.50%] [G loss: 2.097014]\n",
      "epoch:18 step:14645 [D loss: 0.419832, acc: 89.06%] [G loss: 2.422055]\n",
      "epoch:18 step:14646 [D loss: 0.578724, acc: 75.00%] [G loss: 2.165152]\n",
      "epoch:18 step:14647 [D loss: 0.833898, acc: 38.28%] [G loss: 1.736817]\n",
      "epoch:18 step:14648 [D loss: 0.469932, acc: 86.72%] [G loss: 1.787985]\n",
      "epoch:18 step:14649 [D loss: 0.551101, acc: 71.88%] [G loss: 1.883164]\n",
      "epoch:18 step:14650 [D loss: 0.667001, acc: 60.16%] [G loss: 2.439302]\n",
      "epoch:18 step:14651 [D loss: 0.361912, acc: 97.66%] [G loss: 2.970719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14652 [D loss: 0.605707, acc: 67.97%] [G loss: 1.810857]\n",
      "epoch:18 step:14653 [D loss: 0.684881, acc: 54.69%] [G loss: 2.763774]\n",
      "epoch:18 step:14654 [D loss: 0.695999, acc: 54.69%] [G loss: 2.200078]\n",
      "epoch:18 step:14655 [D loss: 0.750403, acc: 50.00%] [G loss: 2.075473]\n",
      "epoch:18 step:14656 [D loss: 0.330753, acc: 88.28%] [G loss: 2.166780]\n",
      "epoch:18 step:14657 [D loss: 0.751176, acc: 51.56%] [G loss: 2.152296]\n",
      "epoch:18 step:14658 [D loss: 0.547161, acc: 71.09%] [G loss: 1.819560]\n",
      "epoch:18 step:14659 [D loss: 0.523366, acc: 77.34%] [G loss: 2.191162]\n",
      "epoch:18 step:14660 [D loss: 0.636945, acc: 67.19%] [G loss: 2.408354]\n",
      "epoch:18 step:14661 [D loss: 0.712979, acc: 53.12%] [G loss: 2.023505]\n",
      "epoch:18 step:14662 [D loss: 0.630523, acc: 58.59%] [G loss: 2.137107]\n",
      "epoch:18 step:14663 [D loss: 0.401350, acc: 85.94%] [G loss: 2.166396]\n",
      "epoch:18 step:14664 [D loss: 0.692179, acc: 56.25%] [G loss: 2.028791]\n",
      "epoch:18 step:14665 [D loss: 0.520032, acc: 71.09%] [G loss: 2.297312]\n",
      "epoch:18 step:14666 [D loss: 0.506506, acc: 78.91%] [G loss: 2.161431]\n",
      "epoch:18 step:14667 [D loss: 0.855581, acc: 35.94%] [G loss: 2.295179]\n",
      "epoch:18 step:14668 [D loss: 0.339968, acc: 95.31%] [G loss: 2.794492]\n",
      "epoch:18 step:14669 [D loss: 0.462678, acc: 82.03%] [G loss: 2.641690]\n",
      "epoch:18 step:14670 [D loss: 0.428704, acc: 92.19%] [G loss: 2.368262]\n",
      "epoch:18 step:14671 [D loss: 0.542442, acc: 79.69%] [G loss: 2.527095]\n",
      "epoch:18 step:14672 [D loss: 0.541406, acc: 76.56%] [G loss: 1.889196]\n",
      "epoch:18 step:14673 [D loss: 0.650125, acc: 56.25%] [G loss: 2.329398]\n",
      "epoch:18 step:14674 [D loss: 0.876853, acc: 45.31%] [G loss: 1.938503]\n",
      "epoch:18 step:14675 [D loss: 0.568316, acc: 64.84%] [G loss: 3.112877]\n",
      "epoch:18 step:14676 [D loss: 1.132431, acc: 15.62%] [G loss: 1.569896]\n",
      "epoch:18 step:14677 [D loss: 0.459543, acc: 91.41%] [G loss: 2.101716]\n",
      "epoch:18 step:14678 [D loss: 0.868195, acc: 45.31%] [G loss: 1.867857]\n",
      "epoch:18 step:14679 [D loss: 0.547643, acc: 75.78%] [G loss: 2.029705]\n",
      "epoch:18 step:14680 [D loss: 0.501231, acc: 67.19%] [G loss: 2.057964]\n",
      "epoch:18 step:14681 [D loss: 0.598895, acc: 66.41%] [G loss: 2.268013]\n",
      "epoch:18 step:14682 [D loss: 0.618736, acc: 60.16%] [G loss: 2.459748]\n",
      "epoch:18 step:14683 [D loss: 0.535651, acc: 63.28%] [G loss: 2.439230]\n",
      "epoch:18 step:14684 [D loss: 0.435696, acc: 92.19%] [G loss: 2.754675]\n",
      "epoch:18 step:14685 [D loss: 0.719525, acc: 53.91%] [G loss: 2.400222]\n",
      "epoch:18 step:14686 [D loss: 0.480967, acc: 77.34%] [G loss: 2.369921]\n",
      "epoch:18 step:14687 [D loss: 0.638160, acc: 64.06%] [G loss: 2.530136]\n",
      "epoch:18 step:14688 [D loss: 0.365618, acc: 92.97%] [G loss: 2.230540]\n",
      "epoch:18 step:14689 [D loss: 1.005702, acc: 18.75%] [G loss: 1.902230]\n",
      "epoch:18 step:14690 [D loss: 0.715621, acc: 53.91%] [G loss: 2.339632]\n",
      "epoch:18 step:14691 [D loss: 0.545687, acc: 71.09%] [G loss: 2.989733]\n",
      "epoch:18 step:14692 [D loss: 0.540594, acc: 78.12%] [G loss: 2.076867]\n",
      "epoch:18 step:14693 [D loss: 0.543938, acc: 67.19%] [G loss: 2.300269]\n",
      "epoch:18 step:14694 [D loss: 0.526096, acc: 85.94%] [G loss: 2.011151]\n",
      "epoch:18 step:14695 [D loss: 0.763496, acc: 42.19%] [G loss: 2.037402]\n",
      "epoch:18 step:14696 [D loss: 0.774180, acc: 45.31%] [G loss: 1.490727]\n",
      "epoch:18 step:14697 [D loss: 0.644016, acc: 64.06%] [G loss: 1.957449]\n",
      "epoch:18 step:14698 [D loss: 0.269293, acc: 100.00%] [G loss: 2.198783]\n",
      "epoch:18 step:14699 [D loss: 0.322403, acc: 93.75%] [G loss: 2.656307]\n",
      "epoch:18 step:14700 [D loss: 0.539313, acc: 76.56%] [G loss: 2.477192]\n",
      "epoch:18 step:14701 [D loss: 0.645864, acc: 60.94%] [G loss: 2.287261]\n",
      "epoch:18 step:14702 [D loss: 0.482600, acc: 71.88%] [G loss: 2.694583]\n",
      "epoch:18 step:14703 [D loss: 0.790407, acc: 46.88%] [G loss: 2.146738]\n",
      "epoch:18 step:14704 [D loss: 0.488717, acc: 75.00%] [G loss: 1.584329]\n",
      "epoch:18 step:14705 [D loss: 0.762446, acc: 50.00%] [G loss: 2.285357]\n",
      "epoch:18 step:14706 [D loss: 0.562893, acc: 79.69%] [G loss: 2.022738]\n",
      "epoch:18 step:14707 [D loss: 0.466959, acc: 86.72%] [G loss: 2.460182]\n",
      "epoch:18 step:14708 [D loss: 0.778729, acc: 47.66%] [G loss: 2.473175]\n",
      "epoch:18 step:14709 [D loss: 0.352292, acc: 89.84%] [G loss: 2.756525]\n",
      "epoch:18 step:14710 [D loss: 0.273661, acc: 92.97%] [G loss: 2.176529]\n",
      "epoch:18 step:14711 [D loss: 0.335141, acc: 91.41%] [G loss: 2.136015]\n",
      "epoch:18 step:14712 [D loss: 0.616428, acc: 64.84%] [G loss: 2.101115]\n",
      "epoch:18 step:14713 [D loss: 0.849524, acc: 49.22%] [G loss: 2.433486]\n",
      "epoch:18 step:14714 [D loss: 0.739005, acc: 47.66%] [G loss: 1.687577]\n",
      "epoch:18 step:14715 [D loss: 0.680910, acc: 55.47%] [G loss: 2.277359]\n",
      "epoch:18 step:14716 [D loss: 0.298900, acc: 92.97%] [G loss: 2.637717]\n",
      "epoch:18 step:14717 [D loss: 0.536787, acc: 82.03%] [G loss: 1.696102]\n",
      "epoch:18 step:14718 [D loss: 0.923441, acc: 32.81%] [G loss: 1.940853]\n",
      "epoch:18 step:14719 [D loss: 0.729710, acc: 51.56%] [G loss: 2.135847]\n",
      "epoch:18 step:14720 [D loss: 0.557542, acc: 71.88%] [G loss: 3.226302]\n",
      "epoch:18 step:14721 [D loss: 0.446460, acc: 83.59%] [G loss: 1.846002]\n",
      "epoch:18 step:14722 [D loss: 0.647269, acc: 58.59%] [G loss: 2.029078]\n",
      "epoch:18 step:14723 [D loss: 0.534611, acc: 82.81%] [G loss: 2.028672]\n",
      "epoch:18 step:14724 [D loss: 0.320887, acc: 97.66%] [G loss: 2.508983]\n",
      "epoch:18 step:14725 [D loss: 0.332490, acc: 84.38%] [G loss: 3.972068]\n",
      "epoch:18 step:14726 [D loss: 0.646655, acc: 61.72%] [G loss: 2.051243]\n",
      "epoch:18 step:14727 [D loss: 0.656340, acc: 59.38%] [G loss: 2.097719]\n",
      "epoch:18 step:14728 [D loss: 1.174309, acc: 7.81%] [G loss: 1.966461]\n",
      "epoch:18 step:14729 [D loss: 0.432578, acc: 91.41%] [G loss: 2.719105]\n",
      "epoch:18 step:14730 [D loss: 0.574844, acc: 62.50%] [G loss: 2.023060]\n",
      "epoch:18 step:14731 [D loss: 0.653315, acc: 54.69%] [G loss: 2.301864]\n",
      "epoch:18 step:14732 [D loss: 0.453265, acc: 88.28%] [G loss: 2.284078]\n",
      "epoch:18 step:14733 [D loss: 0.473765, acc: 85.94%] [G loss: 2.318270]\n",
      "epoch:18 step:14734 [D loss: 0.372232, acc: 93.75%] [G loss: 2.309830]\n",
      "epoch:18 step:14735 [D loss: 0.548550, acc: 75.78%] [G loss: 2.231534]\n",
      "epoch:18 step:14736 [D loss: 0.391987, acc: 91.41%] [G loss: 2.445769]\n",
      "epoch:18 step:14737 [D loss: 0.833616, acc: 43.75%] [G loss: 2.127092]\n",
      "epoch:18 step:14738 [D loss: 0.420487, acc: 87.50%] [G loss: 3.906119]\n",
      "epoch:18 step:14739 [D loss: 0.508542, acc: 78.91%] [G loss: 2.105855]\n",
      "epoch:18 step:14740 [D loss: 0.995822, acc: 46.88%] [G loss: 2.302994]\n",
      "epoch:18 step:14741 [D loss: 0.521338, acc: 61.72%] [G loss: 1.926726]\n",
      "epoch:18 step:14742 [D loss: 1.365781, acc: 7.81%] [G loss: 1.652799]\n",
      "epoch:18 step:14743 [D loss: 0.983177, acc: 49.22%] [G loss: 1.522085]\n",
      "epoch:18 step:14744 [D loss: 1.044964, acc: 17.19%] [G loss: 1.564156]\n",
      "epoch:18 step:14745 [D loss: 0.725358, acc: 50.00%] [G loss: 1.941907]\n",
      "epoch:18 step:14746 [D loss: 0.396873, acc: 96.09%] [G loss: 2.127634]\n",
      "epoch:18 step:14747 [D loss: 0.637390, acc: 64.84%] [G loss: 1.977580]\n",
      "epoch:18 step:14748 [D loss: 0.619872, acc: 63.28%] [G loss: 1.727033]\n",
      "epoch:18 step:14749 [D loss: 0.794662, acc: 47.66%] [G loss: 2.194045]\n",
      "epoch:18 step:14750 [D loss: 1.221170, acc: 39.06%] [G loss: 1.923636]\n",
      "epoch:18 step:14751 [D loss: 0.478385, acc: 85.16%] [G loss: 2.060718]\n",
      "epoch:18 step:14752 [D loss: 0.722666, acc: 46.88%] [G loss: 2.780509]\n",
      "epoch:18 step:14753 [D loss: 0.568819, acc: 72.66%] [G loss: 2.235854]\n",
      "epoch:18 step:14754 [D loss: 0.500907, acc: 89.84%] [G loss: 2.334191]\n",
      "epoch:18 step:14755 [D loss: 0.756210, acc: 48.44%] [G loss: 1.985508]\n",
      "epoch:18 step:14756 [D loss: 0.424237, acc: 91.41%] [G loss: 2.443902]\n",
      "epoch:18 step:14757 [D loss: 0.746941, acc: 50.00%] [G loss: 1.894242]\n",
      "epoch:18 step:14758 [D loss: 0.388509, acc: 88.28%] [G loss: 2.585630]\n",
      "epoch:18 step:14759 [D loss: 0.696797, acc: 57.81%] [G loss: 1.995342]\n",
      "epoch:18 step:14760 [D loss: 0.485968, acc: 82.81%] [G loss: 2.563120]\n",
      "epoch:18 step:14761 [D loss: 0.563807, acc: 60.94%] [G loss: 2.416392]\n",
      "epoch:18 step:14762 [D loss: 0.695656, acc: 50.00%] [G loss: 2.496485]\n",
      "epoch:18 step:14763 [D loss: 0.665020, acc: 54.69%] [G loss: 2.883679]\n",
      "epoch:18 step:14764 [D loss: 0.335001, acc: 91.41%] [G loss: 2.273267]\n",
      "epoch:18 step:14765 [D loss: 0.698864, acc: 50.78%] [G loss: 2.344603]\n",
      "epoch:18 step:14766 [D loss: 0.621420, acc: 61.72%] [G loss: 1.948237]\n",
      "epoch:18 step:14767 [D loss: 0.546477, acc: 75.78%] [G loss: 2.063556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14768 [D loss: 0.786314, acc: 43.75%] [G loss: 2.073769]\n",
      "epoch:18 step:14769 [D loss: 0.658809, acc: 60.94%] [G loss: 1.804263]\n",
      "epoch:18 step:14770 [D loss: 0.598541, acc: 58.59%] [G loss: 1.732459]\n",
      "epoch:18 step:14771 [D loss: 0.166927, acc: 100.00%] [G loss: 2.596180]\n",
      "epoch:18 step:14772 [D loss: 0.573397, acc: 75.78%] [G loss: 2.386383]\n",
      "epoch:18 step:14773 [D loss: 0.574771, acc: 62.50%] [G loss: 1.943494]\n",
      "epoch:18 step:14774 [D loss: 0.419083, acc: 92.97%] [G loss: 2.128973]\n",
      "epoch:18 step:14775 [D loss: 0.422196, acc: 79.69%] [G loss: 2.477443]\n",
      "epoch:18 step:14776 [D loss: 0.743307, acc: 45.31%] [G loss: 1.867346]\n",
      "epoch:18 step:14777 [D loss: 0.730747, acc: 53.12%] [G loss: 2.389466]\n",
      "epoch:18 step:14778 [D loss: 0.641699, acc: 62.50%] [G loss: 1.570971]\n",
      "epoch:18 step:14779 [D loss: 0.924542, acc: 19.53%] [G loss: 1.614082]\n",
      "epoch:18 step:14780 [D loss: 0.735972, acc: 48.44%] [G loss: 2.228482]\n",
      "epoch:18 step:14781 [D loss: 0.930205, acc: 52.34%] [G loss: 2.403002]\n",
      "epoch:18 step:14782 [D loss: 0.580143, acc: 65.62%] [G loss: 2.286349]\n",
      "epoch:18 step:14783 [D loss: 0.729009, acc: 51.56%] [G loss: 1.695924]\n",
      "epoch:18 step:14784 [D loss: 0.605936, acc: 67.97%] [G loss: 1.629440]\n",
      "epoch:18 step:14785 [D loss: 0.492819, acc: 75.00%] [G loss: 1.963927]\n",
      "epoch:18 step:14786 [D loss: 0.434870, acc: 85.94%] [G loss: 2.116994]\n",
      "epoch:18 step:14787 [D loss: 0.693654, acc: 53.91%] [G loss: 1.867594]\n",
      "epoch:18 step:14788 [D loss: 0.619974, acc: 65.62%] [G loss: 2.027822]\n",
      "epoch:18 step:14789 [D loss: 0.480932, acc: 82.81%] [G loss: 2.261524]\n",
      "epoch:18 step:14790 [D loss: 0.897115, acc: 25.78%] [G loss: 1.962399]\n",
      "epoch:18 step:14791 [D loss: 0.823996, acc: 38.28%] [G loss: 1.752244]\n",
      "epoch:18 step:14792 [D loss: 0.683996, acc: 57.03%] [G loss: 1.792726]\n",
      "epoch:18 step:14793 [D loss: 0.310495, acc: 96.09%] [G loss: 2.375078]\n",
      "epoch:18 step:14794 [D loss: 0.479795, acc: 85.94%] [G loss: 2.069288]\n",
      "epoch:18 step:14795 [D loss: 0.790437, acc: 39.84%] [G loss: 2.272233]\n",
      "epoch:18 step:14796 [D loss: 0.456564, acc: 90.62%] [G loss: 2.209828]\n",
      "epoch:18 step:14797 [D loss: 0.823883, acc: 45.31%] [G loss: 1.810704]\n",
      "epoch:18 step:14798 [D loss: 0.685811, acc: 57.81%] [G loss: 2.058333]\n",
      "epoch:18 step:14799 [D loss: 0.441425, acc: 89.84%] [G loss: 2.283813]\n",
      "epoch:18 step:14800 [D loss: 0.631434, acc: 63.28%] [G loss: 2.751562]\n",
      "epoch:18 step:14801 [D loss: 0.522083, acc: 64.84%] [G loss: 2.962615]\n",
      "epoch:18 step:14802 [D loss: 0.460226, acc: 86.72%] [G loss: 2.044795]\n",
      "epoch:18 step:14803 [D loss: 0.266270, acc: 97.66%] [G loss: 2.341079]\n",
      "epoch:18 step:14804 [D loss: 0.743285, acc: 49.22%] [G loss: 2.229204]\n",
      "epoch:18 step:14805 [D loss: 0.402607, acc: 85.94%] [G loss: 2.423092]\n",
      "epoch:18 step:14806 [D loss: 0.615552, acc: 57.81%] [G loss: 3.149300]\n",
      "epoch:18 step:14807 [D loss: 0.610940, acc: 57.03%] [G loss: 2.343236]\n",
      "epoch:18 step:14808 [D loss: 0.644254, acc: 57.03%] [G loss: 2.369734]\n",
      "epoch:18 step:14809 [D loss: 0.951296, acc: 26.56%] [G loss: 1.750583]\n",
      "epoch:18 step:14810 [D loss: 0.754669, acc: 52.34%] [G loss: 2.052869]\n",
      "epoch:18 step:14811 [D loss: 0.540573, acc: 76.56%] [G loss: 2.182326]\n",
      "epoch:18 step:14812 [D loss: 0.546966, acc: 67.97%] [G loss: 2.019916]\n",
      "epoch:18 step:14813 [D loss: 0.677552, acc: 50.78%] [G loss: 1.715050]\n",
      "epoch:18 step:14814 [D loss: 0.510596, acc: 79.69%] [G loss: 2.514474]\n",
      "epoch:18 step:14815 [D loss: 0.518087, acc: 73.44%] [G loss: 1.987402]\n",
      "epoch:18 step:14816 [D loss: 0.574940, acc: 73.44%] [G loss: 2.160653]\n",
      "epoch:18 step:14817 [D loss: 0.829412, acc: 34.38%] [G loss: 1.749545]\n",
      "epoch:18 step:14818 [D loss: 0.474351, acc: 78.12%] [G loss: 2.447556]\n",
      "epoch:18 step:14819 [D loss: 0.342473, acc: 82.03%] [G loss: 2.703168]\n",
      "epoch:18 step:14820 [D loss: 0.741236, acc: 44.53%] [G loss: 1.981855]\n",
      "epoch:18 step:14821 [D loss: 0.555898, acc: 76.56%] [G loss: 1.917913]\n",
      "epoch:18 step:14822 [D loss: 0.683192, acc: 59.38%] [G loss: 2.119334]\n",
      "epoch:18 step:14823 [D loss: 0.541970, acc: 64.06%] [G loss: 2.275564]\n",
      "epoch:18 step:14824 [D loss: 0.447787, acc: 84.38%] [G loss: 2.445238]\n",
      "epoch:18 step:14825 [D loss: 0.463302, acc: 80.47%] [G loss: 2.429111]\n",
      "epoch:18 step:14826 [D loss: 0.510253, acc: 79.69%] [G loss: 2.250041]\n",
      "epoch:18 step:14827 [D loss: 0.616542, acc: 67.19%] [G loss: 2.240867]\n",
      "epoch:18 step:14828 [D loss: 0.333246, acc: 93.75%] [G loss: 2.084144]\n",
      "epoch:18 step:14829 [D loss: 0.794359, acc: 53.12%] [G loss: 1.686735]\n",
      "epoch:18 step:14830 [D loss: 0.910988, acc: 50.78%] [G loss: 2.453745]\n",
      "epoch:18 step:14831 [D loss: 0.690175, acc: 57.03%] [G loss: 1.728802]\n",
      "epoch:18 step:14832 [D loss: 0.594758, acc: 60.16%] [G loss: 2.739137]\n",
      "epoch:18 step:14833 [D loss: 0.794678, acc: 50.00%] [G loss: 2.028218]\n",
      "epoch:18 step:14834 [D loss: 0.554006, acc: 71.88%] [G loss: 2.279910]\n",
      "epoch:18 step:14835 [D loss: 1.044706, acc: 21.88%] [G loss: 2.424619]\n",
      "epoch:18 step:14836 [D loss: 0.810099, acc: 48.44%] [G loss: 2.508889]\n",
      "epoch:18 step:14837 [D loss: 0.779194, acc: 49.22%] [G loss: 2.606634]\n",
      "epoch:18 step:14838 [D loss: 0.557763, acc: 69.53%] [G loss: 1.719190]\n",
      "epoch:18 step:14839 [D loss: 0.479805, acc: 78.91%] [G loss: 2.590361]\n",
      "epoch:19 step:14840 [D loss: 0.445360, acc: 75.78%] [G loss: 2.406727]\n",
      "epoch:19 step:14841 [D loss: 0.537276, acc: 83.59%] [G loss: 2.124755]\n",
      "epoch:19 step:14842 [D loss: 0.357088, acc: 89.84%] [G loss: 2.787640]\n",
      "epoch:19 step:14843 [D loss: 0.791239, acc: 35.94%] [G loss: 2.012336]\n",
      "epoch:19 step:14844 [D loss: 0.632860, acc: 60.94%] [G loss: 1.971386]\n",
      "epoch:19 step:14845 [D loss: 0.624958, acc: 62.50%] [G loss: 1.954374]\n",
      "epoch:19 step:14846 [D loss: 0.472985, acc: 83.59%] [G loss: 2.200793]\n",
      "epoch:19 step:14847 [D loss: 0.681607, acc: 54.69%] [G loss: 1.704854]\n",
      "epoch:19 step:14848 [D loss: 0.531091, acc: 76.56%] [G loss: 1.612397]\n",
      "epoch:19 step:14849 [D loss: 0.481746, acc: 87.50%] [G loss: 1.890192]\n",
      "epoch:19 step:14850 [D loss: 0.567940, acc: 64.06%] [G loss: 2.816713]\n",
      "epoch:19 step:14851 [D loss: 0.781904, acc: 46.09%] [G loss: 1.577257]\n",
      "epoch:19 step:14852 [D loss: 0.809566, acc: 44.53%] [G loss: 2.920888]\n",
      "epoch:19 step:14853 [D loss: 0.757998, acc: 52.34%] [G loss: 1.515147]\n",
      "epoch:19 step:14854 [D loss: 0.607111, acc: 72.66%] [G loss: 3.368104]\n",
      "epoch:19 step:14855 [D loss: 0.683719, acc: 58.59%] [G loss: 1.936185]\n",
      "epoch:19 step:14856 [D loss: 0.529047, acc: 82.81%] [G loss: 2.274849]\n",
      "epoch:19 step:14857 [D loss: 0.623565, acc: 61.72%] [G loss: 2.247270]\n",
      "epoch:19 step:14858 [D loss: 0.612563, acc: 63.28%] [G loss: 1.932893]\n",
      "epoch:19 step:14859 [D loss: 0.735456, acc: 55.47%] [G loss: 2.102348]\n",
      "epoch:19 step:14860 [D loss: 0.785113, acc: 44.53%] [G loss: 2.307172]\n",
      "epoch:19 step:14861 [D loss: 0.700479, acc: 58.59%] [G loss: 1.912765]\n",
      "epoch:19 step:14862 [D loss: 0.477413, acc: 73.44%] [G loss: 2.151386]\n",
      "epoch:19 step:14863 [D loss: 0.864292, acc: 31.25%] [G loss: 1.936804]\n",
      "epoch:19 step:14864 [D loss: 0.550802, acc: 71.09%] [G loss: 1.776831]\n",
      "epoch:19 step:14865 [D loss: 0.550731, acc: 71.09%] [G loss: 2.340713]\n",
      "epoch:19 step:14866 [D loss: 0.533156, acc: 74.22%] [G loss: 1.920950]\n",
      "epoch:19 step:14867 [D loss: 0.614133, acc: 73.44%] [G loss: 2.243538]\n",
      "epoch:19 step:14868 [D loss: 0.421864, acc: 86.72%] [G loss: 3.098206]\n",
      "epoch:19 step:14869 [D loss: 0.469122, acc: 69.53%] [G loss: 2.013500]\n",
      "epoch:19 step:14870 [D loss: 0.430729, acc: 85.94%] [G loss: 2.067196]\n",
      "epoch:19 step:14871 [D loss: 0.372651, acc: 95.31%] [G loss: 3.011322]\n",
      "epoch:19 step:14872 [D loss: 0.447842, acc: 78.91%] [G loss: 2.397899]\n",
      "epoch:19 step:14873 [D loss: 1.047331, acc: 32.81%] [G loss: 1.771410]\n",
      "epoch:19 step:14874 [D loss: 0.665685, acc: 57.03%] [G loss: 2.305682]\n",
      "epoch:19 step:14875 [D loss: 0.477881, acc: 83.59%] [G loss: 2.354135]\n",
      "epoch:19 step:14876 [D loss: 0.628674, acc: 61.72%] [G loss: 2.047948]\n",
      "epoch:19 step:14877 [D loss: 1.096175, acc: 43.75%] [G loss: 1.746518]\n",
      "epoch:19 step:14878 [D loss: 0.365629, acc: 96.09%] [G loss: 1.699733]\n",
      "epoch:19 step:14879 [D loss: 0.414175, acc: 88.28%] [G loss: 2.657893]\n",
      "epoch:19 step:14880 [D loss: 0.368989, acc: 82.81%] [G loss: 3.177240]\n",
      "epoch:19 step:14881 [D loss: 0.966186, acc: 36.72%] [G loss: 1.876619]\n",
      "epoch:19 step:14882 [D loss: 0.752102, acc: 44.53%] [G loss: 2.008593]\n",
      "epoch:19 step:14883 [D loss: 0.651403, acc: 60.16%] [G loss: 1.593781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:14884 [D loss: 0.945815, acc: 31.25%] [G loss: 2.136605]\n",
      "epoch:19 step:14885 [D loss: 0.835054, acc: 43.75%] [G loss: 2.201346]\n",
      "epoch:19 step:14886 [D loss: 0.547107, acc: 64.06%] [G loss: 2.327827]\n",
      "epoch:19 step:14887 [D loss: 0.822863, acc: 43.75%] [G loss: 1.961311]\n",
      "epoch:19 step:14888 [D loss: 0.919781, acc: 41.41%] [G loss: 1.859928]\n",
      "epoch:19 step:14889 [D loss: 0.629428, acc: 65.62%] [G loss: 1.786663]\n",
      "epoch:19 step:14890 [D loss: 0.616807, acc: 60.16%] [G loss: 1.833900]\n",
      "epoch:19 step:14891 [D loss: 0.449962, acc: 85.16%] [G loss: 1.851118]\n",
      "epoch:19 step:14892 [D loss: 0.825974, acc: 41.41%] [G loss: 1.869644]\n",
      "epoch:19 step:14893 [D loss: 0.824577, acc: 40.62%] [G loss: 2.075161]\n",
      "epoch:19 step:14894 [D loss: 0.624355, acc: 61.72%] [G loss: 1.855611]\n",
      "epoch:19 step:14895 [D loss: 0.699336, acc: 53.12%] [G loss: 1.518776]\n",
      "epoch:19 step:14896 [D loss: 0.570553, acc: 66.41%] [G loss: 2.057234]\n",
      "epoch:19 step:14897 [D loss: 0.605727, acc: 71.09%] [G loss: 1.934571]\n",
      "epoch:19 step:14898 [D loss: 0.348399, acc: 96.88%] [G loss: 1.994252]\n",
      "epoch:19 step:14899 [D loss: 0.773818, acc: 48.44%] [G loss: 1.738257]\n",
      "epoch:19 step:14900 [D loss: 0.806719, acc: 39.84%] [G loss: 1.780677]\n",
      "epoch:19 step:14901 [D loss: 0.664583, acc: 63.28%] [G loss: 1.769559]\n",
      "epoch:19 step:14902 [D loss: 0.405375, acc: 83.59%] [G loss: 1.978760]\n",
      "epoch:19 step:14903 [D loss: 0.506644, acc: 82.03%] [G loss: 2.245753]\n",
      "epoch:19 step:14904 [D loss: 0.655071, acc: 59.38%] [G loss: 2.292797]\n",
      "epoch:19 step:14905 [D loss: 0.347456, acc: 91.41%] [G loss: 3.116663]\n",
      "epoch:19 step:14906 [D loss: 0.904146, acc: 50.00%] [G loss: 1.568969]\n",
      "epoch:19 step:14907 [D loss: 0.551434, acc: 79.69%] [G loss: 2.221488]\n",
      "epoch:19 step:14908 [D loss: 0.347866, acc: 96.88%] [G loss: 2.413737]\n",
      "epoch:19 step:14909 [D loss: 0.578316, acc: 71.09%] [G loss: 2.047483]\n",
      "epoch:19 step:14910 [D loss: 0.935571, acc: 39.84%] [G loss: 1.740086]\n",
      "epoch:19 step:14911 [D loss: 0.796085, acc: 39.84%] [G loss: 1.421452]\n",
      "epoch:19 step:14912 [D loss: 0.560880, acc: 78.12%] [G loss: 1.924936]\n",
      "epoch:19 step:14913 [D loss: 0.847966, acc: 46.09%] [G loss: 2.153819]\n",
      "epoch:19 step:14914 [D loss: 0.611917, acc: 61.72%] [G loss: 1.527363]\n",
      "epoch:19 step:14915 [D loss: 0.396731, acc: 85.94%] [G loss: 2.385250]\n",
      "epoch:19 step:14916 [D loss: 0.588561, acc: 67.97%] [G loss: 1.999587]\n",
      "epoch:19 step:14917 [D loss: 0.603489, acc: 71.88%] [G loss: 1.979238]\n",
      "epoch:19 step:14918 [D loss: 0.446633, acc: 88.28%] [G loss: 1.771138]\n",
      "epoch:19 step:14919 [D loss: 0.580803, acc: 74.22%] [G loss: 1.849102]\n",
      "epoch:19 step:14920 [D loss: 0.421339, acc: 71.88%] [G loss: 2.170498]\n",
      "epoch:19 step:14921 [D loss: 0.790907, acc: 42.19%] [G loss: 1.714509]\n",
      "epoch:19 step:14922 [D loss: 0.650128, acc: 56.25%] [G loss: 1.995818]\n",
      "epoch:19 step:14923 [D loss: 1.258411, acc: 16.41%] [G loss: 1.302710]\n",
      "epoch:19 step:14924 [D loss: 0.456558, acc: 89.06%] [G loss: 1.955867]\n",
      "epoch:19 step:14925 [D loss: 0.790401, acc: 42.97%] [G loss: 1.902428]\n",
      "epoch:19 step:14926 [D loss: 0.491945, acc: 83.59%] [G loss: 1.814948]\n",
      "epoch:19 step:14927 [D loss: 1.051010, acc: 21.09%] [G loss: 1.894510]\n",
      "epoch:19 step:14928 [D loss: 0.735021, acc: 52.34%] [G loss: 2.202935]\n",
      "epoch:19 step:14929 [D loss: 0.501679, acc: 83.59%] [G loss: 2.331830]\n",
      "epoch:19 step:14930 [D loss: 0.767255, acc: 46.88%] [G loss: 1.986529]\n",
      "epoch:19 step:14931 [D loss: 0.881914, acc: 37.50%] [G loss: 2.056634]\n",
      "epoch:19 step:14932 [D loss: 0.659594, acc: 62.50%] [G loss: 1.929044]\n",
      "epoch:19 step:14933 [D loss: 0.584505, acc: 73.44%] [G loss: 2.110539]\n",
      "epoch:19 step:14934 [D loss: 0.515074, acc: 82.03%] [G loss: 2.301806]\n",
      "epoch:19 step:14935 [D loss: 0.817380, acc: 39.06%] [G loss: 2.296402]\n",
      "epoch:19 step:14936 [D loss: 0.407468, acc: 87.50%] [G loss: 2.893971]\n",
      "epoch:19 step:14937 [D loss: 0.442074, acc: 95.31%] [G loss: 2.605241]\n",
      "epoch:19 step:14938 [D loss: 0.532291, acc: 75.78%] [G loss: 2.449205]\n",
      "epoch:19 step:14939 [D loss: 0.338486, acc: 96.88%] [G loss: 2.226482]\n",
      "epoch:19 step:14940 [D loss: 0.730670, acc: 51.56%] [G loss: 1.823560]\n",
      "epoch:19 step:14941 [D loss: 0.469006, acc: 80.47%] [G loss: 2.251037]\n",
      "epoch:19 step:14942 [D loss: 0.607524, acc: 69.53%] [G loss: 2.310199]\n",
      "epoch:19 step:14943 [D loss: 0.818386, acc: 40.62%] [G loss: 2.400299]\n",
      "epoch:19 step:14944 [D loss: 0.445895, acc: 90.62%] [G loss: 2.653694]\n",
      "epoch:19 step:14945 [D loss: 0.535974, acc: 76.56%] [G loss: 2.438889]\n",
      "epoch:19 step:14946 [D loss: 0.656923, acc: 61.72%] [G loss: 2.696464]\n",
      "epoch:19 step:14947 [D loss: 1.014475, acc: 32.81%] [G loss: 1.879707]\n",
      "epoch:19 step:14948 [D loss: 0.638896, acc: 60.94%] [G loss: 2.042340]\n",
      "epoch:19 step:14949 [D loss: 0.678192, acc: 61.72%] [G loss: 2.208515]\n",
      "epoch:19 step:14950 [D loss: 0.599855, acc: 64.84%] [G loss: 1.749861]\n",
      "epoch:19 step:14951 [D loss: 0.440128, acc: 87.50%] [G loss: 2.568462]\n",
      "epoch:19 step:14952 [D loss: 0.266053, acc: 97.66%] [G loss: 1.826035]\n",
      "epoch:19 step:14953 [D loss: 0.421131, acc: 78.91%] [G loss: 1.766541]\n",
      "epoch:19 step:14954 [D loss: 0.605882, acc: 69.53%] [G loss: 2.036412]\n",
      "epoch:19 step:14955 [D loss: 0.691670, acc: 56.25%] [G loss: 2.169932]\n",
      "epoch:19 step:14956 [D loss: 0.585337, acc: 64.84%] [G loss: 2.195450]\n",
      "epoch:19 step:14957 [D loss: 0.410818, acc: 90.62%] [G loss: 2.763813]\n",
      "epoch:19 step:14958 [D loss: 0.690627, acc: 57.81%] [G loss: 2.207575]\n",
      "epoch:19 step:14959 [D loss: 0.561307, acc: 78.91%] [G loss: 1.949674]\n",
      "epoch:19 step:14960 [D loss: 0.788495, acc: 51.56%] [G loss: 2.357480]\n",
      "epoch:19 step:14961 [D loss: 0.563242, acc: 74.22%] [G loss: 2.315987]\n",
      "epoch:19 step:14962 [D loss: 0.508573, acc: 78.91%] [G loss: 2.470796]\n",
      "epoch:19 step:14963 [D loss: 0.660752, acc: 58.59%] [G loss: 2.061338]\n",
      "epoch:19 step:14964 [D loss: 0.868889, acc: 31.25%] [G loss: 1.933135]\n",
      "epoch:19 step:14965 [D loss: 0.857085, acc: 32.81%] [G loss: 2.045211]\n",
      "epoch:19 step:14966 [D loss: 0.776565, acc: 43.75%] [G loss: 1.853440]\n",
      "epoch:19 step:14967 [D loss: 0.372319, acc: 93.75%] [G loss: 2.452165]\n",
      "epoch:19 step:14968 [D loss: 0.756181, acc: 50.00%] [G loss: 2.234475]\n",
      "epoch:19 step:14969 [D loss: 0.461761, acc: 82.03%] [G loss: 1.980677]\n",
      "epoch:19 step:14970 [D loss: 0.713349, acc: 51.56%] [G loss: 1.985420]\n",
      "epoch:19 step:14971 [D loss: 0.583512, acc: 71.88%] [G loss: 2.263282]\n",
      "epoch:19 step:14972 [D loss: 0.483093, acc: 86.72%] [G loss: 2.093581]\n",
      "epoch:19 step:14973 [D loss: 0.882237, acc: 34.38%] [G loss: 1.872630]\n",
      "epoch:19 step:14974 [D loss: 0.708873, acc: 54.69%] [G loss: 2.402613]\n",
      "epoch:19 step:14975 [D loss: 0.614849, acc: 72.66%] [G loss: 2.306711]\n",
      "epoch:19 step:14976 [D loss: 0.751749, acc: 49.22%] [G loss: 1.898835]\n",
      "epoch:19 step:14977 [D loss: 0.647268, acc: 64.84%] [G loss: 2.203834]\n",
      "epoch:19 step:14978 [D loss: 0.940286, acc: 43.75%] [G loss: 1.771650]\n",
      "epoch:19 step:14979 [D loss: 0.425885, acc: 92.97%] [G loss: 1.798193]\n",
      "epoch:19 step:14980 [D loss: 0.439854, acc: 89.84%] [G loss: 2.132306]\n",
      "epoch:19 step:14981 [D loss: 0.768152, acc: 50.00%] [G loss: 1.757263]\n",
      "epoch:19 step:14982 [D loss: 0.612375, acc: 62.50%] [G loss: 2.020801]\n",
      "epoch:19 step:14983 [D loss: 0.597255, acc: 68.75%] [G loss: 1.935876]\n",
      "epoch:19 step:14984 [D loss: 0.601946, acc: 71.88%] [G loss: 1.911934]\n",
      "epoch:19 step:14985 [D loss: 0.399361, acc: 88.28%] [G loss: 2.153743]\n",
      "epoch:19 step:14986 [D loss: 0.622643, acc: 62.50%] [G loss: 1.867568]\n",
      "epoch:19 step:14987 [D loss: 0.687004, acc: 60.16%] [G loss: 2.241565]\n",
      "epoch:19 step:14988 [D loss: 0.609990, acc: 64.06%] [G loss: 2.174592]\n",
      "epoch:19 step:14989 [D loss: 0.599052, acc: 68.75%] [G loss: 1.816615]\n",
      "epoch:19 step:14990 [D loss: 0.593921, acc: 68.75%] [G loss: 2.149111]\n",
      "epoch:19 step:14991 [D loss: 0.589704, acc: 67.97%] [G loss: 2.659303]\n",
      "epoch:19 step:14992 [D loss: 0.522927, acc: 78.12%] [G loss: 1.927701]\n",
      "epoch:19 step:14993 [D loss: 0.560769, acc: 78.91%] [G loss: 2.278841]\n",
      "epoch:19 step:14994 [D loss: 0.706716, acc: 55.47%] [G loss: 2.281863]\n",
      "epoch:19 step:14995 [D loss: 0.718747, acc: 54.69%] [G loss: 2.464896]\n",
      "epoch:19 step:14996 [D loss: 0.309802, acc: 99.22%] [G loss: 2.560717]\n",
      "epoch:19 step:14997 [D loss: 0.613990, acc: 70.31%] [G loss: 1.946627]\n",
      "epoch:19 step:14998 [D loss: 0.467824, acc: 85.16%] [G loss: 1.764144]\n",
      "epoch:19 step:14999 [D loss: 0.714201, acc: 50.78%] [G loss: 2.152931]\n",
      "epoch:19 step:15000 [D loss: 0.519302, acc: 82.81%] [G loss: 2.244731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15001 [D loss: 0.373879, acc: 92.19%] [G loss: 2.238825]\n",
      "epoch:19 step:15002 [D loss: 0.713583, acc: 56.25%] [G loss: 1.699602]\n",
      "epoch:19 step:15003 [D loss: 0.345420, acc: 92.97%] [G loss: 1.907381]\n",
      "epoch:19 step:15004 [D loss: 0.566388, acc: 75.78%] [G loss: 1.444470]\n",
      "epoch:19 step:15005 [D loss: 0.422648, acc: 86.72%] [G loss: 2.108305]\n",
      "epoch:19 step:15006 [D loss: 0.719642, acc: 55.47%] [G loss: 2.308298]\n",
      "epoch:19 step:15007 [D loss: 0.451682, acc: 90.62%] [G loss: 2.203441]\n",
      "epoch:19 step:15008 [D loss: 0.580030, acc: 74.22%] [G loss: 1.968577]\n",
      "epoch:19 step:15009 [D loss: 0.473302, acc: 89.84%] [G loss: 2.259367]\n",
      "epoch:19 step:15010 [D loss: 0.657044, acc: 60.16%] [G loss: 2.375792]\n",
      "epoch:19 step:15011 [D loss: 0.637584, acc: 65.62%] [G loss: 2.127375]\n",
      "epoch:19 step:15012 [D loss: 0.659022, acc: 64.84%] [G loss: 2.559168]\n",
      "epoch:19 step:15013 [D loss: 0.744433, acc: 49.22%] [G loss: 2.029818]\n",
      "epoch:19 step:15014 [D loss: 0.535769, acc: 78.91%] [G loss: 1.999661]\n",
      "epoch:19 step:15015 [D loss: 1.028574, acc: 14.84%] [G loss: 1.623101]\n",
      "epoch:19 step:15016 [D loss: 0.705447, acc: 53.12%] [G loss: 1.924014]\n",
      "epoch:19 step:15017 [D loss: 0.934133, acc: 32.03%] [G loss: 1.570121]\n",
      "epoch:19 step:15018 [D loss: 0.731002, acc: 53.91%] [G loss: 2.027187]\n",
      "epoch:19 step:15019 [D loss: 0.560971, acc: 72.66%] [G loss: 1.691410]\n",
      "epoch:19 step:15020 [D loss: 0.785933, acc: 46.09%] [G loss: 1.594714]\n",
      "epoch:19 step:15021 [D loss: 0.691891, acc: 59.38%] [G loss: 2.071802]\n",
      "epoch:19 step:15022 [D loss: 0.633809, acc: 60.94%] [G loss: 1.688008]\n",
      "epoch:19 step:15023 [D loss: 0.832088, acc: 29.69%] [G loss: 2.244143]\n",
      "epoch:19 step:15024 [D loss: 0.644701, acc: 60.94%] [G loss: 1.985100]\n",
      "epoch:19 step:15025 [D loss: 0.440514, acc: 86.72%] [G loss: 2.360958]\n",
      "epoch:19 step:15026 [D loss: 0.314680, acc: 96.09%] [G loss: 2.890680]\n",
      "epoch:19 step:15027 [D loss: 0.447937, acc: 77.34%] [G loss: 1.895248]\n",
      "epoch:19 step:15028 [D loss: 0.487721, acc: 82.81%] [G loss: 2.237281]\n",
      "epoch:19 step:15029 [D loss: 0.499183, acc: 78.91%] [G loss: 2.347373]\n",
      "epoch:19 step:15030 [D loss: 0.280472, acc: 99.22%] [G loss: 2.298627]\n",
      "epoch:19 step:15031 [D loss: 0.651860, acc: 61.72%] [G loss: 1.587594]\n",
      "epoch:19 step:15032 [D loss: 0.574078, acc: 73.44%] [G loss: 2.263044]\n",
      "epoch:19 step:15033 [D loss: 0.672715, acc: 58.59%] [G loss: 1.652024]\n",
      "epoch:19 step:15034 [D loss: 0.848196, acc: 32.03%] [G loss: 1.400198]\n",
      "epoch:19 step:15035 [D loss: 0.680197, acc: 63.28%] [G loss: 1.830171]\n",
      "epoch:19 step:15036 [D loss: 0.684238, acc: 58.59%] [G loss: 1.852118]\n",
      "epoch:19 step:15037 [D loss: 0.688235, acc: 56.25%] [G loss: 2.529161]\n",
      "epoch:19 step:15038 [D loss: 0.433397, acc: 85.94%] [G loss: 2.541603]\n",
      "epoch:19 step:15039 [D loss: 0.490732, acc: 88.28%] [G loss: 2.392038]\n",
      "epoch:19 step:15040 [D loss: 0.282162, acc: 92.19%] [G loss: 2.954382]\n",
      "epoch:19 step:15041 [D loss: 0.687771, acc: 57.03%] [G loss: 1.715689]\n",
      "epoch:19 step:15042 [D loss: 0.721865, acc: 58.59%] [G loss: 1.899603]\n",
      "epoch:19 step:15043 [D loss: 0.694409, acc: 51.56%] [G loss: 1.854235]\n",
      "epoch:19 step:15044 [D loss: 1.163233, acc: 9.38%] [G loss: 1.148671]\n",
      "epoch:19 step:15045 [D loss: 0.422582, acc: 71.09%] [G loss: 2.066746]\n",
      "epoch:19 step:15046 [D loss: 1.120375, acc: 14.84%] [G loss: 1.987218]\n",
      "epoch:19 step:15047 [D loss: 0.635695, acc: 57.03%] [G loss: 1.956832]\n",
      "epoch:19 step:15048 [D loss: 0.899370, acc: 43.75%] [G loss: 1.810711]\n",
      "epoch:19 step:15049 [D loss: 0.628922, acc: 66.41%] [G loss: 1.750657]\n",
      "epoch:19 step:15050 [D loss: 0.536120, acc: 78.12%] [G loss: 2.412987]\n",
      "epoch:19 step:15051 [D loss: 0.679003, acc: 60.16%] [G loss: 2.076633]\n",
      "epoch:19 step:15052 [D loss: 0.525813, acc: 82.81%] [G loss: 1.934569]\n",
      "epoch:19 step:15053 [D loss: 0.415190, acc: 86.72%] [G loss: 2.432299]\n",
      "epoch:19 step:15054 [D loss: 0.687861, acc: 52.34%] [G loss: 2.154210]\n",
      "epoch:19 step:15055 [D loss: 0.678920, acc: 53.91%] [G loss: 2.032327]\n",
      "epoch:19 step:15056 [D loss: 0.667529, acc: 60.16%] [G loss: 1.914655]\n",
      "epoch:19 step:15057 [D loss: 0.612843, acc: 60.94%] [G loss: 2.056160]\n",
      "epoch:19 step:15058 [D loss: 0.667014, acc: 58.59%] [G loss: 2.110153]\n",
      "epoch:19 step:15059 [D loss: 0.539967, acc: 80.47%] [G loss: 1.736617]\n",
      "epoch:19 step:15060 [D loss: 0.575669, acc: 64.84%] [G loss: 1.577457]\n",
      "epoch:19 step:15061 [D loss: 0.658738, acc: 60.94%] [G loss: 1.795622]\n",
      "epoch:19 step:15062 [D loss: 0.885375, acc: 32.81%] [G loss: 2.138958]\n",
      "epoch:19 step:15063 [D loss: 0.513848, acc: 82.81%] [G loss: 1.966342]\n",
      "epoch:19 step:15064 [D loss: 0.356983, acc: 93.75%] [G loss: 3.540745]\n",
      "epoch:19 step:15065 [D loss: 0.676333, acc: 60.16%] [G loss: 2.049302]\n",
      "epoch:19 step:15066 [D loss: 0.718577, acc: 57.81%] [G loss: 2.468981]\n",
      "epoch:19 step:15067 [D loss: 0.470564, acc: 81.25%] [G loss: 2.293591]\n",
      "epoch:19 step:15068 [D loss: 0.684834, acc: 54.69%] [G loss: 2.307975]\n",
      "epoch:19 step:15069 [D loss: 1.107498, acc: 12.50%] [G loss: 1.379792]\n",
      "epoch:19 step:15070 [D loss: 0.318908, acc: 97.66%] [G loss: 2.615585]\n",
      "epoch:19 step:15071 [D loss: 0.866018, acc: 32.03%] [G loss: 1.929751]\n",
      "epoch:19 step:15072 [D loss: 0.537184, acc: 78.12%] [G loss: 2.689994]\n",
      "epoch:19 step:15073 [D loss: 0.551672, acc: 67.19%] [G loss: 1.801997]\n",
      "epoch:19 step:15074 [D loss: 0.671721, acc: 56.25%] [G loss: 2.139090]\n",
      "epoch:19 step:15075 [D loss: 0.663942, acc: 57.03%] [G loss: 2.328337]\n",
      "epoch:19 step:15076 [D loss: 0.475591, acc: 86.72%] [G loss: 2.283090]\n",
      "epoch:19 step:15077 [D loss: 0.448638, acc: 81.25%] [G loss: 2.114166]\n",
      "epoch:19 step:15078 [D loss: 0.372614, acc: 94.53%] [G loss: 2.439405]\n",
      "epoch:19 step:15079 [D loss: 0.717541, acc: 46.09%] [G loss: 1.737475]\n",
      "epoch:19 step:15080 [D loss: 0.550219, acc: 77.34%] [G loss: 2.285501]\n",
      "epoch:19 step:15081 [D loss: 0.590097, acc: 64.06%] [G loss: 2.554412]\n",
      "epoch:19 step:15082 [D loss: 0.592704, acc: 67.97%] [G loss: 2.173306]\n",
      "epoch:19 step:15083 [D loss: 0.731638, acc: 47.66%] [G loss: 2.066263]\n",
      "epoch:19 step:15084 [D loss: 1.191449, acc: 10.16%] [G loss: 1.735986]\n",
      "epoch:19 step:15085 [D loss: 0.389237, acc: 86.72%] [G loss: 1.819834]\n",
      "epoch:19 step:15086 [D loss: 0.640817, acc: 66.41%] [G loss: 1.784870]\n",
      "epoch:19 step:15087 [D loss: 0.697140, acc: 57.03%] [G loss: 2.164745]\n",
      "epoch:19 step:15088 [D loss: 0.732682, acc: 54.69%] [G loss: 1.462544]\n",
      "epoch:19 step:15089 [D loss: 0.509128, acc: 81.25%] [G loss: 2.521779]\n",
      "epoch:19 step:15090 [D loss: 0.447553, acc: 89.84%] [G loss: 1.987388]\n",
      "epoch:19 step:15091 [D loss: 0.510965, acc: 71.09%] [G loss: 1.948118]\n",
      "epoch:19 step:15092 [D loss: 0.784035, acc: 39.84%] [G loss: 1.623107]\n",
      "epoch:19 step:15093 [D loss: 0.427361, acc: 84.38%] [G loss: 2.137655]\n",
      "epoch:19 step:15094 [D loss: 0.730758, acc: 56.25%] [G loss: 2.393295]\n",
      "epoch:19 step:15095 [D loss: 0.433805, acc: 88.28%] [G loss: 2.068945]\n",
      "epoch:19 step:15096 [D loss: 0.611076, acc: 61.72%] [G loss: 2.009896]\n",
      "epoch:19 step:15097 [D loss: 0.400263, acc: 91.41%] [G loss: 2.778037]\n",
      "epoch:19 step:15098 [D loss: 0.483735, acc: 81.25%] [G loss: 2.074176]\n",
      "epoch:19 step:15099 [D loss: 0.573766, acc: 65.62%] [G loss: 2.229073]\n",
      "epoch:19 step:15100 [D loss: 0.582024, acc: 71.88%] [G loss: 1.914738]\n",
      "epoch:19 step:15101 [D loss: 0.378587, acc: 96.88%] [G loss: 2.421998]\n",
      "epoch:19 step:15102 [D loss: 0.775837, acc: 50.00%] [G loss: 1.703972]\n",
      "epoch:19 step:15103 [D loss: 0.615212, acc: 65.62%] [G loss: 2.403293]\n",
      "epoch:19 step:15104 [D loss: 0.630536, acc: 66.41%] [G loss: 1.868976]\n",
      "epoch:19 step:15105 [D loss: 0.409095, acc: 91.41%] [G loss: 2.118553]\n",
      "epoch:19 step:15106 [D loss: 1.253294, acc: 11.72%] [G loss: 1.648767]\n",
      "epoch:19 step:15107 [D loss: 0.411198, acc: 89.84%] [G loss: 2.492424]\n",
      "epoch:19 step:15108 [D loss: 0.686172, acc: 54.69%] [G loss: 1.854376]\n",
      "epoch:19 step:15109 [D loss: 0.324017, acc: 96.88%] [G loss: 2.644563]\n",
      "epoch:19 step:15110 [D loss: 0.547349, acc: 75.78%] [G loss: 1.913984]\n",
      "epoch:19 step:15111 [D loss: 0.686014, acc: 60.16%] [G loss: 1.890457]\n",
      "epoch:19 step:15112 [D loss: 0.691999, acc: 51.56%] [G loss: 1.852551]\n",
      "epoch:19 step:15113 [D loss: 0.767410, acc: 43.75%] [G loss: 2.165296]\n",
      "epoch:19 step:15114 [D loss: 0.619012, acc: 66.41%] [G loss: 2.492575]\n",
      "epoch:19 step:15115 [D loss: 0.521779, acc: 71.09%] [G loss: 2.495712]\n",
      "epoch:19 step:15116 [D loss: 0.611187, acc: 69.53%] [G loss: 2.171480]\n",
      "epoch:19 step:15117 [D loss: 0.774403, acc: 53.91%] [G loss: 2.364418]\n",
      "epoch:19 step:15118 [D loss: 0.356256, acc: 97.66%] [G loss: 2.452836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15119 [D loss: 0.704006, acc: 52.34%] [G loss: 2.035553]\n",
      "epoch:19 step:15120 [D loss: 0.874101, acc: 35.16%] [G loss: 1.936843]\n",
      "epoch:19 step:15121 [D loss: 0.508629, acc: 83.59%] [G loss: 2.137916]\n",
      "epoch:19 step:15122 [D loss: 0.555587, acc: 81.25%] [G loss: 2.633349]\n",
      "epoch:19 step:15123 [D loss: 0.517581, acc: 80.47%] [G loss: 2.491445]\n",
      "epoch:19 step:15124 [D loss: 0.365645, acc: 96.88%] [G loss: 2.388094]\n",
      "epoch:19 step:15125 [D loss: 0.474006, acc: 89.06%] [G loss: 2.657762]\n",
      "epoch:19 step:15126 [D loss: 0.424793, acc: 89.84%] [G loss: 3.381004]\n",
      "epoch:19 step:15127 [D loss: 0.719753, acc: 50.78%] [G loss: 2.391117]\n",
      "epoch:19 step:15128 [D loss: 0.518457, acc: 71.88%] [G loss: 2.713598]\n",
      "epoch:19 step:15129 [D loss: 0.366032, acc: 90.62%] [G loss: 2.175725]\n",
      "epoch:19 step:15130 [D loss: 0.636343, acc: 63.28%] [G loss: 1.789453]\n",
      "epoch:19 step:15131 [D loss: 0.531318, acc: 69.53%] [G loss: 2.868077]\n",
      "epoch:19 step:15132 [D loss: 0.513500, acc: 75.78%] [G loss: 2.061718]\n",
      "epoch:19 step:15133 [D loss: 0.406391, acc: 99.22%] [G loss: 2.310342]\n",
      "epoch:19 step:15134 [D loss: 0.418421, acc: 89.84%] [G loss: 2.035288]\n",
      "epoch:19 step:15135 [D loss: 0.542717, acc: 82.03%] [G loss: 2.691344]\n",
      "epoch:19 step:15136 [D loss: 0.586562, acc: 67.97%] [G loss: 1.977954]\n",
      "epoch:19 step:15137 [D loss: 0.531862, acc: 81.25%] [G loss: 1.829277]\n",
      "epoch:19 step:15138 [D loss: 0.535095, acc: 72.66%] [G loss: 2.294574]\n",
      "epoch:19 step:15139 [D loss: 0.418975, acc: 89.84%] [G loss: 2.269545]\n",
      "epoch:19 step:15140 [D loss: 0.654802, acc: 62.50%] [G loss: 2.275341]\n",
      "epoch:19 step:15141 [D loss: 0.654027, acc: 61.72%] [G loss: 2.536470]\n",
      "epoch:19 step:15142 [D loss: 0.680064, acc: 52.34%] [G loss: 1.942099]\n",
      "epoch:19 step:15143 [D loss: 0.545558, acc: 73.44%] [G loss: 2.497926]\n",
      "epoch:19 step:15144 [D loss: 0.291609, acc: 96.88%] [G loss: 2.687585]\n",
      "epoch:19 step:15145 [D loss: 0.730627, acc: 50.00%] [G loss: 2.257620]\n",
      "epoch:19 step:15146 [D loss: 0.329843, acc: 93.75%] [G loss: 2.344664]\n",
      "epoch:19 step:15147 [D loss: 0.544243, acc: 75.78%] [G loss: 2.597487]\n",
      "epoch:19 step:15148 [D loss: 0.600508, acc: 67.19%] [G loss: 2.249368]\n",
      "epoch:19 step:15149 [D loss: 0.789637, acc: 39.84%] [G loss: 2.157341]\n",
      "epoch:19 step:15150 [D loss: 0.493180, acc: 83.59%] [G loss: 3.109529]\n",
      "epoch:19 step:15151 [D loss: 0.671768, acc: 53.12%] [G loss: 1.762779]\n",
      "epoch:19 step:15152 [D loss: 0.703792, acc: 53.91%] [G loss: 1.906413]\n",
      "epoch:19 step:15153 [D loss: 0.530092, acc: 78.12%] [G loss: 2.191525]\n",
      "epoch:19 step:15154 [D loss: 0.590278, acc: 75.78%] [G loss: 1.759489]\n",
      "epoch:19 step:15155 [D loss: 0.682280, acc: 56.25%] [G loss: 2.431008]\n",
      "epoch:19 step:15156 [D loss: 0.481335, acc: 82.81%] [G loss: 2.381654]\n",
      "epoch:19 step:15157 [D loss: 0.627192, acc: 66.41%] [G loss: 1.746153]\n",
      "epoch:19 step:15158 [D loss: 0.691929, acc: 61.72%] [G loss: 1.874222]\n",
      "epoch:19 step:15159 [D loss: 0.834409, acc: 50.00%] [G loss: 1.745965]\n",
      "epoch:19 step:15160 [D loss: 0.608531, acc: 62.50%] [G loss: 2.221641]\n",
      "epoch:19 step:15161 [D loss: 0.688667, acc: 56.25%] [G loss: 2.470509]\n",
      "epoch:19 step:15162 [D loss: 0.591612, acc: 74.22%] [G loss: 1.776359]\n",
      "epoch:19 step:15163 [D loss: 0.647305, acc: 57.81%] [G loss: 1.976743]\n",
      "epoch:19 step:15164 [D loss: 0.589916, acc: 69.53%] [G loss: 2.051373]\n",
      "epoch:19 step:15165 [D loss: 0.664405, acc: 64.84%] [G loss: 1.837309]\n",
      "epoch:19 step:15166 [D loss: 0.699145, acc: 53.91%] [G loss: 1.994332]\n",
      "epoch:19 step:15167 [D loss: 0.509585, acc: 82.81%] [G loss: 3.185787]\n",
      "epoch:19 step:15168 [D loss: 0.343295, acc: 90.62%] [G loss: 2.448723]\n",
      "epoch:19 step:15169 [D loss: 0.549069, acc: 82.03%] [G loss: 2.903784]\n",
      "epoch:19 step:15170 [D loss: 0.634408, acc: 57.03%] [G loss: 1.890893]\n",
      "epoch:19 step:15171 [D loss: 0.619891, acc: 57.81%] [G loss: 2.238603]\n",
      "epoch:19 step:15172 [D loss: 0.537119, acc: 62.50%] [G loss: 1.984454]\n",
      "epoch:19 step:15173 [D loss: 0.602858, acc: 67.19%] [G loss: 1.880515]\n",
      "epoch:19 step:15174 [D loss: 0.638464, acc: 54.69%] [G loss: 2.164216]\n",
      "epoch:19 step:15175 [D loss: 0.415417, acc: 91.41%] [G loss: 2.648442]\n",
      "epoch:19 step:15176 [D loss: 0.829010, acc: 35.16%] [G loss: 1.430691]\n",
      "epoch:19 step:15177 [D loss: 0.688789, acc: 52.34%] [G loss: 2.765001]\n",
      "epoch:19 step:15178 [D loss: 0.489545, acc: 75.78%] [G loss: 2.327721]\n",
      "epoch:19 step:15179 [D loss: 0.676519, acc: 53.12%] [G loss: 2.151594]\n",
      "epoch:19 step:15180 [D loss: 0.400279, acc: 89.84%] [G loss: 1.609732]\n",
      "epoch:19 step:15181 [D loss: 0.641222, acc: 69.53%] [G loss: 2.073429]\n",
      "epoch:19 step:15182 [D loss: 0.411741, acc: 93.75%] [G loss: 2.636008]\n",
      "epoch:19 step:15183 [D loss: 0.478039, acc: 89.06%] [G loss: 2.347776]\n",
      "epoch:19 step:15184 [D loss: 0.711616, acc: 51.56%] [G loss: 2.163838]\n",
      "epoch:19 step:15185 [D loss: 0.404112, acc: 92.19%] [G loss: 2.289759]\n",
      "epoch:19 step:15186 [D loss: 0.575612, acc: 80.47%] [G loss: 2.116620]\n",
      "epoch:19 step:15187 [D loss: 0.324345, acc: 89.06%] [G loss: 2.198946]\n",
      "epoch:19 step:15188 [D loss: 0.628579, acc: 67.97%] [G loss: 2.295243]\n",
      "epoch:19 step:15189 [D loss: 0.577488, acc: 72.66%] [G loss: 2.875016]\n",
      "epoch:19 step:15190 [D loss: 0.587286, acc: 74.22%] [G loss: 2.374540]\n",
      "epoch:19 step:15191 [D loss: 0.351482, acc: 91.41%] [G loss: 2.720880]\n",
      "epoch:19 step:15192 [D loss: 0.416257, acc: 92.97%] [G loss: 2.665126]\n",
      "epoch:19 step:15193 [D loss: 0.473256, acc: 85.16%] [G loss: 2.870980]\n",
      "epoch:19 step:15194 [D loss: 0.767245, acc: 49.22%] [G loss: 2.451955]\n",
      "epoch:19 step:15195 [D loss: 0.386110, acc: 86.72%] [G loss: 2.774700]\n",
      "epoch:19 step:15196 [D loss: 0.353773, acc: 96.88%] [G loss: 2.405414]\n",
      "epoch:19 step:15197 [D loss: 0.738585, acc: 53.91%] [G loss: 2.269514]\n",
      "epoch:19 step:15198 [D loss: 0.515313, acc: 82.81%] [G loss: 2.911576]\n",
      "epoch:19 step:15199 [D loss: 1.046826, acc: 26.56%] [G loss: 1.608035]\n",
      "epoch:19 step:15200 [D loss: 0.538986, acc: 76.56%] [G loss: 2.650849]\n",
      "epoch:19 step:15201 [D loss: 0.733374, acc: 49.22%] [G loss: 1.961011]\n",
      "epoch:19 step:15202 [D loss: 0.600593, acc: 68.75%] [G loss: 2.803463]\n",
      "epoch:19 step:15203 [D loss: 0.471326, acc: 79.69%] [G loss: 2.591473]\n",
      "epoch:19 step:15204 [D loss: 0.485615, acc: 75.78%] [G loss: 2.349135]\n",
      "epoch:19 step:15205 [D loss: 1.074984, acc: 17.19%] [G loss: 2.438831]\n",
      "epoch:19 step:15206 [D loss: 0.885963, acc: 37.50%] [G loss: 1.771927]\n",
      "epoch:19 step:15207 [D loss: 0.421393, acc: 92.19%] [G loss: 2.095228]\n",
      "epoch:19 step:15208 [D loss: 0.436990, acc: 90.62%] [G loss: 2.294733]\n",
      "epoch:19 step:15209 [D loss: 0.419473, acc: 90.62%] [G loss: 2.828352]\n",
      "epoch:19 step:15210 [D loss: 0.485393, acc: 81.25%] [G loss: 2.321992]\n",
      "epoch:19 step:15211 [D loss: 0.777604, acc: 46.09%] [G loss: 2.567299]\n",
      "epoch:19 step:15212 [D loss: 1.017401, acc: 16.41%] [G loss: 2.471718]\n",
      "epoch:19 step:15213 [D loss: 0.365054, acc: 95.31%] [G loss: 2.907706]\n",
      "epoch:19 step:15214 [D loss: 0.683374, acc: 54.69%] [G loss: 1.843131]\n",
      "epoch:19 step:15215 [D loss: 0.567189, acc: 71.09%] [G loss: 2.315642]\n",
      "epoch:19 step:15216 [D loss: 0.679049, acc: 58.59%] [G loss: 2.087695]\n",
      "epoch:19 step:15217 [D loss: 0.670299, acc: 53.91%] [G loss: 2.114716]\n",
      "epoch:19 step:15218 [D loss: 0.662597, acc: 56.25%] [G loss: 2.022736]\n",
      "epoch:19 step:15219 [D loss: 0.566149, acc: 75.00%] [G loss: 2.298728]\n",
      "epoch:19 step:15220 [D loss: 0.273516, acc: 95.31%] [G loss: 2.126436]\n",
      "epoch:19 step:15221 [D loss: 0.642300, acc: 61.72%] [G loss: 2.378101]\n",
      "epoch:19 step:15222 [D loss: 0.880867, acc: 33.59%] [G loss: 1.813560]\n",
      "epoch:19 step:15223 [D loss: 0.642648, acc: 60.94%] [G loss: 2.199068]\n",
      "epoch:19 step:15224 [D loss: 0.927969, acc: 17.97%] [G loss: 2.255650]\n",
      "epoch:19 step:15225 [D loss: 0.584447, acc: 71.88%] [G loss: 2.312544]\n",
      "epoch:19 step:15226 [D loss: 0.557098, acc: 71.88%] [G loss: 2.639887]\n",
      "epoch:19 step:15227 [D loss: 0.752744, acc: 45.31%] [G loss: 1.645531]\n",
      "epoch:19 step:15228 [D loss: 0.640616, acc: 54.69%] [G loss: 1.925687]\n",
      "epoch:19 step:15229 [D loss: 0.235889, acc: 96.88%] [G loss: 3.097358]\n",
      "epoch:19 step:15230 [D loss: 1.050374, acc: 39.84%] [G loss: 2.030812]\n",
      "epoch:19 step:15231 [D loss: 0.804876, acc: 49.22%] [G loss: 1.751660]\n",
      "epoch:19 step:15232 [D loss: 0.716269, acc: 50.00%] [G loss: 2.042285]\n",
      "epoch:19 step:15233 [D loss: 0.289697, acc: 98.44%] [G loss: 2.243773]\n",
      "epoch:19 step:15234 [D loss: 0.538771, acc: 68.75%] [G loss: 2.053609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15235 [D loss: 0.565409, acc: 74.22%] [G loss: 1.837074]\n",
      "epoch:19 step:15236 [D loss: 0.635783, acc: 64.06%] [G loss: 1.622972]\n",
      "epoch:19 step:15237 [D loss: 0.996102, acc: 28.91%] [G loss: 2.537643]\n",
      "epoch:19 step:15238 [D loss: 0.833179, acc: 35.16%] [G loss: 2.185259]\n",
      "epoch:19 step:15239 [D loss: 0.368257, acc: 93.75%] [G loss: 2.504609]\n",
      "epoch:19 step:15240 [D loss: 0.499838, acc: 80.47%] [G loss: 2.035521]\n",
      "epoch:19 step:15241 [D loss: 0.610339, acc: 67.19%] [G loss: 2.379821]\n",
      "epoch:19 step:15242 [D loss: 0.582600, acc: 67.97%] [G loss: 1.773351]\n",
      "epoch:19 step:15243 [D loss: 0.652619, acc: 55.47%] [G loss: 2.103023]\n",
      "epoch:19 step:15244 [D loss: 0.636923, acc: 57.03%] [G loss: 2.571442]\n",
      "epoch:19 step:15245 [D loss: 0.441583, acc: 89.06%] [G loss: 2.312231]\n",
      "epoch:19 step:15246 [D loss: 0.343601, acc: 98.44%] [G loss: 2.455779]\n",
      "epoch:19 step:15247 [D loss: 0.515924, acc: 82.81%] [G loss: 2.106757]\n",
      "epoch:19 step:15248 [D loss: 0.494775, acc: 85.94%] [G loss: 2.411874]\n",
      "epoch:19 step:15249 [D loss: 0.730313, acc: 50.78%] [G loss: 2.120178]\n",
      "epoch:19 step:15250 [D loss: 0.751325, acc: 52.34%] [G loss: 2.330122]\n",
      "epoch:19 step:15251 [D loss: 0.345789, acc: 94.53%] [G loss: 2.032024]\n",
      "epoch:19 step:15252 [D loss: 0.601524, acc: 67.97%] [G loss: 2.243660]\n",
      "epoch:19 step:15253 [D loss: 0.525597, acc: 80.47%] [G loss: 2.538555]\n",
      "epoch:19 step:15254 [D loss: 0.452850, acc: 87.50%] [G loss: 2.013829]\n",
      "epoch:19 step:15255 [D loss: 0.709130, acc: 54.69%] [G loss: 2.323055]\n",
      "epoch:19 step:15256 [D loss: 0.379284, acc: 89.06%] [G loss: 2.048556]\n",
      "epoch:19 step:15257 [D loss: 0.573217, acc: 64.06%] [G loss: 2.034576]\n",
      "epoch:19 step:15258 [D loss: 0.461677, acc: 85.16%] [G loss: 2.608059]\n",
      "epoch:19 step:15259 [D loss: 0.583878, acc: 69.53%] [G loss: 2.983218]\n",
      "epoch:19 step:15260 [D loss: 0.227888, acc: 96.88%] [G loss: 3.010656]\n",
      "epoch:19 step:15261 [D loss: 0.429853, acc: 89.84%] [G loss: 2.508543]\n",
      "epoch:19 step:15262 [D loss: 0.591797, acc: 69.53%] [G loss: 2.300270]\n",
      "epoch:19 step:15263 [D loss: 1.509347, acc: 9.38%] [G loss: 1.959888]\n",
      "epoch:19 step:15264 [D loss: 0.569150, acc: 76.56%] [G loss: 2.366933]\n",
      "epoch:19 step:15265 [D loss: 0.607847, acc: 58.59%] [G loss: 2.180351]\n",
      "epoch:19 step:15266 [D loss: 0.663112, acc: 55.47%] [G loss: 2.670650]\n",
      "epoch:19 step:15267 [D loss: 0.686907, acc: 60.16%] [G loss: 2.477996]\n",
      "epoch:19 step:15268 [D loss: 0.299680, acc: 97.66%] [G loss: 2.371547]\n",
      "epoch:19 step:15269 [D loss: 0.546816, acc: 72.66%] [G loss: 2.126650]\n",
      "epoch:19 step:15270 [D loss: 0.993560, acc: 21.09%] [G loss: 1.800337]\n",
      "epoch:19 step:15271 [D loss: 0.617158, acc: 61.72%] [G loss: 2.133055]\n",
      "epoch:19 step:15272 [D loss: 0.523787, acc: 76.56%] [G loss: 2.635448]\n",
      "epoch:19 step:15273 [D loss: 0.561248, acc: 53.91%] [G loss: 2.407652]\n",
      "epoch:19 step:15274 [D loss: 0.859403, acc: 30.47%] [G loss: 1.985909]\n",
      "epoch:19 step:15275 [D loss: 0.641227, acc: 67.97%] [G loss: 1.889604]\n",
      "epoch:19 step:15276 [D loss: 0.761077, acc: 44.53%] [G loss: 2.157393]\n",
      "epoch:19 step:15277 [D loss: 0.419674, acc: 93.75%] [G loss: 2.272882]\n",
      "epoch:19 step:15278 [D loss: 0.510339, acc: 64.84%] [G loss: 2.347021]\n",
      "epoch:19 step:15279 [D loss: 0.979684, acc: 33.59%] [G loss: 2.371949]\n",
      "epoch:19 step:15280 [D loss: 0.520040, acc: 79.69%] [G loss: 2.216899]\n",
      "epoch:19 step:15281 [D loss: 0.736856, acc: 51.56%] [G loss: 2.343505]\n",
      "epoch:19 step:15282 [D loss: 0.527306, acc: 75.78%] [G loss: 2.049845]\n",
      "epoch:19 step:15283 [D loss: 0.696683, acc: 53.91%] [G loss: 2.062945]\n",
      "epoch:19 step:15284 [D loss: 0.623322, acc: 64.84%] [G loss: 1.458196]\n",
      "epoch:19 step:15285 [D loss: 0.421613, acc: 84.38%] [G loss: 2.753785]\n",
      "epoch:19 step:15286 [D loss: 0.642713, acc: 62.50%] [G loss: 2.161953]\n",
      "epoch:19 step:15287 [D loss: 0.584456, acc: 73.44%] [G loss: 2.026000]\n",
      "epoch:19 step:15288 [D loss: 0.379525, acc: 93.75%] [G loss: 2.571667]\n",
      "epoch:19 step:15289 [D loss: 0.591072, acc: 71.88%] [G loss: 2.063365]\n",
      "epoch:19 step:15290 [D loss: 0.678522, acc: 57.81%] [G loss: 2.358863]\n",
      "epoch:19 step:15291 [D loss: 0.788172, acc: 42.19%] [G loss: 2.803175]\n",
      "epoch:19 step:15292 [D loss: 0.585497, acc: 72.66%] [G loss: 2.322238]\n",
      "epoch:19 step:15293 [D loss: 0.479578, acc: 87.50%] [G loss: 2.386387]\n",
      "epoch:19 step:15294 [D loss: 0.587339, acc: 60.16%] [G loss: 1.929592]\n",
      "epoch:19 step:15295 [D loss: 0.451102, acc: 80.47%] [G loss: 2.278717]\n",
      "epoch:19 step:15296 [D loss: 0.380339, acc: 89.84%] [G loss: 2.736788]\n",
      "epoch:19 step:15297 [D loss: 0.450924, acc: 87.50%] [G loss: 2.300475]\n",
      "epoch:19 step:15298 [D loss: 0.551676, acc: 72.66%] [G loss: 2.335378]\n",
      "epoch:19 step:15299 [D loss: 0.690647, acc: 55.47%] [G loss: 1.970870]\n",
      "epoch:19 step:15300 [D loss: 0.394687, acc: 95.31%] [G loss: 2.688910]\n",
      "epoch:19 step:15301 [D loss: 0.483047, acc: 85.16%] [G loss: 2.733404]\n",
      "epoch:19 step:15302 [D loss: 0.249169, acc: 95.31%] [G loss: 2.580357]\n",
      "epoch:19 step:15303 [D loss: 0.616309, acc: 67.97%] [G loss: 1.935738]\n",
      "epoch:19 step:15304 [D loss: 0.730966, acc: 47.66%] [G loss: 1.690720]\n",
      "epoch:19 step:15305 [D loss: 0.402068, acc: 94.53%] [G loss: 2.506244]\n",
      "epoch:19 step:15306 [D loss: 0.819644, acc: 50.78%] [G loss: 2.076106]\n",
      "epoch:19 step:15307 [D loss: 0.738027, acc: 46.88%] [G loss: 2.080559]\n",
      "epoch:19 step:15308 [D loss: 0.568827, acc: 65.62%] [G loss: 2.398777]\n",
      "epoch:19 step:15309 [D loss: 0.458257, acc: 82.03%] [G loss: 1.756389]\n",
      "epoch:19 step:15310 [D loss: 0.898296, acc: 29.69%] [G loss: 1.782480]\n",
      "epoch:19 step:15311 [D loss: 0.651219, acc: 58.59%] [G loss: 1.723626]\n",
      "epoch:19 step:15312 [D loss: 0.740198, acc: 48.44%] [G loss: 2.390472]\n",
      "epoch:19 step:15313 [D loss: 0.752409, acc: 43.75%] [G loss: 1.562833]\n",
      "epoch:19 step:15314 [D loss: 0.546657, acc: 75.00%] [G loss: 1.975007]\n",
      "epoch:19 step:15315 [D loss: 0.412540, acc: 88.28%] [G loss: 3.261708]\n",
      "epoch:19 step:15316 [D loss: 0.281567, acc: 96.88%] [G loss: 3.296474]\n",
      "epoch:19 step:15317 [D loss: 0.751411, acc: 50.78%] [G loss: 2.821485]\n",
      "epoch:19 step:15318 [D loss: 0.484615, acc: 82.81%] [G loss: 2.214462]\n",
      "epoch:19 step:15319 [D loss: 0.579209, acc: 73.44%] [G loss: 2.301890]\n",
      "epoch:19 step:15320 [D loss: 0.852755, acc: 35.94%] [G loss: 2.758287]\n",
      "epoch:19 step:15321 [D loss: 0.997471, acc: 25.00%] [G loss: 1.850686]\n",
      "epoch:19 step:15322 [D loss: 0.402247, acc: 89.84%] [G loss: 2.393373]\n",
      "epoch:19 step:15323 [D loss: 0.378560, acc: 84.38%] [G loss: 2.573905]\n",
      "epoch:19 step:15324 [D loss: 0.745085, acc: 52.34%] [G loss: 2.430440]\n",
      "epoch:19 step:15325 [D loss: 0.860240, acc: 44.53%] [G loss: 2.276089]\n",
      "epoch:19 step:15326 [D loss: 0.347916, acc: 96.88%] [G loss: 2.268720]\n",
      "epoch:19 step:15327 [D loss: 0.466402, acc: 87.50%] [G loss: 2.161270]\n",
      "epoch:19 step:15328 [D loss: 0.948360, acc: 48.44%] [G loss: 1.897704]\n",
      "epoch:19 step:15329 [D loss: 0.380676, acc: 90.62%] [G loss: 2.200345]\n",
      "epoch:19 step:15330 [D loss: 0.882485, acc: 32.03%] [G loss: 2.624687]\n",
      "epoch:19 step:15331 [D loss: 0.818291, acc: 46.88%] [G loss: 1.984046]\n",
      "epoch:19 step:15332 [D loss: 0.281175, acc: 95.31%] [G loss: 3.142486]\n",
      "epoch:19 step:15333 [D loss: 0.572280, acc: 64.06%] [G loss: 1.873597]\n",
      "epoch:19 step:15334 [D loss: 0.343605, acc: 94.53%] [G loss: 2.128276]\n",
      "epoch:19 step:15335 [D loss: 0.512308, acc: 85.16%] [G loss: 2.072549]\n",
      "epoch:19 step:15336 [D loss: 0.484062, acc: 84.38%] [G loss: 2.451608]\n",
      "epoch:19 step:15337 [D loss: 0.653104, acc: 64.06%] [G loss: 2.104472]\n",
      "epoch:19 step:15338 [D loss: 0.705070, acc: 52.34%] [G loss: 2.058922]\n",
      "epoch:19 step:15339 [D loss: 0.587778, acc: 64.84%] [G loss: 2.218123]\n",
      "epoch:19 step:15340 [D loss: 0.524753, acc: 82.81%] [G loss: 2.126121]\n",
      "epoch:19 step:15341 [D loss: 0.383750, acc: 92.19%] [G loss: 2.566990]\n",
      "epoch:19 step:15342 [D loss: 0.364797, acc: 92.19%] [G loss: 2.396821]\n",
      "epoch:19 step:15343 [D loss: 0.448636, acc: 85.16%] [G loss: 2.336716]\n",
      "epoch:19 step:15344 [D loss: 0.853988, acc: 40.62%] [G loss: 1.636070]\n",
      "epoch:19 step:15345 [D loss: 0.593829, acc: 62.50%] [G loss: 1.924299]\n",
      "epoch:19 step:15346 [D loss: 0.586341, acc: 68.75%] [G loss: 2.059470]\n",
      "epoch:19 step:15347 [D loss: 0.553603, acc: 76.56%] [G loss: 2.232875]\n",
      "epoch:19 step:15348 [D loss: 0.557931, acc: 75.78%] [G loss: 2.715709]\n",
      "epoch:19 step:15349 [D loss: 0.618710, acc: 68.75%] [G loss: 2.162493]\n",
      "epoch:19 step:15350 [D loss: 0.468839, acc: 85.16%] [G loss: 2.014232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15351 [D loss: 0.780713, acc: 46.09%] [G loss: 1.639900]\n",
      "epoch:19 step:15352 [D loss: 0.803733, acc: 50.78%] [G loss: 1.711891]\n",
      "epoch:19 step:15353 [D loss: 0.433780, acc: 81.25%] [G loss: 3.237467]\n",
      "epoch:19 step:15354 [D loss: 0.788279, acc: 49.22%] [G loss: 2.346366]\n",
      "epoch:19 step:15355 [D loss: 0.445991, acc: 89.06%] [G loss: 2.034517]\n",
      "epoch:19 step:15356 [D loss: 0.556727, acc: 77.34%] [G loss: 2.750465]\n",
      "epoch:19 step:15357 [D loss: 1.199287, acc: 12.50%] [G loss: 1.772487]\n",
      "epoch:19 step:15358 [D loss: 0.723466, acc: 53.91%] [G loss: 2.232305]\n",
      "epoch:19 step:15359 [D loss: 0.445437, acc: 88.28%] [G loss: 2.131594]\n",
      "epoch:19 step:15360 [D loss: 0.444492, acc: 87.50%] [G loss: 2.326178]\n",
      "epoch:19 step:15361 [D loss: 0.738735, acc: 52.34%] [G loss: 1.689619]\n",
      "epoch:19 step:15362 [D loss: 0.586652, acc: 75.78%] [G loss: 2.201633]\n",
      "epoch:19 step:15363 [D loss: 0.567010, acc: 71.09%] [G loss: 2.549745]\n",
      "epoch:19 step:15364 [D loss: 0.710369, acc: 53.91%] [G loss: 1.718893]\n",
      "epoch:19 step:15365 [D loss: 0.535592, acc: 67.19%] [G loss: 2.278449]\n",
      "epoch:19 step:15366 [D loss: 0.608944, acc: 71.88%] [G loss: 1.988177]\n",
      "epoch:19 step:15367 [D loss: 0.499892, acc: 86.72%] [G loss: 2.318915]\n",
      "epoch:19 step:15368 [D loss: 0.426693, acc: 86.72%] [G loss: 2.748630]\n",
      "epoch:19 step:15369 [D loss: 0.658840, acc: 57.81%] [G loss: 1.810724]\n",
      "epoch:19 step:15370 [D loss: 0.598810, acc: 68.75%] [G loss: 2.444566]\n",
      "epoch:19 step:15371 [D loss: 0.601654, acc: 71.88%] [G loss: 2.494896]\n",
      "epoch:19 step:15372 [D loss: 1.176214, acc: 25.00%] [G loss: 2.195692]\n",
      "epoch:19 step:15373 [D loss: 0.303828, acc: 94.53%] [G loss: 2.047507]\n",
      "epoch:19 step:15374 [D loss: 0.578505, acc: 71.88%] [G loss: 2.696309]\n",
      "epoch:19 step:15375 [D loss: 0.392811, acc: 86.72%] [G loss: 2.936524]\n",
      "epoch:19 step:15376 [D loss: 0.196054, acc: 99.22%] [G loss: 2.333642]\n",
      "epoch:19 step:15377 [D loss: 0.348828, acc: 97.66%] [G loss: 3.153568]\n",
      "epoch:19 step:15378 [D loss: 0.740974, acc: 46.09%] [G loss: 2.178158]\n",
      "epoch:19 step:15379 [D loss: 0.713176, acc: 58.59%] [G loss: 2.214583]\n",
      "epoch:19 step:15380 [D loss: 0.304028, acc: 99.22%] [G loss: 2.668708]\n",
      "epoch:19 step:15381 [D loss: 0.467019, acc: 85.16%] [G loss: 2.363110]\n",
      "epoch:19 step:15382 [D loss: 0.544127, acc: 78.12%] [G loss: 2.232822]\n",
      "epoch:19 step:15383 [D loss: 0.696375, acc: 51.56%] [G loss: 2.044663]\n",
      "epoch:19 step:15384 [D loss: 0.526984, acc: 75.00%] [G loss: 2.584502]\n",
      "epoch:19 step:15385 [D loss: 0.930904, acc: 36.72%] [G loss: 2.949885]\n",
      "epoch:19 step:15386 [D loss: 0.532963, acc: 75.00%] [G loss: 2.590498]\n",
      "epoch:19 step:15387 [D loss: 0.554812, acc: 78.91%] [G loss: 2.561338]\n",
      "epoch:19 step:15388 [D loss: 0.332576, acc: 88.28%] [G loss: 2.832614]\n",
      "epoch:19 step:15389 [D loss: 0.605456, acc: 63.28%] [G loss: 2.233104]\n",
      "epoch:19 step:15390 [D loss: 0.303284, acc: 95.31%] [G loss: 1.893788]\n",
      "epoch:19 step:15391 [D loss: 1.037125, acc: 14.84%] [G loss: 1.889139]\n",
      "epoch:19 step:15392 [D loss: 0.969060, acc: 27.34%] [G loss: 1.299301]\n",
      "epoch:19 step:15393 [D loss: 0.752299, acc: 50.00%] [G loss: 2.191614]\n",
      "epoch:19 step:15394 [D loss: 0.280629, acc: 99.22%] [G loss: 3.385497]\n",
      "epoch:19 step:15395 [D loss: 0.546525, acc: 74.22%] [G loss: 2.534943]\n",
      "epoch:19 step:15396 [D loss: 0.473122, acc: 81.25%] [G loss: 2.270880]\n",
      "epoch:19 step:15397 [D loss: 0.696392, acc: 53.91%] [G loss: 1.700429]\n",
      "epoch:19 step:15398 [D loss: 0.498560, acc: 85.16%] [G loss: 2.724332]\n",
      "epoch:19 step:15399 [D loss: 1.002975, acc: 23.44%] [G loss: 1.864211]\n",
      "epoch:19 step:15400 [D loss: 0.719890, acc: 51.56%] [G loss: 3.061590]\n",
      "epoch:19 step:15401 [D loss: 0.424541, acc: 82.03%] [G loss: 2.836643]\n",
      "epoch:19 step:15402 [D loss: 0.522081, acc: 70.31%] [G loss: 2.508268]\n",
      "epoch:19 step:15403 [D loss: 0.683016, acc: 58.59%] [G loss: 2.361780]\n",
      "epoch:19 step:15404 [D loss: 0.789612, acc: 42.97%] [G loss: 1.786698]\n",
      "epoch:19 step:15405 [D loss: 0.431514, acc: 75.00%] [G loss: 2.462759]\n",
      "epoch:19 step:15406 [D loss: 0.410348, acc: 89.06%] [G loss: 2.184289]\n",
      "epoch:19 step:15407 [D loss: 0.579085, acc: 70.31%] [G loss: 2.005357]\n",
      "epoch:19 step:15408 [D loss: 0.504570, acc: 83.59%] [G loss: 2.175618]\n",
      "epoch:19 step:15409 [D loss: 0.566867, acc: 67.19%] [G loss: 1.961679]\n",
      "epoch:19 step:15410 [D loss: 0.474422, acc: 88.28%] [G loss: 1.906247]\n",
      "epoch:19 step:15411 [D loss: 0.833422, acc: 42.97%] [G loss: 2.210378]\n",
      "epoch:19 step:15412 [D loss: 0.592588, acc: 71.88%] [G loss: 2.755388]\n",
      "epoch:19 step:15413 [D loss: 0.689699, acc: 57.81%] [G loss: 2.174616]\n",
      "epoch:19 step:15414 [D loss: 0.626375, acc: 63.28%] [G loss: 2.094109]\n",
      "epoch:19 step:15415 [D loss: 0.564424, acc: 62.50%] [G loss: 3.096210]\n",
      "epoch:19 step:15416 [D loss: 0.286380, acc: 91.41%] [G loss: 2.685709]\n",
      "epoch:19 step:15417 [D loss: 0.557934, acc: 70.31%] [G loss: 2.131043]\n",
      "epoch:19 step:15418 [D loss: 0.631048, acc: 64.84%] [G loss: 2.430990]\n",
      "epoch:19 step:15419 [D loss: 0.629738, acc: 59.38%] [G loss: 2.508641]\n",
      "epoch:19 step:15420 [D loss: 0.503504, acc: 80.47%] [G loss: 2.457250]\n",
      "epoch:19 step:15421 [D loss: 0.564039, acc: 75.78%] [G loss: 1.491482]\n",
      "epoch:19 step:15422 [D loss: 0.533714, acc: 71.09%] [G loss: 1.999714]\n",
      "epoch:19 step:15423 [D loss: 0.691468, acc: 59.38%] [G loss: 2.119714]\n",
      "epoch:19 step:15424 [D loss: 0.581650, acc: 73.44%] [G loss: 2.095931]\n",
      "epoch:19 step:15425 [D loss: 0.437509, acc: 88.28%] [G loss: 2.873239]\n",
      "epoch:19 step:15426 [D loss: 0.495623, acc: 81.25%] [G loss: 2.017745]\n",
      "epoch:19 step:15427 [D loss: 0.606213, acc: 67.19%] [G loss: 1.890037]\n",
      "epoch:19 step:15428 [D loss: 0.766650, acc: 45.31%] [G loss: 1.595783]\n",
      "epoch:19 step:15429 [D loss: 0.464117, acc: 89.06%] [G loss: 2.927176]\n",
      "epoch:19 step:15430 [D loss: 0.472385, acc: 78.91%] [G loss: 2.790581]\n",
      "epoch:19 step:15431 [D loss: 0.692033, acc: 54.69%] [G loss: 2.236352]\n",
      "epoch:19 step:15432 [D loss: 0.544068, acc: 80.47%] [G loss: 2.092177]\n",
      "epoch:19 step:15433 [D loss: 0.621437, acc: 69.53%] [G loss: 1.738355]\n",
      "epoch:19 step:15434 [D loss: 0.500256, acc: 76.56%] [G loss: 1.688259]\n",
      "epoch:19 step:15435 [D loss: 0.843048, acc: 42.19%] [G loss: 2.001657]\n",
      "epoch:19 step:15436 [D loss: 0.844250, acc: 42.19%] [G loss: 2.125404]\n",
      "epoch:19 step:15437 [D loss: 0.330611, acc: 94.53%] [G loss: 1.883812]\n",
      "epoch:19 step:15438 [D loss: 0.779195, acc: 51.56%] [G loss: 1.862546]\n",
      "epoch:19 step:15439 [D loss: 0.640226, acc: 62.50%] [G loss: 2.544371]\n",
      "epoch:19 step:15440 [D loss: 0.518422, acc: 76.56%] [G loss: 3.423770]\n",
      "epoch:19 step:15441 [D loss: 0.701091, acc: 59.38%] [G loss: 2.359024]\n",
      "epoch:19 step:15442 [D loss: 1.003556, acc: 13.28%] [G loss: 1.993836]\n",
      "epoch:19 step:15443 [D loss: 0.405866, acc: 91.41%] [G loss: 2.347807]\n",
      "epoch:19 step:15444 [D loss: 0.573642, acc: 74.22%] [G loss: 2.414385]\n",
      "epoch:19 step:15445 [D loss: 0.534721, acc: 78.12%] [G loss: 2.265447]\n",
      "epoch:19 step:15446 [D loss: 0.689501, acc: 53.91%] [G loss: 1.969696]\n",
      "epoch:19 step:15447 [D loss: 0.527216, acc: 78.91%] [G loss: 1.853383]\n",
      "epoch:19 step:15448 [D loss: 0.622277, acc: 68.75%] [G loss: 1.954610]\n",
      "epoch:19 step:15449 [D loss: 0.967000, acc: 24.22%] [G loss: 1.559835]\n",
      "epoch:19 step:15450 [D loss: 0.446794, acc: 85.16%] [G loss: 2.322922]\n",
      "epoch:19 step:15451 [D loss: 0.262772, acc: 94.53%] [G loss: 3.072564]\n",
      "epoch:19 step:15452 [D loss: 0.935432, acc: 28.91%] [G loss: 1.814037]\n",
      "epoch:19 step:15453 [D loss: 0.284227, acc: 96.88%] [G loss: 2.228814]\n",
      "epoch:19 step:15454 [D loss: 0.393170, acc: 89.84%] [G loss: 3.462229]\n",
      "epoch:19 step:15455 [D loss: 1.050645, acc: 16.41%] [G loss: 2.033305]\n",
      "epoch:19 step:15456 [D loss: 0.604267, acc: 70.31%] [G loss: 2.165472]\n",
      "epoch:19 step:15457 [D loss: 0.897622, acc: 32.81%] [G loss: 1.515930]\n",
      "epoch:19 step:15458 [D loss: 0.878834, acc: 33.59%] [G loss: 1.812328]\n",
      "epoch:19 step:15459 [D loss: 0.704771, acc: 55.47%] [G loss: 2.171593]\n",
      "epoch:19 step:15460 [D loss: 0.397007, acc: 88.28%] [G loss: 1.944552]\n",
      "epoch:19 step:15461 [D loss: 0.594482, acc: 58.59%] [G loss: 2.607622]\n",
      "epoch:19 step:15462 [D loss: 0.486433, acc: 85.16%] [G loss: 2.445506]\n",
      "epoch:19 step:15463 [D loss: 0.312155, acc: 96.09%] [G loss: 1.792518]\n",
      "epoch:19 step:15464 [D loss: 0.577250, acc: 69.53%] [G loss: 2.365123]\n",
      "epoch:19 step:15465 [D loss: 0.465000, acc: 80.47%] [G loss: 2.966780]\n",
      "epoch:19 step:15466 [D loss: 0.543525, acc: 75.78%] [G loss: 2.082102]\n",
      "epoch:19 step:15467 [D loss: 0.499350, acc: 75.00%] [G loss: 2.133578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15468 [D loss: 0.515910, acc: 70.31%] [G loss: 1.473784]\n",
      "epoch:19 step:15469 [D loss: 0.483533, acc: 81.25%] [G loss: 1.887569]\n",
      "epoch:19 step:15470 [D loss: 0.484846, acc: 81.25%] [G loss: 2.538753]\n",
      "epoch:19 step:15471 [D loss: 1.311982, acc: 3.91%] [G loss: 1.573534]\n",
      "epoch:19 step:15472 [D loss: 0.392033, acc: 90.62%] [G loss: 2.596642]\n",
      "epoch:19 step:15473 [D loss: 0.690339, acc: 57.03%] [G loss: 1.538500]\n",
      "epoch:19 step:15474 [D loss: 0.678042, acc: 54.69%] [G loss: 2.025791]\n",
      "epoch:19 step:15475 [D loss: 0.548972, acc: 78.12%] [G loss: 3.348326]\n",
      "epoch:19 step:15476 [D loss: 0.568773, acc: 55.47%] [G loss: 1.753369]\n",
      "epoch:19 step:15477 [D loss: 0.321769, acc: 94.53%] [G loss: 2.503463]\n",
      "epoch:19 step:15478 [D loss: 0.687328, acc: 60.94%] [G loss: 2.127712]\n",
      "epoch:19 step:15479 [D loss: 0.466065, acc: 81.25%] [G loss: 2.223312]\n",
      "epoch:19 step:15480 [D loss: 0.558532, acc: 71.09%] [G loss: 2.461326]\n",
      "epoch:19 step:15481 [D loss: 0.614341, acc: 64.06%] [G loss: 2.147256]\n",
      "epoch:19 step:15482 [D loss: 0.310189, acc: 88.28%] [G loss: 3.143127]\n",
      "epoch:19 step:15483 [D loss: 0.371943, acc: 97.66%] [G loss: 3.184789]\n",
      "epoch:19 step:15484 [D loss: 0.721680, acc: 48.44%] [G loss: 1.861780]\n",
      "epoch:19 step:15485 [D loss: 0.802740, acc: 52.34%] [G loss: 2.981097]\n",
      "epoch:19 step:15486 [D loss: 0.268880, acc: 97.66%] [G loss: 2.275105]\n",
      "epoch:19 step:15487 [D loss: 0.843714, acc: 35.16%] [G loss: 2.083832]\n",
      "epoch:19 step:15488 [D loss: 0.478317, acc: 86.72%] [G loss: 2.013004]\n",
      "epoch:19 step:15489 [D loss: 0.498936, acc: 85.16%] [G loss: 2.306223]\n",
      "epoch:19 step:15490 [D loss: 0.443693, acc: 89.06%] [G loss: 2.846814]\n",
      "epoch:19 step:15491 [D loss: 0.460763, acc: 86.72%] [G loss: 2.131806]\n",
      "epoch:19 step:15492 [D loss: 0.534056, acc: 78.91%] [G loss: 2.208823]\n",
      "epoch:19 step:15493 [D loss: 0.367624, acc: 97.66%] [G loss: 3.018338]\n",
      "epoch:19 step:15494 [D loss: 0.715872, acc: 53.91%] [G loss: 2.643066]\n",
      "epoch:19 step:15495 [D loss: 0.660141, acc: 54.69%] [G loss: 2.471088]\n",
      "epoch:19 step:15496 [D loss: 0.274149, acc: 96.88%] [G loss: 3.300119]\n",
      "epoch:19 step:15497 [D loss: 0.357643, acc: 93.75%] [G loss: 2.717008]\n",
      "epoch:19 step:15498 [D loss: 0.378809, acc: 83.59%] [G loss: 3.058740]\n",
      "epoch:19 step:15499 [D loss: 0.665288, acc: 60.16%] [G loss: 2.405158]\n",
      "epoch:19 step:15500 [D loss: 0.847837, acc: 39.84%] [G loss: 1.883798]\n",
      "epoch:19 step:15501 [D loss: 0.643725, acc: 62.50%] [G loss: 2.733795]\n",
      "epoch:19 step:15502 [D loss: 0.413897, acc: 91.41%] [G loss: 2.626884]\n",
      "epoch:19 step:15503 [D loss: 0.560016, acc: 74.22%] [G loss: 2.770734]\n",
      "epoch:19 step:15504 [D loss: 0.580403, acc: 73.44%] [G loss: 2.142551]\n",
      "epoch:19 step:15505 [D loss: 0.525927, acc: 72.66%] [G loss: 3.317392]\n",
      "epoch:19 step:15506 [D loss: 0.617221, acc: 61.72%] [G loss: 2.218581]\n",
      "epoch:19 step:15507 [D loss: 0.414896, acc: 78.12%] [G loss: 3.056405]\n",
      "epoch:19 step:15508 [D loss: 0.440010, acc: 85.94%] [G loss: 2.016985]\n",
      "epoch:19 step:15509 [D loss: 0.984117, acc: 22.66%] [G loss: 2.061978]\n",
      "epoch:19 step:15510 [D loss: 0.585745, acc: 59.38%] [G loss: 2.881857]\n",
      "epoch:19 step:15511 [D loss: 0.981326, acc: 45.31%] [G loss: 2.274924]\n",
      "epoch:19 step:15512 [D loss: 0.286230, acc: 95.31%] [G loss: 2.601630]\n",
      "epoch:19 step:15513 [D loss: 0.718109, acc: 53.91%] [G loss: 2.355626]\n",
      "epoch:19 step:15514 [D loss: 0.394190, acc: 90.62%] [G loss: 2.587180]\n",
      "epoch:19 step:15515 [D loss: 0.508375, acc: 79.69%] [G loss: 2.559761]\n",
      "epoch:19 step:15516 [D loss: 0.504923, acc: 74.22%] [G loss: 2.194612]\n",
      "epoch:19 step:15517 [D loss: 0.525473, acc: 78.91%] [G loss: 2.194424]\n",
      "epoch:19 step:15518 [D loss: 0.633953, acc: 66.41%] [G loss: 2.152711]\n",
      "epoch:19 step:15519 [D loss: 0.583063, acc: 63.28%] [G loss: 2.366516]\n",
      "epoch:19 step:15520 [D loss: 0.413862, acc: 92.97%] [G loss: 2.193544]\n",
      "epoch:19 step:15521 [D loss: 0.863127, acc: 44.53%] [G loss: 2.224741]\n",
      "epoch:19 step:15522 [D loss: 0.516167, acc: 71.09%] [G loss: 2.821388]\n",
      "epoch:19 step:15523 [D loss: 0.908862, acc: 25.00%] [G loss: 1.321672]\n",
      "epoch:19 step:15524 [D loss: 0.359878, acc: 96.09%] [G loss: 2.379454]\n",
      "epoch:19 step:15525 [D loss: 0.744011, acc: 53.12%] [G loss: 1.897638]\n",
      "epoch:19 step:15526 [D loss: 0.531684, acc: 82.03%] [G loss: 2.359265]\n",
      "epoch:19 step:15527 [D loss: 0.528978, acc: 78.91%] [G loss: 1.755445]\n",
      "epoch:19 step:15528 [D loss: 0.338151, acc: 96.09%] [G loss: 2.962974]\n",
      "epoch:19 step:15529 [D loss: 0.411728, acc: 92.19%] [G loss: 2.641191]\n",
      "epoch:19 step:15530 [D loss: 0.409936, acc: 87.50%] [G loss: 2.251263]\n",
      "epoch:19 step:15531 [D loss: 0.861937, acc: 49.22%] [G loss: 2.364716]\n",
      "epoch:19 step:15532 [D loss: 0.745207, acc: 53.12%] [G loss: 2.799168]\n",
      "epoch:19 step:15533 [D loss: 0.423902, acc: 81.25%] [G loss: 2.300786]\n",
      "epoch:19 step:15534 [D loss: 0.531978, acc: 71.88%] [G loss: 2.445396]\n",
      "epoch:19 step:15535 [D loss: 0.875688, acc: 25.00%] [G loss: 2.154825]\n",
      "epoch:19 step:15536 [D loss: 0.870317, acc: 35.94%] [G loss: 1.971038]\n",
      "epoch:19 step:15537 [D loss: 0.449837, acc: 87.50%] [G loss: 2.419114]\n",
      "epoch:19 step:15538 [D loss: 0.949911, acc: 22.66%] [G loss: 2.524195]\n",
      "epoch:19 step:15539 [D loss: 0.342016, acc: 89.84%] [G loss: 2.205913]\n",
      "epoch:19 step:15540 [D loss: 0.344400, acc: 88.28%] [G loss: 2.656130]\n",
      "epoch:19 step:15541 [D loss: 0.567377, acc: 61.72%] [G loss: 2.318357]\n",
      "epoch:19 step:15542 [D loss: 0.807642, acc: 36.72%] [G loss: 2.120592]\n",
      "epoch:19 step:15543 [D loss: 0.344132, acc: 89.84%] [G loss: 2.656217]\n",
      "epoch:19 step:15544 [D loss: 0.458543, acc: 75.00%] [G loss: 3.068019]\n",
      "epoch:19 step:15545 [D loss: 0.387751, acc: 92.19%] [G loss: 2.208607]\n",
      "epoch:19 step:15546 [D loss: 0.511975, acc: 83.59%] [G loss: 2.252172]\n",
      "epoch:19 step:15547 [D loss: 0.464080, acc: 82.03%] [G loss: 3.131658]\n",
      "epoch:19 step:15548 [D loss: 0.474801, acc: 85.16%] [G loss: 2.071037]\n",
      "epoch:19 step:15549 [D loss: 0.594562, acc: 57.81%] [G loss: 2.228791]\n",
      "epoch:19 step:15550 [D loss: 0.393461, acc: 94.53%] [G loss: 2.314944]\n",
      "epoch:19 step:15551 [D loss: 0.695271, acc: 56.25%] [G loss: 1.564102]\n",
      "epoch:19 step:15552 [D loss: 0.709888, acc: 54.69%] [G loss: 2.882804]\n",
      "epoch:19 step:15553 [D loss: 0.529970, acc: 75.00%] [G loss: 2.319889]\n",
      "epoch:19 step:15554 [D loss: 0.441719, acc: 90.62%] [G loss: 2.214101]\n",
      "epoch:19 step:15555 [D loss: 0.403904, acc: 87.50%] [G loss: 2.328297]\n",
      "epoch:19 step:15556 [D loss: 0.644411, acc: 61.72%] [G loss: 2.395981]\n",
      "epoch:19 step:15557 [D loss: 0.369178, acc: 87.50%] [G loss: 2.462447]\n",
      "epoch:19 step:15558 [D loss: 0.626334, acc: 64.84%] [G loss: 2.284334]\n",
      "epoch:19 step:15559 [D loss: 0.404117, acc: 83.59%] [G loss: 2.061364]\n",
      "epoch:19 step:15560 [D loss: 0.640589, acc: 56.25%] [G loss: 2.411012]\n",
      "epoch:19 step:15561 [D loss: 0.516486, acc: 73.44%] [G loss: 1.919499]\n",
      "epoch:19 step:15562 [D loss: 0.608759, acc: 66.41%] [G loss: 2.300072]\n",
      "epoch:19 step:15563 [D loss: 0.519654, acc: 80.47%] [G loss: 2.465509]\n",
      "epoch:19 step:15564 [D loss: 0.468480, acc: 82.81%] [G loss: 3.662199]\n",
      "epoch:19 step:15565 [D loss: 0.719937, acc: 50.78%] [G loss: 2.491690]\n",
      "epoch:19 step:15566 [D loss: 0.577725, acc: 74.22%] [G loss: 2.655324]\n",
      "epoch:19 step:15567 [D loss: 0.487997, acc: 87.50%] [G loss: 2.286650]\n",
      "epoch:19 step:15568 [D loss: 0.449676, acc: 88.28%] [G loss: 3.364157]\n",
      "epoch:19 step:15569 [D loss: 0.552882, acc: 78.12%] [G loss: 2.546991]\n",
      "epoch:19 step:15570 [D loss: 0.374930, acc: 92.19%] [G loss: 2.346263]\n",
      "epoch:19 step:15571 [D loss: 0.834349, acc: 43.75%] [G loss: 2.193308]\n",
      "epoch:19 step:15572 [D loss: 0.607808, acc: 67.19%] [G loss: 2.007864]\n",
      "epoch:19 step:15573 [D loss: 0.500246, acc: 81.25%] [G loss: 2.156559]\n",
      "epoch:19 step:15574 [D loss: 0.616839, acc: 57.03%] [G loss: 1.735661]\n",
      "epoch:19 step:15575 [D loss: 0.382482, acc: 91.41%] [G loss: 2.621641]\n",
      "epoch:19 step:15576 [D loss: 0.881627, acc: 34.38%] [G loss: 2.219311]\n",
      "epoch:19 step:15577 [D loss: 0.793015, acc: 40.62%] [G loss: 2.260625]\n",
      "epoch:19 step:15578 [D loss: 0.691617, acc: 58.59%] [G loss: 2.306778]\n",
      "epoch:19 step:15579 [D loss: 0.431778, acc: 86.72%] [G loss: 2.322176]\n",
      "epoch:19 step:15580 [D loss: 0.530536, acc: 79.69%] [G loss: 2.806637]\n",
      "epoch:19 step:15581 [D loss: 0.606800, acc: 68.75%] [G loss: 2.361031]\n",
      "epoch:19 step:15582 [D loss: 0.597143, acc: 71.09%] [G loss: 2.887249]\n",
      "epoch:19 step:15583 [D loss: 0.590027, acc: 67.97%] [G loss: 2.588409]\n",
      "epoch:19 step:15584 [D loss: 0.327562, acc: 92.97%] [G loss: 3.196415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15585 [D loss: 0.725837, acc: 46.09%] [G loss: 2.186096]\n",
      "epoch:19 step:15586 [D loss: 0.439975, acc: 85.16%] [G loss: 2.192474]\n",
      "epoch:19 step:15587 [D loss: 0.489772, acc: 74.22%] [G loss: 2.649688]\n",
      "epoch:19 step:15588 [D loss: 0.832070, acc: 39.06%] [G loss: 1.853859]\n",
      "epoch:19 step:15589 [D loss: 0.494077, acc: 82.03%] [G loss: 2.207968]\n",
      "epoch:19 step:15590 [D loss: 1.128401, acc: 21.09%] [G loss: 2.102325]\n",
      "epoch:19 step:15591 [D loss: 0.711419, acc: 53.91%] [G loss: 1.634291]\n",
      "epoch:19 step:15592 [D loss: 0.354059, acc: 89.06%] [G loss: 3.083471]\n",
      "epoch:19 step:15593 [D loss: 0.551873, acc: 71.88%] [G loss: 3.061476]\n",
      "epoch:19 step:15594 [D loss: 0.728071, acc: 51.56%] [G loss: 1.736725]\n",
      "epoch:19 step:15595 [D loss: 0.388468, acc: 87.50%] [G loss: 3.375966]\n",
      "epoch:19 step:15596 [D loss: 0.781966, acc: 52.34%] [G loss: 2.576897]\n",
      "epoch:19 step:15597 [D loss: 0.852615, acc: 35.16%] [G loss: 2.358075]\n",
      "epoch:19 step:15598 [D loss: 0.647370, acc: 62.50%] [G loss: 1.721351]\n",
      "epoch:19 step:15599 [D loss: 0.795538, acc: 43.75%] [G loss: 2.017574]\n",
      "epoch:19 step:15600 [D loss: 0.440530, acc: 92.97%] [G loss: 2.124269]\n",
      "epoch:19 step:15601 [D loss: 0.726553, acc: 51.56%] [G loss: 1.888443]\n",
      "epoch:19 step:15602 [D loss: 0.691405, acc: 57.03%] [G loss: 2.233055]\n",
      "epoch:19 step:15603 [D loss: 0.971996, acc: 43.75%] [G loss: 2.426171]\n",
      "epoch:19 step:15604 [D loss: 0.696840, acc: 56.25%] [G loss: 2.056056]\n",
      "epoch:19 step:15605 [D loss: 0.417213, acc: 82.03%] [G loss: 2.426640]\n",
      "epoch:19 step:15606 [D loss: 0.639366, acc: 60.16%] [G loss: 1.983680]\n",
      "epoch:19 step:15607 [D loss: 0.500255, acc: 81.25%] [G loss: 2.608772]\n",
      "epoch:19 step:15608 [D loss: 0.435718, acc: 75.00%] [G loss: 2.432696]\n",
      "epoch:19 step:15609 [D loss: 0.814832, acc: 41.41%] [G loss: 2.844624]\n",
      "epoch:19 step:15610 [D loss: 0.852630, acc: 42.97%] [G loss: 2.108768]\n",
      "epoch:19 step:15611 [D loss: 0.461162, acc: 77.34%] [G loss: 2.878351]\n",
      "epoch:19 step:15612 [D loss: 0.508580, acc: 72.66%] [G loss: 2.728194]\n",
      "epoch:19 step:15613 [D loss: 0.546722, acc: 72.66%] [G loss: 1.697339]\n",
      "epoch:19 step:15614 [D loss: 0.420447, acc: 79.69%] [G loss: 2.640604]\n",
      "epoch:19 step:15615 [D loss: 0.741195, acc: 53.12%] [G loss: 2.136930]\n",
      "epoch:19 step:15616 [D loss: 0.874121, acc: 37.50%] [G loss: 1.985998]\n",
      "epoch:19 step:15617 [D loss: 0.970027, acc: 22.66%] [G loss: 2.188477]\n",
      "epoch:19 step:15618 [D loss: 0.635148, acc: 66.41%] [G loss: 2.726562]\n",
      "epoch:19 step:15619 [D loss: 0.920317, acc: 29.69%] [G loss: 1.988552]\n",
      "epoch:19 step:15620 [D loss: 0.433477, acc: 84.38%] [G loss: 2.099455]\n",
      "epoch:20 step:15621 [D loss: 0.542375, acc: 78.12%] [G loss: 2.474355]\n",
      "epoch:20 step:15622 [D loss: 0.648943, acc: 53.91%] [G loss: 2.520623]\n",
      "epoch:20 step:15623 [D loss: 0.563609, acc: 70.31%] [G loss: 2.750591]\n",
      "epoch:20 step:15624 [D loss: 0.429532, acc: 93.75%] [G loss: 1.933483]\n",
      "epoch:20 step:15625 [D loss: 0.195834, acc: 99.22%] [G loss: 2.447849]\n",
      "epoch:20 step:15626 [D loss: 0.583481, acc: 57.03%] [G loss: 2.726224]\n",
      "epoch:20 step:15627 [D loss: 0.600859, acc: 63.28%] [G loss: 2.355065]\n",
      "epoch:20 step:15628 [D loss: 0.632101, acc: 69.53%] [G loss: 2.207394]\n",
      "epoch:20 step:15629 [D loss: 0.337860, acc: 96.88%] [G loss: 2.493570]\n",
      "epoch:20 step:15630 [D loss: 0.459196, acc: 87.50%] [G loss: 2.355288]\n",
      "epoch:20 step:15631 [D loss: 0.743510, acc: 50.78%] [G loss: 1.835112]\n",
      "epoch:20 step:15632 [D loss: 0.508073, acc: 77.34%] [G loss: 2.064195]\n",
      "epoch:20 step:15633 [D loss: 0.489105, acc: 82.03%] [G loss: 3.138351]\n",
      "epoch:20 step:15634 [D loss: 0.701747, acc: 54.69%] [G loss: 2.116977]\n",
      "epoch:20 step:15635 [D loss: 0.589442, acc: 69.53%] [G loss: 1.773956]\n",
      "epoch:20 step:15636 [D loss: 0.651917, acc: 58.59%] [G loss: 2.127557]\n",
      "epoch:20 step:15637 [D loss: 0.358693, acc: 91.41%] [G loss: 2.117801]\n",
      "epoch:20 step:15638 [D loss: 0.579647, acc: 69.53%] [G loss: 2.622734]\n",
      "epoch:20 step:15639 [D loss: 0.766699, acc: 50.00%] [G loss: 2.475083]\n",
      "epoch:20 step:15640 [D loss: 0.709224, acc: 57.81%] [G loss: 2.525955]\n",
      "epoch:20 step:15641 [D loss: 0.474640, acc: 83.59%] [G loss: 2.721537]\n",
      "epoch:20 step:15642 [D loss: 0.677142, acc: 64.06%] [G loss: 2.216768]\n",
      "epoch:20 step:15643 [D loss: 0.698623, acc: 58.59%] [G loss: 2.052356]\n",
      "epoch:20 step:15644 [D loss: 1.165723, acc: 30.47%] [G loss: 2.116817]\n",
      "epoch:20 step:15645 [D loss: 0.514706, acc: 76.56%] [G loss: 2.288382]\n",
      "epoch:20 step:15646 [D loss: 0.307339, acc: 96.88%] [G loss: 2.718605]\n",
      "epoch:20 step:15647 [D loss: 0.458880, acc: 86.72%] [G loss: 1.699578]\n",
      "epoch:20 step:15648 [D loss: 0.832329, acc: 48.44%] [G loss: 2.280718]\n",
      "epoch:20 step:15649 [D loss: 0.412509, acc: 92.97%] [G loss: 3.001225]\n",
      "epoch:20 step:15650 [D loss: 0.456603, acc: 82.81%] [G loss: 2.401615]\n",
      "epoch:20 step:15651 [D loss: 0.342843, acc: 91.41%] [G loss: 2.524392]\n",
      "epoch:20 step:15652 [D loss: 0.684076, acc: 56.25%] [G loss: 2.261511]\n",
      "epoch:20 step:15653 [D loss: 0.454033, acc: 88.28%] [G loss: 1.851740]\n",
      "epoch:20 step:15654 [D loss: 0.332918, acc: 96.88%] [G loss: 2.161982]\n",
      "epoch:20 step:15655 [D loss: 0.710490, acc: 57.03%] [G loss: 2.494621]\n",
      "epoch:20 step:15656 [D loss: 0.758537, acc: 51.56%] [G loss: 1.717185]\n",
      "epoch:20 step:15657 [D loss: 1.013368, acc: 32.03%] [G loss: 1.574320]\n",
      "epoch:20 step:15658 [D loss: 0.531233, acc: 80.47%] [G loss: 2.019778]\n",
      "epoch:20 step:15659 [D loss: 0.416582, acc: 81.25%] [G loss: 2.389571]\n",
      "epoch:20 step:15660 [D loss: 0.464072, acc: 75.00%] [G loss: 2.311924]\n",
      "epoch:20 step:15661 [D loss: 0.756411, acc: 44.53%] [G loss: 2.527063]\n",
      "epoch:20 step:15662 [D loss: 0.715428, acc: 54.69%] [G loss: 2.535066]\n",
      "epoch:20 step:15663 [D loss: 0.562534, acc: 65.62%] [G loss: 2.645915]\n",
      "epoch:20 step:15664 [D loss: 1.050816, acc: 14.06%] [G loss: 1.772197]\n",
      "epoch:20 step:15665 [D loss: 0.465062, acc: 84.38%] [G loss: 3.278229]\n",
      "epoch:20 step:15666 [D loss: 0.415850, acc: 82.81%] [G loss: 2.133428]\n",
      "epoch:20 step:15667 [D loss: 0.773940, acc: 50.00%] [G loss: 2.111063]\n",
      "epoch:20 step:15668 [D loss: 0.957885, acc: 36.72%] [G loss: 2.153242]\n",
      "epoch:20 step:15669 [D loss: 0.681615, acc: 53.91%] [G loss: 2.269925]\n",
      "epoch:20 step:15670 [D loss: 0.306207, acc: 92.19%] [G loss: 1.768023]\n",
      "epoch:20 step:15671 [D loss: 0.470263, acc: 79.69%] [G loss: 1.940994]\n",
      "epoch:20 step:15672 [D loss: 0.635696, acc: 64.84%] [G loss: 2.620899]\n",
      "epoch:20 step:15673 [D loss: 0.655730, acc: 57.03%] [G loss: 2.700599]\n",
      "epoch:20 step:15674 [D loss: 1.279809, acc: 9.38%] [G loss: 1.985537]\n",
      "epoch:20 step:15675 [D loss: 1.050607, acc: 18.75%] [G loss: 1.842282]\n",
      "epoch:20 step:15676 [D loss: 0.458043, acc: 87.50%] [G loss: 1.786462]\n",
      "epoch:20 step:15677 [D loss: 0.398356, acc: 94.53%] [G loss: 2.321355]\n",
      "epoch:20 step:15678 [D loss: 0.671594, acc: 59.38%] [G loss: 1.744832]\n",
      "epoch:20 step:15679 [D loss: 0.422328, acc: 89.84%] [G loss: 2.405961]\n",
      "epoch:20 step:15680 [D loss: 0.508347, acc: 73.44%] [G loss: 2.736927]\n",
      "epoch:20 step:15681 [D loss: 0.660015, acc: 58.59%] [G loss: 1.943540]\n",
      "epoch:20 step:15682 [D loss: 0.497407, acc: 84.38%] [G loss: 2.166554]\n",
      "epoch:20 step:15683 [D loss: 0.457295, acc: 86.72%] [G loss: 2.146801]\n",
      "epoch:20 step:15684 [D loss: 0.486056, acc: 86.72%] [G loss: 2.176562]\n",
      "epoch:20 step:15685 [D loss: 0.594302, acc: 67.19%] [G loss: 3.033813]\n",
      "epoch:20 step:15686 [D loss: 0.403159, acc: 92.19%] [G loss: 2.541548]\n",
      "epoch:20 step:15687 [D loss: 0.784928, acc: 46.09%] [G loss: 1.199022]\n",
      "epoch:20 step:15688 [D loss: 0.742546, acc: 50.00%] [G loss: 1.952867]\n",
      "epoch:20 step:15689 [D loss: 0.486818, acc: 83.59%] [G loss: 2.516533]\n",
      "epoch:20 step:15690 [D loss: 0.472053, acc: 82.03%] [G loss: 2.381163]\n",
      "epoch:20 step:15691 [D loss: 1.061308, acc: 26.56%] [G loss: 2.103807]\n",
      "epoch:20 step:15692 [D loss: 1.068872, acc: 23.44%] [G loss: 1.790510]\n",
      "epoch:20 step:15693 [D loss: 0.632374, acc: 60.94%] [G loss: 2.845923]\n",
      "epoch:20 step:15694 [D loss: 0.510940, acc: 77.34%] [G loss: 3.001791]\n",
      "epoch:20 step:15695 [D loss: 0.624237, acc: 65.62%] [G loss: 2.020032]\n",
      "epoch:20 step:15696 [D loss: 0.757779, acc: 49.22%] [G loss: 2.870596]\n",
      "epoch:20 step:15697 [D loss: 0.773553, acc: 44.53%] [G loss: 1.953955]\n",
      "epoch:20 step:15698 [D loss: 0.495614, acc: 75.78%] [G loss: 2.067849]\n",
      "epoch:20 step:15699 [D loss: 0.498977, acc: 85.94%] [G loss: 2.263103]\n",
      "epoch:20 step:15700 [D loss: 0.505122, acc: 86.72%] [G loss: 2.664372]\n",
      "epoch:20 step:15701 [D loss: 0.807100, acc: 44.53%] [G loss: 1.997615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15702 [D loss: 0.457907, acc: 86.72%] [G loss: 2.917458]\n",
      "epoch:20 step:15703 [D loss: 0.611973, acc: 66.41%] [G loss: 2.084671]\n",
      "epoch:20 step:15704 [D loss: 0.765212, acc: 48.44%] [G loss: 1.414218]\n",
      "epoch:20 step:15705 [D loss: 0.435404, acc: 89.06%] [G loss: 2.330708]\n",
      "epoch:20 step:15706 [D loss: 0.755780, acc: 49.22%] [G loss: 1.724270]\n",
      "epoch:20 step:15707 [D loss: 0.572434, acc: 67.97%] [G loss: 2.616402]\n",
      "epoch:20 step:15708 [D loss: 0.507228, acc: 68.75%] [G loss: 2.081266]\n",
      "epoch:20 step:15709 [D loss: 0.685164, acc: 58.59%] [G loss: 1.864166]\n",
      "epoch:20 step:15710 [D loss: 0.513677, acc: 75.00%] [G loss: 2.194864]\n",
      "epoch:20 step:15711 [D loss: 0.255642, acc: 98.44%] [G loss: 2.265220]\n",
      "epoch:20 step:15712 [D loss: 0.702792, acc: 53.91%] [G loss: 1.895805]\n",
      "epoch:20 step:15713 [D loss: 0.555609, acc: 78.91%] [G loss: 1.916003]\n",
      "epoch:20 step:15714 [D loss: 0.355788, acc: 96.88%] [G loss: 2.455487]\n",
      "epoch:20 step:15715 [D loss: 0.472249, acc: 82.81%] [G loss: 2.157224]\n",
      "epoch:20 step:15716 [D loss: 0.999504, acc: 18.75%] [G loss: 2.248409]\n",
      "epoch:20 step:15717 [D loss: 0.606580, acc: 70.31%] [G loss: 2.324039]\n",
      "epoch:20 step:15718 [D loss: 0.613849, acc: 57.03%] [G loss: 2.104268]\n",
      "epoch:20 step:15719 [D loss: 0.333108, acc: 95.31%] [G loss: 2.379583]\n",
      "epoch:20 step:15720 [D loss: 0.402797, acc: 91.41%] [G loss: 2.560950]\n",
      "epoch:20 step:15721 [D loss: 0.962484, acc: 21.88%] [G loss: 2.232340]\n",
      "epoch:20 step:15722 [D loss: 0.322470, acc: 94.53%] [G loss: 2.905349]\n",
      "epoch:20 step:15723 [D loss: 0.804262, acc: 42.97%] [G loss: 1.939819]\n",
      "epoch:20 step:15724 [D loss: 0.594920, acc: 73.44%] [G loss: 2.238528]\n",
      "epoch:20 step:15725 [D loss: 0.730130, acc: 51.56%] [G loss: 2.110109]\n",
      "epoch:20 step:15726 [D loss: 0.583888, acc: 71.09%] [G loss: 2.111743]\n",
      "epoch:20 step:15727 [D loss: 0.670015, acc: 60.16%] [G loss: 1.701855]\n",
      "epoch:20 step:15728 [D loss: 1.088134, acc: 16.41%] [G loss: 2.012058]\n",
      "epoch:20 step:15729 [D loss: 0.839204, acc: 50.00%] [G loss: 1.840805]\n",
      "epoch:20 step:15730 [D loss: 0.487601, acc: 80.47%] [G loss: 2.693364]\n",
      "epoch:20 step:15731 [D loss: 0.673869, acc: 51.56%] [G loss: 1.518251]\n",
      "epoch:20 step:15732 [D loss: 0.424311, acc: 85.16%] [G loss: 1.762526]\n",
      "epoch:20 step:15733 [D loss: 0.400967, acc: 89.06%] [G loss: 2.677947]\n",
      "epoch:20 step:15734 [D loss: 0.414609, acc: 86.72%] [G loss: 2.212409]\n",
      "epoch:20 step:15735 [D loss: 0.868686, acc: 36.72%] [G loss: 1.811594]\n",
      "epoch:20 step:15736 [D loss: 0.404131, acc: 79.69%] [G loss: 2.537994]\n",
      "epoch:20 step:15737 [D loss: 0.714113, acc: 51.56%] [G loss: 1.849627]\n",
      "epoch:20 step:15738 [D loss: 0.557459, acc: 69.53%] [G loss: 2.479912]\n",
      "epoch:20 step:15739 [D loss: 0.524606, acc: 80.47%] [G loss: 2.614579]\n",
      "epoch:20 step:15740 [D loss: 0.629032, acc: 64.06%] [G loss: 1.976769]\n",
      "epoch:20 step:15741 [D loss: 0.399615, acc: 78.91%] [G loss: 2.700129]\n",
      "epoch:20 step:15742 [D loss: 0.705840, acc: 56.25%] [G loss: 2.569860]\n",
      "epoch:20 step:15743 [D loss: 0.426571, acc: 88.28%] [G loss: 2.754525]\n",
      "epoch:20 step:15744 [D loss: 0.431734, acc: 89.06%] [G loss: 2.403424]\n",
      "epoch:20 step:15745 [D loss: 0.719245, acc: 51.56%] [G loss: 1.687015]\n",
      "epoch:20 step:15746 [D loss: 0.586436, acc: 66.41%] [G loss: 2.306016]\n",
      "epoch:20 step:15747 [D loss: 0.646700, acc: 64.84%] [G loss: 2.333788]\n",
      "epoch:20 step:15748 [D loss: 0.543205, acc: 72.66%] [G loss: 2.343650]\n",
      "epoch:20 step:15749 [D loss: 0.212170, acc: 96.88%] [G loss: 2.584619]\n",
      "epoch:20 step:15750 [D loss: 0.574326, acc: 72.66%] [G loss: 2.072651]\n",
      "epoch:20 step:15751 [D loss: 0.393221, acc: 95.31%] [G loss: 2.840195]\n",
      "epoch:20 step:15752 [D loss: 0.433484, acc: 87.50%] [G loss: 2.288151]\n",
      "epoch:20 step:15753 [D loss: 0.530483, acc: 69.53%] [G loss: 2.223979]\n",
      "epoch:20 step:15754 [D loss: 0.437091, acc: 91.41%] [G loss: 2.396805]\n",
      "epoch:20 step:15755 [D loss: 0.609828, acc: 64.84%] [G loss: 2.996710]\n",
      "epoch:20 step:15756 [D loss: 0.392863, acc: 92.97%] [G loss: 3.304149]\n",
      "epoch:20 step:15757 [D loss: 0.510423, acc: 78.12%] [G loss: 2.662662]\n",
      "epoch:20 step:15758 [D loss: 0.378716, acc: 95.31%] [G loss: 2.800613]\n",
      "epoch:20 step:15759 [D loss: 0.317432, acc: 98.44%] [G loss: 2.633331]\n",
      "epoch:20 step:15760 [D loss: 0.379989, acc: 96.88%] [G loss: 2.693519]\n",
      "epoch:20 step:15761 [D loss: 0.603643, acc: 61.72%] [G loss: 3.238607]\n",
      "epoch:20 step:15762 [D loss: 0.693799, acc: 57.81%] [G loss: 2.071022]\n",
      "epoch:20 step:15763 [D loss: 0.496417, acc: 63.28%] [G loss: 3.505692]\n",
      "epoch:20 step:15764 [D loss: 0.874914, acc: 41.41%] [G loss: 2.459016]\n",
      "epoch:20 step:15765 [D loss: 0.455105, acc: 87.50%] [G loss: 2.652388]\n",
      "epoch:20 step:15766 [D loss: 0.328211, acc: 89.06%] [G loss: 2.132874]\n",
      "epoch:20 step:15767 [D loss: 0.486172, acc: 71.09%] [G loss: 2.569891]\n",
      "epoch:20 step:15768 [D loss: 0.839842, acc: 36.72%] [G loss: 2.478756]\n",
      "epoch:20 step:15769 [D loss: 0.790042, acc: 50.78%] [G loss: 2.454088]\n",
      "epoch:20 step:15770 [D loss: 0.642625, acc: 66.41%] [G loss: 2.209409]\n",
      "epoch:20 step:15771 [D loss: 0.203433, acc: 96.88%] [G loss: 3.280868]\n",
      "epoch:20 step:15772 [D loss: 0.528502, acc: 75.78%] [G loss: 2.155403]\n",
      "epoch:20 step:15773 [D loss: 0.562581, acc: 65.62%] [G loss: 2.168535]\n",
      "epoch:20 step:15774 [D loss: 0.493618, acc: 82.81%] [G loss: 2.224289]\n",
      "epoch:20 step:15775 [D loss: 0.466917, acc: 84.38%] [G loss: 2.134774]\n",
      "epoch:20 step:15776 [D loss: 0.446149, acc: 84.38%] [G loss: 3.087383]\n",
      "epoch:20 step:15777 [D loss: 0.515475, acc: 78.12%] [G loss: 3.034901]\n",
      "epoch:20 step:15778 [D loss: 0.752822, acc: 53.12%] [G loss: 1.926669]\n",
      "epoch:20 step:15779 [D loss: 0.405241, acc: 82.81%] [G loss: 3.629833]\n",
      "epoch:20 step:15780 [D loss: 1.105766, acc: 10.16%] [G loss: 2.346790]\n",
      "epoch:20 step:15781 [D loss: 0.404356, acc: 92.97%] [G loss: 2.533802]\n",
      "epoch:20 step:15782 [D loss: 0.402733, acc: 82.03%] [G loss: 2.896049]\n",
      "epoch:20 step:15783 [D loss: 0.330594, acc: 91.41%] [G loss: 2.267459]\n",
      "epoch:20 step:15784 [D loss: 0.842913, acc: 39.06%] [G loss: 1.933658]\n",
      "epoch:20 step:15785 [D loss: 0.424766, acc: 86.72%] [G loss: 4.314436]\n",
      "epoch:20 step:15786 [D loss: 0.609980, acc: 63.28%] [G loss: 2.817970]\n",
      "epoch:20 step:15787 [D loss: 0.235886, acc: 98.44%] [G loss: 4.036048]\n",
      "epoch:20 step:15788 [D loss: 0.557381, acc: 74.22%] [G loss: 2.592854]\n",
      "epoch:20 step:15789 [D loss: 0.418271, acc: 92.19%] [G loss: 1.884958]\n",
      "epoch:20 step:15790 [D loss: 1.057698, acc: 46.88%] [G loss: 2.361045]\n",
      "epoch:20 step:15791 [D loss: 0.515834, acc: 71.88%] [G loss: 2.394260]\n",
      "epoch:20 step:15792 [D loss: 0.456708, acc: 85.94%] [G loss: 2.782373]\n",
      "epoch:20 step:15793 [D loss: 0.755153, acc: 46.09%] [G loss: 2.249169]\n",
      "epoch:20 step:15794 [D loss: 0.738667, acc: 51.56%] [G loss: 2.773256]\n",
      "epoch:20 step:15795 [D loss: 0.670688, acc: 57.81%] [G loss: 1.847379]\n",
      "epoch:20 step:15796 [D loss: 0.751190, acc: 49.22%] [G loss: 1.620347]\n",
      "epoch:20 step:15797 [D loss: 0.261894, acc: 96.09%] [G loss: 2.177516]\n",
      "epoch:20 step:15798 [D loss: 0.980153, acc: 31.25%] [G loss: 2.150204]\n",
      "epoch:20 step:15799 [D loss: 0.655376, acc: 60.94%] [G loss: 1.667594]\n",
      "epoch:20 step:15800 [D loss: 0.374514, acc: 91.41%] [G loss: 2.327589]\n",
      "epoch:20 step:15801 [D loss: 0.660705, acc: 58.59%] [G loss: 1.987491]\n",
      "epoch:20 step:15802 [D loss: 0.651952, acc: 59.38%] [G loss: 1.871314]\n",
      "epoch:20 step:15803 [D loss: 0.468821, acc: 88.28%] [G loss: 2.240151]\n",
      "epoch:20 step:15804 [D loss: 0.917970, acc: 28.12%] [G loss: 1.158513]\n",
      "epoch:20 step:15805 [D loss: 0.761832, acc: 50.78%] [G loss: 1.809381]\n",
      "epoch:20 step:15806 [D loss: 0.620977, acc: 67.97%] [G loss: 2.523306]\n",
      "epoch:20 step:15807 [D loss: 0.283071, acc: 98.44%] [G loss: 2.768254]\n",
      "epoch:20 step:15808 [D loss: 0.627767, acc: 60.16%] [G loss: 2.136416]\n",
      "epoch:20 step:15809 [D loss: 0.477393, acc: 85.94%] [G loss: 3.101059]\n",
      "epoch:20 step:15810 [D loss: 0.535769, acc: 78.91%] [G loss: 3.068630]\n",
      "epoch:20 step:15811 [D loss: 0.421867, acc: 73.44%] [G loss: 3.827100]\n",
      "epoch:20 step:15812 [D loss: 0.657746, acc: 64.06%] [G loss: 2.260570]\n",
      "epoch:20 step:15813 [D loss: 0.471398, acc: 79.69%] [G loss: 1.995332]\n",
      "epoch:20 step:15814 [D loss: 0.527161, acc: 81.25%] [G loss: 2.449045]\n",
      "epoch:20 step:15815 [D loss: 0.791814, acc: 50.00%] [G loss: 2.813580]\n",
      "epoch:20 step:15816 [D loss: 0.717145, acc: 53.12%] [G loss: 1.971305]\n",
      "epoch:20 step:15817 [D loss: 0.304689, acc: 99.22%] [G loss: 2.576923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15818 [D loss: 0.621661, acc: 67.97%] [G loss: 2.545793]\n",
      "epoch:20 step:15819 [D loss: 0.524654, acc: 67.19%] [G loss: 2.413831]\n",
      "epoch:20 step:15820 [D loss: 0.527610, acc: 65.62%] [G loss: 2.868227]\n",
      "epoch:20 step:15821 [D loss: 0.572704, acc: 71.88%] [G loss: 2.387145]\n",
      "epoch:20 step:15822 [D loss: 1.030450, acc: 18.75%] [G loss: 1.869239]\n",
      "epoch:20 step:15823 [D loss: 0.735326, acc: 46.09%] [G loss: 1.543190]\n",
      "epoch:20 step:15824 [D loss: 1.154413, acc: 7.81%] [G loss: 1.606917]\n",
      "epoch:20 step:15825 [D loss: 0.841859, acc: 40.62%] [G loss: 1.926314]\n",
      "epoch:20 step:15826 [D loss: 0.871948, acc: 28.12%] [G loss: 2.258343]\n",
      "epoch:20 step:15827 [D loss: 0.612790, acc: 67.19%] [G loss: 2.205300]\n",
      "epoch:20 step:15828 [D loss: 0.428098, acc: 92.97%] [G loss: 2.225599]\n",
      "epoch:20 step:15829 [D loss: 0.627400, acc: 63.28%] [G loss: 1.883456]\n",
      "epoch:20 step:15830 [D loss: 0.777257, acc: 47.66%] [G loss: 2.164522]\n",
      "epoch:20 step:15831 [D loss: 0.347564, acc: 96.09%] [G loss: 2.087702]\n",
      "epoch:20 step:15832 [D loss: 0.501173, acc: 85.16%] [G loss: 3.758446]\n",
      "epoch:20 step:15833 [D loss: 0.771590, acc: 47.66%] [G loss: 2.520510]\n",
      "epoch:20 step:15834 [D loss: 0.360427, acc: 95.31%] [G loss: 4.270533]\n",
      "epoch:20 step:15835 [D loss: 0.545743, acc: 74.22%] [G loss: 2.077475]\n",
      "epoch:20 step:15836 [D loss: 0.777840, acc: 43.75%] [G loss: 3.260796]\n",
      "epoch:20 step:15837 [D loss: 0.706764, acc: 56.25%] [G loss: 2.285319]\n",
      "epoch:20 step:15838 [D loss: 0.401314, acc: 92.97%] [G loss: 2.088612]\n",
      "epoch:20 step:15839 [D loss: 0.516035, acc: 85.94%] [G loss: 2.261311]\n",
      "epoch:20 step:15840 [D loss: 0.596402, acc: 67.97%] [G loss: 2.545538]\n",
      "epoch:20 step:15841 [D loss: 0.723291, acc: 53.91%] [G loss: 1.888740]\n",
      "epoch:20 step:15842 [D loss: 0.382764, acc: 96.88%] [G loss: 2.599556]\n",
      "epoch:20 step:15843 [D loss: 0.430720, acc: 86.72%] [G loss: 2.363245]\n",
      "epoch:20 step:15844 [D loss: 0.599228, acc: 72.66%] [G loss: 1.792053]\n",
      "epoch:20 step:15845 [D loss: 0.599539, acc: 58.59%] [G loss: 2.734367]\n",
      "epoch:20 step:15846 [D loss: 0.678261, acc: 56.25%] [G loss: 2.207826]\n",
      "epoch:20 step:15847 [D loss: 0.351986, acc: 95.31%] [G loss: 1.984650]\n",
      "epoch:20 step:15848 [D loss: 0.434860, acc: 66.41%] [G loss: 1.910024]\n",
      "epoch:20 step:15849 [D loss: 0.369308, acc: 90.62%] [G loss: 2.556037]\n",
      "epoch:20 step:15850 [D loss: 0.973838, acc: 22.66%] [G loss: 1.735262]\n",
      "epoch:20 step:15851 [D loss: 0.580326, acc: 67.19%] [G loss: 1.611423]\n",
      "epoch:20 step:15852 [D loss: 0.798530, acc: 46.09%] [G loss: 1.909438]\n",
      "epoch:20 step:15853 [D loss: 0.296614, acc: 94.53%] [G loss: 2.007851]\n",
      "epoch:20 step:15854 [D loss: 1.115636, acc: 14.06%] [G loss: 1.969530]\n",
      "epoch:20 step:15855 [D loss: 0.646244, acc: 60.94%] [G loss: 2.661937]\n",
      "epoch:20 step:15856 [D loss: 0.579708, acc: 67.19%] [G loss: 2.678253]\n",
      "epoch:20 step:15857 [D loss: 0.456422, acc: 90.62%] [G loss: 2.908891]\n",
      "epoch:20 step:15858 [D loss: 0.567614, acc: 64.84%] [G loss: 2.062383]\n",
      "epoch:20 step:15859 [D loss: 0.704583, acc: 59.38%] [G loss: 2.048589]\n",
      "epoch:20 step:15860 [D loss: 0.482219, acc: 85.16%] [G loss: 1.944459]\n",
      "epoch:20 step:15861 [D loss: 0.635362, acc: 65.62%] [G loss: 2.892932]\n",
      "epoch:20 step:15862 [D loss: 0.420886, acc: 89.84%] [G loss: 1.824568]\n",
      "epoch:20 step:15863 [D loss: 0.224421, acc: 100.00%] [G loss: 2.001339]\n",
      "epoch:20 step:15864 [D loss: 0.525761, acc: 74.22%] [G loss: 2.448076]\n",
      "epoch:20 step:15865 [D loss: 0.910646, acc: 24.22%] [G loss: 2.057738]\n",
      "epoch:20 step:15866 [D loss: 0.678007, acc: 59.38%] [G loss: 2.407862]\n",
      "epoch:20 step:15867 [D loss: 1.034763, acc: 18.75%] [G loss: 1.251082]\n",
      "epoch:20 step:15868 [D loss: 0.596282, acc: 67.97%] [G loss: 1.885713]\n",
      "epoch:20 step:15869 [D loss: 0.625318, acc: 61.72%] [G loss: 2.228993]\n",
      "epoch:20 step:15870 [D loss: 0.566724, acc: 71.09%] [G loss: 2.489100]\n",
      "epoch:20 step:15871 [D loss: 0.472085, acc: 84.38%] [G loss: 2.456653]\n",
      "epoch:20 step:15872 [D loss: 0.822609, acc: 38.28%] [G loss: 1.757884]\n",
      "epoch:20 step:15873 [D loss: 0.915773, acc: 32.03%] [G loss: 2.148068]\n",
      "epoch:20 step:15874 [D loss: 0.390155, acc: 93.75%] [G loss: 2.092730]\n",
      "epoch:20 step:15875 [D loss: 0.485285, acc: 82.81%] [G loss: 1.857823]\n",
      "epoch:20 step:15876 [D loss: 0.740692, acc: 49.22%] [G loss: 2.001337]\n",
      "epoch:20 step:15877 [D loss: 0.524301, acc: 78.12%] [G loss: 1.858386]\n",
      "epoch:20 step:15878 [D loss: 0.599934, acc: 63.28%] [G loss: 2.948961]\n",
      "epoch:20 step:15879 [D loss: 0.671850, acc: 54.69%] [G loss: 1.868477]\n",
      "epoch:20 step:15880 [D loss: 0.605357, acc: 67.97%] [G loss: 2.377279]\n",
      "epoch:20 step:15881 [D loss: 0.566660, acc: 72.66%] [G loss: 2.500332]\n",
      "epoch:20 step:15882 [D loss: 0.342856, acc: 96.88%] [G loss: 2.449075]\n",
      "epoch:20 step:15883 [D loss: 0.727006, acc: 49.22%] [G loss: 2.370551]\n",
      "epoch:20 step:15884 [D loss: 0.361006, acc: 95.31%] [G loss: 2.192697]\n",
      "epoch:20 step:15885 [D loss: 0.690487, acc: 55.47%] [G loss: 2.391182]\n",
      "epoch:20 step:15886 [D loss: 0.463720, acc: 84.38%] [G loss: 2.475244]\n",
      "epoch:20 step:15887 [D loss: 0.815550, acc: 37.50%] [G loss: 1.832353]\n",
      "epoch:20 step:15888 [D loss: 0.295147, acc: 100.00%] [G loss: 2.661617]\n",
      "epoch:20 step:15889 [D loss: 0.574554, acc: 74.22%] [G loss: 1.869548]\n",
      "epoch:20 step:15890 [D loss: 0.564986, acc: 67.19%] [G loss: 2.377065]\n",
      "epoch:20 step:15891 [D loss: 0.800573, acc: 46.09%] [G loss: 2.519206]\n",
      "epoch:20 step:15892 [D loss: 0.824037, acc: 39.84%] [G loss: 2.075423]\n",
      "epoch:20 step:15893 [D loss: 0.612409, acc: 68.75%] [G loss: 2.211967]\n",
      "epoch:20 step:15894 [D loss: 0.880018, acc: 34.38%] [G loss: 2.214577]\n",
      "epoch:20 step:15895 [D loss: 0.864721, acc: 32.81%] [G loss: 2.260837]\n",
      "epoch:20 step:15896 [D loss: 0.592766, acc: 67.97%] [G loss: 2.206867]\n",
      "epoch:20 step:15897 [D loss: 0.850041, acc: 38.28%] [G loss: 2.174764]\n",
      "epoch:20 step:15898 [D loss: 0.600180, acc: 67.97%] [G loss: 2.419535]\n",
      "epoch:20 step:15899 [D loss: 0.756845, acc: 50.00%] [G loss: 2.419488]\n",
      "epoch:20 step:15900 [D loss: 0.389480, acc: 93.75%] [G loss: 2.062293]\n",
      "epoch:20 step:15901 [D loss: 0.679143, acc: 57.81%] [G loss: 2.314307]\n",
      "epoch:20 step:15902 [D loss: 0.466434, acc: 75.78%] [G loss: 2.279664]\n",
      "epoch:20 step:15903 [D loss: 0.408932, acc: 92.19%] [G loss: 2.465306]\n",
      "epoch:20 step:15904 [D loss: 0.363180, acc: 93.75%] [G loss: 3.621398]\n",
      "epoch:20 step:15905 [D loss: 0.734738, acc: 47.66%] [G loss: 2.464572]\n",
      "epoch:20 step:15906 [D loss: 0.511790, acc: 82.81%] [G loss: 2.246841]\n",
      "epoch:20 step:15907 [D loss: 1.018252, acc: 21.09%] [G loss: 1.755837]\n",
      "epoch:20 step:15908 [D loss: 0.986883, acc: 20.31%] [G loss: 1.820029]\n",
      "epoch:20 step:15909 [D loss: 0.596738, acc: 66.41%] [G loss: 1.776429]\n",
      "epoch:20 step:15910 [D loss: 0.583122, acc: 61.72%] [G loss: 1.735181]\n",
      "epoch:20 step:15911 [D loss: 0.603366, acc: 57.03%] [G loss: 2.735665]\n",
      "epoch:20 step:15912 [D loss: 0.557123, acc: 71.09%] [G loss: 2.359507]\n",
      "epoch:20 step:15913 [D loss: 0.609289, acc: 67.97%] [G loss: 2.260823]\n",
      "epoch:20 step:15914 [D loss: 0.563629, acc: 81.25%] [G loss: 1.755913]\n",
      "epoch:20 step:15915 [D loss: 0.694460, acc: 55.47%] [G loss: 2.396098]\n",
      "epoch:20 step:15916 [D loss: 0.472447, acc: 89.06%] [G loss: 2.602115]\n",
      "epoch:20 step:15917 [D loss: 0.685640, acc: 57.03%] [G loss: 3.048640]\n",
      "epoch:20 step:15918 [D loss: 0.523790, acc: 85.94%] [G loss: 2.345599]\n",
      "epoch:20 step:15919 [D loss: 0.360859, acc: 93.75%] [G loss: 1.952699]\n",
      "epoch:20 step:15920 [D loss: 0.608018, acc: 69.53%] [G loss: 2.228545]\n",
      "epoch:20 step:15921 [D loss: 0.616166, acc: 67.19%] [G loss: 2.565471]\n",
      "epoch:20 step:15922 [D loss: 0.592732, acc: 72.66%] [G loss: 2.084953]\n",
      "epoch:20 step:15923 [D loss: 0.978293, acc: 31.25%] [G loss: 2.177957]\n",
      "epoch:20 step:15924 [D loss: 0.455284, acc: 80.47%] [G loss: 2.247354]\n",
      "epoch:20 step:15925 [D loss: 0.378792, acc: 93.75%] [G loss: 2.197142]\n",
      "epoch:20 step:15926 [D loss: 0.643482, acc: 64.06%] [G loss: 2.547445]\n",
      "epoch:20 step:15927 [D loss: 0.690514, acc: 60.16%] [G loss: 2.229317]\n",
      "epoch:20 step:15928 [D loss: 0.324693, acc: 96.09%] [G loss: 2.318576]\n",
      "epoch:20 step:15929 [D loss: 0.356169, acc: 96.09%] [G loss: 2.723705]\n",
      "epoch:20 step:15930 [D loss: 0.838099, acc: 33.59%] [G loss: 1.789380]\n",
      "epoch:20 step:15931 [D loss: 0.709419, acc: 51.56%] [G loss: 1.970521]\n",
      "epoch:20 step:15932 [D loss: 0.626799, acc: 62.50%] [G loss: 1.977718]\n",
      "epoch:20 step:15933 [D loss: 0.685134, acc: 58.59%] [G loss: 2.261471]\n",
      "epoch:20 step:15934 [D loss: 0.605662, acc: 66.41%] [G loss: 2.436655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15935 [D loss: 0.627463, acc: 60.16%] [G loss: 1.939933]\n",
      "epoch:20 step:15936 [D loss: 0.449428, acc: 77.34%] [G loss: 2.323964]\n",
      "epoch:20 step:15937 [D loss: 0.449476, acc: 90.62%] [G loss: 2.346157]\n",
      "epoch:20 step:15938 [D loss: 0.628732, acc: 65.62%] [G loss: 2.168788]\n",
      "epoch:20 step:15939 [D loss: 0.739718, acc: 49.22%] [G loss: 2.177298]\n",
      "epoch:20 step:15940 [D loss: 0.774985, acc: 47.66%] [G loss: 1.583984]\n",
      "epoch:20 step:15941 [D loss: 0.578730, acc: 71.88%] [G loss: 1.590475]\n",
      "epoch:20 step:15942 [D loss: 0.667338, acc: 64.84%] [G loss: 2.286416]\n",
      "epoch:20 step:15943 [D loss: 0.518988, acc: 80.47%] [G loss: 2.279746]\n",
      "epoch:20 step:15944 [D loss: 0.646586, acc: 61.72%] [G loss: 2.066584]\n",
      "epoch:20 step:15945 [D loss: 0.729728, acc: 50.00%] [G loss: 1.959709]\n",
      "epoch:20 step:15946 [D loss: 0.575123, acc: 72.66%] [G loss: 1.986149]\n",
      "epoch:20 step:15947 [D loss: 0.569969, acc: 69.53%] [G loss: 2.224239]\n",
      "epoch:20 step:15948 [D loss: 0.505004, acc: 83.59%] [G loss: 2.267481]\n",
      "epoch:20 step:15949 [D loss: 0.707568, acc: 52.34%] [G loss: 2.215883]\n",
      "epoch:20 step:15950 [D loss: 0.463112, acc: 86.72%] [G loss: 2.567063]\n",
      "epoch:20 step:15951 [D loss: 0.903849, acc: 33.59%] [G loss: 1.928216]\n",
      "epoch:20 step:15952 [D loss: 0.640250, acc: 60.16%] [G loss: 2.101270]\n",
      "epoch:20 step:15953 [D loss: 0.605019, acc: 65.62%] [G loss: 2.460392]\n",
      "epoch:20 step:15954 [D loss: 0.670093, acc: 53.91%] [G loss: 2.763209]\n",
      "epoch:20 step:15955 [D loss: 0.486204, acc: 75.00%] [G loss: 3.160034]\n",
      "epoch:20 step:15956 [D loss: 0.471101, acc: 81.25%] [G loss: 2.802985]\n",
      "epoch:20 step:15957 [D loss: 0.801447, acc: 40.62%] [G loss: 2.100450]\n",
      "epoch:20 step:15958 [D loss: 0.715352, acc: 49.22%] [G loss: 2.816646]\n",
      "epoch:20 step:15959 [D loss: 0.411310, acc: 89.06%] [G loss: 1.800677]\n",
      "epoch:20 step:15960 [D loss: 0.437178, acc: 90.62%] [G loss: 2.081246]\n",
      "epoch:20 step:15961 [D loss: 0.707876, acc: 57.81%] [G loss: 2.702657]\n",
      "epoch:20 step:15962 [D loss: 0.544300, acc: 72.66%] [G loss: 2.848185]\n",
      "epoch:20 step:15963 [D loss: 0.503382, acc: 72.66%] [G loss: 2.283518]\n",
      "epoch:20 step:15964 [D loss: 0.829293, acc: 47.66%] [G loss: 1.852086]\n",
      "epoch:20 step:15965 [D loss: 0.668840, acc: 60.16%] [G loss: 2.485989]\n",
      "epoch:20 step:15966 [D loss: 0.576936, acc: 67.97%] [G loss: 2.596425]\n",
      "epoch:20 step:15967 [D loss: 0.431681, acc: 90.62%] [G loss: 2.843647]\n",
      "epoch:20 step:15968 [D loss: 0.726447, acc: 50.78%] [G loss: 2.729615]\n",
      "epoch:20 step:15969 [D loss: 0.830830, acc: 35.94%] [G loss: 1.903189]\n",
      "epoch:20 step:15970 [D loss: 0.348525, acc: 95.31%] [G loss: 3.379767]\n",
      "epoch:20 step:15971 [D loss: 0.706678, acc: 51.56%] [G loss: 1.931164]\n",
      "epoch:20 step:15972 [D loss: 0.327223, acc: 94.53%] [G loss: 2.293128]\n",
      "epoch:20 step:15973 [D loss: 0.494656, acc: 75.00%] [G loss: 2.779475]\n",
      "epoch:20 step:15974 [D loss: 0.743645, acc: 49.22%] [G loss: 1.776659]\n",
      "epoch:20 step:15975 [D loss: 0.644234, acc: 60.16%] [G loss: 2.250981]\n",
      "epoch:20 step:15976 [D loss: 0.582551, acc: 71.09%] [G loss: 1.985756]\n",
      "epoch:20 step:15977 [D loss: 0.608485, acc: 57.03%] [G loss: 1.970707]\n",
      "epoch:20 step:15978 [D loss: 0.581125, acc: 70.31%] [G loss: 2.532130]\n",
      "epoch:20 step:15979 [D loss: 0.652734, acc: 56.25%] [G loss: 2.474215]\n",
      "epoch:20 step:15980 [D loss: 0.867700, acc: 35.94%] [G loss: 2.417991]\n",
      "epoch:20 step:15981 [D loss: 0.729520, acc: 53.12%] [G loss: 2.229572]\n",
      "epoch:20 step:15982 [D loss: 0.357661, acc: 90.62%] [G loss: 2.267240]\n",
      "epoch:20 step:15983 [D loss: 0.628259, acc: 57.81%] [G loss: 2.283946]\n",
      "epoch:20 step:15984 [D loss: 0.364306, acc: 95.31%] [G loss: 2.737273]\n",
      "epoch:20 step:15985 [D loss: 0.852927, acc: 40.62%] [G loss: 1.944877]\n",
      "epoch:20 step:15986 [D loss: 0.977332, acc: 34.38%] [G loss: 1.829644]\n",
      "epoch:20 step:15987 [D loss: 0.854123, acc: 35.16%] [G loss: 2.132438]\n",
      "epoch:20 step:15988 [D loss: 0.614862, acc: 69.53%] [G loss: 2.420701]\n",
      "epoch:20 step:15989 [D loss: 0.655730, acc: 62.50%] [G loss: 2.465417]\n",
      "epoch:20 step:15990 [D loss: 0.493210, acc: 82.03%] [G loss: 1.962431]\n",
      "epoch:20 step:15991 [D loss: 0.721285, acc: 50.00%] [G loss: 2.388919]\n",
      "epoch:20 step:15992 [D loss: 0.723410, acc: 55.47%] [G loss: 1.796774]\n",
      "epoch:20 step:15993 [D loss: 0.813368, acc: 40.62%] [G loss: 1.954995]\n",
      "epoch:20 step:15994 [D loss: 0.230501, acc: 99.22%] [G loss: 2.216551]\n",
      "epoch:20 step:15995 [D loss: 0.473637, acc: 79.69%] [G loss: 2.791792]\n",
      "epoch:20 step:15996 [D loss: 0.644586, acc: 64.06%] [G loss: 2.472621]\n",
      "epoch:20 step:15997 [D loss: 0.651213, acc: 67.97%] [G loss: 1.823436]\n",
      "epoch:20 step:15998 [D loss: 0.625168, acc: 70.31%] [G loss: 2.509692]\n",
      "epoch:20 step:15999 [D loss: 0.404633, acc: 87.50%] [G loss: 2.177857]\n",
      "epoch:20 step:16000 [D loss: 0.672841, acc: 57.81%] [G loss: 2.192132]\n",
      "epoch:20 step:16001 [D loss: 0.915003, acc: 23.44%] [G loss: 2.294248]\n",
      "epoch:20 step:16002 [D loss: 0.271791, acc: 98.44%] [G loss: 2.662459]\n",
      "epoch:20 step:16003 [D loss: 0.435045, acc: 88.28%] [G loss: 2.158753]\n",
      "epoch:20 step:16004 [D loss: 0.416034, acc: 89.84%] [G loss: 2.605308]\n",
      "epoch:20 step:16005 [D loss: 0.669001, acc: 56.25%] [G loss: 2.638990]\n",
      "epoch:20 step:16006 [D loss: 0.368905, acc: 93.75%] [G loss: 2.722032]\n",
      "epoch:20 step:16007 [D loss: 0.502105, acc: 76.56%] [G loss: 2.321178]\n",
      "epoch:20 step:16008 [D loss: 0.711529, acc: 52.34%] [G loss: 2.565697]\n",
      "epoch:20 step:16009 [D loss: 0.510305, acc: 80.47%] [G loss: 2.734179]\n",
      "epoch:20 step:16010 [D loss: 0.346372, acc: 92.97%] [G loss: 2.804181]\n",
      "epoch:20 step:16011 [D loss: 0.945356, acc: 47.66%] [G loss: 2.175357]\n",
      "epoch:20 step:16012 [D loss: 0.685438, acc: 53.91%] [G loss: 2.379795]\n",
      "epoch:20 step:16013 [D loss: 0.487633, acc: 83.59%] [G loss: 2.187529]\n",
      "epoch:20 step:16014 [D loss: 0.288185, acc: 94.53%] [G loss: 2.379708]\n",
      "epoch:20 step:16015 [D loss: 0.646731, acc: 62.50%] [G loss: 2.596001]\n",
      "epoch:20 step:16016 [D loss: 0.481975, acc: 73.44%] [G loss: 2.392079]\n",
      "epoch:20 step:16017 [D loss: 0.941631, acc: 23.44%] [G loss: 2.315445]\n",
      "epoch:20 step:16018 [D loss: 0.630337, acc: 67.19%] [G loss: 2.350391]\n",
      "epoch:20 step:16019 [D loss: 0.423134, acc: 89.84%] [G loss: 2.977490]\n",
      "epoch:20 step:16020 [D loss: 0.402914, acc: 89.84%] [G loss: 2.318544]\n",
      "epoch:20 step:16021 [D loss: 0.343297, acc: 90.62%] [G loss: 2.788189]\n",
      "epoch:20 step:16022 [D loss: 0.863075, acc: 36.72%] [G loss: 2.426598]\n",
      "epoch:20 step:16023 [D loss: 0.451318, acc: 83.59%] [G loss: 1.807799]\n",
      "epoch:20 step:16024 [D loss: 0.696743, acc: 57.81%] [G loss: 2.311162]\n",
      "epoch:20 step:16025 [D loss: 0.620507, acc: 59.38%] [G loss: 2.242421]\n",
      "epoch:20 step:16026 [D loss: 0.866043, acc: 35.16%] [G loss: 2.157117]\n",
      "epoch:20 step:16027 [D loss: 0.521886, acc: 75.00%] [G loss: 2.049156]\n",
      "epoch:20 step:16028 [D loss: 0.534777, acc: 75.00%] [G loss: 2.201425]\n",
      "epoch:20 step:16029 [D loss: 0.520671, acc: 69.53%] [G loss: 2.457592]\n",
      "epoch:20 step:16030 [D loss: 0.743323, acc: 54.69%] [G loss: 2.314424]\n",
      "epoch:20 step:16031 [D loss: 0.789783, acc: 43.75%] [G loss: 2.034476]\n",
      "epoch:20 step:16032 [D loss: 0.734548, acc: 50.00%] [G loss: 2.012033]\n",
      "epoch:20 step:16033 [D loss: 0.786295, acc: 40.62%] [G loss: 2.479994]\n",
      "epoch:20 step:16034 [D loss: 0.705684, acc: 54.69%] [G loss: 2.353386]\n",
      "epoch:20 step:16035 [D loss: 0.748954, acc: 46.88%] [G loss: 1.978658]\n",
      "epoch:20 step:16036 [D loss: 0.569411, acc: 72.66%] [G loss: 2.315941]\n",
      "epoch:20 step:16037 [D loss: 0.651732, acc: 64.06%] [G loss: 3.231672]\n",
      "epoch:20 step:16038 [D loss: 0.485045, acc: 85.94%] [G loss: 2.516264]\n",
      "epoch:20 step:16039 [D loss: 0.708023, acc: 59.38%] [G loss: 2.078715]\n",
      "epoch:20 step:16040 [D loss: 0.366780, acc: 89.06%] [G loss: 2.588292]\n",
      "epoch:20 step:16041 [D loss: 0.396282, acc: 90.62%] [G loss: 2.711270]\n",
      "epoch:20 step:16042 [D loss: 0.281632, acc: 99.22%] [G loss: 2.895196]\n",
      "epoch:20 step:16043 [D loss: 0.743173, acc: 50.00%] [G loss: 2.068144]\n",
      "epoch:20 step:16044 [D loss: 1.351618, acc: 7.81%] [G loss: 1.220408]\n",
      "epoch:20 step:16045 [D loss: 0.588874, acc: 65.62%] [G loss: 2.267863]\n",
      "epoch:20 step:16046 [D loss: 0.674124, acc: 54.69%] [G loss: 2.186295]\n",
      "epoch:20 step:16047 [D loss: 0.583424, acc: 71.88%] [G loss: 2.450978]\n",
      "epoch:20 step:16048 [D loss: 0.663608, acc: 57.03%] [G loss: 2.630898]\n",
      "epoch:20 step:16049 [D loss: 0.502224, acc: 78.91%] [G loss: 1.822102]\n",
      "epoch:20 step:16050 [D loss: 0.476314, acc: 87.50%] [G loss: 2.911849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16051 [D loss: 0.623440, acc: 53.91%] [G loss: 2.362738]\n",
      "epoch:20 step:16052 [D loss: 0.489096, acc: 86.72%] [G loss: 2.189107]\n",
      "epoch:20 step:16053 [D loss: 0.697449, acc: 56.25%] [G loss: 2.061771]\n",
      "epoch:20 step:16054 [D loss: 0.557207, acc: 75.78%] [G loss: 2.875830]\n",
      "epoch:20 step:16055 [D loss: 0.434649, acc: 79.69%] [G loss: 2.869798]\n",
      "epoch:20 step:16056 [D loss: 0.910793, acc: 25.00%] [G loss: 1.902000]\n",
      "epoch:20 step:16057 [D loss: 0.689102, acc: 55.47%] [G loss: 2.501312]\n",
      "epoch:20 step:16058 [D loss: 0.504780, acc: 77.34%] [G loss: 2.964546]\n",
      "epoch:20 step:16059 [D loss: 0.573727, acc: 73.44%] [G loss: 2.123543]\n",
      "epoch:20 step:16060 [D loss: 0.615418, acc: 68.75%] [G loss: 2.361686]\n",
      "epoch:20 step:16061 [D loss: 0.760269, acc: 52.34%] [G loss: 2.649855]\n",
      "epoch:20 step:16062 [D loss: 0.836880, acc: 42.19%] [G loss: 2.423004]\n",
      "epoch:20 step:16063 [D loss: 0.756127, acc: 42.97%] [G loss: 2.182113]\n",
      "epoch:20 step:16064 [D loss: 0.761133, acc: 48.44%] [G loss: 1.573153]\n",
      "epoch:20 step:16065 [D loss: 0.800591, acc: 41.41%] [G loss: 1.520128]\n",
      "epoch:20 step:16066 [D loss: 0.526596, acc: 76.56%] [G loss: 2.231080]\n",
      "epoch:20 step:16067 [D loss: 0.422503, acc: 85.16%] [G loss: 2.719656]\n",
      "epoch:20 step:16068 [D loss: 0.873848, acc: 31.25%] [G loss: 2.011238]\n",
      "epoch:20 step:16069 [D loss: 0.462542, acc: 89.84%] [G loss: 2.063404]\n",
      "epoch:20 step:16070 [D loss: 0.489012, acc: 88.28%] [G loss: 2.119861]\n",
      "epoch:20 step:16071 [D loss: 0.875932, acc: 41.41%] [G loss: 1.952762]\n",
      "epoch:20 step:16072 [D loss: 0.744590, acc: 47.66%] [G loss: 1.928803]\n",
      "epoch:20 step:16073 [D loss: 0.465365, acc: 84.38%] [G loss: 2.252604]\n",
      "epoch:20 step:16074 [D loss: 0.527546, acc: 78.12%] [G loss: 2.167493]\n",
      "epoch:20 step:16075 [D loss: 0.505442, acc: 81.25%] [G loss: 2.955085]\n",
      "epoch:20 step:16076 [D loss: 0.461449, acc: 82.81%] [G loss: 2.245687]\n",
      "epoch:20 step:16077 [D loss: 0.667101, acc: 62.50%] [G loss: 2.048221]\n",
      "epoch:20 step:16078 [D loss: 0.580935, acc: 65.62%] [G loss: 2.379394]\n",
      "epoch:20 step:16079 [D loss: 0.542377, acc: 75.78%] [G loss: 1.906700]\n",
      "epoch:20 step:16080 [D loss: 0.663253, acc: 60.16%] [G loss: 2.009019]\n",
      "epoch:20 step:16081 [D loss: 0.465236, acc: 88.28%] [G loss: 2.550721]\n",
      "epoch:20 step:16082 [D loss: 0.274326, acc: 95.31%] [G loss: 2.885055]\n",
      "epoch:20 step:16083 [D loss: 0.500816, acc: 81.25%] [G loss: 2.293574]\n",
      "epoch:20 step:16084 [D loss: 0.570638, acc: 64.84%] [G loss: 2.150689]\n",
      "epoch:20 step:16085 [D loss: 0.601917, acc: 68.75%] [G loss: 2.572328]\n",
      "epoch:20 step:16086 [D loss: 0.406882, acc: 87.50%] [G loss: 2.937074]\n",
      "epoch:20 step:16087 [D loss: 0.798475, acc: 49.22%] [G loss: 1.800686]\n",
      "epoch:20 step:16088 [D loss: 0.696615, acc: 57.03%] [G loss: 2.515876]\n",
      "epoch:20 step:16089 [D loss: 0.627314, acc: 61.72%] [G loss: 2.953479]\n",
      "epoch:20 step:16090 [D loss: 0.554932, acc: 78.12%] [G loss: 1.684771]\n",
      "epoch:20 step:16091 [D loss: 0.571126, acc: 67.97%] [G loss: 2.416230]\n",
      "epoch:20 step:16092 [D loss: 0.428901, acc: 91.41%] [G loss: 2.655662]\n",
      "epoch:20 step:16093 [D loss: 0.779862, acc: 40.62%] [G loss: 2.560826]\n",
      "epoch:20 step:16094 [D loss: 0.934469, acc: 24.22%] [G loss: 2.123914]\n",
      "epoch:20 step:16095 [D loss: 0.749678, acc: 48.44%] [G loss: 2.080658]\n",
      "epoch:20 step:16096 [D loss: 0.229322, acc: 96.88%] [G loss: 2.409462]\n",
      "epoch:20 step:16097 [D loss: 0.351389, acc: 92.19%] [G loss: 3.148866]\n",
      "epoch:20 step:16098 [D loss: 0.218192, acc: 100.00%] [G loss: 2.900997]\n",
      "epoch:20 step:16099 [D loss: 0.598479, acc: 69.53%] [G loss: 2.666763]\n",
      "epoch:20 step:16100 [D loss: 0.434566, acc: 89.06%] [G loss: 2.617131]\n",
      "epoch:20 step:16101 [D loss: 0.379632, acc: 92.19%] [G loss: 1.565983]\n",
      "epoch:20 step:16102 [D loss: 0.800394, acc: 42.97%] [G loss: 2.194683]\n",
      "epoch:20 step:16103 [D loss: 0.414404, acc: 83.59%] [G loss: 2.381473]\n",
      "epoch:20 step:16104 [D loss: 0.576607, acc: 64.84%] [G loss: 2.395068]\n",
      "epoch:20 step:16105 [D loss: 0.698248, acc: 58.59%] [G loss: 2.211180]\n",
      "epoch:20 step:16106 [D loss: 0.609309, acc: 67.97%] [G loss: 2.420491]\n",
      "epoch:20 step:16107 [D loss: 0.422787, acc: 83.59%] [G loss: 2.396847]\n",
      "epoch:20 step:16108 [D loss: 0.681719, acc: 57.03%] [G loss: 2.033788]\n",
      "epoch:20 step:16109 [D loss: 0.836688, acc: 41.41%] [G loss: 1.733956]\n",
      "epoch:20 step:16110 [D loss: 0.317284, acc: 95.31%] [G loss: 2.328894]\n",
      "epoch:20 step:16111 [D loss: 0.245144, acc: 98.44%] [G loss: 3.110621]\n",
      "epoch:20 step:16112 [D loss: 1.106487, acc: 13.28%] [G loss: 2.485403]\n",
      "epoch:20 step:16113 [D loss: 0.445364, acc: 89.84%] [G loss: 2.235376]\n",
      "epoch:20 step:16114 [D loss: 0.561671, acc: 75.78%] [G loss: 2.351351]\n",
      "epoch:20 step:16115 [D loss: 0.518949, acc: 79.69%] [G loss: 2.860579]\n",
      "epoch:20 step:16116 [D loss: 0.471240, acc: 84.38%] [G loss: 2.159331]\n",
      "epoch:20 step:16117 [D loss: 0.555955, acc: 71.09%] [G loss: 2.485471]\n",
      "epoch:20 step:16118 [D loss: 0.428175, acc: 83.59%] [G loss: 2.270982]\n",
      "epoch:20 step:16119 [D loss: 0.397513, acc: 75.78%] [G loss: 2.867460]\n",
      "epoch:20 step:16120 [D loss: 0.517747, acc: 71.88%] [G loss: 2.358407]\n",
      "epoch:20 step:16121 [D loss: 0.626595, acc: 57.03%] [G loss: 1.984868]\n",
      "epoch:20 step:16122 [D loss: 0.679173, acc: 56.25%] [G loss: 1.787828]\n",
      "epoch:20 step:16123 [D loss: 0.524628, acc: 81.25%] [G loss: 1.854558]\n",
      "epoch:20 step:16124 [D loss: 0.805429, acc: 43.75%] [G loss: 1.931396]\n",
      "epoch:20 step:16125 [D loss: 0.796262, acc: 46.88%] [G loss: 1.636760]\n",
      "epoch:20 step:16126 [D loss: 0.598530, acc: 71.09%] [G loss: 2.437052]\n",
      "epoch:20 step:16127 [D loss: 0.909318, acc: 49.22%] [G loss: 2.264938]\n",
      "epoch:20 step:16128 [D loss: 0.441378, acc: 89.06%] [G loss: 2.604040]\n",
      "epoch:20 step:16129 [D loss: 0.467246, acc: 87.50%] [G loss: 2.407516]\n",
      "epoch:20 step:16130 [D loss: 0.612607, acc: 69.53%] [G loss: 2.806964]\n",
      "epoch:20 step:16131 [D loss: 0.433694, acc: 82.03%] [G loss: 2.258622]\n",
      "epoch:20 step:16132 [D loss: 0.474312, acc: 71.09%] [G loss: 2.052366]\n",
      "epoch:20 step:16133 [D loss: 0.825922, acc: 39.84%] [G loss: 1.916947]\n",
      "epoch:20 step:16134 [D loss: 0.467419, acc: 87.50%] [G loss: 2.947835]\n",
      "epoch:20 step:16135 [D loss: 0.414689, acc: 89.84%] [G loss: 2.331878]\n",
      "epoch:20 step:16136 [D loss: 0.582983, acc: 71.88%] [G loss: 2.520365]\n",
      "epoch:20 step:16137 [D loss: 0.316198, acc: 97.66%] [G loss: 3.141152]\n",
      "epoch:20 step:16138 [D loss: 0.758425, acc: 54.69%] [G loss: 2.724643]\n",
      "epoch:20 step:16139 [D loss: 0.934314, acc: 42.97%] [G loss: 2.217349]\n",
      "epoch:20 step:16140 [D loss: 0.383356, acc: 92.97%] [G loss: 2.293740]\n",
      "epoch:20 step:16141 [D loss: 0.319482, acc: 93.75%] [G loss: 2.210333]\n",
      "epoch:20 step:16142 [D loss: 0.824398, acc: 36.72%] [G loss: 1.701568]\n",
      "epoch:20 step:16143 [D loss: 0.317555, acc: 88.28%] [G loss: 2.807831]\n",
      "epoch:20 step:16144 [D loss: 0.441032, acc: 90.62%] [G loss: 2.688420]\n",
      "epoch:20 step:16145 [D loss: 0.734040, acc: 50.78%] [G loss: 2.799784]\n",
      "epoch:20 step:16146 [D loss: 0.607091, acc: 69.53%] [G loss: 2.559927]\n",
      "epoch:20 step:16147 [D loss: 0.596199, acc: 71.88%] [G loss: 2.608578]\n",
      "epoch:20 step:16148 [D loss: 0.588142, acc: 67.97%] [G loss: 2.152858]\n",
      "epoch:20 step:16149 [D loss: 0.404613, acc: 85.16%] [G loss: 2.644700]\n",
      "epoch:20 step:16150 [D loss: 1.166343, acc: 20.31%] [G loss: 2.698056]\n",
      "epoch:20 step:16151 [D loss: 0.530513, acc: 81.25%] [G loss: 2.596870]\n",
      "epoch:20 step:16152 [D loss: 0.507897, acc: 73.44%] [G loss: 2.346252]\n",
      "epoch:20 step:16153 [D loss: 0.768315, acc: 42.19%] [G loss: 1.941114]\n",
      "epoch:20 step:16154 [D loss: 0.609211, acc: 70.31%] [G loss: 1.949841]\n",
      "epoch:20 step:16155 [D loss: 0.981025, acc: 14.84%] [G loss: 1.819149]\n",
      "epoch:20 step:16156 [D loss: 0.406919, acc: 88.28%] [G loss: 2.619488]\n",
      "epoch:20 step:16157 [D loss: 0.279046, acc: 95.31%] [G loss: 2.941427]\n",
      "epoch:20 step:16158 [D loss: 0.342470, acc: 94.53%] [G loss: 2.671323]\n",
      "epoch:20 step:16159 [D loss: 0.514014, acc: 87.50%] [G loss: 2.294568]\n",
      "epoch:20 step:16160 [D loss: 0.731492, acc: 49.22%] [G loss: 2.454948]\n",
      "epoch:20 step:16161 [D loss: 0.521194, acc: 78.91%] [G loss: 2.560040]\n",
      "epoch:20 step:16162 [D loss: 0.728351, acc: 57.03%] [G loss: 3.122553]\n",
      "epoch:20 step:16163 [D loss: 0.850693, acc: 37.50%] [G loss: 2.026040]\n",
      "epoch:20 step:16164 [D loss: 0.549518, acc: 71.88%] [G loss: 3.401688]\n",
      "epoch:20 step:16165 [D loss: 0.468846, acc: 83.59%] [G loss: 1.840570]\n",
      "epoch:20 step:16166 [D loss: 0.581561, acc: 71.88%] [G loss: 2.629414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16167 [D loss: 0.464112, acc: 78.91%] [G loss: 3.156675]\n",
      "epoch:20 step:16168 [D loss: 0.562889, acc: 71.09%] [G loss: 1.547023]\n",
      "epoch:20 step:16169 [D loss: 0.473230, acc: 83.59%] [G loss: 1.617118]\n",
      "epoch:20 step:16170 [D loss: 0.532549, acc: 70.31%] [G loss: 3.058368]\n",
      "epoch:20 step:16171 [D loss: 0.172259, acc: 100.00%] [G loss: 2.159232]\n",
      "epoch:20 step:16172 [D loss: 0.637428, acc: 55.47%] [G loss: 1.650476]\n",
      "epoch:20 step:16173 [D loss: 0.867750, acc: 42.97%] [G loss: 1.843656]\n",
      "epoch:20 step:16174 [D loss: 0.776190, acc: 53.12%] [G loss: 2.000473]\n",
      "epoch:20 step:16175 [D loss: 0.657342, acc: 67.19%] [G loss: 2.635440]\n",
      "epoch:20 step:16176 [D loss: 0.406468, acc: 76.56%] [G loss: 2.232651]\n",
      "epoch:20 step:16177 [D loss: 0.587120, acc: 69.53%] [G loss: 2.409299]\n",
      "epoch:20 step:16178 [D loss: 0.523175, acc: 75.78%] [G loss: 2.068592]\n",
      "epoch:20 step:16179 [D loss: 0.365066, acc: 94.53%] [G loss: 3.389313]\n",
      "epoch:20 step:16180 [D loss: 1.026651, acc: 22.66%] [G loss: 2.306371]\n",
      "epoch:20 step:16181 [D loss: 0.741834, acc: 53.12%] [G loss: 2.351245]\n",
      "epoch:20 step:16182 [D loss: 0.495599, acc: 80.47%] [G loss: 2.324800]\n",
      "epoch:20 step:16183 [D loss: 1.141074, acc: 35.94%] [G loss: 1.935417]\n",
      "epoch:20 step:16184 [D loss: 0.815187, acc: 49.22%] [G loss: 2.230025]\n",
      "epoch:20 step:16185 [D loss: 0.706395, acc: 53.91%] [G loss: 2.655528]\n",
      "epoch:20 step:16186 [D loss: 0.824041, acc: 38.28%] [G loss: 2.355221]\n",
      "epoch:20 step:16187 [D loss: 0.672741, acc: 61.72%] [G loss: 2.287434]\n",
      "epoch:20 step:16188 [D loss: 0.847636, acc: 31.25%] [G loss: 2.260763]\n",
      "epoch:20 step:16189 [D loss: 0.286063, acc: 99.22%] [G loss: 2.657499]\n",
      "epoch:20 step:16190 [D loss: 0.793416, acc: 40.62%] [G loss: 2.641440]\n",
      "epoch:20 step:16191 [D loss: 0.539361, acc: 77.34%] [G loss: 1.909599]\n",
      "epoch:20 step:16192 [D loss: 0.518777, acc: 79.69%] [G loss: 2.127260]\n",
      "epoch:20 step:16193 [D loss: 0.438848, acc: 75.78%] [G loss: 2.314123]\n",
      "epoch:20 step:16194 [D loss: 0.944126, acc: 26.56%] [G loss: 2.691731]\n",
      "epoch:20 step:16195 [D loss: 0.774196, acc: 49.22%] [G loss: 1.874495]\n",
      "epoch:20 step:16196 [D loss: 0.372311, acc: 95.31%] [G loss: 2.940543]\n",
      "epoch:20 step:16197 [D loss: 0.520416, acc: 78.12%] [G loss: 2.412418]\n",
      "epoch:20 step:16198 [D loss: 0.760428, acc: 45.31%] [G loss: 2.089518]\n",
      "epoch:20 step:16199 [D loss: 0.677334, acc: 60.16%] [G loss: 2.130516]\n",
      "epoch:20 step:16200 [D loss: 0.441938, acc: 87.50%] [G loss: 2.466887]\n",
      "epoch:20 step:16201 [D loss: 0.333284, acc: 91.41%] [G loss: 2.523376]\n",
      "epoch:20 step:16202 [D loss: 0.598908, acc: 69.53%] [G loss: 2.701662]\n",
      "epoch:20 step:16203 [D loss: 0.606529, acc: 62.50%] [G loss: 2.116022]\n",
      "epoch:20 step:16204 [D loss: 0.700400, acc: 57.03%] [G loss: 2.186442]\n",
      "epoch:20 step:16205 [D loss: 0.533149, acc: 68.75%] [G loss: 2.701679]\n",
      "epoch:20 step:16206 [D loss: 0.326926, acc: 97.66%] [G loss: 2.851811]\n",
      "epoch:20 step:16207 [D loss: 0.200648, acc: 98.44%] [G loss: 3.335051]\n",
      "epoch:20 step:16208 [D loss: 0.475891, acc: 78.91%] [G loss: 2.539693]\n",
      "epoch:20 step:16209 [D loss: 0.615510, acc: 64.06%] [G loss: 2.608374]\n",
      "epoch:20 step:16210 [D loss: 0.762677, acc: 51.56%] [G loss: 2.450588]\n",
      "epoch:20 step:16211 [D loss: 0.433386, acc: 90.62%] [G loss: 2.490363]\n",
      "epoch:20 step:16212 [D loss: 0.749673, acc: 45.31%] [G loss: 2.358074]\n",
      "epoch:20 step:16213 [D loss: 0.653629, acc: 61.72%] [G loss: 2.888990]\n",
      "epoch:20 step:16214 [D loss: 0.851255, acc: 42.19%] [G loss: 2.481323]\n",
      "epoch:20 step:16215 [D loss: 0.558530, acc: 70.31%] [G loss: 3.181220]\n",
      "epoch:20 step:16216 [D loss: 0.471318, acc: 81.25%] [G loss: 2.233928]\n",
      "epoch:20 step:16217 [D loss: 0.688320, acc: 55.47%] [G loss: 3.086579]\n",
      "epoch:20 step:16218 [D loss: 0.513594, acc: 80.47%] [G loss: 2.092509]\n",
      "epoch:20 step:16219 [D loss: 0.538500, acc: 80.47%] [G loss: 2.805638]\n",
      "epoch:20 step:16220 [D loss: 0.488221, acc: 70.31%] [G loss: 2.429828]\n",
      "epoch:20 step:16221 [D loss: 0.546381, acc: 73.44%] [G loss: 2.067214]\n",
      "epoch:20 step:16222 [D loss: 0.604104, acc: 64.06%] [G loss: 2.146269]\n",
      "epoch:20 step:16223 [D loss: 0.503172, acc: 89.84%] [G loss: 2.068643]\n",
      "epoch:20 step:16224 [D loss: 0.324033, acc: 95.31%] [G loss: 2.369557]\n",
      "epoch:20 step:16225 [D loss: 0.331759, acc: 98.44%] [G loss: 3.406022]\n",
      "epoch:20 step:16226 [D loss: 0.424904, acc: 89.84%] [G loss: 1.921108]\n",
      "epoch:20 step:16227 [D loss: 0.476845, acc: 75.00%] [G loss: 2.806421]\n",
      "epoch:20 step:16228 [D loss: 0.482875, acc: 84.38%] [G loss: 2.006437]\n",
      "epoch:20 step:16229 [D loss: 0.682106, acc: 54.69%] [G loss: 2.401013]\n",
      "epoch:20 step:16230 [D loss: 0.612995, acc: 66.41%] [G loss: 2.328486]\n",
      "epoch:20 step:16231 [D loss: 0.633873, acc: 59.38%] [G loss: 2.137755]\n",
      "epoch:20 step:16232 [D loss: 0.505535, acc: 87.50%] [G loss: 1.571879]\n",
      "epoch:20 step:16233 [D loss: 0.454173, acc: 74.22%] [G loss: 2.649323]\n",
      "epoch:20 step:16234 [D loss: 0.608354, acc: 65.62%] [G loss: 2.131158]\n",
      "epoch:20 step:16235 [D loss: 0.684285, acc: 56.25%] [G loss: 2.698665]\n",
      "epoch:20 step:16236 [D loss: 1.169991, acc: 26.56%] [G loss: 1.778461]\n",
      "epoch:20 step:16237 [D loss: 1.201308, acc: 21.09%] [G loss: 2.453896]\n",
      "epoch:20 step:16238 [D loss: 0.626420, acc: 69.53%] [G loss: 1.932717]\n",
      "epoch:20 step:16239 [D loss: 0.481682, acc: 84.38%] [G loss: 2.844934]\n",
      "epoch:20 step:16240 [D loss: 0.966078, acc: 23.44%] [G loss: 2.006771]\n",
      "epoch:20 step:16241 [D loss: 0.636075, acc: 63.28%] [G loss: 1.930063]\n",
      "epoch:20 step:16242 [D loss: 0.685045, acc: 54.69%] [G loss: 1.867716]\n",
      "epoch:20 step:16243 [D loss: 0.583601, acc: 70.31%] [G loss: 2.167471]\n",
      "epoch:20 step:16244 [D loss: 0.492709, acc: 85.94%] [G loss: 2.743644]\n",
      "epoch:20 step:16245 [D loss: 0.504074, acc: 74.22%] [G loss: 2.690901]\n",
      "epoch:20 step:16246 [D loss: 0.359107, acc: 94.53%] [G loss: 2.421577]\n",
      "epoch:20 step:16247 [D loss: 0.900120, acc: 26.56%] [G loss: 1.938521]\n",
      "epoch:20 step:16248 [D loss: 0.567705, acc: 68.75%] [G loss: 2.721115]\n",
      "epoch:20 step:16249 [D loss: 0.450694, acc: 87.50%] [G loss: 2.312871]\n",
      "epoch:20 step:16250 [D loss: 0.427346, acc: 92.19%] [G loss: 2.013995]\n",
      "epoch:20 step:16251 [D loss: 0.496638, acc: 80.47%] [G loss: 1.971797]\n",
      "epoch:20 step:16252 [D loss: 1.045837, acc: 19.53%] [G loss: 1.616205]\n",
      "epoch:20 step:16253 [D loss: 0.696363, acc: 53.91%] [G loss: 2.297196]\n",
      "epoch:20 step:16254 [D loss: 0.469924, acc: 85.94%] [G loss: 1.929513]\n",
      "epoch:20 step:16255 [D loss: 0.443597, acc: 90.62%] [G loss: 2.371590]\n",
      "epoch:20 step:16256 [D loss: 0.418067, acc: 92.19%] [G loss: 2.312364]\n",
      "epoch:20 step:16257 [D loss: 0.595694, acc: 67.19%] [G loss: 1.558057]\n",
      "epoch:20 step:16258 [D loss: 0.807990, acc: 39.06%] [G loss: 1.548763]\n",
      "epoch:20 step:16259 [D loss: 0.980115, acc: 22.66%] [G loss: 2.200968]\n",
      "epoch:20 step:16260 [D loss: 0.748598, acc: 42.19%] [G loss: 2.394756]\n",
      "epoch:20 step:16261 [D loss: 0.547400, acc: 81.25%] [G loss: 2.324336]\n",
      "epoch:20 step:16262 [D loss: 0.654895, acc: 58.59%] [G loss: 2.551844]\n",
      "epoch:20 step:16263 [D loss: 0.365752, acc: 86.72%] [G loss: 2.068822]\n",
      "epoch:20 step:16264 [D loss: 0.539454, acc: 72.66%] [G loss: 2.353218]\n",
      "epoch:20 step:16265 [D loss: 0.624331, acc: 67.19%] [G loss: 2.064374]\n",
      "epoch:20 step:16266 [D loss: 0.733241, acc: 46.88%] [G loss: 1.930387]\n",
      "epoch:20 step:16267 [D loss: 0.513221, acc: 80.47%] [G loss: 2.014275]\n",
      "epoch:20 step:16268 [D loss: 0.676456, acc: 58.59%] [G loss: 1.989603]\n",
      "epoch:20 step:16269 [D loss: 0.814108, acc: 39.06%] [G loss: 2.299548]\n",
      "epoch:20 step:16270 [D loss: 0.363264, acc: 98.44%] [G loss: 2.433622]\n",
      "epoch:20 step:16271 [D loss: 0.377016, acc: 82.03%] [G loss: 2.703102]\n",
      "epoch:20 step:16272 [D loss: 0.748004, acc: 51.56%] [G loss: 2.215048]\n",
      "epoch:20 step:16273 [D loss: 0.758579, acc: 52.34%] [G loss: 2.018064]\n",
      "epoch:20 step:16274 [D loss: 0.408929, acc: 90.62%] [G loss: 2.155801]\n",
      "epoch:20 step:16275 [D loss: 0.343944, acc: 95.31%] [G loss: 2.923205]\n",
      "epoch:20 step:16276 [D loss: 0.245846, acc: 95.31%] [G loss: 2.167548]\n",
      "epoch:20 step:16277 [D loss: 0.738923, acc: 51.56%] [G loss: 2.162454]\n",
      "epoch:20 step:16278 [D loss: 0.787697, acc: 39.06%] [G loss: 2.112866]\n",
      "epoch:20 step:16279 [D loss: 0.338897, acc: 93.75%] [G loss: 2.457293]\n",
      "epoch:20 step:16280 [D loss: 0.674548, acc: 50.78%] [G loss: 2.375135]\n",
      "epoch:20 step:16281 [D loss: 0.678874, acc: 56.25%] [G loss: 2.003790]\n",
      "epoch:20 step:16282 [D loss: 0.367482, acc: 89.06%] [G loss: 2.254097]\n",
      "epoch:20 step:16283 [D loss: 0.693858, acc: 53.12%] [G loss: 1.880858]\n",
      "epoch:20 step:16284 [D loss: 0.482147, acc: 81.25%] [G loss: 2.235182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16285 [D loss: 0.498302, acc: 70.31%] [G loss: 1.720494]\n",
      "epoch:20 step:16286 [D loss: 0.486484, acc: 68.75%] [G loss: 2.774329]\n",
      "epoch:20 step:16287 [D loss: 0.481931, acc: 82.81%] [G loss: 2.571316]\n",
      "epoch:20 step:16288 [D loss: 0.359185, acc: 93.75%] [G loss: 1.939230]\n",
      "epoch:20 step:16289 [D loss: 0.628224, acc: 58.59%] [G loss: 2.555611]\n",
      "epoch:20 step:16290 [D loss: 0.859851, acc: 27.34%] [G loss: 2.224160]\n",
      "epoch:20 step:16291 [D loss: 0.586866, acc: 72.66%] [G loss: 2.329907]\n",
      "epoch:20 step:16292 [D loss: 0.594064, acc: 63.28%] [G loss: 2.091970]\n",
      "epoch:20 step:16293 [D loss: 0.393294, acc: 94.53%] [G loss: 2.011886]\n",
      "epoch:20 step:16294 [D loss: 0.947286, acc: 32.03%] [G loss: 2.298450]\n",
      "epoch:20 step:16295 [D loss: 0.459470, acc: 85.94%] [G loss: 2.460045]\n",
      "epoch:20 step:16296 [D loss: 0.289161, acc: 97.66%] [G loss: 2.799553]\n",
      "epoch:20 step:16297 [D loss: 0.733706, acc: 53.12%] [G loss: 2.497010]\n",
      "epoch:20 step:16298 [D loss: 0.552978, acc: 75.00%] [G loss: 2.338497]\n",
      "epoch:20 step:16299 [D loss: 0.631533, acc: 64.84%] [G loss: 2.418461]\n",
      "epoch:20 step:16300 [D loss: 0.520756, acc: 78.91%] [G loss: 2.916071]\n",
      "epoch:20 step:16301 [D loss: 0.396973, acc: 93.75%] [G loss: 2.370511]\n",
      "epoch:20 step:16302 [D loss: 0.837147, acc: 46.09%] [G loss: 2.412113]\n",
      "epoch:20 step:16303 [D loss: 0.520779, acc: 74.22%] [G loss: 2.533159]\n",
      "epoch:20 step:16304 [D loss: 1.072477, acc: 12.50%] [G loss: 1.730784]\n",
      "epoch:20 step:16305 [D loss: 1.065107, acc: 36.72%] [G loss: 1.528114]\n",
      "epoch:20 step:16306 [D loss: 0.722370, acc: 57.81%] [G loss: 2.371666]\n",
      "epoch:20 step:16307 [D loss: 0.565012, acc: 77.34%] [G loss: 2.252666]\n",
      "epoch:20 step:16308 [D loss: 0.587621, acc: 66.41%] [G loss: 1.583011]\n",
      "epoch:20 step:16309 [D loss: 0.589861, acc: 69.53%] [G loss: 1.731130]\n",
      "epoch:20 step:16310 [D loss: 0.662620, acc: 61.72%] [G loss: 2.515879]\n",
      "epoch:20 step:16311 [D loss: 0.511885, acc: 82.03%] [G loss: 3.143147]\n",
      "epoch:20 step:16312 [D loss: 0.743412, acc: 55.47%] [G loss: 2.740392]\n",
      "epoch:20 step:16313 [D loss: 0.458536, acc: 88.28%] [G loss: 2.553293]\n",
      "epoch:20 step:16314 [D loss: 1.075410, acc: 31.25%] [G loss: 1.673626]\n",
      "epoch:20 step:16315 [D loss: 0.652660, acc: 63.28%] [G loss: 2.374908]\n",
      "epoch:20 step:16316 [D loss: 0.623278, acc: 66.41%] [G loss: 2.319331]\n",
      "epoch:20 step:16317 [D loss: 0.420588, acc: 91.41%] [G loss: 3.338820]\n",
      "epoch:20 step:16318 [D loss: 0.725125, acc: 51.56%] [G loss: 1.917856]\n",
      "epoch:20 step:16319 [D loss: 0.852531, acc: 47.66%] [G loss: 2.425488]\n",
      "epoch:20 step:16320 [D loss: 0.390752, acc: 92.19%] [G loss: 2.769439]\n",
      "epoch:20 step:16321 [D loss: 0.521742, acc: 75.00%] [G loss: 2.368857]\n",
      "epoch:20 step:16322 [D loss: 0.491577, acc: 84.38%] [G loss: 2.631230]\n",
      "epoch:20 step:16323 [D loss: 0.494865, acc: 75.00%] [G loss: 2.424160]\n",
      "epoch:20 step:16324 [D loss: 0.338353, acc: 98.44%] [G loss: 3.265398]\n",
      "epoch:20 step:16325 [D loss: 0.406779, acc: 88.28%] [G loss: 3.151169]\n",
      "epoch:20 step:16326 [D loss: 0.472273, acc: 76.56%] [G loss: 2.585583]\n",
      "epoch:20 step:16327 [D loss: 0.540460, acc: 76.56%] [G loss: 2.174464]\n",
      "epoch:20 step:16328 [D loss: 0.652753, acc: 61.72%] [G loss: 1.880691]\n",
      "epoch:20 step:16329 [D loss: 0.416968, acc: 89.06%] [G loss: 2.501540]\n",
      "epoch:20 step:16330 [D loss: 0.829799, acc: 39.84%] [G loss: 1.464319]\n",
      "epoch:20 step:16331 [D loss: 0.462003, acc: 85.94%] [G loss: 1.854554]\n",
      "epoch:20 step:16332 [D loss: 0.818337, acc: 50.00%] [G loss: 2.353507]\n",
      "epoch:20 step:16333 [D loss: 0.483443, acc: 77.34%] [G loss: 3.013815]\n",
      "epoch:20 step:16334 [D loss: 0.509953, acc: 82.03%] [G loss: 2.506813]\n",
      "epoch:20 step:16335 [D loss: 0.467429, acc: 78.12%] [G loss: 2.765671]\n",
      "epoch:20 step:16336 [D loss: 0.740003, acc: 49.22%] [G loss: 2.967228]\n",
      "epoch:20 step:16337 [D loss: 0.574794, acc: 74.22%] [G loss: 2.093407]\n",
      "epoch:20 step:16338 [D loss: 0.419272, acc: 77.34%] [G loss: 2.835384]\n",
      "epoch:20 step:16339 [D loss: 0.896184, acc: 35.16%] [G loss: 1.866876]\n",
      "epoch:20 step:16340 [D loss: 0.399944, acc: 91.41%] [G loss: 2.293106]\n",
      "epoch:20 step:16341 [D loss: 0.854233, acc: 41.41%] [G loss: 1.961103]\n",
      "epoch:20 step:16342 [D loss: 0.807228, acc: 32.03%] [G loss: 1.715499]\n",
      "epoch:20 step:16343 [D loss: 0.820182, acc: 39.84%] [G loss: 2.601459]\n",
      "epoch:20 step:16344 [D loss: 0.389937, acc: 88.28%] [G loss: 2.677300]\n",
      "epoch:20 step:16345 [D loss: 0.591606, acc: 71.88%] [G loss: 1.822728]\n",
      "epoch:20 step:16346 [D loss: 0.720226, acc: 51.56%] [G loss: 1.640143]\n",
      "epoch:20 step:16347 [D loss: 0.527096, acc: 78.91%] [G loss: 1.858894]\n",
      "epoch:20 step:16348 [D loss: 0.546607, acc: 63.28%] [G loss: 2.067701]\n",
      "epoch:20 step:16349 [D loss: 0.372167, acc: 95.31%] [G loss: 1.957635]\n",
      "epoch:20 step:16350 [D loss: 0.551852, acc: 71.09%] [G loss: 2.714619]\n",
      "epoch:20 step:16351 [D loss: 0.767307, acc: 47.66%] [G loss: 1.939422]\n",
      "epoch:20 step:16352 [D loss: 0.814300, acc: 40.62%] [G loss: 2.354703]\n",
      "epoch:20 step:16353 [D loss: 0.816683, acc: 45.31%] [G loss: 2.024497]\n",
      "epoch:20 step:16354 [D loss: 0.647905, acc: 62.50%] [G loss: 1.760317]\n",
      "epoch:20 step:16355 [D loss: 0.539628, acc: 77.34%] [G loss: 2.413691]\n",
      "epoch:20 step:16356 [D loss: 0.535907, acc: 75.78%] [G loss: 1.978325]\n",
      "epoch:20 step:16357 [D loss: 0.477284, acc: 85.16%] [G loss: 2.859994]\n",
      "epoch:20 step:16358 [D loss: 0.495203, acc: 79.69%] [G loss: 2.195720]\n",
      "epoch:20 step:16359 [D loss: 0.552907, acc: 76.56%] [G loss: 2.136521]\n",
      "epoch:20 step:16360 [D loss: 0.377762, acc: 88.28%] [G loss: 1.996084]\n",
      "epoch:20 step:16361 [D loss: 0.317778, acc: 100.00%] [G loss: 3.176220]\n",
      "epoch:20 step:16362 [D loss: 0.425897, acc: 89.84%] [G loss: 2.852189]\n",
      "epoch:20 step:16363 [D loss: 0.454367, acc: 85.16%] [G loss: 2.035404]\n",
      "epoch:20 step:16364 [D loss: 0.642444, acc: 63.28%] [G loss: 2.053709]\n",
      "epoch:20 step:16365 [D loss: 0.540647, acc: 61.72%] [G loss: 3.110030]\n",
      "epoch:20 step:16366 [D loss: 1.046337, acc: 41.41%] [G loss: 2.081032]\n",
      "epoch:20 step:16367 [D loss: 0.465516, acc: 85.94%] [G loss: 2.925133]\n",
      "epoch:20 step:16368 [D loss: 0.660845, acc: 62.50%] [G loss: 2.613707]\n",
      "epoch:20 step:16369 [D loss: 0.677731, acc: 57.81%] [G loss: 2.301180]\n",
      "epoch:20 step:16370 [D loss: 0.619391, acc: 63.28%] [G loss: 2.459615]\n",
      "epoch:20 step:16371 [D loss: 0.916874, acc: 22.66%] [G loss: 2.175439]\n",
      "epoch:20 step:16372 [D loss: 0.548858, acc: 66.41%] [G loss: 2.040635]\n",
      "epoch:20 step:16373 [D loss: 0.498406, acc: 83.59%] [G loss: 2.992571]\n",
      "epoch:20 step:16374 [D loss: 0.719882, acc: 50.78%] [G loss: 2.341414]\n",
      "epoch:20 step:16375 [D loss: 0.449514, acc: 82.81%] [G loss: 1.542636]\n",
      "epoch:20 step:16376 [D loss: 0.399314, acc: 91.41%] [G loss: 3.375956]\n",
      "epoch:20 step:16377 [D loss: 0.282479, acc: 97.66%] [G loss: 1.900750]\n",
      "epoch:20 step:16378 [D loss: 0.642754, acc: 64.06%] [G loss: 2.439384]\n",
      "epoch:20 step:16379 [D loss: 0.272288, acc: 96.09%] [G loss: 2.263527]\n",
      "epoch:20 step:16380 [D loss: 0.446634, acc: 71.88%] [G loss: 2.487788]\n",
      "epoch:20 step:16381 [D loss: 0.598049, acc: 69.53%] [G loss: 1.772577]\n",
      "epoch:20 step:16382 [D loss: 0.724196, acc: 48.44%] [G loss: 2.523190]\n",
      "epoch:20 step:16383 [D loss: 0.525926, acc: 79.69%] [G loss: 2.790075]\n",
      "epoch:20 step:16384 [D loss: 0.730232, acc: 50.78%] [G loss: 2.358750]\n",
      "epoch:20 step:16385 [D loss: 0.720155, acc: 53.91%] [G loss: 2.548949]\n",
      "epoch:20 step:16386 [D loss: 0.228687, acc: 100.00%] [G loss: 2.766128]\n",
      "epoch:20 step:16387 [D loss: 0.350485, acc: 95.31%] [G loss: 2.611817]\n",
      "epoch:20 step:16388 [D loss: 0.690010, acc: 59.38%] [G loss: 2.557566]\n",
      "epoch:20 step:16389 [D loss: 0.516283, acc: 77.34%] [G loss: 2.016822]\n",
      "epoch:20 step:16390 [D loss: 0.556968, acc: 78.12%] [G loss: 2.975627]\n",
      "epoch:20 step:16391 [D loss: 0.907182, acc: 50.78%] [G loss: 2.156151]\n",
      "epoch:20 step:16392 [D loss: 1.018005, acc: 44.53%] [G loss: 2.131705]\n",
      "epoch:20 step:16393 [D loss: 0.313802, acc: 95.31%] [G loss: 3.303042]\n",
      "epoch:20 step:16394 [D loss: 0.596191, acc: 69.53%] [G loss: 2.455054]\n",
      "epoch:20 step:16395 [D loss: 0.459559, acc: 86.72%] [G loss: 2.330761]\n",
      "epoch:20 step:16396 [D loss: 0.796610, acc: 46.88%] [G loss: 2.905018]\n",
      "epoch:20 step:16397 [D loss: 1.018421, acc: 28.91%] [G loss: 2.283091]\n",
      "epoch:20 step:16398 [D loss: 0.659779, acc: 57.03%] [G loss: 2.180498]\n",
      "epoch:20 step:16399 [D loss: 0.663525, acc: 57.03%] [G loss: 2.750725]\n",
      "epoch:20 step:16400 [D loss: 0.948606, acc: 40.62%] [G loss: 1.846157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16401 [D loss: 0.455319, acc: 86.72%] [G loss: 2.268538]\n",
      "epoch:21 step:16402 [D loss: 0.466452, acc: 82.81%] [G loss: 2.730284]\n",
      "epoch:21 step:16403 [D loss: 0.394741, acc: 87.50%] [G loss: 3.493254]\n",
      "epoch:21 step:16404 [D loss: 0.768020, acc: 42.97%] [G loss: 2.166932]\n",
      "epoch:21 step:16405 [D loss: 0.541854, acc: 78.12%] [G loss: 1.789939]\n",
      "epoch:21 step:16406 [D loss: 0.746861, acc: 51.56%] [G loss: 1.786949]\n",
      "epoch:21 step:16407 [D loss: 0.344386, acc: 89.84%] [G loss: 2.232815]\n",
      "epoch:21 step:16408 [D loss: 0.660859, acc: 59.38%] [G loss: 1.725989]\n",
      "epoch:21 step:16409 [D loss: 0.824162, acc: 50.00%] [G loss: 2.699064]\n",
      "epoch:21 step:16410 [D loss: 0.611559, acc: 63.28%] [G loss: 1.753671]\n",
      "epoch:21 step:16411 [D loss: 0.389853, acc: 91.41%] [G loss: 3.121921]\n",
      "epoch:21 step:16412 [D loss: 0.343180, acc: 97.66%] [G loss: 2.818849]\n",
      "epoch:21 step:16413 [D loss: 0.769989, acc: 43.75%] [G loss: 2.166758]\n",
      "epoch:21 step:16414 [D loss: 0.250451, acc: 99.22%] [G loss: 3.078720]\n",
      "epoch:21 step:16415 [D loss: 0.469768, acc: 75.00%] [G loss: 2.379952]\n",
      "epoch:21 step:16416 [D loss: 0.518610, acc: 70.31%] [G loss: 2.071813]\n",
      "epoch:21 step:16417 [D loss: 0.353610, acc: 85.94%] [G loss: 2.684043]\n",
      "epoch:21 step:16418 [D loss: 0.229148, acc: 97.66%] [G loss: 2.147833]\n",
      "epoch:21 step:16419 [D loss: 0.106923, acc: 100.00%] [G loss: 4.017490]\n",
      "epoch:21 step:16420 [D loss: 0.547810, acc: 75.78%] [G loss: 2.489095]\n",
      "epoch:21 step:16421 [D loss: 0.550955, acc: 77.34%] [G loss: 3.513165]\n",
      "epoch:21 step:16422 [D loss: 0.452277, acc: 83.59%] [G loss: 2.195235]\n",
      "epoch:21 step:16423 [D loss: 0.381797, acc: 75.78%] [G loss: 2.628785]\n",
      "epoch:21 step:16424 [D loss: 0.739286, acc: 49.22%] [G loss: 2.950072]\n",
      "epoch:21 step:16425 [D loss: 0.717531, acc: 53.12%] [G loss: 1.612711]\n",
      "epoch:21 step:16426 [D loss: 0.552966, acc: 67.97%] [G loss: 4.176996]\n",
      "epoch:21 step:16427 [D loss: 0.333649, acc: 88.28%] [G loss: 2.974795]\n",
      "epoch:21 step:16428 [D loss: 0.997294, acc: 22.66%] [G loss: 2.303575]\n",
      "epoch:21 step:16429 [D loss: 0.449927, acc: 74.22%] [G loss: 2.494267]\n",
      "epoch:21 step:16430 [D loss: 0.655059, acc: 64.06%] [G loss: 1.660478]\n",
      "epoch:21 step:16431 [D loss: 0.728421, acc: 57.03%] [G loss: 2.557607]\n",
      "epoch:21 step:16432 [D loss: 0.457662, acc: 86.72%] [G loss: 2.971175]\n",
      "epoch:21 step:16433 [D loss: 0.480626, acc: 88.28%] [G loss: 2.197411]\n",
      "epoch:21 step:16434 [D loss: 0.398727, acc: 76.56%] [G loss: 1.927212]\n",
      "epoch:21 step:16435 [D loss: 0.547795, acc: 70.31%] [G loss: 3.199880]\n",
      "epoch:21 step:16436 [D loss: 0.511757, acc: 80.47%] [G loss: 2.308763]\n",
      "epoch:21 step:16437 [D loss: 0.858344, acc: 32.03%] [G loss: 3.172192]\n",
      "epoch:21 step:16438 [D loss: 0.566819, acc: 69.53%] [G loss: 2.262846]\n",
      "epoch:21 step:16439 [D loss: 1.116908, acc: 33.59%] [G loss: 2.004868]\n",
      "epoch:21 step:16440 [D loss: 0.702412, acc: 54.69%] [G loss: 2.005263]\n",
      "epoch:21 step:16441 [D loss: 0.357338, acc: 97.66%] [G loss: 2.794021]\n",
      "epoch:21 step:16442 [D loss: 0.432811, acc: 77.34%] [G loss: 2.165130]\n",
      "epoch:21 step:16443 [D loss: 0.570401, acc: 71.88%] [G loss: 2.490437]\n",
      "epoch:21 step:16444 [D loss: 0.653525, acc: 55.47%] [G loss: 1.773887]\n",
      "epoch:21 step:16445 [D loss: 0.599039, acc: 69.53%] [G loss: 1.454731]\n",
      "epoch:21 step:16446 [D loss: 0.587362, acc: 69.53%] [G loss: 2.849482]\n",
      "epoch:21 step:16447 [D loss: 0.755723, acc: 50.78%] [G loss: 2.236371]\n",
      "epoch:21 step:16448 [D loss: 0.407740, acc: 78.91%] [G loss: 2.706433]\n",
      "epoch:21 step:16449 [D loss: 0.774906, acc: 50.00%] [G loss: 2.413219]\n",
      "epoch:21 step:16450 [D loss: 0.851418, acc: 38.28%] [G loss: 2.093792]\n",
      "epoch:21 step:16451 [D loss: 0.812791, acc: 45.31%] [G loss: 2.024055]\n",
      "epoch:21 step:16452 [D loss: 0.803102, acc: 42.19%] [G loss: 1.908026]\n",
      "epoch:21 step:16453 [D loss: 0.265080, acc: 96.88%] [G loss: 1.902540]\n",
      "epoch:21 step:16454 [D loss: 0.598960, acc: 60.16%] [G loss: 1.946271]\n",
      "epoch:21 step:16455 [D loss: 1.102160, acc: 32.81%] [G loss: 2.459878]\n",
      "epoch:21 step:16456 [D loss: 0.614983, acc: 67.19%] [G loss: 2.083513]\n",
      "epoch:21 step:16457 [D loss: 0.446425, acc: 67.97%] [G loss: 2.358857]\n",
      "epoch:21 step:16458 [D loss: 0.556521, acc: 75.78%] [G loss: 2.447383]\n",
      "epoch:21 step:16459 [D loss: 0.540079, acc: 78.91%] [G loss: 1.274630]\n",
      "epoch:21 step:16460 [D loss: 0.626655, acc: 57.81%] [G loss: 2.075519]\n",
      "epoch:21 step:16461 [D loss: 0.699092, acc: 49.22%] [G loss: 1.998637]\n",
      "epoch:21 step:16462 [D loss: 0.994844, acc: 25.00%] [G loss: 1.905041]\n",
      "epoch:21 step:16463 [D loss: 0.610104, acc: 63.28%] [G loss: 2.363439]\n",
      "epoch:21 step:16464 [D loss: 0.784445, acc: 43.75%] [G loss: 2.937347]\n",
      "epoch:21 step:16465 [D loss: 0.264935, acc: 99.22%] [G loss: 2.799761]\n",
      "epoch:21 step:16466 [D loss: 0.315499, acc: 96.09%] [G loss: 2.739937]\n",
      "epoch:21 step:16467 [D loss: 0.398634, acc: 82.03%] [G loss: 2.141843]\n",
      "epoch:21 step:16468 [D loss: 1.402374, acc: 3.91%] [G loss: 2.229319]\n",
      "epoch:21 step:16469 [D loss: 0.539917, acc: 79.69%] [G loss: 2.309252]\n",
      "epoch:21 step:16470 [D loss: 0.297163, acc: 96.09%] [G loss: 2.443559]\n",
      "epoch:21 step:16471 [D loss: 0.303076, acc: 90.62%] [G loss: 2.193377]\n",
      "epoch:21 step:16472 [D loss: 0.454668, acc: 85.94%] [G loss: 1.877106]\n",
      "epoch:21 step:16473 [D loss: 0.770780, acc: 53.12%] [G loss: 1.673685]\n",
      "epoch:21 step:16474 [D loss: 0.542797, acc: 69.53%] [G loss: 2.133748]\n",
      "epoch:21 step:16475 [D loss: 0.493847, acc: 64.06%] [G loss: 2.456263]\n",
      "epoch:21 step:16476 [D loss: 1.240421, acc: 19.53%] [G loss: 1.568220]\n",
      "epoch:21 step:16477 [D loss: 0.631183, acc: 58.59%] [G loss: 2.762322]\n",
      "epoch:21 step:16478 [D loss: 0.446290, acc: 86.72%] [G loss: 2.932589]\n",
      "epoch:21 step:16479 [D loss: 0.744229, acc: 52.34%] [G loss: 2.295116]\n",
      "epoch:21 step:16480 [D loss: 0.684391, acc: 46.88%] [G loss: 1.988425]\n",
      "epoch:21 step:16481 [D loss: 0.506462, acc: 85.16%] [G loss: 2.767590]\n",
      "epoch:21 step:16482 [D loss: 0.329744, acc: 96.09%] [G loss: 2.042750]\n",
      "epoch:21 step:16483 [D loss: 0.356673, acc: 83.59%] [G loss: 2.699494]\n",
      "epoch:21 step:16484 [D loss: 0.714045, acc: 53.12%] [G loss: 2.146366]\n",
      "epoch:21 step:16485 [D loss: 1.237689, acc: 9.38%] [G loss: 1.984217]\n",
      "epoch:21 step:16486 [D loss: 0.239158, acc: 99.22%] [G loss: 2.884826]\n",
      "epoch:21 step:16487 [D loss: 0.957538, acc: 25.00%] [G loss: 2.572656]\n",
      "epoch:21 step:16488 [D loss: 0.690003, acc: 57.81%] [G loss: 2.098795]\n",
      "epoch:21 step:16489 [D loss: 0.753855, acc: 43.75%] [G loss: 1.588010]\n",
      "epoch:21 step:16490 [D loss: 0.312616, acc: 92.19%] [G loss: 2.194515]\n",
      "epoch:21 step:16491 [D loss: 0.867833, acc: 36.72%] [G loss: 2.023206]\n",
      "epoch:21 step:16492 [D loss: 0.184706, acc: 99.22%] [G loss: 2.632204]\n",
      "epoch:21 step:16493 [D loss: 0.531847, acc: 73.44%] [G loss: 2.280297]\n",
      "epoch:21 step:16494 [D loss: 0.716111, acc: 57.81%] [G loss: 2.133223]\n",
      "epoch:21 step:16495 [D loss: 0.506560, acc: 77.34%] [G loss: 2.470196]\n",
      "epoch:21 step:16496 [D loss: 0.536820, acc: 82.03%] [G loss: 2.863443]\n",
      "epoch:21 step:16497 [D loss: 0.591624, acc: 70.31%] [G loss: 2.178045]\n",
      "epoch:21 step:16498 [D loss: 0.392914, acc: 85.16%] [G loss: 3.074397]\n",
      "epoch:21 step:16499 [D loss: 0.442832, acc: 90.62%] [G loss: 2.901133]\n",
      "epoch:21 step:16500 [D loss: 0.373463, acc: 91.41%] [G loss: 3.389527]\n",
      "epoch:21 step:16501 [D loss: 0.216892, acc: 99.22%] [G loss: 2.313100]\n",
      "epoch:21 step:16502 [D loss: 0.810236, acc: 39.84%] [G loss: 2.503149]\n",
      "epoch:21 step:16503 [D loss: 0.352127, acc: 94.53%] [G loss: 2.158704]\n",
      "epoch:21 step:16504 [D loss: 0.553512, acc: 69.53%] [G loss: 2.760354]\n",
      "epoch:21 step:16505 [D loss: 0.454824, acc: 86.72%] [G loss: 2.110548]\n",
      "epoch:21 step:16506 [D loss: 0.519608, acc: 73.44%] [G loss: 2.129791]\n",
      "epoch:21 step:16507 [D loss: 0.453017, acc: 82.81%] [G loss: 2.187912]\n",
      "epoch:21 step:16508 [D loss: 1.041436, acc: 14.06%] [G loss: 2.026642]\n",
      "epoch:21 step:16509 [D loss: 0.676243, acc: 53.91%] [G loss: 2.185850]\n",
      "epoch:21 step:16510 [D loss: 0.514017, acc: 80.47%] [G loss: 2.028993]\n",
      "epoch:21 step:16511 [D loss: 0.660758, acc: 62.50%] [G loss: 2.283462]\n",
      "epoch:21 step:16512 [D loss: 0.659800, acc: 60.94%] [G loss: 2.505973]\n",
      "epoch:21 step:16513 [D loss: 0.366085, acc: 94.53%] [G loss: 2.934860]\n",
      "epoch:21 step:16514 [D loss: 0.475421, acc: 77.34%] [G loss: 2.969953]\n",
      "epoch:21 step:16515 [D loss: 0.441118, acc: 85.16%] [G loss: 3.487874]\n",
      "epoch:21 step:16516 [D loss: 0.910697, acc: 33.59%] [G loss: 3.101109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16517 [D loss: 0.486537, acc: 85.16%] [G loss: 2.563270]\n",
      "epoch:21 step:16518 [D loss: 0.388983, acc: 95.31%] [G loss: 1.929357]\n",
      "epoch:21 step:16519 [D loss: 0.408436, acc: 92.19%] [G loss: 3.007190]\n",
      "epoch:21 step:16520 [D loss: 0.911057, acc: 23.44%] [G loss: 2.007831]\n",
      "epoch:21 step:16521 [D loss: 0.172463, acc: 100.00%] [G loss: 3.210403]\n",
      "epoch:21 step:16522 [D loss: 0.427716, acc: 83.59%] [G loss: 2.805910]\n",
      "epoch:21 step:16523 [D loss: 0.572341, acc: 66.41%] [G loss: 2.144081]\n",
      "epoch:21 step:16524 [D loss: 0.541764, acc: 75.78%] [G loss: 3.597211]\n",
      "epoch:21 step:16525 [D loss: 0.686121, acc: 60.16%] [G loss: 2.274981]\n",
      "epoch:21 step:16526 [D loss: 0.792829, acc: 41.41%] [G loss: 1.852753]\n",
      "epoch:21 step:16527 [D loss: 0.570248, acc: 75.00%] [G loss: 2.058321]\n",
      "epoch:21 step:16528 [D loss: 0.959950, acc: 40.62%] [G loss: 2.205709]\n",
      "epoch:21 step:16529 [D loss: 0.618173, acc: 65.62%] [G loss: 2.322566]\n",
      "epoch:21 step:16530 [D loss: 0.759806, acc: 45.31%] [G loss: 2.420448]\n",
      "epoch:21 step:16531 [D loss: 0.450435, acc: 81.25%] [G loss: 1.861428]\n",
      "epoch:21 step:16532 [D loss: 0.301621, acc: 93.75%] [G loss: 2.401042]\n",
      "epoch:21 step:16533 [D loss: 0.867559, acc: 46.09%] [G loss: 2.571324]\n",
      "epoch:21 step:16534 [D loss: 0.704375, acc: 55.47%] [G loss: 3.070737]\n",
      "epoch:21 step:16535 [D loss: 0.550886, acc: 83.59%] [G loss: 2.287386]\n",
      "epoch:21 step:16536 [D loss: 0.762505, acc: 42.19%] [G loss: 2.192317]\n",
      "epoch:21 step:16537 [D loss: 0.572859, acc: 76.56%] [G loss: 2.405239]\n",
      "epoch:21 step:16538 [D loss: 0.697785, acc: 56.25%] [G loss: 2.060603]\n",
      "epoch:21 step:16539 [D loss: 0.335814, acc: 96.88%] [G loss: 2.773719]\n",
      "epoch:21 step:16540 [D loss: 0.415439, acc: 87.50%] [G loss: 2.197903]\n",
      "epoch:21 step:16541 [D loss: 0.698724, acc: 53.12%] [G loss: 2.252418]\n",
      "epoch:21 step:16542 [D loss: 0.413886, acc: 92.97%] [G loss: 2.958022]\n",
      "epoch:21 step:16543 [D loss: 0.518023, acc: 79.69%] [G loss: 2.451887]\n",
      "epoch:21 step:16544 [D loss: 0.623993, acc: 64.06%] [G loss: 2.023689]\n",
      "epoch:21 step:16545 [D loss: 0.768687, acc: 43.75%] [G loss: 2.186548]\n",
      "epoch:21 step:16546 [D loss: 0.441655, acc: 75.78%] [G loss: 2.519255]\n",
      "epoch:21 step:16547 [D loss: 0.637648, acc: 61.72%] [G loss: 2.181512]\n",
      "epoch:21 step:16548 [D loss: 0.363095, acc: 85.16%] [G loss: 2.107144]\n",
      "epoch:21 step:16549 [D loss: 0.547912, acc: 74.22%] [G loss: 2.119503]\n",
      "epoch:21 step:16550 [D loss: 0.561638, acc: 76.56%] [G loss: 2.179913]\n",
      "epoch:21 step:16551 [D loss: 0.812901, acc: 37.50%] [G loss: 2.689694]\n",
      "epoch:21 step:16552 [D loss: 0.320236, acc: 86.72%] [G loss: 2.040653]\n",
      "epoch:21 step:16553 [D loss: 0.449392, acc: 90.62%] [G loss: 2.139924]\n",
      "epoch:21 step:16554 [D loss: 0.608570, acc: 72.66%] [G loss: 2.136883]\n",
      "epoch:21 step:16555 [D loss: 0.407458, acc: 89.06%] [G loss: 2.203844]\n",
      "epoch:21 step:16556 [D loss: 0.583089, acc: 70.31%] [G loss: 1.998400]\n",
      "epoch:21 step:16557 [D loss: 0.392755, acc: 92.19%] [G loss: 2.158833]\n",
      "epoch:21 step:16558 [D loss: 0.657415, acc: 51.56%] [G loss: 3.152269]\n",
      "epoch:21 step:16559 [D loss: 0.871441, acc: 47.66%] [G loss: 2.533671]\n",
      "epoch:21 step:16560 [D loss: 0.728426, acc: 50.00%] [G loss: 2.585349]\n",
      "epoch:21 step:16561 [D loss: 0.349298, acc: 82.81%] [G loss: 2.972585]\n",
      "epoch:21 step:16562 [D loss: 0.738585, acc: 52.34%] [G loss: 2.954465]\n",
      "epoch:21 step:16563 [D loss: 0.339158, acc: 92.19%] [G loss: 2.503339]\n",
      "epoch:21 step:16564 [D loss: 0.444721, acc: 78.12%] [G loss: 1.776627]\n",
      "epoch:21 step:16565 [D loss: 0.468673, acc: 88.28%] [G loss: 2.493872]\n",
      "epoch:21 step:16566 [D loss: 0.423698, acc: 82.81%] [G loss: 2.788786]\n",
      "epoch:21 step:16567 [D loss: 0.484224, acc: 82.03%] [G loss: 2.224780]\n",
      "epoch:21 step:16568 [D loss: 0.227789, acc: 96.09%] [G loss: 3.239278]\n",
      "epoch:21 step:16569 [D loss: 0.549015, acc: 75.00%] [G loss: 2.951626]\n",
      "epoch:21 step:16570 [D loss: 0.296674, acc: 97.66%] [G loss: 2.611492]\n",
      "epoch:21 step:16571 [D loss: 0.207596, acc: 98.44%] [G loss: 2.799445]\n",
      "epoch:21 step:16572 [D loss: 0.645055, acc: 57.81%] [G loss: 2.288149]\n",
      "epoch:21 step:16573 [D loss: 0.513264, acc: 77.34%] [G loss: 2.253157]\n",
      "epoch:21 step:16574 [D loss: 0.605183, acc: 70.31%] [G loss: 2.522325]\n",
      "epoch:21 step:16575 [D loss: 1.158470, acc: 9.38%] [G loss: 2.381272]\n",
      "epoch:21 step:16576 [D loss: 0.558099, acc: 78.12%] [G loss: 3.016287]\n",
      "epoch:21 step:16577 [D loss: 1.229675, acc: 11.72%] [G loss: 1.794293]\n",
      "epoch:21 step:16578 [D loss: 0.717444, acc: 52.34%] [G loss: 2.037738]\n",
      "epoch:21 step:16579 [D loss: 0.898492, acc: 36.72%] [G loss: 2.377787]\n",
      "epoch:21 step:16580 [D loss: 0.549450, acc: 74.22%] [G loss: 1.836000]\n",
      "epoch:21 step:16581 [D loss: 0.567837, acc: 66.41%] [G loss: 2.122776]\n",
      "epoch:21 step:16582 [D loss: 0.529919, acc: 81.25%] [G loss: 2.561042]\n",
      "epoch:21 step:16583 [D loss: 0.653194, acc: 64.06%] [G loss: 1.887157]\n",
      "epoch:21 step:16584 [D loss: 0.493320, acc: 86.72%] [G loss: 2.168438]\n",
      "epoch:21 step:16585 [D loss: 0.776181, acc: 52.34%] [G loss: 1.864993]\n",
      "epoch:21 step:16586 [D loss: 0.404898, acc: 91.41%] [G loss: 1.985665]\n",
      "epoch:21 step:16587 [D loss: 0.707312, acc: 51.56%] [G loss: 2.038093]\n",
      "epoch:21 step:16588 [D loss: 0.613845, acc: 60.94%] [G loss: 2.207877]\n",
      "epoch:21 step:16589 [D loss: 0.788053, acc: 39.84%] [G loss: 2.032316]\n",
      "epoch:21 step:16590 [D loss: 0.314545, acc: 96.09%] [G loss: 3.065686]\n",
      "epoch:21 step:16591 [D loss: 0.672329, acc: 60.94%] [G loss: 2.467521]\n",
      "epoch:21 step:16592 [D loss: 0.624449, acc: 62.50%] [G loss: 2.124408]\n",
      "epoch:21 step:16593 [D loss: 0.582227, acc: 72.66%] [G loss: 2.258392]\n",
      "epoch:21 step:16594 [D loss: 0.151361, acc: 99.22%] [G loss: 2.817127]\n",
      "epoch:21 step:16595 [D loss: 0.587882, acc: 73.44%] [G loss: 1.883381]\n",
      "epoch:21 step:16596 [D loss: 0.669641, acc: 57.81%] [G loss: 1.666784]\n",
      "epoch:21 step:16597 [D loss: 0.261709, acc: 94.53%] [G loss: 1.728633]\n",
      "epoch:21 step:16598 [D loss: 0.603449, acc: 60.16%] [G loss: 2.552330]\n",
      "epoch:21 step:16599 [D loss: 0.677131, acc: 59.38%] [G loss: 2.643871]\n",
      "epoch:21 step:16600 [D loss: 0.412908, acc: 90.62%] [G loss: 1.870425]\n",
      "epoch:21 step:16601 [D loss: 0.400433, acc: 93.75%] [G loss: 3.556915]\n",
      "epoch:21 step:16602 [D loss: 0.322123, acc: 96.09%] [G loss: 2.873441]\n",
      "epoch:21 step:16603 [D loss: 0.550538, acc: 75.00%] [G loss: 2.314774]\n",
      "epoch:21 step:16604 [D loss: 0.371991, acc: 89.06%] [G loss: 2.801705]\n",
      "epoch:21 step:16605 [D loss: 0.667412, acc: 63.28%] [G loss: 1.327569]\n",
      "epoch:21 step:16606 [D loss: 1.175870, acc: 27.34%] [G loss: 1.642844]\n",
      "epoch:21 step:16607 [D loss: 0.850308, acc: 51.56%] [G loss: 1.636070]\n",
      "epoch:21 step:16608 [D loss: 0.269084, acc: 96.09%] [G loss: 2.475689]\n",
      "epoch:21 step:16609 [D loss: 0.229680, acc: 97.66%] [G loss: 3.702166]\n",
      "epoch:21 step:16610 [D loss: 0.555363, acc: 63.28%] [G loss: 1.921548]\n",
      "epoch:21 step:16611 [D loss: 0.630586, acc: 64.06%] [G loss: 2.007393]\n",
      "epoch:21 step:16612 [D loss: 0.593504, acc: 68.75%] [G loss: 2.408317]\n",
      "epoch:21 step:16613 [D loss: 0.507413, acc: 85.94%] [G loss: 2.381321]\n",
      "epoch:21 step:16614 [D loss: 0.551162, acc: 61.72%] [G loss: 1.986284]\n",
      "epoch:21 step:16615 [D loss: 0.401786, acc: 85.16%] [G loss: 2.861776]\n",
      "epoch:21 step:16616 [D loss: 0.528640, acc: 65.62%] [G loss: 1.933663]\n",
      "epoch:21 step:16617 [D loss: 0.501268, acc: 82.81%] [G loss: 2.307141]\n",
      "epoch:21 step:16618 [D loss: 0.559419, acc: 71.09%] [G loss: 2.534261]\n",
      "epoch:21 step:16619 [D loss: 0.489583, acc: 84.38%] [G loss: 2.270733]\n",
      "epoch:21 step:16620 [D loss: 0.367079, acc: 90.62%] [G loss: 1.886064]\n",
      "epoch:21 step:16621 [D loss: 0.556339, acc: 71.88%] [G loss: 2.792798]\n",
      "epoch:21 step:16622 [D loss: 0.749811, acc: 53.12%] [G loss: 1.459994]\n",
      "epoch:21 step:16623 [D loss: 0.662562, acc: 60.94%] [G loss: 2.107217]\n",
      "epoch:21 step:16624 [D loss: 0.782073, acc: 49.22%] [G loss: 2.685860]\n",
      "epoch:21 step:16625 [D loss: 0.907384, acc: 32.81%] [G loss: 1.971748]\n",
      "epoch:21 step:16626 [D loss: 0.192276, acc: 100.00%] [G loss: 2.774910]\n",
      "epoch:21 step:16627 [D loss: 0.763431, acc: 46.09%] [G loss: 2.150587]\n",
      "epoch:21 step:16628 [D loss: 0.678579, acc: 56.25%] [G loss: 2.077643]\n",
      "epoch:21 step:16629 [D loss: 0.443501, acc: 82.81%] [G loss: 2.076598]\n",
      "epoch:21 step:16630 [D loss: 0.468711, acc: 82.81%] [G loss: 2.695938]\n",
      "epoch:21 step:16631 [D loss: 0.968692, acc: 47.66%] [G loss: 2.189682]\n",
      "epoch:21 step:16632 [D loss: 0.570915, acc: 73.44%] [G loss: 2.266314]\n",
      "epoch:21 step:16633 [D loss: 0.860316, acc: 35.94%] [G loss: 1.995573]\n",
      "epoch:21 step:16634 [D loss: 0.376104, acc: 87.50%] [G loss: 3.189787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16635 [D loss: 0.762009, acc: 46.88%] [G loss: 2.690652]\n",
      "epoch:21 step:16636 [D loss: 0.525163, acc: 75.78%] [G loss: 2.214514]\n",
      "epoch:21 step:16637 [D loss: 0.537542, acc: 78.91%] [G loss: 2.148725]\n",
      "epoch:21 step:16638 [D loss: 0.515468, acc: 72.66%] [G loss: 2.731319]\n",
      "epoch:21 step:16639 [D loss: 0.246628, acc: 99.22%] [G loss: 2.621683]\n",
      "epoch:21 step:16640 [D loss: 0.260301, acc: 96.88%] [G loss: 2.472736]\n",
      "epoch:21 step:16641 [D loss: 0.538507, acc: 74.22%] [G loss: 2.918409]\n",
      "epoch:21 step:16642 [D loss: 0.548330, acc: 79.69%] [G loss: 2.782349]\n",
      "epoch:21 step:16643 [D loss: 0.414025, acc: 92.19%] [G loss: 2.425395]\n",
      "epoch:21 step:16644 [D loss: 0.481122, acc: 83.59%] [G loss: 2.558496]\n",
      "epoch:21 step:16645 [D loss: 0.929118, acc: 25.00%] [G loss: 2.557830]\n",
      "epoch:21 step:16646 [D loss: 0.679863, acc: 61.72%] [G loss: 1.909203]\n",
      "epoch:21 step:16647 [D loss: 0.683133, acc: 57.81%] [G loss: 1.997417]\n",
      "epoch:21 step:16648 [D loss: 0.631538, acc: 60.16%] [G loss: 1.906921]\n",
      "epoch:21 step:16649 [D loss: 0.663780, acc: 66.41%] [G loss: 2.767182]\n",
      "epoch:21 step:16650 [D loss: 0.512591, acc: 67.97%] [G loss: 2.614900]\n",
      "epoch:21 step:16651 [D loss: 0.719848, acc: 50.00%] [G loss: 2.644496]\n",
      "epoch:21 step:16652 [D loss: 0.402441, acc: 93.75%] [G loss: 2.757128]\n",
      "epoch:21 step:16653 [D loss: 0.866107, acc: 36.72%] [G loss: 2.153489]\n",
      "epoch:21 step:16654 [D loss: 0.586693, acc: 63.28%] [G loss: 2.313386]\n",
      "epoch:21 step:16655 [D loss: 0.622256, acc: 61.72%] [G loss: 2.210761]\n",
      "epoch:21 step:16656 [D loss: 0.556744, acc: 72.66%] [G loss: 2.788136]\n",
      "epoch:21 step:16657 [D loss: 0.598861, acc: 67.97%] [G loss: 2.921954]\n",
      "epoch:21 step:16658 [D loss: 0.361033, acc: 84.38%] [G loss: 2.828196]\n",
      "epoch:21 step:16659 [D loss: 0.357290, acc: 93.75%] [G loss: 3.144382]\n",
      "epoch:21 step:16660 [D loss: 0.356517, acc: 92.19%] [G loss: 1.698190]\n",
      "epoch:21 step:16661 [D loss: 0.726067, acc: 57.81%] [G loss: 2.382548]\n",
      "epoch:21 step:16662 [D loss: 0.440250, acc: 94.53%] [G loss: 2.534457]\n",
      "epoch:21 step:16663 [D loss: 0.476996, acc: 75.78%] [G loss: 1.985539]\n",
      "epoch:21 step:16664 [D loss: 1.032399, acc: 36.72%] [G loss: 1.760779]\n",
      "epoch:21 step:16665 [D loss: 0.608434, acc: 66.41%] [G loss: 1.934194]\n",
      "epoch:21 step:16666 [D loss: 0.531945, acc: 75.00%] [G loss: 2.078075]\n",
      "epoch:21 step:16667 [D loss: 0.590700, acc: 66.41%] [G loss: 2.047809]\n",
      "epoch:21 step:16668 [D loss: 0.837120, acc: 34.38%] [G loss: 1.842507]\n",
      "epoch:21 step:16669 [D loss: 0.484949, acc: 85.16%] [G loss: 1.834232]\n",
      "epoch:21 step:16670 [D loss: 0.239637, acc: 99.22%] [G loss: 2.607957]\n",
      "epoch:21 step:16671 [D loss: 0.687766, acc: 60.94%] [G loss: 2.038942]\n",
      "epoch:21 step:16672 [D loss: 0.517358, acc: 72.66%] [G loss: 3.088861]\n",
      "epoch:21 step:16673 [D loss: 0.566383, acc: 71.09%] [G loss: 2.904576]\n",
      "epoch:21 step:16674 [D loss: 0.546694, acc: 75.00%] [G loss: 1.781207]\n",
      "epoch:21 step:16675 [D loss: 0.780862, acc: 41.41%] [G loss: 3.320226]\n",
      "epoch:21 step:16676 [D loss: 0.864352, acc: 30.47%] [G loss: 2.074012]\n",
      "epoch:21 step:16677 [D loss: 0.681343, acc: 56.25%] [G loss: 1.984770]\n",
      "epoch:21 step:16678 [D loss: 0.696372, acc: 53.91%] [G loss: 1.852265]\n",
      "epoch:21 step:16679 [D loss: 0.670594, acc: 60.16%] [G loss: 2.610428]\n",
      "epoch:21 step:16680 [D loss: 0.649832, acc: 61.72%] [G loss: 1.733680]\n",
      "epoch:21 step:16681 [D loss: 0.504087, acc: 75.78%] [G loss: 2.565473]\n",
      "epoch:21 step:16682 [D loss: 0.417133, acc: 92.97%] [G loss: 2.349599]\n",
      "epoch:21 step:16683 [D loss: 0.442543, acc: 89.06%] [G loss: 2.968886]\n",
      "epoch:21 step:16684 [D loss: 0.329445, acc: 88.28%] [G loss: 3.111002]\n",
      "epoch:21 step:16685 [D loss: 0.774172, acc: 48.44%] [G loss: 1.832009]\n",
      "epoch:21 step:16686 [D loss: 0.643567, acc: 60.16%] [G loss: 2.330937]\n",
      "epoch:21 step:16687 [D loss: 0.573599, acc: 78.12%] [G loss: 1.959890]\n",
      "epoch:21 step:16688 [D loss: 0.403424, acc: 87.50%] [G loss: 2.847304]\n",
      "epoch:21 step:16689 [D loss: 0.440703, acc: 91.41%] [G loss: 2.735548]\n",
      "epoch:21 step:16690 [D loss: 0.575153, acc: 72.66%] [G loss: 1.800534]\n",
      "epoch:21 step:16691 [D loss: 0.779626, acc: 42.97%] [G loss: 2.201880]\n",
      "epoch:21 step:16692 [D loss: 0.597762, acc: 69.53%] [G loss: 1.575668]\n",
      "epoch:21 step:16693 [D loss: 0.413174, acc: 85.16%] [G loss: 2.754966]\n",
      "epoch:21 step:16694 [D loss: 0.627431, acc: 67.19%] [G loss: 2.700763]\n",
      "epoch:21 step:16695 [D loss: 0.494059, acc: 82.81%] [G loss: 1.789560]\n",
      "epoch:21 step:16696 [D loss: 0.517148, acc: 83.59%] [G loss: 2.407806]\n",
      "epoch:21 step:16697 [D loss: 0.211637, acc: 97.66%] [G loss: 2.662131]\n",
      "epoch:21 step:16698 [D loss: 0.586667, acc: 73.44%] [G loss: 1.858430]\n",
      "epoch:21 step:16699 [D loss: 0.501377, acc: 78.12%] [G loss: 2.525607]\n",
      "epoch:21 step:16700 [D loss: 0.249702, acc: 99.22%] [G loss: 2.443120]\n",
      "epoch:21 step:16701 [D loss: 0.685824, acc: 55.47%] [G loss: 2.505548]\n",
      "epoch:21 step:16702 [D loss: 0.555059, acc: 71.09%] [G loss: 2.718186]\n",
      "epoch:21 step:16703 [D loss: 0.641847, acc: 60.16%] [G loss: 2.087069]\n",
      "epoch:21 step:16704 [D loss: 0.539169, acc: 66.41%] [G loss: 3.169388]\n",
      "epoch:21 step:16705 [D loss: 0.447891, acc: 87.50%] [G loss: 2.828680]\n",
      "epoch:21 step:16706 [D loss: 0.335447, acc: 89.06%] [G loss: 3.507187]\n",
      "epoch:21 step:16707 [D loss: 0.409351, acc: 90.62%] [G loss: 2.627213]\n",
      "epoch:21 step:16708 [D loss: 0.504058, acc: 77.34%] [G loss: 2.289426]\n",
      "epoch:21 step:16709 [D loss: 0.449044, acc: 89.06%] [G loss: 2.367197]\n",
      "epoch:21 step:16710 [D loss: 0.395166, acc: 90.62%] [G loss: 2.312451]\n",
      "epoch:21 step:16711 [D loss: 0.701144, acc: 57.03%] [G loss: 2.150579]\n",
      "epoch:21 step:16712 [D loss: 0.871467, acc: 46.88%] [G loss: 2.137716]\n",
      "epoch:21 step:16713 [D loss: 0.704949, acc: 57.81%] [G loss: 2.367069]\n",
      "epoch:21 step:16714 [D loss: 0.230047, acc: 100.00%] [G loss: 2.903816]\n",
      "epoch:21 step:16715 [D loss: 0.490031, acc: 79.69%] [G loss: 2.323917]\n",
      "epoch:21 step:16716 [D loss: 0.700836, acc: 57.03%] [G loss: 2.637156]\n",
      "epoch:21 step:16717 [D loss: 0.296530, acc: 97.66%] [G loss: 2.872053]\n",
      "epoch:21 step:16718 [D loss: 0.287032, acc: 96.09%] [G loss: 3.261295]\n",
      "epoch:21 step:16719 [D loss: 0.850320, acc: 50.78%] [G loss: 1.760136]\n",
      "epoch:21 step:16720 [D loss: 0.415264, acc: 82.03%] [G loss: 2.776992]\n",
      "epoch:21 step:16721 [D loss: 0.659340, acc: 58.59%] [G loss: 2.159822]\n",
      "epoch:21 step:16722 [D loss: 0.424139, acc: 89.06%] [G loss: 2.751392]\n",
      "epoch:21 step:16723 [D loss: 0.333608, acc: 90.62%] [G loss: 2.900364]\n",
      "epoch:21 step:16724 [D loss: 0.365712, acc: 97.66%] [G loss: 2.732131]\n",
      "epoch:21 step:16725 [D loss: 0.378867, acc: 89.84%] [G loss: 2.722883]\n",
      "epoch:21 step:16726 [D loss: 0.400152, acc: 92.19%] [G loss: 2.814205]\n",
      "epoch:21 step:16727 [D loss: 0.347430, acc: 96.88%] [G loss: 3.670865]\n",
      "epoch:21 step:16728 [D loss: 0.546610, acc: 65.62%] [G loss: 2.690497]\n",
      "epoch:21 step:16729 [D loss: 0.297827, acc: 97.66%] [G loss: 3.333983]\n",
      "epoch:21 step:16730 [D loss: 0.614517, acc: 67.97%] [G loss: 3.500134]\n",
      "epoch:21 step:16731 [D loss: 0.331632, acc: 92.19%] [G loss: 2.427802]\n",
      "epoch:21 step:16732 [D loss: 0.704720, acc: 56.25%] [G loss: 2.340730]\n",
      "epoch:21 step:16733 [D loss: 0.770063, acc: 51.56%] [G loss: 2.332034]\n",
      "epoch:21 step:16734 [D loss: 0.474565, acc: 83.59%] [G loss: 2.251247]\n",
      "epoch:21 step:16735 [D loss: 0.781710, acc: 38.28%] [G loss: 1.373118]\n",
      "epoch:21 step:16736 [D loss: 0.339800, acc: 96.88%] [G loss: 3.297990]\n",
      "epoch:21 step:16737 [D loss: 0.415282, acc: 85.16%] [G loss: 2.832520]\n",
      "epoch:21 step:16738 [D loss: 0.857925, acc: 50.78%] [G loss: 1.971410]\n",
      "epoch:21 step:16739 [D loss: 0.648821, acc: 58.59%] [G loss: 2.698107]\n",
      "epoch:21 step:16740 [D loss: 0.672070, acc: 57.81%] [G loss: 3.013413]\n",
      "epoch:21 step:16741 [D loss: 0.424180, acc: 90.62%] [G loss: 1.938450]\n",
      "epoch:21 step:16742 [D loss: 0.338289, acc: 91.41%] [G loss: 2.032795]\n",
      "epoch:21 step:16743 [D loss: 0.369809, acc: 92.97%] [G loss: 2.577324]\n",
      "epoch:21 step:16744 [D loss: 0.558668, acc: 75.78%] [G loss: 2.380514]\n",
      "epoch:21 step:16745 [D loss: 0.710946, acc: 52.34%] [G loss: 2.160192]\n",
      "epoch:21 step:16746 [D loss: 0.296632, acc: 96.88%] [G loss: 2.732187]\n",
      "epoch:21 step:16747 [D loss: 0.458838, acc: 82.81%] [G loss: 3.114632]\n",
      "epoch:21 step:16748 [D loss: 0.621280, acc: 68.75%] [G loss: 2.408695]\n",
      "epoch:21 step:16749 [D loss: 0.577924, acc: 64.06%] [G loss: 2.453028]\n",
      "epoch:21 step:16750 [D loss: 0.986131, acc: 14.06%] [G loss: 2.721829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16751 [D loss: 1.231861, acc: 21.88%] [G loss: 3.121157]\n",
      "epoch:21 step:16752 [D loss: 0.688192, acc: 58.59%] [G loss: 2.620420]\n",
      "epoch:21 step:16753 [D loss: 0.654475, acc: 61.72%] [G loss: 2.425423]\n",
      "epoch:21 step:16754 [D loss: 0.629532, acc: 61.72%] [G loss: 2.459100]\n",
      "epoch:21 step:16755 [D loss: 0.579899, acc: 72.66%] [G loss: 2.262944]\n",
      "epoch:21 step:16756 [D loss: 0.979065, acc: 20.31%] [G loss: 2.642907]\n",
      "epoch:21 step:16757 [D loss: 0.575286, acc: 57.81%] [G loss: 2.860386]\n",
      "epoch:21 step:16758 [D loss: 0.349238, acc: 96.09%] [G loss: 2.352957]\n",
      "epoch:21 step:16759 [D loss: 0.783196, acc: 47.66%] [G loss: 2.323183]\n",
      "epoch:21 step:16760 [D loss: 0.720855, acc: 52.34%] [G loss: 2.233609]\n",
      "epoch:21 step:16761 [D loss: 0.753356, acc: 50.78%] [G loss: 2.182512]\n",
      "epoch:21 step:16762 [D loss: 0.407621, acc: 89.84%] [G loss: 2.296084]\n",
      "epoch:21 step:16763 [D loss: 0.369113, acc: 92.97%] [G loss: 2.540277]\n",
      "epoch:21 step:16764 [D loss: 0.444571, acc: 88.28%] [G loss: 3.543958]\n",
      "epoch:21 step:16765 [D loss: 0.405071, acc: 85.94%] [G loss: 3.078843]\n",
      "epoch:21 step:16766 [D loss: 0.524672, acc: 82.81%] [G loss: 2.290044]\n",
      "epoch:21 step:16767 [D loss: 0.632745, acc: 66.41%] [G loss: 1.923090]\n",
      "epoch:21 step:16768 [D loss: 0.676647, acc: 61.72%] [G loss: 1.611643]\n",
      "epoch:21 step:16769 [D loss: 0.523610, acc: 71.88%] [G loss: 2.829221]\n",
      "epoch:21 step:16770 [D loss: 0.386842, acc: 81.25%] [G loss: 2.645612]\n",
      "epoch:21 step:16771 [D loss: 0.791849, acc: 46.09%] [G loss: 2.361564]\n",
      "epoch:21 step:16772 [D loss: 0.558710, acc: 72.66%] [G loss: 2.196194]\n",
      "epoch:21 step:16773 [D loss: 0.955005, acc: 24.22%] [G loss: 1.743723]\n",
      "epoch:21 step:16774 [D loss: 0.948714, acc: 46.88%] [G loss: 1.961767]\n",
      "epoch:21 step:16775 [D loss: 0.623477, acc: 60.94%] [G loss: 2.847611]\n",
      "epoch:21 step:16776 [D loss: 0.331086, acc: 96.88%] [G loss: 2.988116]\n",
      "epoch:21 step:16777 [D loss: 0.454959, acc: 77.34%] [G loss: 3.194402]\n",
      "epoch:21 step:16778 [D loss: 0.462908, acc: 87.50%] [G loss: 3.063016]\n",
      "epoch:21 step:16779 [D loss: 0.634548, acc: 67.97%] [G loss: 2.352782]\n",
      "epoch:21 step:16780 [D loss: 0.279658, acc: 95.31%] [G loss: 2.228283]\n",
      "epoch:21 step:16781 [D loss: 0.482788, acc: 82.03%] [G loss: 3.384632]\n",
      "epoch:21 step:16782 [D loss: 0.353895, acc: 93.75%] [G loss: 2.605285]\n",
      "epoch:21 step:16783 [D loss: 0.308995, acc: 96.88%] [G loss: 2.938819]\n",
      "epoch:21 step:16784 [D loss: 1.030461, acc: 16.41%] [G loss: 1.957106]\n",
      "epoch:21 step:16785 [D loss: 0.785434, acc: 50.00%] [G loss: 2.227630]\n",
      "epoch:21 step:16786 [D loss: 0.644288, acc: 64.06%] [G loss: 1.752071]\n",
      "epoch:21 step:16787 [D loss: 0.666834, acc: 57.81%] [G loss: 2.181145]\n",
      "epoch:21 step:16788 [D loss: 0.441514, acc: 85.16%] [G loss: 2.772279]\n",
      "epoch:21 step:16789 [D loss: 0.587513, acc: 52.34%] [G loss: 2.023607]\n",
      "epoch:21 step:16790 [D loss: 0.443378, acc: 85.16%] [G loss: 3.200899]\n",
      "epoch:21 step:16791 [D loss: 0.548388, acc: 78.91%] [G loss: 2.577252]\n",
      "epoch:21 step:16792 [D loss: 0.977501, acc: 45.31%] [G loss: 2.682441]\n",
      "epoch:21 step:16793 [D loss: 0.265296, acc: 100.00%] [G loss: 2.541016]\n",
      "epoch:21 step:16794 [D loss: 0.581594, acc: 63.28%] [G loss: 2.310711]\n",
      "epoch:21 step:16795 [D loss: 0.438027, acc: 86.72%] [G loss: 3.493742]\n",
      "epoch:21 step:16796 [D loss: 0.876824, acc: 34.38%] [G loss: 2.377652]\n",
      "epoch:21 step:16797 [D loss: 0.531217, acc: 79.69%] [G loss: 2.531498]\n",
      "epoch:21 step:16798 [D loss: 0.936029, acc: 25.00%] [G loss: 2.212259]\n",
      "epoch:21 step:16799 [D loss: 0.526002, acc: 81.25%] [G loss: 1.939560]\n",
      "epoch:21 step:16800 [D loss: 0.437165, acc: 79.69%] [G loss: 2.724903]\n",
      "epoch:21 step:16801 [D loss: 0.803485, acc: 42.97%] [G loss: 2.685061]\n",
      "epoch:21 step:16802 [D loss: 0.406381, acc: 92.97%] [G loss: 3.006327]\n",
      "epoch:21 step:16803 [D loss: 0.529158, acc: 70.31%] [G loss: 2.386788]\n",
      "epoch:21 step:16804 [D loss: 0.567437, acc: 77.34%] [G loss: 2.976902]\n",
      "epoch:21 step:16805 [D loss: 0.599455, acc: 70.31%] [G loss: 1.984446]\n",
      "epoch:21 step:16806 [D loss: 0.837221, acc: 48.44%] [G loss: 2.061632]\n",
      "epoch:21 step:16807 [D loss: 0.314511, acc: 96.88%] [G loss: 2.940477]\n",
      "epoch:21 step:16808 [D loss: 0.424842, acc: 90.62%] [G loss: 2.993985]\n",
      "epoch:21 step:16809 [D loss: 0.239611, acc: 98.44%] [G loss: 2.755859]\n",
      "epoch:21 step:16810 [D loss: 0.493247, acc: 78.12%] [G loss: 2.515401]\n",
      "epoch:21 step:16811 [D loss: 0.723417, acc: 59.38%] [G loss: 2.520516]\n",
      "epoch:21 step:16812 [D loss: 0.698304, acc: 53.12%] [G loss: 2.388434]\n",
      "epoch:21 step:16813 [D loss: 0.542056, acc: 67.19%] [G loss: 2.833786]\n",
      "epoch:21 step:16814 [D loss: 0.418334, acc: 92.19%] [G loss: 2.990619]\n",
      "epoch:21 step:16815 [D loss: 0.611130, acc: 64.06%] [G loss: 2.450639]\n",
      "epoch:21 step:16816 [D loss: 0.187133, acc: 99.22%] [G loss: 2.565494]\n",
      "epoch:21 step:16817 [D loss: 0.252633, acc: 99.22%] [G loss: 2.387993]\n",
      "epoch:21 step:16818 [D loss: 0.255781, acc: 96.88%] [G loss: 2.353688]\n",
      "epoch:21 step:16819 [D loss: 0.664451, acc: 60.94%] [G loss: 2.164416]\n",
      "epoch:21 step:16820 [D loss: 0.451424, acc: 92.97%] [G loss: 2.966384]\n",
      "epoch:21 step:16821 [D loss: 0.602923, acc: 58.59%] [G loss: 2.411181]\n",
      "epoch:21 step:16822 [D loss: 0.249739, acc: 100.00%] [G loss: 2.983163]\n",
      "epoch:21 step:16823 [D loss: 0.542630, acc: 68.75%] [G loss: 3.384637]\n",
      "epoch:21 step:16824 [D loss: 1.004242, acc: 24.22%] [G loss: 2.327291]\n",
      "epoch:21 step:16825 [D loss: 0.770007, acc: 46.09%] [G loss: 2.543073]\n",
      "epoch:21 step:16826 [D loss: 0.418357, acc: 92.97%] [G loss: 2.588277]\n",
      "epoch:21 step:16827 [D loss: 0.348515, acc: 85.94%] [G loss: 2.640948]\n",
      "epoch:21 step:16828 [D loss: 0.422378, acc: 73.44%] [G loss: 2.301714]\n",
      "epoch:21 step:16829 [D loss: 0.832046, acc: 46.09%] [G loss: 2.833497]\n",
      "epoch:21 step:16830 [D loss: 0.213617, acc: 99.22%] [G loss: 2.662988]\n",
      "epoch:21 step:16831 [D loss: 0.450155, acc: 83.59%] [G loss: 2.075369]\n",
      "epoch:21 step:16832 [D loss: 0.860321, acc: 50.78%] [G loss: 1.833387]\n",
      "epoch:21 step:16833 [D loss: 0.425748, acc: 89.06%] [G loss: 2.960363]\n",
      "epoch:21 step:16834 [D loss: 0.164058, acc: 100.00%] [G loss: 2.563906]\n",
      "epoch:21 step:16835 [D loss: 0.574003, acc: 74.22%] [G loss: 3.245960]\n",
      "epoch:21 step:16836 [D loss: 0.471892, acc: 79.69%] [G loss: 2.560514]\n",
      "epoch:21 step:16837 [D loss: 1.026983, acc: 33.59%] [G loss: 2.631466]\n",
      "epoch:21 step:16838 [D loss: 0.614225, acc: 64.84%] [G loss: 2.248984]\n",
      "epoch:21 step:16839 [D loss: 0.303263, acc: 94.53%] [G loss: 2.879735]\n",
      "epoch:21 step:16840 [D loss: 0.561203, acc: 75.00%] [G loss: 2.890827]\n",
      "epoch:21 step:16841 [D loss: 0.716335, acc: 53.12%] [G loss: 2.130371]\n",
      "epoch:21 step:16842 [D loss: 0.720855, acc: 57.03%] [G loss: 2.507291]\n",
      "epoch:21 step:16843 [D loss: 0.678589, acc: 60.94%] [G loss: 1.774871]\n",
      "epoch:21 step:16844 [D loss: 0.463132, acc: 85.16%] [G loss: 2.735508]\n",
      "epoch:21 step:16845 [D loss: 0.361519, acc: 91.41%] [G loss: 2.486296]\n",
      "epoch:21 step:16846 [D loss: 0.631183, acc: 62.50%] [G loss: 3.170080]\n",
      "epoch:21 step:16847 [D loss: 0.280554, acc: 94.53%] [G loss: 3.054980]\n",
      "epoch:21 step:16848 [D loss: 0.787346, acc: 38.28%] [G loss: 2.622562]\n",
      "epoch:21 step:16849 [D loss: 0.759534, acc: 52.34%] [G loss: 2.519757]\n",
      "epoch:21 step:16850 [D loss: 0.188757, acc: 96.09%] [G loss: 2.325342]\n",
      "epoch:21 step:16851 [D loss: 0.235527, acc: 98.44%] [G loss: 2.428950]\n",
      "epoch:21 step:16852 [D loss: 0.259911, acc: 98.44%] [G loss: 2.473474]\n",
      "epoch:21 step:16853 [D loss: 0.554703, acc: 67.97%] [G loss: 2.518566]\n",
      "epoch:21 step:16854 [D loss: 0.609733, acc: 64.06%] [G loss: 2.179483]\n",
      "epoch:21 step:16855 [D loss: 0.397794, acc: 86.72%] [G loss: 1.905802]\n",
      "epoch:21 step:16856 [D loss: 0.535188, acc: 70.31%] [G loss: 2.212572]\n",
      "epoch:21 step:16857 [D loss: 0.622997, acc: 64.84%] [G loss: 3.318545]\n",
      "epoch:21 step:16858 [D loss: 0.837515, acc: 51.56%] [G loss: 2.447460]\n",
      "epoch:21 step:16859 [D loss: 0.252304, acc: 96.88%] [G loss: 2.100125]\n",
      "epoch:21 step:16860 [D loss: 0.306844, acc: 94.53%] [G loss: 3.185207]\n",
      "epoch:21 step:16861 [D loss: 0.620931, acc: 67.97%] [G loss: 3.375227]\n",
      "epoch:21 step:16862 [D loss: 0.163292, acc: 100.00%] [G loss: 3.200113]\n",
      "epoch:21 step:16863 [D loss: 0.282423, acc: 98.44%] [G loss: 2.693542]\n",
      "epoch:21 step:16864 [D loss: 0.479707, acc: 76.56%] [G loss: 3.774389]\n",
      "epoch:21 step:16865 [D loss: 0.442096, acc: 81.25%] [G loss: 3.019279]\n",
      "epoch:21 step:16866 [D loss: 0.623129, acc: 67.19%] [G loss: 2.900781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16867 [D loss: 0.528189, acc: 67.97%] [G loss: 2.886383]\n",
      "epoch:21 step:16868 [D loss: 0.493482, acc: 71.09%] [G loss: 2.334836]\n",
      "epoch:21 step:16869 [D loss: 0.853532, acc: 38.28%] [G loss: 1.986862]\n",
      "epoch:21 step:16870 [D loss: 0.242506, acc: 100.00%] [G loss: 2.378480]\n",
      "epoch:21 step:16871 [D loss: 0.358390, acc: 85.16%] [G loss: 2.978536]\n",
      "epoch:21 step:16872 [D loss: 1.093630, acc: 17.19%] [G loss: 2.244062]\n",
      "epoch:21 step:16873 [D loss: 0.277117, acc: 97.66%] [G loss: 2.413155]\n",
      "epoch:21 step:16874 [D loss: 0.839340, acc: 52.34%] [G loss: 2.715036]\n",
      "epoch:21 step:16875 [D loss: 0.676214, acc: 60.16%] [G loss: 1.900788]\n",
      "epoch:21 step:16876 [D loss: 0.364939, acc: 91.41%] [G loss: 2.995717]\n",
      "epoch:21 step:16877 [D loss: 0.194907, acc: 97.66%] [G loss: 2.558118]\n",
      "epoch:21 step:16878 [D loss: 0.608991, acc: 64.84%] [G loss: 2.590416]\n",
      "epoch:21 step:16879 [D loss: 0.454782, acc: 82.03%] [G loss: 2.641173]\n",
      "epoch:21 step:16880 [D loss: 0.643254, acc: 57.03%] [G loss: 2.547879]\n",
      "epoch:21 step:16881 [D loss: 0.595914, acc: 67.97%] [G loss: 2.775669]\n",
      "epoch:21 step:16882 [D loss: 0.331264, acc: 93.75%] [G loss: 2.896942]\n",
      "epoch:21 step:16883 [D loss: 0.468722, acc: 84.38%] [G loss: 2.131229]\n",
      "epoch:21 step:16884 [D loss: 0.720766, acc: 53.91%] [G loss: 2.388860]\n",
      "epoch:21 step:16885 [D loss: 0.519011, acc: 75.78%] [G loss: 2.209799]\n",
      "epoch:21 step:16886 [D loss: 0.736252, acc: 50.78%] [G loss: 1.991695]\n",
      "epoch:21 step:16887 [D loss: 0.576985, acc: 65.62%] [G loss: 3.118380]\n",
      "epoch:21 step:16888 [D loss: 0.869673, acc: 49.22%] [G loss: 2.347416]\n",
      "epoch:21 step:16889 [D loss: 0.531421, acc: 64.06%] [G loss: 2.638852]\n",
      "epoch:21 step:16890 [D loss: 0.538399, acc: 76.56%] [G loss: 2.679263]\n",
      "epoch:21 step:16891 [D loss: 0.484658, acc: 82.03%] [G loss: 2.364517]\n",
      "epoch:21 step:16892 [D loss: 1.029590, acc: 47.66%] [G loss: 1.931869]\n",
      "epoch:21 step:16893 [D loss: 0.290281, acc: 97.66%] [G loss: 2.435914]\n",
      "epoch:21 step:16894 [D loss: 0.515096, acc: 77.34%] [G loss: 2.453822]\n",
      "epoch:21 step:16895 [D loss: 0.807919, acc: 52.34%] [G loss: 1.975700]\n",
      "epoch:21 step:16896 [D loss: 0.461442, acc: 79.69%] [G loss: 2.098504]\n",
      "epoch:21 step:16897 [D loss: 0.647730, acc: 60.16%] [G loss: 2.118029]\n",
      "epoch:21 step:16898 [D loss: 0.360036, acc: 91.41%] [G loss: 2.713600]\n",
      "epoch:21 step:16899 [D loss: 0.496172, acc: 78.91%] [G loss: 2.860376]\n",
      "epoch:21 step:16900 [D loss: 0.308699, acc: 95.31%] [G loss: 3.485464]\n",
      "epoch:21 step:16901 [D loss: 0.925287, acc: 24.22%] [G loss: 1.392819]\n",
      "epoch:21 step:16902 [D loss: 0.483523, acc: 73.44%] [G loss: 2.946985]\n",
      "epoch:21 step:16903 [D loss: 0.692643, acc: 58.59%] [G loss: 2.617218]\n",
      "epoch:21 step:16904 [D loss: 0.370662, acc: 94.53%] [G loss: 2.611906]\n",
      "epoch:21 step:16905 [D loss: 0.520368, acc: 82.03%] [G loss: 2.731241]\n",
      "epoch:21 step:16906 [D loss: 0.802677, acc: 35.16%] [G loss: 2.095390]\n",
      "epoch:21 step:16907 [D loss: 0.499154, acc: 82.81%] [G loss: 2.760364]\n",
      "epoch:21 step:16908 [D loss: 0.457744, acc: 83.59%] [G loss: 2.130219]\n",
      "epoch:21 step:16909 [D loss: 0.503681, acc: 77.34%] [G loss: 2.442153]\n",
      "epoch:21 step:16910 [D loss: 0.171486, acc: 100.00%] [G loss: 3.644821]\n",
      "epoch:21 step:16911 [D loss: 0.358051, acc: 92.97%] [G loss: 2.942825]\n",
      "epoch:21 step:16912 [D loss: 0.597653, acc: 63.28%] [G loss: 3.886041]\n",
      "epoch:21 step:16913 [D loss: 0.594606, acc: 71.88%] [G loss: 2.542744]\n",
      "epoch:21 step:16914 [D loss: 0.745107, acc: 55.47%] [G loss: 3.288832]\n",
      "epoch:21 step:16915 [D loss: 0.655478, acc: 58.59%] [G loss: 2.755862]\n",
      "epoch:21 step:16916 [D loss: 0.268335, acc: 98.44%] [G loss: 1.626292]\n",
      "epoch:21 step:16917 [D loss: 0.717490, acc: 52.34%] [G loss: 2.507938]\n",
      "epoch:21 step:16918 [D loss: 0.416242, acc: 87.50%] [G loss: 4.411664]\n",
      "epoch:21 step:16919 [D loss: 0.634157, acc: 67.19%] [G loss: 2.184242]\n",
      "epoch:21 step:16920 [D loss: 0.644527, acc: 66.41%] [G loss: 2.867945]\n",
      "epoch:21 step:16921 [D loss: 0.291603, acc: 92.97%] [G loss: 3.366056]\n",
      "epoch:21 step:16922 [D loss: 0.311931, acc: 92.19%] [G loss: 3.306489]\n",
      "epoch:21 step:16923 [D loss: 1.242912, acc: 22.66%] [G loss: 2.168328]\n",
      "epoch:21 step:16924 [D loss: 0.773649, acc: 46.88%] [G loss: 2.101504]\n",
      "epoch:21 step:16925 [D loss: 0.498810, acc: 82.81%] [G loss: 2.758442]\n",
      "epoch:21 step:16926 [D loss: 0.591756, acc: 58.59%] [G loss: 2.136217]\n",
      "epoch:21 step:16927 [D loss: 0.792925, acc: 48.44%] [G loss: 2.934038]\n",
      "epoch:21 step:16928 [D loss: 0.546742, acc: 67.97%] [G loss: 2.363194]\n",
      "epoch:21 step:16929 [D loss: 0.483557, acc: 75.78%] [G loss: 1.814360]\n",
      "epoch:21 step:16930 [D loss: 0.631461, acc: 56.25%] [G loss: 2.961442]\n",
      "epoch:21 step:16931 [D loss: 0.858960, acc: 36.72%] [G loss: 2.994714]\n",
      "epoch:21 step:16932 [D loss: 0.740256, acc: 50.78%] [G loss: 2.105499]\n",
      "epoch:21 step:16933 [D loss: 0.682175, acc: 60.94%] [G loss: 2.071042]\n",
      "epoch:21 step:16934 [D loss: 1.125327, acc: 46.88%] [G loss: 1.910870]\n",
      "epoch:21 step:16935 [D loss: 0.507663, acc: 75.00%] [G loss: 3.047802]\n",
      "epoch:21 step:16936 [D loss: 0.467958, acc: 82.81%] [G loss: 2.643128]\n",
      "epoch:21 step:16937 [D loss: 0.415437, acc: 80.47%] [G loss: 3.326792]\n",
      "epoch:21 step:16938 [D loss: 0.245632, acc: 100.00%] [G loss: 2.383066]\n",
      "epoch:21 step:16939 [D loss: 0.447614, acc: 82.03%] [G loss: 3.049684]\n",
      "epoch:21 step:16940 [D loss: 0.305389, acc: 96.88%] [G loss: 3.240740]\n",
      "epoch:21 step:16941 [D loss: 0.292549, acc: 97.66%] [G loss: 4.262879]\n",
      "epoch:21 step:16942 [D loss: 0.456084, acc: 83.59%] [G loss: 3.160985]\n",
      "epoch:21 step:16943 [D loss: 0.393985, acc: 93.75%] [G loss: 3.071563]\n",
      "epoch:21 step:16944 [D loss: 0.513311, acc: 72.66%] [G loss: 2.415055]\n",
      "epoch:21 step:16945 [D loss: 0.526748, acc: 71.09%] [G loss: 2.722169]\n",
      "epoch:21 step:16946 [D loss: 0.731471, acc: 50.00%] [G loss: 2.204725]\n",
      "epoch:21 step:16947 [D loss: 0.467761, acc: 82.81%] [G loss: 2.284193]\n",
      "epoch:21 step:16948 [D loss: 0.693063, acc: 53.91%] [G loss: 3.098456]\n",
      "epoch:21 step:16949 [D loss: 0.427902, acc: 85.94%] [G loss: 1.992313]\n",
      "epoch:21 step:16950 [D loss: 0.635571, acc: 64.06%] [G loss: 2.910960]\n",
      "epoch:21 step:16951 [D loss: 0.621508, acc: 57.03%] [G loss: 3.255756]\n",
      "epoch:21 step:16952 [D loss: 0.290700, acc: 96.09%] [G loss: 2.670989]\n",
      "epoch:21 step:16953 [D loss: 1.111933, acc: 43.75%] [G loss: 1.699138]\n",
      "epoch:21 step:16954 [D loss: 0.750297, acc: 54.69%] [G loss: 2.020967]\n",
      "epoch:21 step:16955 [D loss: 0.352900, acc: 96.09%] [G loss: 2.443957]\n",
      "epoch:21 step:16956 [D loss: 0.416209, acc: 96.09%] [G loss: 2.578635]\n",
      "epoch:21 step:16957 [D loss: 0.456163, acc: 86.72%] [G loss: 2.796209]\n",
      "epoch:21 step:16958 [D loss: 0.772988, acc: 46.88%] [G loss: 2.748982]\n",
      "epoch:21 step:16959 [D loss: 0.811258, acc: 51.56%] [G loss: 2.400547]\n",
      "epoch:21 step:16960 [D loss: 0.522077, acc: 81.25%] [G loss: 2.358809]\n",
      "epoch:21 step:16961 [D loss: 0.883557, acc: 36.72%] [G loss: 2.253623]\n",
      "epoch:21 step:16962 [D loss: 0.277101, acc: 97.66%] [G loss: 2.514108]\n",
      "epoch:21 step:16963 [D loss: 0.469330, acc: 81.25%] [G loss: 2.605029]\n",
      "epoch:21 step:16964 [D loss: 0.605511, acc: 64.06%] [G loss: 2.094337]\n",
      "epoch:21 step:16965 [D loss: 0.263578, acc: 96.88%] [G loss: 3.245659]\n",
      "epoch:21 step:16966 [D loss: 0.866740, acc: 37.50%] [G loss: 1.851214]\n",
      "epoch:21 step:16967 [D loss: 0.218476, acc: 99.22%] [G loss: 3.155128]\n",
      "epoch:21 step:16968 [D loss: 0.837193, acc: 47.66%] [G loss: 3.012080]\n",
      "epoch:21 step:16969 [D loss: 0.438571, acc: 84.38%] [G loss: 2.439975]\n",
      "epoch:21 step:16970 [D loss: 0.166320, acc: 100.00%] [G loss: 2.654067]\n",
      "epoch:21 step:16971 [D loss: 0.352638, acc: 82.81%] [G loss: 2.332249]\n",
      "epoch:21 step:16972 [D loss: 0.569347, acc: 68.75%] [G loss: 2.485407]\n",
      "epoch:21 step:16973 [D loss: 0.402224, acc: 89.84%] [G loss: 1.893804]\n",
      "epoch:21 step:16974 [D loss: 0.455794, acc: 83.59%] [G loss: 3.491918]\n",
      "epoch:21 step:16975 [D loss: 0.867673, acc: 37.50%] [G loss: 2.553182]\n",
      "epoch:21 step:16976 [D loss: 0.605813, acc: 65.62%] [G loss: 2.631819]\n",
      "epoch:21 step:16977 [D loss: 0.245679, acc: 98.44%] [G loss: 2.704228]\n",
      "epoch:21 step:16978 [D loss: 0.212036, acc: 100.00%] [G loss: 2.198688]\n",
      "epoch:21 step:16979 [D loss: 0.586561, acc: 67.97%] [G loss: 3.181588]\n",
      "epoch:21 step:16980 [D loss: 0.402556, acc: 78.91%] [G loss: 2.877304]\n",
      "epoch:21 step:16981 [D loss: 0.507332, acc: 69.53%] [G loss: 3.207075]\n",
      "epoch:21 step:16982 [D loss: 0.346370, acc: 96.09%] [G loss: 2.496915]\n",
      "epoch:21 step:16983 [D loss: 0.501358, acc: 73.44%] [G loss: 3.400950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16984 [D loss: 0.248408, acc: 93.75%] [G loss: 4.122818]\n",
      "epoch:21 step:16985 [D loss: 1.132747, acc: 21.88%] [G loss: 1.722678]\n",
      "epoch:21 step:16986 [D loss: 0.328158, acc: 96.09%] [G loss: 2.905098]\n",
      "epoch:21 step:16987 [D loss: 0.762617, acc: 53.12%] [G loss: 1.765862]\n",
      "epoch:21 step:16988 [D loss: 0.347371, acc: 89.06%] [G loss: 3.065390]\n",
      "epoch:21 step:16989 [D loss: 0.452626, acc: 85.16%] [G loss: 3.087475]\n",
      "epoch:21 step:16990 [D loss: 0.459214, acc: 66.41%] [G loss: 2.604967]\n",
      "epoch:21 step:16991 [D loss: 0.645896, acc: 65.62%] [G loss: 2.220374]\n",
      "epoch:21 step:16992 [D loss: 0.389200, acc: 90.62%] [G loss: 3.224637]\n",
      "epoch:21 step:16993 [D loss: 0.355075, acc: 83.59%] [G loss: 2.159339]\n",
      "epoch:21 step:16994 [D loss: 0.599542, acc: 57.81%] [G loss: 3.552385]\n",
      "epoch:21 step:16995 [D loss: 0.847342, acc: 53.12%] [G loss: 2.460745]\n",
      "epoch:21 step:16996 [D loss: 0.536464, acc: 71.09%] [G loss: 2.157779]\n",
      "epoch:21 step:16997 [D loss: 0.984273, acc: 33.59%] [G loss: 2.716383]\n",
      "epoch:21 step:16998 [D loss: 0.236844, acc: 98.44%] [G loss: 2.505857]\n",
      "epoch:21 step:16999 [D loss: 0.385364, acc: 91.41%] [G loss: 3.078533]\n",
      "epoch:21 step:17000 [D loss: 0.369921, acc: 92.97%] [G loss: 2.430738]\n",
      "epoch:21 step:17001 [D loss: 0.298985, acc: 97.66%] [G loss: 2.444324]\n",
      "epoch:21 step:17002 [D loss: 0.476646, acc: 82.81%] [G loss: 1.993110]\n",
      "epoch:21 step:17003 [D loss: 0.538784, acc: 75.00%] [G loss: 1.911131]\n",
      "epoch:21 step:17004 [D loss: 1.099087, acc: 21.88%] [G loss: 2.194980]\n",
      "epoch:21 step:17005 [D loss: 0.636097, acc: 64.84%] [G loss: 3.000343]\n",
      "epoch:21 step:17006 [D loss: 0.436653, acc: 78.91%] [G loss: 2.912244]\n",
      "epoch:21 step:17007 [D loss: 0.760269, acc: 53.12%] [G loss: 2.507449]\n",
      "epoch:21 step:17008 [D loss: 0.705462, acc: 53.91%] [G loss: 2.748488]\n",
      "epoch:21 step:17009 [D loss: 0.365246, acc: 86.72%] [G loss: 2.920704]\n",
      "epoch:21 step:17010 [D loss: 0.472848, acc: 81.25%] [G loss: 3.332076]\n",
      "epoch:21 step:17011 [D loss: 0.655005, acc: 56.25%] [G loss: 1.338741]\n",
      "epoch:21 step:17012 [D loss: 0.393454, acc: 79.69%] [G loss: 3.331617]\n",
      "epoch:21 step:17013 [D loss: 0.902586, acc: 37.50%] [G loss: 2.504234]\n",
      "epoch:21 step:17014 [D loss: 0.592064, acc: 74.22%] [G loss: 4.028730]\n",
      "epoch:21 step:17015 [D loss: 0.364201, acc: 90.62%] [G loss: 2.431029]\n",
      "epoch:21 step:17016 [D loss: 0.479046, acc: 75.00%] [G loss: 2.445468]\n",
      "epoch:21 step:17017 [D loss: 0.453316, acc: 83.59%] [G loss: 2.138941]\n",
      "epoch:21 step:17018 [D loss: 0.694807, acc: 59.38%] [G loss: 2.535475]\n",
      "epoch:21 step:17019 [D loss: 1.232365, acc: 9.38%] [G loss: 1.977846]\n",
      "epoch:21 step:17020 [D loss: 0.760733, acc: 44.53%] [G loss: 2.979094]\n",
      "epoch:21 step:17021 [D loss: 0.596909, acc: 62.50%] [G loss: 1.970960]\n",
      "epoch:21 step:17022 [D loss: 0.251132, acc: 98.44%] [G loss: 3.799664]\n",
      "epoch:21 step:17023 [D loss: 1.171508, acc: 28.91%] [G loss: 1.952766]\n",
      "epoch:21 step:17024 [D loss: 0.483711, acc: 77.34%] [G loss: 2.074496]\n",
      "epoch:21 step:17025 [D loss: 0.482132, acc: 83.59%] [G loss: 2.704855]\n",
      "epoch:21 step:17026 [D loss: 0.673498, acc: 58.59%] [G loss: 3.631483]\n",
      "epoch:21 step:17027 [D loss: 0.627827, acc: 64.84%] [G loss: 2.283361]\n",
      "epoch:21 step:17028 [D loss: 0.554723, acc: 69.53%] [G loss: 2.628812]\n",
      "epoch:21 step:17029 [D loss: 0.742328, acc: 51.56%] [G loss: 2.781178]\n",
      "epoch:21 step:17030 [D loss: 0.652955, acc: 59.38%] [G loss: 1.607999]\n",
      "epoch:21 step:17031 [D loss: 0.618865, acc: 62.50%] [G loss: 2.104625]\n",
      "epoch:21 step:17032 [D loss: 0.480238, acc: 82.03%] [G loss: 3.092969]\n",
      "epoch:21 step:17033 [D loss: 0.895746, acc: 46.09%] [G loss: 2.708834]\n",
      "epoch:21 step:17034 [D loss: 0.272241, acc: 96.09%] [G loss: 4.148825]\n",
      "epoch:21 step:17035 [D loss: 0.697610, acc: 52.34%] [G loss: 2.014112]\n",
      "epoch:21 step:17036 [D loss: 0.531518, acc: 77.34%] [G loss: 2.546025]\n",
      "epoch:21 step:17037 [D loss: 0.546353, acc: 64.06%] [G loss: 2.628024]\n",
      "epoch:21 step:17038 [D loss: 0.646173, acc: 56.25%] [G loss: 3.488241]\n",
      "epoch:21 step:17039 [D loss: 0.537485, acc: 78.91%] [G loss: 2.160083]\n",
      "epoch:21 step:17040 [D loss: 0.870978, acc: 40.62%] [G loss: 2.512449]\n",
      "epoch:21 step:17041 [D loss: 0.232273, acc: 100.00%] [G loss: 3.246032]\n",
      "epoch:21 step:17042 [D loss: 0.316689, acc: 96.88%] [G loss: 3.415696]\n",
      "epoch:21 step:17043 [D loss: 0.623087, acc: 68.75%] [G loss: 1.711060]\n",
      "epoch:21 step:17044 [D loss: 0.549896, acc: 74.22%] [G loss: 1.579123]\n",
      "epoch:21 step:17045 [D loss: 0.272435, acc: 97.66%] [G loss: 3.878412]\n",
      "epoch:21 step:17046 [D loss: 0.534066, acc: 64.84%] [G loss: 3.491340]\n",
      "epoch:21 step:17047 [D loss: 0.510417, acc: 75.78%] [G loss: 2.526593]\n",
      "epoch:21 step:17048 [D loss: 0.340925, acc: 91.41%] [G loss: 2.736050]\n",
      "epoch:21 step:17049 [D loss: 0.602352, acc: 62.50%] [G loss: 2.068504]\n",
      "epoch:21 step:17050 [D loss: 0.616825, acc: 65.62%] [G loss: 2.081781]\n",
      "epoch:21 step:17051 [D loss: 0.305420, acc: 97.66%] [G loss: 2.414469]\n",
      "epoch:21 step:17052 [D loss: 0.452976, acc: 88.28%] [G loss: 3.182337]\n",
      "epoch:21 step:17053 [D loss: 0.848660, acc: 44.53%] [G loss: 3.233324]\n",
      "epoch:21 step:17054 [D loss: 0.434993, acc: 86.72%] [G loss: 2.945891]\n",
      "epoch:21 step:17055 [D loss: 0.723691, acc: 51.56%] [G loss: 2.937129]\n",
      "epoch:21 step:17056 [D loss: 0.499168, acc: 81.25%] [G loss: 3.004541]\n",
      "epoch:21 step:17057 [D loss: 0.638037, acc: 68.75%] [G loss: 2.137149]\n",
      "epoch:21 step:17058 [D loss: 0.413888, acc: 82.81%] [G loss: 2.913747]\n",
      "epoch:21 step:17059 [D loss: 0.700448, acc: 57.81%] [G loss: 3.558965]\n",
      "epoch:21 step:17060 [D loss: 0.552382, acc: 71.88%] [G loss: 2.715421]\n",
      "epoch:21 step:17061 [D loss: 0.287658, acc: 96.88%] [G loss: 1.858709]\n",
      "epoch:21 step:17062 [D loss: 0.353197, acc: 77.34%] [G loss: 2.391416]\n",
      "epoch:21 step:17063 [D loss: 0.978597, acc: 47.66%] [G loss: 1.746859]\n",
      "epoch:21 step:17064 [D loss: 0.141939, acc: 99.22%] [G loss: 2.646521]\n",
      "epoch:21 step:17065 [D loss: 0.527736, acc: 71.88%] [G loss: 3.060081]\n",
      "epoch:21 step:17066 [D loss: 0.489104, acc: 84.38%] [G loss: 2.019747]\n",
      "epoch:21 step:17067 [D loss: 0.344458, acc: 90.62%] [G loss: 2.547143]\n",
      "epoch:21 step:17068 [D loss: 0.232192, acc: 96.88%] [G loss: 2.900405]\n",
      "epoch:21 step:17069 [D loss: 0.561388, acc: 75.78%] [G loss: 2.694103]\n",
      "epoch:21 step:17070 [D loss: 0.538384, acc: 58.59%] [G loss: 4.494128]\n",
      "epoch:21 step:17071 [D loss: 0.447130, acc: 85.94%] [G loss: 1.773728]\n",
      "epoch:21 step:17072 [D loss: 0.381547, acc: 90.62%] [G loss: 3.174239]\n",
      "epoch:21 step:17073 [D loss: 0.870753, acc: 40.62%] [G loss: 1.602169]\n",
      "epoch:21 step:17074 [D loss: 0.633035, acc: 64.06%] [G loss: 2.183592]\n",
      "epoch:21 step:17075 [D loss: 0.335160, acc: 96.88%] [G loss: 2.745268]\n",
      "epoch:21 step:17076 [D loss: 0.322147, acc: 96.09%] [G loss: 2.644445]\n",
      "epoch:21 step:17077 [D loss: 0.670630, acc: 56.25%] [G loss: 2.816476]\n",
      "epoch:21 step:17078 [D loss: 0.744725, acc: 54.69%] [G loss: 2.427060]\n",
      "epoch:21 step:17079 [D loss: 0.388270, acc: 90.62%] [G loss: 2.856758]\n",
      "epoch:21 step:17080 [D loss: 0.569612, acc: 62.50%] [G loss: 2.672323]\n",
      "epoch:21 step:17081 [D loss: 0.567506, acc: 61.72%] [G loss: 2.910527]\n",
      "epoch:21 step:17082 [D loss: 0.383457, acc: 95.31%] [G loss: 3.107014]\n",
      "epoch:21 step:17083 [D loss: 0.556244, acc: 62.50%] [G loss: 3.625463]\n",
      "epoch:21 step:17084 [D loss: 0.321085, acc: 89.84%] [G loss: 3.155799]\n",
      "epoch:21 step:17085 [D loss: 0.819250, acc: 39.06%] [G loss: 2.443135]\n",
      "epoch:21 step:17086 [D loss: 0.672113, acc: 59.38%] [G loss: 2.279101]\n",
      "epoch:21 step:17087 [D loss: 0.893463, acc: 29.69%] [G loss: 2.678562]\n",
      "epoch:21 step:17088 [D loss: 0.513627, acc: 78.12%] [G loss: 2.218687]\n",
      "epoch:21 step:17089 [D loss: 0.887850, acc: 33.59%] [G loss: 2.636222]\n",
      "epoch:21 step:17090 [D loss: 0.743942, acc: 50.78%] [G loss: 2.481383]\n",
      "epoch:21 step:17091 [D loss: 0.366789, acc: 94.53%] [G loss: 3.324707]\n",
      "epoch:21 step:17092 [D loss: 0.623734, acc: 60.16%] [G loss: 2.888839]\n",
      "epoch:21 step:17093 [D loss: 0.662487, acc: 62.50%] [G loss: 2.707563]\n",
      "epoch:21 step:17094 [D loss: 0.538680, acc: 67.19%] [G loss: 3.044967]\n",
      "epoch:21 step:17095 [D loss: 0.608097, acc: 68.75%] [G loss: 2.338146]\n",
      "epoch:21 step:17096 [D loss: 0.566923, acc: 74.22%] [G loss: 2.596419]\n",
      "epoch:21 step:17097 [D loss: 0.479331, acc: 83.59%] [G loss: 2.480906]\n",
      "epoch:21 step:17098 [D loss: 0.914952, acc: 50.00%] [G loss: 2.316136]\n",
      "epoch:21 step:17099 [D loss: 0.465027, acc: 88.28%] [G loss: 1.909015]\n",
      "epoch:21 step:17100 [D loss: 1.006835, acc: 46.88%] [G loss: 1.827817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17101 [D loss: 0.571105, acc: 72.66%] [G loss: 3.142153]\n",
      "epoch:21 step:17102 [D loss: 0.614191, acc: 67.97%] [G loss: 1.904442]\n",
      "epoch:21 step:17103 [D loss: 0.260285, acc: 98.44%] [G loss: 1.806330]\n",
      "epoch:21 step:17104 [D loss: 0.339558, acc: 88.28%] [G loss: 2.867489]\n",
      "epoch:21 step:17105 [D loss: 0.762061, acc: 48.44%] [G loss: 3.502516]\n",
      "epoch:21 step:17106 [D loss: 0.425921, acc: 87.50%] [G loss: 2.266005]\n",
      "epoch:21 step:17107 [D loss: 0.531067, acc: 68.75%] [G loss: 2.359965]\n",
      "epoch:21 step:17108 [D loss: 0.632680, acc: 61.72%] [G loss: 2.827457]\n",
      "epoch:21 step:17109 [D loss: 0.596583, acc: 64.06%] [G loss: 2.746010]\n",
      "epoch:21 step:17110 [D loss: 0.570749, acc: 74.22%] [G loss: 1.482074]\n",
      "epoch:21 step:17111 [D loss: 0.303627, acc: 92.97%] [G loss: 1.341599]\n",
      "epoch:21 step:17112 [D loss: 0.414017, acc: 92.19%] [G loss: 2.438909]\n",
      "epoch:21 step:17113 [D loss: 0.944449, acc: 23.44%] [G loss: 1.523747]\n",
      "epoch:21 step:17114 [D loss: 0.409634, acc: 82.03%] [G loss: 2.935286]\n",
      "epoch:21 step:17115 [D loss: 0.356333, acc: 81.25%] [G loss: 2.025367]\n",
      "epoch:21 step:17116 [D loss: 0.480343, acc: 76.56%] [G loss: 3.162230]\n",
      "epoch:21 step:17117 [D loss: 0.645642, acc: 65.62%] [G loss: 3.358474]\n",
      "epoch:21 step:17118 [D loss: 0.289456, acc: 96.88%] [G loss: 3.714963]\n",
      "epoch:21 step:17119 [D loss: 0.610942, acc: 59.38%] [G loss: 3.954793]\n",
      "epoch:21 step:17120 [D loss: 0.757412, acc: 51.56%] [G loss: 3.705131]\n",
      "epoch:21 step:17121 [D loss: 0.267291, acc: 96.88%] [G loss: 4.783440]\n",
      "epoch:21 step:17122 [D loss: 0.341821, acc: 97.66%] [G loss: 2.487488]\n",
      "epoch:21 step:17123 [D loss: 0.447211, acc: 78.12%] [G loss: 2.475302]\n",
      "epoch:21 step:17124 [D loss: 0.413932, acc: 82.03%] [G loss: 2.798354]\n",
      "epoch:21 step:17125 [D loss: 0.756966, acc: 52.34%] [G loss: 2.350604]\n",
      "epoch:21 step:17126 [D loss: 0.728772, acc: 55.47%] [G loss: 1.922346]\n",
      "epoch:21 step:17127 [D loss: 0.642875, acc: 62.50%] [G loss: 2.530784]\n",
      "epoch:21 step:17128 [D loss: 0.488722, acc: 85.16%] [G loss: 1.853233]\n",
      "epoch:21 step:17129 [D loss: 0.532961, acc: 76.56%] [G loss: 2.931115]\n",
      "epoch:21 step:17130 [D loss: 0.374424, acc: 87.50%] [G loss: 2.200741]\n",
      "epoch:21 step:17131 [D loss: 1.109068, acc: 34.38%] [G loss: 2.334611]\n",
      "epoch:21 step:17132 [D loss: 0.303730, acc: 91.41%] [G loss: 2.137330]\n",
      "epoch:21 step:17133 [D loss: 0.457635, acc: 80.47%] [G loss: 2.941020]\n",
      "epoch:21 step:17134 [D loss: 0.782037, acc: 46.09%] [G loss: 2.062581]\n",
      "epoch:21 step:17135 [D loss: 0.830668, acc: 33.59%] [G loss: 2.896440]\n",
      "epoch:21 step:17136 [D loss: 0.657641, acc: 57.81%] [G loss: 3.304289]\n",
      "epoch:21 step:17137 [D loss: 0.283640, acc: 94.53%] [G loss: 2.780608]\n",
      "epoch:21 step:17138 [D loss: 0.283067, acc: 97.66%] [G loss: 3.831231]\n",
      "epoch:21 step:17139 [D loss: 0.679034, acc: 57.81%] [G loss: 2.656333]\n",
      "epoch:21 step:17140 [D loss: 0.822721, acc: 35.94%] [G loss: 3.303517]\n",
      "epoch:21 step:17141 [D loss: 0.232065, acc: 96.88%] [G loss: 3.667747]\n",
      "epoch:21 step:17142 [D loss: 0.521216, acc: 65.62%] [G loss: 2.819782]\n",
      "epoch:21 step:17143 [D loss: 0.749272, acc: 47.66%] [G loss: 3.189417]\n",
      "epoch:21 step:17144 [D loss: 0.503935, acc: 83.59%] [G loss: 2.911607]\n",
      "epoch:21 step:17145 [D loss: 0.998995, acc: 27.34%] [G loss: 1.998938]\n",
      "epoch:21 step:17146 [D loss: 0.097978, acc: 100.00%] [G loss: 3.319008]\n",
      "epoch:21 step:17147 [D loss: 0.614298, acc: 61.72%] [G loss: 2.008955]\n",
      "epoch:21 step:17148 [D loss: 0.680887, acc: 57.03%] [G loss: 2.752610]\n",
      "epoch:21 step:17149 [D loss: 0.468434, acc: 71.09%] [G loss: 2.453785]\n",
      "epoch:21 step:17150 [D loss: 0.343599, acc: 95.31%] [G loss: 2.085839]\n",
      "epoch:21 step:17151 [D loss: 0.678036, acc: 56.25%] [G loss: 2.941313]\n",
      "epoch:21 step:17152 [D loss: 0.537616, acc: 58.59%] [G loss: 2.969433]\n",
      "epoch:21 step:17153 [D loss: 0.348355, acc: 93.75%] [G loss: 2.733563]\n",
      "epoch:21 step:17154 [D loss: 0.337119, acc: 95.31%] [G loss: 3.455557]\n",
      "epoch:21 step:17155 [D loss: 0.377383, acc: 92.97%] [G loss: 2.433108]\n",
      "epoch:21 step:17156 [D loss: 0.614083, acc: 53.12%] [G loss: 2.571673]\n",
      "epoch:21 step:17157 [D loss: 0.380246, acc: 86.72%] [G loss: 2.447480]\n",
      "epoch:21 step:17158 [D loss: 0.807314, acc: 51.56%] [G loss: 2.082193]\n",
      "epoch:21 step:17159 [D loss: 0.915463, acc: 29.69%] [G loss: 1.911353]\n",
      "epoch:21 step:17160 [D loss: 0.737999, acc: 51.56%] [G loss: 2.058324]\n",
      "epoch:21 step:17161 [D loss: 0.371774, acc: 82.03%] [G loss: 3.831622]\n",
      "epoch:21 step:17162 [D loss: 0.588247, acc: 67.19%] [G loss: 2.230776]\n",
      "epoch:21 step:17163 [D loss: 0.378985, acc: 89.84%] [G loss: 3.235733]\n",
      "epoch:21 step:17164 [D loss: 0.982964, acc: 23.44%] [G loss: 2.449036]\n",
      "epoch:21 step:17165 [D loss: 0.601586, acc: 65.62%] [G loss: 2.347942]\n",
      "epoch:21 step:17166 [D loss: 0.424792, acc: 79.69%] [G loss: 2.294246]\n",
      "epoch:21 step:17167 [D loss: 0.359355, acc: 90.62%] [G loss: 3.170330]\n",
      "epoch:21 step:17168 [D loss: 0.617320, acc: 55.47%] [G loss: 2.972917]\n",
      "epoch:21 step:17169 [D loss: 0.457287, acc: 86.72%] [G loss: 2.758410]\n",
      "epoch:21 step:17170 [D loss: 0.466188, acc: 67.19%] [G loss: 2.282149]\n",
      "epoch:21 step:17171 [D loss: 0.438675, acc: 87.50%] [G loss: 3.185286]\n",
      "epoch:21 step:17172 [D loss: 0.361285, acc: 86.72%] [G loss: 3.407214]\n",
      "epoch:21 step:17173 [D loss: 0.497524, acc: 72.66%] [G loss: 2.645366]\n",
      "epoch:21 step:17174 [D loss: 0.237766, acc: 97.66%] [G loss: 3.232464]\n",
      "epoch:21 step:17175 [D loss: 0.520643, acc: 78.12%] [G loss: 2.940305]\n",
      "epoch:21 step:17176 [D loss: 0.662879, acc: 57.03%] [G loss: 2.856447]\n",
      "epoch:21 step:17177 [D loss: 0.360455, acc: 90.62%] [G loss: 2.125072]\n",
      "epoch:21 step:17178 [D loss: 0.636047, acc: 61.72%] [G loss: 2.155603]\n",
      "epoch:21 step:17179 [D loss: 0.806779, acc: 55.47%] [G loss: 3.027887]\n",
      "epoch:21 step:17180 [D loss: 0.464416, acc: 75.78%] [G loss: 2.210431]\n",
      "epoch:21 step:17181 [D loss: 0.886979, acc: 32.81%] [G loss: 2.857741]\n",
      "epoch:21 step:17182 [D loss: 0.703373, acc: 57.03%] [G loss: 1.836544]\n",
      "epoch:22 step:17183 [D loss: 0.588676, acc: 60.16%] [G loss: 3.244511]\n",
      "epoch:22 step:17184 [D loss: 0.376770, acc: 87.50%] [G loss: 3.149744]\n",
      "epoch:22 step:17185 [D loss: 0.583516, acc: 70.31%] [G loss: 3.057370]\n",
      "epoch:22 step:17186 [D loss: 0.808916, acc: 33.59%] [G loss: 2.108695]\n",
      "epoch:22 step:17187 [D loss: 0.458072, acc: 82.81%] [G loss: 2.931551]\n",
      "epoch:22 step:17188 [D loss: 0.334792, acc: 92.19%] [G loss: 4.217971]\n",
      "epoch:22 step:17189 [D loss: 0.733395, acc: 52.34%] [G loss: 2.084719]\n",
      "epoch:22 step:17190 [D loss: 0.499869, acc: 76.56%] [G loss: 2.024379]\n",
      "epoch:22 step:17191 [D loss: 0.511876, acc: 75.78%] [G loss: 3.199780]\n",
      "epoch:22 step:17192 [D loss: 0.582661, acc: 68.75%] [G loss: 2.709491]\n",
      "epoch:22 step:17193 [D loss: 0.634897, acc: 64.84%] [G loss: 2.890707]\n",
      "epoch:22 step:17194 [D loss: 0.779780, acc: 51.56%] [G loss: 3.097320]\n",
      "epoch:22 step:17195 [D loss: 0.438232, acc: 75.00%] [G loss: 2.863882]\n",
      "epoch:22 step:17196 [D loss: 0.412357, acc: 83.59%] [G loss: 2.680060]\n",
      "epoch:22 step:17197 [D loss: 1.138760, acc: 47.66%] [G loss: 2.017205]\n",
      "epoch:22 step:17198 [D loss: 0.713895, acc: 53.12%] [G loss: 2.135166]\n",
      "epoch:22 step:17199 [D loss: 0.619110, acc: 65.62%] [G loss: 2.384840]\n",
      "epoch:22 step:17200 [D loss: 0.352681, acc: 84.38%] [G loss: 3.845012]\n",
      "epoch:22 step:17201 [D loss: 0.604059, acc: 60.16%] [G loss: 2.498113]\n",
      "epoch:22 step:17202 [D loss: 0.739374, acc: 53.91%] [G loss: 2.752196]\n",
      "epoch:22 step:17203 [D loss: 0.888206, acc: 31.25%] [G loss: 2.385393]\n",
      "epoch:22 step:17204 [D loss: 0.598756, acc: 65.62%] [G loss: 2.729326]\n",
      "epoch:22 step:17205 [D loss: 0.683464, acc: 54.69%] [G loss: 2.625026]\n",
      "epoch:22 step:17206 [D loss: 0.734657, acc: 60.16%] [G loss: 2.445439]\n",
      "epoch:22 step:17207 [D loss: 0.608823, acc: 61.72%] [G loss: 2.416427]\n",
      "epoch:22 step:17208 [D loss: 0.349858, acc: 92.19%] [G loss: 2.847992]\n",
      "epoch:22 step:17209 [D loss: 0.371579, acc: 90.62%] [G loss: 4.154050]\n",
      "epoch:22 step:17210 [D loss: 0.965450, acc: 31.25%] [G loss: 2.483418]\n",
      "epoch:22 step:17211 [D loss: 0.296584, acc: 96.88%] [G loss: 2.408107]\n",
      "epoch:22 step:17212 [D loss: 0.287801, acc: 89.06%] [G loss: 2.619485]\n",
      "epoch:22 step:17213 [D loss: 0.488186, acc: 75.00%] [G loss: 3.572855]\n",
      "epoch:22 step:17214 [D loss: 0.578257, acc: 67.19%] [G loss: 2.291296]\n",
      "epoch:22 step:17215 [D loss: 0.864523, acc: 44.53%] [G loss: 2.301037]\n",
      "epoch:22 step:17216 [D loss: 0.430065, acc: 89.06%] [G loss: 2.932319]\n",
      "epoch:22 step:17217 [D loss: 0.663035, acc: 61.72%] [G loss: 2.494594]\n",
      "epoch:22 step:17218 [D loss: 0.399120, acc: 89.84%] [G loss: 2.289266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17219 [D loss: 0.796358, acc: 42.19%] [G loss: 1.994981]\n",
      "epoch:22 step:17220 [D loss: 0.423352, acc: 82.81%] [G loss: 2.311047]\n",
      "epoch:22 step:17221 [D loss: 0.603254, acc: 68.75%] [G loss: 1.955080]\n",
      "epoch:22 step:17222 [D loss: 0.327769, acc: 91.41%] [G loss: 3.073354]\n",
      "epoch:22 step:17223 [D loss: 0.389288, acc: 78.91%] [G loss: 3.408804]\n",
      "epoch:22 step:17224 [D loss: 0.385128, acc: 94.53%] [G loss: 3.256645]\n",
      "epoch:22 step:17225 [D loss: 1.368769, acc: 27.34%] [G loss: 1.715550]\n",
      "epoch:22 step:17226 [D loss: 0.954335, acc: 31.25%] [G loss: 1.527374]\n",
      "epoch:22 step:17227 [D loss: 0.269870, acc: 94.53%] [G loss: 2.857732]\n",
      "epoch:22 step:17228 [D loss: 0.396948, acc: 85.16%] [G loss: 3.699328]\n",
      "epoch:22 step:17229 [D loss: 0.361567, acc: 92.19%] [G loss: 2.796538]\n",
      "epoch:22 step:17230 [D loss: 0.830920, acc: 37.50%] [G loss: 2.000362]\n",
      "epoch:22 step:17231 [D loss: 0.602364, acc: 61.72%] [G loss: 2.386428]\n",
      "epoch:22 step:17232 [D loss: 0.354281, acc: 89.06%] [G loss: 2.475432]\n",
      "epoch:22 step:17233 [D loss: 0.341701, acc: 89.06%] [G loss: 2.975680]\n",
      "epoch:22 step:17234 [D loss: 0.459634, acc: 85.16%] [G loss: 3.100626]\n",
      "epoch:22 step:17235 [D loss: 0.551362, acc: 68.75%] [G loss: 2.487786]\n",
      "epoch:22 step:17236 [D loss: 0.774714, acc: 49.22%] [G loss: 2.251047]\n",
      "epoch:22 step:17237 [D loss: 0.709932, acc: 55.47%] [G loss: 2.547384]\n",
      "epoch:22 step:17238 [D loss: 1.223537, acc: 24.22%] [G loss: 2.541379]\n",
      "epoch:22 step:17239 [D loss: 0.934900, acc: 42.97%] [G loss: 1.789258]\n",
      "epoch:22 step:17240 [D loss: 0.577430, acc: 71.88%] [G loss: 2.399362]\n",
      "epoch:22 step:17241 [D loss: 0.359479, acc: 92.97%] [G loss: 2.027631]\n",
      "epoch:22 step:17242 [D loss: 0.717011, acc: 52.34%] [G loss: 2.274929]\n",
      "epoch:22 step:17243 [D loss: 0.451202, acc: 76.56%] [G loss: 2.292470]\n",
      "epoch:22 step:17244 [D loss: 0.620559, acc: 67.97%] [G loss: 2.738933]\n",
      "epoch:22 step:17245 [D loss: 0.288664, acc: 94.53%] [G loss: 2.919406]\n",
      "epoch:22 step:17246 [D loss: 0.316256, acc: 89.84%] [G loss: 2.751208]\n",
      "epoch:22 step:17247 [D loss: 0.357592, acc: 92.97%] [G loss: 2.472829]\n",
      "epoch:22 step:17248 [D loss: 0.493046, acc: 78.91%] [G loss: 2.935581]\n",
      "epoch:22 step:17249 [D loss: 0.918018, acc: 28.12%] [G loss: 1.637538]\n",
      "epoch:22 step:17250 [D loss: 0.687088, acc: 59.38%] [G loss: 2.320317]\n",
      "epoch:22 step:17251 [D loss: 0.637973, acc: 60.94%] [G loss: 2.884570]\n",
      "epoch:22 step:17252 [D loss: 0.346330, acc: 93.75%] [G loss: 2.945080]\n",
      "epoch:22 step:17253 [D loss: 0.765757, acc: 51.56%] [G loss: 2.375162]\n",
      "epoch:22 step:17254 [D loss: 0.557534, acc: 75.00%] [G loss: 2.083813]\n",
      "epoch:22 step:17255 [D loss: 0.530824, acc: 78.91%] [G loss: 2.237507]\n",
      "epoch:22 step:17256 [D loss: 0.705267, acc: 58.59%] [G loss: 2.759148]\n",
      "epoch:22 step:17257 [D loss: 0.504484, acc: 80.47%] [G loss: 2.332401]\n",
      "epoch:22 step:17258 [D loss: 0.382881, acc: 92.19%] [G loss: 2.713991]\n",
      "epoch:22 step:17259 [D loss: 0.513214, acc: 80.47%] [G loss: 2.337449]\n",
      "epoch:22 step:17260 [D loss: 0.540597, acc: 75.78%] [G loss: 3.010519]\n",
      "epoch:22 step:17261 [D loss: 0.608626, acc: 64.84%] [G loss: 2.351105]\n",
      "epoch:22 step:17262 [D loss: 0.524548, acc: 76.56%] [G loss: 3.085538]\n",
      "epoch:22 step:17263 [D loss: 0.803159, acc: 44.53%] [G loss: 2.363669]\n",
      "epoch:22 step:17264 [D loss: 0.404534, acc: 80.47%] [G loss: 3.535153]\n",
      "epoch:22 step:17265 [D loss: 0.544281, acc: 77.34%] [G loss: 3.131316]\n",
      "epoch:22 step:17266 [D loss: 0.681786, acc: 53.12%] [G loss: 2.045309]\n",
      "epoch:22 step:17267 [D loss: 0.742144, acc: 49.22%] [G loss: 2.846844]\n",
      "epoch:22 step:17268 [D loss: 0.926422, acc: 50.00%] [G loss: 2.185922]\n",
      "epoch:22 step:17269 [D loss: 0.464751, acc: 87.50%] [G loss: 2.826194]\n",
      "epoch:22 step:17270 [D loss: 0.920841, acc: 27.34%] [G loss: 2.677395]\n",
      "epoch:22 step:17271 [D loss: 0.288961, acc: 97.66%] [G loss: 2.909804]\n",
      "epoch:22 step:17272 [D loss: 0.395855, acc: 88.28%] [G loss: 1.978946]\n",
      "epoch:22 step:17273 [D loss: 0.584225, acc: 71.09%] [G loss: 3.106646]\n",
      "epoch:22 step:17274 [D loss: 0.617603, acc: 65.62%] [G loss: 2.998620]\n",
      "epoch:22 step:17275 [D loss: 0.457024, acc: 82.81%] [G loss: 2.650433]\n",
      "epoch:22 step:17276 [D loss: 0.398655, acc: 89.84%] [G loss: 2.242417]\n",
      "epoch:22 step:17277 [D loss: 0.635441, acc: 66.41%] [G loss: 2.803983]\n",
      "epoch:22 step:17278 [D loss: 0.548857, acc: 67.19%] [G loss: 2.480408]\n",
      "epoch:22 step:17279 [D loss: 0.646716, acc: 61.72%] [G loss: 2.542603]\n",
      "epoch:22 step:17280 [D loss: 0.390997, acc: 94.53%] [G loss: 2.500620]\n",
      "epoch:22 step:17281 [D loss: 0.581308, acc: 65.62%] [G loss: 2.881839]\n",
      "epoch:22 step:17282 [D loss: 0.343482, acc: 91.41%] [G loss: 2.160149]\n",
      "epoch:22 step:17283 [D loss: 1.328586, acc: 35.16%] [G loss: 1.949726]\n",
      "epoch:22 step:17284 [D loss: 0.746201, acc: 54.69%] [G loss: 2.666386]\n",
      "epoch:22 step:17285 [D loss: 0.747440, acc: 53.12%] [G loss: 1.909581]\n",
      "epoch:22 step:17286 [D loss: 0.593026, acc: 67.97%] [G loss: 2.802767]\n",
      "epoch:22 step:17287 [D loss: 0.469679, acc: 82.81%] [G loss: 2.877307]\n",
      "epoch:22 step:17288 [D loss: 0.386994, acc: 91.41%] [G loss: 4.362748]\n",
      "epoch:22 step:17289 [D loss: 0.820528, acc: 42.97%] [G loss: 1.632988]\n",
      "epoch:22 step:17290 [D loss: 0.420014, acc: 71.88%] [G loss: 2.365796]\n",
      "epoch:22 step:17291 [D loss: 0.700802, acc: 54.69%] [G loss: 2.855507]\n",
      "epoch:22 step:17292 [D loss: 0.389871, acc: 91.41%] [G loss: 2.482304]\n",
      "epoch:22 step:17293 [D loss: 0.450939, acc: 85.16%] [G loss: 3.257531]\n",
      "epoch:22 step:17294 [D loss: 0.703958, acc: 58.59%] [G loss: 2.461431]\n",
      "epoch:22 step:17295 [D loss: 0.308471, acc: 97.66%] [G loss: 2.401401]\n",
      "epoch:22 step:17296 [D loss: 0.314107, acc: 96.88%] [G loss: 1.934018]\n",
      "epoch:22 step:17297 [D loss: 0.742937, acc: 50.78%] [G loss: 3.066308]\n",
      "epoch:22 step:17298 [D loss: 0.652846, acc: 59.38%] [G loss: 2.470732]\n",
      "epoch:22 step:17299 [D loss: 0.403788, acc: 92.19%] [G loss: 1.844027]\n",
      "epoch:22 step:17300 [D loss: 0.662728, acc: 60.16%] [G loss: 2.821755]\n",
      "epoch:22 step:17301 [D loss: 0.321918, acc: 89.06%] [G loss: 3.477491]\n",
      "epoch:22 step:17302 [D loss: 0.551214, acc: 70.31%] [G loss: 2.478591]\n",
      "epoch:22 step:17303 [D loss: 0.540276, acc: 69.53%] [G loss: 1.652920]\n",
      "epoch:22 step:17304 [D loss: 0.576759, acc: 71.88%] [G loss: 2.082890]\n",
      "epoch:22 step:17305 [D loss: 0.311248, acc: 95.31%] [G loss: 2.703967]\n",
      "epoch:22 step:17306 [D loss: 0.504166, acc: 81.25%] [G loss: 2.998454]\n",
      "epoch:22 step:17307 [D loss: 0.577799, acc: 57.81%] [G loss: 1.749306]\n",
      "epoch:22 step:17308 [D loss: 0.673812, acc: 56.25%] [G loss: 3.092315]\n",
      "epoch:22 step:17309 [D loss: 0.826679, acc: 43.75%] [G loss: 1.915442]\n",
      "epoch:22 step:17310 [D loss: 0.342314, acc: 91.41%] [G loss: 2.046885]\n",
      "epoch:22 step:17311 [D loss: 0.593685, acc: 72.66%] [G loss: 1.920787]\n",
      "epoch:22 step:17312 [D loss: 0.590622, acc: 68.75%] [G loss: 3.634181]\n",
      "epoch:22 step:17313 [D loss: 0.559788, acc: 69.53%] [G loss: 2.959594]\n",
      "epoch:22 step:17314 [D loss: 0.317652, acc: 96.09%] [G loss: 2.549484]\n",
      "epoch:22 step:17315 [D loss: 0.839932, acc: 37.50%] [G loss: 2.408210]\n",
      "epoch:22 step:17316 [D loss: 0.539207, acc: 75.00%] [G loss: 2.780899]\n",
      "epoch:22 step:17317 [D loss: 0.821913, acc: 46.09%] [G loss: 2.353293]\n",
      "epoch:22 step:17318 [D loss: 0.468870, acc: 78.91%] [G loss: 3.048842]\n",
      "epoch:22 step:17319 [D loss: 0.930357, acc: 29.69%] [G loss: 1.979046]\n",
      "epoch:22 step:17320 [D loss: 0.628065, acc: 64.84%] [G loss: 2.221432]\n",
      "epoch:22 step:17321 [D loss: 0.985058, acc: 26.56%] [G loss: 2.613818]\n",
      "epoch:22 step:17322 [D loss: 0.562279, acc: 71.88%] [G loss: 2.618745]\n",
      "epoch:22 step:17323 [D loss: 0.358519, acc: 87.50%] [G loss: 2.367180]\n",
      "epoch:22 step:17324 [D loss: 0.762406, acc: 54.69%] [G loss: 3.327730]\n",
      "epoch:22 step:17325 [D loss: 0.555969, acc: 71.88%] [G loss: 2.447331]\n",
      "epoch:22 step:17326 [D loss: 0.553304, acc: 70.31%] [G loss: 2.338472]\n",
      "epoch:22 step:17327 [D loss: 0.447242, acc: 82.81%] [G loss: 2.160365]\n",
      "epoch:22 step:17328 [D loss: 0.236197, acc: 97.66%] [G loss: 2.539858]\n",
      "epoch:22 step:17329 [D loss: 0.462178, acc: 78.12%] [G loss: 2.638032]\n",
      "epoch:22 step:17330 [D loss: 0.437583, acc: 89.06%] [G loss: 2.062358]\n",
      "epoch:22 step:17331 [D loss: 0.562260, acc: 62.50%] [G loss: 2.410874]\n",
      "epoch:22 step:17332 [D loss: 0.671067, acc: 57.03%] [G loss: 2.461790]\n",
      "epoch:22 step:17333 [D loss: 0.236959, acc: 99.22%] [G loss: 3.472173]\n",
      "epoch:22 step:17334 [D loss: 0.814355, acc: 52.34%] [G loss: 1.879729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17335 [D loss: 0.593443, acc: 53.91%] [G loss: 3.928862]\n",
      "epoch:22 step:17336 [D loss: 0.407547, acc: 89.06%] [G loss: 3.229344]\n",
      "epoch:22 step:17337 [D loss: 0.555092, acc: 67.97%] [G loss: 2.402028]\n",
      "epoch:22 step:17338 [D loss: 0.535852, acc: 71.88%] [G loss: 1.742619]\n",
      "epoch:22 step:17339 [D loss: 0.208480, acc: 97.66%] [G loss: 4.443295]\n",
      "epoch:22 step:17340 [D loss: 0.384625, acc: 92.19%] [G loss: 1.990282]\n",
      "epoch:22 step:17341 [D loss: 0.358113, acc: 93.75%] [G loss: 2.392276]\n",
      "epoch:22 step:17342 [D loss: 0.798660, acc: 36.72%] [G loss: 2.406923]\n",
      "epoch:22 step:17343 [D loss: 0.374950, acc: 88.28%] [G loss: 2.011758]\n",
      "epoch:22 step:17344 [D loss: 0.467240, acc: 85.94%] [G loss: 2.971909]\n",
      "epoch:22 step:17345 [D loss: 1.042893, acc: 32.81%] [G loss: 1.876062]\n",
      "epoch:22 step:17346 [D loss: 0.621031, acc: 67.19%] [G loss: 2.629441]\n",
      "epoch:22 step:17347 [D loss: 0.516244, acc: 82.03%] [G loss: 2.855530]\n",
      "epoch:22 step:17348 [D loss: 0.558319, acc: 70.31%] [G loss: 3.164516]\n",
      "epoch:22 step:17349 [D loss: 0.935749, acc: 44.53%] [G loss: 2.937006]\n",
      "epoch:22 step:17350 [D loss: 0.669421, acc: 54.69%] [G loss: 2.594079]\n",
      "epoch:22 step:17351 [D loss: 0.531905, acc: 82.03%] [G loss: 2.491315]\n",
      "epoch:22 step:17352 [D loss: 0.337740, acc: 89.84%] [G loss: 3.130120]\n",
      "epoch:22 step:17353 [D loss: 0.382023, acc: 90.62%] [G loss: 2.417008]\n",
      "epoch:22 step:17354 [D loss: 0.922051, acc: 37.50%] [G loss: 2.456160]\n",
      "epoch:22 step:17355 [D loss: 0.953572, acc: 31.25%] [G loss: 1.682390]\n",
      "epoch:22 step:17356 [D loss: 0.094566, acc: 100.00%] [G loss: 3.107841]\n",
      "epoch:22 step:17357 [D loss: 0.500877, acc: 68.75%] [G loss: 2.858912]\n",
      "epoch:22 step:17358 [D loss: 0.620219, acc: 60.94%] [G loss: 3.544245]\n",
      "epoch:22 step:17359 [D loss: 0.704045, acc: 53.91%] [G loss: 2.341373]\n",
      "epoch:22 step:17360 [D loss: 0.431281, acc: 88.28%] [G loss: 2.026065]\n",
      "epoch:22 step:17361 [D loss: 1.044843, acc: 13.28%] [G loss: 2.249423]\n",
      "epoch:22 step:17362 [D loss: 0.509591, acc: 77.34%] [G loss: 1.690671]\n",
      "epoch:22 step:17363 [D loss: 0.591074, acc: 73.44%] [G loss: 3.139584]\n",
      "epoch:22 step:17364 [D loss: 0.799742, acc: 47.66%] [G loss: 2.000136]\n",
      "epoch:22 step:17365 [D loss: 0.794826, acc: 49.22%] [G loss: 2.521419]\n",
      "epoch:22 step:17366 [D loss: 0.791945, acc: 43.75%] [G loss: 2.822009]\n",
      "epoch:22 step:17367 [D loss: 0.604824, acc: 68.75%] [G loss: 1.766898]\n",
      "epoch:22 step:17368 [D loss: 0.310690, acc: 96.88%] [G loss: 3.096414]\n",
      "epoch:22 step:17369 [D loss: 0.225043, acc: 100.00%] [G loss: 2.801265]\n",
      "epoch:22 step:17370 [D loss: 0.674994, acc: 55.47%] [G loss: 2.315867]\n",
      "epoch:22 step:17371 [D loss: 0.175046, acc: 98.44%] [G loss: 2.898536]\n",
      "epoch:22 step:17372 [D loss: 0.312864, acc: 98.44%] [G loss: 2.770143]\n",
      "epoch:22 step:17373 [D loss: 0.501156, acc: 82.03%] [G loss: 1.652262]\n",
      "epoch:22 step:17374 [D loss: 0.408571, acc: 90.62%] [G loss: 3.455269]\n",
      "epoch:22 step:17375 [D loss: 0.649742, acc: 56.25%] [G loss: 2.015249]\n",
      "epoch:22 step:17376 [D loss: 0.131540, acc: 100.00%] [G loss: 3.160002]\n",
      "epoch:22 step:17377 [D loss: 0.356951, acc: 90.62%] [G loss: 2.452555]\n",
      "epoch:22 step:17378 [D loss: 0.830218, acc: 39.06%] [G loss: 2.236900]\n",
      "epoch:22 step:17379 [D loss: 0.587666, acc: 62.50%] [G loss: 2.630372]\n",
      "epoch:22 step:17380 [D loss: 0.657642, acc: 58.59%] [G loss: 3.247066]\n",
      "epoch:22 step:17381 [D loss: 0.446700, acc: 85.94%] [G loss: 2.946357]\n",
      "epoch:22 step:17382 [D loss: 0.167813, acc: 100.00%] [G loss: 3.263716]\n",
      "epoch:22 step:17383 [D loss: 0.417221, acc: 75.78%] [G loss: 3.124926]\n",
      "epoch:22 step:17384 [D loss: 0.369197, acc: 92.19%] [G loss: 2.994135]\n",
      "epoch:22 step:17385 [D loss: 0.845825, acc: 35.16%] [G loss: 2.361030]\n",
      "epoch:22 step:17386 [D loss: 0.580501, acc: 68.75%] [G loss: 1.815732]\n",
      "epoch:22 step:17387 [D loss: 0.989896, acc: 17.97%] [G loss: 1.442556]\n",
      "epoch:22 step:17388 [D loss: 0.593506, acc: 71.88%] [G loss: 2.528713]\n",
      "epoch:22 step:17389 [D loss: 0.389386, acc: 90.62%] [G loss: 1.568549]\n",
      "epoch:22 step:17390 [D loss: 0.301695, acc: 95.31%] [G loss: 4.259954]\n",
      "epoch:22 step:17391 [D loss: 0.279628, acc: 97.66%] [G loss: 2.646706]\n",
      "epoch:22 step:17392 [D loss: 1.207723, acc: 21.88%] [G loss: 1.605455]\n",
      "epoch:22 step:17393 [D loss: 0.308355, acc: 94.53%] [G loss: 2.470161]\n",
      "epoch:22 step:17394 [D loss: 0.314688, acc: 96.88%] [G loss: 3.338741]\n",
      "epoch:22 step:17395 [D loss: 0.534363, acc: 68.75%] [G loss: 2.145158]\n",
      "epoch:22 step:17396 [D loss: 0.497886, acc: 67.19%] [G loss: 3.076684]\n",
      "epoch:22 step:17397 [D loss: 0.702656, acc: 56.25%] [G loss: 3.001583]\n",
      "epoch:22 step:17398 [D loss: 0.524376, acc: 60.94%] [G loss: 2.616651]\n",
      "epoch:22 step:17399 [D loss: 0.798862, acc: 41.41%] [G loss: 2.847721]\n",
      "epoch:22 step:17400 [D loss: 0.360134, acc: 93.75%] [G loss: 2.617717]\n",
      "epoch:22 step:17401 [D loss: 0.221015, acc: 96.09%] [G loss: 2.794699]\n",
      "epoch:22 step:17402 [D loss: 0.670316, acc: 56.25%] [G loss: 2.594681]\n",
      "epoch:22 step:17403 [D loss: 0.589272, acc: 60.16%] [G loss: 1.816580]\n",
      "epoch:22 step:17404 [D loss: 0.481167, acc: 71.88%] [G loss: 3.818564]\n",
      "epoch:22 step:17405 [D loss: 0.547416, acc: 75.00%] [G loss: 2.207058]\n",
      "epoch:22 step:17406 [D loss: 0.317516, acc: 95.31%] [G loss: 2.190668]\n",
      "epoch:22 step:17407 [D loss: 0.559794, acc: 68.75%] [G loss: 2.088315]\n",
      "epoch:22 step:17408 [D loss: 0.577557, acc: 71.88%] [G loss: 2.392814]\n",
      "epoch:22 step:17409 [D loss: 0.319116, acc: 96.88%] [G loss: 3.143267]\n",
      "epoch:22 step:17410 [D loss: 0.644770, acc: 63.28%] [G loss: 1.933027]\n",
      "epoch:22 step:17411 [D loss: 0.805134, acc: 45.31%] [G loss: 2.235068]\n",
      "epoch:22 step:17412 [D loss: 1.172027, acc: 21.88%] [G loss: 2.523167]\n",
      "epoch:22 step:17413 [D loss: 0.247527, acc: 100.00%] [G loss: 2.968630]\n",
      "epoch:22 step:17414 [D loss: 0.720118, acc: 53.12%] [G loss: 2.605723]\n",
      "epoch:22 step:17415 [D loss: 0.368976, acc: 93.75%] [G loss: 3.110773]\n",
      "epoch:22 step:17416 [D loss: 0.866348, acc: 38.28%] [G loss: 2.330769]\n",
      "epoch:22 step:17417 [D loss: 0.432474, acc: 85.94%] [G loss: 3.536901]\n",
      "epoch:22 step:17418 [D loss: 0.271888, acc: 96.09%] [G loss: 2.304099]\n",
      "epoch:22 step:17419 [D loss: 0.947105, acc: 43.75%] [G loss: 2.520238]\n",
      "epoch:22 step:17420 [D loss: 0.680388, acc: 59.38%] [G loss: 2.625421]\n",
      "epoch:22 step:17421 [D loss: 0.373637, acc: 92.19%] [G loss: 3.001680]\n",
      "epoch:22 step:17422 [D loss: 0.436303, acc: 77.34%] [G loss: 2.534157]\n",
      "epoch:22 step:17423 [D loss: 0.327899, acc: 90.62%] [G loss: 2.897588]\n",
      "epoch:22 step:17424 [D loss: 0.450310, acc: 81.25%] [G loss: 2.503138]\n",
      "epoch:22 step:17425 [D loss: 0.430294, acc: 87.50%] [G loss: 2.758598]\n",
      "epoch:22 step:17426 [D loss: 1.116710, acc: 14.06%] [G loss: 2.007963]\n",
      "epoch:22 step:17427 [D loss: 1.050296, acc: 50.00%] [G loss: 2.236909]\n",
      "epoch:22 step:17428 [D loss: 0.522913, acc: 76.56%] [G loss: 3.064736]\n",
      "epoch:22 step:17429 [D loss: 0.961601, acc: 34.38%] [G loss: 2.605207]\n",
      "epoch:22 step:17430 [D loss: 0.717161, acc: 56.25%] [G loss: 2.176627]\n",
      "epoch:22 step:17431 [D loss: 0.763400, acc: 50.78%] [G loss: 2.309460]\n",
      "epoch:22 step:17432 [D loss: 0.662801, acc: 63.28%] [G loss: 2.515216]\n",
      "epoch:22 step:17433 [D loss: 0.439050, acc: 75.78%] [G loss: 3.647265]\n",
      "epoch:22 step:17434 [D loss: 0.669905, acc: 56.25%] [G loss: 2.391092]\n",
      "epoch:22 step:17435 [D loss: 1.016207, acc: 21.09%] [G loss: 2.518352]\n",
      "epoch:22 step:17436 [D loss: 0.745597, acc: 45.31%] [G loss: 2.711094]\n",
      "epoch:22 step:17437 [D loss: 0.248930, acc: 100.00%] [G loss: 2.504293]\n",
      "epoch:22 step:17438 [D loss: 0.558486, acc: 69.53%] [G loss: 2.073762]\n",
      "epoch:22 step:17439 [D loss: 1.023420, acc: 17.97%] [G loss: 1.632506]\n",
      "epoch:22 step:17440 [D loss: 0.351940, acc: 85.94%] [G loss: 2.577441]\n",
      "epoch:22 step:17441 [D loss: 0.857726, acc: 50.00%] [G loss: 2.252662]\n",
      "epoch:22 step:17442 [D loss: 0.617926, acc: 64.06%] [G loss: 3.152292]\n",
      "epoch:22 step:17443 [D loss: 0.347093, acc: 93.75%] [G loss: 1.866623]\n",
      "epoch:22 step:17444 [D loss: 0.312946, acc: 92.19%] [G loss: 2.269596]\n",
      "epoch:22 step:17445 [D loss: 0.684143, acc: 57.81%] [G loss: 2.234362]\n",
      "epoch:22 step:17446 [D loss: 0.589682, acc: 71.88%] [G loss: 1.806466]\n",
      "epoch:22 step:17447 [D loss: 0.530375, acc: 71.88%] [G loss: 3.367410]\n",
      "epoch:22 step:17448 [D loss: 0.969402, acc: 32.03%] [G loss: 2.544440]\n",
      "epoch:22 step:17449 [D loss: 0.581831, acc: 75.00%] [G loss: 2.476210]\n",
      "epoch:22 step:17450 [D loss: 0.543451, acc: 72.66%] [G loss: 1.985909]\n",
      "epoch:22 step:17451 [D loss: 0.829344, acc: 50.78%] [G loss: 2.039628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17452 [D loss: 0.630534, acc: 67.19%] [G loss: 1.696413]\n",
      "epoch:22 step:17453 [D loss: 0.473191, acc: 86.72%] [G loss: 2.466869]\n",
      "epoch:22 step:17454 [D loss: 0.407951, acc: 89.84%] [G loss: 2.822569]\n",
      "epoch:22 step:17455 [D loss: 0.550348, acc: 71.88%] [G loss: 2.151737]\n",
      "epoch:22 step:17456 [D loss: 1.518343, acc: 3.12%] [G loss: 1.944610]\n",
      "epoch:22 step:17457 [D loss: 0.756616, acc: 50.78%] [G loss: 1.703915]\n",
      "epoch:22 step:17458 [D loss: 0.513194, acc: 78.12%] [G loss: 2.226794]\n",
      "epoch:22 step:17459 [D loss: 0.799987, acc: 41.41%] [G loss: 2.593112]\n",
      "epoch:22 step:17460 [D loss: 0.577138, acc: 68.75%] [G loss: 3.046310]\n",
      "epoch:22 step:17461 [D loss: 0.511759, acc: 85.16%] [G loss: 2.158811]\n",
      "epoch:22 step:17462 [D loss: 0.479568, acc: 76.56%] [G loss: 2.357593]\n",
      "epoch:22 step:17463 [D loss: 0.619802, acc: 66.41%] [G loss: 2.627679]\n",
      "epoch:22 step:17464 [D loss: 0.797162, acc: 48.44%] [G loss: 2.510603]\n",
      "epoch:22 step:17465 [D loss: 0.231106, acc: 99.22%] [G loss: 2.142359]\n",
      "epoch:22 step:17466 [D loss: 0.637965, acc: 63.28%] [G loss: 2.646990]\n",
      "epoch:22 step:17467 [D loss: 0.348102, acc: 86.72%] [G loss: 3.112388]\n",
      "epoch:22 step:17468 [D loss: 0.622153, acc: 66.41%] [G loss: 2.739993]\n",
      "epoch:22 step:17469 [D loss: 0.731186, acc: 56.25%] [G loss: 2.582917]\n",
      "epoch:22 step:17470 [D loss: 0.925499, acc: 47.66%] [G loss: 1.913456]\n",
      "epoch:22 step:17471 [D loss: 0.628212, acc: 61.72%] [G loss: 1.860979]\n",
      "epoch:22 step:17472 [D loss: 0.927194, acc: 35.16%] [G loss: 1.591104]\n",
      "epoch:22 step:17473 [D loss: 0.619422, acc: 60.94%] [G loss: 2.587666]\n",
      "epoch:22 step:17474 [D loss: 0.455987, acc: 82.03%] [G loss: 2.908663]\n",
      "epoch:22 step:17475 [D loss: 0.368285, acc: 86.72%] [G loss: 2.899864]\n",
      "epoch:22 step:17476 [D loss: 0.752787, acc: 41.41%] [G loss: 1.808942]\n",
      "epoch:22 step:17477 [D loss: 0.485111, acc: 83.59%] [G loss: 3.310566]\n",
      "epoch:22 step:17478 [D loss: 0.337048, acc: 95.31%] [G loss: 3.117572]\n",
      "epoch:22 step:17479 [D loss: 0.566414, acc: 78.12%] [G loss: 2.162813]\n",
      "epoch:22 step:17480 [D loss: 0.586754, acc: 66.41%] [G loss: 2.208878]\n",
      "epoch:22 step:17481 [D loss: 0.612784, acc: 66.41%] [G loss: 2.925582]\n",
      "epoch:22 step:17482 [D loss: 0.577327, acc: 74.22%] [G loss: 2.686394]\n",
      "epoch:22 step:17483 [D loss: 0.366741, acc: 96.09%] [G loss: 2.624119]\n",
      "epoch:22 step:17484 [D loss: 0.443791, acc: 89.06%] [G loss: 2.734014]\n",
      "epoch:22 step:17485 [D loss: 0.614614, acc: 66.41%] [G loss: 2.350456]\n",
      "epoch:22 step:17486 [D loss: 0.351529, acc: 89.84%] [G loss: 3.302809]\n",
      "epoch:22 step:17487 [D loss: 0.740344, acc: 53.12%] [G loss: 2.413071]\n",
      "epoch:22 step:17488 [D loss: 0.310776, acc: 96.88%] [G loss: 2.666707]\n",
      "epoch:22 step:17489 [D loss: 0.479278, acc: 69.53%] [G loss: 2.059489]\n",
      "epoch:22 step:17490 [D loss: 0.404332, acc: 88.28%] [G loss: 3.358702]\n",
      "epoch:22 step:17491 [D loss: 0.393908, acc: 86.72%] [G loss: 3.216086]\n",
      "epoch:22 step:17492 [D loss: 0.422429, acc: 87.50%] [G loss: 4.370976]\n",
      "epoch:22 step:17493 [D loss: 0.806973, acc: 44.53%] [G loss: 3.847666]\n",
      "epoch:22 step:17494 [D loss: 0.879795, acc: 33.59%] [G loss: 2.282351]\n",
      "epoch:22 step:17495 [D loss: 0.665895, acc: 60.16%] [G loss: 2.360809]\n",
      "epoch:22 step:17496 [D loss: 1.043268, acc: 42.97%] [G loss: 2.268818]\n",
      "epoch:22 step:17497 [D loss: 0.679253, acc: 60.16%] [G loss: 2.439363]\n",
      "epoch:22 step:17498 [D loss: 0.889114, acc: 37.50%] [G loss: 2.358666]\n",
      "epoch:22 step:17499 [D loss: 0.423141, acc: 88.28%] [G loss: 2.915214]\n",
      "epoch:22 step:17500 [D loss: 0.696838, acc: 57.03%] [G loss: 3.715872]\n",
      "epoch:22 step:17501 [D loss: 0.755896, acc: 47.66%] [G loss: 2.616230]\n",
      "epoch:22 step:17502 [D loss: 0.949327, acc: 43.75%] [G loss: 2.492650]\n",
      "epoch:22 step:17503 [D loss: 0.583663, acc: 65.62%] [G loss: 2.430048]\n",
      "epoch:22 step:17504 [D loss: 0.554842, acc: 75.00%] [G loss: 2.693345]\n",
      "epoch:22 step:17505 [D loss: 0.192329, acc: 98.44%] [G loss: 3.552177]\n",
      "epoch:22 step:17506 [D loss: 0.433880, acc: 89.84%] [G loss: 2.602651]\n",
      "epoch:22 step:17507 [D loss: 0.342680, acc: 96.88%] [G loss: 2.115569]\n",
      "epoch:22 step:17508 [D loss: 0.635192, acc: 58.59%] [G loss: 2.322942]\n",
      "epoch:22 step:17509 [D loss: 0.216663, acc: 100.00%] [G loss: 3.017613]\n",
      "epoch:22 step:17510 [D loss: 0.348922, acc: 92.19%] [G loss: 3.159340]\n",
      "epoch:22 step:17511 [D loss: 0.384957, acc: 85.94%] [G loss: 2.941218]\n",
      "epoch:22 step:17512 [D loss: 0.698138, acc: 57.81%] [G loss: 2.353694]\n",
      "epoch:22 step:17513 [D loss: 0.961926, acc: 38.28%] [G loss: 2.211972]\n",
      "epoch:22 step:17514 [D loss: 0.878306, acc: 50.78%] [G loss: 2.651577]\n",
      "epoch:22 step:17515 [D loss: 0.380044, acc: 92.97%] [G loss: 3.110659]\n",
      "epoch:22 step:17516 [D loss: 0.487704, acc: 86.72%] [G loss: 1.549489]\n",
      "epoch:22 step:17517 [D loss: 0.364018, acc: 89.06%] [G loss: 2.579939]\n",
      "epoch:22 step:17518 [D loss: 0.233941, acc: 99.22%] [G loss: 3.887091]\n",
      "epoch:22 step:17519 [D loss: 0.788621, acc: 51.56%] [G loss: 2.521275]\n",
      "epoch:22 step:17520 [D loss: 0.808293, acc: 50.00%] [G loss: 2.775970]\n",
      "epoch:22 step:17521 [D loss: 0.337075, acc: 99.22%] [G loss: 2.826244]\n",
      "epoch:22 step:17522 [D loss: 0.771734, acc: 41.41%] [G loss: 2.623189]\n",
      "epoch:22 step:17523 [D loss: 0.465961, acc: 70.31%] [G loss: 2.689670]\n",
      "epoch:22 step:17524 [D loss: 0.931385, acc: 21.88%] [G loss: 3.016592]\n",
      "epoch:22 step:17525 [D loss: 0.610245, acc: 62.50%] [G loss: 2.873260]\n",
      "epoch:22 step:17526 [D loss: 0.644310, acc: 64.84%] [G loss: 2.396549]\n",
      "epoch:22 step:17527 [D loss: 0.581853, acc: 71.88%] [G loss: 2.189481]\n",
      "epoch:22 step:17528 [D loss: 0.310101, acc: 97.66%] [G loss: 2.597933]\n",
      "epoch:22 step:17529 [D loss: 0.656121, acc: 58.59%] [G loss: 2.320305]\n",
      "epoch:22 step:17530 [D loss: 0.591183, acc: 67.19%] [G loss: 2.177102]\n",
      "epoch:22 step:17531 [D loss: 0.505253, acc: 82.03%] [G loss: 2.579108]\n",
      "epoch:22 step:17532 [D loss: 0.450090, acc: 89.84%] [G loss: 2.452788]\n",
      "epoch:22 step:17533 [D loss: 0.444327, acc: 83.59%] [G loss: 2.050704]\n",
      "epoch:22 step:17534 [D loss: 0.266417, acc: 96.09%] [G loss: 2.036163]\n",
      "epoch:22 step:17535 [D loss: 0.534535, acc: 74.22%] [G loss: 2.352920]\n",
      "epoch:22 step:17536 [D loss: 0.623347, acc: 68.75%] [G loss: 2.542700]\n",
      "epoch:22 step:17537 [D loss: 1.107805, acc: 12.50%] [G loss: 2.421236]\n",
      "epoch:22 step:17538 [D loss: 0.625746, acc: 62.50%] [G loss: 2.420166]\n",
      "epoch:22 step:17539 [D loss: 0.229339, acc: 100.00%] [G loss: 3.000248]\n",
      "epoch:22 step:17540 [D loss: 0.354045, acc: 92.97%] [G loss: 2.119020]\n",
      "epoch:22 step:17541 [D loss: 1.029905, acc: 17.97%] [G loss: 3.398133]\n",
      "epoch:22 step:17542 [D loss: 0.708335, acc: 54.69%] [G loss: 3.080747]\n",
      "epoch:22 step:17543 [D loss: 0.424497, acc: 92.19%] [G loss: 2.046850]\n",
      "epoch:22 step:17544 [D loss: 0.504309, acc: 78.12%] [G loss: 2.968993]\n",
      "epoch:22 step:17545 [D loss: 0.494246, acc: 82.03%] [G loss: 2.445084]\n",
      "epoch:22 step:17546 [D loss: 0.708918, acc: 54.69%] [G loss: 3.554031]\n",
      "epoch:22 step:17547 [D loss: 0.522321, acc: 62.50%] [G loss: 2.423195]\n",
      "epoch:22 step:17548 [D loss: 1.075472, acc: 19.53%] [G loss: 2.148664]\n",
      "epoch:22 step:17549 [D loss: 0.573061, acc: 74.22%] [G loss: 1.976198]\n",
      "epoch:22 step:17550 [D loss: 0.297137, acc: 94.53%] [G loss: 2.666604]\n",
      "epoch:22 step:17551 [D loss: 0.240569, acc: 99.22%] [G loss: 3.707996]\n",
      "epoch:22 step:17552 [D loss: 0.451335, acc: 89.06%] [G loss: 2.982375]\n",
      "epoch:22 step:17553 [D loss: 0.560057, acc: 74.22%] [G loss: 2.553207]\n",
      "epoch:22 step:17554 [D loss: 0.815028, acc: 42.19%] [G loss: 1.854609]\n",
      "epoch:22 step:17555 [D loss: 0.459169, acc: 85.16%] [G loss: 3.093105]\n",
      "epoch:22 step:17556 [D loss: 0.415463, acc: 90.62%] [G loss: 2.697882]\n",
      "epoch:22 step:17557 [D loss: 0.309038, acc: 96.09%] [G loss: 2.589495]\n",
      "epoch:22 step:17558 [D loss: 0.690646, acc: 59.38%] [G loss: 2.288724]\n",
      "epoch:22 step:17559 [D loss: 0.696348, acc: 56.25%] [G loss: 3.063062]\n",
      "epoch:22 step:17560 [D loss: 0.648999, acc: 65.62%] [G loss: 2.122885]\n",
      "epoch:22 step:17561 [D loss: 0.448746, acc: 75.00%] [G loss: 3.091118]\n",
      "epoch:22 step:17562 [D loss: 0.313176, acc: 85.16%] [G loss: 2.206336]\n",
      "epoch:22 step:17563 [D loss: 0.757838, acc: 44.53%] [G loss: 2.791347]\n",
      "epoch:22 step:17564 [D loss: 0.364134, acc: 79.69%] [G loss: 3.237189]\n",
      "epoch:22 step:17565 [D loss: 0.380069, acc: 91.41%] [G loss: 3.632671]\n",
      "epoch:22 step:17566 [D loss: 0.714709, acc: 54.69%] [G loss: 1.882683]\n",
      "epoch:22 step:17567 [D loss: 0.595336, acc: 64.06%] [G loss: 2.341684]\n",
      "epoch:22 step:17568 [D loss: 0.514574, acc: 80.47%] [G loss: 3.089439]\n",
      "epoch:22 step:17569 [D loss: 0.285211, acc: 96.09%] [G loss: 3.994896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17570 [D loss: 0.667221, acc: 59.38%] [G loss: 1.791816]\n",
      "epoch:22 step:17571 [D loss: 0.952204, acc: 31.25%] [G loss: 2.061737]\n",
      "epoch:22 step:17572 [D loss: 0.290411, acc: 98.44%] [G loss: 3.059222]\n",
      "epoch:22 step:17573 [D loss: 1.744084, acc: 4.69%] [G loss: 2.584866]\n",
      "epoch:22 step:17574 [D loss: 0.827194, acc: 49.22%] [G loss: 2.731940]\n",
      "epoch:22 step:17575 [D loss: 0.565206, acc: 71.09%] [G loss: 2.420259]\n",
      "epoch:22 step:17576 [D loss: 0.617208, acc: 64.84%] [G loss: 2.953105]\n",
      "epoch:22 step:17577 [D loss: 0.469299, acc: 66.41%] [G loss: 3.561046]\n",
      "epoch:22 step:17578 [D loss: 0.880594, acc: 51.56%] [G loss: 2.462788]\n",
      "epoch:22 step:17579 [D loss: 0.713693, acc: 54.69%] [G loss: 3.618270]\n",
      "epoch:22 step:17580 [D loss: 0.416715, acc: 85.94%] [G loss: 2.167871]\n",
      "epoch:22 step:17581 [D loss: 0.456537, acc: 73.44%] [G loss: 2.493778]\n",
      "epoch:22 step:17582 [D loss: 0.450049, acc: 77.34%] [G loss: 2.796252]\n",
      "epoch:22 step:17583 [D loss: 0.324302, acc: 93.75%] [G loss: 2.900764]\n",
      "epoch:22 step:17584 [D loss: 0.458604, acc: 85.16%] [G loss: 2.637452]\n",
      "epoch:22 step:17585 [D loss: 0.431151, acc: 84.38%] [G loss: 2.451737]\n",
      "epoch:22 step:17586 [D loss: 0.626530, acc: 64.84%] [G loss: 2.345782]\n",
      "epoch:22 step:17587 [D loss: 0.760063, acc: 50.00%] [G loss: 1.395381]\n",
      "epoch:22 step:17588 [D loss: 0.424101, acc: 89.06%] [G loss: 2.578601]\n",
      "epoch:22 step:17589 [D loss: 0.293361, acc: 94.53%] [G loss: 2.339211]\n",
      "epoch:22 step:17590 [D loss: 0.498676, acc: 71.88%] [G loss: 2.124354]\n",
      "epoch:22 step:17591 [D loss: 0.508551, acc: 71.09%] [G loss: 3.598372]\n",
      "epoch:22 step:17592 [D loss: 0.472324, acc: 85.94%] [G loss: 2.677694]\n",
      "epoch:22 step:17593 [D loss: 1.360207, acc: 5.47%] [G loss: 2.564403]\n",
      "epoch:22 step:17594 [D loss: 0.746444, acc: 53.12%] [G loss: 2.570643]\n",
      "epoch:22 step:17595 [D loss: 0.518319, acc: 66.41%] [G loss: 2.771109]\n",
      "epoch:22 step:17596 [D loss: 0.889135, acc: 25.00%] [G loss: 1.978091]\n",
      "epoch:22 step:17597 [D loss: 0.372023, acc: 94.53%] [G loss: 2.759184]\n",
      "epoch:22 step:17598 [D loss: 0.590698, acc: 67.19%] [G loss: 2.592137]\n",
      "epoch:22 step:17599 [D loss: 0.416008, acc: 89.06%] [G loss: 2.255773]\n",
      "epoch:22 step:17600 [D loss: 0.579949, acc: 73.44%] [G loss: 2.037327]\n",
      "epoch:22 step:17601 [D loss: 0.721398, acc: 57.03%] [G loss: 2.072745]\n",
      "epoch:22 step:17602 [D loss: 0.930655, acc: 50.78%] [G loss: 2.139606]\n",
      "epoch:22 step:17603 [D loss: 0.666942, acc: 58.59%] [G loss: 2.840613]\n",
      "epoch:22 step:17604 [D loss: 0.554568, acc: 64.84%] [G loss: 3.286273]\n",
      "epoch:22 step:17605 [D loss: 0.769329, acc: 52.34%] [G loss: 2.217835]\n",
      "epoch:22 step:17606 [D loss: 1.003011, acc: 21.88%] [G loss: 2.170610]\n",
      "epoch:22 step:17607 [D loss: 0.669115, acc: 58.59%] [G loss: 1.830240]\n",
      "epoch:22 step:17608 [D loss: 0.713872, acc: 53.12%] [G loss: 1.880790]\n",
      "epoch:22 step:17609 [D loss: 0.864587, acc: 49.22%] [G loss: 2.345171]\n",
      "epoch:22 step:17610 [D loss: 0.162266, acc: 100.00%] [G loss: 1.973568]\n",
      "epoch:22 step:17611 [D loss: 0.522896, acc: 78.12%] [G loss: 3.062511]\n",
      "epoch:22 step:17612 [D loss: 0.401205, acc: 91.41%] [G loss: 2.390052]\n",
      "epoch:22 step:17613 [D loss: 0.735706, acc: 52.34%] [G loss: 1.850806]\n",
      "epoch:22 step:17614 [D loss: 0.806649, acc: 38.28%] [G loss: 1.885622]\n",
      "epoch:22 step:17615 [D loss: 0.249850, acc: 97.66%] [G loss: 2.641893]\n",
      "epoch:22 step:17616 [D loss: 0.371838, acc: 86.72%] [G loss: 2.406628]\n",
      "epoch:22 step:17617 [D loss: 0.414493, acc: 91.41%] [G loss: 1.936063]\n",
      "epoch:22 step:17618 [D loss: 0.649876, acc: 60.16%] [G loss: 2.734365]\n",
      "epoch:22 step:17619 [D loss: 0.531135, acc: 73.44%] [G loss: 2.409447]\n",
      "epoch:22 step:17620 [D loss: 0.199532, acc: 98.44%] [G loss: 3.541626]\n",
      "epoch:22 step:17621 [D loss: 0.913644, acc: 27.34%] [G loss: 2.323958]\n",
      "epoch:22 step:17622 [D loss: 0.681293, acc: 57.03%] [G loss: 2.603777]\n",
      "epoch:22 step:17623 [D loss: 0.709167, acc: 56.25%] [G loss: 2.631548]\n",
      "epoch:22 step:17624 [D loss: 0.457209, acc: 82.03%] [G loss: 1.650069]\n",
      "epoch:22 step:17625 [D loss: 0.478675, acc: 85.16%] [G loss: 2.652213]\n",
      "epoch:22 step:17626 [D loss: 0.600100, acc: 67.19%] [G loss: 2.788461]\n",
      "epoch:22 step:17627 [D loss: 0.468132, acc: 85.94%] [G loss: 2.601474]\n",
      "epoch:22 step:17628 [D loss: 0.349658, acc: 93.75%] [G loss: 3.056718]\n",
      "epoch:22 step:17629 [D loss: 0.459367, acc: 89.06%] [G loss: 3.478061]\n",
      "epoch:22 step:17630 [D loss: 0.595276, acc: 71.09%] [G loss: 2.394503]\n",
      "epoch:22 step:17631 [D loss: 0.512049, acc: 78.12%] [G loss: 2.680664]\n",
      "epoch:22 step:17632 [D loss: 0.395206, acc: 98.44%] [G loss: 2.257509]\n",
      "epoch:22 step:17633 [D loss: 0.666244, acc: 56.25%] [G loss: 2.616627]\n",
      "epoch:22 step:17634 [D loss: 0.896223, acc: 34.38%] [G loss: 2.583174]\n",
      "epoch:22 step:17635 [D loss: 0.442710, acc: 79.69%] [G loss: 2.441600]\n",
      "epoch:22 step:17636 [D loss: 0.244613, acc: 98.44%] [G loss: 2.671385]\n",
      "epoch:22 step:17637 [D loss: 0.252071, acc: 96.09%] [G loss: 1.975103]\n",
      "epoch:22 step:17638 [D loss: 0.506818, acc: 75.00%] [G loss: 2.291045]\n",
      "epoch:22 step:17639 [D loss: 0.653553, acc: 57.81%] [G loss: 2.150508]\n",
      "epoch:22 step:17640 [D loss: 0.412726, acc: 89.84%] [G loss: 3.845912]\n",
      "epoch:22 step:17641 [D loss: 0.342262, acc: 89.84%] [G loss: 2.770871]\n",
      "epoch:22 step:17642 [D loss: 0.414470, acc: 88.28%] [G loss: 2.322140]\n",
      "epoch:22 step:17643 [D loss: 0.286409, acc: 96.88%] [G loss: 2.846130]\n",
      "epoch:22 step:17644 [D loss: 0.233546, acc: 99.22%] [G loss: 2.529005]\n",
      "epoch:22 step:17645 [D loss: 0.456133, acc: 85.16%] [G loss: 2.979646]\n",
      "epoch:22 step:17646 [D loss: 0.169519, acc: 100.00%] [G loss: 3.566195]\n",
      "epoch:22 step:17647 [D loss: 0.868208, acc: 33.59%] [G loss: 2.813324]\n",
      "epoch:22 step:17648 [D loss: 0.470801, acc: 77.34%] [G loss: 3.452971]\n",
      "epoch:22 step:17649 [D loss: 0.651258, acc: 56.25%] [G loss: 2.039100]\n",
      "epoch:22 step:17650 [D loss: 0.613940, acc: 60.94%] [G loss: 2.487082]\n",
      "epoch:22 step:17651 [D loss: 0.178290, acc: 100.00%] [G loss: 3.541865]\n",
      "epoch:22 step:17652 [D loss: 0.544327, acc: 75.78%] [G loss: 2.911677]\n",
      "epoch:22 step:17653 [D loss: 0.522265, acc: 70.31%] [G loss: 2.696422]\n",
      "epoch:22 step:17654 [D loss: 0.224160, acc: 98.44%] [G loss: 2.752296]\n",
      "epoch:22 step:17655 [D loss: 0.456863, acc: 75.00%] [G loss: 3.394469]\n",
      "epoch:22 step:17656 [D loss: 0.868703, acc: 34.38%] [G loss: 2.099208]\n",
      "epoch:22 step:17657 [D loss: 0.559032, acc: 73.44%] [G loss: 2.795777]\n",
      "epoch:22 step:17658 [D loss: 0.386858, acc: 89.06%] [G loss: 2.969007]\n",
      "epoch:22 step:17659 [D loss: 0.256075, acc: 97.66%] [G loss: 3.855172]\n",
      "epoch:22 step:17660 [D loss: 0.166017, acc: 100.00%] [G loss: 3.578704]\n",
      "epoch:22 step:17661 [D loss: 0.807387, acc: 44.53%] [G loss: 3.569696]\n",
      "epoch:22 step:17662 [D loss: 0.931405, acc: 38.28%] [G loss: 3.281029]\n",
      "epoch:22 step:17663 [D loss: 0.467680, acc: 90.62%] [G loss: 2.713389]\n",
      "epoch:22 step:17664 [D loss: 0.887271, acc: 39.06%] [G loss: 2.843282]\n",
      "epoch:22 step:17665 [D loss: 1.008646, acc: 50.00%] [G loss: 2.368572]\n",
      "epoch:22 step:17666 [D loss: 0.348454, acc: 95.31%] [G loss: 2.407650]\n",
      "epoch:22 step:17667 [D loss: 0.383018, acc: 90.62%] [G loss: 2.906186]\n",
      "epoch:22 step:17668 [D loss: 0.644288, acc: 63.28%] [G loss: 3.208135]\n",
      "epoch:22 step:17669 [D loss: 0.792317, acc: 51.56%] [G loss: 3.321172]\n",
      "epoch:22 step:17670 [D loss: 0.430090, acc: 79.69%] [G loss: 2.517873]\n",
      "epoch:22 step:17671 [D loss: 0.683711, acc: 57.81%] [G loss: 2.707929]\n",
      "epoch:22 step:17672 [D loss: 0.600990, acc: 69.53%] [G loss: 2.184367]\n",
      "epoch:22 step:17673 [D loss: 0.497736, acc: 80.47%] [G loss: 2.247916]\n",
      "epoch:22 step:17674 [D loss: 1.360157, acc: 13.28%] [G loss: 1.546844]\n",
      "epoch:22 step:17675 [D loss: 0.545276, acc: 74.22%] [G loss: 1.842597]\n",
      "epoch:22 step:17676 [D loss: 0.560072, acc: 76.56%] [G loss: 1.990078]\n",
      "epoch:22 step:17677 [D loss: 0.327684, acc: 96.09%] [G loss: 3.083616]\n",
      "epoch:22 step:17678 [D loss: 0.421533, acc: 87.50%] [G loss: 1.955730]\n",
      "epoch:22 step:17679 [D loss: 0.446825, acc: 81.25%] [G loss: 2.884015]\n",
      "epoch:22 step:17680 [D loss: 0.395639, acc: 92.19%] [G loss: 3.078236]\n",
      "epoch:22 step:17681 [D loss: 0.479964, acc: 65.62%] [G loss: 5.230164]\n",
      "epoch:22 step:17682 [D loss: 0.567548, acc: 72.66%] [G loss: 1.720474]\n",
      "epoch:22 step:17683 [D loss: 0.955515, acc: 34.38%] [G loss: 1.654540]\n",
      "epoch:22 step:17684 [D loss: 0.352565, acc: 86.72%] [G loss: 3.879743]\n",
      "epoch:22 step:17685 [D loss: 0.340353, acc: 94.53%] [G loss: 3.717124]\n",
      "epoch:22 step:17686 [D loss: 0.491965, acc: 82.03%] [G loss: 1.924533]\n",
      "epoch:22 step:17687 [D loss: 0.709301, acc: 50.00%] [G loss: 2.191752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17688 [D loss: 0.839487, acc: 44.53%] [G loss: 2.807526]\n",
      "epoch:22 step:17689 [D loss: 0.239495, acc: 99.22%] [G loss: 3.436147]\n",
      "epoch:22 step:17690 [D loss: 0.691328, acc: 59.38%] [G loss: 2.164348]\n",
      "epoch:22 step:17691 [D loss: 0.416124, acc: 91.41%] [G loss: 2.451492]\n",
      "epoch:22 step:17692 [D loss: 0.747499, acc: 46.09%] [G loss: 2.447753]\n",
      "epoch:22 step:17693 [D loss: 0.740059, acc: 48.44%] [G loss: 3.045824]\n",
      "epoch:22 step:17694 [D loss: 0.686876, acc: 55.47%] [G loss: 2.811329]\n",
      "epoch:22 step:17695 [D loss: 0.384516, acc: 89.06%] [G loss: 2.871450]\n",
      "epoch:22 step:17696 [D loss: 0.439367, acc: 85.16%] [G loss: 2.187478]\n",
      "epoch:22 step:17697 [D loss: 0.741933, acc: 55.47%] [G loss: 2.745854]\n",
      "epoch:22 step:17698 [D loss: 0.672417, acc: 54.69%] [G loss: 2.861375]\n",
      "epoch:22 step:17699 [D loss: 0.501371, acc: 74.22%] [G loss: 3.050864]\n",
      "epoch:22 step:17700 [D loss: 0.511607, acc: 66.41%] [G loss: 2.879948]\n",
      "epoch:22 step:17701 [D loss: 0.515404, acc: 80.47%] [G loss: 2.268250]\n",
      "epoch:22 step:17702 [D loss: 0.598874, acc: 68.75%] [G loss: 2.278634]\n",
      "epoch:22 step:17703 [D loss: 0.293879, acc: 95.31%] [G loss: 3.059827]\n",
      "epoch:22 step:17704 [D loss: 0.759282, acc: 49.22%] [G loss: 2.249186]\n",
      "epoch:22 step:17705 [D loss: 0.304410, acc: 96.09%] [G loss: 2.338675]\n",
      "epoch:22 step:17706 [D loss: 0.345826, acc: 86.72%] [G loss: 3.330729]\n",
      "epoch:22 step:17707 [D loss: 0.490083, acc: 80.47%] [G loss: 1.831179]\n",
      "epoch:22 step:17708 [D loss: 0.497811, acc: 84.38%] [G loss: 2.017159]\n",
      "epoch:22 step:17709 [D loss: 0.950047, acc: 50.78%] [G loss: 1.646186]\n",
      "epoch:22 step:17710 [D loss: 0.757655, acc: 55.47%] [G loss: 3.091049]\n",
      "epoch:22 step:17711 [D loss: 0.291951, acc: 95.31%] [G loss: 3.461472]\n",
      "epoch:22 step:17712 [D loss: 0.181518, acc: 99.22%] [G loss: 2.974149]\n",
      "epoch:22 step:17713 [D loss: 0.747106, acc: 47.66%] [G loss: 2.174662]\n",
      "epoch:22 step:17714 [D loss: 0.675440, acc: 57.81%] [G loss: 2.808898]\n",
      "epoch:22 step:17715 [D loss: 0.505015, acc: 67.19%] [G loss: 2.571298]\n",
      "epoch:22 step:17716 [D loss: 0.382786, acc: 92.19%] [G loss: 2.678000]\n",
      "epoch:22 step:17717 [D loss: 0.945662, acc: 25.00%] [G loss: 2.186091]\n",
      "epoch:22 step:17718 [D loss: 0.310857, acc: 89.06%] [G loss: 2.690358]\n",
      "epoch:22 step:17719 [D loss: 0.238030, acc: 98.44%] [G loss: 2.959211]\n",
      "epoch:22 step:17720 [D loss: 0.366709, acc: 96.88%] [G loss: 2.749918]\n",
      "epoch:22 step:17721 [D loss: 0.685611, acc: 53.12%] [G loss: 2.624960]\n",
      "epoch:22 step:17722 [D loss: 0.384099, acc: 96.09%] [G loss: 2.206987]\n",
      "epoch:22 step:17723 [D loss: 0.395869, acc: 92.19%] [G loss: 2.809511]\n",
      "epoch:22 step:17724 [D loss: 0.868471, acc: 47.66%] [G loss: 2.589849]\n",
      "epoch:22 step:17725 [D loss: 0.575737, acc: 71.88%] [G loss: 2.355631]\n",
      "epoch:22 step:17726 [D loss: 0.428215, acc: 73.44%] [G loss: 3.226462]\n",
      "epoch:22 step:17727 [D loss: 0.586963, acc: 64.84%] [G loss: 3.260371]\n",
      "epoch:22 step:17728 [D loss: 0.645457, acc: 60.94%] [G loss: 3.148704]\n",
      "epoch:22 step:17729 [D loss: 0.742421, acc: 49.22%] [G loss: 2.124827]\n",
      "epoch:22 step:17730 [D loss: 0.822104, acc: 43.75%] [G loss: 1.957515]\n",
      "epoch:22 step:17731 [D loss: 0.690925, acc: 53.91%] [G loss: 2.626479]\n",
      "epoch:22 step:17732 [D loss: 0.441615, acc: 85.94%] [G loss: 4.025087]\n",
      "epoch:22 step:17733 [D loss: 0.716451, acc: 55.47%] [G loss: 2.452491]\n",
      "epoch:22 step:17734 [D loss: 0.477391, acc: 83.59%] [G loss: 2.903831]\n",
      "epoch:22 step:17735 [D loss: 0.955119, acc: 36.72%] [G loss: 2.065083]\n",
      "epoch:22 step:17736 [D loss: 0.470539, acc: 78.12%] [G loss: 2.177391]\n",
      "epoch:22 step:17737 [D loss: 0.770487, acc: 51.56%] [G loss: 2.694614]\n",
      "epoch:22 step:17738 [D loss: 0.538075, acc: 78.91%] [G loss: 2.230243]\n",
      "epoch:22 step:17739 [D loss: 0.520860, acc: 69.53%] [G loss: 3.053804]\n",
      "epoch:22 step:17740 [D loss: 1.045394, acc: 16.41%] [G loss: 1.773221]\n",
      "epoch:22 step:17741 [D loss: 0.283632, acc: 99.22%] [G loss: 2.595139]\n",
      "epoch:22 step:17742 [D loss: 0.799149, acc: 38.28%] [G loss: 2.836204]\n",
      "epoch:22 step:17743 [D loss: 0.481601, acc: 77.34%] [G loss: 2.078258]\n",
      "epoch:22 step:17744 [D loss: 0.525175, acc: 81.25%] [G loss: 2.341744]\n",
      "epoch:22 step:17745 [D loss: 1.048054, acc: 15.62%] [G loss: 2.334520]\n",
      "epoch:22 step:17746 [D loss: 0.284940, acc: 97.66%] [G loss: 2.887887]\n",
      "epoch:22 step:17747 [D loss: 0.226203, acc: 100.00%] [G loss: 2.898280]\n",
      "epoch:22 step:17748 [D loss: 0.329602, acc: 94.53%] [G loss: 3.535417]\n",
      "epoch:22 step:17749 [D loss: 0.238349, acc: 96.88%] [G loss: 3.208909]\n",
      "epoch:22 step:17750 [D loss: 0.389553, acc: 91.41%] [G loss: 2.921873]\n",
      "epoch:22 step:17751 [D loss: 0.426080, acc: 85.94%] [G loss: 3.347246]\n",
      "epoch:22 step:17752 [D loss: 0.194205, acc: 100.00%] [G loss: 3.486215]\n",
      "epoch:22 step:17753 [D loss: 0.706472, acc: 53.91%] [G loss: 2.336213]\n",
      "epoch:22 step:17754 [D loss: 0.482942, acc: 85.16%] [G loss: 3.264823]\n",
      "epoch:22 step:17755 [D loss: 0.851236, acc: 34.38%] [G loss: 1.909220]\n",
      "epoch:22 step:17756 [D loss: 1.024232, acc: 10.94%] [G loss: 1.764309]\n",
      "epoch:22 step:17757 [D loss: 0.720011, acc: 50.00%] [G loss: 1.809422]\n",
      "epoch:22 step:17758 [D loss: 0.517914, acc: 75.00%] [G loss: 2.721395]\n",
      "epoch:22 step:17759 [D loss: 0.575810, acc: 61.72%] [G loss: 2.174382]\n",
      "epoch:22 step:17760 [D loss: 0.511358, acc: 66.41%] [G loss: 2.375463]\n",
      "epoch:22 step:17761 [D loss: 0.430150, acc: 89.06%] [G loss: 2.498586]\n",
      "epoch:22 step:17762 [D loss: 0.513604, acc: 70.31%] [G loss: 3.048046]\n",
      "epoch:22 step:17763 [D loss: 0.369935, acc: 81.25%] [G loss: 3.272146]\n",
      "epoch:22 step:17764 [D loss: 0.466598, acc: 81.25%] [G loss: 2.546025]\n",
      "epoch:22 step:17765 [D loss: 0.736884, acc: 53.91%] [G loss: 2.338341]\n",
      "epoch:22 step:17766 [D loss: 1.036765, acc: 19.53%] [G loss: 2.219907]\n",
      "epoch:22 step:17767 [D loss: 0.376245, acc: 87.50%] [G loss: 2.086639]\n",
      "epoch:22 step:17768 [D loss: 0.459248, acc: 85.94%] [G loss: 2.842818]\n",
      "epoch:22 step:17769 [D loss: 0.467128, acc: 72.66%] [G loss: 2.555346]\n",
      "epoch:22 step:17770 [D loss: 0.606440, acc: 65.62%] [G loss: 2.918670]\n",
      "epoch:22 step:17771 [D loss: 0.304719, acc: 87.50%] [G loss: 3.142677]\n",
      "epoch:22 step:17772 [D loss: 0.508126, acc: 80.47%] [G loss: 2.156430]\n",
      "epoch:22 step:17773 [D loss: 0.719332, acc: 48.44%] [G loss: 4.009156]\n",
      "epoch:22 step:17774 [D loss: 0.351324, acc: 94.53%] [G loss: 1.646998]\n",
      "epoch:22 step:17775 [D loss: 0.489792, acc: 81.25%] [G loss: 3.625223]\n",
      "epoch:22 step:17776 [D loss: 1.057156, acc: 46.88%] [G loss: 2.407256]\n",
      "epoch:22 step:17777 [D loss: 0.310280, acc: 92.97%] [G loss: 3.083263]\n",
      "epoch:22 step:17778 [D loss: 0.948290, acc: 29.69%] [G loss: 2.457241]\n",
      "epoch:22 step:17779 [D loss: 0.744773, acc: 50.78%] [G loss: 2.276320]\n",
      "epoch:22 step:17780 [D loss: 0.734489, acc: 52.34%] [G loss: 2.230539]\n",
      "epoch:22 step:17781 [D loss: 0.534631, acc: 73.44%] [G loss: 1.732487]\n",
      "epoch:22 step:17782 [D loss: 0.535772, acc: 68.75%] [G loss: 2.814424]\n",
      "epoch:22 step:17783 [D loss: 0.676884, acc: 53.91%] [G loss: 2.496668]\n",
      "epoch:22 step:17784 [D loss: 0.504420, acc: 81.25%] [G loss: 2.721923]\n",
      "epoch:22 step:17785 [D loss: 0.615261, acc: 66.41%] [G loss: 2.196823]\n",
      "epoch:22 step:17786 [D loss: 0.498172, acc: 71.09%] [G loss: 2.223193]\n",
      "epoch:22 step:17787 [D loss: 0.340478, acc: 93.75%] [G loss: 3.234273]\n",
      "epoch:22 step:17788 [D loss: 0.202023, acc: 97.66%] [G loss: 2.753102]\n",
      "epoch:22 step:17789 [D loss: 0.651314, acc: 61.72%] [G loss: 2.004589]\n",
      "epoch:22 step:17790 [D loss: 0.328546, acc: 95.31%] [G loss: 3.586303]\n",
      "epoch:22 step:17791 [D loss: 0.440136, acc: 86.72%] [G loss: 1.967679]\n",
      "epoch:22 step:17792 [D loss: 0.684727, acc: 56.25%] [G loss: 2.530126]\n",
      "epoch:22 step:17793 [D loss: 0.361117, acc: 89.84%] [G loss: 2.437824]\n",
      "epoch:22 step:17794 [D loss: 0.246282, acc: 98.44%] [G loss: 2.620288]\n",
      "epoch:22 step:17795 [D loss: 0.254024, acc: 98.44%] [G loss: 1.982330]\n",
      "epoch:22 step:17796 [D loss: 0.669503, acc: 56.25%] [G loss: 2.028719]\n",
      "epoch:22 step:17797 [D loss: 0.471044, acc: 83.59%] [G loss: 2.344347]\n",
      "epoch:22 step:17798 [D loss: 0.372380, acc: 85.94%] [G loss: 2.589188]\n",
      "epoch:22 step:17799 [D loss: 0.398604, acc: 87.50%] [G loss: 2.888891]\n",
      "epoch:22 step:17800 [D loss: 0.813084, acc: 41.41%] [G loss: 1.690829]\n",
      "epoch:22 step:17801 [D loss: 1.463757, acc: 31.25%] [G loss: 1.240026]\n",
      "epoch:22 step:17802 [D loss: 0.515821, acc: 82.03%] [G loss: 2.200810]\n",
      "epoch:22 step:17803 [D loss: 0.683279, acc: 59.38%] [G loss: 2.232329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17804 [D loss: 0.510268, acc: 75.00%] [G loss: 1.572940]\n",
      "epoch:22 step:17805 [D loss: 0.496335, acc: 80.47%] [G loss: 3.068107]\n",
      "epoch:22 step:17806 [D loss: 0.659553, acc: 55.47%] [G loss: 2.895498]\n",
      "epoch:22 step:17807 [D loss: 0.698340, acc: 54.69%] [G loss: 2.070934]\n",
      "epoch:22 step:17808 [D loss: 0.368354, acc: 94.53%] [G loss: 2.237464]\n",
      "epoch:22 step:17809 [D loss: 0.522069, acc: 69.53%] [G loss: 2.236238]\n",
      "epoch:22 step:17810 [D loss: 0.408119, acc: 84.38%] [G loss: 2.453079]\n",
      "epoch:22 step:17811 [D loss: 0.804105, acc: 40.62%] [G loss: 1.964789]\n",
      "epoch:22 step:17812 [D loss: 0.667478, acc: 56.25%] [G loss: 2.643413]\n",
      "epoch:22 step:17813 [D loss: 0.928800, acc: 32.03%] [G loss: 2.730161]\n",
      "epoch:22 step:17814 [D loss: 1.002518, acc: 50.00%] [G loss: 2.598530]\n",
      "epoch:22 step:17815 [D loss: 0.632456, acc: 60.16%] [G loss: 2.742407]\n",
      "epoch:22 step:17816 [D loss: 0.345052, acc: 96.09%] [G loss: 2.165835]\n",
      "epoch:22 step:17817 [D loss: 0.570116, acc: 65.62%] [G loss: 2.377535]\n",
      "epoch:22 step:17818 [D loss: 0.594040, acc: 63.28%] [G loss: 2.510471]\n",
      "epoch:22 step:17819 [D loss: 0.676830, acc: 57.03%] [G loss: 2.545928]\n",
      "epoch:22 step:17820 [D loss: 0.482122, acc: 73.44%] [G loss: 2.680661]\n",
      "epoch:22 step:17821 [D loss: 0.984402, acc: 41.41%] [G loss: 3.314452]\n",
      "epoch:22 step:17822 [D loss: 0.543057, acc: 80.47%] [G loss: 3.077621]\n",
      "epoch:22 step:17823 [D loss: 0.650515, acc: 65.62%] [G loss: 3.020349]\n",
      "epoch:22 step:17824 [D loss: 0.593072, acc: 73.44%] [G loss: 2.680112]\n",
      "epoch:22 step:17825 [D loss: 0.576408, acc: 66.41%] [G loss: 2.770740]\n",
      "epoch:22 step:17826 [D loss: 0.279444, acc: 96.88%] [G loss: 2.935825]\n",
      "epoch:22 step:17827 [D loss: 0.975775, acc: 28.91%] [G loss: 2.043763]\n",
      "epoch:22 step:17828 [D loss: 0.461960, acc: 82.81%] [G loss: 3.346618]\n",
      "epoch:22 step:17829 [D loss: 0.570780, acc: 67.97%] [G loss: 3.355164]\n",
      "epoch:22 step:17830 [D loss: 0.581126, acc: 67.97%] [G loss: 2.662146]\n",
      "epoch:22 step:17831 [D loss: 0.498190, acc: 63.28%] [G loss: 3.610837]\n",
      "epoch:22 step:17832 [D loss: 0.286126, acc: 97.66%] [G loss: 3.708003]\n",
      "epoch:22 step:17833 [D loss: 0.288316, acc: 97.66%] [G loss: 3.013623]\n",
      "epoch:22 step:17834 [D loss: 0.230537, acc: 100.00%] [G loss: 3.636296]\n",
      "epoch:22 step:17835 [D loss: 0.589627, acc: 56.25%] [G loss: 1.834087]\n",
      "epoch:22 step:17836 [D loss: 0.230369, acc: 96.09%] [G loss: 3.205667]\n",
      "epoch:22 step:17837 [D loss: 0.199876, acc: 100.00%] [G loss: 3.043705]\n",
      "epoch:22 step:17838 [D loss: 0.599841, acc: 72.66%] [G loss: 2.754459]\n",
      "epoch:22 step:17839 [D loss: 0.412120, acc: 89.84%] [G loss: 2.467630]\n",
      "epoch:22 step:17840 [D loss: 0.648459, acc: 54.69%] [G loss: 3.009072]\n",
      "epoch:22 step:17841 [D loss: 0.437178, acc: 75.00%] [G loss: 3.231395]\n",
      "epoch:22 step:17842 [D loss: 0.515540, acc: 81.25%] [G loss: 2.537029]\n",
      "epoch:22 step:17843 [D loss: 0.435889, acc: 88.28%] [G loss: 2.575799]\n",
      "epoch:22 step:17844 [D loss: 0.438306, acc: 82.03%] [G loss: 2.085089]\n",
      "epoch:22 step:17845 [D loss: 0.407197, acc: 82.81%] [G loss: 2.318676]\n",
      "epoch:22 step:17846 [D loss: 0.508298, acc: 80.47%] [G loss: 2.247516]\n",
      "epoch:22 step:17847 [D loss: 0.496998, acc: 84.38%] [G loss: 2.372961]\n",
      "epoch:22 step:17848 [D loss: 0.197824, acc: 100.00%] [G loss: 3.686749]\n",
      "epoch:22 step:17849 [D loss: 0.519716, acc: 71.88%] [G loss: 3.508110]\n",
      "epoch:22 step:17850 [D loss: 0.643887, acc: 59.38%] [G loss: 3.201648]\n",
      "epoch:22 step:17851 [D loss: 0.518030, acc: 71.09%] [G loss: 2.934307]\n",
      "epoch:22 step:17852 [D loss: 0.669875, acc: 58.59%] [G loss: 2.017868]\n",
      "epoch:22 step:17853 [D loss: 0.348368, acc: 93.75%] [G loss: 2.810739]\n",
      "epoch:22 step:17854 [D loss: 0.467094, acc: 78.91%] [G loss: 2.019469]\n",
      "epoch:22 step:17855 [D loss: 0.482309, acc: 73.44%] [G loss: 2.457308]\n",
      "epoch:22 step:17856 [D loss: 0.195931, acc: 98.44%] [G loss: 3.294120]\n",
      "epoch:22 step:17857 [D loss: 0.252736, acc: 100.00%] [G loss: 3.212335]\n",
      "epoch:22 step:17858 [D loss: 0.376032, acc: 89.06%] [G loss: 3.619226]\n",
      "epoch:22 step:17859 [D loss: 0.330189, acc: 92.19%] [G loss: 3.232538]\n",
      "epoch:22 step:17860 [D loss: 0.313456, acc: 95.31%] [G loss: 2.644616]\n",
      "epoch:22 step:17861 [D loss: 0.291076, acc: 100.00%] [G loss: 2.823134]\n",
      "epoch:22 step:17862 [D loss: 0.122624, acc: 99.22%] [G loss: 3.527687]\n",
      "epoch:22 step:17863 [D loss: 0.090612, acc: 100.00%] [G loss: 3.665515]\n",
      "epoch:22 step:17864 [D loss: 0.621964, acc: 64.84%] [G loss: 2.536033]\n",
      "epoch:22 step:17865 [D loss: 0.851946, acc: 52.34%] [G loss: 2.139562]\n",
      "epoch:22 step:17866 [D loss: 0.470488, acc: 71.88%] [G loss: 2.217358]\n",
      "epoch:22 step:17867 [D loss: 0.412057, acc: 75.00%] [G loss: 2.063764]\n",
      "epoch:22 step:17868 [D loss: 0.883022, acc: 39.06%] [G loss: 3.239581]\n",
      "epoch:22 step:17869 [D loss: 0.814953, acc: 50.78%] [G loss: 2.606238]\n",
      "epoch:22 step:17870 [D loss: 0.615246, acc: 56.25%] [G loss: 2.819530]\n",
      "epoch:22 step:17871 [D loss: 0.439696, acc: 74.22%] [G loss: 2.745144]\n",
      "epoch:22 step:17872 [D loss: 0.724185, acc: 51.56%] [G loss: 3.978114]\n",
      "epoch:22 step:17873 [D loss: 0.380585, acc: 78.12%] [G loss: 2.823590]\n",
      "epoch:22 step:17874 [D loss: 1.385588, acc: 10.94%] [G loss: 2.911718]\n",
      "epoch:22 step:17875 [D loss: 0.253288, acc: 97.66%] [G loss: 2.438210]\n",
      "epoch:22 step:17876 [D loss: 0.170208, acc: 99.22%] [G loss: 2.631980]\n",
      "epoch:22 step:17877 [D loss: 0.256452, acc: 96.09%] [G loss: 2.416005]\n",
      "epoch:22 step:17878 [D loss: 0.788295, acc: 48.44%] [G loss: 1.539975]\n",
      "epoch:22 step:17879 [D loss: 0.794274, acc: 40.62%] [G loss: 2.574591]\n",
      "epoch:22 step:17880 [D loss: 0.394960, acc: 87.50%] [G loss: 2.647688]\n",
      "epoch:22 step:17881 [D loss: 0.231256, acc: 92.97%] [G loss: 4.089795]\n",
      "epoch:22 step:17882 [D loss: 0.710762, acc: 53.91%] [G loss: 2.583144]\n",
      "epoch:22 step:17883 [D loss: 0.300215, acc: 96.09%] [G loss: 3.554338]\n",
      "epoch:22 step:17884 [D loss: 0.292046, acc: 90.62%] [G loss: 3.758086]\n",
      "epoch:22 step:17885 [D loss: 0.673746, acc: 55.47%] [G loss: 2.727414]\n",
      "epoch:22 step:17886 [D loss: 0.877131, acc: 51.56%] [G loss: 3.069570]\n",
      "epoch:22 step:17887 [D loss: 0.550200, acc: 61.72%] [G loss: 2.800821]\n",
      "epoch:22 step:17888 [D loss: 0.371869, acc: 95.31%] [G loss: 2.230369]\n",
      "epoch:22 step:17889 [D loss: 0.520789, acc: 77.34%] [G loss: 2.672662]\n",
      "epoch:22 step:17890 [D loss: 0.459506, acc: 85.94%] [G loss: 2.191992]\n",
      "epoch:22 step:17891 [D loss: 0.567932, acc: 67.97%] [G loss: 2.571461]\n",
      "epoch:22 step:17892 [D loss: 0.943638, acc: 28.91%] [G loss: 2.044003]\n",
      "epoch:22 step:17893 [D loss: 0.250292, acc: 94.53%] [G loss: 3.054065]\n",
      "epoch:22 step:17894 [D loss: 0.434344, acc: 89.06%] [G loss: 2.370034]\n",
      "epoch:22 step:17895 [D loss: 0.197007, acc: 100.00%] [G loss: 3.366999]\n",
      "epoch:22 step:17896 [D loss: 0.708365, acc: 54.69%] [G loss: 2.239584]\n",
      "epoch:22 step:17897 [D loss: 0.224083, acc: 99.22%] [G loss: 3.261878]\n",
      "epoch:22 step:17898 [D loss: 0.455300, acc: 87.50%] [G loss: 3.702778]\n",
      "epoch:22 step:17899 [D loss: 0.343307, acc: 85.94%] [G loss: 3.601683]\n",
      "epoch:22 step:17900 [D loss: 0.554458, acc: 74.22%] [G loss: 2.544594]\n",
      "epoch:22 step:17901 [D loss: 0.697901, acc: 58.59%] [G loss: 1.945905]\n",
      "epoch:22 step:17902 [D loss: 0.449081, acc: 83.59%] [G loss: 3.441318]\n",
      "epoch:22 step:17903 [D loss: 0.296980, acc: 97.66%] [G loss: 3.235266]\n",
      "epoch:22 step:17904 [D loss: 0.175539, acc: 100.00%] [G loss: 3.286374]\n",
      "epoch:22 step:17905 [D loss: 0.314629, acc: 95.31%] [G loss: 2.827738]\n",
      "epoch:22 step:17906 [D loss: 0.404973, acc: 81.25%] [G loss: 3.599640]\n",
      "epoch:22 step:17907 [D loss: 0.648695, acc: 55.47%] [G loss: 2.892045]\n",
      "epoch:22 step:17908 [D loss: 0.284935, acc: 98.44%] [G loss: 3.211066]\n",
      "epoch:22 step:17909 [D loss: 0.465411, acc: 72.66%] [G loss: 3.618453]\n",
      "epoch:22 step:17910 [D loss: 0.247339, acc: 97.66%] [G loss: 2.543304]\n",
      "epoch:22 step:17911 [D loss: 0.200752, acc: 99.22%] [G loss: 3.278111]\n",
      "epoch:22 step:17912 [D loss: 0.249666, acc: 96.88%] [G loss: 2.722721]\n",
      "epoch:22 step:17913 [D loss: 0.609514, acc: 66.41%] [G loss: 2.853858]\n",
      "epoch:22 step:17914 [D loss: 0.734421, acc: 54.69%] [G loss: 4.139887]\n",
      "epoch:22 step:17915 [D loss: 0.647827, acc: 62.50%] [G loss: 2.734738]\n",
      "epoch:22 step:17916 [D loss: 0.576629, acc: 74.22%] [G loss: 2.536317]\n",
      "epoch:22 step:17917 [D loss: 0.679230, acc: 54.69%] [G loss: 2.532981]\n",
      "epoch:22 step:17918 [D loss: 0.120556, acc: 100.00%] [G loss: 2.707350]\n",
      "epoch:22 step:17919 [D loss: 0.828173, acc: 42.19%] [G loss: 3.031423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17920 [D loss: 0.468812, acc: 81.25%] [G loss: 2.367815]\n",
      "epoch:22 step:17921 [D loss: 0.940306, acc: 30.47%] [G loss: 3.496786]\n",
      "epoch:22 step:17922 [D loss: 0.643809, acc: 62.50%] [G loss: 1.822878]\n",
      "epoch:22 step:17923 [D loss: 0.106696, acc: 100.00%] [G loss: 3.368014]\n",
      "epoch:22 step:17924 [D loss: 0.543616, acc: 75.78%] [G loss: 3.314245]\n",
      "epoch:22 step:17925 [D loss: 0.312972, acc: 97.66%] [G loss: 2.796707]\n",
      "epoch:22 step:17926 [D loss: 0.773919, acc: 49.22%] [G loss: 1.529820]\n",
      "epoch:22 step:17927 [D loss: 0.265310, acc: 95.31%] [G loss: 3.047853]\n",
      "epoch:22 step:17928 [D loss: 0.478567, acc: 88.28%] [G loss: 2.561111]\n",
      "epoch:22 step:17929 [D loss: 0.424338, acc: 85.94%] [G loss: 1.522189]\n",
      "epoch:22 step:17930 [D loss: 0.463169, acc: 76.56%] [G loss: 2.422801]\n",
      "epoch:22 step:17931 [D loss: 0.407088, acc: 82.03%] [G loss: 2.894799]\n",
      "epoch:22 step:17932 [D loss: 0.710348, acc: 53.12%] [G loss: 3.152573]\n",
      "epoch:22 step:17933 [D loss: 1.262415, acc: 21.88%] [G loss: 1.910677]\n",
      "epoch:22 step:17934 [D loss: 0.132704, acc: 99.22%] [G loss: 3.375002]\n",
      "epoch:22 step:17935 [D loss: 0.194641, acc: 100.00%] [G loss: 3.964167]\n",
      "epoch:22 step:17936 [D loss: 0.621340, acc: 59.38%] [G loss: 3.779509]\n",
      "epoch:22 step:17937 [D loss: 0.909296, acc: 31.25%] [G loss: 2.395130]\n",
      "epoch:22 step:17938 [D loss: 0.882385, acc: 40.62%] [G loss: 2.652122]\n",
      "epoch:22 step:17939 [D loss: 0.591595, acc: 63.28%] [G loss: 2.229070]\n",
      "epoch:22 step:17940 [D loss: 0.854045, acc: 39.06%] [G loss: 3.375303]\n",
      "epoch:22 step:17941 [D loss: 0.331969, acc: 90.62%] [G loss: 2.336177]\n",
      "epoch:22 step:17942 [D loss: 0.223073, acc: 99.22%] [G loss: 3.246002]\n",
      "epoch:22 step:17943 [D loss: 0.958335, acc: 29.69%] [G loss: 1.837038]\n",
      "epoch:22 step:17944 [D loss: 0.370943, acc: 93.75%] [G loss: 4.300716]\n",
      "epoch:22 step:17945 [D loss: 0.710528, acc: 54.69%] [G loss: 2.774363]\n",
      "epoch:22 step:17946 [D loss: 0.682033, acc: 54.69%] [G loss: 4.074822]\n",
      "epoch:22 step:17947 [D loss: 0.625305, acc: 63.28%] [G loss: 2.400467]\n",
      "epoch:22 step:17948 [D loss: 0.765354, acc: 46.88%] [G loss: 3.115124]\n",
      "epoch:22 step:17949 [D loss: 0.426297, acc: 88.28%] [G loss: 3.450062]\n",
      "epoch:22 step:17950 [D loss: 0.619629, acc: 61.72%] [G loss: 3.076582]\n",
      "epoch:22 step:17951 [D loss: 0.474507, acc: 89.06%] [G loss: 2.315106]\n",
      "epoch:22 step:17952 [D loss: 0.319023, acc: 97.66%] [G loss: 2.585902]\n",
      "epoch:22 step:17953 [D loss: 0.778969, acc: 54.69%] [G loss: 2.867207]\n",
      "epoch:22 step:17954 [D loss: 0.546130, acc: 71.88%] [G loss: 2.085507]\n",
      "epoch:22 step:17955 [D loss: 0.046287, acc: 100.00%] [G loss: 4.451890]\n",
      "epoch:22 step:17956 [D loss: 0.419167, acc: 87.50%] [G loss: 3.531983]\n",
      "epoch:22 step:17957 [D loss: 0.839405, acc: 35.94%] [G loss: 2.707444]\n",
      "epoch:22 step:17958 [D loss: 0.331046, acc: 96.09%] [G loss: 3.920991]\n",
      "epoch:22 step:17959 [D loss: 0.683305, acc: 57.81%] [G loss: 2.225443]\n",
      "epoch:22 step:17960 [D loss: 0.885014, acc: 50.78%] [G loss: 2.542918]\n",
      "epoch:22 step:17961 [D loss: 0.830089, acc: 41.41%] [G loss: 3.029061]\n",
      "epoch:22 step:17962 [D loss: 0.750344, acc: 51.56%] [G loss: 2.022043]\n",
      "epoch:22 step:17963 [D loss: 0.323066, acc: 88.28%] [G loss: 2.214927]\n",
      "epoch:23 step:17964 [D loss: 0.333388, acc: 92.97%] [G loss: 2.809336]\n",
      "epoch:23 step:17965 [D loss: 0.604751, acc: 60.94%] [G loss: 2.565104]\n",
      "epoch:23 step:17966 [D loss: 0.571581, acc: 74.22%] [G loss: 2.229316]\n",
      "epoch:23 step:17967 [D loss: 0.631187, acc: 62.50%] [G loss: 2.222539]\n",
      "epoch:23 step:17968 [D loss: 0.248011, acc: 97.66%] [G loss: 3.132245]\n",
      "epoch:23 step:17969 [D loss: 0.392648, acc: 83.59%] [G loss: 2.489968]\n",
      "epoch:23 step:17970 [D loss: 0.471133, acc: 82.81%] [G loss: 2.297384]\n",
      "epoch:23 step:17971 [D loss: 0.828648, acc: 41.41%] [G loss: 1.976134]\n",
      "epoch:23 step:17972 [D loss: 0.343082, acc: 89.06%] [G loss: 2.524575]\n",
      "epoch:23 step:17973 [D loss: 0.610564, acc: 67.19%] [G loss: 3.411258]\n",
      "epoch:23 step:17974 [D loss: 0.496079, acc: 78.12%] [G loss: 2.587051]\n",
      "epoch:23 step:17975 [D loss: 0.210532, acc: 96.09%] [G loss: 2.431180]\n",
      "epoch:23 step:17976 [D loss: 0.568409, acc: 71.09%] [G loss: 2.369479]\n",
      "epoch:23 step:17977 [D loss: 0.490225, acc: 84.38%] [G loss: 2.781714]\n",
      "epoch:23 step:17978 [D loss: 0.368494, acc: 95.31%] [G loss: 2.884679]\n",
      "epoch:23 step:17979 [D loss: 0.222427, acc: 100.00%] [G loss: 3.342592]\n",
      "epoch:23 step:17980 [D loss: 0.378589, acc: 91.41%] [G loss: 2.962293]\n",
      "epoch:23 step:17981 [D loss: 0.831651, acc: 50.78%] [G loss: 1.938113]\n",
      "epoch:23 step:17982 [D loss: 0.552437, acc: 60.16%] [G loss: 2.526195]\n",
      "epoch:23 step:17983 [D loss: 0.119542, acc: 100.00%] [G loss: 3.870693]\n",
      "epoch:23 step:17984 [D loss: 0.917172, acc: 32.81%] [G loss: 3.113387]\n",
      "epoch:23 step:17985 [D loss: 0.506477, acc: 64.06%] [G loss: 2.729569]\n",
      "epoch:23 step:17986 [D loss: 0.449216, acc: 81.25%] [G loss: 1.972881]\n",
      "epoch:23 step:17987 [D loss: 1.067967, acc: 39.06%] [G loss: 2.416076]\n",
      "epoch:23 step:17988 [D loss: 0.564880, acc: 73.44%] [G loss: 2.259635]\n",
      "epoch:23 step:17989 [D loss: 0.333920, acc: 87.50%] [G loss: 3.158784]\n",
      "epoch:23 step:17990 [D loss: 0.298049, acc: 96.88%] [G loss: 2.773317]\n",
      "epoch:23 step:17991 [D loss: 0.323991, acc: 92.19%] [G loss: 2.131935]\n",
      "epoch:23 step:17992 [D loss: 0.548930, acc: 66.41%] [G loss: 3.034362]\n",
      "epoch:23 step:17993 [D loss: 0.459176, acc: 87.50%] [G loss: 3.211385]\n",
      "epoch:23 step:17994 [D loss: 0.132381, acc: 99.22%] [G loss: 3.291796]\n",
      "epoch:23 step:17995 [D loss: 0.362543, acc: 84.38%] [G loss: 2.346798]\n",
      "epoch:23 step:17996 [D loss: 0.801613, acc: 51.56%] [G loss: 3.856782]\n",
      "epoch:23 step:17997 [D loss: 0.478917, acc: 75.00%] [G loss: 2.315210]\n",
      "epoch:23 step:17998 [D loss: 0.429132, acc: 87.50%] [G loss: 2.739594]\n",
      "epoch:23 step:17999 [D loss: 0.331919, acc: 93.75%] [G loss: 3.322891]\n",
      "epoch:23 step:18000 [D loss: 0.568401, acc: 68.75%] [G loss: 2.711712]\n",
      "epoch:23 step:18001 [D loss: 0.752025, acc: 47.66%] [G loss: 2.065875]\n",
      "epoch:23 step:18002 [D loss: 1.136096, acc: 26.56%] [G loss: 2.547970]\n",
      "epoch:23 step:18003 [D loss: 0.259898, acc: 92.97%] [G loss: 3.349036]\n",
      "epoch:23 step:18004 [D loss: 0.700703, acc: 54.69%] [G loss: 2.529851]\n",
      "epoch:23 step:18005 [D loss: 0.553124, acc: 67.97%] [G loss: 2.698788]\n",
      "epoch:23 step:18006 [D loss: 1.047908, acc: 17.97%] [G loss: 3.117319]\n",
      "epoch:23 step:18007 [D loss: 0.733829, acc: 50.00%] [G loss: 1.839205]\n",
      "epoch:23 step:18008 [D loss: 0.468956, acc: 85.16%] [G loss: 2.616008]\n",
      "epoch:23 step:18009 [D loss: 0.645176, acc: 56.25%] [G loss: 1.947161]\n",
      "epoch:23 step:18010 [D loss: 0.881037, acc: 42.19%] [G loss: 2.216527]\n",
      "epoch:23 step:18011 [D loss: 0.586614, acc: 65.62%] [G loss: 2.331359]\n",
      "epoch:23 step:18012 [D loss: 0.570568, acc: 76.56%] [G loss: 2.914678]\n",
      "epoch:23 step:18013 [D loss: 0.480552, acc: 81.25%] [G loss: 3.475305]\n",
      "epoch:23 step:18014 [D loss: 0.208113, acc: 98.44%] [G loss: 2.835703]\n",
      "epoch:23 step:18015 [D loss: 0.369722, acc: 78.12%] [G loss: 2.997848]\n",
      "epoch:23 step:18016 [D loss: 0.557451, acc: 75.78%] [G loss: 2.744223]\n",
      "epoch:23 step:18017 [D loss: 0.920048, acc: 28.91%] [G loss: 2.386015]\n",
      "epoch:23 step:18018 [D loss: 0.986626, acc: 32.03%] [G loss: 2.058700]\n",
      "epoch:23 step:18019 [D loss: 0.321757, acc: 91.41%] [G loss: 2.271682]\n",
      "epoch:23 step:18020 [D loss: 0.305743, acc: 96.88%] [G loss: 2.401890]\n",
      "epoch:23 step:18021 [D loss: 0.538556, acc: 71.09%] [G loss: 1.902381]\n",
      "epoch:23 step:18022 [D loss: 0.418096, acc: 85.16%] [G loss: 2.253422]\n",
      "epoch:23 step:18023 [D loss: 0.433020, acc: 86.72%] [G loss: 1.769700]\n",
      "epoch:23 step:18024 [D loss: 0.740878, acc: 50.78%] [G loss: 1.730037]\n",
      "epoch:23 step:18025 [D loss: 0.493537, acc: 78.12%] [G loss: 4.329104]\n",
      "epoch:23 step:18026 [D loss: 0.308580, acc: 92.97%] [G loss: 3.232322]\n",
      "epoch:23 step:18027 [D loss: 0.391937, acc: 91.41%] [G loss: 2.180018]\n",
      "epoch:23 step:18028 [D loss: 0.714189, acc: 60.94%] [G loss: 1.982576]\n",
      "epoch:23 step:18029 [D loss: 0.790098, acc: 42.97%] [G loss: 2.658861]\n",
      "epoch:23 step:18030 [D loss: 0.664752, acc: 63.28%] [G loss: 1.923987]\n",
      "epoch:23 step:18031 [D loss: 0.326050, acc: 94.53%] [G loss: 2.677134]\n",
      "epoch:23 step:18032 [D loss: 0.536772, acc: 71.88%] [G loss: 1.975857]\n",
      "epoch:23 step:18033 [D loss: 0.740939, acc: 52.34%] [G loss: 3.945301]\n",
      "epoch:23 step:18034 [D loss: 0.882500, acc: 50.78%] [G loss: 3.295640]\n",
      "epoch:23 step:18035 [D loss: 0.502928, acc: 78.12%] [G loss: 2.489244]\n",
      "epoch:23 step:18036 [D loss: 0.492299, acc: 74.22%] [G loss: 3.044986]\n",
      "epoch:23 step:18037 [D loss: 0.700242, acc: 53.12%] [G loss: 2.522009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18038 [D loss: 0.391721, acc: 89.06%] [G loss: 3.130291]\n",
      "epoch:23 step:18039 [D loss: 0.195056, acc: 100.00%] [G loss: 3.560848]\n",
      "epoch:23 step:18040 [D loss: 0.792707, acc: 48.44%] [G loss: 2.734385]\n",
      "epoch:23 step:18041 [D loss: 0.469980, acc: 83.59%] [G loss: 2.890231]\n",
      "epoch:23 step:18042 [D loss: 0.359827, acc: 84.38%] [G loss: 3.056547]\n",
      "epoch:23 step:18043 [D loss: 0.119138, acc: 99.22%] [G loss: 2.457119]\n",
      "epoch:23 step:18044 [D loss: 0.555626, acc: 69.53%] [G loss: 2.271939]\n",
      "epoch:23 step:18045 [D loss: 0.665970, acc: 58.59%] [G loss: 2.592801]\n",
      "epoch:23 step:18046 [D loss: 0.157063, acc: 100.00%] [G loss: 2.528165]\n",
      "epoch:23 step:18047 [D loss: 0.885478, acc: 31.25%] [G loss: 1.624391]\n",
      "epoch:23 step:18048 [D loss: 0.804228, acc: 36.72%] [G loss: 2.578389]\n",
      "epoch:23 step:18049 [D loss: 0.567195, acc: 73.44%] [G loss: 3.371175]\n",
      "epoch:23 step:18050 [D loss: 0.545064, acc: 77.34%] [G loss: 1.876886]\n",
      "epoch:23 step:18051 [D loss: 1.023383, acc: 21.88%] [G loss: 3.300653]\n",
      "epoch:23 step:18052 [D loss: 0.416947, acc: 85.94%] [G loss: 2.669727]\n",
      "epoch:23 step:18053 [D loss: 0.452625, acc: 86.72%] [G loss: 2.917818]\n",
      "epoch:23 step:18054 [D loss: 0.506495, acc: 77.34%] [G loss: 3.591752]\n",
      "epoch:23 step:18055 [D loss: 0.329562, acc: 95.31%] [G loss: 2.974294]\n",
      "epoch:23 step:18056 [D loss: 0.944489, acc: 25.00%] [G loss: 2.375153]\n",
      "epoch:23 step:18057 [D loss: 0.779974, acc: 52.34%] [G loss: 1.971200]\n",
      "epoch:23 step:18058 [D loss: 0.407640, acc: 89.84%] [G loss: 2.651197]\n",
      "epoch:23 step:18059 [D loss: 1.107566, acc: 42.97%] [G loss: 2.480783]\n",
      "epoch:23 step:18060 [D loss: 0.300051, acc: 98.44%] [G loss: 2.741264]\n",
      "epoch:23 step:18061 [D loss: 0.922394, acc: 28.91%] [G loss: 2.847586]\n",
      "epoch:23 step:18062 [D loss: 0.250946, acc: 97.66%] [G loss: 2.478484]\n",
      "epoch:23 step:18063 [D loss: 0.686999, acc: 58.59%] [G loss: 2.612643]\n",
      "epoch:23 step:18064 [D loss: 0.432554, acc: 71.88%] [G loss: 3.501762]\n",
      "epoch:23 step:18065 [D loss: 0.493991, acc: 83.59%] [G loss: 2.722268]\n",
      "epoch:23 step:18066 [D loss: 0.899671, acc: 32.03%] [G loss: 3.032434]\n",
      "epoch:23 step:18067 [D loss: 0.758962, acc: 51.56%] [G loss: 2.865904]\n",
      "epoch:23 step:18068 [D loss: 0.562660, acc: 64.06%] [G loss: 2.695515]\n",
      "epoch:23 step:18069 [D loss: 0.678614, acc: 58.59%] [G loss: 2.226356]\n",
      "epoch:23 step:18070 [D loss: 1.134326, acc: 20.31%] [G loss: 2.880484]\n",
      "epoch:23 step:18071 [D loss: 0.538479, acc: 81.25%] [G loss: 2.862491]\n",
      "epoch:23 step:18072 [D loss: 0.835773, acc: 53.12%] [G loss: 1.615323]\n",
      "epoch:23 step:18073 [D loss: 0.948573, acc: 26.56%] [G loss: 1.860478]\n",
      "epoch:23 step:18074 [D loss: 0.229871, acc: 94.53%] [G loss: 4.187383]\n",
      "epoch:23 step:18075 [D loss: 0.565681, acc: 74.22%] [G loss: 3.593141]\n",
      "epoch:23 step:18076 [D loss: 0.426055, acc: 85.16%] [G loss: 3.202530]\n",
      "epoch:23 step:18077 [D loss: 0.412198, acc: 85.94%] [G loss: 2.225083]\n",
      "epoch:23 step:18078 [D loss: 0.358958, acc: 88.28%] [G loss: 3.074721]\n",
      "epoch:23 step:18079 [D loss: 0.370254, acc: 85.16%] [G loss: 2.982217]\n",
      "epoch:23 step:18080 [D loss: 0.402682, acc: 85.94%] [G loss: 2.939250]\n",
      "epoch:23 step:18081 [D loss: 0.131125, acc: 99.22%] [G loss: 2.591523]\n",
      "epoch:23 step:18082 [D loss: 0.259482, acc: 96.88%] [G loss: 2.422094]\n",
      "epoch:23 step:18083 [D loss: 0.449240, acc: 72.66%] [G loss: 2.020745]\n",
      "epoch:23 step:18084 [D loss: 0.998294, acc: 35.16%] [G loss: 1.672631]\n",
      "epoch:23 step:18085 [D loss: 0.285347, acc: 92.19%] [G loss: 3.751632]\n",
      "epoch:23 step:18086 [D loss: 0.321150, acc: 91.41%] [G loss: 2.324684]\n",
      "epoch:23 step:18087 [D loss: 0.681089, acc: 52.34%] [G loss: 3.279649]\n",
      "epoch:23 step:18088 [D loss: 0.584124, acc: 61.72%] [G loss: 2.195793]\n",
      "epoch:23 step:18089 [D loss: 0.306151, acc: 96.88%] [G loss: 2.437798]\n",
      "epoch:23 step:18090 [D loss: 0.810505, acc: 42.97%] [G loss: 2.007887]\n",
      "epoch:23 step:18091 [D loss: 0.623139, acc: 62.50%] [G loss: 1.870642]\n",
      "epoch:23 step:18092 [D loss: 0.380480, acc: 89.84%] [G loss: 1.613690]\n",
      "epoch:23 step:18093 [D loss: 0.523841, acc: 67.19%] [G loss: 2.820898]\n",
      "epoch:23 step:18094 [D loss: 0.903366, acc: 48.44%] [G loss: 2.827622]\n",
      "epoch:23 step:18095 [D loss: 0.605224, acc: 58.59%] [G loss: 2.797949]\n",
      "epoch:23 step:18096 [D loss: 0.520917, acc: 64.84%] [G loss: 2.252740]\n",
      "epoch:23 step:18097 [D loss: 0.438228, acc: 85.94%] [G loss: 2.727939]\n",
      "epoch:23 step:18098 [D loss: 0.623735, acc: 64.84%] [G loss: 2.380285]\n",
      "epoch:23 step:18099 [D loss: 0.324949, acc: 96.09%] [G loss: 3.053436]\n",
      "epoch:23 step:18100 [D loss: 0.748558, acc: 47.66%] [G loss: 2.929385]\n",
      "epoch:23 step:18101 [D loss: 0.410914, acc: 85.16%] [G loss: 3.906598]\n",
      "epoch:23 step:18102 [D loss: 0.367639, acc: 89.84%] [G loss: 2.863423]\n",
      "epoch:23 step:18103 [D loss: 0.676325, acc: 60.94%] [G loss: 2.516252]\n",
      "epoch:23 step:18104 [D loss: 0.301756, acc: 96.88%] [G loss: 2.513360]\n",
      "epoch:23 step:18105 [D loss: 0.559788, acc: 78.12%] [G loss: 2.539184]\n",
      "epoch:23 step:18106 [D loss: 0.808181, acc: 40.62%] [G loss: 3.072540]\n",
      "epoch:23 step:18107 [D loss: 0.418853, acc: 78.91%] [G loss: 2.910503]\n",
      "epoch:23 step:18108 [D loss: 0.562676, acc: 69.53%] [G loss: 2.242893]\n",
      "epoch:23 step:18109 [D loss: 0.209279, acc: 99.22%] [G loss: 3.397170]\n",
      "epoch:23 step:18110 [D loss: 0.402418, acc: 93.75%] [G loss: 3.360962]\n",
      "epoch:23 step:18111 [D loss: 0.367591, acc: 82.81%] [G loss: 2.441968]\n",
      "epoch:23 step:18112 [D loss: 0.761136, acc: 53.91%] [G loss: 2.781207]\n",
      "epoch:23 step:18113 [D loss: 0.923024, acc: 50.00%] [G loss: 3.140120]\n",
      "epoch:23 step:18114 [D loss: 0.612083, acc: 62.50%] [G loss: 4.124941]\n",
      "epoch:23 step:18115 [D loss: 0.332528, acc: 96.88%] [G loss: 2.026416]\n",
      "epoch:23 step:18116 [D loss: 0.653785, acc: 53.91%] [G loss: 3.013663]\n",
      "epoch:23 step:18117 [D loss: 0.293015, acc: 96.09%] [G loss: 3.327793]\n",
      "epoch:23 step:18118 [D loss: 0.578424, acc: 71.88%] [G loss: 2.308198]\n",
      "epoch:23 step:18119 [D loss: 0.917345, acc: 35.16%] [G loss: 1.728249]\n",
      "epoch:23 step:18120 [D loss: 0.228488, acc: 100.00%] [G loss: 2.613116]\n",
      "epoch:23 step:18121 [D loss: 0.424955, acc: 92.97%] [G loss: 3.368089]\n",
      "epoch:23 step:18122 [D loss: 0.326384, acc: 95.31%] [G loss: 3.308216]\n",
      "epoch:23 step:18123 [D loss: 0.815847, acc: 49.22%] [G loss: 2.702586]\n",
      "epoch:23 step:18124 [D loss: 0.247727, acc: 97.66%] [G loss: 3.165184]\n",
      "epoch:23 step:18125 [D loss: 0.478789, acc: 66.41%] [G loss: 2.264982]\n",
      "epoch:23 step:18126 [D loss: 1.119685, acc: 20.31%] [G loss: 2.544715]\n",
      "epoch:23 step:18127 [D loss: 0.745357, acc: 48.44%] [G loss: 3.058831]\n",
      "epoch:23 step:18128 [D loss: 0.569389, acc: 60.16%] [G loss: 2.358249]\n",
      "epoch:23 step:18129 [D loss: 0.415975, acc: 86.72%] [G loss: 2.877390]\n",
      "epoch:23 step:18130 [D loss: 0.471291, acc: 84.38%] [G loss: 1.994020]\n",
      "epoch:23 step:18131 [D loss: 0.927471, acc: 33.59%] [G loss: 1.927111]\n",
      "epoch:23 step:18132 [D loss: 0.594522, acc: 60.94%] [G loss: 2.299525]\n",
      "epoch:23 step:18133 [D loss: 0.596507, acc: 60.16%] [G loss: 2.281415]\n",
      "epoch:23 step:18134 [D loss: 0.603369, acc: 68.75%] [G loss: 2.568330]\n",
      "epoch:23 step:18135 [D loss: 0.630737, acc: 60.16%] [G loss: 1.924286]\n",
      "epoch:23 step:18136 [D loss: 1.203740, acc: 10.16%] [G loss: 2.678093]\n",
      "epoch:23 step:18137 [D loss: 0.404728, acc: 85.94%] [G loss: 3.098422]\n",
      "epoch:23 step:18138 [D loss: 0.232517, acc: 97.66%] [G loss: 2.391345]\n",
      "epoch:23 step:18139 [D loss: 1.414530, acc: 7.03%] [G loss: 2.337699]\n",
      "epoch:23 step:18140 [D loss: 0.390549, acc: 83.59%] [G loss: 2.557096]\n",
      "epoch:23 step:18141 [D loss: 0.371862, acc: 94.53%] [G loss: 3.425263]\n",
      "epoch:23 step:18142 [D loss: 0.380107, acc: 92.19%] [G loss: 3.167082]\n",
      "epoch:23 step:18143 [D loss: 1.106820, acc: 7.81%] [G loss: 1.760562]\n",
      "epoch:23 step:18144 [D loss: 0.607668, acc: 68.75%] [G loss: 2.910287]\n",
      "epoch:23 step:18145 [D loss: 0.569339, acc: 67.97%] [G loss: 2.430590]\n",
      "epoch:23 step:18146 [D loss: 0.494236, acc: 84.38%] [G loss: 2.367696]\n",
      "epoch:23 step:18147 [D loss: 0.461937, acc: 76.56%] [G loss: 1.776400]\n",
      "epoch:23 step:18148 [D loss: 0.519571, acc: 67.97%] [G loss: 3.043056]\n",
      "epoch:23 step:18149 [D loss: 0.453712, acc: 88.28%] [G loss: 2.436257]\n",
      "epoch:23 step:18150 [D loss: 0.473728, acc: 70.31%] [G loss: 2.972687]\n",
      "epoch:23 step:18151 [D loss: 0.682781, acc: 56.25%] [G loss: 2.858434]\n",
      "epoch:23 step:18152 [D loss: 0.224484, acc: 100.00%] [G loss: 3.456896]\n",
      "epoch:23 step:18153 [D loss: 0.898813, acc: 35.16%] [G loss: 2.217727]\n",
      "epoch:23 step:18154 [D loss: 0.430892, acc: 89.84%] [G loss: 2.459603]\n",
      "epoch:23 step:18155 [D loss: 0.614554, acc: 68.75%] [G loss: 2.172832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18156 [D loss: 0.483973, acc: 83.59%] [G loss: 2.837521]\n",
      "epoch:23 step:18157 [D loss: 0.260784, acc: 96.09%] [G loss: 3.149883]\n",
      "epoch:23 step:18158 [D loss: 0.412546, acc: 91.41%] [G loss: 2.862035]\n",
      "epoch:23 step:18159 [D loss: 0.632247, acc: 66.41%] [G loss: 2.316590]\n",
      "epoch:23 step:18160 [D loss: 0.939761, acc: 27.34%] [G loss: 2.735343]\n",
      "epoch:23 step:18161 [D loss: 0.216860, acc: 98.44%] [G loss: 4.315780]\n",
      "epoch:23 step:18162 [D loss: 0.380703, acc: 87.50%] [G loss: 2.931418]\n",
      "epoch:23 step:18163 [D loss: 0.865848, acc: 50.00%] [G loss: 2.635974]\n",
      "epoch:23 step:18164 [D loss: 0.430738, acc: 88.28%] [G loss: 3.139598]\n",
      "epoch:23 step:18165 [D loss: 0.874680, acc: 49.22%] [G loss: 2.290546]\n",
      "epoch:23 step:18166 [D loss: 0.594336, acc: 71.88%] [G loss: 2.623286]\n",
      "epoch:23 step:18167 [D loss: 0.541676, acc: 73.44%] [G loss: 2.274811]\n",
      "epoch:23 step:18168 [D loss: 0.599590, acc: 69.53%] [G loss: 1.875246]\n",
      "epoch:23 step:18169 [D loss: 1.112229, acc: 15.62%] [G loss: 2.100812]\n",
      "epoch:23 step:18170 [D loss: 0.797378, acc: 48.44%] [G loss: 2.309979]\n",
      "epoch:23 step:18171 [D loss: 0.506007, acc: 74.22%] [G loss: 2.433621]\n",
      "epoch:23 step:18172 [D loss: 0.612992, acc: 64.84%] [G loss: 2.843396]\n",
      "epoch:23 step:18173 [D loss: 0.681062, acc: 60.16%] [G loss: 2.304307]\n",
      "epoch:23 step:18174 [D loss: 0.769885, acc: 50.78%] [G loss: 1.701769]\n",
      "epoch:23 step:18175 [D loss: 0.256444, acc: 93.75%] [G loss: 2.901670]\n",
      "epoch:23 step:18176 [D loss: 0.744361, acc: 53.12%] [G loss: 2.233368]\n",
      "epoch:23 step:18177 [D loss: 0.219341, acc: 99.22%] [G loss: 3.086329]\n",
      "epoch:23 step:18178 [D loss: 0.500595, acc: 85.16%] [G loss: 2.409472]\n",
      "epoch:23 step:18179 [D loss: 0.451465, acc: 80.47%] [G loss: 2.698989]\n",
      "epoch:23 step:18180 [D loss: 0.519062, acc: 76.56%] [G loss: 1.743273]\n",
      "epoch:23 step:18181 [D loss: 0.581345, acc: 64.84%] [G loss: 3.565424]\n",
      "epoch:23 step:18182 [D loss: 0.479675, acc: 80.47%] [G loss: 2.787039]\n",
      "epoch:23 step:18183 [D loss: 0.681543, acc: 62.50%] [G loss: 2.994236]\n",
      "epoch:23 step:18184 [D loss: 0.929577, acc: 50.00%] [G loss: 1.801605]\n",
      "epoch:23 step:18185 [D loss: 0.356429, acc: 93.75%] [G loss: 2.998570]\n",
      "epoch:23 step:18186 [D loss: 0.752433, acc: 51.56%] [G loss: 3.002369]\n",
      "epoch:23 step:18187 [D loss: 0.588643, acc: 71.88%] [G loss: 2.360224]\n",
      "epoch:23 step:18188 [D loss: 0.508795, acc: 67.19%] [G loss: 2.964700]\n",
      "epoch:23 step:18189 [D loss: 0.630319, acc: 68.75%] [G loss: 2.181543]\n",
      "epoch:23 step:18190 [D loss: 0.287213, acc: 98.44%] [G loss: 3.154720]\n",
      "epoch:23 step:18191 [D loss: 0.621321, acc: 62.50%] [G loss: 2.640022]\n",
      "epoch:23 step:18192 [D loss: 0.843676, acc: 39.84%] [G loss: 3.400902]\n",
      "epoch:23 step:18193 [D loss: 1.790138, acc: 12.50%] [G loss: 2.883629]\n",
      "epoch:23 step:18194 [D loss: 0.593847, acc: 63.28%] [G loss: 2.076462]\n",
      "epoch:23 step:18195 [D loss: 0.883576, acc: 32.81%] [G loss: 2.489510]\n",
      "epoch:23 step:18196 [D loss: 0.662111, acc: 59.38%] [G loss: 1.968324]\n",
      "epoch:23 step:18197 [D loss: 0.923786, acc: 45.31%] [G loss: 2.108052]\n",
      "epoch:23 step:18198 [D loss: 0.545690, acc: 75.78%] [G loss: 2.640311]\n",
      "epoch:23 step:18199 [D loss: 0.343321, acc: 93.75%] [G loss: 3.102050]\n",
      "epoch:23 step:18200 [D loss: 0.399374, acc: 78.91%] [G loss: 2.507885]\n",
      "epoch:23 step:18201 [D loss: 0.745257, acc: 54.69%] [G loss: 1.523845]\n",
      "epoch:23 step:18202 [D loss: 0.748995, acc: 52.34%] [G loss: 2.201839]\n",
      "epoch:23 step:18203 [D loss: 0.523515, acc: 75.78%] [G loss: 2.653291]\n",
      "epoch:23 step:18204 [D loss: 0.606233, acc: 67.19%] [G loss: 3.979167]\n",
      "epoch:23 step:18205 [D loss: 0.368213, acc: 92.19%] [G loss: 2.767044]\n",
      "epoch:23 step:18206 [D loss: 0.422842, acc: 86.72%] [G loss: 2.460526]\n",
      "epoch:23 step:18207 [D loss: 0.540283, acc: 73.44%] [G loss: 2.924111]\n",
      "epoch:23 step:18208 [D loss: 0.676471, acc: 64.06%] [G loss: 1.798442]\n",
      "epoch:23 step:18209 [D loss: 0.330662, acc: 96.09%] [G loss: 2.439456]\n",
      "epoch:23 step:18210 [D loss: 0.682062, acc: 57.03%] [G loss: 2.339511]\n",
      "epoch:23 step:18211 [D loss: 0.828456, acc: 45.31%] [G loss: 1.797552]\n",
      "epoch:23 step:18212 [D loss: 0.459425, acc: 85.16%] [G loss: 2.657957]\n",
      "epoch:23 step:18213 [D loss: 0.704692, acc: 50.78%] [G loss: 2.610124]\n",
      "epoch:23 step:18214 [D loss: 0.391679, acc: 85.16%] [G loss: 3.146424]\n",
      "epoch:23 step:18215 [D loss: 1.055936, acc: 45.31%] [G loss: 2.099620]\n",
      "epoch:23 step:18216 [D loss: 0.864933, acc: 33.59%] [G loss: 2.389609]\n",
      "epoch:23 step:18217 [D loss: 0.707532, acc: 56.25%] [G loss: 2.515779]\n",
      "epoch:23 step:18218 [D loss: 0.476986, acc: 80.47%] [G loss: 2.893264]\n",
      "epoch:23 step:18219 [D loss: 0.423205, acc: 89.84%] [G loss: 2.458812]\n",
      "epoch:23 step:18220 [D loss: 0.948226, acc: 34.38%] [G loss: 2.190622]\n",
      "epoch:23 step:18221 [D loss: 0.466953, acc: 84.38%] [G loss: 2.579116]\n",
      "epoch:23 step:18222 [D loss: 0.666285, acc: 57.03%] [G loss: 2.657832]\n",
      "epoch:23 step:18223 [D loss: 0.712807, acc: 58.59%] [G loss: 2.456709]\n",
      "epoch:23 step:18224 [D loss: 0.667560, acc: 53.12%] [G loss: 3.176715]\n",
      "epoch:23 step:18225 [D loss: 0.378839, acc: 91.41%] [G loss: 3.460870]\n",
      "epoch:23 step:18226 [D loss: 0.972799, acc: 26.56%] [G loss: 1.914579]\n",
      "epoch:23 step:18227 [D loss: 0.326510, acc: 96.88%] [G loss: 3.079688]\n",
      "epoch:23 step:18228 [D loss: 0.647163, acc: 56.25%] [G loss: 2.850299]\n",
      "epoch:23 step:18229 [D loss: 0.852129, acc: 42.97%] [G loss: 3.350357]\n",
      "epoch:23 step:18230 [D loss: 0.438356, acc: 81.25%] [G loss: 1.675986]\n",
      "epoch:23 step:18231 [D loss: 0.435262, acc: 92.97%] [G loss: 3.389889]\n",
      "epoch:23 step:18232 [D loss: 0.568745, acc: 73.44%] [G loss: 2.807264]\n",
      "epoch:23 step:18233 [D loss: 0.638497, acc: 63.28%] [G loss: 2.180274]\n",
      "epoch:23 step:18234 [D loss: 0.357428, acc: 92.19%] [G loss: 2.891203]\n",
      "epoch:23 step:18235 [D loss: 0.663288, acc: 54.69%] [G loss: 2.050982]\n",
      "epoch:23 step:18236 [D loss: 0.657012, acc: 62.50%] [G loss: 1.767308]\n",
      "epoch:23 step:18237 [D loss: 0.632713, acc: 65.62%] [G loss: 1.779990]\n",
      "epoch:23 step:18238 [D loss: 0.364071, acc: 81.25%] [G loss: 2.808638]\n",
      "epoch:23 step:18239 [D loss: 0.717109, acc: 51.56%] [G loss: 2.284594]\n",
      "epoch:23 step:18240 [D loss: 0.409717, acc: 83.59%] [G loss: 2.825530]\n",
      "epoch:23 step:18241 [D loss: 0.458192, acc: 85.16%] [G loss: 2.619535]\n",
      "epoch:23 step:18242 [D loss: 0.430872, acc: 86.72%] [G loss: 2.789246]\n",
      "epoch:23 step:18243 [D loss: 0.430084, acc: 85.16%] [G loss: 2.896906]\n",
      "epoch:23 step:18244 [D loss: 0.667072, acc: 64.84%] [G loss: 2.298865]\n",
      "epoch:23 step:18245 [D loss: 0.427018, acc: 90.62%] [G loss: 2.515608]\n",
      "epoch:23 step:18246 [D loss: 0.718304, acc: 48.44%] [G loss: 1.944192]\n",
      "epoch:23 step:18247 [D loss: 0.485849, acc: 82.81%] [G loss: 2.338612]\n",
      "epoch:23 step:18248 [D loss: 0.542972, acc: 74.22%] [G loss: 2.035421]\n",
      "epoch:23 step:18249 [D loss: 0.332842, acc: 92.19%] [G loss: 2.956024]\n",
      "epoch:23 step:18250 [D loss: 0.505947, acc: 71.09%] [G loss: 2.146550]\n",
      "epoch:23 step:18251 [D loss: 0.590717, acc: 71.88%] [G loss: 2.066681]\n",
      "epoch:23 step:18252 [D loss: 0.473774, acc: 73.44%] [G loss: 2.693523]\n",
      "epoch:23 step:18253 [D loss: 0.595138, acc: 71.88%] [G loss: 1.972677]\n",
      "epoch:23 step:18254 [D loss: 1.050320, acc: 21.09%] [G loss: 1.420118]\n",
      "epoch:23 step:18255 [D loss: 0.407092, acc: 86.72%] [G loss: 3.001631]\n",
      "epoch:23 step:18256 [D loss: 0.525074, acc: 77.34%] [G loss: 2.610729]\n",
      "epoch:23 step:18257 [D loss: 0.489831, acc: 81.25%] [G loss: 1.929694]\n",
      "epoch:23 step:18258 [D loss: 0.364192, acc: 87.50%] [G loss: 3.610950]\n",
      "epoch:23 step:18259 [D loss: 0.329897, acc: 94.53%] [G loss: 2.579068]\n",
      "epoch:23 step:18260 [D loss: 0.532221, acc: 80.47%] [G loss: 2.657789]\n",
      "epoch:23 step:18261 [D loss: 0.341935, acc: 92.97%] [G loss: 2.062053]\n",
      "epoch:23 step:18262 [D loss: 0.333119, acc: 96.09%] [G loss: 2.495999]\n",
      "epoch:23 step:18263 [D loss: 0.300078, acc: 94.53%] [G loss: 2.484548]\n",
      "epoch:23 step:18264 [D loss: 0.402705, acc: 92.19%] [G loss: 2.952857]\n",
      "epoch:23 step:18265 [D loss: 0.471337, acc: 87.50%] [G loss: 3.265913]\n",
      "epoch:23 step:18266 [D loss: 0.581093, acc: 60.94%] [G loss: 2.428627]\n",
      "epoch:23 step:18267 [D loss: 0.240373, acc: 97.66%] [G loss: 3.675364]\n",
      "epoch:23 step:18268 [D loss: 0.446525, acc: 78.12%] [G loss: 2.632928]\n",
      "epoch:23 step:18269 [D loss: 0.652730, acc: 64.84%] [G loss: 2.259204]\n",
      "epoch:23 step:18270 [D loss: 0.532784, acc: 74.22%] [G loss: 2.360509]\n",
      "epoch:23 step:18271 [D loss: 0.515685, acc: 76.56%] [G loss: 3.035704]\n",
      "epoch:23 step:18272 [D loss: 0.370138, acc: 96.09%] [G loss: 2.637970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18273 [D loss: 0.490661, acc: 80.47%] [G loss: 2.801185]\n",
      "epoch:23 step:18274 [D loss: 0.459305, acc: 86.72%] [G loss: 2.611335]\n",
      "epoch:23 step:18275 [D loss: 0.788698, acc: 46.88%] [G loss: 2.375117]\n",
      "epoch:23 step:18276 [D loss: 0.833563, acc: 44.53%] [G loss: 1.918697]\n",
      "epoch:23 step:18277 [D loss: 0.641181, acc: 60.94%] [G loss: 2.690919]\n",
      "epoch:23 step:18278 [D loss: 0.578782, acc: 71.09%] [G loss: 2.138243]\n",
      "epoch:23 step:18279 [D loss: 0.333597, acc: 86.72%] [G loss: 3.412064]\n",
      "epoch:23 step:18280 [D loss: 0.980712, acc: 21.88%] [G loss: 3.477516]\n",
      "epoch:23 step:18281 [D loss: 0.731907, acc: 48.44%] [G loss: 2.247587]\n",
      "epoch:23 step:18282 [D loss: 0.341267, acc: 95.31%] [G loss: 3.379374]\n",
      "epoch:23 step:18283 [D loss: 0.533934, acc: 62.50%] [G loss: 2.323278]\n",
      "epoch:23 step:18284 [D loss: 0.600953, acc: 71.88%] [G loss: 3.601230]\n",
      "epoch:23 step:18285 [D loss: 0.284743, acc: 95.31%] [G loss: 3.555079]\n",
      "epoch:23 step:18286 [D loss: 0.366372, acc: 91.41%] [G loss: 2.686363]\n",
      "epoch:23 step:18287 [D loss: 0.475480, acc: 82.81%] [G loss: 3.327006]\n",
      "epoch:23 step:18288 [D loss: 0.731137, acc: 47.66%] [G loss: 2.063757]\n",
      "epoch:23 step:18289 [D loss: 0.779896, acc: 46.88%] [G loss: 1.820231]\n",
      "epoch:23 step:18290 [D loss: 0.869152, acc: 31.25%] [G loss: 3.031155]\n",
      "epoch:23 step:18291 [D loss: 0.363894, acc: 96.09%] [G loss: 3.853074]\n",
      "epoch:23 step:18292 [D loss: 0.546001, acc: 75.00%] [G loss: 1.952203]\n",
      "epoch:23 step:18293 [D loss: 0.659605, acc: 65.62%] [G loss: 3.707158]\n",
      "epoch:23 step:18294 [D loss: 1.147229, acc: 50.00%] [G loss: 1.639175]\n",
      "epoch:23 step:18295 [D loss: 0.908883, acc: 36.72%] [G loss: 3.302098]\n",
      "epoch:23 step:18296 [D loss: 0.495013, acc: 75.00%] [G loss: 2.973942]\n",
      "epoch:23 step:18297 [D loss: 0.482418, acc: 79.69%] [G loss: 3.012195]\n",
      "epoch:23 step:18298 [D loss: 0.758433, acc: 46.09%] [G loss: 3.869411]\n",
      "epoch:23 step:18299 [D loss: 0.408016, acc: 91.41%] [G loss: 3.949929]\n",
      "epoch:23 step:18300 [D loss: 0.360319, acc: 79.69%] [G loss: 2.539974]\n",
      "epoch:23 step:18301 [D loss: 0.419122, acc: 83.59%] [G loss: 2.229112]\n",
      "epoch:23 step:18302 [D loss: 0.333788, acc: 89.06%] [G loss: 2.338489]\n",
      "epoch:23 step:18303 [D loss: 0.733183, acc: 50.00%] [G loss: 2.061671]\n",
      "epoch:23 step:18304 [D loss: 0.381269, acc: 89.84%] [G loss: 2.708858]\n",
      "epoch:23 step:18305 [D loss: 0.914166, acc: 43.75%] [G loss: 2.701725]\n",
      "epoch:23 step:18306 [D loss: 0.450219, acc: 87.50%] [G loss: 2.775128]\n",
      "epoch:23 step:18307 [D loss: 1.018301, acc: 23.44%] [G loss: 1.944037]\n",
      "epoch:23 step:18308 [D loss: 0.362298, acc: 96.09%] [G loss: 3.419354]\n",
      "epoch:23 step:18309 [D loss: 0.847743, acc: 51.56%] [G loss: 2.819071]\n",
      "epoch:23 step:18310 [D loss: 0.563960, acc: 78.12%] [G loss: 2.676535]\n",
      "epoch:23 step:18311 [D loss: 0.481938, acc: 84.38%] [G loss: 2.333937]\n",
      "epoch:23 step:18312 [D loss: 0.365203, acc: 94.53%] [G loss: 2.256149]\n",
      "epoch:23 step:18313 [D loss: 0.609558, acc: 62.50%] [G loss: 2.151549]\n",
      "epoch:23 step:18314 [D loss: 0.645325, acc: 62.50%] [G loss: 2.659323]\n",
      "epoch:23 step:18315 [D loss: 0.517315, acc: 78.12%] [G loss: 2.050458]\n",
      "epoch:23 step:18316 [D loss: 0.368690, acc: 91.41%] [G loss: 3.006992]\n",
      "epoch:23 step:18317 [D loss: 0.678655, acc: 60.16%] [G loss: 2.407335]\n",
      "epoch:23 step:18318 [D loss: 0.534747, acc: 76.56%] [G loss: 2.748775]\n",
      "epoch:23 step:18319 [D loss: 0.243194, acc: 98.44%] [G loss: 2.747003]\n",
      "epoch:23 step:18320 [D loss: 0.214266, acc: 100.00%] [G loss: 2.792489]\n",
      "epoch:23 step:18321 [D loss: 0.387676, acc: 87.50%] [G loss: 3.263827]\n",
      "epoch:23 step:18322 [D loss: 0.636730, acc: 60.94%] [G loss: 3.279485]\n",
      "epoch:23 step:18323 [D loss: 0.461668, acc: 83.59%] [G loss: 2.284039]\n",
      "epoch:23 step:18324 [D loss: 0.574411, acc: 67.97%] [G loss: 3.258039]\n",
      "epoch:23 step:18325 [D loss: 0.327102, acc: 92.97%] [G loss: 4.044829]\n",
      "epoch:23 step:18326 [D loss: 0.626136, acc: 63.28%] [G loss: 2.389237]\n",
      "epoch:23 step:18327 [D loss: 0.521104, acc: 79.69%] [G loss: 3.087990]\n",
      "epoch:23 step:18328 [D loss: 0.332543, acc: 96.09%] [G loss: 3.127282]\n",
      "epoch:23 step:18329 [D loss: 0.504449, acc: 75.00%] [G loss: 2.986955]\n",
      "epoch:23 step:18330 [D loss: 0.666889, acc: 57.03%] [G loss: 2.378361]\n",
      "epoch:23 step:18331 [D loss: 0.257882, acc: 99.22%] [G loss: 2.527882]\n",
      "epoch:23 step:18332 [D loss: 0.330232, acc: 94.53%] [G loss: 3.585659]\n",
      "epoch:23 step:18333 [D loss: 0.520379, acc: 77.34%] [G loss: 2.680709]\n",
      "epoch:23 step:18334 [D loss: 0.636472, acc: 64.06%] [G loss: 2.385674]\n",
      "epoch:23 step:18335 [D loss: 0.751152, acc: 52.34%] [G loss: 2.617311]\n",
      "epoch:23 step:18336 [D loss: 0.423742, acc: 89.84%] [G loss: 2.503868]\n",
      "epoch:23 step:18337 [D loss: 0.378839, acc: 96.09%] [G loss: 3.628778]\n",
      "epoch:23 step:18338 [D loss: 0.390559, acc: 97.66%] [G loss: 2.176093]\n",
      "epoch:23 step:18339 [D loss: 0.756351, acc: 55.47%] [G loss: 1.796635]\n",
      "epoch:23 step:18340 [D loss: 0.435966, acc: 78.91%] [G loss: 2.249910]\n",
      "epoch:23 step:18341 [D loss: 0.740248, acc: 56.25%] [G loss: 2.379912]\n",
      "epoch:23 step:18342 [D loss: 0.249624, acc: 99.22%] [G loss: 3.179098]\n",
      "epoch:23 step:18343 [D loss: 0.547071, acc: 73.44%] [G loss: 2.352576]\n",
      "epoch:23 step:18344 [D loss: 0.617312, acc: 62.50%] [G loss: 2.055315]\n",
      "epoch:23 step:18345 [D loss: 1.096926, acc: 42.97%] [G loss: 2.241157]\n",
      "epoch:23 step:18346 [D loss: 0.885264, acc: 39.84%] [G loss: 2.002110]\n",
      "epoch:23 step:18347 [D loss: 0.697885, acc: 54.69%] [G loss: 2.260412]\n",
      "epoch:23 step:18348 [D loss: 1.018238, acc: 34.38%] [G loss: 2.002123]\n",
      "epoch:23 step:18349 [D loss: 0.560476, acc: 71.09%] [G loss: 3.163362]\n",
      "epoch:23 step:18350 [D loss: 0.541104, acc: 74.22%] [G loss: 2.437048]\n",
      "epoch:23 step:18351 [D loss: 1.046758, acc: 30.47%] [G loss: 2.477744]\n",
      "epoch:23 step:18352 [D loss: 0.393358, acc: 92.19%] [G loss: 2.368580]\n",
      "epoch:23 step:18353 [D loss: 0.805910, acc: 37.50%] [G loss: 2.200843]\n",
      "epoch:23 step:18354 [D loss: 0.669202, acc: 57.81%] [G loss: 2.593497]\n",
      "epoch:23 step:18355 [D loss: 0.901863, acc: 44.53%] [G loss: 2.156254]\n",
      "epoch:23 step:18356 [D loss: 0.716871, acc: 50.78%] [G loss: 2.120065]\n",
      "epoch:23 step:18357 [D loss: 0.280800, acc: 95.31%] [G loss: 3.278079]\n",
      "epoch:23 step:18358 [D loss: 0.818835, acc: 49.22%] [G loss: 1.666430]\n",
      "epoch:23 step:18359 [D loss: 0.203394, acc: 98.44%] [G loss: 4.024317]\n",
      "epoch:23 step:18360 [D loss: 0.992290, acc: 18.75%] [G loss: 2.133242]\n",
      "epoch:23 step:18361 [D loss: 0.742272, acc: 50.78%] [G loss: 3.089916]\n",
      "epoch:23 step:18362 [D loss: 0.505247, acc: 78.91%] [G loss: 3.099274]\n",
      "epoch:23 step:18363 [D loss: 0.272367, acc: 94.53%] [G loss: 2.665555]\n",
      "epoch:23 step:18364 [D loss: 0.500277, acc: 75.78%] [G loss: 2.389313]\n",
      "epoch:23 step:18365 [D loss: 0.445608, acc: 78.12%] [G loss: 2.672063]\n",
      "epoch:23 step:18366 [D loss: 0.719738, acc: 53.91%] [G loss: 2.004011]\n",
      "epoch:23 step:18367 [D loss: 0.530928, acc: 80.47%] [G loss: 2.114709]\n",
      "epoch:23 step:18368 [D loss: 0.426550, acc: 91.41%] [G loss: 2.010088]\n",
      "epoch:23 step:18369 [D loss: 0.729971, acc: 44.53%] [G loss: 1.831567]\n",
      "epoch:23 step:18370 [D loss: 0.460348, acc: 78.12%] [G loss: 3.242514]\n",
      "epoch:23 step:18371 [D loss: 0.676169, acc: 58.59%] [G loss: 2.470407]\n",
      "epoch:23 step:18372 [D loss: 0.757723, acc: 50.78%] [G loss: 2.704146]\n",
      "epoch:23 step:18373 [D loss: 0.351637, acc: 93.75%] [G loss: 3.159097]\n",
      "epoch:23 step:18374 [D loss: 0.282305, acc: 98.44%] [G loss: 2.627120]\n",
      "epoch:23 step:18375 [D loss: 0.404000, acc: 86.72%] [G loss: 3.155195]\n",
      "epoch:23 step:18376 [D loss: 0.503822, acc: 82.03%] [G loss: 3.598161]\n",
      "epoch:23 step:18377 [D loss: 0.467163, acc: 80.47%] [G loss: 3.217244]\n",
      "epoch:23 step:18378 [D loss: 0.332616, acc: 92.97%] [G loss: 2.022362]\n",
      "epoch:23 step:18379 [D loss: 0.561662, acc: 72.66%] [G loss: 3.793048]\n",
      "epoch:23 step:18380 [D loss: 0.215891, acc: 99.22%] [G loss: 3.359584]\n",
      "epoch:23 step:18381 [D loss: 0.583459, acc: 64.84%] [G loss: 3.082178]\n",
      "epoch:23 step:18382 [D loss: 0.504416, acc: 81.25%] [G loss: 2.462804]\n",
      "epoch:23 step:18383 [D loss: 0.827113, acc: 36.72%] [G loss: 2.103363]\n",
      "epoch:23 step:18384 [D loss: 0.347524, acc: 96.88%] [G loss: 2.761596]\n",
      "epoch:23 step:18385 [D loss: 0.573101, acc: 66.41%] [G loss: 3.504555]\n",
      "epoch:23 step:18386 [D loss: 0.629131, acc: 63.28%] [G loss: 3.311810]\n",
      "epoch:23 step:18387 [D loss: 0.594651, acc: 66.41%] [G loss: 2.223630]\n",
      "epoch:23 step:18388 [D loss: 0.484533, acc: 72.66%] [G loss: 3.081636]\n",
      "epoch:23 step:18389 [D loss: 0.702120, acc: 52.34%] [G loss: 2.876828]\n",
      "epoch:23 step:18390 [D loss: 0.518552, acc: 69.53%] [G loss: 2.490599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18391 [D loss: 0.319727, acc: 92.97%] [G loss: 3.168285]\n",
      "epoch:23 step:18392 [D loss: 0.368002, acc: 92.97%] [G loss: 3.435244]\n",
      "epoch:23 step:18393 [D loss: 0.376570, acc: 89.06%] [G loss: 2.752123]\n",
      "epoch:23 step:18394 [D loss: 0.673070, acc: 54.69%] [G loss: 3.188698]\n",
      "epoch:23 step:18395 [D loss: 0.703545, acc: 58.59%] [G loss: 3.121074]\n",
      "epoch:23 step:18396 [D loss: 0.228372, acc: 100.00%] [G loss: 4.127571]\n",
      "epoch:23 step:18397 [D loss: 0.150322, acc: 99.22%] [G loss: 4.398339]\n",
      "epoch:23 step:18398 [D loss: 0.415386, acc: 92.19%] [G loss: 2.904005]\n",
      "epoch:23 step:18399 [D loss: 0.616864, acc: 60.94%] [G loss: 2.656241]\n",
      "epoch:23 step:18400 [D loss: 0.444934, acc: 87.50%] [G loss: 2.055161]\n",
      "epoch:23 step:18401 [D loss: 0.442520, acc: 69.53%] [G loss: 2.892387]\n",
      "epoch:23 step:18402 [D loss: 0.219092, acc: 96.88%] [G loss: 3.752297]\n",
      "epoch:23 step:18403 [D loss: 0.847949, acc: 38.28%] [G loss: 2.404513]\n",
      "epoch:23 step:18404 [D loss: 0.291028, acc: 98.44%] [G loss: 2.891896]\n",
      "epoch:23 step:18405 [D loss: 0.344986, acc: 89.84%] [G loss: 3.112756]\n",
      "epoch:23 step:18406 [D loss: 0.668904, acc: 57.03%] [G loss: 2.369704]\n",
      "epoch:23 step:18407 [D loss: 0.302551, acc: 93.75%] [G loss: 3.296006]\n",
      "epoch:23 step:18408 [D loss: 0.514089, acc: 80.47%] [G loss: 2.341984]\n",
      "epoch:23 step:18409 [D loss: 0.375190, acc: 90.62%] [G loss: 2.971998]\n",
      "epoch:23 step:18410 [D loss: 0.569045, acc: 75.00%] [G loss: 3.318463]\n",
      "epoch:23 step:18411 [D loss: 1.000016, acc: 17.97%] [G loss: 2.826365]\n",
      "epoch:23 step:18412 [D loss: 0.379637, acc: 94.53%] [G loss: 2.861660]\n",
      "epoch:23 step:18413 [D loss: 0.248317, acc: 100.00%] [G loss: 3.337841]\n",
      "epoch:23 step:18414 [D loss: 0.955151, acc: 32.81%] [G loss: 2.523685]\n",
      "epoch:23 step:18415 [D loss: 0.906860, acc: 31.25%] [G loss: 2.236894]\n",
      "epoch:23 step:18416 [D loss: 0.710028, acc: 53.12%] [G loss: 3.136191]\n",
      "epoch:23 step:18417 [D loss: 0.495677, acc: 82.81%] [G loss: 2.198794]\n",
      "epoch:23 step:18418 [D loss: 0.730772, acc: 53.91%] [G loss: 2.717073]\n",
      "epoch:23 step:18419 [D loss: 0.623809, acc: 63.28%] [G loss: 2.894453]\n",
      "epoch:23 step:18420 [D loss: 0.332252, acc: 94.53%] [G loss: 3.133321]\n",
      "epoch:23 step:18421 [D loss: 0.367281, acc: 94.53%] [G loss: 2.427487]\n",
      "epoch:23 step:18422 [D loss: 0.594661, acc: 71.88%] [G loss: 2.994478]\n",
      "epoch:23 step:18423 [D loss: 0.669701, acc: 57.81%] [G loss: 2.582294]\n",
      "epoch:23 step:18424 [D loss: 0.854634, acc: 52.34%] [G loss: 1.840422]\n",
      "epoch:23 step:18425 [D loss: 0.429474, acc: 89.84%] [G loss: 1.551485]\n",
      "epoch:23 step:18426 [D loss: 0.976176, acc: 33.59%] [G loss: 1.936149]\n",
      "epoch:23 step:18427 [D loss: 0.388022, acc: 93.75%] [G loss: 2.674689]\n",
      "epoch:23 step:18428 [D loss: 0.469941, acc: 85.94%] [G loss: 2.617960]\n",
      "epoch:23 step:18429 [D loss: 0.162436, acc: 99.22%] [G loss: 3.717381]\n",
      "epoch:23 step:18430 [D loss: 0.611182, acc: 64.84%] [G loss: 3.261082]\n",
      "epoch:23 step:18431 [D loss: 0.338836, acc: 98.44%] [G loss: 2.065961]\n",
      "epoch:23 step:18432 [D loss: 0.552020, acc: 72.66%] [G loss: 2.542740]\n",
      "epoch:23 step:18433 [D loss: 0.340798, acc: 93.75%] [G loss: 2.725150]\n",
      "epoch:23 step:18434 [D loss: 0.519247, acc: 64.06%] [G loss: 1.923362]\n",
      "epoch:23 step:18435 [D loss: 0.563851, acc: 75.00%] [G loss: 2.654841]\n",
      "epoch:23 step:18436 [D loss: 0.971252, acc: 44.53%] [G loss: 2.634564]\n",
      "epoch:23 step:18437 [D loss: 0.589057, acc: 73.44%] [G loss: 2.532846]\n",
      "epoch:23 step:18438 [D loss: 0.531508, acc: 78.12%] [G loss: 1.974462]\n",
      "epoch:23 step:18439 [D loss: 0.508453, acc: 82.81%] [G loss: 2.736782]\n",
      "epoch:23 step:18440 [D loss: 0.530187, acc: 78.12%] [G loss: 2.411209]\n",
      "epoch:23 step:18441 [D loss: 0.330588, acc: 97.66%] [G loss: 4.256455]\n",
      "epoch:23 step:18442 [D loss: 0.489605, acc: 65.62%] [G loss: 2.462168]\n",
      "epoch:23 step:18443 [D loss: 0.474589, acc: 73.44%] [G loss: 2.738553]\n",
      "epoch:23 step:18444 [D loss: 1.262070, acc: 41.41%] [G loss: 2.117815]\n",
      "epoch:23 step:18445 [D loss: 0.597867, acc: 62.50%] [G loss: 3.054025]\n",
      "epoch:23 step:18446 [D loss: 0.411671, acc: 88.28%] [G loss: 2.881290]\n",
      "epoch:23 step:18447 [D loss: 0.429238, acc: 89.06%] [G loss: 3.159371]\n",
      "epoch:23 step:18448 [D loss: 0.285608, acc: 92.19%] [G loss: 2.985196]\n",
      "epoch:23 step:18449 [D loss: 0.733689, acc: 53.12%] [G loss: 3.106919]\n",
      "epoch:23 step:18450 [D loss: 0.635116, acc: 65.62%] [G loss: 2.182843]\n",
      "epoch:23 step:18451 [D loss: 0.310557, acc: 96.88%] [G loss: 2.312922]\n",
      "epoch:23 step:18452 [D loss: 0.761006, acc: 54.69%] [G loss: 2.047718]\n",
      "epoch:23 step:18453 [D loss: 0.234517, acc: 99.22%] [G loss: 3.248081]\n",
      "epoch:23 step:18454 [D loss: 0.864373, acc: 39.06%] [G loss: 2.437864]\n",
      "epoch:23 step:18455 [D loss: 0.241975, acc: 100.00%] [G loss: 2.693279]\n",
      "epoch:23 step:18456 [D loss: 0.270356, acc: 96.88%] [G loss: 2.932724]\n",
      "epoch:23 step:18457 [D loss: 0.645030, acc: 65.62%] [G loss: 2.300118]\n",
      "epoch:23 step:18458 [D loss: 0.365914, acc: 85.94%] [G loss: 3.067707]\n",
      "epoch:23 step:18459 [D loss: 0.587278, acc: 71.09%] [G loss: 2.002483]\n",
      "epoch:23 step:18460 [D loss: 0.460642, acc: 82.03%] [G loss: 2.639149]\n",
      "epoch:23 step:18461 [D loss: 0.414355, acc: 85.16%] [G loss: 2.649225]\n",
      "epoch:23 step:18462 [D loss: 0.633592, acc: 59.38%] [G loss: 3.550550]\n",
      "epoch:23 step:18463 [D loss: 0.482968, acc: 82.81%] [G loss: 1.902444]\n",
      "epoch:23 step:18464 [D loss: 0.665180, acc: 57.81%] [G loss: 1.882594]\n",
      "epoch:23 step:18465 [D loss: 0.465590, acc: 89.06%] [G loss: 2.580864]\n",
      "epoch:23 step:18466 [D loss: 0.593241, acc: 61.72%] [G loss: 2.089904]\n",
      "epoch:23 step:18467 [D loss: 0.491859, acc: 84.38%] [G loss: 2.201418]\n",
      "epoch:23 step:18468 [D loss: 0.735945, acc: 54.69%] [G loss: 2.661220]\n",
      "epoch:23 step:18469 [D loss: 0.395556, acc: 89.84%] [G loss: 2.556087]\n",
      "epoch:23 step:18470 [D loss: 0.452289, acc: 88.28%] [G loss: 2.761276]\n",
      "epoch:23 step:18471 [D loss: 0.723510, acc: 51.56%] [G loss: 3.393626]\n",
      "epoch:23 step:18472 [D loss: 0.098072, acc: 100.00%] [G loss: 3.676670]\n",
      "epoch:23 step:18473 [D loss: 0.550869, acc: 64.06%] [G loss: 2.569173]\n",
      "epoch:23 step:18474 [D loss: 0.244999, acc: 98.44%] [G loss: 4.344591]\n",
      "epoch:23 step:18475 [D loss: 0.281126, acc: 95.31%] [G loss: 3.758571]\n",
      "epoch:23 step:18476 [D loss: 0.885487, acc: 41.41%] [G loss: 3.283000]\n",
      "epoch:23 step:18477 [D loss: 0.576534, acc: 71.88%] [G loss: 2.800849]\n",
      "epoch:23 step:18478 [D loss: 0.234585, acc: 98.44%] [G loss: 3.405467]\n",
      "epoch:23 step:18479 [D loss: 0.351316, acc: 93.75%] [G loss: 2.631105]\n",
      "epoch:23 step:18480 [D loss: 0.231868, acc: 96.09%] [G loss: 3.288610]\n",
      "epoch:23 step:18481 [D loss: 0.336932, acc: 94.53%] [G loss: 3.539110]\n",
      "epoch:23 step:18482 [D loss: 0.890420, acc: 38.28%] [G loss: 2.699394]\n",
      "epoch:23 step:18483 [D loss: 0.430625, acc: 76.56%] [G loss: 2.949381]\n",
      "epoch:23 step:18484 [D loss: 0.349591, acc: 94.53%] [G loss: 3.032816]\n",
      "epoch:23 step:18485 [D loss: 0.467922, acc: 77.34%] [G loss: 2.924012]\n",
      "epoch:23 step:18486 [D loss: 0.705113, acc: 60.16%] [G loss: 2.317328]\n",
      "epoch:23 step:18487 [D loss: 0.232163, acc: 96.88%] [G loss: 3.856374]\n",
      "epoch:23 step:18488 [D loss: 0.837368, acc: 37.50%] [G loss: 3.437792]\n",
      "epoch:23 step:18489 [D loss: 0.681926, acc: 59.38%] [G loss: 2.056437]\n",
      "epoch:23 step:18490 [D loss: 0.361507, acc: 94.53%] [G loss: 3.405914]\n",
      "epoch:23 step:18491 [D loss: 0.593465, acc: 71.88%] [G loss: 3.468449]\n",
      "epoch:23 step:18492 [D loss: 0.239758, acc: 97.66%] [G loss: 2.252051]\n",
      "epoch:23 step:18493 [D loss: 0.445485, acc: 85.16%] [G loss: 3.182829]\n",
      "epoch:23 step:18494 [D loss: 0.471397, acc: 77.34%] [G loss: 3.259260]\n",
      "epoch:23 step:18495 [D loss: 0.672650, acc: 57.03%] [G loss: 2.941897]\n",
      "epoch:23 step:18496 [D loss: 0.573278, acc: 67.97%] [G loss: 2.751075]\n",
      "epoch:23 step:18497 [D loss: 0.394403, acc: 90.62%] [G loss: 2.653350]\n",
      "epoch:23 step:18498 [D loss: 0.611288, acc: 64.84%] [G loss: 2.817304]\n",
      "epoch:23 step:18499 [D loss: 0.271635, acc: 96.88%] [G loss: 3.742812]\n",
      "epoch:23 step:18500 [D loss: 0.287463, acc: 93.75%] [G loss: 2.819719]\n",
      "epoch:23 step:18501 [D loss: 0.627647, acc: 60.94%] [G loss: 3.562923]\n",
      "epoch:23 step:18502 [D loss: 0.606445, acc: 71.09%] [G loss: 2.322464]\n",
      "epoch:23 step:18503 [D loss: 0.979040, acc: 45.31%] [G loss: 2.557017]\n",
      "epoch:23 step:18504 [D loss: 0.354948, acc: 90.62%] [G loss: 2.504814]\n",
      "epoch:23 step:18505 [D loss: 0.511663, acc: 82.81%] [G loss: 2.380284]\n",
      "epoch:23 step:18506 [D loss: 0.366218, acc: 92.97%] [G loss: 2.436862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18507 [D loss: 0.696937, acc: 55.47%] [G loss: 2.649873]\n",
      "epoch:23 step:18508 [D loss: 0.433581, acc: 83.59%] [G loss: 3.172132]\n",
      "epoch:23 step:18509 [D loss: 0.690252, acc: 62.50%] [G loss: 3.275317]\n",
      "epoch:23 step:18510 [D loss: 0.652015, acc: 56.25%] [G loss: 2.430700]\n",
      "epoch:23 step:18511 [D loss: 0.532562, acc: 71.09%] [G loss: 2.636104]\n",
      "epoch:23 step:18512 [D loss: 0.581008, acc: 73.44%] [G loss: 2.411972]\n",
      "epoch:23 step:18513 [D loss: 0.302697, acc: 92.97%] [G loss: 2.888272]\n",
      "epoch:23 step:18514 [D loss: 0.321532, acc: 96.09%] [G loss: 3.010234]\n",
      "epoch:23 step:18515 [D loss: 0.920095, acc: 31.25%] [G loss: 2.770151]\n",
      "epoch:23 step:18516 [D loss: 0.935545, acc: 50.00%] [G loss: 2.259561]\n",
      "epoch:23 step:18517 [D loss: 0.859958, acc: 53.12%] [G loss: 3.253723]\n",
      "epoch:23 step:18518 [D loss: 0.220769, acc: 96.88%] [G loss: 2.791107]\n",
      "epoch:23 step:18519 [D loss: 0.410822, acc: 77.34%] [G loss: 2.705872]\n",
      "epoch:23 step:18520 [D loss: 0.251814, acc: 97.66%] [G loss: 2.908183]\n",
      "epoch:23 step:18521 [D loss: 0.550788, acc: 73.44%] [G loss: 3.404351]\n",
      "epoch:23 step:18522 [D loss: 0.665866, acc: 53.12%] [G loss: 2.806840]\n",
      "epoch:23 step:18523 [D loss: 0.797783, acc: 32.81%] [G loss: 2.699852]\n",
      "epoch:23 step:18524 [D loss: 0.372059, acc: 92.19%] [G loss: 2.681563]\n",
      "epoch:23 step:18525 [D loss: 0.791729, acc: 51.56%] [G loss: 2.178260]\n",
      "epoch:23 step:18526 [D loss: 0.756739, acc: 53.12%] [G loss: 2.738128]\n",
      "epoch:23 step:18527 [D loss: 0.161647, acc: 100.00%] [G loss: 2.554620]\n",
      "epoch:23 step:18528 [D loss: 0.457404, acc: 83.59%] [G loss: 2.024927]\n",
      "epoch:23 step:18529 [D loss: 0.621494, acc: 64.84%] [G loss: 2.146451]\n",
      "epoch:23 step:18530 [D loss: 0.942330, acc: 21.09%] [G loss: 2.394214]\n",
      "epoch:23 step:18531 [D loss: 0.305295, acc: 97.66%] [G loss: 2.100077]\n",
      "epoch:23 step:18532 [D loss: 0.206771, acc: 98.44%] [G loss: 3.807415]\n",
      "epoch:23 step:18533 [D loss: 0.429187, acc: 81.25%] [G loss: 4.022204]\n",
      "epoch:23 step:18534 [D loss: 0.644916, acc: 57.81%] [G loss: 3.556665]\n",
      "epoch:23 step:18535 [D loss: 0.598163, acc: 65.62%] [G loss: 2.576956]\n",
      "epoch:23 step:18536 [D loss: 0.566488, acc: 65.62%] [G loss: 2.438181]\n",
      "epoch:23 step:18537 [D loss: 0.722227, acc: 50.00%] [G loss: 3.174115]\n",
      "epoch:23 step:18538 [D loss: 0.627472, acc: 53.12%] [G loss: 2.921813]\n",
      "epoch:23 step:18539 [D loss: 0.528789, acc: 60.16%] [G loss: 3.383107]\n",
      "epoch:23 step:18540 [D loss: 0.239978, acc: 98.44%] [G loss: 2.197206]\n",
      "epoch:23 step:18541 [D loss: 0.648135, acc: 64.06%] [G loss: 2.519252]\n",
      "epoch:23 step:18542 [D loss: 0.278764, acc: 94.53%] [G loss: 3.310771]\n",
      "epoch:23 step:18543 [D loss: 0.167363, acc: 100.00%] [G loss: 3.491305]\n",
      "epoch:23 step:18544 [D loss: 0.690199, acc: 56.25%] [G loss: 3.752821]\n",
      "epoch:23 step:18545 [D loss: 0.835757, acc: 50.00%] [G loss: 2.479506]\n",
      "epoch:23 step:18546 [D loss: 0.847510, acc: 43.75%] [G loss: 2.832334]\n",
      "epoch:23 step:18547 [D loss: 1.101045, acc: 28.91%] [G loss: 1.621783]\n",
      "epoch:23 step:18548 [D loss: 0.286772, acc: 99.22%] [G loss: 3.434547]\n",
      "epoch:23 step:18549 [D loss: 0.843598, acc: 40.62%] [G loss: 2.949169]\n",
      "epoch:23 step:18550 [D loss: 0.235567, acc: 98.44%] [G loss: 2.844299]\n",
      "epoch:23 step:18551 [D loss: 0.378687, acc: 94.53%] [G loss: 3.176371]\n",
      "epoch:23 step:18552 [D loss: 0.625943, acc: 65.62%] [G loss: 2.648162]\n",
      "epoch:23 step:18553 [D loss: 0.766277, acc: 52.34%] [G loss: 2.794766]\n",
      "epoch:23 step:18554 [D loss: 0.589875, acc: 67.97%] [G loss: 2.084095]\n",
      "epoch:23 step:18555 [D loss: 0.654454, acc: 57.81%] [G loss: 1.707388]\n",
      "epoch:23 step:18556 [D loss: 0.743231, acc: 57.03%] [G loss: 3.314893]\n",
      "epoch:23 step:18557 [D loss: 0.839456, acc: 51.56%] [G loss: 2.893919]\n",
      "epoch:23 step:18558 [D loss: 1.134613, acc: 50.00%] [G loss: 1.933506]\n",
      "epoch:23 step:18559 [D loss: 0.628364, acc: 65.62%] [G loss: 2.520757]\n",
      "epoch:23 step:18560 [D loss: 1.163195, acc: 7.03%] [G loss: 2.474568]\n",
      "epoch:23 step:18561 [D loss: 0.353365, acc: 91.41%] [G loss: 3.590223]\n",
      "epoch:23 step:18562 [D loss: 0.849598, acc: 46.88%] [G loss: 1.875156]\n",
      "epoch:23 step:18563 [D loss: 0.627750, acc: 63.28%] [G loss: 3.738263]\n",
      "epoch:23 step:18564 [D loss: 0.633821, acc: 64.84%] [G loss: 2.504343]\n",
      "epoch:23 step:18565 [D loss: 0.535481, acc: 77.34%] [G loss: 2.407164]\n",
      "epoch:23 step:18566 [D loss: 0.292395, acc: 97.66%] [G loss: 1.993255]\n",
      "epoch:23 step:18567 [D loss: 0.294328, acc: 95.31%] [G loss: 3.993767]\n",
      "epoch:23 step:18568 [D loss: 0.261935, acc: 98.44%] [G loss: 3.846215]\n",
      "epoch:23 step:18569 [D loss: 0.511879, acc: 72.66%] [G loss: 2.815925]\n",
      "epoch:23 step:18570 [D loss: 0.749354, acc: 50.78%] [G loss: 2.574352]\n",
      "epoch:23 step:18571 [D loss: 0.524342, acc: 75.00%] [G loss: 2.388134]\n",
      "epoch:23 step:18572 [D loss: 0.408192, acc: 90.62%] [G loss: 3.314896]\n",
      "epoch:23 step:18573 [D loss: 0.553794, acc: 65.62%] [G loss: 2.779505]\n",
      "epoch:23 step:18574 [D loss: 0.577219, acc: 70.31%] [G loss: 2.300019]\n",
      "epoch:23 step:18575 [D loss: 0.638349, acc: 64.06%] [G loss: 2.641418]\n",
      "epoch:23 step:18576 [D loss: 0.391612, acc: 92.97%] [G loss: 2.220818]\n",
      "epoch:23 step:18577 [D loss: 0.348166, acc: 89.06%] [G loss: 2.864203]\n",
      "epoch:23 step:18578 [D loss: 0.369270, acc: 90.62%] [G loss: 3.262991]\n",
      "epoch:23 step:18579 [D loss: 0.739404, acc: 53.12%] [G loss: 2.419514]\n",
      "epoch:23 step:18580 [D loss: 0.766779, acc: 51.56%] [G loss: 4.065559]\n",
      "epoch:23 step:18581 [D loss: 0.740962, acc: 50.78%] [G loss: 3.056564]\n",
      "epoch:23 step:18582 [D loss: 0.516680, acc: 77.34%] [G loss: 4.247412]\n",
      "epoch:23 step:18583 [D loss: 0.600012, acc: 67.19%] [G loss: 2.615530]\n",
      "epoch:23 step:18584 [D loss: 0.634767, acc: 61.72%] [G loss: 2.999044]\n",
      "epoch:23 step:18585 [D loss: 1.176737, acc: 9.38%] [G loss: 1.941485]\n",
      "epoch:23 step:18586 [D loss: 0.823804, acc: 49.22%] [G loss: 2.177354]\n",
      "epoch:23 step:18587 [D loss: 0.127273, acc: 100.00%] [G loss: 3.286844]\n",
      "epoch:23 step:18588 [D loss: 0.480757, acc: 81.25%] [G loss: 2.875550]\n",
      "epoch:23 step:18589 [D loss: 0.615091, acc: 63.28%] [G loss: 3.153428]\n",
      "epoch:23 step:18590 [D loss: 0.355093, acc: 84.38%] [G loss: 2.773963]\n",
      "epoch:23 step:18591 [D loss: 0.253429, acc: 95.31%] [G loss: 2.467758]\n",
      "epoch:23 step:18592 [D loss: 0.602088, acc: 65.62%] [G loss: 4.188431]\n",
      "epoch:23 step:18593 [D loss: 0.488101, acc: 82.81%] [G loss: 2.088863]\n",
      "epoch:23 step:18594 [D loss: 0.570770, acc: 65.62%] [G loss: 1.585873]\n",
      "epoch:23 step:18595 [D loss: 1.045298, acc: 46.09%] [G loss: 2.362025]\n",
      "epoch:23 step:18596 [D loss: 0.989486, acc: 49.22%] [G loss: 2.615383]\n",
      "epoch:23 step:18597 [D loss: 0.552299, acc: 71.88%] [G loss: 2.187175]\n",
      "epoch:23 step:18598 [D loss: 0.288663, acc: 98.44%] [G loss: 2.583585]\n",
      "epoch:23 step:18599 [D loss: 0.543622, acc: 74.22%] [G loss: 2.588140]\n",
      "epoch:23 step:18600 [D loss: 0.377016, acc: 85.16%] [G loss: 2.116343]\n",
      "epoch:23 step:18601 [D loss: 0.697769, acc: 55.47%] [G loss: 2.834181]\n",
      "epoch:23 step:18602 [D loss: 0.813187, acc: 40.62%] [G loss: 1.576778]\n",
      "epoch:23 step:18603 [D loss: 0.494679, acc: 69.53%] [G loss: 2.752425]\n",
      "epoch:23 step:18604 [D loss: 0.462130, acc: 78.91%] [G loss: 2.944689]\n",
      "epoch:23 step:18605 [D loss: 0.549699, acc: 74.22%] [G loss: 2.607793]\n",
      "epoch:23 step:18606 [D loss: 0.936613, acc: 27.34%] [G loss: 1.913458]\n",
      "epoch:23 step:18607 [D loss: 0.258270, acc: 93.75%] [G loss: 3.195253]\n",
      "epoch:23 step:18608 [D loss: 1.048196, acc: 33.59%] [G loss: 2.008044]\n",
      "epoch:23 step:18609 [D loss: 0.651117, acc: 58.59%] [G loss: 3.308616]\n",
      "epoch:23 step:18610 [D loss: 0.762429, acc: 45.31%] [G loss: 2.647875]\n",
      "epoch:23 step:18611 [D loss: 0.424144, acc: 91.41%] [G loss: 2.472573]\n",
      "epoch:23 step:18612 [D loss: 0.433201, acc: 86.72%] [G loss: 3.035984]\n",
      "epoch:23 step:18613 [D loss: 0.490590, acc: 85.94%] [G loss: 3.059260]\n",
      "epoch:23 step:18614 [D loss: 0.433883, acc: 85.16%] [G loss: 3.467487]\n",
      "epoch:23 step:18615 [D loss: 0.522539, acc: 78.91%] [G loss: 2.505292]\n",
      "epoch:23 step:18616 [D loss: 0.269377, acc: 96.09%] [G loss: 3.688722]\n",
      "epoch:23 step:18617 [D loss: 0.324049, acc: 97.66%] [G loss: 2.905534]\n",
      "epoch:23 step:18618 [D loss: 0.211288, acc: 98.44%] [G loss: 3.715176]\n",
      "epoch:23 step:18619 [D loss: 0.951592, acc: 31.25%] [G loss: 3.416590]\n",
      "epoch:23 step:18620 [D loss: 0.365288, acc: 91.41%] [G loss: 3.215130]\n",
      "epoch:23 step:18621 [D loss: 0.779763, acc: 42.97%] [G loss: 3.036104]\n",
      "epoch:23 step:18622 [D loss: 0.647795, acc: 57.03%] [G loss: 3.156390]\n",
      "epoch:23 step:18623 [D loss: 0.865965, acc: 50.78%] [G loss: 2.134930]\n",
      "epoch:23 step:18624 [D loss: 0.385582, acc: 89.84%] [G loss: 3.585288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18625 [D loss: 0.983613, acc: 41.41%] [G loss: 1.804463]\n",
      "epoch:23 step:18626 [D loss: 0.312486, acc: 96.09%] [G loss: 3.380648]\n",
      "epoch:23 step:18627 [D loss: 0.356963, acc: 94.53%] [G loss: 2.891899]\n",
      "epoch:23 step:18628 [D loss: 0.332074, acc: 95.31%] [G loss: 3.523994]\n",
      "epoch:23 step:18629 [D loss: 0.352082, acc: 96.09%] [G loss: 4.188116]\n",
      "epoch:23 step:18630 [D loss: 0.278461, acc: 98.44%] [G loss: 2.956917]\n",
      "epoch:23 step:18631 [D loss: 0.417252, acc: 89.84%] [G loss: 2.982738]\n",
      "epoch:23 step:18632 [D loss: 0.291390, acc: 99.22%] [G loss: 2.451437]\n",
      "epoch:23 step:18633 [D loss: 0.785171, acc: 50.78%] [G loss: 1.828162]\n",
      "epoch:23 step:18634 [D loss: 0.354230, acc: 82.03%] [G loss: 3.864427]\n",
      "epoch:23 step:18635 [D loss: 0.314169, acc: 96.88%] [G loss: 1.903055]\n",
      "epoch:23 step:18636 [D loss: 0.557109, acc: 75.00%] [G loss: 2.213234]\n",
      "epoch:23 step:18637 [D loss: 0.230985, acc: 99.22%] [G loss: 3.228078]\n",
      "epoch:23 step:18638 [D loss: 0.472301, acc: 85.16%] [G loss: 4.151858]\n",
      "epoch:23 step:18639 [D loss: 0.273673, acc: 96.09%] [G loss: 3.570807]\n",
      "epoch:23 step:18640 [D loss: 0.360572, acc: 79.69%] [G loss: 2.666955]\n",
      "epoch:23 step:18641 [D loss: 0.845377, acc: 48.44%] [G loss: 2.569818]\n",
      "epoch:23 step:18642 [D loss: 0.301670, acc: 94.53%] [G loss: 3.668741]\n",
      "epoch:23 step:18643 [D loss: 0.420207, acc: 76.56%] [G loss: 3.904862]\n",
      "epoch:23 step:18644 [D loss: 0.402211, acc: 88.28%] [G loss: 3.385263]\n",
      "epoch:23 step:18645 [D loss: 0.736539, acc: 52.34%] [G loss: 2.584181]\n",
      "epoch:23 step:18646 [D loss: 0.358611, acc: 82.81%] [G loss: 2.440584]\n",
      "epoch:23 step:18647 [D loss: 1.371806, acc: 2.34%] [G loss: 2.465357]\n",
      "epoch:23 step:18648 [D loss: 0.695559, acc: 54.69%] [G loss: 3.205688]\n",
      "epoch:23 step:18649 [D loss: 1.853528, acc: 4.69%] [G loss: 2.080120]\n",
      "epoch:23 step:18650 [D loss: 0.843085, acc: 29.69%] [G loss: 1.728447]\n",
      "epoch:23 step:18651 [D loss: 0.542270, acc: 77.34%] [G loss: 3.318872]\n",
      "epoch:23 step:18652 [D loss: 0.320272, acc: 90.62%] [G loss: 2.113472]\n",
      "epoch:23 step:18653 [D loss: 0.519398, acc: 62.50%] [G loss: 4.723037]\n",
      "epoch:23 step:18654 [D loss: 0.361530, acc: 93.75%] [G loss: 3.233193]\n",
      "epoch:23 step:18655 [D loss: 1.386503, acc: 39.84%] [G loss: 2.758849]\n",
      "epoch:23 step:18656 [D loss: 0.797559, acc: 43.75%] [G loss: 3.172061]\n",
      "epoch:23 step:18657 [D loss: 0.625517, acc: 67.19%] [G loss: 2.530018]\n",
      "epoch:23 step:18658 [D loss: 0.402657, acc: 92.97%] [G loss: 2.487975]\n",
      "epoch:23 step:18659 [D loss: 0.749261, acc: 46.88%] [G loss: 2.119165]\n",
      "epoch:23 step:18660 [D loss: 0.951408, acc: 19.53%] [G loss: 2.718728]\n",
      "epoch:23 step:18661 [D loss: 0.478485, acc: 81.25%] [G loss: 2.249889]\n",
      "epoch:23 step:18662 [D loss: 0.276756, acc: 97.66%] [G loss: 3.181325]\n",
      "epoch:23 step:18663 [D loss: 0.754805, acc: 53.12%] [G loss: 2.447741]\n",
      "epoch:23 step:18664 [D loss: 0.288884, acc: 90.62%] [G loss: 2.547295]\n",
      "epoch:23 step:18665 [D loss: 0.437888, acc: 84.38%] [G loss: 2.958620]\n",
      "epoch:23 step:18666 [D loss: 0.658389, acc: 61.72%] [G loss: 2.613785]\n",
      "epoch:23 step:18667 [D loss: 0.355832, acc: 90.62%] [G loss: 2.137380]\n",
      "epoch:23 step:18668 [D loss: 0.675577, acc: 59.38%] [G loss: 2.460104]\n",
      "epoch:23 step:18669 [D loss: 0.301954, acc: 92.19%] [G loss: 2.120471]\n",
      "epoch:23 step:18670 [D loss: 0.495875, acc: 74.22%] [G loss: 2.625780]\n",
      "epoch:23 step:18671 [D loss: 0.719393, acc: 56.25%] [G loss: 2.775285]\n",
      "epoch:23 step:18672 [D loss: 0.735480, acc: 49.22%] [G loss: 3.034634]\n",
      "epoch:23 step:18673 [D loss: 0.499573, acc: 82.03%] [G loss: 2.177160]\n",
      "epoch:23 step:18674 [D loss: 0.112460, acc: 97.66%] [G loss: 3.860225]\n",
      "epoch:23 step:18675 [D loss: 0.743114, acc: 42.97%] [G loss: 2.599917]\n",
      "epoch:23 step:18676 [D loss: 0.464079, acc: 83.59%] [G loss: 2.621373]\n",
      "epoch:23 step:18677 [D loss: 0.211675, acc: 100.00%] [G loss: 2.604742]\n",
      "epoch:23 step:18678 [D loss: 0.445144, acc: 88.28%] [G loss: 1.878510]\n",
      "epoch:23 step:18679 [D loss: 0.418623, acc: 90.62%] [G loss: 3.622046]\n",
      "epoch:23 step:18680 [D loss: 0.223955, acc: 98.44%] [G loss: 2.627612]\n",
      "epoch:23 step:18681 [D loss: 0.571594, acc: 73.44%] [G loss: 2.512263]\n",
      "epoch:23 step:18682 [D loss: 0.858413, acc: 37.50%] [G loss: 2.997083]\n",
      "epoch:23 step:18683 [D loss: 0.239431, acc: 98.44%] [G loss: 3.465831]\n",
      "epoch:23 step:18684 [D loss: 0.994534, acc: 26.56%] [G loss: 2.641032]\n",
      "epoch:23 step:18685 [D loss: 0.211195, acc: 100.00%] [G loss: 2.517703]\n",
      "epoch:23 step:18686 [D loss: 1.012866, acc: 18.75%] [G loss: 2.369121]\n",
      "epoch:23 step:18687 [D loss: 0.584372, acc: 61.72%] [G loss: 3.089156]\n",
      "epoch:23 step:18688 [D loss: 0.619487, acc: 68.75%] [G loss: 2.657954]\n",
      "epoch:23 step:18689 [D loss: 0.416888, acc: 82.03%] [G loss: 3.951032]\n",
      "epoch:23 step:18690 [D loss: 0.407537, acc: 92.97%] [G loss: 3.969703]\n",
      "epoch:23 step:18691 [D loss: 0.441027, acc: 75.00%] [G loss: 2.223722]\n",
      "epoch:23 step:18692 [D loss: 0.456866, acc: 72.66%] [G loss: 2.931455]\n",
      "epoch:23 step:18693 [D loss: 0.625551, acc: 67.97%] [G loss: 2.125404]\n",
      "epoch:23 step:18694 [D loss: 0.324953, acc: 89.06%] [G loss: 2.822872]\n",
      "epoch:23 step:18695 [D loss: 1.122819, acc: 14.06%] [G loss: 2.317276]\n",
      "epoch:23 step:18696 [D loss: 0.551328, acc: 70.31%] [G loss: 2.205714]\n",
      "epoch:23 step:18697 [D loss: 0.688392, acc: 61.72%] [G loss: 3.186440]\n",
      "epoch:23 step:18698 [D loss: 0.437813, acc: 90.62%] [G loss: 2.770081]\n",
      "epoch:23 step:18699 [D loss: 0.699078, acc: 59.38%] [G loss: 3.319077]\n",
      "epoch:23 step:18700 [D loss: 0.641703, acc: 63.28%] [G loss: 3.111774]\n",
      "epoch:23 step:18701 [D loss: 0.241156, acc: 98.44%] [G loss: 3.025723]\n",
      "epoch:23 step:18702 [D loss: 0.353818, acc: 89.06%] [G loss: 4.077522]\n",
      "epoch:23 step:18703 [D loss: 0.516380, acc: 70.31%] [G loss: 2.773861]\n",
      "epoch:23 step:18704 [D loss: 0.543299, acc: 67.19%] [G loss: 2.900999]\n",
      "epoch:23 step:18705 [D loss: 0.686190, acc: 56.25%] [G loss: 3.218395]\n",
      "epoch:23 step:18706 [D loss: 0.469573, acc: 86.72%] [G loss: 2.794970]\n",
      "epoch:23 step:18707 [D loss: 0.822887, acc: 44.53%] [G loss: 2.182424]\n",
      "epoch:23 step:18708 [D loss: 0.282591, acc: 96.88%] [G loss: 3.467410]\n",
      "epoch:23 step:18709 [D loss: 0.629324, acc: 62.50%] [G loss: 2.658427]\n",
      "epoch:23 step:18710 [D loss: 0.422854, acc: 79.69%] [G loss: 2.903254]\n",
      "epoch:23 step:18711 [D loss: 0.390485, acc: 90.62%] [G loss: 2.624013]\n",
      "epoch:23 step:18712 [D loss: 0.726275, acc: 50.78%] [G loss: 3.165918]\n",
      "epoch:23 step:18713 [D loss: 0.427889, acc: 85.16%] [G loss: 2.466637]\n",
      "epoch:23 step:18714 [D loss: 0.699789, acc: 57.03%] [G loss: 1.622518]\n",
      "epoch:23 step:18715 [D loss: 0.584908, acc: 69.53%] [G loss: 3.924108]\n",
      "epoch:23 step:18716 [D loss: 0.192359, acc: 100.00%] [G loss: 3.058992]\n",
      "epoch:23 step:18717 [D loss: 0.336678, acc: 94.53%] [G loss: 2.464365]\n",
      "epoch:23 step:18718 [D loss: 1.136691, acc: 10.94%] [G loss: 2.467687]\n",
      "epoch:23 step:18719 [D loss: 0.472799, acc: 82.81%] [G loss: 2.829967]\n",
      "epoch:23 step:18720 [D loss: 0.434900, acc: 85.94%] [G loss: 2.613364]\n",
      "epoch:23 step:18721 [D loss: 0.548754, acc: 64.06%] [G loss: 2.622742]\n",
      "epoch:23 step:18722 [D loss: 0.413833, acc: 89.06%] [G loss: 1.878979]\n",
      "epoch:23 step:18723 [D loss: 0.244618, acc: 96.88%] [G loss: 3.574479]\n",
      "epoch:23 step:18724 [D loss: 0.712567, acc: 52.34%] [G loss: 2.316966]\n",
      "epoch:23 step:18725 [D loss: 0.603680, acc: 71.88%] [G loss: 2.363658]\n",
      "epoch:23 step:18726 [D loss: 0.612604, acc: 64.84%] [G loss: 2.674549]\n",
      "epoch:23 step:18727 [D loss: 0.294586, acc: 97.66%] [G loss: 3.277589]\n",
      "epoch:23 step:18728 [D loss: 0.414328, acc: 85.16%] [G loss: 3.148769]\n",
      "epoch:23 step:18729 [D loss: 0.658195, acc: 61.72%] [G loss: 2.614916]\n",
      "epoch:23 step:18730 [D loss: 0.214832, acc: 97.66%] [G loss: 3.064566]\n",
      "epoch:23 step:18731 [D loss: 0.234534, acc: 96.09%] [G loss: 2.248354]\n",
      "epoch:23 step:18732 [D loss: 0.477435, acc: 79.69%] [G loss: 3.434919]\n",
      "epoch:23 step:18733 [D loss: 0.574896, acc: 65.62%] [G loss: 2.959116]\n",
      "epoch:23 step:18734 [D loss: 0.742816, acc: 48.44%] [G loss: 1.863753]\n",
      "epoch:23 step:18735 [D loss: 0.608717, acc: 64.06%] [G loss: 4.401747]\n",
      "epoch:23 step:18736 [D loss: 0.111804, acc: 100.00%] [G loss: 5.473192]\n",
      "epoch:23 step:18737 [D loss: 0.493785, acc: 80.47%] [G loss: 3.963559]\n",
      "epoch:23 step:18738 [D loss: 0.753345, acc: 44.53%] [G loss: 2.182869]\n",
      "epoch:23 step:18739 [D loss: 0.679679, acc: 57.81%] [G loss: 2.969588]\n",
      "epoch:23 step:18740 [D loss: 0.669420, acc: 55.47%] [G loss: 3.075995]\n",
      "epoch:23 step:18741 [D loss: 0.691130, acc: 58.59%] [G loss: 2.362655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18742 [D loss: 0.332479, acc: 92.19%] [G loss: 2.824220]\n",
      "epoch:23 step:18743 [D loss: 0.890855, acc: 32.03%] [G loss: 1.920190]\n",
      "epoch:23 step:18744 [D loss: 0.772362, acc: 54.69%] [G loss: 2.466645]\n",
      "epoch:24 step:18745 [D loss: 0.327396, acc: 95.31%] [G loss: 2.392060]\n",
      "epoch:24 step:18746 [D loss: 0.512928, acc: 82.81%] [G loss: 3.115902]\n",
      "epoch:24 step:18747 [D loss: 0.852551, acc: 44.53%] [G loss: 1.956073]\n",
      "epoch:24 step:18748 [D loss: 0.510588, acc: 80.47%] [G loss: 3.269952]\n",
      "epoch:24 step:18749 [D loss: 0.387372, acc: 91.41%] [G loss: 2.627214]\n",
      "epoch:24 step:18750 [D loss: 0.217424, acc: 97.66%] [G loss: 2.575407]\n",
      "epoch:24 step:18751 [D loss: 0.662241, acc: 53.91%] [G loss: 1.816515]\n",
      "epoch:24 step:18752 [D loss: 0.786595, acc: 44.53%] [G loss: 1.668742]\n",
      "epoch:24 step:18753 [D loss: 0.353506, acc: 92.19%] [G loss: 2.710241]\n",
      "epoch:24 step:18754 [D loss: 0.656213, acc: 57.81%] [G loss: 2.728114]\n",
      "epoch:24 step:18755 [D loss: 0.961985, acc: 25.78%] [G loss: 2.110168]\n",
      "epoch:24 step:18756 [D loss: 0.416925, acc: 83.59%] [G loss: 2.410209]\n",
      "epoch:24 step:18757 [D loss: 0.766250, acc: 54.69%] [G loss: 2.522816]\n",
      "epoch:24 step:18758 [D loss: 0.399019, acc: 89.84%] [G loss: 2.448849]\n",
      "epoch:24 step:18759 [D loss: 0.808473, acc: 43.75%] [G loss: 1.516710]\n",
      "epoch:24 step:18760 [D loss: 0.501657, acc: 79.69%] [G loss: 2.295915]\n",
      "epoch:24 step:18761 [D loss: 0.300922, acc: 95.31%] [G loss: 2.968993]\n",
      "epoch:24 step:18762 [D loss: 0.440985, acc: 86.72%] [G loss: 2.969474]\n",
      "epoch:24 step:18763 [D loss: 0.680556, acc: 61.72%] [G loss: 2.443107]\n",
      "epoch:24 step:18764 [D loss: 0.184395, acc: 98.44%] [G loss: 4.384022]\n",
      "epoch:24 step:18765 [D loss: 0.617330, acc: 61.72%] [G loss: 2.940756]\n",
      "epoch:24 step:18766 [D loss: 0.954873, acc: 25.00%] [G loss: 2.560501]\n",
      "epoch:24 step:18767 [D loss: 0.539980, acc: 75.78%] [G loss: 2.535618]\n",
      "epoch:24 step:18768 [D loss: 1.012730, acc: 26.56%] [G loss: 1.771845]\n",
      "epoch:24 step:18769 [D loss: 0.857138, acc: 50.78%] [G loss: 2.564656]\n",
      "epoch:24 step:18770 [D loss: 0.730327, acc: 53.12%] [G loss: 2.361663]\n",
      "epoch:24 step:18771 [D loss: 0.298920, acc: 95.31%] [G loss: 3.505593]\n",
      "epoch:24 step:18772 [D loss: 0.489465, acc: 84.38%] [G loss: 1.853200]\n",
      "epoch:24 step:18773 [D loss: 0.208292, acc: 100.00%] [G loss: 3.009788]\n",
      "epoch:24 step:18774 [D loss: 0.659515, acc: 55.47%] [G loss: 2.731007]\n",
      "epoch:24 step:18775 [D loss: 0.205877, acc: 99.22%] [G loss: 3.505660]\n",
      "epoch:24 step:18776 [D loss: 0.417644, acc: 71.09%] [G loss: 2.667495]\n",
      "epoch:24 step:18777 [D loss: 0.290877, acc: 92.97%] [G loss: 3.730401]\n",
      "epoch:24 step:18778 [D loss: 0.371775, acc: 86.72%] [G loss: 3.961108]\n",
      "epoch:24 step:18779 [D loss: 0.600632, acc: 64.84%] [G loss: 2.681635]\n",
      "epoch:24 step:18780 [D loss: 0.333291, acc: 98.44%] [G loss: 2.522960]\n",
      "epoch:24 step:18781 [D loss: 0.742423, acc: 51.56%] [G loss: 2.824807]\n",
      "epoch:24 step:18782 [D loss: 0.363907, acc: 92.97%] [G loss: 2.478904]\n",
      "epoch:24 step:18783 [D loss: 0.540161, acc: 76.56%] [G loss: 2.707996]\n",
      "epoch:24 step:18784 [D loss: 0.143965, acc: 99.22%] [G loss: 2.922997]\n",
      "epoch:24 step:18785 [D loss: 0.513153, acc: 71.09%] [G loss: 3.704611]\n",
      "epoch:24 step:18786 [D loss: 0.439255, acc: 69.53%] [G loss: 2.601609]\n",
      "epoch:24 step:18787 [D loss: 0.546291, acc: 78.12%] [G loss: 3.083610]\n",
      "epoch:24 step:18788 [D loss: 0.678062, acc: 57.81%] [G loss: 2.751052]\n",
      "epoch:24 step:18789 [D loss: 0.300186, acc: 95.31%] [G loss: 3.301502]\n",
      "epoch:24 step:18790 [D loss: 0.106904, acc: 100.00%] [G loss: 3.125810]\n",
      "epoch:24 step:18791 [D loss: 0.471422, acc: 78.91%] [G loss: 1.730434]\n",
      "epoch:24 step:18792 [D loss: 0.940841, acc: 37.50%] [G loss: 2.839790]\n",
      "epoch:24 step:18793 [D loss: 0.435959, acc: 87.50%] [G loss: 3.681960]\n",
      "epoch:24 step:18794 [D loss: 0.490330, acc: 80.47%] [G loss: 2.691533]\n",
      "epoch:24 step:18795 [D loss: 0.345567, acc: 88.28%] [G loss: 2.236975]\n",
      "epoch:24 step:18796 [D loss: 0.424421, acc: 83.59%] [G loss: 2.718950]\n",
      "epoch:24 step:18797 [D loss: 0.386781, acc: 85.94%] [G loss: 4.769551]\n",
      "epoch:24 step:18798 [D loss: 1.122179, acc: 20.31%] [G loss: 3.516222]\n",
      "epoch:24 step:18799 [D loss: 0.888350, acc: 28.12%] [G loss: 2.427254]\n",
      "epoch:24 step:18800 [D loss: 0.859843, acc: 52.34%] [G loss: 2.785683]\n",
      "epoch:24 step:18801 [D loss: 1.035188, acc: 49.22%] [G loss: 2.512398]\n",
      "epoch:24 step:18802 [D loss: 0.621938, acc: 64.84%] [G loss: 2.843437]\n",
      "epoch:24 step:18803 [D loss: 0.388070, acc: 84.38%] [G loss: 2.396076]\n",
      "epoch:24 step:18804 [D loss: 0.497204, acc: 79.69%] [G loss: 3.444446]\n",
      "epoch:24 step:18805 [D loss: 0.654839, acc: 61.72%] [G loss: 3.162481]\n",
      "epoch:24 step:18806 [D loss: 0.311637, acc: 98.44%] [G loss: 2.479029]\n",
      "epoch:24 step:18807 [D loss: 0.376273, acc: 92.19%] [G loss: 2.673346]\n",
      "epoch:24 step:18808 [D loss: 0.360496, acc: 93.75%] [G loss: 2.827800]\n",
      "epoch:24 step:18809 [D loss: 0.429297, acc: 85.94%] [G loss: 2.313623]\n",
      "epoch:24 step:18810 [D loss: 0.559914, acc: 71.88%] [G loss: 2.418426]\n",
      "epoch:24 step:18811 [D loss: 0.521428, acc: 76.56%] [G loss: 3.223006]\n",
      "epoch:24 step:18812 [D loss: 0.538594, acc: 71.09%] [G loss: 2.901194]\n",
      "epoch:24 step:18813 [D loss: 0.459487, acc: 85.16%] [G loss: 2.362795]\n",
      "epoch:24 step:18814 [D loss: 0.426573, acc: 89.06%] [G loss: 3.540445]\n",
      "epoch:24 step:18815 [D loss: 0.480973, acc: 75.78%] [G loss: 2.812920]\n",
      "epoch:24 step:18816 [D loss: 0.632566, acc: 58.59%] [G loss: 3.211559]\n",
      "epoch:24 step:18817 [D loss: 0.348256, acc: 92.97%] [G loss: 2.960040]\n",
      "epoch:24 step:18818 [D loss: 0.656123, acc: 61.72%] [G loss: 2.664709]\n",
      "epoch:24 step:18819 [D loss: 0.470919, acc: 90.62%] [G loss: 2.998179]\n",
      "epoch:24 step:18820 [D loss: 0.201171, acc: 97.66%] [G loss: 3.308155]\n",
      "epoch:24 step:18821 [D loss: 1.024364, acc: 29.69%] [G loss: 2.376371]\n",
      "epoch:24 step:18822 [D loss: 0.513160, acc: 78.91%] [G loss: 1.621227]\n",
      "epoch:24 step:18823 [D loss: 0.393458, acc: 92.97%] [G loss: 2.994525]\n",
      "epoch:24 step:18824 [D loss: 0.257345, acc: 98.44%] [G loss: 3.235730]\n",
      "epoch:24 step:18825 [D loss: 0.243815, acc: 98.44%] [G loss: 3.647335]\n",
      "epoch:24 step:18826 [D loss: 0.527994, acc: 82.81%] [G loss: 2.993415]\n",
      "epoch:24 step:18827 [D loss: 0.664920, acc: 62.50%] [G loss: 2.919600]\n",
      "epoch:24 step:18828 [D loss: 0.706936, acc: 47.66%] [G loss: 3.610837]\n",
      "epoch:24 step:18829 [D loss: 0.403213, acc: 90.62%] [G loss: 3.401859]\n",
      "epoch:24 step:18830 [D loss: 0.797316, acc: 39.84%] [G loss: 2.418165]\n",
      "epoch:24 step:18831 [D loss: 0.356416, acc: 91.41%] [G loss: 1.986034]\n",
      "epoch:24 step:18832 [D loss: 0.691901, acc: 53.12%] [G loss: 3.004011]\n",
      "epoch:24 step:18833 [D loss: 0.495492, acc: 61.72%] [G loss: 2.705996]\n",
      "epoch:24 step:18834 [D loss: 0.406959, acc: 75.78%] [G loss: 3.382866]\n",
      "epoch:24 step:18835 [D loss: 0.388115, acc: 84.38%] [G loss: 2.201001]\n",
      "epoch:24 step:18836 [D loss: 0.149725, acc: 100.00%] [G loss: 3.281104]\n",
      "epoch:24 step:18837 [D loss: 0.469487, acc: 90.62%] [G loss: 2.989793]\n",
      "epoch:24 step:18838 [D loss: 0.384106, acc: 92.19%] [G loss: 2.184402]\n",
      "epoch:24 step:18839 [D loss: 0.328397, acc: 89.84%] [G loss: 3.162211]\n",
      "epoch:24 step:18840 [D loss: 0.363267, acc: 92.97%] [G loss: 1.834438]\n",
      "epoch:24 step:18841 [D loss: 0.340691, acc: 95.31%] [G loss: 3.130066]\n",
      "epoch:24 step:18842 [D loss: 0.505952, acc: 73.44%] [G loss: 3.699891]\n",
      "epoch:24 step:18843 [D loss: 0.288767, acc: 96.88%] [G loss: 3.464921]\n",
      "epoch:24 step:18844 [D loss: 0.382144, acc: 88.28%] [G loss: 2.426853]\n",
      "epoch:24 step:18845 [D loss: 0.636286, acc: 60.94%] [G loss: 2.940486]\n",
      "epoch:24 step:18846 [D loss: 0.583017, acc: 67.19%] [G loss: 3.033570]\n",
      "epoch:24 step:18847 [D loss: 0.465714, acc: 85.16%] [G loss: 2.617504]\n",
      "epoch:24 step:18848 [D loss: 0.437344, acc: 88.28%] [G loss: 3.021405]\n",
      "epoch:24 step:18849 [D loss: 0.520003, acc: 74.22%] [G loss: 2.869967]\n",
      "epoch:24 step:18850 [D loss: 0.395841, acc: 78.91%] [G loss: 3.726268]\n",
      "epoch:24 step:18851 [D loss: 0.904646, acc: 35.94%] [G loss: 2.175530]\n",
      "epoch:24 step:18852 [D loss: 0.362208, acc: 78.91%] [G loss: 2.949196]\n",
      "epoch:24 step:18853 [D loss: 0.640228, acc: 57.81%] [G loss: 3.498485]\n",
      "epoch:24 step:18854 [D loss: 0.413870, acc: 88.28%] [G loss: 2.344377]\n",
      "epoch:24 step:18855 [D loss: 0.457878, acc: 75.78%] [G loss: 2.899288]\n",
      "epoch:24 step:18856 [D loss: 0.506602, acc: 79.69%] [G loss: 3.520165]\n",
      "epoch:24 step:18857 [D loss: 0.410077, acc: 89.84%] [G loss: 2.656035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18858 [D loss: 0.441628, acc: 73.44%] [G loss: 3.664894]\n",
      "epoch:24 step:18859 [D loss: 0.496769, acc: 75.78%] [G loss: 3.069968]\n",
      "epoch:24 step:18860 [D loss: 0.512385, acc: 78.91%] [G loss: 3.584500]\n",
      "epoch:24 step:18861 [D loss: 0.552027, acc: 70.31%] [G loss: 3.636840]\n",
      "epoch:24 step:18862 [D loss: 0.295975, acc: 94.53%] [G loss: 2.256647]\n",
      "epoch:24 step:18863 [D loss: 0.315292, acc: 94.53%] [G loss: 3.423599]\n",
      "epoch:24 step:18864 [D loss: 0.483744, acc: 84.38%] [G loss: 3.659068]\n",
      "epoch:24 step:18865 [D loss: 0.632980, acc: 65.62%] [G loss: 2.389840]\n",
      "epoch:24 step:18866 [D loss: 0.496324, acc: 75.78%] [G loss: 4.524061]\n",
      "epoch:24 step:18867 [D loss: 0.456655, acc: 77.34%] [G loss: 3.562761]\n",
      "epoch:24 step:18868 [D loss: 0.191585, acc: 98.44%] [G loss: 3.712536]\n",
      "epoch:24 step:18869 [D loss: 0.693563, acc: 57.81%] [G loss: 2.277982]\n",
      "epoch:24 step:18870 [D loss: 0.269333, acc: 93.75%] [G loss: 3.365796]\n",
      "epoch:24 step:18871 [D loss: 1.103207, acc: 19.53%] [G loss: 1.959728]\n",
      "epoch:24 step:18872 [D loss: 0.518434, acc: 70.31%] [G loss: 3.234601]\n",
      "epoch:24 step:18873 [D loss: 0.953736, acc: 30.47%] [G loss: 3.030439]\n",
      "epoch:24 step:18874 [D loss: 0.690393, acc: 59.38%] [G loss: 1.722518]\n",
      "epoch:24 step:18875 [D loss: 0.258284, acc: 94.53%] [G loss: 3.058424]\n",
      "epoch:24 step:18876 [D loss: 0.143809, acc: 100.00%] [G loss: 2.833579]\n",
      "epoch:24 step:18877 [D loss: 0.681297, acc: 54.69%] [G loss: 2.623806]\n",
      "epoch:24 step:18878 [D loss: 0.488121, acc: 74.22%] [G loss: 2.330678]\n",
      "epoch:24 step:18879 [D loss: 0.217478, acc: 100.00%] [G loss: 2.481452]\n",
      "epoch:24 step:18880 [D loss: 0.346517, acc: 92.19%] [G loss: 3.508642]\n",
      "epoch:24 step:18881 [D loss: 0.333740, acc: 93.75%] [G loss: 1.835619]\n",
      "epoch:24 step:18882 [D loss: 0.326614, acc: 89.06%] [G loss: 2.155076]\n",
      "epoch:24 step:18883 [D loss: 0.418357, acc: 80.47%] [G loss: 3.288980]\n",
      "epoch:24 step:18884 [D loss: 0.356910, acc: 93.75%] [G loss: 2.693348]\n",
      "epoch:24 step:18885 [D loss: 0.426230, acc: 66.41%] [G loss: 6.379492]\n",
      "epoch:24 step:18886 [D loss: 0.370552, acc: 92.97%] [G loss: 1.674139]\n",
      "epoch:24 step:18887 [D loss: 0.826864, acc: 51.56%] [G loss: 1.976294]\n",
      "epoch:24 step:18888 [D loss: 0.684553, acc: 58.59%] [G loss: 2.097088]\n",
      "epoch:24 step:18889 [D loss: 1.226599, acc: 17.97%] [G loss: 2.450184]\n",
      "epoch:24 step:18890 [D loss: 1.041401, acc: 35.94%] [G loss: 2.671716]\n",
      "epoch:24 step:18891 [D loss: 0.222709, acc: 93.75%] [G loss: 3.028665]\n",
      "epoch:24 step:18892 [D loss: 0.432109, acc: 78.91%] [G loss: 2.225404]\n",
      "epoch:24 step:18893 [D loss: 0.777201, acc: 46.88%] [G loss: 2.597794]\n",
      "epoch:24 step:18894 [D loss: 0.322353, acc: 94.53%] [G loss: 2.120232]\n",
      "epoch:24 step:18895 [D loss: 0.673931, acc: 60.16%] [G loss: 2.449793]\n",
      "epoch:24 step:18896 [D loss: 0.560145, acc: 67.19%] [G loss: 3.206828]\n",
      "epoch:24 step:18897 [D loss: 0.423007, acc: 77.34%] [G loss: 2.747259]\n",
      "epoch:24 step:18898 [D loss: 0.247593, acc: 98.44%] [G loss: 2.571568]\n",
      "epoch:24 step:18899 [D loss: 0.448908, acc: 76.56%] [G loss: 2.820225]\n",
      "epoch:24 step:18900 [D loss: 0.479731, acc: 85.94%] [G loss: 2.501578]\n",
      "epoch:24 step:18901 [D loss: 1.007594, acc: 48.44%] [G loss: 2.579866]\n",
      "epoch:24 step:18902 [D loss: 0.361408, acc: 86.72%] [G loss: 2.968763]\n",
      "epoch:24 step:18903 [D loss: 0.293877, acc: 95.31%] [G loss: 3.182422]\n",
      "epoch:24 step:18904 [D loss: 0.755797, acc: 46.88%] [G loss: 2.812001]\n",
      "epoch:24 step:18905 [D loss: 0.547249, acc: 76.56%] [G loss: 3.717727]\n",
      "epoch:24 step:18906 [D loss: 1.085931, acc: 49.22%] [G loss: 2.037764]\n",
      "epoch:24 step:18907 [D loss: 0.446769, acc: 80.47%] [G loss: 2.538010]\n",
      "epoch:24 step:18908 [D loss: 0.534255, acc: 65.62%] [G loss: 3.543456]\n",
      "epoch:24 step:18909 [D loss: 0.251616, acc: 97.66%] [G loss: 3.889842]\n",
      "epoch:24 step:18910 [D loss: 0.416500, acc: 85.94%] [G loss: 2.958822]\n",
      "epoch:24 step:18911 [D loss: 0.214897, acc: 97.66%] [G loss: 1.982302]\n",
      "epoch:24 step:18912 [D loss: 0.615052, acc: 59.38%] [G loss: 2.658976]\n",
      "epoch:24 step:18913 [D loss: 0.540310, acc: 76.56%] [G loss: 2.393162]\n",
      "epoch:24 step:18914 [D loss: 0.434469, acc: 67.19%] [G loss: 2.699440]\n",
      "epoch:24 step:18915 [D loss: 0.158831, acc: 99.22%] [G loss: 2.827752]\n",
      "epoch:24 step:18916 [D loss: 0.775392, acc: 51.56%] [G loss: 2.993912]\n",
      "epoch:24 step:18917 [D loss: 0.875028, acc: 29.69%] [G loss: 1.740896]\n",
      "epoch:24 step:18918 [D loss: 0.516262, acc: 77.34%] [G loss: 2.782940]\n",
      "epoch:24 step:18919 [D loss: 0.559539, acc: 68.75%] [G loss: 2.950008]\n",
      "epoch:24 step:18920 [D loss: 1.201285, acc: 36.72%] [G loss: 2.471717]\n",
      "epoch:24 step:18921 [D loss: 0.341950, acc: 86.72%] [G loss: 2.865696]\n",
      "epoch:24 step:18922 [D loss: 0.602747, acc: 56.25%] [G loss: 2.695732]\n",
      "epoch:24 step:18923 [D loss: 0.429482, acc: 89.06%] [G loss: 2.783119]\n",
      "epoch:24 step:18924 [D loss: 0.603693, acc: 71.09%] [G loss: 3.218462]\n",
      "epoch:24 step:18925 [D loss: 0.264164, acc: 91.41%] [G loss: 4.292027]\n",
      "epoch:24 step:18926 [D loss: 0.739731, acc: 44.53%] [G loss: 3.429466]\n",
      "epoch:24 step:18927 [D loss: 0.776755, acc: 42.19%] [G loss: 3.714444]\n",
      "epoch:24 step:18928 [D loss: 0.573657, acc: 70.31%] [G loss: 2.474807]\n",
      "epoch:24 step:18929 [D loss: 0.653186, acc: 56.25%] [G loss: 2.108872]\n",
      "epoch:24 step:18930 [D loss: 0.508562, acc: 78.91%] [G loss: 3.394361]\n",
      "epoch:24 step:18931 [D loss: 0.192758, acc: 100.00%] [G loss: 3.093439]\n",
      "epoch:24 step:18932 [D loss: 0.562146, acc: 75.00%] [G loss: 3.001089]\n",
      "epoch:24 step:18933 [D loss: 0.234124, acc: 93.75%] [G loss: 4.114391]\n",
      "epoch:24 step:18934 [D loss: 0.260150, acc: 92.97%] [G loss: 2.089769]\n",
      "epoch:24 step:18935 [D loss: 0.530164, acc: 79.69%] [G loss: 2.222459]\n",
      "epoch:24 step:18936 [D loss: 0.437115, acc: 82.03%] [G loss: 2.408501]\n",
      "epoch:24 step:18937 [D loss: 0.397579, acc: 87.50%] [G loss: 2.212329]\n",
      "epoch:24 step:18938 [D loss: 0.548028, acc: 60.16%] [G loss: 1.929714]\n",
      "epoch:24 step:18939 [D loss: 1.204946, acc: 10.94%] [G loss: 2.240748]\n",
      "epoch:24 step:18940 [D loss: 0.396900, acc: 86.72%] [G loss: 3.352020]\n",
      "epoch:24 step:18941 [D loss: 0.405335, acc: 92.97%] [G loss: 4.787035]\n",
      "epoch:24 step:18942 [D loss: 0.296631, acc: 95.31%] [G loss: 3.689216]\n",
      "epoch:24 step:18943 [D loss: 0.409584, acc: 85.16%] [G loss: 2.344675]\n",
      "epoch:24 step:18944 [D loss: 0.409483, acc: 90.62%] [G loss: 4.476899]\n",
      "epoch:24 step:18945 [D loss: 0.562331, acc: 72.66%] [G loss: 2.730182]\n",
      "epoch:24 step:18946 [D loss: 0.858879, acc: 40.62%] [G loss: 5.415610]\n",
      "epoch:24 step:18947 [D loss: 0.234546, acc: 96.09%] [G loss: 3.270314]\n",
      "epoch:24 step:18948 [D loss: 0.268818, acc: 95.31%] [G loss: 3.314620]\n",
      "epoch:24 step:18949 [D loss: 1.028611, acc: 30.47%] [G loss: 1.410070]\n",
      "epoch:24 step:18950 [D loss: 0.858861, acc: 38.28%] [G loss: 2.192712]\n",
      "epoch:24 step:18951 [D loss: 0.304218, acc: 97.66%] [G loss: 2.775040]\n",
      "epoch:24 step:18952 [D loss: 0.375898, acc: 94.53%] [G loss: 3.451961]\n",
      "epoch:24 step:18953 [D loss: 0.524354, acc: 68.75%] [G loss: 4.103050]\n",
      "epoch:24 step:18954 [D loss: 0.380262, acc: 95.31%] [G loss: 2.010880]\n",
      "epoch:24 step:18955 [D loss: 0.196418, acc: 100.00%] [G loss: 3.248416]\n",
      "epoch:24 step:18956 [D loss: 0.611870, acc: 64.84%] [G loss: 2.655224]\n",
      "epoch:24 step:18957 [D loss: 1.402489, acc: 7.03%] [G loss: 1.841488]\n",
      "epoch:24 step:18958 [D loss: 0.182237, acc: 99.22%] [G loss: 2.876076]\n",
      "epoch:24 step:18959 [D loss: 0.356516, acc: 84.38%] [G loss: 3.698888]\n",
      "epoch:24 step:18960 [D loss: 0.961074, acc: 35.94%] [G loss: 3.264585]\n",
      "epoch:24 step:18961 [D loss: 0.222672, acc: 100.00%] [G loss: 2.890497]\n",
      "epoch:24 step:18962 [D loss: 0.518240, acc: 72.66%] [G loss: 3.077210]\n",
      "epoch:24 step:18963 [D loss: 0.136086, acc: 99.22%] [G loss: 3.625730]\n",
      "epoch:24 step:18964 [D loss: 0.697208, acc: 57.03%] [G loss: 2.435513]\n",
      "epoch:24 step:18965 [D loss: 0.659023, acc: 57.03%] [G loss: 2.801424]\n",
      "epoch:24 step:18966 [D loss: 0.319915, acc: 96.09%] [G loss: 1.996340]\n",
      "epoch:24 step:18967 [D loss: 0.656891, acc: 58.59%] [G loss: 3.789181]\n",
      "epoch:24 step:18968 [D loss: 0.341893, acc: 93.75%] [G loss: 3.223770]\n",
      "epoch:24 step:18969 [D loss: 0.659435, acc: 62.50%] [G loss: 2.121180]\n",
      "epoch:24 step:18970 [D loss: 0.410418, acc: 82.03%] [G loss: 2.619487]\n",
      "epoch:24 step:18971 [D loss: 0.524557, acc: 66.41%] [G loss: 4.220214]\n",
      "epoch:24 step:18972 [D loss: 0.622824, acc: 66.41%] [G loss: 4.020326]\n",
      "epoch:24 step:18973 [D loss: 0.417163, acc: 83.59%] [G loss: 2.387277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18974 [D loss: 0.775102, acc: 42.19%] [G loss: 3.027035]\n",
      "epoch:24 step:18975 [D loss: 0.709572, acc: 56.25%] [G loss: 3.365331]\n",
      "epoch:24 step:18976 [D loss: 0.364575, acc: 93.75%] [G loss: 2.569435]\n",
      "epoch:24 step:18977 [D loss: 0.329682, acc: 93.75%] [G loss: 2.726811]\n",
      "epoch:24 step:18978 [D loss: 1.490115, acc: 18.75%] [G loss: 3.041948]\n",
      "epoch:24 step:18979 [D loss: 0.558364, acc: 72.66%] [G loss: 2.923794]\n",
      "epoch:24 step:18980 [D loss: 1.019367, acc: 27.34%] [G loss: 2.159231]\n",
      "epoch:24 step:18981 [D loss: 1.024394, acc: 50.00%] [G loss: 3.248487]\n",
      "epoch:24 step:18982 [D loss: 0.779110, acc: 50.00%] [G loss: 2.732605]\n",
      "epoch:24 step:18983 [D loss: 0.726051, acc: 53.12%] [G loss: 1.544639]\n",
      "epoch:24 step:18984 [D loss: 1.236620, acc: 28.91%] [G loss: 2.414213]\n",
      "epoch:24 step:18985 [D loss: 0.409911, acc: 85.94%] [G loss: 2.614066]\n",
      "epoch:24 step:18986 [D loss: 0.407434, acc: 90.62%] [G loss: 2.915829]\n",
      "epoch:24 step:18987 [D loss: 0.526817, acc: 72.66%] [G loss: 2.303509]\n",
      "epoch:24 step:18988 [D loss: 0.630731, acc: 57.81%] [G loss: 3.333637]\n",
      "epoch:24 step:18989 [D loss: 0.868494, acc: 40.62%] [G loss: 2.008582]\n",
      "epoch:24 step:18990 [D loss: 0.817079, acc: 48.44%] [G loss: 2.555378]\n",
      "epoch:24 step:18991 [D loss: 1.268773, acc: 9.38%] [G loss: 1.975623]\n",
      "epoch:24 step:18992 [D loss: 0.608880, acc: 62.50%] [G loss: 2.446580]\n",
      "epoch:24 step:18993 [D loss: 0.491004, acc: 77.34%] [G loss: 2.407503]\n",
      "epoch:24 step:18994 [D loss: 0.301443, acc: 91.41%] [G loss: 2.719360]\n",
      "epoch:24 step:18995 [D loss: 0.452673, acc: 71.09%] [G loss: 2.762321]\n",
      "epoch:24 step:18996 [D loss: 0.585620, acc: 67.97%] [G loss: 2.797436]\n",
      "epoch:24 step:18997 [D loss: 0.824157, acc: 50.78%] [G loss: 2.256870]\n",
      "epoch:24 step:18998 [D loss: 0.522346, acc: 72.66%] [G loss: 1.775377]\n",
      "epoch:24 step:18999 [D loss: 0.277930, acc: 94.53%] [G loss: 3.585751]\n",
      "epoch:24 step:19000 [D loss: 0.518371, acc: 78.12%] [G loss: 2.725009]\n",
      "epoch:24 step:19001 [D loss: 0.719304, acc: 49.22%] [G loss: 2.199729]\n",
      "epoch:24 step:19002 [D loss: 0.707148, acc: 50.00%] [G loss: 2.441279]\n",
      "epoch:24 step:19003 [D loss: 0.587419, acc: 67.19%] [G loss: 2.561783]\n",
      "epoch:24 step:19004 [D loss: 0.492982, acc: 81.25%] [G loss: 2.042852]\n",
      "epoch:24 step:19005 [D loss: 0.405156, acc: 90.62%] [G loss: 1.878400]\n",
      "epoch:24 step:19006 [D loss: 0.322735, acc: 97.66%] [G loss: 2.984241]\n",
      "epoch:24 step:19007 [D loss: 0.731809, acc: 54.69%] [G loss: 1.941795]\n",
      "epoch:24 step:19008 [D loss: 0.498019, acc: 71.09%] [G loss: 2.335490]\n",
      "epoch:24 step:19009 [D loss: 0.646173, acc: 60.16%] [G loss: 2.414339]\n",
      "epoch:24 step:19010 [D loss: 0.252089, acc: 99.22%] [G loss: 2.881697]\n",
      "epoch:24 step:19011 [D loss: 0.861403, acc: 50.78%] [G loss: 3.906844]\n",
      "epoch:24 step:19012 [D loss: 0.829348, acc: 50.78%] [G loss: 3.046776]\n",
      "epoch:24 step:19013 [D loss: 1.007371, acc: 46.09%] [G loss: 2.265140]\n",
      "epoch:24 step:19014 [D loss: 0.353790, acc: 96.88%] [G loss: 2.724745]\n",
      "epoch:24 step:19015 [D loss: 0.628082, acc: 59.38%] [G loss: 2.976490]\n",
      "epoch:24 step:19016 [D loss: 0.602471, acc: 64.06%] [G loss: 3.563075]\n",
      "epoch:24 step:19017 [D loss: 0.469134, acc: 85.16%] [G loss: 2.763186]\n",
      "epoch:24 step:19018 [D loss: 0.578000, acc: 69.53%] [G loss: 2.654883]\n",
      "epoch:24 step:19019 [D loss: 0.732309, acc: 50.78%] [G loss: 2.355410]\n",
      "epoch:24 step:19020 [D loss: 0.486322, acc: 82.81%] [G loss: 2.788862]\n",
      "epoch:24 step:19021 [D loss: 0.447755, acc: 89.06%] [G loss: 2.520921]\n",
      "epoch:24 step:19022 [D loss: 0.177819, acc: 99.22%] [G loss: 3.605201]\n",
      "epoch:24 step:19023 [D loss: 0.428871, acc: 88.28%] [G loss: 2.415772]\n",
      "epoch:24 step:19024 [D loss: 0.582912, acc: 61.72%] [G loss: 2.765790]\n",
      "epoch:24 step:19025 [D loss: 0.277291, acc: 92.97%] [G loss: 2.377413]\n",
      "epoch:24 step:19026 [D loss: 0.137073, acc: 100.00%] [G loss: 3.519543]\n",
      "epoch:24 step:19027 [D loss: 0.519621, acc: 74.22%] [G loss: 2.867768]\n",
      "epoch:24 step:19028 [D loss: 0.294931, acc: 95.31%] [G loss: 3.920427]\n",
      "epoch:24 step:19029 [D loss: 0.348181, acc: 91.41%] [G loss: 2.657941]\n",
      "epoch:24 step:19030 [D loss: 0.442945, acc: 87.50%] [G loss: 3.314460]\n",
      "epoch:24 step:19031 [D loss: 0.556555, acc: 71.88%] [G loss: 3.088377]\n",
      "epoch:24 step:19032 [D loss: 0.752024, acc: 50.78%] [G loss: 3.393331]\n",
      "epoch:24 step:19033 [D loss: 0.245531, acc: 94.53%] [G loss: 2.475744]\n",
      "epoch:24 step:19034 [D loss: 1.241584, acc: 42.19%] [G loss: 2.709480]\n",
      "epoch:24 step:19035 [D loss: 0.489539, acc: 85.16%] [G loss: 3.017788]\n",
      "epoch:24 step:19036 [D loss: 0.525383, acc: 78.91%] [G loss: 2.563430]\n",
      "epoch:24 step:19037 [D loss: 0.272694, acc: 98.44%] [G loss: 2.713165]\n",
      "epoch:24 step:19038 [D loss: 1.055146, acc: 29.69%] [G loss: 2.094980]\n",
      "epoch:24 step:19039 [D loss: 0.430893, acc: 78.12%] [G loss: 3.163821]\n",
      "epoch:24 step:19040 [D loss: 0.331784, acc: 92.19%] [G loss: 3.665041]\n",
      "epoch:24 step:19041 [D loss: 0.881928, acc: 30.47%] [G loss: 1.885025]\n",
      "epoch:24 step:19042 [D loss: 0.631107, acc: 63.28%] [G loss: 1.886258]\n",
      "epoch:24 step:19043 [D loss: 0.588573, acc: 70.31%] [G loss: 3.199670]\n",
      "epoch:24 step:19044 [D loss: 0.863230, acc: 50.78%] [G loss: 3.497786]\n",
      "epoch:24 step:19045 [D loss: 0.840928, acc: 45.31%] [G loss: 2.631012]\n",
      "epoch:24 step:19046 [D loss: 0.768502, acc: 50.00%] [G loss: 1.869451]\n",
      "epoch:24 step:19047 [D loss: 0.655250, acc: 57.81%] [G loss: 4.141560]\n",
      "epoch:24 step:19048 [D loss: 0.592628, acc: 77.34%] [G loss: 2.345057]\n",
      "epoch:24 step:19049 [D loss: 0.567990, acc: 69.53%] [G loss: 2.529617]\n",
      "epoch:24 step:19050 [D loss: 0.685997, acc: 57.03%] [G loss: 2.917092]\n",
      "epoch:24 step:19051 [D loss: 0.362825, acc: 90.62%] [G loss: 2.855148]\n",
      "epoch:24 step:19052 [D loss: 0.497983, acc: 78.91%] [G loss: 2.363150]\n",
      "epoch:24 step:19053 [D loss: 0.497157, acc: 85.16%] [G loss: 2.738669]\n",
      "epoch:24 step:19054 [D loss: 0.721075, acc: 53.91%] [G loss: 2.543838]\n",
      "epoch:24 step:19055 [D loss: 0.659906, acc: 60.16%] [G loss: 3.843575]\n",
      "epoch:24 step:19056 [D loss: 0.506491, acc: 79.69%] [G loss: 2.639620]\n",
      "epoch:24 step:19057 [D loss: 0.584108, acc: 69.53%] [G loss: 3.075814]\n",
      "epoch:24 step:19058 [D loss: 0.695692, acc: 53.12%] [G loss: 3.180182]\n",
      "epoch:24 step:19059 [D loss: 0.806543, acc: 50.78%] [G loss: 3.455155]\n",
      "epoch:24 step:19060 [D loss: 0.289875, acc: 96.09%] [G loss: 2.793481]\n",
      "epoch:24 step:19061 [D loss: 1.008738, acc: 28.12%] [G loss: 3.320757]\n",
      "epoch:24 step:19062 [D loss: 0.680393, acc: 57.03%] [G loss: 3.021761]\n",
      "epoch:24 step:19063 [D loss: 0.733160, acc: 54.69%] [G loss: 2.658110]\n",
      "epoch:24 step:19064 [D loss: 0.912529, acc: 34.38%] [G loss: 2.737462]\n",
      "epoch:24 step:19065 [D loss: 0.309452, acc: 93.75%] [G loss: 3.685657]\n",
      "epoch:24 step:19066 [D loss: 0.564332, acc: 75.78%] [G loss: 2.213299]\n",
      "epoch:24 step:19067 [D loss: 0.431571, acc: 77.34%] [G loss: 3.276431]\n",
      "epoch:24 step:19068 [D loss: 0.307508, acc: 89.84%] [G loss: 2.571828]\n",
      "epoch:24 step:19069 [D loss: 0.405457, acc: 90.62%] [G loss: 3.259979]\n",
      "epoch:24 step:19070 [D loss: 0.686308, acc: 58.59%] [G loss: 2.918121]\n",
      "epoch:24 step:19071 [D loss: 0.525582, acc: 74.22%] [G loss: 3.282212]\n",
      "epoch:24 step:19072 [D loss: 0.588920, acc: 68.75%] [G loss: 2.972085]\n",
      "epoch:24 step:19073 [D loss: 0.290576, acc: 99.22%] [G loss: 3.951423]\n",
      "epoch:24 step:19074 [D loss: 0.364914, acc: 92.97%] [G loss: 2.512990]\n",
      "epoch:24 step:19075 [D loss: 0.970715, acc: 21.09%] [G loss: 2.596943]\n",
      "epoch:24 step:19076 [D loss: 0.338902, acc: 92.19%] [G loss: 2.655689]\n",
      "epoch:24 step:19077 [D loss: 0.233918, acc: 97.66%] [G loss: 3.716237]\n",
      "epoch:24 step:19078 [D loss: 0.700075, acc: 57.03%] [G loss: 3.591606]\n",
      "epoch:24 step:19079 [D loss: 0.234791, acc: 96.88%] [G loss: 3.072036]\n",
      "epoch:24 step:19080 [D loss: 0.298562, acc: 89.06%] [G loss: 3.833489]\n",
      "epoch:24 step:19081 [D loss: 0.616803, acc: 66.41%] [G loss: 2.661766]\n",
      "epoch:24 step:19082 [D loss: 0.576999, acc: 71.09%] [G loss: 1.684865]\n",
      "epoch:24 step:19083 [D loss: 0.577167, acc: 68.75%] [G loss: 2.846691]\n",
      "epoch:24 step:19084 [D loss: 0.536433, acc: 64.06%] [G loss: 4.738677]\n",
      "epoch:24 step:19085 [D loss: 0.481253, acc: 79.69%] [G loss: 4.026680]\n",
      "epoch:24 step:19086 [D loss: 0.502505, acc: 75.00%] [G loss: 2.792997]\n",
      "epoch:24 step:19087 [D loss: 0.774721, acc: 44.53%] [G loss: 2.176620]\n",
      "epoch:24 step:19088 [D loss: 0.511840, acc: 83.59%] [G loss: 3.177235]\n",
      "epoch:24 step:19089 [D loss: 0.410748, acc: 90.62%] [G loss: 3.444986]\n",
      "epoch:24 step:19090 [D loss: 0.180786, acc: 100.00%] [G loss: 3.200060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19091 [D loss: 0.437249, acc: 77.34%] [G loss: 3.402845]\n",
      "epoch:24 step:19092 [D loss: 0.269647, acc: 96.88%] [G loss: 3.753327]\n",
      "epoch:24 step:19093 [D loss: 0.620613, acc: 63.28%] [G loss: 3.113910]\n",
      "epoch:24 step:19094 [D loss: 0.303206, acc: 96.09%] [G loss: 2.819274]\n",
      "epoch:24 step:19095 [D loss: 0.942378, acc: 27.34%] [G loss: 2.484856]\n",
      "epoch:24 step:19096 [D loss: 0.425684, acc: 87.50%] [G loss: 3.076824]\n",
      "epoch:24 step:19097 [D loss: 0.944536, acc: 40.62%] [G loss: 2.210445]\n",
      "epoch:24 step:19098 [D loss: 0.611244, acc: 65.62%] [G loss: 2.182516]\n",
      "epoch:24 step:19099 [D loss: 0.868421, acc: 39.84%] [G loss: 2.374244]\n",
      "epoch:24 step:19100 [D loss: 0.478126, acc: 79.69%] [G loss: 2.613775]\n",
      "epoch:24 step:19101 [D loss: 0.589235, acc: 64.06%] [G loss: 2.886048]\n",
      "epoch:24 step:19102 [D loss: 0.398398, acc: 86.72%] [G loss: 3.107086]\n",
      "epoch:24 step:19103 [D loss: 0.475714, acc: 82.03%] [G loss: 3.018066]\n",
      "epoch:24 step:19104 [D loss: 0.931752, acc: 43.75%] [G loss: 2.164630]\n",
      "epoch:24 step:19105 [D loss: 0.356577, acc: 91.41%] [G loss: 2.135005]\n",
      "epoch:24 step:19106 [D loss: 0.566734, acc: 67.97%] [G loss: 2.842422]\n",
      "epoch:24 step:19107 [D loss: 0.580166, acc: 69.53%] [G loss: 2.786287]\n",
      "epoch:24 step:19108 [D loss: 0.511964, acc: 75.78%] [G loss: 2.837588]\n",
      "epoch:24 step:19109 [D loss: 0.324418, acc: 93.75%] [G loss: 3.604704]\n",
      "epoch:24 step:19110 [D loss: 0.672788, acc: 58.59%] [G loss: 2.133669]\n",
      "epoch:24 step:19111 [D loss: 0.209650, acc: 99.22%] [G loss: 3.327517]\n",
      "epoch:24 step:19112 [D loss: 0.357275, acc: 89.84%] [G loss: 3.729778]\n",
      "epoch:24 step:19113 [D loss: 0.359857, acc: 88.28%] [G loss: 2.248265]\n",
      "epoch:24 step:19114 [D loss: 0.823898, acc: 42.97%] [G loss: 2.704035]\n",
      "epoch:24 step:19115 [D loss: 0.813984, acc: 43.75%] [G loss: 2.517495]\n",
      "epoch:24 step:19116 [D loss: 0.439540, acc: 78.12%] [G loss: 2.861513]\n",
      "epoch:24 step:19117 [D loss: 1.196600, acc: 5.47%] [G loss: 3.841326]\n",
      "epoch:24 step:19118 [D loss: 0.281278, acc: 94.53%] [G loss: 3.545647]\n",
      "epoch:24 step:19119 [D loss: 0.259963, acc: 99.22%] [G loss: 4.797722]\n",
      "epoch:24 step:19120 [D loss: 0.327589, acc: 87.50%] [G loss: 2.762251]\n",
      "epoch:24 step:19121 [D loss: 0.630904, acc: 63.28%] [G loss: 3.537365]\n",
      "epoch:24 step:19122 [D loss: 0.965793, acc: 30.47%] [G loss: 2.379530]\n",
      "epoch:24 step:19123 [D loss: 0.317402, acc: 96.09%] [G loss: 3.015449]\n",
      "epoch:24 step:19124 [D loss: 0.319734, acc: 96.88%] [G loss: 3.033285]\n",
      "epoch:24 step:19125 [D loss: 0.558690, acc: 76.56%] [G loss: 3.713999]\n",
      "epoch:24 step:19126 [D loss: 0.869991, acc: 42.19%] [G loss: 2.130962]\n",
      "epoch:24 step:19127 [D loss: 0.797379, acc: 45.31%] [G loss: 1.598582]\n",
      "epoch:24 step:19128 [D loss: 0.271900, acc: 97.66%] [G loss: 3.030513]\n",
      "epoch:24 step:19129 [D loss: 0.549921, acc: 74.22%] [G loss: 2.809067]\n",
      "epoch:24 step:19130 [D loss: 0.325789, acc: 96.09%] [G loss: 2.619611]\n",
      "epoch:24 step:19131 [D loss: 0.634906, acc: 67.19%] [G loss: 3.406384]\n",
      "epoch:24 step:19132 [D loss: 0.396578, acc: 83.59%] [G loss: 2.737525]\n",
      "epoch:24 step:19133 [D loss: 0.424172, acc: 89.06%] [G loss: 1.870782]\n",
      "epoch:24 step:19134 [D loss: 0.486836, acc: 85.16%] [G loss: 3.247239]\n",
      "epoch:24 step:19135 [D loss: 1.067959, acc: 18.75%] [G loss: 2.857639]\n",
      "epoch:24 step:19136 [D loss: 0.477328, acc: 78.91%] [G loss: 2.635787]\n",
      "epoch:24 step:19137 [D loss: 0.759664, acc: 48.44%] [G loss: 2.444381]\n",
      "epoch:24 step:19138 [D loss: 0.155459, acc: 100.00%] [G loss: 2.557343]\n",
      "epoch:24 step:19139 [D loss: 0.566696, acc: 69.53%] [G loss: 2.844023]\n",
      "epoch:24 step:19140 [D loss: 0.465829, acc: 87.50%] [G loss: 3.262203]\n",
      "epoch:24 step:19141 [D loss: 1.132293, acc: 32.03%] [G loss: 2.486391]\n",
      "epoch:24 step:19142 [D loss: 0.670127, acc: 55.47%] [G loss: 1.536465]\n",
      "epoch:24 step:19143 [D loss: 0.432433, acc: 75.00%] [G loss: 2.943222]\n",
      "epoch:24 step:19144 [D loss: 0.349381, acc: 87.50%] [G loss: 2.959609]\n",
      "epoch:24 step:19145 [D loss: 0.481652, acc: 82.03%] [G loss: 2.148786]\n",
      "epoch:24 step:19146 [D loss: 0.462461, acc: 82.03%] [G loss: 2.204674]\n",
      "epoch:24 step:19147 [D loss: 0.956563, acc: 25.78%] [G loss: 2.357147]\n",
      "epoch:24 step:19148 [D loss: 0.498843, acc: 82.81%] [G loss: 2.422301]\n",
      "epoch:24 step:19149 [D loss: 0.259617, acc: 96.88%] [G loss: 2.655268]\n",
      "epoch:24 step:19150 [D loss: 0.360163, acc: 93.75%] [G loss: 2.293338]\n",
      "epoch:24 step:19151 [D loss: 0.500775, acc: 82.81%] [G loss: 4.043403]\n",
      "epoch:24 step:19152 [D loss: 0.213255, acc: 100.00%] [G loss: 3.345356]\n",
      "epoch:24 step:19153 [D loss: 0.491509, acc: 82.81%] [G loss: 3.120602]\n",
      "epoch:24 step:19154 [D loss: 1.202458, acc: 7.03%] [G loss: 2.036326]\n",
      "epoch:24 step:19155 [D loss: 0.585444, acc: 72.66%] [G loss: 2.226765]\n",
      "epoch:24 step:19156 [D loss: 0.254546, acc: 96.09%] [G loss: 2.865955]\n",
      "epoch:24 step:19157 [D loss: 0.828192, acc: 40.62%] [G loss: 2.076716]\n",
      "epoch:24 step:19158 [D loss: 0.432312, acc: 78.12%] [G loss: 3.140069]\n",
      "epoch:24 step:19159 [D loss: 0.798395, acc: 51.56%] [G loss: 2.602904]\n",
      "epoch:24 step:19160 [D loss: 0.532207, acc: 78.12%] [G loss: 2.962801]\n",
      "epoch:24 step:19161 [D loss: 0.449780, acc: 86.72%] [G loss: 1.912265]\n",
      "epoch:24 step:19162 [D loss: 0.493851, acc: 64.84%] [G loss: 3.009969]\n",
      "epoch:24 step:19163 [D loss: 0.305792, acc: 98.44%] [G loss: 3.349362]\n",
      "epoch:24 step:19164 [D loss: 1.239350, acc: 7.81%] [G loss: 3.123642]\n",
      "epoch:24 step:19165 [D loss: 0.572116, acc: 62.50%] [G loss: 2.814051]\n",
      "epoch:24 step:19166 [D loss: 0.197718, acc: 98.44%] [G loss: 3.528687]\n",
      "epoch:24 step:19167 [D loss: 0.526264, acc: 60.94%] [G loss: 2.858315]\n",
      "epoch:24 step:19168 [D loss: 0.386923, acc: 82.03%] [G loss: 2.163727]\n",
      "epoch:24 step:19169 [D loss: 0.437856, acc: 85.94%] [G loss: 2.626823]\n",
      "epoch:24 step:19170 [D loss: 1.208737, acc: 50.00%] [G loss: 3.012523]\n",
      "epoch:24 step:19171 [D loss: 0.482808, acc: 76.56%] [G loss: 2.254824]\n",
      "epoch:24 step:19172 [D loss: 0.359414, acc: 94.53%] [G loss: 3.290631]\n",
      "epoch:24 step:19173 [D loss: 0.505118, acc: 67.97%] [G loss: 2.126723]\n",
      "epoch:24 step:19174 [D loss: 0.294507, acc: 96.88%] [G loss: 3.153372]\n",
      "epoch:24 step:19175 [D loss: 1.050393, acc: 50.78%] [G loss: 2.639943]\n",
      "epoch:24 step:19176 [D loss: 0.392220, acc: 91.41%] [G loss: 3.582042]\n",
      "epoch:24 step:19177 [D loss: 0.280212, acc: 95.31%] [G loss: 1.586740]\n",
      "epoch:24 step:19178 [D loss: 0.201789, acc: 99.22%] [G loss: 3.738869]\n",
      "epoch:24 step:19179 [D loss: 0.273567, acc: 96.88%] [G loss: 1.926107]\n",
      "epoch:24 step:19180 [D loss: 0.573618, acc: 67.19%] [G loss: 2.184965]\n",
      "epoch:24 step:19181 [D loss: 0.480404, acc: 82.03%] [G loss: 2.184579]\n",
      "epoch:24 step:19182 [D loss: 0.797158, acc: 50.78%] [G loss: 2.633584]\n",
      "epoch:24 step:19183 [D loss: 0.723019, acc: 52.34%] [G loss: 3.007910]\n",
      "epoch:24 step:19184 [D loss: 0.589805, acc: 68.75%] [G loss: 2.007172]\n",
      "epoch:24 step:19185 [D loss: 0.365555, acc: 93.75%] [G loss: 1.987813]\n",
      "epoch:24 step:19186 [D loss: 0.771834, acc: 45.31%] [G loss: 2.481369]\n",
      "epoch:24 step:19187 [D loss: 0.465144, acc: 74.22%] [G loss: 3.656423]\n",
      "epoch:24 step:19188 [D loss: 0.879816, acc: 50.78%] [G loss: 3.045131]\n",
      "epoch:24 step:19189 [D loss: 0.795255, acc: 42.97%] [G loss: 2.498665]\n",
      "epoch:24 step:19190 [D loss: 0.373345, acc: 89.84%] [G loss: 2.004350]\n",
      "epoch:24 step:19191 [D loss: 0.564034, acc: 74.22%] [G loss: 3.541070]\n",
      "epoch:24 step:19192 [D loss: 0.777852, acc: 53.12%] [G loss: 2.369265]\n",
      "epoch:24 step:19193 [D loss: 0.348042, acc: 97.66%] [G loss: 2.996168]\n",
      "epoch:24 step:19194 [D loss: 0.447301, acc: 79.69%] [G loss: 3.003135]\n",
      "epoch:24 step:19195 [D loss: 0.713416, acc: 57.81%] [G loss: 2.805085]\n",
      "epoch:24 step:19196 [D loss: 0.285848, acc: 97.66%] [G loss: 2.095351]\n",
      "epoch:24 step:19197 [D loss: 0.778214, acc: 50.00%] [G loss: 3.355356]\n",
      "epoch:24 step:19198 [D loss: 0.441230, acc: 72.66%] [G loss: 3.283540]\n",
      "epoch:24 step:19199 [D loss: 0.313594, acc: 96.09%] [G loss: 3.141978]\n",
      "epoch:24 step:19200 [D loss: 1.150699, acc: 12.50%] [G loss: 3.490239]\n",
      "epoch:24 step:19201 [D loss: 0.337456, acc: 94.53%] [G loss: 2.895422]\n",
      "epoch:24 step:19202 [D loss: 0.204515, acc: 97.66%] [G loss: 2.174119]\n",
      "epoch:24 step:19203 [D loss: 0.588610, acc: 65.62%] [G loss: 2.599684]\n",
      "epoch:24 step:19204 [D loss: 0.848265, acc: 40.62%] [G loss: 1.394589]\n",
      "epoch:24 step:19205 [D loss: 0.580696, acc: 67.97%] [G loss: 3.227812]\n",
      "epoch:24 step:19206 [D loss: 0.604382, acc: 63.28%] [G loss: 2.054738]\n",
      "epoch:24 step:19207 [D loss: 0.479339, acc: 86.72%] [G loss: 2.284631]\n",
      "epoch:24 step:19208 [D loss: 0.527935, acc: 79.69%] [G loss: 2.105797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19209 [D loss: 0.570139, acc: 71.88%] [G loss: 2.324144]\n",
      "epoch:24 step:19210 [D loss: 0.165477, acc: 98.44%] [G loss: 3.714180]\n",
      "epoch:24 step:19211 [D loss: 0.282139, acc: 85.16%] [G loss: 3.646608]\n",
      "epoch:24 step:19212 [D loss: 0.398986, acc: 84.38%] [G loss: 3.070909]\n",
      "epoch:24 step:19213 [D loss: 0.879784, acc: 50.78%] [G loss: 3.503392]\n",
      "epoch:24 step:19214 [D loss: 0.198244, acc: 98.44%] [G loss: 3.149638]\n",
      "epoch:24 step:19215 [D loss: 0.795792, acc: 44.53%] [G loss: 3.217094]\n",
      "epoch:24 step:19216 [D loss: 0.461065, acc: 68.75%] [G loss: 2.431883]\n",
      "epoch:24 step:19217 [D loss: 0.375951, acc: 92.19%] [G loss: 2.693870]\n",
      "epoch:24 step:19218 [D loss: 0.563353, acc: 75.00%] [G loss: 2.055781]\n",
      "epoch:24 step:19219 [D loss: 0.463721, acc: 82.81%] [G loss: 2.020262]\n",
      "epoch:24 step:19220 [D loss: 0.635337, acc: 55.47%] [G loss: 2.441132]\n",
      "epoch:24 step:19221 [D loss: 0.502761, acc: 76.56%] [G loss: 2.007830]\n",
      "epoch:24 step:19222 [D loss: 0.437109, acc: 88.28%] [G loss: 2.988274]\n",
      "epoch:24 step:19223 [D loss: 1.319944, acc: 36.72%] [G loss: 1.978258]\n",
      "epoch:24 step:19224 [D loss: 0.381322, acc: 89.84%] [G loss: 2.363869]\n",
      "epoch:24 step:19225 [D loss: 0.341300, acc: 92.19%] [G loss: 2.192638]\n",
      "epoch:24 step:19226 [D loss: 1.029009, acc: 46.88%] [G loss: 2.903549]\n",
      "epoch:24 step:19227 [D loss: 0.470453, acc: 70.31%] [G loss: 2.910880]\n",
      "epoch:24 step:19228 [D loss: 0.267771, acc: 98.44%] [G loss: 3.112964]\n",
      "epoch:24 step:19229 [D loss: 0.280800, acc: 96.88%] [G loss: 3.300226]\n",
      "epoch:24 step:19230 [D loss: 0.493017, acc: 81.25%] [G loss: 3.532726]\n",
      "epoch:24 step:19231 [D loss: 0.854996, acc: 36.72%] [G loss: 3.404194]\n",
      "epoch:24 step:19232 [D loss: 0.294985, acc: 96.88%] [G loss: 2.097254]\n",
      "epoch:24 step:19233 [D loss: 0.866146, acc: 39.84%] [G loss: 2.962040]\n",
      "epoch:24 step:19234 [D loss: 0.286302, acc: 96.88%] [G loss: 2.280536]\n",
      "epoch:24 step:19235 [D loss: 0.452665, acc: 89.84%] [G loss: 2.934922]\n",
      "epoch:24 step:19236 [D loss: 0.659079, acc: 58.59%] [G loss: 3.461817]\n",
      "epoch:24 step:19237 [D loss: 0.439228, acc: 75.00%] [G loss: 4.027903]\n",
      "epoch:24 step:19238 [D loss: 0.478543, acc: 67.97%] [G loss: 3.492050]\n",
      "epoch:24 step:19239 [D loss: 0.689031, acc: 61.72%] [G loss: 2.084334]\n",
      "epoch:24 step:19240 [D loss: 0.715691, acc: 54.69%] [G loss: 2.559619]\n",
      "epoch:24 step:19241 [D loss: 0.159277, acc: 99.22%] [G loss: 4.055339]\n",
      "epoch:24 step:19242 [D loss: 0.417658, acc: 78.12%] [G loss: 3.752749]\n",
      "epoch:24 step:19243 [D loss: 0.253696, acc: 99.22%] [G loss: 2.871741]\n",
      "epoch:24 step:19244 [D loss: 0.852404, acc: 49.22%] [G loss: 2.640190]\n",
      "epoch:24 step:19245 [D loss: 0.663127, acc: 61.72%] [G loss: 2.622410]\n",
      "epoch:24 step:19246 [D loss: 0.241865, acc: 99.22%] [G loss: 3.065103]\n",
      "epoch:24 step:19247 [D loss: 0.512163, acc: 78.12%] [G loss: 2.295626]\n",
      "epoch:24 step:19248 [D loss: 0.324368, acc: 86.72%] [G loss: 3.022033]\n",
      "epoch:24 step:19249 [D loss: 0.581790, acc: 67.97%] [G loss: 1.972965]\n",
      "epoch:24 step:19250 [D loss: 0.524101, acc: 80.47%] [G loss: 3.367317]\n",
      "epoch:24 step:19251 [D loss: 0.474605, acc: 78.91%] [G loss: 2.746196]\n",
      "epoch:24 step:19252 [D loss: 0.400377, acc: 91.41%] [G loss: 2.320107]\n",
      "epoch:24 step:19253 [D loss: 0.344547, acc: 94.53%] [G loss: 3.195357]\n",
      "epoch:24 step:19254 [D loss: 0.241740, acc: 100.00%] [G loss: 3.125181]\n",
      "epoch:24 step:19255 [D loss: 0.671893, acc: 53.91%] [G loss: 2.954376]\n",
      "epoch:24 step:19256 [D loss: 0.291460, acc: 96.09%] [G loss: 3.339557]\n",
      "epoch:24 step:19257 [D loss: 0.661377, acc: 63.28%] [G loss: 3.551745]\n",
      "epoch:24 step:19258 [D loss: 0.310125, acc: 97.66%] [G loss: 2.944158]\n",
      "epoch:24 step:19259 [D loss: 0.360447, acc: 89.06%] [G loss: 3.258607]\n",
      "epoch:24 step:19260 [D loss: 0.788186, acc: 53.12%] [G loss: 2.424003]\n",
      "epoch:24 step:19261 [D loss: 0.172916, acc: 98.44%] [G loss: 3.328952]\n",
      "epoch:24 step:19262 [D loss: 0.482926, acc: 84.38%] [G loss: 2.102528]\n",
      "epoch:24 step:19263 [D loss: 0.985373, acc: 27.34%] [G loss: 3.000457]\n",
      "epoch:24 step:19264 [D loss: 0.468554, acc: 89.06%] [G loss: 3.040599]\n",
      "epoch:24 step:19265 [D loss: 0.300272, acc: 96.09%] [G loss: 2.534756]\n",
      "epoch:24 step:19266 [D loss: 0.907520, acc: 26.56%] [G loss: 1.836099]\n",
      "epoch:24 step:19267 [D loss: 0.519498, acc: 69.53%] [G loss: 2.658137]\n",
      "epoch:24 step:19268 [D loss: 0.374400, acc: 93.75%] [G loss: 3.119531]\n",
      "epoch:24 step:19269 [D loss: 0.612270, acc: 63.28%] [G loss: 2.023281]\n",
      "epoch:24 step:19270 [D loss: 0.599244, acc: 69.53%] [G loss: 2.541985]\n",
      "epoch:24 step:19271 [D loss: 0.639065, acc: 52.34%] [G loss: 2.058174]\n",
      "epoch:24 step:19272 [D loss: 0.542098, acc: 65.62%] [G loss: 3.036666]\n",
      "epoch:24 step:19273 [D loss: 0.494014, acc: 73.44%] [G loss: 3.290204]\n",
      "epoch:24 step:19274 [D loss: 0.654470, acc: 59.38%] [G loss: 3.871973]\n",
      "epoch:24 step:19275 [D loss: 0.476422, acc: 80.47%] [G loss: 3.546480]\n",
      "epoch:24 step:19276 [D loss: 0.728216, acc: 53.91%] [G loss: 2.599802]\n",
      "epoch:24 step:19277 [D loss: 0.782602, acc: 46.88%] [G loss: 2.864716]\n",
      "epoch:24 step:19278 [D loss: 0.236865, acc: 99.22%] [G loss: 2.738512]\n",
      "epoch:24 step:19279 [D loss: 0.520848, acc: 78.12%] [G loss: 3.482465]\n",
      "epoch:24 step:19280 [D loss: 0.159567, acc: 99.22%] [G loss: 4.760166]\n",
      "epoch:24 step:19281 [D loss: 0.395219, acc: 92.97%] [G loss: 2.377708]\n",
      "epoch:24 step:19282 [D loss: 0.432549, acc: 86.72%] [G loss: 4.060904]\n",
      "epoch:24 step:19283 [D loss: 0.468089, acc: 81.25%] [G loss: 3.209193]\n",
      "epoch:24 step:19284 [D loss: 0.404496, acc: 89.84%] [G loss: 2.370049]\n",
      "epoch:24 step:19285 [D loss: 0.310301, acc: 91.41%] [G loss: 2.740866]\n",
      "epoch:24 step:19286 [D loss: 0.591055, acc: 65.62%] [G loss: 2.368736]\n",
      "epoch:24 step:19287 [D loss: 0.617508, acc: 64.84%] [G loss: 2.949333]\n",
      "epoch:24 step:19288 [D loss: 0.397301, acc: 90.62%] [G loss: 2.207672]\n",
      "epoch:24 step:19289 [D loss: 0.307399, acc: 93.75%] [G loss: 2.639268]\n",
      "epoch:24 step:19290 [D loss: 0.515996, acc: 77.34%] [G loss: 2.268481]\n",
      "epoch:24 step:19291 [D loss: 0.585267, acc: 69.53%] [G loss: 2.656657]\n",
      "epoch:24 step:19292 [D loss: 0.758355, acc: 47.66%] [G loss: 1.653674]\n",
      "epoch:24 step:19293 [D loss: 0.549299, acc: 78.12%] [G loss: 3.514492]\n",
      "epoch:24 step:19294 [D loss: 0.194612, acc: 99.22%] [G loss: 2.592129]\n",
      "epoch:24 step:19295 [D loss: 0.500092, acc: 79.69%] [G loss: 2.500847]\n",
      "epoch:24 step:19296 [D loss: 0.508390, acc: 80.47%] [G loss: 2.962358]\n",
      "epoch:24 step:19297 [D loss: 1.034521, acc: 26.56%] [G loss: 2.490052]\n",
      "epoch:24 step:19298 [D loss: 0.367515, acc: 92.19%] [G loss: 2.960371]\n",
      "epoch:24 step:19299 [D loss: 0.289355, acc: 93.75%] [G loss: 3.347143]\n",
      "epoch:24 step:19300 [D loss: 0.360721, acc: 92.19%] [G loss: 2.432036]\n",
      "epoch:24 step:19301 [D loss: 0.505061, acc: 78.12%] [G loss: 2.899979]\n",
      "epoch:24 step:19302 [D loss: 0.471953, acc: 84.38%] [G loss: 3.114341]\n",
      "epoch:24 step:19303 [D loss: 0.302493, acc: 94.53%] [G loss: 3.000675]\n",
      "epoch:24 step:19304 [D loss: 0.529808, acc: 79.69%] [G loss: 2.463898]\n",
      "epoch:24 step:19305 [D loss: 0.430290, acc: 87.50%] [G loss: 2.763683]\n",
      "epoch:24 step:19306 [D loss: 0.383247, acc: 92.97%] [G loss: 3.488439]\n",
      "epoch:24 step:19307 [D loss: 0.973926, acc: 18.75%] [G loss: 3.415354]\n",
      "epoch:24 step:19308 [D loss: 0.516722, acc: 78.12%] [G loss: 2.843416]\n",
      "epoch:24 step:19309 [D loss: 0.481119, acc: 85.94%] [G loss: 3.247444]\n",
      "epoch:24 step:19310 [D loss: 0.710109, acc: 52.34%] [G loss: 2.593984]\n",
      "epoch:24 step:19311 [D loss: 0.707510, acc: 52.34%] [G loss: 2.786944]\n",
      "epoch:24 step:19312 [D loss: 0.140225, acc: 100.00%] [G loss: 4.858294]\n",
      "epoch:24 step:19313 [D loss: 0.124025, acc: 100.00%] [G loss: 3.574799]\n",
      "epoch:24 step:19314 [D loss: 0.768026, acc: 53.12%] [G loss: 2.000931]\n",
      "epoch:24 step:19315 [D loss: 1.060710, acc: 20.31%] [G loss: 2.850470]\n",
      "epoch:24 step:19316 [D loss: 0.309957, acc: 97.66%] [G loss: 2.576841]\n",
      "epoch:24 step:19317 [D loss: 0.955085, acc: 50.78%] [G loss: 2.476066]\n",
      "epoch:24 step:19318 [D loss: 1.059780, acc: 11.72%] [G loss: 3.668735]\n",
      "epoch:24 step:19319 [D loss: 0.863570, acc: 50.78%] [G loss: 2.526783]\n",
      "epoch:24 step:19320 [D loss: 0.364763, acc: 93.75%] [G loss: 2.824655]\n",
      "epoch:24 step:19321 [D loss: 0.342842, acc: 92.97%] [G loss: 2.809148]\n",
      "epoch:24 step:19322 [D loss: 0.300194, acc: 96.88%] [G loss: 3.215389]\n",
      "epoch:24 step:19323 [D loss: 0.525299, acc: 74.22%] [G loss: 2.673137]\n",
      "epoch:24 step:19324 [D loss: 0.297617, acc: 93.75%] [G loss: 2.240098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19325 [D loss: 0.525930, acc: 67.97%] [G loss: 3.429236]\n",
      "epoch:24 step:19326 [D loss: 0.642133, acc: 60.16%] [G loss: 2.864128]\n",
      "epoch:24 step:19327 [D loss: 0.479706, acc: 76.56%] [G loss: 3.530867]\n",
      "epoch:24 step:19328 [D loss: 0.649755, acc: 62.50%] [G loss: 2.737065]\n",
      "epoch:24 step:19329 [D loss: 0.228807, acc: 97.66%] [G loss: 3.500408]\n",
      "epoch:24 step:19330 [D loss: 0.141212, acc: 100.00%] [G loss: 3.427513]\n",
      "epoch:24 step:19331 [D loss: 0.515208, acc: 71.09%] [G loss: 2.779985]\n",
      "epoch:24 step:19332 [D loss: 0.391862, acc: 83.59%] [G loss: 2.290979]\n",
      "epoch:24 step:19333 [D loss: 1.117407, acc: 21.88%] [G loss: 2.738162]\n",
      "epoch:24 step:19334 [D loss: 0.523216, acc: 73.44%] [G loss: 3.178753]\n",
      "epoch:24 step:19335 [D loss: 0.624021, acc: 60.94%] [G loss: 3.111411]\n",
      "epoch:24 step:19336 [D loss: 0.876299, acc: 48.44%] [G loss: 2.470578]\n",
      "epoch:24 step:19337 [D loss: 0.341443, acc: 91.41%] [G loss: 3.946925]\n",
      "epoch:24 step:19338 [D loss: 0.672288, acc: 62.50%] [G loss: 3.138637]\n",
      "epoch:24 step:19339 [D loss: 0.335824, acc: 93.75%] [G loss: 2.394590]\n",
      "epoch:24 step:19340 [D loss: 0.574560, acc: 60.16%] [G loss: 3.049970]\n",
      "epoch:24 step:19341 [D loss: 0.970439, acc: 48.44%] [G loss: 2.374057]\n",
      "epoch:24 step:19342 [D loss: 0.497324, acc: 70.31%] [G loss: 2.799881]\n",
      "epoch:24 step:19343 [D loss: 0.692653, acc: 55.47%] [G loss: 3.583447]\n",
      "epoch:24 step:19344 [D loss: 0.625542, acc: 67.97%] [G loss: 2.372898]\n",
      "epoch:24 step:19345 [D loss: 0.341155, acc: 91.41%] [G loss: 2.911589]\n",
      "epoch:24 step:19346 [D loss: 0.736787, acc: 53.12%] [G loss: 2.690561]\n",
      "epoch:24 step:19347 [D loss: 0.477720, acc: 76.56%] [G loss: 2.627478]\n",
      "epoch:24 step:19348 [D loss: 0.201092, acc: 100.00%] [G loss: 2.947000]\n",
      "epoch:24 step:19349 [D loss: 0.654000, acc: 56.25%] [G loss: 2.480897]\n",
      "epoch:24 step:19350 [D loss: 0.144120, acc: 99.22%] [G loss: 4.157369]\n",
      "epoch:24 step:19351 [D loss: 0.919580, acc: 42.19%] [G loss: 2.223513]\n",
      "epoch:24 step:19352 [D loss: 0.704157, acc: 59.38%] [G loss: 4.334299]\n",
      "epoch:24 step:19353 [D loss: 0.496419, acc: 83.59%] [G loss: 2.993314]\n",
      "epoch:24 step:19354 [D loss: 0.425100, acc: 77.34%] [G loss: 3.058684]\n",
      "epoch:24 step:19355 [D loss: 0.247962, acc: 97.66%] [G loss: 3.260851]\n",
      "epoch:24 step:19356 [D loss: 0.418193, acc: 85.16%] [G loss: 3.757619]\n",
      "epoch:24 step:19357 [D loss: 0.564410, acc: 69.53%] [G loss: 2.739166]\n",
      "epoch:24 step:19358 [D loss: 0.150271, acc: 100.00%] [G loss: 2.585644]\n",
      "epoch:24 step:19359 [D loss: 0.507458, acc: 78.91%] [G loss: 3.551960]\n",
      "epoch:24 step:19360 [D loss: 0.413182, acc: 85.16%] [G loss: 2.520545]\n",
      "epoch:24 step:19361 [D loss: 0.499277, acc: 78.91%] [G loss: 2.697678]\n",
      "epoch:24 step:19362 [D loss: 0.768961, acc: 56.25%] [G loss: 2.771355]\n",
      "epoch:24 step:19363 [D loss: 0.660759, acc: 57.03%] [G loss: 3.150767]\n",
      "epoch:24 step:19364 [D loss: 1.417440, acc: 44.53%] [G loss: 2.556937]\n",
      "epoch:24 step:19365 [D loss: 0.273454, acc: 89.06%] [G loss: 3.286576]\n",
      "epoch:24 step:19366 [D loss: 0.462504, acc: 85.16%] [G loss: 2.043671]\n",
      "epoch:24 step:19367 [D loss: 0.466184, acc: 78.12%] [G loss: 2.830446]\n",
      "epoch:24 step:19368 [D loss: 0.406143, acc: 89.84%] [G loss: 3.028226]\n",
      "epoch:24 step:19369 [D loss: 0.253874, acc: 94.53%] [G loss: 3.781712]\n",
      "epoch:24 step:19370 [D loss: 0.906187, acc: 41.41%] [G loss: 3.333315]\n",
      "epoch:24 step:19371 [D loss: 0.256513, acc: 100.00%] [G loss: 2.742126]\n",
      "epoch:24 step:19372 [D loss: 0.570008, acc: 78.91%] [G loss: 3.369957]\n",
      "epoch:24 step:19373 [D loss: 0.411131, acc: 89.84%] [G loss: 2.237103]\n",
      "epoch:24 step:19374 [D loss: 0.381498, acc: 88.28%] [G loss: 2.913302]\n",
      "epoch:24 step:19375 [D loss: 0.573218, acc: 74.22%] [G loss: 2.574431]\n",
      "epoch:24 step:19376 [D loss: 0.569452, acc: 74.22%] [G loss: 2.982677]\n",
      "epoch:24 step:19377 [D loss: 0.332459, acc: 85.16%] [G loss: 3.474434]\n",
      "epoch:24 step:19378 [D loss: 0.521195, acc: 80.47%] [G loss: 2.960647]\n",
      "epoch:24 step:19379 [D loss: 0.776062, acc: 51.56%] [G loss: 2.360576]\n",
      "epoch:24 step:19380 [D loss: 0.362678, acc: 89.06%] [G loss: 2.410859]\n",
      "epoch:24 step:19381 [D loss: 0.882263, acc: 46.88%] [G loss: 3.448642]\n",
      "epoch:24 step:19382 [D loss: 0.265726, acc: 97.66%] [G loss: 3.042687]\n",
      "epoch:24 step:19383 [D loss: 0.617061, acc: 69.53%] [G loss: 1.924514]\n",
      "epoch:24 step:19384 [D loss: 0.456432, acc: 84.38%] [G loss: 3.444456]\n",
      "epoch:24 step:19385 [D loss: 0.585735, acc: 69.53%] [G loss: 2.299835]\n",
      "epoch:24 step:19386 [D loss: 0.575207, acc: 67.97%] [G loss: 2.695683]\n",
      "epoch:24 step:19387 [D loss: 0.292895, acc: 90.62%] [G loss: 2.515003]\n",
      "epoch:24 step:19388 [D loss: 0.498123, acc: 74.22%] [G loss: 3.931365]\n",
      "epoch:24 step:19389 [D loss: 0.852837, acc: 37.50%] [G loss: 1.928304]\n",
      "epoch:24 step:19390 [D loss: 0.630913, acc: 64.84%] [G loss: 3.337517]\n",
      "epoch:24 step:19391 [D loss: 0.492607, acc: 75.78%] [G loss: 4.184294]\n",
      "epoch:24 step:19392 [D loss: 0.279680, acc: 96.88%] [G loss: 2.220244]\n",
      "epoch:24 step:19393 [D loss: 0.790659, acc: 48.44%] [G loss: 2.729396]\n",
      "epoch:24 step:19394 [D loss: 0.186050, acc: 100.00%] [G loss: 3.593813]\n",
      "epoch:24 step:19395 [D loss: 0.537652, acc: 76.56%] [G loss: 3.260499]\n",
      "epoch:24 step:19396 [D loss: 0.325513, acc: 95.31%] [G loss: 3.118875]\n",
      "epoch:24 step:19397 [D loss: 0.526983, acc: 67.97%] [G loss: 2.915506]\n",
      "epoch:24 step:19398 [D loss: 0.318775, acc: 92.97%] [G loss: 2.836394]\n",
      "epoch:24 step:19399 [D loss: 0.145916, acc: 100.00%] [G loss: 5.621048]\n",
      "epoch:24 step:19400 [D loss: 1.201363, acc: 37.50%] [G loss: 2.504617]\n",
      "epoch:24 step:19401 [D loss: 0.784784, acc: 42.19%] [G loss: 2.347082]\n",
      "epoch:24 step:19402 [D loss: 0.434149, acc: 74.22%] [G loss: 3.401739]\n",
      "epoch:24 step:19403 [D loss: 0.351832, acc: 97.66%] [G loss: 2.187035]\n",
      "epoch:24 step:19404 [D loss: 0.484151, acc: 75.00%] [G loss: 2.337381]\n",
      "epoch:24 step:19405 [D loss: 0.369501, acc: 91.41%] [G loss: 2.682998]\n",
      "epoch:24 step:19406 [D loss: 0.383935, acc: 79.69%] [G loss: 2.593064]\n",
      "epoch:24 step:19407 [D loss: 0.664656, acc: 57.03%] [G loss: 2.900737]\n",
      "epoch:24 step:19408 [D loss: 0.345260, acc: 91.41%] [G loss: 3.271163]\n",
      "epoch:24 step:19409 [D loss: 0.260360, acc: 97.66%] [G loss: 2.092056]\n",
      "epoch:24 step:19410 [D loss: 0.144771, acc: 100.00%] [G loss: 3.925835]\n",
      "epoch:24 step:19411 [D loss: 0.359385, acc: 94.53%] [G loss: 4.116864]\n",
      "epoch:24 step:19412 [D loss: 0.545532, acc: 71.88%] [G loss: 3.437833]\n",
      "epoch:24 step:19413 [D loss: 0.181147, acc: 100.00%] [G loss: 3.681595]\n",
      "epoch:24 step:19414 [D loss: 0.769446, acc: 52.34%] [G loss: 1.913114]\n",
      "epoch:24 step:19415 [D loss: 0.511427, acc: 78.91%] [G loss: 4.513915]\n",
      "epoch:24 step:19416 [D loss: 0.479533, acc: 86.72%] [G loss: 3.170074]\n",
      "epoch:24 step:19417 [D loss: 0.798936, acc: 48.44%] [G loss: 2.539418]\n",
      "epoch:24 step:19418 [D loss: 1.065134, acc: 15.62%] [G loss: 2.224941]\n",
      "epoch:24 step:19419 [D loss: 0.387253, acc: 91.41%] [G loss: 2.593307]\n",
      "epoch:24 step:19420 [D loss: 0.145414, acc: 99.22%] [G loss: 3.779408]\n",
      "epoch:24 step:19421 [D loss: 0.336407, acc: 96.88%] [G loss: 3.347193]\n",
      "epoch:24 step:19422 [D loss: 0.718588, acc: 57.81%] [G loss: 3.001621]\n",
      "epoch:24 step:19423 [D loss: 0.689319, acc: 59.38%] [G loss: 3.085814]\n",
      "epoch:24 step:19424 [D loss: 0.133017, acc: 100.00%] [G loss: 3.410638]\n",
      "epoch:24 step:19425 [D loss: 0.415922, acc: 75.78%] [G loss: 3.636101]\n",
      "epoch:24 step:19426 [D loss: 0.559571, acc: 66.41%] [G loss: 2.646329]\n",
      "epoch:24 step:19427 [D loss: 0.643666, acc: 60.16%] [G loss: 3.585239]\n",
      "epoch:24 step:19428 [D loss: 0.494100, acc: 78.91%] [G loss: 2.455936]\n",
      "epoch:24 step:19429 [D loss: 0.542217, acc: 71.09%] [G loss: 2.003811]\n",
      "epoch:24 step:19430 [D loss: 0.405770, acc: 81.25%] [G loss: 3.067330]\n",
      "epoch:24 step:19431 [D loss: 0.563217, acc: 72.66%] [G loss: 2.830171]\n",
      "epoch:24 step:19432 [D loss: 0.527065, acc: 75.78%] [G loss: 1.380126]\n",
      "epoch:24 step:19433 [D loss: 0.482952, acc: 67.97%] [G loss: 3.488866]\n",
      "epoch:24 step:19434 [D loss: 0.313714, acc: 92.19%] [G loss: 3.060566]\n",
      "epoch:24 step:19435 [D loss: 0.446582, acc: 88.28%] [G loss: 3.211901]\n",
      "epoch:24 step:19436 [D loss: 0.434897, acc: 85.94%] [G loss: 4.700177]\n",
      "epoch:24 step:19437 [D loss: 0.846775, acc: 40.62%] [G loss: 3.485903]\n",
      "epoch:24 step:19438 [D loss: 0.583611, acc: 67.97%] [G loss: 2.958295]\n",
      "epoch:24 step:19439 [D loss: 0.185892, acc: 100.00%] [G loss: 3.659807]\n",
      "epoch:24 step:19440 [D loss: 0.770054, acc: 50.00%] [G loss: 3.428346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19441 [D loss: 0.580122, acc: 70.31%] [G loss: 2.440415]\n",
      "epoch:24 step:19442 [D loss: 0.307002, acc: 90.62%] [G loss: 3.106034]\n",
      "epoch:24 step:19443 [D loss: 0.361999, acc: 96.09%] [G loss: 2.708020]\n",
      "epoch:24 step:19444 [D loss: 0.400819, acc: 78.12%] [G loss: 3.096992]\n",
      "epoch:24 step:19445 [D loss: 0.524904, acc: 76.56%] [G loss: 2.281525]\n",
      "epoch:24 step:19446 [D loss: 0.494871, acc: 78.91%] [G loss: 3.061492]\n",
      "epoch:24 step:19447 [D loss: 0.795026, acc: 57.03%] [G loss: 2.038280]\n",
      "epoch:24 step:19448 [D loss: 0.325184, acc: 98.44%] [G loss: 2.526465]\n",
      "epoch:24 step:19449 [D loss: 0.316775, acc: 97.66%] [G loss: 2.942728]\n",
      "epoch:24 step:19450 [D loss: 0.789834, acc: 54.69%] [G loss: 3.311585]\n",
      "epoch:24 step:19451 [D loss: 0.524719, acc: 71.09%] [G loss: 2.986064]\n",
      "epoch:24 step:19452 [D loss: 0.392735, acc: 86.72%] [G loss: 2.074768]\n",
      "epoch:24 step:19453 [D loss: 0.667002, acc: 54.69%] [G loss: 2.713162]\n",
      "epoch:24 step:19454 [D loss: 0.952406, acc: 33.59%] [G loss: 1.963412]\n",
      "epoch:24 step:19455 [D loss: 0.330663, acc: 89.06%] [G loss: 3.600481]\n",
      "epoch:24 step:19456 [D loss: 0.609658, acc: 65.62%] [G loss: 2.433636]\n",
      "epoch:24 step:19457 [D loss: 0.222299, acc: 100.00%] [G loss: 2.930295]\n",
      "epoch:24 step:19458 [D loss: 0.410557, acc: 92.97%] [G loss: 3.982568]\n",
      "epoch:24 step:19459 [D loss: 0.506817, acc: 67.97%] [G loss: 3.000364]\n",
      "epoch:24 step:19460 [D loss: 0.488788, acc: 70.31%] [G loss: 3.713245]\n",
      "epoch:24 step:19461 [D loss: 0.737112, acc: 48.44%] [G loss: 2.589062]\n",
      "epoch:24 step:19462 [D loss: 0.225257, acc: 97.66%] [G loss: 2.001978]\n",
      "epoch:24 step:19463 [D loss: 0.142142, acc: 99.22%] [G loss: 1.992057]\n",
      "epoch:24 step:19464 [D loss: 0.392142, acc: 85.94%] [G loss: 3.492564]\n",
      "epoch:24 step:19465 [D loss: 0.576712, acc: 67.19%] [G loss: 2.742373]\n",
      "epoch:24 step:19466 [D loss: 0.617794, acc: 68.75%] [G loss: 3.157754]\n",
      "epoch:24 step:19467 [D loss: 0.505173, acc: 75.00%] [G loss: 2.629619]\n",
      "epoch:24 step:19468 [D loss: 0.675770, acc: 58.59%] [G loss: 2.971873]\n",
      "epoch:24 step:19469 [D loss: 0.522150, acc: 83.59%] [G loss: 2.921336]\n",
      "epoch:24 step:19470 [D loss: 0.429597, acc: 89.06%] [G loss: 2.122602]\n",
      "epoch:24 step:19471 [D loss: 0.808882, acc: 40.62%] [G loss: 2.868746]\n",
      "epoch:24 step:19472 [D loss: 0.643039, acc: 60.16%] [G loss: 3.449264]\n",
      "epoch:24 step:19473 [D loss: 0.344728, acc: 96.88%] [G loss: 2.991272]\n",
      "epoch:24 step:19474 [D loss: 0.430083, acc: 77.34%] [G loss: 2.916571]\n",
      "epoch:24 step:19475 [D loss: 0.826084, acc: 51.56%] [G loss: 2.668197]\n",
      "epoch:24 step:19476 [D loss: 0.224684, acc: 99.22%] [G loss: 2.722781]\n",
      "epoch:24 step:19477 [D loss: 0.565069, acc: 60.94%] [G loss: 3.423951]\n",
      "epoch:24 step:19478 [D loss: 0.590056, acc: 60.94%] [G loss: 2.925182]\n",
      "epoch:24 step:19479 [D loss: 0.442693, acc: 74.22%] [G loss: 2.539761]\n",
      "epoch:24 step:19480 [D loss: 0.348375, acc: 95.31%] [G loss: 3.709516]\n",
      "epoch:24 step:19481 [D loss: 0.369445, acc: 82.03%] [G loss: 2.857850]\n",
      "epoch:24 step:19482 [D loss: 0.961896, acc: 26.56%] [G loss: 3.301328]\n",
      "epoch:24 step:19483 [D loss: 0.453918, acc: 76.56%] [G loss: 3.784973]\n",
      "epoch:24 step:19484 [D loss: 0.251234, acc: 96.09%] [G loss: 2.628114]\n",
      "epoch:24 step:19485 [D loss: 0.148783, acc: 99.22%] [G loss: 3.384855]\n",
      "epoch:24 step:19486 [D loss: 0.790741, acc: 46.09%] [G loss: 3.656717]\n",
      "epoch:24 step:19487 [D loss: 0.492115, acc: 78.91%] [G loss: 2.547668]\n",
      "epoch:24 step:19488 [D loss: 1.107810, acc: 23.44%] [G loss: 2.101049]\n",
      "epoch:24 step:19489 [D loss: 0.254443, acc: 98.44%] [G loss: 3.329209]\n",
      "epoch:24 step:19490 [D loss: 0.664957, acc: 62.50%] [G loss: 3.036108]\n",
      "epoch:24 step:19491 [D loss: 0.420713, acc: 77.34%] [G loss: 4.240588]\n",
      "epoch:24 step:19492 [D loss: 0.819822, acc: 53.91%] [G loss: 2.884036]\n",
      "epoch:24 step:19493 [D loss: 0.673054, acc: 55.47%] [G loss: 3.715863]\n",
      "epoch:24 step:19494 [D loss: 0.374017, acc: 88.28%] [G loss: 3.505560]\n",
      "epoch:24 step:19495 [D loss: 0.414561, acc: 85.94%] [G loss: 2.727023]\n",
      "epoch:24 step:19496 [D loss: 0.322461, acc: 88.28%] [G loss: 3.409309]\n",
      "epoch:24 step:19497 [D loss: 0.077626, acc: 100.00%] [G loss: 2.744308]\n",
      "epoch:24 step:19498 [D loss: 0.636626, acc: 69.53%] [G loss: 3.706393]\n",
      "epoch:24 step:19499 [D loss: 0.367846, acc: 91.41%] [G loss: 2.716565]\n",
      "epoch:24 step:19500 [D loss: 0.816067, acc: 40.62%] [G loss: 2.903059]\n",
      "epoch:24 step:19501 [D loss: 0.370112, acc: 90.62%] [G loss: 2.474241]\n",
      "epoch:24 step:19502 [D loss: 0.830481, acc: 48.44%] [G loss: 2.177971]\n",
      "epoch:24 step:19503 [D loss: 0.709279, acc: 59.38%] [G loss: 3.027605]\n",
      "epoch:24 step:19504 [D loss: 0.513612, acc: 60.94%] [G loss: 4.059753]\n",
      "epoch:24 step:19505 [D loss: 1.139456, acc: 38.28%] [G loss: 1.931606]\n",
      "epoch:24 step:19506 [D loss: 0.194464, acc: 98.44%] [G loss: 2.298015]\n",
      "epoch:24 step:19507 [D loss: 0.421571, acc: 89.84%] [G loss: 3.924320]\n",
      "epoch:24 step:19508 [D loss: 0.572704, acc: 71.88%] [G loss: 2.764576]\n",
      "epoch:24 step:19509 [D loss: 0.789576, acc: 42.97%] [G loss: 2.521729]\n",
      "epoch:24 step:19510 [D loss: 0.408800, acc: 89.06%] [G loss: 3.312325]\n",
      "epoch:24 step:19511 [D loss: 0.161437, acc: 99.22%] [G loss: 3.643683]\n",
      "epoch:24 step:19512 [D loss: 0.092680, acc: 100.00%] [G loss: 3.283691]\n",
      "epoch:24 step:19513 [D loss: 0.401987, acc: 83.59%] [G loss: 2.473031]\n",
      "epoch:24 step:19514 [D loss: 0.512004, acc: 79.69%] [G loss: 2.503773]\n",
      "epoch:24 step:19515 [D loss: 0.737437, acc: 50.00%] [G loss: 4.270675]\n",
      "epoch:24 step:19516 [D loss: 0.908194, acc: 34.38%] [G loss: 3.476468]\n",
      "epoch:24 step:19517 [D loss: 0.049200, acc: 100.00%] [G loss: 5.514560]\n",
      "epoch:24 step:19518 [D loss: 0.607400, acc: 64.84%] [G loss: 2.475564]\n",
      "epoch:24 step:19519 [D loss: 0.662743, acc: 57.03%] [G loss: 2.778332]\n",
      "epoch:24 step:19520 [D loss: 1.139137, acc: 21.09%] [G loss: 3.341157]\n",
      "epoch:24 step:19521 [D loss: 0.851988, acc: 50.78%] [G loss: 3.216784]\n",
      "epoch:24 step:19522 [D loss: 0.189814, acc: 98.44%] [G loss: 3.237051]\n",
      "epoch:24 step:19523 [D loss: 0.331194, acc: 89.06%] [G loss: 3.252478]\n",
      "epoch:24 step:19524 [D loss: 1.098680, acc: 43.75%] [G loss: 1.351372]\n",
      "epoch:24 step:19525 [D loss: 0.473024, acc: 79.69%] [G loss: 2.899505]\n",
      "epoch:25 step:19526 [D loss: 0.475193, acc: 81.25%] [G loss: 2.636518]\n",
      "epoch:25 step:19527 [D loss: 0.606151, acc: 67.19%] [G loss: 3.142763]\n",
      "epoch:25 step:19528 [D loss: 0.583947, acc: 64.84%] [G loss: 2.333758]\n",
      "epoch:25 step:19529 [D loss: 0.492479, acc: 72.66%] [G loss: 4.052924]\n",
      "epoch:25 step:19530 [D loss: 0.560699, acc: 61.72%] [G loss: 3.474696]\n",
      "epoch:25 step:19531 [D loss: 0.494230, acc: 72.66%] [G loss: 3.179626]\n",
      "epoch:25 step:19532 [D loss: 0.496266, acc: 79.69%] [G loss: 2.842201]\n",
      "epoch:25 step:19533 [D loss: 0.149445, acc: 98.44%] [G loss: 3.829474]\n",
      "epoch:25 step:19534 [D loss: 0.701108, acc: 52.34%] [G loss: 4.867334]\n",
      "epoch:25 step:19535 [D loss: 0.381737, acc: 85.16%] [G loss: 3.905949]\n",
      "epoch:25 step:19536 [D loss: 0.518235, acc: 73.44%] [G loss: 3.935497]\n",
      "epoch:25 step:19537 [D loss: 0.243957, acc: 96.88%] [G loss: 3.891710]\n",
      "epoch:25 step:19538 [D loss: 0.586391, acc: 71.09%] [G loss: 3.471273]\n",
      "epoch:25 step:19539 [D loss: 0.852191, acc: 49.22%] [G loss: 2.233295]\n",
      "epoch:25 step:19540 [D loss: 0.309209, acc: 84.38%] [G loss: 3.724941]\n",
      "epoch:25 step:19541 [D loss: 0.557527, acc: 64.06%] [G loss: 3.203266]\n",
      "epoch:25 step:19542 [D loss: 0.148189, acc: 100.00%] [G loss: 3.655571]\n",
      "epoch:25 step:19543 [D loss: 0.498008, acc: 82.81%] [G loss: 3.573827]\n",
      "epoch:25 step:19544 [D loss: 0.405147, acc: 92.19%] [G loss: 2.849338]\n",
      "epoch:25 step:19545 [D loss: 0.365705, acc: 85.94%] [G loss: 3.462492]\n",
      "epoch:25 step:19546 [D loss: 0.229120, acc: 96.88%] [G loss: 2.158590]\n",
      "epoch:25 step:19547 [D loss: 0.631147, acc: 60.16%] [G loss: 2.137389]\n",
      "epoch:25 step:19548 [D loss: 0.843051, acc: 37.50%] [G loss: 2.081251]\n",
      "epoch:25 step:19549 [D loss: 0.280095, acc: 97.66%] [G loss: 3.083750]\n",
      "epoch:25 step:19550 [D loss: 0.478522, acc: 75.00%] [G loss: 2.988212]\n",
      "epoch:25 step:19551 [D loss: 0.120980, acc: 100.00%] [G loss: 4.554382]\n",
      "epoch:25 step:19552 [D loss: 0.925745, acc: 50.00%] [G loss: 2.446554]\n",
      "epoch:25 step:19553 [D loss: 0.488196, acc: 64.84%] [G loss: 3.545442]\n",
      "epoch:25 step:19554 [D loss: 0.489525, acc: 70.31%] [G loss: 3.211753]\n",
      "epoch:25 step:19555 [D loss: 0.285097, acc: 94.53%] [G loss: 3.300886]\n",
      "epoch:25 step:19556 [D loss: 0.317413, acc: 91.41%] [G loss: 3.674810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19557 [D loss: 0.218120, acc: 98.44%] [G loss: 3.709670]\n",
      "epoch:25 step:19558 [D loss: 0.706606, acc: 53.12%] [G loss: 3.810771]\n",
      "epoch:25 step:19559 [D loss: 0.089857, acc: 100.00%] [G loss: 2.143737]\n",
      "epoch:25 step:19560 [D loss: 0.594263, acc: 64.06%] [G loss: 2.790022]\n",
      "epoch:25 step:19561 [D loss: 0.223052, acc: 99.22%] [G loss: 4.336350]\n",
      "epoch:25 step:19562 [D loss: 0.671380, acc: 55.47%] [G loss: 2.794835]\n",
      "epoch:25 step:19563 [D loss: 0.387468, acc: 91.41%] [G loss: 2.659319]\n",
      "epoch:25 step:19564 [D loss: 0.829323, acc: 50.00%] [G loss: 3.248448]\n",
      "epoch:25 step:19565 [D loss: 0.102439, acc: 100.00%] [G loss: 2.445811]\n",
      "epoch:25 step:19566 [D loss: 0.721098, acc: 50.00%] [G loss: 3.423062]\n",
      "epoch:25 step:19567 [D loss: 0.779597, acc: 51.56%] [G loss: 2.491091]\n",
      "epoch:25 step:19568 [D loss: 0.482584, acc: 65.62%] [G loss: 2.906672]\n",
      "epoch:25 step:19569 [D loss: 1.185399, acc: 10.16%] [G loss: 2.438479]\n",
      "epoch:25 step:19570 [D loss: 0.454136, acc: 78.91%] [G loss: 2.474271]\n",
      "epoch:25 step:19571 [D loss: 0.294535, acc: 94.53%] [G loss: 2.849926]\n",
      "epoch:25 step:19572 [D loss: 0.610821, acc: 66.41%] [G loss: 2.700874]\n",
      "epoch:25 step:19573 [D loss: 0.552548, acc: 72.66%] [G loss: 2.098044]\n",
      "epoch:25 step:19574 [D loss: 0.722544, acc: 56.25%] [G loss: 2.555635]\n",
      "epoch:25 step:19575 [D loss: 0.559841, acc: 66.41%] [G loss: 2.203881]\n",
      "epoch:25 step:19576 [D loss: 0.185220, acc: 98.44%] [G loss: 1.967054]\n",
      "epoch:25 step:19577 [D loss: 0.725485, acc: 47.66%] [G loss: 3.005482]\n",
      "epoch:25 step:19578 [D loss: 0.218016, acc: 97.66%] [G loss: 2.927191]\n",
      "epoch:25 step:19579 [D loss: 0.827666, acc: 44.53%] [G loss: 2.875200]\n",
      "epoch:25 step:19580 [D loss: 0.625591, acc: 60.94%] [G loss: 2.998258]\n",
      "epoch:25 step:19581 [D loss: 0.430294, acc: 85.94%] [G loss: 2.467522]\n",
      "epoch:25 step:19582 [D loss: 0.507777, acc: 76.56%] [G loss: 3.400150]\n",
      "epoch:25 step:19583 [D loss: 0.785963, acc: 46.88%] [G loss: 2.546473]\n",
      "epoch:25 step:19584 [D loss: 0.433196, acc: 88.28%] [G loss: 3.501067]\n",
      "epoch:25 step:19585 [D loss: 0.491444, acc: 86.72%] [G loss: 3.828383]\n",
      "epoch:25 step:19586 [D loss: 0.667697, acc: 52.34%] [G loss: 4.744943]\n",
      "epoch:25 step:19587 [D loss: 0.287097, acc: 98.44%] [G loss: 2.784479]\n",
      "epoch:25 step:19588 [D loss: 0.206659, acc: 98.44%] [G loss: 2.271091]\n",
      "epoch:25 step:19589 [D loss: 0.249238, acc: 97.66%] [G loss: 3.359839]\n",
      "epoch:25 step:19590 [D loss: 0.556932, acc: 67.19%] [G loss: 2.158784]\n",
      "epoch:25 step:19591 [D loss: 0.335045, acc: 92.97%] [G loss: 2.158384]\n",
      "epoch:25 step:19592 [D loss: 0.444259, acc: 84.38%] [G loss: 3.300288]\n",
      "epoch:25 step:19593 [D loss: 0.622669, acc: 62.50%] [G loss: 3.854748]\n",
      "epoch:25 step:19594 [D loss: 0.571635, acc: 60.16%] [G loss: 2.381312]\n",
      "epoch:25 step:19595 [D loss: 0.529835, acc: 72.66%] [G loss: 4.066330]\n",
      "epoch:25 step:19596 [D loss: 0.898518, acc: 50.00%] [G loss: 2.600614]\n",
      "epoch:25 step:19597 [D loss: 0.705363, acc: 56.25%] [G loss: 4.004016]\n",
      "epoch:25 step:19598 [D loss: 0.435121, acc: 89.84%] [G loss: 3.149246]\n",
      "epoch:25 step:19599 [D loss: 0.330929, acc: 94.53%] [G loss: 3.291613]\n",
      "epoch:25 step:19600 [D loss: 0.582936, acc: 71.88%] [G loss: 2.590592]\n",
      "epoch:25 step:19601 [D loss: 0.409000, acc: 88.28%] [G loss: 2.844543]\n",
      "epoch:25 step:19602 [D loss: 0.484247, acc: 67.19%] [G loss: 2.149716]\n",
      "epoch:25 step:19603 [D loss: 0.383239, acc: 89.06%] [G loss: 2.977106]\n",
      "epoch:25 step:19604 [D loss: 0.459298, acc: 77.34%] [G loss: 2.926879]\n",
      "epoch:25 step:19605 [D loss: 0.275480, acc: 98.44%] [G loss: 2.342655]\n",
      "epoch:25 step:19606 [D loss: 0.181204, acc: 99.22%] [G loss: 2.537040]\n",
      "epoch:25 step:19607 [D loss: 0.270378, acc: 98.44%] [G loss: 2.645242]\n",
      "epoch:25 step:19608 [D loss: 0.505119, acc: 62.50%] [G loss: 3.378742]\n",
      "epoch:25 step:19609 [D loss: 0.606867, acc: 67.97%] [G loss: 3.222290]\n",
      "epoch:25 step:19610 [D loss: 0.277195, acc: 96.09%] [G loss: 5.788191]\n",
      "epoch:25 step:19611 [D loss: 0.979747, acc: 23.44%] [G loss: 2.874808]\n",
      "epoch:25 step:19612 [D loss: 0.239641, acc: 99.22%] [G loss: 2.299636]\n",
      "epoch:25 step:19613 [D loss: 0.392566, acc: 90.62%] [G loss: 3.750582]\n",
      "epoch:25 step:19614 [D loss: 0.112860, acc: 100.00%] [G loss: 4.053051]\n",
      "epoch:25 step:19615 [D loss: 0.266914, acc: 96.88%] [G loss: 3.587069]\n",
      "epoch:25 step:19616 [D loss: 0.251744, acc: 97.66%] [G loss: 4.169142]\n",
      "epoch:25 step:19617 [D loss: 0.602839, acc: 67.19%] [G loss: 4.119122]\n",
      "epoch:25 step:19618 [D loss: 0.338363, acc: 91.41%] [G loss: 2.089209]\n",
      "epoch:25 step:19619 [D loss: 0.637083, acc: 62.50%] [G loss: 3.460118]\n",
      "epoch:25 step:19620 [D loss: 0.375212, acc: 87.50%] [G loss: 3.451987]\n",
      "epoch:25 step:19621 [D loss: 0.718598, acc: 52.34%] [G loss: 2.415872]\n",
      "epoch:25 step:19622 [D loss: 0.329598, acc: 92.97%] [G loss: 2.414727]\n",
      "epoch:25 step:19623 [D loss: 0.630414, acc: 63.28%] [G loss: 2.188433]\n",
      "epoch:25 step:19624 [D loss: 0.163220, acc: 98.44%] [G loss: 3.762819]\n",
      "epoch:25 step:19625 [D loss: 0.584852, acc: 56.25%] [G loss: 4.268471]\n",
      "epoch:25 step:19626 [D loss: 1.170814, acc: 13.28%] [G loss: 2.795535]\n",
      "epoch:25 step:19627 [D loss: 0.288701, acc: 96.09%] [G loss: 3.287832]\n",
      "epoch:25 step:19628 [D loss: 0.688525, acc: 56.25%] [G loss: 2.546237]\n",
      "epoch:25 step:19629 [D loss: 0.132343, acc: 99.22%] [G loss: 2.479962]\n",
      "epoch:25 step:19630 [D loss: 0.656896, acc: 61.72%] [G loss: 2.956287]\n",
      "epoch:25 step:19631 [D loss: 0.496574, acc: 82.81%] [G loss: 3.071029]\n",
      "epoch:25 step:19632 [D loss: 0.593710, acc: 66.41%] [G loss: 2.659258]\n",
      "epoch:25 step:19633 [D loss: 0.897551, acc: 43.75%] [G loss: 3.775463]\n",
      "epoch:25 step:19634 [D loss: 0.394897, acc: 79.69%] [G loss: 2.821108]\n",
      "epoch:25 step:19635 [D loss: 0.518711, acc: 83.59%] [G loss: 2.579029]\n",
      "epoch:25 step:19636 [D loss: 0.635940, acc: 63.28%] [G loss: 3.251856]\n",
      "epoch:25 step:19637 [D loss: 0.277777, acc: 98.44%] [G loss: 2.222149]\n",
      "epoch:25 step:19638 [D loss: 0.343555, acc: 86.72%] [G loss: 2.978281]\n",
      "epoch:25 step:19639 [D loss: 1.314662, acc: 12.50%] [G loss: 1.609575]\n",
      "epoch:25 step:19640 [D loss: 1.028766, acc: 38.28%] [G loss: 3.467687]\n",
      "epoch:25 step:19641 [D loss: 0.391495, acc: 89.06%] [G loss: 2.480428]\n",
      "epoch:25 step:19642 [D loss: 0.775078, acc: 50.00%] [G loss: 3.917695]\n",
      "epoch:25 step:19643 [D loss: 0.156578, acc: 100.00%] [G loss: 4.148052]\n",
      "epoch:25 step:19644 [D loss: 0.513466, acc: 73.44%] [G loss: 2.603840]\n",
      "epoch:25 step:19645 [D loss: 0.565478, acc: 67.97%] [G loss: 3.417082]\n",
      "epoch:25 step:19646 [D loss: 0.331461, acc: 98.44%] [G loss: 3.093256]\n",
      "epoch:25 step:19647 [D loss: 0.454264, acc: 85.94%] [G loss: 5.153292]\n",
      "epoch:25 step:19648 [D loss: 0.456246, acc: 72.66%] [G loss: 3.015094]\n",
      "epoch:25 step:19649 [D loss: 0.301595, acc: 90.62%] [G loss: 3.342573]\n",
      "epoch:25 step:19650 [D loss: 0.448301, acc: 85.94%] [G loss: 2.651903]\n",
      "epoch:25 step:19651 [D loss: 0.613562, acc: 61.72%] [G loss: 3.571475]\n",
      "epoch:25 step:19652 [D loss: 0.409925, acc: 91.41%] [G loss: 1.888083]\n",
      "epoch:25 step:19653 [D loss: 0.382224, acc: 89.84%] [G loss: 2.408008]\n",
      "epoch:25 step:19654 [D loss: 0.575303, acc: 71.09%] [G loss: 2.411346]\n",
      "epoch:25 step:19655 [D loss: 0.614762, acc: 63.28%] [G loss: 2.694834]\n",
      "epoch:25 step:19656 [D loss: 0.799469, acc: 47.66%] [G loss: 1.997385]\n",
      "epoch:25 step:19657 [D loss: 0.780832, acc: 42.97%] [G loss: 3.717003]\n",
      "epoch:25 step:19658 [D loss: 0.664828, acc: 63.28%] [G loss: 1.958298]\n",
      "epoch:25 step:19659 [D loss: 0.549911, acc: 63.28%] [G loss: 3.681942]\n",
      "epoch:25 step:19660 [D loss: 0.054748, acc: 100.00%] [G loss: 4.083172]\n",
      "epoch:25 step:19661 [D loss: 0.655701, acc: 53.91%] [G loss: 2.683768]\n",
      "epoch:25 step:19662 [D loss: 0.456604, acc: 78.12%] [G loss: 2.641314]\n",
      "epoch:25 step:19663 [D loss: 0.704931, acc: 52.34%] [G loss: 2.418865]\n",
      "epoch:25 step:19664 [D loss: 0.653471, acc: 58.59%] [G loss: 2.420494]\n",
      "epoch:25 step:19665 [D loss: 0.311613, acc: 92.19%] [G loss: 1.952806]\n",
      "epoch:25 step:19666 [D loss: 0.673003, acc: 61.72%] [G loss: 3.145255]\n",
      "epoch:25 step:19667 [D loss: 0.580539, acc: 71.88%] [G loss: 2.417620]\n",
      "epoch:25 step:19668 [D loss: 0.285428, acc: 90.62%] [G loss: 2.600736]\n",
      "epoch:25 step:19669 [D loss: 0.889106, acc: 50.78%] [G loss: 2.492277]\n",
      "epoch:25 step:19670 [D loss: 0.452534, acc: 85.94%] [G loss: 2.904699]\n",
      "epoch:25 step:19671 [D loss: 0.705756, acc: 52.34%] [G loss: 2.548092]\n",
      "epoch:25 step:19672 [D loss: 0.380600, acc: 94.53%] [G loss: 2.609577]\n",
      "epoch:25 step:19673 [D loss: 0.559192, acc: 71.88%] [G loss: 3.035438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19674 [D loss: 0.734350, acc: 53.12%] [G loss: 3.615658]\n",
      "epoch:25 step:19675 [D loss: 0.459178, acc: 83.59%] [G loss: 3.804971]\n",
      "epoch:25 step:19676 [D loss: 0.306626, acc: 92.97%] [G loss: 2.919379]\n",
      "epoch:25 step:19677 [D loss: 0.384534, acc: 83.59%] [G loss: 2.678157]\n",
      "epoch:25 step:19678 [D loss: 0.373239, acc: 91.41%] [G loss: 2.454237]\n",
      "epoch:25 step:19679 [D loss: 0.289198, acc: 93.75%] [G loss: 3.420301]\n",
      "epoch:25 step:19680 [D loss: 0.341035, acc: 96.09%] [G loss: 2.681294]\n",
      "epoch:25 step:19681 [D loss: 0.472258, acc: 82.03%] [G loss: 1.646864]\n",
      "epoch:25 step:19682 [D loss: 0.074095, acc: 100.00%] [G loss: 3.418547]\n",
      "epoch:25 step:19683 [D loss: 0.515936, acc: 82.03%] [G loss: 2.262367]\n",
      "epoch:25 step:19684 [D loss: 0.501785, acc: 66.41%] [G loss: 3.549193]\n",
      "epoch:25 step:19685 [D loss: 0.785850, acc: 48.44%] [G loss: 1.773744]\n",
      "epoch:25 step:19686 [D loss: 0.434828, acc: 67.97%] [G loss: 3.954122]\n",
      "epoch:25 step:19687 [D loss: 0.451920, acc: 83.59%] [G loss: 2.869169]\n",
      "epoch:25 step:19688 [D loss: 0.437034, acc: 87.50%] [G loss: 2.545524]\n",
      "epoch:25 step:19689 [D loss: 0.947185, acc: 46.09%] [G loss: 3.401525]\n",
      "epoch:25 step:19690 [D loss: 0.398349, acc: 80.47%] [G loss: 2.338568]\n",
      "epoch:25 step:19691 [D loss: 0.434299, acc: 87.50%] [G loss: 3.051554]\n",
      "epoch:25 step:19692 [D loss: 0.400930, acc: 91.41%] [G loss: 2.868351]\n",
      "epoch:25 step:19693 [D loss: 0.674449, acc: 58.59%] [G loss: 2.571362]\n",
      "epoch:25 step:19694 [D loss: 0.458317, acc: 89.06%] [G loss: 2.765845]\n",
      "epoch:25 step:19695 [D loss: 0.449644, acc: 86.72%] [G loss: 3.436841]\n",
      "epoch:25 step:19696 [D loss: 0.713600, acc: 57.81%] [G loss: 2.716802]\n",
      "epoch:25 step:19697 [D loss: 0.782022, acc: 50.00%] [G loss: 2.447463]\n",
      "epoch:25 step:19698 [D loss: 0.891127, acc: 38.28%] [G loss: 2.864361]\n",
      "epoch:25 step:19699 [D loss: 0.281717, acc: 96.09%] [G loss: 3.483235]\n",
      "epoch:25 step:19700 [D loss: 0.467358, acc: 67.19%] [G loss: 3.526031]\n",
      "epoch:25 step:19701 [D loss: 0.551552, acc: 69.53%] [G loss: 2.897845]\n",
      "epoch:25 step:19702 [D loss: 0.452547, acc: 86.72%] [G loss: 1.902213]\n",
      "epoch:25 step:19703 [D loss: 0.688441, acc: 57.03%] [G loss: 3.494609]\n",
      "epoch:25 step:19704 [D loss: 0.898190, acc: 46.88%] [G loss: 2.807103]\n",
      "epoch:25 step:19705 [D loss: 0.420096, acc: 75.00%] [G loss: 3.462589]\n",
      "epoch:25 step:19706 [D loss: 0.558652, acc: 69.53%] [G loss: 1.891631]\n",
      "epoch:25 step:19707 [D loss: 0.328251, acc: 84.38%] [G loss: 4.297290]\n",
      "epoch:25 step:19708 [D loss: 0.292447, acc: 99.22%] [G loss: 2.537290]\n",
      "epoch:25 step:19709 [D loss: 0.509682, acc: 71.88%] [G loss: 1.719141]\n",
      "epoch:25 step:19710 [D loss: 0.252370, acc: 99.22%] [G loss: 3.845416]\n",
      "epoch:25 step:19711 [D loss: 0.283408, acc: 96.88%] [G loss: 3.246726]\n",
      "epoch:25 step:19712 [D loss: 0.562030, acc: 58.59%] [G loss: 2.681585]\n",
      "epoch:25 step:19713 [D loss: 0.777102, acc: 50.00%] [G loss: 2.385148]\n",
      "epoch:25 step:19714 [D loss: 0.140937, acc: 100.00%] [G loss: 4.629866]\n",
      "epoch:25 step:19715 [D loss: 0.294946, acc: 94.53%] [G loss: 3.742907]\n",
      "epoch:25 step:19716 [D loss: 0.402771, acc: 82.81%] [G loss: 4.500895]\n",
      "epoch:25 step:19717 [D loss: 0.612754, acc: 67.97%] [G loss: 2.448739]\n",
      "epoch:25 step:19718 [D loss: 0.386769, acc: 79.69%] [G loss: 2.627012]\n",
      "epoch:25 step:19719 [D loss: 0.421958, acc: 85.94%] [G loss: 3.118091]\n",
      "epoch:25 step:19720 [D loss: 0.541476, acc: 79.69%] [G loss: 4.608699]\n",
      "epoch:25 step:19721 [D loss: 0.209471, acc: 99.22%] [G loss: 1.578509]\n",
      "epoch:25 step:19722 [D loss: 0.485807, acc: 78.12%] [G loss: 4.190225]\n",
      "epoch:25 step:19723 [D loss: 0.486731, acc: 65.62%] [G loss: 3.341748]\n",
      "epoch:25 step:19724 [D loss: 0.300096, acc: 95.31%] [G loss: 3.358775]\n",
      "epoch:25 step:19725 [D loss: 0.298674, acc: 86.72%] [G loss: 4.389055]\n",
      "epoch:25 step:19726 [D loss: 0.388833, acc: 76.56%] [G loss: 3.549827]\n",
      "epoch:25 step:19727 [D loss: 0.637763, acc: 61.72%] [G loss: 2.459250]\n",
      "epoch:25 step:19728 [D loss: 0.180439, acc: 99.22%] [G loss: 2.801669]\n",
      "epoch:25 step:19729 [D loss: 0.454431, acc: 85.16%] [G loss: 2.659536]\n",
      "epoch:25 step:19730 [D loss: 0.722840, acc: 55.47%] [G loss: 2.688872]\n",
      "epoch:25 step:19731 [D loss: 0.710902, acc: 60.94%] [G loss: 2.646648]\n",
      "epoch:25 step:19732 [D loss: 0.593981, acc: 54.69%] [G loss: 2.321028]\n",
      "epoch:25 step:19733 [D loss: 0.306431, acc: 89.84%] [G loss: 3.563715]\n",
      "epoch:25 step:19734 [D loss: 0.499208, acc: 79.69%] [G loss: 3.149532]\n",
      "epoch:25 step:19735 [D loss: 0.336538, acc: 94.53%] [G loss: 3.715641]\n",
      "epoch:25 step:19736 [D loss: 0.744911, acc: 51.56%] [G loss: 3.319940]\n",
      "epoch:25 step:19737 [D loss: 0.212390, acc: 98.44%] [G loss: 4.090661]\n",
      "epoch:25 step:19738 [D loss: 0.609236, acc: 68.75%] [G loss: 2.201295]\n",
      "epoch:25 step:19739 [D loss: 0.161775, acc: 100.00%] [G loss: 3.689922]\n",
      "epoch:25 step:19740 [D loss: 0.269978, acc: 98.44%] [G loss: 3.639287]\n",
      "epoch:25 step:19741 [D loss: 0.572561, acc: 67.19%] [G loss: 3.741680]\n",
      "epoch:25 step:19742 [D loss: 0.469516, acc: 78.91%] [G loss: 3.284569]\n",
      "epoch:25 step:19743 [D loss: 0.636014, acc: 60.94%] [G loss: 3.362522]\n",
      "epoch:25 step:19744 [D loss: 0.193194, acc: 100.00%] [G loss: 4.742715]\n",
      "epoch:25 step:19745 [D loss: 1.353846, acc: 42.19%] [G loss: 2.382748]\n",
      "epoch:25 step:19746 [D loss: 0.629757, acc: 57.81%] [G loss: 2.916968]\n",
      "epoch:25 step:19747 [D loss: 0.658845, acc: 61.72%] [G loss: 2.908429]\n",
      "epoch:25 step:19748 [D loss: 0.562894, acc: 64.06%] [G loss: 3.099413]\n",
      "epoch:25 step:19749 [D loss: 0.737594, acc: 53.91%] [G loss: 3.268902]\n",
      "epoch:25 step:19750 [D loss: 0.392484, acc: 88.28%] [G loss: 2.832408]\n",
      "epoch:25 step:19751 [D loss: 0.448210, acc: 86.72%] [G loss: 3.281361]\n",
      "epoch:25 step:19752 [D loss: 0.438212, acc: 79.69%] [G loss: 3.871252]\n",
      "epoch:25 step:19753 [D loss: 0.572860, acc: 62.50%] [G loss: 3.409170]\n",
      "epoch:25 step:19754 [D loss: 0.379412, acc: 90.62%] [G loss: 3.044628]\n",
      "epoch:25 step:19755 [D loss: 0.847830, acc: 43.75%] [G loss: 3.683521]\n",
      "epoch:25 step:19756 [D loss: 0.241140, acc: 99.22%] [G loss: 2.754598]\n",
      "epoch:25 step:19757 [D loss: 0.725608, acc: 52.34%] [G loss: 1.954010]\n",
      "epoch:25 step:19758 [D loss: 0.350444, acc: 92.19%] [G loss: 4.195229]\n",
      "epoch:25 step:19759 [D loss: 1.025645, acc: 26.56%] [G loss: 3.796802]\n",
      "epoch:25 step:19760 [D loss: 0.580545, acc: 67.97%] [G loss: 2.661113]\n",
      "epoch:25 step:19761 [D loss: 0.602819, acc: 69.53%] [G loss: 2.533879]\n",
      "epoch:25 step:19762 [D loss: 0.574207, acc: 66.41%] [G loss: 3.320108]\n",
      "epoch:25 step:19763 [D loss: 0.609949, acc: 57.03%] [G loss: 3.439178]\n",
      "epoch:25 step:19764 [D loss: 0.188047, acc: 98.44%] [G loss: 3.011101]\n",
      "epoch:25 step:19765 [D loss: 0.484954, acc: 71.09%] [G loss: 2.934384]\n",
      "epoch:25 step:19766 [D loss: 0.384662, acc: 85.16%] [G loss: 2.623550]\n",
      "epoch:25 step:19767 [D loss: 0.226065, acc: 99.22%] [G loss: 3.322852]\n",
      "epoch:25 step:19768 [D loss: 0.292471, acc: 96.09%] [G loss: 3.645763]\n",
      "epoch:25 step:19769 [D loss: 0.569461, acc: 72.66%] [G loss: 2.852586]\n",
      "epoch:25 step:19770 [D loss: 0.267463, acc: 96.09%] [G loss: 2.564008]\n",
      "epoch:25 step:19771 [D loss: 0.337946, acc: 92.19%] [G loss: 4.401971]\n",
      "epoch:25 step:19772 [D loss: 0.494731, acc: 78.12%] [G loss: 3.426468]\n",
      "epoch:25 step:19773 [D loss: 0.633553, acc: 65.62%] [G loss: 2.930773]\n",
      "epoch:25 step:19774 [D loss: 0.363141, acc: 85.94%] [G loss: 2.945440]\n",
      "epoch:25 step:19775 [D loss: 0.502755, acc: 79.69%] [G loss: 3.345296]\n",
      "epoch:25 step:19776 [D loss: 0.128300, acc: 100.00%] [G loss: 2.915209]\n",
      "epoch:25 step:19777 [D loss: 0.717037, acc: 53.12%] [G loss: 3.121999]\n",
      "epoch:25 step:19778 [D loss: 0.748014, acc: 48.44%] [G loss: 2.738589]\n",
      "epoch:25 step:19779 [D loss: 0.617016, acc: 53.12%] [G loss: 3.958136]\n",
      "epoch:25 step:19780 [D loss: 0.514885, acc: 67.19%] [G loss: 3.687703]\n",
      "epoch:25 step:19781 [D loss: 0.312732, acc: 83.59%] [G loss: 2.624989]\n",
      "epoch:25 step:19782 [D loss: 1.111949, acc: 34.38%] [G loss: 2.697371]\n",
      "epoch:25 step:19783 [D loss: 0.289731, acc: 96.88%] [G loss: 3.465303]\n",
      "epoch:25 step:19784 [D loss: 0.371455, acc: 89.06%] [G loss: 2.665025]\n",
      "epoch:25 step:19785 [D loss: 0.612492, acc: 71.09%] [G loss: 2.170624]\n",
      "epoch:25 step:19786 [D loss: 0.562569, acc: 69.53%] [G loss: 2.659261]\n",
      "epoch:25 step:19787 [D loss: 0.593838, acc: 64.06%] [G loss: 3.648111]\n",
      "epoch:25 step:19788 [D loss: 0.458221, acc: 71.09%] [G loss: 2.862961]\n",
      "epoch:25 step:19789 [D loss: 1.471654, acc: 9.38%] [G loss: 2.355603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19790 [D loss: 0.515886, acc: 78.91%] [G loss: 3.519107]\n",
      "epoch:25 step:19791 [D loss: 0.284133, acc: 96.09%] [G loss: 3.438663]\n",
      "epoch:25 step:19792 [D loss: 0.819271, acc: 39.06%] [G loss: 3.331515]\n",
      "epoch:25 step:19793 [D loss: 0.657958, acc: 64.06%] [G loss: 1.897392]\n",
      "epoch:25 step:19794 [D loss: 0.951430, acc: 36.72%] [G loss: 2.191877]\n",
      "epoch:25 step:19795 [D loss: 0.371289, acc: 76.56%] [G loss: 3.639731]\n",
      "epoch:25 step:19796 [D loss: 0.185063, acc: 99.22%] [G loss: 3.764460]\n",
      "epoch:25 step:19797 [D loss: 0.572545, acc: 58.59%] [G loss: 2.729333]\n",
      "epoch:25 step:19798 [D loss: 0.501988, acc: 78.12%] [G loss: 2.347208]\n",
      "epoch:25 step:19799 [D loss: 0.458672, acc: 76.56%] [G loss: 3.759521]\n",
      "epoch:25 step:19800 [D loss: 1.063146, acc: 18.75%] [G loss: 2.995087]\n",
      "epoch:25 step:19801 [D loss: 0.568865, acc: 69.53%] [G loss: 4.127477]\n",
      "epoch:25 step:19802 [D loss: 0.476336, acc: 71.09%] [G loss: 3.396125]\n",
      "epoch:25 step:19803 [D loss: 0.800407, acc: 47.66%] [G loss: 3.653268]\n",
      "epoch:25 step:19804 [D loss: 0.884345, acc: 27.34%] [G loss: 3.249248]\n",
      "epoch:25 step:19805 [D loss: 0.447555, acc: 82.81%] [G loss: 2.610299]\n",
      "epoch:25 step:19806 [D loss: 0.336906, acc: 87.50%] [G loss: 3.524281]\n",
      "epoch:25 step:19807 [D loss: 0.636461, acc: 64.06%] [G loss: 2.733004]\n",
      "epoch:25 step:19808 [D loss: 0.562012, acc: 73.44%] [G loss: 3.784733]\n",
      "epoch:25 step:19809 [D loss: 0.242992, acc: 96.88%] [G loss: 2.112322]\n",
      "epoch:25 step:19810 [D loss: 0.378615, acc: 89.84%] [G loss: 3.467073]\n",
      "epoch:25 step:19811 [D loss: 0.329872, acc: 78.91%] [G loss: 3.434839]\n",
      "epoch:25 step:19812 [D loss: 0.350237, acc: 89.84%] [G loss: 3.418051]\n",
      "epoch:25 step:19813 [D loss: 0.373841, acc: 92.19%] [G loss: 2.673269]\n",
      "epoch:25 step:19814 [D loss: 0.480435, acc: 73.44%] [G loss: 3.523818]\n",
      "epoch:25 step:19815 [D loss: 0.580913, acc: 70.31%] [G loss: 3.590948]\n",
      "epoch:25 step:19816 [D loss: 0.596578, acc: 56.25%] [G loss: 2.874215]\n",
      "epoch:25 step:19817 [D loss: 0.766851, acc: 50.00%] [G loss: 3.409293]\n",
      "epoch:25 step:19818 [D loss: 0.817341, acc: 43.75%] [G loss: 2.881525]\n",
      "epoch:25 step:19819 [D loss: 0.858137, acc: 42.19%] [G loss: 2.473298]\n",
      "epoch:25 step:19820 [D loss: 0.441578, acc: 89.84%] [G loss: 2.852588]\n",
      "epoch:25 step:19821 [D loss: 0.409035, acc: 85.94%] [G loss: 1.915659]\n",
      "epoch:25 step:19822 [D loss: 0.630434, acc: 64.84%] [G loss: 3.513599]\n",
      "epoch:25 step:19823 [D loss: 0.501194, acc: 72.66%] [G loss: 2.571541]\n",
      "epoch:25 step:19824 [D loss: 0.305569, acc: 91.41%] [G loss: 2.217265]\n",
      "epoch:25 step:19825 [D loss: 0.648334, acc: 61.72%] [G loss: 3.165783]\n",
      "epoch:25 step:19826 [D loss: 0.824420, acc: 52.34%] [G loss: 2.051020]\n",
      "epoch:25 step:19827 [D loss: 0.330007, acc: 84.38%] [G loss: 4.593561]\n",
      "epoch:25 step:19828 [D loss: 0.500130, acc: 77.34%] [G loss: 2.423824]\n",
      "epoch:25 step:19829 [D loss: 0.472088, acc: 76.56%] [G loss: 2.416293]\n",
      "epoch:25 step:19830 [D loss: 0.452638, acc: 72.66%] [G loss: 3.565376]\n",
      "epoch:25 step:19831 [D loss: 0.351447, acc: 96.88%] [G loss: 2.417766]\n",
      "epoch:25 step:19832 [D loss: 0.394952, acc: 89.84%] [G loss: 3.391465]\n",
      "epoch:25 step:19833 [D loss: 0.277456, acc: 96.88%] [G loss: 3.192202]\n",
      "epoch:25 step:19834 [D loss: 0.227507, acc: 99.22%] [G loss: 2.602507]\n",
      "epoch:25 step:19835 [D loss: 0.633772, acc: 64.84%] [G loss: 2.537062]\n",
      "epoch:25 step:19836 [D loss: 0.732497, acc: 52.34%] [G loss: 2.713110]\n",
      "epoch:25 step:19837 [D loss: 1.053104, acc: 28.12%] [G loss: 3.189852]\n",
      "epoch:25 step:19838 [D loss: 0.537333, acc: 67.97%] [G loss: 2.842770]\n",
      "epoch:25 step:19839 [D loss: 0.544123, acc: 71.09%] [G loss: 3.066060]\n",
      "epoch:25 step:19840 [D loss: 0.611532, acc: 66.41%] [G loss: 2.170628]\n",
      "epoch:25 step:19841 [D loss: 0.712677, acc: 60.16%] [G loss: 2.144587]\n",
      "epoch:25 step:19842 [D loss: 0.337564, acc: 83.59%] [G loss: 4.205421]\n",
      "epoch:25 step:19843 [D loss: 0.855898, acc: 41.41%] [G loss: 3.648361]\n",
      "epoch:25 step:19844 [D loss: 0.614145, acc: 71.88%] [G loss: 3.995869]\n",
      "epoch:25 step:19845 [D loss: 0.652329, acc: 59.38%] [G loss: 3.415274]\n",
      "epoch:25 step:19846 [D loss: 0.347350, acc: 92.97%] [G loss: 3.198772]\n",
      "epoch:25 step:19847 [D loss: 0.749603, acc: 54.69%] [G loss: 3.058813]\n",
      "epoch:25 step:19848 [D loss: 0.443525, acc: 76.56%] [G loss: 1.879553]\n",
      "epoch:25 step:19849 [D loss: 0.257911, acc: 99.22%] [G loss: 2.540501]\n",
      "epoch:25 step:19850 [D loss: 0.445881, acc: 83.59%] [G loss: 2.551198]\n",
      "epoch:25 step:19851 [D loss: 0.963053, acc: 29.69%] [G loss: 2.571044]\n",
      "epoch:25 step:19852 [D loss: 0.190410, acc: 99.22%] [G loss: 4.104572]\n",
      "epoch:25 step:19853 [D loss: 0.275111, acc: 97.66%] [G loss: 4.244439]\n",
      "epoch:25 step:19854 [D loss: 0.554268, acc: 74.22%] [G loss: 3.482883]\n",
      "epoch:25 step:19855 [D loss: 0.545932, acc: 73.44%] [G loss: 2.932074]\n",
      "epoch:25 step:19856 [D loss: 0.510651, acc: 75.78%] [G loss: 3.083090]\n",
      "epoch:25 step:19857 [D loss: 0.332904, acc: 96.09%] [G loss: 2.331477]\n",
      "epoch:25 step:19858 [D loss: 0.175046, acc: 100.00%] [G loss: 2.690065]\n",
      "epoch:25 step:19859 [D loss: 0.636895, acc: 64.84%] [G loss: 3.479572]\n",
      "epoch:25 step:19860 [D loss: 0.135789, acc: 100.00%] [G loss: 4.957439]\n",
      "epoch:25 step:19861 [D loss: 0.249116, acc: 96.09%] [G loss: 2.449727]\n",
      "epoch:25 step:19862 [D loss: 0.447185, acc: 82.81%] [G loss: 2.882914]\n",
      "epoch:25 step:19863 [D loss: 0.901798, acc: 42.19%] [G loss: 1.812650]\n",
      "epoch:25 step:19864 [D loss: 0.388779, acc: 83.59%] [G loss: 3.057874]\n",
      "epoch:25 step:19865 [D loss: 0.531526, acc: 75.78%] [G loss: 2.481383]\n",
      "epoch:25 step:19866 [D loss: 0.429540, acc: 92.19%] [G loss: 3.562639]\n",
      "epoch:25 step:19867 [D loss: 0.519229, acc: 77.34%] [G loss: 3.078752]\n",
      "epoch:25 step:19868 [D loss: 0.571627, acc: 68.75%] [G loss: 2.904681]\n",
      "epoch:25 step:19869 [D loss: 0.395133, acc: 94.53%] [G loss: 2.152495]\n",
      "epoch:25 step:19870 [D loss: 0.801684, acc: 49.22%] [G loss: 3.032874]\n",
      "epoch:25 step:19871 [D loss: 0.391683, acc: 76.56%] [G loss: 3.046579]\n",
      "epoch:25 step:19872 [D loss: 0.469978, acc: 76.56%] [G loss: 3.140342]\n",
      "epoch:25 step:19873 [D loss: 0.407951, acc: 82.03%] [G loss: 3.682968]\n",
      "epoch:25 step:19874 [D loss: 0.309406, acc: 96.09%] [G loss: 2.954646]\n",
      "epoch:25 step:19875 [D loss: 1.035472, acc: 29.69%] [G loss: 1.319946]\n",
      "epoch:25 step:19876 [D loss: 0.644172, acc: 61.72%] [G loss: 3.573353]\n",
      "epoch:25 step:19877 [D loss: 0.321909, acc: 95.31%] [G loss: 3.687525]\n",
      "epoch:25 step:19878 [D loss: 0.343237, acc: 89.06%] [G loss: 3.542016]\n",
      "epoch:25 step:19879 [D loss: 0.435727, acc: 80.47%] [G loss: 3.629140]\n",
      "epoch:25 step:19880 [D loss: 0.284514, acc: 95.31%] [G loss: 1.597685]\n",
      "epoch:25 step:19881 [D loss: 0.366663, acc: 83.59%] [G loss: 3.290344]\n",
      "epoch:25 step:19882 [D loss: 0.201995, acc: 98.44%] [G loss: 3.150778]\n",
      "epoch:25 step:19883 [D loss: 0.250502, acc: 98.44%] [G loss: 2.661252]\n",
      "epoch:25 step:19884 [D loss: 0.632475, acc: 67.97%] [G loss: 3.588642]\n",
      "epoch:25 step:19885 [D loss: 0.991339, acc: 38.28%] [G loss: 1.885341]\n",
      "epoch:25 step:19886 [D loss: 0.164714, acc: 97.66%] [G loss: 3.139168]\n",
      "epoch:25 step:19887 [D loss: 0.586191, acc: 64.06%] [G loss: 3.739638]\n",
      "epoch:25 step:19888 [D loss: 0.677506, acc: 63.28%] [G loss: 3.044112]\n",
      "epoch:25 step:19889 [D loss: 0.464534, acc: 75.00%] [G loss: 3.964262]\n",
      "epoch:25 step:19890 [D loss: 0.276746, acc: 90.62%] [G loss: 4.499405]\n",
      "epoch:25 step:19891 [D loss: 0.401150, acc: 92.19%] [G loss: 3.340621]\n",
      "epoch:25 step:19892 [D loss: 0.407858, acc: 90.62%] [G loss: 3.650834]\n",
      "epoch:25 step:19893 [D loss: 0.544681, acc: 60.94%] [G loss: 3.682912]\n",
      "epoch:25 step:19894 [D loss: 0.259818, acc: 96.09%] [G loss: 5.675109]\n",
      "epoch:25 step:19895 [D loss: 0.249615, acc: 95.31%] [G loss: 3.531926]\n",
      "epoch:25 step:19896 [D loss: 0.707715, acc: 46.09%] [G loss: 3.223911]\n",
      "epoch:25 step:19897 [D loss: 0.710155, acc: 53.91%] [G loss: 3.014526]\n",
      "epoch:25 step:19898 [D loss: 0.269665, acc: 96.88%] [G loss: 4.216129]\n",
      "epoch:25 step:19899 [D loss: 0.356792, acc: 91.41%] [G loss: 3.392248]\n",
      "epoch:25 step:19900 [D loss: 0.484243, acc: 80.47%] [G loss: 3.098537]\n",
      "epoch:25 step:19901 [D loss: 0.409312, acc: 92.19%] [G loss: 2.585844]\n",
      "epoch:25 step:19902 [D loss: 0.662352, acc: 52.34%] [G loss: 3.114318]\n",
      "epoch:25 step:19903 [D loss: 1.349713, acc: 50.78%] [G loss: 2.916775]\n",
      "epoch:25 step:19904 [D loss: 0.288606, acc: 94.53%] [G loss: 3.341999]\n",
      "epoch:25 step:19905 [D loss: 0.176880, acc: 100.00%] [G loss: 3.724417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19906 [D loss: 0.464882, acc: 85.94%] [G loss: 3.634198]\n",
      "epoch:25 step:19907 [D loss: 0.406774, acc: 88.28%] [G loss: 3.082219]\n",
      "epoch:25 step:19908 [D loss: 0.664879, acc: 61.72%] [G loss: 2.623874]\n",
      "epoch:25 step:19909 [D loss: 0.273697, acc: 98.44%] [G loss: 3.444992]\n",
      "epoch:25 step:19910 [D loss: 0.533918, acc: 83.59%] [G loss: 2.981432]\n",
      "epoch:25 step:19911 [D loss: 0.199427, acc: 98.44%] [G loss: 6.587980]\n",
      "epoch:25 step:19912 [D loss: 0.087292, acc: 100.00%] [G loss: 3.912704]\n",
      "epoch:25 step:19913 [D loss: 0.654769, acc: 58.59%] [G loss: 3.847494]\n",
      "epoch:25 step:19914 [D loss: 0.601492, acc: 58.59%] [G loss: 2.901414]\n",
      "epoch:25 step:19915 [D loss: 0.400562, acc: 84.38%] [G loss: 3.372477]\n",
      "epoch:25 step:19916 [D loss: 1.608964, acc: 39.84%] [G loss: 2.357333]\n",
      "epoch:25 step:19917 [D loss: 0.539452, acc: 73.44%] [G loss: 2.664590]\n",
      "epoch:25 step:19918 [D loss: 0.514595, acc: 74.22%] [G loss: 2.619549]\n",
      "epoch:25 step:19919 [D loss: 0.400628, acc: 75.78%] [G loss: 4.197114]\n",
      "epoch:25 step:19920 [D loss: 0.286633, acc: 90.62%] [G loss: 2.840026]\n",
      "epoch:25 step:19921 [D loss: 0.509999, acc: 79.69%] [G loss: 3.056027]\n",
      "epoch:25 step:19922 [D loss: 0.886638, acc: 42.19%] [G loss: 3.529032]\n",
      "epoch:25 step:19923 [D loss: 0.398447, acc: 85.16%] [G loss: 3.200467]\n",
      "epoch:25 step:19924 [D loss: 0.608405, acc: 68.75%] [G loss: 2.195185]\n",
      "epoch:25 step:19925 [D loss: 0.223178, acc: 96.88%] [G loss: 3.602775]\n",
      "epoch:25 step:19926 [D loss: 0.291351, acc: 92.97%] [G loss: 4.003477]\n",
      "epoch:25 step:19927 [D loss: 0.277448, acc: 97.66%] [G loss: 3.286193]\n",
      "epoch:25 step:19928 [D loss: 0.325588, acc: 93.75%] [G loss: 3.362852]\n",
      "epoch:25 step:19929 [D loss: 0.465647, acc: 82.03%] [G loss: 2.361299]\n",
      "epoch:25 step:19930 [D loss: 0.456103, acc: 78.91%] [G loss: 4.330523]\n",
      "epoch:25 step:19931 [D loss: 1.146163, acc: 24.22%] [G loss: 3.122408]\n",
      "epoch:25 step:19932 [D loss: 0.297351, acc: 95.31%] [G loss: 3.874684]\n",
      "epoch:25 step:19933 [D loss: 0.259661, acc: 97.66%] [G loss: 4.433708]\n",
      "epoch:25 step:19934 [D loss: 0.334337, acc: 88.28%] [G loss: 3.705352]\n",
      "epoch:25 step:19935 [D loss: 0.168279, acc: 99.22%] [G loss: 3.849428]\n",
      "epoch:25 step:19936 [D loss: 0.706717, acc: 51.56%] [G loss: 3.099625]\n",
      "epoch:25 step:19937 [D loss: 0.206832, acc: 99.22%] [G loss: 2.931514]\n",
      "epoch:25 step:19938 [D loss: 0.608752, acc: 63.28%] [G loss: 2.624364]\n",
      "epoch:25 step:19939 [D loss: 0.239723, acc: 96.09%] [G loss: 2.880083]\n",
      "epoch:25 step:19940 [D loss: 0.991704, acc: 25.00%] [G loss: 3.062208]\n",
      "epoch:25 step:19941 [D loss: 0.627608, acc: 67.97%] [G loss: 2.544803]\n",
      "epoch:25 step:19942 [D loss: 0.362733, acc: 88.28%] [G loss: 4.585063]\n",
      "epoch:25 step:19943 [D loss: 0.162606, acc: 100.00%] [G loss: 3.729851]\n",
      "epoch:25 step:19944 [D loss: 0.225676, acc: 97.66%] [G loss: 4.021345]\n",
      "epoch:25 step:19945 [D loss: 0.429425, acc: 85.94%] [G loss: 3.259359]\n",
      "epoch:25 step:19946 [D loss: 0.250156, acc: 98.44%] [G loss: 3.288460]\n",
      "epoch:25 step:19947 [D loss: 0.569659, acc: 75.78%] [G loss: 3.142541]\n",
      "epoch:25 step:19948 [D loss: 0.714453, acc: 56.25%] [G loss: 2.827943]\n",
      "epoch:25 step:19949 [D loss: 0.599939, acc: 64.06%] [G loss: 2.761365]\n",
      "epoch:25 step:19950 [D loss: 0.815493, acc: 51.56%] [G loss: 3.545953]\n",
      "epoch:25 step:19951 [D loss: 0.275259, acc: 92.97%] [G loss: 3.759837]\n",
      "epoch:25 step:19952 [D loss: 0.950555, acc: 49.22%] [G loss: 1.707764]\n",
      "epoch:25 step:19953 [D loss: 0.291035, acc: 97.66%] [G loss: 3.932827]\n",
      "epoch:25 step:19954 [D loss: 0.632054, acc: 58.59%] [G loss: 3.726344]\n",
      "epoch:25 step:19955 [D loss: 0.347004, acc: 92.97%] [G loss: 4.103663]\n",
      "epoch:25 step:19956 [D loss: 0.234063, acc: 98.44%] [G loss: 1.984571]\n",
      "epoch:25 step:19957 [D loss: 0.673361, acc: 57.03%] [G loss: 2.392368]\n",
      "epoch:25 step:19958 [D loss: 0.806283, acc: 52.34%] [G loss: 2.386189]\n",
      "epoch:25 step:19959 [D loss: 0.102285, acc: 100.00%] [G loss: 3.716709]\n",
      "epoch:25 step:19960 [D loss: 0.669295, acc: 59.38%] [G loss: 3.583335]\n",
      "epoch:25 step:19961 [D loss: 1.067545, acc: 23.44%] [G loss: 2.356080]\n",
      "epoch:25 step:19962 [D loss: 0.556795, acc: 72.66%] [G loss: 2.449943]\n",
      "epoch:25 step:19963 [D loss: 0.490477, acc: 78.91%] [G loss: 3.146023]\n",
      "epoch:25 step:19964 [D loss: 0.461149, acc: 77.34%] [G loss: 2.563277]\n",
      "epoch:25 step:19965 [D loss: 0.535567, acc: 74.22%] [G loss: 2.940775]\n",
      "epoch:25 step:19966 [D loss: 0.647816, acc: 60.16%] [G loss: 3.555365]\n",
      "epoch:25 step:19967 [D loss: 0.862499, acc: 45.31%] [G loss: 5.199871]\n",
      "epoch:25 step:19968 [D loss: 0.645351, acc: 62.50%] [G loss: 2.956476]\n",
      "epoch:25 step:19969 [D loss: 0.287041, acc: 91.41%] [G loss: 3.438904]\n",
      "epoch:25 step:19970 [D loss: 0.715945, acc: 51.56%] [G loss: 2.463511]\n",
      "epoch:25 step:19971 [D loss: 0.801573, acc: 50.00%] [G loss: 3.852962]\n",
      "epoch:25 step:19972 [D loss: 0.355053, acc: 84.38%] [G loss: 2.830438]\n",
      "epoch:25 step:19973 [D loss: 0.827603, acc: 38.28%] [G loss: 2.360082]\n",
      "epoch:25 step:19974 [D loss: 0.291681, acc: 95.31%] [G loss: 3.308894]\n",
      "epoch:25 step:19975 [D loss: 0.206529, acc: 99.22%] [G loss: 3.610370]\n",
      "epoch:25 step:19976 [D loss: 0.614681, acc: 64.06%] [G loss: 3.002462]\n",
      "epoch:25 step:19977 [D loss: 0.385312, acc: 89.84%] [G loss: 2.950010]\n",
      "epoch:25 step:19978 [D loss: 0.224054, acc: 97.66%] [G loss: 3.755529]\n",
      "epoch:25 step:19979 [D loss: 0.363420, acc: 85.16%] [G loss: 3.042818]\n",
      "epoch:25 step:19980 [D loss: 0.315339, acc: 94.53%] [G loss: 3.291666]\n",
      "epoch:25 step:19981 [D loss: 0.729644, acc: 53.91%] [G loss: 3.363611]\n",
      "epoch:25 step:19982 [D loss: 0.821860, acc: 43.75%] [G loss: 3.264936]\n",
      "epoch:25 step:19983 [D loss: 0.379228, acc: 86.72%] [G loss: 4.409329]\n",
      "epoch:25 step:19984 [D loss: 0.227620, acc: 98.44%] [G loss: 2.812457]\n",
      "epoch:25 step:19985 [D loss: 0.595160, acc: 59.38%] [G loss: 2.975015]\n",
      "epoch:25 step:19986 [D loss: 0.515012, acc: 66.41%] [G loss: 3.703893]\n",
      "epoch:25 step:19987 [D loss: 0.720729, acc: 54.69%] [G loss: 3.437114]\n",
      "epoch:25 step:19988 [D loss: 0.280116, acc: 87.50%] [G loss: 4.335985]\n",
      "epoch:25 step:19989 [D loss: 0.177788, acc: 100.00%] [G loss: 3.248044]\n",
      "epoch:25 step:19990 [D loss: 0.489090, acc: 85.16%] [G loss: 2.802939]\n",
      "epoch:25 step:19991 [D loss: 0.122593, acc: 100.00%] [G loss: 3.866463]\n",
      "epoch:25 step:19992 [D loss: 0.486687, acc: 83.59%] [G loss: 2.810232]\n",
      "epoch:25 step:19993 [D loss: 0.494509, acc: 71.88%] [G loss: 3.047030]\n",
      "epoch:25 step:19994 [D loss: 0.223712, acc: 97.66%] [G loss: 3.290451]\n",
      "epoch:25 step:19995 [D loss: 0.458209, acc: 78.12%] [G loss: 3.900151]\n",
      "epoch:25 step:19996 [D loss: 0.442154, acc: 75.00%] [G loss: 3.013790]\n",
      "epoch:25 step:19997 [D loss: 0.371313, acc: 92.19%] [G loss: 3.118220]\n",
      "epoch:25 step:19998 [D loss: 1.058784, acc: 45.31%] [G loss: 3.679377]\n",
      "epoch:25 step:19999 [D loss: 0.712334, acc: 57.03%] [G loss: 2.718427]\n",
      "epoch:25 step:20000 [D loss: 0.379758, acc: 75.78%] [G loss: 3.918492]\n",
      "epoch:25 step:20001 [D loss: 0.619268, acc: 63.28%] [G loss: 2.440560]\n",
      "epoch:25 step:20002 [D loss: 0.252810, acc: 97.66%] [G loss: 3.719939]\n",
      "epoch:25 step:20003 [D loss: 0.493043, acc: 67.97%] [G loss: 3.494503]\n",
      "epoch:25 step:20004 [D loss: 1.041283, acc: 50.78%] [G loss: 1.994569]\n",
      "epoch:25 step:20005 [D loss: 0.674831, acc: 60.16%] [G loss: 2.751763]\n",
      "epoch:25 step:20006 [D loss: 0.496973, acc: 75.00%] [G loss: 2.742657]\n",
      "epoch:25 step:20007 [D loss: 0.535496, acc: 65.62%] [G loss: 3.117144]\n",
      "epoch:25 step:20008 [D loss: 0.176055, acc: 97.66%] [G loss: 3.719376]\n",
      "epoch:25 step:20009 [D loss: 0.317473, acc: 90.62%] [G loss: 3.282500]\n",
      "epoch:25 step:20010 [D loss: 0.473058, acc: 77.34%] [G loss: 2.758018]\n",
      "epoch:25 step:20011 [D loss: 0.837766, acc: 50.78%] [G loss: 3.165022]\n",
      "epoch:25 step:20012 [D loss: 0.628360, acc: 57.03%] [G loss: 4.164224]\n",
      "epoch:25 step:20013 [D loss: 0.801704, acc: 47.66%] [G loss: 3.342426]\n",
      "epoch:25 step:20014 [D loss: 0.375351, acc: 83.59%] [G loss: 3.020458]\n",
      "epoch:25 step:20015 [D loss: 0.311377, acc: 97.66%] [G loss: 3.518411]\n",
      "epoch:25 step:20016 [D loss: 0.613596, acc: 67.19%] [G loss: 1.951213]\n",
      "epoch:25 step:20017 [D loss: 0.539221, acc: 77.34%] [G loss: 3.607771]\n",
      "epoch:25 step:20018 [D loss: 0.423980, acc: 93.75%] [G loss: 3.587453]\n",
      "epoch:25 step:20019 [D loss: 0.603452, acc: 63.28%] [G loss: 2.743945]\n",
      "epoch:25 step:20020 [D loss: 0.438094, acc: 86.72%] [G loss: 3.224414]\n",
      "epoch:25 step:20021 [D loss: 0.887202, acc: 47.66%] [G loss: 3.365141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20022 [D loss: 0.167391, acc: 98.44%] [G loss: 3.766503]\n",
      "epoch:25 step:20023 [D loss: 0.305909, acc: 90.62%] [G loss: 5.994522]\n",
      "epoch:25 step:20024 [D loss: 0.226385, acc: 96.88%] [G loss: 3.696633]\n",
      "epoch:25 step:20025 [D loss: 0.334191, acc: 94.53%] [G loss: 4.381614]\n",
      "epoch:25 step:20026 [D loss: 0.861859, acc: 39.84%] [G loss: 2.735823]\n",
      "epoch:25 step:20027 [D loss: 0.535269, acc: 65.62%] [G loss: 2.669102]\n",
      "epoch:25 step:20028 [D loss: 0.323933, acc: 94.53%] [G loss: 2.776618]\n",
      "epoch:25 step:20029 [D loss: 0.424866, acc: 88.28%] [G loss: 3.595711]\n",
      "epoch:25 step:20030 [D loss: 0.684889, acc: 57.03%] [G loss: 2.989303]\n",
      "epoch:25 step:20031 [D loss: 0.536194, acc: 72.66%] [G loss: 3.375391]\n",
      "epoch:25 step:20032 [D loss: 0.921192, acc: 40.62%] [G loss: 3.151836]\n",
      "epoch:25 step:20033 [D loss: 0.248762, acc: 98.44%] [G loss: 2.263240]\n",
      "epoch:25 step:20034 [D loss: 0.427558, acc: 89.84%] [G loss: 2.964315]\n",
      "epoch:25 step:20035 [D loss: 0.239892, acc: 98.44%] [G loss: 2.661653]\n",
      "epoch:25 step:20036 [D loss: 0.186199, acc: 98.44%] [G loss: 4.477664]\n",
      "epoch:25 step:20037 [D loss: 0.578075, acc: 67.97%] [G loss: 3.229853]\n",
      "epoch:25 step:20038 [D loss: 0.952269, acc: 50.00%] [G loss: 4.566473]\n",
      "epoch:25 step:20039 [D loss: 0.802674, acc: 52.34%] [G loss: 2.829466]\n",
      "epoch:25 step:20040 [D loss: 0.193824, acc: 99.22%] [G loss: 3.031060]\n",
      "epoch:25 step:20041 [D loss: 0.473086, acc: 68.75%] [G loss: 2.798017]\n",
      "epoch:25 step:20042 [D loss: 0.219413, acc: 97.66%] [G loss: 4.246302]\n",
      "epoch:25 step:20043 [D loss: 0.785190, acc: 53.91%] [G loss: 1.650000]\n",
      "epoch:25 step:20044 [D loss: 0.405051, acc: 74.22%] [G loss: 4.051494]\n",
      "epoch:25 step:20045 [D loss: 0.327404, acc: 96.09%] [G loss: 2.788106]\n",
      "epoch:25 step:20046 [D loss: 0.439483, acc: 82.03%] [G loss: 3.758149]\n",
      "epoch:25 step:20047 [D loss: 0.736792, acc: 51.56%] [G loss: 2.473915]\n",
      "epoch:25 step:20048 [D loss: 0.636599, acc: 60.16%] [G loss: 3.738589]\n",
      "epoch:25 step:20049 [D loss: 0.815784, acc: 52.34%] [G loss: 4.065045]\n",
      "epoch:25 step:20050 [D loss: 0.416206, acc: 90.62%] [G loss: 2.769488]\n",
      "epoch:25 step:20051 [D loss: 0.765881, acc: 53.91%] [G loss: 5.902182]\n",
      "epoch:25 step:20052 [D loss: 0.180885, acc: 96.88%] [G loss: 4.940286]\n",
      "epoch:25 step:20053 [D loss: 0.563703, acc: 64.84%] [G loss: 3.664634]\n",
      "epoch:25 step:20054 [D loss: 0.197859, acc: 99.22%] [G loss: 2.944784]\n",
      "epoch:25 step:20055 [D loss: 1.609377, acc: 42.97%] [G loss: 3.583240]\n",
      "epoch:25 step:20056 [D loss: 1.018428, acc: 50.00%] [G loss: 2.286818]\n",
      "epoch:25 step:20057 [D loss: 0.744754, acc: 53.12%] [G loss: 3.627495]\n",
      "epoch:25 step:20058 [D loss: 1.018813, acc: 35.16%] [G loss: 2.913283]\n",
      "epoch:25 step:20059 [D loss: 0.163705, acc: 99.22%] [G loss: 3.580161]\n",
      "epoch:25 step:20060 [D loss: 0.560484, acc: 64.84%] [G loss: 3.609232]\n",
      "epoch:25 step:20061 [D loss: 0.574817, acc: 57.03%] [G loss: 3.126335]\n",
      "epoch:25 step:20062 [D loss: 0.763972, acc: 53.12%] [G loss: 2.435555]\n",
      "epoch:25 step:20063 [D loss: 0.179589, acc: 97.66%] [G loss: 3.494969]\n",
      "epoch:25 step:20064 [D loss: 0.588941, acc: 64.84%] [G loss: 2.706047]\n",
      "epoch:25 step:20065 [D loss: 1.200873, acc: 15.62%] [G loss: 3.611631]\n",
      "epoch:25 step:20066 [D loss: 0.397464, acc: 77.34%] [G loss: 4.547877]\n",
      "epoch:25 step:20067 [D loss: 0.754833, acc: 48.44%] [G loss: 3.061966]\n",
      "epoch:25 step:20068 [D loss: 0.493833, acc: 74.22%] [G loss: 2.211830]\n",
      "epoch:25 step:20069 [D loss: 1.250422, acc: 46.09%] [G loss: 1.417597]\n",
      "epoch:25 step:20070 [D loss: 1.087134, acc: 46.88%] [G loss: 3.839315]\n",
      "epoch:25 step:20071 [D loss: 0.843288, acc: 46.09%] [G loss: 2.938391]\n",
      "epoch:25 step:20072 [D loss: 0.311714, acc: 94.53%] [G loss: 2.878124]\n",
      "epoch:25 step:20073 [D loss: 0.645183, acc: 66.41%] [G loss: 2.272425]\n",
      "epoch:25 step:20074 [D loss: 0.169655, acc: 99.22%] [G loss: 3.407375]\n",
      "epoch:25 step:20075 [D loss: 0.186624, acc: 100.00%] [G loss: 4.671421]\n",
      "epoch:25 step:20076 [D loss: 0.799838, acc: 47.66%] [G loss: 2.795383]\n",
      "epoch:25 step:20077 [D loss: 0.859044, acc: 45.31%] [G loss: 3.489898]\n",
      "epoch:25 step:20078 [D loss: 0.912639, acc: 25.78%] [G loss: 2.095425]\n",
      "epoch:25 step:20079 [D loss: 0.788617, acc: 53.12%] [G loss: 2.111985]\n",
      "epoch:25 step:20080 [D loss: 0.172737, acc: 100.00%] [G loss: 3.555152]\n",
      "epoch:25 step:20081 [D loss: 0.691592, acc: 54.69%] [G loss: 2.984440]\n",
      "epoch:25 step:20082 [D loss: 0.573142, acc: 61.72%] [G loss: 2.512791]\n",
      "epoch:25 step:20083 [D loss: 0.430330, acc: 76.56%] [G loss: 2.697317]\n",
      "epoch:25 step:20084 [D loss: 0.299295, acc: 94.53%] [G loss: 3.276925]\n",
      "epoch:25 step:20085 [D loss: 0.601207, acc: 69.53%] [G loss: 1.952220]\n",
      "epoch:25 step:20086 [D loss: 0.814287, acc: 40.62%] [G loss: 3.017622]\n",
      "epoch:25 step:20087 [D loss: 0.490394, acc: 79.69%] [G loss: 3.020771]\n",
      "epoch:25 step:20088 [D loss: 0.660935, acc: 62.50%] [G loss: 3.025218]\n",
      "epoch:25 step:20089 [D loss: 0.329969, acc: 92.97%] [G loss: 3.277139]\n",
      "epoch:25 step:20090 [D loss: 0.231251, acc: 94.53%] [G loss: 3.473632]\n",
      "epoch:25 step:20091 [D loss: 0.445532, acc: 86.72%] [G loss: 2.103106]\n",
      "epoch:25 step:20092 [D loss: 0.744251, acc: 45.31%] [G loss: 3.756456]\n",
      "epoch:25 step:20093 [D loss: 0.659387, acc: 57.81%] [G loss: 3.507952]\n",
      "epoch:25 step:20094 [D loss: 0.242992, acc: 97.66%] [G loss: 3.611128]\n",
      "epoch:25 step:20095 [D loss: 0.971890, acc: 44.53%] [G loss: 3.178063]\n",
      "epoch:25 step:20096 [D loss: 0.600392, acc: 71.88%] [G loss: 2.335183]\n",
      "epoch:25 step:20097 [D loss: 0.526193, acc: 78.12%] [G loss: 3.500335]\n",
      "epoch:25 step:20098 [D loss: 0.585636, acc: 70.31%] [G loss: 3.051498]\n",
      "epoch:25 step:20099 [D loss: 0.510295, acc: 82.03%] [G loss: 3.356629]\n",
      "epoch:25 step:20100 [D loss: 0.553469, acc: 74.22%] [G loss: 3.029490]\n",
      "epoch:25 step:20101 [D loss: 0.234130, acc: 98.44%] [G loss: 2.399328]\n",
      "epoch:25 step:20102 [D loss: 0.718044, acc: 51.56%] [G loss: 2.584936]\n",
      "epoch:25 step:20103 [D loss: 0.297135, acc: 95.31%] [G loss: 2.981843]\n",
      "epoch:25 step:20104 [D loss: 0.392066, acc: 86.72%] [G loss: 3.409272]\n",
      "epoch:25 step:20105 [D loss: 0.122699, acc: 100.00%] [G loss: 3.635838]\n",
      "epoch:25 step:20106 [D loss: 0.822204, acc: 52.34%] [G loss: 4.549263]\n",
      "epoch:25 step:20107 [D loss: 0.538485, acc: 64.06%] [G loss: 3.129144]\n",
      "epoch:25 step:20108 [D loss: 0.588232, acc: 68.75%] [G loss: 3.495428]\n",
      "epoch:25 step:20109 [D loss: 0.588784, acc: 63.28%] [G loss: 2.319383]\n",
      "epoch:25 step:20110 [D loss: 0.957755, acc: 42.19%] [G loss: 2.999711]\n",
      "epoch:25 step:20111 [D loss: 0.315332, acc: 93.75%] [G loss: 2.731803]\n",
      "epoch:25 step:20112 [D loss: 0.480928, acc: 76.56%] [G loss: 1.574005]\n",
      "epoch:25 step:20113 [D loss: 0.680936, acc: 55.47%] [G loss: 3.380909]\n",
      "epoch:25 step:20114 [D loss: 0.253692, acc: 96.88%] [G loss: 2.748109]\n",
      "epoch:25 step:20115 [D loss: 0.483095, acc: 83.59%] [G loss: 2.901740]\n",
      "epoch:25 step:20116 [D loss: 0.655491, acc: 59.38%] [G loss: 2.434987]\n",
      "epoch:25 step:20117 [D loss: 0.398279, acc: 84.38%] [G loss: 2.453986]\n",
      "epoch:25 step:20118 [D loss: 0.432712, acc: 74.22%] [G loss: 2.753139]\n",
      "epoch:25 step:20119 [D loss: 0.443349, acc: 79.69%] [G loss: 3.403486]\n",
      "epoch:25 step:20120 [D loss: 0.415293, acc: 85.16%] [G loss: 2.609779]\n",
      "epoch:25 step:20121 [D loss: 0.280764, acc: 96.09%] [G loss: 2.785976]\n",
      "epoch:25 step:20122 [D loss: 0.773031, acc: 39.06%] [G loss: 2.629731]\n",
      "epoch:25 step:20123 [D loss: 0.296237, acc: 97.66%] [G loss: 3.118960]\n",
      "epoch:25 step:20124 [D loss: 0.555453, acc: 72.66%] [G loss: 2.242143]\n",
      "epoch:25 step:20125 [D loss: 0.353194, acc: 96.09%] [G loss: 2.667147]\n",
      "epoch:25 step:20126 [D loss: 0.373829, acc: 92.19%] [G loss: 3.913687]\n",
      "epoch:25 step:20127 [D loss: 0.616671, acc: 64.84%] [G loss: 3.581874]\n",
      "epoch:25 step:20128 [D loss: 1.236262, acc: 21.88%] [G loss: 3.096961]\n",
      "epoch:25 step:20129 [D loss: 0.120548, acc: 100.00%] [G loss: 3.641338]\n",
      "epoch:25 step:20130 [D loss: 0.397469, acc: 74.22%] [G loss: 2.507823]\n",
      "epoch:25 step:20131 [D loss: 0.536385, acc: 79.69%] [G loss: 2.450692]\n",
      "epoch:25 step:20132 [D loss: 0.343397, acc: 87.50%] [G loss: 2.911841]\n",
      "epoch:25 step:20133 [D loss: 0.641333, acc: 61.72%] [G loss: 2.533615]\n",
      "epoch:25 step:20134 [D loss: 0.383117, acc: 93.75%] [G loss: 3.065886]\n",
      "epoch:25 step:20135 [D loss: 0.383544, acc: 95.31%] [G loss: 2.579736]\n",
      "epoch:25 step:20136 [D loss: 0.227738, acc: 98.44%] [G loss: 3.642159]\n",
      "epoch:25 step:20137 [D loss: 0.790501, acc: 43.75%] [G loss: 4.019638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20138 [D loss: 0.483493, acc: 85.16%] [G loss: 2.656826]\n",
      "epoch:25 step:20139 [D loss: 0.215573, acc: 99.22%] [G loss: 3.213423]\n",
      "epoch:25 step:20140 [D loss: 0.289318, acc: 96.88%] [G loss: 3.203447]\n",
      "epoch:25 step:20141 [D loss: 0.382344, acc: 89.84%] [G loss: 3.428850]\n",
      "epoch:25 step:20142 [D loss: 0.380390, acc: 89.84%] [G loss: 3.810458]\n",
      "epoch:25 step:20143 [D loss: 0.284788, acc: 94.53%] [G loss: 3.681684]\n",
      "epoch:25 step:20144 [D loss: 0.532077, acc: 75.00%] [G loss: 2.471658]\n",
      "epoch:25 step:20145 [D loss: 0.761920, acc: 47.66%] [G loss: 3.344856]\n",
      "epoch:25 step:20146 [D loss: 0.730933, acc: 53.91%] [G loss: 2.063763]\n",
      "epoch:25 step:20147 [D loss: 0.731476, acc: 46.09%] [G loss: 3.255759]\n",
      "epoch:25 step:20148 [D loss: 0.554076, acc: 67.19%] [G loss: 4.390873]\n",
      "epoch:25 step:20149 [D loss: 0.515885, acc: 70.31%] [G loss: 4.035529]\n",
      "epoch:25 step:20150 [D loss: 0.290164, acc: 94.53%] [G loss: 4.398921]\n",
      "epoch:25 step:20151 [D loss: 0.148691, acc: 99.22%] [G loss: 3.953603]\n",
      "epoch:25 step:20152 [D loss: 0.701930, acc: 46.88%] [G loss: 2.059584]\n",
      "epoch:25 step:20153 [D loss: 0.558905, acc: 74.22%] [G loss: 2.124462]\n",
      "epoch:25 step:20154 [D loss: 0.310693, acc: 93.75%] [G loss: 4.437348]\n",
      "epoch:25 step:20155 [D loss: 0.478834, acc: 80.47%] [G loss: 2.750974]\n",
      "epoch:25 step:20156 [D loss: 0.606415, acc: 72.66%] [G loss: 3.642054]\n",
      "epoch:25 step:20157 [D loss: 0.821932, acc: 43.75%] [G loss: 2.213821]\n",
      "epoch:25 step:20158 [D loss: 0.782371, acc: 44.53%] [G loss: 2.998490]\n",
      "epoch:25 step:20159 [D loss: 0.650086, acc: 61.72%] [G loss: 2.707745]\n",
      "epoch:25 step:20160 [D loss: 0.314599, acc: 89.84%] [G loss: 2.638228]\n",
      "epoch:25 step:20161 [D loss: 0.932100, acc: 31.25%] [G loss: 3.458210]\n",
      "epoch:25 step:20162 [D loss: 0.658750, acc: 63.28%] [G loss: 2.811142]\n",
      "epoch:25 step:20163 [D loss: 0.567505, acc: 75.78%] [G loss: 2.210237]\n",
      "epoch:25 step:20164 [D loss: 0.895843, acc: 39.84%] [G loss: 1.997057]\n",
      "epoch:25 step:20165 [D loss: 0.339491, acc: 96.09%] [G loss: 2.764540]\n",
      "epoch:25 step:20166 [D loss: 0.288853, acc: 96.09%] [G loss: 3.258759]\n",
      "epoch:25 step:20167 [D loss: 0.927898, acc: 48.44%] [G loss: 2.770419]\n",
      "epoch:25 step:20168 [D loss: 0.282464, acc: 96.88%] [G loss: 3.344537]\n",
      "epoch:25 step:20169 [D loss: 0.312767, acc: 95.31%] [G loss: 3.247129]\n",
      "epoch:25 step:20170 [D loss: 0.435522, acc: 72.66%] [G loss: 3.801866]\n",
      "epoch:25 step:20171 [D loss: 0.440087, acc: 84.38%] [G loss: 2.366743]\n",
      "epoch:25 step:20172 [D loss: 0.666588, acc: 62.50%] [G loss: 2.088436]\n",
      "epoch:25 step:20173 [D loss: 0.464171, acc: 88.28%] [G loss: 3.186065]\n",
      "epoch:25 step:20174 [D loss: 0.626710, acc: 67.19%] [G loss: 2.204841]\n",
      "epoch:25 step:20175 [D loss: 0.301891, acc: 96.88%] [G loss: 4.253396]\n",
      "epoch:25 step:20176 [D loss: 0.415223, acc: 88.28%] [G loss: 4.857326]\n",
      "epoch:25 step:20177 [D loss: 0.672204, acc: 52.34%] [G loss: 4.051963]\n",
      "epoch:25 step:20178 [D loss: 0.685563, acc: 60.16%] [G loss: 4.162075]\n",
      "epoch:25 step:20179 [D loss: 0.443678, acc: 81.25%] [G loss: 5.308733]\n",
      "epoch:25 step:20180 [D loss: 0.213489, acc: 100.00%] [G loss: 3.536467]\n",
      "epoch:25 step:20181 [D loss: 0.472769, acc: 71.09%] [G loss: 2.825768]\n",
      "epoch:25 step:20182 [D loss: 0.590702, acc: 66.41%] [G loss: 3.451288]\n",
      "epoch:25 step:20183 [D loss: 0.654647, acc: 65.62%] [G loss: 2.675059]\n",
      "epoch:25 step:20184 [D loss: 0.610671, acc: 63.28%] [G loss: 4.047692]\n",
      "epoch:25 step:20185 [D loss: 0.561470, acc: 71.09%] [G loss: 2.853320]\n",
      "epoch:25 step:20186 [D loss: 0.522477, acc: 75.00%] [G loss: 3.220140]\n",
      "epoch:25 step:20187 [D loss: 0.390107, acc: 91.41%] [G loss: 2.744167]\n",
      "epoch:25 step:20188 [D loss: 0.503604, acc: 81.25%] [G loss: 2.089414]\n",
      "epoch:25 step:20189 [D loss: 0.565395, acc: 71.09%] [G loss: 2.395453]\n",
      "epoch:25 step:20190 [D loss: 0.366319, acc: 77.34%] [G loss: 2.884559]\n",
      "epoch:25 step:20191 [D loss: 0.363745, acc: 86.72%] [G loss: 2.992838]\n",
      "epoch:25 step:20192 [D loss: 0.267407, acc: 95.31%] [G loss: 2.516425]\n",
      "epoch:25 step:20193 [D loss: 0.344559, acc: 90.62%] [G loss: 3.125590]\n",
      "epoch:25 step:20194 [D loss: 0.340121, acc: 82.03%] [G loss: 4.378496]\n",
      "epoch:25 step:20195 [D loss: 0.320300, acc: 90.62%] [G loss: 2.736344]\n",
      "epoch:25 step:20196 [D loss: 0.530380, acc: 56.25%] [G loss: 4.728615]\n",
      "epoch:25 step:20197 [D loss: 1.075247, acc: 26.56%] [G loss: 2.586208]\n",
      "epoch:25 step:20198 [D loss: 0.270734, acc: 99.22%] [G loss: 3.027515]\n",
      "epoch:25 step:20199 [D loss: 0.192772, acc: 97.66%] [G loss: 4.341884]\n",
      "epoch:25 step:20200 [D loss: 0.199939, acc: 100.00%] [G loss: 3.955573]\n",
      "epoch:25 step:20201 [D loss: 0.260819, acc: 98.44%] [G loss: 3.826260]\n",
      "epoch:25 step:20202 [D loss: 0.386208, acc: 91.41%] [G loss: 2.206390]\n",
      "epoch:25 step:20203 [D loss: 0.387446, acc: 89.06%] [G loss: 2.917416]\n",
      "epoch:25 step:20204 [D loss: 0.227494, acc: 100.00%] [G loss: 3.558543]\n",
      "epoch:25 step:20205 [D loss: 0.471389, acc: 71.88%] [G loss: 3.313975]\n",
      "epoch:25 step:20206 [D loss: 0.228465, acc: 96.88%] [G loss: 2.812353]\n",
      "epoch:25 step:20207 [D loss: 0.829435, acc: 53.12%] [G loss: 4.664637]\n",
      "epoch:25 step:20208 [D loss: 0.604667, acc: 64.06%] [G loss: 3.979941]\n",
      "epoch:25 step:20209 [D loss: 0.562410, acc: 70.31%] [G loss: 2.435109]\n",
      "epoch:25 step:20210 [D loss: 0.343336, acc: 96.09%] [G loss: 2.541543]\n",
      "epoch:25 step:20211 [D loss: 1.337120, acc: 43.75%] [G loss: 3.348599]\n",
      "epoch:25 step:20212 [D loss: 0.245135, acc: 99.22%] [G loss: 3.600328]\n",
      "epoch:25 step:20213 [D loss: 0.765844, acc: 53.91%] [G loss: 2.977119]\n",
      "epoch:25 step:20214 [D loss: 0.463304, acc: 67.97%] [G loss: 4.151031]\n",
      "epoch:25 step:20215 [D loss: 0.193869, acc: 96.88%] [G loss: 3.597854]\n",
      "epoch:25 step:20216 [D loss: 0.440212, acc: 74.22%] [G loss: 6.326097]\n",
      "epoch:25 step:20217 [D loss: 0.398170, acc: 90.62%] [G loss: 4.368443]\n",
      "epoch:25 step:20218 [D loss: 0.457365, acc: 77.34%] [G loss: 2.989252]\n",
      "epoch:25 step:20219 [D loss: 0.358237, acc: 94.53%] [G loss: 3.048781]\n",
      "epoch:25 step:20220 [D loss: 0.521467, acc: 72.66%] [G loss: 1.503477]\n",
      "epoch:25 step:20221 [D loss: 0.589545, acc: 71.88%] [G loss: 3.857662]\n",
      "epoch:25 step:20222 [D loss: 0.489441, acc: 75.00%] [G loss: 2.517723]\n",
      "epoch:25 step:20223 [D loss: 0.266004, acc: 91.41%] [G loss: 2.870979]\n",
      "epoch:25 step:20224 [D loss: 0.386066, acc: 82.81%] [G loss: 4.295367]\n",
      "epoch:25 step:20225 [D loss: 0.830829, acc: 42.19%] [G loss: 3.531811]\n",
      "epoch:25 step:20226 [D loss: 0.480746, acc: 64.06%] [G loss: 2.275089]\n",
      "epoch:25 step:20227 [D loss: 0.309176, acc: 95.31%] [G loss: 4.148897]\n",
      "epoch:25 step:20228 [D loss: 0.299276, acc: 92.97%] [G loss: 4.425008]\n",
      "epoch:25 step:20229 [D loss: 0.250210, acc: 97.66%] [G loss: 3.042555]\n",
      "epoch:25 step:20230 [D loss: 0.804190, acc: 51.56%] [G loss: 4.400019]\n",
      "epoch:25 step:20231 [D loss: 0.412504, acc: 81.25%] [G loss: 2.575144]\n",
      "epoch:25 step:20232 [D loss: 0.422960, acc: 83.59%] [G loss: 3.078574]\n",
      "epoch:25 step:20233 [D loss: 0.369720, acc: 84.38%] [G loss: 3.862897]\n",
      "epoch:25 step:20234 [D loss: 0.159866, acc: 100.00%] [G loss: 3.651657]\n",
      "epoch:25 step:20235 [D loss: 0.847193, acc: 40.62%] [G loss: 2.657922]\n",
      "epoch:25 step:20236 [D loss: 0.317496, acc: 92.19%] [G loss: 3.872077]\n",
      "epoch:25 step:20237 [D loss: 0.927335, acc: 28.91%] [G loss: 1.860639]\n",
      "epoch:25 step:20238 [D loss: 0.184379, acc: 99.22%] [G loss: 4.612150]\n",
      "epoch:25 step:20239 [D loss: 0.371689, acc: 82.03%] [G loss: 3.500755]\n",
      "epoch:25 step:20240 [D loss: 0.289789, acc: 92.97%] [G loss: 2.056986]\n",
      "epoch:25 step:20241 [D loss: 0.133649, acc: 99.22%] [G loss: 5.363822]\n",
      "epoch:25 step:20242 [D loss: 0.469754, acc: 79.69%] [G loss: 2.912722]\n",
      "epoch:25 step:20243 [D loss: 0.261402, acc: 95.31%] [G loss: 3.830953]\n",
      "epoch:25 step:20244 [D loss: 1.059864, acc: 14.06%] [G loss: 4.049436]\n",
      "epoch:25 step:20245 [D loss: 0.226575, acc: 96.09%] [G loss: 2.492533]\n",
      "epoch:25 step:20246 [D loss: 0.221365, acc: 100.00%] [G loss: 4.024908]\n",
      "epoch:25 step:20247 [D loss: 0.291398, acc: 96.09%] [G loss: 3.384655]\n",
      "epoch:25 step:20248 [D loss: 0.321556, acc: 93.75%] [G loss: 2.749230]\n",
      "epoch:25 step:20249 [D loss: 0.837268, acc: 39.84%] [G loss: 4.308271]\n",
      "epoch:25 step:20250 [D loss: 0.406203, acc: 78.91%] [G loss: 2.793856]\n",
      "epoch:25 step:20251 [D loss: 0.649076, acc: 56.25%] [G loss: 3.296416]\n",
      "epoch:25 step:20252 [D loss: 0.744163, acc: 45.31%] [G loss: 4.133156]\n",
      "epoch:25 step:20253 [D loss: 0.414132, acc: 91.41%] [G loss: 3.462297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20254 [D loss: 0.259961, acc: 100.00%] [G loss: 2.188753]\n",
      "epoch:25 step:20255 [D loss: 0.267610, acc: 89.06%] [G loss: 3.811419]\n",
      "epoch:25 step:20256 [D loss: 0.431042, acc: 84.38%] [G loss: 2.808953]\n",
      "epoch:25 step:20257 [D loss: 0.853178, acc: 39.84%] [G loss: 3.222730]\n",
      "epoch:25 step:20258 [D loss: 0.181523, acc: 100.00%] [G loss: 2.337907]\n",
      "epoch:25 step:20259 [D loss: 0.516544, acc: 76.56%] [G loss: 2.903857]\n",
      "epoch:25 step:20260 [D loss: 0.200814, acc: 98.44%] [G loss: 3.965082]\n",
      "epoch:25 step:20261 [D loss: 0.280073, acc: 92.19%] [G loss: 3.590611]\n",
      "epoch:25 step:20262 [D loss: 0.888435, acc: 34.38%] [G loss: 3.172813]\n",
      "epoch:25 step:20263 [D loss: 0.171409, acc: 98.44%] [G loss: 3.250831]\n",
      "epoch:25 step:20264 [D loss: 0.808488, acc: 48.44%] [G loss: 5.192758]\n",
      "epoch:25 step:20265 [D loss: 0.841978, acc: 46.09%] [G loss: 2.539294]\n",
      "epoch:25 step:20266 [D loss: 0.229623, acc: 99.22%] [G loss: 3.864437]\n",
      "epoch:25 step:20267 [D loss: 0.431156, acc: 67.19%] [G loss: 3.348457]\n",
      "epoch:25 step:20268 [D loss: 0.768541, acc: 48.44%] [G loss: 2.193794]\n",
      "epoch:25 step:20269 [D loss: 0.864428, acc: 51.56%] [G loss: 1.998561]\n",
      "epoch:25 step:20270 [D loss: 0.201501, acc: 99.22%] [G loss: 2.220668]\n",
      "epoch:25 step:20271 [D loss: 0.543313, acc: 61.72%] [G loss: 4.064404]\n",
      "epoch:25 step:20272 [D loss: 1.039287, acc: 42.19%] [G loss: 3.759551]\n",
      "epoch:25 step:20273 [D loss: 0.355635, acc: 88.28%] [G loss: 4.211806]\n",
      "epoch:25 step:20274 [D loss: 0.383753, acc: 89.84%] [G loss: 3.066047]\n",
      "epoch:25 step:20275 [D loss: 0.239727, acc: 94.53%] [G loss: 3.002967]\n",
      "epoch:25 step:20276 [D loss: 1.254360, acc: 46.09%] [G loss: 4.988939]\n",
      "epoch:25 step:20277 [D loss: 0.759358, acc: 52.34%] [G loss: 3.197530]\n",
      "epoch:25 step:20278 [D loss: 0.531111, acc: 63.28%] [G loss: 4.404439]\n",
      "epoch:25 step:20279 [D loss: 0.327800, acc: 88.28%] [G loss: 3.713413]\n",
      "epoch:25 step:20280 [D loss: 1.063537, acc: 18.75%] [G loss: 2.051752]\n",
      "epoch:25 step:20281 [D loss: 1.317856, acc: 18.75%] [G loss: 2.517336]\n",
      "epoch:25 step:20282 [D loss: 0.202489, acc: 100.00%] [G loss: 4.197465]\n",
      "epoch:25 step:20283 [D loss: 1.010513, acc: 44.53%] [G loss: 3.075891]\n",
      "epoch:25 step:20284 [D loss: 0.265016, acc: 97.66%] [G loss: 3.198464]\n",
      "epoch:25 step:20285 [D loss: 0.638789, acc: 53.12%] [G loss: 4.063206]\n",
      "epoch:25 step:20286 [D loss: 0.535522, acc: 58.59%] [G loss: 4.356138]\n",
      "epoch:25 step:20287 [D loss: 0.380197, acc: 94.53%] [G loss: 3.226774]\n",
      "epoch:25 step:20288 [D loss: 0.505519, acc: 75.00%] [G loss: 2.701452]\n",
      "epoch:25 step:20289 [D loss: 0.872869, acc: 32.03%] [G loss: 3.156103]\n",
      "epoch:25 step:20290 [D loss: 0.562852, acc: 75.00%] [G loss: 2.985012]\n",
      "epoch:25 step:20291 [D loss: 0.530894, acc: 69.53%] [G loss: 2.425839]\n",
      "epoch:25 step:20292 [D loss: 0.453752, acc: 76.56%] [G loss: 2.303921]\n",
      "epoch:25 step:20293 [D loss: 0.174679, acc: 100.00%] [G loss: 2.175436]\n",
      "epoch:25 step:20294 [D loss: 0.699461, acc: 51.56%] [G loss: 4.795564]\n",
      "epoch:25 step:20295 [D loss: 0.531749, acc: 75.78%] [G loss: 2.437974]\n",
      "epoch:25 step:20296 [D loss: 1.378232, acc: 16.41%] [G loss: 2.156159]\n",
      "epoch:25 step:20297 [D loss: 0.444461, acc: 78.91%] [G loss: 3.743803]\n",
      "epoch:25 step:20298 [D loss: 0.653987, acc: 57.03%] [G loss: 4.458714]\n",
      "epoch:25 step:20299 [D loss: 0.442677, acc: 85.94%] [G loss: 3.222311]\n",
      "epoch:25 step:20300 [D loss: 0.620884, acc: 60.16%] [G loss: 3.792934]\n",
      "epoch:25 step:20301 [D loss: 0.564716, acc: 73.44%] [G loss: 2.453426]\n",
      "epoch:25 step:20302 [D loss: 1.016323, acc: 35.16%] [G loss: 1.857515]\n",
      "epoch:25 step:20303 [D loss: 0.385882, acc: 87.50%] [G loss: 2.779504]\n",
      "epoch:25 step:20304 [D loss: 0.545756, acc: 66.41%] [G loss: 4.088923]\n",
      "epoch:25 step:20305 [D loss: 0.596351, acc: 64.06%] [G loss: 3.222659]\n",
      "epoch:25 step:20306 [D loss: 0.576046, acc: 64.06%] [G loss: 3.948698]\n",
      "epoch:26 step:20307 [D loss: 0.283799, acc: 95.31%] [G loss: 2.154672]\n",
      "epoch:26 step:20308 [D loss: 0.221324, acc: 98.44%] [G loss: 3.496114]\n",
      "epoch:26 step:20309 [D loss: 0.715876, acc: 56.25%] [G loss: 2.734888]\n",
      "epoch:26 step:20310 [D loss: 0.563794, acc: 71.09%] [G loss: 2.928673]\n",
      "epoch:26 step:20311 [D loss: 0.259530, acc: 96.88%] [G loss: 4.712339]\n",
      "epoch:26 step:20312 [D loss: 0.391541, acc: 88.28%] [G loss: 4.069393]\n",
      "epoch:26 step:20313 [D loss: 0.987001, acc: 35.94%] [G loss: 2.294523]\n",
      "epoch:26 step:20314 [D loss: 0.324699, acc: 95.31%] [G loss: 4.149309]\n",
      "epoch:26 step:20315 [D loss: 0.230141, acc: 99.22%] [G loss: 3.420368]\n",
      "epoch:26 step:20316 [D loss: 0.328256, acc: 87.50%] [G loss: 2.054986]\n",
      "epoch:26 step:20317 [D loss: 0.331744, acc: 96.09%] [G loss: 3.231374]\n",
      "epoch:26 step:20318 [D loss: 0.704648, acc: 56.25%] [G loss: 2.776988]\n",
      "epoch:26 step:20319 [D loss: 0.233888, acc: 99.22%] [G loss: 3.090050]\n",
      "epoch:26 step:20320 [D loss: 0.668378, acc: 57.81%] [G loss: 2.665213]\n",
      "epoch:26 step:20321 [D loss: 1.647426, acc: 50.00%] [G loss: 2.343946]\n",
      "epoch:26 step:20322 [D loss: 0.635695, acc: 59.38%] [G loss: 2.924789]\n",
      "epoch:26 step:20323 [D loss: 0.308239, acc: 95.31%] [G loss: 2.464646]\n",
      "epoch:26 step:20324 [D loss: 0.234192, acc: 96.88%] [G loss: 3.014410]\n",
      "epoch:26 step:20325 [D loss: 0.319862, acc: 89.06%] [G loss: 2.361965]\n",
      "epoch:26 step:20326 [D loss: 0.369160, acc: 89.06%] [G loss: 3.734780]\n",
      "epoch:26 step:20327 [D loss: 0.153903, acc: 99.22%] [G loss: 3.919944]\n",
      "epoch:26 step:20328 [D loss: 0.372371, acc: 87.50%] [G loss: 1.922121]\n",
      "epoch:26 step:20329 [D loss: 0.491815, acc: 74.22%] [G loss: 3.217334]\n",
      "epoch:26 step:20330 [D loss: 0.593483, acc: 68.75%] [G loss: 3.411765]\n",
      "epoch:26 step:20331 [D loss: 0.122536, acc: 99.22%] [G loss: 3.057576]\n",
      "epoch:26 step:20332 [D loss: 0.387463, acc: 89.84%] [G loss: 2.728384]\n",
      "epoch:26 step:20333 [D loss: 0.204544, acc: 96.88%] [G loss: 2.779448]\n",
      "epoch:26 step:20334 [D loss: 1.338733, acc: 38.28%] [G loss: 4.374295]\n",
      "epoch:26 step:20335 [D loss: 0.644973, acc: 60.16%] [G loss: 4.064950]\n",
      "epoch:26 step:20336 [D loss: 0.327997, acc: 97.66%] [G loss: 2.525900]\n",
      "epoch:26 step:20337 [D loss: 0.844309, acc: 50.78%] [G loss: 4.270564]\n",
      "epoch:26 step:20338 [D loss: 0.601669, acc: 71.09%] [G loss: 2.608058]\n",
      "epoch:26 step:20339 [D loss: 1.050719, acc: 20.31%] [G loss: 2.665001]\n",
      "epoch:26 step:20340 [D loss: 0.267430, acc: 94.53%] [G loss: 3.958336]\n",
      "epoch:26 step:20341 [D loss: 0.551872, acc: 75.00%] [G loss: 2.691820]\n",
      "epoch:26 step:20342 [D loss: 0.602166, acc: 66.41%] [G loss: 3.111076]\n",
      "epoch:26 step:20343 [D loss: 0.242237, acc: 97.66%] [G loss: 2.988430]\n",
      "epoch:26 step:20344 [D loss: 0.389432, acc: 88.28%] [G loss: 2.698168]\n",
      "epoch:26 step:20345 [D loss: 0.571771, acc: 75.00%] [G loss: 2.946422]\n",
      "epoch:26 step:20346 [D loss: 0.250566, acc: 96.88%] [G loss: 6.320041]\n",
      "epoch:26 step:20347 [D loss: 0.444168, acc: 83.59%] [G loss: 4.220442]\n",
      "epoch:26 step:20348 [D loss: 0.196501, acc: 100.00%] [G loss: 3.188723]\n",
      "epoch:26 step:20349 [D loss: 0.916228, acc: 34.38%] [G loss: 4.000782]\n",
      "epoch:26 step:20350 [D loss: 0.443259, acc: 77.34%] [G loss: 2.066208]\n",
      "epoch:26 step:20351 [D loss: 0.341139, acc: 93.75%] [G loss: 3.942389]\n",
      "epoch:26 step:20352 [D loss: 0.358402, acc: 84.38%] [G loss: 3.001446]\n",
      "epoch:26 step:20353 [D loss: 0.317345, acc: 92.97%] [G loss: 4.893106]\n",
      "epoch:26 step:20354 [D loss: 1.137904, acc: 17.19%] [G loss: 2.529089]\n",
      "epoch:26 step:20355 [D loss: 0.399230, acc: 90.62%] [G loss: 4.723537]\n",
      "epoch:26 step:20356 [D loss: 0.282120, acc: 93.75%] [G loss: 3.251701]\n",
      "epoch:26 step:20357 [D loss: 0.718562, acc: 55.47%] [G loss: 2.526229]\n",
      "epoch:26 step:20358 [D loss: 0.253404, acc: 97.66%] [G loss: 1.921744]\n",
      "epoch:26 step:20359 [D loss: 0.786608, acc: 53.12%] [G loss: 2.504910]\n",
      "epoch:26 step:20360 [D loss: 1.092993, acc: 21.09%] [G loss: 2.209561]\n",
      "epoch:26 step:20361 [D loss: 0.441533, acc: 84.38%] [G loss: 4.048450]\n",
      "epoch:26 step:20362 [D loss: 0.824959, acc: 52.34%] [G loss: 2.349886]\n",
      "epoch:26 step:20363 [D loss: 1.060325, acc: 50.00%] [G loss: 2.407244]\n",
      "epoch:26 step:20364 [D loss: 0.316758, acc: 96.88%] [G loss: 2.558251]\n",
      "epoch:26 step:20365 [D loss: 0.328426, acc: 92.19%] [G loss: 2.328002]\n",
      "epoch:26 step:20366 [D loss: 0.678749, acc: 59.38%] [G loss: 2.665595]\n",
      "epoch:26 step:20367 [D loss: 0.444669, acc: 88.28%] [G loss: 1.746917]\n",
      "epoch:26 step:20368 [D loss: 0.415574, acc: 89.06%] [G loss: 2.381231]\n",
      "epoch:26 step:20369 [D loss: 0.352587, acc: 94.53%] [G loss: 2.428486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20370 [D loss: 0.846486, acc: 35.94%] [G loss: 3.589717]\n",
      "epoch:26 step:20371 [D loss: 0.958650, acc: 43.75%] [G loss: 3.095116]\n",
      "epoch:26 step:20372 [D loss: 0.805020, acc: 50.78%] [G loss: 3.279872]\n",
      "epoch:26 step:20373 [D loss: 0.905815, acc: 30.47%] [G loss: 1.724282]\n",
      "epoch:26 step:20374 [D loss: 0.291130, acc: 95.31%] [G loss: 2.402983]\n",
      "epoch:26 step:20375 [D loss: 0.452047, acc: 78.91%] [G loss: 3.172302]\n",
      "epoch:26 step:20376 [D loss: 0.542191, acc: 76.56%] [G loss: 4.373645]\n",
      "epoch:26 step:20377 [D loss: 0.434344, acc: 78.12%] [G loss: 1.975791]\n",
      "epoch:26 step:20378 [D loss: 0.401817, acc: 83.59%] [G loss: 3.412214]\n",
      "epoch:26 step:20379 [D loss: 0.476420, acc: 85.94%] [G loss: 2.626749]\n",
      "epoch:26 step:20380 [D loss: 0.416429, acc: 86.72%] [G loss: 1.600544]\n",
      "epoch:26 step:20381 [D loss: 0.676869, acc: 60.16%] [G loss: 3.368518]\n",
      "epoch:26 step:20382 [D loss: 0.262968, acc: 94.53%] [G loss: 2.806448]\n",
      "epoch:26 step:20383 [D loss: 0.278947, acc: 85.94%] [G loss: 3.088565]\n",
      "epoch:26 step:20384 [D loss: 0.987090, acc: 28.12%] [G loss: 3.895404]\n",
      "epoch:26 step:20385 [D loss: 0.372476, acc: 88.28%] [G loss: 3.709868]\n",
      "epoch:26 step:20386 [D loss: 0.223023, acc: 98.44%] [G loss: 3.574244]\n",
      "epoch:26 step:20387 [D loss: 0.622003, acc: 60.94%] [G loss: 2.375411]\n",
      "epoch:26 step:20388 [D loss: 0.280821, acc: 89.84%] [G loss: 3.170399]\n",
      "epoch:26 step:20389 [D loss: 0.383029, acc: 89.06%] [G loss: 2.925181]\n",
      "epoch:26 step:20390 [D loss: 0.893877, acc: 50.00%] [G loss: 2.301067]\n",
      "epoch:26 step:20391 [D loss: 0.406801, acc: 85.16%] [G loss: 2.281220]\n",
      "epoch:26 step:20392 [D loss: 0.644913, acc: 60.16%] [G loss: 2.862361]\n",
      "epoch:26 step:20393 [D loss: 0.498509, acc: 74.22%] [G loss: 3.123868]\n",
      "epoch:26 step:20394 [D loss: 0.551568, acc: 69.53%] [G loss: 2.444449]\n",
      "epoch:26 step:20395 [D loss: 0.460482, acc: 69.53%] [G loss: 3.843972]\n",
      "epoch:26 step:20396 [D loss: 0.448026, acc: 82.03%] [G loss: 3.701217]\n",
      "epoch:26 step:20397 [D loss: 0.140581, acc: 100.00%] [G loss: 3.911435]\n",
      "epoch:26 step:20398 [D loss: 0.314623, acc: 84.38%] [G loss: 3.984915]\n",
      "epoch:26 step:20399 [D loss: 0.739220, acc: 53.91%] [G loss: 3.691478]\n",
      "epoch:26 step:20400 [D loss: 0.141785, acc: 100.00%] [G loss: 3.829403]\n",
      "epoch:26 step:20401 [D loss: 0.260494, acc: 95.31%] [G loss: 3.279423]\n",
      "epoch:26 step:20402 [D loss: 0.280311, acc: 99.22%] [G loss: 2.519377]\n",
      "epoch:26 step:20403 [D loss: 0.556876, acc: 71.09%] [G loss: 2.143396]\n",
      "epoch:26 step:20404 [D loss: 0.492532, acc: 81.25%] [G loss: 3.079794]\n",
      "epoch:26 step:20405 [D loss: 0.255717, acc: 98.44%] [G loss: 3.329808]\n",
      "epoch:26 step:20406 [D loss: 0.390184, acc: 93.75%] [G loss: 4.672651]\n",
      "epoch:26 step:20407 [D loss: 0.675274, acc: 54.69%] [G loss: 2.210772]\n",
      "epoch:26 step:20408 [D loss: 0.320696, acc: 92.97%] [G loss: 3.362590]\n",
      "epoch:26 step:20409 [D loss: 0.479357, acc: 85.16%] [G loss: 3.220252]\n",
      "epoch:26 step:20410 [D loss: 0.107286, acc: 100.00%] [G loss: 5.311255]\n",
      "epoch:26 step:20411 [D loss: 0.168553, acc: 99.22%] [G loss: 3.271130]\n",
      "epoch:26 step:20412 [D loss: 0.615637, acc: 65.62%] [G loss: 5.456498]\n",
      "epoch:26 step:20413 [D loss: 0.476772, acc: 82.03%] [G loss: 2.875677]\n",
      "epoch:26 step:20414 [D loss: 0.512423, acc: 77.34%] [G loss: 2.359114]\n",
      "epoch:26 step:20415 [D loss: 0.218201, acc: 98.44%] [G loss: 4.004817]\n",
      "epoch:26 step:20416 [D loss: 0.386891, acc: 92.19%] [G loss: 2.594858]\n",
      "epoch:26 step:20417 [D loss: 0.670084, acc: 54.69%] [G loss: 2.525555]\n",
      "epoch:26 step:20418 [D loss: 0.177301, acc: 96.88%] [G loss: 2.116419]\n",
      "epoch:26 step:20419 [D loss: 0.348360, acc: 87.50%] [G loss: 2.173431]\n",
      "epoch:26 step:20420 [D loss: 0.561838, acc: 66.41%] [G loss: 3.704653]\n",
      "epoch:26 step:20421 [D loss: 0.287831, acc: 94.53%] [G loss: 3.430703]\n",
      "epoch:26 step:20422 [D loss: 0.592999, acc: 70.31%] [G loss: 2.177486]\n",
      "epoch:26 step:20423 [D loss: 0.655262, acc: 54.69%] [G loss: 3.375483]\n",
      "epoch:26 step:20424 [D loss: 0.188962, acc: 98.44%] [G loss: 3.373591]\n",
      "epoch:26 step:20425 [D loss: 0.249283, acc: 96.09%] [G loss: 3.048731]\n",
      "epoch:26 step:20426 [D loss: 0.501494, acc: 70.31%] [G loss: 3.431337]\n",
      "epoch:26 step:20427 [D loss: 0.657355, acc: 60.16%] [G loss: 2.350682]\n",
      "epoch:26 step:20428 [D loss: 0.403170, acc: 86.72%] [G loss: 3.336748]\n",
      "epoch:26 step:20429 [D loss: 0.226267, acc: 96.88%] [G loss: 2.571930]\n",
      "epoch:26 step:20430 [D loss: 0.787278, acc: 51.56%] [G loss: 2.121751]\n",
      "epoch:26 step:20431 [D loss: 0.602062, acc: 67.97%] [G loss: 3.063307]\n",
      "epoch:26 step:20432 [D loss: 0.662768, acc: 56.25%] [G loss: 4.919987]\n",
      "epoch:26 step:20433 [D loss: 0.687075, acc: 57.81%] [G loss: 3.661639]\n",
      "epoch:26 step:20434 [D loss: 0.621321, acc: 54.69%] [G loss: 3.537926]\n",
      "epoch:26 step:20435 [D loss: 0.930468, acc: 42.97%] [G loss: 2.629662]\n",
      "epoch:26 step:20436 [D loss: 0.475751, acc: 70.31%] [G loss: 4.770600]\n",
      "epoch:26 step:20437 [D loss: 0.114324, acc: 100.00%] [G loss: 2.991966]\n",
      "epoch:26 step:20438 [D loss: 0.170503, acc: 100.00%] [G loss: 4.054054]\n",
      "epoch:26 step:20439 [D loss: 0.202678, acc: 99.22%] [G loss: 2.389921]\n",
      "epoch:26 step:20440 [D loss: 0.353360, acc: 90.62%] [G loss: 3.009055]\n",
      "epoch:26 step:20441 [D loss: 1.134701, acc: 15.62%] [G loss: 3.216378]\n",
      "epoch:26 step:20442 [D loss: 0.252883, acc: 91.41%] [G loss: 3.513579]\n",
      "epoch:26 step:20443 [D loss: 0.798203, acc: 52.34%] [G loss: 3.061430]\n",
      "epoch:26 step:20444 [D loss: 0.769967, acc: 43.75%] [G loss: 2.051707]\n",
      "epoch:26 step:20445 [D loss: 0.080141, acc: 100.00%] [G loss: 5.020155]\n",
      "epoch:26 step:20446 [D loss: 0.330865, acc: 93.75%] [G loss: 2.635839]\n",
      "epoch:26 step:20447 [D loss: 0.572492, acc: 71.09%] [G loss: 2.787914]\n",
      "epoch:26 step:20448 [D loss: 0.379807, acc: 92.19%] [G loss: 1.787382]\n",
      "epoch:26 step:20449 [D loss: 0.402898, acc: 83.59%] [G loss: 2.799322]\n",
      "epoch:26 step:20450 [D loss: 0.183299, acc: 100.00%] [G loss: 3.047932]\n",
      "epoch:26 step:20451 [D loss: 0.997348, acc: 26.56%] [G loss: 3.182846]\n",
      "epoch:26 step:20452 [D loss: 0.174938, acc: 99.22%] [G loss: 3.071976]\n",
      "epoch:26 step:20453 [D loss: 0.919190, acc: 47.66%] [G loss: 2.589692]\n",
      "epoch:26 step:20454 [D loss: 0.370284, acc: 91.41%] [G loss: 3.364398]\n",
      "epoch:26 step:20455 [D loss: 0.907790, acc: 51.56%] [G loss: 4.243421]\n",
      "epoch:26 step:20456 [D loss: 0.501927, acc: 72.66%] [G loss: 2.896466]\n",
      "epoch:26 step:20457 [D loss: 0.514770, acc: 78.12%] [G loss: 2.427158]\n",
      "epoch:26 step:20458 [D loss: 0.521795, acc: 77.34%] [G loss: 3.507341]\n",
      "epoch:26 step:20459 [D loss: 0.335042, acc: 94.53%] [G loss: 2.545508]\n",
      "epoch:26 step:20460 [D loss: 0.511964, acc: 73.44%] [G loss: 3.859155]\n",
      "epoch:26 step:20461 [D loss: 0.473083, acc: 82.81%] [G loss: 4.001879]\n",
      "epoch:26 step:20462 [D loss: 0.509791, acc: 73.44%] [G loss: 3.300884]\n",
      "epoch:26 step:20463 [D loss: 0.241014, acc: 93.75%] [G loss: 3.306207]\n",
      "epoch:26 step:20464 [D loss: 1.738263, acc: 29.69%] [G loss: 3.266638]\n",
      "epoch:26 step:20465 [D loss: 0.064870, acc: 100.00%] [G loss: 4.791041]\n",
      "epoch:26 step:20466 [D loss: 0.571136, acc: 70.31%] [G loss: 4.076091]\n",
      "epoch:26 step:20467 [D loss: 0.699710, acc: 54.69%] [G loss: 2.211855]\n",
      "epoch:26 step:20468 [D loss: 0.518259, acc: 75.78%] [G loss: 2.881331]\n",
      "epoch:26 step:20469 [D loss: 0.479231, acc: 78.12%] [G loss: 3.255178]\n",
      "epoch:26 step:20470 [D loss: 0.590789, acc: 67.19%] [G loss: 2.162188]\n",
      "epoch:26 step:20471 [D loss: 0.564673, acc: 71.88%] [G loss: 2.729043]\n",
      "epoch:26 step:20472 [D loss: 0.418752, acc: 87.50%] [G loss: 3.570897]\n",
      "epoch:26 step:20473 [D loss: 0.664873, acc: 64.06%] [G loss: 3.647972]\n",
      "epoch:26 step:20474 [D loss: 0.146411, acc: 98.44%] [G loss: 2.614149]\n",
      "epoch:26 step:20475 [D loss: 0.552966, acc: 75.00%] [G loss: 2.525044]\n",
      "epoch:26 step:20476 [D loss: 0.446039, acc: 82.81%] [G loss: 3.282536]\n",
      "epoch:26 step:20477 [D loss: 0.191254, acc: 98.44%] [G loss: 3.213112]\n",
      "epoch:26 step:20478 [D loss: 0.668523, acc: 59.38%] [G loss: 2.459781]\n",
      "epoch:26 step:20479 [D loss: 0.771027, acc: 47.66%] [G loss: 3.101792]\n",
      "epoch:26 step:20480 [D loss: 0.248158, acc: 98.44%] [G loss: 3.110163]\n",
      "epoch:26 step:20481 [D loss: 0.424225, acc: 85.16%] [G loss: 3.749985]\n",
      "epoch:26 step:20482 [D loss: 0.814337, acc: 43.75%] [G loss: 2.415240]\n",
      "epoch:26 step:20483 [D loss: 0.399693, acc: 90.62%] [G loss: 3.415123]\n",
      "epoch:26 step:20484 [D loss: 0.674525, acc: 55.47%] [G loss: 2.605959]\n",
      "epoch:26 step:20485 [D loss: 0.278258, acc: 89.84%] [G loss: 3.576501]\n",
      "epoch:26 step:20486 [D loss: 0.858871, acc: 35.94%] [G loss: 3.129984]\n",
      "epoch:26 step:20487 [D loss: 0.235444, acc: 99.22%] [G loss: 3.428689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20488 [D loss: 0.296283, acc: 91.41%] [G loss: 2.952626]\n",
      "epoch:26 step:20489 [D loss: 0.399212, acc: 88.28%] [G loss: 3.460819]\n",
      "epoch:26 step:20490 [D loss: 1.122441, acc: 31.25%] [G loss: 2.369097]\n",
      "epoch:26 step:20491 [D loss: 0.528019, acc: 78.12%] [G loss: 4.067559]\n",
      "epoch:26 step:20492 [D loss: 0.136104, acc: 100.00%] [G loss: 3.759254]\n",
      "epoch:26 step:20493 [D loss: 0.255125, acc: 98.44%] [G loss: 2.850685]\n",
      "epoch:26 step:20494 [D loss: 1.105718, acc: 20.31%] [G loss: 2.851611]\n",
      "epoch:26 step:20495 [D loss: 0.422677, acc: 85.94%] [G loss: 5.142180]\n",
      "epoch:26 step:20496 [D loss: 0.198046, acc: 96.09%] [G loss: 3.199048]\n",
      "epoch:26 step:20497 [D loss: 0.892520, acc: 43.75%] [G loss: 3.627401]\n",
      "epoch:26 step:20498 [D loss: 0.097875, acc: 100.00%] [G loss: 3.770082]\n",
      "epoch:26 step:20499 [D loss: 0.279301, acc: 91.41%] [G loss: 4.220574]\n",
      "epoch:26 step:20500 [D loss: 0.269361, acc: 96.88%] [G loss: 3.623782]\n",
      "epoch:26 step:20501 [D loss: 0.774797, acc: 45.31%] [G loss: 2.771031]\n",
      "epoch:26 step:20502 [D loss: 0.512453, acc: 78.12%] [G loss: 2.245648]\n",
      "epoch:26 step:20503 [D loss: 0.218066, acc: 98.44%] [G loss: 2.963179]\n",
      "epoch:26 step:20504 [D loss: 0.513885, acc: 71.09%] [G loss: 3.477532]\n",
      "epoch:26 step:20505 [D loss: 0.199895, acc: 96.88%] [G loss: 4.246229]\n",
      "epoch:26 step:20506 [D loss: 0.178026, acc: 100.00%] [G loss: 4.171523]\n",
      "epoch:26 step:20507 [D loss: 0.387595, acc: 84.38%] [G loss: 2.932965]\n",
      "epoch:26 step:20508 [D loss: 0.699737, acc: 54.69%] [G loss: 3.759972]\n",
      "epoch:26 step:20509 [D loss: 0.631568, acc: 61.72%] [G loss: 2.372933]\n",
      "epoch:26 step:20510 [D loss: 0.586543, acc: 75.00%] [G loss: 2.169324]\n",
      "epoch:26 step:20511 [D loss: 0.622637, acc: 61.72%] [G loss: 2.215968]\n",
      "epoch:26 step:20512 [D loss: 1.247828, acc: 18.75%] [G loss: 1.960605]\n",
      "epoch:26 step:20513 [D loss: 0.410935, acc: 85.94%] [G loss: 2.229869]\n",
      "epoch:26 step:20514 [D loss: 0.401029, acc: 83.59%] [G loss: 2.752497]\n",
      "epoch:26 step:20515 [D loss: 0.204642, acc: 94.53%] [G loss: 3.437478]\n",
      "epoch:26 step:20516 [D loss: 0.307826, acc: 93.75%] [G loss: 2.782438]\n",
      "epoch:26 step:20517 [D loss: 0.474094, acc: 84.38%] [G loss: 3.846561]\n",
      "epoch:26 step:20518 [D loss: 0.244545, acc: 98.44%] [G loss: 3.630218]\n",
      "epoch:26 step:20519 [D loss: 1.062312, acc: 22.66%] [G loss: 2.306057]\n",
      "epoch:26 step:20520 [D loss: 0.594776, acc: 61.72%] [G loss: 3.155088]\n",
      "epoch:26 step:20521 [D loss: 0.454544, acc: 67.19%] [G loss: 3.013295]\n",
      "epoch:26 step:20522 [D loss: 1.148583, acc: 40.62%] [G loss: 2.935650]\n",
      "epoch:26 step:20523 [D loss: 0.432964, acc: 84.38%] [G loss: 3.435728]\n",
      "epoch:26 step:20524 [D loss: 0.377054, acc: 82.03%] [G loss: 3.239794]\n",
      "epoch:26 step:20525 [D loss: 0.644346, acc: 64.84%] [G loss: 3.743875]\n",
      "epoch:26 step:20526 [D loss: 0.198069, acc: 99.22%] [G loss: 3.655854]\n",
      "epoch:26 step:20527 [D loss: 0.740606, acc: 48.44%] [G loss: 2.856917]\n",
      "epoch:26 step:20528 [D loss: 0.279405, acc: 92.19%] [G loss: 2.618263]\n",
      "epoch:26 step:20529 [D loss: 0.305855, acc: 92.19%] [G loss: 3.066258]\n",
      "epoch:26 step:20530 [D loss: 0.671915, acc: 60.94%] [G loss: 2.609383]\n",
      "epoch:26 step:20531 [D loss: 0.295425, acc: 96.09%] [G loss: 2.918391]\n",
      "epoch:26 step:20532 [D loss: 0.254156, acc: 97.66%] [G loss: 2.609325]\n",
      "epoch:26 step:20533 [D loss: 0.178881, acc: 100.00%] [G loss: 3.425497]\n",
      "epoch:26 step:20534 [D loss: 0.514956, acc: 60.94%] [G loss: 3.869621]\n",
      "epoch:26 step:20535 [D loss: 0.428987, acc: 76.56%] [G loss: 3.013277]\n",
      "epoch:26 step:20536 [D loss: 0.550618, acc: 60.16%] [G loss: 3.035958]\n",
      "epoch:26 step:20537 [D loss: 0.784558, acc: 55.47%] [G loss: 2.623901]\n",
      "epoch:26 step:20538 [D loss: 0.550763, acc: 71.09%] [G loss: 3.498986]\n",
      "epoch:26 step:20539 [D loss: 0.261761, acc: 99.22%] [G loss: 3.849393]\n",
      "epoch:26 step:20540 [D loss: 1.440898, acc: 50.78%] [G loss: 2.899212]\n",
      "epoch:26 step:20541 [D loss: 0.816669, acc: 52.34%] [G loss: 2.742991]\n",
      "epoch:26 step:20542 [D loss: 0.335855, acc: 95.31%] [G loss: 4.298901]\n",
      "epoch:26 step:20543 [D loss: 0.350652, acc: 85.94%] [G loss: 2.569912]\n",
      "epoch:26 step:20544 [D loss: 0.660935, acc: 64.06%] [G loss: 2.273798]\n",
      "epoch:26 step:20545 [D loss: 0.113825, acc: 99.22%] [G loss: 3.062321]\n",
      "epoch:26 step:20546 [D loss: 0.372047, acc: 95.31%] [G loss: 2.701188]\n",
      "epoch:26 step:20547 [D loss: 0.438037, acc: 86.72%] [G loss: 2.613424]\n",
      "epoch:26 step:20548 [D loss: 0.529613, acc: 66.41%] [G loss: 4.275600]\n",
      "epoch:26 step:20549 [D loss: 0.168452, acc: 99.22%] [G loss: 3.996377]\n",
      "epoch:26 step:20550 [D loss: 0.287511, acc: 87.50%] [G loss: 2.921081]\n",
      "epoch:26 step:20551 [D loss: 1.090389, acc: 17.97%] [G loss: 1.588168]\n",
      "epoch:26 step:20552 [D loss: 0.466332, acc: 85.94%] [G loss: 3.771126]\n",
      "epoch:26 step:20553 [D loss: 0.384339, acc: 87.50%] [G loss: 3.279995]\n",
      "epoch:26 step:20554 [D loss: 0.409195, acc: 76.56%] [G loss: 3.036142]\n",
      "epoch:26 step:20555 [D loss: 0.436707, acc: 79.69%] [G loss: 1.957258]\n",
      "epoch:26 step:20556 [D loss: 0.463913, acc: 82.03%] [G loss: 3.671603]\n",
      "epoch:26 step:20557 [D loss: 0.155394, acc: 100.00%] [G loss: 3.199049]\n",
      "epoch:26 step:20558 [D loss: 0.887078, acc: 28.91%] [G loss: 2.365345]\n",
      "epoch:26 step:20559 [D loss: 0.975656, acc: 50.00%] [G loss: 3.438519]\n",
      "epoch:26 step:20560 [D loss: 0.972900, acc: 29.69%] [G loss: 4.549440]\n",
      "epoch:26 step:20561 [D loss: 0.317978, acc: 92.19%] [G loss: 4.032738]\n",
      "epoch:26 step:20562 [D loss: 0.391921, acc: 84.38%] [G loss: 2.169685]\n",
      "epoch:26 step:20563 [D loss: 0.674645, acc: 53.91%] [G loss: 2.435207]\n",
      "epoch:26 step:20564 [D loss: 0.286214, acc: 96.09%] [G loss: 4.081504]\n",
      "epoch:26 step:20565 [D loss: 0.480327, acc: 85.16%] [G loss: 2.202368]\n",
      "epoch:26 step:20566 [D loss: 0.266051, acc: 96.09%] [G loss: 3.933106]\n",
      "epoch:26 step:20567 [D loss: 0.335650, acc: 94.53%] [G loss: 2.304571]\n",
      "epoch:26 step:20568 [D loss: 0.300280, acc: 95.31%] [G loss: 3.372874]\n",
      "epoch:26 step:20569 [D loss: 0.390355, acc: 82.03%] [G loss: 3.345220]\n",
      "epoch:26 step:20570 [D loss: 0.328947, acc: 92.97%] [G loss: 2.908705]\n",
      "epoch:26 step:20571 [D loss: 0.448032, acc: 82.81%] [G loss: 5.825436]\n",
      "epoch:26 step:20572 [D loss: 0.846114, acc: 52.34%] [G loss: 2.831205]\n",
      "epoch:26 step:20573 [D loss: 0.935063, acc: 25.00%] [G loss: 2.097573]\n",
      "epoch:26 step:20574 [D loss: 0.240357, acc: 99.22%] [G loss: 2.498349]\n",
      "epoch:26 step:20575 [D loss: 0.997162, acc: 22.66%] [G loss: 2.901752]\n",
      "epoch:26 step:20576 [D loss: 0.329730, acc: 95.31%] [G loss: 2.556210]\n",
      "epoch:26 step:20577 [D loss: 0.184561, acc: 97.66%] [G loss: 2.886209]\n",
      "epoch:26 step:20578 [D loss: 0.199059, acc: 99.22%] [G loss: 3.698318]\n",
      "epoch:26 step:20579 [D loss: 0.354252, acc: 93.75%] [G loss: 3.206009]\n",
      "epoch:26 step:20580 [D loss: 0.547042, acc: 67.97%] [G loss: 2.060625]\n",
      "epoch:26 step:20581 [D loss: 0.448718, acc: 85.16%] [G loss: 3.331439]\n",
      "epoch:26 step:20582 [D loss: 0.848480, acc: 35.94%] [G loss: 3.667390]\n",
      "epoch:26 step:20583 [D loss: 0.846798, acc: 53.12%] [G loss: 4.134652]\n",
      "epoch:26 step:20584 [D loss: 0.714141, acc: 57.03%] [G loss: 2.807270]\n",
      "epoch:26 step:20585 [D loss: 0.343218, acc: 82.81%] [G loss: 3.704947]\n",
      "epoch:26 step:20586 [D loss: 0.202813, acc: 96.88%] [G loss: 2.857281]\n",
      "epoch:26 step:20587 [D loss: 0.312237, acc: 90.62%] [G loss: 3.524990]\n",
      "epoch:26 step:20588 [D loss: 0.198613, acc: 99.22%] [G loss: 2.851923]\n",
      "epoch:26 step:20589 [D loss: 0.286862, acc: 96.09%] [G loss: 2.671932]\n",
      "epoch:26 step:20590 [D loss: 0.544581, acc: 72.66%] [G loss: 3.287605]\n",
      "epoch:26 step:20591 [D loss: 0.317740, acc: 92.19%] [G loss: 3.886329]\n",
      "epoch:26 step:20592 [D loss: 0.600321, acc: 68.75%] [G loss: 2.742727]\n",
      "epoch:26 step:20593 [D loss: 0.225210, acc: 96.88%] [G loss: 3.199666]\n",
      "epoch:26 step:20594 [D loss: 0.774211, acc: 56.25%] [G loss: 3.001215]\n",
      "epoch:26 step:20595 [D loss: 0.563834, acc: 69.53%] [G loss: 3.084939]\n",
      "epoch:26 step:20596 [D loss: 0.586976, acc: 71.88%] [G loss: 2.034059]\n",
      "epoch:26 step:20597 [D loss: 0.777020, acc: 50.00%] [G loss: 2.543483]\n",
      "epoch:26 step:20598 [D loss: 0.595136, acc: 59.38%] [G loss: 3.342228]\n",
      "epoch:26 step:20599 [D loss: 0.848186, acc: 45.31%] [G loss: 4.379766]\n",
      "epoch:26 step:20600 [D loss: 0.931266, acc: 29.69%] [G loss: 2.996408]\n",
      "epoch:26 step:20601 [D loss: 0.242765, acc: 98.44%] [G loss: 2.965036]\n",
      "epoch:26 step:20602 [D loss: 0.153139, acc: 99.22%] [G loss: 5.038109]\n",
      "epoch:26 step:20603 [D loss: 0.247068, acc: 98.44%] [G loss: 3.829602]\n",
      "epoch:26 step:20604 [D loss: 0.354866, acc: 86.72%] [G loss: 3.048918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20605 [D loss: 0.241048, acc: 96.88%] [G loss: 2.913850]\n",
      "epoch:26 step:20606 [D loss: 0.427177, acc: 88.28%] [G loss: 3.314718]\n",
      "epoch:26 step:20607 [D loss: 0.402136, acc: 86.72%] [G loss: 3.941193]\n",
      "epoch:26 step:20608 [D loss: 0.739031, acc: 53.91%] [G loss: 3.399795]\n",
      "epoch:26 step:20609 [D loss: 0.416917, acc: 85.94%] [G loss: 4.269273]\n",
      "epoch:26 step:20610 [D loss: 0.696390, acc: 59.38%] [G loss: 2.654654]\n",
      "epoch:26 step:20611 [D loss: 0.203027, acc: 96.09%] [G loss: 2.246104]\n",
      "epoch:26 step:20612 [D loss: 0.396513, acc: 80.47%] [G loss: 3.227911]\n",
      "epoch:26 step:20613 [D loss: 0.538919, acc: 74.22%] [G loss: 2.641112]\n",
      "epoch:26 step:20614 [D loss: 0.191093, acc: 96.88%] [G loss: 4.059506]\n",
      "epoch:26 step:20615 [D loss: 0.498377, acc: 66.41%] [G loss: 2.198930]\n",
      "epoch:26 step:20616 [D loss: 0.389620, acc: 91.41%] [G loss: 4.194581]\n",
      "epoch:26 step:20617 [D loss: 0.797336, acc: 51.56%] [G loss: 3.755425]\n",
      "epoch:26 step:20618 [D loss: 0.437541, acc: 71.88%] [G loss: 2.951479]\n",
      "epoch:26 step:20619 [D loss: 0.577686, acc: 59.38%] [G loss: 2.577199]\n",
      "epoch:26 step:20620 [D loss: 0.131747, acc: 99.22%] [G loss: 2.718361]\n",
      "epoch:26 step:20621 [D loss: 0.570603, acc: 66.41%] [G loss: 2.741878]\n",
      "epoch:26 step:20622 [D loss: 0.921179, acc: 50.78%] [G loss: 4.397357]\n",
      "epoch:26 step:20623 [D loss: 0.152394, acc: 99.22%] [G loss: 4.265516]\n",
      "epoch:26 step:20624 [D loss: 0.419892, acc: 81.25%] [G loss: 2.205320]\n",
      "epoch:26 step:20625 [D loss: 0.535765, acc: 71.09%] [G loss: 2.565281]\n",
      "epoch:26 step:20626 [D loss: 0.534985, acc: 73.44%] [G loss: 3.137475]\n",
      "epoch:26 step:20627 [D loss: 0.371076, acc: 96.09%] [G loss: 3.220000]\n",
      "epoch:26 step:20628 [D loss: 0.379063, acc: 86.72%] [G loss: 3.273315]\n",
      "epoch:26 step:20629 [D loss: 0.363286, acc: 94.53%] [G loss: 3.628870]\n",
      "epoch:26 step:20630 [D loss: 0.486123, acc: 69.53%] [G loss: 3.200263]\n",
      "epoch:26 step:20631 [D loss: 0.358334, acc: 90.62%] [G loss: 3.955606]\n",
      "epoch:26 step:20632 [D loss: 0.361614, acc: 84.38%] [G loss: 3.106447]\n",
      "epoch:26 step:20633 [D loss: 0.358465, acc: 90.62%] [G loss: 4.794042]\n",
      "epoch:26 step:20634 [D loss: 0.972841, acc: 50.00%] [G loss: 2.947919]\n",
      "epoch:26 step:20635 [D loss: 0.188223, acc: 99.22%] [G loss: 3.556724]\n",
      "epoch:26 step:20636 [D loss: 1.505501, acc: 10.94%] [G loss: 3.778174]\n",
      "epoch:26 step:20637 [D loss: 0.264101, acc: 94.53%] [G loss: 3.101619]\n",
      "epoch:26 step:20638 [D loss: 0.805295, acc: 50.00%] [G loss: 3.341190]\n",
      "epoch:26 step:20639 [D loss: 0.108054, acc: 99.22%] [G loss: 3.790621]\n",
      "epoch:26 step:20640 [D loss: 0.391835, acc: 92.19%] [G loss: 3.338950]\n",
      "epoch:26 step:20641 [D loss: 0.680906, acc: 55.47%] [G loss: 3.236987]\n",
      "epoch:26 step:20642 [D loss: 0.065855, acc: 100.00%] [G loss: 4.726961]\n",
      "epoch:26 step:20643 [D loss: 0.540761, acc: 72.66%] [G loss: 3.731064]\n",
      "epoch:26 step:20644 [D loss: 0.625114, acc: 62.50%] [G loss: 3.944695]\n",
      "epoch:26 step:20645 [D loss: 0.442103, acc: 76.56%] [G loss: 3.142465]\n",
      "epoch:26 step:20646 [D loss: 0.521405, acc: 81.25%] [G loss: 1.788451]\n",
      "epoch:26 step:20647 [D loss: 0.549398, acc: 71.09%] [G loss: 4.035838]\n",
      "epoch:26 step:20648 [D loss: 0.196952, acc: 100.00%] [G loss: 3.441885]\n",
      "epoch:26 step:20649 [D loss: 0.721564, acc: 52.34%] [G loss: 3.163176]\n",
      "epoch:26 step:20650 [D loss: 0.704367, acc: 58.59%] [G loss: 3.086339]\n",
      "epoch:26 step:20651 [D loss: 0.203545, acc: 97.66%] [G loss: 3.617414]\n",
      "epoch:26 step:20652 [D loss: 0.506644, acc: 77.34%] [G loss: 3.086756]\n",
      "epoch:26 step:20653 [D loss: 0.242746, acc: 98.44%] [G loss: 2.928424]\n",
      "epoch:26 step:20654 [D loss: 0.464335, acc: 78.12%] [G loss: 3.115109]\n",
      "epoch:26 step:20655 [D loss: 0.828565, acc: 35.16%] [G loss: 2.070925]\n",
      "epoch:26 step:20656 [D loss: 0.867214, acc: 36.72%] [G loss: 4.386271]\n",
      "epoch:26 step:20657 [D loss: 0.311031, acc: 94.53%] [G loss: 1.984200]\n",
      "epoch:26 step:20658 [D loss: 0.338285, acc: 89.84%] [G loss: 2.431632]\n",
      "epoch:26 step:20659 [D loss: 0.895746, acc: 38.28%] [G loss: 2.341930]\n",
      "epoch:26 step:20660 [D loss: 0.943601, acc: 34.38%] [G loss: 1.881550]\n",
      "epoch:26 step:20661 [D loss: 1.270009, acc: 7.81%] [G loss: 1.669700]\n",
      "epoch:26 step:20662 [D loss: 0.436755, acc: 86.72%] [G loss: 3.503618]\n",
      "epoch:26 step:20663 [D loss: 0.314675, acc: 89.84%] [G loss: 2.979720]\n",
      "epoch:26 step:20664 [D loss: 0.447613, acc: 76.56%] [G loss: 3.517982]\n",
      "epoch:26 step:20665 [D loss: 0.511710, acc: 70.31%] [G loss: 2.830708]\n",
      "epoch:26 step:20666 [D loss: 0.261429, acc: 98.44%] [G loss: 3.867995]\n",
      "epoch:26 step:20667 [D loss: 0.505835, acc: 73.44%] [G loss: 3.126947]\n",
      "epoch:26 step:20668 [D loss: 0.419700, acc: 82.81%] [G loss: 2.610778]\n",
      "epoch:26 step:20669 [D loss: 0.104258, acc: 100.00%] [G loss: 3.324807]\n",
      "epoch:26 step:20670 [D loss: 0.599212, acc: 63.28%] [G loss: 2.369419]\n",
      "epoch:26 step:20671 [D loss: 0.236842, acc: 96.88%] [G loss: 3.803799]\n",
      "epoch:26 step:20672 [D loss: 0.440383, acc: 84.38%] [G loss: 2.626534]\n",
      "epoch:26 step:20673 [D loss: 0.558051, acc: 70.31%] [G loss: 2.812596]\n",
      "epoch:26 step:20674 [D loss: 0.402661, acc: 92.97%] [G loss: 2.869575]\n",
      "epoch:26 step:20675 [D loss: 0.632563, acc: 59.38%] [G loss: 2.595938]\n",
      "epoch:26 step:20676 [D loss: 0.320480, acc: 92.97%] [G loss: 3.956646]\n",
      "epoch:26 step:20677 [D loss: 0.373873, acc: 79.69%] [G loss: 3.233820]\n",
      "epoch:26 step:20678 [D loss: 0.332676, acc: 91.41%] [G loss: 3.606257]\n",
      "epoch:26 step:20679 [D loss: 0.201335, acc: 97.66%] [G loss: 3.733703]\n",
      "epoch:26 step:20680 [D loss: 0.113586, acc: 100.00%] [G loss: 3.410423]\n",
      "epoch:26 step:20681 [D loss: 0.430538, acc: 88.28%] [G loss: 3.690319]\n",
      "epoch:26 step:20682 [D loss: 0.529373, acc: 75.00%] [G loss: 3.290044]\n",
      "epoch:26 step:20683 [D loss: 0.640277, acc: 60.16%] [G loss: 2.791398]\n",
      "epoch:26 step:20684 [D loss: 0.339706, acc: 94.53%] [G loss: 3.166341]\n",
      "epoch:26 step:20685 [D loss: 0.268971, acc: 98.44%] [G loss: 3.515913]\n",
      "epoch:26 step:20686 [D loss: 0.281592, acc: 94.53%] [G loss: 2.713300]\n",
      "epoch:26 step:20687 [D loss: 0.393513, acc: 85.94%] [G loss: 2.767071]\n",
      "epoch:26 step:20688 [D loss: 0.530734, acc: 67.19%] [G loss: 2.911034]\n",
      "epoch:26 step:20689 [D loss: 0.348187, acc: 87.50%] [G loss: 4.073388]\n",
      "epoch:26 step:20690 [D loss: 0.477823, acc: 81.25%] [G loss: 3.756575]\n",
      "epoch:26 step:20691 [D loss: 0.409337, acc: 89.06%] [G loss: 3.316102]\n",
      "epoch:26 step:20692 [D loss: 1.387356, acc: 50.78%] [G loss: 4.331732]\n",
      "epoch:26 step:20693 [D loss: 0.069359, acc: 100.00%] [G loss: 4.788903]\n",
      "epoch:26 step:20694 [D loss: 0.287241, acc: 88.28%] [G loss: 3.443971]\n",
      "epoch:26 step:20695 [D loss: 0.421552, acc: 86.72%] [G loss: 2.366411]\n",
      "epoch:26 step:20696 [D loss: 0.226340, acc: 98.44%] [G loss: 3.252822]\n",
      "epoch:26 step:20697 [D loss: 0.381057, acc: 85.16%] [G loss: 5.158998]\n",
      "epoch:26 step:20698 [D loss: 0.712947, acc: 51.56%] [G loss: 4.617383]\n",
      "epoch:26 step:20699 [D loss: 0.707139, acc: 55.47%] [G loss: 3.816291]\n",
      "epoch:26 step:20700 [D loss: 0.408779, acc: 90.62%] [G loss: 3.370759]\n",
      "epoch:26 step:20701 [D loss: 0.561104, acc: 75.78%] [G loss: 2.972580]\n",
      "epoch:26 step:20702 [D loss: 0.190784, acc: 97.66%] [G loss: 5.610474]\n",
      "epoch:26 step:20703 [D loss: 0.466857, acc: 89.84%] [G loss: 3.748045]\n",
      "epoch:26 step:20704 [D loss: 0.215214, acc: 98.44%] [G loss: 3.508090]\n",
      "epoch:26 step:20705 [D loss: 0.457764, acc: 73.44%] [G loss: 4.063856]\n",
      "epoch:26 step:20706 [D loss: 0.287898, acc: 96.09%] [G loss: 4.514215]\n",
      "epoch:26 step:20707 [D loss: 0.417519, acc: 77.34%] [G loss: 3.829433]\n",
      "epoch:26 step:20708 [D loss: 0.423638, acc: 75.00%] [G loss: 4.079238]\n",
      "epoch:26 step:20709 [D loss: 1.089990, acc: 16.41%] [G loss: 2.105802]\n",
      "epoch:26 step:20710 [D loss: 0.441811, acc: 78.91%] [G loss: 2.973366]\n",
      "epoch:26 step:20711 [D loss: 0.680374, acc: 60.16%] [G loss: 3.400896]\n",
      "epoch:26 step:20712 [D loss: 0.075799, acc: 100.00%] [G loss: 4.019292]\n",
      "epoch:26 step:20713 [D loss: 0.166003, acc: 100.00%] [G loss: 3.489815]\n",
      "epoch:26 step:20714 [D loss: 0.649608, acc: 60.16%] [G loss: 3.203822]\n",
      "epoch:26 step:20715 [D loss: 0.531371, acc: 74.22%] [G loss: 2.262032]\n",
      "epoch:26 step:20716 [D loss: 0.250430, acc: 93.75%] [G loss: 4.788228]\n",
      "epoch:26 step:20717 [D loss: 0.424424, acc: 82.03%] [G loss: 3.822224]\n",
      "epoch:26 step:20718 [D loss: 0.367963, acc: 79.69%] [G loss: 5.864581]\n",
      "epoch:26 step:20719 [D loss: 0.663035, acc: 63.28%] [G loss: 4.773259]\n",
      "epoch:26 step:20720 [D loss: 0.253288, acc: 99.22%] [G loss: 4.362348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20721 [D loss: 0.915036, acc: 45.31%] [G loss: 1.966765]\n",
      "epoch:26 step:20722 [D loss: 0.847788, acc: 48.44%] [G loss: 1.794392]\n",
      "epoch:26 step:20723 [D loss: 0.353149, acc: 93.75%] [G loss: 2.470702]\n",
      "epoch:26 step:20724 [D loss: 0.410187, acc: 83.59%] [G loss: 1.999062]\n",
      "epoch:26 step:20725 [D loss: 0.324545, acc: 93.75%] [G loss: 5.167818]\n",
      "epoch:26 step:20726 [D loss: 0.824556, acc: 37.50%] [G loss: 4.442165]\n",
      "epoch:26 step:20727 [D loss: 0.396097, acc: 86.72%] [G loss: 3.327743]\n",
      "epoch:26 step:20728 [D loss: 1.109959, acc: 48.44%] [G loss: 4.082453]\n",
      "epoch:26 step:20729 [D loss: 0.378020, acc: 83.59%] [G loss: 4.105868]\n",
      "epoch:26 step:20730 [D loss: 0.631562, acc: 60.16%] [G loss: 2.552266]\n",
      "epoch:26 step:20731 [D loss: 1.375957, acc: 21.88%] [G loss: 2.431641]\n",
      "epoch:26 step:20732 [D loss: 0.547441, acc: 63.28%] [G loss: 2.847559]\n",
      "epoch:26 step:20733 [D loss: 0.551497, acc: 57.03%] [G loss: 2.395866]\n",
      "epoch:26 step:20734 [D loss: 1.473270, acc: 32.81%] [G loss: 5.062675]\n",
      "epoch:26 step:20735 [D loss: 0.996990, acc: 50.00%] [G loss: 3.902441]\n",
      "epoch:26 step:20736 [D loss: 0.337820, acc: 92.97%] [G loss: 2.284567]\n",
      "epoch:26 step:20737 [D loss: 0.773856, acc: 49.22%] [G loss: 2.425814]\n",
      "epoch:26 step:20738 [D loss: 0.333360, acc: 88.28%] [G loss: 3.796267]\n",
      "epoch:26 step:20739 [D loss: 0.096476, acc: 100.00%] [G loss: 4.801353]\n",
      "epoch:26 step:20740 [D loss: 0.267280, acc: 95.31%] [G loss: 4.790762]\n",
      "epoch:26 step:20741 [D loss: 0.632306, acc: 64.84%] [G loss: 3.067961]\n",
      "epoch:26 step:20742 [D loss: 0.501104, acc: 64.06%] [G loss: 2.825060]\n",
      "epoch:26 step:20743 [D loss: 0.677311, acc: 59.38%] [G loss: 3.593583]\n",
      "epoch:26 step:20744 [D loss: 0.257876, acc: 95.31%] [G loss: 5.294451]\n",
      "epoch:26 step:20745 [D loss: 0.353396, acc: 90.62%] [G loss: 4.654143]\n",
      "epoch:26 step:20746 [D loss: 0.564251, acc: 69.53%] [G loss: 4.168664]\n",
      "epoch:26 step:20747 [D loss: 0.349024, acc: 80.47%] [G loss: 2.868837]\n",
      "epoch:26 step:20748 [D loss: 0.151567, acc: 100.00%] [G loss: 3.207580]\n",
      "epoch:26 step:20749 [D loss: 0.354263, acc: 90.62%] [G loss: 3.817288]\n",
      "epoch:26 step:20750 [D loss: 0.216066, acc: 97.66%] [G loss: 2.864823]\n",
      "epoch:26 step:20751 [D loss: 0.654609, acc: 59.38%] [G loss: 4.321217]\n",
      "epoch:26 step:20752 [D loss: 0.378315, acc: 76.56%] [G loss: 2.996000]\n",
      "epoch:26 step:20753 [D loss: 0.290028, acc: 90.62%] [G loss: 3.181083]\n",
      "epoch:26 step:20754 [D loss: 0.246248, acc: 92.97%] [G loss: 4.918316]\n",
      "epoch:26 step:20755 [D loss: 0.105558, acc: 99.22%] [G loss: 3.994869]\n",
      "epoch:26 step:20756 [D loss: 0.352781, acc: 84.38%] [G loss: 3.325392]\n",
      "epoch:26 step:20757 [D loss: 0.225840, acc: 99.22%] [G loss: 3.295747]\n",
      "epoch:26 step:20758 [D loss: 0.377012, acc: 92.19%] [G loss: 1.902493]\n",
      "epoch:26 step:20759 [D loss: 0.867287, acc: 53.12%] [G loss: 2.750794]\n",
      "epoch:26 step:20760 [D loss: 0.187946, acc: 97.66%] [G loss: 3.822105]\n",
      "epoch:26 step:20761 [D loss: 0.358545, acc: 79.69%] [G loss: 4.451198]\n",
      "epoch:26 step:20762 [D loss: 0.806159, acc: 49.22%] [G loss: 4.927027]\n",
      "epoch:26 step:20763 [D loss: 0.650617, acc: 59.38%] [G loss: 3.149362]\n",
      "epoch:26 step:20764 [D loss: 0.198898, acc: 98.44%] [G loss: 3.255821]\n",
      "epoch:26 step:20765 [D loss: 0.336051, acc: 94.53%] [G loss: 3.169307]\n",
      "epoch:26 step:20766 [D loss: 0.276329, acc: 99.22%] [G loss: 3.946890]\n",
      "epoch:26 step:20767 [D loss: 0.117478, acc: 100.00%] [G loss: 4.088993]\n",
      "epoch:26 step:20768 [D loss: 0.373891, acc: 89.84%] [G loss: 3.355817]\n",
      "epoch:26 step:20769 [D loss: 0.184153, acc: 100.00%] [G loss: 3.419213]\n",
      "epoch:26 step:20770 [D loss: 0.297915, acc: 92.19%] [G loss: 3.495062]\n",
      "epoch:26 step:20771 [D loss: 0.629690, acc: 60.94%] [G loss: 3.253169]\n",
      "epoch:26 step:20772 [D loss: 0.130902, acc: 100.00%] [G loss: 3.605404]\n",
      "epoch:26 step:20773 [D loss: 0.851324, acc: 48.44%] [G loss: 3.276000]\n",
      "epoch:26 step:20774 [D loss: 0.724654, acc: 58.59%] [G loss: 3.489897]\n",
      "epoch:26 step:20775 [D loss: 0.237375, acc: 97.66%] [G loss: 3.645535]\n",
      "epoch:26 step:20776 [D loss: 0.333721, acc: 91.41%] [G loss: 3.601898]\n",
      "epoch:26 step:20777 [D loss: 1.018463, acc: 36.72%] [G loss: 2.490476]\n",
      "epoch:26 step:20778 [D loss: 0.632498, acc: 65.62%] [G loss: 3.419151]\n",
      "epoch:26 step:20779 [D loss: 0.289639, acc: 94.53%] [G loss: 4.614850]\n",
      "epoch:26 step:20780 [D loss: 0.725481, acc: 50.78%] [G loss: 2.479470]\n",
      "epoch:26 step:20781 [D loss: 0.372049, acc: 89.84%] [G loss: 4.122566]\n",
      "epoch:26 step:20782 [D loss: 0.100636, acc: 100.00%] [G loss: 3.094241]\n",
      "epoch:26 step:20783 [D loss: 0.715089, acc: 53.91%] [G loss: 2.962114]\n",
      "epoch:26 step:20784 [D loss: 0.111803, acc: 99.22%] [G loss: 3.902926]\n",
      "epoch:26 step:20785 [D loss: 1.368073, acc: 24.22%] [G loss: 4.527134]\n",
      "epoch:26 step:20786 [D loss: 0.610687, acc: 64.84%] [G loss: 3.694696]\n",
      "epoch:26 step:20787 [D loss: 0.712973, acc: 52.34%] [G loss: 2.052539]\n",
      "epoch:26 step:20788 [D loss: 1.061564, acc: 29.69%] [G loss: 2.501485]\n",
      "epoch:26 step:20789 [D loss: 0.438923, acc: 88.28%] [G loss: 3.049752]\n",
      "epoch:26 step:20790 [D loss: 0.741001, acc: 48.44%] [G loss: 2.831066]\n",
      "epoch:26 step:20791 [D loss: 0.332660, acc: 94.53%] [G loss: 4.144449]\n",
      "epoch:26 step:20792 [D loss: 0.869762, acc: 37.50%] [G loss: 4.502083]\n",
      "epoch:26 step:20793 [D loss: 0.492114, acc: 70.31%] [G loss: 4.494220]\n",
      "epoch:26 step:20794 [D loss: 0.891482, acc: 49.22%] [G loss: 1.933330]\n",
      "epoch:26 step:20795 [D loss: 0.539975, acc: 73.44%] [G loss: 2.693015]\n",
      "epoch:26 step:20796 [D loss: 0.239489, acc: 99.22%] [G loss: 4.476099]\n",
      "epoch:26 step:20797 [D loss: 0.107010, acc: 100.00%] [G loss: 2.938191]\n",
      "epoch:26 step:20798 [D loss: 0.651491, acc: 59.38%] [G loss: 2.872965]\n",
      "epoch:26 step:20799 [D loss: 0.141553, acc: 100.00%] [G loss: 4.624140]\n",
      "epoch:26 step:20800 [D loss: 0.681164, acc: 62.50%] [G loss: 2.570018]\n",
      "epoch:26 step:20801 [D loss: 0.369352, acc: 94.53%] [G loss: 3.190096]\n",
      "epoch:26 step:20802 [D loss: 0.415285, acc: 89.06%] [G loss: 2.695157]\n",
      "epoch:26 step:20803 [D loss: 0.156591, acc: 99.22%] [G loss: 3.825854]\n",
      "epoch:26 step:20804 [D loss: 0.148066, acc: 100.00%] [G loss: 3.118873]\n",
      "epoch:26 step:20805 [D loss: 0.555586, acc: 74.22%] [G loss: 3.077136]\n",
      "epoch:26 step:20806 [D loss: 0.526835, acc: 78.12%] [G loss: 2.303004]\n",
      "epoch:26 step:20807 [D loss: 0.339901, acc: 94.53%] [G loss: 3.432822]\n",
      "epoch:26 step:20808 [D loss: 0.417560, acc: 67.97%] [G loss: 4.219395]\n",
      "epoch:26 step:20809 [D loss: 0.274637, acc: 98.44%] [G loss: 2.791124]\n",
      "epoch:26 step:20810 [D loss: 0.777034, acc: 51.56%] [G loss: 2.468024]\n",
      "epoch:26 step:20811 [D loss: 0.923895, acc: 50.00%] [G loss: 4.150432]\n",
      "epoch:26 step:20812 [D loss: 0.288445, acc: 97.66%] [G loss: 3.848367]\n",
      "epoch:26 step:20813 [D loss: 0.368966, acc: 93.75%] [G loss: 3.131477]\n",
      "epoch:26 step:20814 [D loss: 0.566022, acc: 69.53%] [G loss: 3.889846]\n",
      "epoch:26 step:20815 [D loss: 0.356026, acc: 81.25%] [G loss: 3.166421]\n",
      "epoch:26 step:20816 [D loss: 0.191056, acc: 97.66%] [G loss: 2.660927]\n",
      "epoch:26 step:20817 [D loss: 0.263518, acc: 92.97%] [G loss: 3.980138]\n",
      "epoch:26 step:20818 [D loss: 0.504188, acc: 73.44%] [G loss: 3.115169]\n",
      "epoch:26 step:20819 [D loss: 0.488225, acc: 82.81%] [G loss: 3.591865]\n",
      "epoch:26 step:20820 [D loss: 0.241391, acc: 100.00%] [G loss: 3.006879]\n",
      "epoch:26 step:20821 [D loss: 0.195902, acc: 98.44%] [G loss: 3.829350]\n",
      "epoch:26 step:20822 [D loss: 0.499686, acc: 74.22%] [G loss: 2.821038]\n",
      "epoch:26 step:20823 [D loss: 0.314630, acc: 92.97%] [G loss: 3.822025]\n",
      "epoch:26 step:20824 [D loss: 0.418994, acc: 89.06%] [G loss: 2.200591]\n",
      "epoch:26 step:20825 [D loss: 0.303640, acc: 89.84%] [G loss: 5.689244]\n",
      "epoch:26 step:20826 [D loss: 0.475000, acc: 79.69%] [G loss: 3.996131]\n",
      "epoch:26 step:20827 [D loss: 0.437412, acc: 80.47%] [G loss: 3.930278]\n",
      "epoch:26 step:20828 [D loss: 0.695560, acc: 56.25%] [G loss: 2.514226]\n",
      "epoch:26 step:20829 [D loss: 0.273256, acc: 95.31%] [G loss: 3.805625]\n",
      "epoch:26 step:20830 [D loss: 0.528897, acc: 62.50%] [G loss: 3.208200]\n",
      "epoch:26 step:20831 [D loss: 0.766968, acc: 44.53%] [G loss: 4.496827]\n",
      "epoch:26 step:20832 [D loss: 0.464204, acc: 73.44%] [G loss: 4.503184]\n",
      "epoch:26 step:20833 [D loss: 0.387187, acc: 80.47%] [G loss: 2.246174]\n",
      "epoch:26 step:20834 [D loss: 0.849823, acc: 42.19%] [G loss: 3.008573]\n",
      "epoch:26 step:20835 [D loss: 0.427043, acc: 86.72%] [G loss: 2.287395]\n",
      "epoch:26 step:20836 [D loss: 0.212150, acc: 98.44%] [G loss: 4.181530]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20837 [D loss: 0.685530, acc: 57.81%] [G loss: 3.682252]\n",
      "epoch:26 step:20838 [D loss: 0.593840, acc: 67.97%] [G loss: 3.641281]\n",
      "epoch:26 step:20839 [D loss: 0.673880, acc: 64.84%] [G loss: 2.436175]\n",
      "epoch:26 step:20840 [D loss: 0.163551, acc: 100.00%] [G loss: 3.388505]\n",
      "epoch:26 step:20841 [D loss: 0.691616, acc: 53.12%] [G loss: 2.328522]\n",
      "epoch:26 step:20842 [D loss: 0.127925, acc: 99.22%] [G loss: 2.105532]\n",
      "epoch:26 step:20843 [D loss: 0.429902, acc: 83.59%] [G loss: 2.809489]\n",
      "epoch:26 step:20844 [D loss: 0.146155, acc: 99.22%] [G loss: 4.661939]\n",
      "epoch:26 step:20845 [D loss: 0.550288, acc: 71.09%] [G loss: 3.246627]\n",
      "epoch:26 step:20846 [D loss: 0.691532, acc: 58.59%] [G loss: 3.666545]\n",
      "epoch:26 step:20847 [D loss: 0.393437, acc: 89.06%] [G loss: 3.187082]\n",
      "epoch:26 step:20848 [D loss: 0.172388, acc: 99.22%] [G loss: 2.695545]\n",
      "epoch:26 step:20849 [D loss: 0.409600, acc: 89.84%] [G loss: 2.728529]\n",
      "epoch:26 step:20850 [D loss: 0.617534, acc: 67.19%] [G loss: 2.560096]\n",
      "epoch:26 step:20851 [D loss: 0.295194, acc: 88.28%] [G loss: 5.624047]\n",
      "epoch:26 step:20852 [D loss: 0.204594, acc: 97.66%] [G loss: 3.927428]\n",
      "epoch:26 step:20853 [D loss: 0.614248, acc: 61.72%] [G loss: 5.107510]\n",
      "epoch:26 step:20854 [D loss: 0.695613, acc: 53.91%] [G loss: 3.709367]\n",
      "epoch:26 step:20855 [D loss: 0.461251, acc: 82.03%] [G loss: 3.129109]\n",
      "epoch:26 step:20856 [D loss: 0.170302, acc: 100.00%] [G loss: 4.281476]\n",
      "epoch:26 step:20857 [D loss: 0.429853, acc: 85.16%] [G loss: 4.198544]\n",
      "epoch:26 step:20858 [D loss: 0.301679, acc: 96.09%] [G loss: 4.447795]\n",
      "epoch:26 step:20859 [D loss: 0.895565, acc: 43.75%] [G loss: 2.461994]\n",
      "epoch:26 step:20860 [D loss: 0.253195, acc: 99.22%] [G loss: 3.146813]\n",
      "epoch:26 step:20861 [D loss: 0.304063, acc: 87.50%] [G loss: 2.969955]\n",
      "epoch:26 step:20862 [D loss: 0.459043, acc: 84.38%] [G loss: 4.155218]\n",
      "epoch:26 step:20863 [D loss: 0.365618, acc: 89.84%] [G loss: 2.049080]\n",
      "epoch:26 step:20864 [D loss: 0.564862, acc: 62.50%] [G loss: 4.345378]\n",
      "epoch:26 step:20865 [D loss: 0.625840, acc: 53.91%] [G loss: 4.272193]\n",
      "epoch:26 step:20866 [D loss: 0.158898, acc: 97.66%] [G loss: 3.644083]\n",
      "epoch:26 step:20867 [D loss: 0.460680, acc: 82.03%] [G loss: 3.358652]\n",
      "epoch:26 step:20868 [D loss: 0.424316, acc: 85.16%] [G loss: 4.566072]\n",
      "epoch:26 step:20869 [D loss: 0.334244, acc: 91.41%] [G loss: 2.829959]\n",
      "epoch:26 step:20870 [D loss: 0.830058, acc: 44.53%] [G loss: 3.649235]\n",
      "epoch:26 step:20871 [D loss: 0.496577, acc: 83.59%] [G loss: 5.021766]\n",
      "epoch:26 step:20872 [D loss: 0.428652, acc: 84.38%] [G loss: 2.881378]\n",
      "epoch:26 step:20873 [D loss: 0.576990, acc: 61.72%] [G loss: 3.083419]\n",
      "epoch:26 step:20874 [D loss: 0.539151, acc: 67.19%] [G loss: 4.082262]\n",
      "epoch:26 step:20875 [D loss: 0.237215, acc: 96.88%] [G loss: 3.875991]\n",
      "epoch:26 step:20876 [D loss: 0.527189, acc: 75.78%] [G loss: 3.661836]\n",
      "epoch:26 step:20877 [D loss: 0.430174, acc: 85.16%] [G loss: 3.171457]\n",
      "epoch:26 step:20878 [D loss: 0.257699, acc: 96.88%] [G loss: 4.147040]\n",
      "epoch:26 step:20879 [D loss: 1.148146, acc: 32.03%] [G loss: 2.302089]\n",
      "epoch:26 step:20880 [D loss: 0.830504, acc: 51.56%] [G loss: 4.237179]\n",
      "epoch:26 step:20881 [D loss: 0.671037, acc: 59.38%] [G loss: 1.831572]\n",
      "epoch:26 step:20882 [D loss: 0.157406, acc: 98.44%] [G loss: 3.771611]\n",
      "epoch:26 step:20883 [D loss: 0.699534, acc: 58.59%] [G loss: 2.459217]\n",
      "epoch:26 step:20884 [D loss: 0.522163, acc: 82.81%] [G loss: 4.265083]\n",
      "epoch:26 step:20885 [D loss: 0.269202, acc: 97.66%] [G loss: 3.207608]\n",
      "epoch:26 step:20886 [D loss: 0.661913, acc: 58.59%] [G loss: 2.325048]\n",
      "epoch:26 step:20887 [D loss: 0.167010, acc: 99.22%] [G loss: 4.556276]\n",
      "epoch:26 step:20888 [D loss: 0.340234, acc: 92.19%] [G loss: 4.973615]\n",
      "epoch:26 step:20889 [D loss: 0.531046, acc: 80.47%] [G loss: 3.216952]\n",
      "epoch:26 step:20890 [D loss: 1.025800, acc: 28.91%] [G loss: 3.586946]\n",
      "epoch:26 step:20891 [D loss: 0.277666, acc: 97.66%] [G loss: 2.731703]\n",
      "epoch:26 step:20892 [D loss: 0.484246, acc: 75.00%] [G loss: 4.606720]\n",
      "epoch:26 step:20893 [D loss: 0.325320, acc: 91.41%] [G loss: 2.797752]\n",
      "epoch:26 step:20894 [D loss: 0.301412, acc: 92.19%] [G loss: 4.927365]\n",
      "epoch:26 step:20895 [D loss: 0.412866, acc: 80.47%] [G loss: 3.771100]\n",
      "epoch:26 step:20896 [D loss: 0.269784, acc: 97.66%] [G loss: 2.767048]\n",
      "epoch:26 step:20897 [D loss: 1.001508, acc: 33.59%] [G loss: 3.322119]\n",
      "epoch:26 step:20898 [D loss: 0.194664, acc: 100.00%] [G loss: 3.375772]\n",
      "epoch:26 step:20899 [D loss: 0.562042, acc: 64.06%] [G loss: 4.099496]\n",
      "epoch:26 step:20900 [D loss: 0.874944, acc: 29.69%] [G loss: 4.221789]\n",
      "epoch:26 step:20901 [D loss: 0.239437, acc: 96.88%] [G loss: 4.167953]\n",
      "epoch:26 step:20902 [D loss: 0.580733, acc: 67.19%] [G loss: 2.897621]\n",
      "epoch:26 step:20903 [D loss: 0.128911, acc: 100.00%] [G loss: 3.473778]\n",
      "epoch:26 step:20904 [D loss: 0.236702, acc: 95.31%] [G loss: 3.775457]\n",
      "epoch:26 step:20905 [D loss: 1.458062, acc: 24.22%] [G loss: 2.652960]\n",
      "epoch:26 step:20906 [D loss: 0.874287, acc: 38.28%] [G loss: 2.688613]\n",
      "epoch:26 step:20907 [D loss: 0.638422, acc: 59.38%] [G loss: 2.944366]\n",
      "epoch:26 step:20908 [D loss: 0.276435, acc: 96.88%] [G loss: 2.130505]\n",
      "epoch:26 step:20909 [D loss: 0.401866, acc: 90.62%] [G loss: 1.963280]\n",
      "epoch:26 step:20910 [D loss: 0.341475, acc: 94.53%] [G loss: 3.920033]\n",
      "epoch:26 step:20911 [D loss: 0.320340, acc: 96.09%] [G loss: 3.481460]\n",
      "epoch:26 step:20912 [D loss: 0.408962, acc: 89.06%] [G loss: 3.457281]\n",
      "epoch:26 step:20913 [D loss: 0.310721, acc: 89.84%] [G loss: 2.550683]\n",
      "epoch:26 step:20914 [D loss: 0.906688, acc: 45.31%] [G loss: 2.132725]\n",
      "epoch:26 step:20915 [D loss: 0.489444, acc: 78.12%] [G loss: 4.230980]\n",
      "epoch:26 step:20916 [D loss: 0.855461, acc: 49.22%] [G loss: 3.780733]\n",
      "epoch:26 step:20917 [D loss: 0.576906, acc: 64.84%] [G loss: 3.001608]\n",
      "epoch:26 step:20918 [D loss: 0.617364, acc: 64.06%] [G loss: 2.631967]\n",
      "epoch:26 step:20919 [D loss: 0.622338, acc: 53.12%] [G loss: 4.338800]\n",
      "epoch:26 step:20920 [D loss: 0.133804, acc: 99.22%] [G loss: 3.797284]\n",
      "epoch:26 step:20921 [D loss: 0.517231, acc: 67.19%] [G loss: 2.313424]\n",
      "epoch:26 step:20922 [D loss: 0.422833, acc: 72.66%] [G loss: 3.056105]\n",
      "epoch:26 step:20923 [D loss: 0.351702, acc: 89.06%] [G loss: 3.114557]\n",
      "epoch:26 step:20924 [D loss: 0.244868, acc: 94.53%] [G loss: 2.904264]\n",
      "epoch:26 step:20925 [D loss: 0.484232, acc: 79.69%] [G loss: 2.520483]\n",
      "epoch:26 step:20926 [D loss: 0.701602, acc: 54.69%] [G loss: 3.955652]\n",
      "epoch:26 step:20927 [D loss: 0.374783, acc: 91.41%] [G loss: 2.297999]\n",
      "epoch:26 step:20928 [D loss: 0.267958, acc: 97.66%] [G loss: 1.760208]\n",
      "epoch:26 step:20929 [D loss: 0.123283, acc: 100.00%] [G loss: 2.430239]\n",
      "epoch:26 step:20930 [D loss: 0.376560, acc: 89.06%] [G loss: 3.022589]\n",
      "epoch:26 step:20931 [D loss: 0.106214, acc: 100.00%] [G loss: 3.672476]\n",
      "epoch:26 step:20932 [D loss: 0.489422, acc: 67.97%] [G loss: 3.239381]\n",
      "epoch:26 step:20933 [D loss: 0.385206, acc: 81.25%] [G loss: 4.284324]\n",
      "epoch:26 step:20934 [D loss: 0.273514, acc: 92.19%] [G loss: 4.311759]\n",
      "epoch:26 step:20935 [D loss: 0.502142, acc: 72.66%] [G loss: 2.833861]\n",
      "epoch:26 step:20936 [D loss: 0.221327, acc: 96.88%] [G loss: 3.817599]\n",
      "epoch:26 step:20937 [D loss: 0.578622, acc: 75.00%] [G loss: 3.187696]\n",
      "epoch:26 step:20938 [D loss: 0.606705, acc: 63.28%] [G loss: 2.378146]\n",
      "epoch:26 step:20939 [D loss: 0.303469, acc: 96.09%] [G loss: 2.339857]\n",
      "epoch:26 step:20940 [D loss: 0.241301, acc: 96.09%] [G loss: 3.379383]\n",
      "epoch:26 step:20941 [D loss: 0.571498, acc: 75.78%] [G loss: 3.487658]\n",
      "epoch:26 step:20942 [D loss: 0.410041, acc: 76.56%] [G loss: 3.444433]\n",
      "epoch:26 step:20943 [D loss: 0.387780, acc: 90.62%] [G loss: 2.241710]\n",
      "epoch:26 step:20944 [D loss: 0.340384, acc: 83.59%] [G loss: 3.339087]\n",
      "epoch:26 step:20945 [D loss: 1.052586, acc: 29.69%] [G loss: 3.496893]\n",
      "epoch:26 step:20946 [D loss: 0.267050, acc: 96.88%] [G loss: 3.971775]\n",
      "epoch:26 step:20947 [D loss: 0.199653, acc: 98.44%] [G loss: 2.414804]\n",
      "epoch:26 step:20948 [D loss: 0.349923, acc: 95.31%] [G loss: 3.697930]\n",
      "epoch:26 step:20949 [D loss: 0.232825, acc: 99.22%] [G loss: 2.041796]\n",
      "epoch:26 step:20950 [D loss: 0.096169, acc: 100.00%] [G loss: 5.584064]\n",
      "epoch:26 step:20951 [D loss: 0.406948, acc: 83.59%] [G loss: 3.618073]\n",
      "epoch:26 step:20952 [D loss: 0.539018, acc: 78.12%] [G loss: 2.519153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20953 [D loss: 0.550667, acc: 72.66%] [G loss: 3.293857]\n",
      "epoch:26 step:20954 [D loss: 0.116142, acc: 100.00%] [G loss: 4.653207]\n",
      "epoch:26 step:20955 [D loss: 0.420986, acc: 79.69%] [G loss: 3.918469]\n",
      "epoch:26 step:20956 [D loss: 0.163596, acc: 98.44%] [G loss: 4.149164]\n",
      "epoch:26 step:20957 [D loss: 0.623231, acc: 64.06%] [G loss: 2.855449]\n",
      "epoch:26 step:20958 [D loss: 0.664580, acc: 59.38%] [G loss: 3.235709]\n",
      "epoch:26 step:20959 [D loss: 0.239029, acc: 96.09%] [G loss: 3.256518]\n",
      "epoch:26 step:20960 [D loss: 0.260106, acc: 97.66%] [G loss: 2.116960]\n",
      "epoch:26 step:20961 [D loss: 0.108698, acc: 100.00%] [G loss: 4.467862]\n",
      "epoch:26 step:20962 [D loss: 0.357623, acc: 96.09%] [G loss: 4.034722]\n",
      "epoch:26 step:20963 [D loss: 0.206068, acc: 97.66%] [G loss: 1.895014]\n",
      "epoch:26 step:20964 [D loss: 0.368300, acc: 84.38%] [G loss: 3.922715]\n",
      "epoch:26 step:20965 [D loss: 0.103675, acc: 100.00%] [G loss: 2.394700]\n",
      "epoch:26 step:20966 [D loss: 1.002716, acc: 21.09%] [G loss: 3.238383]\n",
      "epoch:26 step:20967 [D loss: 0.851771, acc: 37.50%] [G loss: 3.244734]\n",
      "epoch:26 step:20968 [D loss: 0.919769, acc: 42.19%] [G loss: 1.596588]\n",
      "epoch:26 step:20969 [D loss: 0.378572, acc: 77.34%] [G loss: 4.433388]\n",
      "epoch:26 step:20970 [D loss: 0.537881, acc: 72.66%] [G loss: 4.209673]\n",
      "epoch:26 step:20971 [D loss: 0.264613, acc: 96.88%] [G loss: 1.275223]\n",
      "epoch:26 step:20972 [D loss: 0.556286, acc: 60.16%] [G loss: 2.858490]\n",
      "epoch:26 step:20973 [D loss: 0.182173, acc: 99.22%] [G loss: 4.157952]\n",
      "epoch:26 step:20974 [D loss: 0.292209, acc: 94.53%] [G loss: 3.026345]\n",
      "epoch:26 step:20975 [D loss: 1.081690, acc: 25.00%] [G loss: 3.935589]\n",
      "epoch:26 step:20976 [D loss: 0.458902, acc: 70.31%] [G loss: 2.486125]\n",
      "epoch:26 step:20977 [D loss: 0.404724, acc: 68.75%] [G loss: 4.485230]\n",
      "epoch:26 step:20978 [D loss: 0.380859, acc: 85.16%] [G loss: 2.560855]\n",
      "epoch:26 step:20979 [D loss: 0.174701, acc: 98.44%] [G loss: 4.351900]\n",
      "epoch:26 step:20980 [D loss: 0.105893, acc: 99.22%] [G loss: 3.386866]\n",
      "epoch:26 step:20981 [D loss: 0.102482, acc: 99.22%] [G loss: 5.400009]\n",
      "epoch:26 step:20982 [D loss: 0.277906, acc: 100.00%] [G loss: 3.907576]\n",
      "epoch:26 step:20983 [D loss: 0.500561, acc: 82.03%] [G loss: 3.934968]\n",
      "epoch:26 step:20984 [D loss: 0.251992, acc: 96.09%] [G loss: 4.759282]\n",
      "epoch:26 step:20985 [D loss: 0.881339, acc: 35.16%] [G loss: 3.620140]\n",
      "epoch:26 step:20986 [D loss: 0.245206, acc: 90.62%] [G loss: 6.270830]\n",
      "epoch:26 step:20987 [D loss: 0.130595, acc: 100.00%] [G loss: 5.060198]\n",
      "epoch:26 step:20988 [D loss: 0.828449, acc: 53.12%] [G loss: 4.706609]\n",
      "epoch:26 step:20989 [D loss: 0.318494, acc: 88.28%] [G loss: 2.941937]\n",
      "epoch:26 step:20990 [D loss: 0.853107, acc: 39.84%] [G loss: 3.275331]\n",
      "epoch:26 step:20991 [D loss: 0.332782, acc: 92.19%] [G loss: 1.926112]\n",
      "epoch:26 step:20992 [D loss: 1.080478, acc: 28.91%] [G loss: 3.803922]\n",
      "epoch:26 step:20993 [D loss: 0.304943, acc: 96.09%] [G loss: 1.654083]\n",
      "epoch:26 step:20994 [D loss: 0.743321, acc: 55.47%] [G loss: 2.476638]\n",
      "epoch:26 step:20995 [D loss: 0.684034, acc: 59.38%] [G loss: 1.990911]\n",
      "epoch:26 step:20996 [D loss: 0.679536, acc: 53.12%] [G loss: 3.536706]\n",
      "epoch:26 step:20997 [D loss: 0.105017, acc: 100.00%] [G loss: 5.006490]\n",
      "epoch:26 step:20998 [D loss: 0.886872, acc: 32.81%] [G loss: 5.415562]\n",
      "epoch:26 step:20999 [D loss: 0.405740, acc: 90.62%] [G loss: 3.787543]\n",
      "epoch:26 step:21000 [D loss: 1.111934, acc: 23.44%] [G loss: 2.680199]\n",
      "epoch:26 step:21001 [D loss: 0.417264, acc: 87.50%] [G loss: 2.738248]\n",
      "epoch:26 step:21002 [D loss: 0.892005, acc: 50.00%] [G loss: 4.220078]\n",
      "epoch:26 step:21003 [D loss: 0.691728, acc: 61.72%] [G loss: 3.315689]\n",
      "epoch:26 step:21004 [D loss: 0.533060, acc: 67.97%] [G loss: 2.810843]\n",
      "epoch:26 step:21005 [D loss: 0.575029, acc: 67.19%] [G loss: 2.526971]\n",
      "epoch:26 step:21006 [D loss: 0.563502, acc: 63.28%] [G loss: 3.262649]\n",
      "epoch:26 step:21007 [D loss: 0.401487, acc: 92.19%] [G loss: 2.184784]\n",
      "epoch:26 step:21008 [D loss: 0.930721, acc: 50.00%] [G loss: 3.484226]\n",
      "epoch:26 step:21009 [D loss: 0.436191, acc: 84.38%] [G loss: 4.347243]\n",
      "epoch:26 step:21010 [D loss: 0.480671, acc: 71.88%] [G loss: 3.030851]\n",
      "epoch:26 step:21011 [D loss: 0.289472, acc: 92.97%] [G loss: 4.611798]\n",
      "epoch:26 step:21012 [D loss: 0.237046, acc: 99.22%] [G loss: 4.827774]\n",
      "epoch:26 step:21013 [D loss: 0.222680, acc: 96.88%] [G loss: 3.418077]\n",
      "epoch:26 step:21014 [D loss: 0.156010, acc: 100.00%] [G loss: 6.020803]\n",
      "epoch:26 step:21015 [D loss: 0.727699, acc: 52.34%] [G loss: 2.409426]\n",
      "epoch:26 step:21016 [D loss: 1.196162, acc: 35.16%] [G loss: 2.901888]\n",
      "epoch:26 step:21017 [D loss: 0.253314, acc: 95.31%] [G loss: 3.742720]\n",
      "epoch:26 step:21018 [D loss: 0.485146, acc: 71.09%] [G loss: 3.327258]\n",
      "epoch:26 step:21019 [D loss: 0.129375, acc: 100.00%] [G loss: 3.996249]\n",
      "epoch:26 step:21020 [D loss: 0.346781, acc: 92.97%] [G loss: 3.438635]\n",
      "epoch:26 step:21021 [D loss: 0.260427, acc: 97.66%] [G loss: 3.960714]\n",
      "epoch:26 step:21022 [D loss: 0.319101, acc: 85.94%] [G loss: 2.761286]\n",
      "epoch:26 step:21023 [D loss: 0.451910, acc: 75.00%] [G loss: 2.975851]\n",
      "epoch:26 step:21024 [D loss: 0.662921, acc: 62.50%] [G loss: 4.254818]\n",
      "epoch:26 step:21025 [D loss: 0.704887, acc: 55.47%] [G loss: 4.010202]\n",
      "epoch:26 step:21026 [D loss: 0.505157, acc: 76.56%] [G loss: 3.648582]\n",
      "epoch:26 step:21027 [D loss: 0.240337, acc: 96.09%] [G loss: 3.956210]\n",
      "epoch:26 step:21028 [D loss: 0.350940, acc: 90.62%] [G loss: 2.721993]\n",
      "epoch:26 step:21029 [D loss: 0.688402, acc: 53.12%] [G loss: 3.140336]\n",
      "epoch:26 step:21030 [D loss: 0.342881, acc: 92.19%] [G loss: 3.806328]\n",
      "epoch:26 step:21031 [D loss: 0.218707, acc: 98.44%] [G loss: 2.538427]\n",
      "epoch:26 step:21032 [D loss: 0.656236, acc: 57.81%] [G loss: 2.673588]\n",
      "epoch:26 step:21033 [D loss: 0.181813, acc: 100.00%] [G loss: 2.212110]\n",
      "epoch:26 step:21034 [D loss: 0.492196, acc: 67.97%] [G loss: 4.369854]\n",
      "epoch:26 step:21035 [D loss: 0.453493, acc: 81.25%] [G loss: 3.365505]\n",
      "epoch:26 step:21036 [D loss: 0.450754, acc: 75.00%] [G loss: 4.536661]\n",
      "epoch:26 step:21037 [D loss: 0.585744, acc: 66.41%] [G loss: 2.824694]\n",
      "epoch:26 step:21038 [D loss: 0.229400, acc: 99.22%] [G loss: 3.815950]\n",
      "epoch:26 step:21039 [D loss: 0.512123, acc: 80.47%] [G loss: 3.319542]\n",
      "epoch:26 step:21040 [D loss: 0.650435, acc: 63.28%] [G loss: 3.476892]\n",
      "epoch:26 step:21041 [D loss: 0.625536, acc: 69.53%] [G loss: 3.777056]\n",
      "epoch:26 step:21042 [D loss: 0.609574, acc: 63.28%] [G loss: 3.730926]\n",
      "epoch:26 step:21043 [D loss: 0.409317, acc: 92.19%] [G loss: 3.291142]\n",
      "epoch:26 step:21044 [D loss: 0.497369, acc: 67.19%] [G loss: 3.980704]\n",
      "epoch:26 step:21045 [D loss: 0.354123, acc: 92.97%] [G loss: 3.117933]\n",
      "epoch:26 step:21046 [D loss: 0.202432, acc: 97.66%] [G loss: 2.573887]\n",
      "epoch:26 step:21047 [D loss: 0.899519, acc: 50.00%] [G loss: 4.112933]\n",
      "epoch:26 step:21048 [D loss: 0.398645, acc: 83.59%] [G loss: 3.227908]\n",
      "epoch:26 step:21049 [D loss: 0.371448, acc: 92.19%] [G loss: 3.266389]\n",
      "epoch:26 step:21050 [D loss: 0.627042, acc: 60.16%] [G loss: 2.773432]\n",
      "epoch:26 step:21051 [D loss: 0.072449, acc: 100.00%] [G loss: 3.658995]\n",
      "epoch:26 step:21052 [D loss: 0.683981, acc: 56.25%] [G loss: 2.882470]\n",
      "epoch:26 step:21053 [D loss: 0.189059, acc: 97.66%] [G loss: 2.683869]\n",
      "epoch:26 step:21054 [D loss: 0.348929, acc: 92.19%] [G loss: 2.533527]\n",
      "epoch:26 step:21055 [D loss: 0.569994, acc: 70.31%] [G loss: 3.228136]\n",
      "epoch:26 step:21056 [D loss: 0.758663, acc: 53.12%] [G loss: 2.672442]\n",
      "epoch:26 step:21057 [D loss: 0.626042, acc: 57.03%] [G loss: 3.372397]\n",
      "epoch:26 step:21058 [D loss: 0.065976, acc: 100.00%] [G loss: 5.545819]\n",
      "epoch:26 step:21059 [D loss: 0.203184, acc: 98.44%] [G loss: 3.665076]\n",
      "epoch:26 step:21060 [D loss: 0.345558, acc: 92.97%] [G loss: 2.715451]\n",
      "epoch:26 step:21061 [D loss: 0.499086, acc: 71.09%] [G loss: 3.184335]\n",
      "epoch:26 step:21062 [D loss: 0.331045, acc: 89.84%] [G loss: 3.431702]\n",
      "epoch:26 step:21063 [D loss: 0.557318, acc: 71.88%] [G loss: 3.227790]\n",
      "epoch:26 step:21064 [D loss: 0.986381, acc: 29.69%] [G loss: 2.271412]\n",
      "epoch:26 step:21065 [D loss: 0.675922, acc: 57.81%] [G loss: 2.526489]\n",
      "epoch:26 step:21066 [D loss: 0.127125, acc: 100.00%] [G loss: 4.842772]\n",
      "epoch:26 step:21067 [D loss: 0.791925, acc: 53.91%] [G loss: 4.993465]\n",
      "epoch:26 step:21068 [D loss: 1.056316, acc: 48.44%] [G loss: 3.423822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:21069 [D loss: 0.573480, acc: 74.22%] [G loss: 2.431332]\n",
      "epoch:26 step:21070 [D loss: 0.719663, acc: 60.16%] [G loss: 2.724291]\n",
      "epoch:26 step:21071 [D loss: 0.122135, acc: 98.44%] [G loss: 5.303907]\n",
      "epoch:26 step:21072 [D loss: 0.183635, acc: 97.66%] [G loss: 2.878355]\n",
      "epoch:26 step:21073 [D loss: 0.249768, acc: 95.31%] [G loss: 3.357939]\n",
      "epoch:26 step:21074 [D loss: 0.122260, acc: 100.00%] [G loss: 3.541719]\n",
      "epoch:26 step:21075 [D loss: 0.520601, acc: 80.47%] [G loss: 2.461477]\n",
      "epoch:26 step:21076 [D loss: 0.956968, acc: 35.16%] [G loss: 2.693799]\n",
      "epoch:26 step:21077 [D loss: 0.647773, acc: 62.50%] [G loss: 3.292405]\n",
      "epoch:26 step:21078 [D loss: 0.344235, acc: 85.94%] [G loss: 3.439496]\n",
      "epoch:26 step:21079 [D loss: 0.192259, acc: 96.09%] [G loss: 6.996727]\n",
      "epoch:26 step:21080 [D loss: 0.851282, acc: 52.34%] [G loss: 4.541552]\n",
      "epoch:26 step:21081 [D loss: 0.298969, acc: 89.06%] [G loss: 2.476625]\n",
      "epoch:26 step:21082 [D loss: 0.782846, acc: 53.91%] [G loss: 1.831486]\n",
      "epoch:26 step:21083 [D loss: 0.680135, acc: 58.59%] [G loss: 4.171360]\n",
      "epoch:26 step:21084 [D loss: 0.153337, acc: 99.22%] [G loss: 2.994976]\n",
      "epoch:26 step:21085 [D loss: 0.915044, acc: 35.94%] [G loss: 3.499825]\n",
      "epoch:26 step:21086 [D loss: 0.574590, acc: 75.78%] [G loss: 1.444679]\n",
      "epoch:26 step:21087 [D loss: 0.377414, acc: 92.19%] [G loss: 3.015147]\n",
      "epoch:27 step:21088 [D loss: 0.196186, acc: 98.44%] [G loss: 2.458455]\n",
      "epoch:27 step:21089 [D loss: 0.439398, acc: 80.47%] [G loss: 4.243351]\n",
      "epoch:27 step:21090 [D loss: 0.361078, acc: 92.19%] [G loss: 4.639673]\n",
      "epoch:27 step:21091 [D loss: 0.805758, acc: 53.12%] [G loss: 3.300364]\n",
      "epoch:27 step:21092 [D loss: 0.249335, acc: 96.88%] [G loss: 3.036197]\n",
      "epoch:27 step:21093 [D loss: 0.391669, acc: 89.06%] [G loss: 3.112574]\n",
      "epoch:27 step:21094 [D loss: 0.804209, acc: 48.44%] [G loss: 2.325130]\n",
      "epoch:27 step:21095 [D loss: 0.747865, acc: 54.69%] [G loss: 2.736414]\n",
      "epoch:27 step:21096 [D loss: 0.467548, acc: 79.69%] [G loss: 4.664070]\n",
      "epoch:27 step:21097 [D loss: 1.371628, acc: 49.22%] [G loss: 2.204635]\n",
      "epoch:27 step:21098 [D loss: 0.414581, acc: 82.81%] [G loss: 3.249959]\n",
      "epoch:27 step:21099 [D loss: 0.383032, acc: 91.41%] [G loss: 4.128138]\n",
      "epoch:27 step:21100 [D loss: 0.319192, acc: 95.31%] [G loss: 3.471898]\n",
      "epoch:27 step:21101 [D loss: 0.344349, acc: 91.41%] [G loss: 2.178092]\n",
      "epoch:27 step:21102 [D loss: 0.379928, acc: 88.28%] [G loss: 2.733519]\n",
      "epoch:27 step:21103 [D loss: 0.613172, acc: 60.94%] [G loss: 4.130334]\n",
      "epoch:27 step:21104 [D loss: 0.646471, acc: 61.72%] [G loss: 4.461516]\n",
      "epoch:27 step:21105 [D loss: 0.321122, acc: 84.38%] [G loss: 3.701828]\n",
      "epoch:27 step:21106 [D loss: 1.171300, acc: 28.91%] [G loss: 2.029487]\n",
      "epoch:27 step:21107 [D loss: 0.318176, acc: 94.53%] [G loss: 3.065996]\n",
      "epoch:27 step:21108 [D loss: 0.119525, acc: 99.22%] [G loss: 3.793040]\n",
      "epoch:27 step:21109 [D loss: 0.351551, acc: 92.97%] [G loss: 3.749244]\n",
      "epoch:27 step:21110 [D loss: 0.177304, acc: 99.22%] [G loss: 3.783825]\n",
      "epoch:27 step:21111 [D loss: 0.414920, acc: 89.84%] [G loss: 2.218292]\n",
      "epoch:27 step:21112 [D loss: 0.442378, acc: 78.91%] [G loss: 3.758430]\n",
      "epoch:27 step:21113 [D loss: 0.261543, acc: 96.09%] [G loss: 4.334427]\n",
      "epoch:27 step:21114 [D loss: 0.491232, acc: 65.62%] [G loss: 3.865756]\n",
      "epoch:27 step:21115 [D loss: 1.009461, acc: 23.44%] [G loss: 2.314004]\n",
      "epoch:27 step:21116 [D loss: 0.443106, acc: 75.00%] [G loss: 4.652760]\n",
      "epoch:27 step:21117 [D loss: 0.272990, acc: 97.66%] [G loss: 2.820112]\n",
      "epoch:27 step:21118 [D loss: 0.539134, acc: 69.53%] [G loss: 4.528238]\n",
      "epoch:27 step:21119 [D loss: 0.931212, acc: 50.78%] [G loss: 3.127612]\n",
      "epoch:27 step:21120 [D loss: 0.498915, acc: 80.47%] [G loss: 3.944109]\n",
      "epoch:27 step:21121 [D loss: 0.413117, acc: 83.59%] [G loss: 4.032144]\n",
      "epoch:27 step:21122 [D loss: 0.863463, acc: 42.97%] [G loss: 2.318232]\n",
      "epoch:27 step:21123 [D loss: 0.439034, acc: 73.44%] [G loss: 3.983421]\n",
      "epoch:27 step:21124 [D loss: 0.408039, acc: 89.06%] [G loss: 2.836529]\n",
      "epoch:27 step:21125 [D loss: 0.733600, acc: 57.81%] [G loss: 3.889030]\n",
      "epoch:27 step:21126 [D loss: 0.232063, acc: 99.22%] [G loss: 3.493250]\n",
      "epoch:27 step:21127 [D loss: 0.454831, acc: 72.66%] [G loss: 3.644531]\n",
      "epoch:27 step:21128 [D loss: 0.308083, acc: 85.94%] [G loss: 2.944752]\n",
      "epoch:27 step:21129 [D loss: 0.318181, acc: 90.62%] [G loss: 3.455345]\n",
      "epoch:27 step:21130 [D loss: 0.562816, acc: 67.97%] [G loss: 2.596675]\n",
      "epoch:27 step:21131 [D loss: 0.818532, acc: 49.22%] [G loss: 3.130724]\n",
      "epoch:27 step:21132 [D loss: 0.284246, acc: 91.41%] [G loss: 2.451556]\n",
      "epoch:27 step:21133 [D loss: 0.846315, acc: 42.19%] [G loss: 3.131496]\n",
      "epoch:27 step:21134 [D loss: 0.269959, acc: 98.44%] [G loss: 3.056382]\n",
      "epoch:27 step:21135 [D loss: 0.616401, acc: 62.50%] [G loss: 1.824751]\n",
      "epoch:27 step:21136 [D loss: 0.844698, acc: 41.41%] [G loss: 2.769791]\n",
      "epoch:27 step:21137 [D loss: 0.625773, acc: 66.41%] [G loss: 3.422276]\n",
      "epoch:27 step:21138 [D loss: 0.995122, acc: 35.94%] [G loss: 3.737961]\n",
      "epoch:27 step:21139 [D loss: 0.296106, acc: 96.88%] [G loss: 2.762962]\n",
      "epoch:27 step:21140 [D loss: 0.544821, acc: 72.66%] [G loss: 4.011058]\n",
      "epoch:27 step:21141 [D loss: 0.593387, acc: 73.44%] [G loss: 3.100139]\n",
      "epoch:27 step:21142 [D loss: 0.311194, acc: 95.31%] [G loss: 3.550357]\n",
      "epoch:27 step:21143 [D loss: 0.400561, acc: 85.16%] [G loss: 3.898914]\n",
      "epoch:27 step:21144 [D loss: 0.559345, acc: 72.66%] [G loss: 3.039861]\n",
      "epoch:27 step:21145 [D loss: 0.513008, acc: 75.00%] [G loss: 1.643606]\n",
      "epoch:27 step:21146 [D loss: 0.738251, acc: 56.25%] [G loss: 3.154920]\n",
      "epoch:27 step:21147 [D loss: 0.162267, acc: 99.22%] [G loss: 3.696973]\n",
      "epoch:27 step:21148 [D loss: 0.710445, acc: 52.34%] [G loss: 2.985768]\n",
      "epoch:27 step:21149 [D loss: 0.532600, acc: 62.50%] [G loss: 3.056946]\n",
      "epoch:27 step:21150 [D loss: 0.455605, acc: 64.84%] [G loss: 5.768585]\n",
      "epoch:27 step:21151 [D loss: 0.304279, acc: 95.31%] [G loss: 3.531673]\n",
      "epoch:27 step:21152 [D loss: 0.515179, acc: 75.78%] [G loss: 4.926859]\n",
      "epoch:27 step:21153 [D loss: 0.770682, acc: 42.97%] [G loss: 2.751755]\n",
      "epoch:27 step:21154 [D loss: 0.426530, acc: 69.53%] [G loss: 3.402459]\n",
      "epoch:27 step:21155 [D loss: 0.905871, acc: 34.38%] [G loss: 3.043430]\n",
      "epoch:27 step:21156 [D loss: 0.624591, acc: 63.28%] [G loss: 1.645578]\n",
      "epoch:27 step:21157 [D loss: 0.434047, acc: 92.97%] [G loss: 3.779639]\n",
      "epoch:27 step:21158 [D loss: 0.540303, acc: 77.34%] [G loss: 4.071323]\n",
      "epoch:27 step:21159 [D loss: 0.503739, acc: 80.47%] [G loss: 4.456468]\n",
      "epoch:27 step:21160 [D loss: 0.363295, acc: 89.06%] [G loss: 2.698907]\n",
      "epoch:27 step:21161 [D loss: 1.230862, acc: 12.50%] [G loss: 4.127250]\n",
      "epoch:27 step:21162 [D loss: 0.295115, acc: 91.41%] [G loss: 3.595954]\n",
      "epoch:27 step:21163 [D loss: 0.305516, acc: 93.75%] [G loss: 3.441785]\n",
      "epoch:27 step:21164 [D loss: 0.809170, acc: 39.06%] [G loss: 2.533185]\n",
      "epoch:27 step:21165 [D loss: 0.845967, acc: 41.41%] [G loss: 3.461705]\n",
      "epoch:27 step:21166 [D loss: 0.497890, acc: 69.53%] [G loss: 5.183194]\n",
      "epoch:27 step:21167 [D loss: 0.633582, acc: 57.81%] [G loss: 3.978084]\n",
      "epoch:27 step:21168 [D loss: 0.411653, acc: 83.59%] [G loss: 5.083579]\n",
      "epoch:27 step:21169 [D loss: 0.481705, acc: 82.03%] [G loss: 3.971559]\n",
      "epoch:27 step:21170 [D loss: 0.214992, acc: 97.66%] [G loss: 3.288721]\n",
      "epoch:27 step:21171 [D loss: 0.207800, acc: 98.44%] [G loss: 2.873758]\n",
      "epoch:27 step:21172 [D loss: 0.237227, acc: 97.66%] [G loss: 2.640632]\n",
      "epoch:27 step:21173 [D loss: 0.846071, acc: 35.94%] [G loss: 2.236984]\n",
      "epoch:27 step:21174 [D loss: 0.400264, acc: 92.19%] [G loss: 1.803652]\n",
      "epoch:27 step:21175 [D loss: 0.331455, acc: 82.81%] [G loss: 3.507843]\n",
      "epoch:27 step:21176 [D loss: 0.394060, acc: 76.56%] [G loss: 4.426376]\n",
      "epoch:27 step:21177 [D loss: 0.150233, acc: 99.22%] [G loss: 2.304431]\n",
      "epoch:27 step:21178 [D loss: 0.278376, acc: 96.09%] [G loss: 4.668236]\n",
      "epoch:27 step:21179 [D loss: 0.425943, acc: 87.50%] [G loss: 4.293994]\n",
      "epoch:27 step:21180 [D loss: 0.185600, acc: 100.00%] [G loss: 3.603305]\n",
      "epoch:27 step:21181 [D loss: 0.430200, acc: 83.59%] [G loss: 4.433585]\n",
      "epoch:27 step:21182 [D loss: 0.782776, acc: 52.34%] [G loss: 3.906878]\n",
      "epoch:27 step:21183 [D loss: 0.429819, acc: 88.28%] [G loss: 2.307910]\n",
      "epoch:27 step:21184 [D loss: 0.565259, acc: 71.88%] [G loss: 3.669733]\n",
      "epoch:27 step:21185 [D loss: 0.102198, acc: 100.00%] [G loss: 2.755075]\n",
      "epoch:27 step:21186 [D loss: 0.124347, acc: 99.22%] [G loss: 5.243401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21187 [D loss: 0.212288, acc: 98.44%] [G loss: 3.889455]\n",
      "epoch:27 step:21188 [D loss: 0.428034, acc: 85.94%] [G loss: 2.402813]\n",
      "epoch:27 step:21189 [D loss: 0.584998, acc: 67.19%] [G loss: 4.090872]\n",
      "epoch:27 step:21190 [D loss: 0.862792, acc: 40.62%] [G loss: 3.393766]\n",
      "epoch:27 step:21191 [D loss: 0.113749, acc: 100.00%] [G loss: 4.856019]\n",
      "epoch:27 step:21192 [D loss: 0.590207, acc: 69.53%] [G loss: 3.026654]\n",
      "epoch:27 step:21193 [D loss: 0.401041, acc: 87.50%] [G loss: 4.035186]\n",
      "epoch:27 step:21194 [D loss: 0.641934, acc: 62.50%] [G loss: 3.519693]\n",
      "epoch:27 step:21195 [D loss: 0.324899, acc: 92.19%] [G loss: 3.310213]\n",
      "epoch:27 step:21196 [D loss: 0.310972, acc: 93.75%] [G loss: 2.698375]\n",
      "epoch:27 step:21197 [D loss: 0.152602, acc: 100.00%] [G loss: 3.887249]\n",
      "epoch:27 step:21198 [D loss: 0.585990, acc: 59.38%] [G loss: 3.429961]\n",
      "epoch:27 step:21199 [D loss: 0.414400, acc: 83.59%] [G loss: 3.526161]\n",
      "epoch:27 step:21200 [D loss: 0.176455, acc: 98.44%] [G loss: 4.289856]\n",
      "epoch:27 step:21201 [D loss: 0.628883, acc: 57.03%] [G loss: 2.142540]\n",
      "epoch:27 step:21202 [D loss: 0.786805, acc: 49.22%] [G loss: 3.387684]\n",
      "epoch:27 step:21203 [D loss: 0.234541, acc: 100.00%] [G loss: 3.912918]\n",
      "epoch:27 step:21204 [D loss: 0.465276, acc: 82.81%] [G loss: 3.860725]\n",
      "epoch:27 step:21205 [D loss: 0.371448, acc: 89.84%] [G loss: 3.229381]\n",
      "epoch:27 step:21206 [D loss: 0.356950, acc: 91.41%] [G loss: 3.495676]\n",
      "epoch:27 step:21207 [D loss: 0.176278, acc: 100.00%] [G loss: 3.675401]\n",
      "epoch:27 step:21208 [D loss: 1.160679, acc: 9.38%] [G loss: 3.744480]\n",
      "epoch:27 step:21209 [D loss: 0.472612, acc: 79.69%] [G loss: 3.941046]\n",
      "epoch:27 step:21210 [D loss: 0.179225, acc: 97.66%] [G loss: 3.465523]\n",
      "epoch:27 step:21211 [D loss: 0.205409, acc: 97.66%] [G loss: 5.462069]\n",
      "epoch:27 step:21212 [D loss: 0.334277, acc: 93.75%] [G loss: 3.779838]\n",
      "epoch:27 step:21213 [D loss: 0.128229, acc: 100.00%] [G loss: 2.654503]\n",
      "epoch:27 step:21214 [D loss: 0.428116, acc: 88.28%] [G loss: 3.408266]\n",
      "epoch:27 step:21215 [D loss: 0.390819, acc: 86.72%] [G loss: 3.445488]\n",
      "epoch:27 step:21216 [D loss: 0.136948, acc: 99.22%] [G loss: 2.731213]\n",
      "epoch:27 step:21217 [D loss: 0.409175, acc: 83.59%] [G loss: 3.089212]\n",
      "epoch:27 step:21218 [D loss: 0.342198, acc: 94.53%] [G loss: 2.182656]\n",
      "epoch:27 step:21219 [D loss: 0.762180, acc: 53.12%] [G loss: 2.977705]\n",
      "epoch:27 step:21220 [D loss: 0.198492, acc: 98.44%] [G loss: 2.834392]\n",
      "epoch:27 step:21221 [D loss: 0.673011, acc: 55.47%] [G loss: 3.199659]\n",
      "epoch:27 step:21222 [D loss: 0.703555, acc: 53.12%] [G loss: 3.762866]\n",
      "epoch:27 step:21223 [D loss: 0.773333, acc: 51.56%] [G loss: 5.328061]\n",
      "epoch:27 step:21224 [D loss: 0.386871, acc: 92.97%] [G loss: 2.224043]\n",
      "epoch:27 step:21225 [D loss: 0.580541, acc: 70.31%] [G loss: 3.756133]\n",
      "epoch:27 step:21226 [D loss: 0.423048, acc: 71.09%] [G loss: 3.761929]\n",
      "epoch:27 step:21227 [D loss: 0.526771, acc: 66.41%] [G loss: 3.055383]\n",
      "epoch:27 step:21228 [D loss: 0.323870, acc: 96.09%] [G loss: 3.986161]\n",
      "epoch:27 step:21229 [D loss: 0.291865, acc: 97.66%] [G loss: 4.210219]\n",
      "epoch:27 step:21230 [D loss: 0.418129, acc: 84.38%] [G loss: 3.536230]\n",
      "epoch:27 step:21231 [D loss: 0.318584, acc: 89.84%] [G loss: 2.251162]\n",
      "epoch:27 step:21232 [D loss: 1.378117, acc: 7.03%] [G loss: 4.718770]\n",
      "epoch:27 step:21233 [D loss: 0.282185, acc: 99.22%] [G loss: 4.467944]\n",
      "epoch:27 step:21234 [D loss: 0.669668, acc: 55.47%] [G loss: 3.458477]\n",
      "epoch:27 step:21235 [D loss: 0.371735, acc: 89.84%] [G loss: 4.414582]\n",
      "epoch:27 step:21236 [D loss: 0.976646, acc: 38.28%] [G loss: 3.340444]\n",
      "epoch:27 step:21237 [D loss: 0.159255, acc: 100.00%] [G loss: 3.516172]\n",
      "epoch:27 step:21238 [D loss: 0.627557, acc: 62.50%] [G loss: 3.568868]\n",
      "epoch:27 step:21239 [D loss: 0.670481, acc: 57.81%] [G loss: 4.183290]\n",
      "epoch:27 step:21240 [D loss: 0.570149, acc: 64.06%] [G loss: 3.317690]\n",
      "epoch:27 step:21241 [D loss: 0.166809, acc: 98.44%] [G loss: 2.571035]\n",
      "epoch:27 step:21242 [D loss: 0.436794, acc: 87.50%] [G loss: 4.687184]\n",
      "epoch:27 step:21243 [D loss: 0.273924, acc: 89.84%] [G loss: 3.690172]\n",
      "epoch:27 step:21244 [D loss: 0.337771, acc: 95.31%] [G loss: 2.892138]\n",
      "epoch:27 step:21245 [D loss: 0.439943, acc: 72.66%] [G loss: 1.988020]\n",
      "epoch:27 step:21246 [D loss: 0.202060, acc: 97.66%] [G loss: 5.104834]\n",
      "epoch:27 step:21247 [D loss: 0.188385, acc: 99.22%] [G loss: 3.520630]\n",
      "epoch:27 step:21248 [D loss: 0.796378, acc: 44.53%] [G loss: 3.090002]\n",
      "epoch:27 step:21249 [D loss: 0.246950, acc: 99.22%] [G loss: 5.320768]\n",
      "epoch:27 step:21250 [D loss: 0.591768, acc: 71.09%] [G loss: 2.528973]\n",
      "epoch:27 step:21251 [D loss: 0.514652, acc: 65.62%] [G loss: 2.887294]\n",
      "epoch:27 step:21252 [D loss: 0.487277, acc: 82.03%] [G loss: 4.255543]\n",
      "epoch:27 step:21253 [D loss: 0.335898, acc: 85.16%] [G loss: 4.736494]\n",
      "epoch:27 step:21254 [D loss: 0.420910, acc: 75.00%] [G loss: 3.250904]\n",
      "epoch:27 step:21255 [D loss: 0.234363, acc: 97.66%] [G loss: 4.061806]\n",
      "epoch:27 step:21256 [D loss: 0.429222, acc: 75.00%] [G loss: 2.468328]\n",
      "epoch:27 step:21257 [D loss: 0.254302, acc: 95.31%] [G loss: 5.158968]\n",
      "epoch:27 step:21258 [D loss: 0.382789, acc: 89.84%] [G loss: 1.955968]\n",
      "epoch:27 step:21259 [D loss: 1.343714, acc: 8.59%] [G loss: 4.394640]\n",
      "epoch:27 step:21260 [D loss: 0.563586, acc: 68.75%] [G loss: 2.164693]\n",
      "epoch:27 step:21261 [D loss: 0.117751, acc: 100.00%] [G loss: 2.922701]\n",
      "epoch:27 step:21262 [D loss: 0.461032, acc: 82.03%] [G loss: 4.052686]\n",
      "epoch:27 step:21263 [D loss: 0.799214, acc: 48.44%] [G loss: 2.732328]\n",
      "epoch:27 step:21264 [D loss: 0.434570, acc: 87.50%] [G loss: 2.762367]\n",
      "epoch:27 step:21265 [D loss: 0.259350, acc: 99.22%] [G loss: 3.770860]\n",
      "epoch:27 step:21266 [D loss: 0.330604, acc: 96.09%] [G loss: 5.469913]\n",
      "epoch:27 step:21267 [D loss: 0.819227, acc: 43.75%] [G loss: 1.669293]\n",
      "epoch:27 step:21268 [D loss: 0.474664, acc: 75.78%] [G loss: 4.014980]\n",
      "epoch:27 step:21269 [D loss: 0.321162, acc: 90.62%] [G loss: 3.511797]\n",
      "epoch:27 step:21270 [D loss: 0.915326, acc: 50.00%] [G loss: 2.625001]\n",
      "epoch:27 step:21271 [D loss: 1.517115, acc: 14.06%] [G loss: 3.899663]\n",
      "epoch:27 step:21272 [D loss: 0.159698, acc: 99.22%] [G loss: 3.378370]\n",
      "epoch:27 step:21273 [D loss: 0.880251, acc: 47.66%] [G loss: 3.988629]\n",
      "epoch:27 step:21274 [D loss: 0.814569, acc: 50.78%] [G loss: 3.023055]\n",
      "epoch:27 step:21275 [D loss: 0.593256, acc: 64.84%] [G loss: 2.713648]\n",
      "epoch:27 step:21276 [D loss: 0.070028, acc: 100.00%] [G loss: 4.735349]\n",
      "epoch:27 step:21277 [D loss: 0.292031, acc: 94.53%] [G loss: 3.064779]\n",
      "epoch:27 step:21278 [D loss: 0.543320, acc: 63.28%] [G loss: 3.805071]\n",
      "epoch:27 step:21279 [D loss: 0.847698, acc: 45.31%] [G loss: 3.512074]\n",
      "epoch:27 step:21280 [D loss: 0.245093, acc: 92.97%] [G loss: 4.929338]\n",
      "epoch:27 step:21281 [D loss: 0.444998, acc: 82.81%] [G loss: 3.531008]\n",
      "epoch:27 step:21282 [D loss: 0.905875, acc: 47.66%] [G loss: 3.149575]\n",
      "epoch:27 step:21283 [D loss: 0.232533, acc: 98.44%] [G loss: 2.901383]\n",
      "epoch:27 step:21284 [D loss: 0.384811, acc: 77.34%] [G loss: 2.539809]\n",
      "epoch:27 step:21285 [D loss: 0.162242, acc: 99.22%] [G loss: 5.383711]\n",
      "epoch:27 step:21286 [D loss: 0.545384, acc: 72.66%] [G loss: 2.947309]\n",
      "epoch:27 step:21287 [D loss: 0.221115, acc: 98.44%] [G loss: 4.258520]\n",
      "epoch:27 step:21288 [D loss: 0.131121, acc: 99.22%] [G loss: 4.861065]\n",
      "epoch:27 step:21289 [D loss: 0.412506, acc: 84.38%] [G loss: 3.551139]\n",
      "epoch:27 step:21290 [D loss: 0.554890, acc: 71.09%] [G loss: 3.289316]\n",
      "epoch:27 step:21291 [D loss: 0.087215, acc: 100.00%] [G loss: 3.412217]\n",
      "epoch:27 step:21292 [D loss: 1.314856, acc: 18.75%] [G loss: 1.690837]\n",
      "epoch:27 step:21293 [D loss: 1.141355, acc: 33.59%] [G loss: 2.065861]\n",
      "epoch:27 step:21294 [D loss: 0.249523, acc: 96.88%] [G loss: 5.033309]\n",
      "epoch:27 step:21295 [D loss: 0.248869, acc: 96.88%] [G loss: 3.394756]\n",
      "epoch:27 step:21296 [D loss: 0.763478, acc: 47.66%] [G loss: 2.806133]\n",
      "epoch:27 step:21297 [D loss: 0.209636, acc: 95.31%] [G loss: 2.446302]\n",
      "epoch:27 step:21298 [D loss: 0.297148, acc: 95.31%] [G loss: 4.208933]\n",
      "epoch:27 step:21299 [D loss: 0.219151, acc: 96.88%] [G loss: 3.229521]\n",
      "epoch:27 step:21300 [D loss: 0.370401, acc: 78.91%] [G loss: 2.276000]\n",
      "epoch:27 step:21301 [D loss: 0.675182, acc: 53.91%] [G loss: 2.739710]\n",
      "epoch:27 step:21302 [D loss: 0.508520, acc: 76.56%] [G loss: 2.029626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21303 [D loss: 0.563309, acc: 64.84%] [G loss: 2.715501]\n",
      "epoch:27 step:21304 [D loss: 0.086188, acc: 100.00%] [G loss: 3.423124]\n",
      "epoch:27 step:21305 [D loss: 0.617520, acc: 64.84%] [G loss: 3.852242]\n",
      "epoch:27 step:21306 [D loss: 0.156099, acc: 99.22%] [G loss: 2.619926]\n",
      "epoch:27 step:21307 [D loss: 0.794767, acc: 39.84%] [G loss: 2.229678]\n",
      "epoch:27 step:21308 [D loss: 0.935267, acc: 27.34%] [G loss: 3.065265]\n",
      "epoch:27 step:21309 [D loss: 0.428557, acc: 83.59%] [G loss: 4.371726]\n",
      "epoch:27 step:21310 [D loss: 0.332256, acc: 87.50%] [G loss: 3.110409]\n",
      "epoch:27 step:21311 [D loss: 0.639551, acc: 61.72%] [G loss: 3.841057]\n",
      "epoch:27 step:21312 [D loss: 0.142468, acc: 100.00%] [G loss: 3.487206]\n",
      "epoch:27 step:21313 [D loss: 0.363256, acc: 86.72%] [G loss: 4.376972]\n",
      "epoch:27 step:21314 [D loss: 0.287458, acc: 95.31%] [G loss: 5.074089]\n",
      "epoch:27 step:21315 [D loss: 0.252028, acc: 96.09%] [G loss: 4.523715]\n",
      "epoch:27 step:21316 [D loss: 0.284146, acc: 94.53%] [G loss: 2.785014]\n",
      "epoch:27 step:21317 [D loss: 0.600304, acc: 56.25%] [G loss: 3.796836]\n",
      "epoch:27 step:21318 [D loss: 0.500065, acc: 70.31%] [G loss: 3.654443]\n",
      "epoch:27 step:21319 [D loss: 0.798481, acc: 47.66%] [G loss: 2.486784]\n",
      "epoch:27 step:21320 [D loss: 0.176213, acc: 100.00%] [G loss: 3.756561]\n",
      "epoch:27 step:21321 [D loss: 0.522836, acc: 67.19%] [G loss: 4.207913]\n",
      "epoch:27 step:21322 [D loss: 0.634408, acc: 60.94%] [G loss: 2.245708]\n",
      "epoch:27 step:21323 [D loss: 1.053306, acc: 44.53%] [G loss: 3.327364]\n",
      "epoch:27 step:21324 [D loss: 0.091984, acc: 100.00%] [G loss: 3.781520]\n",
      "epoch:27 step:21325 [D loss: 0.666739, acc: 60.16%] [G loss: 4.374352]\n",
      "epoch:27 step:21326 [D loss: 0.287967, acc: 92.19%] [G loss: 4.223542]\n",
      "epoch:27 step:21327 [D loss: 0.331725, acc: 88.28%] [G loss: 2.183522]\n",
      "epoch:27 step:21328 [D loss: 0.059717, acc: 100.00%] [G loss: 5.685623]\n",
      "epoch:27 step:21329 [D loss: 0.378742, acc: 83.59%] [G loss: 4.841379]\n",
      "epoch:27 step:21330 [D loss: 0.248838, acc: 96.88%] [G loss: 3.620479]\n",
      "epoch:27 step:21331 [D loss: 0.227105, acc: 96.88%] [G loss: 4.442422]\n",
      "epoch:27 step:21332 [D loss: 0.604339, acc: 57.81%] [G loss: 2.925820]\n",
      "epoch:27 step:21333 [D loss: 0.901270, acc: 50.00%] [G loss: 2.412932]\n",
      "epoch:27 step:21334 [D loss: 1.043489, acc: 29.69%] [G loss: 2.315812]\n",
      "epoch:27 step:21335 [D loss: 1.433048, acc: 37.50%] [G loss: 3.320876]\n",
      "epoch:27 step:21336 [D loss: 0.243285, acc: 96.88%] [G loss: 3.672086]\n",
      "epoch:27 step:21337 [D loss: 0.354624, acc: 95.31%] [G loss: 3.301291]\n",
      "epoch:27 step:21338 [D loss: 0.553806, acc: 64.06%] [G loss: 4.165695]\n",
      "epoch:27 step:21339 [D loss: 1.315728, acc: 17.19%] [G loss: 2.713258]\n",
      "epoch:27 step:21340 [D loss: 0.355043, acc: 89.84%] [G loss: 3.905395]\n",
      "epoch:27 step:21341 [D loss: 0.682775, acc: 59.38%] [G loss: 3.387811]\n",
      "epoch:27 step:21342 [D loss: 0.534358, acc: 77.34%] [G loss: 4.556282]\n",
      "epoch:27 step:21343 [D loss: 0.422576, acc: 83.59%] [G loss: 2.328063]\n",
      "epoch:27 step:21344 [D loss: 0.545023, acc: 72.66%] [G loss: 2.883260]\n",
      "epoch:27 step:21345 [D loss: 0.818268, acc: 42.19%] [G loss: 3.335549]\n",
      "epoch:27 step:21346 [D loss: 0.571428, acc: 69.53%] [G loss: 3.977813]\n",
      "epoch:27 step:21347 [D loss: 0.276378, acc: 96.88%] [G loss: 3.403174]\n",
      "epoch:27 step:21348 [D loss: 0.866791, acc: 39.84%] [G loss: 3.077852]\n",
      "epoch:27 step:21349 [D loss: 0.301214, acc: 96.88%] [G loss: 3.732119]\n",
      "epoch:27 step:21350 [D loss: 0.824383, acc: 37.50%] [G loss: 2.698682]\n",
      "epoch:27 step:21351 [D loss: 0.688044, acc: 57.81%] [G loss: 3.487113]\n",
      "epoch:27 step:21352 [D loss: 0.467506, acc: 81.25%] [G loss: 4.163532]\n",
      "epoch:27 step:21353 [D loss: 0.612872, acc: 55.47%] [G loss: 4.197416]\n",
      "epoch:27 step:21354 [D loss: 0.536804, acc: 71.09%] [G loss: 1.804127]\n",
      "epoch:27 step:21355 [D loss: 0.583822, acc: 67.19%] [G loss: 2.687890]\n",
      "epoch:27 step:21356 [D loss: 0.267143, acc: 97.66%] [G loss: 2.102109]\n",
      "epoch:27 step:21357 [D loss: 0.569350, acc: 71.88%] [G loss: 3.058359]\n",
      "epoch:27 step:21358 [D loss: 0.265942, acc: 97.66%] [G loss: 3.408449]\n",
      "epoch:27 step:21359 [D loss: 0.260122, acc: 94.53%] [G loss: 2.884688]\n",
      "epoch:27 step:21360 [D loss: 0.522333, acc: 78.91%] [G loss: 2.908437]\n",
      "epoch:27 step:21361 [D loss: 0.701569, acc: 57.81%] [G loss: 2.132878]\n",
      "epoch:27 step:21362 [D loss: 0.353637, acc: 91.41%] [G loss: 3.497318]\n",
      "epoch:27 step:21363 [D loss: 0.457792, acc: 76.56%] [G loss: 2.003099]\n",
      "epoch:27 step:21364 [D loss: 0.484752, acc: 75.78%] [G loss: 4.953074]\n",
      "epoch:27 step:21365 [D loss: 0.558962, acc: 67.19%] [G loss: 4.526772]\n",
      "epoch:27 step:21366 [D loss: 0.375225, acc: 84.38%] [G loss: 2.895080]\n",
      "epoch:27 step:21367 [D loss: 0.341712, acc: 92.97%] [G loss: 3.688732]\n",
      "epoch:27 step:21368 [D loss: 0.600141, acc: 66.41%] [G loss: 3.294418]\n",
      "epoch:27 step:21369 [D loss: 0.539563, acc: 71.09%] [G loss: 3.404935]\n",
      "epoch:27 step:21370 [D loss: 0.348492, acc: 91.41%] [G loss: 3.049032]\n",
      "epoch:27 step:21371 [D loss: 0.310433, acc: 92.97%] [G loss: 3.356122]\n",
      "epoch:27 step:21372 [D loss: 0.306535, acc: 92.97%] [G loss: 3.718147]\n",
      "epoch:27 step:21373 [D loss: 0.212433, acc: 96.09%] [G loss: 3.046686]\n",
      "epoch:27 step:21374 [D loss: 0.279526, acc: 93.75%] [G loss: 4.196043]\n",
      "epoch:27 step:21375 [D loss: 0.690920, acc: 59.38%] [G loss: 2.820815]\n",
      "epoch:27 step:21376 [D loss: 0.804195, acc: 50.78%] [G loss: 2.926211]\n",
      "epoch:27 step:21377 [D loss: 0.567067, acc: 64.06%] [G loss: 2.461709]\n",
      "epoch:27 step:21378 [D loss: 0.914318, acc: 28.91%] [G loss: 2.583493]\n",
      "epoch:27 step:21379 [D loss: 0.429769, acc: 84.38%] [G loss: 3.867771]\n",
      "epoch:27 step:21380 [D loss: 0.251796, acc: 91.41%] [G loss: 3.681536]\n",
      "epoch:27 step:21381 [D loss: 0.330038, acc: 82.03%] [G loss: 3.967107]\n",
      "epoch:27 step:21382 [D loss: 0.377390, acc: 88.28%] [G loss: 2.996340]\n",
      "epoch:27 step:21383 [D loss: 0.239622, acc: 93.75%] [G loss: 2.719629]\n",
      "epoch:27 step:21384 [D loss: 0.352814, acc: 90.62%] [G loss: 4.135086]\n",
      "epoch:27 step:21385 [D loss: 0.304465, acc: 96.88%] [G loss: 2.765067]\n",
      "epoch:27 step:21386 [D loss: 0.876272, acc: 32.81%] [G loss: 3.377893]\n",
      "epoch:27 step:21387 [D loss: 0.758893, acc: 54.69%] [G loss: 2.405246]\n",
      "epoch:27 step:21388 [D loss: 0.288301, acc: 96.88%] [G loss: 3.019292]\n",
      "epoch:27 step:21389 [D loss: 0.527194, acc: 71.88%] [G loss: 2.676739]\n",
      "epoch:27 step:21390 [D loss: 0.858180, acc: 38.28%] [G loss: 2.741306]\n",
      "epoch:27 step:21391 [D loss: 0.471032, acc: 80.47%] [G loss: 2.361712]\n",
      "epoch:27 step:21392 [D loss: 0.274338, acc: 93.75%] [G loss: 5.120701]\n",
      "epoch:27 step:21393 [D loss: 0.301150, acc: 95.31%] [G loss: 3.758745]\n",
      "epoch:27 step:21394 [D loss: 0.490085, acc: 76.56%] [G loss: 3.364270]\n",
      "epoch:27 step:21395 [D loss: 0.471065, acc: 82.03%] [G loss: 4.730698]\n",
      "epoch:27 step:21396 [D loss: 0.177257, acc: 98.44%] [G loss: 3.526563]\n",
      "epoch:27 step:21397 [D loss: 0.304335, acc: 93.75%] [G loss: 6.006355]\n",
      "epoch:27 step:21398 [D loss: 0.398999, acc: 85.94%] [G loss: 2.502028]\n",
      "epoch:27 step:21399 [D loss: 0.755223, acc: 53.91%] [G loss: 3.081993]\n",
      "epoch:27 step:21400 [D loss: 0.193744, acc: 100.00%] [G loss: 4.039231]\n",
      "epoch:27 step:21401 [D loss: 0.281391, acc: 95.31%] [G loss: 4.169313]\n",
      "epoch:27 step:21402 [D loss: 0.653658, acc: 59.38%] [G loss: 5.139199]\n",
      "epoch:27 step:21403 [D loss: 0.546481, acc: 64.06%] [G loss: 2.896815]\n",
      "epoch:27 step:21404 [D loss: 0.073115, acc: 100.00%] [G loss: 4.422930]\n",
      "epoch:27 step:21405 [D loss: 0.514077, acc: 81.25%] [G loss: 3.048617]\n",
      "epoch:27 step:21406 [D loss: 0.464760, acc: 89.06%] [G loss: 5.576479]\n",
      "epoch:27 step:21407 [D loss: 0.564860, acc: 69.53%] [G loss: 2.378706]\n",
      "epoch:27 step:21408 [D loss: 0.614131, acc: 56.25%] [G loss: 3.049605]\n",
      "epoch:27 step:21409 [D loss: 0.326019, acc: 93.75%] [G loss: 3.030695]\n",
      "epoch:27 step:21410 [D loss: 0.251324, acc: 97.66%] [G loss: 4.570622]\n",
      "epoch:27 step:21411 [D loss: 0.494252, acc: 71.88%] [G loss: 3.023837]\n",
      "epoch:27 step:21412 [D loss: 0.165373, acc: 100.00%] [G loss: 3.282280]\n",
      "epoch:27 step:21413 [D loss: 0.813907, acc: 52.34%] [G loss: 2.771216]\n",
      "epoch:27 step:21414 [D loss: 0.559143, acc: 59.38%] [G loss: 4.183778]\n",
      "epoch:27 step:21415 [D loss: 0.120428, acc: 99.22%] [G loss: 4.065616]\n",
      "epoch:27 step:21416 [D loss: 0.319177, acc: 97.66%] [G loss: 5.074339]\n",
      "epoch:27 step:21417 [D loss: 0.227935, acc: 98.44%] [G loss: 3.392847]\n",
      "epoch:27 step:21418 [D loss: 0.370105, acc: 87.50%] [G loss: 3.581115]\n",
      "epoch:27 step:21419 [D loss: 0.385225, acc: 89.06%] [G loss: 4.196182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21420 [D loss: 0.485953, acc: 65.62%] [G loss: 3.585050]\n",
      "epoch:27 step:21421 [D loss: 0.702858, acc: 50.00%] [G loss: 3.543837]\n",
      "epoch:27 step:21422 [D loss: 0.116557, acc: 99.22%] [G loss: 3.787766]\n",
      "epoch:27 step:21423 [D loss: 0.528952, acc: 71.88%] [G loss: 4.742750]\n",
      "epoch:27 step:21424 [D loss: 0.253437, acc: 91.41%] [G loss: 4.773655]\n",
      "epoch:27 step:21425 [D loss: 0.910150, acc: 46.88%] [G loss: 3.723976]\n",
      "epoch:27 step:21426 [D loss: 0.336189, acc: 87.50%] [G loss: 5.534444]\n",
      "epoch:27 step:21427 [D loss: 0.459687, acc: 71.88%] [G loss: 4.146957]\n",
      "epoch:27 step:21428 [D loss: 0.105977, acc: 100.00%] [G loss: 3.283193]\n",
      "epoch:27 step:21429 [D loss: 0.807351, acc: 42.19%] [G loss: 2.900005]\n",
      "epoch:27 step:21430 [D loss: 0.591086, acc: 56.25%] [G loss: 3.721247]\n",
      "epoch:27 step:21431 [D loss: 1.095935, acc: 22.66%] [G loss: 4.233520]\n",
      "epoch:27 step:21432 [D loss: 0.155013, acc: 100.00%] [G loss: 4.058851]\n",
      "epoch:27 step:21433 [D loss: 0.532678, acc: 71.88%] [G loss: 4.222977]\n",
      "epoch:27 step:21434 [D loss: 0.159607, acc: 100.00%] [G loss: 3.590330]\n",
      "epoch:27 step:21435 [D loss: 0.711192, acc: 54.69%] [G loss: 1.883251]\n",
      "epoch:27 step:21436 [D loss: 0.536601, acc: 63.28%] [G loss: 3.453468]\n",
      "epoch:27 step:21437 [D loss: 0.922459, acc: 28.12%] [G loss: 3.968826]\n",
      "epoch:27 step:21438 [D loss: 0.266784, acc: 96.09%] [G loss: 2.461756]\n",
      "epoch:27 step:21439 [D loss: 0.490154, acc: 67.97%] [G loss: 4.479503]\n",
      "epoch:27 step:21440 [D loss: 0.413779, acc: 71.88%] [G loss: 3.065095]\n",
      "epoch:27 step:21441 [D loss: 0.282014, acc: 97.66%] [G loss: 4.046792]\n",
      "epoch:27 step:21442 [D loss: 0.752073, acc: 49.22%] [G loss: 2.579862]\n",
      "epoch:27 step:21443 [D loss: 0.533675, acc: 63.28%] [G loss: 1.854928]\n",
      "epoch:27 step:21444 [D loss: 0.707541, acc: 59.38%] [G loss: 3.990444]\n",
      "epoch:27 step:21445 [D loss: 0.288742, acc: 97.66%] [G loss: 2.249193]\n",
      "epoch:27 step:21446 [D loss: 0.493112, acc: 80.47%] [G loss: 3.621730]\n",
      "epoch:27 step:21447 [D loss: 0.707036, acc: 57.03%] [G loss: 4.700265]\n",
      "epoch:27 step:21448 [D loss: 0.296589, acc: 96.09%] [G loss: 3.492428]\n",
      "epoch:27 step:21449 [D loss: 0.497079, acc: 78.91%] [G loss: 2.843112]\n",
      "epoch:27 step:21450 [D loss: 0.365325, acc: 85.94%] [G loss: 3.632166]\n",
      "epoch:27 step:21451 [D loss: 0.603006, acc: 71.88%] [G loss: 3.393194]\n",
      "epoch:27 step:21452 [D loss: 0.584899, acc: 71.09%] [G loss: 4.684580]\n",
      "epoch:27 step:21453 [D loss: 0.572557, acc: 57.81%] [G loss: 3.977648]\n",
      "epoch:27 step:21454 [D loss: 0.436372, acc: 85.16%] [G loss: 2.334866]\n",
      "epoch:27 step:21455 [D loss: 0.150536, acc: 99.22%] [G loss: 4.463820]\n",
      "epoch:27 step:21456 [D loss: 0.580869, acc: 64.06%] [G loss: 4.472056]\n",
      "epoch:27 step:21457 [D loss: 0.310296, acc: 91.41%] [G loss: 2.301417]\n",
      "epoch:27 step:21458 [D loss: 0.299164, acc: 82.81%] [G loss: 3.517510]\n",
      "epoch:27 step:21459 [D loss: 0.343969, acc: 91.41%] [G loss: 3.410771]\n",
      "epoch:27 step:21460 [D loss: 0.512493, acc: 79.69%] [G loss: 3.072310]\n",
      "epoch:27 step:21461 [D loss: 0.472847, acc: 74.22%] [G loss: 3.667022]\n",
      "epoch:27 step:21462 [D loss: 0.331520, acc: 91.41%] [G loss: 2.635779]\n",
      "epoch:27 step:21463 [D loss: 0.612803, acc: 57.81%] [G loss: 4.226679]\n",
      "epoch:27 step:21464 [D loss: 0.611618, acc: 58.59%] [G loss: 3.065199]\n",
      "epoch:27 step:21465 [D loss: 0.597639, acc: 57.03%] [G loss: 4.274555]\n",
      "epoch:27 step:21466 [D loss: 0.407772, acc: 75.78%] [G loss: 5.420561]\n",
      "epoch:27 step:21467 [D loss: 0.499027, acc: 69.53%] [G loss: 4.339727]\n",
      "epoch:27 step:21468 [D loss: 0.514065, acc: 72.66%] [G loss: 2.655803]\n",
      "epoch:27 step:21469 [D loss: 0.271998, acc: 94.53%] [G loss: 3.608075]\n",
      "epoch:27 step:21470 [D loss: 1.551995, acc: 36.72%] [G loss: 2.341027]\n",
      "epoch:27 step:21471 [D loss: 0.246746, acc: 94.53%] [G loss: 2.786927]\n",
      "epoch:27 step:21472 [D loss: 0.457774, acc: 78.12%] [G loss: 3.252205]\n",
      "epoch:27 step:21473 [D loss: 1.054484, acc: 50.00%] [G loss: 3.632895]\n",
      "epoch:27 step:21474 [D loss: 0.263454, acc: 96.88%] [G loss: 4.040389]\n",
      "epoch:27 step:21475 [D loss: 1.002736, acc: 41.41%] [G loss: 2.671627]\n",
      "epoch:27 step:21476 [D loss: 1.451738, acc: 47.66%] [G loss: 2.173715]\n",
      "epoch:27 step:21477 [D loss: 0.231016, acc: 98.44%] [G loss: 3.489784]\n",
      "epoch:27 step:21478 [D loss: 1.362648, acc: 13.28%] [G loss: 2.871961]\n",
      "epoch:27 step:21479 [D loss: 0.645917, acc: 63.28%] [G loss: 5.414820]\n",
      "epoch:27 step:21480 [D loss: 0.361345, acc: 80.47%] [G loss: 3.079234]\n",
      "epoch:27 step:21481 [D loss: 0.129177, acc: 100.00%] [G loss: 3.328517]\n",
      "epoch:27 step:21482 [D loss: 0.253994, acc: 99.22%] [G loss: 3.351556]\n",
      "epoch:27 step:21483 [D loss: 0.376813, acc: 87.50%] [G loss: 3.456451]\n",
      "epoch:27 step:21484 [D loss: 0.878282, acc: 31.25%] [G loss: 2.793110]\n",
      "epoch:27 step:21485 [D loss: 0.837287, acc: 46.09%] [G loss: 2.953007]\n",
      "epoch:27 step:21486 [D loss: 0.314503, acc: 92.19%] [G loss: 3.171916]\n",
      "epoch:27 step:21487 [D loss: 0.482782, acc: 80.47%] [G loss: 4.291664]\n",
      "epoch:27 step:21488 [D loss: 0.189977, acc: 97.66%] [G loss: 4.265994]\n",
      "epoch:27 step:21489 [D loss: 0.539359, acc: 75.00%] [G loss: 4.810696]\n",
      "epoch:27 step:21490 [D loss: 0.873234, acc: 50.78%] [G loss: 2.815580]\n",
      "epoch:27 step:21491 [D loss: 0.722876, acc: 53.91%] [G loss: 4.105431]\n",
      "epoch:27 step:21492 [D loss: 0.728609, acc: 55.47%] [G loss: 1.673457]\n",
      "epoch:27 step:21493 [D loss: 0.263251, acc: 91.41%] [G loss: 4.267390]\n",
      "epoch:27 step:21494 [D loss: 0.607923, acc: 57.03%] [G loss: 2.393412]\n",
      "epoch:27 step:21495 [D loss: 0.270807, acc: 96.09%] [G loss: 3.384942]\n",
      "epoch:27 step:21496 [D loss: 0.396804, acc: 85.16%] [G loss: 4.461024]\n",
      "epoch:27 step:21497 [D loss: 0.583428, acc: 71.88%] [G loss: 3.630021]\n",
      "epoch:27 step:21498 [D loss: 0.199126, acc: 92.97%] [G loss: 3.421151]\n",
      "epoch:27 step:21499 [D loss: 0.125273, acc: 99.22%] [G loss: 4.260158]\n",
      "epoch:27 step:21500 [D loss: 0.363672, acc: 89.06%] [G loss: 2.626027]\n",
      "epoch:27 step:21501 [D loss: 0.466038, acc: 81.25%] [G loss: 3.062950]\n",
      "epoch:27 step:21502 [D loss: 0.442919, acc: 75.78%] [G loss: 4.554249]\n",
      "epoch:27 step:21503 [D loss: 0.892808, acc: 34.38%] [G loss: 2.697557]\n",
      "epoch:27 step:21504 [D loss: 0.330872, acc: 94.53%] [G loss: 3.927378]\n",
      "epoch:27 step:21505 [D loss: 0.101170, acc: 100.00%] [G loss: 4.167819]\n",
      "epoch:27 step:21506 [D loss: 0.208083, acc: 96.88%] [G loss: 3.327478]\n",
      "epoch:27 step:21507 [D loss: 0.382073, acc: 92.19%] [G loss: 2.374598]\n",
      "epoch:27 step:21508 [D loss: 0.178145, acc: 98.44%] [G loss: 1.746779]\n",
      "epoch:27 step:21509 [D loss: 0.654050, acc: 58.59%] [G loss: 5.030516]\n",
      "epoch:27 step:21510 [D loss: 0.937330, acc: 48.44%] [G loss: 4.644439]\n",
      "epoch:27 step:21511 [D loss: 0.490422, acc: 84.38%] [G loss: 3.164423]\n",
      "epoch:27 step:21512 [D loss: 0.402943, acc: 92.97%] [G loss: 2.772230]\n",
      "epoch:27 step:21513 [D loss: 0.214362, acc: 98.44%] [G loss: 3.047185]\n",
      "epoch:27 step:21514 [D loss: 0.599775, acc: 67.97%] [G loss: 2.615937]\n",
      "epoch:27 step:21515 [D loss: 0.243756, acc: 99.22%] [G loss: 3.084761]\n",
      "epoch:27 step:21516 [D loss: 0.086001, acc: 100.00%] [G loss: 5.202455]\n",
      "epoch:27 step:21517 [D loss: 0.300569, acc: 98.44%] [G loss: 3.390413]\n",
      "epoch:27 step:21518 [D loss: 1.055500, acc: 17.97%] [G loss: 2.503184]\n",
      "epoch:27 step:21519 [D loss: 0.846276, acc: 50.78%] [G loss: 2.669557]\n",
      "epoch:27 step:21520 [D loss: 0.367108, acc: 86.72%] [G loss: 3.616043]\n",
      "epoch:27 step:21521 [D loss: 0.267518, acc: 97.66%] [G loss: 2.709018]\n",
      "epoch:27 step:21522 [D loss: 0.204427, acc: 99.22%] [G loss: 4.923102]\n",
      "epoch:27 step:21523 [D loss: 0.740886, acc: 56.25%] [G loss: 2.612334]\n",
      "epoch:27 step:21524 [D loss: 0.335955, acc: 94.53%] [G loss: 3.452297]\n",
      "epoch:27 step:21525 [D loss: 0.447048, acc: 64.84%] [G loss: 3.217936]\n",
      "epoch:27 step:21526 [D loss: 0.527031, acc: 77.34%] [G loss: 3.142464]\n",
      "epoch:27 step:21527 [D loss: 0.564148, acc: 58.59%] [G loss: 4.337343]\n",
      "epoch:27 step:21528 [D loss: 0.579808, acc: 67.97%] [G loss: 2.548784]\n",
      "epoch:27 step:21529 [D loss: 0.361327, acc: 83.59%] [G loss: 3.557134]\n",
      "epoch:27 step:21530 [D loss: 0.203267, acc: 98.44%] [G loss: 2.441685]\n",
      "epoch:27 step:21531 [D loss: 0.346715, acc: 92.19%] [G loss: 4.129930]\n",
      "epoch:27 step:21532 [D loss: 0.252983, acc: 92.19%] [G loss: 2.627857]\n",
      "epoch:27 step:21533 [D loss: 0.207603, acc: 97.66%] [G loss: 4.642506]\n",
      "epoch:27 step:21534 [D loss: 0.373721, acc: 90.62%] [G loss: 1.643471]\n",
      "epoch:27 step:21535 [D loss: 0.577800, acc: 62.50%] [G loss: 2.310788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21536 [D loss: 0.089542, acc: 100.00%] [G loss: 4.371998]\n",
      "epoch:27 step:21537 [D loss: 0.354216, acc: 91.41%] [G loss: 2.755812]\n",
      "epoch:27 step:21538 [D loss: 0.274760, acc: 99.22%] [G loss: 2.824073]\n",
      "epoch:27 step:21539 [D loss: 0.504147, acc: 81.25%] [G loss: 2.468437]\n",
      "epoch:27 step:21540 [D loss: 0.202837, acc: 99.22%] [G loss: 5.616679]\n",
      "epoch:27 step:21541 [D loss: 0.550821, acc: 70.31%] [G loss: 3.982614]\n",
      "epoch:27 step:21542 [D loss: 0.971459, acc: 50.00%] [G loss: 5.054395]\n",
      "epoch:27 step:21543 [D loss: 0.293139, acc: 96.88%] [G loss: 3.209747]\n",
      "epoch:27 step:21544 [D loss: 0.378174, acc: 78.12%] [G loss: 3.966949]\n",
      "epoch:27 step:21545 [D loss: 0.374642, acc: 85.94%] [G loss: 2.852838]\n",
      "epoch:27 step:21546 [D loss: 0.384472, acc: 79.69%] [G loss: 3.910463]\n",
      "epoch:27 step:21547 [D loss: 1.023362, acc: 37.50%] [G loss: 2.203234]\n",
      "epoch:27 step:21548 [D loss: 0.975924, acc: 50.00%] [G loss: 4.264282]\n",
      "epoch:27 step:21549 [D loss: 0.190364, acc: 99.22%] [G loss: 3.432758]\n",
      "epoch:27 step:21550 [D loss: 0.356388, acc: 77.34%] [G loss: 4.127847]\n",
      "epoch:27 step:21551 [D loss: 0.647582, acc: 60.94%] [G loss: 3.220038]\n",
      "epoch:27 step:21552 [D loss: 0.269011, acc: 96.88%] [G loss: 3.053717]\n",
      "epoch:27 step:21553 [D loss: 0.307438, acc: 89.84%] [G loss: 3.626550]\n",
      "epoch:27 step:21554 [D loss: 0.206819, acc: 94.53%] [G loss: 4.160779]\n",
      "epoch:27 step:21555 [D loss: 0.952521, acc: 42.97%] [G loss: 1.787788]\n",
      "epoch:27 step:21556 [D loss: 0.279971, acc: 93.75%] [G loss: 4.580044]\n",
      "epoch:27 step:21557 [D loss: 0.333076, acc: 92.19%] [G loss: 2.193796]\n",
      "epoch:27 step:21558 [D loss: 0.952926, acc: 46.09%] [G loss: 2.267931]\n",
      "epoch:27 step:21559 [D loss: 0.559064, acc: 74.22%] [G loss: 5.196776]\n",
      "epoch:27 step:21560 [D loss: 1.211199, acc: 50.00%] [G loss: 2.800319]\n",
      "epoch:27 step:21561 [D loss: 0.457544, acc: 81.25%] [G loss: 3.087570]\n",
      "epoch:27 step:21562 [D loss: 0.347335, acc: 92.97%] [G loss: 4.066796]\n",
      "epoch:27 step:21563 [D loss: 0.606967, acc: 61.72%] [G loss: 2.607642]\n",
      "epoch:27 step:21564 [D loss: 0.306975, acc: 95.31%] [G loss: 3.012670]\n",
      "epoch:27 step:21565 [D loss: 0.322865, acc: 94.53%] [G loss: 3.881886]\n",
      "epoch:27 step:21566 [D loss: 0.284117, acc: 93.75%] [G loss: 2.752249]\n",
      "epoch:27 step:21567 [D loss: 0.552540, acc: 72.66%] [G loss: 3.305870]\n",
      "epoch:27 step:21568 [D loss: 0.144275, acc: 100.00%] [G loss: 3.919696]\n",
      "epoch:27 step:21569 [D loss: 0.674989, acc: 53.91%] [G loss: 3.966240]\n",
      "epoch:27 step:21570 [D loss: 0.355720, acc: 88.28%] [G loss: 4.753392]\n",
      "epoch:27 step:21571 [D loss: 0.434094, acc: 78.12%] [G loss: 3.808120]\n",
      "epoch:27 step:21572 [D loss: 0.234791, acc: 96.88%] [G loss: 4.898814]\n",
      "epoch:27 step:21573 [D loss: 0.663371, acc: 64.06%] [G loss: 3.543562]\n",
      "epoch:27 step:21574 [D loss: 0.591689, acc: 57.03%] [G loss: 2.636593]\n",
      "epoch:27 step:21575 [D loss: 0.607352, acc: 69.53%] [G loss: 2.958017]\n",
      "epoch:27 step:21576 [D loss: 0.434945, acc: 74.22%] [G loss: 2.914157]\n",
      "epoch:27 step:21577 [D loss: 0.389495, acc: 85.94%] [G loss: 3.809117]\n",
      "epoch:27 step:21578 [D loss: 0.609239, acc: 67.19%] [G loss: 3.691838]\n",
      "epoch:27 step:21579 [D loss: 0.414216, acc: 85.94%] [G loss: 3.368021]\n",
      "epoch:27 step:21580 [D loss: 0.108173, acc: 100.00%] [G loss: 4.901113]\n",
      "epoch:27 step:21581 [D loss: 0.343320, acc: 94.53%] [G loss: 4.107017]\n",
      "epoch:27 step:21582 [D loss: 0.351460, acc: 85.94%] [G loss: 3.309425]\n",
      "epoch:27 step:21583 [D loss: 0.413793, acc: 91.41%] [G loss: 5.151309]\n",
      "epoch:27 step:21584 [D loss: 0.567698, acc: 71.09%] [G loss: 3.428038]\n",
      "epoch:27 step:21585 [D loss: 0.315856, acc: 92.19%] [G loss: 3.851123]\n",
      "epoch:27 step:21586 [D loss: 0.400319, acc: 70.31%] [G loss: 4.061462]\n",
      "epoch:27 step:21587 [D loss: 0.551191, acc: 67.19%] [G loss: 3.751586]\n",
      "epoch:27 step:21588 [D loss: 0.549421, acc: 72.66%] [G loss: 2.382400]\n",
      "epoch:27 step:21589 [D loss: 0.487303, acc: 82.81%] [G loss: 2.882386]\n",
      "epoch:27 step:21590 [D loss: 0.469199, acc: 75.00%] [G loss: 2.835899]\n",
      "epoch:27 step:21591 [D loss: 0.517933, acc: 72.66%] [G loss: 2.576608]\n",
      "epoch:27 step:21592 [D loss: 0.151946, acc: 100.00%] [G loss: 3.525258]\n",
      "epoch:27 step:21593 [D loss: 0.643628, acc: 57.81%] [G loss: 4.754788]\n",
      "epoch:27 step:21594 [D loss: 1.257071, acc: 8.59%] [G loss: 3.082801]\n",
      "epoch:27 step:21595 [D loss: 0.533333, acc: 75.00%] [G loss: 3.068856]\n",
      "epoch:27 step:21596 [D loss: 0.156154, acc: 99.22%] [G loss: 2.988747]\n",
      "epoch:27 step:21597 [D loss: 0.363713, acc: 85.16%] [G loss: 4.199060]\n",
      "epoch:27 step:21598 [D loss: 0.148828, acc: 98.44%] [G loss: 5.697272]\n",
      "epoch:27 step:21599 [D loss: 0.222082, acc: 96.09%] [G loss: 5.131432]\n",
      "epoch:27 step:21600 [D loss: 0.543741, acc: 68.75%] [G loss: 4.282172]\n",
      "epoch:27 step:21601 [D loss: 0.110552, acc: 98.44%] [G loss: 4.546350]\n",
      "epoch:27 step:21602 [D loss: 0.401252, acc: 85.16%] [G loss: 3.617150]\n",
      "epoch:27 step:21603 [D loss: 0.748008, acc: 45.31%] [G loss: 3.448028]\n",
      "epoch:27 step:21604 [D loss: 0.227960, acc: 95.31%] [G loss: 2.968635]\n",
      "epoch:27 step:21605 [D loss: 0.324552, acc: 94.53%] [G loss: 2.650182]\n",
      "epoch:27 step:21606 [D loss: 0.222502, acc: 97.66%] [G loss: 3.706999]\n",
      "epoch:27 step:21607 [D loss: 0.652575, acc: 56.25%] [G loss: 5.602620]\n",
      "epoch:27 step:21608 [D loss: 0.623346, acc: 60.16%] [G loss: 3.742327]\n",
      "epoch:27 step:21609 [D loss: 0.289679, acc: 94.53%] [G loss: 3.177161]\n",
      "epoch:27 step:21610 [D loss: 0.599692, acc: 64.84%] [G loss: 3.523969]\n",
      "epoch:27 step:21611 [D loss: 0.299419, acc: 86.72%] [G loss: 6.254254]\n",
      "epoch:27 step:21612 [D loss: 1.108868, acc: 35.94%] [G loss: 3.858772]\n",
      "epoch:27 step:21613 [D loss: 0.397929, acc: 85.94%] [G loss: 4.526062]\n",
      "epoch:27 step:21614 [D loss: 0.326255, acc: 87.50%] [G loss: 2.972544]\n",
      "epoch:27 step:21615 [D loss: 0.317034, acc: 84.38%] [G loss: 2.469265]\n",
      "epoch:27 step:21616 [D loss: 0.240923, acc: 100.00%] [G loss: 2.991872]\n",
      "epoch:27 step:21617 [D loss: 0.498985, acc: 69.53%] [G loss: 4.027102]\n",
      "epoch:27 step:21618 [D loss: 0.477533, acc: 72.66%] [G loss: 3.931860]\n",
      "epoch:27 step:21619 [D loss: 0.291543, acc: 96.09%] [G loss: 2.078049]\n",
      "epoch:27 step:21620 [D loss: 0.142062, acc: 100.00%] [G loss: 4.384970]\n",
      "epoch:27 step:21621 [D loss: 0.111945, acc: 100.00%] [G loss: 4.378248]\n",
      "epoch:27 step:21622 [D loss: 0.880605, acc: 42.19%] [G loss: 4.223803]\n",
      "epoch:27 step:21623 [D loss: 0.329006, acc: 82.03%] [G loss: 4.783679]\n",
      "epoch:27 step:21624 [D loss: 0.222299, acc: 96.88%] [G loss: 5.851353]\n",
      "epoch:27 step:21625 [D loss: 0.299308, acc: 96.09%] [G loss: 4.113355]\n",
      "epoch:27 step:21626 [D loss: 1.080353, acc: 17.97%] [G loss: 4.635669]\n",
      "epoch:27 step:21627 [D loss: 0.407016, acc: 89.06%] [G loss: 3.164778]\n",
      "epoch:27 step:21628 [D loss: 0.399591, acc: 84.38%] [G loss: 3.570192]\n",
      "epoch:27 step:21629 [D loss: 0.724972, acc: 56.25%] [G loss: 3.854442]\n",
      "epoch:27 step:21630 [D loss: 0.356096, acc: 79.69%] [G loss: 3.367588]\n",
      "epoch:27 step:21631 [D loss: 0.510005, acc: 63.28%] [G loss: 3.756862]\n",
      "epoch:27 step:21632 [D loss: 0.470205, acc: 69.53%] [G loss: 3.723222]\n",
      "epoch:27 step:21633 [D loss: 1.038217, acc: 51.56%] [G loss: 5.082688]\n",
      "epoch:27 step:21634 [D loss: 0.464276, acc: 80.47%] [G loss: 2.921103]\n",
      "epoch:27 step:21635 [D loss: 0.536905, acc: 77.34%] [G loss: 4.200623]\n",
      "epoch:27 step:21636 [D loss: 0.299012, acc: 92.97%] [G loss: 2.369975]\n",
      "epoch:27 step:21637 [D loss: 0.182385, acc: 99.22%] [G loss: 3.858557]\n",
      "epoch:27 step:21638 [D loss: 0.087627, acc: 99.22%] [G loss: 2.324942]\n",
      "epoch:27 step:21639 [D loss: 0.936623, acc: 25.78%] [G loss: 2.903421]\n",
      "epoch:27 step:21640 [D loss: 0.265439, acc: 96.88%] [G loss: 2.657408]\n",
      "epoch:27 step:21641 [D loss: 0.642623, acc: 61.72%] [G loss: 4.284597]\n",
      "epoch:27 step:21642 [D loss: 0.201499, acc: 99.22%] [G loss: 2.833688]\n",
      "epoch:27 step:21643 [D loss: 0.197902, acc: 100.00%] [G loss: 4.114285]\n",
      "epoch:27 step:21644 [D loss: 0.593361, acc: 67.97%] [G loss: 4.875868]\n",
      "epoch:27 step:21645 [D loss: 0.474619, acc: 79.69%] [G loss: 2.755400]\n",
      "epoch:27 step:21646 [D loss: 0.269331, acc: 97.66%] [G loss: 3.046822]\n",
      "epoch:27 step:21647 [D loss: 1.205484, acc: 36.72%] [G loss: 2.472089]\n",
      "epoch:27 step:21648 [D loss: 0.345955, acc: 88.28%] [G loss: 5.595264]\n",
      "epoch:27 step:21649 [D loss: 0.358746, acc: 85.16%] [G loss: 3.788468]\n",
      "epoch:27 step:21650 [D loss: 0.136045, acc: 99.22%] [G loss: 3.616412]\n",
      "epoch:27 step:21651 [D loss: 0.606568, acc: 58.59%] [G loss: 2.165347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21652 [D loss: 0.178985, acc: 98.44%] [G loss: 3.416357]\n",
      "epoch:27 step:21653 [D loss: 0.278472, acc: 90.62%] [G loss: 4.144911]\n",
      "epoch:27 step:21654 [D loss: 0.274519, acc: 93.75%] [G loss: 5.312140]\n",
      "epoch:27 step:21655 [D loss: 0.327767, acc: 93.75%] [G loss: 3.144887]\n",
      "epoch:27 step:21656 [D loss: 0.342652, acc: 91.41%] [G loss: 2.542103]\n",
      "epoch:27 step:21657 [D loss: 0.560655, acc: 75.78%] [G loss: 3.142688]\n",
      "epoch:27 step:21658 [D loss: 1.490582, acc: 8.59%] [G loss: 3.226319]\n",
      "epoch:27 step:21659 [D loss: 0.577354, acc: 68.75%] [G loss: 2.926466]\n",
      "epoch:27 step:21660 [D loss: 0.527224, acc: 67.97%] [G loss: 2.964615]\n",
      "epoch:27 step:21661 [D loss: 0.877228, acc: 45.31%] [G loss: 5.069573]\n",
      "epoch:27 step:21662 [D loss: 0.390141, acc: 85.16%] [G loss: 3.600231]\n",
      "epoch:27 step:21663 [D loss: 0.434604, acc: 75.00%] [G loss: 3.410745]\n",
      "epoch:27 step:21664 [D loss: 0.256319, acc: 99.22%] [G loss: 3.364429]\n",
      "epoch:27 step:21665 [D loss: 0.154392, acc: 100.00%] [G loss: 2.604576]\n",
      "epoch:27 step:21666 [D loss: 0.264656, acc: 96.88%] [G loss: 2.444978]\n",
      "epoch:27 step:21667 [D loss: 0.764930, acc: 44.53%] [G loss: 3.803607]\n",
      "epoch:27 step:21668 [D loss: 0.367135, acc: 85.16%] [G loss: 4.438769]\n",
      "epoch:27 step:21669 [D loss: 0.587641, acc: 57.81%] [G loss: 5.424964]\n",
      "epoch:27 step:21670 [D loss: 0.224028, acc: 99.22%] [G loss: 3.700509]\n",
      "epoch:27 step:21671 [D loss: 0.674522, acc: 59.38%] [G loss: 4.662959]\n",
      "epoch:27 step:21672 [D loss: 0.576519, acc: 74.22%] [G loss: 4.988476]\n",
      "epoch:27 step:21673 [D loss: 0.307476, acc: 89.06%] [G loss: 3.704373]\n",
      "epoch:27 step:21674 [D loss: 0.401896, acc: 79.69%] [G loss: 4.199428]\n",
      "epoch:27 step:21675 [D loss: 0.536884, acc: 74.22%] [G loss: 3.427939]\n",
      "epoch:27 step:21676 [D loss: 0.834002, acc: 50.78%] [G loss: 2.490693]\n",
      "epoch:27 step:21677 [D loss: 0.142958, acc: 100.00%] [G loss: 2.331265]\n",
      "epoch:27 step:21678 [D loss: 0.735210, acc: 44.53%] [G loss: 3.610750]\n",
      "epoch:27 step:21679 [D loss: 0.724778, acc: 53.12%] [G loss: 5.493433]\n",
      "epoch:27 step:21680 [D loss: 0.115527, acc: 100.00%] [G loss: 5.981706]\n",
      "epoch:27 step:21681 [D loss: 0.544352, acc: 64.06%] [G loss: 2.436965]\n",
      "epoch:27 step:21682 [D loss: 0.085984, acc: 100.00%] [G loss: 5.682233]\n",
      "epoch:27 step:21683 [D loss: 0.409468, acc: 74.22%] [G loss: 3.174473]\n",
      "epoch:27 step:21684 [D loss: 0.534611, acc: 63.28%] [G loss: 2.485358]\n",
      "epoch:27 step:21685 [D loss: 0.179849, acc: 99.22%] [G loss: 4.369070]\n",
      "epoch:27 step:21686 [D loss: 0.329981, acc: 90.62%] [G loss: 5.871855]\n",
      "epoch:27 step:21687 [D loss: 0.211557, acc: 100.00%] [G loss: 4.117352]\n",
      "epoch:27 step:21688 [D loss: 1.048614, acc: 42.97%] [G loss: 4.847923]\n",
      "epoch:27 step:21689 [D loss: 0.495606, acc: 83.59%] [G loss: 2.931082]\n",
      "epoch:27 step:21690 [D loss: 1.890721, acc: 2.34%] [G loss: 3.248124]\n",
      "epoch:27 step:21691 [D loss: 0.635960, acc: 55.47%] [G loss: 4.448975]\n",
      "epoch:27 step:21692 [D loss: 0.367538, acc: 82.03%] [G loss: 2.456090]\n",
      "epoch:27 step:21693 [D loss: 0.241165, acc: 96.09%] [G loss: 3.799562]\n",
      "epoch:27 step:21694 [D loss: 0.754864, acc: 51.56%] [G loss: 4.162779]\n",
      "epoch:27 step:21695 [D loss: 0.384512, acc: 81.25%] [G loss: 3.332108]\n",
      "epoch:27 step:21696 [D loss: 0.238276, acc: 98.44%] [G loss: 3.399065]\n",
      "epoch:27 step:21697 [D loss: 0.419246, acc: 75.78%] [G loss: 2.420038]\n",
      "epoch:27 step:21698 [D loss: 0.578358, acc: 75.78%] [G loss: 2.742755]\n",
      "epoch:27 step:21699 [D loss: 0.851192, acc: 51.56%] [G loss: 2.839528]\n",
      "epoch:27 step:21700 [D loss: 0.630922, acc: 64.06%] [G loss: 3.837491]\n",
      "epoch:27 step:21701 [D loss: 0.235027, acc: 97.66%] [G loss: 3.027398]\n",
      "epoch:27 step:21702 [D loss: 0.354849, acc: 88.28%] [G loss: 3.109075]\n",
      "epoch:27 step:21703 [D loss: 0.233474, acc: 98.44%] [G loss: 3.016284]\n",
      "epoch:27 step:21704 [D loss: 0.601631, acc: 59.38%] [G loss: 4.000064]\n",
      "epoch:27 step:21705 [D loss: 0.390587, acc: 87.50%] [G loss: 3.345681]\n",
      "epoch:27 step:21706 [D loss: 0.806996, acc: 51.56%] [G loss: 2.475193]\n",
      "epoch:27 step:21707 [D loss: 0.571933, acc: 66.41%] [G loss: 2.633088]\n",
      "epoch:27 step:21708 [D loss: 0.275365, acc: 92.19%] [G loss: 3.407890]\n",
      "epoch:27 step:21709 [D loss: 0.982768, acc: 27.34%] [G loss: 3.860148]\n",
      "epoch:27 step:21710 [D loss: 0.339750, acc: 85.94%] [G loss: 5.111480]\n",
      "epoch:27 step:21711 [D loss: 0.612532, acc: 55.47%] [G loss: 3.511915]\n",
      "epoch:27 step:21712 [D loss: 0.223491, acc: 99.22%] [G loss: 3.380631]\n",
      "epoch:27 step:21713 [D loss: 0.312974, acc: 96.88%] [G loss: 3.031777]\n",
      "epoch:27 step:21714 [D loss: 0.636695, acc: 55.47%] [G loss: 3.932714]\n",
      "epoch:27 step:21715 [D loss: 0.533441, acc: 64.84%] [G loss: 3.951421]\n",
      "epoch:27 step:21716 [D loss: 0.792655, acc: 48.44%] [G loss: 3.388013]\n",
      "epoch:27 step:21717 [D loss: 0.675653, acc: 64.06%] [G loss: 3.040133]\n",
      "epoch:27 step:21718 [D loss: 0.410187, acc: 86.72%] [G loss: 4.109393]\n",
      "epoch:27 step:21719 [D loss: 1.684366, acc: 5.47%] [G loss: 2.583263]\n",
      "epoch:27 step:21720 [D loss: 0.680344, acc: 63.28%] [G loss: 3.490649]\n",
      "epoch:27 step:21721 [D loss: 0.874415, acc: 42.19%] [G loss: 4.382636]\n",
      "epoch:27 step:21722 [D loss: 0.794204, acc: 46.88%] [G loss: 1.751513]\n",
      "epoch:27 step:21723 [D loss: 0.397955, acc: 92.97%] [G loss: 2.359061]\n",
      "epoch:27 step:21724 [D loss: 0.686080, acc: 57.03%] [G loss: 3.449969]\n",
      "epoch:27 step:21725 [D loss: 0.589496, acc: 59.38%] [G loss: 4.251038]\n",
      "epoch:27 step:21726 [D loss: 0.872948, acc: 44.53%] [G loss: 3.122346]\n",
      "epoch:27 step:21727 [D loss: 0.620588, acc: 62.50%] [G loss: 2.570919]\n",
      "epoch:27 step:21728 [D loss: 0.337984, acc: 95.31%] [G loss: 3.108456]\n",
      "epoch:27 step:21729 [D loss: 0.764754, acc: 51.56%] [G loss: 3.618758]\n",
      "epoch:27 step:21730 [D loss: 1.213795, acc: 7.03%] [G loss: 3.717469]\n",
      "epoch:27 step:21731 [D loss: 0.176365, acc: 100.00%] [G loss: 3.715534]\n",
      "epoch:27 step:21732 [D loss: 0.612572, acc: 71.88%] [G loss: 2.938089]\n",
      "epoch:27 step:21733 [D loss: 0.573855, acc: 73.44%] [G loss: 3.123780]\n",
      "epoch:27 step:21734 [D loss: 0.361252, acc: 90.62%] [G loss: 2.764471]\n",
      "epoch:27 step:21735 [D loss: 0.659251, acc: 55.47%] [G loss: 3.174426]\n",
      "epoch:27 step:21736 [D loss: 0.647031, acc: 64.84%] [G loss: 2.917110]\n",
      "epoch:27 step:21737 [D loss: 0.152683, acc: 98.44%] [G loss: 2.771834]\n",
      "epoch:27 step:21738 [D loss: 0.150090, acc: 100.00%] [G loss: 3.829173]\n",
      "epoch:27 step:21739 [D loss: 0.625053, acc: 58.59%] [G loss: 3.215068]\n",
      "epoch:27 step:21740 [D loss: 0.130401, acc: 99.22%] [G loss: 2.962858]\n",
      "epoch:27 step:21741 [D loss: 0.272700, acc: 96.88%] [G loss: 3.261449]\n",
      "epoch:27 step:21742 [D loss: 0.321218, acc: 90.62%] [G loss: 3.700467]\n",
      "epoch:27 step:21743 [D loss: 1.018263, acc: 28.91%] [G loss: 3.290722]\n",
      "epoch:27 step:21744 [D loss: 0.259550, acc: 96.88%] [G loss: 3.441299]\n",
      "epoch:27 step:21745 [D loss: 0.521991, acc: 75.78%] [G loss: 4.934788]\n",
      "epoch:27 step:21746 [D loss: 0.094738, acc: 100.00%] [G loss: 5.629123]\n",
      "epoch:27 step:21747 [D loss: 0.697354, acc: 58.59%] [G loss: 2.347430]\n",
      "epoch:27 step:21748 [D loss: 0.358659, acc: 92.97%] [G loss: 3.433434]\n",
      "epoch:27 step:21749 [D loss: 0.227181, acc: 96.09%] [G loss: 2.960102]\n",
      "epoch:27 step:21750 [D loss: 0.394995, acc: 88.28%] [G loss: 3.476688]\n",
      "epoch:27 step:21751 [D loss: 0.228082, acc: 96.09%] [G loss: 3.675326]\n",
      "epoch:27 step:21752 [D loss: 0.343355, acc: 92.97%] [G loss: 3.494860]\n",
      "epoch:27 step:21753 [D loss: 0.502617, acc: 81.25%] [G loss: 2.990390]\n",
      "epoch:27 step:21754 [D loss: 0.545073, acc: 74.22%] [G loss: 2.723635]\n",
      "epoch:27 step:21755 [D loss: 0.144714, acc: 100.00%] [G loss: 4.372829]\n",
      "epoch:27 step:21756 [D loss: 0.159138, acc: 100.00%] [G loss: 2.910377]\n",
      "epoch:27 step:21757 [D loss: 1.197727, acc: 43.75%] [G loss: 2.210146]\n",
      "epoch:27 step:21758 [D loss: 0.257626, acc: 96.88%] [G loss: 4.128389]\n",
      "epoch:27 step:21759 [D loss: 1.320405, acc: 4.69%] [G loss: 3.113291]\n",
      "epoch:27 step:21760 [D loss: 0.754154, acc: 56.25%] [G loss: 3.885100]\n",
      "epoch:27 step:21761 [D loss: 0.752481, acc: 52.34%] [G loss: 3.039592]\n",
      "epoch:27 step:21762 [D loss: 0.471877, acc: 82.03%] [G loss: 3.382168]\n",
      "epoch:27 step:21763 [D loss: 0.276971, acc: 93.75%] [G loss: 2.288999]\n",
      "epoch:27 step:21764 [D loss: 0.519102, acc: 63.28%] [G loss: 2.715591]\n",
      "epoch:27 step:21765 [D loss: 0.477253, acc: 75.78%] [G loss: 2.286380]\n",
      "epoch:27 step:21766 [D loss: 0.187003, acc: 98.44%] [G loss: 4.396377]\n",
      "epoch:27 step:21767 [D loss: 0.177216, acc: 98.44%] [G loss: 4.934505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21768 [D loss: 0.108147, acc: 100.00%] [G loss: 4.658316]\n",
      "epoch:27 step:21769 [D loss: 0.816020, acc: 43.75%] [G loss: 4.966644]\n",
      "epoch:27 step:21770 [D loss: 0.139808, acc: 100.00%] [G loss: 3.401016]\n",
      "epoch:27 step:21771 [D loss: 0.668975, acc: 64.06%] [G loss: 3.446248]\n",
      "epoch:27 step:21772 [D loss: 0.212608, acc: 98.44%] [G loss: 2.731001]\n",
      "epoch:27 step:21773 [D loss: 0.934870, acc: 32.81%] [G loss: 3.134676]\n",
      "epoch:27 step:21774 [D loss: 0.600923, acc: 66.41%] [G loss: 2.830966]\n",
      "epoch:27 step:21775 [D loss: 0.236848, acc: 96.09%] [G loss: 3.482422]\n",
      "epoch:27 step:21776 [D loss: 0.286775, acc: 96.09%] [G loss: 2.708713]\n",
      "epoch:27 step:21777 [D loss: 0.561929, acc: 69.53%] [G loss: 4.354516]\n",
      "epoch:27 step:21778 [D loss: 0.556311, acc: 64.84%] [G loss: 5.217103]\n",
      "epoch:27 step:21779 [D loss: 0.678875, acc: 59.38%] [G loss: 3.333418]\n",
      "epoch:27 step:21780 [D loss: 0.433502, acc: 89.06%] [G loss: 2.533776]\n",
      "epoch:27 step:21781 [D loss: 0.077542, acc: 100.00%] [G loss: 3.015900]\n",
      "epoch:27 step:21782 [D loss: 0.446334, acc: 85.16%] [G loss: 3.455477]\n",
      "epoch:27 step:21783 [D loss: 0.678395, acc: 57.03%] [G loss: 3.538687]\n",
      "epoch:27 step:21784 [D loss: 0.839814, acc: 45.31%] [G loss: 2.354797]\n",
      "epoch:27 step:21785 [D loss: 0.304973, acc: 95.31%] [G loss: 3.991384]\n",
      "epoch:27 step:21786 [D loss: 0.356286, acc: 93.75%] [G loss: 2.696387]\n",
      "epoch:27 step:21787 [D loss: 0.445945, acc: 77.34%] [G loss: 3.368132]\n",
      "epoch:27 step:21788 [D loss: 0.418918, acc: 84.38%] [G loss: 4.087726]\n",
      "epoch:27 step:21789 [D loss: 0.479321, acc: 78.91%] [G loss: 3.057050]\n",
      "epoch:27 step:21790 [D loss: 0.119612, acc: 100.00%] [G loss: 3.114226]\n",
      "epoch:27 step:21791 [D loss: 0.458208, acc: 82.81%] [G loss: 3.666117]\n",
      "epoch:27 step:21792 [D loss: 0.334942, acc: 93.75%] [G loss: 2.142838]\n",
      "epoch:27 step:21793 [D loss: 0.589989, acc: 75.78%] [G loss: 2.922210]\n",
      "epoch:27 step:21794 [D loss: 0.511499, acc: 73.44%] [G loss: 4.628713]\n",
      "epoch:27 step:21795 [D loss: 0.273214, acc: 99.22%] [G loss: 3.158643]\n",
      "epoch:27 step:21796 [D loss: 0.707524, acc: 52.34%] [G loss: 3.800286]\n",
      "epoch:27 step:21797 [D loss: 0.513665, acc: 75.78%] [G loss: 4.584452]\n",
      "epoch:27 step:21798 [D loss: 0.075832, acc: 100.00%] [G loss: 4.742026]\n",
      "epoch:27 step:21799 [D loss: 0.342953, acc: 83.59%] [G loss: 2.921384]\n",
      "epoch:27 step:21800 [D loss: 0.177395, acc: 96.09%] [G loss: 6.194051]\n",
      "epoch:27 step:21801 [D loss: 0.187320, acc: 100.00%] [G loss: 3.831631]\n",
      "epoch:27 step:21802 [D loss: 0.660654, acc: 60.94%] [G loss: 3.888394]\n",
      "epoch:27 step:21803 [D loss: 0.122838, acc: 100.00%] [G loss: 4.521517]\n",
      "epoch:27 step:21804 [D loss: 0.725324, acc: 53.91%] [G loss: 3.231333]\n",
      "epoch:27 step:21805 [D loss: 0.472571, acc: 83.59%] [G loss: 2.138708]\n",
      "epoch:27 step:21806 [D loss: 0.967897, acc: 50.78%] [G loss: 2.906164]\n",
      "epoch:27 step:21807 [D loss: 0.452276, acc: 82.81%] [G loss: 2.511240]\n",
      "epoch:27 step:21808 [D loss: 0.172328, acc: 99.22%] [G loss: 4.076612]\n",
      "epoch:27 step:21809 [D loss: 0.312845, acc: 95.31%] [G loss: 1.782366]\n",
      "epoch:27 step:21810 [D loss: 1.643619, acc: 33.59%] [G loss: 3.558908]\n",
      "epoch:27 step:21811 [D loss: 0.584219, acc: 71.88%] [G loss: 3.117640]\n",
      "epoch:27 step:21812 [D loss: 0.813485, acc: 53.91%] [G loss: 2.645067]\n",
      "epoch:27 step:21813 [D loss: 0.178905, acc: 98.44%] [G loss: 2.709118]\n",
      "epoch:27 step:21814 [D loss: 0.663532, acc: 55.47%] [G loss: 2.545432]\n",
      "epoch:27 step:21815 [D loss: 0.565722, acc: 65.62%] [G loss: 4.957002]\n",
      "epoch:27 step:21816 [D loss: 0.574706, acc: 68.75%] [G loss: 4.058893]\n",
      "epoch:27 step:21817 [D loss: 0.538490, acc: 71.88%] [G loss: 3.217516]\n",
      "epoch:27 step:21818 [D loss: 0.735941, acc: 53.91%] [G loss: 3.147322]\n",
      "epoch:27 step:21819 [D loss: 0.540066, acc: 63.28%] [G loss: 3.603203]\n",
      "epoch:27 step:21820 [D loss: 0.359127, acc: 94.53%] [G loss: 3.193766]\n",
      "epoch:27 step:21821 [D loss: 0.449434, acc: 89.84%] [G loss: 3.768651]\n",
      "epoch:27 step:21822 [D loss: 0.539224, acc: 60.94%] [G loss: 4.404039]\n",
      "epoch:27 step:21823 [D loss: 0.461818, acc: 75.78%] [G loss: 2.457033]\n",
      "epoch:27 step:21824 [D loss: 0.655384, acc: 56.25%] [G loss: 5.053118]\n",
      "epoch:27 step:21825 [D loss: 0.521421, acc: 75.00%] [G loss: 3.114156]\n",
      "epoch:27 step:21826 [D loss: 0.813612, acc: 50.78%] [G loss: 4.227472]\n",
      "epoch:27 step:21827 [D loss: 0.204947, acc: 95.31%] [G loss: 3.893247]\n",
      "epoch:27 step:21828 [D loss: 0.401427, acc: 81.25%] [G loss: 1.808043]\n",
      "epoch:27 step:21829 [D loss: 0.608466, acc: 65.62%] [G loss: 2.263775]\n",
      "epoch:27 step:21830 [D loss: 0.654341, acc: 57.03%] [G loss: 3.674734]\n",
      "epoch:27 step:21831 [D loss: 0.693785, acc: 56.25%] [G loss: 3.304809]\n",
      "epoch:27 step:21832 [D loss: 0.112071, acc: 100.00%] [G loss: 5.052988]\n",
      "epoch:27 step:21833 [D loss: 0.255632, acc: 96.88%] [G loss: 2.979229]\n",
      "epoch:27 step:21834 [D loss: 0.471479, acc: 74.22%] [G loss: 2.800630]\n",
      "epoch:27 step:21835 [D loss: 0.151037, acc: 99.22%] [G loss: 3.855190]\n",
      "epoch:27 step:21836 [D loss: 0.502508, acc: 67.97%] [G loss: 3.638102]\n",
      "epoch:27 step:21837 [D loss: 0.402392, acc: 87.50%] [G loss: 3.238134]\n",
      "epoch:27 step:21838 [D loss: 0.329402, acc: 92.19%] [G loss: 4.931629]\n",
      "epoch:27 step:21839 [D loss: 0.494764, acc: 67.19%] [G loss: 2.793588]\n",
      "epoch:27 step:21840 [D loss: 0.781859, acc: 45.31%] [G loss: 3.669410]\n",
      "epoch:27 step:21841 [D loss: 0.444210, acc: 75.78%] [G loss: 3.584131]\n",
      "epoch:27 step:21842 [D loss: 0.623145, acc: 64.06%] [G loss: 4.343324]\n",
      "epoch:27 step:21843 [D loss: 0.155943, acc: 99.22%] [G loss: 3.714949]\n",
      "epoch:27 step:21844 [D loss: 0.126536, acc: 100.00%] [G loss: 4.161994]\n",
      "epoch:27 step:21845 [D loss: 0.278916, acc: 96.09%] [G loss: 3.226346]\n",
      "epoch:27 step:21846 [D loss: 0.628035, acc: 58.59%] [G loss: 4.086048]\n",
      "epoch:27 step:21847 [D loss: 0.298707, acc: 89.06%] [G loss: 4.769626]\n",
      "epoch:27 step:21848 [D loss: 0.470774, acc: 73.44%] [G loss: 4.121448]\n",
      "epoch:27 step:21849 [D loss: 1.267491, acc: 38.28%] [G loss: 2.462409]\n",
      "epoch:27 step:21850 [D loss: 0.236209, acc: 97.66%] [G loss: 2.743443]\n",
      "epoch:27 step:21851 [D loss: 0.608840, acc: 66.41%] [G loss: 4.245126]\n",
      "epoch:27 step:21852 [D loss: 0.426834, acc: 87.50%] [G loss: 3.833601]\n",
      "epoch:27 step:21853 [D loss: 0.118587, acc: 99.22%] [G loss: 4.064779]\n",
      "epoch:27 step:21854 [D loss: 0.051718, acc: 100.00%] [G loss: 4.981539]\n",
      "epoch:27 step:21855 [D loss: 1.214290, acc: 50.00%] [G loss: 2.955427]\n",
      "epoch:27 step:21856 [D loss: 0.271854, acc: 89.06%] [G loss: 4.840703]\n",
      "epoch:27 step:21857 [D loss: 0.461018, acc: 78.91%] [G loss: 3.626519]\n",
      "epoch:27 step:21858 [D loss: 0.447119, acc: 86.72%] [G loss: 4.078693]\n",
      "epoch:27 step:21859 [D loss: 0.421833, acc: 86.72%] [G loss: 3.800581]\n",
      "epoch:27 step:21860 [D loss: 0.143980, acc: 99.22%] [G loss: 4.448218]\n",
      "epoch:27 step:21861 [D loss: 0.465989, acc: 87.50%] [G loss: 3.783336]\n",
      "epoch:27 step:21862 [D loss: 0.872772, acc: 42.97%] [G loss: 3.695817]\n",
      "epoch:27 step:21863 [D loss: 0.615236, acc: 60.16%] [G loss: 2.655204]\n",
      "epoch:27 step:21864 [D loss: 0.340606, acc: 83.59%] [G loss: 3.190407]\n",
      "epoch:27 step:21865 [D loss: 0.554074, acc: 73.44%] [G loss: 4.202968]\n",
      "epoch:27 step:21866 [D loss: 0.148767, acc: 100.00%] [G loss: 5.068323]\n",
      "epoch:27 step:21867 [D loss: 0.719966, acc: 52.34%] [G loss: 3.200203]\n",
      "epoch:27 step:21868 [D loss: 0.982107, acc: 51.56%] [G loss: 2.746331]\n",
      "epoch:28 step:21869 [D loss: 0.751878, acc: 53.12%] [G loss: 3.099246]\n",
      "epoch:28 step:21870 [D loss: 0.074941, acc: 100.00%] [G loss: 3.111830]\n",
      "epoch:28 step:21871 [D loss: 0.573357, acc: 67.19%] [G loss: 2.183589]\n",
      "epoch:28 step:21872 [D loss: 0.662727, acc: 56.25%] [G loss: 3.545334]\n",
      "epoch:28 step:21873 [D loss: 0.809306, acc: 52.34%] [G loss: 3.235588]\n",
      "epoch:28 step:21874 [D loss: 0.412598, acc: 87.50%] [G loss: 3.391330]\n",
      "epoch:28 step:21875 [D loss: 0.998199, acc: 28.12%] [G loss: 4.649230]\n",
      "epoch:28 step:21876 [D loss: 0.343218, acc: 92.97%] [G loss: 2.668847]\n",
      "epoch:28 step:21877 [D loss: 0.416490, acc: 83.59%] [G loss: 4.206296]\n",
      "epoch:28 step:21878 [D loss: 1.422272, acc: 44.53%] [G loss: 3.552540]\n",
      "epoch:28 step:21879 [D loss: 0.482658, acc: 66.41%] [G loss: 3.833957]\n",
      "epoch:28 step:21880 [D loss: 1.195434, acc: 14.06%] [G loss: 3.096964]\n",
      "epoch:28 step:21881 [D loss: 0.577461, acc: 64.84%] [G loss: 2.746380]\n",
      "epoch:28 step:21882 [D loss: 0.413524, acc: 84.38%] [G loss: 4.611043]\n",
      "epoch:28 step:21883 [D loss: 1.429287, acc: 48.44%] [G loss: 2.276251]\n",
      "epoch:28 step:21884 [D loss: 0.377584, acc: 89.84%] [G loss: 3.979479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:21885 [D loss: 0.898437, acc: 50.78%] [G loss: 1.794886]\n",
      "epoch:28 step:21886 [D loss: 0.336584, acc: 96.09%] [G loss: 4.367435]\n",
      "epoch:28 step:21887 [D loss: 0.251844, acc: 92.97%] [G loss: 4.730124]\n",
      "epoch:28 step:21888 [D loss: 1.011865, acc: 28.91%] [G loss: 3.845907]\n",
      "epoch:28 step:21889 [D loss: 0.221889, acc: 96.09%] [G loss: 4.490534]\n",
      "epoch:28 step:21890 [D loss: 0.140877, acc: 98.44%] [G loss: 2.713778]\n",
      "epoch:28 step:21891 [D loss: 0.497045, acc: 76.56%] [G loss: 2.654827]\n",
      "epoch:28 step:21892 [D loss: 0.993739, acc: 50.00%] [G loss: 2.375241]\n",
      "epoch:28 step:21893 [D loss: 0.424015, acc: 84.38%] [G loss: 3.894053]\n",
      "epoch:28 step:21894 [D loss: 0.554046, acc: 72.66%] [G loss: 5.273536]\n",
      "epoch:28 step:21895 [D loss: 0.391695, acc: 80.47%] [G loss: 3.020060]\n",
      "epoch:28 step:21896 [D loss: 0.269384, acc: 95.31%] [G loss: 4.471920]\n",
      "epoch:28 step:21897 [D loss: 0.663614, acc: 53.91%] [G loss: 4.336319]\n",
      "epoch:28 step:21898 [D loss: 0.285840, acc: 96.09%] [G loss: 3.855737]\n",
      "epoch:28 step:21899 [D loss: 0.127747, acc: 99.22%] [G loss: 5.131527]\n",
      "epoch:28 step:21900 [D loss: 0.243525, acc: 96.09%] [G loss: 3.037026]\n",
      "epoch:28 step:21901 [D loss: 0.546344, acc: 70.31%] [G loss: 3.342471]\n",
      "epoch:28 step:21902 [D loss: 0.594502, acc: 71.09%] [G loss: 5.063066]\n",
      "epoch:28 step:21903 [D loss: 0.325393, acc: 90.62%] [G loss: 3.598281]\n",
      "epoch:28 step:21904 [D loss: 0.235125, acc: 97.66%] [G loss: 3.547800]\n",
      "epoch:28 step:21905 [D loss: 0.318763, acc: 85.94%] [G loss: 4.470063]\n",
      "epoch:28 step:21906 [D loss: 0.590272, acc: 68.75%] [G loss: 3.263936]\n",
      "epoch:28 step:21907 [D loss: 0.259493, acc: 93.75%] [G loss: 3.270729]\n",
      "epoch:28 step:21908 [D loss: 0.343914, acc: 83.59%] [G loss: 2.418427]\n",
      "epoch:28 step:21909 [D loss: 0.490821, acc: 79.69%] [G loss: 4.239870]\n",
      "epoch:28 step:21910 [D loss: 0.726672, acc: 55.47%] [G loss: 2.980186]\n",
      "epoch:28 step:21911 [D loss: 0.562597, acc: 69.53%] [G loss: 3.724214]\n",
      "epoch:28 step:21912 [D loss: 1.338530, acc: 13.28%] [G loss: 2.264651]\n",
      "epoch:28 step:21913 [D loss: 0.611814, acc: 68.75%] [G loss: 4.203208]\n",
      "epoch:28 step:21914 [D loss: 0.539188, acc: 75.78%] [G loss: 2.706226]\n",
      "epoch:28 step:21915 [D loss: 0.594287, acc: 61.72%] [G loss: 3.937132]\n",
      "epoch:28 step:21916 [D loss: 0.754819, acc: 53.12%] [G loss: 3.496787]\n",
      "epoch:28 step:21917 [D loss: 0.219020, acc: 96.88%] [G loss: 4.390502]\n",
      "epoch:28 step:21918 [D loss: 0.555932, acc: 64.84%] [G loss: 3.393017]\n",
      "epoch:28 step:21919 [D loss: 1.145892, acc: 23.44%] [G loss: 2.642114]\n",
      "epoch:28 step:21920 [D loss: 0.881236, acc: 45.31%] [G loss: 2.663733]\n",
      "epoch:28 step:21921 [D loss: 0.656406, acc: 61.72%] [G loss: 2.820748]\n",
      "epoch:28 step:21922 [D loss: 0.196476, acc: 97.66%] [G loss: 3.405852]\n",
      "epoch:28 step:21923 [D loss: 1.208987, acc: 35.94%] [G loss: 2.824167]\n",
      "epoch:28 step:21924 [D loss: 0.295517, acc: 96.09%] [G loss: 4.064752]\n",
      "epoch:28 step:21925 [D loss: 0.550630, acc: 57.03%] [G loss: 2.640853]\n",
      "epoch:28 step:21926 [D loss: 0.512641, acc: 60.16%] [G loss: 1.879488]\n",
      "epoch:28 step:21927 [D loss: 0.430123, acc: 76.56%] [G loss: 4.070523]\n",
      "epoch:28 step:21928 [D loss: 0.177081, acc: 99.22%] [G loss: 2.667258]\n",
      "epoch:28 step:21929 [D loss: 1.087360, acc: 37.50%] [G loss: 4.426785]\n",
      "epoch:28 step:21930 [D loss: 0.175419, acc: 98.44%] [G loss: 4.088780]\n",
      "epoch:28 step:21931 [D loss: 0.097190, acc: 100.00%] [G loss: 3.384440]\n",
      "epoch:28 step:21932 [D loss: 1.120322, acc: 25.00%] [G loss: 3.776124]\n",
      "epoch:28 step:21933 [D loss: 0.391634, acc: 77.34%] [G loss: 4.306000]\n",
      "epoch:28 step:21934 [D loss: 0.723722, acc: 57.03%] [G loss: 2.455854]\n",
      "epoch:28 step:21935 [D loss: 0.559282, acc: 67.97%] [G loss: 4.360540]\n",
      "epoch:28 step:21936 [D loss: 0.700087, acc: 54.69%] [G loss: 1.593309]\n",
      "epoch:28 step:21937 [D loss: 0.232731, acc: 99.22%] [G loss: 1.995621]\n",
      "epoch:28 step:21938 [D loss: 0.397694, acc: 77.34%] [G loss: 3.489697]\n",
      "epoch:28 step:21939 [D loss: 1.025464, acc: 50.78%] [G loss: 5.213529]\n",
      "epoch:28 step:21940 [D loss: 0.684466, acc: 52.34%] [G loss: 4.815819]\n",
      "epoch:28 step:21941 [D loss: 0.234132, acc: 96.88%] [G loss: 3.242622]\n",
      "epoch:28 step:21942 [D loss: 0.448294, acc: 71.88%] [G loss: 3.570479]\n",
      "epoch:28 step:21943 [D loss: 0.091568, acc: 100.00%] [G loss: 4.582571]\n",
      "epoch:28 step:21944 [D loss: 0.415009, acc: 78.12%] [G loss: 3.608750]\n",
      "epoch:28 step:21945 [D loss: 0.154093, acc: 99.22%] [G loss: 2.348683]\n",
      "epoch:28 step:21946 [D loss: 1.407481, acc: 28.91%] [G loss: 2.785692]\n",
      "epoch:28 step:21947 [D loss: 0.506419, acc: 78.91%] [G loss: 3.210834]\n",
      "epoch:28 step:21948 [D loss: 0.656184, acc: 60.94%] [G loss: 3.048550]\n",
      "epoch:28 step:21949 [D loss: 0.096916, acc: 100.00%] [G loss: 2.779762]\n",
      "epoch:28 step:21950 [D loss: 0.540834, acc: 60.94%] [G loss: 3.965034]\n",
      "epoch:28 step:21951 [D loss: 0.671241, acc: 58.59%] [G loss: 5.189226]\n",
      "epoch:28 step:21952 [D loss: 0.190436, acc: 100.00%] [G loss: 5.370866]\n",
      "epoch:28 step:21953 [D loss: 0.436713, acc: 70.31%] [G loss: 3.448531]\n",
      "epoch:28 step:21954 [D loss: 0.241167, acc: 95.31%] [G loss: 3.971999]\n",
      "epoch:28 step:21955 [D loss: 0.370277, acc: 85.94%] [G loss: 3.924095]\n",
      "epoch:28 step:21956 [D loss: 0.662161, acc: 62.50%] [G loss: 3.459483]\n",
      "epoch:28 step:21957 [D loss: 0.523505, acc: 67.19%] [G loss: 3.307305]\n",
      "epoch:28 step:21958 [D loss: 0.617375, acc: 67.19%] [G loss: 3.746006]\n",
      "epoch:28 step:21959 [D loss: 0.117229, acc: 100.00%] [G loss: 4.632882]\n",
      "epoch:28 step:21960 [D loss: 0.432402, acc: 78.12%] [G loss: 4.687979]\n",
      "epoch:28 step:21961 [D loss: 1.212352, acc: 50.00%] [G loss: 2.678840]\n",
      "epoch:28 step:21962 [D loss: 0.195723, acc: 100.00%] [G loss: 4.238868]\n",
      "epoch:28 step:21963 [D loss: 0.868966, acc: 50.00%] [G loss: 2.651826]\n",
      "epoch:28 step:21964 [D loss: 0.594758, acc: 64.06%] [G loss: 2.624796]\n",
      "epoch:28 step:21965 [D loss: 0.537547, acc: 72.66%] [G loss: 2.063334]\n",
      "epoch:28 step:21966 [D loss: 0.335460, acc: 96.88%] [G loss: 2.951185]\n",
      "epoch:28 step:21967 [D loss: 0.412640, acc: 76.56%] [G loss: 4.898868]\n",
      "epoch:28 step:21968 [D loss: 0.289484, acc: 90.62%] [G loss: 3.629224]\n",
      "epoch:28 step:21969 [D loss: 1.210232, acc: 14.84%] [G loss: 3.651206]\n",
      "epoch:28 step:21970 [D loss: 0.345838, acc: 88.28%] [G loss: 3.202404]\n",
      "epoch:28 step:21971 [D loss: 0.817390, acc: 42.97%] [G loss: 4.933138]\n",
      "epoch:28 step:21972 [D loss: 0.876532, acc: 48.44%] [G loss: 1.458511]\n",
      "epoch:28 step:21973 [D loss: 0.276453, acc: 88.28%] [G loss: 4.208501]\n",
      "epoch:28 step:21974 [D loss: 0.896925, acc: 39.84%] [G loss: 2.821550]\n",
      "epoch:28 step:21975 [D loss: 0.268642, acc: 86.72%] [G loss: 3.868211]\n",
      "epoch:28 step:21976 [D loss: 0.973008, acc: 27.34%] [G loss: 3.091085]\n",
      "epoch:28 step:21977 [D loss: 0.852144, acc: 34.38%] [G loss: 2.336835]\n",
      "epoch:28 step:21978 [D loss: 1.223695, acc: 17.19%] [G loss: 2.617549]\n",
      "epoch:28 step:21979 [D loss: 0.372379, acc: 88.28%] [G loss: 2.680344]\n",
      "epoch:28 step:21980 [D loss: 0.617822, acc: 66.41%] [G loss: 3.233836]\n",
      "epoch:28 step:21981 [D loss: 0.297265, acc: 90.62%] [G loss: 3.607446]\n",
      "epoch:28 step:21982 [D loss: 0.292266, acc: 96.09%] [G loss: 2.853716]\n",
      "epoch:28 step:21983 [D loss: 0.470977, acc: 82.03%] [G loss: 2.407161]\n",
      "epoch:28 step:21984 [D loss: 0.429006, acc: 89.06%] [G loss: 3.452512]\n",
      "epoch:28 step:21985 [D loss: 0.665507, acc: 59.38%] [G loss: 4.667272]\n",
      "epoch:28 step:21986 [D loss: 0.413668, acc: 84.38%] [G loss: 2.648675]\n",
      "epoch:28 step:21987 [D loss: 0.289715, acc: 89.84%] [G loss: 3.197801]\n",
      "epoch:28 step:21988 [D loss: 0.324617, acc: 93.75%] [G loss: 4.165669]\n",
      "epoch:28 step:21989 [D loss: 0.458106, acc: 85.94%] [G loss: 2.241384]\n",
      "epoch:28 step:21990 [D loss: 0.075821, acc: 100.00%] [G loss: 3.083311]\n",
      "epoch:28 step:21991 [D loss: 0.089610, acc: 100.00%] [G loss: 4.929693]\n",
      "epoch:28 step:21992 [D loss: 1.047995, acc: 22.66%] [G loss: 2.162716]\n",
      "epoch:28 step:21993 [D loss: 0.328760, acc: 93.75%] [G loss: 2.680052]\n",
      "epoch:28 step:21994 [D loss: 0.242657, acc: 98.44%] [G loss: 2.710905]\n",
      "epoch:28 step:21995 [D loss: 0.318155, acc: 82.81%] [G loss: 2.714757]\n",
      "epoch:28 step:21996 [D loss: 0.099701, acc: 100.00%] [G loss: 4.090257]\n",
      "epoch:28 step:21997 [D loss: 0.619462, acc: 64.84%] [G loss: 2.953817]\n",
      "epoch:28 step:21998 [D loss: 1.033632, acc: 35.94%] [G loss: 2.321846]\n",
      "epoch:28 step:21999 [D loss: 1.079644, acc: 43.75%] [G loss: 2.594641]\n",
      "epoch:28 step:22000 [D loss: 0.360695, acc: 91.41%] [G loss: 3.467257]\n",
      "epoch:28 step:22001 [D loss: 0.515060, acc: 73.44%] [G loss: 2.881234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22002 [D loss: 0.178889, acc: 99.22%] [G loss: 4.669680]\n",
      "epoch:28 step:22003 [D loss: 0.519020, acc: 66.41%] [G loss: 3.161839]\n",
      "epoch:28 step:22004 [D loss: 0.083349, acc: 100.00%] [G loss: 3.033967]\n",
      "epoch:28 step:22005 [D loss: 0.792514, acc: 50.78%] [G loss: 4.051870]\n",
      "epoch:28 step:22006 [D loss: 0.260173, acc: 92.97%] [G loss: 3.785719]\n",
      "epoch:28 step:22007 [D loss: 0.293473, acc: 92.19%] [G loss: 3.839193]\n",
      "epoch:28 step:22008 [D loss: 0.200182, acc: 98.44%] [G loss: 3.885143]\n",
      "epoch:28 step:22009 [D loss: 0.292615, acc: 98.44%] [G loss: 4.919142]\n",
      "epoch:28 step:22010 [D loss: 0.530013, acc: 68.75%] [G loss: 2.672330]\n",
      "epoch:28 step:22011 [D loss: 0.458704, acc: 79.69%] [G loss: 3.691499]\n",
      "epoch:28 step:22012 [D loss: 0.867062, acc: 35.94%] [G loss: 3.369611]\n",
      "epoch:28 step:22013 [D loss: 0.193751, acc: 100.00%] [G loss: 3.242612]\n",
      "epoch:28 step:22014 [D loss: 0.561316, acc: 64.84%] [G loss: 2.433082]\n",
      "epoch:28 step:22015 [D loss: 0.115340, acc: 100.00%] [G loss: 5.167603]\n",
      "epoch:28 step:22016 [D loss: 0.899653, acc: 46.09%] [G loss: 3.638486]\n",
      "epoch:28 step:22017 [D loss: 0.710560, acc: 53.91%] [G loss: 3.949448]\n",
      "epoch:28 step:22018 [D loss: 1.078390, acc: 46.88%] [G loss: 1.387692]\n",
      "epoch:28 step:22019 [D loss: 0.584641, acc: 71.88%] [G loss: 3.118632]\n",
      "epoch:28 step:22020 [D loss: 0.374279, acc: 85.94%] [G loss: 4.437874]\n",
      "epoch:28 step:22021 [D loss: 1.167366, acc: 17.97%] [G loss: 3.414117]\n",
      "epoch:28 step:22022 [D loss: 0.283969, acc: 89.84%] [G loss: 4.570462]\n",
      "epoch:28 step:22023 [D loss: 0.366687, acc: 84.38%] [G loss: 2.499996]\n",
      "epoch:28 step:22024 [D loss: 0.387879, acc: 92.19%] [G loss: 1.850650]\n",
      "epoch:28 step:22025 [D loss: 0.222203, acc: 96.09%] [G loss: 2.615589]\n",
      "epoch:28 step:22026 [D loss: 0.159502, acc: 99.22%] [G loss: 3.714552]\n",
      "epoch:28 step:22027 [D loss: 0.182975, acc: 98.44%] [G loss: 4.902080]\n",
      "epoch:28 step:22028 [D loss: 0.320653, acc: 91.41%] [G loss: 2.715751]\n",
      "epoch:28 step:22029 [D loss: 0.207530, acc: 96.09%] [G loss: 2.780907]\n",
      "epoch:28 step:22030 [D loss: 0.522645, acc: 75.78%] [G loss: 3.076040]\n",
      "epoch:28 step:22031 [D loss: 0.888810, acc: 50.00%] [G loss: 3.871903]\n",
      "epoch:28 step:22032 [D loss: 0.199136, acc: 96.09%] [G loss: 3.052815]\n",
      "epoch:28 step:22033 [D loss: 0.328113, acc: 96.09%] [G loss: 3.850224]\n",
      "epoch:28 step:22034 [D loss: 0.740946, acc: 54.69%] [G loss: 2.123801]\n",
      "epoch:28 step:22035 [D loss: 0.411646, acc: 84.38%] [G loss: 3.877491]\n",
      "epoch:28 step:22036 [D loss: 0.405449, acc: 80.47%] [G loss: 1.687772]\n",
      "epoch:28 step:22037 [D loss: 0.254594, acc: 97.66%] [G loss: 1.464802]\n",
      "epoch:28 step:22038 [D loss: 0.713208, acc: 53.12%] [G loss: 3.945507]\n",
      "epoch:28 step:22039 [D loss: 0.381964, acc: 93.75%] [G loss: 3.224903]\n",
      "epoch:28 step:22040 [D loss: 0.323005, acc: 92.19%] [G loss: 5.282726]\n",
      "epoch:28 step:22041 [D loss: 0.583742, acc: 64.84%] [G loss: 2.747034]\n",
      "epoch:28 step:22042 [D loss: 0.157554, acc: 99.22%] [G loss: 4.244294]\n",
      "epoch:28 step:22043 [D loss: 0.332455, acc: 89.06%] [G loss: 2.444581]\n",
      "epoch:28 step:22044 [D loss: 0.662898, acc: 54.69%] [G loss: 4.578870]\n",
      "epoch:28 step:22045 [D loss: 0.746808, acc: 52.34%] [G loss: 3.388627]\n",
      "epoch:28 step:22046 [D loss: 0.266626, acc: 95.31%] [G loss: 1.985985]\n",
      "epoch:28 step:22047 [D loss: 0.309098, acc: 90.62%] [G loss: 3.144538]\n",
      "epoch:28 step:22048 [D loss: 0.688806, acc: 58.59%] [G loss: 4.097159]\n",
      "epoch:28 step:22049 [D loss: 0.269401, acc: 95.31%] [G loss: 4.624235]\n",
      "epoch:28 step:22050 [D loss: 0.836714, acc: 46.09%] [G loss: 2.834347]\n",
      "epoch:28 step:22051 [D loss: 0.219263, acc: 97.66%] [G loss: 3.159088]\n",
      "epoch:28 step:22052 [D loss: 0.462950, acc: 76.56%] [G loss: 6.260285]\n",
      "epoch:28 step:22053 [D loss: 0.140415, acc: 99.22%] [G loss: 3.514179]\n",
      "epoch:28 step:22054 [D loss: 0.924289, acc: 33.59%] [G loss: 4.860450]\n",
      "epoch:28 step:22055 [D loss: 0.327400, acc: 93.75%] [G loss: 3.083828]\n",
      "epoch:28 step:22056 [D loss: 0.401778, acc: 86.72%] [G loss: 2.615049]\n",
      "epoch:28 step:22057 [D loss: 0.243058, acc: 95.31%] [G loss: 2.759029]\n",
      "epoch:28 step:22058 [D loss: 1.208221, acc: 35.94%] [G loss: 3.215948]\n",
      "epoch:28 step:22059 [D loss: 0.628174, acc: 62.50%] [G loss: 2.981886]\n",
      "epoch:28 step:22060 [D loss: 0.191638, acc: 97.66%] [G loss: 3.276115]\n",
      "epoch:28 step:22061 [D loss: 0.198995, acc: 96.09%] [G loss: 4.388702]\n",
      "epoch:28 step:22062 [D loss: 0.249774, acc: 96.09%] [G loss: 2.606266]\n",
      "epoch:28 step:22063 [D loss: 0.627797, acc: 62.50%] [G loss: 3.370643]\n",
      "epoch:28 step:22064 [D loss: 0.712994, acc: 55.47%] [G loss: 3.077996]\n",
      "epoch:28 step:22065 [D loss: 0.202882, acc: 97.66%] [G loss: 3.505565]\n",
      "epoch:28 step:22066 [D loss: 0.138470, acc: 100.00%] [G loss: 5.599334]\n",
      "epoch:28 step:22067 [D loss: 0.430848, acc: 82.03%] [G loss: 3.377613]\n",
      "epoch:28 step:22068 [D loss: 0.152623, acc: 98.44%] [G loss: 4.976522]\n",
      "epoch:28 step:22069 [D loss: 0.422583, acc: 78.91%] [G loss: 4.760950]\n",
      "epoch:28 step:22070 [D loss: 0.858205, acc: 51.56%] [G loss: 3.919016]\n",
      "epoch:28 step:22071 [D loss: 0.226860, acc: 98.44%] [G loss: 3.990521]\n",
      "epoch:28 step:22072 [D loss: 0.690164, acc: 59.38%] [G loss: 2.456374]\n",
      "epoch:28 step:22073 [D loss: 0.961493, acc: 36.72%] [G loss: 2.622132]\n",
      "epoch:28 step:22074 [D loss: 0.568386, acc: 67.97%] [G loss: 3.800820]\n",
      "epoch:28 step:22075 [D loss: 0.481110, acc: 64.06%] [G loss: 4.527256]\n",
      "epoch:28 step:22076 [D loss: 0.126587, acc: 99.22%] [G loss: 3.434735]\n",
      "epoch:28 step:22077 [D loss: 0.156388, acc: 100.00%] [G loss: 5.048559]\n",
      "epoch:28 step:22078 [D loss: 0.450600, acc: 89.84%] [G loss: 4.054681]\n",
      "epoch:28 step:22079 [D loss: 0.440047, acc: 85.94%] [G loss: 2.927044]\n",
      "epoch:28 step:22080 [D loss: 0.315210, acc: 93.75%] [G loss: 3.132868]\n",
      "epoch:28 step:22081 [D loss: 0.861593, acc: 40.62%] [G loss: 4.177969]\n",
      "epoch:28 step:22082 [D loss: 0.173137, acc: 99.22%] [G loss: 3.282001]\n",
      "epoch:28 step:22083 [D loss: 0.548038, acc: 74.22%] [G loss: 3.658003]\n",
      "epoch:28 step:22084 [D loss: 0.680412, acc: 56.25%] [G loss: 4.145376]\n",
      "epoch:28 step:22085 [D loss: 0.180234, acc: 100.00%] [G loss: 1.691762]\n",
      "epoch:28 step:22086 [D loss: 0.468630, acc: 75.78%] [G loss: 2.718319]\n",
      "epoch:28 step:22087 [D loss: 0.286008, acc: 96.09%] [G loss: 4.651883]\n",
      "epoch:28 step:22088 [D loss: 0.840350, acc: 51.56%] [G loss: 3.473847]\n",
      "epoch:28 step:22089 [D loss: 0.860689, acc: 44.53%] [G loss: 3.230489]\n",
      "epoch:28 step:22090 [D loss: 0.416176, acc: 78.91%] [G loss: 2.421250]\n",
      "epoch:28 step:22091 [D loss: 0.918442, acc: 41.41%] [G loss: 3.942827]\n",
      "epoch:28 step:22092 [D loss: 0.457766, acc: 78.12%] [G loss: 2.889973]\n",
      "epoch:28 step:22093 [D loss: 0.148931, acc: 99.22%] [G loss: 2.349172]\n",
      "epoch:28 step:22094 [D loss: 0.288053, acc: 90.62%] [G loss: 4.585334]\n",
      "epoch:28 step:22095 [D loss: 0.464669, acc: 71.88%] [G loss: 3.612668]\n",
      "epoch:28 step:22096 [D loss: 0.435980, acc: 84.38%] [G loss: 2.942554]\n",
      "epoch:28 step:22097 [D loss: 0.199364, acc: 97.66%] [G loss: 3.401692]\n",
      "epoch:28 step:22098 [D loss: 0.928146, acc: 42.19%] [G loss: 2.664984]\n",
      "epoch:28 step:22099 [D loss: 0.648159, acc: 56.25%] [G loss: 3.374696]\n",
      "epoch:28 step:22100 [D loss: 1.078493, acc: 30.47%] [G loss: 2.101569]\n",
      "epoch:28 step:22101 [D loss: 0.257973, acc: 96.09%] [G loss: 2.141752]\n",
      "epoch:28 step:22102 [D loss: 0.561531, acc: 64.84%] [G loss: 2.953216]\n",
      "epoch:28 step:22103 [D loss: 0.599146, acc: 73.44%] [G loss: 3.004726]\n",
      "epoch:28 step:22104 [D loss: 0.712505, acc: 56.25%] [G loss: 2.230846]\n",
      "epoch:28 step:22105 [D loss: 0.432078, acc: 84.38%] [G loss: 4.246929]\n",
      "epoch:28 step:22106 [D loss: 0.733185, acc: 50.78%] [G loss: 2.349265]\n",
      "epoch:28 step:22107 [D loss: 0.185968, acc: 99.22%] [G loss: 3.521670]\n",
      "epoch:28 step:22108 [D loss: 0.179519, acc: 99.22%] [G loss: 3.567833]\n",
      "epoch:28 step:22109 [D loss: 0.113290, acc: 100.00%] [G loss: 3.206977]\n",
      "epoch:28 step:22110 [D loss: 0.245995, acc: 99.22%] [G loss: 5.050586]\n",
      "epoch:28 step:22111 [D loss: 0.513143, acc: 67.97%] [G loss: 2.702715]\n",
      "epoch:28 step:22112 [D loss: 0.994799, acc: 43.75%] [G loss: 3.652061]\n",
      "epoch:28 step:22113 [D loss: 0.991438, acc: 27.34%] [G loss: 3.132296]\n",
      "epoch:28 step:22114 [D loss: 0.334231, acc: 89.06%] [G loss: 2.009648]\n",
      "epoch:28 step:22115 [D loss: 0.414353, acc: 76.56%] [G loss: 3.488756]\n",
      "epoch:28 step:22116 [D loss: 1.008921, acc: 49.22%] [G loss: 1.853218]\n",
      "epoch:28 step:22117 [D loss: 0.158969, acc: 99.22%] [G loss: 4.775263]\n",
      "epoch:28 step:22118 [D loss: 0.533442, acc: 67.97%] [G loss: 4.463717]\n",
      "epoch:28 step:22119 [D loss: 0.495006, acc: 80.47%] [G loss: 4.933489]\n",
      "epoch:28 step:22120 [D loss: 0.408177, acc: 88.28%] [G loss: 2.804148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22121 [D loss: 0.547014, acc: 58.59%] [G loss: 4.221100]\n",
      "epoch:28 step:22122 [D loss: 0.323567, acc: 95.31%] [G loss: 4.379568]\n",
      "epoch:28 step:22123 [D loss: 0.130956, acc: 99.22%] [G loss: 4.169608]\n",
      "epoch:28 step:22124 [D loss: 0.599532, acc: 66.41%] [G loss: 2.143795]\n",
      "epoch:28 step:22125 [D loss: 0.507512, acc: 67.97%] [G loss: 2.442449]\n",
      "epoch:28 step:22126 [D loss: 0.175779, acc: 99.22%] [G loss: 3.517819]\n",
      "epoch:28 step:22127 [D loss: 0.463453, acc: 65.62%] [G loss: 2.690985]\n",
      "epoch:28 step:22128 [D loss: 0.274806, acc: 96.88%] [G loss: 4.614944]\n",
      "epoch:28 step:22129 [D loss: 0.897279, acc: 45.31%] [G loss: 2.111220]\n",
      "epoch:28 step:22130 [D loss: 0.292607, acc: 94.53%] [G loss: 4.618070]\n",
      "epoch:28 step:22131 [D loss: 0.705863, acc: 56.25%] [G loss: 3.436805]\n",
      "epoch:28 step:22132 [D loss: 1.298115, acc: 8.59%] [G loss: 3.938137]\n",
      "epoch:28 step:22133 [D loss: 0.247749, acc: 96.09%] [G loss: 2.719825]\n",
      "epoch:28 step:22134 [D loss: 0.201738, acc: 98.44%] [G loss: 4.029989]\n",
      "epoch:28 step:22135 [D loss: 0.575648, acc: 71.88%] [G loss: 3.424190]\n",
      "epoch:28 step:22136 [D loss: 0.830631, acc: 42.19%] [G loss: 3.805931]\n",
      "epoch:28 step:22137 [D loss: 0.090532, acc: 99.22%] [G loss: 3.083310]\n",
      "epoch:28 step:22138 [D loss: 0.482775, acc: 78.12%] [G loss: 2.598552]\n",
      "epoch:28 step:22139 [D loss: 0.276125, acc: 94.53%] [G loss: 4.436107]\n",
      "epoch:28 step:22140 [D loss: 0.229545, acc: 96.09%] [G loss: 3.620661]\n",
      "epoch:28 step:22141 [D loss: 0.862242, acc: 39.84%] [G loss: 2.800402]\n",
      "epoch:28 step:22142 [D loss: 0.693512, acc: 55.47%] [G loss: 2.884467]\n",
      "epoch:28 step:22143 [D loss: 0.442043, acc: 71.09%] [G loss: 2.967095]\n",
      "epoch:28 step:22144 [D loss: 0.756853, acc: 47.66%] [G loss: 2.735250]\n",
      "epoch:28 step:22145 [D loss: 0.162918, acc: 100.00%] [G loss: 3.436342]\n",
      "epoch:28 step:22146 [D loss: 0.128712, acc: 99.22%] [G loss: 3.068964]\n",
      "epoch:28 step:22147 [D loss: 0.583876, acc: 67.19%] [G loss: 2.714292]\n",
      "epoch:28 step:22148 [D loss: 0.752182, acc: 50.00%] [G loss: 3.347162]\n",
      "epoch:28 step:22149 [D loss: 0.799867, acc: 46.88%] [G loss: 3.213596]\n",
      "epoch:28 step:22150 [D loss: 0.112307, acc: 100.00%] [G loss: 3.967585]\n",
      "epoch:28 step:22151 [D loss: 0.322251, acc: 88.28%] [G loss: 2.965321]\n",
      "epoch:28 step:22152 [D loss: 0.477443, acc: 70.31%] [G loss: 3.409717]\n",
      "epoch:28 step:22153 [D loss: 0.220986, acc: 95.31%] [G loss: 3.624839]\n",
      "epoch:28 step:22154 [D loss: 0.369664, acc: 83.59%] [G loss: 2.813771]\n",
      "epoch:28 step:22155 [D loss: 0.810874, acc: 50.00%] [G loss: 3.127690]\n",
      "epoch:28 step:22156 [D loss: 0.258090, acc: 96.88%] [G loss: 2.117364]\n",
      "epoch:28 step:22157 [D loss: 0.416611, acc: 75.78%] [G loss: 4.249166]\n",
      "epoch:28 step:22158 [D loss: 0.269432, acc: 95.31%] [G loss: 5.152138]\n",
      "epoch:28 step:22159 [D loss: 0.676877, acc: 60.16%] [G loss: 1.695133]\n",
      "epoch:28 step:22160 [D loss: 0.069119, acc: 100.00%] [G loss: 6.594706]\n",
      "epoch:28 step:22161 [D loss: 0.177662, acc: 100.00%] [G loss: 3.379590]\n",
      "epoch:28 step:22162 [D loss: 0.689487, acc: 54.69%] [G loss: 3.970181]\n",
      "epoch:28 step:22163 [D loss: 0.424778, acc: 82.03%] [G loss: 3.417796]\n",
      "epoch:28 step:22164 [D loss: 0.444132, acc: 68.75%] [G loss: 4.047516]\n",
      "epoch:28 step:22165 [D loss: 0.169489, acc: 100.00%] [G loss: 2.208111]\n",
      "epoch:28 step:22166 [D loss: 0.758909, acc: 52.34%] [G loss: 1.754586]\n",
      "epoch:28 step:22167 [D loss: 0.807591, acc: 46.88%] [G loss: 4.714708]\n",
      "epoch:28 step:22168 [D loss: 1.248428, acc: 46.09%] [G loss: 1.341734]\n",
      "epoch:28 step:22169 [D loss: 0.368799, acc: 85.94%] [G loss: 3.069079]\n",
      "epoch:28 step:22170 [D loss: 0.836368, acc: 39.84%] [G loss: 3.465852]\n",
      "epoch:28 step:22171 [D loss: 0.612285, acc: 54.69%] [G loss: 4.098556]\n",
      "epoch:28 step:22172 [D loss: 0.426254, acc: 77.34%] [G loss: 3.346723]\n",
      "epoch:28 step:22173 [D loss: 0.263014, acc: 95.31%] [G loss: 3.396357]\n",
      "epoch:28 step:22174 [D loss: 0.270482, acc: 93.75%] [G loss: 3.940035]\n",
      "epoch:28 step:22175 [D loss: 0.448729, acc: 87.50%] [G loss: 3.049616]\n",
      "epoch:28 step:22176 [D loss: 0.115780, acc: 100.00%] [G loss: 4.679935]\n",
      "epoch:28 step:22177 [D loss: 0.156647, acc: 99.22%] [G loss: 3.508795]\n",
      "epoch:28 step:22178 [D loss: 0.661327, acc: 56.25%] [G loss: 3.780779]\n",
      "epoch:28 step:22179 [D loss: 0.351659, acc: 89.84%] [G loss: 5.827450]\n",
      "epoch:28 step:22180 [D loss: 0.606294, acc: 66.41%] [G loss: 2.424019]\n",
      "epoch:28 step:22181 [D loss: 0.126058, acc: 98.44%] [G loss: 2.358019]\n",
      "epoch:28 step:22182 [D loss: 0.476082, acc: 67.19%] [G loss: 3.042935]\n",
      "epoch:28 step:22183 [D loss: 0.501170, acc: 78.91%] [G loss: 3.354497]\n",
      "epoch:28 step:22184 [D loss: 0.742736, acc: 47.66%] [G loss: 2.536915]\n",
      "epoch:28 step:22185 [D loss: 0.300782, acc: 96.09%] [G loss: 4.894914]\n",
      "epoch:28 step:22186 [D loss: 0.558265, acc: 75.78%] [G loss: 2.790456]\n",
      "epoch:28 step:22187 [D loss: 0.598135, acc: 71.88%] [G loss: 3.470101]\n",
      "epoch:28 step:22188 [D loss: 1.096815, acc: 17.19%] [G loss: 3.770203]\n",
      "epoch:28 step:22189 [D loss: 0.845608, acc: 37.50%] [G loss: 2.547396]\n",
      "epoch:28 step:22190 [D loss: 1.242976, acc: 18.75%] [G loss: 3.565599]\n",
      "epoch:28 step:22191 [D loss: 0.309469, acc: 88.28%] [G loss: 3.903540]\n",
      "epoch:28 step:22192 [D loss: 0.327225, acc: 89.06%] [G loss: 2.815799]\n",
      "epoch:28 step:22193 [D loss: 0.670268, acc: 57.03%] [G loss: 4.000006]\n",
      "epoch:28 step:22194 [D loss: 0.486882, acc: 63.28%] [G loss: 2.585835]\n",
      "epoch:28 step:22195 [D loss: 0.257285, acc: 94.53%] [G loss: 3.699756]\n",
      "epoch:28 step:22196 [D loss: 0.410497, acc: 90.62%] [G loss: 3.732797]\n",
      "epoch:28 step:22197 [D loss: 0.048323, acc: 100.00%] [G loss: 4.212545]\n",
      "epoch:28 step:22198 [D loss: 0.211049, acc: 97.66%] [G loss: 4.534042]\n",
      "epoch:28 step:22199 [D loss: 0.757029, acc: 50.78%] [G loss: 3.049063]\n",
      "epoch:28 step:22200 [D loss: 0.754541, acc: 52.34%] [G loss: 3.880723]\n",
      "epoch:28 step:22201 [D loss: 0.589900, acc: 62.50%] [G loss: 2.723623]\n",
      "epoch:28 step:22202 [D loss: 0.451483, acc: 75.78%] [G loss: 3.250579]\n",
      "epoch:28 step:22203 [D loss: 0.205387, acc: 99.22%] [G loss: 3.784205]\n",
      "epoch:28 step:22204 [D loss: 0.649496, acc: 63.28%] [G loss: 3.533055]\n",
      "epoch:28 step:22205 [D loss: 0.307735, acc: 94.53%] [G loss: 3.171498]\n",
      "epoch:28 step:22206 [D loss: 0.681513, acc: 55.47%] [G loss: 2.789424]\n",
      "epoch:28 step:22207 [D loss: 0.081337, acc: 100.00%] [G loss: 5.054318]\n",
      "epoch:28 step:22208 [D loss: 0.293252, acc: 93.75%] [G loss: 4.907417]\n",
      "epoch:28 step:22209 [D loss: 0.237664, acc: 94.53%] [G loss: 5.074879]\n",
      "epoch:28 step:22210 [D loss: 0.637444, acc: 61.72%] [G loss: 3.532479]\n",
      "epoch:28 step:22211 [D loss: 0.631250, acc: 60.16%] [G loss: 4.675997]\n",
      "epoch:28 step:22212 [D loss: 0.395748, acc: 89.84%] [G loss: 4.811931]\n",
      "epoch:28 step:22213 [D loss: 0.206662, acc: 96.88%] [G loss: 5.824073]\n",
      "epoch:28 step:22214 [D loss: 0.694113, acc: 54.69%] [G loss: 3.469394]\n",
      "epoch:28 step:22215 [D loss: 0.173468, acc: 100.00%] [G loss: 3.243404]\n",
      "epoch:28 step:22216 [D loss: 0.165040, acc: 100.00%] [G loss: 4.500639]\n",
      "epoch:28 step:22217 [D loss: 0.864684, acc: 36.72%] [G loss: 2.903667]\n",
      "epoch:28 step:22218 [D loss: 0.159984, acc: 100.00%] [G loss: 3.872480]\n",
      "epoch:28 step:22219 [D loss: 0.732208, acc: 50.00%] [G loss: 4.190010]\n",
      "epoch:28 step:22220 [D loss: 0.682081, acc: 58.59%] [G loss: 3.172971]\n",
      "epoch:28 step:22221 [D loss: 0.897883, acc: 48.44%] [G loss: 3.376031]\n",
      "epoch:28 step:22222 [D loss: 0.338428, acc: 89.06%] [G loss: 4.067093]\n",
      "epoch:28 step:22223 [D loss: 0.251680, acc: 96.88%] [G loss: 4.786109]\n",
      "epoch:28 step:22224 [D loss: 0.877988, acc: 50.78%] [G loss: 1.832933]\n",
      "epoch:28 step:22225 [D loss: 0.867963, acc: 50.00%] [G loss: 4.005093]\n",
      "epoch:28 step:22226 [D loss: 0.312106, acc: 82.81%] [G loss: 3.913626]\n",
      "epoch:28 step:22227 [D loss: 0.374548, acc: 79.69%] [G loss: 2.327389]\n",
      "epoch:28 step:22228 [D loss: 0.213345, acc: 94.53%] [G loss: 4.270221]\n",
      "epoch:28 step:22229 [D loss: 0.842912, acc: 49.22%] [G loss: 3.081414]\n",
      "epoch:28 step:22230 [D loss: 0.185092, acc: 99.22%] [G loss: 3.217001]\n",
      "epoch:28 step:22231 [D loss: 0.632813, acc: 66.41%] [G loss: 1.886226]\n",
      "epoch:28 step:22232 [D loss: 0.323814, acc: 87.50%] [G loss: 3.657956]\n",
      "epoch:28 step:22233 [D loss: 0.140055, acc: 99.22%] [G loss: 4.891652]\n",
      "epoch:28 step:22234 [D loss: 0.733181, acc: 51.56%] [G loss: 4.348880]\n",
      "epoch:28 step:22235 [D loss: 0.584027, acc: 64.06%] [G loss: 2.724906]\n",
      "epoch:28 step:22236 [D loss: 0.304113, acc: 95.31%] [G loss: 2.327856]\n",
      "epoch:28 step:22237 [D loss: 0.612587, acc: 66.41%] [G loss: 4.309232]\n",
      "epoch:28 step:22238 [D loss: 0.283449, acc: 95.31%] [G loss: 2.468750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22239 [D loss: 0.342466, acc: 92.19%] [G loss: 3.567322]\n",
      "epoch:28 step:22240 [D loss: 0.792206, acc: 46.09%] [G loss: 2.996830]\n",
      "epoch:28 step:22241 [D loss: 0.551098, acc: 67.97%] [G loss: 3.338689]\n",
      "epoch:28 step:22242 [D loss: 0.123374, acc: 100.00%] [G loss: 4.854485]\n",
      "epoch:28 step:22243 [D loss: 0.760596, acc: 46.88%] [G loss: 3.387158]\n",
      "epoch:28 step:22244 [D loss: 0.398722, acc: 82.81%] [G loss: 3.100224]\n",
      "epoch:28 step:22245 [D loss: 0.329567, acc: 94.53%] [G loss: 4.745288]\n",
      "epoch:28 step:22246 [D loss: 0.256730, acc: 98.44%] [G loss: 3.515022]\n",
      "epoch:28 step:22247 [D loss: 0.154208, acc: 100.00%] [G loss: 5.059571]\n",
      "epoch:28 step:22248 [D loss: 0.238427, acc: 96.88%] [G loss: 3.375554]\n",
      "epoch:28 step:22249 [D loss: 0.523385, acc: 71.09%] [G loss: 2.809938]\n",
      "epoch:28 step:22250 [D loss: 0.204096, acc: 97.66%] [G loss: 2.559215]\n",
      "epoch:28 step:22251 [D loss: 0.772163, acc: 50.78%] [G loss: 3.245960]\n",
      "epoch:28 step:22252 [D loss: 0.570402, acc: 65.62%] [G loss: 2.374172]\n",
      "epoch:28 step:22253 [D loss: 0.362445, acc: 90.62%] [G loss: 4.160917]\n",
      "epoch:28 step:22254 [D loss: 0.574551, acc: 62.50%] [G loss: 3.371402]\n",
      "epoch:28 step:22255 [D loss: 0.319885, acc: 87.50%] [G loss: 3.187364]\n",
      "epoch:28 step:22256 [D loss: 0.326770, acc: 89.06%] [G loss: 1.889181]\n",
      "epoch:28 step:22257 [D loss: 0.351914, acc: 93.75%] [G loss: 3.887894]\n",
      "epoch:28 step:22258 [D loss: 0.403464, acc: 91.41%] [G loss: 3.044961]\n",
      "epoch:28 step:22259 [D loss: 0.473988, acc: 83.59%] [G loss: 3.063626]\n",
      "epoch:28 step:22260 [D loss: 0.496488, acc: 77.34%] [G loss: 3.845546]\n",
      "epoch:28 step:22261 [D loss: 0.651772, acc: 59.38%] [G loss: 3.506304]\n",
      "epoch:28 step:22262 [D loss: 0.098136, acc: 100.00%] [G loss: 3.150923]\n",
      "epoch:28 step:22263 [D loss: 0.798412, acc: 49.22%] [G loss: 3.193228]\n",
      "epoch:28 step:22264 [D loss: 0.656481, acc: 57.03%] [G loss: 4.204022]\n",
      "epoch:28 step:22265 [D loss: 0.623509, acc: 61.72%] [G loss: 1.865116]\n",
      "epoch:28 step:22266 [D loss: 0.479522, acc: 83.59%] [G loss: 2.807346]\n",
      "epoch:28 step:22267 [D loss: 0.266621, acc: 96.88%] [G loss: 3.667560]\n",
      "epoch:28 step:22268 [D loss: 0.428978, acc: 88.28%] [G loss: 5.097873]\n",
      "epoch:28 step:22269 [D loss: 0.691968, acc: 54.69%] [G loss: 4.175136]\n",
      "epoch:28 step:22270 [D loss: 0.267265, acc: 99.22%] [G loss: 3.233945]\n",
      "epoch:28 step:22271 [D loss: 0.795716, acc: 51.56%] [G loss: 3.519246]\n",
      "epoch:28 step:22272 [D loss: 0.688764, acc: 60.94%] [G loss: 3.515178]\n",
      "epoch:28 step:22273 [D loss: 0.428114, acc: 89.06%] [G loss: 5.406310]\n",
      "epoch:28 step:22274 [D loss: 0.791190, acc: 52.34%] [G loss: 3.435875]\n",
      "epoch:28 step:22275 [D loss: 0.541921, acc: 73.44%] [G loss: 2.673207]\n",
      "epoch:28 step:22276 [D loss: 0.377019, acc: 80.47%] [G loss: 5.072268]\n",
      "epoch:28 step:22277 [D loss: 0.509045, acc: 79.69%] [G loss: 3.959480]\n",
      "epoch:28 step:22278 [D loss: 0.418908, acc: 78.91%] [G loss: 3.284319]\n",
      "epoch:28 step:22279 [D loss: 0.267518, acc: 95.31%] [G loss: 3.110338]\n",
      "epoch:28 step:22280 [D loss: 0.136223, acc: 100.00%] [G loss: 3.963559]\n",
      "epoch:28 step:22281 [D loss: 0.396117, acc: 80.47%] [G loss: 4.374458]\n",
      "epoch:28 step:22282 [D loss: 0.244505, acc: 96.88%] [G loss: 3.463579]\n",
      "epoch:28 step:22283 [D loss: 0.647481, acc: 56.25%] [G loss: 4.371560]\n",
      "epoch:28 step:22284 [D loss: 0.513044, acc: 78.12%] [G loss: 3.269257]\n",
      "epoch:28 step:22285 [D loss: 0.459960, acc: 84.38%] [G loss: 3.269027]\n",
      "epoch:28 step:22286 [D loss: 0.484741, acc: 85.94%] [G loss: 3.519854]\n",
      "epoch:28 step:22287 [D loss: 0.510526, acc: 77.34%] [G loss: 3.733443]\n",
      "epoch:28 step:22288 [D loss: 0.359475, acc: 95.31%] [G loss: 3.115626]\n",
      "epoch:28 step:22289 [D loss: 0.297268, acc: 96.88%] [G loss: 4.018182]\n",
      "epoch:28 step:22290 [D loss: 0.167002, acc: 99.22%] [G loss: 4.423153]\n",
      "epoch:28 step:22291 [D loss: 0.427286, acc: 89.84%] [G loss: 3.296028]\n",
      "epoch:28 step:22292 [D loss: 1.038767, acc: 40.62%] [G loss: 1.659949]\n",
      "epoch:28 step:22293 [D loss: 0.736172, acc: 51.56%] [G loss: 3.448578]\n",
      "epoch:28 step:22294 [D loss: 0.377857, acc: 90.62%] [G loss: 4.289676]\n",
      "epoch:28 step:22295 [D loss: 0.423728, acc: 89.06%] [G loss: 2.235100]\n",
      "epoch:28 step:22296 [D loss: 0.340778, acc: 92.97%] [G loss: 4.050477]\n",
      "epoch:28 step:22297 [D loss: 0.094239, acc: 100.00%] [G loss: 3.935362]\n",
      "epoch:28 step:22298 [D loss: 0.104596, acc: 100.00%] [G loss: 5.259639]\n",
      "epoch:28 step:22299 [D loss: 0.336173, acc: 91.41%] [G loss: 3.161090]\n",
      "epoch:28 step:22300 [D loss: 0.143613, acc: 100.00%] [G loss: 4.596133]\n",
      "epoch:28 step:22301 [D loss: 0.160682, acc: 98.44%] [G loss: 4.723382]\n",
      "epoch:28 step:22302 [D loss: 0.030521, acc: 100.00%] [G loss: 5.053953]\n",
      "epoch:28 step:22303 [D loss: 0.284447, acc: 96.88%] [G loss: 4.974160]\n",
      "epoch:28 step:22304 [D loss: 0.913475, acc: 36.72%] [G loss: 4.108085]\n",
      "epoch:28 step:22305 [D loss: 0.754457, acc: 51.56%] [G loss: 2.425125]\n",
      "epoch:28 step:22306 [D loss: 0.319450, acc: 94.53%] [G loss: 4.632699]\n",
      "epoch:28 step:22307 [D loss: 0.715984, acc: 55.47%] [G loss: 5.140606]\n",
      "epoch:28 step:22308 [D loss: 0.439661, acc: 75.00%] [G loss: 4.106754]\n",
      "epoch:28 step:22309 [D loss: 0.340838, acc: 96.09%] [G loss: 2.623362]\n",
      "epoch:28 step:22310 [D loss: 0.540299, acc: 69.53%] [G loss: 3.596645]\n",
      "epoch:28 step:22311 [D loss: 0.205090, acc: 96.09%] [G loss: 5.640248]\n",
      "epoch:28 step:22312 [D loss: 0.696741, acc: 59.38%] [G loss: 4.568553]\n",
      "epoch:28 step:22313 [D loss: 1.139646, acc: 50.00%] [G loss: 4.680296]\n",
      "epoch:28 step:22314 [D loss: 0.098534, acc: 100.00%] [G loss: 4.367906]\n",
      "epoch:28 step:22315 [D loss: 0.495567, acc: 64.84%] [G loss: 4.506874]\n",
      "epoch:28 step:22316 [D loss: 0.670730, acc: 57.03%] [G loss: 2.195650]\n",
      "epoch:28 step:22317 [D loss: 0.590156, acc: 60.94%] [G loss: 3.223137]\n",
      "epoch:28 step:22318 [D loss: 0.461254, acc: 82.81%] [G loss: 3.250135]\n",
      "epoch:28 step:22319 [D loss: 0.562874, acc: 71.88%] [G loss: 4.051117]\n",
      "epoch:28 step:22320 [D loss: 0.455535, acc: 75.00%] [G loss: 1.909433]\n",
      "epoch:28 step:22321 [D loss: 0.331287, acc: 93.75%] [G loss: 3.114911]\n",
      "epoch:28 step:22322 [D loss: 0.447017, acc: 80.47%] [G loss: 4.406891]\n",
      "epoch:28 step:22323 [D loss: 0.223680, acc: 99.22%] [G loss: 4.148091]\n",
      "epoch:28 step:22324 [D loss: 0.188019, acc: 99.22%] [G loss: 2.901958]\n",
      "epoch:28 step:22325 [D loss: 0.322435, acc: 92.19%] [G loss: 3.534342]\n",
      "epoch:28 step:22326 [D loss: 0.657707, acc: 54.69%] [G loss: 5.390740]\n",
      "epoch:28 step:22327 [D loss: 0.357031, acc: 87.50%] [G loss: 3.343954]\n",
      "epoch:28 step:22328 [D loss: 0.267093, acc: 92.97%] [G loss: 3.709837]\n",
      "epoch:28 step:22329 [D loss: 0.283665, acc: 93.75%] [G loss: 2.331685]\n",
      "epoch:28 step:22330 [D loss: 0.585721, acc: 66.41%] [G loss: 3.786099]\n",
      "epoch:28 step:22331 [D loss: 0.337768, acc: 97.66%] [G loss: 2.337955]\n",
      "epoch:28 step:22332 [D loss: 0.036859, acc: 100.00%] [G loss: 4.562703]\n",
      "epoch:28 step:22333 [D loss: 0.204706, acc: 97.66%] [G loss: 4.889557]\n",
      "epoch:28 step:22334 [D loss: 0.103074, acc: 100.00%] [G loss: 5.633203]\n",
      "epoch:28 step:22335 [D loss: 0.808544, acc: 47.66%] [G loss: 2.898378]\n",
      "epoch:28 step:22336 [D loss: 0.710405, acc: 57.03%] [G loss: 1.744336]\n",
      "epoch:28 step:22337 [D loss: 0.208342, acc: 96.88%] [G loss: 3.827507]\n",
      "epoch:28 step:22338 [D loss: 0.720344, acc: 52.34%] [G loss: 2.270888]\n",
      "epoch:28 step:22339 [D loss: 0.999163, acc: 28.91%] [G loss: 2.321722]\n",
      "epoch:28 step:22340 [D loss: 0.480432, acc: 82.81%] [G loss: 5.004823]\n",
      "epoch:28 step:22341 [D loss: 0.225769, acc: 95.31%] [G loss: 3.564156]\n",
      "epoch:28 step:22342 [D loss: 0.942212, acc: 49.22%] [G loss: 3.361727]\n",
      "epoch:28 step:22343 [D loss: 0.277200, acc: 95.31%] [G loss: 1.908535]\n",
      "epoch:28 step:22344 [D loss: 0.414811, acc: 85.94%] [G loss: 5.685906]\n",
      "epoch:28 step:22345 [D loss: 0.230062, acc: 96.88%] [G loss: 4.657873]\n",
      "epoch:28 step:22346 [D loss: 0.214111, acc: 95.31%] [G loss: 3.624757]\n",
      "epoch:28 step:22347 [D loss: 0.644127, acc: 62.50%] [G loss: 3.225250]\n",
      "epoch:28 step:22348 [D loss: 0.524786, acc: 70.31%] [G loss: 2.969505]\n",
      "epoch:28 step:22349 [D loss: 1.413434, acc: 36.72%] [G loss: 2.675644]\n",
      "epoch:28 step:22350 [D loss: 1.095374, acc: 48.44%] [G loss: 2.579912]\n",
      "epoch:28 step:22351 [D loss: 1.321274, acc: 22.66%] [G loss: 2.807421]\n",
      "epoch:28 step:22352 [D loss: 0.580500, acc: 62.50%] [G loss: 3.176286]\n",
      "epoch:28 step:22353 [D loss: 0.209424, acc: 96.88%] [G loss: 3.018378]\n",
      "epoch:28 step:22354 [D loss: 0.306293, acc: 92.19%] [G loss: 3.015665]\n",
      "epoch:28 step:22355 [D loss: 0.205302, acc: 97.66%] [G loss: 3.915894]\n",
      "epoch:28 step:22356 [D loss: 0.777218, acc: 46.09%] [G loss: 2.126268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22357 [D loss: 0.398985, acc: 88.28%] [G loss: 3.579640]\n",
      "epoch:28 step:22358 [D loss: 0.305423, acc: 91.41%] [G loss: 4.455644]\n",
      "epoch:28 step:22359 [D loss: 0.403213, acc: 86.72%] [G loss: 3.634386]\n",
      "epoch:28 step:22360 [D loss: 1.064275, acc: 22.66%] [G loss: 5.258241]\n",
      "epoch:28 step:22361 [D loss: 0.358601, acc: 90.62%] [G loss: 3.252002]\n",
      "epoch:28 step:22362 [D loss: 0.464118, acc: 85.16%] [G loss: 3.024561]\n",
      "epoch:28 step:22363 [D loss: 0.517612, acc: 66.41%] [G loss: 3.357235]\n",
      "epoch:28 step:22364 [D loss: 0.147398, acc: 99.22%] [G loss: 6.739379]\n",
      "epoch:28 step:22365 [D loss: 0.498924, acc: 67.19%] [G loss: 3.905410]\n",
      "epoch:28 step:22366 [D loss: 0.406336, acc: 75.00%] [G loss: 4.476636]\n",
      "epoch:28 step:22367 [D loss: 0.326479, acc: 95.31%] [G loss: 5.093968]\n",
      "epoch:28 step:22368 [D loss: 1.004494, acc: 46.09%] [G loss: 3.740178]\n",
      "epoch:28 step:22369 [D loss: 0.212841, acc: 94.53%] [G loss: 3.804149]\n",
      "epoch:28 step:22370 [D loss: 0.310825, acc: 88.28%] [G loss: 4.030332]\n",
      "epoch:28 step:22371 [D loss: 0.454136, acc: 85.94%] [G loss: 3.449198]\n",
      "epoch:28 step:22372 [D loss: 0.138590, acc: 99.22%] [G loss: 3.644303]\n",
      "epoch:28 step:22373 [D loss: 0.445877, acc: 78.12%] [G loss: 2.915906]\n",
      "epoch:28 step:22374 [D loss: 0.099938, acc: 100.00%] [G loss: 3.509881]\n",
      "epoch:28 step:22375 [D loss: 1.008240, acc: 37.50%] [G loss: 3.333376]\n",
      "epoch:28 step:22376 [D loss: 0.191600, acc: 98.44%] [G loss: 5.123755]\n",
      "epoch:28 step:22377 [D loss: 0.318339, acc: 89.06%] [G loss: 5.713106]\n",
      "epoch:28 step:22378 [D loss: 0.321815, acc: 94.53%] [G loss: 2.898459]\n",
      "epoch:28 step:22379 [D loss: 0.085171, acc: 100.00%] [G loss: 5.825633]\n",
      "epoch:28 step:22380 [D loss: 0.398275, acc: 88.28%] [G loss: 5.366634]\n",
      "epoch:28 step:22381 [D loss: 0.896697, acc: 37.50%] [G loss: 4.696342]\n",
      "epoch:28 step:22382 [D loss: 0.486474, acc: 77.34%] [G loss: 3.445413]\n",
      "epoch:28 step:22383 [D loss: 0.107827, acc: 100.00%] [G loss: 5.239669]\n",
      "epoch:28 step:22384 [D loss: 0.214331, acc: 97.66%] [G loss: 3.706731]\n",
      "epoch:28 step:22385 [D loss: 0.229612, acc: 94.53%] [G loss: 4.169726]\n",
      "epoch:28 step:22386 [D loss: 0.508696, acc: 68.75%] [G loss: 3.095685]\n",
      "epoch:28 step:22387 [D loss: 1.327557, acc: 19.53%] [G loss: 5.129858]\n",
      "epoch:28 step:22388 [D loss: 0.601408, acc: 65.62%] [G loss: 3.262086]\n",
      "epoch:28 step:22389 [D loss: 0.421468, acc: 85.94%] [G loss: 3.902404]\n",
      "epoch:28 step:22390 [D loss: 1.148741, acc: 46.88%] [G loss: 3.297645]\n",
      "epoch:28 step:22391 [D loss: 0.278827, acc: 89.84%] [G loss: 4.913329]\n",
      "epoch:28 step:22392 [D loss: 0.505431, acc: 68.75%] [G loss: 4.483571]\n",
      "epoch:28 step:22393 [D loss: 0.359727, acc: 91.41%] [G loss: 3.160309]\n",
      "epoch:28 step:22394 [D loss: 0.678461, acc: 55.47%] [G loss: 3.993388]\n",
      "epoch:28 step:22395 [D loss: 0.245163, acc: 97.66%] [G loss: 2.864875]\n",
      "epoch:28 step:22396 [D loss: 0.096634, acc: 100.00%] [G loss: 3.774360]\n",
      "epoch:28 step:22397 [D loss: 0.677502, acc: 63.28%] [G loss: 5.360771]\n",
      "epoch:28 step:22398 [D loss: 0.502590, acc: 76.56%] [G loss: 4.683670]\n",
      "epoch:28 step:22399 [D loss: 0.147141, acc: 100.00%] [G loss: 3.823905]\n",
      "epoch:28 step:22400 [D loss: 0.320092, acc: 92.19%] [G loss: 5.055435]\n",
      "epoch:28 step:22401 [D loss: 0.625453, acc: 68.75%] [G loss: 4.381836]\n",
      "epoch:28 step:22402 [D loss: 0.171593, acc: 97.66%] [G loss: 5.331898]\n",
      "epoch:28 step:22403 [D loss: 0.176404, acc: 97.66%] [G loss: 5.364025]\n",
      "epoch:28 step:22404 [D loss: 0.509098, acc: 78.91%] [G loss: 4.771847]\n",
      "epoch:28 step:22405 [D loss: 0.232762, acc: 92.97%] [G loss: 3.521832]\n",
      "epoch:28 step:22406 [D loss: 0.659905, acc: 60.94%] [G loss: 3.328647]\n",
      "epoch:28 step:22407 [D loss: 0.581814, acc: 64.06%] [G loss: 4.051688]\n",
      "epoch:28 step:22408 [D loss: 1.214016, acc: 14.84%] [G loss: 2.626437]\n",
      "epoch:28 step:22409 [D loss: 0.533953, acc: 71.09%] [G loss: 3.369740]\n",
      "epoch:28 step:22410 [D loss: 0.191464, acc: 96.09%] [G loss: 2.201685]\n",
      "epoch:28 step:22411 [D loss: 0.347907, acc: 86.72%] [G loss: 3.990148]\n",
      "epoch:28 step:22412 [D loss: 0.293322, acc: 94.53%] [G loss: 3.871073]\n",
      "epoch:28 step:22413 [D loss: 0.099836, acc: 100.00%] [G loss: 3.897019]\n",
      "epoch:28 step:22414 [D loss: 0.615522, acc: 63.28%] [G loss: 3.599151]\n",
      "epoch:28 step:22415 [D loss: 0.191058, acc: 98.44%] [G loss: 3.261473]\n",
      "epoch:28 step:22416 [D loss: 0.921601, acc: 35.16%] [G loss: 2.066967]\n",
      "epoch:28 step:22417 [D loss: 0.413100, acc: 86.72%] [G loss: 3.300278]\n",
      "epoch:28 step:22418 [D loss: 0.565530, acc: 67.19%] [G loss: 3.518290]\n",
      "epoch:28 step:22419 [D loss: 0.180223, acc: 100.00%] [G loss: 4.257673]\n",
      "epoch:28 step:22420 [D loss: 0.395100, acc: 75.78%] [G loss: 4.374918]\n",
      "epoch:28 step:22421 [D loss: 0.549177, acc: 68.75%] [G loss: 2.722379]\n",
      "epoch:28 step:22422 [D loss: 0.184195, acc: 96.88%] [G loss: 3.203069]\n",
      "epoch:28 step:22423 [D loss: 0.175729, acc: 100.00%] [G loss: 4.789004]\n",
      "epoch:28 step:22424 [D loss: 0.658192, acc: 57.03%] [G loss: 4.746494]\n",
      "epoch:28 step:22425 [D loss: 0.213576, acc: 94.53%] [G loss: 3.171206]\n",
      "epoch:28 step:22426 [D loss: 0.797814, acc: 47.66%] [G loss: 2.092170]\n",
      "epoch:28 step:22427 [D loss: 0.180603, acc: 98.44%] [G loss: 4.688850]\n",
      "epoch:28 step:22428 [D loss: 0.175094, acc: 100.00%] [G loss: 2.725306]\n",
      "epoch:28 step:22429 [D loss: 0.434059, acc: 84.38%] [G loss: 3.455944]\n",
      "epoch:28 step:22430 [D loss: 0.212162, acc: 98.44%] [G loss: 2.197416]\n",
      "epoch:28 step:22431 [D loss: 0.248010, acc: 97.66%] [G loss: 3.317230]\n",
      "epoch:28 step:22432 [D loss: 0.173741, acc: 97.66%] [G loss: 3.658628]\n",
      "epoch:28 step:22433 [D loss: 0.169688, acc: 98.44%] [G loss: 4.950034]\n",
      "epoch:28 step:22434 [D loss: 0.804413, acc: 50.00%] [G loss: 3.113131]\n",
      "epoch:28 step:22435 [D loss: 1.114461, acc: 15.62%] [G loss: 3.288374]\n",
      "epoch:28 step:22436 [D loss: 1.488623, acc: 46.09%] [G loss: 3.651890]\n",
      "epoch:28 step:22437 [D loss: 0.076243, acc: 100.00%] [G loss: 5.207884]\n",
      "epoch:28 step:22438 [D loss: 0.454529, acc: 79.69%] [G loss: 2.382018]\n",
      "epoch:28 step:22439 [D loss: 0.479374, acc: 76.56%] [G loss: 4.306961]\n",
      "epoch:28 step:22440 [D loss: 0.893932, acc: 28.12%] [G loss: 4.386715]\n",
      "epoch:28 step:22441 [D loss: 1.129563, acc: 19.53%] [G loss: 4.296476]\n",
      "epoch:28 step:22442 [D loss: 0.553133, acc: 64.84%] [G loss: 3.524927]\n",
      "epoch:28 step:22443 [D loss: 1.526834, acc: 44.53%] [G loss: 4.449903]\n",
      "epoch:28 step:22444 [D loss: 0.669120, acc: 62.50%] [G loss: 3.523353]\n",
      "epoch:28 step:22445 [D loss: 0.473611, acc: 86.72%] [G loss: 3.882639]\n",
      "epoch:28 step:22446 [D loss: 0.547879, acc: 74.22%] [G loss: 3.744312]\n",
      "epoch:28 step:22447 [D loss: 0.197615, acc: 98.44%] [G loss: 3.300112]\n",
      "epoch:28 step:22448 [D loss: 0.614668, acc: 64.84%] [G loss: 2.528897]\n",
      "epoch:28 step:22449 [D loss: 0.108001, acc: 100.00%] [G loss: 7.082682]\n",
      "epoch:28 step:22450 [D loss: 0.320454, acc: 87.50%] [G loss: 3.691287]\n",
      "epoch:28 step:22451 [D loss: 1.051452, acc: 19.53%] [G loss: 3.171103]\n",
      "epoch:28 step:22452 [D loss: 0.428917, acc: 87.50%] [G loss: 2.979244]\n",
      "epoch:28 step:22453 [D loss: 0.316888, acc: 81.25%] [G loss: 6.254855]\n",
      "epoch:28 step:22454 [D loss: 0.609973, acc: 64.06%] [G loss: 3.722598]\n",
      "epoch:28 step:22455 [D loss: 0.242661, acc: 93.75%] [G loss: 5.750053]\n",
      "epoch:28 step:22456 [D loss: 0.242043, acc: 93.75%] [G loss: 4.435904]\n",
      "epoch:28 step:22457 [D loss: 0.963686, acc: 32.81%] [G loss: 2.573785]\n",
      "epoch:28 step:22458 [D loss: 0.503424, acc: 70.31%] [G loss: 5.676730]\n",
      "epoch:28 step:22459 [D loss: 0.727555, acc: 58.59%] [G loss: 2.972524]\n",
      "epoch:28 step:22460 [D loss: 0.538742, acc: 60.94%] [G loss: 4.169337]\n",
      "epoch:28 step:22461 [D loss: 0.058289, acc: 100.00%] [G loss: 4.399375]\n",
      "epoch:28 step:22462 [D loss: 0.655656, acc: 63.28%] [G loss: 3.571454]\n",
      "epoch:28 step:22463 [D loss: 0.281630, acc: 87.50%] [G loss: 3.959568]\n",
      "epoch:28 step:22464 [D loss: 0.868955, acc: 50.78%] [G loss: 2.954165]\n",
      "epoch:28 step:22465 [D loss: 1.242250, acc: 17.97%] [G loss: 4.058422]\n",
      "epoch:28 step:22466 [D loss: 0.153256, acc: 99.22%] [G loss: 2.227375]\n",
      "epoch:28 step:22467 [D loss: 0.727275, acc: 55.47%] [G loss: 3.491915]\n",
      "epoch:28 step:22468 [D loss: 0.562766, acc: 66.41%] [G loss: 4.079289]\n",
      "epoch:28 step:22469 [D loss: 0.730742, acc: 56.25%] [G loss: 2.653637]\n",
      "epoch:28 step:22470 [D loss: 0.322562, acc: 91.41%] [G loss: 3.951030]\n",
      "epoch:28 step:22471 [D loss: 0.314971, acc: 84.38%] [G loss: 3.319178]\n",
      "epoch:28 step:22472 [D loss: 0.458525, acc: 77.34%] [G loss: 3.977933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22473 [D loss: 0.356370, acc: 88.28%] [G loss: 2.652393]\n",
      "epoch:28 step:22474 [D loss: 0.201333, acc: 98.44%] [G loss: 3.595123]\n",
      "epoch:28 step:22475 [D loss: 1.084867, acc: 50.00%] [G loss: 5.574575]\n",
      "epoch:28 step:22476 [D loss: 0.525618, acc: 68.75%] [G loss: 2.317265]\n",
      "epoch:28 step:22477 [D loss: 0.138284, acc: 99.22%] [G loss: 3.081795]\n",
      "epoch:28 step:22478 [D loss: 0.523160, acc: 78.12%] [G loss: 2.614443]\n",
      "epoch:28 step:22479 [D loss: 0.298527, acc: 85.16%] [G loss: 3.891628]\n",
      "epoch:28 step:22480 [D loss: 0.438817, acc: 84.38%] [G loss: 2.120790]\n",
      "epoch:28 step:22481 [D loss: 0.381921, acc: 90.62%] [G loss: 2.696601]\n",
      "epoch:28 step:22482 [D loss: 0.245425, acc: 98.44%] [G loss: 3.250532]\n",
      "epoch:28 step:22483 [D loss: 0.429977, acc: 81.25%] [G loss: 2.697966]\n",
      "epoch:28 step:22484 [D loss: 0.548547, acc: 67.19%] [G loss: 3.097923]\n",
      "epoch:28 step:22485 [D loss: 0.482619, acc: 79.69%] [G loss: 2.235186]\n",
      "epoch:28 step:22486 [D loss: 1.487274, acc: 7.03%] [G loss: 2.676655]\n",
      "epoch:28 step:22487 [D loss: 0.336072, acc: 85.94%] [G loss: 3.154952]\n",
      "epoch:28 step:22488 [D loss: 0.772249, acc: 49.22%] [G loss: 3.185187]\n",
      "epoch:28 step:22489 [D loss: 0.336643, acc: 82.03%] [G loss: 2.584213]\n",
      "epoch:28 step:22490 [D loss: 0.424655, acc: 90.62%] [G loss: 3.708006]\n",
      "epoch:28 step:22491 [D loss: 0.400046, acc: 87.50%] [G loss: 4.391588]\n",
      "epoch:28 step:22492 [D loss: 0.358037, acc: 93.75%] [G loss: 2.603685]\n",
      "epoch:28 step:22493 [D loss: 0.411546, acc: 85.16%] [G loss: 4.012560]\n",
      "epoch:28 step:22494 [D loss: 0.471140, acc: 75.00%] [G loss: 3.150543]\n",
      "epoch:28 step:22495 [D loss: 1.005849, acc: 28.12%] [G loss: 4.203113]\n",
      "epoch:28 step:22496 [D loss: 0.623411, acc: 64.06%] [G loss: 2.678940]\n",
      "epoch:28 step:22497 [D loss: 0.523292, acc: 75.78%] [G loss: 3.194306]\n",
      "epoch:28 step:22498 [D loss: 0.146220, acc: 98.44%] [G loss: 3.195081]\n",
      "epoch:28 step:22499 [D loss: 0.628292, acc: 64.06%] [G loss: 3.190117]\n",
      "epoch:28 step:22500 [D loss: 1.078784, acc: 35.94%] [G loss: 4.081726]\n",
      "epoch:28 step:22501 [D loss: 0.771602, acc: 54.69%] [G loss: 2.654588]\n",
      "epoch:28 step:22502 [D loss: 0.793229, acc: 42.19%] [G loss: 2.744156]\n",
      "epoch:28 step:22503 [D loss: 0.389044, acc: 94.53%] [G loss: 3.697738]\n",
      "epoch:28 step:22504 [D loss: 0.481263, acc: 71.88%] [G loss: 4.370411]\n",
      "epoch:28 step:22505 [D loss: 0.161809, acc: 98.44%] [G loss: 3.930008]\n",
      "epoch:28 step:22506 [D loss: 0.527501, acc: 74.22%] [G loss: 3.260593]\n",
      "epoch:28 step:22507 [D loss: 0.719842, acc: 58.59%] [G loss: 2.846984]\n",
      "epoch:28 step:22508 [D loss: 0.151893, acc: 98.44%] [G loss: 4.423190]\n",
      "epoch:28 step:22509 [D loss: 0.386360, acc: 81.25%] [G loss: 3.108032]\n",
      "epoch:28 step:22510 [D loss: 0.348586, acc: 81.25%] [G loss: 5.231337]\n",
      "epoch:28 step:22511 [D loss: 1.034512, acc: 38.28%] [G loss: 3.766918]\n",
      "epoch:28 step:22512 [D loss: 0.183790, acc: 98.44%] [G loss: 5.665002]\n",
      "epoch:28 step:22513 [D loss: 1.154886, acc: 50.00%] [G loss: 3.369495]\n",
      "epoch:28 step:22514 [D loss: 0.424994, acc: 85.94%] [G loss: 3.151004]\n",
      "epoch:28 step:22515 [D loss: 0.520447, acc: 63.28%] [G loss: 3.165738]\n",
      "epoch:28 step:22516 [D loss: 0.121845, acc: 100.00%] [G loss: 3.420058]\n",
      "epoch:28 step:22517 [D loss: 0.647395, acc: 57.81%] [G loss: 3.283483]\n",
      "epoch:28 step:22518 [D loss: 0.439569, acc: 83.59%] [G loss: 2.410093]\n",
      "epoch:28 step:22519 [D loss: 0.581671, acc: 64.06%] [G loss: 5.764356]\n",
      "epoch:28 step:22520 [D loss: 0.670728, acc: 53.12%] [G loss: 3.309509]\n",
      "epoch:28 step:22521 [D loss: 0.189176, acc: 96.88%] [G loss: 5.644547]\n",
      "epoch:28 step:22522 [D loss: 0.154034, acc: 99.22%] [G loss: 5.332099]\n",
      "epoch:28 step:22523 [D loss: 0.369814, acc: 88.28%] [G loss: 3.897272]\n",
      "epoch:28 step:22524 [D loss: 0.359127, acc: 90.62%] [G loss: 1.769253]\n",
      "epoch:28 step:22525 [D loss: 0.944252, acc: 48.44%] [G loss: 1.800307]\n",
      "epoch:28 step:22526 [D loss: 0.177589, acc: 98.44%] [G loss: 4.407852]\n",
      "epoch:28 step:22527 [D loss: 0.161573, acc: 99.22%] [G loss: 5.114571]\n",
      "epoch:28 step:22528 [D loss: 1.086169, acc: 33.59%] [G loss: 2.219352]\n",
      "epoch:28 step:22529 [D loss: 0.629242, acc: 64.84%] [G loss: 4.054327]\n",
      "epoch:28 step:22530 [D loss: 0.237063, acc: 98.44%] [G loss: 2.829422]\n",
      "epoch:28 step:22531 [D loss: 0.611736, acc: 65.62%] [G loss: 3.058950]\n",
      "epoch:28 step:22532 [D loss: 0.388841, acc: 86.72%] [G loss: 3.716875]\n",
      "epoch:28 step:22533 [D loss: 0.272563, acc: 95.31%] [G loss: 4.655447]\n",
      "epoch:28 step:22534 [D loss: 0.191512, acc: 96.88%] [G loss: 2.908010]\n",
      "epoch:28 step:22535 [D loss: 0.279361, acc: 93.75%] [G loss: 4.872039]\n",
      "epoch:28 step:22536 [D loss: 0.603086, acc: 67.19%] [G loss: 4.211389]\n",
      "epoch:28 step:22537 [D loss: 0.433578, acc: 80.47%] [G loss: 5.193799]\n",
      "epoch:28 step:22538 [D loss: 0.322312, acc: 92.97%] [G loss: 2.436624]\n",
      "epoch:28 step:22539 [D loss: 0.794170, acc: 53.12%] [G loss: 2.974545]\n",
      "epoch:28 step:22540 [D loss: 1.010566, acc: 32.03%] [G loss: 2.249772]\n",
      "epoch:28 step:22541 [D loss: 0.651505, acc: 55.47%] [G loss: 4.275261]\n",
      "epoch:28 step:22542 [D loss: 0.634226, acc: 54.69%] [G loss: 4.750691]\n",
      "epoch:28 step:22543 [D loss: 0.620489, acc: 62.50%] [G loss: 3.934576]\n",
      "epoch:28 step:22544 [D loss: 0.295867, acc: 90.62%] [G loss: 4.648563]\n",
      "epoch:28 step:22545 [D loss: 0.782591, acc: 53.12%] [G loss: 3.061399]\n",
      "epoch:28 step:22546 [D loss: 0.234336, acc: 98.44%] [G loss: 3.345664]\n",
      "epoch:28 step:22547 [D loss: 0.225455, acc: 93.75%] [G loss: 3.702221]\n",
      "epoch:28 step:22548 [D loss: 0.232888, acc: 95.31%] [G loss: 3.444939]\n",
      "epoch:28 step:22549 [D loss: 0.133446, acc: 100.00%] [G loss: 3.117312]\n",
      "epoch:28 step:22550 [D loss: 0.460035, acc: 78.12%] [G loss: 2.495719]\n",
      "epoch:28 step:22551 [D loss: 0.337722, acc: 92.19%] [G loss: 3.411527]\n",
      "epoch:28 step:22552 [D loss: 0.789683, acc: 48.44%] [G loss: 2.476596]\n",
      "epoch:28 step:22553 [D loss: 0.275996, acc: 94.53%] [G loss: 3.009870]\n",
      "epoch:28 step:22554 [D loss: 0.181734, acc: 98.44%] [G loss: 2.467370]\n",
      "epoch:28 step:22555 [D loss: 0.859238, acc: 35.16%] [G loss: 3.207617]\n",
      "epoch:28 step:22556 [D loss: 0.476163, acc: 67.19%] [G loss: 3.356812]\n",
      "epoch:28 step:22557 [D loss: 0.413411, acc: 87.50%] [G loss: 2.116709]\n",
      "epoch:28 step:22558 [D loss: 0.090457, acc: 100.00%] [G loss: 3.882081]\n",
      "epoch:28 step:22559 [D loss: 0.067289, acc: 100.00%] [G loss: 5.048103]\n",
      "epoch:28 step:22560 [D loss: 0.208286, acc: 96.09%] [G loss: 5.457796]\n",
      "epoch:28 step:22561 [D loss: 0.223770, acc: 97.66%] [G loss: 3.524774]\n",
      "epoch:28 step:22562 [D loss: 0.845418, acc: 49.22%] [G loss: 3.603901]\n",
      "epoch:28 step:22563 [D loss: 0.193859, acc: 100.00%] [G loss: 3.843738]\n",
      "epoch:28 step:22564 [D loss: 0.321005, acc: 91.41%] [G loss: 3.777405]\n",
      "epoch:28 step:22565 [D loss: 0.906106, acc: 50.78%] [G loss: 3.053396]\n",
      "epoch:28 step:22566 [D loss: 0.645846, acc: 52.34%] [G loss: 4.762840]\n",
      "epoch:28 step:22567 [D loss: 0.471694, acc: 70.31%] [G loss: 5.018476]\n",
      "epoch:28 step:22568 [D loss: 0.235862, acc: 97.66%] [G loss: 2.555963]\n",
      "epoch:28 step:22569 [D loss: 0.340406, acc: 96.09%] [G loss: 3.395608]\n",
      "epoch:28 step:22570 [D loss: 0.896811, acc: 48.44%] [G loss: 3.261152]\n",
      "epoch:28 step:22571 [D loss: 0.197679, acc: 99.22%] [G loss: 2.888358]\n",
      "epoch:28 step:22572 [D loss: 0.452548, acc: 73.44%] [G loss: 3.775637]\n",
      "epoch:28 step:22573 [D loss: 0.689027, acc: 57.03%] [G loss: 4.076137]\n",
      "epoch:28 step:22574 [D loss: 0.113110, acc: 100.00%] [G loss: 4.652431]\n",
      "epoch:28 step:22575 [D loss: 0.672137, acc: 61.72%] [G loss: 3.277542]\n",
      "epoch:28 step:22576 [D loss: 0.958140, acc: 27.34%] [G loss: 3.868599]\n",
      "epoch:28 step:22577 [D loss: 0.367167, acc: 92.19%] [G loss: 3.650500]\n",
      "epoch:28 step:22578 [D loss: 0.499690, acc: 76.56%] [G loss: 3.632507]\n",
      "epoch:28 step:22579 [D loss: 0.106187, acc: 100.00%] [G loss: 4.874016]\n",
      "epoch:28 step:22580 [D loss: 0.179272, acc: 99.22%] [G loss: 2.291372]\n",
      "epoch:28 step:22581 [D loss: 0.351818, acc: 88.28%] [G loss: 3.997470]\n",
      "epoch:28 step:22582 [D loss: 0.230711, acc: 98.44%] [G loss: 3.043198]\n",
      "epoch:28 step:22583 [D loss: 0.681566, acc: 60.16%] [G loss: 2.899590]\n",
      "epoch:28 step:22584 [D loss: 0.661536, acc: 59.38%] [G loss: 3.336109]\n",
      "epoch:28 step:22585 [D loss: 0.375529, acc: 82.03%] [G loss: 5.095585]\n",
      "epoch:28 step:22586 [D loss: 0.273228, acc: 92.97%] [G loss: 3.861598]\n",
      "epoch:28 step:22587 [D loss: 0.792439, acc: 50.00%] [G loss: 4.705724]\n",
      "epoch:28 step:22588 [D loss: 1.196852, acc: 50.00%] [G loss: 3.752924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22589 [D loss: 0.150738, acc: 99.22%] [G loss: 3.705082]\n",
      "epoch:28 step:22590 [D loss: 0.367332, acc: 89.84%] [G loss: 2.414220]\n",
      "epoch:28 step:22591 [D loss: 0.483985, acc: 71.09%] [G loss: 3.563373]\n",
      "epoch:28 step:22592 [D loss: 0.536678, acc: 76.56%] [G loss: 3.455778]\n",
      "epoch:28 step:22593 [D loss: 0.510610, acc: 64.06%] [G loss: 3.478315]\n",
      "epoch:28 step:22594 [D loss: 0.411779, acc: 89.06%] [G loss: 3.233463]\n",
      "epoch:28 step:22595 [D loss: 0.141003, acc: 100.00%] [G loss: 3.981832]\n",
      "epoch:28 step:22596 [D loss: 0.100519, acc: 100.00%] [G loss: 6.099587]\n",
      "epoch:28 step:22597 [D loss: 0.361814, acc: 86.72%] [G loss: 3.318545]\n",
      "epoch:28 step:22598 [D loss: 0.419511, acc: 71.09%] [G loss: 6.395051]\n",
      "epoch:28 step:22599 [D loss: 0.781789, acc: 53.12%] [G loss: 4.126797]\n",
      "epoch:28 step:22600 [D loss: 0.954379, acc: 51.56%] [G loss: 2.326582]\n",
      "epoch:28 step:22601 [D loss: 0.472560, acc: 74.22%] [G loss: 1.902228]\n",
      "epoch:28 step:22602 [D loss: 0.567148, acc: 73.44%] [G loss: 4.494212]\n",
      "epoch:28 step:22603 [D loss: 0.425194, acc: 89.06%] [G loss: 3.909154]\n",
      "epoch:28 step:22604 [D loss: 0.654420, acc: 58.59%] [G loss: 4.231722]\n",
      "epoch:28 step:22605 [D loss: 0.314418, acc: 93.75%] [G loss: 4.450727]\n",
      "epoch:28 step:22606 [D loss: 0.543914, acc: 65.62%] [G loss: 4.367317]\n",
      "epoch:28 step:22607 [D loss: 0.540077, acc: 78.12%] [G loss: 4.138515]\n",
      "epoch:28 step:22608 [D loss: 0.887427, acc: 37.50%] [G loss: 4.068844]\n",
      "epoch:28 step:22609 [D loss: 0.276014, acc: 96.09%] [G loss: 4.745331]\n",
      "epoch:28 step:22610 [D loss: 0.281446, acc: 96.09%] [G loss: 3.172329]\n",
      "epoch:28 step:22611 [D loss: 0.540661, acc: 71.09%] [G loss: 4.459214]\n",
      "epoch:28 step:22612 [D loss: 0.536052, acc: 78.12%] [G loss: 4.685208]\n",
      "epoch:28 step:22613 [D loss: 0.247591, acc: 96.09%] [G loss: 4.463830]\n",
      "epoch:28 step:22614 [D loss: 0.678317, acc: 60.94%] [G loss: 3.449245]\n",
      "epoch:28 step:22615 [D loss: 0.211451, acc: 98.44%] [G loss: 3.921719]\n",
      "epoch:28 step:22616 [D loss: 0.116134, acc: 100.00%] [G loss: 5.010289]\n",
      "epoch:28 step:22617 [D loss: 0.491488, acc: 70.31%] [G loss: 4.235932]\n",
      "epoch:28 step:22618 [D loss: 0.400150, acc: 82.03%] [G loss: 3.368306]\n",
      "epoch:28 step:22619 [D loss: 0.359293, acc: 87.50%] [G loss: 3.877544]\n",
      "epoch:28 step:22620 [D loss: 0.304670, acc: 93.75%] [G loss: 4.639452]\n",
      "epoch:28 step:22621 [D loss: 0.321092, acc: 85.16%] [G loss: 4.182545]\n",
      "epoch:28 step:22622 [D loss: 0.295917, acc: 97.66%] [G loss: 2.333146]\n",
      "epoch:28 step:22623 [D loss: 0.278951, acc: 92.97%] [G loss: 3.657648]\n",
      "epoch:28 step:22624 [D loss: 0.484246, acc: 83.59%] [G loss: 2.795064]\n",
      "epoch:28 step:22625 [D loss: 0.144481, acc: 99.22%] [G loss: 3.150590]\n",
      "epoch:28 step:22626 [D loss: 0.314445, acc: 93.75%] [G loss: 2.486467]\n",
      "epoch:28 step:22627 [D loss: 0.884408, acc: 49.22%] [G loss: 4.628486]\n",
      "epoch:28 step:22628 [D loss: 0.072240, acc: 100.00%] [G loss: 3.818040]\n",
      "epoch:28 step:22629 [D loss: 0.638588, acc: 57.81%] [G loss: 4.560979]\n",
      "epoch:28 step:22630 [D loss: 0.300200, acc: 92.19%] [G loss: 3.208692]\n",
      "epoch:28 step:22631 [D loss: 0.192191, acc: 100.00%] [G loss: 3.443998]\n",
      "epoch:28 step:22632 [D loss: 0.220888, acc: 97.66%] [G loss: 3.323390]\n",
      "epoch:28 step:22633 [D loss: 0.887191, acc: 35.94%] [G loss: 4.175234]\n",
      "epoch:28 step:22634 [D loss: 0.387382, acc: 79.69%] [G loss: 3.920606]\n",
      "epoch:28 step:22635 [D loss: 0.100673, acc: 100.00%] [G loss: 4.054132]\n",
      "epoch:28 step:22636 [D loss: 0.829162, acc: 50.78%] [G loss: 3.019351]\n",
      "epoch:28 step:22637 [D loss: 0.934088, acc: 50.78%] [G loss: 4.356390]\n",
      "epoch:28 step:22638 [D loss: 0.575752, acc: 71.09%] [G loss: 3.597028]\n",
      "epoch:28 step:22639 [D loss: 0.680097, acc: 60.94%] [G loss: 4.055822]\n",
      "epoch:28 step:22640 [D loss: 0.680228, acc: 56.25%] [G loss: 4.086500]\n",
      "epoch:28 step:22641 [D loss: 0.233661, acc: 96.09%] [G loss: 3.926834]\n",
      "epoch:28 step:22642 [D loss: 0.742751, acc: 55.47%] [G loss: 2.989898]\n",
      "epoch:28 step:22643 [D loss: 1.260970, acc: 17.19%] [G loss: 4.030920]\n",
      "epoch:28 step:22644 [D loss: 0.240027, acc: 96.09%] [G loss: 1.903456]\n",
      "epoch:28 step:22645 [D loss: 2.033256, acc: 28.12%] [G loss: 1.987851]\n",
      "epoch:28 step:22646 [D loss: 0.175272, acc: 99.22%] [G loss: 4.346067]\n",
      "epoch:28 step:22647 [D loss: 0.297647, acc: 92.19%] [G loss: 2.571504]\n",
      "epoch:28 step:22648 [D loss: 0.880468, acc: 39.84%] [G loss: 4.565296]\n",
      "epoch:28 step:22649 [D loss: 0.772221, acc: 53.12%] [G loss: 3.088291]\n",
      "epoch:29 step:22650 [D loss: 0.608570, acc: 67.19%] [G loss: 2.590299]\n",
      "epoch:29 step:22651 [D loss: 0.373909, acc: 87.50%] [G loss: 3.626503]\n",
      "epoch:29 step:22652 [D loss: 0.335447, acc: 81.25%] [G loss: 5.883159]\n",
      "epoch:29 step:22653 [D loss: 0.240625, acc: 98.44%] [G loss: 4.047044]\n",
      "epoch:29 step:22654 [D loss: 0.297987, acc: 89.84%] [G loss: 4.230443]\n",
      "epoch:29 step:22655 [D loss: 0.556769, acc: 60.94%] [G loss: 3.816548]\n",
      "epoch:29 step:22656 [D loss: 0.271193, acc: 97.66%] [G loss: 2.810897]\n",
      "epoch:29 step:22657 [D loss: 0.309846, acc: 92.97%] [G loss: 3.725526]\n",
      "epoch:29 step:22658 [D loss: 0.317626, acc: 92.97%] [G loss: 2.444137]\n",
      "epoch:29 step:22659 [D loss: 0.236333, acc: 98.44%] [G loss: 3.549721]\n",
      "epoch:29 step:22660 [D loss: 0.360904, acc: 89.84%] [G loss: 3.306548]\n",
      "epoch:29 step:22661 [D loss: 0.281823, acc: 86.72%] [G loss: 3.590444]\n",
      "epoch:29 step:22662 [D loss: 0.665216, acc: 60.16%] [G loss: 3.262457]\n",
      "epoch:29 step:22663 [D loss: 0.247025, acc: 98.44%] [G loss: 4.247864]\n",
      "epoch:29 step:22664 [D loss: 1.523994, acc: 48.44%] [G loss: 3.278812]\n",
      "epoch:29 step:22665 [D loss: 0.871939, acc: 40.62%] [G loss: 2.452024]\n",
      "epoch:29 step:22666 [D loss: 0.548942, acc: 78.91%] [G loss: 3.660188]\n",
      "epoch:29 step:22667 [D loss: 0.669752, acc: 56.25%] [G loss: 4.434870]\n",
      "epoch:29 step:22668 [D loss: 0.338398, acc: 92.97%] [G loss: 1.894600]\n",
      "epoch:29 step:22669 [D loss: 0.167135, acc: 100.00%] [G loss: 4.811789]\n",
      "epoch:29 step:22670 [D loss: 0.334566, acc: 93.75%] [G loss: 3.343827]\n",
      "epoch:29 step:22671 [D loss: 0.727381, acc: 52.34%] [G loss: 2.560773]\n",
      "epoch:29 step:22672 [D loss: 0.629083, acc: 59.38%] [G loss: 2.874073]\n",
      "epoch:29 step:22673 [D loss: 0.609352, acc: 64.06%] [G loss: 3.688021]\n",
      "epoch:29 step:22674 [D loss: 0.755355, acc: 55.47%] [G loss: 3.331987]\n",
      "epoch:29 step:22675 [D loss: 0.152593, acc: 100.00%] [G loss: 4.645389]\n",
      "epoch:29 step:22676 [D loss: 0.436142, acc: 85.16%] [G loss: 2.904433]\n",
      "epoch:29 step:22677 [D loss: 0.508608, acc: 62.50%] [G loss: 4.129719]\n",
      "epoch:29 step:22678 [D loss: 0.310627, acc: 87.50%] [G loss: 4.073024]\n",
      "epoch:29 step:22679 [D loss: 0.777094, acc: 54.69%] [G loss: 3.057280]\n",
      "epoch:29 step:22680 [D loss: 0.203340, acc: 96.88%] [G loss: 6.344072]\n",
      "epoch:29 step:22681 [D loss: 0.367326, acc: 76.56%] [G loss: 5.178638]\n",
      "epoch:29 step:22682 [D loss: 0.415351, acc: 82.03%] [G loss: 3.631275]\n",
      "epoch:29 step:22683 [D loss: 0.241083, acc: 91.41%] [G loss: 6.017142]\n",
      "epoch:29 step:22684 [D loss: 0.137130, acc: 99.22%] [G loss: 3.677995]\n",
      "epoch:29 step:22685 [D loss: 1.519137, acc: 50.00%] [G loss: 3.247663]\n",
      "epoch:29 step:22686 [D loss: 0.269011, acc: 91.41%] [G loss: 3.651403]\n",
      "epoch:29 step:22687 [D loss: 0.541778, acc: 76.56%] [G loss: 4.537632]\n",
      "epoch:29 step:22688 [D loss: 0.516053, acc: 79.69%] [G loss: 3.620246]\n",
      "epoch:29 step:22689 [D loss: 0.349488, acc: 84.38%] [G loss: 4.123266]\n",
      "epoch:29 step:22690 [D loss: 0.258547, acc: 94.53%] [G loss: 4.873621]\n",
      "epoch:29 step:22691 [D loss: 0.466135, acc: 82.03%] [G loss: 4.200417]\n",
      "epoch:29 step:22692 [D loss: 0.116875, acc: 98.44%] [G loss: 5.585602]\n",
      "epoch:29 step:22693 [D loss: 0.618428, acc: 64.06%] [G loss: 3.468891]\n",
      "epoch:29 step:22694 [D loss: 0.957671, acc: 46.09%] [G loss: 4.363756]\n",
      "epoch:29 step:22695 [D loss: 0.122552, acc: 100.00%] [G loss: 2.162734]\n",
      "epoch:29 step:22696 [D loss: 0.224569, acc: 97.66%] [G loss: 3.138903]\n",
      "epoch:29 step:22697 [D loss: 0.523327, acc: 74.22%] [G loss: 2.958236]\n",
      "epoch:29 step:22698 [D loss: 0.547055, acc: 73.44%] [G loss: 3.697325]\n",
      "epoch:29 step:22699 [D loss: 0.320126, acc: 92.97%] [G loss: 2.969020]\n",
      "epoch:29 step:22700 [D loss: 0.587417, acc: 63.28%] [G loss: 2.267205]\n",
      "epoch:29 step:22701 [D loss: 0.177176, acc: 98.44%] [G loss: 3.040870]\n",
      "epoch:29 step:22702 [D loss: 0.334812, acc: 89.06%] [G loss: 2.328485]\n",
      "epoch:29 step:22703 [D loss: 0.428796, acc: 80.47%] [G loss: 3.380571]\n",
      "epoch:29 step:22704 [D loss: 0.184169, acc: 98.44%] [G loss: 3.748787]\n",
      "epoch:29 step:22705 [D loss: 0.760305, acc: 50.78%] [G loss: 4.675935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22706 [D loss: 0.709579, acc: 53.12%] [G loss: 2.187785]\n",
      "epoch:29 step:22707 [D loss: 0.452156, acc: 73.44%] [G loss: 4.921886]\n",
      "epoch:29 step:22708 [D loss: 0.664200, acc: 53.91%] [G loss: 3.326647]\n",
      "epoch:29 step:22709 [D loss: 0.142921, acc: 100.00%] [G loss: 2.897181]\n",
      "epoch:29 step:22710 [D loss: 0.884649, acc: 47.66%] [G loss: 4.461975]\n",
      "epoch:29 step:22711 [D loss: 0.160353, acc: 99.22%] [G loss: 4.225701]\n",
      "epoch:29 step:22712 [D loss: 0.569973, acc: 62.50%] [G loss: 3.166059]\n",
      "epoch:29 step:22713 [D loss: 0.889165, acc: 50.78%] [G loss: 4.122629]\n",
      "epoch:29 step:22714 [D loss: 0.336138, acc: 83.59%] [G loss: 5.071471]\n",
      "epoch:29 step:22715 [D loss: 1.082688, acc: 22.66%] [G loss: 4.554902]\n",
      "epoch:29 step:22716 [D loss: 0.947630, acc: 45.31%] [G loss: 3.361914]\n",
      "epoch:29 step:22717 [D loss: 0.286947, acc: 89.84%] [G loss: 3.209500]\n",
      "epoch:29 step:22718 [D loss: 0.159302, acc: 100.00%] [G loss: 4.777258]\n",
      "epoch:29 step:22719 [D loss: 0.311421, acc: 93.75%] [G loss: 3.380931]\n",
      "epoch:29 step:22720 [D loss: 0.443965, acc: 77.34%] [G loss: 3.561224]\n",
      "epoch:29 step:22721 [D loss: 0.291206, acc: 99.22%] [G loss: 4.254390]\n",
      "epoch:29 step:22722 [D loss: 0.644503, acc: 58.59%] [G loss: 2.733910]\n",
      "epoch:29 step:22723 [D loss: 0.901066, acc: 48.44%] [G loss: 2.389653]\n",
      "epoch:29 step:22724 [D loss: 0.250035, acc: 94.53%] [G loss: 3.869385]\n",
      "epoch:29 step:22725 [D loss: 0.225837, acc: 92.97%] [G loss: 4.441678]\n",
      "epoch:29 step:22726 [D loss: 0.704638, acc: 55.47%] [G loss: 4.267994]\n",
      "epoch:29 step:22727 [D loss: 1.140294, acc: 14.06%] [G loss: 3.494960]\n",
      "epoch:29 step:22728 [D loss: 0.911746, acc: 51.56%] [G loss: 2.868198]\n",
      "epoch:29 step:22729 [D loss: 0.440163, acc: 75.00%] [G loss: 3.622481]\n",
      "epoch:29 step:22730 [D loss: 1.158916, acc: 23.44%] [G loss: 3.678226]\n",
      "epoch:29 step:22731 [D loss: 0.442498, acc: 79.69%] [G loss: 2.116150]\n",
      "epoch:29 step:22732 [D loss: 0.365306, acc: 91.41%] [G loss: 4.876518]\n",
      "epoch:29 step:22733 [D loss: 0.868615, acc: 50.78%] [G loss: 3.122211]\n",
      "epoch:29 step:22734 [D loss: 0.118645, acc: 100.00%] [G loss: 3.551666]\n",
      "epoch:29 step:22735 [D loss: 0.321620, acc: 92.97%] [G loss: 3.282201]\n",
      "epoch:29 step:22736 [D loss: 0.487505, acc: 75.00%] [G loss: 3.628098]\n",
      "epoch:29 step:22737 [D loss: 0.350737, acc: 88.28%] [G loss: 2.566166]\n",
      "epoch:29 step:22738 [D loss: 0.113029, acc: 100.00%] [G loss: 3.881804]\n",
      "epoch:29 step:22739 [D loss: 0.208406, acc: 97.66%] [G loss: 3.939790]\n",
      "epoch:29 step:22740 [D loss: 0.375200, acc: 79.69%] [G loss: 3.805492]\n",
      "epoch:29 step:22741 [D loss: 0.202967, acc: 96.88%] [G loss: 4.994709]\n",
      "epoch:29 step:22742 [D loss: 1.154538, acc: 36.72%] [G loss: 3.046840]\n",
      "epoch:29 step:22743 [D loss: 0.577135, acc: 70.31%] [G loss: 4.155996]\n",
      "epoch:29 step:22744 [D loss: 0.454742, acc: 80.47%] [G loss: 1.845179]\n",
      "epoch:29 step:22745 [D loss: 0.888024, acc: 33.59%] [G loss: 3.497378]\n",
      "epoch:29 step:22746 [D loss: 0.308731, acc: 96.09%] [G loss: 2.848415]\n",
      "epoch:29 step:22747 [D loss: 0.342112, acc: 94.53%] [G loss: 2.834836]\n",
      "epoch:29 step:22748 [D loss: 0.256130, acc: 98.44%] [G loss: 4.676216]\n",
      "epoch:29 step:22749 [D loss: 0.171305, acc: 100.00%] [G loss: 4.021681]\n",
      "epoch:29 step:22750 [D loss: 0.603903, acc: 60.16%] [G loss: 3.717155]\n",
      "epoch:29 step:22751 [D loss: 0.432716, acc: 86.72%] [G loss: 2.810247]\n",
      "epoch:29 step:22752 [D loss: 0.428405, acc: 89.84%] [G loss: 3.180421]\n",
      "epoch:29 step:22753 [D loss: 0.235227, acc: 94.53%] [G loss: 3.516826]\n",
      "epoch:29 step:22754 [D loss: 0.950524, acc: 37.50%] [G loss: 3.077060]\n",
      "epoch:29 step:22755 [D loss: 0.555420, acc: 68.75%] [G loss: 3.276934]\n",
      "epoch:29 step:22756 [D loss: 0.850502, acc: 40.62%] [G loss: 2.606947]\n",
      "epoch:29 step:22757 [D loss: 0.478126, acc: 83.59%] [G loss: 3.934440]\n",
      "epoch:29 step:22758 [D loss: 0.691761, acc: 55.47%] [G loss: 2.353374]\n",
      "epoch:29 step:22759 [D loss: 0.444130, acc: 91.41%] [G loss: 2.425107]\n",
      "epoch:29 step:22760 [D loss: 0.324290, acc: 90.62%] [G loss: 3.143301]\n",
      "epoch:29 step:22761 [D loss: 0.307667, acc: 96.88%] [G loss: 2.277152]\n",
      "epoch:29 step:22762 [D loss: 0.377728, acc: 86.72%] [G loss: 3.276694]\n",
      "epoch:29 step:22763 [D loss: 0.593981, acc: 69.53%] [G loss: 4.490284]\n",
      "epoch:29 step:22764 [D loss: 0.672646, acc: 57.81%] [G loss: 4.193745]\n",
      "epoch:29 step:22765 [D loss: 0.753161, acc: 52.34%] [G loss: 4.605833]\n",
      "epoch:29 step:22766 [D loss: 0.485526, acc: 75.78%] [G loss: 2.755307]\n",
      "epoch:29 step:22767 [D loss: 0.710939, acc: 50.78%] [G loss: 3.354278]\n",
      "epoch:29 step:22768 [D loss: 0.460269, acc: 64.06%] [G loss: 4.477491]\n",
      "epoch:29 step:22769 [D loss: 0.415856, acc: 76.56%] [G loss: 4.626615]\n",
      "epoch:29 step:22770 [D loss: 0.982553, acc: 25.78%] [G loss: 2.731732]\n",
      "epoch:29 step:22771 [D loss: 0.545505, acc: 59.38%] [G loss: 3.025563]\n",
      "epoch:29 step:22772 [D loss: 0.717030, acc: 54.69%] [G loss: 3.761763]\n",
      "epoch:29 step:22773 [D loss: 0.733950, acc: 51.56%] [G loss: 3.150451]\n",
      "epoch:29 step:22774 [D loss: 0.486575, acc: 70.31%] [G loss: 3.412974]\n",
      "epoch:29 step:22775 [D loss: 0.994862, acc: 29.69%] [G loss: 4.637022]\n",
      "epoch:29 step:22776 [D loss: 0.431440, acc: 77.34%] [G loss: 4.367597]\n",
      "epoch:29 step:22777 [D loss: 0.237172, acc: 96.09%] [G loss: 4.852587]\n",
      "epoch:29 step:22778 [D loss: 1.099387, acc: 36.72%] [G loss: 2.041436]\n",
      "epoch:29 step:22779 [D loss: 0.288950, acc: 88.28%] [G loss: 3.156995]\n",
      "epoch:29 step:22780 [D loss: 0.891849, acc: 37.50%] [G loss: 2.816980]\n",
      "epoch:29 step:22781 [D loss: 0.185887, acc: 100.00%] [G loss: 3.228146]\n",
      "epoch:29 step:22782 [D loss: 0.404567, acc: 89.84%] [G loss: 3.913224]\n",
      "epoch:29 step:22783 [D loss: 0.567847, acc: 64.06%] [G loss: 3.453317]\n",
      "epoch:29 step:22784 [D loss: 0.335789, acc: 86.72%] [G loss: 4.338873]\n",
      "epoch:29 step:22785 [D loss: 0.505646, acc: 64.84%] [G loss: 3.023531]\n",
      "epoch:29 step:22786 [D loss: 0.396015, acc: 91.41%] [G loss: 4.313025]\n",
      "epoch:29 step:22787 [D loss: 0.550110, acc: 74.22%] [G loss: 3.030190]\n",
      "epoch:29 step:22788 [D loss: 0.154115, acc: 99.22%] [G loss: 4.902672]\n",
      "epoch:29 step:22789 [D loss: 0.250079, acc: 96.88%] [G loss: 3.452522]\n",
      "epoch:29 step:22790 [D loss: 0.160611, acc: 99.22%] [G loss: 4.458984]\n",
      "epoch:29 step:22791 [D loss: 0.887792, acc: 33.59%] [G loss: 3.844926]\n",
      "epoch:29 step:22792 [D loss: 0.360983, acc: 92.97%] [G loss: 3.483354]\n",
      "epoch:29 step:22793 [D loss: 0.613616, acc: 66.41%] [G loss: 3.880082]\n",
      "epoch:29 step:22794 [D loss: 0.276169, acc: 91.41%] [G loss: 3.539063]\n",
      "epoch:29 step:22795 [D loss: 0.233066, acc: 96.09%] [G loss: 4.365845]\n",
      "epoch:29 step:22796 [D loss: 0.395687, acc: 90.62%] [G loss: 3.793151]\n",
      "epoch:29 step:22797 [D loss: 0.390215, acc: 88.28%] [G loss: 5.709707]\n",
      "epoch:29 step:22798 [D loss: 0.340175, acc: 93.75%] [G loss: 1.812461]\n",
      "epoch:29 step:22799 [D loss: 1.134953, acc: 14.06%] [G loss: 3.825216]\n",
      "epoch:29 step:22800 [D loss: 0.607614, acc: 59.38%] [G loss: 3.743834]\n",
      "epoch:29 step:22801 [D loss: 0.209933, acc: 97.66%] [G loss: 4.691532]\n",
      "epoch:29 step:22802 [D loss: 0.993989, acc: 50.00%] [G loss: 3.156726]\n",
      "epoch:29 step:22803 [D loss: 0.261963, acc: 94.53%] [G loss: 3.530543]\n",
      "epoch:29 step:22804 [D loss: 0.645307, acc: 64.84%] [G loss: 3.348124]\n",
      "epoch:29 step:22805 [D loss: 0.281921, acc: 96.88%] [G loss: 2.021406]\n",
      "epoch:29 step:22806 [D loss: 0.827787, acc: 50.00%] [G loss: 4.606674]\n",
      "epoch:29 step:22807 [D loss: 0.259216, acc: 92.19%] [G loss: 5.070629]\n",
      "epoch:29 step:22808 [D loss: 0.571033, acc: 67.97%] [G loss: 2.934664]\n",
      "epoch:29 step:22809 [D loss: 0.393311, acc: 87.50%] [G loss: 4.968593]\n",
      "epoch:29 step:22810 [D loss: 0.281969, acc: 90.62%] [G loss: 4.847960]\n",
      "epoch:29 step:22811 [D loss: 0.822052, acc: 50.78%] [G loss: 3.069157]\n",
      "epoch:29 step:22812 [D loss: 0.430509, acc: 81.25%] [G loss: 4.202660]\n",
      "epoch:29 step:22813 [D loss: 0.232005, acc: 96.88%] [G loss: 3.142838]\n",
      "epoch:29 step:22814 [D loss: 1.347596, acc: 24.22%] [G loss: 3.015092]\n",
      "epoch:29 step:22815 [D loss: 0.506038, acc: 71.88%] [G loss: 4.485460]\n",
      "epoch:29 step:22816 [D loss: 0.706466, acc: 60.16%] [G loss: 2.717073]\n",
      "epoch:29 step:22817 [D loss: 0.157943, acc: 99.22%] [G loss: 5.463692]\n",
      "epoch:29 step:22818 [D loss: 0.971801, acc: 35.94%] [G loss: 3.310934]\n",
      "epoch:29 step:22819 [D loss: 0.199791, acc: 98.44%] [G loss: 3.398792]\n",
      "epoch:29 step:22820 [D loss: 0.178369, acc: 98.44%] [G loss: 4.718382]\n",
      "epoch:29 step:22821 [D loss: 0.692527, acc: 53.91%] [G loss: 1.525397]\n",
      "epoch:29 step:22822 [D loss: 0.492467, acc: 72.66%] [G loss: 2.296703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22823 [D loss: 0.193307, acc: 97.66%] [G loss: 4.412086]\n",
      "epoch:29 step:22824 [D loss: 0.309175, acc: 89.84%] [G loss: 3.300292]\n",
      "epoch:29 step:22825 [D loss: 0.295221, acc: 94.53%] [G loss: 2.611127]\n",
      "epoch:29 step:22826 [D loss: 1.290024, acc: 38.28%] [G loss: 4.170879]\n",
      "epoch:29 step:22827 [D loss: 0.724438, acc: 53.12%] [G loss: 2.381851]\n",
      "epoch:29 step:22828 [D loss: 0.217055, acc: 100.00%] [G loss: 4.331930]\n",
      "epoch:29 step:22829 [D loss: 0.508612, acc: 65.62%] [G loss: 2.552378]\n",
      "epoch:29 step:22830 [D loss: 0.546017, acc: 67.97%] [G loss: 3.570234]\n",
      "epoch:29 step:22831 [D loss: 0.590112, acc: 64.06%] [G loss: 3.999574]\n",
      "epoch:29 step:22832 [D loss: 0.101572, acc: 100.00%] [G loss: 1.888982]\n",
      "epoch:29 step:22833 [D loss: 0.329518, acc: 92.97%] [G loss: 3.516396]\n",
      "epoch:29 step:22834 [D loss: 0.298333, acc: 91.41%] [G loss: 4.066048]\n",
      "epoch:29 step:22835 [D loss: 0.653438, acc: 60.16%] [G loss: 4.613916]\n",
      "epoch:29 step:22836 [D loss: 0.277163, acc: 92.97%] [G loss: 3.327828]\n",
      "epoch:29 step:22837 [D loss: 0.488461, acc: 80.47%] [G loss: 2.416353]\n",
      "epoch:29 step:22838 [D loss: 0.034920, acc: 100.00%] [G loss: 5.279316]\n",
      "epoch:29 step:22839 [D loss: 0.198431, acc: 99.22%] [G loss: 4.956436]\n",
      "epoch:29 step:22840 [D loss: 0.925145, acc: 33.59%] [G loss: 3.215026]\n",
      "epoch:29 step:22841 [D loss: 0.359671, acc: 87.50%] [G loss: 4.428458]\n",
      "epoch:29 step:22842 [D loss: 0.597642, acc: 68.75%] [G loss: 3.403613]\n",
      "epoch:29 step:22843 [D loss: 0.511913, acc: 64.06%] [G loss: 3.208341]\n",
      "epoch:29 step:22844 [D loss: 0.378871, acc: 89.06%] [G loss: 2.375553]\n",
      "epoch:29 step:22845 [D loss: 0.476429, acc: 85.16%] [G loss: 2.258369]\n",
      "epoch:29 step:22846 [D loss: 0.653101, acc: 52.34%] [G loss: 4.489550]\n",
      "epoch:29 step:22847 [D loss: 0.102077, acc: 100.00%] [G loss: 4.022483]\n",
      "epoch:29 step:22848 [D loss: 0.728912, acc: 53.12%] [G loss: 4.647628]\n",
      "epoch:29 step:22849 [D loss: 0.068478, acc: 100.00%] [G loss: 2.917687]\n",
      "epoch:29 step:22850 [D loss: 0.415253, acc: 78.91%] [G loss: 4.465013]\n",
      "epoch:29 step:22851 [D loss: 0.242436, acc: 96.88%] [G loss: 2.770470]\n",
      "epoch:29 step:22852 [D loss: 0.319220, acc: 94.53%] [G loss: 4.034560]\n",
      "epoch:29 step:22853 [D loss: 0.790023, acc: 50.00%] [G loss: 2.336936]\n",
      "epoch:29 step:22854 [D loss: 0.555893, acc: 76.56%] [G loss: 1.768747]\n",
      "epoch:29 step:22855 [D loss: 0.975314, acc: 46.09%] [G loss: 2.533306]\n",
      "epoch:29 step:22856 [D loss: 0.491679, acc: 68.75%] [G loss: 5.149056]\n",
      "epoch:29 step:22857 [D loss: 0.160239, acc: 97.66%] [G loss: 4.234548]\n",
      "epoch:29 step:22858 [D loss: 0.834501, acc: 42.19%] [G loss: 4.154880]\n",
      "epoch:29 step:22859 [D loss: 0.323556, acc: 93.75%] [G loss: 3.901917]\n",
      "epoch:29 step:22860 [D loss: 0.243300, acc: 96.09%] [G loss: 3.240586]\n",
      "epoch:29 step:22861 [D loss: 0.237428, acc: 93.75%] [G loss: 4.014524]\n",
      "epoch:29 step:22862 [D loss: 0.773007, acc: 42.19%] [G loss: 3.505325]\n",
      "epoch:29 step:22863 [D loss: 0.263410, acc: 99.22%] [G loss: 5.039793]\n",
      "epoch:29 step:22864 [D loss: 1.089950, acc: 51.56%] [G loss: 5.664166]\n",
      "epoch:29 step:22865 [D loss: 0.338608, acc: 90.62%] [G loss: 3.087871]\n",
      "epoch:29 step:22866 [D loss: 0.088410, acc: 100.00%] [G loss: 2.909278]\n",
      "epoch:29 step:22867 [D loss: 0.289987, acc: 95.31%] [G loss: 4.425334]\n",
      "epoch:29 step:22868 [D loss: 0.204964, acc: 96.88%] [G loss: 4.229590]\n",
      "epoch:29 step:22869 [D loss: 0.517724, acc: 74.22%] [G loss: 3.578697]\n",
      "epoch:29 step:22870 [D loss: 0.634390, acc: 62.50%] [G loss: 1.790100]\n",
      "epoch:29 step:22871 [D loss: 0.161418, acc: 99.22%] [G loss: 2.729848]\n",
      "epoch:29 step:22872 [D loss: 0.902297, acc: 32.81%] [G loss: 3.344748]\n",
      "epoch:29 step:22873 [D loss: 0.652146, acc: 55.47%] [G loss: 5.795163]\n",
      "epoch:29 step:22874 [D loss: 0.219190, acc: 96.88%] [G loss: 2.770665]\n",
      "epoch:29 step:22875 [D loss: 0.496449, acc: 72.66%] [G loss: 2.325945]\n",
      "epoch:29 step:22876 [D loss: 0.085843, acc: 100.00%] [G loss: 5.277080]\n",
      "epoch:29 step:22877 [D loss: 0.376046, acc: 91.41%] [G loss: 3.003974]\n",
      "epoch:29 step:22878 [D loss: 0.220885, acc: 96.09%] [G loss: 3.285535]\n",
      "epoch:29 step:22879 [D loss: 0.363260, acc: 82.03%] [G loss: 3.550778]\n",
      "epoch:29 step:22880 [D loss: 0.243279, acc: 98.44%] [G loss: 3.432868]\n",
      "epoch:29 step:22881 [D loss: 0.571242, acc: 62.50%] [G loss: 3.421035]\n",
      "epoch:29 step:22882 [D loss: 0.272963, acc: 96.09%] [G loss: 2.599416]\n",
      "epoch:29 step:22883 [D loss: 1.067441, acc: 45.31%] [G loss: 3.964025]\n",
      "epoch:29 step:22884 [D loss: 1.179519, acc: 34.38%] [G loss: 4.130121]\n",
      "epoch:29 step:22885 [D loss: 1.354830, acc: 25.78%] [G loss: 3.415444]\n",
      "epoch:29 step:22886 [D loss: 0.190132, acc: 99.22%] [G loss: 3.519948]\n",
      "epoch:29 step:22887 [D loss: 0.463092, acc: 86.72%] [G loss: 4.064620]\n",
      "epoch:29 step:22888 [D loss: 1.145553, acc: 31.25%] [G loss: 2.856386]\n",
      "epoch:29 step:22889 [D loss: 0.390167, acc: 82.03%] [G loss: 2.879466]\n",
      "epoch:29 step:22890 [D loss: 0.427195, acc: 87.50%] [G loss: 3.507591]\n",
      "epoch:29 step:22891 [D loss: 0.099376, acc: 100.00%] [G loss: 5.912439]\n",
      "epoch:29 step:22892 [D loss: 0.338867, acc: 92.97%] [G loss: 3.244576]\n",
      "epoch:29 step:22893 [D loss: 0.468305, acc: 74.22%] [G loss: 5.005350]\n",
      "epoch:29 step:22894 [D loss: 1.415049, acc: 7.03%] [G loss: 2.535231]\n",
      "epoch:29 step:22895 [D loss: 0.278624, acc: 98.44%] [G loss: 4.683180]\n",
      "epoch:29 step:22896 [D loss: 0.402275, acc: 82.81%] [G loss: 3.280387]\n",
      "epoch:29 step:22897 [D loss: 0.757406, acc: 48.44%] [G loss: 3.080467]\n",
      "epoch:29 step:22898 [D loss: 0.141779, acc: 100.00%] [G loss: 3.399809]\n",
      "epoch:29 step:22899 [D loss: 0.284403, acc: 95.31%] [G loss: 4.183026]\n",
      "epoch:29 step:22900 [D loss: 0.344407, acc: 94.53%] [G loss: 5.078466]\n",
      "epoch:29 step:22901 [D loss: 0.359128, acc: 86.72%] [G loss: 2.863726]\n",
      "epoch:29 step:22902 [D loss: 1.112781, acc: 14.84%] [G loss: 2.425952]\n",
      "epoch:29 step:22903 [D loss: 0.207927, acc: 100.00%] [G loss: 1.945585]\n",
      "epoch:29 step:22904 [D loss: 0.539016, acc: 60.16%] [G loss: 3.232375]\n",
      "epoch:29 step:22905 [D loss: 0.346274, acc: 85.94%] [G loss: 3.727540]\n",
      "epoch:29 step:22906 [D loss: 0.698047, acc: 57.81%] [G loss: 2.197848]\n",
      "epoch:29 step:22907 [D loss: 0.321286, acc: 92.97%] [G loss: 5.299550]\n",
      "epoch:29 step:22908 [D loss: 0.256815, acc: 96.09%] [G loss: 4.641366]\n",
      "epoch:29 step:22909 [D loss: 0.479378, acc: 64.06%] [G loss: 4.847381]\n",
      "epoch:29 step:22910 [D loss: 0.538263, acc: 67.19%] [G loss: 2.871135]\n",
      "epoch:29 step:22911 [D loss: 0.427238, acc: 75.00%] [G loss: 4.438365]\n",
      "epoch:29 step:22912 [D loss: 0.726026, acc: 58.59%] [G loss: 2.915393]\n",
      "epoch:29 step:22913 [D loss: 0.457281, acc: 64.84%] [G loss: 2.402076]\n",
      "epoch:29 step:22914 [D loss: 0.677334, acc: 53.91%] [G loss: 3.503312]\n",
      "epoch:29 step:22915 [D loss: 0.270018, acc: 97.66%] [G loss: 4.745066]\n",
      "epoch:29 step:22916 [D loss: 0.437453, acc: 85.94%] [G loss: 3.506315]\n",
      "epoch:29 step:22917 [D loss: 1.015385, acc: 35.94%] [G loss: 3.800664]\n",
      "epoch:29 step:22918 [D loss: 0.580468, acc: 69.53%] [G loss: 2.867212]\n",
      "epoch:29 step:22919 [D loss: 0.253236, acc: 96.88%] [G loss: 3.855148]\n",
      "epoch:29 step:22920 [D loss: 0.548957, acc: 77.34%] [G loss: 4.651778]\n",
      "epoch:29 step:22921 [D loss: 0.298062, acc: 96.88%] [G loss: 3.403188]\n",
      "epoch:29 step:22922 [D loss: 0.425742, acc: 83.59%] [G loss: 3.356950]\n",
      "epoch:29 step:22923 [D loss: 1.302706, acc: 9.38%] [G loss: 3.113852]\n",
      "epoch:29 step:22924 [D loss: 0.838252, acc: 51.56%] [G loss: 1.662174]\n",
      "epoch:29 step:22925 [D loss: 0.662809, acc: 51.56%] [G loss: 3.833163]\n",
      "epoch:29 step:22926 [D loss: 0.602514, acc: 58.59%] [G loss: 3.756892]\n",
      "epoch:29 step:22927 [D loss: 0.450152, acc: 83.59%] [G loss: 2.811185]\n",
      "epoch:29 step:22928 [D loss: 0.180412, acc: 97.66%] [G loss: 3.043724]\n",
      "epoch:29 step:22929 [D loss: 0.868176, acc: 47.66%] [G loss: 3.167918]\n",
      "epoch:29 step:22930 [D loss: 0.140865, acc: 100.00%] [G loss: 3.155504]\n",
      "epoch:29 step:22931 [D loss: 0.296718, acc: 98.44%] [G loss: 3.125309]\n",
      "epoch:29 step:22932 [D loss: 0.350015, acc: 93.75%] [G loss: 3.485390]\n",
      "epoch:29 step:22933 [D loss: 0.161537, acc: 100.00%] [G loss: 4.780640]\n",
      "epoch:29 step:22934 [D loss: 0.222042, acc: 96.88%] [G loss: 4.830110]\n",
      "epoch:29 step:22935 [D loss: 0.926461, acc: 46.09%] [G loss: 3.963174]\n",
      "epoch:29 step:22936 [D loss: 0.726511, acc: 51.56%] [G loss: 3.645701]\n",
      "epoch:29 step:22937 [D loss: 0.387735, acc: 91.41%] [G loss: 2.501212]\n",
      "epoch:29 step:22938 [D loss: 0.456898, acc: 85.16%] [G loss: 2.984996]\n",
      "epoch:29 step:22939 [D loss: 0.575204, acc: 70.31%] [G loss: 2.556428]\n",
      "epoch:29 step:22940 [D loss: 1.105680, acc: 50.00%] [G loss: 3.034844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22941 [D loss: 0.363124, acc: 84.38%] [G loss: 4.154262]\n",
      "epoch:29 step:22942 [D loss: 0.454828, acc: 75.78%] [G loss: 4.145511]\n",
      "epoch:29 step:22943 [D loss: 0.330292, acc: 88.28%] [G loss: 3.493382]\n",
      "epoch:29 step:22944 [D loss: 0.780540, acc: 52.34%] [G loss: 2.276783]\n",
      "epoch:29 step:22945 [D loss: 0.298725, acc: 88.28%] [G loss: 2.477994]\n",
      "epoch:29 step:22946 [D loss: 0.794210, acc: 47.66%] [G loss: 2.411417]\n",
      "epoch:29 step:22947 [D loss: 1.119174, acc: 21.09%] [G loss: 4.718488]\n",
      "epoch:29 step:22948 [D loss: 0.559247, acc: 76.56%] [G loss: 5.582859]\n",
      "epoch:29 step:22949 [D loss: 0.659999, acc: 58.59%] [G loss: 2.798278]\n",
      "epoch:29 step:22950 [D loss: 1.287688, acc: 25.00%] [G loss: 2.525091]\n",
      "epoch:29 step:22951 [D loss: 0.417258, acc: 88.28%] [G loss: 2.618740]\n",
      "epoch:29 step:22952 [D loss: 0.185203, acc: 98.44%] [G loss: 3.449396]\n",
      "epoch:29 step:22953 [D loss: 0.726185, acc: 52.34%] [G loss: 3.499578]\n",
      "epoch:29 step:22954 [D loss: 0.601605, acc: 54.69%] [G loss: 4.219693]\n",
      "epoch:29 step:22955 [D loss: 0.633657, acc: 59.38%] [G loss: 3.673897]\n",
      "epoch:29 step:22956 [D loss: 0.630408, acc: 64.06%] [G loss: 3.156197]\n",
      "epoch:29 step:22957 [D loss: 0.124572, acc: 100.00%] [G loss: 3.907485]\n",
      "epoch:29 step:22958 [D loss: 0.373778, acc: 93.75%] [G loss: 4.558569]\n",
      "epoch:29 step:22959 [D loss: 0.108914, acc: 99.22%] [G loss: 3.641945]\n",
      "epoch:29 step:22960 [D loss: 0.428223, acc: 73.44%] [G loss: 2.423536]\n",
      "epoch:29 step:22961 [D loss: 0.850073, acc: 42.19%] [G loss: 1.357040]\n",
      "epoch:29 step:22962 [D loss: 0.528935, acc: 78.12%] [G loss: 2.726353]\n",
      "epoch:29 step:22963 [D loss: 0.583269, acc: 67.97%] [G loss: 2.389860]\n",
      "epoch:29 step:22964 [D loss: 0.377668, acc: 89.84%] [G loss: 3.198001]\n",
      "epoch:29 step:22965 [D loss: 0.348177, acc: 94.53%] [G loss: 2.408805]\n",
      "epoch:29 step:22966 [D loss: 0.483725, acc: 82.81%] [G loss: 2.934870]\n",
      "epoch:29 step:22967 [D loss: 0.839293, acc: 39.84%] [G loss: 2.190666]\n",
      "epoch:29 step:22968 [D loss: 0.397674, acc: 84.38%] [G loss: 4.089003]\n",
      "epoch:29 step:22969 [D loss: 0.599175, acc: 61.72%] [G loss: 4.696040]\n",
      "epoch:29 step:22970 [D loss: 0.357818, acc: 81.25%] [G loss: 4.310835]\n",
      "epoch:29 step:22971 [D loss: 0.336623, acc: 84.38%] [G loss: 3.963502]\n",
      "epoch:29 step:22972 [D loss: 0.482361, acc: 85.16%] [G loss: 4.393046]\n",
      "epoch:29 step:22973 [D loss: 0.399503, acc: 89.06%] [G loss: 4.004156]\n",
      "epoch:29 step:22974 [D loss: 0.483086, acc: 81.25%] [G loss: 3.344718]\n",
      "epoch:29 step:22975 [D loss: 0.602548, acc: 74.22%] [G loss: 4.266346]\n",
      "epoch:29 step:22976 [D loss: 0.477645, acc: 72.66%] [G loss: 5.860476]\n",
      "epoch:29 step:22977 [D loss: 0.116026, acc: 99.22%] [G loss: 4.966092]\n",
      "epoch:29 step:22978 [D loss: 0.176762, acc: 99.22%] [G loss: 4.608113]\n",
      "epoch:29 step:22979 [D loss: 0.305140, acc: 96.09%] [G loss: 4.332964]\n",
      "epoch:29 step:22980 [D loss: 0.393129, acc: 81.25%] [G loss: 2.510404]\n",
      "epoch:29 step:22981 [D loss: 0.311656, acc: 97.66%] [G loss: 2.771147]\n",
      "epoch:29 step:22982 [D loss: 0.245020, acc: 92.19%] [G loss: 3.666175]\n",
      "epoch:29 step:22983 [D loss: 0.587677, acc: 69.53%] [G loss: 3.029939]\n",
      "epoch:29 step:22984 [D loss: 0.312822, acc: 92.97%] [G loss: 5.172407]\n",
      "epoch:29 step:22985 [D loss: 0.214749, acc: 97.66%] [G loss: 3.595575]\n",
      "epoch:29 step:22986 [D loss: 1.032936, acc: 35.94%] [G loss: 3.945587]\n",
      "epoch:29 step:22987 [D loss: 0.417817, acc: 88.28%] [G loss: 2.694200]\n",
      "epoch:29 step:22988 [D loss: 0.318725, acc: 89.84%] [G loss: 4.621163]\n",
      "epoch:29 step:22989 [D loss: 0.229070, acc: 95.31%] [G loss: 3.456447]\n",
      "epoch:29 step:22990 [D loss: 0.553135, acc: 67.19%] [G loss: 3.454201]\n",
      "epoch:29 step:22991 [D loss: 0.349473, acc: 86.72%] [G loss: 2.754728]\n",
      "epoch:29 step:22992 [D loss: 0.601750, acc: 64.06%] [G loss: 3.518771]\n",
      "epoch:29 step:22993 [D loss: 0.732100, acc: 52.34%] [G loss: 3.927088]\n",
      "epoch:29 step:22994 [D loss: 0.270697, acc: 92.19%] [G loss: 5.386631]\n",
      "epoch:29 step:22995 [D loss: 1.303006, acc: 23.44%] [G loss: 4.414511]\n",
      "epoch:29 step:22996 [D loss: 0.051144, acc: 100.00%] [G loss: 5.069133]\n",
      "epoch:29 step:22997 [D loss: 0.920292, acc: 42.19%] [G loss: 3.434626]\n",
      "epoch:29 step:22998 [D loss: 0.211881, acc: 96.09%] [G loss: 2.893441]\n",
      "epoch:29 step:22999 [D loss: 0.423955, acc: 83.59%] [G loss: 3.493236]\n",
      "epoch:29 step:23000 [D loss: 0.561528, acc: 75.78%] [G loss: 2.364812]\n",
      "epoch:29 step:23001 [D loss: 0.359382, acc: 81.25%] [G loss: 2.986307]\n",
      "epoch:29 step:23002 [D loss: 0.429080, acc: 85.94%] [G loss: 3.448750]\n",
      "epoch:29 step:23003 [D loss: 0.350162, acc: 93.75%] [G loss: 2.294455]\n",
      "epoch:29 step:23004 [D loss: 0.856627, acc: 44.53%] [G loss: 3.485007]\n",
      "epoch:29 step:23005 [D loss: 0.683803, acc: 61.72%] [G loss: 4.613419]\n",
      "epoch:29 step:23006 [D loss: 0.579778, acc: 60.94%] [G loss: 3.431427]\n",
      "epoch:29 step:23007 [D loss: 0.140605, acc: 99.22%] [G loss: 3.537624]\n",
      "epoch:29 step:23008 [D loss: 0.403036, acc: 86.72%] [G loss: 4.520465]\n",
      "epoch:29 step:23009 [D loss: 0.400611, acc: 86.72%] [G loss: 4.597628]\n",
      "epoch:29 step:23010 [D loss: 0.239231, acc: 96.09%] [G loss: 2.834025]\n",
      "epoch:29 step:23011 [D loss: 1.486530, acc: 12.50%] [G loss: 2.811378]\n",
      "epoch:29 step:23012 [D loss: 0.235909, acc: 100.00%] [G loss: 3.044734]\n",
      "epoch:29 step:23013 [D loss: 0.947255, acc: 50.00%] [G loss: 3.007787]\n",
      "epoch:29 step:23014 [D loss: 0.390392, acc: 92.19%] [G loss: 5.370838]\n",
      "epoch:29 step:23015 [D loss: 1.152094, acc: 50.78%] [G loss: 4.468312]\n",
      "epoch:29 step:23016 [D loss: 0.333523, acc: 94.53%] [G loss: 3.499956]\n",
      "epoch:29 step:23017 [D loss: 0.645385, acc: 64.06%] [G loss: 3.407710]\n",
      "epoch:29 step:23018 [D loss: 0.262482, acc: 99.22%] [G loss: 2.769972]\n",
      "epoch:29 step:23019 [D loss: 0.227750, acc: 96.88%] [G loss: 4.994225]\n",
      "epoch:29 step:23020 [D loss: 0.904413, acc: 36.72%] [G loss: 3.865222]\n",
      "epoch:29 step:23021 [D loss: 0.301591, acc: 92.19%] [G loss: 5.003915]\n",
      "epoch:29 step:23022 [D loss: 0.675511, acc: 63.28%] [G loss: 3.551466]\n",
      "epoch:29 step:23023 [D loss: 0.116812, acc: 100.00%] [G loss: 1.794655]\n",
      "epoch:29 step:23024 [D loss: 0.240957, acc: 98.44%] [G loss: 3.920670]\n",
      "epoch:29 step:23025 [D loss: 1.541810, acc: 8.59%] [G loss: 4.081439]\n",
      "epoch:29 step:23026 [D loss: 0.321856, acc: 90.62%] [G loss: 4.265398]\n",
      "epoch:29 step:23027 [D loss: 0.252988, acc: 92.97%] [G loss: 7.421454]\n",
      "epoch:29 step:23028 [D loss: 0.221118, acc: 98.44%] [G loss: 5.231675]\n",
      "epoch:29 step:23029 [D loss: 0.269167, acc: 97.66%] [G loss: 2.698468]\n",
      "epoch:29 step:23030 [D loss: 0.195211, acc: 98.44%] [G loss: 4.733234]\n",
      "epoch:29 step:23031 [D loss: 0.278618, acc: 95.31%] [G loss: 5.071583]\n",
      "epoch:29 step:23032 [D loss: 0.499560, acc: 73.44%] [G loss: 2.537747]\n",
      "epoch:29 step:23033 [D loss: 0.413852, acc: 88.28%] [G loss: 4.136049]\n",
      "epoch:29 step:23034 [D loss: 0.231481, acc: 96.88%] [G loss: 2.235331]\n",
      "epoch:29 step:23035 [D loss: 0.154435, acc: 99.22%] [G loss: 3.817331]\n",
      "epoch:29 step:23036 [D loss: 0.204956, acc: 96.09%] [G loss: 3.759383]\n",
      "epoch:29 step:23037 [D loss: 0.329689, acc: 90.62%] [G loss: 5.533168]\n",
      "epoch:29 step:23038 [D loss: 0.560118, acc: 66.41%] [G loss: 2.704245]\n",
      "epoch:29 step:23039 [D loss: 0.148580, acc: 98.44%] [G loss: 2.557482]\n",
      "epoch:29 step:23040 [D loss: 0.640151, acc: 57.03%] [G loss: 3.302257]\n",
      "epoch:29 step:23041 [D loss: 0.443781, acc: 76.56%] [G loss: 4.607351]\n",
      "epoch:29 step:23042 [D loss: 0.542130, acc: 75.78%] [G loss: 3.247441]\n",
      "epoch:29 step:23043 [D loss: 0.067299, acc: 100.00%] [G loss: 3.340548]\n",
      "epoch:29 step:23044 [D loss: 1.147686, acc: 48.44%] [G loss: 3.461163]\n",
      "epoch:29 step:23045 [D loss: 0.792488, acc: 48.44%] [G loss: 4.329752]\n",
      "epoch:29 step:23046 [D loss: 0.513137, acc: 81.25%] [G loss: 3.876940]\n",
      "epoch:29 step:23047 [D loss: 0.292321, acc: 96.88%] [G loss: 4.665275]\n",
      "epoch:29 step:23048 [D loss: 0.374213, acc: 89.84%] [G loss: 5.843984]\n",
      "epoch:29 step:23049 [D loss: 0.694012, acc: 56.25%] [G loss: 3.795266]\n",
      "epoch:29 step:23050 [D loss: 0.112275, acc: 100.00%] [G loss: 3.636483]\n",
      "epoch:29 step:23051 [D loss: 0.503169, acc: 75.00%] [G loss: 4.910702]\n",
      "epoch:29 step:23052 [D loss: 0.511275, acc: 76.56%] [G loss: 4.822771]\n",
      "epoch:29 step:23053 [D loss: 0.374752, acc: 89.06%] [G loss: 3.062894]\n",
      "epoch:29 step:23054 [D loss: 0.229079, acc: 94.53%] [G loss: 2.808248]\n",
      "epoch:29 step:23055 [D loss: 0.595061, acc: 70.31%] [G loss: 4.188522]\n",
      "epoch:29 step:23056 [D loss: 0.423145, acc: 76.56%] [G loss: 5.202148]\n",
      "epoch:29 step:23057 [D loss: 0.336894, acc: 95.31%] [G loss: 5.056515]\n",
      "epoch:29 step:23058 [D loss: 0.690730, acc: 57.03%] [G loss: 2.467692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23059 [D loss: 0.113854, acc: 100.00%] [G loss: 3.174356]\n",
      "epoch:29 step:23060 [D loss: 0.477446, acc: 83.59%] [G loss: 3.371841]\n",
      "epoch:29 step:23061 [D loss: 0.478823, acc: 76.56%] [G loss: 5.531754]\n",
      "epoch:29 step:23062 [D loss: 0.232555, acc: 93.75%] [G loss: 5.209826]\n",
      "epoch:29 step:23063 [D loss: 0.107407, acc: 98.44%] [G loss: 5.352264]\n",
      "epoch:29 step:23064 [D loss: 0.423805, acc: 90.62%] [G loss: 4.425407]\n",
      "epoch:29 step:23065 [D loss: 0.699440, acc: 49.22%] [G loss: 3.022659]\n",
      "epoch:29 step:23066 [D loss: 0.198137, acc: 100.00%] [G loss: 4.340694]\n",
      "epoch:29 step:23067 [D loss: 0.188043, acc: 99.22%] [G loss: 3.747144]\n",
      "epoch:29 step:23068 [D loss: 0.305198, acc: 92.97%] [G loss: 5.209281]\n",
      "epoch:29 step:23069 [D loss: 0.716098, acc: 56.25%] [G loss: 2.767791]\n",
      "epoch:29 step:23070 [D loss: 0.433706, acc: 73.44%] [G loss: 5.800826]\n",
      "epoch:29 step:23071 [D loss: 0.222922, acc: 94.53%] [G loss: 4.710608]\n",
      "epoch:29 step:23072 [D loss: 0.259665, acc: 96.09%] [G loss: 2.882642]\n",
      "epoch:29 step:23073 [D loss: 0.611453, acc: 66.41%] [G loss: 1.824678]\n",
      "epoch:29 step:23074 [D loss: 0.203117, acc: 97.66%] [G loss: 3.275805]\n",
      "epoch:29 step:23075 [D loss: 0.198925, acc: 95.31%] [G loss: 2.105941]\n",
      "epoch:29 step:23076 [D loss: 0.595845, acc: 64.84%] [G loss: 3.230415]\n",
      "epoch:29 step:23077 [D loss: 0.234713, acc: 97.66%] [G loss: 4.251313]\n",
      "epoch:29 step:23078 [D loss: 0.101370, acc: 97.66%] [G loss: 4.530347]\n",
      "epoch:29 step:23079 [D loss: 0.076283, acc: 100.00%] [G loss: 4.334026]\n",
      "epoch:29 step:23080 [D loss: 0.947900, acc: 31.25%] [G loss: 3.933809]\n",
      "epoch:29 step:23081 [D loss: 0.352731, acc: 89.84%] [G loss: 4.351358]\n",
      "epoch:29 step:23082 [D loss: 0.196315, acc: 100.00%] [G loss: 3.636892]\n",
      "epoch:29 step:23083 [D loss: 0.427462, acc: 89.84%] [G loss: 3.790973]\n",
      "epoch:29 step:23084 [D loss: 0.317765, acc: 94.53%] [G loss: 3.874485]\n",
      "epoch:29 step:23085 [D loss: 1.033743, acc: 50.00%] [G loss: 3.899020]\n",
      "epoch:29 step:23086 [D loss: 0.718954, acc: 53.12%] [G loss: 2.434857]\n",
      "epoch:29 step:23087 [D loss: 0.094207, acc: 100.00%] [G loss: 3.352824]\n",
      "epoch:29 step:23088 [D loss: 0.152264, acc: 100.00%] [G loss: 3.855262]\n",
      "epoch:29 step:23089 [D loss: 0.590179, acc: 67.97%] [G loss: 3.343182]\n",
      "epoch:29 step:23090 [D loss: 0.455299, acc: 77.34%] [G loss: 3.425504]\n",
      "epoch:29 step:23091 [D loss: 0.512198, acc: 75.00%] [G loss: 5.070994]\n",
      "epoch:29 step:23092 [D loss: 0.516381, acc: 74.22%] [G loss: 4.113892]\n",
      "epoch:29 step:23093 [D loss: 0.304971, acc: 86.72%] [G loss: 3.960720]\n",
      "epoch:29 step:23094 [D loss: 0.951349, acc: 47.66%] [G loss: 3.185003]\n",
      "epoch:29 step:23095 [D loss: 0.574632, acc: 70.31%] [G loss: 3.519215]\n",
      "epoch:29 step:23096 [D loss: 0.602080, acc: 64.06%] [G loss: 2.931237]\n",
      "epoch:29 step:23097 [D loss: 0.355557, acc: 82.81%] [G loss: 3.342749]\n",
      "epoch:29 step:23098 [D loss: 0.426288, acc: 89.06%] [G loss: 3.809081]\n",
      "epoch:29 step:23099 [D loss: 0.576747, acc: 76.56%] [G loss: 3.447209]\n",
      "epoch:29 step:23100 [D loss: 0.416952, acc: 79.69%] [G loss: 3.285800]\n",
      "epoch:29 step:23101 [D loss: 0.365856, acc: 84.38%] [G loss: 4.802751]\n",
      "epoch:29 step:23102 [D loss: 0.628697, acc: 64.06%] [G loss: 3.668451]\n",
      "epoch:29 step:23103 [D loss: 0.232958, acc: 99.22%] [G loss: 4.047946]\n",
      "epoch:29 step:23104 [D loss: 0.289461, acc: 97.66%] [G loss: 4.551157]\n",
      "epoch:29 step:23105 [D loss: 0.412920, acc: 78.12%] [G loss: 5.809924]\n",
      "epoch:29 step:23106 [D loss: 0.322032, acc: 92.97%] [G loss: 2.803188]\n",
      "epoch:29 step:23107 [D loss: 0.079038, acc: 100.00%] [G loss: 4.807495]\n",
      "epoch:29 step:23108 [D loss: 0.196026, acc: 98.44%] [G loss: 4.482766]\n",
      "epoch:29 step:23109 [D loss: 0.316675, acc: 88.28%] [G loss: 4.175992]\n",
      "epoch:29 step:23110 [D loss: 0.897716, acc: 48.44%] [G loss: 3.192225]\n",
      "epoch:29 step:23111 [D loss: 0.288429, acc: 95.31%] [G loss: 4.523602]\n",
      "epoch:29 step:23112 [D loss: 0.551356, acc: 75.00%] [G loss: 4.528535]\n",
      "epoch:29 step:23113 [D loss: 0.244015, acc: 98.44%] [G loss: 3.274459]\n",
      "epoch:29 step:23114 [D loss: 0.395554, acc: 79.69%] [G loss: 2.291325]\n",
      "epoch:29 step:23115 [D loss: 0.173401, acc: 98.44%] [G loss: 4.908452]\n",
      "epoch:29 step:23116 [D loss: 0.577304, acc: 57.03%] [G loss: 5.382231]\n",
      "epoch:29 step:23117 [D loss: 1.100390, acc: 43.75%] [G loss: 2.534198]\n",
      "epoch:29 step:23118 [D loss: 0.214421, acc: 99.22%] [G loss: 3.615211]\n",
      "epoch:29 step:23119 [D loss: 0.213883, acc: 97.66%] [G loss: 5.540729]\n",
      "epoch:29 step:23120 [D loss: 1.598619, acc: 3.91%] [G loss: 4.088753]\n",
      "epoch:29 step:23121 [D loss: 0.153192, acc: 99.22%] [G loss: 3.093369]\n",
      "epoch:29 step:23122 [D loss: 0.574928, acc: 72.66%] [G loss: 4.083551]\n",
      "epoch:29 step:23123 [D loss: 0.492243, acc: 81.25%] [G loss: 3.752709]\n",
      "epoch:29 step:23124 [D loss: 0.110901, acc: 100.00%] [G loss: 2.383663]\n",
      "epoch:29 step:23125 [D loss: 1.009075, acc: 32.03%] [G loss: 2.149850]\n",
      "epoch:29 step:23126 [D loss: 0.739374, acc: 57.81%] [G loss: 2.342795]\n",
      "epoch:29 step:23127 [D loss: 0.276100, acc: 90.62%] [G loss: 6.357857]\n",
      "epoch:29 step:23128 [D loss: 0.871095, acc: 50.00%] [G loss: 2.250897]\n",
      "epoch:29 step:23129 [D loss: 0.334120, acc: 92.97%] [G loss: 3.230192]\n",
      "epoch:29 step:23130 [D loss: 0.558952, acc: 73.44%] [G loss: 5.029005]\n",
      "epoch:29 step:23131 [D loss: 0.631171, acc: 62.50%] [G loss: 2.593624]\n",
      "epoch:29 step:23132 [D loss: 0.202351, acc: 99.22%] [G loss: 4.212652]\n",
      "epoch:29 step:23133 [D loss: 0.655601, acc: 54.69%] [G loss: 3.591988]\n",
      "epoch:29 step:23134 [D loss: 0.254337, acc: 96.09%] [G loss: 3.892151]\n",
      "epoch:29 step:23135 [D loss: 0.196588, acc: 100.00%] [G loss: 2.594407]\n",
      "epoch:29 step:23136 [D loss: 0.985928, acc: 50.78%] [G loss: 3.871081]\n",
      "epoch:29 step:23137 [D loss: 0.097062, acc: 100.00%] [G loss: 5.764567]\n",
      "epoch:29 step:23138 [D loss: 0.997633, acc: 46.09%] [G loss: 3.842989]\n",
      "epoch:29 step:23139 [D loss: 0.848781, acc: 54.69%] [G loss: 4.485342]\n",
      "epoch:29 step:23140 [D loss: 0.182827, acc: 97.66%] [G loss: 3.285388]\n",
      "epoch:29 step:23141 [D loss: 0.062564, acc: 100.00%] [G loss: 2.954179]\n",
      "epoch:29 step:23142 [D loss: 0.142125, acc: 99.22%] [G loss: 4.750774]\n",
      "epoch:29 step:23143 [D loss: 0.238735, acc: 96.09%] [G loss: 4.124100]\n",
      "epoch:29 step:23144 [D loss: 0.269949, acc: 96.88%] [G loss: 2.548477]\n",
      "epoch:29 step:23145 [D loss: 0.878961, acc: 50.78%] [G loss: 3.297269]\n",
      "epoch:29 step:23146 [D loss: 0.160764, acc: 98.44%] [G loss: 2.833234]\n",
      "epoch:29 step:23147 [D loss: 0.308747, acc: 88.28%] [G loss: 3.928501]\n",
      "epoch:29 step:23148 [D loss: 0.085851, acc: 99.22%] [G loss: 6.210455]\n",
      "epoch:29 step:23149 [D loss: 0.532094, acc: 75.78%] [G loss: 3.445740]\n",
      "epoch:29 step:23150 [D loss: 0.426247, acc: 67.97%] [G loss: 4.740454]\n",
      "epoch:29 step:23151 [D loss: 1.066672, acc: 21.09%] [G loss: 4.599523]\n",
      "epoch:29 step:23152 [D loss: 0.585003, acc: 65.62%] [G loss: 3.201726]\n",
      "epoch:29 step:23153 [D loss: 0.870389, acc: 50.00%] [G loss: 3.467985]\n",
      "epoch:29 step:23154 [D loss: 0.382050, acc: 75.78%] [G loss: 3.323687]\n",
      "epoch:29 step:23155 [D loss: 0.636813, acc: 60.94%] [G loss: 4.081870]\n",
      "epoch:29 step:23156 [D loss: 0.790267, acc: 41.41%] [G loss: 4.762325]\n",
      "epoch:29 step:23157 [D loss: 0.685551, acc: 52.34%] [G loss: 2.481565]\n",
      "epoch:29 step:23158 [D loss: 0.392913, acc: 85.16%] [G loss: 3.707202]\n",
      "epoch:29 step:23159 [D loss: 0.546943, acc: 74.22%] [G loss: 4.290566]\n",
      "epoch:29 step:23160 [D loss: 0.051444, acc: 100.00%] [G loss: 6.675889]\n",
      "epoch:29 step:23161 [D loss: 0.391853, acc: 72.66%] [G loss: 4.343853]\n",
      "epoch:29 step:23162 [D loss: 0.459146, acc: 78.91%] [G loss: 4.140623]\n",
      "epoch:29 step:23163 [D loss: 0.601184, acc: 62.50%] [G loss: 4.333360]\n",
      "epoch:29 step:23164 [D loss: 0.270163, acc: 96.09%] [G loss: 4.540782]\n",
      "epoch:29 step:23165 [D loss: 0.561819, acc: 66.41%] [G loss: 4.154171]\n",
      "epoch:29 step:23166 [D loss: 0.245919, acc: 94.53%] [G loss: 2.609748]\n",
      "epoch:29 step:23167 [D loss: 0.094461, acc: 100.00%] [G loss: 3.954895]\n",
      "epoch:29 step:23168 [D loss: 0.646510, acc: 62.50%] [G loss: 3.445196]\n",
      "epoch:29 step:23169 [D loss: 0.362789, acc: 89.06%] [G loss: 2.178184]\n",
      "epoch:29 step:23170 [D loss: 0.214593, acc: 100.00%] [G loss: 4.440372]\n",
      "epoch:29 step:23171 [D loss: 1.005036, acc: 50.00%] [G loss: 2.065811]\n",
      "epoch:29 step:23172 [D loss: 0.425467, acc: 78.12%] [G loss: 3.560111]\n",
      "epoch:29 step:23173 [D loss: 0.173146, acc: 98.44%] [G loss: 2.590528]\n",
      "epoch:29 step:23174 [D loss: 0.830517, acc: 46.09%] [G loss: 3.802323]\n",
      "epoch:29 step:23175 [D loss: 0.395814, acc: 85.16%] [G loss: 2.604482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23176 [D loss: 0.131001, acc: 100.00%] [G loss: 3.827027]\n",
      "epoch:29 step:23177 [D loss: 0.249065, acc: 99.22%] [G loss: 3.859746]\n",
      "epoch:29 step:23178 [D loss: 0.140229, acc: 99.22%] [G loss: 2.836839]\n",
      "epoch:29 step:23179 [D loss: 0.223229, acc: 98.44%] [G loss: 3.798341]\n",
      "epoch:29 step:23180 [D loss: 0.477193, acc: 82.81%] [G loss: 3.118414]\n",
      "epoch:29 step:23181 [D loss: 0.485070, acc: 73.44%] [G loss: 3.243808]\n",
      "epoch:29 step:23182 [D loss: 0.350241, acc: 87.50%] [G loss: 3.552795]\n",
      "epoch:29 step:23183 [D loss: 0.389221, acc: 79.69%] [G loss: 2.798925]\n",
      "epoch:29 step:23184 [D loss: 0.879618, acc: 38.28%] [G loss: 2.427592]\n",
      "epoch:29 step:23185 [D loss: 0.388275, acc: 76.56%] [G loss: 1.458374]\n",
      "epoch:29 step:23186 [D loss: 0.111707, acc: 99.22%] [G loss: 5.756942]\n",
      "epoch:29 step:23187 [D loss: 0.469399, acc: 64.06%] [G loss: 6.704798]\n",
      "epoch:29 step:23188 [D loss: 0.516745, acc: 79.69%] [G loss: 3.667125]\n",
      "epoch:29 step:23189 [D loss: 1.223822, acc: 43.75%] [G loss: 3.849517]\n",
      "epoch:29 step:23190 [D loss: 0.209588, acc: 97.66%] [G loss: 5.048126]\n",
      "epoch:29 step:23191 [D loss: 0.510918, acc: 74.22%] [G loss: 5.751061]\n",
      "epoch:29 step:23192 [D loss: 1.290061, acc: 6.25%] [G loss: 3.348628]\n",
      "epoch:29 step:23193 [D loss: 0.375980, acc: 87.50%] [G loss: 3.569831]\n",
      "epoch:29 step:23194 [D loss: 0.295410, acc: 96.88%] [G loss: 5.414842]\n",
      "epoch:29 step:23195 [D loss: 1.449762, acc: 7.81%] [G loss: 4.506762]\n",
      "epoch:29 step:23196 [D loss: 0.126842, acc: 99.22%] [G loss: 4.810985]\n",
      "epoch:29 step:23197 [D loss: 0.514439, acc: 77.34%] [G loss: 3.427241]\n",
      "epoch:29 step:23198 [D loss: 0.173547, acc: 99.22%] [G loss: 5.095259]\n",
      "epoch:29 step:23199 [D loss: 0.362240, acc: 92.19%] [G loss: 3.279317]\n",
      "epoch:29 step:23200 [D loss: 0.327917, acc: 90.62%] [G loss: 3.530485]\n",
      "epoch:29 step:23201 [D loss: 0.601911, acc: 60.94%] [G loss: 4.775803]\n",
      "epoch:29 step:23202 [D loss: 0.970918, acc: 42.97%] [G loss: 3.365496]\n",
      "epoch:29 step:23203 [D loss: 0.291112, acc: 90.62%] [G loss: 5.076472]\n",
      "epoch:29 step:23204 [D loss: 0.078839, acc: 100.00%] [G loss: 6.946541]\n",
      "epoch:29 step:23205 [D loss: 0.431341, acc: 71.88%] [G loss: 4.186341]\n",
      "epoch:29 step:23206 [D loss: 0.799140, acc: 51.56%] [G loss: 3.874513]\n",
      "epoch:29 step:23207 [D loss: 0.744930, acc: 49.22%] [G loss: 3.416748]\n",
      "epoch:29 step:23208 [D loss: 0.189171, acc: 98.44%] [G loss: 3.964027]\n",
      "epoch:29 step:23209 [D loss: 0.451980, acc: 83.59%] [G loss: 4.664869]\n",
      "epoch:29 step:23210 [D loss: 0.177678, acc: 99.22%] [G loss: 4.317406]\n",
      "epoch:29 step:23211 [D loss: 0.942816, acc: 35.16%] [G loss: 4.543003]\n",
      "epoch:29 step:23212 [D loss: 0.061666, acc: 100.00%] [G loss: 4.371848]\n",
      "epoch:29 step:23213 [D loss: 0.121855, acc: 100.00%] [G loss: 3.332085]\n",
      "epoch:29 step:23214 [D loss: 0.294182, acc: 97.66%] [G loss: 4.440174]\n",
      "epoch:29 step:23215 [D loss: 0.159158, acc: 98.44%] [G loss: 4.604306]\n",
      "epoch:29 step:23216 [D loss: 0.263901, acc: 97.66%] [G loss: 3.233854]\n",
      "epoch:29 step:23217 [D loss: 0.137940, acc: 98.44%] [G loss: 3.336542]\n",
      "epoch:29 step:23218 [D loss: 0.217930, acc: 95.31%] [G loss: 4.503353]\n",
      "epoch:29 step:23219 [D loss: 0.359674, acc: 86.72%] [G loss: 4.043172]\n",
      "epoch:29 step:23220 [D loss: 0.517945, acc: 74.22%] [G loss: 3.381436]\n",
      "epoch:29 step:23221 [D loss: 0.111760, acc: 97.66%] [G loss: 5.215708]\n",
      "epoch:29 step:23222 [D loss: 0.179506, acc: 99.22%] [G loss: 3.068446]\n",
      "epoch:29 step:23223 [D loss: 0.452621, acc: 85.16%] [G loss: 3.146956]\n",
      "epoch:29 step:23224 [D loss: 1.031417, acc: 23.44%] [G loss: 3.095260]\n",
      "epoch:29 step:23225 [D loss: 0.293953, acc: 90.62%] [G loss: 4.378600]\n",
      "epoch:29 step:23226 [D loss: 0.520555, acc: 75.78%] [G loss: 3.951762]\n",
      "epoch:29 step:23227 [D loss: 0.120290, acc: 100.00%] [G loss: 4.812541]\n",
      "epoch:29 step:23228 [D loss: 0.340388, acc: 89.06%] [G loss: 3.943700]\n",
      "epoch:29 step:23229 [D loss: 0.312450, acc: 93.75%] [G loss: 4.623026]\n",
      "epoch:29 step:23230 [D loss: 0.487516, acc: 66.41%] [G loss: 6.659170]\n",
      "epoch:29 step:23231 [D loss: 0.368220, acc: 85.16%] [G loss: 4.711026]\n",
      "epoch:29 step:23232 [D loss: 0.182033, acc: 99.22%] [G loss: 3.106205]\n",
      "epoch:29 step:23233 [D loss: 1.134283, acc: 50.00%] [G loss: 3.767019]\n",
      "epoch:29 step:23234 [D loss: 0.638046, acc: 54.69%] [G loss: 5.937545]\n",
      "epoch:29 step:23235 [D loss: 0.771446, acc: 51.56%] [G loss: 4.268934]\n",
      "epoch:29 step:23236 [D loss: 0.551378, acc: 65.62%] [G loss: 2.938503]\n",
      "epoch:29 step:23237 [D loss: 0.755212, acc: 54.69%] [G loss: 4.064102]\n",
      "epoch:29 step:23238 [D loss: 1.114182, acc: 18.75%] [G loss: 2.605542]\n",
      "epoch:29 step:23239 [D loss: 0.796973, acc: 52.34%] [G loss: 3.173018]\n",
      "epoch:29 step:23240 [D loss: 0.563510, acc: 73.44%] [G loss: 3.769535]\n",
      "epoch:29 step:23241 [D loss: 0.339854, acc: 92.97%] [G loss: 2.763224]\n",
      "epoch:29 step:23242 [D loss: 0.287482, acc: 96.09%] [G loss: 2.643980]\n",
      "epoch:29 step:23243 [D loss: 0.376082, acc: 90.62%] [G loss: 2.372864]\n",
      "epoch:29 step:23244 [D loss: 0.215504, acc: 97.66%] [G loss: 3.123236]\n",
      "epoch:29 step:23245 [D loss: 0.407596, acc: 89.84%] [G loss: 2.745283]\n",
      "epoch:29 step:23246 [D loss: 0.399689, acc: 79.69%] [G loss: 3.399125]\n",
      "epoch:29 step:23247 [D loss: 0.245676, acc: 95.31%] [G loss: 6.200315]\n",
      "epoch:29 step:23248 [D loss: 0.469146, acc: 75.00%] [G loss: 1.754878]\n",
      "epoch:29 step:23249 [D loss: 0.239198, acc: 98.44%] [G loss: 2.642591]\n",
      "epoch:29 step:23250 [D loss: 0.070533, acc: 100.00%] [G loss: 4.362708]\n",
      "epoch:29 step:23251 [D loss: 0.898291, acc: 51.56%] [G loss: 5.317620]\n",
      "epoch:29 step:23252 [D loss: 1.015885, acc: 48.44%] [G loss: 3.417541]\n",
      "epoch:29 step:23253 [D loss: 1.141031, acc: 46.09%] [G loss: 2.184383]\n",
      "epoch:29 step:23254 [D loss: 0.122541, acc: 98.44%] [G loss: 2.672266]\n",
      "epoch:29 step:23255 [D loss: 0.319602, acc: 90.62%] [G loss: 3.168310]\n",
      "epoch:29 step:23256 [D loss: 0.884504, acc: 50.00%] [G loss: 4.714996]\n",
      "epoch:29 step:23257 [D loss: 0.366764, acc: 78.12%] [G loss: 4.889169]\n",
      "epoch:29 step:23258 [D loss: 0.521816, acc: 71.09%] [G loss: 3.167035]\n",
      "epoch:29 step:23259 [D loss: 0.344133, acc: 81.25%] [G loss: 3.684685]\n",
      "epoch:29 step:23260 [D loss: 0.050062, acc: 100.00%] [G loss: 5.978868]\n",
      "epoch:29 step:23261 [D loss: 0.296621, acc: 95.31%] [G loss: 3.118546]\n",
      "epoch:29 step:23262 [D loss: 0.324852, acc: 96.88%] [G loss: 4.673606]\n",
      "epoch:29 step:23263 [D loss: 0.215278, acc: 98.44%] [G loss: 4.530406]\n",
      "epoch:29 step:23264 [D loss: 0.437956, acc: 77.34%] [G loss: 4.357386]\n",
      "epoch:29 step:23265 [D loss: 0.488714, acc: 67.19%] [G loss: 2.486895]\n",
      "epoch:29 step:23266 [D loss: 0.648556, acc: 54.69%] [G loss: 1.831430]\n",
      "epoch:29 step:23267 [D loss: 0.646561, acc: 63.28%] [G loss: 3.659256]\n",
      "epoch:29 step:23268 [D loss: 1.316494, acc: 50.00%] [G loss: 5.528668]\n",
      "epoch:29 step:23269 [D loss: 0.771661, acc: 51.56%] [G loss: 3.802836]\n",
      "epoch:29 step:23270 [D loss: 0.345885, acc: 81.25%] [G loss: 3.286347]\n",
      "epoch:29 step:23271 [D loss: 0.189614, acc: 98.44%] [G loss: 2.464911]\n",
      "epoch:29 step:23272 [D loss: 0.781967, acc: 54.69%] [G loss: 3.790854]\n",
      "epoch:29 step:23273 [D loss: 0.204133, acc: 98.44%] [G loss: 4.868535]\n",
      "epoch:29 step:23274 [D loss: 0.629342, acc: 56.25%] [G loss: 4.701923]\n",
      "epoch:29 step:23275 [D loss: 0.464715, acc: 66.41%] [G loss: 4.423444]\n",
      "epoch:29 step:23276 [D loss: 0.233201, acc: 98.44%] [G loss: 3.862560]\n",
      "epoch:29 step:23277 [D loss: 0.079118, acc: 100.00%] [G loss: 3.770008]\n",
      "epoch:29 step:23278 [D loss: 0.297622, acc: 89.06%] [G loss: 3.807489]\n",
      "epoch:29 step:23279 [D loss: 0.067892, acc: 100.00%] [G loss: 3.026546]\n",
      "epoch:29 step:23280 [D loss: 0.518442, acc: 62.50%] [G loss: 5.904605]\n",
      "epoch:29 step:23281 [D loss: 1.417315, acc: 28.91%] [G loss: 4.581969]\n",
      "epoch:29 step:23282 [D loss: 0.653789, acc: 58.59%] [G loss: 2.696776]\n",
      "epoch:29 step:23283 [D loss: 1.090484, acc: 23.44%] [G loss: 4.312186]\n",
      "epoch:29 step:23284 [D loss: 0.745134, acc: 50.78%] [G loss: 4.810538]\n",
      "epoch:29 step:23285 [D loss: 0.506011, acc: 68.75%] [G loss: 3.330586]\n",
      "epoch:29 step:23286 [D loss: 0.324108, acc: 93.75%] [G loss: 3.967069]\n",
      "epoch:29 step:23287 [D loss: 1.008311, acc: 50.00%] [G loss: 2.655368]\n",
      "epoch:29 step:23288 [D loss: 1.045650, acc: 22.66%] [G loss: 1.676768]\n",
      "epoch:29 step:23289 [D loss: 0.435350, acc: 84.38%] [G loss: 3.235631]\n",
      "epoch:29 step:23290 [D loss: 0.604753, acc: 55.47%] [G loss: 3.030140]\n",
      "epoch:29 step:23291 [D loss: 0.205310, acc: 97.66%] [G loss: 3.934972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23292 [D loss: 0.552146, acc: 71.88%] [G loss: 2.900555]\n",
      "epoch:29 step:23293 [D loss: 0.102138, acc: 100.00%] [G loss: 5.156091]\n",
      "epoch:29 step:23294 [D loss: 0.629157, acc: 72.66%] [G loss: 2.608882]\n",
      "epoch:29 step:23295 [D loss: 0.470413, acc: 69.53%] [G loss: 2.543017]\n",
      "epoch:29 step:23296 [D loss: 0.494426, acc: 80.47%] [G loss: 3.282714]\n",
      "epoch:29 step:23297 [D loss: 0.500543, acc: 65.62%] [G loss: 5.601233]\n",
      "epoch:29 step:23298 [D loss: 0.362527, acc: 89.06%] [G loss: 3.431987]\n",
      "epoch:29 step:23299 [D loss: 0.106061, acc: 99.22%] [G loss: 3.271494]\n",
      "epoch:29 step:23300 [D loss: 0.187414, acc: 97.66%] [G loss: 3.062333]\n",
      "epoch:29 step:23301 [D loss: 0.370735, acc: 88.28%] [G loss: 3.502820]\n",
      "epoch:29 step:23302 [D loss: 0.164064, acc: 100.00%] [G loss: 3.928797]\n",
      "epoch:29 step:23303 [D loss: 0.267394, acc: 92.19%] [G loss: 2.729067]\n",
      "epoch:29 step:23304 [D loss: 0.105550, acc: 100.00%] [G loss: 5.431309]\n",
      "epoch:29 step:23305 [D loss: 0.735388, acc: 50.78%] [G loss: 3.774871]\n",
      "epoch:29 step:23306 [D loss: 0.353996, acc: 90.62%] [G loss: 3.731844]\n",
      "epoch:29 step:23307 [D loss: 0.256481, acc: 96.09%] [G loss: 3.297615]\n",
      "epoch:29 step:23308 [D loss: 0.086975, acc: 99.22%] [G loss: 3.011174]\n",
      "epoch:29 step:23309 [D loss: 0.202156, acc: 97.66%] [G loss: 3.353059]\n",
      "epoch:29 step:23310 [D loss: 0.602241, acc: 64.84%] [G loss: 4.404866]\n",
      "epoch:29 step:23311 [D loss: 0.213804, acc: 99.22%] [G loss: 3.713692]\n",
      "epoch:29 step:23312 [D loss: 0.703128, acc: 59.38%] [G loss: 2.733184]\n",
      "epoch:29 step:23313 [D loss: 0.274604, acc: 91.41%] [G loss: 3.305277]\n",
      "epoch:29 step:23314 [D loss: 0.947050, acc: 50.00%] [G loss: 4.286191]\n",
      "epoch:29 step:23315 [D loss: 0.464055, acc: 80.47%] [G loss: 4.186753]\n",
      "epoch:29 step:23316 [D loss: 0.383509, acc: 88.28%] [G loss: 4.052170]\n",
      "epoch:29 step:23317 [D loss: 0.560534, acc: 71.88%] [G loss: 2.076042]\n",
      "epoch:29 step:23318 [D loss: 0.435737, acc: 72.66%] [G loss: 3.540628]\n",
      "epoch:29 step:23319 [D loss: 0.477188, acc: 83.59%] [G loss: 2.101406]\n",
      "epoch:29 step:23320 [D loss: 0.287461, acc: 85.16%] [G loss: 6.804210]\n",
      "epoch:29 step:23321 [D loss: 0.461827, acc: 69.53%] [G loss: 1.892625]\n",
      "epoch:29 step:23322 [D loss: 0.331612, acc: 89.84%] [G loss: 2.554996]\n",
      "epoch:29 step:23323 [D loss: 0.084512, acc: 100.00%] [G loss: 3.427305]\n",
      "epoch:29 step:23324 [D loss: 0.199149, acc: 97.66%] [G loss: 3.464714]\n",
      "epoch:29 step:23325 [D loss: 0.214605, acc: 97.66%] [G loss: 3.675594]\n",
      "epoch:29 step:23326 [D loss: 0.328364, acc: 93.75%] [G loss: 4.620755]\n",
      "epoch:29 step:23327 [D loss: 0.220035, acc: 99.22%] [G loss: 3.082034]\n",
      "epoch:29 step:23328 [D loss: 0.392919, acc: 92.19%] [G loss: 3.829039]\n",
      "epoch:29 step:23329 [D loss: 0.329398, acc: 85.16%] [G loss: 5.411551]\n",
      "epoch:29 step:23330 [D loss: 0.102531, acc: 100.00%] [G loss: 7.766226]\n",
      "epoch:29 step:23331 [D loss: 0.645541, acc: 60.16%] [G loss: 2.650095]\n",
      "epoch:29 step:23332 [D loss: 0.248884, acc: 98.44%] [G loss: 1.942527]\n",
      "epoch:29 step:23333 [D loss: 1.339460, acc: 10.16%] [G loss: 1.756242]\n",
      "epoch:29 step:23334 [D loss: 0.390355, acc: 92.97%] [G loss: 3.336814]\n",
      "epoch:29 step:23335 [D loss: 0.852360, acc: 53.91%] [G loss: 3.391630]\n",
      "epoch:29 step:23336 [D loss: 0.721572, acc: 52.34%] [G loss: 2.183137]\n",
      "epoch:29 step:23337 [D loss: 1.256076, acc: 25.78%] [G loss: 5.494672]\n",
      "epoch:29 step:23338 [D loss: 0.313227, acc: 90.62%] [G loss: 4.447837]\n",
      "epoch:29 step:23339 [D loss: 0.113079, acc: 99.22%] [G loss: 2.141630]\n",
      "epoch:29 step:23340 [D loss: 0.988940, acc: 50.00%] [G loss: 4.437324]\n",
      "epoch:29 step:23341 [D loss: 0.936462, acc: 47.66%] [G loss: 5.490068]\n",
      "epoch:29 step:23342 [D loss: 0.159504, acc: 98.44%] [G loss: 2.292373]\n",
      "epoch:29 step:23343 [D loss: 0.411530, acc: 85.94%] [G loss: 2.527544]\n",
      "epoch:29 step:23344 [D loss: 0.201791, acc: 97.66%] [G loss: 4.434542]\n",
      "epoch:29 step:23345 [D loss: 0.931882, acc: 28.91%] [G loss: 2.640790]\n",
      "epoch:29 step:23346 [D loss: 0.429925, acc: 75.00%] [G loss: 4.295357]\n",
      "epoch:29 step:23347 [D loss: 0.212300, acc: 98.44%] [G loss: 5.646039]\n",
      "epoch:29 step:23348 [D loss: 0.395881, acc: 85.16%] [G loss: 2.705086]\n",
      "epoch:29 step:23349 [D loss: 0.694452, acc: 50.00%] [G loss: 3.506680]\n",
      "epoch:29 step:23350 [D loss: 0.140465, acc: 100.00%] [G loss: 3.866137]\n",
      "epoch:29 step:23351 [D loss: 0.722127, acc: 54.69%] [G loss: 2.877130]\n",
      "epoch:29 step:23352 [D loss: 0.467931, acc: 81.25%] [G loss: 4.862596]\n",
      "epoch:29 step:23353 [D loss: 0.498367, acc: 81.25%] [G loss: 4.214436]\n",
      "epoch:29 step:23354 [D loss: 0.126916, acc: 100.00%] [G loss: 5.564944]\n",
      "epoch:29 step:23355 [D loss: 0.410074, acc: 89.84%] [G loss: 4.369791]\n",
      "epoch:29 step:23356 [D loss: 0.555008, acc: 77.34%] [G loss: 3.720989]\n",
      "epoch:29 step:23357 [D loss: 0.649383, acc: 67.97%] [G loss: 2.957536]\n",
      "epoch:29 step:23358 [D loss: 0.459165, acc: 82.03%] [G loss: 3.302488]\n",
      "epoch:29 step:23359 [D loss: 0.741748, acc: 54.69%] [G loss: 4.047096]\n",
      "epoch:29 step:23360 [D loss: 0.161113, acc: 100.00%] [G loss: 3.630993]\n",
      "epoch:29 step:23361 [D loss: 0.981705, acc: 21.88%] [G loss: 3.621013]\n",
      "epoch:29 step:23362 [D loss: 0.664963, acc: 60.94%] [G loss: 6.194800]\n",
      "epoch:29 step:23363 [D loss: 0.269963, acc: 95.31%] [G loss: 3.157528]\n",
      "epoch:29 step:23364 [D loss: 0.096310, acc: 100.00%] [G loss: 4.514301]\n",
      "epoch:29 step:23365 [D loss: 0.265273, acc: 97.66%] [G loss: 4.783386]\n",
      "epoch:29 step:23366 [D loss: 0.383780, acc: 77.34%] [G loss: 4.551252]\n",
      "epoch:29 step:23367 [D loss: 1.026836, acc: 50.78%] [G loss: 2.533569]\n",
      "epoch:29 step:23368 [D loss: 0.327566, acc: 84.38%] [G loss: 5.510374]\n",
      "epoch:29 step:23369 [D loss: 0.067607, acc: 100.00%] [G loss: 4.341351]\n",
      "epoch:29 step:23370 [D loss: 0.397756, acc: 87.50%] [G loss: 4.716383]\n",
      "epoch:29 step:23371 [D loss: 0.609273, acc: 60.16%] [G loss: 4.473953]\n",
      "epoch:29 step:23372 [D loss: 0.518709, acc: 75.78%] [G loss: 2.836544]\n",
      "epoch:29 step:23373 [D loss: 0.218694, acc: 99.22%] [G loss: 4.116197]\n",
      "epoch:29 step:23374 [D loss: 0.387374, acc: 82.03%] [G loss: 2.305485]\n",
      "epoch:29 step:23375 [D loss: 0.364151, acc: 95.31%] [G loss: 3.904723]\n",
      "epoch:29 step:23376 [D loss: 0.248966, acc: 95.31%] [G loss: 3.958512]\n",
      "epoch:29 step:23377 [D loss: 0.266087, acc: 94.53%] [G loss: 3.096371]\n",
      "epoch:29 step:23378 [D loss: 0.509571, acc: 76.56%] [G loss: 4.121340]\n",
      "epoch:29 step:23379 [D loss: 0.242389, acc: 97.66%] [G loss: 3.197711]\n",
      "epoch:29 step:23380 [D loss: 1.298095, acc: 11.72%] [G loss: 3.299625]\n",
      "epoch:29 step:23381 [D loss: 0.602771, acc: 63.28%] [G loss: 4.428753]\n",
      "epoch:29 step:23382 [D loss: 0.327924, acc: 91.41%] [G loss: 3.425043]\n",
      "epoch:29 step:23383 [D loss: 0.547807, acc: 71.09%] [G loss: 3.841958]\n",
      "epoch:29 step:23384 [D loss: 0.239003, acc: 96.09%] [G loss: 2.629246]\n",
      "epoch:29 step:23385 [D loss: 0.221423, acc: 99.22%] [G loss: 4.009408]\n",
      "epoch:29 step:23386 [D loss: 0.287848, acc: 90.62%] [G loss: 3.883407]\n",
      "epoch:29 step:23387 [D loss: 0.301466, acc: 94.53%] [G loss: 4.306505]\n",
      "epoch:29 step:23388 [D loss: 0.630469, acc: 66.41%] [G loss: 3.833745]\n",
      "epoch:29 step:23389 [D loss: 0.524238, acc: 63.28%] [G loss: 2.099035]\n",
      "epoch:29 step:23390 [D loss: 0.147162, acc: 100.00%] [G loss: 3.833982]\n",
      "epoch:29 step:23391 [D loss: 0.157528, acc: 98.44%] [G loss: 5.461921]\n",
      "epoch:29 step:23392 [D loss: 0.916071, acc: 53.12%] [G loss: 4.462529]\n",
      "epoch:29 step:23393 [D loss: 0.469747, acc: 82.03%] [G loss: 2.898755]\n",
      "epoch:29 step:23394 [D loss: 0.260405, acc: 93.75%] [G loss: 3.649786]\n",
      "epoch:29 step:23395 [D loss: 0.517126, acc: 79.69%] [G loss: 3.078709]\n",
      "epoch:29 step:23396 [D loss: 0.701571, acc: 56.25%] [G loss: 4.246971]\n",
      "epoch:29 step:23397 [D loss: 0.587175, acc: 61.72%] [G loss: 3.978806]\n",
      "epoch:29 step:23398 [D loss: 0.255676, acc: 94.53%] [G loss: 4.103138]\n",
      "epoch:29 step:23399 [D loss: 0.275759, acc: 95.31%] [G loss: 3.338646]\n",
      "epoch:29 step:23400 [D loss: 0.669412, acc: 56.25%] [G loss: 4.641785]\n",
      "epoch:29 step:23401 [D loss: 0.403213, acc: 71.09%] [G loss: 7.819370]\n",
      "epoch:29 step:23402 [D loss: 0.173933, acc: 99.22%] [G loss: 4.960316]\n",
      "epoch:29 step:23403 [D loss: 0.472302, acc: 82.81%] [G loss: 3.534393]\n",
      "epoch:29 step:23404 [D loss: 0.326735, acc: 92.97%] [G loss: 3.084368]\n",
      "epoch:29 step:23405 [D loss: 0.059993, acc: 100.00%] [G loss: 3.809833]\n",
      "epoch:29 step:23406 [D loss: 0.587924, acc: 60.16%] [G loss: 5.276684]\n",
      "epoch:29 step:23407 [D loss: 0.525847, acc: 67.97%] [G loss: 4.570883]\n",
      "epoch:29 step:23408 [D loss: 0.912956, acc: 34.38%] [G loss: 4.381971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23409 [D loss: 0.105169, acc: 100.00%] [G loss: 4.727602]\n",
      "epoch:29 step:23410 [D loss: 0.458058, acc: 79.69%] [G loss: 3.094494]\n",
      "epoch:29 step:23411 [D loss: 0.155264, acc: 100.00%] [G loss: 4.008494]\n",
      "epoch:29 step:23412 [D loss: 0.811484, acc: 51.56%] [G loss: 2.273196]\n",
      "epoch:29 step:23413 [D loss: 0.724064, acc: 50.00%] [G loss: 2.975729]\n",
      "epoch:29 step:23414 [D loss: 0.340298, acc: 85.16%] [G loss: 3.510911]\n",
      "epoch:29 step:23415 [D loss: 0.884933, acc: 39.84%] [G loss: 4.927471]\n",
      "epoch:29 step:23416 [D loss: 0.506415, acc: 69.53%] [G loss: 4.004163]\n",
      "epoch:29 step:23417 [D loss: 0.124659, acc: 100.00%] [G loss: 5.846799]\n",
      "epoch:29 step:23418 [D loss: 0.583852, acc: 56.25%] [G loss: 3.571496]\n",
      "epoch:29 step:23419 [D loss: 0.516972, acc: 78.91%] [G loss: 4.255191]\n",
      "epoch:29 step:23420 [D loss: 0.437334, acc: 72.66%] [G loss: 3.033797]\n",
      "epoch:29 step:23421 [D loss: 0.455900, acc: 85.16%] [G loss: 4.524056]\n",
      "epoch:29 step:23422 [D loss: 0.257703, acc: 92.19%] [G loss: 5.213605]\n",
      "epoch:29 step:23423 [D loss: 0.570021, acc: 65.62%] [G loss: 3.999440]\n",
      "epoch:29 step:23424 [D loss: 0.487604, acc: 76.56%] [G loss: 4.205327]\n",
      "epoch:29 step:23425 [D loss: 0.934874, acc: 38.28%] [G loss: 5.563653]\n",
      "epoch:29 step:23426 [D loss: 0.334947, acc: 85.94%] [G loss: 1.896436]\n",
      "epoch:29 step:23427 [D loss: 0.594755, acc: 63.28%] [G loss: 2.768538]\n",
      "epoch:29 step:23428 [D loss: 0.433955, acc: 83.59%] [G loss: 2.078542]\n",
      "epoch:29 step:23429 [D loss: 1.153088, acc: 17.97%] [G loss: 2.794626]\n",
      "epoch:29 step:23430 [D loss: 0.439720, acc: 78.91%] [G loss: 2.350155]\n",
      "epoch:30 step:23431 [D loss: 0.103199, acc: 100.00%] [G loss: 5.145929]\n",
      "epoch:30 step:23432 [D loss: 0.207073, acc: 96.09%] [G loss: 5.047470]\n",
      "epoch:30 step:23433 [D loss: 0.325478, acc: 96.09%] [G loss: 5.163022]\n",
      "epoch:30 step:23434 [D loss: 0.784957, acc: 51.56%] [G loss: 2.662229]\n",
      "epoch:30 step:23435 [D loss: 0.179006, acc: 98.44%] [G loss: 5.291270]\n",
      "epoch:30 step:23436 [D loss: 0.543047, acc: 63.28%] [G loss: 4.934637]\n",
      "epoch:30 step:23437 [D loss: 0.672899, acc: 50.78%] [G loss: 4.535455]\n",
      "epoch:30 step:23438 [D loss: 0.799820, acc: 44.53%] [G loss: 3.335089]\n",
      "epoch:30 step:23439 [D loss: 0.276418, acc: 92.97%] [G loss: 4.063777]\n",
      "epoch:30 step:23440 [D loss: 0.434181, acc: 78.91%] [G loss: 3.802526]\n",
      "epoch:30 step:23441 [D loss: 0.338772, acc: 92.97%] [G loss: 3.959120]\n",
      "epoch:30 step:23442 [D loss: 0.639774, acc: 61.72%] [G loss: 2.526989]\n",
      "epoch:30 step:23443 [D loss: 0.173667, acc: 98.44%] [G loss: 3.744807]\n",
      "epoch:30 step:23444 [D loss: 0.258649, acc: 95.31%] [G loss: 3.392430]\n",
      "epoch:30 step:23445 [D loss: 0.254737, acc: 95.31%] [G loss: 4.857455]\n",
      "epoch:30 step:23446 [D loss: 0.357777, acc: 94.53%] [G loss: 2.978277]\n",
      "epoch:30 step:23447 [D loss: 0.167649, acc: 100.00%] [G loss: 4.197425]\n",
      "epoch:30 step:23448 [D loss: 0.394313, acc: 84.38%] [G loss: 2.965774]\n",
      "epoch:30 step:23449 [D loss: 0.421217, acc: 82.03%] [G loss: 3.510990]\n",
      "epoch:30 step:23450 [D loss: 0.555844, acc: 70.31%] [G loss: 5.140617]\n",
      "epoch:30 step:23451 [D loss: 0.170251, acc: 97.66%] [G loss: 3.281243]\n",
      "epoch:30 step:23452 [D loss: 0.463490, acc: 77.34%] [G loss: 5.264045]\n",
      "epoch:30 step:23453 [D loss: 0.389398, acc: 84.38%] [G loss: 3.925383]\n",
      "epoch:30 step:23454 [D loss: 0.621706, acc: 57.03%] [G loss: 4.591949]\n",
      "epoch:30 step:23455 [D loss: 0.530717, acc: 64.84%] [G loss: 3.738229]\n",
      "epoch:30 step:23456 [D loss: 0.079094, acc: 100.00%] [G loss: 4.101915]\n",
      "epoch:30 step:23457 [D loss: 0.157089, acc: 99.22%] [G loss: 6.635446]\n",
      "epoch:30 step:23458 [D loss: 0.335580, acc: 79.69%] [G loss: 4.497801]\n",
      "epoch:30 step:23459 [D loss: 0.169955, acc: 98.44%] [G loss: 4.580001]\n",
      "epoch:30 step:23460 [D loss: 0.229847, acc: 95.31%] [G loss: 5.368145]\n",
      "epoch:30 step:23461 [D loss: 0.119874, acc: 99.22%] [G loss: 4.690580]\n",
      "epoch:30 step:23462 [D loss: 0.438564, acc: 78.12%] [G loss: 4.089940]\n",
      "epoch:30 step:23463 [D loss: 0.402238, acc: 76.56%] [G loss: 5.540383]\n",
      "epoch:30 step:23464 [D loss: 0.520767, acc: 69.53%] [G loss: 2.049379]\n",
      "epoch:30 step:23465 [D loss: 0.581816, acc: 70.31%] [G loss: 2.982882]\n",
      "epoch:30 step:23466 [D loss: 0.999020, acc: 50.00%] [G loss: 5.014055]\n",
      "epoch:30 step:23467 [D loss: 0.170217, acc: 98.44%] [G loss: 2.960929]\n",
      "epoch:30 step:23468 [D loss: 0.333507, acc: 82.81%] [G loss: 5.414492]\n",
      "epoch:30 step:23469 [D loss: 0.896968, acc: 48.44%] [G loss: 5.441793]\n",
      "epoch:30 step:23470 [D loss: 1.013423, acc: 51.56%] [G loss: 5.458522]\n",
      "epoch:30 step:23471 [D loss: 0.448104, acc: 69.53%] [G loss: 4.345393]\n",
      "epoch:30 step:23472 [D loss: 0.310169, acc: 82.81%] [G loss: 6.259016]\n",
      "epoch:30 step:23473 [D loss: 0.526634, acc: 76.56%] [G loss: 5.496481]\n",
      "epoch:30 step:23474 [D loss: 0.444691, acc: 82.03%] [G loss: 3.962549]\n",
      "epoch:30 step:23475 [D loss: 0.192817, acc: 97.66%] [G loss: 3.924327]\n",
      "epoch:30 step:23476 [D loss: 0.454786, acc: 84.38%] [G loss: 5.314764]\n",
      "epoch:30 step:23477 [D loss: 0.525488, acc: 74.22%] [G loss: 4.283937]\n",
      "epoch:30 step:23478 [D loss: 0.908522, acc: 30.47%] [G loss: 3.560669]\n",
      "epoch:30 step:23479 [D loss: 0.263550, acc: 96.09%] [G loss: 5.466609]\n",
      "epoch:30 step:23480 [D loss: 1.173582, acc: 40.62%] [G loss: 2.105302]\n",
      "epoch:30 step:23481 [D loss: 0.192681, acc: 98.44%] [G loss: 2.896414]\n",
      "epoch:30 step:23482 [D loss: 0.356889, acc: 89.84%] [G loss: 4.281754]\n",
      "epoch:30 step:23483 [D loss: 0.638939, acc: 60.16%] [G loss: 2.977145]\n",
      "epoch:30 step:23484 [D loss: 0.693297, acc: 57.81%] [G loss: 3.762511]\n",
      "epoch:30 step:23485 [D loss: 0.175096, acc: 100.00%] [G loss: 4.101176]\n",
      "epoch:30 step:23486 [D loss: 0.556581, acc: 65.62%] [G loss: 3.217036]\n",
      "epoch:30 step:23487 [D loss: 1.331374, acc: 8.59%] [G loss: 2.950836]\n",
      "epoch:30 step:23488 [D loss: 0.343281, acc: 83.59%] [G loss: 2.872578]\n",
      "epoch:30 step:23489 [D loss: 0.810487, acc: 52.34%] [G loss: 3.472460]\n",
      "epoch:30 step:23490 [D loss: 0.360583, acc: 93.75%] [G loss: 3.870990]\n",
      "epoch:30 step:23491 [D loss: 0.356156, acc: 94.53%] [G loss: 3.349147]\n",
      "epoch:30 step:23492 [D loss: 0.268412, acc: 92.19%] [G loss: 5.459365]\n",
      "epoch:30 step:23493 [D loss: 0.177375, acc: 98.44%] [G loss: 3.253092]\n",
      "epoch:30 step:23494 [D loss: 0.796975, acc: 53.91%] [G loss: 3.634470]\n",
      "epoch:30 step:23495 [D loss: 0.303930, acc: 87.50%] [G loss: 3.365719]\n",
      "epoch:30 step:23496 [D loss: 0.326856, acc: 82.03%] [G loss: 2.749831]\n",
      "epoch:30 step:23497 [D loss: 0.232995, acc: 92.19%] [G loss: 3.333436]\n",
      "epoch:30 step:23498 [D loss: 0.385178, acc: 80.47%] [G loss: 4.658322]\n",
      "epoch:30 step:23499 [D loss: 0.102679, acc: 100.00%] [G loss: 5.017189]\n",
      "epoch:30 step:23500 [D loss: 0.394851, acc: 82.03%] [G loss: 4.111136]\n",
      "epoch:30 step:23501 [D loss: 1.216527, acc: 28.12%] [G loss: 3.508259]\n",
      "epoch:30 step:23502 [D loss: 0.494323, acc: 67.97%] [G loss: 3.195771]\n",
      "epoch:30 step:23503 [D loss: 0.327783, acc: 89.84%] [G loss: 3.678626]\n",
      "epoch:30 step:23504 [D loss: 0.603960, acc: 63.28%] [G loss: 6.262218]\n",
      "epoch:30 step:23505 [D loss: 0.212830, acc: 96.09%] [G loss: 3.088464]\n",
      "epoch:30 step:23506 [D loss: 0.778161, acc: 57.81%] [G loss: 5.583396]\n",
      "epoch:30 step:23507 [D loss: 0.331671, acc: 89.84%] [G loss: 3.996627]\n",
      "epoch:30 step:23508 [D loss: 0.265634, acc: 88.28%] [G loss: 4.396542]\n",
      "epoch:30 step:23509 [D loss: 0.655517, acc: 58.59%] [G loss: 2.309825]\n",
      "epoch:30 step:23510 [D loss: 0.518895, acc: 64.84%] [G loss: 3.990088]\n",
      "epoch:30 step:23511 [D loss: 0.248278, acc: 96.88%] [G loss: 3.350859]\n",
      "epoch:30 step:23512 [D loss: 0.157317, acc: 100.00%] [G loss: 2.013944]\n",
      "epoch:30 step:23513 [D loss: 0.281262, acc: 97.66%] [G loss: 4.947145]\n",
      "epoch:30 step:23514 [D loss: 0.396135, acc: 84.38%] [G loss: 4.269250]\n",
      "epoch:30 step:23515 [D loss: 0.730880, acc: 53.91%] [G loss: 3.299744]\n",
      "epoch:30 step:23516 [D loss: 0.646342, acc: 62.50%] [G loss: 3.885036]\n",
      "epoch:30 step:23517 [D loss: 0.687951, acc: 54.69%] [G loss: 2.833120]\n",
      "epoch:30 step:23518 [D loss: 0.406056, acc: 75.00%] [G loss: 2.663635]\n",
      "epoch:30 step:23519 [D loss: 0.789950, acc: 52.34%] [G loss: 4.929430]\n",
      "epoch:30 step:23520 [D loss: 0.437749, acc: 80.47%] [G loss: 2.721797]\n",
      "epoch:30 step:23521 [D loss: 0.154117, acc: 100.00%] [G loss: 3.871813]\n",
      "epoch:30 step:23522 [D loss: 0.145516, acc: 100.00%] [G loss: 5.477562]\n",
      "epoch:30 step:23523 [D loss: 0.175835, acc: 100.00%] [G loss: 3.763384]\n",
      "epoch:30 step:23524 [D loss: 0.288256, acc: 89.06%] [G loss: 3.190529]\n",
      "epoch:30 step:23525 [D loss: 0.361738, acc: 85.94%] [G loss: 6.052204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23526 [D loss: 0.404698, acc: 88.28%] [G loss: 3.123954]\n",
      "epoch:30 step:23527 [D loss: 1.251761, acc: 10.94%] [G loss: 3.532444]\n",
      "epoch:30 step:23528 [D loss: 0.240169, acc: 97.66%] [G loss: 4.241491]\n",
      "epoch:30 step:23529 [D loss: 0.142122, acc: 99.22%] [G loss: 5.638620]\n",
      "epoch:30 step:23530 [D loss: 0.639618, acc: 67.97%] [G loss: 2.879956]\n",
      "epoch:30 step:23531 [D loss: 0.407705, acc: 91.41%] [G loss: 2.374946]\n",
      "epoch:30 step:23532 [D loss: 0.056873, acc: 100.00%] [G loss: 3.896278]\n",
      "epoch:30 step:23533 [D loss: 0.808197, acc: 45.31%] [G loss: 4.133156]\n",
      "epoch:30 step:23534 [D loss: 0.136508, acc: 98.44%] [G loss: 4.133175]\n",
      "epoch:30 step:23535 [D loss: 0.381393, acc: 82.81%] [G loss: 5.379346]\n",
      "epoch:30 step:23536 [D loss: 0.531124, acc: 78.12%] [G loss: 3.399788]\n",
      "epoch:30 step:23537 [D loss: 0.738939, acc: 55.47%] [G loss: 5.497067]\n",
      "epoch:30 step:23538 [D loss: 0.930679, acc: 50.78%] [G loss: 4.841773]\n",
      "epoch:30 step:23539 [D loss: 0.447921, acc: 80.47%] [G loss: 4.087411]\n",
      "epoch:30 step:23540 [D loss: 0.834468, acc: 51.56%] [G loss: 5.749002]\n",
      "epoch:30 step:23541 [D loss: 0.587950, acc: 72.66%] [G loss: 4.824054]\n",
      "epoch:30 step:23542 [D loss: 0.542159, acc: 67.19%] [G loss: 2.925035]\n",
      "epoch:30 step:23543 [D loss: 0.226475, acc: 98.44%] [G loss: 3.118033]\n",
      "epoch:30 step:23544 [D loss: 0.355750, acc: 91.41%] [G loss: 3.860168]\n",
      "epoch:30 step:23545 [D loss: 0.372214, acc: 87.50%] [G loss: 5.897727]\n",
      "epoch:30 step:23546 [D loss: 0.131034, acc: 100.00%] [G loss: 3.515662]\n",
      "epoch:30 step:23547 [D loss: 0.453115, acc: 71.09%] [G loss: 2.824136]\n",
      "epoch:30 step:23548 [D loss: 0.205043, acc: 97.66%] [G loss: 4.369339]\n",
      "epoch:30 step:23549 [D loss: 0.232207, acc: 95.31%] [G loss: 4.368704]\n",
      "epoch:30 step:23550 [D loss: 0.441476, acc: 78.91%] [G loss: 2.887802]\n",
      "epoch:30 step:23551 [D loss: 0.079574, acc: 100.00%] [G loss: 3.486802]\n",
      "epoch:30 step:23552 [D loss: 0.099031, acc: 100.00%] [G loss: 5.762487]\n",
      "epoch:30 step:23553 [D loss: 0.108046, acc: 100.00%] [G loss: 4.227009]\n",
      "epoch:30 step:23554 [D loss: 1.399997, acc: 9.38%] [G loss: 5.326323]\n",
      "epoch:30 step:23555 [D loss: 1.163005, acc: 48.44%] [G loss: 2.599046]\n",
      "epoch:30 step:23556 [D loss: 0.164109, acc: 98.44%] [G loss: 3.710677]\n",
      "epoch:30 step:23557 [D loss: 0.403064, acc: 76.56%] [G loss: 4.951525]\n",
      "epoch:30 step:23558 [D loss: 0.218068, acc: 98.44%] [G loss: 3.990349]\n",
      "epoch:30 step:23559 [D loss: 1.132648, acc: 29.69%] [G loss: 4.788149]\n",
      "epoch:30 step:23560 [D loss: 0.157306, acc: 100.00%] [G loss: 2.089707]\n",
      "epoch:30 step:23561 [D loss: 0.195941, acc: 97.66%] [G loss: 4.146616]\n",
      "epoch:30 step:23562 [D loss: 0.382352, acc: 83.59%] [G loss: 3.616575]\n",
      "epoch:30 step:23563 [D loss: 0.340088, acc: 88.28%] [G loss: 4.302743]\n",
      "epoch:30 step:23564 [D loss: 0.225338, acc: 95.31%] [G loss: 4.277256]\n",
      "epoch:30 step:23565 [D loss: 0.273819, acc: 96.88%] [G loss: 5.235666]\n",
      "epoch:30 step:23566 [D loss: 0.167731, acc: 100.00%] [G loss: 3.624888]\n",
      "epoch:30 step:23567 [D loss: 0.437596, acc: 75.78%] [G loss: 2.798123]\n",
      "epoch:30 step:23568 [D loss: 0.530165, acc: 75.00%] [G loss: 3.323839]\n",
      "epoch:30 step:23569 [D loss: 0.311433, acc: 89.84%] [G loss: 3.393548]\n",
      "epoch:30 step:23570 [D loss: 0.715261, acc: 56.25%] [G loss: 3.459973]\n",
      "epoch:30 step:23571 [D loss: 0.104422, acc: 100.00%] [G loss: 3.987547]\n",
      "epoch:30 step:23572 [D loss: 0.149641, acc: 99.22%] [G loss: 4.452864]\n",
      "epoch:30 step:23573 [D loss: 1.070932, acc: 46.09%] [G loss: 4.638470]\n",
      "epoch:30 step:23574 [D loss: 0.424331, acc: 76.56%] [G loss: 2.142526]\n",
      "epoch:30 step:23575 [D loss: 0.312789, acc: 95.31%] [G loss: 2.983325]\n",
      "epoch:30 step:23576 [D loss: 0.221964, acc: 97.66%] [G loss: 5.834820]\n",
      "epoch:30 step:23577 [D loss: 0.318712, acc: 93.75%] [G loss: 3.933610]\n",
      "epoch:30 step:23578 [D loss: 0.515947, acc: 77.34%] [G loss: 4.197389]\n",
      "epoch:30 step:23579 [D loss: 0.250488, acc: 92.97%] [G loss: 4.921813]\n",
      "epoch:30 step:23580 [D loss: 0.875117, acc: 50.78%] [G loss: 3.642183]\n",
      "epoch:30 step:23581 [D loss: 0.499528, acc: 76.56%] [G loss: 3.272749]\n",
      "epoch:30 step:23582 [D loss: 0.299451, acc: 95.31%] [G loss: 3.932690]\n",
      "epoch:30 step:23583 [D loss: 0.252034, acc: 97.66%] [G loss: 2.525350]\n",
      "epoch:30 step:23584 [D loss: 0.157520, acc: 99.22%] [G loss: 4.835200]\n",
      "epoch:30 step:23585 [D loss: 0.565546, acc: 67.19%] [G loss: 7.246788]\n",
      "epoch:30 step:23586 [D loss: 0.164238, acc: 99.22%] [G loss: 2.782217]\n",
      "epoch:30 step:23587 [D loss: 0.363161, acc: 93.75%] [G loss: 4.778135]\n",
      "epoch:30 step:23588 [D loss: 0.173623, acc: 96.09%] [G loss: 3.685513]\n",
      "epoch:30 step:23589 [D loss: 0.018459, acc: 100.00%] [G loss: 5.521677]\n",
      "epoch:30 step:23590 [D loss: 2.155475, acc: 3.12%] [G loss: 4.354773]\n",
      "epoch:30 step:23591 [D loss: 0.423128, acc: 77.34%] [G loss: 3.926190]\n",
      "epoch:30 step:23592 [D loss: 0.200306, acc: 98.44%] [G loss: 3.496702]\n",
      "epoch:30 step:23593 [D loss: 0.558701, acc: 71.88%] [G loss: 6.450535]\n",
      "epoch:30 step:23594 [D loss: 0.730686, acc: 59.38%] [G loss: 5.944844]\n",
      "epoch:30 step:23595 [D loss: 0.532810, acc: 67.19%] [G loss: 1.597452]\n",
      "epoch:30 step:23596 [D loss: 0.396968, acc: 78.12%] [G loss: 4.542460]\n",
      "epoch:30 step:23597 [D loss: 0.307257, acc: 93.75%] [G loss: 5.632777]\n",
      "epoch:30 step:23598 [D loss: 1.111489, acc: 50.00%] [G loss: 4.925122]\n",
      "epoch:30 step:23599 [D loss: 0.288794, acc: 94.53%] [G loss: 3.789671]\n",
      "epoch:30 step:23600 [D loss: 0.629554, acc: 57.81%] [G loss: 3.237047]\n",
      "epoch:30 step:23601 [D loss: 0.497156, acc: 79.69%] [G loss: 4.723742]\n",
      "epoch:30 step:23602 [D loss: 0.330113, acc: 91.41%] [G loss: 3.604854]\n",
      "epoch:30 step:23603 [D loss: 0.483907, acc: 70.31%] [G loss: 3.107507]\n",
      "epoch:30 step:23604 [D loss: 0.481784, acc: 75.78%] [G loss: 5.661325]\n",
      "epoch:30 step:23605 [D loss: 0.371266, acc: 91.41%] [G loss: 4.716276]\n",
      "epoch:30 step:23606 [D loss: 0.740916, acc: 47.66%] [G loss: 3.262291]\n",
      "epoch:30 step:23607 [D loss: 0.120865, acc: 100.00%] [G loss: 2.621881]\n",
      "epoch:30 step:23608 [D loss: 0.402215, acc: 87.50%] [G loss: 2.334976]\n",
      "epoch:30 step:23609 [D loss: 0.466935, acc: 84.38%] [G loss: 3.682690]\n",
      "epoch:30 step:23610 [D loss: 0.616651, acc: 65.62%] [G loss: 2.033128]\n",
      "epoch:30 step:23611 [D loss: 0.196697, acc: 100.00%] [G loss: 6.161911]\n",
      "epoch:30 step:23612 [D loss: 0.303808, acc: 92.19%] [G loss: 2.795902]\n",
      "epoch:30 step:23613 [D loss: 0.621152, acc: 60.94%] [G loss: 3.668402]\n",
      "epoch:30 step:23614 [D loss: 0.699502, acc: 55.47%] [G loss: 4.857769]\n",
      "epoch:30 step:23615 [D loss: 0.508954, acc: 61.72%] [G loss: 6.035271]\n",
      "epoch:30 step:23616 [D loss: 0.190136, acc: 95.31%] [G loss: 4.376021]\n",
      "epoch:30 step:23617 [D loss: 0.400644, acc: 84.38%] [G loss: 3.429255]\n",
      "epoch:30 step:23618 [D loss: 0.600725, acc: 65.62%] [G loss: 2.534434]\n",
      "epoch:30 step:23619 [D loss: 0.436243, acc: 72.66%] [G loss: 5.225214]\n",
      "epoch:30 step:23620 [D loss: 0.453728, acc: 77.34%] [G loss: 4.708685]\n",
      "epoch:30 step:23621 [D loss: 0.210014, acc: 99.22%] [G loss: 2.981239]\n",
      "epoch:30 step:23622 [D loss: 0.717175, acc: 53.12%] [G loss: 4.122942]\n",
      "epoch:30 step:23623 [D loss: 0.249344, acc: 97.66%] [G loss: 3.434853]\n",
      "epoch:30 step:23624 [D loss: 0.313225, acc: 91.41%] [G loss: 3.759786]\n",
      "epoch:30 step:23625 [D loss: 0.476680, acc: 83.59%] [G loss: 3.704640]\n",
      "epoch:30 step:23626 [D loss: 0.217473, acc: 98.44%] [G loss: 2.207095]\n",
      "epoch:30 step:23627 [D loss: 1.539995, acc: 50.00%] [G loss: 4.825223]\n",
      "epoch:30 step:23628 [D loss: 0.249626, acc: 91.41%] [G loss: 4.539536]\n",
      "epoch:30 step:23629 [D loss: 0.426900, acc: 71.88%] [G loss: 5.681727]\n",
      "epoch:30 step:23630 [D loss: 0.337837, acc: 87.50%] [G loss: 5.304216]\n",
      "epoch:30 step:23631 [D loss: 0.754312, acc: 56.25%] [G loss: 4.580976]\n",
      "epoch:30 step:23632 [D loss: 0.349766, acc: 82.03%] [G loss: 2.702185]\n",
      "epoch:30 step:23633 [D loss: 0.230318, acc: 94.53%] [G loss: 5.198698]\n",
      "epoch:30 step:23634 [D loss: 0.385524, acc: 88.28%] [G loss: 3.520821]\n",
      "epoch:30 step:23635 [D loss: 0.898924, acc: 48.44%] [G loss: 4.461551]\n",
      "epoch:30 step:23636 [D loss: 0.602742, acc: 60.94%] [G loss: 1.738028]\n",
      "epoch:30 step:23637 [D loss: 0.115405, acc: 100.00%] [G loss: 5.100729]\n",
      "epoch:30 step:23638 [D loss: 0.612978, acc: 68.75%] [G loss: 3.966361]\n",
      "epoch:30 step:23639 [D loss: 0.390933, acc: 90.62%] [G loss: 3.387757]\n",
      "epoch:30 step:23640 [D loss: 0.162800, acc: 98.44%] [G loss: 3.960363]\n",
      "epoch:30 step:23641 [D loss: 0.341307, acc: 83.59%] [G loss: 6.158388]\n",
      "epoch:30 step:23642 [D loss: 0.461672, acc: 75.00%] [G loss: 3.066478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23643 [D loss: 1.482731, acc: 25.00%] [G loss: 3.294469]\n",
      "epoch:30 step:23644 [D loss: 0.283246, acc: 90.62%] [G loss: 4.590426]\n",
      "epoch:30 step:23645 [D loss: 0.459777, acc: 77.34%] [G loss: 3.803151]\n",
      "epoch:30 step:23646 [D loss: 0.313132, acc: 95.31%] [G loss: 2.156136]\n",
      "epoch:30 step:23647 [D loss: 0.405045, acc: 84.38%] [G loss: 4.538737]\n",
      "epoch:30 step:23648 [D loss: 0.237027, acc: 96.09%] [G loss: 3.757155]\n",
      "epoch:30 step:23649 [D loss: 0.228627, acc: 96.88%] [G loss: 4.836333]\n",
      "epoch:30 step:23650 [D loss: 1.163998, acc: 32.81%] [G loss: 4.807014]\n",
      "epoch:30 step:23651 [D loss: 0.953567, acc: 33.59%] [G loss: 5.025979]\n",
      "epoch:30 step:23652 [D loss: 0.468355, acc: 87.50%] [G loss: 5.121848]\n",
      "epoch:30 step:23653 [D loss: 0.727393, acc: 56.25%] [G loss: 4.711753]\n",
      "epoch:30 step:23654 [D loss: 0.148532, acc: 100.00%] [G loss: 4.324368]\n",
      "epoch:30 step:23655 [D loss: 0.286612, acc: 95.31%] [G loss: 4.277030]\n",
      "epoch:30 step:23656 [D loss: 0.373194, acc: 89.06%] [G loss: 2.946330]\n",
      "epoch:30 step:23657 [D loss: 0.172928, acc: 100.00%] [G loss: 4.661230]\n",
      "epoch:30 step:23658 [D loss: 0.430318, acc: 82.03%] [G loss: 4.634583]\n",
      "epoch:30 step:23659 [D loss: 0.368539, acc: 89.84%] [G loss: 4.768819]\n",
      "epoch:30 step:23660 [D loss: 0.769469, acc: 53.12%] [G loss: 3.043799]\n",
      "epoch:30 step:23661 [D loss: 0.391448, acc: 76.56%] [G loss: 4.662825]\n",
      "epoch:30 step:23662 [D loss: 0.937398, acc: 39.84%] [G loss: 3.612468]\n",
      "epoch:30 step:23663 [D loss: 0.342222, acc: 81.25%] [G loss: 5.208309]\n",
      "epoch:30 step:23664 [D loss: 1.574737, acc: 38.28%] [G loss: 6.122671]\n",
      "epoch:30 step:23665 [D loss: 0.596411, acc: 67.19%] [G loss: 4.367514]\n",
      "epoch:30 step:23666 [D loss: 0.306096, acc: 94.53%] [G loss: 4.982584]\n",
      "epoch:30 step:23667 [D loss: 0.218384, acc: 96.88%] [G loss: 3.785125]\n",
      "epoch:30 step:23668 [D loss: 0.228987, acc: 98.44%] [G loss: 4.324111]\n",
      "epoch:30 step:23669 [D loss: 0.834893, acc: 53.91%] [G loss: 4.768624]\n",
      "epoch:30 step:23670 [D loss: 0.896159, acc: 40.62%] [G loss: 3.583537]\n",
      "epoch:30 step:23671 [D loss: 0.471918, acc: 82.03%] [G loss: 4.415572]\n",
      "epoch:30 step:23672 [D loss: 0.140788, acc: 99.22%] [G loss: 4.425103]\n",
      "epoch:30 step:23673 [D loss: 0.061166, acc: 100.00%] [G loss: 4.760401]\n",
      "epoch:30 step:23674 [D loss: 0.174866, acc: 99.22%] [G loss: 3.117156]\n",
      "epoch:30 step:23675 [D loss: 0.519245, acc: 72.66%] [G loss: 3.465860]\n",
      "epoch:30 step:23676 [D loss: 0.756690, acc: 49.22%] [G loss: 4.128476]\n",
      "epoch:30 step:23677 [D loss: 0.360932, acc: 89.84%] [G loss: 2.403592]\n",
      "epoch:30 step:23678 [D loss: 1.048343, acc: 46.88%] [G loss: 2.339886]\n",
      "epoch:30 step:23679 [D loss: 0.310297, acc: 96.88%] [G loss: 2.413700]\n",
      "epoch:30 step:23680 [D loss: 0.332573, acc: 90.62%] [G loss: 4.493360]\n",
      "epoch:30 step:23681 [D loss: 0.189341, acc: 99.22%] [G loss: 4.171144]\n",
      "epoch:30 step:23682 [D loss: 1.244113, acc: 10.16%] [G loss: 2.888918]\n",
      "epoch:30 step:23683 [D loss: 0.328606, acc: 97.66%] [G loss: 3.468529]\n",
      "epoch:30 step:23684 [D loss: 0.148401, acc: 98.44%] [G loss: 2.757267]\n",
      "epoch:30 step:23685 [D loss: 0.364308, acc: 89.06%] [G loss: 2.982090]\n",
      "epoch:30 step:23686 [D loss: 0.514908, acc: 61.72%] [G loss: 4.136754]\n",
      "epoch:30 step:23687 [D loss: 0.360766, acc: 87.50%] [G loss: 2.187128]\n",
      "epoch:30 step:23688 [D loss: 0.191043, acc: 98.44%] [G loss: 3.167266]\n",
      "epoch:30 step:23689 [D loss: 1.365556, acc: 7.81%] [G loss: 3.390051]\n",
      "epoch:30 step:23690 [D loss: 0.270050, acc: 96.09%] [G loss: 4.623398]\n",
      "epoch:30 step:23691 [D loss: 0.550014, acc: 78.91%] [G loss: 1.804289]\n",
      "epoch:30 step:23692 [D loss: 0.187309, acc: 98.44%] [G loss: 2.791469]\n",
      "epoch:30 step:23693 [D loss: 0.368731, acc: 82.03%] [G loss: 3.625815]\n",
      "epoch:30 step:23694 [D loss: 0.779837, acc: 44.53%] [G loss: 2.822444]\n",
      "epoch:30 step:23695 [D loss: 0.574938, acc: 67.19%] [G loss: 3.536657]\n",
      "epoch:30 step:23696 [D loss: 0.404435, acc: 77.34%] [G loss: 5.309907]\n",
      "epoch:30 step:23697 [D loss: 1.269423, acc: 13.28%] [G loss: 4.287909]\n",
      "epoch:30 step:23698 [D loss: 0.303678, acc: 96.88%] [G loss: 2.480943]\n",
      "epoch:30 step:23699 [D loss: 0.246636, acc: 96.09%] [G loss: 3.089556]\n",
      "epoch:30 step:23700 [D loss: 0.262061, acc: 95.31%] [G loss: 2.858910]\n",
      "epoch:30 step:23701 [D loss: 0.417396, acc: 75.00%] [G loss: 3.514628]\n",
      "epoch:30 step:23702 [D loss: 0.111984, acc: 99.22%] [G loss: 4.051235]\n",
      "epoch:30 step:23703 [D loss: 0.510859, acc: 71.09%] [G loss: 2.511703]\n",
      "epoch:30 step:23704 [D loss: 0.782115, acc: 47.66%] [G loss: 5.145182]\n",
      "epoch:30 step:23705 [D loss: 0.394454, acc: 86.72%] [G loss: 3.182518]\n",
      "epoch:30 step:23706 [D loss: 0.588353, acc: 68.75%] [G loss: 4.543878]\n",
      "epoch:30 step:23707 [D loss: 0.341105, acc: 92.97%] [G loss: 3.734503]\n",
      "epoch:30 step:23708 [D loss: 0.711943, acc: 57.03%] [G loss: 3.991878]\n",
      "epoch:30 step:23709 [D loss: 0.643287, acc: 57.03%] [G loss: 3.086855]\n",
      "epoch:30 step:23710 [D loss: 0.560336, acc: 72.66%] [G loss: 3.087264]\n",
      "epoch:30 step:23711 [D loss: 0.752266, acc: 54.69%] [G loss: 3.612981]\n",
      "epoch:30 step:23712 [D loss: 0.222716, acc: 97.66%] [G loss: 2.707802]\n",
      "epoch:30 step:23713 [D loss: 0.229997, acc: 97.66%] [G loss: 3.740028]\n",
      "epoch:30 step:23714 [D loss: 0.153566, acc: 97.66%] [G loss: 3.304302]\n",
      "epoch:30 step:23715 [D loss: 0.609604, acc: 57.81%] [G loss: 6.850115]\n",
      "epoch:30 step:23716 [D loss: 0.125351, acc: 100.00%] [G loss: 4.205286]\n",
      "epoch:30 step:23717 [D loss: 0.506295, acc: 76.56%] [G loss: 4.379827]\n",
      "epoch:30 step:23718 [D loss: 0.718001, acc: 57.03%] [G loss: 2.088931]\n",
      "epoch:30 step:23719 [D loss: 0.286495, acc: 96.09%] [G loss: 3.985360]\n",
      "epoch:30 step:23720 [D loss: 0.313562, acc: 91.41%] [G loss: 2.983584]\n",
      "epoch:30 step:23721 [D loss: 1.224957, acc: 35.94%] [G loss: 3.204725]\n",
      "epoch:30 step:23722 [D loss: 0.391067, acc: 78.12%] [G loss: 4.612369]\n",
      "epoch:30 step:23723 [D loss: 0.171668, acc: 96.09%] [G loss: 3.605498]\n",
      "epoch:30 step:23724 [D loss: 0.359448, acc: 91.41%] [G loss: 2.496691]\n",
      "epoch:30 step:23725 [D loss: 0.126502, acc: 100.00%] [G loss: 3.106921]\n",
      "epoch:30 step:23726 [D loss: 0.370311, acc: 86.72%] [G loss: 4.119627]\n",
      "epoch:30 step:23727 [D loss: 0.280665, acc: 89.84%] [G loss: 1.992709]\n",
      "epoch:30 step:23728 [D loss: 0.421628, acc: 75.78%] [G loss: 2.854652]\n",
      "epoch:30 step:23729 [D loss: 0.293550, acc: 97.66%] [G loss: 3.738781]\n",
      "epoch:30 step:23730 [D loss: 0.353134, acc: 91.41%] [G loss: 2.272861]\n",
      "epoch:30 step:23731 [D loss: 0.644289, acc: 61.72%] [G loss: 4.112131]\n",
      "epoch:30 step:23732 [D loss: 0.478112, acc: 81.25%] [G loss: 3.041582]\n",
      "epoch:30 step:23733 [D loss: 0.571847, acc: 63.28%] [G loss: 3.310513]\n",
      "epoch:30 step:23734 [D loss: 0.555336, acc: 58.59%] [G loss: 2.718708]\n",
      "epoch:30 step:23735 [D loss: 0.373460, acc: 92.19%] [G loss: 3.770285]\n",
      "epoch:30 step:23736 [D loss: 0.149821, acc: 100.00%] [G loss: 5.319081]\n",
      "epoch:30 step:23737 [D loss: 0.486059, acc: 78.12%] [G loss: 4.241385]\n",
      "epoch:30 step:23738 [D loss: 0.220442, acc: 97.66%] [G loss: 6.127235]\n",
      "epoch:30 step:23739 [D loss: 0.251875, acc: 96.09%] [G loss: 4.501317]\n",
      "epoch:30 step:23740 [D loss: 0.189676, acc: 96.88%] [G loss: 5.314306]\n",
      "epoch:30 step:23741 [D loss: 1.436985, acc: 7.03%] [G loss: 2.963778]\n",
      "epoch:30 step:23742 [D loss: 0.199673, acc: 97.66%] [G loss: 2.987929]\n",
      "epoch:30 step:23743 [D loss: 0.331117, acc: 89.84%] [G loss: 2.795429]\n",
      "epoch:30 step:23744 [D loss: 0.323639, acc: 94.53%] [G loss: 3.257247]\n",
      "epoch:30 step:23745 [D loss: 0.546300, acc: 75.78%] [G loss: 3.911004]\n",
      "epoch:30 step:23746 [D loss: 0.509761, acc: 78.12%] [G loss: 3.807412]\n",
      "epoch:30 step:23747 [D loss: 0.432591, acc: 85.16%] [G loss: 3.877988]\n",
      "epoch:30 step:23748 [D loss: 0.703296, acc: 55.47%] [G loss: 3.188959]\n",
      "epoch:30 step:23749 [D loss: 0.280144, acc: 96.09%] [G loss: 4.909025]\n",
      "epoch:30 step:23750 [D loss: 0.381922, acc: 85.94%] [G loss: 3.222647]\n",
      "epoch:30 step:23751 [D loss: 0.290479, acc: 96.09%] [G loss: 3.956841]\n",
      "epoch:30 step:23752 [D loss: 0.133131, acc: 100.00%] [G loss: 3.977307]\n",
      "epoch:30 step:23753 [D loss: 0.415205, acc: 75.00%] [G loss: 4.586425]\n",
      "epoch:30 step:23754 [D loss: 0.215584, acc: 98.44%] [G loss: 6.151021]\n",
      "epoch:30 step:23755 [D loss: 0.208997, acc: 99.22%] [G loss: 3.782962]\n",
      "epoch:30 step:23756 [D loss: 0.586107, acc: 66.41%] [G loss: 3.838562]\n",
      "epoch:30 step:23757 [D loss: 0.176989, acc: 99.22%] [G loss: 2.588262]\n",
      "epoch:30 step:23758 [D loss: 0.598327, acc: 60.94%] [G loss: 3.669735]\n",
      "epoch:30 step:23759 [D loss: 0.174285, acc: 99.22%] [G loss: 4.029444]\n",
      "epoch:30 step:23760 [D loss: 0.242289, acc: 93.75%] [G loss: 3.032620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23761 [D loss: 0.777580, acc: 53.12%] [G loss: 3.936324]\n",
      "epoch:30 step:23762 [D loss: 1.206023, acc: 44.53%] [G loss: 2.467682]\n",
      "epoch:30 step:23763 [D loss: 0.763121, acc: 50.78%] [G loss: 3.846834]\n",
      "epoch:30 step:23764 [D loss: 0.604601, acc: 62.50%] [G loss: 6.138801]\n",
      "epoch:30 step:23765 [D loss: 0.464189, acc: 76.56%] [G loss: 4.300896]\n",
      "epoch:30 step:23766 [D loss: 0.370171, acc: 92.97%] [G loss: 2.072462]\n",
      "epoch:30 step:23767 [D loss: 0.277716, acc: 92.19%] [G loss: 4.507900]\n",
      "epoch:30 step:23768 [D loss: 0.363879, acc: 92.97%] [G loss: 3.079523]\n",
      "epoch:30 step:23769 [D loss: 0.454207, acc: 89.06%] [G loss: 2.595358]\n",
      "epoch:30 step:23770 [D loss: 0.686919, acc: 57.81%] [G loss: 3.900007]\n",
      "epoch:30 step:23771 [D loss: 0.492393, acc: 69.53%] [G loss: 2.044723]\n",
      "epoch:30 step:23772 [D loss: 0.671913, acc: 55.47%] [G loss: 4.232456]\n",
      "epoch:30 step:23773 [D loss: 0.235726, acc: 96.09%] [G loss: 4.227147]\n",
      "epoch:30 step:23774 [D loss: 0.142572, acc: 98.44%] [G loss: 4.899253]\n",
      "epoch:30 step:23775 [D loss: 0.131408, acc: 99.22%] [G loss: 4.925111]\n",
      "epoch:30 step:23776 [D loss: 0.286073, acc: 93.75%] [G loss: 3.889150]\n",
      "epoch:30 step:23777 [D loss: 0.328884, acc: 86.72%] [G loss: 3.779428]\n",
      "epoch:30 step:23778 [D loss: 0.231178, acc: 93.75%] [G loss: 3.333960]\n",
      "epoch:30 step:23779 [D loss: 1.164981, acc: 42.19%] [G loss: 4.025496]\n",
      "epoch:30 step:23780 [D loss: 0.357106, acc: 85.94%] [G loss: 3.364825]\n",
      "epoch:30 step:23781 [D loss: 0.717633, acc: 57.81%] [G loss: 2.487890]\n",
      "epoch:30 step:23782 [D loss: 0.386764, acc: 80.47%] [G loss: 4.582999]\n",
      "epoch:30 step:23783 [D loss: 0.200905, acc: 98.44%] [G loss: 4.221884]\n",
      "epoch:30 step:23784 [D loss: 0.412818, acc: 88.28%] [G loss: 3.427983]\n",
      "epoch:30 step:23785 [D loss: 0.286827, acc: 96.88%] [G loss: 4.079561]\n",
      "epoch:30 step:23786 [D loss: 0.142401, acc: 99.22%] [G loss: 6.446983]\n",
      "epoch:30 step:23787 [D loss: 0.317837, acc: 94.53%] [G loss: 1.823683]\n",
      "epoch:30 step:23788 [D loss: 0.193198, acc: 99.22%] [G loss: 3.096448]\n",
      "epoch:30 step:23789 [D loss: 0.388869, acc: 91.41%] [G loss: 5.755208]\n",
      "epoch:30 step:23790 [D loss: 0.586123, acc: 65.62%] [G loss: 3.958766]\n",
      "epoch:30 step:23791 [D loss: 0.737460, acc: 59.38%] [G loss: 4.477120]\n",
      "epoch:30 step:23792 [D loss: 0.152845, acc: 100.00%] [G loss: 3.729086]\n",
      "epoch:30 step:23793 [D loss: 0.224684, acc: 97.66%] [G loss: 5.327347]\n",
      "epoch:30 step:23794 [D loss: 0.452575, acc: 73.44%] [G loss: 4.048187]\n",
      "epoch:30 step:23795 [D loss: 0.187279, acc: 100.00%] [G loss: 4.478754]\n",
      "epoch:30 step:23796 [D loss: 0.748987, acc: 52.34%] [G loss: 6.124493]\n",
      "epoch:30 step:23797 [D loss: 0.421680, acc: 78.91%] [G loss: 3.108019]\n",
      "epoch:30 step:23798 [D loss: 0.265154, acc: 93.75%] [G loss: 3.859702]\n",
      "epoch:30 step:23799 [D loss: 0.208762, acc: 99.22%] [G loss: 4.023762]\n",
      "epoch:30 step:23800 [D loss: 0.421064, acc: 86.72%] [G loss: 3.993497]\n",
      "epoch:30 step:23801 [D loss: 0.928988, acc: 49.22%] [G loss: 4.112380]\n",
      "epoch:30 step:23802 [D loss: 0.224929, acc: 96.88%] [G loss: 4.257298]\n",
      "epoch:30 step:23803 [D loss: 0.425014, acc: 82.03%] [G loss: 5.066182]\n",
      "epoch:30 step:23804 [D loss: 0.052381, acc: 100.00%] [G loss: 3.899458]\n",
      "epoch:30 step:23805 [D loss: 0.391511, acc: 75.78%] [G loss: 4.017194]\n",
      "epoch:30 step:23806 [D loss: 0.091551, acc: 100.00%] [G loss: 4.242626]\n",
      "epoch:30 step:23807 [D loss: 0.176123, acc: 97.66%] [G loss: 3.942000]\n",
      "epoch:30 step:23808 [D loss: 0.588673, acc: 61.72%] [G loss: 2.675412]\n",
      "epoch:30 step:23809 [D loss: 0.036590, acc: 99.22%] [G loss: 3.899771]\n",
      "epoch:30 step:23810 [D loss: 0.306207, acc: 90.62%] [G loss: 3.805267]\n",
      "epoch:30 step:23811 [D loss: 0.578873, acc: 62.50%] [G loss: 4.369137]\n",
      "epoch:30 step:23812 [D loss: 0.531805, acc: 71.88%] [G loss: 5.498116]\n",
      "epoch:30 step:23813 [D loss: 0.471761, acc: 81.25%] [G loss: 4.920812]\n",
      "epoch:30 step:23814 [D loss: 0.240625, acc: 96.09%] [G loss: 3.717071]\n",
      "epoch:30 step:23815 [D loss: 0.420240, acc: 78.12%] [G loss: 2.336738]\n",
      "epoch:30 step:23816 [D loss: 1.051356, acc: 35.16%] [G loss: 4.610432]\n",
      "epoch:30 step:23817 [D loss: 0.336777, acc: 85.16%] [G loss: 3.649471]\n",
      "epoch:30 step:23818 [D loss: 1.656252, acc: 20.31%] [G loss: 4.130586]\n",
      "epoch:30 step:23819 [D loss: 0.862664, acc: 46.09%] [G loss: 4.128506]\n",
      "epoch:30 step:23820 [D loss: 0.181990, acc: 100.00%] [G loss: 3.642596]\n",
      "epoch:30 step:23821 [D loss: 1.176810, acc: 19.53%] [G loss: 5.627783]\n",
      "epoch:30 step:23822 [D loss: 0.343740, acc: 90.62%] [G loss: 4.777800]\n",
      "epoch:30 step:23823 [D loss: 0.195144, acc: 97.66%] [G loss: 3.813258]\n",
      "epoch:30 step:23824 [D loss: 0.096597, acc: 99.22%] [G loss: 6.129382]\n",
      "epoch:30 step:23825 [D loss: 0.708737, acc: 54.69%] [G loss: 5.195998]\n",
      "epoch:30 step:23826 [D loss: 0.707252, acc: 56.25%] [G loss: 4.416219]\n",
      "epoch:30 step:23827 [D loss: 0.200465, acc: 93.75%] [G loss: 3.038798]\n",
      "epoch:30 step:23828 [D loss: 0.260091, acc: 96.09%] [G loss: 3.135760]\n",
      "epoch:30 step:23829 [D loss: 0.505682, acc: 78.91%] [G loss: 3.111068]\n",
      "epoch:30 step:23830 [D loss: 0.479505, acc: 78.12%] [G loss: 6.542671]\n",
      "epoch:30 step:23831 [D loss: 0.089558, acc: 100.00%] [G loss: 4.485265]\n",
      "epoch:30 step:23832 [D loss: 0.177211, acc: 98.44%] [G loss: 4.282471]\n",
      "epoch:30 step:23833 [D loss: 0.380560, acc: 92.19%] [G loss: 3.524061]\n",
      "epoch:30 step:23834 [D loss: 0.600223, acc: 55.47%] [G loss: 4.006660]\n",
      "epoch:30 step:23835 [D loss: 0.475555, acc: 77.34%] [G loss: 2.144660]\n",
      "epoch:30 step:23836 [D loss: 0.455002, acc: 79.69%] [G loss: 4.715508]\n",
      "epoch:30 step:23837 [D loss: 0.274877, acc: 94.53%] [G loss: 3.369928]\n",
      "epoch:30 step:23838 [D loss: 1.025366, acc: 38.28%] [G loss: 3.125060]\n",
      "epoch:30 step:23839 [D loss: 0.525303, acc: 76.56%] [G loss: 4.836309]\n",
      "epoch:30 step:23840 [D loss: 0.317663, acc: 80.47%] [G loss: 4.646450]\n",
      "epoch:30 step:23841 [D loss: 0.193197, acc: 98.44%] [G loss: 2.622765]\n",
      "epoch:30 step:23842 [D loss: 0.201276, acc: 96.88%] [G loss: 3.858191]\n",
      "epoch:30 step:23843 [D loss: 0.839328, acc: 39.84%] [G loss: 4.355061]\n",
      "epoch:30 step:23844 [D loss: 0.622557, acc: 58.59%] [G loss: 2.361774]\n",
      "epoch:30 step:23845 [D loss: 0.151219, acc: 99.22%] [G loss: 4.980706]\n",
      "epoch:30 step:23846 [D loss: 0.399295, acc: 80.47%] [G loss: 4.456627]\n",
      "epoch:30 step:23847 [D loss: 0.294664, acc: 95.31%] [G loss: 5.313307]\n",
      "epoch:30 step:23848 [D loss: 0.749508, acc: 54.69%] [G loss: 3.638232]\n",
      "epoch:30 step:23849 [D loss: 0.374915, acc: 88.28%] [G loss: 3.155962]\n",
      "epoch:30 step:23850 [D loss: 0.818517, acc: 53.91%] [G loss: 5.765140]\n",
      "epoch:30 step:23851 [D loss: 0.257694, acc: 96.88%] [G loss: 5.739867]\n",
      "epoch:30 step:23852 [D loss: 0.728957, acc: 53.91%] [G loss: 3.353309]\n",
      "epoch:30 step:23853 [D loss: 0.714476, acc: 54.69%] [G loss: 1.341444]\n",
      "epoch:30 step:23854 [D loss: 0.827078, acc: 53.91%] [G loss: 2.788268]\n",
      "epoch:30 step:23855 [D loss: 0.493215, acc: 82.81%] [G loss: 2.456691]\n",
      "epoch:30 step:23856 [D loss: 1.205292, acc: 44.53%] [G loss: 2.042660]\n",
      "epoch:30 step:23857 [D loss: 0.247269, acc: 96.88%] [G loss: 5.078557]\n",
      "epoch:30 step:23858 [D loss: 0.396595, acc: 88.28%] [G loss: 4.529648]\n",
      "epoch:30 step:23859 [D loss: 0.210936, acc: 95.31%] [G loss: 4.327899]\n",
      "epoch:30 step:23860 [D loss: 1.109149, acc: 22.66%] [G loss: 3.776587]\n",
      "epoch:30 step:23861 [D loss: 0.163226, acc: 100.00%] [G loss: 1.882194]\n",
      "epoch:30 step:23862 [D loss: 0.718940, acc: 54.69%] [G loss: 4.533760]\n",
      "epoch:30 step:23863 [D loss: 1.135502, acc: 50.00%] [G loss: 3.127744]\n",
      "epoch:30 step:23864 [D loss: 0.081070, acc: 100.00%] [G loss: 4.723580]\n",
      "epoch:30 step:23865 [D loss: 0.966144, acc: 32.81%] [G loss: 5.084299]\n",
      "epoch:30 step:23866 [D loss: 0.321669, acc: 87.50%] [G loss: 3.005535]\n",
      "epoch:30 step:23867 [D loss: 0.811353, acc: 51.56%] [G loss: 3.064443]\n",
      "epoch:30 step:23868 [D loss: 0.919226, acc: 47.66%] [G loss: 5.223460]\n",
      "epoch:30 step:23869 [D loss: 0.262486, acc: 93.75%] [G loss: 3.619258]\n",
      "epoch:30 step:23870 [D loss: 0.685046, acc: 57.03%] [G loss: 4.378022]\n",
      "epoch:30 step:23871 [D loss: 0.243541, acc: 98.44%] [G loss: 4.364552]\n",
      "epoch:30 step:23872 [D loss: 0.364702, acc: 92.19%] [G loss: 2.580561]\n",
      "epoch:30 step:23873 [D loss: 0.305530, acc: 93.75%] [G loss: 4.167227]\n",
      "epoch:30 step:23874 [D loss: 0.356471, acc: 80.47%] [G loss: 3.828274]\n",
      "epoch:30 step:23875 [D loss: 0.505440, acc: 75.00%] [G loss: 5.749676]\n",
      "epoch:30 step:23876 [D loss: 0.132873, acc: 98.44%] [G loss: 4.780363]\n",
      "epoch:30 step:23877 [D loss: 0.520574, acc: 62.50%] [G loss: 4.427924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23878 [D loss: 0.757059, acc: 52.34%] [G loss: 1.452099]\n",
      "epoch:30 step:23879 [D loss: 0.231827, acc: 96.88%] [G loss: 3.557170]\n",
      "epoch:30 step:23880 [D loss: 0.298679, acc: 88.28%] [G loss: 2.181566]\n",
      "epoch:30 step:23881 [D loss: 0.370434, acc: 85.94%] [G loss: 3.584893]\n",
      "epoch:30 step:23882 [D loss: 0.160616, acc: 100.00%] [G loss: 5.043008]\n",
      "epoch:30 step:23883 [D loss: 0.416005, acc: 78.12%] [G loss: 2.957728]\n",
      "epoch:30 step:23884 [D loss: 0.178623, acc: 99.22%] [G loss: 3.236535]\n",
      "epoch:30 step:23885 [D loss: 0.677038, acc: 60.16%] [G loss: 4.382470]\n",
      "epoch:30 step:23886 [D loss: 0.658005, acc: 60.16%] [G loss: 5.377677]\n",
      "epoch:30 step:23887 [D loss: 0.418419, acc: 85.94%] [G loss: 1.862098]\n",
      "epoch:30 step:23888 [D loss: 0.746462, acc: 52.34%] [G loss: 3.978773]\n",
      "epoch:30 step:23889 [D loss: 0.254091, acc: 97.66%] [G loss: 2.548661]\n",
      "epoch:30 step:23890 [D loss: 0.266733, acc: 97.66%] [G loss: 3.587417]\n",
      "epoch:30 step:23891 [D loss: 0.227990, acc: 96.09%] [G loss: 4.413003]\n",
      "epoch:30 step:23892 [D loss: 0.491966, acc: 70.31%] [G loss: 6.812355]\n",
      "epoch:30 step:23893 [D loss: 0.226718, acc: 99.22%] [G loss: 3.547284]\n",
      "epoch:30 step:23894 [D loss: 0.220301, acc: 100.00%] [G loss: 4.715400]\n",
      "epoch:30 step:23895 [D loss: 0.506015, acc: 78.91%] [G loss: 3.915090]\n",
      "epoch:30 step:23896 [D loss: 0.426601, acc: 68.75%] [G loss: 5.292626]\n",
      "epoch:30 step:23897 [D loss: 0.219846, acc: 95.31%] [G loss: 4.022097]\n",
      "epoch:30 step:23898 [D loss: 0.578732, acc: 69.53%] [G loss: 3.491718]\n",
      "epoch:30 step:23899 [D loss: 0.267226, acc: 90.62%] [G loss: 4.585418]\n",
      "epoch:30 step:23900 [D loss: 0.388932, acc: 78.91%] [G loss: 4.302033]\n",
      "epoch:30 step:23901 [D loss: 0.473128, acc: 68.75%] [G loss: 3.258826]\n",
      "epoch:30 step:23902 [D loss: 0.345700, acc: 88.28%] [G loss: 3.312022]\n",
      "epoch:30 step:23903 [D loss: 0.617824, acc: 64.84%] [G loss: 3.206500]\n",
      "epoch:30 step:23904 [D loss: 0.300123, acc: 94.53%] [G loss: 2.490927]\n",
      "epoch:30 step:23905 [D loss: 0.594796, acc: 67.97%] [G loss: 4.221802]\n",
      "epoch:30 step:23906 [D loss: 0.363279, acc: 85.94%] [G loss: 2.306216]\n",
      "epoch:30 step:23907 [D loss: 0.062755, acc: 100.00%] [G loss: 3.759566]\n",
      "epoch:30 step:23908 [D loss: 0.100360, acc: 100.00%] [G loss: 6.758697]\n",
      "epoch:30 step:23909 [D loss: 0.796422, acc: 45.31%] [G loss: 3.027174]\n",
      "epoch:30 step:23910 [D loss: 0.308771, acc: 92.97%] [G loss: 3.179738]\n",
      "epoch:30 step:23911 [D loss: 0.396016, acc: 74.22%] [G loss: 3.417540]\n",
      "epoch:30 step:23912 [D loss: 0.824547, acc: 39.84%] [G loss: 5.279752]\n",
      "epoch:30 step:23913 [D loss: 1.271316, acc: 50.00%] [G loss: 1.952102]\n",
      "epoch:30 step:23914 [D loss: 0.208484, acc: 97.66%] [G loss: 3.253241]\n",
      "epoch:30 step:23915 [D loss: 0.266257, acc: 97.66%] [G loss: 1.885107]\n",
      "epoch:30 step:23916 [D loss: 0.554468, acc: 71.09%] [G loss: 3.980157]\n",
      "epoch:30 step:23917 [D loss: 0.453346, acc: 77.34%] [G loss: 2.978582]\n",
      "epoch:30 step:23918 [D loss: 0.370364, acc: 82.03%] [G loss: 3.207626]\n",
      "epoch:30 step:23919 [D loss: 0.046476, acc: 100.00%] [G loss: 3.574472]\n",
      "epoch:30 step:23920 [D loss: 0.090204, acc: 100.00%] [G loss: 3.827175]\n",
      "epoch:30 step:23921 [D loss: 0.709066, acc: 53.91%] [G loss: 4.994682]\n",
      "epoch:30 step:23922 [D loss: 0.340762, acc: 86.72%] [G loss: 2.763118]\n",
      "epoch:30 step:23923 [D loss: 0.207237, acc: 98.44%] [G loss: 3.115355]\n",
      "epoch:30 step:23924 [D loss: 0.335206, acc: 95.31%] [G loss: 3.867420]\n",
      "epoch:30 step:23925 [D loss: 0.314265, acc: 94.53%] [G loss: 2.911916]\n",
      "epoch:30 step:23926 [D loss: 0.338444, acc: 93.75%] [G loss: 3.533360]\n",
      "epoch:30 step:23927 [D loss: 0.178470, acc: 100.00%] [G loss: 4.569077]\n",
      "epoch:30 step:23928 [D loss: 0.178082, acc: 98.44%] [G loss: 5.034886]\n",
      "epoch:30 step:23929 [D loss: 0.194862, acc: 97.66%] [G loss: 5.283866]\n",
      "epoch:30 step:23930 [D loss: 0.672850, acc: 60.94%] [G loss: 6.272827]\n",
      "epoch:30 step:23931 [D loss: 0.241153, acc: 98.44%] [G loss: 2.714454]\n",
      "epoch:30 step:23932 [D loss: 0.957394, acc: 43.75%] [G loss: 3.883591]\n",
      "epoch:30 step:23933 [D loss: 0.363443, acc: 92.19%] [G loss: 3.144475]\n",
      "epoch:30 step:23934 [D loss: 0.439871, acc: 75.78%] [G loss: 1.347887]\n",
      "epoch:30 step:23935 [D loss: 0.736142, acc: 53.12%] [G loss: 2.412685]\n",
      "epoch:30 step:23936 [D loss: 0.449100, acc: 68.75%] [G loss: 4.234931]\n",
      "epoch:30 step:23937 [D loss: 1.381585, acc: 7.81%] [G loss: 4.185506]\n",
      "epoch:30 step:23938 [D loss: 0.786885, acc: 46.88%] [G loss: 2.477341]\n",
      "epoch:30 step:23939 [D loss: 0.491794, acc: 72.66%] [G loss: 2.644459]\n",
      "epoch:30 step:23940 [D loss: 0.138691, acc: 100.00%] [G loss: 4.393239]\n",
      "epoch:30 step:23941 [D loss: 0.064630, acc: 100.00%] [G loss: 6.549057]\n",
      "epoch:30 step:23942 [D loss: 1.438052, acc: 3.12%] [G loss: 6.913073]\n",
      "epoch:30 step:23943 [D loss: 0.688267, acc: 55.47%] [G loss: 3.389236]\n",
      "epoch:30 step:23944 [D loss: 0.278921, acc: 96.09%] [G loss: 4.088698]\n",
      "epoch:30 step:23945 [D loss: 0.503882, acc: 78.91%] [G loss: 4.387444]\n",
      "epoch:30 step:23946 [D loss: 0.294738, acc: 98.44%] [G loss: 4.047382]\n",
      "epoch:30 step:23947 [D loss: 0.127211, acc: 100.00%] [G loss: 4.891591]\n",
      "epoch:30 step:23948 [D loss: 0.273377, acc: 96.09%] [G loss: 4.024345]\n",
      "epoch:30 step:23949 [D loss: 0.177216, acc: 97.66%] [G loss: 3.725855]\n",
      "epoch:30 step:23950 [D loss: 0.609458, acc: 66.41%] [G loss: 4.369201]\n",
      "epoch:30 step:23951 [D loss: 0.154894, acc: 100.00%] [G loss: 4.427118]\n",
      "epoch:30 step:23952 [D loss: 0.683282, acc: 59.38%] [G loss: 3.524822]\n",
      "epoch:30 step:23953 [D loss: 0.144932, acc: 99.22%] [G loss: 4.809192]\n",
      "epoch:30 step:23954 [D loss: 0.613381, acc: 60.94%] [G loss: 3.384240]\n",
      "epoch:30 step:23955 [D loss: 0.362780, acc: 82.03%] [G loss: 4.182653]\n",
      "epoch:30 step:23956 [D loss: 0.087185, acc: 100.00%] [G loss: 4.440329]\n",
      "epoch:30 step:23957 [D loss: 0.193341, acc: 96.88%] [G loss: 6.662631]\n",
      "epoch:30 step:23958 [D loss: 0.461770, acc: 77.34%] [G loss: 3.844702]\n",
      "epoch:30 step:23959 [D loss: 0.290469, acc: 89.06%] [G loss: 3.072189]\n",
      "epoch:30 step:23960 [D loss: 0.180005, acc: 99.22%] [G loss: 4.937921]\n",
      "epoch:30 step:23961 [D loss: 0.228912, acc: 96.88%] [G loss: 3.387325]\n",
      "epoch:30 step:23962 [D loss: 0.949798, acc: 35.94%] [G loss: 4.893108]\n",
      "epoch:30 step:23963 [D loss: 0.369057, acc: 94.53%] [G loss: 3.848895]\n",
      "epoch:30 step:23964 [D loss: 0.135926, acc: 99.22%] [G loss: 4.834678]\n",
      "epoch:30 step:23965 [D loss: 0.547177, acc: 67.97%] [G loss: 3.143908]\n",
      "epoch:30 step:23966 [D loss: 0.258464, acc: 98.44%] [G loss: 3.099335]\n",
      "epoch:30 step:23967 [D loss: 0.175746, acc: 97.66%] [G loss: 3.540040]\n",
      "epoch:30 step:23968 [D loss: 0.157723, acc: 99.22%] [G loss: 5.346599]\n",
      "epoch:30 step:23969 [D loss: 0.477696, acc: 82.81%] [G loss: 2.265511]\n",
      "epoch:30 step:23970 [D loss: 0.612211, acc: 67.97%] [G loss: 2.448324]\n",
      "epoch:30 step:23971 [D loss: 0.159377, acc: 100.00%] [G loss: 5.309748]\n",
      "epoch:30 step:23972 [D loss: 0.274780, acc: 98.44%] [G loss: 5.323461]\n",
      "epoch:30 step:23973 [D loss: 0.304943, acc: 96.88%] [G loss: 5.497133]\n",
      "epoch:30 step:23974 [D loss: 0.770915, acc: 52.34%] [G loss: 5.602707]\n",
      "epoch:30 step:23975 [D loss: 0.220853, acc: 96.88%] [G loss: 3.914763]\n",
      "epoch:30 step:23976 [D loss: 0.321559, acc: 90.62%] [G loss: 2.892578]\n",
      "epoch:30 step:23977 [D loss: 0.299385, acc: 92.97%] [G loss: 2.306508]\n",
      "epoch:30 step:23978 [D loss: 0.744611, acc: 57.03%] [G loss: 2.016846]\n",
      "epoch:30 step:23979 [D loss: 0.244769, acc: 97.66%] [G loss: 5.201726]\n",
      "epoch:30 step:23980 [D loss: 0.420296, acc: 80.47%] [G loss: 5.534776]\n",
      "epoch:30 step:23981 [D loss: 0.029229, acc: 100.00%] [G loss: 5.495270]\n",
      "epoch:30 step:23982 [D loss: 0.228138, acc: 91.41%] [G loss: 5.371505]\n",
      "epoch:30 step:23983 [D loss: 0.666942, acc: 57.81%] [G loss: 3.160136]\n",
      "epoch:30 step:23984 [D loss: 0.129365, acc: 100.00%] [G loss: 4.807853]\n",
      "epoch:30 step:23985 [D loss: 0.097007, acc: 100.00%] [G loss: 3.656114]\n",
      "epoch:30 step:23986 [D loss: 0.434377, acc: 79.69%] [G loss: 5.625911]\n",
      "epoch:30 step:23987 [D loss: 0.830279, acc: 33.59%] [G loss: 5.203822]\n",
      "epoch:30 step:23988 [D loss: 0.651443, acc: 63.28%] [G loss: 2.775254]\n",
      "epoch:30 step:23989 [D loss: 1.275432, acc: 49.22%] [G loss: 3.843677]\n",
      "epoch:30 step:23990 [D loss: 0.614219, acc: 63.28%] [G loss: 5.504906]\n",
      "epoch:30 step:23991 [D loss: 0.182923, acc: 100.00%] [G loss: 4.510864]\n",
      "epoch:30 step:23992 [D loss: 0.223969, acc: 93.75%] [G loss: 2.800102]\n",
      "epoch:30 step:23993 [D loss: 0.156961, acc: 100.00%] [G loss: 4.273373]\n",
      "epoch:30 step:23994 [D loss: 0.085475, acc: 100.00%] [G loss: 3.231583]\n",
      "epoch:30 step:23995 [D loss: 1.042202, acc: 21.88%] [G loss: 3.863854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23996 [D loss: 0.450650, acc: 83.59%] [G loss: 2.690042]\n",
      "epoch:30 step:23997 [D loss: 0.650771, acc: 57.81%] [G loss: 3.678176]\n",
      "epoch:30 step:23998 [D loss: 0.217084, acc: 96.88%] [G loss: 3.205121]\n",
      "epoch:30 step:23999 [D loss: 0.327828, acc: 90.62%] [G loss: 5.060940]\n",
      "epoch:30 step:24000 [D loss: 0.241120, acc: 95.31%] [G loss: 5.999494]\n",
      "epoch:30 step:24001 [D loss: 0.141288, acc: 100.00%] [G loss: 5.002990]\n",
      "epoch:30 step:24002 [D loss: 0.322685, acc: 88.28%] [G loss: 4.516751]\n",
      "epoch:30 step:24003 [D loss: 0.325442, acc: 91.41%] [G loss: 4.607649]\n",
      "epoch:30 step:24004 [D loss: 0.523737, acc: 75.78%] [G loss: 3.907214]\n",
      "epoch:30 step:24005 [D loss: 0.598179, acc: 64.06%] [G loss: 4.440334]\n",
      "epoch:30 step:24006 [D loss: 0.469657, acc: 74.22%] [G loss: 4.165238]\n",
      "epoch:30 step:24007 [D loss: 0.127323, acc: 100.00%] [G loss: 3.939891]\n",
      "epoch:30 step:24008 [D loss: 0.789862, acc: 48.44%] [G loss: 4.740357]\n",
      "epoch:30 step:24009 [D loss: 0.170187, acc: 99.22%] [G loss: 3.993552]\n",
      "epoch:30 step:24010 [D loss: 0.463479, acc: 85.94%] [G loss: 2.642998]\n",
      "epoch:30 step:24011 [D loss: 0.113305, acc: 98.44%] [G loss: 4.315357]\n",
      "epoch:30 step:24012 [D loss: 0.196979, acc: 96.88%] [G loss: 2.564474]\n",
      "epoch:30 step:24013 [D loss: 0.445874, acc: 88.28%] [G loss: 4.769967]\n",
      "epoch:30 step:24014 [D loss: 0.676488, acc: 62.50%] [G loss: 4.719278]\n",
      "epoch:30 step:24015 [D loss: 0.173301, acc: 99.22%] [G loss: 3.402709]\n",
      "epoch:30 step:24016 [D loss: 0.253749, acc: 93.75%] [G loss: 4.281212]\n",
      "epoch:30 step:24017 [D loss: 0.360347, acc: 78.91%] [G loss: 5.048407]\n",
      "epoch:30 step:24018 [D loss: 0.214534, acc: 99.22%] [G loss: 3.919151]\n",
      "epoch:30 step:24019 [D loss: 0.730094, acc: 53.12%] [G loss: 5.248211]\n",
      "epoch:30 step:24020 [D loss: 0.217942, acc: 98.44%] [G loss: 4.214622]\n",
      "epoch:30 step:24021 [D loss: 0.301159, acc: 95.31%] [G loss: 1.845452]\n",
      "epoch:30 step:24022 [D loss: 0.751475, acc: 52.34%] [G loss: 3.616494]\n",
      "epoch:30 step:24023 [D loss: 0.268848, acc: 88.28%] [G loss: 4.541452]\n",
      "epoch:30 step:24024 [D loss: 0.694519, acc: 60.94%] [G loss: 3.482017]\n",
      "epoch:30 step:24025 [D loss: 0.218033, acc: 99.22%] [G loss: 3.188403]\n",
      "epoch:30 step:24026 [D loss: 0.478952, acc: 80.47%] [G loss: 4.647651]\n",
      "epoch:30 step:24027 [D loss: 0.842744, acc: 51.56%] [G loss: 5.271229]\n",
      "epoch:30 step:24028 [D loss: 0.223528, acc: 94.53%] [G loss: 4.177436]\n",
      "epoch:30 step:24029 [D loss: 0.830436, acc: 46.88%] [G loss: 3.569796]\n",
      "epoch:30 step:24030 [D loss: 0.723413, acc: 53.91%] [G loss: 2.493782]\n",
      "epoch:30 step:24031 [D loss: 0.783455, acc: 53.91%] [G loss: 5.491404]\n",
      "epoch:30 step:24032 [D loss: 0.379784, acc: 85.16%] [G loss: 3.150488]\n",
      "epoch:30 step:24033 [D loss: 0.421643, acc: 72.66%] [G loss: 4.951571]\n",
      "epoch:30 step:24034 [D loss: 1.232873, acc: 50.00%] [G loss: 4.278770]\n",
      "epoch:30 step:24035 [D loss: 0.251396, acc: 97.66%] [G loss: 4.955088]\n",
      "epoch:30 step:24036 [D loss: 0.439210, acc: 89.06%] [G loss: 2.216155]\n",
      "epoch:30 step:24037 [D loss: 0.057721, acc: 100.00%] [G loss: 7.265471]\n",
      "epoch:30 step:24038 [D loss: 0.473372, acc: 81.25%] [G loss: 2.678063]\n",
      "epoch:30 step:24039 [D loss: 0.063062, acc: 100.00%] [G loss: 4.676013]\n",
      "epoch:30 step:24040 [D loss: 0.357087, acc: 80.47%] [G loss: 4.480155]\n",
      "epoch:30 step:24041 [D loss: 0.197645, acc: 98.44%] [G loss: 5.060454]\n",
      "epoch:30 step:24042 [D loss: 0.738931, acc: 54.69%] [G loss: 3.471271]\n",
      "epoch:30 step:24043 [D loss: 0.227590, acc: 96.09%] [G loss: 3.112120]\n",
      "epoch:30 step:24044 [D loss: 0.079582, acc: 100.00%] [G loss: 5.879302]\n",
      "epoch:30 step:24045 [D loss: 0.044552, acc: 100.00%] [G loss: 4.357494]\n",
      "epoch:30 step:24046 [D loss: 0.090075, acc: 100.00%] [G loss: 4.534483]\n",
      "epoch:30 step:24047 [D loss: 0.411753, acc: 89.84%] [G loss: 3.086875]\n",
      "epoch:30 step:24048 [D loss: 0.789053, acc: 53.12%] [G loss: 3.285616]\n",
      "epoch:30 step:24049 [D loss: 0.686712, acc: 55.47%] [G loss: 3.047495]\n",
      "epoch:30 step:24050 [D loss: 0.212424, acc: 99.22%] [G loss: 2.398638]\n",
      "epoch:30 step:24051 [D loss: 0.752478, acc: 50.78%] [G loss: 2.407551]\n",
      "epoch:30 step:24052 [D loss: 0.380454, acc: 87.50%] [G loss: 4.865827]\n",
      "epoch:30 step:24053 [D loss: 0.403547, acc: 75.00%] [G loss: 3.661498]\n",
      "epoch:30 step:24054 [D loss: 0.603091, acc: 57.81%] [G loss: 6.771455]\n",
      "epoch:30 step:24055 [D loss: 0.524898, acc: 66.41%] [G loss: 4.412745]\n",
      "epoch:30 step:24056 [D loss: 0.374853, acc: 78.12%] [G loss: 4.346224]\n",
      "epoch:30 step:24057 [D loss: 0.464503, acc: 65.62%] [G loss: 5.221015]\n",
      "epoch:30 step:24058 [D loss: 0.391025, acc: 88.28%] [G loss: 5.196785]\n",
      "epoch:30 step:24059 [D loss: 0.204279, acc: 99.22%] [G loss: 3.292962]\n",
      "epoch:30 step:24060 [D loss: 0.208602, acc: 97.66%] [G loss: 4.202121]\n",
      "epoch:30 step:24061 [D loss: 0.226838, acc: 96.09%] [G loss: 2.197869]\n",
      "epoch:30 step:24062 [D loss: 1.453968, acc: 16.41%] [G loss: 3.467994]\n",
      "epoch:30 step:24063 [D loss: 0.178904, acc: 100.00%] [G loss: 4.185948]\n",
      "epoch:30 step:24064 [D loss: 0.267574, acc: 92.97%] [G loss: 5.333219]\n",
      "epoch:30 step:24065 [D loss: 0.371409, acc: 84.38%] [G loss: 3.216572]\n",
      "epoch:30 step:24066 [D loss: 0.634133, acc: 64.84%] [G loss: 4.313264]\n",
      "epoch:30 step:24067 [D loss: 0.599859, acc: 66.41%] [G loss: 4.320263]\n",
      "epoch:30 step:24068 [D loss: 0.881167, acc: 42.97%] [G loss: 2.282816]\n",
      "epoch:30 step:24069 [D loss: 1.539343, acc: 46.88%] [G loss: 5.137844]\n",
      "epoch:30 step:24070 [D loss: 0.427312, acc: 74.22%] [G loss: 5.086725]\n",
      "epoch:30 step:24071 [D loss: 0.278210, acc: 93.75%] [G loss: 2.263734]\n",
      "epoch:30 step:24072 [D loss: 0.458506, acc: 85.16%] [G loss: 5.673419]\n",
      "epoch:30 step:24073 [D loss: 0.942491, acc: 52.34%] [G loss: 6.211781]\n",
      "epoch:30 step:24074 [D loss: 0.512227, acc: 68.75%] [G loss: 6.595007]\n",
      "epoch:30 step:24075 [D loss: 0.488709, acc: 76.56%] [G loss: 4.182895]\n",
      "epoch:30 step:24076 [D loss: 0.085254, acc: 100.00%] [G loss: 3.130322]\n",
      "epoch:30 step:24077 [D loss: 0.197928, acc: 95.31%] [G loss: 4.019575]\n",
      "epoch:30 step:24078 [D loss: 0.926938, acc: 52.34%] [G loss: 2.905056]\n",
      "epoch:30 step:24079 [D loss: 0.271886, acc: 98.44%] [G loss: 5.499326]\n",
      "epoch:30 step:24080 [D loss: 0.088069, acc: 100.00%] [G loss: 6.970603]\n",
      "epoch:30 step:24081 [D loss: 0.303244, acc: 94.53%] [G loss: 4.337909]\n",
      "epoch:30 step:24082 [D loss: 0.117895, acc: 100.00%] [G loss: 5.120671]\n",
      "epoch:30 step:24083 [D loss: 0.038550, acc: 100.00%] [G loss: 3.681586]\n",
      "epoch:30 step:24084 [D loss: 0.052073, acc: 100.00%] [G loss: 2.501285]\n",
      "epoch:30 step:24085 [D loss: 0.248404, acc: 99.22%] [G loss: 3.958720]\n",
      "epoch:30 step:24086 [D loss: 1.392561, acc: 10.16%] [G loss: 3.809009]\n",
      "epoch:30 step:24087 [D loss: 0.872419, acc: 52.34%] [G loss: 3.209809]\n",
      "epoch:30 step:24088 [D loss: 0.787976, acc: 50.00%] [G loss: 3.855312]\n",
      "epoch:30 step:24089 [D loss: 0.302733, acc: 88.28%] [G loss: 6.015242]\n",
      "epoch:30 step:24090 [D loss: 0.676914, acc: 55.47%] [G loss: 3.190219]\n",
      "epoch:30 step:24091 [D loss: 0.386724, acc: 89.84%] [G loss: 3.859864]\n",
      "epoch:30 step:24092 [D loss: 0.397110, acc: 89.06%] [G loss: 1.728253]\n",
      "epoch:30 step:24093 [D loss: 0.269079, acc: 95.31%] [G loss: 2.960854]\n",
      "epoch:30 step:24094 [D loss: 0.085568, acc: 100.00%] [G loss: 3.891940]\n",
      "epoch:30 step:24095 [D loss: 0.108025, acc: 100.00%] [G loss: 2.968724]\n",
      "epoch:30 step:24096 [D loss: 0.061353, acc: 100.00%] [G loss: 6.624659]\n",
      "epoch:30 step:24097 [D loss: 0.120423, acc: 100.00%] [G loss: 5.246894]\n",
      "epoch:30 step:24098 [D loss: 0.371846, acc: 84.38%] [G loss: 3.513361]\n",
      "epoch:30 step:24099 [D loss: 0.757862, acc: 51.56%] [G loss: 5.108793]\n",
      "epoch:30 step:24100 [D loss: 0.294248, acc: 92.19%] [G loss: 4.359727]\n",
      "epoch:30 step:24101 [D loss: 0.212164, acc: 96.09%] [G loss: 3.041961]\n",
      "epoch:30 step:24102 [D loss: 0.634073, acc: 59.38%] [G loss: 3.857787]\n",
      "epoch:30 step:24103 [D loss: 0.810240, acc: 53.12%] [G loss: 2.514079]\n",
      "epoch:30 step:24104 [D loss: 0.082619, acc: 100.00%] [G loss: 4.245575]\n",
      "epoch:30 step:24105 [D loss: 0.992137, acc: 35.94%] [G loss: 5.172506]\n",
      "epoch:30 step:24106 [D loss: 0.115604, acc: 98.44%] [G loss: 5.155187]\n",
      "epoch:30 step:24107 [D loss: 0.529808, acc: 76.56%] [G loss: 2.555575]\n",
      "epoch:30 step:24108 [D loss: 0.048838, acc: 100.00%] [G loss: 4.360206]\n",
      "epoch:30 step:24109 [D loss: 0.479737, acc: 74.22%] [G loss: 5.119720]\n",
      "epoch:30 step:24110 [D loss: 0.052070, acc: 99.22%] [G loss: 6.347170]\n",
      "epoch:30 step:24111 [D loss: 0.177799, acc: 98.44%] [G loss: 8.198722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24112 [D loss: 0.839063, acc: 43.75%] [G loss: 3.288508]\n",
      "epoch:30 step:24113 [D loss: 0.486052, acc: 75.00%] [G loss: 3.735539]\n",
      "epoch:30 step:24114 [D loss: 0.445789, acc: 83.59%] [G loss: 4.792292]\n",
      "epoch:30 step:24115 [D loss: 0.472619, acc: 82.81%] [G loss: 2.429170]\n",
      "epoch:30 step:24116 [D loss: 0.805669, acc: 50.00%] [G loss: 4.063957]\n",
      "epoch:30 step:24117 [D loss: 0.911973, acc: 42.19%] [G loss: 3.538768]\n",
      "epoch:30 step:24118 [D loss: 0.311126, acc: 92.97%] [G loss: 5.431901]\n",
      "epoch:30 step:24119 [D loss: 0.163240, acc: 98.44%] [G loss: 4.119828]\n",
      "epoch:30 step:24120 [D loss: 0.446616, acc: 75.78%] [G loss: 4.438007]\n",
      "epoch:30 step:24121 [D loss: 0.061405, acc: 100.00%] [G loss: 6.916577]\n",
      "epoch:30 step:24122 [D loss: 0.671252, acc: 57.81%] [G loss: 6.806872]\n",
      "epoch:30 step:24123 [D loss: 0.417056, acc: 82.03%] [G loss: 2.737956]\n",
      "epoch:30 step:24124 [D loss: 0.140014, acc: 99.22%] [G loss: 4.201968]\n",
      "epoch:30 step:24125 [D loss: 0.782137, acc: 53.12%] [G loss: 4.486847]\n",
      "epoch:30 step:24126 [D loss: 0.239774, acc: 93.75%] [G loss: 3.227739]\n",
      "epoch:30 step:24127 [D loss: 0.262049, acc: 92.97%] [G loss: 3.698617]\n",
      "epoch:30 step:24128 [D loss: 0.088629, acc: 100.00%] [G loss: 5.098200]\n",
      "epoch:30 step:24129 [D loss: 1.227587, acc: 50.00%] [G loss: 5.938412]\n",
      "epoch:30 step:24130 [D loss: 1.227056, acc: 50.00%] [G loss: 4.308412]\n",
      "epoch:30 step:24131 [D loss: 0.287791, acc: 88.28%] [G loss: 3.482414]\n",
      "epoch:30 step:24132 [D loss: 0.545106, acc: 60.16%] [G loss: 2.087856]\n",
      "epoch:30 step:24133 [D loss: 0.512194, acc: 78.91%] [G loss: 4.864805]\n",
      "epoch:30 step:24134 [D loss: 0.242498, acc: 96.88%] [G loss: 5.186168]\n",
      "epoch:30 step:24135 [D loss: 0.215842, acc: 97.66%] [G loss: 3.828874]\n",
      "epoch:30 step:24136 [D loss: 0.121010, acc: 100.00%] [G loss: 6.396896]\n",
      "epoch:30 step:24137 [D loss: 0.495982, acc: 67.97%] [G loss: 4.147026]\n",
      "epoch:30 step:24138 [D loss: 0.341860, acc: 92.97%] [G loss: 3.638904]\n",
      "epoch:30 step:24139 [D loss: 0.438749, acc: 69.53%] [G loss: 3.690050]\n",
      "epoch:30 step:24140 [D loss: 1.094959, acc: 38.28%] [G loss: 2.856708]\n",
      "epoch:30 step:24141 [D loss: 0.084641, acc: 100.00%] [G loss: 3.266675]\n",
      "epoch:30 step:24142 [D loss: 1.229700, acc: 28.12%] [G loss: 3.865417]\n",
      "epoch:30 step:24143 [D loss: 0.111006, acc: 99.22%] [G loss: 5.788924]\n",
      "epoch:30 step:24144 [D loss: 0.436101, acc: 86.72%] [G loss: 4.999955]\n",
      "epoch:30 step:24145 [D loss: 0.228044, acc: 98.44%] [G loss: 4.561340]\n",
      "epoch:30 step:24146 [D loss: 0.091526, acc: 100.00%] [G loss: 5.101403]\n",
      "epoch:30 step:24147 [D loss: 0.608897, acc: 64.06%] [G loss: 4.348232]\n",
      "epoch:30 step:24148 [D loss: 0.601513, acc: 62.50%] [G loss: 4.353216]\n",
      "epoch:30 step:24149 [D loss: 0.682586, acc: 57.81%] [G loss: 3.084425]\n",
      "epoch:30 step:24150 [D loss: 0.166612, acc: 99.22%] [G loss: 4.444694]\n",
      "epoch:30 step:24151 [D loss: 0.655561, acc: 56.25%] [G loss: 3.494188]\n",
      "epoch:30 step:24152 [D loss: 0.703061, acc: 62.50%] [G loss: 2.615891]\n",
      "epoch:30 step:24153 [D loss: 0.138009, acc: 98.44%] [G loss: 4.105865]\n",
      "epoch:30 step:24154 [D loss: 0.196213, acc: 98.44%] [G loss: 3.690666]\n",
      "epoch:30 step:24155 [D loss: 0.322169, acc: 95.31%] [G loss: 4.627263]\n",
      "epoch:30 step:24156 [D loss: 0.651473, acc: 57.81%] [G loss: 4.362427]\n",
      "epoch:30 step:24157 [D loss: 0.182143, acc: 99.22%] [G loss: 2.784696]\n",
      "epoch:30 step:24158 [D loss: 0.760743, acc: 50.78%] [G loss: 4.323780]\n",
      "epoch:30 step:24159 [D loss: 0.221693, acc: 98.44%] [G loss: 4.343760]\n",
      "epoch:30 step:24160 [D loss: 0.413086, acc: 75.00%] [G loss: 3.424822]\n",
      "epoch:30 step:24161 [D loss: 0.734973, acc: 50.78%] [G loss: 3.705870]\n",
      "epoch:30 step:24162 [D loss: 0.307145, acc: 91.41%] [G loss: 2.927452]\n",
      "epoch:30 step:24163 [D loss: 0.880873, acc: 42.19%] [G loss: 5.779398]\n",
      "epoch:30 step:24164 [D loss: 0.226839, acc: 96.88%] [G loss: 4.187298]\n",
      "epoch:30 step:24165 [D loss: 0.257530, acc: 96.88%] [G loss: 2.017395]\n",
      "epoch:30 step:24166 [D loss: 1.314066, acc: 10.16%] [G loss: 5.268043]\n",
      "epoch:30 step:24167 [D loss: 0.608320, acc: 60.94%] [G loss: 2.318583]\n",
      "epoch:30 step:24168 [D loss: 0.223023, acc: 99.22%] [G loss: 2.757458]\n",
      "epoch:30 step:24169 [D loss: 0.558837, acc: 71.09%] [G loss: 4.023355]\n",
      "epoch:30 step:24170 [D loss: 0.557491, acc: 67.97%] [G loss: 4.292501]\n",
      "epoch:30 step:24171 [D loss: 0.116171, acc: 100.00%] [G loss: 5.393044]\n",
      "epoch:30 step:24172 [D loss: 0.501121, acc: 70.31%] [G loss: 4.261675]\n",
      "epoch:30 step:24173 [D loss: 0.889643, acc: 47.66%] [G loss: 6.040051]\n",
      "epoch:30 step:24174 [D loss: 0.706652, acc: 57.81%] [G loss: 5.279885]\n",
      "epoch:30 step:24175 [D loss: 0.197853, acc: 99.22%] [G loss: 4.056912]\n",
      "epoch:30 step:24176 [D loss: 0.599828, acc: 67.97%] [G loss: 5.279158]\n",
      "epoch:30 step:24177 [D loss: 0.371305, acc: 89.84%] [G loss: 2.772382]\n",
      "epoch:30 step:24178 [D loss: 0.491662, acc: 79.69%] [G loss: 6.451544]\n",
      "epoch:30 step:24179 [D loss: 0.080990, acc: 100.00%] [G loss: 3.722713]\n",
      "epoch:30 step:24180 [D loss: 0.584282, acc: 58.59%] [G loss: 6.126513]\n",
      "epoch:30 step:24181 [D loss: 0.250000, acc: 98.44%] [G loss: 2.135843]\n",
      "epoch:30 step:24182 [D loss: 0.060336, acc: 99.22%] [G loss: 5.021521]\n",
      "epoch:30 step:24183 [D loss: 0.163660, acc: 99.22%] [G loss: 4.088526]\n",
      "epoch:30 step:24184 [D loss: 0.254117, acc: 96.88%] [G loss: 4.809458]\n",
      "epoch:30 step:24185 [D loss: 0.358419, acc: 81.25%] [G loss: 5.888083]\n",
      "epoch:30 step:24186 [D loss: 0.186110, acc: 99.22%] [G loss: 4.559480]\n",
      "epoch:30 step:24187 [D loss: 0.237256, acc: 94.53%] [G loss: 3.855556]\n",
      "epoch:30 step:24188 [D loss: 0.445767, acc: 74.22%] [G loss: 3.751145]\n",
      "epoch:30 step:24189 [D loss: 0.369185, acc: 89.06%] [G loss: 2.772196]\n",
      "epoch:30 step:24190 [D loss: 0.518551, acc: 57.81%] [G loss: 4.437661]\n",
      "epoch:30 step:24191 [D loss: 0.638831, acc: 54.69%] [G loss: 3.943499]\n",
      "epoch:30 step:24192 [D loss: 0.476278, acc: 82.81%] [G loss: 2.907019]\n",
      "epoch:30 step:24193 [D loss: 0.659681, acc: 61.72%] [G loss: 5.407714]\n",
      "epoch:30 step:24194 [D loss: 0.339036, acc: 92.19%] [G loss: 3.441708]\n",
      "epoch:30 step:24195 [D loss: 0.271544, acc: 96.09%] [G loss: 3.288430]\n",
      "epoch:30 step:24196 [D loss: 0.150412, acc: 100.00%] [G loss: 4.066231]\n",
      "epoch:30 step:24197 [D loss: 1.197861, acc: 50.00%] [G loss: 2.840615]\n",
      "epoch:30 step:24198 [D loss: 0.092257, acc: 99.22%] [G loss: 4.019030]\n",
      "epoch:30 step:24199 [D loss: 1.263747, acc: 50.00%] [G loss: 4.470300]\n",
      "epoch:30 step:24200 [D loss: 0.259505, acc: 96.09%] [G loss: 5.245354]\n",
      "epoch:30 step:24201 [D loss: 0.170951, acc: 100.00%] [G loss: 3.172623]\n",
      "epoch:30 step:24202 [D loss: 0.489308, acc: 81.25%] [G loss: 3.683394]\n",
      "epoch:30 step:24203 [D loss: 0.067770, acc: 99.22%] [G loss: 6.777749]\n",
      "epoch:30 step:24204 [D loss: 0.508731, acc: 71.09%] [G loss: 3.052425]\n",
      "epoch:30 step:24205 [D loss: 0.187311, acc: 94.53%] [G loss: 5.269684]\n",
      "epoch:30 step:24206 [D loss: 0.552470, acc: 74.22%] [G loss: 3.492929]\n",
      "epoch:30 step:24207 [D loss: 0.692947, acc: 59.38%] [G loss: 2.966588]\n",
      "epoch:30 step:24208 [D loss: 0.634420, acc: 69.53%] [G loss: 3.431140]\n",
      "epoch:30 step:24209 [D loss: 0.704888, acc: 57.03%] [G loss: 3.259328]\n",
      "epoch:30 step:24210 [D loss: 0.701100, acc: 56.25%] [G loss: 2.922802]\n",
      "epoch:30 step:24211 [D loss: 0.273805, acc: 95.31%] [G loss: 5.228656]\n",
      "epoch:31 step:24212 [D loss: 0.460018, acc: 77.34%] [G loss: 3.524247]\n",
      "epoch:31 step:24213 [D loss: 0.285065, acc: 92.97%] [G loss: 5.888709]\n",
      "epoch:31 step:24214 [D loss: 0.506102, acc: 75.00%] [G loss: 4.120000]\n",
      "epoch:31 step:24215 [D loss: 0.295323, acc: 89.06%] [G loss: 2.961359]\n",
      "epoch:31 step:24216 [D loss: 0.180081, acc: 98.44%] [G loss: 1.807953]\n",
      "epoch:31 step:24217 [D loss: 0.455889, acc: 77.34%] [G loss: 3.724256]\n",
      "epoch:31 step:24218 [D loss: 0.510280, acc: 72.66%] [G loss: 5.463371]\n",
      "epoch:31 step:24219 [D loss: 0.052708, acc: 100.00%] [G loss: 6.493362]\n",
      "epoch:31 step:24220 [D loss: 0.824414, acc: 53.12%] [G loss: 3.185822]\n",
      "epoch:31 step:24221 [D loss: 0.225589, acc: 97.66%] [G loss: 2.645452]\n",
      "epoch:31 step:24222 [D loss: 0.542222, acc: 63.28%] [G loss: 4.505452]\n",
      "epoch:31 step:24223 [D loss: 0.360436, acc: 83.59%] [G loss: 4.857137]\n",
      "epoch:31 step:24224 [D loss: 1.031139, acc: 50.00%] [G loss: 4.996354]\n",
      "epoch:31 step:24225 [D loss: 0.164631, acc: 99.22%] [G loss: 5.552948]\n",
      "epoch:31 step:24226 [D loss: 0.992772, acc: 50.78%] [G loss: 5.268311]\n",
      "epoch:31 step:24227 [D loss: 0.136094, acc: 99.22%] [G loss: 4.862083]\n",
      "epoch:31 step:24228 [D loss: 0.231204, acc: 96.88%] [G loss: 3.906548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24229 [D loss: 0.397848, acc: 77.34%] [G loss: 2.846022]\n",
      "epoch:31 step:24230 [D loss: 0.507550, acc: 76.56%] [G loss: 2.866177]\n",
      "epoch:31 step:24231 [D loss: 0.292765, acc: 93.75%] [G loss: 4.929532]\n",
      "epoch:31 step:24232 [D loss: 0.101775, acc: 100.00%] [G loss: 3.636367]\n",
      "epoch:31 step:24233 [D loss: 0.098799, acc: 100.00%] [G loss: 3.445952]\n",
      "epoch:31 step:24234 [D loss: 0.209059, acc: 95.31%] [G loss: 6.306344]\n",
      "epoch:31 step:24235 [D loss: 0.594840, acc: 67.19%] [G loss: 3.753676]\n",
      "epoch:31 step:24236 [D loss: 0.216915, acc: 98.44%] [G loss: 4.968460]\n",
      "epoch:31 step:24237 [D loss: 0.216461, acc: 99.22%] [G loss: 2.316636]\n",
      "epoch:31 step:24238 [D loss: 0.139031, acc: 98.44%] [G loss: 5.140966]\n",
      "epoch:31 step:24239 [D loss: 0.109390, acc: 99.22%] [G loss: 3.957420]\n",
      "epoch:31 step:24240 [D loss: 1.310676, acc: 13.28%] [G loss: 3.241116]\n",
      "epoch:31 step:24241 [D loss: 0.056222, acc: 100.00%] [G loss: 4.859347]\n",
      "epoch:31 step:24242 [D loss: 0.209749, acc: 97.66%] [G loss: 3.522503]\n",
      "epoch:31 step:24243 [D loss: 0.402849, acc: 87.50%] [G loss: 4.403825]\n",
      "epoch:31 step:24244 [D loss: 0.266628, acc: 96.09%] [G loss: 6.351244]\n",
      "epoch:31 step:24245 [D loss: 0.487536, acc: 68.75%] [G loss: 3.767190]\n",
      "epoch:31 step:24246 [D loss: 0.480457, acc: 77.34%] [G loss: 4.293575]\n",
      "epoch:31 step:24247 [D loss: 0.318250, acc: 93.75%] [G loss: 3.479455]\n",
      "epoch:31 step:24248 [D loss: 0.248262, acc: 95.31%] [G loss: 5.172096]\n",
      "epoch:31 step:24249 [D loss: 0.392301, acc: 84.38%] [G loss: 2.955140]\n",
      "epoch:31 step:24250 [D loss: 0.645021, acc: 64.06%] [G loss: 4.043372]\n",
      "epoch:31 step:24251 [D loss: 0.036629, acc: 100.00%] [G loss: 3.226366]\n",
      "epoch:31 step:24252 [D loss: 0.442171, acc: 64.84%] [G loss: 3.422422]\n",
      "epoch:31 step:24253 [D loss: 0.357806, acc: 92.97%] [G loss: 3.697359]\n",
      "epoch:31 step:24254 [D loss: 0.638651, acc: 57.81%] [G loss: 2.602798]\n",
      "epoch:31 step:24255 [D loss: 0.299298, acc: 92.97%] [G loss: 3.390181]\n",
      "epoch:31 step:24256 [D loss: 1.703235, acc: 3.12%] [G loss: 5.204655]\n",
      "epoch:31 step:24257 [D loss: 0.111857, acc: 100.00%] [G loss: 4.195592]\n",
      "epoch:31 step:24258 [D loss: 0.137976, acc: 99.22%] [G loss: 4.496587]\n",
      "epoch:31 step:24259 [D loss: 1.140210, acc: 15.62%] [G loss: 5.582970]\n",
      "epoch:31 step:24260 [D loss: 0.805108, acc: 54.69%] [G loss: 4.250072]\n",
      "epoch:31 step:24261 [D loss: 0.363815, acc: 85.16%] [G loss: 3.244887]\n",
      "epoch:31 step:24262 [D loss: 0.623472, acc: 60.94%] [G loss: 3.632705]\n",
      "epoch:31 step:24263 [D loss: 0.249443, acc: 92.97%] [G loss: 2.650526]\n",
      "epoch:31 step:24264 [D loss: 0.791790, acc: 54.69%] [G loss: 3.326308]\n",
      "epoch:31 step:24265 [D loss: 0.929191, acc: 35.94%] [G loss: 6.045608]\n",
      "epoch:31 step:24266 [D loss: 0.261870, acc: 92.19%] [G loss: 5.108021]\n",
      "epoch:31 step:24267 [D loss: 0.377294, acc: 78.12%] [G loss: 5.068149]\n",
      "epoch:31 step:24268 [D loss: 0.209269, acc: 95.31%] [G loss: 4.256506]\n",
      "epoch:31 step:24269 [D loss: 0.150493, acc: 99.22%] [G loss: 2.406882]\n",
      "epoch:31 step:24270 [D loss: 0.565465, acc: 59.38%] [G loss: 4.164719]\n",
      "epoch:31 step:24271 [D loss: 0.441592, acc: 74.22%] [G loss: 3.483410]\n",
      "epoch:31 step:24272 [D loss: 1.035421, acc: 24.22%] [G loss: 4.182966]\n",
      "epoch:31 step:24273 [D loss: 0.261319, acc: 92.97%] [G loss: 5.199210]\n",
      "epoch:31 step:24274 [D loss: 0.604581, acc: 63.28%] [G loss: 4.467210]\n",
      "epoch:31 step:24275 [D loss: 0.337180, acc: 93.75%] [G loss: 3.191451]\n",
      "epoch:31 step:24276 [D loss: 0.430660, acc: 82.81%] [G loss: 4.657851]\n",
      "epoch:31 step:24277 [D loss: 0.090141, acc: 100.00%] [G loss: 4.738167]\n",
      "epoch:31 step:24278 [D loss: 0.783104, acc: 50.78%] [G loss: 5.490482]\n",
      "epoch:31 step:24279 [D loss: 0.346111, acc: 80.47%] [G loss: 3.793830]\n",
      "epoch:31 step:24280 [D loss: 0.287685, acc: 96.09%] [G loss: 3.872552]\n",
      "epoch:31 step:24281 [D loss: 0.087371, acc: 100.00%] [G loss: 5.762277]\n",
      "epoch:31 step:24282 [D loss: 0.412877, acc: 85.94%] [G loss: 2.672736]\n",
      "epoch:31 step:24283 [D loss: 0.472243, acc: 69.53%] [G loss: 3.403588]\n",
      "epoch:31 step:24284 [D loss: 0.776802, acc: 52.34%] [G loss: 2.710871]\n",
      "epoch:31 step:24285 [D loss: 0.673520, acc: 59.38%] [G loss: 4.130353]\n",
      "epoch:31 step:24286 [D loss: 0.668880, acc: 60.16%] [G loss: 5.322107]\n",
      "epoch:31 step:24287 [D loss: 1.199857, acc: 50.00%] [G loss: 4.554379]\n",
      "epoch:31 step:24288 [D loss: 0.359272, acc: 92.97%] [G loss: 5.429109]\n",
      "epoch:31 step:24289 [D loss: 0.608681, acc: 56.25%] [G loss: 6.137736]\n",
      "epoch:31 step:24290 [D loss: 0.147391, acc: 98.44%] [G loss: 2.646539]\n",
      "epoch:31 step:24291 [D loss: 0.202689, acc: 98.44%] [G loss: 3.911059]\n",
      "epoch:31 step:24292 [D loss: 0.328766, acc: 88.28%] [G loss: 4.743319]\n",
      "epoch:31 step:24293 [D loss: 0.316480, acc: 94.53%] [G loss: 5.639070]\n",
      "epoch:31 step:24294 [D loss: 0.136645, acc: 100.00%] [G loss: 4.601102]\n",
      "epoch:31 step:24295 [D loss: 0.875478, acc: 52.34%] [G loss: 5.173041]\n",
      "epoch:31 step:24296 [D loss: 0.183959, acc: 97.66%] [G loss: 3.435246]\n",
      "epoch:31 step:24297 [D loss: 0.758429, acc: 51.56%] [G loss: 2.485474]\n",
      "epoch:31 step:24298 [D loss: 0.084689, acc: 100.00%] [G loss: 4.012303]\n",
      "epoch:31 step:24299 [D loss: 1.112122, acc: 18.75%] [G loss: 4.773487]\n",
      "epoch:31 step:24300 [D loss: 0.200557, acc: 96.88%] [G loss: 4.364180]\n",
      "epoch:31 step:24301 [D loss: 0.069647, acc: 100.00%] [G loss: 4.229716]\n",
      "epoch:31 step:24302 [D loss: 0.520026, acc: 69.53%] [G loss: 4.274590]\n",
      "epoch:31 step:24303 [D loss: 0.243563, acc: 99.22%] [G loss: 3.669815]\n",
      "epoch:31 step:24304 [D loss: 0.647111, acc: 58.59%] [G loss: 6.352469]\n",
      "epoch:31 step:24305 [D loss: 0.686048, acc: 59.38%] [G loss: 3.809898]\n",
      "epoch:31 step:24306 [D loss: 0.241070, acc: 97.66%] [G loss: 3.307853]\n",
      "epoch:31 step:24307 [D loss: 0.342223, acc: 76.56%] [G loss: 3.776084]\n",
      "epoch:31 step:24308 [D loss: 0.423852, acc: 88.28%] [G loss: 3.150552]\n",
      "epoch:31 step:24309 [D loss: 0.373966, acc: 92.19%] [G loss: 3.457702]\n",
      "epoch:31 step:24310 [D loss: 0.122745, acc: 100.00%] [G loss: 3.806859]\n",
      "epoch:31 step:24311 [D loss: 0.398341, acc: 89.84%] [G loss: 3.225939]\n",
      "epoch:31 step:24312 [D loss: 1.535173, acc: 10.16%] [G loss: 3.957749]\n",
      "epoch:31 step:24313 [D loss: 0.245454, acc: 96.88%] [G loss: 2.286143]\n",
      "epoch:31 step:24314 [D loss: 0.802392, acc: 44.53%] [G loss: 4.085459]\n",
      "epoch:31 step:24315 [D loss: 0.256441, acc: 95.31%] [G loss: 7.287106]\n",
      "epoch:31 step:24316 [D loss: 0.241040, acc: 97.66%] [G loss: 3.241946]\n",
      "epoch:31 step:24317 [D loss: 0.301918, acc: 96.88%] [G loss: 6.676991]\n",
      "epoch:31 step:24318 [D loss: 0.596264, acc: 64.06%] [G loss: 2.922812]\n",
      "epoch:31 step:24319 [D loss: 0.446514, acc: 79.69%] [G loss: 1.932658]\n",
      "epoch:31 step:24320 [D loss: 0.672899, acc: 67.97%] [G loss: 4.550770]\n",
      "epoch:31 step:24321 [D loss: 0.161000, acc: 100.00%] [G loss: 3.922251]\n",
      "epoch:31 step:24322 [D loss: 0.855368, acc: 35.94%] [G loss: 2.780753]\n",
      "epoch:31 step:24323 [D loss: 0.770722, acc: 45.31%] [G loss: 3.386177]\n",
      "epoch:31 step:24324 [D loss: 0.036410, acc: 100.00%] [G loss: 4.629161]\n",
      "epoch:31 step:24325 [D loss: 0.094705, acc: 100.00%] [G loss: 5.635612]\n",
      "epoch:31 step:24326 [D loss: 0.356065, acc: 87.50%] [G loss: 4.591652]\n",
      "epoch:31 step:24327 [D loss: 0.652494, acc: 60.94%] [G loss: 3.213890]\n",
      "epoch:31 step:24328 [D loss: 0.382901, acc: 85.94%] [G loss: 3.625803]\n",
      "epoch:31 step:24329 [D loss: 0.194067, acc: 96.88%] [G loss: 4.063052]\n",
      "epoch:31 step:24330 [D loss: 1.260230, acc: 21.09%] [G loss: 3.378179]\n",
      "epoch:31 step:24331 [D loss: 0.485450, acc: 65.62%] [G loss: 3.454731]\n",
      "epoch:31 step:24332 [D loss: 0.655208, acc: 55.47%] [G loss: 4.703597]\n",
      "epoch:31 step:24333 [D loss: 1.239409, acc: 50.00%] [G loss: 4.442897]\n",
      "epoch:31 step:24334 [D loss: 0.119605, acc: 99.22%] [G loss: 4.731958]\n",
      "epoch:31 step:24335 [D loss: 0.571471, acc: 57.81%] [G loss: 5.303035]\n",
      "epoch:31 step:24336 [D loss: 0.721505, acc: 57.81%] [G loss: 3.857759]\n",
      "epoch:31 step:24337 [D loss: 0.278606, acc: 95.31%] [G loss: 2.252443]\n",
      "epoch:31 step:24338 [D loss: 1.119585, acc: 50.00%] [G loss: 4.620619]\n",
      "epoch:31 step:24339 [D loss: 0.165173, acc: 95.31%] [G loss: 4.782727]\n",
      "epoch:31 step:24340 [D loss: 0.526724, acc: 66.41%] [G loss: 3.375715]\n",
      "epoch:31 step:24341 [D loss: 0.685680, acc: 58.59%] [G loss: 4.014149]\n",
      "epoch:31 step:24342 [D loss: 0.495086, acc: 71.09%] [G loss: 2.791005]\n",
      "epoch:31 step:24343 [D loss: 0.867187, acc: 50.78%] [G loss: 4.305649]\n",
      "epoch:31 step:24344 [D loss: 0.833423, acc: 42.97%] [G loss: 2.844841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24345 [D loss: 0.145470, acc: 99.22%] [G loss: 3.850696]\n",
      "epoch:31 step:24346 [D loss: 0.366881, acc: 92.19%] [G loss: 4.746078]\n",
      "epoch:31 step:24347 [D loss: 0.240521, acc: 96.09%] [G loss: 4.061241]\n",
      "epoch:31 step:24348 [D loss: 0.322669, acc: 85.94%] [G loss: 4.017015]\n",
      "epoch:31 step:24349 [D loss: 0.534816, acc: 68.75%] [G loss: 4.346472]\n",
      "epoch:31 step:24350 [D loss: 0.211220, acc: 97.66%] [G loss: 4.011693]\n",
      "epoch:31 step:24351 [D loss: 0.455569, acc: 87.50%] [G loss: 3.580282]\n",
      "epoch:31 step:24352 [D loss: 0.214233, acc: 93.75%] [G loss: 4.169834]\n",
      "epoch:31 step:24353 [D loss: 0.781644, acc: 54.69%] [G loss: 4.672253]\n",
      "epoch:31 step:24354 [D loss: 0.695525, acc: 56.25%] [G loss: 3.050386]\n",
      "epoch:31 step:24355 [D loss: 0.340358, acc: 92.19%] [G loss: 3.159894]\n",
      "epoch:31 step:24356 [D loss: 1.032157, acc: 25.00%] [G loss: 4.017449]\n",
      "epoch:31 step:24357 [D loss: 0.403484, acc: 90.62%] [G loss: 2.687590]\n",
      "epoch:31 step:24358 [D loss: 0.141226, acc: 98.44%] [G loss: 4.998913]\n",
      "epoch:31 step:24359 [D loss: 0.189908, acc: 98.44%] [G loss: 6.239228]\n",
      "epoch:31 step:24360 [D loss: 0.164516, acc: 99.22%] [G loss: 4.554385]\n",
      "epoch:31 step:24361 [D loss: 0.790939, acc: 52.34%] [G loss: 3.535863]\n",
      "epoch:31 step:24362 [D loss: 0.539323, acc: 67.97%] [G loss: 5.102406]\n",
      "epoch:31 step:24363 [D loss: 0.629348, acc: 63.28%] [G loss: 3.985417]\n",
      "epoch:31 step:24364 [D loss: 1.349332, acc: 39.84%] [G loss: 3.304964]\n",
      "epoch:31 step:24365 [D loss: 0.667297, acc: 62.50%] [G loss: 4.162457]\n",
      "epoch:31 step:24366 [D loss: 0.260325, acc: 93.75%] [G loss: 3.351466]\n",
      "epoch:31 step:24367 [D loss: 0.888418, acc: 51.56%] [G loss: 4.504742]\n",
      "epoch:31 step:24368 [D loss: 0.622285, acc: 66.41%] [G loss: 3.983450]\n",
      "epoch:31 step:24369 [D loss: 0.533565, acc: 65.62%] [G loss: 3.249037]\n",
      "epoch:31 step:24370 [D loss: 0.149566, acc: 99.22%] [G loss: 6.218118]\n",
      "epoch:31 step:24371 [D loss: 0.505049, acc: 82.03%] [G loss: 4.922937]\n",
      "epoch:31 step:24372 [D loss: 0.460113, acc: 85.16%] [G loss: 4.091825]\n",
      "epoch:31 step:24373 [D loss: 0.190850, acc: 96.09%] [G loss: 4.150229]\n",
      "epoch:31 step:24374 [D loss: 0.182034, acc: 98.44%] [G loss: 4.175691]\n",
      "epoch:31 step:24375 [D loss: 0.141858, acc: 98.44%] [G loss: 5.606517]\n",
      "epoch:31 step:24376 [D loss: 0.424035, acc: 82.81%] [G loss: 3.600562]\n",
      "epoch:31 step:24377 [D loss: 0.922145, acc: 44.53%] [G loss: 2.194355]\n",
      "epoch:31 step:24378 [D loss: 0.343563, acc: 85.94%] [G loss: 4.201345]\n",
      "epoch:31 step:24379 [D loss: 0.427706, acc: 86.72%] [G loss: 3.417397]\n",
      "epoch:31 step:24380 [D loss: 0.387338, acc: 85.94%] [G loss: 4.511197]\n",
      "epoch:31 step:24381 [D loss: 0.590974, acc: 68.75%] [G loss: 4.018507]\n",
      "epoch:31 step:24382 [D loss: 0.430317, acc: 84.38%] [G loss: 4.113852]\n",
      "epoch:31 step:24383 [D loss: 0.564878, acc: 69.53%] [G loss: 3.701989]\n",
      "epoch:31 step:24384 [D loss: 0.987729, acc: 43.75%] [G loss: 4.018486]\n",
      "epoch:31 step:24385 [D loss: 0.234597, acc: 96.88%] [G loss: 3.321107]\n",
      "epoch:31 step:24386 [D loss: 0.229995, acc: 96.88%] [G loss: 3.659584]\n",
      "epoch:31 step:24387 [D loss: 0.280755, acc: 97.66%] [G loss: 4.476679]\n",
      "epoch:31 step:24388 [D loss: 0.411385, acc: 88.28%] [G loss: 3.271337]\n",
      "epoch:31 step:24389 [D loss: 0.310722, acc: 92.97%] [G loss: 2.549445]\n",
      "epoch:31 step:24390 [D loss: 0.230225, acc: 99.22%] [G loss: 3.276423]\n",
      "epoch:31 step:24391 [D loss: 0.588536, acc: 61.72%] [G loss: 3.464910]\n",
      "epoch:31 step:24392 [D loss: 0.088379, acc: 99.22%] [G loss: 3.308775]\n",
      "epoch:31 step:24393 [D loss: 0.346566, acc: 89.06%] [G loss: 4.278472]\n",
      "epoch:31 step:24394 [D loss: 0.295785, acc: 95.31%] [G loss: 5.574250]\n",
      "epoch:31 step:24395 [D loss: 0.578598, acc: 70.31%] [G loss: 2.531546]\n",
      "epoch:31 step:24396 [D loss: 0.146910, acc: 100.00%] [G loss: 2.859987]\n",
      "epoch:31 step:24397 [D loss: 0.699100, acc: 57.03%] [G loss: 6.379184]\n",
      "epoch:31 step:24398 [D loss: 0.101424, acc: 100.00%] [G loss: 4.508751]\n",
      "epoch:31 step:24399 [D loss: 0.174874, acc: 97.66%] [G loss: 4.302991]\n",
      "epoch:31 step:24400 [D loss: 0.054468, acc: 100.00%] [G loss: 6.223695]\n",
      "epoch:31 step:24401 [D loss: 0.284547, acc: 97.66%] [G loss: 4.194140]\n",
      "epoch:31 step:24402 [D loss: 1.336232, acc: 19.53%] [G loss: 2.584415]\n",
      "epoch:31 step:24403 [D loss: 0.209904, acc: 97.66%] [G loss: 4.305432]\n",
      "epoch:31 step:24404 [D loss: 0.196717, acc: 96.09%] [G loss: 5.064775]\n",
      "epoch:31 step:24405 [D loss: 0.105731, acc: 100.00%] [G loss: 6.335159]\n",
      "epoch:31 step:24406 [D loss: 0.520534, acc: 80.47%] [G loss: 3.747122]\n",
      "epoch:31 step:24407 [D loss: 1.162024, acc: 47.66%] [G loss: 2.704237]\n",
      "epoch:31 step:24408 [D loss: 0.147872, acc: 99.22%] [G loss: 2.332118]\n",
      "epoch:31 step:24409 [D loss: 0.215832, acc: 98.44%] [G loss: 6.717663]\n",
      "epoch:31 step:24410 [D loss: 0.281248, acc: 90.62%] [G loss: 3.702781]\n",
      "epoch:31 step:24411 [D loss: 0.649103, acc: 57.81%] [G loss: 4.626662]\n",
      "epoch:31 step:24412 [D loss: 0.466828, acc: 68.75%] [G loss: 5.891652]\n",
      "epoch:31 step:24413 [D loss: 0.894423, acc: 46.88%] [G loss: 3.485793]\n",
      "epoch:31 step:24414 [D loss: 0.314588, acc: 96.09%] [G loss: 5.054330]\n",
      "epoch:31 step:24415 [D loss: 1.082290, acc: 42.97%] [G loss: 3.182960]\n",
      "epoch:31 step:24416 [D loss: 0.614929, acc: 57.81%] [G loss: 4.645377]\n",
      "epoch:31 step:24417 [D loss: 0.736762, acc: 54.69%] [G loss: 4.365039]\n",
      "epoch:31 step:24418 [D loss: 0.772039, acc: 51.56%] [G loss: 3.492220]\n",
      "epoch:31 step:24419 [D loss: 0.704281, acc: 53.12%] [G loss: 6.400930]\n",
      "epoch:31 step:24420 [D loss: 0.114710, acc: 100.00%] [G loss: 4.132578]\n",
      "epoch:31 step:24421 [D loss: 0.385839, acc: 88.28%] [G loss: 3.241302]\n",
      "epoch:31 step:24422 [D loss: 0.231992, acc: 92.19%] [G loss: 3.242282]\n",
      "epoch:31 step:24423 [D loss: 0.298723, acc: 91.41%] [G loss: 4.326699]\n",
      "epoch:31 step:24424 [D loss: 0.843246, acc: 39.06%] [G loss: 4.593814]\n",
      "epoch:31 step:24425 [D loss: 0.263571, acc: 95.31%] [G loss: 3.211521]\n",
      "epoch:31 step:24426 [D loss: 0.291054, acc: 96.09%] [G loss: 2.569636]\n",
      "epoch:31 step:24427 [D loss: 0.391459, acc: 77.34%] [G loss: 1.988727]\n",
      "epoch:31 step:24428 [D loss: 0.511417, acc: 80.47%] [G loss: 5.889964]\n",
      "epoch:31 step:24429 [D loss: 0.569740, acc: 71.09%] [G loss: 4.963671]\n",
      "epoch:31 step:24430 [D loss: 0.150615, acc: 100.00%] [G loss: 2.332451]\n",
      "epoch:31 step:24431 [D loss: 0.238362, acc: 97.66%] [G loss: 3.916044]\n",
      "epoch:31 step:24432 [D loss: 0.361797, acc: 88.28%] [G loss: 4.388422]\n",
      "epoch:31 step:24433 [D loss: 0.364803, acc: 83.59%] [G loss: 3.368732]\n",
      "epoch:31 step:24434 [D loss: 0.484513, acc: 75.00%] [G loss: 1.552201]\n",
      "epoch:31 step:24435 [D loss: 0.296476, acc: 87.50%] [G loss: 4.964045]\n",
      "epoch:31 step:24436 [D loss: 0.086169, acc: 100.00%] [G loss: 4.987896]\n",
      "epoch:31 step:24437 [D loss: 0.118794, acc: 99.22%] [G loss: 4.252348]\n",
      "epoch:31 step:24438 [D loss: 0.201486, acc: 97.66%] [G loss: 4.451038]\n",
      "epoch:31 step:24439 [D loss: 0.243522, acc: 96.09%] [G loss: 4.076701]\n",
      "epoch:31 step:24440 [D loss: 0.276246, acc: 95.31%] [G loss: 3.369719]\n",
      "epoch:31 step:24441 [D loss: 0.514685, acc: 63.28%] [G loss: 1.723371]\n",
      "epoch:31 step:24442 [D loss: 1.039877, acc: 34.38%] [G loss: 4.911729]\n",
      "epoch:31 step:24443 [D loss: 0.237028, acc: 97.66%] [G loss: 1.878268]\n",
      "epoch:31 step:24444 [D loss: 0.357648, acc: 86.72%] [G loss: 2.871609]\n",
      "epoch:31 step:24445 [D loss: 0.505854, acc: 77.34%] [G loss: 4.584049]\n",
      "epoch:31 step:24446 [D loss: 0.384123, acc: 93.75%] [G loss: 4.070603]\n",
      "epoch:31 step:24447 [D loss: 1.095355, acc: 20.31%] [G loss: 4.178084]\n",
      "epoch:31 step:24448 [D loss: 0.192825, acc: 96.88%] [G loss: 5.820833]\n",
      "epoch:31 step:24449 [D loss: 0.359582, acc: 92.97%] [G loss: 2.601598]\n",
      "epoch:31 step:24450 [D loss: 0.807432, acc: 48.44%] [G loss: 2.136773]\n",
      "epoch:31 step:24451 [D loss: 0.505508, acc: 72.66%] [G loss: 3.669732]\n",
      "epoch:31 step:24452 [D loss: 0.176201, acc: 100.00%] [G loss: 4.059993]\n",
      "epoch:31 step:24453 [D loss: 0.279778, acc: 92.19%] [G loss: 5.050196]\n",
      "epoch:31 step:24454 [D loss: 0.282345, acc: 95.31%] [G loss: 3.985973]\n",
      "epoch:31 step:24455 [D loss: 0.421016, acc: 78.91%] [G loss: 2.765504]\n",
      "epoch:31 step:24456 [D loss: 0.458160, acc: 81.25%] [G loss: 3.699818]\n",
      "epoch:31 step:24457 [D loss: 0.462691, acc: 81.25%] [G loss: 5.191454]\n",
      "epoch:31 step:24458 [D loss: 0.950336, acc: 25.78%] [G loss: 3.296446]\n",
      "epoch:31 step:24459 [D loss: 0.226046, acc: 96.09%] [G loss: 3.632113]\n",
      "epoch:31 step:24460 [D loss: 0.079714, acc: 100.00%] [G loss: 4.246892]\n",
      "epoch:31 step:24461 [D loss: 0.359108, acc: 90.62%] [G loss: 3.117860]\n",
      "epoch:31 step:24462 [D loss: 0.692663, acc: 53.91%] [G loss: 6.292948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24463 [D loss: 0.777446, acc: 53.12%] [G loss: 4.029999]\n",
      "epoch:31 step:24464 [D loss: 0.848944, acc: 49.22%] [G loss: 2.378419]\n",
      "epoch:31 step:24465 [D loss: 0.468345, acc: 74.22%] [G loss: 3.485627]\n",
      "epoch:31 step:24466 [D loss: 0.248039, acc: 96.88%] [G loss: 3.534107]\n",
      "epoch:31 step:24467 [D loss: 0.480359, acc: 85.94%] [G loss: 4.454197]\n",
      "epoch:31 step:24468 [D loss: 1.554116, acc: 42.97%] [G loss: 4.261461]\n",
      "epoch:31 step:24469 [D loss: 0.082184, acc: 100.00%] [G loss: 3.858007]\n",
      "epoch:31 step:24470 [D loss: 0.353404, acc: 79.69%] [G loss: 2.848800]\n",
      "epoch:31 step:24471 [D loss: 0.347250, acc: 90.62%] [G loss: 3.098860]\n",
      "epoch:31 step:24472 [D loss: 0.505022, acc: 77.34%] [G loss: 3.821844]\n",
      "epoch:31 step:24473 [D loss: 0.034155, acc: 100.00%] [G loss: 6.352606]\n",
      "epoch:31 step:24474 [D loss: 0.691525, acc: 55.47%] [G loss: 3.753527]\n",
      "epoch:31 step:24475 [D loss: 1.267254, acc: 50.78%] [G loss: 3.837790]\n",
      "epoch:31 step:24476 [D loss: 0.351213, acc: 92.97%] [G loss: 4.089451]\n",
      "epoch:31 step:24477 [D loss: 0.088984, acc: 100.00%] [G loss: 3.717764]\n",
      "epoch:31 step:24478 [D loss: 0.400700, acc: 76.56%] [G loss: 3.411132]\n",
      "epoch:31 step:24479 [D loss: 0.603916, acc: 67.19%] [G loss: 2.190256]\n",
      "epoch:31 step:24480 [D loss: 0.377174, acc: 77.34%] [G loss: 5.257136]\n",
      "epoch:31 step:24481 [D loss: 0.238125, acc: 97.66%] [G loss: 3.133836]\n",
      "epoch:31 step:24482 [D loss: 0.508893, acc: 68.75%] [G loss: 2.684832]\n",
      "epoch:31 step:24483 [D loss: 0.162140, acc: 100.00%] [G loss: 2.911581]\n",
      "epoch:31 step:24484 [D loss: 0.804857, acc: 46.09%] [G loss: 4.907220]\n",
      "epoch:31 step:24485 [D loss: 0.384795, acc: 78.12%] [G loss: 3.329449]\n",
      "epoch:31 step:24486 [D loss: 0.869505, acc: 47.66%] [G loss: 4.038811]\n",
      "epoch:31 step:24487 [D loss: 0.189475, acc: 98.44%] [G loss: 4.176395]\n",
      "epoch:31 step:24488 [D loss: 0.704295, acc: 54.69%] [G loss: 5.530741]\n",
      "epoch:31 step:24489 [D loss: 0.202044, acc: 96.88%] [G loss: 3.984388]\n",
      "epoch:31 step:24490 [D loss: 0.821078, acc: 52.34%] [G loss: 5.600138]\n",
      "epoch:31 step:24491 [D loss: 0.548437, acc: 68.75%] [G loss: 3.373485]\n",
      "epoch:31 step:24492 [D loss: 0.872176, acc: 37.50%] [G loss: 3.999713]\n",
      "epoch:31 step:24493 [D loss: 0.267419, acc: 98.44%] [G loss: 3.137549]\n",
      "epoch:31 step:24494 [D loss: 0.477006, acc: 81.25%] [G loss: 2.781678]\n",
      "epoch:31 step:24495 [D loss: 0.575791, acc: 57.03%] [G loss: 3.766503]\n",
      "epoch:31 step:24496 [D loss: 0.378385, acc: 80.47%] [G loss: 4.836739]\n",
      "epoch:31 step:24497 [D loss: 0.952107, acc: 31.25%] [G loss: 4.380089]\n",
      "epoch:31 step:24498 [D loss: 1.708683, acc: 35.16%] [G loss: 3.721977]\n",
      "epoch:31 step:24499 [D loss: 0.440024, acc: 68.75%] [G loss: 3.751087]\n",
      "epoch:31 step:24500 [D loss: 0.529383, acc: 78.12%] [G loss: 3.530156]\n",
      "epoch:31 step:24501 [D loss: 0.572030, acc: 73.44%] [G loss: 3.692290]\n",
      "epoch:31 step:24502 [D loss: 0.301788, acc: 95.31%] [G loss: 2.524240]\n",
      "epoch:31 step:24503 [D loss: 0.369798, acc: 75.78%] [G loss: 4.160535]\n",
      "epoch:31 step:24504 [D loss: 0.290984, acc: 94.53%] [G loss: 2.467396]\n",
      "epoch:31 step:24505 [D loss: 0.267224, acc: 96.88%] [G loss: 3.414670]\n",
      "epoch:31 step:24506 [D loss: 0.824153, acc: 46.09%] [G loss: 5.245463]\n",
      "epoch:31 step:24507 [D loss: 0.154408, acc: 99.22%] [G loss: 4.042946]\n",
      "epoch:31 step:24508 [D loss: 0.549212, acc: 67.97%] [G loss: 2.849511]\n",
      "epoch:31 step:24509 [D loss: 0.330242, acc: 96.88%] [G loss: 4.518227]\n",
      "epoch:31 step:24510 [D loss: 0.319034, acc: 95.31%] [G loss: 3.104793]\n",
      "epoch:31 step:24511 [D loss: 0.293277, acc: 93.75%] [G loss: 3.893298]\n",
      "epoch:31 step:24512 [D loss: 0.771279, acc: 51.56%] [G loss: 4.236451]\n",
      "epoch:31 step:24513 [D loss: 0.272700, acc: 95.31%] [G loss: 4.149108]\n",
      "epoch:31 step:24514 [D loss: 1.055189, acc: 44.53%] [G loss: 3.787091]\n",
      "epoch:31 step:24515 [D loss: 0.344308, acc: 95.31%] [G loss: 3.919878]\n",
      "epoch:31 step:24516 [D loss: 0.326266, acc: 83.59%] [G loss: 4.797723]\n",
      "epoch:31 step:24517 [D loss: 0.186359, acc: 98.44%] [G loss: 3.240001]\n",
      "epoch:31 step:24518 [D loss: 0.473582, acc: 64.84%] [G loss: 5.074915]\n",
      "epoch:31 step:24519 [D loss: 0.219335, acc: 93.75%] [G loss: 4.032782]\n",
      "epoch:31 step:24520 [D loss: 0.366598, acc: 80.47%] [G loss: 3.308717]\n",
      "epoch:31 step:24521 [D loss: 0.357948, acc: 96.09%] [G loss: 4.149557]\n",
      "epoch:31 step:24522 [D loss: 0.663598, acc: 54.69%] [G loss: 3.477851]\n",
      "epoch:31 step:24523 [D loss: 0.536594, acc: 65.62%] [G loss: 1.714147]\n",
      "epoch:31 step:24524 [D loss: 0.193228, acc: 99.22%] [G loss: 6.647132]\n",
      "epoch:31 step:24525 [D loss: 0.138755, acc: 100.00%] [G loss: 5.473655]\n",
      "epoch:31 step:24526 [D loss: 0.740261, acc: 48.44%] [G loss: 2.693142]\n",
      "epoch:31 step:24527 [D loss: 0.535000, acc: 76.56%] [G loss: 4.518742]\n",
      "epoch:31 step:24528 [D loss: 0.228067, acc: 98.44%] [G loss: 3.340362]\n",
      "epoch:31 step:24529 [D loss: 0.112396, acc: 100.00%] [G loss: 4.589037]\n",
      "epoch:31 step:24530 [D loss: 0.265370, acc: 96.09%] [G loss: 5.635904]\n",
      "epoch:31 step:24531 [D loss: 0.531887, acc: 77.34%] [G loss: 2.936742]\n",
      "epoch:31 step:24532 [D loss: 1.005096, acc: 45.31%] [G loss: 2.579388]\n",
      "epoch:31 step:24533 [D loss: 0.209542, acc: 100.00%] [G loss: 3.725165]\n",
      "epoch:31 step:24534 [D loss: 0.135512, acc: 98.44%] [G loss: 4.873843]\n",
      "epoch:31 step:24535 [D loss: 0.734894, acc: 54.69%] [G loss: 4.292756]\n",
      "epoch:31 step:24536 [D loss: 0.863298, acc: 42.19%] [G loss: 2.504652]\n",
      "epoch:31 step:24537 [D loss: 0.583074, acc: 60.16%] [G loss: 4.067429]\n",
      "epoch:31 step:24538 [D loss: 0.544819, acc: 75.00%] [G loss: 4.236831]\n",
      "epoch:31 step:24539 [D loss: 0.374653, acc: 89.84%] [G loss: 3.048160]\n",
      "epoch:31 step:24540 [D loss: 0.057841, acc: 100.00%] [G loss: 4.633844]\n",
      "epoch:31 step:24541 [D loss: 0.652546, acc: 58.59%] [G loss: 4.540835]\n",
      "epoch:31 step:24542 [D loss: 0.267209, acc: 95.31%] [G loss: 2.125397]\n",
      "epoch:31 step:24543 [D loss: 0.297393, acc: 93.75%] [G loss: 3.862989]\n",
      "epoch:31 step:24544 [D loss: 0.104068, acc: 100.00%] [G loss: 7.461461]\n",
      "epoch:31 step:24545 [D loss: 0.267599, acc: 90.62%] [G loss: 3.359588]\n",
      "epoch:31 step:24546 [D loss: 0.115904, acc: 99.22%] [G loss: 4.955195]\n",
      "epoch:31 step:24547 [D loss: 0.569264, acc: 71.88%] [G loss: 3.322570]\n",
      "epoch:31 step:24548 [D loss: 0.256333, acc: 97.66%] [G loss: 3.816669]\n",
      "epoch:31 step:24549 [D loss: 0.819202, acc: 50.00%] [G loss: 3.658176]\n",
      "epoch:31 step:24550 [D loss: 0.184322, acc: 96.88%] [G loss: 4.888715]\n",
      "epoch:31 step:24551 [D loss: 0.759746, acc: 52.34%] [G loss: 3.871109]\n",
      "epoch:31 step:24552 [D loss: 0.142775, acc: 98.44%] [G loss: 2.022581]\n",
      "epoch:31 step:24553 [D loss: 0.376302, acc: 92.97%] [G loss: 4.943163]\n",
      "epoch:31 step:24554 [D loss: 0.192697, acc: 99.22%] [G loss: 3.012496]\n",
      "epoch:31 step:24555 [D loss: 0.083634, acc: 100.00%] [G loss: 3.775282]\n",
      "epoch:31 step:24556 [D loss: 0.217236, acc: 96.88%] [G loss: 5.039944]\n",
      "epoch:31 step:24557 [D loss: 0.495345, acc: 85.16%] [G loss: 2.891264]\n",
      "epoch:31 step:24558 [D loss: 0.339137, acc: 93.75%] [G loss: 3.987207]\n",
      "epoch:31 step:24559 [D loss: 0.830427, acc: 54.69%] [G loss: 4.849004]\n",
      "epoch:31 step:24560 [D loss: 0.455105, acc: 76.56%] [G loss: 5.172821]\n",
      "epoch:31 step:24561 [D loss: 0.355973, acc: 88.28%] [G loss: 3.210720]\n",
      "epoch:31 step:24562 [D loss: 0.271902, acc: 88.28%] [G loss: 4.157478]\n",
      "epoch:31 step:24563 [D loss: 0.102176, acc: 100.00%] [G loss: 4.222128]\n",
      "epoch:31 step:24564 [D loss: 0.441637, acc: 87.50%] [G loss: 5.290060]\n",
      "epoch:31 step:24565 [D loss: 1.351466, acc: 47.66%] [G loss: 3.072775]\n",
      "epoch:31 step:24566 [D loss: 1.034316, acc: 39.84%] [G loss: 2.859163]\n",
      "epoch:31 step:24567 [D loss: 0.279767, acc: 94.53%] [G loss: 3.052829]\n",
      "epoch:31 step:24568 [D loss: 0.446470, acc: 70.31%] [G loss: 4.022304]\n",
      "epoch:31 step:24569 [D loss: 0.722831, acc: 54.69%] [G loss: 4.133665]\n",
      "epoch:31 step:24570 [D loss: 0.378561, acc: 85.16%] [G loss: 4.425858]\n",
      "epoch:31 step:24571 [D loss: 0.401448, acc: 75.00%] [G loss: 5.516171]\n",
      "epoch:31 step:24572 [D loss: 0.385939, acc: 78.91%] [G loss: 3.348171]\n",
      "epoch:31 step:24573 [D loss: 0.618298, acc: 57.03%] [G loss: 3.640197]\n",
      "epoch:31 step:24574 [D loss: 0.313797, acc: 86.72%] [G loss: 3.247294]\n",
      "epoch:31 step:24575 [D loss: 0.713023, acc: 60.94%] [G loss: 3.829196]\n",
      "epoch:31 step:24576 [D loss: 0.727796, acc: 53.91%] [G loss: 3.861165]\n",
      "epoch:31 step:24577 [D loss: 0.642847, acc: 63.28%] [G loss: 3.667669]\n",
      "epoch:31 step:24578 [D loss: 0.522364, acc: 76.56%] [G loss: 3.821949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24579 [D loss: 0.185220, acc: 99.22%] [G loss: 4.374470]\n",
      "epoch:31 step:24580 [D loss: 0.451884, acc: 81.25%] [G loss: 3.616835]\n",
      "epoch:31 step:24581 [D loss: 0.598560, acc: 59.38%] [G loss: 3.811163]\n",
      "epoch:31 step:24582 [D loss: 0.777360, acc: 45.31%] [G loss: 2.308531]\n",
      "epoch:31 step:24583 [D loss: 0.214927, acc: 97.66%] [G loss: 3.966179]\n",
      "epoch:31 step:24584 [D loss: 0.785653, acc: 50.78%] [G loss: 5.423867]\n",
      "epoch:31 step:24585 [D loss: 0.670076, acc: 51.56%] [G loss: 3.725057]\n",
      "epoch:31 step:24586 [D loss: 0.562598, acc: 67.97%] [G loss: 3.752403]\n",
      "epoch:31 step:24587 [D loss: 0.824018, acc: 42.19%] [G loss: 4.295673]\n",
      "epoch:31 step:24588 [D loss: 0.449216, acc: 85.94%] [G loss: 3.249385]\n",
      "epoch:31 step:24589 [D loss: 0.594152, acc: 65.62%] [G loss: 2.816887]\n",
      "epoch:31 step:24590 [D loss: 0.394002, acc: 90.62%] [G loss: 3.121946]\n",
      "epoch:31 step:24591 [D loss: 0.232599, acc: 92.97%] [G loss: 3.869331]\n",
      "epoch:31 step:24592 [D loss: 0.269625, acc: 96.88%] [G loss: 3.522169]\n",
      "epoch:31 step:24593 [D loss: 0.437316, acc: 75.00%] [G loss: 3.195125]\n",
      "epoch:31 step:24594 [D loss: 0.272479, acc: 91.41%] [G loss: 4.326964]\n",
      "epoch:31 step:24595 [D loss: 0.522606, acc: 66.41%] [G loss: 2.212517]\n",
      "epoch:31 step:24596 [D loss: 0.536618, acc: 64.84%] [G loss: 3.765703]\n",
      "epoch:31 step:24597 [D loss: 0.859602, acc: 50.78%] [G loss: 4.185301]\n",
      "epoch:31 step:24598 [D loss: 0.236620, acc: 96.09%] [G loss: 4.291483]\n",
      "epoch:31 step:24599 [D loss: 0.863304, acc: 46.88%] [G loss: 3.019956]\n",
      "epoch:31 step:24600 [D loss: 0.348964, acc: 75.78%] [G loss: 4.731526]\n",
      "epoch:31 step:24601 [D loss: 0.801588, acc: 50.78%] [G loss: 2.498946]\n",
      "epoch:31 step:24602 [D loss: 0.249521, acc: 92.19%] [G loss: 6.145647]\n",
      "epoch:31 step:24603 [D loss: 0.366374, acc: 76.56%] [G loss: 3.833527]\n",
      "epoch:31 step:24604 [D loss: 0.245456, acc: 97.66%] [G loss: 3.088491]\n",
      "epoch:31 step:24605 [D loss: 0.238908, acc: 93.75%] [G loss: 4.403163]\n",
      "epoch:31 step:24606 [D loss: 0.320462, acc: 94.53%] [G loss: 3.396030]\n",
      "epoch:31 step:24607 [D loss: 0.473168, acc: 69.53%] [G loss: 3.568179]\n",
      "epoch:31 step:24608 [D loss: 0.739143, acc: 50.00%] [G loss: 3.485580]\n",
      "epoch:31 step:24609 [D loss: 0.523212, acc: 65.62%] [G loss: 4.083197]\n",
      "epoch:31 step:24610 [D loss: 0.272416, acc: 96.09%] [G loss: 3.683407]\n",
      "epoch:31 step:24611 [D loss: 0.158652, acc: 97.66%] [G loss: 6.985980]\n",
      "epoch:31 step:24612 [D loss: 0.528363, acc: 75.78%] [G loss: 4.896130]\n",
      "epoch:31 step:24613 [D loss: 0.142606, acc: 100.00%] [G loss: 4.077416]\n",
      "epoch:31 step:24614 [D loss: 0.377623, acc: 78.12%] [G loss: 3.448756]\n",
      "epoch:31 step:24615 [D loss: 0.382895, acc: 82.81%] [G loss: 2.833393]\n",
      "epoch:31 step:24616 [D loss: 0.498817, acc: 75.78%] [G loss: 3.275008]\n",
      "epoch:31 step:24617 [D loss: 0.727990, acc: 56.25%] [G loss: 3.743289]\n",
      "epoch:31 step:24618 [D loss: 0.330247, acc: 94.53%] [G loss: 4.390468]\n",
      "epoch:31 step:24619 [D loss: 0.593670, acc: 67.97%] [G loss: 3.454127]\n",
      "epoch:31 step:24620 [D loss: 0.231654, acc: 93.75%] [G loss: 6.813823]\n",
      "epoch:31 step:24621 [D loss: 0.461385, acc: 75.00%] [G loss: 3.622317]\n",
      "epoch:31 step:24622 [D loss: 1.066609, acc: 50.00%] [G loss: 2.826486]\n",
      "epoch:31 step:24623 [D loss: 0.208601, acc: 97.66%] [G loss: 4.456119]\n",
      "epoch:31 step:24624 [D loss: 0.132772, acc: 100.00%] [G loss: 4.128654]\n",
      "epoch:31 step:24625 [D loss: 0.398739, acc: 71.88%] [G loss: 7.043418]\n",
      "epoch:31 step:24626 [D loss: 0.287546, acc: 88.28%] [G loss: 1.596726]\n",
      "epoch:31 step:24627 [D loss: 0.737027, acc: 49.22%] [G loss: 1.910688]\n",
      "epoch:31 step:24628 [D loss: 0.174672, acc: 99.22%] [G loss: 4.044085]\n",
      "epoch:31 step:24629 [D loss: 0.314029, acc: 88.28%] [G loss: 3.463143]\n",
      "epoch:31 step:24630 [D loss: 0.325242, acc: 85.94%] [G loss: 5.328452]\n",
      "epoch:31 step:24631 [D loss: 0.196760, acc: 99.22%] [G loss: 4.849155]\n",
      "epoch:31 step:24632 [D loss: 0.567728, acc: 62.50%] [G loss: 4.033135]\n",
      "epoch:31 step:24633 [D loss: 0.060383, acc: 100.00%] [G loss: 4.983055]\n",
      "epoch:31 step:24634 [D loss: 0.926800, acc: 47.66%] [G loss: 5.002169]\n",
      "epoch:31 step:24635 [D loss: 0.756383, acc: 50.00%] [G loss: 2.511981]\n",
      "epoch:31 step:24636 [D loss: 1.288449, acc: 50.00%] [G loss: 3.707446]\n",
      "epoch:31 step:24637 [D loss: 0.336427, acc: 92.19%] [G loss: 2.909587]\n",
      "epoch:31 step:24638 [D loss: 0.580425, acc: 57.81%] [G loss: 2.413591]\n",
      "epoch:31 step:24639 [D loss: 1.586540, acc: 3.91%] [G loss: 6.768756]\n",
      "epoch:31 step:24640 [D loss: 0.099379, acc: 99.22%] [G loss: 7.703283]\n",
      "epoch:31 step:24641 [D loss: 0.411491, acc: 79.69%] [G loss: 4.044484]\n",
      "epoch:31 step:24642 [D loss: 0.524640, acc: 77.34%] [G loss: 3.865290]\n",
      "epoch:31 step:24643 [D loss: 0.263305, acc: 96.88%] [G loss: 4.426688]\n",
      "epoch:31 step:24644 [D loss: 0.272468, acc: 99.22%] [G loss: 5.198673]\n",
      "epoch:31 step:24645 [D loss: 0.116139, acc: 99.22%] [G loss: 4.665611]\n",
      "epoch:31 step:24646 [D loss: 0.469834, acc: 84.38%] [G loss: 1.903612]\n",
      "epoch:31 step:24647 [D loss: 0.514731, acc: 66.41%] [G loss: 3.793962]\n",
      "epoch:31 step:24648 [D loss: 0.379018, acc: 85.94%] [G loss: 2.859519]\n",
      "epoch:31 step:24649 [D loss: 0.500533, acc: 64.84%] [G loss: 5.239601]\n",
      "epoch:31 step:24650 [D loss: 0.504970, acc: 68.75%] [G loss: 3.845875]\n",
      "epoch:31 step:24651 [D loss: 0.426362, acc: 79.69%] [G loss: 4.664801]\n",
      "epoch:31 step:24652 [D loss: 0.502377, acc: 68.75%] [G loss: 4.608221]\n",
      "epoch:31 step:24653 [D loss: 0.508474, acc: 60.16%] [G loss: 2.501674]\n",
      "epoch:31 step:24654 [D loss: 1.178224, acc: 50.00%] [G loss: 2.820340]\n",
      "epoch:31 step:24655 [D loss: 0.087733, acc: 100.00%] [G loss: 4.039438]\n",
      "epoch:31 step:24656 [D loss: 0.290782, acc: 92.97%] [G loss: 2.694315]\n",
      "epoch:31 step:24657 [D loss: 0.176458, acc: 98.44%] [G loss: 4.340875]\n",
      "epoch:31 step:24658 [D loss: 0.563995, acc: 68.75%] [G loss: 6.041653]\n",
      "epoch:31 step:24659 [D loss: 0.178798, acc: 100.00%] [G loss: 5.494486]\n",
      "epoch:31 step:24660 [D loss: 0.617560, acc: 57.81%] [G loss: 3.956143]\n",
      "epoch:31 step:24661 [D loss: 0.165901, acc: 99.22%] [G loss: 3.896225]\n",
      "epoch:31 step:24662 [D loss: 0.246170, acc: 97.66%] [G loss: 2.668814]\n",
      "epoch:31 step:24663 [D loss: 1.061790, acc: 50.78%] [G loss: 3.285119]\n",
      "epoch:31 step:24664 [D loss: 0.041741, acc: 100.00%] [G loss: 5.236702]\n",
      "epoch:31 step:24665 [D loss: 1.074691, acc: 50.78%] [G loss: 2.771002]\n",
      "epoch:31 step:24666 [D loss: 0.431088, acc: 88.28%] [G loss: 3.112432]\n",
      "epoch:31 step:24667 [D loss: 0.461732, acc: 74.22%] [G loss: 4.490259]\n",
      "epoch:31 step:24668 [D loss: 0.590378, acc: 68.75%] [G loss: 4.174644]\n",
      "epoch:31 step:24669 [D loss: 0.452666, acc: 85.16%] [G loss: 3.536209]\n",
      "epoch:31 step:24670 [D loss: 0.305307, acc: 84.38%] [G loss: 2.255647]\n",
      "epoch:31 step:24671 [D loss: 0.309311, acc: 92.97%] [G loss: 3.737405]\n",
      "epoch:31 step:24672 [D loss: 0.226183, acc: 96.09%] [G loss: 4.454341]\n",
      "epoch:31 step:24673 [D loss: 0.399867, acc: 75.00%] [G loss: 2.647075]\n",
      "epoch:31 step:24674 [D loss: 0.267728, acc: 98.44%] [G loss: 4.847027]\n",
      "epoch:31 step:24675 [D loss: 0.118881, acc: 99.22%] [G loss: 3.197488]\n",
      "epoch:31 step:24676 [D loss: 1.030612, acc: 27.34%] [G loss: 3.842391]\n",
      "epoch:31 step:24677 [D loss: 0.327551, acc: 88.28%] [G loss: 4.202099]\n",
      "epoch:31 step:24678 [D loss: 0.799093, acc: 53.91%] [G loss: 3.301586]\n",
      "epoch:31 step:24679 [D loss: 0.434671, acc: 86.72%] [G loss: 1.724133]\n",
      "epoch:31 step:24680 [D loss: 0.298648, acc: 92.19%] [G loss: 1.776769]\n",
      "epoch:31 step:24681 [D loss: 0.084297, acc: 100.00%] [G loss: 3.926913]\n",
      "epoch:31 step:24682 [D loss: 0.518487, acc: 65.62%] [G loss: 3.491114]\n",
      "epoch:31 step:24683 [D loss: 0.419514, acc: 74.22%] [G loss: 2.192467]\n",
      "epoch:31 step:24684 [D loss: 0.474681, acc: 80.47%] [G loss: 3.176086]\n",
      "epoch:31 step:24685 [D loss: 0.221754, acc: 97.66%] [G loss: 2.480530]\n",
      "epoch:31 step:24686 [D loss: 0.135528, acc: 100.00%] [G loss: 4.534942]\n",
      "epoch:31 step:24687 [D loss: 0.304176, acc: 86.72%] [G loss: 4.566851]\n",
      "epoch:31 step:24688 [D loss: 0.767281, acc: 51.56%] [G loss: 3.024739]\n",
      "epoch:31 step:24689 [D loss: 0.017300, acc: 100.00%] [G loss: 6.210690]\n",
      "epoch:31 step:24690 [D loss: 0.332841, acc: 84.38%] [G loss: 2.502186]\n",
      "epoch:31 step:24691 [D loss: 0.201420, acc: 100.00%] [G loss: 4.940665]\n",
      "epoch:31 step:24692 [D loss: 0.590204, acc: 73.44%] [G loss: 2.095317]\n",
      "epoch:31 step:24693 [D loss: 0.297761, acc: 92.97%] [G loss: 2.344160]\n",
      "epoch:31 step:24694 [D loss: 0.243592, acc: 91.41%] [G loss: 2.939815]\n",
      "epoch:31 step:24695 [D loss: 0.517999, acc: 64.06%] [G loss: 4.208264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24696 [D loss: 0.320015, acc: 92.97%] [G loss: 3.283648]\n",
      "epoch:31 step:24697 [D loss: 0.729526, acc: 53.91%] [G loss: 4.621654]\n",
      "epoch:31 step:24698 [D loss: 0.495659, acc: 82.03%] [G loss: 4.707772]\n",
      "epoch:31 step:24699 [D loss: 0.114135, acc: 100.00%] [G loss: 3.637700]\n",
      "epoch:31 step:24700 [D loss: 0.821328, acc: 51.56%] [G loss: 4.289610]\n",
      "epoch:31 step:24701 [D loss: 0.124728, acc: 100.00%] [G loss: 5.898246]\n",
      "epoch:31 step:24702 [D loss: 0.623280, acc: 60.94%] [G loss: 1.658627]\n",
      "epoch:31 step:24703 [D loss: 0.182517, acc: 98.44%] [G loss: 4.920985]\n",
      "epoch:31 step:24704 [D loss: 0.125951, acc: 100.00%] [G loss: 4.442452]\n",
      "epoch:31 step:24705 [D loss: 0.052651, acc: 100.00%] [G loss: 3.353374]\n",
      "epoch:31 step:24706 [D loss: 0.336761, acc: 87.50%] [G loss: 2.171614]\n",
      "epoch:31 step:24707 [D loss: 0.323005, acc: 90.62%] [G loss: 5.013917]\n",
      "epoch:31 step:24708 [D loss: 0.069569, acc: 100.00%] [G loss: 3.495386]\n",
      "epoch:31 step:24709 [D loss: 0.311316, acc: 98.44%] [G loss: 4.843606]\n",
      "epoch:31 step:24710 [D loss: 0.373822, acc: 86.72%] [G loss: 4.897769]\n",
      "epoch:31 step:24711 [D loss: 0.116406, acc: 100.00%] [G loss: 3.540373]\n",
      "epoch:31 step:24712 [D loss: 1.025078, acc: 48.44%] [G loss: 4.574856]\n",
      "epoch:31 step:24713 [D loss: 0.675735, acc: 53.91%] [G loss: 5.743447]\n",
      "epoch:31 step:24714 [D loss: 0.972857, acc: 35.94%] [G loss: 5.804881]\n",
      "epoch:31 step:24715 [D loss: 0.557309, acc: 71.09%] [G loss: 2.981953]\n",
      "epoch:31 step:24716 [D loss: 0.270292, acc: 89.84%] [G loss: 3.438561]\n",
      "epoch:31 step:24717 [D loss: 0.432987, acc: 84.38%] [G loss: 5.056899]\n",
      "epoch:31 step:24718 [D loss: 1.985855, acc: 15.62%] [G loss: 4.157513]\n",
      "epoch:31 step:24719 [D loss: 0.657521, acc: 62.50%] [G loss: 5.407583]\n",
      "epoch:31 step:24720 [D loss: 0.339101, acc: 83.59%] [G loss: 5.027936]\n",
      "epoch:31 step:24721 [D loss: 0.108739, acc: 99.22%] [G loss: 4.768188]\n",
      "epoch:31 step:24722 [D loss: 0.128533, acc: 100.00%] [G loss: 6.695563]\n",
      "epoch:31 step:24723 [D loss: 1.557080, acc: 46.88%] [G loss: 3.430239]\n",
      "epoch:31 step:24724 [D loss: 0.700782, acc: 53.12%] [G loss: 4.821725]\n",
      "epoch:31 step:24725 [D loss: 0.199947, acc: 96.88%] [G loss: 4.516872]\n",
      "epoch:31 step:24726 [D loss: 0.562505, acc: 74.22%] [G loss: 4.174806]\n",
      "epoch:31 step:24727 [D loss: 0.516864, acc: 60.94%] [G loss: 5.689360]\n",
      "epoch:31 step:24728 [D loss: 0.683175, acc: 53.91%] [G loss: 5.456012]\n",
      "epoch:31 step:24729 [D loss: 0.465460, acc: 80.47%] [G loss: 3.178411]\n",
      "epoch:31 step:24730 [D loss: 0.137056, acc: 99.22%] [G loss: 3.302108]\n",
      "epoch:31 step:24731 [D loss: 0.115620, acc: 98.44%] [G loss: 4.856588]\n",
      "epoch:31 step:24732 [D loss: 0.905007, acc: 34.38%] [G loss: 4.900114]\n",
      "epoch:31 step:24733 [D loss: 1.151965, acc: 28.12%] [G loss: 4.104212]\n",
      "epoch:31 step:24734 [D loss: 0.257652, acc: 91.41%] [G loss: 4.279426]\n",
      "epoch:31 step:24735 [D loss: 0.746007, acc: 53.12%] [G loss: 2.901283]\n",
      "epoch:31 step:24736 [D loss: 0.470083, acc: 80.47%] [G loss: 3.157583]\n",
      "epoch:31 step:24737 [D loss: 0.942707, acc: 50.00%] [G loss: 2.908190]\n",
      "epoch:31 step:24738 [D loss: 0.403001, acc: 72.66%] [G loss: 5.047514]\n",
      "epoch:31 step:24739 [D loss: 0.088260, acc: 100.00%] [G loss: 3.393754]\n",
      "epoch:31 step:24740 [D loss: 0.583417, acc: 70.31%] [G loss: 4.322270]\n",
      "epoch:31 step:24741 [D loss: 0.042208, acc: 100.00%] [G loss: 2.710870]\n",
      "epoch:31 step:24742 [D loss: 0.286799, acc: 97.66%] [G loss: 3.893142]\n",
      "epoch:31 step:24743 [D loss: 0.489144, acc: 71.09%] [G loss: 2.349978]\n",
      "epoch:31 step:24744 [D loss: 0.925445, acc: 50.78%] [G loss: 3.412610]\n",
      "epoch:31 step:24745 [D loss: 0.446157, acc: 78.91%] [G loss: 2.952539]\n",
      "epoch:31 step:24746 [D loss: 0.168032, acc: 97.66%] [G loss: 5.035760]\n",
      "epoch:31 step:24747 [D loss: 0.114020, acc: 100.00%] [G loss: 2.215627]\n",
      "epoch:31 step:24748 [D loss: 0.219326, acc: 99.22%] [G loss: 5.038941]\n",
      "epoch:31 step:24749 [D loss: 0.208166, acc: 99.22%] [G loss: 4.049185]\n",
      "epoch:31 step:24750 [D loss: 0.969820, acc: 29.69%] [G loss: 4.099995]\n",
      "epoch:31 step:24751 [D loss: 0.708932, acc: 53.91%] [G loss: 4.720775]\n",
      "epoch:31 step:24752 [D loss: 0.623671, acc: 61.72%] [G loss: 4.583220]\n",
      "epoch:31 step:24753 [D loss: 0.379564, acc: 75.78%] [G loss: 3.918797]\n",
      "epoch:31 step:24754 [D loss: 0.500112, acc: 61.72%] [G loss: 4.604604]\n",
      "epoch:31 step:24755 [D loss: 1.455925, acc: 14.06%] [G loss: 4.287913]\n",
      "epoch:31 step:24756 [D loss: 0.288542, acc: 89.84%] [G loss: 5.111524]\n",
      "epoch:31 step:24757 [D loss: 0.647273, acc: 64.84%] [G loss: 3.240175]\n",
      "epoch:31 step:24758 [D loss: 0.568488, acc: 70.31%] [G loss: 3.477116]\n",
      "epoch:31 step:24759 [D loss: 0.755203, acc: 52.34%] [G loss: 4.085230]\n",
      "epoch:31 step:24760 [D loss: 1.109938, acc: 23.44%] [G loss: 4.929226]\n",
      "epoch:31 step:24761 [D loss: 0.288322, acc: 91.41%] [G loss: 4.585835]\n",
      "epoch:31 step:24762 [D loss: 0.294089, acc: 90.62%] [G loss: 3.203629]\n",
      "epoch:31 step:24763 [D loss: 0.101737, acc: 99.22%] [G loss: 4.303738]\n",
      "epoch:31 step:24764 [D loss: 0.238672, acc: 93.75%] [G loss: 4.972795]\n",
      "epoch:31 step:24765 [D loss: 0.217172, acc: 98.44%] [G loss: 2.810362]\n",
      "epoch:31 step:24766 [D loss: 0.107413, acc: 100.00%] [G loss: 4.160244]\n",
      "epoch:31 step:24767 [D loss: 0.566847, acc: 66.41%] [G loss: 4.672936]\n",
      "epoch:31 step:24768 [D loss: 0.208988, acc: 97.66%] [G loss: 4.233376]\n",
      "epoch:31 step:24769 [D loss: 1.149680, acc: 49.22%] [G loss: 3.990955]\n",
      "epoch:31 step:24770 [D loss: 0.619544, acc: 66.41%] [G loss: 3.064147]\n",
      "epoch:31 step:24771 [D loss: 0.367375, acc: 80.47%] [G loss: 3.656162]\n",
      "epoch:31 step:24772 [D loss: 0.417181, acc: 90.62%] [G loss: 3.632997]\n",
      "epoch:31 step:24773 [D loss: 0.694367, acc: 55.47%] [G loss: 4.737355]\n",
      "epoch:31 step:24774 [D loss: 0.568615, acc: 58.59%] [G loss: 4.475311]\n",
      "epoch:31 step:24775 [D loss: 0.267324, acc: 92.97%] [G loss: 5.272880]\n",
      "epoch:31 step:24776 [D loss: 0.249778, acc: 96.88%] [G loss: 4.981059]\n",
      "epoch:31 step:24777 [D loss: 0.731975, acc: 53.91%] [G loss: 3.025093]\n",
      "epoch:31 step:24778 [D loss: 0.534963, acc: 71.09%] [G loss: 2.462014]\n",
      "epoch:31 step:24779 [D loss: 0.253482, acc: 95.31%] [G loss: 5.565156]\n",
      "epoch:31 step:24780 [D loss: 0.400656, acc: 77.34%] [G loss: 4.915582]\n",
      "epoch:31 step:24781 [D loss: 0.340256, acc: 89.06%] [G loss: 2.897030]\n",
      "epoch:31 step:24782 [D loss: 0.649059, acc: 63.28%] [G loss: 4.497859]\n",
      "epoch:31 step:24783 [D loss: 0.296999, acc: 94.53%] [G loss: 2.421976]\n",
      "epoch:31 step:24784 [D loss: 0.441754, acc: 78.12%] [G loss: 2.143241]\n",
      "epoch:31 step:24785 [D loss: 0.592255, acc: 64.06%] [G loss: 3.262473]\n",
      "epoch:31 step:24786 [D loss: 0.654031, acc: 55.47%] [G loss: 3.131676]\n",
      "epoch:31 step:24787 [D loss: 1.334764, acc: 48.44%] [G loss: 2.934207]\n",
      "epoch:31 step:24788 [D loss: 0.256610, acc: 90.62%] [G loss: 2.838887]\n",
      "epoch:31 step:24789 [D loss: 0.276016, acc: 96.09%] [G loss: 3.314589]\n",
      "epoch:31 step:24790 [D loss: 0.172338, acc: 99.22%] [G loss: 4.227082]\n",
      "epoch:31 step:24791 [D loss: 0.530914, acc: 67.97%] [G loss: 3.719403]\n",
      "epoch:31 step:24792 [D loss: 0.081348, acc: 99.22%] [G loss: 7.087596]\n",
      "epoch:31 step:24793 [D loss: 0.268123, acc: 99.22%] [G loss: 4.591107]\n",
      "epoch:31 step:24794 [D loss: 0.229227, acc: 96.09%] [G loss: 3.997444]\n",
      "epoch:31 step:24795 [D loss: 0.360160, acc: 84.38%] [G loss: 3.076377]\n",
      "epoch:31 step:24796 [D loss: 0.143134, acc: 99.22%] [G loss: 5.731470]\n",
      "epoch:31 step:24797 [D loss: 0.548792, acc: 71.88%] [G loss: 5.399571]\n",
      "epoch:31 step:24798 [D loss: 0.323131, acc: 85.94%] [G loss: 4.985607]\n",
      "epoch:31 step:24799 [D loss: 0.678375, acc: 57.03%] [G loss: 3.322000]\n",
      "epoch:31 step:24800 [D loss: 0.981183, acc: 35.94%] [G loss: 4.924567]\n",
      "epoch:31 step:24801 [D loss: 0.988884, acc: 48.44%] [G loss: 1.741518]\n",
      "epoch:31 step:24802 [D loss: 0.253263, acc: 97.66%] [G loss: 3.697286]\n",
      "epoch:31 step:24803 [D loss: 0.503267, acc: 65.62%] [G loss: 3.804320]\n",
      "epoch:31 step:24804 [D loss: 0.267604, acc: 93.75%] [G loss: 3.702213]\n",
      "epoch:31 step:24805 [D loss: 0.916564, acc: 32.81%] [G loss: 2.642622]\n",
      "epoch:31 step:24806 [D loss: 0.257501, acc: 96.88%] [G loss: 2.794246]\n",
      "epoch:31 step:24807 [D loss: 0.409447, acc: 80.47%] [G loss: 2.652927]\n",
      "epoch:31 step:24808 [D loss: 0.214359, acc: 98.44%] [G loss: 1.948537]\n",
      "epoch:31 step:24809 [D loss: 0.336066, acc: 95.31%] [G loss: 7.075170]\n",
      "epoch:31 step:24810 [D loss: 0.963915, acc: 51.56%] [G loss: 3.278273]\n",
      "epoch:31 step:24811 [D loss: 0.565888, acc: 64.84%] [G loss: 2.674301]\n",
      "epoch:31 step:24812 [D loss: 0.168281, acc: 98.44%] [G loss: 3.125108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24813 [D loss: 0.466014, acc: 81.25%] [G loss: 4.220889]\n",
      "epoch:31 step:24814 [D loss: 0.663324, acc: 60.94%] [G loss: 3.008138]\n",
      "epoch:31 step:24815 [D loss: 1.072057, acc: 50.78%] [G loss: 2.893795]\n",
      "epoch:31 step:24816 [D loss: 0.159153, acc: 98.44%] [G loss: 2.645372]\n",
      "epoch:31 step:24817 [D loss: 0.113248, acc: 100.00%] [G loss: 2.330349]\n",
      "epoch:31 step:24818 [D loss: 0.640185, acc: 58.59%] [G loss: 4.226252]\n",
      "epoch:31 step:24819 [D loss: 0.600619, acc: 71.09%] [G loss: 4.483918]\n",
      "epoch:31 step:24820 [D loss: 0.256673, acc: 96.09%] [G loss: 2.030819]\n",
      "epoch:31 step:24821 [D loss: 0.109369, acc: 99.22%] [G loss: 3.536211]\n",
      "epoch:31 step:24822 [D loss: 0.362436, acc: 84.38%] [G loss: 4.097555]\n",
      "epoch:31 step:24823 [D loss: 0.278686, acc: 98.44%] [G loss: 3.724185]\n",
      "epoch:31 step:24824 [D loss: 0.080796, acc: 100.00%] [G loss: 4.288458]\n",
      "epoch:31 step:24825 [D loss: 0.181447, acc: 96.88%] [G loss: 4.531547]\n",
      "epoch:31 step:24826 [D loss: 0.181983, acc: 97.66%] [G loss: 4.230970]\n",
      "epoch:31 step:24827 [D loss: 0.229143, acc: 95.31%] [G loss: 1.980246]\n",
      "epoch:31 step:24828 [D loss: 0.317125, acc: 94.53%] [G loss: 2.699661]\n",
      "epoch:31 step:24829 [D loss: 0.658956, acc: 58.59%] [G loss: 3.141933]\n",
      "epoch:31 step:24830 [D loss: 0.340946, acc: 87.50%] [G loss: 1.710884]\n",
      "epoch:31 step:24831 [D loss: 0.655561, acc: 57.03%] [G loss: 4.283089]\n",
      "epoch:31 step:24832 [D loss: 0.286147, acc: 94.53%] [G loss: 2.817733]\n",
      "epoch:31 step:24833 [D loss: 0.539502, acc: 76.56%] [G loss: 2.760227]\n",
      "epoch:31 step:24834 [D loss: 0.545192, acc: 60.94%] [G loss: 4.051363]\n",
      "epoch:31 step:24835 [D loss: 0.420826, acc: 71.88%] [G loss: 6.025119]\n",
      "epoch:31 step:24836 [D loss: 0.094356, acc: 100.00%] [G loss: 6.504707]\n",
      "epoch:31 step:24837 [D loss: 0.203981, acc: 95.31%] [G loss: 5.276493]\n",
      "epoch:31 step:24838 [D loss: 0.646085, acc: 65.62%] [G loss: 6.363807]\n",
      "epoch:31 step:24839 [D loss: 0.434910, acc: 83.59%] [G loss: 3.071669]\n",
      "epoch:31 step:24840 [D loss: 0.294027, acc: 92.19%] [G loss: 3.308138]\n",
      "epoch:31 step:24841 [D loss: 0.640676, acc: 57.81%] [G loss: 5.026644]\n",
      "epoch:31 step:24842 [D loss: 0.932224, acc: 51.56%] [G loss: 4.886838]\n",
      "epoch:31 step:24843 [D loss: 0.537432, acc: 65.62%] [G loss: 3.435386]\n",
      "epoch:31 step:24844 [D loss: 0.942834, acc: 35.94%] [G loss: 3.283785]\n",
      "epoch:31 step:24845 [D loss: 0.430379, acc: 82.03%] [G loss: 2.671944]\n",
      "epoch:31 step:24846 [D loss: 0.475687, acc: 78.12%] [G loss: 3.219810]\n",
      "epoch:31 step:24847 [D loss: 0.433237, acc: 88.28%] [G loss: 4.244069]\n",
      "epoch:31 step:24848 [D loss: 0.195717, acc: 100.00%] [G loss: 3.311458]\n",
      "epoch:31 step:24849 [D loss: 0.129765, acc: 97.66%] [G loss: 4.635091]\n",
      "epoch:31 step:24850 [D loss: 1.247975, acc: 15.62%] [G loss: 5.621750]\n",
      "epoch:31 step:24851 [D loss: 0.722205, acc: 52.34%] [G loss: 4.254121]\n",
      "epoch:31 step:24852 [D loss: 0.047036, acc: 100.00%] [G loss: 4.634344]\n",
      "epoch:31 step:24853 [D loss: 0.063368, acc: 100.00%] [G loss: 2.834108]\n",
      "epoch:31 step:24854 [D loss: 0.845933, acc: 52.34%] [G loss: 3.657626]\n",
      "epoch:31 step:24855 [D loss: 0.176349, acc: 100.00%] [G loss: 4.676792]\n",
      "epoch:31 step:24856 [D loss: 1.616667, acc: 48.44%] [G loss: 3.971944]\n",
      "epoch:31 step:24857 [D loss: 0.362096, acc: 89.06%] [G loss: 2.989203]\n",
      "epoch:31 step:24858 [D loss: 0.147425, acc: 97.66%] [G loss: 3.418748]\n",
      "epoch:31 step:24859 [D loss: 0.485339, acc: 67.97%] [G loss: 3.610415]\n",
      "epoch:31 step:24860 [D loss: 0.204586, acc: 99.22%] [G loss: 2.818802]\n",
      "epoch:31 step:24861 [D loss: 0.450397, acc: 86.72%] [G loss: 3.321989]\n",
      "epoch:31 step:24862 [D loss: 0.202388, acc: 99.22%] [G loss: 2.307063]\n",
      "epoch:31 step:24863 [D loss: 0.509029, acc: 75.78%] [G loss: 3.234262]\n",
      "epoch:31 step:24864 [D loss: 0.123380, acc: 100.00%] [G loss: 4.848639]\n",
      "epoch:31 step:24865 [D loss: 0.194537, acc: 96.09%] [G loss: 3.988954]\n",
      "epoch:31 step:24866 [D loss: 0.067751, acc: 100.00%] [G loss: 5.006557]\n",
      "epoch:31 step:24867 [D loss: 0.176206, acc: 100.00%] [G loss: 3.475145]\n",
      "epoch:31 step:24868 [D loss: 0.611576, acc: 69.53%] [G loss: 3.639850]\n",
      "epoch:31 step:24869 [D loss: 0.734558, acc: 54.69%] [G loss: 3.493389]\n",
      "epoch:31 step:24870 [D loss: 0.103951, acc: 100.00%] [G loss: 5.540992]\n",
      "epoch:31 step:24871 [D loss: 0.135376, acc: 100.00%] [G loss: 2.623002]\n",
      "epoch:31 step:24872 [D loss: 0.380942, acc: 79.69%] [G loss: 5.081721]\n",
      "epoch:31 step:24873 [D loss: 0.269911, acc: 94.53%] [G loss: 3.615468]\n",
      "epoch:31 step:24874 [D loss: 0.275031, acc: 90.62%] [G loss: 2.606730]\n",
      "epoch:31 step:24875 [D loss: 0.508233, acc: 64.84%] [G loss: 2.452694]\n",
      "epoch:31 step:24876 [D loss: 0.887829, acc: 37.50%] [G loss: 4.625515]\n",
      "epoch:31 step:24877 [D loss: 0.199319, acc: 99.22%] [G loss: 4.092742]\n",
      "epoch:31 step:24878 [D loss: 0.103226, acc: 99.22%] [G loss: 4.201365]\n",
      "epoch:31 step:24879 [D loss: 0.334058, acc: 77.34%] [G loss: 5.648351]\n",
      "epoch:31 step:24880 [D loss: 0.770117, acc: 53.91%] [G loss: 2.756517]\n",
      "epoch:31 step:24881 [D loss: 0.503227, acc: 71.88%] [G loss: 4.309215]\n",
      "epoch:31 step:24882 [D loss: 0.370952, acc: 85.16%] [G loss: 5.306382]\n",
      "epoch:31 step:24883 [D loss: 1.460938, acc: 25.78%] [G loss: 4.152154]\n",
      "epoch:31 step:24884 [D loss: 1.087538, acc: 50.78%] [G loss: 3.198909]\n",
      "epoch:31 step:24885 [D loss: 0.131351, acc: 98.44%] [G loss: 7.092870]\n",
      "epoch:31 step:24886 [D loss: 0.057481, acc: 100.00%] [G loss: 3.178292]\n",
      "epoch:31 step:24887 [D loss: 0.199050, acc: 97.66%] [G loss: 4.829983]\n",
      "epoch:31 step:24888 [D loss: 0.449378, acc: 82.03%] [G loss: 4.252255]\n",
      "epoch:31 step:24889 [D loss: 0.223634, acc: 92.19%] [G loss: 4.449501]\n",
      "epoch:31 step:24890 [D loss: 0.395645, acc: 89.06%] [G loss: 3.192882]\n",
      "epoch:31 step:24891 [D loss: 0.326516, acc: 89.06%] [G loss: 4.764191]\n",
      "epoch:31 step:24892 [D loss: 0.099447, acc: 100.00%] [G loss: 4.555362]\n",
      "epoch:31 step:24893 [D loss: 0.296800, acc: 85.16%] [G loss: 3.169420]\n",
      "epoch:31 step:24894 [D loss: 0.560564, acc: 71.09%] [G loss: 4.177939]\n",
      "epoch:31 step:24895 [D loss: 0.433984, acc: 81.25%] [G loss: 3.738851]\n",
      "epoch:31 step:24896 [D loss: 0.829627, acc: 50.78%] [G loss: 4.713949]\n",
      "epoch:31 step:24897 [D loss: 1.112564, acc: 17.97%] [G loss: 3.783051]\n",
      "epoch:31 step:24898 [D loss: 0.121985, acc: 99.22%] [G loss: 1.595989]\n",
      "epoch:31 step:24899 [D loss: 0.395758, acc: 82.03%] [G loss: 3.966890]\n",
      "epoch:31 step:24900 [D loss: 0.420905, acc: 87.50%] [G loss: 4.036291]\n",
      "epoch:31 step:24901 [D loss: 0.294084, acc: 98.44%] [G loss: 3.838085]\n",
      "epoch:31 step:24902 [D loss: 0.241250, acc: 92.19%] [G loss: 4.439188]\n",
      "epoch:31 step:24903 [D loss: 0.356881, acc: 87.50%] [G loss: 6.256593]\n",
      "epoch:31 step:24904 [D loss: 0.707628, acc: 57.81%] [G loss: 3.476880]\n",
      "epoch:31 step:24905 [D loss: 0.307159, acc: 91.41%] [G loss: 3.184288]\n",
      "epoch:31 step:24906 [D loss: 0.196542, acc: 100.00%] [G loss: 4.121805]\n",
      "epoch:31 step:24907 [D loss: 1.131058, acc: 47.66%] [G loss: 3.568928]\n",
      "epoch:31 step:24908 [D loss: 0.454533, acc: 72.66%] [G loss: 3.016854]\n",
      "epoch:31 step:24909 [D loss: 0.188741, acc: 96.88%] [G loss: 2.569586]\n",
      "epoch:31 step:24910 [D loss: 0.202128, acc: 98.44%] [G loss: 2.545165]\n",
      "epoch:31 step:24911 [D loss: 0.237275, acc: 96.09%] [G loss: 4.970740]\n",
      "epoch:31 step:24912 [D loss: 0.911239, acc: 32.81%] [G loss: 3.513026]\n",
      "epoch:31 step:24913 [D loss: 0.114854, acc: 99.22%] [G loss: 3.802284]\n",
      "epoch:31 step:24914 [D loss: 0.256851, acc: 93.75%] [G loss: 3.909717]\n",
      "epoch:31 step:24915 [D loss: 0.078062, acc: 100.00%] [G loss: 6.377261]\n",
      "epoch:31 step:24916 [D loss: 0.250758, acc: 91.41%] [G loss: 5.346416]\n",
      "epoch:31 step:24917 [D loss: 0.353286, acc: 91.41%] [G loss: 4.368097]\n",
      "epoch:31 step:24918 [D loss: 0.609671, acc: 70.31%] [G loss: 5.866480]\n",
      "epoch:31 step:24919 [D loss: 0.215875, acc: 98.44%] [G loss: 4.685632]\n",
      "epoch:31 step:24920 [D loss: 0.426334, acc: 83.59%] [G loss: 3.939140]\n",
      "epoch:31 step:24921 [D loss: 0.440992, acc: 75.00%] [G loss: 4.897257]\n",
      "epoch:31 step:24922 [D loss: 0.047825, acc: 100.00%] [G loss: 5.609917]\n",
      "epoch:31 step:24923 [D loss: 0.896041, acc: 35.16%] [G loss: 3.196205]\n",
      "epoch:31 step:24924 [D loss: 0.423697, acc: 89.06%] [G loss: 4.404955]\n",
      "epoch:31 step:24925 [D loss: 0.394089, acc: 89.06%] [G loss: 3.700800]\n",
      "epoch:31 step:24926 [D loss: 0.495486, acc: 70.31%] [G loss: 1.249002]\n",
      "epoch:31 step:24927 [D loss: 0.035129, acc: 100.00%] [G loss: 6.769684]\n",
      "epoch:31 step:24928 [D loss: 0.438162, acc: 80.47%] [G loss: 3.617426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24929 [D loss: 0.344429, acc: 95.31%] [G loss: 5.180822]\n",
      "epoch:31 step:24930 [D loss: 0.539341, acc: 63.28%] [G loss: 5.745720]\n",
      "epoch:31 step:24931 [D loss: 0.316653, acc: 92.19%] [G loss: 6.203600]\n",
      "epoch:31 step:24932 [D loss: 0.510399, acc: 57.03%] [G loss: 5.351793]\n",
      "epoch:31 step:24933 [D loss: 0.159536, acc: 100.00%] [G loss: 2.846121]\n",
      "epoch:31 step:24934 [D loss: 0.546286, acc: 75.78%] [G loss: 4.230874]\n",
      "epoch:31 step:24935 [D loss: 0.305188, acc: 96.88%] [G loss: 2.123354]\n",
      "epoch:31 step:24936 [D loss: 0.578524, acc: 67.97%] [G loss: 5.367354]\n",
      "epoch:31 step:24937 [D loss: 0.048748, acc: 100.00%] [G loss: 4.575195]\n",
      "epoch:31 step:24938 [D loss: 0.377364, acc: 84.38%] [G loss: 4.730840]\n",
      "epoch:31 step:24939 [D loss: 0.289997, acc: 94.53%] [G loss: 5.271770]\n",
      "epoch:31 step:24940 [D loss: 0.629230, acc: 57.03%] [G loss: 4.581638]\n",
      "epoch:31 step:24941 [D loss: 0.754432, acc: 51.56%] [G loss: 2.374897]\n",
      "epoch:31 step:24942 [D loss: 0.237936, acc: 100.00%] [G loss: 3.884011]\n",
      "epoch:31 step:24943 [D loss: 0.374236, acc: 79.69%] [G loss: 5.990401]\n",
      "epoch:31 step:24944 [D loss: 0.472576, acc: 77.34%] [G loss: 3.206416]\n",
      "epoch:31 step:24945 [D loss: 0.533506, acc: 62.50%] [G loss: 2.995688]\n",
      "epoch:31 step:24946 [D loss: 0.070954, acc: 100.00%] [G loss: 3.297239]\n",
      "epoch:31 step:24947 [D loss: 0.823465, acc: 43.75%] [G loss: 6.961986]\n",
      "epoch:31 step:24948 [D loss: 1.235458, acc: 42.19%] [G loss: 5.228136]\n",
      "epoch:31 step:24949 [D loss: 0.325373, acc: 91.41%] [G loss: 4.556767]\n",
      "epoch:31 step:24950 [D loss: 1.062282, acc: 28.12%] [G loss: 3.174208]\n",
      "epoch:31 step:24951 [D loss: 0.607683, acc: 57.81%] [G loss: 5.761865]\n",
      "epoch:31 step:24952 [D loss: 0.399751, acc: 74.22%] [G loss: 3.678165]\n",
      "epoch:31 step:24953 [D loss: 0.528835, acc: 67.19%] [G loss: 5.261300]\n",
      "epoch:31 step:24954 [D loss: 1.105253, acc: 23.44%] [G loss: 4.530905]\n",
      "epoch:31 step:24955 [D loss: 1.093049, acc: 18.75%] [G loss: 1.634066]\n",
      "epoch:31 step:24956 [D loss: 0.609762, acc: 54.69%] [G loss: 6.053796]\n",
      "epoch:31 step:24957 [D loss: 0.326374, acc: 85.16%] [G loss: 2.503690]\n",
      "epoch:31 step:24958 [D loss: 0.240305, acc: 92.19%] [G loss: 8.947420]\n",
      "epoch:31 step:24959 [D loss: 0.119775, acc: 100.00%] [G loss: 5.273730]\n",
      "epoch:31 step:24960 [D loss: 0.388438, acc: 75.78%] [G loss: 5.690748]\n",
      "epoch:31 step:24961 [D loss: 0.253164, acc: 97.66%] [G loss: 4.653722]\n",
      "epoch:31 step:24962 [D loss: 0.543931, acc: 74.22%] [G loss: 3.820510]\n",
      "epoch:31 step:24963 [D loss: 0.159590, acc: 99.22%] [G loss: 2.708843]\n",
      "epoch:31 step:24964 [D loss: 0.395140, acc: 82.81%] [G loss: 3.995123]\n",
      "epoch:31 step:24965 [D loss: 0.554614, acc: 71.88%] [G loss: 3.217894]\n",
      "epoch:31 step:24966 [D loss: 0.560094, acc: 66.41%] [G loss: 4.279271]\n",
      "epoch:31 step:24967 [D loss: 0.388014, acc: 81.25%] [G loss: 4.317645]\n",
      "epoch:31 step:24968 [D loss: 0.038604, acc: 100.00%] [G loss: 4.788763]\n",
      "epoch:31 step:24969 [D loss: 0.453479, acc: 78.12%] [G loss: 2.362913]\n",
      "epoch:31 step:24970 [D loss: 0.826570, acc: 42.97%] [G loss: 3.414902]\n",
      "epoch:31 step:24971 [D loss: 0.097153, acc: 100.00%] [G loss: 6.923938]\n",
      "epoch:31 step:24972 [D loss: 0.397352, acc: 75.00%] [G loss: 3.952239]\n",
      "epoch:31 step:24973 [D loss: 0.398548, acc: 87.50%] [G loss: 4.269561]\n",
      "epoch:31 step:24974 [D loss: 0.307855, acc: 94.53%] [G loss: 2.692759]\n",
      "epoch:31 step:24975 [D loss: 0.047933, acc: 100.00%] [G loss: 3.398303]\n",
      "epoch:31 step:24976 [D loss: 1.378469, acc: 43.75%] [G loss: 3.298338]\n",
      "epoch:31 step:24977 [D loss: 0.838528, acc: 42.97%] [G loss: 0.753424]\n",
      "epoch:31 step:24978 [D loss: 0.106040, acc: 99.22%] [G loss: 5.463840]\n",
      "epoch:31 step:24979 [D loss: 0.165999, acc: 99.22%] [G loss: 6.260730]\n",
      "epoch:31 step:24980 [D loss: 0.510181, acc: 75.78%] [G loss: 4.447598]\n",
      "epoch:31 step:24981 [D loss: 0.084270, acc: 100.00%] [G loss: 3.749014]\n",
      "epoch:31 step:24982 [D loss: 0.668057, acc: 59.38%] [G loss: 3.646580]\n",
      "epoch:31 step:24983 [D loss: 0.754592, acc: 53.91%] [G loss: 4.186821]\n",
      "epoch:31 step:24984 [D loss: 0.132806, acc: 99.22%] [G loss: 5.731082]\n",
      "epoch:31 step:24985 [D loss: 1.493372, acc: 48.44%] [G loss: 5.102198]\n",
      "epoch:31 step:24986 [D loss: 0.239217, acc: 95.31%] [G loss: 3.499861]\n",
      "epoch:31 step:24987 [D loss: 0.667664, acc: 58.59%] [G loss: 2.839197]\n",
      "epoch:31 step:24988 [D loss: 0.663676, acc: 61.72%] [G loss: 3.155187]\n",
      "epoch:31 step:24989 [D loss: 0.179535, acc: 100.00%] [G loss: 1.272778]\n",
      "epoch:31 step:24990 [D loss: 0.045578, acc: 100.00%] [G loss: 4.925646]\n",
      "epoch:31 step:24991 [D loss: 0.538914, acc: 70.31%] [G loss: 5.154162]\n",
      "epoch:31 step:24992 [D loss: 0.205151, acc: 98.44%] [G loss: 3.217116]\n",
      "epoch:32 step:24993 [D loss: 0.278300, acc: 97.66%] [G loss: 4.139015]\n",
      "epoch:32 step:24994 [D loss: 0.304336, acc: 95.31%] [G loss: 4.374922]\n",
      "epoch:32 step:24995 [D loss: 1.110557, acc: 44.53%] [G loss: 3.529413]\n",
      "epoch:32 step:24996 [D loss: 0.420208, acc: 75.00%] [G loss: 3.584846]\n",
      "epoch:32 step:24997 [D loss: 0.905805, acc: 50.00%] [G loss: 3.700483]\n",
      "epoch:32 step:24998 [D loss: 0.393483, acc: 86.72%] [G loss: 4.382064]\n",
      "epoch:32 step:24999 [D loss: 0.298569, acc: 96.09%] [G loss: 3.596406]\n",
      "epoch:32 step:25000 [D loss: 0.447309, acc: 71.09%] [G loss: 2.824836]\n",
      "epoch:32 step:25001 [D loss: 0.416778, acc: 79.69%] [G loss: 3.081744]\n",
      "epoch:32 step:25002 [D loss: 0.092746, acc: 100.00%] [G loss: 4.408357]\n",
      "epoch:32 step:25003 [D loss: 0.523241, acc: 69.53%] [G loss: 3.333751]\n",
      "epoch:32 step:25004 [D loss: 0.696844, acc: 59.38%] [G loss: 2.871658]\n",
      "epoch:32 step:25005 [D loss: 0.120902, acc: 100.00%] [G loss: 5.554125]\n",
      "epoch:32 step:25006 [D loss: 0.520591, acc: 73.44%] [G loss: 3.996499]\n",
      "epoch:32 step:25007 [D loss: 0.329901, acc: 86.72%] [G loss: 3.844203]\n",
      "epoch:32 step:25008 [D loss: 2.137012, acc: 49.22%] [G loss: 3.638186]\n",
      "epoch:32 step:25009 [D loss: 0.197742, acc: 99.22%] [G loss: 4.470643]\n",
      "epoch:32 step:25010 [D loss: 0.504674, acc: 63.28%] [G loss: 4.529815]\n",
      "epoch:32 step:25011 [D loss: 0.273139, acc: 96.88%] [G loss: 4.048811]\n",
      "epoch:32 step:25012 [D loss: 0.070538, acc: 100.00%] [G loss: 7.520323]\n",
      "epoch:32 step:25013 [D loss: 0.510087, acc: 75.00%] [G loss: 3.729036]\n",
      "epoch:32 step:25014 [D loss: 0.241418, acc: 96.09%] [G loss: 3.633880]\n",
      "epoch:32 step:25015 [D loss: 0.224973, acc: 96.88%] [G loss: 3.941280]\n",
      "epoch:32 step:25016 [D loss: 1.948340, acc: 2.34%] [G loss: 3.589848]\n",
      "epoch:32 step:25017 [D loss: 0.472970, acc: 82.03%] [G loss: 3.932000]\n",
      "epoch:32 step:25018 [D loss: 0.529875, acc: 75.78%] [G loss: 4.771210]\n",
      "epoch:32 step:25019 [D loss: 0.482657, acc: 69.53%] [G loss: 2.526080]\n",
      "epoch:32 step:25020 [D loss: 0.946531, acc: 28.91%] [G loss: 4.161253]\n",
      "epoch:32 step:25021 [D loss: 0.354548, acc: 88.28%] [G loss: 3.898075]\n",
      "epoch:32 step:25022 [D loss: 0.190204, acc: 97.66%] [G loss: 3.467373]\n",
      "epoch:32 step:25023 [D loss: 0.204423, acc: 95.31%] [G loss: 3.655145]\n",
      "epoch:32 step:25024 [D loss: 0.767813, acc: 50.78%] [G loss: 4.082255]\n",
      "epoch:32 step:25025 [D loss: 0.369714, acc: 92.97%] [G loss: 5.103831]\n",
      "epoch:32 step:25026 [D loss: 0.335580, acc: 94.53%] [G loss: 3.329104]\n",
      "epoch:32 step:25027 [D loss: 0.543786, acc: 62.50%] [G loss: 5.165530]\n",
      "epoch:32 step:25028 [D loss: 0.049425, acc: 100.00%] [G loss: 4.225560]\n",
      "epoch:32 step:25029 [D loss: 0.462913, acc: 75.78%] [G loss: 4.278196]\n",
      "epoch:32 step:25030 [D loss: 0.137673, acc: 100.00%] [G loss: 4.305227]\n",
      "epoch:32 step:25031 [D loss: 0.550522, acc: 71.88%] [G loss: 4.044487]\n",
      "epoch:32 step:25032 [D loss: 0.199576, acc: 97.66%] [G loss: 4.179889]\n",
      "epoch:32 step:25033 [D loss: 0.438532, acc: 82.03%] [G loss: 5.273761]\n",
      "epoch:32 step:25034 [D loss: 0.149801, acc: 100.00%] [G loss: 3.887618]\n",
      "epoch:32 step:25035 [D loss: 0.341650, acc: 96.09%] [G loss: 1.782034]\n",
      "epoch:32 step:25036 [D loss: 0.953903, acc: 35.16%] [G loss: 4.145367]\n",
      "epoch:32 step:25037 [D loss: 0.147515, acc: 97.66%] [G loss: 6.002153]\n",
      "epoch:32 step:25038 [D loss: 0.743569, acc: 56.25%] [G loss: 4.536226]\n",
      "epoch:32 step:25039 [D loss: 0.463443, acc: 72.66%] [G loss: 4.773727]\n",
      "epoch:32 step:25040 [D loss: 0.243551, acc: 98.44%] [G loss: 4.261423]\n",
      "epoch:32 step:25041 [D loss: 0.675227, acc: 59.38%] [G loss: 3.578116]\n",
      "epoch:32 step:25042 [D loss: 0.102514, acc: 99.22%] [G loss: 1.897573]\n",
      "epoch:32 step:25043 [D loss: 0.118573, acc: 99.22%] [G loss: 4.333319]\n",
      "epoch:32 step:25044 [D loss: 0.168613, acc: 97.66%] [G loss: 5.348778]\n",
      "epoch:32 step:25045 [D loss: 0.211827, acc: 96.88%] [G loss: 4.136234]\n",
      "epoch:32 step:25046 [D loss: 0.442677, acc: 82.81%] [G loss: 2.877141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25047 [D loss: 0.231201, acc: 96.09%] [G loss: 3.274299]\n",
      "epoch:32 step:25048 [D loss: 0.573463, acc: 66.41%] [G loss: 4.641810]\n",
      "epoch:32 step:25049 [D loss: 0.452949, acc: 85.16%] [G loss: 2.357234]\n",
      "epoch:32 step:25050 [D loss: 1.329516, acc: 27.34%] [G loss: 2.097486]\n",
      "epoch:32 step:25051 [D loss: 0.140179, acc: 99.22%] [G loss: 3.665738]\n",
      "epoch:32 step:25052 [D loss: 0.357005, acc: 93.75%] [G loss: 3.792739]\n",
      "epoch:32 step:25053 [D loss: 0.527973, acc: 76.56%] [G loss: 3.909697]\n",
      "epoch:32 step:25054 [D loss: 0.226836, acc: 97.66%] [G loss: 2.236506]\n",
      "epoch:32 step:25055 [D loss: 0.556061, acc: 65.62%] [G loss: 4.302123]\n",
      "epoch:32 step:25056 [D loss: 0.335914, acc: 86.72%] [G loss: 4.159619]\n",
      "epoch:32 step:25057 [D loss: 0.421199, acc: 82.03%] [G loss: 2.729552]\n",
      "epoch:32 step:25058 [D loss: 0.463658, acc: 79.69%] [G loss: 3.596875]\n",
      "epoch:32 step:25059 [D loss: 0.236501, acc: 99.22%] [G loss: 2.982273]\n",
      "epoch:32 step:25060 [D loss: 0.840703, acc: 52.34%] [G loss: 5.176047]\n",
      "epoch:32 step:25061 [D loss: 1.000744, acc: 48.44%] [G loss: 3.825330]\n",
      "epoch:32 step:25062 [D loss: 0.120430, acc: 100.00%] [G loss: 3.596486]\n",
      "epoch:32 step:25063 [D loss: 1.768762, acc: 3.91%] [G loss: 4.226922]\n",
      "epoch:32 step:25064 [D loss: 0.145719, acc: 99.22%] [G loss: 2.743879]\n",
      "epoch:32 step:25065 [D loss: 0.479524, acc: 71.09%] [G loss: 4.731336]\n",
      "epoch:32 step:25066 [D loss: 0.303312, acc: 91.41%] [G loss: 5.517313]\n",
      "epoch:32 step:25067 [D loss: 0.254583, acc: 89.84%] [G loss: 2.965738]\n",
      "epoch:32 step:25068 [D loss: 0.126476, acc: 100.00%] [G loss: 3.958241]\n",
      "epoch:32 step:25069 [D loss: 0.301470, acc: 96.09%] [G loss: 3.507280]\n",
      "epoch:32 step:25070 [D loss: 0.293307, acc: 84.38%] [G loss: 4.598095]\n",
      "epoch:32 step:25071 [D loss: 0.401913, acc: 85.94%] [G loss: 3.143057]\n",
      "epoch:32 step:25072 [D loss: 0.143912, acc: 100.00%] [G loss: 3.899487]\n",
      "epoch:32 step:25073 [D loss: 0.915688, acc: 52.34%] [G loss: 3.597183]\n",
      "epoch:32 step:25074 [D loss: 0.313892, acc: 92.19%] [G loss: 2.946981]\n",
      "epoch:32 step:25075 [D loss: 0.840230, acc: 53.12%] [G loss: 5.495971]\n",
      "epoch:32 step:25076 [D loss: 0.099870, acc: 99.22%] [G loss: 5.465380]\n",
      "epoch:32 step:25077 [D loss: 0.377684, acc: 89.06%] [G loss: 5.152482]\n",
      "epoch:32 step:25078 [D loss: 0.088021, acc: 100.00%] [G loss: 3.522456]\n",
      "epoch:32 step:25079 [D loss: 0.521042, acc: 76.56%] [G loss: 1.765445]\n",
      "epoch:32 step:25080 [D loss: 0.281687, acc: 96.09%] [G loss: 3.082373]\n",
      "epoch:32 step:25081 [D loss: 0.405291, acc: 76.56%] [G loss: 5.702659]\n",
      "epoch:32 step:25082 [D loss: 0.446641, acc: 80.47%] [G loss: 4.119357]\n",
      "epoch:32 step:25083 [D loss: 0.054460, acc: 100.00%] [G loss: 5.320949]\n",
      "epoch:32 step:25084 [D loss: 0.351795, acc: 87.50%] [G loss: 5.516026]\n",
      "epoch:32 step:25085 [D loss: 0.187877, acc: 99.22%] [G loss: 7.368909]\n",
      "epoch:32 step:25086 [D loss: 0.605271, acc: 60.16%] [G loss: 5.196483]\n",
      "epoch:32 step:25087 [D loss: 0.230851, acc: 99.22%] [G loss: 5.154043]\n",
      "epoch:32 step:25088 [D loss: 0.620738, acc: 60.94%] [G loss: 3.948773]\n",
      "epoch:32 step:25089 [D loss: 0.437132, acc: 82.81%] [G loss: 4.551376]\n",
      "epoch:32 step:25090 [D loss: 0.285350, acc: 90.62%] [G loss: 3.971580]\n",
      "epoch:32 step:25091 [D loss: 0.074367, acc: 100.00%] [G loss: 4.856141]\n",
      "epoch:32 step:25092 [D loss: 0.205697, acc: 94.53%] [G loss: 4.495344]\n",
      "epoch:32 step:25093 [D loss: 0.316179, acc: 85.94%] [G loss: 5.109117]\n",
      "epoch:32 step:25094 [D loss: 0.840648, acc: 53.91%] [G loss: 4.402520]\n",
      "epoch:32 step:25095 [D loss: 0.719045, acc: 53.91%] [G loss: 3.767569]\n",
      "epoch:32 step:25096 [D loss: 0.045740, acc: 100.00%] [G loss: 6.911802]\n",
      "epoch:32 step:25097 [D loss: 0.218358, acc: 97.66%] [G loss: 3.248872]\n",
      "epoch:32 step:25098 [D loss: 0.401557, acc: 92.19%] [G loss: 3.529066]\n",
      "epoch:32 step:25099 [D loss: 0.669513, acc: 61.72%] [G loss: 4.071854]\n",
      "epoch:32 step:25100 [D loss: 0.482700, acc: 71.88%] [G loss: 2.478711]\n",
      "epoch:32 step:25101 [D loss: 0.573536, acc: 65.62%] [G loss: 3.918236]\n",
      "epoch:32 step:25102 [D loss: 0.730704, acc: 50.78%] [G loss: 2.308510]\n",
      "epoch:32 step:25103 [D loss: 0.536497, acc: 75.00%] [G loss: 4.152750]\n",
      "epoch:32 step:25104 [D loss: 0.165194, acc: 100.00%] [G loss: 2.949569]\n",
      "epoch:32 step:25105 [D loss: 0.114053, acc: 100.00%] [G loss: 6.911318]\n",
      "epoch:32 step:25106 [D loss: 0.513047, acc: 72.66%] [G loss: 5.018189]\n",
      "epoch:32 step:25107 [D loss: 0.180283, acc: 99.22%] [G loss: 2.173569]\n",
      "epoch:32 step:25108 [D loss: 0.306049, acc: 96.88%] [G loss: 3.087885]\n",
      "epoch:32 step:25109 [D loss: 0.074219, acc: 99.22%] [G loss: 4.246863]\n",
      "epoch:32 step:25110 [D loss: 0.648576, acc: 61.72%] [G loss: 3.195457]\n",
      "epoch:32 step:25111 [D loss: 0.200707, acc: 95.31%] [G loss: 4.298345]\n",
      "epoch:32 step:25112 [D loss: 0.709482, acc: 53.91%] [G loss: 4.878230]\n",
      "epoch:32 step:25113 [D loss: 0.749272, acc: 55.47%] [G loss: 3.205906]\n",
      "epoch:32 step:25114 [D loss: 0.073924, acc: 100.00%] [G loss: 5.713984]\n",
      "epoch:32 step:25115 [D loss: 0.451715, acc: 73.44%] [G loss: 3.349760]\n",
      "epoch:32 step:25116 [D loss: 0.128026, acc: 100.00%] [G loss: 4.440677]\n",
      "epoch:32 step:25117 [D loss: 0.710135, acc: 53.91%] [G loss: 4.543499]\n",
      "epoch:32 step:25118 [D loss: 0.785313, acc: 52.34%] [G loss: 2.321985]\n",
      "epoch:32 step:25119 [D loss: 0.095306, acc: 100.00%] [G loss: 4.547854]\n",
      "epoch:32 step:25120 [D loss: 0.390824, acc: 85.94%] [G loss: 3.455946]\n",
      "epoch:32 step:25121 [D loss: 0.306770, acc: 89.06%] [G loss: 1.330493]\n",
      "epoch:32 step:25122 [D loss: 0.448228, acc: 85.94%] [G loss: 5.829102]\n",
      "epoch:32 step:25123 [D loss: 0.871280, acc: 51.56%] [G loss: 2.932474]\n",
      "epoch:32 step:25124 [D loss: 0.636539, acc: 56.25%] [G loss: 4.180572]\n",
      "epoch:32 step:25125 [D loss: 0.109135, acc: 98.44%] [G loss: 4.928222]\n",
      "epoch:32 step:25126 [D loss: 0.897453, acc: 50.00%] [G loss: 6.462759]\n",
      "epoch:32 step:25127 [D loss: 0.726146, acc: 54.69%] [G loss: 4.038775]\n",
      "epoch:32 step:25128 [D loss: 0.130830, acc: 100.00%] [G loss: 4.969739]\n",
      "epoch:32 step:25129 [D loss: 0.047676, acc: 100.00%] [G loss: 2.781196]\n",
      "epoch:32 step:25130 [D loss: 0.458652, acc: 82.03%] [G loss: 3.273273]\n",
      "epoch:32 step:25131 [D loss: 0.925113, acc: 50.78%] [G loss: 3.560982]\n",
      "epoch:32 step:25132 [D loss: 0.215214, acc: 92.97%] [G loss: 3.606552]\n",
      "epoch:32 step:25133 [D loss: 0.496066, acc: 65.62%] [G loss: 3.548293]\n",
      "epoch:32 step:25134 [D loss: 0.150128, acc: 98.44%] [G loss: 4.661362]\n",
      "epoch:32 step:25135 [D loss: 0.464803, acc: 74.22%] [G loss: 3.757093]\n",
      "epoch:32 step:25136 [D loss: 1.291258, acc: 14.84%] [G loss: 4.140796]\n",
      "epoch:32 step:25137 [D loss: 0.247683, acc: 96.09%] [G loss: 2.937857]\n",
      "epoch:32 step:25138 [D loss: 0.499590, acc: 69.53%] [G loss: 4.806702]\n",
      "epoch:32 step:25139 [D loss: 0.152802, acc: 100.00%] [G loss: 2.671876]\n",
      "epoch:32 step:25140 [D loss: 0.308378, acc: 92.97%] [G loss: 2.875563]\n",
      "epoch:32 step:25141 [D loss: 2.039893, acc: 3.12%] [G loss: 5.443063]\n",
      "epoch:32 step:25142 [D loss: 0.400152, acc: 95.31%] [G loss: 2.341989]\n",
      "epoch:32 step:25143 [D loss: 0.610358, acc: 60.94%] [G loss: 3.534046]\n",
      "epoch:32 step:25144 [D loss: 0.222510, acc: 99.22%] [G loss: 5.629586]\n",
      "epoch:32 step:25145 [D loss: 0.350634, acc: 89.06%] [G loss: 3.481173]\n",
      "epoch:32 step:25146 [D loss: 0.597773, acc: 60.16%] [G loss: 4.744531]\n",
      "epoch:32 step:25147 [D loss: 0.118340, acc: 100.00%] [G loss: 3.868005]\n",
      "epoch:32 step:25148 [D loss: 0.322783, acc: 92.19%] [G loss: 2.530006]\n",
      "epoch:32 step:25149 [D loss: 0.800743, acc: 52.34%] [G loss: 3.025194]\n",
      "epoch:32 step:25150 [D loss: 0.169392, acc: 99.22%] [G loss: 4.447396]\n",
      "epoch:32 step:25151 [D loss: 0.237855, acc: 98.44%] [G loss: 3.015109]\n",
      "epoch:32 step:25152 [D loss: 0.741421, acc: 49.22%] [G loss: 4.014813]\n",
      "epoch:32 step:25153 [D loss: 0.043877, acc: 100.00%] [G loss: 3.896349]\n",
      "epoch:32 step:25154 [D loss: 0.051319, acc: 100.00%] [G loss: 4.721156]\n",
      "epoch:32 step:25155 [D loss: 0.576648, acc: 69.53%] [G loss: 3.281190]\n",
      "epoch:32 step:25156 [D loss: 0.205320, acc: 96.88%] [G loss: 5.042798]\n",
      "epoch:32 step:25157 [D loss: 0.683067, acc: 54.69%] [G loss: 2.678201]\n",
      "epoch:32 step:25158 [D loss: 0.583135, acc: 62.50%] [G loss: 2.193847]\n",
      "epoch:32 step:25159 [D loss: 0.087666, acc: 99.22%] [G loss: 3.831384]\n",
      "epoch:32 step:25160 [D loss: 0.489379, acc: 80.47%] [G loss: 3.476757]\n",
      "epoch:32 step:25161 [D loss: 0.282482, acc: 95.31%] [G loss: 4.185513]\n",
      "epoch:32 step:25162 [D loss: 0.235647, acc: 99.22%] [G loss: 4.252117]\n",
      "epoch:32 step:25163 [D loss: 0.537884, acc: 69.53%] [G loss: 3.236059]\n",
      "epoch:32 step:25164 [D loss: 0.499812, acc: 69.53%] [G loss: 4.757480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25165 [D loss: 1.603260, acc: 21.09%] [G loss: 2.615515]\n",
      "epoch:32 step:25166 [D loss: 0.178228, acc: 97.66%] [G loss: 5.686394]\n",
      "epoch:32 step:25167 [D loss: 0.122006, acc: 100.00%] [G loss: 4.831869]\n",
      "epoch:32 step:25168 [D loss: 0.614849, acc: 63.28%] [G loss: 4.043337]\n",
      "epoch:32 step:25169 [D loss: 0.962951, acc: 45.31%] [G loss: 2.394385]\n",
      "epoch:32 step:25170 [D loss: 0.150214, acc: 99.22%] [G loss: 3.604856]\n",
      "epoch:32 step:25171 [D loss: 1.090696, acc: 37.50%] [G loss: 2.034799]\n",
      "epoch:32 step:25172 [D loss: 0.888826, acc: 49.22%] [G loss: 4.633988]\n",
      "epoch:32 step:25173 [D loss: 0.202442, acc: 97.66%] [G loss: 2.729506]\n",
      "epoch:32 step:25174 [D loss: 0.309125, acc: 96.09%] [G loss: 4.158765]\n",
      "epoch:32 step:25175 [D loss: 0.262562, acc: 96.88%] [G loss: 2.567003]\n",
      "epoch:32 step:25176 [D loss: 0.425551, acc: 82.03%] [G loss: 1.548071]\n",
      "epoch:32 step:25177 [D loss: 0.235625, acc: 94.53%] [G loss: 3.747011]\n",
      "epoch:32 step:25178 [D loss: 0.582578, acc: 67.97%] [G loss: 4.556776]\n",
      "epoch:32 step:25179 [D loss: 0.536646, acc: 77.34%] [G loss: 2.629443]\n",
      "epoch:32 step:25180 [D loss: 0.584937, acc: 61.72%] [G loss: 4.097221]\n",
      "epoch:32 step:25181 [D loss: 0.296674, acc: 85.16%] [G loss: 7.022280]\n",
      "epoch:32 step:25182 [D loss: 0.386520, acc: 85.16%] [G loss: 5.594183]\n",
      "epoch:32 step:25183 [D loss: 0.427152, acc: 78.91%] [G loss: 3.719327]\n",
      "epoch:32 step:25184 [D loss: 0.111816, acc: 100.00%] [G loss: 4.959520]\n",
      "epoch:32 step:25185 [D loss: 0.441531, acc: 84.38%] [G loss: 4.521953]\n",
      "epoch:32 step:25186 [D loss: 0.605486, acc: 60.94%] [G loss: 2.890193]\n",
      "epoch:32 step:25187 [D loss: 0.861486, acc: 47.66%] [G loss: 3.451777]\n",
      "epoch:32 step:25188 [D loss: 1.007688, acc: 44.53%] [G loss: 3.373780]\n",
      "epoch:32 step:25189 [D loss: 0.096609, acc: 99.22%] [G loss: 4.629002]\n",
      "epoch:32 step:25190 [D loss: 0.264809, acc: 89.84%] [G loss: 3.893119]\n",
      "epoch:32 step:25191 [D loss: 0.244063, acc: 94.53%] [G loss: 3.762310]\n",
      "epoch:32 step:25192 [D loss: 0.136683, acc: 98.44%] [G loss: 6.034542]\n",
      "epoch:32 step:25193 [D loss: 0.319926, acc: 83.59%] [G loss: 3.436648]\n",
      "epoch:32 step:25194 [D loss: 1.169277, acc: 49.22%] [G loss: 3.591335]\n",
      "epoch:32 step:25195 [D loss: 0.815426, acc: 52.34%] [G loss: 1.626995]\n",
      "epoch:32 step:25196 [D loss: 0.323930, acc: 94.53%] [G loss: 4.383965]\n",
      "epoch:32 step:25197 [D loss: 0.472498, acc: 79.69%] [G loss: 5.024296]\n",
      "epoch:32 step:25198 [D loss: 0.905096, acc: 43.75%] [G loss: 4.058018]\n",
      "epoch:32 step:25199 [D loss: 0.326399, acc: 92.97%] [G loss: 3.602468]\n",
      "epoch:32 step:25200 [D loss: 0.528627, acc: 62.50%] [G loss: 6.161423]\n",
      "epoch:32 step:25201 [D loss: 1.856147, acc: 50.00%] [G loss: 3.564282]\n",
      "epoch:32 step:25202 [D loss: 0.432939, acc: 84.38%] [G loss: 1.809793]\n",
      "epoch:32 step:25203 [D loss: 0.474988, acc: 82.03%] [G loss: 2.489073]\n",
      "epoch:32 step:25204 [D loss: 0.078321, acc: 100.00%] [G loss: 5.585876]\n",
      "epoch:32 step:25205 [D loss: 0.298417, acc: 89.84%] [G loss: 2.779351]\n",
      "epoch:32 step:25206 [D loss: 0.296140, acc: 93.75%] [G loss: 4.698525]\n",
      "epoch:32 step:25207 [D loss: 0.561168, acc: 64.06%] [G loss: 3.104275]\n",
      "epoch:32 step:25208 [D loss: 0.580188, acc: 67.97%] [G loss: 3.860766]\n",
      "epoch:32 step:25209 [D loss: 0.377975, acc: 91.41%] [G loss: 2.938693]\n",
      "epoch:32 step:25210 [D loss: 0.159405, acc: 99.22%] [G loss: 3.561977]\n",
      "epoch:32 step:25211 [D loss: 0.269999, acc: 97.66%] [G loss: 3.898124]\n",
      "epoch:32 step:25212 [D loss: 0.263469, acc: 92.19%] [G loss: 5.094689]\n",
      "epoch:32 step:25213 [D loss: 0.557567, acc: 65.62%] [G loss: 2.777972]\n",
      "epoch:32 step:25214 [D loss: 0.285819, acc: 90.62%] [G loss: 4.776636]\n",
      "epoch:32 step:25215 [D loss: 0.963560, acc: 40.62%] [G loss: 3.822056]\n",
      "epoch:32 step:25216 [D loss: 0.034319, acc: 100.00%] [G loss: 4.310954]\n",
      "epoch:32 step:25217 [D loss: 0.679759, acc: 59.38%] [G loss: 4.965053]\n",
      "epoch:32 step:25218 [D loss: 0.798129, acc: 53.12%] [G loss: 2.144181]\n",
      "epoch:32 step:25219 [D loss: 0.201944, acc: 99.22%] [G loss: 4.153342]\n",
      "epoch:32 step:25220 [D loss: 0.433831, acc: 72.66%] [G loss: 3.609293]\n",
      "epoch:32 step:25221 [D loss: 0.395088, acc: 80.47%] [G loss: 5.097105]\n",
      "epoch:32 step:25222 [D loss: 0.952532, acc: 46.88%] [G loss: 3.590678]\n",
      "epoch:32 step:25223 [D loss: 0.755686, acc: 51.56%] [G loss: 4.180760]\n",
      "epoch:32 step:25224 [D loss: 0.546338, acc: 70.31%] [G loss: 2.987252]\n",
      "epoch:32 step:25225 [D loss: 0.316249, acc: 93.75%] [G loss: 2.090105]\n",
      "epoch:32 step:25226 [D loss: 1.475998, acc: 10.16%] [G loss: 4.518254]\n",
      "epoch:32 step:25227 [D loss: 0.440255, acc: 86.72%] [G loss: 4.613805]\n",
      "epoch:32 step:25228 [D loss: 0.595768, acc: 60.94%] [G loss: 3.951950]\n",
      "epoch:32 step:25229 [D loss: 0.195787, acc: 96.09%] [G loss: 5.152975]\n",
      "epoch:32 step:25230 [D loss: 0.192384, acc: 96.88%] [G loss: 4.559928]\n",
      "epoch:32 step:25231 [D loss: 0.219783, acc: 95.31%] [G loss: 3.324015]\n",
      "epoch:32 step:25232 [D loss: 0.298250, acc: 92.19%] [G loss: 4.417870]\n",
      "epoch:32 step:25233 [D loss: 0.155305, acc: 99.22%] [G loss: 4.391672]\n",
      "epoch:32 step:25234 [D loss: 0.166887, acc: 99.22%] [G loss: 4.967949]\n",
      "epoch:32 step:25235 [D loss: 0.338928, acc: 91.41%] [G loss: 6.376443]\n",
      "epoch:32 step:25236 [D loss: 0.067667, acc: 100.00%] [G loss: 2.901605]\n",
      "epoch:32 step:25237 [D loss: 0.567362, acc: 66.41%] [G loss: 4.208467]\n",
      "epoch:32 step:25238 [D loss: 0.626329, acc: 60.16%] [G loss: 3.831015]\n",
      "epoch:32 step:25239 [D loss: 0.143580, acc: 98.44%] [G loss: 3.061042]\n",
      "epoch:32 step:25240 [D loss: 0.187224, acc: 96.09%] [G loss: 3.299491]\n",
      "epoch:32 step:25241 [D loss: 0.443911, acc: 86.72%] [G loss: 5.428680]\n",
      "epoch:32 step:25242 [D loss: 0.922378, acc: 44.53%] [G loss: 5.039968]\n",
      "epoch:32 step:25243 [D loss: 0.358958, acc: 82.81%] [G loss: 4.485950]\n",
      "epoch:32 step:25244 [D loss: 0.524796, acc: 69.53%] [G loss: 3.767393]\n",
      "epoch:32 step:25245 [D loss: 0.614260, acc: 67.97%] [G loss: 5.004960]\n",
      "epoch:32 step:25246 [D loss: 0.543501, acc: 71.09%] [G loss: 4.040658]\n",
      "epoch:32 step:25247 [D loss: 0.055681, acc: 100.00%] [G loss: 4.966726]\n",
      "epoch:32 step:25248 [D loss: 0.130281, acc: 100.00%] [G loss: 4.304500]\n",
      "epoch:32 step:25249 [D loss: 0.199314, acc: 97.66%] [G loss: 3.834580]\n",
      "epoch:32 step:25250 [D loss: 0.368662, acc: 92.97%] [G loss: 3.980372]\n",
      "epoch:32 step:25251 [D loss: 0.301000, acc: 86.72%] [G loss: 3.799680]\n",
      "epoch:32 step:25252 [D loss: 0.116069, acc: 100.00%] [G loss: 2.672460]\n",
      "epoch:32 step:25253 [D loss: 0.604520, acc: 62.50%] [G loss: 5.450222]\n",
      "epoch:32 step:25254 [D loss: 0.735857, acc: 53.12%] [G loss: 3.847726]\n",
      "epoch:32 step:25255 [D loss: 0.282765, acc: 94.53%] [G loss: 3.056084]\n",
      "epoch:32 step:25256 [D loss: 0.377314, acc: 89.84%] [G loss: 3.693396]\n",
      "epoch:32 step:25257 [D loss: 1.314312, acc: 10.94%] [G loss: 3.414963]\n",
      "epoch:32 step:25258 [D loss: 0.119198, acc: 100.00%] [G loss: 6.910068]\n",
      "epoch:32 step:25259 [D loss: 0.516000, acc: 71.88%] [G loss: 3.055701]\n",
      "epoch:32 step:25260 [D loss: 0.236194, acc: 98.44%] [G loss: 4.460231]\n",
      "epoch:32 step:25261 [D loss: 0.661010, acc: 58.59%] [G loss: 4.432976]\n",
      "epoch:32 step:25262 [D loss: 0.954469, acc: 36.72%] [G loss: 3.378663]\n",
      "epoch:32 step:25263 [D loss: 0.105130, acc: 99.22%] [G loss: 4.368882]\n",
      "epoch:32 step:25264 [D loss: 0.289557, acc: 86.72%] [G loss: 3.985572]\n",
      "epoch:32 step:25265 [D loss: 0.499213, acc: 78.12%] [G loss: 4.198464]\n",
      "epoch:32 step:25266 [D loss: 0.619084, acc: 56.25%] [G loss: 6.641057]\n",
      "epoch:32 step:25267 [D loss: 0.489056, acc: 73.44%] [G loss: 3.714204]\n",
      "epoch:32 step:25268 [D loss: 0.387487, acc: 75.78%] [G loss: 2.370580]\n",
      "epoch:32 step:25269 [D loss: 0.054286, acc: 100.00%] [G loss: 4.192437]\n",
      "epoch:32 step:25270 [D loss: 0.527639, acc: 63.28%] [G loss: 5.861580]\n",
      "epoch:32 step:25271 [D loss: 0.150560, acc: 99.22%] [G loss: 4.279544]\n",
      "epoch:32 step:25272 [D loss: 0.495234, acc: 78.91%] [G loss: 5.353937]\n",
      "epoch:32 step:25273 [D loss: 0.237483, acc: 94.53%] [G loss: 4.695764]\n",
      "epoch:32 step:25274 [D loss: 0.235815, acc: 93.75%] [G loss: 3.058073]\n",
      "epoch:32 step:25275 [D loss: 0.646121, acc: 64.84%] [G loss: 4.295691]\n",
      "epoch:32 step:25276 [D loss: 0.292506, acc: 92.19%] [G loss: 4.995981]\n",
      "epoch:32 step:25277 [D loss: 0.709767, acc: 56.25%] [G loss: 2.843099]\n",
      "epoch:32 step:25278 [D loss: 0.232585, acc: 96.88%] [G loss: 3.350437]\n",
      "epoch:32 step:25279 [D loss: 0.542787, acc: 70.31%] [G loss: 4.798810]\n",
      "epoch:32 step:25280 [D loss: 1.269996, acc: 50.00%] [G loss: 3.729209]\n",
      "epoch:32 step:25281 [D loss: 0.250375, acc: 96.88%] [G loss: 3.303053]\n",
      "epoch:32 step:25282 [D loss: 0.505333, acc: 75.78%] [G loss: 3.571796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25283 [D loss: 0.868333, acc: 45.31%] [G loss: 2.955811]\n",
      "epoch:32 step:25284 [D loss: 0.025832, acc: 100.00%] [G loss: 4.125440]\n",
      "epoch:32 step:25285 [D loss: 1.156932, acc: 47.66%] [G loss: 4.655829]\n",
      "epoch:32 step:25286 [D loss: 0.670196, acc: 60.94%] [G loss: 4.626190]\n",
      "epoch:32 step:25287 [D loss: 0.168052, acc: 100.00%] [G loss: 3.320162]\n",
      "epoch:32 step:25288 [D loss: 0.071293, acc: 99.22%] [G loss: 4.629594]\n",
      "epoch:32 step:25289 [D loss: 0.430261, acc: 89.06%] [G loss: 4.656989]\n",
      "epoch:32 step:25290 [D loss: 0.334080, acc: 85.16%] [G loss: 3.260068]\n",
      "epoch:32 step:25291 [D loss: 0.341485, acc: 86.72%] [G loss: 5.097819]\n",
      "epoch:32 step:25292 [D loss: 0.595450, acc: 64.06%] [G loss: 4.476575]\n",
      "epoch:32 step:25293 [D loss: 1.007003, acc: 50.78%] [G loss: 5.580184]\n",
      "epoch:32 step:25294 [D loss: 0.263841, acc: 95.31%] [G loss: 5.311803]\n",
      "epoch:32 step:25295 [D loss: 1.047154, acc: 37.50%] [G loss: 2.068186]\n",
      "epoch:32 step:25296 [D loss: 0.322098, acc: 91.41%] [G loss: 4.348348]\n",
      "epoch:32 step:25297 [D loss: 0.090647, acc: 99.22%] [G loss: 3.542661]\n",
      "epoch:32 step:25298 [D loss: 0.168974, acc: 96.88%] [G loss: 5.359142]\n",
      "epoch:32 step:25299 [D loss: 0.265016, acc: 98.44%] [G loss: 3.089013]\n",
      "epoch:32 step:25300 [D loss: 0.884078, acc: 39.84%] [G loss: 6.321068]\n",
      "epoch:32 step:25301 [D loss: 0.100966, acc: 100.00%] [G loss: 5.342203]\n",
      "epoch:32 step:25302 [D loss: 0.120484, acc: 99.22%] [G loss: 3.472726]\n",
      "epoch:32 step:25303 [D loss: 0.220381, acc: 99.22%] [G loss: 3.777542]\n",
      "epoch:32 step:25304 [D loss: 0.736301, acc: 55.47%] [G loss: 4.922008]\n",
      "epoch:32 step:25305 [D loss: 0.198659, acc: 97.66%] [G loss: 4.522655]\n",
      "epoch:32 step:25306 [D loss: 0.128772, acc: 99.22%] [G loss: 3.430084]\n",
      "epoch:32 step:25307 [D loss: 0.583098, acc: 70.31%] [G loss: 4.499526]\n",
      "epoch:32 step:25308 [D loss: 0.107738, acc: 100.00%] [G loss: 4.585526]\n",
      "epoch:32 step:25309 [D loss: 0.260395, acc: 96.09%] [G loss: 5.688200]\n",
      "epoch:32 step:25310 [D loss: 0.332864, acc: 89.06%] [G loss: 5.452838]\n",
      "epoch:32 step:25311 [D loss: 0.103712, acc: 100.00%] [G loss: 5.190349]\n",
      "epoch:32 step:25312 [D loss: 1.046068, acc: 42.19%] [G loss: 3.557705]\n",
      "epoch:32 step:25313 [D loss: 0.050996, acc: 100.00%] [G loss: 4.747572]\n",
      "epoch:32 step:25314 [D loss: 0.676673, acc: 53.12%] [G loss: 3.602100]\n",
      "epoch:32 step:25315 [D loss: 0.176144, acc: 100.00%] [G loss: 4.049229]\n",
      "epoch:32 step:25316 [D loss: 0.598624, acc: 71.09%] [G loss: 3.391434]\n",
      "epoch:32 step:25317 [D loss: 0.288934, acc: 94.53%] [G loss: 3.393443]\n",
      "epoch:32 step:25318 [D loss: 0.234269, acc: 97.66%] [G loss: 4.463562]\n",
      "epoch:32 step:25319 [D loss: 0.138530, acc: 99.22%] [G loss: 3.604187]\n",
      "epoch:32 step:25320 [D loss: 0.553833, acc: 60.16%] [G loss: 4.750226]\n",
      "epoch:32 step:25321 [D loss: 0.080925, acc: 100.00%] [G loss: 5.004304]\n",
      "epoch:32 step:25322 [D loss: 0.272997, acc: 92.97%] [G loss: 3.114358]\n",
      "epoch:32 step:25323 [D loss: 0.855543, acc: 55.47%] [G loss: 4.380885]\n",
      "epoch:32 step:25324 [D loss: 0.371612, acc: 80.47%] [G loss: 2.142363]\n",
      "epoch:32 step:25325 [D loss: 0.039219, acc: 100.00%] [G loss: 5.938581]\n",
      "epoch:32 step:25326 [D loss: 0.970770, acc: 28.91%] [G loss: 5.617414]\n",
      "epoch:32 step:25327 [D loss: 0.770163, acc: 53.12%] [G loss: 3.514596]\n",
      "epoch:32 step:25328 [D loss: 0.877767, acc: 32.81%] [G loss: 3.628824]\n",
      "epoch:32 step:25329 [D loss: 0.911125, acc: 50.00%] [G loss: 4.493425]\n",
      "epoch:32 step:25330 [D loss: 0.742491, acc: 60.16%] [G loss: 3.378188]\n",
      "epoch:32 step:25331 [D loss: 0.160100, acc: 97.66%] [G loss: 4.798280]\n",
      "epoch:32 step:25332 [D loss: 1.554529, acc: 45.31%] [G loss: 5.464499]\n",
      "epoch:32 step:25333 [D loss: 0.482637, acc: 79.69%] [G loss: 4.027069]\n",
      "epoch:32 step:25334 [D loss: 0.630989, acc: 63.28%] [G loss: 3.863717]\n",
      "epoch:32 step:25335 [D loss: 0.283196, acc: 96.09%] [G loss: 5.204444]\n",
      "epoch:32 step:25336 [D loss: 0.398844, acc: 90.62%] [G loss: 4.029961]\n",
      "epoch:32 step:25337 [D loss: 0.256856, acc: 88.28%] [G loss: 2.826453]\n",
      "epoch:32 step:25338 [D loss: 0.205876, acc: 97.66%] [G loss: 3.130162]\n",
      "epoch:32 step:25339 [D loss: 0.211956, acc: 97.66%] [G loss: 5.267261]\n",
      "epoch:32 step:25340 [D loss: 0.102779, acc: 100.00%] [G loss: 4.732948]\n",
      "epoch:32 step:25341 [D loss: 0.711882, acc: 51.56%] [G loss: 3.627700]\n",
      "epoch:32 step:25342 [D loss: 0.915457, acc: 39.06%] [G loss: 4.992688]\n",
      "epoch:32 step:25343 [D loss: 1.035408, acc: 42.19%] [G loss: 4.338109]\n",
      "epoch:32 step:25344 [D loss: 0.425692, acc: 73.44%] [G loss: 7.069889]\n",
      "epoch:32 step:25345 [D loss: 0.311019, acc: 92.19%] [G loss: 3.470080]\n",
      "epoch:32 step:25346 [D loss: 0.410766, acc: 72.66%] [G loss: 3.279141]\n",
      "epoch:32 step:25347 [D loss: 0.250113, acc: 98.44%] [G loss: 4.027760]\n",
      "epoch:32 step:25348 [D loss: 0.159817, acc: 97.66%] [G loss: 3.561336]\n",
      "epoch:32 step:25349 [D loss: 0.374125, acc: 86.72%] [G loss: 4.540644]\n",
      "epoch:32 step:25350 [D loss: 0.136809, acc: 99.22%] [G loss: 2.504171]\n",
      "epoch:32 step:25351 [D loss: 0.288777, acc: 96.09%] [G loss: 3.597925]\n",
      "epoch:32 step:25352 [D loss: 0.205382, acc: 96.88%] [G loss: 3.477881]\n",
      "epoch:32 step:25353 [D loss: 0.242704, acc: 97.66%] [G loss: 4.123301]\n",
      "epoch:32 step:25354 [D loss: 0.542675, acc: 72.66%] [G loss: 4.866621]\n",
      "epoch:32 step:25355 [D loss: 0.333011, acc: 92.19%] [G loss: 3.240632]\n",
      "epoch:32 step:25356 [D loss: 0.160217, acc: 99.22%] [G loss: 5.745238]\n",
      "epoch:32 step:25357 [D loss: 0.056477, acc: 100.00%] [G loss: 4.740258]\n",
      "epoch:32 step:25358 [D loss: 0.355145, acc: 82.03%] [G loss: 3.257654]\n",
      "epoch:32 step:25359 [D loss: 0.316135, acc: 85.16%] [G loss: 3.569113]\n",
      "epoch:32 step:25360 [D loss: 0.693823, acc: 57.03%] [G loss: 3.474458]\n",
      "epoch:32 step:25361 [D loss: 0.260012, acc: 92.19%] [G loss: 4.751934]\n",
      "epoch:32 step:25362 [D loss: 0.331822, acc: 86.72%] [G loss: 6.677947]\n",
      "epoch:32 step:25363 [D loss: 0.188605, acc: 99.22%] [G loss: 4.515962]\n",
      "epoch:32 step:25364 [D loss: 1.380420, acc: 38.28%] [G loss: 3.580590]\n",
      "epoch:32 step:25365 [D loss: 0.232507, acc: 98.44%] [G loss: 2.858086]\n",
      "epoch:32 step:25366 [D loss: 0.457381, acc: 85.16%] [G loss: 3.481466]\n",
      "epoch:32 step:25367 [D loss: 0.369754, acc: 75.78%] [G loss: 4.576130]\n",
      "epoch:32 step:25368 [D loss: 0.358907, acc: 83.59%] [G loss: 3.576956]\n",
      "epoch:32 step:25369 [D loss: 0.220943, acc: 96.88%] [G loss: 3.812765]\n",
      "epoch:32 step:25370 [D loss: 0.353662, acc: 92.19%] [G loss: 4.058603]\n",
      "epoch:32 step:25371 [D loss: 0.154222, acc: 97.66%] [G loss: 5.793768]\n",
      "epoch:32 step:25372 [D loss: 0.153668, acc: 98.44%] [G loss: 3.804060]\n",
      "epoch:32 step:25373 [D loss: 0.537506, acc: 68.75%] [G loss: 4.069473]\n",
      "epoch:32 step:25374 [D loss: 0.212465, acc: 99.22%] [G loss: 2.054706]\n",
      "epoch:32 step:25375 [D loss: 0.573104, acc: 67.19%] [G loss: 2.840306]\n",
      "epoch:32 step:25376 [D loss: 0.388807, acc: 82.03%] [G loss: 3.906923]\n",
      "epoch:32 step:25377 [D loss: 0.359598, acc: 92.19%] [G loss: 5.092039]\n",
      "epoch:32 step:25378 [D loss: 0.278461, acc: 96.88%] [G loss: 2.384607]\n",
      "epoch:32 step:25379 [D loss: 0.130898, acc: 99.22%] [G loss: 4.732825]\n",
      "epoch:32 step:25380 [D loss: 1.728930, acc: 11.72%] [G loss: 2.794139]\n",
      "epoch:32 step:25381 [D loss: 0.802950, acc: 45.31%] [G loss: 2.168525]\n",
      "epoch:32 step:25382 [D loss: 0.729807, acc: 53.91%] [G loss: 5.728286]\n",
      "epoch:32 step:25383 [D loss: 0.467151, acc: 70.31%] [G loss: 5.498398]\n",
      "epoch:32 step:25384 [D loss: 0.051716, acc: 100.00%] [G loss: 5.538087]\n",
      "epoch:32 step:25385 [D loss: 1.611651, acc: 18.75%] [G loss: 2.620587]\n",
      "epoch:32 step:25386 [D loss: 0.203302, acc: 96.88%] [G loss: 4.484606]\n",
      "epoch:32 step:25387 [D loss: 0.329862, acc: 96.09%] [G loss: 3.481833]\n",
      "epoch:32 step:25388 [D loss: 0.244637, acc: 89.84%] [G loss: 3.657283]\n",
      "epoch:32 step:25389 [D loss: 0.157845, acc: 97.66%] [G loss: 3.829705]\n",
      "epoch:32 step:25390 [D loss: 0.905132, acc: 53.12%] [G loss: 4.371862]\n",
      "epoch:32 step:25391 [D loss: 0.225199, acc: 99.22%] [G loss: 6.263214]\n",
      "epoch:32 step:25392 [D loss: 0.454353, acc: 64.84%] [G loss: 3.408554]\n",
      "epoch:32 step:25393 [D loss: 0.284274, acc: 88.28%] [G loss: 5.275819]\n",
      "epoch:32 step:25394 [D loss: 0.467357, acc: 84.38%] [G loss: 4.687281]\n",
      "epoch:32 step:25395 [D loss: 0.477272, acc: 82.03%] [G loss: 2.299459]\n",
      "epoch:32 step:25396 [D loss: 1.622680, acc: 4.69%] [G loss: 4.741919]\n",
      "epoch:32 step:25397 [D loss: 0.212985, acc: 98.44%] [G loss: 4.937608]\n",
      "epoch:32 step:25398 [D loss: 0.626746, acc: 53.91%] [G loss: 3.230772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25399 [D loss: 0.290561, acc: 94.53%] [G loss: 5.423740]\n",
      "epoch:32 step:25400 [D loss: 0.195285, acc: 99.22%] [G loss: 3.238131]\n",
      "epoch:32 step:25401 [D loss: 0.108415, acc: 100.00%] [G loss: 6.691262]\n",
      "epoch:32 step:25402 [D loss: 0.387733, acc: 78.12%] [G loss: 4.289533]\n",
      "epoch:32 step:25403 [D loss: 0.664611, acc: 65.62%] [G loss: 4.859891]\n",
      "epoch:32 step:25404 [D loss: 0.275574, acc: 92.19%] [G loss: 3.433303]\n",
      "epoch:32 step:25405 [D loss: 0.597494, acc: 63.28%] [G loss: 3.550596]\n",
      "epoch:32 step:25406 [D loss: 0.809460, acc: 51.56%] [G loss: 5.117486]\n",
      "epoch:32 step:25407 [D loss: 0.658576, acc: 54.69%] [G loss: 4.330952]\n",
      "epoch:32 step:25408 [D loss: 0.663628, acc: 61.72%] [G loss: 3.883123]\n",
      "epoch:32 step:25409 [D loss: 0.112243, acc: 100.00%] [G loss: 5.142733]\n",
      "epoch:32 step:25410 [D loss: 0.458869, acc: 75.78%] [G loss: 3.272665]\n",
      "epoch:32 step:25411 [D loss: 0.213769, acc: 99.22%] [G loss: 3.604961]\n",
      "epoch:32 step:25412 [D loss: 1.026084, acc: 26.56%] [G loss: 3.695283]\n",
      "epoch:32 step:25413 [D loss: 0.092354, acc: 100.00%] [G loss: 3.350734]\n",
      "epoch:32 step:25414 [D loss: 0.132148, acc: 99.22%] [G loss: 4.674278]\n",
      "epoch:32 step:25415 [D loss: 0.831099, acc: 42.97%] [G loss: 3.448036]\n",
      "epoch:32 step:25416 [D loss: 0.750164, acc: 53.91%] [G loss: 4.163758]\n",
      "epoch:32 step:25417 [D loss: 0.360006, acc: 80.47%] [G loss: 4.243174]\n",
      "epoch:32 step:25418 [D loss: 0.325468, acc: 91.41%] [G loss: 3.444958]\n",
      "epoch:32 step:25419 [D loss: 0.467982, acc: 68.75%] [G loss: 3.375197]\n",
      "epoch:32 step:25420 [D loss: 0.600542, acc: 67.97%] [G loss: 4.227114]\n",
      "epoch:32 step:25421 [D loss: 0.135221, acc: 99.22%] [G loss: 4.264453]\n",
      "epoch:32 step:25422 [D loss: 0.091631, acc: 99.22%] [G loss: 3.759298]\n",
      "epoch:32 step:25423 [D loss: 0.491616, acc: 78.12%] [G loss: 4.174356]\n",
      "epoch:32 step:25424 [D loss: 0.076776, acc: 100.00%] [G loss: 5.264234]\n",
      "epoch:32 step:25425 [D loss: 0.544122, acc: 75.00%] [G loss: 4.449935]\n",
      "epoch:32 step:25426 [D loss: 0.233716, acc: 95.31%] [G loss: 2.893828]\n",
      "epoch:32 step:25427 [D loss: 0.204630, acc: 100.00%] [G loss: 4.702576]\n",
      "epoch:32 step:25428 [D loss: 1.192370, acc: 15.62%] [G loss: 5.102127]\n",
      "epoch:32 step:25429 [D loss: 1.294454, acc: 34.38%] [G loss: 3.639489]\n",
      "epoch:32 step:25430 [D loss: 0.545626, acc: 61.72%] [G loss: 5.081444]\n",
      "epoch:32 step:25431 [D loss: 0.262676, acc: 96.88%] [G loss: 2.683199]\n",
      "epoch:32 step:25432 [D loss: 0.224073, acc: 96.09%] [G loss: 4.506667]\n",
      "epoch:32 step:25433 [D loss: 0.499063, acc: 64.06%] [G loss: 3.188643]\n",
      "epoch:32 step:25434 [D loss: 0.460485, acc: 77.34%] [G loss: 4.306886]\n",
      "epoch:32 step:25435 [D loss: 0.430274, acc: 90.62%] [G loss: 2.241933]\n",
      "epoch:32 step:25436 [D loss: 0.190728, acc: 99.22%] [G loss: 4.903541]\n",
      "epoch:32 step:25437 [D loss: 0.431751, acc: 80.47%] [G loss: 4.055262]\n",
      "epoch:32 step:25438 [D loss: 0.315915, acc: 92.19%] [G loss: 4.994259]\n",
      "epoch:32 step:25439 [D loss: 0.276400, acc: 93.75%] [G loss: 4.152197]\n",
      "epoch:32 step:25440 [D loss: 0.087479, acc: 100.00%] [G loss: 2.757937]\n",
      "epoch:32 step:25441 [D loss: 1.116431, acc: 50.00%] [G loss: 3.169743]\n",
      "epoch:32 step:25442 [D loss: 0.189593, acc: 96.88%] [G loss: 5.345580]\n",
      "epoch:32 step:25443 [D loss: 0.704311, acc: 57.81%] [G loss: 6.206195]\n",
      "epoch:32 step:25444 [D loss: 0.356768, acc: 90.62%] [G loss: 5.330209]\n",
      "epoch:32 step:25445 [D loss: 0.347346, acc: 87.50%] [G loss: 4.413705]\n",
      "epoch:32 step:25446 [D loss: 0.307996, acc: 92.19%] [G loss: 4.423290]\n",
      "epoch:32 step:25447 [D loss: 0.536781, acc: 69.53%] [G loss: 6.437027]\n",
      "epoch:32 step:25448 [D loss: 0.292237, acc: 96.09%] [G loss: 3.826650]\n",
      "epoch:32 step:25449 [D loss: 0.580266, acc: 60.94%] [G loss: 3.371114]\n",
      "epoch:32 step:25450 [D loss: 0.115332, acc: 100.00%] [G loss: 4.780393]\n",
      "epoch:32 step:25451 [D loss: 0.505126, acc: 64.84%] [G loss: 3.621918]\n",
      "epoch:32 step:25452 [D loss: 0.196799, acc: 100.00%] [G loss: 2.821332]\n",
      "epoch:32 step:25453 [D loss: 0.093851, acc: 100.00%] [G loss: 5.536697]\n",
      "epoch:32 step:25454 [D loss: 0.326665, acc: 92.97%] [G loss: 4.019242]\n",
      "epoch:32 step:25455 [D loss: 0.260608, acc: 98.44%] [G loss: 4.011615]\n",
      "epoch:32 step:25456 [D loss: 0.248249, acc: 98.44%] [G loss: 2.926569]\n",
      "epoch:32 step:25457 [D loss: 0.500222, acc: 71.88%] [G loss: 6.377843]\n",
      "epoch:32 step:25458 [D loss: 0.030571, acc: 100.00%] [G loss: 5.629658]\n",
      "epoch:32 step:25459 [D loss: 0.244830, acc: 95.31%] [G loss: 2.570361]\n",
      "epoch:32 step:25460 [D loss: 0.502054, acc: 67.97%] [G loss: 3.645863]\n",
      "epoch:32 step:25461 [D loss: 0.045825, acc: 100.00%] [G loss: 4.940857]\n",
      "epoch:32 step:25462 [D loss: 0.390074, acc: 75.00%] [G loss: 4.692586]\n",
      "epoch:32 step:25463 [D loss: 0.381528, acc: 84.38%] [G loss: 2.288991]\n",
      "epoch:32 step:25464 [D loss: 0.461065, acc: 85.16%] [G loss: 3.298728]\n",
      "epoch:32 step:25465 [D loss: 0.953932, acc: 52.34%] [G loss: 3.560336]\n",
      "epoch:32 step:25466 [D loss: 0.382499, acc: 85.16%] [G loss: 3.401546]\n",
      "epoch:32 step:25467 [D loss: 0.072442, acc: 100.00%] [G loss: 2.916738]\n",
      "epoch:32 step:25468 [D loss: 0.439571, acc: 69.53%] [G loss: 2.722547]\n",
      "epoch:32 step:25469 [D loss: 0.943538, acc: 48.44%] [G loss: 3.371045]\n",
      "epoch:32 step:25470 [D loss: 0.138491, acc: 99.22%] [G loss: 5.688403]\n",
      "epoch:32 step:25471 [D loss: 0.355933, acc: 90.62%] [G loss: 3.119241]\n",
      "epoch:32 step:25472 [D loss: 0.509619, acc: 77.34%] [G loss: 3.420345]\n",
      "epoch:32 step:25473 [D loss: 0.491406, acc: 65.62%] [G loss: 2.004267]\n",
      "epoch:32 step:25474 [D loss: 0.875787, acc: 51.56%] [G loss: 5.042301]\n",
      "epoch:32 step:25475 [D loss: 0.637774, acc: 64.06%] [G loss: 2.477217]\n",
      "epoch:32 step:25476 [D loss: 0.268995, acc: 95.31%] [G loss: 5.065554]\n",
      "epoch:32 step:25477 [D loss: 1.344206, acc: 29.69%] [G loss: 3.699448]\n",
      "epoch:32 step:25478 [D loss: 0.396533, acc: 77.34%] [G loss: 3.647601]\n",
      "epoch:32 step:25479 [D loss: 0.620175, acc: 65.62%] [G loss: 4.696964]\n",
      "epoch:32 step:25480 [D loss: 0.356605, acc: 84.38%] [G loss: 3.251850]\n",
      "epoch:32 step:25481 [D loss: 0.262898, acc: 95.31%] [G loss: 4.105206]\n",
      "epoch:32 step:25482 [D loss: 0.153205, acc: 99.22%] [G loss: 4.432078]\n",
      "epoch:32 step:25483 [D loss: 0.148715, acc: 100.00%] [G loss: 4.513518]\n",
      "epoch:32 step:25484 [D loss: 0.213513, acc: 99.22%] [G loss: 3.878768]\n",
      "epoch:32 step:25485 [D loss: 0.078114, acc: 100.00%] [G loss: 4.341473]\n",
      "epoch:32 step:25486 [D loss: 0.952266, acc: 50.78%] [G loss: 4.075016]\n",
      "epoch:32 step:25487 [D loss: 0.367771, acc: 76.56%] [G loss: 4.748872]\n",
      "epoch:32 step:25488 [D loss: 0.515873, acc: 64.06%] [G loss: 4.310081]\n",
      "epoch:32 step:25489 [D loss: 0.146592, acc: 98.44%] [G loss: 3.670249]\n",
      "epoch:32 step:25490 [D loss: 0.130230, acc: 99.22%] [G loss: 5.109871]\n",
      "epoch:32 step:25491 [D loss: 0.634676, acc: 53.12%] [G loss: 6.687696]\n",
      "epoch:32 step:25492 [D loss: 0.941270, acc: 48.44%] [G loss: 5.713710]\n",
      "epoch:32 step:25493 [D loss: 0.557886, acc: 64.06%] [G loss: 4.465800]\n",
      "epoch:32 step:25494 [D loss: 1.318964, acc: 14.06%] [G loss: 4.878805]\n",
      "epoch:32 step:25495 [D loss: 0.147134, acc: 99.22%] [G loss: 4.781817]\n",
      "epoch:32 step:25496 [D loss: 0.473029, acc: 82.03%] [G loss: 2.507128]\n",
      "epoch:32 step:25497 [D loss: 0.493152, acc: 79.69%] [G loss: 3.358950]\n",
      "epoch:32 step:25498 [D loss: 0.312716, acc: 92.97%] [G loss: 3.469226]\n",
      "epoch:32 step:25499 [D loss: 0.386147, acc: 77.34%] [G loss: 4.184493]\n",
      "epoch:32 step:25500 [D loss: 0.349075, acc: 85.94%] [G loss: 5.504479]\n",
      "epoch:32 step:25501 [D loss: 0.379584, acc: 85.94%] [G loss: 5.254008]\n",
      "epoch:32 step:25502 [D loss: 0.054526, acc: 100.00%] [G loss: 3.977765]\n",
      "epoch:32 step:25503 [D loss: 0.107424, acc: 99.22%] [G loss: 5.575812]\n",
      "epoch:32 step:25504 [D loss: 0.517104, acc: 61.72%] [G loss: 5.677029]\n",
      "epoch:32 step:25505 [D loss: 0.750677, acc: 57.81%] [G loss: 4.514351]\n",
      "epoch:32 step:25506 [D loss: 0.101135, acc: 100.00%] [G loss: 5.348542]\n",
      "epoch:32 step:25507 [D loss: 0.116324, acc: 99.22%] [G loss: 4.087032]\n",
      "epoch:32 step:25508 [D loss: 0.255014, acc: 97.66%] [G loss: 3.695308]\n",
      "epoch:32 step:25509 [D loss: 0.200746, acc: 99.22%] [G loss: 4.905150]\n",
      "epoch:32 step:25510 [D loss: 0.352181, acc: 89.06%] [G loss: 4.717536]\n",
      "epoch:32 step:25511 [D loss: 0.266007, acc: 96.88%] [G loss: 5.319210]\n",
      "epoch:32 step:25512 [D loss: 0.375728, acc: 91.41%] [G loss: 4.726959]\n",
      "epoch:32 step:25513 [D loss: 0.504712, acc: 67.19%] [G loss: 3.868905]\n",
      "epoch:32 step:25514 [D loss: 0.641503, acc: 55.47%] [G loss: 3.921061]\n",
      "epoch:32 step:25515 [D loss: 0.974492, acc: 48.44%] [G loss: 2.691829]\n",
      "epoch:32 step:25516 [D loss: 0.258671, acc: 89.06%] [G loss: 4.462856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25517 [D loss: 0.769568, acc: 46.09%] [G loss: 3.452622]\n",
      "epoch:32 step:25518 [D loss: 0.124898, acc: 100.00%] [G loss: 3.835791]\n",
      "epoch:32 step:25519 [D loss: 0.315836, acc: 90.62%] [G loss: 3.596090]\n",
      "epoch:32 step:25520 [D loss: 0.520746, acc: 71.09%] [G loss: 6.140698]\n",
      "epoch:32 step:25521 [D loss: 0.439976, acc: 80.47%] [G loss: 5.006717]\n",
      "epoch:32 step:25522 [D loss: 0.557216, acc: 65.62%] [G loss: 6.112877]\n",
      "epoch:32 step:25523 [D loss: 0.116262, acc: 100.00%] [G loss: 5.432820]\n",
      "epoch:32 step:25524 [D loss: 0.713148, acc: 58.59%] [G loss: 6.428226]\n",
      "epoch:32 step:25525 [D loss: 0.704912, acc: 56.25%] [G loss: 3.638516]\n",
      "epoch:32 step:25526 [D loss: 1.037153, acc: 26.56%] [G loss: 3.005894]\n",
      "epoch:32 step:25527 [D loss: 0.429761, acc: 85.94%] [G loss: 3.337368]\n",
      "epoch:32 step:25528 [D loss: 0.054597, acc: 100.00%] [G loss: 4.404913]\n",
      "epoch:32 step:25529 [D loss: 0.210936, acc: 96.09%] [G loss: 4.409354]\n",
      "epoch:32 step:25530 [D loss: 0.267112, acc: 92.97%] [G loss: 4.605482]\n",
      "epoch:32 step:25531 [D loss: 0.300892, acc: 84.38%] [G loss: 3.651103]\n",
      "epoch:32 step:25532 [D loss: 0.523225, acc: 61.72%] [G loss: 2.606855]\n",
      "epoch:32 step:25533 [D loss: 0.148307, acc: 100.00%] [G loss: 4.460443]\n",
      "epoch:32 step:25534 [D loss: 0.113581, acc: 100.00%] [G loss: 5.599559]\n",
      "epoch:32 step:25535 [D loss: 0.108284, acc: 100.00%] [G loss: 3.709975]\n",
      "epoch:32 step:25536 [D loss: 0.148321, acc: 98.44%] [G loss: 2.052582]\n",
      "epoch:32 step:25537 [D loss: 0.330657, acc: 95.31%] [G loss: 6.137639]\n",
      "epoch:32 step:25538 [D loss: 1.426084, acc: 7.81%] [G loss: 4.354100]\n",
      "epoch:32 step:25539 [D loss: 0.167858, acc: 97.66%] [G loss: 3.566180]\n",
      "epoch:32 step:25540 [D loss: 0.811914, acc: 51.56%] [G loss: 2.706519]\n",
      "epoch:32 step:25541 [D loss: 0.859478, acc: 35.16%] [G loss: 5.129622]\n",
      "epoch:32 step:25542 [D loss: 0.262855, acc: 88.28%] [G loss: 2.750246]\n",
      "epoch:32 step:25543 [D loss: 0.456631, acc: 76.56%] [G loss: 4.468339]\n",
      "epoch:32 step:25544 [D loss: 1.116740, acc: 50.00%] [G loss: 2.759942]\n",
      "epoch:32 step:25545 [D loss: 0.188023, acc: 100.00%] [G loss: 3.467809]\n",
      "epoch:32 step:25546 [D loss: 0.429630, acc: 77.34%] [G loss: 4.061474]\n",
      "epoch:32 step:25547 [D loss: 0.188570, acc: 95.31%] [G loss: 8.040834]\n",
      "epoch:32 step:25548 [D loss: 0.259195, acc: 100.00%] [G loss: 2.666662]\n",
      "epoch:32 step:25549 [D loss: 0.167120, acc: 99.22%] [G loss: 3.545231]\n",
      "epoch:32 step:25550 [D loss: 0.179398, acc: 97.66%] [G loss: 4.196747]\n",
      "epoch:32 step:25551 [D loss: 0.139211, acc: 100.00%] [G loss: 4.294309]\n",
      "epoch:32 step:25552 [D loss: 0.298709, acc: 92.19%] [G loss: 6.939282]\n",
      "epoch:32 step:25553 [D loss: 0.211094, acc: 98.44%] [G loss: 3.259987]\n",
      "epoch:32 step:25554 [D loss: 0.590832, acc: 68.75%] [G loss: 4.751339]\n",
      "epoch:32 step:25555 [D loss: 1.237437, acc: 37.50%] [G loss: 4.564619]\n",
      "epoch:32 step:25556 [D loss: 0.091906, acc: 100.00%] [G loss: 4.741763]\n",
      "epoch:32 step:25557 [D loss: 0.260794, acc: 97.66%] [G loss: 3.878170]\n",
      "epoch:32 step:25558 [D loss: 0.337546, acc: 88.28%] [G loss: 3.914789]\n",
      "epoch:32 step:25559 [D loss: 0.199605, acc: 99.22%] [G loss: 6.383943]\n",
      "epoch:32 step:25560 [D loss: 0.183070, acc: 96.88%] [G loss: 5.347431]\n",
      "epoch:32 step:25561 [D loss: 0.266113, acc: 89.84%] [G loss: 5.055048]\n",
      "epoch:32 step:25562 [D loss: 0.383873, acc: 76.56%] [G loss: 3.765390]\n",
      "epoch:32 step:25563 [D loss: 0.146478, acc: 100.00%] [G loss: 5.127756]\n",
      "epoch:32 step:25564 [D loss: 0.827051, acc: 50.00%] [G loss: 3.612687]\n",
      "epoch:32 step:25565 [D loss: 0.254827, acc: 91.41%] [G loss: 3.040172]\n",
      "epoch:32 step:25566 [D loss: 0.897240, acc: 37.50%] [G loss: 3.465435]\n",
      "epoch:32 step:25567 [D loss: 0.420097, acc: 85.94%] [G loss: 3.394448]\n",
      "epoch:32 step:25568 [D loss: 0.746092, acc: 55.47%] [G loss: 2.249723]\n",
      "epoch:32 step:25569 [D loss: 0.761644, acc: 49.22%] [G loss: 4.181695]\n",
      "epoch:32 step:25570 [D loss: 0.139673, acc: 100.00%] [G loss: 5.142148]\n",
      "epoch:32 step:25571 [D loss: 0.196549, acc: 99.22%] [G loss: 4.561165]\n",
      "epoch:32 step:25572 [D loss: 0.381266, acc: 93.75%] [G loss: 7.095978]\n",
      "epoch:32 step:25573 [D loss: 0.085392, acc: 100.00%] [G loss: 4.971605]\n",
      "epoch:32 step:25574 [D loss: 0.110961, acc: 100.00%] [G loss: 3.946826]\n",
      "epoch:32 step:25575 [D loss: 0.272353, acc: 91.41%] [G loss: 4.979103]\n",
      "epoch:32 step:25576 [D loss: 0.404404, acc: 85.94%] [G loss: 3.672018]\n",
      "epoch:32 step:25577 [D loss: 0.660422, acc: 60.94%] [G loss: 6.290022]\n",
      "epoch:32 step:25578 [D loss: 0.428004, acc: 75.00%] [G loss: 3.347722]\n",
      "epoch:32 step:25579 [D loss: 0.777690, acc: 54.69%] [G loss: 5.685851]\n",
      "epoch:32 step:25580 [D loss: 0.226144, acc: 98.44%] [G loss: 4.134350]\n",
      "epoch:32 step:25581 [D loss: 0.448358, acc: 75.78%] [G loss: 4.297292]\n",
      "epoch:32 step:25582 [D loss: 0.183399, acc: 96.09%] [G loss: 3.151771]\n",
      "epoch:32 step:25583 [D loss: 0.861234, acc: 52.34%] [G loss: 3.734649]\n",
      "epoch:32 step:25584 [D loss: 0.401591, acc: 85.16%] [G loss: 4.491027]\n",
      "epoch:32 step:25585 [D loss: 0.420023, acc: 81.25%] [G loss: 3.195515]\n",
      "epoch:32 step:25586 [D loss: 0.322583, acc: 91.41%] [G loss: 4.242631]\n",
      "epoch:32 step:25587 [D loss: 0.506116, acc: 69.53%] [G loss: 4.115320]\n",
      "epoch:32 step:25588 [D loss: 0.869246, acc: 51.56%] [G loss: 4.421925]\n",
      "epoch:32 step:25589 [D loss: 0.492265, acc: 71.09%] [G loss: 3.493169]\n",
      "epoch:32 step:25590 [D loss: 0.515567, acc: 73.44%] [G loss: 2.630267]\n",
      "epoch:32 step:25591 [D loss: 0.406190, acc: 85.94%] [G loss: 2.798029]\n",
      "epoch:32 step:25592 [D loss: 0.668542, acc: 57.81%] [G loss: 3.928190]\n",
      "epoch:32 step:25593 [D loss: 0.372217, acc: 86.72%] [G loss: 1.812412]\n",
      "epoch:32 step:25594 [D loss: 0.856822, acc: 50.78%] [G loss: 4.677667]\n",
      "epoch:32 step:25595 [D loss: 2.039758, acc: 29.69%] [G loss: 1.705936]\n",
      "epoch:32 step:25596 [D loss: 2.008027, acc: 37.50%] [G loss: 4.230494]\n",
      "epoch:32 step:25597 [D loss: 0.402054, acc: 76.56%] [G loss: 5.109906]\n",
      "epoch:32 step:25598 [D loss: 0.122962, acc: 98.44%] [G loss: 6.079096]\n",
      "epoch:32 step:25599 [D loss: 0.195079, acc: 97.66%] [G loss: 5.429040]\n",
      "epoch:32 step:25600 [D loss: 0.411354, acc: 69.53%] [G loss: 5.423544]\n",
      "epoch:32 step:25601 [D loss: 0.081708, acc: 100.00%] [G loss: 4.119144]\n",
      "epoch:32 step:25602 [D loss: 0.597407, acc: 70.31%] [G loss: 4.328963]\n",
      "epoch:32 step:25603 [D loss: 1.298656, acc: 21.88%] [G loss: 3.962549]\n",
      "epoch:32 step:25604 [D loss: 0.276698, acc: 97.66%] [G loss: 1.527205]\n",
      "epoch:32 step:25605 [D loss: 0.133922, acc: 99.22%] [G loss: 3.697561]\n",
      "epoch:32 step:25606 [D loss: 0.274844, acc: 92.97%] [G loss: 3.735959]\n",
      "epoch:32 step:25607 [D loss: 0.263438, acc: 94.53%] [G loss: 3.732409]\n",
      "epoch:32 step:25608 [D loss: 0.549601, acc: 70.31%] [G loss: 5.292144]\n",
      "epoch:32 step:25609 [D loss: 0.678329, acc: 58.59%] [G loss: 3.971697]\n",
      "epoch:32 step:25610 [D loss: 0.789793, acc: 51.56%] [G loss: 2.959534]\n",
      "epoch:32 step:25611 [D loss: 0.450567, acc: 74.22%] [G loss: 4.494251]\n",
      "epoch:32 step:25612 [D loss: 0.204784, acc: 99.22%] [G loss: 3.837749]\n",
      "epoch:32 step:25613 [D loss: 0.512292, acc: 83.59%] [G loss: 2.145272]\n",
      "epoch:32 step:25614 [D loss: 0.542132, acc: 72.66%] [G loss: 3.863685]\n",
      "epoch:32 step:25615 [D loss: 0.334989, acc: 92.19%] [G loss: 3.391097]\n",
      "epoch:32 step:25616 [D loss: 1.042779, acc: 50.78%] [G loss: 4.153156]\n",
      "epoch:32 step:25617 [D loss: 1.003131, acc: 50.78%] [G loss: 5.692687]\n",
      "epoch:32 step:25618 [D loss: 0.527981, acc: 79.69%] [G loss: 4.550928]\n",
      "epoch:32 step:25619 [D loss: 0.077821, acc: 100.00%] [G loss: 5.169394]\n",
      "epoch:32 step:25620 [D loss: 0.157750, acc: 99.22%] [G loss: 5.488879]\n",
      "epoch:32 step:25621 [D loss: 0.628779, acc: 67.19%] [G loss: 4.484774]\n",
      "epoch:32 step:25622 [D loss: 0.104513, acc: 99.22%] [G loss: 6.019083]\n",
      "epoch:32 step:25623 [D loss: 0.520553, acc: 70.31%] [G loss: 4.437944]\n",
      "epoch:32 step:25624 [D loss: 0.623531, acc: 58.59%] [G loss: 4.711083]\n",
      "epoch:32 step:25625 [D loss: 0.422456, acc: 84.38%] [G loss: 4.250975]\n",
      "epoch:32 step:25626 [D loss: 0.786022, acc: 55.47%] [G loss: 3.518674]\n",
      "epoch:32 step:25627 [D loss: 0.452755, acc: 82.81%] [G loss: 3.104516]\n",
      "epoch:32 step:25628 [D loss: 0.628461, acc: 61.72%] [G loss: 3.775568]\n",
      "epoch:32 step:25629 [D loss: 0.486755, acc: 79.69%] [G loss: 2.521550]\n",
      "epoch:32 step:25630 [D loss: 0.245114, acc: 94.53%] [G loss: 4.794240]\n",
      "epoch:32 step:25631 [D loss: 0.272212, acc: 96.88%] [G loss: 4.525553]\n",
      "epoch:32 step:25632 [D loss: 0.337578, acc: 85.94%] [G loss: 4.843375]\n",
      "epoch:32 step:25633 [D loss: 0.258874, acc: 97.66%] [G loss: 3.757641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25634 [D loss: 0.148630, acc: 98.44%] [G loss: 5.086274]\n",
      "epoch:32 step:25635 [D loss: 0.491787, acc: 85.94%] [G loss: 3.107288]\n",
      "epoch:32 step:25636 [D loss: 0.438737, acc: 85.94%] [G loss: 4.763520]\n",
      "epoch:32 step:25637 [D loss: 0.992418, acc: 50.78%] [G loss: 3.527869]\n",
      "epoch:32 step:25638 [D loss: 0.490596, acc: 82.03%] [G loss: 4.520906]\n",
      "epoch:32 step:25639 [D loss: 0.400124, acc: 79.69%] [G loss: 3.044815]\n",
      "epoch:32 step:25640 [D loss: 0.159795, acc: 97.66%] [G loss: 2.776739]\n",
      "epoch:32 step:25641 [D loss: 0.508257, acc: 64.06%] [G loss: 5.626416]\n",
      "epoch:32 step:25642 [D loss: 0.336883, acc: 84.38%] [G loss: 4.339559]\n",
      "epoch:32 step:25643 [D loss: 0.179404, acc: 97.66%] [G loss: 2.584347]\n",
      "epoch:32 step:25644 [D loss: 0.655268, acc: 63.28%] [G loss: 4.075973]\n",
      "epoch:32 step:25645 [D loss: 0.227477, acc: 93.75%] [G loss: 4.454813]\n",
      "epoch:32 step:25646 [D loss: 0.193495, acc: 98.44%] [G loss: 4.048976]\n",
      "epoch:32 step:25647 [D loss: 0.092606, acc: 100.00%] [G loss: 7.073761]\n",
      "epoch:32 step:25648 [D loss: 0.776349, acc: 49.22%] [G loss: 5.648042]\n",
      "epoch:32 step:25649 [D loss: 0.610582, acc: 57.81%] [G loss: 3.992837]\n",
      "epoch:32 step:25650 [D loss: 0.728464, acc: 49.22%] [G loss: 5.779658]\n",
      "epoch:32 step:25651 [D loss: 0.544446, acc: 59.38%] [G loss: 5.923423]\n",
      "epoch:32 step:25652 [D loss: 0.431161, acc: 87.50%] [G loss: 4.252545]\n",
      "epoch:32 step:25653 [D loss: 0.302910, acc: 92.19%] [G loss: 1.756201]\n",
      "epoch:32 step:25654 [D loss: 0.566465, acc: 68.75%] [G loss: 4.828389]\n",
      "epoch:32 step:25655 [D loss: 0.347925, acc: 93.75%] [G loss: 4.360734]\n",
      "epoch:32 step:25656 [D loss: 0.356825, acc: 92.97%] [G loss: 3.321890]\n",
      "epoch:32 step:25657 [D loss: 0.498607, acc: 66.41%] [G loss: 6.354939]\n",
      "epoch:32 step:25658 [D loss: 0.112129, acc: 100.00%] [G loss: 4.548044]\n",
      "epoch:32 step:25659 [D loss: 0.154179, acc: 98.44%] [G loss: 4.403231]\n",
      "epoch:32 step:25660 [D loss: 0.288756, acc: 96.09%] [G loss: 5.587313]\n",
      "epoch:32 step:25661 [D loss: 0.735624, acc: 50.78%] [G loss: 5.778994]\n",
      "epoch:32 step:25662 [D loss: 0.173502, acc: 99.22%] [G loss: 4.655258]\n",
      "epoch:32 step:25663 [D loss: 0.227498, acc: 97.66%] [G loss: 4.184402]\n",
      "epoch:32 step:25664 [D loss: 0.766409, acc: 44.53%] [G loss: 2.300189]\n",
      "epoch:32 step:25665 [D loss: 0.745462, acc: 54.69%] [G loss: 4.206738]\n",
      "epoch:32 step:25666 [D loss: 0.083207, acc: 100.00%] [G loss: 4.581058]\n",
      "epoch:32 step:25667 [D loss: 0.506534, acc: 70.31%] [G loss: 6.166452]\n",
      "epoch:32 step:25668 [D loss: 0.539296, acc: 74.22%] [G loss: 3.889024]\n",
      "epoch:32 step:25669 [D loss: 0.146894, acc: 97.66%] [G loss: 3.429819]\n",
      "epoch:32 step:25670 [D loss: 0.222925, acc: 97.66%] [G loss: 6.138960]\n",
      "epoch:32 step:25671 [D loss: 0.224074, acc: 98.44%] [G loss: 3.567725]\n",
      "epoch:32 step:25672 [D loss: 0.037855, acc: 100.00%] [G loss: 6.285127]\n",
      "epoch:32 step:25673 [D loss: 0.278018, acc: 92.97%] [G loss: 3.912242]\n",
      "epoch:32 step:25674 [D loss: 0.675190, acc: 59.38%] [G loss: 4.980199]\n",
      "epoch:32 step:25675 [D loss: 0.172886, acc: 99.22%] [G loss: 3.291397]\n",
      "epoch:32 step:25676 [D loss: 1.686163, acc: 3.91%] [G loss: 3.532965]\n",
      "epoch:32 step:25677 [D loss: 0.427205, acc: 87.50%] [G loss: 4.335221]\n",
      "epoch:32 step:25678 [D loss: 0.733311, acc: 54.69%] [G loss: 3.992135]\n",
      "epoch:32 step:25679 [D loss: 0.552325, acc: 66.41%] [G loss: 4.378598]\n",
      "epoch:32 step:25680 [D loss: 0.741873, acc: 53.91%] [G loss: 2.658323]\n",
      "epoch:32 step:25681 [D loss: 0.716406, acc: 60.16%] [G loss: 6.314183]\n",
      "epoch:32 step:25682 [D loss: 0.324747, acc: 85.16%] [G loss: 4.702410]\n",
      "epoch:32 step:25683 [D loss: 0.293570, acc: 98.44%] [G loss: 4.331374]\n",
      "epoch:32 step:25684 [D loss: 0.872293, acc: 40.62%] [G loss: 6.162987]\n",
      "epoch:32 step:25685 [D loss: 0.470921, acc: 71.88%] [G loss: 2.709359]\n",
      "epoch:32 step:25686 [D loss: 0.127028, acc: 99.22%] [G loss: 4.547019]\n",
      "epoch:32 step:25687 [D loss: 0.207881, acc: 94.53%] [G loss: 4.290279]\n",
      "epoch:32 step:25688 [D loss: 0.587698, acc: 65.62%] [G loss: 5.177369]\n",
      "epoch:32 step:25689 [D loss: 0.346769, acc: 92.97%] [G loss: 5.736082]\n",
      "epoch:32 step:25690 [D loss: 0.336617, acc: 82.03%] [G loss: 2.886842]\n",
      "epoch:32 step:25691 [D loss: 0.087447, acc: 99.22%] [G loss: 4.703769]\n",
      "epoch:32 step:25692 [D loss: 0.771098, acc: 51.56%] [G loss: 5.434669]\n",
      "epoch:32 step:25693 [D loss: 0.162192, acc: 98.44%] [G loss: 4.501534]\n",
      "epoch:32 step:25694 [D loss: 0.205869, acc: 98.44%] [G loss: 2.999872]\n",
      "epoch:32 step:25695 [D loss: 0.632023, acc: 59.38%] [G loss: 6.517527]\n",
      "epoch:32 step:25696 [D loss: 0.711496, acc: 52.34%] [G loss: 3.295349]\n",
      "epoch:32 step:25697 [D loss: 0.105385, acc: 99.22%] [G loss: 4.271988]\n",
      "epoch:32 step:25698 [D loss: 0.179599, acc: 97.66%] [G loss: 6.042002]\n",
      "epoch:32 step:25699 [D loss: 0.535924, acc: 59.38%] [G loss: 6.205549]\n",
      "epoch:32 step:25700 [D loss: 0.769380, acc: 53.91%] [G loss: 3.546221]\n",
      "epoch:32 step:25701 [D loss: 0.809595, acc: 39.06%] [G loss: 6.316185]\n",
      "epoch:32 step:25702 [D loss: 0.583237, acc: 75.00%] [G loss: 3.646853]\n",
      "epoch:32 step:25703 [D loss: 0.193757, acc: 98.44%] [G loss: 5.794617]\n",
      "epoch:32 step:25704 [D loss: 0.293950, acc: 92.97%] [G loss: 4.329295]\n",
      "epoch:32 step:25705 [D loss: 0.143799, acc: 98.44%] [G loss: 4.973023]\n",
      "epoch:32 step:25706 [D loss: 0.297470, acc: 92.97%] [G loss: 6.561523]\n",
      "epoch:32 step:25707 [D loss: 0.270738, acc: 97.66%] [G loss: 5.579589]\n",
      "epoch:32 step:25708 [D loss: 0.152878, acc: 99.22%] [G loss: 4.375318]\n",
      "epoch:32 step:25709 [D loss: 0.310935, acc: 90.62%] [G loss: 3.449121]\n",
      "epoch:32 step:25710 [D loss: 1.371554, acc: 27.34%] [G loss: 5.309993]\n",
      "epoch:32 step:25711 [D loss: 1.266200, acc: 50.00%] [G loss: 2.663022]\n",
      "epoch:32 step:25712 [D loss: 0.388458, acc: 92.97%] [G loss: 5.315643]\n",
      "epoch:32 step:25713 [D loss: 0.127860, acc: 100.00%] [G loss: 5.870593]\n",
      "epoch:32 step:25714 [D loss: 0.862464, acc: 35.16%] [G loss: 4.526318]\n",
      "epoch:32 step:25715 [D loss: 0.246505, acc: 92.97%] [G loss: 5.177024]\n",
      "epoch:32 step:25716 [D loss: 0.200034, acc: 100.00%] [G loss: 3.607982]\n",
      "epoch:32 step:25717 [D loss: 0.491160, acc: 73.44%] [G loss: 4.338231]\n",
      "epoch:32 step:25718 [D loss: 0.220991, acc: 96.88%] [G loss: 4.129742]\n",
      "epoch:32 step:25719 [D loss: 0.237664, acc: 96.09%] [G loss: 3.561123]\n",
      "epoch:32 step:25720 [D loss: 0.207199, acc: 99.22%] [G loss: 3.901880]\n",
      "epoch:32 step:25721 [D loss: 0.257297, acc: 98.44%] [G loss: 3.991520]\n",
      "epoch:32 step:25722 [D loss: 0.619751, acc: 63.28%] [G loss: 3.805482]\n",
      "epoch:32 step:25723 [D loss: 0.195323, acc: 98.44%] [G loss: 6.447306]\n",
      "epoch:32 step:25724 [D loss: 0.195918, acc: 97.66%] [G loss: 4.334810]\n",
      "epoch:32 step:25725 [D loss: 0.381794, acc: 89.06%] [G loss: 4.933378]\n",
      "epoch:32 step:25726 [D loss: 0.199739, acc: 98.44%] [G loss: 3.430938]\n",
      "epoch:32 step:25727 [D loss: 0.050826, acc: 100.00%] [G loss: 6.392692]\n",
      "epoch:32 step:25728 [D loss: 0.157254, acc: 100.00%] [G loss: 3.843755]\n",
      "epoch:32 step:25729 [D loss: 0.504236, acc: 78.91%] [G loss: 3.762306]\n",
      "epoch:32 step:25730 [D loss: 0.367343, acc: 90.62%] [G loss: 4.905339]\n",
      "epoch:32 step:25731 [D loss: 0.490346, acc: 78.91%] [G loss: 3.154131]\n",
      "epoch:32 step:25732 [D loss: 0.306325, acc: 89.84%] [G loss: 5.174903]\n",
      "epoch:32 step:25733 [D loss: 0.702296, acc: 57.81%] [G loss: 3.596298]\n",
      "epoch:32 step:25734 [D loss: 0.599362, acc: 74.22%] [G loss: 3.701862]\n",
      "epoch:32 step:25735 [D loss: 0.610378, acc: 57.81%] [G loss: 3.970109]\n",
      "epoch:32 step:25736 [D loss: 1.465472, acc: 50.00%] [G loss: 2.362643]\n",
      "epoch:32 step:25737 [D loss: 0.160702, acc: 100.00%] [G loss: 3.616021]\n",
      "epoch:32 step:25738 [D loss: 0.302943, acc: 91.41%] [G loss: 4.116842]\n",
      "epoch:32 step:25739 [D loss: 0.143974, acc: 99.22%] [G loss: 1.874544]\n",
      "epoch:32 step:25740 [D loss: 0.268715, acc: 94.53%] [G loss: 4.116400]\n",
      "epoch:32 step:25741 [D loss: 0.669851, acc: 55.47%] [G loss: 5.146368]\n",
      "epoch:32 step:25742 [D loss: 0.362607, acc: 85.94%] [G loss: 2.728981]\n",
      "epoch:32 step:25743 [D loss: 0.700567, acc: 57.81%] [G loss: 3.801469]\n",
      "epoch:32 step:25744 [D loss: 0.283747, acc: 91.41%] [G loss: 5.807063]\n",
      "epoch:32 step:25745 [D loss: 0.471179, acc: 80.47%] [G loss: 4.397438]\n",
      "epoch:32 step:25746 [D loss: 0.273982, acc: 92.97%] [G loss: 4.388398]\n",
      "epoch:32 step:25747 [D loss: 0.153838, acc: 100.00%] [G loss: 4.073729]\n",
      "epoch:32 step:25748 [D loss: 0.129914, acc: 99.22%] [G loss: 5.372185]\n",
      "epoch:32 step:25749 [D loss: 0.265737, acc: 94.53%] [G loss: 3.489483]\n",
      "epoch:32 step:25750 [D loss: 0.382926, acc: 85.94%] [G loss: 3.528366]\n",
      "epoch:32 step:25751 [D loss: 0.628633, acc: 60.16%] [G loss: 3.232226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25752 [D loss: 0.138280, acc: 99.22%] [G loss: 5.526079]\n",
      "epoch:32 step:25753 [D loss: 0.709354, acc: 53.91%] [G loss: 4.246197]\n",
      "epoch:32 step:25754 [D loss: 0.269337, acc: 89.06%] [G loss: 5.389899]\n",
      "epoch:32 step:25755 [D loss: 0.868479, acc: 51.56%] [G loss: 2.678347]\n",
      "epoch:32 step:25756 [D loss: 0.405953, acc: 88.28%] [G loss: 2.302775]\n",
      "epoch:32 step:25757 [D loss: 1.495856, acc: 50.00%] [G loss: 2.786763]\n",
      "epoch:32 step:25758 [D loss: 0.224064, acc: 95.31%] [G loss: 4.724597]\n",
      "epoch:32 step:25759 [D loss: 0.447035, acc: 86.72%] [G loss: 3.910203]\n",
      "epoch:32 step:25760 [D loss: 0.295672, acc: 96.09%] [G loss: 5.271647]\n",
      "epoch:32 step:25761 [D loss: 0.996329, acc: 50.00%] [G loss: 4.412220]\n",
      "epoch:32 step:25762 [D loss: 0.645292, acc: 60.16%] [G loss: 4.167285]\n",
      "epoch:32 step:25763 [D loss: 0.409529, acc: 74.22%] [G loss: 5.166996]\n",
      "epoch:32 step:25764 [D loss: 0.298303, acc: 94.53%] [G loss: 3.854525]\n",
      "epoch:32 step:25765 [D loss: 0.701777, acc: 52.34%] [G loss: 6.400757]\n",
      "epoch:32 step:25766 [D loss: 0.157659, acc: 99.22%] [G loss: 4.129345]\n",
      "epoch:32 step:25767 [D loss: 0.732811, acc: 56.25%] [G loss: 4.507195]\n",
      "epoch:32 step:25768 [D loss: 0.254015, acc: 97.66%] [G loss: 4.315973]\n",
      "epoch:32 step:25769 [D loss: 0.912123, acc: 45.31%] [G loss: 3.571641]\n",
      "epoch:32 step:25770 [D loss: 0.228800, acc: 97.66%] [G loss: 2.893195]\n",
      "epoch:32 step:25771 [D loss: 0.223375, acc: 92.97%] [G loss: 5.685202]\n",
      "epoch:32 step:25772 [D loss: 0.558515, acc: 67.19%] [G loss: 2.746842]\n",
      "epoch:32 step:25773 [D loss: 0.259399, acc: 89.84%] [G loss: 3.958086]\n",
      "epoch:33 step:25774 [D loss: 0.321008, acc: 91.41%] [G loss: 3.666124]\n",
      "epoch:33 step:25775 [D loss: 0.188266, acc: 97.66%] [G loss: 5.170115]\n",
      "epoch:33 step:25776 [D loss: 0.127028, acc: 99.22%] [G loss: 1.181475]\n",
      "epoch:33 step:25777 [D loss: 0.120679, acc: 100.00%] [G loss: 3.852284]\n",
      "epoch:33 step:25778 [D loss: 0.544240, acc: 65.62%] [G loss: 5.679878]\n",
      "epoch:33 step:25779 [D loss: 0.388248, acc: 90.62%] [G loss: 4.263233]\n",
      "epoch:33 step:25780 [D loss: 0.711060, acc: 53.91%] [G loss: 4.507327]\n",
      "epoch:33 step:25781 [D loss: 0.199353, acc: 94.53%] [G loss: 5.614305]\n",
      "epoch:33 step:25782 [D loss: 0.146236, acc: 100.00%] [G loss: 3.498056]\n",
      "epoch:33 step:25783 [D loss: 0.267665, acc: 89.06%] [G loss: 3.932580]\n",
      "epoch:33 step:25784 [D loss: 0.246344, acc: 96.88%] [G loss: 4.444219]\n",
      "epoch:33 step:25785 [D loss: 0.243319, acc: 94.53%] [G loss: 2.796021]\n",
      "epoch:33 step:25786 [D loss: 0.197375, acc: 100.00%] [G loss: 4.158545]\n",
      "epoch:33 step:25787 [D loss: 0.069924, acc: 100.00%] [G loss: 4.507941]\n",
      "epoch:33 step:25788 [D loss: 0.405009, acc: 88.28%] [G loss: 1.493359]\n",
      "epoch:33 step:25789 [D loss: 0.187429, acc: 99.22%] [G loss: 2.842842]\n",
      "epoch:33 step:25790 [D loss: 0.457531, acc: 78.12%] [G loss: 2.839296]\n",
      "epoch:33 step:25791 [D loss: 1.008673, acc: 50.00%] [G loss: 3.646421]\n",
      "epoch:33 step:25792 [D loss: 0.694939, acc: 57.03%] [G loss: 3.472277]\n",
      "epoch:33 step:25793 [D loss: 0.689231, acc: 55.47%] [G loss: 6.238277]\n",
      "epoch:33 step:25794 [D loss: 0.157317, acc: 96.88%] [G loss: 2.575340]\n",
      "epoch:33 step:25795 [D loss: 0.230840, acc: 97.66%] [G loss: 4.089835]\n",
      "epoch:33 step:25796 [D loss: 0.444188, acc: 87.50%] [G loss: 3.070628]\n",
      "epoch:33 step:25797 [D loss: 1.349172, acc: 24.22%] [G loss: 5.871350]\n",
      "epoch:33 step:25798 [D loss: 1.343354, acc: 49.22%] [G loss: 3.093110]\n",
      "epoch:33 step:25799 [D loss: 0.103732, acc: 100.00%] [G loss: 3.138903]\n",
      "epoch:33 step:25800 [D loss: 0.332613, acc: 92.97%] [G loss: 4.772146]\n",
      "epoch:33 step:25801 [D loss: 0.135358, acc: 99.22%] [G loss: 5.308741]\n",
      "epoch:33 step:25802 [D loss: 0.091615, acc: 100.00%] [G loss: 5.163653]\n",
      "epoch:33 step:25803 [D loss: 0.312397, acc: 92.97%] [G loss: 5.468974]\n",
      "epoch:33 step:25804 [D loss: 0.296890, acc: 90.62%] [G loss: 5.965083]\n",
      "epoch:33 step:25805 [D loss: 0.175888, acc: 96.09%] [G loss: 3.274289]\n",
      "epoch:33 step:25806 [D loss: 0.474991, acc: 67.97%] [G loss: 6.433022]\n",
      "epoch:33 step:25807 [D loss: 0.414910, acc: 75.78%] [G loss: 2.634754]\n",
      "epoch:33 step:25808 [D loss: 0.554798, acc: 75.00%] [G loss: 4.247018]\n",
      "epoch:33 step:25809 [D loss: 0.380481, acc: 76.56%] [G loss: 5.264010]\n",
      "epoch:33 step:25810 [D loss: 0.047649, acc: 100.00%] [G loss: 4.425351]\n",
      "epoch:33 step:25811 [D loss: 0.340548, acc: 80.47%] [G loss: 6.578418]\n",
      "epoch:33 step:25812 [D loss: 0.298440, acc: 92.97%] [G loss: 4.441996]\n",
      "epoch:33 step:25813 [D loss: 0.266210, acc: 91.41%] [G loss: 2.922433]\n",
      "epoch:33 step:25814 [D loss: 0.708746, acc: 49.22%] [G loss: 4.844621]\n",
      "epoch:33 step:25815 [D loss: 0.203776, acc: 92.97%] [G loss: 5.018239]\n",
      "epoch:33 step:25816 [D loss: 0.475077, acc: 78.91%] [G loss: 3.757900]\n",
      "epoch:33 step:25817 [D loss: 0.654770, acc: 60.94%] [G loss: 4.789440]\n",
      "epoch:33 step:25818 [D loss: 0.159697, acc: 99.22%] [G loss: 6.860943]\n",
      "epoch:33 step:25819 [D loss: 0.188937, acc: 100.00%] [G loss: 3.563144]\n",
      "epoch:33 step:25820 [D loss: 0.516617, acc: 78.12%] [G loss: 2.991972]\n",
      "epoch:33 step:25821 [D loss: 1.607487, acc: 10.94%] [G loss: 3.974422]\n",
      "epoch:33 step:25822 [D loss: 0.215568, acc: 95.31%] [G loss: 2.640936]\n",
      "epoch:33 step:25823 [D loss: 0.482843, acc: 69.53%] [G loss: 3.519364]\n",
      "epoch:33 step:25824 [D loss: 0.350458, acc: 86.72%] [G loss: 2.560480]\n",
      "epoch:33 step:25825 [D loss: 0.322924, acc: 93.75%] [G loss: 3.297432]\n",
      "epoch:33 step:25826 [D loss: 0.475145, acc: 73.44%] [G loss: 3.994174]\n",
      "epoch:33 step:25827 [D loss: 0.620918, acc: 70.31%] [G loss: 4.111983]\n",
      "epoch:33 step:25828 [D loss: 0.759596, acc: 52.34%] [G loss: 4.800055]\n",
      "epoch:33 step:25829 [D loss: 0.275820, acc: 93.75%] [G loss: 3.342687]\n",
      "epoch:33 step:25830 [D loss: 0.638138, acc: 60.16%] [G loss: 4.018023]\n",
      "epoch:33 step:25831 [D loss: 0.480253, acc: 74.22%] [G loss: 2.756211]\n",
      "epoch:33 step:25832 [D loss: 0.359051, acc: 82.81%] [G loss: 3.921412]\n",
      "epoch:33 step:25833 [D loss: 0.432979, acc: 80.47%] [G loss: 2.616255]\n",
      "epoch:33 step:25834 [D loss: 0.533925, acc: 75.78%] [G loss: 3.789259]\n",
      "epoch:33 step:25835 [D loss: 0.086333, acc: 99.22%] [G loss: 4.963334]\n",
      "epoch:33 step:25836 [D loss: 0.230610, acc: 92.19%] [G loss: 4.878513]\n",
      "epoch:33 step:25837 [D loss: 0.439193, acc: 84.38%] [G loss: 4.453906]\n",
      "epoch:33 step:25838 [D loss: 0.226723, acc: 96.09%] [G loss: 3.879924]\n",
      "epoch:33 step:25839 [D loss: 0.529041, acc: 67.19%] [G loss: 3.302610]\n",
      "epoch:33 step:25840 [D loss: 0.665409, acc: 53.12%] [G loss: 3.038900]\n",
      "epoch:33 step:25841 [D loss: 0.172361, acc: 96.09%] [G loss: 2.253060]\n",
      "epoch:33 step:25842 [D loss: 0.355803, acc: 81.25%] [G loss: 5.131239]\n",
      "epoch:33 step:25843 [D loss: 1.677211, acc: 4.69%] [G loss: 5.065099]\n",
      "epoch:33 step:25844 [D loss: 0.547995, acc: 71.09%] [G loss: 2.745436]\n",
      "epoch:33 step:25845 [D loss: 0.141573, acc: 98.44%] [G loss: 3.559181]\n",
      "epoch:33 step:25846 [D loss: 0.797957, acc: 47.66%] [G loss: 3.452096]\n",
      "epoch:33 step:25847 [D loss: 0.415662, acc: 85.94%] [G loss: 3.354935]\n",
      "epoch:33 step:25848 [D loss: 0.140846, acc: 99.22%] [G loss: 5.811147]\n",
      "epoch:33 step:25849 [D loss: 0.114110, acc: 100.00%] [G loss: 3.426575]\n",
      "epoch:33 step:25850 [D loss: 0.739238, acc: 57.03%] [G loss: 2.492663]\n",
      "epoch:33 step:25851 [D loss: 0.309804, acc: 93.75%] [G loss: 3.316970]\n",
      "epoch:33 step:25852 [D loss: 1.076036, acc: 35.16%] [G loss: 4.407325]\n",
      "epoch:33 step:25853 [D loss: 0.371691, acc: 88.28%] [G loss: 1.562672]\n",
      "epoch:33 step:25854 [D loss: 0.978884, acc: 48.44%] [G loss: 3.794417]\n",
      "epoch:33 step:25855 [D loss: 2.153749, acc: 8.59%] [G loss: 2.866775]\n",
      "epoch:33 step:25856 [D loss: 0.641160, acc: 56.25%] [G loss: 5.792070]\n",
      "epoch:33 step:25857 [D loss: 1.112960, acc: 49.22%] [G loss: 6.166658]\n",
      "epoch:33 step:25858 [D loss: 0.764343, acc: 50.78%] [G loss: 4.353182]\n",
      "epoch:33 step:25859 [D loss: 0.676962, acc: 59.38%] [G loss: 5.372690]\n",
      "epoch:33 step:25860 [D loss: 0.303741, acc: 90.62%] [G loss: 3.246644]\n",
      "epoch:33 step:25861 [D loss: 0.107544, acc: 100.00%] [G loss: 3.622835]\n",
      "epoch:33 step:25862 [D loss: 0.562981, acc: 60.94%] [G loss: 4.377195]\n",
      "epoch:33 step:25863 [D loss: 0.298319, acc: 92.19%] [G loss: 2.772907]\n",
      "epoch:33 step:25864 [D loss: 0.172724, acc: 100.00%] [G loss: 3.505800]\n",
      "epoch:33 step:25865 [D loss: 0.062162, acc: 100.00%] [G loss: 4.423712]\n",
      "epoch:33 step:25866 [D loss: 0.476372, acc: 82.03%] [G loss: 5.938949]\n",
      "epoch:33 step:25867 [D loss: 0.133395, acc: 99.22%] [G loss: 3.085558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25868 [D loss: 0.687253, acc: 58.59%] [G loss: 4.900984]\n",
      "epoch:33 step:25869 [D loss: 0.325028, acc: 89.06%] [G loss: 4.443369]\n",
      "epoch:33 step:25870 [D loss: 0.074400, acc: 100.00%] [G loss: 4.512410]\n",
      "epoch:33 step:25871 [D loss: 0.876084, acc: 50.78%] [G loss: 1.576220]\n",
      "epoch:33 step:25872 [D loss: 0.404330, acc: 75.78%] [G loss: 4.840189]\n",
      "epoch:33 step:25873 [D loss: 0.460493, acc: 67.19%] [G loss: 4.157314]\n",
      "epoch:33 step:25874 [D loss: 1.301138, acc: 50.00%] [G loss: 3.051517]\n",
      "epoch:33 step:25875 [D loss: 0.530969, acc: 64.06%] [G loss: 5.739364]\n",
      "epoch:33 step:25876 [D loss: 0.147253, acc: 98.44%] [G loss: 2.510803]\n",
      "epoch:33 step:25877 [D loss: 0.322289, acc: 86.72%] [G loss: 2.782331]\n",
      "epoch:33 step:25878 [D loss: 0.252501, acc: 98.44%] [G loss: 3.736501]\n",
      "epoch:33 step:25879 [D loss: 0.536066, acc: 65.62%] [G loss: 4.375715]\n",
      "epoch:33 step:25880 [D loss: 0.952566, acc: 39.06%] [G loss: 3.181604]\n",
      "epoch:33 step:25881 [D loss: 0.218150, acc: 96.09%] [G loss: 3.155164]\n",
      "epoch:33 step:25882 [D loss: 0.181764, acc: 98.44%] [G loss: 3.206745]\n",
      "epoch:33 step:25883 [D loss: 0.867694, acc: 48.44%] [G loss: 3.717321]\n",
      "epoch:33 step:25884 [D loss: 0.380506, acc: 84.38%] [G loss: 5.524769]\n",
      "epoch:33 step:25885 [D loss: 0.113220, acc: 100.00%] [G loss: 3.686341]\n",
      "epoch:33 step:25886 [D loss: 0.301654, acc: 92.97%] [G loss: 6.956362]\n",
      "epoch:33 step:25887 [D loss: 0.502448, acc: 60.16%] [G loss: 4.698733]\n",
      "epoch:33 step:25888 [D loss: 0.600333, acc: 60.16%] [G loss: 6.980083]\n",
      "epoch:33 step:25889 [D loss: 0.162189, acc: 99.22%] [G loss: 4.268710]\n",
      "epoch:33 step:25890 [D loss: 0.272100, acc: 91.41%] [G loss: 3.994151]\n",
      "epoch:33 step:25891 [D loss: 0.309410, acc: 89.84%] [G loss: 4.359489]\n",
      "epoch:33 step:25892 [D loss: 0.176253, acc: 100.00%] [G loss: 6.029455]\n",
      "epoch:33 step:25893 [D loss: 0.438986, acc: 85.94%] [G loss: 4.985736]\n",
      "epoch:33 step:25894 [D loss: 0.336034, acc: 81.25%] [G loss: 4.115432]\n",
      "epoch:33 step:25895 [D loss: 0.142893, acc: 98.44%] [G loss: 4.025970]\n",
      "epoch:33 step:25896 [D loss: 0.148364, acc: 98.44%] [G loss: 4.329840]\n",
      "epoch:33 step:25897 [D loss: 0.189087, acc: 96.88%] [G loss: 4.872087]\n",
      "epoch:33 step:25898 [D loss: 0.791499, acc: 45.31%] [G loss: 3.179880]\n",
      "epoch:33 step:25899 [D loss: 0.129377, acc: 98.44%] [G loss: 5.012308]\n",
      "epoch:33 step:25900 [D loss: 0.350003, acc: 92.19%] [G loss: 5.675730]\n",
      "epoch:33 step:25901 [D loss: 0.293680, acc: 92.19%] [G loss: 4.191730]\n",
      "epoch:33 step:25902 [D loss: 0.734034, acc: 56.25%] [G loss: 3.337169]\n",
      "epoch:33 step:25903 [D loss: 0.291505, acc: 92.97%] [G loss: 3.119248]\n",
      "epoch:33 step:25904 [D loss: 0.106393, acc: 99.22%] [G loss: 4.048781]\n",
      "epoch:33 step:25905 [D loss: 0.749180, acc: 53.12%] [G loss: 4.276525]\n",
      "epoch:33 step:25906 [D loss: 0.581151, acc: 70.31%] [G loss: 3.590305]\n",
      "epoch:33 step:25907 [D loss: 0.227183, acc: 96.88%] [G loss: 5.516004]\n",
      "epoch:33 step:25908 [D loss: 0.088403, acc: 100.00%] [G loss: 3.756023]\n",
      "epoch:33 step:25909 [D loss: 0.564737, acc: 64.06%] [G loss: 3.970895]\n",
      "epoch:33 step:25910 [D loss: 0.221545, acc: 96.09%] [G loss: 3.849383]\n",
      "epoch:33 step:25911 [D loss: 0.925763, acc: 37.50%] [G loss: 4.332781]\n",
      "epoch:33 step:25912 [D loss: 0.419031, acc: 79.69%] [G loss: 4.123289]\n",
      "epoch:33 step:25913 [D loss: 0.448057, acc: 86.72%] [G loss: 4.473334]\n",
      "epoch:33 step:25914 [D loss: 0.332120, acc: 92.97%] [G loss: 4.573492]\n",
      "epoch:33 step:25915 [D loss: 0.419288, acc: 78.91%] [G loss: 5.260201]\n",
      "epoch:33 step:25916 [D loss: 0.467949, acc: 71.88%] [G loss: 3.542722]\n",
      "epoch:33 step:25917 [D loss: 0.294789, acc: 92.97%] [G loss: 1.798815]\n",
      "epoch:33 step:25918 [D loss: 0.184942, acc: 96.88%] [G loss: 2.356511]\n",
      "epoch:33 step:25919 [D loss: 0.341842, acc: 92.19%] [G loss: 3.893869]\n",
      "epoch:33 step:25920 [D loss: 0.173072, acc: 97.66%] [G loss: 3.895036]\n",
      "epoch:33 step:25921 [D loss: 0.472987, acc: 83.59%] [G loss: 4.923999]\n",
      "epoch:33 step:25922 [D loss: 0.818941, acc: 48.44%] [G loss: 5.682736]\n",
      "epoch:33 step:25923 [D loss: 0.561878, acc: 69.53%] [G loss: 3.204440]\n",
      "epoch:33 step:25924 [D loss: 0.841126, acc: 46.09%] [G loss: 4.443925]\n",
      "epoch:33 step:25925 [D loss: 1.772520, acc: 50.00%] [G loss: 3.875785]\n",
      "epoch:33 step:25926 [D loss: 0.885500, acc: 35.16%] [G loss: 3.349952]\n",
      "epoch:33 step:25927 [D loss: 0.076928, acc: 100.00%] [G loss: 3.729509]\n",
      "epoch:33 step:25928 [D loss: 0.539438, acc: 68.75%] [G loss: 3.520523]\n",
      "epoch:33 step:25929 [D loss: 0.551201, acc: 76.56%] [G loss: 4.487236]\n",
      "epoch:33 step:25930 [D loss: 0.641879, acc: 57.81%] [G loss: 5.422588]\n",
      "epoch:33 step:25931 [D loss: 0.239748, acc: 93.75%] [G loss: 3.464790]\n",
      "epoch:33 step:25932 [D loss: 0.497571, acc: 71.09%] [G loss: 3.612749]\n",
      "epoch:33 step:25933 [D loss: 0.786112, acc: 54.69%] [G loss: 3.996336]\n",
      "epoch:33 step:25934 [D loss: 0.227136, acc: 94.53%] [G loss: 6.659444]\n",
      "epoch:33 step:25935 [D loss: 0.122327, acc: 100.00%] [G loss: 3.763392]\n",
      "epoch:33 step:25936 [D loss: 0.464820, acc: 87.50%] [G loss: 3.073139]\n",
      "epoch:33 step:25937 [D loss: 0.569804, acc: 65.62%] [G loss: 3.789977]\n",
      "epoch:33 step:25938 [D loss: 1.004452, acc: 43.75%] [G loss: 4.626476]\n",
      "epoch:33 step:25939 [D loss: 0.312789, acc: 93.75%] [G loss: 2.847625]\n",
      "epoch:33 step:25940 [D loss: 0.150534, acc: 99.22%] [G loss: 3.298712]\n",
      "epoch:33 step:25941 [D loss: 0.257999, acc: 97.66%] [G loss: 3.463277]\n",
      "epoch:33 step:25942 [D loss: 0.228135, acc: 95.31%] [G loss: 2.693035]\n",
      "epoch:33 step:25943 [D loss: 0.161012, acc: 100.00%] [G loss: 3.938948]\n",
      "epoch:33 step:25944 [D loss: 0.326657, acc: 89.84%] [G loss: 3.146129]\n",
      "epoch:33 step:25945 [D loss: 0.462170, acc: 89.06%] [G loss: 3.681187]\n",
      "epoch:33 step:25946 [D loss: 1.006087, acc: 38.28%] [G loss: 4.604732]\n",
      "epoch:33 step:25947 [D loss: 0.102085, acc: 100.00%] [G loss: 4.682552]\n",
      "epoch:33 step:25948 [D loss: 0.481631, acc: 68.75%] [G loss: 4.801779]\n",
      "epoch:33 step:25949 [D loss: 0.673023, acc: 58.59%] [G loss: 4.551799]\n",
      "epoch:33 step:25950 [D loss: 0.401615, acc: 89.84%] [G loss: 3.887031]\n",
      "epoch:33 step:25951 [D loss: 0.241324, acc: 96.88%] [G loss: 3.557508]\n",
      "epoch:33 step:25952 [D loss: 0.232006, acc: 96.88%] [G loss: 5.306318]\n",
      "epoch:33 step:25953 [D loss: 0.293315, acc: 89.84%] [G loss: 2.110478]\n",
      "epoch:33 step:25954 [D loss: 0.500961, acc: 70.31%] [G loss: 5.913197]\n",
      "epoch:33 step:25955 [D loss: 0.842005, acc: 53.12%] [G loss: 4.083719]\n",
      "epoch:33 step:25956 [D loss: 0.174295, acc: 100.00%] [G loss: 5.636818]\n",
      "epoch:33 step:25957 [D loss: 0.872405, acc: 51.56%] [G loss: 4.282667]\n",
      "epoch:33 step:25958 [D loss: 0.139878, acc: 97.66%] [G loss: 3.434554]\n",
      "epoch:33 step:25959 [D loss: 0.792961, acc: 45.31%] [G loss: 2.382496]\n",
      "epoch:33 step:25960 [D loss: 0.465778, acc: 83.59%] [G loss: 4.735157]\n",
      "epoch:33 step:25961 [D loss: 0.505198, acc: 81.25%] [G loss: 3.492795]\n",
      "epoch:33 step:25962 [D loss: 0.017911, acc: 100.00%] [G loss: 8.021224]\n",
      "epoch:33 step:25963 [D loss: 0.561647, acc: 76.56%] [G loss: 3.204943]\n",
      "epoch:33 step:25964 [D loss: 0.789953, acc: 54.69%] [G loss: 6.334148]\n",
      "epoch:33 step:25965 [D loss: 0.906687, acc: 51.56%] [G loss: 3.398921]\n",
      "epoch:33 step:25966 [D loss: 0.117698, acc: 100.00%] [G loss: 5.941238]\n",
      "epoch:33 step:25967 [D loss: 0.255238, acc: 92.97%] [G loss: 6.709787]\n",
      "epoch:33 step:25968 [D loss: 0.444438, acc: 78.12%] [G loss: 3.213639]\n",
      "epoch:33 step:25969 [D loss: 0.111143, acc: 99.22%] [G loss: 5.279109]\n",
      "epoch:33 step:25970 [D loss: 0.371332, acc: 75.78%] [G loss: 4.277427]\n",
      "epoch:33 step:25971 [D loss: 0.044872, acc: 100.00%] [G loss: 5.444242]\n",
      "epoch:33 step:25972 [D loss: 0.175235, acc: 98.44%] [G loss: 5.017715]\n",
      "epoch:33 step:25973 [D loss: 0.170593, acc: 100.00%] [G loss: 4.203353]\n",
      "epoch:33 step:25974 [D loss: 0.155051, acc: 99.22%] [G loss: 4.393539]\n",
      "epoch:33 step:25975 [D loss: 0.338809, acc: 91.41%] [G loss: 3.229360]\n",
      "epoch:33 step:25976 [D loss: 1.290027, acc: 7.81%] [G loss: 6.306788]\n",
      "epoch:33 step:25977 [D loss: 0.165748, acc: 98.44%] [G loss: 2.185593]\n",
      "epoch:33 step:25978 [D loss: 0.333805, acc: 85.94%] [G loss: 3.661664]\n",
      "epoch:33 step:25979 [D loss: 0.399968, acc: 77.34%] [G loss: 4.848905]\n",
      "epoch:33 step:25980 [D loss: 0.902707, acc: 50.78%] [G loss: 6.295581]\n",
      "epoch:33 step:25981 [D loss: 0.150739, acc: 98.44%] [G loss: 3.824458]\n",
      "epoch:33 step:25982 [D loss: 1.006330, acc: 48.44%] [G loss: 4.362513]\n",
      "epoch:33 step:25983 [D loss: 0.579358, acc: 71.88%] [G loss: 3.078959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25984 [D loss: 0.488915, acc: 68.75%] [G loss: 1.896191]\n",
      "epoch:33 step:25985 [D loss: 0.128472, acc: 99.22%] [G loss: 5.094064]\n",
      "epoch:33 step:25986 [D loss: 1.147235, acc: 32.81%] [G loss: 3.856379]\n",
      "epoch:33 step:25987 [D loss: 0.414068, acc: 90.62%] [G loss: 3.355905]\n",
      "epoch:33 step:25988 [D loss: 0.555872, acc: 60.16%] [G loss: 3.928391]\n",
      "epoch:33 step:25989 [D loss: 0.543810, acc: 71.88%] [G loss: 2.744459]\n",
      "epoch:33 step:25990 [D loss: 0.062299, acc: 100.00%] [G loss: 4.262501]\n",
      "epoch:33 step:25991 [D loss: 0.348135, acc: 88.28%] [G loss: 5.656823]\n",
      "epoch:33 step:25992 [D loss: 0.202320, acc: 96.88%] [G loss: 3.839827]\n",
      "epoch:33 step:25993 [D loss: 0.268182, acc: 92.97%] [G loss: 5.126431]\n",
      "epoch:33 step:25994 [D loss: 0.176354, acc: 99.22%] [G loss: 4.941319]\n",
      "epoch:33 step:25995 [D loss: 0.317855, acc: 87.50%] [G loss: 5.472001]\n",
      "epoch:33 step:25996 [D loss: 0.201440, acc: 96.09%] [G loss: 5.285059]\n",
      "epoch:33 step:25997 [D loss: 0.123478, acc: 98.44%] [G loss: 3.890450]\n",
      "epoch:33 step:25998 [D loss: 0.474995, acc: 80.47%] [G loss: 4.475080]\n",
      "epoch:33 step:25999 [D loss: 0.107020, acc: 99.22%] [G loss: 4.966428]\n",
      "epoch:33 step:26000 [D loss: 0.276673, acc: 92.97%] [G loss: 6.890225]\n",
      "epoch:33 step:26001 [D loss: 0.210022, acc: 98.44%] [G loss: 5.149634]\n",
      "epoch:33 step:26002 [D loss: 0.043626, acc: 100.00%] [G loss: 4.629423]\n",
      "epoch:33 step:26003 [D loss: 0.832027, acc: 52.34%] [G loss: 5.183189]\n",
      "epoch:33 step:26004 [D loss: 0.444272, acc: 78.91%] [G loss: 2.649818]\n",
      "epoch:33 step:26005 [D loss: 0.386270, acc: 85.94%] [G loss: 4.370481]\n",
      "epoch:33 step:26006 [D loss: 0.193622, acc: 98.44%] [G loss: 3.806323]\n",
      "epoch:33 step:26007 [D loss: 0.267856, acc: 91.41%] [G loss: 4.996820]\n",
      "epoch:33 step:26008 [D loss: 0.282516, acc: 95.31%] [G loss: 4.916763]\n",
      "epoch:33 step:26009 [D loss: 0.542480, acc: 77.34%] [G loss: 4.543685]\n",
      "epoch:33 step:26010 [D loss: 0.407884, acc: 78.91%] [G loss: 4.888111]\n",
      "epoch:33 step:26011 [D loss: 0.462633, acc: 80.47%] [G loss: 5.136172]\n",
      "epoch:33 step:26012 [D loss: 0.207292, acc: 98.44%] [G loss: 3.658616]\n",
      "epoch:33 step:26013 [D loss: 0.676399, acc: 58.59%] [G loss: 3.947852]\n",
      "epoch:33 step:26014 [D loss: 0.276761, acc: 96.09%] [G loss: 3.638932]\n",
      "epoch:33 step:26015 [D loss: 0.237549, acc: 92.19%] [G loss: 3.742946]\n",
      "epoch:33 step:26016 [D loss: 0.135977, acc: 99.22%] [G loss: 5.806561]\n",
      "epoch:33 step:26017 [D loss: 0.860316, acc: 51.56%] [G loss: 3.996046]\n",
      "epoch:33 step:26018 [D loss: 0.148529, acc: 99.22%] [G loss: 2.102905]\n",
      "epoch:33 step:26019 [D loss: 0.169852, acc: 96.09%] [G loss: 6.638181]\n",
      "epoch:33 step:26020 [D loss: 1.133267, acc: 16.41%] [G loss: 6.644035]\n",
      "epoch:33 step:26021 [D loss: 0.710086, acc: 61.72%] [G loss: 2.962433]\n",
      "epoch:33 step:26022 [D loss: 0.129178, acc: 99.22%] [G loss: 6.739050]\n",
      "epoch:33 step:26023 [D loss: 0.266257, acc: 95.31%] [G loss: 4.083394]\n",
      "epoch:33 step:26024 [D loss: 0.050809, acc: 99.22%] [G loss: 5.970672]\n",
      "epoch:33 step:26025 [D loss: 0.882380, acc: 53.91%] [G loss: 4.263000]\n",
      "epoch:33 step:26026 [D loss: 1.175938, acc: 28.12%] [G loss: 4.701344]\n",
      "epoch:33 step:26027 [D loss: 0.820392, acc: 49.22%] [G loss: 6.039040]\n",
      "epoch:33 step:26028 [D loss: 0.256500, acc: 96.88%] [G loss: 3.947877]\n",
      "epoch:33 step:26029 [D loss: 0.095225, acc: 100.00%] [G loss: 3.985379]\n",
      "epoch:33 step:26030 [D loss: 0.307466, acc: 84.38%] [G loss: 2.933179]\n",
      "epoch:33 step:26031 [D loss: 0.128168, acc: 100.00%] [G loss: 5.137056]\n",
      "epoch:33 step:26032 [D loss: 0.241070, acc: 97.66%] [G loss: 3.366445]\n",
      "epoch:33 step:26033 [D loss: 0.201661, acc: 99.22%] [G loss: 4.232673]\n",
      "epoch:33 step:26034 [D loss: 0.382975, acc: 89.06%] [G loss: 3.617969]\n",
      "epoch:33 step:26035 [D loss: 0.779460, acc: 53.91%] [G loss: 5.019391]\n",
      "epoch:33 step:26036 [D loss: 1.348207, acc: 47.66%] [G loss: 4.944099]\n",
      "epoch:33 step:26037 [D loss: 0.241572, acc: 94.53%] [G loss: 1.096197]\n",
      "epoch:33 step:26038 [D loss: 0.412687, acc: 89.06%] [G loss: 3.721035]\n",
      "epoch:33 step:26039 [D loss: 0.188693, acc: 96.09%] [G loss: 5.656617]\n",
      "epoch:33 step:26040 [D loss: 2.204687, acc: 0.00%] [G loss: 2.605082]\n",
      "epoch:33 step:26041 [D loss: 0.891752, acc: 43.75%] [G loss: 5.404522]\n",
      "epoch:33 step:26042 [D loss: 0.247366, acc: 98.44%] [G loss: 3.203853]\n",
      "epoch:33 step:26043 [D loss: 0.397174, acc: 79.69%] [G loss: 3.769281]\n",
      "epoch:33 step:26044 [D loss: 0.356917, acc: 89.06%] [G loss: 4.072968]\n",
      "epoch:33 step:26045 [D loss: 0.248765, acc: 97.66%] [G loss: 4.328895]\n",
      "epoch:33 step:26046 [D loss: 0.466265, acc: 82.03%] [G loss: 3.785049]\n",
      "epoch:33 step:26047 [D loss: 0.243892, acc: 97.66%] [G loss: 3.397017]\n",
      "epoch:33 step:26048 [D loss: 0.693840, acc: 60.16%] [G loss: 4.808615]\n",
      "epoch:33 step:26049 [D loss: 0.672383, acc: 55.47%] [G loss: 4.839465]\n",
      "epoch:33 step:26050 [D loss: 0.079846, acc: 99.22%] [G loss: 4.411687]\n",
      "epoch:33 step:26051 [D loss: 0.934850, acc: 47.66%] [G loss: 3.908575]\n",
      "epoch:33 step:26052 [D loss: 0.441059, acc: 75.00%] [G loss: 3.288746]\n",
      "epoch:33 step:26053 [D loss: 0.323723, acc: 85.94%] [G loss: 3.362499]\n",
      "epoch:33 step:26054 [D loss: 0.470208, acc: 68.75%] [G loss: 4.114767]\n",
      "epoch:33 step:26055 [D loss: 0.191210, acc: 96.88%] [G loss: 3.116288]\n",
      "epoch:33 step:26056 [D loss: 0.583161, acc: 70.31%] [G loss: 2.731020]\n",
      "epoch:33 step:26057 [D loss: 0.069529, acc: 100.00%] [G loss: 5.258477]\n",
      "epoch:33 step:26058 [D loss: 0.398357, acc: 72.66%] [G loss: 6.725156]\n",
      "epoch:33 step:26059 [D loss: 0.550902, acc: 71.09%] [G loss: 2.365716]\n",
      "epoch:33 step:26060 [D loss: 0.135495, acc: 100.00%] [G loss: 3.808282]\n",
      "epoch:33 step:26061 [D loss: 0.629471, acc: 67.97%] [G loss: 3.405406]\n",
      "epoch:33 step:26062 [D loss: 0.351047, acc: 87.50%] [G loss: 6.325653]\n",
      "epoch:33 step:26063 [D loss: 0.850038, acc: 50.78%] [G loss: 3.235803]\n",
      "epoch:33 step:26064 [D loss: 0.834267, acc: 48.44%] [G loss: 4.630653]\n",
      "epoch:33 step:26065 [D loss: 0.187478, acc: 98.44%] [G loss: 3.490937]\n",
      "epoch:33 step:26066 [D loss: 0.344328, acc: 83.59%] [G loss: 3.329203]\n",
      "epoch:33 step:26067 [D loss: 0.150970, acc: 99.22%] [G loss: 4.580565]\n",
      "epoch:33 step:26068 [D loss: 1.204739, acc: 39.84%] [G loss: 3.725458]\n",
      "epoch:33 step:26069 [D loss: 0.205403, acc: 96.09%] [G loss: 4.903049]\n",
      "epoch:33 step:26070 [D loss: 0.083528, acc: 100.00%] [G loss: 4.126454]\n",
      "epoch:33 step:26071 [D loss: 0.101711, acc: 100.00%] [G loss: 3.601273]\n",
      "epoch:33 step:26072 [D loss: 0.064760, acc: 100.00%] [G loss: 4.466733]\n",
      "epoch:33 step:26073 [D loss: 0.345054, acc: 82.81%] [G loss: 2.617734]\n",
      "epoch:33 step:26074 [D loss: 0.177970, acc: 97.66%] [G loss: 2.973217]\n",
      "epoch:33 step:26075 [D loss: 0.306313, acc: 95.31%] [G loss: 6.805490]\n",
      "epoch:33 step:26076 [D loss: 0.331952, acc: 87.50%] [G loss: 3.658842]\n",
      "epoch:33 step:26077 [D loss: 0.145331, acc: 98.44%] [G loss: 3.821457]\n",
      "epoch:33 step:26078 [D loss: 0.490735, acc: 75.00%] [G loss: 5.051919]\n",
      "epoch:33 step:26079 [D loss: 0.185875, acc: 98.44%] [G loss: 6.205311]\n",
      "epoch:33 step:26080 [D loss: 0.583164, acc: 69.53%] [G loss: 5.511704]\n",
      "epoch:33 step:26081 [D loss: 0.498672, acc: 66.41%] [G loss: 4.129977]\n",
      "epoch:33 step:26082 [D loss: 0.353325, acc: 91.41%] [G loss: 4.253673]\n",
      "epoch:33 step:26083 [D loss: 0.761853, acc: 56.25%] [G loss: 4.581075]\n",
      "epoch:33 step:26084 [D loss: 0.357099, acc: 86.72%] [G loss: 3.653050]\n",
      "epoch:33 step:26085 [D loss: 0.307495, acc: 96.88%] [G loss: 3.580841]\n",
      "epoch:33 step:26086 [D loss: 0.285157, acc: 95.31%] [G loss: 2.543311]\n",
      "epoch:33 step:26087 [D loss: 0.313233, acc: 97.66%] [G loss: 3.560838]\n",
      "epoch:33 step:26088 [D loss: 0.300102, acc: 92.97%] [G loss: 6.029035]\n",
      "epoch:33 step:26089 [D loss: 0.199200, acc: 98.44%] [G loss: 4.108154]\n",
      "epoch:33 step:26090 [D loss: 0.386486, acc: 85.16%] [G loss: 4.132696]\n",
      "epoch:33 step:26091 [D loss: 0.162710, acc: 100.00%] [G loss: 3.008356]\n",
      "epoch:33 step:26092 [D loss: 0.124791, acc: 100.00%] [G loss: 5.047260]\n",
      "epoch:33 step:26093 [D loss: 0.714225, acc: 56.25%] [G loss: 2.709595]\n",
      "epoch:33 step:26094 [D loss: 0.298145, acc: 92.19%] [G loss: 4.375811]\n",
      "epoch:33 step:26095 [D loss: 0.403779, acc: 82.03%] [G loss: 4.388120]\n",
      "epoch:33 step:26096 [D loss: 0.229598, acc: 94.53%] [G loss: 3.883483]\n",
      "epoch:33 step:26097 [D loss: 0.652909, acc: 62.50%] [G loss: 2.663960]\n",
      "epoch:33 step:26098 [D loss: 0.435186, acc: 86.72%] [G loss: 3.265456]\n",
      "epoch:33 step:26099 [D loss: 0.410820, acc: 81.25%] [G loss: 3.491595]\n",
      "epoch:33 step:26100 [D loss: 0.267356, acc: 96.88%] [G loss: 5.017485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26101 [D loss: 0.175336, acc: 96.88%] [G loss: 4.373185]\n",
      "epoch:33 step:26102 [D loss: 0.193733, acc: 99.22%] [G loss: 5.926466]\n",
      "epoch:33 step:26103 [D loss: 0.504797, acc: 72.66%] [G loss: 3.901692]\n",
      "epoch:33 step:26104 [D loss: 0.318778, acc: 91.41%] [G loss: 5.002063]\n",
      "epoch:33 step:26105 [D loss: 0.510435, acc: 64.84%] [G loss: 3.773316]\n",
      "epoch:33 step:26106 [D loss: 0.203628, acc: 95.31%] [G loss: 5.631461]\n",
      "epoch:33 step:26107 [D loss: 0.228748, acc: 96.88%] [G loss: 5.537464]\n",
      "epoch:33 step:26108 [D loss: 0.387285, acc: 79.69%] [G loss: 5.230628]\n",
      "epoch:33 step:26109 [D loss: 0.094466, acc: 100.00%] [G loss: 3.375391]\n",
      "epoch:33 step:26110 [D loss: 0.438420, acc: 71.88%] [G loss: 4.226407]\n",
      "epoch:33 step:26111 [D loss: 1.397847, acc: 37.50%] [G loss: 3.529041]\n",
      "epoch:33 step:26112 [D loss: 0.142095, acc: 100.00%] [G loss: 6.910744]\n",
      "epoch:33 step:26113 [D loss: 0.668032, acc: 60.16%] [G loss: 4.694036]\n",
      "epoch:33 step:26114 [D loss: 0.070730, acc: 100.00%] [G loss: 5.412035]\n",
      "epoch:33 step:26115 [D loss: 0.250260, acc: 95.31%] [G loss: 3.448234]\n",
      "epoch:33 step:26116 [D loss: 0.317199, acc: 88.28%] [G loss: 4.058653]\n",
      "epoch:33 step:26117 [D loss: 1.147280, acc: 46.09%] [G loss: 3.798078]\n",
      "epoch:33 step:26118 [D loss: 0.034406, acc: 100.00%] [G loss: 3.484207]\n",
      "epoch:33 step:26119 [D loss: 0.376416, acc: 90.62%] [G loss: 3.431075]\n",
      "epoch:33 step:26120 [D loss: 0.468652, acc: 80.47%] [G loss: 1.921679]\n",
      "epoch:33 step:26121 [D loss: 0.579105, acc: 66.41%] [G loss: 3.874094]\n",
      "epoch:33 step:26122 [D loss: 0.488478, acc: 67.19%] [G loss: 3.071640]\n",
      "epoch:33 step:26123 [D loss: 0.327481, acc: 89.06%] [G loss: 5.314008]\n",
      "epoch:33 step:26124 [D loss: 0.438195, acc: 76.56%] [G loss: 4.252414]\n",
      "epoch:33 step:26125 [D loss: 0.126191, acc: 98.44%] [G loss: 2.443181]\n",
      "epoch:33 step:26126 [D loss: 0.195725, acc: 99.22%] [G loss: 2.839167]\n",
      "epoch:33 step:26127 [D loss: 0.348276, acc: 87.50%] [G loss: 3.876696]\n",
      "epoch:33 step:26128 [D loss: 0.471012, acc: 79.69%] [G loss: 5.041094]\n",
      "epoch:33 step:26129 [D loss: 0.705263, acc: 51.56%] [G loss: 5.281353]\n",
      "epoch:33 step:26130 [D loss: 0.721881, acc: 57.81%] [G loss: 3.786199]\n",
      "epoch:33 step:26131 [D loss: 0.149919, acc: 99.22%] [G loss: 3.612420]\n",
      "epoch:33 step:26132 [D loss: 0.258464, acc: 97.66%] [G loss: 3.983613]\n",
      "epoch:33 step:26133 [D loss: 0.369841, acc: 95.31%] [G loss: 4.363560]\n",
      "epoch:33 step:26134 [D loss: 0.248871, acc: 91.41%] [G loss: 3.433335]\n",
      "epoch:33 step:26135 [D loss: 0.458436, acc: 77.34%] [G loss: 3.110120]\n",
      "epoch:33 step:26136 [D loss: 0.153532, acc: 99.22%] [G loss: 4.655850]\n",
      "epoch:33 step:26137 [D loss: 0.567572, acc: 61.72%] [G loss: 4.166107]\n",
      "epoch:33 step:26138 [D loss: 0.517933, acc: 63.28%] [G loss: 4.644008]\n",
      "epoch:33 step:26139 [D loss: 0.330868, acc: 88.28%] [G loss: 3.628974]\n",
      "epoch:33 step:26140 [D loss: 0.378135, acc: 86.72%] [G loss: 4.103677]\n",
      "epoch:33 step:26141 [D loss: 0.577857, acc: 57.03%] [G loss: 5.110737]\n",
      "epoch:33 step:26142 [D loss: 0.785716, acc: 53.12%] [G loss: 3.559805]\n",
      "epoch:33 step:26143 [D loss: 0.080422, acc: 99.22%] [G loss: 7.448530]\n",
      "epoch:33 step:26144 [D loss: 0.201111, acc: 98.44%] [G loss: 7.221453]\n",
      "epoch:33 step:26145 [D loss: 0.212564, acc: 99.22%] [G loss: 3.689739]\n",
      "epoch:33 step:26146 [D loss: 0.720305, acc: 53.12%] [G loss: 5.223946]\n",
      "epoch:33 step:26147 [D loss: 0.215905, acc: 97.66%] [G loss: 5.574952]\n",
      "epoch:33 step:26148 [D loss: 0.224140, acc: 94.53%] [G loss: 2.685180]\n",
      "epoch:33 step:26149 [D loss: 0.273591, acc: 96.88%] [G loss: 2.808060]\n",
      "epoch:33 step:26150 [D loss: 0.606500, acc: 67.97%] [G loss: 4.170170]\n",
      "epoch:33 step:26151 [D loss: 0.243455, acc: 96.09%] [G loss: 4.787894]\n",
      "epoch:33 step:26152 [D loss: 0.501336, acc: 67.97%] [G loss: 7.612663]\n",
      "epoch:33 step:26153 [D loss: 0.860587, acc: 50.78%] [G loss: 7.121851]\n",
      "epoch:33 step:26154 [D loss: 0.329316, acc: 85.94%] [G loss: 7.330230]\n",
      "epoch:33 step:26155 [D loss: 0.121641, acc: 99.22%] [G loss: 2.275953]\n",
      "epoch:33 step:26156 [D loss: 0.254775, acc: 90.62%] [G loss: 3.082255]\n",
      "epoch:33 step:26157 [D loss: 0.386145, acc: 82.03%] [G loss: 2.633786]\n",
      "epoch:33 step:26158 [D loss: 0.062281, acc: 100.00%] [G loss: 2.192068]\n",
      "epoch:33 step:26159 [D loss: 0.430033, acc: 75.78%] [G loss: 3.934216]\n",
      "epoch:33 step:26160 [D loss: 0.255226, acc: 95.31%] [G loss: 3.405521]\n",
      "epoch:33 step:26161 [D loss: 0.381883, acc: 76.56%] [G loss: 5.772473]\n",
      "epoch:33 step:26162 [D loss: 0.519625, acc: 64.06%] [G loss: 4.243209]\n",
      "epoch:33 step:26163 [D loss: 0.453828, acc: 72.66%] [G loss: 3.329953]\n",
      "epoch:33 step:26164 [D loss: 0.158949, acc: 100.00%] [G loss: 4.624054]\n",
      "epoch:33 step:26165 [D loss: 0.373233, acc: 91.41%] [G loss: 3.385307]\n",
      "epoch:33 step:26166 [D loss: 0.360963, acc: 83.59%] [G loss: 5.734637]\n",
      "epoch:33 step:26167 [D loss: 0.225742, acc: 95.31%] [G loss: 3.218065]\n",
      "epoch:33 step:26168 [D loss: 0.338591, acc: 88.28%] [G loss: 2.504848]\n",
      "epoch:33 step:26169 [D loss: 0.456354, acc: 82.81%] [G loss: 5.262259]\n",
      "epoch:33 step:26170 [D loss: 0.976759, acc: 28.91%] [G loss: 3.926788]\n",
      "epoch:33 step:26171 [D loss: 0.595114, acc: 67.97%] [G loss: 6.283627]\n",
      "epoch:33 step:26172 [D loss: 0.480600, acc: 65.62%] [G loss: 8.153687]\n",
      "epoch:33 step:26173 [D loss: 0.345450, acc: 89.06%] [G loss: 3.049626]\n",
      "epoch:33 step:26174 [D loss: 0.192846, acc: 98.44%] [G loss: 4.009360]\n",
      "epoch:33 step:26175 [D loss: 0.082254, acc: 100.00%] [G loss: 4.297035]\n",
      "epoch:33 step:26176 [D loss: 0.245523, acc: 92.97%] [G loss: 3.676956]\n",
      "epoch:33 step:26177 [D loss: 0.568971, acc: 69.53%] [G loss: 4.595158]\n",
      "epoch:33 step:26178 [D loss: 0.196883, acc: 100.00%] [G loss: 3.462484]\n",
      "epoch:33 step:26179 [D loss: 0.812983, acc: 49.22%] [G loss: 3.394225]\n",
      "epoch:33 step:26180 [D loss: 0.399374, acc: 85.16%] [G loss: 6.059094]\n",
      "epoch:33 step:26181 [D loss: 0.154499, acc: 99.22%] [G loss: 4.736960]\n",
      "epoch:33 step:26182 [D loss: 0.355015, acc: 94.53%] [G loss: 3.858793]\n",
      "epoch:33 step:26183 [D loss: 0.826953, acc: 52.34%] [G loss: 5.722926]\n",
      "epoch:33 step:26184 [D loss: 0.179534, acc: 100.00%] [G loss: 3.162821]\n",
      "epoch:33 step:26185 [D loss: 0.041108, acc: 100.00%] [G loss: 4.801255]\n",
      "epoch:33 step:26186 [D loss: 0.219436, acc: 96.09%] [G loss: 4.253401]\n",
      "epoch:33 step:26187 [D loss: 0.270926, acc: 96.88%] [G loss: 3.035670]\n",
      "epoch:33 step:26188 [D loss: 0.456019, acc: 81.25%] [G loss: 3.227212]\n",
      "epoch:33 step:26189 [D loss: 0.263254, acc: 93.75%] [G loss: 3.776032]\n",
      "epoch:33 step:26190 [D loss: 0.192556, acc: 98.44%] [G loss: 4.245652]\n",
      "epoch:33 step:26191 [D loss: 1.027922, acc: 51.56%] [G loss: 5.356818]\n",
      "epoch:33 step:26192 [D loss: 0.282999, acc: 91.41%] [G loss: 7.613930]\n",
      "epoch:33 step:26193 [D loss: 0.680723, acc: 57.81%] [G loss: 4.600611]\n",
      "epoch:33 step:26194 [D loss: 0.553063, acc: 68.75%] [G loss: 4.312181]\n",
      "epoch:33 step:26195 [D loss: 0.167847, acc: 98.44%] [G loss: 5.288140]\n",
      "epoch:33 step:26196 [D loss: 0.522964, acc: 68.75%] [G loss: 5.124885]\n",
      "epoch:33 step:26197 [D loss: 0.180627, acc: 97.66%] [G loss: 3.926994]\n",
      "epoch:33 step:26198 [D loss: 0.702963, acc: 53.12%] [G loss: 2.733429]\n",
      "epoch:33 step:26199 [D loss: 0.857113, acc: 39.06%] [G loss: 3.549119]\n",
      "epoch:33 step:26200 [D loss: 0.337933, acc: 80.47%] [G loss: 4.027698]\n",
      "epoch:33 step:26201 [D loss: 0.028207, acc: 100.00%] [G loss: 5.784941]\n",
      "epoch:33 step:26202 [D loss: 0.162896, acc: 98.44%] [G loss: 3.767130]\n",
      "epoch:33 step:26203 [D loss: 0.212469, acc: 97.66%] [G loss: 7.904638]\n",
      "epoch:33 step:26204 [D loss: 0.145938, acc: 100.00%] [G loss: 3.475494]\n",
      "epoch:33 step:26205 [D loss: 0.160182, acc: 98.44%] [G loss: 2.986034]\n",
      "epoch:33 step:26206 [D loss: 0.217148, acc: 93.75%] [G loss: 5.023998]\n",
      "epoch:33 step:26207 [D loss: 0.233070, acc: 98.44%] [G loss: 6.125201]\n",
      "epoch:33 step:26208 [D loss: 0.317343, acc: 92.19%] [G loss: 5.100234]\n",
      "epoch:33 step:26209 [D loss: 1.499124, acc: 9.38%] [G loss: 6.252045]\n",
      "epoch:33 step:26210 [D loss: 0.759454, acc: 54.69%] [G loss: 2.966480]\n",
      "epoch:33 step:26211 [D loss: 0.080415, acc: 100.00%] [G loss: 4.300354]\n",
      "epoch:33 step:26212 [D loss: 0.324708, acc: 90.62%] [G loss: 3.406345]\n",
      "epoch:33 step:26213 [D loss: 0.395581, acc: 91.41%] [G loss: 3.263414]\n",
      "epoch:33 step:26214 [D loss: 0.269050, acc: 97.66%] [G loss: 4.293976]\n",
      "epoch:33 step:26215 [D loss: 1.407934, acc: 36.72%] [G loss: 3.811321]\n",
      "epoch:33 step:26216 [D loss: 0.759186, acc: 55.47%] [G loss: 3.889127]\n",
      "epoch:33 step:26217 [D loss: 0.110847, acc: 100.00%] [G loss: 4.149396]\n",
      "epoch:33 step:26218 [D loss: 0.224619, acc: 96.09%] [G loss: 3.713711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26219 [D loss: 0.321789, acc: 84.38%] [G loss: 7.472406]\n",
      "epoch:33 step:26220 [D loss: 0.540280, acc: 66.41%] [G loss: 4.350388]\n",
      "epoch:33 step:26221 [D loss: 0.606862, acc: 67.97%] [G loss: 7.914518]\n",
      "epoch:33 step:26222 [D loss: 0.173570, acc: 100.00%] [G loss: 4.881071]\n",
      "epoch:33 step:26223 [D loss: 0.700635, acc: 60.94%] [G loss: 3.383171]\n",
      "epoch:33 step:26224 [D loss: 0.280694, acc: 95.31%] [G loss: 3.441192]\n",
      "epoch:33 step:26225 [D loss: 0.062325, acc: 100.00%] [G loss: 5.868991]\n",
      "epoch:33 step:26226 [D loss: 0.133905, acc: 98.44%] [G loss: 5.254045]\n",
      "epoch:33 step:26227 [D loss: 0.400038, acc: 85.16%] [G loss: 3.365511]\n",
      "epoch:33 step:26228 [D loss: 0.412802, acc: 77.34%] [G loss: 3.838201]\n",
      "epoch:33 step:26229 [D loss: 0.286438, acc: 98.44%] [G loss: 3.157380]\n",
      "epoch:33 step:26230 [D loss: 0.127164, acc: 98.44%] [G loss: 5.643711]\n",
      "epoch:33 step:26231 [D loss: 0.317802, acc: 91.41%] [G loss: 3.720900]\n",
      "epoch:33 step:26232 [D loss: 0.561311, acc: 66.41%] [G loss: 2.918452]\n",
      "epoch:33 step:26233 [D loss: 0.240848, acc: 90.62%] [G loss: 5.575336]\n",
      "epoch:33 step:26234 [D loss: 0.448014, acc: 76.56%] [G loss: 3.618597]\n",
      "epoch:33 step:26235 [D loss: 0.241293, acc: 97.66%] [G loss: 4.948822]\n",
      "epoch:33 step:26236 [D loss: 0.486162, acc: 71.88%] [G loss: 7.689104]\n",
      "epoch:33 step:26237 [D loss: 0.453201, acc: 72.66%] [G loss: 4.034014]\n",
      "epoch:33 step:26238 [D loss: 0.387133, acc: 86.72%] [G loss: 4.343618]\n",
      "epoch:33 step:26239 [D loss: 0.137966, acc: 100.00%] [G loss: 6.189301]\n",
      "epoch:33 step:26240 [D loss: 0.262201, acc: 98.44%] [G loss: 3.785059]\n",
      "epoch:33 step:26241 [D loss: 1.117486, acc: 17.97%] [G loss: 5.491370]\n",
      "epoch:33 step:26242 [D loss: 0.116720, acc: 100.00%] [G loss: 5.407615]\n",
      "epoch:33 step:26243 [D loss: 0.196433, acc: 98.44%] [G loss: 5.779126]\n",
      "epoch:33 step:26244 [D loss: 0.367854, acc: 77.34%] [G loss: 4.190266]\n",
      "epoch:33 step:26245 [D loss: 0.228046, acc: 98.44%] [G loss: 4.382243]\n",
      "epoch:33 step:26246 [D loss: 0.539242, acc: 64.84%] [G loss: 4.377513]\n",
      "epoch:33 step:26247 [D loss: 0.466503, acc: 68.75%] [G loss: 3.254746]\n",
      "epoch:33 step:26248 [D loss: 0.310579, acc: 92.19%] [G loss: 3.568707]\n",
      "epoch:33 step:26249 [D loss: 0.242487, acc: 96.88%] [G loss: 4.538309]\n",
      "epoch:33 step:26250 [D loss: 0.331484, acc: 93.75%] [G loss: 2.873686]\n",
      "epoch:33 step:26251 [D loss: 0.292903, acc: 84.38%] [G loss: 7.319409]\n",
      "epoch:33 step:26252 [D loss: 0.592590, acc: 64.84%] [G loss: 4.567056]\n",
      "epoch:33 step:26253 [D loss: 0.421477, acc: 80.47%] [G loss: 5.032653]\n",
      "epoch:33 step:26254 [D loss: 0.119524, acc: 100.00%] [G loss: 4.057961]\n",
      "epoch:33 step:26255 [D loss: 1.530653, acc: 7.03%] [G loss: 4.884254]\n",
      "epoch:33 step:26256 [D loss: 0.242436, acc: 96.88%] [G loss: 2.768537]\n",
      "epoch:33 step:26257 [D loss: 0.730598, acc: 54.69%] [G loss: 4.081751]\n",
      "epoch:33 step:26258 [D loss: 0.554273, acc: 63.28%] [G loss: 4.704176]\n",
      "epoch:33 step:26259 [D loss: 0.331532, acc: 91.41%] [G loss: 4.312060]\n",
      "epoch:33 step:26260 [D loss: 0.681213, acc: 59.38%] [G loss: 4.436254]\n",
      "epoch:33 step:26261 [D loss: 0.237246, acc: 97.66%] [G loss: 5.902353]\n",
      "epoch:33 step:26262 [D loss: 0.225083, acc: 98.44%] [G loss: 4.477988]\n",
      "epoch:33 step:26263 [D loss: 0.074863, acc: 100.00%] [G loss: 5.846653]\n",
      "epoch:33 step:26264 [D loss: 0.186180, acc: 99.22%] [G loss: 3.605231]\n",
      "epoch:33 step:26265 [D loss: 0.379378, acc: 89.06%] [G loss: 4.683813]\n",
      "epoch:33 step:26266 [D loss: 0.918203, acc: 50.78%] [G loss: 4.942100]\n",
      "epoch:33 step:26267 [D loss: 0.313955, acc: 96.88%] [G loss: 6.136171]\n",
      "epoch:33 step:26268 [D loss: 0.125572, acc: 100.00%] [G loss: 4.528165]\n",
      "epoch:33 step:26269 [D loss: 1.174293, acc: 38.28%] [G loss: 5.755618]\n",
      "epoch:33 step:26270 [D loss: 0.558970, acc: 66.41%] [G loss: 4.506594]\n",
      "epoch:33 step:26271 [D loss: 0.139472, acc: 97.66%] [G loss: 3.858253]\n",
      "epoch:33 step:26272 [D loss: 0.435273, acc: 85.94%] [G loss: 4.567520]\n",
      "epoch:33 step:26273 [D loss: 0.295010, acc: 92.19%] [G loss: 7.116308]\n",
      "epoch:33 step:26274 [D loss: 0.215610, acc: 95.31%] [G loss: 5.338480]\n",
      "epoch:33 step:26275 [D loss: 0.415576, acc: 77.34%] [G loss: 5.621473]\n",
      "epoch:33 step:26276 [D loss: 0.821607, acc: 50.00%] [G loss: 5.797493]\n",
      "epoch:33 step:26277 [D loss: 0.496643, acc: 77.34%] [G loss: 4.088710]\n",
      "epoch:33 step:26278 [D loss: 0.353956, acc: 85.94%] [G loss: 3.503947]\n",
      "epoch:33 step:26279 [D loss: 0.246575, acc: 97.66%] [G loss: 3.309078]\n",
      "epoch:33 step:26280 [D loss: 0.318243, acc: 96.09%] [G loss: 2.666741]\n",
      "epoch:33 step:26281 [D loss: 0.677468, acc: 64.06%] [G loss: 4.448605]\n",
      "epoch:33 step:26282 [D loss: 0.488161, acc: 73.44%] [G loss: 3.055563]\n",
      "epoch:33 step:26283 [D loss: 0.086076, acc: 100.00%] [G loss: 5.454794]\n",
      "epoch:33 step:26284 [D loss: 0.032152, acc: 100.00%] [G loss: 6.194351]\n",
      "epoch:33 step:26285 [D loss: 0.125528, acc: 98.44%] [G loss: 7.258214]\n",
      "epoch:33 step:26286 [D loss: 0.683678, acc: 57.81%] [G loss: 4.522356]\n",
      "epoch:33 step:26287 [D loss: 0.394456, acc: 86.72%] [G loss: 3.974649]\n",
      "epoch:33 step:26288 [D loss: 0.064846, acc: 100.00%] [G loss: 5.805496]\n",
      "epoch:33 step:26289 [D loss: 0.312696, acc: 95.31%] [G loss: 3.839737]\n",
      "epoch:33 step:26290 [D loss: 0.016360, acc: 100.00%] [G loss: 5.514421]\n",
      "epoch:33 step:26291 [D loss: 0.063562, acc: 99.22%] [G loss: 3.268242]\n",
      "epoch:33 step:26292 [D loss: 0.406885, acc: 74.22%] [G loss: 2.068544]\n",
      "epoch:33 step:26293 [D loss: 0.357891, acc: 85.94%] [G loss: 5.098001]\n",
      "epoch:33 step:26294 [D loss: 0.730585, acc: 53.91%] [G loss: 4.297212]\n",
      "epoch:33 step:26295 [D loss: 0.406896, acc: 87.50%] [G loss: 2.571161]\n",
      "epoch:33 step:26296 [D loss: 0.748623, acc: 51.56%] [G loss: 3.071093]\n",
      "epoch:33 step:26297 [D loss: 0.045612, acc: 100.00%] [G loss: 4.525208]\n",
      "epoch:33 step:26298 [D loss: 1.577151, acc: 46.09%] [G loss: 5.955562]\n",
      "epoch:33 step:26299 [D loss: 0.126123, acc: 97.66%] [G loss: 5.114936]\n",
      "epoch:33 step:26300 [D loss: 0.234968, acc: 97.66%] [G loss: 5.749717]\n",
      "epoch:33 step:26301 [D loss: 0.278695, acc: 92.97%] [G loss: 5.857484]\n",
      "epoch:33 step:26302 [D loss: 0.110295, acc: 100.00%] [G loss: 4.364268]\n",
      "epoch:33 step:26303 [D loss: 0.175786, acc: 97.66%] [G loss: 5.406045]\n",
      "epoch:33 step:26304 [D loss: 0.612838, acc: 61.72%] [G loss: 5.792013]\n",
      "epoch:33 step:26305 [D loss: 0.431714, acc: 79.69%] [G loss: 2.605487]\n",
      "epoch:33 step:26306 [D loss: 0.460639, acc: 82.81%] [G loss: 3.369265]\n",
      "epoch:33 step:26307 [D loss: 0.158184, acc: 96.88%] [G loss: 5.466009]\n",
      "epoch:33 step:26308 [D loss: 1.386029, acc: 10.16%] [G loss: 4.762837]\n",
      "epoch:33 step:26309 [D loss: 0.172523, acc: 99.22%] [G loss: 4.406421]\n",
      "epoch:33 step:26310 [D loss: 0.215193, acc: 96.09%] [G loss: 4.481972]\n",
      "epoch:33 step:26311 [D loss: 0.081837, acc: 99.22%] [G loss: 8.597688]\n",
      "epoch:33 step:26312 [D loss: 0.309491, acc: 88.28%] [G loss: 5.470735]\n",
      "epoch:33 step:26313 [D loss: 0.363831, acc: 95.31%] [G loss: 3.616709]\n",
      "epoch:33 step:26314 [D loss: 0.281407, acc: 95.31%] [G loss: 3.860711]\n",
      "epoch:33 step:26315 [D loss: 0.956359, acc: 51.56%] [G loss: 3.107920]\n",
      "epoch:33 step:26316 [D loss: 0.115758, acc: 98.44%] [G loss: 4.086124]\n",
      "epoch:33 step:26317 [D loss: 0.636089, acc: 66.41%] [G loss: 2.453134]\n",
      "epoch:33 step:26318 [D loss: 0.255944, acc: 97.66%] [G loss: 2.813674]\n",
      "epoch:33 step:26319 [D loss: 0.070805, acc: 100.00%] [G loss: 4.234004]\n",
      "epoch:33 step:26320 [D loss: 0.471704, acc: 80.47%] [G loss: 5.962436]\n",
      "epoch:33 step:26321 [D loss: 0.485181, acc: 82.81%] [G loss: 5.228606]\n",
      "epoch:33 step:26322 [D loss: 0.263294, acc: 91.41%] [G loss: 6.090048]\n",
      "epoch:33 step:26323 [D loss: 0.186521, acc: 96.88%] [G loss: 6.776493]\n",
      "epoch:33 step:26324 [D loss: 0.145705, acc: 98.44%] [G loss: 7.928041]\n",
      "epoch:33 step:26325 [D loss: 1.319648, acc: 9.38%] [G loss: 5.940259]\n",
      "epoch:33 step:26326 [D loss: 0.695588, acc: 55.47%] [G loss: 4.188108]\n",
      "epoch:33 step:26327 [D loss: 0.042451, acc: 100.00%] [G loss: 3.350893]\n",
      "epoch:33 step:26328 [D loss: 0.055023, acc: 100.00%] [G loss: 5.736993]\n",
      "epoch:33 step:26329 [D loss: 0.628128, acc: 56.25%] [G loss: 4.033998]\n",
      "epoch:33 step:26330 [D loss: 0.927776, acc: 50.00%] [G loss: 3.376581]\n",
      "epoch:33 step:26331 [D loss: 0.122950, acc: 100.00%] [G loss: 2.920384]\n",
      "epoch:33 step:26332 [D loss: 0.038781, acc: 100.00%] [G loss: 9.711552]\n",
      "epoch:33 step:26333 [D loss: 0.441134, acc: 85.16%] [G loss: 3.279258]\n",
      "epoch:33 step:26334 [D loss: 0.353941, acc: 82.81%] [G loss: 4.309733]\n",
      "epoch:33 step:26335 [D loss: 0.533855, acc: 72.66%] [G loss: 5.504601]\n",
      "epoch:33 step:26336 [D loss: 0.175897, acc: 98.44%] [G loss: 4.698385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26337 [D loss: 0.074102, acc: 100.00%] [G loss: 4.935678]\n",
      "epoch:33 step:26338 [D loss: 0.247161, acc: 93.75%] [G loss: 4.470113]\n",
      "epoch:33 step:26339 [D loss: 1.032619, acc: 40.62%] [G loss: 5.222373]\n",
      "epoch:33 step:26340 [D loss: 1.068025, acc: 50.00%] [G loss: 4.852439]\n",
      "epoch:33 step:26341 [D loss: 0.103914, acc: 100.00%] [G loss: 5.987999]\n",
      "epoch:33 step:26342 [D loss: 0.362855, acc: 81.25%] [G loss: 4.790759]\n",
      "epoch:33 step:26343 [D loss: 0.713131, acc: 53.91%] [G loss: 5.306100]\n",
      "epoch:33 step:26344 [D loss: 1.036987, acc: 46.09%] [G loss: 4.989128]\n",
      "epoch:33 step:26345 [D loss: 0.385335, acc: 94.53%] [G loss: 3.167020]\n",
      "epoch:33 step:26346 [D loss: 0.591136, acc: 67.97%] [G loss: 4.262209]\n",
      "epoch:33 step:26347 [D loss: 0.557839, acc: 67.19%] [G loss: 3.817024]\n",
      "epoch:33 step:26348 [D loss: 0.140502, acc: 98.44%] [G loss: 4.075638]\n",
      "epoch:33 step:26349 [D loss: 0.159327, acc: 98.44%] [G loss: 5.369446]\n",
      "epoch:33 step:26350 [D loss: 0.801207, acc: 46.88%] [G loss: 3.619519]\n",
      "epoch:33 step:26351 [D loss: 0.592825, acc: 71.88%] [G loss: 5.524440]\n",
      "epoch:33 step:26352 [D loss: 0.427647, acc: 71.88%] [G loss: 5.719143]\n",
      "epoch:33 step:26353 [D loss: 0.117777, acc: 100.00%] [G loss: 5.842463]\n",
      "epoch:33 step:26354 [D loss: 0.554973, acc: 58.59%] [G loss: 6.947151]\n",
      "epoch:33 step:26355 [D loss: 0.708576, acc: 57.03%] [G loss: 4.939835]\n",
      "epoch:33 step:26356 [D loss: 0.136358, acc: 99.22%] [G loss: 6.006762]\n",
      "epoch:33 step:26357 [D loss: 0.984953, acc: 50.78%] [G loss: 5.351832]\n",
      "epoch:33 step:26358 [D loss: 0.234158, acc: 96.88%] [G loss: 6.803885]\n",
      "epoch:33 step:26359 [D loss: 0.257887, acc: 95.31%] [G loss: 5.314814]\n",
      "epoch:33 step:26360 [D loss: 0.150846, acc: 97.66%] [G loss: 4.632631]\n",
      "epoch:33 step:26361 [D loss: 0.564358, acc: 69.53%] [G loss: 2.528928]\n",
      "epoch:33 step:26362 [D loss: 0.215804, acc: 99.22%] [G loss: 3.611282]\n",
      "epoch:33 step:26363 [D loss: 0.263590, acc: 92.97%] [G loss: 3.100837]\n",
      "epoch:33 step:26364 [D loss: 0.466652, acc: 82.81%] [G loss: 3.606150]\n",
      "epoch:33 step:26365 [D loss: 0.666738, acc: 53.91%] [G loss: 2.956673]\n",
      "epoch:33 step:26366 [D loss: 0.385014, acc: 85.16%] [G loss: 4.396573]\n",
      "epoch:33 step:26367 [D loss: 0.637203, acc: 58.59%] [G loss: 4.488138]\n",
      "epoch:33 step:26368 [D loss: 1.099750, acc: 50.00%] [G loss: 3.335927]\n",
      "epoch:33 step:26369 [D loss: 0.754864, acc: 53.91%] [G loss: 7.228571]\n",
      "epoch:33 step:26370 [D loss: 0.309897, acc: 92.97%] [G loss: 3.681750]\n",
      "epoch:33 step:26371 [D loss: 0.340278, acc: 89.84%] [G loss: 5.876205]\n",
      "epoch:33 step:26372 [D loss: 0.189427, acc: 98.44%] [G loss: 3.634339]\n",
      "epoch:33 step:26373 [D loss: 0.365270, acc: 88.28%] [G loss: 4.183740]\n",
      "epoch:33 step:26374 [D loss: 0.257720, acc: 96.09%] [G loss: 4.036673]\n",
      "epoch:33 step:26375 [D loss: 0.313546, acc: 83.59%] [G loss: 4.129512]\n",
      "epoch:33 step:26376 [D loss: 0.738835, acc: 53.12%] [G loss: 4.213400]\n",
      "epoch:33 step:26377 [D loss: 0.139265, acc: 96.88%] [G loss: 5.982412]\n",
      "epoch:33 step:26378 [D loss: 0.202161, acc: 97.66%] [G loss: 4.139462]\n",
      "epoch:33 step:26379 [D loss: 0.233565, acc: 95.31%] [G loss: 5.259274]\n",
      "epoch:33 step:26380 [D loss: 0.113388, acc: 100.00%] [G loss: 5.554898]\n",
      "epoch:33 step:26381 [D loss: 0.387476, acc: 85.94%] [G loss: 3.913646]\n",
      "epoch:33 step:26382 [D loss: 0.117978, acc: 98.44%] [G loss: 5.430184]\n",
      "epoch:33 step:26383 [D loss: 0.345747, acc: 77.34%] [G loss: 3.211590]\n",
      "epoch:33 step:26384 [D loss: 0.078974, acc: 100.00%] [G loss: 6.600248]\n",
      "epoch:33 step:26385 [D loss: 0.567446, acc: 71.09%] [G loss: 5.459433]\n",
      "epoch:33 step:26386 [D loss: 0.795169, acc: 54.69%] [G loss: 6.157268]\n",
      "epoch:33 step:26387 [D loss: 0.203230, acc: 95.31%] [G loss: 5.308105]\n",
      "epoch:33 step:26388 [D loss: 0.667748, acc: 54.69%] [G loss: 4.748744]\n",
      "epoch:33 step:26389 [D loss: 0.491260, acc: 79.69%] [G loss: 3.290592]\n",
      "epoch:33 step:26390 [D loss: 0.774253, acc: 52.34%] [G loss: 3.713195]\n",
      "epoch:33 step:26391 [D loss: 0.342529, acc: 85.94%] [G loss: 5.545126]\n",
      "epoch:33 step:26392 [D loss: 0.576821, acc: 69.53%] [G loss: 4.374094]\n",
      "epoch:33 step:26393 [D loss: 0.236192, acc: 95.31%] [G loss: 2.547817]\n",
      "epoch:33 step:26394 [D loss: 0.308391, acc: 92.97%] [G loss: 3.975537]\n",
      "epoch:33 step:26395 [D loss: 0.163715, acc: 98.44%] [G loss: 5.156691]\n",
      "epoch:33 step:26396 [D loss: 0.206423, acc: 98.44%] [G loss: 4.408998]\n",
      "epoch:33 step:26397 [D loss: 0.130302, acc: 100.00%] [G loss: 2.871216]\n",
      "epoch:33 step:26398 [D loss: 0.307654, acc: 89.06%] [G loss: 6.316720]\n",
      "epoch:33 step:26399 [D loss: 0.726116, acc: 52.34%] [G loss: 3.365738]\n",
      "epoch:33 step:26400 [D loss: 0.562373, acc: 75.00%] [G loss: 5.132560]\n",
      "epoch:33 step:26401 [D loss: 0.125264, acc: 100.00%] [G loss: 3.805810]\n",
      "epoch:33 step:26402 [D loss: 0.303689, acc: 92.19%] [G loss: 2.434631]\n",
      "epoch:33 step:26403 [D loss: 0.171162, acc: 98.44%] [G loss: 5.122470]\n",
      "epoch:33 step:26404 [D loss: 0.827228, acc: 53.12%] [G loss: 3.264356]\n",
      "epoch:33 step:26405 [D loss: 0.712071, acc: 51.56%] [G loss: 4.828880]\n",
      "epoch:33 step:26406 [D loss: 0.087139, acc: 100.00%] [G loss: 3.640730]\n",
      "epoch:33 step:26407 [D loss: 1.056429, acc: 42.97%] [G loss: 2.791408]\n",
      "epoch:33 step:26408 [D loss: 0.224689, acc: 96.88%] [G loss: 3.214910]\n",
      "epoch:33 step:26409 [D loss: 0.242384, acc: 96.88%] [G loss: 5.362989]\n",
      "epoch:33 step:26410 [D loss: 0.561084, acc: 61.72%] [G loss: 4.173499]\n",
      "epoch:33 step:26411 [D loss: 0.915168, acc: 44.53%] [G loss: 4.780399]\n",
      "epoch:33 step:26412 [D loss: 0.673314, acc: 62.50%] [G loss: 6.436340]\n",
      "epoch:33 step:26413 [D loss: 0.195276, acc: 98.44%] [G loss: 4.548872]\n",
      "epoch:33 step:26414 [D loss: 0.218570, acc: 98.44%] [G loss: 2.252519]\n",
      "epoch:33 step:26415 [D loss: 0.495991, acc: 60.94%] [G loss: 4.795020]\n",
      "epoch:33 step:26416 [D loss: 1.125981, acc: 20.31%] [G loss: 5.001107]\n",
      "epoch:33 step:26417 [D loss: 0.363783, acc: 78.12%] [G loss: 4.969081]\n",
      "epoch:33 step:26418 [D loss: 0.243489, acc: 93.75%] [G loss: 3.334370]\n",
      "epoch:33 step:26419 [D loss: 0.208789, acc: 100.00%] [G loss: 3.850848]\n",
      "epoch:33 step:26420 [D loss: 0.149557, acc: 99.22%] [G loss: 3.339664]\n",
      "epoch:33 step:26421 [D loss: 1.116349, acc: 16.41%] [G loss: 3.274182]\n",
      "epoch:33 step:26422 [D loss: 0.167781, acc: 97.66%] [G loss: 4.829877]\n",
      "epoch:33 step:26423 [D loss: 0.462129, acc: 73.44%] [G loss: 4.500781]\n",
      "epoch:33 step:26424 [D loss: 0.391193, acc: 73.44%] [G loss: 7.174496]\n",
      "epoch:33 step:26425 [D loss: 0.483443, acc: 66.41%] [G loss: 5.659492]\n",
      "epoch:33 step:26426 [D loss: 0.121811, acc: 97.66%] [G loss: 5.197575]\n",
      "epoch:33 step:26427 [D loss: 0.159067, acc: 97.66%] [G loss: 4.119871]\n",
      "epoch:33 step:26428 [D loss: 0.597236, acc: 72.66%] [G loss: 5.403805]\n",
      "epoch:33 step:26429 [D loss: 0.220657, acc: 98.44%] [G loss: 3.296430]\n",
      "epoch:33 step:26430 [D loss: 0.200022, acc: 99.22%] [G loss: 6.195877]\n",
      "epoch:33 step:26431 [D loss: 0.273800, acc: 92.97%] [G loss: 2.997356]\n",
      "epoch:33 step:26432 [D loss: 0.231459, acc: 95.31%] [G loss: 6.574762]\n",
      "epoch:33 step:26433 [D loss: 0.251223, acc: 96.88%] [G loss: 5.120361]\n",
      "epoch:33 step:26434 [D loss: 0.734354, acc: 50.78%] [G loss: 4.006645]\n",
      "epoch:33 step:26435 [D loss: 0.591952, acc: 64.84%] [G loss: 2.728340]\n",
      "epoch:33 step:26436 [D loss: 0.800470, acc: 52.34%] [G loss: 3.799417]\n",
      "epoch:33 step:26437 [D loss: 0.678386, acc: 57.81%] [G loss: 6.356693]\n",
      "epoch:33 step:26438 [D loss: 0.198077, acc: 98.44%] [G loss: 6.954298]\n",
      "epoch:33 step:26439 [D loss: 0.309814, acc: 91.41%] [G loss: 5.790901]\n",
      "epoch:33 step:26440 [D loss: 0.043123, acc: 100.00%] [G loss: 6.165733]\n",
      "epoch:33 step:26441 [D loss: 0.126088, acc: 99.22%] [G loss: 6.888950]\n",
      "epoch:33 step:26442 [D loss: 0.620914, acc: 60.16%] [G loss: 3.701283]\n",
      "epoch:33 step:26443 [D loss: 0.148029, acc: 100.00%] [G loss: 6.031049]\n",
      "epoch:33 step:26444 [D loss: 0.063101, acc: 100.00%] [G loss: 6.191947]\n",
      "epoch:33 step:26445 [D loss: 1.048237, acc: 50.00%] [G loss: 4.610534]\n",
      "epoch:33 step:26446 [D loss: 0.908021, acc: 52.34%] [G loss: 3.458638]\n",
      "epoch:33 step:26447 [D loss: 1.133032, acc: 48.44%] [G loss: 5.233293]\n",
      "epoch:33 step:26448 [D loss: 0.098270, acc: 100.00%] [G loss: 4.373878]\n",
      "epoch:33 step:26449 [D loss: 0.439633, acc: 68.75%] [G loss: 5.751990]\n",
      "epoch:33 step:26450 [D loss: 2.058709, acc: 0.78%] [G loss: 6.440405]\n",
      "epoch:33 step:26451 [D loss: 1.025307, acc: 40.62%] [G loss: 5.959524]\n",
      "epoch:33 step:26452 [D loss: 0.575214, acc: 60.16%] [G loss: 3.266179]\n",
      "epoch:33 step:26453 [D loss: 0.211422, acc: 95.31%] [G loss: 4.331693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26454 [D loss: 0.967206, acc: 50.78%] [G loss: 3.485695]\n",
      "epoch:33 step:26455 [D loss: 0.160195, acc: 99.22%] [G loss: 5.041266]\n",
      "epoch:33 step:26456 [D loss: 0.635767, acc: 57.81%] [G loss: 3.114893]\n",
      "epoch:33 step:26457 [D loss: 0.129664, acc: 100.00%] [G loss: 2.928457]\n",
      "epoch:33 step:26458 [D loss: 1.014702, acc: 50.78%] [G loss: 3.318817]\n",
      "epoch:33 step:26459 [D loss: 0.168125, acc: 96.09%] [G loss: 5.029658]\n",
      "epoch:33 step:26460 [D loss: 0.474187, acc: 67.19%] [G loss: 5.179731]\n",
      "epoch:33 step:26461 [D loss: 0.505266, acc: 77.34%] [G loss: 2.738577]\n",
      "epoch:33 step:26462 [D loss: 0.632306, acc: 61.72%] [G loss: 2.095516]\n",
      "epoch:33 step:26463 [D loss: 0.029906, acc: 100.00%] [G loss: 6.647706]\n",
      "epoch:33 step:26464 [D loss: 0.139324, acc: 98.44%] [G loss: 3.782015]\n",
      "epoch:33 step:26465 [D loss: 0.309240, acc: 93.75%] [G loss: 7.637816]\n",
      "epoch:33 step:26466 [D loss: 0.836026, acc: 54.69%] [G loss: 3.965017]\n",
      "epoch:33 step:26467 [D loss: 0.721163, acc: 52.34%] [G loss: 4.065367]\n",
      "epoch:33 step:26468 [D loss: 0.260277, acc: 96.09%] [G loss: 3.718594]\n",
      "epoch:33 step:26469 [D loss: 0.712825, acc: 55.47%] [G loss: 2.797047]\n",
      "epoch:33 step:26470 [D loss: 0.631561, acc: 62.50%] [G loss: 6.873510]\n",
      "epoch:33 step:26471 [D loss: 0.154038, acc: 99.22%] [G loss: 6.109327]\n",
      "epoch:33 step:26472 [D loss: 0.955452, acc: 31.25%] [G loss: 3.728969]\n",
      "epoch:33 step:26473 [D loss: 0.559036, acc: 73.44%] [G loss: 3.156442]\n",
      "epoch:33 step:26474 [D loss: 0.217769, acc: 98.44%] [G loss: 2.397684]\n",
      "epoch:33 step:26475 [D loss: 0.527578, acc: 60.94%] [G loss: 3.344794]\n",
      "epoch:33 step:26476 [D loss: 0.496715, acc: 65.62%] [G loss: 5.400486]\n",
      "epoch:33 step:26477 [D loss: 0.403237, acc: 78.91%] [G loss: 6.931314]\n",
      "epoch:33 step:26478 [D loss: 0.094747, acc: 100.00%] [G loss: 7.139084]\n",
      "epoch:33 step:26479 [D loss: 0.442738, acc: 72.66%] [G loss: 4.715212]\n",
      "epoch:33 step:26480 [D loss: 0.061319, acc: 100.00%] [G loss: 7.041431]\n",
      "epoch:33 step:26481 [D loss: 0.536298, acc: 64.06%] [G loss: 4.762870]\n",
      "epoch:33 step:26482 [D loss: 1.097542, acc: 50.00%] [G loss: 5.289597]\n",
      "epoch:33 step:26483 [D loss: 0.298347, acc: 90.62%] [G loss: 4.463074]\n",
      "epoch:33 step:26484 [D loss: 0.307123, acc: 85.16%] [G loss: 4.870781]\n",
      "epoch:33 step:26485 [D loss: 0.523512, acc: 75.00%] [G loss: 2.626910]\n",
      "epoch:33 step:26486 [D loss: 0.042271, acc: 100.00%] [G loss: 5.292696]\n",
      "epoch:33 step:26487 [D loss: 0.360025, acc: 83.59%] [G loss: 4.671457]\n",
      "epoch:33 step:26488 [D loss: 0.298144, acc: 93.75%] [G loss: 4.036861]\n",
      "epoch:33 step:26489 [D loss: 0.023311, acc: 100.00%] [G loss: 4.176656]\n",
      "epoch:33 step:26490 [D loss: 0.365790, acc: 87.50%] [G loss: 4.207923]\n",
      "epoch:33 step:26491 [D loss: 0.062632, acc: 100.00%] [G loss: 2.512968]\n",
      "epoch:33 step:26492 [D loss: 0.258370, acc: 96.88%] [G loss: 4.816721]\n",
      "epoch:33 step:26493 [D loss: 0.178357, acc: 98.44%] [G loss: 4.361543]\n",
      "epoch:33 step:26494 [D loss: 0.450827, acc: 67.19%] [G loss: 6.002518]\n",
      "epoch:33 step:26495 [D loss: 0.333632, acc: 92.19%] [G loss: 2.594653]\n",
      "epoch:33 step:26496 [D loss: 0.185937, acc: 98.44%] [G loss: 4.670586]\n",
      "epoch:33 step:26497 [D loss: 0.852176, acc: 38.28%] [G loss: 5.270223]\n",
      "epoch:33 step:26498 [D loss: 0.500453, acc: 75.78%] [G loss: 3.312865]\n",
      "epoch:33 step:26499 [D loss: 0.108998, acc: 100.00%] [G loss: 4.346652]\n",
      "epoch:33 step:26500 [D loss: 0.072648, acc: 100.00%] [G loss: 3.958665]\n",
      "epoch:33 step:26501 [D loss: 0.161160, acc: 98.44%] [G loss: 3.899840]\n",
      "epoch:33 step:26502 [D loss: 0.215574, acc: 95.31%] [G loss: 4.391726]\n",
      "epoch:33 step:26503 [D loss: 0.784948, acc: 53.91%] [G loss: 6.430392]\n",
      "epoch:33 step:26504 [D loss: 0.493600, acc: 69.53%] [G loss: 4.429545]\n",
      "epoch:33 step:26505 [D loss: 0.228648, acc: 97.66%] [G loss: 4.654337]\n",
      "epoch:33 step:26506 [D loss: 0.566011, acc: 63.28%] [G loss: 3.768769]\n",
      "epoch:33 step:26507 [D loss: 1.093029, acc: 43.75%] [G loss: 5.264939]\n",
      "epoch:33 step:26508 [D loss: 0.145467, acc: 99.22%] [G loss: 4.410748]\n",
      "epoch:33 step:26509 [D loss: 0.126206, acc: 100.00%] [G loss: 3.739123]\n",
      "epoch:33 step:26510 [D loss: 0.162044, acc: 99.22%] [G loss: 4.898413]\n",
      "epoch:33 step:26511 [D loss: 0.192925, acc: 98.44%] [G loss: 3.817171]\n",
      "epoch:33 step:26512 [D loss: 0.225868, acc: 97.66%] [G loss: 5.214076]\n",
      "epoch:33 step:26513 [D loss: 0.373804, acc: 92.19%] [G loss: 5.510966]\n",
      "epoch:33 step:26514 [D loss: 0.255008, acc: 99.22%] [G loss: 3.825013]\n",
      "epoch:33 step:26515 [D loss: 0.340806, acc: 85.94%] [G loss: 2.766991]\n",
      "epoch:33 step:26516 [D loss: 0.227965, acc: 97.66%] [G loss: 3.625196]\n",
      "epoch:33 step:26517 [D loss: 0.699147, acc: 57.81%] [G loss: 2.664193]\n",
      "epoch:33 step:26518 [D loss: 0.826275, acc: 49.22%] [G loss: 3.411459]\n",
      "epoch:33 step:26519 [D loss: 0.349062, acc: 94.53%] [G loss: 4.549581]\n",
      "epoch:33 step:26520 [D loss: 0.487096, acc: 75.78%] [G loss: 4.768839]\n",
      "epoch:33 step:26521 [D loss: 0.476246, acc: 81.25%] [G loss: 3.610910]\n",
      "epoch:33 step:26522 [D loss: 0.035541, acc: 100.00%] [G loss: 4.776038]\n",
      "epoch:33 step:26523 [D loss: 0.681460, acc: 60.16%] [G loss: 2.798123]\n",
      "epoch:33 step:26524 [D loss: 0.380218, acc: 79.69%] [G loss: 4.518383]\n",
      "epoch:33 step:26525 [D loss: 0.044212, acc: 100.00%] [G loss: 5.383945]\n",
      "epoch:33 step:26526 [D loss: 0.112462, acc: 99.22%] [G loss: 6.425634]\n",
      "epoch:33 step:26527 [D loss: 0.575812, acc: 69.53%] [G loss: 4.743584]\n",
      "epoch:33 step:26528 [D loss: 0.164326, acc: 98.44%] [G loss: 3.494239]\n",
      "epoch:33 step:26529 [D loss: 0.596321, acc: 64.84%] [G loss: 3.989175]\n",
      "epoch:33 step:26530 [D loss: 0.443603, acc: 78.91%] [G loss: 3.405770]\n",
      "epoch:33 step:26531 [D loss: 1.050109, acc: 35.94%] [G loss: 5.780033]\n",
      "epoch:33 step:26532 [D loss: 0.356446, acc: 88.28%] [G loss: 5.487529]\n",
      "epoch:33 step:26533 [D loss: 0.420662, acc: 67.97%] [G loss: 4.165363]\n",
      "epoch:33 step:26534 [D loss: 0.554625, acc: 65.62%] [G loss: 5.131470]\n",
      "epoch:33 step:26535 [D loss: 0.369883, acc: 89.84%] [G loss: 2.762851]\n",
      "epoch:33 step:26536 [D loss: 1.036883, acc: 50.78%] [G loss: 6.277401]\n",
      "epoch:33 step:26537 [D loss: 0.320431, acc: 88.28%] [G loss: 1.890833]\n",
      "epoch:33 step:26538 [D loss: 0.165060, acc: 98.44%] [G loss: 4.066577]\n",
      "epoch:33 step:26539 [D loss: 0.331364, acc: 93.75%] [G loss: 3.365044]\n",
      "epoch:33 step:26540 [D loss: 0.365199, acc: 89.06%] [G loss: 5.033902]\n",
      "epoch:33 step:26541 [D loss: 0.106021, acc: 100.00%] [G loss: 5.296456]\n",
      "epoch:33 step:26542 [D loss: 0.573262, acc: 63.28%] [G loss: 8.079140]\n",
      "epoch:33 step:26543 [D loss: 0.447323, acc: 82.03%] [G loss: 4.221276]\n",
      "epoch:33 step:26544 [D loss: 0.406387, acc: 86.72%] [G loss: 4.310427]\n",
      "epoch:33 step:26545 [D loss: 0.359702, acc: 89.84%] [G loss: 4.510734]\n",
      "epoch:33 step:26546 [D loss: 0.027282, acc: 100.00%] [G loss: 6.936793]\n",
      "epoch:33 step:26547 [D loss: 0.144423, acc: 100.00%] [G loss: 3.092266]\n",
      "epoch:33 step:26548 [D loss: 0.090278, acc: 100.00%] [G loss: 3.212167]\n",
      "epoch:33 step:26549 [D loss: 1.081730, acc: 35.16%] [G loss: 3.060365]\n",
      "epoch:33 step:26550 [D loss: 0.680382, acc: 57.03%] [G loss: 5.403503]\n",
      "epoch:33 step:26551 [D loss: 0.131147, acc: 98.44%] [G loss: 4.014852]\n",
      "epoch:33 step:26552 [D loss: 0.252270, acc: 93.75%] [G loss: 4.424925]\n",
      "epoch:33 step:26553 [D loss: 0.471347, acc: 88.28%] [G loss: 2.885666]\n",
      "epoch:33 step:26554 [D loss: 1.546823, acc: 25.00%] [G loss: 3.746464]\n",
      "epoch:34 step:26555 [D loss: 0.632666, acc: 54.69%] [G loss: 3.920336]\n",
      "epoch:34 step:26556 [D loss: 0.597252, acc: 59.38%] [G loss: 5.146570]\n",
      "epoch:34 step:26557 [D loss: 1.383401, acc: 10.94%] [G loss: 4.828575]\n",
      "epoch:34 step:26558 [D loss: 0.221541, acc: 99.22%] [G loss: 3.373110]\n",
      "epoch:34 step:26559 [D loss: 0.596990, acc: 63.28%] [G loss: 4.803301]\n",
      "epoch:34 step:26560 [D loss: 0.575989, acc: 71.88%] [G loss: 3.213488]\n",
      "epoch:34 step:26561 [D loss: 0.117336, acc: 100.00%] [G loss: 4.199575]\n",
      "epoch:34 step:26562 [D loss: 0.773173, acc: 53.91%] [G loss: 3.866700]\n",
      "epoch:34 step:26563 [D loss: 0.351379, acc: 85.94%] [G loss: 2.975560]\n",
      "epoch:34 step:26564 [D loss: 1.122178, acc: 29.69%] [G loss: 6.406421]\n",
      "epoch:34 step:26565 [D loss: 0.091664, acc: 100.00%] [G loss: 4.061359]\n",
      "epoch:34 step:26566 [D loss: 1.227845, acc: 46.88%] [G loss: 3.054290]\n",
      "epoch:34 step:26567 [D loss: 0.659915, acc: 56.25%] [G loss: 3.838682]\n",
      "epoch:34 step:26568 [D loss: 1.230631, acc: 20.31%] [G loss: 5.399047]\n",
      "epoch:34 step:26569 [D loss: 0.152428, acc: 97.66%] [G loss: 4.103555]\n",
      "epoch:34 step:26570 [D loss: 0.290691, acc: 96.09%] [G loss: 4.119942]\n",
      "epoch:34 step:26571 [D loss: 0.233204, acc: 94.53%] [G loss: 4.645713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26572 [D loss: 0.415197, acc: 85.16%] [G loss: 4.453301]\n",
      "epoch:34 step:26573 [D loss: 0.697860, acc: 56.25%] [G loss: 4.282508]\n",
      "epoch:34 step:26574 [D loss: 0.474288, acc: 77.34%] [G loss: 4.175118]\n",
      "epoch:34 step:26575 [D loss: 0.262097, acc: 95.31%] [G loss: 4.172427]\n",
      "epoch:34 step:26576 [D loss: 0.639310, acc: 60.94%] [G loss: 4.768550]\n",
      "epoch:34 step:26577 [D loss: 0.378065, acc: 88.28%] [G loss: 3.845495]\n",
      "epoch:34 step:26578 [D loss: 0.619511, acc: 60.94%] [G loss: 4.559998]\n",
      "epoch:34 step:26579 [D loss: 0.259623, acc: 89.84%] [G loss: 3.978932]\n",
      "epoch:34 step:26580 [D loss: 0.202429, acc: 98.44%] [G loss: 3.467424]\n",
      "epoch:34 step:26581 [D loss: 0.363605, acc: 89.06%] [G loss: 5.175985]\n",
      "epoch:34 step:26582 [D loss: 0.051933, acc: 100.00%] [G loss: 5.650500]\n",
      "epoch:34 step:26583 [D loss: 0.065152, acc: 100.00%] [G loss: 5.148838]\n",
      "epoch:34 step:26584 [D loss: 0.437573, acc: 70.31%] [G loss: 2.885522]\n",
      "epoch:34 step:26585 [D loss: 0.226246, acc: 92.19%] [G loss: 6.999018]\n",
      "epoch:34 step:26586 [D loss: 0.110813, acc: 100.00%] [G loss: 5.163883]\n",
      "epoch:34 step:26587 [D loss: 0.091530, acc: 100.00%] [G loss: 3.577071]\n",
      "epoch:34 step:26588 [D loss: 0.571915, acc: 68.75%] [G loss: 3.797234]\n",
      "epoch:34 step:26589 [D loss: 0.479114, acc: 78.91%] [G loss: 3.053013]\n",
      "epoch:34 step:26590 [D loss: 0.875302, acc: 50.00%] [G loss: 3.975705]\n",
      "epoch:34 step:26591 [D loss: 0.193624, acc: 98.44%] [G loss: 6.243084]\n",
      "epoch:34 step:26592 [D loss: 0.661326, acc: 57.03%] [G loss: 4.066220]\n",
      "epoch:34 step:26593 [D loss: 0.148252, acc: 100.00%] [G loss: 5.054461]\n",
      "epoch:34 step:26594 [D loss: 0.297552, acc: 93.75%] [G loss: 6.038578]\n",
      "epoch:34 step:26595 [D loss: 0.090269, acc: 99.22%] [G loss: 4.097929]\n",
      "epoch:34 step:26596 [D loss: 0.266220, acc: 94.53%] [G loss: 3.272537]\n",
      "epoch:34 step:26597 [D loss: 0.184227, acc: 96.09%] [G loss: 2.704861]\n",
      "epoch:34 step:26598 [D loss: 1.839848, acc: 48.44%] [G loss: 3.020250]\n",
      "epoch:34 step:26599 [D loss: 0.730916, acc: 51.56%] [G loss: 6.337409]\n",
      "epoch:34 step:26600 [D loss: 0.451904, acc: 73.44%] [G loss: 5.104828]\n",
      "epoch:34 step:26601 [D loss: 0.847612, acc: 48.44%] [G loss: 6.938562]\n",
      "epoch:34 step:26602 [D loss: 0.076474, acc: 100.00%] [G loss: 5.439860]\n",
      "epoch:34 step:26603 [D loss: 0.294924, acc: 96.09%] [G loss: 3.647465]\n",
      "epoch:34 step:26604 [D loss: 0.464763, acc: 82.81%] [G loss: 3.200629]\n",
      "epoch:34 step:26605 [D loss: 0.732709, acc: 51.56%] [G loss: 3.745088]\n",
      "epoch:34 step:26606 [D loss: 0.067865, acc: 100.00%] [G loss: 5.925651]\n",
      "epoch:34 step:26607 [D loss: 0.078092, acc: 100.00%] [G loss: 6.408239]\n",
      "epoch:34 step:26608 [D loss: 0.456510, acc: 71.09%] [G loss: 4.363719]\n",
      "epoch:34 step:26609 [D loss: 0.598360, acc: 72.66%] [G loss: 6.278646]\n",
      "epoch:34 step:26610 [D loss: 0.674282, acc: 57.81%] [G loss: 5.222761]\n",
      "epoch:34 step:26611 [D loss: 0.538965, acc: 73.44%] [G loss: 5.738914]\n",
      "epoch:34 step:26612 [D loss: 0.640223, acc: 65.62%] [G loss: 4.137691]\n",
      "epoch:34 step:26613 [D loss: 0.570485, acc: 73.44%] [G loss: 2.902295]\n",
      "epoch:34 step:26614 [D loss: 1.033924, acc: 26.56%] [G loss: 7.718115]\n",
      "epoch:34 step:26615 [D loss: 1.000398, acc: 42.19%] [G loss: 5.577395]\n",
      "epoch:34 step:26616 [D loss: 0.311322, acc: 95.31%] [G loss: 6.148761]\n",
      "epoch:34 step:26617 [D loss: 0.741496, acc: 55.47%] [G loss: 4.089622]\n",
      "epoch:34 step:26618 [D loss: 0.466019, acc: 64.84%] [G loss: 5.069369]\n",
      "epoch:34 step:26619 [D loss: 1.316993, acc: 32.81%] [G loss: 3.135722]\n",
      "epoch:34 step:26620 [D loss: 0.790338, acc: 55.47%] [G loss: 3.442502]\n",
      "epoch:34 step:26621 [D loss: 0.360245, acc: 86.72%] [G loss: 4.025422]\n",
      "epoch:34 step:26622 [D loss: 0.803357, acc: 52.34%] [G loss: 4.104549]\n",
      "epoch:34 step:26623 [D loss: 0.426192, acc: 85.94%] [G loss: 4.020958]\n",
      "epoch:34 step:26624 [D loss: 0.160168, acc: 98.44%] [G loss: 4.337215]\n",
      "epoch:34 step:26625 [D loss: 0.326618, acc: 83.59%] [G loss: 3.863865]\n",
      "epoch:34 step:26626 [D loss: 0.110970, acc: 99.22%] [G loss: 6.016158]\n",
      "epoch:34 step:26627 [D loss: 0.277031, acc: 98.44%] [G loss: 5.396302]\n",
      "epoch:34 step:26628 [D loss: 0.128144, acc: 100.00%] [G loss: 4.345190]\n",
      "epoch:34 step:26629 [D loss: 0.426133, acc: 74.22%] [G loss: 3.798331]\n",
      "epoch:34 step:26630 [D loss: 0.978994, acc: 27.34%] [G loss: 6.689303]\n",
      "epoch:34 step:26631 [D loss: 0.607797, acc: 64.06%] [G loss: 4.027653]\n",
      "epoch:34 step:26632 [D loss: 0.275780, acc: 92.97%] [G loss: 4.738684]\n",
      "epoch:34 step:26633 [D loss: 0.580442, acc: 71.09%] [G loss: 3.549628]\n",
      "epoch:34 step:26634 [D loss: 0.463367, acc: 82.81%] [G loss: 4.526739]\n",
      "epoch:34 step:26635 [D loss: 0.348149, acc: 83.59%] [G loss: 3.608257]\n",
      "epoch:34 step:26636 [D loss: 0.358539, acc: 85.16%] [G loss: 4.980296]\n",
      "epoch:34 step:26637 [D loss: 0.137887, acc: 98.44%] [G loss: 4.513465]\n",
      "epoch:34 step:26638 [D loss: 0.472909, acc: 67.97%] [G loss: 5.680264]\n",
      "epoch:34 step:26639 [D loss: 0.337698, acc: 85.16%] [G loss: 6.001132]\n",
      "epoch:34 step:26640 [D loss: 0.422024, acc: 82.81%] [G loss: 3.964438]\n",
      "epoch:34 step:26641 [D loss: 0.270887, acc: 92.19%] [G loss: 4.713134]\n",
      "epoch:34 step:26642 [D loss: 0.725005, acc: 57.03%] [G loss: 4.403621]\n",
      "epoch:34 step:26643 [D loss: 0.317005, acc: 85.16%] [G loss: 3.313451]\n",
      "epoch:34 step:26644 [D loss: 0.134131, acc: 98.44%] [G loss: 5.893621]\n",
      "epoch:34 step:26645 [D loss: 0.420359, acc: 71.88%] [G loss: 5.957536]\n",
      "epoch:34 step:26646 [D loss: 0.103021, acc: 100.00%] [G loss: 4.596827]\n",
      "epoch:34 step:26647 [D loss: 0.216723, acc: 95.31%] [G loss: 4.018349]\n",
      "epoch:34 step:26648 [D loss: 0.720361, acc: 54.69%] [G loss: 3.967583]\n",
      "epoch:34 step:26649 [D loss: 0.347988, acc: 85.94%] [G loss: 4.134550]\n",
      "epoch:34 step:26650 [D loss: 0.886425, acc: 50.00%] [G loss: 3.910494]\n",
      "epoch:34 step:26651 [D loss: 1.048141, acc: 50.00%] [G loss: 7.574484]\n",
      "epoch:34 step:26652 [D loss: 0.118316, acc: 99.22%] [G loss: 5.052060]\n",
      "epoch:34 step:26653 [D loss: 0.166477, acc: 97.66%] [G loss: 6.711669]\n",
      "epoch:34 step:26654 [D loss: 0.682904, acc: 56.25%] [G loss: 3.074352]\n",
      "epoch:34 step:26655 [D loss: 0.394192, acc: 75.00%] [G loss: 2.957437]\n",
      "epoch:34 step:26656 [D loss: 0.384905, acc: 83.59%] [G loss: 4.586711]\n",
      "epoch:34 step:26657 [D loss: 0.133676, acc: 98.44%] [G loss: 4.508347]\n",
      "epoch:34 step:26658 [D loss: 0.116960, acc: 100.00%] [G loss: 4.329611]\n",
      "epoch:34 step:26659 [D loss: 0.163917, acc: 97.66%] [G loss: 4.731960]\n",
      "epoch:34 step:26660 [D loss: 0.357886, acc: 85.94%] [G loss: 2.966817]\n",
      "epoch:34 step:26661 [D loss: 0.172150, acc: 100.00%] [G loss: 2.379089]\n",
      "epoch:34 step:26662 [D loss: 0.730215, acc: 58.59%] [G loss: 5.905414]\n",
      "epoch:34 step:26663 [D loss: 0.650061, acc: 64.84%] [G loss: 4.658699]\n",
      "epoch:34 step:26664 [D loss: 1.598846, acc: 29.69%] [G loss: 3.392006]\n",
      "epoch:34 step:26665 [D loss: 0.404898, acc: 85.16%] [G loss: 4.249520]\n",
      "epoch:34 step:26666 [D loss: 0.588613, acc: 66.41%] [G loss: 5.696821]\n",
      "epoch:34 step:26667 [D loss: 0.825435, acc: 51.56%] [G loss: 4.061601]\n",
      "epoch:34 step:26668 [D loss: 0.768481, acc: 53.91%] [G loss: 7.232368]\n",
      "epoch:34 step:26669 [D loss: 0.172226, acc: 96.88%] [G loss: 3.465290]\n",
      "epoch:34 step:26670 [D loss: 0.525759, acc: 72.66%] [G loss: 2.472423]\n",
      "epoch:34 step:26671 [D loss: 0.438375, acc: 85.94%] [G loss: 3.870867]\n",
      "epoch:34 step:26672 [D loss: 0.371974, acc: 77.34%] [G loss: 2.170287]\n",
      "epoch:34 step:26673 [D loss: 0.526380, acc: 67.19%] [G loss: 5.125988]\n",
      "epoch:34 step:26674 [D loss: 0.638199, acc: 64.06%] [G loss: 5.090246]\n",
      "epoch:34 step:26675 [D loss: 0.556835, acc: 70.31%] [G loss: 6.599305]\n",
      "epoch:34 step:26676 [D loss: 0.139803, acc: 98.44%] [G loss: 5.612051]\n",
      "epoch:34 step:26677 [D loss: 0.751950, acc: 52.34%] [G loss: 3.845513]\n",
      "epoch:34 step:26678 [D loss: 0.266834, acc: 89.84%] [G loss: 3.078140]\n",
      "epoch:34 step:26679 [D loss: 1.059724, acc: 50.00%] [G loss: 5.047030]\n",
      "epoch:34 step:26680 [D loss: 0.392154, acc: 86.72%] [G loss: 3.605374]\n",
      "epoch:34 step:26681 [D loss: 0.183044, acc: 99.22%] [G loss: 3.714289]\n",
      "epoch:34 step:26682 [D loss: 0.348901, acc: 89.06%] [G loss: 5.125786]\n",
      "epoch:34 step:26683 [D loss: 0.140633, acc: 100.00%] [G loss: 4.178791]\n",
      "epoch:34 step:26684 [D loss: 0.433385, acc: 75.78%] [G loss: 3.561699]\n",
      "epoch:34 step:26685 [D loss: 0.136206, acc: 98.44%] [G loss: 2.607517]\n",
      "epoch:34 step:26686 [D loss: 0.367083, acc: 83.59%] [G loss: 4.520558]\n",
      "epoch:34 step:26687 [D loss: 0.186685, acc: 99.22%] [G loss: 3.791935]\n",
      "epoch:34 step:26688 [D loss: 0.133967, acc: 97.66%] [G loss: 3.905315]\n",
      "epoch:34 step:26689 [D loss: 0.479028, acc: 72.66%] [G loss: 5.031617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26690 [D loss: 0.199031, acc: 96.88%] [G loss: 4.515680]\n",
      "epoch:34 step:26691 [D loss: 0.174589, acc: 96.09%] [G loss: 4.831401]\n",
      "epoch:34 step:26692 [D loss: 0.839479, acc: 53.12%] [G loss: 4.495544]\n",
      "epoch:34 step:26693 [D loss: 0.106101, acc: 99.22%] [G loss: 3.603149]\n",
      "epoch:34 step:26694 [D loss: 0.401448, acc: 86.72%] [G loss: 3.446388]\n",
      "epoch:34 step:26695 [D loss: 1.165285, acc: 51.56%] [G loss: 4.437431]\n",
      "epoch:34 step:26696 [D loss: 0.485214, acc: 70.31%] [G loss: 5.426672]\n",
      "epoch:34 step:26697 [D loss: 0.300253, acc: 89.06%] [G loss: 3.437660]\n",
      "epoch:34 step:26698 [D loss: 1.435118, acc: 12.50%] [G loss: 6.510657]\n",
      "epoch:34 step:26699 [D loss: 0.898108, acc: 48.44%] [G loss: 3.223645]\n",
      "epoch:34 step:26700 [D loss: 0.173676, acc: 100.00%] [G loss: 3.461378]\n",
      "epoch:34 step:26701 [D loss: 0.705759, acc: 59.38%] [G loss: 3.129382]\n",
      "epoch:34 step:26702 [D loss: 0.147560, acc: 100.00%] [G loss: 3.560583]\n",
      "epoch:34 step:26703 [D loss: 0.178189, acc: 97.66%] [G loss: 3.586944]\n",
      "epoch:34 step:26704 [D loss: 0.525098, acc: 72.66%] [G loss: 5.206104]\n",
      "epoch:34 step:26705 [D loss: 0.093984, acc: 99.22%] [G loss: 2.991508]\n",
      "epoch:34 step:26706 [D loss: 0.064907, acc: 100.00%] [G loss: 6.166170]\n",
      "epoch:34 step:26707 [D loss: 0.372966, acc: 82.03%] [G loss: 1.515080]\n",
      "epoch:34 step:26708 [D loss: 0.445511, acc: 82.03%] [G loss: 5.366965]\n",
      "epoch:34 step:26709 [D loss: 0.720726, acc: 50.78%] [G loss: 2.823463]\n",
      "epoch:34 step:26710 [D loss: 0.537095, acc: 69.53%] [G loss: 5.659395]\n",
      "epoch:34 step:26711 [D loss: 0.282731, acc: 90.62%] [G loss: 4.050601]\n",
      "epoch:34 step:26712 [D loss: 0.365943, acc: 89.84%] [G loss: 2.634232]\n",
      "epoch:34 step:26713 [D loss: 0.043619, acc: 100.00%] [G loss: 6.123267]\n",
      "epoch:34 step:26714 [D loss: 0.254908, acc: 93.75%] [G loss: 2.820606]\n",
      "epoch:34 step:26715 [D loss: 0.224569, acc: 95.31%] [G loss: 5.191414]\n",
      "epoch:34 step:26716 [D loss: 0.443014, acc: 71.88%] [G loss: 6.469953]\n",
      "epoch:34 step:26717 [D loss: 0.277860, acc: 89.84%] [G loss: 5.339208]\n",
      "epoch:34 step:26718 [D loss: 0.505062, acc: 67.97%] [G loss: 4.115130]\n",
      "epoch:34 step:26719 [D loss: 0.429233, acc: 76.56%] [G loss: 3.824843]\n",
      "epoch:34 step:26720 [D loss: 0.389527, acc: 85.94%] [G loss: 5.848745]\n",
      "epoch:34 step:26721 [D loss: 0.376996, acc: 91.41%] [G loss: 3.947941]\n",
      "epoch:34 step:26722 [D loss: 0.603045, acc: 68.75%] [G loss: 4.744438]\n",
      "epoch:34 step:26723 [D loss: 0.295045, acc: 95.31%] [G loss: 2.979648]\n",
      "epoch:34 step:26724 [D loss: 0.601403, acc: 66.41%] [G loss: 4.852360]\n",
      "epoch:34 step:26725 [D loss: 0.378934, acc: 79.69%] [G loss: 3.231306]\n",
      "epoch:34 step:26726 [D loss: 0.644661, acc: 60.94%] [G loss: 4.163900]\n",
      "epoch:34 step:26727 [D loss: 0.262405, acc: 92.19%] [G loss: 4.467834]\n",
      "epoch:34 step:26728 [D loss: 0.501444, acc: 63.28%] [G loss: 4.944671]\n",
      "epoch:34 step:26729 [D loss: 0.474914, acc: 83.59%] [G loss: 3.413049]\n",
      "epoch:34 step:26730 [D loss: 0.896425, acc: 39.84%] [G loss: 5.944866]\n",
      "epoch:34 step:26731 [D loss: 0.341352, acc: 85.94%] [G loss: 3.983792]\n",
      "epoch:34 step:26732 [D loss: 0.752488, acc: 50.78%] [G loss: 3.432341]\n",
      "epoch:34 step:26733 [D loss: 0.258736, acc: 96.09%] [G loss: 6.063377]\n",
      "epoch:34 step:26734 [D loss: 0.326833, acc: 82.03%] [G loss: 5.554302]\n",
      "epoch:34 step:26735 [D loss: 0.166190, acc: 97.66%] [G loss: 4.185506]\n",
      "epoch:34 step:26736 [D loss: 0.474849, acc: 68.75%] [G loss: 4.597106]\n",
      "epoch:34 step:26737 [D loss: 0.177779, acc: 98.44%] [G loss: 4.452775]\n",
      "epoch:34 step:26738 [D loss: 0.316792, acc: 96.09%] [G loss: 3.087113]\n",
      "epoch:34 step:26739 [D loss: 0.385604, acc: 73.44%] [G loss: 7.034483]\n",
      "epoch:34 step:26740 [D loss: 0.533560, acc: 59.38%] [G loss: 4.638667]\n",
      "epoch:34 step:26741 [D loss: 0.057138, acc: 100.00%] [G loss: 5.830977]\n",
      "epoch:34 step:26742 [D loss: 1.031675, acc: 35.16%] [G loss: 7.105771]\n",
      "epoch:34 step:26743 [D loss: 0.080031, acc: 100.00%] [G loss: 6.807441]\n",
      "epoch:34 step:26744 [D loss: 0.398233, acc: 89.06%] [G loss: 4.902190]\n",
      "epoch:34 step:26745 [D loss: 0.152316, acc: 100.00%] [G loss: 4.338362]\n",
      "epoch:34 step:26746 [D loss: 0.116304, acc: 100.00%] [G loss: 5.079847]\n",
      "epoch:34 step:26747 [D loss: 0.403573, acc: 85.94%] [G loss: 4.812636]\n",
      "epoch:34 step:26748 [D loss: 0.161969, acc: 100.00%] [G loss: 5.355210]\n",
      "epoch:34 step:26749 [D loss: 0.600515, acc: 67.97%] [G loss: 4.260398]\n",
      "epoch:34 step:26750 [D loss: 0.332958, acc: 85.16%] [G loss: 6.064801]\n",
      "epoch:34 step:26751 [D loss: 0.147063, acc: 98.44%] [G loss: 3.636386]\n",
      "epoch:34 step:26752 [D loss: 0.071805, acc: 100.00%] [G loss: 3.746791]\n",
      "epoch:34 step:26753 [D loss: 0.340443, acc: 91.41%] [G loss: 3.071347]\n",
      "epoch:34 step:26754 [D loss: 0.043642, acc: 100.00%] [G loss: 4.102842]\n",
      "epoch:34 step:26755 [D loss: 0.247439, acc: 96.88%] [G loss: 3.022503]\n",
      "epoch:34 step:26756 [D loss: 0.169134, acc: 99.22%] [G loss: 3.526326]\n",
      "epoch:34 step:26757 [D loss: 1.117157, acc: 50.78%] [G loss: 3.854629]\n",
      "epoch:34 step:26758 [D loss: 1.167871, acc: 46.09%] [G loss: 5.263421]\n",
      "epoch:34 step:26759 [D loss: 0.670800, acc: 55.47%] [G loss: 2.524626]\n",
      "epoch:34 step:26760 [D loss: 0.124909, acc: 100.00%] [G loss: 7.362386]\n",
      "epoch:34 step:26761 [D loss: 0.372569, acc: 90.62%] [G loss: 5.066341]\n",
      "epoch:34 step:26762 [D loss: 0.311527, acc: 90.62%] [G loss: 4.198445]\n",
      "epoch:34 step:26763 [D loss: 0.463186, acc: 87.50%] [G loss: 4.513898]\n",
      "epoch:34 step:26764 [D loss: 1.390190, acc: 46.09%] [G loss: 3.746255]\n",
      "epoch:34 step:26765 [D loss: 1.552958, acc: 10.94%] [G loss: 4.092968]\n",
      "epoch:34 step:26766 [D loss: 0.056072, acc: 100.00%] [G loss: 3.898752]\n",
      "epoch:34 step:26767 [D loss: 0.300589, acc: 89.06%] [G loss: 5.545886]\n",
      "epoch:34 step:26768 [D loss: 0.347623, acc: 88.28%] [G loss: 3.002539]\n",
      "epoch:34 step:26769 [D loss: 0.135591, acc: 99.22%] [G loss: 3.640589]\n",
      "epoch:34 step:26770 [D loss: 1.052720, acc: 40.62%] [G loss: 4.246418]\n",
      "epoch:34 step:26771 [D loss: 0.785614, acc: 52.34%] [G loss: 4.154118]\n",
      "epoch:34 step:26772 [D loss: 0.246332, acc: 96.88%] [G loss: 4.773596]\n",
      "epoch:34 step:26773 [D loss: 1.217496, acc: 22.66%] [G loss: 3.644389]\n",
      "epoch:34 step:26774 [D loss: 0.506879, acc: 77.34%] [G loss: 3.305123]\n",
      "epoch:34 step:26775 [D loss: 0.241122, acc: 95.31%] [G loss: 4.351310]\n",
      "epoch:34 step:26776 [D loss: 0.398689, acc: 85.16%] [G loss: 3.135880]\n",
      "epoch:34 step:26777 [D loss: 0.639937, acc: 64.06%] [G loss: 5.959376]\n",
      "epoch:34 step:26778 [D loss: 0.507352, acc: 67.19%] [G loss: 6.402193]\n",
      "epoch:34 step:26779 [D loss: 0.267883, acc: 96.09%] [G loss: 2.459117]\n",
      "epoch:34 step:26780 [D loss: 0.410874, acc: 78.91%] [G loss: 4.845743]\n",
      "epoch:34 step:26781 [D loss: 0.082098, acc: 100.00%] [G loss: 5.141451]\n",
      "epoch:34 step:26782 [D loss: 0.104988, acc: 99.22%] [G loss: 4.285549]\n",
      "epoch:34 step:26783 [D loss: 0.220400, acc: 96.88%] [G loss: 2.699573]\n",
      "epoch:34 step:26784 [D loss: 0.465352, acc: 79.69%] [G loss: 4.514120]\n",
      "epoch:34 step:26785 [D loss: 0.441259, acc: 85.16%] [G loss: 2.598790]\n",
      "epoch:34 step:26786 [D loss: 0.252622, acc: 93.75%] [G loss: 2.692384]\n",
      "epoch:34 step:26787 [D loss: 0.077551, acc: 100.00%] [G loss: 5.597391]\n",
      "epoch:34 step:26788 [D loss: 0.971673, acc: 25.00%] [G loss: 2.506316]\n",
      "epoch:34 step:26789 [D loss: 0.198011, acc: 98.44%] [G loss: 2.703431]\n",
      "epoch:34 step:26790 [D loss: 0.246410, acc: 96.88%] [G loss: 2.769459]\n",
      "epoch:34 step:26791 [D loss: 0.661540, acc: 60.94%] [G loss: 4.095052]\n",
      "epoch:34 step:26792 [D loss: 0.650269, acc: 54.69%] [G loss: 6.217201]\n",
      "epoch:34 step:26793 [D loss: 0.717987, acc: 59.38%] [G loss: 3.910580]\n",
      "epoch:34 step:26794 [D loss: 0.292897, acc: 88.28%] [G loss: 4.427569]\n",
      "epoch:34 step:26795 [D loss: 0.384134, acc: 75.78%] [G loss: 4.415894]\n",
      "epoch:34 step:26796 [D loss: 0.224049, acc: 94.53%] [G loss: 5.426435]\n",
      "epoch:34 step:26797 [D loss: 0.131014, acc: 99.22%] [G loss: 3.127169]\n",
      "epoch:34 step:26798 [D loss: 0.493599, acc: 79.69%] [G loss: 3.962192]\n",
      "epoch:34 step:26799 [D loss: 0.303200, acc: 95.31%] [G loss: 4.478989]\n",
      "epoch:34 step:26800 [D loss: 0.483863, acc: 70.31%] [G loss: 4.304241]\n",
      "epoch:34 step:26801 [D loss: 2.220939, acc: 2.34%] [G loss: 5.472404]\n",
      "epoch:34 step:26802 [D loss: 0.292614, acc: 92.19%] [G loss: 2.569513]\n",
      "epoch:34 step:26803 [D loss: 0.275946, acc: 91.41%] [G loss: 5.373252]\n",
      "epoch:34 step:26804 [D loss: 0.169958, acc: 97.66%] [G loss: 5.139205]\n",
      "epoch:34 step:26805 [D loss: 0.231463, acc: 96.88%] [G loss: 3.779532]\n",
      "epoch:34 step:26806 [D loss: 1.083740, acc: 30.47%] [G loss: 3.540673]\n",
      "epoch:34 step:26807 [D loss: 0.840662, acc: 39.06%] [G loss: 3.422424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26808 [D loss: 0.648624, acc: 52.34%] [G loss: 3.365824]\n",
      "epoch:34 step:26809 [D loss: 0.185215, acc: 100.00%] [G loss: 6.157193]\n",
      "epoch:34 step:26810 [D loss: 0.980778, acc: 25.00%] [G loss: 6.187697]\n",
      "epoch:34 step:26811 [D loss: 1.186360, acc: 50.00%] [G loss: 3.394916]\n",
      "epoch:34 step:26812 [D loss: 0.319565, acc: 96.09%] [G loss: 7.081713]\n",
      "epoch:34 step:26813 [D loss: 0.330509, acc: 89.06%] [G loss: 2.662405]\n",
      "epoch:34 step:26814 [D loss: 0.143360, acc: 99.22%] [G loss: 4.983018]\n",
      "epoch:34 step:26815 [D loss: 0.451240, acc: 75.00%] [G loss: 3.172191]\n",
      "epoch:34 step:26816 [D loss: 0.204519, acc: 96.88%] [G loss: 4.182112]\n",
      "epoch:34 step:26817 [D loss: 0.404238, acc: 90.62%] [G loss: 4.294038]\n",
      "epoch:34 step:26818 [D loss: 0.813780, acc: 47.66%] [G loss: 3.668010]\n",
      "epoch:34 step:26819 [D loss: 0.251336, acc: 96.88%] [G loss: 2.604079]\n",
      "epoch:34 step:26820 [D loss: 0.485255, acc: 78.12%] [G loss: 4.631450]\n",
      "epoch:34 step:26821 [D loss: 0.054619, acc: 99.22%] [G loss: 3.089133]\n",
      "epoch:34 step:26822 [D loss: 0.127895, acc: 98.44%] [G loss: 2.699155]\n",
      "epoch:34 step:26823 [D loss: 0.360723, acc: 87.50%] [G loss: 3.391772]\n",
      "epoch:34 step:26824 [D loss: 1.492897, acc: 33.59%] [G loss: 3.321094]\n",
      "epoch:34 step:26825 [D loss: 0.337381, acc: 92.97%] [G loss: 2.651232]\n",
      "epoch:34 step:26826 [D loss: 0.139710, acc: 99.22%] [G loss: 2.917231]\n",
      "epoch:34 step:26827 [D loss: 0.288011, acc: 96.09%] [G loss: 3.041934]\n",
      "epoch:34 step:26828 [D loss: 0.843864, acc: 44.53%] [G loss: 4.720760]\n",
      "epoch:34 step:26829 [D loss: 0.210737, acc: 96.88%] [G loss: 5.990522]\n",
      "epoch:34 step:26830 [D loss: 0.550668, acc: 64.06%] [G loss: 4.587060]\n",
      "epoch:34 step:26831 [D loss: 0.568130, acc: 73.44%] [G loss: 5.889294]\n",
      "epoch:34 step:26832 [D loss: 0.259884, acc: 94.53%] [G loss: 4.626365]\n",
      "epoch:34 step:26833 [D loss: 0.585527, acc: 62.50%] [G loss: 3.646578]\n",
      "epoch:34 step:26834 [D loss: 0.377225, acc: 84.38%] [G loss: 3.457589]\n",
      "epoch:34 step:26835 [D loss: 0.481953, acc: 78.12%] [G loss: 3.379598]\n",
      "epoch:34 step:26836 [D loss: 0.279916, acc: 94.53%] [G loss: 4.041188]\n",
      "epoch:34 step:26837 [D loss: 0.354624, acc: 94.53%] [G loss: 4.013935]\n",
      "epoch:34 step:26838 [D loss: 0.577627, acc: 65.62%] [G loss: 3.644844]\n",
      "epoch:34 step:26839 [D loss: 0.262766, acc: 98.44%] [G loss: 2.965235]\n",
      "epoch:34 step:26840 [D loss: 0.424153, acc: 74.22%] [G loss: 6.411744]\n",
      "epoch:34 step:26841 [D loss: 0.225858, acc: 97.66%] [G loss: 5.118546]\n",
      "epoch:34 step:26842 [D loss: 0.153838, acc: 100.00%] [G loss: 4.246750]\n",
      "epoch:34 step:26843 [D loss: 0.454163, acc: 78.91%] [G loss: 7.482950]\n",
      "epoch:34 step:26844 [D loss: 0.327330, acc: 82.81%] [G loss: 4.034110]\n",
      "epoch:34 step:26845 [D loss: 0.657257, acc: 59.38%] [G loss: 2.744269]\n",
      "epoch:34 step:26846 [D loss: 0.215973, acc: 97.66%] [G loss: 5.743881]\n",
      "epoch:34 step:26847 [D loss: 0.436009, acc: 70.31%] [G loss: 5.418764]\n",
      "epoch:34 step:26848 [D loss: 0.393751, acc: 92.19%] [G loss: 3.376851]\n",
      "epoch:34 step:26849 [D loss: 0.640339, acc: 62.50%] [G loss: 3.357703]\n",
      "epoch:34 step:26850 [D loss: 0.280352, acc: 90.62%] [G loss: 7.519374]\n",
      "epoch:34 step:26851 [D loss: 0.741551, acc: 53.12%] [G loss: 4.778230]\n",
      "epoch:34 step:26852 [D loss: 0.109811, acc: 98.44%] [G loss: 3.474397]\n",
      "epoch:34 step:26853 [D loss: 0.285406, acc: 93.75%] [G loss: 2.434266]\n",
      "epoch:34 step:26854 [D loss: 0.565766, acc: 75.00%] [G loss: 5.173261]\n",
      "epoch:34 step:26855 [D loss: 0.228849, acc: 97.66%] [G loss: 5.068881]\n",
      "epoch:34 step:26856 [D loss: 0.196608, acc: 98.44%] [G loss: 5.465819]\n",
      "epoch:34 step:26857 [D loss: 0.494379, acc: 79.69%] [G loss: 5.532506]\n",
      "epoch:34 step:26858 [D loss: 1.189994, acc: 17.19%] [G loss: 4.328743]\n",
      "epoch:34 step:26859 [D loss: 0.353084, acc: 86.72%] [G loss: 2.988713]\n",
      "epoch:34 step:26860 [D loss: 0.165751, acc: 100.00%] [G loss: 3.531376]\n",
      "epoch:34 step:26861 [D loss: 0.469476, acc: 68.75%] [G loss: 5.041712]\n",
      "epoch:34 step:26862 [D loss: 0.569175, acc: 57.03%] [G loss: 6.709003]\n",
      "epoch:34 step:26863 [D loss: 0.087451, acc: 100.00%] [G loss: 3.720409]\n",
      "epoch:34 step:26864 [D loss: 0.535575, acc: 62.50%] [G loss: 5.107477]\n",
      "epoch:34 step:26865 [D loss: 0.343496, acc: 90.62%] [G loss: 4.406140]\n",
      "epoch:34 step:26866 [D loss: 0.278264, acc: 94.53%] [G loss: 3.104506]\n",
      "epoch:34 step:26867 [D loss: 0.035340, acc: 100.00%] [G loss: 6.898313]\n",
      "epoch:34 step:26868 [D loss: 0.175337, acc: 96.88%] [G loss: 3.810254]\n",
      "epoch:34 step:26869 [D loss: 0.601356, acc: 69.53%] [G loss: 4.356029]\n",
      "epoch:34 step:26870 [D loss: 0.088684, acc: 98.44%] [G loss: 3.296060]\n",
      "epoch:34 step:26871 [D loss: 0.413337, acc: 79.69%] [G loss: 4.764784]\n",
      "epoch:34 step:26872 [D loss: 0.169826, acc: 99.22%] [G loss: 3.391478]\n",
      "epoch:34 step:26873 [D loss: 0.277764, acc: 92.19%] [G loss: 5.546091]\n",
      "epoch:34 step:26874 [D loss: 0.407251, acc: 84.38%] [G loss: 3.748174]\n",
      "epoch:34 step:26875 [D loss: 0.507185, acc: 78.91%] [G loss: 4.618990]\n",
      "epoch:34 step:26876 [D loss: 0.381678, acc: 88.28%] [G loss: 5.481039]\n",
      "epoch:34 step:26877 [D loss: 0.297112, acc: 86.72%] [G loss: 5.040002]\n",
      "epoch:34 step:26878 [D loss: 0.061253, acc: 100.00%] [G loss: 3.879228]\n",
      "epoch:34 step:26879 [D loss: 0.341678, acc: 93.75%] [G loss: 3.880381]\n",
      "epoch:34 step:26880 [D loss: 0.323265, acc: 91.41%] [G loss: 2.786133]\n",
      "epoch:34 step:26881 [D loss: 0.211086, acc: 96.09%] [G loss: 4.983964]\n",
      "epoch:34 step:26882 [D loss: 0.133510, acc: 99.22%] [G loss: 5.045485]\n",
      "epoch:34 step:26883 [D loss: 2.041479, acc: 50.00%] [G loss: 3.123347]\n",
      "epoch:34 step:26884 [D loss: 0.418222, acc: 76.56%] [G loss: 3.802121]\n",
      "epoch:34 step:26885 [D loss: 0.611848, acc: 60.16%] [G loss: 4.751532]\n",
      "epoch:34 step:26886 [D loss: 0.421698, acc: 77.34%] [G loss: 4.912825]\n",
      "epoch:34 step:26887 [D loss: 0.482386, acc: 60.16%] [G loss: 5.303476]\n",
      "epoch:34 step:26888 [D loss: 0.208969, acc: 98.44%] [G loss: 3.925263]\n",
      "epoch:34 step:26889 [D loss: 0.139103, acc: 98.44%] [G loss: 5.990110]\n",
      "epoch:34 step:26890 [D loss: 0.240636, acc: 94.53%] [G loss: 5.608234]\n",
      "epoch:34 step:26891 [D loss: 0.743827, acc: 58.59%] [G loss: 3.967152]\n",
      "epoch:34 step:26892 [D loss: 0.980714, acc: 52.34%] [G loss: 6.497142]\n",
      "epoch:34 step:26893 [D loss: 0.710928, acc: 54.69%] [G loss: 4.433054]\n",
      "epoch:34 step:26894 [D loss: 0.136990, acc: 100.00%] [G loss: 7.609210]\n",
      "epoch:34 step:26895 [D loss: 0.199894, acc: 100.00%] [G loss: 5.761420]\n",
      "epoch:34 step:26896 [D loss: 0.413258, acc: 82.81%] [G loss: 6.315626]\n",
      "epoch:34 step:26897 [D loss: 0.295262, acc: 92.19%] [G loss: 4.277579]\n",
      "epoch:34 step:26898 [D loss: 0.380144, acc: 90.62%] [G loss: 3.792253]\n",
      "epoch:34 step:26899 [D loss: 0.291810, acc: 86.72%] [G loss: 6.018978]\n",
      "epoch:34 step:26900 [D loss: 0.688100, acc: 56.25%] [G loss: 5.289010]\n",
      "epoch:34 step:26901 [D loss: 0.440793, acc: 65.62%] [G loss: 4.391418]\n",
      "epoch:34 step:26902 [D loss: 1.083290, acc: 50.78%] [G loss: 4.940279]\n",
      "epoch:34 step:26903 [D loss: 0.359506, acc: 92.97%] [G loss: 4.587116]\n",
      "epoch:34 step:26904 [D loss: 0.126414, acc: 99.22%] [G loss: 2.686539]\n",
      "epoch:34 step:26905 [D loss: 0.282623, acc: 93.75%] [G loss: 3.738648]\n",
      "epoch:34 step:26906 [D loss: 0.069238, acc: 100.00%] [G loss: 2.417757]\n",
      "epoch:34 step:26907 [D loss: 0.469762, acc: 82.03%] [G loss: 5.040565]\n",
      "epoch:34 step:26908 [D loss: 0.343797, acc: 92.19%] [G loss: 4.579832]\n",
      "epoch:34 step:26909 [D loss: 1.173333, acc: 50.00%] [G loss: 2.723089]\n",
      "epoch:34 step:26910 [D loss: 0.630178, acc: 61.72%] [G loss: 3.336760]\n",
      "epoch:34 step:26911 [D loss: 0.336985, acc: 92.19%] [G loss: 2.979808]\n",
      "epoch:34 step:26912 [D loss: 0.362188, acc: 85.94%] [G loss: 2.612369]\n",
      "epoch:34 step:26913 [D loss: 0.099995, acc: 100.00%] [G loss: 6.743208]\n",
      "epoch:34 step:26914 [D loss: 0.197124, acc: 100.00%] [G loss: 3.379317]\n",
      "epoch:34 step:26915 [D loss: 0.066139, acc: 100.00%] [G loss: 2.793853]\n",
      "epoch:34 step:26916 [D loss: 0.222046, acc: 97.66%] [G loss: 4.020814]\n",
      "epoch:34 step:26917 [D loss: 0.097828, acc: 99.22%] [G loss: 5.265774]\n",
      "epoch:34 step:26918 [D loss: 0.223762, acc: 98.44%] [G loss: 4.375599]\n",
      "epoch:34 step:26919 [D loss: 0.064692, acc: 100.00%] [G loss: 6.419042]\n",
      "epoch:34 step:26920 [D loss: 0.304430, acc: 92.19%] [G loss: 4.875151]\n",
      "epoch:34 step:26921 [D loss: 0.249440, acc: 96.09%] [G loss: 2.325675]\n",
      "epoch:34 step:26922 [D loss: 0.394560, acc: 88.28%] [G loss: 3.524141]\n",
      "epoch:34 step:26923 [D loss: 0.152155, acc: 99.22%] [G loss: 5.208644]\n",
      "epoch:34 step:26924 [D loss: 0.303381, acc: 97.66%] [G loss: 2.300576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26925 [D loss: 0.130404, acc: 99.22%] [G loss: 3.882238]\n",
      "epoch:34 step:26926 [D loss: 1.183146, acc: 14.84%] [G loss: 4.259358]\n",
      "epoch:34 step:26927 [D loss: 1.667360, acc: 3.91%] [G loss: 4.415001]\n",
      "epoch:34 step:26928 [D loss: 0.316905, acc: 78.91%] [G loss: 3.878700]\n",
      "epoch:34 step:26929 [D loss: 0.599576, acc: 71.88%] [G loss: 3.878303]\n",
      "epoch:34 step:26930 [D loss: 0.420755, acc: 67.97%] [G loss: 4.901371]\n",
      "epoch:34 step:26931 [D loss: 0.167621, acc: 100.00%] [G loss: 5.333145]\n",
      "epoch:34 step:26932 [D loss: 0.201301, acc: 95.31%] [G loss: 3.436452]\n",
      "epoch:34 step:26933 [D loss: 0.604173, acc: 58.59%] [G loss: 6.238759]\n",
      "epoch:34 step:26934 [D loss: 0.197060, acc: 96.88%] [G loss: 6.318602]\n",
      "epoch:34 step:26935 [D loss: 0.398281, acc: 85.94%] [G loss: 2.349022]\n",
      "epoch:34 step:26936 [D loss: 0.887297, acc: 39.06%] [G loss: 6.163147]\n",
      "epoch:34 step:26937 [D loss: 0.190197, acc: 99.22%] [G loss: 4.091244]\n",
      "epoch:34 step:26938 [D loss: 0.790644, acc: 51.56%] [G loss: 5.867852]\n",
      "epoch:34 step:26939 [D loss: 0.429250, acc: 87.50%] [G loss: 2.705526]\n",
      "epoch:34 step:26940 [D loss: 1.785936, acc: 24.22%] [G loss: 5.923458]\n",
      "epoch:34 step:26941 [D loss: 0.264527, acc: 96.09%] [G loss: 4.701575]\n",
      "epoch:34 step:26942 [D loss: 0.333312, acc: 92.97%] [G loss: 2.742203]\n",
      "epoch:34 step:26943 [D loss: 0.193596, acc: 92.19%] [G loss: 3.512984]\n",
      "epoch:34 step:26944 [D loss: 0.896979, acc: 38.28%] [G loss: 4.038961]\n",
      "epoch:34 step:26945 [D loss: 0.303344, acc: 94.53%] [G loss: 3.614765]\n",
      "epoch:34 step:26946 [D loss: 0.033932, acc: 100.00%] [G loss: 7.230090]\n",
      "epoch:34 step:26947 [D loss: 0.064229, acc: 100.00%] [G loss: 5.303152]\n",
      "epoch:34 step:26948 [D loss: 0.313060, acc: 92.19%] [G loss: 3.363203]\n",
      "epoch:34 step:26949 [D loss: 0.198953, acc: 99.22%] [G loss: 6.001594]\n",
      "epoch:34 step:26950 [D loss: 0.274758, acc: 95.31%] [G loss: 4.121243]\n",
      "epoch:34 step:26951 [D loss: 0.353633, acc: 82.03%] [G loss: 2.758924]\n",
      "epoch:34 step:26952 [D loss: 0.832469, acc: 50.00%] [G loss: 3.718307]\n",
      "epoch:34 step:26953 [D loss: 0.128719, acc: 100.00%] [G loss: 4.890600]\n",
      "epoch:34 step:26954 [D loss: 0.504138, acc: 64.84%] [G loss: 3.153386]\n",
      "epoch:34 step:26955 [D loss: 0.785010, acc: 54.69%] [G loss: 3.287670]\n",
      "epoch:34 step:26956 [D loss: 0.834399, acc: 51.56%] [G loss: 1.245078]\n",
      "epoch:34 step:26957 [D loss: 0.590543, acc: 61.72%] [G loss: 5.252474]\n",
      "epoch:34 step:26958 [D loss: 0.493890, acc: 81.25%] [G loss: 3.362198]\n",
      "epoch:34 step:26959 [D loss: 0.717795, acc: 53.12%] [G loss: 3.836124]\n",
      "epoch:34 step:26960 [D loss: 0.406728, acc: 84.38%] [G loss: 4.263458]\n",
      "epoch:34 step:26961 [D loss: 0.163848, acc: 97.66%] [G loss: 3.378509]\n",
      "epoch:34 step:26962 [D loss: 0.248636, acc: 96.88%] [G loss: 4.413640]\n",
      "epoch:34 step:26963 [D loss: 0.556474, acc: 64.84%] [G loss: 2.230335]\n",
      "epoch:34 step:26964 [D loss: 0.713769, acc: 56.25%] [G loss: 3.315520]\n",
      "epoch:34 step:26965 [D loss: 0.304387, acc: 93.75%] [G loss: 2.985324]\n",
      "epoch:34 step:26966 [D loss: 0.196882, acc: 96.88%] [G loss: 5.420152]\n",
      "epoch:34 step:26967 [D loss: 0.493319, acc: 64.84%] [G loss: 5.748994]\n",
      "epoch:34 step:26968 [D loss: 0.304398, acc: 84.38%] [G loss: 4.485696]\n",
      "epoch:34 step:26969 [D loss: 0.381641, acc: 75.78%] [G loss: 3.798292]\n",
      "epoch:34 step:26970 [D loss: 0.382165, acc: 89.06%] [G loss: 4.916387]\n",
      "epoch:34 step:26971 [D loss: 0.120797, acc: 100.00%] [G loss: 5.517096]\n",
      "epoch:34 step:26972 [D loss: 0.165078, acc: 99.22%] [G loss: 4.372461]\n",
      "epoch:34 step:26973 [D loss: 0.066727, acc: 100.00%] [G loss: 3.434651]\n",
      "epoch:34 step:26974 [D loss: 0.121870, acc: 99.22%] [G loss: 4.295498]\n",
      "epoch:34 step:26975 [D loss: 0.194695, acc: 100.00%] [G loss: 5.724371]\n",
      "epoch:34 step:26976 [D loss: 0.381539, acc: 78.91%] [G loss: 4.462124]\n",
      "epoch:34 step:26977 [D loss: 0.673607, acc: 61.72%] [G loss: 4.138366]\n",
      "epoch:34 step:26978 [D loss: 0.205681, acc: 99.22%] [G loss: 2.371025]\n",
      "epoch:34 step:26979 [D loss: 1.290486, acc: 36.72%] [G loss: 6.171834]\n",
      "epoch:34 step:26980 [D loss: 0.253566, acc: 92.97%] [G loss: 4.796326]\n",
      "epoch:34 step:26981 [D loss: 1.013124, acc: 29.69%] [G loss: 5.808567]\n",
      "epoch:34 step:26982 [D loss: 0.098267, acc: 100.00%] [G loss: 5.213364]\n",
      "epoch:34 step:26983 [D loss: 0.124132, acc: 100.00%] [G loss: 4.669005]\n",
      "epoch:34 step:26984 [D loss: 0.053616, acc: 99.22%] [G loss: 5.843654]\n",
      "epoch:34 step:26985 [D loss: 0.438716, acc: 75.00%] [G loss: 5.183401]\n",
      "epoch:34 step:26986 [D loss: 0.231061, acc: 96.09%] [G loss: 6.515121]\n",
      "epoch:34 step:26987 [D loss: 0.355062, acc: 92.97%] [G loss: 4.457935]\n",
      "epoch:34 step:26988 [D loss: 0.300472, acc: 86.72%] [G loss: 5.029680]\n",
      "epoch:34 step:26989 [D loss: 0.148283, acc: 100.00%] [G loss: 6.245160]\n",
      "epoch:34 step:26990 [D loss: 0.270940, acc: 91.41%] [G loss: 2.658744]\n",
      "epoch:34 step:26991 [D loss: 0.422413, acc: 85.16%] [G loss: 5.171058]\n",
      "epoch:34 step:26992 [D loss: 0.066716, acc: 100.00%] [G loss: 4.898575]\n",
      "epoch:34 step:26993 [D loss: 0.278068, acc: 96.09%] [G loss: 4.448868]\n",
      "epoch:34 step:26994 [D loss: 0.413913, acc: 86.72%] [G loss: 3.724388]\n",
      "epoch:34 step:26995 [D loss: 0.304252, acc: 93.75%] [G loss: 4.485401]\n",
      "epoch:34 step:26996 [D loss: 0.397608, acc: 75.00%] [G loss: 4.654422]\n",
      "epoch:34 step:26997 [D loss: 0.229411, acc: 95.31%] [G loss: 3.015721]\n",
      "epoch:34 step:26998 [D loss: 0.663684, acc: 59.38%] [G loss: 4.721964]\n",
      "epoch:34 step:26999 [D loss: 0.692093, acc: 53.12%] [G loss: 7.358565]\n",
      "epoch:34 step:27000 [D loss: 0.066668, acc: 99.22%] [G loss: 5.186646]\n",
      "epoch:34 step:27001 [D loss: 0.545610, acc: 63.28%] [G loss: 3.967117]\n",
      "epoch:34 step:27002 [D loss: 0.238015, acc: 100.00%] [G loss: 4.838040]\n",
      "epoch:34 step:27003 [D loss: 0.183208, acc: 98.44%] [G loss: 6.413913]\n",
      "epoch:34 step:27004 [D loss: 0.052671, acc: 100.00%] [G loss: 4.065156]\n",
      "epoch:34 step:27005 [D loss: 0.385935, acc: 78.91%] [G loss: 5.615340]\n",
      "epoch:34 step:27006 [D loss: 0.221097, acc: 96.88%] [G loss: 3.168192]\n",
      "epoch:34 step:27007 [D loss: 0.235434, acc: 96.88%] [G loss: 3.933901]\n",
      "epoch:34 step:27008 [D loss: 0.626148, acc: 53.91%] [G loss: 5.573578]\n",
      "epoch:34 step:27009 [D loss: 0.429696, acc: 78.91%] [G loss: 5.736180]\n",
      "epoch:34 step:27010 [D loss: 0.359936, acc: 75.78%] [G loss: 4.898170]\n",
      "epoch:34 step:27011 [D loss: 0.345284, acc: 84.38%] [G loss: 5.092613]\n",
      "epoch:34 step:27012 [D loss: 0.079701, acc: 100.00%] [G loss: 6.788180]\n",
      "epoch:34 step:27013 [D loss: 0.389990, acc: 88.28%] [G loss: 3.041773]\n",
      "epoch:34 step:27014 [D loss: 0.451129, acc: 80.47%] [G loss: 5.601501]\n",
      "epoch:34 step:27015 [D loss: 0.165930, acc: 98.44%] [G loss: 4.655031]\n",
      "epoch:34 step:27016 [D loss: 0.680986, acc: 56.25%] [G loss: 3.877779]\n",
      "epoch:34 step:27017 [D loss: 0.247616, acc: 94.53%] [G loss: 5.882995]\n",
      "epoch:34 step:27018 [D loss: 0.455112, acc: 80.47%] [G loss: 6.875177]\n",
      "epoch:34 step:27019 [D loss: 0.448409, acc: 73.44%] [G loss: 6.773722]\n",
      "epoch:34 step:27020 [D loss: 0.305366, acc: 86.72%] [G loss: 7.005090]\n",
      "epoch:34 step:27021 [D loss: 0.128520, acc: 99.22%] [G loss: 3.603067]\n",
      "epoch:34 step:27022 [D loss: 0.232481, acc: 97.66%] [G loss: 5.026854]\n",
      "epoch:34 step:27023 [D loss: 0.553453, acc: 64.84%] [G loss: 7.856396]\n",
      "epoch:34 step:27024 [D loss: 0.135551, acc: 100.00%] [G loss: 3.449635]\n",
      "epoch:34 step:27025 [D loss: 1.120690, acc: 50.00%] [G loss: 6.869615]\n",
      "epoch:34 step:27026 [D loss: 0.455789, acc: 85.16%] [G loss: 4.883845]\n",
      "epoch:34 step:27027 [D loss: 0.202197, acc: 96.09%] [G loss: 4.264712]\n",
      "epoch:34 step:27028 [D loss: 0.275648, acc: 92.97%] [G loss: 3.100223]\n",
      "epoch:34 step:27029 [D loss: 0.206855, acc: 97.66%] [G loss: 4.724130]\n",
      "epoch:34 step:27030 [D loss: 0.234656, acc: 96.09%] [G loss: 4.123557]\n",
      "epoch:34 step:27031 [D loss: 0.114655, acc: 100.00%] [G loss: 5.272613]\n",
      "epoch:34 step:27032 [D loss: 0.047459, acc: 100.00%] [G loss: 4.557886]\n",
      "epoch:34 step:27033 [D loss: 0.875120, acc: 42.97%] [G loss: 4.734369]\n",
      "epoch:34 step:27034 [D loss: 1.477808, acc: 19.53%] [G loss: 6.059390]\n",
      "epoch:34 step:27035 [D loss: 0.482438, acc: 72.66%] [G loss: 1.856246]\n",
      "epoch:34 step:27036 [D loss: 0.189880, acc: 96.88%] [G loss: 4.970170]\n",
      "epoch:34 step:27037 [D loss: 0.220121, acc: 92.19%] [G loss: 4.978209]\n",
      "epoch:34 step:27038 [D loss: 0.264261, acc: 97.66%] [G loss: 3.900012]\n",
      "epoch:34 step:27039 [D loss: 0.143100, acc: 99.22%] [G loss: 3.550721]\n",
      "epoch:34 step:27040 [D loss: 0.647074, acc: 67.97%] [G loss: 4.151292]\n",
      "epoch:34 step:27041 [D loss: 0.451745, acc: 83.59%] [G loss: 3.622563]\n",
      "epoch:34 step:27042 [D loss: 0.658449, acc: 53.91%] [G loss: 2.503573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27043 [D loss: 0.104237, acc: 100.00%] [G loss: 3.953581]\n",
      "epoch:34 step:27044 [D loss: 0.024450, acc: 100.00%] [G loss: 9.231498]\n",
      "epoch:34 step:27045 [D loss: 0.163328, acc: 100.00%] [G loss: 4.672937]\n",
      "epoch:34 step:27046 [D loss: 0.691448, acc: 58.59%] [G loss: 6.383079]\n",
      "epoch:34 step:27047 [D loss: 0.282259, acc: 95.31%] [G loss: 3.785300]\n",
      "epoch:34 step:27048 [D loss: 0.117346, acc: 100.00%] [G loss: 4.700428]\n",
      "epoch:34 step:27049 [D loss: 0.515084, acc: 65.62%] [G loss: 5.636138]\n",
      "epoch:34 step:27050 [D loss: 0.301942, acc: 93.75%] [G loss: 4.010421]\n",
      "epoch:34 step:27051 [D loss: 0.043986, acc: 100.00%] [G loss: 5.757588]\n",
      "epoch:34 step:27052 [D loss: 0.140380, acc: 100.00%] [G loss: 4.156064]\n",
      "epoch:34 step:27053 [D loss: 0.361543, acc: 81.25%] [G loss: 2.865146]\n",
      "epoch:34 step:27054 [D loss: 0.649021, acc: 60.94%] [G loss: 5.150430]\n",
      "epoch:34 step:27055 [D loss: 1.277967, acc: 26.56%] [G loss: 2.770415]\n",
      "epoch:34 step:27056 [D loss: 0.065934, acc: 100.00%] [G loss: 2.779426]\n",
      "epoch:34 step:27057 [D loss: 1.137213, acc: 50.00%] [G loss: 2.791378]\n",
      "epoch:34 step:27058 [D loss: 0.116823, acc: 99.22%] [G loss: 5.104997]\n",
      "epoch:34 step:27059 [D loss: 0.633222, acc: 60.94%] [G loss: 3.365005]\n",
      "epoch:34 step:27060 [D loss: 0.227468, acc: 98.44%] [G loss: 3.559793]\n",
      "epoch:34 step:27061 [D loss: 0.640523, acc: 66.41%] [G loss: 5.474040]\n",
      "epoch:34 step:27062 [D loss: 0.064161, acc: 100.00%] [G loss: 4.510087]\n",
      "epoch:34 step:27063 [D loss: 0.100609, acc: 100.00%] [G loss: 4.116911]\n",
      "epoch:34 step:27064 [D loss: 0.593191, acc: 71.09%] [G loss: 4.698366]\n",
      "epoch:34 step:27065 [D loss: 0.155286, acc: 100.00%] [G loss: 6.658094]\n",
      "epoch:34 step:27066 [D loss: 0.540160, acc: 60.16%] [G loss: 3.967730]\n",
      "epoch:34 step:27067 [D loss: 0.287836, acc: 95.31%] [G loss: 3.330124]\n",
      "epoch:34 step:27068 [D loss: 0.119757, acc: 100.00%] [G loss: 4.025532]\n",
      "epoch:34 step:27069 [D loss: 0.076335, acc: 99.22%] [G loss: 4.923299]\n",
      "epoch:34 step:27070 [D loss: 0.556164, acc: 60.16%] [G loss: 1.992129]\n",
      "epoch:34 step:27071 [D loss: 0.224460, acc: 96.09%] [G loss: 3.924130]\n",
      "epoch:34 step:27072 [D loss: 0.362321, acc: 78.91%] [G loss: 6.009487]\n",
      "epoch:34 step:27073 [D loss: 1.195367, acc: 38.28%] [G loss: 2.997452]\n",
      "epoch:34 step:27074 [D loss: 0.396195, acc: 81.25%] [G loss: 3.621472]\n",
      "epoch:34 step:27075 [D loss: 0.341475, acc: 87.50%] [G loss: 4.411879]\n",
      "epoch:34 step:27076 [D loss: 1.627380, acc: 41.41%] [G loss: 6.712021]\n",
      "epoch:34 step:27077 [D loss: 1.214580, acc: 48.44%] [G loss: 4.592196]\n",
      "epoch:34 step:27078 [D loss: 0.123723, acc: 100.00%] [G loss: 6.365986]\n",
      "epoch:34 step:27079 [D loss: 0.417305, acc: 82.03%] [G loss: 6.189626]\n",
      "epoch:34 step:27080 [D loss: 1.084095, acc: 38.28%] [G loss: 8.651182]\n",
      "epoch:34 step:27081 [D loss: 0.707930, acc: 57.03%] [G loss: 4.189253]\n",
      "epoch:34 step:27082 [D loss: 0.187466, acc: 97.66%] [G loss: 4.184831]\n",
      "epoch:34 step:27083 [D loss: 0.378323, acc: 73.44%] [G loss: 5.001486]\n",
      "epoch:34 step:27084 [D loss: 0.114734, acc: 98.44%] [G loss: 6.730731]\n",
      "epoch:34 step:27085 [D loss: 0.082857, acc: 99.22%] [G loss: 4.820450]\n",
      "epoch:34 step:27086 [D loss: 0.370283, acc: 71.88%] [G loss: 4.544855]\n",
      "epoch:34 step:27087 [D loss: 0.203763, acc: 96.88%] [G loss: 4.521311]\n",
      "epoch:34 step:27088 [D loss: 0.689028, acc: 50.78%] [G loss: 4.967978]\n",
      "epoch:34 step:27089 [D loss: 0.474701, acc: 71.88%] [G loss: 6.277849]\n",
      "epoch:34 step:27090 [D loss: 0.019909, acc: 100.00%] [G loss: 6.668619]\n",
      "epoch:34 step:27091 [D loss: 0.049588, acc: 100.00%] [G loss: 3.871272]\n",
      "epoch:34 step:27092 [D loss: 0.268731, acc: 94.53%] [G loss: 5.709982]\n",
      "epoch:34 step:27093 [D loss: 1.473769, acc: 5.47%] [G loss: 5.180421]\n",
      "epoch:34 step:27094 [D loss: 0.225318, acc: 96.09%] [G loss: 6.741947]\n",
      "epoch:34 step:27095 [D loss: 0.134641, acc: 100.00%] [G loss: 7.770050]\n",
      "epoch:34 step:27096 [D loss: 0.070481, acc: 100.00%] [G loss: 7.639613]\n",
      "epoch:34 step:27097 [D loss: 0.487429, acc: 75.78%] [G loss: 5.512836]\n",
      "epoch:34 step:27098 [D loss: 0.411325, acc: 75.00%] [G loss: 4.870923]\n",
      "epoch:34 step:27099 [D loss: 0.165353, acc: 100.00%] [G loss: 3.116303]\n",
      "epoch:34 step:27100 [D loss: 0.326695, acc: 84.38%] [G loss: 3.558322]\n",
      "epoch:34 step:27101 [D loss: 0.298607, acc: 92.97%] [G loss: 5.855330]\n",
      "epoch:34 step:27102 [D loss: 0.165778, acc: 98.44%] [G loss: 3.454551]\n",
      "epoch:34 step:27103 [D loss: 0.655594, acc: 56.25%] [G loss: 3.846438]\n",
      "epoch:34 step:27104 [D loss: 0.565637, acc: 64.84%] [G loss: 2.761597]\n",
      "epoch:34 step:27105 [D loss: 0.079737, acc: 100.00%] [G loss: 6.418787]\n",
      "epoch:34 step:27106 [D loss: 0.408770, acc: 68.75%] [G loss: 4.029941]\n",
      "epoch:34 step:27107 [D loss: 1.145184, acc: 28.12%] [G loss: 4.708099]\n",
      "epoch:34 step:27108 [D loss: 0.135499, acc: 100.00%] [G loss: 3.733752]\n",
      "epoch:34 step:27109 [D loss: 0.124071, acc: 98.44%] [G loss: 3.257425]\n",
      "epoch:34 step:27110 [D loss: 0.171234, acc: 98.44%] [G loss: 5.874389]\n",
      "epoch:34 step:27111 [D loss: 0.642843, acc: 61.72%] [G loss: 1.877914]\n",
      "epoch:34 step:27112 [D loss: 0.355014, acc: 92.97%] [G loss: 4.270813]\n",
      "epoch:34 step:27113 [D loss: 0.620117, acc: 66.41%] [G loss: 3.856501]\n",
      "epoch:34 step:27114 [D loss: 0.116164, acc: 99.22%] [G loss: 7.246541]\n",
      "epoch:34 step:27115 [D loss: 0.144395, acc: 97.66%] [G loss: 5.194128]\n",
      "epoch:34 step:27116 [D loss: 0.934961, acc: 38.28%] [G loss: 5.185610]\n",
      "epoch:34 step:27117 [D loss: 0.033797, acc: 100.00%] [G loss: 4.480959]\n",
      "epoch:34 step:27118 [D loss: 0.754795, acc: 52.34%] [G loss: 5.060215]\n",
      "epoch:34 step:27119 [D loss: 0.260459, acc: 95.31%] [G loss: 3.389791]\n",
      "epoch:34 step:27120 [D loss: 0.335207, acc: 83.59%] [G loss: 4.049350]\n",
      "epoch:34 step:27121 [D loss: 0.613396, acc: 55.47%] [G loss: 5.528634]\n",
      "epoch:34 step:27122 [D loss: 0.320316, acc: 89.06%] [G loss: 5.360457]\n",
      "epoch:34 step:27123 [D loss: 0.309407, acc: 86.72%] [G loss: 6.104089]\n",
      "epoch:34 step:27124 [D loss: 0.577249, acc: 61.72%] [G loss: 4.912505]\n",
      "epoch:34 step:27125 [D loss: 0.237578, acc: 95.31%] [G loss: 3.614553]\n",
      "epoch:34 step:27126 [D loss: 0.311698, acc: 96.09%] [G loss: 4.948489]\n",
      "epoch:34 step:27127 [D loss: 0.198752, acc: 99.22%] [G loss: 5.346465]\n",
      "epoch:34 step:27128 [D loss: 1.231143, acc: 14.06%] [G loss: 4.310232]\n",
      "epoch:34 step:27129 [D loss: 0.201276, acc: 99.22%] [G loss: 3.827566]\n",
      "epoch:34 step:27130 [D loss: 0.954419, acc: 50.78%] [G loss: 4.255352]\n",
      "epoch:34 step:27131 [D loss: 0.151809, acc: 99.22%] [G loss: 5.326708]\n",
      "epoch:34 step:27132 [D loss: 0.265953, acc: 95.31%] [G loss: 4.007454]\n",
      "epoch:34 step:27133 [D loss: 0.154570, acc: 99.22%] [G loss: 4.163681]\n",
      "epoch:34 step:27134 [D loss: 0.321011, acc: 88.28%] [G loss: 2.515558]\n",
      "epoch:34 step:27135 [D loss: 0.237980, acc: 94.53%] [G loss: 4.621074]\n",
      "epoch:34 step:27136 [D loss: 0.411303, acc: 85.94%] [G loss: 4.103293]\n",
      "epoch:34 step:27137 [D loss: 0.300692, acc: 85.94%] [G loss: 8.036960]\n",
      "epoch:34 step:27138 [D loss: 0.260755, acc: 96.09%] [G loss: 3.877554]\n",
      "epoch:34 step:27139 [D loss: 0.184640, acc: 100.00%] [G loss: 4.763685]\n",
      "epoch:34 step:27140 [D loss: 0.113408, acc: 99.22%] [G loss: 4.834147]\n",
      "epoch:34 step:27141 [D loss: 0.243149, acc: 92.97%] [G loss: 5.276928]\n",
      "epoch:34 step:27142 [D loss: 0.283530, acc: 86.72%] [G loss: 3.998252]\n",
      "epoch:34 step:27143 [D loss: 0.249583, acc: 94.53%] [G loss: 4.597382]\n",
      "epoch:34 step:27144 [D loss: 0.355715, acc: 92.19%] [G loss: 4.994528]\n",
      "epoch:34 step:27145 [D loss: 0.419924, acc: 85.94%] [G loss: 3.523599]\n",
      "epoch:34 step:27146 [D loss: 0.808554, acc: 43.75%] [G loss: 5.253888]\n",
      "epoch:34 step:27147 [D loss: 0.428129, acc: 86.72%] [G loss: 4.564509]\n",
      "epoch:34 step:27148 [D loss: 0.587837, acc: 73.44%] [G loss: 2.715911]\n",
      "epoch:34 step:27149 [D loss: 0.513777, acc: 71.09%] [G loss: 1.846479]\n",
      "epoch:34 step:27150 [D loss: 0.028355, acc: 100.00%] [G loss: 5.351905]\n",
      "epoch:34 step:27151 [D loss: 0.216948, acc: 99.22%] [G loss: 2.860694]\n",
      "epoch:34 step:27152 [D loss: 0.674228, acc: 62.50%] [G loss: 6.116476]\n",
      "epoch:34 step:27153 [D loss: 0.852211, acc: 53.91%] [G loss: 3.774611]\n",
      "epoch:34 step:27154 [D loss: 0.381343, acc: 90.62%] [G loss: 3.884277]\n",
      "epoch:34 step:27155 [D loss: 1.265721, acc: 47.66%] [G loss: 2.325681]\n",
      "epoch:34 step:27156 [D loss: 0.417042, acc: 85.94%] [G loss: 4.174823]\n",
      "epoch:34 step:27157 [D loss: 0.618655, acc: 65.62%] [G loss: 4.221247]\n",
      "epoch:34 step:27158 [D loss: 0.604345, acc: 59.38%] [G loss: 5.140367]\n",
      "epoch:34 step:27159 [D loss: 0.204515, acc: 97.66%] [G loss: 2.919013]\n",
      "epoch:34 step:27160 [D loss: 0.433937, acc: 83.59%] [G loss: 6.112385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27161 [D loss: 0.131267, acc: 99.22%] [G loss: 3.622294]\n",
      "epoch:34 step:27162 [D loss: 0.441868, acc: 74.22%] [G loss: 6.178912]\n",
      "epoch:34 step:27163 [D loss: 0.075114, acc: 99.22%] [G loss: 5.936251]\n",
      "epoch:34 step:27164 [D loss: 0.306340, acc: 89.84%] [G loss: 5.500080]\n",
      "epoch:34 step:27165 [D loss: 0.188814, acc: 97.66%] [G loss: 3.786472]\n",
      "epoch:34 step:27166 [D loss: 0.522295, acc: 59.38%] [G loss: 3.540464]\n",
      "epoch:34 step:27167 [D loss: 0.208004, acc: 98.44%] [G loss: 6.965378]\n",
      "epoch:34 step:27168 [D loss: 0.888556, acc: 51.56%] [G loss: 4.691712]\n",
      "epoch:34 step:27169 [D loss: 0.335970, acc: 82.03%] [G loss: 3.096209]\n",
      "epoch:34 step:27170 [D loss: 0.129305, acc: 100.00%] [G loss: 3.512938]\n",
      "epoch:34 step:27171 [D loss: 0.239129, acc: 99.22%] [G loss: 3.022260]\n",
      "epoch:34 step:27172 [D loss: 0.344201, acc: 90.62%] [G loss: 4.795947]\n",
      "epoch:34 step:27173 [D loss: 1.523629, acc: 47.66%] [G loss: 7.466211]\n",
      "epoch:34 step:27174 [D loss: 0.724691, acc: 53.12%] [G loss: 4.370358]\n",
      "epoch:34 step:27175 [D loss: 0.297195, acc: 96.09%] [G loss: 2.604155]\n",
      "epoch:34 step:27176 [D loss: 0.482267, acc: 72.66%] [G loss: 5.393526]\n",
      "epoch:34 step:27177 [D loss: 0.528654, acc: 64.84%] [G loss: 4.634149]\n",
      "epoch:34 step:27178 [D loss: 0.101264, acc: 100.00%] [G loss: 4.735034]\n",
      "epoch:34 step:27179 [D loss: 0.354111, acc: 90.62%] [G loss: 2.286897]\n",
      "epoch:34 step:27180 [D loss: 0.451925, acc: 68.75%] [G loss: 3.394332]\n",
      "epoch:34 step:27181 [D loss: 0.445182, acc: 86.72%] [G loss: 4.099169]\n",
      "epoch:34 step:27182 [D loss: 0.591360, acc: 61.72%] [G loss: 5.090729]\n",
      "epoch:34 step:27183 [D loss: 0.210860, acc: 97.66%] [G loss: 4.527668]\n",
      "epoch:34 step:27184 [D loss: 0.249008, acc: 92.97%] [G loss: 4.818877]\n",
      "epoch:34 step:27185 [D loss: 1.026174, acc: 49.22%] [G loss: 7.638857]\n",
      "epoch:34 step:27186 [D loss: 0.299960, acc: 94.53%] [G loss: 3.244100]\n",
      "epoch:34 step:27187 [D loss: 0.099878, acc: 100.00%] [G loss: 6.021720]\n",
      "epoch:34 step:27188 [D loss: 0.950748, acc: 53.91%] [G loss: 4.525746]\n",
      "epoch:34 step:27189 [D loss: 0.166088, acc: 97.66%] [G loss: 2.765147]\n",
      "epoch:34 step:27190 [D loss: 0.261508, acc: 94.53%] [G loss: 3.349801]\n",
      "epoch:34 step:27191 [D loss: 0.382942, acc: 73.44%] [G loss: 5.577893]\n",
      "epoch:34 step:27192 [D loss: 1.683099, acc: 22.66%] [G loss: 7.632277]\n",
      "epoch:34 step:27193 [D loss: 0.578703, acc: 71.09%] [G loss: 4.486686]\n",
      "epoch:34 step:27194 [D loss: 0.690167, acc: 53.12%] [G loss: 6.051873]\n",
      "epoch:34 step:27195 [D loss: 0.030594, acc: 100.00%] [G loss: 3.404185]\n",
      "epoch:34 step:27196 [D loss: 0.501585, acc: 61.72%] [G loss: 4.181168]\n",
      "epoch:34 step:27197 [D loss: 0.343171, acc: 84.38%] [G loss: 4.342105]\n",
      "epoch:34 step:27198 [D loss: 0.054562, acc: 100.00%] [G loss: 4.595531]\n",
      "epoch:34 step:27199 [D loss: 0.255495, acc: 96.09%] [G loss: 4.833026]\n",
      "epoch:34 step:27200 [D loss: 0.146994, acc: 99.22%] [G loss: 5.105275]\n",
      "epoch:34 step:27201 [D loss: 0.333795, acc: 89.06%] [G loss: 6.140602]\n",
      "epoch:34 step:27202 [D loss: 0.248486, acc: 97.66%] [G loss: 4.678417]\n",
      "epoch:34 step:27203 [D loss: 0.732479, acc: 53.12%] [G loss: 4.501803]\n",
      "epoch:34 step:27204 [D loss: 0.165902, acc: 99.22%] [G loss: 3.085743]\n",
      "epoch:34 step:27205 [D loss: 0.698915, acc: 53.91%] [G loss: 3.959722]\n",
      "epoch:34 step:27206 [D loss: 0.071686, acc: 100.00%] [G loss: 3.380047]\n",
      "epoch:34 step:27207 [D loss: 0.359626, acc: 81.25%] [G loss: 5.786896]\n",
      "epoch:34 step:27208 [D loss: 0.593076, acc: 63.28%] [G loss: 5.556065]\n",
      "epoch:34 step:27209 [D loss: 0.106382, acc: 100.00%] [G loss: 5.740535]\n",
      "epoch:34 step:27210 [D loss: 0.268201, acc: 93.75%] [G loss: 5.620546]\n",
      "epoch:34 step:27211 [D loss: 0.294955, acc: 91.41%] [G loss: 3.743985]\n",
      "epoch:34 step:27212 [D loss: 0.351247, acc: 92.19%] [G loss: 5.293013]\n",
      "epoch:34 step:27213 [D loss: 0.067115, acc: 100.00%] [G loss: 6.745873]\n",
      "epoch:34 step:27214 [D loss: 0.749437, acc: 60.16%] [G loss: 4.597310]\n",
      "epoch:34 step:27215 [D loss: 0.105777, acc: 100.00%] [G loss: 3.301794]\n",
      "epoch:34 step:27216 [D loss: 0.382651, acc: 85.94%] [G loss: 4.684633]\n",
      "epoch:34 step:27217 [D loss: 0.729556, acc: 54.69%] [G loss: 6.259090]\n",
      "epoch:34 step:27218 [D loss: 0.009948, acc: 100.00%] [G loss: 6.228780]\n",
      "epoch:34 step:27219 [D loss: 0.149499, acc: 99.22%] [G loss: 3.075448]\n",
      "epoch:34 step:27220 [D loss: 0.188835, acc: 99.22%] [G loss: 6.313483]\n",
      "epoch:34 step:27221 [D loss: 0.151607, acc: 100.00%] [G loss: 4.918780]\n",
      "epoch:34 step:27222 [D loss: 0.393829, acc: 86.72%] [G loss: 6.023457]\n",
      "epoch:34 step:27223 [D loss: 0.318801, acc: 95.31%] [G loss: 3.627003]\n",
      "epoch:34 step:27224 [D loss: 0.336302, acc: 95.31%] [G loss: 2.261034]\n",
      "epoch:34 step:27225 [D loss: 0.520326, acc: 57.03%] [G loss: 5.535310]\n",
      "epoch:34 step:27226 [D loss: 0.419058, acc: 71.09%] [G loss: 3.930309]\n",
      "epoch:34 step:27227 [D loss: 0.267358, acc: 99.22%] [G loss: 3.629905]\n",
      "epoch:34 step:27228 [D loss: 0.184088, acc: 97.66%] [G loss: 5.778582]\n",
      "epoch:34 step:27229 [D loss: 0.059186, acc: 100.00%] [G loss: 6.793071]\n",
      "epoch:34 step:27230 [D loss: 0.151852, acc: 97.66%] [G loss: 6.790565]\n",
      "epoch:34 step:27231 [D loss: 0.289967, acc: 90.62%] [G loss: 5.445280]\n",
      "epoch:34 step:27232 [D loss: 0.260857, acc: 88.28%] [G loss: 5.575724]\n",
      "epoch:34 step:27233 [D loss: 0.223482, acc: 97.66%] [G loss: 5.910349]\n",
      "epoch:34 step:27234 [D loss: 0.942764, acc: 47.66%] [G loss: 6.209240]\n",
      "epoch:34 step:27235 [D loss: 0.414007, acc: 67.97%] [G loss: 6.991784]\n",
      "epoch:34 step:27236 [D loss: 0.162868, acc: 99.22%] [G loss: 3.136543]\n",
      "epoch:34 step:27237 [D loss: 0.248312, acc: 96.09%] [G loss: 5.649026]\n",
      "epoch:34 step:27238 [D loss: 0.694757, acc: 57.81%] [G loss: 4.947889]\n",
      "epoch:34 step:27239 [D loss: 0.229236, acc: 89.84%] [G loss: 4.712796]\n",
      "epoch:34 step:27240 [D loss: 0.400427, acc: 89.06%] [G loss: 4.813127]\n",
      "epoch:34 step:27241 [D loss: 0.479262, acc: 70.31%] [G loss: 4.125877]\n",
      "epoch:34 step:27242 [D loss: 0.067088, acc: 100.00%] [G loss: 3.095670]\n",
      "epoch:34 step:27243 [D loss: 0.591833, acc: 71.09%] [G loss: 4.244976]\n",
      "epoch:34 step:27244 [D loss: 0.287410, acc: 89.84%] [G loss: 4.558366]\n",
      "epoch:34 step:27245 [D loss: 0.690961, acc: 53.91%] [G loss: 8.097311]\n",
      "epoch:34 step:27246 [D loss: 0.224378, acc: 94.53%] [G loss: 5.688690]\n",
      "epoch:34 step:27247 [D loss: 0.094865, acc: 100.00%] [G loss: 3.337961]\n",
      "epoch:34 step:27248 [D loss: 0.941000, acc: 46.88%] [G loss: 6.411408]\n",
      "epoch:34 step:27249 [D loss: 0.029847, acc: 100.00%] [G loss: 5.899022]\n",
      "epoch:34 step:27250 [D loss: 0.780549, acc: 52.34%] [G loss: 3.138985]\n",
      "epoch:34 step:27251 [D loss: 0.511751, acc: 64.06%] [G loss: 3.975663]\n",
      "epoch:34 step:27252 [D loss: 0.100781, acc: 100.00%] [G loss: 4.306651]\n",
      "epoch:34 step:27253 [D loss: 0.508100, acc: 61.72%] [G loss: 3.034024]\n",
      "epoch:34 step:27254 [D loss: 0.896728, acc: 34.38%] [G loss: 3.602919]\n",
      "epoch:34 step:27255 [D loss: 0.358919, acc: 85.94%] [G loss: 5.623032]\n",
      "epoch:34 step:27256 [D loss: 0.209273, acc: 98.44%] [G loss: 2.521177]\n",
      "epoch:34 step:27257 [D loss: 0.466421, acc: 82.03%] [G loss: 6.429924]\n",
      "epoch:34 step:27258 [D loss: 0.549821, acc: 68.75%] [G loss: 2.678735]\n",
      "epoch:34 step:27259 [D loss: 0.203043, acc: 96.09%] [G loss: 6.110067]\n",
      "epoch:34 step:27260 [D loss: 0.321948, acc: 82.81%] [G loss: 4.750391]\n",
      "epoch:34 step:27261 [D loss: 0.166637, acc: 100.00%] [G loss: 4.440998]\n",
      "epoch:34 step:27262 [D loss: 0.506038, acc: 64.84%] [G loss: 6.716871]\n",
      "epoch:34 step:27263 [D loss: 0.312883, acc: 85.16%] [G loss: 3.899232]\n",
      "epoch:34 step:27264 [D loss: 0.951474, acc: 50.00%] [G loss: 2.980747]\n",
      "epoch:34 step:27265 [D loss: 0.054675, acc: 100.00%] [G loss: 7.252842]\n",
      "epoch:34 step:27266 [D loss: 1.079720, acc: 51.56%] [G loss: 6.065839]\n",
      "epoch:34 step:27267 [D loss: 0.379640, acc: 82.03%] [G loss: 3.366201]\n",
      "epoch:34 step:27268 [D loss: 0.199357, acc: 94.53%] [G loss: 4.034580]\n",
      "epoch:34 step:27269 [D loss: 0.177839, acc: 98.44%] [G loss: 5.092077]\n",
      "epoch:34 step:27270 [D loss: 0.144655, acc: 100.00%] [G loss: 5.091165]\n",
      "epoch:34 step:27271 [D loss: 0.577354, acc: 69.53%] [G loss: 4.782240]\n",
      "epoch:34 step:27272 [D loss: 0.218501, acc: 95.31%] [G loss: 6.253938]\n",
      "epoch:34 step:27273 [D loss: 1.113187, acc: 50.78%] [G loss: 3.308264]\n",
      "epoch:34 step:27274 [D loss: 0.193491, acc: 96.88%] [G loss: 2.728269]\n",
      "epoch:34 step:27275 [D loss: 0.338206, acc: 92.19%] [G loss: 4.550828]\n",
      "epoch:34 step:27276 [D loss: 0.094853, acc: 100.00%] [G loss: 3.669310]\n",
      "epoch:34 step:27277 [D loss: 0.295695, acc: 93.75%] [G loss: 6.541675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27278 [D loss: 0.311373, acc: 95.31%] [G loss: 4.129241]\n",
      "epoch:34 step:27279 [D loss: 0.250047, acc: 97.66%] [G loss: 5.216327]\n",
      "epoch:34 step:27280 [D loss: 0.388216, acc: 82.03%] [G loss: 6.795267]\n",
      "epoch:34 step:27281 [D loss: 1.074516, acc: 41.41%] [G loss: 6.001751]\n",
      "epoch:34 step:27282 [D loss: 0.556704, acc: 74.22%] [G loss: 6.001359]\n",
      "epoch:34 step:27283 [D loss: 0.102533, acc: 100.00%] [G loss: 3.328001]\n",
      "epoch:34 step:27284 [D loss: 0.984005, acc: 46.88%] [G loss: 4.341831]\n",
      "epoch:34 step:27285 [D loss: 0.592535, acc: 69.53%] [G loss: 4.982723]\n",
      "epoch:34 step:27286 [D loss: 0.554336, acc: 75.78%] [G loss: 5.173096]\n",
      "epoch:34 step:27287 [D loss: 0.297701, acc: 96.09%] [G loss: 4.556993]\n",
      "epoch:34 step:27288 [D loss: 0.311831, acc: 95.31%] [G loss: 5.124448]\n",
      "epoch:34 step:27289 [D loss: 0.082884, acc: 98.44%] [G loss: 4.332148]\n",
      "epoch:34 step:27290 [D loss: 0.685365, acc: 58.59%] [G loss: 7.054088]\n",
      "epoch:34 step:27291 [D loss: 0.589687, acc: 64.06%] [G loss: 6.687769]\n",
      "epoch:34 step:27292 [D loss: 0.650926, acc: 57.03%] [G loss: 6.054913]\n",
      "epoch:34 step:27293 [D loss: 0.140740, acc: 99.22%] [G loss: 3.811858]\n",
      "epoch:34 step:27294 [D loss: 0.553726, acc: 75.78%] [G loss: 2.861460]\n",
      "epoch:34 step:27295 [D loss: 0.059333, acc: 100.00%] [G loss: 5.156677]\n",
      "epoch:34 step:27296 [D loss: 0.518250, acc: 64.06%] [G loss: 6.873941]\n",
      "epoch:34 step:27297 [D loss: 0.516382, acc: 77.34%] [G loss: 3.650472]\n",
      "epoch:34 step:27298 [D loss: 1.536155, acc: 45.31%] [G loss: 5.612221]\n",
      "epoch:34 step:27299 [D loss: 0.071466, acc: 100.00%] [G loss: 5.101137]\n",
      "epoch:34 step:27300 [D loss: 0.816767, acc: 48.44%] [G loss: 3.497286]\n",
      "epoch:34 step:27301 [D loss: 1.247629, acc: 39.84%] [G loss: 2.819123]\n",
      "epoch:34 step:27302 [D loss: 0.189117, acc: 96.88%] [G loss: 5.204866]\n",
      "epoch:34 step:27303 [D loss: 0.439611, acc: 74.22%] [G loss: 6.378597]\n",
      "epoch:34 step:27304 [D loss: 0.194962, acc: 99.22%] [G loss: 3.103601]\n",
      "epoch:34 step:27305 [D loss: 0.868905, acc: 39.06%] [G loss: 2.616771]\n",
      "epoch:34 step:27306 [D loss: 0.048563, acc: 100.00%] [G loss: 4.446071]\n",
      "epoch:34 step:27307 [D loss: 0.312769, acc: 91.41%] [G loss: 5.965115]\n",
      "epoch:34 step:27308 [D loss: 0.083472, acc: 99.22%] [G loss: 4.734905]\n",
      "epoch:34 step:27309 [D loss: 0.472666, acc: 80.47%] [G loss: 4.832544]\n",
      "epoch:34 step:27310 [D loss: 0.308604, acc: 89.06%] [G loss: 3.974711]\n",
      "epoch:34 step:27311 [D loss: 0.265642, acc: 89.84%] [G loss: 4.362854]\n",
      "epoch:34 step:27312 [D loss: 0.689027, acc: 61.72%] [G loss: 5.947368]\n",
      "epoch:34 step:27313 [D loss: 0.630171, acc: 61.72%] [G loss: 3.573392]\n",
      "epoch:34 step:27314 [D loss: 0.028229, acc: 100.00%] [G loss: 5.544692]\n",
      "epoch:34 step:27315 [D loss: 0.666927, acc: 60.16%] [G loss: 4.730059]\n",
      "epoch:34 step:27316 [D loss: 0.347222, acc: 82.03%] [G loss: 5.438111]\n",
      "epoch:34 step:27317 [D loss: 0.536607, acc: 73.44%] [G loss: 2.906338]\n",
      "epoch:34 step:27318 [D loss: 0.408810, acc: 85.94%] [G loss: 5.010601]\n",
      "epoch:34 step:27319 [D loss: 0.108621, acc: 100.00%] [G loss: 3.987802]\n",
      "epoch:34 step:27320 [D loss: 0.232777, acc: 96.88%] [G loss: 2.421839]\n",
      "epoch:34 step:27321 [D loss: 0.107876, acc: 100.00%] [G loss: 6.427375]\n",
      "epoch:34 step:27322 [D loss: 0.101027, acc: 100.00%] [G loss: 5.953500]\n",
      "epoch:34 step:27323 [D loss: 0.901168, acc: 46.09%] [G loss: 5.338627]\n",
      "epoch:34 step:27324 [D loss: 0.488836, acc: 64.84%] [G loss: 4.755645]\n",
      "epoch:34 step:27325 [D loss: 0.274390, acc: 92.19%] [G loss: 4.961791]\n",
      "epoch:34 step:27326 [D loss: 0.986296, acc: 46.09%] [G loss: 4.671381]\n",
      "epoch:34 step:27327 [D loss: 0.038136, acc: 100.00%] [G loss: 6.707299]\n",
      "epoch:34 step:27328 [D loss: 0.900642, acc: 51.56%] [G loss: 5.529192]\n",
      "epoch:34 step:27329 [D loss: 0.374060, acc: 87.50%] [G loss: 4.142204]\n",
      "epoch:34 step:27330 [D loss: 0.275032, acc: 91.41%] [G loss: 4.584280]\n",
      "epoch:34 step:27331 [D loss: 0.500098, acc: 71.88%] [G loss: 4.981324]\n",
      "epoch:34 step:27332 [D loss: 0.844903, acc: 42.19%] [G loss: 3.792645]\n",
      "epoch:34 step:27333 [D loss: 0.035744, acc: 100.00%] [G loss: 4.873198]\n",
      "epoch:34 step:27334 [D loss: 0.646306, acc: 59.38%] [G loss: 5.331488]\n",
      "epoch:34 step:27335 [D loss: 0.498146, acc: 74.22%] [G loss: 4.368093]\n",
      "epoch:35 step:27336 [D loss: 0.217506, acc: 92.19%] [G loss: 6.150451]\n",
      "epoch:35 step:27337 [D loss: 0.139081, acc: 100.00%] [G loss: 4.558363]\n",
      "epoch:35 step:27338 [D loss: 0.229881, acc: 93.75%] [G loss: 4.252178]\n",
      "epoch:35 step:27339 [D loss: 0.605153, acc: 61.72%] [G loss: 5.876626]\n",
      "epoch:35 step:27340 [D loss: 0.360416, acc: 89.84%] [G loss: 2.546743]\n",
      "epoch:35 step:27341 [D loss: 0.859608, acc: 44.53%] [G loss: 5.081091]\n",
      "epoch:35 step:27342 [D loss: 0.120345, acc: 100.00%] [G loss: 4.354146]\n",
      "epoch:35 step:27343 [D loss: 0.213453, acc: 94.53%] [G loss: 5.854804]\n",
      "epoch:35 step:27344 [D loss: 1.101083, acc: 46.88%] [G loss: 5.574184]\n",
      "epoch:35 step:27345 [D loss: 0.501496, acc: 78.91%] [G loss: 5.541274]\n",
      "epoch:35 step:27346 [D loss: 0.344905, acc: 80.47%] [G loss: 6.015463]\n",
      "epoch:35 step:27347 [D loss: 0.136956, acc: 99.22%] [G loss: 3.865098]\n",
      "epoch:35 step:27348 [D loss: 1.356426, acc: 50.00%] [G loss: 2.694968]\n",
      "epoch:35 step:27349 [D loss: 0.268733, acc: 93.75%] [G loss: 4.896823]\n",
      "epoch:35 step:27350 [D loss: 1.358096, acc: 50.00%] [G loss: 3.563375]\n",
      "epoch:35 step:27351 [D loss: 0.475811, acc: 72.66%] [G loss: 8.323851]\n",
      "epoch:35 step:27352 [D loss: 0.308653, acc: 83.59%] [G loss: 3.415137]\n",
      "epoch:35 step:27353 [D loss: 0.277295, acc: 93.75%] [G loss: 3.572334]\n",
      "epoch:35 step:27354 [D loss: 0.310509, acc: 93.75%] [G loss: 3.646157]\n",
      "epoch:35 step:27355 [D loss: 0.109779, acc: 100.00%] [G loss: 5.637515]\n",
      "epoch:35 step:27356 [D loss: 0.285696, acc: 96.09%] [G loss: 4.780790]\n",
      "epoch:35 step:27357 [D loss: 0.570727, acc: 64.84%] [G loss: 4.491992]\n",
      "epoch:35 step:27358 [D loss: 0.911914, acc: 29.69%] [G loss: 4.692850]\n",
      "epoch:35 step:27359 [D loss: 0.368092, acc: 92.19%] [G loss: 4.023407]\n",
      "epoch:35 step:27360 [D loss: 0.866427, acc: 50.00%] [G loss: 4.114795]\n",
      "epoch:35 step:27361 [D loss: 0.304527, acc: 94.53%] [G loss: 2.392334]\n",
      "epoch:35 step:27362 [D loss: 0.196703, acc: 97.66%] [G loss: 4.577962]\n",
      "epoch:35 step:27363 [D loss: 0.147871, acc: 100.00%] [G loss: 3.850828]\n",
      "epoch:35 step:27364 [D loss: 0.199193, acc: 98.44%] [G loss: 3.879890]\n",
      "epoch:35 step:27365 [D loss: 0.179985, acc: 97.66%] [G loss: 6.459940]\n",
      "epoch:35 step:27366 [D loss: 0.086558, acc: 100.00%] [G loss: 4.047164]\n",
      "epoch:35 step:27367 [D loss: 0.305340, acc: 85.16%] [G loss: 4.544976]\n",
      "epoch:35 step:27368 [D loss: 0.140162, acc: 98.44%] [G loss: 3.868586]\n",
      "epoch:35 step:27369 [D loss: 0.311173, acc: 89.06%] [G loss: 7.664720]\n",
      "epoch:35 step:27370 [D loss: 0.143091, acc: 99.22%] [G loss: 4.784139]\n",
      "epoch:35 step:27371 [D loss: 0.071607, acc: 100.00%] [G loss: 4.417186]\n",
      "epoch:35 step:27372 [D loss: 0.097236, acc: 98.44%] [G loss: 5.424407]\n",
      "epoch:35 step:27373 [D loss: 0.064699, acc: 100.00%] [G loss: 5.498956]\n",
      "epoch:35 step:27374 [D loss: 0.908817, acc: 43.75%] [G loss: 3.895130]\n",
      "epoch:35 step:27375 [D loss: 0.162729, acc: 99.22%] [G loss: 3.783043]\n",
      "epoch:35 step:27376 [D loss: 0.093410, acc: 100.00%] [G loss: 3.826687]\n",
      "epoch:35 step:27377 [D loss: 0.475886, acc: 71.88%] [G loss: 5.301770]\n",
      "epoch:35 step:27378 [D loss: 0.068891, acc: 99.22%] [G loss: 6.072523]\n",
      "epoch:35 step:27379 [D loss: 0.577248, acc: 71.09%] [G loss: 4.626357]\n",
      "epoch:35 step:27380 [D loss: 0.525883, acc: 67.97%] [G loss: 3.954436]\n",
      "epoch:35 step:27381 [D loss: 0.087864, acc: 100.00%] [G loss: 3.334653]\n",
      "epoch:35 step:27382 [D loss: 1.123605, acc: 26.56%] [G loss: 4.853658]\n",
      "epoch:35 step:27383 [D loss: 0.522055, acc: 64.84%] [G loss: 5.602196]\n",
      "epoch:35 step:27384 [D loss: 0.150200, acc: 99.22%] [G loss: 4.737891]\n",
      "epoch:35 step:27385 [D loss: 0.115711, acc: 100.00%] [G loss: 3.839350]\n",
      "epoch:35 step:27386 [D loss: 0.203895, acc: 98.44%] [G loss: 3.013915]\n",
      "epoch:35 step:27387 [D loss: 0.249429, acc: 96.09%] [G loss: 6.626331]\n",
      "epoch:35 step:27388 [D loss: 0.594910, acc: 67.19%] [G loss: 4.983448]\n",
      "epoch:35 step:27389 [D loss: 0.720228, acc: 54.69%] [G loss: 2.475666]\n",
      "epoch:35 step:27390 [D loss: 0.062812, acc: 100.00%] [G loss: 6.569060]\n",
      "epoch:35 step:27391 [D loss: 0.341421, acc: 89.06%] [G loss: 5.404804]\n",
      "epoch:35 step:27392 [D loss: 0.735502, acc: 56.25%] [G loss: 5.723541]\n",
      "epoch:35 step:27393 [D loss: 0.219082, acc: 100.00%] [G loss: 3.794724]\n",
      "epoch:35 step:27394 [D loss: 0.723566, acc: 53.12%] [G loss: 5.673387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27395 [D loss: 0.266960, acc: 93.75%] [G loss: 3.387303]\n",
      "epoch:35 step:27396 [D loss: 0.957125, acc: 50.00%] [G loss: 3.687930]\n",
      "epoch:35 step:27397 [D loss: 0.434186, acc: 78.91%] [G loss: 5.990451]\n",
      "epoch:35 step:27398 [D loss: 0.367886, acc: 90.62%] [G loss: 2.931321]\n",
      "epoch:35 step:27399 [D loss: 0.980887, acc: 50.00%] [G loss: 9.949213]\n",
      "epoch:35 step:27400 [D loss: 0.900101, acc: 53.12%] [G loss: 5.066443]\n",
      "epoch:35 step:27401 [D loss: 0.300406, acc: 92.19%] [G loss: 3.604634]\n",
      "epoch:35 step:27402 [D loss: 0.045174, acc: 100.00%] [G loss: 4.645426]\n",
      "epoch:35 step:27403 [D loss: 0.289200, acc: 91.41%] [G loss: 2.878649]\n",
      "epoch:35 step:27404 [D loss: 0.114654, acc: 99.22%] [G loss: 4.822233]\n",
      "epoch:35 step:27405 [D loss: 0.111974, acc: 100.00%] [G loss: 6.914001]\n",
      "epoch:35 step:27406 [D loss: 0.351159, acc: 81.25%] [G loss: 2.973516]\n",
      "epoch:35 step:27407 [D loss: 1.071255, acc: 50.78%] [G loss: 7.080519]\n",
      "epoch:35 step:27408 [D loss: 1.107940, acc: 50.00%] [G loss: 4.649177]\n",
      "epoch:35 step:27409 [D loss: 0.088527, acc: 99.22%] [G loss: 7.496622]\n",
      "epoch:35 step:27410 [D loss: 0.338991, acc: 90.62%] [G loss: 3.424838]\n",
      "epoch:35 step:27411 [D loss: 0.326533, acc: 86.72%] [G loss: 7.349647]\n",
      "epoch:35 step:27412 [D loss: 0.956264, acc: 49.22%] [G loss: 1.994166]\n",
      "epoch:35 step:27413 [D loss: 0.734266, acc: 52.34%] [G loss: 3.886111]\n",
      "epoch:35 step:27414 [D loss: 0.402661, acc: 82.03%] [G loss: 6.939531]\n",
      "epoch:35 step:27415 [D loss: 0.632483, acc: 57.03%] [G loss: 2.787884]\n",
      "epoch:35 step:27416 [D loss: 0.250561, acc: 94.53%] [G loss: 4.990767]\n",
      "epoch:35 step:27417 [D loss: 0.302200, acc: 94.53%] [G loss: 1.653415]\n",
      "epoch:35 step:27418 [D loss: 0.160813, acc: 96.88%] [G loss: 3.517123]\n",
      "epoch:35 step:27419 [D loss: 0.600100, acc: 66.41%] [G loss: 4.599529]\n",
      "epoch:35 step:27420 [D loss: 1.576736, acc: 49.22%] [G loss: 3.290067]\n",
      "epoch:35 step:27421 [D loss: 0.194470, acc: 96.09%] [G loss: 3.579125]\n",
      "epoch:35 step:27422 [D loss: 0.662031, acc: 60.16%] [G loss: 3.627456]\n",
      "epoch:35 step:27423 [D loss: 0.116762, acc: 100.00%] [G loss: 3.355945]\n",
      "epoch:35 step:27424 [D loss: 0.120124, acc: 100.00%] [G loss: 3.999418]\n",
      "epoch:35 step:27425 [D loss: 0.219499, acc: 97.66%] [G loss: 4.141395]\n",
      "epoch:35 step:27426 [D loss: 0.105615, acc: 100.00%] [G loss: 6.221564]\n",
      "epoch:35 step:27427 [D loss: 0.313234, acc: 96.09%] [G loss: 5.450051]\n",
      "epoch:35 step:27428 [D loss: 0.187511, acc: 97.66%] [G loss: 3.456656]\n",
      "epoch:35 step:27429 [D loss: 0.384863, acc: 78.12%] [G loss: 7.833061]\n",
      "epoch:35 step:27430 [D loss: 0.129339, acc: 100.00%] [G loss: 2.461798]\n",
      "epoch:35 step:27431 [D loss: 0.165451, acc: 96.88%] [G loss: 6.283741]\n",
      "epoch:35 step:27432 [D loss: 0.234015, acc: 97.66%] [G loss: 3.424514]\n",
      "epoch:35 step:27433 [D loss: 0.726838, acc: 53.91%] [G loss: 5.188835]\n",
      "epoch:35 step:27434 [D loss: 0.079455, acc: 100.00%] [G loss: 6.910345]\n",
      "epoch:35 step:27435 [D loss: 0.520201, acc: 71.09%] [G loss: 3.239165]\n",
      "epoch:35 step:27436 [D loss: 0.815305, acc: 44.53%] [G loss: 3.549513]\n",
      "epoch:35 step:27437 [D loss: 0.437778, acc: 67.19%] [G loss: 4.725941]\n",
      "epoch:35 step:27438 [D loss: 0.617003, acc: 62.50%] [G loss: 3.277842]\n",
      "epoch:35 step:27439 [D loss: 0.186174, acc: 96.88%] [G loss: 5.736393]\n",
      "epoch:35 step:27440 [D loss: 0.153307, acc: 98.44%] [G loss: 2.398108]\n",
      "epoch:35 step:27441 [D loss: 0.206064, acc: 99.22%] [G loss: 4.782820]\n",
      "epoch:35 step:27442 [D loss: 0.526321, acc: 71.09%] [G loss: 3.558158]\n",
      "epoch:35 step:27443 [D loss: 0.166446, acc: 98.44%] [G loss: 5.303020]\n",
      "epoch:35 step:27444 [D loss: 0.170553, acc: 99.22%] [G loss: 3.855875]\n",
      "epoch:35 step:27445 [D loss: 0.429779, acc: 71.88%] [G loss: 4.468390]\n",
      "epoch:35 step:27446 [D loss: 0.203687, acc: 97.66%] [G loss: 5.279457]\n",
      "epoch:35 step:27447 [D loss: 0.061035, acc: 100.00%] [G loss: 6.154331]\n",
      "epoch:35 step:27448 [D loss: 0.172119, acc: 97.66%] [G loss: 5.176016]\n",
      "epoch:35 step:27449 [D loss: 0.326731, acc: 92.97%] [G loss: 6.693569]\n",
      "epoch:35 step:27450 [D loss: 0.071443, acc: 100.00%] [G loss: 4.888470]\n",
      "epoch:35 step:27451 [D loss: 0.602045, acc: 64.06%] [G loss: 4.930368]\n",
      "epoch:35 step:27452 [D loss: 0.950356, acc: 51.56%] [G loss: 5.256571]\n",
      "epoch:35 step:27453 [D loss: 0.377840, acc: 89.84%] [G loss: 5.044400]\n",
      "epoch:35 step:27454 [D loss: 0.307931, acc: 84.38%] [G loss: 6.342108]\n",
      "epoch:35 step:27455 [D loss: 0.244943, acc: 93.75%] [G loss: 8.039762]\n",
      "epoch:35 step:27456 [D loss: 0.733224, acc: 56.25%] [G loss: 4.411157]\n",
      "epoch:35 step:27457 [D loss: 0.068961, acc: 99.22%] [G loss: 5.017697]\n",
      "epoch:35 step:27458 [D loss: 0.149544, acc: 99.22%] [G loss: 6.191298]\n",
      "epoch:35 step:27459 [D loss: 0.467079, acc: 64.84%] [G loss: 4.975608]\n",
      "epoch:35 step:27460 [D loss: 0.152684, acc: 99.22%] [G loss: 2.520751]\n",
      "epoch:35 step:27461 [D loss: 0.722100, acc: 54.69%] [G loss: 4.477551]\n",
      "epoch:35 step:27462 [D loss: 0.163431, acc: 100.00%] [G loss: 4.151618]\n",
      "epoch:35 step:27463 [D loss: 0.053968, acc: 100.00%] [G loss: 4.635937]\n",
      "epoch:35 step:27464 [D loss: 0.681993, acc: 57.81%] [G loss: 3.955000]\n",
      "epoch:35 step:27465 [D loss: 0.807950, acc: 53.91%] [G loss: 4.171274]\n",
      "epoch:35 step:27466 [D loss: 0.453674, acc: 82.03%] [G loss: 4.417149]\n",
      "epoch:35 step:27467 [D loss: 0.141793, acc: 99.22%] [G loss: 4.107597]\n",
      "epoch:35 step:27468 [D loss: 0.794686, acc: 50.00%] [G loss: 4.562239]\n",
      "epoch:35 step:27469 [D loss: 0.066452, acc: 100.00%] [G loss: 5.116172]\n",
      "epoch:35 step:27470 [D loss: 0.541918, acc: 59.38%] [G loss: 3.643714]\n",
      "epoch:35 step:27471 [D loss: 0.120735, acc: 99.22%] [G loss: 4.397866]\n",
      "epoch:35 step:27472 [D loss: 0.296999, acc: 92.19%] [G loss: 3.366112]\n",
      "epoch:35 step:27473 [D loss: 0.711453, acc: 58.59%] [G loss: 4.090080]\n",
      "epoch:35 step:27474 [D loss: 0.166968, acc: 95.31%] [G loss: 6.159628]\n",
      "epoch:35 step:27475 [D loss: 0.472295, acc: 76.56%] [G loss: 4.033013]\n",
      "epoch:35 step:27476 [D loss: 0.236271, acc: 94.53%] [G loss: 5.428746]\n",
      "epoch:35 step:27477 [D loss: 0.235351, acc: 94.53%] [G loss: 4.449041]\n",
      "epoch:35 step:27478 [D loss: 0.278364, acc: 89.06%] [G loss: 4.907401]\n",
      "epoch:35 step:27479 [D loss: 0.136549, acc: 100.00%] [G loss: 4.721770]\n",
      "epoch:35 step:27480 [D loss: 0.517704, acc: 63.28%] [G loss: 4.718960]\n",
      "epoch:35 step:27481 [D loss: 0.378643, acc: 79.69%] [G loss: 4.655066]\n",
      "epoch:35 step:27482 [D loss: 0.657133, acc: 53.91%] [G loss: 3.883342]\n",
      "epoch:35 step:27483 [D loss: 0.364972, acc: 81.25%] [G loss: 8.171583]\n",
      "epoch:35 step:27484 [D loss: 0.099901, acc: 100.00%] [G loss: 5.749219]\n",
      "epoch:35 step:27485 [D loss: 0.262001, acc: 96.09%] [G loss: 6.698986]\n",
      "epoch:35 step:27486 [D loss: 0.159679, acc: 98.44%] [G loss: 4.074348]\n",
      "epoch:35 step:27487 [D loss: 0.114464, acc: 99.22%] [G loss: 5.865568]\n",
      "epoch:35 step:27488 [D loss: 0.153282, acc: 100.00%] [G loss: 5.066104]\n",
      "epoch:35 step:27489 [D loss: 0.097271, acc: 100.00%] [G loss: 4.384468]\n",
      "epoch:35 step:27490 [D loss: 0.273986, acc: 96.88%] [G loss: 3.076048]\n",
      "epoch:35 step:27491 [D loss: 0.310881, acc: 96.09%] [G loss: 4.282362]\n",
      "epoch:35 step:27492 [D loss: 0.438440, acc: 86.72%] [G loss: 2.415946]\n",
      "epoch:35 step:27493 [D loss: 0.120965, acc: 98.44%] [G loss: 5.924560]\n",
      "epoch:35 step:27494 [D loss: 0.194979, acc: 98.44%] [G loss: 4.217038]\n",
      "epoch:35 step:27495 [D loss: 0.413392, acc: 92.97%] [G loss: 3.093365]\n",
      "epoch:35 step:27496 [D loss: 0.081569, acc: 100.00%] [G loss: 6.024056]\n",
      "epoch:35 step:27497 [D loss: 0.084859, acc: 100.00%] [G loss: 3.102721]\n",
      "epoch:35 step:27498 [D loss: 0.448984, acc: 84.38%] [G loss: 2.819451]\n",
      "epoch:35 step:27499 [D loss: 0.737022, acc: 56.25%] [G loss: 3.811238]\n",
      "epoch:35 step:27500 [D loss: 0.344375, acc: 93.75%] [G loss: 4.239310]\n",
      "epoch:35 step:27501 [D loss: 0.168280, acc: 99.22%] [G loss: 3.644684]\n",
      "epoch:35 step:27502 [D loss: 0.173640, acc: 100.00%] [G loss: 5.094763]\n",
      "epoch:35 step:27503 [D loss: 0.180081, acc: 96.88%] [G loss: 4.285806]\n",
      "epoch:35 step:27504 [D loss: 0.482590, acc: 79.69%] [G loss: 3.333946]\n",
      "epoch:35 step:27505 [D loss: 0.585738, acc: 57.03%] [G loss: 3.939489]\n",
      "epoch:35 step:27506 [D loss: 0.250543, acc: 96.09%] [G loss: 3.002511]\n",
      "epoch:35 step:27507 [D loss: 1.084368, acc: 40.62%] [G loss: 5.716750]\n",
      "epoch:35 step:27508 [D loss: 0.606149, acc: 72.66%] [G loss: 4.440732]\n",
      "epoch:35 step:27509 [D loss: 0.113457, acc: 100.00%] [G loss: 3.545315]\n",
      "epoch:35 step:27510 [D loss: 0.129945, acc: 99.22%] [G loss: 4.375973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27511 [D loss: 0.716908, acc: 55.47%] [G loss: 4.019212]\n",
      "epoch:35 step:27512 [D loss: 0.427249, acc: 86.72%] [G loss: 6.430680]\n",
      "epoch:35 step:27513 [D loss: 0.840872, acc: 39.06%] [G loss: 6.010517]\n",
      "epoch:35 step:27514 [D loss: 0.158157, acc: 100.00%] [G loss: 3.508157]\n",
      "epoch:35 step:27515 [D loss: 0.112826, acc: 100.00%] [G loss: 4.830591]\n",
      "epoch:35 step:27516 [D loss: 0.114483, acc: 99.22%] [G loss: 6.436385]\n",
      "epoch:35 step:27517 [D loss: 0.576932, acc: 57.81%] [G loss: 3.956137]\n",
      "epoch:35 step:27518 [D loss: 0.144800, acc: 100.00%] [G loss: 4.030761]\n",
      "epoch:35 step:27519 [D loss: 0.281349, acc: 90.62%] [G loss: 4.498375]\n",
      "epoch:35 step:27520 [D loss: 0.558679, acc: 65.62%] [G loss: 4.747419]\n",
      "epoch:35 step:27521 [D loss: 0.355537, acc: 92.19%] [G loss: 5.334044]\n",
      "epoch:35 step:27522 [D loss: 0.617881, acc: 65.62%] [G loss: 4.858177]\n",
      "epoch:35 step:27523 [D loss: 0.269529, acc: 93.75%] [G loss: 4.001040]\n",
      "epoch:35 step:27524 [D loss: 0.090501, acc: 99.22%] [G loss: 5.183224]\n",
      "epoch:35 step:27525 [D loss: 0.112732, acc: 99.22%] [G loss: 3.334428]\n",
      "epoch:35 step:27526 [D loss: 0.377515, acc: 78.91%] [G loss: 5.081958]\n",
      "epoch:35 step:27527 [D loss: 0.914399, acc: 47.66%] [G loss: 4.940569]\n",
      "epoch:35 step:27528 [D loss: 0.075308, acc: 99.22%] [G loss: 3.822451]\n",
      "epoch:35 step:27529 [D loss: 0.575464, acc: 65.62%] [G loss: 4.874176]\n",
      "epoch:35 step:27530 [D loss: 0.624783, acc: 60.16%] [G loss: 2.563927]\n",
      "epoch:35 step:27531 [D loss: 1.251004, acc: 16.41%] [G loss: 4.536660]\n",
      "epoch:35 step:27532 [D loss: 0.377948, acc: 83.59%] [G loss: 4.448354]\n",
      "epoch:35 step:27533 [D loss: 0.304297, acc: 89.84%] [G loss: 5.065715]\n",
      "epoch:35 step:27534 [D loss: 0.417501, acc: 67.97%] [G loss: 6.596871]\n",
      "epoch:35 step:27535 [D loss: 0.190359, acc: 96.09%] [G loss: 4.987758]\n",
      "epoch:35 step:27536 [D loss: 0.337040, acc: 90.62%] [G loss: 3.435123]\n",
      "epoch:35 step:27537 [D loss: 0.418954, acc: 83.59%] [G loss: 4.008112]\n",
      "epoch:35 step:27538 [D loss: 0.708396, acc: 60.16%] [G loss: 6.679401]\n",
      "epoch:35 step:27539 [D loss: 0.391515, acc: 83.59%] [G loss: 4.781739]\n",
      "epoch:35 step:27540 [D loss: 0.759805, acc: 53.12%] [G loss: 7.254420]\n",
      "epoch:35 step:27541 [D loss: 0.357544, acc: 89.84%] [G loss: 2.170042]\n",
      "epoch:35 step:27542 [D loss: 0.379299, acc: 79.69%] [G loss: 5.435327]\n",
      "epoch:35 step:27543 [D loss: 0.422531, acc: 85.94%] [G loss: 4.791483]\n",
      "epoch:35 step:27544 [D loss: 1.426878, acc: 8.59%] [G loss: 5.516272]\n",
      "epoch:35 step:27545 [D loss: 0.609371, acc: 59.38%] [G loss: 3.013767]\n",
      "epoch:35 step:27546 [D loss: 0.183727, acc: 98.44%] [G loss: 3.739571]\n",
      "epoch:35 step:27547 [D loss: 0.377277, acc: 80.47%] [G loss: 6.925778]\n",
      "epoch:35 step:27548 [D loss: 0.690973, acc: 60.16%] [G loss: 2.929525]\n",
      "epoch:35 step:27549 [D loss: 0.100388, acc: 98.44%] [G loss: 5.029556]\n",
      "epoch:35 step:27550 [D loss: 0.369523, acc: 89.84%] [G loss: 3.373539]\n",
      "epoch:35 step:27551 [D loss: 0.618968, acc: 61.72%] [G loss: 1.938318]\n",
      "epoch:35 step:27552 [D loss: 0.036574, acc: 100.00%] [G loss: 4.968987]\n",
      "epoch:35 step:27553 [D loss: 0.743443, acc: 57.81%] [G loss: 8.078163]\n",
      "epoch:35 step:27554 [D loss: 0.189547, acc: 96.88%] [G loss: 3.450192]\n",
      "epoch:35 step:27555 [D loss: 0.273474, acc: 85.16%] [G loss: 3.275760]\n",
      "epoch:35 step:27556 [D loss: 0.285367, acc: 90.62%] [G loss: 4.613425]\n",
      "epoch:35 step:27557 [D loss: 0.225775, acc: 94.53%] [G loss: 5.478706]\n",
      "epoch:35 step:27558 [D loss: 0.643466, acc: 60.16%] [G loss: 5.646474]\n",
      "epoch:35 step:27559 [D loss: 0.407603, acc: 73.44%] [G loss: 6.599694]\n",
      "epoch:35 step:27560 [D loss: 0.484848, acc: 64.06%] [G loss: 4.145099]\n",
      "epoch:35 step:27561 [D loss: 0.086918, acc: 100.00%] [G loss: 4.582433]\n",
      "epoch:35 step:27562 [D loss: 0.149813, acc: 99.22%] [G loss: 4.186870]\n",
      "epoch:35 step:27563 [D loss: 0.114045, acc: 99.22%] [G loss: 7.355024]\n",
      "epoch:35 step:27564 [D loss: 0.323585, acc: 95.31%] [G loss: 4.040741]\n",
      "epoch:35 step:27565 [D loss: 1.639004, acc: 31.25%] [G loss: 5.107080]\n",
      "epoch:35 step:27566 [D loss: 0.809977, acc: 41.41%] [G loss: 5.131771]\n",
      "epoch:35 step:27567 [D loss: 0.259759, acc: 98.44%] [G loss: 4.369583]\n",
      "epoch:35 step:27568 [D loss: 0.258546, acc: 95.31%] [G loss: 6.314047]\n",
      "epoch:35 step:27569 [D loss: 0.317889, acc: 92.19%] [G loss: 2.547022]\n",
      "epoch:35 step:27570 [D loss: 0.384750, acc: 86.72%] [G loss: 3.667867]\n",
      "epoch:35 step:27571 [D loss: 0.633952, acc: 61.72%] [G loss: 3.346359]\n",
      "epoch:35 step:27572 [D loss: 0.231220, acc: 98.44%] [G loss: 5.243364]\n",
      "epoch:35 step:27573 [D loss: 0.342314, acc: 85.16%] [G loss: 2.006479]\n",
      "epoch:35 step:27574 [D loss: 0.188221, acc: 96.88%] [G loss: 4.656233]\n",
      "epoch:35 step:27575 [D loss: 0.467324, acc: 77.34%] [G loss: 3.182687]\n",
      "epoch:35 step:27576 [D loss: 0.702652, acc: 53.91%] [G loss: 6.039426]\n",
      "epoch:35 step:27577 [D loss: 0.081271, acc: 99.22%] [G loss: 4.709614]\n",
      "epoch:35 step:27578 [D loss: 0.369812, acc: 75.00%] [G loss: 6.232362]\n",
      "epoch:35 step:27579 [D loss: 0.419462, acc: 83.59%] [G loss: 4.665058]\n",
      "epoch:35 step:27580 [D loss: 0.418201, acc: 72.66%] [G loss: 4.461479]\n",
      "epoch:35 step:27581 [D loss: 0.156499, acc: 99.22%] [G loss: 4.620613]\n",
      "epoch:35 step:27582 [D loss: 0.078498, acc: 100.00%] [G loss: 5.817194]\n",
      "epoch:35 step:27583 [D loss: 0.982072, acc: 32.81%] [G loss: 4.067342]\n",
      "epoch:35 step:27584 [D loss: 0.057690, acc: 100.00%] [G loss: 4.854370]\n",
      "epoch:35 step:27585 [D loss: 0.018051, acc: 100.00%] [G loss: 6.481341]\n",
      "epoch:35 step:27586 [D loss: 0.146511, acc: 98.44%] [G loss: 4.226809]\n",
      "epoch:35 step:27587 [D loss: 0.335239, acc: 96.88%] [G loss: 2.866796]\n",
      "epoch:35 step:27588 [D loss: 1.890523, acc: 4.69%] [G loss: 3.546998]\n",
      "epoch:35 step:27589 [D loss: 0.207577, acc: 96.88%] [G loss: 3.331686]\n",
      "epoch:35 step:27590 [D loss: 0.260048, acc: 90.62%] [G loss: 4.670622]\n",
      "epoch:35 step:27591 [D loss: 0.393339, acc: 88.28%] [G loss: 6.090062]\n",
      "epoch:35 step:27592 [D loss: 0.802239, acc: 53.12%] [G loss: 2.698457]\n",
      "epoch:35 step:27593 [D loss: 0.305291, acc: 92.97%] [G loss: 6.017277]\n",
      "epoch:35 step:27594 [D loss: 0.389468, acc: 78.12%] [G loss: 5.632665]\n",
      "epoch:35 step:27595 [D loss: 0.847127, acc: 52.34%] [G loss: 6.006569]\n",
      "epoch:35 step:27596 [D loss: 0.826513, acc: 51.56%] [G loss: 4.993064]\n",
      "epoch:35 step:27597 [D loss: 0.480781, acc: 71.09%] [G loss: 4.732521]\n",
      "epoch:35 step:27598 [D loss: 0.499461, acc: 69.53%] [G loss: 4.996196]\n",
      "epoch:35 step:27599 [D loss: 0.450441, acc: 77.34%] [G loss: 4.820999]\n",
      "epoch:35 step:27600 [D loss: 0.541073, acc: 78.12%] [G loss: 5.781771]\n",
      "epoch:35 step:27601 [D loss: 0.925782, acc: 33.59%] [G loss: 5.965300]\n",
      "epoch:35 step:27602 [D loss: 0.381930, acc: 75.78%] [G loss: 2.810265]\n",
      "epoch:35 step:27603 [D loss: 0.228536, acc: 94.53%] [G loss: 3.742020]\n",
      "epoch:35 step:27604 [D loss: 0.179508, acc: 99.22%] [G loss: 2.423232]\n",
      "epoch:35 step:27605 [D loss: 0.465702, acc: 84.38%] [G loss: 5.014606]\n",
      "epoch:35 step:27606 [D loss: 0.054889, acc: 100.00%] [G loss: 4.679821]\n",
      "epoch:35 step:27607 [D loss: 0.345540, acc: 87.50%] [G loss: 3.277076]\n",
      "epoch:35 step:27608 [D loss: 0.876934, acc: 42.19%] [G loss: 3.251543]\n",
      "epoch:35 step:27609 [D loss: 0.403894, acc: 81.25%] [G loss: 6.626624]\n",
      "epoch:35 step:27610 [D loss: 0.175575, acc: 98.44%] [G loss: 4.261784]\n",
      "epoch:35 step:27611 [D loss: 0.260167, acc: 95.31%] [G loss: 6.394589]\n",
      "epoch:35 step:27612 [D loss: 0.211086, acc: 94.53%] [G loss: 6.632414]\n",
      "epoch:35 step:27613 [D loss: 0.101884, acc: 100.00%] [G loss: 4.334396]\n",
      "epoch:35 step:27614 [D loss: 0.103636, acc: 100.00%] [G loss: 4.086333]\n",
      "epoch:35 step:27615 [D loss: 0.069793, acc: 100.00%] [G loss: 3.963746]\n",
      "epoch:35 step:27616 [D loss: 0.373727, acc: 82.81%] [G loss: 5.101119]\n",
      "epoch:35 step:27617 [D loss: 0.382547, acc: 89.84%] [G loss: 5.443367]\n",
      "epoch:35 step:27618 [D loss: 0.257419, acc: 95.31%] [G loss: 3.518458]\n",
      "epoch:35 step:27619 [D loss: 0.193195, acc: 95.31%] [G loss: 5.440278]\n",
      "epoch:35 step:27620 [D loss: 0.394681, acc: 81.25%] [G loss: 3.593550]\n",
      "epoch:35 step:27621 [D loss: 0.274562, acc: 89.84%] [G loss: 3.491016]\n",
      "epoch:35 step:27622 [D loss: 0.244692, acc: 94.53%] [G loss: 5.477055]\n",
      "epoch:35 step:27623 [D loss: 1.017675, acc: 32.03%] [G loss: 3.761946]\n",
      "epoch:35 step:27624 [D loss: 0.301191, acc: 90.62%] [G loss: 5.758772]\n",
      "epoch:35 step:27625 [D loss: 0.995364, acc: 28.91%] [G loss: 4.960529]\n",
      "epoch:35 step:27626 [D loss: 0.235748, acc: 96.09%] [G loss: 2.772942]\n",
      "epoch:35 step:27627 [D loss: 0.437513, acc: 82.81%] [G loss: 5.827738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27628 [D loss: 0.093175, acc: 98.44%] [G loss: 3.528710]\n",
      "epoch:35 step:27629 [D loss: 1.428217, acc: 13.28%] [G loss: 4.462833]\n",
      "epoch:35 step:27630 [D loss: 0.155157, acc: 97.66%] [G loss: 5.607556]\n",
      "epoch:35 step:27631 [D loss: 0.186268, acc: 97.66%] [G loss: 4.811345]\n",
      "epoch:35 step:27632 [D loss: 0.470464, acc: 74.22%] [G loss: 3.903973]\n",
      "epoch:35 step:27633 [D loss: 0.494183, acc: 76.56%] [G loss: 2.432057]\n",
      "epoch:35 step:27634 [D loss: 0.261219, acc: 92.19%] [G loss: 4.941810]\n",
      "epoch:35 step:27635 [D loss: 0.281000, acc: 94.53%] [G loss: 3.839926]\n",
      "epoch:35 step:27636 [D loss: 0.722482, acc: 53.91%] [G loss: 4.569806]\n",
      "epoch:35 step:27637 [D loss: 0.194141, acc: 98.44%] [G loss: 3.735810]\n",
      "epoch:35 step:27638 [D loss: 1.020398, acc: 48.44%] [G loss: 4.874648]\n",
      "epoch:35 step:27639 [D loss: 0.124133, acc: 100.00%] [G loss: 3.027416]\n",
      "epoch:35 step:27640 [D loss: 0.543953, acc: 64.84%] [G loss: 7.439592]\n",
      "epoch:35 step:27641 [D loss: 0.516873, acc: 65.62%] [G loss: 3.908839]\n",
      "epoch:35 step:27642 [D loss: 0.273195, acc: 91.41%] [G loss: 4.602096]\n",
      "epoch:35 step:27643 [D loss: 0.428975, acc: 75.00%] [G loss: 7.781687]\n",
      "epoch:35 step:27644 [D loss: 0.623808, acc: 60.94%] [G loss: 3.511730]\n",
      "epoch:35 step:27645 [D loss: 0.206882, acc: 93.75%] [G loss: 6.946384]\n",
      "epoch:35 step:27646 [D loss: 0.519676, acc: 76.56%] [G loss: 3.614940]\n",
      "epoch:35 step:27647 [D loss: 0.524310, acc: 69.53%] [G loss: 3.711430]\n",
      "epoch:35 step:27648 [D loss: 0.390953, acc: 83.59%] [G loss: 5.519959]\n",
      "epoch:35 step:27649 [D loss: 0.213680, acc: 99.22%] [G loss: 2.994071]\n",
      "epoch:35 step:27650 [D loss: 0.382145, acc: 89.06%] [G loss: 3.372268]\n",
      "epoch:35 step:27651 [D loss: 1.735488, acc: 12.50%] [G loss: 4.834549]\n",
      "epoch:35 step:27652 [D loss: 0.302995, acc: 90.62%] [G loss: 3.956567]\n",
      "epoch:35 step:27653 [D loss: 0.541815, acc: 69.53%] [G loss: 5.799735]\n",
      "epoch:35 step:27654 [D loss: 0.400215, acc: 88.28%] [G loss: 3.774235]\n",
      "epoch:35 step:27655 [D loss: 0.403806, acc: 84.38%] [G loss: 4.531981]\n",
      "epoch:35 step:27656 [D loss: 0.177086, acc: 97.66%] [G loss: 5.842237]\n",
      "epoch:35 step:27657 [D loss: 0.209378, acc: 92.19%] [G loss: 6.265676]\n",
      "epoch:35 step:27658 [D loss: 0.068411, acc: 99.22%] [G loss: 4.364705]\n",
      "epoch:35 step:27659 [D loss: 0.176438, acc: 100.00%] [G loss: 3.386550]\n",
      "epoch:35 step:27660 [D loss: 0.216223, acc: 97.66%] [G loss: 4.592160]\n",
      "epoch:35 step:27661 [D loss: 0.592323, acc: 62.50%] [G loss: 5.111072]\n",
      "epoch:35 step:27662 [D loss: 0.308439, acc: 86.72%] [G loss: 6.292753]\n",
      "epoch:35 step:27663 [D loss: 0.235948, acc: 95.31%] [G loss: 3.975323]\n",
      "epoch:35 step:27664 [D loss: 0.065933, acc: 100.00%] [G loss: 4.028310]\n",
      "epoch:35 step:27665 [D loss: 0.405977, acc: 83.59%] [G loss: 5.437043]\n",
      "epoch:35 step:27666 [D loss: 0.142451, acc: 99.22%] [G loss: 3.171608]\n",
      "epoch:35 step:27667 [D loss: 0.496142, acc: 65.62%] [G loss: 4.131267]\n",
      "epoch:35 step:27668 [D loss: 0.093990, acc: 100.00%] [G loss: 6.777808]\n",
      "epoch:35 step:27669 [D loss: 0.438836, acc: 72.66%] [G loss: 5.990614]\n",
      "epoch:35 step:27670 [D loss: 0.281695, acc: 94.53%] [G loss: 4.902188]\n",
      "epoch:35 step:27671 [D loss: 0.014634, acc: 100.00%] [G loss: 5.188426]\n",
      "epoch:35 step:27672 [D loss: 0.371042, acc: 87.50%] [G loss: 4.825606]\n",
      "epoch:35 step:27673 [D loss: 0.798578, acc: 50.00%] [G loss: 4.628732]\n",
      "epoch:35 step:27674 [D loss: 0.161149, acc: 98.44%] [G loss: 6.728973]\n",
      "epoch:35 step:27675 [D loss: 0.620261, acc: 59.38%] [G loss: 7.193624]\n",
      "epoch:35 step:27676 [D loss: 0.486517, acc: 75.78%] [G loss: 2.655706]\n",
      "epoch:35 step:27677 [D loss: 0.583341, acc: 55.47%] [G loss: 2.743120]\n",
      "epoch:35 step:27678 [D loss: 0.678048, acc: 54.69%] [G loss: 3.302933]\n",
      "epoch:35 step:27679 [D loss: 0.430755, acc: 86.72%] [G loss: 3.900862]\n",
      "epoch:35 step:27680 [D loss: 0.087853, acc: 100.00%] [G loss: 4.866137]\n",
      "epoch:35 step:27681 [D loss: 0.138341, acc: 100.00%] [G loss: 4.358031]\n",
      "epoch:35 step:27682 [D loss: 0.409128, acc: 82.81%] [G loss: 5.310134]\n",
      "epoch:35 step:27683 [D loss: 0.274448, acc: 96.09%] [G loss: 3.037739]\n",
      "epoch:35 step:27684 [D loss: 0.468139, acc: 77.34%] [G loss: 4.242176]\n",
      "epoch:35 step:27685 [D loss: 0.552486, acc: 71.88%] [G loss: 5.796479]\n",
      "epoch:35 step:27686 [D loss: 0.782877, acc: 53.91%] [G loss: 5.988881]\n",
      "epoch:35 step:27687 [D loss: 0.306426, acc: 85.16%] [G loss: 4.254782]\n",
      "epoch:35 step:27688 [D loss: 0.473763, acc: 78.91%] [G loss: 5.149334]\n",
      "epoch:35 step:27689 [D loss: 0.478327, acc: 78.12%] [G loss: 2.581488]\n",
      "epoch:35 step:27690 [D loss: 0.786644, acc: 57.03%] [G loss: 6.122633]\n",
      "epoch:35 step:27691 [D loss: 0.100415, acc: 99.22%] [G loss: 5.482692]\n",
      "epoch:35 step:27692 [D loss: 0.526004, acc: 78.12%] [G loss: 3.427267]\n",
      "epoch:35 step:27693 [D loss: 0.234592, acc: 92.19%] [G loss: 3.671591]\n",
      "epoch:35 step:27694 [D loss: 0.077970, acc: 100.00%] [G loss: 4.719322]\n",
      "epoch:35 step:27695 [D loss: 0.100172, acc: 100.00%] [G loss: 5.316231]\n",
      "epoch:35 step:27696 [D loss: 0.890042, acc: 47.66%] [G loss: 5.271457]\n",
      "epoch:35 step:27697 [D loss: 0.382564, acc: 89.06%] [G loss: 5.664390]\n",
      "epoch:35 step:27698 [D loss: 0.924297, acc: 48.44%] [G loss: 5.538733]\n",
      "epoch:35 step:27699 [D loss: 0.164231, acc: 98.44%] [G loss: 5.675595]\n",
      "epoch:35 step:27700 [D loss: 0.144025, acc: 97.66%] [G loss: 5.631541]\n",
      "epoch:35 step:27701 [D loss: 0.555805, acc: 65.62%] [G loss: 4.632240]\n",
      "epoch:35 step:27702 [D loss: 0.133254, acc: 99.22%] [G loss: 3.983829]\n",
      "epoch:35 step:27703 [D loss: 0.263616, acc: 94.53%] [G loss: 5.073067]\n",
      "epoch:35 step:27704 [D loss: 0.161648, acc: 98.44%] [G loss: 5.385888]\n",
      "epoch:35 step:27705 [D loss: 0.342562, acc: 84.38%] [G loss: 3.609781]\n",
      "epoch:35 step:27706 [D loss: 0.231519, acc: 95.31%] [G loss: 4.282805]\n",
      "epoch:35 step:27707 [D loss: 0.345609, acc: 88.28%] [G loss: 5.167665]\n",
      "epoch:35 step:27708 [D loss: 0.393929, acc: 78.12%] [G loss: 3.456950]\n",
      "epoch:35 step:27709 [D loss: 0.344005, acc: 86.72%] [G loss: 7.453979]\n",
      "epoch:35 step:27710 [D loss: 0.064486, acc: 100.00%] [G loss: 5.935305]\n",
      "epoch:35 step:27711 [D loss: 0.443733, acc: 78.12%] [G loss: 5.969818]\n",
      "epoch:35 step:27712 [D loss: 0.672446, acc: 64.06%] [G loss: 4.943980]\n",
      "epoch:35 step:27713 [D loss: 0.452071, acc: 72.66%] [G loss: 6.751379]\n",
      "epoch:35 step:27714 [D loss: 0.147597, acc: 98.44%] [G loss: 4.779377]\n",
      "epoch:35 step:27715 [D loss: 0.084619, acc: 100.00%] [G loss: 5.278974]\n",
      "epoch:35 step:27716 [D loss: 0.708312, acc: 57.03%] [G loss: 2.040550]\n",
      "epoch:35 step:27717 [D loss: 0.163846, acc: 97.66%] [G loss: 3.833068]\n",
      "epoch:35 step:27718 [D loss: 0.804960, acc: 51.56%] [G loss: 4.721925]\n",
      "epoch:35 step:27719 [D loss: 0.331379, acc: 82.81%] [G loss: 5.747571]\n",
      "epoch:35 step:27720 [D loss: 1.838893, acc: 50.00%] [G loss: 2.756803]\n",
      "epoch:35 step:27721 [D loss: 0.052507, acc: 100.00%] [G loss: 4.792759]\n",
      "epoch:35 step:27722 [D loss: 0.963797, acc: 50.00%] [G loss: 7.614529]\n",
      "epoch:35 step:27723 [D loss: 0.596317, acc: 57.81%] [G loss: 3.804808]\n",
      "epoch:35 step:27724 [D loss: 0.250050, acc: 92.19%] [G loss: 2.660579]\n",
      "epoch:35 step:27725 [D loss: 0.838361, acc: 50.78%] [G loss: 4.206592]\n",
      "epoch:35 step:27726 [D loss: 1.032306, acc: 50.00%] [G loss: 6.387897]\n",
      "epoch:35 step:27727 [D loss: 0.258924, acc: 90.62%] [G loss: 6.000675]\n",
      "epoch:35 step:27728 [D loss: 0.403250, acc: 84.38%] [G loss: 3.178200]\n",
      "epoch:35 step:27729 [D loss: 0.170682, acc: 99.22%] [G loss: 7.016042]\n",
      "epoch:35 step:27730 [D loss: 1.184568, acc: 26.56%] [G loss: 4.641893]\n",
      "epoch:35 step:27731 [D loss: 0.464434, acc: 75.00%] [G loss: 3.677578]\n",
      "epoch:35 step:27732 [D loss: 0.207879, acc: 100.00%] [G loss: 5.009254]\n",
      "epoch:35 step:27733 [D loss: 0.347857, acc: 87.50%] [G loss: 2.658543]\n",
      "epoch:35 step:27734 [D loss: 0.117780, acc: 100.00%] [G loss: 3.795700]\n",
      "epoch:35 step:27735 [D loss: 0.317209, acc: 91.41%] [G loss: 5.069314]\n",
      "epoch:35 step:27736 [D loss: 0.042585, acc: 100.00%] [G loss: 4.733110]\n",
      "epoch:35 step:27737 [D loss: 0.787023, acc: 55.47%] [G loss: 1.720655]\n",
      "epoch:35 step:27738 [D loss: 0.184625, acc: 100.00%] [G loss: 3.181367]\n",
      "epoch:35 step:27739 [D loss: 0.331588, acc: 85.94%] [G loss: 4.622600]\n",
      "epoch:35 step:27740 [D loss: 0.159184, acc: 100.00%] [G loss: 5.145230]\n",
      "epoch:35 step:27741 [D loss: 1.024896, acc: 42.97%] [G loss: 6.039462]\n",
      "epoch:35 step:27742 [D loss: 0.462446, acc: 64.84%] [G loss: 4.415678]\n",
      "epoch:35 step:27743 [D loss: 0.322622, acc: 87.50%] [G loss: 3.560916]\n",
      "epoch:35 step:27744 [D loss: 0.608742, acc: 68.75%] [G loss: 4.158878]\n",
      "epoch:35 step:27745 [D loss: 0.720328, acc: 54.69%] [G loss: 3.435531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27746 [D loss: 0.444130, acc: 75.78%] [G loss: 2.415749]\n",
      "epoch:35 step:27747 [D loss: 0.373792, acc: 75.00%] [G loss: 5.409130]\n",
      "epoch:35 step:27748 [D loss: 0.072546, acc: 100.00%] [G loss: 3.613713]\n",
      "epoch:35 step:27749 [D loss: 0.699957, acc: 60.16%] [G loss: 4.162199]\n",
      "epoch:35 step:27750 [D loss: 0.576355, acc: 74.22%] [G loss: 4.675677]\n",
      "epoch:35 step:27751 [D loss: 1.143600, acc: 25.78%] [G loss: 5.475739]\n",
      "epoch:35 step:27752 [D loss: 0.149009, acc: 97.66%] [G loss: 4.861678]\n",
      "epoch:35 step:27753 [D loss: 0.148527, acc: 99.22%] [G loss: 5.446674]\n",
      "epoch:35 step:27754 [D loss: 0.242339, acc: 97.66%] [G loss: 4.427172]\n",
      "epoch:35 step:27755 [D loss: 0.506106, acc: 67.19%] [G loss: 3.133949]\n",
      "epoch:35 step:27756 [D loss: 0.080582, acc: 100.00%] [G loss: 6.092649]\n",
      "epoch:35 step:27757 [D loss: 0.057051, acc: 100.00%] [G loss: 5.986733]\n",
      "epoch:35 step:27758 [D loss: 0.431024, acc: 71.88%] [G loss: 4.176217]\n",
      "epoch:35 step:27759 [D loss: 0.651301, acc: 60.16%] [G loss: 4.936674]\n",
      "epoch:35 step:27760 [D loss: 0.308695, acc: 88.28%] [G loss: 2.665718]\n",
      "epoch:35 step:27761 [D loss: 0.231332, acc: 100.00%] [G loss: 4.118455]\n",
      "epoch:35 step:27762 [D loss: 0.592934, acc: 62.50%] [G loss: 3.416754]\n",
      "epoch:35 step:27763 [D loss: 0.085897, acc: 100.00%] [G loss: 4.415848]\n",
      "epoch:35 step:27764 [D loss: 0.766441, acc: 51.56%] [G loss: 3.036532]\n",
      "epoch:35 step:27765 [D loss: 0.499851, acc: 69.53%] [G loss: 6.275906]\n",
      "epoch:35 step:27766 [D loss: 0.188945, acc: 97.66%] [G loss: 2.976696]\n",
      "epoch:35 step:27767 [D loss: 0.168132, acc: 99.22%] [G loss: 2.242287]\n",
      "epoch:35 step:27768 [D loss: 0.549227, acc: 64.06%] [G loss: 3.524843]\n",
      "epoch:35 step:27769 [D loss: 0.035349, acc: 100.00%] [G loss: 7.980844]\n",
      "epoch:35 step:27770 [D loss: 0.351117, acc: 78.91%] [G loss: 5.974308]\n",
      "epoch:35 step:27771 [D loss: 0.277553, acc: 96.88%] [G loss: 7.632798]\n",
      "epoch:35 step:27772 [D loss: 1.027543, acc: 25.00%] [G loss: 4.763234]\n",
      "epoch:35 step:27773 [D loss: 0.172276, acc: 97.66%] [G loss: 4.959139]\n",
      "epoch:35 step:27774 [D loss: 2.487768, acc: 39.06%] [G loss: 4.054512]\n",
      "epoch:35 step:27775 [D loss: 0.060655, acc: 100.00%] [G loss: 5.112526]\n",
      "epoch:35 step:27776 [D loss: 0.483157, acc: 81.25%] [G loss: 4.921424]\n",
      "epoch:35 step:27777 [D loss: 0.557253, acc: 71.09%] [G loss: 3.977375]\n",
      "epoch:35 step:27778 [D loss: 0.752614, acc: 46.88%] [G loss: 3.275171]\n",
      "epoch:35 step:27779 [D loss: 0.266638, acc: 96.09%] [G loss: 4.482871]\n",
      "epoch:35 step:27780 [D loss: 1.132854, acc: 16.41%] [G loss: 2.261483]\n",
      "epoch:35 step:27781 [D loss: 0.344065, acc: 90.62%] [G loss: 5.847422]\n",
      "epoch:35 step:27782 [D loss: 0.483521, acc: 80.47%] [G loss: 3.851300]\n",
      "epoch:35 step:27783 [D loss: 0.513461, acc: 64.06%] [G loss: 2.375506]\n",
      "epoch:35 step:27784 [D loss: 0.102265, acc: 98.44%] [G loss: 3.809400]\n",
      "epoch:35 step:27785 [D loss: 0.163696, acc: 99.22%] [G loss: 3.791914]\n",
      "epoch:35 step:27786 [D loss: 0.344538, acc: 95.31%] [G loss: 3.728614]\n",
      "epoch:35 step:27787 [D loss: 0.563693, acc: 66.41%] [G loss: 5.617319]\n",
      "epoch:35 step:27788 [D loss: 0.170877, acc: 99.22%] [G loss: 3.034268]\n",
      "epoch:35 step:27789 [D loss: 0.093306, acc: 99.22%] [G loss: 6.251652]\n",
      "epoch:35 step:27790 [D loss: 0.135069, acc: 100.00%] [G loss: 3.770216]\n",
      "epoch:35 step:27791 [D loss: 0.755298, acc: 54.69%] [G loss: 3.504475]\n",
      "epoch:35 step:27792 [D loss: 0.464126, acc: 74.22%] [G loss: 2.782824]\n",
      "epoch:35 step:27793 [D loss: 0.086996, acc: 100.00%] [G loss: 3.651749]\n",
      "epoch:35 step:27794 [D loss: 0.510828, acc: 64.84%] [G loss: 4.577260]\n",
      "epoch:35 step:27795 [D loss: 0.504665, acc: 73.44%] [G loss: 3.120500]\n",
      "epoch:35 step:27796 [D loss: 0.220474, acc: 96.09%] [G loss: 6.043644]\n",
      "epoch:35 step:27797 [D loss: 0.249448, acc: 92.19%] [G loss: 3.541498]\n",
      "epoch:35 step:27798 [D loss: 0.154747, acc: 96.88%] [G loss: 7.708630]\n",
      "epoch:35 step:27799 [D loss: 0.329042, acc: 93.75%] [G loss: 4.701934]\n",
      "epoch:35 step:27800 [D loss: 0.587634, acc: 67.19%] [G loss: 5.073906]\n",
      "epoch:35 step:27801 [D loss: 0.079848, acc: 100.00%] [G loss: 4.335428]\n",
      "epoch:35 step:27802 [D loss: 0.363969, acc: 92.19%] [G loss: 3.681472]\n",
      "epoch:35 step:27803 [D loss: 0.761042, acc: 46.88%] [G loss: 6.670358]\n",
      "epoch:35 step:27804 [D loss: 0.091351, acc: 100.00%] [G loss: 4.888642]\n",
      "epoch:35 step:27805 [D loss: 0.243152, acc: 94.53%] [G loss: 7.615324]\n",
      "epoch:35 step:27806 [D loss: 0.387170, acc: 82.03%] [G loss: 3.356039]\n",
      "epoch:35 step:27807 [D loss: 0.447000, acc: 78.91%] [G loss: 4.717515]\n",
      "epoch:35 step:27808 [D loss: 0.773904, acc: 51.56%] [G loss: 5.264678]\n",
      "epoch:35 step:27809 [D loss: 0.670727, acc: 53.12%] [G loss: 4.876395]\n",
      "epoch:35 step:27810 [D loss: 0.400325, acc: 87.50%] [G loss: 4.077147]\n",
      "epoch:35 step:27811 [D loss: 0.256510, acc: 94.53%] [G loss: 5.597992]\n",
      "epoch:35 step:27812 [D loss: 0.615527, acc: 56.25%] [G loss: 6.214440]\n",
      "epoch:35 step:27813 [D loss: 0.955291, acc: 50.00%] [G loss: 8.678615]\n",
      "epoch:35 step:27814 [D loss: 0.307359, acc: 85.94%] [G loss: 5.460433]\n",
      "epoch:35 step:27815 [D loss: 1.047162, acc: 50.78%] [G loss: 5.039060]\n",
      "epoch:35 step:27816 [D loss: 0.209442, acc: 94.53%] [G loss: 3.491128]\n",
      "epoch:35 step:27817 [D loss: 1.397619, acc: 35.94%] [G loss: 6.415978]\n",
      "epoch:35 step:27818 [D loss: 0.312822, acc: 83.59%] [G loss: 5.616214]\n",
      "epoch:35 step:27819 [D loss: 0.509746, acc: 66.41%] [G loss: 6.864939]\n",
      "epoch:35 step:27820 [D loss: 0.912665, acc: 45.31%] [G loss: 4.650295]\n",
      "epoch:35 step:27821 [D loss: 0.307372, acc: 95.31%] [G loss: 1.980740]\n",
      "epoch:35 step:27822 [D loss: 0.154504, acc: 97.66%] [G loss: 6.001112]\n",
      "epoch:35 step:27823 [D loss: 0.037837, acc: 100.00%] [G loss: 6.533978]\n",
      "epoch:35 step:27824 [D loss: 1.454996, acc: 50.00%] [G loss: 2.622474]\n",
      "epoch:35 step:27825 [D loss: 0.039527, acc: 99.22%] [G loss: 7.781045]\n",
      "epoch:35 step:27826 [D loss: 0.393680, acc: 78.91%] [G loss: 5.248417]\n",
      "epoch:35 step:27827 [D loss: 0.575063, acc: 67.97%] [G loss: 4.765281]\n",
      "epoch:35 step:27828 [D loss: 0.309656, acc: 93.75%] [G loss: 4.295488]\n",
      "epoch:35 step:27829 [D loss: 0.124946, acc: 100.00%] [G loss: 3.679042]\n",
      "epoch:35 step:27830 [D loss: 0.088398, acc: 100.00%] [G loss: 3.269547]\n",
      "epoch:35 step:27831 [D loss: 0.137689, acc: 100.00%] [G loss: 3.893641]\n",
      "epoch:35 step:27832 [D loss: 0.196139, acc: 97.66%] [G loss: 5.208661]\n",
      "epoch:35 step:27833 [D loss: 0.307864, acc: 95.31%] [G loss: 5.442556]\n",
      "epoch:35 step:27834 [D loss: 0.071503, acc: 99.22%] [G loss: 4.817472]\n",
      "epoch:35 step:27835 [D loss: 0.724660, acc: 55.47%] [G loss: 4.181056]\n",
      "epoch:35 step:27836 [D loss: 0.317686, acc: 85.94%] [G loss: 3.900196]\n",
      "epoch:35 step:27837 [D loss: 0.356765, acc: 90.62%] [G loss: 4.345950]\n",
      "epoch:35 step:27838 [D loss: 0.098138, acc: 100.00%] [G loss: 5.307168]\n",
      "epoch:35 step:27839 [D loss: 0.337871, acc: 85.94%] [G loss: 4.491869]\n",
      "epoch:35 step:27840 [D loss: 0.240660, acc: 100.00%] [G loss: 3.961272]\n",
      "epoch:35 step:27841 [D loss: 0.775715, acc: 49.22%] [G loss: 3.553283]\n",
      "epoch:35 step:27842 [D loss: 0.745369, acc: 55.47%] [G loss: 2.994322]\n",
      "epoch:35 step:27843 [D loss: 0.228354, acc: 97.66%] [G loss: 3.736703]\n",
      "epoch:35 step:27844 [D loss: 0.149953, acc: 100.00%] [G loss: 4.151887]\n",
      "epoch:35 step:27845 [D loss: 0.128628, acc: 100.00%] [G loss: 4.644458]\n",
      "epoch:35 step:27846 [D loss: 0.035721, acc: 100.00%] [G loss: 8.557101]\n",
      "epoch:35 step:27847 [D loss: 0.096365, acc: 99.22%] [G loss: 5.944350]\n",
      "epoch:35 step:27848 [D loss: 0.672593, acc: 57.81%] [G loss: 4.510502]\n",
      "epoch:35 step:27849 [D loss: 0.192500, acc: 95.31%] [G loss: 4.566716]\n",
      "epoch:35 step:27850 [D loss: 0.596031, acc: 58.59%] [G loss: 3.687787]\n",
      "epoch:35 step:27851 [D loss: 0.472804, acc: 79.69%] [G loss: 4.057998]\n",
      "epoch:35 step:27852 [D loss: 0.273279, acc: 89.06%] [G loss: 6.534091]\n",
      "epoch:35 step:27853 [D loss: 0.788218, acc: 55.47%] [G loss: 4.060925]\n",
      "epoch:35 step:27854 [D loss: 0.943826, acc: 49.22%] [G loss: 5.801823]\n",
      "epoch:35 step:27855 [D loss: 0.322481, acc: 85.94%] [G loss: 5.495312]\n",
      "epoch:35 step:27856 [D loss: 0.994078, acc: 46.88%] [G loss: 4.260786]\n",
      "epoch:35 step:27857 [D loss: 0.646541, acc: 62.50%] [G loss: 3.960064]\n",
      "epoch:35 step:27858 [D loss: 0.144871, acc: 99.22%] [G loss: 7.814040]\n",
      "epoch:35 step:27859 [D loss: 0.349985, acc: 91.41%] [G loss: 3.041864]\n",
      "epoch:35 step:27860 [D loss: 0.361196, acc: 92.19%] [G loss: 2.512363]\n",
      "epoch:35 step:27861 [D loss: 0.940913, acc: 52.34%] [G loss: 2.890249]\n",
      "epoch:35 step:27862 [D loss: 0.435829, acc: 68.75%] [G loss: 5.714751]\n",
      "epoch:35 step:27863 [D loss: 0.489342, acc: 75.78%] [G loss: 3.487336]\n",
      "epoch:35 step:27864 [D loss: 0.160095, acc: 99.22%] [G loss: 4.277544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27865 [D loss: 0.225546, acc: 92.97%] [G loss: 5.345363]\n",
      "epoch:35 step:27866 [D loss: 0.438381, acc: 75.78%] [G loss: 4.983287]\n",
      "epoch:35 step:27867 [D loss: 1.553103, acc: 50.00%] [G loss: 3.749777]\n",
      "epoch:35 step:27868 [D loss: 0.402404, acc: 87.50%] [G loss: 3.958991]\n",
      "epoch:35 step:27869 [D loss: 0.501693, acc: 66.41%] [G loss: 4.664488]\n",
      "epoch:35 step:27870 [D loss: 0.106461, acc: 100.00%] [G loss: 2.375831]\n",
      "epoch:35 step:27871 [D loss: 0.170007, acc: 100.00%] [G loss: 3.893462]\n",
      "epoch:35 step:27872 [D loss: 0.519708, acc: 67.97%] [G loss: 4.178060]\n",
      "epoch:35 step:27873 [D loss: 0.938017, acc: 48.44%] [G loss: 5.914648]\n",
      "epoch:35 step:27874 [D loss: 0.635528, acc: 53.91%] [G loss: 4.212176]\n",
      "epoch:35 step:27875 [D loss: 0.773590, acc: 45.31%] [G loss: 4.287925]\n",
      "epoch:35 step:27876 [D loss: 0.558620, acc: 75.78%] [G loss: 4.889733]\n",
      "epoch:35 step:27877 [D loss: 0.385527, acc: 90.62%] [G loss: 3.899434]\n",
      "epoch:35 step:27878 [D loss: 0.329622, acc: 92.19%] [G loss: 4.528961]\n",
      "epoch:35 step:27879 [D loss: 0.323594, acc: 95.31%] [G loss: 4.426820]\n",
      "epoch:35 step:27880 [D loss: 0.253836, acc: 86.72%] [G loss: 4.572154]\n",
      "epoch:35 step:27881 [D loss: 0.253594, acc: 96.88%] [G loss: 4.662773]\n",
      "epoch:35 step:27882 [D loss: 0.216382, acc: 96.88%] [G loss: 5.472169]\n",
      "epoch:35 step:27883 [D loss: 0.800968, acc: 57.03%] [G loss: 3.834869]\n",
      "epoch:35 step:27884 [D loss: 0.724393, acc: 56.25%] [G loss: 5.502407]\n",
      "epoch:35 step:27885 [D loss: 0.060749, acc: 100.00%] [G loss: 4.518767]\n",
      "epoch:35 step:27886 [D loss: 0.205705, acc: 96.88%] [G loss: 7.631533]\n",
      "epoch:35 step:27887 [D loss: 0.702968, acc: 59.38%] [G loss: 6.619656]\n",
      "epoch:35 step:27888 [D loss: 0.278882, acc: 90.62%] [G loss: 3.467287]\n",
      "epoch:35 step:27889 [D loss: 0.379003, acc: 88.28%] [G loss: 4.129866]\n",
      "epoch:35 step:27890 [D loss: 0.007658, acc: 100.00%] [G loss: 5.746607]\n",
      "epoch:35 step:27891 [D loss: 0.639523, acc: 58.59%] [G loss: 6.426641]\n",
      "epoch:35 step:27892 [D loss: 0.364033, acc: 84.38%] [G loss: 4.976953]\n",
      "epoch:35 step:27893 [D loss: 1.616152, acc: 49.22%] [G loss: 4.007874]\n",
      "epoch:35 step:27894 [D loss: 0.197918, acc: 99.22%] [G loss: 5.006171]\n",
      "epoch:35 step:27895 [D loss: 0.235427, acc: 96.88%] [G loss: 5.524179]\n",
      "epoch:35 step:27896 [D loss: 0.878699, acc: 53.91%] [G loss: 5.059876]\n",
      "epoch:35 step:27897 [D loss: 0.225614, acc: 98.44%] [G loss: 5.732508]\n",
      "epoch:35 step:27898 [D loss: 0.226764, acc: 95.31%] [G loss: 6.314178]\n",
      "epoch:35 step:27899 [D loss: 0.073339, acc: 100.00%] [G loss: 4.561417]\n",
      "epoch:35 step:27900 [D loss: 0.268634, acc: 96.88%] [G loss: 4.094025]\n",
      "epoch:35 step:27901 [D loss: 0.320764, acc: 94.53%] [G loss: 4.160828]\n",
      "epoch:35 step:27902 [D loss: 0.403019, acc: 84.38%] [G loss: 6.020020]\n",
      "epoch:35 step:27903 [D loss: 0.836113, acc: 42.97%] [G loss: 6.244457]\n",
      "epoch:35 step:27904 [D loss: 0.045680, acc: 100.00%] [G loss: 8.170992]\n",
      "epoch:35 step:27905 [D loss: 0.785200, acc: 50.78%] [G loss: 2.317550]\n",
      "epoch:35 step:27906 [D loss: 0.348048, acc: 78.12%] [G loss: 6.823000]\n",
      "epoch:35 step:27907 [D loss: 0.554969, acc: 65.62%] [G loss: 4.687379]\n",
      "epoch:35 step:27908 [D loss: 0.113236, acc: 100.00%] [G loss: 5.680588]\n",
      "epoch:35 step:27909 [D loss: 0.602217, acc: 60.16%] [G loss: 4.860922]\n",
      "epoch:35 step:27910 [D loss: 0.614427, acc: 59.38%] [G loss: 3.715000]\n",
      "epoch:35 step:27911 [D loss: 0.187157, acc: 99.22%] [G loss: 4.316500]\n",
      "epoch:35 step:27912 [D loss: 0.413762, acc: 73.44%] [G loss: 7.449610]\n",
      "epoch:35 step:27913 [D loss: 0.653774, acc: 57.03%] [G loss: 4.581599]\n",
      "epoch:35 step:27914 [D loss: 0.087050, acc: 100.00%] [G loss: 6.289661]\n",
      "epoch:35 step:27915 [D loss: 0.169602, acc: 96.88%] [G loss: 5.480232]\n",
      "epoch:35 step:27916 [D loss: 0.389419, acc: 80.47%] [G loss: 8.439594]\n",
      "epoch:35 step:27917 [D loss: 0.215255, acc: 98.44%] [G loss: 6.451859]\n",
      "epoch:35 step:27918 [D loss: 0.855745, acc: 42.97%] [G loss: 3.815989]\n",
      "epoch:35 step:27919 [D loss: 0.299149, acc: 85.94%] [G loss: 3.971205]\n",
      "epoch:35 step:27920 [D loss: 0.450614, acc: 78.12%] [G loss: 4.892008]\n",
      "epoch:35 step:27921 [D loss: 0.072158, acc: 100.00%] [G loss: 5.552411]\n",
      "epoch:35 step:27922 [D loss: 0.499594, acc: 77.34%] [G loss: 4.429540]\n",
      "epoch:35 step:27923 [D loss: 1.778774, acc: 10.94%] [G loss: 4.924577]\n",
      "epoch:35 step:27924 [D loss: 0.210532, acc: 98.44%] [G loss: 6.776584]\n",
      "epoch:35 step:27925 [D loss: 0.566054, acc: 64.06%] [G loss: 6.925194]\n",
      "epoch:35 step:27926 [D loss: 1.036779, acc: 41.41%] [G loss: 4.909521]\n",
      "epoch:35 step:27927 [D loss: 0.232030, acc: 96.09%] [G loss: 4.679732]\n",
      "epoch:35 step:27928 [D loss: 0.553780, acc: 63.28%] [G loss: 6.154268]\n",
      "epoch:35 step:27929 [D loss: 0.308408, acc: 85.94%] [G loss: 5.160376]\n",
      "epoch:35 step:27930 [D loss: 0.111016, acc: 98.44%] [G loss: 5.524242]\n",
      "epoch:35 step:27931 [D loss: 0.078490, acc: 100.00%] [G loss: 3.730308]\n",
      "epoch:35 step:27932 [D loss: 1.067484, acc: 50.78%] [G loss: 4.040011]\n",
      "epoch:35 step:27933 [D loss: 0.265584, acc: 92.19%] [G loss: 7.193973]\n",
      "epoch:35 step:27934 [D loss: 1.408298, acc: 49.22%] [G loss: 2.591569]\n",
      "epoch:35 step:27935 [D loss: 0.778244, acc: 54.69%] [G loss: 5.753654]\n",
      "epoch:35 step:27936 [D loss: 0.589284, acc: 71.09%] [G loss: 2.513625]\n",
      "epoch:35 step:27937 [D loss: 0.398910, acc: 72.66%] [G loss: 5.714958]\n",
      "epoch:35 step:27938 [D loss: 0.419622, acc: 72.66%] [G loss: 3.631675]\n",
      "epoch:35 step:27939 [D loss: 0.389089, acc: 75.00%] [G loss: 4.168839]\n",
      "epoch:35 step:27940 [D loss: 0.119522, acc: 100.00%] [G loss: 5.827406]\n",
      "epoch:35 step:27941 [D loss: 0.671460, acc: 61.72%] [G loss: 5.587197]\n",
      "epoch:35 step:27942 [D loss: 0.765842, acc: 53.12%] [G loss: 5.600857]\n",
      "epoch:35 step:27943 [D loss: 0.935612, acc: 50.78%] [G loss: 2.804589]\n",
      "epoch:35 step:27944 [D loss: 0.625167, acc: 63.28%] [G loss: 7.159946]\n",
      "epoch:35 step:27945 [D loss: 1.142726, acc: 50.00%] [G loss: 5.501461]\n",
      "epoch:35 step:27946 [D loss: 0.151017, acc: 100.00%] [G loss: 2.787071]\n",
      "epoch:35 step:27947 [D loss: 0.152227, acc: 100.00%] [G loss: 6.720556]\n",
      "epoch:35 step:27948 [D loss: 0.468422, acc: 80.47%] [G loss: 2.549178]\n",
      "epoch:35 step:27949 [D loss: 0.127507, acc: 100.00%] [G loss: 6.855175]\n",
      "epoch:35 step:27950 [D loss: 0.367646, acc: 78.12%] [G loss: 4.298090]\n",
      "epoch:35 step:27951 [D loss: 0.206595, acc: 94.53%] [G loss: 4.760758]\n",
      "epoch:35 step:27952 [D loss: 0.638266, acc: 64.06%] [G loss: 4.605246]\n",
      "epoch:35 step:27953 [D loss: 0.381863, acc: 75.00%] [G loss: 4.537458]\n",
      "epoch:35 step:27954 [D loss: 0.924632, acc: 51.56%] [G loss: 4.553804]\n",
      "epoch:35 step:27955 [D loss: 0.486383, acc: 63.28%] [G loss: 5.611574]\n",
      "epoch:35 step:27956 [D loss: 0.320145, acc: 95.31%] [G loss: 3.103185]\n",
      "epoch:35 step:27957 [D loss: 0.103696, acc: 100.00%] [G loss: 3.607289]\n",
      "epoch:35 step:27958 [D loss: 0.235329, acc: 94.53%] [G loss: 4.936497]\n",
      "epoch:35 step:27959 [D loss: 0.147207, acc: 97.66%] [G loss: 5.670381]\n",
      "epoch:35 step:27960 [D loss: 0.330136, acc: 91.41%] [G loss: 3.435999]\n",
      "epoch:35 step:27961 [D loss: 0.148035, acc: 99.22%] [G loss: 2.686809]\n",
      "epoch:35 step:27962 [D loss: 1.033520, acc: 23.44%] [G loss: 3.615623]\n",
      "epoch:35 step:27963 [D loss: 0.493601, acc: 78.91%] [G loss: 3.486751]\n",
      "epoch:35 step:27964 [D loss: 0.106664, acc: 99.22%] [G loss: 5.452286]\n",
      "epoch:35 step:27965 [D loss: 0.040676, acc: 100.00%] [G loss: 6.053217]\n",
      "epoch:35 step:27966 [D loss: 0.702931, acc: 59.38%] [G loss: 4.371359]\n",
      "epoch:35 step:27967 [D loss: 0.260328, acc: 92.19%] [G loss: 5.023224]\n",
      "epoch:35 step:27968 [D loss: 0.210113, acc: 96.88%] [G loss: 4.366510]\n",
      "epoch:35 step:27969 [D loss: 0.660812, acc: 59.38%] [G loss: 3.091211]\n",
      "epoch:35 step:27970 [D loss: 0.371005, acc: 81.25%] [G loss: 3.225767]\n",
      "epoch:35 step:27971 [D loss: 0.244820, acc: 94.53%] [G loss: 3.460995]\n",
      "epoch:35 step:27972 [D loss: 0.524618, acc: 76.56%] [G loss: 1.826369]\n",
      "epoch:35 step:27973 [D loss: 0.689736, acc: 57.03%] [G loss: 5.489467]\n",
      "epoch:35 step:27974 [D loss: 0.327110, acc: 92.19%] [G loss: 4.062095]\n",
      "epoch:35 step:27975 [D loss: 0.110063, acc: 100.00%] [G loss: 4.930230]\n",
      "epoch:35 step:27976 [D loss: 0.508239, acc: 78.91%] [G loss: 4.701820]\n",
      "epoch:35 step:27977 [D loss: 0.203302, acc: 94.53%] [G loss: 7.612973]\n",
      "epoch:35 step:27978 [D loss: 0.670931, acc: 66.41%] [G loss: 4.968429]\n",
      "epoch:35 step:27979 [D loss: 0.373121, acc: 88.28%] [G loss: 3.853195]\n",
      "epoch:35 step:27980 [D loss: 0.224154, acc: 95.31%] [G loss: 3.213205]\n",
      "epoch:35 step:27981 [D loss: 0.540470, acc: 61.72%] [G loss: 4.513543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27982 [D loss: 0.231755, acc: 94.53%] [G loss: 4.652068]\n",
      "epoch:35 step:27983 [D loss: 0.342135, acc: 79.69%] [G loss: 5.339469]\n",
      "epoch:35 step:27984 [D loss: 0.168305, acc: 98.44%] [G loss: 6.056287]\n",
      "epoch:35 step:27985 [D loss: 0.909502, acc: 51.56%] [G loss: 4.674169]\n",
      "epoch:35 step:27986 [D loss: 0.158574, acc: 96.09%] [G loss: 4.915974]\n",
      "epoch:35 step:27987 [D loss: 0.163283, acc: 97.66%] [G loss: 4.928697]\n",
      "epoch:35 step:27988 [D loss: 0.019599, acc: 100.00%] [G loss: 7.225835]\n",
      "epoch:35 step:27989 [D loss: 0.342697, acc: 82.81%] [G loss: 4.779649]\n",
      "epoch:35 step:27990 [D loss: 0.089581, acc: 100.00%] [G loss: 5.382825]\n",
      "epoch:35 step:27991 [D loss: 0.405534, acc: 75.78%] [G loss: 3.951111]\n",
      "epoch:35 step:27992 [D loss: 1.055282, acc: 39.84%] [G loss: 5.559292]\n",
      "epoch:35 step:27993 [D loss: 1.312105, acc: 49.22%] [G loss: 2.839028]\n",
      "epoch:35 step:27994 [D loss: 0.181082, acc: 95.31%] [G loss: 4.938020]\n",
      "epoch:35 step:27995 [D loss: 1.057071, acc: 50.78%] [G loss: 4.769624]\n",
      "epoch:35 step:27996 [D loss: 0.950062, acc: 50.78%] [G loss: 6.650804]\n",
      "epoch:35 step:27997 [D loss: 0.475427, acc: 75.78%] [G loss: 3.921896]\n",
      "epoch:35 step:27998 [D loss: 0.061580, acc: 100.00%] [G loss: 4.634313]\n",
      "epoch:35 step:27999 [D loss: 0.380275, acc: 77.34%] [G loss: 3.334376]\n",
      "epoch:35 step:28000 [D loss: 0.709118, acc: 52.34%] [G loss: 3.518587]\n",
      "epoch:35 step:28001 [D loss: 0.051829, acc: 99.22%] [G loss: 3.623444]\n",
      "epoch:35 step:28002 [D loss: 0.106968, acc: 100.00%] [G loss: 4.560390]\n",
      "epoch:35 step:28003 [D loss: 0.093430, acc: 100.00%] [G loss: 5.019351]\n",
      "epoch:35 step:28004 [D loss: 1.205782, acc: 50.78%] [G loss: 4.910929]\n",
      "epoch:35 step:28005 [D loss: 0.918187, acc: 50.78%] [G loss: 0.956810]\n",
      "epoch:35 step:28006 [D loss: 0.605163, acc: 64.06%] [G loss: 5.028931]\n",
      "epoch:35 step:28007 [D loss: 0.260023, acc: 90.62%] [G loss: 4.797252]\n",
      "epoch:35 step:28008 [D loss: 0.770172, acc: 50.78%] [G loss: 3.225454]\n",
      "epoch:35 step:28009 [D loss: 0.393875, acc: 78.91%] [G loss: 5.788151]\n",
      "epoch:35 step:28010 [D loss: 0.272666, acc: 96.09%] [G loss: 4.202089]\n",
      "epoch:35 step:28011 [D loss: 0.210746, acc: 96.09%] [G loss: 5.402193]\n",
      "epoch:35 step:28012 [D loss: 1.793709, acc: 46.88%] [G loss: 4.451512]\n",
      "epoch:35 step:28013 [D loss: 0.204314, acc: 99.22%] [G loss: 5.313689]\n",
      "epoch:35 step:28014 [D loss: 0.233090, acc: 92.19%] [G loss: 5.536130]\n",
      "epoch:35 step:28015 [D loss: 0.279048, acc: 96.88%] [G loss: 3.791170]\n",
      "epoch:35 step:28016 [D loss: 0.168346, acc: 98.44%] [G loss: 4.686633]\n",
      "epoch:35 step:28017 [D loss: 0.465319, acc: 79.69%] [G loss: 2.477310]\n",
      "epoch:35 step:28018 [D loss: 0.508163, acc: 65.62%] [G loss: 5.187212]\n",
      "epoch:35 step:28019 [D loss: 0.384156, acc: 81.25%] [G loss: 4.306949]\n",
      "epoch:35 step:28020 [D loss: 0.311758, acc: 92.19%] [G loss: 3.192187]\n",
      "epoch:35 step:28021 [D loss: 1.171228, acc: 48.44%] [G loss: 5.823493]\n",
      "epoch:35 step:28022 [D loss: 0.932878, acc: 42.19%] [G loss: 2.874236]\n",
      "epoch:35 step:28023 [D loss: 0.529554, acc: 77.34%] [G loss: 2.995061]\n",
      "epoch:35 step:28024 [D loss: 1.357494, acc: 49.22%] [G loss: 4.372550]\n",
      "epoch:35 step:28025 [D loss: 0.061977, acc: 100.00%] [G loss: 8.030983]\n",
      "epoch:35 step:28026 [D loss: 0.136453, acc: 98.44%] [G loss: 6.106317]\n",
      "epoch:35 step:28027 [D loss: 0.441079, acc: 74.22%] [G loss: 4.758101]\n",
      "epoch:35 step:28028 [D loss: 0.186848, acc: 99.22%] [G loss: 4.928885]\n",
      "epoch:35 step:28029 [D loss: 0.210187, acc: 97.66%] [G loss: 4.397631]\n",
      "epoch:35 step:28030 [D loss: 0.456430, acc: 78.91%] [G loss: 6.241523]\n",
      "epoch:35 step:28031 [D loss: 1.137545, acc: 46.09%] [G loss: 5.316093]\n",
      "epoch:35 step:28032 [D loss: 0.505548, acc: 78.91%] [G loss: 4.342611]\n",
      "epoch:35 step:28033 [D loss: 0.473078, acc: 75.00%] [G loss: 2.245381]\n",
      "epoch:35 step:28034 [D loss: 0.464802, acc: 76.56%] [G loss: 6.264702]\n",
      "epoch:35 step:28035 [D loss: 0.258208, acc: 95.31%] [G loss: 3.375646]\n",
      "epoch:35 step:28036 [D loss: 0.273527, acc: 90.62%] [G loss: 4.978195]\n",
      "epoch:35 step:28037 [D loss: 0.361468, acc: 96.09%] [G loss: 4.402156]\n",
      "epoch:35 step:28038 [D loss: 0.198403, acc: 96.88%] [G loss: 3.694985]\n",
      "epoch:35 step:28039 [D loss: 0.600506, acc: 57.81%] [G loss: 3.533236]\n",
      "epoch:35 step:28040 [D loss: 0.090739, acc: 100.00%] [G loss: 6.938330]\n",
      "epoch:35 step:28041 [D loss: 0.081015, acc: 100.00%] [G loss: 4.104454]\n",
      "epoch:35 step:28042 [D loss: 1.008719, acc: 27.34%] [G loss: 6.749097]\n",
      "epoch:35 step:28043 [D loss: 0.104366, acc: 100.00%] [G loss: 5.416063]\n",
      "epoch:35 step:28044 [D loss: 0.770325, acc: 52.34%] [G loss: 4.414638]\n",
      "epoch:35 step:28045 [D loss: 1.105819, acc: 39.06%] [G loss: 4.485992]\n",
      "epoch:35 step:28046 [D loss: 0.146030, acc: 100.00%] [G loss: 6.139839]\n",
      "epoch:35 step:28047 [D loss: 0.091107, acc: 100.00%] [G loss: 4.151429]\n",
      "epoch:35 step:28048 [D loss: 0.059865, acc: 100.00%] [G loss: 5.920666]\n",
      "epoch:35 step:28049 [D loss: 0.132622, acc: 100.00%] [G loss: 4.330725]\n",
      "epoch:35 step:28050 [D loss: 0.934457, acc: 28.91%] [G loss: 5.557129]\n",
      "epoch:35 step:28051 [D loss: 0.079089, acc: 100.00%] [G loss: 6.597200]\n",
      "epoch:35 step:28052 [D loss: 0.205423, acc: 97.66%] [G loss: 4.586078]\n",
      "epoch:35 step:28053 [D loss: 0.155369, acc: 99.22%] [G loss: 5.715649]\n",
      "epoch:35 step:28054 [D loss: 0.156483, acc: 99.22%] [G loss: 4.807813]\n",
      "epoch:35 step:28055 [D loss: 0.162618, acc: 96.88%] [G loss: 5.094636]\n",
      "epoch:35 step:28056 [D loss: 0.184018, acc: 100.00%] [G loss: 3.592216]\n",
      "epoch:35 step:28057 [D loss: 0.356663, acc: 88.28%] [G loss: 3.731714]\n",
      "epoch:35 step:28058 [D loss: 0.237832, acc: 97.66%] [G loss: 7.325977]\n",
      "epoch:35 step:28059 [D loss: 0.097281, acc: 99.22%] [G loss: 3.659439]\n",
      "epoch:35 step:28060 [D loss: 0.274516, acc: 90.62%] [G loss: 5.641972]\n",
      "epoch:35 step:28061 [D loss: 0.192683, acc: 95.31%] [G loss: 3.448343]\n",
      "epoch:35 step:28062 [D loss: 0.229177, acc: 96.09%] [G loss: 2.971888]\n",
      "epoch:35 step:28063 [D loss: 0.071241, acc: 100.00%] [G loss: 5.199406]\n",
      "epoch:35 step:28064 [D loss: 1.129138, acc: 25.78%] [G loss: 4.127269]\n",
      "epoch:35 step:28065 [D loss: 0.104414, acc: 100.00%] [G loss: 3.283521]\n",
      "epoch:35 step:28066 [D loss: 0.270158, acc: 92.19%] [G loss: 2.268415]\n",
      "epoch:35 step:28067 [D loss: 0.224756, acc: 93.75%] [G loss: 5.073632]\n",
      "epoch:35 step:28068 [D loss: 0.623559, acc: 64.06%] [G loss: 4.316929]\n",
      "epoch:35 step:28069 [D loss: 0.451464, acc: 80.47%] [G loss: 3.071774]\n",
      "epoch:35 step:28070 [D loss: 0.444889, acc: 73.44%] [G loss: 6.209684]\n",
      "epoch:35 step:28071 [D loss: 0.485892, acc: 72.66%] [G loss: 4.280748]\n",
      "epoch:35 step:28072 [D loss: 0.618291, acc: 58.59%] [G loss: 4.958423]\n",
      "epoch:35 step:28073 [D loss: 0.626186, acc: 66.41%] [G loss: 4.677674]\n",
      "epoch:35 step:28074 [D loss: 0.558842, acc: 67.97%] [G loss: 6.702663]\n",
      "epoch:35 step:28075 [D loss: 0.667064, acc: 56.25%] [G loss: 3.086495]\n",
      "epoch:35 step:28076 [D loss: 0.239185, acc: 92.97%] [G loss: 3.378639]\n",
      "epoch:35 step:28077 [D loss: 0.446099, acc: 85.94%] [G loss: 4.313415]\n",
      "epoch:35 step:28078 [D loss: 0.162419, acc: 99.22%] [G loss: 4.570281]\n",
      "epoch:35 step:28079 [D loss: 0.614203, acc: 64.06%] [G loss: 3.097867]\n",
      "epoch:35 step:28080 [D loss: 0.410947, acc: 71.09%] [G loss: 3.110040]\n",
      "epoch:35 step:28081 [D loss: 0.555075, acc: 76.56%] [G loss: 2.712423]\n",
      "epoch:35 step:28082 [D loss: 0.299945, acc: 81.25%] [G loss: 3.900088]\n",
      "epoch:35 step:28083 [D loss: 0.223245, acc: 94.53%] [G loss: 4.170970]\n",
      "epoch:35 step:28084 [D loss: 0.025276, acc: 100.00%] [G loss: 7.365534]\n",
      "epoch:35 step:28085 [D loss: 0.143590, acc: 100.00%] [G loss: 2.746271]\n",
      "epoch:35 step:28086 [D loss: 0.119986, acc: 100.00%] [G loss: 4.929353]\n",
      "epoch:35 step:28087 [D loss: 0.480411, acc: 64.84%] [G loss: 3.450514]\n",
      "epoch:35 step:28088 [D loss: 0.176604, acc: 99.22%] [G loss: 4.047871]\n",
      "epoch:35 step:28089 [D loss: 0.893385, acc: 50.78%] [G loss: 4.819131]\n",
      "epoch:35 step:28090 [D loss: 0.496186, acc: 67.19%] [G loss: 2.918880]\n",
      "epoch:35 step:28091 [D loss: 0.393533, acc: 74.22%] [G loss: 3.678576]\n",
      "epoch:35 step:28092 [D loss: 0.325541, acc: 93.75%] [G loss: 4.195560]\n",
      "epoch:35 step:28093 [D loss: 0.152291, acc: 99.22%] [G loss: 6.353737]\n",
      "epoch:35 step:28094 [D loss: 0.232185, acc: 95.31%] [G loss: 4.945529]\n",
      "epoch:35 step:28095 [D loss: 0.545993, acc: 57.81%] [G loss: 8.117769]\n",
      "epoch:35 step:28096 [D loss: 0.229863, acc: 92.97%] [G loss: 4.737422]\n",
      "epoch:35 step:28097 [D loss: 0.133637, acc: 100.00%] [G loss: 7.730983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:28098 [D loss: 0.539024, acc: 67.97%] [G loss: 6.452246]\n",
      "epoch:35 step:28099 [D loss: 0.278093, acc: 97.66%] [G loss: 5.995951]\n",
      "epoch:35 step:28100 [D loss: 0.339438, acc: 92.19%] [G loss: 4.195095]\n",
      "epoch:35 step:28101 [D loss: 0.437567, acc: 75.00%] [G loss: 3.882705]\n",
      "epoch:35 step:28102 [D loss: 0.191819, acc: 96.88%] [G loss: 6.570843]\n",
      "epoch:35 step:28103 [D loss: 0.217187, acc: 100.00%] [G loss: 3.674277]\n",
      "epoch:35 step:28104 [D loss: 0.350988, acc: 92.97%] [G loss: 4.704876]\n",
      "epoch:35 step:28105 [D loss: 0.076571, acc: 100.00%] [G loss: 4.489697]\n",
      "epoch:35 step:28106 [D loss: 0.533517, acc: 75.00%] [G loss: 3.506664]\n",
      "epoch:35 step:28107 [D loss: 0.208408, acc: 97.66%] [G loss: 4.079353]\n",
      "epoch:35 step:28108 [D loss: 0.052138, acc: 100.00%] [G loss: 6.038767]\n",
      "epoch:35 step:28109 [D loss: 0.485399, acc: 65.62%] [G loss: 4.954714]\n",
      "epoch:35 step:28110 [D loss: 1.442043, acc: 49.22%] [G loss: 3.631875]\n",
      "epoch:35 step:28111 [D loss: 0.715230, acc: 58.59%] [G loss: 4.127704]\n",
      "epoch:35 step:28112 [D loss: 0.508442, acc: 75.78%] [G loss: 4.772167]\n",
      "epoch:35 step:28113 [D loss: 0.522464, acc: 77.34%] [G loss: 4.442381]\n",
      "epoch:35 step:28114 [D loss: 0.243350, acc: 92.19%] [G loss: 1.908534]\n",
      "epoch:35 step:28115 [D loss: 0.554297, acc: 58.59%] [G loss: 3.563491]\n",
      "epoch:35 step:28116 [D loss: 0.850405, acc: 39.84%] [G loss: 3.919755]\n",
      "epoch:36 step:28117 [D loss: 0.650072, acc: 56.25%] [G loss: 3.198285]\n",
      "epoch:36 step:28118 [D loss: 0.086384, acc: 100.00%] [G loss: 5.101723]\n",
      "epoch:36 step:28119 [D loss: 1.184721, acc: 20.31%] [G loss: 2.538356]\n",
      "epoch:36 step:28120 [D loss: 0.443291, acc: 78.12%] [G loss: 5.410772]\n",
      "epoch:36 step:28121 [D loss: 0.433529, acc: 74.22%] [G loss: 5.409045]\n",
      "epoch:36 step:28122 [D loss: 0.237525, acc: 97.66%] [G loss: 3.635336]\n",
      "epoch:36 step:28123 [D loss: 0.131405, acc: 98.44%] [G loss: 3.476922]\n",
      "epoch:36 step:28124 [D loss: 0.084481, acc: 99.22%] [G loss: 3.619900]\n",
      "epoch:36 step:28125 [D loss: 0.903181, acc: 48.44%] [G loss: 5.243314]\n",
      "epoch:36 step:28126 [D loss: 0.207734, acc: 97.66%] [G loss: 5.731956]\n",
      "epoch:36 step:28127 [D loss: 0.349945, acc: 92.97%] [G loss: 4.933955]\n",
      "epoch:36 step:28128 [D loss: 0.171829, acc: 99.22%] [G loss: 3.515579]\n",
      "epoch:36 step:28129 [D loss: 0.236559, acc: 96.88%] [G loss: 4.216163]\n",
      "epoch:36 step:28130 [D loss: 0.177092, acc: 98.44%] [G loss: 4.963393]\n",
      "epoch:36 step:28131 [D loss: 1.244507, acc: 25.00%] [G loss: 4.208171]\n",
      "epoch:36 step:28132 [D loss: 0.149414, acc: 98.44%] [G loss: 3.276806]\n",
      "epoch:36 step:28133 [D loss: 0.047574, acc: 100.00%] [G loss: 5.059181]\n",
      "epoch:36 step:28134 [D loss: 1.788044, acc: 6.25%] [G loss: 4.435111]\n",
      "epoch:36 step:28135 [D loss: 0.690635, acc: 55.47%] [G loss: 4.038088]\n",
      "epoch:36 step:28136 [D loss: 0.358682, acc: 84.38%] [G loss: 4.575515]\n",
      "epoch:36 step:28137 [D loss: 0.851961, acc: 39.84%] [G loss: 6.431112]\n",
      "epoch:36 step:28138 [D loss: 0.190841, acc: 96.09%] [G loss: 3.670663]\n",
      "epoch:36 step:28139 [D loss: 0.709184, acc: 57.03%] [G loss: 4.240069]\n",
      "epoch:36 step:28140 [D loss: 0.136885, acc: 99.22%] [G loss: 3.095889]\n",
      "epoch:36 step:28141 [D loss: 0.151234, acc: 100.00%] [G loss: 4.035155]\n",
      "epoch:36 step:28142 [D loss: 0.923772, acc: 50.78%] [G loss: 5.318021]\n",
      "epoch:36 step:28143 [D loss: 0.340227, acc: 93.75%] [G loss: 4.092218]\n",
      "epoch:36 step:28144 [D loss: 0.205440, acc: 96.09%] [G loss: 7.190167]\n",
      "epoch:36 step:28145 [D loss: 0.237145, acc: 90.62%] [G loss: 4.963777]\n",
      "epoch:36 step:28146 [D loss: 0.077955, acc: 100.00%] [G loss: 6.870705]\n",
      "epoch:36 step:28147 [D loss: 0.647993, acc: 57.81%] [G loss: 4.587823]\n",
      "epoch:36 step:28148 [D loss: 0.257628, acc: 94.53%] [G loss: 5.616758]\n",
      "epoch:36 step:28149 [D loss: 0.400455, acc: 72.66%] [G loss: 7.693567]\n",
      "epoch:36 step:28150 [D loss: 0.080194, acc: 100.00%] [G loss: 5.002454]\n",
      "epoch:36 step:28151 [D loss: 0.374978, acc: 86.72%] [G loss: 3.184535]\n",
      "epoch:36 step:28152 [D loss: 0.863431, acc: 51.56%] [G loss: 3.142945]\n",
      "epoch:36 step:28153 [D loss: 0.061157, acc: 100.00%] [G loss: 3.406928]\n",
      "epoch:36 step:28154 [D loss: 0.252784, acc: 90.62%] [G loss: 4.395650]\n",
      "epoch:36 step:28155 [D loss: 0.260333, acc: 90.62%] [G loss: 7.117214]\n",
      "epoch:36 step:28156 [D loss: 0.145719, acc: 99.22%] [G loss: 3.369468]\n",
      "epoch:36 step:28157 [D loss: 0.169625, acc: 99.22%] [G loss: 6.483152]\n",
      "epoch:36 step:28158 [D loss: 0.514837, acc: 78.12%] [G loss: 4.430065]\n",
      "epoch:36 step:28159 [D loss: 0.210566, acc: 96.88%] [G loss: 7.313279]\n",
      "epoch:36 step:28160 [D loss: 0.285817, acc: 90.62%] [G loss: 6.334629]\n",
      "epoch:36 step:28161 [D loss: 0.760088, acc: 53.12%] [G loss: 6.498435]\n",
      "epoch:36 step:28162 [D loss: 0.109626, acc: 100.00%] [G loss: 5.985774]\n",
      "epoch:36 step:28163 [D loss: 0.067413, acc: 100.00%] [G loss: 5.732104]\n",
      "epoch:36 step:28164 [D loss: 0.451836, acc: 72.66%] [G loss: 4.713355]\n",
      "epoch:36 step:28165 [D loss: 0.501166, acc: 78.91%] [G loss: 4.101766]\n",
      "epoch:36 step:28166 [D loss: 0.701688, acc: 57.03%] [G loss: 3.963958]\n",
      "epoch:36 step:28167 [D loss: 0.652295, acc: 60.16%] [G loss: 3.499468]\n",
      "epoch:36 step:28168 [D loss: 0.304161, acc: 92.97%] [G loss: 2.937686]\n",
      "epoch:36 step:28169 [D loss: 0.576676, acc: 62.50%] [G loss: 5.202365]\n",
      "epoch:36 step:28170 [D loss: 0.574615, acc: 64.06%] [G loss: 6.950434]\n",
      "epoch:36 step:28171 [D loss: 0.402964, acc: 82.03%] [G loss: 5.780354]\n",
      "epoch:36 step:28172 [D loss: 0.801324, acc: 52.34%] [G loss: 4.683927]\n",
      "epoch:36 step:28173 [D loss: 0.191066, acc: 96.09%] [G loss: 5.561356]\n",
      "epoch:36 step:28174 [D loss: 0.396647, acc: 89.06%] [G loss: 4.135328]\n",
      "epoch:36 step:28175 [D loss: 1.013402, acc: 46.88%] [G loss: 6.066686]\n",
      "epoch:36 step:28176 [D loss: 0.345943, acc: 87.50%] [G loss: 6.069151]\n",
      "epoch:36 step:28177 [D loss: 0.220386, acc: 96.09%] [G loss: 3.691834]\n",
      "epoch:36 step:28178 [D loss: 0.570118, acc: 73.44%] [G loss: 4.773845]\n",
      "epoch:36 step:28179 [D loss: 0.249440, acc: 92.19%] [G loss: 5.339156]\n",
      "epoch:36 step:28180 [D loss: 0.166816, acc: 100.00%] [G loss: 5.518716]\n",
      "epoch:36 step:28181 [D loss: 0.773521, acc: 52.34%] [G loss: 3.895602]\n",
      "epoch:36 step:28182 [D loss: 0.232915, acc: 98.44%] [G loss: 2.215305]\n",
      "epoch:36 step:28183 [D loss: 0.452667, acc: 83.59%] [G loss: 2.570385]\n",
      "epoch:36 step:28184 [D loss: 0.372742, acc: 89.84%] [G loss: 2.772431]\n",
      "epoch:36 step:28185 [D loss: 0.198898, acc: 97.66%] [G loss: 5.809590]\n",
      "epoch:36 step:28186 [D loss: 0.023455, acc: 100.00%] [G loss: 5.485073]\n",
      "epoch:36 step:28187 [D loss: 1.103970, acc: 25.78%] [G loss: 3.294386]\n",
      "epoch:36 step:28188 [D loss: 0.643056, acc: 55.47%] [G loss: 4.253807]\n",
      "epoch:36 step:28189 [D loss: 0.416393, acc: 86.72%] [G loss: 4.892838]\n",
      "epoch:36 step:28190 [D loss: 0.207943, acc: 93.75%] [G loss: 5.859875]\n",
      "epoch:36 step:28191 [D loss: 0.091617, acc: 100.00%] [G loss: 5.814457]\n",
      "epoch:36 step:28192 [D loss: 0.142230, acc: 99.22%] [G loss: 8.187399]\n",
      "epoch:36 step:28193 [D loss: 0.176396, acc: 100.00%] [G loss: 6.162325]\n",
      "epoch:36 step:28194 [D loss: 0.141022, acc: 99.22%] [G loss: 2.577569]\n",
      "epoch:36 step:28195 [D loss: 0.468858, acc: 74.22%] [G loss: 6.034807]\n",
      "epoch:36 step:28196 [D loss: 0.369983, acc: 82.81%] [G loss: 3.455351]\n",
      "epoch:36 step:28197 [D loss: 0.720689, acc: 58.59%] [G loss: 4.307766]\n",
      "epoch:36 step:28198 [D loss: 0.067661, acc: 100.00%] [G loss: 3.911011]\n",
      "epoch:36 step:28199 [D loss: 0.092008, acc: 100.00%] [G loss: 6.571160]\n",
      "epoch:36 step:28200 [D loss: 0.253231, acc: 92.19%] [G loss: 6.040371]\n",
      "epoch:36 step:28201 [D loss: 0.110972, acc: 100.00%] [G loss: 5.730763]\n",
      "epoch:36 step:28202 [D loss: 0.190874, acc: 96.09%] [G loss: 4.315105]\n",
      "epoch:36 step:28203 [D loss: 0.525372, acc: 71.09%] [G loss: 6.580708]\n",
      "epoch:36 step:28204 [D loss: 0.980455, acc: 43.75%] [G loss: 4.962178]\n",
      "epoch:36 step:28205 [D loss: 0.497353, acc: 65.62%] [G loss: 3.497578]\n",
      "epoch:36 step:28206 [D loss: 0.503253, acc: 67.19%] [G loss: 6.808371]\n",
      "epoch:36 step:28207 [D loss: 0.111288, acc: 100.00%] [G loss: 4.243506]\n",
      "epoch:36 step:28208 [D loss: 0.367397, acc: 86.72%] [G loss: 5.939197]\n",
      "epoch:36 step:28209 [D loss: 1.122268, acc: 24.22%] [G loss: 6.820448]\n",
      "epoch:36 step:28210 [D loss: 0.237670, acc: 95.31%] [G loss: 2.618460]\n",
      "epoch:36 step:28211 [D loss: 0.519204, acc: 79.69%] [G loss: 4.432069]\n",
      "epoch:36 step:28212 [D loss: 0.575074, acc: 57.81%] [G loss: 5.205764]\n",
      "epoch:36 step:28213 [D loss: 0.399134, acc: 85.94%] [G loss: 2.875715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28214 [D loss: 0.753485, acc: 50.78%] [G loss: 4.309627]\n",
      "epoch:36 step:28215 [D loss: 0.093813, acc: 100.00%] [G loss: 4.312896]\n",
      "epoch:36 step:28216 [D loss: 0.373625, acc: 83.59%] [G loss: 5.368873]\n",
      "epoch:36 step:28217 [D loss: 0.271831, acc: 90.62%] [G loss: 6.772972]\n",
      "epoch:36 step:28218 [D loss: 1.230797, acc: 50.00%] [G loss: 2.996613]\n",
      "epoch:36 step:28219 [D loss: 0.567002, acc: 63.28%] [G loss: 5.611277]\n",
      "epoch:36 step:28220 [D loss: 0.480386, acc: 80.47%] [G loss: 6.308867]\n",
      "epoch:36 step:28221 [D loss: 0.546032, acc: 76.56%] [G loss: 6.508151]\n",
      "epoch:36 step:28222 [D loss: 0.091409, acc: 100.00%] [G loss: 5.013047]\n",
      "epoch:36 step:28223 [D loss: 0.350202, acc: 88.28%] [G loss: 4.483754]\n",
      "epoch:36 step:28224 [D loss: 0.226230, acc: 96.09%] [G loss: 3.830092]\n",
      "epoch:36 step:28225 [D loss: 0.183922, acc: 99.22%] [G loss: 4.121870]\n",
      "epoch:36 step:28226 [D loss: 0.479185, acc: 77.34%] [G loss: 3.019762]\n",
      "epoch:36 step:28227 [D loss: 0.470074, acc: 80.47%] [G loss: 3.870303]\n",
      "epoch:36 step:28228 [D loss: 0.347459, acc: 93.75%] [G loss: 4.334739]\n",
      "epoch:36 step:28229 [D loss: 0.427027, acc: 71.09%] [G loss: 4.810909]\n",
      "epoch:36 step:28230 [D loss: 0.411808, acc: 78.91%] [G loss: 5.316463]\n",
      "epoch:36 step:28231 [D loss: 0.482697, acc: 65.62%] [G loss: 4.140284]\n",
      "epoch:36 step:28232 [D loss: 0.264766, acc: 92.97%] [G loss: 4.385756]\n",
      "epoch:36 step:28233 [D loss: 0.501082, acc: 81.25%] [G loss: 3.740096]\n",
      "epoch:36 step:28234 [D loss: 0.158223, acc: 100.00%] [G loss: 5.148426]\n",
      "epoch:36 step:28235 [D loss: 0.330141, acc: 84.38%] [G loss: 5.620169]\n",
      "epoch:36 step:28236 [D loss: 0.131950, acc: 100.00%] [G loss: 3.782927]\n",
      "epoch:36 step:28237 [D loss: 0.532523, acc: 72.66%] [G loss: 4.696895]\n",
      "epoch:36 step:28238 [D loss: 0.270878, acc: 92.19%] [G loss: 4.293997]\n",
      "epoch:36 step:28239 [D loss: 0.553472, acc: 72.66%] [G loss: 5.884780]\n",
      "epoch:36 step:28240 [D loss: 0.324741, acc: 86.72%] [G loss: 5.156863]\n",
      "epoch:36 step:28241 [D loss: 0.069950, acc: 100.00%] [G loss: 4.993345]\n",
      "epoch:36 step:28242 [D loss: 0.472667, acc: 78.12%] [G loss: 3.263312]\n",
      "epoch:36 step:28243 [D loss: 0.128213, acc: 98.44%] [G loss: 4.324346]\n",
      "epoch:36 step:28244 [D loss: 0.204055, acc: 96.09%] [G loss: 3.577933]\n",
      "epoch:36 step:28245 [D loss: 0.719990, acc: 54.69%] [G loss: 5.378932]\n",
      "epoch:36 step:28246 [D loss: 0.288290, acc: 92.97%] [G loss: 6.819838]\n",
      "epoch:36 step:28247 [D loss: 0.607374, acc: 57.03%] [G loss: 2.232036]\n",
      "epoch:36 step:28248 [D loss: 0.064650, acc: 100.00%] [G loss: 5.295387]\n",
      "epoch:36 step:28249 [D loss: 0.394529, acc: 85.94%] [G loss: 3.291405]\n",
      "epoch:36 step:28250 [D loss: 0.160570, acc: 99.22%] [G loss: 3.184038]\n",
      "epoch:36 step:28251 [D loss: 0.097440, acc: 99.22%] [G loss: 4.470475]\n",
      "epoch:36 step:28252 [D loss: 1.293630, acc: 12.50%] [G loss: 2.804184]\n",
      "epoch:36 step:28253 [D loss: 0.167878, acc: 100.00%] [G loss: 5.071634]\n",
      "epoch:36 step:28254 [D loss: 0.552696, acc: 72.66%] [G loss: 4.961311]\n",
      "epoch:36 step:28255 [D loss: 0.100197, acc: 100.00%] [G loss: 6.388876]\n",
      "epoch:36 step:28256 [D loss: 0.241584, acc: 95.31%] [G loss: 4.543920]\n",
      "epoch:36 step:28257 [D loss: 0.458039, acc: 71.09%] [G loss: 4.840926]\n",
      "epoch:36 step:28258 [D loss: 0.457697, acc: 75.00%] [G loss: 3.790094]\n",
      "epoch:36 step:28259 [D loss: 0.540639, acc: 71.88%] [G loss: 5.535801]\n",
      "epoch:36 step:28260 [D loss: 0.131019, acc: 98.44%] [G loss: 3.781226]\n",
      "epoch:36 step:28261 [D loss: 0.521812, acc: 66.41%] [G loss: 6.082204]\n",
      "epoch:36 step:28262 [D loss: 0.034691, acc: 100.00%] [G loss: 3.655734]\n",
      "epoch:36 step:28263 [D loss: 0.682030, acc: 56.25%] [G loss: 5.816768]\n",
      "epoch:36 step:28264 [D loss: 0.249929, acc: 94.53%] [G loss: 5.335912]\n",
      "epoch:36 step:28265 [D loss: 0.419367, acc: 73.44%] [G loss: 4.493869]\n",
      "epoch:36 step:28266 [D loss: 0.388526, acc: 75.00%] [G loss: 5.528569]\n",
      "epoch:36 step:28267 [D loss: 0.369740, acc: 86.72%] [G loss: 3.909257]\n",
      "epoch:36 step:28268 [D loss: 0.366580, acc: 90.62%] [G loss: 3.825251]\n",
      "epoch:36 step:28269 [D loss: 0.111799, acc: 99.22%] [G loss: 4.519325]\n",
      "epoch:36 step:28270 [D loss: 0.312537, acc: 95.31%] [G loss: 4.186220]\n",
      "epoch:36 step:28271 [D loss: 0.381363, acc: 89.06%] [G loss: 2.558053]\n",
      "epoch:36 step:28272 [D loss: 0.111412, acc: 100.00%] [G loss: 4.488629]\n",
      "epoch:36 step:28273 [D loss: 0.185376, acc: 98.44%] [G loss: 4.220012]\n",
      "epoch:36 step:28274 [D loss: 0.324225, acc: 89.06%] [G loss: 4.794621]\n",
      "epoch:36 step:28275 [D loss: 0.241678, acc: 90.62%] [G loss: 7.592875]\n",
      "epoch:36 step:28276 [D loss: 0.611216, acc: 60.16%] [G loss: 5.973097]\n",
      "epoch:36 step:28277 [D loss: 0.661593, acc: 56.25%] [G loss: 6.446619]\n",
      "epoch:36 step:28278 [D loss: 0.056349, acc: 100.00%] [G loss: 6.172836]\n",
      "epoch:36 step:28279 [D loss: 0.218583, acc: 96.09%] [G loss: 4.288578]\n",
      "epoch:36 step:28280 [D loss: 0.416389, acc: 79.69%] [G loss: 4.676319]\n",
      "epoch:36 step:28281 [D loss: 0.620868, acc: 64.06%] [G loss: 4.688139]\n",
      "epoch:36 step:28282 [D loss: 0.459562, acc: 80.47%] [G loss: 8.323642]\n",
      "epoch:36 step:28283 [D loss: 0.230747, acc: 92.19%] [G loss: 5.365557]\n",
      "epoch:36 step:28284 [D loss: 0.275730, acc: 96.88%] [G loss: 5.651340]\n",
      "epoch:36 step:28285 [D loss: 0.697199, acc: 61.72%] [G loss: 3.441857]\n",
      "epoch:36 step:28286 [D loss: 0.302609, acc: 90.62%] [G loss: 4.007768]\n",
      "epoch:36 step:28287 [D loss: 0.505390, acc: 76.56%] [G loss: 3.185385]\n",
      "epoch:36 step:28288 [D loss: 0.594713, acc: 57.81%] [G loss: 5.899687]\n",
      "epoch:36 step:28289 [D loss: 1.034834, acc: 22.66%] [G loss: 5.848575]\n",
      "epoch:36 step:28290 [D loss: 0.183915, acc: 95.31%] [G loss: 4.376627]\n",
      "epoch:36 step:28291 [D loss: 0.045175, acc: 100.00%] [G loss: 3.261728]\n",
      "epoch:36 step:28292 [D loss: 0.281433, acc: 86.72%] [G loss: 5.399946]\n",
      "epoch:36 step:28293 [D loss: 0.286804, acc: 93.75%] [G loss: 3.558475]\n",
      "epoch:36 step:28294 [D loss: 0.446158, acc: 85.16%] [G loss: 3.376491]\n",
      "epoch:36 step:28295 [D loss: 0.240173, acc: 99.22%] [G loss: 3.143645]\n",
      "epoch:36 step:28296 [D loss: 0.563192, acc: 71.88%] [G loss: 4.076789]\n",
      "epoch:36 step:28297 [D loss: 0.033399, acc: 100.00%] [G loss: 6.645252]\n",
      "epoch:36 step:28298 [D loss: 0.352192, acc: 84.38%] [G loss: 4.032763]\n",
      "epoch:36 step:28299 [D loss: 0.185359, acc: 98.44%] [G loss: 3.993867]\n",
      "epoch:36 step:28300 [D loss: 0.176676, acc: 99.22%] [G loss: 3.136082]\n",
      "epoch:36 step:28301 [D loss: 0.804921, acc: 52.34%] [G loss: 2.664674]\n",
      "epoch:36 step:28302 [D loss: 0.349423, acc: 84.38%] [G loss: 3.354896]\n",
      "epoch:36 step:28303 [D loss: 0.470424, acc: 67.97%] [G loss: 2.762769]\n",
      "epoch:36 step:28304 [D loss: 0.721422, acc: 57.03%] [G loss: 6.161418]\n",
      "epoch:36 step:28305 [D loss: 0.305839, acc: 82.81%] [G loss: 6.384804]\n",
      "epoch:36 step:28306 [D loss: 0.078043, acc: 100.00%] [G loss: 2.747625]\n",
      "epoch:36 step:28307 [D loss: 0.329812, acc: 85.16%] [G loss: 3.353796]\n",
      "epoch:36 step:28308 [D loss: 0.257660, acc: 92.19%] [G loss: 4.608795]\n",
      "epoch:36 step:28309 [D loss: 0.220959, acc: 96.88%] [G loss: 2.593208]\n",
      "epoch:36 step:28310 [D loss: 0.663283, acc: 61.72%] [G loss: 4.351075]\n",
      "epoch:36 step:28311 [D loss: 0.831609, acc: 52.34%] [G loss: 6.657652]\n",
      "epoch:36 step:28312 [D loss: 0.606604, acc: 62.50%] [G loss: 4.943657]\n",
      "epoch:36 step:28313 [D loss: 0.415757, acc: 82.81%] [G loss: 4.651923]\n",
      "epoch:36 step:28314 [D loss: 0.045688, acc: 100.00%] [G loss: 4.299091]\n",
      "epoch:36 step:28315 [D loss: 0.063980, acc: 100.00%] [G loss: 3.796519]\n",
      "epoch:36 step:28316 [D loss: 0.119961, acc: 96.88%] [G loss: 3.520391]\n",
      "epoch:36 step:28317 [D loss: 0.295997, acc: 87.50%] [G loss: 3.189316]\n",
      "epoch:36 step:28318 [D loss: 0.637348, acc: 60.16%] [G loss: 7.329836]\n",
      "epoch:36 step:28319 [D loss: 0.655223, acc: 58.59%] [G loss: 5.594982]\n",
      "epoch:36 step:28320 [D loss: 0.896076, acc: 51.56%] [G loss: 3.151599]\n",
      "epoch:36 step:28321 [D loss: 0.358796, acc: 89.84%] [G loss: 2.735584]\n",
      "epoch:36 step:28322 [D loss: 0.562647, acc: 61.72%] [G loss: 3.982095]\n",
      "epoch:36 step:28323 [D loss: 0.104971, acc: 100.00%] [G loss: 3.620836]\n",
      "epoch:36 step:28324 [D loss: 0.264015, acc: 95.31%] [G loss: 3.866236]\n",
      "epoch:36 step:28325 [D loss: 0.051216, acc: 100.00%] [G loss: 3.068779]\n",
      "epoch:36 step:28326 [D loss: 0.816796, acc: 53.12%] [G loss: 5.999159]\n",
      "epoch:36 step:28327 [D loss: 0.621561, acc: 62.50%] [G loss: 6.014206]\n",
      "epoch:36 step:28328 [D loss: 0.186448, acc: 97.66%] [G loss: 4.756160]\n",
      "epoch:36 step:28329 [D loss: 0.464324, acc: 78.12%] [G loss: 2.616393]\n",
      "epoch:36 step:28330 [D loss: 0.137302, acc: 97.66%] [G loss: 3.212778]\n",
      "epoch:36 step:28331 [D loss: 1.179653, acc: 20.31%] [G loss: 5.525405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28332 [D loss: 0.104559, acc: 100.00%] [G loss: 3.346838]\n",
      "epoch:36 step:28333 [D loss: 0.581860, acc: 67.97%] [G loss: 8.020369]\n",
      "epoch:36 step:28334 [D loss: 0.119568, acc: 99.22%] [G loss: 6.154227]\n",
      "epoch:36 step:28335 [D loss: 0.374392, acc: 87.50%] [G loss: 5.109118]\n",
      "epoch:36 step:28336 [D loss: 0.853301, acc: 53.91%] [G loss: 5.758606]\n",
      "epoch:36 step:28337 [D loss: 0.703182, acc: 53.91%] [G loss: 1.981605]\n",
      "epoch:36 step:28338 [D loss: 0.185539, acc: 96.09%] [G loss: 7.118242]\n",
      "epoch:36 step:28339 [D loss: 0.116696, acc: 99.22%] [G loss: 4.362172]\n",
      "epoch:36 step:28340 [D loss: 0.508464, acc: 81.25%] [G loss: 3.904343]\n",
      "epoch:36 step:28341 [D loss: 0.409843, acc: 80.47%] [G loss: 5.774293]\n",
      "epoch:36 step:28342 [D loss: 1.820905, acc: 49.22%] [G loss: 4.742180]\n",
      "epoch:36 step:28343 [D loss: 0.050167, acc: 100.00%] [G loss: 3.275358]\n",
      "epoch:36 step:28344 [D loss: 0.091247, acc: 100.00%] [G loss: 5.085083]\n",
      "epoch:36 step:28345 [D loss: 0.255691, acc: 95.31%] [G loss: 4.777758]\n",
      "epoch:36 step:28346 [D loss: 0.433362, acc: 75.00%] [G loss: 4.483441]\n",
      "epoch:36 step:28347 [D loss: 0.177241, acc: 93.75%] [G loss: 4.848947]\n",
      "epoch:36 step:28348 [D loss: 1.870841, acc: 7.03%] [G loss: 3.394067]\n",
      "epoch:36 step:28349 [D loss: 1.075478, acc: 49.22%] [G loss: 6.236876]\n",
      "epoch:36 step:28350 [D loss: 1.003877, acc: 52.34%] [G loss: 4.769035]\n",
      "epoch:36 step:28351 [D loss: 0.325323, acc: 85.16%] [G loss: 2.890612]\n",
      "epoch:36 step:28352 [D loss: 0.229949, acc: 92.19%] [G loss: 4.901638]\n",
      "epoch:36 step:28353 [D loss: 1.174447, acc: 50.00%] [G loss: 5.583842]\n",
      "epoch:36 step:28354 [D loss: 0.125569, acc: 100.00%] [G loss: 4.460732]\n",
      "epoch:36 step:28355 [D loss: 0.608292, acc: 64.06%] [G loss: 4.145124]\n",
      "epoch:36 step:28356 [D loss: 0.152429, acc: 99.22%] [G loss: 3.978357]\n",
      "epoch:36 step:28357 [D loss: 1.344925, acc: 25.00%] [G loss: 4.548842]\n",
      "epoch:36 step:28358 [D loss: 0.070594, acc: 100.00%] [G loss: 5.754845]\n",
      "epoch:36 step:28359 [D loss: 0.043559, acc: 100.00%] [G loss: 6.116824]\n",
      "epoch:36 step:28360 [D loss: 0.390008, acc: 83.59%] [G loss: 8.060152]\n",
      "epoch:36 step:28361 [D loss: 0.155553, acc: 98.44%] [G loss: 4.092295]\n",
      "epoch:36 step:28362 [D loss: 0.550062, acc: 69.53%] [G loss: 3.936671]\n",
      "epoch:36 step:28363 [D loss: 0.033614, acc: 100.00%] [G loss: 5.581017]\n",
      "epoch:36 step:28364 [D loss: 0.852887, acc: 52.34%] [G loss: 4.999164]\n",
      "epoch:36 step:28365 [D loss: 0.308993, acc: 89.84%] [G loss: 4.766136]\n",
      "epoch:36 step:28366 [D loss: 0.393710, acc: 75.00%] [G loss: 4.603221]\n",
      "epoch:36 step:28367 [D loss: 1.023666, acc: 53.12%] [G loss: 6.290016]\n",
      "epoch:36 step:28368 [D loss: 0.287993, acc: 89.84%] [G loss: 2.964894]\n",
      "epoch:36 step:28369 [D loss: 0.311291, acc: 92.19%] [G loss: 6.017301]\n",
      "epoch:36 step:28370 [D loss: 0.223964, acc: 96.88%] [G loss: 5.365431]\n",
      "epoch:36 step:28371 [D loss: 0.394852, acc: 81.25%] [G loss: 4.681364]\n",
      "epoch:36 step:28372 [D loss: 0.836284, acc: 46.88%] [G loss: 4.129093]\n",
      "epoch:36 step:28373 [D loss: 0.681953, acc: 53.12%] [G loss: 4.961359]\n",
      "epoch:36 step:28374 [D loss: 0.203863, acc: 99.22%] [G loss: 3.320410]\n",
      "epoch:36 step:28375 [D loss: 0.086445, acc: 100.00%] [G loss: 5.673776]\n",
      "epoch:36 step:28376 [D loss: 0.111367, acc: 100.00%] [G loss: 4.909144]\n",
      "epoch:36 step:28377 [D loss: 0.738443, acc: 55.47%] [G loss: 3.457480]\n",
      "epoch:36 step:28378 [D loss: 0.142814, acc: 100.00%] [G loss: 5.532818]\n",
      "epoch:36 step:28379 [D loss: 0.551920, acc: 73.44%] [G loss: 2.541409]\n",
      "epoch:36 step:28380 [D loss: 1.169306, acc: 15.62%] [G loss: 3.038236]\n",
      "epoch:36 step:28381 [D loss: 0.457554, acc: 66.41%] [G loss: 4.827131]\n",
      "epoch:36 step:28382 [D loss: 0.533272, acc: 70.31%] [G loss: 6.932737]\n",
      "epoch:36 step:28383 [D loss: 0.331873, acc: 84.38%] [G loss: 5.531941]\n",
      "epoch:36 step:28384 [D loss: 0.570784, acc: 59.38%] [G loss: 3.166820]\n",
      "epoch:36 step:28385 [D loss: 0.190699, acc: 98.44%] [G loss: 6.086792]\n",
      "epoch:36 step:28386 [D loss: 0.234269, acc: 95.31%] [G loss: 5.882398]\n",
      "epoch:36 step:28387 [D loss: 0.409594, acc: 75.78%] [G loss: 5.078073]\n",
      "epoch:36 step:28388 [D loss: 0.464523, acc: 65.62%] [G loss: 6.337059]\n",
      "epoch:36 step:28389 [D loss: 0.522825, acc: 67.19%] [G loss: 3.909351]\n",
      "epoch:36 step:28390 [D loss: 0.066993, acc: 99.22%] [G loss: 4.221087]\n",
      "epoch:36 step:28391 [D loss: 1.201876, acc: 35.16%] [G loss: 4.221419]\n",
      "epoch:36 step:28392 [D loss: 0.219218, acc: 98.44%] [G loss: 4.593485]\n",
      "epoch:36 step:28393 [D loss: 0.516094, acc: 66.41%] [G loss: 10.302239]\n",
      "epoch:36 step:28394 [D loss: 0.303514, acc: 86.72%] [G loss: 6.544401]\n",
      "epoch:36 step:28395 [D loss: 0.355150, acc: 92.97%] [G loss: 5.555157]\n",
      "epoch:36 step:28396 [D loss: 0.181678, acc: 96.09%] [G loss: 3.957645]\n",
      "epoch:36 step:28397 [D loss: 0.111922, acc: 100.00%] [G loss: 4.598423]\n",
      "epoch:36 step:28398 [D loss: 0.307459, acc: 88.28%] [G loss: 4.480868]\n",
      "epoch:36 step:28399 [D loss: 0.088114, acc: 99.22%] [G loss: 6.907308]\n",
      "epoch:36 step:28400 [D loss: 0.978677, acc: 49.22%] [G loss: 2.636964]\n",
      "epoch:36 step:28401 [D loss: 0.087282, acc: 100.00%] [G loss: 7.016771]\n",
      "epoch:36 step:28402 [D loss: 0.450292, acc: 82.81%] [G loss: 4.694894]\n",
      "epoch:36 step:28403 [D loss: 0.083102, acc: 100.00%] [G loss: 6.634503]\n",
      "epoch:36 step:28404 [D loss: 0.555400, acc: 73.44%] [G loss: 5.903671]\n",
      "epoch:36 step:28405 [D loss: 0.374987, acc: 78.91%] [G loss: 5.875699]\n",
      "epoch:36 step:28406 [D loss: 0.543131, acc: 58.59%] [G loss: 3.432434]\n",
      "epoch:36 step:28407 [D loss: 1.440116, acc: 47.66%] [G loss: 5.240551]\n",
      "epoch:36 step:28408 [D loss: 0.261295, acc: 93.75%] [G loss: 4.152481]\n",
      "epoch:36 step:28409 [D loss: 0.112980, acc: 99.22%] [G loss: 3.090674]\n",
      "epoch:36 step:28410 [D loss: 0.230878, acc: 96.88%] [G loss: 2.710815]\n",
      "epoch:36 step:28411 [D loss: 0.384794, acc: 85.16%] [G loss: 3.038923]\n",
      "epoch:36 step:28412 [D loss: 0.223359, acc: 97.66%] [G loss: 3.662226]\n",
      "epoch:36 step:28413 [D loss: 1.120301, acc: 38.28%] [G loss: 4.426461]\n",
      "epoch:36 step:28414 [D loss: 0.635375, acc: 66.41%] [G loss: 3.265835]\n",
      "epoch:36 step:28415 [D loss: 0.040638, acc: 100.00%] [G loss: 3.796383]\n",
      "epoch:36 step:28416 [D loss: 0.278213, acc: 91.41%] [G loss: 4.114979]\n",
      "epoch:36 step:28417 [D loss: 0.231652, acc: 96.88%] [G loss: 4.780876]\n",
      "epoch:36 step:28418 [D loss: 0.251862, acc: 97.66%] [G loss: 3.653619]\n",
      "epoch:36 step:28419 [D loss: 0.174597, acc: 99.22%] [G loss: 3.435966]\n",
      "epoch:36 step:28420 [D loss: 1.177710, acc: 47.66%] [G loss: 4.048883]\n",
      "epoch:36 step:28421 [D loss: 0.073174, acc: 100.00%] [G loss: 3.329118]\n",
      "epoch:36 step:28422 [D loss: 0.991946, acc: 51.56%] [G loss: 6.620238]\n",
      "epoch:36 step:28423 [D loss: 0.517750, acc: 62.50%] [G loss: 2.552522]\n",
      "epoch:36 step:28424 [D loss: 0.859898, acc: 43.75%] [G loss: 6.273056]\n",
      "epoch:36 step:28425 [D loss: 0.799135, acc: 56.25%] [G loss: 3.595335]\n",
      "epoch:36 step:28426 [D loss: 0.047405, acc: 100.00%] [G loss: 4.739436]\n",
      "epoch:36 step:28427 [D loss: 0.881652, acc: 52.34%] [G loss: 3.024331]\n",
      "epoch:36 step:28428 [D loss: 0.098995, acc: 100.00%] [G loss: 4.768454]\n",
      "epoch:36 step:28429 [D loss: 1.363562, acc: 50.00%] [G loss: 5.440439]\n",
      "epoch:36 step:28430 [D loss: 0.402457, acc: 78.12%] [G loss: 4.225315]\n",
      "epoch:36 step:28431 [D loss: 1.176389, acc: 18.75%] [G loss: 2.589296]\n",
      "epoch:36 step:28432 [D loss: 0.126512, acc: 99.22%] [G loss: 4.394772]\n",
      "epoch:36 step:28433 [D loss: 0.261357, acc: 96.88%] [G loss: 3.283613]\n",
      "epoch:36 step:28434 [D loss: 0.283489, acc: 95.31%] [G loss: 5.480258]\n",
      "epoch:36 step:28435 [D loss: 0.548503, acc: 72.66%] [G loss: 4.766627]\n",
      "epoch:36 step:28436 [D loss: 0.654712, acc: 60.16%] [G loss: 4.299502]\n",
      "epoch:36 step:28437 [D loss: 0.854715, acc: 51.56%] [G loss: 5.576349]\n",
      "epoch:36 step:28438 [D loss: 0.281222, acc: 94.53%] [G loss: 4.624494]\n",
      "epoch:36 step:28439 [D loss: 0.032783, acc: 100.00%] [G loss: 3.687394]\n",
      "epoch:36 step:28440 [D loss: 0.648025, acc: 56.25%] [G loss: 5.079658]\n",
      "epoch:36 step:28441 [D loss: 0.427971, acc: 82.81%] [G loss: 4.752611]\n",
      "epoch:36 step:28442 [D loss: 0.081843, acc: 100.00%] [G loss: 6.062493]\n",
      "epoch:36 step:28443 [D loss: 0.348692, acc: 79.69%] [G loss: 4.449721]\n",
      "epoch:36 step:28444 [D loss: 0.235778, acc: 96.09%] [G loss: 3.028898]\n",
      "epoch:36 step:28445 [D loss: 0.087212, acc: 99.22%] [G loss: 4.314931]\n",
      "epoch:36 step:28446 [D loss: 0.822119, acc: 46.88%] [G loss: 3.741439]\n",
      "epoch:36 step:28447 [D loss: 0.103093, acc: 99.22%] [G loss: 4.445248]\n",
      "epoch:36 step:28448 [D loss: 0.356590, acc: 92.19%] [G loss: 6.342361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28449 [D loss: 0.359538, acc: 80.47%] [G loss: 7.003737]\n",
      "epoch:36 step:28450 [D loss: 0.604416, acc: 59.38%] [G loss: 4.324831]\n",
      "epoch:36 step:28451 [D loss: 0.118714, acc: 99.22%] [G loss: 6.607709]\n",
      "epoch:36 step:28452 [D loss: 0.139969, acc: 99.22%] [G loss: 5.084831]\n",
      "epoch:36 step:28453 [D loss: 0.268412, acc: 97.66%] [G loss: 1.994904]\n",
      "epoch:36 step:28454 [D loss: 0.698224, acc: 57.81%] [G loss: 6.873389]\n",
      "epoch:36 step:28455 [D loss: 0.473160, acc: 75.78%] [G loss: 3.381570]\n",
      "epoch:36 step:28456 [D loss: 0.057232, acc: 100.00%] [G loss: 4.865671]\n",
      "epoch:36 step:28457 [D loss: 0.405010, acc: 77.34%] [G loss: 5.323470]\n",
      "epoch:36 step:28458 [D loss: 1.401386, acc: 9.38%] [G loss: 5.966359]\n",
      "epoch:36 step:28459 [D loss: 0.126512, acc: 100.00%] [G loss: 4.633724]\n",
      "epoch:36 step:28460 [D loss: 0.211280, acc: 99.22%] [G loss: 4.227041]\n",
      "epoch:36 step:28461 [D loss: 0.137693, acc: 100.00%] [G loss: 3.369468]\n",
      "epoch:36 step:28462 [D loss: 0.369885, acc: 85.94%] [G loss: 5.079855]\n",
      "epoch:36 step:28463 [D loss: 0.459347, acc: 81.25%] [G loss: 5.121657]\n",
      "epoch:36 step:28464 [D loss: 0.558417, acc: 57.81%] [G loss: 5.446905]\n",
      "epoch:36 step:28465 [D loss: 1.191376, acc: 41.41%] [G loss: 3.639566]\n",
      "epoch:36 step:28466 [D loss: 0.269759, acc: 97.66%] [G loss: 4.951587]\n",
      "epoch:36 step:28467 [D loss: 0.127076, acc: 99.22%] [G loss: 4.166561]\n",
      "epoch:36 step:28468 [D loss: 0.065044, acc: 100.00%] [G loss: 5.547239]\n",
      "epoch:36 step:28469 [D loss: 0.278439, acc: 92.19%] [G loss: 3.514325]\n",
      "epoch:36 step:28470 [D loss: 0.486629, acc: 71.09%] [G loss: 4.006701]\n",
      "epoch:36 step:28471 [D loss: 0.099619, acc: 100.00%] [G loss: 3.245213]\n",
      "epoch:36 step:28472 [D loss: 0.375978, acc: 82.03%] [G loss: 3.058193]\n",
      "epoch:36 step:28473 [D loss: 0.213200, acc: 98.44%] [G loss: 4.884511]\n",
      "epoch:36 step:28474 [D loss: 0.358250, acc: 75.78%] [G loss: 5.200914]\n",
      "epoch:36 step:28475 [D loss: 0.520247, acc: 62.50%] [G loss: 4.057453]\n",
      "epoch:36 step:28476 [D loss: 0.148725, acc: 96.88%] [G loss: 6.132789]\n",
      "epoch:36 step:28477 [D loss: 0.973351, acc: 53.12%] [G loss: 5.979758]\n",
      "epoch:36 step:28478 [D loss: 0.897151, acc: 50.78%] [G loss: 5.523205]\n",
      "epoch:36 step:28479 [D loss: 0.081113, acc: 99.22%] [G loss: 4.638647]\n",
      "epoch:36 step:28480 [D loss: 0.142020, acc: 98.44%] [G loss: 2.336269]\n",
      "epoch:36 step:28481 [D loss: 0.211803, acc: 96.88%] [G loss: 4.045687]\n",
      "epoch:36 step:28482 [D loss: 0.145896, acc: 100.00%] [G loss: 6.996018]\n",
      "epoch:36 step:28483 [D loss: 0.108773, acc: 100.00%] [G loss: 3.853506]\n",
      "epoch:36 step:28484 [D loss: 0.149718, acc: 100.00%] [G loss: 3.095097]\n",
      "epoch:36 step:28485 [D loss: 0.521639, acc: 74.22%] [G loss: 4.042362]\n",
      "epoch:36 step:28486 [D loss: 0.710094, acc: 60.16%] [G loss: 2.691240]\n",
      "epoch:36 step:28487 [D loss: 0.610077, acc: 65.62%] [G loss: 4.284458]\n",
      "epoch:36 step:28488 [D loss: 0.312199, acc: 92.19%] [G loss: 3.635860]\n",
      "epoch:36 step:28489 [D loss: 0.047878, acc: 100.00%] [G loss: 6.339828]\n",
      "epoch:36 step:28490 [D loss: 0.201862, acc: 96.09%] [G loss: 1.896888]\n",
      "epoch:36 step:28491 [D loss: 0.056757, acc: 100.00%] [G loss: 4.302192]\n",
      "epoch:36 step:28492 [D loss: 0.148780, acc: 99.22%] [G loss: 4.262970]\n",
      "epoch:36 step:28493 [D loss: 0.382848, acc: 89.84%] [G loss: 5.190796]\n",
      "epoch:36 step:28494 [D loss: 0.169997, acc: 96.88%] [G loss: 6.285830]\n",
      "epoch:36 step:28495 [D loss: 0.379920, acc: 89.84%] [G loss: 6.467532]\n",
      "epoch:36 step:28496 [D loss: 0.195099, acc: 96.09%] [G loss: 5.596688]\n",
      "epoch:36 step:28497 [D loss: 0.759024, acc: 53.91%] [G loss: 3.893798]\n",
      "epoch:36 step:28498 [D loss: 0.340935, acc: 90.62%] [G loss: 5.158340]\n",
      "epoch:36 step:28499 [D loss: 0.872947, acc: 50.00%] [G loss: 4.800162]\n",
      "epoch:36 step:28500 [D loss: 1.538732, acc: 50.00%] [G loss: 3.411412]\n",
      "epoch:36 step:28501 [D loss: 1.169873, acc: 15.62%] [G loss: 3.739120]\n",
      "epoch:36 step:28502 [D loss: 0.505889, acc: 78.91%] [G loss: 5.603668]\n",
      "epoch:36 step:28503 [D loss: 0.129025, acc: 99.22%] [G loss: 5.247276]\n",
      "epoch:36 step:28504 [D loss: 0.373182, acc: 87.50%] [G loss: 2.470170]\n",
      "epoch:36 step:28505 [D loss: 0.576444, acc: 64.84%] [G loss: 3.821203]\n",
      "epoch:36 step:28506 [D loss: 0.066957, acc: 100.00%] [G loss: 2.986011]\n",
      "epoch:36 step:28507 [D loss: 0.148089, acc: 98.44%] [G loss: 5.877586]\n",
      "epoch:36 step:28508 [D loss: 0.242969, acc: 99.22%] [G loss: 5.099082]\n",
      "epoch:36 step:28509 [D loss: 0.125024, acc: 99.22%] [G loss: 4.762868]\n",
      "epoch:36 step:28510 [D loss: 0.880207, acc: 57.03%] [G loss: 6.261909]\n",
      "epoch:36 step:28511 [D loss: 0.229303, acc: 93.75%] [G loss: 3.948443]\n",
      "epoch:36 step:28512 [D loss: 0.224220, acc: 96.88%] [G loss: 5.535872]\n",
      "epoch:36 step:28513 [D loss: 0.495127, acc: 67.19%] [G loss: 6.617083]\n",
      "epoch:36 step:28514 [D loss: 0.518088, acc: 65.62%] [G loss: 5.194224]\n",
      "epoch:36 step:28515 [D loss: 0.328073, acc: 94.53%] [G loss: 6.156656]\n",
      "epoch:36 step:28516 [D loss: 0.173947, acc: 97.66%] [G loss: 6.632327]\n",
      "epoch:36 step:28517 [D loss: 0.149806, acc: 97.66%] [G loss: 6.120835]\n",
      "epoch:36 step:28518 [D loss: 0.120850, acc: 100.00%] [G loss: 4.243050]\n",
      "epoch:36 step:28519 [D loss: 0.279592, acc: 87.50%] [G loss: 6.654016]\n",
      "epoch:36 step:28520 [D loss: 0.314817, acc: 85.94%] [G loss: 3.788502]\n",
      "epoch:36 step:28521 [D loss: 0.472005, acc: 70.31%] [G loss: 1.910801]\n",
      "epoch:36 step:28522 [D loss: 0.275311, acc: 93.75%] [G loss: 2.752603]\n",
      "epoch:36 step:28523 [D loss: 0.318620, acc: 92.97%] [G loss: 4.458220]\n",
      "epoch:36 step:28524 [D loss: 0.089057, acc: 100.00%] [G loss: 4.044045]\n",
      "epoch:36 step:28525 [D loss: 0.298632, acc: 89.06%] [G loss: 4.650754]\n",
      "epoch:36 step:28526 [D loss: 0.103901, acc: 100.00%] [G loss: 4.235702]\n",
      "epoch:36 step:28527 [D loss: 0.783269, acc: 56.25%] [G loss: 5.083564]\n",
      "epoch:36 step:28528 [D loss: 0.397741, acc: 73.44%] [G loss: 3.862875]\n",
      "epoch:36 step:28529 [D loss: 0.134013, acc: 100.00%] [G loss: 4.890977]\n",
      "epoch:36 step:28530 [D loss: 0.200195, acc: 98.44%] [G loss: 5.783379]\n",
      "epoch:36 step:28531 [D loss: 0.149909, acc: 97.66%] [G loss: 4.782449]\n",
      "epoch:36 step:28532 [D loss: 0.471131, acc: 77.34%] [G loss: 4.987487]\n",
      "epoch:36 step:28533 [D loss: 0.164486, acc: 99.22%] [G loss: 3.501059]\n",
      "epoch:36 step:28534 [D loss: 0.256828, acc: 96.88%] [G loss: 4.886485]\n",
      "epoch:36 step:28535 [D loss: 0.072818, acc: 100.00%] [G loss: 7.014839]\n",
      "epoch:36 step:28536 [D loss: 0.556078, acc: 66.41%] [G loss: 3.664970]\n",
      "epoch:36 step:28537 [D loss: 0.201674, acc: 98.44%] [G loss: 5.064634]\n",
      "epoch:36 step:28538 [D loss: 0.480936, acc: 79.69%] [G loss: 5.732488]\n",
      "epoch:36 step:28539 [D loss: 0.287163, acc: 89.84%] [G loss: 7.868728]\n",
      "epoch:36 step:28540 [D loss: 0.242875, acc: 98.44%] [G loss: 3.639112]\n",
      "epoch:36 step:28541 [D loss: 0.406068, acc: 76.56%] [G loss: 4.800865]\n",
      "epoch:36 step:28542 [D loss: 0.235492, acc: 97.66%] [G loss: 4.892546]\n",
      "epoch:36 step:28543 [D loss: 0.875209, acc: 44.53%] [G loss: 3.343966]\n",
      "epoch:36 step:28544 [D loss: 0.612765, acc: 64.06%] [G loss: 5.646695]\n",
      "epoch:36 step:28545 [D loss: 0.081782, acc: 99.22%] [G loss: 7.294625]\n",
      "epoch:36 step:28546 [D loss: 0.317585, acc: 82.81%] [G loss: 6.195843]\n",
      "epoch:36 step:28547 [D loss: 0.951855, acc: 26.56%] [G loss: 5.706952]\n",
      "epoch:36 step:28548 [D loss: 0.039135, acc: 100.00%] [G loss: 6.596981]\n",
      "epoch:36 step:28549 [D loss: 0.210817, acc: 96.88%] [G loss: 6.301269]\n",
      "epoch:36 step:28550 [D loss: 0.106413, acc: 100.00%] [G loss: 7.762724]\n",
      "epoch:36 step:28551 [D loss: 0.536394, acc: 63.28%] [G loss: 5.560229]\n",
      "epoch:36 step:28552 [D loss: 0.582884, acc: 68.75%] [G loss: 3.736594]\n",
      "epoch:36 step:28553 [D loss: 0.734245, acc: 51.56%] [G loss: 4.383313]\n",
      "epoch:36 step:28554 [D loss: 1.253862, acc: 11.72%] [G loss: 6.397471]\n",
      "epoch:36 step:28555 [D loss: 0.300452, acc: 96.88%] [G loss: 3.214401]\n",
      "epoch:36 step:28556 [D loss: 0.625970, acc: 57.81%] [G loss: 5.477496]\n",
      "epoch:36 step:28557 [D loss: 0.073097, acc: 100.00%] [G loss: 3.881483]\n",
      "epoch:36 step:28558 [D loss: 0.286387, acc: 89.84%] [G loss: 4.583055]\n",
      "epoch:36 step:28559 [D loss: 0.291966, acc: 91.41%] [G loss: 4.042903]\n",
      "epoch:36 step:28560 [D loss: 0.065195, acc: 100.00%] [G loss: 5.296077]\n",
      "epoch:36 step:28561 [D loss: 0.681595, acc: 62.50%] [G loss: 3.980609]\n",
      "epoch:36 step:28562 [D loss: 0.141260, acc: 100.00%] [G loss: 3.748826]\n",
      "epoch:36 step:28563 [D loss: 1.141025, acc: 39.84%] [G loss: 6.816459]\n",
      "epoch:36 step:28564 [D loss: 0.439532, acc: 78.12%] [G loss: 4.683342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28565 [D loss: 0.876743, acc: 43.75%] [G loss: 5.591152]\n",
      "epoch:36 step:28566 [D loss: 0.118177, acc: 100.00%] [G loss: 4.723014]\n",
      "epoch:36 step:28567 [D loss: 0.245540, acc: 93.75%] [G loss: 4.675790]\n",
      "epoch:36 step:28568 [D loss: 0.094866, acc: 99.22%] [G loss: 2.715301]\n",
      "epoch:36 step:28569 [D loss: 0.115835, acc: 100.00%] [G loss: 2.272851]\n",
      "epoch:36 step:28570 [D loss: 0.289505, acc: 95.31%] [G loss: 2.767434]\n",
      "epoch:36 step:28571 [D loss: 0.208426, acc: 99.22%] [G loss: 4.237514]\n",
      "epoch:36 step:28572 [D loss: 0.439963, acc: 80.47%] [G loss: 3.531338]\n",
      "epoch:36 step:28573 [D loss: 0.546820, acc: 67.97%] [G loss: 4.743557]\n",
      "epoch:36 step:28574 [D loss: 0.586158, acc: 58.59%] [G loss: 4.391280]\n",
      "epoch:36 step:28575 [D loss: 0.278472, acc: 92.19%] [G loss: 6.584359]\n",
      "epoch:36 step:28576 [D loss: 0.471593, acc: 83.59%] [G loss: 2.798862]\n",
      "epoch:36 step:28577 [D loss: 0.158807, acc: 98.44%] [G loss: 6.771420]\n",
      "epoch:36 step:28578 [D loss: 0.043056, acc: 100.00%] [G loss: 4.923686]\n",
      "epoch:36 step:28579 [D loss: 0.717807, acc: 54.69%] [G loss: 5.872523]\n",
      "epoch:36 step:28580 [D loss: 0.205887, acc: 98.44%] [G loss: 5.653819]\n",
      "epoch:36 step:28581 [D loss: 0.701812, acc: 50.78%] [G loss: 2.811648]\n",
      "epoch:36 step:28582 [D loss: 0.068986, acc: 100.00%] [G loss: 3.460154]\n",
      "epoch:36 step:28583 [D loss: 0.185232, acc: 99.22%] [G loss: 2.413795]\n",
      "epoch:36 step:28584 [D loss: 0.291701, acc: 90.62%] [G loss: 5.087896]\n",
      "epoch:36 step:28585 [D loss: 0.326846, acc: 85.94%] [G loss: 3.555191]\n",
      "epoch:36 step:28586 [D loss: 0.204153, acc: 96.09%] [G loss: 5.900942]\n",
      "epoch:36 step:28587 [D loss: 0.408011, acc: 87.50%] [G loss: 5.067005]\n",
      "epoch:36 step:28588 [D loss: 0.515775, acc: 77.34%] [G loss: 6.094964]\n",
      "epoch:36 step:28589 [D loss: 0.387317, acc: 75.78%] [G loss: 5.107865]\n",
      "epoch:36 step:28590 [D loss: 0.252493, acc: 92.19%] [G loss: 7.055800]\n",
      "epoch:36 step:28591 [D loss: 0.852623, acc: 53.12%] [G loss: 6.026539]\n",
      "epoch:36 step:28592 [D loss: 0.180265, acc: 96.88%] [G loss: 4.446386]\n",
      "epoch:36 step:28593 [D loss: 0.614756, acc: 63.28%] [G loss: 5.511425]\n",
      "epoch:36 step:28594 [D loss: 0.025978, acc: 100.00%] [G loss: 7.126474]\n",
      "epoch:36 step:28595 [D loss: 1.399100, acc: 7.03%] [G loss: 5.944860]\n",
      "epoch:36 step:28596 [D loss: 0.362771, acc: 95.31%] [G loss: 5.180430]\n",
      "epoch:36 step:28597 [D loss: 0.158382, acc: 99.22%] [G loss: 5.746248]\n",
      "epoch:36 step:28598 [D loss: 0.065774, acc: 100.00%] [G loss: 3.128751]\n",
      "epoch:36 step:28599 [D loss: 0.553967, acc: 69.53%] [G loss: 5.695971]\n",
      "epoch:36 step:28600 [D loss: 0.288515, acc: 92.97%] [G loss: 4.481216]\n",
      "epoch:36 step:28601 [D loss: 0.082997, acc: 100.00%] [G loss: 4.438637]\n",
      "epoch:36 step:28602 [D loss: 0.437699, acc: 87.50%] [G loss: 2.794358]\n",
      "epoch:36 step:28603 [D loss: 0.187209, acc: 94.53%] [G loss: 5.892091]\n",
      "epoch:36 step:28604 [D loss: 0.107671, acc: 99.22%] [G loss: 4.134930]\n",
      "epoch:36 step:28605 [D loss: 0.153641, acc: 98.44%] [G loss: 4.208198]\n",
      "epoch:36 step:28606 [D loss: 0.341932, acc: 81.25%] [G loss: 3.101704]\n",
      "epoch:36 step:28607 [D loss: 0.188591, acc: 96.88%] [G loss: 3.812443]\n",
      "epoch:36 step:28608 [D loss: 0.271024, acc: 96.09%] [G loss: 3.940688]\n",
      "epoch:36 step:28609 [D loss: 0.177487, acc: 98.44%] [G loss: 5.172313]\n",
      "epoch:36 step:28610 [D loss: 0.180944, acc: 100.00%] [G loss: 3.403981]\n",
      "epoch:36 step:28611 [D loss: 0.416530, acc: 84.38%] [G loss: 5.357353]\n",
      "epoch:36 step:28612 [D loss: 0.217861, acc: 94.53%] [G loss: 5.076883]\n",
      "epoch:36 step:28613 [D loss: 0.207680, acc: 98.44%] [G loss: 4.755342]\n",
      "epoch:36 step:28614 [D loss: 0.042745, acc: 100.00%] [G loss: 7.222449]\n",
      "epoch:36 step:28615 [D loss: 0.425100, acc: 76.56%] [G loss: 3.925415]\n",
      "epoch:36 step:28616 [D loss: 0.220801, acc: 95.31%] [G loss: 6.425372]\n",
      "epoch:36 step:28617 [D loss: 0.736291, acc: 55.47%] [G loss: 5.581466]\n",
      "epoch:36 step:28618 [D loss: 0.923364, acc: 50.78%] [G loss: 3.556899]\n",
      "epoch:36 step:28619 [D loss: 0.134735, acc: 98.44%] [G loss: 5.851394]\n",
      "epoch:36 step:28620 [D loss: 0.227155, acc: 96.88%] [G loss: 3.919309]\n",
      "epoch:36 step:28621 [D loss: 0.555727, acc: 65.62%] [G loss: 4.663755]\n",
      "epoch:36 step:28622 [D loss: 0.558228, acc: 75.00%] [G loss: 2.949436]\n",
      "epoch:36 step:28623 [D loss: 1.419182, acc: 21.88%] [G loss: 4.414619]\n",
      "epoch:36 step:28624 [D loss: 0.168564, acc: 98.44%] [G loss: 4.984691]\n",
      "epoch:36 step:28625 [D loss: 0.258097, acc: 93.75%] [G loss: 5.368310]\n",
      "epoch:36 step:28626 [D loss: 0.409708, acc: 89.84%] [G loss: 5.189877]\n",
      "epoch:36 step:28627 [D loss: 0.016715, acc: 100.00%] [G loss: 7.614206]\n",
      "epoch:36 step:28628 [D loss: 0.234843, acc: 96.09%] [G loss: 3.467925]\n",
      "epoch:36 step:28629 [D loss: 1.029834, acc: 21.88%] [G loss: 7.282534]\n",
      "epoch:36 step:28630 [D loss: 0.215175, acc: 93.75%] [G loss: 5.150438]\n",
      "epoch:36 step:28631 [D loss: 0.187774, acc: 98.44%] [G loss: 3.106286]\n",
      "epoch:36 step:28632 [D loss: 0.228217, acc: 93.75%] [G loss: 2.987957]\n",
      "epoch:36 step:28633 [D loss: 0.458259, acc: 71.88%] [G loss: 4.446284]\n",
      "epoch:36 step:28634 [D loss: 0.701655, acc: 54.69%] [G loss: 5.894970]\n",
      "epoch:36 step:28635 [D loss: 0.252240, acc: 89.84%] [G loss: 4.808862]\n",
      "epoch:36 step:28636 [D loss: 0.233204, acc: 94.53%] [G loss: 4.186015]\n",
      "epoch:36 step:28637 [D loss: 0.017726, acc: 100.00%] [G loss: 6.318081]\n",
      "epoch:36 step:28638 [D loss: 0.844739, acc: 36.72%] [G loss: 5.012677]\n",
      "epoch:36 step:28639 [D loss: 0.229431, acc: 94.53%] [G loss: 7.414462]\n",
      "epoch:36 step:28640 [D loss: 0.264320, acc: 94.53%] [G loss: 3.756950]\n",
      "epoch:36 step:28641 [D loss: 0.288646, acc: 92.97%] [G loss: 4.359853]\n",
      "epoch:36 step:28642 [D loss: 0.308561, acc: 94.53%] [G loss: 9.311186]\n",
      "epoch:36 step:28643 [D loss: 0.219945, acc: 96.88%] [G loss: 7.991413]\n",
      "epoch:36 step:28644 [D loss: 0.424982, acc: 84.38%] [G loss: 3.791493]\n",
      "epoch:36 step:28645 [D loss: 0.031260, acc: 100.00%] [G loss: 6.764334]\n",
      "epoch:36 step:28646 [D loss: 0.122151, acc: 99.22%] [G loss: 7.779050]\n",
      "epoch:36 step:28647 [D loss: 0.273690, acc: 92.19%] [G loss: 3.119294]\n",
      "epoch:36 step:28648 [D loss: 0.514523, acc: 76.56%] [G loss: 2.513188]\n",
      "epoch:36 step:28649 [D loss: 0.938751, acc: 40.62%] [G loss: 4.232275]\n",
      "epoch:36 step:28650 [D loss: 0.513432, acc: 67.97%] [G loss: 4.271307]\n",
      "epoch:36 step:28651 [D loss: 0.806707, acc: 45.31%] [G loss: 4.090676]\n",
      "epoch:36 step:28652 [D loss: 0.019006, acc: 100.00%] [G loss: 2.734272]\n",
      "epoch:36 step:28653 [D loss: 0.105457, acc: 100.00%] [G loss: 6.590294]\n",
      "epoch:36 step:28654 [D loss: 0.163492, acc: 98.44%] [G loss: 6.971573]\n",
      "epoch:36 step:28655 [D loss: 0.375017, acc: 88.28%] [G loss: 4.363069]\n",
      "epoch:36 step:28656 [D loss: 0.053785, acc: 100.00%] [G loss: 7.238458]\n",
      "epoch:36 step:28657 [D loss: 0.156062, acc: 98.44%] [G loss: 4.979000]\n",
      "epoch:36 step:28658 [D loss: 0.373303, acc: 83.59%] [G loss: 4.631905]\n",
      "epoch:36 step:28659 [D loss: 0.310323, acc: 89.06%] [G loss: 5.463098]\n",
      "epoch:36 step:28660 [D loss: 0.337902, acc: 90.62%] [G loss: 3.329517]\n",
      "epoch:36 step:28661 [D loss: 0.194344, acc: 99.22%] [G loss: 3.984570]\n",
      "epoch:36 step:28662 [D loss: 0.143847, acc: 98.44%] [G loss: 6.155899]\n",
      "epoch:36 step:28663 [D loss: 0.159033, acc: 98.44%] [G loss: 6.623459]\n",
      "epoch:36 step:28664 [D loss: 0.573920, acc: 62.50%] [G loss: 3.578944]\n",
      "epoch:36 step:28665 [D loss: 0.367863, acc: 78.91%] [G loss: 2.815145]\n",
      "epoch:36 step:28666 [D loss: 0.115919, acc: 100.00%] [G loss: 2.872099]\n",
      "epoch:36 step:28667 [D loss: 0.141053, acc: 98.44%] [G loss: 5.582178]\n",
      "epoch:36 step:28668 [D loss: 0.272315, acc: 95.31%] [G loss: 5.134411]\n",
      "epoch:36 step:28669 [D loss: 0.318237, acc: 93.75%] [G loss: 2.549810]\n",
      "epoch:36 step:28670 [D loss: 0.642869, acc: 55.47%] [G loss: 5.870489]\n",
      "epoch:36 step:28671 [D loss: 0.552290, acc: 60.94%] [G loss: 4.914416]\n",
      "epoch:36 step:28672 [D loss: 0.500624, acc: 67.19%] [G loss: 5.716254]\n",
      "epoch:36 step:28673 [D loss: 0.129904, acc: 97.66%] [G loss: 3.758638]\n",
      "epoch:36 step:28674 [D loss: 1.128608, acc: 50.00%] [G loss: 5.349053]\n",
      "epoch:36 step:28675 [D loss: 0.824401, acc: 52.34%] [G loss: 6.442841]\n",
      "epoch:36 step:28676 [D loss: 0.129431, acc: 99.22%] [G loss: 2.891425]\n",
      "epoch:36 step:28677 [D loss: 0.238987, acc: 91.41%] [G loss: 5.729311]\n",
      "epoch:36 step:28678 [D loss: 0.219935, acc: 96.09%] [G loss: 3.613689]\n",
      "epoch:36 step:28679 [D loss: 1.087676, acc: 50.00%] [G loss: 3.134946]\n",
      "epoch:36 step:28680 [D loss: 0.083298, acc: 100.00%] [G loss: 6.282711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28681 [D loss: 0.365567, acc: 78.12%] [G loss: 6.683393]\n",
      "epoch:36 step:28682 [D loss: 1.037365, acc: 42.19%] [G loss: 6.181549]\n",
      "epoch:36 step:28683 [D loss: 0.397808, acc: 84.38%] [G loss: 3.127644]\n",
      "epoch:36 step:28684 [D loss: 0.034170, acc: 100.00%] [G loss: 4.675940]\n",
      "epoch:36 step:28685 [D loss: 0.560760, acc: 64.06%] [G loss: 6.802921]\n",
      "epoch:36 step:28686 [D loss: 0.857397, acc: 50.78%] [G loss: 4.749977]\n",
      "epoch:36 step:28687 [D loss: 0.533031, acc: 77.34%] [G loss: 5.476624]\n",
      "epoch:36 step:28688 [D loss: 0.119025, acc: 99.22%] [G loss: 5.506994]\n",
      "epoch:36 step:28689 [D loss: 0.628773, acc: 63.28%] [G loss: 5.456511]\n",
      "epoch:36 step:28690 [D loss: 0.519856, acc: 73.44%] [G loss: 3.310387]\n",
      "epoch:36 step:28691 [D loss: 1.071311, acc: 46.09%] [G loss: 5.153913]\n",
      "epoch:36 step:28692 [D loss: 0.229841, acc: 96.88%] [G loss: 3.186094]\n",
      "epoch:36 step:28693 [D loss: 0.627452, acc: 64.84%] [G loss: 6.795186]\n",
      "epoch:36 step:28694 [D loss: 0.214149, acc: 94.53%] [G loss: 5.703957]\n",
      "epoch:36 step:28695 [D loss: 0.319097, acc: 96.09%] [G loss: 4.754098]\n",
      "epoch:36 step:28696 [D loss: 0.123397, acc: 100.00%] [G loss: 3.765075]\n",
      "epoch:36 step:28697 [D loss: 0.119959, acc: 99.22%] [G loss: 7.293118]\n",
      "epoch:36 step:28698 [D loss: 0.118221, acc: 100.00%] [G loss: 5.173885]\n",
      "epoch:36 step:28699 [D loss: 0.277009, acc: 96.09%] [G loss: 2.931950]\n",
      "epoch:36 step:28700 [D loss: 0.392136, acc: 92.19%] [G loss: 3.876827]\n",
      "epoch:36 step:28701 [D loss: 0.127903, acc: 100.00%] [G loss: 6.108389]\n",
      "epoch:36 step:28702 [D loss: 0.321218, acc: 85.94%] [G loss: 4.744172]\n",
      "epoch:36 step:28703 [D loss: 0.265152, acc: 91.41%] [G loss: 4.221042]\n",
      "epoch:36 step:28704 [D loss: 0.498239, acc: 75.00%] [G loss: 5.245020]\n",
      "epoch:36 step:28705 [D loss: 0.259992, acc: 97.66%] [G loss: 2.258639]\n",
      "epoch:36 step:28706 [D loss: 0.395954, acc: 85.94%] [G loss: 3.577982]\n",
      "epoch:36 step:28707 [D loss: 1.162052, acc: 44.53%] [G loss: 2.202860]\n",
      "epoch:36 step:28708 [D loss: 0.938223, acc: 50.00%] [G loss: 5.901999]\n",
      "epoch:36 step:28709 [D loss: 0.023421, acc: 100.00%] [G loss: 5.353123]\n",
      "epoch:36 step:28710 [D loss: 0.708124, acc: 57.81%] [G loss: 5.500947]\n",
      "epoch:36 step:28711 [D loss: 0.573479, acc: 60.94%] [G loss: 4.750616]\n",
      "epoch:36 step:28712 [D loss: 0.029572, acc: 100.00%] [G loss: 6.103498]\n",
      "epoch:36 step:28713 [D loss: 0.800973, acc: 47.66%] [G loss: 4.154208]\n",
      "epoch:36 step:28714 [D loss: 0.003442, acc: 100.00%] [G loss: 7.842788]\n",
      "epoch:36 step:28715 [D loss: 1.229374, acc: 41.41%] [G loss: 5.015953]\n",
      "epoch:36 step:28716 [D loss: 0.247298, acc: 96.09%] [G loss: 4.088398]\n",
      "epoch:36 step:28717 [D loss: 1.088724, acc: 15.62%] [G loss: 3.790825]\n",
      "epoch:36 step:28718 [D loss: 0.368363, acc: 83.59%] [G loss: 4.640757]\n",
      "epoch:36 step:28719 [D loss: 0.784820, acc: 47.66%] [G loss: 5.326149]\n",
      "epoch:36 step:28720 [D loss: 0.241270, acc: 92.19%] [G loss: 2.919828]\n",
      "epoch:36 step:28721 [D loss: 0.257259, acc: 96.88%] [G loss: 4.223376]\n",
      "epoch:36 step:28722 [D loss: 0.189930, acc: 98.44%] [G loss: 4.089377]\n",
      "epoch:36 step:28723 [D loss: 0.354152, acc: 93.75%] [G loss: 4.881318]\n",
      "epoch:36 step:28724 [D loss: 0.337893, acc: 93.75%] [G loss: 2.573307]\n",
      "epoch:36 step:28725 [D loss: 0.115026, acc: 97.66%] [G loss: 5.127078]\n",
      "epoch:36 step:28726 [D loss: 0.116598, acc: 100.00%] [G loss: 5.010812]\n",
      "epoch:36 step:28727 [D loss: 0.055044, acc: 100.00%] [G loss: 5.524499]\n",
      "epoch:36 step:28728 [D loss: 0.324033, acc: 81.25%] [G loss: 6.943487]\n",
      "epoch:36 step:28729 [D loss: 0.663308, acc: 59.38%] [G loss: 3.024992]\n",
      "epoch:36 step:28730 [D loss: 0.130914, acc: 98.44%] [G loss: 5.466261]\n",
      "epoch:36 step:28731 [D loss: 0.611552, acc: 64.06%] [G loss: 4.294713]\n",
      "epoch:36 step:28732 [D loss: 0.177432, acc: 96.88%] [G loss: 8.296896]\n",
      "epoch:36 step:28733 [D loss: 0.686050, acc: 61.72%] [G loss: 6.220049]\n",
      "epoch:36 step:28734 [D loss: 0.707094, acc: 55.47%] [G loss: 5.553584]\n",
      "epoch:36 step:28735 [D loss: 0.078695, acc: 100.00%] [G loss: 3.113110]\n",
      "epoch:36 step:28736 [D loss: 0.298561, acc: 85.16%] [G loss: 4.270038]\n",
      "epoch:36 step:28737 [D loss: 0.968314, acc: 50.00%] [G loss: 4.393157]\n",
      "epoch:36 step:28738 [D loss: 1.163891, acc: 50.78%] [G loss: 2.588221]\n",
      "epoch:36 step:28739 [D loss: 0.161474, acc: 99.22%] [G loss: 3.911340]\n",
      "epoch:36 step:28740 [D loss: 0.738130, acc: 52.34%] [G loss: 5.597268]\n",
      "epoch:36 step:28741 [D loss: 0.083453, acc: 99.22%] [G loss: 4.773634]\n",
      "epoch:36 step:28742 [D loss: 0.150830, acc: 99.22%] [G loss: 1.844049]\n",
      "epoch:36 step:28743 [D loss: 1.631977, acc: 17.19%] [G loss: 2.783122]\n",
      "epoch:36 step:28744 [D loss: 0.135724, acc: 100.00%] [G loss: 5.711901]\n",
      "epoch:36 step:28745 [D loss: 0.045002, acc: 100.00%] [G loss: 4.232458]\n",
      "epoch:36 step:28746 [D loss: 0.472270, acc: 67.97%] [G loss: 5.677811]\n",
      "epoch:36 step:28747 [D loss: 0.542373, acc: 73.44%] [G loss: 2.981104]\n",
      "epoch:36 step:28748 [D loss: 1.150933, acc: 50.00%] [G loss: 4.672704]\n",
      "epoch:36 step:28749 [D loss: 0.264285, acc: 92.97%] [G loss: 5.367107]\n",
      "epoch:36 step:28750 [D loss: 1.124660, acc: 32.81%] [G loss: 5.928786]\n",
      "epoch:36 step:28751 [D loss: 0.095702, acc: 98.44%] [G loss: 5.200396]\n",
      "epoch:36 step:28752 [D loss: 0.262498, acc: 95.31%] [G loss: 4.131508]\n",
      "epoch:36 step:28753 [D loss: 0.584406, acc: 68.75%] [G loss: 5.008321]\n",
      "epoch:36 step:28754 [D loss: 0.456321, acc: 67.97%] [G loss: 7.050179]\n",
      "epoch:36 step:28755 [D loss: 0.465397, acc: 70.31%] [G loss: 3.795293]\n",
      "epoch:36 step:28756 [D loss: 0.173532, acc: 98.44%] [G loss: 3.103043]\n",
      "epoch:36 step:28757 [D loss: 0.104941, acc: 100.00%] [G loss: 4.084277]\n",
      "epoch:36 step:28758 [D loss: 0.083395, acc: 99.22%] [G loss: 4.817505]\n",
      "epoch:36 step:28759 [D loss: 0.722095, acc: 55.47%] [G loss: 4.031138]\n",
      "epoch:36 step:28760 [D loss: 0.107094, acc: 99.22%] [G loss: 5.935649]\n",
      "epoch:36 step:28761 [D loss: 0.251441, acc: 91.41%] [G loss: 4.331240]\n",
      "epoch:36 step:28762 [D loss: 1.442480, acc: 25.78%] [G loss: 4.026715]\n",
      "epoch:36 step:28763 [D loss: 1.671308, acc: 3.91%] [G loss: 4.362701]\n",
      "epoch:36 step:28764 [D loss: 0.152267, acc: 100.00%] [G loss: 4.811295]\n",
      "epoch:36 step:28765 [D loss: 0.257213, acc: 96.88%] [G loss: 4.368141]\n",
      "epoch:36 step:28766 [D loss: 0.257249, acc: 98.44%] [G loss: 6.212913]\n",
      "epoch:36 step:28767 [D loss: 0.536363, acc: 67.97%] [G loss: 5.314548]\n",
      "epoch:36 step:28768 [D loss: 0.264177, acc: 95.31%] [G loss: 4.580467]\n",
      "epoch:36 step:28769 [D loss: 0.217175, acc: 93.75%] [G loss: 4.532167]\n",
      "epoch:36 step:28770 [D loss: 0.805970, acc: 49.22%] [G loss: 5.620436]\n",
      "epoch:36 step:28771 [D loss: 0.058167, acc: 100.00%] [G loss: 2.095399]\n",
      "epoch:36 step:28772 [D loss: 0.216063, acc: 96.09%] [G loss: 4.455664]\n",
      "epoch:36 step:28773 [D loss: 0.170931, acc: 99.22%] [G loss: 5.255420]\n",
      "epoch:36 step:28774 [D loss: 0.488235, acc: 83.59%] [G loss: 5.333348]\n",
      "epoch:36 step:28775 [D loss: 1.107591, acc: 39.84%] [G loss: 7.219312]\n",
      "epoch:36 step:28776 [D loss: 0.303624, acc: 88.28%] [G loss: 3.232490]\n",
      "epoch:36 step:28777 [D loss: 0.235816, acc: 93.75%] [G loss: 3.914082]\n",
      "epoch:36 step:28778 [D loss: 0.124543, acc: 99.22%] [G loss: 3.519568]\n",
      "epoch:36 step:28779 [D loss: 0.175717, acc: 97.66%] [G loss: 5.468557]\n",
      "epoch:36 step:28780 [D loss: 0.171218, acc: 97.66%] [G loss: 5.776674]\n",
      "epoch:36 step:28781 [D loss: 0.260456, acc: 96.88%] [G loss: 5.529340]\n",
      "epoch:36 step:28782 [D loss: 0.106480, acc: 100.00%] [G loss: 3.145119]\n",
      "epoch:36 step:28783 [D loss: 0.135082, acc: 99.22%] [G loss: 5.011586]\n",
      "epoch:36 step:28784 [D loss: 0.026438, acc: 100.00%] [G loss: 6.267758]\n",
      "epoch:36 step:28785 [D loss: 0.327186, acc: 94.53%] [G loss: 6.236557]\n",
      "epoch:36 step:28786 [D loss: 0.956865, acc: 34.38%] [G loss: 5.100742]\n",
      "epoch:36 step:28787 [D loss: 0.312934, acc: 85.16%] [G loss: 5.124558]\n",
      "epoch:36 step:28788 [D loss: 0.868947, acc: 51.56%] [G loss: 5.654462]\n",
      "epoch:36 step:28789 [D loss: 0.099346, acc: 100.00%] [G loss: 3.389113]\n",
      "epoch:36 step:28790 [D loss: 0.095481, acc: 100.00%] [G loss: 6.671756]\n",
      "epoch:36 step:28791 [D loss: 0.114756, acc: 98.44%] [G loss: 7.002942]\n",
      "epoch:36 step:28792 [D loss: 0.018428, acc: 100.00%] [G loss: 6.352023]\n",
      "epoch:36 step:28793 [D loss: 0.723251, acc: 50.78%] [G loss: 7.725867]\n",
      "epoch:36 step:28794 [D loss: 0.027344, acc: 100.00%] [G loss: 4.596639]\n",
      "epoch:36 step:28795 [D loss: 0.272080, acc: 93.75%] [G loss: 6.904603]\n",
      "epoch:36 step:28796 [D loss: 0.177294, acc: 97.66%] [G loss: 5.328551]\n",
      "epoch:36 step:28797 [D loss: 0.746504, acc: 53.91%] [G loss: 3.946064]\n",
      "epoch:36 step:28798 [D loss: 1.038205, acc: 39.06%] [G loss: 2.979553]\n",
      "epoch:36 step:28799 [D loss: 0.595575, acc: 67.97%] [G loss: 6.359790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28800 [D loss: 0.750155, acc: 49.22%] [G loss: 5.872546]\n",
      "epoch:36 step:28801 [D loss: 0.300313, acc: 91.41%] [G loss: 4.092627]\n",
      "epoch:36 step:28802 [D loss: 0.589889, acc: 63.28%] [G loss: 5.073012]\n",
      "epoch:36 step:28803 [D loss: 1.207279, acc: 46.88%] [G loss: 4.141217]\n",
      "epoch:36 step:28804 [D loss: 0.069209, acc: 100.00%] [G loss: 3.501604]\n",
      "epoch:36 step:28805 [D loss: 0.358143, acc: 82.81%] [G loss: 4.466132]\n",
      "epoch:36 step:28806 [D loss: 0.467457, acc: 69.53%] [G loss: 7.585810]\n",
      "epoch:36 step:28807 [D loss: 0.318613, acc: 86.72%] [G loss: 6.906161]\n",
      "epoch:36 step:28808 [D loss: 0.046152, acc: 100.00%] [G loss: 4.556910]\n",
      "epoch:36 step:28809 [D loss: 0.643612, acc: 63.28%] [G loss: 4.623394]\n",
      "epoch:36 step:28810 [D loss: 0.190259, acc: 96.09%] [G loss: 4.822992]\n",
      "epoch:36 step:28811 [D loss: 1.074878, acc: 50.00%] [G loss: 4.484126]\n",
      "epoch:36 step:28812 [D loss: 0.151337, acc: 99.22%] [G loss: 3.908495]\n",
      "epoch:36 step:28813 [D loss: 1.278187, acc: 48.44%] [G loss: 4.224313]\n",
      "epoch:36 step:28814 [D loss: 0.924725, acc: 45.31%] [G loss: 5.754670]\n",
      "epoch:36 step:28815 [D loss: 0.176945, acc: 98.44%] [G loss: 7.181021]\n",
      "epoch:36 step:28816 [D loss: 0.156440, acc: 99.22%] [G loss: 4.739195]\n",
      "epoch:36 step:28817 [D loss: 0.181167, acc: 97.66%] [G loss: 4.885919]\n",
      "epoch:36 step:28818 [D loss: 0.438503, acc: 67.97%] [G loss: 4.360917]\n",
      "epoch:36 step:28819 [D loss: 0.799403, acc: 43.75%] [G loss: 4.847631]\n",
      "epoch:36 step:28820 [D loss: 0.338090, acc: 86.72%] [G loss: 6.730809]\n",
      "epoch:36 step:28821 [D loss: 0.131945, acc: 99.22%] [G loss: 4.275467]\n",
      "epoch:36 step:28822 [D loss: 0.777226, acc: 43.75%] [G loss: 3.729492]\n",
      "epoch:36 step:28823 [D loss: 0.119007, acc: 99.22%] [G loss: 9.621800]\n",
      "epoch:36 step:28824 [D loss: 0.464551, acc: 79.69%] [G loss: 4.659451]\n",
      "epoch:36 step:28825 [D loss: 0.182715, acc: 99.22%] [G loss: 5.478618]\n",
      "epoch:36 step:28826 [D loss: 0.700806, acc: 53.12%] [G loss: 3.419535]\n",
      "epoch:36 step:28827 [D loss: 0.161150, acc: 97.66%] [G loss: 5.772424]\n",
      "epoch:36 step:28828 [D loss: 0.898436, acc: 51.56%] [G loss: 5.279874]\n",
      "epoch:36 step:28829 [D loss: 0.189894, acc: 96.09%] [G loss: 7.027629]\n",
      "epoch:36 step:28830 [D loss: 0.529832, acc: 61.72%] [G loss: 5.908068]\n",
      "epoch:36 step:28831 [D loss: 0.208021, acc: 98.44%] [G loss: 7.236103]\n",
      "epoch:36 step:28832 [D loss: 0.864731, acc: 39.84%] [G loss: 8.459896]\n",
      "epoch:36 step:28833 [D loss: 0.102561, acc: 100.00%] [G loss: 6.120206]\n",
      "epoch:36 step:28834 [D loss: 0.144721, acc: 99.22%] [G loss: 4.078958]\n",
      "epoch:36 step:28835 [D loss: 1.131884, acc: 27.34%] [G loss: 7.703249]\n",
      "epoch:36 step:28836 [D loss: 0.045546, acc: 100.00%] [G loss: 4.102500]\n",
      "epoch:36 step:28837 [D loss: 0.489589, acc: 63.28%] [G loss: 6.843607]\n",
      "epoch:36 step:28838 [D loss: 0.596714, acc: 67.97%] [G loss: 4.405703]\n",
      "epoch:36 step:28839 [D loss: 0.061688, acc: 100.00%] [G loss: 6.571069]\n",
      "epoch:36 step:28840 [D loss: 0.691841, acc: 55.47%] [G loss: 4.134860]\n",
      "epoch:36 step:28841 [D loss: 0.497208, acc: 79.69%] [G loss: 4.081546]\n",
      "epoch:36 step:28842 [D loss: 0.581771, acc: 54.69%] [G loss: 3.838745]\n",
      "epoch:36 step:28843 [D loss: 0.045834, acc: 100.00%] [G loss: 7.963729]\n",
      "epoch:36 step:28844 [D loss: 0.837335, acc: 50.78%] [G loss: 9.855984]\n",
      "epoch:36 step:28845 [D loss: 1.515419, acc: 3.91%] [G loss: 6.035998]\n",
      "epoch:36 step:28846 [D loss: 0.737156, acc: 53.12%] [G loss: 4.615890]\n",
      "epoch:36 step:28847 [D loss: 0.405278, acc: 85.16%] [G loss: 3.307077]\n",
      "epoch:36 step:28848 [D loss: 0.232664, acc: 98.44%] [G loss: 4.681115]\n",
      "epoch:36 step:28849 [D loss: 0.204502, acc: 99.22%] [G loss: 3.299098]\n",
      "epoch:36 step:28850 [D loss: 0.960956, acc: 50.78%] [G loss: 5.517271]\n",
      "epoch:36 step:28851 [D loss: 0.118106, acc: 99.22%] [G loss: 2.556868]\n",
      "epoch:36 step:28852 [D loss: 0.425931, acc: 71.09%] [G loss: 5.274256]\n",
      "epoch:36 step:28853 [D loss: 0.377890, acc: 89.84%] [G loss: 3.581144]\n",
      "epoch:36 step:28854 [D loss: 0.533230, acc: 70.31%] [G loss: 4.600374]\n",
      "epoch:36 step:28855 [D loss: 0.619398, acc: 61.72%] [G loss: 5.065186]\n",
      "epoch:36 step:28856 [D loss: 0.136866, acc: 100.00%] [G loss: 6.205101]\n",
      "epoch:36 step:28857 [D loss: 0.296849, acc: 92.97%] [G loss: 4.152229]\n",
      "epoch:36 step:28858 [D loss: 0.323143, acc: 82.81%] [G loss: 5.257930]\n",
      "epoch:36 step:28859 [D loss: 0.322909, acc: 92.19%] [G loss: 4.429897]\n",
      "epoch:36 step:28860 [D loss: 0.865414, acc: 50.00%] [G loss: 5.012635]\n",
      "epoch:36 step:28861 [D loss: 0.364231, acc: 81.25%] [G loss: 1.766691]\n",
      "epoch:36 step:28862 [D loss: 0.466513, acc: 77.34%] [G loss: 4.503419]\n",
      "epoch:36 step:28863 [D loss: 0.669404, acc: 62.50%] [G loss: 5.367256]\n",
      "epoch:36 step:28864 [D loss: 0.252723, acc: 91.41%] [G loss: 4.195569]\n",
      "epoch:36 step:28865 [D loss: 0.664121, acc: 64.06%] [G loss: 4.677697]\n",
      "epoch:36 step:28866 [D loss: 0.927450, acc: 51.56%] [G loss: 3.930500]\n",
      "epoch:36 step:28867 [D loss: 0.936867, acc: 50.00%] [G loss: 6.066769]\n",
      "epoch:36 step:28868 [D loss: 0.162173, acc: 97.66%] [G loss: 4.947935]\n",
      "epoch:36 step:28869 [D loss: 0.113944, acc: 100.00%] [G loss: 5.375937]\n",
      "epoch:36 step:28870 [D loss: 0.927331, acc: 50.00%] [G loss: 3.404037]\n",
      "epoch:36 step:28871 [D loss: 0.535328, acc: 64.84%] [G loss: 3.407475]\n",
      "epoch:36 step:28872 [D loss: 0.434172, acc: 71.09%] [G loss: 4.390261]\n",
      "epoch:36 step:28873 [D loss: 0.185083, acc: 97.66%] [G loss: 4.659551]\n",
      "epoch:36 step:28874 [D loss: 0.208855, acc: 99.22%] [G loss: 4.639631]\n",
      "epoch:36 step:28875 [D loss: 0.165776, acc: 96.88%] [G loss: 6.475730]\n",
      "epoch:36 step:28876 [D loss: 0.152534, acc: 99.22%] [G loss: 4.610766]\n",
      "epoch:36 step:28877 [D loss: 0.147673, acc: 99.22%] [G loss: 5.426332]\n",
      "epoch:36 step:28878 [D loss: 0.979820, acc: 32.81%] [G loss: 4.212187]\n",
      "epoch:36 step:28879 [D loss: 0.538060, acc: 68.75%] [G loss: 4.666656]\n",
      "epoch:36 step:28880 [D loss: 0.248798, acc: 91.41%] [G loss: 5.212390]\n",
      "epoch:36 step:28881 [D loss: 0.203723, acc: 94.53%] [G loss: 6.208495]\n",
      "epoch:36 step:28882 [D loss: 0.627674, acc: 60.94%] [G loss: 5.837512]\n",
      "epoch:36 step:28883 [D loss: 0.149612, acc: 99.22%] [G loss: 5.573459]\n",
      "epoch:36 step:28884 [D loss: 0.093146, acc: 100.00%] [G loss: 4.455158]\n",
      "epoch:36 step:28885 [D loss: 0.062431, acc: 100.00%] [G loss: 3.555719]\n",
      "epoch:36 step:28886 [D loss: 2.308736, acc: 0.00%] [G loss: 4.089732]\n",
      "epoch:36 step:28887 [D loss: 0.478639, acc: 82.03%] [G loss: 4.706129]\n",
      "epoch:36 step:28888 [D loss: 0.393773, acc: 84.38%] [G loss: 5.288679]\n",
      "epoch:36 step:28889 [D loss: 0.130894, acc: 98.44%] [G loss: 7.172303]\n",
      "epoch:36 step:28890 [D loss: 1.038504, acc: 45.31%] [G loss: 4.419148]\n",
      "epoch:36 step:28891 [D loss: 0.613289, acc: 64.06%] [G loss: 5.106491]\n",
      "epoch:36 step:28892 [D loss: 1.622925, acc: 47.66%] [G loss: 3.057291]\n",
      "epoch:36 step:28893 [D loss: 0.280607, acc: 96.09%] [G loss: 3.308189]\n",
      "epoch:36 step:28894 [D loss: 0.455895, acc: 73.44%] [G loss: 3.037316]\n",
      "epoch:36 step:28895 [D loss: 0.248580, acc: 92.97%] [G loss: 4.011172]\n",
      "epoch:36 step:28896 [D loss: 0.248199, acc: 99.22%] [G loss: 3.317081]\n",
      "epoch:36 step:28897 [D loss: 0.130935, acc: 100.00%] [G loss: 3.412871]\n",
      "epoch:37 step:28898 [D loss: 0.802170, acc: 50.00%] [G loss: 4.169670]\n",
      "epoch:37 step:28899 [D loss: 0.069279, acc: 99.22%] [G loss: 6.299693]\n",
      "epoch:37 step:28900 [D loss: 0.389384, acc: 76.56%] [G loss: 3.973121]\n",
      "epoch:37 step:28901 [D loss: 0.118724, acc: 99.22%] [G loss: 4.414036]\n",
      "epoch:37 step:28902 [D loss: 0.098704, acc: 100.00%] [G loss: 6.380939]\n",
      "epoch:37 step:28903 [D loss: 0.176084, acc: 99.22%] [G loss: 4.149848]\n",
      "epoch:37 step:28904 [D loss: 0.565152, acc: 69.53%] [G loss: 2.256065]\n",
      "epoch:37 step:28905 [D loss: 0.994304, acc: 35.16%] [G loss: 4.714847]\n",
      "epoch:37 step:28906 [D loss: 0.522895, acc: 61.72%] [G loss: 5.525692]\n",
      "epoch:37 step:28907 [D loss: 0.351152, acc: 92.19%] [G loss: 6.675124]\n",
      "epoch:37 step:28908 [D loss: 0.259534, acc: 92.97%] [G loss: 6.626156]\n",
      "epoch:37 step:28909 [D loss: 0.609232, acc: 64.06%] [G loss: 4.012036]\n",
      "epoch:37 step:28910 [D loss: 0.400554, acc: 89.06%] [G loss: 3.511285]\n",
      "epoch:37 step:28911 [D loss: 0.135557, acc: 100.00%] [G loss: 3.608843]\n",
      "epoch:37 step:28912 [D loss: 0.685974, acc: 56.25%] [G loss: 4.271464]\n",
      "epoch:37 step:28913 [D loss: 0.255947, acc: 96.09%] [G loss: 6.816706]\n",
      "epoch:37 step:28914 [D loss: 0.309412, acc: 91.41%] [G loss: 3.589467]\n",
      "epoch:37 step:28915 [D loss: 0.176695, acc: 97.66%] [G loss: 3.055284]\n",
      "epoch:37 step:28916 [D loss: 0.238890, acc: 98.44%] [G loss: 5.292113]\n",
      "epoch:37 step:28917 [D loss: 0.126760, acc: 100.00%] [G loss: 3.711162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:28918 [D loss: 0.168881, acc: 97.66%] [G loss: 5.812360]\n",
      "epoch:37 step:28919 [D loss: 0.321586, acc: 94.53%] [G loss: 3.672210]\n",
      "epoch:37 step:28920 [D loss: 0.587266, acc: 64.84%] [G loss: 5.632977]\n",
      "epoch:37 step:28921 [D loss: 0.551938, acc: 76.56%] [G loss: 4.999104]\n",
      "epoch:37 step:28922 [D loss: 0.641886, acc: 64.06%] [G loss: 5.565289]\n",
      "epoch:37 step:28923 [D loss: 0.538789, acc: 64.06%] [G loss: 2.501317]\n",
      "epoch:37 step:28924 [D loss: 0.099343, acc: 100.00%] [G loss: 3.219432]\n",
      "epoch:37 step:28925 [D loss: 0.165490, acc: 99.22%] [G loss: 2.840132]\n",
      "epoch:37 step:28926 [D loss: 0.235946, acc: 92.19%] [G loss: 4.178354]\n",
      "epoch:37 step:28927 [D loss: 0.369986, acc: 90.62%] [G loss: 4.312806]\n",
      "epoch:37 step:28928 [D loss: 0.370447, acc: 89.84%] [G loss: 4.003200]\n",
      "epoch:37 step:28929 [D loss: 0.878536, acc: 34.38%] [G loss: 3.847105]\n",
      "epoch:37 step:28930 [D loss: 0.153703, acc: 100.00%] [G loss: 5.108881]\n",
      "epoch:37 step:28931 [D loss: 0.470477, acc: 80.47%] [G loss: 6.340377]\n",
      "epoch:37 step:28932 [D loss: 0.221831, acc: 96.88%] [G loss: 4.526830]\n",
      "epoch:37 step:28933 [D loss: 0.220150, acc: 94.53%] [G loss: 4.051353]\n",
      "epoch:37 step:28934 [D loss: 0.208614, acc: 92.97%] [G loss: 5.155182]\n",
      "epoch:37 step:28935 [D loss: 0.157991, acc: 98.44%] [G loss: 6.004164]\n",
      "epoch:37 step:28936 [D loss: 0.075724, acc: 100.00%] [G loss: 5.064363]\n",
      "epoch:37 step:28937 [D loss: 0.901953, acc: 53.12%] [G loss: 5.666374]\n",
      "epoch:37 step:28938 [D loss: 0.048890, acc: 100.00%] [G loss: 5.174300]\n",
      "epoch:37 step:28939 [D loss: 0.145529, acc: 99.22%] [G loss: 5.023519]\n",
      "epoch:37 step:28940 [D loss: 0.182924, acc: 99.22%] [G loss: 3.365949]\n",
      "epoch:37 step:28941 [D loss: 0.557171, acc: 69.53%] [G loss: 3.376581]\n",
      "epoch:37 step:28942 [D loss: 0.540982, acc: 60.16%] [G loss: 4.573808]\n",
      "epoch:37 step:28943 [D loss: 0.346662, acc: 79.69%] [G loss: 5.066196]\n",
      "epoch:37 step:28944 [D loss: 1.710376, acc: 25.78%] [G loss: 8.435029]\n",
      "epoch:37 step:28945 [D loss: 0.440874, acc: 78.12%] [G loss: 4.371260]\n",
      "epoch:37 step:28946 [D loss: 0.184398, acc: 95.31%] [G loss: 1.878440]\n",
      "epoch:37 step:28947 [D loss: 0.778464, acc: 51.56%] [G loss: 5.861003]\n",
      "epoch:37 step:28948 [D loss: 0.238724, acc: 95.31%] [G loss: 3.523919]\n",
      "epoch:37 step:28949 [D loss: 0.040290, acc: 100.00%] [G loss: 4.948305]\n",
      "epoch:37 step:28950 [D loss: 0.296353, acc: 95.31%] [G loss: 4.875182]\n",
      "epoch:37 step:28951 [D loss: 0.112931, acc: 100.00%] [G loss: 7.734474]\n",
      "epoch:37 step:28952 [D loss: 0.235426, acc: 99.22%] [G loss: 6.144739]\n",
      "epoch:37 step:28953 [D loss: 0.067496, acc: 100.00%] [G loss: 8.929973]\n",
      "epoch:37 step:28954 [D loss: 0.527955, acc: 74.22%] [G loss: 5.610650]\n",
      "epoch:37 step:28955 [D loss: 0.359030, acc: 82.03%] [G loss: 4.446615]\n",
      "epoch:37 step:28956 [D loss: 0.093841, acc: 99.22%] [G loss: 5.592634]\n",
      "epoch:37 step:28957 [D loss: 1.639587, acc: 50.00%] [G loss: 3.508476]\n",
      "epoch:37 step:28958 [D loss: 0.147012, acc: 99.22%] [G loss: 5.542375]\n",
      "epoch:37 step:28959 [D loss: 0.101928, acc: 100.00%] [G loss: 9.460178]\n",
      "epoch:37 step:28960 [D loss: 0.866009, acc: 28.91%] [G loss: 3.223429]\n",
      "epoch:37 step:28961 [D loss: 0.286039, acc: 96.09%] [G loss: 3.700606]\n",
      "epoch:37 step:28962 [D loss: 0.666418, acc: 57.81%] [G loss: 3.362532]\n",
      "epoch:37 step:28963 [D loss: 0.509364, acc: 66.41%] [G loss: 3.811340]\n",
      "epoch:37 step:28964 [D loss: 0.322523, acc: 82.81%] [G loss: 2.094866]\n",
      "epoch:37 step:28965 [D loss: 0.256822, acc: 93.75%] [G loss: 2.221501]\n",
      "epoch:37 step:28966 [D loss: 0.824870, acc: 42.19%] [G loss: 7.454386]\n",
      "epoch:37 step:28967 [D loss: 0.193269, acc: 95.31%] [G loss: 6.688696]\n",
      "epoch:37 step:28968 [D loss: 0.084695, acc: 100.00%] [G loss: 5.839667]\n",
      "epoch:37 step:28969 [D loss: 0.184494, acc: 96.09%] [G loss: 5.021611]\n",
      "epoch:37 step:28970 [D loss: 0.605086, acc: 60.16%] [G loss: 2.477530]\n",
      "epoch:37 step:28971 [D loss: 0.117652, acc: 100.00%] [G loss: 8.125945]\n",
      "epoch:37 step:28972 [D loss: 0.505116, acc: 81.25%] [G loss: 3.683026]\n",
      "epoch:37 step:28973 [D loss: 0.256401, acc: 94.53%] [G loss: 6.098010]\n",
      "epoch:37 step:28974 [D loss: 0.445559, acc: 79.69%] [G loss: 5.246331]\n",
      "epoch:37 step:28975 [D loss: 0.281780, acc: 93.75%] [G loss: 4.176754]\n",
      "epoch:37 step:28976 [D loss: 0.073483, acc: 100.00%] [G loss: 5.251986]\n",
      "epoch:37 step:28977 [D loss: 0.497377, acc: 78.91%] [G loss: 3.694679]\n",
      "epoch:37 step:28978 [D loss: 1.786375, acc: 49.22%] [G loss: 2.030329]\n",
      "epoch:37 step:28979 [D loss: 0.083628, acc: 100.00%] [G loss: 4.057591]\n",
      "epoch:37 step:28980 [D loss: 0.111716, acc: 100.00%] [G loss: 4.613315]\n",
      "epoch:37 step:28981 [D loss: 0.534721, acc: 75.78%] [G loss: 6.314857]\n",
      "epoch:37 step:28982 [D loss: 0.122396, acc: 99.22%] [G loss: 5.213113]\n",
      "epoch:37 step:28983 [D loss: 0.309137, acc: 89.06%] [G loss: 2.980907]\n",
      "epoch:37 step:28984 [D loss: 0.730366, acc: 57.81%] [G loss: 5.516776]\n",
      "epoch:37 step:28985 [D loss: 0.416444, acc: 87.50%] [G loss: 4.800899]\n",
      "epoch:37 step:28986 [D loss: 0.379215, acc: 86.72%] [G loss: 4.147892]\n",
      "epoch:37 step:28987 [D loss: 0.267004, acc: 96.09%] [G loss: 4.459280]\n",
      "epoch:37 step:28988 [D loss: 0.033139, acc: 100.00%] [G loss: 5.246770]\n",
      "epoch:37 step:28989 [D loss: 0.170014, acc: 98.44%] [G loss: 4.687282]\n",
      "epoch:37 step:28990 [D loss: 0.600039, acc: 67.19%] [G loss: 3.927564]\n",
      "epoch:37 step:28991 [D loss: 0.183467, acc: 97.66%] [G loss: 4.938204]\n",
      "epoch:37 step:28992 [D loss: 0.351548, acc: 81.25%] [G loss: 5.247004]\n",
      "epoch:37 step:28993 [D loss: 1.061996, acc: 22.66%] [G loss: 7.105739]\n",
      "epoch:37 step:28994 [D loss: 0.804892, acc: 51.56%] [G loss: 1.979213]\n",
      "epoch:37 step:28995 [D loss: 0.095985, acc: 99.22%] [G loss: 5.144373]\n",
      "epoch:37 step:28996 [D loss: 0.091143, acc: 100.00%] [G loss: 6.223823]\n",
      "epoch:37 step:28997 [D loss: 0.405413, acc: 72.66%] [G loss: 2.750889]\n",
      "epoch:37 step:28998 [D loss: 0.225599, acc: 96.88%] [G loss: 4.085278]\n",
      "epoch:37 step:28999 [D loss: 1.336578, acc: 50.00%] [G loss: 4.932405]\n",
      "epoch:37 step:29000 [D loss: 0.279722, acc: 96.09%] [G loss: 3.442286]\n",
      "epoch:37 step:29001 [D loss: 0.100609, acc: 100.00%] [G loss: 5.555367]\n",
      "epoch:37 step:29002 [D loss: 0.138164, acc: 97.66%] [G loss: 7.544694]\n",
      "epoch:37 step:29003 [D loss: 0.495209, acc: 74.22%] [G loss: 4.293096]\n",
      "epoch:37 step:29004 [D loss: 0.271781, acc: 90.62%] [G loss: 3.921634]\n",
      "epoch:37 step:29005 [D loss: 0.210580, acc: 98.44%] [G loss: 4.625136]\n",
      "epoch:37 step:29006 [D loss: 0.182883, acc: 99.22%] [G loss: 2.387984]\n",
      "epoch:37 step:29007 [D loss: 0.390770, acc: 75.00%] [G loss: 4.872028]\n",
      "epoch:37 step:29008 [D loss: 1.456416, acc: 39.06%] [G loss: 6.014701]\n",
      "epoch:37 step:29009 [D loss: 0.336591, acc: 81.25%] [G loss: 3.774653]\n",
      "epoch:37 step:29010 [D loss: 0.200654, acc: 99.22%] [G loss: 4.348619]\n",
      "epoch:37 step:29011 [D loss: 0.251571, acc: 89.84%] [G loss: 6.664907]\n",
      "epoch:37 step:29012 [D loss: 0.770685, acc: 47.66%] [G loss: 7.218148]\n",
      "epoch:37 step:29013 [D loss: 0.600938, acc: 67.97%] [G loss: 2.030448]\n",
      "epoch:37 step:29014 [D loss: 0.270582, acc: 89.06%] [G loss: 4.207119]\n",
      "epoch:37 step:29015 [D loss: 0.230095, acc: 96.88%] [G loss: 4.010763]\n",
      "epoch:37 step:29016 [D loss: 0.265517, acc: 89.06%] [G loss: 4.012715]\n",
      "epoch:37 step:29017 [D loss: 0.120281, acc: 98.44%] [G loss: 4.490313]\n",
      "epoch:37 step:29018 [D loss: 0.604325, acc: 57.81%] [G loss: 4.976937]\n",
      "epoch:37 step:29019 [D loss: 0.150666, acc: 100.00%] [G loss: 5.603725]\n",
      "epoch:37 step:29020 [D loss: 0.392487, acc: 88.28%] [G loss: 1.954378]\n",
      "epoch:37 step:29021 [D loss: 0.541597, acc: 61.72%] [G loss: 3.334417]\n",
      "epoch:37 step:29022 [D loss: 1.303732, acc: 50.00%] [G loss: 4.662132]\n",
      "epoch:37 step:29023 [D loss: 0.129996, acc: 99.22%] [G loss: 4.347954]\n",
      "epoch:37 step:29024 [D loss: 0.259010, acc: 89.06%] [G loss: 3.202093]\n",
      "epoch:37 step:29025 [D loss: 0.154328, acc: 99.22%] [G loss: 4.610020]\n",
      "epoch:37 step:29026 [D loss: 0.448843, acc: 82.81%] [G loss: 2.314643]\n",
      "epoch:37 step:29027 [D loss: 0.630456, acc: 64.06%] [G loss: 4.566777]\n",
      "epoch:37 step:29028 [D loss: 0.376852, acc: 81.25%] [G loss: 4.549534]\n",
      "epoch:37 step:29029 [D loss: 0.088046, acc: 99.22%] [G loss: 5.538263]\n",
      "epoch:37 step:29030 [D loss: 0.209299, acc: 93.75%] [G loss: 7.696118]\n",
      "epoch:37 step:29031 [D loss: 1.220101, acc: 43.75%] [G loss: 5.126844]\n",
      "epoch:37 step:29032 [D loss: 0.132829, acc: 99.22%] [G loss: 2.620003]\n",
      "epoch:37 step:29033 [D loss: 0.029611, acc: 100.00%] [G loss: 6.231524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29034 [D loss: 1.414231, acc: 7.81%] [G loss: 7.260687]\n",
      "epoch:37 step:29035 [D loss: 0.122580, acc: 100.00%] [G loss: 5.143550]\n",
      "epoch:37 step:29036 [D loss: 0.446224, acc: 83.59%] [G loss: 4.382027]\n",
      "epoch:37 step:29037 [D loss: 0.612170, acc: 57.81%] [G loss: 3.270778]\n",
      "epoch:37 step:29038 [D loss: 0.594723, acc: 60.16%] [G loss: 4.148608]\n",
      "epoch:37 step:29039 [D loss: 0.739547, acc: 52.34%] [G loss: 6.135176]\n",
      "epoch:37 step:29040 [D loss: 0.182337, acc: 96.88%] [G loss: 7.244514]\n",
      "epoch:37 step:29041 [D loss: 0.474626, acc: 64.06%] [G loss: 4.083706]\n",
      "epoch:37 step:29042 [D loss: 0.428967, acc: 82.81%] [G loss: 3.823153]\n",
      "epoch:37 step:29043 [D loss: 0.331180, acc: 88.28%] [G loss: 3.943529]\n",
      "epoch:37 step:29044 [D loss: 0.402825, acc: 89.06%] [G loss: 5.523746]\n",
      "epoch:37 step:29045 [D loss: 0.495400, acc: 74.22%] [G loss: 3.546905]\n",
      "epoch:37 step:29046 [D loss: 0.321754, acc: 87.50%] [G loss: 4.960693]\n",
      "epoch:37 step:29047 [D loss: 0.395101, acc: 85.16%] [G loss: 2.958537]\n",
      "epoch:37 step:29048 [D loss: 0.169806, acc: 98.44%] [G loss: 6.581802]\n",
      "epoch:37 step:29049 [D loss: 0.100876, acc: 100.00%] [G loss: 3.879785]\n",
      "epoch:37 step:29050 [D loss: 0.265437, acc: 93.75%] [G loss: 4.340061]\n",
      "epoch:37 step:29051 [D loss: 0.136874, acc: 98.44%] [G loss: 4.235740]\n",
      "epoch:37 step:29052 [D loss: 0.258370, acc: 94.53%] [G loss: 3.777616]\n",
      "epoch:37 step:29053 [D loss: 0.126625, acc: 100.00%] [G loss: 1.415220]\n",
      "epoch:37 step:29054 [D loss: 0.523296, acc: 79.69%] [G loss: 2.851344]\n",
      "epoch:37 step:29055 [D loss: 0.110142, acc: 99.22%] [G loss: 6.760054]\n",
      "epoch:37 step:29056 [D loss: 0.297647, acc: 88.28%] [G loss: 5.109154]\n",
      "epoch:37 step:29057 [D loss: 0.251624, acc: 94.53%] [G loss: 3.446970]\n",
      "epoch:37 step:29058 [D loss: 0.481728, acc: 79.69%] [G loss: 7.277634]\n",
      "epoch:37 step:29059 [D loss: 0.093741, acc: 99.22%] [G loss: 5.353298]\n",
      "epoch:37 step:29060 [D loss: 0.147498, acc: 98.44%] [G loss: 5.106335]\n",
      "epoch:37 step:29061 [D loss: 0.178581, acc: 98.44%] [G loss: 5.295241]\n",
      "epoch:37 step:29062 [D loss: 0.551794, acc: 58.59%] [G loss: 5.182043]\n",
      "epoch:37 step:29063 [D loss: 1.368503, acc: 50.00%] [G loss: 3.727420]\n",
      "epoch:37 step:29064 [D loss: 0.158148, acc: 96.88%] [G loss: 4.640575]\n",
      "epoch:37 step:29065 [D loss: 0.224994, acc: 98.44%] [G loss: 6.062769]\n",
      "epoch:37 step:29066 [D loss: 0.676993, acc: 53.91%] [G loss: 5.797555]\n",
      "epoch:37 step:29067 [D loss: 0.251239, acc: 91.41%] [G loss: 3.795361]\n",
      "epoch:37 step:29068 [D loss: 0.185850, acc: 98.44%] [G loss: 5.171329]\n",
      "epoch:37 step:29069 [D loss: 0.401888, acc: 89.06%] [G loss: 3.386734]\n",
      "epoch:37 step:29070 [D loss: 0.176066, acc: 96.88%] [G loss: 3.148713]\n",
      "epoch:37 step:29071 [D loss: 0.076681, acc: 100.00%] [G loss: 5.652167]\n",
      "epoch:37 step:29072 [D loss: 0.052067, acc: 100.00%] [G loss: 7.245028]\n",
      "epoch:37 step:29073 [D loss: 0.157033, acc: 99.22%] [G loss: 6.196534]\n",
      "epoch:37 step:29074 [D loss: 0.351517, acc: 89.06%] [G loss: 3.673533]\n",
      "epoch:37 step:29075 [D loss: 0.596144, acc: 60.94%] [G loss: 2.805083]\n",
      "epoch:37 step:29076 [D loss: 0.357591, acc: 91.41%] [G loss: 4.370437]\n",
      "epoch:37 step:29077 [D loss: 0.298017, acc: 85.94%] [G loss: 4.437190]\n",
      "epoch:37 step:29078 [D loss: 0.785325, acc: 48.44%] [G loss: 4.276515]\n",
      "epoch:37 step:29079 [D loss: 0.659303, acc: 60.94%] [G loss: 4.336212]\n",
      "epoch:37 step:29080 [D loss: 1.017016, acc: 39.84%] [G loss: 6.415931]\n",
      "epoch:37 step:29081 [D loss: 0.632792, acc: 70.31%] [G loss: 5.036841]\n",
      "epoch:37 step:29082 [D loss: 0.086851, acc: 100.00%] [G loss: 4.038802]\n",
      "epoch:37 step:29083 [D loss: 0.437425, acc: 73.44%] [G loss: 7.015242]\n",
      "epoch:37 step:29084 [D loss: 0.109110, acc: 100.00%] [G loss: 4.981102]\n",
      "epoch:37 step:29085 [D loss: 0.151935, acc: 99.22%] [G loss: 2.001422]\n",
      "epoch:37 step:29086 [D loss: 0.125325, acc: 99.22%] [G loss: 4.222084]\n",
      "epoch:37 step:29087 [D loss: 0.440696, acc: 76.56%] [G loss: 2.658599]\n",
      "epoch:37 step:29088 [D loss: 0.093570, acc: 100.00%] [G loss: 3.396012]\n",
      "epoch:37 step:29089 [D loss: 0.075392, acc: 100.00%] [G loss: 5.356813]\n",
      "epoch:37 step:29090 [D loss: 0.419426, acc: 79.69%] [G loss: 1.683560]\n",
      "epoch:37 step:29091 [D loss: 0.114394, acc: 99.22%] [G loss: 4.626131]\n",
      "epoch:37 step:29092 [D loss: 0.186118, acc: 97.66%] [G loss: 2.543381]\n",
      "epoch:37 step:29093 [D loss: 0.283749, acc: 96.09%] [G loss: 5.282978]\n",
      "epoch:37 step:29094 [D loss: 0.255742, acc: 92.97%] [G loss: 5.640834]\n",
      "epoch:37 step:29095 [D loss: 0.048084, acc: 100.00%] [G loss: 3.430662]\n",
      "epoch:37 step:29096 [D loss: 0.261829, acc: 91.41%] [G loss: 5.432286]\n",
      "epoch:37 step:29097 [D loss: 1.262218, acc: 32.03%] [G loss: 4.984392]\n",
      "epoch:37 step:29098 [D loss: 0.222735, acc: 92.19%] [G loss: 4.099652]\n",
      "epoch:37 step:29099 [D loss: 0.472922, acc: 75.78%] [G loss: 4.758386]\n",
      "epoch:37 step:29100 [D loss: 0.300449, acc: 94.53%] [G loss: 6.334626]\n",
      "epoch:37 step:29101 [D loss: 0.083771, acc: 100.00%] [G loss: 3.628066]\n",
      "epoch:37 step:29102 [D loss: 0.242019, acc: 96.09%] [G loss: 2.407438]\n",
      "epoch:37 step:29103 [D loss: 0.126778, acc: 100.00%] [G loss: 3.057306]\n",
      "epoch:37 step:29104 [D loss: 0.211394, acc: 97.66%] [G loss: 6.158678]\n",
      "epoch:37 step:29105 [D loss: 0.435102, acc: 68.75%] [G loss: 3.845801]\n",
      "epoch:37 step:29106 [D loss: 0.103706, acc: 99.22%] [G loss: 4.974287]\n",
      "epoch:37 step:29107 [D loss: 0.203664, acc: 100.00%] [G loss: 4.305581]\n",
      "epoch:37 step:29108 [D loss: 1.602518, acc: 6.25%] [G loss: 4.979888]\n",
      "epoch:37 step:29109 [D loss: 0.380961, acc: 78.12%] [G loss: 5.704878]\n",
      "epoch:37 step:29110 [D loss: 1.471183, acc: 22.66%] [G loss: 4.390576]\n",
      "epoch:37 step:29111 [D loss: 0.518177, acc: 72.66%] [G loss: 3.855472]\n",
      "epoch:37 step:29112 [D loss: 0.739613, acc: 51.56%] [G loss: 4.853579]\n",
      "epoch:37 step:29113 [D loss: 0.418893, acc: 86.72%] [G loss: 2.160575]\n",
      "epoch:37 step:29114 [D loss: 0.976622, acc: 50.00%] [G loss: 6.851021]\n",
      "epoch:37 step:29115 [D loss: 0.248828, acc: 96.09%] [G loss: 4.004823]\n",
      "epoch:37 step:29116 [D loss: 0.313930, acc: 89.06%] [G loss: 3.728364]\n",
      "epoch:37 step:29117 [D loss: 0.647943, acc: 61.72%] [G loss: 5.726692]\n",
      "epoch:37 step:29118 [D loss: 1.114653, acc: 22.66%] [G loss: 5.341294]\n",
      "epoch:37 step:29119 [D loss: 0.654943, acc: 54.69%] [G loss: 5.229541]\n",
      "epoch:37 step:29120 [D loss: 0.846174, acc: 39.06%] [G loss: 7.048646]\n",
      "epoch:37 step:29121 [D loss: 0.186183, acc: 96.88%] [G loss: 7.020370]\n",
      "epoch:37 step:29122 [D loss: 0.033707, acc: 100.00%] [G loss: 6.122743]\n",
      "epoch:37 step:29123 [D loss: 0.681749, acc: 57.81%] [G loss: 4.528046]\n",
      "epoch:37 step:29124 [D loss: 0.297684, acc: 81.25%] [G loss: 3.602595]\n",
      "epoch:37 step:29125 [D loss: 0.116100, acc: 99.22%] [G loss: 6.070401]\n",
      "epoch:37 step:29126 [D loss: 0.343219, acc: 84.38%] [G loss: 7.065367]\n",
      "epoch:37 step:29127 [D loss: 0.259984, acc: 94.53%] [G loss: 1.870415]\n",
      "epoch:37 step:29128 [D loss: 0.105519, acc: 98.44%] [G loss: 7.756341]\n",
      "epoch:37 step:29129 [D loss: 0.187887, acc: 99.22%] [G loss: 4.592694]\n",
      "epoch:37 step:29130 [D loss: 0.438629, acc: 77.34%] [G loss: 3.063897]\n",
      "epoch:37 step:29131 [D loss: 0.925388, acc: 39.84%] [G loss: 3.671347]\n",
      "epoch:37 step:29132 [D loss: 1.643286, acc: 26.56%] [G loss: 5.764853]\n",
      "epoch:37 step:29133 [D loss: 0.214847, acc: 99.22%] [G loss: 5.100186]\n",
      "epoch:37 step:29134 [D loss: 0.046596, acc: 100.00%] [G loss: 5.166856]\n",
      "epoch:37 step:29135 [D loss: 0.609752, acc: 67.19%] [G loss: 4.831754]\n",
      "epoch:37 step:29136 [D loss: 1.101875, acc: 42.97%] [G loss: 2.017863]\n",
      "epoch:37 step:29137 [D loss: 0.260993, acc: 89.84%] [G loss: 3.634654]\n",
      "epoch:37 step:29138 [D loss: 0.116108, acc: 98.44%] [G loss: 5.456934]\n",
      "epoch:37 step:29139 [D loss: 0.058104, acc: 100.00%] [G loss: 4.794086]\n",
      "epoch:37 step:29140 [D loss: 0.044356, acc: 100.00%] [G loss: 5.039582]\n",
      "epoch:37 step:29141 [D loss: 0.431168, acc: 84.38%] [G loss: 4.541211]\n",
      "epoch:37 step:29142 [D loss: 0.303968, acc: 88.28%] [G loss: 4.962035]\n",
      "epoch:37 step:29143 [D loss: 0.667460, acc: 61.72%] [G loss: 4.284259]\n",
      "epoch:37 step:29144 [D loss: 0.187553, acc: 96.09%] [G loss: 3.680542]\n",
      "epoch:37 step:29145 [D loss: 0.181992, acc: 96.09%] [G loss: 2.825912]\n",
      "epoch:37 step:29146 [D loss: 0.157138, acc: 100.00%] [G loss: 4.760622]\n",
      "epoch:37 step:29147 [D loss: 0.080450, acc: 99.22%] [G loss: 5.757493]\n",
      "epoch:37 step:29148 [D loss: 0.057364, acc: 100.00%] [G loss: 4.147929]\n",
      "epoch:37 step:29149 [D loss: 0.954380, acc: 50.78%] [G loss: 5.837358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29150 [D loss: 1.322556, acc: 47.66%] [G loss: 3.956537]\n",
      "epoch:37 step:29151 [D loss: 0.713064, acc: 53.91%] [G loss: 3.335253]\n",
      "epoch:37 step:29152 [D loss: 0.793462, acc: 53.91%] [G loss: 8.952302]\n",
      "epoch:37 step:29153 [D loss: 0.155920, acc: 99.22%] [G loss: 3.844756]\n",
      "epoch:37 step:29154 [D loss: 0.429423, acc: 85.16%] [G loss: 4.195002]\n",
      "epoch:37 step:29155 [D loss: 0.305528, acc: 97.66%] [G loss: 2.243929]\n",
      "epoch:37 step:29156 [D loss: 0.247762, acc: 97.66%] [G loss: 4.295681]\n",
      "epoch:37 step:29157 [D loss: 0.259120, acc: 97.66%] [G loss: 4.298918]\n",
      "epoch:37 step:29158 [D loss: 0.176648, acc: 98.44%] [G loss: 3.629093]\n",
      "epoch:37 step:29159 [D loss: 0.379660, acc: 82.81%] [G loss: 4.210823]\n",
      "epoch:37 step:29160 [D loss: 0.651373, acc: 52.34%] [G loss: 3.840049]\n",
      "epoch:37 step:29161 [D loss: 0.340103, acc: 89.84%] [G loss: 6.205483]\n",
      "epoch:37 step:29162 [D loss: 0.041765, acc: 100.00%] [G loss: 4.129001]\n",
      "epoch:37 step:29163 [D loss: 0.166306, acc: 98.44%] [G loss: 1.884676]\n",
      "epoch:37 step:29164 [D loss: 1.193744, acc: 45.31%] [G loss: 4.814656]\n",
      "epoch:37 step:29165 [D loss: 0.248928, acc: 96.88%] [G loss: 2.408659]\n",
      "epoch:37 step:29166 [D loss: 0.498532, acc: 64.06%] [G loss: 5.864493]\n",
      "epoch:37 step:29167 [D loss: 0.192623, acc: 98.44%] [G loss: 3.925522]\n",
      "epoch:37 step:29168 [D loss: 0.556288, acc: 68.75%] [G loss: 3.777451]\n",
      "epoch:37 step:29169 [D loss: 0.705399, acc: 53.91%] [G loss: 7.194515]\n",
      "epoch:37 step:29170 [D loss: 0.718433, acc: 57.81%] [G loss: 2.338932]\n",
      "epoch:37 step:29171 [D loss: 0.013308, acc: 100.00%] [G loss: 9.443943]\n",
      "epoch:37 step:29172 [D loss: 0.147551, acc: 100.00%] [G loss: 4.065960]\n",
      "epoch:37 step:29173 [D loss: 0.834791, acc: 51.56%] [G loss: 3.487441]\n",
      "epoch:37 step:29174 [D loss: 0.300113, acc: 89.84%] [G loss: 3.606681]\n",
      "epoch:37 step:29175 [D loss: 0.337762, acc: 80.47%] [G loss: 5.072050]\n",
      "epoch:37 step:29176 [D loss: 0.189409, acc: 97.66%] [G loss: 4.983522]\n",
      "epoch:37 step:29177 [D loss: 0.358373, acc: 87.50%] [G loss: 4.174394]\n",
      "epoch:37 step:29178 [D loss: 0.516456, acc: 62.50%] [G loss: 4.334248]\n",
      "epoch:37 step:29179 [D loss: 0.400918, acc: 92.19%] [G loss: 3.551242]\n",
      "epoch:37 step:29180 [D loss: 0.557417, acc: 59.38%] [G loss: 6.148149]\n",
      "epoch:37 step:29181 [D loss: 0.055977, acc: 100.00%] [G loss: 4.737166]\n",
      "epoch:37 step:29182 [D loss: 0.571739, acc: 59.38%] [G loss: 4.437368]\n",
      "epoch:37 step:29183 [D loss: 0.054214, acc: 100.00%] [G loss: 3.244294]\n",
      "epoch:37 step:29184 [D loss: 0.099834, acc: 100.00%] [G loss: 3.263682]\n",
      "epoch:37 step:29185 [D loss: 0.593833, acc: 65.62%] [G loss: 5.711543]\n",
      "epoch:37 step:29186 [D loss: 0.878421, acc: 44.53%] [G loss: 4.845286]\n",
      "epoch:37 step:29187 [D loss: 0.051689, acc: 100.00%] [G loss: 3.511688]\n",
      "epoch:37 step:29188 [D loss: 0.371565, acc: 91.41%] [G loss: 5.762695]\n",
      "epoch:37 step:29189 [D loss: 0.047651, acc: 100.00%] [G loss: 2.934000]\n",
      "epoch:37 step:29190 [D loss: 0.653218, acc: 63.28%] [G loss: 3.015910]\n",
      "epoch:37 step:29191 [D loss: 0.381246, acc: 88.28%] [G loss: 3.285918]\n",
      "epoch:37 step:29192 [D loss: 0.425562, acc: 89.84%] [G loss: 2.831760]\n",
      "epoch:37 step:29193 [D loss: 0.183858, acc: 96.88%] [G loss: 3.981985]\n",
      "epoch:37 step:29194 [D loss: 0.227126, acc: 98.44%] [G loss: 7.495835]\n",
      "epoch:37 step:29195 [D loss: 1.121676, acc: 43.75%] [G loss: 4.347824]\n",
      "epoch:37 step:29196 [D loss: 0.306104, acc: 92.19%] [G loss: 5.410418]\n",
      "epoch:37 step:29197 [D loss: 0.320980, acc: 84.38%] [G loss: 6.528949]\n",
      "epoch:37 step:29198 [D loss: 0.765068, acc: 51.56%] [G loss: 2.039134]\n",
      "epoch:37 step:29199 [D loss: 0.284095, acc: 89.06%] [G loss: 2.603638]\n",
      "epoch:37 step:29200 [D loss: 0.479234, acc: 85.16%] [G loss: 3.100437]\n",
      "epoch:37 step:29201 [D loss: 0.216451, acc: 96.09%] [G loss: 3.484919]\n",
      "epoch:37 step:29202 [D loss: 0.601375, acc: 60.94%] [G loss: 4.032763]\n",
      "epoch:37 step:29203 [D loss: 0.057386, acc: 100.00%] [G loss: 6.872772]\n",
      "epoch:37 step:29204 [D loss: 0.560735, acc: 73.44%] [G loss: 4.459764]\n",
      "epoch:37 step:29205 [D loss: 0.272956, acc: 91.41%] [G loss: 5.039942]\n",
      "epoch:37 step:29206 [D loss: 0.098293, acc: 100.00%] [G loss: 4.124342]\n",
      "epoch:37 step:29207 [D loss: 0.280237, acc: 90.62%] [G loss: 6.521158]\n",
      "epoch:37 step:29208 [D loss: 0.557466, acc: 73.44%] [G loss: 4.300100]\n",
      "epoch:37 step:29209 [D loss: 0.480416, acc: 80.47%] [G loss: 5.613743]\n",
      "epoch:37 step:29210 [D loss: 0.087448, acc: 100.00%] [G loss: 5.471197]\n",
      "epoch:37 step:29211 [D loss: 0.396247, acc: 85.16%] [G loss: 4.932752]\n",
      "epoch:37 step:29212 [D loss: 0.541101, acc: 76.56%] [G loss: 4.963964]\n",
      "epoch:37 step:29213 [D loss: 0.487637, acc: 78.12%] [G loss: 4.989334]\n",
      "epoch:37 step:29214 [D loss: 0.250438, acc: 89.84%] [G loss: 7.783300]\n",
      "epoch:37 step:29215 [D loss: 0.434318, acc: 81.25%] [G loss: 3.887925]\n",
      "epoch:37 step:29216 [D loss: 0.297479, acc: 84.38%] [G loss: 3.566866]\n",
      "epoch:37 step:29217 [D loss: 0.314644, acc: 94.53%] [G loss: 3.988079]\n",
      "epoch:37 step:29218 [D loss: 0.265908, acc: 98.44%] [G loss: 3.919465]\n",
      "epoch:37 step:29219 [D loss: 0.299206, acc: 89.06%] [G loss: 6.724751]\n",
      "epoch:37 step:29220 [D loss: 1.063315, acc: 21.88%] [G loss: 6.652371]\n",
      "epoch:37 step:29221 [D loss: 0.624406, acc: 57.81%] [G loss: 2.187188]\n",
      "epoch:37 step:29222 [D loss: 0.103414, acc: 100.00%] [G loss: 3.619454]\n",
      "epoch:37 step:29223 [D loss: 0.997589, acc: 50.78%] [G loss: 4.418251]\n",
      "epoch:37 step:29224 [D loss: 0.110421, acc: 100.00%] [G loss: 5.297139]\n",
      "epoch:37 step:29225 [D loss: 0.226278, acc: 94.53%] [G loss: 3.395159]\n",
      "epoch:37 step:29226 [D loss: 0.095911, acc: 99.22%] [G loss: 5.858497]\n",
      "epoch:37 step:29227 [D loss: 0.595452, acc: 61.72%] [G loss: 4.231325]\n",
      "epoch:37 step:29228 [D loss: 0.704894, acc: 60.16%] [G loss: 5.302828]\n",
      "epoch:37 step:29229 [D loss: 0.460501, acc: 71.88%] [G loss: 5.044441]\n",
      "epoch:37 step:29230 [D loss: 0.123892, acc: 100.00%] [G loss: 7.245074]\n",
      "epoch:37 step:29231 [D loss: 0.057196, acc: 100.00%] [G loss: 4.481345]\n",
      "epoch:37 step:29232 [D loss: 0.047328, acc: 100.00%] [G loss: 3.377758]\n",
      "epoch:37 step:29233 [D loss: 0.255262, acc: 96.09%] [G loss: 5.996553]\n",
      "epoch:37 step:29234 [D loss: 0.314863, acc: 89.06%] [G loss: 4.899036]\n",
      "epoch:37 step:29235 [D loss: 0.081994, acc: 99.22%] [G loss: 5.392579]\n",
      "epoch:37 step:29236 [D loss: 0.372014, acc: 80.47%] [G loss: 5.574520]\n",
      "epoch:37 step:29237 [D loss: 0.433336, acc: 84.38%] [G loss: 5.433103]\n",
      "epoch:37 step:29238 [D loss: 0.412055, acc: 72.66%] [G loss: 3.922203]\n",
      "epoch:37 step:29239 [D loss: 0.269319, acc: 91.41%] [G loss: 3.233645]\n",
      "epoch:37 step:29240 [D loss: 0.406613, acc: 87.50%] [G loss: 4.668491]\n",
      "epoch:37 step:29241 [D loss: 0.374903, acc: 74.22%] [G loss: 6.023073]\n",
      "epoch:37 step:29242 [D loss: 0.421776, acc: 74.22%] [G loss: 5.360116]\n",
      "epoch:37 step:29243 [D loss: 0.339932, acc: 90.62%] [G loss: 5.436522]\n",
      "epoch:37 step:29244 [D loss: 0.421991, acc: 75.78%] [G loss: 7.727460]\n",
      "epoch:37 step:29245 [D loss: 0.617503, acc: 65.62%] [G loss: 4.791096]\n",
      "epoch:37 step:29246 [D loss: 0.202132, acc: 99.22%] [G loss: 2.900882]\n",
      "epoch:37 step:29247 [D loss: 0.688192, acc: 60.16%] [G loss: 4.105800]\n",
      "epoch:37 step:29248 [D loss: 0.111730, acc: 99.22%] [G loss: 4.359905]\n",
      "epoch:37 step:29249 [D loss: 0.266479, acc: 89.84%] [G loss: 2.802181]\n",
      "epoch:37 step:29250 [D loss: 0.292344, acc: 85.16%] [G loss: 6.271214]\n",
      "epoch:37 step:29251 [D loss: 0.450965, acc: 86.72%] [G loss: 4.004666]\n",
      "epoch:37 step:29252 [D loss: 0.450341, acc: 80.47%] [G loss: 3.723935]\n",
      "epoch:37 step:29253 [D loss: 0.151460, acc: 97.66%] [G loss: 7.334086]\n",
      "epoch:37 step:29254 [D loss: 0.238638, acc: 92.97%] [G loss: 5.205554]\n",
      "epoch:37 step:29255 [D loss: 0.079198, acc: 100.00%] [G loss: 6.433165]\n",
      "epoch:37 step:29256 [D loss: 0.398361, acc: 87.50%] [G loss: 8.404837]\n",
      "epoch:37 step:29257 [D loss: 0.278285, acc: 88.28%] [G loss: 1.986311]\n",
      "epoch:37 step:29258 [D loss: 0.132125, acc: 99.22%] [G loss: 7.023705]\n",
      "epoch:37 step:29259 [D loss: 0.421757, acc: 72.66%] [G loss: 5.100308]\n",
      "epoch:37 step:29260 [D loss: 0.233554, acc: 92.97%] [G loss: 5.029695]\n",
      "epoch:37 step:29261 [D loss: 0.143505, acc: 99.22%] [G loss: 4.334389]\n",
      "epoch:37 step:29262 [D loss: 0.102536, acc: 100.00%] [G loss: 4.225230]\n",
      "epoch:37 step:29263 [D loss: 0.243304, acc: 92.97%] [G loss: 6.321383]\n",
      "epoch:37 step:29264 [D loss: 0.107135, acc: 100.00%] [G loss: 5.942778]\n",
      "epoch:37 step:29265 [D loss: 0.349672, acc: 87.50%] [G loss: 5.103952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29266 [D loss: 0.377122, acc: 83.59%] [G loss: 4.939255]\n",
      "epoch:37 step:29267 [D loss: 0.877647, acc: 46.88%] [G loss: 4.464655]\n",
      "epoch:37 step:29268 [D loss: 0.981551, acc: 42.19%] [G loss: 4.898801]\n",
      "epoch:37 step:29269 [D loss: 0.819605, acc: 53.12%] [G loss: 5.446537]\n",
      "epoch:37 step:29270 [D loss: 0.188007, acc: 96.09%] [G loss: 3.534075]\n",
      "epoch:37 step:29271 [D loss: 0.064888, acc: 100.00%] [G loss: 4.835954]\n",
      "epoch:37 step:29272 [D loss: 0.095525, acc: 99.22%] [G loss: 4.562740]\n",
      "epoch:37 step:29273 [D loss: 0.300960, acc: 89.06%] [G loss: 3.682091]\n",
      "epoch:37 step:29274 [D loss: 0.527410, acc: 78.12%] [G loss: 5.061334]\n",
      "epoch:37 step:29275 [D loss: 0.157229, acc: 100.00%] [G loss: 3.323319]\n",
      "epoch:37 step:29276 [D loss: 0.317509, acc: 91.41%] [G loss: 4.933443]\n",
      "epoch:37 step:29277 [D loss: 0.606575, acc: 57.81%] [G loss: 6.173665]\n",
      "epoch:37 step:29278 [D loss: 0.055012, acc: 100.00%] [G loss: 4.259394]\n",
      "epoch:37 step:29279 [D loss: 0.117574, acc: 100.00%] [G loss: 2.733453]\n",
      "epoch:37 step:29280 [D loss: 0.685350, acc: 54.69%] [G loss: 4.172683]\n",
      "epoch:37 step:29281 [D loss: 0.801193, acc: 46.88%] [G loss: 4.757486]\n",
      "epoch:37 step:29282 [D loss: 0.757277, acc: 55.47%] [G loss: 7.308693]\n",
      "epoch:37 step:29283 [D loss: 0.121192, acc: 100.00%] [G loss: 5.823308]\n",
      "epoch:37 step:29284 [D loss: 0.515225, acc: 67.19%] [G loss: 5.285301]\n",
      "epoch:37 step:29285 [D loss: 0.101665, acc: 100.00%] [G loss: 4.912255]\n",
      "epoch:37 step:29286 [D loss: 1.078018, acc: 35.94%] [G loss: 3.683259]\n",
      "epoch:37 step:29287 [D loss: 0.944836, acc: 32.81%] [G loss: 5.606600]\n",
      "epoch:37 step:29288 [D loss: 0.251268, acc: 92.19%] [G loss: 6.456370]\n",
      "epoch:37 step:29289 [D loss: 0.122516, acc: 98.44%] [G loss: 6.249496]\n",
      "epoch:37 step:29290 [D loss: 0.473454, acc: 72.66%] [G loss: 6.861618]\n",
      "epoch:37 step:29291 [D loss: 0.154338, acc: 99.22%] [G loss: 6.295217]\n",
      "epoch:37 step:29292 [D loss: 0.444176, acc: 84.38%] [G loss: 4.636059]\n",
      "epoch:37 step:29293 [D loss: 0.482632, acc: 77.34%] [G loss: 2.843835]\n",
      "epoch:37 step:29294 [D loss: 1.515897, acc: 27.34%] [G loss: 6.032999]\n",
      "epoch:37 step:29295 [D loss: 0.204416, acc: 97.66%] [G loss: 3.329972]\n",
      "epoch:37 step:29296 [D loss: 0.179540, acc: 97.66%] [G loss: 4.963558]\n",
      "epoch:37 step:29297 [D loss: 0.089391, acc: 100.00%] [G loss: 3.126668]\n",
      "epoch:37 step:29298 [D loss: 0.088151, acc: 100.00%] [G loss: 6.348211]\n",
      "epoch:37 step:29299 [D loss: 0.051905, acc: 100.00%] [G loss: 4.617363]\n",
      "epoch:37 step:29300 [D loss: 0.174268, acc: 99.22%] [G loss: 4.718829]\n",
      "epoch:37 step:29301 [D loss: 0.034132, acc: 100.00%] [G loss: 7.114630]\n",
      "epoch:37 step:29302 [D loss: 1.588926, acc: 5.47%] [G loss: 4.660665]\n",
      "epoch:37 step:29303 [D loss: 0.125868, acc: 97.66%] [G loss: 6.196936]\n",
      "epoch:37 step:29304 [D loss: 0.209437, acc: 92.97%] [G loss: 6.067625]\n",
      "epoch:37 step:29305 [D loss: 0.362696, acc: 89.84%] [G loss: 4.726895]\n",
      "epoch:37 step:29306 [D loss: 0.120414, acc: 98.44%] [G loss: 6.043676]\n",
      "epoch:37 step:29307 [D loss: 0.309205, acc: 89.06%] [G loss: 6.678528]\n",
      "epoch:37 step:29308 [D loss: 0.672678, acc: 60.16%] [G loss: 3.406598]\n",
      "epoch:37 step:29309 [D loss: 0.233578, acc: 95.31%] [G loss: 4.376336]\n",
      "epoch:37 step:29310 [D loss: 0.270147, acc: 87.50%] [G loss: 3.035227]\n",
      "epoch:37 step:29311 [D loss: 0.642982, acc: 64.84%] [G loss: 7.742337]\n",
      "epoch:37 step:29312 [D loss: 0.156154, acc: 99.22%] [G loss: 4.811851]\n",
      "epoch:37 step:29313 [D loss: 0.345301, acc: 91.41%] [G loss: 3.284475]\n",
      "epoch:37 step:29314 [D loss: 0.213487, acc: 97.66%] [G loss: 3.932478]\n",
      "epoch:37 step:29315 [D loss: 0.033612, acc: 100.00%] [G loss: 4.318665]\n",
      "epoch:37 step:29316 [D loss: 0.175958, acc: 97.66%] [G loss: 4.763360]\n",
      "epoch:37 step:29317 [D loss: 0.206442, acc: 96.88%] [G loss: 3.444084]\n",
      "epoch:37 step:29318 [D loss: 0.103172, acc: 99.22%] [G loss: 7.825441]\n",
      "epoch:37 step:29319 [D loss: 0.051488, acc: 100.00%] [G loss: 6.975067]\n",
      "epoch:37 step:29320 [D loss: 0.507826, acc: 67.19%] [G loss: 4.720050]\n",
      "epoch:37 step:29321 [D loss: 0.709839, acc: 56.25%] [G loss: 5.206279]\n",
      "epoch:37 step:29322 [D loss: 0.323384, acc: 83.59%] [G loss: 3.119294]\n",
      "epoch:37 step:29323 [D loss: 0.197896, acc: 98.44%] [G loss: 4.923990]\n",
      "epoch:37 step:29324 [D loss: 0.154052, acc: 100.00%] [G loss: 2.979121]\n",
      "epoch:37 step:29325 [D loss: 0.031082, acc: 100.00%] [G loss: 6.269787]\n",
      "epoch:37 step:29326 [D loss: 0.157270, acc: 98.44%] [G loss: 6.178157]\n",
      "epoch:37 step:29327 [D loss: 0.104899, acc: 98.44%] [G loss: 4.716167]\n",
      "epoch:37 step:29328 [D loss: 0.492281, acc: 67.19%] [G loss: 5.269026]\n",
      "epoch:37 step:29329 [D loss: 0.051785, acc: 100.00%] [G loss: 4.328140]\n",
      "epoch:37 step:29330 [D loss: 0.699486, acc: 57.03%] [G loss: 3.420176]\n",
      "epoch:37 step:29331 [D loss: 0.926823, acc: 53.12%] [G loss: 5.078010]\n",
      "epoch:37 step:29332 [D loss: 0.690208, acc: 52.34%] [G loss: 5.244626]\n",
      "epoch:37 step:29333 [D loss: 0.289839, acc: 94.53%] [G loss: 4.096747]\n",
      "epoch:37 step:29334 [D loss: 0.454191, acc: 87.50%] [G loss: 3.741813]\n",
      "epoch:37 step:29335 [D loss: 0.093991, acc: 100.00%] [G loss: 4.415051]\n",
      "epoch:37 step:29336 [D loss: 0.207042, acc: 96.88%] [G loss: 2.548035]\n",
      "epoch:37 step:29337 [D loss: 0.179515, acc: 97.66%] [G loss: 4.640838]\n",
      "epoch:37 step:29338 [D loss: 0.302434, acc: 94.53%] [G loss: 4.504804]\n",
      "epoch:37 step:29339 [D loss: 1.257238, acc: 50.00%] [G loss: 3.602691]\n",
      "epoch:37 step:29340 [D loss: 0.604272, acc: 58.59%] [G loss: 3.736100]\n",
      "epoch:37 step:29341 [D loss: 0.289954, acc: 90.62%] [G loss: 5.232920]\n",
      "epoch:37 step:29342 [D loss: 0.626509, acc: 57.81%] [G loss: 4.192865]\n",
      "epoch:37 step:29343 [D loss: 0.072639, acc: 100.00%] [G loss: 5.187880]\n",
      "epoch:37 step:29344 [D loss: 0.045221, acc: 100.00%] [G loss: 4.834683]\n",
      "epoch:37 step:29345 [D loss: 0.530992, acc: 74.22%] [G loss: 4.455982]\n",
      "epoch:37 step:29346 [D loss: 0.055764, acc: 100.00%] [G loss: 3.811186]\n",
      "epoch:37 step:29347 [D loss: 0.200017, acc: 98.44%] [G loss: 2.193497]\n",
      "epoch:37 step:29348 [D loss: 0.515050, acc: 79.69%] [G loss: 4.901131]\n",
      "epoch:37 step:29349 [D loss: 0.170318, acc: 98.44%] [G loss: 4.508159]\n",
      "epoch:37 step:29350 [D loss: 0.210516, acc: 98.44%] [G loss: 5.893203]\n",
      "epoch:37 step:29351 [D loss: 0.281039, acc: 95.31%] [G loss: 3.763587]\n",
      "epoch:37 step:29352 [D loss: 0.249033, acc: 95.31%] [G loss: 6.021621]\n",
      "epoch:37 step:29353 [D loss: 0.061845, acc: 100.00%] [G loss: 5.030062]\n",
      "epoch:37 step:29354 [D loss: 0.385482, acc: 82.03%] [G loss: 7.394836]\n",
      "epoch:37 step:29355 [D loss: 0.105845, acc: 100.00%] [G loss: 5.435839]\n",
      "epoch:37 step:29356 [D loss: 0.090228, acc: 100.00%] [G loss: 5.589574]\n",
      "epoch:37 step:29357 [D loss: 0.330806, acc: 85.16%] [G loss: 6.534736]\n",
      "epoch:37 step:29358 [D loss: 0.006511, acc: 100.00%] [G loss: 6.727712]\n",
      "epoch:37 step:29359 [D loss: 0.246922, acc: 96.88%] [G loss: 5.874516]\n",
      "epoch:37 step:29360 [D loss: 0.134839, acc: 100.00%] [G loss: 3.779307]\n",
      "epoch:37 step:29361 [D loss: 0.130178, acc: 99.22%] [G loss: 4.843548]\n",
      "epoch:37 step:29362 [D loss: 0.182540, acc: 99.22%] [G loss: 4.587138]\n",
      "epoch:37 step:29363 [D loss: 0.215903, acc: 98.44%] [G loss: 4.865986]\n",
      "epoch:37 step:29364 [D loss: 0.540725, acc: 74.22%] [G loss: 4.474449]\n",
      "epoch:37 step:29365 [D loss: 0.269920, acc: 97.66%] [G loss: 4.505142]\n",
      "epoch:37 step:29366 [D loss: 0.127992, acc: 100.00%] [G loss: 5.337882]\n",
      "epoch:37 step:29367 [D loss: 0.395551, acc: 91.41%] [G loss: 5.929968]\n",
      "epoch:37 step:29368 [D loss: 1.308586, acc: 47.66%] [G loss: 7.143635]\n",
      "epoch:37 step:29369 [D loss: 0.393951, acc: 71.09%] [G loss: 4.293651]\n",
      "epoch:37 step:29370 [D loss: 0.742195, acc: 54.69%] [G loss: 2.520701]\n",
      "epoch:37 step:29371 [D loss: 0.889643, acc: 51.56%] [G loss: 4.104478]\n",
      "epoch:37 step:29372 [D loss: 0.643570, acc: 60.16%] [G loss: 4.733953]\n",
      "epoch:37 step:29373 [D loss: 0.277266, acc: 95.31%] [G loss: 2.737320]\n",
      "epoch:37 step:29374 [D loss: 0.332335, acc: 88.28%] [G loss: 3.791818]\n",
      "epoch:37 step:29375 [D loss: 0.142841, acc: 100.00%] [G loss: 7.273843]\n",
      "epoch:37 step:29376 [D loss: 0.553671, acc: 70.31%] [G loss: 4.752512]\n",
      "epoch:37 step:29377 [D loss: 0.461151, acc: 71.88%] [G loss: 5.817849]\n",
      "epoch:37 step:29378 [D loss: 0.319959, acc: 94.53%] [G loss: 3.617175]\n",
      "epoch:37 step:29379 [D loss: 0.933267, acc: 50.78%] [G loss: 4.681007]\n",
      "epoch:37 step:29380 [D loss: 0.477593, acc: 66.41%] [G loss: 5.412519]\n",
      "epoch:37 step:29381 [D loss: 0.763521, acc: 55.47%] [G loss: 5.690470]\n",
      "epoch:37 step:29382 [D loss: 0.107710, acc: 99.22%] [G loss: 4.554471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29383 [D loss: 0.745876, acc: 54.69%] [G loss: 3.543347]\n",
      "epoch:37 step:29384 [D loss: 0.529892, acc: 67.19%] [G loss: 5.377689]\n",
      "epoch:37 step:29385 [D loss: 0.144145, acc: 96.88%] [G loss: 4.355987]\n",
      "epoch:37 step:29386 [D loss: 0.364741, acc: 85.16%] [G loss: 3.093059]\n",
      "epoch:37 step:29387 [D loss: 0.042226, acc: 100.00%] [G loss: 6.489151]\n",
      "epoch:37 step:29388 [D loss: 0.696752, acc: 57.03%] [G loss: 3.904479]\n",
      "epoch:37 step:29389 [D loss: 0.273879, acc: 89.84%] [G loss: 4.505240]\n",
      "epoch:37 step:29390 [D loss: 0.217456, acc: 92.97%] [G loss: 4.558729]\n",
      "epoch:37 step:29391 [D loss: 0.552653, acc: 64.06%] [G loss: 6.946822]\n",
      "epoch:37 step:29392 [D loss: 0.124482, acc: 99.22%] [G loss: 5.506599]\n",
      "epoch:37 step:29393 [D loss: 0.319810, acc: 82.03%] [G loss: 3.542231]\n",
      "epoch:37 step:29394 [D loss: 0.578573, acc: 57.81%] [G loss: 6.484738]\n",
      "epoch:37 step:29395 [D loss: 0.022566, acc: 100.00%] [G loss: 6.472814]\n",
      "epoch:37 step:29396 [D loss: 0.074221, acc: 100.00%] [G loss: 6.100240]\n",
      "epoch:37 step:29397 [D loss: 0.283356, acc: 90.62%] [G loss: 6.898638]\n",
      "epoch:37 step:29398 [D loss: 0.252197, acc: 96.09%] [G loss: 3.913187]\n",
      "epoch:37 step:29399 [D loss: 0.183412, acc: 96.88%] [G loss: 3.365548]\n",
      "epoch:37 step:29400 [D loss: 0.094098, acc: 100.00%] [G loss: 2.486224]\n",
      "epoch:37 step:29401 [D loss: 0.856468, acc: 49.22%] [G loss: 4.568953]\n",
      "epoch:37 step:29402 [D loss: 0.300923, acc: 87.50%] [G loss: 5.200144]\n",
      "epoch:37 step:29403 [D loss: 0.220274, acc: 96.88%] [G loss: 5.205000]\n",
      "epoch:37 step:29404 [D loss: 0.992395, acc: 50.00%] [G loss: 2.697166]\n",
      "epoch:37 step:29405 [D loss: 0.125939, acc: 98.44%] [G loss: 2.788852]\n",
      "epoch:37 step:29406 [D loss: 0.438062, acc: 84.38%] [G loss: 3.098440]\n",
      "epoch:37 step:29407 [D loss: 0.251518, acc: 96.88%] [G loss: 3.445462]\n",
      "epoch:37 step:29408 [D loss: 0.047298, acc: 100.00%] [G loss: 8.688124]\n",
      "epoch:37 step:29409 [D loss: 0.226192, acc: 94.53%] [G loss: 5.681269]\n",
      "epoch:37 step:29410 [D loss: 0.961834, acc: 35.94%] [G loss: 6.963133]\n",
      "epoch:37 step:29411 [D loss: 0.481716, acc: 80.47%] [G loss: 3.806211]\n",
      "epoch:37 step:29412 [D loss: 0.049821, acc: 100.00%] [G loss: 7.201031]\n",
      "epoch:37 step:29413 [D loss: 0.220354, acc: 99.22%] [G loss: 5.010720]\n",
      "epoch:37 step:29414 [D loss: 0.108831, acc: 99.22%] [G loss: 5.906204]\n",
      "epoch:37 step:29415 [D loss: 0.110177, acc: 99.22%] [G loss: 3.795912]\n",
      "epoch:37 step:29416 [D loss: 0.070543, acc: 100.00%] [G loss: 7.905819]\n",
      "epoch:37 step:29417 [D loss: 0.653617, acc: 55.47%] [G loss: 5.580276]\n",
      "epoch:37 step:29418 [D loss: 0.228481, acc: 90.62%] [G loss: 5.921600]\n",
      "epoch:37 step:29419 [D loss: 0.247805, acc: 97.66%] [G loss: 3.407914]\n",
      "epoch:37 step:29420 [D loss: 0.512215, acc: 78.91%] [G loss: 1.558104]\n",
      "epoch:37 step:29421 [D loss: 0.108026, acc: 99.22%] [G loss: 5.022222]\n",
      "epoch:37 step:29422 [D loss: 0.276760, acc: 96.88%] [G loss: 4.156998]\n",
      "epoch:37 step:29423 [D loss: 0.265390, acc: 92.97%] [G loss: 4.813549]\n",
      "epoch:37 step:29424 [D loss: 0.328657, acc: 92.97%] [G loss: 2.673059]\n",
      "epoch:37 step:29425 [D loss: 0.145005, acc: 99.22%] [G loss: 6.488703]\n",
      "epoch:37 step:29426 [D loss: 0.149076, acc: 99.22%] [G loss: 4.995231]\n",
      "epoch:37 step:29427 [D loss: 0.277270, acc: 89.84%] [G loss: 8.743360]\n",
      "epoch:37 step:29428 [D loss: 0.856959, acc: 39.84%] [G loss: 4.926918]\n",
      "epoch:37 step:29429 [D loss: 0.654822, acc: 57.81%] [G loss: 5.017219]\n",
      "epoch:37 step:29430 [D loss: 0.302075, acc: 90.62%] [G loss: 1.139714]\n",
      "epoch:37 step:29431 [D loss: 0.505756, acc: 68.75%] [G loss: 7.912954]\n",
      "epoch:37 step:29432 [D loss: 1.218288, acc: 35.94%] [G loss: 6.985463]\n",
      "epoch:37 step:29433 [D loss: 0.246215, acc: 96.09%] [G loss: 4.712041]\n",
      "epoch:37 step:29434 [D loss: 0.052659, acc: 100.00%] [G loss: 6.592868]\n",
      "epoch:37 step:29435 [D loss: 0.142673, acc: 99.22%] [G loss: 3.965443]\n",
      "epoch:37 step:29436 [D loss: 0.806092, acc: 52.34%] [G loss: 6.395861]\n",
      "epoch:37 step:29437 [D loss: 0.129506, acc: 99.22%] [G loss: 4.677623]\n",
      "epoch:37 step:29438 [D loss: 0.476600, acc: 71.09%] [G loss: 8.733629]\n",
      "epoch:37 step:29439 [D loss: 0.029420, acc: 100.00%] [G loss: 6.497961]\n",
      "epoch:37 step:29440 [D loss: 0.391721, acc: 85.94%] [G loss: 2.283625]\n",
      "epoch:37 step:29441 [D loss: 0.195659, acc: 99.22%] [G loss: 5.566506]\n",
      "epoch:37 step:29442 [D loss: 0.183076, acc: 97.66%] [G loss: 3.607946]\n",
      "epoch:37 step:29443 [D loss: 0.962037, acc: 49.22%] [G loss: 2.789280]\n",
      "epoch:37 step:29444 [D loss: 0.131743, acc: 100.00%] [G loss: 3.190942]\n",
      "epoch:37 step:29445 [D loss: 0.140210, acc: 97.66%] [G loss: 4.290282]\n",
      "epoch:37 step:29446 [D loss: 0.186747, acc: 94.53%] [G loss: 5.554976]\n",
      "epoch:37 step:29447 [D loss: 1.003250, acc: 39.06%] [G loss: 3.841742]\n",
      "epoch:37 step:29448 [D loss: 1.634682, acc: 50.00%] [G loss: 3.973088]\n",
      "epoch:37 step:29449 [D loss: 0.413402, acc: 82.03%] [G loss: 4.060829]\n",
      "epoch:37 step:29450 [D loss: 1.236084, acc: 50.00%] [G loss: 6.078981]\n",
      "epoch:37 step:29451 [D loss: 0.135298, acc: 98.44%] [G loss: 4.091214]\n",
      "epoch:37 step:29452 [D loss: 0.212748, acc: 94.53%] [G loss: 5.132462]\n",
      "epoch:37 step:29453 [D loss: 0.068836, acc: 100.00%] [G loss: 4.477777]\n",
      "epoch:37 step:29454 [D loss: 0.168241, acc: 98.44%] [G loss: 4.768655]\n",
      "epoch:37 step:29455 [D loss: 0.617230, acc: 56.25%] [G loss: 5.596229]\n",
      "epoch:37 step:29456 [D loss: 0.107605, acc: 99.22%] [G loss: 4.035732]\n",
      "epoch:37 step:29457 [D loss: 0.104566, acc: 100.00%] [G loss: 5.523308]\n",
      "epoch:37 step:29458 [D loss: 0.873403, acc: 34.38%] [G loss: 5.789125]\n",
      "epoch:37 step:29459 [D loss: 0.690644, acc: 55.47%] [G loss: 3.681184]\n",
      "epoch:37 step:29460 [D loss: 0.080053, acc: 100.00%] [G loss: 6.672263]\n",
      "epoch:37 step:29461 [D loss: 0.227542, acc: 95.31%] [G loss: 3.752872]\n",
      "epoch:37 step:29462 [D loss: 0.190567, acc: 97.66%] [G loss: 3.646482]\n",
      "epoch:37 step:29463 [D loss: 0.033398, acc: 100.00%] [G loss: 4.191201]\n",
      "epoch:37 step:29464 [D loss: 0.853290, acc: 50.78%] [G loss: 4.452456]\n",
      "epoch:37 step:29465 [D loss: 0.600669, acc: 61.72%] [G loss: 4.882189]\n",
      "epoch:37 step:29466 [D loss: 0.452171, acc: 69.53%] [G loss: 6.668009]\n",
      "epoch:37 step:29467 [D loss: 0.057504, acc: 100.00%] [G loss: 6.635342]\n",
      "epoch:37 step:29468 [D loss: 0.436398, acc: 72.66%] [G loss: 5.518577]\n",
      "epoch:37 step:29469 [D loss: 0.762809, acc: 52.34%] [G loss: 5.162549]\n",
      "epoch:37 step:29470 [D loss: 0.265438, acc: 89.06%] [G loss: 5.130404]\n",
      "epoch:37 step:29471 [D loss: 0.300851, acc: 96.88%] [G loss: 4.154411]\n",
      "epoch:37 step:29472 [D loss: 0.151391, acc: 97.66%] [G loss: 4.266937]\n",
      "epoch:37 step:29473 [D loss: 0.332710, acc: 86.72%] [G loss: 4.177236]\n",
      "epoch:37 step:29474 [D loss: 0.065538, acc: 100.00%] [G loss: 6.087451]\n",
      "epoch:37 step:29475 [D loss: 0.204117, acc: 96.09%] [G loss: 7.908619]\n",
      "epoch:37 step:29476 [D loss: 0.798957, acc: 44.53%] [G loss: 5.189991]\n",
      "epoch:37 step:29477 [D loss: 0.263372, acc: 89.06%] [G loss: 3.134563]\n",
      "epoch:37 step:29478 [D loss: 0.168527, acc: 94.53%] [G loss: 6.459146]\n",
      "epoch:37 step:29479 [D loss: 0.051919, acc: 100.00%] [G loss: 5.703012]\n",
      "epoch:37 step:29480 [D loss: 0.215264, acc: 100.00%] [G loss: 2.923538]\n",
      "epoch:37 step:29481 [D loss: 0.491826, acc: 67.19%] [G loss: 7.449091]\n",
      "epoch:37 step:29482 [D loss: 0.238703, acc: 96.88%] [G loss: 5.876045]\n",
      "epoch:37 step:29483 [D loss: 0.569753, acc: 60.16%] [G loss: 4.905518]\n",
      "epoch:37 step:29484 [D loss: 0.107904, acc: 98.44%] [G loss: 5.579220]\n",
      "epoch:37 step:29485 [D loss: 0.501238, acc: 83.59%] [G loss: 5.677616]\n",
      "epoch:37 step:29486 [D loss: 0.789190, acc: 49.22%] [G loss: 7.210299]\n",
      "epoch:37 step:29487 [D loss: 0.071971, acc: 100.00%] [G loss: 4.719896]\n",
      "epoch:37 step:29488 [D loss: 0.444399, acc: 64.84%] [G loss: 5.868943]\n",
      "epoch:37 step:29489 [D loss: 0.212363, acc: 98.44%] [G loss: 4.649631]\n",
      "epoch:37 step:29490 [D loss: 0.217804, acc: 99.22%] [G loss: 6.788643]\n",
      "epoch:37 step:29491 [D loss: 0.367787, acc: 87.50%] [G loss: 3.443411]\n",
      "epoch:37 step:29492 [D loss: 0.642931, acc: 63.28%] [G loss: 3.003543]\n",
      "epoch:37 step:29493 [D loss: 0.213100, acc: 95.31%] [G loss: 7.019412]\n",
      "epoch:37 step:29494 [D loss: 0.540628, acc: 71.88%] [G loss: 6.441619]\n",
      "epoch:37 step:29495 [D loss: 0.397984, acc: 76.56%] [G loss: 4.121853]\n",
      "epoch:37 step:29496 [D loss: 0.302031, acc: 90.62%] [G loss: 4.232612]\n",
      "epoch:37 step:29497 [D loss: 0.299246, acc: 92.97%] [G loss: 3.305257]\n",
      "epoch:37 step:29498 [D loss: 0.245009, acc: 96.09%] [G loss: 4.609176]\n",
      "epoch:37 step:29499 [D loss: 0.118456, acc: 98.44%] [G loss: 4.344543]\n",
      "epoch:37 step:29500 [D loss: 1.217098, acc: 47.66%] [G loss: 4.002985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29501 [D loss: 0.323659, acc: 89.84%] [G loss: 5.341549]\n",
      "epoch:37 step:29502 [D loss: 0.301888, acc: 86.72%] [G loss: 4.798589]\n",
      "epoch:37 step:29503 [D loss: 0.047681, acc: 100.00%] [G loss: 6.528050]\n",
      "epoch:37 step:29504 [D loss: 0.531203, acc: 80.47%] [G loss: 5.519727]\n",
      "epoch:37 step:29505 [D loss: 0.225882, acc: 95.31%] [G loss: 4.639122]\n",
      "epoch:37 step:29506 [D loss: 0.242460, acc: 88.28%] [G loss: 6.639727]\n",
      "epoch:37 step:29507 [D loss: 0.621936, acc: 57.03%] [G loss: 6.449583]\n",
      "epoch:37 step:29508 [D loss: 0.385160, acc: 89.06%] [G loss: 6.766155]\n",
      "epoch:37 step:29509 [D loss: 1.457360, acc: 50.78%] [G loss: 5.548707]\n",
      "epoch:37 step:29510 [D loss: 0.321639, acc: 89.84%] [G loss: 4.385246]\n",
      "epoch:37 step:29511 [D loss: 0.333200, acc: 79.69%] [G loss: 4.958539]\n",
      "epoch:37 step:29512 [D loss: 0.701893, acc: 60.16%] [G loss: 5.067752]\n",
      "epoch:37 step:29513 [D loss: 0.249580, acc: 92.19%] [G loss: 7.151100]\n",
      "epoch:37 step:29514 [D loss: 0.027902, acc: 100.00%] [G loss: 5.661160]\n",
      "epoch:37 step:29515 [D loss: 0.233240, acc: 92.97%] [G loss: 3.074247]\n",
      "epoch:37 step:29516 [D loss: 1.174720, acc: 49.22%] [G loss: 2.837493]\n",
      "epoch:37 step:29517 [D loss: 0.310840, acc: 93.75%] [G loss: 5.916873]\n",
      "epoch:37 step:29518 [D loss: 0.659453, acc: 59.38%] [G loss: 4.224252]\n",
      "epoch:37 step:29519 [D loss: 0.182938, acc: 96.88%] [G loss: 2.729393]\n",
      "epoch:37 step:29520 [D loss: 0.377403, acc: 83.59%] [G loss: 4.826510]\n",
      "epoch:37 step:29521 [D loss: 0.100568, acc: 98.44%] [G loss: 8.118708]\n",
      "epoch:37 step:29522 [D loss: 0.191403, acc: 97.66%] [G loss: 4.886147]\n",
      "epoch:37 step:29523 [D loss: 0.497885, acc: 76.56%] [G loss: 4.640740]\n",
      "epoch:37 step:29524 [D loss: 0.240542, acc: 96.09%] [G loss: 3.708045]\n",
      "epoch:37 step:29525 [D loss: 0.106343, acc: 100.00%] [G loss: 5.259206]\n",
      "epoch:37 step:29526 [D loss: 0.428795, acc: 75.00%] [G loss: 2.207690]\n",
      "epoch:37 step:29527 [D loss: 0.153838, acc: 100.00%] [G loss: 4.623607]\n",
      "epoch:37 step:29528 [D loss: 0.258167, acc: 92.97%] [G loss: 4.939266]\n",
      "epoch:37 step:29529 [D loss: 0.569657, acc: 66.41%] [G loss: 2.675669]\n",
      "epoch:37 step:29530 [D loss: 0.193259, acc: 96.88%] [G loss: 3.498066]\n",
      "epoch:37 step:29531 [D loss: 0.274617, acc: 94.53%] [G loss: 2.411340]\n",
      "epoch:37 step:29532 [D loss: 0.142808, acc: 99.22%] [G loss: 2.411801]\n",
      "epoch:37 step:29533 [D loss: 0.103022, acc: 100.00%] [G loss: 4.629140]\n",
      "epoch:37 step:29534 [D loss: 0.087237, acc: 100.00%] [G loss: 4.316539]\n",
      "epoch:37 step:29535 [D loss: 0.521160, acc: 75.00%] [G loss: 4.075664]\n",
      "epoch:37 step:29536 [D loss: 0.352276, acc: 82.03%] [G loss: 4.466120]\n",
      "epoch:37 step:29537 [D loss: 0.197325, acc: 96.88%] [G loss: 6.622970]\n",
      "epoch:37 step:29538 [D loss: 0.051116, acc: 100.00%] [G loss: 9.405735]\n",
      "epoch:37 step:29539 [D loss: 0.285113, acc: 86.72%] [G loss: 4.841562]\n",
      "epoch:37 step:29540 [D loss: 0.300387, acc: 96.88%] [G loss: 4.621130]\n",
      "epoch:37 step:29541 [D loss: 0.676065, acc: 53.91%] [G loss: 7.007936]\n",
      "epoch:37 step:29542 [D loss: 0.178949, acc: 98.44%] [G loss: 4.254986]\n",
      "epoch:37 step:29543 [D loss: 0.277433, acc: 96.88%] [G loss: 3.663781]\n",
      "epoch:37 step:29544 [D loss: 0.303516, acc: 92.19%] [G loss: 5.100043]\n",
      "epoch:37 step:29545 [D loss: 0.293098, acc: 94.53%] [G loss: 5.113776]\n",
      "epoch:37 step:29546 [D loss: 0.693262, acc: 57.81%] [G loss: 9.058821]\n",
      "epoch:37 step:29547 [D loss: 0.599759, acc: 60.94%] [G loss: 5.487839]\n",
      "epoch:37 step:29548 [D loss: 0.382408, acc: 77.34%] [G loss: 4.697652]\n",
      "epoch:37 step:29549 [D loss: 0.312646, acc: 87.50%] [G loss: 6.724720]\n",
      "epoch:37 step:29550 [D loss: 0.041929, acc: 100.00%] [G loss: 8.825403]\n",
      "epoch:37 step:29551 [D loss: 0.180658, acc: 99.22%] [G loss: 5.734038]\n",
      "epoch:37 step:29552 [D loss: 0.350751, acc: 87.50%] [G loss: 6.860979]\n",
      "epoch:37 step:29553 [D loss: 0.306076, acc: 92.19%] [G loss: 5.956182]\n",
      "epoch:37 step:29554 [D loss: 1.735035, acc: 25.00%] [G loss: 6.850679]\n",
      "epoch:37 step:29555 [D loss: 0.051714, acc: 100.00%] [G loss: 3.984349]\n",
      "epoch:37 step:29556 [D loss: 0.053885, acc: 100.00%] [G loss: 4.591284]\n",
      "epoch:37 step:29557 [D loss: 0.815162, acc: 53.12%] [G loss: 4.026829]\n",
      "epoch:37 step:29558 [D loss: 0.218390, acc: 94.53%] [G loss: 3.898431]\n",
      "epoch:37 step:29559 [D loss: 1.109293, acc: 50.00%] [G loss: 3.583189]\n",
      "epoch:37 step:29560 [D loss: 0.423073, acc: 72.66%] [G loss: 6.991047]\n",
      "epoch:37 step:29561 [D loss: 0.285145, acc: 90.62%] [G loss: 4.396570]\n",
      "epoch:37 step:29562 [D loss: 0.021227, acc: 100.00%] [G loss: 5.725619]\n",
      "epoch:37 step:29563 [D loss: 0.603230, acc: 65.62%] [G loss: 5.961072]\n",
      "epoch:37 step:29564 [D loss: 0.056682, acc: 100.00%] [G loss: 7.054942]\n",
      "epoch:37 step:29565 [D loss: 0.301680, acc: 96.09%] [G loss: 5.423841]\n",
      "epoch:37 step:29566 [D loss: 0.219879, acc: 93.75%] [G loss: 6.332366]\n",
      "epoch:37 step:29567 [D loss: 1.344357, acc: 9.38%] [G loss: 2.652963]\n",
      "epoch:37 step:29568 [D loss: 0.035116, acc: 100.00%] [G loss: 7.535785]\n",
      "epoch:37 step:29569 [D loss: 0.121638, acc: 100.00%] [G loss: 4.299527]\n",
      "epoch:37 step:29570 [D loss: 0.230402, acc: 95.31%] [G loss: 4.754813]\n",
      "epoch:37 step:29571 [D loss: 0.111887, acc: 100.00%] [G loss: 2.669057]\n",
      "epoch:37 step:29572 [D loss: 0.784129, acc: 50.00%] [G loss: 5.751831]\n",
      "epoch:37 step:29573 [D loss: 0.051990, acc: 100.00%] [G loss: 4.103456]\n",
      "epoch:37 step:29574 [D loss: 0.499738, acc: 75.78%] [G loss: 4.012605]\n",
      "epoch:37 step:29575 [D loss: 0.180458, acc: 98.44%] [G loss: 5.300166]\n",
      "epoch:37 step:29576 [D loss: 0.041116, acc: 100.00%] [G loss: 3.377452]\n",
      "epoch:37 step:29577 [D loss: 0.542192, acc: 73.44%] [G loss: 5.623284]\n",
      "epoch:37 step:29578 [D loss: 0.263496, acc: 92.19%] [G loss: 5.330438]\n",
      "epoch:37 step:29579 [D loss: 0.270384, acc: 96.09%] [G loss: 4.182616]\n",
      "epoch:37 step:29580 [D loss: 0.072962, acc: 100.00%] [G loss: 6.575817]\n",
      "epoch:37 step:29581 [D loss: 0.134784, acc: 97.66%] [G loss: 6.717350]\n",
      "epoch:37 step:29582 [D loss: 0.240706, acc: 96.09%] [G loss: 5.118878]\n",
      "epoch:37 step:29583 [D loss: 0.260684, acc: 95.31%] [G loss: 5.948094]\n",
      "epoch:37 step:29584 [D loss: 0.719208, acc: 57.03%] [G loss: 4.231560]\n",
      "epoch:37 step:29585 [D loss: 0.206776, acc: 96.09%] [G loss: 2.625940]\n",
      "epoch:37 step:29586 [D loss: 0.140407, acc: 99.22%] [G loss: 6.220824]\n",
      "epoch:37 step:29587 [D loss: 0.151600, acc: 97.66%] [G loss: 5.068792]\n",
      "epoch:37 step:29588 [D loss: 0.019766, acc: 100.00%] [G loss: 6.204619]\n",
      "epoch:37 step:29589 [D loss: 0.220971, acc: 97.66%] [G loss: 2.973247]\n",
      "epoch:37 step:29590 [D loss: 0.140975, acc: 99.22%] [G loss: 8.156895]\n",
      "epoch:37 step:29591 [D loss: 0.969969, acc: 53.12%] [G loss: 4.362499]\n",
      "epoch:37 step:29592 [D loss: 0.474448, acc: 66.41%] [G loss: 7.125912]\n",
      "epoch:37 step:29593 [D loss: 1.434156, acc: 9.38%] [G loss: 3.772982]\n",
      "epoch:37 step:29594 [D loss: 0.141246, acc: 99.22%] [G loss: 4.624613]\n",
      "epoch:37 step:29595 [D loss: 0.104165, acc: 100.00%] [G loss: 5.864544]\n",
      "epoch:37 step:29596 [D loss: 0.183905, acc: 96.88%] [G loss: 4.137309]\n",
      "epoch:37 step:29597 [D loss: 0.447038, acc: 79.69%] [G loss: 5.957536]\n",
      "epoch:37 step:29598 [D loss: 0.360077, acc: 88.28%] [G loss: 3.462833]\n",
      "epoch:37 step:29599 [D loss: 0.922266, acc: 32.03%] [G loss: 4.723791]\n",
      "epoch:37 step:29600 [D loss: 0.899176, acc: 49.22%] [G loss: 7.466563]\n",
      "epoch:37 step:29601 [D loss: 0.203958, acc: 96.88%] [G loss: 8.615780]\n",
      "epoch:37 step:29602 [D loss: 0.105853, acc: 99.22%] [G loss: 4.959161]\n",
      "epoch:37 step:29603 [D loss: 0.169749, acc: 96.09%] [G loss: 5.926708]\n",
      "epoch:37 step:29604 [D loss: 0.778253, acc: 51.56%] [G loss: 3.379875]\n",
      "epoch:37 step:29605 [D loss: 0.087770, acc: 100.00%] [G loss: 2.788776]\n",
      "epoch:37 step:29606 [D loss: 0.869808, acc: 50.78%] [G loss: 6.138713]\n",
      "epoch:37 step:29607 [D loss: 1.345475, acc: 50.00%] [G loss: 5.010198]\n",
      "epoch:37 step:29608 [D loss: 0.445581, acc: 67.97%] [G loss: 6.738173]\n",
      "epoch:37 step:29609 [D loss: 0.315551, acc: 90.62%] [G loss: 4.693321]\n",
      "epoch:37 step:29610 [D loss: 0.169065, acc: 97.66%] [G loss: 6.579746]\n",
      "epoch:37 step:29611 [D loss: 0.622452, acc: 66.41%] [G loss: 5.551097]\n",
      "epoch:37 step:29612 [D loss: 0.615016, acc: 55.47%] [G loss: 5.598452]\n",
      "epoch:37 step:29613 [D loss: 0.011870, acc: 100.00%] [G loss: 4.261596]\n",
      "epoch:37 step:29614 [D loss: 0.072133, acc: 99.22%] [G loss: 4.890038]\n",
      "epoch:37 step:29615 [D loss: 0.386985, acc: 92.97%] [G loss: 4.915815]\n",
      "epoch:37 step:29616 [D loss: 0.183762, acc: 98.44%] [G loss: 4.479321]\n",
      "epoch:37 step:29617 [D loss: 0.043066, acc: 100.00%] [G loss: 6.469573]\n",
      "epoch:37 step:29618 [D loss: 0.284336, acc: 96.88%] [G loss: 5.336930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29619 [D loss: 0.155241, acc: 98.44%] [G loss: 5.323019]\n",
      "epoch:37 step:29620 [D loss: 0.133453, acc: 100.00%] [G loss: 3.612515]\n",
      "epoch:37 step:29621 [D loss: 1.227037, acc: 12.50%] [G loss: 5.615685]\n",
      "epoch:37 step:29622 [D loss: 0.585676, acc: 64.06%] [G loss: 4.831033]\n",
      "epoch:37 step:29623 [D loss: 0.241409, acc: 91.41%] [G loss: 7.018882]\n",
      "epoch:37 step:29624 [D loss: 0.381693, acc: 89.84%] [G loss: 3.846899]\n",
      "epoch:37 step:29625 [D loss: 0.296070, acc: 85.16%] [G loss: 7.906935]\n",
      "epoch:37 step:29626 [D loss: 1.256378, acc: 17.19%] [G loss: 6.469994]\n",
      "epoch:37 step:29627 [D loss: 0.453803, acc: 72.66%] [G loss: 5.323754]\n",
      "epoch:37 step:29628 [D loss: 1.066188, acc: 25.78%] [G loss: 4.412664]\n",
      "epoch:37 step:29629 [D loss: 0.163344, acc: 97.66%] [G loss: 2.946212]\n",
      "epoch:37 step:29630 [D loss: 0.208034, acc: 93.75%] [G loss: 4.558812]\n",
      "epoch:37 step:29631 [D loss: 0.351699, acc: 87.50%] [G loss: 3.974812]\n",
      "epoch:37 step:29632 [D loss: 0.237395, acc: 96.09%] [G loss: 5.104545]\n",
      "epoch:37 step:29633 [D loss: 1.371941, acc: 32.03%] [G loss: 5.690623]\n",
      "epoch:37 step:29634 [D loss: 0.021898, acc: 100.00%] [G loss: 4.665851]\n",
      "epoch:37 step:29635 [D loss: 0.771015, acc: 56.25%] [G loss: 4.448553]\n",
      "epoch:37 step:29636 [D loss: 0.227413, acc: 95.31%] [G loss: 5.270646]\n",
      "epoch:37 step:29637 [D loss: 0.425421, acc: 82.81%] [G loss: 4.073809]\n",
      "epoch:37 step:29638 [D loss: 0.058161, acc: 100.00%] [G loss: 6.070532]\n",
      "epoch:37 step:29639 [D loss: 0.184190, acc: 99.22%] [G loss: 4.965090]\n",
      "epoch:37 step:29640 [D loss: 0.158105, acc: 99.22%] [G loss: 3.878290]\n",
      "epoch:37 step:29641 [D loss: 0.511230, acc: 77.34%] [G loss: 4.650002]\n",
      "epoch:37 step:29642 [D loss: 0.914949, acc: 51.56%] [G loss: 6.810205]\n",
      "epoch:37 step:29643 [D loss: 0.594425, acc: 60.16%] [G loss: 5.474273]\n",
      "epoch:37 step:29644 [D loss: 0.779842, acc: 51.56%] [G loss: 6.889260]\n",
      "epoch:37 step:29645 [D loss: 0.263901, acc: 87.50%] [G loss: 5.505754]\n",
      "epoch:37 step:29646 [D loss: 0.310412, acc: 87.50%] [G loss: 4.251796]\n",
      "epoch:37 step:29647 [D loss: 0.140432, acc: 100.00%] [G loss: 4.692430]\n",
      "epoch:37 step:29648 [D loss: 0.497460, acc: 67.19%] [G loss: 5.791769]\n",
      "epoch:37 step:29649 [D loss: 0.385243, acc: 78.91%] [G loss: 4.754594]\n",
      "epoch:37 step:29650 [D loss: 0.575359, acc: 60.16%] [G loss: 5.225558]\n",
      "epoch:37 step:29651 [D loss: 0.876508, acc: 50.78%] [G loss: 4.629583]\n",
      "epoch:37 step:29652 [D loss: 0.481394, acc: 82.03%] [G loss: 5.588477]\n",
      "epoch:37 step:29653 [D loss: 0.274529, acc: 89.06%] [G loss: 7.046115]\n",
      "epoch:37 step:29654 [D loss: 0.974906, acc: 50.78%] [G loss: 6.417627]\n",
      "epoch:37 step:29655 [D loss: 0.050170, acc: 100.00%] [G loss: 5.707134]\n",
      "epoch:37 step:29656 [D loss: 0.213509, acc: 93.75%] [G loss: 4.137186]\n",
      "epoch:37 step:29657 [D loss: 0.045147, acc: 100.00%] [G loss: 5.838087]\n",
      "epoch:37 step:29658 [D loss: 0.522581, acc: 77.34%] [G loss: 2.791825]\n",
      "epoch:37 step:29659 [D loss: 0.413042, acc: 82.03%] [G loss: 5.633149]\n",
      "epoch:37 step:29660 [D loss: 1.407026, acc: 50.00%] [G loss: 6.154119]\n",
      "epoch:37 step:29661 [D loss: 0.125219, acc: 100.00%] [G loss: 3.634865]\n",
      "epoch:37 step:29662 [D loss: 0.273706, acc: 89.06%] [G loss: 6.091995]\n",
      "epoch:37 step:29663 [D loss: 0.295626, acc: 95.31%] [G loss: 4.451105]\n",
      "epoch:37 step:29664 [D loss: 0.110003, acc: 100.00%] [G loss: 7.341242]\n",
      "epoch:37 step:29665 [D loss: 0.098865, acc: 100.00%] [G loss: 4.802143]\n",
      "epoch:37 step:29666 [D loss: 0.276877, acc: 95.31%] [G loss: 4.925350]\n",
      "epoch:37 step:29667 [D loss: 0.057542, acc: 100.00%] [G loss: 1.774110]\n",
      "epoch:37 step:29668 [D loss: 0.223866, acc: 91.41%] [G loss: 6.868027]\n",
      "epoch:37 step:29669 [D loss: 1.058052, acc: 50.78%] [G loss: 2.282902]\n",
      "epoch:37 step:29670 [D loss: 0.006816, acc: 100.00%] [G loss: 6.869652]\n",
      "epoch:37 step:29671 [D loss: 0.621045, acc: 57.81%] [G loss: 5.375884]\n",
      "epoch:37 step:29672 [D loss: 1.435074, acc: 7.03%] [G loss: 5.945267]\n",
      "epoch:37 step:29673 [D loss: 0.625992, acc: 60.16%] [G loss: 3.329205]\n",
      "epoch:37 step:29674 [D loss: 0.563487, acc: 60.94%] [G loss: 3.800088]\n",
      "epoch:37 step:29675 [D loss: 0.481732, acc: 76.56%] [G loss: 5.949503]\n",
      "epoch:37 step:29676 [D loss: 0.576951, acc: 60.16%] [G loss: 5.029826]\n",
      "epoch:37 step:29677 [D loss: 0.517331, acc: 66.41%] [G loss: 4.764021]\n",
      "epoch:37 step:29678 [D loss: 0.246652, acc: 92.97%] [G loss: 4.202803]\n",
      "epoch:38 step:29679 [D loss: 0.201418, acc: 96.88%] [G loss: 4.201283]\n",
      "epoch:38 step:29680 [D loss: 0.069101, acc: 100.00%] [G loss: 5.159949]\n",
      "epoch:38 step:29681 [D loss: 0.358493, acc: 83.59%] [G loss: 6.692228]\n",
      "epoch:38 step:29682 [D loss: 0.126757, acc: 99.22%] [G loss: 5.649791]\n",
      "epoch:38 step:29683 [D loss: 0.217505, acc: 92.97%] [G loss: 7.128727]\n",
      "epoch:38 step:29684 [D loss: 0.494192, acc: 77.34%] [G loss: 4.089186]\n",
      "epoch:38 step:29685 [D loss: 0.114829, acc: 100.00%] [G loss: 4.840508]\n",
      "epoch:38 step:29686 [D loss: 0.271023, acc: 98.44%] [G loss: 4.996181]\n",
      "epoch:38 step:29687 [D loss: 0.138057, acc: 99.22%] [G loss: 2.859231]\n",
      "epoch:38 step:29688 [D loss: 0.337624, acc: 83.59%] [G loss: 5.703209]\n",
      "epoch:38 step:29689 [D loss: 0.261374, acc: 88.28%] [G loss: 7.291417]\n",
      "epoch:38 step:29690 [D loss: 0.320889, acc: 93.75%] [G loss: 4.740622]\n",
      "epoch:38 step:29691 [D loss: 0.147639, acc: 97.66%] [G loss: 3.295390]\n",
      "epoch:38 step:29692 [D loss: 0.283365, acc: 91.41%] [G loss: 4.964990]\n",
      "epoch:38 step:29693 [D loss: 1.288098, acc: 50.00%] [G loss: 4.929694]\n",
      "epoch:38 step:29694 [D loss: 0.268944, acc: 96.09%] [G loss: 4.960378]\n",
      "epoch:38 step:29695 [D loss: 0.967476, acc: 51.56%] [G loss: 5.279865]\n",
      "epoch:38 step:29696 [D loss: 0.221726, acc: 96.88%] [G loss: 4.468965]\n",
      "epoch:38 step:29697 [D loss: 0.084206, acc: 100.00%] [G loss: 4.660184]\n",
      "epoch:38 step:29698 [D loss: 0.251302, acc: 91.41%] [G loss: 6.384808]\n",
      "epoch:38 step:29699 [D loss: 0.152925, acc: 99.22%] [G loss: 4.572453]\n",
      "epoch:38 step:29700 [D loss: 0.745875, acc: 54.69%] [G loss: 2.535234]\n",
      "epoch:38 step:29701 [D loss: 0.033396, acc: 100.00%] [G loss: 4.246473]\n",
      "epoch:38 step:29702 [D loss: 0.667541, acc: 56.25%] [G loss: 3.246769]\n",
      "epoch:38 step:29703 [D loss: 0.300189, acc: 95.31%] [G loss: 7.055548]\n",
      "epoch:38 step:29704 [D loss: 0.378424, acc: 89.06%] [G loss: 6.711641]\n",
      "epoch:38 step:29705 [D loss: 0.094766, acc: 100.00%] [G loss: 4.461711]\n",
      "epoch:38 step:29706 [D loss: 0.141082, acc: 100.00%] [G loss: 1.855639]\n",
      "epoch:38 step:29707 [D loss: 0.737779, acc: 52.34%] [G loss: 4.157280]\n",
      "epoch:38 step:29708 [D loss: 0.045291, acc: 100.00%] [G loss: 5.938297]\n",
      "epoch:38 step:29709 [D loss: 0.425796, acc: 67.97%] [G loss: 5.221992]\n",
      "epoch:38 step:29710 [D loss: 0.286341, acc: 96.88%] [G loss: 5.248967]\n",
      "epoch:38 step:29711 [D loss: 0.188226, acc: 100.00%] [G loss: 5.413104]\n",
      "epoch:38 step:29712 [D loss: 0.153351, acc: 100.00%] [G loss: 7.096938]\n",
      "epoch:38 step:29713 [D loss: 1.245802, acc: 32.81%] [G loss: 4.873734]\n",
      "epoch:38 step:29714 [D loss: 0.511824, acc: 63.28%] [G loss: 5.992444]\n",
      "epoch:38 step:29715 [D loss: 0.126320, acc: 99.22%] [G loss: 4.725087]\n",
      "epoch:38 step:29716 [D loss: 0.166285, acc: 98.44%] [G loss: 3.923957]\n",
      "epoch:38 step:29717 [D loss: 0.462702, acc: 68.75%] [G loss: 4.048287]\n",
      "epoch:38 step:29718 [D loss: 0.389445, acc: 79.69%] [G loss: 2.231260]\n",
      "epoch:38 step:29719 [D loss: 0.065627, acc: 100.00%] [G loss: 3.989790]\n",
      "epoch:38 step:29720 [D loss: 0.267196, acc: 96.09%] [G loss: 6.499485]\n",
      "epoch:38 step:29721 [D loss: 0.222486, acc: 97.66%] [G loss: 6.686850]\n",
      "epoch:38 step:29722 [D loss: 0.247710, acc: 96.88%] [G loss: 3.627577]\n",
      "epoch:38 step:29723 [D loss: 0.102252, acc: 100.00%] [G loss: 5.192344]\n",
      "epoch:38 step:29724 [D loss: 0.040262, acc: 100.00%] [G loss: 6.469665]\n",
      "epoch:38 step:29725 [D loss: 0.810078, acc: 46.88%] [G loss: 7.003412]\n",
      "epoch:38 step:29726 [D loss: 0.498390, acc: 78.12%] [G loss: 4.602249]\n",
      "epoch:38 step:29727 [D loss: 0.377696, acc: 78.91%] [G loss: 6.265672]\n",
      "epoch:38 step:29728 [D loss: 0.196861, acc: 97.66%] [G loss: 7.982571]\n",
      "epoch:38 step:29729 [D loss: 0.188733, acc: 96.88%] [G loss: 6.870582]\n",
      "epoch:38 step:29730 [D loss: 0.141465, acc: 97.66%] [G loss: 4.380611]\n",
      "epoch:38 step:29731 [D loss: 0.259692, acc: 94.53%] [G loss: 3.774803]\n",
      "epoch:38 step:29732 [D loss: 0.366244, acc: 89.84%] [G loss: 5.740891]\n",
      "epoch:38 step:29733 [D loss: 0.266450, acc: 90.62%] [G loss: 3.961762]\n",
      "epoch:38 step:29734 [D loss: 0.074362, acc: 100.00%] [G loss: 6.113015]\n",
      "epoch:38 step:29735 [D loss: 0.498140, acc: 71.88%] [G loss: 3.701679]\n",
      "epoch:38 step:29736 [D loss: 0.118026, acc: 100.00%] [G loss: 4.320254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29737 [D loss: 0.131317, acc: 100.00%] [G loss: 5.465398]\n",
      "epoch:38 step:29738 [D loss: 0.237163, acc: 94.53%] [G loss: 4.631444]\n",
      "epoch:38 step:29739 [D loss: 0.271756, acc: 94.53%] [G loss: 5.579388]\n",
      "epoch:38 step:29740 [D loss: 0.199508, acc: 96.88%] [G loss: 6.650415]\n",
      "epoch:38 step:29741 [D loss: 0.744221, acc: 54.69%] [G loss: 4.986249]\n",
      "epoch:38 step:29742 [D loss: 0.114979, acc: 99.22%] [G loss: 4.906192]\n",
      "epoch:38 step:29743 [D loss: 0.141974, acc: 99.22%] [G loss: 4.970980]\n",
      "epoch:38 step:29744 [D loss: 0.163234, acc: 98.44%] [G loss: 3.707283]\n",
      "epoch:38 step:29745 [D loss: 1.067424, acc: 44.53%] [G loss: 5.657017]\n",
      "epoch:38 step:29746 [D loss: 0.600935, acc: 66.41%] [G loss: 5.875974]\n",
      "epoch:38 step:29747 [D loss: 0.261790, acc: 89.84%] [G loss: 6.122257]\n",
      "epoch:38 step:29748 [D loss: 0.291671, acc: 96.88%] [G loss: 4.717196]\n",
      "epoch:38 step:29749 [D loss: 1.113627, acc: 40.62%] [G loss: 4.401009]\n",
      "epoch:38 step:29750 [D loss: 0.379398, acc: 85.94%] [G loss: 4.997639]\n",
      "epoch:38 step:29751 [D loss: 0.868239, acc: 48.44%] [G loss: 3.573605]\n",
      "epoch:38 step:29752 [D loss: 0.203690, acc: 97.66%] [G loss: 5.083336]\n",
      "epoch:38 step:29753 [D loss: 0.159981, acc: 98.44%] [G loss: 5.381973]\n",
      "epoch:38 step:29754 [D loss: 0.039309, acc: 100.00%] [G loss: 7.846078]\n",
      "epoch:38 step:29755 [D loss: 0.552575, acc: 76.56%] [G loss: 4.042637]\n",
      "epoch:38 step:29756 [D loss: 0.623006, acc: 66.41%] [G loss: 5.197790]\n",
      "epoch:38 step:29757 [D loss: 0.641165, acc: 64.06%] [G loss: 4.643438]\n",
      "epoch:38 step:29758 [D loss: 0.357049, acc: 86.72%] [G loss: 0.810784]\n",
      "epoch:38 step:29759 [D loss: 0.663276, acc: 59.38%] [G loss: 4.050724]\n",
      "epoch:38 step:29760 [D loss: 0.130681, acc: 100.00%] [G loss: 5.270311]\n",
      "epoch:38 step:29761 [D loss: 0.087849, acc: 99.22%] [G loss: 5.636467]\n",
      "epoch:38 step:29762 [D loss: 0.083099, acc: 100.00%] [G loss: 4.222946]\n",
      "epoch:38 step:29763 [D loss: 0.435073, acc: 86.72%] [G loss: 4.711193]\n",
      "epoch:38 step:29764 [D loss: 0.471015, acc: 71.88%] [G loss: 5.046146]\n",
      "epoch:38 step:29765 [D loss: 1.451051, acc: 48.44%] [G loss: 4.669756]\n",
      "epoch:38 step:29766 [D loss: 0.204094, acc: 95.31%] [G loss: 5.152609]\n",
      "epoch:38 step:29767 [D loss: 0.089995, acc: 99.22%] [G loss: 4.974171]\n",
      "epoch:38 step:29768 [D loss: 0.832645, acc: 50.78%] [G loss: 5.562737]\n",
      "epoch:38 step:29769 [D loss: 0.124254, acc: 98.44%] [G loss: 7.959005]\n",
      "epoch:38 step:29770 [D loss: 0.269617, acc: 92.19%] [G loss: 3.175607]\n",
      "epoch:38 step:29771 [D loss: 0.404760, acc: 76.56%] [G loss: 6.338257]\n",
      "epoch:38 step:29772 [D loss: 0.244708, acc: 97.66%] [G loss: 2.342547]\n",
      "epoch:38 step:29773 [D loss: 0.250670, acc: 93.75%] [G loss: 5.074171]\n",
      "epoch:38 step:29774 [D loss: 0.280183, acc: 89.06%] [G loss: 3.629541]\n",
      "epoch:38 step:29775 [D loss: 0.339741, acc: 96.09%] [G loss: 3.308539]\n",
      "epoch:38 step:29776 [D loss: 0.118883, acc: 99.22%] [G loss: 3.847615]\n",
      "epoch:38 step:29777 [D loss: 0.485099, acc: 69.53%] [G loss: 7.064661]\n",
      "epoch:38 step:29778 [D loss: 0.200359, acc: 96.88%] [G loss: 3.178703]\n",
      "epoch:38 step:29779 [D loss: 0.669058, acc: 53.91%] [G loss: 5.906221]\n",
      "epoch:38 step:29780 [D loss: 0.073410, acc: 100.00%] [G loss: 5.376684]\n",
      "epoch:38 step:29781 [D loss: 0.692476, acc: 60.16%] [G loss: 5.089685]\n",
      "epoch:38 step:29782 [D loss: 0.175064, acc: 96.09%] [G loss: 5.800119]\n",
      "epoch:38 step:29783 [D loss: 0.186771, acc: 96.88%] [G loss: 5.436164]\n",
      "epoch:38 step:29784 [D loss: 0.707390, acc: 54.69%] [G loss: 4.179210]\n",
      "epoch:38 step:29785 [D loss: 0.222324, acc: 93.75%] [G loss: 7.871296]\n",
      "epoch:38 step:29786 [D loss: 0.084370, acc: 99.22%] [G loss: 4.673203]\n",
      "epoch:38 step:29787 [D loss: 0.304065, acc: 82.03%] [G loss: 4.035859]\n",
      "epoch:38 step:29788 [D loss: 0.387912, acc: 81.25%] [G loss: 4.919920]\n",
      "epoch:38 step:29789 [D loss: 0.068529, acc: 99.22%] [G loss: 2.931039]\n",
      "epoch:38 step:29790 [D loss: 0.483021, acc: 70.31%] [G loss: 6.534137]\n",
      "epoch:38 step:29791 [D loss: 0.100977, acc: 99.22%] [G loss: 5.948993]\n",
      "epoch:38 step:29792 [D loss: 0.140110, acc: 100.00%] [G loss: 5.141896]\n",
      "epoch:38 step:29793 [D loss: 0.166433, acc: 97.66%] [G loss: 3.011795]\n",
      "epoch:38 step:29794 [D loss: 0.208687, acc: 96.88%] [G loss: 5.025560]\n",
      "epoch:38 step:29795 [D loss: 0.822006, acc: 50.78%] [G loss: 7.085108]\n",
      "epoch:38 step:29796 [D loss: 0.554401, acc: 62.50%] [G loss: 5.165746]\n",
      "epoch:38 step:29797 [D loss: 0.386791, acc: 78.91%] [G loss: 6.799055]\n",
      "epoch:38 step:29798 [D loss: 0.048080, acc: 100.00%] [G loss: 3.215063]\n",
      "epoch:38 step:29799 [D loss: 0.165223, acc: 96.88%] [G loss: 3.860251]\n",
      "epoch:38 step:29800 [D loss: 0.076114, acc: 100.00%] [G loss: 6.609926]\n",
      "epoch:38 step:29801 [D loss: 0.095699, acc: 100.00%] [G loss: 3.660884]\n",
      "epoch:38 step:29802 [D loss: 0.729901, acc: 55.47%] [G loss: 5.832695]\n",
      "epoch:38 step:29803 [D loss: 0.586700, acc: 56.25%] [G loss: 5.485011]\n",
      "epoch:38 step:29804 [D loss: 0.467630, acc: 76.56%] [G loss: 7.820873]\n",
      "epoch:38 step:29805 [D loss: 0.079254, acc: 100.00%] [G loss: 5.611982]\n",
      "epoch:38 step:29806 [D loss: 1.800126, acc: 50.00%] [G loss: 5.872108]\n",
      "epoch:38 step:29807 [D loss: 0.844332, acc: 49.22%] [G loss: 4.104631]\n",
      "epoch:38 step:29808 [D loss: 0.353196, acc: 91.41%] [G loss: 5.238893]\n",
      "epoch:38 step:29809 [D loss: 0.176849, acc: 96.88%] [G loss: 3.979634]\n",
      "epoch:38 step:29810 [D loss: 0.484679, acc: 66.41%] [G loss: 5.551236]\n",
      "epoch:38 step:29811 [D loss: 0.474155, acc: 64.84%] [G loss: 6.539847]\n",
      "epoch:38 step:29812 [D loss: 0.030573, acc: 100.00%] [G loss: 2.963382]\n",
      "epoch:38 step:29813 [D loss: 0.782851, acc: 52.34%] [G loss: 4.452209]\n",
      "epoch:38 step:29814 [D loss: 0.165654, acc: 100.00%] [G loss: 4.315722]\n",
      "epoch:38 step:29815 [D loss: 0.455265, acc: 73.44%] [G loss: 4.820575]\n",
      "epoch:38 step:29816 [D loss: 0.252320, acc: 94.53%] [G loss: 4.775134]\n",
      "epoch:38 step:29817 [D loss: 0.109217, acc: 100.00%] [G loss: 3.316845]\n",
      "epoch:38 step:29818 [D loss: 0.345683, acc: 92.97%] [G loss: 5.214014]\n",
      "epoch:38 step:29819 [D loss: 0.406333, acc: 86.72%] [G loss: 4.160760]\n",
      "epoch:38 step:29820 [D loss: 0.412513, acc: 84.38%] [G loss: 5.408941]\n",
      "epoch:38 step:29821 [D loss: 0.627060, acc: 55.47%] [G loss: 4.650749]\n",
      "epoch:38 step:29822 [D loss: 0.497910, acc: 78.91%] [G loss: 3.396104]\n",
      "epoch:38 step:29823 [D loss: 0.908725, acc: 36.72%] [G loss: 7.226549]\n",
      "epoch:38 step:29824 [D loss: 0.963377, acc: 40.62%] [G loss: 6.251077]\n",
      "epoch:38 step:29825 [D loss: 0.219968, acc: 92.97%] [G loss: 5.976130]\n",
      "epoch:38 step:29826 [D loss: 0.735276, acc: 53.91%] [G loss: 6.892546]\n",
      "epoch:38 step:29827 [D loss: 0.629964, acc: 57.03%] [G loss: 3.202852]\n",
      "epoch:38 step:29828 [D loss: 0.224547, acc: 92.97%] [G loss: 5.555621]\n",
      "epoch:38 step:29829 [D loss: 0.178815, acc: 96.88%] [G loss: 3.213567]\n",
      "epoch:38 step:29830 [D loss: 0.331103, acc: 92.97%] [G loss: 6.709300]\n",
      "epoch:38 step:29831 [D loss: 0.194041, acc: 96.09%] [G loss: 5.192432]\n",
      "epoch:38 step:29832 [D loss: 0.182003, acc: 96.09%] [G loss: 4.462999]\n",
      "epoch:38 step:29833 [D loss: 0.150334, acc: 99.22%] [G loss: 4.861871]\n",
      "epoch:38 step:29834 [D loss: 0.230827, acc: 96.09%] [G loss: 3.787559]\n",
      "epoch:38 step:29835 [D loss: 0.197270, acc: 100.00%] [G loss: 4.680013]\n",
      "epoch:38 step:29836 [D loss: 0.757620, acc: 55.47%] [G loss: 6.438151]\n",
      "epoch:38 step:29837 [D loss: 0.072841, acc: 100.00%] [G loss: 5.371905]\n",
      "epoch:38 step:29838 [D loss: 0.155499, acc: 99.22%] [G loss: 3.436584]\n",
      "epoch:38 step:29839 [D loss: 0.061925, acc: 100.00%] [G loss: 7.474589]\n",
      "epoch:38 step:29840 [D loss: 0.086214, acc: 100.00%] [G loss: 5.918767]\n",
      "epoch:38 step:29841 [D loss: 0.168414, acc: 99.22%] [G loss: 2.169166]\n",
      "epoch:38 step:29842 [D loss: 0.491795, acc: 82.81%] [G loss: 6.903724]\n",
      "epoch:38 step:29843 [D loss: 0.196717, acc: 96.09%] [G loss: 4.713137]\n",
      "epoch:38 step:29844 [D loss: 0.925047, acc: 50.00%] [G loss: 5.418173]\n",
      "epoch:38 step:29845 [D loss: 0.039324, acc: 100.00%] [G loss: 5.043473]\n",
      "epoch:38 step:29846 [D loss: 1.071486, acc: 50.00%] [G loss: 3.276026]\n",
      "epoch:38 step:29847 [D loss: 0.196323, acc: 99.22%] [G loss: 4.165221]\n",
      "epoch:38 step:29848 [D loss: 0.399748, acc: 75.78%] [G loss: 3.777270]\n",
      "epoch:38 step:29849 [D loss: 0.171629, acc: 100.00%] [G loss: 3.922046]\n",
      "epoch:38 step:29850 [D loss: 0.984328, acc: 33.59%] [G loss: 5.137139]\n",
      "epoch:38 step:29851 [D loss: 0.714644, acc: 55.47%] [G loss: 4.343338]\n",
      "epoch:38 step:29852 [D loss: 0.128755, acc: 99.22%] [G loss: 4.872743]\n",
      "epoch:38 step:29853 [D loss: 0.073605, acc: 100.00%] [G loss: 3.560352]\n",
      "epoch:38 step:29854 [D loss: 1.363824, acc: 45.31%] [G loss: 3.154712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29855 [D loss: 1.491008, acc: 9.38%] [G loss: 5.376586]\n",
      "epoch:38 step:29856 [D loss: 0.130229, acc: 99.22%] [G loss: 4.801392]\n",
      "epoch:38 step:29857 [D loss: 0.466476, acc: 80.47%] [G loss: 4.150093]\n",
      "epoch:38 step:29858 [D loss: 0.444405, acc: 79.69%] [G loss: 5.896354]\n",
      "epoch:38 step:29859 [D loss: 0.335726, acc: 86.72%] [G loss: 4.314698]\n",
      "epoch:38 step:29860 [D loss: 0.840082, acc: 50.78%] [G loss: 7.760069]\n",
      "epoch:38 step:29861 [D loss: 0.093122, acc: 100.00%] [G loss: 5.185042]\n",
      "epoch:38 step:29862 [D loss: 0.261573, acc: 90.62%] [G loss: 2.590714]\n",
      "epoch:38 step:29863 [D loss: 0.148526, acc: 99.22%] [G loss: 6.220291]\n",
      "epoch:38 step:29864 [D loss: 0.336045, acc: 85.94%] [G loss: 4.658656]\n",
      "epoch:38 step:29865 [D loss: 0.043367, acc: 100.00%] [G loss: 5.565432]\n",
      "epoch:38 step:29866 [D loss: 0.046774, acc: 100.00%] [G loss: 5.213252]\n",
      "epoch:38 step:29867 [D loss: 0.261082, acc: 89.06%] [G loss: 6.287330]\n",
      "epoch:38 step:29868 [D loss: 0.233723, acc: 98.44%] [G loss: 1.183367]\n",
      "epoch:38 step:29869 [D loss: 0.411424, acc: 75.78%] [G loss: 4.182243]\n",
      "epoch:38 step:29870 [D loss: 0.915944, acc: 42.19%] [G loss: 6.736913]\n",
      "epoch:38 step:29871 [D loss: 0.128236, acc: 100.00%] [G loss: 5.475725]\n",
      "epoch:38 step:29872 [D loss: 0.286687, acc: 91.41%] [G loss: 5.071507]\n",
      "epoch:38 step:29873 [D loss: 0.214816, acc: 92.97%] [G loss: 2.488703]\n",
      "epoch:38 step:29874 [D loss: 0.354915, acc: 78.91%] [G loss: 2.935491]\n",
      "epoch:38 step:29875 [D loss: 0.484973, acc: 60.16%] [G loss: 5.708375]\n",
      "epoch:38 step:29876 [D loss: 0.018240, acc: 100.00%] [G loss: 7.398658]\n",
      "epoch:38 step:29877 [D loss: 0.180875, acc: 98.44%] [G loss: 4.532898]\n",
      "epoch:38 step:29878 [D loss: 0.034363, acc: 100.00%] [G loss: 5.082775]\n",
      "epoch:38 step:29879 [D loss: 0.154936, acc: 99.22%] [G loss: 4.706180]\n",
      "epoch:38 step:29880 [D loss: 0.346668, acc: 81.25%] [G loss: 4.627583]\n",
      "epoch:38 step:29881 [D loss: 0.390926, acc: 77.34%] [G loss: 3.455635]\n",
      "epoch:38 step:29882 [D loss: 0.256288, acc: 94.53%] [G loss: 4.353775]\n",
      "epoch:38 step:29883 [D loss: 0.763633, acc: 53.12%] [G loss: 5.853170]\n",
      "epoch:38 step:29884 [D loss: 1.405371, acc: 13.28%] [G loss: 7.594345]\n",
      "epoch:38 step:29885 [D loss: 0.104916, acc: 99.22%] [G loss: 4.831829]\n",
      "epoch:38 step:29886 [D loss: 0.300268, acc: 86.72%] [G loss: 6.077105]\n",
      "epoch:38 step:29887 [D loss: 0.069410, acc: 99.22%] [G loss: 6.552466]\n",
      "epoch:38 step:29888 [D loss: 0.970531, acc: 33.59%] [G loss: 5.268135]\n",
      "epoch:38 step:29889 [D loss: 0.877858, acc: 51.56%] [G loss: 4.422427]\n",
      "epoch:38 step:29890 [D loss: 0.109701, acc: 100.00%] [G loss: 4.433756]\n",
      "epoch:38 step:29891 [D loss: 0.398793, acc: 78.91%] [G loss: 4.987981]\n",
      "epoch:38 step:29892 [D loss: 0.301314, acc: 85.94%] [G loss: 5.588380]\n",
      "epoch:38 step:29893 [D loss: 0.507729, acc: 72.66%] [G loss: 3.848326]\n",
      "epoch:38 step:29894 [D loss: 0.172691, acc: 100.00%] [G loss: 3.426713]\n",
      "epoch:38 step:29895 [D loss: 0.077092, acc: 100.00%] [G loss: 6.212110]\n",
      "epoch:38 step:29896 [D loss: 0.703848, acc: 56.25%] [G loss: 6.018434]\n",
      "epoch:38 step:29897 [D loss: 0.460468, acc: 86.72%] [G loss: 5.878248]\n",
      "epoch:38 step:29898 [D loss: 0.053653, acc: 100.00%] [G loss: 2.113918]\n",
      "epoch:38 step:29899 [D loss: 0.225590, acc: 98.44%] [G loss: 4.045938]\n",
      "epoch:38 step:29900 [D loss: 0.447815, acc: 83.59%] [G loss: 2.815691]\n",
      "epoch:38 step:29901 [D loss: 0.377251, acc: 90.62%] [G loss: 2.994371]\n",
      "epoch:38 step:29902 [D loss: 1.137011, acc: 50.00%] [G loss: 5.427530]\n",
      "epoch:38 step:29903 [D loss: 0.232372, acc: 97.66%] [G loss: 4.584661]\n",
      "epoch:38 step:29904 [D loss: 0.097985, acc: 100.00%] [G loss: 5.588186]\n",
      "epoch:38 step:29905 [D loss: 0.148376, acc: 100.00%] [G loss: 6.291392]\n",
      "epoch:38 step:29906 [D loss: 0.130001, acc: 100.00%] [G loss: 5.518075]\n",
      "epoch:38 step:29907 [D loss: 0.131136, acc: 98.44%] [G loss: 3.245338]\n",
      "epoch:38 step:29908 [D loss: 0.282464, acc: 95.31%] [G loss: 5.498017]\n",
      "epoch:38 step:29909 [D loss: 0.294668, acc: 86.72%] [G loss: 3.336837]\n",
      "epoch:38 step:29910 [D loss: 0.336325, acc: 81.25%] [G loss: 5.173938]\n",
      "epoch:38 step:29911 [D loss: 0.070501, acc: 99.22%] [G loss: 7.395446]\n",
      "epoch:38 step:29912 [D loss: 0.230714, acc: 93.75%] [G loss: 3.677014]\n",
      "epoch:38 step:29913 [D loss: 0.949580, acc: 52.34%] [G loss: 5.131960]\n",
      "epoch:38 step:29914 [D loss: 0.103118, acc: 100.00%] [G loss: 3.202581]\n",
      "epoch:38 step:29915 [D loss: 0.356645, acc: 87.50%] [G loss: 3.119995]\n",
      "epoch:38 step:29916 [D loss: 0.537749, acc: 75.00%] [G loss: 3.141553]\n",
      "epoch:38 step:29917 [D loss: 0.304103, acc: 93.75%] [G loss: 6.167553]\n",
      "epoch:38 step:29918 [D loss: 0.379866, acc: 83.59%] [G loss: 7.332117]\n",
      "epoch:38 step:29919 [D loss: 0.193931, acc: 99.22%] [G loss: 5.932218]\n",
      "epoch:38 step:29920 [D loss: 0.093655, acc: 100.00%] [G loss: 5.230363]\n",
      "epoch:38 step:29921 [D loss: 0.219819, acc: 97.66%] [G loss: 4.840002]\n",
      "epoch:38 step:29922 [D loss: 0.192503, acc: 96.88%] [G loss: 5.799357]\n",
      "epoch:38 step:29923 [D loss: 0.446017, acc: 78.91%] [G loss: 2.689254]\n",
      "epoch:38 step:29924 [D loss: 0.471322, acc: 67.19%] [G loss: 4.150192]\n",
      "epoch:38 step:29925 [D loss: 0.231695, acc: 99.22%] [G loss: 5.045712]\n",
      "epoch:38 step:29926 [D loss: 0.779009, acc: 51.56%] [G loss: 4.553851]\n",
      "epoch:38 step:29927 [D loss: 0.402508, acc: 78.12%] [G loss: 6.547468]\n",
      "epoch:38 step:29928 [D loss: 0.136640, acc: 99.22%] [G loss: 4.625660]\n",
      "epoch:38 step:29929 [D loss: 0.200425, acc: 95.31%] [G loss: 4.790397]\n",
      "epoch:38 step:29930 [D loss: 0.243423, acc: 95.31%] [G loss: 3.806658]\n",
      "epoch:38 step:29931 [D loss: 0.734090, acc: 54.69%] [G loss: 3.961399]\n",
      "epoch:38 step:29932 [D loss: 0.423470, acc: 85.16%] [G loss: 5.558566]\n",
      "epoch:38 step:29933 [D loss: 0.489336, acc: 64.06%] [G loss: 6.109368]\n",
      "epoch:38 step:29934 [D loss: 0.201775, acc: 98.44%] [G loss: 4.766803]\n",
      "epoch:38 step:29935 [D loss: 0.821513, acc: 50.78%] [G loss: 5.613465]\n",
      "epoch:38 step:29936 [D loss: 0.091183, acc: 100.00%] [G loss: 5.005026]\n",
      "epoch:38 step:29937 [D loss: 0.740165, acc: 51.56%] [G loss: 6.574212]\n",
      "epoch:38 step:29938 [D loss: 0.239093, acc: 96.09%] [G loss: 4.856355]\n",
      "epoch:38 step:29939 [D loss: 0.586522, acc: 60.16%] [G loss: 4.650189]\n",
      "epoch:38 step:29940 [D loss: 0.367618, acc: 79.69%] [G loss: 3.711102]\n",
      "epoch:38 step:29941 [D loss: 0.790133, acc: 51.56%] [G loss: 5.050980]\n",
      "epoch:38 step:29942 [D loss: 0.107415, acc: 99.22%] [G loss: 9.573122]\n",
      "epoch:38 step:29943 [D loss: 0.911459, acc: 52.34%] [G loss: 3.769173]\n",
      "epoch:38 step:29944 [D loss: 0.360584, acc: 89.06%] [G loss: 6.991976]\n",
      "epoch:38 step:29945 [D loss: 0.118244, acc: 99.22%] [G loss: 4.235316]\n",
      "epoch:38 step:29946 [D loss: 0.224985, acc: 96.09%] [G loss: 3.981005]\n",
      "epoch:38 step:29947 [D loss: 0.052059, acc: 100.00%] [G loss: 5.613360]\n",
      "epoch:38 step:29948 [D loss: 0.441692, acc: 73.44%] [G loss: 2.928104]\n",
      "epoch:38 step:29949 [D loss: 0.141796, acc: 100.00%] [G loss: 5.768722]\n",
      "epoch:38 step:29950 [D loss: 0.063578, acc: 100.00%] [G loss: 3.529909]\n",
      "epoch:38 step:29951 [D loss: 0.605394, acc: 60.16%] [G loss: 3.889686]\n",
      "epoch:38 step:29952 [D loss: 0.178829, acc: 97.66%] [G loss: 5.659889]\n",
      "epoch:38 step:29953 [D loss: 0.209137, acc: 98.44%] [G loss: 5.040395]\n",
      "epoch:38 step:29954 [D loss: 0.414863, acc: 71.09%] [G loss: 6.484934]\n",
      "epoch:38 step:29955 [D loss: 0.425665, acc: 84.38%] [G loss: 5.967979]\n",
      "epoch:38 step:29956 [D loss: 0.194127, acc: 99.22%] [G loss: 6.010907]\n",
      "epoch:38 step:29957 [D loss: 0.711917, acc: 54.69%] [G loss: 4.024313]\n",
      "epoch:38 step:29958 [D loss: 0.530318, acc: 70.31%] [G loss: 4.094376]\n",
      "epoch:38 step:29959 [D loss: 1.029678, acc: 50.00%] [G loss: 3.944825]\n",
      "epoch:38 step:29960 [D loss: 0.136637, acc: 99.22%] [G loss: 6.211028]\n",
      "epoch:38 step:29961 [D loss: 0.453341, acc: 79.69%] [G loss: 6.939682]\n",
      "epoch:38 step:29962 [D loss: 0.311537, acc: 83.59%] [G loss: 8.144165]\n",
      "epoch:38 step:29963 [D loss: 0.196260, acc: 98.44%] [G loss: 4.458137]\n",
      "epoch:38 step:29964 [D loss: 0.133463, acc: 98.44%] [G loss: 3.188445]\n",
      "epoch:38 step:29965 [D loss: 0.074096, acc: 100.00%] [G loss: 6.679465]\n",
      "epoch:38 step:29966 [D loss: 0.347162, acc: 88.28%] [G loss: 6.381095]\n",
      "epoch:38 step:29967 [D loss: 0.180814, acc: 99.22%] [G loss: 5.433294]\n",
      "epoch:38 step:29968 [D loss: 0.040751, acc: 100.00%] [G loss: 4.347799]\n",
      "epoch:38 step:29969 [D loss: 0.604267, acc: 64.84%] [G loss: 4.606215]\n",
      "epoch:38 step:29970 [D loss: 0.040119, acc: 100.00%] [G loss: 3.752446]\n",
      "epoch:38 step:29971 [D loss: 0.587292, acc: 60.94%] [G loss: 6.091296]\n",
      "epoch:38 step:29972 [D loss: 0.843716, acc: 50.00%] [G loss: 5.331073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29973 [D loss: 0.358320, acc: 81.25%] [G loss: 4.849137]\n",
      "epoch:38 step:29974 [D loss: 0.272840, acc: 93.75%] [G loss: 2.424726]\n",
      "epoch:38 step:29975 [D loss: 0.719149, acc: 53.91%] [G loss: 6.493093]\n",
      "epoch:38 step:29976 [D loss: 0.832528, acc: 41.41%] [G loss: 3.642190]\n",
      "epoch:38 step:29977 [D loss: 0.073199, acc: 99.22%] [G loss: 5.854317]\n",
      "epoch:38 step:29978 [D loss: 0.205981, acc: 98.44%] [G loss: 5.178106]\n",
      "epoch:38 step:29979 [D loss: 0.484476, acc: 76.56%] [G loss: 4.152847]\n",
      "epoch:38 step:29980 [D loss: 0.397702, acc: 85.16%] [G loss: 3.172225]\n",
      "epoch:38 step:29981 [D loss: 0.462672, acc: 78.12%] [G loss: 2.931036]\n",
      "epoch:38 step:29982 [D loss: 0.473679, acc: 71.88%] [G loss: 5.220098]\n",
      "epoch:38 step:29983 [D loss: 0.392312, acc: 79.69%] [G loss: 5.367643]\n",
      "epoch:38 step:29984 [D loss: 0.284160, acc: 96.09%] [G loss: 8.441864]\n",
      "epoch:38 step:29985 [D loss: 0.424128, acc: 85.16%] [G loss: 7.286234]\n",
      "epoch:38 step:29986 [D loss: 0.232315, acc: 97.66%] [G loss: 6.755708]\n",
      "epoch:38 step:29987 [D loss: 1.042726, acc: 25.00%] [G loss: 5.662772]\n",
      "epoch:38 step:29988 [D loss: 0.253973, acc: 99.22%] [G loss: 4.226872]\n",
      "epoch:38 step:29989 [D loss: 0.250363, acc: 95.31%] [G loss: 3.304351]\n",
      "epoch:38 step:29990 [D loss: 0.846671, acc: 51.56%] [G loss: 6.540139]\n",
      "epoch:38 step:29991 [D loss: 0.312335, acc: 89.06%] [G loss: 4.832581]\n",
      "epoch:38 step:29992 [D loss: 0.038440, acc: 100.00%] [G loss: 7.145018]\n",
      "epoch:38 step:29993 [D loss: 0.443473, acc: 82.81%] [G loss: 5.963872]\n",
      "epoch:38 step:29994 [D loss: 0.271468, acc: 90.62%] [G loss: 5.038539]\n",
      "epoch:38 step:29995 [D loss: 0.067355, acc: 100.00%] [G loss: 3.447092]\n",
      "epoch:38 step:29996 [D loss: 0.245560, acc: 97.66%] [G loss: 4.520092]\n",
      "epoch:38 step:29997 [D loss: 0.082145, acc: 100.00%] [G loss: 2.923262]\n",
      "epoch:38 step:29998 [D loss: 0.222450, acc: 95.31%] [G loss: 3.477985]\n",
      "epoch:38 step:29999 [D loss: 1.206507, acc: 37.50%] [G loss: 3.778805]\n",
      "epoch:38 step:30000 [D loss: 0.138025, acc: 97.66%] [G loss: 6.570767]\n",
      "epoch:38 step:30001 [D loss: 0.118084, acc: 100.00%] [G loss: 4.561839]\n",
      "epoch:38 step:30002 [D loss: 0.213289, acc: 98.44%] [G loss: 6.006578]\n",
      "epoch:38 step:30003 [D loss: 0.092599, acc: 99.22%] [G loss: 5.233521]\n",
      "epoch:38 step:30004 [D loss: 0.170602, acc: 99.22%] [G loss: 4.381574]\n",
      "epoch:38 step:30005 [D loss: 0.352827, acc: 83.59%] [G loss: 5.374482]\n",
      "epoch:38 step:30006 [D loss: 0.712610, acc: 52.34%] [G loss: 4.904782]\n",
      "epoch:38 step:30007 [D loss: 0.273318, acc: 97.66%] [G loss: 4.212592]\n",
      "epoch:38 step:30008 [D loss: 0.563939, acc: 73.44%] [G loss: 5.244677]\n",
      "epoch:38 step:30009 [D loss: 0.395941, acc: 88.28%] [G loss: 5.997179]\n",
      "epoch:38 step:30010 [D loss: 0.643949, acc: 64.06%] [G loss: 3.802318]\n",
      "epoch:38 step:30011 [D loss: 0.083956, acc: 99.22%] [G loss: 5.945292]\n",
      "epoch:38 step:30012 [D loss: 0.113763, acc: 97.66%] [G loss: 6.393741]\n",
      "epoch:38 step:30013 [D loss: 0.145631, acc: 100.00%] [G loss: 5.324388]\n",
      "epoch:38 step:30014 [D loss: 0.054586, acc: 100.00%] [G loss: 6.929435]\n",
      "epoch:38 step:30015 [D loss: 0.204618, acc: 100.00%] [G loss: 4.845400]\n",
      "epoch:38 step:30016 [D loss: 0.226127, acc: 96.09%] [G loss: 6.408387]\n",
      "epoch:38 step:30017 [D loss: 0.400901, acc: 74.22%] [G loss: 6.117473]\n",
      "epoch:38 step:30018 [D loss: 0.119642, acc: 100.00%] [G loss: 3.920207]\n",
      "epoch:38 step:30019 [D loss: 0.182112, acc: 100.00%] [G loss: 4.829725]\n",
      "epoch:38 step:30020 [D loss: 0.208990, acc: 96.88%] [G loss: 3.221180]\n",
      "epoch:38 step:30021 [D loss: 0.176467, acc: 96.88%] [G loss: 6.903845]\n",
      "epoch:38 step:30022 [D loss: 0.260723, acc: 97.66%] [G loss: 3.263687]\n",
      "epoch:38 step:30023 [D loss: 0.741527, acc: 53.91%] [G loss: 6.136146]\n",
      "epoch:38 step:30024 [D loss: 0.186943, acc: 97.66%] [G loss: 2.484941]\n",
      "epoch:38 step:30025 [D loss: 0.202659, acc: 98.44%] [G loss: 7.145592]\n",
      "epoch:38 step:30026 [D loss: 0.409163, acc: 86.72%] [G loss: 3.085773]\n",
      "epoch:38 step:30027 [D loss: 0.670072, acc: 61.72%] [G loss: 3.878220]\n",
      "epoch:38 step:30028 [D loss: 0.362323, acc: 89.06%] [G loss: 5.545194]\n",
      "epoch:38 step:30029 [D loss: 1.337249, acc: 10.94%] [G loss: 5.294129]\n",
      "epoch:38 step:30030 [D loss: 0.094102, acc: 99.22%] [G loss: 7.534251]\n",
      "epoch:38 step:30031 [D loss: 0.265726, acc: 93.75%] [G loss: 5.539198]\n",
      "epoch:38 step:30032 [D loss: 0.317696, acc: 94.53%] [G loss: 3.654301]\n",
      "epoch:38 step:30033 [D loss: 0.161449, acc: 99.22%] [G loss: 4.223874]\n",
      "epoch:38 step:30034 [D loss: 0.160034, acc: 96.88%] [G loss: 7.679159]\n",
      "epoch:38 step:30035 [D loss: 1.043066, acc: 26.56%] [G loss: 4.733594]\n",
      "epoch:38 step:30036 [D loss: 0.359514, acc: 75.78%] [G loss: 4.018005]\n",
      "epoch:38 step:30037 [D loss: 0.219316, acc: 97.66%] [G loss: 4.209328]\n",
      "epoch:38 step:30038 [D loss: 0.573530, acc: 58.59%] [G loss: 6.607686]\n",
      "epoch:38 step:30039 [D loss: 0.899659, acc: 51.56%] [G loss: 3.110561]\n",
      "epoch:38 step:30040 [D loss: 0.163313, acc: 100.00%] [G loss: 4.924141]\n",
      "epoch:38 step:30041 [D loss: 0.364860, acc: 88.28%] [G loss: 6.597349]\n",
      "epoch:38 step:30042 [D loss: 0.139370, acc: 99.22%] [G loss: 4.565208]\n",
      "epoch:38 step:30043 [D loss: 0.450914, acc: 79.69%] [G loss: 6.545906]\n",
      "epoch:38 step:30044 [D loss: 0.133360, acc: 100.00%] [G loss: 5.140965]\n",
      "epoch:38 step:30045 [D loss: 0.520012, acc: 64.06%] [G loss: 4.085609]\n",
      "epoch:38 step:30046 [D loss: 0.270678, acc: 89.06%] [G loss: 5.599469]\n",
      "epoch:38 step:30047 [D loss: 0.241933, acc: 96.88%] [G loss: 3.983511]\n",
      "epoch:38 step:30048 [D loss: 0.098239, acc: 100.00%] [G loss: 8.651363]\n",
      "epoch:38 step:30049 [D loss: 0.486996, acc: 71.88%] [G loss: 4.354978]\n",
      "epoch:38 step:30050 [D loss: 0.182219, acc: 96.09%] [G loss: 6.217467]\n",
      "epoch:38 step:30051 [D loss: 0.166865, acc: 100.00%] [G loss: 3.014511]\n",
      "epoch:38 step:30052 [D loss: 0.118155, acc: 100.00%] [G loss: 2.832067]\n",
      "epoch:38 step:30053 [D loss: 0.417097, acc: 78.91%] [G loss: 7.826490]\n",
      "epoch:38 step:30054 [D loss: 0.511289, acc: 76.56%] [G loss: 5.954947]\n",
      "epoch:38 step:30055 [D loss: 0.394849, acc: 75.78%] [G loss: 5.679441]\n",
      "epoch:38 step:30056 [D loss: 0.262172, acc: 94.53%] [G loss: 5.171058]\n",
      "epoch:38 step:30057 [D loss: 0.269496, acc: 87.50%] [G loss: 6.113450]\n",
      "epoch:38 step:30058 [D loss: 0.135334, acc: 100.00%] [G loss: 4.563656]\n",
      "epoch:38 step:30059 [D loss: 0.146931, acc: 97.66%] [G loss: 6.619158]\n",
      "epoch:38 step:30060 [D loss: 0.336982, acc: 89.84%] [G loss: 7.290359]\n",
      "epoch:38 step:30061 [D loss: 0.694516, acc: 60.94%] [G loss: 5.834286]\n",
      "epoch:38 step:30062 [D loss: 0.103928, acc: 100.00%] [G loss: 5.614627]\n",
      "epoch:38 step:30063 [D loss: 0.272726, acc: 91.41%] [G loss: 6.807305]\n",
      "epoch:38 step:30064 [D loss: 0.321904, acc: 79.69%] [G loss: 3.927294]\n",
      "epoch:38 step:30065 [D loss: 0.117963, acc: 99.22%] [G loss: 8.294739]\n",
      "epoch:38 step:30066 [D loss: 0.335405, acc: 87.50%] [G loss: 2.688814]\n",
      "epoch:38 step:30067 [D loss: 0.251567, acc: 96.09%] [G loss: 4.380809]\n",
      "epoch:38 step:30068 [D loss: 0.091009, acc: 100.00%] [G loss: 3.754477]\n",
      "epoch:38 step:30069 [D loss: 0.029937, acc: 100.00%] [G loss: 5.920049]\n",
      "epoch:38 step:30070 [D loss: 0.161551, acc: 96.09%] [G loss: 5.968822]\n",
      "epoch:38 step:30071 [D loss: 0.204507, acc: 98.44%] [G loss: 2.044533]\n",
      "epoch:38 step:30072 [D loss: 0.012696, acc: 100.00%] [G loss: 6.030939]\n",
      "epoch:38 step:30073 [D loss: 0.948362, acc: 36.72%] [G loss: 7.007133]\n",
      "epoch:38 step:30074 [D loss: 0.215911, acc: 95.31%] [G loss: 3.862028]\n",
      "epoch:38 step:30075 [D loss: 0.383778, acc: 80.47%] [G loss: 4.471827]\n",
      "epoch:38 step:30076 [D loss: 0.322510, acc: 92.97%] [G loss: 2.343633]\n",
      "epoch:38 step:30077 [D loss: 0.386186, acc: 79.69%] [G loss: 5.830784]\n",
      "epoch:38 step:30078 [D loss: 2.763520, acc: 47.66%] [G loss: 4.892801]\n",
      "epoch:38 step:30079 [D loss: 0.047372, acc: 99.22%] [G loss: 6.127398]\n",
      "epoch:38 step:30080 [D loss: 1.225056, acc: 14.84%] [G loss: 4.454686]\n",
      "epoch:38 step:30081 [D loss: 0.845349, acc: 54.69%] [G loss: 5.828866]\n",
      "epoch:38 step:30082 [D loss: 0.119510, acc: 98.44%] [G loss: 4.210980]\n",
      "epoch:38 step:30083 [D loss: 0.133917, acc: 100.00%] [G loss: 2.676249]\n",
      "epoch:38 step:30084 [D loss: 0.797559, acc: 48.44%] [G loss: 4.115437]\n",
      "epoch:38 step:30085 [D loss: 0.197555, acc: 100.00%] [G loss: 3.067779]\n",
      "epoch:38 step:30086 [D loss: 0.228303, acc: 99.22%] [G loss: 3.477537]\n",
      "epoch:38 step:30087 [D loss: 0.067901, acc: 100.00%] [G loss: 6.886002]\n",
      "epoch:38 step:30088 [D loss: 0.174977, acc: 99.22%] [G loss: 3.140356]\n",
      "epoch:38 step:30089 [D loss: 0.281427, acc: 91.41%] [G loss: 6.375852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30090 [D loss: 0.598476, acc: 57.03%] [G loss: 4.957248]\n",
      "epoch:38 step:30091 [D loss: 0.085330, acc: 99.22%] [G loss: 6.836813]\n",
      "epoch:38 step:30092 [D loss: 0.389363, acc: 91.41%] [G loss: 6.848110]\n",
      "epoch:38 step:30093 [D loss: 0.528796, acc: 69.53%] [G loss: 3.745821]\n",
      "epoch:38 step:30094 [D loss: 0.246004, acc: 97.66%] [G loss: 3.042791]\n",
      "epoch:38 step:30095 [D loss: 0.408175, acc: 82.03%] [G loss: 6.024007]\n",
      "epoch:38 step:30096 [D loss: 0.120789, acc: 97.66%] [G loss: 4.512635]\n",
      "epoch:38 step:30097 [D loss: 0.452008, acc: 66.41%] [G loss: 5.299821]\n",
      "epoch:38 step:30098 [D loss: 0.111103, acc: 100.00%] [G loss: 4.096034]\n",
      "epoch:38 step:30099 [D loss: 0.441453, acc: 83.59%] [G loss: 5.703814]\n",
      "epoch:38 step:30100 [D loss: 0.108370, acc: 99.22%] [G loss: 3.482957]\n",
      "epoch:38 step:30101 [D loss: 0.492640, acc: 64.84%] [G loss: 7.221087]\n",
      "epoch:38 step:30102 [D loss: 0.346981, acc: 84.38%] [G loss: 3.809388]\n",
      "epoch:38 step:30103 [D loss: 0.163037, acc: 96.88%] [G loss: 6.104292]\n",
      "epoch:38 step:30104 [D loss: 0.439944, acc: 69.53%] [G loss: 4.605401]\n",
      "epoch:38 step:30105 [D loss: 0.675319, acc: 58.59%] [G loss: 5.143307]\n",
      "epoch:38 step:30106 [D loss: 0.449645, acc: 71.09%] [G loss: 8.776463]\n",
      "epoch:38 step:30107 [D loss: 1.029419, acc: 35.94%] [G loss: 6.488675]\n",
      "epoch:38 step:30108 [D loss: 0.608599, acc: 55.47%] [G loss: 6.292800]\n",
      "epoch:38 step:30109 [D loss: 0.145548, acc: 98.44%] [G loss: 4.463604]\n",
      "epoch:38 step:30110 [D loss: 0.204291, acc: 98.44%] [G loss: 5.184947]\n",
      "epoch:38 step:30111 [D loss: 0.211920, acc: 97.66%] [G loss: 3.962763]\n",
      "epoch:38 step:30112 [D loss: 0.323750, acc: 83.59%] [G loss: 5.588609]\n",
      "epoch:38 step:30113 [D loss: 0.117150, acc: 100.00%] [G loss: 6.473765]\n",
      "epoch:38 step:30114 [D loss: 0.910056, acc: 51.56%] [G loss: 6.204048]\n",
      "epoch:38 step:30115 [D loss: 0.675499, acc: 56.25%] [G loss: 5.659633]\n",
      "epoch:38 step:30116 [D loss: 0.900491, acc: 50.00%] [G loss: 6.320740]\n",
      "epoch:38 step:30117 [D loss: 0.063499, acc: 100.00%] [G loss: 4.705179]\n",
      "epoch:38 step:30118 [D loss: 0.562761, acc: 67.19%] [G loss: 4.530015]\n",
      "epoch:38 step:30119 [D loss: 0.495181, acc: 72.66%] [G loss: 3.556530]\n",
      "epoch:38 step:30120 [D loss: 0.333548, acc: 83.59%] [G loss: 5.374108]\n",
      "epoch:38 step:30121 [D loss: 0.804813, acc: 53.12%] [G loss: 5.621866]\n",
      "epoch:38 step:30122 [D loss: 0.260865, acc: 89.84%] [G loss: 6.045713]\n",
      "epoch:38 step:30123 [D loss: 0.554102, acc: 71.88%] [G loss: 2.971415]\n",
      "epoch:38 step:30124 [D loss: 0.079466, acc: 100.00%] [G loss: 4.127530]\n",
      "epoch:38 step:30125 [D loss: 0.050404, acc: 100.00%] [G loss: 6.668741]\n",
      "epoch:38 step:30126 [D loss: 0.116849, acc: 99.22%] [G loss: 7.596184]\n",
      "epoch:38 step:30127 [D loss: 0.090739, acc: 100.00%] [G loss: 7.358249]\n",
      "epoch:38 step:30128 [D loss: 0.097108, acc: 99.22%] [G loss: 4.853231]\n",
      "epoch:38 step:30129 [D loss: 0.207788, acc: 98.44%] [G loss: 4.768491]\n",
      "epoch:38 step:30130 [D loss: 0.263291, acc: 94.53%] [G loss: 4.870961]\n",
      "epoch:38 step:30131 [D loss: 0.076165, acc: 100.00%] [G loss: 4.864012]\n",
      "epoch:38 step:30132 [D loss: 0.247726, acc: 98.44%] [G loss: 6.224171]\n",
      "epoch:38 step:30133 [D loss: 0.255075, acc: 97.66%] [G loss: 2.222867]\n",
      "epoch:38 step:30134 [D loss: 0.519645, acc: 67.19%] [G loss: 6.565219]\n",
      "epoch:38 step:30135 [D loss: 0.521752, acc: 67.19%] [G loss: 4.267896]\n",
      "epoch:38 step:30136 [D loss: 0.170305, acc: 98.44%] [G loss: 6.098615]\n",
      "epoch:38 step:30137 [D loss: 0.148638, acc: 96.88%] [G loss: 5.610564]\n",
      "epoch:38 step:30138 [D loss: 1.691953, acc: 5.47%] [G loss: 7.878506]\n",
      "epoch:38 step:30139 [D loss: 0.037359, acc: 100.00%] [G loss: 7.126197]\n",
      "epoch:38 step:30140 [D loss: 0.119846, acc: 99.22%] [G loss: 4.631132]\n",
      "epoch:38 step:30141 [D loss: 0.338449, acc: 89.84%] [G loss: 5.604658]\n",
      "epoch:38 step:30142 [D loss: 0.118286, acc: 99.22%] [G loss: 2.944182]\n",
      "epoch:38 step:30143 [D loss: 0.206380, acc: 93.75%] [G loss: 4.987819]\n",
      "epoch:38 step:30144 [D loss: 0.025492, acc: 100.00%] [G loss: 5.809367]\n",
      "epoch:38 step:30145 [D loss: 0.391696, acc: 91.41%] [G loss: 4.667854]\n",
      "epoch:38 step:30146 [D loss: 0.045292, acc: 100.00%] [G loss: 6.245144]\n",
      "epoch:38 step:30147 [D loss: 0.121821, acc: 99.22%] [G loss: 3.592104]\n",
      "epoch:38 step:30148 [D loss: 0.311102, acc: 82.03%] [G loss: 5.229878]\n",
      "epoch:38 step:30149 [D loss: 0.029503, acc: 100.00%] [G loss: 4.517258]\n",
      "epoch:38 step:30150 [D loss: 1.606787, acc: 14.06%] [G loss: 6.562091]\n",
      "epoch:38 step:30151 [D loss: 0.187716, acc: 97.66%] [G loss: 4.253042]\n",
      "epoch:38 step:30152 [D loss: 0.453636, acc: 79.69%] [G loss: 3.630927]\n",
      "epoch:38 step:30153 [D loss: 0.489599, acc: 60.94%] [G loss: 9.192114]\n",
      "epoch:38 step:30154 [D loss: 0.268060, acc: 96.09%] [G loss: 4.888144]\n",
      "epoch:38 step:30155 [D loss: 1.057653, acc: 51.56%] [G loss: 8.651431]\n",
      "epoch:38 step:30156 [D loss: 0.034071, acc: 100.00%] [G loss: 5.169526]\n",
      "epoch:38 step:30157 [D loss: 0.964676, acc: 49.22%] [G loss: 6.842331]\n",
      "epoch:38 step:30158 [D loss: 0.210430, acc: 98.44%] [G loss: 4.538247]\n",
      "epoch:38 step:30159 [D loss: 0.580013, acc: 65.62%] [G loss: 4.228915]\n",
      "epoch:38 step:30160 [D loss: 0.375827, acc: 76.56%] [G loss: 4.570721]\n",
      "epoch:38 step:30161 [D loss: 0.528412, acc: 73.44%] [G loss: 6.879999]\n",
      "epoch:38 step:30162 [D loss: 1.127949, acc: 50.78%] [G loss: 8.274786]\n",
      "epoch:38 step:30163 [D loss: 1.413741, acc: 32.81%] [G loss: 3.821859]\n",
      "epoch:38 step:30164 [D loss: 0.109554, acc: 100.00%] [G loss: 6.823717]\n",
      "epoch:38 step:30165 [D loss: 0.189059, acc: 96.09%] [G loss: 4.680215]\n",
      "epoch:38 step:30166 [D loss: 0.138040, acc: 100.00%] [G loss: 3.659383]\n",
      "epoch:38 step:30167 [D loss: 0.184288, acc: 98.44%] [G loss: 5.074424]\n",
      "epoch:38 step:30168 [D loss: 0.105286, acc: 99.22%] [G loss: 5.630211]\n",
      "epoch:38 step:30169 [D loss: 0.445372, acc: 79.69%] [G loss: 2.570644]\n",
      "epoch:38 step:30170 [D loss: 0.654870, acc: 61.72%] [G loss: 6.373014]\n",
      "epoch:38 step:30171 [D loss: 0.086241, acc: 100.00%] [G loss: 3.300614]\n",
      "epoch:38 step:30172 [D loss: 0.055182, acc: 100.00%] [G loss: 7.322109]\n",
      "epoch:38 step:30173 [D loss: 0.157040, acc: 99.22%] [G loss: 3.974357]\n",
      "epoch:38 step:30174 [D loss: 0.590362, acc: 71.09%] [G loss: 3.776264]\n",
      "epoch:38 step:30175 [D loss: 0.112912, acc: 100.00%] [G loss: 4.508996]\n",
      "epoch:38 step:30176 [D loss: 0.079669, acc: 100.00%] [G loss: 6.538705]\n",
      "epoch:38 step:30177 [D loss: 0.086681, acc: 99.22%] [G loss: 3.749640]\n",
      "epoch:38 step:30178 [D loss: 0.419820, acc: 78.12%] [G loss: 5.820798]\n",
      "epoch:38 step:30179 [D loss: 0.376487, acc: 75.78%] [G loss: 7.077566]\n",
      "epoch:38 step:30180 [D loss: 0.183162, acc: 100.00%] [G loss: 4.458274]\n",
      "epoch:38 step:30181 [D loss: 0.247141, acc: 92.97%] [G loss: 5.778018]\n",
      "epoch:38 step:30182 [D loss: 0.340840, acc: 84.38%] [G loss: 5.159963]\n",
      "epoch:38 step:30183 [D loss: 0.225893, acc: 92.19%] [G loss: 2.594181]\n",
      "epoch:38 step:30184 [D loss: 0.062140, acc: 100.00%] [G loss: 4.096398]\n",
      "epoch:38 step:30185 [D loss: 0.239249, acc: 96.09%] [G loss: 4.369080]\n",
      "epoch:38 step:30186 [D loss: 0.410967, acc: 74.22%] [G loss: 5.876812]\n",
      "epoch:38 step:30187 [D loss: 0.148693, acc: 99.22%] [G loss: 3.247722]\n",
      "epoch:38 step:30188 [D loss: 0.309197, acc: 91.41%] [G loss: 5.351726]\n",
      "epoch:38 step:30189 [D loss: 0.151941, acc: 98.44%] [G loss: 6.809169]\n",
      "epoch:38 step:30190 [D loss: 0.120460, acc: 100.00%] [G loss: 6.049958]\n",
      "epoch:38 step:30191 [D loss: 0.238136, acc: 92.19%] [G loss: 5.039550]\n",
      "epoch:38 step:30192 [D loss: 0.249463, acc: 92.97%] [G loss: 8.661644]\n",
      "epoch:38 step:30193 [D loss: 0.522169, acc: 64.84%] [G loss: 5.827612]\n",
      "epoch:38 step:30194 [D loss: 0.050695, acc: 100.00%] [G loss: 6.382379]\n",
      "epoch:38 step:30195 [D loss: 0.140820, acc: 96.09%] [G loss: 7.448920]\n",
      "epoch:38 step:30196 [D loss: 0.064681, acc: 99.22%] [G loss: 5.483117]\n",
      "epoch:38 step:30197 [D loss: 0.149995, acc: 99.22%] [G loss: 3.838284]\n",
      "epoch:38 step:30198 [D loss: 1.090561, acc: 26.56%] [G loss: 8.345018]\n",
      "epoch:38 step:30199 [D loss: 0.368982, acc: 85.94%] [G loss: 5.891476]\n",
      "epoch:38 step:30200 [D loss: 0.468898, acc: 63.28%] [G loss: 5.898072]\n",
      "epoch:38 step:30201 [D loss: 0.585108, acc: 61.72%] [G loss: 6.123255]\n",
      "epoch:38 step:30202 [D loss: 1.087299, acc: 35.16%] [G loss: 6.906015]\n",
      "epoch:38 step:30203 [D loss: 0.545104, acc: 60.94%] [G loss: 5.543865]\n",
      "epoch:38 step:30204 [D loss: 0.358021, acc: 81.25%] [G loss: 5.170500]\n",
      "epoch:38 step:30205 [D loss: 0.190400, acc: 96.09%] [G loss: 2.907545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30206 [D loss: 0.794750, acc: 51.56%] [G loss: 6.184847]\n",
      "epoch:38 step:30207 [D loss: 2.885541, acc: 0.78%] [G loss: 4.811826]\n",
      "epoch:38 step:30208 [D loss: 0.213891, acc: 96.88%] [G loss: 6.284990]\n",
      "epoch:38 step:30209 [D loss: 0.336043, acc: 90.62%] [G loss: 4.037407]\n",
      "epoch:38 step:30210 [D loss: 0.882501, acc: 39.84%] [G loss: 7.180552]\n",
      "epoch:38 step:30211 [D loss: 0.832625, acc: 50.78%] [G loss: 6.032486]\n",
      "epoch:38 step:30212 [D loss: 0.091032, acc: 100.00%] [G loss: 6.650632]\n",
      "epoch:38 step:30213 [D loss: 0.561638, acc: 65.62%] [G loss: 4.435167]\n",
      "epoch:38 step:30214 [D loss: 0.124823, acc: 100.00%] [G loss: 4.482697]\n",
      "epoch:38 step:30215 [D loss: 0.417794, acc: 79.69%] [G loss: 6.890902]\n",
      "epoch:38 step:30216 [D loss: 0.262974, acc: 90.62%] [G loss: 8.960911]\n",
      "epoch:38 step:30217 [D loss: 0.235054, acc: 95.31%] [G loss: 7.438877]\n",
      "epoch:38 step:30218 [D loss: 0.113325, acc: 99.22%] [G loss: 5.051582]\n",
      "epoch:38 step:30219 [D loss: 0.303149, acc: 87.50%] [G loss: 3.088077]\n",
      "epoch:38 step:30220 [D loss: 1.731422, acc: 3.12%] [G loss: 10.511768]\n",
      "epoch:38 step:30221 [D loss: 0.539037, acc: 75.78%] [G loss: 6.344491]\n",
      "epoch:38 step:30222 [D loss: 0.930685, acc: 53.91%] [G loss: 6.682383]\n",
      "epoch:38 step:30223 [D loss: 0.239305, acc: 94.53%] [G loss: 5.438473]\n",
      "epoch:38 step:30224 [D loss: 0.475454, acc: 79.69%] [G loss: 4.358992]\n",
      "epoch:38 step:30225 [D loss: 0.023117, acc: 100.00%] [G loss: 7.191748]\n",
      "epoch:38 step:30226 [D loss: 0.263312, acc: 92.97%] [G loss: 4.171360]\n",
      "epoch:38 step:30227 [D loss: 0.569326, acc: 68.75%] [G loss: 6.611265]\n",
      "epoch:38 step:30228 [D loss: 0.098414, acc: 99.22%] [G loss: 4.849451]\n",
      "epoch:38 step:30229 [D loss: 0.239356, acc: 98.44%] [G loss: 7.249979]\n",
      "epoch:38 step:30230 [D loss: 1.243178, acc: 11.72%] [G loss: 7.052244]\n",
      "epoch:38 step:30231 [D loss: 0.220431, acc: 98.44%] [G loss: 3.175253]\n",
      "epoch:38 step:30232 [D loss: 0.315503, acc: 89.06%] [G loss: 3.216011]\n",
      "epoch:38 step:30233 [D loss: 0.388196, acc: 86.72%] [G loss: 9.427059]\n",
      "epoch:38 step:30234 [D loss: 0.701318, acc: 53.91%] [G loss: 7.780443]\n",
      "epoch:38 step:30235 [D loss: 1.846769, acc: 39.06%] [G loss: 2.954573]\n",
      "epoch:38 step:30236 [D loss: 0.120996, acc: 97.66%] [G loss: 5.367264]\n",
      "epoch:38 step:30237 [D loss: 0.111335, acc: 99.22%] [G loss: 3.810211]\n",
      "epoch:38 step:30238 [D loss: 0.075308, acc: 100.00%] [G loss: 4.187695]\n",
      "epoch:38 step:30239 [D loss: 0.069385, acc: 100.00%] [G loss: 8.553720]\n",
      "epoch:38 step:30240 [D loss: 0.323350, acc: 94.53%] [G loss: 4.715099]\n",
      "epoch:38 step:30241 [D loss: 0.816550, acc: 46.88%] [G loss: 4.525403]\n",
      "epoch:38 step:30242 [D loss: 1.030563, acc: 50.78%] [G loss: 5.751968]\n",
      "epoch:38 step:30243 [D loss: 0.081960, acc: 100.00%] [G loss: 4.367894]\n",
      "epoch:38 step:30244 [D loss: 0.067352, acc: 100.00%] [G loss: 2.783839]\n",
      "epoch:38 step:30245 [D loss: 0.071624, acc: 100.00%] [G loss: 7.753305]\n",
      "epoch:38 step:30246 [D loss: 0.916329, acc: 51.56%] [G loss: 4.666961]\n",
      "epoch:38 step:30247 [D loss: 0.403948, acc: 72.66%] [G loss: 5.767201]\n",
      "epoch:38 step:30248 [D loss: 0.344994, acc: 79.69%] [G loss: 5.186421]\n",
      "epoch:38 step:30249 [D loss: 0.151942, acc: 99.22%] [G loss: 6.800083]\n",
      "epoch:38 step:30250 [D loss: 0.409776, acc: 71.09%] [G loss: 3.966115]\n",
      "epoch:38 step:30251 [D loss: 0.035416, acc: 100.00%] [G loss: 8.003630]\n",
      "epoch:38 step:30252 [D loss: 0.281256, acc: 89.06%] [G loss: 4.614052]\n",
      "epoch:38 step:30253 [D loss: 0.297124, acc: 92.19%] [G loss: 5.106792]\n",
      "epoch:38 step:30254 [D loss: 0.969265, acc: 52.34%] [G loss: 3.006766]\n",
      "epoch:38 step:30255 [D loss: 0.156350, acc: 98.44%] [G loss: 4.014013]\n",
      "epoch:38 step:30256 [D loss: 0.313644, acc: 83.59%] [G loss: 8.224196]\n",
      "epoch:38 step:30257 [D loss: 0.089489, acc: 100.00%] [G loss: 3.980655]\n",
      "epoch:38 step:30258 [D loss: 0.511037, acc: 78.12%] [G loss: 4.299700]\n",
      "epoch:38 step:30259 [D loss: 0.387198, acc: 72.66%] [G loss: 7.022119]\n",
      "epoch:38 step:30260 [D loss: 1.413797, acc: 28.12%] [G loss: 7.306064]\n",
      "epoch:38 step:30261 [D loss: 0.713116, acc: 53.12%] [G loss: 4.833041]\n",
      "epoch:38 step:30262 [D loss: 0.474993, acc: 71.88%] [G loss: 4.995663]\n",
      "epoch:38 step:30263 [D loss: 1.050692, acc: 46.88%] [G loss: 6.644992]\n",
      "epoch:38 step:30264 [D loss: 0.348667, acc: 75.78%] [G loss: 5.439308]\n",
      "epoch:38 step:30265 [D loss: 0.206466, acc: 96.88%] [G loss: 3.098345]\n",
      "epoch:38 step:30266 [D loss: 0.613840, acc: 58.59%] [G loss: 7.156303]\n",
      "epoch:38 step:30267 [D loss: 0.041560, acc: 100.00%] [G loss: 5.407201]\n",
      "epoch:38 step:30268 [D loss: 0.055891, acc: 99.22%] [G loss: 5.927411]\n",
      "epoch:38 step:30269 [D loss: 0.248167, acc: 91.41%] [G loss: 5.366044]\n",
      "epoch:38 step:30270 [D loss: 0.154048, acc: 99.22%] [G loss: 4.855108]\n",
      "epoch:38 step:30271 [D loss: 0.612278, acc: 66.41%] [G loss: 8.155383]\n",
      "epoch:38 step:30272 [D loss: 0.522921, acc: 66.41%] [G loss: 6.789109]\n",
      "epoch:38 step:30273 [D loss: 0.616222, acc: 55.47%] [G loss: 4.265858]\n",
      "epoch:38 step:30274 [D loss: 0.051669, acc: 100.00%] [G loss: 5.970439]\n",
      "epoch:38 step:30275 [D loss: 0.275231, acc: 93.75%] [G loss: 3.283135]\n",
      "epoch:38 step:30276 [D loss: 0.270892, acc: 94.53%] [G loss: 2.530471]\n",
      "epoch:38 step:30277 [D loss: 0.251645, acc: 96.88%] [G loss: 4.421892]\n",
      "epoch:38 step:30278 [D loss: 0.725783, acc: 52.34%] [G loss: 6.753845]\n",
      "epoch:38 step:30279 [D loss: 1.675279, acc: 50.00%] [G loss: 4.855165]\n",
      "epoch:38 step:30280 [D loss: 0.358666, acc: 82.03%] [G loss: 4.324973]\n",
      "epoch:38 step:30281 [D loss: 0.495152, acc: 64.06%] [G loss: 8.497927]\n",
      "epoch:38 step:30282 [D loss: 0.390911, acc: 86.72%] [G loss: 5.755538]\n",
      "epoch:38 step:30283 [D loss: 0.052020, acc: 100.00%] [G loss: 4.223369]\n",
      "epoch:38 step:30284 [D loss: 0.102979, acc: 100.00%] [G loss: 4.699758]\n",
      "epoch:38 step:30285 [D loss: 1.256868, acc: 32.03%] [G loss: 7.518567]\n",
      "epoch:38 step:30286 [D loss: 0.143256, acc: 100.00%] [G loss: 5.856144]\n",
      "epoch:38 step:30287 [D loss: 0.092514, acc: 100.00%] [G loss: 5.434556]\n",
      "epoch:38 step:30288 [D loss: 0.747191, acc: 56.25%] [G loss: 4.500227]\n",
      "epoch:38 step:30289 [D loss: 0.204068, acc: 99.22%] [G loss: 2.316096]\n",
      "epoch:38 step:30290 [D loss: 0.834489, acc: 52.34%] [G loss: 5.800505]\n",
      "epoch:38 step:30291 [D loss: 0.155797, acc: 97.66%] [G loss: 4.296639]\n",
      "epoch:38 step:30292 [D loss: 0.480255, acc: 67.19%] [G loss: 5.197091]\n",
      "epoch:38 step:30293 [D loss: 0.201936, acc: 96.09%] [G loss: 3.990042]\n",
      "epoch:38 step:30294 [D loss: 0.452783, acc: 81.25%] [G loss: 4.254202]\n",
      "epoch:38 step:30295 [D loss: 0.713077, acc: 56.25%] [G loss: 2.884878]\n",
      "epoch:38 step:30296 [D loss: 0.713878, acc: 56.25%] [G loss: 4.537915]\n",
      "epoch:38 step:30297 [D loss: 0.886829, acc: 37.50%] [G loss: 3.840306]\n",
      "epoch:38 step:30298 [D loss: 1.368493, acc: 13.28%] [G loss: 3.818309]\n",
      "epoch:38 step:30299 [D loss: 1.322692, acc: 50.00%] [G loss: 6.389647]\n",
      "epoch:38 step:30300 [D loss: 0.499917, acc: 63.28%] [G loss: 3.587149]\n",
      "epoch:38 step:30301 [D loss: 0.133378, acc: 100.00%] [G loss: 5.653162]\n",
      "epoch:38 step:30302 [D loss: 0.345133, acc: 88.28%] [G loss: 5.111412]\n",
      "epoch:38 step:30303 [D loss: 0.213960, acc: 94.53%] [G loss: 7.117366]\n",
      "epoch:38 step:30304 [D loss: 0.829046, acc: 51.56%] [G loss: 4.961699]\n",
      "epoch:38 step:30305 [D loss: 0.779318, acc: 52.34%] [G loss: 6.883087]\n",
      "epoch:38 step:30306 [D loss: 0.107562, acc: 100.00%] [G loss: 4.534403]\n",
      "epoch:38 step:30307 [D loss: 0.075378, acc: 100.00%] [G loss: 4.463406]\n",
      "epoch:38 step:30308 [D loss: 0.121142, acc: 100.00%] [G loss: 3.944318]\n",
      "epoch:38 step:30309 [D loss: 0.402381, acc: 79.69%] [G loss: 3.328566]\n",
      "epoch:38 step:30310 [D loss: 0.316505, acc: 85.94%] [G loss: 5.032097]\n",
      "epoch:38 step:30311 [D loss: 0.341277, acc: 85.94%] [G loss: 7.067549]\n",
      "epoch:38 step:30312 [D loss: 0.387921, acc: 85.16%] [G loss: 4.302338]\n",
      "epoch:38 step:30313 [D loss: 1.872447, acc: 7.81%] [G loss: 3.265059]\n",
      "epoch:38 step:30314 [D loss: 0.731076, acc: 53.91%] [G loss: 4.509610]\n",
      "epoch:38 step:30315 [D loss: 0.396140, acc: 74.22%] [G loss: 3.479326]\n",
      "epoch:38 step:30316 [D loss: 0.390726, acc: 90.62%] [G loss: 3.747876]\n",
      "epoch:38 step:30317 [D loss: 0.206197, acc: 97.66%] [G loss: 3.788324]\n",
      "epoch:38 step:30318 [D loss: 0.114937, acc: 100.00%] [G loss: 3.774651]\n",
      "epoch:38 step:30319 [D loss: 0.099408, acc: 100.00%] [G loss: 7.402546]\n",
      "epoch:38 step:30320 [D loss: 0.159763, acc: 99.22%] [G loss: 6.143359]\n",
      "epoch:38 step:30321 [D loss: 0.364809, acc: 82.03%] [G loss: 5.613575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30322 [D loss: 0.691126, acc: 52.34%] [G loss: 4.125870]\n",
      "epoch:38 step:30323 [D loss: 0.035854, acc: 100.00%] [G loss: 4.695984]\n",
      "epoch:38 step:30324 [D loss: 0.560261, acc: 74.22%] [G loss: 3.940803]\n",
      "epoch:38 step:30325 [D loss: 0.549239, acc: 72.66%] [G loss: 5.257358]\n",
      "epoch:38 step:30326 [D loss: 0.421681, acc: 85.94%] [G loss: 3.910319]\n",
      "epoch:38 step:30327 [D loss: 0.456827, acc: 69.53%] [G loss: 6.592849]\n",
      "epoch:38 step:30328 [D loss: 0.283563, acc: 87.50%] [G loss: 6.780945]\n",
      "epoch:38 step:30329 [D loss: 0.293587, acc: 93.75%] [G loss: 4.275932]\n",
      "epoch:38 step:30330 [D loss: 0.286101, acc: 97.66%] [G loss: 4.466208]\n",
      "epoch:38 step:30331 [D loss: 0.475879, acc: 68.75%] [G loss: 4.974498]\n",
      "epoch:38 step:30332 [D loss: 0.113160, acc: 99.22%] [G loss: 5.607654]\n",
      "epoch:38 step:30333 [D loss: 0.214477, acc: 97.66%] [G loss: 5.890266]\n",
      "epoch:38 step:30334 [D loss: 0.561651, acc: 64.06%] [G loss: 3.018063]\n",
      "epoch:38 step:30335 [D loss: 0.299872, acc: 92.97%] [G loss: 3.692857]\n",
      "epoch:38 step:30336 [D loss: 1.286354, acc: 33.59%] [G loss: 6.607608]\n",
      "epoch:38 step:30337 [D loss: 0.057324, acc: 100.00%] [G loss: 3.364844]\n",
      "epoch:38 step:30338 [D loss: 0.399909, acc: 84.38%] [G loss: 3.774892]\n",
      "epoch:38 step:30339 [D loss: 0.783186, acc: 52.34%] [G loss: 4.448349]\n",
      "epoch:38 step:30340 [D loss: 0.507421, acc: 78.91%] [G loss: 3.004164]\n",
      "epoch:38 step:30341 [D loss: 0.149243, acc: 98.44%] [G loss: 3.620479]\n",
      "epoch:38 step:30342 [D loss: 0.223901, acc: 97.66%] [G loss: 5.180814]\n",
      "epoch:38 step:30343 [D loss: 0.189619, acc: 99.22%] [G loss: 4.063068]\n",
      "epoch:38 step:30344 [D loss: 0.652209, acc: 62.50%] [G loss: 3.834851]\n",
      "epoch:38 step:30345 [D loss: 0.254398, acc: 96.88%] [G loss: 4.824642]\n",
      "epoch:38 step:30346 [D loss: 0.736828, acc: 56.25%] [G loss: 4.330221]\n",
      "epoch:38 step:30347 [D loss: 0.885496, acc: 50.78%] [G loss: 6.334615]\n",
      "epoch:38 step:30348 [D loss: 0.188563, acc: 95.31%] [G loss: 7.268022]\n",
      "epoch:38 step:30349 [D loss: 0.073314, acc: 100.00%] [G loss: 6.582431]\n",
      "epoch:38 step:30350 [D loss: 0.164117, acc: 97.66%] [G loss: 4.905785]\n",
      "epoch:38 step:30351 [D loss: 0.082181, acc: 99.22%] [G loss: 5.906718]\n",
      "epoch:38 step:30352 [D loss: 0.173299, acc: 96.09%] [G loss: 6.161365]\n",
      "epoch:38 step:30353 [D loss: 0.062497, acc: 100.00%] [G loss: 4.497808]\n",
      "epoch:38 step:30354 [D loss: 0.134513, acc: 100.00%] [G loss: 4.883047]\n",
      "epoch:38 step:30355 [D loss: 0.378288, acc: 84.38%] [G loss: 4.656829]\n",
      "epoch:38 step:30356 [D loss: 0.216566, acc: 95.31%] [G loss: 2.761284]\n",
      "epoch:38 step:30357 [D loss: 0.576801, acc: 61.72%] [G loss: 5.932433]\n",
      "epoch:38 step:30358 [D loss: 0.237270, acc: 97.66%] [G loss: 4.695732]\n",
      "epoch:38 step:30359 [D loss: 0.313240, acc: 93.75%] [G loss: 3.862004]\n",
      "epoch:38 step:30360 [D loss: 0.174931, acc: 96.09%] [G loss: 4.117402]\n",
      "epoch:38 step:30361 [D loss: 0.030012, acc: 100.00%] [G loss: 3.951356]\n",
      "epoch:38 step:30362 [D loss: 0.220449, acc: 97.66%] [G loss: 1.466832]\n",
      "epoch:38 step:30363 [D loss: 0.433666, acc: 74.22%] [G loss: 6.685680]\n",
      "epoch:38 step:30364 [D loss: 0.712361, acc: 57.03%] [G loss: 4.706107]\n",
      "epoch:38 step:30365 [D loss: 0.633479, acc: 61.72%] [G loss: 2.742390]\n",
      "epoch:38 step:30366 [D loss: 0.208214, acc: 100.00%] [G loss: 4.140000]\n",
      "epoch:38 step:30367 [D loss: 0.129221, acc: 99.22%] [G loss: 4.285333]\n",
      "epoch:38 step:30368 [D loss: 0.110568, acc: 100.00%] [G loss: 5.578999]\n",
      "epoch:38 step:30369 [D loss: 0.568240, acc: 64.84%] [G loss: 7.261932]\n",
      "epoch:38 step:30370 [D loss: 0.097610, acc: 100.00%] [G loss: 5.516230]\n",
      "epoch:38 step:30371 [D loss: 0.547197, acc: 73.44%] [G loss: 3.473129]\n",
      "epoch:38 step:30372 [D loss: 0.067855, acc: 100.00%] [G loss: 3.559960]\n",
      "epoch:38 step:30373 [D loss: 0.193276, acc: 98.44%] [G loss: 6.250199]\n",
      "epoch:38 step:30374 [D loss: 0.125817, acc: 99.22%] [G loss: 2.689128]\n",
      "epoch:38 step:30375 [D loss: 0.138948, acc: 99.22%] [G loss: 4.649254]\n",
      "epoch:38 step:30376 [D loss: 0.328393, acc: 91.41%] [G loss: 3.820824]\n",
      "epoch:38 step:30377 [D loss: 0.223040, acc: 97.66%] [G loss: 5.487989]\n",
      "epoch:38 step:30378 [D loss: 0.892739, acc: 51.56%] [G loss: 8.230605]\n",
      "epoch:38 step:30379 [D loss: 1.652354, acc: 50.00%] [G loss: 2.543552]\n",
      "epoch:38 step:30380 [D loss: 0.807566, acc: 54.69%] [G loss: 4.202808]\n",
      "epoch:38 step:30381 [D loss: 0.711175, acc: 57.03%] [G loss: 3.788669]\n",
      "epoch:38 step:30382 [D loss: 0.131978, acc: 99.22%] [G loss: 5.268654]\n",
      "epoch:38 step:30383 [D loss: 0.187741, acc: 97.66%] [G loss: 4.304953]\n",
      "epoch:38 step:30384 [D loss: 0.141094, acc: 98.44%] [G loss: 2.899402]\n",
      "epoch:38 step:30385 [D loss: 0.152025, acc: 100.00%] [G loss: 5.589565]\n",
      "epoch:38 step:30386 [D loss: 0.267446, acc: 90.62%] [G loss: 4.081948]\n",
      "epoch:38 step:30387 [D loss: 0.413427, acc: 86.72%] [G loss: 6.818279]\n",
      "epoch:38 step:30388 [D loss: 1.155219, acc: 50.00%] [G loss: 3.284275]\n",
      "epoch:38 step:30389 [D loss: 0.100825, acc: 99.22%] [G loss: 5.465559]\n",
      "epoch:38 step:30390 [D loss: 1.592821, acc: 45.31%] [G loss: 3.702240]\n",
      "epoch:38 step:30391 [D loss: 0.115573, acc: 99.22%] [G loss: 6.103645]\n",
      "epoch:38 step:30392 [D loss: 0.129064, acc: 98.44%] [G loss: 6.675113]\n",
      "epoch:38 step:30393 [D loss: 0.281185, acc: 94.53%] [G loss: 3.905777]\n",
      "epoch:38 step:30394 [D loss: 0.295897, acc: 95.31%] [G loss: 6.869063]\n",
      "epoch:38 step:30395 [D loss: 0.171979, acc: 96.88%] [G loss: 6.279148]\n",
      "epoch:38 step:30396 [D loss: 0.193570, acc: 98.44%] [G loss: 3.434555]\n",
      "epoch:38 step:30397 [D loss: 0.109615, acc: 99.22%] [G loss: 2.817246]\n",
      "epoch:38 step:30398 [D loss: 0.140297, acc: 99.22%] [G loss: 3.531767]\n",
      "epoch:38 step:30399 [D loss: 0.269892, acc: 96.88%] [G loss: 3.731576]\n",
      "epoch:38 step:30400 [D loss: 0.218838, acc: 95.31%] [G loss: 5.213169]\n",
      "epoch:38 step:30401 [D loss: 0.142910, acc: 100.00%] [G loss: 6.517342]\n",
      "epoch:38 step:30402 [D loss: 1.396116, acc: 19.53%] [G loss: 4.804527]\n",
      "epoch:38 step:30403 [D loss: 0.230350, acc: 99.22%] [G loss: 4.227103]\n",
      "epoch:38 step:30404 [D loss: 0.195447, acc: 99.22%] [G loss: 4.306820]\n",
      "epoch:38 step:30405 [D loss: 0.206931, acc: 99.22%] [G loss: 5.580941]\n",
      "epoch:38 step:30406 [D loss: 0.438359, acc: 72.66%] [G loss: 6.031413]\n",
      "epoch:38 step:30407 [D loss: 0.194473, acc: 99.22%] [G loss: 3.078785]\n",
      "epoch:38 step:30408 [D loss: 0.111817, acc: 100.00%] [G loss: 4.136154]\n",
      "epoch:38 step:30409 [D loss: 1.082713, acc: 39.06%] [G loss: 3.773481]\n",
      "epoch:38 step:30410 [D loss: 0.424013, acc: 87.50%] [G loss: 6.922367]\n",
      "epoch:38 step:30411 [D loss: 0.241294, acc: 92.97%] [G loss: 2.620072]\n",
      "epoch:38 step:30412 [D loss: 0.691480, acc: 57.81%] [G loss: 4.949401]\n",
      "epoch:38 step:30413 [D loss: 0.133848, acc: 100.00%] [G loss: 2.700903]\n",
      "epoch:38 step:30414 [D loss: 0.172541, acc: 99.22%] [G loss: 3.681425]\n",
      "epoch:38 step:30415 [D loss: 0.839723, acc: 46.09%] [G loss: 6.768289]\n",
      "epoch:38 step:30416 [D loss: 0.449664, acc: 80.47%] [G loss: 4.594721]\n",
      "epoch:38 step:30417 [D loss: 0.964335, acc: 32.81%] [G loss: 4.156724]\n",
      "epoch:38 step:30418 [D loss: 0.270969, acc: 94.53%] [G loss: 3.290700]\n",
      "epoch:38 step:30419 [D loss: 0.119171, acc: 99.22%] [G loss: 3.707412]\n",
      "epoch:38 step:30420 [D loss: 0.470336, acc: 79.69%] [G loss: 2.731264]\n",
      "epoch:38 step:30421 [D loss: 0.206387, acc: 97.66%] [G loss: 3.606905]\n",
      "epoch:38 step:30422 [D loss: 1.674831, acc: 50.00%] [G loss: 5.407041]\n",
      "epoch:38 step:30423 [D loss: 0.877374, acc: 53.12%] [G loss: 7.576957]\n",
      "epoch:38 step:30424 [D loss: 0.121162, acc: 99.22%] [G loss: 3.213402]\n",
      "epoch:38 step:30425 [D loss: 0.888549, acc: 37.50%] [G loss: 6.011747]\n",
      "epoch:38 step:30426 [D loss: 0.289816, acc: 97.66%] [G loss: 5.712559]\n",
      "epoch:38 step:30427 [D loss: 0.180964, acc: 100.00%] [G loss: 2.805686]\n",
      "epoch:38 step:30428 [D loss: 0.396287, acc: 78.12%] [G loss: 4.155334]\n",
      "epoch:38 step:30429 [D loss: 0.079991, acc: 100.00%] [G loss: 3.843632]\n",
      "epoch:38 step:30430 [D loss: 0.382809, acc: 74.22%] [G loss: 3.963957]\n",
      "epoch:38 step:30431 [D loss: 0.208074, acc: 97.66%] [G loss: 4.253192]\n",
      "epoch:38 step:30432 [D loss: 0.529413, acc: 75.78%] [G loss: 4.193580]\n",
      "epoch:38 step:30433 [D loss: 0.693032, acc: 52.34%] [G loss: 3.385625]\n",
      "epoch:38 step:30434 [D loss: 0.147999, acc: 99.22%] [G loss: 3.697136]\n",
      "epoch:38 step:30435 [D loss: 0.728092, acc: 53.12%] [G loss: 4.919312]\n",
      "epoch:38 step:30436 [D loss: 0.267353, acc: 86.72%] [G loss: 5.812512]\n",
      "epoch:38 step:30437 [D loss: 0.201709, acc: 94.53%] [G loss: 6.520551]\n",
      "epoch:38 step:30438 [D loss: 0.041742, acc: 100.00%] [G loss: 6.717589]\n",
      "epoch:38 step:30439 [D loss: 0.119629, acc: 100.00%] [G loss: 3.080856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30440 [D loss: 0.383598, acc: 85.16%] [G loss: 4.437344]\n",
      "epoch:38 step:30441 [D loss: 0.197709, acc: 99.22%] [G loss: 4.332275]\n",
      "epoch:38 step:30442 [D loss: 0.739411, acc: 53.12%] [G loss: 4.771749]\n",
      "epoch:38 step:30443 [D loss: 0.049525, acc: 100.00%] [G loss: 7.565466]\n",
      "epoch:38 step:30444 [D loss: 0.272030, acc: 96.88%] [G loss: 3.054385]\n",
      "epoch:38 step:30445 [D loss: 0.230299, acc: 96.09%] [G loss: 6.260626]\n",
      "epoch:38 step:30446 [D loss: 0.146400, acc: 99.22%] [G loss: 4.066757]\n",
      "epoch:38 step:30447 [D loss: 0.278221, acc: 96.88%] [G loss: 2.957081]\n",
      "epoch:38 step:30448 [D loss: 0.138464, acc: 100.00%] [G loss: 3.886094]\n",
      "epoch:38 step:30449 [D loss: 0.446590, acc: 71.88%] [G loss: 4.384105]\n",
      "epoch:38 step:30450 [D loss: 0.897053, acc: 53.12%] [G loss: 2.954772]\n",
      "epoch:38 step:30451 [D loss: 0.017641, acc: 100.00%] [G loss: 4.417338]\n",
      "epoch:38 step:30452 [D loss: 0.529742, acc: 68.75%] [G loss: 6.315359]\n",
      "epoch:38 step:30453 [D loss: 0.548310, acc: 64.84%] [G loss: 5.489205]\n",
      "epoch:38 step:30454 [D loss: 1.288617, acc: 14.84%] [G loss: 3.889666]\n",
      "epoch:38 step:30455 [D loss: 0.312774, acc: 91.41%] [G loss: 5.389421]\n",
      "epoch:38 step:30456 [D loss: 0.251918, acc: 96.88%] [G loss: 3.329481]\n",
      "epoch:38 step:30457 [D loss: 1.198570, acc: 16.41%] [G loss: 6.541008]\n",
      "epoch:38 step:30458 [D loss: 0.102422, acc: 99.22%] [G loss: 5.660147]\n",
      "epoch:38 step:30459 [D loss: 0.104921, acc: 100.00%] [G loss: 3.888740]\n",
      "epoch:39 step:30460 [D loss: 0.798726, acc: 52.34%] [G loss: 3.138797]\n",
      "epoch:39 step:30461 [D loss: 0.194324, acc: 99.22%] [G loss: 5.697419]\n",
      "epoch:39 step:30462 [D loss: 0.516688, acc: 60.94%] [G loss: 4.319979]\n",
      "epoch:39 step:30463 [D loss: 0.195955, acc: 97.66%] [G loss: 3.752602]\n",
      "epoch:39 step:30464 [D loss: 0.305134, acc: 94.53%] [G loss: 4.461623]\n",
      "epoch:39 step:30465 [D loss: 0.282447, acc: 92.97%] [G loss: 5.269063]\n",
      "epoch:39 step:30466 [D loss: 0.354128, acc: 87.50%] [G loss: 3.699835]\n",
      "epoch:39 step:30467 [D loss: 1.100440, acc: 20.31%] [G loss: 6.196227]\n",
      "epoch:39 step:30468 [D loss: 0.197827, acc: 97.66%] [G loss: 2.664857]\n",
      "epoch:39 step:30469 [D loss: 0.152845, acc: 99.22%] [G loss: 7.340149]\n",
      "epoch:39 step:30470 [D loss: 0.142857, acc: 99.22%] [G loss: 4.009528]\n",
      "epoch:39 step:30471 [D loss: 0.089126, acc: 100.00%] [G loss: 2.862673]\n",
      "epoch:39 step:30472 [D loss: 0.194014, acc: 96.09%] [G loss: 6.947126]\n",
      "epoch:39 step:30473 [D loss: 0.208916, acc: 96.88%] [G loss: 3.962816]\n",
      "epoch:39 step:30474 [D loss: 0.183596, acc: 98.44%] [G loss: 2.713736]\n",
      "epoch:39 step:30475 [D loss: 0.065857, acc: 100.00%] [G loss: 3.987166]\n",
      "epoch:39 step:30476 [D loss: 1.138932, acc: 50.78%] [G loss: 5.974566]\n",
      "epoch:39 step:30477 [D loss: 0.635534, acc: 59.38%] [G loss: 3.580552]\n",
      "epoch:39 step:30478 [D loss: 0.372186, acc: 90.62%] [G loss: 4.321671]\n",
      "epoch:39 step:30479 [D loss: 0.910367, acc: 45.31%] [G loss: 2.288835]\n",
      "epoch:39 step:30480 [D loss: 0.356934, acc: 75.78%] [G loss: 5.707059]\n",
      "epoch:39 step:30481 [D loss: 0.127781, acc: 99.22%] [G loss: 5.510651]\n",
      "epoch:39 step:30482 [D loss: 1.046672, acc: 32.03%] [G loss: 4.890863]\n",
      "epoch:39 step:30483 [D loss: 0.367567, acc: 92.97%] [G loss: 6.138694]\n",
      "epoch:39 step:30484 [D loss: 0.467224, acc: 76.56%] [G loss: 5.586023]\n",
      "epoch:39 step:30485 [D loss: 0.701574, acc: 54.69%] [G loss: 5.498571]\n",
      "epoch:39 step:30486 [D loss: 0.119816, acc: 99.22%] [G loss: 4.467844]\n",
      "epoch:39 step:30487 [D loss: 0.056845, acc: 100.00%] [G loss: 3.826469]\n",
      "epoch:39 step:30488 [D loss: 0.261106, acc: 94.53%] [G loss: 4.538837]\n",
      "epoch:39 step:30489 [D loss: 0.054432, acc: 100.00%] [G loss: 3.965287]\n",
      "epoch:39 step:30490 [D loss: 0.119712, acc: 99.22%] [G loss: 5.246815]\n",
      "epoch:39 step:30491 [D loss: 0.111780, acc: 100.00%] [G loss: 2.408848]\n",
      "epoch:39 step:30492 [D loss: 0.263907, acc: 94.53%] [G loss: 4.884136]\n",
      "epoch:39 step:30493 [D loss: 0.333472, acc: 95.31%] [G loss: 3.932445]\n",
      "epoch:39 step:30494 [D loss: 0.306157, acc: 89.06%] [G loss: 4.860665]\n",
      "epoch:39 step:30495 [D loss: 0.144995, acc: 99.22%] [G loss: 2.168902]\n",
      "epoch:39 step:30496 [D loss: 0.107914, acc: 99.22%] [G loss: 4.748520]\n",
      "epoch:39 step:30497 [D loss: 0.433799, acc: 75.00%] [G loss: 4.470599]\n",
      "epoch:39 step:30498 [D loss: 0.624905, acc: 68.75%] [G loss: 5.878798]\n",
      "epoch:39 step:30499 [D loss: 0.433122, acc: 78.91%] [G loss: 8.193838]\n",
      "epoch:39 step:30500 [D loss: 0.391422, acc: 83.59%] [G loss: 4.580275]\n",
      "epoch:39 step:30501 [D loss: 0.564128, acc: 58.59%] [G loss: 2.857867]\n",
      "epoch:39 step:30502 [D loss: 0.102018, acc: 100.00%] [G loss: 4.186230]\n",
      "epoch:39 step:30503 [D loss: 0.229861, acc: 99.22%] [G loss: 4.932987]\n",
      "epoch:39 step:30504 [D loss: 0.176775, acc: 96.88%] [G loss: 5.082029]\n",
      "epoch:39 step:30505 [D loss: 0.035462, acc: 100.00%] [G loss: 4.906545]\n",
      "epoch:39 step:30506 [D loss: 0.639059, acc: 61.72%] [G loss: 6.235283]\n",
      "epoch:39 step:30507 [D loss: 0.739110, acc: 55.47%] [G loss: 3.193609]\n",
      "epoch:39 step:30508 [D loss: 0.427155, acc: 68.75%] [G loss: 5.190539]\n",
      "epoch:39 step:30509 [D loss: 0.426806, acc: 88.28%] [G loss: 1.467547]\n",
      "epoch:39 step:30510 [D loss: 0.135465, acc: 99.22%] [G loss: 2.975349]\n",
      "epoch:39 step:30511 [D loss: 0.165239, acc: 98.44%] [G loss: 4.003820]\n",
      "epoch:39 step:30512 [D loss: 0.454131, acc: 74.22%] [G loss: 3.716352]\n",
      "epoch:39 step:30513 [D loss: 0.734769, acc: 54.69%] [G loss: 5.362058]\n",
      "epoch:39 step:30514 [D loss: 0.163459, acc: 98.44%] [G loss: 7.958323]\n",
      "epoch:39 step:30515 [D loss: 0.805446, acc: 53.12%] [G loss: 4.789753]\n",
      "epoch:39 step:30516 [D loss: 0.107133, acc: 100.00%] [G loss: 3.841925]\n",
      "epoch:39 step:30517 [D loss: 0.075921, acc: 100.00%] [G loss: 4.687179]\n",
      "epoch:39 step:30518 [D loss: 0.356864, acc: 80.47%] [G loss: 4.123416]\n",
      "epoch:39 step:30519 [D loss: 0.412832, acc: 89.84%] [G loss: 5.515662]\n",
      "epoch:39 step:30520 [D loss: 0.177002, acc: 96.88%] [G loss: 7.097812]\n",
      "epoch:39 step:30521 [D loss: 0.034534, acc: 100.00%] [G loss: 4.433504]\n",
      "epoch:39 step:30522 [D loss: 0.547077, acc: 59.38%] [G loss: 3.971508]\n",
      "epoch:39 step:30523 [D loss: 0.495946, acc: 60.94%] [G loss: 6.033195]\n",
      "epoch:39 step:30524 [D loss: 0.164191, acc: 99.22%] [G loss: 3.292321]\n",
      "epoch:39 step:30525 [D loss: 0.591129, acc: 68.75%] [G loss: 5.602407]\n",
      "epoch:39 step:30526 [D loss: 0.284918, acc: 96.88%] [G loss: 4.906129]\n",
      "epoch:39 step:30527 [D loss: 0.174680, acc: 100.00%] [G loss: 2.076613]\n",
      "epoch:39 step:30528 [D loss: 0.300280, acc: 92.97%] [G loss: 3.109154]\n",
      "epoch:39 step:30529 [D loss: 0.038374, acc: 100.00%] [G loss: 5.763965]\n",
      "epoch:39 step:30530 [D loss: 0.654034, acc: 51.56%] [G loss: 5.963005]\n",
      "epoch:39 step:30531 [D loss: 0.973417, acc: 48.44%] [G loss: 5.472543]\n",
      "epoch:39 step:30532 [D loss: 0.385276, acc: 80.47%] [G loss: 3.089757]\n",
      "epoch:39 step:30533 [D loss: 0.421654, acc: 75.78%] [G loss: 7.059283]\n",
      "epoch:39 step:30534 [D loss: 0.575777, acc: 65.62%] [G loss: 5.428742]\n",
      "epoch:39 step:30535 [D loss: 0.822660, acc: 50.78%] [G loss: 5.936479]\n",
      "epoch:39 step:30536 [D loss: 0.955037, acc: 51.56%] [G loss: 5.762489]\n",
      "epoch:39 step:30537 [D loss: 0.795466, acc: 52.34%] [G loss: 4.997773]\n",
      "epoch:39 step:30538 [D loss: 0.082309, acc: 100.00%] [G loss: 3.207656]\n",
      "epoch:39 step:30539 [D loss: 1.043367, acc: 50.00%] [G loss: 3.887915]\n",
      "epoch:39 step:30540 [D loss: 0.924073, acc: 47.66%] [G loss: 4.664842]\n",
      "epoch:39 step:30541 [D loss: 0.479622, acc: 73.44%] [G loss: 6.900814]\n",
      "epoch:39 step:30542 [D loss: 0.276298, acc: 98.44%] [G loss: 4.112771]\n",
      "epoch:39 step:30543 [D loss: 1.313856, acc: 29.69%] [G loss: 8.617977]\n",
      "epoch:39 step:30544 [D loss: 0.091492, acc: 99.22%] [G loss: 4.177030]\n",
      "epoch:39 step:30545 [D loss: 0.130712, acc: 99.22%] [G loss: 7.136522]\n",
      "epoch:39 step:30546 [D loss: 0.104076, acc: 100.00%] [G loss: 3.529680]\n",
      "epoch:39 step:30547 [D loss: 0.098861, acc: 100.00%] [G loss: 3.912303]\n",
      "epoch:39 step:30548 [D loss: 0.108300, acc: 99.22%] [G loss: 6.626386]\n",
      "epoch:39 step:30549 [D loss: 0.120396, acc: 97.66%] [G loss: 3.289351]\n",
      "epoch:39 step:30550 [D loss: 0.049861, acc: 100.00%] [G loss: 8.915222]\n",
      "epoch:39 step:30551 [D loss: 0.244660, acc: 94.53%] [G loss: 5.838769]\n",
      "epoch:39 step:30552 [D loss: 0.065619, acc: 100.00%] [G loss: 7.117230]\n",
      "epoch:39 step:30553 [D loss: 0.121393, acc: 99.22%] [G loss: 5.724277]\n",
      "epoch:39 step:30554 [D loss: 0.361802, acc: 82.81%] [G loss: 3.920272]\n",
      "epoch:39 step:30555 [D loss: 0.119847, acc: 99.22%] [G loss: 5.194948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30556 [D loss: 0.296818, acc: 93.75%] [G loss: 4.268619]\n",
      "epoch:39 step:30557 [D loss: 0.282326, acc: 94.53%] [G loss: 2.798980]\n",
      "epoch:39 step:30558 [D loss: 0.136416, acc: 96.88%] [G loss: 6.869879]\n",
      "epoch:39 step:30559 [D loss: 0.308006, acc: 93.75%] [G loss: 7.622272]\n",
      "epoch:39 step:30560 [D loss: 0.218431, acc: 94.53%] [G loss: 5.778321]\n",
      "epoch:39 step:30561 [D loss: 0.036277, acc: 100.00%] [G loss: 3.898240]\n",
      "epoch:39 step:30562 [D loss: 0.226138, acc: 96.09%] [G loss: 6.007607]\n",
      "epoch:39 step:30563 [D loss: 0.165249, acc: 99.22%] [G loss: 4.925970]\n",
      "epoch:39 step:30564 [D loss: 0.225074, acc: 100.00%] [G loss: 4.344236]\n",
      "epoch:39 step:30565 [D loss: 0.580268, acc: 60.16%] [G loss: 4.848292]\n",
      "epoch:39 step:30566 [D loss: 1.186424, acc: 21.09%] [G loss: 5.600828]\n",
      "epoch:39 step:30567 [D loss: 0.318635, acc: 87.50%] [G loss: 3.647530]\n",
      "epoch:39 step:30568 [D loss: 0.290042, acc: 91.41%] [G loss: 5.346549]\n",
      "epoch:39 step:30569 [D loss: 0.124526, acc: 97.66%] [G loss: 4.189424]\n",
      "epoch:39 step:30570 [D loss: 0.163622, acc: 98.44%] [G loss: 5.639668]\n",
      "epoch:39 step:30571 [D loss: 0.468367, acc: 78.91%] [G loss: 7.789627]\n",
      "epoch:39 step:30572 [D loss: 0.248591, acc: 93.75%] [G loss: 4.918863]\n",
      "epoch:39 step:30573 [D loss: 0.748608, acc: 53.12%] [G loss: 4.739390]\n",
      "epoch:39 step:30574 [D loss: 0.433907, acc: 73.44%] [G loss: 6.690555]\n",
      "epoch:39 step:30575 [D loss: 0.213386, acc: 97.66%] [G loss: 6.319445]\n",
      "epoch:39 step:30576 [D loss: 0.152494, acc: 98.44%] [G loss: 5.727904]\n",
      "epoch:39 step:30577 [D loss: 0.235931, acc: 96.09%] [G loss: 4.830855]\n",
      "epoch:39 step:30578 [D loss: 0.213678, acc: 96.09%] [G loss: 3.406996]\n",
      "epoch:39 step:30579 [D loss: 0.811856, acc: 43.75%] [G loss: 5.417645]\n",
      "epoch:39 step:30580 [D loss: 0.335943, acc: 91.41%] [G loss: 5.612812]\n",
      "epoch:39 step:30581 [D loss: 1.518418, acc: 25.78%] [G loss: 5.029581]\n",
      "epoch:39 step:30582 [D loss: 0.432849, acc: 73.44%] [G loss: 6.117426]\n",
      "epoch:39 step:30583 [D loss: 0.033830, acc: 100.00%] [G loss: 5.189222]\n",
      "epoch:39 step:30584 [D loss: 0.081791, acc: 100.00%] [G loss: 4.758199]\n",
      "epoch:39 step:30585 [D loss: 0.434607, acc: 71.88%] [G loss: 5.574775]\n",
      "epoch:39 step:30586 [D loss: 0.460138, acc: 85.16%] [G loss: 2.739362]\n",
      "epoch:39 step:30587 [D loss: 0.276960, acc: 93.75%] [G loss: 3.682811]\n",
      "epoch:39 step:30588 [D loss: 1.489596, acc: 28.91%] [G loss: 7.522541]\n",
      "epoch:39 step:30589 [D loss: 0.396498, acc: 89.84%] [G loss: 4.702019]\n",
      "epoch:39 step:30590 [D loss: 0.453617, acc: 80.47%] [G loss: 4.708931]\n",
      "epoch:39 step:30591 [D loss: 0.263702, acc: 96.09%] [G loss: 2.522987]\n",
      "epoch:39 step:30592 [D loss: 0.365350, acc: 89.06%] [G loss: 4.118176]\n",
      "epoch:39 step:30593 [D loss: 0.121719, acc: 100.00%] [G loss: 6.414045]\n",
      "epoch:39 step:30594 [D loss: 0.148310, acc: 99.22%] [G loss: 5.840452]\n",
      "epoch:39 step:30595 [D loss: 0.616570, acc: 67.19%] [G loss: 5.346622]\n",
      "epoch:39 step:30596 [D loss: 0.072822, acc: 100.00%] [G loss: 5.042824]\n",
      "epoch:39 step:30597 [D loss: 0.036793, acc: 100.00%] [G loss: 2.578663]\n",
      "epoch:39 step:30598 [D loss: 0.571982, acc: 75.00%] [G loss: 3.587473]\n",
      "epoch:39 step:30599 [D loss: 0.522830, acc: 68.75%] [G loss: 3.243314]\n",
      "epoch:39 step:30600 [D loss: 0.325724, acc: 82.81%] [G loss: 4.429820]\n",
      "epoch:39 step:30601 [D loss: 0.322909, acc: 95.31%] [G loss: 5.639477]\n",
      "epoch:39 step:30602 [D loss: 0.394787, acc: 89.06%] [G loss: 4.256457]\n",
      "epoch:39 step:30603 [D loss: 0.393335, acc: 78.91%] [G loss: 4.184319]\n",
      "epoch:39 step:30604 [D loss: 0.510731, acc: 69.53%] [G loss: 4.716147]\n",
      "epoch:39 step:30605 [D loss: 0.020127, acc: 100.00%] [G loss: 3.306617]\n",
      "epoch:39 step:30606 [D loss: 0.768412, acc: 52.34%] [G loss: 5.329490]\n",
      "epoch:39 step:30607 [D loss: 0.142442, acc: 99.22%] [G loss: 3.399617]\n",
      "epoch:39 step:30608 [D loss: 0.133714, acc: 100.00%] [G loss: 5.848233]\n",
      "epoch:39 step:30609 [D loss: 0.072980, acc: 100.00%] [G loss: 5.754876]\n",
      "epoch:39 step:30610 [D loss: 0.131847, acc: 100.00%] [G loss: 3.294978]\n",
      "epoch:39 step:30611 [D loss: 0.041147, acc: 100.00%] [G loss: 4.302775]\n",
      "epoch:39 step:30612 [D loss: 0.208863, acc: 95.31%] [G loss: 4.761851]\n",
      "epoch:39 step:30613 [D loss: 0.062260, acc: 100.00%] [G loss: 9.211685]\n",
      "epoch:39 step:30614 [D loss: 0.885812, acc: 34.38%] [G loss: 4.567186]\n",
      "epoch:39 step:30615 [D loss: 0.615077, acc: 62.50%] [G loss: 5.591395]\n",
      "epoch:39 step:30616 [D loss: 0.223808, acc: 92.97%] [G loss: 4.079354]\n",
      "epoch:39 step:30617 [D loss: 0.129865, acc: 98.44%] [G loss: 5.253573]\n",
      "epoch:39 step:30618 [D loss: 0.326425, acc: 83.59%] [G loss: 5.159815]\n",
      "epoch:39 step:30619 [D loss: 0.235936, acc: 99.22%] [G loss: 3.233344]\n",
      "epoch:39 step:30620 [D loss: 0.025867, acc: 100.00%] [G loss: 5.916177]\n",
      "epoch:39 step:30621 [D loss: 0.223848, acc: 95.31%] [G loss: 4.145451]\n",
      "epoch:39 step:30622 [D loss: 0.237721, acc: 95.31%] [G loss: 4.795622]\n",
      "epoch:39 step:30623 [D loss: 0.025468, acc: 100.00%] [G loss: 4.842484]\n",
      "epoch:39 step:30624 [D loss: 0.434462, acc: 77.34%] [G loss: 3.657695]\n",
      "epoch:39 step:30625 [D loss: 0.119752, acc: 99.22%] [G loss: 4.558336]\n",
      "epoch:39 step:30626 [D loss: 0.253549, acc: 94.53%] [G loss: 3.952184]\n",
      "epoch:39 step:30627 [D loss: 0.191843, acc: 97.66%] [G loss: 3.302372]\n",
      "epoch:39 step:30628 [D loss: 0.317799, acc: 86.72%] [G loss: 5.973842]\n",
      "epoch:39 step:30629 [D loss: 0.289196, acc: 96.88%] [G loss: 5.847592]\n",
      "epoch:39 step:30630 [D loss: 0.104557, acc: 100.00%] [G loss: 2.837805]\n",
      "epoch:39 step:30631 [D loss: 0.574197, acc: 60.16%] [G loss: 4.204251]\n",
      "epoch:39 step:30632 [D loss: 1.150019, acc: 50.00%] [G loss: 6.716615]\n",
      "epoch:39 step:30633 [D loss: 0.100551, acc: 98.44%] [G loss: 5.015408]\n",
      "epoch:39 step:30634 [D loss: 0.171736, acc: 96.88%] [G loss: 5.150753]\n",
      "epoch:39 step:30635 [D loss: 0.399246, acc: 82.81%] [G loss: 5.847625]\n",
      "epoch:39 step:30636 [D loss: 0.423836, acc: 77.34%] [G loss: 4.466807]\n",
      "epoch:39 step:30637 [D loss: 0.642267, acc: 64.84%] [G loss: 7.398139]\n",
      "epoch:39 step:30638 [D loss: 0.869198, acc: 50.78%] [G loss: 5.916133]\n",
      "epoch:39 step:30639 [D loss: 1.088738, acc: 30.47%] [G loss: 6.042996]\n",
      "epoch:39 step:30640 [D loss: 0.021572, acc: 100.00%] [G loss: 7.580751]\n",
      "epoch:39 step:30641 [D loss: 0.027591, acc: 100.00%] [G loss: 4.858810]\n",
      "epoch:39 step:30642 [D loss: 0.272825, acc: 89.84%] [G loss: 3.048306]\n",
      "epoch:39 step:30643 [D loss: 0.371623, acc: 78.12%] [G loss: 6.991520]\n",
      "epoch:39 step:30644 [D loss: 0.278803, acc: 89.84%] [G loss: 5.261863]\n",
      "epoch:39 step:30645 [D loss: 1.568503, acc: 47.66%] [G loss: 7.810053]\n",
      "epoch:39 step:30646 [D loss: 0.150988, acc: 98.44%] [G loss: 5.481523]\n",
      "epoch:39 step:30647 [D loss: 0.647287, acc: 64.84%] [G loss: 5.391720]\n",
      "epoch:39 step:30648 [D loss: 0.066863, acc: 100.00%] [G loss: 6.401889]\n",
      "epoch:39 step:30649 [D loss: 0.719215, acc: 55.47%] [G loss: 7.393142]\n",
      "epoch:39 step:30650 [D loss: 0.085863, acc: 100.00%] [G loss: 2.976840]\n",
      "epoch:39 step:30651 [D loss: 0.157752, acc: 97.66%] [G loss: 3.880317]\n",
      "epoch:39 step:30652 [D loss: 0.473626, acc: 78.91%] [G loss: 6.983545]\n",
      "epoch:39 step:30653 [D loss: 0.238625, acc: 95.31%] [G loss: 4.832745]\n",
      "epoch:39 step:30654 [D loss: 0.179886, acc: 96.09%] [G loss: 5.388805]\n",
      "epoch:39 step:30655 [D loss: 0.414700, acc: 78.12%] [G loss: 6.374531]\n",
      "epoch:39 step:30656 [D loss: 0.064523, acc: 100.00%] [G loss: 4.330991]\n",
      "epoch:39 step:30657 [D loss: 0.019236, acc: 100.00%] [G loss: 8.397765]\n",
      "epoch:39 step:30658 [D loss: 0.121322, acc: 100.00%] [G loss: 7.561168]\n",
      "epoch:39 step:30659 [D loss: 0.050864, acc: 100.00%] [G loss: 5.948864]\n",
      "epoch:39 step:30660 [D loss: 0.152360, acc: 98.44%] [G loss: 5.354139]\n",
      "epoch:39 step:30661 [D loss: 0.401536, acc: 75.78%] [G loss: 7.449415]\n",
      "epoch:39 step:30662 [D loss: 0.124408, acc: 98.44%] [G loss: 3.368200]\n",
      "epoch:39 step:30663 [D loss: 0.334086, acc: 92.97%] [G loss: 4.352783]\n",
      "epoch:39 step:30664 [D loss: 0.462117, acc: 74.22%] [G loss: 2.463375]\n",
      "epoch:39 step:30665 [D loss: 0.347685, acc: 78.91%] [G loss: 5.694195]\n",
      "epoch:39 step:30666 [D loss: 0.125431, acc: 100.00%] [G loss: 4.187047]\n",
      "epoch:39 step:30667 [D loss: 0.813837, acc: 44.53%] [G loss: 5.507978]\n",
      "epoch:39 step:30668 [D loss: 0.232321, acc: 96.09%] [G loss: 5.432195]\n",
      "epoch:39 step:30669 [D loss: 0.245638, acc: 98.44%] [G loss: 3.220588]\n",
      "epoch:39 step:30670 [D loss: 0.555455, acc: 67.19%] [G loss: 5.720150]\n",
      "epoch:39 step:30671 [D loss: 0.109176, acc: 100.00%] [G loss: 7.359659]\n",
      "epoch:39 step:30672 [D loss: 0.667127, acc: 57.81%] [G loss: 5.721553]\n",
      "epoch:39 step:30673 [D loss: 0.272907, acc: 88.28%] [G loss: 2.399243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30674 [D loss: 0.967197, acc: 33.59%] [G loss: 5.109787]\n",
      "epoch:39 step:30675 [D loss: 1.022355, acc: 53.12%] [G loss: 5.007245]\n",
      "epoch:39 step:30676 [D loss: 0.039682, acc: 100.00%] [G loss: 4.755930]\n",
      "epoch:39 step:30677 [D loss: 0.227836, acc: 88.28%] [G loss: 5.714373]\n",
      "epoch:39 step:30678 [D loss: 0.383498, acc: 75.78%] [G loss: 4.323575]\n",
      "epoch:39 step:30679 [D loss: 0.639735, acc: 64.84%] [G loss: 6.719360]\n",
      "epoch:39 step:30680 [D loss: 0.622100, acc: 56.25%] [G loss: 5.857875]\n",
      "epoch:39 step:30681 [D loss: 0.412526, acc: 72.66%] [G loss: 6.677082]\n",
      "epoch:39 step:30682 [D loss: 0.708273, acc: 56.25%] [G loss: 3.464350]\n",
      "epoch:39 step:30683 [D loss: 0.059545, acc: 100.00%] [G loss: 6.800483]\n",
      "epoch:39 step:30684 [D loss: 0.275940, acc: 87.50%] [G loss: 5.250937]\n",
      "epoch:39 step:30685 [D loss: 0.357071, acc: 89.06%] [G loss: 5.607088]\n",
      "epoch:39 step:30686 [D loss: 0.014773, acc: 100.00%] [G loss: 7.108635]\n",
      "epoch:39 step:30687 [D loss: 0.215696, acc: 92.19%] [G loss: 4.607808]\n",
      "epoch:39 step:30688 [D loss: 0.071617, acc: 99.22%] [G loss: 6.827939]\n",
      "epoch:39 step:30689 [D loss: 0.284260, acc: 92.97%] [G loss: 5.158448]\n",
      "epoch:39 step:30690 [D loss: 0.145185, acc: 98.44%] [G loss: 3.529075]\n",
      "epoch:39 step:30691 [D loss: 0.201693, acc: 96.09%] [G loss: 7.905148]\n",
      "epoch:39 step:30692 [D loss: 0.103697, acc: 99.22%] [G loss: 4.506787]\n",
      "epoch:39 step:30693 [D loss: 0.252824, acc: 93.75%] [G loss: 3.014389]\n",
      "epoch:39 step:30694 [D loss: 0.626893, acc: 57.81%] [G loss: 2.936518]\n",
      "epoch:39 step:30695 [D loss: 0.209940, acc: 97.66%] [G loss: 4.358214]\n",
      "epoch:39 step:30696 [D loss: 0.439148, acc: 71.88%] [G loss: 4.852187]\n",
      "epoch:39 step:30697 [D loss: 0.257578, acc: 91.41%] [G loss: 6.409866]\n",
      "epoch:39 step:30698 [D loss: 0.418414, acc: 81.25%] [G loss: 3.787352]\n",
      "epoch:39 step:30699 [D loss: 0.086416, acc: 100.00%] [G loss: 4.228200]\n",
      "epoch:39 step:30700 [D loss: 0.243274, acc: 88.28%] [G loss: 7.929030]\n",
      "epoch:39 step:30701 [D loss: 0.152591, acc: 98.44%] [G loss: 3.946422]\n",
      "epoch:39 step:30702 [D loss: 0.037839, acc: 100.00%] [G loss: 4.985234]\n",
      "epoch:39 step:30703 [D loss: 0.053703, acc: 100.00%] [G loss: 4.280785]\n",
      "epoch:39 step:30704 [D loss: 0.526276, acc: 77.34%] [G loss: 4.637874]\n",
      "epoch:39 step:30705 [D loss: 1.602607, acc: 50.00%] [G loss: 3.892903]\n",
      "epoch:39 step:30706 [D loss: 0.330485, acc: 80.47%] [G loss: 5.302240]\n",
      "epoch:39 step:30707 [D loss: 0.343975, acc: 84.38%] [G loss: 5.040394]\n",
      "epoch:39 step:30708 [D loss: 0.203719, acc: 96.88%] [G loss: 5.437496]\n",
      "epoch:39 step:30709 [D loss: 0.088978, acc: 100.00%] [G loss: 6.414977]\n",
      "epoch:39 step:30710 [D loss: 0.567821, acc: 58.59%] [G loss: 7.495082]\n",
      "epoch:39 step:30711 [D loss: 0.170334, acc: 96.88%] [G loss: 4.725149]\n",
      "epoch:39 step:30712 [D loss: 0.329240, acc: 85.94%] [G loss: 3.268901]\n",
      "epoch:39 step:30713 [D loss: 0.202863, acc: 98.44%] [G loss: 6.765757]\n",
      "epoch:39 step:30714 [D loss: 0.628822, acc: 63.28%] [G loss: 6.828601]\n",
      "epoch:39 step:30715 [D loss: 0.119053, acc: 98.44%] [G loss: 4.870923]\n",
      "epoch:39 step:30716 [D loss: 0.222435, acc: 95.31%] [G loss: 5.166164]\n",
      "epoch:39 step:30717 [D loss: 0.380207, acc: 80.47%] [G loss: 6.441179]\n",
      "epoch:39 step:30718 [D loss: 0.392685, acc: 73.44%] [G loss: 4.087465]\n",
      "epoch:39 step:30719 [D loss: 0.155043, acc: 99.22%] [G loss: 4.726927]\n",
      "epoch:39 step:30720 [D loss: 0.464932, acc: 68.75%] [G loss: 7.175233]\n",
      "epoch:39 step:30721 [D loss: 0.334108, acc: 85.94%] [G loss: 6.433407]\n",
      "epoch:39 step:30722 [D loss: 0.847950, acc: 46.88%] [G loss: 5.857643]\n",
      "epoch:39 step:30723 [D loss: 0.617300, acc: 64.84%] [G loss: 5.161463]\n",
      "epoch:39 step:30724 [D loss: 1.169176, acc: 50.78%] [G loss: 3.864846]\n",
      "epoch:39 step:30725 [D loss: 0.488354, acc: 70.31%] [G loss: 5.901733]\n",
      "epoch:39 step:30726 [D loss: 1.264121, acc: 50.00%] [G loss: 5.190805]\n",
      "epoch:39 step:30727 [D loss: 0.267086, acc: 96.88%] [G loss: 2.325189]\n",
      "epoch:39 step:30728 [D loss: 0.165408, acc: 100.00%] [G loss: 4.845543]\n",
      "epoch:39 step:30729 [D loss: 0.365765, acc: 88.28%] [G loss: 3.212482]\n",
      "epoch:39 step:30730 [D loss: 0.536486, acc: 74.22%] [G loss: 6.091587]\n",
      "epoch:39 step:30731 [D loss: 0.037669, acc: 100.00%] [G loss: 4.180975]\n",
      "epoch:39 step:30732 [D loss: 1.238794, acc: 14.06%] [G loss: 2.913431]\n",
      "epoch:39 step:30733 [D loss: 1.279979, acc: 14.06%] [G loss: 6.218947]\n",
      "epoch:39 step:30734 [D loss: 0.907355, acc: 36.72%] [G loss: 1.948214]\n",
      "epoch:39 step:30735 [D loss: 0.555283, acc: 61.72%] [G loss: 5.900078]\n",
      "epoch:39 step:30736 [D loss: 0.083928, acc: 100.00%] [G loss: 3.846395]\n",
      "epoch:39 step:30737 [D loss: 0.116892, acc: 98.44%] [G loss: 5.488442]\n",
      "epoch:39 step:30738 [D loss: 1.417378, acc: 50.00%] [G loss: 7.162557]\n",
      "epoch:39 step:30739 [D loss: 0.370536, acc: 82.03%] [G loss: 4.525594]\n",
      "epoch:39 step:30740 [D loss: 0.597354, acc: 64.06%] [G loss: 4.304990]\n",
      "epoch:39 step:30741 [D loss: 0.309963, acc: 89.06%] [G loss: 4.814929]\n",
      "epoch:39 step:30742 [D loss: 0.095420, acc: 100.00%] [G loss: 5.735054]\n",
      "epoch:39 step:30743 [D loss: 0.119689, acc: 100.00%] [G loss: 6.987334]\n",
      "epoch:39 step:30744 [D loss: 0.331989, acc: 90.62%] [G loss: 4.471865]\n",
      "epoch:39 step:30745 [D loss: 0.455193, acc: 71.88%] [G loss: 3.745811]\n",
      "epoch:39 step:30746 [D loss: 0.423267, acc: 78.12%] [G loss: 5.105459]\n",
      "epoch:39 step:30747 [D loss: 0.314190, acc: 94.53%] [G loss: 3.165577]\n",
      "epoch:39 step:30748 [D loss: 0.182321, acc: 96.88%] [G loss: 7.138277]\n",
      "epoch:39 step:30749 [D loss: 0.693524, acc: 54.69%] [G loss: 3.594759]\n",
      "epoch:39 step:30750 [D loss: 0.411588, acc: 85.16%] [G loss: 5.599565]\n",
      "epoch:39 step:30751 [D loss: 0.048253, acc: 100.00%] [G loss: 5.726620]\n",
      "epoch:39 step:30752 [D loss: 0.773658, acc: 56.25%] [G loss: 8.335971]\n",
      "epoch:39 step:30753 [D loss: 0.277413, acc: 90.62%] [G loss: 7.124201]\n",
      "epoch:39 step:30754 [D loss: 1.117022, acc: 48.44%] [G loss: 3.921531]\n",
      "epoch:39 step:30755 [D loss: 1.148000, acc: 49.22%] [G loss: 4.080441]\n",
      "epoch:39 step:30756 [D loss: 0.840586, acc: 51.56%] [G loss: 6.235018]\n",
      "epoch:39 step:30757 [D loss: 0.783675, acc: 51.56%] [G loss: 3.828688]\n",
      "epoch:39 step:30758 [D loss: 0.054444, acc: 100.00%] [G loss: 4.033511]\n",
      "epoch:39 step:30759 [D loss: 0.126782, acc: 100.00%] [G loss: 3.717594]\n",
      "epoch:39 step:30760 [D loss: 0.232470, acc: 96.09%] [G loss: 4.807755]\n",
      "epoch:39 step:30761 [D loss: 0.227127, acc: 98.44%] [G loss: 6.631384]\n",
      "epoch:39 step:30762 [D loss: 0.359735, acc: 90.62%] [G loss: 2.634886]\n",
      "epoch:39 step:30763 [D loss: 0.246134, acc: 94.53%] [G loss: 4.761926]\n",
      "epoch:39 step:30764 [D loss: 0.226638, acc: 97.66%] [G loss: 2.919294]\n",
      "epoch:39 step:30765 [D loss: 0.442802, acc: 84.38%] [G loss: 7.383881]\n",
      "epoch:39 step:30766 [D loss: 0.943896, acc: 50.78%] [G loss: 5.133186]\n",
      "epoch:39 step:30767 [D loss: 0.049946, acc: 100.00%] [G loss: 7.630954]\n",
      "epoch:39 step:30768 [D loss: 0.151127, acc: 98.44%] [G loss: 5.143147]\n",
      "epoch:39 step:30769 [D loss: 0.056964, acc: 100.00%] [G loss: 5.921851]\n",
      "epoch:39 step:30770 [D loss: 0.462932, acc: 70.31%] [G loss: 4.666943]\n",
      "epoch:39 step:30771 [D loss: 0.153516, acc: 100.00%] [G loss: 4.740146]\n",
      "epoch:39 step:30772 [D loss: 0.332321, acc: 83.59%] [G loss: 5.082326]\n",
      "epoch:39 step:30773 [D loss: 0.709094, acc: 52.34%] [G loss: 8.346242]\n",
      "epoch:39 step:30774 [D loss: 0.322054, acc: 83.59%] [G loss: 5.567501]\n",
      "epoch:39 step:30775 [D loss: 0.588547, acc: 60.16%] [G loss: 6.005490]\n",
      "epoch:39 step:30776 [D loss: 0.411963, acc: 75.78%] [G loss: 5.274146]\n",
      "epoch:39 step:30777 [D loss: 0.785767, acc: 52.34%] [G loss: 4.348013]\n",
      "epoch:39 step:30778 [D loss: 0.254340, acc: 87.50%] [G loss: 4.520937]\n",
      "epoch:39 step:30779 [D loss: 0.312831, acc: 94.53%] [G loss: 3.361454]\n",
      "epoch:39 step:30780 [D loss: 0.055908, acc: 100.00%] [G loss: 6.221734]\n",
      "epoch:39 step:30781 [D loss: 0.261072, acc: 92.19%] [G loss: 2.499591]\n",
      "epoch:39 step:30782 [D loss: 0.241802, acc: 92.97%] [G loss: 5.494515]\n",
      "epoch:39 step:30783 [D loss: 1.266399, acc: 22.66%] [G loss: 6.148921]\n",
      "epoch:39 step:30784 [D loss: 0.359926, acc: 89.84%] [G loss: 3.015428]\n",
      "epoch:39 step:30785 [D loss: 0.257108, acc: 97.66%] [G loss: 3.912785]\n",
      "epoch:39 step:30786 [D loss: 0.201447, acc: 98.44%] [G loss: 4.920062]\n",
      "epoch:39 step:30787 [D loss: 0.344206, acc: 89.06%] [G loss: 5.329513]\n",
      "epoch:39 step:30788 [D loss: 0.611287, acc: 59.38%] [G loss: 7.918870]\n",
      "epoch:39 step:30789 [D loss: 0.144261, acc: 99.22%] [G loss: 4.542422]\n",
      "epoch:39 step:30790 [D loss: 0.463959, acc: 80.47%] [G loss: 6.206902]\n",
      "epoch:39 step:30791 [D loss: 0.173395, acc: 96.88%] [G loss: 2.826240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30792 [D loss: 0.123350, acc: 98.44%] [G loss: 7.283603]\n",
      "epoch:39 step:30793 [D loss: 0.222616, acc: 96.09%] [G loss: 5.323074]\n",
      "epoch:39 step:30794 [D loss: 0.061005, acc: 100.00%] [G loss: 4.115773]\n",
      "epoch:39 step:30795 [D loss: 0.305789, acc: 89.84%] [G loss: 5.387061]\n",
      "epoch:39 step:30796 [D loss: 0.089196, acc: 100.00%] [G loss: 3.827851]\n",
      "epoch:39 step:30797 [D loss: 0.095562, acc: 100.00%] [G loss: 3.075802]\n",
      "epoch:39 step:30798 [D loss: 0.041019, acc: 100.00%] [G loss: 6.774682]\n",
      "epoch:39 step:30799 [D loss: 0.937765, acc: 49.22%] [G loss: 4.683319]\n",
      "epoch:39 step:30800 [D loss: 0.663712, acc: 58.59%] [G loss: 2.815624]\n",
      "epoch:39 step:30801 [D loss: 0.775929, acc: 53.12%] [G loss: 4.895328]\n",
      "epoch:39 step:30802 [D loss: 0.202487, acc: 95.31%] [G loss: 6.419604]\n",
      "epoch:39 step:30803 [D loss: 0.102869, acc: 100.00%] [G loss: 2.991251]\n",
      "epoch:39 step:30804 [D loss: 0.238754, acc: 92.97%] [G loss: 3.519565]\n",
      "epoch:39 step:30805 [D loss: 0.215698, acc: 93.75%] [G loss: 6.994178]\n",
      "epoch:39 step:30806 [D loss: 0.947548, acc: 50.00%] [G loss: 2.298758]\n",
      "epoch:39 step:30807 [D loss: 0.382613, acc: 78.91%] [G loss: 4.818429]\n",
      "epoch:39 step:30808 [D loss: 0.264333, acc: 89.84%] [G loss: 4.506765]\n",
      "epoch:39 step:30809 [D loss: 0.114659, acc: 99.22%] [G loss: 4.340714]\n",
      "epoch:39 step:30810 [D loss: 0.556242, acc: 63.28%] [G loss: 4.231920]\n",
      "epoch:39 step:30811 [D loss: 0.102414, acc: 100.00%] [G loss: 8.363710]\n",
      "epoch:39 step:30812 [D loss: 0.784880, acc: 53.12%] [G loss: 5.986140]\n",
      "epoch:39 step:30813 [D loss: 0.242936, acc: 96.88%] [G loss: 2.599447]\n",
      "epoch:39 step:30814 [D loss: 0.546923, acc: 67.97%] [G loss: 4.958508]\n",
      "epoch:39 step:30815 [D loss: 0.592205, acc: 58.59%] [G loss: 6.975094]\n",
      "epoch:39 step:30816 [D loss: 0.432433, acc: 70.31%] [G loss: 4.982790]\n",
      "epoch:39 step:30817 [D loss: 0.333426, acc: 90.62%] [G loss: 4.678819]\n",
      "epoch:39 step:30818 [D loss: 0.081665, acc: 100.00%] [G loss: 2.879044]\n",
      "epoch:39 step:30819 [D loss: 0.099367, acc: 100.00%] [G loss: 3.587647]\n",
      "epoch:39 step:30820 [D loss: 0.273417, acc: 94.53%] [G loss: 3.809730]\n",
      "epoch:39 step:30821 [D loss: 0.053209, acc: 100.00%] [G loss: 6.007385]\n",
      "epoch:39 step:30822 [D loss: 0.788074, acc: 53.91%] [G loss: 5.362291]\n",
      "epoch:39 step:30823 [D loss: 0.535933, acc: 75.78%] [G loss: 5.317270]\n",
      "epoch:39 step:30824 [D loss: 0.065801, acc: 100.00%] [G loss: 7.395695]\n",
      "epoch:39 step:30825 [D loss: 0.504201, acc: 71.09%] [G loss: 5.835617]\n",
      "epoch:39 step:30826 [D loss: 0.464864, acc: 67.19%] [G loss: 5.096423]\n",
      "epoch:39 step:30827 [D loss: 0.427590, acc: 85.94%] [G loss: 4.081860]\n",
      "epoch:39 step:30828 [D loss: 0.401489, acc: 78.12%] [G loss: 4.630915]\n",
      "epoch:39 step:30829 [D loss: 0.152079, acc: 100.00%] [G loss: 3.470626]\n",
      "epoch:39 step:30830 [D loss: 0.186071, acc: 97.66%] [G loss: 3.580411]\n",
      "epoch:39 step:30831 [D loss: 0.089748, acc: 99.22%] [G loss: 3.945643]\n",
      "epoch:39 step:30832 [D loss: 0.100754, acc: 100.00%] [G loss: 6.155677]\n",
      "epoch:39 step:30833 [D loss: 0.054286, acc: 100.00%] [G loss: 5.978933]\n",
      "epoch:39 step:30834 [D loss: 0.452923, acc: 75.00%] [G loss: 5.446048]\n",
      "epoch:39 step:30835 [D loss: 0.680733, acc: 53.91%] [G loss: 3.899911]\n",
      "epoch:39 step:30836 [D loss: 0.293078, acc: 95.31%] [G loss: 4.858771]\n",
      "epoch:39 step:30837 [D loss: 0.284682, acc: 88.28%] [G loss: 9.557880]\n",
      "epoch:39 step:30838 [D loss: 0.228396, acc: 97.66%] [G loss: 5.722935]\n",
      "epoch:39 step:30839 [D loss: 0.283833, acc: 89.84%] [G loss: 4.371552]\n",
      "epoch:39 step:30840 [D loss: 1.443196, acc: 50.78%] [G loss: 5.292267]\n",
      "epoch:39 step:30841 [D loss: 2.564476, acc: 50.00%] [G loss: 2.895521]\n",
      "epoch:39 step:30842 [D loss: 0.641953, acc: 62.50%] [G loss: 5.843888]\n",
      "epoch:39 step:30843 [D loss: 0.097745, acc: 100.00%] [G loss: 5.033440]\n",
      "epoch:39 step:30844 [D loss: 0.214111, acc: 99.22%] [G loss: 5.435583]\n",
      "epoch:39 step:30845 [D loss: 0.798653, acc: 50.78%] [G loss: 4.794752]\n",
      "epoch:39 step:30846 [D loss: 0.082303, acc: 100.00%] [G loss: 5.304138]\n",
      "epoch:39 step:30847 [D loss: 1.519558, acc: 50.00%] [G loss: 5.649129]\n",
      "epoch:39 step:30848 [D loss: 0.414434, acc: 83.59%] [G loss: 6.669982]\n",
      "epoch:39 step:30849 [D loss: 0.372764, acc: 87.50%] [G loss: 3.974033]\n",
      "epoch:39 step:30850 [D loss: 0.298951, acc: 84.38%] [G loss: 5.490620]\n",
      "epoch:39 step:30851 [D loss: 0.105667, acc: 100.00%] [G loss: 6.083095]\n",
      "epoch:39 step:30852 [D loss: 0.542546, acc: 67.19%] [G loss: 4.858885]\n",
      "epoch:39 step:30853 [D loss: 0.065191, acc: 100.00%] [G loss: 5.224422]\n",
      "epoch:39 step:30854 [D loss: 0.304476, acc: 92.97%] [G loss: 4.745090]\n",
      "epoch:39 step:30855 [D loss: 0.504369, acc: 71.09%] [G loss: 4.465110]\n",
      "epoch:39 step:30856 [D loss: 0.654847, acc: 60.94%] [G loss: 4.054204]\n",
      "epoch:39 step:30857 [D loss: 0.131513, acc: 100.00%] [G loss: 6.042323]\n",
      "epoch:39 step:30858 [D loss: 0.366432, acc: 88.28%] [G loss: 3.880015]\n",
      "epoch:39 step:30859 [D loss: 0.206394, acc: 99.22%] [G loss: 4.290720]\n",
      "epoch:39 step:30860 [D loss: 0.103031, acc: 100.00%] [G loss: 4.573083]\n",
      "epoch:39 step:30861 [D loss: 0.265326, acc: 90.62%] [G loss: 6.361479]\n",
      "epoch:39 step:30862 [D loss: 0.252824, acc: 99.22%] [G loss: 5.341833]\n",
      "epoch:39 step:30863 [D loss: 0.254992, acc: 94.53%] [G loss: 3.974115]\n",
      "epoch:39 step:30864 [D loss: 0.038873, acc: 100.00%] [G loss: 7.658172]\n",
      "epoch:39 step:30865 [D loss: 0.762284, acc: 49.22%] [G loss: 3.189270]\n",
      "epoch:39 step:30866 [D loss: 0.234096, acc: 89.84%] [G loss: 3.711094]\n",
      "epoch:39 step:30867 [D loss: 0.283235, acc: 92.19%] [G loss: 2.469479]\n",
      "epoch:39 step:30868 [D loss: 0.863732, acc: 50.78%] [G loss: 9.057679]\n",
      "epoch:39 step:30869 [D loss: 0.612632, acc: 63.28%] [G loss: 6.664896]\n",
      "epoch:39 step:30870 [D loss: 0.161742, acc: 97.66%] [G loss: 4.050062]\n",
      "epoch:39 step:30871 [D loss: 0.413326, acc: 71.88%] [G loss: 3.848140]\n",
      "epoch:39 step:30872 [D loss: 0.409584, acc: 82.81%] [G loss: 3.284633]\n",
      "epoch:39 step:30873 [D loss: 0.731184, acc: 53.12%] [G loss: 6.149462]\n",
      "epoch:39 step:30874 [D loss: 0.052720, acc: 100.00%] [G loss: 5.041821]\n",
      "epoch:39 step:30875 [D loss: 0.675762, acc: 57.03%] [G loss: 6.075868]\n",
      "epoch:39 step:30876 [D loss: 0.113547, acc: 100.00%] [G loss: 6.222856]\n",
      "epoch:39 step:30877 [D loss: 0.226778, acc: 97.66%] [G loss: 5.515798]\n",
      "epoch:39 step:30878 [D loss: 0.168721, acc: 96.88%] [G loss: 5.772418]\n",
      "epoch:39 step:30879 [D loss: 1.102910, acc: 25.00%] [G loss: 5.496067]\n",
      "epoch:39 step:30880 [D loss: 0.104008, acc: 99.22%] [G loss: 4.426859]\n",
      "epoch:39 step:30881 [D loss: 0.296950, acc: 86.72%] [G loss: 3.572477]\n",
      "epoch:39 step:30882 [D loss: 0.491253, acc: 71.09%] [G loss: 4.767689]\n",
      "epoch:39 step:30883 [D loss: 0.401013, acc: 82.03%] [G loss: 4.212798]\n",
      "epoch:39 step:30884 [D loss: 0.121512, acc: 100.00%] [G loss: 4.130797]\n",
      "epoch:39 step:30885 [D loss: 0.068431, acc: 100.00%] [G loss: 4.533263]\n",
      "epoch:39 step:30886 [D loss: 0.307107, acc: 94.53%] [G loss: 4.437144]\n",
      "epoch:39 step:30887 [D loss: 0.418793, acc: 82.03%] [G loss: 4.536583]\n",
      "epoch:39 step:30888 [D loss: 0.054305, acc: 100.00%] [G loss: 6.194697]\n",
      "epoch:39 step:30889 [D loss: 0.115839, acc: 100.00%] [G loss: 5.216883]\n",
      "epoch:39 step:30890 [D loss: 0.836083, acc: 50.78%] [G loss: 2.373671]\n",
      "epoch:39 step:30891 [D loss: 0.225991, acc: 98.44%] [G loss: 2.600803]\n",
      "epoch:39 step:30892 [D loss: 0.608921, acc: 58.59%] [G loss: 5.564771]\n",
      "epoch:39 step:30893 [D loss: 0.142961, acc: 99.22%] [G loss: 7.458169]\n",
      "epoch:39 step:30894 [D loss: 0.019740, acc: 100.00%] [G loss: 7.698731]\n",
      "epoch:39 step:30895 [D loss: 0.442577, acc: 85.16%] [G loss: 6.484386]\n",
      "epoch:39 step:30896 [D loss: 0.199031, acc: 95.31%] [G loss: 1.996533]\n",
      "epoch:39 step:30897 [D loss: 0.160802, acc: 98.44%] [G loss: 5.056385]\n",
      "epoch:39 step:30898 [D loss: 0.478319, acc: 81.25%] [G loss: 4.617286]\n",
      "epoch:39 step:30899 [D loss: 0.338257, acc: 82.03%] [G loss: 3.895281]\n",
      "epoch:39 step:30900 [D loss: 0.170010, acc: 99.22%] [G loss: 5.139397]\n",
      "epoch:39 step:30901 [D loss: 0.446799, acc: 71.88%] [G loss: 5.643529]\n",
      "epoch:39 step:30902 [D loss: 0.657943, acc: 55.47%] [G loss: 5.369069]\n",
      "epoch:39 step:30903 [D loss: 0.607702, acc: 57.03%] [G loss: 6.794807]\n",
      "epoch:39 step:30904 [D loss: 0.602923, acc: 64.06%] [G loss: 2.205668]\n",
      "epoch:39 step:30905 [D loss: 0.038132, acc: 100.00%] [G loss: 4.645129]\n",
      "epoch:39 step:30906 [D loss: 0.275848, acc: 94.53%] [G loss: 3.589783]\n",
      "epoch:39 step:30907 [D loss: 0.187701, acc: 97.66%] [G loss: 5.121731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30908 [D loss: 0.172236, acc: 99.22%] [G loss: 5.279722]\n",
      "epoch:39 step:30909 [D loss: 0.150707, acc: 94.53%] [G loss: 1.785633]\n",
      "epoch:39 step:30910 [D loss: 0.289410, acc: 93.75%] [G loss: 3.498069]\n",
      "epoch:39 step:30911 [D loss: 0.221532, acc: 100.00%] [G loss: 4.158554]\n",
      "epoch:39 step:30912 [D loss: 0.316768, acc: 94.53%] [G loss: 5.451059]\n",
      "epoch:39 step:30913 [D loss: 0.256215, acc: 93.75%] [G loss: 3.068008]\n",
      "epoch:39 step:30914 [D loss: 0.178347, acc: 97.66%] [G loss: 3.637821]\n",
      "epoch:39 step:30915 [D loss: 0.028407, acc: 100.00%] [G loss: 6.460561]\n",
      "epoch:39 step:30916 [D loss: 0.241569, acc: 91.41%] [G loss: 5.155280]\n",
      "epoch:39 step:30917 [D loss: 1.079621, acc: 50.00%] [G loss: 9.200754]\n",
      "epoch:39 step:30918 [D loss: 0.542388, acc: 65.62%] [G loss: 5.024110]\n",
      "epoch:39 step:30919 [D loss: 0.098222, acc: 99.22%] [G loss: 4.560629]\n",
      "epoch:39 step:30920 [D loss: 0.317866, acc: 90.62%] [G loss: 4.995504]\n",
      "epoch:39 step:30921 [D loss: 0.312442, acc: 82.81%] [G loss: 5.860804]\n",
      "epoch:39 step:30922 [D loss: 0.116101, acc: 100.00%] [G loss: 4.218544]\n",
      "epoch:39 step:30923 [D loss: 0.191457, acc: 99.22%] [G loss: 5.996919]\n",
      "epoch:39 step:30924 [D loss: 0.586952, acc: 60.94%] [G loss: 6.190633]\n",
      "epoch:39 step:30925 [D loss: 0.019487, acc: 100.00%] [G loss: 9.422404]\n",
      "epoch:39 step:30926 [D loss: 0.359316, acc: 89.06%] [G loss: 4.327389]\n",
      "epoch:39 step:30927 [D loss: 0.339697, acc: 82.81%] [G loss: 5.240940]\n",
      "epoch:39 step:30928 [D loss: 0.648899, acc: 58.59%] [G loss: 5.787850]\n",
      "epoch:39 step:30929 [D loss: 0.250088, acc: 91.41%] [G loss: 7.082027]\n",
      "epoch:39 step:30930 [D loss: 0.170780, acc: 98.44%] [G loss: 4.033139]\n",
      "epoch:39 step:30931 [D loss: 0.088305, acc: 100.00%] [G loss: 6.934909]\n",
      "epoch:39 step:30932 [D loss: 0.420791, acc: 74.22%] [G loss: 8.543383]\n",
      "epoch:39 step:30933 [D loss: 0.096505, acc: 100.00%] [G loss: 3.770471]\n",
      "epoch:39 step:30934 [D loss: 0.272923, acc: 89.84%] [G loss: 3.688138]\n",
      "epoch:39 step:30935 [D loss: 0.224742, acc: 96.09%] [G loss: 4.192456]\n",
      "epoch:39 step:30936 [D loss: 0.200185, acc: 98.44%] [G loss: 3.106863]\n",
      "epoch:39 step:30937 [D loss: 0.040010, acc: 100.00%] [G loss: 7.177738]\n",
      "epoch:39 step:30938 [D loss: 0.273064, acc: 96.09%] [G loss: 6.535980]\n",
      "epoch:39 step:30939 [D loss: 0.210217, acc: 98.44%] [G loss: 5.289711]\n",
      "epoch:39 step:30940 [D loss: 0.716832, acc: 57.81%] [G loss: 3.230331]\n",
      "epoch:39 step:30941 [D loss: 0.263578, acc: 97.66%] [G loss: 3.713511]\n",
      "epoch:39 step:30942 [D loss: 0.517034, acc: 68.75%] [G loss: 8.406025]\n",
      "epoch:39 step:30943 [D loss: 1.403640, acc: 47.66%] [G loss: 5.309069]\n",
      "epoch:39 step:30944 [D loss: 0.541545, acc: 76.56%] [G loss: 6.569725]\n",
      "epoch:39 step:30945 [D loss: 0.856007, acc: 51.56%] [G loss: 3.687596]\n",
      "epoch:39 step:30946 [D loss: 0.624727, acc: 57.03%] [G loss: 6.102968]\n",
      "epoch:39 step:30947 [D loss: 0.595436, acc: 67.19%] [G loss: 3.801473]\n",
      "epoch:39 step:30948 [D loss: 0.213719, acc: 98.44%] [G loss: 5.800117]\n",
      "epoch:39 step:30949 [D loss: 0.109346, acc: 99.22%] [G loss: 7.887795]\n",
      "epoch:39 step:30950 [D loss: 0.023196, acc: 100.00%] [G loss: 6.450882]\n",
      "epoch:39 step:30951 [D loss: 0.193766, acc: 97.66%] [G loss: 6.236875]\n",
      "epoch:39 step:30952 [D loss: 0.166585, acc: 99.22%] [G loss: 8.191195]\n",
      "epoch:39 step:30953 [D loss: 0.209813, acc: 95.31%] [G loss: 5.158059]\n",
      "epoch:39 step:30954 [D loss: 0.209292, acc: 98.44%] [G loss: 4.514218]\n",
      "epoch:39 step:30955 [D loss: 0.317671, acc: 91.41%] [G loss: 5.336315]\n",
      "epoch:39 step:30956 [D loss: 0.087881, acc: 99.22%] [G loss: 5.802995]\n",
      "epoch:39 step:30957 [D loss: 0.036911, acc: 100.00%] [G loss: 5.735597]\n",
      "epoch:39 step:30958 [D loss: 0.116792, acc: 100.00%] [G loss: 7.148012]\n",
      "epoch:39 step:30959 [D loss: 0.575576, acc: 57.03%] [G loss: 7.144693]\n",
      "epoch:39 step:30960 [D loss: 0.661619, acc: 57.03%] [G loss: 5.837681]\n",
      "epoch:39 step:30961 [D loss: 0.198377, acc: 98.44%] [G loss: 8.383360]\n",
      "epoch:39 step:30962 [D loss: 0.209302, acc: 98.44%] [G loss: 5.640687]\n",
      "epoch:39 step:30963 [D loss: 0.231989, acc: 98.44%] [G loss: 5.831839]\n",
      "epoch:39 step:30964 [D loss: 0.337458, acc: 95.31%] [G loss: 3.766109]\n",
      "epoch:39 step:30965 [D loss: 0.140823, acc: 99.22%] [G loss: 3.995286]\n",
      "epoch:39 step:30966 [D loss: 0.293110, acc: 88.28%] [G loss: 2.413216]\n",
      "epoch:39 step:30967 [D loss: 0.350854, acc: 82.03%] [G loss: 4.507078]\n",
      "epoch:39 step:30968 [D loss: 0.034114, acc: 100.00%] [G loss: 3.091785]\n",
      "epoch:39 step:30969 [D loss: 0.192621, acc: 96.88%] [G loss: 4.978448]\n",
      "epoch:39 step:30970 [D loss: 0.205740, acc: 95.31%] [G loss: 7.591971]\n",
      "epoch:39 step:30971 [D loss: 0.201567, acc: 96.09%] [G loss: 5.402584]\n",
      "epoch:39 step:30972 [D loss: 1.164154, acc: 21.88%] [G loss: 6.050353]\n",
      "epoch:39 step:30973 [D loss: 0.083151, acc: 99.22%] [G loss: 4.163112]\n",
      "epoch:39 step:30974 [D loss: 0.320115, acc: 90.62%] [G loss: 5.897527]\n",
      "epoch:39 step:30975 [D loss: 0.172890, acc: 98.44%] [G loss: 5.978951]\n",
      "epoch:39 step:30976 [D loss: 0.038767, acc: 100.00%] [G loss: 5.481199]\n",
      "epoch:39 step:30977 [D loss: 0.098179, acc: 99.22%] [G loss: 6.050269]\n",
      "epoch:39 step:30978 [D loss: 0.322042, acc: 86.72%] [G loss: 6.072476]\n",
      "epoch:39 step:30979 [D loss: 0.855774, acc: 50.78%] [G loss: 2.814232]\n",
      "epoch:39 step:30980 [D loss: 0.192912, acc: 96.88%] [G loss: 4.834473]\n",
      "epoch:39 step:30981 [D loss: 0.633355, acc: 52.34%] [G loss: 2.615618]\n",
      "epoch:39 step:30982 [D loss: 0.195291, acc: 95.31%] [G loss: 6.162278]\n",
      "epoch:39 step:30983 [D loss: 0.175496, acc: 96.09%] [G loss: 5.741961]\n",
      "epoch:39 step:30984 [D loss: 0.883466, acc: 42.19%] [G loss: 6.743853]\n",
      "epoch:39 step:30985 [D loss: 0.190634, acc: 99.22%] [G loss: 6.858306]\n",
      "epoch:39 step:30986 [D loss: 0.206191, acc: 96.09%] [G loss: 7.937160]\n",
      "epoch:39 step:30987 [D loss: 0.217656, acc: 93.75%] [G loss: 7.092954]\n",
      "epoch:39 step:30988 [D loss: 0.659955, acc: 57.81%] [G loss: 3.775667]\n",
      "epoch:39 step:30989 [D loss: 0.040515, acc: 100.00%] [G loss: 8.544025]\n",
      "epoch:39 step:30990 [D loss: 0.225526, acc: 96.88%] [G loss: 7.949660]\n",
      "epoch:39 step:30991 [D loss: 0.135073, acc: 100.00%] [G loss: 4.473047]\n",
      "epoch:39 step:30992 [D loss: 0.130324, acc: 99.22%] [G loss: 7.748386]\n",
      "epoch:39 step:30993 [D loss: 0.109197, acc: 99.22%] [G loss: 6.429283]\n",
      "epoch:39 step:30994 [D loss: 0.338276, acc: 89.84%] [G loss: 5.318383]\n",
      "epoch:39 step:30995 [D loss: 0.328977, acc: 92.97%] [G loss: 6.611190]\n",
      "epoch:39 step:30996 [D loss: 0.090259, acc: 100.00%] [G loss: 4.495846]\n",
      "epoch:39 step:30997 [D loss: 1.072924, acc: 51.56%] [G loss: 7.455130]\n",
      "epoch:39 step:30998 [D loss: 0.403803, acc: 85.16%] [G loss: 3.512638]\n",
      "epoch:39 step:30999 [D loss: 0.393869, acc: 72.66%] [G loss: 8.173141]\n",
      "epoch:39 step:31000 [D loss: 0.245740, acc: 96.88%] [G loss: 4.721694]\n",
      "epoch:39 step:31001 [D loss: 0.018242, acc: 100.00%] [G loss: 6.396132]\n",
      "epoch:39 step:31002 [D loss: 0.457654, acc: 76.56%] [G loss: 6.238732]\n",
      "epoch:39 step:31003 [D loss: 0.288359, acc: 96.09%] [G loss: 5.241220]\n",
      "epoch:39 step:31004 [D loss: 0.180747, acc: 98.44%] [G loss: 6.539982]\n",
      "epoch:39 step:31005 [D loss: 0.158682, acc: 97.66%] [G loss: 3.050762]\n",
      "epoch:39 step:31006 [D loss: 0.181169, acc: 96.88%] [G loss: 2.671047]\n",
      "epoch:39 step:31007 [D loss: 0.062568, acc: 100.00%] [G loss: 5.452664]\n",
      "epoch:39 step:31008 [D loss: 0.066940, acc: 100.00%] [G loss: 3.628716]\n",
      "epoch:39 step:31009 [D loss: 0.110041, acc: 100.00%] [G loss: 5.771724]\n",
      "epoch:39 step:31010 [D loss: 0.069671, acc: 100.00%] [G loss: 4.608864]\n",
      "epoch:39 step:31011 [D loss: 1.330437, acc: 46.09%] [G loss: 7.310258]\n",
      "epoch:39 step:31012 [D loss: 1.672053, acc: 45.31%] [G loss: 6.656950]\n",
      "epoch:39 step:31013 [D loss: 1.519992, acc: 48.44%] [G loss: 5.453447]\n",
      "epoch:39 step:31014 [D loss: 0.432765, acc: 85.94%] [G loss: 9.519448]\n",
      "epoch:39 step:31015 [D loss: 0.379303, acc: 85.94%] [G loss: 6.868271]\n",
      "epoch:39 step:31016 [D loss: 0.700071, acc: 55.47%] [G loss: 5.727469]\n",
      "epoch:39 step:31017 [D loss: 0.158164, acc: 98.44%] [G loss: 4.194726]\n",
      "epoch:39 step:31018 [D loss: 0.078968, acc: 100.00%] [G loss: 4.145347]\n",
      "epoch:39 step:31019 [D loss: 0.395544, acc: 72.66%] [G loss: 7.188293]\n",
      "epoch:39 step:31020 [D loss: 0.143757, acc: 97.66%] [G loss: 3.282434]\n",
      "epoch:39 step:31021 [D loss: 0.272250, acc: 94.53%] [G loss: 3.569150]\n",
      "epoch:39 step:31022 [D loss: 0.358171, acc: 82.03%] [G loss: 4.676882]\n",
      "epoch:39 step:31023 [D loss: 0.179497, acc: 98.44%] [G loss: 6.962421]\n",
      "epoch:39 step:31024 [D loss: 0.019252, acc: 100.00%] [G loss: 7.612026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31025 [D loss: 0.610769, acc: 62.50%] [G loss: 3.920866]\n",
      "epoch:39 step:31026 [D loss: 0.147716, acc: 96.09%] [G loss: 6.315406]\n",
      "epoch:39 step:31027 [D loss: 0.042344, acc: 100.00%] [G loss: 4.384294]\n",
      "epoch:39 step:31028 [D loss: 0.162095, acc: 99.22%] [G loss: 5.175956]\n",
      "epoch:39 step:31029 [D loss: 0.360406, acc: 84.38%] [G loss: 3.147449]\n",
      "epoch:39 step:31030 [D loss: 0.382488, acc: 82.03%] [G loss: 7.429452]\n",
      "epoch:39 step:31031 [D loss: 0.438811, acc: 77.34%] [G loss: 5.615685]\n",
      "epoch:39 step:31032 [D loss: 0.235146, acc: 92.97%] [G loss: 4.433294]\n",
      "epoch:39 step:31033 [D loss: 1.224424, acc: 45.31%] [G loss: 6.308710]\n",
      "epoch:39 step:31034 [D loss: 0.703583, acc: 53.91%] [G loss: 3.324140]\n",
      "epoch:39 step:31035 [D loss: 0.043570, acc: 100.00%] [G loss: 4.890307]\n",
      "epoch:39 step:31036 [D loss: 0.336729, acc: 81.25%] [G loss: 6.590579]\n",
      "epoch:39 step:31037 [D loss: 0.046599, acc: 100.00%] [G loss: 8.429005]\n",
      "epoch:39 step:31038 [D loss: 0.289245, acc: 85.16%] [G loss: 4.853198]\n",
      "epoch:39 step:31039 [D loss: 0.632564, acc: 67.97%] [G loss: 6.509316]\n",
      "epoch:39 step:31040 [D loss: 0.016513, acc: 100.00%] [G loss: 11.250065]\n",
      "epoch:39 step:31041 [D loss: 0.248331, acc: 92.19%] [G loss: 4.481697]\n",
      "epoch:39 step:31042 [D loss: 0.895239, acc: 40.62%] [G loss: 5.355857]\n",
      "epoch:39 step:31043 [D loss: 0.057337, acc: 100.00%] [G loss: 3.221033]\n",
      "epoch:39 step:31044 [D loss: 0.055666, acc: 100.00%] [G loss: 8.065826]\n",
      "epoch:39 step:31045 [D loss: 0.040591, acc: 100.00%] [G loss: 4.858474]\n",
      "epoch:39 step:31046 [D loss: 0.196685, acc: 98.44%] [G loss: 4.562428]\n",
      "epoch:39 step:31047 [D loss: 0.404033, acc: 86.72%] [G loss: 5.350016]\n",
      "epoch:39 step:31048 [D loss: 0.062867, acc: 100.00%] [G loss: 3.453726]\n",
      "epoch:39 step:31049 [D loss: 0.439051, acc: 76.56%] [G loss: 3.220972]\n",
      "epoch:39 step:31050 [D loss: 0.547668, acc: 66.41%] [G loss: 6.157889]\n",
      "epoch:39 step:31051 [D loss: 1.370097, acc: 10.16%] [G loss: 5.999148]\n",
      "epoch:39 step:31052 [D loss: 0.052794, acc: 100.00%] [G loss: 4.665524]\n",
      "epoch:39 step:31053 [D loss: 0.447173, acc: 69.53%] [G loss: 4.722518]\n",
      "epoch:39 step:31054 [D loss: 0.554079, acc: 66.41%] [G loss: 6.967532]\n",
      "epoch:39 step:31055 [D loss: 0.085673, acc: 99.22%] [G loss: 7.938309]\n",
      "epoch:39 step:31056 [D loss: 0.057614, acc: 100.00%] [G loss: 6.542559]\n",
      "epoch:39 step:31057 [D loss: 0.183974, acc: 98.44%] [G loss: 6.886195]\n",
      "epoch:39 step:31058 [D loss: 0.998943, acc: 29.69%] [G loss: 5.056033]\n",
      "epoch:39 step:31059 [D loss: 2.105323, acc: 2.34%] [G loss: 4.159219]\n",
      "epoch:39 step:31060 [D loss: 0.345848, acc: 81.25%] [G loss: 6.495538]\n",
      "epoch:39 step:31061 [D loss: 0.869240, acc: 50.00%] [G loss: 3.831896]\n",
      "epoch:39 step:31062 [D loss: 0.231832, acc: 93.75%] [G loss: 3.625883]\n",
      "epoch:39 step:31063 [D loss: 0.481710, acc: 67.97%] [G loss: 4.510794]\n",
      "epoch:39 step:31064 [D loss: 1.289757, acc: 50.78%] [G loss: 3.868524]\n",
      "epoch:39 step:31065 [D loss: 0.050126, acc: 99.22%] [G loss: 2.497442]\n",
      "epoch:39 step:31066 [D loss: 0.182919, acc: 97.66%] [G loss: 4.815129]\n",
      "epoch:39 step:31067 [D loss: 0.193098, acc: 95.31%] [G loss: 5.745587]\n",
      "epoch:39 step:31068 [D loss: 0.128602, acc: 98.44%] [G loss: 6.181062]\n",
      "epoch:39 step:31069 [D loss: 0.274101, acc: 94.53%] [G loss: 6.425303]\n",
      "epoch:39 step:31070 [D loss: 0.188409, acc: 98.44%] [G loss: 6.456419]\n",
      "epoch:39 step:31071 [D loss: 0.213576, acc: 97.66%] [G loss: 5.773723]\n",
      "epoch:39 step:31072 [D loss: 0.126518, acc: 100.00%] [G loss: 3.478245]\n",
      "epoch:39 step:31073 [D loss: 0.016802, acc: 100.00%] [G loss: 6.306684]\n",
      "epoch:39 step:31074 [D loss: 0.551531, acc: 60.16%] [G loss: 5.208783]\n",
      "epoch:39 step:31075 [D loss: 0.400340, acc: 83.59%] [G loss: 5.544947]\n",
      "epoch:39 step:31076 [D loss: 0.284651, acc: 92.19%] [G loss: 5.193143]\n",
      "epoch:39 step:31077 [D loss: 0.369733, acc: 92.19%] [G loss: 5.409244]\n",
      "epoch:39 step:31078 [D loss: 0.245774, acc: 92.19%] [G loss: 5.957443]\n",
      "epoch:39 step:31079 [D loss: 0.363970, acc: 91.41%] [G loss: 2.590775]\n",
      "epoch:39 step:31080 [D loss: 1.221301, acc: 32.81%] [G loss: 5.581084]\n",
      "epoch:39 step:31081 [D loss: 1.113510, acc: 40.62%] [G loss: 5.851969]\n",
      "epoch:39 step:31082 [D loss: 1.164803, acc: 30.47%] [G loss: 5.312654]\n",
      "epoch:39 step:31083 [D loss: 0.268795, acc: 92.97%] [G loss: 6.509117]\n",
      "epoch:39 step:31084 [D loss: 0.817861, acc: 53.12%] [G loss: 5.939368]\n",
      "epoch:39 step:31085 [D loss: 0.220305, acc: 98.44%] [G loss: 3.778044]\n",
      "epoch:39 step:31086 [D loss: 0.253054, acc: 94.53%] [G loss: 6.078484]\n",
      "epoch:39 step:31087 [D loss: 1.272529, acc: 21.09%] [G loss: 4.897159]\n",
      "epoch:39 step:31088 [D loss: 0.481214, acc: 69.53%] [G loss: 4.528213]\n",
      "epoch:39 step:31089 [D loss: 0.008957, acc: 100.00%] [G loss: 7.110112]\n",
      "epoch:39 step:31090 [D loss: 0.764197, acc: 50.00%] [G loss: 3.618601]\n",
      "epoch:39 step:31091 [D loss: 0.966393, acc: 37.50%] [G loss: 3.303402]\n",
      "epoch:39 step:31092 [D loss: 0.135828, acc: 100.00%] [G loss: 7.373938]\n",
      "epoch:39 step:31093 [D loss: 1.349066, acc: 11.72%] [G loss: 3.223490]\n",
      "epoch:39 step:31094 [D loss: 0.101290, acc: 99.22%] [G loss: 4.146790]\n",
      "epoch:39 step:31095 [D loss: 0.103400, acc: 100.00%] [G loss: 4.068243]\n",
      "epoch:39 step:31096 [D loss: 0.177253, acc: 100.00%] [G loss: 7.311021]\n",
      "epoch:39 step:31097 [D loss: 0.871841, acc: 50.00%] [G loss: 5.739554]\n",
      "epoch:39 step:31098 [D loss: 0.247244, acc: 95.31%] [G loss: 2.520388]\n",
      "epoch:39 step:31099 [D loss: 0.154825, acc: 99.22%] [G loss: 6.170037]\n",
      "epoch:39 step:31100 [D loss: 0.119200, acc: 99.22%] [G loss: 5.455520]\n",
      "epoch:39 step:31101 [D loss: 0.099344, acc: 100.00%] [G loss: 5.239852]\n",
      "epoch:39 step:31102 [D loss: 0.474657, acc: 79.69%] [G loss: 4.544263]\n",
      "epoch:39 step:31103 [D loss: 0.009331, acc: 100.00%] [G loss: 5.189971]\n",
      "epoch:39 step:31104 [D loss: 0.301777, acc: 96.09%] [G loss: 3.727349]\n",
      "epoch:39 step:31105 [D loss: 0.758102, acc: 57.81%] [G loss: 5.189356]\n",
      "epoch:39 step:31106 [D loss: 0.205425, acc: 95.31%] [G loss: 4.054249]\n",
      "epoch:39 step:31107 [D loss: 0.036295, acc: 100.00%] [G loss: 7.312708]\n",
      "epoch:39 step:31108 [D loss: 0.174192, acc: 96.88%] [G loss: 5.338112]\n",
      "epoch:39 step:31109 [D loss: 1.278455, acc: 18.75%] [G loss: 5.962846]\n",
      "epoch:39 step:31110 [D loss: 0.689294, acc: 56.25%] [G loss: 6.043407]\n",
      "epoch:39 step:31111 [D loss: 0.426584, acc: 74.22%] [G loss: 2.471184]\n",
      "epoch:39 step:31112 [D loss: 0.023810, acc: 100.00%] [G loss: 4.620718]\n",
      "epoch:39 step:31113 [D loss: 0.589841, acc: 62.50%] [G loss: 4.475527]\n",
      "epoch:39 step:31114 [D loss: 0.127641, acc: 100.00%] [G loss: 10.331951]\n",
      "epoch:39 step:31115 [D loss: 0.439510, acc: 74.22%] [G loss: 4.516837]\n",
      "epoch:39 step:31116 [D loss: 0.194709, acc: 98.44%] [G loss: 5.189398]\n",
      "epoch:39 step:31117 [D loss: 0.301811, acc: 86.72%] [G loss: 5.262181]\n",
      "epoch:39 step:31118 [D loss: 0.115136, acc: 100.00%] [G loss: 7.800302]\n",
      "epoch:39 step:31119 [D loss: 0.432941, acc: 81.25%] [G loss: 5.378714]\n",
      "epoch:39 step:31120 [D loss: 0.343386, acc: 92.19%] [G loss: 5.419410]\n",
      "epoch:39 step:31121 [D loss: 0.281990, acc: 87.50%] [G loss: 5.235936]\n",
      "epoch:39 step:31122 [D loss: 0.475250, acc: 70.31%] [G loss: 2.791332]\n",
      "epoch:39 step:31123 [D loss: 0.331038, acc: 90.62%] [G loss: 6.009855]\n",
      "epoch:39 step:31124 [D loss: 0.091607, acc: 100.00%] [G loss: 4.588799]\n",
      "epoch:39 step:31125 [D loss: 0.146624, acc: 99.22%] [G loss: 4.221157]\n",
      "epoch:39 step:31126 [D loss: 0.007936, acc: 100.00%] [G loss: 6.600715]\n",
      "epoch:39 step:31127 [D loss: 0.106316, acc: 99.22%] [G loss: 6.074754]\n",
      "epoch:39 step:31128 [D loss: 0.122877, acc: 100.00%] [G loss: 4.903915]\n",
      "epoch:39 step:31129 [D loss: 0.147759, acc: 99.22%] [G loss: 3.368062]\n",
      "epoch:39 step:31130 [D loss: 0.384537, acc: 78.12%] [G loss: 7.916641]\n",
      "epoch:39 step:31131 [D loss: 0.179102, acc: 98.44%] [G loss: 1.409671]\n",
      "epoch:39 step:31132 [D loss: 0.776057, acc: 50.78%] [G loss: 5.908100]\n",
      "epoch:39 step:31133 [D loss: 1.487937, acc: 21.09%] [G loss: 4.783916]\n",
      "epoch:39 step:31134 [D loss: 0.035730, acc: 100.00%] [G loss: 4.451065]\n",
      "epoch:39 step:31135 [D loss: 1.793023, acc: 48.44%] [G loss: 4.541532]\n",
      "epoch:39 step:31136 [D loss: 0.220233, acc: 95.31%] [G loss: 4.700352]\n",
      "epoch:39 step:31137 [D loss: 0.140931, acc: 97.66%] [G loss: 2.624676]\n",
      "epoch:39 step:31138 [D loss: 0.756470, acc: 52.34%] [G loss: 2.959942]\n",
      "epoch:39 step:31139 [D loss: 0.055962, acc: 100.00%] [G loss: 4.810114]\n",
      "epoch:39 step:31140 [D loss: 0.084912, acc: 100.00%] [G loss: 4.411669]\n",
      "epoch:39 step:31141 [D loss: 0.371565, acc: 90.62%] [G loss: 3.420279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31142 [D loss: 0.283467, acc: 96.09%] [G loss: 2.769557]\n",
      "epoch:39 step:31143 [D loss: 1.735621, acc: 3.91%] [G loss: 3.220033]\n",
      "epoch:39 step:31144 [D loss: 0.159219, acc: 98.44%] [G loss: 6.081364]\n",
      "epoch:39 step:31145 [D loss: 1.483901, acc: 27.34%] [G loss: 5.969297]\n",
      "epoch:39 step:31146 [D loss: 0.105676, acc: 98.44%] [G loss: 2.651188]\n",
      "epoch:39 step:31147 [D loss: 0.295948, acc: 95.31%] [G loss: 3.993882]\n",
      "epoch:39 step:31148 [D loss: 0.112505, acc: 100.00%] [G loss: 4.201578]\n",
      "epoch:39 step:31149 [D loss: 0.162367, acc: 98.44%] [G loss: 4.437807]\n",
      "epoch:39 step:31150 [D loss: 0.082071, acc: 100.00%] [G loss: 4.930544]\n",
      "epoch:39 step:31151 [D loss: 0.231510, acc: 94.53%] [G loss: 5.927948]\n",
      "epoch:39 step:31152 [D loss: 0.142449, acc: 97.66%] [G loss: 5.072742]\n",
      "epoch:39 step:31153 [D loss: 0.355083, acc: 89.06%] [G loss: 4.721193]\n",
      "epoch:39 step:31154 [D loss: 0.519397, acc: 64.06%] [G loss: 4.454315]\n",
      "epoch:39 step:31155 [D loss: 0.430940, acc: 75.00%] [G loss: 4.377436]\n",
      "epoch:39 step:31156 [D loss: 0.106454, acc: 100.00%] [G loss: 5.229492]\n",
      "epoch:39 step:31157 [D loss: 0.187505, acc: 95.31%] [G loss: 6.599641]\n",
      "epoch:39 step:31158 [D loss: 0.079065, acc: 100.00%] [G loss: 5.023950]\n",
      "epoch:39 step:31159 [D loss: 0.213598, acc: 95.31%] [G loss: 7.041988]\n",
      "epoch:39 step:31160 [D loss: 0.895642, acc: 38.28%] [G loss: 5.674197]\n",
      "epoch:39 step:31161 [D loss: 0.663901, acc: 60.16%] [G loss: 5.205212]\n",
      "epoch:39 step:31162 [D loss: 0.712831, acc: 53.91%] [G loss: 5.613009]\n",
      "epoch:39 step:31163 [D loss: 0.213816, acc: 94.53%] [G loss: 5.599498]\n",
      "epoch:39 step:31164 [D loss: 0.162467, acc: 97.66%] [G loss: 5.352515]\n",
      "epoch:39 step:31165 [D loss: 0.049660, acc: 100.00%] [G loss: 2.826481]\n",
      "epoch:39 step:31166 [D loss: 0.362324, acc: 89.84%] [G loss: 7.344977]\n",
      "epoch:39 step:31167 [D loss: 0.359160, acc: 84.38%] [G loss: 5.600093]\n",
      "epoch:39 step:31168 [D loss: 0.364217, acc: 84.38%] [G loss: 7.231709]\n",
      "epoch:39 step:31169 [D loss: 0.576426, acc: 74.22%] [G loss: 4.770222]\n",
      "epoch:39 step:31170 [D loss: 0.010948, acc: 100.00%] [G loss: 6.368799]\n",
      "epoch:39 step:31171 [D loss: 0.126562, acc: 100.00%] [G loss: 4.977664]\n",
      "epoch:39 step:31172 [D loss: 0.016068, acc: 100.00%] [G loss: 2.357794]\n",
      "epoch:39 step:31173 [D loss: 0.287510, acc: 93.75%] [G loss: 4.922431]\n",
      "epoch:39 step:31174 [D loss: 0.411369, acc: 87.50%] [G loss: 5.940028]\n",
      "epoch:39 step:31175 [D loss: 0.085521, acc: 100.00%] [G loss: 5.464258]\n",
      "epoch:39 step:31176 [D loss: 0.251707, acc: 94.53%] [G loss: 6.004493]\n",
      "epoch:39 step:31177 [D loss: 0.700010, acc: 60.16%] [G loss: 5.524805]\n",
      "epoch:39 step:31178 [D loss: 1.165577, acc: 49.22%] [G loss: 4.364000]\n",
      "epoch:39 step:31179 [D loss: 0.121985, acc: 98.44%] [G loss: 4.237962]\n",
      "epoch:39 step:31180 [D loss: 0.229036, acc: 91.41%] [G loss: 3.739124]\n",
      "epoch:39 step:31181 [D loss: 0.810443, acc: 43.75%] [G loss: 6.315298]\n",
      "epoch:39 step:31182 [D loss: 0.213033, acc: 96.09%] [G loss: 5.338044]\n",
      "epoch:39 step:31183 [D loss: 0.191620, acc: 98.44%] [G loss: 6.538209]\n",
      "epoch:39 step:31184 [D loss: 0.281175, acc: 92.97%] [G loss: 4.789701]\n",
      "epoch:39 step:31185 [D loss: 0.133922, acc: 100.00%] [G loss: 6.454659]\n",
      "epoch:39 step:31186 [D loss: 0.745660, acc: 57.03%] [G loss: 3.378353]\n",
      "epoch:39 step:31187 [D loss: 0.314545, acc: 95.31%] [G loss: 3.032468]\n",
      "epoch:39 step:31188 [D loss: 0.295340, acc: 89.84%] [G loss: 4.955606]\n",
      "epoch:39 step:31189 [D loss: 0.026416, acc: 100.00%] [G loss: 5.513193]\n",
      "epoch:39 step:31190 [D loss: 0.595330, acc: 63.28%] [G loss: 4.271562]\n",
      "epoch:39 step:31191 [D loss: 0.153213, acc: 94.53%] [G loss: 3.136892]\n",
      "epoch:39 step:31192 [D loss: 0.120546, acc: 98.44%] [G loss: 6.750050]\n",
      "epoch:39 step:31193 [D loss: 0.154575, acc: 99.22%] [G loss: 4.465465]\n",
      "epoch:39 step:31194 [D loss: 0.162784, acc: 99.22%] [G loss: 5.316822]\n",
      "epoch:39 step:31195 [D loss: 0.129230, acc: 97.66%] [G loss: 5.578028]\n",
      "epoch:39 step:31196 [D loss: 0.124497, acc: 100.00%] [G loss: 5.300285]\n",
      "epoch:39 step:31197 [D loss: 0.189985, acc: 98.44%] [G loss: 5.017885]\n",
      "epoch:39 step:31198 [D loss: 0.130773, acc: 100.00%] [G loss: 6.087385]\n",
      "epoch:39 step:31199 [D loss: 0.843711, acc: 51.56%] [G loss: 6.549184]\n",
      "epoch:39 step:31200 [D loss: 0.784801, acc: 54.69%] [G loss: 4.783188]\n",
      "epoch:39 step:31201 [D loss: 0.059965, acc: 100.00%] [G loss: 3.102738]\n",
      "epoch:39 step:31202 [D loss: 0.832999, acc: 50.78%] [G loss: 8.135088]\n",
      "epoch:39 step:31203 [D loss: 0.409349, acc: 80.47%] [G loss: 2.733347]\n",
      "epoch:39 step:31204 [D loss: 0.030776, acc: 100.00%] [G loss: 2.737350]\n",
      "epoch:39 step:31205 [D loss: 0.294688, acc: 85.16%] [G loss: 2.501418]\n",
      "epoch:39 step:31206 [D loss: 0.232958, acc: 95.31%] [G loss: 5.395829]\n",
      "epoch:39 step:31207 [D loss: 0.088904, acc: 98.44%] [G loss: 3.190647]\n",
      "epoch:39 step:31208 [D loss: 0.671712, acc: 60.16%] [G loss: 5.285772]\n",
      "epoch:39 step:31209 [D loss: 0.108953, acc: 100.00%] [G loss: 5.344102]\n",
      "epoch:39 step:31210 [D loss: 0.593858, acc: 65.62%] [G loss: 5.221048]\n",
      "epoch:39 step:31211 [D loss: 0.245424, acc: 89.84%] [G loss: 6.286437]\n",
      "epoch:39 step:31212 [D loss: 0.255132, acc: 92.19%] [G loss: 6.507331]\n",
      "epoch:39 step:31213 [D loss: 0.068932, acc: 100.00%] [G loss: 4.350245]\n",
      "epoch:39 step:31214 [D loss: 0.377720, acc: 78.12%] [G loss: 5.632459]\n",
      "epoch:39 step:31215 [D loss: 0.107914, acc: 100.00%] [G loss: 5.751372]\n",
      "epoch:39 step:31216 [D loss: 0.542027, acc: 64.06%] [G loss: 5.219465]\n",
      "epoch:39 step:31217 [D loss: 0.455412, acc: 74.22%] [G loss: 4.884171]\n",
      "epoch:39 step:31218 [D loss: 0.074248, acc: 99.22%] [G loss: 4.768354]\n",
      "epoch:39 step:31219 [D loss: 0.109112, acc: 100.00%] [G loss: 5.114917]\n",
      "epoch:39 step:31220 [D loss: 0.074731, acc: 100.00%] [G loss: 4.472759]\n",
      "epoch:39 step:31221 [D loss: 0.160176, acc: 100.00%] [G loss: 4.641045]\n",
      "epoch:39 step:31222 [D loss: 0.816092, acc: 45.31%] [G loss: 5.744769]\n",
      "epoch:39 step:31223 [D loss: 0.233855, acc: 92.97%] [G loss: 4.343109]\n",
      "epoch:39 step:31224 [D loss: 0.237682, acc: 96.88%] [G loss: 6.319520]\n",
      "epoch:39 step:31225 [D loss: 0.299684, acc: 97.66%] [G loss: 3.707219]\n",
      "epoch:39 step:31226 [D loss: 0.110410, acc: 100.00%] [G loss: 7.939469]\n",
      "epoch:39 step:31227 [D loss: 0.403409, acc: 89.06%] [G loss: 6.617598]\n",
      "epoch:39 step:31228 [D loss: 0.503239, acc: 71.88%] [G loss: 4.188467]\n",
      "epoch:39 step:31229 [D loss: 0.305590, acc: 89.84%] [G loss: 5.566553]\n",
      "epoch:39 step:31230 [D loss: 0.166740, acc: 98.44%] [G loss: 5.624310]\n",
      "epoch:39 step:31231 [D loss: 0.071520, acc: 99.22%] [G loss: 5.844679]\n",
      "epoch:39 step:31232 [D loss: 0.143232, acc: 97.66%] [G loss: 7.038583]\n",
      "epoch:39 step:31233 [D loss: 0.389364, acc: 83.59%] [G loss: 4.047386]\n",
      "epoch:39 step:31234 [D loss: 0.191201, acc: 99.22%] [G loss: 3.169286]\n",
      "epoch:39 step:31235 [D loss: 0.299492, acc: 96.88%] [G loss: 6.192146]\n",
      "epoch:39 step:31236 [D loss: 0.683347, acc: 58.59%] [G loss: 5.428251]\n",
      "epoch:39 step:31237 [D loss: 0.238562, acc: 98.44%] [G loss: 4.158353]\n",
      "epoch:39 step:31238 [D loss: 0.022168, acc: 100.00%] [G loss: 6.581348]\n",
      "epoch:39 step:31239 [D loss: 0.327194, acc: 93.75%] [G loss: 6.560454]\n",
      "epoch:39 step:31240 [D loss: 0.228855, acc: 98.44%] [G loss: 4.385412]\n",
      "epoch:40 step:31241 [D loss: 0.344356, acc: 88.28%] [G loss: 6.128390]\n",
      "epoch:40 step:31242 [D loss: 0.123866, acc: 99.22%] [G loss: 6.631166]\n",
      "epoch:40 step:31243 [D loss: 0.214373, acc: 98.44%] [G loss: 5.585966]\n",
      "epoch:40 step:31244 [D loss: 0.072655, acc: 100.00%] [G loss: 5.107310]\n",
      "epoch:40 step:31245 [D loss: 0.240690, acc: 95.31%] [G loss: 3.751443]\n",
      "epoch:40 step:31246 [D loss: 0.265661, acc: 91.41%] [G loss: 4.547169]\n",
      "epoch:40 step:31247 [D loss: 0.479525, acc: 65.62%] [G loss: 6.391361]\n",
      "epoch:40 step:31248 [D loss: 0.561176, acc: 60.16%] [G loss: 3.244073]\n",
      "epoch:40 step:31249 [D loss: 0.078559, acc: 100.00%] [G loss: 5.294647]\n",
      "epoch:40 step:31250 [D loss: 0.045628, acc: 100.00%] [G loss: 5.728904]\n",
      "epoch:40 step:31251 [D loss: 0.233767, acc: 96.09%] [G loss: 5.083628]\n",
      "epoch:40 step:31252 [D loss: 0.148630, acc: 98.44%] [G loss: 3.937225]\n",
      "epoch:40 step:31253 [D loss: 0.174397, acc: 98.44%] [G loss: 6.660391]\n",
      "epoch:40 step:31254 [D loss: 0.226962, acc: 95.31%] [G loss: 3.526934]\n",
      "epoch:40 step:31255 [D loss: 0.754568, acc: 53.91%] [G loss: 6.307775]\n",
      "epoch:40 step:31256 [D loss: 0.736743, acc: 55.47%] [G loss: 5.386592]\n",
      "epoch:40 step:31257 [D loss: 0.122724, acc: 100.00%] [G loss: 5.566715]\n",
      "epoch:40 step:31258 [D loss: 0.297837, acc: 89.84%] [G loss: 5.826860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31259 [D loss: 0.444987, acc: 82.03%] [G loss: 6.659670]\n",
      "epoch:40 step:31260 [D loss: 0.050290, acc: 100.00%] [G loss: 4.412066]\n",
      "epoch:40 step:31261 [D loss: 0.456418, acc: 70.31%] [G loss: 3.020318]\n",
      "epoch:40 step:31262 [D loss: 0.320055, acc: 84.38%] [G loss: 3.537860]\n",
      "epoch:40 step:31263 [D loss: 0.270726, acc: 90.62%] [G loss: 6.915799]\n",
      "epoch:40 step:31264 [D loss: 0.302686, acc: 93.75%] [G loss: 4.860275]\n",
      "epoch:40 step:31265 [D loss: 0.348054, acc: 78.91%] [G loss: 7.036518]\n",
      "epoch:40 step:31266 [D loss: 0.417305, acc: 71.09%] [G loss: 4.913113]\n",
      "epoch:40 step:31267 [D loss: 0.189758, acc: 96.88%] [G loss: 2.732486]\n",
      "epoch:40 step:31268 [D loss: 0.180330, acc: 96.09%] [G loss: 4.447192]\n",
      "epoch:40 step:31269 [D loss: 0.328141, acc: 84.38%] [G loss: 5.544114]\n",
      "epoch:40 step:31270 [D loss: 0.955655, acc: 50.78%] [G loss: 6.662805]\n",
      "epoch:40 step:31271 [D loss: 0.228836, acc: 93.75%] [G loss: 6.303609]\n",
      "epoch:40 step:31272 [D loss: 1.275046, acc: 48.44%] [G loss: 4.340964]\n",
      "epoch:40 step:31273 [D loss: 0.202550, acc: 97.66%] [G loss: 5.780653]\n",
      "epoch:40 step:31274 [D loss: 0.138231, acc: 99.22%] [G loss: 6.324211]\n",
      "epoch:40 step:31275 [D loss: 0.983092, acc: 50.00%] [G loss: 4.530616]\n",
      "epoch:40 step:31276 [D loss: 0.193662, acc: 94.53%] [G loss: 6.256520]\n",
      "epoch:40 step:31277 [D loss: 0.134756, acc: 99.22%] [G loss: 5.592986]\n",
      "epoch:40 step:31278 [D loss: 0.304321, acc: 85.16%] [G loss: 7.446857]\n",
      "epoch:40 step:31279 [D loss: 1.148176, acc: 50.00%] [G loss: 9.601192]\n",
      "epoch:40 step:31280 [D loss: 1.855290, acc: 50.00%] [G loss: 4.466501]\n",
      "epoch:40 step:31281 [D loss: 0.120547, acc: 100.00%] [G loss: 5.991685]\n",
      "epoch:40 step:31282 [D loss: 0.860459, acc: 52.34%] [G loss: 4.618381]\n",
      "epoch:40 step:31283 [D loss: 0.708745, acc: 59.38%] [G loss: 5.316079]\n",
      "epoch:40 step:31284 [D loss: 0.645640, acc: 64.06%] [G loss: 2.706394]\n",
      "epoch:40 step:31285 [D loss: 0.451523, acc: 72.66%] [G loss: 6.553607]\n",
      "epoch:40 step:31286 [D loss: 0.055146, acc: 99.22%] [G loss: 4.318314]\n",
      "epoch:40 step:31287 [D loss: 0.569453, acc: 59.38%] [G loss: 4.564247]\n",
      "epoch:40 step:31288 [D loss: 0.745096, acc: 52.34%] [G loss: 10.169130]\n",
      "epoch:40 step:31289 [D loss: 0.025141, acc: 100.00%] [G loss: 6.064290]\n",
      "epoch:40 step:31290 [D loss: 1.197764, acc: 50.00%] [G loss: 2.291046]\n",
      "epoch:40 step:31291 [D loss: 0.097086, acc: 99.22%] [G loss: 2.817294]\n",
      "epoch:40 step:31292 [D loss: 0.229235, acc: 92.97%] [G loss: 5.461855]\n",
      "epoch:40 step:31293 [D loss: 0.072677, acc: 100.00%] [G loss: 4.302217]\n",
      "epoch:40 step:31294 [D loss: 0.318827, acc: 83.59%] [G loss: 6.250321]\n",
      "epoch:40 step:31295 [D loss: 0.113086, acc: 100.00%] [G loss: 2.910624]\n",
      "epoch:40 step:31296 [D loss: 0.472939, acc: 77.34%] [G loss: 5.100801]\n",
      "epoch:40 step:31297 [D loss: 0.256329, acc: 91.41%] [G loss: 6.114422]\n",
      "epoch:40 step:31298 [D loss: 0.872127, acc: 54.69%] [G loss: 6.633466]\n",
      "epoch:40 step:31299 [D loss: 0.506174, acc: 66.41%] [G loss: 6.023562]\n",
      "epoch:40 step:31300 [D loss: 0.098855, acc: 100.00%] [G loss: 5.821325]\n",
      "epoch:40 step:31301 [D loss: 0.315669, acc: 85.16%] [G loss: 6.863176]\n",
      "epoch:40 step:31302 [D loss: 0.058439, acc: 100.00%] [G loss: 8.546106]\n",
      "epoch:40 step:31303 [D loss: 0.621131, acc: 55.47%] [G loss: 5.016771]\n",
      "epoch:40 step:31304 [D loss: 0.164088, acc: 99.22%] [G loss: 1.980656]\n",
      "epoch:40 step:31305 [D loss: 2.420434, acc: 3.12%] [G loss: 7.805553]\n",
      "epoch:40 step:31306 [D loss: 0.865853, acc: 46.09%] [G loss: 5.840784]\n",
      "epoch:40 step:31307 [D loss: 0.462449, acc: 73.44%] [G loss: 6.538126]\n",
      "epoch:40 step:31308 [D loss: 0.379315, acc: 80.47%] [G loss: 1.591354]\n",
      "epoch:40 step:31309 [D loss: 0.277964, acc: 92.19%] [G loss: 7.047980]\n",
      "epoch:40 step:31310 [D loss: 0.368681, acc: 81.25%] [G loss: 2.744470]\n",
      "epoch:40 step:31311 [D loss: 1.249354, acc: 18.75%] [G loss: 8.617752]\n",
      "epoch:40 step:31312 [D loss: 0.567046, acc: 59.38%] [G loss: 5.297237]\n",
      "epoch:40 step:31313 [D loss: 0.399353, acc: 84.38%] [G loss: 5.315848]\n",
      "epoch:40 step:31314 [D loss: 0.216963, acc: 91.41%] [G loss: 4.233753]\n",
      "epoch:40 step:31315 [D loss: 0.208730, acc: 96.88%] [G loss: 5.703453]\n",
      "epoch:40 step:31316 [D loss: 0.380243, acc: 78.12%] [G loss: 6.366642]\n",
      "epoch:40 step:31317 [D loss: 0.429074, acc: 75.00%] [G loss: 4.528461]\n",
      "epoch:40 step:31318 [D loss: 0.031676, acc: 100.00%] [G loss: 6.882742]\n",
      "epoch:40 step:31319 [D loss: 0.647190, acc: 61.72%] [G loss: 8.357780]\n",
      "epoch:40 step:31320 [D loss: 0.074493, acc: 100.00%] [G loss: 6.096760]\n",
      "epoch:40 step:31321 [D loss: 0.856610, acc: 53.12%] [G loss: 5.741014]\n",
      "epoch:40 step:31322 [D loss: 0.131629, acc: 99.22%] [G loss: 5.426059]\n",
      "epoch:40 step:31323 [D loss: 1.414273, acc: 12.50%] [G loss: 7.062909]\n",
      "epoch:40 step:31324 [D loss: 0.113011, acc: 99.22%] [G loss: 5.562725]\n",
      "epoch:40 step:31325 [D loss: 0.077896, acc: 100.00%] [G loss: 5.681276]\n",
      "epoch:40 step:31326 [D loss: 0.657910, acc: 60.16%] [G loss: 8.884639]\n",
      "epoch:40 step:31327 [D loss: 0.471174, acc: 77.34%] [G loss: 4.965710]\n",
      "epoch:40 step:31328 [D loss: 0.086009, acc: 99.22%] [G loss: 4.598279]\n",
      "epoch:40 step:31329 [D loss: 0.140056, acc: 97.66%] [G loss: 8.707537]\n",
      "epoch:40 step:31330 [D loss: 0.209258, acc: 98.44%] [G loss: 5.885350]\n",
      "epoch:40 step:31331 [D loss: 0.098160, acc: 99.22%] [G loss: 3.922592]\n",
      "epoch:40 step:31332 [D loss: 0.040759, acc: 100.00%] [G loss: 5.908333]\n",
      "epoch:40 step:31333 [D loss: 0.119963, acc: 98.44%] [G loss: 3.996181]\n",
      "epoch:40 step:31334 [D loss: 0.056394, acc: 100.00%] [G loss: 2.815880]\n",
      "epoch:40 step:31335 [D loss: 0.808729, acc: 51.56%] [G loss: 5.935615]\n",
      "epoch:40 step:31336 [D loss: 0.435398, acc: 89.84%] [G loss: 5.417598]\n",
      "epoch:40 step:31337 [D loss: 0.681510, acc: 60.16%] [G loss: 3.323354]\n",
      "epoch:40 step:31338 [D loss: 0.093602, acc: 100.00%] [G loss: 6.430001]\n",
      "epoch:40 step:31339 [D loss: 0.006547, acc: 100.00%] [G loss: 6.729163]\n",
      "epoch:40 step:31340 [D loss: 0.119424, acc: 97.66%] [G loss: 5.830647]\n",
      "epoch:40 step:31341 [D loss: 0.358053, acc: 82.81%] [G loss: 5.465374]\n",
      "epoch:40 step:31342 [D loss: 0.444100, acc: 70.31%] [G loss: 6.206872]\n",
      "epoch:40 step:31343 [D loss: 0.135941, acc: 100.00%] [G loss: 6.022084]\n",
      "epoch:40 step:31344 [D loss: 0.100339, acc: 99.22%] [G loss: 5.327651]\n",
      "epoch:40 step:31345 [D loss: 0.195843, acc: 96.09%] [G loss: 6.701506]\n",
      "epoch:40 step:31346 [D loss: 1.077589, acc: 22.66%] [G loss: 3.683428]\n",
      "epoch:40 step:31347 [D loss: 0.146796, acc: 97.66%] [G loss: 5.361927]\n",
      "epoch:40 step:31348 [D loss: 0.125588, acc: 99.22%] [G loss: 5.032613]\n",
      "epoch:40 step:31349 [D loss: 0.146246, acc: 98.44%] [G loss: 4.880111]\n",
      "epoch:40 step:31350 [D loss: 0.538252, acc: 61.72%] [G loss: 4.647911]\n",
      "epoch:40 step:31351 [D loss: 0.626610, acc: 59.38%] [G loss: 5.227639]\n",
      "epoch:40 step:31352 [D loss: 0.008876, acc: 100.00%] [G loss: 7.659925]\n",
      "epoch:40 step:31353 [D loss: 0.137534, acc: 96.88%] [G loss: 3.312408]\n",
      "epoch:40 step:31354 [D loss: 0.756574, acc: 60.16%] [G loss: 3.397058]\n",
      "epoch:40 step:31355 [D loss: 0.569759, acc: 64.84%] [G loss: 4.147601]\n",
      "epoch:40 step:31356 [D loss: 0.698008, acc: 55.47%] [G loss: 2.795716]\n",
      "epoch:40 step:31357 [D loss: 0.191312, acc: 96.88%] [G loss: 3.685274]\n",
      "epoch:40 step:31358 [D loss: 0.131027, acc: 100.00%] [G loss: 4.791104]\n",
      "epoch:40 step:31359 [D loss: 0.064715, acc: 100.00%] [G loss: 3.909667]\n",
      "epoch:40 step:31360 [D loss: 0.130827, acc: 100.00%] [G loss: 6.233270]\n",
      "epoch:40 step:31361 [D loss: 0.363177, acc: 85.94%] [G loss: 2.136415]\n",
      "epoch:40 step:31362 [D loss: 0.060000, acc: 100.00%] [G loss: 3.395923]\n",
      "epoch:40 step:31363 [D loss: 0.640815, acc: 57.81%] [G loss: 3.143496]\n",
      "epoch:40 step:31364 [D loss: 0.187906, acc: 95.31%] [G loss: 3.963511]\n",
      "epoch:40 step:31365 [D loss: 0.478822, acc: 67.19%] [G loss: 3.825644]\n",
      "epoch:40 step:31366 [D loss: 0.132435, acc: 100.00%] [G loss: 3.462844]\n",
      "epoch:40 step:31367 [D loss: 0.260622, acc: 92.19%] [G loss: 6.096036]\n",
      "epoch:40 step:31368 [D loss: 0.242007, acc: 91.41%] [G loss: 6.243337]\n",
      "epoch:40 step:31369 [D loss: 0.885350, acc: 51.56%] [G loss: 5.271739]\n",
      "epoch:40 step:31370 [D loss: 0.138900, acc: 98.44%] [G loss: 3.544056]\n",
      "epoch:40 step:31371 [D loss: 0.439240, acc: 75.78%] [G loss: 5.317899]\n",
      "epoch:40 step:31372 [D loss: 0.305514, acc: 92.19%] [G loss: 6.244138]\n",
      "epoch:40 step:31373 [D loss: 0.201375, acc: 99.22%] [G loss: 5.661421]\n",
      "epoch:40 step:31374 [D loss: 0.444101, acc: 70.31%] [G loss: 7.536885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31375 [D loss: 0.291182, acc: 92.97%] [G loss: 4.855491]\n",
      "epoch:40 step:31376 [D loss: 0.860403, acc: 50.00%] [G loss: 5.869597]\n",
      "epoch:40 step:31377 [D loss: 0.556366, acc: 70.31%] [G loss: 3.997092]\n",
      "epoch:40 step:31378 [D loss: 2.368224, acc: 50.00%] [G loss: 6.681489]\n",
      "epoch:40 step:31379 [D loss: 0.215588, acc: 97.66%] [G loss: 6.117834]\n",
      "epoch:40 step:31380 [D loss: 0.056018, acc: 100.00%] [G loss: 3.979353]\n",
      "epoch:40 step:31381 [D loss: 0.102520, acc: 100.00%] [G loss: 5.725241]\n",
      "epoch:40 step:31382 [D loss: 0.631790, acc: 56.25%] [G loss: 4.876858]\n",
      "epoch:40 step:31383 [D loss: 0.507624, acc: 82.03%] [G loss: 5.518103]\n",
      "epoch:40 step:31384 [D loss: 0.052176, acc: 100.00%] [G loss: 4.671273]\n",
      "epoch:40 step:31385 [D loss: 0.028165, acc: 99.22%] [G loss: 3.993872]\n",
      "epoch:40 step:31386 [D loss: 1.158649, acc: 38.28%] [G loss: 5.883227]\n",
      "epoch:40 step:31387 [D loss: 0.076697, acc: 100.00%] [G loss: 3.466776]\n",
      "epoch:40 step:31388 [D loss: 0.046905, acc: 100.00%] [G loss: 3.552208]\n",
      "epoch:40 step:31389 [D loss: 0.231039, acc: 96.88%] [G loss: 5.063457]\n",
      "epoch:40 step:31390 [D loss: 0.201559, acc: 97.66%] [G loss: 3.678049]\n",
      "epoch:40 step:31391 [D loss: 0.272520, acc: 95.31%] [G loss: 7.950828]\n",
      "epoch:40 step:31392 [D loss: 0.117286, acc: 97.66%] [G loss: 5.256155]\n",
      "epoch:40 step:31393 [D loss: 0.091327, acc: 100.00%] [G loss: 4.024583]\n",
      "epoch:40 step:31394 [D loss: 0.078418, acc: 100.00%] [G loss: 4.200102]\n",
      "epoch:40 step:31395 [D loss: 0.127739, acc: 100.00%] [G loss: 3.498107]\n",
      "epoch:40 step:31396 [D loss: 0.370911, acc: 78.91%] [G loss: 6.034281]\n",
      "epoch:40 step:31397 [D loss: 0.221854, acc: 96.09%] [G loss: 4.645050]\n",
      "epoch:40 step:31398 [D loss: 0.103722, acc: 99.22%] [G loss: 6.025694]\n",
      "epoch:40 step:31399 [D loss: 0.191128, acc: 97.66%] [G loss: 7.020484]\n",
      "epoch:40 step:31400 [D loss: 0.085077, acc: 100.00%] [G loss: 3.190145]\n",
      "epoch:40 step:31401 [D loss: 0.026587, acc: 100.00%] [G loss: 8.892635]\n",
      "epoch:40 step:31402 [D loss: 0.202634, acc: 96.88%] [G loss: 4.948105]\n",
      "epoch:40 step:31403 [D loss: 0.171784, acc: 100.00%] [G loss: 5.669970]\n",
      "epoch:40 step:31404 [D loss: 0.826973, acc: 51.56%] [G loss: 4.297019]\n",
      "epoch:40 step:31405 [D loss: 0.269802, acc: 90.62%] [G loss: 3.186929]\n",
      "epoch:40 step:31406 [D loss: 0.094269, acc: 100.00%] [G loss: 5.864640]\n",
      "epoch:40 step:31407 [D loss: 0.509495, acc: 76.56%] [G loss: 4.870281]\n",
      "epoch:40 step:31408 [D loss: 0.297449, acc: 83.59%] [G loss: 5.399302]\n",
      "epoch:40 step:31409 [D loss: 0.347359, acc: 89.06%] [G loss: 1.961481]\n",
      "epoch:40 step:31410 [D loss: 0.818906, acc: 53.12%] [G loss: 7.684638]\n",
      "epoch:40 step:31411 [D loss: 0.193166, acc: 97.66%] [G loss: 4.168025]\n",
      "epoch:40 step:31412 [D loss: 0.510005, acc: 62.50%] [G loss: 5.024115]\n",
      "epoch:40 step:31413 [D loss: 0.275228, acc: 90.62%] [G loss: 6.952742]\n",
      "epoch:40 step:31414 [D loss: 0.396785, acc: 82.03%] [G loss: 5.901582]\n",
      "epoch:40 step:31415 [D loss: 0.043402, acc: 100.00%] [G loss: 4.841374]\n",
      "epoch:40 step:31416 [D loss: 0.967264, acc: 51.56%] [G loss: 6.086156]\n",
      "epoch:40 step:31417 [D loss: 0.438742, acc: 75.78%] [G loss: 3.390806]\n",
      "epoch:40 step:31418 [D loss: 0.186550, acc: 94.53%] [G loss: 5.508143]\n",
      "epoch:40 step:31419 [D loss: 0.125858, acc: 99.22%] [G loss: 5.443515]\n",
      "epoch:40 step:31420 [D loss: 0.306295, acc: 86.72%] [G loss: 4.911114]\n",
      "epoch:40 step:31421 [D loss: 0.319160, acc: 88.28%] [G loss: 5.193829]\n",
      "epoch:40 step:31422 [D loss: 0.651088, acc: 58.59%] [G loss: 5.693682]\n",
      "epoch:40 step:31423 [D loss: 0.228630, acc: 90.62%] [G loss: 4.998629]\n",
      "epoch:40 step:31424 [D loss: 0.550382, acc: 72.66%] [G loss: 3.731329]\n",
      "epoch:40 step:31425 [D loss: 0.460958, acc: 71.88%] [G loss: 6.255929]\n",
      "epoch:40 step:31426 [D loss: 0.043961, acc: 99.22%] [G loss: 5.618638]\n",
      "epoch:40 step:31427 [D loss: 0.053833, acc: 100.00%] [G loss: 3.786098]\n",
      "epoch:40 step:31428 [D loss: 0.546147, acc: 64.84%] [G loss: 4.866102]\n",
      "epoch:40 step:31429 [D loss: 0.036218, acc: 100.00%] [G loss: 4.775936]\n",
      "epoch:40 step:31430 [D loss: 0.176707, acc: 98.44%] [G loss: 5.594576]\n",
      "epoch:40 step:31431 [D loss: 0.524876, acc: 72.66%] [G loss: 4.025808]\n",
      "epoch:40 step:31432 [D loss: 0.152540, acc: 98.44%] [G loss: 3.792033]\n",
      "epoch:40 step:31433 [D loss: 0.204442, acc: 96.88%] [G loss: 4.224012]\n",
      "epoch:40 step:31434 [D loss: 0.049120, acc: 100.00%] [G loss: 4.087569]\n",
      "epoch:40 step:31435 [D loss: 0.675328, acc: 61.72%] [G loss: 3.301623]\n",
      "epoch:40 step:31436 [D loss: 0.273234, acc: 96.88%] [G loss: 3.253404]\n",
      "epoch:40 step:31437 [D loss: 0.202244, acc: 98.44%] [G loss: 3.141386]\n",
      "epoch:40 step:31438 [D loss: 0.012859, acc: 100.00%] [G loss: 4.993189]\n",
      "epoch:40 step:31439 [D loss: 0.181753, acc: 97.66%] [G loss: 5.425389]\n",
      "epoch:40 step:31440 [D loss: 0.024189, acc: 100.00%] [G loss: 4.399657]\n",
      "epoch:40 step:31441 [D loss: 0.526109, acc: 63.28%] [G loss: 3.846248]\n",
      "epoch:40 step:31442 [D loss: 0.357873, acc: 88.28%] [G loss: 5.091769]\n",
      "epoch:40 step:31443 [D loss: 0.278825, acc: 91.41%] [G loss: 3.807986]\n",
      "epoch:40 step:31444 [D loss: 0.604318, acc: 53.91%] [G loss: 4.199864]\n",
      "epoch:40 step:31445 [D loss: 0.082581, acc: 100.00%] [G loss: 3.782657]\n",
      "epoch:40 step:31446 [D loss: 0.108255, acc: 100.00%] [G loss: 6.770410]\n",
      "epoch:40 step:31447 [D loss: 0.911617, acc: 51.56%] [G loss: 3.022186]\n",
      "epoch:40 step:31448 [D loss: 0.189728, acc: 97.66%] [G loss: 5.098292]\n",
      "epoch:40 step:31449 [D loss: 0.421424, acc: 68.75%] [G loss: 6.776293]\n",
      "epoch:40 step:31450 [D loss: 0.129101, acc: 100.00%] [G loss: 4.331648]\n",
      "epoch:40 step:31451 [D loss: 0.370501, acc: 87.50%] [G loss: 4.745569]\n",
      "epoch:40 step:31452 [D loss: 0.727085, acc: 51.56%] [G loss: 4.630648]\n",
      "epoch:40 step:31453 [D loss: 0.365378, acc: 74.22%] [G loss: 4.626171]\n",
      "epoch:40 step:31454 [D loss: 0.084268, acc: 99.22%] [G loss: 4.649523]\n",
      "epoch:40 step:31455 [D loss: 0.563292, acc: 62.50%] [G loss: 3.824757]\n",
      "epoch:40 step:31456 [D loss: 0.789355, acc: 57.03%] [G loss: 3.883986]\n",
      "epoch:40 step:31457 [D loss: 0.898787, acc: 50.78%] [G loss: 5.253674]\n",
      "epoch:40 step:31458 [D loss: 0.126406, acc: 98.44%] [G loss: 5.021134]\n",
      "epoch:40 step:31459 [D loss: 0.188006, acc: 99.22%] [G loss: 7.155737]\n",
      "epoch:40 step:31460 [D loss: 0.269856, acc: 95.31%] [G loss: 3.998541]\n",
      "epoch:40 step:31461 [D loss: 0.452134, acc: 71.88%] [G loss: 4.584140]\n",
      "epoch:40 step:31462 [D loss: 0.621585, acc: 56.25%] [G loss: 4.391635]\n",
      "epoch:40 step:31463 [D loss: 0.846067, acc: 43.75%] [G loss: 7.465981]\n",
      "epoch:40 step:31464 [D loss: 0.265335, acc: 89.06%] [G loss: 5.869613]\n",
      "epoch:40 step:31465 [D loss: 0.591335, acc: 69.53%] [G loss: 7.741495]\n",
      "epoch:40 step:31466 [D loss: 0.240984, acc: 99.22%] [G loss: 7.152952]\n",
      "epoch:40 step:31467 [D loss: 0.544169, acc: 71.88%] [G loss: 4.635286]\n",
      "epoch:40 step:31468 [D loss: 0.193431, acc: 95.31%] [G loss: 5.549401]\n",
      "epoch:40 step:31469 [D loss: 0.095542, acc: 100.00%] [G loss: 3.868335]\n",
      "epoch:40 step:31470 [D loss: 0.536396, acc: 66.41%] [G loss: 5.925729]\n",
      "epoch:40 step:31471 [D loss: 0.080137, acc: 100.00%] [G loss: 4.374260]\n",
      "epoch:40 step:31472 [D loss: 0.427266, acc: 75.00%] [G loss: 4.130359]\n",
      "epoch:40 step:31473 [D loss: 0.454409, acc: 82.03%] [G loss: 3.238818]\n",
      "epoch:40 step:31474 [D loss: 1.556953, acc: 29.69%] [G loss: 8.605766]\n",
      "epoch:40 step:31475 [D loss: 0.185256, acc: 99.22%] [G loss: 5.338089]\n",
      "epoch:40 step:31476 [D loss: 0.211706, acc: 98.44%] [G loss: 3.827309]\n",
      "epoch:40 step:31477 [D loss: 0.462066, acc: 76.56%] [G loss: 5.272139]\n",
      "epoch:40 step:31478 [D loss: 0.397470, acc: 81.25%] [G loss: 3.718915]\n",
      "epoch:40 step:31479 [D loss: 0.046409, acc: 100.00%] [G loss: 5.294233]\n",
      "epoch:40 step:31480 [D loss: 0.127762, acc: 99.22%] [G loss: 4.817364]\n",
      "epoch:40 step:31481 [D loss: 0.099853, acc: 100.00%] [G loss: 4.644929]\n",
      "epoch:40 step:31482 [D loss: 0.098794, acc: 100.00%] [G loss: 5.936433]\n",
      "epoch:40 step:31483 [D loss: 0.044126, acc: 100.00%] [G loss: 6.269813]\n",
      "epoch:40 step:31484 [D loss: 0.226298, acc: 97.66%] [G loss: 7.283681]\n",
      "epoch:40 step:31485 [D loss: 0.381767, acc: 80.47%] [G loss: 4.529472]\n",
      "epoch:40 step:31486 [D loss: 0.052585, acc: 100.00%] [G loss: 5.234282]\n",
      "epoch:40 step:31487 [D loss: 0.441498, acc: 85.16%] [G loss: 6.763070]\n",
      "epoch:40 step:31488 [D loss: 0.853880, acc: 39.84%] [G loss: 5.195006]\n",
      "epoch:40 step:31489 [D loss: 0.102035, acc: 100.00%] [G loss: 5.428768]\n",
      "epoch:40 step:31490 [D loss: 0.045687, acc: 100.00%] [G loss: 5.933190]\n",
      "epoch:40 step:31491 [D loss: 0.294824, acc: 96.09%] [G loss: 6.431509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31492 [D loss: 1.232135, acc: 23.44%] [G loss: 4.998161]\n",
      "epoch:40 step:31493 [D loss: 0.741284, acc: 55.47%] [G loss: 4.334791]\n",
      "epoch:40 step:31494 [D loss: 0.545366, acc: 77.34%] [G loss: 5.362981]\n",
      "epoch:40 step:31495 [D loss: 0.251878, acc: 94.53%] [G loss: 5.620741]\n",
      "epoch:40 step:31496 [D loss: 0.301552, acc: 95.31%] [G loss: 6.283597]\n",
      "epoch:40 step:31497 [D loss: 0.128079, acc: 99.22%] [G loss: 4.606504]\n",
      "epoch:40 step:31498 [D loss: 0.179691, acc: 99.22%] [G loss: 4.919044]\n",
      "epoch:40 step:31499 [D loss: 0.133564, acc: 100.00%] [G loss: 1.420095]\n",
      "epoch:40 step:31500 [D loss: 0.587952, acc: 60.16%] [G loss: 5.331366]\n",
      "epoch:40 step:31501 [D loss: 0.101070, acc: 100.00%] [G loss: 6.591213]\n",
      "epoch:40 step:31502 [D loss: 0.186786, acc: 98.44%] [G loss: 4.762225]\n",
      "epoch:40 step:31503 [D loss: 0.946003, acc: 32.81%] [G loss: 4.954978]\n",
      "epoch:40 step:31504 [D loss: 0.118301, acc: 100.00%] [G loss: 7.744434]\n",
      "epoch:40 step:31505 [D loss: 0.112300, acc: 99.22%] [G loss: 4.847310]\n",
      "epoch:40 step:31506 [D loss: 0.898599, acc: 51.56%] [G loss: 3.123675]\n",
      "epoch:40 step:31507 [D loss: 0.055446, acc: 100.00%] [G loss: 8.708601]\n",
      "epoch:40 step:31508 [D loss: 1.022828, acc: 50.00%] [G loss: 4.825543]\n",
      "epoch:40 step:31509 [D loss: 0.359092, acc: 87.50%] [G loss: 4.856418]\n",
      "epoch:40 step:31510 [D loss: 0.634037, acc: 57.03%] [G loss: 4.626135]\n",
      "epoch:40 step:31511 [D loss: 1.186737, acc: 50.00%] [G loss: 5.226580]\n",
      "epoch:40 step:31512 [D loss: 0.111604, acc: 100.00%] [G loss: 4.527519]\n",
      "epoch:40 step:31513 [D loss: 0.675407, acc: 53.12%] [G loss: 6.275606]\n",
      "epoch:40 step:31514 [D loss: 0.091449, acc: 100.00%] [G loss: 5.205362]\n",
      "epoch:40 step:31515 [D loss: 0.284737, acc: 89.84%] [G loss: 2.920461]\n",
      "epoch:40 step:31516 [D loss: 0.516385, acc: 65.62%] [G loss: 6.137100]\n",
      "epoch:40 step:31517 [D loss: 0.045096, acc: 100.00%] [G loss: 4.145041]\n",
      "epoch:40 step:31518 [D loss: 0.065852, acc: 100.00%] [G loss: 7.726537]\n",
      "epoch:40 step:31519 [D loss: 1.228648, acc: 40.62%] [G loss: 4.763890]\n",
      "epoch:40 step:31520 [D loss: 0.059949, acc: 100.00%] [G loss: 4.689677]\n",
      "epoch:40 step:31521 [D loss: 0.036818, acc: 100.00%] [G loss: 4.266004]\n",
      "epoch:40 step:31522 [D loss: 1.039134, acc: 50.00%] [G loss: 3.789961]\n",
      "epoch:40 step:31523 [D loss: 0.386356, acc: 85.16%] [G loss: 4.379886]\n",
      "epoch:40 step:31524 [D loss: 0.201919, acc: 100.00%] [G loss: 6.519859]\n",
      "epoch:40 step:31525 [D loss: 1.780563, acc: 46.09%] [G loss: 6.437490]\n",
      "epoch:40 step:31526 [D loss: 0.264760, acc: 94.53%] [G loss: 7.804493]\n",
      "epoch:40 step:31527 [D loss: 0.284805, acc: 93.75%] [G loss: 7.592983]\n",
      "epoch:40 step:31528 [D loss: 0.562751, acc: 69.53%] [G loss: 3.782256]\n",
      "epoch:40 step:31529 [D loss: 0.764214, acc: 47.66%] [G loss: 6.418973]\n",
      "epoch:40 step:31530 [D loss: 0.758195, acc: 55.47%] [G loss: 6.888545]\n",
      "epoch:40 step:31531 [D loss: 0.714086, acc: 53.91%] [G loss: 5.659304]\n",
      "epoch:40 step:31532 [D loss: 0.780080, acc: 52.34%] [G loss: 4.654140]\n",
      "epoch:40 step:31533 [D loss: 0.160111, acc: 96.88%] [G loss: 6.499578]\n",
      "epoch:40 step:31534 [D loss: 0.931705, acc: 46.09%] [G loss: 2.306465]\n",
      "epoch:40 step:31535 [D loss: 0.413438, acc: 71.88%] [G loss: 6.362642]\n",
      "epoch:40 step:31536 [D loss: 0.122389, acc: 100.00%] [G loss: 6.043926]\n",
      "epoch:40 step:31537 [D loss: 0.312849, acc: 87.50%] [G loss: 5.485908]\n",
      "epoch:40 step:31538 [D loss: 0.215054, acc: 96.88%] [G loss: 5.636780]\n",
      "epoch:40 step:31539 [D loss: 0.419144, acc: 81.25%] [G loss: 2.532816]\n",
      "epoch:40 step:31540 [D loss: 0.183953, acc: 99.22%] [G loss: 3.384431]\n",
      "epoch:40 step:31541 [D loss: 0.193238, acc: 96.09%] [G loss: 3.972123]\n",
      "epoch:40 step:31542 [D loss: 0.726022, acc: 53.12%] [G loss: 3.656409]\n",
      "epoch:40 step:31543 [D loss: 0.589604, acc: 63.28%] [G loss: 5.615913]\n",
      "epoch:40 step:31544 [D loss: 0.087667, acc: 100.00%] [G loss: 3.069917]\n",
      "epoch:40 step:31545 [D loss: 0.102407, acc: 100.00%] [G loss: 7.264893]\n",
      "epoch:40 step:31546 [D loss: 0.203187, acc: 96.88%] [G loss: 5.044510]\n",
      "epoch:40 step:31547 [D loss: 0.452564, acc: 71.09%] [G loss: 7.548857]\n",
      "epoch:40 step:31548 [D loss: 0.406487, acc: 89.06%] [G loss: 3.358754]\n",
      "epoch:40 step:31549 [D loss: 0.493297, acc: 65.62%] [G loss: 3.472665]\n",
      "epoch:40 step:31550 [D loss: 0.016941, acc: 100.00%] [G loss: 5.007914]\n",
      "epoch:40 step:31551 [D loss: 0.186783, acc: 96.09%] [G loss: 4.091845]\n",
      "epoch:40 step:31552 [D loss: 0.577549, acc: 68.75%] [G loss: 3.191715]\n",
      "epoch:40 step:31553 [D loss: 1.276610, acc: 20.31%] [G loss: 3.655130]\n",
      "epoch:40 step:31554 [D loss: 0.086753, acc: 100.00%] [G loss: 4.699157]\n",
      "epoch:40 step:31555 [D loss: 0.623307, acc: 62.50%] [G loss: 9.005330]\n",
      "epoch:40 step:31556 [D loss: 0.799452, acc: 52.34%] [G loss: 6.785571]\n",
      "epoch:40 step:31557 [D loss: 1.063614, acc: 34.38%] [G loss: 7.903716]\n",
      "epoch:40 step:31558 [D loss: 0.176917, acc: 98.44%] [G loss: 2.041786]\n",
      "epoch:40 step:31559 [D loss: 0.373348, acc: 86.72%] [G loss: 6.096536]\n",
      "epoch:40 step:31560 [D loss: 0.090056, acc: 100.00%] [G loss: 3.560346]\n",
      "epoch:40 step:31561 [D loss: 0.380363, acc: 84.38%] [G loss: 5.695680]\n",
      "epoch:40 step:31562 [D loss: 0.642578, acc: 67.19%] [G loss: 4.559926]\n",
      "epoch:40 step:31563 [D loss: 0.045470, acc: 100.00%] [G loss: 3.842669]\n",
      "epoch:40 step:31564 [D loss: 1.149845, acc: 24.22%] [G loss: 6.430684]\n",
      "epoch:40 step:31565 [D loss: 0.509364, acc: 66.41%] [G loss: 2.051877]\n",
      "epoch:40 step:31566 [D loss: 0.351897, acc: 85.94%] [G loss: 1.944949]\n",
      "epoch:40 step:31567 [D loss: 0.258978, acc: 94.53%] [G loss: 1.844005]\n",
      "epoch:40 step:31568 [D loss: 0.321587, acc: 86.72%] [G loss: 5.353890]\n",
      "epoch:40 step:31569 [D loss: 0.494694, acc: 64.84%] [G loss: 7.142121]\n",
      "epoch:40 step:31570 [D loss: 1.105911, acc: 37.50%] [G loss: 6.013806]\n",
      "epoch:40 step:31571 [D loss: 1.028937, acc: 27.34%] [G loss: 5.896305]\n",
      "epoch:40 step:31572 [D loss: 0.271130, acc: 89.06%] [G loss: 6.318651]\n",
      "epoch:40 step:31573 [D loss: 0.285363, acc: 87.50%] [G loss: 5.928253]\n",
      "epoch:40 step:31574 [D loss: 0.184649, acc: 99.22%] [G loss: 2.698946]\n",
      "epoch:40 step:31575 [D loss: 0.082975, acc: 100.00%] [G loss: 4.473091]\n",
      "epoch:40 step:31576 [D loss: 0.221762, acc: 98.44%] [G loss: 7.233617]\n",
      "epoch:40 step:31577 [D loss: 0.293203, acc: 89.06%] [G loss: 3.527401]\n",
      "epoch:40 step:31578 [D loss: 0.243228, acc: 96.88%] [G loss: 5.778242]\n",
      "epoch:40 step:31579 [D loss: 0.030897, acc: 100.00%] [G loss: 3.899206]\n",
      "epoch:40 step:31580 [D loss: 0.463888, acc: 69.53%] [G loss: 8.260951]\n",
      "epoch:40 step:31581 [D loss: 0.230628, acc: 96.09%] [G loss: 3.538550]\n",
      "epoch:40 step:31582 [D loss: 0.520314, acc: 76.56%] [G loss: 5.711867]\n",
      "epoch:40 step:31583 [D loss: 0.101809, acc: 100.00%] [G loss: 6.118260]\n",
      "epoch:40 step:31584 [D loss: 0.403670, acc: 75.00%] [G loss: 4.299000]\n",
      "epoch:40 step:31585 [D loss: 0.850013, acc: 51.56%] [G loss: 6.456870]\n",
      "epoch:40 step:31586 [D loss: 0.176908, acc: 99.22%] [G loss: 3.314617]\n",
      "epoch:40 step:31587 [D loss: 0.048673, acc: 100.00%] [G loss: 4.056669]\n",
      "epoch:40 step:31588 [D loss: 0.668761, acc: 60.16%] [G loss: 6.713277]\n",
      "epoch:40 step:31589 [D loss: 0.285243, acc: 98.44%] [G loss: 3.975605]\n",
      "epoch:40 step:31590 [D loss: 0.272301, acc: 97.66%] [G loss: 3.581191]\n",
      "epoch:40 step:31591 [D loss: 1.029699, acc: 50.78%] [G loss: 3.206963]\n",
      "epoch:40 step:31592 [D loss: 0.203182, acc: 97.66%] [G loss: 5.439358]\n",
      "epoch:40 step:31593 [D loss: 0.332670, acc: 79.69%] [G loss: 7.780558]\n",
      "epoch:40 step:31594 [D loss: 0.826561, acc: 47.66%] [G loss: 6.425661]\n",
      "epoch:40 step:31595 [D loss: 0.378023, acc: 89.84%] [G loss: 5.675452]\n",
      "epoch:40 step:31596 [D loss: 0.671907, acc: 54.69%] [G loss: 6.698549]\n",
      "epoch:40 step:31597 [D loss: 0.218112, acc: 96.09%] [G loss: 7.084733]\n",
      "epoch:40 step:31598 [D loss: 0.288278, acc: 90.62%] [G loss: 4.699929]\n",
      "epoch:40 step:31599 [D loss: 0.041951, acc: 100.00%] [G loss: 6.131848]\n",
      "epoch:40 step:31600 [D loss: 0.088390, acc: 100.00%] [G loss: 6.125974]\n",
      "epoch:40 step:31601 [D loss: 0.066608, acc: 100.00%] [G loss: 4.619071]\n",
      "epoch:40 step:31602 [D loss: 0.115904, acc: 99.22%] [G loss: 7.569796]\n",
      "epoch:40 step:31603 [D loss: 0.440999, acc: 78.91%] [G loss: 3.063514]\n",
      "epoch:40 step:31604 [D loss: 0.143967, acc: 99.22%] [G loss: 6.097783]\n",
      "epoch:40 step:31605 [D loss: 0.139317, acc: 99.22%] [G loss: 8.569896]\n",
      "epoch:40 step:31606 [D loss: 0.267545, acc: 93.75%] [G loss: 6.482767]\n",
      "epoch:40 step:31607 [D loss: 0.172190, acc: 98.44%] [G loss: 5.754787]\n",
      "epoch:40 step:31608 [D loss: 0.719028, acc: 52.34%] [G loss: 4.978655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31609 [D loss: 0.270701, acc: 87.50%] [G loss: 7.328354]\n",
      "epoch:40 step:31610 [D loss: 0.387083, acc: 82.03%] [G loss: 6.281313]\n",
      "epoch:40 step:31611 [D loss: 0.412152, acc: 83.59%] [G loss: 5.923715]\n",
      "epoch:40 step:31612 [D loss: 0.049295, acc: 100.00%] [G loss: 3.701035]\n",
      "epoch:40 step:31613 [D loss: 0.573788, acc: 69.53%] [G loss: 2.043437]\n",
      "epoch:40 step:31614 [D loss: 0.007827, acc: 100.00%] [G loss: 2.870035]\n",
      "epoch:40 step:31615 [D loss: 0.320724, acc: 81.25%] [G loss: 4.740652]\n",
      "epoch:40 step:31616 [D loss: 0.158109, acc: 100.00%] [G loss: 4.607349]\n",
      "epoch:40 step:31617 [D loss: 0.298780, acc: 91.41%] [G loss: 5.479087]\n",
      "epoch:40 step:31618 [D loss: 0.206506, acc: 96.09%] [G loss: 5.871580]\n",
      "epoch:40 step:31619 [D loss: 0.107825, acc: 99.22%] [G loss: 4.273282]\n",
      "epoch:40 step:31620 [D loss: 0.217665, acc: 94.53%] [G loss: 5.451296]\n",
      "epoch:40 step:31621 [D loss: 0.441770, acc: 86.72%] [G loss: 6.864612]\n",
      "epoch:40 step:31622 [D loss: 0.404066, acc: 88.28%] [G loss: 5.427780]\n",
      "epoch:40 step:31623 [D loss: 0.243668, acc: 95.31%] [G loss: 3.396816]\n",
      "epoch:40 step:31624 [D loss: 0.313090, acc: 88.28%] [G loss: 5.178029]\n",
      "epoch:40 step:31625 [D loss: 0.447669, acc: 86.72%] [G loss: 3.123532]\n",
      "epoch:40 step:31626 [D loss: 0.189732, acc: 97.66%] [G loss: 4.369815]\n",
      "epoch:40 step:31627 [D loss: 0.061738, acc: 100.00%] [G loss: 6.813248]\n",
      "epoch:40 step:31628 [D loss: 1.311672, acc: 49.22%] [G loss: 9.855606]\n",
      "epoch:40 step:31629 [D loss: 0.496459, acc: 80.47%] [G loss: 3.215993]\n",
      "epoch:40 step:31630 [D loss: 0.065353, acc: 100.00%] [G loss: 3.919818]\n",
      "epoch:40 step:31631 [D loss: 0.437964, acc: 85.16%] [G loss: 8.047256]\n",
      "epoch:40 step:31632 [D loss: 0.081420, acc: 100.00%] [G loss: 3.614119]\n",
      "epoch:40 step:31633 [D loss: 0.249391, acc: 92.97%] [G loss: 4.420775]\n",
      "epoch:40 step:31634 [D loss: 0.124842, acc: 96.88%] [G loss: 6.973705]\n",
      "epoch:40 step:31635 [D loss: 0.968781, acc: 53.12%] [G loss: 5.110075]\n",
      "epoch:40 step:31636 [D loss: 0.468835, acc: 83.59%] [G loss: 5.409676]\n",
      "epoch:40 step:31637 [D loss: 0.700229, acc: 60.94%] [G loss: 3.708250]\n",
      "epoch:40 step:31638 [D loss: 1.317918, acc: 23.44%] [G loss: 4.445390]\n",
      "epoch:40 step:31639 [D loss: 0.588476, acc: 72.66%] [G loss: 5.836490]\n",
      "epoch:40 step:31640 [D loss: 0.145433, acc: 100.00%] [G loss: 3.598163]\n",
      "epoch:40 step:31641 [D loss: 0.169709, acc: 98.44%] [G loss: 3.255765]\n",
      "epoch:40 step:31642 [D loss: 0.278418, acc: 92.97%] [G loss: 7.342309]\n",
      "epoch:40 step:31643 [D loss: 0.094270, acc: 100.00%] [G loss: 4.798058]\n",
      "epoch:40 step:31644 [D loss: 1.726156, acc: 9.38%] [G loss: 6.723104]\n",
      "epoch:40 step:31645 [D loss: 0.552270, acc: 64.06%] [G loss: 1.822178]\n",
      "epoch:40 step:31646 [D loss: 0.232831, acc: 96.88%] [G loss: 3.235355]\n",
      "epoch:40 step:31647 [D loss: 0.252040, acc: 96.88%] [G loss: 7.390103]\n",
      "epoch:40 step:31648 [D loss: 0.210544, acc: 96.88%] [G loss: 5.038935]\n",
      "epoch:40 step:31649 [D loss: 0.162130, acc: 100.00%] [G loss: 5.036572]\n",
      "epoch:40 step:31650 [D loss: 0.253239, acc: 89.06%] [G loss: 5.231781]\n",
      "epoch:40 step:31651 [D loss: 0.247937, acc: 96.88%] [G loss: 6.421281]\n",
      "epoch:40 step:31652 [D loss: 0.366242, acc: 91.41%] [G loss: 4.237122]\n",
      "epoch:40 step:31653 [D loss: 0.065249, acc: 100.00%] [G loss: 5.116276]\n",
      "epoch:40 step:31654 [D loss: 0.193922, acc: 93.75%] [G loss: 6.294302]\n",
      "epoch:40 step:31655 [D loss: 0.346914, acc: 85.94%] [G loss: 4.494266]\n",
      "epoch:40 step:31656 [D loss: 0.526208, acc: 75.78%] [G loss: 8.416759]\n",
      "epoch:40 step:31657 [D loss: 0.237808, acc: 93.75%] [G loss: 4.723056]\n",
      "epoch:40 step:31658 [D loss: 0.279306, acc: 89.06%] [G loss: 2.229188]\n",
      "epoch:40 step:31659 [D loss: 0.026028, acc: 100.00%] [G loss: 8.950089]\n",
      "epoch:40 step:31660 [D loss: 0.298582, acc: 88.28%] [G loss: 5.148931]\n",
      "epoch:40 step:31661 [D loss: 0.996012, acc: 42.97%] [G loss: 6.267098]\n",
      "epoch:40 step:31662 [D loss: 0.847548, acc: 43.75%] [G loss: 5.528484]\n",
      "epoch:40 step:31663 [D loss: 0.341290, acc: 79.69%] [G loss: 5.322146]\n",
      "epoch:40 step:31664 [D loss: 0.038755, acc: 100.00%] [G loss: 4.295332]\n",
      "epoch:40 step:31665 [D loss: 0.389750, acc: 73.44%] [G loss: 6.709946]\n",
      "epoch:40 step:31666 [D loss: 0.095938, acc: 99.22%] [G loss: 5.032060]\n",
      "epoch:40 step:31667 [D loss: 0.088263, acc: 100.00%] [G loss: 4.315389]\n",
      "epoch:40 step:31668 [D loss: 0.091016, acc: 99.22%] [G loss: 4.861567]\n",
      "epoch:40 step:31669 [D loss: 0.100890, acc: 100.00%] [G loss: 6.196839]\n",
      "epoch:40 step:31670 [D loss: 0.146880, acc: 97.66%] [G loss: 5.172650]\n",
      "epoch:40 step:31671 [D loss: 0.424816, acc: 78.91%] [G loss: 2.705077]\n",
      "epoch:40 step:31672 [D loss: 0.442667, acc: 69.53%] [G loss: 6.598240]\n",
      "epoch:40 step:31673 [D loss: 0.146475, acc: 99.22%] [G loss: 4.140170]\n",
      "epoch:40 step:31674 [D loss: 0.181248, acc: 96.09%] [G loss: 5.270617]\n",
      "epoch:40 step:31675 [D loss: 0.106098, acc: 99.22%] [G loss: 4.269826]\n",
      "epoch:40 step:31676 [D loss: 0.132927, acc: 100.00%] [G loss: 6.708781]\n",
      "epoch:40 step:31677 [D loss: 0.376453, acc: 78.91%] [G loss: 4.572915]\n",
      "epoch:40 step:31678 [D loss: 0.241985, acc: 89.84%] [G loss: 11.076628]\n",
      "epoch:40 step:31679 [D loss: 0.211565, acc: 94.53%] [G loss: 4.757174]\n",
      "epoch:40 step:31680 [D loss: 1.243859, acc: 50.00%] [G loss: 5.554595]\n",
      "epoch:40 step:31681 [D loss: 0.209369, acc: 97.66%] [G loss: 4.695057]\n",
      "epoch:40 step:31682 [D loss: 0.087896, acc: 100.00%] [G loss: 5.755609]\n",
      "epoch:40 step:31683 [D loss: 0.439176, acc: 71.09%] [G loss: 3.848545]\n",
      "epoch:40 step:31684 [D loss: 0.025822, acc: 100.00%] [G loss: 4.776333]\n",
      "epoch:40 step:31685 [D loss: 0.212467, acc: 96.09%] [G loss: 6.012928]\n",
      "epoch:40 step:31686 [D loss: 0.350363, acc: 79.69%] [G loss: 8.411251]\n",
      "epoch:40 step:31687 [D loss: 0.191539, acc: 97.66%] [G loss: 4.776737]\n",
      "epoch:40 step:31688 [D loss: 0.189035, acc: 96.09%] [G loss: 6.010902]\n",
      "epoch:40 step:31689 [D loss: 0.048988, acc: 100.00%] [G loss: 4.094316]\n",
      "epoch:40 step:31690 [D loss: 0.298116, acc: 92.19%] [G loss: 4.335157]\n",
      "epoch:40 step:31691 [D loss: 0.396693, acc: 88.28%] [G loss: 1.981132]\n",
      "epoch:40 step:31692 [D loss: 0.278410, acc: 85.94%] [G loss: 4.285469]\n",
      "epoch:40 step:31693 [D loss: 0.186903, acc: 97.66%] [G loss: 4.500192]\n",
      "epoch:40 step:31694 [D loss: 0.292211, acc: 89.84%] [G loss: 6.127700]\n",
      "epoch:40 step:31695 [D loss: 0.802625, acc: 54.69%] [G loss: 3.856720]\n",
      "epoch:40 step:31696 [D loss: 0.006864, acc: 100.00%] [G loss: 5.509240]\n",
      "epoch:40 step:31697 [D loss: 0.086728, acc: 99.22%] [G loss: 4.788901]\n",
      "epoch:40 step:31698 [D loss: 0.218889, acc: 97.66%] [G loss: 4.875620]\n",
      "epoch:40 step:31699 [D loss: 0.098973, acc: 100.00%] [G loss: 6.084002]\n",
      "epoch:40 step:31700 [D loss: 0.598605, acc: 67.97%] [G loss: 6.477337]\n",
      "epoch:40 step:31701 [D loss: 0.043570, acc: 100.00%] [G loss: 6.710728]\n",
      "epoch:40 step:31702 [D loss: 0.158792, acc: 97.66%] [G loss: 1.626245]\n",
      "epoch:40 step:31703 [D loss: 0.171069, acc: 100.00%] [G loss: 6.983517]\n",
      "epoch:40 step:31704 [D loss: 0.291691, acc: 92.19%] [G loss: 3.955175]\n",
      "epoch:40 step:31705 [D loss: 0.867819, acc: 50.00%] [G loss: 3.991210]\n",
      "epoch:40 step:31706 [D loss: 0.061379, acc: 100.00%] [G loss: 6.700440]\n",
      "epoch:40 step:31707 [D loss: 0.201068, acc: 95.31%] [G loss: 5.015539]\n",
      "epoch:40 step:31708 [D loss: 0.213925, acc: 98.44%] [G loss: 1.594640]\n",
      "epoch:40 step:31709 [D loss: 0.178142, acc: 99.22%] [G loss: 6.370566]\n",
      "epoch:40 step:31710 [D loss: 0.203778, acc: 95.31%] [G loss: 3.614447]\n",
      "epoch:40 step:31711 [D loss: 0.927485, acc: 51.56%] [G loss: 6.962425]\n",
      "epoch:40 step:31712 [D loss: 1.704049, acc: 50.00%] [G loss: 6.434678]\n",
      "epoch:40 step:31713 [D loss: 0.062699, acc: 100.00%] [G loss: 6.457340]\n",
      "epoch:40 step:31714 [D loss: 0.878442, acc: 39.06%] [G loss: 5.924848]\n",
      "epoch:40 step:31715 [D loss: 0.635396, acc: 65.62%] [G loss: 4.982684]\n",
      "epoch:40 step:31716 [D loss: 0.660793, acc: 60.94%] [G loss: 6.113202]\n",
      "epoch:40 step:31717 [D loss: 0.165585, acc: 97.66%] [G loss: 5.239047]\n",
      "epoch:40 step:31718 [D loss: 0.027316, acc: 100.00%] [G loss: 3.982909]\n",
      "epoch:40 step:31719 [D loss: 0.380298, acc: 87.50%] [G loss: 4.490571]\n",
      "epoch:40 step:31720 [D loss: 0.107341, acc: 100.00%] [G loss: 4.345262]\n",
      "epoch:40 step:31721 [D loss: 0.533183, acc: 74.22%] [G loss: 2.635152]\n",
      "epoch:40 step:31722 [D loss: 0.241554, acc: 92.19%] [G loss: 4.708996]\n",
      "epoch:40 step:31723 [D loss: 0.221135, acc: 93.75%] [G loss: 5.798147]\n",
      "epoch:40 step:31724 [D loss: 0.294566, acc: 94.53%] [G loss: 5.116379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31725 [D loss: 0.232937, acc: 94.53%] [G loss: 5.855894]\n",
      "epoch:40 step:31726 [D loss: 0.309215, acc: 94.53%] [G loss: 5.565417]\n",
      "epoch:40 step:31727 [D loss: 0.667931, acc: 57.81%] [G loss: 3.761441]\n",
      "epoch:40 step:31728 [D loss: 0.140273, acc: 99.22%] [G loss: 5.353273]\n",
      "epoch:40 step:31729 [D loss: 0.092539, acc: 100.00%] [G loss: 4.992585]\n",
      "epoch:40 step:31730 [D loss: 0.066887, acc: 100.00%] [G loss: 6.685690]\n",
      "epoch:40 step:31731 [D loss: 0.324559, acc: 89.06%] [G loss: 7.279852]\n",
      "epoch:40 step:31732 [D loss: 0.956010, acc: 39.06%] [G loss: 7.382155]\n",
      "epoch:40 step:31733 [D loss: 0.333684, acc: 82.03%] [G loss: 7.034235]\n",
      "epoch:40 step:31734 [D loss: 0.743114, acc: 50.78%] [G loss: 5.029400]\n",
      "epoch:40 step:31735 [D loss: 0.953962, acc: 27.34%] [G loss: 9.137305]\n",
      "epoch:40 step:31736 [D loss: 0.251332, acc: 97.66%] [G loss: 5.218535]\n",
      "epoch:40 step:31737 [D loss: 0.056023, acc: 100.00%] [G loss: 6.267901]\n",
      "epoch:40 step:31738 [D loss: 0.051730, acc: 100.00%] [G loss: 5.511053]\n",
      "epoch:40 step:31739 [D loss: 0.713083, acc: 56.25%] [G loss: 5.409825]\n",
      "epoch:40 step:31740 [D loss: 0.085276, acc: 99.22%] [G loss: 3.698370]\n",
      "epoch:40 step:31741 [D loss: 0.237992, acc: 94.53%] [G loss: 4.319777]\n",
      "epoch:40 step:31742 [D loss: 0.357755, acc: 90.62%] [G loss: 5.017606]\n",
      "epoch:40 step:31743 [D loss: 0.429717, acc: 69.53%] [G loss: 5.487403]\n",
      "epoch:40 step:31744 [D loss: 0.221046, acc: 97.66%] [G loss: 3.403304]\n",
      "epoch:40 step:31745 [D loss: 0.378614, acc: 79.69%] [G loss: 3.897788]\n",
      "epoch:40 step:31746 [D loss: 0.382951, acc: 91.41%] [G loss: 5.606819]\n",
      "epoch:40 step:31747 [D loss: 0.356931, acc: 84.38%] [G loss: 6.639777]\n",
      "epoch:40 step:31748 [D loss: 0.237526, acc: 97.66%] [G loss: 6.587321]\n",
      "epoch:40 step:31749 [D loss: 0.148597, acc: 98.44%] [G loss: 9.921589]\n",
      "epoch:40 step:31750 [D loss: 0.145280, acc: 99.22%] [G loss: 4.333478]\n",
      "epoch:40 step:31751 [D loss: 0.093484, acc: 99.22%] [G loss: 5.274497]\n",
      "epoch:40 step:31752 [D loss: 0.172295, acc: 99.22%] [G loss: 6.661973]\n",
      "epoch:40 step:31753 [D loss: 0.068079, acc: 100.00%] [G loss: 5.975646]\n",
      "epoch:40 step:31754 [D loss: 0.299830, acc: 91.41%] [G loss: 5.569231]\n",
      "epoch:40 step:31755 [D loss: 0.249050, acc: 96.09%] [G loss: 7.640705]\n",
      "epoch:40 step:31756 [D loss: 0.253865, acc: 96.09%] [G loss: 4.462160]\n",
      "epoch:40 step:31757 [D loss: 0.058629, acc: 100.00%] [G loss: 6.407805]\n",
      "epoch:40 step:31758 [D loss: 0.366117, acc: 81.25%] [G loss: 6.817495]\n",
      "epoch:40 step:31759 [D loss: 0.101899, acc: 100.00%] [G loss: 4.385420]\n",
      "epoch:40 step:31760 [D loss: 0.838652, acc: 41.41%] [G loss: 7.127595]\n",
      "epoch:40 step:31761 [D loss: 0.086039, acc: 100.00%] [G loss: 2.123842]\n",
      "epoch:40 step:31762 [D loss: 0.147365, acc: 98.44%] [G loss: 7.028184]\n",
      "epoch:40 step:31763 [D loss: 0.142672, acc: 98.44%] [G loss: 8.792189]\n",
      "epoch:40 step:31764 [D loss: 0.206769, acc: 97.66%] [G loss: 6.660946]\n",
      "epoch:40 step:31765 [D loss: 0.191022, acc: 98.44%] [G loss: 6.443544]\n",
      "epoch:40 step:31766 [D loss: 0.137391, acc: 99.22%] [G loss: 5.218134]\n",
      "epoch:40 step:31767 [D loss: 0.272502, acc: 86.72%] [G loss: 5.805422]\n",
      "epoch:40 step:31768 [D loss: 0.143955, acc: 99.22%] [G loss: 6.585110]\n",
      "epoch:40 step:31769 [D loss: 0.046604, acc: 100.00%] [G loss: 5.435760]\n",
      "epoch:40 step:31770 [D loss: 0.048345, acc: 100.00%] [G loss: 8.965021]\n",
      "epoch:40 step:31771 [D loss: 0.096956, acc: 100.00%] [G loss: 5.669518]\n",
      "epoch:40 step:31772 [D loss: 0.543029, acc: 69.53%] [G loss: 3.457902]\n",
      "epoch:40 step:31773 [D loss: 0.290307, acc: 88.28%] [G loss: 4.409109]\n",
      "epoch:40 step:31774 [D loss: 0.192153, acc: 98.44%] [G loss: 6.725172]\n",
      "epoch:40 step:31775 [D loss: 0.266568, acc: 88.28%] [G loss: 6.322515]\n",
      "epoch:40 step:31776 [D loss: 0.581551, acc: 61.72%] [G loss: 8.045731]\n",
      "epoch:40 step:31777 [D loss: 0.071497, acc: 100.00%] [G loss: 6.248154]\n",
      "epoch:40 step:31778 [D loss: 0.189569, acc: 95.31%] [G loss: 7.856598]\n",
      "epoch:40 step:31779 [D loss: 0.072384, acc: 100.00%] [G loss: 6.958282]\n",
      "epoch:40 step:31780 [D loss: 0.682750, acc: 56.25%] [G loss: 3.148349]\n",
      "epoch:40 step:31781 [D loss: 0.091700, acc: 99.22%] [G loss: 5.186701]\n",
      "epoch:40 step:31782 [D loss: 0.038934, acc: 100.00%] [G loss: 6.844042]\n",
      "epoch:40 step:31783 [D loss: 0.242939, acc: 92.19%] [G loss: 7.750075]\n",
      "epoch:40 step:31784 [D loss: 0.176230, acc: 97.66%] [G loss: 7.585974]\n",
      "epoch:40 step:31785 [D loss: 0.439285, acc: 78.12%] [G loss: 8.917780]\n",
      "epoch:40 step:31786 [D loss: 0.954532, acc: 48.44%] [G loss: 7.121352]\n",
      "epoch:40 step:31787 [D loss: 0.108838, acc: 99.22%] [G loss: 4.094564]\n",
      "epoch:40 step:31788 [D loss: 1.103976, acc: 50.00%] [G loss: 8.478341]\n",
      "epoch:40 step:31789 [D loss: 0.076119, acc: 99.22%] [G loss: 8.184912]\n",
      "epoch:40 step:31790 [D loss: 0.177807, acc: 97.66%] [G loss: 5.573711]\n",
      "epoch:40 step:31791 [D loss: 0.870605, acc: 52.34%] [G loss: 6.888227]\n",
      "epoch:40 step:31792 [D loss: 0.113933, acc: 100.00%] [G loss: 4.651468]\n",
      "epoch:40 step:31793 [D loss: 1.685003, acc: 50.78%] [G loss: 6.419489]\n",
      "epoch:40 step:31794 [D loss: 0.330660, acc: 89.84%] [G loss: 3.265749]\n",
      "epoch:40 step:31795 [D loss: 0.261408, acc: 89.06%] [G loss: 10.356110]\n",
      "epoch:40 step:31796 [D loss: 0.144242, acc: 99.22%] [G loss: 6.068213]\n",
      "epoch:40 step:31797 [D loss: 0.115904, acc: 99.22%] [G loss: 5.116368]\n",
      "epoch:40 step:31798 [D loss: 0.899969, acc: 50.78%] [G loss: 5.312651]\n",
      "epoch:40 step:31799 [D loss: 0.071868, acc: 100.00%] [G loss: 7.539954]\n",
      "epoch:40 step:31800 [D loss: 1.216336, acc: 51.56%] [G loss: 3.843005]\n",
      "epoch:40 step:31801 [D loss: 0.079372, acc: 100.00%] [G loss: 5.572515]\n",
      "epoch:40 step:31802 [D loss: 0.603348, acc: 65.62%] [G loss: 4.960579]\n",
      "epoch:40 step:31803 [D loss: 0.100488, acc: 100.00%] [G loss: 6.214437]\n",
      "epoch:40 step:31804 [D loss: 0.171021, acc: 98.44%] [G loss: 6.699049]\n",
      "epoch:40 step:31805 [D loss: 0.083076, acc: 100.00%] [G loss: 5.646959]\n",
      "epoch:40 step:31806 [D loss: 0.665892, acc: 64.06%] [G loss: 5.408771]\n",
      "epoch:40 step:31807 [D loss: 0.075509, acc: 100.00%] [G loss: 4.125400]\n",
      "epoch:40 step:31808 [D loss: 0.185073, acc: 98.44%] [G loss: 4.467939]\n",
      "epoch:40 step:31809 [D loss: 0.416843, acc: 76.56%] [G loss: 7.104356]\n",
      "epoch:40 step:31810 [D loss: 0.777533, acc: 53.12%] [G loss: 4.422772]\n",
      "epoch:40 step:31811 [D loss: 0.293324, acc: 93.75%] [G loss: 6.003491]\n",
      "epoch:40 step:31812 [D loss: 0.167596, acc: 98.44%] [G loss: 4.809376]\n",
      "epoch:40 step:31813 [D loss: 0.486686, acc: 82.81%] [G loss: 5.847425]\n",
      "epoch:40 step:31814 [D loss: 0.132136, acc: 100.00%] [G loss: 2.597114]\n",
      "epoch:40 step:31815 [D loss: 0.359485, acc: 85.16%] [G loss: 3.693682]\n",
      "epoch:40 step:31816 [D loss: 0.128836, acc: 100.00%] [G loss: 6.334127]\n",
      "epoch:40 step:31817 [D loss: 0.088421, acc: 100.00%] [G loss: 5.813093]\n",
      "epoch:40 step:31818 [D loss: 0.085955, acc: 99.22%] [G loss: 9.401748]\n",
      "epoch:40 step:31819 [D loss: 0.637659, acc: 63.28%] [G loss: 7.214084]\n",
      "epoch:40 step:31820 [D loss: 0.215198, acc: 99.22%] [G loss: 7.038441]\n",
      "epoch:40 step:31821 [D loss: 0.024353, acc: 100.00%] [G loss: 8.284345]\n",
      "epoch:40 step:31822 [D loss: 0.640804, acc: 57.81%] [G loss: 7.329741]\n",
      "epoch:40 step:31823 [D loss: 0.172009, acc: 98.44%] [G loss: 8.021143]\n",
      "epoch:40 step:31824 [D loss: 0.281481, acc: 89.06%] [G loss: 3.838981]\n",
      "epoch:40 step:31825 [D loss: 0.750944, acc: 53.12%] [G loss: 5.339464]\n",
      "epoch:40 step:31826 [D loss: 0.379873, acc: 74.22%] [G loss: 8.652287]\n",
      "epoch:40 step:31827 [D loss: 0.282904, acc: 89.84%] [G loss: 6.870091]\n",
      "epoch:40 step:31828 [D loss: 0.841971, acc: 48.44%] [G loss: 4.679047]\n",
      "epoch:40 step:31829 [D loss: 0.483835, acc: 68.75%] [G loss: 3.630599]\n",
      "epoch:40 step:31830 [D loss: 0.228520, acc: 96.88%] [G loss: 5.602182]\n",
      "epoch:40 step:31831 [D loss: 0.241811, acc: 97.66%] [G loss: 7.528788]\n",
      "epoch:40 step:31832 [D loss: 0.323098, acc: 95.31%] [G loss: 5.512578]\n",
      "epoch:40 step:31833 [D loss: 0.038361, acc: 100.00%] [G loss: 8.762809]\n",
      "epoch:40 step:31834 [D loss: 0.816366, acc: 44.53%] [G loss: 4.595506]\n",
      "epoch:40 step:31835 [D loss: 0.706437, acc: 59.38%] [G loss: 5.252795]\n",
      "epoch:40 step:31836 [D loss: 0.185156, acc: 98.44%] [G loss: 6.570259]\n",
      "epoch:40 step:31837 [D loss: 0.122269, acc: 100.00%] [G loss: 3.918067]\n",
      "epoch:40 step:31838 [D loss: 0.222093, acc: 93.75%] [G loss: 4.718834]\n",
      "epoch:40 step:31839 [D loss: 1.281519, acc: 17.19%] [G loss: 6.235917]\n",
      "epoch:40 step:31840 [D loss: 0.545896, acc: 75.78%] [G loss: 7.319543]\n",
      "epoch:40 step:31841 [D loss: 0.891046, acc: 40.62%] [G loss: 5.167375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31842 [D loss: 0.515186, acc: 69.53%] [G loss: 5.075637]\n",
      "epoch:40 step:31843 [D loss: 0.138707, acc: 96.88%] [G loss: 6.477885]\n",
      "epoch:40 step:31844 [D loss: 1.262757, acc: 50.00%] [G loss: 4.150096]\n",
      "epoch:40 step:31845 [D loss: 0.023559, acc: 100.00%] [G loss: 6.257603]\n",
      "epoch:40 step:31846 [D loss: 0.422405, acc: 76.56%] [G loss: 4.312440]\n",
      "epoch:40 step:31847 [D loss: 0.056444, acc: 99.22%] [G loss: 5.170479]\n",
      "epoch:40 step:31848 [D loss: 0.389791, acc: 82.81%] [G loss: 5.080615]\n",
      "epoch:40 step:31849 [D loss: 0.117228, acc: 99.22%] [G loss: 5.324503]\n",
      "epoch:40 step:31850 [D loss: 0.480000, acc: 72.66%] [G loss: 4.944686]\n",
      "epoch:40 step:31851 [D loss: 0.560023, acc: 70.31%] [G loss: 4.983613]\n",
      "epoch:40 step:31852 [D loss: 0.251583, acc: 92.97%] [G loss: 7.280417]\n",
      "epoch:40 step:31853 [D loss: 0.202172, acc: 97.66%] [G loss: 7.287538]\n",
      "epoch:40 step:31854 [D loss: 0.428686, acc: 71.09%] [G loss: 7.109560]\n",
      "epoch:40 step:31855 [D loss: 0.193714, acc: 98.44%] [G loss: 2.998236]\n",
      "epoch:40 step:31856 [D loss: 1.273958, acc: 39.06%] [G loss: 7.715412]\n",
      "epoch:40 step:31857 [D loss: 0.866935, acc: 52.34%] [G loss: 7.313666]\n",
      "epoch:40 step:31858 [D loss: 0.922679, acc: 38.28%] [G loss: 5.063178]\n",
      "epoch:40 step:31859 [D loss: 0.662111, acc: 59.38%] [G loss: 4.319730]\n",
      "epoch:40 step:31860 [D loss: 0.141442, acc: 99.22%] [G loss: 4.217422]\n",
      "epoch:40 step:31861 [D loss: 0.331491, acc: 82.03%] [G loss: 3.197453]\n",
      "epoch:40 step:31862 [D loss: 0.137804, acc: 99.22%] [G loss: 3.055022]\n",
      "epoch:40 step:31863 [D loss: 0.064461, acc: 100.00%] [G loss: 6.393951]\n",
      "epoch:40 step:31864 [D loss: 0.017242, acc: 100.00%] [G loss: 5.509627]\n",
      "epoch:40 step:31865 [D loss: 0.144298, acc: 98.44%] [G loss: 4.566965]\n",
      "epoch:40 step:31866 [D loss: 0.412099, acc: 75.78%] [G loss: 4.734569]\n",
      "epoch:40 step:31867 [D loss: 0.058111, acc: 100.00%] [G loss: 6.080961]\n",
      "epoch:40 step:31868 [D loss: 0.169130, acc: 96.88%] [G loss: 4.308546]\n",
      "epoch:40 step:31869 [D loss: 0.115581, acc: 100.00%] [G loss: 5.879076]\n",
      "epoch:40 step:31870 [D loss: 0.379496, acc: 83.59%] [G loss: 5.351222]\n",
      "epoch:40 step:31871 [D loss: 1.015576, acc: 43.75%] [G loss: 4.307190]\n",
      "epoch:40 step:31872 [D loss: 0.256692, acc: 94.53%] [G loss: 5.222103]\n",
      "epoch:40 step:31873 [D loss: 0.129540, acc: 99.22%] [G loss: 4.382832]\n",
      "epoch:40 step:31874 [D loss: 0.487245, acc: 80.47%] [G loss: 5.368842]\n",
      "epoch:40 step:31875 [D loss: 0.703017, acc: 59.38%] [G loss: 4.110733]\n",
      "epoch:40 step:31876 [D loss: 0.052712, acc: 100.00%] [G loss: 3.029728]\n",
      "epoch:40 step:31877 [D loss: 0.783037, acc: 53.91%] [G loss: 8.051254]\n",
      "epoch:40 step:31878 [D loss: 0.098434, acc: 100.00%] [G loss: 4.636369]\n",
      "epoch:40 step:31879 [D loss: 0.493963, acc: 78.12%] [G loss: 4.300358]\n",
      "epoch:40 step:31880 [D loss: 0.246558, acc: 93.75%] [G loss: 4.955115]\n",
      "epoch:40 step:31881 [D loss: 0.167044, acc: 99.22%] [G loss: 3.855046]\n",
      "epoch:40 step:31882 [D loss: 0.051315, acc: 100.00%] [G loss: 6.331342]\n",
      "epoch:40 step:31883 [D loss: 0.174256, acc: 97.66%] [G loss: 4.154147]\n",
      "epoch:40 step:31884 [D loss: 0.071758, acc: 100.00%] [G loss: 6.158104]\n",
      "epoch:40 step:31885 [D loss: 0.304311, acc: 91.41%] [G loss: 6.833622]\n",
      "epoch:40 step:31886 [D loss: 0.384099, acc: 77.34%] [G loss: 3.991267]\n",
      "epoch:40 step:31887 [D loss: 0.053739, acc: 100.00%] [G loss: 6.366656]\n",
      "epoch:40 step:31888 [D loss: 0.321497, acc: 94.53%] [G loss: 4.148208]\n",
      "epoch:40 step:31889 [D loss: 0.093159, acc: 100.00%] [G loss: 5.738824]\n",
      "epoch:40 step:31890 [D loss: 0.167426, acc: 99.22%] [G loss: 4.876379]\n",
      "epoch:40 step:31891 [D loss: 0.523031, acc: 64.84%] [G loss: 6.964224]\n",
      "epoch:40 step:31892 [D loss: 0.552865, acc: 61.72%] [G loss: 6.182989]\n",
      "epoch:40 step:31893 [D loss: 0.118049, acc: 100.00%] [G loss: 7.793076]\n",
      "epoch:40 step:31894 [D loss: 0.069401, acc: 100.00%] [G loss: 4.480037]\n",
      "epoch:40 step:31895 [D loss: 0.019730, acc: 100.00%] [G loss: 5.572684]\n",
      "epoch:40 step:31896 [D loss: 0.308243, acc: 94.53%] [G loss: 2.685910]\n",
      "epoch:40 step:31897 [D loss: 0.396523, acc: 81.25%] [G loss: 3.866123]\n",
      "epoch:40 step:31898 [D loss: 0.303370, acc: 86.72%] [G loss: 5.558740]\n",
      "epoch:40 step:31899 [D loss: 0.512463, acc: 63.28%] [G loss: 5.742633]\n",
      "epoch:40 step:31900 [D loss: 0.758041, acc: 53.12%] [G loss: 5.326427]\n",
      "epoch:40 step:31901 [D loss: 0.564698, acc: 71.88%] [G loss: 4.409845]\n",
      "epoch:40 step:31902 [D loss: 0.324939, acc: 89.84%] [G loss: 4.306744]\n",
      "epoch:40 step:31903 [D loss: 0.554226, acc: 61.72%] [G loss: 4.076199]\n",
      "epoch:40 step:31904 [D loss: 0.496781, acc: 62.50%] [G loss: 5.632500]\n",
      "epoch:40 step:31905 [D loss: 0.161658, acc: 98.44%] [G loss: 3.070505]\n",
      "epoch:40 step:31906 [D loss: 0.297729, acc: 89.06%] [G loss: 4.155189]\n",
      "epoch:40 step:31907 [D loss: 0.199518, acc: 97.66%] [G loss: 5.680189]\n",
      "epoch:40 step:31908 [D loss: 0.443817, acc: 69.53%] [G loss: 6.933709]\n",
      "epoch:40 step:31909 [D loss: 0.137643, acc: 99.22%] [G loss: 5.053431]\n",
      "epoch:40 step:31910 [D loss: 0.415316, acc: 75.78%] [G loss: 4.784710]\n",
      "epoch:40 step:31911 [D loss: 0.198896, acc: 98.44%] [G loss: 4.934732]\n",
      "epoch:40 step:31912 [D loss: 0.949488, acc: 51.56%] [G loss: 3.947375]\n",
      "epoch:40 step:31913 [D loss: 0.389435, acc: 80.47%] [G loss: 7.759051]\n",
      "epoch:40 step:31914 [D loss: 0.524963, acc: 73.44%] [G loss: 6.682743]\n",
      "epoch:40 step:31915 [D loss: 0.941254, acc: 39.84%] [G loss: 6.209433]\n",
      "epoch:40 step:31916 [D loss: 0.013886, acc: 100.00%] [G loss: 7.745806]\n",
      "epoch:40 step:31917 [D loss: 0.542765, acc: 60.94%] [G loss: 7.085304]\n",
      "epoch:40 step:31918 [D loss: 0.226500, acc: 95.31%] [G loss: 3.678844]\n",
      "epoch:40 step:31919 [D loss: 0.254644, acc: 94.53%] [G loss: 8.504539]\n",
      "epoch:40 step:31920 [D loss: 0.147982, acc: 100.00%] [G loss: 5.234962]\n",
      "epoch:40 step:31921 [D loss: 0.128511, acc: 100.00%] [G loss: 5.047818]\n",
      "epoch:40 step:31922 [D loss: 0.151396, acc: 98.44%] [G loss: 4.400322]\n",
      "epoch:40 step:31923 [D loss: 0.302031, acc: 85.16%] [G loss: 5.978751]\n",
      "epoch:40 step:31924 [D loss: 0.938093, acc: 50.00%] [G loss: 6.151272]\n",
      "epoch:40 step:31925 [D loss: 0.760509, acc: 53.12%] [G loss: 6.837279]\n",
      "epoch:40 step:31926 [D loss: 0.164379, acc: 96.09%] [G loss: 6.986682]\n",
      "epoch:40 step:31927 [D loss: 1.145308, acc: 34.38%] [G loss: 5.607708]\n",
      "epoch:40 step:31928 [D loss: 0.375386, acc: 89.84%] [G loss: 3.139990]\n",
      "epoch:40 step:31929 [D loss: 0.040883, acc: 100.00%] [G loss: 7.647550]\n",
      "epoch:40 step:31930 [D loss: 0.648444, acc: 58.59%] [G loss: 5.917780]\n",
      "epoch:40 step:31931 [D loss: 0.291176, acc: 91.41%] [G loss: 9.554592]\n",
      "epoch:40 step:31932 [D loss: 0.425836, acc: 70.31%] [G loss: 10.456461]\n",
      "epoch:40 step:31933 [D loss: 0.198203, acc: 95.31%] [G loss: 7.100338]\n",
      "epoch:40 step:31934 [D loss: 0.280843, acc: 93.75%] [G loss: 6.451569]\n",
      "epoch:40 step:31935 [D loss: 0.191468, acc: 93.75%] [G loss: 5.572178]\n",
      "epoch:40 step:31936 [D loss: 0.142657, acc: 96.88%] [G loss: 4.017350]\n",
      "epoch:40 step:31937 [D loss: 0.336606, acc: 81.25%] [G loss: 5.545734]\n",
      "epoch:40 step:31938 [D loss: 0.105086, acc: 98.44%] [G loss: 5.870936]\n",
      "epoch:40 step:31939 [D loss: 0.104533, acc: 100.00%] [G loss: 7.625820]\n",
      "epoch:40 step:31940 [D loss: 0.673157, acc: 56.25%] [G loss: 4.205563]\n",
      "epoch:40 step:31941 [D loss: 0.539132, acc: 67.19%] [G loss: 5.004053]\n",
      "epoch:40 step:31942 [D loss: 0.531105, acc: 60.16%] [G loss: 6.377302]\n",
      "epoch:40 step:31943 [D loss: 0.130508, acc: 99.22%] [G loss: 4.858922]\n",
      "epoch:40 step:31944 [D loss: 1.023251, acc: 35.16%] [G loss: 4.904831]\n",
      "epoch:40 step:31945 [D loss: 0.123739, acc: 99.22%] [G loss: 4.207628]\n",
      "epoch:40 step:31946 [D loss: 0.066576, acc: 100.00%] [G loss: 6.600154]\n",
      "epoch:40 step:31947 [D loss: 0.956749, acc: 50.00%] [G loss: 7.054731]\n",
      "epoch:40 step:31948 [D loss: 0.013463, acc: 100.00%] [G loss: 6.040702]\n",
      "epoch:40 step:31949 [D loss: 0.369544, acc: 80.47%] [G loss: 8.021744]\n",
      "epoch:40 step:31950 [D loss: 0.066257, acc: 100.00%] [G loss: 7.102918]\n",
      "epoch:40 step:31951 [D loss: 0.066339, acc: 100.00%] [G loss: 8.096853]\n",
      "epoch:40 step:31952 [D loss: 0.483640, acc: 66.41%] [G loss: 5.116320]\n",
      "epoch:40 step:31953 [D loss: 0.978367, acc: 29.69%] [G loss: 10.722881]\n",
      "epoch:40 step:31954 [D loss: 0.018769, acc: 100.00%] [G loss: 5.930435]\n",
      "epoch:40 step:31955 [D loss: 0.075454, acc: 99.22%] [G loss: 7.902317]\n",
      "epoch:40 step:31956 [D loss: 0.190532, acc: 96.88%] [G loss: 5.829584]\n",
      "epoch:40 step:31957 [D loss: 0.058222, acc: 100.00%] [G loss: 4.730814]\n",
      "epoch:40 step:31958 [D loss: 1.048416, acc: 50.00%] [G loss: 5.808552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31959 [D loss: 0.439808, acc: 74.22%] [G loss: 5.960654]\n",
      "epoch:40 step:31960 [D loss: 0.173861, acc: 98.44%] [G loss: 3.386406]\n",
      "epoch:40 step:31961 [D loss: 0.304194, acc: 89.84%] [G loss: 9.441338]\n",
      "epoch:40 step:31962 [D loss: 1.263420, acc: 50.00%] [G loss: 5.462139]\n",
      "epoch:40 step:31963 [D loss: 0.017152, acc: 100.00%] [G loss: 5.852861]\n",
      "epoch:40 step:31964 [D loss: 0.274596, acc: 92.97%] [G loss: 5.595087]\n",
      "epoch:40 step:31965 [D loss: 1.056874, acc: 26.56%] [G loss: 3.902623]\n",
      "epoch:40 step:31966 [D loss: 0.415315, acc: 86.72%] [G loss: 6.979923]\n",
      "epoch:40 step:31967 [D loss: 0.134717, acc: 99.22%] [G loss: 4.748950]\n",
      "epoch:40 step:31968 [D loss: 0.240414, acc: 98.44%] [G loss: 5.658492]\n",
      "epoch:40 step:31969 [D loss: 0.227457, acc: 96.09%] [G loss: 5.198215]\n",
      "epoch:40 step:31970 [D loss: 0.443029, acc: 80.47%] [G loss: 5.667633]\n",
      "epoch:40 step:31971 [D loss: 0.053112, acc: 100.00%] [G loss: 4.266088]\n",
      "epoch:40 step:31972 [D loss: 0.149095, acc: 99.22%] [G loss: 3.966310]\n",
      "epoch:40 step:31973 [D loss: 0.087422, acc: 98.44%] [G loss: 5.199930]\n",
      "epoch:40 step:31974 [D loss: 1.503509, acc: 42.97%] [G loss: 7.703181]\n",
      "epoch:40 step:31975 [D loss: 0.019157, acc: 100.00%] [G loss: 7.044312]\n",
      "epoch:40 step:31976 [D loss: 0.064980, acc: 100.00%] [G loss: 6.191322]\n",
      "epoch:40 step:31977 [D loss: 0.252229, acc: 88.28%] [G loss: 8.066712]\n",
      "epoch:40 step:31978 [D loss: 0.271021, acc: 92.19%] [G loss: 6.221120]\n",
      "epoch:40 step:31979 [D loss: 0.194780, acc: 97.66%] [G loss: 5.824695]\n",
      "epoch:40 step:31980 [D loss: 0.107091, acc: 100.00%] [G loss: 6.576317]\n",
      "epoch:40 step:31981 [D loss: 0.026410, acc: 100.00%] [G loss: 3.435161]\n",
      "epoch:40 step:31982 [D loss: 0.228972, acc: 98.44%] [G loss: 4.081959]\n",
      "epoch:40 step:31983 [D loss: 0.418506, acc: 85.16%] [G loss: 4.789871]\n",
      "epoch:40 step:31984 [D loss: 0.172986, acc: 98.44%] [G loss: 3.291759]\n",
      "epoch:40 step:31985 [D loss: 0.325958, acc: 88.28%] [G loss: 6.598744]\n",
      "epoch:40 step:31986 [D loss: 0.140052, acc: 98.44%] [G loss: 7.433454]\n",
      "epoch:40 step:31987 [D loss: 0.767646, acc: 54.69%] [G loss: 6.459145]\n",
      "epoch:40 step:31988 [D loss: 0.173523, acc: 96.88%] [G loss: 4.086340]\n",
      "epoch:40 step:31989 [D loss: 0.350501, acc: 85.94%] [G loss: 5.103805]\n",
      "epoch:40 step:31990 [D loss: 0.745604, acc: 56.25%] [G loss: 4.809762]\n",
      "epoch:40 step:31991 [D loss: 0.502588, acc: 75.78%] [G loss: 7.660987]\n",
      "epoch:40 step:31992 [D loss: 0.572573, acc: 60.94%] [G loss: 5.757207]\n",
      "epoch:40 step:31993 [D loss: 0.071812, acc: 100.00%] [G loss: 7.643297]\n",
      "epoch:40 step:31994 [D loss: 1.593925, acc: 17.97%] [G loss: 10.119307]\n",
      "epoch:40 step:31995 [D loss: 0.223734, acc: 98.44%] [G loss: 4.856321]\n",
      "epoch:40 step:31996 [D loss: 0.926753, acc: 39.06%] [G loss: 9.467331]\n",
      "epoch:40 step:31997 [D loss: 0.310315, acc: 90.62%] [G loss: 6.319718]\n",
      "epoch:40 step:31998 [D loss: 0.732604, acc: 50.78%] [G loss: 5.789993]\n",
      "epoch:40 step:31999 [D loss: 0.077944, acc: 100.00%] [G loss: 7.746855]\n",
      "epoch:40 step:32000 [D loss: 0.018199, acc: 100.00%] [G loss: 8.674147]\n",
      "epoch:40 step:32001 [D loss: 0.666541, acc: 55.47%] [G loss: 6.511433]\n",
      "epoch:40 step:32002 [D loss: 0.107689, acc: 99.22%] [G loss: 5.570350]\n",
      "epoch:40 step:32003 [D loss: 0.185103, acc: 96.09%] [G loss: 3.040559]\n",
      "epoch:40 step:32004 [D loss: 0.283083, acc: 92.19%] [G loss: 4.845427]\n",
      "epoch:40 step:32005 [D loss: 0.281741, acc: 86.72%] [G loss: 5.593339]\n",
      "epoch:40 step:32006 [D loss: 0.222753, acc: 99.22%] [G loss: 5.182488]\n",
      "epoch:40 step:32007 [D loss: 0.164822, acc: 97.66%] [G loss: 7.248022]\n",
      "epoch:40 step:32008 [D loss: 0.135265, acc: 99.22%] [G loss: 7.123046]\n",
      "epoch:40 step:32009 [D loss: 0.424152, acc: 86.72%] [G loss: 6.438895]\n",
      "epoch:40 step:32010 [D loss: 0.043750, acc: 100.00%] [G loss: 4.385766]\n",
      "epoch:40 step:32011 [D loss: 0.645137, acc: 64.06%] [G loss: 3.894271]\n",
      "epoch:40 step:32012 [D loss: 0.366681, acc: 83.59%] [G loss: 5.444897]\n",
      "epoch:40 step:32013 [D loss: 0.144908, acc: 97.66%] [G loss: 8.562705]\n",
      "epoch:40 step:32014 [D loss: 0.051139, acc: 100.00%] [G loss: 6.752748]\n",
      "epoch:40 step:32015 [D loss: 0.898187, acc: 53.12%] [G loss: 8.728313]\n",
      "epoch:40 step:32016 [D loss: 0.673732, acc: 53.91%] [G loss: 3.164104]\n",
      "epoch:40 step:32017 [D loss: 0.135878, acc: 100.00%] [G loss: 5.756481]\n",
      "epoch:40 step:32018 [D loss: 0.139309, acc: 98.44%] [G loss: 5.800875]\n",
      "epoch:40 step:32019 [D loss: 0.033682, acc: 100.00%] [G loss: 8.865591]\n",
      "epoch:40 step:32020 [D loss: 0.452613, acc: 85.16%] [G loss: 3.417061]\n",
      "epoch:40 step:32021 [D loss: 0.288870, acc: 92.19%] [G loss: 4.916076]\n",
      "epoch:41 step:32022 [D loss: 0.047331, acc: 100.00%] [G loss: 3.587541]\n",
      "epoch:41 step:32023 [D loss: 0.114194, acc: 99.22%] [G loss: 6.675237]\n",
      "epoch:41 step:32024 [D loss: 0.136918, acc: 98.44%] [G loss: 6.879085]\n",
      "epoch:41 step:32025 [D loss: 0.267504, acc: 86.72%] [G loss: 7.802011]\n",
      "epoch:41 step:32026 [D loss: 0.723161, acc: 57.03%] [G loss: 5.209090]\n",
      "epoch:41 step:32027 [D loss: 0.352930, acc: 85.94%] [G loss: 5.062039]\n",
      "epoch:41 step:32028 [D loss: 0.039370, acc: 100.00%] [G loss: 5.928150]\n",
      "epoch:41 step:32029 [D loss: 0.253205, acc: 92.19%] [G loss: 6.102234]\n",
      "epoch:41 step:32030 [D loss: 0.059710, acc: 100.00%] [G loss: 5.496442]\n",
      "epoch:41 step:32031 [D loss: 0.156417, acc: 98.44%] [G loss: 5.264908]\n",
      "epoch:41 step:32032 [D loss: 0.139501, acc: 98.44%] [G loss: 4.725903]\n",
      "epoch:41 step:32033 [D loss: 0.333293, acc: 88.28%] [G loss: 5.070225]\n",
      "epoch:41 step:32034 [D loss: 0.041510, acc: 100.00%] [G loss: 7.082482]\n",
      "epoch:41 step:32035 [D loss: 0.257151, acc: 88.28%] [G loss: 3.500529]\n",
      "epoch:41 step:32036 [D loss: 0.769525, acc: 56.25%] [G loss: 5.567123]\n",
      "epoch:41 step:32037 [D loss: 0.060831, acc: 100.00%] [G loss: 4.615040]\n",
      "epoch:41 step:32038 [D loss: 0.164282, acc: 96.88%] [G loss: 2.029830]\n",
      "epoch:41 step:32039 [D loss: 0.549149, acc: 61.72%] [G loss: 4.100806]\n",
      "epoch:41 step:32040 [D loss: 0.213415, acc: 94.53%] [G loss: 5.456738]\n",
      "epoch:41 step:32041 [D loss: 0.566194, acc: 71.09%] [G loss: 7.109051]\n",
      "epoch:41 step:32042 [D loss: 0.135961, acc: 100.00%] [G loss: 4.830858]\n",
      "epoch:41 step:32043 [D loss: 0.172216, acc: 97.66%] [G loss: 3.946383]\n",
      "epoch:41 step:32044 [D loss: 0.065427, acc: 100.00%] [G loss: 7.364368]\n",
      "epoch:41 step:32045 [D loss: 0.331839, acc: 86.72%] [G loss: 5.941294]\n",
      "epoch:41 step:32046 [D loss: 0.150717, acc: 96.88%] [G loss: 1.943093]\n",
      "epoch:41 step:32047 [D loss: 0.090180, acc: 100.00%] [G loss: 5.481634]\n",
      "epoch:41 step:32048 [D loss: 0.237157, acc: 93.75%] [G loss: 3.409790]\n",
      "epoch:41 step:32049 [D loss: 0.307283, acc: 91.41%] [G loss: 5.011463]\n",
      "epoch:41 step:32050 [D loss: 0.963889, acc: 50.00%] [G loss: 6.683856]\n",
      "epoch:41 step:32051 [D loss: 0.042352, acc: 100.00%] [G loss: 7.897039]\n",
      "epoch:41 step:32052 [D loss: 0.131886, acc: 99.22%] [G loss: 7.864120]\n",
      "epoch:41 step:32053 [D loss: 0.129554, acc: 100.00%] [G loss: 7.953207]\n",
      "epoch:41 step:32054 [D loss: 0.048227, acc: 100.00%] [G loss: 7.280142]\n",
      "epoch:41 step:32055 [D loss: 0.078403, acc: 99.22%] [G loss: 7.424742]\n",
      "epoch:41 step:32056 [D loss: 0.153048, acc: 99.22%] [G loss: 5.174841]\n",
      "epoch:41 step:32057 [D loss: 0.093007, acc: 99.22%] [G loss: 8.129599]\n",
      "epoch:41 step:32058 [D loss: 0.861958, acc: 38.28%] [G loss: 9.345603]\n",
      "epoch:41 step:32059 [D loss: 0.031983, acc: 100.00%] [G loss: 5.591919]\n",
      "epoch:41 step:32060 [D loss: 0.205075, acc: 98.44%] [G loss: 8.311868]\n",
      "epoch:41 step:32061 [D loss: 0.302803, acc: 83.59%] [G loss: 4.097758]\n",
      "epoch:41 step:32062 [D loss: 0.102036, acc: 100.00%] [G loss: 5.582972]\n",
      "epoch:41 step:32063 [D loss: 0.534927, acc: 71.09%] [G loss: 6.650865]\n",
      "epoch:41 step:32064 [D loss: 0.149339, acc: 100.00%] [G loss: 5.265167]\n",
      "epoch:41 step:32065 [D loss: 0.132815, acc: 100.00%] [G loss: 3.287663]\n",
      "epoch:41 step:32066 [D loss: 0.181097, acc: 96.88%] [G loss: 8.248589]\n",
      "epoch:41 step:32067 [D loss: 0.034284, acc: 100.00%] [G loss: 8.217724]\n",
      "epoch:41 step:32068 [D loss: 0.047116, acc: 100.00%] [G loss: 3.868123]\n",
      "epoch:41 step:32069 [D loss: 0.159486, acc: 97.66%] [G loss: 4.391165]\n",
      "epoch:41 step:32070 [D loss: 0.389515, acc: 81.25%] [G loss: 5.684272]\n",
      "epoch:41 step:32071 [D loss: 0.220438, acc: 98.44%] [G loss: 4.017436]\n",
      "epoch:41 step:32072 [D loss: 0.234591, acc: 98.44%] [G loss: 5.008802]\n",
      "epoch:41 step:32073 [D loss: 0.077553, acc: 100.00%] [G loss: 6.404846]\n",
      "epoch:41 step:32074 [D loss: 0.439789, acc: 83.59%] [G loss: 4.493317]\n",
      "epoch:41 step:32075 [D loss: 0.108710, acc: 100.00%] [G loss: 2.588275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32076 [D loss: 0.580361, acc: 64.06%] [G loss: 6.406664]\n",
      "epoch:41 step:32077 [D loss: 0.538350, acc: 67.19%] [G loss: 5.853654]\n",
      "epoch:41 step:32078 [D loss: 0.996304, acc: 50.78%] [G loss: 3.811910]\n",
      "epoch:41 step:32079 [D loss: 0.154647, acc: 99.22%] [G loss: 5.816554]\n",
      "epoch:41 step:32080 [D loss: 0.053986, acc: 100.00%] [G loss: 3.309007]\n",
      "epoch:41 step:32081 [D loss: 0.258785, acc: 92.19%] [G loss: 6.643917]\n",
      "epoch:41 step:32082 [D loss: 0.969630, acc: 49.22%] [G loss: 3.537582]\n",
      "epoch:41 step:32083 [D loss: 0.022612, acc: 100.00%] [G loss: 6.890246]\n",
      "epoch:41 step:32084 [D loss: 0.607537, acc: 66.41%] [G loss: 7.687620]\n",
      "epoch:41 step:32085 [D loss: 0.151806, acc: 99.22%] [G loss: 5.201237]\n",
      "epoch:41 step:32086 [D loss: 0.685525, acc: 60.94%] [G loss: 5.525849]\n",
      "epoch:41 step:32087 [D loss: 0.442264, acc: 74.22%] [G loss: 4.488255]\n",
      "epoch:41 step:32088 [D loss: 0.335373, acc: 85.16%] [G loss: 2.852943]\n",
      "epoch:41 step:32089 [D loss: 0.540554, acc: 76.56%] [G loss: 5.490726]\n",
      "epoch:41 step:32090 [D loss: 0.121585, acc: 99.22%] [G loss: 6.033230]\n",
      "epoch:41 step:32091 [D loss: 0.237248, acc: 97.66%] [G loss: 5.077221]\n",
      "epoch:41 step:32092 [D loss: 0.219487, acc: 95.31%] [G loss: 5.435038]\n",
      "epoch:41 step:32093 [D loss: 0.042564, acc: 100.00%] [G loss: 9.284958]\n",
      "epoch:41 step:32094 [D loss: 0.086430, acc: 99.22%] [G loss: 7.112379]\n",
      "epoch:41 step:32095 [D loss: 0.169601, acc: 98.44%] [G loss: 9.248240]\n",
      "epoch:41 step:32096 [D loss: 0.226110, acc: 95.31%] [G loss: 6.861667]\n",
      "epoch:41 step:32097 [D loss: 0.671548, acc: 56.25%] [G loss: 5.305541]\n",
      "epoch:41 step:32098 [D loss: 0.579883, acc: 69.53%] [G loss: 4.989919]\n",
      "epoch:41 step:32099 [D loss: 0.211286, acc: 94.53%] [G loss: 7.826059]\n",
      "epoch:41 step:32100 [D loss: 1.122028, acc: 46.09%] [G loss: 6.955209]\n",
      "epoch:41 step:32101 [D loss: 0.205278, acc: 95.31%] [G loss: 6.781504]\n",
      "epoch:41 step:32102 [D loss: 0.600462, acc: 60.16%] [G loss: 6.238616]\n",
      "epoch:41 step:32103 [D loss: 0.269563, acc: 96.88%] [G loss: 6.971230]\n",
      "epoch:41 step:32104 [D loss: 0.394679, acc: 74.22%] [G loss: 4.383672]\n",
      "epoch:41 step:32105 [D loss: 0.954092, acc: 39.84%] [G loss: 8.117132]\n",
      "epoch:41 step:32106 [D loss: 0.151799, acc: 100.00%] [G loss: 7.548208]\n",
      "epoch:41 step:32107 [D loss: 0.020479, acc: 100.00%] [G loss: 3.632444]\n",
      "epoch:41 step:32108 [D loss: 0.092710, acc: 100.00%] [G loss: 5.251970]\n",
      "epoch:41 step:32109 [D loss: 0.600753, acc: 60.16%] [G loss: 6.937191]\n",
      "epoch:41 step:32110 [D loss: 0.903844, acc: 50.78%] [G loss: 7.955265]\n",
      "epoch:41 step:32111 [D loss: 0.113461, acc: 100.00%] [G loss: 5.539620]\n",
      "epoch:41 step:32112 [D loss: 0.016719, acc: 100.00%] [G loss: 7.186893]\n",
      "epoch:41 step:32113 [D loss: 0.261219, acc: 96.09%] [G loss: 6.060074]\n",
      "epoch:41 step:32114 [D loss: 0.219718, acc: 97.66%] [G loss: 3.171558]\n",
      "epoch:41 step:32115 [D loss: 0.274146, acc: 88.28%] [G loss: 5.767272]\n",
      "epoch:41 step:32116 [D loss: 1.582147, acc: 13.28%] [G loss: 7.156927]\n",
      "epoch:41 step:32117 [D loss: 0.115609, acc: 98.44%] [G loss: 7.750183]\n",
      "epoch:41 step:32118 [D loss: 0.474622, acc: 68.75%] [G loss: 6.105496]\n",
      "epoch:41 step:32119 [D loss: 1.078480, acc: 51.56%] [G loss: 2.485122]\n",
      "epoch:41 step:32120 [D loss: 0.046128, acc: 99.22%] [G loss: 4.149889]\n",
      "epoch:41 step:32121 [D loss: 0.328451, acc: 81.25%] [G loss: 8.572640]\n",
      "epoch:41 step:32122 [D loss: 0.231443, acc: 93.75%] [G loss: 6.915514]\n",
      "epoch:41 step:32123 [D loss: 0.242889, acc: 93.75%] [G loss: 5.174282]\n",
      "epoch:41 step:32124 [D loss: 0.356255, acc: 91.41%] [G loss: 5.526919]\n",
      "epoch:41 step:32125 [D loss: 0.114826, acc: 99.22%] [G loss: 4.342875]\n",
      "epoch:41 step:32126 [D loss: 0.054367, acc: 99.22%] [G loss: 9.373190]\n",
      "epoch:41 step:32127 [D loss: 0.493650, acc: 75.00%] [G loss: 5.805844]\n",
      "epoch:41 step:32128 [D loss: 0.118455, acc: 99.22%] [G loss: 4.611722]\n",
      "epoch:41 step:32129 [D loss: 0.184050, acc: 98.44%] [G loss: 8.621973]\n",
      "epoch:41 step:32130 [D loss: 0.472263, acc: 84.38%] [G loss: 3.142150]\n",
      "epoch:41 step:32131 [D loss: 0.965326, acc: 51.56%] [G loss: 4.523026]\n",
      "epoch:41 step:32132 [D loss: 0.532597, acc: 61.72%] [G loss: 7.031773]\n",
      "epoch:41 step:32133 [D loss: 0.132771, acc: 100.00%] [G loss: 4.353853]\n",
      "epoch:41 step:32134 [D loss: 0.257662, acc: 91.41%] [G loss: 4.805170]\n",
      "epoch:41 step:32135 [D loss: 0.055736, acc: 100.00%] [G loss: 4.385505]\n",
      "epoch:41 step:32136 [D loss: 0.041343, acc: 100.00%] [G loss: 6.607239]\n",
      "epoch:41 step:32137 [D loss: 0.264005, acc: 89.06%] [G loss: 5.450070]\n",
      "epoch:41 step:32138 [D loss: 0.419579, acc: 88.28%] [G loss: 3.493973]\n",
      "epoch:41 step:32139 [D loss: 0.135131, acc: 99.22%] [G loss: 3.399555]\n",
      "epoch:41 step:32140 [D loss: 0.398683, acc: 81.25%] [G loss: 5.824883]\n",
      "epoch:41 step:32141 [D loss: 1.602137, acc: 50.00%] [G loss: 4.886621]\n",
      "epoch:41 step:32142 [D loss: 0.102356, acc: 100.00%] [G loss: 4.287137]\n",
      "epoch:41 step:32143 [D loss: 0.153597, acc: 97.66%] [G loss: 5.205112]\n",
      "epoch:41 step:32144 [D loss: 0.407135, acc: 77.34%] [G loss: 5.882490]\n",
      "epoch:41 step:32145 [D loss: 0.126560, acc: 100.00%] [G loss: 4.386162]\n",
      "epoch:41 step:32146 [D loss: 0.115870, acc: 100.00%] [G loss: 3.163856]\n",
      "epoch:41 step:32147 [D loss: 0.040642, acc: 100.00%] [G loss: 6.978346]\n",
      "epoch:41 step:32148 [D loss: 0.251844, acc: 94.53%] [G loss: 6.614020]\n",
      "epoch:41 step:32149 [D loss: 0.025602, acc: 100.00%] [G loss: 6.096397]\n",
      "epoch:41 step:32150 [D loss: 0.911371, acc: 50.78%] [G loss: 3.170529]\n",
      "epoch:41 step:32151 [D loss: 0.161724, acc: 98.44%] [G loss: 4.369245]\n",
      "epoch:41 step:32152 [D loss: 0.616863, acc: 63.28%] [G loss: 6.289582]\n",
      "epoch:41 step:32153 [D loss: 0.614695, acc: 66.41%] [G loss: 5.831120]\n",
      "epoch:41 step:32154 [D loss: 0.304624, acc: 92.19%] [G loss: 4.410859]\n",
      "epoch:41 step:32155 [D loss: 0.292660, acc: 96.09%] [G loss: 5.993210]\n",
      "epoch:41 step:32156 [D loss: 0.390248, acc: 90.62%] [G loss: 4.738236]\n",
      "epoch:41 step:32157 [D loss: 0.037726, acc: 100.00%] [G loss: 6.689967]\n",
      "epoch:41 step:32158 [D loss: 0.136971, acc: 100.00%] [G loss: 3.816896]\n",
      "epoch:41 step:32159 [D loss: 0.384305, acc: 86.72%] [G loss: 3.779995]\n",
      "epoch:41 step:32160 [D loss: 0.248075, acc: 93.75%] [G loss: 5.139670]\n",
      "epoch:41 step:32161 [D loss: 0.599155, acc: 71.88%] [G loss: 4.973351]\n",
      "epoch:41 step:32162 [D loss: 0.351210, acc: 84.38%] [G loss: 7.533469]\n",
      "epoch:41 step:32163 [D loss: 0.349228, acc: 82.03%] [G loss: 5.139202]\n",
      "epoch:41 step:32164 [D loss: 0.351909, acc: 89.06%] [G loss: 6.644436]\n",
      "epoch:41 step:32165 [D loss: 0.454341, acc: 68.75%] [G loss: 5.471382]\n",
      "epoch:41 step:32166 [D loss: 0.974984, acc: 51.56%] [G loss: 3.482202]\n",
      "epoch:41 step:32167 [D loss: 0.064203, acc: 100.00%] [G loss: 6.141654]\n",
      "epoch:41 step:32168 [D loss: 0.172333, acc: 99.22%] [G loss: 7.605890]\n",
      "epoch:41 step:32169 [D loss: 0.274382, acc: 92.19%] [G loss: 2.659304]\n",
      "epoch:41 step:32170 [D loss: 1.079606, acc: 36.72%] [G loss: 6.944030]\n",
      "epoch:41 step:32171 [D loss: 0.104268, acc: 99.22%] [G loss: 3.996810]\n",
      "epoch:41 step:32172 [D loss: 0.112156, acc: 100.00%] [G loss: 4.162114]\n",
      "epoch:41 step:32173 [D loss: 0.406675, acc: 72.66%] [G loss: 8.273963]\n",
      "epoch:41 step:32174 [D loss: 0.561079, acc: 63.28%] [G loss: 7.347570]\n",
      "epoch:41 step:32175 [D loss: 0.625016, acc: 60.94%] [G loss: 5.125829]\n",
      "epoch:41 step:32176 [D loss: 0.415714, acc: 88.28%] [G loss: 3.259480]\n",
      "epoch:41 step:32177 [D loss: 0.291072, acc: 84.38%] [G loss: 6.307902]\n",
      "epoch:41 step:32178 [D loss: 0.171230, acc: 98.44%] [G loss: 3.794654]\n",
      "epoch:41 step:32179 [D loss: 0.233448, acc: 97.66%] [G loss: 5.361971]\n",
      "epoch:41 step:32180 [D loss: 0.164283, acc: 97.66%] [G loss: 6.059200]\n",
      "epoch:41 step:32181 [D loss: 1.396788, acc: 26.56%] [G loss: 10.189738]\n",
      "epoch:41 step:32182 [D loss: 0.080507, acc: 100.00%] [G loss: 4.000729]\n",
      "epoch:41 step:32183 [D loss: 0.196687, acc: 97.66%] [G loss: 4.991218]\n",
      "epoch:41 step:32184 [D loss: 1.266438, acc: 14.84%] [G loss: 6.555826]\n",
      "epoch:41 step:32185 [D loss: 0.498868, acc: 75.00%] [G loss: 6.087623]\n",
      "epoch:41 step:32186 [D loss: 0.967975, acc: 39.84%] [G loss: 4.901637]\n",
      "epoch:41 step:32187 [D loss: 0.578874, acc: 59.38%] [G loss: 4.256258]\n",
      "epoch:41 step:32188 [D loss: 0.680112, acc: 57.03%] [G loss: 6.078757]\n",
      "epoch:41 step:32189 [D loss: 0.709968, acc: 55.47%] [G loss: 6.019748]\n",
      "epoch:41 step:32190 [D loss: 0.516323, acc: 68.75%] [G loss: 2.225509]\n",
      "epoch:41 step:32191 [D loss: 0.091002, acc: 100.00%] [G loss: 4.339266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32192 [D loss: 0.146920, acc: 99.22%] [G loss: 3.869196]\n",
      "epoch:41 step:32193 [D loss: 0.199034, acc: 89.06%] [G loss: 6.049196]\n",
      "epoch:41 step:32194 [D loss: 0.270347, acc: 96.88%] [G loss: 3.153533]\n",
      "epoch:41 step:32195 [D loss: 0.215913, acc: 91.41%] [G loss: 4.046018]\n",
      "epoch:41 step:32196 [D loss: 0.264718, acc: 89.06%] [G loss: 6.256336]\n",
      "epoch:41 step:32197 [D loss: 0.230558, acc: 95.31%] [G loss: 3.967963]\n",
      "epoch:41 step:32198 [D loss: 0.494506, acc: 71.88%] [G loss: 7.001552]\n",
      "epoch:41 step:32199 [D loss: 0.655905, acc: 61.72%] [G loss: 4.122395]\n",
      "epoch:41 step:32200 [D loss: 0.294075, acc: 89.06%] [G loss: 1.937915]\n",
      "epoch:41 step:32201 [D loss: 0.366251, acc: 81.25%] [G loss: 3.910557]\n",
      "epoch:41 step:32202 [D loss: 0.853709, acc: 54.69%] [G loss: 6.427258]\n",
      "epoch:41 step:32203 [D loss: 0.143371, acc: 96.88%] [G loss: 7.157447]\n",
      "epoch:41 step:32204 [D loss: 0.319365, acc: 82.03%] [G loss: 5.897336]\n",
      "epoch:41 step:32205 [D loss: 0.320970, acc: 85.16%] [G loss: 6.336115]\n",
      "epoch:41 step:32206 [D loss: 0.412723, acc: 71.88%] [G loss: 6.446836]\n",
      "epoch:41 step:32207 [D loss: 0.448978, acc: 85.16%] [G loss: 6.100507]\n",
      "epoch:41 step:32208 [D loss: 0.461448, acc: 82.03%] [G loss: 4.248185]\n",
      "epoch:41 step:32209 [D loss: 0.224032, acc: 96.88%] [G loss: 4.191862]\n",
      "epoch:41 step:32210 [D loss: 0.089507, acc: 100.00%] [G loss: 6.524271]\n",
      "epoch:41 step:32211 [D loss: 0.879828, acc: 43.75%] [G loss: 3.740231]\n",
      "epoch:41 step:32212 [D loss: 0.476344, acc: 67.97%] [G loss: 5.791675]\n",
      "epoch:41 step:32213 [D loss: 0.211730, acc: 97.66%] [G loss: 6.299899]\n",
      "epoch:41 step:32214 [D loss: 0.389672, acc: 85.16%] [G loss: 7.622770]\n",
      "epoch:41 step:32215 [D loss: 0.160159, acc: 98.44%] [G loss: 4.456406]\n",
      "epoch:41 step:32216 [D loss: 0.158288, acc: 99.22%] [G loss: 6.311032]\n",
      "epoch:41 step:32217 [D loss: 0.305214, acc: 94.53%] [G loss: 4.384687]\n",
      "epoch:41 step:32218 [D loss: 0.379523, acc: 79.69%] [G loss: 3.015628]\n",
      "epoch:41 step:32219 [D loss: 0.042170, acc: 100.00%] [G loss: 6.666544]\n",
      "epoch:41 step:32220 [D loss: 0.215784, acc: 96.09%] [G loss: 1.863546]\n",
      "epoch:41 step:32221 [D loss: 0.041599, acc: 100.00%] [G loss: 5.986253]\n",
      "epoch:41 step:32222 [D loss: 0.215638, acc: 90.62%] [G loss: 9.384453]\n",
      "epoch:41 step:32223 [D loss: 0.069444, acc: 100.00%] [G loss: 2.380899]\n",
      "epoch:41 step:32224 [D loss: 0.731074, acc: 59.38%] [G loss: 5.878979]\n",
      "epoch:41 step:32225 [D loss: 0.545279, acc: 58.59%] [G loss: 7.102297]\n",
      "epoch:41 step:32226 [D loss: 0.249237, acc: 90.62%] [G loss: 4.590266]\n",
      "epoch:41 step:32227 [D loss: 0.344030, acc: 89.84%] [G loss: 6.681030]\n",
      "epoch:41 step:32228 [D loss: 0.226250, acc: 99.22%] [G loss: 4.962230]\n",
      "epoch:41 step:32229 [D loss: 0.102685, acc: 99.22%] [G loss: 5.489861]\n",
      "epoch:41 step:32230 [D loss: 0.168654, acc: 100.00%] [G loss: 5.020438]\n",
      "epoch:41 step:32231 [D loss: 0.155804, acc: 97.66%] [G loss: 4.673933]\n",
      "epoch:41 step:32232 [D loss: 0.246299, acc: 92.97%] [G loss: 5.936826]\n",
      "epoch:41 step:32233 [D loss: 0.038540, acc: 100.00%] [G loss: 6.881121]\n",
      "epoch:41 step:32234 [D loss: 0.476875, acc: 79.69%] [G loss: 5.558621]\n",
      "epoch:41 step:32235 [D loss: 0.340285, acc: 78.91%] [G loss: 7.388484]\n",
      "epoch:41 step:32236 [D loss: 0.403026, acc: 82.03%] [G loss: 4.794490]\n",
      "epoch:41 step:32237 [D loss: 0.907185, acc: 52.34%] [G loss: 4.670153]\n",
      "epoch:41 step:32238 [D loss: 0.213813, acc: 95.31%] [G loss: 6.114948]\n",
      "epoch:41 step:32239 [D loss: 0.604826, acc: 62.50%] [G loss: 6.895983]\n",
      "epoch:41 step:32240 [D loss: 0.468033, acc: 67.19%] [G loss: 6.014349]\n",
      "epoch:41 step:32241 [D loss: 0.278172, acc: 90.62%] [G loss: 4.211006]\n",
      "epoch:41 step:32242 [D loss: 0.441039, acc: 82.03%] [G loss: 2.942917]\n",
      "epoch:41 step:32243 [D loss: 0.188494, acc: 96.88%] [G loss: 2.692946]\n",
      "epoch:41 step:32244 [D loss: 0.980811, acc: 50.78%] [G loss: 5.842864]\n",
      "epoch:41 step:32245 [D loss: 0.623398, acc: 56.25%] [G loss: 6.917744]\n",
      "epoch:41 step:32246 [D loss: 0.087455, acc: 99.22%] [G loss: 6.518041]\n",
      "epoch:41 step:32247 [D loss: 0.135951, acc: 98.44%] [G loss: 4.614729]\n",
      "epoch:41 step:32248 [D loss: 0.733953, acc: 51.56%] [G loss: 6.363647]\n",
      "epoch:41 step:32249 [D loss: 0.639335, acc: 58.59%] [G loss: 6.163288]\n",
      "epoch:41 step:32250 [D loss: 0.084244, acc: 100.00%] [G loss: 8.097269]\n",
      "epoch:41 step:32251 [D loss: 0.926415, acc: 49.22%] [G loss: 8.482443]\n",
      "epoch:41 step:32252 [D loss: 0.270981, acc: 89.06%] [G loss: 3.366074]\n",
      "epoch:41 step:32253 [D loss: 1.014966, acc: 48.44%] [G loss: 5.821408]\n",
      "epoch:41 step:32254 [D loss: 0.194801, acc: 95.31%] [G loss: 3.745479]\n",
      "epoch:41 step:32255 [D loss: 0.378823, acc: 77.34%] [G loss: 7.450035]\n",
      "epoch:41 step:32256 [D loss: 0.528441, acc: 70.31%] [G loss: 5.913499]\n",
      "epoch:41 step:32257 [D loss: 0.909123, acc: 53.91%] [G loss: 3.947729]\n",
      "epoch:41 step:32258 [D loss: 0.138006, acc: 99.22%] [G loss: 8.957878]\n",
      "epoch:41 step:32259 [D loss: 0.307756, acc: 90.62%] [G loss: 7.694084]\n",
      "epoch:41 step:32260 [D loss: 0.569676, acc: 64.06%] [G loss: 6.159427]\n",
      "epoch:41 step:32261 [D loss: 0.147686, acc: 98.44%] [G loss: 4.234145]\n",
      "epoch:41 step:32262 [D loss: 0.049022, acc: 100.00%] [G loss: 8.547825]\n",
      "epoch:41 step:32263 [D loss: 1.047313, acc: 50.78%] [G loss: 3.737420]\n",
      "epoch:41 step:32264 [D loss: 0.427513, acc: 71.09%] [G loss: 7.997026]\n",
      "epoch:41 step:32265 [D loss: 0.781045, acc: 54.69%] [G loss: 8.537233]\n",
      "epoch:41 step:32266 [D loss: 0.411318, acc: 82.03%] [G loss: 3.862160]\n",
      "epoch:41 step:32267 [D loss: 0.743197, acc: 56.25%] [G loss: 5.592232]\n",
      "epoch:41 step:32268 [D loss: 0.060137, acc: 100.00%] [G loss: 7.692479]\n",
      "epoch:41 step:32269 [D loss: 0.127272, acc: 100.00%] [G loss: 9.231557]\n",
      "epoch:41 step:32270 [D loss: 0.439617, acc: 69.53%] [G loss: 5.032520]\n",
      "epoch:41 step:32271 [D loss: 0.219924, acc: 89.06%] [G loss: 3.457002]\n",
      "epoch:41 step:32272 [D loss: 0.099135, acc: 96.88%] [G loss: 4.830098]\n",
      "epoch:41 step:32273 [D loss: 0.217394, acc: 95.31%] [G loss: 3.402927]\n",
      "epoch:41 step:32274 [D loss: 0.439870, acc: 82.03%] [G loss: 2.947473]\n",
      "epoch:41 step:32275 [D loss: 0.262574, acc: 88.28%] [G loss: 5.351691]\n",
      "epoch:41 step:32276 [D loss: 0.217344, acc: 96.88%] [G loss: 4.715590]\n",
      "epoch:41 step:32277 [D loss: 0.129863, acc: 98.44%] [G loss: 5.588057]\n",
      "epoch:41 step:32278 [D loss: 0.757229, acc: 54.69%] [G loss: 5.183788]\n",
      "epoch:41 step:32279 [D loss: 0.164825, acc: 96.88%] [G loss: 4.965151]\n",
      "epoch:41 step:32280 [D loss: 0.762532, acc: 53.91%] [G loss: 7.574116]\n",
      "epoch:41 step:32281 [D loss: 0.162276, acc: 98.44%] [G loss: 7.118755]\n",
      "epoch:41 step:32282 [D loss: 0.725829, acc: 55.47%] [G loss: 4.131444]\n",
      "epoch:41 step:32283 [D loss: 0.469217, acc: 65.62%] [G loss: 9.557383]\n",
      "epoch:41 step:32284 [D loss: 1.339375, acc: 30.47%] [G loss: 6.641556]\n",
      "epoch:41 step:32285 [D loss: 0.056962, acc: 100.00%] [G loss: 6.464624]\n",
      "epoch:41 step:32286 [D loss: 0.889260, acc: 44.53%] [G loss: 7.525018]\n",
      "epoch:41 step:32287 [D loss: 2.109233, acc: 3.12%] [G loss: 5.882328]\n",
      "epoch:41 step:32288 [D loss: 0.111552, acc: 100.00%] [G loss: 3.172352]\n",
      "epoch:41 step:32289 [D loss: 0.080494, acc: 100.00%] [G loss: 4.930908]\n",
      "epoch:41 step:32290 [D loss: 0.297590, acc: 92.97%] [G loss: 4.259694]\n",
      "epoch:41 step:32291 [D loss: 1.210976, acc: 50.78%] [G loss: 6.911432]\n",
      "epoch:41 step:32292 [D loss: 0.064666, acc: 100.00%] [G loss: 2.997024]\n",
      "epoch:41 step:32293 [D loss: 0.361971, acc: 80.47%] [G loss: 8.376568]\n",
      "epoch:41 step:32294 [D loss: 0.273049, acc: 94.53%] [G loss: 3.418719]\n",
      "epoch:41 step:32295 [D loss: 0.241654, acc: 98.44%] [G loss: 2.769095]\n",
      "epoch:41 step:32296 [D loss: 0.680558, acc: 60.94%] [G loss: 8.197077]\n",
      "epoch:41 step:32297 [D loss: 0.298200, acc: 92.19%] [G loss: 6.838690]\n",
      "epoch:41 step:32298 [D loss: 0.175503, acc: 99.22%] [G loss: 4.818804]\n",
      "epoch:41 step:32299 [D loss: 0.193932, acc: 100.00%] [G loss: 6.900009]\n",
      "epoch:41 step:32300 [D loss: 0.401347, acc: 78.12%] [G loss: 3.174536]\n",
      "epoch:41 step:32301 [D loss: 0.284190, acc: 89.84%] [G loss: 6.713336]\n",
      "epoch:41 step:32302 [D loss: 0.082331, acc: 100.00%] [G loss: 5.782409]\n",
      "epoch:41 step:32303 [D loss: 0.302888, acc: 85.16%] [G loss: 6.529089]\n",
      "epoch:41 step:32304 [D loss: 0.916663, acc: 51.56%] [G loss: 3.642834]\n",
      "epoch:41 step:32305 [D loss: 0.053692, acc: 100.00%] [G loss: 8.060795]\n",
      "epoch:41 step:32306 [D loss: 0.571660, acc: 63.28%] [G loss: 8.448594]\n",
      "epoch:41 step:32307 [D loss: 1.012417, acc: 31.25%] [G loss: 6.549635]\n",
      "epoch:41 step:32308 [D loss: 0.209885, acc: 96.09%] [G loss: 5.762557]\n",
      "epoch:41 step:32309 [D loss: 0.472017, acc: 76.56%] [G loss: 4.742031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32310 [D loss: 0.075751, acc: 100.00%] [G loss: 4.639086]\n",
      "epoch:41 step:32311 [D loss: 0.139575, acc: 99.22%] [G loss: 6.049273]\n",
      "epoch:41 step:32312 [D loss: 0.879177, acc: 52.34%] [G loss: 4.406548]\n",
      "epoch:41 step:32313 [D loss: 0.483470, acc: 64.84%] [G loss: 6.849584]\n",
      "epoch:41 step:32314 [D loss: 0.049640, acc: 100.00%] [G loss: 3.917504]\n",
      "epoch:41 step:32315 [D loss: 0.606691, acc: 65.62%] [G loss: 7.628983]\n",
      "epoch:41 step:32316 [D loss: 0.211013, acc: 96.09%] [G loss: 3.943432]\n",
      "epoch:41 step:32317 [D loss: 0.261801, acc: 89.84%] [G loss: 4.005101]\n",
      "epoch:41 step:32318 [D loss: 0.193305, acc: 97.66%] [G loss: 6.142417]\n",
      "epoch:41 step:32319 [D loss: 0.046855, acc: 100.00%] [G loss: 3.431302]\n",
      "epoch:41 step:32320 [D loss: 0.535261, acc: 67.19%] [G loss: 5.921342]\n",
      "epoch:41 step:32321 [D loss: 0.235911, acc: 89.06%] [G loss: 4.506976]\n",
      "epoch:41 step:32322 [D loss: 0.789941, acc: 50.78%] [G loss: 4.746308]\n",
      "epoch:41 step:32323 [D loss: 0.111128, acc: 100.00%] [G loss: 2.864030]\n",
      "epoch:41 step:32324 [D loss: 1.007977, acc: 50.00%] [G loss: 5.119585]\n",
      "epoch:41 step:32325 [D loss: 0.872728, acc: 46.09%] [G loss: 3.882741]\n",
      "epoch:41 step:32326 [D loss: 0.080857, acc: 100.00%] [G loss: 4.269810]\n",
      "epoch:41 step:32327 [D loss: 0.080077, acc: 99.22%] [G loss: 4.442396]\n",
      "epoch:41 step:32328 [D loss: 0.105799, acc: 100.00%] [G loss: 7.515183]\n",
      "epoch:41 step:32329 [D loss: 0.144699, acc: 98.44%] [G loss: 3.183960]\n",
      "epoch:41 step:32330 [D loss: 0.453903, acc: 83.59%] [G loss: 5.101757]\n",
      "epoch:41 step:32331 [D loss: 0.539274, acc: 71.88%] [G loss: 5.649247]\n",
      "epoch:41 step:32332 [D loss: 0.539354, acc: 75.78%] [G loss: 4.228497]\n",
      "epoch:41 step:32333 [D loss: 1.090746, acc: 50.78%] [G loss: 4.427573]\n",
      "epoch:41 step:32334 [D loss: 0.069495, acc: 99.22%] [G loss: 4.384762]\n",
      "epoch:41 step:32335 [D loss: 0.190691, acc: 97.66%] [G loss: 5.722239]\n",
      "epoch:41 step:32336 [D loss: 0.751258, acc: 56.25%] [G loss: 6.746973]\n",
      "epoch:41 step:32337 [D loss: 0.066627, acc: 100.00%] [G loss: 1.604792]\n",
      "epoch:41 step:32338 [D loss: 0.079407, acc: 99.22%] [G loss: 4.080401]\n",
      "epoch:41 step:32339 [D loss: 0.100166, acc: 98.44%] [G loss: 9.517096]\n",
      "epoch:41 step:32340 [D loss: 1.192396, acc: 50.00%] [G loss: 2.398200]\n",
      "epoch:41 step:32341 [D loss: 0.124999, acc: 98.44%] [G loss: 4.205822]\n",
      "epoch:41 step:32342 [D loss: 0.551506, acc: 71.88%] [G loss: 3.424271]\n",
      "epoch:41 step:32343 [D loss: 0.243243, acc: 92.97%] [G loss: 3.149539]\n",
      "epoch:41 step:32344 [D loss: 0.489841, acc: 73.44%] [G loss: 4.286949]\n",
      "epoch:41 step:32345 [D loss: 0.122003, acc: 100.00%] [G loss: 2.483387]\n",
      "epoch:41 step:32346 [D loss: 0.183816, acc: 97.66%] [G loss: 4.667404]\n",
      "epoch:41 step:32347 [D loss: 0.594072, acc: 71.88%] [G loss: 5.533421]\n",
      "epoch:41 step:32348 [D loss: 0.222611, acc: 95.31%] [G loss: 4.822173]\n",
      "epoch:41 step:32349 [D loss: 0.780678, acc: 52.34%] [G loss: 4.049042]\n",
      "epoch:41 step:32350 [D loss: 0.331841, acc: 85.94%] [G loss: 7.069214]\n",
      "epoch:41 step:32351 [D loss: 0.162470, acc: 100.00%] [G loss: 2.839109]\n",
      "epoch:41 step:32352 [D loss: 0.074570, acc: 100.00%] [G loss: 5.777945]\n",
      "epoch:41 step:32353 [D loss: 0.156575, acc: 100.00%] [G loss: 3.740533]\n",
      "epoch:41 step:32354 [D loss: 0.148247, acc: 97.66%] [G loss: 6.462905]\n",
      "epoch:41 step:32355 [D loss: 0.203150, acc: 93.75%] [G loss: 7.507355]\n",
      "epoch:41 step:32356 [D loss: 0.212899, acc: 98.44%] [G loss: 3.572947]\n",
      "epoch:41 step:32357 [D loss: 0.087005, acc: 100.00%] [G loss: 4.804880]\n",
      "epoch:41 step:32358 [D loss: 0.796297, acc: 53.91%] [G loss: 6.883917]\n",
      "epoch:41 step:32359 [D loss: 0.487325, acc: 60.94%] [G loss: 1.561627]\n",
      "epoch:41 step:32360 [D loss: 0.175503, acc: 99.22%] [G loss: 5.408293]\n",
      "epoch:41 step:32361 [D loss: 0.350603, acc: 79.69%] [G loss: 6.579619]\n",
      "epoch:41 step:32362 [D loss: 0.061624, acc: 100.00%] [G loss: 6.450638]\n",
      "epoch:41 step:32363 [D loss: 0.374860, acc: 84.38%] [G loss: 6.423738]\n",
      "epoch:41 step:32364 [D loss: 0.210124, acc: 96.88%] [G loss: 2.484765]\n",
      "epoch:41 step:32365 [D loss: 0.450326, acc: 82.81%] [G loss: 4.278138]\n",
      "epoch:41 step:32366 [D loss: 0.133674, acc: 98.44%] [G loss: 5.425826]\n",
      "epoch:41 step:32367 [D loss: 0.434562, acc: 82.81%] [G loss: 4.674920]\n",
      "epoch:41 step:32368 [D loss: 0.358333, acc: 81.25%] [G loss: 6.513111]\n",
      "epoch:41 step:32369 [D loss: 0.026602, acc: 100.00%] [G loss: 6.329561]\n",
      "epoch:41 step:32370 [D loss: 1.164530, acc: 30.47%] [G loss: 6.036741]\n",
      "epoch:41 step:32371 [D loss: 0.271931, acc: 90.62%] [G loss: 4.030308]\n",
      "epoch:41 step:32372 [D loss: 0.064846, acc: 100.00%] [G loss: 8.884573]\n",
      "epoch:41 step:32373 [D loss: 0.012444, acc: 100.00%] [G loss: 8.078609]\n",
      "epoch:41 step:32374 [D loss: 0.013675, acc: 100.00%] [G loss: 4.383172]\n",
      "epoch:41 step:32375 [D loss: 1.001227, acc: 23.44%] [G loss: 5.459217]\n",
      "epoch:41 step:32376 [D loss: 0.567640, acc: 61.72%] [G loss: 4.395663]\n",
      "epoch:41 step:32377 [D loss: 0.454713, acc: 71.09%] [G loss: 8.300365]\n",
      "epoch:41 step:32378 [D loss: 0.075906, acc: 100.00%] [G loss: 1.182789]\n",
      "epoch:41 step:32379 [D loss: 0.220416, acc: 98.44%] [G loss: 9.126170]\n",
      "epoch:41 step:32380 [D loss: 0.392749, acc: 71.88%] [G loss: 6.717397]\n",
      "epoch:41 step:32381 [D loss: 1.451896, acc: 50.78%] [G loss: 3.510960]\n",
      "epoch:41 step:32382 [D loss: 0.273440, acc: 89.06%] [G loss: 5.834180]\n",
      "epoch:41 step:32383 [D loss: 0.071321, acc: 100.00%] [G loss: 4.479385]\n",
      "epoch:41 step:32384 [D loss: 0.318083, acc: 85.16%] [G loss: 8.096976]\n",
      "epoch:41 step:32385 [D loss: 0.254500, acc: 92.19%] [G loss: 6.235194]\n",
      "epoch:41 step:32386 [D loss: 0.776442, acc: 53.91%] [G loss: 8.048622]\n",
      "epoch:41 step:32387 [D loss: 0.295663, acc: 93.75%] [G loss: 2.888185]\n",
      "epoch:41 step:32388 [D loss: 0.523638, acc: 61.72%] [G loss: 6.097703]\n",
      "epoch:41 step:32389 [D loss: 0.492670, acc: 64.06%] [G loss: 8.949907]\n",
      "epoch:41 step:32390 [D loss: 0.897321, acc: 51.56%] [G loss: 8.941448]\n",
      "epoch:41 step:32391 [D loss: 0.136765, acc: 98.44%] [G loss: 2.566228]\n",
      "epoch:41 step:32392 [D loss: 0.814713, acc: 51.56%] [G loss: 3.986321]\n",
      "epoch:41 step:32393 [D loss: 0.223489, acc: 92.97%] [G loss: 4.634450]\n",
      "epoch:41 step:32394 [D loss: 0.127949, acc: 99.22%] [G loss: 4.617574]\n",
      "epoch:41 step:32395 [D loss: 0.396109, acc: 78.91%] [G loss: 6.092914]\n",
      "epoch:41 step:32396 [D loss: 0.495104, acc: 67.19%] [G loss: 4.651830]\n",
      "epoch:41 step:32397 [D loss: 1.270357, acc: 50.00%] [G loss: 9.386087]\n",
      "epoch:41 step:32398 [D loss: 0.072582, acc: 100.00%] [G loss: 7.649934]\n",
      "epoch:41 step:32399 [D loss: 0.589315, acc: 62.50%] [G loss: 5.136502]\n",
      "epoch:41 step:32400 [D loss: 0.056381, acc: 100.00%] [G loss: 4.261373]\n",
      "epoch:41 step:32401 [D loss: 0.353476, acc: 76.56%] [G loss: 6.630597]\n",
      "epoch:41 step:32402 [D loss: 0.320621, acc: 91.41%] [G loss: 5.436459]\n",
      "epoch:41 step:32403 [D loss: 0.134831, acc: 98.44%] [G loss: 5.036002]\n",
      "epoch:41 step:32404 [D loss: 1.199687, acc: 45.31%] [G loss: 3.488357]\n",
      "epoch:41 step:32405 [D loss: 0.153517, acc: 99.22%] [G loss: 4.818362]\n",
      "epoch:41 step:32406 [D loss: 0.072728, acc: 100.00%] [G loss: 1.863893]\n",
      "epoch:41 step:32407 [D loss: 0.137687, acc: 96.88%] [G loss: 5.287926]\n",
      "epoch:41 step:32408 [D loss: 0.276906, acc: 88.28%] [G loss: 4.803590]\n",
      "epoch:41 step:32409 [D loss: 0.325828, acc: 89.84%] [G loss: 8.311949]\n",
      "epoch:41 step:32410 [D loss: 0.166260, acc: 100.00%] [G loss: 3.688602]\n",
      "epoch:41 step:32411 [D loss: 0.242417, acc: 96.09%] [G loss: 5.906458]\n",
      "epoch:41 step:32412 [D loss: 0.302350, acc: 93.75%] [G loss: 5.728096]\n",
      "epoch:41 step:32413 [D loss: 0.076754, acc: 100.00%] [G loss: 6.948231]\n",
      "epoch:41 step:32414 [D loss: 0.688027, acc: 57.03%] [G loss: 5.968190]\n",
      "epoch:41 step:32415 [D loss: 1.370182, acc: 11.72%] [G loss: 9.459146]\n",
      "epoch:41 step:32416 [D loss: 0.446763, acc: 71.88%] [G loss: 5.773057]\n",
      "epoch:41 step:32417 [D loss: 0.778633, acc: 50.00%] [G loss: 5.919166]\n",
      "epoch:41 step:32418 [D loss: 1.144646, acc: 50.00%] [G loss: 4.737568]\n",
      "epoch:41 step:32419 [D loss: 0.135163, acc: 98.44%] [G loss: 4.074490]\n",
      "epoch:41 step:32420 [D loss: 0.057117, acc: 99.22%] [G loss: 3.462649]\n",
      "epoch:41 step:32421 [D loss: 0.480019, acc: 75.78%] [G loss: 5.221747]\n",
      "epoch:41 step:32422 [D loss: 0.079169, acc: 100.00%] [G loss: 6.955902]\n",
      "epoch:41 step:32423 [D loss: 0.206405, acc: 94.53%] [G loss: 7.592888]\n",
      "epoch:41 step:32424 [D loss: 0.442537, acc: 88.28%] [G loss: 4.784211]\n",
      "epoch:41 step:32425 [D loss: 0.338065, acc: 90.62%] [G loss: 5.181397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32426 [D loss: 0.127510, acc: 97.66%] [G loss: 5.632937]\n",
      "epoch:41 step:32427 [D loss: 0.409276, acc: 85.16%] [G loss: 5.583324]\n",
      "epoch:41 step:32428 [D loss: 0.243346, acc: 92.97%] [G loss: 6.758916]\n",
      "epoch:41 step:32429 [D loss: 0.209278, acc: 97.66%] [G loss: 2.964755]\n",
      "epoch:41 step:32430 [D loss: 0.815595, acc: 51.56%] [G loss: 6.105335]\n",
      "epoch:41 step:32431 [D loss: 0.627927, acc: 64.84%] [G loss: 4.474034]\n",
      "epoch:41 step:32432 [D loss: 1.348884, acc: 50.78%] [G loss: 4.027232]\n",
      "epoch:41 step:32433 [D loss: 0.614233, acc: 66.41%] [G loss: 4.076087]\n",
      "epoch:41 step:32434 [D loss: 0.269666, acc: 90.62%] [G loss: 8.643595]\n",
      "epoch:41 step:32435 [D loss: 0.426693, acc: 86.72%] [G loss: 5.099882]\n",
      "epoch:41 step:32436 [D loss: 0.074241, acc: 99.22%] [G loss: 6.285770]\n",
      "epoch:41 step:32437 [D loss: 0.606284, acc: 58.59%] [G loss: 3.549795]\n",
      "epoch:41 step:32438 [D loss: 0.041353, acc: 100.00%] [G loss: 5.573778]\n",
      "epoch:41 step:32439 [D loss: 0.150624, acc: 98.44%] [G loss: 4.811725]\n",
      "epoch:41 step:32440 [D loss: 0.177612, acc: 96.09%] [G loss: 6.772534]\n",
      "epoch:41 step:32441 [D loss: 0.233138, acc: 97.66%] [G loss: 4.570083]\n",
      "epoch:41 step:32442 [D loss: 0.767206, acc: 56.25%] [G loss: 4.086667]\n",
      "epoch:41 step:32443 [D loss: 0.303936, acc: 83.59%] [G loss: 4.646599]\n",
      "epoch:41 step:32444 [D loss: 0.986277, acc: 45.31%] [G loss: 3.787681]\n",
      "epoch:41 step:32445 [D loss: 0.463604, acc: 71.88%] [G loss: 8.225214]\n",
      "epoch:41 step:32446 [D loss: 0.181900, acc: 99.22%] [G loss: 5.386266]\n",
      "epoch:41 step:32447 [D loss: 0.197326, acc: 99.22%] [G loss: 4.597937]\n",
      "epoch:41 step:32448 [D loss: 1.107658, acc: 43.75%] [G loss: 6.688518]\n",
      "epoch:41 step:32449 [D loss: 0.045091, acc: 100.00%] [G loss: 6.004985]\n",
      "epoch:41 step:32450 [D loss: 0.153933, acc: 99.22%] [G loss: 6.326957]\n",
      "epoch:41 step:32451 [D loss: 0.021771, acc: 100.00%] [G loss: 6.032871]\n",
      "epoch:41 step:32452 [D loss: 0.769619, acc: 52.34%] [G loss: 3.235181]\n",
      "epoch:41 step:32453 [D loss: 0.195904, acc: 97.66%] [G loss: 5.755619]\n",
      "epoch:41 step:32454 [D loss: 0.080743, acc: 100.00%] [G loss: 3.501678]\n",
      "epoch:41 step:32455 [D loss: 0.403767, acc: 81.25%] [G loss: 10.046368]\n",
      "epoch:41 step:32456 [D loss: 0.201730, acc: 96.88%] [G loss: 5.072424]\n",
      "epoch:41 step:32457 [D loss: 0.103188, acc: 100.00%] [G loss: 5.665665]\n",
      "epoch:41 step:32458 [D loss: 0.754666, acc: 50.78%] [G loss: 5.893921]\n",
      "epoch:41 step:32459 [D loss: 0.040778, acc: 100.00%] [G loss: 6.606948]\n",
      "epoch:41 step:32460 [D loss: 1.233706, acc: 43.75%] [G loss: 6.392060]\n",
      "epoch:41 step:32461 [D loss: 0.178532, acc: 99.22%] [G loss: 2.580367]\n",
      "epoch:41 step:32462 [D loss: 0.656191, acc: 60.16%] [G loss: 7.650406]\n",
      "epoch:41 step:32463 [D loss: 0.177622, acc: 98.44%] [G loss: 4.842427]\n",
      "epoch:41 step:32464 [D loss: 0.110547, acc: 100.00%] [G loss: 4.161381]\n",
      "epoch:41 step:32465 [D loss: 0.195003, acc: 99.22%] [G loss: 1.821757]\n",
      "epoch:41 step:32466 [D loss: 0.876495, acc: 45.31%] [G loss: 5.880278]\n",
      "epoch:41 step:32467 [D loss: 0.697640, acc: 53.12%] [G loss: 5.571816]\n",
      "epoch:41 step:32468 [D loss: 0.451599, acc: 74.22%] [G loss: 3.973359]\n",
      "epoch:41 step:32469 [D loss: 0.109129, acc: 100.00%] [G loss: 4.687586]\n",
      "epoch:41 step:32470 [D loss: 1.121296, acc: 48.44%] [G loss: 7.601110]\n",
      "epoch:41 step:32471 [D loss: 0.257777, acc: 90.62%] [G loss: 7.332365]\n",
      "epoch:41 step:32472 [D loss: 0.553637, acc: 71.09%] [G loss: 2.672711]\n",
      "epoch:41 step:32473 [D loss: 0.160066, acc: 97.66%] [G loss: 3.926529]\n",
      "epoch:41 step:32474 [D loss: 0.054243, acc: 99.22%] [G loss: 5.836410]\n",
      "epoch:41 step:32475 [D loss: 1.056254, acc: 50.78%] [G loss: 5.498176]\n",
      "epoch:41 step:32476 [D loss: 0.737908, acc: 53.91%] [G loss: 7.756941]\n",
      "epoch:41 step:32477 [D loss: 0.160703, acc: 99.22%] [G loss: 5.153719]\n",
      "epoch:41 step:32478 [D loss: 1.745526, acc: 4.69%] [G loss: 8.039303]\n",
      "epoch:41 step:32479 [D loss: 0.114166, acc: 98.44%] [G loss: 4.392610]\n",
      "epoch:41 step:32480 [D loss: 0.164912, acc: 96.09%] [G loss: 2.747242]\n",
      "epoch:41 step:32481 [D loss: 0.520466, acc: 64.06%] [G loss: 6.747243]\n",
      "epoch:41 step:32482 [D loss: 0.127521, acc: 100.00%] [G loss: 4.277452]\n",
      "epoch:41 step:32483 [D loss: 0.209495, acc: 96.88%] [G loss: 5.200305]\n",
      "epoch:41 step:32484 [D loss: 0.349936, acc: 92.19%] [G loss: 5.419812]\n",
      "epoch:41 step:32485 [D loss: 0.146865, acc: 97.66%] [G loss: 6.257333]\n",
      "epoch:41 step:32486 [D loss: 0.369675, acc: 88.28%] [G loss: 7.615616]\n",
      "epoch:41 step:32487 [D loss: 0.011996, acc: 100.00%] [G loss: 6.243413]\n",
      "epoch:41 step:32488 [D loss: 0.319165, acc: 85.94%] [G loss: 3.781927]\n",
      "epoch:41 step:32489 [D loss: 0.232122, acc: 96.09%] [G loss: 5.248732]\n",
      "epoch:41 step:32490 [D loss: 0.537037, acc: 63.28%] [G loss: 6.674778]\n",
      "epoch:41 step:32491 [D loss: 0.687297, acc: 58.59%] [G loss: 6.087238]\n",
      "epoch:41 step:32492 [D loss: 0.260739, acc: 91.41%] [G loss: 6.116043]\n",
      "epoch:41 step:32493 [D loss: 0.156220, acc: 96.88%] [G loss: 5.179408]\n",
      "epoch:41 step:32494 [D loss: 0.932535, acc: 45.31%] [G loss: 4.433015]\n",
      "epoch:41 step:32495 [D loss: 0.223436, acc: 95.31%] [G loss: 4.161777]\n",
      "epoch:41 step:32496 [D loss: 1.073783, acc: 26.56%] [G loss: 4.788509]\n",
      "epoch:41 step:32497 [D loss: 0.544829, acc: 61.72%] [G loss: 8.224489]\n",
      "epoch:41 step:32498 [D loss: 0.103435, acc: 99.22%] [G loss: 3.819532]\n",
      "epoch:41 step:32499 [D loss: 0.229848, acc: 92.19%] [G loss: 4.239969]\n",
      "epoch:41 step:32500 [D loss: 1.170127, acc: 50.00%] [G loss: 4.456997]\n",
      "epoch:41 step:32501 [D loss: 0.940878, acc: 33.59%] [G loss: 4.808988]\n",
      "epoch:41 step:32502 [D loss: 0.355923, acc: 76.56%] [G loss: 4.575294]\n",
      "epoch:41 step:32503 [D loss: 0.257680, acc: 89.06%] [G loss: 4.934766]\n",
      "epoch:41 step:32504 [D loss: 0.360728, acc: 89.84%] [G loss: 4.754591]\n",
      "epoch:41 step:32505 [D loss: 0.097164, acc: 100.00%] [G loss: 4.411865]\n",
      "epoch:41 step:32506 [D loss: 0.224614, acc: 98.44%] [G loss: 2.635464]\n",
      "epoch:41 step:32507 [D loss: 0.306009, acc: 91.41%] [G loss: 4.930506]\n",
      "epoch:41 step:32508 [D loss: 0.099130, acc: 97.66%] [G loss: 5.960183]\n",
      "epoch:41 step:32509 [D loss: 0.455479, acc: 83.59%] [G loss: 9.235606]\n",
      "epoch:41 step:32510 [D loss: 0.084308, acc: 100.00%] [G loss: 3.993665]\n",
      "epoch:41 step:32511 [D loss: 0.456685, acc: 67.97%] [G loss: 8.833658]\n",
      "epoch:41 step:32512 [D loss: 0.256184, acc: 97.66%] [G loss: 3.947581]\n",
      "epoch:41 step:32513 [D loss: 0.144242, acc: 100.00%] [G loss: 5.362338]\n",
      "epoch:41 step:32514 [D loss: 0.021215, acc: 100.00%] [G loss: 4.144922]\n",
      "epoch:41 step:32515 [D loss: 0.192807, acc: 98.44%] [G loss: 7.618660]\n",
      "epoch:41 step:32516 [D loss: 0.127440, acc: 99.22%] [G loss: 5.574244]\n",
      "epoch:41 step:32517 [D loss: 0.191200, acc: 98.44%] [G loss: 4.424962]\n",
      "epoch:41 step:32518 [D loss: 0.059327, acc: 100.00%] [G loss: 5.921557]\n",
      "epoch:41 step:32519 [D loss: 0.673112, acc: 60.94%] [G loss: 6.061930]\n",
      "epoch:41 step:32520 [D loss: 0.672577, acc: 53.12%] [G loss: 5.399969]\n",
      "epoch:41 step:32521 [D loss: 0.396332, acc: 86.72%] [G loss: 5.063689]\n",
      "epoch:41 step:32522 [D loss: 0.927947, acc: 35.16%] [G loss: 6.161652]\n",
      "epoch:41 step:32523 [D loss: 0.285669, acc: 93.75%] [G loss: 6.165999]\n",
      "epoch:41 step:32524 [D loss: 0.359886, acc: 85.94%] [G loss: 7.220769]\n",
      "epoch:41 step:32525 [D loss: 0.166307, acc: 99.22%] [G loss: 6.721767]\n",
      "epoch:41 step:32526 [D loss: 0.184894, acc: 99.22%] [G loss: 2.116514]\n",
      "epoch:41 step:32527 [D loss: 0.379753, acc: 78.12%] [G loss: 6.669884]\n",
      "epoch:41 step:32528 [D loss: 0.614667, acc: 63.28%] [G loss: 2.833431]\n",
      "epoch:41 step:32529 [D loss: 0.372290, acc: 78.91%] [G loss: 5.201886]\n",
      "epoch:41 step:32530 [D loss: 0.699035, acc: 54.69%] [G loss: 4.631823]\n",
      "epoch:41 step:32531 [D loss: 0.314775, acc: 90.62%] [G loss: 4.554845]\n",
      "epoch:41 step:32532 [D loss: 0.003938, acc: 100.00%] [G loss: 9.220640]\n",
      "epoch:41 step:32533 [D loss: 0.319949, acc: 85.94%] [G loss: 3.109631]\n",
      "epoch:41 step:32534 [D loss: 0.472430, acc: 75.00%] [G loss: 5.923499]\n",
      "epoch:41 step:32535 [D loss: 0.019631, acc: 100.00%] [G loss: 7.467713]\n",
      "epoch:41 step:32536 [D loss: 0.346903, acc: 79.69%] [G loss: 4.997849]\n",
      "epoch:41 step:32537 [D loss: 0.124818, acc: 99.22%] [G loss: 5.606854]\n",
      "epoch:41 step:32538 [D loss: 0.131029, acc: 98.44%] [G loss: 5.395459]\n",
      "epoch:41 step:32539 [D loss: 0.113730, acc: 99.22%] [G loss: 5.421672]\n",
      "epoch:41 step:32540 [D loss: 0.815775, acc: 43.75%] [G loss: 5.352812]\n",
      "epoch:41 step:32541 [D loss: 0.077123, acc: 99.22%] [G loss: 4.590683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32542 [D loss: 0.119467, acc: 100.00%] [G loss: 5.405648]\n",
      "epoch:41 step:32543 [D loss: 0.961900, acc: 46.09%] [G loss: 7.142945]\n",
      "epoch:41 step:32544 [D loss: 0.060538, acc: 100.00%] [G loss: 4.754980]\n",
      "epoch:41 step:32545 [D loss: 0.162057, acc: 100.00%] [G loss: 3.645761]\n",
      "epoch:41 step:32546 [D loss: 0.601059, acc: 61.72%] [G loss: 3.030969]\n",
      "epoch:41 step:32547 [D loss: 0.202069, acc: 96.88%] [G loss: 7.797576]\n",
      "epoch:41 step:32548 [D loss: 0.022858, acc: 100.00%] [G loss: 3.320005]\n",
      "epoch:41 step:32549 [D loss: 0.572881, acc: 71.09%] [G loss: 6.783851]\n",
      "epoch:41 step:32550 [D loss: 0.525508, acc: 78.12%] [G loss: 4.838368]\n",
      "epoch:41 step:32551 [D loss: 0.088636, acc: 100.00%] [G loss: 7.479855]\n",
      "epoch:41 step:32552 [D loss: 0.298794, acc: 88.28%] [G loss: 5.659054]\n",
      "epoch:41 step:32553 [D loss: 0.303708, acc: 84.38%] [G loss: 4.725464]\n",
      "epoch:41 step:32554 [D loss: 0.389629, acc: 77.34%] [G loss: 5.743950]\n",
      "epoch:41 step:32555 [D loss: 0.098702, acc: 100.00%] [G loss: 4.479320]\n",
      "epoch:41 step:32556 [D loss: 0.381439, acc: 82.81%] [G loss: 4.727510]\n",
      "epoch:41 step:32557 [D loss: 0.176200, acc: 96.88%] [G loss: 3.959999]\n",
      "epoch:41 step:32558 [D loss: 0.298839, acc: 92.19%] [G loss: 8.436638]\n",
      "epoch:41 step:32559 [D loss: 0.441446, acc: 86.72%] [G loss: 6.269809]\n",
      "epoch:41 step:32560 [D loss: 0.291269, acc: 87.50%] [G loss: 5.073298]\n",
      "epoch:41 step:32561 [D loss: 0.316646, acc: 92.97%] [G loss: 6.136003]\n",
      "epoch:41 step:32562 [D loss: 0.052513, acc: 100.00%] [G loss: 5.591092]\n",
      "epoch:41 step:32563 [D loss: 0.111817, acc: 98.44%] [G loss: 7.002514]\n",
      "epoch:41 step:32564 [D loss: 0.576531, acc: 67.19%] [G loss: 2.633699]\n",
      "epoch:41 step:32565 [D loss: 0.266675, acc: 91.41%] [G loss: 4.663609]\n",
      "epoch:41 step:32566 [D loss: 0.935209, acc: 46.09%] [G loss: 5.718408]\n",
      "epoch:41 step:32567 [D loss: 0.352026, acc: 80.47%] [G loss: 2.940376]\n",
      "epoch:41 step:32568 [D loss: 0.068717, acc: 100.00%] [G loss: 4.643107]\n",
      "epoch:41 step:32569 [D loss: 0.361025, acc: 90.62%] [G loss: 4.966105]\n",
      "epoch:41 step:32570 [D loss: 0.327260, acc: 86.72%] [G loss: 4.589668]\n",
      "epoch:41 step:32571 [D loss: 0.388964, acc: 81.25%] [G loss: 4.372900]\n",
      "epoch:41 step:32572 [D loss: 0.039218, acc: 100.00%] [G loss: 3.369697]\n",
      "epoch:41 step:32573 [D loss: 0.117023, acc: 100.00%] [G loss: 5.211462]\n",
      "epoch:41 step:32574 [D loss: 0.039947, acc: 100.00%] [G loss: 7.118532]\n",
      "epoch:41 step:32575 [D loss: 0.084908, acc: 100.00%] [G loss: 3.296477]\n",
      "epoch:41 step:32576 [D loss: 0.117208, acc: 99.22%] [G loss: 6.947251]\n",
      "epoch:41 step:32577 [D loss: 0.157452, acc: 100.00%] [G loss: 5.528319]\n",
      "epoch:41 step:32578 [D loss: 1.216121, acc: 13.28%] [G loss: 9.336526]\n",
      "epoch:41 step:32579 [D loss: 0.703892, acc: 53.91%] [G loss: 9.978975]\n",
      "epoch:41 step:32580 [D loss: 0.027353, acc: 100.00%] [G loss: 4.004605]\n",
      "epoch:41 step:32581 [D loss: 1.005468, acc: 50.00%] [G loss: 3.049410]\n",
      "epoch:41 step:32582 [D loss: 0.230408, acc: 96.88%] [G loss: 3.960006]\n",
      "epoch:41 step:32583 [D loss: 0.430454, acc: 75.00%] [G loss: 4.639973]\n",
      "epoch:41 step:32584 [D loss: 0.158601, acc: 99.22%] [G loss: 3.522957]\n",
      "epoch:41 step:32585 [D loss: 0.155848, acc: 100.00%] [G loss: 4.668610]\n",
      "epoch:41 step:32586 [D loss: 0.238318, acc: 92.19%] [G loss: 4.263186]\n",
      "epoch:41 step:32587 [D loss: 0.357420, acc: 88.28%] [G loss: 6.118649]\n",
      "epoch:41 step:32588 [D loss: 0.214909, acc: 93.75%] [G loss: 5.636230]\n",
      "epoch:41 step:32589 [D loss: 0.142704, acc: 98.44%] [G loss: 5.007626]\n",
      "epoch:41 step:32590 [D loss: 0.072281, acc: 99.22%] [G loss: 5.239220]\n",
      "epoch:41 step:32591 [D loss: 0.497245, acc: 71.09%] [G loss: 7.286254]\n",
      "epoch:41 step:32592 [D loss: 0.085311, acc: 100.00%] [G loss: 5.622726]\n",
      "epoch:41 step:32593 [D loss: 0.143027, acc: 100.00%] [G loss: 6.323087]\n",
      "epoch:41 step:32594 [D loss: 0.032420, acc: 100.00%] [G loss: 6.340424]\n",
      "epoch:41 step:32595 [D loss: 0.755193, acc: 53.12%] [G loss: 7.105169]\n",
      "epoch:41 step:32596 [D loss: 1.692614, acc: 50.00%] [G loss: 3.228924]\n",
      "epoch:41 step:32597 [D loss: 0.205692, acc: 98.44%] [G loss: 5.210947]\n",
      "epoch:41 step:32598 [D loss: 0.421289, acc: 73.44%] [G loss: 6.192088]\n",
      "epoch:41 step:32599 [D loss: 0.055946, acc: 99.22%] [G loss: 7.003660]\n",
      "epoch:41 step:32600 [D loss: 0.318153, acc: 83.59%] [G loss: 7.696325]\n",
      "epoch:41 step:32601 [D loss: 0.573918, acc: 65.62%] [G loss: 9.136385]\n",
      "epoch:41 step:32602 [D loss: 0.042482, acc: 100.00%] [G loss: 6.351433]\n",
      "epoch:41 step:32603 [D loss: 0.027736, acc: 100.00%] [G loss: 6.696196]\n",
      "epoch:41 step:32604 [D loss: 0.394752, acc: 84.38%] [G loss: 5.231481]\n",
      "epoch:41 step:32605 [D loss: 1.478226, acc: 41.41%] [G loss: 7.334637]\n",
      "epoch:41 step:32606 [D loss: 0.361274, acc: 77.34%] [G loss: 6.970185]\n",
      "epoch:41 step:32607 [D loss: 0.746516, acc: 53.12%] [G loss: 4.978253]\n",
      "epoch:41 step:32608 [D loss: 0.027568, acc: 100.00%] [G loss: 8.119546]\n",
      "epoch:41 step:32609 [D loss: 0.144282, acc: 98.44%] [G loss: 6.200557]\n",
      "epoch:41 step:32610 [D loss: 0.039454, acc: 100.00%] [G loss: 4.640258]\n",
      "epoch:41 step:32611 [D loss: 0.887442, acc: 50.78%] [G loss: 5.712432]\n",
      "epoch:41 step:32612 [D loss: 1.362326, acc: 41.41%] [G loss: 4.648777]\n",
      "epoch:41 step:32613 [D loss: 0.970391, acc: 38.28%] [G loss: 6.145082]\n",
      "epoch:41 step:32614 [D loss: 0.046576, acc: 99.22%] [G loss: 4.551830]\n",
      "epoch:41 step:32615 [D loss: 0.153820, acc: 99.22%] [G loss: 5.760882]\n",
      "epoch:41 step:32616 [D loss: 1.053138, acc: 26.56%] [G loss: 7.919493]\n",
      "epoch:41 step:32617 [D loss: 0.087801, acc: 100.00%] [G loss: 6.763604]\n",
      "epoch:41 step:32618 [D loss: 0.104642, acc: 100.00%] [G loss: 7.471256]\n",
      "epoch:41 step:32619 [D loss: 1.479224, acc: 37.50%] [G loss: 5.200812]\n",
      "epoch:41 step:32620 [D loss: 0.679919, acc: 56.25%] [G loss: 3.126936]\n",
      "epoch:41 step:32621 [D loss: 0.202683, acc: 96.88%] [G loss: 4.378120]\n",
      "epoch:41 step:32622 [D loss: 0.573253, acc: 58.59%] [G loss: 5.133295]\n",
      "epoch:41 step:32623 [D loss: 0.517100, acc: 69.53%] [G loss: 4.607169]\n",
      "epoch:41 step:32624 [D loss: 0.208493, acc: 95.31%] [G loss: 4.160867]\n",
      "epoch:41 step:32625 [D loss: 0.625474, acc: 62.50%] [G loss: 5.773716]\n",
      "epoch:41 step:32626 [D loss: 0.497400, acc: 79.69%] [G loss: 4.737749]\n",
      "epoch:41 step:32627 [D loss: 0.182444, acc: 98.44%] [G loss: 6.404054]\n",
      "epoch:41 step:32628 [D loss: 0.143803, acc: 99.22%] [G loss: 5.474884]\n",
      "epoch:41 step:32629 [D loss: 0.172181, acc: 98.44%] [G loss: 4.567940]\n",
      "epoch:41 step:32630 [D loss: 0.664818, acc: 55.47%] [G loss: 6.968442]\n",
      "epoch:41 step:32631 [D loss: 0.270423, acc: 94.53%] [G loss: 4.210436]\n",
      "epoch:41 step:32632 [D loss: 0.285036, acc: 86.72%] [G loss: 7.156289]\n",
      "epoch:41 step:32633 [D loss: 0.401999, acc: 86.72%] [G loss: 2.890201]\n",
      "epoch:41 step:32634 [D loss: 0.235783, acc: 93.75%] [G loss: 7.197538]\n",
      "epoch:41 step:32635 [D loss: 0.211663, acc: 98.44%] [G loss: 8.029927]\n",
      "epoch:41 step:32636 [D loss: 0.102229, acc: 100.00%] [G loss: 4.020826]\n",
      "epoch:41 step:32637 [D loss: 0.221452, acc: 92.97%] [G loss: 7.160573]\n",
      "epoch:41 step:32638 [D loss: 0.684298, acc: 57.81%] [G loss: 4.898836]\n",
      "epoch:41 step:32639 [D loss: 0.617521, acc: 57.03%] [G loss: 8.991554]\n",
      "epoch:41 step:32640 [D loss: 0.146816, acc: 99.22%] [G loss: 4.520908]\n",
      "epoch:41 step:32641 [D loss: 1.339160, acc: 40.62%] [G loss: 6.145529]\n",
      "epoch:41 step:32642 [D loss: 0.311566, acc: 82.03%] [G loss: 5.326223]\n",
      "epoch:41 step:32643 [D loss: 0.956875, acc: 53.12%] [G loss: 3.502108]\n",
      "epoch:41 step:32644 [D loss: 0.444119, acc: 85.16%] [G loss: 8.940622]\n",
      "epoch:41 step:32645 [D loss: 0.018063, acc: 100.00%] [G loss: 7.321859]\n",
      "epoch:41 step:32646 [D loss: 0.085123, acc: 100.00%] [G loss: 4.634311]\n",
      "epoch:41 step:32647 [D loss: 0.097685, acc: 99.22%] [G loss: 5.002171]\n",
      "epoch:41 step:32648 [D loss: 0.350100, acc: 85.94%] [G loss: 3.653432]\n",
      "epoch:41 step:32649 [D loss: 0.741149, acc: 53.91%] [G loss: 6.259045]\n",
      "epoch:41 step:32650 [D loss: 0.399041, acc: 90.62%] [G loss: 7.009013]\n",
      "epoch:41 step:32651 [D loss: 0.255334, acc: 89.06%] [G loss: 7.564159]\n",
      "epoch:41 step:32652 [D loss: 0.647529, acc: 64.06%] [G loss: 5.049914]\n",
      "epoch:41 step:32653 [D loss: 0.216623, acc: 97.66%] [G loss: 5.242824]\n",
      "epoch:41 step:32654 [D loss: 0.213277, acc: 96.88%] [G loss: 5.247864]\n",
      "epoch:41 step:32655 [D loss: 0.662847, acc: 60.16%] [G loss: 3.238318]\n",
      "epoch:41 step:32656 [D loss: 0.553024, acc: 65.62%] [G loss: 6.340875]\n",
      "epoch:41 step:32657 [D loss: 0.059382, acc: 100.00%] [G loss: 8.460199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32658 [D loss: 0.206233, acc: 97.66%] [G loss: 3.308882]\n",
      "epoch:41 step:32659 [D loss: 0.109664, acc: 99.22%] [G loss: 4.621581]\n",
      "epoch:41 step:32660 [D loss: 0.163974, acc: 99.22%] [G loss: 4.237399]\n",
      "epoch:41 step:32661 [D loss: 0.096952, acc: 100.00%] [G loss: 4.258240]\n",
      "epoch:41 step:32662 [D loss: 0.525531, acc: 65.62%] [G loss: 3.118251]\n",
      "epoch:41 step:32663 [D loss: 0.186318, acc: 95.31%] [G loss: 7.444442]\n",
      "epoch:41 step:32664 [D loss: 0.371108, acc: 81.25%] [G loss: 4.993699]\n",
      "epoch:41 step:32665 [D loss: 0.103018, acc: 100.00%] [G loss: 4.446619]\n",
      "epoch:41 step:32666 [D loss: 0.136393, acc: 99.22%] [G loss: 6.667828]\n",
      "epoch:41 step:32667 [D loss: 0.398826, acc: 85.16%] [G loss: 2.863363]\n",
      "epoch:41 step:32668 [D loss: 0.308604, acc: 86.72%] [G loss: 6.717130]\n",
      "epoch:41 step:32669 [D loss: 0.831363, acc: 50.78%] [G loss: 5.436490]\n",
      "epoch:41 step:32670 [D loss: 0.175962, acc: 97.66%] [G loss: 4.519941]\n",
      "epoch:41 step:32671 [D loss: 0.078652, acc: 100.00%] [G loss: 7.930217]\n",
      "epoch:41 step:32672 [D loss: 0.248708, acc: 94.53%] [G loss: 7.713831]\n",
      "epoch:41 step:32673 [D loss: 0.235717, acc: 93.75%] [G loss: 3.656572]\n",
      "epoch:41 step:32674 [D loss: 0.207407, acc: 96.88%] [G loss: 5.403846]\n",
      "epoch:41 step:32675 [D loss: 0.054445, acc: 100.00%] [G loss: 4.317952]\n",
      "epoch:41 step:32676 [D loss: 0.150389, acc: 99.22%] [G loss: 4.429277]\n",
      "epoch:41 step:32677 [D loss: 0.161910, acc: 99.22%] [G loss: 2.621110]\n",
      "epoch:41 step:32678 [D loss: 0.190616, acc: 97.66%] [G loss: 4.780753]\n",
      "epoch:41 step:32679 [D loss: 0.300456, acc: 90.62%] [G loss: 6.645008]\n",
      "epoch:41 step:32680 [D loss: 0.037429, acc: 100.00%] [G loss: 6.965387]\n",
      "epoch:41 step:32681 [D loss: 0.064973, acc: 100.00%] [G loss: 5.344206]\n",
      "epoch:41 step:32682 [D loss: 0.762137, acc: 49.22%] [G loss: 3.550317]\n",
      "epoch:41 step:32683 [D loss: 0.186259, acc: 97.66%] [G loss: 4.537232]\n",
      "epoch:41 step:32684 [D loss: 0.306440, acc: 96.09%] [G loss: 6.149953]\n",
      "epoch:41 step:32685 [D loss: 0.767314, acc: 55.47%] [G loss: 5.750467]\n",
      "epoch:41 step:32686 [D loss: 0.350675, acc: 81.25%] [G loss: 4.295102]\n",
      "epoch:41 step:32687 [D loss: 0.085787, acc: 100.00%] [G loss: 5.099654]\n",
      "epoch:41 step:32688 [D loss: 0.580012, acc: 71.09%] [G loss: 5.596169]\n",
      "epoch:41 step:32689 [D loss: 0.032319, acc: 100.00%] [G loss: 3.531948]\n",
      "epoch:41 step:32690 [D loss: 0.894515, acc: 49.22%] [G loss: 6.941581]\n",
      "epoch:41 step:32691 [D loss: 0.785655, acc: 50.00%] [G loss: 5.298743]\n",
      "epoch:41 step:32692 [D loss: 0.055048, acc: 100.00%] [G loss: 4.185450]\n",
      "epoch:41 step:32693 [D loss: 0.403640, acc: 72.66%] [G loss: 5.272424]\n",
      "epoch:41 step:32694 [D loss: 0.043843, acc: 100.00%] [G loss: 5.495563]\n",
      "epoch:41 step:32695 [D loss: 1.023109, acc: 50.00%] [G loss: 5.232608]\n",
      "epoch:41 step:32696 [D loss: 0.340691, acc: 87.50%] [G loss: 3.176630]\n",
      "epoch:41 step:32697 [D loss: 0.114723, acc: 99.22%] [G loss: 7.635861]\n",
      "epoch:41 step:32698 [D loss: 0.408104, acc: 75.00%] [G loss: 8.339783]\n",
      "epoch:41 step:32699 [D loss: 0.163015, acc: 98.44%] [G loss: 4.933805]\n",
      "epoch:41 step:32700 [D loss: 0.024667, acc: 100.00%] [G loss: 5.338535]\n",
      "epoch:41 step:32701 [D loss: 0.298710, acc: 89.06%] [G loss: 4.117751]\n",
      "epoch:41 step:32702 [D loss: 0.104411, acc: 98.44%] [G loss: 4.003153]\n",
      "epoch:41 step:32703 [D loss: 1.428996, acc: 9.38%] [G loss: 5.970457]\n",
      "epoch:41 step:32704 [D loss: 0.076426, acc: 100.00%] [G loss: 4.785953]\n",
      "epoch:41 step:32705 [D loss: 0.496028, acc: 74.22%] [G loss: 4.575859]\n",
      "epoch:41 step:32706 [D loss: 0.798062, acc: 48.44%] [G loss: 4.416141]\n",
      "epoch:41 step:32707 [D loss: 0.592545, acc: 66.41%] [G loss: 2.450266]\n",
      "epoch:41 step:32708 [D loss: 1.056630, acc: 47.66%] [G loss: 5.683659]\n",
      "epoch:41 step:32709 [D loss: 0.067893, acc: 100.00%] [G loss: 4.645013]\n",
      "epoch:41 step:32710 [D loss: 0.678475, acc: 65.62%] [G loss: 5.826375]\n",
      "epoch:41 step:32711 [D loss: 0.017584, acc: 100.00%] [G loss: 7.042939]\n",
      "epoch:41 step:32712 [D loss: 0.163526, acc: 98.44%] [G loss: 7.569902]\n",
      "epoch:41 step:32713 [D loss: 0.069925, acc: 100.00%] [G loss: 1.841363]\n",
      "epoch:41 step:32714 [D loss: 0.470001, acc: 60.94%] [G loss: 6.470872]\n",
      "epoch:41 step:32715 [D loss: 0.506933, acc: 78.12%] [G loss: 5.811193]\n",
      "epoch:41 step:32716 [D loss: 0.183602, acc: 92.97%] [G loss: 5.740109]\n",
      "epoch:41 step:32717 [D loss: 0.151522, acc: 99.22%] [G loss: 7.742213]\n",
      "epoch:41 step:32718 [D loss: 0.076983, acc: 99.22%] [G loss: 6.071772]\n",
      "epoch:41 step:32719 [D loss: 0.358802, acc: 78.91%] [G loss: 8.060536]\n",
      "epoch:41 step:32720 [D loss: 0.170216, acc: 100.00%] [G loss: 6.208665]\n",
      "epoch:41 step:32721 [D loss: 0.640629, acc: 60.94%] [G loss: 4.391269]\n",
      "epoch:41 step:32722 [D loss: 0.726714, acc: 55.47%] [G loss: 2.995391]\n",
      "epoch:41 step:32723 [D loss: 0.187098, acc: 97.66%] [G loss: 4.848599]\n",
      "epoch:41 step:32724 [D loss: 0.387090, acc: 83.59%] [G loss: 7.402477]\n",
      "epoch:41 step:32725 [D loss: 0.019361, acc: 100.00%] [G loss: 7.767527]\n",
      "epoch:41 step:32726 [D loss: 0.285205, acc: 83.59%] [G loss: 6.203326]\n",
      "epoch:41 step:32727 [D loss: 0.413036, acc: 82.81%] [G loss: 6.006675]\n",
      "epoch:41 step:32728 [D loss: 0.044171, acc: 100.00%] [G loss: 8.079550]\n",
      "epoch:41 step:32729 [D loss: 0.105919, acc: 100.00%] [G loss: 5.836244]\n",
      "epoch:41 step:32730 [D loss: 0.041926, acc: 100.00%] [G loss: 7.080057]\n",
      "epoch:41 step:32731 [D loss: 0.709215, acc: 53.12%] [G loss: 5.165132]\n",
      "epoch:41 step:32732 [D loss: 0.107035, acc: 99.22%] [G loss: 8.406916]\n",
      "epoch:41 step:32733 [D loss: 0.019830, acc: 100.00%] [G loss: 6.880732]\n",
      "epoch:41 step:32734 [D loss: 0.210802, acc: 98.44%] [G loss: 4.825385]\n",
      "epoch:41 step:32735 [D loss: 0.113499, acc: 100.00%] [G loss: 3.946913]\n",
      "epoch:41 step:32736 [D loss: 0.171435, acc: 97.66%] [G loss: 6.566634]\n",
      "epoch:41 step:32737 [D loss: 1.706317, acc: 3.91%] [G loss: 6.636972]\n",
      "epoch:41 step:32738 [D loss: 0.092785, acc: 99.22%] [G loss: 5.619735]\n",
      "epoch:41 step:32739 [D loss: 0.336201, acc: 85.94%] [G loss: 4.647521]\n",
      "epoch:41 step:32740 [D loss: 0.240921, acc: 97.66%] [G loss: 5.598627]\n",
      "epoch:41 step:32741 [D loss: 0.225358, acc: 94.53%] [G loss: 7.419893]\n",
      "epoch:41 step:32742 [D loss: 0.458691, acc: 71.09%] [G loss: 6.813600]\n",
      "epoch:41 step:32743 [D loss: 0.055234, acc: 99.22%] [G loss: 5.740999]\n",
      "epoch:41 step:32744 [D loss: 0.721700, acc: 57.03%] [G loss: 7.213558]\n",
      "epoch:41 step:32745 [D loss: 0.081820, acc: 100.00%] [G loss: 4.548153]\n",
      "epoch:41 step:32746 [D loss: 0.248830, acc: 92.19%] [G loss: 7.028787]\n",
      "epoch:41 step:32747 [D loss: 0.077712, acc: 100.00%] [G loss: 4.524785]\n",
      "epoch:41 step:32748 [D loss: 0.322748, acc: 82.03%] [G loss: 6.070388]\n",
      "epoch:41 step:32749 [D loss: 0.460613, acc: 75.00%] [G loss: 3.758534]\n",
      "epoch:41 step:32750 [D loss: 0.171259, acc: 97.66%] [G loss: 4.085602]\n",
      "epoch:41 step:32751 [D loss: 0.392538, acc: 77.34%] [G loss: 6.878716]\n",
      "epoch:41 step:32752 [D loss: 0.323477, acc: 92.19%] [G loss: 5.037964]\n",
      "epoch:41 step:32753 [D loss: 0.112289, acc: 100.00%] [G loss: 5.772792]\n",
      "epoch:41 step:32754 [D loss: 0.082437, acc: 100.00%] [G loss: 3.815346]\n",
      "epoch:41 step:32755 [D loss: 0.189399, acc: 97.66%] [G loss: 4.231101]\n",
      "epoch:41 step:32756 [D loss: 0.172686, acc: 99.22%] [G loss: 5.024107]\n",
      "epoch:41 step:32757 [D loss: 0.251123, acc: 91.41%] [G loss: 3.556397]\n",
      "epoch:41 step:32758 [D loss: 0.060134, acc: 100.00%] [G loss: 3.263479]\n",
      "epoch:41 step:32759 [D loss: 1.092634, acc: 50.00%] [G loss: 6.452223]\n",
      "epoch:41 step:32760 [D loss: 0.830388, acc: 50.78%] [G loss: 4.071162]\n",
      "epoch:41 step:32761 [D loss: 0.418925, acc: 79.69%] [G loss: 4.112150]\n",
      "epoch:41 step:32762 [D loss: 0.231437, acc: 97.66%] [G loss: 4.076566]\n",
      "epoch:41 step:32763 [D loss: 0.688535, acc: 60.16%] [G loss: 5.009630]\n",
      "epoch:41 step:32764 [D loss: 0.706281, acc: 58.59%] [G loss: 3.834937]\n",
      "epoch:41 step:32765 [D loss: 0.428994, acc: 85.16%] [G loss: 2.017419]\n",
      "epoch:41 step:32766 [D loss: 0.235506, acc: 90.62%] [G loss: 8.245214]\n",
      "epoch:41 step:32767 [D loss: 0.199567, acc: 98.44%] [G loss: 7.203092]\n",
      "epoch:41 step:32768 [D loss: 0.200368, acc: 99.22%] [G loss: 7.119316]\n",
      "epoch:41 step:32769 [D loss: 1.095324, acc: 45.31%] [G loss: 4.152359]\n",
      "epoch:41 step:32770 [D loss: 0.064304, acc: 100.00%] [G loss: 7.885850]\n",
      "epoch:41 step:32771 [D loss: 0.246586, acc: 90.62%] [G loss: 4.808543]\n",
      "epoch:41 step:32772 [D loss: 0.078879, acc: 100.00%] [G loss: 6.864135]\n",
      "epoch:41 step:32773 [D loss: 0.681995, acc: 57.03%] [G loss: 9.627975]\n",
      "epoch:41 step:32774 [D loss: 0.030177, acc: 100.00%] [G loss: 5.936579]\n",
      "epoch:41 step:32775 [D loss: 0.272588, acc: 92.97%] [G loss: 5.410546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32776 [D loss: 0.200262, acc: 96.88%] [G loss: 6.151114]\n",
      "epoch:41 step:32777 [D loss: 0.014569, acc: 100.00%] [G loss: 5.808578]\n",
      "epoch:41 step:32778 [D loss: 0.116938, acc: 100.00%] [G loss: 3.443566]\n",
      "epoch:41 step:32779 [D loss: 0.199356, acc: 99.22%] [G loss: 6.584832]\n",
      "epoch:41 step:32780 [D loss: 1.311066, acc: 47.66%] [G loss: 5.942641]\n",
      "epoch:41 step:32781 [D loss: 0.015312, acc: 100.00%] [G loss: 7.067961]\n",
      "epoch:41 step:32782 [D loss: 0.449737, acc: 71.09%] [G loss: 3.434652]\n",
      "epoch:41 step:32783 [D loss: 0.170253, acc: 97.66%] [G loss: 4.228832]\n",
      "epoch:41 step:32784 [D loss: 0.360776, acc: 89.84%] [G loss: 3.337284]\n",
      "epoch:41 step:32785 [D loss: 1.968676, acc: 5.47%] [G loss: 4.361042]\n",
      "epoch:41 step:32786 [D loss: 0.221770, acc: 92.97%] [G loss: 2.840751]\n",
      "epoch:41 step:32787 [D loss: 0.225460, acc: 92.19%] [G loss: 4.893375]\n",
      "epoch:41 step:32788 [D loss: 0.259670, acc: 96.09%] [G loss: 6.580410]\n",
      "epoch:41 step:32789 [D loss: 0.045751, acc: 100.00%] [G loss: 8.333389]\n",
      "epoch:41 step:32790 [D loss: 0.138626, acc: 100.00%] [G loss: 5.709468]\n",
      "epoch:41 step:32791 [D loss: 0.459815, acc: 67.97%] [G loss: 6.000628]\n",
      "epoch:41 step:32792 [D loss: 0.495274, acc: 70.31%] [G loss: 2.995090]\n",
      "epoch:41 step:32793 [D loss: 0.060025, acc: 100.00%] [G loss: 4.878689]\n",
      "epoch:41 step:32794 [D loss: 0.159812, acc: 96.09%] [G loss: 9.427985]\n",
      "epoch:41 step:32795 [D loss: 0.448723, acc: 87.50%] [G loss: 5.525592]\n",
      "epoch:41 step:32796 [D loss: 0.123291, acc: 98.44%] [G loss: 6.033533]\n",
      "epoch:41 step:32797 [D loss: 0.216133, acc: 96.09%] [G loss: 4.754619]\n",
      "epoch:41 step:32798 [D loss: 0.571888, acc: 66.41%] [G loss: 3.715686]\n",
      "epoch:41 step:32799 [D loss: 0.373166, acc: 85.16%] [G loss: 5.487309]\n",
      "epoch:41 step:32800 [D loss: 0.550304, acc: 75.00%] [G loss: 4.108939]\n",
      "epoch:41 step:32801 [D loss: 0.095140, acc: 100.00%] [G loss: 3.768613]\n",
      "epoch:41 step:32802 [D loss: 0.876276, acc: 36.72%] [G loss: 6.889136]\n",
      "epoch:42 step:32803 [D loss: 0.679972, acc: 53.91%] [G loss: 4.701912]\n",
      "epoch:42 step:32804 [D loss: 0.430819, acc: 71.88%] [G loss: 5.681400]\n",
      "epoch:42 step:32805 [D loss: 0.418653, acc: 82.03%] [G loss: 4.875993]\n",
      "epoch:42 step:32806 [D loss: 0.934849, acc: 50.78%] [G loss: 7.502985]\n",
      "epoch:42 step:32807 [D loss: 0.105455, acc: 100.00%] [G loss: 7.203469]\n",
      "epoch:42 step:32808 [D loss: 0.135114, acc: 98.44%] [G loss: 6.608610]\n",
      "epoch:42 step:32809 [D loss: 0.372142, acc: 76.56%] [G loss: 7.250089]\n",
      "epoch:42 step:32810 [D loss: 0.025363, acc: 100.00%] [G loss: 7.329237]\n",
      "epoch:42 step:32811 [D loss: 0.310303, acc: 94.53%] [G loss: 3.843205]\n",
      "epoch:42 step:32812 [D loss: 0.108855, acc: 100.00%] [G loss: 4.923547]\n",
      "epoch:42 step:32813 [D loss: 0.137255, acc: 99.22%] [G loss: 8.017479]\n",
      "epoch:42 step:32814 [D loss: 0.160194, acc: 97.66%] [G loss: 5.857120]\n",
      "epoch:42 step:32815 [D loss: 0.415496, acc: 88.28%] [G loss: 5.109861]\n",
      "epoch:42 step:32816 [D loss: 0.872090, acc: 35.94%] [G loss: 6.988907]\n",
      "epoch:42 step:32817 [D loss: 0.941286, acc: 39.84%] [G loss: 3.438499]\n",
      "epoch:42 step:32818 [D loss: 0.624245, acc: 57.81%] [G loss: 5.892386]\n",
      "epoch:42 step:32819 [D loss: 0.731512, acc: 52.34%] [G loss: 8.440486]\n",
      "epoch:42 step:32820 [D loss: 1.121236, acc: 50.78%] [G loss: 4.499089]\n",
      "epoch:42 step:32821 [D loss: 0.413458, acc: 75.78%] [G loss: 4.770353]\n",
      "epoch:42 step:32822 [D loss: 0.115065, acc: 99.22%] [G loss: 7.216988]\n",
      "epoch:42 step:32823 [D loss: 0.121031, acc: 99.22%] [G loss: 6.171338]\n",
      "epoch:42 step:32824 [D loss: 0.236362, acc: 89.84%] [G loss: 4.783703]\n",
      "epoch:42 step:32825 [D loss: 0.059933, acc: 100.00%] [G loss: 5.572939]\n",
      "epoch:42 step:32826 [D loss: 0.918189, acc: 33.59%] [G loss: 4.210277]\n",
      "epoch:42 step:32827 [D loss: 0.305584, acc: 90.62%] [G loss: 6.148798]\n",
      "epoch:42 step:32828 [D loss: 0.041855, acc: 99.22%] [G loss: 4.810791]\n",
      "epoch:42 step:32829 [D loss: 0.584522, acc: 55.47%] [G loss: 2.650392]\n",
      "epoch:42 step:32830 [D loss: 0.114320, acc: 97.66%] [G loss: 5.337790]\n",
      "epoch:42 step:32831 [D loss: 0.258959, acc: 96.09%] [G loss: 7.175963]\n",
      "epoch:42 step:32832 [D loss: 0.365562, acc: 87.50%] [G loss: 5.425140]\n",
      "epoch:42 step:32833 [D loss: 0.635158, acc: 60.16%] [G loss: 6.938735]\n",
      "epoch:42 step:32834 [D loss: 0.060889, acc: 100.00%] [G loss: 6.037830]\n",
      "epoch:42 step:32835 [D loss: 0.207038, acc: 92.97%] [G loss: 5.564127]\n",
      "epoch:42 step:32836 [D loss: 0.148372, acc: 99.22%] [G loss: 5.354938]\n",
      "epoch:42 step:32837 [D loss: 0.837439, acc: 52.34%] [G loss: 5.399639]\n",
      "epoch:42 step:32838 [D loss: 0.612093, acc: 62.50%] [G loss: 6.686120]\n",
      "epoch:42 step:32839 [D loss: 0.043919, acc: 100.00%] [G loss: 6.226776]\n",
      "epoch:42 step:32840 [D loss: 0.773787, acc: 50.00%] [G loss: 7.757254]\n",
      "epoch:42 step:32841 [D loss: 0.055758, acc: 100.00%] [G loss: 6.844410]\n",
      "epoch:42 step:32842 [D loss: 0.060215, acc: 100.00%] [G loss: 6.981236]\n",
      "epoch:42 step:32843 [D loss: 0.412223, acc: 82.81%] [G loss: 6.564836]\n",
      "epoch:42 step:32844 [D loss: 0.146402, acc: 99.22%] [G loss: 4.319771]\n",
      "epoch:42 step:32845 [D loss: 0.212698, acc: 96.88%] [G loss: 8.255617]\n",
      "epoch:42 step:32846 [D loss: 0.265470, acc: 95.31%] [G loss: 3.119089]\n",
      "epoch:42 step:32847 [D loss: 0.298326, acc: 85.94%] [G loss: 3.969809]\n",
      "epoch:42 step:32848 [D loss: 0.033679, acc: 100.00%] [G loss: 6.771039]\n",
      "epoch:42 step:32849 [D loss: 0.181160, acc: 97.66%] [G loss: 6.350784]\n",
      "epoch:42 step:32850 [D loss: 0.573505, acc: 70.31%] [G loss: 2.589747]\n",
      "epoch:42 step:32851 [D loss: 0.626149, acc: 63.28%] [G loss: 4.407290]\n",
      "epoch:42 step:32852 [D loss: 1.063183, acc: 39.84%] [G loss: 8.598717]\n",
      "epoch:42 step:32853 [D loss: 0.488068, acc: 75.00%] [G loss: 4.006292]\n",
      "epoch:42 step:32854 [D loss: 0.145376, acc: 100.00%] [G loss: 4.826520]\n",
      "epoch:42 step:32855 [D loss: 0.797019, acc: 51.56%] [G loss: 3.447793]\n",
      "epoch:42 step:32856 [D loss: 0.136310, acc: 100.00%] [G loss: 7.484622]\n",
      "epoch:42 step:32857 [D loss: 0.593157, acc: 63.28%] [G loss: 7.506452]\n",
      "epoch:42 step:32858 [D loss: 0.344347, acc: 92.97%] [G loss: 3.861717]\n",
      "epoch:42 step:32859 [D loss: 1.343411, acc: 21.09%] [G loss: 5.172754]\n",
      "epoch:42 step:32860 [D loss: 0.233535, acc: 97.66%] [G loss: 4.353058]\n",
      "epoch:42 step:32861 [D loss: 0.160890, acc: 98.44%] [G loss: 4.779357]\n",
      "epoch:42 step:32862 [D loss: 0.299063, acc: 82.81%] [G loss: 5.092957]\n",
      "epoch:42 step:32863 [D loss: 0.180287, acc: 97.66%] [G loss: 4.014937]\n",
      "epoch:42 step:32864 [D loss: 0.135970, acc: 98.44%] [G loss: 4.902853]\n",
      "epoch:42 step:32865 [D loss: 0.025381, acc: 100.00%] [G loss: 5.330373]\n",
      "epoch:42 step:32866 [D loss: 0.409852, acc: 82.03%] [G loss: 4.630208]\n",
      "epoch:42 step:32867 [D loss: 0.228865, acc: 97.66%] [G loss: 3.756635]\n",
      "epoch:42 step:32868 [D loss: 0.581544, acc: 58.59%] [G loss: 7.099905]\n",
      "epoch:42 step:32869 [D loss: 0.317167, acc: 86.72%] [G loss: 6.916143]\n",
      "epoch:42 step:32870 [D loss: 0.301049, acc: 86.72%] [G loss: 8.236237]\n",
      "epoch:42 step:32871 [D loss: 0.047402, acc: 100.00%] [G loss: 7.751028]\n",
      "epoch:42 step:32872 [D loss: 0.406843, acc: 81.25%] [G loss: 3.827305]\n",
      "epoch:42 step:32873 [D loss: 0.360725, acc: 82.81%] [G loss: 4.571640]\n",
      "epoch:42 step:32874 [D loss: 0.084185, acc: 100.00%] [G loss: 7.271126]\n",
      "epoch:42 step:32875 [D loss: 0.298596, acc: 85.16%] [G loss: 3.647129]\n",
      "epoch:42 step:32876 [D loss: 0.603944, acc: 67.97%] [G loss: 8.355034]\n",
      "epoch:42 step:32877 [D loss: 0.196003, acc: 96.88%] [G loss: 7.089468]\n",
      "epoch:42 step:32878 [D loss: 0.074648, acc: 100.00%] [G loss: 5.791836]\n",
      "epoch:42 step:32879 [D loss: 0.030764, acc: 100.00%] [G loss: 4.463537]\n",
      "epoch:42 step:32880 [D loss: 0.175582, acc: 99.22%] [G loss: 4.003848]\n",
      "epoch:42 step:32881 [D loss: 0.820815, acc: 46.09%] [G loss: 7.321197]\n",
      "epoch:42 step:32882 [D loss: 0.329716, acc: 85.94%] [G loss: 6.474448]\n",
      "epoch:42 step:32883 [D loss: 0.014458, acc: 100.00%] [G loss: 3.275920]\n",
      "epoch:42 step:32884 [D loss: 0.401176, acc: 88.28%] [G loss: 6.402369]\n",
      "epoch:42 step:32885 [D loss: 0.419444, acc: 79.69%] [G loss: 6.971937]\n",
      "epoch:42 step:32886 [D loss: 0.069608, acc: 100.00%] [G loss: 6.574889]\n",
      "epoch:42 step:32887 [D loss: 0.115146, acc: 97.66%] [G loss: 2.588549]\n",
      "epoch:42 step:32888 [D loss: 0.733543, acc: 56.25%] [G loss: 6.789558]\n",
      "epoch:42 step:32889 [D loss: 0.660799, acc: 64.84%] [G loss: 4.686530]\n",
      "epoch:42 step:32890 [D loss: 0.081469, acc: 100.00%] [G loss: 3.983300]\n",
      "epoch:42 step:32891 [D loss: 0.176786, acc: 95.31%] [G loss: 6.213787]\n",
      "epoch:42 step:32892 [D loss: 0.107996, acc: 100.00%] [G loss: 7.359396]\n",
      "epoch:42 step:32893 [D loss: 0.048377, acc: 100.00%] [G loss: 3.903878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:32894 [D loss: 0.253653, acc: 88.28%] [G loss: 6.417039]\n",
      "epoch:42 step:32895 [D loss: 0.210256, acc: 97.66%] [G loss: 4.128687]\n",
      "epoch:42 step:32896 [D loss: 0.077090, acc: 100.00%] [G loss: 4.386289]\n",
      "epoch:42 step:32897 [D loss: 0.577893, acc: 66.41%] [G loss: 5.660263]\n",
      "epoch:42 step:32898 [D loss: 0.464841, acc: 84.38%] [G loss: 3.636915]\n",
      "epoch:42 step:32899 [D loss: 0.164482, acc: 96.09%] [G loss: 5.952155]\n",
      "epoch:42 step:32900 [D loss: 0.204926, acc: 96.09%] [G loss: 4.754233]\n",
      "epoch:42 step:32901 [D loss: 0.062034, acc: 99.22%] [G loss: 2.967942]\n",
      "epoch:42 step:32902 [D loss: 0.085765, acc: 100.00%] [G loss: 5.011982]\n",
      "epoch:42 step:32903 [D loss: 0.716069, acc: 55.47%] [G loss: 6.593744]\n",
      "epoch:42 step:32904 [D loss: 0.130516, acc: 100.00%] [G loss: 5.933217]\n",
      "epoch:42 step:32905 [D loss: 0.511423, acc: 70.31%] [G loss: 4.684242]\n",
      "epoch:42 step:32906 [D loss: 0.063369, acc: 100.00%] [G loss: 4.306811]\n",
      "epoch:42 step:32907 [D loss: 0.159831, acc: 97.66%] [G loss: 5.113365]\n",
      "epoch:42 step:32908 [D loss: 0.131755, acc: 100.00%] [G loss: 3.914360]\n",
      "epoch:42 step:32909 [D loss: 0.144784, acc: 99.22%] [G loss: 5.847142]\n",
      "epoch:42 step:32910 [D loss: 0.880696, acc: 51.56%] [G loss: 8.147141]\n",
      "epoch:42 step:32911 [D loss: 1.285987, acc: 50.78%] [G loss: 4.681939]\n",
      "epoch:42 step:32912 [D loss: 0.155144, acc: 100.00%] [G loss: 5.147364]\n",
      "epoch:42 step:32913 [D loss: 0.182202, acc: 99.22%] [G loss: 3.569176]\n",
      "epoch:42 step:32914 [D loss: 0.404739, acc: 76.56%] [G loss: 6.255557]\n",
      "epoch:42 step:32915 [D loss: 0.407789, acc: 84.38%] [G loss: 6.197159]\n",
      "epoch:42 step:32916 [D loss: 0.419982, acc: 73.44%] [G loss: 4.137708]\n",
      "epoch:42 step:32917 [D loss: 0.148530, acc: 99.22%] [G loss: 4.770386]\n",
      "epoch:42 step:32918 [D loss: 0.038165, acc: 100.00%] [G loss: 5.805021]\n",
      "epoch:42 step:32919 [D loss: 0.520619, acc: 76.56%] [G loss: 7.840195]\n",
      "epoch:42 step:32920 [D loss: 0.208865, acc: 96.88%] [G loss: 5.453637]\n",
      "epoch:42 step:32921 [D loss: 0.068388, acc: 100.00%] [G loss: 4.760235]\n",
      "epoch:42 step:32922 [D loss: 0.863037, acc: 53.91%] [G loss: 7.880522]\n",
      "epoch:42 step:32923 [D loss: 0.068263, acc: 100.00%] [G loss: 4.890934]\n",
      "epoch:42 step:32924 [D loss: 0.125525, acc: 96.88%] [G loss: 5.596660]\n",
      "epoch:42 step:32925 [D loss: 0.222167, acc: 97.66%] [G loss: 4.542294]\n",
      "epoch:42 step:32926 [D loss: 0.680715, acc: 56.25%] [G loss: 5.058676]\n",
      "epoch:42 step:32927 [D loss: 0.092717, acc: 100.00%] [G loss: 5.152514]\n",
      "epoch:42 step:32928 [D loss: 0.587110, acc: 58.59%] [G loss: 2.952544]\n",
      "epoch:42 step:32929 [D loss: 0.953525, acc: 30.47%] [G loss: 3.819679]\n",
      "epoch:42 step:32930 [D loss: 0.122033, acc: 99.22%] [G loss: 4.829017]\n",
      "epoch:42 step:32931 [D loss: 0.808611, acc: 53.91%] [G loss: 3.693287]\n",
      "epoch:42 step:32932 [D loss: 0.172230, acc: 98.44%] [G loss: 4.407272]\n",
      "epoch:42 step:32933 [D loss: 1.104420, acc: 50.78%] [G loss: 3.963010]\n",
      "epoch:42 step:32934 [D loss: 0.056795, acc: 100.00%] [G loss: 8.085389]\n",
      "epoch:42 step:32935 [D loss: 0.048793, acc: 100.00%] [G loss: 6.033902]\n",
      "epoch:42 step:32936 [D loss: 0.310371, acc: 85.16%] [G loss: 8.941166]\n",
      "epoch:42 step:32937 [D loss: 0.415825, acc: 81.25%] [G loss: 6.851978]\n",
      "epoch:42 step:32938 [D loss: 0.124574, acc: 99.22%] [G loss: 2.999564]\n",
      "epoch:42 step:32939 [D loss: 0.031572, acc: 100.00%] [G loss: 6.171138]\n",
      "epoch:42 step:32940 [D loss: 1.304692, acc: 46.09%] [G loss: 5.857329]\n",
      "epoch:42 step:32941 [D loss: 0.157167, acc: 98.44%] [G loss: 5.250584]\n",
      "epoch:42 step:32942 [D loss: 0.452212, acc: 72.66%] [G loss: 5.427537]\n",
      "epoch:42 step:32943 [D loss: 0.233852, acc: 96.09%] [G loss: 7.437992]\n",
      "epoch:42 step:32944 [D loss: 0.544963, acc: 68.75%] [G loss: 6.380121]\n",
      "epoch:42 step:32945 [D loss: 0.042646, acc: 99.22%] [G loss: 3.671361]\n",
      "epoch:42 step:32946 [D loss: 1.432484, acc: 37.50%] [G loss: 3.996078]\n",
      "epoch:42 step:32947 [D loss: 0.179860, acc: 98.44%] [G loss: 2.697924]\n",
      "epoch:42 step:32948 [D loss: 0.030356, acc: 100.00%] [G loss: 7.227462]\n",
      "epoch:42 step:32949 [D loss: 0.286724, acc: 85.94%] [G loss: 8.055013]\n",
      "epoch:42 step:32950 [D loss: 1.896084, acc: 3.12%] [G loss: 7.596272]\n",
      "epoch:42 step:32951 [D loss: 0.038719, acc: 100.00%] [G loss: 2.953043]\n",
      "epoch:42 step:32952 [D loss: 0.130798, acc: 99.22%] [G loss: 3.994493]\n",
      "epoch:42 step:32953 [D loss: 0.634892, acc: 57.81%] [G loss: 7.546916]\n",
      "epoch:42 step:32954 [D loss: 0.217685, acc: 94.53%] [G loss: 5.246551]\n",
      "epoch:42 step:32955 [D loss: 1.341170, acc: 26.56%] [G loss: 9.475790]\n",
      "epoch:42 step:32956 [D loss: 0.491788, acc: 82.81%] [G loss: 5.266221]\n",
      "epoch:42 step:32957 [D loss: 0.175472, acc: 99.22%] [G loss: 6.638864]\n",
      "epoch:42 step:32958 [D loss: 0.100861, acc: 100.00%] [G loss: 3.572032]\n",
      "epoch:42 step:32959 [D loss: 0.176713, acc: 98.44%] [G loss: 3.403748]\n",
      "epoch:42 step:32960 [D loss: 0.109563, acc: 99.22%] [G loss: 4.157203]\n",
      "epoch:42 step:32961 [D loss: 0.672929, acc: 60.16%] [G loss: 3.493052]\n",
      "epoch:42 step:32962 [D loss: 0.570220, acc: 71.88%] [G loss: 4.026674]\n",
      "epoch:42 step:32963 [D loss: 0.010116, acc: 100.00%] [G loss: 5.754324]\n",
      "epoch:42 step:32964 [D loss: 0.036875, acc: 100.00%] [G loss: 3.460317]\n",
      "epoch:42 step:32965 [D loss: 1.106758, acc: 50.78%] [G loss: 4.899157]\n",
      "epoch:42 step:32966 [D loss: 0.214006, acc: 93.75%] [G loss: 7.168038]\n",
      "epoch:42 step:32967 [D loss: 0.178999, acc: 98.44%] [G loss: 3.185700]\n",
      "epoch:42 step:32968 [D loss: 0.026679, acc: 100.00%] [G loss: 6.339613]\n",
      "epoch:42 step:32969 [D loss: 0.596551, acc: 60.16%] [G loss: 5.761183]\n",
      "epoch:42 step:32970 [D loss: 1.061768, acc: 51.56%] [G loss: 5.501326]\n",
      "epoch:42 step:32971 [D loss: 0.427189, acc: 76.56%] [G loss: 5.236125]\n",
      "epoch:42 step:32972 [D loss: 0.034066, acc: 100.00%] [G loss: 3.920319]\n",
      "epoch:42 step:32973 [D loss: 0.195284, acc: 99.22%] [G loss: 2.286012]\n",
      "epoch:42 step:32974 [D loss: 0.157311, acc: 96.09%] [G loss: 5.644809]\n",
      "epoch:42 step:32975 [D loss: 0.234401, acc: 94.53%] [G loss: 5.136247]\n",
      "epoch:42 step:32976 [D loss: 0.091986, acc: 99.22%] [G loss: 7.373216]\n",
      "epoch:42 step:32977 [D loss: 0.164044, acc: 100.00%] [G loss: 3.320408]\n",
      "epoch:42 step:32978 [D loss: 0.312007, acc: 93.75%] [G loss: 5.788602]\n",
      "epoch:42 step:32979 [D loss: 0.158766, acc: 99.22%] [G loss: 4.968191]\n",
      "epoch:42 step:32980 [D loss: 0.568226, acc: 60.16%] [G loss: 6.800773]\n",
      "epoch:42 step:32981 [D loss: 0.210438, acc: 97.66%] [G loss: 5.022369]\n",
      "epoch:42 step:32982 [D loss: 0.055424, acc: 100.00%] [G loss: 4.875294]\n",
      "epoch:42 step:32983 [D loss: 0.120130, acc: 99.22%] [G loss: 4.391685]\n",
      "epoch:42 step:32984 [D loss: 0.049050, acc: 100.00%] [G loss: 5.396532]\n",
      "epoch:42 step:32985 [D loss: 0.778448, acc: 55.47%] [G loss: 3.732477]\n",
      "epoch:42 step:32986 [D loss: 0.537482, acc: 59.38%] [G loss: 6.562243]\n",
      "epoch:42 step:32987 [D loss: 0.019672, acc: 100.00%] [G loss: 7.150768]\n",
      "epoch:42 step:32988 [D loss: 0.069604, acc: 100.00%] [G loss: 6.248366]\n",
      "epoch:42 step:32989 [D loss: 0.169637, acc: 99.22%] [G loss: 5.607567]\n",
      "epoch:42 step:32990 [D loss: 0.236376, acc: 93.75%] [G loss: 6.367077]\n",
      "epoch:42 step:32991 [D loss: 0.497708, acc: 63.28%] [G loss: 3.374885]\n",
      "epoch:42 step:32992 [D loss: 0.338427, acc: 79.69%] [G loss: 3.195220]\n",
      "epoch:42 step:32993 [D loss: 0.158527, acc: 98.44%] [G loss: 4.835738]\n",
      "epoch:42 step:32994 [D loss: 0.147895, acc: 97.66%] [G loss: 5.761345]\n",
      "epoch:42 step:32995 [D loss: 0.447333, acc: 68.75%] [G loss: 6.024841]\n",
      "epoch:42 step:32996 [D loss: 0.377975, acc: 87.50%] [G loss: 3.282150]\n",
      "epoch:42 step:32997 [D loss: 0.065515, acc: 100.00%] [G loss: 6.346013]\n",
      "epoch:42 step:32998 [D loss: 0.231206, acc: 95.31%] [G loss: 5.734030]\n",
      "epoch:42 step:32999 [D loss: 0.833855, acc: 50.78%] [G loss: 4.614349]\n",
      "epoch:42 step:33000 [D loss: 0.109096, acc: 100.00%] [G loss: 5.160613]\n",
      "epoch:42 step:33001 [D loss: 0.045294, acc: 100.00%] [G loss: 9.397621]\n",
      "epoch:42 step:33002 [D loss: 0.125048, acc: 100.00%] [G loss: 5.052453]\n",
      "epoch:42 step:33003 [D loss: 0.209487, acc: 92.19%] [G loss: 6.562099]\n",
      "epoch:42 step:33004 [D loss: 1.097668, acc: 31.25%] [G loss: 4.110865]\n",
      "epoch:42 step:33005 [D loss: 0.285748, acc: 89.84%] [G loss: 7.166606]\n",
      "epoch:42 step:33006 [D loss: 0.105822, acc: 100.00%] [G loss: 5.807575]\n",
      "epoch:42 step:33007 [D loss: 0.150945, acc: 99.22%] [G loss: 6.521640]\n",
      "epoch:42 step:33008 [D loss: 0.315220, acc: 92.19%] [G loss: 2.584402]\n",
      "epoch:42 step:33009 [D loss: 0.106996, acc: 100.00%] [G loss: 8.483212]\n",
      "epoch:42 step:33010 [D loss: 0.076568, acc: 100.00%] [G loss: 2.397492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33011 [D loss: 0.734827, acc: 60.94%] [G loss: 5.805253]\n",
      "epoch:42 step:33012 [D loss: 0.793003, acc: 55.47%] [G loss: 6.121790]\n",
      "epoch:42 step:33013 [D loss: 0.714527, acc: 56.25%] [G loss: 7.719010]\n",
      "epoch:42 step:33014 [D loss: 0.136309, acc: 98.44%] [G loss: 5.471322]\n",
      "epoch:42 step:33015 [D loss: 0.414821, acc: 80.47%] [G loss: 5.175614]\n",
      "epoch:42 step:33016 [D loss: 0.105540, acc: 99.22%] [G loss: 5.534938]\n",
      "epoch:42 step:33017 [D loss: 0.269235, acc: 89.06%] [G loss: 3.455030]\n",
      "epoch:42 step:33018 [D loss: 0.492007, acc: 71.88%] [G loss: 4.245948]\n",
      "epoch:42 step:33019 [D loss: 0.759178, acc: 53.12%] [G loss: 8.443041]\n",
      "epoch:42 step:33020 [D loss: 0.851865, acc: 55.47%] [G loss: 5.747849]\n",
      "epoch:42 step:33021 [D loss: 0.215071, acc: 97.66%] [G loss: 3.860168]\n",
      "epoch:42 step:33022 [D loss: 0.357955, acc: 90.62%] [G loss: 3.790283]\n",
      "epoch:42 step:33023 [D loss: 0.123392, acc: 100.00%] [G loss: 5.867465]\n",
      "epoch:42 step:33024 [D loss: 0.163495, acc: 98.44%] [G loss: 5.140625]\n",
      "epoch:42 step:33025 [D loss: 0.073541, acc: 100.00%] [G loss: 2.845626]\n",
      "epoch:42 step:33026 [D loss: 0.089691, acc: 100.00%] [G loss: 5.395736]\n",
      "epoch:42 step:33027 [D loss: 0.099898, acc: 99.22%] [G loss: 5.903884]\n",
      "epoch:42 step:33028 [D loss: 0.573307, acc: 64.06%] [G loss: 5.793016]\n",
      "epoch:42 step:33029 [D loss: 0.378053, acc: 74.22%] [G loss: 6.143484]\n",
      "epoch:42 step:33030 [D loss: 0.245147, acc: 92.97%] [G loss: 4.754531]\n",
      "epoch:42 step:33031 [D loss: 0.371155, acc: 82.03%] [G loss: 8.024536]\n",
      "epoch:42 step:33032 [D loss: 0.852781, acc: 48.44%] [G loss: 6.442056]\n",
      "epoch:42 step:33033 [D loss: 0.165811, acc: 98.44%] [G loss: 5.042540]\n",
      "epoch:42 step:33034 [D loss: 0.267151, acc: 96.09%] [G loss: 2.818565]\n",
      "epoch:42 step:33035 [D loss: 0.242622, acc: 98.44%] [G loss: 4.621787]\n",
      "epoch:42 step:33036 [D loss: 0.944561, acc: 51.56%] [G loss: 7.176039]\n",
      "epoch:42 step:33037 [D loss: 1.448884, acc: 50.00%] [G loss: 5.219920]\n",
      "epoch:42 step:33038 [D loss: 0.954217, acc: 39.84%] [G loss: 3.013996]\n",
      "epoch:42 step:33039 [D loss: 0.114698, acc: 97.66%] [G loss: 8.964035]\n",
      "epoch:42 step:33040 [D loss: 0.732132, acc: 51.56%] [G loss: 9.129083]\n",
      "epoch:42 step:33041 [D loss: 0.523462, acc: 77.34%] [G loss: 4.941292]\n",
      "epoch:42 step:33042 [D loss: 0.188209, acc: 96.09%] [G loss: 5.269715]\n",
      "epoch:42 step:33043 [D loss: 0.429064, acc: 73.44%] [G loss: 7.947004]\n",
      "epoch:42 step:33044 [D loss: 0.022417, acc: 100.00%] [G loss: 6.409660]\n",
      "epoch:42 step:33045 [D loss: 0.031698, acc: 100.00%] [G loss: 8.208969]\n",
      "epoch:42 step:33046 [D loss: 0.209788, acc: 97.66%] [G loss: 5.723352]\n",
      "epoch:42 step:33047 [D loss: 0.173192, acc: 96.88%] [G loss: 6.100464]\n",
      "epoch:42 step:33048 [D loss: 0.271855, acc: 92.97%] [G loss: 3.196968]\n",
      "epoch:42 step:33049 [D loss: 0.263691, acc: 88.28%] [G loss: 3.994670]\n",
      "epoch:42 step:33050 [D loss: 0.073069, acc: 100.00%] [G loss: 1.664089]\n",
      "epoch:42 step:33051 [D loss: 0.122280, acc: 99.22%] [G loss: 4.662992]\n",
      "epoch:42 step:33052 [D loss: 0.303165, acc: 97.66%] [G loss: 3.937363]\n",
      "epoch:42 step:33053 [D loss: 0.091611, acc: 100.00%] [G loss: 4.434781]\n",
      "epoch:42 step:33054 [D loss: 0.620103, acc: 53.91%] [G loss: 6.967117]\n",
      "epoch:42 step:33055 [D loss: 0.459870, acc: 69.53%] [G loss: 4.316962]\n",
      "epoch:42 step:33056 [D loss: 0.194928, acc: 99.22%] [G loss: 2.374593]\n",
      "epoch:42 step:33057 [D loss: 0.210021, acc: 96.88%] [G loss: 5.299545]\n",
      "epoch:42 step:33058 [D loss: 0.217729, acc: 98.44%] [G loss: 4.606258]\n",
      "epoch:42 step:33059 [D loss: 1.392159, acc: 5.47%] [G loss: 4.491521]\n",
      "epoch:42 step:33060 [D loss: 0.348411, acc: 78.91%] [G loss: 6.090733]\n",
      "epoch:42 step:33061 [D loss: 0.024497, acc: 100.00%] [G loss: 9.634161]\n",
      "epoch:42 step:33062 [D loss: 0.167959, acc: 99.22%] [G loss: 3.847007]\n",
      "epoch:42 step:33063 [D loss: 0.917060, acc: 49.22%] [G loss: 4.606816]\n",
      "epoch:42 step:33064 [D loss: 0.189056, acc: 98.44%] [G loss: 6.849583]\n",
      "epoch:42 step:33065 [D loss: 0.298737, acc: 86.72%] [G loss: 6.145342]\n",
      "epoch:42 step:33066 [D loss: 0.274357, acc: 89.84%] [G loss: 5.635037]\n",
      "epoch:42 step:33067 [D loss: 0.111941, acc: 100.00%] [G loss: 5.281567]\n",
      "epoch:42 step:33068 [D loss: 0.072340, acc: 100.00%] [G loss: 5.570776]\n",
      "epoch:42 step:33069 [D loss: 0.157756, acc: 99.22%] [G loss: 5.914645]\n",
      "epoch:42 step:33070 [D loss: 0.318889, acc: 93.75%] [G loss: 4.758595]\n",
      "epoch:42 step:33071 [D loss: 0.191231, acc: 96.88%] [G loss: 5.337863]\n",
      "epoch:42 step:33072 [D loss: 0.549772, acc: 64.84%] [G loss: 4.099030]\n",
      "epoch:42 step:33073 [D loss: 0.180960, acc: 99.22%] [G loss: 2.910282]\n",
      "epoch:42 step:33074 [D loss: 0.171800, acc: 96.09%] [G loss: 6.745534]\n",
      "epoch:42 step:33075 [D loss: 0.156864, acc: 100.00%] [G loss: 4.752320]\n",
      "epoch:42 step:33076 [D loss: 0.465888, acc: 82.81%] [G loss: 3.050070]\n",
      "epoch:42 step:33077 [D loss: 0.442483, acc: 84.38%] [G loss: 5.312926]\n",
      "epoch:42 step:33078 [D loss: 0.365791, acc: 81.25%] [G loss: 8.315208]\n",
      "epoch:42 step:33079 [D loss: 1.757508, acc: 46.88%] [G loss: 7.105029]\n",
      "epoch:42 step:33080 [D loss: 0.100703, acc: 99.22%] [G loss: 3.994842]\n",
      "epoch:42 step:33081 [D loss: 0.581763, acc: 60.94%] [G loss: 7.106686]\n",
      "epoch:42 step:33082 [D loss: 0.150585, acc: 98.44%] [G loss: 5.935043]\n",
      "epoch:42 step:33083 [D loss: 0.062836, acc: 99.22%] [G loss: 5.707972]\n",
      "epoch:42 step:33084 [D loss: 0.217074, acc: 98.44%] [G loss: 4.897944]\n",
      "epoch:42 step:33085 [D loss: 0.108105, acc: 99.22%] [G loss: 6.199760]\n",
      "epoch:42 step:33086 [D loss: 1.217141, acc: 49.22%] [G loss: 5.379644]\n",
      "epoch:42 step:33087 [D loss: 0.042394, acc: 100.00%] [G loss: 5.936003]\n",
      "epoch:42 step:33088 [D loss: 0.275123, acc: 86.72%] [G loss: 8.761932]\n",
      "epoch:42 step:33089 [D loss: 0.363759, acc: 86.72%] [G loss: 4.644790]\n",
      "epoch:42 step:33090 [D loss: 0.288445, acc: 94.53%] [G loss: 3.702507]\n",
      "epoch:42 step:33091 [D loss: 0.176380, acc: 95.31%] [G loss: 4.693220]\n",
      "epoch:42 step:33092 [D loss: 0.122694, acc: 100.00%] [G loss: 6.651072]\n",
      "epoch:42 step:33093 [D loss: 0.554545, acc: 72.66%] [G loss: 8.715581]\n",
      "epoch:42 step:33094 [D loss: 0.126938, acc: 100.00%] [G loss: 5.161558]\n",
      "epoch:42 step:33095 [D loss: 0.280155, acc: 85.16%] [G loss: 6.649036]\n",
      "epoch:42 step:33096 [D loss: 0.790293, acc: 51.56%] [G loss: 4.326412]\n",
      "epoch:42 step:33097 [D loss: 0.319150, acc: 82.03%] [G loss: 3.853952]\n",
      "epoch:42 step:33098 [D loss: 0.420420, acc: 79.69%] [G loss: 4.913724]\n",
      "epoch:42 step:33099 [D loss: 0.086962, acc: 100.00%] [G loss: 5.465890]\n",
      "epoch:42 step:33100 [D loss: 0.128087, acc: 100.00%] [G loss: 3.444671]\n",
      "epoch:42 step:33101 [D loss: 0.059667, acc: 100.00%] [G loss: 5.113987]\n",
      "epoch:42 step:33102 [D loss: 0.518023, acc: 70.31%] [G loss: 3.453052]\n",
      "epoch:42 step:33103 [D loss: 0.571319, acc: 67.19%] [G loss: 4.995442]\n",
      "epoch:42 step:33104 [D loss: 0.195009, acc: 95.31%] [G loss: 6.732940]\n",
      "epoch:42 step:33105 [D loss: 0.350901, acc: 80.47%] [G loss: 4.937107]\n",
      "epoch:42 step:33106 [D loss: 0.314527, acc: 91.41%] [G loss: 2.299608]\n",
      "epoch:42 step:33107 [D loss: 1.301520, acc: 38.28%] [G loss: 5.399597]\n",
      "epoch:42 step:33108 [D loss: 0.007890, acc: 100.00%] [G loss: 7.353908]\n",
      "epoch:42 step:33109 [D loss: 0.201716, acc: 98.44%] [G loss: 7.973577]\n",
      "epoch:42 step:33110 [D loss: 0.053429, acc: 100.00%] [G loss: 4.361067]\n",
      "epoch:42 step:33111 [D loss: 0.553975, acc: 58.59%] [G loss: 6.115964]\n",
      "epoch:42 step:33112 [D loss: 0.708220, acc: 53.91%] [G loss: 3.178908]\n",
      "epoch:42 step:33113 [D loss: 0.351458, acc: 81.25%] [G loss: 5.344851]\n",
      "epoch:42 step:33114 [D loss: 1.512043, acc: 50.78%] [G loss: 8.443184]\n",
      "epoch:42 step:33115 [D loss: 0.942605, acc: 51.56%] [G loss: 5.758095]\n",
      "epoch:42 step:33116 [D loss: 0.463252, acc: 71.88%] [G loss: 4.420968]\n",
      "epoch:42 step:33117 [D loss: 0.306530, acc: 92.19%] [G loss: 5.515632]\n",
      "epoch:42 step:33118 [D loss: 1.351748, acc: 49.22%] [G loss: 7.111536]\n",
      "epoch:42 step:33119 [D loss: 0.173320, acc: 99.22%] [G loss: 4.269095]\n",
      "epoch:42 step:33120 [D loss: 1.071575, acc: 49.22%] [G loss: 5.256594]\n",
      "epoch:42 step:33121 [D loss: 0.199743, acc: 99.22%] [G loss: 5.952038]\n",
      "epoch:42 step:33122 [D loss: 0.320611, acc: 82.81%] [G loss: 7.676115]\n",
      "epoch:42 step:33123 [D loss: 0.425546, acc: 85.16%] [G loss: 5.597109]\n",
      "epoch:42 step:33124 [D loss: 0.099191, acc: 100.00%] [G loss: 4.273163]\n",
      "epoch:42 step:33125 [D loss: 0.142192, acc: 100.00%] [G loss: 4.767380]\n",
      "epoch:42 step:33126 [D loss: 0.510480, acc: 78.12%] [G loss: 7.462467]\n",
      "epoch:42 step:33127 [D loss: 0.144498, acc: 100.00%] [G loss: 5.193463]\n",
      "epoch:42 step:33128 [D loss: 0.212247, acc: 93.75%] [G loss: 6.581438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33129 [D loss: 0.097248, acc: 100.00%] [G loss: 4.177926]\n",
      "epoch:42 step:33130 [D loss: 0.237192, acc: 92.97%] [G loss: 3.187857]\n",
      "epoch:42 step:33131 [D loss: 0.099865, acc: 99.22%] [G loss: 5.005603]\n",
      "epoch:42 step:33132 [D loss: 0.245401, acc: 95.31%] [G loss: 5.093033]\n",
      "epoch:42 step:33133 [D loss: 0.562307, acc: 73.44%] [G loss: 5.022202]\n",
      "epoch:42 step:33134 [D loss: 0.189754, acc: 94.53%] [G loss: 2.450039]\n",
      "epoch:42 step:33135 [D loss: 0.012250, acc: 100.00%] [G loss: 8.947769]\n",
      "epoch:42 step:33136 [D loss: 0.598674, acc: 61.72%] [G loss: 4.707768]\n",
      "epoch:42 step:33137 [D loss: 0.050620, acc: 100.00%] [G loss: 5.349059]\n",
      "epoch:42 step:33138 [D loss: 0.250901, acc: 93.75%] [G loss: 5.200547]\n",
      "epoch:42 step:33139 [D loss: 0.390178, acc: 85.94%] [G loss: 6.997930]\n",
      "epoch:42 step:33140 [D loss: 0.328299, acc: 85.16%] [G loss: 7.441525]\n",
      "epoch:42 step:33141 [D loss: 0.549307, acc: 64.84%] [G loss: 5.724985]\n",
      "epoch:42 step:33142 [D loss: 0.597827, acc: 60.94%] [G loss: 7.316593]\n",
      "epoch:42 step:33143 [D loss: 0.502236, acc: 68.75%] [G loss: 5.288392]\n",
      "epoch:42 step:33144 [D loss: 0.145798, acc: 98.44%] [G loss: 3.639180]\n",
      "epoch:42 step:33145 [D loss: 0.684465, acc: 58.59%] [G loss: 4.958320]\n",
      "epoch:42 step:33146 [D loss: 0.548392, acc: 75.00%] [G loss: 6.874829]\n",
      "epoch:42 step:33147 [D loss: 0.006544, acc: 100.00%] [G loss: 2.790515]\n",
      "epoch:42 step:33148 [D loss: 1.296590, acc: 9.38%] [G loss: 7.879068]\n",
      "epoch:42 step:33149 [D loss: 0.050037, acc: 100.00%] [G loss: 4.771871]\n",
      "epoch:42 step:33150 [D loss: 0.112145, acc: 100.00%] [G loss: 5.746703]\n",
      "epoch:42 step:33151 [D loss: 0.154843, acc: 100.00%] [G loss: 2.611180]\n",
      "epoch:42 step:33152 [D loss: 0.300458, acc: 87.50%] [G loss: 5.748985]\n",
      "epoch:42 step:33153 [D loss: 0.907975, acc: 51.56%] [G loss: 8.654458]\n",
      "epoch:42 step:33154 [D loss: 0.509441, acc: 64.06%] [G loss: 3.665771]\n",
      "epoch:42 step:33155 [D loss: 0.103270, acc: 100.00%] [G loss: 6.341210]\n",
      "epoch:42 step:33156 [D loss: 0.104535, acc: 100.00%] [G loss: 6.332087]\n",
      "epoch:42 step:33157 [D loss: 0.066258, acc: 100.00%] [G loss: 5.512299]\n",
      "epoch:42 step:33158 [D loss: 0.122541, acc: 99.22%] [G loss: 7.727570]\n",
      "epoch:42 step:33159 [D loss: 0.442482, acc: 85.16%] [G loss: 4.932269]\n",
      "epoch:42 step:33160 [D loss: 0.233494, acc: 92.97%] [G loss: 5.347963]\n",
      "epoch:42 step:33161 [D loss: 0.641511, acc: 57.81%] [G loss: 7.881851]\n",
      "epoch:42 step:33162 [D loss: 1.203871, acc: 19.53%] [G loss: 7.392288]\n",
      "epoch:42 step:33163 [D loss: 0.402046, acc: 73.44%] [G loss: 6.161789]\n",
      "epoch:42 step:33164 [D loss: 0.450876, acc: 67.97%] [G loss: 5.258297]\n",
      "epoch:42 step:33165 [D loss: 0.179653, acc: 96.88%] [G loss: 5.257648]\n",
      "epoch:42 step:33166 [D loss: 0.499919, acc: 72.66%] [G loss: 5.879319]\n",
      "epoch:42 step:33167 [D loss: 0.132642, acc: 99.22%] [G loss: 5.766045]\n",
      "epoch:42 step:33168 [D loss: 1.861320, acc: 3.91%] [G loss: 8.256046]\n",
      "epoch:42 step:33169 [D loss: 0.211432, acc: 92.97%] [G loss: 4.209534]\n",
      "epoch:42 step:33170 [D loss: 0.923578, acc: 47.66%] [G loss: 3.767267]\n",
      "epoch:42 step:33171 [D loss: 0.313288, acc: 96.88%] [G loss: 5.407248]\n",
      "epoch:42 step:33172 [D loss: 0.126665, acc: 100.00%] [G loss: 7.441800]\n",
      "epoch:42 step:33173 [D loss: 0.175376, acc: 97.66%] [G loss: 5.714925]\n",
      "epoch:42 step:33174 [D loss: 0.156174, acc: 98.44%] [G loss: 6.440023]\n",
      "epoch:42 step:33175 [D loss: 0.906780, acc: 28.12%] [G loss: 4.859753]\n",
      "epoch:42 step:33176 [D loss: 0.267897, acc: 95.31%] [G loss: 5.381764]\n",
      "epoch:42 step:33177 [D loss: 0.391118, acc: 82.03%] [G loss: 6.547362]\n",
      "epoch:42 step:33178 [D loss: 0.122096, acc: 100.00%] [G loss: 4.706641]\n",
      "epoch:42 step:33179 [D loss: 0.587296, acc: 64.84%] [G loss: 3.685763]\n",
      "epoch:42 step:33180 [D loss: 0.238850, acc: 94.53%] [G loss: 6.205496]\n",
      "epoch:42 step:33181 [D loss: 0.158953, acc: 98.44%] [G loss: 5.873218]\n",
      "epoch:42 step:33182 [D loss: 0.128346, acc: 99.22%] [G loss: 6.919209]\n",
      "epoch:42 step:33183 [D loss: 0.223860, acc: 96.88%] [G loss: 3.985843]\n",
      "epoch:42 step:33184 [D loss: 0.514358, acc: 65.62%] [G loss: 5.168355]\n",
      "epoch:42 step:33185 [D loss: 0.217825, acc: 96.88%] [G loss: 2.555295]\n",
      "epoch:42 step:33186 [D loss: 0.340618, acc: 79.69%] [G loss: 4.618385]\n",
      "epoch:42 step:33187 [D loss: 0.300696, acc: 94.53%] [G loss: 2.708653]\n",
      "epoch:42 step:33188 [D loss: 0.221645, acc: 96.09%] [G loss: 9.762600]\n",
      "epoch:42 step:33189 [D loss: 0.029118, acc: 100.00%] [G loss: 8.059291]\n",
      "epoch:42 step:33190 [D loss: 0.058452, acc: 99.22%] [G loss: 6.840467]\n",
      "epoch:42 step:33191 [D loss: 0.160548, acc: 100.00%] [G loss: 3.964489]\n",
      "epoch:42 step:33192 [D loss: 0.152597, acc: 97.66%] [G loss: 4.960598]\n",
      "epoch:42 step:33193 [D loss: 0.363530, acc: 82.03%] [G loss: 6.685027]\n",
      "epoch:42 step:33194 [D loss: 0.095305, acc: 100.00%] [G loss: 6.726499]\n",
      "epoch:42 step:33195 [D loss: 0.149262, acc: 99.22%] [G loss: 5.883807]\n",
      "epoch:42 step:33196 [D loss: 0.029697, acc: 100.00%] [G loss: 7.419311]\n",
      "epoch:42 step:33197 [D loss: 0.764756, acc: 53.12%] [G loss: 9.508289]\n",
      "epoch:42 step:33198 [D loss: 0.068373, acc: 100.00%] [G loss: 4.622955]\n",
      "epoch:42 step:33199 [D loss: 0.178669, acc: 98.44%] [G loss: 5.395360]\n",
      "epoch:42 step:33200 [D loss: 0.220271, acc: 96.09%] [G loss: 2.485822]\n",
      "epoch:42 step:33201 [D loss: 0.801300, acc: 53.12%] [G loss: 4.174666]\n",
      "epoch:42 step:33202 [D loss: 0.180446, acc: 99.22%] [G loss: 3.708375]\n",
      "epoch:42 step:33203 [D loss: 0.364985, acc: 92.97%] [G loss: 8.934271]\n",
      "epoch:42 step:33204 [D loss: 0.207827, acc: 91.41%] [G loss: 7.101686]\n",
      "epoch:42 step:33205 [D loss: 0.049706, acc: 100.00%] [G loss: 3.880927]\n",
      "epoch:42 step:33206 [D loss: 0.663718, acc: 57.03%] [G loss: 5.087560]\n",
      "epoch:42 step:33207 [D loss: 0.414755, acc: 73.44%] [G loss: 6.761786]\n",
      "epoch:42 step:33208 [D loss: 0.279644, acc: 95.31%] [G loss: 4.477529]\n",
      "epoch:42 step:33209 [D loss: 0.590595, acc: 58.59%] [G loss: 6.976088]\n",
      "epoch:42 step:33210 [D loss: 0.446969, acc: 77.34%] [G loss: 5.440563]\n",
      "epoch:42 step:33211 [D loss: 0.848334, acc: 48.44%] [G loss: 7.108434]\n",
      "epoch:42 step:33212 [D loss: 0.419216, acc: 80.47%] [G loss: 8.354098]\n",
      "epoch:42 step:33213 [D loss: 0.064540, acc: 100.00%] [G loss: 3.160605]\n",
      "epoch:42 step:33214 [D loss: 0.280034, acc: 85.94%] [G loss: 5.963260]\n",
      "epoch:42 step:33215 [D loss: 0.217207, acc: 91.41%] [G loss: 7.308869]\n",
      "epoch:42 step:33216 [D loss: 0.266916, acc: 96.09%] [G loss: 6.375755]\n",
      "epoch:42 step:33217 [D loss: 0.264423, acc: 96.09%] [G loss: 6.198668]\n",
      "epoch:42 step:33218 [D loss: 0.198286, acc: 98.44%] [G loss: 5.013001]\n",
      "epoch:42 step:33219 [D loss: 0.159710, acc: 98.44%] [G loss: 5.285590]\n",
      "epoch:42 step:33220 [D loss: 0.432447, acc: 67.19%] [G loss: 5.419467]\n",
      "epoch:42 step:33221 [D loss: 0.044342, acc: 100.00%] [G loss: 9.694630]\n",
      "epoch:42 step:33222 [D loss: 0.564224, acc: 69.53%] [G loss: 4.149091]\n",
      "epoch:42 step:33223 [D loss: 0.315781, acc: 94.53%] [G loss: 6.274606]\n",
      "epoch:42 step:33224 [D loss: 0.463627, acc: 64.84%] [G loss: 3.792126]\n",
      "epoch:42 step:33225 [D loss: 0.540201, acc: 64.84%] [G loss: 5.901297]\n",
      "epoch:42 step:33226 [D loss: 0.157477, acc: 98.44%] [G loss: 5.404539]\n",
      "epoch:42 step:33227 [D loss: 0.272670, acc: 89.84%] [G loss: 6.316121]\n",
      "epoch:42 step:33228 [D loss: 1.113973, acc: 31.25%] [G loss: 8.603786]\n",
      "epoch:42 step:33229 [D loss: 0.346300, acc: 79.69%] [G loss: 5.239587]\n",
      "epoch:42 step:33230 [D loss: 0.099388, acc: 100.00%] [G loss: 4.712124]\n",
      "epoch:42 step:33231 [D loss: 0.094093, acc: 100.00%] [G loss: 6.241978]\n",
      "epoch:42 step:33232 [D loss: 0.304793, acc: 87.50%] [G loss: 6.692643]\n",
      "epoch:42 step:33233 [D loss: 0.581242, acc: 69.53%] [G loss: 4.967518]\n",
      "epoch:42 step:33234 [D loss: 0.218501, acc: 92.19%] [G loss: 3.626517]\n",
      "epoch:42 step:33235 [D loss: 0.706959, acc: 50.78%] [G loss: 4.326956]\n",
      "epoch:42 step:33236 [D loss: 0.330279, acc: 89.84%] [G loss: 6.885704]\n",
      "epoch:42 step:33237 [D loss: 0.123382, acc: 98.44%] [G loss: 7.017783]\n",
      "epoch:42 step:33238 [D loss: 0.530310, acc: 76.56%] [G loss: 5.150058]\n",
      "epoch:42 step:33239 [D loss: 0.142135, acc: 98.44%] [G loss: 3.702586]\n",
      "epoch:42 step:33240 [D loss: 1.128712, acc: 50.00%] [G loss: 9.481832]\n",
      "epoch:42 step:33241 [D loss: 0.029583, acc: 100.00%] [G loss: 6.684988]\n",
      "epoch:42 step:33242 [D loss: 0.202970, acc: 95.31%] [G loss: 6.594885]\n",
      "epoch:42 step:33243 [D loss: 0.432384, acc: 70.31%] [G loss: 7.301592]\n",
      "epoch:42 step:33244 [D loss: 0.146377, acc: 98.44%] [G loss: 6.269210]\n",
      "epoch:42 step:33245 [D loss: 0.064656, acc: 100.00%] [G loss: 2.991934]\n",
      "epoch:42 step:33246 [D loss: 0.040504, acc: 100.00%] [G loss: 7.501351]\n",
      "epoch:42 step:33247 [D loss: 0.122150, acc: 100.00%] [G loss: 4.933456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33248 [D loss: 0.169146, acc: 96.09%] [G loss: 4.758759]\n",
      "epoch:42 step:33249 [D loss: 0.646172, acc: 61.72%] [G loss: 7.088332]\n",
      "epoch:42 step:33250 [D loss: 0.247272, acc: 96.88%] [G loss: 5.632436]\n",
      "epoch:42 step:33251 [D loss: 0.291563, acc: 87.50%] [G loss: 4.004992]\n",
      "epoch:42 step:33252 [D loss: 0.138841, acc: 99.22%] [G loss: 4.627697]\n",
      "epoch:42 step:33253 [D loss: 0.669726, acc: 57.03%] [G loss: 6.807254]\n",
      "epoch:42 step:33254 [D loss: 0.329121, acc: 81.25%] [G loss: 5.972741]\n",
      "epoch:42 step:33255 [D loss: 0.237798, acc: 91.41%] [G loss: 6.235815]\n",
      "epoch:42 step:33256 [D loss: 0.122341, acc: 99.22%] [G loss: 5.157144]\n",
      "epoch:42 step:33257 [D loss: 0.162868, acc: 97.66%] [G loss: 5.990528]\n",
      "epoch:42 step:33258 [D loss: 0.066141, acc: 100.00%] [G loss: 3.899409]\n",
      "epoch:42 step:33259 [D loss: 0.066270, acc: 100.00%] [G loss: 6.553692]\n",
      "epoch:42 step:33260 [D loss: 0.057868, acc: 100.00%] [G loss: 5.350427]\n",
      "epoch:42 step:33261 [D loss: 0.093704, acc: 100.00%] [G loss: 5.615274]\n",
      "epoch:42 step:33262 [D loss: 0.016536, acc: 100.00%] [G loss: 7.309505]\n",
      "epoch:42 step:33263 [D loss: 0.375040, acc: 76.56%] [G loss: 6.723797]\n",
      "epoch:42 step:33264 [D loss: 0.237045, acc: 91.41%] [G loss: 4.809526]\n",
      "epoch:42 step:33265 [D loss: 0.121400, acc: 100.00%] [G loss: 5.636890]\n",
      "epoch:42 step:33266 [D loss: 0.027227, acc: 100.00%] [G loss: 4.580869]\n",
      "epoch:42 step:33267 [D loss: 0.571182, acc: 72.66%] [G loss: 3.439856]\n",
      "epoch:42 step:33268 [D loss: 0.088309, acc: 100.00%] [G loss: 8.162367]\n",
      "epoch:42 step:33269 [D loss: 0.399766, acc: 91.41%] [G loss: 4.088006]\n",
      "epoch:42 step:33270 [D loss: 0.082333, acc: 98.44%] [G loss: 4.669753]\n",
      "epoch:42 step:33271 [D loss: 0.065068, acc: 100.00%] [G loss: 5.168692]\n",
      "epoch:42 step:33272 [D loss: 0.034773, acc: 100.00%] [G loss: 7.679519]\n",
      "epoch:42 step:33273 [D loss: 0.142244, acc: 98.44%] [G loss: 5.168015]\n",
      "epoch:42 step:33274 [D loss: 0.110645, acc: 100.00%] [G loss: 5.489881]\n",
      "epoch:42 step:33275 [D loss: 0.198313, acc: 96.88%] [G loss: 6.188764]\n",
      "epoch:42 step:33276 [D loss: 0.501872, acc: 71.09%] [G loss: 6.321260]\n",
      "epoch:42 step:33277 [D loss: 0.287188, acc: 89.06%] [G loss: 7.258373]\n",
      "epoch:42 step:33278 [D loss: 0.216595, acc: 94.53%] [G loss: 7.394251]\n",
      "epoch:42 step:33279 [D loss: 0.262362, acc: 96.88%] [G loss: 3.880914]\n",
      "epoch:42 step:33280 [D loss: 0.773051, acc: 51.56%] [G loss: 9.371582]\n",
      "epoch:42 step:33281 [D loss: 1.160703, acc: 46.88%] [G loss: 6.792592]\n",
      "epoch:42 step:33282 [D loss: 0.087441, acc: 99.22%] [G loss: 4.101057]\n",
      "epoch:42 step:33283 [D loss: 0.397305, acc: 85.16%] [G loss: 4.369595]\n",
      "epoch:42 step:33284 [D loss: 0.183251, acc: 95.31%] [G loss: 4.889191]\n",
      "epoch:42 step:33285 [D loss: 0.954765, acc: 35.94%] [G loss: 5.840503]\n",
      "epoch:42 step:33286 [D loss: 0.057571, acc: 100.00%] [G loss: 6.691854]\n",
      "epoch:42 step:33287 [D loss: 0.219791, acc: 96.09%] [G loss: 4.927995]\n",
      "epoch:42 step:33288 [D loss: 0.166539, acc: 96.88%] [G loss: 4.961886]\n",
      "epoch:42 step:33289 [D loss: 0.596964, acc: 60.94%] [G loss: 4.296737]\n",
      "epoch:42 step:33290 [D loss: 0.477424, acc: 81.25%] [G loss: 6.556132]\n",
      "epoch:42 step:33291 [D loss: 0.201784, acc: 94.53%] [G loss: 5.108396]\n",
      "epoch:42 step:33292 [D loss: 0.314734, acc: 83.59%] [G loss: 4.696507]\n",
      "epoch:42 step:33293 [D loss: 0.282869, acc: 95.31%] [G loss: 5.606990]\n",
      "epoch:42 step:33294 [D loss: 0.049914, acc: 100.00%] [G loss: 9.633699]\n",
      "epoch:42 step:33295 [D loss: 0.060212, acc: 100.00%] [G loss: 7.409769]\n",
      "epoch:42 step:33296 [D loss: 0.198370, acc: 97.66%] [G loss: 3.713787]\n",
      "epoch:42 step:33297 [D loss: 0.068526, acc: 100.00%] [G loss: 3.481220]\n",
      "epoch:42 step:33298 [D loss: 0.340483, acc: 92.19%] [G loss: 4.951660]\n",
      "epoch:42 step:33299 [D loss: 0.263184, acc: 89.06%] [G loss: 7.552244]\n",
      "epoch:42 step:33300 [D loss: 0.638179, acc: 55.47%] [G loss: 8.229725]\n",
      "epoch:42 step:33301 [D loss: 0.147878, acc: 100.00%] [G loss: 4.646922]\n",
      "epoch:42 step:33302 [D loss: 0.038043, acc: 100.00%] [G loss: 4.464438]\n",
      "epoch:42 step:33303 [D loss: 0.117402, acc: 98.44%] [G loss: 6.325559]\n",
      "epoch:42 step:33304 [D loss: 0.555927, acc: 64.06%] [G loss: 5.971440]\n",
      "epoch:42 step:33305 [D loss: 1.189561, acc: 50.00%] [G loss: 5.464045]\n",
      "epoch:42 step:33306 [D loss: 0.528654, acc: 71.09%] [G loss: 4.535446]\n",
      "epoch:42 step:33307 [D loss: 0.246121, acc: 97.66%] [G loss: 6.949809]\n",
      "epoch:42 step:33308 [D loss: 0.297835, acc: 88.28%] [G loss: 9.188600]\n",
      "epoch:42 step:33309 [D loss: 1.167919, acc: 17.97%] [G loss: 6.711343]\n",
      "epoch:42 step:33310 [D loss: 0.527498, acc: 65.62%] [G loss: 3.034187]\n",
      "epoch:42 step:33311 [D loss: 0.055607, acc: 100.00%] [G loss: 3.888977]\n",
      "epoch:42 step:33312 [D loss: 1.031611, acc: 50.00%] [G loss: 6.734555]\n",
      "epoch:42 step:33313 [D loss: 0.197257, acc: 94.53%] [G loss: 10.125404]\n",
      "epoch:42 step:33314 [D loss: 0.226460, acc: 96.09%] [G loss: 5.622484]\n",
      "epoch:42 step:33315 [D loss: 0.175172, acc: 95.31%] [G loss: 5.682321]\n",
      "epoch:42 step:33316 [D loss: 0.149040, acc: 99.22%] [G loss: 3.138687]\n",
      "epoch:42 step:33317 [D loss: 0.338349, acc: 93.75%] [G loss: 4.726573]\n",
      "epoch:42 step:33318 [D loss: 0.251957, acc: 94.53%] [G loss: 6.885585]\n",
      "epoch:42 step:33319 [D loss: 0.042977, acc: 100.00%] [G loss: 8.637223]\n",
      "epoch:42 step:33320 [D loss: 0.057366, acc: 100.00%] [G loss: 7.435019]\n",
      "epoch:42 step:33321 [D loss: 0.228104, acc: 95.31%] [G loss: 5.082690]\n",
      "epoch:42 step:33322 [D loss: 0.255069, acc: 95.31%] [G loss: 4.023691]\n",
      "epoch:42 step:33323 [D loss: 0.831959, acc: 42.97%] [G loss: 5.939185]\n",
      "epoch:42 step:33324 [D loss: 0.111113, acc: 99.22%] [G loss: 5.286891]\n",
      "epoch:42 step:33325 [D loss: 0.449049, acc: 77.34%] [G loss: 7.330615]\n",
      "epoch:42 step:33326 [D loss: 0.080395, acc: 100.00%] [G loss: 5.466250]\n",
      "epoch:42 step:33327 [D loss: 0.416852, acc: 88.28%] [G loss: 2.864746]\n",
      "epoch:42 step:33328 [D loss: 0.141810, acc: 97.66%] [G loss: 4.704779]\n",
      "epoch:42 step:33329 [D loss: 0.326520, acc: 82.03%] [G loss: 5.220870]\n",
      "epoch:42 step:33330 [D loss: 0.297847, acc: 92.19%] [G loss: 5.371291]\n",
      "epoch:42 step:33331 [D loss: 0.555426, acc: 59.38%] [G loss: 6.642024]\n",
      "epoch:42 step:33332 [D loss: 0.083227, acc: 100.00%] [G loss: 4.069512]\n",
      "epoch:42 step:33333 [D loss: 0.550527, acc: 58.59%] [G loss: 8.353292]\n",
      "epoch:42 step:33334 [D loss: 0.235802, acc: 97.66%] [G loss: 7.586957]\n",
      "epoch:42 step:33335 [D loss: 0.170180, acc: 97.66%] [G loss: 2.791277]\n",
      "epoch:42 step:33336 [D loss: 0.167957, acc: 99.22%] [G loss: 4.381094]\n",
      "epoch:42 step:33337 [D loss: 0.479587, acc: 64.06%] [G loss: 7.617039]\n",
      "epoch:42 step:33338 [D loss: 0.306230, acc: 93.75%] [G loss: 7.754726]\n",
      "epoch:42 step:33339 [D loss: 1.085690, acc: 50.00%] [G loss: 7.685222]\n",
      "epoch:42 step:33340 [D loss: 0.083307, acc: 100.00%] [G loss: 7.703884]\n",
      "epoch:42 step:33341 [D loss: 0.117520, acc: 99.22%] [G loss: 6.897664]\n",
      "epoch:42 step:33342 [D loss: 0.124984, acc: 99.22%] [G loss: 5.368380]\n",
      "epoch:42 step:33343 [D loss: 0.031790, acc: 100.00%] [G loss: 3.837117]\n",
      "epoch:42 step:33344 [D loss: 0.047439, acc: 99.22%] [G loss: 6.915531]\n",
      "epoch:42 step:33345 [D loss: 0.701512, acc: 54.69%] [G loss: 5.441436]\n",
      "epoch:42 step:33346 [D loss: 0.466840, acc: 74.22%] [G loss: 6.173648]\n",
      "epoch:42 step:33347 [D loss: 0.085803, acc: 100.00%] [G loss: 7.376774]\n",
      "epoch:42 step:33348 [D loss: 0.607602, acc: 64.06%] [G loss: 5.910315]\n",
      "epoch:42 step:33349 [D loss: 0.140966, acc: 98.44%] [G loss: 6.776151]\n",
      "epoch:42 step:33350 [D loss: 0.472510, acc: 77.34%] [G loss: 3.871371]\n",
      "epoch:42 step:33351 [D loss: 0.435294, acc: 87.50%] [G loss: 7.078009]\n",
      "epoch:42 step:33352 [D loss: 0.158381, acc: 96.88%] [G loss: 5.686875]\n",
      "epoch:42 step:33353 [D loss: 0.395873, acc: 77.34%] [G loss: 7.205265]\n",
      "epoch:42 step:33354 [D loss: 0.341815, acc: 90.62%] [G loss: 6.671638]\n",
      "epoch:42 step:33355 [D loss: 1.562077, acc: 7.03%] [G loss: 7.589016]\n",
      "epoch:42 step:33356 [D loss: 0.360261, acc: 88.28%] [G loss: 5.306516]\n",
      "epoch:42 step:33357 [D loss: 0.183410, acc: 98.44%] [G loss: 6.850874]\n",
      "epoch:42 step:33358 [D loss: 0.332230, acc: 84.38%] [G loss: 7.043196]\n",
      "epoch:42 step:33359 [D loss: 0.110967, acc: 99.22%] [G loss: 4.935666]\n",
      "epoch:42 step:33360 [D loss: 0.149310, acc: 99.22%] [G loss: 3.197827]\n",
      "epoch:42 step:33361 [D loss: 0.204731, acc: 93.75%] [G loss: 6.735562]\n",
      "epoch:42 step:33362 [D loss: 0.103730, acc: 100.00%] [G loss: 6.419499]\n",
      "epoch:42 step:33363 [D loss: 0.246055, acc: 92.19%] [G loss: 7.545429]\n",
      "epoch:42 step:33364 [D loss: 0.541447, acc: 65.62%] [G loss: 3.102465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33365 [D loss: 0.473677, acc: 65.62%] [G loss: 5.186619]\n",
      "epoch:42 step:33366 [D loss: 0.087445, acc: 100.00%] [G loss: 6.427825]\n",
      "epoch:42 step:33367 [D loss: 0.707280, acc: 57.81%] [G loss: 4.842459]\n",
      "epoch:42 step:33368 [D loss: 0.149937, acc: 98.44%] [G loss: 4.078974]\n",
      "epoch:42 step:33369 [D loss: 0.205000, acc: 95.31%] [G loss: 6.417089]\n",
      "epoch:42 step:33370 [D loss: 0.039572, acc: 100.00%] [G loss: 4.203003]\n",
      "epoch:42 step:33371 [D loss: 0.227014, acc: 96.09%] [G loss: 7.411216]\n",
      "epoch:42 step:33372 [D loss: 0.406703, acc: 82.03%] [G loss: 5.934215]\n",
      "epoch:42 step:33373 [D loss: 0.753259, acc: 53.91%] [G loss: 4.218816]\n",
      "epoch:42 step:33374 [D loss: 0.099660, acc: 100.00%] [G loss: 5.629676]\n",
      "epoch:42 step:33375 [D loss: 0.608858, acc: 57.03%] [G loss: 8.611966]\n",
      "epoch:42 step:33376 [D loss: 0.072996, acc: 100.00%] [G loss: 7.153861]\n",
      "epoch:42 step:33377 [D loss: 0.095035, acc: 99.22%] [G loss: 7.700189]\n",
      "epoch:42 step:33378 [D loss: 1.019685, acc: 50.00%] [G loss: 4.807213]\n",
      "epoch:42 step:33379 [D loss: 0.203195, acc: 96.09%] [G loss: 5.854751]\n",
      "epoch:42 step:33380 [D loss: 0.148917, acc: 100.00%] [G loss: 10.534657]\n",
      "epoch:42 step:33381 [D loss: 0.165316, acc: 97.66%] [G loss: 4.486532]\n",
      "epoch:42 step:33382 [D loss: 0.833181, acc: 51.56%] [G loss: 8.447578]\n",
      "epoch:42 step:33383 [D loss: 0.564127, acc: 57.81%] [G loss: 11.135654]\n",
      "epoch:42 step:33384 [D loss: 0.146707, acc: 99.22%] [G loss: 3.340230]\n",
      "epoch:42 step:33385 [D loss: 0.065877, acc: 100.00%] [G loss: 5.159293]\n",
      "epoch:42 step:33386 [D loss: 0.462368, acc: 81.25%] [G loss: 5.133623]\n",
      "epoch:42 step:33387 [D loss: 0.023996, acc: 100.00%] [G loss: 9.303754]\n",
      "epoch:42 step:33388 [D loss: 0.163856, acc: 95.31%] [G loss: 5.592136]\n",
      "epoch:42 step:33389 [D loss: 0.943748, acc: 50.78%] [G loss: 8.596544]\n",
      "epoch:42 step:33390 [D loss: 0.551073, acc: 62.50%] [G loss: 5.693897]\n",
      "epoch:42 step:33391 [D loss: 0.945638, acc: 43.75%] [G loss: 10.904306]\n",
      "epoch:42 step:33392 [D loss: 0.385587, acc: 78.91%] [G loss: 4.160869]\n",
      "epoch:42 step:33393 [D loss: 0.340868, acc: 85.16%] [G loss: 7.458988]\n",
      "epoch:42 step:33394 [D loss: 0.319586, acc: 84.38%] [G loss: 7.485292]\n",
      "epoch:42 step:33395 [D loss: 0.032777, acc: 100.00%] [G loss: 3.590388]\n",
      "epoch:42 step:33396 [D loss: 0.081695, acc: 100.00%] [G loss: 5.331373]\n",
      "epoch:42 step:33397 [D loss: 0.111032, acc: 100.00%] [G loss: 3.852816]\n",
      "epoch:42 step:33398 [D loss: 0.045197, acc: 100.00%] [G loss: 5.032488]\n",
      "epoch:42 step:33399 [D loss: 0.332859, acc: 92.19%] [G loss: 6.752141]\n",
      "epoch:42 step:33400 [D loss: 0.036891, acc: 100.00%] [G loss: 4.885729]\n",
      "epoch:42 step:33401 [D loss: 0.426540, acc: 85.16%] [G loss: 3.382452]\n",
      "epoch:42 step:33402 [D loss: 0.070758, acc: 100.00%] [G loss: 6.503630]\n",
      "epoch:42 step:33403 [D loss: 0.783385, acc: 43.75%] [G loss: 8.220868]\n",
      "epoch:42 step:33404 [D loss: 0.384851, acc: 78.12%] [G loss: 4.543987]\n",
      "epoch:42 step:33405 [D loss: 0.149403, acc: 97.66%] [G loss: 3.979752]\n",
      "epoch:42 step:33406 [D loss: 0.508618, acc: 67.97%] [G loss: 5.448206]\n",
      "epoch:42 step:33407 [D loss: 0.422889, acc: 82.81%] [G loss: 9.533237]\n",
      "epoch:42 step:33408 [D loss: 0.078542, acc: 100.00%] [G loss: 2.457665]\n",
      "epoch:42 step:33409 [D loss: 0.376781, acc: 89.06%] [G loss: 6.808691]\n",
      "epoch:42 step:33410 [D loss: 0.081691, acc: 100.00%] [G loss: 5.563618]\n",
      "epoch:42 step:33411 [D loss: 0.158936, acc: 98.44%] [G loss: 4.747188]\n",
      "epoch:42 step:33412 [D loss: 0.212784, acc: 96.88%] [G loss: 5.715584]\n",
      "epoch:42 step:33413 [D loss: 0.058179, acc: 100.00%] [G loss: 4.588202]\n",
      "epoch:42 step:33414 [D loss: 0.249366, acc: 96.09%] [G loss: 6.184941]\n",
      "epoch:42 step:33415 [D loss: 0.095899, acc: 100.00%] [G loss: 2.435803]\n",
      "epoch:42 step:33416 [D loss: 0.025673, acc: 100.00%] [G loss: 4.005978]\n",
      "epoch:42 step:33417 [D loss: 1.240942, acc: 18.75%] [G loss: 6.748072]\n",
      "epoch:42 step:33418 [D loss: 0.125275, acc: 99.22%] [G loss: 9.369995]\n",
      "epoch:42 step:33419 [D loss: 0.196619, acc: 96.88%] [G loss: 5.517776]\n",
      "epoch:42 step:33420 [D loss: 0.275302, acc: 85.94%] [G loss: 3.817585]\n",
      "epoch:42 step:33421 [D loss: 0.657524, acc: 59.38%] [G loss: 3.327511]\n",
      "epoch:42 step:33422 [D loss: 0.236160, acc: 95.31%] [G loss: 4.599804]\n",
      "epoch:42 step:33423 [D loss: 0.127918, acc: 99.22%] [G loss: 4.229229]\n",
      "epoch:42 step:33424 [D loss: 0.511507, acc: 71.09%] [G loss: 5.640309]\n",
      "epoch:42 step:33425 [D loss: 0.216301, acc: 95.31%] [G loss: 3.669870]\n",
      "epoch:42 step:33426 [D loss: 0.005813, acc: 100.00%] [G loss: 5.655581]\n",
      "epoch:42 step:33427 [D loss: 0.089563, acc: 99.22%] [G loss: 7.562814]\n",
      "epoch:42 step:33428 [D loss: 0.558239, acc: 70.31%] [G loss: 3.592221]\n",
      "epoch:42 step:33429 [D loss: 0.200901, acc: 97.66%] [G loss: 5.058165]\n",
      "epoch:42 step:33430 [D loss: 0.028602, acc: 100.00%] [G loss: 5.010634]\n",
      "epoch:42 step:33431 [D loss: 0.435700, acc: 73.44%] [G loss: 6.840882]\n",
      "epoch:42 step:33432 [D loss: 0.217631, acc: 96.09%] [G loss: 7.008619]\n",
      "epoch:42 step:33433 [D loss: 0.091831, acc: 100.00%] [G loss: 5.674186]\n",
      "epoch:42 step:33434 [D loss: 0.399599, acc: 77.34%] [G loss: 6.180466]\n",
      "epoch:42 step:33435 [D loss: 1.434220, acc: 50.00%] [G loss: 4.361737]\n",
      "epoch:42 step:33436 [D loss: 0.432021, acc: 75.00%] [G loss: 7.398603]\n",
      "epoch:42 step:33437 [D loss: 0.073658, acc: 100.00%] [G loss: 6.157813]\n",
      "epoch:42 step:33438 [D loss: 0.060221, acc: 99.22%] [G loss: 4.950766]\n",
      "epoch:42 step:33439 [D loss: 0.055462, acc: 100.00%] [G loss: 3.911393]\n",
      "epoch:42 step:33440 [D loss: 0.519112, acc: 66.41%] [G loss: 7.226324]\n",
      "epoch:42 step:33441 [D loss: 0.519101, acc: 67.19%] [G loss: 5.209289]\n",
      "epoch:42 step:33442 [D loss: 0.908272, acc: 47.66%] [G loss: 6.526380]\n",
      "epoch:42 step:33443 [D loss: 0.377903, acc: 88.28%] [G loss: 2.168289]\n",
      "epoch:42 step:33444 [D loss: 0.749963, acc: 54.69%] [G loss: 7.246142]\n",
      "epoch:42 step:33445 [D loss: 0.254565, acc: 95.31%] [G loss: 4.605382]\n",
      "epoch:42 step:33446 [D loss: 1.717408, acc: 50.00%] [G loss: 6.986913]\n",
      "epoch:42 step:33447 [D loss: 0.302629, acc: 86.72%] [G loss: 8.441980]\n",
      "epoch:42 step:33448 [D loss: 0.754349, acc: 56.25%] [G loss: 3.913488]\n",
      "epoch:42 step:33449 [D loss: 0.156661, acc: 96.88%] [G loss: 6.661734]\n",
      "epoch:42 step:33450 [D loss: 0.178166, acc: 96.88%] [G loss: 6.227181]\n",
      "epoch:42 step:33451 [D loss: 0.117059, acc: 100.00%] [G loss: 5.485123]\n",
      "epoch:42 step:33452 [D loss: 0.249350, acc: 93.75%] [G loss: 6.441074]\n",
      "epoch:42 step:33453 [D loss: 0.400782, acc: 90.62%] [G loss: 6.118157]\n",
      "epoch:42 step:33454 [D loss: 0.157015, acc: 97.66%] [G loss: 6.858615]\n",
      "epoch:42 step:33455 [D loss: 0.142879, acc: 99.22%] [G loss: 7.140242]\n",
      "epoch:42 step:33456 [D loss: 0.571066, acc: 69.53%] [G loss: 4.619920]\n",
      "epoch:42 step:33457 [D loss: 0.643858, acc: 66.41%] [G loss: 8.977445]\n",
      "epoch:42 step:33458 [D loss: 0.046352, acc: 100.00%] [G loss: 6.275875]\n",
      "epoch:42 step:33459 [D loss: 0.150905, acc: 99.22%] [G loss: 5.620753]\n",
      "epoch:42 step:33460 [D loss: 0.256545, acc: 91.41%] [G loss: 3.547645]\n",
      "epoch:42 step:33461 [D loss: 0.295326, acc: 89.06%] [G loss: 7.076324]\n",
      "epoch:42 step:33462 [D loss: 0.285158, acc: 84.38%] [G loss: 4.578083]\n",
      "epoch:42 step:33463 [D loss: 0.645470, acc: 64.06%] [G loss: 5.794276]\n",
      "epoch:42 step:33464 [D loss: 0.304206, acc: 85.94%] [G loss: 4.367923]\n",
      "epoch:42 step:33465 [D loss: 0.322475, acc: 95.31%] [G loss: 6.309882]\n",
      "epoch:42 step:33466 [D loss: 0.755462, acc: 56.25%] [G loss: 4.936604]\n",
      "epoch:42 step:33467 [D loss: 0.222323, acc: 93.75%] [G loss: 7.141378]\n",
      "epoch:42 step:33468 [D loss: 0.305024, acc: 91.41%] [G loss: 7.128317]\n",
      "epoch:42 step:33469 [D loss: 0.008278, acc: 100.00%] [G loss: 8.102331]\n",
      "epoch:42 step:33470 [D loss: 0.415979, acc: 73.44%] [G loss: 6.543115]\n",
      "epoch:42 step:33471 [D loss: 0.109243, acc: 99.22%] [G loss: 8.221857]\n",
      "epoch:42 step:33472 [D loss: 0.383177, acc: 73.44%] [G loss: 3.648481]\n",
      "epoch:42 step:33473 [D loss: 0.059408, acc: 100.00%] [G loss: 5.676551]\n",
      "epoch:42 step:33474 [D loss: 0.104927, acc: 100.00%] [G loss: 5.892023]\n",
      "epoch:42 step:33475 [D loss: 0.157871, acc: 99.22%] [G loss: 5.747617]\n",
      "epoch:42 step:33476 [D loss: 0.079645, acc: 100.00%] [G loss: 7.904414]\n",
      "epoch:42 step:33477 [D loss: 0.019499, acc: 100.00%] [G loss: 4.674409]\n",
      "epoch:42 step:33478 [D loss: 0.103879, acc: 99.22%] [G loss: 6.654282]\n",
      "epoch:42 step:33479 [D loss: 0.074481, acc: 100.00%] [G loss: 6.764108]\n",
      "epoch:42 step:33480 [D loss: 0.222486, acc: 98.44%] [G loss: 5.552537]\n",
      "epoch:42 step:33481 [D loss: 1.378392, acc: 11.72%] [G loss: 7.670395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33482 [D loss: 0.192892, acc: 93.75%] [G loss: 3.107709]\n",
      "epoch:42 step:33483 [D loss: 0.455256, acc: 78.91%] [G loss: 2.588785]\n",
      "epoch:42 step:33484 [D loss: 0.242118, acc: 92.19%] [G loss: 6.314334]\n",
      "epoch:42 step:33485 [D loss: 0.019847, acc: 100.00%] [G loss: 9.148535]\n",
      "epoch:42 step:33486 [D loss: 0.385224, acc: 75.78%] [G loss: 6.400993]\n",
      "epoch:42 step:33487 [D loss: 0.675200, acc: 57.81%] [G loss: 6.822667]\n",
      "epoch:42 step:33488 [D loss: 0.363469, acc: 86.72%] [G loss: 3.684344]\n",
      "epoch:42 step:33489 [D loss: 0.248161, acc: 95.31%] [G loss: 2.427820]\n",
      "epoch:42 step:33490 [D loss: 0.506302, acc: 82.03%] [G loss: 8.159059]\n",
      "epoch:42 step:33491 [D loss: 0.348835, acc: 90.62%] [G loss: 5.182244]\n",
      "epoch:42 step:33492 [D loss: 0.095752, acc: 98.44%] [G loss: 5.837893]\n",
      "epoch:42 step:33493 [D loss: 0.117269, acc: 100.00%] [G loss: 6.377577]\n",
      "epoch:42 step:33494 [D loss: 0.708496, acc: 57.03%] [G loss: 7.978342]\n",
      "epoch:42 step:33495 [D loss: 0.056332, acc: 100.00%] [G loss: 7.014396]\n",
      "epoch:42 step:33496 [D loss: 0.081409, acc: 100.00%] [G loss: 5.034209]\n",
      "epoch:42 step:33497 [D loss: 0.226090, acc: 92.19%] [G loss: 4.462260]\n",
      "epoch:42 step:33498 [D loss: 0.073806, acc: 100.00%] [G loss: 7.188233]\n",
      "epoch:42 step:33499 [D loss: 0.151086, acc: 97.66%] [G loss: 5.303645]\n",
      "epoch:42 step:33500 [D loss: 0.050091, acc: 100.00%] [G loss: 6.833563]\n",
      "epoch:42 step:33501 [D loss: 0.533012, acc: 66.41%] [G loss: 3.628898]\n",
      "epoch:42 step:33502 [D loss: 0.097476, acc: 100.00%] [G loss: 3.970987]\n",
      "epoch:42 step:33503 [D loss: 0.349379, acc: 80.47%] [G loss: 6.371312]\n",
      "epoch:42 step:33504 [D loss: 0.083352, acc: 100.00%] [G loss: 3.897882]\n",
      "epoch:42 step:33505 [D loss: 0.929164, acc: 49.22%] [G loss: 4.265249]\n",
      "epoch:42 step:33506 [D loss: 0.266023, acc: 88.28%] [G loss: 3.194020]\n",
      "epoch:42 step:33507 [D loss: 0.073583, acc: 100.00%] [G loss: 8.810911]\n",
      "epoch:42 step:33508 [D loss: 0.669364, acc: 60.16%] [G loss: 4.860879]\n",
      "epoch:42 step:33509 [D loss: 0.015277, acc: 100.00%] [G loss: 7.492491]\n",
      "epoch:42 step:33510 [D loss: 0.046144, acc: 100.00%] [G loss: 4.084654]\n",
      "epoch:42 step:33511 [D loss: 0.015285, acc: 100.00%] [G loss: 6.644729]\n",
      "epoch:42 step:33512 [D loss: 0.753309, acc: 53.91%] [G loss: 2.931265]\n",
      "epoch:42 step:33513 [D loss: 0.014448, acc: 100.00%] [G loss: 10.073904]\n",
      "epoch:42 step:33514 [D loss: 0.053445, acc: 100.00%] [G loss: 5.923935]\n",
      "epoch:42 step:33515 [D loss: 0.024135, acc: 100.00%] [G loss: 3.925877]\n",
      "epoch:42 step:33516 [D loss: 0.128831, acc: 100.00%] [G loss: 5.572055]\n",
      "epoch:42 step:33517 [D loss: 0.073895, acc: 100.00%] [G loss: 4.647248]\n",
      "epoch:42 step:33518 [D loss: 0.142381, acc: 97.66%] [G loss: 8.652522]\n",
      "epoch:42 step:33519 [D loss: 0.047201, acc: 100.00%] [G loss: 5.750647]\n",
      "epoch:42 step:33520 [D loss: 0.187213, acc: 93.75%] [G loss: 6.350323]\n",
      "epoch:42 step:33521 [D loss: 0.362261, acc: 90.62%] [G loss: 5.631848]\n",
      "epoch:42 step:33522 [D loss: 0.085681, acc: 100.00%] [G loss: 4.620023]\n",
      "epoch:42 step:33523 [D loss: 0.180918, acc: 98.44%] [G loss: 7.041501]\n",
      "epoch:42 step:33524 [D loss: 0.481848, acc: 73.44%] [G loss: 4.453922]\n",
      "epoch:42 step:33525 [D loss: 0.075467, acc: 100.00%] [G loss: 5.641595]\n",
      "epoch:42 step:33526 [D loss: 0.175245, acc: 96.88%] [G loss: 3.787393]\n",
      "epoch:42 step:33527 [D loss: 0.100237, acc: 99.22%] [G loss: 5.879796]\n",
      "epoch:42 step:33528 [D loss: 0.224250, acc: 96.09%] [G loss: 6.695322]\n",
      "epoch:42 step:33529 [D loss: 0.402741, acc: 88.28%] [G loss: 3.641841]\n",
      "epoch:42 step:33530 [D loss: 0.317475, acc: 88.28%] [G loss: 7.195149]\n",
      "epoch:42 step:33531 [D loss: 0.044610, acc: 100.00%] [G loss: 3.208810]\n",
      "epoch:42 step:33532 [D loss: 0.795234, acc: 48.44%] [G loss: 7.744170]\n",
      "epoch:42 step:33533 [D loss: 0.303880, acc: 87.50%] [G loss: 4.874469]\n",
      "epoch:42 step:33534 [D loss: 0.354703, acc: 89.84%] [G loss: 5.352655]\n",
      "epoch:42 step:33535 [D loss: 0.257199, acc: 91.41%] [G loss: 9.068062]\n",
      "epoch:42 step:33536 [D loss: 1.238199, acc: 29.69%] [G loss: 8.210686]\n",
      "epoch:42 step:33537 [D loss: 0.044997, acc: 100.00%] [G loss: 5.642034]\n",
      "epoch:42 step:33538 [D loss: 0.491885, acc: 70.31%] [G loss: 1.338529]\n",
      "epoch:42 step:33539 [D loss: 1.610447, acc: 14.06%] [G loss: 6.711901]\n",
      "epoch:42 step:33540 [D loss: 0.324186, acc: 84.38%] [G loss: 4.533937]\n",
      "epoch:42 step:33541 [D loss: 0.513094, acc: 74.22%] [G loss: 6.617326]\n",
      "epoch:42 step:33542 [D loss: 0.445299, acc: 73.44%] [G loss: 6.368805]\n",
      "epoch:42 step:33543 [D loss: 0.084018, acc: 100.00%] [G loss: 7.075815]\n",
      "epoch:42 step:33544 [D loss: 0.252546, acc: 89.84%] [G loss: 8.344840]\n",
      "epoch:42 step:33545 [D loss: 0.195219, acc: 96.88%] [G loss: 5.171730]\n",
      "epoch:42 step:33546 [D loss: 0.381082, acc: 90.62%] [G loss: 6.465269]\n",
      "epoch:42 step:33547 [D loss: 0.094359, acc: 99.22%] [G loss: 5.850042]\n",
      "epoch:42 step:33548 [D loss: 0.279353, acc: 86.72%] [G loss: 7.301028]\n",
      "epoch:42 step:33549 [D loss: 0.156890, acc: 98.44%] [G loss: 5.121133]\n",
      "epoch:42 step:33550 [D loss: 0.189276, acc: 95.31%] [G loss: 5.059669]\n",
      "epoch:42 step:33551 [D loss: 0.440454, acc: 67.97%] [G loss: 4.795437]\n",
      "epoch:42 step:33552 [D loss: 0.633731, acc: 61.72%] [G loss: 3.787150]\n",
      "epoch:42 step:33553 [D loss: 0.110484, acc: 100.00%] [G loss: 3.554394]\n",
      "epoch:42 step:33554 [D loss: 0.742234, acc: 53.91%] [G loss: 10.879404]\n",
      "epoch:42 step:33555 [D loss: 0.485722, acc: 64.06%] [G loss: 4.518891]\n",
      "epoch:42 step:33556 [D loss: 0.290839, acc: 94.53%] [G loss: 10.938302]\n",
      "epoch:42 step:33557 [D loss: 0.215113, acc: 94.53%] [G loss: 4.698845]\n",
      "epoch:42 step:33558 [D loss: 0.091798, acc: 99.22%] [G loss: 7.527122]\n",
      "epoch:42 step:33559 [D loss: 0.096940, acc: 99.22%] [G loss: 5.502629]\n",
      "epoch:42 step:33560 [D loss: 0.125877, acc: 100.00%] [G loss: 5.358100]\n",
      "epoch:42 step:33561 [D loss: 0.224852, acc: 92.97%] [G loss: 2.714937]\n",
      "epoch:42 step:33562 [D loss: 0.008538, acc: 100.00%] [G loss: 7.414907]\n",
      "epoch:42 step:33563 [D loss: 0.261431, acc: 95.31%] [G loss: 7.685821]\n",
      "epoch:42 step:33564 [D loss: 0.446206, acc: 65.62%] [G loss: 6.172828]\n",
      "epoch:42 step:33565 [D loss: 0.099079, acc: 100.00%] [G loss: 5.707935]\n",
      "epoch:42 step:33566 [D loss: 0.029278, acc: 100.00%] [G loss: 7.207249]\n",
      "epoch:42 step:33567 [D loss: 0.319870, acc: 80.47%] [G loss: 4.405813]\n",
      "epoch:42 step:33568 [D loss: 0.643399, acc: 57.81%] [G loss: 5.740000]\n",
      "epoch:42 step:33569 [D loss: 0.141072, acc: 99.22%] [G loss: 5.268870]\n",
      "epoch:42 step:33570 [D loss: 0.099400, acc: 99.22%] [G loss: 8.497685]\n",
      "epoch:42 step:33571 [D loss: 0.188838, acc: 94.53%] [G loss: 4.333900]\n",
      "epoch:42 step:33572 [D loss: 0.275942, acc: 96.88%] [G loss: 7.123313]\n",
      "epoch:42 step:33573 [D loss: 0.445103, acc: 78.91%] [G loss: 6.662044]\n",
      "epoch:42 step:33574 [D loss: 0.135609, acc: 98.44%] [G loss: 3.558523]\n",
      "epoch:42 step:33575 [D loss: 0.356260, acc: 78.91%] [G loss: 10.832510]\n",
      "epoch:42 step:33576 [D loss: 0.189369, acc: 96.88%] [G loss: 4.729905]\n",
      "epoch:42 step:33577 [D loss: 0.156424, acc: 97.66%] [G loss: 7.933565]\n",
      "epoch:42 step:33578 [D loss: 0.302663, acc: 94.53%] [G loss: 5.476763]\n",
      "epoch:42 step:33579 [D loss: 0.106556, acc: 100.00%] [G loss: 2.913374]\n",
      "epoch:42 step:33580 [D loss: 0.710012, acc: 57.03%] [G loss: 6.627605]\n",
      "epoch:42 step:33581 [D loss: 0.079898, acc: 100.00%] [G loss: 6.722867]\n",
      "epoch:42 step:33582 [D loss: 0.276124, acc: 95.31%] [G loss: 5.188049]\n",
      "epoch:42 step:33583 [D loss: 0.510841, acc: 72.66%] [G loss: 5.207406]\n",
      "epoch:43 step:33584 [D loss: 0.041221, acc: 100.00%] [G loss: 7.384983]\n",
      "epoch:43 step:33585 [D loss: 0.138631, acc: 99.22%] [G loss: 2.038610]\n",
      "epoch:43 step:33586 [D loss: 0.132889, acc: 96.88%] [G loss: 5.535429]\n",
      "epoch:43 step:33587 [D loss: 0.097784, acc: 100.00%] [G loss: 5.872950]\n",
      "epoch:43 step:33588 [D loss: 0.201011, acc: 97.66%] [G loss: 9.281658]\n",
      "epoch:43 step:33589 [D loss: 0.183603, acc: 95.31%] [G loss: 4.670584]\n",
      "epoch:43 step:33590 [D loss: 0.245454, acc: 91.41%] [G loss: 6.004134]\n",
      "epoch:43 step:33591 [D loss: 0.183276, acc: 99.22%] [G loss: 4.509676]\n",
      "epoch:43 step:33592 [D loss: 0.429930, acc: 72.66%] [G loss: 7.611020]\n",
      "epoch:43 step:33593 [D loss: 0.102531, acc: 100.00%] [G loss: 4.623647]\n",
      "epoch:43 step:33594 [D loss: 0.414681, acc: 72.66%] [G loss: 10.050964]\n",
      "epoch:43 step:33595 [D loss: 0.209849, acc: 97.66%] [G loss: 2.074054]\n",
      "epoch:43 step:33596 [D loss: 0.257760, acc: 96.88%] [G loss: 5.562398]\n",
      "epoch:43 step:33597 [D loss: 0.159739, acc: 97.66%] [G loss: 5.699488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33598 [D loss: 0.046093, acc: 100.00%] [G loss: 4.130865]\n",
      "epoch:43 step:33599 [D loss: 0.909578, acc: 38.28%] [G loss: 8.452103]\n",
      "epoch:43 step:33600 [D loss: 0.766061, acc: 47.66%] [G loss: 5.873188]\n",
      "epoch:43 step:33601 [D loss: 0.161390, acc: 96.09%] [G loss: 5.518610]\n",
      "epoch:43 step:33602 [D loss: 0.634400, acc: 64.84%] [G loss: 4.977038]\n",
      "epoch:43 step:33603 [D loss: 0.714121, acc: 57.03%] [G loss: 7.354162]\n",
      "epoch:43 step:33604 [D loss: 0.146565, acc: 99.22%] [G loss: 5.478893]\n",
      "epoch:43 step:33605 [D loss: 0.067048, acc: 100.00%] [G loss: 7.413648]\n",
      "epoch:43 step:33606 [D loss: 0.201515, acc: 95.31%] [G loss: 6.082731]\n",
      "epoch:43 step:33607 [D loss: 0.177701, acc: 98.44%] [G loss: 4.194062]\n",
      "epoch:43 step:33608 [D loss: 0.267262, acc: 93.75%] [G loss: 4.901287]\n",
      "epoch:43 step:33609 [D loss: 1.073012, acc: 50.00%] [G loss: 3.756311]\n",
      "epoch:43 step:33610 [D loss: 0.246419, acc: 94.53%] [G loss: 3.390970]\n",
      "epoch:43 step:33611 [D loss: 0.781328, acc: 51.56%] [G loss: 5.985315]\n",
      "epoch:43 step:33612 [D loss: 0.372856, acc: 77.34%] [G loss: 7.187664]\n",
      "epoch:43 step:33613 [D loss: 0.761842, acc: 53.12%] [G loss: 7.787187]\n",
      "epoch:43 step:33614 [D loss: 0.362761, acc: 79.69%] [G loss: 5.333801]\n",
      "epoch:43 step:33615 [D loss: 0.065639, acc: 100.00%] [G loss: 5.423946]\n",
      "epoch:43 step:33616 [D loss: 0.293665, acc: 89.06%] [G loss: 5.548553]\n",
      "epoch:43 step:33617 [D loss: 0.456532, acc: 72.66%] [G loss: 5.759225]\n",
      "epoch:43 step:33618 [D loss: 1.385749, acc: 50.78%] [G loss: 2.553322]\n",
      "epoch:43 step:33619 [D loss: 0.017075, acc: 100.00%] [G loss: 5.212096]\n",
      "epoch:43 step:33620 [D loss: 0.199264, acc: 95.31%] [G loss: 6.456885]\n",
      "epoch:43 step:33621 [D loss: 0.122056, acc: 98.44%] [G loss: 5.565065]\n",
      "epoch:43 step:33622 [D loss: 0.638979, acc: 57.81%] [G loss: 5.214172]\n",
      "epoch:43 step:33623 [D loss: 0.056366, acc: 100.00%] [G loss: 4.995756]\n",
      "epoch:43 step:33624 [D loss: 0.278561, acc: 89.84%] [G loss: 6.286505]\n",
      "epoch:43 step:33625 [D loss: 0.232585, acc: 96.09%] [G loss: 5.164247]\n",
      "epoch:43 step:33626 [D loss: 0.135005, acc: 99.22%] [G loss: 5.015617]\n",
      "epoch:43 step:33627 [D loss: 0.147669, acc: 99.22%] [G loss: 5.274703]\n",
      "epoch:43 step:33628 [D loss: 0.056561, acc: 100.00%] [G loss: 5.669076]\n",
      "epoch:43 step:33629 [D loss: 0.297820, acc: 83.59%] [G loss: 5.679266]\n",
      "epoch:43 step:33630 [D loss: 0.231343, acc: 99.22%] [G loss: 6.072782]\n",
      "epoch:43 step:33631 [D loss: 0.248961, acc: 90.62%] [G loss: 9.834612]\n",
      "epoch:43 step:33632 [D loss: 0.268637, acc: 93.75%] [G loss: 5.783664]\n",
      "epoch:43 step:33633 [D loss: 0.891333, acc: 41.41%] [G loss: 5.624994]\n",
      "epoch:43 step:33634 [D loss: 0.417670, acc: 77.34%] [G loss: 5.480060]\n",
      "epoch:43 step:33635 [D loss: 0.293978, acc: 95.31%] [G loss: 8.388347]\n",
      "epoch:43 step:33636 [D loss: 0.853877, acc: 51.56%] [G loss: 6.970113]\n",
      "epoch:43 step:33637 [D loss: 0.304644, acc: 78.91%] [G loss: 7.024576]\n",
      "epoch:43 step:33638 [D loss: 0.178438, acc: 98.44%] [G loss: 6.858463]\n",
      "epoch:43 step:33639 [D loss: 0.657289, acc: 62.50%] [G loss: 8.535538]\n",
      "epoch:43 step:33640 [D loss: 0.431386, acc: 82.03%] [G loss: 6.042518]\n",
      "epoch:43 step:33641 [D loss: 0.289613, acc: 93.75%] [G loss: 3.419992]\n",
      "epoch:43 step:33642 [D loss: 0.137931, acc: 98.44%] [G loss: 4.767308]\n",
      "epoch:43 step:33643 [D loss: 0.358917, acc: 84.38%] [G loss: 3.379930]\n",
      "epoch:43 step:33644 [D loss: 1.119137, acc: 44.53%] [G loss: 5.294555]\n",
      "epoch:43 step:33645 [D loss: 0.403280, acc: 74.22%] [G loss: 9.999352]\n",
      "epoch:43 step:33646 [D loss: 0.137005, acc: 99.22%] [G loss: 1.581192]\n",
      "epoch:43 step:33647 [D loss: 0.023831, acc: 100.00%] [G loss: 6.387297]\n",
      "epoch:43 step:33648 [D loss: 2.866200, acc: 34.38%] [G loss: 7.433623]\n",
      "epoch:43 step:33649 [D loss: 0.235692, acc: 92.97%] [G loss: 6.118819]\n",
      "epoch:43 step:33650 [D loss: 0.178996, acc: 97.66%] [G loss: 5.404271]\n",
      "epoch:43 step:33651 [D loss: 0.662047, acc: 57.81%] [G loss: 4.611696]\n",
      "epoch:43 step:33652 [D loss: 0.010119, acc: 100.00%] [G loss: 7.891568]\n",
      "epoch:43 step:33653 [D loss: 0.380546, acc: 77.34%] [G loss: 8.154413]\n",
      "epoch:43 step:33654 [D loss: 0.657462, acc: 57.81%] [G loss: 6.018497]\n",
      "epoch:43 step:33655 [D loss: 0.062403, acc: 100.00%] [G loss: 6.370995]\n",
      "epoch:43 step:33656 [D loss: 0.138505, acc: 96.88%] [G loss: 8.048996]\n",
      "epoch:43 step:33657 [D loss: 0.094826, acc: 100.00%] [G loss: 4.075909]\n",
      "epoch:43 step:33658 [D loss: 0.117765, acc: 98.44%] [G loss: 5.309096]\n",
      "epoch:43 step:33659 [D loss: 0.267785, acc: 95.31%] [G loss: 8.311511]\n",
      "epoch:43 step:33660 [D loss: 0.094267, acc: 100.00%] [G loss: 5.305757]\n",
      "epoch:43 step:33661 [D loss: 0.134740, acc: 96.88%] [G loss: 3.724751]\n",
      "epoch:43 step:33662 [D loss: 0.927708, acc: 50.78%] [G loss: 6.721429]\n",
      "epoch:43 step:33663 [D loss: 0.703909, acc: 54.69%] [G loss: 6.748686]\n",
      "epoch:43 step:33664 [D loss: 0.521964, acc: 72.66%] [G loss: 6.895858]\n",
      "epoch:43 step:33665 [D loss: 0.062584, acc: 100.00%] [G loss: 7.687424]\n",
      "epoch:43 step:33666 [D loss: 0.126628, acc: 99.22%] [G loss: 3.750803]\n",
      "epoch:43 step:33667 [D loss: 0.207406, acc: 97.66%] [G loss: 8.130322]\n",
      "epoch:43 step:33668 [D loss: 0.235290, acc: 98.44%] [G loss: 5.193941]\n",
      "epoch:43 step:33669 [D loss: 0.024471, acc: 100.00%] [G loss: 4.240172]\n",
      "epoch:43 step:33670 [D loss: 0.024629, acc: 100.00%] [G loss: 4.749803]\n",
      "epoch:43 step:33671 [D loss: 0.268157, acc: 89.84%] [G loss: 6.458089]\n",
      "epoch:43 step:33672 [D loss: 0.046050, acc: 100.00%] [G loss: 6.328494]\n",
      "epoch:43 step:33673 [D loss: 0.903082, acc: 34.38%] [G loss: 7.674485]\n",
      "epoch:43 step:33674 [D loss: 0.022205, acc: 100.00%] [G loss: 10.653908]\n",
      "epoch:43 step:33675 [D loss: 0.061967, acc: 100.00%] [G loss: 7.111224]\n",
      "epoch:43 step:33676 [D loss: 0.061859, acc: 100.00%] [G loss: 5.779445]\n",
      "epoch:43 step:33677 [D loss: 0.370753, acc: 77.34%] [G loss: 4.119221]\n",
      "epoch:43 step:33678 [D loss: 0.041248, acc: 100.00%] [G loss: 6.939043]\n",
      "epoch:43 step:33679 [D loss: 0.184582, acc: 97.66%] [G loss: 6.367342]\n",
      "epoch:43 step:33680 [D loss: 0.482041, acc: 67.97%] [G loss: 4.128769]\n",
      "epoch:43 step:33681 [D loss: 0.240128, acc: 98.44%] [G loss: 6.784268]\n",
      "epoch:43 step:33682 [D loss: 0.149160, acc: 97.66%] [G loss: 9.275679]\n",
      "epoch:43 step:33683 [D loss: 0.442940, acc: 85.16%] [G loss: 5.568328]\n",
      "epoch:43 step:33684 [D loss: 0.522562, acc: 77.34%] [G loss: 7.809441]\n",
      "epoch:43 step:33685 [D loss: 0.054161, acc: 100.00%] [G loss: 6.302313]\n",
      "epoch:43 step:33686 [D loss: 0.121098, acc: 99.22%] [G loss: 2.583610]\n",
      "epoch:43 step:33687 [D loss: 0.485959, acc: 69.53%] [G loss: 5.983046]\n",
      "epoch:43 step:33688 [D loss: 0.431360, acc: 85.94%] [G loss: 3.415529]\n",
      "epoch:43 step:33689 [D loss: 0.040504, acc: 100.00%] [G loss: 8.718720]\n",
      "epoch:43 step:33690 [D loss: 1.562793, acc: 21.09%] [G loss: 8.220954]\n",
      "epoch:43 step:33691 [D loss: 0.450467, acc: 71.88%] [G loss: 5.238781]\n",
      "epoch:43 step:33692 [D loss: 0.061055, acc: 100.00%] [G loss: 6.176420]\n",
      "epoch:43 step:33693 [D loss: 0.110915, acc: 99.22%] [G loss: 6.851471]\n",
      "epoch:43 step:33694 [D loss: 0.254459, acc: 91.41%] [G loss: 3.816773]\n",
      "epoch:43 step:33695 [D loss: 0.090125, acc: 100.00%] [G loss: 5.254685]\n",
      "epoch:43 step:33696 [D loss: 0.015434, acc: 100.00%] [G loss: 5.022139]\n",
      "epoch:43 step:33697 [D loss: 0.812256, acc: 50.78%] [G loss: 6.850383]\n",
      "epoch:43 step:33698 [D loss: 0.028067, acc: 100.00%] [G loss: 6.956810]\n",
      "epoch:43 step:33699 [D loss: 0.451117, acc: 83.59%] [G loss: 3.922985]\n",
      "epoch:43 step:33700 [D loss: 0.254455, acc: 93.75%] [G loss: 5.945553]\n",
      "epoch:43 step:33701 [D loss: 0.361338, acc: 86.72%] [G loss: 5.283597]\n",
      "epoch:43 step:33702 [D loss: 0.308375, acc: 83.59%] [G loss: 6.251037]\n",
      "epoch:43 step:33703 [D loss: 0.098967, acc: 100.00%] [G loss: 5.464128]\n",
      "epoch:43 step:33704 [D loss: 0.084444, acc: 100.00%] [G loss: 3.886997]\n",
      "epoch:43 step:33705 [D loss: 0.139829, acc: 97.66%] [G loss: 5.465317]\n",
      "epoch:43 step:33706 [D loss: 0.140060, acc: 100.00%] [G loss: 6.359384]\n",
      "epoch:43 step:33707 [D loss: 0.149841, acc: 99.22%] [G loss: 5.966840]\n",
      "epoch:43 step:33708 [D loss: 0.824476, acc: 50.00%] [G loss: 6.542053]\n",
      "epoch:43 step:33709 [D loss: 0.399058, acc: 76.56%] [G loss: 5.359659]\n",
      "epoch:43 step:33710 [D loss: 1.387189, acc: 50.00%] [G loss: 5.531027]\n",
      "epoch:43 step:33711 [D loss: 0.123550, acc: 100.00%] [G loss: 7.378407]\n",
      "epoch:43 step:33712 [D loss: 0.281496, acc: 86.72%] [G loss: 5.004605]\n",
      "epoch:43 step:33713 [D loss: 0.205889, acc: 92.19%] [G loss: 3.612663]\n",
      "epoch:43 step:33714 [D loss: 1.159826, acc: 22.66%] [G loss: 7.310553]\n",
      "epoch:43 step:33715 [D loss: 0.215514, acc: 98.44%] [G loss: 6.032659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33716 [D loss: 0.733312, acc: 53.91%] [G loss: 5.943688]\n",
      "epoch:43 step:33717 [D loss: 0.231672, acc: 92.19%] [G loss: 7.710887]\n",
      "epoch:43 step:33718 [D loss: 0.596871, acc: 67.19%] [G loss: 12.228352]\n",
      "epoch:43 step:33719 [D loss: 0.627861, acc: 61.72%] [G loss: 5.785515]\n",
      "epoch:43 step:33720 [D loss: 1.036275, acc: 50.00%] [G loss: 9.198558]\n",
      "epoch:43 step:33721 [D loss: 0.146479, acc: 98.44%] [G loss: 3.994380]\n",
      "epoch:43 step:33722 [D loss: 0.470284, acc: 67.97%] [G loss: 5.425426]\n",
      "epoch:43 step:33723 [D loss: 0.264682, acc: 97.66%] [G loss: 4.162475]\n",
      "epoch:43 step:33724 [D loss: 0.784799, acc: 46.88%] [G loss: 4.320907]\n",
      "epoch:43 step:33725 [D loss: 0.388193, acc: 77.34%] [G loss: 7.053256]\n",
      "epoch:43 step:33726 [D loss: 1.037945, acc: 50.78%] [G loss: 8.687941]\n",
      "epoch:43 step:33727 [D loss: 0.295871, acc: 82.81%] [G loss: 7.136086]\n",
      "epoch:43 step:33728 [D loss: 1.884299, acc: 7.81%] [G loss: 6.330811]\n",
      "epoch:43 step:33729 [D loss: 0.030662, acc: 100.00%] [G loss: 3.157421]\n",
      "epoch:43 step:33730 [D loss: 0.809570, acc: 53.91%] [G loss: 7.735013]\n",
      "epoch:43 step:33731 [D loss: 0.536550, acc: 67.19%] [G loss: 4.917521]\n",
      "epoch:43 step:33732 [D loss: 0.102378, acc: 100.00%] [G loss: 5.277473]\n",
      "epoch:43 step:33733 [D loss: 1.016972, acc: 46.88%] [G loss: 2.921643]\n",
      "epoch:43 step:33734 [D loss: 0.504091, acc: 65.62%] [G loss: 6.313803]\n",
      "epoch:43 step:33735 [D loss: 0.318966, acc: 90.62%] [G loss: 5.703731]\n",
      "epoch:43 step:33736 [D loss: 1.095316, acc: 48.44%] [G loss: 4.934562]\n",
      "epoch:43 step:33737 [D loss: 0.415378, acc: 71.88%] [G loss: 5.691202]\n",
      "epoch:43 step:33738 [D loss: 0.215049, acc: 98.44%] [G loss: 6.112695]\n",
      "epoch:43 step:33739 [D loss: 0.163098, acc: 99.22%] [G loss: 2.864041]\n",
      "epoch:43 step:33740 [D loss: 0.753780, acc: 53.12%] [G loss: 7.454763]\n",
      "epoch:43 step:33741 [D loss: 0.870465, acc: 50.78%] [G loss: 6.719545]\n",
      "epoch:43 step:33742 [D loss: 0.059336, acc: 100.00%] [G loss: 5.184065]\n",
      "epoch:43 step:33743 [D loss: 0.255603, acc: 89.84%] [G loss: 6.222096]\n",
      "epoch:43 step:33744 [D loss: 0.464733, acc: 70.31%] [G loss: 11.268640]\n",
      "epoch:43 step:33745 [D loss: 0.190653, acc: 97.66%] [G loss: 7.415337]\n",
      "epoch:43 step:33746 [D loss: 0.248496, acc: 92.19%] [G loss: 5.212562]\n",
      "epoch:43 step:33747 [D loss: 0.739856, acc: 50.78%] [G loss: 6.394056]\n",
      "epoch:43 step:33748 [D loss: 0.100833, acc: 99.22%] [G loss: 7.016411]\n",
      "epoch:43 step:33749 [D loss: 0.081156, acc: 100.00%] [G loss: 6.530914]\n",
      "epoch:43 step:33750 [D loss: 0.128843, acc: 100.00%] [G loss: 5.360169]\n",
      "epoch:43 step:33751 [D loss: 0.320533, acc: 83.59%] [G loss: 6.061729]\n",
      "epoch:43 step:33752 [D loss: 0.951651, acc: 52.34%] [G loss: 6.505661]\n",
      "epoch:43 step:33753 [D loss: 0.492362, acc: 73.44%] [G loss: 6.667308]\n",
      "epoch:43 step:33754 [D loss: 0.567329, acc: 70.31%] [G loss: 7.500218]\n",
      "epoch:43 step:33755 [D loss: 0.487927, acc: 75.00%] [G loss: 2.567270]\n",
      "epoch:43 step:33756 [D loss: 0.629067, acc: 60.94%] [G loss: 5.360543]\n",
      "epoch:43 step:33757 [D loss: 0.938919, acc: 51.56%] [G loss: 6.131922]\n",
      "epoch:43 step:33758 [D loss: 0.018547, acc: 100.00%] [G loss: 8.056210]\n",
      "epoch:43 step:33759 [D loss: 0.447756, acc: 77.34%] [G loss: 8.979063]\n",
      "epoch:43 step:33760 [D loss: 0.415267, acc: 86.72%] [G loss: 7.676198]\n",
      "epoch:43 step:33761 [D loss: 0.410703, acc: 77.34%] [G loss: 4.494689]\n",
      "epoch:43 step:33762 [D loss: 0.711037, acc: 54.69%] [G loss: 5.859965]\n",
      "epoch:43 step:33763 [D loss: 0.534328, acc: 64.84%] [G loss: 5.797882]\n",
      "epoch:43 step:33764 [D loss: 0.098358, acc: 100.00%] [G loss: 5.130726]\n",
      "epoch:43 step:33765 [D loss: 0.086973, acc: 99.22%] [G loss: 8.391748]\n",
      "epoch:43 step:33766 [D loss: 0.139215, acc: 98.44%] [G loss: 5.841930]\n",
      "epoch:43 step:33767 [D loss: 1.169686, acc: 16.41%] [G loss: 6.508775]\n",
      "epoch:43 step:33768 [D loss: 0.083906, acc: 100.00%] [G loss: 2.545632]\n",
      "epoch:43 step:33769 [D loss: 0.887243, acc: 51.56%] [G loss: 3.040659]\n",
      "epoch:43 step:33770 [D loss: 0.220408, acc: 92.97%] [G loss: 6.623092]\n",
      "epoch:43 step:33771 [D loss: 0.067718, acc: 100.00%] [G loss: 5.363838]\n",
      "epoch:43 step:33772 [D loss: 0.030205, acc: 100.00%] [G loss: 3.933430]\n",
      "epoch:43 step:33773 [D loss: 0.354440, acc: 87.50%] [G loss: 5.923118]\n",
      "epoch:43 step:33774 [D loss: 0.375145, acc: 81.25%] [G loss: 5.836518]\n",
      "epoch:43 step:33775 [D loss: 0.072747, acc: 100.00%] [G loss: 3.714446]\n",
      "epoch:43 step:33776 [D loss: 0.070476, acc: 100.00%] [G loss: 4.611558]\n",
      "epoch:43 step:33777 [D loss: 0.629246, acc: 63.28%] [G loss: 5.790453]\n",
      "epoch:43 step:33778 [D loss: 0.431432, acc: 78.12%] [G loss: 6.396898]\n",
      "epoch:43 step:33779 [D loss: 0.350864, acc: 83.59%] [G loss: 6.150333]\n",
      "epoch:43 step:33780 [D loss: 0.179770, acc: 98.44%] [G loss: 4.971977]\n",
      "epoch:43 step:33781 [D loss: 0.032481, acc: 100.00%] [G loss: 7.764915]\n",
      "epoch:43 step:33782 [D loss: 0.285887, acc: 92.19%] [G loss: 5.215323]\n",
      "epoch:43 step:33783 [D loss: 0.234382, acc: 90.62%] [G loss: 5.241322]\n",
      "epoch:43 step:33784 [D loss: 0.134315, acc: 99.22%] [G loss: 6.957978]\n",
      "epoch:43 step:33785 [D loss: 0.297329, acc: 85.94%] [G loss: 6.955381]\n",
      "epoch:43 step:33786 [D loss: 0.511000, acc: 69.53%] [G loss: 4.253984]\n",
      "epoch:43 step:33787 [D loss: 0.346990, acc: 95.31%] [G loss: 6.457031]\n",
      "epoch:43 step:33788 [D loss: 0.550559, acc: 75.00%] [G loss: 4.686379]\n",
      "epoch:43 step:33789 [D loss: 0.876071, acc: 52.34%] [G loss: 3.861066]\n",
      "epoch:43 step:33790 [D loss: 0.656848, acc: 56.25%] [G loss: 4.021472]\n",
      "epoch:43 step:33791 [D loss: 0.175728, acc: 95.31%] [G loss: 6.205220]\n",
      "epoch:43 step:33792 [D loss: 0.976080, acc: 51.56%] [G loss: 2.654973]\n",
      "epoch:43 step:33793 [D loss: 0.993696, acc: 50.78%] [G loss: 5.090372]\n",
      "epoch:43 step:33794 [D loss: 0.242403, acc: 95.31%] [G loss: 4.708563]\n",
      "epoch:43 step:33795 [D loss: 0.039367, acc: 100.00%] [G loss: 4.726467]\n",
      "epoch:43 step:33796 [D loss: 0.416043, acc: 71.88%] [G loss: 4.675777]\n",
      "epoch:43 step:33797 [D loss: 0.330719, acc: 80.47%] [G loss: 3.049855]\n",
      "epoch:43 step:33798 [D loss: 0.419152, acc: 79.69%] [G loss: 7.135918]\n",
      "epoch:43 step:33799 [D loss: 0.178736, acc: 94.53%] [G loss: 3.990509]\n",
      "epoch:43 step:33800 [D loss: 0.074054, acc: 99.22%] [G loss: 9.381390]\n",
      "epoch:43 step:33801 [D loss: 0.008691, acc: 100.00%] [G loss: 7.001127]\n",
      "epoch:43 step:33802 [D loss: 0.439713, acc: 82.03%] [G loss: 5.777169]\n",
      "epoch:43 step:33803 [D loss: 0.079521, acc: 100.00%] [G loss: 6.273394]\n",
      "epoch:43 step:33804 [D loss: 0.741910, acc: 53.91%] [G loss: 6.045797]\n",
      "epoch:43 step:33805 [D loss: 0.854561, acc: 50.00%] [G loss: 3.161647]\n",
      "epoch:43 step:33806 [D loss: 0.069039, acc: 100.00%] [G loss: 3.856023]\n",
      "epoch:43 step:33807 [D loss: 0.119157, acc: 99.22%] [G loss: 5.994610]\n",
      "epoch:43 step:33808 [D loss: 0.053943, acc: 100.00%] [G loss: 3.507287]\n",
      "epoch:43 step:33809 [D loss: 0.159990, acc: 98.44%] [G loss: 4.578774]\n",
      "epoch:43 step:33810 [D loss: 0.037763, acc: 100.00%] [G loss: 7.067678]\n",
      "epoch:43 step:33811 [D loss: 0.246043, acc: 89.84%] [G loss: 3.788264]\n",
      "epoch:43 step:33812 [D loss: 0.418135, acc: 82.81%] [G loss: 5.225635]\n",
      "epoch:43 step:33813 [D loss: 0.122063, acc: 99.22%] [G loss: 6.604753]\n",
      "epoch:43 step:33814 [D loss: 0.250811, acc: 98.44%] [G loss: 5.215078]\n",
      "epoch:43 step:33815 [D loss: 1.059060, acc: 50.78%] [G loss: 4.396075]\n",
      "epoch:43 step:33816 [D loss: 0.573670, acc: 64.84%] [G loss: 6.248747]\n",
      "epoch:43 step:33817 [D loss: 0.942282, acc: 41.41%] [G loss: 9.103922]\n",
      "epoch:43 step:33818 [D loss: 0.315892, acc: 88.28%] [G loss: 4.315440]\n",
      "epoch:43 step:33819 [D loss: 0.076862, acc: 100.00%] [G loss: 5.596032]\n",
      "epoch:43 step:33820 [D loss: 1.011703, acc: 50.00%] [G loss: 2.948916]\n",
      "epoch:43 step:33821 [D loss: 0.063681, acc: 100.00%] [G loss: 4.603805]\n",
      "epoch:43 step:33822 [D loss: 0.807642, acc: 53.91%] [G loss: 6.163645]\n",
      "epoch:43 step:33823 [D loss: 0.260908, acc: 93.75%] [G loss: 4.632092]\n",
      "epoch:43 step:33824 [D loss: 0.133361, acc: 99.22%] [G loss: 2.767516]\n",
      "epoch:43 step:33825 [D loss: 0.035042, acc: 100.00%] [G loss: 5.407042]\n",
      "epoch:43 step:33826 [D loss: 0.388882, acc: 90.62%] [G loss: 8.207380]\n",
      "epoch:43 step:33827 [D loss: 0.098291, acc: 100.00%] [G loss: 5.327250]\n",
      "epoch:43 step:33828 [D loss: 1.002256, acc: 50.78%] [G loss: 7.703715]\n",
      "epoch:43 step:33829 [D loss: 0.609979, acc: 62.50%] [G loss: 6.621148]\n",
      "epoch:43 step:33830 [D loss: 0.270198, acc: 96.88%] [G loss: 8.799517]\n",
      "epoch:43 step:33831 [D loss: 0.208723, acc: 96.88%] [G loss: 4.531822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33832 [D loss: 0.064709, acc: 100.00%] [G loss: 5.070167]\n",
      "epoch:43 step:33833 [D loss: 0.348574, acc: 82.03%] [G loss: 6.970569]\n",
      "epoch:43 step:33834 [D loss: 0.479377, acc: 64.06%] [G loss: 3.785272]\n",
      "epoch:43 step:33835 [D loss: 0.336300, acc: 82.81%] [G loss: 8.050608]\n",
      "epoch:43 step:33836 [D loss: 1.365303, acc: 50.78%] [G loss: 7.827480]\n",
      "epoch:43 step:33837 [D loss: 0.342696, acc: 92.19%] [G loss: 2.294232]\n",
      "epoch:43 step:33838 [D loss: 0.523996, acc: 65.62%] [G loss: 9.434204]\n",
      "epoch:43 step:33839 [D loss: 0.085133, acc: 100.00%] [G loss: 4.504812]\n",
      "epoch:43 step:33840 [D loss: 0.281386, acc: 95.31%] [G loss: 5.921205]\n",
      "epoch:43 step:33841 [D loss: 0.026608, acc: 100.00%] [G loss: 5.212474]\n",
      "epoch:43 step:33842 [D loss: 0.884589, acc: 41.41%] [G loss: 7.922216]\n",
      "epoch:43 step:33843 [D loss: 0.278805, acc: 95.31%] [G loss: 4.214005]\n",
      "epoch:43 step:33844 [D loss: 0.163132, acc: 97.66%] [G loss: 6.476023]\n",
      "epoch:43 step:33845 [D loss: 0.317046, acc: 83.59%] [G loss: 6.097455]\n",
      "epoch:43 step:33846 [D loss: 0.147987, acc: 97.66%] [G loss: 6.665514]\n",
      "epoch:43 step:33847 [D loss: 0.276587, acc: 92.19%] [G loss: 3.530598]\n",
      "epoch:43 step:33848 [D loss: 0.349403, acc: 76.56%] [G loss: 3.844477]\n",
      "epoch:43 step:33849 [D loss: 0.850446, acc: 53.91%] [G loss: 6.352497]\n",
      "epoch:43 step:33850 [D loss: 0.214813, acc: 93.75%] [G loss: 5.680195]\n",
      "epoch:43 step:33851 [D loss: 0.383781, acc: 82.03%] [G loss: 3.563454]\n",
      "epoch:43 step:33852 [D loss: 0.274111, acc: 90.62%] [G loss: 5.651620]\n",
      "epoch:43 step:33853 [D loss: 0.091619, acc: 99.22%] [G loss: 4.780151]\n",
      "epoch:43 step:33854 [D loss: 0.383612, acc: 73.44%] [G loss: 7.281268]\n",
      "epoch:43 step:33855 [D loss: 0.143647, acc: 100.00%] [G loss: 7.274156]\n",
      "epoch:43 step:33856 [D loss: 0.062031, acc: 100.00%] [G loss: 3.111244]\n",
      "epoch:43 step:33857 [D loss: 0.945590, acc: 46.09%] [G loss: 3.817770]\n",
      "epoch:43 step:33858 [D loss: 0.753887, acc: 48.44%] [G loss: 7.770023]\n",
      "epoch:43 step:33859 [D loss: 0.045171, acc: 99.22%] [G loss: 5.099910]\n",
      "epoch:43 step:33860 [D loss: 0.076014, acc: 100.00%] [G loss: 9.717688]\n",
      "epoch:43 step:33861 [D loss: 0.465099, acc: 70.31%] [G loss: 4.782632]\n",
      "epoch:43 step:33862 [D loss: 0.300660, acc: 92.97%] [G loss: 3.841555]\n",
      "epoch:43 step:33863 [D loss: 0.418325, acc: 86.72%] [G loss: 6.334487]\n",
      "epoch:43 step:33864 [D loss: 0.288714, acc: 90.62%] [G loss: 4.620581]\n",
      "epoch:43 step:33865 [D loss: 0.184136, acc: 97.66%] [G loss: 4.363301]\n",
      "epoch:43 step:33866 [D loss: 0.245438, acc: 93.75%] [G loss: 4.115135]\n",
      "epoch:43 step:33867 [D loss: 0.113218, acc: 99.22%] [G loss: 3.833194]\n",
      "epoch:43 step:33868 [D loss: 0.038573, acc: 100.00%] [G loss: 5.430775]\n",
      "epoch:43 step:33869 [D loss: 0.198230, acc: 97.66%] [G loss: 8.947420]\n",
      "epoch:43 step:33870 [D loss: 0.480882, acc: 74.22%] [G loss: 4.849937]\n",
      "epoch:43 step:33871 [D loss: 0.287091, acc: 96.88%] [G loss: 6.298955]\n",
      "epoch:43 step:33872 [D loss: 0.309035, acc: 90.62%] [G loss: 4.404570]\n",
      "epoch:43 step:33873 [D loss: 0.187887, acc: 96.88%] [G loss: 4.607675]\n",
      "epoch:43 step:33874 [D loss: 1.088408, acc: 40.62%] [G loss: 6.305087]\n",
      "epoch:43 step:33875 [D loss: 0.412072, acc: 84.38%] [G loss: 7.855618]\n",
      "epoch:43 step:33876 [D loss: 0.409190, acc: 76.56%] [G loss: 4.941190]\n",
      "epoch:43 step:33877 [D loss: 0.144511, acc: 98.44%] [G loss: 5.715899]\n",
      "epoch:43 step:33878 [D loss: 0.539375, acc: 67.97%] [G loss: 5.882455]\n",
      "epoch:43 step:33879 [D loss: 0.785463, acc: 52.34%] [G loss: 5.097310]\n",
      "epoch:43 step:33880 [D loss: 0.383626, acc: 71.88%] [G loss: 5.986575]\n",
      "epoch:43 step:33881 [D loss: 0.262482, acc: 96.88%] [G loss: 4.795801]\n",
      "epoch:43 step:33882 [D loss: 0.030536, acc: 100.00%] [G loss: 4.596920]\n",
      "epoch:43 step:33883 [D loss: 0.316732, acc: 89.84%] [G loss: 5.043251]\n",
      "epoch:43 step:33884 [D loss: 0.427386, acc: 78.91%] [G loss: 5.621555]\n",
      "epoch:43 step:33885 [D loss: 0.258426, acc: 93.75%] [G loss: 2.559303]\n",
      "epoch:43 step:33886 [D loss: 0.434167, acc: 75.78%] [G loss: 4.324676]\n",
      "epoch:43 step:33887 [D loss: 1.350779, acc: 50.00%] [G loss: 6.148846]\n",
      "epoch:43 step:33888 [D loss: 0.009250, acc: 100.00%] [G loss: 6.293670]\n",
      "epoch:43 step:33889 [D loss: 0.368418, acc: 77.34%] [G loss: 3.196288]\n",
      "epoch:43 step:33890 [D loss: 0.172784, acc: 96.09%] [G loss: 6.547486]\n",
      "epoch:43 step:33891 [D loss: 0.067849, acc: 100.00%] [G loss: 6.876715]\n",
      "epoch:43 step:33892 [D loss: 0.212428, acc: 96.88%] [G loss: 5.818231]\n",
      "epoch:43 step:33893 [D loss: 0.032617, acc: 100.00%] [G loss: 5.380708]\n",
      "epoch:43 step:33894 [D loss: 0.496512, acc: 70.31%] [G loss: 7.147731]\n",
      "epoch:43 step:33895 [D loss: 0.902085, acc: 51.56%] [G loss: 7.056690]\n",
      "epoch:43 step:33896 [D loss: 0.070200, acc: 100.00%] [G loss: 4.816967]\n",
      "epoch:43 step:33897 [D loss: 0.058419, acc: 100.00%] [G loss: 5.422407]\n",
      "epoch:43 step:33898 [D loss: 0.565373, acc: 75.00%] [G loss: 5.622182]\n",
      "epoch:43 step:33899 [D loss: 0.012522, acc: 100.00%] [G loss: 5.866642]\n",
      "epoch:43 step:33900 [D loss: 0.071730, acc: 99.22%] [G loss: 4.667358]\n",
      "epoch:43 step:33901 [D loss: 0.973194, acc: 39.84%] [G loss: 4.717702]\n",
      "epoch:43 step:33902 [D loss: 0.141246, acc: 100.00%] [G loss: 5.409584]\n",
      "epoch:43 step:33903 [D loss: 0.210208, acc: 97.66%] [G loss: 4.709866]\n",
      "epoch:43 step:33904 [D loss: 0.234252, acc: 96.09%] [G loss: 3.882353]\n",
      "epoch:43 step:33905 [D loss: 0.569287, acc: 68.75%] [G loss: 8.849439]\n",
      "epoch:43 step:33906 [D loss: 0.174290, acc: 98.44%] [G loss: 7.492170]\n",
      "epoch:43 step:33907 [D loss: 0.085500, acc: 100.00%] [G loss: 3.529284]\n",
      "epoch:43 step:33908 [D loss: 0.516151, acc: 62.50%] [G loss: 6.884329]\n",
      "epoch:43 step:33909 [D loss: 0.348914, acc: 91.41%] [G loss: 4.286957]\n",
      "epoch:43 step:33910 [D loss: 0.115334, acc: 100.00%] [G loss: 6.470262]\n",
      "epoch:43 step:33911 [D loss: 0.450313, acc: 80.47%] [G loss: 6.298312]\n",
      "epoch:43 step:33912 [D loss: 0.188932, acc: 97.66%] [G loss: 5.865721]\n",
      "epoch:43 step:33913 [D loss: 0.169734, acc: 96.09%] [G loss: 4.262673]\n",
      "epoch:43 step:33914 [D loss: 0.172112, acc: 96.88%] [G loss: 5.152211]\n",
      "epoch:43 step:33915 [D loss: 0.351480, acc: 80.47%] [G loss: 4.732411]\n",
      "epoch:43 step:33916 [D loss: 0.061821, acc: 100.00%] [G loss: 4.944946]\n",
      "epoch:43 step:33917 [D loss: 0.128051, acc: 99.22%] [G loss: 7.077986]\n",
      "epoch:43 step:33918 [D loss: 0.031301, acc: 100.00%] [G loss: 8.318328]\n",
      "epoch:43 step:33919 [D loss: 0.361958, acc: 89.84%] [G loss: 7.974572]\n",
      "epoch:43 step:33920 [D loss: 0.149687, acc: 100.00%] [G loss: 7.616506]\n",
      "epoch:43 step:33921 [D loss: 0.285126, acc: 90.62%] [G loss: 6.695605]\n",
      "epoch:43 step:33922 [D loss: 0.057980, acc: 100.00%] [G loss: 7.622152]\n",
      "epoch:43 step:33923 [D loss: 0.036831, acc: 100.00%] [G loss: 3.902425]\n",
      "epoch:43 step:33924 [D loss: 0.016560, acc: 100.00%] [G loss: 6.074493]\n",
      "epoch:43 step:33925 [D loss: 1.212323, acc: 48.44%] [G loss: 4.314276]\n",
      "epoch:43 step:33926 [D loss: 0.091064, acc: 100.00%] [G loss: 5.339870]\n",
      "epoch:43 step:33927 [D loss: 0.935622, acc: 51.56%] [G loss: 4.578336]\n",
      "epoch:43 step:33928 [D loss: 0.011128, acc: 100.00%] [G loss: 7.585566]\n",
      "epoch:43 step:33929 [D loss: 0.029851, acc: 100.00%] [G loss: 5.161346]\n",
      "epoch:43 step:33930 [D loss: 0.022043, acc: 100.00%] [G loss: 4.368495]\n",
      "epoch:43 step:33931 [D loss: 0.225724, acc: 95.31%] [G loss: 7.513833]\n",
      "epoch:43 step:33932 [D loss: 0.608874, acc: 67.97%] [G loss: 5.819041]\n",
      "epoch:43 step:33933 [D loss: 0.226837, acc: 96.88%] [G loss: 4.266876]\n",
      "epoch:43 step:33934 [D loss: 0.234632, acc: 92.19%] [G loss: 4.549957]\n",
      "epoch:43 step:33935 [D loss: 0.332543, acc: 84.38%] [G loss: 6.300756]\n",
      "epoch:43 step:33936 [D loss: 0.615803, acc: 59.38%] [G loss: 6.010653]\n",
      "epoch:43 step:33937 [D loss: 0.617148, acc: 59.38%] [G loss: 6.274886]\n",
      "epoch:43 step:33938 [D loss: 0.780392, acc: 56.25%] [G loss: 5.403208]\n",
      "epoch:43 step:33939 [D loss: 0.469544, acc: 80.47%] [G loss: 4.063287]\n",
      "epoch:43 step:33940 [D loss: 0.575147, acc: 75.00%] [G loss: 2.830689]\n",
      "epoch:43 step:33941 [D loss: 0.014182, acc: 100.00%] [G loss: 7.848941]\n",
      "epoch:43 step:33942 [D loss: 0.079285, acc: 99.22%] [G loss: 4.827564]\n",
      "epoch:43 step:33943 [D loss: 0.067678, acc: 99.22%] [G loss: 8.476620]\n",
      "epoch:43 step:33944 [D loss: 0.065219, acc: 100.00%] [G loss: 7.711823]\n",
      "epoch:43 step:33945 [D loss: 0.112187, acc: 100.00%] [G loss: 7.938261]\n",
      "epoch:43 step:33946 [D loss: 0.254754, acc: 92.97%] [G loss: 7.203964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33947 [D loss: 0.138445, acc: 100.00%] [G loss: 3.069776]\n",
      "epoch:43 step:33948 [D loss: 0.326567, acc: 84.38%] [G loss: 7.082405]\n",
      "epoch:43 step:33949 [D loss: 0.499715, acc: 65.62%] [G loss: 5.032503]\n",
      "epoch:43 step:33950 [D loss: 0.058411, acc: 100.00%] [G loss: 5.814026]\n",
      "epoch:43 step:33951 [D loss: 0.502064, acc: 67.97%] [G loss: 3.482650]\n",
      "epoch:43 step:33952 [D loss: 0.391839, acc: 78.91%] [G loss: 5.169553]\n",
      "epoch:43 step:33953 [D loss: 0.623838, acc: 63.28%] [G loss: 4.442375]\n",
      "epoch:43 step:33954 [D loss: 0.627716, acc: 57.81%] [G loss: 4.961937]\n",
      "epoch:43 step:33955 [D loss: 0.026312, acc: 100.00%] [G loss: 3.476096]\n",
      "epoch:43 step:33956 [D loss: 0.493759, acc: 64.06%] [G loss: 6.363315]\n",
      "epoch:43 step:33957 [D loss: 1.410711, acc: 23.44%] [G loss: 6.625789]\n",
      "epoch:43 step:33958 [D loss: 0.304269, acc: 89.06%] [G loss: 7.262867]\n",
      "epoch:43 step:33959 [D loss: 0.221396, acc: 93.75%] [G loss: 4.230188]\n",
      "epoch:43 step:33960 [D loss: 0.991529, acc: 33.59%] [G loss: 6.656734]\n",
      "epoch:43 step:33961 [D loss: 0.095387, acc: 100.00%] [G loss: 5.107346]\n",
      "epoch:43 step:33962 [D loss: 0.360334, acc: 78.91%] [G loss: 6.027590]\n",
      "epoch:43 step:33963 [D loss: 1.007887, acc: 45.31%] [G loss: 7.199349]\n",
      "epoch:43 step:33964 [D loss: 0.470474, acc: 78.91%] [G loss: 5.732518]\n",
      "epoch:43 step:33965 [D loss: 0.296986, acc: 83.59%] [G loss: 7.330133]\n",
      "epoch:43 step:33966 [D loss: 1.147476, acc: 46.88%] [G loss: 5.229445]\n",
      "epoch:43 step:33967 [D loss: 0.516781, acc: 75.78%] [G loss: 4.847065]\n",
      "epoch:43 step:33968 [D loss: 0.598189, acc: 57.81%] [G loss: 5.170302]\n",
      "epoch:43 step:33969 [D loss: 0.190525, acc: 97.66%] [G loss: 6.496486]\n",
      "epoch:43 step:33970 [D loss: 0.146849, acc: 98.44%] [G loss: 5.221970]\n",
      "epoch:43 step:33971 [D loss: 0.300702, acc: 94.53%] [G loss: 3.727454]\n",
      "epoch:43 step:33972 [D loss: 1.135641, acc: 50.00%] [G loss: 8.234416]\n",
      "epoch:43 step:33973 [D loss: 0.099991, acc: 100.00%] [G loss: 6.116807]\n",
      "epoch:43 step:33974 [D loss: 0.227856, acc: 90.62%] [G loss: 6.531407]\n",
      "epoch:43 step:33975 [D loss: 0.041539, acc: 100.00%] [G loss: 9.889572]\n",
      "epoch:43 step:33976 [D loss: 0.251480, acc: 93.75%] [G loss: 4.599269]\n",
      "epoch:43 step:33977 [D loss: 0.493346, acc: 64.06%] [G loss: 5.150209]\n",
      "epoch:43 step:33978 [D loss: 0.425817, acc: 80.47%] [G loss: 6.448527]\n",
      "epoch:43 step:33979 [D loss: 0.366557, acc: 89.06%] [G loss: 4.636535]\n",
      "epoch:43 step:33980 [D loss: 1.238316, acc: 47.66%] [G loss: 6.513311]\n",
      "epoch:43 step:33981 [D loss: 0.355900, acc: 78.12%] [G loss: 6.664865]\n",
      "epoch:43 step:33982 [D loss: 0.053039, acc: 100.00%] [G loss: 6.693184]\n",
      "epoch:43 step:33983 [D loss: 0.389099, acc: 85.16%] [G loss: 5.313417]\n",
      "epoch:43 step:33984 [D loss: 0.339788, acc: 89.06%] [G loss: 8.782792]\n",
      "epoch:43 step:33985 [D loss: 0.133318, acc: 99.22%] [G loss: 5.523206]\n",
      "epoch:43 step:33986 [D loss: 0.194884, acc: 95.31%] [G loss: 5.943351]\n",
      "epoch:43 step:33987 [D loss: 0.536959, acc: 67.19%] [G loss: 5.902835]\n",
      "epoch:43 step:33988 [D loss: 0.110721, acc: 99.22%] [G loss: 4.871828]\n",
      "epoch:43 step:33989 [D loss: 0.127053, acc: 99.22%] [G loss: 3.896171]\n",
      "epoch:43 step:33990 [D loss: 0.141656, acc: 98.44%] [G loss: 8.316320]\n",
      "epoch:43 step:33991 [D loss: 0.352960, acc: 78.12%] [G loss: 3.214177]\n",
      "epoch:43 step:33992 [D loss: 0.145891, acc: 100.00%] [G loss: 9.490077]\n",
      "epoch:43 step:33993 [D loss: 0.156363, acc: 99.22%] [G loss: 6.355392]\n",
      "epoch:43 step:33994 [D loss: 0.940204, acc: 46.88%] [G loss: 8.538685]\n",
      "epoch:43 step:33995 [D loss: 0.501783, acc: 64.84%] [G loss: 4.046642]\n",
      "epoch:43 step:33996 [D loss: 0.095385, acc: 100.00%] [G loss: 3.705743]\n",
      "epoch:43 step:33997 [D loss: 0.218271, acc: 96.88%] [G loss: 3.058879]\n",
      "epoch:43 step:33998 [D loss: 1.282594, acc: 50.78%] [G loss: 7.807528]\n",
      "epoch:43 step:33999 [D loss: 0.279798, acc: 92.97%] [G loss: 1.596395]\n",
      "epoch:43 step:34000 [D loss: 0.043880, acc: 100.00%] [G loss: 5.336035]\n",
      "epoch:43 step:34001 [D loss: 0.173733, acc: 96.09%] [G loss: 8.563064]\n",
      "epoch:43 step:34002 [D loss: 0.262800, acc: 92.19%] [G loss: 4.310343]\n",
      "epoch:43 step:34003 [D loss: 0.232293, acc: 92.97%] [G loss: 5.197136]\n",
      "epoch:43 step:34004 [D loss: 0.107959, acc: 99.22%] [G loss: 4.984872]\n",
      "epoch:43 step:34005 [D loss: 0.026965, acc: 100.00%] [G loss: 9.707118]\n",
      "epoch:43 step:34006 [D loss: 0.129214, acc: 98.44%] [G loss: 7.410789]\n",
      "epoch:43 step:34007 [D loss: 0.458889, acc: 69.53%] [G loss: 6.938395]\n",
      "epoch:43 step:34008 [D loss: 0.019352, acc: 100.00%] [G loss: 7.321504]\n",
      "epoch:43 step:34009 [D loss: 0.584749, acc: 60.94%] [G loss: 3.871044]\n",
      "epoch:43 step:34010 [D loss: 0.595587, acc: 62.50%] [G loss: 3.686399]\n",
      "epoch:43 step:34011 [D loss: 0.590479, acc: 70.31%] [G loss: 9.181833]\n",
      "epoch:43 step:34012 [D loss: 0.450811, acc: 67.97%] [G loss: 7.438735]\n",
      "epoch:43 step:34013 [D loss: 0.916711, acc: 50.00%] [G loss: 7.713829]\n",
      "epoch:43 step:34014 [D loss: 0.137403, acc: 100.00%] [G loss: 5.710854]\n",
      "epoch:43 step:34015 [D loss: 0.076604, acc: 100.00%] [G loss: 4.599287]\n",
      "epoch:43 step:34016 [D loss: 0.159157, acc: 96.88%] [G loss: 5.237856]\n",
      "epoch:43 step:34017 [D loss: 0.033319, acc: 100.00%] [G loss: 7.160528]\n",
      "epoch:43 step:34018 [D loss: 2.088376, acc: 29.69%] [G loss: 4.635097]\n",
      "epoch:43 step:34019 [D loss: 0.596171, acc: 59.38%] [G loss: 9.762941]\n",
      "epoch:43 step:34020 [D loss: 1.075509, acc: 23.44%] [G loss: 6.985046]\n",
      "epoch:43 step:34021 [D loss: 0.017040, acc: 100.00%] [G loss: 6.234224]\n",
      "epoch:43 step:34022 [D loss: 0.679243, acc: 62.50%] [G loss: 6.411029]\n",
      "epoch:43 step:34023 [D loss: 0.338614, acc: 78.12%] [G loss: 6.499122]\n",
      "epoch:43 step:34024 [D loss: 0.091321, acc: 100.00%] [G loss: 5.970007]\n",
      "epoch:43 step:34025 [D loss: 0.397736, acc: 81.25%] [G loss: 5.058236]\n",
      "epoch:43 step:34026 [D loss: 0.270215, acc: 95.31%] [G loss: 3.779987]\n",
      "epoch:43 step:34027 [D loss: 0.430963, acc: 74.22%] [G loss: 7.733611]\n",
      "epoch:43 step:34028 [D loss: 0.118187, acc: 100.00%] [G loss: 3.292982]\n",
      "epoch:43 step:34029 [D loss: 0.218531, acc: 92.19%] [G loss: 6.404476]\n",
      "epoch:43 step:34030 [D loss: 0.170360, acc: 96.09%] [G loss: 5.189568]\n",
      "epoch:43 step:34031 [D loss: 0.986926, acc: 37.50%] [G loss: 8.041510]\n",
      "epoch:43 step:34032 [D loss: 0.036018, acc: 100.00%] [G loss: 4.511115]\n",
      "epoch:43 step:34033 [D loss: 0.080031, acc: 100.00%] [G loss: 4.586408]\n",
      "epoch:43 step:34034 [D loss: 0.135408, acc: 98.44%] [G loss: 6.912539]\n",
      "epoch:43 step:34035 [D loss: 0.227117, acc: 94.53%] [G loss: 8.180453]\n",
      "epoch:43 step:34036 [D loss: 0.308401, acc: 83.59%] [G loss: 7.500604]\n",
      "epoch:43 step:34037 [D loss: 0.318547, acc: 88.28%] [G loss: 5.329168]\n",
      "epoch:43 step:34038 [D loss: 0.088799, acc: 99.22%] [G loss: 3.541927]\n",
      "epoch:43 step:34039 [D loss: 0.106965, acc: 99.22%] [G loss: 2.759597]\n",
      "epoch:43 step:34040 [D loss: 0.645339, acc: 70.31%] [G loss: 5.210395]\n",
      "epoch:43 step:34041 [D loss: 0.154528, acc: 99.22%] [G loss: 4.095092]\n",
      "epoch:43 step:34042 [D loss: 0.152446, acc: 100.00%] [G loss: 4.452788]\n",
      "epoch:43 step:34043 [D loss: 0.201487, acc: 96.09%] [G loss: 3.018599]\n",
      "epoch:43 step:34044 [D loss: 0.128497, acc: 98.44%] [G loss: 6.659847]\n",
      "epoch:43 step:34045 [D loss: 0.025854, acc: 100.00%] [G loss: 4.189619]\n",
      "epoch:43 step:34046 [D loss: 0.092692, acc: 99.22%] [G loss: 4.354184]\n",
      "epoch:43 step:34047 [D loss: 0.471908, acc: 65.62%] [G loss: 6.551337]\n",
      "epoch:43 step:34048 [D loss: 0.177052, acc: 100.00%] [G loss: 3.398506]\n",
      "epoch:43 step:34049 [D loss: 0.028902, acc: 100.00%] [G loss: 6.618394]\n",
      "epoch:43 step:34050 [D loss: 0.038693, acc: 100.00%] [G loss: 5.693269]\n",
      "epoch:43 step:34051 [D loss: 0.567376, acc: 71.88%] [G loss: 5.905153]\n",
      "epoch:43 step:34052 [D loss: 0.578103, acc: 66.41%] [G loss: 3.866021]\n",
      "epoch:43 step:34053 [D loss: 0.128695, acc: 99.22%] [G loss: 5.621236]\n",
      "epoch:43 step:34054 [D loss: 1.552986, acc: 42.97%] [G loss: 6.604136]\n",
      "epoch:43 step:34055 [D loss: 0.756299, acc: 48.44%] [G loss: 4.467942]\n",
      "epoch:43 step:34056 [D loss: 0.541050, acc: 71.88%] [G loss: 5.629622]\n",
      "epoch:43 step:34057 [D loss: 0.088674, acc: 100.00%] [G loss: 5.051440]\n",
      "epoch:43 step:34058 [D loss: 0.070138, acc: 99.22%] [G loss: 5.634135]\n",
      "epoch:43 step:34059 [D loss: 0.818685, acc: 42.19%] [G loss: 6.580635]\n",
      "epoch:43 step:34060 [D loss: 0.173774, acc: 99.22%] [G loss: 5.861252]\n",
      "epoch:43 step:34061 [D loss: 0.042561, acc: 100.00%] [G loss: 9.020454]\n",
      "epoch:43 step:34062 [D loss: 0.282065, acc: 92.97%] [G loss: 5.108972]\n",
      "epoch:43 step:34063 [D loss: 0.082842, acc: 100.00%] [G loss: 6.831292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34064 [D loss: 0.288266, acc: 89.84%] [G loss: 3.165475]\n",
      "epoch:43 step:34065 [D loss: 0.210517, acc: 98.44%] [G loss: 2.268948]\n",
      "epoch:43 step:34066 [D loss: 0.187013, acc: 97.66%] [G loss: 4.867763]\n",
      "epoch:43 step:34067 [D loss: 1.153057, acc: 45.31%] [G loss: 7.193456]\n",
      "epoch:43 step:34068 [D loss: 1.090088, acc: 50.78%] [G loss: 3.658431]\n",
      "epoch:43 step:34069 [D loss: 0.704436, acc: 57.81%] [G loss: 8.029095]\n",
      "epoch:43 step:34070 [D loss: 0.523923, acc: 75.00%] [G loss: 4.441731]\n",
      "epoch:43 step:34071 [D loss: 0.081408, acc: 100.00%] [G loss: 5.321294]\n",
      "epoch:43 step:34072 [D loss: 0.307797, acc: 92.19%] [G loss: 3.376749]\n",
      "epoch:43 step:34073 [D loss: 0.257893, acc: 87.50%] [G loss: 9.538908]\n",
      "epoch:43 step:34074 [D loss: 0.350591, acc: 80.47%] [G loss: 8.118383]\n",
      "epoch:43 step:34075 [D loss: 0.850005, acc: 51.56%] [G loss: 5.929639]\n",
      "epoch:43 step:34076 [D loss: 0.022074, acc: 100.00%] [G loss: 5.020575]\n",
      "epoch:43 step:34077 [D loss: 0.179609, acc: 100.00%] [G loss: 3.350876]\n",
      "epoch:43 step:34078 [D loss: 0.476120, acc: 68.75%] [G loss: 3.657846]\n",
      "epoch:43 step:34079 [D loss: 0.178567, acc: 98.44%] [G loss: 6.188128]\n",
      "epoch:43 step:34080 [D loss: 0.040300, acc: 100.00%] [G loss: 8.045662]\n",
      "epoch:43 step:34081 [D loss: 0.009125, acc: 100.00%] [G loss: 8.195331]\n",
      "epoch:43 step:34082 [D loss: 0.709758, acc: 55.47%] [G loss: 9.141135]\n",
      "epoch:43 step:34083 [D loss: 0.051547, acc: 100.00%] [G loss: 3.772354]\n",
      "epoch:43 step:34084 [D loss: 0.162476, acc: 98.44%] [G loss: 7.477043]\n",
      "epoch:43 step:34085 [D loss: 0.428876, acc: 84.38%] [G loss: 5.524701]\n",
      "epoch:43 step:34086 [D loss: 0.135428, acc: 97.66%] [G loss: 6.260155]\n",
      "epoch:43 step:34087 [D loss: 0.301857, acc: 84.38%] [G loss: 4.178259]\n",
      "epoch:43 step:34088 [D loss: 0.059982, acc: 100.00%] [G loss: 4.224911]\n",
      "epoch:43 step:34089 [D loss: 0.078255, acc: 100.00%] [G loss: 4.945071]\n",
      "epoch:43 step:34090 [D loss: 0.433013, acc: 85.16%] [G loss: 4.770365]\n",
      "epoch:43 step:34091 [D loss: 0.071192, acc: 100.00%] [G loss: 6.941837]\n",
      "epoch:43 step:34092 [D loss: 0.211483, acc: 98.44%] [G loss: 4.771624]\n",
      "epoch:43 step:34093 [D loss: 0.121471, acc: 100.00%] [G loss: 5.780224]\n",
      "epoch:43 step:34094 [D loss: 0.153064, acc: 97.66%] [G loss: 5.652487]\n",
      "epoch:43 step:34095 [D loss: 0.125964, acc: 98.44%] [G loss: 4.126504]\n",
      "epoch:43 step:34096 [D loss: 0.058483, acc: 100.00%] [G loss: 6.201816]\n",
      "epoch:43 step:34097 [D loss: 1.093653, acc: 51.56%] [G loss: 8.734613]\n",
      "epoch:43 step:34098 [D loss: 0.334842, acc: 83.59%] [G loss: 6.895509]\n",
      "epoch:43 step:34099 [D loss: 0.159868, acc: 98.44%] [G loss: 3.470226]\n",
      "epoch:43 step:34100 [D loss: 0.420345, acc: 77.34%] [G loss: 6.592629]\n",
      "epoch:43 step:34101 [D loss: 1.245274, acc: 47.66%] [G loss: 6.050137]\n",
      "epoch:43 step:34102 [D loss: 0.321152, acc: 92.97%] [G loss: 7.212141]\n",
      "epoch:43 step:34103 [D loss: 0.090494, acc: 100.00%] [G loss: 2.867178]\n",
      "epoch:43 step:34104 [D loss: 0.150126, acc: 98.44%] [G loss: 7.547253]\n",
      "epoch:43 step:34105 [D loss: 0.193100, acc: 96.88%] [G loss: 4.713755]\n",
      "epoch:43 step:34106 [D loss: 0.127543, acc: 98.44%] [G loss: 7.751856]\n",
      "epoch:43 step:34107 [D loss: 0.252217, acc: 94.53%] [G loss: 7.030230]\n",
      "epoch:43 step:34108 [D loss: 0.497202, acc: 71.88%] [G loss: 7.880695]\n",
      "epoch:43 step:34109 [D loss: 0.691720, acc: 53.91%] [G loss: 8.983665]\n",
      "epoch:43 step:34110 [D loss: 0.964094, acc: 52.34%] [G loss: 5.707448]\n",
      "epoch:43 step:34111 [D loss: 0.413672, acc: 78.12%] [G loss: 2.888554]\n",
      "epoch:43 step:34112 [D loss: 0.333654, acc: 78.12%] [G loss: 7.052814]\n",
      "epoch:43 step:34113 [D loss: 0.030082, acc: 100.00%] [G loss: 4.113178]\n",
      "epoch:43 step:34114 [D loss: 0.363181, acc: 74.22%] [G loss: 6.733823]\n",
      "epoch:43 step:34115 [D loss: 0.137496, acc: 100.00%] [G loss: 4.548843]\n",
      "epoch:43 step:34116 [D loss: 0.248446, acc: 95.31%] [G loss: 3.704036]\n",
      "epoch:43 step:34117 [D loss: 1.035419, acc: 25.00%] [G loss: 5.676033]\n",
      "epoch:43 step:34118 [D loss: 0.240943, acc: 89.84%] [G loss: 5.522634]\n",
      "epoch:43 step:34119 [D loss: 0.219800, acc: 97.66%] [G loss: 6.171683]\n",
      "epoch:43 step:34120 [D loss: 0.038240, acc: 100.00%] [G loss: 3.153646]\n",
      "epoch:43 step:34121 [D loss: 0.103584, acc: 100.00%] [G loss: 5.648502]\n",
      "epoch:43 step:34122 [D loss: 0.376920, acc: 75.00%] [G loss: 4.544894]\n",
      "epoch:43 step:34123 [D loss: 0.357210, acc: 83.59%] [G loss: 5.785615]\n",
      "epoch:43 step:34124 [D loss: 0.377848, acc: 76.56%] [G loss: 9.017389]\n",
      "epoch:43 step:34125 [D loss: 0.746188, acc: 53.12%] [G loss: 9.942226]\n",
      "epoch:43 step:34126 [D loss: 0.410608, acc: 73.44%] [G loss: 4.083742]\n",
      "epoch:43 step:34127 [D loss: 0.090642, acc: 99.22%] [G loss: 8.789640]\n",
      "epoch:43 step:34128 [D loss: 0.308972, acc: 83.59%] [G loss: 5.351315]\n",
      "epoch:43 step:34129 [D loss: 0.959389, acc: 32.81%] [G loss: 7.597322]\n",
      "epoch:43 step:34130 [D loss: 0.063993, acc: 100.00%] [G loss: 8.165824]\n",
      "epoch:43 step:34131 [D loss: 0.064196, acc: 100.00%] [G loss: 2.950930]\n",
      "epoch:43 step:34132 [D loss: 0.355340, acc: 82.81%] [G loss: 9.405287]\n",
      "epoch:43 step:34133 [D loss: 0.417654, acc: 75.78%] [G loss: 7.907604]\n",
      "epoch:43 step:34134 [D loss: 0.015809, acc: 100.00%] [G loss: 8.058850]\n",
      "epoch:43 step:34135 [D loss: 0.371001, acc: 89.84%] [G loss: 7.748652]\n",
      "epoch:43 step:34136 [D loss: 0.209865, acc: 97.66%] [G loss: 5.299551]\n",
      "epoch:43 step:34137 [D loss: 0.218374, acc: 98.44%] [G loss: 2.744887]\n",
      "epoch:43 step:34138 [D loss: 0.002572, acc: 100.00%] [G loss: 7.147652]\n",
      "epoch:43 step:34139 [D loss: 0.226071, acc: 97.66%] [G loss: 7.022573]\n",
      "epoch:43 step:34140 [D loss: 0.218974, acc: 94.53%] [G loss: 7.370140]\n",
      "epoch:43 step:34141 [D loss: 0.395617, acc: 88.28%] [G loss: 5.223167]\n",
      "epoch:43 step:34142 [D loss: 0.702337, acc: 56.25%] [G loss: 4.068419]\n",
      "epoch:43 step:34143 [D loss: 0.206411, acc: 96.09%] [G loss: 4.324381]\n",
      "epoch:43 step:34144 [D loss: 0.272920, acc: 92.97%] [G loss: 5.248270]\n",
      "epoch:43 step:34145 [D loss: 0.427473, acc: 73.44%] [G loss: 7.603783]\n",
      "epoch:43 step:34146 [D loss: 1.796774, acc: 50.00%] [G loss: 6.547706]\n",
      "epoch:43 step:34147 [D loss: 0.539721, acc: 67.19%] [G loss: 5.501213]\n",
      "epoch:43 step:34148 [D loss: 0.109788, acc: 99.22%] [G loss: 1.047097]\n",
      "epoch:43 step:34149 [D loss: 0.324075, acc: 92.97%] [G loss: 5.876163]\n",
      "epoch:43 step:34150 [D loss: 0.250356, acc: 93.75%] [G loss: 8.293428]\n",
      "epoch:43 step:34151 [D loss: 0.147482, acc: 99.22%] [G loss: 2.506963]\n",
      "epoch:43 step:34152 [D loss: 0.048010, acc: 100.00%] [G loss: 4.272614]\n",
      "epoch:43 step:34153 [D loss: 2.324927, acc: 17.97%] [G loss: 5.064834]\n",
      "epoch:43 step:34154 [D loss: 0.293330, acc: 90.62%] [G loss: 6.086769]\n",
      "epoch:43 step:34155 [D loss: 0.268732, acc: 94.53%] [G loss: 6.016912]\n",
      "epoch:43 step:34156 [D loss: 0.099345, acc: 100.00%] [G loss: 5.154983]\n",
      "epoch:43 step:34157 [D loss: 0.161380, acc: 96.09%] [G loss: 4.764366]\n",
      "epoch:43 step:34158 [D loss: 0.210912, acc: 98.44%] [G loss: 5.519059]\n",
      "epoch:43 step:34159 [D loss: 0.387852, acc: 83.59%] [G loss: 6.244593]\n",
      "epoch:43 step:34160 [D loss: 0.141735, acc: 99.22%] [G loss: 3.540881]\n",
      "epoch:43 step:34161 [D loss: 0.009291, acc: 100.00%] [G loss: 7.063825]\n",
      "epoch:43 step:34162 [D loss: 0.155539, acc: 100.00%] [G loss: 4.952318]\n",
      "epoch:43 step:34163 [D loss: 0.038840, acc: 100.00%] [G loss: 4.373940]\n",
      "epoch:43 step:34164 [D loss: 0.059576, acc: 99.22%] [G loss: 9.606573]\n",
      "epoch:43 step:34165 [D loss: 0.127490, acc: 96.88%] [G loss: 7.116939]\n",
      "epoch:43 step:34166 [D loss: 0.550031, acc: 67.19%] [G loss: 3.904853]\n",
      "epoch:43 step:34167 [D loss: 0.103603, acc: 99.22%] [G loss: 6.582063]\n",
      "epoch:43 step:34168 [D loss: 1.536844, acc: 36.72%] [G loss: 8.703255]\n",
      "epoch:43 step:34169 [D loss: 0.349425, acc: 78.91%] [G loss: 5.801152]\n",
      "epoch:43 step:34170 [D loss: 0.092985, acc: 98.44%] [G loss: 6.281870]\n",
      "epoch:43 step:34171 [D loss: 0.851034, acc: 49.22%] [G loss: 8.805651]\n",
      "epoch:43 step:34172 [D loss: 0.456219, acc: 72.66%] [G loss: 6.188629]\n",
      "epoch:43 step:34173 [D loss: 0.067364, acc: 100.00%] [G loss: 9.855923]\n",
      "epoch:43 step:34174 [D loss: 0.360500, acc: 78.91%] [G loss: 9.862488]\n",
      "epoch:43 step:34175 [D loss: 0.293294, acc: 97.66%] [G loss: 3.843759]\n",
      "epoch:43 step:34176 [D loss: 0.376861, acc: 85.16%] [G loss: 5.803411]\n",
      "epoch:43 step:34177 [D loss: 0.150183, acc: 98.44%] [G loss: 5.421633]\n",
      "epoch:43 step:34178 [D loss: 0.057399, acc: 100.00%] [G loss: 7.205855]\n",
      "epoch:43 step:34179 [D loss: 0.241681, acc: 96.09%] [G loss: 4.244009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34180 [D loss: 0.484757, acc: 71.88%] [G loss: 5.878746]\n",
      "epoch:43 step:34181 [D loss: 0.385533, acc: 74.22%] [G loss: 8.159130]\n",
      "epoch:43 step:34182 [D loss: 0.343684, acc: 82.81%] [G loss: 5.404036]\n",
      "epoch:43 step:34183 [D loss: 0.097383, acc: 99.22%] [G loss: 4.799416]\n",
      "epoch:43 step:34184 [D loss: 1.611431, acc: 44.53%] [G loss: 6.316923]\n",
      "epoch:43 step:34185 [D loss: 0.077252, acc: 99.22%] [G loss: 3.537580]\n",
      "epoch:43 step:34186 [D loss: 0.044109, acc: 100.00%] [G loss: 6.234371]\n",
      "epoch:43 step:34187 [D loss: 0.225500, acc: 93.75%] [G loss: 6.766721]\n",
      "epoch:43 step:34188 [D loss: 1.700642, acc: 44.53%] [G loss: 2.404826]\n",
      "epoch:43 step:34189 [D loss: 0.097630, acc: 100.00%] [G loss: 2.990762]\n",
      "epoch:43 step:34190 [D loss: 1.495897, acc: 50.00%] [G loss: 8.425314]\n",
      "epoch:43 step:34191 [D loss: 0.688915, acc: 55.47%] [G loss: 9.092742]\n",
      "epoch:43 step:34192 [D loss: 0.046383, acc: 100.00%] [G loss: 4.755151]\n",
      "epoch:43 step:34193 [D loss: 0.222776, acc: 96.88%] [G loss: 6.382666]\n",
      "epoch:43 step:34194 [D loss: 0.586136, acc: 64.84%] [G loss: 9.440517]\n",
      "epoch:43 step:34195 [D loss: 0.725874, acc: 53.91%] [G loss: 4.246366]\n",
      "epoch:43 step:34196 [D loss: 0.088825, acc: 99.22%] [G loss: 7.320669]\n",
      "epoch:43 step:34197 [D loss: 0.078107, acc: 100.00%] [G loss: 7.198132]\n",
      "epoch:43 step:34198 [D loss: 0.107958, acc: 100.00%] [G loss: 5.122706]\n",
      "epoch:43 step:34199 [D loss: 0.079417, acc: 99.22%] [G loss: 2.520318]\n",
      "epoch:43 step:34200 [D loss: 0.886204, acc: 53.12%] [G loss: 6.767032]\n",
      "epoch:43 step:34201 [D loss: 0.261200, acc: 96.88%] [G loss: 4.149221]\n",
      "epoch:43 step:34202 [D loss: 0.196472, acc: 96.88%] [G loss: 4.461956]\n",
      "epoch:43 step:34203 [D loss: 0.523481, acc: 61.72%] [G loss: 2.985818]\n",
      "epoch:43 step:34204 [D loss: 1.089901, acc: 40.62%] [G loss: 5.232333]\n",
      "epoch:43 step:34205 [D loss: 0.121798, acc: 99.22%] [G loss: 6.279795]\n",
      "epoch:43 step:34206 [D loss: 0.621114, acc: 60.94%] [G loss: 7.654481]\n",
      "epoch:43 step:34207 [D loss: 0.331296, acc: 86.72%] [G loss: 7.687266]\n",
      "epoch:43 step:34208 [D loss: 0.283314, acc: 83.59%] [G loss: 4.486545]\n",
      "epoch:43 step:34209 [D loss: 0.354573, acc: 81.25%] [G loss: 4.198154]\n",
      "epoch:43 step:34210 [D loss: 0.101983, acc: 99.22%] [G loss: 3.850074]\n",
      "epoch:43 step:34211 [D loss: 0.144551, acc: 98.44%] [G loss: 5.354202]\n",
      "epoch:43 step:34212 [D loss: 1.634898, acc: 7.03%] [G loss: 8.748007]\n",
      "epoch:43 step:34213 [D loss: 0.082786, acc: 100.00%] [G loss: 9.388403]\n",
      "epoch:43 step:34214 [D loss: 0.149946, acc: 99.22%] [G loss: 3.138721]\n",
      "epoch:43 step:34215 [D loss: 0.180440, acc: 97.66%] [G loss: 2.458474]\n",
      "epoch:43 step:34216 [D loss: 0.589185, acc: 70.31%] [G loss: 4.284217]\n",
      "epoch:43 step:34217 [D loss: 0.377550, acc: 89.84%] [G loss: 4.664374]\n",
      "epoch:43 step:34218 [D loss: 0.043037, acc: 100.00%] [G loss: 5.000065]\n",
      "epoch:43 step:34219 [D loss: 0.126811, acc: 96.88%] [G loss: 4.640242]\n",
      "epoch:43 step:34220 [D loss: 0.174948, acc: 96.09%] [G loss: 2.475950]\n",
      "epoch:43 step:34221 [D loss: 0.898501, acc: 48.44%] [G loss: 6.147101]\n",
      "epoch:43 step:34222 [D loss: 0.312724, acc: 89.06%] [G loss: 6.018065]\n",
      "epoch:43 step:34223 [D loss: 0.095961, acc: 99.22%] [G loss: 4.006968]\n",
      "epoch:43 step:34224 [D loss: 0.104120, acc: 100.00%] [G loss: 7.486453]\n",
      "epoch:43 step:34225 [D loss: 0.015200, acc: 100.00%] [G loss: 9.547394]\n",
      "epoch:43 step:34226 [D loss: 0.110280, acc: 99.22%] [G loss: 6.648768]\n",
      "epoch:43 step:34227 [D loss: 0.078013, acc: 99.22%] [G loss: 2.558052]\n",
      "epoch:43 step:34228 [D loss: 0.536635, acc: 71.09%] [G loss: 4.746501]\n",
      "epoch:43 step:34229 [D loss: 0.461701, acc: 71.09%] [G loss: 1.556425]\n",
      "epoch:43 step:34230 [D loss: 0.106035, acc: 99.22%] [G loss: 4.990745]\n",
      "epoch:43 step:34231 [D loss: 0.391311, acc: 74.22%] [G loss: 5.508481]\n",
      "epoch:43 step:34232 [D loss: 0.109280, acc: 99.22%] [G loss: 5.878413]\n",
      "epoch:43 step:34233 [D loss: 0.073163, acc: 100.00%] [G loss: 8.439382]\n",
      "epoch:43 step:34234 [D loss: 0.234518, acc: 96.88%] [G loss: 6.153371]\n",
      "epoch:43 step:34235 [D loss: 0.068015, acc: 100.00%] [G loss: 6.264748]\n",
      "epoch:43 step:34236 [D loss: 0.227360, acc: 94.53%] [G loss: 6.710308]\n",
      "epoch:43 step:34237 [D loss: 1.368764, acc: 14.06%] [G loss: 7.889199]\n",
      "epoch:43 step:34238 [D loss: 0.105143, acc: 98.44%] [G loss: 5.560859]\n",
      "epoch:43 step:34239 [D loss: 0.263176, acc: 91.41%] [G loss: 5.093184]\n",
      "epoch:43 step:34240 [D loss: 0.926648, acc: 34.38%] [G loss: 5.111318]\n",
      "epoch:43 step:34241 [D loss: 0.216110, acc: 98.44%] [G loss: 4.664913]\n",
      "epoch:43 step:34242 [D loss: 0.404019, acc: 75.78%] [G loss: 5.860227]\n",
      "epoch:43 step:34243 [D loss: 0.334634, acc: 77.34%] [G loss: 6.738173]\n",
      "epoch:43 step:34244 [D loss: 0.165726, acc: 97.66%] [G loss: 3.337639]\n",
      "epoch:43 step:34245 [D loss: 0.302494, acc: 92.97%] [G loss: 5.612228]\n",
      "epoch:43 step:34246 [D loss: 0.070835, acc: 99.22%] [G loss: 5.275955]\n",
      "epoch:43 step:34247 [D loss: 0.033722, acc: 100.00%] [G loss: 4.624101]\n",
      "epoch:43 step:34248 [D loss: 2.020813, acc: 2.34%] [G loss: 8.964591]\n",
      "epoch:43 step:34249 [D loss: 0.197799, acc: 96.09%] [G loss: 3.660997]\n",
      "epoch:43 step:34250 [D loss: 0.401305, acc: 87.50%] [G loss: 7.728948]\n",
      "epoch:43 step:34251 [D loss: 0.045012, acc: 100.00%] [G loss: 5.463876]\n",
      "epoch:43 step:34252 [D loss: 0.571575, acc: 64.06%] [G loss: 8.033415]\n",
      "epoch:43 step:34253 [D loss: 0.069259, acc: 100.00%] [G loss: 6.728770]\n",
      "epoch:43 step:34254 [D loss: 0.081936, acc: 100.00%] [G loss: 7.375279]\n",
      "epoch:43 step:34255 [D loss: 0.240812, acc: 89.06%] [G loss: 5.660020]\n",
      "epoch:43 step:34256 [D loss: 1.088504, acc: 26.56%] [G loss: 9.440243]\n",
      "epoch:43 step:34257 [D loss: 0.169466, acc: 95.31%] [G loss: 7.349813]\n",
      "epoch:43 step:34258 [D loss: 0.956923, acc: 50.78%] [G loss: 4.780798]\n",
      "epoch:43 step:34259 [D loss: 0.840764, acc: 46.09%] [G loss: 11.126042]\n",
      "epoch:43 step:34260 [D loss: 0.192922, acc: 92.97%] [G loss: 7.879917]\n",
      "epoch:43 step:34261 [D loss: 0.483004, acc: 74.22%] [G loss: 6.903200]\n",
      "epoch:43 step:34262 [D loss: 0.068322, acc: 100.00%] [G loss: 5.268879]\n",
      "epoch:43 step:34263 [D loss: 0.322619, acc: 91.41%] [G loss: 4.641242]\n",
      "epoch:43 step:34264 [D loss: 0.088378, acc: 99.22%] [G loss: 5.389003]\n",
      "epoch:43 step:34265 [D loss: 0.288204, acc: 93.75%] [G loss: 5.097090]\n",
      "epoch:43 step:34266 [D loss: 0.278301, acc: 89.84%] [G loss: 4.591935]\n",
      "epoch:43 step:34267 [D loss: 0.109719, acc: 100.00%] [G loss: 5.429900]\n",
      "epoch:43 step:34268 [D loss: 0.709293, acc: 57.81%] [G loss: 3.989938]\n",
      "epoch:43 step:34269 [D loss: 0.117791, acc: 100.00%] [G loss: 4.791604]\n",
      "epoch:43 step:34270 [D loss: 0.247261, acc: 92.97%] [G loss: 3.672745]\n",
      "epoch:43 step:34271 [D loss: 0.038759, acc: 100.00%] [G loss: 4.240591]\n",
      "epoch:43 step:34272 [D loss: 0.480871, acc: 78.91%] [G loss: 4.466568]\n",
      "epoch:43 step:34273 [D loss: 0.093721, acc: 99.22%] [G loss: 4.523979]\n",
      "epoch:43 step:34274 [D loss: 0.167680, acc: 97.66%] [G loss: 7.235538]\n",
      "epoch:43 step:34275 [D loss: 1.575365, acc: 13.28%] [G loss: 11.226746]\n",
      "epoch:43 step:34276 [D loss: 0.160860, acc: 100.00%] [G loss: 2.504989]\n",
      "epoch:43 step:34277 [D loss: 0.763435, acc: 56.25%] [G loss: 6.594593]\n",
      "epoch:43 step:34278 [D loss: 0.082728, acc: 100.00%] [G loss: 7.789170]\n",
      "epoch:43 step:34279 [D loss: 0.214161, acc: 95.31%] [G loss: 5.457529]\n",
      "epoch:43 step:34280 [D loss: 0.140095, acc: 99.22%] [G loss: 4.211888]\n",
      "epoch:43 step:34281 [D loss: 0.222044, acc: 93.75%] [G loss: 7.637156]\n",
      "epoch:43 step:34282 [D loss: 0.084352, acc: 100.00%] [G loss: 5.244430]\n",
      "epoch:43 step:34283 [D loss: 0.404836, acc: 73.44%] [G loss: 3.759540]\n",
      "epoch:43 step:34284 [D loss: 0.260253, acc: 90.62%] [G loss: 4.007906]\n",
      "epoch:43 step:34285 [D loss: 0.319751, acc: 87.50%] [G loss: 2.621624]\n",
      "epoch:43 step:34286 [D loss: 0.182362, acc: 99.22%] [G loss: 4.266240]\n",
      "epoch:43 step:34287 [D loss: 0.586547, acc: 68.75%] [G loss: 5.615454]\n",
      "epoch:43 step:34288 [D loss: 0.134427, acc: 98.44%] [G loss: 5.320685]\n",
      "epoch:43 step:34289 [D loss: 0.024887, acc: 100.00%] [G loss: 8.793625]\n",
      "epoch:43 step:34290 [D loss: 0.070903, acc: 100.00%] [G loss: 5.733213]\n",
      "epoch:43 step:34291 [D loss: 0.055466, acc: 100.00%] [G loss: 9.340244]\n",
      "epoch:43 step:34292 [D loss: 0.302463, acc: 90.62%] [G loss: 5.700327]\n",
      "epoch:43 step:34293 [D loss: 0.098077, acc: 99.22%] [G loss: 5.367896]\n",
      "epoch:43 step:34294 [D loss: 0.005994, acc: 100.00%] [G loss: 8.132076]\n",
      "epoch:43 step:34295 [D loss: 1.653073, acc: 39.84%] [G loss: 8.733201]\n",
      "epoch:43 step:34296 [D loss: 0.221939, acc: 92.19%] [G loss: 7.556779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34297 [D loss: 0.106950, acc: 99.22%] [G loss: 6.834052]\n",
      "epoch:43 step:34298 [D loss: 0.020272, acc: 100.00%] [G loss: 5.770073]\n",
      "epoch:43 step:34299 [D loss: 0.361185, acc: 94.53%] [G loss: 10.146822]\n",
      "epoch:43 step:34300 [D loss: 0.031882, acc: 100.00%] [G loss: 7.934162]\n",
      "epoch:43 step:34301 [D loss: 0.234127, acc: 91.41%] [G loss: 9.131364]\n",
      "epoch:43 step:34302 [D loss: 1.064837, acc: 51.56%] [G loss: 3.973403]\n",
      "epoch:43 step:34303 [D loss: 0.016507, acc: 100.00%] [G loss: 4.958235]\n",
      "epoch:43 step:34304 [D loss: 0.159690, acc: 98.44%] [G loss: 10.390272]\n",
      "epoch:43 step:34305 [D loss: 0.699183, acc: 53.91%] [G loss: 8.118111]\n",
      "epoch:43 step:34306 [D loss: 0.438746, acc: 71.09%] [G loss: 6.683129]\n",
      "epoch:43 step:34307 [D loss: 0.055946, acc: 100.00%] [G loss: 4.065317]\n",
      "epoch:43 step:34308 [D loss: 0.307248, acc: 87.50%] [G loss: 7.795220]\n",
      "epoch:43 step:34309 [D loss: 0.199859, acc: 98.44%] [G loss: 4.110602]\n",
      "epoch:43 step:34310 [D loss: 0.055139, acc: 100.00%] [G loss: 6.209420]\n",
      "epoch:43 step:34311 [D loss: 0.126218, acc: 98.44%] [G loss: 7.075817]\n",
      "epoch:43 step:34312 [D loss: 0.051262, acc: 100.00%] [G loss: 5.260970]\n",
      "epoch:43 step:34313 [D loss: 0.038608, acc: 100.00%] [G loss: 4.709872]\n",
      "epoch:43 step:34314 [D loss: 0.482403, acc: 69.53%] [G loss: 7.614104]\n",
      "epoch:43 step:34315 [D loss: 0.529154, acc: 60.94%] [G loss: 5.388587]\n",
      "epoch:43 step:34316 [D loss: 1.234412, acc: 46.88%] [G loss: 3.754493]\n",
      "epoch:43 step:34317 [D loss: 0.144865, acc: 100.00%] [G loss: 4.928440]\n",
      "epoch:43 step:34318 [D loss: 0.132098, acc: 100.00%] [G loss: 6.260421]\n",
      "epoch:43 step:34319 [D loss: 0.142683, acc: 100.00%] [G loss: 5.530410]\n",
      "epoch:43 step:34320 [D loss: 0.169499, acc: 99.22%] [G loss: 6.738041]\n",
      "epoch:43 step:34321 [D loss: 0.111451, acc: 97.66%] [G loss: 3.870339]\n",
      "epoch:43 step:34322 [D loss: 0.268953, acc: 91.41%] [G loss: 6.145505]\n",
      "epoch:43 step:34323 [D loss: 0.110041, acc: 100.00%] [G loss: 6.255944]\n",
      "epoch:43 step:34324 [D loss: 0.153140, acc: 100.00%] [G loss: 2.611462]\n",
      "epoch:43 step:34325 [D loss: 1.232093, acc: 50.00%] [G loss: 6.462214]\n",
      "epoch:43 step:34326 [D loss: 0.721190, acc: 58.59%] [G loss: 4.028388]\n",
      "epoch:43 step:34327 [D loss: 0.913184, acc: 50.78%] [G loss: 5.504889]\n",
      "epoch:43 step:34328 [D loss: 0.013903, acc: 100.00%] [G loss: 5.691462]\n",
      "epoch:43 step:34329 [D loss: 0.244502, acc: 92.97%] [G loss: 2.921100]\n",
      "epoch:43 step:34330 [D loss: 0.551263, acc: 68.75%] [G loss: 6.657341]\n",
      "epoch:43 step:34331 [D loss: 0.381527, acc: 87.50%] [G loss: 4.410107]\n",
      "epoch:43 step:34332 [D loss: 0.339382, acc: 88.28%] [G loss: 5.760017]\n",
      "epoch:43 step:34333 [D loss: 0.201318, acc: 98.44%] [G loss: 3.592415]\n",
      "epoch:43 step:34334 [D loss: 0.050660, acc: 100.00%] [G loss: 3.888251]\n",
      "epoch:43 step:34335 [D loss: 0.134254, acc: 96.88%] [G loss: 3.708287]\n",
      "epoch:43 step:34336 [D loss: 0.559688, acc: 57.81%] [G loss: 4.048089]\n",
      "epoch:43 step:34337 [D loss: 0.246109, acc: 92.19%] [G loss: 7.674645]\n",
      "epoch:43 step:34338 [D loss: 1.964620, acc: 50.00%] [G loss: 8.923191]\n",
      "epoch:43 step:34339 [D loss: 0.137549, acc: 100.00%] [G loss: 6.270135]\n",
      "epoch:43 step:34340 [D loss: 0.427353, acc: 75.78%] [G loss: 4.692051]\n",
      "epoch:43 step:34341 [D loss: 0.043074, acc: 100.00%] [G loss: 7.114996]\n",
      "epoch:43 step:34342 [D loss: 0.166300, acc: 99.22%] [G loss: 6.410506]\n",
      "epoch:43 step:34343 [D loss: 0.038938, acc: 100.00%] [G loss: 6.314182]\n",
      "epoch:43 step:34344 [D loss: 0.025959, acc: 100.00%] [G loss: 6.528996]\n",
      "epoch:43 step:34345 [D loss: 0.092526, acc: 100.00%] [G loss: 4.196990]\n",
      "epoch:43 step:34346 [D loss: 0.918234, acc: 51.56%] [G loss: 4.454199]\n",
      "epoch:43 step:34347 [D loss: 0.157922, acc: 98.44%] [G loss: 5.926637]\n",
      "epoch:43 step:34348 [D loss: 0.334879, acc: 79.69%] [G loss: 5.585196]\n",
      "epoch:43 step:34349 [D loss: 0.127930, acc: 99.22%] [G loss: 4.948828]\n",
      "epoch:43 step:34350 [D loss: 0.092304, acc: 100.00%] [G loss: 4.910306]\n",
      "epoch:43 step:34351 [D loss: 0.115049, acc: 100.00%] [G loss: 5.072231]\n",
      "epoch:43 step:34352 [D loss: 0.238796, acc: 96.88%] [G loss: 4.832265]\n",
      "epoch:43 step:34353 [D loss: 0.160423, acc: 99.22%] [G loss: 5.065386]\n",
      "epoch:43 step:34354 [D loss: 0.788905, acc: 47.66%] [G loss: 7.635622]\n",
      "epoch:43 step:34355 [D loss: 0.204449, acc: 97.66%] [G loss: 4.209266]\n",
      "epoch:43 step:34356 [D loss: 0.019010, acc: 100.00%] [G loss: 10.956806]\n",
      "epoch:43 step:34357 [D loss: 0.104995, acc: 99.22%] [G loss: 5.129634]\n",
      "epoch:43 step:34358 [D loss: 1.851177, acc: 22.66%] [G loss: 10.802279]\n",
      "epoch:43 step:34359 [D loss: 0.245197, acc: 96.09%] [G loss: 4.489764]\n",
      "epoch:43 step:34360 [D loss: 0.983892, acc: 50.00%] [G loss: 9.978460]\n",
      "epoch:43 step:34361 [D loss: 0.273576, acc: 89.84%] [G loss: 6.167274]\n",
      "epoch:43 step:34362 [D loss: 0.345474, acc: 86.72%] [G loss: 5.468395]\n",
      "epoch:43 step:34363 [D loss: 1.285165, acc: 50.00%] [G loss: 7.225164]\n",
      "epoch:43 step:34364 [D loss: 0.514366, acc: 74.22%] [G loss: 4.674831]\n",
      "epoch:44 step:34365 [D loss: 0.298959, acc: 85.16%] [G loss: 5.252949]\n",
      "epoch:44 step:34366 [D loss: 0.226826, acc: 96.88%] [G loss: 5.780320]\n",
      "epoch:44 step:34367 [D loss: 1.091487, acc: 50.00%] [G loss: 3.675367]\n",
      "epoch:44 step:34368 [D loss: 0.313175, acc: 85.16%] [G loss: 8.630014]\n",
      "epoch:44 step:34369 [D loss: 0.233522, acc: 91.41%] [G loss: 5.235488]\n",
      "epoch:44 step:34370 [D loss: 0.176870, acc: 99.22%] [G loss: 4.931552]\n",
      "epoch:44 step:34371 [D loss: 1.272083, acc: 50.00%] [G loss: 4.898377]\n",
      "epoch:44 step:34372 [D loss: 0.178453, acc: 98.44%] [G loss: 5.536331]\n",
      "epoch:44 step:34373 [D loss: 0.555866, acc: 61.72%] [G loss: 9.802841]\n",
      "epoch:44 step:34374 [D loss: 0.161686, acc: 96.09%] [G loss: 7.335414]\n",
      "epoch:44 step:34375 [D loss: 0.149909, acc: 99.22%] [G loss: 4.335462]\n",
      "epoch:44 step:34376 [D loss: 1.303669, acc: 11.72%] [G loss: 4.974991]\n",
      "epoch:44 step:34377 [D loss: 0.336673, acc: 82.81%] [G loss: 5.021154]\n",
      "epoch:44 step:34378 [D loss: 0.427594, acc: 89.06%] [G loss: 4.889366]\n",
      "epoch:44 step:34379 [D loss: 0.842748, acc: 50.00%] [G loss: 6.228180]\n",
      "epoch:44 step:34380 [D loss: 0.299576, acc: 94.53%] [G loss: 5.393518]\n",
      "epoch:44 step:34381 [D loss: 0.238869, acc: 98.44%] [G loss: 6.573601]\n",
      "epoch:44 step:34382 [D loss: 0.855606, acc: 40.62%] [G loss: 4.761092]\n",
      "epoch:44 step:34383 [D loss: 0.524503, acc: 70.31%] [G loss: 3.830486]\n",
      "epoch:44 step:34384 [D loss: 0.333251, acc: 89.84%] [G loss: 6.065163]\n",
      "epoch:44 step:34385 [D loss: 0.259280, acc: 95.31%] [G loss: 3.243968]\n",
      "epoch:44 step:34386 [D loss: 0.095925, acc: 100.00%] [G loss: 3.173125]\n",
      "epoch:44 step:34387 [D loss: 0.607957, acc: 57.81%] [G loss: 5.242422]\n",
      "epoch:44 step:34388 [D loss: 0.143532, acc: 98.44%] [G loss: 6.050569]\n",
      "epoch:44 step:34389 [D loss: 1.023096, acc: 50.00%] [G loss: 10.813412]\n",
      "epoch:44 step:34390 [D loss: 0.054563, acc: 100.00%] [G loss: 5.425362]\n",
      "epoch:44 step:34391 [D loss: 1.605109, acc: 50.00%] [G loss: 4.316895]\n",
      "epoch:44 step:34392 [D loss: 0.052541, acc: 100.00%] [G loss: 5.657082]\n",
      "epoch:44 step:34393 [D loss: 0.282918, acc: 92.19%] [G loss: 4.318564]\n",
      "epoch:44 step:34394 [D loss: 0.038411, acc: 100.00%] [G loss: 5.298470]\n",
      "epoch:44 step:34395 [D loss: 0.346255, acc: 87.50%] [G loss: 5.729010]\n",
      "epoch:44 step:34396 [D loss: 0.045198, acc: 100.00%] [G loss: 6.520432]\n",
      "epoch:44 step:34397 [D loss: 0.214697, acc: 97.66%] [G loss: 4.266147]\n",
      "epoch:44 step:34398 [D loss: 0.010170, acc: 100.00%] [G loss: 4.583508]\n",
      "epoch:44 step:34399 [D loss: 1.412048, acc: 50.78%] [G loss: 7.077049]\n",
      "epoch:44 step:34400 [D loss: 1.079438, acc: 50.00%] [G loss: 6.213921]\n",
      "epoch:44 step:34401 [D loss: 0.031021, acc: 100.00%] [G loss: 9.095848]\n",
      "epoch:44 step:34402 [D loss: 0.263000, acc: 93.75%] [G loss: 5.311298]\n",
      "epoch:44 step:34403 [D loss: 1.303271, acc: 22.66%] [G loss: 5.748366]\n",
      "epoch:44 step:34404 [D loss: 0.350063, acc: 80.47%] [G loss: 8.976530]\n",
      "epoch:44 step:34405 [D loss: 0.200246, acc: 100.00%] [G loss: 5.236360]\n",
      "epoch:44 step:34406 [D loss: 0.202441, acc: 96.88%] [G loss: 3.641372]\n",
      "epoch:44 step:34407 [D loss: 0.140970, acc: 98.44%] [G loss: 5.324508]\n",
      "epoch:44 step:34408 [D loss: 0.121151, acc: 97.66%] [G loss: 5.099806]\n",
      "epoch:44 step:34409 [D loss: 0.023114, acc: 100.00%] [G loss: 4.918029]\n",
      "epoch:44 step:34410 [D loss: 0.262542, acc: 97.66%] [G loss: 6.921929]\n",
      "epoch:44 step:34411 [D loss: 0.041775, acc: 100.00%] [G loss: 5.856121]\n",
      "epoch:44 step:34412 [D loss: 0.230208, acc: 98.44%] [G loss: 3.053130]\n",
      "epoch:44 step:34413 [D loss: 0.067483, acc: 100.00%] [G loss: 4.661265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34414 [D loss: 0.193371, acc: 94.53%] [G loss: 3.910873]\n",
      "epoch:44 step:34415 [D loss: 0.392877, acc: 73.44%] [G loss: 5.414828]\n",
      "epoch:44 step:34416 [D loss: 0.895532, acc: 51.56%] [G loss: 6.747096]\n",
      "epoch:44 step:34417 [D loss: 0.380174, acc: 78.91%] [G loss: 3.823735]\n",
      "epoch:44 step:34418 [D loss: 0.797795, acc: 52.34%] [G loss: 7.390871]\n",
      "epoch:44 step:34419 [D loss: 0.109838, acc: 99.22%] [G loss: 6.425845]\n",
      "epoch:44 step:34420 [D loss: 0.782671, acc: 51.56%] [G loss: 7.845686]\n",
      "epoch:44 step:34421 [D loss: 0.511615, acc: 79.69%] [G loss: 4.254457]\n",
      "epoch:44 step:34422 [D loss: 0.218217, acc: 90.62%] [G loss: 7.212584]\n",
      "epoch:44 step:34423 [D loss: 1.005210, acc: 40.62%] [G loss: 5.397411]\n",
      "epoch:44 step:34424 [D loss: 0.199307, acc: 98.44%] [G loss: 6.759583]\n",
      "epoch:44 step:34425 [D loss: 0.259888, acc: 92.97%] [G loss: 4.034122]\n",
      "epoch:44 step:34426 [D loss: 0.187974, acc: 96.09%] [G loss: 8.504715]\n",
      "epoch:44 step:34427 [D loss: 0.918480, acc: 43.75%] [G loss: 6.260727]\n",
      "epoch:44 step:34428 [D loss: 0.402056, acc: 89.84%] [G loss: 5.268526]\n",
      "epoch:44 step:34429 [D loss: 0.553964, acc: 67.19%] [G loss: 3.224321]\n",
      "epoch:44 step:34430 [D loss: 0.195393, acc: 92.19%] [G loss: 4.647781]\n",
      "epoch:44 step:34431 [D loss: 0.467594, acc: 63.28%] [G loss: 6.252430]\n",
      "epoch:44 step:34432 [D loss: 0.227210, acc: 93.75%] [G loss: 4.749591]\n",
      "epoch:44 step:34433 [D loss: 0.115982, acc: 99.22%] [G loss: 3.656708]\n",
      "epoch:44 step:34434 [D loss: 0.019614, acc: 100.00%] [G loss: 5.947687]\n",
      "epoch:44 step:34435 [D loss: 0.034121, acc: 100.00%] [G loss: 6.837539]\n",
      "epoch:44 step:34436 [D loss: 1.750923, acc: 49.22%] [G loss: 6.138018]\n",
      "epoch:44 step:34437 [D loss: 1.192024, acc: 21.09%] [G loss: 3.137447]\n",
      "epoch:44 step:34438 [D loss: 0.273672, acc: 92.97%] [G loss: 2.954023]\n",
      "epoch:44 step:34439 [D loss: 0.214092, acc: 96.88%] [G loss: 9.489106]\n",
      "epoch:44 step:34440 [D loss: 1.061292, acc: 49.22%] [G loss: 6.925639]\n",
      "epoch:44 step:34441 [D loss: 0.601694, acc: 59.38%] [G loss: 7.489085]\n",
      "epoch:44 step:34442 [D loss: 0.034627, acc: 100.00%] [G loss: 6.459056]\n",
      "epoch:44 step:34443 [D loss: 0.090948, acc: 99.22%] [G loss: 8.192184]\n",
      "epoch:44 step:34444 [D loss: 0.070404, acc: 98.44%] [G loss: 10.616808]\n",
      "epoch:44 step:34445 [D loss: 0.101765, acc: 100.00%] [G loss: 8.389652]\n",
      "epoch:44 step:34446 [D loss: 0.129778, acc: 100.00%] [G loss: 3.317729]\n",
      "epoch:44 step:34447 [D loss: 0.233075, acc: 95.31%] [G loss: 5.725685]\n",
      "epoch:44 step:34448 [D loss: 0.353919, acc: 86.72%] [G loss: 4.022660]\n",
      "epoch:44 step:34449 [D loss: 0.876050, acc: 46.09%] [G loss: 5.451712]\n",
      "epoch:44 step:34450 [D loss: 0.192578, acc: 95.31%] [G loss: 4.590662]\n",
      "epoch:44 step:34451 [D loss: 0.326037, acc: 91.41%] [G loss: 5.732472]\n",
      "epoch:44 step:34452 [D loss: 0.556404, acc: 73.44%] [G loss: 4.225979]\n",
      "epoch:44 step:34453 [D loss: 0.527178, acc: 59.38%] [G loss: 5.920819]\n",
      "epoch:44 step:34454 [D loss: 0.292961, acc: 85.16%] [G loss: 6.225098]\n",
      "epoch:44 step:34455 [D loss: 0.060422, acc: 100.00%] [G loss: 6.781318]\n",
      "epoch:44 step:34456 [D loss: 0.105357, acc: 100.00%] [G loss: 4.779917]\n",
      "epoch:44 step:34457 [D loss: 0.640380, acc: 64.06%] [G loss: 7.431706]\n",
      "epoch:44 step:34458 [D loss: 0.889699, acc: 35.94%] [G loss: 7.418825]\n",
      "epoch:44 step:34459 [D loss: 0.243556, acc: 96.09%] [G loss: 8.006607]\n",
      "epoch:44 step:34460 [D loss: 0.141753, acc: 99.22%] [G loss: 7.208560]\n",
      "epoch:44 step:34461 [D loss: 0.109838, acc: 97.66%] [G loss: 4.477004]\n",
      "epoch:44 step:34462 [D loss: 0.042185, acc: 100.00%] [G loss: 7.478178]\n",
      "epoch:44 step:34463 [D loss: 0.224603, acc: 96.88%] [G loss: 6.605652]\n",
      "epoch:44 step:34464 [D loss: 0.127573, acc: 98.44%] [G loss: 4.900094]\n",
      "epoch:44 step:34465 [D loss: 0.096483, acc: 100.00%] [G loss: 4.626629]\n",
      "epoch:44 step:34466 [D loss: 0.307364, acc: 89.84%] [G loss: 4.542834]\n",
      "epoch:44 step:34467 [D loss: 0.103035, acc: 99.22%] [G loss: 4.703488]\n",
      "epoch:44 step:34468 [D loss: 0.019460, acc: 100.00%] [G loss: 7.231860]\n",
      "epoch:44 step:34469 [D loss: 0.091911, acc: 100.00%] [G loss: 4.225858]\n",
      "epoch:44 step:34470 [D loss: 0.070467, acc: 100.00%] [G loss: 4.901906]\n",
      "epoch:44 step:34471 [D loss: 0.898263, acc: 30.47%] [G loss: 4.299836]\n",
      "epoch:44 step:34472 [D loss: 0.111606, acc: 99.22%] [G loss: 2.435401]\n",
      "epoch:44 step:34473 [D loss: 0.073472, acc: 100.00%] [G loss: 5.025126]\n",
      "epoch:44 step:34474 [D loss: 0.646922, acc: 58.59%] [G loss: 6.573076]\n",
      "epoch:44 step:34475 [D loss: 1.014917, acc: 32.03%] [G loss: 9.586772]\n",
      "epoch:44 step:34476 [D loss: 0.097317, acc: 100.00%] [G loss: 2.589961]\n",
      "epoch:44 step:34477 [D loss: 0.144332, acc: 99.22%] [G loss: 4.453066]\n",
      "epoch:44 step:34478 [D loss: 0.140750, acc: 100.00%] [G loss: 3.802778]\n",
      "epoch:44 step:34479 [D loss: 0.058529, acc: 100.00%] [G loss: 3.691302]\n",
      "epoch:44 step:34480 [D loss: 0.147664, acc: 99.22%] [G loss: 5.509445]\n",
      "epoch:44 step:34481 [D loss: 0.124872, acc: 99.22%] [G loss: 5.891739]\n",
      "epoch:44 step:34482 [D loss: 0.279805, acc: 89.84%] [G loss: 3.301420]\n",
      "epoch:44 step:34483 [D loss: 0.382879, acc: 81.25%] [G loss: 4.601300]\n",
      "epoch:44 step:34484 [D loss: 0.097713, acc: 100.00%] [G loss: 5.030674]\n",
      "epoch:44 step:34485 [D loss: 0.151578, acc: 96.88%] [G loss: 7.342868]\n",
      "epoch:44 step:34486 [D loss: 0.337687, acc: 82.03%] [G loss: 7.218845]\n",
      "epoch:44 step:34487 [D loss: 0.316936, acc: 89.84%] [G loss: 5.166456]\n",
      "epoch:44 step:34488 [D loss: 0.327155, acc: 93.75%] [G loss: 5.324844]\n",
      "epoch:44 step:34489 [D loss: 0.633532, acc: 58.59%] [G loss: 1.885436]\n",
      "epoch:44 step:34490 [D loss: 1.360563, acc: 25.78%] [G loss: 8.497397]\n",
      "epoch:44 step:34491 [D loss: 0.707490, acc: 54.69%] [G loss: 7.500879]\n",
      "epoch:44 step:34492 [D loss: 0.233522, acc: 89.84%] [G loss: 6.903985]\n",
      "epoch:44 step:34493 [D loss: 0.035781, acc: 100.00%] [G loss: 5.908424]\n",
      "epoch:44 step:34494 [D loss: 0.400308, acc: 85.16%] [G loss: 8.669506]\n",
      "epoch:44 step:34495 [D loss: 0.846168, acc: 48.44%] [G loss: 4.296242]\n",
      "epoch:44 step:34496 [D loss: 0.167318, acc: 95.31%] [G loss: 8.124082]\n",
      "epoch:44 step:34497 [D loss: 0.285479, acc: 89.84%] [G loss: 5.551620]\n",
      "epoch:44 step:34498 [D loss: 0.318561, acc: 93.75%] [G loss: 4.923305]\n",
      "epoch:44 step:34499 [D loss: 0.306843, acc: 85.94%] [G loss: 5.689097]\n",
      "epoch:44 step:34500 [D loss: 0.265443, acc: 97.66%] [G loss: 4.168808]\n",
      "epoch:44 step:34501 [D loss: 0.252634, acc: 95.31%] [G loss: 4.972240]\n",
      "epoch:44 step:34502 [D loss: 0.427278, acc: 75.00%] [G loss: 6.999431]\n",
      "epoch:44 step:34503 [D loss: 0.115814, acc: 100.00%] [G loss: 4.335600]\n",
      "epoch:44 step:34504 [D loss: 0.183487, acc: 98.44%] [G loss: 5.607175]\n",
      "epoch:44 step:34505 [D loss: 0.697508, acc: 55.47%] [G loss: 4.809910]\n",
      "epoch:44 step:34506 [D loss: 0.034671, acc: 100.00%] [G loss: 5.465882]\n",
      "epoch:44 step:34507 [D loss: 0.186412, acc: 99.22%] [G loss: 2.530719]\n",
      "epoch:44 step:34508 [D loss: 0.700953, acc: 53.91%] [G loss: 5.514141]\n",
      "epoch:44 step:34509 [D loss: 0.092434, acc: 99.22%] [G loss: 3.488462]\n",
      "epoch:44 step:34510 [D loss: 0.029081, acc: 100.00%] [G loss: 7.487653]\n",
      "epoch:44 step:34511 [D loss: 0.207367, acc: 97.66%] [G loss: 2.505626]\n",
      "epoch:44 step:34512 [D loss: 1.117747, acc: 50.00%] [G loss: 6.794664]\n",
      "epoch:44 step:34513 [D loss: 0.829919, acc: 50.78%] [G loss: 7.518624]\n",
      "epoch:44 step:34514 [D loss: 0.227082, acc: 95.31%] [G loss: 5.713935]\n",
      "epoch:44 step:34515 [D loss: 0.139397, acc: 100.00%] [G loss: 4.073475]\n",
      "epoch:44 step:34516 [D loss: 0.227181, acc: 96.09%] [G loss: 2.448004]\n",
      "epoch:44 step:34517 [D loss: 0.559607, acc: 71.09%] [G loss: 7.217201]\n",
      "epoch:44 step:34518 [D loss: 0.217303, acc: 97.66%] [G loss: 3.876775]\n",
      "epoch:44 step:34519 [D loss: 0.020383, acc: 100.00%] [G loss: 8.211825]\n",
      "epoch:44 step:34520 [D loss: 0.908478, acc: 36.72%] [G loss: 3.904849]\n",
      "epoch:44 step:34521 [D loss: 0.032287, acc: 100.00%] [G loss: 4.024617]\n",
      "epoch:44 step:34522 [D loss: 0.176586, acc: 100.00%] [G loss: 5.210171]\n",
      "epoch:44 step:34523 [D loss: 0.064352, acc: 100.00%] [G loss: 6.813264]\n",
      "epoch:44 step:34524 [D loss: 0.429451, acc: 85.94%] [G loss: 6.993827]\n",
      "epoch:44 step:34525 [D loss: 0.029676, acc: 100.00%] [G loss: 6.895495]\n",
      "epoch:44 step:34526 [D loss: 0.204646, acc: 96.88%] [G loss: 3.092304]\n",
      "epoch:44 step:34527 [D loss: 0.229575, acc: 99.22%] [G loss: 4.797781]\n",
      "epoch:44 step:34528 [D loss: 0.321144, acc: 89.84%] [G loss: 6.440839]\n",
      "epoch:44 step:34529 [D loss: 0.777378, acc: 50.78%] [G loss: 6.252390]\n",
      "epoch:44 step:34530 [D loss: 0.561188, acc: 70.31%] [G loss: 5.020444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34531 [D loss: 0.921773, acc: 37.50%] [G loss: 5.479838]\n",
      "epoch:44 step:34532 [D loss: 0.076683, acc: 98.44%] [G loss: 4.520398]\n",
      "epoch:44 step:34533 [D loss: 0.177686, acc: 98.44%] [G loss: 5.536758]\n",
      "epoch:44 step:34534 [D loss: 0.068193, acc: 99.22%] [G loss: 7.172054]\n",
      "epoch:44 step:34535 [D loss: 0.296344, acc: 84.38%] [G loss: 5.777091]\n",
      "epoch:44 step:34536 [D loss: 0.130954, acc: 98.44%] [G loss: 5.906421]\n",
      "epoch:44 step:34537 [D loss: 0.328500, acc: 92.19%] [G loss: 4.054613]\n",
      "epoch:44 step:34538 [D loss: 0.155887, acc: 100.00%] [G loss: 7.444561]\n",
      "epoch:44 step:34539 [D loss: 0.016017, acc: 100.00%] [G loss: 9.707415]\n",
      "epoch:44 step:34540 [D loss: 0.061762, acc: 100.00%] [G loss: 6.862377]\n",
      "epoch:44 step:34541 [D loss: 0.084899, acc: 100.00%] [G loss: 5.026711]\n",
      "epoch:44 step:34542 [D loss: 0.265384, acc: 89.06%] [G loss: 8.190949]\n",
      "epoch:44 step:34543 [D loss: 0.287271, acc: 87.50%] [G loss: 3.405264]\n",
      "epoch:44 step:34544 [D loss: 0.134693, acc: 100.00%] [G loss: 6.549007]\n",
      "epoch:44 step:34545 [D loss: 0.971155, acc: 28.91%] [G loss: 7.976630]\n",
      "epoch:44 step:34546 [D loss: 0.077370, acc: 100.00%] [G loss: 6.543636]\n",
      "epoch:44 step:34547 [D loss: 0.044129, acc: 100.00%] [G loss: 5.148522]\n",
      "epoch:44 step:34548 [D loss: 0.075374, acc: 100.00%] [G loss: 6.996595]\n",
      "epoch:44 step:34549 [D loss: 0.078364, acc: 99.22%] [G loss: 5.912481]\n",
      "epoch:44 step:34550 [D loss: 0.428880, acc: 79.69%] [G loss: 7.367110]\n",
      "epoch:44 step:34551 [D loss: 0.029176, acc: 100.00%] [G loss: 7.034092]\n",
      "epoch:44 step:34552 [D loss: 0.824504, acc: 53.91%] [G loss: 9.132582]\n",
      "epoch:44 step:34553 [D loss: 0.120964, acc: 99.22%] [G loss: 6.138574]\n",
      "epoch:44 step:34554 [D loss: 0.712736, acc: 57.03%] [G loss: 5.311257]\n",
      "epoch:44 step:34555 [D loss: 0.701886, acc: 56.25%] [G loss: 5.193112]\n",
      "epoch:44 step:34556 [D loss: 0.321114, acc: 80.47%] [G loss: 7.815089]\n",
      "epoch:44 step:34557 [D loss: 0.142078, acc: 97.66%] [G loss: 5.392634]\n",
      "epoch:44 step:34558 [D loss: 0.025194, acc: 100.00%] [G loss: 6.018206]\n",
      "epoch:44 step:34559 [D loss: 0.321677, acc: 85.16%] [G loss: 7.009776]\n",
      "epoch:44 step:34560 [D loss: 0.050591, acc: 100.00%] [G loss: 6.017674]\n",
      "epoch:44 step:34561 [D loss: 0.171948, acc: 94.53%] [G loss: 5.981052]\n",
      "epoch:44 step:34562 [D loss: 0.093608, acc: 98.44%] [G loss: 4.989991]\n",
      "epoch:44 step:34563 [D loss: 0.049497, acc: 100.00%] [G loss: 6.805640]\n",
      "epoch:44 step:34564 [D loss: 0.164274, acc: 98.44%] [G loss: 8.353916]\n",
      "epoch:44 step:34565 [D loss: 0.232527, acc: 92.97%] [G loss: 6.620686]\n",
      "epoch:44 step:34566 [D loss: 0.314617, acc: 88.28%] [G loss: 3.254554]\n",
      "epoch:44 step:34567 [D loss: 0.186087, acc: 99.22%] [G loss: 4.030483]\n",
      "epoch:44 step:34568 [D loss: 0.355252, acc: 81.25%] [G loss: 4.504194]\n",
      "epoch:44 step:34569 [D loss: 0.040210, acc: 100.00%] [G loss: 5.577960]\n",
      "epoch:44 step:34570 [D loss: 0.049891, acc: 100.00%] [G loss: 4.190770]\n",
      "epoch:44 step:34571 [D loss: 0.352755, acc: 83.59%] [G loss: 6.374911]\n",
      "epoch:44 step:34572 [D loss: 0.341456, acc: 84.38%] [G loss: 4.761616]\n",
      "epoch:44 step:34573 [D loss: 0.144875, acc: 96.88%] [G loss: 3.776390]\n",
      "epoch:44 step:34574 [D loss: 0.176712, acc: 97.66%] [G loss: 5.877824]\n",
      "epoch:44 step:34575 [D loss: 0.112401, acc: 100.00%] [G loss: 4.186560]\n",
      "epoch:44 step:34576 [D loss: 0.213605, acc: 98.44%] [G loss: 6.613429]\n",
      "epoch:44 step:34577 [D loss: 0.067917, acc: 100.00%] [G loss: 4.591867]\n",
      "epoch:44 step:34578 [D loss: 0.057227, acc: 100.00%] [G loss: 6.744870]\n",
      "epoch:44 step:34579 [D loss: 0.913873, acc: 39.06%] [G loss: 5.356680]\n",
      "epoch:44 step:34580 [D loss: 0.980039, acc: 51.56%] [G loss: 4.680826]\n",
      "epoch:44 step:34581 [D loss: 0.040627, acc: 100.00%] [G loss: 6.673119]\n",
      "epoch:44 step:34582 [D loss: 0.106995, acc: 100.00%] [G loss: 3.038470]\n",
      "epoch:44 step:34583 [D loss: 0.124620, acc: 100.00%] [G loss: 4.780958]\n",
      "epoch:44 step:34584 [D loss: 0.231490, acc: 94.53%] [G loss: 4.202300]\n",
      "epoch:44 step:34585 [D loss: 0.278744, acc: 88.28%] [G loss: 6.237973]\n",
      "epoch:44 step:34586 [D loss: 0.349617, acc: 88.28%] [G loss: 2.830863]\n",
      "epoch:44 step:34587 [D loss: 0.031845, acc: 100.00%] [G loss: 2.650948]\n",
      "epoch:44 step:34588 [D loss: 0.094709, acc: 99.22%] [G loss: 8.867640]\n",
      "epoch:44 step:34589 [D loss: 0.022710, acc: 100.00%] [G loss: 4.993526]\n",
      "epoch:44 step:34590 [D loss: 0.216845, acc: 95.31%] [G loss: 6.407761]\n",
      "epoch:44 step:34591 [D loss: 0.172032, acc: 97.66%] [G loss: 8.048300]\n",
      "epoch:44 step:34592 [D loss: 0.418527, acc: 71.88%] [G loss: 5.511975]\n",
      "epoch:44 step:34593 [D loss: 0.856850, acc: 49.22%] [G loss: 11.498349]\n",
      "epoch:44 step:34594 [D loss: 1.105848, acc: 46.88%] [G loss: 8.168831]\n",
      "epoch:44 step:34595 [D loss: 0.082239, acc: 99.22%] [G loss: 4.479382]\n",
      "epoch:44 step:34596 [D loss: 0.350898, acc: 84.38%] [G loss: 3.600565]\n",
      "epoch:44 step:34597 [D loss: 0.030546, acc: 100.00%] [G loss: 6.134355]\n",
      "epoch:44 step:34598 [D loss: 0.292203, acc: 92.97%] [G loss: 3.016953]\n",
      "epoch:44 step:34599 [D loss: 0.966070, acc: 50.00%] [G loss: 7.785759]\n",
      "epoch:44 step:34600 [D loss: 0.175761, acc: 98.44%] [G loss: 5.889564]\n",
      "epoch:44 step:34601 [D loss: 0.036288, acc: 100.00%] [G loss: 8.986516]\n",
      "epoch:44 step:34602 [D loss: 1.874357, acc: 50.00%] [G loss: 3.947238]\n",
      "epoch:44 step:34603 [D loss: 0.166235, acc: 98.44%] [G loss: 5.555227]\n",
      "epoch:44 step:34604 [D loss: 0.092764, acc: 100.00%] [G loss: 5.345709]\n",
      "epoch:44 step:34605 [D loss: 0.047735, acc: 100.00%] [G loss: 5.513394]\n",
      "epoch:44 step:34606 [D loss: 0.030335, acc: 99.22%] [G loss: 6.998961]\n",
      "epoch:44 step:34607 [D loss: 0.085101, acc: 100.00%] [G loss: 5.959965]\n",
      "epoch:44 step:34608 [D loss: 0.046547, acc: 100.00%] [G loss: 7.914219]\n",
      "epoch:44 step:34609 [D loss: 0.101572, acc: 100.00%] [G loss: 5.612148]\n",
      "epoch:44 step:34610 [D loss: 0.241515, acc: 97.66%] [G loss: 7.029077]\n",
      "epoch:44 step:34611 [D loss: 0.860007, acc: 51.56%] [G loss: 4.242667]\n",
      "epoch:44 step:34612 [D loss: 0.379040, acc: 89.06%] [G loss: 5.745175]\n",
      "epoch:44 step:34613 [D loss: 0.043556, acc: 100.00%] [G loss: 7.606099]\n",
      "epoch:44 step:34614 [D loss: 0.182682, acc: 97.66%] [G loss: 5.936452]\n",
      "epoch:44 step:34615 [D loss: 0.110178, acc: 99.22%] [G loss: 5.795667]\n",
      "epoch:44 step:34616 [D loss: 0.014584, acc: 100.00%] [G loss: 8.159930]\n",
      "epoch:44 step:34617 [D loss: 1.101997, acc: 29.69%] [G loss: 7.441907]\n",
      "epoch:44 step:34618 [D loss: 0.181350, acc: 97.66%] [G loss: 6.237422]\n",
      "epoch:44 step:34619 [D loss: 0.104467, acc: 100.00%] [G loss: 5.217385]\n",
      "epoch:44 step:34620 [D loss: 0.233118, acc: 97.66%] [G loss: 6.561597]\n",
      "epoch:44 step:34621 [D loss: 0.357266, acc: 93.75%] [G loss: 5.214606]\n",
      "epoch:44 step:34622 [D loss: 0.406029, acc: 83.59%] [G loss: 7.251649]\n",
      "epoch:44 step:34623 [D loss: 0.104055, acc: 98.44%] [G loss: 7.941723]\n",
      "epoch:44 step:34624 [D loss: 0.101401, acc: 99.22%] [G loss: 4.322042]\n",
      "epoch:44 step:34625 [D loss: 0.364539, acc: 88.28%] [G loss: 4.712272]\n",
      "epoch:44 step:34626 [D loss: 0.291406, acc: 96.09%] [G loss: 6.626482]\n",
      "epoch:44 step:34627 [D loss: 0.364064, acc: 89.84%] [G loss: 3.859596]\n",
      "epoch:44 step:34628 [D loss: 0.109018, acc: 99.22%] [G loss: 4.746596]\n",
      "epoch:44 step:34629 [D loss: 2.151223, acc: 50.00%] [G loss: 3.090733]\n",
      "epoch:44 step:34630 [D loss: 0.369519, acc: 75.00%] [G loss: 7.079439]\n",
      "epoch:44 step:34631 [D loss: 0.149525, acc: 98.44%] [G loss: 6.721023]\n",
      "epoch:44 step:34632 [D loss: 0.440677, acc: 78.12%] [G loss: 6.883359]\n",
      "epoch:44 step:34633 [D loss: 0.146316, acc: 98.44%] [G loss: 4.405232]\n",
      "epoch:44 step:34634 [D loss: 0.040869, acc: 100.00%] [G loss: 4.339260]\n",
      "epoch:44 step:34635 [D loss: 0.159324, acc: 98.44%] [G loss: 3.979090]\n",
      "epoch:44 step:34636 [D loss: 0.021138, acc: 100.00%] [G loss: 3.422285]\n",
      "epoch:44 step:34637 [D loss: 0.527024, acc: 68.75%] [G loss: 3.522883]\n",
      "epoch:44 step:34638 [D loss: 0.582667, acc: 60.94%] [G loss: 6.337625]\n",
      "epoch:44 step:34639 [D loss: 0.588136, acc: 57.03%] [G loss: 5.489954]\n",
      "epoch:44 step:34640 [D loss: 0.163743, acc: 98.44%] [G loss: 7.136425]\n",
      "epoch:44 step:34641 [D loss: 0.595153, acc: 59.38%] [G loss: 5.473279]\n",
      "epoch:44 step:34642 [D loss: 0.015977, acc: 100.00%] [G loss: 7.749050]\n",
      "epoch:44 step:34643 [D loss: 0.825700, acc: 42.97%] [G loss: 5.350065]\n",
      "epoch:44 step:34644 [D loss: 0.157337, acc: 96.88%] [G loss: 6.728558]\n",
      "epoch:44 step:34645 [D loss: 0.138769, acc: 100.00%] [G loss: 8.925013]\n",
      "epoch:44 step:34646 [D loss: 0.137075, acc: 100.00%] [G loss: 8.270372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34647 [D loss: 0.358379, acc: 84.38%] [G loss: 5.228585]\n",
      "epoch:44 step:34648 [D loss: 0.516263, acc: 67.97%] [G loss: 9.458128]\n",
      "epoch:44 step:34649 [D loss: 0.295183, acc: 86.72%] [G loss: 3.619868]\n",
      "epoch:44 step:34650 [D loss: 0.218992, acc: 96.09%] [G loss: 4.701159]\n",
      "epoch:44 step:34651 [D loss: 0.477045, acc: 68.75%] [G loss: 7.190267]\n",
      "epoch:44 step:34652 [D loss: 0.119521, acc: 99.22%] [G loss: 5.985803]\n",
      "epoch:44 step:34653 [D loss: 0.335833, acc: 89.06%] [G loss: 4.512394]\n",
      "epoch:44 step:34654 [D loss: 0.084508, acc: 100.00%] [G loss: 5.997393]\n",
      "epoch:44 step:34655 [D loss: 0.185686, acc: 98.44%] [G loss: 3.348658]\n",
      "epoch:44 step:34656 [D loss: 0.103611, acc: 99.22%] [G loss: 3.712532]\n",
      "epoch:44 step:34657 [D loss: 0.080678, acc: 100.00%] [G loss: 6.162562]\n",
      "epoch:44 step:34658 [D loss: 0.364931, acc: 82.81%] [G loss: 5.169334]\n",
      "epoch:44 step:34659 [D loss: 0.590849, acc: 65.62%] [G loss: 4.183153]\n",
      "epoch:44 step:34660 [D loss: 1.220106, acc: 50.78%] [G loss: 4.947438]\n",
      "epoch:44 step:34661 [D loss: 0.152745, acc: 97.66%] [G loss: 4.130804]\n",
      "epoch:44 step:34662 [D loss: 1.036637, acc: 35.94%] [G loss: 7.215300]\n",
      "epoch:44 step:34663 [D loss: 0.149356, acc: 98.44%] [G loss: 5.870965]\n",
      "epoch:44 step:34664 [D loss: 0.018018, acc: 100.00%] [G loss: 5.571600]\n",
      "epoch:44 step:34665 [D loss: 1.770225, acc: 3.91%] [G loss: 8.131304]\n",
      "epoch:44 step:34666 [D loss: 0.081871, acc: 99.22%] [G loss: 3.317241]\n",
      "epoch:44 step:34667 [D loss: 0.547172, acc: 67.19%] [G loss: 3.577882]\n",
      "epoch:44 step:34668 [D loss: 0.467703, acc: 76.56%] [G loss: 5.259593]\n",
      "epoch:44 step:34669 [D loss: 0.132014, acc: 100.00%] [G loss: 6.959836]\n",
      "epoch:44 step:34670 [D loss: 0.024604, acc: 100.00%] [G loss: 6.508733]\n",
      "epoch:44 step:34671 [D loss: 0.405658, acc: 85.94%] [G loss: 4.875451]\n",
      "epoch:44 step:34672 [D loss: 0.654171, acc: 59.38%] [G loss: 7.199905]\n",
      "epoch:44 step:34673 [D loss: 0.350603, acc: 85.94%] [G loss: 8.099077]\n",
      "epoch:44 step:34674 [D loss: 0.029758, acc: 100.00%] [G loss: 6.031386]\n",
      "epoch:44 step:34675 [D loss: 0.410592, acc: 86.72%] [G loss: 6.059716]\n",
      "epoch:44 step:34676 [D loss: 0.082832, acc: 100.00%] [G loss: 3.818020]\n",
      "epoch:44 step:34677 [D loss: 0.152737, acc: 97.66%] [G loss: 5.259473]\n",
      "epoch:44 step:34678 [D loss: 0.035787, acc: 100.00%] [G loss: 11.079753]\n",
      "epoch:44 step:34679 [D loss: 0.144304, acc: 100.00%] [G loss: 7.372128]\n",
      "epoch:44 step:34680 [D loss: 0.322155, acc: 94.53%] [G loss: 4.863648]\n",
      "epoch:44 step:34681 [D loss: 0.701469, acc: 54.69%] [G loss: 3.841267]\n",
      "epoch:44 step:34682 [D loss: 0.518429, acc: 65.62%] [G loss: 7.170127]\n",
      "epoch:44 step:34683 [D loss: 0.606457, acc: 66.41%] [G loss: 5.834369]\n",
      "epoch:44 step:34684 [D loss: 0.915922, acc: 33.59%] [G loss: 9.110134]\n",
      "epoch:44 step:34685 [D loss: 0.366742, acc: 89.06%] [G loss: 4.511799]\n",
      "epoch:44 step:34686 [D loss: 0.187183, acc: 96.09%] [G loss: 5.323156]\n",
      "epoch:44 step:34687 [D loss: 0.247205, acc: 95.31%] [G loss: 5.197893]\n",
      "epoch:44 step:34688 [D loss: 0.601888, acc: 60.94%] [G loss: 4.823090]\n",
      "epoch:44 step:34689 [D loss: 0.085418, acc: 100.00%] [G loss: 6.203981]\n",
      "epoch:44 step:34690 [D loss: 0.415076, acc: 74.22%] [G loss: 7.270341]\n",
      "epoch:44 step:34691 [D loss: 0.085083, acc: 99.22%] [G loss: 7.796872]\n",
      "epoch:44 step:34692 [D loss: 0.763061, acc: 53.91%] [G loss: 4.937201]\n",
      "epoch:44 step:34693 [D loss: 0.288703, acc: 92.19%] [G loss: 6.094046]\n",
      "epoch:44 step:34694 [D loss: 1.055013, acc: 52.34%] [G loss: 9.828249]\n",
      "epoch:44 step:34695 [D loss: 0.075524, acc: 100.00%] [G loss: 3.095493]\n",
      "epoch:44 step:34696 [D loss: 0.564021, acc: 63.28%] [G loss: 7.637305]\n",
      "epoch:44 step:34697 [D loss: 0.153384, acc: 97.66%] [G loss: 7.627373]\n",
      "epoch:44 step:34698 [D loss: 0.063576, acc: 100.00%] [G loss: 8.291540]\n",
      "epoch:44 step:34699 [D loss: 0.074235, acc: 100.00%] [G loss: 6.746052]\n",
      "epoch:44 step:34700 [D loss: 0.129035, acc: 98.44%] [G loss: 6.362025]\n",
      "epoch:44 step:34701 [D loss: 0.809484, acc: 51.56%] [G loss: 5.641078]\n",
      "epoch:44 step:34702 [D loss: 0.010772, acc: 100.00%] [G loss: 11.480204]\n",
      "epoch:44 step:34703 [D loss: 0.085799, acc: 100.00%] [G loss: 8.381150]\n",
      "epoch:44 step:34704 [D loss: 0.096101, acc: 99.22%] [G loss: 5.335945]\n",
      "epoch:44 step:34705 [D loss: 0.209215, acc: 98.44%] [G loss: 4.499346]\n",
      "epoch:44 step:34706 [D loss: 0.834065, acc: 55.47%] [G loss: 2.902039]\n",
      "epoch:44 step:34707 [D loss: 0.139656, acc: 100.00%] [G loss: 6.038752]\n",
      "epoch:44 step:34708 [D loss: 1.797466, acc: 26.56%] [G loss: 7.876286]\n",
      "epoch:44 step:34709 [D loss: 0.141242, acc: 99.22%] [G loss: 5.043028]\n",
      "epoch:44 step:34710 [D loss: 0.565312, acc: 60.16%] [G loss: 7.941767]\n",
      "epoch:44 step:34711 [D loss: 0.209583, acc: 98.44%] [G loss: 3.994344]\n",
      "epoch:44 step:34712 [D loss: 0.108356, acc: 99.22%] [G loss: 3.920243]\n",
      "epoch:44 step:34713 [D loss: 0.375512, acc: 88.28%] [G loss: 4.415254]\n",
      "epoch:44 step:34714 [D loss: 0.229131, acc: 96.88%] [G loss: 7.128320]\n",
      "epoch:44 step:34715 [D loss: 0.125018, acc: 98.44%] [G loss: 7.514326]\n",
      "epoch:44 step:34716 [D loss: 0.109013, acc: 100.00%] [G loss: 7.077366]\n",
      "epoch:44 step:34717 [D loss: 0.039797, acc: 100.00%] [G loss: 6.339161]\n",
      "epoch:44 step:34718 [D loss: 0.799047, acc: 53.12%] [G loss: 5.101640]\n",
      "epoch:44 step:34719 [D loss: 0.662286, acc: 57.03%] [G loss: 5.624968]\n",
      "epoch:44 step:34720 [D loss: 1.144768, acc: 50.00%] [G loss: 4.942658]\n",
      "epoch:44 step:34721 [D loss: 1.930740, acc: 1.56%] [G loss: 6.999402]\n",
      "epoch:44 step:34722 [D loss: 0.168467, acc: 100.00%] [G loss: 6.070365]\n",
      "epoch:44 step:34723 [D loss: 0.241628, acc: 90.62%] [G loss: 7.765068]\n",
      "epoch:44 step:34724 [D loss: 1.562849, acc: 36.72%] [G loss: 7.456670]\n",
      "epoch:44 step:34725 [D loss: 0.129108, acc: 98.44%] [G loss: 8.395653]\n",
      "epoch:44 step:34726 [D loss: 0.417227, acc: 76.56%] [G loss: 4.918051]\n",
      "epoch:44 step:34727 [D loss: 0.357703, acc: 92.19%] [G loss: 3.853313]\n",
      "epoch:44 step:34728 [D loss: 0.071206, acc: 100.00%] [G loss: 6.261562]\n",
      "epoch:44 step:34729 [D loss: 0.115807, acc: 99.22%] [G loss: 3.925671]\n",
      "epoch:44 step:34730 [D loss: 0.090832, acc: 100.00%] [G loss: 6.599136]\n",
      "epoch:44 step:34731 [D loss: 0.334408, acc: 85.16%] [G loss: 4.278668]\n",
      "epoch:44 step:34732 [D loss: 0.112101, acc: 99.22%] [G loss: 6.740392]\n",
      "epoch:44 step:34733 [D loss: 0.420050, acc: 84.38%] [G loss: 6.119309]\n",
      "epoch:44 step:34734 [D loss: 0.082734, acc: 100.00%] [G loss: 3.641620]\n",
      "epoch:44 step:34735 [D loss: 0.043708, acc: 100.00%] [G loss: 7.448082]\n",
      "epoch:44 step:34736 [D loss: 0.408748, acc: 73.44%] [G loss: 1.149486]\n",
      "epoch:44 step:34737 [D loss: 0.051108, acc: 100.00%] [G loss: 3.699427]\n",
      "epoch:44 step:34738 [D loss: 0.236596, acc: 95.31%] [G loss: 4.434072]\n",
      "epoch:44 step:34739 [D loss: 0.112950, acc: 99.22%] [G loss: 3.420834]\n",
      "epoch:44 step:34740 [D loss: 0.354378, acc: 85.94%] [G loss: 3.984737]\n",
      "epoch:44 step:34741 [D loss: 0.071456, acc: 100.00%] [G loss: 5.604423]\n",
      "epoch:44 step:34742 [D loss: 0.212885, acc: 95.31%] [G loss: 5.483201]\n",
      "epoch:44 step:34743 [D loss: 0.037637, acc: 100.00%] [G loss: 8.564089]\n",
      "epoch:44 step:34744 [D loss: 0.161483, acc: 96.88%] [G loss: 8.109194]\n",
      "epoch:44 step:34745 [D loss: 0.209412, acc: 96.88%] [G loss: 5.956246]\n",
      "epoch:44 step:34746 [D loss: 0.197639, acc: 97.66%] [G loss: 4.322051]\n",
      "epoch:44 step:34747 [D loss: 0.087117, acc: 100.00%] [G loss: 4.904290]\n",
      "epoch:44 step:34748 [D loss: 0.243188, acc: 94.53%] [G loss: 2.030260]\n",
      "epoch:44 step:34749 [D loss: 0.265246, acc: 97.66%] [G loss: 6.035719]\n",
      "epoch:44 step:34750 [D loss: 0.127365, acc: 98.44%] [G loss: 3.280890]\n",
      "epoch:44 step:34751 [D loss: 0.050540, acc: 100.00%] [G loss: 1.733303]\n",
      "epoch:44 step:34752 [D loss: 0.674184, acc: 60.94%] [G loss: 8.838205]\n",
      "epoch:44 step:34753 [D loss: 0.688785, acc: 55.47%] [G loss: 6.680477]\n",
      "epoch:44 step:34754 [D loss: 0.587151, acc: 60.94%] [G loss: 5.054487]\n",
      "epoch:44 step:34755 [D loss: 0.294431, acc: 85.16%] [G loss: 8.033325]\n",
      "epoch:44 step:34756 [D loss: 0.115217, acc: 99.22%] [G loss: 8.150857]\n",
      "epoch:44 step:34757 [D loss: 0.349026, acc: 78.12%] [G loss: 6.709880]\n",
      "epoch:44 step:34758 [D loss: 0.075307, acc: 100.00%] [G loss: 4.777346]\n",
      "epoch:44 step:34759 [D loss: 0.165815, acc: 96.88%] [G loss: 8.555550]\n",
      "epoch:44 step:34760 [D loss: 0.092672, acc: 100.00%] [G loss: 7.710172]\n",
      "epoch:44 step:34761 [D loss: 0.619875, acc: 65.62%] [G loss: 5.100928]\n",
      "epoch:44 step:34762 [D loss: 1.058026, acc: 32.81%] [G loss: 7.271811]\n",
      "epoch:44 step:34763 [D loss: 0.118364, acc: 98.44%] [G loss: 5.114848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34764 [D loss: 0.336534, acc: 91.41%] [G loss: 5.706492]\n",
      "epoch:44 step:34765 [D loss: 0.048386, acc: 99.22%] [G loss: 7.713996]\n",
      "epoch:44 step:34766 [D loss: 0.068702, acc: 100.00%] [G loss: 7.905300]\n",
      "epoch:44 step:34767 [D loss: 0.291657, acc: 91.41%] [G loss: 5.138323]\n",
      "epoch:44 step:34768 [D loss: 0.156884, acc: 99.22%] [G loss: 5.465017]\n",
      "epoch:44 step:34769 [D loss: 0.588730, acc: 71.88%] [G loss: 4.336303]\n",
      "epoch:44 step:34770 [D loss: 0.384298, acc: 90.62%] [G loss: 3.741814]\n",
      "epoch:44 step:34771 [D loss: 0.078612, acc: 100.00%] [G loss: 6.197885]\n",
      "epoch:44 step:34772 [D loss: 0.517949, acc: 65.62%] [G loss: 8.428944]\n",
      "epoch:44 step:34773 [D loss: 1.217971, acc: 50.00%] [G loss: 5.596762]\n",
      "epoch:44 step:34774 [D loss: 0.242612, acc: 93.75%] [G loss: 5.030519]\n",
      "epoch:44 step:34775 [D loss: 0.146593, acc: 97.66%] [G loss: 4.289577]\n",
      "epoch:44 step:34776 [D loss: 0.083374, acc: 100.00%] [G loss: 6.689980]\n",
      "epoch:44 step:34777 [D loss: 0.099495, acc: 100.00%] [G loss: 4.757806]\n",
      "epoch:44 step:34778 [D loss: 0.133532, acc: 100.00%] [G loss: 3.980812]\n",
      "epoch:44 step:34779 [D loss: 0.096860, acc: 100.00%] [G loss: 5.764927]\n",
      "epoch:44 step:34780 [D loss: 0.265230, acc: 97.66%] [G loss: 4.798018]\n",
      "epoch:44 step:34781 [D loss: 0.111966, acc: 99.22%] [G loss: 6.547935]\n",
      "epoch:44 step:34782 [D loss: 0.029505, acc: 100.00%] [G loss: 5.200073]\n",
      "epoch:44 step:34783 [D loss: 0.406980, acc: 82.03%] [G loss: 5.748395]\n",
      "epoch:44 step:34784 [D loss: 0.215351, acc: 94.53%] [G loss: 3.247624]\n",
      "epoch:44 step:34785 [D loss: 0.747947, acc: 55.47%] [G loss: 6.269377]\n",
      "epoch:44 step:34786 [D loss: 0.103567, acc: 100.00%] [G loss: 5.960294]\n",
      "epoch:44 step:34787 [D loss: 1.188606, acc: 34.38%] [G loss: 7.775918]\n",
      "epoch:44 step:34788 [D loss: 0.045081, acc: 100.00%] [G loss: 3.409980]\n",
      "epoch:44 step:34789 [D loss: 0.310176, acc: 85.94%] [G loss: 5.447306]\n",
      "epoch:44 step:34790 [D loss: 0.471567, acc: 81.25%] [G loss: 4.711719]\n",
      "epoch:44 step:34791 [D loss: 0.978771, acc: 50.78%] [G loss: 7.859178]\n",
      "epoch:44 step:34792 [D loss: 0.311031, acc: 85.94%] [G loss: 6.947248]\n",
      "epoch:44 step:34793 [D loss: 0.063994, acc: 100.00%] [G loss: 7.019059]\n",
      "epoch:44 step:34794 [D loss: 0.251052, acc: 94.53%] [G loss: 5.477282]\n",
      "epoch:44 step:34795 [D loss: 0.046128, acc: 100.00%] [G loss: 6.600638]\n",
      "epoch:44 step:34796 [D loss: 0.057704, acc: 100.00%] [G loss: 8.013762]\n",
      "epoch:44 step:34797 [D loss: 0.422972, acc: 86.72%] [G loss: 5.282352]\n",
      "epoch:44 step:34798 [D loss: 0.096123, acc: 100.00%] [G loss: 8.010152]\n",
      "epoch:44 step:34799 [D loss: 0.416708, acc: 75.00%] [G loss: 1.872897]\n",
      "epoch:44 step:34800 [D loss: 0.177686, acc: 97.66%] [G loss: 6.851860]\n",
      "epoch:44 step:34801 [D loss: 0.701690, acc: 56.25%] [G loss: 4.932173]\n",
      "epoch:44 step:34802 [D loss: 0.650809, acc: 64.06%] [G loss: 2.817492]\n",
      "epoch:44 step:34803 [D loss: 0.112493, acc: 100.00%] [G loss: 4.184469]\n",
      "epoch:44 step:34804 [D loss: 0.036175, acc: 100.00%] [G loss: 5.479790]\n",
      "epoch:44 step:34805 [D loss: 0.096492, acc: 100.00%] [G loss: 4.111840]\n",
      "epoch:44 step:34806 [D loss: 1.130484, acc: 50.00%] [G loss: 8.229106]\n",
      "epoch:44 step:34807 [D loss: 0.364702, acc: 79.69%] [G loss: 7.376338]\n",
      "epoch:44 step:34808 [D loss: 0.532886, acc: 60.16%] [G loss: 7.686680]\n",
      "epoch:44 step:34809 [D loss: 0.735914, acc: 53.12%] [G loss: 3.741402]\n",
      "epoch:44 step:34810 [D loss: 0.669145, acc: 53.91%] [G loss: 5.415260]\n",
      "epoch:44 step:34811 [D loss: 0.421318, acc: 70.31%] [G loss: 10.729169]\n",
      "epoch:44 step:34812 [D loss: 0.886379, acc: 50.00%] [G loss: 7.392902]\n",
      "epoch:44 step:34813 [D loss: 0.643158, acc: 62.50%] [G loss: 8.466549]\n",
      "epoch:44 step:34814 [D loss: 0.295393, acc: 82.81%] [G loss: 4.456425]\n",
      "epoch:44 step:34815 [D loss: 0.481795, acc: 65.62%] [G loss: 5.145578]\n",
      "epoch:44 step:34816 [D loss: 0.132054, acc: 100.00%] [G loss: 4.667202]\n",
      "epoch:44 step:34817 [D loss: 0.400608, acc: 73.44%] [G loss: 6.928960]\n",
      "epoch:44 step:34818 [D loss: 0.049440, acc: 100.00%] [G loss: 7.578348]\n",
      "epoch:44 step:34819 [D loss: 0.466556, acc: 66.41%] [G loss: 5.831105]\n",
      "epoch:44 step:34820 [D loss: 0.062905, acc: 100.00%] [G loss: 4.796054]\n",
      "epoch:44 step:34821 [D loss: 0.676300, acc: 53.12%] [G loss: 4.512995]\n",
      "epoch:44 step:34822 [D loss: 0.053034, acc: 100.00%] [G loss: 4.691622]\n",
      "epoch:44 step:34823 [D loss: 0.710281, acc: 57.03%] [G loss: 6.903234]\n",
      "epoch:44 step:34824 [D loss: 0.027234, acc: 100.00%] [G loss: 5.909399]\n",
      "epoch:44 step:34825 [D loss: 0.516005, acc: 62.50%] [G loss: 3.953460]\n",
      "epoch:44 step:34826 [D loss: 0.152707, acc: 99.22%] [G loss: 3.208130]\n",
      "epoch:44 step:34827 [D loss: 0.612765, acc: 64.06%] [G loss: 10.491904]\n",
      "epoch:44 step:34828 [D loss: 0.157542, acc: 97.66%] [G loss: 3.572868]\n",
      "epoch:44 step:34829 [D loss: 0.364872, acc: 80.47%] [G loss: 5.796009]\n",
      "epoch:44 step:34830 [D loss: 0.576467, acc: 60.16%] [G loss: 7.751590]\n",
      "epoch:44 step:34831 [D loss: 0.121369, acc: 100.00%] [G loss: 3.924883]\n",
      "epoch:44 step:34832 [D loss: 0.495484, acc: 71.09%] [G loss: 5.173407]\n",
      "epoch:44 step:34833 [D loss: 0.870325, acc: 55.47%] [G loss: 4.743338]\n",
      "epoch:44 step:34834 [D loss: 0.038243, acc: 100.00%] [G loss: 7.309686]\n",
      "epoch:44 step:34835 [D loss: 0.050045, acc: 100.00%] [G loss: 6.122565]\n",
      "epoch:44 step:34836 [D loss: 0.217242, acc: 93.75%] [G loss: 8.169149]\n",
      "epoch:44 step:34837 [D loss: 0.099378, acc: 100.00%] [G loss: 4.518784]\n",
      "epoch:44 step:34838 [D loss: 0.079931, acc: 99.22%] [G loss: 3.097723]\n",
      "epoch:44 step:34839 [D loss: 0.130612, acc: 98.44%] [G loss: 3.207816]\n",
      "epoch:44 step:34840 [D loss: 0.580086, acc: 61.72%] [G loss: 6.695228]\n",
      "epoch:44 step:34841 [D loss: 0.218682, acc: 92.97%] [G loss: 5.727606]\n",
      "epoch:44 step:34842 [D loss: 0.047107, acc: 100.00%] [G loss: 5.372494]\n",
      "epoch:44 step:34843 [D loss: 0.723400, acc: 57.03%] [G loss: 5.233263]\n",
      "epoch:44 step:34844 [D loss: 0.113656, acc: 100.00%] [G loss: 4.953146]\n",
      "epoch:44 step:34845 [D loss: 0.629774, acc: 61.72%] [G loss: 7.618584]\n",
      "epoch:44 step:34846 [D loss: 0.273289, acc: 90.62%] [G loss: 4.134598]\n",
      "epoch:44 step:34847 [D loss: 0.059479, acc: 100.00%] [G loss: 4.553154]\n",
      "epoch:44 step:34848 [D loss: 0.340731, acc: 82.03%] [G loss: 3.862584]\n",
      "epoch:44 step:34849 [D loss: 1.062509, acc: 46.09%] [G loss: 5.743089]\n",
      "epoch:44 step:34850 [D loss: 0.751627, acc: 50.78%] [G loss: 4.258791]\n",
      "epoch:44 step:34851 [D loss: 0.102941, acc: 100.00%] [G loss: 5.230407]\n",
      "epoch:44 step:34852 [D loss: 0.324982, acc: 91.41%] [G loss: 6.800081]\n",
      "epoch:44 step:34853 [D loss: 0.349877, acc: 92.97%] [G loss: 4.207750]\n",
      "epoch:44 step:34854 [D loss: 0.711259, acc: 53.91%] [G loss: 8.664673]\n",
      "epoch:44 step:34855 [D loss: 0.241035, acc: 93.75%] [G loss: 5.061752]\n",
      "epoch:44 step:34856 [D loss: 0.296641, acc: 92.19%] [G loss: 7.003601]\n",
      "epoch:44 step:34857 [D loss: 0.309925, acc: 95.31%] [G loss: 4.150318]\n",
      "epoch:44 step:34858 [D loss: 0.123367, acc: 100.00%] [G loss: 5.405086]\n",
      "epoch:44 step:34859 [D loss: 0.205463, acc: 92.97%] [G loss: 5.588089]\n",
      "epoch:44 step:34860 [D loss: 0.099582, acc: 100.00%] [G loss: 4.135697]\n",
      "epoch:44 step:34861 [D loss: 0.329767, acc: 82.03%] [G loss: 4.222107]\n",
      "epoch:44 step:34862 [D loss: 0.059129, acc: 100.00%] [G loss: 6.403960]\n",
      "epoch:44 step:34863 [D loss: 0.251341, acc: 96.09%] [G loss: 4.804504]\n",
      "epoch:44 step:34864 [D loss: 0.161765, acc: 98.44%] [G loss: 5.257659]\n",
      "epoch:44 step:34865 [D loss: 0.130692, acc: 100.00%] [G loss: 4.076657]\n",
      "epoch:44 step:34866 [D loss: 0.483914, acc: 71.88%] [G loss: 7.621896]\n",
      "epoch:44 step:34867 [D loss: 0.206395, acc: 96.09%] [G loss: 4.345460]\n",
      "epoch:44 step:34868 [D loss: 0.260511, acc: 92.97%] [G loss: 4.990272]\n",
      "epoch:44 step:34869 [D loss: 0.198309, acc: 97.66%] [G loss: 4.025564]\n",
      "epoch:44 step:34870 [D loss: 0.017628, acc: 100.00%] [G loss: 6.630616]\n",
      "epoch:44 step:34871 [D loss: 1.075482, acc: 19.53%] [G loss: 2.842656]\n",
      "epoch:44 step:34872 [D loss: 0.124056, acc: 99.22%] [G loss: 5.351673]\n",
      "epoch:44 step:34873 [D loss: 0.747714, acc: 57.03%] [G loss: 6.878386]\n",
      "epoch:44 step:34874 [D loss: 0.613360, acc: 66.41%] [G loss: 2.886371]\n",
      "epoch:44 step:34875 [D loss: 0.531356, acc: 61.72%] [G loss: 6.697364]\n",
      "epoch:44 step:34876 [D loss: 0.271103, acc: 89.06%] [G loss: 3.669705]\n",
      "epoch:44 step:34877 [D loss: 0.035923, acc: 99.22%] [G loss: 5.105116]\n",
      "epoch:44 step:34878 [D loss: 0.062807, acc: 100.00%] [G loss: 8.013517]\n",
      "epoch:44 step:34879 [D loss: 0.180564, acc: 97.66%] [G loss: 3.926784]\n",
      "epoch:44 step:34880 [D loss: 0.086628, acc: 99.22%] [G loss: 6.152596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34881 [D loss: 0.081180, acc: 100.00%] [G loss: 7.047010]\n",
      "epoch:44 step:34882 [D loss: 0.184683, acc: 98.44%] [G loss: 8.248478]\n",
      "epoch:44 step:34883 [D loss: 0.029306, acc: 100.00%] [G loss: 5.878857]\n",
      "epoch:44 step:34884 [D loss: 1.786164, acc: 35.94%] [G loss: 9.121992]\n",
      "epoch:44 step:34885 [D loss: 0.062931, acc: 100.00%] [G loss: 5.889556]\n",
      "epoch:44 step:34886 [D loss: 0.196646, acc: 100.00%] [G loss: 6.779657]\n",
      "epoch:44 step:34887 [D loss: 0.151702, acc: 96.09%] [G loss: 6.863330]\n",
      "epoch:44 step:34888 [D loss: 0.051241, acc: 100.00%] [G loss: 5.045194]\n",
      "epoch:44 step:34889 [D loss: 0.417590, acc: 79.69%] [G loss: 2.708833]\n",
      "epoch:44 step:34890 [D loss: 0.115429, acc: 99.22%] [G loss: 6.282885]\n",
      "epoch:44 step:34891 [D loss: 0.462670, acc: 67.19%] [G loss: 5.293109]\n",
      "epoch:44 step:34892 [D loss: 0.078629, acc: 99.22%] [G loss: 4.109006]\n",
      "epoch:44 step:34893 [D loss: 0.218033, acc: 97.66%] [G loss: 6.548462]\n",
      "epoch:44 step:34894 [D loss: 0.210416, acc: 96.09%] [G loss: 6.674182]\n",
      "epoch:44 step:34895 [D loss: 0.072532, acc: 100.00%] [G loss: 7.626425]\n",
      "epoch:44 step:34896 [D loss: 0.066498, acc: 100.00%] [G loss: 3.897871]\n",
      "epoch:44 step:34897 [D loss: 0.089908, acc: 100.00%] [G loss: 6.342978]\n",
      "epoch:44 step:34898 [D loss: 0.206706, acc: 91.41%] [G loss: 6.268736]\n",
      "epoch:44 step:34899 [D loss: 0.600995, acc: 66.41%] [G loss: 8.964491]\n",
      "epoch:44 step:34900 [D loss: 0.130286, acc: 99.22%] [G loss: 4.912686]\n",
      "epoch:44 step:34901 [D loss: 0.997184, acc: 50.00%] [G loss: 9.591087]\n",
      "epoch:44 step:34902 [D loss: 0.974118, acc: 50.00%] [G loss: 6.684927]\n",
      "epoch:44 step:34903 [D loss: 0.352580, acc: 90.62%] [G loss: 2.972053]\n",
      "epoch:44 step:34904 [D loss: 0.340171, acc: 82.81%] [G loss: 4.506310]\n",
      "epoch:44 step:34905 [D loss: 0.341897, acc: 80.47%] [G loss: 8.289610]\n",
      "epoch:44 step:34906 [D loss: 0.167021, acc: 97.66%] [G loss: 7.907684]\n",
      "epoch:44 step:34907 [D loss: 0.478091, acc: 65.62%] [G loss: 6.407632]\n",
      "epoch:44 step:34908 [D loss: 0.139968, acc: 99.22%] [G loss: 4.877157]\n",
      "epoch:44 step:34909 [D loss: 0.412928, acc: 75.78%] [G loss: 4.026954]\n",
      "epoch:44 step:34910 [D loss: 0.090871, acc: 98.44%] [G loss: 5.263121]\n",
      "epoch:44 step:34911 [D loss: 0.627773, acc: 65.62%] [G loss: 9.254131]\n",
      "epoch:44 step:34912 [D loss: 0.247135, acc: 96.88%] [G loss: 4.065119]\n",
      "epoch:44 step:34913 [D loss: 0.031725, acc: 100.00%] [G loss: 7.014167]\n",
      "epoch:44 step:34914 [D loss: 0.139792, acc: 98.44%] [G loss: 9.441683]\n",
      "epoch:44 step:34915 [D loss: 0.191521, acc: 98.44%] [G loss: 3.508651]\n",
      "epoch:44 step:34916 [D loss: 0.732434, acc: 52.34%] [G loss: 4.989727]\n",
      "epoch:44 step:34917 [D loss: 0.590027, acc: 57.03%] [G loss: 6.858958]\n",
      "epoch:44 step:34918 [D loss: 1.448175, acc: 50.00%] [G loss: 5.164601]\n",
      "epoch:44 step:34919 [D loss: 0.196897, acc: 94.53%] [G loss: 8.248220]\n",
      "epoch:44 step:34920 [D loss: 0.063195, acc: 100.00%] [G loss: 7.458339]\n",
      "epoch:44 step:34921 [D loss: 1.116140, acc: 51.56%] [G loss: 9.753259]\n",
      "epoch:44 step:34922 [D loss: 0.164261, acc: 100.00%] [G loss: 5.471044]\n",
      "epoch:44 step:34923 [D loss: 0.015845, acc: 100.00%] [G loss: 7.860794]\n",
      "epoch:44 step:34924 [D loss: 0.219172, acc: 97.66%] [G loss: 3.008860]\n",
      "epoch:44 step:34925 [D loss: 0.280657, acc: 92.19%] [G loss: 5.064077]\n",
      "epoch:44 step:34926 [D loss: 0.098446, acc: 100.00%] [G loss: 5.939827]\n",
      "epoch:44 step:34927 [D loss: 0.259374, acc: 97.66%] [G loss: 6.847869]\n",
      "epoch:44 step:34928 [D loss: 0.169982, acc: 96.88%] [G loss: 4.273738]\n",
      "epoch:44 step:34929 [D loss: 0.673882, acc: 53.12%] [G loss: 5.662224]\n",
      "epoch:44 step:34930 [D loss: 1.075820, acc: 31.25%] [G loss: 6.833406]\n",
      "epoch:44 step:34931 [D loss: 0.302657, acc: 85.94%] [G loss: 3.791372]\n",
      "epoch:44 step:34932 [D loss: 0.728901, acc: 58.59%] [G loss: 5.181625]\n",
      "epoch:44 step:34933 [D loss: 0.061859, acc: 99.22%] [G loss: 7.414368]\n",
      "epoch:44 step:34934 [D loss: 0.485027, acc: 78.12%] [G loss: 5.703167]\n",
      "epoch:44 step:34935 [D loss: 0.300496, acc: 90.62%] [G loss: 4.784848]\n",
      "epoch:44 step:34936 [D loss: 0.041928, acc: 100.00%] [G loss: 5.938091]\n",
      "epoch:44 step:34937 [D loss: 0.085593, acc: 99.22%] [G loss: 5.160587]\n",
      "epoch:44 step:34938 [D loss: 0.759061, acc: 55.47%] [G loss: 8.618330]\n",
      "epoch:44 step:34939 [D loss: 0.180108, acc: 98.44%] [G loss: 7.231108]\n",
      "epoch:44 step:34940 [D loss: 0.745922, acc: 52.34%] [G loss: 8.330109]\n",
      "epoch:44 step:34941 [D loss: 0.120208, acc: 98.44%] [G loss: 8.421560]\n",
      "epoch:44 step:34942 [D loss: 0.004899, acc: 100.00%] [G loss: 8.445194]\n",
      "epoch:44 step:34943 [D loss: 0.097377, acc: 99.22%] [G loss: 3.448078]\n",
      "epoch:44 step:34944 [D loss: 0.353113, acc: 88.28%] [G loss: 7.073696]\n",
      "epoch:44 step:34945 [D loss: 0.023720, acc: 100.00%] [G loss: 7.157791]\n",
      "epoch:44 step:34946 [D loss: 0.113571, acc: 100.00%] [G loss: 7.102901]\n",
      "epoch:44 step:34947 [D loss: 1.114154, acc: 50.00%] [G loss: 8.692843]\n",
      "epoch:44 step:34948 [D loss: 0.293734, acc: 85.94%] [G loss: 5.709140]\n",
      "epoch:44 step:34949 [D loss: 0.049595, acc: 99.22%] [G loss: 4.608430]\n",
      "epoch:44 step:34950 [D loss: 1.040328, acc: 50.00%] [G loss: 3.018493]\n",
      "epoch:44 step:34951 [D loss: 0.122641, acc: 100.00%] [G loss: 4.463686]\n",
      "epoch:44 step:34952 [D loss: 0.765985, acc: 53.91%] [G loss: 9.407401]\n",
      "epoch:44 step:34953 [D loss: 0.078207, acc: 100.00%] [G loss: 7.316278]\n",
      "epoch:44 step:34954 [D loss: 0.666902, acc: 61.72%] [G loss: 5.662887]\n",
      "epoch:44 step:34955 [D loss: 0.307267, acc: 87.50%] [G loss: 4.954553]\n",
      "epoch:44 step:34956 [D loss: 0.048141, acc: 100.00%] [G loss: 5.427435]\n",
      "epoch:44 step:34957 [D loss: 1.245922, acc: 7.81%] [G loss: 5.839543]\n",
      "epoch:44 step:34958 [D loss: 0.936461, acc: 35.94%] [G loss: 3.420384]\n",
      "epoch:44 step:34959 [D loss: 0.359030, acc: 78.91%] [G loss: 8.699188]\n",
      "epoch:44 step:34960 [D loss: 0.174848, acc: 93.75%] [G loss: 5.301469]\n",
      "epoch:44 step:34961 [D loss: 0.118203, acc: 100.00%] [G loss: 3.382130]\n",
      "epoch:44 step:34962 [D loss: 0.470999, acc: 77.34%] [G loss: 4.890449]\n",
      "epoch:44 step:34963 [D loss: 0.171437, acc: 98.44%] [G loss: 4.271543]\n",
      "epoch:44 step:34964 [D loss: 0.560012, acc: 59.38%] [G loss: 4.945217]\n",
      "epoch:44 step:34965 [D loss: 0.291034, acc: 93.75%] [G loss: 4.217472]\n",
      "epoch:44 step:34966 [D loss: 1.461107, acc: 48.44%] [G loss: 7.549294]\n",
      "epoch:44 step:34967 [D loss: 0.442571, acc: 78.12%] [G loss: 5.646988]\n",
      "epoch:44 step:34968 [D loss: 0.071948, acc: 100.00%] [G loss: 5.005788]\n",
      "epoch:44 step:34969 [D loss: 0.123833, acc: 98.44%] [G loss: 3.465130]\n",
      "epoch:44 step:34970 [D loss: 0.515218, acc: 74.22%] [G loss: 3.116457]\n",
      "epoch:44 step:34971 [D loss: 0.024705, acc: 100.00%] [G loss: 4.482575]\n",
      "epoch:44 step:34972 [D loss: 0.191072, acc: 97.66%] [G loss: 6.017959]\n",
      "epoch:44 step:34973 [D loss: 0.066345, acc: 100.00%] [G loss: 9.175556]\n",
      "epoch:44 step:34974 [D loss: 0.296992, acc: 92.97%] [G loss: 8.212522]\n",
      "epoch:44 step:34975 [D loss: 0.267413, acc: 85.94%] [G loss: 4.568913]\n",
      "epoch:44 step:34976 [D loss: 0.042976, acc: 99.22%] [G loss: 6.816995]\n",
      "epoch:44 step:34977 [D loss: 0.541818, acc: 71.09%] [G loss: 6.380783]\n",
      "epoch:44 step:34978 [D loss: 0.135144, acc: 96.88%] [G loss: 4.572753]\n",
      "epoch:44 step:34979 [D loss: 0.019589, acc: 100.00%] [G loss: 6.763478]\n",
      "epoch:44 step:34980 [D loss: 0.233013, acc: 95.31%] [G loss: 7.098837]\n",
      "epoch:44 step:34981 [D loss: 0.056796, acc: 99.22%] [G loss: 5.225281]\n",
      "epoch:44 step:34982 [D loss: 0.275662, acc: 94.53%] [G loss: 6.688811]\n",
      "epoch:44 step:34983 [D loss: 0.568569, acc: 69.53%] [G loss: 3.598289]\n",
      "epoch:44 step:34984 [D loss: 0.672932, acc: 58.59%] [G loss: 5.857341]\n",
      "epoch:44 step:34985 [D loss: 0.806496, acc: 53.12%] [G loss: 6.748393]\n",
      "epoch:44 step:34986 [D loss: 0.204630, acc: 92.19%] [G loss: 5.687931]\n",
      "epoch:44 step:34987 [D loss: 0.582142, acc: 67.97%] [G loss: 4.916102]\n",
      "epoch:44 step:34988 [D loss: 0.057893, acc: 98.44%] [G loss: 5.441615]\n",
      "epoch:44 step:34989 [D loss: 0.437430, acc: 74.22%] [G loss: 7.658815]\n",
      "epoch:44 step:34990 [D loss: 0.385145, acc: 84.38%] [G loss: 4.247590]\n",
      "epoch:44 step:34991 [D loss: 0.233025, acc: 90.62%] [G loss: 8.246384]\n",
      "epoch:44 step:34992 [D loss: 0.948183, acc: 51.56%] [G loss: 8.258974]\n",
      "epoch:44 step:34993 [D loss: 0.317574, acc: 80.47%] [G loss: 6.714057]\n",
      "epoch:44 step:34994 [D loss: 1.155454, acc: 50.00%] [G loss: 5.656848]\n",
      "epoch:44 step:34995 [D loss: 0.371166, acc: 73.44%] [G loss: 7.570436]\n",
      "epoch:44 step:34996 [D loss: 0.724777, acc: 55.47%] [G loss: 4.972081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34997 [D loss: 0.081170, acc: 100.00%] [G loss: 5.982801]\n",
      "epoch:44 step:34998 [D loss: 1.255857, acc: 32.03%] [G loss: 4.290960]\n",
      "epoch:44 step:34999 [D loss: 0.616659, acc: 61.72%] [G loss: 4.019278]\n",
      "epoch:44 step:35000 [D loss: 0.329886, acc: 85.94%] [G loss: 6.241428]\n",
      "epoch:44 step:35001 [D loss: 0.081348, acc: 100.00%] [G loss: 3.256196]\n",
      "epoch:44 step:35002 [D loss: 0.170946, acc: 99.22%] [G loss: 6.367700]\n",
      "epoch:44 step:35003 [D loss: 0.656813, acc: 60.94%] [G loss: 4.754787]\n",
      "epoch:44 step:35004 [D loss: 0.379839, acc: 84.38%] [G loss: 6.347462]\n",
      "epoch:44 step:35005 [D loss: 0.486489, acc: 69.53%] [G loss: 6.361644]\n",
      "epoch:44 step:35006 [D loss: 0.342365, acc: 92.97%] [G loss: 9.566905]\n",
      "epoch:44 step:35007 [D loss: 0.370184, acc: 92.19%] [G loss: 4.244744]\n",
      "epoch:44 step:35008 [D loss: 0.331139, acc: 97.66%] [G loss: 3.793319]\n",
      "epoch:44 step:35009 [D loss: 0.052313, acc: 100.00%] [G loss: 4.359762]\n",
      "epoch:44 step:35010 [D loss: 0.270739, acc: 88.28%] [G loss: 3.858053]\n",
      "epoch:44 step:35011 [D loss: 0.274209, acc: 93.75%] [G loss: 2.623107]\n",
      "epoch:44 step:35012 [D loss: 0.230088, acc: 93.75%] [G loss: 5.766732]\n",
      "epoch:44 step:35013 [D loss: 0.402242, acc: 82.81%] [G loss: 5.354029]\n",
      "epoch:44 step:35014 [D loss: 0.269170, acc: 91.41%] [G loss: 7.648548]\n",
      "epoch:44 step:35015 [D loss: 0.079427, acc: 99.22%] [G loss: 10.769528]\n",
      "epoch:44 step:35016 [D loss: 0.624128, acc: 60.94%] [G loss: 5.773013]\n",
      "epoch:44 step:35017 [D loss: 0.263966, acc: 91.41%] [G loss: 6.198468]\n",
      "epoch:44 step:35018 [D loss: 0.032423, acc: 100.00%] [G loss: 8.496181]\n",
      "epoch:44 step:35019 [D loss: 0.071345, acc: 100.00%] [G loss: 7.480466]\n",
      "epoch:44 step:35020 [D loss: 0.060843, acc: 100.00%] [G loss: 4.993635]\n",
      "epoch:44 step:35021 [D loss: 0.249821, acc: 96.88%] [G loss: 5.579246]\n",
      "epoch:44 step:35022 [D loss: 0.401460, acc: 89.84%] [G loss: 3.974206]\n",
      "epoch:44 step:35023 [D loss: 0.089133, acc: 99.22%] [G loss: 6.771895]\n",
      "epoch:44 step:35024 [D loss: 0.024701, acc: 100.00%] [G loss: 8.158900]\n",
      "epoch:44 step:35025 [D loss: 0.019363, acc: 100.00%] [G loss: 5.259065]\n",
      "epoch:44 step:35026 [D loss: 1.119656, acc: 50.00%] [G loss: 7.193818]\n",
      "epoch:44 step:35027 [D loss: 0.042408, acc: 100.00%] [G loss: 8.076243]\n",
      "epoch:44 step:35028 [D loss: 1.449751, acc: 50.00%] [G loss: 9.049754]\n",
      "epoch:44 step:35029 [D loss: 0.045407, acc: 100.00%] [G loss: 5.622436]\n",
      "epoch:44 step:35030 [D loss: 0.141983, acc: 98.44%] [G loss: 3.707639]\n",
      "epoch:44 step:35031 [D loss: 0.062677, acc: 100.00%] [G loss: 6.252509]\n",
      "epoch:44 step:35032 [D loss: 0.773021, acc: 53.12%] [G loss: 3.200282]\n",
      "epoch:44 step:35033 [D loss: 0.096068, acc: 99.22%] [G loss: 4.241847]\n",
      "epoch:44 step:35034 [D loss: 0.399783, acc: 76.56%] [G loss: 6.968855]\n",
      "epoch:44 step:35035 [D loss: 0.328536, acc: 92.19%] [G loss: 8.749846]\n",
      "epoch:44 step:35036 [D loss: 0.873591, acc: 50.00%] [G loss: 6.918614]\n",
      "epoch:44 step:35037 [D loss: 0.863175, acc: 50.78%] [G loss: 8.077374]\n",
      "epoch:44 step:35038 [D loss: 0.637728, acc: 63.28%] [G loss: 4.929246]\n",
      "epoch:44 step:35039 [D loss: 0.167102, acc: 98.44%] [G loss: 4.960775]\n",
      "epoch:44 step:35040 [D loss: 0.048854, acc: 100.00%] [G loss: 8.594654]\n",
      "epoch:44 step:35041 [D loss: 0.163483, acc: 97.66%] [G loss: 5.788883]\n",
      "epoch:44 step:35042 [D loss: 0.344079, acc: 79.69%] [G loss: 5.513874]\n",
      "epoch:44 step:35043 [D loss: 0.211096, acc: 92.19%] [G loss: 5.254596]\n",
      "epoch:44 step:35044 [D loss: 0.113346, acc: 100.00%] [G loss: 5.357907]\n",
      "epoch:44 step:35045 [D loss: 0.254361, acc: 96.09%] [G loss: 2.502764]\n",
      "epoch:44 step:35046 [D loss: 0.336379, acc: 79.69%] [G loss: 6.171736]\n",
      "epoch:44 step:35047 [D loss: 1.130251, acc: 49.22%] [G loss: 4.508883]\n",
      "epoch:44 step:35048 [D loss: 0.599707, acc: 68.75%] [G loss: 4.871066]\n",
      "epoch:44 step:35049 [D loss: 0.441085, acc: 78.91%] [G loss: 5.722065]\n",
      "epoch:44 step:35050 [D loss: 0.097594, acc: 99.22%] [G loss: 5.731627]\n",
      "epoch:44 step:35051 [D loss: 0.135458, acc: 100.00%] [G loss: 6.526275]\n",
      "epoch:44 step:35052 [D loss: 0.147704, acc: 100.00%] [G loss: 5.396199]\n",
      "epoch:44 step:35053 [D loss: 0.108519, acc: 100.00%] [G loss: 6.173556]\n",
      "epoch:44 step:35054 [D loss: 0.024949, acc: 100.00%] [G loss: 4.647513]\n",
      "epoch:44 step:35055 [D loss: 0.317764, acc: 96.09%] [G loss: 5.956523]\n",
      "epoch:44 step:35056 [D loss: 0.206999, acc: 97.66%] [G loss: 9.145163]\n",
      "epoch:44 step:35057 [D loss: 0.165026, acc: 96.88%] [G loss: 7.707588]\n",
      "epoch:44 step:35058 [D loss: 0.144182, acc: 99.22%] [G loss: 2.845024]\n",
      "epoch:44 step:35059 [D loss: 0.080218, acc: 100.00%] [G loss: 6.882403]\n",
      "epoch:44 step:35060 [D loss: 0.264243, acc: 97.66%] [G loss: 2.150881]\n",
      "epoch:44 step:35061 [D loss: 0.044399, acc: 99.22%] [G loss: 3.943791]\n",
      "epoch:44 step:35062 [D loss: 0.914418, acc: 44.53%] [G loss: 7.634860]\n",
      "epoch:44 step:35063 [D loss: 0.185712, acc: 100.00%] [G loss: 10.348177]\n",
      "epoch:44 step:35064 [D loss: 0.394067, acc: 72.66%] [G loss: 7.004157]\n",
      "epoch:44 step:35065 [D loss: 0.118973, acc: 100.00%] [G loss: 3.947074]\n",
      "epoch:44 step:35066 [D loss: 0.229360, acc: 92.97%] [G loss: 4.355835]\n",
      "epoch:44 step:35067 [D loss: 0.266358, acc: 95.31%] [G loss: 6.350386]\n",
      "epoch:44 step:35068 [D loss: 0.075436, acc: 100.00%] [G loss: 7.195561]\n",
      "epoch:44 step:35069 [D loss: 0.680710, acc: 55.47%] [G loss: 5.275820]\n",
      "epoch:44 step:35070 [D loss: 0.271306, acc: 88.28%] [G loss: 8.062489]\n",
      "epoch:44 step:35071 [D loss: 0.413984, acc: 89.06%] [G loss: 7.803087]\n",
      "epoch:44 step:35072 [D loss: 0.210434, acc: 100.00%] [G loss: 3.228334]\n",
      "epoch:44 step:35073 [D loss: 0.302106, acc: 92.19%] [G loss: 4.250188]\n",
      "epoch:44 step:35074 [D loss: 0.420189, acc: 74.22%] [G loss: 5.859700]\n",
      "epoch:44 step:35075 [D loss: 0.070232, acc: 100.00%] [G loss: 7.488245]\n",
      "epoch:44 step:35076 [D loss: 0.616779, acc: 57.81%] [G loss: 6.489486]\n",
      "epoch:44 step:35077 [D loss: 1.008785, acc: 50.78%] [G loss: 12.160907]\n",
      "epoch:44 step:35078 [D loss: 0.201662, acc: 99.22%] [G loss: 4.504938]\n",
      "epoch:44 step:35079 [D loss: 0.143183, acc: 96.09%] [G loss: 6.085588]\n",
      "epoch:44 step:35080 [D loss: 0.191438, acc: 97.66%] [G loss: 7.523928]\n",
      "epoch:44 step:35081 [D loss: 0.316624, acc: 84.38%] [G loss: 3.177312]\n",
      "epoch:44 step:35082 [D loss: 0.256769, acc: 94.53%] [G loss: 8.556572]\n",
      "epoch:44 step:35083 [D loss: 0.135829, acc: 100.00%] [G loss: 4.814655]\n",
      "epoch:44 step:35084 [D loss: 0.212863, acc: 99.22%] [G loss: 4.260303]\n",
      "epoch:44 step:35085 [D loss: 0.950956, acc: 50.78%] [G loss: 7.898494]\n",
      "epoch:44 step:35086 [D loss: 0.737298, acc: 53.91%] [G loss: 7.998309]\n",
      "epoch:44 step:35087 [D loss: 0.106312, acc: 100.00%] [G loss: 4.530773]\n",
      "epoch:44 step:35088 [D loss: 2.653986, acc: 41.41%] [G loss: 9.584349]\n",
      "epoch:44 step:35089 [D loss: 0.062159, acc: 100.00%] [G loss: 6.876493]\n",
      "epoch:44 step:35090 [D loss: 0.264498, acc: 91.41%] [G loss: 7.213409]\n",
      "epoch:44 step:35091 [D loss: 0.289138, acc: 87.50%] [G loss: 5.272410]\n",
      "epoch:44 step:35092 [D loss: 0.896465, acc: 49.22%] [G loss: 2.623921]\n",
      "epoch:44 step:35093 [D loss: 0.090611, acc: 100.00%] [G loss: 3.521044]\n",
      "epoch:44 step:35094 [D loss: 0.391352, acc: 89.06%] [G loss: 6.202798]\n",
      "epoch:44 step:35095 [D loss: 0.759082, acc: 60.16%] [G loss: 5.578607]\n",
      "epoch:44 step:35096 [D loss: 0.105270, acc: 99.22%] [G loss: 5.526323]\n",
      "epoch:44 step:35097 [D loss: 0.165773, acc: 98.44%] [G loss: 6.998291]\n",
      "epoch:44 step:35098 [D loss: 0.137244, acc: 99.22%] [G loss: 4.302427]\n",
      "epoch:44 step:35099 [D loss: 0.008288, acc: 100.00%] [G loss: 9.731836]\n",
      "epoch:44 step:35100 [D loss: 0.636022, acc: 59.38%] [G loss: 5.305206]\n",
      "epoch:44 step:35101 [D loss: 0.145463, acc: 100.00%] [G loss: 6.971958]\n",
      "epoch:44 step:35102 [D loss: 0.416911, acc: 82.03%] [G loss: 5.808618]\n",
      "epoch:44 step:35103 [D loss: 0.541268, acc: 75.00%] [G loss: 6.644983]\n",
      "epoch:44 step:35104 [D loss: 0.191646, acc: 98.44%] [G loss: 4.697505]\n",
      "epoch:44 step:35105 [D loss: 0.228371, acc: 94.53%] [G loss: 4.859985]\n",
      "epoch:44 step:35106 [D loss: 0.382926, acc: 78.12%] [G loss: 4.987149]\n",
      "epoch:44 step:35107 [D loss: 0.023721, acc: 100.00%] [G loss: 4.645513]\n",
      "epoch:44 step:35108 [D loss: 0.140988, acc: 100.00%] [G loss: 4.741934]\n",
      "epoch:44 step:35109 [D loss: 0.110858, acc: 98.44%] [G loss: 3.590463]\n",
      "epoch:44 step:35110 [D loss: 0.236471, acc: 95.31%] [G loss: 2.871058]\n",
      "epoch:44 step:35111 [D loss: 0.555649, acc: 63.28%] [G loss: 6.449389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:35112 [D loss: 0.608942, acc: 57.81%] [G loss: 6.411087]\n",
      "epoch:44 step:35113 [D loss: 0.281703, acc: 93.75%] [G loss: 5.829717]\n",
      "epoch:44 step:35114 [D loss: 0.107279, acc: 100.00%] [G loss: 5.519679]\n",
      "epoch:44 step:35115 [D loss: 0.433941, acc: 78.91%] [G loss: 7.643118]\n",
      "epoch:44 step:35116 [D loss: 0.155860, acc: 97.66%] [G loss: 6.247096]\n",
      "epoch:44 step:35117 [D loss: 0.069264, acc: 100.00%] [G loss: 6.437269]\n",
      "epoch:44 step:35118 [D loss: 0.064763, acc: 100.00%] [G loss: 10.710112]\n",
      "epoch:44 step:35119 [D loss: 0.156583, acc: 95.31%] [G loss: 5.322112]\n",
      "epoch:44 step:35120 [D loss: 0.197271, acc: 93.75%] [G loss: 4.528844]\n",
      "epoch:44 step:35121 [D loss: 0.715240, acc: 60.94%] [G loss: 7.734179]\n",
      "epoch:44 step:35122 [D loss: 0.196919, acc: 96.88%] [G loss: 6.048537]\n",
      "epoch:44 step:35123 [D loss: 0.097978, acc: 99.22%] [G loss: 3.802929]\n",
      "epoch:44 step:35124 [D loss: 0.120186, acc: 100.00%] [G loss: 5.360548]\n",
      "epoch:44 step:35125 [D loss: 0.370857, acc: 82.81%] [G loss: 5.376242]\n",
      "epoch:44 step:35126 [D loss: 0.519809, acc: 67.97%] [G loss: 5.825018]\n",
      "epoch:44 step:35127 [D loss: 0.059258, acc: 100.00%] [G loss: 4.235540]\n",
      "epoch:44 step:35128 [D loss: 0.342808, acc: 85.16%] [G loss: 5.190490]\n",
      "epoch:44 step:35129 [D loss: 0.110876, acc: 99.22%] [G loss: 4.795644]\n",
      "epoch:44 step:35130 [D loss: 0.117992, acc: 100.00%] [G loss: 3.796774]\n",
      "epoch:44 step:35131 [D loss: 0.064308, acc: 100.00%] [G loss: 6.342050]\n",
      "epoch:44 step:35132 [D loss: 0.410427, acc: 85.94%] [G loss: 3.893214]\n",
      "epoch:44 step:35133 [D loss: 0.388750, acc: 85.16%] [G loss: 6.550945]\n",
      "epoch:44 step:35134 [D loss: 0.067811, acc: 100.00%] [G loss: 5.714056]\n",
      "epoch:44 step:35135 [D loss: 0.381268, acc: 76.56%] [G loss: 8.376044]\n",
      "epoch:44 step:35136 [D loss: 1.901054, acc: 13.28%] [G loss: 6.989352]\n",
      "epoch:44 step:35137 [D loss: 0.073507, acc: 100.00%] [G loss: 11.020452]\n",
      "epoch:44 step:35138 [D loss: 0.338739, acc: 83.59%] [G loss: 5.980465]\n",
      "epoch:44 step:35139 [D loss: 0.118825, acc: 98.44%] [G loss: 4.973661]\n",
      "epoch:44 step:35140 [D loss: 0.190201, acc: 95.31%] [G loss: 4.955338]\n",
      "epoch:44 step:35141 [D loss: 0.416835, acc: 75.78%] [G loss: 3.255243]\n",
      "epoch:44 step:35142 [D loss: 0.095601, acc: 99.22%] [G loss: 4.664937]\n",
      "epoch:44 step:35143 [D loss: 0.375126, acc: 89.06%] [G loss: 3.073554]\n",
      "epoch:44 step:35144 [D loss: 0.190456, acc: 96.88%] [G loss: 4.359369]\n",
      "epoch:44 step:35145 [D loss: 0.674327, acc: 58.59%] [G loss: 7.150209]\n",
      "epoch:45 step:35146 [D loss: 0.801956, acc: 50.78%] [G loss: 7.536464]\n",
      "epoch:45 step:35147 [D loss: 0.144207, acc: 100.00%] [G loss: 6.369227]\n",
      "epoch:45 step:35148 [D loss: 0.147935, acc: 100.00%] [G loss: 5.144436]\n",
      "epoch:45 step:35149 [D loss: 1.457756, acc: 50.00%] [G loss: 10.073833]\n",
      "epoch:45 step:35150 [D loss: 0.324561, acc: 89.06%] [G loss: 4.930779]\n",
      "epoch:45 step:35151 [D loss: 0.304843, acc: 82.81%] [G loss: 6.377925]\n",
      "epoch:45 step:35152 [D loss: 0.065557, acc: 100.00%] [G loss: 5.629931]\n",
      "epoch:45 step:35153 [D loss: 0.027295, acc: 100.00%] [G loss: 7.321781]\n",
      "epoch:45 step:35154 [D loss: 0.035853, acc: 100.00%] [G loss: 6.265478]\n",
      "epoch:45 step:35155 [D loss: 0.140932, acc: 97.66%] [G loss: 6.017358]\n",
      "epoch:45 step:35156 [D loss: 0.996709, acc: 46.09%] [G loss: 5.251447]\n",
      "epoch:45 step:35157 [D loss: 0.400330, acc: 78.91%] [G loss: 1.261268]\n",
      "epoch:45 step:35158 [D loss: 0.065459, acc: 100.00%] [G loss: 4.899250]\n",
      "epoch:45 step:35159 [D loss: 0.077748, acc: 100.00%] [G loss: 4.634603]\n",
      "epoch:45 step:35160 [D loss: 0.445734, acc: 84.38%] [G loss: 4.977238]\n",
      "epoch:45 step:35161 [D loss: 0.727736, acc: 59.38%] [G loss: 7.742668]\n",
      "epoch:45 step:35162 [D loss: 0.391845, acc: 82.03%] [G loss: 7.000841]\n",
      "epoch:45 step:35163 [D loss: 0.094902, acc: 100.00%] [G loss: 5.832448]\n",
      "epoch:45 step:35164 [D loss: 0.685857, acc: 60.16%] [G loss: 6.822247]\n",
      "epoch:45 step:35165 [D loss: 1.011656, acc: 51.56%] [G loss: 10.470955]\n",
      "epoch:45 step:35166 [D loss: 0.064714, acc: 100.00%] [G loss: 3.133713]\n",
      "epoch:45 step:35167 [D loss: 0.307873, acc: 88.28%] [G loss: 5.422668]\n",
      "epoch:45 step:35168 [D loss: 0.185199, acc: 99.22%] [G loss: 2.575997]\n",
      "epoch:45 step:35169 [D loss: 0.319205, acc: 89.06%] [G loss: 4.251194]\n",
      "epoch:45 step:35170 [D loss: 0.027874, acc: 100.00%] [G loss: 5.042763]\n",
      "epoch:45 step:35171 [D loss: 0.624239, acc: 61.72%] [G loss: 5.180667]\n",
      "epoch:45 step:35172 [D loss: 0.976813, acc: 33.59%] [G loss: 5.816171]\n",
      "epoch:45 step:35173 [D loss: 0.100575, acc: 100.00%] [G loss: 3.066419]\n",
      "epoch:45 step:35174 [D loss: 0.177407, acc: 99.22%] [G loss: 4.296459]\n",
      "epoch:45 step:35175 [D loss: 0.039128, acc: 100.00%] [G loss: 2.728577]\n",
      "epoch:45 step:35176 [D loss: 0.035765, acc: 100.00%] [G loss: 6.498276]\n",
      "epoch:45 step:35177 [D loss: 0.069505, acc: 100.00%] [G loss: 5.871411]\n",
      "epoch:45 step:35178 [D loss: 0.083684, acc: 100.00%] [G loss: 5.838073]\n",
      "epoch:45 step:35179 [D loss: 0.069077, acc: 100.00%] [G loss: 3.513902]\n",
      "epoch:45 step:35180 [D loss: 1.049550, acc: 51.56%] [G loss: 7.985727]\n",
      "epoch:45 step:35181 [D loss: 0.525358, acc: 67.19%] [G loss: 5.719413]\n",
      "epoch:45 step:35182 [D loss: 0.081355, acc: 100.00%] [G loss: 7.345917]\n",
      "epoch:45 step:35183 [D loss: 0.336018, acc: 91.41%] [G loss: 6.949465]\n",
      "epoch:45 step:35184 [D loss: 0.576252, acc: 69.53%] [G loss: 9.302095]\n",
      "epoch:45 step:35185 [D loss: 0.175923, acc: 95.31%] [G loss: 6.360675]\n",
      "epoch:45 step:35186 [D loss: 1.039741, acc: 53.12%] [G loss: 8.991302]\n",
      "epoch:45 step:35187 [D loss: 0.091021, acc: 100.00%] [G loss: 4.538407]\n",
      "epoch:45 step:35188 [D loss: 0.680202, acc: 59.38%] [G loss: 5.348020]\n",
      "epoch:45 step:35189 [D loss: 0.095484, acc: 100.00%] [G loss: 8.497730]\n",
      "epoch:45 step:35190 [D loss: 0.532451, acc: 69.53%] [G loss: 7.785057]\n",
      "epoch:45 step:35191 [D loss: 0.058832, acc: 100.00%] [G loss: 6.623410]\n",
      "epoch:45 step:35192 [D loss: 0.076242, acc: 100.00%] [G loss: 6.240675]\n",
      "epoch:45 step:35193 [D loss: 0.349752, acc: 86.72%] [G loss: 3.792629]\n",
      "epoch:45 step:35194 [D loss: 0.851819, acc: 53.12%] [G loss: 6.227260]\n",
      "epoch:45 step:35195 [D loss: 0.045485, acc: 100.00%] [G loss: 5.673879]\n",
      "epoch:45 step:35196 [D loss: 0.600749, acc: 58.59%] [G loss: 2.724035]\n",
      "epoch:45 step:35197 [D loss: 0.253641, acc: 87.50%] [G loss: 4.907156]\n",
      "epoch:45 step:35198 [D loss: 0.902035, acc: 48.44%] [G loss: 10.513416]\n",
      "epoch:45 step:35199 [D loss: 0.096575, acc: 100.00%] [G loss: 5.328671]\n",
      "epoch:45 step:35200 [D loss: 0.267842, acc: 87.50%] [G loss: 7.438220]\n",
      "epoch:45 step:35201 [D loss: 0.052717, acc: 100.00%] [G loss: 3.379904]\n",
      "epoch:45 step:35202 [D loss: 0.050842, acc: 100.00%] [G loss: 3.533128]\n",
      "epoch:45 step:35203 [D loss: 0.987828, acc: 46.88%] [G loss: 5.359229]\n",
      "epoch:45 step:35204 [D loss: 0.464226, acc: 75.78%] [G loss: 2.956736]\n",
      "epoch:45 step:35205 [D loss: 0.243123, acc: 91.41%] [G loss: 3.864077]\n",
      "epoch:45 step:35206 [D loss: 0.084088, acc: 100.00%] [G loss: 7.058866]\n",
      "epoch:45 step:35207 [D loss: 0.100221, acc: 98.44%] [G loss: 8.450985]\n",
      "epoch:45 step:35208 [D loss: 0.100877, acc: 100.00%] [G loss: 5.941647]\n",
      "epoch:45 step:35209 [D loss: 0.217014, acc: 92.97%] [G loss: 5.192353]\n",
      "epoch:45 step:35210 [D loss: 0.070141, acc: 100.00%] [G loss: 3.514792]\n",
      "epoch:45 step:35211 [D loss: 0.065266, acc: 100.00%] [G loss: 4.624270]\n",
      "epoch:45 step:35212 [D loss: 0.101344, acc: 100.00%] [G loss: 3.872328]\n",
      "epoch:45 step:35213 [D loss: 1.043009, acc: 32.81%] [G loss: 8.093470]\n",
      "epoch:45 step:35214 [D loss: 0.207564, acc: 96.09%] [G loss: 6.053503]\n",
      "epoch:45 step:35215 [D loss: 0.577032, acc: 72.66%] [G loss: 5.740538]\n",
      "epoch:45 step:35216 [D loss: 1.764168, acc: 10.16%] [G loss: 6.588441]\n",
      "epoch:45 step:35217 [D loss: 0.325437, acc: 84.38%] [G loss: 4.268487]\n",
      "epoch:45 step:35218 [D loss: 0.669749, acc: 55.47%] [G loss: 6.875354]\n",
      "epoch:45 step:35219 [D loss: 0.053077, acc: 100.00%] [G loss: 4.857902]\n",
      "epoch:45 step:35220 [D loss: 0.437099, acc: 88.28%] [G loss: 7.493812]\n",
      "epoch:45 step:35221 [D loss: 0.669231, acc: 53.91%] [G loss: 3.554828]\n",
      "epoch:45 step:35222 [D loss: 0.094542, acc: 99.22%] [G loss: 3.571759]\n",
      "epoch:45 step:35223 [D loss: 0.646852, acc: 55.47%] [G loss: 4.227871]\n",
      "epoch:45 step:35224 [D loss: 0.153046, acc: 99.22%] [G loss: 4.840004]\n",
      "epoch:45 step:35225 [D loss: 0.227228, acc: 96.09%] [G loss: 7.547459]\n",
      "epoch:45 step:35226 [D loss: 0.045173, acc: 100.00%] [G loss: 5.702525]\n",
      "epoch:45 step:35227 [D loss: 0.117942, acc: 100.00%] [G loss: 6.538320]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35228 [D loss: 0.184101, acc: 96.88%] [G loss: 7.532205]\n",
      "epoch:45 step:35229 [D loss: 0.107328, acc: 100.00%] [G loss: 4.205053]\n",
      "epoch:45 step:35230 [D loss: 0.136670, acc: 98.44%] [G loss: 6.197857]\n",
      "epoch:45 step:35231 [D loss: 0.186845, acc: 98.44%] [G loss: 5.285133]\n",
      "epoch:45 step:35232 [D loss: 0.760052, acc: 51.56%] [G loss: 6.438439]\n",
      "epoch:45 step:35233 [D loss: 0.047422, acc: 99.22%] [G loss: 5.638087]\n",
      "epoch:45 step:35234 [D loss: 0.031037, acc: 100.00%] [G loss: 5.225136]\n",
      "epoch:45 step:35235 [D loss: 0.065418, acc: 100.00%] [G loss: 5.848629]\n",
      "epoch:45 step:35236 [D loss: 0.146898, acc: 97.66%] [G loss: 5.457360]\n",
      "epoch:45 step:35237 [D loss: 0.034296, acc: 100.00%] [G loss: 4.864251]\n",
      "epoch:45 step:35238 [D loss: 0.239380, acc: 95.31%] [G loss: 9.409733]\n",
      "epoch:45 step:35239 [D loss: 0.021502, acc: 100.00%] [G loss: 3.676377]\n",
      "epoch:45 step:35240 [D loss: 0.248759, acc: 92.97%] [G loss: 2.657690]\n",
      "epoch:45 step:35241 [D loss: 0.314689, acc: 89.84%] [G loss: 5.619263]\n",
      "epoch:45 step:35242 [D loss: 0.124073, acc: 99.22%] [G loss: 3.758123]\n",
      "epoch:45 step:35243 [D loss: 0.194893, acc: 96.09%] [G loss: 6.782553]\n",
      "epoch:45 step:35244 [D loss: 0.128480, acc: 98.44%] [G loss: 9.157000]\n",
      "epoch:45 step:35245 [D loss: 0.069268, acc: 100.00%] [G loss: 5.424582]\n",
      "epoch:45 step:35246 [D loss: 0.137515, acc: 99.22%] [G loss: 9.103073]\n",
      "epoch:45 step:35247 [D loss: 0.075867, acc: 100.00%] [G loss: 4.008862]\n",
      "epoch:45 step:35248 [D loss: 1.033760, acc: 50.78%] [G loss: 6.028079]\n",
      "epoch:45 step:35249 [D loss: 0.066149, acc: 99.22%] [G loss: 5.139647]\n",
      "epoch:45 step:35250 [D loss: 1.014397, acc: 47.66%] [G loss: 5.705801]\n",
      "epoch:45 step:35251 [D loss: 0.745124, acc: 50.78%] [G loss: 4.147193]\n",
      "epoch:45 step:35252 [D loss: 0.295205, acc: 92.97%] [G loss: 6.326255]\n",
      "epoch:45 step:35253 [D loss: 0.813144, acc: 50.78%] [G loss: 8.337447]\n",
      "epoch:45 step:35254 [D loss: 0.142929, acc: 98.44%] [G loss: 2.729752]\n",
      "epoch:45 step:35255 [D loss: 0.552329, acc: 60.16%] [G loss: 7.546496]\n",
      "epoch:45 step:35256 [D loss: 1.157596, acc: 32.81%] [G loss: 7.080980]\n",
      "epoch:45 step:35257 [D loss: 0.034879, acc: 100.00%] [G loss: 6.940356]\n",
      "epoch:45 step:35258 [D loss: 0.021822, acc: 100.00%] [G loss: 6.737076]\n",
      "epoch:45 step:35259 [D loss: 0.068331, acc: 100.00%] [G loss: 5.276147]\n",
      "epoch:45 step:35260 [D loss: 0.128491, acc: 99.22%] [G loss: 2.216919]\n",
      "epoch:45 step:35261 [D loss: 0.339250, acc: 87.50%] [G loss: 3.961783]\n",
      "epoch:45 step:35262 [D loss: 0.276397, acc: 93.75%] [G loss: 6.317225]\n",
      "epoch:45 step:35263 [D loss: 0.116211, acc: 99.22%] [G loss: 8.965654]\n",
      "epoch:45 step:35264 [D loss: 0.305823, acc: 93.75%] [G loss: 7.638048]\n",
      "epoch:45 step:35265 [D loss: 1.060356, acc: 50.78%] [G loss: 6.682626]\n",
      "epoch:45 step:35266 [D loss: 0.137388, acc: 98.44%] [G loss: 5.124279]\n",
      "epoch:45 step:35267 [D loss: 0.086533, acc: 100.00%] [G loss: 6.635911]\n",
      "epoch:45 step:35268 [D loss: 0.381162, acc: 82.03%] [G loss: 7.148207]\n",
      "epoch:45 step:35269 [D loss: 0.094215, acc: 100.00%] [G loss: 8.198288]\n",
      "epoch:45 step:35270 [D loss: 1.088315, acc: 50.78%] [G loss: 9.380725]\n",
      "epoch:45 step:35271 [D loss: 0.419623, acc: 68.75%] [G loss: 7.657595]\n",
      "epoch:45 step:35272 [D loss: 0.287377, acc: 93.75%] [G loss: 6.693301]\n",
      "epoch:45 step:35273 [D loss: 0.080864, acc: 99.22%] [G loss: 6.855849]\n",
      "epoch:45 step:35274 [D loss: 0.079136, acc: 100.00%] [G loss: 4.700353]\n",
      "epoch:45 step:35275 [D loss: 0.163463, acc: 98.44%] [G loss: 4.849509]\n",
      "epoch:45 step:35276 [D loss: 0.150375, acc: 99.22%] [G loss: 3.003427]\n",
      "epoch:45 step:35277 [D loss: 0.079193, acc: 100.00%] [G loss: 5.892550]\n",
      "epoch:45 step:35278 [D loss: 0.750590, acc: 49.22%] [G loss: 5.848060]\n",
      "epoch:45 step:35279 [D loss: 0.201497, acc: 99.22%] [G loss: 3.827418]\n",
      "epoch:45 step:35280 [D loss: 0.191204, acc: 98.44%] [G loss: 5.400821]\n",
      "epoch:45 step:35281 [D loss: 0.826888, acc: 46.88%] [G loss: 5.445741]\n",
      "epoch:45 step:35282 [D loss: 0.131461, acc: 98.44%] [G loss: 6.439491]\n",
      "epoch:45 step:35283 [D loss: 0.564515, acc: 74.22%] [G loss: 6.322515]\n",
      "epoch:45 step:35284 [D loss: 0.124719, acc: 100.00%] [G loss: 7.426776]\n",
      "epoch:45 step:35285 [D loss: 0.254849, acc: 89.84%] [G loss: 6.882422]\n",
      "epoch:45 step:35286 [D loss: 0.298335, acc: 89.84%] [G loss: 6.468154]\n",
      "epoch:45 step:35287 [D loss: 0.114284, acc: 100.00%] [G loss: 4.578278]\n",
      "epoch:45 step:35288 [D loss: 0.130175, acc: 98.44%] [G loss: 3.614997]\n",
      "epoch:45 step:35289 [D loss: 0.441123, acc: 78.12%] [G loss: 5.743283]\n",
      "epoch:45 step:35290 [D loss: 0.249465, acc: 96.88%] [G loss: 4.518492]\n",
      "epoch:45 step:35291 [D loss: 0.032409, acc: 100.00%] [G loss: 4.135301]\n",
      "epoch:45 step:35292 [D loss: 0.068734, acc: 100.00%] [G loss: 5.646831]\n",
      "epoch:45 step:35293 [D loss: 0.217507, acc: 95.31%] [G loss: 5.518846]\n",
      "epoch:45 step:35294 [D loss: 0.612634, acc: 57.81%] [G loss: 4.996352]\n",
      "epoch:45 step:35295 [D loss: 0.497630, acc: 64.06%] [G loss: 6.555867]\n",
      "epoch:45 step:35296 [D loss: 0.016604, acc: 100.00%] [G loss: 3.660591]\n",
      "epoch:45 step:35297 [D loss: 0.020889, acc: 100.00%] [G loss: 7.064655]\n",
      "epoch:45 step:35298 [D loss: 0.120205, acc: 98.44%] [G loss: 3.616010]\n",
      "epoch:45 step:35299 [D loss: 0.076471, acc: 100.00%] [G loss: 5.671889]\n",
      "epoch:45 step:35300 [D loss: 0.430304, acc: 86.72%] [G loss: 5.450212]\n",
      "epoch:45 step:35301 [D loss: 0.062387, acc: 100.00%] [G loss: 4.010242]\n",
      "epoch:45 step:35302 [D loss: 0.219375, acc: 95.31%] [G loss: 4.266335]\n",
      "epoch:45 step:35303 [D loss: 0.073806, acc: 100.00%] [G loss: 5.872519]\n",
      "epoch:45 step:35304 [D loss: 0.256423, acc: 93.75%] [G loss: 2.452849]\n",
      "epoch:45 step:35305 [D loss: 0.283274, acc: 94.53%] [G loss: 4.282722]\n",
      "epoch:45 step:35306 [D loss: 0.016675, acc: 100.00%] [G loss: 5.021078]\n",
      "epoch:45 step:35307 [D loss: 0.859516, acc: 53.12%] [G loss: 9.214528]\n",
      "epoch:45 step:35308 [D loss: 0.106185, acc: 99.22%] [G loss: 5.099459]\n",
      "epoch:45 step:35309 [D loss: 0.152031, acc: 96.09%] [G loss: 5.395754]\n",
      "epoch:45 step:35310 [D loss: 0.366311, acc: 89.84%] [G loss: 5.365773]\n",
      "epoch:45 step:35311 [D loss: 0.420285, acc: 74.22%] [G loss: 6.004677]\n",
      "epoch:45 step:35312 [D loss: 0.684672, acc: 56.25%] [G loss: 3.938435]\n",
      "epoch:45 step:35313 [D loss: 0.245942, acc: 92.19%] [G loss: 6.088837]\n",
      "epoch:45 step:35314 [D loss: 0.691553, acc: 56.25%] [G loss: 4.197216]\n",
      "epoch:45 step:35315 [D loss: 0.296591, acc: 92.97%] [G loss: 3.630376]\n",
      "epoch:45 step:35316 [D loss: 0.202992, acc: 95.31%] [G loss: 6.272574]\n",
      "epoch:45 step:35317 [D loss: 0.248452, acc: 93.75%] [G loss: 4.994242]\n",
      "epoch:45 step:35318 [D loss: 0.464551, acc: 64.84%] [G loss: 5.774163]\n",
      "epoch:45 step:35319 [D loss: 0.106421, acc: 99.22%] [G loss: 6.910520]\n",
      "epoch:45 step:35320 [D loss: 0.025574, acc: 100.00%] [G loss: 9.139788]\n",
      "epoch:45 step:35321 [D loss: 0.198815, acc: 98.44%] [G loss: 6.507907]\n",
      "epoch:45 step:35322 [D loss: 0.149381, acc: 99.22%] [G loss: 5.964762]\n",
      "epoch:45 step:35323 [D loss: 1.123441, acc: 45.31%] [G loss: 3.622067]\n",
      "epoch:45 step:35324 [D loss: 0.296316, acc: 87.50%] [G loss: 4.292574]\n",
      "epoch:45 step:35325 [D loss: 0.030968, acc: 100.00%] [G loss: 5.660626]\n",
      "epoch:45 step:35326 [D loss: 0.021326, acc: 100.00%] [G loss: 7.462069]\n",
      "epoch:45 step:35327 [D loss: 0.162878, acc: 96.88%] [G loss: 7.721446]\n",
      "epoch:45 step:35328 [D loss: 0.818882, acc: 50.78%] [G loss: 3.995736]\n",
      "epoch:45 step:35329 [D loss: 0.363604, acc: 78.12%] [G loss: 7.074601]\n",
      "epoch:45 step:35330 [D loss: 0.160028, acc: 99.22%] [G loss: 6.202194]\n",
      "epoch:45 step:35331 [D loss: 0.426801, acc: 84.38%] [G loss: 5.618743]\n",
      "epoch:45 step:35332 [D loss: 0.476248, acc: 82.03%] [G loss: 4.815427]\n",
      "epoch:45 step:35333 [D loss: 0.269786, acc: 92.97%] [G loss: 3.319920]\n",
      "epoch:45 step:35334 [D loss: 0.111340, acc: 99.22%] [G loss: 8.516893]\n",
      "epoch:45 step:35335 [D loss: 0.722101, acc: 53.12%] [G loss: 7.909734]\n",
      "epoch:45 step:35336 [D loss: 1.460619, acc: 50.00%] [G loss: 4.797979]\n",
      "epoch:45 step:35337 [D loss: 0.116203, acc: 99.22%] [G loss: 0.880999]\n",
      "epoch:45 step:35338 [D loss: 0.384135, acc: 85.94%] [G loss: 6.546822]\n",
      "epoch:45 step:35339 [D loss: 0.426008, acc: 84.38%] [G loss: 4.980973]\n",
      "epoch:45 step:35340 [D loss: 1.159179, acc: 19.53%] [G loss: 6.667301]\n",
      "epoch:45 step:35341 [D loss: 0.307673, acc: 92.97%] [G loss: 4.794581]\n",
      "epoch:45 step:35342 [D loss: 1.136837, acc: 49.22%] [G loss: 3.889792]\n",
      "epoch:45 step:35343 [D loss: 0.115214, acc: 99.22%] [G loss: 4.089923]\n",
      "epoch:45 step:35344 [D loss: 0.607004, acc: 64.06%] [G loss: 6.699748]\n",
      "epoch:45 step:35345 [D loss: 0.024571, acc: 100.00%] [G loss: 6.879518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35346 [D loss: 1.026819, acc: 50.00%] [G loss: 8.755647]\n",
      "epoch:45 step:35347 [D loss: 0.276627, acc: 87.50%] [G loss: 5.989418]\n",
      "epoch:45 step:35348 [D loss: 0.176487, acc: 99.22%] [G loss: 2.794115]\n",
      "epoch:45 step:35349 [D loss: 0.210398, acc: 96.09%] [G loss: 5.098119]\n",
      "epoch:45 step:35350 [D loss: 0.876507, acc: 51.56%] [G loss: 9.097066]\n",
      "epoch:45 step:35351 [D loss: 0.606364, acc: 56.25%] [G loss: 4.900577]\n",
      "epoch:45 step:35352 [D loss: 0.308513, acc: 86.72%] [G loss: 6.268388]\n",
      "epoch:45 step:35353 [D loss: 0.059768, acc: 100.00%] [G loss: 5.418128]\n",
      "epoch:45 step:35354 [D loss: 0.506206, acc: 67.19%] [G loss: 4.212900]\n",
      "epoch:45 step:35355 [D loss: 0.056920, acc: 100.00%] [G loss: 6.123750]\n",
      "epoch:45 step:35356 [D loss: 0.041682, acc: 100.00%] [G loss: 5.039182]\n",
      "epoch:45 step:35357 [D loss: 0.288063, acc: 91.41%] [G loss: 5.779324]\n",
      "epoch:45 step:35358 [D loss: 0.192222, acc: 94.53%] [G loss: 7.014284]\n",
      "epoch:45 step:35359 [D loss: 0.158831, acc: 100.00%] [G loss: 4.347850]\n",
      "epoch:45 step:35360 [D loss: 0.198370, acc: 98.44%] [G loss: 4.539938]\n",
      "epoch:45 step:35361 [D loss: 0.250261, acc: 96.09%] [G loss: 1.293985]\n",
      "epoch:45 step:35362 [D loss: 0.049033, acc: 100.00%] [G loss: 6.617592]\n",
      "epoch:45 step:35363 [D loss: 0.289877, acc: 94.53%] [G loss: 3.763726]\n",
      "epoch:45 step:35364 [D loss: 0.315170, acc: 85.16%] [G loss: 3.733309]\n",
      "epoch:45 step:35365 [D loss: 0.142936, acc: 100.00%] [G loss: 5.321250]\n",
      "epoch:45 step:35366 [D loss: 0.008487, acc: 100.00%] [G loss: 5.180038]\n",
      "epoch:45 step:35367 [D loss: 0.755026, acc: 54.69%] [G loss: 5.675016]\n",
      "epoch:45 step:35368 [D loss: 0.389429, acc: 77.34%] [G loss: 5.623055]\n",
      "epoch:45 step:35369 [D loss: 0.517798, acc: 67.97%] [G loss: 4.358096]\n",
      "epoch:45 step:35370 [D loss: 0.063642, acc: 100.00%] [G loss: 4.491660]\n",
      "epoch:45 step:35371 [D loss: 0.491454, acc: 74.22%] [G loss: 6.575506]\n",
      "epoch:45 step:35372 [D loss: 0.235173, acc: 94.53%] [G loss: 4.532722]\n",
      "epoch:45 step:35373 [D loss: 0.077462, acc: 100.00%] [G loss: 6.445704]\n",
      "epoch:45 step:35374 [D loss: 0.434730, acc: 82.81%] [G loss: 3.805155]\n",
      "epoch:45 step:35375 [D loss: 1.237595, acc: 41.41%] [G loss: 6.208457]\n",
      "epoch:45 step:35376 [D loss: 0.232155, acc: 95.31%] [G loss: 5.964010]\n",
      "epoch:45 step:35377 [D loss: 1.517092, acc: 14.84%] [G loss: 6.472997]\n",
      "epoch:45 step:35378 [D loss: 0.316591, acc: 85.16%] [G loss: 6.161187]\n",
      "epoch:45 step:35379 [D loss: 0.595159, acc: 69.53%] [G loss: 7.774278]\n",
      "epoch:45 step:35380 [D loss: 0.243446, acc: 91.41%] [G loss: 4.161347]\n",
      "epoch:45 step:35381 [D loss: 0.169197, acc: 96.88%] [G loss: 3.634202]\n",
      "epoch:45 step:35382 [D loss: 0.559628, acc: 60.16%] [G loss: 5.335813]\n",
      "epoch:45 step:35383 [D loss: 0.707528, acc: 59.38%] [G loss: 4.458458]\n",
      "epoch:45 step:35384 [D loss: 0.692915, acc: 57.03%] [G loss: 5.768420]\n",
      "epoch:45 step:35385 [D loss: 0.418022, acc: 69.53%] [G loss: 6.261493]\n",
      "epoch:45 step:35386 [D loss: 1.439872, acc: 50.00%] [G loss: 9.586390]\n",
      "epoch:45 step:35387 [D loss: 0.035842, acc: 99.22%] [G loss: 6.486612]\n",
      "epoch:45 step:35388 [D loss: 0.592741, acc: 59.38%] [G loss: 5.423214]\n",
      "epoch:45 step:35389 [D loss: 0.093811, acc: 100.00%] [G loss: 3.731792]\n",
      "epoch:45 step:35390 [D loss: 0.074449, acc: 100.00%] [G loss: 5.137928]\n",
      "epoch:45 step:35391 [D loss: 1.431930, acc: 50.78%] [G loss: 7.969724]\n",
      "epoch:45 step:35392 [D loss: 0.273555, acc: 89.84%] [G loss: 4.262149]\n",
      "epoch:45 step:35393 [D loss: 0.487124, acc: 76.56%] [G loss: 3.197289]\n",
      "epoch:45 step:35394 [D loss: 0.254627, acc: 94.53%] [G loss: 6.213067]\n",
      "epoch:45 step:35395 [D loss: 0.092808, acc: 100.00%] [G loss: 6.976086]\n",
      "epoch:45 step:35396 [D loss: 0.375467, acc: 78.12%] [G loss: 3.154546]\n",
      "epoch:45 step:35397 [D loss: 0.487580, acc: 63.28%] [G loss: 4.766891]\n",
      "epoch:45 step:35398 [D loss: 0.490946, acc: 65.62%] [G loss: 3.900978]\n",
      "epoch:45 step:35399 [D loss: 0.350169, acc: 83.59%] [G loss: 2.692594]\n",
      "epoch:45 step:35400 [D loss: 0.102226, acc: 99.22%] [G loss: 3.921393]\n",
      "epoch:45 step:35401 [D loss: 0.129163, acc: 97.66%] [G loss: 5.797973]\n",
      "epoch:45 step:35402 [D loss: 0.554526, acc: 67.19%] [G loss: 4.890817]\n",
      "epoch:45 step:35403 [D loss: 0.417996, acc: 91.41%] [G loss: 4.679993]\n",
      "epoch:45 step:35404 [D loss: 0.520733, acc: 64.84%] [G loss: 5.653615]\n",
      "epoch:45 step:35405 [D loss: 0.319355, acc: 92.97%] [G loss: 6.331412]\n",
      "epoch:45 step:35406 [D loss: 2.424871, acc: 50.00%] [G loss: 6.916385]\n",
      "epoch:45 step:35407 [D loss: 0.032378, acc: 100.00%] [G loss: 7.965249]\n",
      "epoch:45 step:35408 [D loss: 0.578367, acc: 58.59%] [G loss: 6.651258]\n",
      "epoch:45 step:35409 [D loss: 0.077220, acc: 100.00%] [G loss: 4.955326]\n",
      "epoch:45 step:35410 [D loss: 0.671387, acc: 59.38%] [G loss: 6.109097]\n",
      "epoch:45 step:35411 [D loss: 0.071013, acc: 99.22%] [G loss: 5.958389]\n",
      "epoch:45 step:35412 [D loss: 0.097207, acc: 100.00%] [G loss: 9.472504]\n",
      "epoch:45 step:35413 [D loss: 0.071748, acc: 99.22%] [G loss: 3.989953]\n",
      "epoch:45 step:35414 [D loss: 0.262937, acc: 91.41%] [G loss: 3.202706]\n",
      "epoch:45 step:35415 [D loss: 0.220762, acc: 97.66%] [G loss: 4.946878]\n",
      "epoch:45 step:35416 [D loss: 0.392312, acc: 78.12%] [G loss: 5.253070]\n",
      "epoch:45 step:35417 [D loss: 0.184702, acc: 95.31%] [G loss: 7.673315]\n",
      "epoch:45 step:35418 [D loss: 0.197525, acc: 96.09%] [G loss: 4.581295]\n",
      "epoch:45 step:35419 [D loss: 0.053703, acc: 100.00%] [G loss: 7.976961]\n",
      "epoch:45 step:35420 [D loss: 0.750883, acc: 56.25%] [G loss: 5.653578]\n",
      "epoch:45 step:35421 [D loss: 0.806176, acc: 50.78%] [G loss: 4.299057]\n",
      "epoch:45 step:35422 [D loss: 0.026134, acc: 99.22%] [G loss: 5.572773]\n",
      "epoch:45 step:35423 [D loss: 1.128392, acc: 38.28%] [G loss: 6.281469]\n",
      "epoch:45 step:35424 [D loss: 0.104308, acc: 100.00%] [G loss: 5.361872]\n",
      "epoch:45 step:35425 [D loss: 0.106721, acc: 98.44%] [G loss: 8.926859]\n",
      "epoch:45 step:35426 [D loss: 0.418895, acc: 69.53%] [G loss: 6.740076]\n",
      "epoch:45 step:35427 [D loss: 0.940323, acc: 52.34%] [G loss: 3.382574]\n",
      "epoch:45 step:35428 [D loss: 0.373260, acc: 78.12%] [G loss: 6.186586]\n",
      "epoch:45 step:35429 [D loss: 0.099437, acc: 100.00%] [G loss: 8.220337]\n",
      "epoch:45 step:35430 [D loss: 0.113679, acc: 100.00%] [G loss: 5.603411]\n",
      "epoch:45 step:35431 [D loss: 0.309390, acc: 92.19%] [G loss: 5.797059]\n",
      "epoch:45 step:35432 [D loss: 0.269950, acc: 96.09%] [G loss: 6.275154]\n",
      "epoch:45 step:35433 [D loss: 0.842871, acc: 45.31%] [G loss: 5.955367]\n",
      "epoch:45 step:35434 [D loss: 0.553534, acc: 65.62%] [G loss: 5.332730]\n",
      "epoch:45 step:35435 [D loss: 0.356098, acc: 85.94%] [G loss: 4.509140]\n",
      "epoch:45 step:35436 [D loss: 1.039371, acc: 33.59%] [G loss: 6.639692]\n",
      "epoch:45 step:35437 [D loss: 0.068204, acc: 100.00%] [G loss: 5.695540]\n",
      "epoch:45 step:35438 [D loss: 0.104104, acc: 99.22%] [G loss: 4.961012]\n",
      "epoch:45 step:35439 [D loss: 0.108159, acc: 100.00%] [G loss: 4.916339]\n",
      "epoch:45 step:35440 [D loss: 0.192953, acc: 94.53%] [G loss: 7.740853]\n",
      "epoch:45 step:35441 [D loss: 0.286094, acc: 90.62%] [G loss: 6.576751]\n",
      "epoch:45 step:35442 [D loss: 0.601524, acc: 64.84%] [G loss: 4.182247]\n",
      "epoch:45 step:35443 [D loss: 0.157762, acc: 96.88%] [G loss: 7.793848]\n",
      "epoch:45 step:35444 [D loss: 0.128520, acc: 99.22%] [G loss: 7.891034]\n",
      "epoch:45 step:35445 [D loss: 0.363999, acc: 80.47%] [G loss: 5.093322]\n",
      "epoch:45 step:35446 [D loss: 0.197135, acc: 99.22%] [G loss: 4.545966]\n",
      "epoch:45 step:35447 [D loss: 0.185541, acc: 94.53%] [G loss: 7.302070]\n",
      "epoch:45 step:35448 [D loss: 0.143290, acc: 99.22%] [G loss: 4.305261]\n",
      "epoch:45 step:35449 [D loss: 0.196177, acc: 97.66%] [G loss: 1.935341]\n",
      "epoch:45 step:35450 [D loss: 0.018046, acc: 100.00%] [G loss: 5.387850]\n",
      "epoch:45 step:35451 [D loss: 0.138673, acc: 98.44%] [G loss: 5.779393]\n",
      "epoch:45 step:35452 [D loss: 0.265494, acc: 95.31%] [G loss: 6.526269]\n",
      "epoch:45 step:35453 [D loss: 0.275355, acc: 88.28%] [G loss: 7.816238]\n",
      "epoch:45 step:35454 [D loss: 0.154479, acc: 98.44%] [G loss: 4.876534]\n",
      "epoch:45 step:35455 [D loss: 0.553789, acc: 64.06%] [G loss: 5.999823]\n",
      "epoch:45 step:35456 [D loss: 0.168310, acc: 96.88%] [G loss: 6.720369]\n",
      "epoch:45 step:35457 [D loss: 0.233227, acc: 94.53%] [G loss: 2.215783]\n",
      "epoch:45 step:35458 [D loss: 0.685165, acc: 57.81%] [G loss: 6.122922]\n",
      "epoch:45 step:35459 [D loss: 0.839375, acc: 37.50%] [G loss: 6.124520]\n",
      "epoch:45 step:35460 [D loss: 0.168788, acc: 98.44%] [G loss: 6.801882]\n",
      "epoch:45 step:35461 [D loss: 0.104263, acc: 100.00%] [G loss: 7.796152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35462 [D loss: 0.173252, acc: 97.66%] [G loss: 5.529750]\n",
      "epoch:45 step:35463 [D loss: 1.055310, acc: 23.44%] [G loss: 4.489307]\n",
      "epoch:45 step:35464 [D loss: 0.108111, acc: 99.22%] [G loss: 3.525661]\n",
      "epoch:45 step:35465 [D loss: 0.087625, acc: 99.22%] [G loss: 2.968592]\n",
      "epoch:45 step:35466 [D loss: 0.049803, acc: 100.00%] [G loss: 7.997561]\n",
      "epoch:45 step:35467 [D loss: 0.146344, acc: 98.44%] [G loss: 6.743361]\n",
      "epoch:45 step:35468 [D loss: 0.113951, acc: 100.00%] [G loss: 5.548963]\n",
      "epoch:45 step:35469 [D loss: 1.213114, acc: 41.41%] [G loss: 4.638888]\n",
      "epoch:45 step:35470 [D loss: 0.316827, acc: 82.81%] [G loss: 3.260293]\n",
      "epoch:45 step:35471 [D loss: 1.649347, acc: 29.69%] [G loss: 2.589316]\n",
      "epoch:45 step:35472 [D loss: 0.070515, acc: 100.00%] [G loss: 2.176305]\n",
      "epoch:45 step:35473 [D loss: 0.219592, acc: 94.53%] [G loss: 4.575442]\n",
      "epoch:45 step:35474 [D loss: 0.339523, acc: 85.16%] [G loss: 3.730564]\n",
      "epoch:45 step:35475 [D loss: 0.049538, acc: 100.00%] [G loss: 6.604736]\n",
      "epoch:45 step:35476 [D loss: 0.265913, acc: 92.97%] [G loss: 7.620004]\n",
      "epoch:45 step:35477 [D loss: 0.557018, acc: 63.28%] [G loss: 6.702638]\n",
      "epoch:45 step:35478 [D loss: 0.846463, acc: 53.91%] [G loss: 6.091311]\n",
      "epoch:45 step:35479 [D loss: 0.239363, acc: 89.84%] [G loss: 4.555324]\n",
      "epoch:45 step:35480 [D loss: 0.069073, acc: 100.00%] [G loss: 4.931420]\n",
      "epoch:45 step:35481 [D loss: 0.052509, acc: 100.00%] [G loss: 6.196058]\n",
      "epoch:45 step:35482 [D loss: 0.137447, acc: 97.66%] [G loss: 5.294070]\n",
      "epoch:45 step:35483 [D loss: 0.458129, acc: 79.69%] [G loss: 7.452991]\n",
      "epoch:45 step:35484 [D loss: 0.311382, acc: 89.84%] [G loss: 7.281505]\n",
      "epoch:45 step:35485 [D loss: 0.305400, acc: 85.94%] [G loss: 8.715108]\n",
      "epoch:45 step:35486 [D loss: 0.108271, acc: 100.00%] [G loss: 6.894270]\n",
      "epoch:45 step:35487 [D loss: 0.461841, acc: 72.66%] [G loss: 3.294446]\n",
      "epoch:45 step:35488 [D loss: 0.144882, acc: 97.66%] [G loss: 4.386949]\n",
      "epoch:45 step:35489 [D loss: 0.040788, acc: 100.00%] [G loss: 7.170636]\n",
      "epoch:45 step:35490 [D loss: 0.175253, acc: 97.66%] [G loss: 5.566971]\n",
      "epoch:45 step:35491 [D loss: 0.158780, acc: 98.44%] [G loss: 6.118019]\n",
      "epoch:45 step:35492 [D loss: 0.025821, acc: 100.00%] [G loss: 8.456933]\n",
      "epoch:45 step:35493 [D loss: 0.028489, acc: 100.00%] [G loss: 4.070368]\n",
      "epoch:45 step:35494 [D loss: 0.479374, acc: 81.25%] [G loss: 5.805506]\n",
      "epoch:45 step:35495 [D loss: 0.192957, acc: 98.44%] [G loss: 4.057675]\n",
      "epoch:45 step:35496 [D loss: 0.064339, acc: 99.22%] [G loss: 5.948214]\n",
      "epoch:45 step:35497 [D loss: 0.065589, acc: 99.22%] [G loss: 6.331491]\n",
      "epoch:45 step:35498 [D loss: 0.094446, acc: 100.00%] [G loss: 5.536778]\n",
      "epoch:45 step:35499 [D loss: 0.533688, acc: 65.62%] [G loss: 3.531110]\n",
      "epoch:45 step:35500 [D loss: 0.527944, acc: 65.62%] [G loss: 6.972584]\n",
      "epoch:45 step:35501 [D loss: 1.123299, acc: 28.91%] [G loss: 6.530403]\n",
      "epoch:45 step:35502 [D loss: 0.259901, acc: 93.75%] [G loss: 2.762319]\n",
      "epoch:45 step:35503 [D loss: 0.189381, acc: 97.66%] [G loss: 6.620212]\n",
      "epoch:45 step:35504 [D loss: 0.168438, acc: 97.66%] [G loss: 5.767326]\n",
      "epoch:45 step:35505 [D loss: 0.357658, acc: 90.62%] [G loss: 7.339060]\n",
      "epoch:45 step:35506 [D loss: 0.416963, acc: 76.56%] [G loss: 5.002684]\n",
      "epoch:45 step:35507 [D loss: 0.293584, acc: 92.19%] [G loss: 4.024708]\n",
      "epoch:45 step:35508 [D loss: 1.549243, acc: 48.44%] [G loss: 9.683276]\n",
      "epoch:45 step:35509 [D loss: 0.228928, acc: 94.53%] [G loss: 3.475852]\n",
      "epoch:45 step:35510 [D loss: 0.717719, acc: 55.47%] [G loss: 4.168050]\n",
      "epoch:45 step:35511 [D loss: 0.206503, acc: 92.97%] [G loss: 9.261282]\n",
      "epoch:45 step:35512 [D loss: 0.009697, acc: 100.00%] [G loss: 6.460046]\n",
      "epoch:45 step:35513 [D loss: 0.948839, acc: 34.38%] [G loss: 8.271500]\n",
      "epoch:45 step:35514 [D loss: 0.166281, acc: 98.44%] [G loss: 6.201259]\n",
      "epoch:45 step:35515 [D loss: 0.521699, acc: 72.66%] [G loss: 8.223684]\n",
      "epoch:45 step:35516 [D loss: 0.167168, acc: 98.44%] [G loss: 5.563996]\n",
      "epoch:45 step:35517 [D loss: 0.186820, acc: 95.31%] [G loss: 6.425198]\n",
      "epoch:45 step:35518 [D loss: 1.227015, acc: 45.31%] [G loss: 6.912888]\n",
      "epoch:45 step:35519 [D loss: 0.005570, acc: 100.00%] [G loss: 5.622255]\n",
      "epoch:45 step:35520 [D loss: 0.678261, acc: 57.81%] [G loss: 4.115770]\n",
      "epoch:45 step:35521 [D loss: 0.157225, acc: 98.44%] [G loss: 6.590830]\n",
      "epoch:45 step:35522 [D loss: 0.085875, acc: 100.00%] [G loss: 7.268171]\n",
      "epoch:45 step:35523 [D loss: 0.044031, acc: 100.00%] [G loss: 4.714499]\n",
      "epoch:45 step:35524 [D loss: 0.409686, acc: 75.78%] [G loss: 3.446723]\n",
      "epoch:45 step:35525 [D loss: 0.594805, acc: 65.62%] [G loss: 6.499774]\n",
      "epoch:45 step:35526 [D loss: 0.087800, acc: 99.22%] [G loss: 6.284003]\n",
      "epoch:45 step:35527 [D loss: 0.857974, acc: 53.91%] [G loss: 8.662935]\n",
      "epoch:45 step:35528 [D loss: 0.577437, acc: 57.81%] [G loss: 6.480911]\n",
      "epoch:45 step:35529 [D loss: 0.098396, acc: 99.22%] [G loss: 4.870233]\n",
      "epoch:45 step:35530 [D loss: 1.150531, acc: 50.00%] [G loss: 7.087903]\n",
      "epoch:45 step:35531 [D loss: 0.121923, acc: 100.00%] [G loss: 4.516760]\n",
      "epoch:45 step:35532 [D loss: 1.313964, acc: 50.00%] [G loss: 10.645820]\n",
      "epoch:45 step:35533 [D loss: 0.147438, acc: 100.00%] [G loss: 10.143217]\n",
      "epoch:45 step:35534 [D loss: 0.059515, acc: 100.00%] [G loss: 6.888626]\n",
      "epoch:45 step:35535 [D loss: 0.313352, acc: 82.81%] [G loss: 4.955054]\n",
      "epoch:45 step:35536 [D loss: 0.369435, acc: 78.91%] [G loss: 2.328803]\n",
      "epoch:45 step:35537 [D loss: 0.030418, acc: 100.00%] [G loss: 5.884531]\n",
      "epoch:45 step:35538 [D loss: 0.305348, acc: 89.84%] [G loss: 5.275257]\n",
      "epoch:45 step:35539 [D loss: 0.038281, acc: 100.00%] [G loss: 7.374657]\n",
      "epoch:45 step:35540 [D loss: 0.144771, acc: 99.22%] [G loss: 4.430937]\n",
      "epoch:45 step:35541 [D loss: 0.890813, acc: 47.66%] [G loss: 7.416785]\n",
      "epoch:45 step:35542 [D loss: 1.169906, acc: 50.78%] [G loss: 3.093664]\n",
      "epoch:45 step:35543 [D loss: 0.319312, acc: 92.97%] [G loss: 3.106826]\n",
      "epoch:45 step:35544 [D loss: 1.305946, acc: 28.91%] [G loss: 3.646454]\n",
      "epoch:45 step:35545 [D loss: 0.765758, acc: 53.91%] [G loss: 4.397202]\n",
      "epoch:45 step:35546 [D loss: 0.037556, acc: 100.00%] [G loss: 6.733738]\n",
      "epoch:45 step:35547 [D loss: 0.110822, acc: 100.00%] [G loss: 5.178105]\n",
      "epoch:45 step:35548 [D loss: 0.129082, acc: 98.44%] [G loss: 3.525069]\n",
      "epoch:45 step:35549 [D loss: 0.258311, acc: 89.06%] [G loss: 6.138350]\n",
      "epoch:45 step:35550 [D loss: 0.332354, acc: 88.28%] [G loss: 4.557535]\n",
      "epoch:45 step:35551 [D loss: 0.629991, acc: 62.50%] [G loss: 8.468974]\n",
      "epoch:45 step:35552 [D loss: 0.561042, acc: 60.94%] [G loss: 10.283563]\n",
      "epoch:45 step:35553 [D loss: 0.618914, acc: 57.81%] [G loss: 2.626902]\n",
      "epoch:45 step:35554 [D loss: 0.128934, acc: 99.22%] [G loss: 7.272339]\n",
      "epoch:45 step:35555 [D loss: 0.218342, acc: 99.22%] [G loss: 6.059144]\n",
      "epoch:45 step:35556 [D loss: 0.114432, acc: 98.44%] [G loss: 5.382261]\n",
      "epoch:45 step:35557 [D loss: 1.004771, acc: 28.12%] [G loss: 6.941310]\n",
      "epoch:45 step:35558 [D loss: 0.044090, acc: 100.00%] [G loss: 3.843677]\n",
      "epoch:45 step:35559 [D loss: 0.079380, acc: 100.00%] [G loss: 6.984211]\n",
      "epoch:45 step:35560 [D loss: 0.100517, acc: 100.00%] [G loss: 4.106441]\n",
      "epoch:45 step:35561 [D loss: 0.380015, acc: 89.84%] [G loss: 4.911644]\n",
      "epoch:45 step:35562 [D loss: 0.195522, acc: 95.31%] [G loss: 3.801204]\n",
      "epoch:45 step:35563 [D loss: 0.186667, acc: 96.09%] [G loss: 6.368382]\n",
      "epoch:45 step:35564 [D loss: 0.922349, acc: 46.09%] [G loss: 2.567526]\n",
      "epoch:45 step:35565 [D loss: 0.667471, acc: 53.12%] [G loss: 9.434935]\n",
      "epoch:45 step:35566 [D loss: 0.235082, acc: 92.19%] [G loss: 5.436073]\n",
      "epoch:45 step:35567 [D loss: 0.216458, acc: 96.09%] [G loss: 6.248899]\n",
      "epoch:45 step:35568 [D loss: 0.967733, acc: 50.78%] [G loss: 6.990987]\n",
      "epoch:45 step:35569 [D loss: 0.305176, acc: 82.81%] [G loss: 8.050239]\n",
      "epoch:45 step:35570 [D loss: 0.380736, acc: 90.62%] [G loss: 5.299901]\n",
      "epoch:45 step:35571 [D loss: 0.174369, acc: 96.88%] [G loss: 4.860334]\n",
      "epoch:45 step:35572 [D loss: 0.142601, acc: 100.00%] [G loss: 3.412336]\n",
      "epoch:45 step:35573 [D loss: 0.039235, acc: 99.22%] [G loss: 6.629265]\n",
      "epoch:45 step:35574 [D loss: 0.124698, acc: 100.00%] [G loss: 5.513942]\n",
      "epoch:45 step:35575 [D loss: 0.099931, acc: 100.00%] [G loss: 6.123141]\n",
      "epoch:45 step:35576 [D loss: 0.683073, acc: 58.59%] [G loss: 3.838545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35577 [D loss: 0.360537, acc: 78.12%] [G loss: 6.958591]\n",
      "epoch:45 step:35578 [D loss: 0.285373, acc: 89.06%] [G loss: 5.500154]\n",
      "epoch:45 step:35579 [D loss: 0.711096, acc: 52.34%] [G loss: 7.405426]\n",
      "epoch:45 step:35580 [D loss: 0.075151, acc: 100.00%] [G loss: 5.456386]\n",
      "epoch:45 step:35581 [D loss: 0.507765, acc: 79.69%] [G loss: 5.841392]\n",
      "epoch:45 step:35582 [D loss: 0.299343, acc: 89.06%] [G loss: 6.260610]\n",
      "epoch:45 step:35583 [D loss: 0.641829, acc: 58.59%] [G loss: 5.644673]\n",
      "epoch:45 step:35584 [D loss: 1.009881, acc: 39.06%] [G loss: 5.476564]\n",
      "epoch:45 step:35585 [D loss: 0.365541, acc: 84.38%] [G loss: 3.977786]\n",
      "epoch:45 step:35586 [D loss: 0.757165, acc: 54.69%] [G loss: 5.786135]\n",
      "epoch:45 step:35587 [D loss: 0.174829, acc: 97.66%] [G loss: 4.236532]\n",
      "epoch:45 step:35588 [D loss: 0.623764, acc: 60.94%] [G loss: 6.388371]\n",
      "epoch:45 step:35589 [D loss: 0.173366, acc: 99.22%] [G loss: 3.083435]\n",
      "epoch:45 step:35590 [D loss: 0.069867, acc: 100.00%] [G loss: 4.252105]\n",
      "epoch:45 step:35591 [D loss: 0.067898, acc: 100.00%] [G loss: 5.274043]\n",
      "epoch:45 step:35592 [D loss: 0.414796, acc: 81.25%] [G loss: 6.166173]\n",
      "epoch:45 step:35593 [D loss: 0.633028, acc: 65.62%] [G loss: 9.456333]\n",
      "epoch:45 step:35594 [D loss: 0.261010, acc: 92.97%] [G loss: 5.384348]\n",
      "epoch:45 step:35595 [D loss: 0.030442, acc: 100.00%] [G loss: 5.552741]\n",
      "epoch:45 step:35596 [D loss: 0.103642, acc: 99.22%] [G loss: 6.220340]\n",
      "epoch:45 step:35597 [D loss: 0.757269, acc: 54.69%] [G loss: 4.669277]\n",
      "epoch:45 step:35598 [D loss: 0.218172, acc: 95.31%] [G loss: 6.977651]\n",
      "epoch:45 step:35599 [D loss: 1.189442, acc: 50.00%] [G loss: 8.877151]\n",
      "epoch:45 step:35600 [D loss: 0.473826, acc: 79.69%] [G loss: 6.027183]\n",
      "epoch:45 step:35601 [D loss: 1.289747, acc: 51.56%] [G loss: 2.845058]\n",
      "epoch:45 step:35602 [D loss: 0.913859, acc: 45.31%] [G loss: 5.467581]\n",
      "epoch:45 step:35603 [D loss: 0.167879, acc: 98.44%] [G loss: 5.214315]\n",
      "epoch:45 step:35604 [D loss: 0.206311, acc: 98.44%] [G loss: 4.969137]\n",
      "epoch:45 step:35605 [D loss: 0.065019, acc: 98.44%] [G loss: 5.950911]\n",
      "epoch:45 step:35606 [D loss: 0.223287, acc: 92.97%] [G loss: 6.391958]\n",
      "epoch:45 step:35607 [D loss: 0.072158, acc: 100.00%] [G loss: 7.837662]\n",
      "epoch:45 step:35608 [D loss: 0.449403, acc: 72.66%] [G loss: 4.218863]\n",
      "epoch:45 step:35609 [D loss: 0.340840, acc: 94.53%] [G loss: 4.883799]\n",
      "epoch:45 step:35610 [D loss: 0.259738, acc: 95.31%] [G loss: 4.885056]\n",
      "epoch:45 step:35611 [D loss: 0.107204, acc: 100.00%] [G loss: 7.559498]\n",
      "epoch:45 step:35612 [D loss: 1.628024, acc: 50.00%] [G loss: 6.879180]\n",
      "epoch:45 step:35613 [D loss: 1.456721, acc: 50.00%] [G loss: 8.394917]\n",
      "epoch:45 step:35614 [D loss: 0.089864, acc: 100.00%] [G loss: 3.481534]\n",
      "epoch:45 step:35615 [D loss: 0.027586, acc: 100.00%] [G loss: 6.904765]\n",
      "epoch:45 step:35616 [D loss: 0.302569, acc: 81.25%] [G loss: 4.039647]\n",
      "epoch:45 step:35617 [D loss: 0.044158, acc: 100.00%] [G loss: 6.792070]\n",
      "epoch:45 step:35618 [D loss: 1.087768, acc: 48.44%] [G loss: 4.932765]\n",
      "epoch:45 step:35619 [D loss: 0.201384, acc: 96.88%] [G loss: 4.381658]\n",
      "epoch:45 step:35620 [D loss: 0.113603, acc: 98.44%] [G loss: 4.874732]\n",
      "epoch:45 step:35621 [D loss: 0.163536, acc: 100.00%] [G loss: 6.951478]\n",
      "epoch:45 step:35622 [D loss: 1.513471, acc: 8.59%] [G loss: 5.597451]\n",
      "epoch:45 step:35623 [D loss: 0.055648, acc: 100.00%] [G loss: 9.175563]\n",
      "epoch:45 step:35624 [D loss: 0.075829, acc: 100.00%] [G loss: 3.571965]\n",
      "epoch:45 step:35625 [D loss: 0.158030, acc: 97.66%] [G loss: 6.313190]\n",
      "epoch:45 step:35626 [D loss: 0.127611, acc: 100.00%] [G loss: 7.446172]\n",
      "epoch:45 step:35627 [D loss: 0.274434, acc: 92.19%] [G loss: 3.365007]\n",
      "epoch:45 step:35628 [D loss: 0.074519, acc: 100.00%] [G loss: 4.462515]\n",
      "epoch:45 step:35629 [D loss: 0.329084, acc: 82.81%] [G loss: 4.243454]\n",
      "epoch:45 step:35630 [D loss: 0.094614, acc: 100.00%] [G loss: 3.782012]\n",
      "epoch:45 step:35631 [D loss: 0.045422, acc: 100.00%] [G loss: 6.989830]\n",
      "epoch:45 step:35632 [D loss: 0.359562, acc: 95.31%] [G loss: 4.251394]\n",
      "epoch:45 step:35633 [D loss: 0.223050, acc: 95.31%] [G loss: 3.463276]\n",
      "epoch:45 step:35634 [D loss: 0.095689, acc: 99.22%] [G loss: 3.821825]\n",
      "epoch:45 step:35635 [D loss: 0.137494, acc: 99.22%] [G loss: 5.276485]\n",
      "epoch:45 step:35636 [D loss: 0.951617, acc: 51.56%] [G loss: 3.857948]\n",
      "epoch:45 step:35637 [D loss: 0.264506, acc: 87.50%] [G loss: 3.581469]\n",
      "epoch:45 step:35638 [D loss: 0.029440, acc: 100.00%] [G loss: 7.034459]\n",
      "epoch:45 step:35639 [D loss: 0.515607, acc: 78.91%] [G loss: 6.505883]\n",
      "epoch:45 step:35640 [D loss: 2.106221, acc: 19.53%] [G loss: 5.074454]\n",
      "epoch:45 step:35641 [D loss: 0.050198, acc: 100.00%] [G loss: 5.180434]\n",
      "epoch:45 step:35642 [D loss: 0.596714, acc: 60.16%] [G loss: 5.243270]\n",
      "epoch:45 step:35643 [D loss: 0.052987, acc: 100.00%] [G loss: 2.676364]\n",
      "epoch:45 step:35644 [D loss: 0.766417, acc: 50.78%] [G loss: 7.822809]\n",
      "epoch:45 step:35645 [D loss: 0.102175, acc: 100.00%] [G loss: 6.520138]\n",
      "epoch:45 step:35646 [D loss: 0.067516, acc: 100.00%] [G loss: 3.354974]\n",
      "epoch:45 step:35647 [D loss: 0.250802, acc: 97.66%] [G loss: 4.510156]\n",
      "epoch:45 step:35648 [D loss: 1.179248, acc: 49.22%] [G loss: 7.733366]\n",
      "epoch:45 step:35649 [D loss: 1.009749, acc: 50.78%] [G loss: 4.055539]\n",
      "epoch:45 step:35650 [D loss: 0.270423, acc: 94.53%] [G loss: 8.483278]\n",
      "epoch:45 step:35651 [D loss: 0.620023, acc: 61.72%] [G loss: 7.282830]\n",
      "epoch:45 step:35652 [D loss: 0.641436, acc: 62.50%] [G loss: 3.583652]\n",
      "epoch:45 step:35653 [D loss: 0.162818, acc: 99.22%] [G loss: 2.453084]\n",
      "epoch:45 step:35654 [D loss: 0.540529, acc: 68.75%] [G loss: 4.561042]\n",
      "epoch:45 step:35655 [D loss: 0.415110, acc: 71.09%] [G loss: 6.154418]\n",
      "epoch:45 step:35656 [D loss: 0.051224, acc: 100.00%] [G loss: 5.812984]\n",
      "epoch:45 step:35657 [D loss: 0.619090, acc: 58.59%] [G loss: 6.356072]\n",
      "epoch:45 step:35658 [D loss: 0.147267, acc: 96.88%] [G loss: 7.904616]\n",
      "epoch:45 step:35659 [D loss: 0.688028, acc: 59.38%] [G loss: 7.167351]\n",
      "epoch:45 step:35660 [D loss: 0.491560, acc: 68.75%] [G loss: 7.187295]\n",
      "epoch:45 step:35661 [D loss: 0.189034, acc: 97.66%] [G loss: 4.932771]\n",
      "epoch:45 step:35662 [D loss: 0.076076, acc: 100.00%] [G loss: 4.777563]\n",
      "epoch:45 step:35663 [D loss: 0.365366, acc: 84.38%] [G loss: 7.301812]\n",
      "epoch:45 step:35664 [D loss: 0.026228, acc: 100.00%] [G loss: 5.914282]\n",
      "epoch:45 step:35665 [D loss: 0.217690, acc: 92.97%] [G loss: 7.732349]\n",
      "epoch:45 step:35666 [D loss: 0.873367, acc: 36.72%] [G loss: 6.997603]\n",
      "epoch:45 step:35667 [D loss: 0.274111, acc: 96.09%] [G loss: 5.776714]\n",
      "epoch:45 step:35668 [D loss: 0.159280, acc: 99.22%] [G loss: 4.726925]\n",
      "epoch:45 step:35669 [D loss: 0.107279, acc: 99.22%] [G loss: 5.413315]\n",
      "epoch:45 step:35670 [D loss: 0.817883, acc: 52.34%] [G loss: 4.448483]\n",
      "epoch:45 step:35671 [D loss: 0.318240, acc: 80.47%] [G loss: 6.969243]\n",
      "epoch:45 step:35672 [D loss: 0.157410, acc: 99.22%] [G loss: 5.088440]\n",
      "epoch:45 step:35673 [D loss: 0.015697, acc: 100.00%] [G loss: 5.810892]\n",
      "epoch:45 step:35674 [D loss: 0.117261, acc: 99.22%] [G loss: 8.046527]\n",
      "epoch:45 step:35675 [D loss: 0.523449, acc: 62.50%] [G loss: 4.560394]\n",
      "epoch:45 step:35676 [D loss: 0.024647, acc: 100.00%] [G loss: 9.785938]\n",
      "epoch:45 step:35677 [D loss: 0.662572, acc: 55.47%] [G loss: 6.939688]\n",
      "epoch:45 step:35678 [D loss: 0.236603, acc: 95.31%] [G loss: 2.499055]\n",
      "epoch:45 step:35679 [D loss: 0.330434, acc: 85.16%] [G loss: 4.028907]\n",
      "epoch:45 step:35680 [D loss: 0.517442, acc: 75.78%] [G loss: 9.168266]\n",
      "epoch:45 step:35681 [D loss: 0.523957, acc: 66.41%] [G loss: 5.540814]\n",
      "epoch:45 step:35682 [D loss: 0.021642, acc: 100.00%] [G loss: 7.100280]\n",
      "epoch:45 step:35683 [D loss: 0.905332, acc: 49.22%] [G loss: 7.164817]\n",
      "epoch:45 step:35684 [D loss: 0.177825, acc: 99.22%] [G loss: 4.627320]\n",
      "epoch:45 step:35685 [D loss: 0.631157, acc: 57.03%] [G loss: 7.537815]\n",
      "epoch:45 step:35686 [D loss: 0.397098, acc: 82.81%] [G loss: 5.616479]\n",
      "epoch:45 step:35687 [D loss: 0.009701, acc: 100.00%] [G loss: 6.023211]\n",
      "epoch:45 step:35688 [D loss: 0.174176, acc: 96.88%] [G loss: 7.370049]\n",
      "epoch:45 step:35689 [D loss: 0.671698, acc: 56.25%] [G loss: 6.599761]\n",
      "epoch:45 step:35690 [D loss: 0.213728, acc: 99.22%] [G loss: 6.439155]\n",
      "epoch:45 step:35691 [D loss: 1.433788, acc: 14.84%] [G loss: 4.780753]\n",
      "epoch:45 step:35692 [D loss: 0.060678, acc: 100.00%] [G loss: 8.164404]\n",
      "epoch:45 step:35693 [D loss: 2.270953, acc: 50.00%] [G loss: 1.541074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35694 [D loss: 0.173410, acc: 95.31%] [G loss: 5.228112]\n",
      "epoch:45 step:35695 [D loss: 0.874053, acc: 51.56%] [G loss: 5.017334]\n",
      "epoch:45 step:35696 [D loss: 0.134798, acc: 97.66%] [G loss: 6.592843]\n",
      "epoch:45 step:35697 [D loss: 0.294878, acc: 88.28%] [G loss: 3.169882]\n",
      "epoch:45 step:35698 [D loss: 0.199633, acc: 95.31%] [G loss: 2.767118]\n",
      "epoch:45 step:35699 [D loss: 0.114110, acc: 100.00%] [G loss: 5.007520]\n",
      "epoch:45 step:35700 [D loss: 0.214746, acc: 96.88%] [G loss: 5.903648]\n",
      "epoch:45 step:35701 [D loss: 1.013199, acc: 51.56%] [G loss: 8.979977]\n",
      "epoch:45 step:35702 [D loss: 0.043131, acc: 100.00%] [G loss: 6.632281]\n",
      "epoch:45 step:35703 [D loss: 0.487099, acc: 79.69%] [G loss: 4.164006]\n",
      "epoch:45 step:35704 [D loss: 0.095055, acc: 99.22%] [G loss: 3.368943]\n",
      "epoch:45 step:35705 [D loss: 0.199946, acc: 96.09%] [G loss: 7.022182]\n",
      "epoch:45 step:35706 [D loss: 0.018110, acc: 100.00%] [G loss: 5.668288]\n",
      "epoch:45 step:35707 [D loss: 0.194879, acc: 94.53%] [G loss: 3.984208]\n",
      "epoch:45 step:35708 [D loss: 0.174828, acc: 99.22%] [G loss: 7.435855]\n",
      "epoch:45 step:35709 [D loss: 0.363340, acc: 73.44%] [G loss: 4.722644]\n",
      "epoch:45 step:35710 [D loss: 0.081602, acc: 100.00%] [G loss: 2.513312]\n",
      "epoch:45 step:35711 [D loss: 0.268228, acc: 95.31%] [G loss: 7.728282]\n",
      "epoch:45 step:35712 [D loss: 0.315469, acc: 92.19%] [G loss: 4.348140]\n",
      "epoch:45 step:35713 [D loss: 0.173096, acc: 99.22%] [G loss: 5.675513]\n",
      "epoch:45 step:35714 [D loss: 0.142782, acc: 99.22%] [G loss: 5.921257]\n",
      "epoch:45 step:35715 [D loss: 0.022194, acc: 100.00%] [G loss: 6.925827]\n",
      "epoch:45 step:35716 [D loss: 1.578290, acc: 40.62%] [G loss: 2.258037]\n",
      "epoch:45 step:35717 [D loss: 0.101630, acc: 100.00%] [G loss: 3.907394]\n",
      "epoch:45 step:35718 [D loss: 0.231264, acc: 96.09%] [G loss: 5.399577]\n",
      "epoch:45 step:35719 [D loss: 1.586308, acc: 23.44%] [G loss: 6.966253]\n",
      "epoch:45 step:35720 [D loss: 1.834235, acc: 49.22%] [G loss: 4.782094]\n",
      "epoch:45 step:35721 [D loss: 0.324058, acc: 87.50%] [G loss: 4.985604]\n",
      "epoch:45 step:35722 [D loss: 0.719770, acc: 53.12%] [G loss: 5.917527]\n",
      "epoch:45 step:35723 [D loss: 0.160994, acc: 96.88%] [G loss: 6.636960]\n",
      "epoch:45 step:35724 [D loss: 0.280705, acc: 90.62%] [G loss: 4.708154]\n",
      "epoch:45 step:35725 [D loss: 0.716608, acc: 53.12%] [G loss: 6.049513]\n",
      "epoch:45 step:35726 [D loss: 0.207004, acc: 99.22%] [G loss: 6.066475]\n",
      "epoch:45 step:35727 [D loss: 0.260023, acc: 95.31%] [G loss: 6.222843]\n",
      "epoch:45 step:35728 [D loss: 0.042407, acc: 100.00%] [G loss: 4.200808]\n",
      "epoch:45 step:35729 [D loss: 1.083720, acc: 38.28%] [G loss: 5.197298]\n",
      "epoch:45 step:35730 [D loss: 0.029107, acc: 100.00%] [G loss: 6.755324]\n",
      "epoch:45 step:35731 [D loss: 0.260881, acc: 94.53%] [G loss: 7.286726]\n",
      "epoch:45 step:35732 [D loss: 0.239774, acc: 91.41%] [G loss: 3.669504]\n",
      "epoch:45 step:35733 [D loss: 0.226029, acc: 98.44%] [G loss: 8.870258]\n",
      "epoch:45 step:35734 [D loss: 0.342008, acc: 84.38%] [G loss: 6.483970]\n",
      "epoch:45 step:35735 [D loss: 0.569303, acc: 71.88%] [G loss: 4.585441]\n",
      "epoch:45 step:35736 [D loss: 0.381330, acc: 88.28%] [G loss: 5.109444]\n",
      "epoch:45 step:35737 [D loss: 0.194847, acc: 96.09%] [G loss: 5.421134]\n",
      "epoch:45 step:35738 [D loss: 0.085336, acc: 100.00%] [G loss: 6.155153]\n",
      "epoch:45 step:35739 [D loss: 0.348860, acc: 84.38%] [G loss: 6.880302]\n",
      "epoch:45 step:35740 [D loss: 0.278318, acc: 92.97%] [G loss: 6.084914]\n",
      "epoch:45 step:35741 [D loss: 0.280531, acc: 98.44%] [G loss: 4.370883]\n",
      "epoch:45 step:35742 [D loss: 0.283119, acc: 91.41%] [G loss: 5.001956]\n",
      "epoch:45 step:35743 [D loss: 0.290013, acc: 90.62%] [G loss: 5.044783]\n",
      "epoch:45 step:35744 [D loss: 0.890662, acc: 36.72%] [G loss: 4.339794]\n",
      "epoch:45 step:35745 [D loss: 0.467296, acc: 78.91%] [G loss: 5.784530]\n",
      "epoch:45 step:35746 [D loss: 0.086383, acc: 99.22%] [G loss: 4.524194]\n",
      "epoch:45 step:35747 [D loss: 0.051524, acc: 100.00%] [G loss: 3.984493]\n",
      "epoch:45 step:35748 [D loss: 0.162725, acc: 98.44%] [G loss: 4.758678]\n",
      "epoch:45 step:35749 [D loss: 0.941535, acc: 30.47%] [G loss: 6.219349]\n",
      "epoch:45 step:35750 [D loss: 0.597411, acc: 59.38%] [G loss: 3.774208]\n",
      "epoch:45 step:35751 [D loss: 0.076158, acc: 100.00%] [G loss: 6.045151]\n",
      "epoch:45 step:35752 [D loss: 0.062195, acc: 100.00%] [G loss: 5.763282]\n",
      "epoch:45 step:35753 [D loss: 0.476916, acc: 64.84%] [G loss: 4.451205]\n",
      "epoch:45 step:35754 [D loss: 0.108538, acc: 99.22%] [G loss: 2.891570]\n",
      "epoch:45 step:35755 [D loss: 0.898203, acc: 38.28%] [G loss: 6.677061]\n",
      "epoch:45 step:35756 [D loss: 0.063392, acc: 100.00%] [G loss: 3.228630]\n",
      "epoch:45 step:35757 [D loss: 0.319935, acc: 94.53%] [G loss: 4.588141]\n",
      "epoch:45 step:35758 [D loss: 0.039083, acc: 100.00%] [G loss: 3.830288]\n",
      "epoch:45 step:35759 [D loss: 0.138932, acc: 99.22%] [G loss: 5.970687]\n",
      "epoch:45 step:35760 [D loss: 0.373704, acc: 78.91%] [G loss: 6.315226]\n",
      "epoch:45 step:35761 [D loss: 0.108963, acc: 100.00%] [G loss: 6.035743]\n",
      "epoch:45 step:35762 [D loss: 0.324703, acc: 87.50%] [G loss: 6.433492]\n",
      "epoch:45 step:35763 [D loss: 0.079380, acc: 99.22%] [G loss: 8.117840]\n",
      "epoch:45 step:35764 [D loss: 0.515594, acc: 71.09%] [G loss: 5.330722]\n",
      "epoch:45 step:35765 [D loss: 0.307681, acc: 88.28%] [G loss: 5.017811]\n",
      "epoch:45 step:35766 [D loss: 1.507384, acc: 50.00%] [G loss: 5.851110]\n",
      "epoch:45 step:35767 [D loss: 0.095635, acc: 99.22%] [G loss: 5.700357]\n",
      "epoch:45 step:35768 [D loss: 0.361417, acc: 85.16%] [G loss: 4.846169]\n",
      "epoch:45 step:35769 [D loss: 0.588884, acc: 54.69%] [G loss: 7.824301]\n",
      "epoch:45 step:35770 [D loss: 0.098721, acc: 100.00%] [G loss: 7.821707]\n",
      "epoch:45 step:35771 [D loss: 0.098822, acc: 97.66%] [G loss: 2.653095]\n",
      "epoch:45 step:35772 [D loss: 0.036941, acc: 100.00%] [G loss: 5.810163]\n",
      "epoch:45 step:35773 [D loss: 0.141745, acc: 99.22%] [G loss: 6.604350]\n",
      "epoch:45 step:35774 [D loss: 0.162016, acc: 99.22%] [G loss: 5.715240]\n",
      "epoch:45 step:35775 [D loss: 0.069847, acc: 100.00%] [G loss: 3.590808]\n",
      "epoch:45 step:35776 [D loss: 0.061993, acc: 99.22%] [G loss: 4.661736]\n",
      "epoch:45 step:35777 [D loss: 0.101381, acc: 100.00%] [G loss: 4.548796]\n",
      "epoch:45 step:35778 [D loss: 0.150005, acc: 99.22%] [G loss: 5.550904]\n",
      "epoch:45 step:35779 [D loss: 1.901936, acc: 25.00%] [G loss: 4.896534]\n",
      "epoch:45 step:35780 [D loss: 1.186087, acc: 50.00%] [G loss: 4.956791]\n",
      "epoch:45 step:35781 [D loss: 0.793770, acc: 46.09%] [G loss: 6.066027]\n",
      "epoch:45 step:35782 [D loss: 0.485231, acc: 73.44%] [G loss: 4.527052]\n",
      "epoch:45 step:35783 [D loss: 0.217821, acc: 94.53%] [G loss: 5.823084]\n",
      "epoch:45 step:35784 [D loss: 0.761169, acc: 57.03%] [G loss: 3.567472]\n",
      "epoch:45 step:35785 [D loss: 0.615950, acc: 60.16%] [G loss: 1.866455]\n",
      "epoch:45 step:35786 [D loss: 0.135120, acc: 97.66%] [G loss: 6.115249]\n",
      "epoch:45 step:35787 [D loss: 0.085018, acc: 100.00%] [G loss: 4.925453]\n",
      "epoch:45 step:35788 [D loss: 0.882548, acc: 48.44%] [G loss: 4.917809]\n",
      "epoch:45 step:35789 [D loss: 0.124887, acc: 97.66%] [G loss: 4.089121]\n",
      "epoch:45 step:35790 [D loss: 0.125892, acc: 100.00%] [G loss: 3.964876]\n",
      "epoch:45 step:35791 [D loss: 0.626649, acc: 60.16%] [G loss: 4.356294]\n",
      "epoch:45 step:35792 [D loss: 0.504736, acc: 69.53%] [G loss: 4.895363]\n",
      "epoch:45 step:35793 [D loss: 0.060398, acc: 100.00%] [G loss: 4.555727]\n",
      "epoch:45 step:35794 [D loss: 0.137392, acc: 99.22%] [G loss: 5.507526]\n",
      "epoch:45 step:35795 [D loss: 0.216804, acc: 93.75%] [G loss: 9.396717]\n",
      "epoch:45 step:35796 [D loss: 0.912971, acc: 50.78%] [G loss: 6.011976]\n",
      "epoch:45 step:35797 [D loss: 0.213845, acc: 93.75%] [G loss: 6.386915]\n",
      "epoch:45 step:35798 [D loss: 0.106871, acc: 99.22%] [G loss: 2.095824]\n",
      "epoch:45 step:35799 [D loss: 0.157717, acc: 96.09%] [G loss: 9.426020]\n",
      "epoch:45 step:35800 [D loss: 0.433440, acc: 71.09%] [G loss: 7.646562]\n",
      "epoch:45 step:35801 [D loss: 0.661889, acc: 60.16%] [G loss: 5.404508]\n",
      "epoch:45 step:35802 [D loss: 0.563532, acc: 66.41%] [G loss: 6.843757]\n",
      "epoch:45 step:35803 [D loss: 0.112470, acc: 99.22%] [G loss: 4.332967]\n",
      "epoch:45 step:35804 [D loss: 0.503621, acc: 73.44%] [G loss: 6.199659]\n",
      "epoch:45 step:35805 [D loss: 1.504697, acc: 11.72%] [G loss: 3.905188]\n",
      "epoch:45 step:35806 [D loss: 0.239546, acc: 94.53%] [G loss: 6.721692]\n",
      "epoch:45 step:35807 [D loss: 0.454645, acc: 65.62%] [G loss: 8.522320]\n",
      "epoch:45 step:35808 [D loss: 0.208579, acc: 94.53%] [G loss: 5.657230]\n",
      "epoch:45 step:35809 [D loss: 0.130671, acc: 99.22%] [G loss: 4.694215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35810 [D loss: 0.305700, acc: 86.72%] [G loss: 3.201818]\n",
      "epoch:45 step:35811 [D loss: 0.942620, acc: 39.06%] [G loss: 4.714013]\n",
      "epoch:45 step:35812 [D loss: 0.088340, acc: 99.22%] [G loss: 6.470772]\n",
      "epoch:45 step:35813 [D loss: 0.045614, acc: 100.00%] [G loss: 6.626264]\n",
      "epoch:45 step:35814 [D loss: 0.159892, acc: 100.00%] [G loss: 3.975879]\n",
      "epoch:45 step:35815 [D loss: 0.329441, acc: 81.25%] [G loss: 5.003848]\n",
      "epoch:45 step:35816 [D loss: 0.450354, acc: 85.94%] [G loss: 7.283055]\n",
      "epoch:45 step:35817 [D loss: 0.397720, acc: 82.81%] [G loss: 6.409094]\n",
      "epoch:45 step:35818 [D loss: 0.217812, acc: 94.53%] [G loss: 5.068257]\n",
      "epoch:45 step:35819 [D loss: 0.170442, acc: 98.44%] [G loss: 2.901383]\n",
      "epoch:45 step:35820 [D loss: 0.312666, acc: 92.97%] [G loss: 9.538797]\n",
      "epoch:45 step:35821 [D loss: 0.030180, acc: 100.00%] [G loss: 7.195006]\n",
      "epoch:45 step:35822 [D loss: 0.082499, acc: 100.00%] [G loss: 5.277951]\n",
      "epoch:45 step:35823 [D loss: 0.482596, acc: 66.41%] [G loss: 9.696690]\n",
      "epoch:45 step:35824 [D loss: 0.046490, acc: 99.22%] [G loss: 6.534052]\n",
      "epoch:45 step:35825 [D loss: 0.332003, acc: 85.94%] [G loss: 3.643715]\n",
      "epoch:45 step:35826 [D loss: 0.142011, acc: 97.66%] [G loss: 2.573571]\n",
      "epoch:45 step:35827 [D loss: 0.302639, acc: 94.53%] [G loss: 5.766924]\n",
      "epoch:45 step:35828 [D loss: 1.187827, acc: 46.09%] [G loss: 7.242368]\n",
      "epoch:45 step:35829 [D loss: 1.419212, acc: 50.00%] [G loss: 4.574354]\n",
      "epoch:45 step:35830 [D loss: 0.696686, acc: 53.12%] [G loss: 8.850130]\n",
      "epoch:45 step:35831 [D loss: 1.445795, acc: 50.00%] [G loss: 7.317086]\n",
      "epoch:45 step:35832 [D loss: 0.241088, acc: 95.31%] [G loss: 4.358175]\n",
      "epoch:45 step:35833 [D loss: 0.279021, acc: 89.06%] [G loss: 5.950453]\n",
      "epoch:45 step:35834 [D loss: 0.064088, acc: 100.00%] [G loss: 6.641531]\n",
      "epoch:45 step:35835 [D loss: 0.481520, acc: 63.28%] [G loss: 3.289830]\n",
      "epoch:45 step:35836 [D loss: 0.143615, acc: 99.22%] [G loss: 4.480639]\n",
      "epoch:45 step:35837 [D loss: 0.003294, acc: 100.00%] [G loss: 6.177762]\n",
      "epoch:45 step:35838 [D loss: 0.927342, acc: 32.03%] [G loss: 6.879896]\n",
      "epoch:45 step:35839 [D loss: 0.110451, acc: 99.22%] [G loss: 6.212533]\n",
      "epoch:45 step:35840 [D loss: 0.182331, acc: 98.44%] [G loss: 5.796349]\n",
      "epoch:45 step:35841 [D loss: 0.126174, acc: 99.22%] [G loss: 5.945828]\n",
      "epoch:45 step:35842 [D loss: 0.288246, acc: 85.16%] [G loss: 5.870296]\n",
      "epoch:45 step:35843 [D loss: 0.119931, acc: 100.00%] [G loss: 4.782199]\n",
      "epoch:45 step:35844 [D loss: 0.106866, acc: 100.00%] [G loss: 3.880241]\n",
      "epoch:45 step:35845 [D loss: 0.423119, acc: 75.78%] [G loss: 4.920577]\n",
      "epoch:45 step:35846 [D loss: 0.120016, acc: 100.00%] [G loss: 4.723064]\n",
      "epoch:45 step:35847 [D loss: 1.958442, acc: 7.81%] [G loss: 6.944640]\n",
      "epoch:45 step:35848 [D loss: 0.809325, acc: 44.53%] [G loss: 6.018836]\n",
      "epoch:45 step:35849 [D loss: 0.158018, acc: 99.22%] [G loss: 6.494730]\n",
      "epoch:45 step:35850 [D loss: 0.100510, acc: 99.22%] [G loss: 7.934121]\n",
      "epoch:45 step:35851 [D loss: 0.119547, acc: 98.44%] [G loss: 6.560901]\n",
      "epoch:45 step:35852 [D loss: 0.114964, acc: 100.00%] [G loss: 5.854674]\n",
      "epoch:45 step:35853 [D loss: 0.047680, acc: 100.00%] [G loss: 2.420094]\n",
      "epoch:45 step:35854 [D loss: 0.832233, acc: 40.62%] [G loss: 7.156470]\n",
      "epoch:45 step:35855 [D loss: 0.910622, acc: 44.53%] [G loss: 6.315021]\n",
      "epoch:45 step:35856 [D loss: 0.104877, acc: 100.00%] [G loss: 9.505172]\n",
      "epoch:45 step:35857 [D loss: 0.051711, acc: 100.00%] [G loss: 3.727813]\n",
      "epoch:45 step:35858 [D loss: 0.009054, acc: 100.00%] [G loss: 9.776663]\n",
      "epoch:45 step:35859 [D loss: 0.075507, acc: 100.00%] [G loss: 8.541118]\n",
      "epoch:45 step:35860 [D loss: 0.393228, acc: 90.62%] [G loss: 6.084147]\n",
      "epoch:45 step:35861 [D loss: 0.217033, acc: 96.09%] [G loss: 9.379076]\n",
      "epoch:45 step:35862 [D loss: 0.124935, acc: 98.44%] [G loss: 11.152460]\n",
      "epoch:45 step:35863 [D loss: 0.614365, acc: 65.62%] [G loss: 6.611103]\n",
      "epoch:45 step:35864 [D loss: 0.351728, acc: 82.81%] [G loss: 7.020042]\n",
      "epoch:45 step:35865 [D loss: 0.352906, acc: 82.03%] [G loss: 3.524871]\n",
      "epoch:45 step:35866 [D loss: 1.617774, acc: 22.66%] [G loss: 5.233521]\n",
      "epoch:45 step:35867 [D loss: 0.033449, acc: 100.00%] [G loss: 5.399038]\n",
      "epoch:45 step:35868 [D loss: 0.252130, acc: 90.62%] [G loss: 8.060861]\n",
      "epoch:45 step:35869 [D loss: 0.291385, acc: 93.75%] [G loss: 5.171776]\n",
      "epoch:45 step:35870 [D loss: 0.025503, acc: 100.00%] [G loss: 6.164545]\n",
      "epoch:45 step:35871 [D loss: 0.390575, acc: 81.25%] [G loss: 3.081059]\n",
      "epoch:45 step:35872 [D loss: 0.573804, acc: 60.16%] [G loss: 8.110831]\n",
      "epoch:45 step:35873 [D loss: 0.779728, acc: 57.03%] [G loss: 6.660614]\n",
      "epoch:45 step:35874 [D loss: 0.207066, acc: 96.88%] [G loss: 7.265834]\n",
      "epoch:45 step:35875 [D loss: 0.513106, acc: 58.59%] [G loss: 5.961408]\n",
      "epoch:45 step:35876 [D loss: 0.219508, acc: 95.31%] [G loss: 4.059628]\n",
      "epoch:45 step:35877 [D loss: 1.034134, acc: 24.22%] [G loss: 6.051755]\n",
      "epoch:45 step:35878 [D loss: 0.161470, acc: 98.44%] [G loss: 6.891468]\n",
      "epoch:45 step:35879 [D loss: 1.218660, acc: 46.88%] [G loss: 5.956837]\n",
      "epoch:45 step:35880 [D loss: 0.332485, acc: 86.72%] [G loss: 7.513307]\n",
      "epoch:45 step:35881 [D loss: 0.429939, acc: 70.31%] [G loss: 4.671522]\n",
      "epoch:45 step:35882 [D loss: 0.252555, acc: 89.84%] [G loss: 6.054740]\n",
      "epoch:45 step:35883 [D loss: 0.275193, acc: 94.53%] [G loss: 3.571908]\n",
      "epoch:45 step:35884 [D loss: 0.208320, acc: 97.66%] [G loss: 4.596805]\n",
      "epoch:45 step:35885 [D loss: 0.415783, acc: 87.50%] [G loss: 5.198232]\n",
      "epoch:45 step:35886 [D loss: 0.127517, acc: 99.22%] [G loss: 5.758812]\n",
      "epoch:45 step:35887 [D loss: 0.364031, acc: 86.72%] [G loss: 5.147609]\n",
      "epoch:45 step:35888 [D loss: 0.078895, acc: 100.00%] [G loss: 2.632459]\n",
      "epoch:45 step:35889 [D loss: 0.124232, acc: 99.22%] [G loss: 5.866010]\n",
      "epoch:45 step:35890 [D loss: 0.105051, acc: 100.00%] [G loss: 3.766651]\n",
      "epoch:45 step:35891 [D loss: 0.399747, acc: 72.66%] [G loss: 5.147270]\n",
      "epoch:45 step:35892 [D loss: 0.174799, acc: 97.66%] [G loss: 6.632567]\n",
      "epoch:45 step:35893 [D loss: 0.098804, acc: 100.00%] [G loss: 6.001379]\n",
      "epoch:45 step:35894 [D loss: 0.037009, acc: 100.00%] [G loss: 4.392232]\n",
      "epoch:45 step:35895 [D loss: 0.094417, acc: 98.44%] [G loss: 7.028089]\n",
      "epoch:45 step:35896 [D loss: 0.732198, acc: 55.47%] [G loss: 5.017604]\n",
      "epoch:45 step:35897 [D loss: 0.035585, acc: 100.00%] [G loss: 6.620825]\n",
      "epoch:45 step:35898 [D loss: 0.333726, acc: 92.19%] [G loss: 5.830758]\n",
      "epoch:45 step:35899 [D loss: 0.061539, acc: 100.00%] [G loss: 5.416020]\n",
      "epoch:45 step:35900 [D loss: 0.184869, acc: 96.09%] [G loss: 2.410076]\n",
      "epoch:45 step:35901 [D loss: 0.164650, acc: 97.66%] [G loss: 5.166166]\n",
      "epoch:45 step:35902 [D loss: 0.135568, acc: 100.00%] [G loss: 4.867102]\n",
      "epoch:45 step:35903 [D loss: 0.127575, acc: 100.00%] [G loss: 4.584279]\n",
      "epoch:45 step:35904 [D loss: 0.119905, acc: 100.00%] [G loss: 5.288346]\n",
      "epoch:45 step:35905 [D loss: 0.016812, acc: 100.00%] [G loss: 7.063926]\n",
      "epoch:45 step:35906 [D loss: 0.056620, acc: 100.00%] [G loss: 4.679657]\n",
      "epoch:45 step:35907 [D loss: 0.080345, acc: 100.00%] [G loss: 5.622501]\n",
      "epoch:45 step:35908 [D loss: 0.295638, acc: 92.97%] [G loss: 4.835420]\n",
      "epoch:45 step:35909 [D loss: 0.706324, acc: 56.25%] [G loss: 3.540707]\n",
      "epoch:45 step:35910 [D loss: 0.072309, acc: 100.00%] [G loss: 3.515333]\n",
      "epoch:45 step:35911 [D loss: 0.398237, acc: 79.69%] [G loss: 5.670237]\n",
      "epoch:45 step:35912 [D loss: 0.046424, acc: 100.00%] [G loss: 8.453442]\n",
      "epoch:45 step:35913 [D loss: 0.528808, acc: 62.50%] [G loss: 6.475694]\n",
      "epoch:45 step:35914 [D loss: 0.118746, acc: 100.00%] [G loss: 6.368406]\n",
      "epoch:45 step:35915 [D loss: 0.440105, acc: 79.69%] [G loss: 5.326876]\n",
      "epoch:45 step:35916 [D loss: 0.610571, acc: 67.19%] [G loss: 5.080846]\n",
      "epoch:45 step:35917 [D loss: 0.215845, acc: 93.75%] [G loss: 4.006861]\n",
      "epoch:45 step:35918 [D loss: 0.146885, acc: 98.44%] [G loss: 7.871964]\n",
      "epoch:45 step:35919 [D loss: 0.169879, acc: 99.22%] [G loss: 5.727982]\n",
      "epoch:45 step:35920 [D loss: 0.152223, acc: 99.22%] [G loss: 4.498306]\n",
      "epoch:45 step:35921 [D loss: 0.411045, acc: 73.44%] [G loss: 7.462831]\n",
      "epoch:45 step:35922 [D loss: 0.463150, acc: 82.03%] [G loss: 5.672391]\n",
      "epoch:45 step:35923 [D loss: 1.040367, acc: 47.66%] [G loss: 4.189175]\n",
      "epoch:45 step:35924 [D loss: 0.174950, acc: 96.88%] [G loss: 4.314316]\n",
      "epoch:45 step:35925 [D loss: 0.822811, acc: 51.56%] [G loss: 6.391252]\n",
      "epoch:45 step:35926 [D loss: 0.401981, acc: 75.00%] [G loss: 6.607572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:35927 [D loss: 0.966683, acc: 41.41%] [G loss: 4.505232]\n",
      "epoch:46 step:35928 [D loss: 0.342433, acc: 76.56%] [G loss: 7.372785]\n",
      "epoch:46 step:35929 [D loss: 0.605839, acc: 64.06%] [G loss: 3.928843]\n",
      "epoch:46 step:35930 [D loss: 0.211431, acc: 96.88%] [G loss: 3.309919]\n",
      "epoch:46 step:35931 [D loss: 0.395669, acc: 83.59%] [G loss: 4.215948]\n",
      "epoch:46 step:35932 [D loss: 0.320251, acc: 89.06%] [G loss: 5.383035]\n",
      "epoch:46 step:35933 [D loss: 0.227428, acc: 98.44%] [G loss: 6.987210]\n",
      "epoch:46 step:35934 [D loss: 0.132605, acc: 100.00%] [G loss: 3.025202]\n",
      "epoch:46 step:35935 [D loss: 0.098535, acc: 100.00%] [G loss: 7.891458]\n",
      "epoch:46 step:35936 [D loss: 0.150035, acc: 99.22%] [G loss: 10.612243]\n",
      "epoch:46 step:35937 [D loss: 0.380456, acc: 80.47%] [G loss: 5.523835]\n",
      "epoch:46 step:35938 [D loss: 0.070893, acc: 100.00%] [G loss: 4.358418]\n",
      "epoch:46 step:35939 [D loss: 0.648511, acc: 54.69%] [G loss: 7.050767]\n",
      "epoch:46 step:35940 [D loss: 0.223528, acc: 95.31%] [G loss: 5.657559]\n",
      "epoch:46 step:35941 [D loss: 0.813466, acc: 54.69%] [G loss: 2.477839]\n",
      "epoch:46 step:35942 [D loss: 0.197167, acc: 96.88%] [G loss: 3.557911]\n",
      "epoch:46 step:35943 [D loss: 0.778755, acc: 53.12%] [G loss: 7.374655]\n",
      "epoch:46 step:35944 [D loss: 0.936591, acc: 39.06%] [G loss: 5.672392]\n",
      "epoch:46 step:35945 [D loss: 0.251230, acc: 89.84%] [G loss: 4.216959]\n",
      "epoch:46 step:35946 [D loss: 0.062895, acc: 100.00%] [G loss: 2.360960]\n",
      "epoch:46 step:35947 [D loss: 0.480441, acc: 70.31%] [G loss: 7.235552]\n",
      "epoch:46 step:35948 [D loss: 0.189293, acc: 97.66%] [G loss: 1.785781]\n",
      "epoch:46 step:35949 [D loss: 0.769900, acc: 53.12%] [G loss: 4.468877]\n",
      "epoch:46 step:35950 [D loss: 0.337300, acc: 84.38%] [G loss: 2.966862]\n",
      "epoch:46 step:35951 [D loss: 0.146352, acc: 97.66%] [G loss: 6.480830]\n",
      "epoch:46 step:35952 [D loss: 1.235650, acc: 46.88%] [G loss: 5.606442]\n",
      "epoch:46 step:35953 [D loss: 0.054023, acc: 99.22%] [G loss: 8.436839]\n",
      "epoch:46 step:35954 [D loss: 0.224359, acc: 95.31%] [G loss: 2.608746]\n",
      "epoch:46 step:35955 [D loss: 0.046581, acc: 100.00%] [G loss: 3.812332]\n",
      "epoch:46 step:35956 [D loss: 0.053506, acc: 100.00%] [G loss: 5.662210]\n",
      "epoch:46 step:35957 [D loss: 0.043741, acc: 100.00%] [G loss: 7.063102]\n",
      "epoch:46 step:35958 [D loss: 0.649691, acc: 57.81%] [G loss: 4.515967]\n",
      "epoch:46 step:35959 [D loss: 0.176030, acc: 97.66%] [G loss: 3.217239]\n",
      "epoch:46 step:35960 [D loss: 0.482754, acc: 75.00%] [G loss: 6.918391]\n",
      "epoch:46 step:35961 [D loss: 0.800577, acc: 57.03%] [G loss: 6.183264]\n",
      "epoch:46 step:35962 [D loss: 0.599090, acc: 69.53%] [G loss: 4.578718]\n",
      "epoch:46 step:35963 [D loss: 0.034642, acc: 99.22%] [G loss: 6.634588]\n",
      "epoch:46 step:35964 [D loss: 0.167245, acc: 96.88%] [G loss: 3.010353]\n",
      "epoch:46 step:35965 [D loss: 0.077408, acc: 100.00%] [G loss: 5.226092]\n",
      "epoch:46 step:35966 [D loss: 0.523462, acc: 64.06%] [G loss: 6.203989]\n",
      "epoch:46 step:35967 [D loss: 0.101725, acc: 100.00%] [G loss: 6.861427]\n",
      "epoch:46 step:35968 [D loss: 0.185403, acc: 95.31%] [G loss: 3.994283]\n",
      "epoch:46 step:35969 [D loss: 0.668100, acc: 60.16%] [G loss: 7.978826]\n",
      "epoch:46 step:35970 [D loss: 0.060816, acc: 99.22%] [G loss: 2.309034]\n",
      "epoch:46 step:35971 [D loss: 1.008188, acc: 50.78%] [G loss: 5.178559]\n",
      "epoch:46 step:35972 [D loss: 0.144621, acc: 98.44%] [G loss: 4.566636]\n",
      "epoch:46 step:35973 [D loss: 0.518043, acc: 64.84%] [G loss: 7.212080]\n",
      "epoch:46 step:35974 [D loss: 0.354602, acc: 87.50%] [G loss: 6.094130]\n",
      "epoch:46 step:35975 [D loss: 0.498009, acc: 64.06%] [G loss: 3.611072]\n",
      "epoch:46 step:35976 [D loss: 0.055210, acc: 100.00%] [G loss: 5.288594]\n",
      "epoch:46 step:35977 [D loss: 0.168776, acc: 95.31%] [G loss: 4.557106]\n",
      "epoch:46 step:35978 [D loss: 0.535729, acc: 75.78%] [G loss: 6.060788]\n",
      "epoch:46 step:35979 [D loss: 0.330003, acc: 84.38%] [G loss: 6.223018]\n",
      "epoch:46 step:35980 [D loss: 0.033342, acc: 100.00%] [G loss: 4.477763]\n",
      "epoch:46 step:35981 [D loss: 0.751710, acc: 54.69%] [G loss: 7.936893]\n",
      "epoch:46 step:35982 [D loss: 0.016835, acc: 100.00%] [G loss: 9.826893]\n",
      "epoch:46 step:35983 [D loss: 1.068961, acc: 50.00%] [G loss: 5.066333]\n",
      "epoch:46 step:35984 [D loss: 0.095445, acc: 100.00%] [G loss: 2.652605]\n",
      "epoch:46 step:35985 [D loss: 0.078716, acc: 100.00%] [G loss: 4.892227]\n",
      "epoch:46 step:35986 [D loss: 0.669780, acc: 54.69%] [G loss: 7.642053]\n",
      "epoch:46 step:35987 [D loss: 0.975317, acc: 50.78%] [G loss: 5.050086]\n",
      "epoch:46 step:35988 [D loss: 0.006455, acc: 100.00%] [G loss: 11.116649]\n",
      "epoch:46 step:35989 [D loss: 0.538436, acc: 60.94%] [G loss: 4.186435]\n",
      "epoch:46 step:35990 [D loss: 0.417060, acc: 72.66%] [G loss: 4.537634]\n",
      "epoch:46 step:35991 [D loss: 0.315685, acc: 92.97%] [G loss: 3.613040]\n",
      "epoch:46 step:35992 [D loss: 0.663428, acc: 60.94%] [G loss: 5.754333]\n",
      "epoch:46 step:35993 [D loss: 0.092521, acc: 98.44%] [G loss: 3.660038]\n",
      "epoch:46 step:35994 [D loss: 0.124647, acc: 99.22%] [G loss: 3.607165]\n",
      "epoch:46 step:35995 [D loss: 0.074857, acc: 100.00%] [G loss: 5.181703]\n",
      "epoch:46 step:35996 [D loss: 0.717257, acc: 54.69%] [G loss: 5.599700]\n",
      "epoch:46 step:35997 [D loss: 0.068229, acc: 100.00%] [G loss: 3.503436]\n",
      "epoch:46 step:35998 [D loss: 0.232609, acc: 96.88%] [G loss: 5.217569]\n",
      "epoch:46 step:35999 [D loss: 0.291834, acc: 92.19%] [G loss: 4.576775]\n",
      "epoch:46 step:36000 [D loss: 1.115865, acc: 28.91%] [G loss: 7.642983]\n",
      "epoch:46 step:36001 [D loss: 0.479140, acc: 64.84%] [G loss: 6.819705]\n",
      "epoch:46 step:36002 [D loss: 0.067799, acc: 100.00%] [G loss: 8.038456]\n",
      "epoch:46 step:36003 [D loss: 0.421500, acc: 77.34%] [G loss: 4.598538]\n",
      "epoch:46 step:36004 [D loss: 0.367229, acc: 80.47%] [G loss: 5.382583]\n",
      "epoch:46 step:36005 [D loss: 0.149873, acc: 99.22%] [G loss: 5.268214]\n",
      "epoch:46 step:36006 [D loss: 0.072747, acc: 100.00%] [G loss: 6.539388]\n",
      "epoch:46 step:36007 [D loss: 0.367418, acc: 87.50%] [G loss: 2.873700]\n",
      "epoch:46 step:36008 [D loss: 0.114896, acc: 100.00%] [G loss: 6.266130]\n",
      "epoch:46 step:36009 [D loss: 1.024658, acc: 50.00%] [G loss: 8.967859]\n",
      "epoch:46 step:36010 [D loss: 0.336348, acc: 88.28%] [G loss: 3.509911]\n",
      "epoch:46 step:36011 [D loss: 0.176769, acc: 96.09%] [G loss: 9.285074]\n",
      "epoch:46 step:36012 [D loss: 0.111095, acc: 99.22%] [G loss: 6.508357]\n",
      "epoch:46 step:36013 [D loss: 0.439631, acc: 78.12%] [G loss: 2.690514]\n",
      "epoch:46 step:36014 [D loss: 0.181370, acc: 97.66%] [G loss: 7.589523]\n",
      "epoch:46 step:36015 [D loss: 0.056971, acc: 100.00%] [G loss: 6.268650]\n",
      "epoch:46 step:36016 [D loss: 0.093650, acc: 100.00%] [G loss: 7.105323]\n",
      "epoch:46 step:36017 [D loss: 0.069045, acc: 100.00%] [G loss: 4.423203]\n",
      "epoch:46 step:36018 [D loss: 0.025157, acc: 100.00%] [G loss: 7.881793]\n",
      "epoch:46 step:36019 [D loss: 0.010652, acc: 100.00%] [G loss: 5.339906]\n",
      "epoch:46 step:36020 [D loss: 0.058186, acc: 100.00%] [G loss: 5.441857]\n",
      "epoch:46 step:36021 [D loss: 0.311076, acc: 88.28%] [G loss: 6.247313]\n",
      "epoch:46 step:36022 [D loss: 0.587997, acc: 71.09%] [G loss: 3.854434]\n",
      "epoch:46 step:36023 [D loss: 0.354874, acc: 89.06%] [G loss: 6.877376]\n",
      "epoch:46 step:36024 [D loss: 0.253718, acc: 92.97%] [G loss: 3.530300]\n",
      "epoch:46 step:36025 [D loss: 0.230496, acc: 96.88%] [G loss: 6.640805]\n",
      "epoch:46 step:36026 [D loss: 0.215427, acc: 96.88%] [G loss: 4.646698]\n",
      "epoch:46 step:36027 [D loss: 0.611875, acc: 57.03%] [G loss: 7.748836]\n",
      "epoch:46 step:36028 [D loss: 0.066197, acc: 100.00%] [G loss: 4.100734]\n",
      "epoch:46 step:36029 [D loss: 0.837874, acc: 53.91%] [G loss: 7.282132]\n",
      "epoch:46 step:36030 [D loss: 0.053127, acc: 100.00%] [G loss: 4.921349]\n",
      "epoch:46 step:36031 [D loss: 0.115030, acc: 100.00%] [G loss: 7.008174]\n",
      "epoch:46 step:36032 [D loss: 0.264486, acc: 96.09%] [G loss: 7.273338]\n",
      "epoch:46 step:36033 [D loss: 0.237799, acc: 96.09%] [G loss: 6.041566]\n",
      "epoch:46 step:36034 [D loss: 0.635553, acc: 61.72%] [G loss: 7.040924]\n",
      "epoch:46 step:36035 [D loss: 0.148329, acc: 97.66%] [G loss: 4.445552]\n",
      "epoch:46 step:36036 [D loss: 1.573391, acc: 10.16%] [G loss: 6.787766]\n",
      "epoch:46 step:36037 [D loss: 0.053593, acc: 100.00%] [G loss: 5.773790]\n",
      "epoch:46 step:36038 [D loss: 0.276984, acc: 93.75%] [G loss: 8.706572]\n",
      "epoch:46 step:36039 [D loss: 0.168140, acc: 100.00%] [G loss: 7.938197]\n",
      "epoch:46 step:36040 [D loss: 0.029953, acc: 100.00%] [G loss: 6.951819]\n",
      "epoch:46 step:36041 [D loss: 0.352594, acc: 91.41%] [G loss: 7.368012]\n",
      "epoch:46 step:36042 [D loss: 0.172894, acc: 100.00%] [G loss: 2.776536]\n",
      "epoch:46 step:36043 [D loss: 0.632692, acc: 61.72%] [G loss: 12.331510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36044 [D loss: 0.267509, acc: 94.53%] [G loss: 5.478487]\n",
      "epoch:46 step:36045 [D loss: 0.125918, acc: 98.44%] [G loss: 6.693624]\n",
      "epoch:46 step:36046 [D loss: 0.144462, acc: 99.22%] [G loss: 6.007533]\n",
      "epoch:46 step:36047 [D loss: 0.726853, acc: 50.78%] [G loss: 4.808044]\n",
      "epoch:46 step:36048 [D loss: 0.087949, acc: 100.00%] [G loss: 8.118704]\n",
      "epoch:46 step:36049 [D loss: 0.563606, acc: 67.97%] [G loss: 5.363981]\n",
      "epoch:46 step:36050 [D loss: 0.074490, acc: 100.00%] [G loss: 8.274519]\n",
      "epoch:46 step:36051 [D loss: 0.907705, acc: 41.41%] [G loss: 3.115130]\n",
      "epoch:46 step:36052 [D loss: 0.036890, acc: 100.00%] [G loss: 3.891639]\n",
      "epoch:46 step:36053 [D loss: 0.792952, acc: 56.25%] [G loss: 6.453498]\n",
      "epoch:46 step:36054 [D loss: 0.509775, acc: 62.50%] [G loss: 4.725923]\n",
      "epoch:46 step:36055 [D loss: 0.294305, acc: 88.28%] [G loss: 3.990303]\n",
      "epoch:46 step:36056 [D loss: 0.295188, acc: 93.75%] [G loss: 4.074407]\n",
      "epoch:46 step:36057 [D loss: 0.465602, acc: 75.78%] [G loss: 2.454632]\n",
      "epoch:46 step:36058 [D loss: 0.046900, acc: 100.00%] [G loss: 6.267505]\n",
      "epoch:46 step:36059 [D loss: 0.018411, acc: 100.00%] [G loss: 5.437783]\n",
      "epoch:46 step:36060 [D loss: 0.071396, acc: 99.22%] [G loss: 6.321192]\n",
      "epoch:46 step:36061 [D loss: 1.426705, acc: 4.69%] [G loss: 9.747815]\n",
      "epoch:46 step:36062 [D loss: 0.907531, acc: 50.78%] [G loss: 5.472940]\n",
      "epoch:46 step:36063 [D loss: 0.097125, acc: 100.00%] [G loss: 8.676558]\n",
      "epoch:46 step:36064 [D loss: 0.633844, acc: 60.94%] [G loss: 6.804611]\n",
      "epoch:46 step:36065 [D loss: 0.682082, acc: 55.47%] [G loss: 5.297766]\n",
      "epoch:46 step:36066 [D loss: 0.725343, acc: 53.91%] [G loss: 7.311520]\n",
      "epoch:46 step:36067 [D loss: 0.238791, acc: 96.88%] [G loss: 3.076010]\n",
      "epoch:46 step:36068 [D loss: 0.716732, acc: 56.25%] [G loss: 4.788047]\n",
      "epoch:46 step:36069 [D loss: 0.244073, acc: 92.97%] [G loss: 6.227747]\n",
      "epoch:46 step:36070 [D loss: 0.113063, acc: 99.22%] [G loss: 4.430101]\n",
      "epoch:46 step:36071 [D loss: 0.368207, acc: 90.62%] [G loss: 3.444074]\n",
      "epoch:46 step:36072 [D loss: 0.118813, acc: 98.44%] [G loss: 6.270546]\n",
      "epoch:46 step:36073 [D loss: 0.078803, acc: 99.22%] [G loss: 8.778469]\n",
      "epoch:46 step:36074 [D loss: 0.143341, acc: 99.22%] [G loss: 4.484838]\n",
      "epoch:46 step:36075 [D loss: 0.446125, acc: 72.66%] [G loss: 4.672348]\n",
      "epoch:46 step:36076 [D loss: 0.464681, acc: 78.12%] [G loss: 5.922270]\n",
      "epoch:46 step:36077 [D loss: 0.211168, acc: 95.31%] [G loss: 5.009204]\n",
      "epoch:46 step:36078 [D loss: 0.217060, acc: 97.66%] [G loss: 3.045987]\n",
      "epoch:46 step:36079 [D loss: 0.307911, acc: 95.31%] [G loss: 5.686100]\n",
      "epoch:46 step:36080 [D loss: 0.047399, acc: 100.00%] [G loss: 4.189832]\n",
      "epoch:46 step:36081 [D loss: 0.297286, acc: 95.31%] [G loss: 6.117339]\n",
      "epoch:46 step:36082 [D loss: 0.192282, acc: 96.88%] [G loss: 4.928229]\n",
      "epoch:46 step:36083 [D loss: 0.034188, acc: 100.00%] [G loss: 4.229967]\n",
      "epoch:46 step:36084 [D loss: 0.120773, acc: 98.44%] [G loss: 6.803466]\n",
      "epoch:46 step:36085 [D loss: 0.415666, acc: 73.44%] [G loss: 9.697717]\n",
      "epoch:46 step:36086 [D loss: 1.468367, acc: 10.94%] [G loss: 8.317648]\n",
      "epoch:46 step:36087 [D loss: 0.787070, acc: 53.91%] [G loss: 7.628720]\n",
      "epoch:46 step:36088 [D loss: 0.503318, acc: 63.28%] [G loss: 6.136573]\n",
      "epoch:46 step:36089 [D loss: 1.483470, acc: 50.00%] [G loss: 7.193933]\n",
      "epoch:46 step:36090 [D loss: 0.326126, acc: 84.38%] [G loss: 6.078486]\n",
      "epoch:46 step:36091 [D loss: 0.129188, acc: 100.00%] [G loss: 2.332075]\n",
      "epoch:46 step:36092 [D loss: 0.516476, acc: 67.19%] [G loss: 5.329213]\n",
      "epoch:46 step:36093 [D loss: 0.037291, acc: 100.00%] [G loss: 4.318168]\n",
      "epoch:46 step:36094 [D loss: 0.275313, acc: 92.19%] [G loss: 3.835283]\n",
      "epoch:46 step:36095 [D loss: 0.195654, acc: 96.09%] [G loss: 2.495423]\n",
      "epoch:46 step:36096 [D loss: 0.365928, acc: 75.78%] [G loss: 3.132581]\n",
      "epoch:46 step:36097 [D loss: 0.361114, acc: 86.72%] [G loss: 6.017822]\n",
      "epoch:46 step:36098 [D loss: 0.208563, acc: 98.44%] [G loss: 3.788463]\n",
      "epoch:46 step:36099 [D loss: 0.438502, acc: 82.03%] [G loss: 3.848231]\n",
      "epoch:46 step:36100 [D loss: 0.064701, acc: 100.00%] [G loss: 8.819036]\n",
      "epoch:46 step:36101 [D loss: 0.156070, acc: 100.00%] [G loss: 7.989739]\n",
      "epoch:46 step:36102 [D loss: 0.139358, acc: 99.22%] [G loss: 3.806980]\n",
      "epoch:46 step:36103 [D loss: 0.745496, acc: 55.47%] [G loss: 4.900724]\n",
      "epoch:46 step:36104 [D loss: 0.108973, acc: 99.22%] [G loss: 3.319866]\n",
      "epoch:46 step:36105 [D loss: 0.409969, acc: 74.22%] [G loss: 3.990502]\n",
      "epoch:46 step:36106 [D loss: 0.332188, acc: 93.75%] [G loss: 4.272960]\n",
      "epoch:46 step:36107 [D loss: 0.403925, acc: 79.69%] [G loss: 4.791800]\n",
      "epoch:46 step:36108 [D loss: 0.054770, acc: 99.22%] [G loss: 6.674222]\n",
      "epoch:46 step:36109 [D loss: 0.054831, acc: 100.00%] [G loss: 7.541162]\n",
      "epoch:46 step:36110 [D loss: 0.239215, acc: 92.97%] [G loss: 6.993137]\n",
      "epoch:46 step:36111 [D loss: 0.171647, acc: 96.88%] [G loss: 6.515690]\n",
      "epoch:46 step:36112 [D loss: 0.113143, acc: 98.44%] [G loss: 7.851906]\n",
      "epoch:46 step:36113 [D loss: 0.229814, acc: 94.53%] [G loss: 7.033846]\n",
      "epoch:46 step:36114 [D loss: 0.109205, acc: 97.66%] [G loss: 6.380969]\n",
      "epoch:46 step:36115 [D loss: 0.003946, acc: 100.00%] [G loss: 6.386735]\n",
      "epoch:46 step:36116 [D loss: 0.179306, acc: 98.44%] [G loss: 7.294260]\n",
      "epoch:46 step:36117 [D loss: 0.108576, acc: 99.22%] [G loss: 5.141043]\n",
      "epoch:46 step:36118 [D loss: 0.044577, acc: 100.00%] [G loss: 4.583196]\n",
      "epoch:46 step:36119 [D loss: 0.143047, acc: 98.44%] [G loss: 7.336335]\n",
      "epoch:46 step:36120 [D loss: 0.075064, acc: 99.22%] [G loss: 5.451090]\n",
      "epoch:46 step:36121 [D loss: 0.180664, acc: 98.44%] [G loss: 5.797302]\n",
      "epoch:46 step:36122 [D loss: 0.120376, acc: 100.00%] [G loss: 3.710228]\n",
      "epoch:46 step:36123 [D loss: 0.339493, acc: 80.47%] [G loss: 7.242533]\n",
      "epoch:46 step:36124 [D loss: 0.521375, acc: 59.38%] [G loss: 8.236627]\n",
      "epoch:46 step:36125 [D loss: 0.026087, acc: 100.00%] [G loss: 8.625873]\n",
      "epoch:46 step:36126 [D loss: 0.063239, acc: 100.00%] [G loss: 6.362849]\n",
      "epoch:46 step:36127 [D loss: 0.182255, acc: 95.31%] [G loss: 8.671541]\n",
      "epoch:46 step:36128 [D loss: 0.327142, acc: 87.50%] [G loss: 7.713914]\n",
      "epoch:46 step:36129 [D loss: 0.100639, acc: 99.22%] [G loss: 2.976276]\n",
      "epoch:46 step:36130 [D loss: 0.142998, acc: 100.00%] [G loss: 7.346891]\n",
      "epoch:46 step:36131 [D loss: 0.077134, acc: 99.22%] [G loss: 5.626883]\n",
      "epoch:46 step:36132 [D loss: 0.919631, acc: 50.00%] [G loss: 5.371006]\n",
      "epoch:46 step:36133 [D loss: 0.633748, acc: 64.84%] [G loss: 5.818521]\n",
      "epoch:46 step:36134 [D loss: 0.425017, acc: 71.88%] [G loss: 6.922142]\n",
      "epoch:46 step:36135 [D loss: 0.383739, acc: 75.00%] [G loss: 4.760076]\n",
      "epoch:46 step:36136 [D loss: 0.296132, acc: 92.19%] [G loss: 6.811626]\n",
      "epoch:46 step:36137 [D loss: 0.085247, acc: 100.00%] [G loss: 6.732285]\n",
      "epoch:46 step:36138 [D loss: 0.701685, acc: 52.34%] [G loss: 5.321409]\n",
      "epoch:46 step:36139 [D loss: 0.222107, acc: 96.88%] [G loss: 5.848534]\n",
      "epoch:46 step:36140 [D loss: 0.139042, acc: 99.22%] [G loss: 4.990430]\n",
      "epoch:46 step:36141 [D loss: 0.419508, acc: 71.09%] [G loss: 5.322319]\n",
      "epoch:46 step:36142 [D loss: 0.703099, acc: 57.81%] [G loss: 3.380285]\n",
      "epoch:46 step:36143 [D loss: 0.387489, acc: 78.91%] [G loss: 7.527254]\n",
      "epoch:46 step:36144 [D loss: 0.040938, acc: 100.00%] [G loss: 4.830231]\n",
      "epoch:46 step:36145 [D loss: 0.233850, acc: 91.41%] [G loss: 4.140729]\n",
      "epoch:46 step:36146 [D loss: 0.289258, acc: 85.94%] [G loss: 4.798061]\n",
      "epoch:46 step:36147 [D loss: 0.049852, acc: 100.00%] [G loss: 2.804505]\n",
      "epoch:46 step:36148 [D loss: 0.161118, acc: 97.66%] [G loss: 5.047940]\n",
      "epoch:46 step:36149 [D loss: 0.380251, acc: 92.19%] [G loss: 5.072391]\n",
      "epoch:46 step:36150 [D loss: 0.177762, acc: 98.44%] [G loss: 6.310300]\n",
      "epoch:46 step:36151 [D loss: 0.100019, acc: 100.00%] [G loss: 4.459423]\n",
      "epoch:46 step:36152 [D loss: 0.030091, acc: 100.00%] [G loss: 3.447529]\n",
      "epoch:46 step:36153 [D loss: 0.206946, acc: 96.88%] [G loss: 6.223371]\n",
      "epoch:46 step:36154 [D loss: 0.563939, acc: 64.84%] [G loss: 5.530616]\n",
      "epoch:46 step:36155 [D loss: 0.592931, acc: 54.69%] [G loss: 7.114123]\n",
      "epoch:46 step:36156 [D loss: 0.157838, acc: 98.44%] [G loss: 5.899949]\n",
      "epoch:46 step:36157 [D loss: 0.171382, acc: 96.88%] [G loss: 4.429449]\n",
      "epoch:46 step:36158 [D loss: 0.279400, acc: 89.84%] [G loss: 6.465993]\n",
      "epoch:46 step:36159 [D loss: 0.713276, acc: 53.91%] [G loss: 6.572893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36160 [D loss: 0.154851, acc: 99.22%] [G loss: 1.467305]\n",
      "epoch:46 step:36161 [D loss: 0.795084, acc: 56.25%] [G loss: 7.742870]\n",
      "epoch:46 step:36162 [D loss: 0.182275, acc: 97.66%] [G loss: 5.223581]\n",
      "epoch:46 step:36163 [D loss: 0.554452, acc: 60.94%] [G loss: 6.555381]\n",
      "epoch:46 step:36164 [D loss: 0.444695, acc: 84.38%] [G loss: 5.240253]\n",
      "epoch:46 step:36165 [D loss: 0.363499, acc: 79.69%] [G loss: 6.598791]\n",
      "epoch:46 step:36166 [D loss: 0.046561, acc: 100.00%] [G loss: 5.004743]\n",
      "epoch:46 step:36167 [D loss: 0.221399, acc: 96.09%] [G loss: 4.151705]\n",
      "epoch:46 step:36168 [D loss: 0.020474, acc: 100.00%] [G loss: 5.831132]\n",
      "epoch:46 step:36169 [D loss: 0.140014, acc: 97.66%] [G loss: 3.858654]\n",
      "epoch:46 step:36170 [D loss: 0.692839, acc: 56.25%] [G loss: 10.231053]\n",
      "epoch:46 step:36171 [D loss: 0.865210, acc: 45.31%] [G loss: 7.461927]\n",
      "epoch:46 step:36172 [D loss: 0.069838, acc: 99.22%] [G loss: 7.959789]\n",
      "epoch:46 step:36173 [D loss: 0.244326, acc: 91.41%] [G loss: 5.680889]\n",
      "epoch:46 step:36174 [D loss: 0.284175, acc: 92.97%] [G loss: 4.334929]\n",
      "epoch:46 step:36175 [D loss: 0.017103, acc: 100.00%] [G loss: 6.166357]\n",
      "epoch:46 step:36176 [D loss: 0.855250, acc: 54.69%] [G loss: 6.248535]\n",
      "epoch:46 step:36177 [D loss: 0.032992, acc: 100.00%] [G loss: 8.221794]\n",
      "epoch:46 step:36178 [D loss: 0.022993, acc: 100.00%] [G loss: 6.315788]\n",
      "epoch:46 step:36179 [D loss: 0.971856, acc: 35.94%] [G loss: 8.681902]\n",
      "epoch:46 step:36180 [D loss: 1.055208, acc: 50.78%] [G loss: 9.938139]\n",
      "epoch:46 step:36181 [D loss: 0.118344, acc: 99.22%] [G loss: 7.969177]\n",
      "epoch:46 step:36182 [D loss: 0.198828, acc: 96.09%] [G loss: 8.191976]\n",
      "epoch:46 step:36183 [D loss: 0.096965, acc: 98.44%] [G loss: 5.355630]\n",
      "epoch:46 step:36184 [D loss: 0.077569, acc: 99.22%] [G loss: 5.656706]\n",
      "epoch:46 step:36185 [D loss: 0.014784, acc: 100.00%] [G loss: 6.345625]\n",
      "epoch:46 step:36186 [D loss: 1.355879, acc: 50.78%] [G loss: 6.522896]\n",
      "epoch:46 step:36187 [D loss: 1.380902, acc: 50.00%] [G loss: 6.383207]\n",
      "epoch:46 step:36188 [D loss: 0.174840, acc: 94.53%] [G loss: 6.887865]\n",
      "epoch:46 step:36189 [D loss: 0.480388, acc: 74.22%] [G loss: 4.835758]\n",
      "epoch:46 step:36190 [D loss: 0.226615, acc: 96.09%] [G loss: 4.589162]\n",
      "epoch:46 step:36191 [D loss: 0.665219, acc: 60.94%] [G loss: 5.121360]\n",
      "epoch:46 step:36192 [D loss: 0.266159, acc: 97.66%] [G loss: 4.942899]\n",
      "epoch:46 step:36193 [D loss: 0.122216, acc: 100.00%] [G loss: 6.248212]\n",
      "epoch:46 step:36194 [D loss: 0.256737, acc: 93.75%] [G loss: 6.299106]\n",
      "epoch:46 step:36195 [D loss: 0.294288, acc: 94.53%] [G loss: 4.973322]\n",
      "epoch:46 step:36196 [D loss: 0.777583, acc: 46.88%] [G loss: 5.426289]\n",
      "epoch:46 step:36197 [D loss: 0.149612, acc: 98.44%] [G loss: 9.022895]\n",
      "epoch:46 step:36198 [D loss: 1.120378, acc: 50.00%] [G loss: 3.615941]\n",
      "epoch:46 step:36199 [D loss: 0.397808, acc: 79.69%] [G loss: 6.387003]\n",
      "epoch:46 step:36200 [D loss: 0.174193, acc: 97.66%] [G loss: 4.091175]\n",
      "epoch:46 step:36201 [D loss: 0.577085, acc: 71.88%] [G loss: 8.659156]\n",
      "epoch:46 step:36202 [D loss: 0.152081, acc: 100.00%] [G loss: 4.306129]\n",
      "epoch:46 step:36203 [D loss: 0.016474, acc: 100.00%] [G loss: 8.320458]\n",
      "epoch:46 step:36204 [D loss: 0.017496, acc: 100.00%] [G loss: 7.282223]\n",
      "epoch:46 step:36205 [D loss: 0.613430, acc: 59.38%] [G loss: 5.622272]\n",
      "epoch:46 step:36206 [D loss: 0.078939, acc: 100.00%] [G loss: 5.211411]\n",
      "epoch:46 step:36207 [D loss: 0.066996, acc: 100.00%] [G loss: 6.004278]\n",
      "epoch:46 step:36208 [D loss: 0.031283, acc: 100.00%] [G loss: 4.831616]\n",
      "epoch:46 step:36209 [D loss: 0.106633, acc: 100.00%] [G loss: 6.697861]\n",
      "epoch:46 step:36210 [D loss: 0.044915, acc: 100.00%] [G loss: 5.444892]\n",
      "epoch:46 step:36211 [D loss: 0.076798, acc: 100.00%] [G loss: 7.367188]\n",
      "epoch:46 step:36212 [D loss: 0.046879, acc: 100.00%] [G loss: 5.388151]\n",
      "epoch:46 step:36213 [D loss: 0.339834, acc: 91.41%] [G loss: 5.067577]\n",
      "epoch:46 step:36214 [D loss: 0.168564, acc: 99.22%] [G loss: 2.812356]\n",
      "epoch:46 step:36215 [D loss: 0.698428, acc: 53.91%] [G loss: 4.775519]\n",
      "epoch:46 step:36216 [D loss: 0.551594, acc: 59.38%] [G loss: 7.951839]\n",
      "epoch:46 step:36217 [D loss: 0.896480, acc: 51.56%] [G loss: 6.091619]\n",
      "epoch:46 step:36218 [D loss: 0.050267, acc: 100.00%] [G loss: 5.429253]\n",
      "epoch:46 step:36219 [D loss: 0.482659, acc: 78.91%] [G loss: 2.591250]\n",
      "epoch:46 step:36220 [D loss: 0.154540, acc: 96.88%] [G loss: 7.026238]\n",
      "epoch:46 step:36221 [D loss: 0.240962, acc: 92.97%] [G loss: 7.936323]\n",
      "epoch:46 step:36222 [D loss: 0.483501, acc: 77.34%] [G loss: 7.439671]\n",
      "epoch:46 step:36223 [D loss: 0.173986, acc: 100.00%] [G loss: 5.510861]\n",
      "epoch:46 step:36224 [D loss: 0.315444, acc: 88.28%] [G loss: 6.441607]\n",
      "epoch:46 step:36225 [D loss: 0.072339, acc: 99.22%] [G loss: 5.182500]\n",
      "epoch:46 step:36226 [D loss: 0.297191, acc: 87.50%] [G loss: 4.848685]\n",
      "epoch:46 step:36227 [D loss: 0.144880, acc: 100.00%] [G loss: 5.492123]\n",
      "epoch:46 step:36228 [D loss: 0.115292, acc: 100.00%] [G loss: 3.752016]\n",
      "epoch:46 step:36229 [D loss: 1.351600, acc: 21.88%] [G loss: 5.739730]\n",
      "epoch:46 step:36230 [D loss: 0.553695, acc: 65.62%] [G loss: 5.482498]\n",
      "epoch:46 step:36231 [D loss: 0.240937, acc: 87.50%] [G loss: 7.189130]\n",
      "epoch:46 step:36232 [D loss: 0.245059, acc: 96.09%] [G loss: 5.289167]\n",
      "epoch:46 step:36233 [D loss: 0.151834, acc: 99.22%] [G loss: 4.316331]\n",
      "epoch:46 step:36234 [D loss: 0.091785, acc: 99.22%] [G loss: 7.100393]\n",
      "epoch:46 step:36235 [D loss: 0.102959, acc: 100.00%] [G loss: 2.843585]\n",
      "epoch:46 step:36236 [D loss: 0.024715, acc: 100.00%] [G loss: 5.990708]\n",
      "epoch:46 step:36237 [D loss: 0.559573, acc: 69.53%] [G loss: 4.069210]\n",
      "epoch:46 step:36238 [D loss: 0.037517, acc: 100.00%] [G loss: 2.673751]\n",
      "epoch:46 step:36239 [D loss: 0.074115, acc: 99.22%] [G loss: 6.039539]\n",
      "epoch:46 step:36240 [D loss: 0.038098, acc: 100.00%] [G loss: 10.604557]\n",
      "epoch:46 step:36241 [D loss: 0.058223, acc: 100.00%] [G loss: 2.511586]\n",
      "epoch:46 step:36242 [D loss: 0.332326, acc: 85.16%] [G loss: 9.868125]\n",
      "epoch:46 step:36243 [D loss: 0.174507, acc: 99.22%] [G loss: 3.850677]\n",
      "epoch:46 step:36244 [D loss: 0.991346, acc: 27.34%] [G loss: 4.469031]\n",
      "epoch:46 step:36245 [D loss: 0.709956, acc: 58.59%] [G loss: 5.018472]\n",
      "epoch:46 step:36246 [D loss: 0.238845, acc: 91.41%] [G loss: 4.421790]\n",
      "epoch:46 step:36247 [D loss: 0.979235, acc: 22.66%] [G loss: 6.028588]\n",
      "epoch:46 step:36248 [D loss: 0.185954, acc: 99.22%] [G loss: 3.302948]\n",
      "epoch:46 step:36249 [D loss: 0.240052, acc: 94.53%] [G loss: 6.426147]\n",
      "epoch:46 step:36250 [D loss: 0.481196, acc: 74.22%] [G loss: 6.598984]\n",
      "epoch:46 step:36251 [D loss: 0.198302, acc: 99.22%] [G loss: 4.364886]\n",
      "epoch:46 step:36252 [D loss: 1.052640, acc: 29.69%] [G loss: 5.079066]\n",
      "epoch:46 step:36253 [D loss: 0.051790, acc: 100.00%] [G loss: 6.655715]\n",
      "epoch:46 step:36254 [D loss: 1.277181, acc: 34.38%] [G loss: 5.286368]\n",
      "epoch:46 step:36255 [D loss: 0.548276, acc: 60.94%] [G loss: 5.208423]\n",
      "epoch:46 step:36256 [D loss: 0.544289, acc: 75.78%] [G loss: 9.245544]\n",
      "epoch:46 step:36257 [D loss: 0.057767, acc: 100.00%] [G loss: 3.032447]\n",
      "epoch:46 step:36258 [D loss: 1.251790, acc: 11.72%] [G loss: 8.416847]\n",
      "epoch:46 step:36259 [D loss: 0.021666, acc: 100.00%] [G loss: 6.367770]\n",
      "epoch:46 step:36260 [D loss: 0.917419, acc: 44.53%] [G loss: 10.709856]\n",
      "epoch:46 step:36261 [D loss: 0.108504, acc: 99.22%] [G loss: 5.117394]\n",
      "epoch:46 step:36262 [D loss: 0.041536, acc: 100.00%] [G loss: 2.346151]\n",
      "epoch:46 step:36263 [D loss: 0.108534, acc: 100.00%] [G loss: 5.862339]\n",
      "epoch:46 step:36264 [D loss: 1.739860, acc: 50.00%] [G loss: 3.721831]\n",
      "epoch:46 step:36265 [D loss: 0.004930, acc: 100.00%] [G loss: 7.918367]\n",
      "epoch:46 step:36266 [D loss: 1.044928, acc: 50.78%] [G loss: 7.584517]\n",
      "epoch:46 step:36267 [D loss: 0.246978, acc: 93.75%] [G loss: 5.543658]\n",
      "epoch:46 step:36268 [D loss: 0.138013, acc: 96.88%] [G loss: 4.393478]\n",
      "epoch:46 step:36269 [D loss: 1.327093, acc: 50.00%] [G loss: 3.316185]\n",
      "epoch:46 step:36270 [D loss: 0.157208, acc: 99.22%] [G loss: 2.573802]\n",
      "epoch:46 step:36271 [D loss: 0.250294, acc: 91.41%] [G loss: 6.773643]\n",
      "epoch:46 step:36272 [D loss: 0.298643, acc: 94.53%] [G loss: 8.212726]\n",
      "epoch:46 step:36273 [D loss: 0.215521, acc: 92.97%] [G loss: 4.333830]\n",
      "epoch:46 step:36274 [D loss: 0.288242, acc: 91.41%] [G loss: 7.436818]\n",
      "epoch:46 step:36275 [D loss: 0.305509, acc: 84.38%] [G loss: 7.193680]\n",
      "epoch:46 step:36276 [D loss: 0.132658, acc: 100.00%] [G loss: 4.292789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36277 [D loss: 0.722891, acc: 54.69%] [G loss: 5.709181]\n",
      "epoch:46 step:36278 [D loss: 0.186387, acc: 96.09%] [G loss: 8.814291]\n",
      "epoch:46 step:36279 [D loss: 0.317108, acc: 89.06%] [G loss: 6.316835]\n",
      "epoch:46 step:36280 [D loss: 0.715910, acc: 49.22%] [G loss: 7.521143]\n",
      "epoch:46 step:36281 [D loss: 0.101949, acc: 100.00%] [G loss: 4.064688]\n",
      "epoch:46 step:36282 [D loss: 0.232640, acc: 96.88%] [G loss: 6.004480]\n",
      "epoch:46 step:36283 [D loss: 0.329457, acc: 85.16%] [G loss: 7.502679]\n",
      "epoch:46 step:36284 [D loss: 0.409729, acc: 82.03%] [G loss: 4.214314]\n",
      "epoch:46 step:36285 [D loss: 0.657584, acc: 59.38%] [G loss: 3.566914]\n",
      "epoch:46 step:36286 [D loss: 0.086633, acc: 99.22%] [G loss: 5.428224]\n",
      "epoch:46 step:36287 [D loss: 0.165589, acc: 98.44%] [G loss: 4.494357]\n",
      "epoch:46 step:36288 [D loss: 0.385266, acc: 76.56%] [G loss: 4.294861]\n",
      "epoch:46 step:36289 [D loss: 0.115282, acc: 99.22%] [G loss: 5.317684]\n",
      "epoch:46 step:36290 [D loss: 0.132147, acc: 100.00%] [G loss: 4.110763]\n",
      "epoch:46 step:36291 [D loss: 0.190803, acc: 96.88%] [G loss: 5.889761]\n",
      "epoch:46 step:36292 [D loss: 0.333557, acc: 82.81%] [G loss: 4.537380]\n",
      "epoch:46 step:36293 [D loss: 0.191683, acc: 97.66%] [G loss: 8.010038]\n",
      "epoch:46 step:36294 [D loss: 0.121654, acc: 97.66%] [G loss: 6.344726]\n",
      "epoch:46 step:36295 [D loss: 0.509750, acc: 67.97%] [G loss: 1.920287]\n",
      "epoch:46 step:36296 [D loss: 0.093669, acc: 100.00%] [G loss: 2.768063]\n",
      "epoch:46 step:36297 [D loss: 0.072644, acc: 100.00%] [G loss: 3.513812]\n",
      "epoch:46 step:36298 [D loss: 0.397315, acc: 72.66%] [G loss: 5.257711]\n",
      "epoch:46 step:36299 [D loss: 0.546181, acc: 67.97%] [G loss: 4.156497]\n",
      "epoch:46 step:36300 [D loss: 0.068439, acc: 100.00%] [G loss: 6.123754]\n",
      "epoch:46 step:36301 [D loss: 2.221574, acc: 0.00%] [G loss: 5.540476]\n",
      "epoch:46 step:36302 [D loss: 0.037796, acc: 100.00%] [G loss: 5.042413]\n",
      "epoch:46 step:36303 [D loss: 0.062296, acc: 100.00%] [G loss: 5.715672]\n",
      "epoch:46 step:36304 [D loss: 0.121500, acc: 100.00%] [G loss: 6.201516]\n",
      "epoch:46 step:36305 [D loss: 0.131509, acc: 99.22%] [G loss: 5.226388]\n",
      "epoch:46 step:36306 [D loss: 0.057178, acc: 100.00%] [G loss: 4.392769]\n",
      "epoch:46 step:36307 [D loss: 0.027989, acc: 100.00%] [G loss: 3.796072]\n",
      "epoch:46 step:36308 [D loss: 0.355925, acc: 83.59%] [G loss: 5.589556]\n",
      "epoch:46 step:36309 [D loss: 0.525186, acc: 63.28%] [G loss: 6.103375]\n",
      "epoch:46 step:36310 [D loss: 1.295910, acc: 50.00%] [G loss: 3.365598]\n",
      "epoch:46 step:36311 [D loss: 0.291991, acc: 85.94%] [G loss: 6.547585]\n",
      "epoch:46 step:36312 [D loss: 0.025333, acc: 100.00%] [G loss: 3.963906]\n",
      "epoch:46 step:36313 [D loss: 0.356746, acc: 78.12%] [G loss: 7.675406]\n",
      "epoch:46 step:36314 [D loss: 0.091106, acc: 100.00%] [G loss: 5.275421]\n",
      "epoch:46 step:36315 [D loss: 0.281515, acc: 86.72%] [G loss: 4.389446]\n",
      "epoch:46 step:36316 [D loss: 0.455492, acc: 69.53%] [G loss: 6.761738]\n",
      "epoch:46 step:36317 [D loss: 0.477992, acc: 61.72%] [G loss: 4.797153]\n",
      "epoch:46 step:36318 [D loss: 0.450278, acc: 78.91%] [G loss: 7.953818]\n",
      "epoch:46 step:36319 [D loss: 0.205971, acc: 97.66%] [G loss: 6.492407]\n",
      "epoch:46 step:36320 [D loss: 0.287518, acc: 86.72%] [G loss: 6.816453]\n",
      "epoch:46 step:36321 [D loss: 0.089076, acc: 100.00%] [G loss: 4.245705]\n",
      "epoch:46 step:36322 [D loss: 0.056211, acc: 100.00%] [G loss: 3.451734]\n",
      "epoch:46 step:36323 [D loss: 0.021207, acc: 100.00%] [G loss: 9.843931]\n",
      "epoch:46 step:36324 [D loss: 1.162605, acc: 30.47%] [G loss: 7.387290]\n",
      "epoch:46 step:36325 [D loss: 0.148605, acc: 98.44%] [G loss: 5.316614]\n",
      "epoch:46 step:36326 [D loss: 0.169365, acc: 99.22%] [G loss: 5.245275]\n",
      "epoch:46 step:36327 [D loss: 0.106353, acc: 100.00%] [G loss: 7.244280]\n",
      "epoch:46 step:36328 [D loss: 0.040808, acc: 100.00%] [G loss: 3.504144]\n",
      "epoch:46 step:36329 [D loss: 0.259513, acc: 93.75%] [G loss: 8.323876]\n",
      "epoch:46 step:36330 [D loss: 0.345330, acc: 88.28%] [G loss: 4.365628]\n",
      "epoch:46 step:36331 [D loss: 0.062365, acc: 100.00%] [G loss: 3.516055]\n",
      "epoch:46 step:36332 [D loss: 0.652419, acc: 64.06%] [G loss: 3.145831]\n",
      "epoch:46 step:36333 [D loss: 0.356826, acc: 79.69%] [G loss: 4.213755]\n",
      "epoch:46 step:36334 [D loss: 0.139509, acc: 100.00%] [G loss: 5.464287]\n",
      "epoch:46 step:36335 [D loss: 0.057398, acc: 100.00%] [G loss: 6.321882]\n",
      "epoch:46 step:36336 [D loss: 1.090996, acc: 50.00%] [G loss: 9.363251]\n",
      "epoch:46 step:36337 [D loss: 1.758235, acc: 50.78%] [G loss: 4.298079]\n",
      "epoch:46 step:36338 [D loss: 0.017442, acc: 100.00%] [G loss: 6.398943]\n",
      "epoch:46 step:36339 [D loss: 0.185411, acc: 96.09%] [G loss: 3.066328]\n",
      "epoch:46 step:36340 [D loss: 0.243513, acc: 92.97%] [G loss: 4.385122]\n",
      "epoch:46 step:36341 [D loss: 0.197758, acc: 99.22%] [G loss: 3.685784]\n",
      "epoch:46 step:36342 [D loss: 0.293031, acc: 94.53%] [G loss: 2.620469]\n",
      "epoch:46 step:36343 [D loss: 0.079225, acc: 100.00%] [G loss: 6.026726]\n",
      "epoch:46 step:36344 [D loss: 0.503247, acc: 62.50%] [G loss: 7.291454]\n",
      "epoch:46 step:36345 [D loss: 0.189791, acc: 99.22%] [G loss: 5.512989]\n",
      "epoch:46 step:36346 [D loss: 0.446613, acc: 88.28%] [G loss: 5.631279]\n",
      "epoch:46 step:36347 [D loss: 0.279415, acc: 96.88%] [G loss: 6.015575]\n",
      "epoch:46 step:36348 [D loss: 0.032658, acc: 100.00%] [G loss: 11.161034]\n",
      "epoch:46 step:36349 [D loss: 0.046996, acc: 100.00%] [G loss: 4.729024]\n",
      "epoch:46 step:36350 [D loss: 0.164453, acc: 97.66%] [G loss: 6.260612]\n",
      "epoch:46 step:36351 [D loss: 0.268790, acc: 98.44%] [G loss: 6.708230]\n",
      "epoch:46 step:36352 [D loss: 0.157565, acc: 99.22%] [G loss: 5.729920]\n",
      "epoch:46 step:36353 [D loss: 0.243742, acc: 97.66%] [G loss: 4.027745]\n",
      "epoch:46 step:36354 [D loss: 0.047695, acc: 100.00%] [G loss: 6.789655]\n",
      "epoch:46 step:36355 [D loss: 0.060482, acc: 100.00%] [G loss: 3.649384]\n",
      "epoch:46 step:36356 [D loss: 0.483091, acc: 75.00%] [G loss: 3.661446]\n",
      "epoch:46 step:36357 [D loss: 0.133748, acc: 99.22%] [G loss: 1.619883]\n",
      "epoch:46 step:36358 [D loss: 0.516411, acc: 75.78%] [G loss: 4.756187]\n",
      "epoch:46 step:36359 [D loss: 0.189906, acc: 96.09%] [G loss: 6.318915]\n",
      "epoch:46 step:36360 [D loss: 0.065964, acc: 100.00%] [G loss: 7.568405]\n",
      "epoch:46 step:36361 [D loss: 0.254564, acc: 95.31%] [G loss: 9.101045]\n",
      "epoch:46 step:36362 [D loss: 0.051822, acc: 100.00%] [G loss: 2.717160]\n",
      "epoch:46 step:36363 [D loss: 0.288127, acc: 87.50%] [G loss: 3.843246]\n",
      "epoch:46 step:36364 [D loss: 0.316710, acc: 95.31%] [G loss: 4.654081]\n",
      "epoch:46 step:36365 [D loss: 0.129120, acc: 100.00%] [G loss: 6.593440]\n",
      "epoch:46 step:36366 [D loss: 0.128879, acc: 99.22%] [G loss: 4.348196]\n",
      "epoch:46 step:36367 [D loss: 0.647718, acc: 62.50%] [G loss: 3.579845]\n",
      "epoch:46 step:36368 [D loss: 0.055748, acc: 100.00%] [G loss: 5.416839]\n",
      "epoch:46 step:36369 [D loss: 0.337594, acc: 92.97%] [G loss: 5.531484]\n",
      "epoch:46 step:36370 [D loss: 0.196078, acc: 97.66%] [G loss: 7.150395]\n",
      "epoch:46 step:36371 [D loss: 0.150782, acc: 99.22%] [G loss: 3.050514]\n",
      "epoch:46 step:36372 [D loss: 0.152373, acc: 100.00%] [G loss: 4.348603]\n",
      "epoch:46 step:36373 [D loss: 0.224643, acc: 98.44%] [G loss: 4.247484]\n",
      "epoch:46 step:36374 [D loss: 0.284120, acc: 89.84%] [G loss: 8.188965]\n",
      "epoch:46 step:36375 [D loss: 0.481316, acc: 75.00%] [G loss: 4.504403]\n",
      "epoch:46 step:36376 [D loss: 0.178582, acc: 99.22%] [G loss: 3.983070]\n",
      "epoch:46 step:36377 [D loss: 0.599797, acc: 64.84%] [G loss: 6.864076]\n",
      "epoch:46 step:36378 [D loss: 0.784929, acc: 50.78%] [G loss: 7.711850]\n",
      "epoch:46 step:36379 [D loss: 0.072214, acc: 100.00%] [G loss: 10.031350]\n",
      "epoch:46 step:36380 [D loss: 0.145284, acc: 100.00%] [G loss: 4.749379]\n",
      "epoch:46 step:36381 [D loss: 0.408788, acc: 92.97%] [G loss: 3.191707]\n",
      "epoch:46 step:36382 [D loss: 0.168421, acc: 97.66%] [G loss: 6.851497]\n",
      "epoch:46 step:36383 [D loss: 0.732387, acc: 52.34%] [G loss: 6.350046]\n",
      "epoch:46 step:36384 [D loss: 0.224609, acc: 97.66%] [G loss: 4.450304]\n",
      "epoch:46 step:36385 [D loss: 0.196206, acc: 95.31%] [G loss: 4.247683]\n",
      "epoch:46 step:36386 [D loss: 0.385806, acc: 84.38%] [G loss: 5.746281]\n",
      "epoch:46 step:36387 [D loss: 0.007992, acc: 100.00%] [G loss: 8.953676]\n",
      "epoch:46 step:36388 [D loss: 0.407319, acc: 78.12%] [G loss: 5.539467]\n",
      "epoch:46 step:36389 [D loss: 1.225769, acc: 38.28%] [G loss: 7.458205]\n",
      "epoch:46 step:36390 [D loss: 0.555952, acc: 71.88%] [G loss: 6.637753]\n",
      "epoch:46 step:36391 [D loss: 0.058576, acc: 100.00%] [G loss: 3.076532]\n",
      "epoch:46 step:36392 [D loss: 0.019335, acc: 100.00%] [G loss: 7.474334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36393 [D loss: 0.160658, acc: 98.44%] [G loss: 2.102015]\n",
      "epoch:46 step:36394 [D loss: 0.483306, acc: 64.06%] [G loss: 7.939713]\n",
      "epoch:46 step:36395 [D loss: 1.342822, acc: 48.44%] [G loss: 6.046272]\n",
      "epoch:46 step:36396 [D loss: 0.060570, acc: 100.00%] [G loss: 5.309837]\n",
      "epoch:46 step:36397 [D loss: 0.167599, acc: 100.00%] [G loss: 5.912391]\n",
      "epoch:46 step:36398 [D loss: 0.313910, acc: 92.97%] [G loss: 4.490313]\n",
      "epoch:46 step:36399 [D loss: 0.055245, acc: 100.00%] [G loss: 8.554306]\n",
      "epoch:46 step:36400 [D loss: 0.579481, acc: 61.72%] [G loss: 6.393042]\n",
      "epoch:46 step:36401 [D loss: 0.219961, acc: 99.22%] [G loss: 6.757214]\n",
      "epoch:46 step:36402 [D loss: 0.152425, acc: 97.66%] [G loss: 5.567025]\n",
      "epoch:46 step:36403 [D loss: 0.129150, acc: 99.22%] [G loss: 7.527368]\n",
      "epoch:46 step:36404 [D loss: 0.157623, acc: 96.88%] [G loss: 6.684742]\n",
      "epoch:46 step:36405 [D loss: 0.675939, acc: 59.38%] [G loss: 6.200469]\n",
      "epoch:46 step:36406 [D loss: 0.097211, acc: 100.00%] [G loss: 4.642768]\n",
      "epoch:46 step:36407 [D loss: 0.173428, acc: 96.09%] [G loss: 5.624470]\n",
      "epoch:46 step:36408 [D loss: 0.635353, acc: 57.03%] [G loss: 9.488239]\n",
      "epoch:46 step:36409 [D loss: 0.040835, acc: 100.00%] [G loss: 7.535107]\n",
      "epoch:46 step:36410 [D loss: 1.031883, acc: 53.12%] [G loss: 6.381773]\n",
      "epoch:46 step:36411 [D loss: 0.337536, acc: 90.62%] [G loss: 4.179333]\n",
      "epoch:46 step:36412 [D loss: 0.386181, acc: 89.06%] [G loss: 3.735735]\n",
      "epoch:46 step:36413 [D loss: 0.440845, acc: 71.09%] [G loss: 7.006227]\n",
      "epoch:46 step:36414 [D loss: 0.844803, acc: 52.34%] [G loss: 6.538907]\n",
      "epoch:46 step:36415 [D loss: 0.259013, acc: 92.19%] [G loss: 5.034718]\n",
      "epoch:46 step:36416 [D loss: 0.024664, acc: 100.00%] [G loss: 7.494211]\n",
      "epoch:46 step:36417 [D loss: 0.215091, acc: 93.75%] [G loss: 4.732066]\n",
      "epoch:46 step:36418 [D loss: 0.091557, acc: 99.22%] [G loss: 4.325026]\n",
      "epoch:46 step:36419 [D loss: 0.029388, acc: 100.00%] [G loss: 3.218673]\n",
      "epoch:46 step:36420 [D loss: 0.318116, acc: 94.53%] [G loss: 7.355344]\n",
      "epoch:46 step:36421 [D loss: 0.282890, acc: 85.16%] [G loss: 6.618180]\n",
      "epoch:46 step:36422 [D loss: 1.060146, acc: 50.00%] [G loss: 8.102703]\n",
      "epoch:46 step:36423 [D loss: 0.014208, acc: 100.00%] [G loss: 5.969540]\n",
      "epoch:46 step:36424 [D loss: 0.776726, acc: 50.78%] [G loss: 7.474589]\n",
      "epoch:46 step:36425 [D loss: 0.163555, acc: 99.22%] [G loss: 3.772581]\n",
      "epoch:46 step:36426 [D loss: 0.054300, acc: 100.00%] [G loss: 3.836526]\n",
      "epoch:46 step:36427 [D loss: 0.361284, acc: 79.69%] [G loss: 5.260991]\n",
      "epoch:46 step:36428 [D loss: 0.639357, acc: 62.50%] [G loss: 5.695882]\n",
      "epoch:46 step:36429 [D loss: 0.123107, acc: 100.00%] [G loss: 3.406562]\n",
      "epoch:46 step:36430 [D loss: 0.096684, acc: 100.00%] [G loss: 5.104360]\n",
      "epoch:46 step:36431 [D loss: 0.592258, acc: 58.59%] [G loss: 3.816818]\n",
      "epoch:46 step:36432 [D loss: 1.878112, acc: 46.88%] [G loss: 4.358608]\n",
      "epoch:46 step:36433 [D loss: 0.305250, acc: 90.62%] [G loss: 6.547106]\n",
      "epoch:46 step:36434 [D loss: 0.165983, acc: 96.88%] [G loss: 3.996933]\n",
      "epoch:46 step:36435 [D loss: 0.115264, acc: 99.22%] [G loss: 5.844450]\n",
      "epoch:46 step:36436 [D loss: 0.138976, acc: 98.44%] [G loss: 7.498713]\n",
      "epoch:46 step:36437 [D loss: 0.022617, acc: 100.00%] [G loss: 9.764097]\n",
      "epoch:46 step:36438 [D loss: 0.473364, acc: 76.56%] [G loss: 2.326200]\n",
      "epoch:46 step:36439 [D loss: 0.205290, acc: 97.66%] [G loss: 5.670038]\n",
      "epoch:46 step:36440 [D loss: 0.104433, acc: 97.66%] [G loss: 6.124210]\n",
      "epoch:46 step:36441 [D loss: 0.309956, acc: 82.81%] [G loss: 10.608257]\n",
      "epoch:46 step:36442 [D loss: 0.170185, acc: 98.44%] [G loss: 4.727126]\n",
      "epoch:46 step:36443 [D loss: 0.134287, acc: 100.00%] [G loss: 5.524562]\n",
      "epoch:46 step:36444 [D loss: 0.132716, acc: 97.66%] [G loss: 5.004816]\n",
      "epoch:46 step:36445 [D loss: 0.048935, acc: 100.00%] [G loss: 4.519609]\n",
      "epoch:46 step:36446 [D loss: 0.525585, acc: 62.50%] [G loss: 9.339224]\n",
      "epoch:46 step:36447 [D loss: 0.082372, acc: 100.00%] [G loss: 6.314173]\n",
      "epoch:46 step:36448 [D loss: 0.354770, acc: 82.81%] [G loss: 3.522189]\n",
      "epoch:46 step:36449 [D loss: 0.098172, acc: 99.22%] [G loss: 5.113438]\n",
      "epoch:46 step:36450 [D loss: 0.074167, acc: 100.00%] [G loss: 4.970520]\n",
      "epoch:46 step:36451 [D loss: 0.134235, acc: 100.00%] [G loss: 2.698323]\n",
      "epoch:46 step:36452 [D loss: 0.132119, acc: 98.44%] [G loss: 3.840996]\n",
      "epoch:46 step:36453 [D loss: 0.418332, acc: 86.72%] [G loss: 5.688368]\n",
      "epoch:46 step:36454 [D loss: 0.087039, acc: 99.22%] [G loss: 5.616292]\n",
      "epoch:46 step:36455 [D loss: 0.144266, acc: 100.00%] [G loss: 4.947789]\n",
      "epoch:46 step:36456 [D loss: 0.204004, acc: 92.97%] [G loss: 6.748704]\n",
      "epoch:46 step:36457 [D loss: 0.053521, acc: 99.22%] [G loss: 7.388646]\n",
      "epoch:46 step:36458 [D loss: 0.264752, acc: 89.84%] [G loss: 5.878221]\n",
      "epoch:46 step:36459 [D loss: 0.029533, acc: 100.00%] [G loss: 6.336029]\n",
      "epoch:46 step:36460 [D loss: 0.441365, acc: 76.56%] [G loss: 4.279508]\n",
      "epoch:46 step:36461 [D loss: 1.411559, acc: 49.22%] [G loss: 8.241287]\n",
      "epoch:46 step:36462 [D loss: 0.704718, acc: 54.69%] [G loss: 8.289953]\n",
      "epoch:46 step:36463 [D loss: 0.212188, acc: 92.97%] [G loss: 10.860288]\n",
      "epoch:46 step:36464 [D loss: 0.070446, acc: 100.00%] [G loss: 6.635923]\n",
      "epoch:46 step:36465 [D loss: 0.850219, acc: 46.09%] [G loss: 4.467627]\n",
      "epoch:46 step:36466 [D loss: 0.113109, acc: 100.00%] [G loss: 4.848518]\n",
      "epoch:46 step:36467 [D loss: 1.947006, acc: 49.22%] [G loss: 8.303753]\n",
      "epoch:46 step:36468 [D loss: 0.041745, acc: 100.00%] [G loss: 10.674841]\n",
      "epoch:46 step:36469 [D loss: 0.681303, acc: 57.03%] [G loss: 11.073540]\n",
      "epoch:46 step:36470 [D loss: 0.226112, acc: 95.31%] [G loss: 2.729824]\n",
      "epoch:46 step:36471 [D loss: 0.580090, acc: 75.00%] [G loss: 7.209429]\n",
      "epoch:46 step:36472 [D loss: 1.155227, acc: 19.53%] [G loss: 7.202395]\n",
      "epoch:46 step:36473 [D loss: 0.164536, acc: 99.22%] [G loss: 6.009330]\n",
      "epoch:46 step:36474 [D loss: 0.462912, acc: 71.88%] [G loss: 6.355997]\n",
      "epoch:46 step:36475 [D loss: 0.017575, acc: 100.00%] [G loss: 5.776316]\n",
      "epoch:46 step:36476 [D loss: 0.961442, acc: 50.00%] [G loss: 4.242171]\n",
      "epoch:46 step:36477 [D loss: 0.040276, acc: 100.00%] [G loss: 3.711071]\n",
      "epoch:46 step:36478 [D loss: 0.736639, acc: 50.78%] [G loss: 5.339869]\n",
      "epoch:46 step:36479 [D loss: 0.288146, acc: 90.62%] [G loss: 8.311021]\n",
      "epoch:46 step:36480 [D loss: 2.940068, acc: 0.00%] [G loss: 6.380105]\n",
      "epoch:46 step:36481 [D loss: 0.063796, acc: 100.00%] [G loss: 7.873479]\n",
      "epoch:46 step:36482 [D loss: 0.087627, acc: 99.22%] [G loss: 4.196906]\n",
      "epoch:46 step:36483 [D loss: 0.179119, acc: 99.22%] [G loss: 5.898105]\n",
      "epoch:46 step:36484 [D loss: 0.468780, acc: 85.94%] [G loss: 5.183326]\n",
      "epoch:46 step:36485 [D loss: 0.262112, acc: 95.31%] [G loss: 5.028458]\n",
      "epoch:46 step:36486 [D loss: 0.659858, acc: 58.59%] [G loss: 6.238575]\n",
      "epoch:46 step:36487 [D loss: 0.100347, acc: 99.22%] [G loss: 8.145311]\n",
      "epoch:46 step:36488 [D loss: 0.286802, acc: 89.84%] [G loss: 4.879175]\n",
      "epoch:46 step:36489 [D loss: 0.259541, acc: 92.97%] [G loss: 4.744737]\n",
      "epoch:46 step:36490 [D loss: 0.171672, acc: 96.09%] [G loss: 7.467993]\n",
      "epoch:46 step:36491 [D loss: 0.155611, acc: 98.44%] [G loss: 4.100881]\n",
      "epoch:46 step:36492 [D loss: 0.236362, acc: 92.19%] [G loss: 6.723206]\n",
      "epoch:46 step:36493 [D loss: 0.343634, acc: 82.81%] [G loss: 9.369620]\n",
      "epoch:46 step:36494 [D loss: 0.071165, acc: 100.00%] [G loss: 5.472538]\n",
      "epoch:46 step:36495 [D loss: 0.111068, acc: 99.22%] [G loss: 6.904241]\n",
      "epoch:46 step:36496 [D loss: 0.104542, acc: 100.00%] [G loss: 5.440777]\n",
      "epoch:46 step:36497 [D loss: 0.149381, acc: 99.22%] [G loss: 5.201957]\n",
      "epoch:46 step:36498 [D loss: 0.015260, acc: 100.00%] [G loss: 6.216421]\n",
      "epoch:46 step:36499 [D loss: 0.295452, acc: 83.59%] [G loss: 7.072462]\n",
      "epoch:46 step:36500 [D loss: 0.033458, acc: 100.00%] [G loss: 7.660396]\n",
      "epoch:46 step:36501 [D loss: 0.185058, acc: 93.75%] [G loss: 4.723748]\n",
      "epoch:46 step:36502 [D loss: 0.339985, acc: 87.50%] [G loss: 7.944259]\n",
      "epoch:46 step:36503 [D loss: 0.145634, acc: 97.66%] [G loss: 3.147084]\n",
      "epoch:46 step:36504 [D loss: 0.073086, acc: 100.00%] [G loss: 5.091178]\n",
      "epoch:46 step:36505 [D loss: 0.217677, acc: 99.22%] [G loss: 2.209843]\n",
      "epoch:46 step:36506 [D loss: 0.065555, acc: 100.00%] [G loss: 7.181550]\n",
      "epoch:46 step:36507 [D loss: 0.003581, acc: 100.00%] [G loss: 9.239367]\n",
      "epoch:46 step:36508 [D loss: 0.717092, acc: 53.12%] [G loss: 7.182154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36509 [D loss: 0.050163, acc: 100.00%] [G loss: 6.204333]\n",
      "epoch:46 step:36510 [D loss: 0.252233, acc: 89.84%] [G loss: 6.815905]\n",
      "epoch:46 step:36511 [D loss: 0.074130, acc: 100.00%] [G loss: 1.958304]\n",
      "epoch:46 step:36512 [D loss: 0.237757, acc: 92.19%] [G loss: 5.612671]\n",
      "epoch:46 step:36513 [D loss: 0.127093, acc: 99.22%] [G loss: 7.987602]\n",
      "epoch:46 step:36514 [D loss: 0.531458, acc: 62.50%] [G loss: 4.881327]\n",
      "epoch:46 step:36515 [D loss: 0.268560, acc: 93.75%] [G loss: 5.381528]\n",
      "epoch:46 step:36516 [D loss: 0.417779, acc: 76.56%] [G loss: 6.145448]\n",
      "epoch:46 step:36517 [D loss: 0.127896, acc: 98.44%] [G loss: 6.472832]\n",
      "epoch:46 step:36518 [D loss: 1.490884, acc: 42.19%] [G loss: 4.316634]\n",
      "epoch:46 step:36519 [D loss: 0.064043, acc: 100.00%] [G loss: 3.162277]\n",
      "epoch:46 step:36520 [D loss: 0.143055, acc: 98.44%] [G loss: 5.179071]\n",
      "epoch:46 step:36521 [D loss: 0.301771, acc: 87.50%] [G loss: 7.047541]\n",
      "epoch:46 step:36522 [D loss: 0.252706, acc: 89.84%] [G loss: 3.304318]\n",
      "epoch:46 step:36523 [D loss: 0.654667, acc: 58.59%] [G loss: 7.230213]\n",
      "epoch:46 step:36524 [D loss: 0.926976, acc: 46.09%] [G loss: 5.535890]\n",
      "epoch:46 step:36525 [D loss: 0.119222, acc: 100.00%] [G loss: 3.305561]\n",
      "epoch:46 step:36526 [D loss: 0.874822, acc: 39.84%] [G loss: 7.790373]\n",
      "epoch:46 step:36527 [D loss: 0.453273, acc: 68.75%] [G loss: 7.961238]\n",
      "epoch:46 step:36528 [D loss: 0.098774, acc: 100.00%] [G loss: 6.215037]\n",
      "epoch:46 step:36529 [D loss: 1.383548, acc: 36.72%] [G loss: 7.269164]\n",
      "epoch:46 step:36530 [D loss: 0.217403, acc: 97.66%] [G loss: 6.619520]\n",
      "epoch:46 step:36531 [D loss: 0.192540, acc: 96.88%] [G loss: 6.933288]\n",
      "epoch:46 step:36532 [D loss: 0.129316, acc: 100.00%] [G loss: 5.679192]\n",
      "epoch:46 step:36533 [D loss: 0.163172, acc: 98.44%] [G loss: 3.652627]\n",
      "epoch:46 step:36534 [D loss: 0.279167, acc: 92.97%] [G loss: 5.535390]\n",
      "epoch:46 step:36535 [D loss: 0.077151, acc: 100.00%] [G loss: 7.408838]\n",
      "epoch:46 step:36536 [D loss: 0.202264, acc: 96.88%] [G loss: 6.534634]\n",
      "epoch:46 step:36537 [D loss: 0.090428, acc: 100.00%] [G loss: 6.568487]\n",
      "epoch:46 step:36538 [D loss: 1.515177, acc: 42.97%] [G loss: 6.875423]\n",
      "epoch:46 step:36539 [D loss: 0.049444, acc: 100.00%] [G loss: 6.778617]\n",
      "epoch:46 step:36540 [D loss: 0.094309, acc: 100.00%] [G loss: 5.438197]\n",
      "epoch:46 step:36541 [D loss: 0.205132, acc: 93.75%] [G loss: 6.322999]\n",
      "epoch:46 step:36542 [D loss: 0.503159, acc: 63.28%] [G loss: 9.291854]\n",
      "epoch:46 step:36543 [D loss: 0.942580, acc: 35.94%] [G loss: 10.534018]\n",
      "epoch:46 step:36544 [D loss: 1.655732, acc: 23.44%] [G loss: 6.901576]\n",
      "epoch:46 step:36545 [D loss: 0.060144, acc: 100.00%] [G loss: 5.517929]\n",
      "epoch:46 step:36546 [D loss: 0.261178, acc: 95.31%] [G loss: 4.736016]\n",
      "epoch:46 step:36547 [D loss: 0.096803, acc: 100.00%] [G loss: 6.164940]\n",
      "epoch:46 step:36548 [D loss: 0.338591, acc: 92.97%] [G loss: 7.273873]\n",
      "epoch:46 step:36549 [D loss: 0.158178, acc: 98.44%] [G loss: 4.245164]\n",
      "epoch:46 step:36550 [D loss: 0.024566, acc: 100.00%] [G loss: 7.714124]\n",
      "epoch:46 step:36551 [D loss: 0.019300, acc: 100.00%] [G loss: 6.530160]\n",
      "epoch:46 step:36552 [D loss: 0.365495, acc: 82.81%] [G loss: 4.919524]\n",
      "epoch:46 step:36553 [D loss: 0.842677, acc: 44.53%] [G loss: 5.573188]\n",
      "epoch:46 step:36554 [D loss: 0.362551, acc: 78.12%] [G loss: 7.030546]\n",
      "epoch:46 step:36555 [D loss: 0.034009, acc: 100.00%] [G loss: 5.180739]\n",
      "epoch:46 step:36556 [D loss: 0.079847, acc: 100.00%] [G loss: 5.324350]\n",
      "epoch:46 step:36557 [D loss: 0.305581, acc: 85.16%] [G loss: 7.488195]\n",
      "epoch:46 step:36558 [D loss: 1.937855, acc: 46.88%] [G loss: 6.220716]\n",
      "epoch:46 step:36559 [D loss: 0.193283, acc: 95.31%] [G loss: 4.500767]\n",
      "epoch:46 step:36560 [D loss: 0.187480, acc: 96.88%] [G loss: 6.368022]\n",
      "epoch:46 step:36561 [D loss: 1.178995, acc: 16.41%] [G loss: 8.335118]\n",
      "epoch:46 step:36562 [D loss: 0.049766, acc: 100.00%] [G loss: 9.849155]\n",
      "epoch:46 step:36563 [D loss: 0.333016, acc: 82.03%] [G loss: 7.092530]\n",
      "epoch:46 step:36564 [D loss: 1.010397, acc: 46.88%] [G loss: 10.363401]\n",
      "epoch:46 step:36565 [D loss: 0.218546, acc: 96.09%] [G loss: 6.776619]\n",
      "epoch:46 step:36566 [D loss: 0.643876, acc: 65.62%] [G loss: 6.989226]\n",
      "epoch:46 step:36567 [D loss: 0.300997, acc: 91.41%] [G loss: 7.399817]\n",
      "epoch:46 step:36568 [D loss: 0.057676, acc: 99.22%] [G loss: 5.542615]\n",
      "epoch:46 step:36569 [D loss: 0.271826, acc: 90.62%] [G loss: 3.807681]\n",
      "epoch:46 step:36570 [D loss: 0.081892, acc: 100.00%] [G loss: 6.817784]\n",
      "epoch:46 step:36571 [D loss: 0.225541, acc: 92.97%] [G loss: 6.177902]\n",
      "epoch:46 step:36572 [D loss: 0.097657, acc: 99.22%] [G loss: 3.936206]\n",
      "epoch:46 step:36573 [D loss: 0.419996, acc: 83.59%] [G loss: 4.482404]\n",
      "epoch:46 step:36574 [D loss: 0.462778, acc: 64.84%] [G loss: 5.862644]\n",
      "epoch:46 step:36575 [D loss: 0.336686, acc: 85.16%] [G loss: 3.507268]\n",
      "epoch:46 step:36576 [D loss: 0.301079, acc: 89.06%] [G loss: 4.779406]\n",
      "epoch:46 step:36577 [D loss: 0.058548, acc: 100.00%] [G loss: 7.096087]\n",
      "epoch:46 step:36578 [D loss: 0.252224, acc: 96.09%] [G loss: 5.400838]\n",
      "epoch:46 step:36579 [D loss: 0.544109, acc: 69.53%] [G loss: 10.327713]\n",
      "epoch:46 step:36580 [D loss: 0.224534, acc: 92.19%] [G loss: 8.982212]\n",
      "epoch:46 step:36581 [D loss: 0.090130, acc: 100.00%] [G loss: 8.915008]\n",
      "epoch:46 step:36582 [D loss: 0.423802, acc: 72.66%] [G loss: 6.704417]\n",
      "epoch:46 step:36583 [D loss: 0.426403, acc: 75.00%] [G loss: 2.631824]\n",
      "epoch:46 step:36584 [D loss: 0.933639, acc: 52.34%] [G loss: 6.578625]\n",
      "epoch:46 step:36585 [D loss: 0.306944, acc: 92.97%] [G loss: 3.318089]\n",
      "epoch:46 step:36586 [D loss: 0.123107, acc: 99.22%] [G loss: 4.180435]\n",
      "epoch:46 step:36587 [D loss: 0.591719, acc: 62.50%] [G loss: 5.093872]\n",
      "epoch:46 step:36588 [D loss: 0.250834, acc: 93.75%] [G loss: 4.647532]\n",
      "epoch:46 step:36589 [D loss: 0.089000, acc: 100.00%] [G loss: 4.234704]\n",
      "epoch:46 step:36590 [D loss: 1.043873, acc: 50.00%] [G loss: 5.401118]\n",
      "epoch:46 step:36591 [D loss: 0.900239, acc: 50.78%] [G loss: 6.615669]\n",
      "epoch:46 step:36592 [D loss: 0.086076, acc: 100.00%] [G loss: 5.214962]\n",
      "epoch:46 step:36593 [D loss: 0.207122, acc: 96.09%] [G loss: 5.794618]\n",
      "epoch:46 step:36594 [D loss: 0.035936, acc: 100.00%] [G loss: 8.432403]\n",
      "epoch:46 step:36595 [D loss: 0.198817, acc: 97.66%] [G loss: 7.023236]\n",
      "epoch:46 step:36596 [D loss: 0.457897, acc: 64.84%] [G loss: 7.254118]\n",
      "epoch:46 step:36597 [D loss: 0.046031, acc: 100.00%] [G loss: 4.589164]\n",
      "epoch:46 step:36598 [D loss: 0.031761, acc: 100.00%] [G loss: 5.611818]\n",
      "epoch:46 step:36599 [D loss: 0.340668, acc: 87.50%] [G loss: 7.073866]\n",
      "epoch:46 step:36600 [D loss: 0.020263, acc: 100.00%] [G loss: 3.401156]\n",
      "epoch:46 step:36601 [D loss: 0.046884, acc: 99.22%] [G loss: 6.994477]\n",
      "epoch:46 step:36602 [D loss: 0.131619, acc: 99.22%] [G loss: 6.620007]\n",
      "epoch:46 step:36603 [D loss: 0.131215, acc: 98.44%] [G loss: 1.422891]\n",
      "epoch:46 step:36604 [D loss: 0.781001, acc: 50.78%] [G loss: 7.148888]\n",
      "epoch:46 step:36605 [D loss: 1.102398, acc: 48.44%] [G loss: 4.689037]\n",
      "epoch:46 step:36606 [D loss: 0.175370, acc: 98.44%] [G loss: 4.774517]\n",
      "epoch:46 step:36607 [D loss: 0.427524, acc: 66.41%] [G loss: 4.550080]\n",
      "epoch:46 step:36608 [D loss: 0.285278, acc: 97.66%] [G loss: 6.400537]\n",
      "epoch:46 step:36609 [D loss: 0.666304, acc: 57.03%] [G loss: 6.348333]\n",
      "epoch:46 step:36610 [D loss: 0.115700, acc: 99.22%] [G loss: 6.237141]\n",
      "epoch:46 step:36611 [D loss: 1.090814, acc: 50.78%] [G loss: 6.737601]\n",
      "epoch:46 step:36612 [D loss: 0.089668, acc: 100.00%] [G loss: 7.472557]\n",
      "epoch:46 step:36613 [D loss: 0.259965, acc: 97.66%] [G loss: 3.662986]\n",
      "epoch:46 step:36614 [D loss: 0.245959, acc: 92.19%] [G loss: 3.059189]\n",
      "epoch:46 step:36615 [D loss: 0.120348, acc: 98.44%] [G loss: 6.099512]\n",
      "epoch:46 step:36616 [D loss: 0.039283, acc: 100.00%] [G loss: 6.950992]\n",
      "epoch:46 step:36617 [D loss: 0.053114, acc: 100.00%] [G loss: 5.757159]\n",
      "epoch:46 step:36618 [D loss: 0.658531, acc: 58.59%] [G loss: 5.190207]\n",
      "epoch:46 step:36619 [D loss: 0.586230, acc: 57.03%] [G loss: 6.108990]\n",
      "epoch:46 step:36620 [D loss: 0.152908, acc: 98.44%] [G loss: 6.345660]\n",
      "epoch:46 step:36621 [D loss: 0.024012, acc: 100.00%] [G loss: 8.166470]\n",
      "epoch:46 step:36622 [D loss: 0.316648, acc: 89.84%] [G loss: 6.971608]\n",
      "epoch:46 step:36623 [D loss: 0.011579, acc: 100.00%] [G loss: 6.250299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36624 [D loss: 0.126336, acc: 99.22%] [G loss: 4.409722]\n",
      "epoch:46 step:36625 [D loss: 0.258109, acc: 93.75%] [G loss: 6.306884]\n",
      "epoch:46 step:36626 [D loss: 0.100703, acc: 100.00%] [G loss: 5.058264]\n",
      "epoch:46 step:36627 [D loss: 0.172138, acc: 100.00%] [G loss: 4.199067]\n",
      "epoch:46 step:36628 [D loss: 0.166582, acc: 99.22%] [G loss: 2.516487]\n",
      "epoch:46 step:36629 [D loss: 0.304610, acc: 91.41%] [G loss: 5.908978]\n",
      "epoch:46 step:36630 [D loss: 0.024122, acc: 100.00%] [G loss: 7.140846]\n",
      "epoch:46 step:36631 [D loss: 0.193152, acc: 96.88%] [G loss: 4.554947]\n",
      "epoch:46 step:36632 [D loss: 0.608188, acc: 58.59%] [G loss: 10.594990]\n",
      "epoch:46 step:36633 [D loss: 0.243501, acc: 92.19%] [G loss: 5.495877]\n",
      "epoch:46 step:36634 [D loss: 0.780349, acc: 50.78%] [G loss: 4.597115]\n",
      "epoch:46 step:36635 [D loss: 0.044421, acc: 100.00%] [G loss: 5.819109]\n",
      "epoch:46 step:36636 [D loss: 0.209827, acc: 98.44%] [G loss: 6.803857]\n",
      "epoch:46 step:36637 [D loss: 0.052859, acc: 100.00%] [G loss: 10.170654]\n",
      "epoch:46 step:36638 [D loss: 0.702878, acc: 57.03%] [G loss: 6.886767]\n",
      "epoch:46 step:36639 [D loss: 0.069708, acc: 100.00%] [G loss: 8.178659]\n",
      "epoch:46 step:36640 [D loss: 0.907735, acc: 50.00%] [G loss: 6.262431]\n",
      "epoch:46 step:36641 [D loss: 0.204020, acc: 96.88%] [G loss: 8.211267]\n",
      "epoch:46 step:36642 [D loss: 0.073904, acc: 100.00%] [G loss: 3.864370]\n",
      "epoch:46 step:36643 [D loss: 0.475252, acc: 85.16%] [G loss: 5.314005]\n",
      "epoch:46 step:36644 [D loss: 0.114946, acc: 99.22%] [G loss: 7.559497]\n",
      "epoch:46 step:36645 [D loss: 0.156476, acc: 99.22%] [G loss: 7.119005]\n",
      "epoch:46 step:36646 [D loss: 0.446049, acc: 89.06%] [G loss: 7.719499]\n",
      "epoch:46 step:36647 [D loss: 0.028514, acc: 100.00%] [G loss: 6.605849]\n",
      "epoch:46 step:36648 [D loss: 0.037923, acc: 100.00%] [G loss: 4.805463]\n",
      "epoch:46 step:36649 [D loss: 0.176422, acc: 96.88%] [G loss: 6.527422]\n",
      "epoch:46 step:36650 [D loss: 0.684017, acc: 55.47%] [G loss: 5.728139]\n",
      "epoch:46 step:36651 [D loss: 0.106107, acc: 100.00%] [G loss: 3.073936]\n",
      "epoch:46 step:36652 [D loss: 0.897600, acc: 46.88%] [G loss: 9.183691]\n",
      "epoch:46 step:36653 [D loss: 0.289954, acc: 92.19%] [G loss: 7.003932]\n",
      "epoch:46 step:36654 [D loss: 0.853502, acc: 50.78%] [G loss: 5.148426]\n",
      "epoch:46 step:36655 [D loss: 0.188975, acc: 96.88%] [G loss: 3.795604]\n",
      "epoch:46 step:36656 [D loss: 0.297259, acc: 89.84%] [G loss: 5.622924]\n",
      "epoch:46 step:36657 [D loss: 0.474812, acc: 65.62%] [G loss: 7.427185]\n",
      "epoch:46 step:36658 [D loss: 0.377893, acc: 87.50%] [G loss: 7.096304]\n",
      "epoch:46 step:36659 [D loss: 0.080494, acc: 100.00%] [G loss: 6.011972]\n",
      "epoch:46 step:36660 [D loss: 0.271082, acc: 89.84%] [G loss: 5.746511]\n",
      "epoch:46 step:36661 [D loss: 0.098711, acc: 100.00%] [G loss: 6.601035]\n",
      "epoch:46 step:36662 [D loss: 1.175937, acc: 48.44%] [G loss: 7.636662]\n",
      "epoch:46 step:36663 [D loss: 0.294615, acc: 85.94%] [G loss: 5.399318]\n",
      "epoch:46 step:36664 [D loss: 0.154500, acc: 99.22%] [G loss: 4.660520]\n",
      "epoch:46 step:36665 [D loss: 0.487871, acc: 68.75%] [G loss: 5.840722]\n",
      "epoch:46 step:36666 [D loss: 1.648244, acc: 50.00%] [G loss: 7.561666]\n",
      "epoch:46 step:36667 [D loss: 0.071990, acc: 99.22%] [G loss: 7.352007]\n",
      "epoch:46 step:36668 [D loss: 0.388976, acc: 88.28%] [G loss: 6.319897]\n",
      "epoch:46 step:36669 [D loss: 0.239716, acc: 95.31%] [G loss: 6.007240]\n",
      "epoch:46 step:36670 [D loss: 0.123985, acc: 97.66%] [G loss: 6.720873]\n",
      "epoch:46 step:36671 [D loss: 0.058419, acc: 100.00%] [G loss: 4.669351]\n",
      "epoch:46 step:36672 [D loss: 0.074651, acc: 99.22%] [G loss: 6.002530]\n",
      "epoch:46 step:36673 [D loss: 0.325144, acc: 93.75%] [G loss: 2.281279]\n",
      "epoch:46 step:36674 [D loss: 0.823659, acc: 51.56%] [G loss: 8.436928]\n",
      "epoch:46 step:36675 [D loss: 0.290738, acc: 85.94%] [G loss: 6.140326]\n",
      "epoch:46 step:36676 [D loss: 0.194957, acc: 96.88%] [G loss: 8.020849]\n",
      "epoch:46 step:36677 [D loss: 0.249061, acc: 92.19%] [G loss: 5.314170]\n",
      "epoch:46 step:36678 [D loss: 0.128265, acc: 98.44%] [G loss: 5.849398]\n",
      "epoch:46 step:36679 [D loss: 0.485503, acc: 65.62%] [G loss: 6.216322]\n",
      "epoch:46 step:36680 [D loss: 0.053891, acc: 99.22%] [G loss: 5.130686]\n",
      "epoch:46 step:36681 [D loss: 0.078017, acc: 100.00%] [G loss: 3.463347]\n",
      "epoch:46 step:36682 [D loss: 0.181710, acc: 94.53%] [G loss: 5.155884]\n",
      "epoch:46 step:36683 [D loss: 0.274909, acc: 92.97%] [G loss: 4.437464]\n",
      "epoch:46 step:36684 [D loss: 0.101285, acc: 99.22%] [G loss: 4.386049]\n",
      "epoch:46 step:36685 [D loss: 0.038048, acc: 100.00%] [G loss: 3.904992]\n",
      "epoch:46 step:36686 [D loss: 0.033391, acc: 100.00%] [G loss: 9.407813]\n",
      "epoch:46 step:36687 [D loss: 0.304005, acc: 93.75%] [G loss: 6.884512]\n",
      "epoch:46 step:36688 [D loss: 0.178566, acc: 96.88%] [G loss: 7.054059]\n",
      "epoch:46 step:36689 [D loss: 1.010409, acc: 50.00%] [G loss: 7.595807]\n",
      "epoch:46 step:36690 [D loss: 0.272844, acc: 97.66%] [G loss: 6.343234]\n",
      "epoch:46 step:36691 [D loss: 2.299951, acc: 41.41%] [G loss: 8.114885]\n",
      "epoch:46 step:36692 [D loss: 0.318211, acc: 87.50%] [G loss: 4.326143]\n",
      "epoch:46 step:36693 [D loss: 0.183368, acc: 98.44%] [G loss: 8.422945]\n",
      "epoch:46 step:36694 [D loss: 0.635192, acc: 62.50%] [G loss: 7.297770]\n",
      "epoch:46 step:36695 [D loss: 0.295406, acc: 90.62%] [G loss: 5.793757]\n",
      "epoch:46 step:36696 [D loss: 0.010699, acc: 100.00%] [G loss: 6.139460]\n",
      "epoch:46 step:36697 [D loss: 0.197287, acc: 94.53%] [G loss: 5.483611]\n",
      "epoch:46 step:36698 [D loss: 0.091453, acc: 99.22%] [G loss: 6.696551]\n",
      "epoch:46 step:36699 [D loss: 0.057312, acc: 100.00%] [G loss: 7.043805]\n",
      "epoch:46 step:36700 [D loss: 0.999629, acc: 50.78%] [G loss: 4.475470]\n",
      "epoch:46 step:36701 [D loss: 0.064783, acc: 100.00%] [G loss: 4.176527]\n",
      "epoch:46 step:36702 [D loss: 0.250776, acc: 93.75%] [G loss: 3.043491]\n",
      "epoch:46 step:36703 [D loss: 0.425766, acc: 72.66%] [G loss: 6.378520]\n",
      "epoch:46 step:36704 [D loss: 0.040244, acc: 100.00%] [G loss: 5.059880]\n",
      "epoch:46 step:36705 [D loss: 0.266401, acc: 92.97%] [G loss: 6.295336]\n",
      "epoch:46 step:36706 [D loss: 0.054245, acc: 100.00%] [G loss: 6.059108]\n",
      "epoch:46 step:36707 [D loss: 0.514997, acc: 71.88%] [G loss: 5.790220]\n",
      "epoch:47 step:36708 [D loss: 0.029563, acc: 100.00%] [G loss: 5.018834]\n",
      "epoch:47 step:36709 [D loss: 0.103359, acc: 100.00%] [G loss: 5.503492]\n",
      "epoch:47 step:36710 [D loss: 0.018536, acc: 100.00%] [G loss: 6.774177]\n",
      "epoch:47 step:36711 [D loss: 0.012379, acc: 100.00%] [G loss: 7.492952]\n",
      "epoch:47 step:36712 [D loss: 0.141225, acc: 99.22%] [G loss: 5.030820]\n",
      "epoch:47 step:36713 [D loss: 0.665360, acc: 54.69%] [G loss: 5.431361]\n",
      "epoch:47 step:36714 [D loss: 0.042505, acc: 100.00%] [G loss: 6.108466]\n",
      "epoch:47 step:36715 [D loss: 0.158437, acc: 97.66%] [G loss: 2.158380]\n",
      "epoch:47 step:36716 [D loss: 0.120604, acc: 99.22%] [G loss: 6.996692]\n",
      "epoch:47 step:36717 [D loss: 0.040176, acc: 100.00%] [G loss: 4.771732]\n",
      "epoch:47 step:36718 [D loss: 0.558782, acc: 66.41%] [G loss: 5.347530]\n",
      "epoch:47 step:36719 [D loss: 0.625978, acc: 58.59%] [G loss: 5.316195]\n",
      "epoch:47 step:36720 [D loss: 0.038168, acc: 100.00%] [G loss: 7.911481]\n",
      "epoch:47 step:36721 [D loss: 0.178518, acc: 95.31%] [G loss: 3.667195]\n",
      "epoch:47 step:36722 [D loss: 0.706163, acc: 56.25%] [G loss: 5.402764]\n",
      "epoch:47 step:36723 [D loss: 0.340113, acc: 82.03%] [G loss: 8.118131]\n",
      "epoch:47 step:36724 [D loss: 0.112726, acc: 100.00%] [G loss: 5.821136]\n",
      "epoch:47 step:36725 [D loss: 0.016891, acc: 100.00%] [G loss: 3.431991]\n",
      "epoch:47 step:36726 [D loss: 0.376204, acc: 82.81%] [G loss: 2.172098]\n",
      "epoch:47 step:36727 [D loss: 0.581057, acc: 59.38%] [G loss: 4.802686]\n",
      "epoch:47 step:36728 [D loss: 0.519314, acc: 60.16%] [G loss: 3.396658]\n",
      "epoch:47 step:36729 [D loss: 0.104000, acc: 99.22%] [G loss: 3.980505]\n",
      "epoch:47 step:36730 [D loss: 0.407716, acc: 89.06%] [G loss: 5.218080]\n",
      "epoch:47 step:36731 [D loss: 0.247604, acc: 96.88%] [G loss: 6.817774]\n",
      "epoch:47 step:36732 [D loss: 0.338868, acc: 81.25%] [G loss: 4.895401]\n",
      "epoch:47 step:36733 [D loss: 0.303166, acc: 87.50%] [G loss: 5.596138]\n",
      "epoch:47 step:36734 [D loss: 0.737354, acc: 52.34%] [G loss: 4.756269]\n",
      "epoch:47 step:36735 [D loss: 0.736313, acc: 53.91%] [G loss: 2.565908]\n",
      "epoch:47 step:36736 [D loss: 1.186893, acc: 45.31%] [G loss: 8.374792]\n",
      "epoch:47 step:36737 [D loss: 0.114078, acc: 99.22%] [G loss: 7.799706]\n",
      "epoch:47 step:36738 [D loss: 0.116133, acc: 97.66%] [G loss: 6.883614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36739 [D loss: 0.090433, acc: 100.00%] [G loss: 5.504453]\n",
      "epoch:47 step:36740 [D loss: 0.172111, acc: 95.31%] [G loss: 6.303418]\n",
      "epoch:47 step:36741 [D loss: 0.391099, acc: 89.84%] [G loss: 9.278637]\n",
      "epoch:47 step:36742 [D loss: 0.093195, acc: 98.44%] [G loss: 5.862666]\n",
      "epoch:47 step:36743 [D loss: 0.838720, acc: 50.00%] [G loss: 7.954576]\n",
      "epoch:47 step:36744 [D loss: 1.407375, acc: 16.41%] [G loss: 8.981178]\n",
      "epoch:47 step:36745 [D loss: 0.985075, acc: 46.88%] [G loss: 9.389244]\n",
      "epoch:47 step:36746 [D loss: 0.317492, acc: 90.62%] [G loss: 4.656474]\n",
      "epoch:47 step:36747 [D loss: 0.096050, acc: 100.00%] [G loss: 6.792843]\n",
      "epoch:47 step:36748 [D loss: 0.223942, acc: 97.66%] [G loss: 3.917832]\n",
      "epoch:47 step:36749 [D loss: 0.263940, acc: 90.62%] [G loss: 6.557617]\n",
      "epoch:47 step:36750 [D loss: 0.065805, acc: 100.00%] [G loss: 4.133101]\n",
      "epoch:47 step:36751 [D loss: 0.200444, acc: 92.97%] [G loss: 4.833951]\n",
      "epoch:47 step:36752 [D loss: 0.107733, acc: 100.00%] [G loss: 5.580885]\n",
      "epoch:47 step:36753 [D loss: 0.121678, acc: 99.22%] [G loss: 6.903464]\n",
      "epoch:47 step:36754 [D loss: 0.152768, acc: 96.09%] [G loss: 6.547344]\n",
      "epoch:47 step:36755 [D loss: 0.231262, acc: 90.62%] [G loss: 10.359152]\n",
      "epoch:47 step:36756 [D loss: 0.575733, acc: 66.41%] [G loss: 6.688323]\n",
      "epoch:47 step:36757 [D loss: 0.032682, acc: 100.00%] [G loss: 3.471071]\n",
      "epoch:47 step:36758 [D loss: 0.177499, acc: 98.44%] [G loss: 6.584963]\n",
      "epoch:47 step:36759 [D loss: 0.369405, acc: 89.84%] [G loss: 4.667394]\n",
      "epoch:47 step:36760 [D loss: 0.130381, acc: 97.66%] [G loss: 6.188604]\n",
      "epoch:47 step:36761 [D loss: 0.056855, acc: 100.00%] [G loss: 3.348703]\n",
      "epoch:47 step:36762 [D loss: 0.471024, acc: 67.19%] [G loss: 7.774681]\n",
      "epoch:47 step:36763 [D loss: 0.048181, acc: 100.00%] [G loss: 4.761201]\n",
      "epoch:47 step:36764 [D loss: 0.148060, acc: 99.22%] [G loss: 5.607741]\n",
      "epoch:47 step:36765 [D loss: 1.127192, acc: 50.78%] [G loss: 7.358619]\n",
      "epoch:47 step:36766 [D loss: 0.229053, acc: 96.09%] [G loss: 5.215795]\n",
      "epoch:47 step:36767 [D loss: 0.240483, acc: 96.88%] [G loss: 6.038650]\n",
      "epoch:47 step:36768 [D loss: 0.020912, acc: 100.00%] [G loss: 4.767525]\n",
      "epoch:47 step:36769 [D loss: 0.460301, acc: 69.53%] [G loss: 7.464648]\n",
      "epoch:47 step:36770 [D loss: 0.042999, acc: 100.00%] [G loss: 6.902428]\n",
      "epoch:47 step:36771 [D loss: 0.134843, acc: 100.00%] [G loss: 6.179819]\n",
      "epoch:47 step:36772 [D loss: 1.003250, acc: 50.78%] [G loss: 7.366224]\n",
      "epoch:47 step:36773 [D loss: 1.036364, acc: 50.78%] [G loss: 5.772633]\n",
      "epoch:47 step:36774 [D loss: 0.448993, acc: 73.44%] [G loss: 7.822886]\n",
      "epoch:47 step:36775 [D loss: 0.846208, acc: 52.34%] [G loss: 6.059723]\n",
      "epoch:47 step:36776 [D loss: 0.289555, acc: 91.41%] [G loss: 4.698965]\n",
      "epoch:47 step:36777 [D loss: 0.609732, acc: 60.94%] [G loss: 4.066245]\n",
      "epoch:47 step:36778 [D loss: 0.143909, acc: 99.22%] [G loss: 2.342321]\n",
      "epoch:47 step:36779 [D loss: 0.181271, acc: 98.44%] [G loss: 5.872709]\n",
      "epoch:47 step:36780 [D loss: 0.543191, acc: 75.78%] [G loss: 2.862818]\n",
      "epoch:47 step:36781 [D loss: 0.941054, acc: 52.34%] [G loss: 10.044312]\n",
      "epoch:47 step:36782 [D loss: 0.873141, acc: 52.34%] [G loss: 5.626016]\n",
      "epoch:47 step:36783 [D loss: 0.547200, acc: 71.09%] [G loss: 3.613281]\n",
      "epoch:47 step:36784 [D loss: 0.160397, acc: 98.44%] [G loss: 5.567580]\n",
      "epoch:47 step:36785 [D loss: 0.946142, acc: 52.34%] [G loss: 6.018352]\n",
      "epoch:47 step:36786 [D loss: 0.022614, acc: 100.00%] [G loss: 6.686508]\n",
      "epoch:47 step:36787 [D loss: 0.283169, acc: 88.28%] [G loss: 6.787022]\n",
      "epoch:47 step:36788 [D loss: 0.062427, acc: 100.00%] [G loss: 5.412424]\n",
      "epoch:47 step:36789 [D loss: 0.272650, acc: 88.28%] [G loss: 8.249980]\n",
      "epoch:47 step:36790 [D loss: 0.019947, acc: 100.00%] [G loss: 4.520629]\n",
      "epoch:47 step:36791 [D loss: 0.290170, acc: 93.75%] [G loss: 3.335526]\n",
      "epoch:47 step:36792 [D loss: 0.043884, acc: 100.00%] [G loss: 7.054572]\n",
      "epoch:47 step:36793 [D loss: 0.014404, acc: 100.00%] [G loss: 10.051159]\n",
      "epoch:47 step:36794 [D loss: 0.184463, acc: 96.88%] [G loss: 3.897628]\n",
      "epoch:47 step:36795 [D loss: 0.122822, acc: 98.44%] [G loss: 2.514438]\n",
      "epoch:47 step:36796 [D loss: 0.041334, acc: 100.00%] [G loss: 8.062136]\n",
      "epoch:47 step:36797 [D loss: 0.555775, acc: 62.50%] [G loss: 5.497028]\n",
      "epoch:47 step:36798 [D loss: 0.321504, acc: 81.25%] [G loss: 4.880618]\n",
      "epoch:47 step:36799 [D loss: 0.029933, acc: 100.00%] [G loss: 8.336415]\n",
      "epoch:47 step:36800 [D loss: 0.439184, acc: 67.97%] [G loss: 8.548019]\n",
      "epoch:47 step:36801 [D loss: 0.042017, acc: 100.00%] [G loss: 10.299065]\n",
      "epoch:47 step:36802 [D loss: 0.097316, acc: 99.22%] [G loss: 6.779852]\n",
      "epoch:47 step:36803 [D loss: 0.131642, acc: 99.22%] [G loss: 4.184252]\n",
      "epoch:47 step:36804 [D loss: 0.288580, acc: 95.31%] [G loss: 6.036124]\n",
      "epoch:47 step:36805 [D loss: 0.059827, acc: 100.00%] [G loss: 6.761485]\n",
      "epoch:47 step:36806 [D loss: 0.027386, acc: 100.00%] [G loss: 6.735511]\n",
      "epoch:47 step:36807 [D loss: 0.163659, acc: 97.66%] [G loss: 4.268084]\n",
      "epoch:47 step:36808 [D loss: 0.052061, acc: 100.00%] [G loss: 5.850045]\n",
      "epoch:47 step:36809 [D loss: 0.104763, acc: 100.00%] [G loss: 6.849410]\n",
      "epoch:47 step:36810 [D loss: 0.066179, acc: 100.00%] [G loss: 5.316928]\n",
      "epoch:47 step:36811 [D loss: 0.357136, acc: 75.78%] [G loss: 8.417522]\n",
      "epoch:47 step:36812 [D loss: 0.561665, acc: 61.72%] [G loss: 6.720248]\n",
      "epoch:47 step:36813 [D loss: 1.056039, acc: 50.78%] [G loss: 7.950953]\n",
      "epoch:47 step:36814 [D loss: 0.899856, acc: 32.03%] [G loss: 3.772285]\n",
      "epoch:47 step:36815 [D loss: 0.047036, acc: 100.00%] [G loss: 7.910516]\n",
      "epoch:47 step:36816 [D loss: 0.291337, acc: 85.16%] [G loss: 5.411657]\n",
      "epoch:47 step:36817 [D loss: 0.432943, acc: 68.75%] [G loss: 7.313952]\n",
      "epoch:47 step:36818 [D loss: 0.037489, acc: 100.00%] [G loss: 4.027567]\n",
      "epoch:47 step:36819 [D loss: 0.223044, acc: 92.19%] [G loss: 5.093919]\n",
      "epoch:47 step:36820 [D loss: 0.541264, acc: 69.53%] [G loss: 8.695730]\n",
      "epoch:47 step:36821 [D loss: 0.419949, acc: 75.78%] [G loss: 5.857431]\n",
      "epoch:47 step:36822 [D loss: 0.163991, acc: 100.00%] [G loss: 4.552572]\n",
      "epoch:47 step:36823 [D loss: 0.750075, acc: 53.12%] [G loss: 7.220934]\n",
      "epoch:47 step:36824 [D loss: 0.390945, acc: 71.09%] [G loss: 14.345440]\n",
      "epoch:47 step:36825 [D loss: 0.600220, acc: 63.28%] [G loss: 2.968627]\n",
      "epoch:47 step:36826 [D loss: 0.115224, acc: 100.00%] [G loss: 4.565749]\n",
      "epoch:47 step:36827 [D loss: 0.126113, acc: 100.00%] [G loss: 3.124864]\n",
      "epoch:47 step:36828 [D loss: 0.307922, acc: 89.06%] [G loss: 7.151250]\n",
      "epoch:47 step:36829 [D loss: 0.135884, acc: 98.44%] [G loss: 5.509769]\n",
      "epoch:47 step:36830 [D loss: 0.163021, acc: 96.09%] [G loss: 2.286377]\n",
      "epoch:47 step:36831 [D loss: 0.545745, acc: 73.44%] [G loss: 6.746146]\n",
      "epoch:47 step:36832 [D loss: 0.537739, acc: 74.22%] [G loss: 4.644451]\n",
      "epoch:47 step:36833 [D loss: 0.054482, acc: 100.00%] [G loss: 7.067608]\n",
      "epoch:47 step:36834 [D loss: 0.586372, acc: 60.94%] [G loss: 4.541682]\n",
      "epoch:47 step:36835 [D loss: 0.053422, acc: 100.00%] [G loss: 3.412024]\n",
      "epoch:47 step:36836 [D loss: 0.600385, acc: 67.19%] [G loss: 6.815754]\n",
      "epoch:47 step:36837 [D loss: 0.081946, acc: 99.22%] [G loss: 3.462332]\n",
      "epoch:47 step:36838 [D loss: 0.065877, acc: 100.00%] [G loss: 5.184560]\n",
      "epoch:47 step:36839 [D loss: 1.116741, acc: 32.03%] [G loss: 5.266341]\n",
      "epoch:47 step:36840 [D loss: 0.018967, acc: 100.00%] [G loss: 5.558719]\n",
      "epoch:47 step:36841 [D loss: 0.028641, acc: 100.00%] [G loss: 8.796206]\n",
      "epoch:47 step:36842 [D loss: 0.124470, acc: 99.22%] [G loss: 4.097795]\n",
      "epoch:47 step:36843 [D loss: 0.117668, acc: 98.44%] [G loss: 7.911767]\n",
      "epoch:47 step:36844 [D loss: 0.053547, acc: 100.00%] [G loss: 5.602613]\n",
      "epoch:47 step:36845 [D loss: 1.149920, acc: 42.19%] [G loss: 9.048454]\n",
      "epoch:47 step:36846 [D loss: 0.011263, acc: 100.00%] [G loss: 6.452523]\n",
      "epoch:47 step:36847 [D loss: 0.205267, acc: 89.84%] [G loss: 6.265915]\n",
      "epoch:47 step:36848 [D loss: 0.250644, acc: 94.53%] [G loss: 7.849704]\n",
      "epoch:47 step:36849 [D loss: 0.189322, acc: 96.88%] [G loss: 4.202459]\n",
      "epoch:47 step:36850 [D loss: 0.322112, acc: 85.94%] [G loss: 6.834112]\n",
      "epoch:47 step:36851 [D loss: 0.146403, acc: 100.00%] [G loss: 6.266692]\n",
      "epoch:47 step:36852 [D loss: 0.060685, acc: 100.00%] [G loss: 4.964154]\n",
      "epoch:47 step:36853 [D loss: 0.364362, acc: 92.97%] [G loss: 4.297698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36854 [D loss: 0.136338, acc: 98.44%] [G loss: 3.846100]\n",
      "epoch:47 step:36855 [D loss: 0.100555, acc: 99.22%] [G loss: 5.261794]\n",
      "epoch:47 step:36856 [D loss: 0.106479, acc: 100.00%] [G loss: 5.073410]\n",
      "epoch:47 step:36857 [D loss: 0.141189, acc: 98.44%] [G loss: 4.832304]\n",
      "epoch:47 step:36858 [D loss: 0.819327, acc: 50.78%] [G loss: 8.148965]\n",
      "epoch:47 step:36859 [D loss: 0.209390, acc: 95.31%] [G loss: 3.899941]\n",
      "epoch:47 step:36860 [D loss: 0.101394, acc: 100.00%] [G loss: 7.845596]\n",
      "epoch:47 step:36861 [D loss: 0.085649, acc: 100.00%] [G loss: 10.015720]\n",
      "epoch:47 step:36862 [D loss: 0.359599, acc: 80.47%] [G loss: 3.759303]\n",
      "epoch:47 step:36863 [D loss: 0.199232, acc: 96.09%] [G loss: 5.673734]\n",
      "epoch:47 step:36864 [D loss: 1.150939, acc: 49.22%] [G loss: 7.625706]\n",
      "epoch:47 step:36865 [D loss: 0.382981, acc: 89.06%] [G loss: 5.331759]\n",
      "epoch:47 step:36866 [D loss: 0.695089, acc: 53.12%] [G loss: 5.779263]\n",
      "epoch:47 step:36867 [D loss: 0.280672, acc: 91.41%] [G loss: 3.433382]\n",
      "epoch:47 step:36868 [D loss: 0.107032, acc: 98.44%] [G loss: 9.916698]\n",
      "epoch:47 step:36869 [D loss: 0.096019, acc: 99.22%] [G loss: 4.792113]\n",
      "epoch:47 step:36870 [D loss: 0.297920, acc: 86.72%] [G loss: 7.402560]\n",
      "epoch:47 step:36871 [D loss: 0.106578, acc: 100.00%] [G loss: 5.216847]\n",
      "epoch:47 step:36872 [D loss: 0.161311, acc: 98.44%] [G loss: 4.159695]\n",
      "epoch:47 step:36873 [D loss: 0.384651, acc: 71.88%] [G loss: 9.845526]\n",
      "epoch:47 step:36874 [D loss: 0.137527, acc: 100.00%] [G loss: 6.946275]\n",
      "epoch:47 step:36875 [D loss: 0.018424, acc: 100.00%] [G loss: 7.846703]\n",
      "epoch:47 step:36876 [D loss: 0.724041, acc: 52.34%] [G loss: 8.350747]\n",
      "epoch:47 step:36877 [D loss: 1.254346, acc: 50.00%] [G loss: 6.919126]\n",
      "epoch:47 step:36878 [D loss: 0.580547, acc: 59.38%] [G loss: 6.971750]\n",
      "epoch:47 step:36879 [D loss: 0.216748, acc: 93.75%] [G loss: 7.774026]\n",
      "epoch:47 step:36880 [D loss: 1.324846, acc: 47.66%] [G loss: 4.138521]\n",
      "epoch:47 step:36881 [D loss: 0.107130, acc: 100.00%] [G loss: 6.760568]\n",
      "epoch:47 step:36882 [D loss: 0.176259, acc: 96.09%] [G loss: 7.079587]\n",
      "epoch:47 step:36883 [D loss: 0.584919, acc: 70.31%] [G loss: 7.667822]\n",
      "epoch:47 step:36884 [D loss: 0.184658, acc: 94.53%] [G loss: 4.250278]\n",
      "epoch:47 step:36885 [D loss: 0.706558, acc: 57.03%] [G loss: 6.218030]\n",
      "epoch:47 step:36886 [D loss: 0.246157, acc: 93.75%] [G loss: 5.277248]\n",
      "epoch:47 step:36887 [D loss: 1.183503, acc: 49.22%] [G loss: 5.113503]\n",
      "epoch:47 step:36888 [D loss: 0.073286, acc: 100.00%] [G loss: 8.302070]\n",
      "epoch:47 step:36889 [D loss: 1.252762, acc: 17.19%] [G loss: 4.148726]\n",
      "epoch:47 step:36890 [D loss: 0.061426, acc: 100.00%] [G loss: 4.357925]\n",
      "epoch:47 step:36891 [D loss: 0.256928, acc: 92.97%] [G loss: 3.400808]\n",
      "epoch:47 step:36892 [D loss: 0.644839, acc: 54.69%] [G loss: 6.330830]\n",
      "epoch:47 step:36893 [D loss: 0.356311, acc: 76.56%] [G loss: 7.355104]\n",
      "epoch:47 step:36894 [D loss: 0.059081, acc: 100.00%] [G loss: 4.769194]\n",
      "epoch:47 step:36895 [D loss: 0.151869, acc: 98.44%] [G loss: 5.784823]\n",
      "epoch:47 step:36896 [D loss: 0.045371, acc: 100.00%] [G loss: 7.076179]\n",
      "epoch:47 step:36897 [D loss: 0.148174, acc: 99.22%] [G loss: 5.671328]\n",
      "epoch:47 step:36898 [D loss: 0.291518, acc: 93.75%] [G loss: 4.445327]\n",
      "epoch:47 step:36899 [D loss: 0.136202, acc: 100.00%] [G loss: 6.728992]\n",
      "epoch:47 step:36900 [D loss: 0.552804, acc: 64.06%] [G loss: 7.916243]\n",
      "epoch:47 step:36901 [D loss: 0.059762, acc: 100.00%] [G loss: 4.095357]\n",
      "epoch:47 step:36902 [D loss: 0.354692, acc: 85.16%] [G loss: 4.112173]\n",
      "epoch:47 step:36903 [D loss: 1.091053, acc: 22.66%] [G loss: 7.978672]\n",
      "epoch:47 step:36904 [D loss: 0.191182, acc: 97.66%] [G loss: 5.858144]\n",
      "epoch:47 step:36905 [D loss: 0.328872, acc: 84.38%] [G loss: 7.394547]\n",
      "epoch:47 step:36906 [D loss: 0.179843, acc: 99.22%] [G loss: 6.742591]\n",
      "epoch:47 step:36907 [D loss: 0.012802, acc: 100.00%] [G loss: 6.436730]\n",
      "epoch:47 step:36908 [D loss: 0.166138, acc: 97.66%] [G loss: 6.593416]\n",
      "epoch:47 step:36909 [D loss: 0.258543, acc: 92.97%] [G loss: 7.276741]\n",
      "epoch:47 step:36910 [D loss: 0.756857, acc: 56.25%] [G loss: 6.030645]\n",
      "epoch:47 step:36911 [D loss: 0.233226, acc: 96.09%] [G loss: 6.268791]\n",
      "epoch:47 step:36912 [D loss: 0.264705, acc: 92.97%] [G loss: 4.011785]\n",
      "epoch:47 step:36913 [D loss: 0.265282, acc: 96.88%] [G loss: 5.590285]\n",
      "epoch:47 step:36914 [D loss: 1.339200, acc: 20.31%] [G loss: 9.505280]\n",
      "epoch:47 step:36915 [D loss: 0.025797, acc: 100.00%] [G loss: 7.817874]\n",
      "epoch:47 step:36916 [D loss: 0.645831, acc: 57.03%] [G loss: 6.870577]\n",
      "epoch:47 step:36917 [D loss: 0.489315, acc: 82.03%] [G loss: 8.000011]\n",
      "epoch:47 step:36918 [D loss: 0.968505, acc: 51.56%] [G loss: 5.393623]\n",
      "epoch:47 step:36919 [D loss: 0.340641, acc: 82.03%] [G loss: 4.204632]\n",
      "epoch:47 step:36920 [D loss: 0.585095, acc: 57.81%] [G loss: 9.236300]\n",
      "epoch:47 step:36921 [D loss: 0.279238, acc: 88.28%] [G loss: 7.872069]\n",
      "epoch:47 step:36922 [D loss: 0.171938, acc: 100.00%] [G loss: 3.927554]\n",
      "epoch:47 step:36923 [D loss: 0.369073, acc: 83.59%] [G loss: 4.402163]\n",
      "epoch:47 step:36924 [D loss: 0.142764, acc: 99.22%] [G loss: 5.767510]\n",
      "epoch:47 step:36925 [D loss: 1.484569, acc: 50.00%] [G loss: 6.949145]\n",
      "epoch:47 step:36926 [D loss: 0.264405, acc: 90.62%] [G loss: 6.365095]\n",
      "epoch:47 step:36927 [D loss: 0.483476, acc: 72.66%] [G loss: 4.010641]\n",
      "epoch:47 step:36928 [D loss: 0.289247, acc: 89.06%] [G loss: 4.189002]\n",
      "epoch:47 step:36929 [D loss: 0.035425, acc: 100.00%] [G loss: 5.261312]\n",
      "epoch:47 step:36930 [D loss: 1.241456, acc: 50.78%] [G loss: 3.960194]\n",
      "epoch:47 step:36931 [D loss: 0.360141, acc: 90.62%] [G loss: 4.548538]\n",
      "epoch:47 step:36932 [D loss: 0.202372, acc: 96.88%] [G loss: 3.060327]\n",
      "epoch:47 step:36933 [D loss: 0.116790, acc: 100.00%] [G loss: 5.419461]\n",
      "epoch:47 step:36934 [D loss: 0.192306, acc: 96.09%] [G loss: 6.161236]\n",
      "epoch:47 step:36935 [D loss: 0.579443, acc: 61.72%] [G loss: 5.239692]\n",
      "epoch:47 step:36936 [D loss: 0.290412, acc: 87.50%] [G loss: 9.290702]\n",
      "epoch:47 step:36937 [D loss: 1.932832, acc: 1.56%] [G loss: 6.637257]\n",
      "epoch:47 step:36938 [D loss: 0.080658, acc: 100.00%] [G loss: 8.204487]\n",
      "epoch:47 step:36939 [D loss: 0.464236, acc: 66.41%] [G loss: 3.755006]\n",
      "epoch:47 step:36940 [D loss: 0.037306, acc: 100.00%] [G loss: 4.132281]\n",
      "epoch:47 step:36941 [D loss: 1.463290, acc: 47.66%] [G loss: 6.761923]\n",
      "epoch:47 step:36942 [D loss: 1.023829, acc: 34.38%] [G loss: 6.909600]\n",
      "epoch:47 step:36943 [D loss: 1.012162, acc: 25.00%] [G loss: 5.918275]\n",
      "epoch:47 step:36944 [D loss: 0.044879, acc: 100.00%] [G loss: 4.939299]\n",
      "epoch:47 step:36945 [D loss: 2.193574, acc: 41.41%] [G loss: 8.477489]\n",
      "epoch:47 step:36946 [D loss: 0.091964, acc: 100.00%] [G loss: 3.382852]\n",
      "epoch:47 step:36947 [D loss: 1.103826, acc: 50.78%] [G loss: 5.597201]\n",
      "epoch:47 step:36948 [D loss: 0.211872, acc: 93.75%] [G loss: 7.135112]\n",
      "epoch:47 step:36949 [D loss: 0.038198, acc: 100.00%] [G loss: 8.045233]\n",
      "epoch:47 step:36950 [D loss: 0.071894, acc: 100.00%] [G loss: 5.478486]\n",
      "epoch:47 step:36951 [D loss: 0.030831, acc: 100.00%] [G loss: 5.224422]\n",
      "epoch:47 step:36952 [D loss: 0.216255, acc: 92.97%] [G loss: 5.188025]\n",
      "epoch:47 step:36953 [D loss: 0.353702, acc: 82.03%] [G loss: 6.270037]\n",
      "epoch:47 step:36954 [D loss: 0.102317, acc: 100.00%] [G loss: 6.579166]\n",
      "epoch:47 step:36955 [D loss: 0.391358, acc: 83.59%] [G loss: 4.343877]\n",
      "epoch:47 step:36956 [D loss: 0.155068, acc: 99.22%] [G loss: 4.485522]\n",
      "epoch:47 step:36957 [D loss: 0.166648, acc: 98.44%] [G loss: 3.394413]\n",
      "epoch:47 step:36958 [D loss: 0.121853, acc: 99.22%] [G loss: 3.782300]\n",
      "epoch:47 step:36959 [D loss: 0.131984, acc: 99.22%] [G loss: 5.931511]\n",
      "epoch:47 step:36960 [D loss: 0.797306, acc: 50.78%] [G loss: 9.106123]\n",
      "epoch:47 step:36961 [D loss: 0.382237, acc: 80.47%] [G loss: 4.991806]\n",
      "epoch:47 step:36962 [D loss: 0.717820, acc: 56.25%] [G loss: 4.340249]\n",
      "epoch:47 step:36963 [D loss: 0.238611, acc: 92.97%] [G loss: 6.047109]\n",
      "epoch:47 step:36964 [D loss: 0.058983, acc: 100.00%] [G loss: 4.574412]\n",
      "epoch:47 step:36965 [D loss: 0.300983, acc: 85.94%] [G loss: 5.744372]\n",
      "epoch:47 step:36966 [D loss: 0.048492, acc: 100.00%] [G loss: 4.993365]\n",
      "epoch:47 step:36967 [D loss: 0.753875, acc: 52.34%] [G loss: 6.779105]\n",
      "epoch:47 step:36968 [D loss: 0.559842, acc: 60.94%] [G loss: 8.038776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36969 [D loss: 0.036753, acc: 100.00%] [G loss: 5.733176]\n",
      "epoch:47 step:36970 [D loss: 0.707167, acc: 57.03%] [G loss: 4.956256]\n",
      "epoch:47 step:36971 [D loss: 0.203127, acc: 92.97%] [G loss: 9.445572]\n",
      "epoch:47 step:36972 [D loss: 0.936400, acc: 32.81%] [G loss: 2.679835]\n",
      "epoch:47 step:36973 [D loss: 0.114082, acc: 97.66%] [G loss: 2.621212]\n",
      "epoch:47 step:36974 [D loss: 0.338402, acc: 85.94%] [G loss: 6.688008]\n",
      "epoch:47 step:36975 [D loss: 1.446271, acc: 37.50%] [G loss: 5.794783]\n",
      "epoch:47 step:36976 [D loss: 0.650699, acc: 55.47%] [G loss: 5.102112]\n",
      "epoch:47 step:36977 [D loss: 0.157215, acc: 98.44%] [G loss: 4.403057]\n",
      "epoch:47 step:36978 [D loss: 0.511695, acc: 77.34%] [G loss: 6.059157]\n",
      "epoch:47 step:36979 [D loss: 0.026385, acc: 100.00%] [G loss: 8.143726]\n",
      "epoch:47 step:36980 [D loss: 0.270148, acc: 96.88%] [G loss: 3.584563]\n",
      "epoch:47 step:36981 [D loss: 0.314194, acc: 92.19%] [G loss: 4.872684]\n",
      "epoch:47 step:36982 [D loss: 0.302805, acc: 84.38%] [G loss: 4.425533]\n",
      "epoch:47 step:36983 [D loss: 0.046816, acc: 100.00%] [G loss: 5.722475]\n",
      "epoch:47 step:36984 [D loss: 0.336808, acc: 83.59%] [G loss: 9.344284]\n",
      "epoch:47 step:36985 [D loss: 0.876787, acc: 52.34%] [G loss: 4.255702]\n",
      "epoch:47 step:36986 [D loss: 0.125663, acc: 100.00%] [G loss: 4.891541]\n",
      "epoch:47 step:36987 [D loss: 0.185489, acc: 99.22%] [G loss: 7.883909]\n",
      "epoch:47 step:36988 [D loss: 0.312156, acc: 82.81%] [G loss: 6.123903]\n",
      "epoch:47 step:36989 [D loss: 0.253426, acc: 96.88%] [G loss: 8.516541]\n",
      "epoch:47 step:36990 [D loss: 0.025660, acc: 100.00%] [G loss: 3.729734]\n",
      "epoch:47 step:36991 [D loss: 0.328990, acc: 88.28%] [G loss: 5.323075]\n",
      "epoch:47 step:36992 [D loss: 0.044392, acc: 100.00%] [G loss: 3.534765]\n",
      "epoch:47 step:36993 [D loss: 1.335121, acc: 42.19%] [G loss: 7.893757]\n",
      "epoch:47 step:36994 [D loss: 0.233707, acc: 95.31%] [G loss: 2.831305]\n",
      "epoch:47 step:36995 [D loss: 0.233368, acc: 93.75%] [G loss: 3.967355]\n",
      "epoch:47 step:36996 [D loss: 0.812378, acc: 51.56%] [G loss: 5.382151]\n",
      "epoch:47 step:36997 [D loss: 0.192379, acc: 100.00%] [G loss: 4.840399]\n",
      "epoch:47 step:36998 [D loss: 0.046060, acc: 100.00%] [G loss: 6.940952]\n",
      "epoch:47 step:36999 [D loss: 0.299614, acc: 91.41%] [G loss: 5.717902]\n",
      "epoch:47 step:37000 [D loss: 0.246807, acc: 95.31%] [G loss: 4.481284]\n",
      "epoch:47 step:37001 [D loss: 0.420522, acc: 76.56%] [G loss: 3.468944]\n",
      "epoch:47 step:37002 [D loss: 0.973590, acc: 30.47%] [G loss: 6.570625]\n",
      "epoch:47 step:37003 [D loss: 0.139816, acc: 99.22%] [G loss: 7.175248]\n",
      "epoch:47 step:37004 [D loss: 0.178080, acc: 99.22%] [G loss: 4.281281]\n",
      "epoch:47 step:37005 [D loss: 0.385062, acc: 88.28%] [G loss: 5.342215]\n",
      "epoch:47 step:37006 [D loss: 0.173618, acc: 98.44%] [G loss: 4.838678]\n",
      "epoch:47 step:37007 [D loss: 0.379852, acc: 75.78%] [G loss: 5.459161]\n",
      "epoch:47 step:37008 [D loss: 0.171443, acc: 97.66%] [G loss: 7.188677]\n",
      "epoch:47 step:37009 [D loss: 0.133836, acc: 100.00%] [G loss: 6.157178]\n",
      "epoch:47 step:37010 [D loss: 0.190965, acc: 96.09%] [G loss: 5.522372]\n",
      "epoch:47 step:37011 [D loss: 0.508867, acc: 66.41%] [G loss: 5.593338]\n",
      "epoch:47 step:37012 [D loss: 0.072778, acc: 100.00%] [G loss: 9.489357]\n",
      "epoch:47 step:37013 [D loss: 0.073246, acc: 99.22%] [G loss: 7.598645]\n",
      "epoch:47 step:37014 [D loss: 0.147879, acc: 98.44%] [G loss: 6.060132]\n",
      "epoch:47 step:37015 [D loss: 0.018048, acc: 100.00%] [G loss: 5.451191]\n",
      "epoch:47 step:37016 [D loss: 0.094217, acc: 100.00%] [G loss: 5.659695]\n",
      "epoch:47 step:37017 [D loss: 0.216471, acc: 99.22%] [G loss: 3.895634]\n",
      "epoch:47 step:37018 [D loss: 0.711362, acc: 51.56%] [G loss: 5.366683]\n",
      "epoch:47 step:37019 [D loss: 0.844772, acc: 38.28%] [G loss: 2.847570]\n",
      "epoch:47 step:37020 [D loss: 0.187038, acc: 95.31%] [G loss: 3.255984]\n",
      "epoch:47 step:37021 [D loss: 0.396860, acc: 75.78%] [G loss: 7.934574]\n",
      "epoch:47 step:37022 [D loss: 0.832145, acc: 42.97%] [G loss: 11.572868]\n",
      "epoch:47 step:37023 [D loss: 0.173854, acc: 99.22%] [G loss: 4.305787]\n",
      "epoch:47 step:37024 [D loss: 0.134992, acc: 98.44%] [G loss: 8.677116]\n",
      "epoch:47 step:37025 [D loss: 0.138774, acc: 100.00%] [G loss: 5.211766]\n",
      "epoch:47 step:37026 [D loss: 0.177386, acc: 96.09%] [G loss: 4.362750]\n",
      "epoch:47 step:37027 [D loss: 0.779162, acc: 53.91%] [G loss: 3.657879]\n",
      "epoch:47 step:37028 [D loss: 0.072609, acc: 100.00%] [G loss: 3.410020]\n",
      "epoch:47 step:37029 [D loss: 0.222008, acc: 96.88%] [G loss: 1.623875]\n",
      "epoch:47 step:37030 [D loss: 0.837315, acc: 52.34%] [G loss: 4.137636]\n",
      "epoch:47 step:37031 [D loss: 0.232049, acc: 96.09%] [G loss: 4.072054]\n",
      "epoch:47 step:37032 [D loss: 0.062472, acc: 100.00%] [G loss: 6.666020]\n",
      "epoch:47 step:37033 [D loss: 0.258384, acc: 97.66%] [G loss: 5.216123]\n",
      "epoch:47 step:37034 [D loss: 0.389791, acc: 78.12%] [G loss: 5.888706]\n",
      "epoch:47 step:37035 [D loss: 0.065852, acc: 100.00%] [G loss: 3.460287]\n",
      "epoch:47 step:37036 [D loss: 0.163434, acc: 100.00%] [G loss: 5.392463]\n",
      "epoch:47 step:37037 [D loss: 0.226396, acc: 96.88%] [G loss: 3.359968]\n",
      "epoch:47 step:37038 [D loss: 1.495558, acc: 48.44%] [G loss: 5.311437]\n",
      "epoch:47 step:37039 [D loss: 0.888882, acc: 51.56%] [G loss: 5.586695]\n",
      "epoch:47 step:37040 [D loss: 0.020852, acc: 100.00%] [G loss: 5.767677]\n",
      "epoch:47 step:37041 [D loss: 0.174654, acc: 98.44%] [G loss: 4.251589]\n",
      "epoch:47 step:37042 [D loss: 0.091488, acc: 99.22%] [G loss: 3.742296]\n",
      "epoch:47 step:37043 [D loss: 0.412163, acc: 72.66%] [G loss: 5.974774]\n",
      "epoch:47 step:37044 [D loss: 0.069124, acc: 100.00%] [G loss: 3.424915]\n",
      "epoch:47 step:37045 [D loss: 1.042962, acc: 24.22%] [G loss: 6.961376]\n",
      "epoch:47 step:37046 [D loss: 0.024595, acc: 100.00%] [G loss: 4.383871]\n",
      "epoch:47 step:37047 [D loss: 0.017034, acc: 100.00%] [G loss: 5.156696]\n",
      "epoch:47 step:37048 [D loss: 0.066982, acc: 100.00%] [G loss: 6.826828]\n",
      "epoch:47 step:37049 [D loss: 0.611037, acc: 70.31%] [G loss: 5.669794]\n",
      "epoch:47 step:37050 [D loss: 0.603592, acc: 57.81%] [G loss: 3.510834]\n",
      "epoch:47 step:37051 [D loss: 0.491036, acc: 78.91%] [G loss: 6.799191]\n",
      "epoch:47 step:37052 [D loss: 0.156661, acc: 100.00%] [G loss: 4.411797]\n",
      "epoch:47 step:37053 [D loss: 0.178448, acc: 96.09%] [G loss: 6.815258]\n",
      "epoch:47 step:37054 [D loss: 0.310093, acc: 83.59%] [G loss: 7.313544]\n",
      "epoch:47 step:37055 [D loss: 0.253931, acc: 94.53%] [G loss: 2.492491]\n",
      "epoch:47 step:37056 [D loss: 0.491845, acc: 67.19%] [G loss: 5.034356]\n",
      "epoch:47 step:37057 [D loss: 0.034320, acc: 100.00%] [G loss: 8.584046]\n",
      "epoch:47 step:37058 [D loss: 0.382277, acc: 90.62%] [G loss: 5.119813]\n",
      "epoch:47 step:37059 [D loss: 0.060684, acc: 100.00%] [G loss: 4.481333]\n",
      "epoch:47 step:37060 [D loss: 0.045130, acc: 100.00%] [G loss: 6.958430]\n",
      "epoch:47 step:37061 [D loss: 0.464309, acc: 78.12%] [G loss: 5.142842]\n",
      "epoch:47 step:37062 [D loss: 0.402587, acc: 75.00%] [G loss: 1.847471]\n",
      "epoch:47 step:37063 [D loss: 0.679260, acc: 54.69%] [G loss: 2.405883]\n",
      "epoch:47 step:37064 [D loss: 0.416028, acc: 78.12%] [G loss: 7.855119]\n",
      "epoch:47 step:37065 [D loss: 0.034442, acc: 100.00%] [G loss: 5.127148]\n",
      "epoch:47 step:37066 [D loss: 0.390867, acc: 85.16%] [G loss: 1.408833]\n",
      "epoch:47 step:37067 [D loss: 0.270657, acc: 96.09%] [G loss: 4.124614]\n",
      "epoch:47 step:37068 [D loss: 0.264224, acc: 89.06%] [G loss: 9.179205]\n",
      "epoch:47 step:37069 [D loss: 0.387577, acc: 75.00%] [G loss: 9.294657]\n",
      "epoch:47 step:37070 [D loss: 0.145340, acc: 98.44%] [G loss: 5.106636]\n",
      "epoch:47 step:37071 [D loss: 0.270256, acc: 96.09%] [G loss: 5.374656]\n",
      "epoch:47 step:37072 [D loss: 0.053486, acc: 100.00%] [G loss: 4.969796]\n",
      "epoch:47 step:37073 [D loss: 0.076522, acc: 100.00%] [G loss: 6.518248]\n",
      "epoch:47 step:37074 [D loss: 0.674984, acc: 56.25%] [G loss: 5.452780]\n",
      "epoch:47 step:37075 [D loss: 0.034289, acc: 100.00%] [G loss: 4.815786]\n",
      "epoch:47 step:37076 [D loss: 0.118479, acc: 100.00%] [G loss: 4.104484]\n",
      "epoch:47 step:37077 [D loss: 0.726736, acc: 56.25%] [G loss: 7.938138]\n",
      "epoch:47 step:37078 [D loss: 0.053968, acc: 100.00%] [G loss: 3.595097]\n",
      "epoch:47 step:37079 [D loss: 1.234403, acc: 27.34%] [G loss: 5.056726]\n",
      "epoch:47 step:37080 [D loss: 0.142495, acc: 99.22%] [G loss: 5.531890]\n",
      "epoch:47 step:37081 [D loss: 0.052251, acc: 100.00%] [G loss: 8.647539]\n",
      "epoch:47 step:37082 [D loss: 0.394202, acc: 75.78%] [G loss: 5.495079]\n",
      "epoch:47 step:37083 [D loss: 0.153463, acc: 100.00%] [G loss: 3.896686]\n",
      "epoch:47 step:37084 [D loss: 0.101842, acc: 99.22%] [G loss: 4.119332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37085 [D loss: 0.742326, acc: 53.12%] [G loss: 8.740673]\n",
      "epoch:47 step:37086 [D loss: 0.374451, acc: 73.44%] [G loss: 5.834175]\n",
      "epoch:47 step:37087 [D loss: 0.390853, acc: 78.91%] [G loss: 7.140707]\n",
      "epoch:47 step:37088 [D loss: 0.299298, acc: 89.06%] [G loss: 6.316541]\n",
      "epoch:47 step:37089 [D loss: 0.442110, acc: 73.44%] [G loss: 4.728007]\n",
      "epoch:47 step:37090 [D loss: 0.183802, acc: 99.22%] [G loss: 4.595651]\n",
      "epoch:47 step:37091 [D loss: 0.176122, acc: 95.31%] [G loss: 4.528269]\n",
      "epoch:47 step:37092 [D loss: 0.201824, acc: 97.66%] [G loss: 3.759033]\n",
      "epoch:47 step:37093 [D loss: 0.299937, acc: 87.50%] [G loss: 7.174208]\n",
      "epoch:47 step:37094 [D loss: 0.081526, acc: 100.00%] [G loss: 6.611219]\n",
      "epoch:47 step:37095 [D loss: 0.058555, acc: 99.22%] [G loss: 6.015518]\n",
      "epoch:47 step:37096 [D loss: 0.881587, acc: 48.44%] [G loss: 5.451591]\n",
      "epoch:47 step:37097 [D loss: 0.049325, acc: 100.00%] [G loss: 6.407380]\n",
      "epoch:47 step:37098 [D loss: 0.067481, acc: 100.00%] [G loss: 10.208233]\n",
      "epoch:47 step:37099 [D loss: 0.169785, acc: 98.44%] [G loss: 8.583922]\n",
      "epoch:47 step:37100 [D loss: 0.949543, acc: 50.78%] [G loss: 5.171964]\n",
      "epoch:47 step:37101 [D loss: 0.293253, acc: 85.94%] [G loss: 7.153296]\n",
      "epoch:47 step:37102 [D loss: 1.200684, acc: 50.00%] [G loss: 8.795654]\n",
      "epoch:47 step:37103 [D loss: 0.115950, acc: 100.00%] [G loss: 5.017419]\n",
      "epoch:47 step:37104 [D loss: 1.240465, acc: 50.78%] [G loss: 3.851202]\n",
      "epoch:47 step:37105 [D loss: 1.988147, acc: 2.34%] [G loss: 6.675081]\n",
      "epoch:47 step:37106 [D loss: 0.597411, acc: 62.50%] [G loss: 6.487641]\n",
      "epoch:47 step:37107 [D loss: 0.977815, acc: 46.88%] [G loss: 7.761085]\n",
      "epoch:47 step:37108 [D loss: 0.033877, acc: 100.00%] [G loss: 6.438403]\n",
      "epoch:47 step:37109 [D loss: 0.953797, acc: 53.91%] [G loss: 6.721269]\n",
      "epoch:47 step:37110 [D loss: 0.064900, acc: 100.00%] [G loss: 8.497173]\n",
      "epoch:47 step:37111 [D loss: 0.926134, acc: 49.22%] [G loss: 8.786492]\n",
      "epoch:47 step:37112 [D loss: 0.129407, acc: 98.44%] [G loss: 7.224596]\n",
      "epoch:47 step:37113 [D loss: 0.202911, acc: 95.31%] [G loss: 5.013708]\n",
      "epoch:47 step:37114 [D loss: 0.114328, acc: 100.00%] [G loss: 4.860521]\n",
      "epoch:47 step:37115 [D loss: 0.194694, acc: 95.31%] [G loss: 2.042051]\n",
      "epoch:47 step:37116 [D loss: 0.091681, acc: 99.22%] [G loss: 3.897825]\n",
      "epoch:47 step:37117 [D loss: 0.069879, acc: 99.22%] [G loss: 2.067409]\n",
      "epoch:47 step:37118 [D loss: 0.662432, acc: 64.06%] [G loss: 6.604437]\n",
      "epoch:47 step:37119 [D loss: 0.065229, acc: 100.00%] [G loss: 6.491275]\n",
      "epoch:47 step:37120 [D loss: 0.497460, acc: 71.09%] [G loss: 4.912963]\n",
      "epoch:47 step:37121 [D loss: 0.391711, acc: 71.88%] [G loss: 6.154580]\n",
      "epoch:47 step:37122 [D loss: 1.780109, acc: 16.41%] [G loss: 5.412079]\n",
      "epoch:47 step:37123 [D loss: 0.026723, acc: 100.00%] [G loss: 4.095062]\n",
      "epoch:47 step:37124 [D loss: 0.275641, acc: 95.31%] [G loss: 5.585056]\n",
      "epoch:47 step:37125 [D loss: 0.161266, acc: 99.22%] [G loss: 7.512786]\n",
      "epoch:47 step:37126 [D loss: 0.020100, acc: 100.00%] [G loss: 5.195293]\n",
      "epoch:47 step:37127 [D loss: 0.305607, acc: 92.19%] [G loss: 5.325966]\n",
      "epoch:47 step:37128 [D loss: 0.072789, acc: 100.00%] [G loss: 2.349082]\n",
      "epoch:47 step:37129 [D loss: 0.088051, acc: 99.22%] [G loss: 4.106943]\n",
      "epoch:47 step:37130 [D loss: 0.459017, acc: 82.03%] [G loss: 5.233381]\n",
      "epoch:47 step:37131 [D loss: 0.080399, acc: 100.00%] [G loss: 2.909424]\n",
      "epoch:47 step:37132 [D loss: 0.913952, acc: 50.00%] [G loss: 8.245949]\n",
      "epoch:47 step:37133 [D loss: 0.283117, acc: 84.38%] [G loss: 7.445380]\n",
      "epoch:47 step:37134 [D loss: 0.750085, acc: 55.47%] [G loss: 9.621090]\n",
      "epoch:47 step:37135 [D loss: 0.075077, acc: 99.22%] [G loss: 4.122519]\n",
      "epoch:47 step:37136 [D loss: 0.018925, acc: 100.00%] [G loss: 5.134623]\n",
      "epoch:47 step:37137 [D loss: 0.272105, acc: 91.41%] [G loss: 6.652939]\n",
      "epoch:47 step:37138 [D loss: 0.525956, acc: 78.91%] [G loss: 6.429625]\n",
      "epoch:47 step:37139 [D loss: 0.170289, acc: 97.66%] [G loss: 1.906920]\n",
      "epoch:47 step:37140 [D loss: 0.386419, acc: 82.03%] [G loss: 4.512121]\n",
      "epoch:47 step:37141 [D loss: 0.074987, acc: 100.00%] [G loss: 10.235459]\n",
      "epoch:47 step:37142 [D loss: 0.031655, acc: 99.22%] [G loss: 7.979433]\n",
      "epoch:47 step:37143 [D loss: 0.089538, acc: 100.00%] [G loss: 2.019638]\n",
      "epoch:47 step:37144 [D loss: 0.260936, acc: 92.19%] [G loss: 5.552087]\n",
      "epoch:47 step:37145 [D loss: 0.890178, acc: 39.06%] [G loss: 10.495946]\n",
      "epoch:47 step:37146 [D loss: 0.052675, acc: 100.00%] [G loss: 9.137935]\n",
      "epoch:47 step:37147 [D loss: 0.209577, acc: 98.44%] [G loss: 6.806561]\n",
      "epoch:47 step:37148 [D loss: 0.258732, acc: 97.66%] [G loss: 5.216722]\n",
      "epoch:47 step:37149 [D loss: 0.352021, acc: 86.72%] [G loss: 2.637885]\n",
      "epoch:47 step:37150 [D loss: 0.105562, acc: 99.22%] [G loss: 5.277587]\n",
      "epoch:47 step:37151 [D loss: 0.041775, acc: 100.00%] [G loss: 8.929701]\n",
      "epoch:47 step:37152 [D loss: 0.227273, acc: 97.66%] [G loss: 4.394211]\n",
      "epoch:47 step:37153 [D loss: 0.011147, acc: 100.00%] [G loss: 6.364163]\n",
      "epoch:47 step:37154 [D loss: 0.299759, acc: 93.75%] [G loss: 4.646907]\n",
      "epoch:47 step:37155 [D loss: 0.254786, acc: 95.31%] [G loss: 5.206231]\n",
      "epoch:47 step:37156 [D loss: 0.029958, acc: 100.00%] [G loss: 6.710669]\n",
      "epoch:47 step:37157 [D loss: 0.070532, acc: 100.00%] [G loss: 9.841140]\n",
      "epoch:47 step:37158 [D loss: 0.110286, acc: 99.22%] [G loss: 5.022361]\n",
      "epoch:47 step:37159 [D loss: 0.619227, acc: 65.62%] [G loss: 7.716460]\n",
      "epoch:47 step:37160 [D loss: 0.061999, acc: 100.00%] [G loss: 8.680319]\n",
      "epoch:47 step:37161 [D loss: 0.061676, acc: 100.00%] [G loss: 3.983086]\n",
      "epoch:47 step:37162 [D loss: 0.143294, acc: 96.88%] [G loss: 5.850904]\n",
      "epoch:47 step:37163 [D loss: 0.034758, acc: 100.00%] [G loss: 5.163435]\n",
      "epoch:47 step:37164 [D loss: 0.070876, acc: 100.00%] [G loss: 4.724846]\n",
      "epoch:47 step:37165 [D loss: 1.024318, acc: 50.78%] [G loss: 5.618510]\n",
      "epoch:47 step:37166 [D loss: 0.582069, acc: 60.16%] [G loss: 8.386146]\n",
      "epoch:47 step:37167 [D loss: 0.357370, acc: 82.03%] [G loss: 5.263791]\n",
      "epoch:47 step:37168 [D loss: 0.185520, acc: 96.88%] [G loss: 4.268729]\n",
      "epoch:47 step:37169 [D loss: 0.156832, acc: 99.22%] [G loss: 6.587305]\n",
      "epoch:47 step:37170 [D loss: 0.133647, acc: 99.22%] [G loss: 6.189380]\n",
      "epoch:47 step:37171 [D loss: 0.246009, acc: 94.53%] [G loss: 3.010092]\n",
      "epoch:47 step:37172 [D loss: 0.153390, acc: 98.44%] [G loss: 6.234865]\n",
      "epoch:47 step:37173 [D loss: 0.070395, acc: 100.00%] [G loss: 3.808285]\n",
      "epoch:47 step:37174 [D loss: 0.315994, acc: 89.06%] [G loss: 3.509729]\n",
      "epoch:47 step:37175 [D loss: 0.054823, acc: 99.22%] [G loss: 7.292415]\n",
      "epoch:47 step:37176 [D loss: 0.607895, acc: 61.72%] [G loss: 7.158609]\n",
      "epoch:47 step:37177 [D loss: 0.080926, acc: 100.00%] [G loss: 6.721332]\n",
      "epoch:47 step:37178 [D loss: 0.840808, acc: 53.12%] [G loss: 5.642013]\n",
      "epoch:47 step:37179 [D loss: 0.219704, acc: 95.31%] [G loss: 6.474481]\n",
      "epoch:47 step:37180 [D loss: 0.064040, acc: 100.00%] [G loss: 4.911232]\n",
      "epoch:47 step:37181 [D loss: 0.159087, acc: 97.66%] [G loss: 6.685517]\n",
      "epoch:47 step:37182 [D loss: 0.076882, acc: 100.00%] [G loss: 7.126061]\n",
      "epoch:47 step:37183 [D loss: 0.348181, acc: 80.47%] [G loss: 5.419859]\n",
      "epoch:47 step:37184 [D loss: 1.442173, acc: 44.53%] [G loss: 7.214772]\n",
      "epoch:47 step:37185 [D loss: 0.106336, acc: 100.00%] [G loss: 6.840248]\n",
      "epoch:47 step:37186 [D loss: 1.062547, acc: 49.22%] [G loss: 8.516560]\n",
      "epoch:47 step:37187 [D loss: 0.646586, acc: 60.94%] [G loss: 7.093378]\n",
      "epoch:47 step:37188 [D loss: 0.045422, acc: 100.00%] [G loss: 6.170446]\n",
      "epoch:47 step:37189 [D loss: 0.627865, acc: 59.38%] [G loss: 5.243155]\n",
      "epoch:47 step:37190 [D loss: 0.524053, acc: 60.94%] [G loss: 5.490924]\n",
      "epoch:47 step:37191 [D loss: 0.629418, acc: 60.16%] [G loss: 7.273252]\n",
      "epoch:47 step:37192 [D loss: 0.111552, acc: 100.00%] [G loss: 6.642956]\n",
      "epoch:47 step:37193 [D loss: 0.448521, acc: 75.00%] [G loss: 5.876891]\n",
      "epoch:47 step:37194 [D loss: 1.346956, acc: 50.00%] [G loss: 5.502316]\n",
      "epoch:47 step:37195 [D loss: 0.231695, acc: 92.19%] [G loss: 7.568531]\n",
      "epoch:47 step:37196 [D loss: 0.098859, acc: 99.22%] [G loss: 4.180507]\n",
      "epoch:47 step:37197 [D loss: 0.147943, acc: 100.00%] [G loss: 7.407218]\n",
      "epoch:47 step:37198 [D loss: 0.356176, acc: 93.75%] [G loss: 5.158532]\n",
      "epoch:47 step:37199 [D loss: 0.536417, acc: 62.50%] [G loss: 3.478245]\n",
      "epoch:47 step:37200 [D loss: 0.062513, acc: 100.00%] [G loss: 5.646956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37201 [D loss: 0.066182, acc: 100.00%] [G loss: 5.951573]\n",
      "epoch:47 step:37202 [D loss: 1.488256, acc: 15.62%] [G loss: 7.431626]\n",
      "epoch:47 step:37203 [D loss: 0.266786, acc: 89.84%] [G loss: 8.984721]\n",
      "epoch:47 step:37204 [D loss: 0.543493, acc: 71.88%] [G loss: 7.964331]\n",
      "epoch:47 step:37205 [D loss: 0.054822, acc: 100.00%] [G loss: 4.433090]\n",
      "epoch:47 step:37206 [D loss: 0.176585, acc: 98.44%] [G loss: 8.405107]\n",
      "epoch:47 step:37207 [D loss: 0.547674, acc: 72.66%] [G loss: 6.430511]\n",
      "epoch:47 step:37208 [D loss: 0.224347, acc: 96.88%] [G loss: 4.290125]\n",
      "epoch:47 step:37209 [D loss: 0.050614, acc: 100.00%] [G loss: 5.637746]\n",
      "epoch:47 step:37210 [D loss: 0.184519, acc: 96.09%] [G loss: 7.189579]\n",
      "epoch:47 step:37211 [D loss: 0.593416, acc: 59.38%] [G loss: 6.898389]\n",
      "epoch:47 step:37212 [D loss: 0.095062, acc: 99.22%] [G loss: 4.407087]\n",
      "epoch:47 step:37213 [D loss: 0.780735, acc: 54.69%] [G loss: 7.198501]\n",
      "epoch:47 step:37214 [D loss: 0.281116, acc: 91.41%] [G loss: 4.906927]\n",
      "epoch:47 step:37215 [D loss: 0.430745, acc: 82.81%] [G loss: 5.074302]\n",
      "epoch:47 step:37216 [D loss: 0.044164, acc: 100.00%] [G loss: 3.544446]\n",
      "epoch:47 step:37217 [D loss: 0.067831, acc: 100.00%] [G loss: 7.490553]\n",
      "epoch:47 step:37218 [D loss: 0.005511, acc: 100.00%] [G loss: 10.587478]\n",
      "epoch:47 step:37219 [D loss: 0.076034, acc: 100.00%] [G loss: 4.652201]\n",
      "epoch:47 step:37220 [D loss: 0.276665, acc: 89.06%] [G loss: 7.851403]\n",
      "epoch:47 step:37221 [D loss: 0.975320, acc: 50.78%] [G loss: 6.622158]\n",
      "epoch:47 step:37222 [D loss: 0.013380, acc: 100.00%] [G loss: 3.627391]\n",
      "epoch:47 step:37223 [D loss: 0.170033, acc: 99.22%] [G loss: 3.899184]\n",
      "epoch:47 step:37224 [D loss: 0.024609, acc: 100.00%] [G loss: 7.184597]\n",
      "epoch:47 step:37225 [D loss: 0.131375, acc: 98.44%] [G loss: 5.496801]\n",
      "epoch:47 step:37226 [D loss: 0.336431, acc: 92.97%] [G loss: 7.244229]\n",
      "epoch:47 step:37227 [D loss: 0.151014, acc: 100.00%] [G loss: 5.449462]\n",
      "epoch:47 step:37228 [D loss: 0.065976, acc: 100.00%] [G loss: 7.296238]\n",
      "epoch:47 step:37229 [D loss: 0.086119, acc: 100.00%] [G loss: 4.939353]\n",
      "epoch:47 step:37230 [D loss: 0.984844, acc: 50.78%] [G loss: 3.765366]\n",
      "epoch:47 step:37231 [D loss: 0.100684, acc: 100.00%] [G loss: 3.537619]\n",
      "epoch:47 step:37232 [D loss: 0.312483, acc: 87.50%] [G loss: 7.328020]\n",
      "epoch:47 step:37233 [D loss: 1.074212, acc: 46.88%] [G loss: 4.291961]\n",
      "epoch:47 step:37234 [D loss: 0.190400, acc: 95.31%] [G loss: 3.717578]\n",
      "epoch:47 step:37235 [D loss: 0.092891, acc: 98.44%] [G loss: 6.145968]\n",
      "epoch:47 step:37236 [D loss: 0.124317, acc: 99.22%] [G loss: 5.396725]\n",
      "epoch:47 step:37237 [D loss: 0.037088, acc: 100.00%] [G loss: 7.528703]\n",
      "epoch:47 step:37238 [D loss: 0.065445, acc: 99.22%] [G loss: 7.797659]\n",
      "epoch:47 step:37239 [D loss: 0.222125, acc: 92.19%] [G loss: 7.712072]\n",
      "epoch:47 step:37240 [D loss: 0.208197, acc: 98.44%] [G loss: 3.701080]\n",
      "epoch:47 step:37241 [D loss: 0.469759, acc: 64.84%] [G loss: 4.844150]\n",
      "epoch:47 step:37242 [D loss: 0.196715, acc: 98.44%] [G loss: 6.524393]\n",
      "epoch:47 step:37243 [D loss: 0.081872, acc: 100.00%] [G loss: 6.045444]\n",
      "epoch:47 step:37244 [D loss: 0.129462, acc: 100.00%] [G loss: 6.865867]\n",
      "epoch:47 step:37245 [D loss: 0.034818, acc: 100.00%] [G loss: 7.168413]\n",
      "epoch:47 step:37246 [D loss: 0.238763, acc: 97.66%] [G loss: 6.313008]\n",
      "epoch:47 step:37247 [D loss: 0.067040, acc: 100.00%] [G loss: 6.265203]\n",
      "epoch:47 step:37248 [D loss: 0.135262, acc: 99.22%] [G loss: 8.778390]\n",
      "epoch:47 step:37249 [D loss: 0.075260, acc: 99.22%] [G loss: 7.088044]\n",
      "epoch:47 step:37250 [D loss: 0.249245, acc: 91.41%] [G loss: 4.070362]\n",
      "epoch:47 step:37251 [D loss: 1.241936, acc: 32.81%] [G loss: 6.958297]\n",
      "epoch:47 step:37252 [D loss: 1.195040, acc: 19.53%] [G loss: 11.572672]\n",
      "epoch:47 step:37253 [D loss: 0.449091, acc: 78.91%] [G loss: 6.847095]\n",
      "epoch:47 step:37254 [D loss: 0.286831, acc: 93.75%] [G loss: 5.076628]\n",
      "epoch:47 step:37255 [D loss: 0.453964, acc: 76.56%] [G loss: 6.483897]\n",
      "epoch:47 step:37256 [D loss: 0.020621, acc: 100.00%] [G loss: 6.370272]\n",
      "epoch:47 step:37257 [D loss: 0.436429, acc: 73.44%] [G loss: 5.184361]\n",
      "epoch:47 step:37258 [D loss: 0.051370, acc: 100.00%] [G loss: 6.730973]\n",
      "epoch:47 step:37259 [D loss: 0.101617, acc: 99.22%] [G loss: 5.277434]\n",
      "epoch:47 step:37260 [D loss: 0.178723, acc: 96.88%] [G loss: 7.605999]\n",
      "epoch:47 step:37261 [D loss: 0.080003, acc: 99.22%] [G loss: 9.517944]\n",
      "epoch:47 step:37262 [D loss: 0.017645, acc: 100.00%] [G loss: 7.716778]\n",
      "epoch:47 step:37263 [D loss: 0.133280, acc: 99.22%] [G loss: 5.257098]\n",
      "epoch:47 step:37264 [D loss: 0.694016, acc: 57.03%] [G loss: 9.207784]\n",
      "epoch:47 step:37265 [D loss: 0.521920, acc: 76.56%] [G loss: 5.311800]\n",
      "epoch:47 step:37266 [D loss: 0.189474, acc: 96.88%] [G loss: 4.474653]\n",
      "epoch:47 step:37267 [D loss: 0.070176, acc: 99.22%] [G loss: 6.197847]\n",
      "epoch:47 step:37268 [D loss: 0.108522, acc: 100.00%] [G loss: 6.062614]\n",
      "epoch:47 step:37269 [D loss: 0.912559, acc: 50.78%] [G loss: 8.235065]\n",
      "epoch:47 step:37270 [D loss: 0.793047, acc: 51.56%] [G loss: 5.868639]\n",
      "epoch:47 step:37271 [D loss: 0.039488, acc: 100.00%] [G loss: 4.090740]\n",
      "epoch:47 step:37272 [D loss: 0.199056, acc: 97.66%] [G loss: 5.453021]\n",
      "epoch:47 step:37273 [D loss: 0.502002, acc: 65.62%] [G loss: 5.309370]\n",
      "epoch:47 step:37274 [D loss: 0.240131, acc: 90.62%] [G loss: 6.472746]\n",
      "epoch:47 step:37275 [D loss: 0.201880, acc: 95.31%] [G loss: 6.286712]\n",
      "epoch:47 step:37276 [D loss: 0.006616, acc: 100.00%] [G loss: 8.633185]\n",
      "epoch:47 step:37277 [D loss: 0.185673, acc: 95.31%] [G loss: 6.215512]\n",
      "epoch:47 step:37278 [D loss: 0.040860, acc: 100.00%] [G loss: 7.117176]\n",
      "epoch:47 step:37279 [D loss: 0.042365, acc: 100.00%] [G loss: 3.067162]\n",
      "epoch:47 step:37280 [D loss: 0.494349, acc: 70.31%] [G loss: 5.016687]\n",
      "epoch:47 step:37281 [D loss: 0.116627, acc: 100.00%] [G loss: 3.379089]\n",
      "epoch:47 step:37282 [D loss: 0.395719, acc: 87.50%] [G loss: 2.459728]\n",
      "epoch:47 step:37283 [D loss: 0.050200, acc: 100.00%] [G loss: 7.286688]\n",
      "epoch:47 step:37284 [D loss: 0.239478, acc: 94.53%] [G loss: 6.579734]\n",
      "epoch:47 step:37285 [D loss: 0.070093, acc: 100.00%] [G loss: 8.073750]\n",
      "epoch:47 step:37286 [D loss: 1.295714, acc: 48.44%] [G loss: 7.300607]\n",
      "epoch:47 step:37287 [D loss: 0.806977, acc: 52.34%] [G loss: 11.373465]\n",
      "epoch:47 step:37288 [D loss: 0.013228, acc: 100.00%] [G loss: 10.493328]\n",
      "epoch:47 step:37289 [D loss: 0.298385, acc: 94.53%] [G loss: 8.261341]\n",
      "epoch:47 step:37290 [D loss: 0.372553, acc: 80.47%] [G loss: 3.711620]\n",
      "epoch:47 step:37291 [D loss: 0.057055, acc: 100.00%] [G loss: 8.264703]\n",
      "epoch:47 step:37292 [D loss: 0.255768, acc: 91.41%] [G loss: 8.449203]\n",
      "epoch:47 step:37293 [D loss: 0.156685, acc: 97.66%] [G loss: 7.922749]\n",
      "epoch:47 step:37294 [D loss: 0.135076, acc: 100.00%] [G loss: 5.643956]\n",
      "epoch:47 step:37295 [D loss: 0.138437, acc: 99.22%] [G loss: 3.333059]\n",
      "epoch:47 step:37296 [D loss: 0.083503, acc: 100.00%] [G loss: 7.253983]\n",
      "epoch:47 step:37297 [D loss: 0.399449, acc: 75.00%] [G loss: 7.476510]\n",
      "epoch:47 step:37298 [D loss: 0.434518, acc: 73.44%] [G loss: 9.968663]\n",
      "epoch:47 step:37299 [D loss: 0.246008, acc: 91.41%] [G loss: 5.175558]\n",
      "epoch:47 step:37300 [D loss: 0.028431, acc: 100.00%] [G loss: 9.130743]\n",
      "epoch:47 step:37301 [D loss: 0.088117, acc: 100.00%] [G loss: 6.453988]\n",
      "epoch:47 step:37302 [D loss: 0.056931, acc: 100.00%] [G loss: 5.393811]\n",
      "epoch:47 step:37303 [D loss: 0.767497, acc: 50.78%] [G loss: 3.064036]\n",
      "epoch:47 step:37304 [D loss: 0.061509, acc: 100.00%] [G loss: 6.978562]\n",
      "epoch:47 step:37305 [D loss: 0.314771, acc: 84.38%] [G loss: 8.183201]\n",
      "epoch:47 step:37306 [D loss: 0.209541, acc: 93.75%] [G loss: 7.146769]\n",
      "epoch:47 step:37307 [D loss: 0.053315, acc: 100.00%] [G loss: 6.858593]\n",
      "epoch:47 step:37308 [D loss: 0.068391, acc: 100.00%] [G loss: 6.784348]\n",
      "epoch:47 step:37309 [D loss: 0.268147, acc: 91.41%] [G loss: 5.484782]\n",
      "epoch:47 step:37310 [D loss: 0.640399, acc: 62.50%] [G loss: 6.354462]\n",
      "epoch:47 step:37311 [D loss: 0.911970, acc: 50.78%] [G loss: 5.326210]\n",
      "epoch:47 step:37312 [D loss: 0.101317, acc: 100.00%] [G loss: 6.621181]\n",
      "epoch:47 step:37313 [D loss: 0.049167, acc: 100.00%] [G loss: 4.398012]\n",
      "epoch:47 step:37314 [D loss: 0.728224, acc: 52.34%] [G loss: 2.409786]\n",
      "epoch:47 step:37315 [D loss: 1.222279, acc: 50.00%] [G loss: 7.162344]\n",
      "epoch:47 step:37316 [D loss: 0.207951, acc: 95.31%] [G loss: 5.519775]\n",
      "epoch:47 step:37317 [D loss: 0.119734, acc: 100.00%] [G loss: 4.210821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37318 [D loss: 0.302458, acc: 93.75%] [G loss: 6.860187]\n",
      "epoch:47 step:37319 [D loss: 0.060868, acc: 100.00%] [G loss: 5.322561]\n",
      "epoch:47 step:37320 [D loss: 0.132200, acc: 99.22%] [G loss: 3.912588]\n",
      "epoch:47 step:37321 [D loss: 0.120338, acc: 100.00%] [G loss: 5.473350]\n",
      "epoch:47 step:37322 [D loss: 0.143101, acc: 99.22%] [G loss: 8.413289]\n",
      "epoch:47 step:37323 [D loss: 1.291405, acc: 10.94%] [G loss: 7.484458]\n",
      "epoch:47 step:37324 [D loss: 0.084091, acc: 99.22%] [G loss: 4.835503]\n",
      "epoch:47 step:37325 [D loss: 0.090357, acc: 100.00%] [G loss: 8.805799]\n",
      "epoch:47 step:37326 [D loss: 0.678720, acc: 57.03%] [G loss: 2.194360]\n",
      "epoch:47 step:37327 [D loss: 0.737897, acc: 47.66%] [G loss: 4.871572]\n",
      "epoch:47 step:37328 [D loss: 0.192105, acc: 98.44%] [G loss: 5.537958]\n",
      "epoch:47 step:37329 [D loss: 0.186895, acc: 98.44%] [G loss: 5.348175]\n",
      "epoch:47 step:37330 [D loss: 0.124946, acc: 99.22%] [G loss: 3.849631]\n",
      "epoch:47 step:37331 [D loss: 0.153173, acc: 99.22%] [G loss: 7.061961]\n",
      "epoch:47 step:37332 [D loss: 0.556850, acc: 60.94%] [G loss: 4.831439]\n",
      "epoch:47 step:37333 [D loss: 0.222668, acc: 92.97%] [G loss: 5.855907]\n",
      "epoch:47 step:37334 [D loss: 0.493411, acc: 68.75%] [G loss: 8.267827]\n",
      "epoch:47 step:37335 [D loss: 0.387046, acc: 82.03%] [G loss: 4.487637]\n",
      "epoch:47 step:37336 [D loss: 0.532460, acc: 70.31%] [G loss: 8.314529]\n",
      "epoch:47 step:37337 [D loss: 0.274576, acc: 85.94%] [G loss: 4.735619]\n",
      "epoch:47 step:37338 [D loss: 0.163817, acc: 97.66%] [G loss: 6.998751]\n",
      "epoch:47 step:37339 [D loss: 0.290461, acc: 85.94%] [G loss: 5.927340]\n",
      "epoch:47 step:37340 [D loss: 0.337215, acc: 88.28%] [G loss: 5.571759]\n",
      "epoch:47 step:37341 [D loss: 0.810755, acc: 53.12%] [G loss: 8.346743]\n",
      "epoch:47 step:37342 [D loss: 0.131795, acc: 98.44%] [G loss: 3.527689]\n",
      "epoch:47 step:37343 [D loss: 0.749085, acc: 57.03%] [G loss: 5.800613]\n",
      "epoch:47 step:37344 [D loss: 0.144724, acc: 98.44%] [G loss: 5.229542]\n",
      "epoch:47 step:37345 [D loss: 0.265419, acc: 89.84%] [G loss: 5.222534]\n",
      "epoch:47 step:37346 [D loss: 0.825281, acc: 42.97%] [G loss: 4.324716]\n",
      "epoch:47 step:37347 [D loss: 0.048748, acc: 100.00%] [G loss: 3.760028]\n",
      "epoch:47 step:37348 [D loss: 0.062213, acc: 100.00%] [G loss: 5.622033]\n",
      "epoch:47 step:37349 [D loss: 0.134388, acc: 99.22%] [G loss: 6.412240]\n",
      "epoch:47 step:37350 [D loss: 0.322601, acc: 86.72%] [G loss: 2.955646]\n",
      "epoch:47 step:37351 [D loss: 0.641459, acc: 60.94%] [G loss: 9.728430]\n",
      "epoch:47 step:37352 [D loss: 0.682304, acc: 58.59%] [G loss: 5.319038]\n",
      "epoch:47 step:37353 [D loss: 0.413086, acc: 88.28%] [G loss: 4.354656]\n",
      "epoch:47 step:37354 [D loss: 0.168283, acc: 98.44%] [G loss: 3.982183]\n",
      "epoch:47 step:37355 [D loss: 0.184745, acc: 96.09%] [G loss: 2.237278]\n",
      "epoch:47 step:37356 [D loss: 0.054047, acc: 100.00%] [G loss: 6.837373]\n",
      "epoch:47 step:37357 [D loss: 0.047057, acc: 100.00%] [G loss: 4.617349]\n",
      "epoch:47 step:37358 [D loss: 0.070604, acc: 100.00%] [G loss: 6.891162]\n",
      "epoch:47 step:37359 [D loss: 0.126538, acc: 98.44%] [G loss: 7.215609]\n",
      "epoch:47 step:37360 [D loss: 0.467407, acc: 66.41%] [G loss: 4.375798]\n",
      "epoch:47 step:37361 [D loss: 0.044431, acc: 99.22%] [G loss: 5.742710]\n",
      "epoch:47 step:37362 [D loss: 0.101485, acc: 99.22%] [G loss: 5.384937]\n",
      "epoch:47 step:37363 [D loss: 0.426327, acc: 83.59%] [G loss: 7.281133]\n",
      "epoch:47 step:37364 [D loss: 1.022242, acc: 32.81%] [G loss: 5.687342]\n",
      "epoch:47 step:37365 [D loss: 0.173611, acc: 97.66%] [G loss: 6.781515]\n",
      "epoch:47 step:37366 [D loss: 0.102719, acc: 99.22%] [G loss: 6.903604]\n",
      "epoch:47 step:37367 [D loss: 0.118629, acc: 100.00%] [G loss: 6.274678]\n",
      "epoch:47 step:37368 [D loss: 0.036320, acc: 100.00%] [G loss: 8.587095]\n",
      "epoch:47 step:37369 [D loss: 0.043190, acc: 100.00%] [G loss: 4.376228]\n",
      "epoch:47 step:37370 [D loss: 0.059421, acc: 100.00%] [G loss: 7.754409]\n",
      "epoch:47 step:37371 [D loss: 0.641000, acc: 60.94%] [G loss: 7.764776]\n",
      "epoch:47 step:37372 [D loss: 0.278796, acc: 93.75%] [G loss: 8.054768]\n",
      "epoch:47 step:37373 [D loss: 0.006527, acc: 100.00%] [G loss: 5.564767]\n",
      "epoch:47 step:37374 [D loss: 0.162676, acc: 97.66%] [G loss: 7.362633]\n",
      "epoch:47 step:37375 [D loss: 0.647110, acc: 57.81%] [G loss: 8.390200]\n",
      "epoch:47 step:37376 [D loss: 0.035504, acc: 100.00%] [G loss: 6.009190]\n",
      "epoch:47 step:37377 [D loss: 0.588710, acc: 65.62%] [G loss: 5.513515]\n",
      "epoch:47 step:37378 [D loss: 0.213879, acc: 95.31%] [G loss: 4.920536]\n",
      "epoch:47 step:37379 [D loss: 0.687488, acc: 57.81%] [G loss: 9.632999]\n",
      "epoch:47 step:37380 [D loss: 0.370949, acc: 87.50%] [G loss: 8.510466]\n",
      "epoch:47 step:37381 [D loss: 0.746591, acc: 56.25%] [G loss: 7.258739]\n",
      "epoch:47 step:37382 [D loss: 0.044339, acc: 100.00%] [G loss: 3.726792]\n",
      "epoch:47 step:37383 [D loss: 0.119467, acc: 99.22%] [G loss: 6.238317]\n",
      "epoch:47 step:37384 [D loss: 0.420318, acc: 69.53%] [G loss: 6.911584]\n",
      "epoch:47 step:37385 [D loss: 0.280281, acc: 88.28%] [G loss: 6.564185]\n",
      "epoch:47 step:37386 [D loss: 0.325773, acc: 92.97%] [G loss: 4.318970]\n",
      "epoch:47 step:37387 [D loss: 0.339100, acc: 89.06%] [G loss: 3.664440]\n",
      "epoch:47 step:37388 [D loss: 0.187066, acc: 95.31%] [G loss: 7.223100]\n",
      "epoch:47 step:37389 [D loss: 0.275553, acc: 93.75%] [G loss: 6.811069]\n",
      "epoch:47 step:37390 [D loss: 0.154984, acc: 98.44%] [G loss: 4.965349]\n",
      "epoch:47 step:37391 [D loss: 0.054953, acc: 99.22%] [G loss: 4.587595]\n",
      "epoch:47 step:37392 [D loss: 0.301717, acc: 87.50%] [G loss: 4.488953]\n",
      "epoch:47 step:37393 [D loss: 0.210548, acc: 93.75%] [G loss: 6.409417]\n",
      "epoch:47 step:37394 [D loss: 0.346311, acc: 83.59%] [G loss: 2.309923]\n",
      "epoch:47 step:37395 [D loss: 0.779903, acc: 52.34%] [G loss: 6.128640]\n",
      "epoch:47 step:37396 [D loss: 0.085797, acc: 100.00%] [G loss: 4.801755]\n",
      "epoch:47 step:37397 [D loss: 0.449020, acc: 68.75%] [G loss: 5.302024]\n",
      "epoch:47 step:37398 [D loss: 0.321848, acc: 93.75%] [G loss: 8.242521]\n",
      "epoch:47 step:37399 [D loss: 0.404321, acc: 75.00%] [G loss: 10.449427]\n",
      "epoch:47 step:37400 [D loss: 0.936418, acc: 45.31%] [G loss: 9.104186]\n",
      "epoch:47 step:37401 [D loss: 0.057955, acc: 100.00%] [G loss: 8.386616]\n",
      "epoch:47 step:37402 [D loss: 0.191120, acc: 98.44%] [G loss: 5.095393]\n",
      "epoch:47 step:37403 [D loss: 0.019622, acc: 100.00%] [G loss: 7.528450]\n",
      "epoch:47 step:37404 [D loss: 0.585548, acc: 67.97%] [G loss: 7.573634]\n",
      "epoch:47 step:37405 [D loss: 0.122042, acc: 98.44%] [G loss: 4.393410]\n",
      "epoch:47 step:37406 [D loss: 0.098208, acc: 99.22%] [G loss: 6.446856]\n",
      "epoch:47 step:37407 [D loss: 0.146399, acc: 97.66%] [G loss: 6.355738]\n",
      "epoch:47 step:37408 [D loss: 0.235523, acc: 95.31%] [G loss: 5.428174]\n",
      "epoch:47 step:37409 [D loss: 0.140493, acc: 97.66%] [G loss: 1.288541]\n",
      "epoch:47 step:37410 [D loss: 0.885229, acc: 50.78%] [G loss: 7.659059]\n",
      "epoch:47 step:37411 [D loss: 0.038811, acc: 100.00%] [G loss: 4.341722]\n",
      "epoch:47 step:37412 [D loss: 1.444330, acc: 50.00%] [G loss: 12.222185]\n",
      "epoch:47 step:37413 [D loss: 0.030389, acc: 100.00%] [G loss: 7.456702]\n",
      "epoch:47 step:37414 [D loss: 0.080978, acc: 100.00%] [G loss: 8.767695]\n",
      "epoch:47 step:37415 [D loss: 0.230002, acc: 92.19%] [G loss: 7.463583]\n",
      "epoch:47 step:37416 [D loss: 0.389172, acc: 82.81%] [G loss: 5.840437]\n",
      "epoch:47 step:37417 [D loss: 0.605925, acc: 57.81%] [G loss: 4.946584]\n",
      "epoch:47 step:37418 [D loss: 0.101290, acc: 99.22%] [G loss: 8.990131]\n",
      "epoch:47 step:37419 [D loss: 0.053980, acc: 100.00%] [G loss: 7.952231]\n",
      "epoch:47 step:37420 [D loss: 0.044603, acc: 100.00%] [G loss: 7.198618]\n",
      "epoch:47 step:37421 [D loss: 0.631006, acc: 64.06%] [G loss: 5.793221]\n",
      "epoch:47 step:37422 [D loss: 0.156415, acc: 99.22%] [G loss: 3.145959]\n",
      "epoch:47 step:37423 [D loss: 0.176603, acc: 96.88%] [G loss: 4.096844]\n",
      "epoch:47 step:37424 [D loss: 0.371565, acc: 89.06%] [G loss: 5.513241]\n",
      "epoch:47 step:37425 [D loss: 0.273001, acc: 90.62%] [G loss: 8.076539]\n",
      "epoch:47 step:37426 [D loss: 0.114074, acc: 98.44%] [G loss: 3.681801]\n",
      "epoch:47 step:37427 [D loss: 0.335595, acc: 93.75%] [G loss: 6.737550]\n",
      "epoch:47 step:37428 [D loss: 0.800311, acc: 52.34%] [G loss: 5.394906]\n",
      "epoch:47 step:37429 [D loss: 0.046855, acc: 100.00%] [G loss: 3.333376]\n",
      "epoch:47 step:37430 [D loss: 0.224947, acc: 98.44%] [G loss: 4.093163]\n",
      "epoch:47 step:37431 [D loss: 0.356722, acc: 78.12%] [G loss: 6.426212]\n",
      "epoch:47 step:37432 [D loss: 0.577661, acc: 60.94%] [G loss: 8.047768]\n",
      "epoch:47 step:37433 [D loss: 1.830982, acc: 50.00%] [G loss: 8.128971]\n",
      "epoch:47 step:37434 [D loss: 0.136993, acc: 99.22%] [G loss: 4.135772]\n",
      "epoch:47 step:37435 [D loss: 0.133203, acc: 99.22%] [G loss: 4.103424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37436 [D loss: 0.507508, acc: 58.59%] [G loss: 5.597442]\n",
      "epoch:47 step:37437 [D loss: 0.372332, acc: 85.94%] [G loss: 6.335925]\n",
      "epoch:47 step:37438 [D loss: 0.869901, acc: 42.97%] [G loss: 6.770085]\n",
      "epoch:47 step:37439 [D loss: 0.034591, acc: 100.00%] [G loss: 4.908691]\n",
      "epoch:47 step:37440 [D loss: 0.805930, acc: 42.97%] [G loss: 8.087825]\n",
      "epoch:47 step:37441 [D loss: 0.594719, acc: 56.25%] [G loss: 7.296968]\n",
      "epoch:47 step:37442 [D loss: 0.100429, acc: 99.22%] [G loss: 4.533876]\n",
      "epoch:47 step:37443 [D loss: 1.533061, acc: 50.00%] [G loss: 6.876633]\n",
      "epoch:47 step:37444 [D loss: 0.022211, acc: 100.00%] [G loss: 6.471740]\n",
      "epoch:47 step:37445 [D loss: 0.118189, acc: 99.22%] [G loss: 5.307407]\n",
      "epoch:47 step:37446 [D loss: 0.164969, acc: 96.88%] [G loss: 5.647032]\n",
      "epoch:47 step:37447 [D loss: 0.086023, acc: 100.00%] [G loss: 6.604918]\n",
      "epoch:47 step:37448 [D loss: 0.214072, acc: 99.22%] [G loss: 5.629708]\n",
      "epoch:47 step:37449 [D loss: 0.334184, acc: 92.19%] [G loss: 10.326872]\n",
      "epoch:47 step:37450 [D loss: 2.154509, acc: 20.31%] [G loss: 11.104008]\n",
      "epoch:47 step:37451 [D loss: 0.328699, acc: 89.84%] [G loss: 2.843671]\n",
      "epoch:47 step:37452 [D loss: 0.318314, acc: 80.47%] [G loss: 8.225491]\n",
      "epoch:47 step:37453 [D loss: 0.104172, acc: 99.22%] [G loss: 5.699421]\n",
      "epoch:47 step:37454 [D loss: 0.224372, acc: 98.44%] [G loss: 4.860072]\n",
      "epoch:47 step:37455 [D loss: 0.131648, acc: 98.44%] [G loss: 6.432831]\n",
      "epoch:47 step:37456 [D loss: 0.244513, acc: 92.97%] [G loss: 3.251465]\n",
      "epoch:47 step:37457 [D loss: 0.472185, acc: 71.09%] [G loss: 8.351189]\n",
      "epoch:47 step:37458 [D loss: 1.095523, acc: 50.00%] [G loss: 6.009953]\n",
      "epoch:47 step:37459 [D loss: 0.064272, acc: 100.00%] [G loss: 8.441349]\n",
      "epoch:47 step:37460 [D loss: 0.014421, acc: 100.00%] [G loss: 8.264784]\n",
      "epoch:47 step:37461 [D loss: 1.032988, acc: 50.78%] [G loss: 6.742528]\n",
      "epoch:47 step:37462 [D loss: 0.033482, acc: 100.00%] [G loss: 3.527751]\n",
      "epoch:47 step:37463 [D loss: 0.220332, acc: 92.19%] [G loss: 7.085025]\n",
      "epoch:47 step:37464 [D loss: 0.526463, acc: 77.34%] [G loss: 6.336811]\n",
      "epoch:47 step:37465 [D loss: 0.161633, acc: 100.00%] [G loss: 8.211134]\n",
      "epoch:47 step:37466 [D loss: 0.139502, acc: 100.00%] [G loss: 7.311225]\n",
      "epoch:47 step:37467 [D loss: 0.129183, acc: 98.44%] [G loss: 10.683670]\n",
      "epoch:47 step:37468 [D loss: 0.053704, acc: 100.00%] [G loss: 4.318390]\n",
      "epoch:47 step:37469 [D loss: 0.697749, acc: 60.94%] [G loss: 7.569723]\n",
      "epoch:47 step:37470 [D loss: 0.259224, acc: 91.41%] [G loss: 5.313295]\n",
      "epoch:47 step:37471 [D loss: 0.028296, acc: 100.00%] [G loss: 4.298584]\n",
      "epoch:47 step:37472 [D loss: 0.928550, acc: 52.34%] [G loss: 6.133904]\n",
      "epoch:47 step:37473 [D loss: 0.255323, acc: 96.88%] [G loss: 5.779348]\n",
      "epoch:47 step:37474 [D loss: 0.030036, acc: 100.00%] [G loss: 6.888650]\n",
      "epoch:47 step:37475 [D loss: 0.256236, acc: 96.88%] [G loss: 9.575033]\n",
      "epoch:47 step:37476 [D loss: 0.134067, acc: 99.22%] [G loss: 4.747802]\n",
      "epoch:47 step:37477 [D loss: 0.190281, acc: 100.00%] [G loss: 6.376345]\n",
      "epoch:47 step:37478 [D loss: 0.061353, acc: 100.00%] [G loss: 6.701605]\n",
      "epoch:47 step:37479 [D loss: 0.109236, acc: 100.00%] [G loss: 6.674489]\n",
      "epoch:47 step:37480 [D loss: 0.087482, acc: 100.00%] [G loss: 9.257942]\n",
      "epoch:47 step:37481 [D loss: 0.234773, acc: 94.53%] [G loss: 4.929872]\n",
      "epoch:47 step:37482 [D loss: 0.198899, acc: 95.31%] [G loss: 3.949040]\n",
      "epoch:47 step:37483 [D loss: 0.029527, acc: 100.00%] [G loss: 3.575679]\n",
      "epoch:47 step:37484 [D loss: 0.660792, acc: 67.19%] [G loss: 8.555634]\n",
      "epoch:47 step:37485 [D loss: 0.138056, acc: 97.66%] [G loss: 4.238288]\n",
      "epoch:47 step:37486 [D loss: 0.035873, acc: 100.00%] [G loss: 5.640329]\n",
      "epoch:47 step:37487 [D loss: 0.670754, acc: 60.16%] [G loss: 5.876500]\n",
      "epoch:47 step:37488 [D loss: 0.243905, acc: 90.62%] [G loss: 8.382298]\n",
      "epoch:48 step:37489 [D loss: 0.058350, acc: 100.00%] [G loss: 4.680813]\n",
      "epoch:48 step:37490 [D loss: 0.802080, acc: 53.91%] [G loss: 8.033339]\n",
      "epoch:48 step:37491 [D loss: 0.722566, acc: 56.25%] [G loss: 3.742651]\n",
      "epoch:48 step:37492 [D loss: 0.354709, acc: 87.50%] [G loss: 7.412234]\n",
      "epoch:48 step:37493 [D loss: 0.454393, acc: 72.66%] [G loss: 7.150987]\n",
      "epoch:48 step:37494 [D loss: 1.267447, acc: 16.41%] [G loss: 3.475760]\n",
      "epoch:48 step:37495 [D loss: 0.021900, acc: 100.00%] [G loss: 6.005169]\n",
      "epoch:48 step:37496 [D loss: 0.150064, acc: 100.00%] [G loss: 5.727571]\n",
      "epoch:48 step:37497 [D loss: 0.408530, acc: 71.88%] [G loss: 7.728989]\n",
      "epoch:48 step:37498 [D loss: 0.046613, acc: 100.00%] [G loss: 4.939370]\n",
      "epoch:48 step:37499 [D loss: 0.674678, acc: 56.25%] [G loss: 7.435415]\n",
      "epoch:48 step:37500 [D loss: 0.056762, acc: 100.00%] [G loss: 4.286730]\n",
      "epoch:48 step:37501 [D loss: 0.112893, acc: 99.22%] [G loss: 8.007940]\n",
      "epoch:48 step:37502 [D loss: 0.143307, acc: 100.00%] [G loss: 4.653172]\n",
      "epoch:48 step:37503 [D loss: 0.304014, acc: 85.16%] [G loss: 2.257258]\n",
      "epoch:48 step:37504 [D loss: 0.068839, acc: 100.00%] [G loss: 5.264224]\n",
      "epoch:48 step:37505 [D loss: 0.200651, acc: 93.75%] [G loss: 6.311701]\n",
      "epoch:48 step:37506 [D loss: 0.133357, acc: 97.66%] [G loss: 4.616863]\n",
      "epoch:48 step:37507 [D loss: 0.130251, acc: 99.22%] [G loss: 6.576305]\n",
      "epoch:48 step:37508 [D loss: 0.451518, acc: 71.09%] [G loss: 9.139344]\n",
      "epoch:48 step:37509 [D loss: 0.857518, acc: 51.56%] [G loss: 6.867409]\n",
      "epoch:48 step:37510 [D loss: 0.287840, acc: 89.06%] [G loss: 4.947800]\n",
      "epoch:48 step:37511 [D loss: 0.397687, acc: 71.09%] [G loss: 5.863058]\n",
      "epoch:48 step:37512 [D loss: 0.236176, acc: 92.19%] [G loss: 5.634288]\n",
      "epoch:48 step:37513 [D loss: 0.429930, acc: 72.66%] [G loss: 4.876333]\n",
      "epoch:48 step:37514 [D loss: 0.410945, acc: 74.22%] [G loss: 4.512483]\n",
      "epoch:48 step:37515 [D loss: 0.721720, acc: 54.69%] [G loss: 5.231322]\n",
      "epoch:48 step:37516 [D loss: 0.695134, acc: 57.81%] [G loss: 4.390887]\n",
      "epoch:48 step:37517 [D loss: 0.655623, acc: 58.59%] [G loss: 4.455503]\n",
      "epoch:48 step:37518 [D loss: 0.131723, acc: 99.22%] [G loss: 7.518932]\n",
      "epoch:48 step:37519 [D loss: 0.265322, acc: 89.84%] [G loss: 4.455511]\n",
      "epoch:48 step:37520 [D loss: 0.302943, acc: 87.50%] [G loss: 7.307481]\n",
      "epoch:48 step:37521 [D loss: 0.637532, acc: 57.81%] [G loss: 8.556707]\n",
      "epoch:48 step:37522 [D loss: 0.416969, acc: 84.38%] [G loss: 3.932584]\n",
      "epoch:48 step:37523 [D loss: 0.220991, acc: 97.66%] [G loss: 3.523843]\n",
      "epoch:48 step:37524 [D loss: 0.110024, acc: 98.44%] [G loss: 7.486815]\n",
      "epoch:48 step:37525 [D loss: 0.017843, acc: 100.00%] [G loss: 4.293668]\n",
      "epoch:48 step:37526 [D loss: 0.361569, acc: 78.12%] [G loss: 6.519945]\n",
      "epoch:48 step:37527 [D loss: 0.013745, acc: 100.00%] [G loss: 4.822683]\n",
      "epoch:48 step:37528 [D loss: 0.082114, acc: 100.00%] [G loss: 5.175505]\n",
      "epoch:48 step:37529 [D loss: 0.651607, acc: 59.38%] [G loss: 7.277383]\n",
      "epoch:48 step:37530 [D loss: 0.510452, acc: 62.50%] [G loss: 7.946403]\n",
      "epoch:48 step:37531 [D loss: 0.126571, acc: 100.00%] [G loss: 2.655387]\n",
      "epoch:48 step:37532 [D loss: 0.313642, acc: 86.72%] [G loss: 6.284105]\n",
      "epoch:48 step:37533 [D loss: 0.150920, acc: 99.22%] [G loss: 7.241815]\n",
      "epoch:48 step:37534 [D loss: 0.722944, acc: 56.25%] [G loss: 4.761329]\n",
      "epoch:48 step:37535 [D loss: 0.218222, acc: 94.53%] [G loss: 8.262280]\n",
      "epoch:48 step:37536 [D loss: 0.580823, acc: 62.50%] [G loss: 4.964958]\n",
      "epoch:48 step:37537 [D loss: 0.128419, acc: 99.22%] [G loss: 7.271826]\n",
      "epoch:48 step:37538 [D loss: 0.299585, acc: 89.06%] [G loss: 5.783696]\n",
      "epoch:48 step:37539 [D loss: 0.189273, acc: 96.09%] [G loss: 5.374166]\n",
      "epoch:48 step:37540 [D loss: 0.092166, acc: 100.00%] [G loss: 4.364298]\n",
      "epoch:48 step:37541 [D loss: 0.046178, acc: 100.00%] [G loss: 6.692411]\n",
      "epoch:48 step:37542 [D loss: 0.112367, acc: 100.00%] [G loss: 2.883911]\n",
      "epoch:48 step:37543 [D loss: 0.298707, acc: 87.50%] [G loss: 1.617676]\n",
      "epoch:48 step:37544 [D loss: 0.657614, acc: 55.47%] [G loss: 4.942127]\n",
      "epoch:48 step:37545 [D loss: 0.490289, acc: 71.88%] [G loss: 5.284876]\n",
      "epoch:48 step:37546 [D loss: 1.291958, acc: 50.78%] [G loss: 5.998944]\n",
      "epoch:48 step:37547 [D loss: 0.291734, acc: 84.38%] [G loss: 6.104691]\n",
      "epoch:48 step:37548 [D loss: 0.091414, acc: 99.22%] [G loss: 4.430673]\n",
      "epoch:48 step:37549 [D loss: 0.681424, acc: 56.25%] [G loss: 9.398937]\n",
      "epoch:48 step:37550 [D loss: 0.181578, acc: 94.53%] [G loss: 6.069086]\n",
      "epoch:48 step:37551 [D loss: 0.091642, acc: 100.00%] [G loss: 3.873896]\n",
      "epoch:48 step:37552 [D loss: 0.581290, acc: 68.75%] [G loss: 8.438749]\n",
      "epoch:48 step:37553 [D loss: 0.059451, acc: 100.00%] [G loss: 8.449446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37554 [D loss: 0.446259, acc: 83.59%] [G loss: 5.452203]\n",
      "epoch:48 step:37555 [D loss: 0.205039, acc: 97.66%] [G loss: 4.213011]\n",
      "epoch:48 step:37556 [D loss: 0.324284, acc: 82.03%] [G loss: 8.433756]\n",
      "epoch:48 step:37557 [D loss: 0.564315, acc: 58.59%] [G loss: 6.694504]\n",
      "epoch:48 step:37558 [D loss: 0.050987, acc: 99.22%] [G loss: 3.460757]\n",
      "epoch:48 step:37559 [D loss: 0.811960, acc: 43.75%] [G loss: 7.739256]\n",
      "epoch:48 step:37560 [D loss: 0.020572, acc: 100.00%] [G loss: 5.977587]\n",
      "epoch:48 step:37561 [D loss: 0.119491, acc: 98.44%] [G loss: 8.875101]\n",
      "epoch:48 step:37562 [D loss: 0.242447, acc: 91.41%] [G loss: 6.841131]\n",
      "epoch:48 step:37563 [D loss: 0.610225, acc: 69.53%] [G loss: 4.474122]\n",
      "epoch:48 step:37564 [D loss: 0.107041, acc: 100.00%] [G loss: 4.350421]\n",
      "epoch:48 step:37565 [D loss: 0.095114, acc: 100.00%] [G loss: 8.172968]\n",
      "epoch:48 step:37566 [D loss: 0.034004, acc: 100.00%] [G loss: 7.059053]\n",
      "epoch:48 step:37567 [D loss: 0.908166, acc: 52.34%] [G loss: 6.064552]\n",
      "epoch:48 step:37568 [D loss: 1.036966, acc: 50.78%] [G loss: 6.803100]\n",
      "epoch:48 step:37569 [D loss: 0.765562, acc: 52.34%] [G loss: 7.325025]\n",
      "epoch:48 step:37570 [D loss: 0.106850, acc: 98.44%] [G loss: 8.631737]\n",
      "epoch:48 step:37571 [D loss: 1.356516, acc: 50.00%] [G loss: 7.339161]\n",
      "epoch:48 step:37572 [D loss: 0.659328, acc: 57.81%] [G loss: 7.027246]\n",
      "epoch:48 step:37573 [D loss: 0.565315, acc: 53.91%] [G loss: 7.022738]\n",
      "epoch:48 step:37574 [D loss: 1.093071, acc: 49.22%] [G loss: 3.716200]\n",
      "epoch:48 step:37575 [D loss: 0.029806, acc: 100.00%] [G loss: 5.233452]\n",
      "epoch:48 step:37576 [D loss: 0.369751, acc: 77.34%] [G loss: 5.770760]\n",
      "epoch:48 step:37577 [D loss: 0.350541, acc: 81.25%] [G loss: 5.790466]\n",
      "epoch:48 step:37578 [D loss: 0.038331, acc: 100.00%] [G loss: 4.747109]\n",
      "epoch:48 step:37579 [D loss: 0.053496, acc: 100.00%] [G loss: 4.748660]\n",
      "epoch:48 step:37580 [D loss: 0.358874, acc: 88.28%] [G loss: 7.118475]\n",
      "epoch:48 step:37581 [D loss: 0.319970, acc: 83.59%] [G loss: 7.375694]\n",
      "epoch:48 step:37582 [D loss: 0.014851, acc: 100.00%] [G loss: 6.947275]\n",
      "epoch:48 step:37583 [D loss: 0.181379, acc: 96.09%] [G loss: 2.690416]\n",
      "epoch:48 step:37584 [D loss: 0.207505, acc: 93.75%] [G loss: 4.780575]\n",
      "epoch:48 step:37585 [D loss: 1.816601, acc: 0.78%] [G loss: 6.665873]\n",
      "epoch:48 step:37586 [D loss: 0.174448, acc: 97.66%] [G loss: 7.629525]\n",
      "epoch:48 step:37587 [D loss: 0.076816, acc: 100.00%] [G loss: 2.012399]\n",
      "epoch:48 step:37588 [D loss: 0.041844, acc: 100.00%] [G loss: 6.248839]\n",
      "epoch:48 step:37589 [D loss: 0.375214, acc: 78.91%] [G loss: 4.542004]\n",
      "epoch:48 step:37590 [D loss: 0.185544, acc: 95.31%] [G loss: 4.630990]\n",
      "epoch:48 step:37591 [D loss: 0.299092, acc: 85.16%] [G loss: 5.353958]\n",
      "epoch:48 step:37592 [D loss: 0.120965, acc: 100.00%] [G loss: 5.160685]\n",
      "epoch:48 step:37593 [D loss: 0.553997, acc: 66.41%] [G loss: 6.093023]\n",
      "epoch:48 step:37594 [D loss: 0.580453, acc: 60.16%] [G loss: 5.387923]\n",
      "epoch:48 step:37595 [D loss: 0.317565, acc: 90.62%] [G loss: 6.558790]\n",
      "epoch:48 step:37596 [D loss: 0.181800, acc: 96.88%] [G loss: 6.387823]\n",
      "epoch:48 step:37597 [D loss: 0.414004, acc: 70.31%] [G loss: 4.028819]\n",
      "epoch:48 step:37598 [D loss: 0.317282, acc: 89.06%] [G loss: 6.064542]\n",
      "epoch:48 step:37599 [D loss: 0.437144, acc: 70.31%] [G loss: 7.063940]\n",
      "epoch:48 step:37600 [D loss: 0.383205, acc: 82.03%] [G loss: 6.439572]\n",
      "epoch:48 step:37601 [D loss: 0.542367, acc: 61.72%] [G loss: 6.548208]\n",
      "epoch:48 step:37602 [D loss: 0.096486, acc: 100.00%] [G loss: 6.140676]\n",
      "epoch:48 step:37603 [D loss: 0.713267, acc: 57.81%] [G loss: 7.635145]\n",
      "epoch:48 step:37604 [D loss: 0.122978, acc: 100.00%] [G loss: 6.597680]\n",
      "epoch:48 step:37605 [D loss: 0.234375, acc: 95.31%] [G loss: 5.563499]\n",
      "epoch:48 step:37606 [D loss: 0.134671, acc: 98.44%] [G loss: 9.272838]\n",
      "epoch:48 step:37607 [D loss: 1.577515, acc: 50.00%] [G loss: 6.007552]\n",
      "epoch:48 step:37608 [D loss: 0.316048, acc: 91.41%] [G loss: 3.061536]\n",
      "epoch:48 step:37609 [D loss: 1.517674, acc: 50.00%] [G loss: 8.490325]\n",
      "epoch:48 step:37610 [D loss: 0.024116, acc: 100.00%] [G loss: 3.789394]\n",
      "epoch:48 step:37611 [D loss: 0.175827, acc: 99.22%] [G loss: 3.034521]\n",
      "epoch:48 step:37612 [D loss: 0.455045, acc: 83.59%] [G loss: 4.924303]\n",
      "epoch:48 step:37613 [D loss: 0.368312, acc: 78.12%] [G loss: 4.274776]\n",
      "epoch:48 step:37614 [D loss: 0.040015, acc: 100.00%] [G loss: 8.077374]\n",
      "epoch:48 step:37615 [D loss: 0.318355, acc: 85.16%] [G loss: 3.542717]\n",
      "epoch:48 step:37616 [D loss: 0.055509, acc: 100.00%] [G loss: 3.097127]\n",
      "epoch:48 step:37617 [D loss: 0.355849, acc: 81.25%] [G loss: 7.616390]\n",
      "epoch:48 step:37618 [D loss: 0.402613, acc: 75.78%] [G loss: 6.076528]\n",
      "epoch:48 step:37619 [D loss: 0.647863, acc: 60.94%] [G loss: 3.528451]\n",
      "epoch:48 step:37620 [D loss: 0.074462, acc: 100.00%] [G loss: 5.840840]\n",
      "epoch:48 step:37621 [D loss: 0.265082, acc: 96.88%] [G loss: 3.516299]\n",
      "epoch:48 step:37622 [D loss: 0.546506, acc: 60.16%] [G loss: 3.888800]\n",
      "epoch:48 step:37623 [D loss: 0.437593, acc: 71.09%] [G loss: 9.559800]\n",
      "epoch:48 step:37624 [D loss: 0.094916, acc: 99.22%] [G loss: 7.823493]\n",
      "epoch:48 step:37625 [D loss: 0.653473, acc: 60.94%] [G loss: 7.638429]\n",
      "epoch:48 step:37626 [D loss: 0.236216, acc: 96.09%] [G loss: 5.661161]\n",
      "epoch:48 step:37627 [D loss: 1.661984, acc: 6.25%] [G loss: 8.225568]\n",
      "epoch:48 step:37628 [D loss: 0.120023, acc: 100.00%] [G loss: 4.623287]\n",
      "epoch:48 step:37629 [D loss: 0.188615, acc: 96.88%] [G loss: 6.261452]\n",
      "epoch:48 step:37630 [D loss: 0.140223, acc: 100.00%] [G loss: 3.218079]\n",
      "epoch:48 step:37631 [D loss: 0.443991, acc: 78.91%] [G loss: 6.931046]\n",
      "epoch:48 step:37632 [D loss: 0.101439, acc: 100.00%] [G loss: 6.341543]\n",
      "epoch:48 step:37633 [D loss: 0.353358, acc: 81.25%] [G loss: 4.512914]\n",
      "epoch:48 step:37634 [D loss: 0.572195, acc: 69.53%] [G loss: 6.254169]\n",
      "epoch:48 step:37635 [D loss: 0.260876, acc: 92.19%] [G loss: 4.647261]\n",
      "epoch:48 step:37636 [D loss: 0.071145, acc: 100.00%] [G loss: 4.499003]\n",
      "epoch:48 step:37637 [D loss: 1.986512, acc: 48.44%] [G loss: 4.236512]\n",
      "epoch:48 step:37638 [D loss: 0.234947, acc: 96.09%] [G loss: 4.277474]\n",
      "epoch:48 step:37639 [D loss: 0.068362, acc: 99.22%] [G loss: 5.611102]\n",
      "epoch:48 step:37640 [D loss: 0.722460, acc: 55.47%] [G loss: 6.515004]\n",
      "epoch:48 step:37641 [D loss: 0.143600, acc: 98.44%] [G loss: 3.447529]\n",
      "epoch:48 step:37642 [D loss: 0.089808, acc: 98.44%] [G loss: 4.509242]\n",
      "epoch:48 step:37643 [D loss: 0.501068, acc: 64.06%] [G loss: 5.008111]\n",
      "epoch:48 step:37644 [D loss: 0.110690, acc: 99.22%] [G loss: 4.242133]\n",
      "epoch:48 step:37645 [D loss: 0.525167, acc: 73.44%] [G loss: 4.264855]\n",
      "epoch:48 step:37646 [D loss: 0.575050, acc: 57.03%] [G loss: 9.261952]\n",
      "epoch:48 step:37647 [D loss: 0.141111, acc: 100.00%] [G loss: 4.191216]\n",
      "epoch:48 step:37648 [D loss: 0.447367, acc: 77.34%] [G loss: 7.049662]\n",
      "epoch:48 step:37649 [D loss: 0.740278, acc: 53.91%] [G loss: 9.405099]\n",
      "epoch:48 step:37650 [D loss: 0.088148, acc: 100.00%] [G loss: 6.219581]\n",
      "epoch:48 step:37651 [D loss: 0.331559, acc: 83.59%] [G loss: 3.822607]\n",
      "epoch:48 step:37652 [D loss: 0.124278, acc: 99.22%] [G loss: 8.007767]\n",
      "epoch:48 step:37653 [D loss: 0.280812, acc: 89.84%] [G loss: 4.368146]\n",
      "epoch:48 step:37654 [D loss: 0.157623, acc: 98.44%] [G loss: 4.064068]\n",
      "epoch:48 step:37655 [D loss: 0.269031, acc: 93.75%] [G loss: 7.857193]\n",
      "epoch:48 step:37656 [D loss: 0.026387, acc: 100.00%] [G loss: 5.606382]\n",
      "epoch:48 step:37657 [D loss: 0.270407, acc: 91.41%] [G loss: 4.264341]\n",
      "epoch:48 step:37658 [D loss: 0.427010, acc: 71.09%] [G loss: 4.317167]\n",
      "epoch:48 step:37659 [D loss: 0.138480, acc: 98.44%] [G loss: 6.676871]\n",
      "epoch:48 step:37660 [D loss: 0.266545, acc: 89.06%] [G loss: 5.183563]\n",
      "epoch:48 step:37661 [D loss: 1.784893, acc: 6.25%] [G loss: 5.949212]\n",
      "epoch:48 step:37662 [D loss: 0.582677, acc: 61.72%] [G loss: 6.382437]\n",
      "epoch:48 step:37663 [D loss: 0.031280, acc: 100.00%] [G loss: 5.538902]\n",
      "epoch:48 step:37664 [D loss: 0.543592, acc: 63.28%] [G loss: 7.984834]\n",
      "epoch:48 step:37665 [D loss: 0.408581, acc: 84.38%] [G loss: 6.338207]\n",
      "epoch:48 step:37666 [D loss: 0.182535, acc: 99.22%] [G loss: 4.265899]\n",
      "epoch:48 step:37667 [D loss: 0.508828, acc: 79.69%] [G loss: 3.493352]\n",
      "epoch:48 step:37668 [D loss: 0.359035, acc: 87.50%] [G loss: 6.055014]\n",
      "epoch:48 step:37669 [D loss: 0.071789, acc: 100.00%] [G loss: 4.181204]\n",
      "epoch:48 step:37670 [D loss: 0.049823, acc: 100.00%] [G loss: 2.538287]\n",
      "epoch:48 step:37671 [D loss: 0.117185, acc: 100.00%] [G loss: 3.257677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37672 [D loss: 0.186442, acc: 99.22%] [G loss: 5.751244]\n",
      "epoch:48 step:37673 [D loss: 0.373939, acc: 93.75%] [G loss: 6.512356]\n",
      "epoch:48 step:37674 [D loss: 1.028594, acc: 50.00%] [G loss: 4.976868]\n",
      "epoch:48 step:37675 [D loss: 0.303573, acc: 94.53%] [G loss: 4.334144]\n",
      "epoch:48 step:37676 [D loss: 0.600702, acc: 57.03%] [G loss: 7.641339]\n",
      "epoch:48 step:37677 [D loss: 0.794242, acc: 56.25%] [G loss: 5.945154]\n",
      "epoch:48 step:37678 [D loss: 1.195837, acc: 49.22%] [G loss: 7.730109]\n",
      "epoch:48 step:37679 [D loss: 0.143901, acc: 100.00%] [G loss: 6.283826]\n",
      "epoch:48 step:37680 [D loss: 0.102714, acc: 100.00%] [G loss: 4.605781]\n",
      "epoch:48 step:37681 [D loss: 0.489784, acc: 75.00%] [G loss: 5.151946]\n",
      "epoch:48 step:37682 [D loss: 0.297115, acc: 85.94%] [G loss: 5.605556]\n",
      "epoch:48 step:37683 [D loss: 1.020387, acc: 40.62%] [G loss: 6.596559]\n",
      "epoch:48 step:37684 [D loss: 0.285353, acc: 95.31%] [G loss: 3.186817]\n",
      "epoch:48 step:37685 [D loss: 0.298638, acc: 92.19%] [G loss: 6.103230]\n",
      "epoch:48 step:37686 [D loss: 0.274515, acc: 86.72%] [G loss: 7.862505]\n",
      "epoch:48 step:37687 [D loss: 0.307935, acc: 80.47%] [G loss: 4.494401]\n",
      "epoch:48 step:37688 [D loss: 0.113977, acc: 99.22%] [G loss: 4.389515]\n",
      "epoch:48 step:37689 [D loss: 0.256895, acc: 96.09%] [G loss: 4.005113]\n",
      "epoch:48 step:37690 [D loss: 0.415733, acc: 84.38%] [G loss: 8.571709]\n",
      "epoch:48 step:37691 [D loss: 1.540329, acc: 37.50%] [G loss: 8.478648]\n",
      "epoch:48 step:37692 [D loss: 0.152174, acc: 99.22%] [G loss: 1.675013]\n",
      "epoch:48 step:37693 [D loss: 0.564506, acc: 72.66%] [G loss: 5.108520]\n",
      "epoch:48 step:37694 [D loss: 0.473942, acc: 79.69%] [G loss: 3.694612]\n",
      "epoch:48 step:37695 [D loss: 0.242391, acc: 92.19%] [G loss: 6.069920]\n",
      "epoch:48 step:37696 [D loss: 0.059227, acc: 100.00%] [G loss: 5.470785]\n",
      "epoch:48 step:37697 [D loss: 0.287146, acc: 92.97%] [G loss: 6.199178]\n",
      "epoch:48 step:37698 [D loss: 0.033668, acc: 100.00%] [G loss: 5.051877]\n",
      "epoch:48 step:37699 [D loss: 0.098739, acc: 99.22%] [G loss: 7.941628]\n",
      "epoch:48 step:37700 [D loss: 0.212863, acc: 97.66%] [G loss: 4.282302]\n",
      "epoch:48 step:37701 [D loss: 0.268840, acc: 89.84%] [G loss: 7.299682]\n",
      "epoch:48 step:37702 [D loss: 0.037617, acc: 100.00%] [G loss: 3.189283]\n",
      "epoch:48 step:37703 [D loss: 0.066938, acc: 100.00%] [G loss: 4.473822]\n",
      "epoch:48 step:37704 [D loss: 0.061556, acc: 98.44%] [G loss: 6.066161]\n",
      "epoch:48 step:37705 [D loss: 1.145642, acc: 51.56%] [G loss: 4.283059]\n",
      "epoch:48 step:37706 [D loss: 0.182704, acc: 98.44%] [G loss: 4.449502]\n",
      "epoch:48 step:37707 [D loss: 1.308003, acc: 48.44%] [G loss: 8.299101]\n",
      "epoch:48 step:37708 [D loss: 0.358604, acc: 80.47%] [G loss: 4.520522]\n",
      "epoch:48 step:37709 [D loss: 1.226868, acc: 51.56%] [G loss: 5.022185]\n",
      "epoch:48 step:37710 [D loss: 0.083290, acc: 100.00%] [G loss: 4.671449]\n",
      "epoch:48 step:37711 [D loss: 0.984522, acc: 50.00%] [G loss: 8.432392]\n",
      "epoch:48 step:37712 [D loss: 0.861166, acc: 52.34%] [G loss: 3.904418]\n",
      "epoch:48 step:37713 [D loss: 0.152235, acc: 99.22%] [G loss: 4.926361]\n",
      "epoch:48 step:37714 [D loss: 0.516082, acc: 80.47%] [G loss: 7.416595]\n",
      "epoch:48 step:37715 [D loss: 0.037764, acc: 100.00%] [G loss: 5.767826]\n",
      "epoch:48 step:37716 [D loss: 0.162682, acc: 97.66%] [G loss: 9.154118]\n",
      "epoch:48 step:37717 [D loss: 0.425924, acc: 85.16%] [G loss: 6.373184]\n",
      "epoch:48 step:37718 [D loss: 0.711127, acc: 56.25%] [G loss: 4.665375]\n",
      "epoch:48 step:37719 [D loss: 0.034195, acc: 100.00%] [G loss: 5.664352]\n",
      "epoch:48 step:37720 [D loss: 0.379396, acc: 78.12%] [G loss: 6.718930]\n",
      "epoch:48 step:37721 [D loss: 0.159635, acc: 100.00%] [G loss: 5.952563]\n",
      "epoch:48 step:37722 [D loss: 1.668467, acc: 9.38%] [G loss: 3.550845]\n",
      "epoch:48 step:37723 [D loss: 0.081031, acc: 100.00%] [G loss: 6.132921]\n",
      "epoch:48 step:37724 [D loss: 0.888285, acc: 46.88%] [G loss: 8.548382]\n",
      "epoch:48 step:37725 [D loss: 0.343421, acc: 83.59%] [G loss: 7.827586]\n",
      "epoch:48 step:37726 [D loss: 0.060975, acc: 100.00%] [G loss: 5.970473]\n",
      "epoch:48 step:37727 [D loss: 0.536447, acc: 64.84%] [G loss: 5.607730]\n",
      "epoch:48 step:37728 [D loss: 1.431996, acc: 50.00%] [G loss: 4.747901]\n",
      "epoch:48 step:37729 [D loss: 1.371764, acc: 21.88%] [G loss: 9.950937]\n",
      "epoch:48 step:37730 [D loss: 0.079526, acc: 99.22%] [G loss: 6.017939]\n",
      "epoch:48 step:37731 [D loss: 0.614524, acc: 58.59%] [G loss: 8.734963]\n",
      "epoch:48 step:37732 [D loss: 0.222260, acc: 99.22%] [G loss: 4.076080]\n",
      "epoch:48 step:37733 [D loss: 0.443465, acc: 73.44%] [G loss: 5.685584]\n",
      "epoch:48 step:37734 [D loss: 0.069838, acc: 100.00%] [G loss: 5.577850]\n",
      "epoch:48 step:37735 [D loss: 0.051567, acc: 100.00%] [G loss: 6.504575]\n",
      "epoch:48 step:37736 [D loss: 0.213542, acc: 98.44%] [G loss: 5.251809]\n",
      "epoch:48 step:37737 [D loss: 0.046488, acc: 100.00%] [G loss: 6.406008]\n",
      "epoch:48 step:37738 [D loss: 0.358124, acc: 87.50%] [G loss: 4.407255]\n",
      "epoch:48 step:37739 [D loss: 0.237698, acc: 95.31%] [G loss: 5.392116]\n",
      "epoch:48 step:37740 [D loss: 0.095423, acc: 98.44%] [G loss: 6.726886]\n",
      "epoch:48 step:37741 [D loss: 0.467394, acc: 75.78%] [G loss: 5.948684]\n",
      "epoch:48 step:37742 [D loss: 0.279961, acc: 95.31%] [G loss: 3.761745]\n",
      "epoch:48 step:37743 [D loss: 0.088990, acc: 100.00%] [G loss: 3.498870]\n",
      "epoch:48 step:37744 [D loss: 0.366926, acc: 81.25%] [G loss: 7.647673]\n",
      "epoch:48 step:37745 [D loss: 0.147713, acc: 99.22%] [G loss: 5.275292]\n",
      "epoch:48 step:37746 [D loss: 0.419417, acc: 73.44%] [G loss: 5.013445]\n",
      "epoch:48 step:37747 [D loss: 0.125738, acc: 99.22%] [G loss: 3.533382]\n",
      "epoch:48 step:37748 [D loss: 0.090726, acc: 100.00%] [G loss: 4.540009]\n",
      "epoch:48 step:37749 [D loss: 0.062981, acc: 100.00%] [G loss: 3.515013]\n",
      "epoch:48 step:37750 [D loss: 0.162181, acc: 99.22%] [G loss: 6.531652]\n",
      "epoch:48 step:37751 [D loss: 0.250836, acc: 91.41%] [G loss: 1.910187]\n",
      "epoch:48 step:37752 [D loss: 1.097854, acc: 36.72%] [G loss: 7.060033]\n",
      "epoch:48 step:37753 [D loss: 0.225704, acc: 94.53%] [G loss: 6.668288]\n",
      "epoch:48 step:37754 [D loss: 0.490593, acc: 71.09%] [G loss: 11.084916]\n",
      "epoch:48 step:37755 [D loss: 0.126043, acc: 98.44%] [G loss: 5.096985]\n",
      "epoch:48 step:37756 [D loss: 0.075397, acc: 100.00%] [G loss: 5.710771]\n",
      "epoch:48 step:37757 [D loss: 0.219558, acc: 94.53%] [G loss: 7.053083]\n",
      "epoch:48 step:37758 [D loss: 0.576135, acc: 64.84%] [G loss: 8.555595]\n",
      "epoch:48 step:37759 [D loss: 0.274017, acc: 96.88%] [G loss: 4.860620]\n",
      "epoch:48 step:37760 [D loss: 0.586280, acc: 60.16%] [G loss: 6.390553]\n",
      "epoch:48 step:37761 [D loss: 0.612163, acc: 59.38%] [G loss: 8.162508]\n",
      "epoch:48 step:37762 [D loss: 0.348089, acc: 90.62%] [G loss: 5.926761]\n",
      "epoch:48 step:37763 [D loss: 0.244486, acc: 98.44%] [G loss: 5.760898]\n",
      "epoch:48 step:37764 [D loss: 0.648006, acc: 57.03%] [G loss: 5.966866]\n",
      "epoch:48 step:37765 [D loss: 0.032165, acc: 100.00%] [G loss: 7.919711]\n",
      "epoch:48 step:37766 [D loss: 0.229019, acc: 96.88%] [G loss: 7.684774]\n",
      "epoch:48 step:37767 [D loss: 0.375987, acc: 78.91%] [G loss: 6.500038]\n",
      "epoch:48 step:37768 [D loss: 0.033228, acc: 100.00%] [G loss: 4.504659]\n",
      "epoch:48 step:37769 [D loss: 0.081313, acc: 100.00%] [G loss: 7.271920]\n",
      "epoch:48 step:37770 [D loss: 0.847685, acc: 48.44%] [G loss: 7.185856]\n",
      "epoch:48 step:37771 [D loss: 0.095392, acc: 100.00%] [G loss: 4.570304]\n",
      "epoch:48 step:37772 [D loss: 0.427906, acc: 74.22%] [G loss: 6.020493]\n",
      "epoch:48 step:37773 [D loss: 0.830044, acc: 51.56%] [G loss: 11.283052]\n",
      "epoch:48 step:37774 [D loss: 0.188868, acc: 95.31%] [G loss: 6.938246]\n",
      "epoch:48 step:37775 [D loss: 0.024846, acc: 100.00%] [G loss: 3.635989]\n",
      "epoch:48 step:37776 [D loss: 0.090045, acc: 100.00%] [G loss: 2.961859]\n",
      "epoch:48 step:37777 [D loss: 0.634663, acc: 59.38%] [G loss: 5.234315]\n",
      "epoch:48 step:37778 [D loss: 0.277762, acc: 93.75%] [G loss: 3.428177]\n",
      "epoch:48 step:37779 [D loss: 0.174044, acc: 98.44%] [G loss: 6.115100]\n",
      "epoch:48 step:37780 [D loss: 0.416937, acc: 70.31%] [G loss: 5.899232]\n",
      "epoch:48 step:37781 [D loss: 0.130357, acc: 99.22%] [G loss: 7.230456]\n",
      "epoch:48 step:37782 [D loss: 0.484110, acc: 69.53%] [G loss: 2.642789]\n",
      "epoch:48 step:37783 [D loss: 0.139624, acc: 98.44%] [G loss: 5.187756]\n",
      "epoch:48 step:37784 [D loss: 0.038482, acc: 100.00%] [G loss: 4.713015]\n",
      "epoch:48 step:37785 [D loss: 0.143964, acc: 100.00%] [G loss: 5.963613]\n",
      "epoch:48 step:37786 [D loss: 0.490107, acc: 71.09%] [G loss: 6.138031]\n",
      "epoch:48 step:37787 [D loss: 0.104609, acc: 99.22%] [G loss: 6.483756]\n",
      "epoch:48 step:37788 [D loss: 0.421549, acc: 88.28%] [G loss: 6.750107]\n",
      "epoch:48 step:37789 [D loss: 0.974292, acc: 41.41%] [G loss: 6.803821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37790 [D loss: 1.315284, acc: 50.00%] [G loss: 8.464220]\n",
      "epoch:48 step:37791 [D loss: 0.411422, acc: 73.44%] [G loss: 3.677781]\n",
      "epoch:48 step:37792 [D loss: 0.173447, acc: 98.44%] [G loss: 5.224742]\n",
      "epoch:48 step:37793 [D loss: 0.149826, acc: 96.88%] [G loss: 12.448225]\n",
      "epoch:48 step:37794 [D loss: 0.039815, acc: 100.00%] [G loss: 7.390382]\n",
      "epoch:48 step:37795 [D loss: 1.658607, acc: 50.00%] [G loss: 11.384043]\n",
      "epoch:48 step:37796 [D loss: 0.109296, acc: 97.66%] [G loss: 6.532402]\n",
      "epoch:48 step:37797 [D loss: 0.060762, acc: 99.22%] [G loss: 7.586606]\n",
      "epoch:48 step:37798 [D loss: 0.174177, acc: 99.22%] [G loss: 5.830779]\n",
      "epoch:48 step:37799 [D loss: 2.284429, acc: 50.00%] [G loss: 3.580268]\n",
      "epoch:48 step:37800 [D loss: 0.313894, acc: 89.84%] [G loss: 5.695773]\n",
      "epoch:48 step:37801 [D loss: 0.169444, acc: 97.66%] [G loss: 9.598881]\n",
      "epoch:48 step:37802 [D loss: 0.189093, acc: 99.22%] [G loss: 5.294977]\n",
      "epoch:48 step:37803 [D loss: 0.065769, acc: 100.00%] [G loss: 7.007232]\n",
      "epoch:48 step:37804 [D loss: 0.166156, acc: 97.66%] [G loss: 3.276425]\n",
      "epoch:48 step:37805 [D loss: 0.104691, acc: 98.44%] [G loss: 6.553463]\n",
      "epoch:48 step:37806 [D loss: 0.011562, acc: 100.00%] [G loss: 4.073455]\n",
      "epoch:48 step:37807 [D loss: 0.058989, acc: 100.00%] [G loss: 5.548498]\n",
      "epoch:48 step:37808 [D loss: 0.382964, acc: 87.50%] [G loss: 4.297484]\n",
      "epoch:48 step:37809 [D loss: 0.129869, acc: 99.22%] [G loss: 5.009605]\n",
      "epoch:48 step:37810 [D loss: 0.188613, acc: 99.22%] [G loss: 7.982963]\n",
      "epoch:48 step:37811 [D loss: 0.090237, acc: 100.00%] [G loss: 8.565210]\n",
      "epoch:48 step:37812 [D loss: 1.647413, acc: 50.00%] [G loss: 7.008410]\n",
      "epoch:48 step:37813 [D loss: 0.072933, acc: 100.00%] [G loss: 6.175046]\n",
      "epoch:48 step:37814 [D loss: 0.776586, acc: 52.34%] [G loss: 7.647777]\n",
      "epoch:48 step:37815 [D loss: 0.206512, acc: 96.09%] [G loss: 6.887084]\n",
      "epoch:48 step:37816 [D loss: 0.682746, acc: 58.59%] [G loss: 4.260657]\n",
      "epoch:48 step:37817 [D loss: 0.228747, acc: 95.31%] [G loss: 6.224530]\n",
      "epoch:48 step:37818 [D loss: 0.089658, acc: 100.00%] [G loss: 7.028042]\n",
      "epoch:48 step:37819 [D loss: 0.876375, acc: 51.56%] [G loss: 5.826032]\n",
      "epoch:48 step:37820 [D loss: 0.312538, acc: 84.38%] [G loss: 4.364101]\n",
      "epoch:48 step:37821 [D loss: 0.072291, acc: 100.00%] [G loss: 8.083723]\n",
      "epoch:48 step:37822 [D loss: 0.046888, acc: 100.00%] [G loss: 8.737377]\n",
      "epoch:48 step:37823 [D loss: 0.017419, acc: 100.00%] [G loss: 6.413562]\n",
      "epoch:48 step:37824 [D loss: 0.051928, acc: 100.00%] [G loss: 7.924762]\n",
      "epoch:48 step:37825 [D loss: 0.332019, acc: 94.53%] [G loss: 3.029640]\n",
      "epoch:48 step:37826 [D loss: 0.232947, acc: 96.09%] [G loss: 7.507286]\n",
      "epoch:48 step:37827 [D loss: 0.022950, acc: 100.00%] [G loss: 3.906903]\n",
      "epoch:48 step:37828 [D loss: 0.094894, acc: 100.00%] [G loss: 3.319948]\n",
      "epoch:48 step:37829 [D loss: 0.094019, acc: 100.00%] [G loss: 4.380514]\n",
      "epoch:48 step:37830 [D loss: 0.755022, acc: 55.47%] [G loss: 3.066198]\n",
      "epoch:48 step:37831 [D loss: 1.130550, acc: 51.56%] [G loss: 7.480892]\n",
      "epoch:48 step:37832 [D loss: 0.079773, acc: 99.22%] [G loss: 4.149096]\n",
      "epoch:48 step:37833 [D loss: 0.153575, acc: 98.44%] [G loss: 4.747431]\n",
      "epoch:48 step:37834 [D loss: 0.131826, acc: 99.22%] [G loss: 5.775334]\n",
      "epoch:48 step:37835 [D loss: 0.180557, acc: 96.09%] [G loss: 7.480814]\n",
      "epoch:48 step:37836 [D loss: 0.075539, acc: 100.00%] [G loss: 3.455686]\n",
      "epoch:48 step:37837 [D loss: 0.143851, acc: 98.44%] [G loss: 1.769268]\n",
      "epoch:48 step:37838 [D loss: 0.219761, acc: 96.09%] [G loss: 1.882895]\n",
      "epoch:48 step:37839 [D loss: 0.091147, acc: 99.22%] [G loss: 3.935297]\n",
      "epoch:48 step:37840 [D loss: 0.100457, acc: 99.22%] [G loss: 4.083484]\n",
      "epoch:48 step:37841 [D loss: 0.139519, acc: 99.22%] [G loss: 3.010539]\n",
      "epoch:48 step:37842 [D loss: 1.476214, acc: 50.00%] [G loss: 5.801832]\n",
      "epoch:48 step:37843 [D loss: 0.252009, acc: 93.75%] [G loss: 2.637664]\n",
      "epoch:48 step:37844 [D loss: 1.456254, acc: 50.00%] [G loss: 5.854783]\n",
      "epoch:48 step:37845 [D loss: 0.137585, acc: 100.00%] [G loss: 4.944880]\n",
      "epoch:48 step:37846 [D loss: 0.436657, acc: 85.16%] [G loss: 5.558100]\n",
      "epoch:48 step:37847 [D loss: 1.097011, acc: 51.56%] [G loss: 6.867386]\n",
      "epoch:48 step:37848 [D loss: 0.047906, acc: 100.00%] [G loss: 7.078335]\n",
      "epoch:48 step:37849 [D loss: 0.095969, acc: 100.00%] [G loss: 5.991190]\n",
      "epoch:48 step:37850 [D loss: 0.196414, acc: 98.44%] [G loss: 3.119844]\n",
      "epoch:48 step:37851 [D loss: 0.441619, acc: 82.03%] [G loss: 5.684190]\n",
      "epoch:48 step:37852 [D loss: 0.455399, acc: 81.25%] [G loss: 5.389804]\n",
      "epoch:48 step:37853 [D loss: 0.087541, acc: 100.00%] [G loss: 8.511507]\n",
      "epoch:48 step:37854 [D loss: 0.271084, acc: 95.31%] [G loss: 5.547762]\n",
      "epoch:48 step:37855 [D loss: 0.064485, acc: 100.00%] [G loss: 8.808958]\n",
      "epoch:48 step:37856 [D loss: 0.471324, acc: 81.25%] [G loss: 3.926553]\n",
      "epoch:48 step:37857 [D loss: 0.222866, acc: 98.44%] [G loss: 6.243606]\n",
      "epoch:48 step:37858 [D loss: 0.010461, acc: 100.00%] [G loss: 8.019768]\n",
      "epoch:48 step:37859 [D loss: 0.175740, acc: 97.66%] [G loss: 6.690264]\n",
      "epoch:48 step:37860 [D loss: 0.073652, acc: 99.22%] [G loss: 5.576176]\n",
      "epoch:48 step:37861 [D loss: 0.043316, acc: 100.00%] [G loss: 4.751768]\n",
      "epoch:48 step:37862 [D loss: 0.469044, acc: 79.69%] [G loss: 7.989936]\n",
      "epoch:48 step:37863 [D loss: 0.842922, acc: 50.00%] [G loss: 5.372421]\n",
      "epoch:48 step:37864 [D loss: 0.304134, acc: 89.06%] [G loss: 6.055120]\n",
      "epoch:48 step:37865 [D loss: 0.448774, acc: 76.56%] [G loss: 8.156467]\n",
      "epoch:48 step:37866 [D loss: 0.050126, acc: 100.00%] [G loss: 6.733003]\n",
      "epoch:48 step:37867 [D loss: 0.072888, acc: 99.22%] [G loss: 3.839196]\n",
      "epoch:48 step:37868 [D loss: 0.193680, acc: 98.44%] [G loss: 3.381696]\n",
      "epoch:48 step:37869 [D loss: 0.570186, acc: 70.31%] [G loss: 7.617630]\n",
      "epoch:48 step:37870 [D loss: 0.334947, acc: 86.72%] [G loss: 5.009011]\n",
      "epoch:48 step:37871 [D loss: 0.412035, acc: 83.59%] [G loss: 5.884251]\n",
      "epoch:48 step:37872 [D loss: 2.251378, acc: 39.84%] [G loss: 5.021139]\n",
      "epoch:48 step:37873 [D loss: 0.101912, acc: 100.00%] [G loss: 4.806508]\n",
      "epoch:48 step:37874 [D loss: 1.096972, acc: 50.00%] [G loss: 8.750267]\n",
      "epoch:48 step:37875 [D loss: 0.197926, acc: 99.22%] [G loss: 6.659583]\n",
      "epoch:48 step:37876 [D loss: 1.103272, acc: 50.78%] [G loss: 10.056032]\n",
      "epoch:48 step:37877 [D loss: 0.155303, acc: 99.22%] [G loss: 5.489104]\n",
      "epoch:48 step:37878 [D loss: 0.141835, acc: 99.22%] [G loss: 4.971669]\n",
      "epoch:48 step:37879 [D loss: 0.547823, acc: 69.53%] [G loss: 8.336355]\n",
      "epoch:48 step:37880 [D loss: 0.022306, acc: 100.00%] [G loss: 7.614221]\n",
      "epoch:48 step:37881 [D loss: 0.208813, acc: 96.88%] [G loss: 4.040313]\n",
      "epoch:48 step:37882 [D loss: 0.058068, acc: 99.22%] [G loss: 7.717522]\n",
      "epoch:48 step:37883 [D loss: 0.015579, acc: 100.00%] [G loss: 5.818007]\n",
      "epoch:48 step:37884 [D loss: 0.475966, acc: 63.28%] [G loss: 5.603240]\n",
      "epoch:48 step:37885 [D loss: 0.385422, acc: 85.16%] [G loss: 4.801925]\n",
      "epoch:48 step:37886 [D loss: 0.551003, acc: 60.94%] [G loss: 4.965484]\n",
      "epoch:48 step:37887 [D loss: 0.051830, acc: 100.00%] [G loss: 5.848534]\n",
      "epoch:48 step:37888 [D loss: 0.121031, acc: 98.44%] [G loss: 4.318027]\n",
      "epoch:48 step:37889 [D loss: 0.069388, acc: 100.00%] [G loss: 7.705684]\n",
      "epoch:48 step:37890 [D loss: 0.295509, acc: 89.06%] [G loss: 5.109717]\n",
      "epoch:48 step:37891 [D loss: 0.076134, acc: 100.00%] [G loss: 7.388256]\n",
      "epoch:48 step:37892 [D loss: 0.234034, acc: 99.22%] [G loss: 4.907764]\n",
      "epoch:48 step:37893 [D loss: 0.221292, acc: 95.31%] [G loss: 6.091740]\n",
      "epoch:48 step:37894 [D loss: 0.101221, acc: 100.00%] [G loss: 4.588094]\n",
      "epoch:48 step:37895 [D loss: 0.099187, acc: 100.00%] [G loss: 6.990763]\n",
      "epoch:48 step:37896 [D loss: 1.241689, acc: 50.00%] [G loss: 4.253972]\n",
      "epoch:48 step:37897 [D loss: 0.177478, acc: 96.09%] [G loss: 3.199800]\n",
      "epoch:48 step:37898 [D loss: 0.273378, acc: 86.72%] [G loss: 9.743832]\n",
      "epoch:48 step:37899 [D loss: 0.061264, acc: 100.00%] [G loss: 3.530365]\n",
      "epoch:48 step:37900 [D loss: 0.318053, acc: 83.59%] [G loss: 6.170186]\n",
      "epoch:48 step:37901 [D loss: 0.007215, acc: 100.00%] [G loss: 5.573273]\n",
      "epoch:48 step:37902 [D loss: 0.116115, acc: 100.00%] [G loss: 3.322482]\n",
      "epoch:48 step:37903 [D loss: 0.211126, acc: 93.75%] [G loss: 5.299026]\n",
      "epoch:48 step:37904 [D loss: 0.678492, acc: 57.03%] [G loss: 5.683748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37905 [D loss: 1.444834, acc: 50.78%] [G loss: 4.874567]\n",
      "epoch:48 step:37906 [D loss: 0.043946, acc: 100.00%] [G loss: 5.140472]\n",
      "epoch:48 step:37907 [D loss: 0.016953, acc: 100.00%] [G loss: 7.314794]\n",
      "epoch:48 step:37908 [D loss: 0.299244, acc: 83.59%] [G loss: 6.221524]\n",
      "epoch:48 step:37909 [D loss: 0.662741, acc: 63.28%] [G loss: 7.463396]\n",
      "epoch:48 step:37910 [D loss: 0.141563, acc: 100.00%] [G loss: 8.928872]\n",
      "epoch:48 step:37911 [D loss: 0.189989, acc: 98.44%] [G loss: 5.640333]\n",
      "epoch:48 step:37912 [D loss: 0.327338, acc: 84.38%] [G loss: 4.482986]\n",
      "epoch:48 step:37913 [D loss: 0.236332, acc: 90.62%] [G loss: 4.026269]\n",
      "epoch:48 step:37914 [D loss: 0.664599, acc: 55.47%] [G loss: 9.005329]\n",
      "epoch:48 step:37915 [D loss: 0.040682, acc: 100.00%] [G loss: 6.149708]\n",
      "epoch:48 step:37916 [D loss: 0.124253, acc: 99.22%] [G loss: 5.936411]\n",
      "epoch:48 step:37917 [D loss: 0.273140, acc: 91.41%] [G loss: 4.561085]\n",
      "epoch:48 step:37918 [D loss: 0.028825, acc: 100.00%] [G loss: 3.239600]\n",
      "epoch:48 step:37919 [D loss: 1.421336, acc: 13.28%] [G loss: 7.148943]\n",
      "epoch:48 step:37920 [D loss: 0.012383, acc: 100.00%] [G loss: 7.118447]\n",
      "epoch:48 step:37921 [D loss: 0.444711, acc: 85.16%] [G loss: 5.672521]\n",
      "epoch:48 step:37922 [D loss: 0.078846, acc: 100.00%] [G loss: 7.056911]\n",
      "epoch:48 step:37923 [D loss: 0.094907, acc: 100.00%] [G loss: 5.354632]\n",
      "epoch:48 step:37924 [D loss: 0.316302, acc: 84.38%] [G loss: 5.822381]\n",
      "epoch:48 step:37925 [D loss: 0.239248, acc: 98.44%] [G loss: 7.246698]\n",
      "epoch:48 step:37926 [D loss: 0.478170, acc: 82.81%] [G loss: 7.239231]\n",
      "epoch:48 step:37927 [D loss: 0.781395, acc: 52.34%] [G loss: 4.800848]\n",
      "epoch:48 step:37928 [D loss: 1.056280, acc: 42.19%] [G loss: 7.564483]\n",
      "epoch:48 step:37929 [D loss: 0.490953, acc: 79.69%] [G loss: 5.711469]\n",
      "epoch:48 step:37930 [D loss: 0.110696, acc: 100.00%] [G loss: 6.090278]\n",
      "epoch:48 step:37931 [D loss: 0.264107, acc: 96.09%] [G loss: 5.901581]\n",
      "epoch:48 step:37932 [D loss: 0.484020, acc: 64.84%] [G loss: 4.848346]\n",
      "epoch:48 step:37933 [D loss: 0.442870, acc: 85.94%] [G loss: 4.044636]\n",
      "epoch:48 step:37934 [D loss: 0.563183, acc: 71.09%] [G loss: 7.174878]\n",
      "epoch:48 step:37935 [D loss: 0.203193, acc: 96.09%] [G loss: 8.181240]\n",
      "epoch:48 step:37936 [D loss: 0.365966, acc: 77.34%] [G loss: 4.881394]\n",
      "epoch:48 step:37937 [D loss: 0.170787, acc: 96.88%] [G loss: 5.780711]\n",
      "epoch:48 step:37938 [D loss: 0.102884, acc: 99.22%] [G loss: 8.847743]\n",
      "epoch:48 step:37939 [D loss: 0.104628, acc: 99.22%] [G loss: 3.579243]\n",
      "epoch:48 step:37940 [D loss: 0.300627, acc: 94.53%] [G loss: 2.923007]\n",
      "epoch:48 step:37941 [D loss: 0.078076, acc: 99.22%] [G loss: 7.200794]\n",
      "epoch:48 step:37942 [D loss: 0.071909, acc: 100.00%] [G loss: 6.583626]\n",
      "epoch:48 step:37943 [D loss: 0.098914, acc: 100.00%] [G loss: 2.906347]\n",
      "epoch:48 step:37944 [D loss: 0.072662, acc: 100.00%] [G loss: 6.822202]\n",
      "epoch:48 step:37945 [D loss: 0.107405, acc: 100.00%] [G loss: 3.732488]\n",
      "epoch:48 step:37946 [D loss: 0.113353, acc: 100.00%] [G loss: 3.466311]\n",
      "epoch:48 step:37947 [D loss: 0.564310, acc: 67.19%] [G loss: 6.790965]\n",
      "epoch:48 step:37948 [D loss: 0.225104, acc: 91.41%] [G loss: 5.145380]\n",
      "epoch:48 step:37949 [D loss: 0.041820, acc: 100.00%] [G loss: 4.432780]\n",
      "epoch:48 step:37950 [D loss: 0.779792, acc: 53.12%] [G loss: 4.980614]\n",
      "epoch:48 step:37951 [D loss: 0.230241, acc: 92.19%] [G loss: 7.231417]\n",
      "epoch:48 step:37952 [D loss: 0.479555, acc: 68.75%] [G loss: 2.885483]\n",
      "epoch:48 step:37953 [D loss: 0.160138, acc: 99.22%] [G loss: 5.824177]\n",
      "epoch:48 step:37954 [D loss: 0.304091, acc: 82.81%] [G loss: 5.015563]\n",
      "epoch:48 step:37955 [D loss: 0.089013, acc: 99.22%] [G loss: 6.419831]\n",
      "epoch:48 step:37956 [D loss: 0.262571, acc: 96.88%] [G loss: 5.364868]\n",
      "epoch:48 step:37957 [D loss: 0.168367, acc: 99.22%] [G loss: 7.708421]\n",
      "epoch:48 step:37958 [D loss: 0.042874, acc: 100.00%] [G loss: 8.757515]\n",
      "epoch:48 step:37959 [D loss: 0.247236, acc: 98.44%] [G loss: 4.275752]\n",
      "epoch:48 step:37960 [D loss: 0.441411, acc: 80.47%] [G loss: 7.192005]\n",
      "epoch:48 step:37961 [D loss: 0.400212, acc: 78.91%] [G loss: 4.714561]\n",
      "epoch:48 step:37962 [D loss: 0.353965, acc: 82.81%] [G loss: 4.827195]\n",
      "epoch:48 step:37963 [D loss: 0.755153, acc: 53.91%] [G loss: 9.642035]\n",
      "epoch:48 step:37964 [D loss: 0.498391, acc: 63.28%] [G loss: 5.310327]\n",
      "epoch:48 step:37965 [D loss: 0.406758, acc: 79.69%] [G loss: 5.239276]\n",
      "epoch:48 step:37966 [D loss: 0.024954, acc: 100.00%] [G loss: 7.183734]\n",
      "epoch:48 step:37967 [D loss: 0.934228, acc: 50.00%] [G loss: 6.045796]\n",
      "epoch:48 step:37968 [D loss: 0.089909, acc: 100.00%] [G loss: 5.089744]\n",
      "epoch:48 step:37969 [D loss: 0.102518, acc: 100.00%] [G loss: 5.119273]\n",
      "epoch:48 step:37970 [D loss: 0.034772, acc: 100.00%] [G loss: 6.479372]\n",
      "epoch:48 step:37971 [D loss: 0.372131, acc: 72.66%] [G loss: 4.502309]\n",
      "epoch:48 step:37972 [D loss: 0.262400, acc: 96.88%] [G loss: 6.178136]\n",
      "epoch:48 step:37973 [D loss: 0.401461, acc: 77.34%] [G loss: 2.576986]\n",
      "epoch:48 step:37974 [D loss: 0.433486, acc: 70.31%] [G loss: 2.913053]\n",
      "epoch:48 step:37975 [D loss: 0.228802, acc: 93.75%] [G loss: 4.492701]\n",
      "epoch:48 step:37976 [D loss: 0.168940, acc: 95.31%] [G loss: 8.978750]\n",
      "epoch:48 step:37977 [D loss: 0.690562, acc: 55.47%] [G loss: 5.418916]\n",
      "epoch:48 step:37978 [D loss: 0.068594, acc: 100.00%] [G loss: 6.937420]\n",
      "epoch:48 step:37979 [D loss: 0.038854, acc: 100.00%] [G loss: 7.217739]\n",
      "epoch:48 step:37980 [D loss: 0.266813, acc: 88.28%] [G loss: 4.194907]\n",
      "epoch:48 step:37981 [D loss: 0.073919, acc: 100.00%] [G loss: 3.973163]\n",
      "epoch:48 step:37982 [D loss: 0.512314, acc: 63.28%] [G loss: 3.344021]\n",
      "epoch:48 step:37983 [D loss: 0.062627, acc: 100.00%] [G loss: 3.377415]\n",
      "epoch:48 step:37984 [D loss: 0.277906, acc: 94.53%] [G loss: 6.122673]\n",
      "epoch:48 step:37985 [D loss: 0.126773, acc: 100.00%] [G loss: 7.855929]\n",
      "epoch:48 step:37986 [D loss: 0.135538, acc: 97.66%] [G loss: 4.587441]\n",
      "epoch:48 step:37987 [D loss: 0.147770, acc: 98.44%] [G loss: 1.377073]\n",
      "epoch:48 step:37988 [D loss: 0.376322, acc: 89.84%] [G loss: 4.576638]\n",
      "epoch:48 step:37989 [D loss: 0.333785, acc: 85.16%] [G loss: 5.523424]\n",
      "epoch:48 step:37990 [D loss: 0.278686, acc: 92.19%] [G loss: 6.043056]\n",
      "epoch:48 step:37991 [D loss: 0.181199, acc: 96.09%] [G loss: 4.288769]\n",
      "epoch:48 step:37992 [D loss: 0.148764, acc: 100.00%] [G loss: 6.215729]\n",
      "epoch:48 step:37993 [D loss: 0.178276, acc: 97.66%] [G loss: 2.120097]\n",
      "epoch:48 step:37994 [D loss: 0.065443, acc: 99.22%] [G loss: 4.549666]\n",
      "epoch:48 step:37995 [D loss: 0.176694, acc: 98.44%] [G loss: 8.141545]\n",
      "epoch:48 step:37996 [D loss: 0.217111, acc: 93.75%] [G loss: 4.432618]\n",
      "epoch:48 step:37997 [D loss: 0.125649, acc: 97.66%] [G loss: 9.576142]\n",
      "epoch:48 step:37998 [D loss: 0.034222, acc: 100.00%] [G loss: 6.149228]\n",
      "epoch:48 step:37999 [D loss: 0.187055, acc: 96.88%] [G loss: 7.357037]\n",
      "epoch:48 step:38000 [D loss: 0.196365, acc: 96.09%] [G loss: 5.957337]\n",
      "epoch:48 step:38001 [D loss: 0.165131, acc: 99.22%] [G loss: 4.286373]\n",
      "epoch:48 step:38002 [D loss: 0.113548, acc: 99.22%] [G loss: 6.941757]\n",
      "epoch:48 step:38003 [D loss: 0.024451, acc: 100.00%] [G loss: 6.189243]\n",
      "epoch:48 step:38004 [D loss: 0.433261, acc: 78.91%] [G loss: 6.472795]\n",
      "epoch:48 step:38005 [D loss: 0.190840, acc: 95.31%] [G loss: 5.559758]\n",
      "epoch:48 step:38006 [D loss: 0.312621, acc: 84.38%] [G loss: 6.646479]\n",
      "epoch:48 step:38007 [D loss: 0.161093, acc: 99.22%] [G loss: 9.323528]\n",
      "epoch:48 step:38008 [D loss: 0.358416, acc: 85.16%] [G loss: 8.015409]\n",
      "epoch:48 step:38009 [D loss: 0.647399, acc: 54.69%] [G loss: 8.662764]\n",
      "epoch:48 step:38010 [D loss: 0.779947, acc: 55.47%] [G loss: 5.130620]\n",
      "epoch:48 step:38011 [D loss: 0.366027, acc: 91.41%] [G loss: 4.270579]\n",
      "epoch:48 step:38012 [D loss: 0.316332, acc: 84.38%] [G loss: 3.911438]\n",
      "epoch:48 step:38013 [D loss: 0.323807, acc: 95.31%] [G loss: 2.781592]\n",
      "epoch:48 step:38014 [D loss: 0.171566, acc: 98.44%] [G loss: 4.538148]\n",
      "epoch:48 step:38015 [D loss: 0.173443, acc: 99.22%] [G loss: 7.054945]\n",
      "epoch:48 step:38016 [D loss: 0.302366, acc: 95.31%] [G loss: 8.235273]\n",
      "epoch:48 step:38017 [D loss: 0.020754, acc: 100.00%] [G loss: 6.588908]\n",
      "epoch:48 step:38018 [D loss: 0.053849, acc: 100.00%] [G loss: 4.459086]\n",
      "epoch:48 step:38019 [D loss: 0.059781, acc: 100.00%] [G loss: 5.860164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38020 [D loss: 0.291011, acc: 94.53%] [G loss: 10.215330]\n",
      "epoch:48 step:38021 [D loss: 0.483725, acc: 73.44%] [G loss: 5.377196]\n",
      "epoch:48 step:38022 [D loss: 0.391892, acc: 75.00%] [G loss: 6.783789]\n",
      "epoch:48 step:38023 [D loss: 0.023554, acc: 100.00%] [G loss: 5.826587]\n",
      "epoch:48 step:38024 [D loss: 0.021638, acc: 100.00%] [G loss: 12.400212]\n",
      "epoch:48 step:38025 [D loss: 0.192024, acc: 99.22%] [G loss: 9.268869]\n",
      "epoch:48 step:38026 [D loss: 0.153354, acc: 96.88%] [G loss: 8.093545]\n",
      "epoch:48 step:38027 [D loss: 0.443554, acc: 83.59%] [G loss: 5.827550]\n",
      "epoch:48 step:38028 [D loss: 0.511294, acc: 72.66%] [G loss: 6.665834]\n",
      "epoch:48 step:38029 [D loss: 0.040187, acc: 100.00%] [G loss: 4.409822]\n",
      "epoch:48 step:38030 [D loss: 0.049297, acc: 100.00%] [G loss: 4.284045]\n",
      "epoch:48 step:38031 [D loss: 0.338466, acc: 92.19%] [G loss: 6.534266]\n",
      "epoch:48 step:38032 [D loss: 0.007561, acc: 100.00%] [G loss: 9.664316]\n",
      "epoch:48 step:38033 [D loss: 0.010573, acc: 100.00%] [G loss: 6.195542]\n",
      "epoch:48 step:38034 [D loss: 0.087872, acc: 99.22%] [G loss: 3.628862]\n",
      "epoch:48 step:38035 [D loss: 0.013966, acc: 100.00%] [G loss: 7.685639]\n",
      "epoch:48 step:38036 [D loss: 0.070717, acc: 100.00%] [G loss: 3.974900]\n",
      "epoch:48 step:38037 [D loss: 0.158049, acc: 99.22%] [G loss: 4.734242]\n",
      "epoch:48 step:38038 [D loss: 0.386546, acc: 77.34%] [G loss: 5.280800]\n",
      "epoch:48 step:38039 [D loss: 0.051839, acc: 100.00%] [G loss: 1.454005]\n",
      "epoch:48 step:38040 [D loss: 0.110990, acc: 99.22%] [G loss: 4.057791]\n",
      "epoch:48 step:38041 [D loss: 0.036427, acc: 100.00%] [G loss: 4.226727]\n",
      "epoch:48 step:38042 [D loss: 0.137228, acc: 100.00%] [G loss: 6.215065]\n",
      "epoch:48 step:38043 [D loss: 0.025736, acc: 100.00%] [G loss: 6.843279]\n",
      "epoch:48 step:38044 [D loss: 1.109246, acc: 19.53%] [G loss: 8.546599]\n",
      "epoch:48 step:38045 [D loss: 1.358279, acc: 50.78%] [G loss: 5.914861]\n",
      "epoch:48 step:38046 [D loss: 0.230168, acc: 92.19%] [G loss: 6.977909]\n",
      "epoch:48 step:38047 [D loss: 0.031761, acc: 100.00%] [G loss: 8.030123]\n",
      "epoch:48 step:38048 [D loss: 0.131527, acc: 97.66%] [G loss: 5.715392]\n",
      "epoch:48 step:38049 [D loss: 0.157496, acc: 98.44%] [G loss: 7.357263]\n",
      "epoch:48 step:38050 [D loss: 0.199723, acc: 92.97%] [G loss: 7.259157]\n",
      "epoch:48 step:38051 [D loss: 0.079846, acc: 99.22%] [G loss: 8.437687]\n",
      "epoch:48 step:38052 [D loss: 0.068229, acc: 100.00%] [G loss: 4.925178]\n",
      "epoch:48 step:38053 [D loss: 0.220364, acc: 96.09%] [G loss: 4.277167]\n",
      "epoch:48 step:38054 [D loss: 0.803416, acc: 52.34%] [G loss: 6.230648]\n",
      "epoch:48 step:38055 [D loss: 0.054894, acc: 100.00%] [G loss: 5.759542]\n",
      "epoch:48 step:38056 [D loss: 0.079810, acc: 100.00%] [G loss: 6.161352]\n",
      "epoch:48 step:38057 [D loss: 0.035365, acc: 100.00%] [G loss: 6.559308]\n",
      "epoch:48 step:38058 [D loss: 0.088584, acc: 100.00%] [G loss: 6.461552]\n",
      "epoch:48 step:38059 [D loss: 0.211788, acc: 96.09%] [G loss: 8.257613]\n",
      "epoch:48 step:38060 [D loss: 0.023596, acc: 100.00%] [G loss: 9.269147]\n",
      "epoch:48 step:38061 [D loss: 0.445576, acc: 75.00%] [G loss: 8.419083]\n",
      "epoch:48 step:38062 [D loss: 0.266668, acc: 90.62%] [G loss: 5.844111]\n",
      "epoch:48 step:38063 [D loss: 0.121017, acc: 99.22%] [G loss: 4.095428]\n",
      "epoch:48 step:38064 [D loss: 0.434520, acc: 71.88%] [G loss: 6.068938]\n",
      "epoch:48 step:38065 [D loss: 0.012812, acc: 100.00%] [G loss: 7.668860]\n",
      "epoch:48 step:38066 [D loss: 0.237972, acc: 92.19%] [G loss: 9.604094]\n",
      "epoch:48 step:38067 [D loss: 0.376276, acc: 89.84%] [G loss: 6.547124]\n",
      "epoch:48 step:38068 [D loss: 0.079106, acc: 100.00%] [G loss: 7.721124]\n",
      "epoch:48 step:38069 [D loss: 0.334697, acc: 82.81%] [G loss: 8.952335]\n",
      "epoch:48 step:38070 [D loss: 0.037597, acc: 100.00%] [G loss: 10.440035]\n",
      "epoch:48 step:38071 [D loss: 1.504482, acc: 50.00%] [G loss: 9.056707]\n",
      "epoch:48 step:38072 [D loss: 0.403578, acc: 78.12%] [G loss: 8.348282]\n",
      "epoch:48 step:38073 [D loss: 0.433323, acc: 75.78%] [G loss: 8.674438]\n",
      "epoch:48 step:38074 [D loss: 0.091482, acc: 100.00%] [G loss: 7.517817]\n",
      "epoch:48 step:38075 [D loss: 0.013659, acc: 100.00%] [G loss: 2.859845]\n",
      "epoch:48 step:38076 [D loss: 0.113123, acc: 100.00%] [G loss: 8.373355]\n",
      "epoch:48 step:38077 [D loss: 1.042425, acc: 50.00%] [G loss: 6.383597]\n",
      "epoch:48 step:38078 [D loss: 0.623390, acc: 54.69%] [G loss: 9.812456]\n",
      "epoch:48 step:38079 [D loss: 0.319783, acc: 86.72%] [G loss: 5.616920]\n",
      "epoch:48 step:38080 [D loss: 0.154737, acc: 99.22%] [G loss: 4.771829]\n",
      "epoch:48 step:38081 [D loss: 0.029456, acc: 100.00%] [G loss: 6.894198]\n",
      "epoch:48 step:38082 [D loss: 0.482456, acc: 69.53%] [G loss: 6.618010]\n",
      "epoch:48 step:38083 [D loss: 0.267787, acc: 92.19%] [G loss: 6.204836]\n",
      "epoch:48 step:38084 [D loss: 0.020079, acc: 100.00%] [G loss: 4.519419]\n",
      "epoch:48 step:38085 [D loss: 0.100317, acc: 100.00%] [G loss: 6.868124]\n",
      "epoch:48 step:38086 [D loss: 0.234001, acc: 95.31%] [G loss: 5.910249]\n",
      "epoch:48 step:38087 [D loss: 0.154031, acc: 98.44%] [G loss: 5.334851]\n",
      "epoch:48 step:38088 [D loss: 0.037635, acc: 99.22%] [G loss: 8.685496]\n",
      "epoch:48 step:38089 [D loss: 0.179511, acc: 98.44%] [G loss: 6.293637]\n",
      "epoch:48 step:38090 [D loss: 0.079706, acc: 99.22%] [G loss: 3.642297]\n",
      "epoch:48 step:38091 [D loss: 1.084436, acc: 21.09%] [G loss: 4.429525]\n",
      "epoch:48 step:38092 [D loss: 0.637976, acc: 57.81%] [G loss: 4.468088]\n",
      "epoch:48 step:38093 [D loss: 0.017512, acc: 100.00%] [G loss: 4.608125]\n",
      "epoch:48 step:38094 [D loss: 0.116265, acc: 100.00%] [G loss: 5.281498]\n",
      "epoch:48 step:38095 [D loss: 0.843477, acc: 52.34%] [G loss: 9.843193]\n",
      "epoch:48 step:38096 [D loss: 0.460275, acc: 78.91%] [G loss: 6.409728]\n",
      "epoch:48 step:38097 [D loss: 0.373873, acc: 85.94%] [G loss: 3.781347]\n",
      "epoch:48 step:38098 [D loss: 0.403393, acc: 73.44%] [G loss: 6.645618]\n",
      "epoch:48 step:38099 [D loss: 0.248659, acc: 92.97%] [G loss: 2.459751]\n",
      "epoch:48 step:38100 [D loss: 0.214379, acc: 96.09%] [G loss: 8.987218]\n",
      "epoch:48 step:38101 [D loss: 0.204938, acc: 96.88%] [G loss: 8.928008]\n",
      "epoch:48 step:38102 [D loss: 0.097975, acc: 99.22%] [G loss: 5.326396]\n",
      "epoch:48 step:38103 [D loss: 0.227317, acc: 95.31%] [G loss: 6.092635]\n",
      "epoch:48 step:38104 [D loss: 0.160142, acc: 99.22%] [G loss: 2.759818]\n",
      "epoch:48 step:38105 [D loss: 0.190342, acc: 97.66%] [G loss: 4.537078]\n",
      "epoch:48 step:38106 [D loss: 0.029972, acc: 100.00%] [G loss: 6.553895]\n",
      "epoch:48 step:38107 [D loss: 0.485583, acc: 80.47%] [G loss: 4.106838]\n",
      "epoch:48 step:38108 [D loss: 0.228113, acc: 95.31%] [G loss: 7.048675]\n",
      "epoch:48 step:38109 [D loss: 0.211083, acc: 94.53%] [G loss: 8.748942]\n",
      "epoch:48 step:38110 [D loss: 0.264910, acc: 92.19%] [G loss: 4.155173]\n",
      "epoch:48 step:38111 [D loss: 0.080838, acc: 100.00%] [G loss: 6.360256]\n",
      "epoch:48 step:38112 [D loss: 0.025236, acc: 100.00%] [G loss: 7.675639]\n",
      "epoch:48 step:38113 [D loss: 0.153347, acc: 96.88%] [G loss: 3.560596]\n",
      "epoch:48 step:38114 [D loss: 1.579064, acc: 17.19%] [G loss: 4.751410]\n",
      "epoch:48 step:38115 [D loss: 0.287208, acc: 92.19%] [G loss: 4.347864]\n",
      "epoch:48 step:38116 [D loss: 0.068182, acc: 100.00%] [G loss: 7.876479]\n",
      "epoch:48 step:38117 [D loss: 1.446889, acc: 25.78%] [G loss: 7.227283]\n",
      "epoch:48 step:38118 [D loss: 0.049901, acc: 100.00%] [G loss: 4.673968]\n",
      "epoch:48 step:38119 [D loss: 0.889642, acc: 49.22%] [G loss: 6.016763]\n",
      "epoch:48 step:38120 [D loss: 0.152833, acc: 99.22%] [G loss: 5.443624]\n",
      "epoch:48 step:38121 [D loss: 0.662253, acc: 62.50%] [G loss: 4.251538]\n",
      "epoch:48 step:38122 [D loss: 1.036595, acc: 50.00%] [G loss: 6.927722]\n",
      "epoch:48 step:38123 [D loss: 0.302443, acc: 85.94%] [G loss: 7.214882]\n",
      "epoch:48 step:38124 [D loss: 0.244312, acc: 91.41%] [G loss: 9.670498]\n",
      "epoch:48 step:38125 [D loss: 0.393523, acc: 75.78%] [G loss: 5.608715]\n",
      "epoch:48 step:38126 [D loss: 0.155870, acc: 98.44%] [G loss: 6.814396]\n",
      "epoch:48 step:38127 [D loss: 0.275378, acc: 90.62%] [G loss: 5.808066]\n",
      "epoch:48 step:38128 [D loss: 0.100009, acc: 100.00%] [G loss: 2.976016]\n",
      "epoch:48 step:38129 [D loss: 0.229329, acc: 91.41%] [G loss: 8.288885]\n",
      "epoch:48 step:38130 [D loss: 0.111274, acc: 100.00%] [G loss: 5.053895]\n",
      "epoch:48 step:38131 [D loss: 0.128128, acc: 97.66%] [G loss: 3.958697]\n",
      "epoch:48 step:38132 [D loss: 0.765596, acc: 57.81%] [G loss: 7.493650]\n",
      "epoch:48 step:38133 [D loss: 0.138574, acc: 97.66%] [G loss: 7.054169]\n",
      "epoch:48 step:38134 [D loss: 0.839855, acc: 46.88%] [G loss: 5.290966]\n",
      "epoch:48 step:38135 [D loss: 1.023179, acc: 51.56%] [G loss: 10.195171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38136 [D loss: 0.260460, acc: 96.88%] [G loss: 5.860656]\n",
      "epoch:48 step:38137 [D loss: 0.059572, acc: 100.00%] [G loss: 4.701114]\n",
      "epoch:48 step:38138 [D loss: 0.252572, acc: 92.97%] [G loss: 4.608644]\n",
      "epoch:48 step:38139 [D loss: 0.309869, acc: 86.72%] [G loss: 5.363253]\n",
      "epoch:48 step:38140 [D loss: 0.200246, acc: 94.53%] [G loss: 6.505750]\n",
      "epoch:48 step:38141 [D loss: 0.022767, acc: 100.00%] [G loss: 4.159226]\n",
      "epoch:48 step:38142 [D loss: 0.107470, acc: 99.22%] [G loss: 4.409753]\n",
      "epoch:48 step:38143 [D loss: 0.197966, acc: 98.44%] [G loss: 6.161025]\n",
      "epoch:48 step:38144 [D loss: 0.561086, acc: 69.53%] [G loss: 4.441743]\n",
      "epoch:48 step:38145 [D loss: 0.089378, acc: 100.00%] [G loss: 4.767061]\n",
      "epoch:48 step:38146 [D loss: 0.708067, acc: 60.16%] [G loss: 8.488095]\n",
      "epoch:48 step:38147 [D loss: 0.063767, acc: 100.00%] [G loss: 8.099839]\n",
      "epoch:48 step:38148 [D loss: 0.519663, acc: 66.41%] [G loss: 4.699567]\n",
      "epoch:48 step:38149 [D loss: 0.023091, acc: 100.00%] [G loss: 7.097870]\n",
      "epoch:48 step:38150 [D loss: 0.208427, acc: 94.53%] [G loss: 4.725202]\n",
      "epoch:48 step:38151 [D loss: 0.506765, acc: 66.41%] [G loss: 7.122445]\n",
      "epoch:48 step:38152 [D loss: 0.239927, acc: 92.97%] [G loss: 7.477084]\n",
      "epoch:48 step:38153 [D loss: 0.517997, acc: 78.91%] [G loss: 5.731983]\n",
      "epoch:48 step:38154 [D loss: 0.282339, acc: 90.62%] [G loss: 3.690055]\n",
      "epoch:48 step:38155 [D loss: 0.005563, acc: 100.00%] [G loss: 6.273618]\n",
      "epoch:48 step:38156 [D loss: 0.072174, acc: 99.22%] [G loss: 4.302771]\n",
      "epoch:48 step:38157 [D loss: 0.737779, acc: 56.25%] [G loss: 6.150523]\n",
      "epoch:48 step:38158 [D loss: 0.021532, acc: 100.00%] [G loss: 4.714176]\n",
      "epoch:48 step:38159 [D loss: 0.305416, acc: 89.06%] [G loss: 8.899874]\n",
      "epoch:48 step:38160 [D loss: 0.085065, acc: 100.00%] [G loss: 6.466376]\n",
      "epoch:48 step:38161 [D loss: 0.949330, acc: 28.91%] [G loss: 5.320571]\n",
      "epoch:48 step:38162 [D loss: 0.172395, acc: 96.09%] [G loss: 5.482178]\n",
      "epoch:48 step:38163 [D loss: 0.076644, acc: 100.00%] [G loss: 7.198410]\n",
      "epoch:48 step:38164 [D loss: 0.236424, acc: 94.53%] [G loss: 5.807813]\n",
      "epoch:48 step:38165 [D loss: 0.073919, acc: 100.00%] [G loss: 3.735478]\n",
      "epoch:48 step:38166 [D loss: 0.580326, acc: 59.38%] [G loss: 3.371162]\n",
      "epoch:48 step:38167 [D loss: 0.202383, acc: 96.88%] [G loss: 2.814855]\n",
      "epoch:48 step:38168 [D loss: 0.084879, acc: 100.00%] [G loss: 6.313823]\n",
      "epoch:48 step:38169 [D loss: 0.111210, acc: 100.00%] [G loss: 4.385958]\n",
      "epoch:48 step:38170 [D loss: 0.483066, acc: 64.84%] [G loss: 7.020179]\n",
      "epoch:48 step:38171 [D loss: 0.292065, acc: 84.38%] [G loss: 8.726917]\n",
      "epoch:48 step:38172 [D loss: 0.333868, acc: 78.91%] [G loss: 5.445350]\n",
      "epoch:48 step:38173 [D loss: 0.211420, acc: 95.31%] [G loss: 4.577600]\n",
      "epoch:48 step:38174 [D loss: 0.293111, acc: 96.09%] [G loss: 6.803082]\n",
      "epoch:48 step:38175 [D loss: 0.281002, acc: 88.28%] [G loss: 6.824883]\n",
      "epoch:48 step:38176 [D loss: 0.628100, acc: 64.06%] [G loss: 8.264982]\n",
      "epoch:48 step:38177 [D loss: 0.170368, acc: 94.53%] [G loss: 5.725815]\n",
      "epoch:48 step:38178 [D loss: 0.181588, acc: 96.09%] [G loss: 7.490122]\n",
      "epoch:48 step:38179 [D loss: 0.056473, acc: 100.00%] [G loss: 6.825277]\n",
      "epoch:48 step:38180 [D loss: 0.543700, acc: 72.66%] [G loss: 8.462303]\n",
      "epoch:48 step:38181 [D loss: 0.413429, acc: 69.53%] [G loss: 8.811831]\n",
      "epoch:48 step:38182 [D loss: 0.084869, acc: 99.22%] [G loss: 3.741517]\n",
      "epoch:48 step:38183 [D loss: 0.126253, acc: 99.22%] [G loss: 7.512717]\n",
      "epoch:48 step:38184 [D loss: 0.597217, acc: 61.72%] [G loss: 6.267812]\n",
      "epoch:48 step:38185 [D loss: 0.016019, acc: 100.00%] [G loss: 5.878203]\n",
      "epoch:48 step:38186 [D loss: 0.041278, acc: 100.00%] [G loss: 4.861447]\n",
      "epoch:48 step:38187 [D loss: 0.414640, acc: 76.56%] [G loss: 7.240843]\n",
      "epoch:48 step:38188 [D loss: 1.014938, acc: 52.34%] [G loss: 5.364142]\n",
      "epoch:48 step:38189 [D loss: 0.135759, acc: 97.66%] [G loss: 8.580755]\n",
      "epoch:48 step:38190 [D loss: 2.913708, acc: 0.78%] [G loss: 6.278744]\n",
      "epoch:48 step:38191 [D loss: 0.024432, acc: 100.00%] [G loss: 3.964365]\n",
      "epoch:48 step:38192 [D loss: 0.687997, acc: 57.81%] [G loss: 5.858632]\n",
      "epoch:48 step:38193 [D loss: 0.119510, acc: 100.00%] [G loss: 10.016232]\n",
      "epoch:48 step:38194 [D loss: 0.540798, acc: 67.19%] [G loss: 6.065851]\n",
      "epoch:48 step:38195 [D loss: 0.066813, acc: 100.00%] [G loss: 6.345318]\n",
      "epoch:48 step:38196 [D loss: 0.096993, acc: 100.00%] [G loss: 5.937572]\n",
      "epoch:48 step:38197 [D loss: 0.052406, acc: 100.00%] [G loss: 6.825839]\n",
      "epoch:48 step:38198 [D loss: 0.416239, acc: 78.12%] [G loss: 6.118983]\n",
      "epoch:48 step:38199 [D loss: 0.036364, acc: 100.00%] [G loss: 5.887002]\n",
      "epoch:48 step:38200 [D loss: 0.238632, acc: 93.75%] [G loss: 6.461579]\n",
      "epoch:48 step:38201 [D loss: 0.055353, acc: 100.00%] [G loss: 4.128917]\n",
      "epoch:48 step:38202 [D loss: 0.092756, acc: 100.00%] [G loss: 6.226251]\n",
      "epoch:48 step:38203 [D loss: 0.143623, acc: 99.22%] [G loss: 2.951869]\n",
      "epoch:48 step:38204 [D loss: 0.135449, acc: 98.44%] [G loss: 7.005119]\n",
      "epoch:48 step:38205 [D loss: 0.105859, acc: 99.22%] [G loss: 4.976397]\n",
      "epoch:48 step:38206 [D loss: 0.064194, acc: 100.00%] [G loss: 4.949924]\n",
      "epoch:48 step:38207 [D loss: 0.108962, acc: 99.22%] [G loss: 5.351126]\n",
      "epoch:48 step:38208 [D loss: 0.110452, acc: 100.00%] [G loss: 4.744109]\n",
      "epoch:48 step:38209 [D loss: 0.244598, acc: 91.41%] [G loss: 9.553455]\n",
      "epoch:48 step:38210 [D loss: 0.808108, acc: 50.00%] [G loss: 6.431056]\n",
      "epoch:48 step:38211 [D loss: 0.114005, acc: 96.88%] [G loss: 8.011547]\n",
      "epoch:48 step:38212 [D loss: 0.058767, acc: 99.22%] [G loss: 6.982467]\n",
      "epoch:48 step:38213 [D loss: 0.080232, acc: 100.00%] [G loss: 6.106009]\n",
      "epoch:48 step:38214 [D loss: 0.011186, acc: 100.00%] [G loss: 9.138570]\n",
      "epoch:48 step:38215 [D loss: 0.182018, acc: 99.22%] [G loss: 4.601661]\n",
      "epoch:48 step:38216 [D loss: 0.093234, acc: 100.00%] [G loss: 7.476200]\n",
      "epoch:48 step:38217 [D loss: 0.057923, acc: 99.22%] [G loss: 4.254068]\n",
      "epoch:48 step:38218 [D loss: 0.674293, acc: 53.91%] [G loss: 3.634323]\n",
      "epoch:48 step:38219 [D loss: 0.087106, acc: 99.22%] [G loss: 6.000964]\n",
      "epoch:48 step:38220 [D loss: 0.332187, acc: 88.28%] [G loss: 4.541252]\n",
      "epoch:48 step:38221 [D loss: 0.085566, acc: 100.00%] [G loss: 4.282485]\n",
      "epoch:48 step:38222 [D loss: 0.693267, acc: 54.69%] [G loss: 9.591068]\n",
      "epoch:48 step:38223 [D loss: 0.086891, acc: 100.00%] [G loss: 6.936939]\n",
      "epoch:48 step:38224 [D loss: 0.045865, acc: 100.00%] [G loss: 4.396359]\n",
      "epoch:48 step:38225 [D loss: 0.948681, acc: 45.31%] [G loss: 5.048345]\n",
      "epoch:48 step:38226 [D loss: 0.617794, acc: 67.97%] [G loss: 4.086655]\n",
      "epoch:48 step:38227 [D loss: 0.698088, acc: 60.94%] [G loss: 5.223382]\n",
      "epoch:48 step:38228 [D loss: 0.326816, acc: 89.84%] [G loss: 5.777606]\n",
      "epoch:48 step:38229 [D loss: 0.487208, acc: 77.34%] [G loss: 7.561048]\n",
      "epoch:48 step:38230 [D loss: 0.302370, acc: 93.75%] [G loss: 1.693298]\n",
      "epoch:48 step:38231 [D loss: 0.047207, acc: 100.00%] [G loss: 5.625200]\n",
      "epoch:48 step:38232 [D loss: 0.373697, acc: 79.69%] [G loss: 8.295325]\n",
      "epoch:48 step:38233 [D loss: 0.011036, acc: 100.00%] [G loss: 3.630977]\n",
      "epoch:48 step:38234 [D loss: 0.242928, acc: 93.75%] [G loss: 4.882244]\n",
      "epoch:48 step:38235 [D loss: 0.891369, acc: 52.34%] [G loss: 6.807688]\n",
      "epoch:48 step:38236 [D loss: 0.452026, acc: 65.62%] [G loss: 6.730223]\n",
      "epoch:48 step:38237 [D loss: 0.083499, acc: 100.00%] [G loss: 6.735530]\n",
      "epoch:48 step:38238 [D loss: 0.043299, acc: 100.00%] [G loss: 6.003894]\n",
      "epoch:48 step:38239 [D loss: 0.260362, acc: 95.31%] [G loss: 9.199947]\n",
      "epoch:48 step:38240 [D loss: 0.028998, acc: 100.00%] [G loss: 3.351696]\n",
      "epoch:48 step:38241 [D loss: 0.038264, acc: 100.00%] [G loss: 8.605129]\n",
      "epoch:48 step:38242 [D loss: 0.038912, acc: 100.00%] [G loss: 7.409476]\n",
      "epoch:48 step:38243 [D loss: 0.009596, acc: 100.00%] [G loss: 7.593320]\n",
      "epoch:48 step:38244 [D loss: 0.300335, acc: 92.19%] [G loss: 10.033730]\n",
      "epoch:48 step:38245 [D loss: 0.257996, acc: 93.75%] [G loss: 4.756264]\n",
      "epoch:48 step:38246 [D loss: 0.136682, acc: 98.44%] [G loss: 5.333988]\n",
      "epoch:48 step:38247 [D loss: 0.193908, acc: 96.09%] [G loss: 8.686519]\n",
      "epoch:48 step:38248 [D loss: 0.164526, acc: 96.88%] [G loss: 5.804234]\n",
      "epoch:48 step:38249 [D loss: 0.148928, acc: 99.22%] [G loss: 6.196670]\n",
      "epoch:48 step:38250 [D loss: 0.283642, acc: 92.97%] [G loss: 8.279542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38251 [D loss: 0.217483, acc: 99.22%] [G loss: 6.313785]\n",
      "epoch:48 step:38252 [D loss: 0.282148, acc: 84.38%] [G loss: 5.470116]\n",
      "epoch:48 step:38253 [D loss: 0.069613, acc: 100.00%] [G loss: 5.952358]\n",
      "epoch:48 step:38254 [D loss: 0.463059, acc: 71.88%] [G loss: 7.540977]\n",
      "epoch:48 step:38255 [D loss: 0.677792, acc: 52.34%] [G loss: 6.061752]\n",
      "epoch:48 step:38256 [D loss: 0.070750, acc: 100.00%] [G loss: 6.469341]\n",
      "epoch:48 step:38257 [D loss: 0.267243, acc: 97.66%] [G loss: 6.801592]\n",
      "epoch:48 step:38258 [D loss: 0.052056, acc: 100.00%] [G loss: 3.753358]\n",
      "epoch:48 step:38259 [D loss: 0.065479, acc: 100.00%] [G loss: 4.763030]\n",
      "epoch:48 step:38260 [D loss: 0.319344, acc: 82.81%] [G loss: 7.282283]\n",
      "epoch:48 step:38261 [D loss: 0.013849, acc: 100.00%] [G loss: 9.072573]\n",
      "epoch:48 step:38262 [D loss: 0.995554, acc: 51.56%] [G loss: 4.056220]\n",
      "epoch:48 step:38263 [D loss: 0.195437, acc: 92.97%] [G loss: 6.465054]\n",
      "epoch:48 step:38264 [D loss: 0.785642, acc: 52.34%] [G loss: 8.284702]\n",
      "epoch:48 step:38265 [D loss: 0.509599, acc: 72.66%] [G loss: 5.251693]\n",
      "epoch:48 step:38266 [D loss: 0.426096, acc: 86.72%] [G loss: 2.767671]\n",
      "epoch:48 step:38267 [D loss: 0.424193, acc: 74.22%] [G loss: 7.520428]\n",
      "epoch:48 step:38268 [D loss: 0.138526, acc: 99.22%] [G loss: 7.082714]\n",
      "epoch:48 step:38269 [D loss: 0.458887, acc: 66.41%] [G loss: 12.163303]\n",
      "epoch:49 step:38270 [D loss: 0.333087, acc: 93.75%] [G loss: 5.703369]\n",
      "epoch:49 step:38271 [D loss: 0.018692, acc: 100.00%] [G loss: 7.810250]\n",
      "epoch:49 step:38272 [D loss: 0.033073, acc: 100.00%] [G loss: 3.864976]\n",
      "epoch:49 step:38273 [D loss: 0.283653, acc: 89.06%] [G loss: 8.656536]\n",
      "epoch:49 step:38274 [D loss: 0.181609, acc: 99.22%] [G loss: 5.844449]\n",
      "epoch:49 step:38275 [D loss: 0.881248, acc: 44.53%] [G loss: 5.365134]\n",
      "epoch:49 step:38276 [D loss: 0.125276, acc: 98.44%] [G loss: 8.559987]\n",
      "epoch:49 step:38277 [D loss: 0.032322, acc: 100.00%] [G loss: 7.188046]\n",
      "epoch:49 step:38278 [D loss: 0.216922, acc: 96.09%] [G loss: 10.310383]\n",
      "epoch:49 step:38279 [D loss: 0.266989, acc: 96.09%] [G loss: 5.835182]\n",
      "epoch:49 step:38280 [D loss: 0.744648, acc: 54.69%] [G loss: 5.503638]\n",
      "epoch:49 step:38281 [D loss: 0.837870, acc: 49.22%] [G loss: 6.546158]\n",
      "epoch:49 step:38282 [D loss: 0.374121, acc: 80.47%] [G loss: 4.275712]\n",
      "epoch:49 step:38283 [D loss: 0.060077, acc: 100.00%] [G loss: 6.110420]\n",
      "epoch:49 step:38284 [D loss: 0.964158, acc: 50.00%] [G loss: 8.385574]\n",
      "epoch:49 step:38285 [D loss: 0.066448, acc: 100.00%] [G loss: 5.590792]\n",
      "epoch:49 step:38286 [D loss: 0.048003, acc: 99.22%] [G loss: 7.145489]\n",
      "epoch:49 step:38287 [D loss: 1.262109, acc: 34.38%] [G loss: 10.447577]\n",
      "epoch:49 step:38288 [D loss: 0.617604, acc: 56.25%] [G loss: 4.670500]\n",
      "epoch:49 step:38289 [D loss: 0.028472, acc: 100.00%] [G loss: 6.477943]\n",
      "epoch:49 step:38290 [D loss: 0.030768, acc: 100.00%] [G loss: 7.417397]\n",
      "epoch:49 step:38291 [D loss: 0.371896, acc: 82.03%] [G loss: 5.318299]\n",
      "epoch:49 step:38292 [D loss: 0.290055, acc: 87.50%] [G loss: 5.716899]\n",
      "epoch:49 step:38293 [D loss: 0.146510, acc: 97.66%] [G loss: 4.366337]\n",
      "epoch:49 step:38294 [D loss: 0.454157, acc: 76.56%] [G loss: 6.929418]\n",
      "epoch:49 step:38295 [D loss: 0.035578, acc: 100.00%] [G loss: 7.292739]\n",
      "epoch:49 step:38296 [D loss: 0.191202, acc: 96.88%] [G loss: 4.456470]\n",
      "epoch:49 step:38297 [D loss: 0.037434, acc: 100.00%] [G loss: 4.161264]\n",
      "epoch:49 step:38298 [D loss: 0.232403, acc: 92.97%] [G loss: 5.856273]\n",
      "epoch:49 step:38299 [D loss: 0.019020, acc: 100.00%] [G loss: 3.627732]\n",
      "epoch:49 step:38300 [D loss: 0.283085, acc: 90.62%] [G loss: 6.473905]\n",
      "epoch:49 step:38301 [D loss: 0.195758, acc: 96.09%] [G loss: 6.070301]\n",
      "epoch:49 step:38302 [D loss: 0.037828, acc: 100.00%] [G loss: 9.849566]\n",
      "epoch:49 step:38303 [D loss: 0.335234, acc: 92.97%] [G loss: 7.112160]\n",
      "epoch:49 step:38304 [D loss: 0.273120, acc: 93.75%] [G loss: 3.868452]\n",
      "epoch:49 step:38305 [D loss: 0.023214, acc: 100.00%] [G loss: 6.528966]\n",
      "epoch:49 step:38306 [D loss: 0.058888, acc: 100.00%] [G loss: 5.488816]\n",
      "epoch:49 step:38307 [D loss: 0.152698, acc: 99.22%] [G loss: 7.274789]\n",
      "epoch:49 step:38308 [D loss: 0.042184, acc: 100.00%] [G loss: 9.506043]\n",
      "epoch:49 step:38309 [D loss: 0.006172, acc: 100.00%] [G loss: 7.336637]\n",
      "epoch:49 step:38310 [D loss: 0.117171, acc: 99.22%] [G loss: 4.190559]\n",
      "epoch:49 step:38311 [D loss: 0.081299, acc: 100.00%] [G loss: 7.906379]\n",
      "epoch:49 step:38312 [D loss: 0.548956, acc: 60.16%] [G loss: 7.008698]\n",
      "epoch:49 step:38313 [D loss: 0.093854, acc: 100.00%] [G loss: 4.656209]\n",
      "epoch:49 step:38314 [D loss: 0.257102, acc: 93.75%] [G loss: 6.921082]\n",
      "epoch:49 step:38315 [D loss: 0.036701, acc: 100.00%] [G loss: 6.583155]\n",
      "epoch:49 step:38316 [D loss: 0.178787, acc: 98.44%] [G loss: 11.295603]\n",
      "epoch:49 step:38317 [D loss: 0.225214, acc: 92.19%] [G loss: 4.906613]\n",
      "epoch:49 step:38318 [D loss: 0.110055, acc: 100.00%] [G loss: 7.851452]\n",
      "epoch:49 step:38319 [D loss: 0.148700, acc: 99.22%] [G loss: 4.888803]\n",
      "epoch:49 step:38320 [D loss: 0.591424, acc: 70.31%] [G loss: 5.668238]\n",
      "epoch:49 step:38321 [D loss: 0.632213, acc: 64.84%] [G loss: 9.582704]\n",
      "epoch:49 step:38322 [D loss: 0.050848, acc: 100.00%] [G loss: 6.992884]\n",
      "epoch:49 step:38323 [D loss: 0.248130, acc: 94.53%] [G loss: 3.118444]\n",
      "epoch:49 step:38324 [D loss: 0.106135, acc: 100.00%] [G loss: 3.960731]\n",
      "epoch:49 step:38325 [D loss: 0.055867, acc: 100.00%] [G loss: 6.592832]\n",
      "epoch:49 step:38326 [D loss: 0.093166, acc: 98.44%] [G loss: 3.256060]\n",
      "epoch:49 step:38327 [D loss: 0.062025, acc: 100.00%] [G loss: 7.930995]\n",
      "epoch:49 step:38328 [D loss: 0.077789, acc: 100.00%] [G loss: 5.817657]\n",
      "epoch:49 step:38329 [D loss: 0.060932, acc: 100.00%] [G loss: 3.350771]\n",
      "epoch:49 step:38330 [D loss: 0.637238, acc: 57.03%] [G loss: 4.796352]\n",
      "epoch:49 step:38331 [D loss: 0.095644, acc: 99.22%] [G loss: 4.485562]\n",
      "epoch:49 step:38332 [D loss: 0.210252, acc: 92.19%] [G loss: 5.332994]\n",
      "epoch:49 step:38333 [D loss: 1.043830, acc: 50.00%] [G loss: 7.355252]\n",
      "epoch:49 step:38334 [D loss: 0.258534, acc: 94.53%] [G loss: 5.043148]\n",
      "epoch:49 step:38335 [D loss: 0.118543, acc: 98.44%] [G loss: 6.312348]\n",
      "epoch:49 step:38336 [D loss: 1.290190, acc: 30.47%] [G loss: 6.091760]\n",
      "epoch:49 step:38337 [D loss: 0.033179, acc: 100.00%] [G loss: 3.568418]\n",
      "epoch:49 step:38338 [D loss: 0.085322, acc: 100.00%] [G loss: 6.011617]\n",
      "epoch:49 step:38339 [D loss: 0.478720, acc: 81.25%] [G loss: 7.194962]\n",
      "epoch:49 step:38340 [D loss: 0.134361, acc: 100.00%] [G loss: 4.204416]\n",
      "epoch:49 step:38341 [D loss: 0.102796, acc: 99.22%] [G loss: 6.065030]\n",
      "epoch:49 step:38342 [D loss: 0.921714, acc: 50.78%] [G loss: 7.305144]\n",
      "epoch:49 step:38343 [D loss: 0.091886, acc: 100.00%] [G loss: 7.750626]\n",
      "epoch:49 step:38344 [D loss: 0.052762, acc: 100.00%] [G loss: 7.808939]\n",
      "epoch:49 step:38345 [D loss: 0.503502, acc: 64.84%] [G loss: 8.361919]\n",
      "epoch:49 step:38346 [D loss: 0.278983, acc: 95.31%] [G loss: 3.877822]\n",
      "epoch:49 step:38347 [D loss: 0.316816, acc: 92.19%] [G loss: 7.779040]\n",
      "epoch:49 step:38348 [D loss: 0.410588, acc: 67.97%] [G loss: 9.275551]\n",
      "epoch:49 step:38349 [D loss: 0.064811, acc: 100.00%] [G loss: 3.846689]\n",
      "epoch:49 step:38350 [D loss: 0.432997, acc: 76.56%] [G loss: 8.202923]\n",
      "epoch:49 step:38351 [D loss: 0.146094, acc: 96.09%] [G loss: 4.784431]\n",
      "epoch:49 step:38352 [D loss: 0.174301, acc: 96.88%] [G loss: 9.154522]\n",
      "epoch:49 step:38353 [D loss: 0.685284, acc: 53.91%] [G loss: 6.963209]\n",
      "epoch:49 step:38354 [D loss: 0.513490, acc: 67.19%] [G loss: 3.197947]\n",
      "epoch:49 step:38355 [D loss: 0.121171, acc: 99.22%] [G loss: 7.208612]\n",
      "epoch:49 step:38356 [D loss: 1.482174, acc: 51.56%] [G loss: 8.613054]\n",
      "epoch:49 step:38357 [D loss: 0.041828, acc: 100.00%] [G loss: 4.617880]\n",
      "epoch:49 step:38358 [D loss: 0.228924, acc: 92.97%] [G loss: 6.921343]\n",
      "epoch:49 step:38359 [D loss: 0.375044, acc: 87.50%] [G loss: 5.839513]\n",
      "epoch:49 step:38360 [D loss: 0.087541, acc: 100.00%] [G loss: 9.007113]\n",
      "epoch:49 step:38361 [D loss: 0.012278, acc: 100.00%] [G loss: 7.422791]\n",
      "epoch:49 step:38362 [D loss: 0.118554, acc: 100.00%] [G loss: 6.030268]\n",
      "epoch:49 step:38363 [D loss: 0.413226, acc: 85.16%] [G loss: 6.169864]\n",
      "epoch:49 step:38364 [D loss: 0.098145, acc: 100.00%] [G loss: 6.040983]\n",
      "epoch:49 step:38365 [D loss: 0.265128, acc: 96.88%] [G loss: 3.634261]\n",
      "epoch:49 step:38366 [D loss: 0.159107, acc: 99.22%] [G loss: 11.534846]\n",
      "epoch:49 step:38367 [D loss: 0.103959, acc: 99.22%] [G loss: 11.072424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38368 [D loss: 0.263462, acc: 91.41%] [G loss: 2.942619]\n",
      "epoch:49 step:38369 [D loss: 0.067557, acc: 100.00%] [G loss: 4.389875]\n",
      "epoch:49 step:38370 [D loss: 0.215776, acc: 96.88%] [G loss: 3.723673]\n",
      "epoch:49 step:38371 [D loss: 0.299149, acc: 80.47%] [G loss: 4.545618]\n",
      "epoch:49 step:38372 [D loss: 0.964555, acc: 41.41%] [G loss: 9.330993]\n",
      "epoch:49 step:38373 [D loss: 0.114762, acc: 99.22%] [G loss: 5.069360]\n",
      "epoch:49 step:38374 [D loss: 0.222930, acc: 92.97%] [G loss: 4.934375]\n",
      "epoch:49 step:38375 [D loss: 0.315749, acc: 85.16%] [G loss: 6.498098]\n",
      "epoch:49 step:38376 [D loss: 0.289214, acc: 85.16%] [G loss: 5.918021]\n",
      "epoch:49 step:38377 [D loss: 0.378037, acc: 85.94%] [G loss: 4.195685]\n",
      "epoch:49 step:38378 [D loss: 0.505512, acc: 81.25%] [G loss: 8.371440]\n",
      "epoch:49 step:38379 [D loss: 1.109436, acc: 31.25%] [G loss: 7.030184]\n",
      "epoch:49 step:38380 [D loss: 0.012787, acc: 100.00%] [G loss: 7.633185]\n",
      "epoch:49 step:38381 [D loss: 0.045119, acc: 100.00%] [G loss: 4.703264]\n",
      "epoch:49 step:38382 [D loss: 0.476019, acc: 65.62%] [G loss: 5.020666]\n",
      "epoch:49 step:38383 [D loss: 0.015229, acc: 100.00%] [G loss: 6.487910]\n",
      "epoch:49 step:38384 [D loss: 0.655184, acc: 57.03%] [G loss: 5.009037]\n",
      "epoch:49 step:38385 [D loss: 0.419815, acc: 79.69%] [G loss: 8.760695]\n",
      "epoch:49 step:38386 [D loss: 1.448827, acc: 48.44%] [G loss: 5.427470]\n",
      "epoch:49 step:38387 [D loss: 0.198083, acc: 97.66%] [G loss: 5.401124]\n",
      "epoch:49 step:38388 [D loss: 0.676454, acc: 62.50%] [G loss: 5.080055]\n",
      "epoch:49 step:38389 [D loss: 0.024128, acc: 100.00%] [G loss: 5.319029]\n",
      "epoch:49 step:38390 [D loss: 0.112788, acc: 97.66%] [G loss: 5.195507]\n",
      "epoch:49 step:38391 [D loss: 0.050449, acc: 100.00%] [G loss: 6.325546]\n",
      "epoch:49 step:38392 [D loss: 0.635696, acc: 62.50%] [G loss: 9.073051]\n",
      "epoch:49 step:38393 [D loss: 0.264255, acc: 91.41%] [G loss: 8.371292]\n",
      "epoch:49 step:38394 [D loss: 1.334452, acc: 47.66%] [G loss: 12.102861]\n",
      "epoch:49 step:38395 [D loss: 0.120323, acc: 97.66%] [G loss: 4.230541]\n",
      "epoch:49 step:38396 [D loss: 1.321120, acc: 50.00%] [G loss: 10.194756]\n",
      "epoch:49 step:38397 [D loss: 0.101930, acc: 99.22%] [G loss: 4.428423]\n",
      "epoch:49 step:38398 [D loss: 0.032556, acc: 100.00%] [G loss: 7.571054]\n",
      "epoch:49 step:38399 [D loss: 0.070708, acc: 99.22%] [G loss: 7.331201]\n",
      "epoch:49 step:38400 [D loss: 0.181177, acc: 96.09%] [G loss: 7.815191]\n",
      "epoch:49 step:38401 [D loss: 1.540641, acc: 50.00%] [G loss: 9.198857]\n",
      "epoch:49 step:38402 [D loss: 0.124601, acc: 98.44%] [G loss: 7.641103]\n",
      "epoch:49 step:38403 [D loss: 0.107394, acc: 100.00%] [G loss: 7.705840]\n",
      "epoch:49 step:38404 [D loss: 0.109526, acc: 99.22%] [G loss: 5.708001]\n",
      "epoch:49 step:38405 [D loss: 0.050616, acc: 99.22%] [G loss: 5.188010]\n",
      "epoch:49 step:38406 [D loss: 0.267553, acc: 94.53%] [G loss: 2.860689]\n",
      "epoch:49 step:38407 [D loss: 0.210244, acc: 95.31%] [G loss: 3.841311]\n",
      "epoch:49 step:38408 [D loss: 0.141376, acc: 98.44%] [G loss: 5.324317]\n",
      "epoch:49 step:38409 [D loss: 1.040375, acc: 50.78%] [G loss: 8.211266]\n",
      "epoch:49 step:38410 [D loss: 0.379246, acc: 79.69%] [G loss: 3.870512]\n",
      "epoch:49 step:38411 [D loss: 0.263071, acc: 93.75%] [G loss: 5.191152]\n",
      "epoch:49 step:38412 [D loss: 0.232297, acc: 95.31%] [G loss: 5.649748]\n",
      "epoch:49 step:38413 [D loss: 0.206608, acc: 98.44%] [G loss: 8.478329]\n",
      "epoch:49 step:38414 [D loss: 0.101832, acc: 99.22%] [G loss: 6.229136]\n",
      "epoch:49 step:38415 [D loss: 0.195310, acc: 97.66%] [G loss: 6.859471]\n",
      "epoch:49 step:38416 [D loss: 0.568285, acc: 64.06%] [G loss: 6.763850]\n",
      "epoch:49 step:38417 [D loss: 1.592063, acc: 50.00%] [G loss: 5.911687]\n",
      "epoch:49 step:38418 [D loss: 0.255304, acc: 90.62%] [G loss: 9.881109]\n",
      "epoch:49 step:38419 [D loss: 0.322929, acc: 85.94%] [G loss: 5.506922]\n",
      "epoch:49 step:38420 [D loss: 0.152184, acc: 97.66%] [G loss: 4.720170]\n",
      "epoch:49 step:38421 [D loss: 0.810154, acc: 56.25%] [G loss: 8.354841]\n",
      "epoch:49 step:38422 [D loss: 0.102316, acc: 99.22%] [G loss: 4.860836]\n",
      "epoch:49 step:38423 [D loss: 0.092542, acc: 100.00%] [G loss: 3.581206]\n",
      "epoch:49 step:38424 [D loss: 0.511821, acc: 65.62%] [G loss: 9.746962]\n",
      "epoch:49 step:38425 [D loss: 0.241896, acc: 92.97%] [G loss: 5.810014]\n",
      "epoch:49 step:38426 [D loss: 0.362689, acc: 77.34%] [G loss: 5.970160]\n",
      "epoch:49 step:38427 [D loss: 0.110580, acc: 99.22%] [G loss: 4.104484]\n",
      "epoch:49 step:38428 [D loss: 0.401972, acc: 85.16%] [G loss: 5.266273]\n",
      "epoch:49 step:38429 [D loss: 0.151468, acc: 97.66%] [G loss: 4.242963]\n",
      "epoch:49 step:38430 [D loss: 0.180813, acc: 96.09%] [G loss: 8.876186]\n",
      "epoch:49 step:38431 [D loss: 0.712832, acc: 63.28%] [G loss: 7.091711]\n",
      "epoch:49 step:38432 [D loss: 0.206711, acc: 92.97%] [G loss: 6.949326]\n",
      "epoch:49 step:38433 [D loss: 0.255208, acc: 92.97%] [G loss: 3.039086]\n",
      "epoch:49 step:38434 [D loss: 0.086448, acc: 100.00%] [G loss: 5.405798]\n",
      "epoch:49 step:38435 [D loss: 1.052118, acc: 48.44%] [G loss: 9.059605]\n",
      "epoch:49 step:38436 [D loss: 1.122744, acc: 25.00%] [G loss: 5.539169]\n",
      "epoch:49 step:38437 [D loss: 0.219549, acc: 90.62%] [G loss: 4.756347]\n",
      "epoch:49 step:38438 [D loss: 0.579774, acc: 65.62%] [G loss: 6.452690]\n",
      "epoch:49 step:38439 [D loss: 1.140348, acc: 32.03%] [G loss: 6.026511]\n",
      "epoch:49 step:38440 [D loss: 0.057510, acc: 100.00%] [G loss: 8.747264]\n",
      "epoch:49 step:38441 [D loss: 0.074803, acc: 100.00%] [G loss: 2.240909]\n",
      "epoch:49 step:38442 [D loss: 0.922719, acc: 53.12%] [G loss: 5.031544]\n",
      "epoch:49 step:38443 [D loss: 0.072404, acc: 100.00%] [G loss: 9.170537]\n",
      "epoch:49 step:38444 [D loss: 0.229353, acc: 90.62%] [G loss: 7.943268]\n",
      "epoch:49 step:38445 [D loss: 0.067997, acc: 100.00%] [G loss: 9.321877]\n",
      "epoch:49 step:38446 [D loss: 0.179263, acc: 96.09%] [G loss: 5.377684]\n",
      "epoch:49 step:38447 [D loss: 0.120747, acc: 98.44%] [G loss: 6.575518]\n",
      "epoch:49 step:38448 [D loss: 0.167651, acc: 97.66%] [G loss: 4.841764]\n",
      "epoch:49 step:38449 [D loss: 0.859530, acc: 57.03%] [G loss: 5.969559]\n",
      "epoch:49 step:38450 [D loss: 0.124335, acc: 100.00%] [G loss: 8.533342]\n",
      "epoch:49 step:38451 [D loss: 0.515254, acc: 67.19%] [G loss: 4.783006]\n",
      "epoch:49 step:38452 [D loss: 1.098483, acc: 50.00%] [G loss: 6.821075]\n",
      "epoch:49 step:38453 [D loss: 0.064680, acc: 100.00%] [G loss: 5.071605]\n",
      "epoch:49 step:38454 [D loss: 0.187636, acc: 97.66%] [G loss: 7.767581]\n",
      "epoch:49 step:38455 [D loss: 0.447376, acc: 69.53%] [G loss: 10.576977]\n",
      "epoch:49 step:38456 [D loss: 0.097207, acc: 97.66%] [G loss: 5.001064]\n",
      "epoch:49 step:38457 [D loss: 0.229056, acc: 91.41%] [G loss: 7.228427]\n",
      "epoch:49 step:38458 [D loss: 0.021689, acc: 100.00%] [G loss: 6.609958]\n",
      "epoch:49 step:38459 [D loss: 0.007397, acc: 100.00%] [G loss: 5.137253]\n",
      "epoch:49 step:38460 [D loss: 0.675758, acc: 62.50%] [G loss: 4.507334]\n",
      "epoch:49 step:38461 [D loss: 0.055456, acc: 100.00%] [G loss: 9.045261]\n",
      "epoch:49 step:38462 [D loss: 0.046549, acc: 100.00%] [G loss: 6.383172]\n",
      "epoch:49 step:38463 [D loss: 0.130191, acc: 100.00%] [G loss: 3.832465]\n",
      "epoch:49 step:38464 [D loss: 0.689655, acc: 53.91%] [G loss: 5.509961]\n",
      "epoch:49 step:38465 [D loss: 0.230077, acc: 95.31%] [G loss: 4.358976]\n",
      "epoch:49 step:38466 [D loss: 0.288535, acc: 85.16%] [G loss: 8.868124]\n",
      "epoch:49 step:38467 [D loss: 0.266569, acc: 96.88%] [G loss: 3.142331]\n",
      "epoch:49 step:38468 [D loss: 0.030155, acc: 100.00%] [G loss: 4.565143]\n",
      "epoch:49 step:38469 [D loss: 0.112213, acc: 100.00%] [G loss: 1.891736]\n",
      "epoch:49 step:38470 [D loss: 0.632337, acc: 61.72%] [G loss: 9.297962]\n",
      "epoch:49 step:38471 [D loss: 0.487582, acc: 78.12%] [G loss: 6.864443]\n",
      "epoch:49 step:38472 [D loss: 0.408564, acc: 86.72%] [G loss: 3.673988]\n",
      "epoch:49 step:38473 [D loss: 0.118074, acc: 100.00%] [G loss: 3.691666]\n",
      "epoch:49 step:38474 [D loss: 0.911919, acc: 53.12%] [G loss: 10.960407]\n",
      "epoch:49 step:38475 [D loss: 0.412247, acc: 74.22%] [G loss: 8.760668]\n",
      "epoch:49 step:38476 [D loss: 0.066055, acc: 100.00%] [G loss: 4.482458]\n",
      "epoch:49 step:38477 [D loss: 0.070052, acc: 100.00%] [G loss: 8.229866]\n",
      "epoch:49 step:38478 [D loss: 0.163157, acc: 95.31%] [G loss: 5.535535]\n",
      "epoch:49 step:38479 [D loss: 0.107746, acc: 99.22%] [G loss: 4.700279]\n",
      "epoch:49 step:38480 [D loss: 0.793065, acc: 54.69%] [G loss: 4.587152]\n",
      "epoch:49 step:38481 [D loss: 0.089544, acc: 99.22%] [G loss: 6.249561]\n",
      "epoch:49 step:38482 [D loss: 0.635551, acc: 57.81%] [G loss: 11.691376]\n",
      "epoch:49 step:38483 [D loss: 0.129260, acc: 100.00%] [G loss: 7.705171]\n",
      "epoch:49 step:38484 [D loss: 0.127640, acc: 99.22%] [G loss: 4.460732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38485 [D loss: 0.208620, acc: 96.09%] [G loss: 5.298833]\n",
      "epoch:49 step:38486 [D loss: 0.113674, acc: 98.44%] [G loss: 8.741997]\n",
      "epoch:49 step:38487 [D loss: 0.053399, acc: 100.00%] [G loss: 4.126187]\n",
      "epoch:49 step:38488 [D loss: 0.168738, acc: 97.66%] [G loss: 6.619267]\n",
      "epoch:49 step:38489 [D loss: 0.170117, acc: 100.00%] [G loss: 3.991983]\n",
      "epoch:49 step:38490 [D loss: 0.123856, acc: 100.00%] [G loss: 4.410958]\n",
      "epoch:49 step:38491 [D loss: 0.994063, acc: 50.78%] [G loss: 7.601133]\n",
      "epoch:49 step:38492 [D loss: 0.315539, acc: 85.94%] [G loss: 3.228077]\n",
      "epoch:49 step:38493 [D loss: 0.122353, acc: 99.22%] [G loss: 8.190208]\n",
      "epoch:49 step:38494 [D loss: 0.166754, acc: 99.22%] [G loss: 2.041938]\n",
      "epoch:49 step:38495 [D loss: 0.048760, acc: 100.00%] [G loss: 3.594729]\n",
      "epoch:49 step:38496 [D loss: 0.123447, acc: 99.22%] [G loss: 5.096913]\n",
      "epoch:49 step:38497 [D loss: 0.164486, acc: 99.22%] [G loss: 4.346774]\n",
      "epoch:49 step:38498 [D loss: 0.150741, acc: 97.66%] [G loss: 8.161093]\n",
      "epoch:49 step:38499 [D loss: 0.086896, acc: 100.00%] [G loss: 7.332062]\n",
      "epoch:49 step:38500 [D loss: 0.171000, acc: 97.66%] [G loss: 6.263998]\n",
      "epoch:49 step:38501 [D loss: 0.436933, acc: 73.44%] [G loss: 7.619119]\n",
      "epoch:49 step:38502 [D loss: 0.295908, acc: 87.50%] [G loss: 8.552687]\n",
      "epoch:49 step:38503 [D loss: 0.804909, acc: 52.34%] [G loss: 4.448997]\n",
      "epoch:49 step:38504 [D loss: 0.396359, acc: 76.56%] [G loss: 6.721209]\n",
      "epoch:49 step:38505 [D loss: 0.845111, acc: 53.12%] [G loss: 7.886567]\n",
      "epoch:49 step:38506 [D loss: 0.038825, acc: 100.00%] [G loss: 9.555363]\n",
      "epoch:49 step:38507 [D loss: 0.294766, acc: 97.66%] [G loss: 7.575562]\n",
      "epoch:49 step:38508 [D loss: 0.021565, acc: 100.00%] [G loss: 7.449048]\n",
      "epoch:49 step:38509 [D loss: 0.177249, acc: 99.22%] [G loss: 4.361132]\n",
      "epoch:49 step:38510 [D loss: 0.062487, acc: 100.00%] [G loss: 7.679293]\n",
      "epoch:49 step:38511 [D loss: 0.045557, acc: 100.00%] [G loss: 2.616510]\n",
      "epoch:49 step:38512 [D loss: 0.031798, acc: 100.00%] [G loss: 5.311135]\n",
      "epoch:49 step:38513 [D loss: 0.304272, acc: 95.31%] [G loss: 7.277282]\n",
      "epoch:49 step:38514 [D loss: 0.113401, acc: 100.00%] [G loss: 7.305529]\n",
      "epoch:49 step:38515 [D loss: 0.252180, acc: 92.97%] [G loss: 4.061214]\n",
      "epoch:49 step:38516 [D loss: 0.037094, acc: 100.00%] [G loss: 5.419977]\n",
      "epoch:49 step:38517 [D loss: 1.770292, acc: 46.88%] [G loss: 4.604509]\n",
      "epoch:49 step:38518 [D loss: 0.092622, acc: 99.22%] [G loss: 9.707561]\n",
      "epoch:49 step:38519 [D loss: 1.514712, acc: 32.03%] [G loss: 6.626339]\n",
      "epoch:49 step:38520 [D loss: 0.022450, acc: 100.00%] [G loss: 8.730945]\n",
      "epoch:49 step:38521 [D loss: 0.308626, acc: 90.62%] [G loss: 2.987027]\n",
      "epoch:49 step:38522 [D loss: 0.982219, acc: 49.22%] [G loss: 7.500262]\n",
      "epoch:49 step:38523 [D loss: 0.302051, acc: 87.50%] [G loss: 4.182766]\n",
      "epoch:49 step:38524 [D loss: 0.261807, acc: 91.41%] [G loss: 5.184092]\n",
      "epoch:49 step:38525 [D loss: 0.415999, acc: 81.25%] [G loss: 7.603691]\n",
      "epoch:49 step:38526 [D loss: 0.793641, acc: 54.69%] [G loss: 3.535448]\n",
      "epoch:49 step:38527 [D loss: 0.072842, acc: 99.22%] [G loss: 5.057911]\n",
      "epoch:49 step:38528 [D loss: 0.300002, acc: 87.50%] [G loss: 9.874437]\n",
      "epoch:49 step:38529 [D loss: 0.012034, acc: 100.00%] [G loss: 2.966456]\n",
      "epoch:49 step:38530 [D loss: 0.840563, acc: 53.91%] [G loss: 6.117085]\n",
      "epoch:49 step:38531 [D loss: 0.075513, acc: 100.00%] [G loss: 5.471249]\n",
      "epoch:49 step:38532 [D loss: 0.485763, acc: 65.62%] [G loss: 10.645764]\n",
      "epoch:49 step:38533 [D loss: 0.067306, acc: 99.22%] [G loss: 3.399498]\n",
      "epoch:49 step:38534 [D loss: 0.326214, acc: 82.03%] [G loss: 4.878321]\n",
      "epoch:49 step:38535 [D loss: 0.042116, acc: 100.00%] [G loss: 7.352018]\n",
      "epoch:49 step:38536 [D loss: 0.449942, acc: 70.31%] [G loss: 4.987781]\n",
      "epoch:49 step:38537 [D loss: 0.047922, acc: 100.00%] [G loss: 2.211968]\n",
      "epoch:49 step:38538 [D loss: 0.142418, acc: 100.00%] [G loss: 5.047132]\n",
      "epoch:49 step:38539 [D loss: 0.560061, acc: 65.62%] [G loss: 9.267893]\n",
      "epoch:49 step:38540 [D loss: 0.406534, acc: 74.22%] [G loss: 7.344526]\n",
      "epoch:49 step:38541 [D loss: 0.664866, acc: 56.25%] [G loss: 4.555838]\n",
      "epoch:49 step:38542 [D loss: 1.009835, acc: 36.72%] [G loss: 4.102228]\n",
      "epoch:49 step:38543 [D loss: 1.557528, acc: 6.25%] [G loss: 4.503909]\n",
      "epoch:49 step:38544 [D loss: 0.307318, acc: 89.84%] [G loss: 5.319168]\n",
      "epoch:49 step:38545 [D loss: 0.669408, acc: 56.25%] [G loss: 7.650070]\n",
      "epoch:49 step:38546 [D loss: 0.031030, acc: 100.00%] [G loss: 7.302596]\n",
      "epoch:49 step:38547 [D loss: 0.719551, acc: 53.91%] [G loss: 9.915127]\n",
      "epoch:49 step:38548 [D loss: 0.152355, acc: 96.88%] [G loss: 6.639803]\n",
      "epoch:49 step:38549 [D loss: 0.057834, acc: 100.00%] [G loss: 6.553386]\n",
      "epoch:49 step:38550 [D loss: 0.078997, acc: 100.00%] [G loss: 7.492585]\n",
      "epoch:49 step:38551 [D loss: 0.424507, acc: 85.94%] [G loss: 5.461327]\n",
      "epoch:49 step:38552 [D loss: 0.049630, acc: 100.00%] [G loss: 5.177309]\n",
      "epoch:49 step:38553 [D loss: 0.005362, acc: 100.00%] [G loss: 7.707065]\n",
      "epoch:49 step:38554 [D loss: 0.047631, acc: 100.00%] [G loss: 3.709866]\n",
      "epoch:49 step:38555 [D loss: 0.422085, acc: 74.22%] [G loss: 7.538191]\n",
      "epoch:49 step:38556 [D loss: 0.126648, acc: 100.00%] [G loss: 5.827050]\n",
      "epoch:49 step:38557 [D loss: 0.318184, acc: 92.97%] [G loss: 5.461102]\n",
      "epoch:49 step:38558 [D loss: 0.087491, acc: 99.22%] [G loss: 4.009003]\n",
      "epoch:49 step:38559 [D loss: 0.231841, acc: 93.75%] [G loss: 6.729480]\n",
      "epoch:49 step:38560 [D loss: 0.563216, acc: 57.81%] [G loss: 5.887699]\n",
      "epoch:49 step:38561 [D loss: 0.673623, acc: 63.28%] [G loss: 6.781896]\n",
      "epoch:49 step:38562 [D loss: 0.514400, acc: 65.62%] [G loss: 4.615350]\n",
      "epoch:49 step:38563 [D loss: 0.371016, acc: 77.34%] [G loss: 5.109523]\n",
      "epoch:49 step:38564 [D loss: 0.120650, acc: 100.00%] [G loss: 6.766144]\n",
      "epoch:49 step:38565 [D loss: 0.039597, acc: 100.00%] [G loss: 4.221712]\n",
      "epoch:49 step:38566 [D loss: 0.284872, acc: 94.53%] [G loss: 8.307920]\n",
      "epoch:49 step:38567 [D loss: 0.161616, acc: 97.66%] [G loss: 3.882079]\n",
      "epoch:49 step:38568 [D loss: 0.035159, acc: 100.00%] [G loss: 6.875627]\n",
      "epoch:49 step:38569 [D loss: 0.205663, acc: 98.44%] [G loss: 6.586856]\n",
      "epoch:49 step:38570 [D loss: 1.053594, acc: 32.81%] [G loss: 6.905539]\n",
      "epoch:49 step:38571 [D loss: 0.333432, acc: 88.28%] [G loss: 5.584941]\n",
      "epoch:49 step:38572 [D loss: 0.147184, acc: 100.00%] [G loss: 6.335595]\n",
      "epoch:49 step:38573 [D loss: 0.983977, acc: 36.72%] [G loss: 4.850920]\n",
      "epoch:49 step:38574 [D loss: 0.016243, acc: 100.00%] [G loss: 9.223276]\n",
      "epoch:49 step:38575 [D loss: 0.231264, acc: 95.31%] [G loss: 6.326248]\n",
      "epoch:49 step:38576 [D loss: 0.220800, acc: 96.88%] [G loss: 5.758242]\n",
      "epoch:49 step:38577 [D loss: 0.200031, acc: 96.09%] [G loss: 8.027506]\n",
      "epoch:49 step:38578 [D loss: 0.072212, acc: 99.22%] [G loss: 4.965844]\n",
      "epoch:49 step:38579 [D loss: 0.279925, acc: 86.72%] [G loss: 8.679916]\n",
      "epoch:49 step:38580 [D loss: 0.042841, acc: 100.00%] [G loss: 7.186188]\n",
      "epoch:49 step:38581 [D loss: 0.139830, acc: 100.00%] [G loss: 6.874632]\n",
      "epoch:49 step:38582 [D loss: 0.423312, acc: 69.53%] [G loss: 6.867682]\n",
      "epoch:49 step:38583 [D loss: 0.037318, acc: 100.00%] [G loss: 8.689087]\n",
      "epoch:49 step:38584 [D loss: 0.058157, acc: 100.00%] [G loss: 4.472363]\n",
      "epoch:49 step:38585 [D loss: 0.074894, acc: 100.00%] [G loss: 9.081230]\n",
      "epoch:49 step:38586 [D loss: 0.842434, acc: 45.31%] [G loss: 7.515116]\n",
      "epoch:49 step:38587 [D loss: 0.052401, acc: 100.00%] [G loss: 6.040793]\n",
      "epoch:49 step:38588 [D loss: 0.028837, acc: 100.00%] [G loss: 7.706523]\n",
      "epoch:49 step:38589 [D loss: 0.097016, acc: 99.22%] [G loss: 5.921027]\n",
      "epoch:49 step:38590 [D loss: 0.078741, acc: 100.00%] [G loss: 6.651176]\n",
      "epoch:49 step:38591 [D loss: 0.264226, acc: 90.62%] [G loss: 4.583426]\n",
      "epoch:49 step:38592 [D loss: 0.287284, acc: 94.53%] [G loss: 8.575935]\n",
      "epoch:49 step:38593 [D loss: 0.784979, acc: 51.56%] [G loss: 5.472636]\n",
      "epoch:49 step:38594 [D loss: 0.041408, acc: 100.00%] [G loss: 5.664472]\n",
      "epoch:49 step:38595 [D loss: 0.510991, acc: 62.50%] [G loss: 6.562446]\n",
      "epoch:49 step:38596 [D loss: 1.036329, acc: 32.03%] [G loss: 7.032709]\n",
      "epoch:49 step:38597 [D loss: 0.169513, acc: 98.44%] [G loss: 7.588135]\n",
      "epoch:49 step:38598 [D loss: 0.083927, acc: 99.22%] [G loss: 8.301239]\n",
      "epoch:49 step:38599 [D loss: 0.399074, acc: 79.69%] [G loss: 8.457952]\n",
      "epoch:49 step:38600 [D loss: 0.030831, acc: 100.00%] [G loss: 5.350486]\n",
      "epoch:49 step:38601 [D loss: 0.015037, acc: 100.00%] [G loss: 7.539934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38602 [D loss: 0.041012, acc: 100.00%] [G loss: 6.682612]\n",
      "epoch:49 step:38603 [D loss: 0.073029, acc: 100.00%] [G loss: 6.975055]\n",
      "epoch:49 step:38604 [D loss: 0.288087, acc: 88.28%] [G loss: 3.926732]\n",
      "epoch:49 step:38605 [D loss: 0.040220, acc: 100.00%] [G loss: 6.265657]\n",
      "epoch:49 step:38606 [D loss: 0.376593, acc: 76.56%] [G loss: 6.817908]\n",
      "epoch:49 step:38607 [D loss: 0.785327, acc: 53.12%] [G loss: 8.859297]\n",
      "epoch:49 step:38608 [D loss: 0.045576, acc: 100.00%] [G loss: 7.728898]\n",
      "epoch:49 step:38609 [D loss: 0.428489, acc: 89.06%] [G loss: 3.107597]\n",
      "epoch:49 step:38610 [D loss: 1.016035, acc: 50.00%] [G loss: 6.948203]\n",
      "epoch:49 step:38611 [D loss: 0.232984, acc: 92.97%] [G loss: 3.482243]\n",
      "epoch:49 step:38612 [D loss: 0.019877, acc: 100.00%] [G loss: 9.520734]\n",
      "epoch:49 step:38613 [D loss: 0.701399, acc: 56.25%] [G loss: 5.495139]\n",
      "epoch:49 step:38614 [D loss: 0.502794, acc: 63.28%] [G loss: 7.050310]\n",
      "epoch:49 step:38615 [D loss: 0.064051, acc: 100.00%] [G loss: 1.855579]\n",
      "epoch:49 step:38616 [D loss: 0.261920, acc: 95.31%] [G loss: 9.002855]\n",
      "epoch:49 step:38617 [D loss: 0.105729, acc: 98.44%] [G loss: 8.271803]\n",
      "epoch:49 step:38618 [D loss: 1.312285, acc: 49.22%] [G loss: 6.712214]\n",
      "epoch:49 step:38619 [D loss: 1.431118, acc: 50.00%] [G loss: 9.158299]\n",
      "epoch:49 step:38620 [D loss: 0.017796, acc: 100.00%] [G loss: 4.503631]\n",
      "epoch:49 step:38621 [D loss: 0.252896, acc: 90.62%] [G loss: 9.136232]\n",
      "epoch:49 step:38622 [D loss: 0.405268, acc: 86.72%] [G loss: 2.602540]\n",
      "epoch:49 step:38623 [D loss: 0.156765, acc: 99.22%] [G loss: 4.249324]\n",
      "epoch:49 step:38624 [D loss: 0.209812, acc: 90.62%] [G loss: 6.775337]\n",
      "epoch:49 step:38625 [D loss: 0.229096, acc: 91.41%] [G loss: 5.241640]\n",
      "epoch:49 step:38626 [D loss: 0.458589, acc: 75.78%] [G loss: 9.352532]\n",
      "epoch:49 step:38627 [D loss: 0.095400, acc: 99.22%] [G loss: 7.222425]\n",
      "epoch:49 step:38628 [D loss: 0.016087, acc: 100.00%] [G loss: 5.403847]\n",
      "epoch:49 step:38629 [D loss: 0.066960, acc: 100.00%] [G loss: 5.819993]\n",
      "epoch:49 step:38630 [D loss: 0.353337, acc: 82.81%] [G loss: 2.453912]\n",
      "epoch:49 step:38631 [D loss: 0.800486, acc: 53.12%] [G loss: 8.144056]\n",
      "epoch:49 step:38632 [D loss: 0.214415, acc: 92.19%] [G loss: 5.878790]\n",
      "epoch:49 step:38633 [D loss: 0.016422, acc: 100.00%] [G loss: 7.416685]\n",
      "epoch:49 step:38634 [D loss: 0.184488, acc: 96.09%] [G loss: 4.094398]\n",
      "epoch:49 step:38635 [D loss: 0.187950, acc: 92.97%] [G loss: 5.375082]\n",
      "epoch:49 step:38636 [D loss: 0.192563, acc: 97.66%] [G loss: 2.780320]\n",
      "epoch:49 step:38637 [D loss: 0.060048, acc: 100.00%] [G loss: 2.895301]\n",
      "epoch:49 step:38638 [D loss: 0.365039, acc: 87.50%] [G loss: 5.468300]\n",
      "epoch:49 step:38639 [D loss: 0.296224, acc: 89.84%] [G loss: 8.134817]\n",
      "epoch:49 step:38640 [D loss: 0.407873, acc: 89.06%] [G loss: 7.655684]\n",
      "epoch:49 step:38641 [D loss: 0.174456, acc: 98.44%] [G loss: 6.085546]\n",
      "epoch:49 step:38642 [D loss: 0.102742, acc: 100.00%] [G loss: 10.020565]\n",
      "epoch:49 step:38643 [D loss: 0.016461, acc: 100.00%] [G loss: 5.627205]\n",
      "epoch:49 step:38644 [D loss: 0.101027, acc: 99.22%] [G loss: 2.684562]\n",
      "epoch:49 step:38645 [D loss: 0.220390, acc: 94.53%] [G loss: 6.292542]\n",
      "epoch:49 step:38646 [D loss: 0.175366, acc: 99.22%] [G loss: 5.645010]\n",
      "epoch:49 step:38647 [D loss: 0.072196, acc: 100.00%] [G loss: 9.334597]\n",
      "epoch:49 step:38648 [D loss: 0.340122, acc: 91.41%] [G loss: 8.384701]\n",
      "epoch:49 step:38649 [D loss: 0.375460, acc: 79.69%] [G loss: 8.414496]\n",
      "epoch:49 step:38650 [D loss: 0.087878, acc: 100.00%] [G loss: 2.401534]\n",
      "epoch:49 step:38651 [D loss: 0.339128, acc: 87.50%] [G loss: 4.820265]\n",
      "epoch:49 step:38652 [D loss: 0.080499, acc: 100.00%] [G loss: 3.481108]\n",
      "epoch:49 step:38653 [D loss: 0.066824, acc: 100.00%] [G loss: 4.797192]\n",
      "epoch:49 step:38654 [D loss: 1.061239, acc: 50.78%] [G loss: 8.672338]\n",
      "epoch:49 step:38655 [D loss: 1.288195, acc: 50.78%] [G loss: 8.103934]\n",
      "epoch:49 step:38656 [D loss: 0.047367, acc: 100.00%] [G loss: 6.175444]\n",
      "epoch:49 step:38657 [D loss: 0.249272, acc: 96.88%] [G loss: 8.395465]\n",
      "epoch:49 step:38658 [D loss: 0.980481, acc: 34.38%] [G loss: 8.898727]\n",
      "epoch:49 step:38659 [D loss: 0.480401, acc: 64.06%] [G loss: 5.744650]\n",
      "epoch:49 step:38660 [D loss: 0.294395, acc: 86.72%] [G loss: 4.043419]\n",
      "epoch:49 step:38661 [D loss: 0.477825, acc: 75.00%] [G loss: 3.837178]\n",
      "epoch:49 step:38662 [D loss: 0.193999, acc: 96.09%] [G loss: 7.335609]\n",
      "epoch:49 step:38663 [D loss: 0.164895, acc: 98.44%] [G loss: 6.980102]\n",
      "epoch:49 step:38664 [D loss: 0.163094, acc: 98.44%] [G loss: 4.943016]\n",
      "epoch:49 step:38665 [D loss: 0.035503, acc: 100.00%] [G loss: 4.239884]\n",
      "epoch:49 step:38666 [D loss: 0.078575, acc: 100.00%] [G loss: 5.332700]\n",
      "epoch:49 step:38667 [D loss: 0.121264, acc: 99.22%] [G loss: 3.294448]\n",
      "epoch:49 step:38668 [D loss: 0.117240, acc: 98.44%] [G loss: 5.799938]\n",
      "epoch:49 step:38669 [D loss: 1.363945, acc: 7.81%] [G loss: 9.292816]\n",
      "epoch:49 step:38670 [D loss: 0.069768, acc: 99.22%] [G loss: 9.011247]\n",
      "epoch:49 step:38671 [D loss: 0.322574, acc: 92.19%] [G loss: 6.687852]\n",
      "epoch:49 step:38672 [D loss: 0.058489, acc: 100.00%] [G loss: 3.173898]\n",
      "epoch:49 step:38673 [D loss: 0.258513, acc: 92.19%] [G loss: 4.495970]\n",
      "epoch:49 step:38674 [D loss: 0.075118, acc: 100.00%] [G loss: 2.845098]\n",
      "epoch:49 step:38675 [D loss: 1.427435, acc: 38.28%] [G loss: 2.742300]\n",
      "epoch:49 step:38676 [D loss: 0.091771, acc: 100.00%] [G loss: 9.393225]\n",
      "epoch:49 step:38677 [D loss: 0.258480, acc: 89.06%] [G loss: 5.760437]\n",
      "epoch:49 step:38678 [D loss: 0.015513, acc: 100.00%] [G loss: 6.253363]\n",
      "epoch:49 step:38679 [D loss: 0.314794, acc: 85.16%] [G loss: 6.452987]\n",
      "epoch:49 step:38680 [D loss: 0.750631, acc: 54.69%] [G loss: 5.695165]\n",
      "epoch:49 step:38681 [D loss: 0.054707, acc: 100.00%] [G loss: 5.113822]\n",
      "epoch:49 step:38682 [D loss: 0.164227, acc: 95.31%] [G loss: 6.888173]\n",
      "epoch:49 step:38683 [D loss: 0.469556, acc: 64.84%] [G loss: 4.632964]\n",
      "epoch:49 step:38684 [D loss: 0.688291, acc: 54.69%] [G loss: 7.799258]\n",
      "epoch:49 step:38685 [D loss: 0.069392, acc: 100.00%] [G loss: 7.696284]\n",
      "epoch:49 step:38686 [D loss: 0.667120, acc: 57.03%] [G loss: 3.945752]\n",
      "epoch:49 step:38687 [D loss: 0.026523, acc: 100.00%] [G loss: 8.255830]\n",
      "epoch:49 step:38688 [D loss: 0.108178, acc: 99.22%] [G loss: 6.810578]\n",
      "epoch:49 step:38689 [D loss: 0.464033, acc: 71.09%] [G loss: 11.342032]\n",
      "epoch:49 step:38690 [D loss: 0.297584, acc: 87.50%] [G loss: 5.699831]\n",
      "epoch:49 step:38691 [D loss: 0.345726, acc: 86.72%] [G loss: 9.219642]\n",
      "epoch:49 step:38692 [D loss: 0.228658, acc: 92.97%] [G loss: 4.447365]\n",
      "epoch:49 step:38693 [D loss: 0.234382, acc: 95.31%] [G loss: 4.677471]\n",
      "epoch:49 step:38694 [D loss: 0.486785, acc: 70.31%] [G loss: 2.610085]\n",
      "epoch:49 step:38695 [D loss: 0.010504, acc: 100.00%] [G loss: 6.741965]\n",
      "epoch:49 step:38696 [D loss: 0.447022, acc: 85.94%] [G loss: 4.555865]\n",
      "epoch:49 step:38697 [D loss: 1.006264, acc: 50.00%] [G loss: 16.710382]\n",
      "epoch:49 step:38698 [D loss: 0.980564, acc: 50.78%] [G loss: 5.173813]\n",
      "epoch:49 step:38699 [D loss: 0.117105, acc: 99.22%] [G loss: 3.043103]\n",
      "epoch:49 step:38700 [D loss: 0.390048, acc: 80.47%] [G loss: 6.820184]\n",
      "epoch:49 step:38701 [D loss: 0.063113, acc: 100.00%] [G loss: 6.690233]\n",
      "epoch:49 step:38702 [D loss: 0.018662, acc: 100.00%] [G loss: 8.258900]\n",
      "epoch:49 step:38703 [D loss: 0.598967, acc: 57.03%] [G loss: 4.920098]\n",
      "epoch:49 step:38704 [D loss: 0.107874, acc: 99.22%] [G loss: 5.036510]\n",
      "epoch:49 step:38705 [D loss: 0.644193, acc: 65.62%] [G loss: 4.547807]\n",
      "epoch:49 step:38706 [D loss: 1.349271, acc: 46.88%] [G loss: 5.876761]\n",
      "epoch:49 step:38707 [D loss: 0.217541, acc: 92.19%] [G loss: 7.458645]\n",
      "epoch:49 step:38708 [D loss: 0.021175, acc: 100.00%] [G loss: 6.529597]\n",
      "epoch:49 step:38709 [D loss: 0.190515, acc: 96.09%] [G loss: 5.296627]\n",
      "epoch:49 step:38710 [D loss: 0.192716, acc: 96.09%] [G loss: 8.030228]\n",
      "epoch:49 step:38711 [D loss: 0.664487, acc: 55.47%] [G loss: 8.261786]\n",
      "epoch:49 step:38712 [D loss: 1.024910, acc: 50.00%] [G loss: 7.768893]\n",
      "epoch:49 step:38713 [D loss: 0.032887, acc: 100.00%] [G loss: 8.244064]\n",
      "epoch:49 step:38714 [D loss: 0.237580, acc: 94.53%] [G loss: 8.465920]\n",
      "epoch:49 step:38715 [D loss: 0.014328, acc: 100.00%] [G loss: 8.995604]\n",
      "epoch:49 step:38716 [D loss: 0.911784, acc: 51.56%] [G loss: 10.111708]\n",
      "epoch:49 step:38717 [D loss: 0.124506, acc: 98.44%] [G loss: 8.243240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38718 [D loss: 0.068820, acc: 99.22%] [G loss: 8.604400]\n",
      "epoch:49 step:38719 [D loss: 0.164810, acc: 97.66%] [G loss: 8.003288]\n",
      "epoch:49 step:38720 [D loss: 0.095342, acc: 99.22%] [G loss: 6.035913]\n",
      "epoch:49 step:38721 [D loss: 0.213181, acc: 99.22%] [G loss: 7.354232]\n",
      "epoch:49 step:38722 [D loss: 0.049886, acc: 100.00%] [G loss: 6.379041]\n",
      "epoch:49 step:38723 [D loss: 0.484681, acc: 75.78%] [G loss: 6.087607]\n",
      "epoch:49 step:38724 [D loss: 0.310704, acc: 95.31%] [G loss: 5.391438]\n",
      "epoch:49 step:38725 [D loss: 0.685896, acc: 57.81%] [G loss: 8.374493]\n",
      "epoch:49 step:38726 [D loss: 0.149275, acc: 97.66%] [G loss: 6.560239]\n",
      "epoch:49 step:38727 [D loss: 0.056758, acc: 100.00%] [G loss: 9.107834]\n",
      "epoch:49 step:38728 [D loss: 0.252650, acc: 92.19%] [G loss: 5.463428]\n",
      "epoch:49 step:38729 [D loss: 0.102270, acc: 100.00%] [G loss: 4.914287]\n",
      "epoch:49 step:38730 [D loss: 0.514609, acc: 77.34%] [G loss: 9.280899]\n",
      "epoch:49 step:38731 [D loss: 0.107122, acc: 98.44%] [G loss: 5.498803]\n",
      "epoch:49 step:38732 [D loss: 0.007329, acc: 100.00%] [G loss: 8.447069]\n",
      "epoch:49 step:38733 [D loss: 0.067308, acc: 100.00%] [G loss: 9.175857]\n",
      "epoch:49 step:38734 [D loss: 0.102210, acc: 99.22%] [G loss: 4.684565]\n",
      "epoch:49 step:38735 [D loss: 0.371284, acc: 77.34%] [G loss: 12.337166]\n",
      "epoch:49 step:38736 [D loss: 0.580473, acc: 60.16%] [G loss: 7.339661]\n",
      "epoch:49 step:38737 [D loss: 0.199269, acc: 94.53%] [G loss: 5.850522]\n",
      "epoch:49 step:38738 [D loss: 0.221609, acc: 92.19%] [G loss: 8.739298]\n",
      "epoch:49 step:38739 [D loss: 0.054430, acc: 100.00%] [G loss: 9.126566]\n",
      "epoch:49 step:38740 [D loss: 0.335351, acc: 82.81%] [G loss: 12.380812]\n",
      "epoch:49 step:38741 [D loss: 0.126025, acc: 100.00%] [G loss: 6.829932]\n",
      "epoch:49 step:38742 [D loss: 0.449003, acc: 80.47%] [G loss: 7.251608]\n",
      "epoch:49 step:38743 [D loss: 1.048562, acc: 50.00%] [G loss: 4.196519]\n",
      "epoch:49 step:38744 [D loss: 0.133336, acc: 99.22%] [G loss: 5.900589]\n",
      "epoch:49 step:38745 [D loss: 0.596396, acc: 61.72%] [G loss: 8.048476]\n",
      "epoch:49 step:38746 [D loss: 0.406009, acc: 89.84%] [G loss: 5.687742]\n",
      "epoch:49 step:38747 [D loss: 0.015236, acc: 100.00%] [G loss: 9.744421]\n",
      "epoch:49 step:38748 [D loss: 1.075167, acc: 50.00%] [G loss: 4.648065]\n",
      "epoch:49 step:38749 [D loss: 0.040139, acc: 100.00%] [G loss: 3.973397]\n",
      "epoch:49 step:38750 [D loss: 0.618930, acc: 61.72%] [G loss: 7.083236]\n",
      "epoch:49 step:38751 [D loss: 1.039679, acc: 50.78%] [G loss: 7.930199]\n",
      "epoch:49 step:38752 [D loss: 0.434907, acc: 71.09%] [G loss: 7.629101]\n",
      "epoch:49 step:38753 [D loss: 0.869032, acc: 47.66%] [G loss: 5.618725]\n",
      "epoch:49 step:38754 [D loss: 0.462832, acc: 82.03%] [G loss: 7.102417]\n",
      "epoch:49 step:38755 [D loss: 0.157451, acc: 98.44%] [G loss: 2.616832]\n",
      "epoch:49 step:38756 [D loss: 0.116330, acc: 98.44%] [G loss: 6.574200]\n",
      "epoch:49 step:38757 [D loss: 0.417008, acc: 81.25%] [G loss: 5.412677]\n",
      "epoch:49 step:38758 [D loss: 0.074489, acc: 99.22%] [G loss: 5.511817]\n",
      "epoch:49 step:38759 [D loss: 0.038287, acc: 100.00%] [G loss: 8.888256]\n",
      "epoch:49 step:38760 [D loss: 0.344987, acc: 78.12%] [G loss: 7.200651]\n",
      "epoch:49 step:38761 [D loss: 0.211734, acc: 97.66%] [G loss: 5.575393]\n",
      "epoch:49 step:38762 [D loss: 0.163429, acc: 96.88%] [G loss: 7.138635]\n",
      "epoch:49 step:38763 [D loss: 0.068246, acc: 100.00%] [G loss: 5.554843]\n",
      "epoch:49 step:38764 [D loss: 0.113071, acc: 99.22%] [G loss: 6.612374]\n",
      "epoch:49 step:38765 [D loss: 0.138404, acc: 98.44%] [G loss: 6.413367]\n",
      "epoch:49 step:38766 [D loss: 0.092687, acc: 100.00%] [G loss: 9.294584]\n",
      "epoch:49 step:38767 [D loss: 0.304676, acc: 92.97%] [G loss: 7.136760]\n",
      "epoch:49 step:38768 [D loss: 0.021748, acc: 100.00%] [G loss: 9.043325]\n",
      "epoch:49 step:38769 [D loss: 0.239976, acc: 96.88%] [G loss: 4.708313]\n",
      "epoch:49 step:38770 [D loss: 0.365559, acc: 81.25%] [G loss: 2.778618]\n",
      "epoch:49 step:38771 [D loss: 0.123698, acc: 98.44%] [G loss: 7.208816]\n",
      "epoch:49 step:38772 [D loss: 0.224994, acc: 92.97%] [G loss: 4.490086]\n",
      "epoch:49 step:38773 [D loss: 0.025118, acc: 100.00%] [G loss: 5.418307]\n",
      "epoch:49 step:38774 [D loss: 0.806834, acc: 53.12%] [G loss: 10.421964]\n",
      "epoch:49 step:38775 [D loss: 0.046051, acc: 100.00%] [G loss: 6.918842]\n",
      "epoch:49 step:38776 [D loss: 0.060691, acc: 100.00%] [G loss: 4.679673]\n",
      "epoch:49 step:38777 [D loss: 0.409567, acc: 75.78%] [G loss: 7.919815]\n",
      "epoch:49 step:38778 [D loss: 0.045118, acc: 100.00%] [G loss: 5.630760]\n",
      "epoch:49 step:38779 [D loss: 0.263692, acc: 92.19%] [G loss: 5.478563]\n",
      "epoch:49 step:38780 [D loss: 0.299387, acc: 85.16%] [G loss: 8.419567]\n",
      "epoch:49 step:38781 [D loss: 0.173111, acc: 96.88%] [G loss: 5.285365]\n",
      "epoch:49 step:38782 [D loss: 0.115098, acc: 99.22%] [G loss: 9.034199]\n",
      "epoch:49 step:38783 [D loss: 0.144392, acc: 99.22%] [G loss: 6.925042]\n",
      "epoch:49 step:38784 [D loss: 0.215993, acc: 95.31%] [G loss: 7.787434]\n",
      "epoch:49 step:38785 [D loss: 1.509257, acc: 17.19%] [G loss: 4.372856]\n",
      "epoch:49 step:38786 [D loss: 0.051739, acc: 100.00%] [G loss: 6.923645]\n",
      "epoch:49 step:38787 [D loss: 0.021634, acc: 100.00%] [G loss: 4.178469]\n",
      "epoch:49 step:38788 [D loss: 0.754667, acc: 53.12%] [G loss: 12.169305]\n",
      "epoch:49 step:38789 [D loss: 0.077805, acc: 100.00%] [G loss: 7.147606]\n",
      "epoch:49 step:38790 [D loss: 0.171435, acc: 96.09%] [G loss: 3.870528]\n",
      "epoch:49 step:38791 [D loss: 0.239075, acc: 96.09%] [G loss: 2.937140]\n",
      "epoch:49 step:38792 [D loss: 0.061396, acc: 100.00%] [G loss: 5.493995]\n",
      "epoch:49 step:38793 [D loss: 0.399489, acc: 72.66%] [G loss: 5.278607]\n",
      "epoch:49 step:38794 [D loss: 0.609762, acc: 65.62%] [G loss: 8.128579]\n",
      "epoch:49 step:38795 [D loss: 0.655494, acc: 60.16%] [G loss: 8.592880]\n",
      "epoch:49 step:38796 [D loss: 0.372039, acc: 82.03%] [G loss: 2.406613]\n",
      "epoch:49 step:38797 [D loss: 0.060407, acc: 99.22%] [G loss: 8.326913]\n",
      "epoch:49 step:38798 [D loss: 0.612163, acc: 67.19%] [G loss: 7.542900]\n",
      "epoch:49 step:38799 [D loss: 0.572611, acc: 59.38%] [G loss: 3.950458]\n",
      "epoch:49 step:38800 [D loss: 0.055298, acc: 100.00%] [G loss: 4.998019]\n",
      "epoch:49 step:38801 [D loss: 0.264453, acc: 86.72%] [G loss: 4.510535]\n",
      "epoch:49 step:38802 [D loss: 0.058626, acc: 100.00%] [G loss: 6.773836]\n",
      "epoch:49 step:38803 [D loss: 0.152916, acc: 99.22%] [G loss: 4.593615]\n",
      "epoch:49 step:38804 [D loss: 0.740163, acc: 57.81%] [G loss: 3.966550]\n",
      "epoch:49 step:38805 [D loss: 0.140416, acc: 97.66%] [G loss: 4.298717]\n",
      "epoch:49 step:38806 [D loss: 0.655583, acc: 59.38%] [G loss: 8.506821]\n",
      "epoch:49 step:38807 [D loss: 0.100401, acc: 100.00%] [G loss: 6.059320]\n",
      "epoch:49 step:38808 [D loss: 0.182281, acc: 98.44%] [G loss: 3.774604]\n",
      "epoch:49 step:38809 [D loss: 0.121695, acc: 99.22%] [G loss: 7.581066]\n",
      "epoch:49 step:38810 [D loss: 0.148605, acc: 97.66%] [G loss: 9.472372]\n",
      "epoch:49 step:38811 [D loss: 0.266230, acc: 91.41%] [G loss: 9.830044]\n",
      "epoch:49 step:38812 [D loss: 0.240579, acc: 97.66%] [G loss: 4.269959]\n",
      "epoch:49 step:38813 [D loss: 0.027221, acc: 100.00%] [G loss: 6.564011]\n",
      "epoch:49 step:38814 [D loss: 0.179790, acc: 99.22%] [G loss: 7.033185]\n",
      "epoch:49 step:38815 [D loss: 0.083841, acc: 98.44%] [G loss: 5.924778]\n",
      "epoch:49 step:38816 [D loss: 0.115862, acc: 97.66%] [G loss: 5.348740]\n",
      "epoch:49 step:38817 [D loss: 0.965397, acc: 44.53%] [G loss: 5.652738]\n",
      "epoch:49 step:38818 [D loss: 0.497395, acc: 64.84%] [G loss: 7.258850]\n",
      "epoch:49 step:38819 [D loss: 0.085515, acc: 98.44%] [G loss: 5.492129]\n",
      "epoch:49 step:38820 [D loss: 0.042664, acc: 100.00%] [G loss: 3.348410]\n",
      "epoch:49 step:38821 [D loss: 0.167555, acc: 96.09%] [G loss: 5.412410]\n",
      "epoch:49 step:38822 [D loss: 0.496375, acc: 67.19%] [G loss: 7.871211]\n",
      "epoch:49 step:38823 [D loss: 1.339814, acc: 50.00%] [G loss: 3.977173]\n",
      "epoch:49 step:38824 [D loss: 0.038038, acc: 100.00%] [G loss: 3.128410]\n",
      "epoch:49 step:38825 [D loss: 0.057561, acc: 100.00%] [G loss: 7.316737]\n",
      "epoch:49 step:38826 [D loss: 1.210976, acc: 50.78%] [G loss: 9.571756]\n",
      "epoch:49 step:38827 [D loss: 0.218767, acc: 96.88%] [G loss: 4.443102]\n",
      "epoch:49 step:38828 [D loss: 0.340158, acc: 82.03%] [G loss: 6.977279]\n",
      "epoch:49 step:38829 [D loss: 0.082760, acc: 99.22%] [G loss: 8.262966]\n",
      "epoch:49 step:38830 [D loss: 0.102899, acc: 100.00%] [G loss: 4.468740]\n",
      "epoch:49 step:38831 [D loss: 0.087550, acc: 99.22%] [G loss: 8.500584]\n",
      "epoch:49 step:38832 [D loss: 0.010031, acc: 100.00%] [G loss: 9.329557]\n",
      "epoch:49 step:38833 [D loss: 0.305607, acc: 92.97%] [G loss: 6.806632]\n",
      "epoch:49 step:38834 [D loss: 0.299722, acc: 89.06%] [G loss: 4.286650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38835 [D loss: 0.464397, acc: 81.25%] [G loss: 6.284185]\n",
      "epoch:49 step:38836 [D loss: 0.079180, acc: 99.22%] [G loss: 6.355426]\n",
      "epoch:49 step:38837 [D loss: 0.182601, acc: 99.22%] [G loss: 5.712676]\n",
      "epoch:49 step:38838 [D loss: 0.583070, acc: 67.97%] [G loss: 9.178040]\n",
      "epoch:49 step:38839 [D loss: 0.509483, acc: 65.62%] [G loss: 8.551725]\n",
      "epoch:49 step:38840 [D loss: 0.200219, acc: 96.09%] [G loss: 5.036223]\n",
      "epoch:49 step:38841 [D loss: 0.097369, acc: 100.00%] [G loss: 5.261866]\n",
      "epoch:49 step:38842 [D loss: 0.686384, acc: 57.81%] [G loss: 6.913753]\n",
      "epoch:49 step:38843 [D loss: 0.049907, acc: 100.00%] [G loss: 5.639013]\n",
      "epoch:49 step:38844 [D loss: 0.244501, acc: 95.31%] [G loss: 1.888864]\n",
      "epoch:49 step:38845 [D loss: 0.083843, acc: 100.00%] [G loss: 8.442393]\n",
      "epoch:49 step:38846 [D loss: 0.655819, acc: 58.59%] [G loss: 6.186566]\n",
      "epoch:49 step:38847 [D loss: 0.004490, acc: 100.00%] [G loss: 7.129922]\n",
      "epoch:49 step:38848 [D loss: 0.347741, acc: 79.69%] [G loss: 9.354444]\n",
      "epoch:49 step:38849 [D loss: 0.608955, acc: 55.47%] [G loss: 8.655472]\n",
      "epoch:49 step:38850 [D loss: 0.017519, acc: 100.00%] [G loss: 7.781410]\n",
      "epoch:49 step:38851 [D loss: 0.041517, acc: 100.00%] [G loss: 9.721222]\n",
      "epoch:49 step:38852 [D loss: 0.946179, acc: 51.56%] [G loss: 11.476520]\n",
      "epoch:49 step:38853 [D loss: 0.077734, acc: 100.00%] [G loss: 2.655888]\n",
      "epoch:49 step:38854 [D loss: 0.082565, acc: 100.00%] [G loss: 7.833718]\n",
      "epoch:49 step:38855 [D loss: 0.100481, acc: 99.22%] [G loss: 6.929107]\n",
      "epoch:49 step:38856 [D loss: 0.116887, acc: 98.44%] [G loss: 4.553234]\n",
      "epoch:49 step:38857 [D loss: 0.621700, acc: 60.16%] [G loss: 5.055565]\n",
      "epoch:49 step:38858 [D loss: 0.023535, acc: 100.00%] [G loss: 6.005885]\n",
      "epoch:49 step:38859 [D loss: 0.888144, acc: 52.34%] [G loss: 8.746797]\n",
      "epoch:49 step:38860 [D loss: 0.062847, acc: 100.00%] [G loss: 5.195460]\n",
      "epoch:49 step:38861 [D loss: 0.745678, acc: 53.91%] [G loss: 7.896142]\n",
      "epoch:49 step:38862 [D loss: 0.136624, acc: 100.00%] [G loss: 6.147027]\n",
      "epoch:49 step:38863 [D loss: 0.203516, acc: 93.75%] [G loss: 4.490468]\n",
      "epoch:49 step:38864 [D loss: 0.365880, acc: 77.34%] [G loss: 3.948879]\n",
      "epoch:49 step:38865 [D loss: 0.008148, acc: 100.00%] [G loss: 10.046036]\n",
      "epoch:49 step:38866 [D loss: 0.147912, acc: 97.66%] [G loss: 4.635476]\n",
      "epoch:49 step:38867 [D loss: 0.047955, acc: 100.00%] [G loss: 5.011321]\n",
      "epoch:49 step:38868 [D loss: 0.100473, acc: 100.00%] [G loss: 5.695063]\n",
      "epoch:49 step:38869 [D loss: 0.137549, acc: 99.22%] [G loss: 6.596447]\n",
      "epoch:49 step:38870 [D loss: 0.151445, acc: 98.44%] [G loss: 6.573084]\n",
      "epoch:49 step:38871 [D loss: 0.220717, acc: 96.88%] [G loss: 5.923477]\n",
      "epoch:49 step:38872 [D loss: 0.312581, acc: 86.72%] [G loss: 11.390806]\n",
      "epoch:49 step:38873 [D loss: 0.485056, acc: 65.62%] [G loss: 5.473621]\n",
      "epoch:49 step:38874 [D loss: 0.252571, acc: 91.41%] [G loss: 5.278214]\n",
      "epoch:49 step:38875 [D loss: 0.150332, acc: 99.22%] [G loss: 6.169450]\n",
      "epoch:49 step:38876 [D loss: 0.316005, acc: 96.09%] [G loss: 6.915912]\n",
      "epoch:49 step:38877 [D loss: 0.187078, acc: 93.75%] [G loss: 8.895226]\n",
      "epoch:49 step:38878 [D loss: 1.244828, acc: 50.00%] [G loss: 9.949471]\n",
      "epoch:49 step:38879 [D loss: 0.025413, acc: 100.00%] [G loss: 8.436869]\n",
      "epoch:49 step:38880 [D loss: 0.382182, acc: 79.69%] [G loss: 5.110828]\n",
      "epoch:49 step:38881 [D loss: 0.424637, acc: 70.31%] [G loss: 7.598734]\n",
      "epoch:49 step:38882 [D loss: 0.167966, acc: 96.09%] [G loss: 3.612562]\n",
      "epoch:49 step:38883 [D loss: 0.075443, acc: 98.44%] [G loss: 7.505959]\n",
      "epoch:49 step:38884 [D loss: 0.088657, acc: 100.00%] [G loss: 7.861838]\n",
      "epoch:49 step:38885 [D loss: 0.986772, acc: 44.53%] [G loss: 3.008723]\n",
      "epoch:49 step:38886 [D loss: 0.037052, acc: 100.00%] [G loss: 5.380322]\n",
      "epoch:49 step:38887 [D loss: 0.175833, acc: 97.66%] [G loss: 6.892509]\n",
      "epoch:49 step:38888 [D loss: 1.211686, acc: 28.12%] [G loss: 5.225079]\n",
      "epoch:49 step:38889 [D loss: 0.361585, acc: 83.59%] [G loss: 6.985765]\n",
      "epoch:49 step:38890 [D loss: 0.019971, acc: 100.00%] [G loss: 9.651056]\n",
      "epoch:49 step:38891 [D loss: 1.374827, acc: 48.44%] [G loss: 5.486482]\n",
      "epoch:49 step:38892 [D loss: 0.128580, acc: 99.22%] [G loss: 5.956222]\n",
      "epoch:49 step:38893 [D loss: 0.037659, acc: 100.00%] [G loss: 5.497351]\n",
      "epoch:49 step:38894 [D loss: 0.450027, acc: 74.22%] [G loss: 10.396919]\n",
      "epoch:49 step:38895 [D loss: 0.155655, acc: 95.31%] [G loss: 5.668221]\n",
      "epoch:49 step:38896 [D loss: 0.153652, acc: 98.44%] [G loss: 5.115441]\n",
      "epoch:49 step:38897 [D loss: 0.178083, acc: 96.88%] [G loss: 4.045029]\n",
      "epoch:49 step:38898 [D loss: 0.014526, acc: 100.00%] [G loss: 8.862605]\n",
      "epoch:49 step:38899 [D loss: 0.048682, acc: 100.00%] [G loss: 9.872217]\n",
      "epoch:49 step:38900 [D loss: 0.363243, acc: 91.41%] [G loss: 6.109729]\n",
      "epoch:49 step:38901 [D loss: 0.088106, acc: 100.00%] [G loss: 6.770043]\n",
      "epoch:49 step:38902 [D loss: 0.456314, acc: 80.47%] [G loss: 5.480536]\n",
      "epoch:49 step:38903 [D loss: 0.470271, acc: 83.59%] [G loss: 6.748333]\n",
      "epoch:49 step:38904 [D loss: 0.037780, acc: 100.00%] [G loss: 6.571963]\n",
      "epoch:49 step:38905 [D loss: 0.067474, acc: 100.00%] [G loss: 5.545920]\n",
      "epoch:49 step:38906 [D loss: 0.087606, acc: 100.00%] [G loss: 7.972077]\n",
      "epoch:49 step:38907 [D loss: 0.367268, acc: 89.84%] [G loss: 6.887879]\n",
      "epoch:49 step:38908 [D loss: 0.093294, acc: 100.00%] [G loss: 2.830002]\n",
      "epoch:49 step:38909 [D loss: 0.377813, acc: 71.09%] [G loss: 4.694860]\n",
      "epoch:49 step:38910 [D loss: 0.182404, acc: 96.88%] [G loss: 5.039738]\n",
      "epoch:49 step:38911 [D loss: 1.636957, acc: 3.12%] [G loss: 9.283126]\n",
      "epoch:49 step:38912 [D loss: 0.677663, acc: 57.81%] [G loss: 5.832022]\n",
      "epoch:49 step:38913 [D loss: 0.062941, acc: 100.00%] [G loss: 4.899023]\n",
      "epoch:49 step:38914 [D loss: 0.252434, acc: 91.41%] [G loss: 4.169186]\n",
      "epoch:49 step:38915 [D loss: 0.256729, acc: 89.84%] [G loss: 5.737602]\n",
      "epoch:49 step:38916 [D loss: 0.314038, acc: 91.41%] [G loss: 2.894598]\n",
      "epoch:49 step:38917 [D loss: 0.030024, acc: 100.00%] [G loss: 7.834293]\n",
      "epoch:49 step:38918 [D loss: 0.208001, acc: 96.09%] [G loss: 2.868252]\n",
      "epoch:49 step:38919 [D loss: 0.218585, acc: 96.88%] [G loss: 4.875524]\n",
      "epoch:49 step:38920 [D loss: 0.176234, acc: 96.88%] [G loss: 5.790851]\n",
      "epoch:49 step:38921 [D loss: 0.335215, acc: 91.41%] [G loss: 6.049601]\n",
      "epoch:49 step:38922 [D loss: 0.413297, acc: 73.44%] [G loss: 12.253185]\n",
      "epoch:49 step:38923 [D loss: 0.107634, acc: 100.00%] [G loss: 5.640453]\n",
      "epoch:49 step:38924 [D loss: 0.232779, acc: 97.66%] [G loss: 5.866466]\n",
      "epoch:49 step:38925 [D loss: 0.046354, acc: 99.22%] [G loss: 5.456682]\n",
      "epoch:49 step:38926 [D loss: 0.379972, acc: 87.50%] [G loss: 9.720819]\n",
      "epoch:49 step:38927 [D loss: 0.063207, acc: 100.00%] [G loss: 6.507627]\n",
      "epoch:49 step:38928 [D loss: 0.036786, acc: 100.00%] [G loss: 8.561628]\n",
      "epoch:49 step:38929 [D loss: 0.103121, acc: 99.22%] [G loss: 4.894105]\n",
      "epoch:49 step:38930 [D loss: 0.344995, acc: 82.81%] [G loss: 9.383485]\n",
      "epoch:49 step:38931 [D loss: 0.291183, acc: 89.84%] [G loss: 7.793506]\n",
      "epoch:49 step:38932 [D loss: 1.987014, acc: 50.00%] [G loss: 6.882220]\n",
      "epoch:49 step:38933 [D loss: 0.378641, acc: 81.25%] [G loss: 6.047473]\n",
      "epoch:49 step:38934 [D loss: 0.181069, acc: 97.66%] [G loss: 6.899487]\n",
      "epoch:49 step:38935 [D loss: 1.366369, acc: 50.00%] [G loss: 7.614643]\n",
      "epoch:49 step:38936 [D loss: 0.122748, acc: 99.22%] [G loss: 5.838494]\n",
      "epoch:49 step:38937 [D loss: 0.044174, acc: 100.00%] [G loss: 4.518417]\n",
      "epoch:49 step:38938 [D loss: 0.024734, acc: 100.00%] [G loss: 6.520817]\n",
      "epoch:49 step:38939 [D loss: 0.151904, acc: 98.44%] [G loss: 2.992906]\n",
      "epoch:49 step:38940 [D loss: 0.253192, acc: 95.31%] [G loss: 4.950212]\n",
      "epoch:49 step:38941 [D loss: 0.478337, acc: 73.44%] [G loss: 7.957941]\n",
      "epoch:49 step:38942 [D loss: 1.115825, acc: 50.00%] [G loss: 8.561062]\n",
      "epoch:49 step:38943 [D loss: 0.001221, acc: 100.00%] [G loss: 7.224074]\n",
      "epoch:49 step:38944 [D loss: 0.678089, acc: 57.03%] [G loss: 3.869174]\n",
      "epoch:49 step:38945 [D loss: 0.112357, acc: 100.00%] [G loss: 10.056240]\n",
      "epoch:49 step:38946 [D loss: 0.144040, acc: 96.88%] [G loss: 8.534769]\n",
      "epoch:49 step:38947 [D loss: 0.140792, acc: 97.66%] [G loss: 7.810069]\n",
      "epoch:49 step:38948 [D loss: 0.563960, acc: 61.72%] [G loss: 9.195559]\n",
      "epoch:49 step:38949 [D loss: 1.322846, acc: 50.00%] [G loss: 9.933508]\n",
      "epoch:49 step:38950 [D loss: 0.052004, acc: 100.00%] [G loss: 8.287798]\n",
      "epoch:49 step:38951 [D loss: 0.473167, acc: 66.41%] [G loss: 6.221892]\n",
      "epoch:49 step:38952 [D loss: 0.039013, acc: 100.00%] [G loss: 3.978217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38953 [D loss: 0.146606, acc: 97.66%] [G loss: 4.495331]\n",
      "epoch:49 step:38954 [D loss: 0.021447, acc: 100.00%] [G loss: 5.923525]\n",
      "epoch:49 step:38955 [D loss: 0.250912, acc: 96.09%] [G loss: 7.293523]\n",
      "epoch:49 step:38956 [D loss: 1.138623, acc: 26.56%] [G loss: 7.429673]\n",
      "epoch:49 step:38957 [D loss: 0.113422, acc: 98.44%] [G loss: 8.368131]\n",
      "epoch:49 step:38958 [D loss: 0.108716, acc: 99.22%] [G loss: 7.030182]\n",
      "epoch:49 step:38959 [D loss: 0.150770, acc: 98.44%] [G loss: 3.482654]\n",
      "epoch:49 step:38960 [D loss: 0.082823, acc: 100.00%] [G loss: 8.817965]\n",
      "epoch:49 step:38961 [D loss: 0.055348, acc: 100.00%] [G loss: 5.920137]\n",
      "epoch:49 step:38962 [D loss: 0.316173, acc: 82.81%] [G loss: 4.563265]\n",
      "epoch:49 step:38963 [D loss: 0.156637, acc: 96.09%] [G loss: 4.879123]\n",
      "epoch:49 step:38964 [D loss: 0.036984, acc: 100.00%] [G loss: 5.734174]\n",
      "epoch:49 step:38965 [D loss: 0.283293, acc: 88.28%] [G loss: 7.586598]\n",
      "epoch:49 step:38966 [D loss: 0.129493, acc: 98.44%] [G loss: 8.404425]\n",
      "epoch:49 step:38967 [D loss: 0.283671, acc: 94.53%] [G loss: 3.452265]\n",
      "epoch:49 step:38968 [D loss: 0.922376, acc: 50.78%] [G loss: 10.901434]\n",
      "epoch:49 step:38969 [D loss: 0.212266, acc: 94.53%] [G loss: 7.075197]\n",
      "epoch:49 step:38970 [D loss: 0.110752, acc: 100.00%] [G loss: 8.017096]\n",
      "epoch:49 step:38971 [D loss: 0.750717, acc: 53.12%] [G loss: 8.747533]\n",
      "epoch:49 step:38972 [D loss: 0.085451, acc: 99.22%] [G loss: 5.245481]\n",
      "epoch:49 step:38973 [D loss: 0.081138, acc: 99.22%] [G loss: 8.109598]\n",
      "epoch:49 step:38974 [D loss: 0.191452, acc: 98.44%] [G loss: 5.157059]\n",
      "epoch:49 step:38975 [D loss: 0.420574, acc: 75.78%] [G loss: 8.522405]\n",
      "epoch:49 step:38976 [D loss: 0.301894, acc: 86.72%] [G loss: 10.490258]\n",
      "epoch:49 step:38977 [D loss: 0.681859, acc: 59.38%] [G loss: 9.097683]\n",
      "epoch:49 step:38978 [D loss: 0.104482, acc: 100.00%] [G loss: 7.593196]\n",
      "epoch:49 step:38979 [D loss: 0.224934, acc: 95.31%] [G loss: 4.662285]\n",
      "epoch:49 step:38980 [D loss: 0.241185, acc: 96.09%] [G loss: 6.973041]\n",
      "epoch:49 step:38981 [D loss: 0.702496, acc: 59.38%] [G loss: 6.692099]\n",
      "epoch:49 step:38982 [D loss: 0.018999, acc: 100.00%] [G loss: 7.821160]\n",
      "epoch:49 step:38983 [D loss: 0.032968, acc: 100.00%] [G loss: 5.314143]\n",
      "epoch:49 step:38984 [D loss: 0.110584, acc: 97.66%] [G loss: 3.081002]\n",
      "epoch:49 step:38985 [D loss: 0.088549, acc: 100.00%] [G loss: 7.339920]\n",
      "epoch:49 step:38986 [D loss: 0.463267, acc: 67.19%] [G loss: 8.805111]\n",
      "epoch:49 step:38987 [D loss: 0.463661, acc: 82.81%] [G loss: 4.460161]\n",
      "epoch:49 step:38988 [D loss: 0.294203, acc: 85.94%] [G loss: 8.654683]\n",
      "epoch:49 step:38989 [D loss: 0.115091, acc: 99.22%] [G loss: 4.371451]\n",
      "epoch:49 step:38990 [D loss: 0.162341, acc: 99.22%] [G loss: 3.107950]\n",
      "epoch:49 step:38991 [D loss: 0.176521, acc: 97.66%] [G loss: 6.029129]\n",
      "epoch:49 step:38992 [D loss: 0.326390, acc: 83.59%] [G loss: 5.825591]\n",
      "epoch:49 step:38993 [D loss: 0.173300, acc: 99.22%] [G loss: 8.157516]\n",
      "epoch:49 step:38994 [D loss: 0.006725, acc: 100.00%] [G loss: 4.365028]\n",
      "epoch:49 step:38995 [D loss: 0.500595, acc: 75.78%] [G loss: 5.818752]\n",
      "epoch:49 step:38996 [D loss: 0.055257, acc: 100.00%] [G loss: 4.941560]\n",
      "epoch:49 step:38997 [D loss: 0.112966, acc: 99.22%] [G loss: 2.811035]\n",
      "epoch:49 step:38998 [D loss: 0.030607, acc: 100.00%] [G loss: 3.871629]\n",
      "epoch:49 step:38999 [D loss: 0.275160, acc: 86.72%] [G loss: 7.097378]\n",
      "epoch:49 step:39000 [D loss: 0.537135, acc: 61.72%] [G loss: 4.583912]\n",
      "epoch:49 step:39001 [D loss: 0.921137, acc: 52.34%] [G loss: 9.118133]\n",
      "epoch:49 step:39002 [D loss: 0.689144, acc: 57.81%] [G loss: 10.386348]\n",
      "epoch:49 step:39003 [D loss: 0.044203, acc: 100.00%] [G loss: 9.008741]\n",
      "epoch:49 step:39004 [D loss: 0.352593, acc: 96.09%] [G loss: 7.939495]\n",
      "epoch:49 step:39005 [D loss: 0.098708, acc: 100.00%] [G loss: 2.718398]\n",
      "epoch:49 step:39006 [D loss: 0.766094, acc: 55.47%] [G loss: 3.181911]\n",
      "epoch:49 step:39007 [D loss: 1.455159, acc: 20.31%] [G loss: 8.187605]\n",
      "epoch:49 step:39008 [D loss: 0.563572, acc: 62.50%] [G loss: 8.072325]\n",
      "epoch:49 step:39009 [D loss: 0.199376, acc: 96.09%] [G loss: 2.994710]\n",
      "epoch:49 step:39010 [D loss: 0.280409, acc: 92.97%] [G loss: 7.654650]\n",
      "epoch:49 step:39011 [D loss: 0.605220, acc: 66.41%] [G loss: 5.959645]\n",
      "epoch:49 step:39012 [D loss: 0.035160, acc: 100.00%] [G loss: 4.772308]\n",
      "epoch:49 step:39013 [D loss: 0.362729, acc: 88.28%] [G loss: 3.971919]\n",
      "epoch:49 step:39014 [D loss: 0.349866, acc: 78.91%] [G loss: 7.056636]\n",
      "epoch:49 step:39015 [D loss: 0.087271, acc: 100.00%] [G loss: 4.694489]\n",
      "epoch:49 step:39016 [D loss: 0.059296, acc: 100.00%] [G loss: 4.211707]\n",
      "epoch:49 step:39017 [D loss: 0.020608, acc: 100.00%] [G loss: 5.691950]\n",
      "epoch:49 step:39018 [D loss: 0.178685, acc: 94.53%] [G loss: 5.767932]\n",
      "epoch:49 step:39019 [D loss: 0.141286, acc: 97.66%] [G loss: 7.913433]\n",
      "epoch:49 step:39020 [D loss: 0.151088, acc: 98.44%] [G loss: 4.734614]\n",
      "epoch:49 step:39021 [D loss: 0.229363, acc: 95.31%] [G loss: 7.461040]\n",
      "epoch:49 step:39022 [D loss: 0.431724, acc: 68.75%] [G loss: 5.002162]\n",
      "epoch:49 step:39023 [D loss: 0.132449, acc: 98.44%] [G loss: 6.790138]\n",
      "epoch:49 step:39024 [D loss: 1.091794, acc: 50.00%] [G loss: 8.589035]\n",
      "epoch:49 step:39025 [D loss: 0.113555, acc: 99.22%] [G loss: 3.901275]\n",
      "epoch:49 step:39026 [D loss: 1.069860, acc: 46.88%] [G loss: 5.574849]\n",
      "epoch:49 step:39027 [D loss: 0.087300, acc: 100.00%] [G loss: 7.961191]\n",
      "epoch:49 step:39028 [D loss: 0.087790, acc: 100.00%] [G loss: 6.670334]\n",
      "epoch:49 step:39029 [D loss: 0.027142, acc: 100.00%] [G loss: 5.909055]\n",
      "epoch:49 step:39030 [D loss: 0.806489, acc: 53.12%] [G loss: 5.528379]\n",
      "epoch:49 step:39031 [D loss: 0.655881, acc: 58.59%] [G loss: 5.640071]\n",
      "epoch:49 step:39032 [D loss: 0.161044, acc: 95.31%] [G loss: 5.612348]\n",
      "epoch:49 step:39033 [D loss: 0.301962, acc: 89.06%] [G loss: 3.428710]\n",
      "epoch:49 step:39034 [D loss: 0.835826, acc: 53.91%] [G loss: 6.831462]\n",
      "epoch:49 step:39035 [D loss: 1.144402, acc: 48.44%] [G loss: 4.720437]\n",
      "epoch:49 step:39036 [D loss: 0.142540, acc: 97.66%] [G loss: 12.194897]\n",
      "epoch:49 step:39037 [D loss: 0.113972, acc: 100.00%] [G loss: 4.316895]\n",
      "epoch:49 step:39038 [D loss: 0.158659, acc: 98.44%] [G loss: 5.472032]\n",
      "epoch:49 step:39039 [D loss: 0.480560, acc: 71.09%] [G loss: 9.702754]\n",
      "epoch:49 step:39040 [D loss: 0.255250, acc: 93.75%] [G loss: 9.209463]\n",
      "epoch:49 step:39041 [D loss: 0.021510, acc: 100.00%] [G loss: 9.588864]\n",
      "epoch:49 step:39042 [D loss: 0.090250, acc: 99.22%] [G loss: 9.378193]\n",
      "epoch:49 step:39043 [D loss: 0.251314, acc: 96.88%] [G loss: 8.266548]\n",
      "epoch:49 step:39044 [D loss: 0.080289, acc: 100.00%] [G loss: 4.772643]\n",
      "epoch:49 step:39045 [D loss: 0.222323, acc: 90.62%] [G loss: 6.077054]\n",
      "epoch:49 step:39046 [D loss: 0.953864, acc: 53.12%] [G loss: 6.059185]\n",
      "epoch:49 step:39047 [D loss: 0.320670, acc: 87.50%] [G loss: 3.416023]\n",
      "epoch:49 step:39048 [D loss: 0.167833, acc: 98.44%] [G loss: 9.771908]\n",
      "epoch:49 step:39049 [D loss: 0.103179, acc: 100.00%] [G loss: 5.397828]\n",
      "epoch:49 step:39050 [D loss: 0.152302, acc: 99.22%] [G loss: 10.358710]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class BIGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # Build the encoder\n",
    "        self.encoder = self.build_encoder()\n",
    "\n",
    "        # The part of the bigan that trains the discriminator and encoder\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Generate image from sampled noise\n",
    "        z = Input(shape=(self.latent_dim, ))\n",
    "        img_ = self.generator(z)\n",
    "\n",
    "        # Encode image\n",
    "        img = Input(shape=self.img_shape)\n",
    "        z_ = self.encoder(img)\n",
    "\n",
    "        # Latent -> img is fake, and img -> latent is valid\n",
    "        fake = self.discriminator([z, img_])\n",
    "        valid = self.discriminator([z_, img])\n",
    "\n",
    "        # Set up and compile the combined model\n",
    "        # Trains generator to fool the discriminator\n",
    "        self.bigan_generator = Model([z, img], [fake, valid])\n",
    "        self.bigan_generator.compile(loss=['binary_crossentropy', 'binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_encoder(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        # model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.latent_dim))\n",
    "\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        z = model(img)\n",
    "\n",
    "        return Model(img, z)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        gen_img = model(z)\n",
    "\n",
    "        return Model(z, gen_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = Input(shape=self.img_shape)\n",
    "        d_in = concatenate([z, Flatten()(img)])\n",
    "\n",
    "        model = Dense(32 * 32 * 3)(d_in)\n",
    "        model = Reshape((32, 32, 3))(model)\n",
    "        model = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(model)\n",
    "        model = ZeroPadding2D(padding=((0, 1), (0, 1)))(model)\n",
    "        model = BatchNormalization(momentum=0.8)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(model)\n",
    "        model = BatchNormalization(momentum=0.8)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(model)\n",
    "        model = BatchNormalization(momentum=0.8)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Flatten()(model)\n",
    "        validity = Dense(1, activation=\"sigmoid\")(model)\n",
    "\n",
    "        return Model([z, img], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = cifar10.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                # progress_bar.update(index)\n",
    "\n",
    "                # get a batch of real images\n",
    "                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                z = np.random.normal(size=(batch_size, self.latent_dim))\n",
    "                imgs_ = self.generator.predict(z)\n",
    "\n",
    "                # Select a random batch of images and encode\n",
    "                # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                # imgs = X_train[idx]\n",
    "                z_ = self.encoder.predict(image_batch)\n",
    "\n",
    "                # Train the discriminator (img -> z is valid, z -> img is fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([z_, image_batch], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([z, imgs_], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Train the generator (z -> img is valid and img -> z is is invalid)\n",
    "                g_loss = self.bigan_generator.train_on_batch([z, image_batch], [valid, fake])\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, global_step, d_loss[0],\n",
    "                                                                                   100 * d_loss[1], g_loss[0]))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.sample_interval(epoch, global_step)\n",
    "\n",
    "    def sample_interval(self, epoch, global_step):\n",
    "        r, c = 10, 10\n",
    "        z = np.random.normal(size=(r*c, self.latent_dim))\n",
    "        generated_images = self.generator.predict(z)\n",
    "\n",
    "        generated_images = np.asarray((generated_images * 127.5 + 127.5).astype(np.uint8))\n",
    "\n",
    "        def vis_square(data, padsize=1, padval=0):\n",
    "            # force the number of filters to be square\n",
    "            n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "            padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
    "            data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
    "\n",
    "            # tile the filters into an image\n",
    "            data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "            data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "            return data\n",
    "\n",
    "        img = vis_square(generated_images)\n",
    "        if not os.path.isdir('images_bigan_cifar10'):\n",
    "            os.mkdir('images_bigan_cifar10')\n",
    "        Image.fromarray(img).save(\n",
    "            \"images_bigan_cifar10/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bigan = BIGAN()\n",
    "    bigan.train(epochs=50, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
