{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 1.287789, acc.: 23.44%] [G loss: 0.541541]\n",
      "epoch:0 step:2 [D loss: 0.801238, acc.: 50.78%] [G loss: 0.979042]\n",
      "epoch:0 step:3 [D loss: 0.587529, acc.: 66.41%] [G loss: 1.276818]\n",
      "epoch:0 step:4 [D loss: 0.698658, acc.: 64.84%] [G loss: 1.160223]\n",
      "epoch:0 step:5 [D loss: 0.705121, acc.: 56.25%] [G loss: 0.972318]\n",
      "epoch:0 step:6 [D loss: 0.636824, acc.: 64.06%] [G loss: 0.983631]\n",
      "epoch:0 step:7 [D loss: 0.504648, acc.: 76.56%] [G loss: 1.083948]\n",
      "epoch:0 step:8 [D loss: 0.516334, acc.: 78.12%] [G loss: 0.685956]\n",
      "epoch:0 step:9 [D loss: 0.525487, acc.: 76.56%] [G loss: 0.833036]\n",
      "epoch:0 step:10 [D loss: 0.739761, acc.: 59.38%] [G loss: 1.261822]\n",
      "epoch:0 step:11 [D loss: 0.696613, acc.: 60.16%] [G loss: 1.636428]\n",
      "epoch:0 step:12 [D loss: 0.648218, acc.: 68.75%] [G loss: 1.611941]\n",
      "epoch:0 step:13 [D loss: 0.598673, acc.: 70.31%] [G loss: 1.678117]\n",
      "epoch:0 step:14 [D loss: 0.625595, acc.: 67.19%] [G loss: 1.873719]\n",
      "epoch:0 step:15 [D loss: 0.753085, acc.: 60.94%] [G loss: 1.647895]\n",
      "epoch:0 step:16 [D loss: 0.738469, acc.: 57.03%] [G loss: 1.425098]\n",
      "epoch:0 step:17 [D loss: 0.564473, acc.: 72.66%] [G loss: 1.050995]\n",
      "epoch:0 step:18 [D loss: 0.724058, acc.: 61.72%] [G loss: 1.010090]\n",
      "epoch:0 step:19 [D loss: 0.833936, acc.: 53.91%] [G loss: 1.386836]\n",
      "epoch:0 step:20 [D loss: 1.003130, acc.: 40.62%] [G loss: 1.613798]\n",
      "epoch:0 step:21 [D loss: 0.821624, acc.: 57.81%] [G loss: 1.102471]\n",
      "epoch:0 step:22 [D loss: 0.578411, acc.: 72.66%] [G loss: 0.665558]\n",
      "epoch:0 step:23 [D loss: 0.570917, acc.: 74.22%] [G loss: 0.510713]\n",
      "epoch:0 step:24 [D loss: 0.848780, acc.: 60.16%] [G loss: 0.759145]\n",
      "epoch:0 step:25 [D loss: 0.851250, acc.: 49.22%] [G loss: 1.591043]\n",
      "epoch:0 step:26 [D loss: 1.049067, acc.: 39.84%] [G loss: 1.688680]\n",
      "epoch:0 step:27 [D loss: 1.039611, acc.: 40.62%] [G loss: 1.374966]\n",
      "epoch:0 step:28 [D loss: 0.778625, acc.: 57.81%] [G loss: 1.152659]\n",
      "epoch:0 step:29 [D loss: 0.645487, acc.: 64.06%] [G loss: 1.020288]\n",
      "epoch:0 step:30 [D loss: 0.623434, acc.: 70.31%] [G loss: 1.332434]\n",
      "epoch:0 step:31 [D loss: 0.970666, acc.: 46.09%] [G loss: 1.528114]\n",
      "epoch:0 step:32 [D loss: 0.847726, acc.: 50.00%] [G loss: 1.151006]\n",
      "epoch:0 step:33 [D loss: 0.594682, acc.: 70.31%] [G loss: 0.837595]\n",
      "epoch:0 step:34 [D loss: 0.526739, acc.: 77.34%] [G loss: 0.887053]\n",
      "epoch:0 step:35 [D loss: 0.616369, acc.: 66.41%] [G loss: 1.055189]\n",
      "epoch:0 step:36 [D loss: 0.693005, acc.: 65.62%] [G loss: 1.405587]\n",
      "epoch:0 step:37 [D loss: 1.032997, acc.: 37.50%] [G loss: 1.334762]\n",
      "epoch:0 step:38 [D loss: 1.121303, acc.: 31.25%] [G loss: 1.176647]\n",
      "epoch:0 step:39 [D loss: 0.948762, acc.: 44.53%] [G loss: 1.284691]\n",
      "epoch:0 step:40 [D loss: 0.843018, acc.: 50.00%] [G loss: 1.210988]\n",
      "epoch:0 step:41 [D loss: 0.980413, acc.: 39.84%] [G loss: 1.367593]\n",
      "epoch:0 step:42 [D loss: 0.893843, acc.: 46.88%] [G loss: 1.437114]\n",
      "epoch:0 step:43 [D loss: 0.941747, acc.: 44.53%] [G loss: 1.249566]\n",
      "epoch:0 step:44 [D loss: 1.026223, acc.: 38.28%] [G loss: 1.147302]\n",
      "epoch:0 step:45 [D loss: 0.868466, acc.: 50.00%] [G loss: 1.297388]\n",
      "epoch:0 step:46 [D loss: 0.910411, acc.: 42.19%] [G loss: 1.183440]\n",
      "epoch:0 step:47 [D loss: 0.877216, acc.: 47.66%] [G loss: 1.381650]\n",
      "epoch:0 step:48 [D loss: 0.927483, acc.: 42.19%] [G loss: 1.276469]\n",
      "epoch:0 step:49 [D loss: 0.818503, acc.: 49.22%] [G loss: 1.150548]\n",
      "epoch:0 step:50 [D loss: 0.810681, acc.: 53.91%] [G loss: 1.364156]\n",
      "epoch:0 step:51 [D loss: 0.821013, acc.: 53.12%] [G loss: 1.328204]\n",
      "epoch:0 step:52 [D loss: 0.799839, acc.: 52.34%] [G loss: 1.432745]\n",
      "epoch:0 step:53 [D loss: 0.895584, acc.: 48.44%] [G loss: 1.469197]\n",
      "epoch:0 step:54 [D loss: 0.869870, acc.: 50.00%] [G loss: 1.425966]\n",
      "epoch:0 step:55 [D loss: 0.849817, acc.: 51.56%] [G loss: 1.458900]\n",
      "epoch:0 step:56 [D loss: 0.953827, acc.: 49.22%] [G loss: 1.160382]\n",
      "epoch:0 step:57 [D loss: 0.890948, acc.: 52.34%] [G loss: 1.312201]\n",
      "epoch:0 step:58 [D loss: 0.962714, acc.: 49.22%] [G loss: 1.250111]\n",
      "epoch:0 step:59 [D loss: 0.814196, acc.: 50.78%] [G loss: 1.227806]\n",
      "epoch:0 step:60 [D loss: 0.762417, acc.: 55.47%] [G loss: 1.248748]\n",
      "epoch:0 step:61 [D loss: 0.816463, acc.: 53.12%] [G loss: 1.155404]\n",
      "epoch:0 step:62 [D loss: 0.975310, acc.: 43.75%] [G loss: 1.028208]\n",
      "epoch:0 step:63 [D loss: 1.002060, acc.: 44.53%] [G loss: 1.195092]\n",
      "epoch:0 step:64 [D loss: 0.853026, acc.: 44.53%] [G loss: 1.325111]\n",
      "epoch:0 step:65 [D loss: 0.934768, acc.: 41.41%] [G loss: 1.131590]\n",
      "epoch:0 step:66 [D loss: 0.877695, acc.: 45.31%] [G loss: 1.314033]\n",
      "epoch:0 step:67 [D loss: 0.865274, acc.: 45.31%] [G loss: 1.222597]\n",
      "epoch:0 step:68 [D loss: 0.851973, acc.: 49.22%] [G loss: 1.254374]\n",
      "epoch:0 step:69 [D loss: 0.856940, acc.: 46.88%] [G loss: 1.257761]\n",
      "epoch:0 step:70 [D loss: 0.833388, acc.: 50.78%] [G loss: 1.301792]\n",
      "epoch:0 step:71 [D loss: 0.964415, acc.: 39.84%] [G loss: 1.195027]\n",
      "epoch:0 step:72 [D loss: 0.961814, acc.: 43.75%] [G loss: 1.019488]\n",
      "epoch:0 step:73 [D loss: 0.798116, acc.: 52.34%] [G loss: 1.194729]\n",
      "epoch:0 step:74 [D loss: 0.786919, acc.: 49.22%] [G loss: 1.205470]\n",
      "epoch:0 step:75 [D loss: 0.826004, acc.: 47.66%] [G loss: 1.013916]\n",
      "epoch:0 step:76 [D loss: 0.822933, acc.: 43.75%] [G loss: 1.322344]\n",
      "epoch:0 step:77 [D loss: 0.815544, acc.: 51.56%] [G loss: 1.431070]\n",
      "epoch:0 step:78 [D loss: 0.869514, acc.: 50.00%] [G loss: 1.222430]\n",
      "epoch:0 step:79 [D loss: 1.020298, acc.: 44.53%] [G loss: 1.190524]\n",
      "epoch:0 step:80 [D loss: 0.833768, acc.: 46.88%] [G loss: 1.032953]\n",
      "epoch:0 step:81 [D loss: 0.841847, acc.: 55.47%] [G loss: 1.258306]\n",
      "epoch:0 step:82 [D loss: 0.898743, acc.: 44.53%] [G loss: 1.157195]\n",
      "epoch:0 step:83 [D loss: 0.970037, acc.: 38.28%] [G loss: 1.075493]\n",
      "epoch:0 step:84 [D loss: 0.815491, acc.: 49.22%] [G loss: 1.146692]\n",
      "epoch:0 step:85 [D loss: 0.965637, acc.: 44.53%] [G loss: 1.240936]\n",
      "epoch:0 step:86 [D loss: 0.967434, acc.: 41.41%] [G loss: 1.245564]\n",
      "epoch:0 step:87 [D loss: 0.835645, acc.: 53.91%] [G loss: 1.128953]\n",
      "epoch:0 step:88 [D loss: 0.891187, acc.: 42.97%] [G loss: 1.211943]\n",
      "epoch:0 step:89 [D loss: 0.812439, acc.: 45.31%] [G loss: 1.151151]\n",
      "epoch:0 step:90 [D loss: 0.782833, acc.: 53.12%] [G loss: 1.212993]\n",
      "epoch:0 step:91 [D loss: 0.783656, acc.: 55.47%] [G loss: 1.001304]\n",
      "epoch:0 step:92 [D loss: 0.872622, acc.: 44.53%] [G loss: 1.119205]\n",
      "epoch:0 step:93 [D loss: 0.745442, acc.: 48.44%] [G loss: 1.102816]\n",
      "epoch:0 step:94 [D loss: 0.921721, acc.: 47.66%] [G loss: 1.113078]\n",
      "epoch:0 step:95 [D loss: 0.893744, acc.: 46.09%] [G loss: 1.027343]\n",
      "epoch:0 step:96 [D loss: 0.930611, acc.: 41.41%] [G loss: 1.131078]\n",
      "epoch:0 step:97 [D loss: 0.804195, acc.: 47.66%] [G loss: 1.117299]\n",
      "epoch:0 step:98 [D loss: 0.928074, acc.: 42.19%] [G loss: 1.048485]\n",
      "epoch:0 step:99 [D loss: 0.879386, acc.: 38.28%] [G loss: 1.101207]\n",
      "epoch:0 step:100 [D loss: 0.804683, acc.: 53.12%] [G loss: 1.090838]\n",
      "epoch:0 step:101 [D loss: 0.792924, acc.: 55.47%] [G loss: 1.095666]\n",
      "epoch:0 step:102 [D loss: 0.847717, acc.: 47.66%] [G loss: 1.069347]\n",
      "epoch:0 step:103 [D loss: 0.679592, acc.: 56.25%] [G loss: 1.135629]\n",
      "epoch:0 step:104 [D loss: 0.828626, acc.: 46.09%] [G loss: 1.001759]\n",
      "epoch:0 step:105 [D loss: 0.785603, acc.: 51.56%] [G loss: 1.048127]\n",
      "epoch:0 step:106 [D loss: 0.776853, acc.: 50.78%] [G loss: 1.108178]\n",
      "epoch:0 step:107 [D loss: 0.698231, acc.: 62.50%] [G loss: 1.267682]\n",
      "epoch:0 step:108 [D loss: 0.968042, acc.: 42.19%] [G loss: 1.071746]\n",
      "epoch:0 step:109 [D loss: 0.931393, acc.: 42.97%] [G loss: 1.135733]\n",
      "epoch:0 step:110 [D loss: 0.821359, acc.: 49.22%] [G loss: 1.118076]\n",
      "epoch:0 step:111 [D loss: 0.790332, acc.: 45.31%] [G loss: 1.195341]\n",
      "epoch:0 step:112 [D loss: 0.865653, acc.: 42.19%] [G loss: 1.016106]\n",
      "epoch:0 step:113 [D loss: 0.817694, acc.: 46.09%] [G loss: 1.181600]\n",
      "epoch:0 step:114 [D loss: 0.951526, acc.: 41.41%] [G loss: 1.086309]\n",
      "epoch:0 step:115 [D loss: 0.808370, acc.: 53.91%] [G loss: 1.089779]\n",
      "epoch:0 step:116 [D loss: 0.814418, acc.: 49.22%] [G loss: 1.115725]\n",
      "epoch:0 step:117 [D loss: 0.757094, acc.: 52.34%] [G loss: 1.073992]\n",
      "epoch:0 step:118 [D loss: 0.832935, acc.: 46.88%] [G loss: 1.035126]\n",
      "epoch:0 step:119 [D loss: 0.790110, acc.: 49.22%] [G loss: 1.166177]\n",
      "epoch:0 step:120 [D loss: 0.866077, acc.: 39.06%] [G loss: 1.007909]\n",
      "epoch:0 step:121 [D loss: 0.886547, acc.: 47.66%] [G loss: 0.923388]\n",
      "epoch:0 step:122 [D loss: 0.956634, acc.: 41.41%] [G loss: 0.990626]\n",
      "epoch:0 step:123 [D loss: 0.888317, acc.: 41.41%] [G loss: 0.970498]\n",
      "epoch:0 step:124 [D loss: 0.907826, acc.: 39.84%] [G loss: 0.956841]\n",
      "epoch:0 step:125 [D loss: 0.861725, acc.: 44.53%] [G loss: 1.063808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:126 [D loss: 0.766735, acc.: 51.56%] [G loss: 1.232647]\n",
      "epoch:0 step:127 [D loss: 0.821657, acc.: 43.75%] [G loss: 1.175924]\n",
      "epoch:0 step:128 [D loss: 0.724581, acc.: 55.47%] [G loss: 0.919375]\n",
      "epoch:0 step:129 [D loss: 0.899751, acc.: 41.41%] [G loss: 1.123849]\n",
      "epoch:0 step:130 [D loss: 0.760593, acc.: 47.66%] [G loss: 1.171886]\n",
      "epoch:0 step:131 [D loss: 0.796568, acc.: 47.66%] [G loss: 1.165784]\n",
      "epoch:0 step:132 [D loss: 0.894369, acc.: 42.97%] [G loss: 1.051179]\n",
      "epoch:0 step:133 [D loss: 0.844079, acc.: 46.88%] [G loss: 1.044677]\n",
      "epoch:0 step:134 [D loss: 0.868471, acc.: 46.88%] [G loss: 1.032505]\n",
      "epoch:0 step:135 [D loss: 0.729335, acc.: 54.69%] [G loss: 1.134413]\n",
      "epoch:0 step:136 [D loss: 0.807881, acc.: 50.00%] [G loss: 1.086956]\n",
      "epoch:0 step:137 [D loss: 0.843468, acc.: 50.78%] [G loss: 0.986600]\n",
      "epoch:0 step:138 [D loss: 0.719735, acc.: 58.59%] [G loss: 1.057983]\n",
      "epoch:0 step:139 [D loss: 0.815333, acc.: 45.31%] [G loss: 1.192881]\n",
      "epoch:0 step:140 [D loss: 0.880056, acc.: 49.22%] [G loss: 1.077360]\n",
      "epoch:0 step:141 [D loss: 0.873971, acc.: 42.19%] [G loss: 1.020755]\n",
      "epoch:0 step:142 [D loss: 0.857017, acc.: 46.88%] [G loss: 1.034099]\n",
      "epoch:0 step:143 [D loss: 0.843474, acc.: 46.88%] [G loss: 1.132611]\n",
      "epoch:0 step:144 [D loss: 0.694917, acc.: 56.25%] [G loss: 1.149806]\n",
      "epoch:0 step:145 [D loss: 0.713111, acc.: 60.94%] [G loss: 1.187053]\n",
      "epoch:0 step:146 [D loss: 0.857391, acc.: 40.62%] [G loss: 1.067929]\n",
      "epoch:0 step:147 [D loss: 0.885343, acc.: 43.75%] [G loss: 1.016032]\n",
      "epoch:0 step:148 [D loss: 0.795856, acc.: 46.88%] [G loss: 1.154015]\n",
      "epoch:0 step:149 [D loss: 0.814253, acc.: 53.12%] [G loss: 1.012334]\n",
      "epoch:0 step:150 [D loss: 0.832634, acc.: 53.12%] [G loss: 1.045720]\n",
      "epoch:0 step:151 [D loss: 0.695348, acc.: 60.94%] [G loss: 1.160355]\n",
      "epoch:0 step:152 [D loss: 0.667864, acc.: 60.94%] [G loss: 1.315395]\n",
      "epoch:0 step:153 [D loss: 0.784047, acc.: 55.47%] [G loss: 1.050400]\n",
      "epoch:0 step:154 [D loss: 0.843150, acc.: 42.97%] [G loss: 1.017123]\n",
      "epoch:0 step:155 [D loss: 0.809062, acc.: 50.00%] [G loss: 0.974882]\n",
      "epoch:0 step:156 [D loss: 0.815001, acc.: 50.00%] [G loss: 1.052059]\n",
      "epoch:0 step:157 [D loss: 0.835844, acc.: 43.75%] [G loss: 1.190575]\n",
      "epoch:0 step:158 [D loss: 0.890482, acc.: 41.41%] [G loss: 1.192682]\n",
      "epoch:0 step:159 [D loss: 0.752707, acc.: 55.47%] [G loss: 1.047449]\n",
      "epoch:0 step:160 [D loss: 0.871621, acc.: 39.06%] [G loss: 0.997754]\n",
      "epoch:0 step:161 [D loss: 0.785738, acc.: 52.34%] [G loss: 0.999878]\n",
      "epoch:0 step:162 [D loss: 0.751069, acc.: 53.12%] [G loss: 1.031991]\n",
      "epoch:0 step:163 [D loss: 0.781805, acc.: 50.78%] [G loss: 1.023575]\n",
      "epoch:0 step:164 [D loss: 0.743815, acc.: 50.78%] [G loss: 1.133782]\n",
      "epoch:0 step:165 [D loss: 0.837272, acc.: 49.22%] [G loss: 1.063412]\n",
      "epoch:0 step:166 [D loss: 0.767234, acc.: 51.56%] [G loss: 1.153240]\n",
      "epoch:0 step:167 [D loss: 0.706615, acc.: 57.03%] [G loss: 1.185940]\n",
      "epoch:0 step:168 [D loss: 0.754087, acc.: 46.88%] [G loss: 1.054926]\n",
      "epoch:0 step:169 [D loss: 0.849702, acc.: 43.75%] [G loss: 1.130219]\n",
      "epoch:0 step:170 [D loss: 0.764056, acc.: 52.34%] [G loss: 1.146346]\n",
      "epoch:0 step:171 [D loss: 0.816184, acc.: 47.66%] [G loss: 1.153839]\n",
      "epoch:0 step:172 [D loss: 0.893850, acc.: 44.53%] [G loss: 0.960589]\n",
      "epoch:0 step:173 [D loss: 0.797127, acc.: 49.22%] [G loss: 1.151196]\n",
      "epoch:0 step:174 [D loss: 0.873906, acc.: 45.31%] [G loss: 1.067266]\n",
      "epoch:0 step:175 [D loss: 0.772636, acc.: 49.22%] [G loss: 0.953418]\n",
      "epoch:0 step:176 [D loss: 0.847456, acc.: 40.62%] [G loss: 1.014149]\n",
      "epoch:0 step:177 [D loss: 0.828925, acc.: 48.44%] [G loss: 0.997215]\n",
      "epoch:0 step:178 [D loss: 0.819688, acc.: 46.88%] [G loss: 1.046809]\n",
      "epoch:0 step:179 [D loss: 0.763835, acc.: 53.12%] [G loss: 1.062000]\n",
      "epoch:0 step:180 [D loss: 0.678509, acc.: 59.38%] [G loss: 1.082570]\n",
      "epoch:0 step:181 [D loss: 0.829428, acc.: 50.78%] [G loss: 1.010489]\n",
      "epoch:0 step:182 [D loss: 0.928380, acc.: 40.62%] [G loss: 1.009415]\n",
      "epoch:0 step:183 [D loss: 0.837993, acc.: 42.19%] [G loss: 1.095072]\n",
      "epoch:0 step:184 [D loss: 0.782233, acc.: 49.22%] [G loss: 1.203004]\n",
      "epoch:0 step:185 [D loss: 0.792752, acc.: 51.56%] [G loss: 1.085189]\n",
      "epoch:0 step:186 [D loss: 0.779917, acc.: 53.91%] [G loss: 1.135124]\n",
      "epoch:0 step:187 [D loss: 0.787198, acc.: 52.34%] [G loss: 1.029946]\n",
      "epoch:0 step:188 [D loss: 0.794423, acc.: 57.03%] [G loss: 1.087442]\n",
      "epoch:0 step:189 [D loss: 0.868743, acc.: 46.88%] [G loss: 1.012046]\n",
      "epoch:0 step:190 [D loss: 0.831185, acc.: 51.56%] [G loss: 1.074799]\n",
      "epoch:0 step:191 [D loss: 0.782660, acc.: 48.44%] [G loss: 1.063471]\n",
      "epoch:0 step:192 [D loss: 0.895572, acc.: 43.75%] [G loss: 1.098779]\n",
      "epoch:0 step:193 [D loss: 0.848245, acc.: 42.19%] [G loss: 1.000551]\n",
      "epoch:0 step:194 [D loss: 0.768435, acc.: 52.34%] [G loss: 1.135428]\n",
      "epoch:0 step:195 [D loss: 0.846102, acc.: 49.22%] [G loss: 1.134678]\n",
      "epoch:0 step:196 [D loss: 0.780463, acc.: 53.91%] [G loss: 0.993711]\n",
      "epoch:0 step:197 [D loss: 0.711679, acc.: 55.47%] [G loss: 1.168991]\n",
      "epoch:0 step:198 [D loss: 0.714527, acc.: 54.69%] [G loss: 1.077914]\n",
      "epoch:0 step:199 [D loss: 0.837064, acc.: 45.31%] [G loss: 1.041346]\n",
      "epoch:0 step:200 [D loss: 0.808390, acc.: 50.78%] [G loss: 1.035418]\n",
      "epoch:0 step:201 [D loss: 0.833922, acc.: 43.75%] [G loss: 1.102086]\n",
      "epoch:0 step:202 [D loss: 0.819132, acc.: 46.88%] [G loss: 0.928452]\n",
      "epoch:0 step:203 [D loss: 0.863333, acc.: 46.09%] [G loss: 0.813055]\n",
      "epoch:0 step:204 [D loss: 0.851356, acc.: 48.44%] [G loss: 0.898950]\n",
      "epoch:0 step:205 [D loss: 0.845270, acc.: 46.88%] [G loss: 0.935722]\n",
      "epoch:0 step:206 [D loss: 0.796375, acc.: 46.88%] [G loss: 0.983300]\n",
      "epoch:0 step:207 [D loss: 0.784516, acc.: 49.22%] [G loss: 1.120467]\n",
      "epoch:0 step:208 [D loss: 0.857875, acc.: 44.53%] [G loss: 1.080854]\n",
      "epoch:0 step:209 [D loss: 0.773012, acc.: 52.34%] [G loss: 1.158642]\n",
      "epoch:0 step:210 [D loss: 0.883761, acc.: 40.62%] [G loss: 1.094115]\n",
      "epoch:0 step:211 [D loss: 0.856343, acc.: 47.66%] [G loss: 1.121118]\n",
      "epoch:0 step:212 [D loss: 0.780458, acc.: 48.44%] [G loss: 1.021416]\n",
      "epoch:0 step:213 [D loss: 0.739317, acc.: 53.91%] [G loss: 1.260055]\n",
      "epoch:0 step:214 [D loss: 0.791399, acc.: 46.88%] [G loss: 1.125518]\n",
      "epoch:0 step:215 [D loss: 0.785596, acc.: 51.56%] [G loss: 1.039992]\n",
      "epoch:0 step:216 [D loss: 0.787273, acc.: 53.12%] [G loss: 1.020361]\n",
      "epoch:0 step:217 [D loss: 0.824330, acc.: 48.44%] [G loss: 1.205386]\n",
      "epoch:0 step:218 [D loss: 0.841810, acc.: 44.53%] [G loss: 1.079043]\n",
      "epoch:0 step:219 [D loss: 0.890896, acc.: 44.53%] [G loss: 1.033349]\n",
      "epoch:0 step:220 [D loss: 0.818360, acc.: 46.88%] [G loss: 1.127496]\n",
      "epoch:0 step:221 [D loss: 0.828988, acc.: 46.88%] [G loss: 1.051390]\n",
      "epoch:0 step:222 [D loss: 0.751026, acc.: 49.22%] [G loss: 1.078742]\n",
      "epoch:0 step:223 [D loss: 0.733156, acc.: 57.81%] [G loss: 1.104743]\n",
      "epoch:0 step:224 [D loss: 0.819026, acc.: 47.66%] [G loss: 1.116978]\n",
      "epoch:0 step:225 [D loss: 0.902995, acc.: 40.62%] [G loss: 0.964767]\n",
      "epoch:0 step:226 [D loss: 0.730187, acc.: 53.12%] [G loss: 0.936975]\n",
      "epoch:0 step:227 [D loss: 0.735147, acc.: 53.91%] [G loss: 1.078309]\n",
      "epoch:0 step:228 [D loss: 0.764671, acc.: 49.22%] [G loss: 1.024383]\n",
      "epoch:0 step:229 [D loss: 0.912812, acc.: 35.94%] [G loss: 1.084718]\n",
      "epoch:0 step:230 [D loss: 0.711225, acc.: 53.12%] [G loss: 1.095572]\n",
      "epoch:0 step:231 [D loss: 0.734427, acc.: 52.34%] [G loss: 1.129025]\n",
      "epoch:0 step:232 [D loss: 0.685866, acc.: 60.94%] [G loss: 1.188091]\n",
      "epoch:0 step:233 [D loss: 0.834886, acc.: 47.66%] [G loss: 1.027331]\n",
      "epoch:0 step:234 [D loss: 0.876493, acc.: 48.44%] [G loss: 1.078250]\n",
      "epoch:0 step:235 [D loss: 0.884747, acc.: 39.06%] [G loss: 0.982089]\n",
      "epoch:0 step:236 [D loss: 0.796062, acc.: 50.00%] [G loss: 0.891215]\n",
      "epoch:0 step:237 [D loss: 0.852395, acc.: 41.41%] [G loss: 0.952973]\n",
      "epoch:0 step:238 [D loss: 0.674929, acc.: 65.62%] [G loss: 1.118471]\n",
      "epoch:0 step:239 [D loss: 0.835654, acc.: 49.22%] [G loss: 1.087783]\n",
      "epoch:0 step:240 [D loss: 0.739654, acc.: 54.69%] [G loss: 0.979900]\n",
      "epoch:0 step:241 [D loss: 0.744662, acc.: 51.56%] [G loss: 1.026274]\n",
      "epoch:0 step:242 [D loss: 0.839054, acc.: 43.75%] [G loss: 1.226198]\n",
      "epoch:0 step:243 [D loss: 0.790679, acc.: 51.56%] [G loss: 0.976238]\n",
      "epoch:0 step:244 [D loss: 0.692792, acc.: 57.81%] [G loss: 0.912325]\n",
      "epoch:0 step:245 [D loss: 0.774969, acc.: 53.12%] [G loss: 1.147023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:246 [D loss: 0.723133, acc.: 53.12%] [G loss: 1.070776]\n",
      "epoch:0 step:247 [D loss: 0.813910, acc.: 46.88%] [G loss: 0.998600]\n",
      "epoch:0 step:248 [D loss: 0.727747, acc.: 56.25%] [G loss: 1.208804]\n",
      "epoch:0 step:249 [D loss: 0.759354, acc.: 52.34%] [G loss: 1.059098]\n",
      "epoch:0 step:250 [D loss: 0.859249, acc.: 46.09%] [G loss: 0.879811]\n",
      "epoch:0 step:251 [D loss: 0.888389, acc.: 39.06%] [G loss: 0.962884]\n",
      "epoch:0 step:252 [D loss: 0.785604, acc.: 56.25%] [G loss: 1.013687]\n",
      "epoch:0 step:253 [D loss: 0.753131, acc.: 57.03%] [G loss: 1.005148]\n",
      "epoch:0 step:254 [D loss: 0.803237, acc.: 47.66%] [G loss: 1.085441]\n",
      "epoch:0 step:255 [D loss: 0.757708, acc.: 49.22%] [G loss: 0.871258]\n",
      "epoch:0 step:256 [D loss: 0.792637, acc.: 47.66%] [G loss: 1.107943]\n",
      "epoch:0 step:257 [D loss: 0.687143, acc.: 57.81%] [G loss: 1.086909]\n",
      "epoch:0 step:258 [D loss: 0.669225, acc.: 60.94%] [G loss: 1.099468]\n",
      "epoch:0 step:259 [D loss: 0.732983, acc.: 54.69%] [G loss: 1.144948]\n",
      "epoch:0 step:260 [D loss: 0.802732, acc.: 46.88%] [G loss: 1.125644]\n",
      "epoch:0 step:261 [D loss: 0.750263, acc.: 53.12%] [G loss: 1.051178]\n",
      "epoch:0 step:262 [D loss: 0.682768, acc.: 59.38%] [G loss: 1.076978]\n",
      "epoch:0 step:263 [D loss: 0.768600, acc.: 53.91%] [G loss: 1.087141]\n",
      "epoch:0 step:264 [D loss: 0.749578, acc.: 47.66%] [G loss: 1.144367]\n",
      "epoch:0 step:265 [D loss: 0.804438, acc.: 46.09%] [G loss: 1.020051]\n",
      "epoch:0 step:266 [D loss: 0.696698, acc.: 59.38%] [G loss: 1.071339]\n",
      "epoch:0 step:267 [D loss: 0.730196, acc.: 54.69%] [G loss: 0.924835]\n",
      "epoch:0 step:268 [D loss: 0.783479, acc.: 53.12%] [G loss: 1.015298]\n",
      "epoch:0 step:269 [D loss: 0.806112, acc.: 47.66%] [G loss: 0.979410]\n",
      "epoch:0 step:270 [D loss: 0.782772, acc.: 55.47%] [G loss: 0.947767]\n",
      "epoch:0 step:271 [D loss: 0.836324, acc.: 42.97%] [G loss: 0.983537]\n",
      "epoch:0 step:272 [D loss: 0.775114, acc.: 48.44%] [G loss: 1.045148]\n",
      "epoch:0 step:273 [D loss: 0.832003, acc.: 42.97%] [G loss: 0.936185]\n",
      "epoch:0 step:274 [D loss: 0.848781, acc.: 37.50%] [G loss: 1.005708]\n",
      "epoch:0 step:275 [D loss: 0.708724, acc.: 58.59%] [G loss: 1.012717]\n",
      "epoch:0 step:276 [D loss: 0.794243, acc.: 45.31%] [G loss: 1.050276]\n",
      "epoch:0 step:277 [D loss: 0.794445, acc.: 53.91%] [G loss: 0.861496]\n",
      "epoch:0 step:278 [D loss: 0.805016, acc.: 50.78%] [G loss: 1.034909]\n",
      "epoch:0 step:279 [D loss: 0.693614, acc.: 61.72%] [G loss: 1.049624]\n",
      "epoch:0 step:280 [D loss: 0.739382, acc.: 54.69%] [G loss: 0.993901]\n",
      "epoch:0 step:281 [D loss: 0.774804, acc.: 54.69%] [G loss: 1.037318]\n",
      "epoch:0 step:282 [D loss: 0.733394, acc.: 55.47%] [G loss: 1.036714]\n",
      "epoch:0 step:283 [D loss: 0.750405, acc.: 55.47%] [G loss: 0.934294]\n",
      "epoch:0 step:284 [D loss: 0.773185, acc.: 48.44%] [G loss: 1.062195]\n",
      "epoch:0 step:285 [D loss: 0.760207, acc.: 48.44%] [G loss: 1.031165]\n",
      "epoch:0 step:286 [D loss: 0.782017, acc.: 46.88%] [G loss: 1.103257]\n",
      "epoch:0 step:287 [D loss: 0.776824, acc.: 51.56%] [G loss: 1.067559]\n",
      "epoch:0 step:288 [D loss: 0.750036, acc.: 53.12%] [G loss: 0.993328]\n",
      "epoch:0 step:289 [D loss: 0.774717, acc.: 56.25%] [G loss: 1.152338]\n",
      "epoch:0 step:290 [D loss: 0.829072, acc.: 45.31%] [G loss: 0.983436]\n",
      "epoch:0 step:291 [D loss: 0.737348, acc.: 50.78%] [G loss: 1.106995]\n",
      "epoch:0 step:292 [D loss: 0.763135, acc.: 47.66%] [G loss: 0.939012]\n",
      "epoch:0 step:293 [D loss: 0.708001, acc.: 58.59%] [G loss: 1.092337]\n",
      "epoch:0 step:294 [D loss: 0.776510, acc.: 50.00%] [G loss: 0.956833]\n",
      "epoch:0 step:295 [D loss: 0.755094, acc.: 52.34%] [G loss: 1.116201]\n",
      "epoch:0 step:296 [D loss: 0.747840, acc.: 53.12%] [G loss: 1.073872]\n",
      "epoch:0 step:297 [D loss: 0.778632, acc.: 47.66%] [G loss: 0.977979]\n",
      "epoch:0 step:298 [D loss: 0.796477, acc.: 46.88%] [G loss: 1.154127]\n",
      "epoch:0 step:299 [D loss: 0.750177, acc.: 47.66%] [G loss: 1.187710]\n",
      "epoch:0 step:300 [D loss: 0.745743, acc.: 58.59%] [G loss: 1.111161]\n",
      "epoch:0 step:301 [D loss: 0.792706, acc.: 50.00%] [G loss: 0.967938]\n",
      "epoch:0 step:302 [D loss: 0.661091, acc.: 63.28%] [G loss: 1.103606]\n",
      "epoch:0 step:303 [D loss: 0.810842, acc.: 46.88%] [G loss: 1.069707]\n",
      "epoch:0 step:304 [D loss: 0.717270, acc.: 54.69%] [G loss: 1.169267]\n",
      "epoch:0 step:305 [D loss: 0.832350, acc.: 40.62%] [G loss: 1.173500]\n",
      "epoch:0 step:306 [D loss: 0.705519, acc.: 57.81%] [G loss: 1.018119]\n",
      "epoch:0 step:307 [D loss: 0.769654, acc.: 51.56%] [G loss: 0.950461]\n",
      "epoch:0 step:308 [D loss: 0.788629, acc.: 45.31%] [G loss: 1.002260]\n",
      "epoch:0 step:309 [D loss: 0.674794, acc.: 57.81%] [G loss: 1.202852]\n",
      "epoch:0 step:310 [D loss: 0.747408, acc.: 53.12%] [G loss: 0.925528]\n",
      "epoch:0 step:311 [D loss: 0.802326, acc.: 51.56%] [G loss: 1.018304]\n",
      "epoch:0 step:312 [D loss: 0.717585, acc.: 53.91%] [G loss: 1.016003]\n",
      "epoch:0 step:313 [D loss: 0.660344, acc.: 64.06%] [G loss: 1.239507]\n",
      "epoch:0 step:314 [D loss: 0.756208, acc.: 52.34%] [G loss: 1.068446]\n",
      "epoch:0 step:315 [D loss: 0.693434, acc.: 59.38%] [G loss: 1.135319]\n",
      "epoch:0 step:316 [D loss: 0.854832, acc.: 46.88%] [G loss: 1.174221]\n",
      "epoch:0 step:317 [D loss: 0.793283, acc.: 50.78%] [G loss: 0.995870]\n",
      "epoch:0 step:318 [D loss: 0.744750, acc.: 50.78%] [G loss: 1.015523]\n",
      "epoch:0 step:319 [D loss: 0.813561, acc.: 50.00%] [G loss: 1.021748]\n",
      "epoch:0 step:320 [D loss: 0.820853, acc.: 37.50%] [G loss: 1.055624]\n",
      "epoch:0 step:321 [D loss: 0.834963, acc.: 48.44%] [G loss: 0.993988]\n",
      "epoch:0 step:322 [D loss: 0.758349, acc.: 46.88%] [G loss: 0.986840]\n",
      "epoch:0 step:323 [D loss: 0.826878, acc.: 47.66%] [G loss: 0.942835]\n",
      "epoch:0 step:324 [D loss: 0.737627, acc.: 52.34%] [G loss: 0.923445]\n",
      "epoch:0 step:325 [D loss: 0.726334, acc.: 55.47%] [G loss: 1.060668]\n",
      "epoch:0 step:326 [D loss: 0.725117, acc.: 57.81%] [G loss: 1.003052]\n",
      "epoch:0 step:327 [D loss: 0.718282, acc.: 53.12%] [G loss: 1.127750]\n",
      "epoch:0 step:328 [D loss: 0.779130, acc.: 51.56%] [G loss: 1.158685]\n",
      "epoch:0 step:329 [D loss: 0.726315, acc.: 53.91%] [G loss: 1.132413]\n",
      "epoch:0 step:330 [D loss: 0.738059, acc.: 51.56%] [G loss: 1.054012]\n",
      "epoch:0 step:331 [D loss: 0.743966, acc.: 50.78%] [G loss: 1.096330]\n",
      "epoch:0 step:332 [D loss: 0.645206, acc.: 60.16%] [G loss: 1.142179]\n",
      "epoch:0 step:333 [D loss: 0.661073, acc.: 64.06%] [G loss: 1.190590]\n",
      "epoch:0 step:334 [D loss: 0.685330, acc.: 56.25%] [G loss: 1.129800]\n",
      "epoch:0 step:335 [D loss: 0.707764, acc.: 58.59%] [G loss: 1.031952]\n",
      "epoch:0 step:336 [D loss: 0.736450, acc.: 54.69%] [G loss: 1.074041]\n",
      "epoch:0 step:337 [D loss: 0.667074, acc.: 57.03%] [G loss: 1.080649]\n",
      "epoch:0 step:338 [D loss: 0.729673, acc.: 49.22%] [G loss: 1.110356]\n",
      "epoch:0 step:339 [D loss: 0.749506, acc.: 54.69%] [G loss: 0.922161]\n",
      "epoch:0 step:340 [D loss: 0.740100, acc.: 52.34%] [G loss: 1.040593]\n",
      "epoch:0 step:341 [D loss: 0.827003, acc.: 45.31%] [G loss: 1.031310]\n",
      "epoch:0 step:342 [D loss: 0.721819, acc.: 57.03%] [G loss: 1.035099]\n",
      "epoch:0 step:343 [D loss: 0.795288, acc.: 51.56%] [G loss: 0.963240]\n",
      "epoch:0 step:344 [D loss: 0.654787, acc.: 67.97%] [G loss: 1.149573]\n",
      "epoch:0 step:345 [D loss: 0.822926, acc.: 44.53%] [G loss: 1.069910]\n",
      "epoch:0 step:346 [D loss: 0.749446, acc.: 52.34%] [G loss: 1.102882]\n",
      "epoch:0 step:347 [D loss: 0.672384, acc.: 57.03%] [G loss: 1.272352]\n",
      "epoch:0 step:348 [D loss: 0.858007, acc.: 44.53%] [G loss: 1.127794]\n",
      "epoch:0 step:349 [D loss: 0.826947, acc.: 46.88%] [G loss: 0.972001]\n",
      "epoch:0 step:350 [D loss: 0.797094, acc.: 47.66%] [G loss: 1.019965]\n",
      "epoch:0 step:351 [D loss: 0.745650, acc.: 50.00%] [G loss: 1.111792]\n",
      "epoch:0 step:352 [D loss: 0.780001, acc.: 51.56%] [G loss: 1.090026]\n",
      "epoch:0 step:353 [D loss: 0.784894, acc.: 53.91%] [G loss: 1.157386]\n",
      "epoch:0 step:354 [D loss: 0.692104, acc.: 57.81%] [G loss: 1.163780]\n",
      "epoch:0 step:355 [D loss: 0.742206, acc.: 50.00%] [G loss: 1.002265]\n",
      "epoch:0 step:356 [D loss: 0.743688, acc.: 50.78%] [G loss: 1.121292]\n",
      "epoch:0 step:357 [D loss: 0.759938, acc.: 59.38%] [G loss: 1.007314]\n",
      "epoch:0 step:358 [D loss: 0.681553, acc.: 59.38%] [G loss: 1.154955]\n",
      "epoch:0 step:359 [D loss: 0.786586, acc.: 53.91%] [G loss: 1.138939]\n",
      "epoch:0 step:360 [D loss: 0.674494, acc.: 56.25%] [G loss: 1.171766]\n",
      "epoch:0 step:361 [D loss: 0.790524, acc.: 46.88%] [G loss: 1.047899]\n",
      "epoch:0 step:362 [D loss: 0.836049, acc.: 53.12%] [G loss: 1.073537]\n",
      "epoch:0 step:363 [D loss: 0.789636, acc.: 52.34%] [G loss: 1.006768]\n",
      "epoch:0 step:364 [D loss: 0.798755, acc.: 50.78%] [G loss: 1.059292]\n",
      "epoch:0 step:365 [D loss: 0.771332, acc.: 51.56%] [G loss: 1.224516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:366 [D loss: 0.694067, acc.: 53.91%] [G loss: 1.114067]\n",
      "epoch:0 step:367 [D loss: 0.726456, acc.: 52.34%] [G loss: 1.134926]\n",
      "epoch:0 step:368 [D loss: 0.784781, acc.: 51.56%] [G loss: 1.180644]\n",
      "epoch:0 step:369 [D loss: 0.819519, acc.: 42.97%] [G loss: 1.210620]\n",
      "epoch:0 step:370 [D loss: 0.745654, acc.: 55.47%] [G loss: 1.076681]\n",
      "epoch:0 step:371 [D loss: 0.809768, acc.: 42.19%] [G loss: 1.049457]\n",
      "epoch:0 step:372 [D loss: 0.723345, acc.: 58.59%] [G loss: 0.950790]\n",
      "epoch:0 step:373 [D loss: 0.727200, acc.: 60.16%] [G loss: 1.024140]\n",
      "epoch:0 step:374 [D loss: 0.744923, acc.: 51.56%] [G loss: 1.033076]\n",
      "epoch:0 step:375 [D loss: 0.773123, acc.: 46.88%] [G loss: 0.981378]\n",
      "epoch:0 step:376 [D loss: 0.887102, acc.: 39.06%] [G loss: 0.862013]\n",
      "epoch:0 step:377 [D loss: 0.792515, acc.: 47.66%] [G loss: 0.913037]\n",
      "epoch:0 step:378 [D loss: 0.746229, acc.: 57.03%] [G loss: 1.060229]\n",
      "epoch:0 step:379 [D loss: 0.709313, acc.: 55.47%] [G loss: 0.964236]\n",
      "epoch:0 step:380 [D loss: 0.778570, acc.: 50.78%] [G loss: 1.065391]\n",
      "epoch:0 step:381 [D loss: 0.670845, acc.: 59.38%] [G loss: 1.100554]\n",
      "epoch:0 step:382 [D loss: 0.725374, acc.: 51.56%] [G loss: 1.106513]\n",
      "epoch:0 step:383 [D loss: 0.779728, acc.: 50.78%] [G loss: 1.070790]\n",
      "epoch:0 step:384 [D loss: 0.698562, acc.: 59.38%] [G loss: 0.926749]\n",
      "epoch:0 step:385 [D loss: 0.820763, acc.: 44.53%] [G loss: 1.143538]\n",
      "epoch:0 step:386 [D loss: 0.766554, acc.: 49.22%] [G loss: 0.987689]\n",
      "epoch:0 step:387 [D loss: 0.761714, acc.: 51.56%] [G loss: 1.337678]\n",
      "epoch:0 step:388 [D loss: 0.740593, acc.: 52.34%] [G loss: 1.203649]\n",
      "epoch:0 step:389 [D loss: 0.716651, acc.: 56.25%] [G loss: 1.169770]\n",
      "epoch:0 step:390 [D loss: 0.752650, acc.: 57.03%] [G loss: 1.034503]\n",
      "epoch:0 step:391 [D loss: 0.760587, acc.: 49.22%] [G loss: 1.085487]\n",
      "epoch:0 step:392 [D loss: 0.738185, acc.: 52.34%] [G loss: 0.936730]\n",
      "epoch:0 step:393 [D loss: 0.764677, acc.: 50.78%] [G loss: 1.149892]\n",
      "epoch:0 step:394 [D loss: 0.753342, acc.: 50.78%] [G loss: 1.020875]\n",
      "epoch:0 step:395 [D loss: 0.703443, acc.: 53.12%] [G loss: 1.143589]\n",
      "epoch:0 step:396 [D loss: 0.749815, acc.: 62.50%] [G loss: 1.110620]\n",
      "epoch:0 step:397 [D loss: 0.727594, acc.: 60.94%] [G loss: 1.008462]\n",
      "epoch:0 step:398 [D loss: 0.687406, acc.: 57.03%] [G loss: 1.086351]\n",
      "epoch:0 step:399 [D loss: 0.602995, acc.: 67.97%] [G loss: 1.101243]\n",
      "epoch:0 step:400 [D loss: 0.735407, acc.: 53.91%] [G loss: 1.101681]\n",
      "epoch:0 step:401 [D loss: 0.745003, acc.: 55.47%] [G loss: 1.058612]\n",
      "epoch:0 step:402 [D loss: 0.647146, acc.: 63.28%] [G loss: 1.260043]\n",
      "epoch:0 step:403 [D loss: 0.718465, acc.: 55.47%] [G loss: 1.067288]\n",
      "epoch:0 step:404 [D loss: 0.724274, acc.: 54.69%] [G loss: 0.952668]\n",
      "epoch:0 step:405 [D loss: 0.678701, acc.: 62.50%] [G loss: 1.113217]\n",
      "epoch:0 step:406 [D loss: 0.635006, acc.: 64.84%] [G loss: 1.147238]\n",
      "epoch:0 step:407 [D loss: 0.674095, acc.: 61.72%] [G loss: 1.132533]\n",
      "epoch:0 step:408 [D loss: 0.702409, acc.: 56.25%] [G loss: 1.018616]\n",
      "epoch:0 step:409 [D loss: 0.647500, acc.: 57.81%] [G loss: 1.008762]\n",
      "epoch:0 step:410 [D loss: 0.753446, acc.: 51.56%] [G loss: 0.956521]\n",
      "epoch:0 step:411 [D loss: 0.742246, acc.: 49.22%] [G loss: 1.065798]\n",
      "epoch:0 step:412 [D loss: 0.695140, acc.: 54.69%] [G loss: 1.058285]\n",
      "epoch:0 step:413 [D loss: 0.704211, acc.: 55.47%] [G loss: 1.037344]\n",
      "epoch:0 step:414 [D loss: 0.678054, acc.: 55.47%] [G loss: 1.042761]\n",
      "epoch:0 step:415 [D loss: 0.747062, acc.: 51.56%] [G loss: 1.010703]\n",
      "epoch:0 step:416 [D loss: 0.669158, acc.: 60.94%] [G loss: 1.100352]\n",
      "epoch:0 step:417 [D loss: 0.809629, acc.: 50.78%] [G loss: 1.033297]\n",
      "epoch:0 step:418 [D loss: 0.662193, acc.: 58.59%] [G loss: 1.068983]\n",
      "epoch:0 step:419 [D loss: 0.792231, acc.: 49.22%] [G loss: 1.142853]\n",
      "epoch:0 step:420 [D loss: 0.730143, acc.: 57.81%] [G loss: 1.015461]\n",
      "epoch:0 step:421 [D loss: 0.746743, acc.: 55.47%] [G loss: 1.109419]\n",
      "epoch:0 step:422 [D loss: 0.757820, acc.: 51.56%] [G loss: 0.951329]\n",
      "epoch:0 step:423 [D loss: 0.784336, acc.: 43.75%] [G loss: 1.041048]\n",
      "epoch:0 step:424 [D loss: 0.740620, acc.: 50.78%] [G loss: 1.050369]\n",
      "epoch:0 step:425 [D loss: 0.715240, acc.: 57.03%] [G loss: 1.176092]\n",
      "epoch:0 step:426 [D loss: 0.730441, acc.: 55.47%] [G loss: 1.127976]\n",
      "epoch:0 step:427 [D loss: 0.738361, acc.: 55.47%] [G loss: 1.099706]\n",
      "epoch:0 step:428 [D loss: 0.712300, acc.: 59.38%] [G loss: 1.111397]\n",
      "epoch:0 step:429 [D loss: 0.701626, acc.: 61.72%] [G loss: 1.051435]\n",
      "epoch:0 step:430 [D loss: 0.710378, acc.: 56.25%] [G loss: 1.180645]\n",
      "epoch:0 step:431 [D loss: 0.741100, acc.: 51.56%] [G loss: 1.132261]\n",
      "epoch:0 step:432 [D loss: 0.824511, acc.: 44.53%] [G loss: 0.947347]\n",
      "epoch:0 step:433 [D loss: 0.675104, acc.: 62.50%] [G loss: 1.065016]\n",
      "epoch:0 step:434 [D loss: 0.657025, acc.: 60.16%] [G loss: 1.090227]\n",
      "epoch:0 step:435 [D loss: 0.768556, acc.: 52.34%] [G loss: 1.108581]\n",
      "epoch:0 step:436 [D loss: 0.680218, acc.: 60.94%] [G loss: 1.065949]\n",
      "epoch:0 step:437 [D loss: 0.846827, acc.: 42.97%] [G loss: 1.102376]\n",
      "epoch:0 step:438 [D loss: 0.806347, acc.: 48.44%] [G loss: 0.873094]\n",
      "epoch:0 step:439 [D loss: 0.767950, acc.: 46.88%] [G loss: 0.889688]\n",
      "epoch:0 step:440 [D loss: 0.656410, acc.: 59.38%] [G loss: 0.892074]\n",
      "epoch:0 step:441 [D loss: 0.740698, acc.: 54.69%] [G loss: 0.984654]\n",
      "epoch:0 step:442 [D loss: 0.677171, acc.: 61.72%] [G loss: 0.981381]\n",
      "epoch:0 step:443 [D loss: 0.649543, acc.: 61.72%] [G loss: 1.124347]\n",
      "epoch:0 step:444 [D loss: 0.756059, acc.: 51.56%] [G loss: 1.069248]\n",
      "epoch:0 step:445 [D loss: 0.706681, acc.: 55.47%] [G loss: 1.142105]\n",
      "epoch:0 step:446 [D loss: 0.835349, acc.: 44.53%] [G loss: 0.953940]\n",
      "epoch:0 step:447 [D loss: 0.684547, acc.: 61.72%] [G loss: 1.076180]\n",
      "epoch:0 step:448 [D loss: 0.754916, acc.: 50.00%] [G loss: 1.123814]\n",
      "epoch:0 step:449 [D loss: 0.747837, acc.: 49.22%] [G loss: 1.101420]\n",
      "epoch:0 step:450 [D loss: 0.739450, acc.: 53.91%] [G loss: 1.132857]\n",
      "epoch:0 step:451 [D loss: 0.707673, acc.: 61.72%] [G loss: 1.093991]\n",
      "epoch:0 step:452 [D loss: 0.738047, acc.: 51.56%] [G loss: 1.175895]\n",
      "epoch:0 step:453 [D loss: 0.686361, acc.: 60.16%] [G loss: 1.253161]\n",
      "epoch:0 step:454 [D loss: 0.839744, acc.: 41.41%] [G loss: 1.040149]\n",
      "epoch:0 step:455 [D loss: 0.733508, acc.: 49.22%] [G loss: 1.149484]\n",
      "epoch:0 step:456 [D loss: 0.715494, acc.: 55.47%] [G loss: 1.149317]\n",
      "epoch:0 step:457 [D loss: 0.695132, acc.: 58.59%] [G loss: 1.116692]\n",
      "epoch:0 step:458 [D loss: 0.935338, acc.: 41.41%] [G loss: 0.899565]\n",
      "epoch:0 step:459 [D loss: 0.773816, acc.: 51.56%] [G loss: 1.070964]\n",
      "epoch:0 step:460 [D loss: 0.788233, acc.: 48.44%] [G loss: 1.027060]\n",
      "epoch:0 step:461 [D loss: 0.775308, acc.: 51.56%] [G loss: 0.932922]\n",
      "epoch:0 step:462 [D loss: 0.643348, acc.: 63.28%] [G loss: 1.057641]\n",
      "epoch:0 step:463 [D loss: 0.687615, acc.: 56.25%] [G loss: 1.000804]\n",
      "epoch:0 step:464 [D loss: 0.665336, acc.: 61.72%] [G loss: 1.185761]\n",
      "epoch:0 step:465 [D loss: 0.754327, acc.: 43.75%] [G loss: 1.113007]\n",
      "epoch:0 step:466 [D loss: 0.760852, acc.: 56.25%] [G loss: 0.973796]\n",
      "epoch:0 step:467 [D loss: 0.777231, acc.: 52.34%] [G loss: 0.986371]\n",
      "epoch:0 step:468 [D loss: 0.805860, acc.: 45.31%] [G loss: 1.045615]\n",
      "epoch:0 step:469 [D loss: 0.784028, acc.: 53.12%] [G loss: 1.006097]\n",
      "epoch:0 step:470 [D loss: 0.731702, acc.: 54.69%] [G loss: 1.038933]\n",
      "epoch:0 step:471 [D loss: 0.750655, acc.: 50.78%] [G loss: 1.193157]\n",
      "epoch:0 step:472 [D loss: 0.712738, acc.: 57.03%] [G loss: 1.016838]\n",
      "epoch:0 step:473 [D loss: 0.746499, acc.: 52.34%] [G loss: 1.004982]\n",
      "epoch:0 step:474 [D loss: 0.710589, acc.: 57.03%] [G loss: 0.983239]\n",
      "epoch:0 step:475 [D loss: 0.760619, acc.: 53.91%] [G loss: 1.110857]\n",
      "epoch:0 step:476 [D loss: 0.778736, acc.: 46.09%] [G loss: 1.026340]\n",
      "epoch:0 step:477 [D loss: 0.843056, acc.: 43.75%] [G loss: 1.060055]\n",
      "epoch:0 step:478 [D loss: 0.771910, acc.: 56.25%] [G loss: 0.961128]\n",
      "epoch:0 step:479 [D loss: 0.694453, acc.: 60.16%] [G loss: 0.962135]\n",
      "epoch:0 step:480 [D loss: 0.669714, acc.: 60.94%] [G loss: 1.035970]\n",
      "epoch:0 step:481 [D loss: 0.727049, acc.: 57.81%] [G loss: 0.934300]\n",
      "epoch:0 step:482 [D loss: 0.741757, acc.: 56.25%] [G loss: 1.053271]\n",
      "epoch:0 step:483 [D loss: 0.703447, acc.: 53.91%] [G loss: 1.195455]\n",
      "epoch:0 step:484 [D loss: 0.677058, acc.: 60.16%] [G loss: 0.995823]\n",
      "epoch:0 step:485 [D loss: 0.597849, acc.: 64.84%] [G loss: 1.001209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:486 [D loss: 0.770296, acc.: 57.81%] [G loss: 1.013245]\n",
      "epoch:0 step:487 [D loss: 0.710029, acc.: 58.59%] [G loss: 1.004858]\n",
      "epoch:0 step:488 [D loss: 0.697986, acc.: 56.25%] [G loss: 1.109075]\n",
      "epoch:0 step:489 [D loss: 0.734945, acc.: 57.03%] [G loss: 1.013147]\n",
      "epoch:0 step:490 [D loss: 0.768823, acc.: 50.78%] [G loss: 1.099359]\n",
      "epoch:0 step:491 [D loss: 0.682658, acc.: 56.25%] [G loss: 0.960268]\n",
      "epoch:0 step:492 [D loss: 0.721643, acc.: 54.69%] [G loss: 1.074366]\n",
      "epoch:0 step:493 [D loss: 0.656185, acc.: 59.38%] [G loss: 1.196626]\n",
      "epoch:0 step:494 [D loss: 0.767021, acc.: 51.56%] [G loss: 0.972330]\n",
      "epoch:0 step:495 [D loss: 0.714624, acc.: 53.91%] [G loss: 1.133984]\n",
      "epoch:0 step:496 [D loss: 0.698927, acc.: 55.47%] [G loss: 0.976843]\n",
      "epoch:0 step:497 [D loss: 0.714946, acc.: 60.16%] [G loss: 1.001500]\n",
      "epoch:0 step:498 [D loss: 0.688194, acc.: 61.72%] [G loss: 1.036833]\n",
      "epoch:0 step:499 [D loss: 0.591923, acc.: 65.62%] [G loss: 1.154380]\n",
      "epoch:0 step:500 [D loss: 0.730140, acc.: 53.91%] [G loss: 1.147607]\n",
      "epoch:0 step:501 [D loss: 0.707035, acc.: 57.03%] [G loss: 0.971051]\n",
      "epoch:0 step:502 [D loss: 0.751509, acc.: 50.78%] [G loss: 0.903357]\n",
      "epoch:0 step:503 [D loss: 0.689473, acc.: 57.03%] [G loss: 0.981937]\n",
      "epoch:0 step:504 [D loss: 0.770322, acc.: 47.66%] [G loss: 1.004856]\n",
      "epoch:0 step:505 [D loss: 0.785905, acc.: 45.31%] [G loss: 1.057828]\n",
      "epoch:0 step:506 [D loss: 0.678435, acc.: 60.16%] [G loss: 1.012260]\n",
      "epoch:0 step:507 [D loss: 0.768710, acc.: 51.56%] [G loss: 1.027476]\n",
      "epoch:0 step:508 [D loss: 0.703897, acc.: 56.25%] [G loss: 0.931965]\n",
      "epoch:0 step:509 [D loss: 0.800651, acc.: 53.91%] [G loss: 1.130384]\n",
      "epoch:0 step:510 [D loss: 0.723270, acc.: 50.78%] [G loss: 1.104114]\n",
      "epoch:0 step:511 [D loss: 0.792587, acc.: 46.88%] [G loss: 1.107162]\n",
      "epoch:0 step:512 [D loss: 0.611677, acc.: 67.19%] [G loss: 1.134750]\n",
      "epoch:0 step:513 [D loss: 0.649857, acc.: 58.59%] [G loss: 1.013092]\n",
      "epoch:0 step:514 [D loss: 0.660136, acc.: 64.06%] [G loss: 1.075326]\n",
      "epoch:0 step:515 [D loss: 0.679095, acc.: 55.47%] [G loss: 1.049231]\n",
      "epoch:0 step:516 [D loss: 0.741282, acc.: 54.69%] [G loss: 0.935956]\n",
      "epoch:0 step:517 [D loss: 0.841677, acc.: 39.84%] [G loss: 0.975899]\n",
      "epoch:0 step:518 [D loss: 0.814931, acc.: 50.00%] [G loss: 0.929387]\n",
      "epoch:0 step:519 [D loss: 0.734542, acc.: 55.47%] [G loss: 1.084152]\n",
      "epoch:0 step:520 [D loss: 0.731919, acc.: 53.12%] [G loss: 1.106961]\n",
      "epoch:0 step:521 [D loss: 0.727931, acc.: 55.47%] [G loss: 0.991054]\n",
      "epoch:0 step:522 [D loss: 0.675050, acc.: 60.16%] [G loss: 1.258011]\n",
      "epoch:0 step:523 [D loss: 0.658564, acc.: 59.38%] [G loss: 1.195631]\n",
      "epoch:0 step:524 [D loss: 0.647576, acc.: 64.84%] [G loss: 1.093786]\n",
      "epoch:0 step:525 [D loss: 0.726333, acc.: 55.47%] [G loss: 1.078839]\n",
      "epoch:0 step:526 [D loss: 0.712870, acc.: 57.81%] [G loss: 1.139496]\n",
      "epoch:0 step:527 [D loss: 0.808347, acc.: 45.31%] [G loss: 1.005529]\n",
      "epoch:0 step:528 [D loss: 0.724606, acc.: 55.47%] [G loss: 1.062908]\n",
      "epoch:0 step:529 [D loss: 0.767103, acc.: 44.53%] [G loss: 1.011993]\n",
      "epoch:0 step:530 [D loss: 0.805949, acc.: 53.12%] [G loss: 0.993302]\n",
      "epoch:0 step:531 [D loss: 0.753448, acc.: 51.56%] [G loss: 0.949111]\n",
      "epoch:0 step:532 [D loss: 0.815463, acc.: 47.66%] [G loss: 0.940791]\n",
      "epoch:0 step:533 [D loss: 0.742368, acc.: 44.53%] [G loss: 1.063920]\n",
      "epoch:0 step:534 [D loss: 0.764384, acc.: 53.12%] [G loss: 1.030496]\n",
      "epoch:0 step:535 [D loss: 0.756894, acc.: 50.78%] [G loss: 1.042506]\n",
      "epoch:0 step:536 [D loss: 0.647903, acc.: 57.81%] [G loss: 1.060691]\n",
      "epoch:0 step:537 [D loss: 0.701367, acc.: 56.25%] [G loss: 1.025908]\n",
      "epoch:0 step:538 [D loss: 0.739960, acc.: 57.03%] [G loss: 1.093777]\n",
      "epoch:0 step:539 [D loss: 0.741467, acc.: 57.03%] [G loss: 1.079350]\n",
      "epoch:0 step:540 [D loss: 0.692907, acc.: 58.59%] [G loss: 1.197929]\n",
      "epoch:0 step:541 [D loss: 0.700175, acc.: 50.78%] [G loss: 1.067381]\n",
      "epoch:0 step:542 [D loss: 0.821382, acc.: 42.97%] [G loss: 0.932770]\n",
      "epoch:0 step:543 [D loss: 0.731685, acc.: 50.00%] [G loss: 0.902870]\n",
      "epoch:0 step:544 [D loss: 0.769207, acc.: 51.56%] [G loss: 0.852248]\n",
      "epoch:0 step:545 [D loss: 0.805979, acc.: 46.88%] [G loss: 0.942798]\n",
      "epoch:0 step:546 [D loss: 0.687190, acc.: 59.38%] [G loss: 0.909912]\n",
      "epoch:0 step:547 [D loss: 0.688661, acc.: 54.69%] [G loss: 1.064110]\n",
      "epoch:0 step:548 [D loss: 0.742818, acc.: 54.69%] [G loss: 0.972429]\n",
      "epoch:0 step:549 [D loss: 0.750718, acc.: 54.69%] [G loss: 1.058519]\n",
      "epoch:0 step:550 [D loss: 0.679921, acc.: 58.59%] [G loss: 1.090916]\n",
      "epoch:0 step:551 [D loss: 0.681192, acc.: 60.16%] [G loss: 0.988384]\n",
      "epoch:0 step:552 [D loss: 0.755396, acc.: 50.78%] [G loss: 1.030687]\n",
      "epoch:0 step:553 [D loss: 0.724285, acc.: 52.34%] [G loss: 1.046004]\n",
      "epoch:0 step:554 [D loss: 0.731668, acc.: 55.47%] [G loss: 1.058979]\n",
      "epoch:0 step:555 [D loss: 0.721568, acc.: 57.03%] [G loss: 1.111321]\n",
      "epoch:0 step:556 [D loss: 0.748286, acc.: 55.47%] [G loss: 1.014424]\n",
      "epoch:0 step:557 [D loss: 0.736458, acc.: 55.47%] [G loss: 0.990065]\n",
      "epoch:0 step:558 [D loss: 0.699987, acc.: 53.91%] [G loss: 1.016332]\n",
      "epoch:0 step:559 [D loss: 0.759524, acc.: 50.78%] [G loss: 1.126912]\n",
      "epoch:0 step:560 [D loss: 0.785149, acc.: 45.31%] [G loss: 0.977091]\n",
      "epoch:0 step:561 [D loss: 0.781937, acc.: 48.44%] [G loss: 1.016965]\n",
      "epoch:0 step:562 [D loss: 0.774279, acc.: 46.09%] [G loss: 1.148955]\n",
      "epoch:0 step:563 [D loss: 0.778180, acc.: 46.88%] [G loss: 1.032819]\n",
      "epoch:0 step:564 [D loss: 0.753328, acc.: 56.25%] [G loss: 0.981778]\n",
      "epoch:0 step:565 [D loss: 0.733290, acc.: 51.56%] [G loss: 0.974427]\n",
      "epoch:0 step:566 [D loss: 0.778647, acc.: 48.44%] [G loss: 0.976091]\n",
      "epoch:0 step:567 [D loss: 0.680600, acc.: 55.47%] [G loss: 1.087277]\n",
      "epoch:0 step:568 [D loss: 0.761555, acc.: 50.00%] [G loss: 1.091866]\n",
      "epoch:0 step:569 [D loss: 0.784620, acc.: 47.66%] [G loss: 1.009585]\n",
      "epoch:0 step:570 [D loss: 0.732551, acc.: 53.12%] [G loss: 1.006845]\n",
      "epoch:0 step:571 [D loss: 0.753613, acc.: 50.78%] [G loss: 1.108576]\n",
      "epoch:0 step:572 [D loss: 0.813128, acc.: 42.97%] [G loss: 1.066940]\n",
      "epoch:0 step:573 [D loss: 0.747043, acc.: 50.00%] [G loss: 0.988016]\n",
      "epoch:0 step:574 [D loss: 0.668674, acc.: 56.25%] [G loss: 0.945267]\n",
      "epoch:0 step:575 [D loss: 0.696649, acc.: 53.91%] [G loss: 0.853334]\n",
      "epoch:0 step:576 [D loss: 0.847125, acc.: 43.75%] [G loss: 1.007100]\n",
      "epoch:0 step:577 [D loss: 0.772662, acc.: 46.09%] [G loss: 0.976454]\n",
      "epoch:0 step:578 [D loss: 0.762227, acc.: 52.34%] [G loss: 1.087715]\n",
      "epoch:0 step:579 [D loss: 0.743160, acc.: 50.00%] [G loss: 1.080814]\n",
      "epoch:0 step:580 [D loss: 0.776001, acc.: 50.78%] [G loss: 1.108177]\n",
      "epoch:0 step:581 [D loss: 0.744018, acc.: 53.91%] [G loss: 0.994868]\n",
      "epoch:0 step:582 [D loss: 0.733368, acc.: 53.12%] [G loss: 0.994828]\n",
      "epoch:0 step:583 [D loss: 0.695159, acc.: 62.50%] [G loss: 0.958573]\n",
      "epoch:0 step:584 [D loss: 0.749578, acc.: 49.22%] [G loss: 0.964663]\n",
      "epoch:0 step:585 [D loss: 0.648980, acc.: 64.84%] [G loss: 0.930818]\n",
      "epoch:0 step:586 [D loss: 0.698447, acc.: 58.59%] [G loss: 1.040269]\n",
      "epoch:0 step:587 [D loss: 0.673439, acc.: 58.59%] [G loss: 1.013408]\n",
      "epoch:0 step:588 [D loss: 0.625604, acc.: 64.84%] [G loss: 1.141623]\n",
      "epoch:0 step:589 [D loss: 0.653438, acc.: 60.16%] [G loss: 1.119335]\n",
      "epoch:0 step:590 [D loss: 0.726965, acc.: 54.69%] [G loss: 1.140315]\n",
      "epoch:0 step:591 [D loss: 0.781161, acc.: 47.66%] [G loss: 0.927543]\n",
      "epoch:0 step:592 [D loss: 0.770629, acc.: 52.34%] [G loss: 0.989289]\n",
      "epoch:0 step:593 [D loss: 0.696684, acc.: 57.03%] [G loss: 1.087337]\n",
      "epoch:0 step:594 [D loss: 0.732680, acc.: 55.47%] [G loss: 0.987559]\n",
      "epoch:0 step:595 [D loss: 0.742857, acc.: 50.00%] [G loss: 0.949338]\n",
      "epoch:0 step:596 [D loss: 0.666018, acc.: 61.72%] [G loss: 1.032666]\n",
      "epoch:0 step:597 [D loss: 0.761795, acc.: 50.00%] [G loss: 0.972890]\n",
      "epoch:0 step:598 [D loss: 0.714784, acc.: 50.78%] [G loss: 1.070352]\n",
      "epoch:0 step:599 [D loss: 0.724067, acc.: 53.12%] [G loss: 0.968944]\n",
      "epoch:0 step:600 [D loss: 0.747696, acc.: 48.44%] [G loss: 0.958426]\n",
      "epoch:0 step:601 [D loss: 0.681084, acc.: 54.69%] [G loss: 0.960889]\n",
      "epoch:0 step:602 [D loss: 0.685384, acc.: 54.69%] [G loss: 1.028176]\n",
      "epoch:0 step:603 [D loss: 0.666101, acc.: 54.69%] [G loss: 1.020441]\n",
      "epoch:0 step:604 [D loss: 0.722081, acc.: 52.34%] [G loss: 1.039514]\n",
      "epoch:0 step:605 [D loss: 0.723495, acc.: 53.91%] [G loss: 0.919755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:606 [D loss: 0.690672, acc.: 58.59%] [G loss: 1.032324]\n",
      "epoch:0 step:607 [D loss: 0.739954, acc.: 54.69%] [G loss: 1.049167]\n",
      "epoch:0 step:608 [D loss: 0.735361, acc.: 53.12%] [G loss: 0.954872]\n",
      "epoch:0 step:609 [D loss: 0.653945, acc.: 58.59%] [G loss: 0.941456]\n",
      "epoch:0 step:610 [D loss: 0.681436, acc.: 57.81%] [G loss: 1.055338]\n",
      "epoch:0 step:611 [D loss: 0.751501, acc.: 52.34%] [G loss: 1.033373]\n",
      "epoch:0 step:612 [D loss: 0.728150, acc.: 60.16%] [G loss: 1.005265]\n",
      "epoch:0 step:613 [D loss: 0.703935, acc.: 58.59%] [G loss: 1.007315]\n",
      "epoch:0 step:614 [D loss: 0.700214, acc.: 55.47%] [G loss: 1.038821]\n",
      "epoch:0 step:615 [D loss: 0.812688, acc.: 46.88%] [G loss: 0.920942]\n",
      "epoch:0 step:616 [D loss: 0.787716, acc.: 42.19%] [G loss: 0.941258]\n",
      "epoch:0 step:617 [D loss: 0.720648, acc.: 60.16%] [G loss: 0.897846]\n",
      "epoch:0 step:618 [D loss: 0.773660, acc.: 49.22%] [G loss: 0.850233]\n",
      "epoch:0 step:619 [D loss: 0.691800, acc.: 57.03%] [G loss: 1.001484]\n",
      "epoch:0 step:620 [D loss: 0.774327, acc.: 47.66%] [G loss: 0.980442]\n",
      "epoch:0 step:621 [D loss: 0.773370, acc.: 47.66%] [G loss: 0.960402]\n",
      "epoch:0 step:622 [D loss: 0.714032, acc.: 52.34%] [G loss: 0.864004]\n",
      "epoch:0 step:623 [D loss: 0.741662, acc.: 51.56%] [G loss: 0.929654]\n",
      "epoch:0 step:624 [D loss: 0.759526, acc.: 46.88%] [G loss: 0.982685]\n",
      "epoch:0 step:625 [D loss: 0.730545, acc.: 53.91%] [G loss: 1.142179]\n",
      "epoch:0 step:626 [D loss: 0.776411, acc.: 48.44%] [G loss: 1.129289]\n",
      "epoch:0 step:627 [D loss: 0.710238, acc.: 54.69%] [G loss: 1.075561]\n",
      "epoch:0 step:628 [D loss: 0.726092, acc.: 53.91%] [G loss: 0.969892]\n",
      "epoch:0 step:629 [D loss: 0.702352, acc.: 51.56%] [G loss: 0.944098]\n",
      "epoch:0 step:630 [D loss: 0.721217, acc.: 56.25%] [G loss: 0.998747]\n",
      "epoch:0 step:631 [D loss: 0.634352, acc.: 63.28%] [G loss: 1.055533]\n",
      "epoch:0 step:632 [D loss: 0.733333, acc.: 53.12%] [G loss: 0.973749]\n",
      "epoch:0 step:633 [D loss: 0.699019, acc.: 53.91%] [G loss: 0.892569]\n",
      "epoch:0 step:634 [D loss: 0.717803, acc.: 52.34%] [G loss: 1.124236]\n",
      "epoch:0 step:635 [D loss: 0.654878, acc.: 61.72%] [G loss: 1.121336]\n",
      "epoch:0 step:636 [D loss: 0.742095, acc.: 52.34%] [G loss: 1.032558]\n",
      "epoch:0 step:637 [D loss: 0.741184, acc.: 50.00%] [G loss: 1.132093]\n",
      "epoch:0 step:638 [D loss: 0.721719, acc.: 50.78%] [G loss: 1.076227]\n",
      "epoch:0 step:639 [D loss: 0.660843, acc.: 62.50%] [G loss: 1.038477]\n",
      "epoch:0 step:640 [D loss: 0.693254, acc.: 60.94%] [G loss: 1.049355]\n",
      "epoch:0 step:641 [D loss: 0.694944, acc.: 53.91%] [G loss: 1.041642]\n",
      "epoch:0 step:642 [D loss: 0.638512, acc.: 63.28%] [G loss: 1.094955]\n",
      "epoch:0 step:643 [D loss: 0.728137, acc.: 55.47%] [G loss: 1.134298]\n",
      "epoch:0 step:644 [D loss: 0.714249, acc.: 53.12%] [G loss: 1.022037]\n",
      "epoch:0 step:645 [D loss: 0.745928, acc.: 50.78%] [G loss: 0.929197]\n",
      "epoch:0 step:646 [D loss: 0.686092, acc.: 57.03%] [G loss: 1.019392]\n",
      "epoch:0 step:647 [D loss: 0.692606, acc.: 60.94%] [G loss: 1.107012]\n",
      "epoch:0 step:648 [D loss: 0.662695, acc.: 60.94%] [G loss: 1.053638]\n",
      "epoch:0 step:649 [D loss: 0.700763, acc.: 57.03%] [G loss: 0.978726]\n",
      "epoch:0 step:650 [D loss: 0.699284, acc.: 57.81%] [G loss: 1.004094]\n",
      "epoch:0 step:651 [D loss: 0.662675, acc.: 57.81%] [G loss: 0.891951]\n",
      "epoch:0 step:652 [D loss: 0.704299, acc.: 57.81%] [G loss: 1.020451]\n",
      "epoch:0 step:653 [D loss: 0.723376, acc.: 53.12%] [G loss: 0.985406]\n",
      "epoch:0 step:654 [D loss: 0.773834, acc.: 51.56%] [G loss: 0.929053]\n",
      "epoch:0 step:655 [D loss: 0.751985, acc.: 55.47%] [G loss: 0.917169]\n",
      "epoch:0 step:656 [D loss: 0.699824, acc.: 60.16%] [G loss: 0.994238]\n",
      "epoch:0 step:657 [D loss: 0.787712, acc.: 46.88%] [G loss: 1.010527]\n",
      "epoch:0 step:658 [D loss: 0.785657, acc.: 44.53%] [G loss: 1.002116]\n",
      "epoch:0 step:659 [D loss: 0.774719, acc.: 46.88%] [G loss: 0.991802]\n",
      "epoch:0 step:660 [D loss: 0.652555, acc.: 63.28%] [G loss: 0.964130]\n",
      "epoch:0 step:661 [D loss: 0.729561, acc.: 50.00%] [G loss: 0.966765]\n",
      "epoch:0 step:662 [D loss: 0.753114, acc.: 57.03%] [G loss: 1.024103]\n",
      "epoch:0 step:663 [D loss: 0.793202, acc.: 49.22%] [G loss: 1.045523]\n",
      "epoch:0 step:664 [D loss: 0.624709, acc.: 67.19%] [G loss: 1.109887]\n",
      "epoch:0 step:665 [D loss: 0.724683, acc.: 54.69%] [G loss: 1.110248]\n",
      "epoch:0 step:666 [D loss: 0.676070, acc.: 57.81%] [G loss: 1.137244]\n",
      "epoch:0 step:667 [D loss: 0.744415, acc.: 53.12%] [G loss: 1.014687]\n",
      "epoch:0 step:668 [D loss: 0.754115, acc.: 53.91%] [G loss: 1.050164]\n",
      "epoch:0 step:669 [D loss: 0.731212, acc.: 57.03%] [G loss: 1.018531]\n",
      "epoch:0 step:670 [D loss: 0.699246, acc.: 54.69%] [G loss: 0.961558]\n",
      "epoch:0 step:671 [D loss: 0.655348, acc.: 62.50%] [G loss: 1.049466]\n",
      "epoch:0 step:672 [D loss: 0.673488, acc.: 59.38%] [G loss: 1.012383]\n",
      "epoch:0 step:673 [D loss: 0.798037, acc.: 49.22%] [G loss: 0.865674]\n",
      "epoch:0 step:674 [D loss: 0.741852, acc.: 55.47%] [G loss: 1.001164]\n",
      "epoch:0 step:675 [D loss: 0.735606, acc.: 53.12%] [G loss: 1.043150]\n",
      "epoch:0 step:676 [D loss: 0.700057, acc.: 60.16%] [G loss: 0.924684]\n",
      "epoch:0 step:677 [D loss: 0.687339, acc.: 55.47%] [G loss: 1.013887]\n",
      "epoch:0 step:678 [D loss: 0.651522, acc.: 57.81%] [G loss: 1.128536]\n",
      "epoch:0 step:679 [D loss: 0.691433, acc.: 58.59%] [G loss: 1.086439]\n",
      "epoch:0 step:680 [D loss: 0.711703, acc.: 55.47%] [G loss: 1.001517]\n",
      "epoch:0 step:681 [D loss: 0.770461, acc.: 46.09%] [G loss: 1.006192]\n",
      "epoch:0 step:682 [D loss: 0.710303, acc.: 53.12%] [G loss: 0.952869]\n",
      "epoch:0 step:683 [D loss: 0.739890, acc.: 53.12%] [G loss: 1.085011]\n",
      "epoch:0 step:684 [D loss: 0.731124, acc.: 53.91%] [G loss: 0.827987]\n",
      "epoch:0 step:685 [D loss: 0.800725, acc.: 42.19%] [G loss: 0.985123]\n",
      "epoch:0 step:686 [D loss: 0.748681, acc.: 47.66%] [G loss: 1.082554]\n",
      "epoch:0 step:687 [D loss: 0.711476, acc.: 55.47%] [G loss: 0.951341]\n",
      "epoch:0 step:688 [D loss: 0.725734, acc.: 53.12%] [G loss: 0.942686]\n",
      "epoch:0 step:689 [D loss: 0.753140, acc.: 47.66%] [G loss: 1.063508]\n",
      "epoch:0 step:690 [D loss: 0.771523, acc.: 46.09%] [G loss: 0.945450]\n",
      "epoch:0 step:691 [D loss: 0.737033, acc.: 50.00%] [G loss: 1.069299]\n",
      "epoch:0 step:692 [D loss: 0.768838, acc.: 50.78%] [G loss: 1.068495]\n",
      "epoch:0 step:693 [D loss: 0.665986, acc.: 60.16%] [G loss: 1.117679]\n",
      "epoch:0 step:694 [D loss: 0.674476, acc.: 57.81%] [G loss: 1.025128]\n",
      "epoch:0 step:695 [D loss: 0.712634, acc.: 56.25%] [G loss: 0.979844]\n",
      "epoch:0 step:696 [D loss: 0.778068, acc.: 46.88%] [G loss: 0.910885]\n",
      "epoch:0 step:697 [D loss: 0.725563, acc.: 54.69%] [G loss: 1.068759]\n",
      "epoch:0 step:698 [D loss: 0.737942, acc.: 47.66%] [G loss: 0.994817]\n",
      "epoch:0 step:699 [D loss: 0.657286, acc.: 57.81%] [G loss: 1.049333]\n",
      "epoch:0 step:700 [D loss: 0.655031, acc.: 56.25%] [G loss: 0.991593]\n",
      "epoch:0 step:701 [D loss: 0.728948, acc.: 56.25%] [G loss: 1.106659]\n",
      "epoch:0 step:702 [D loss: 0.773163, acc.: 44.53%] [G loss: 0.902304]\n",
      "epoch:0 step:703 [D loss: 0.772504, acc.: 47.66%] [G loss: 0.997692]\n",
      "epoch:0 step:704 [D loss: 0.824337, acc.: 43.75%] [G loss: 0.930338]\n",
      "epoch:0 step:705 [D loss: 0.738325, acc.: 50.00%] [G loss: 0.984839]\n",
      "epoch:0 step:706 [D loss: 0.761381, acc.: 51.56%] [G loss: 1.161975]\n",
      "epoch:0 step:707 [D loss: 0.689193, acc.: 58.59%] [G loss: 0.912538]\n",
      "epoch:0 step:708 [D loss: 0.630396, acc.: 64.06%] [G loss: 1.091521]\n",
      "epoch:0 step:709 [D loss: 0.695442, acc.: 60.16%] [G loss: 0.969321]\n",
      "epoch:0 step:710 [D loss: 0.809004, acc.: 44.53%] [G loss: 1.019920]\n",
      "epoch:0 step:711 [D loss: 0.723680, acc.: 53.12%] [G loss: 0.974634]\n",
      "epoch:0 step:712 [D loss: 0.703019, acc.: 54.69%] [G loss: 0.964837]\n",
      "epoch:0 step:713 [D loss: 0.813892, acc.: 46.09%] [G loss: 0.916708]\n",
      "epoch:0 step:714 [D loss: 0.700680, acc.: 57.81%] [G loss: 0.980123]\n",
      "epoch:0 step:715 [D loss: 0.693766, acc.: 62.50%] [G loss: 0.937334]\n",
      "epoch:0 step:716 [D loss: 0.735697, acc.: 53.91%] [G loss: 1.017873]\n",
      "epoch:0 step:717 [D loss: 0.680950, acc.: 61.72%] [G loss: 0.931541]\n",
      "epoch:0 step:718 [D loss: 0.733266, acc.: 52.34%] [G loss: 0.994588]\n",
      "epoch:0 step:719 [D loss: 0.658591, acc.: 60.16%] [G loss: 1.045747]\n",
      "epoch:0 step:720 [D loss: 0.786266, acc.: 48.44%] [G loss: 1.160518]\n",
      "epoch:0 step:721 [D loss: 0.779502, acc.: 48.44%] [G loss: 1.014989]\n",
      "epoch:0 step:722 [D loss: 0.754780, acc.: 50.78%] [G loss: 0.918037]\n",
      "epoch:0 step:723 [D loss: 0.774938, acc.: 45.31%] [G loss: 1.025187]\n",
      "epoch:0 step:724 [D loss: 0.740105, acc.: 50.00%] [G loss: 0.951612]\n",
      "epoch:0 step:725 [D loss: 0.781271, acc.: 49.22%] [G loss: 1.064080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:726 [D loss: 0.784009, acc.: 44.53%] [G loss: 0.992834]\n",
      "epoch:0 step:727 [D loss: 0.762614, acc.: 50.00%] [G loss: 1.014307]\n",
      "epoch:0 step:728 [D loss: 0.762690, acc.: 46.88%] [G loss: 1.020699]\n",
      "epoch:0 step:729 [D loss: 0.744854, acc.: 55.47%] [G loss: 0.923317]\n",
      "epoch:0 step:730 [D loss: 0.827096, acc.: 43.75%] [G loss: 0.899541]\n",
      "epoch:0 step:731 [D loss: 0.811710, acc.: 45.31%] [G loss: 0.855602]\n",
      "epoch:0 step:732 [D loss: 0.699031, acc.: 50.78%] [G loss: 1.026181]\n",
      "epoch:0 step:733 [D loss: 0.675657, acc.: 64.06%] [G loss: 1.107848]\n",
      "epoch:0 step:734 [D loss: 0.723744, acc.: 53.91%] [G loss: 1.154281]\n",
      "epoch:0 step:735 [D loss: 0.750567, acc.: 51.56%] [G loss: 1.077902]\n",
      "epoch:0 step:736 [D loss: 0.711301, acc.: 57.03%] [G loss: 1.107206]\n",
      "epoch:0 step:737 [D loss: 0.715341, acc.: 55.47%] [G loss: 0.931444]\n",
      "epoch:0 step:738 [D loss: 0.699700, acc.: 60.94%] [G loss: 1.059699]\n",
      "epoch:0 step:739 [D loss: 0.809011, acc.: 43.75%] [G loss: 0.941661]\n",
      "epoch:0 step:740 [D loss: 0.740997, acc.: 51.56%] [G loss: 0.903754]\n",
      "epoch:0 step:741 [D loss: 0.744164, acc.: 49.22%] [G loss: 0.950702]\n",
      "epoch:0 step:742 [D loss: 0.774461, acc.: 46.09%] [G loss: 0.943305]\n",
      "epoch:0 step:743 [D loss: 0.694345, acc.: 60.16%] [G loss: 0.954390]\n",
      "epoch:0 step:744 [D loss: 0.723853, acc.: 52.34%] [G loss: 0.903632]\n",
      "epoch:0 step:745 [D loss: 0.697634, acc.: 57.03%] [G loss: 1.029905]\n",
      "epoch:0 step:746 [D loss: 0.692818, acc.: 57.81%] [G loss: 0.993122]\n",
      "epoch:0 step:747 [D loss: 0.657669, acc.: 60.94%] [G loss: 1.018534]\n",
      "epoch:0 step:748 [D loss: 0.710929, acc.: 54.69%] [G loss: 1.079281]\n",
      "epoch:0 step:749 [D loss: 0.763086, acc.: 50.00%] [G loss: 0.981932]\n",
      "epoch:0 step:750 [D loss: 0.764248, acc.: 52.34%] [G loss: 0.965171]\n",
      "epoch:0 step:751 [D loss: 0.695394, acc.: 54.69%] [G loss: 0.975483]\n",
      "epoch:0 step:752 [D loss: 0.779238, acc.: 52.34%] [G loss: 0.905224]\n",
      "epoch:0 step:753 [D loss: 0.740705, acc.: 54.69%] [G loss: 1.000170]\n",
      "epoch:0 step:754 [D loss: 0.725605, acc.: 54.69%] [G loss: 1.063134]\n",
      "epoch:0 step:755 [D loss: 0.783350, acc.: 46.88%] [G loss: 0.950433]\n",
      "epoch:0 step:756 [D loss: 0.736526, acc.: 48.44%] [G loss: 0.980115]\n",
      "epoch:0 step:757 [D loss: 0.738701, acc.: 52.34%] [G loss: 0.939390]\n",
      "epoch:0 step:758 [D loss: 0.741220, acc.: 49.22%] [G loss: 1.070311]\n",
      "epoch:0 step:759 [D loss: 0.728769, acc.: 54.69%] [G loss: 1.006829]\n",
      "epoch:0 step:760 [D loss: 0.767460, acc.: 46.88%] [G loss: 1.011225]\n",
      "epoch:0 step:761 [D loss: 0.754657, acc.: 49.22%] [G loss: 1.048149]\n",
      "epoch:0 step:762 [D loss: 0.757370, acc.: 50.00%] [G loss: 0.967804]\n",
      "epoch:0 step:763 [D loss: 0.727780, acc.: 51.56%] [G loss: 1.027017]\n",
      "epoch:0 step:764 [D loss: 0.776656, acc.: 50.00%] [G loss: 0.958026]\n",
      "epoch:0 step:765 [D loss: 0.763832, acc.: 50.00%] [G loss: 0.986418]\n",
      "epoch:0 step:766 [D loss: 0.788074, acc.: 46.88%] [G loss: 0.933317]\n",
      "epoch:0 step:767 [D loss: 0.769108, acc.: 46.88%] [G loss: 0.909229]\n",
      "epoch:0 step:768 [D loss: 0.732098, acc.: 56.25%] [G loss: 0.968448]\n",
      "epoch:0 step:769 [D loss: 0.750614, acc.: 50.78%] [G loss: 1.044281]\n",
      "epoch:0 step:770 [D loss: 0.736891, acc.: 52.34%] [G loss: 0.887156]\n",
      "epoch:0 step:771 [D loss: 0.722346, acc.: 55.47%] [G loss: 0.943676]\n",
      "epoch:0 step:772 [D loss: 0.702895, acc.: 52.34%] [G loss: 1.038040]\n",
      "epoch:0 step:773 [D loss: 0.747850, acc.: 51.56%] [G loss: 0.881032]\n",
      "epoch:0 step:774 [D loss: 0.788912, acc.: 50.00%] [G loss: 0.864333]\n",
      "epoch:0 step:775 [D loss: 0.706680, acc.: 57.81%] [G loss: 1.121692]\n",
      "epoch:0 step:776 [D loss: 0.664168, acc.: 62.50%] [G loss: 1.089360]\n",
      "epoch:0 step:777 [D loss: 0.659688, acc.: 63.28%] [G loss: 1.053747]\n",
      "epoch:0 step:778 [D loss: 0.739894, acc.: 51.56%] [G loss: 0.979426]\n",
      "epoch:0 step:779 [D loss: 0.752122, acc.: 52.34%] [G loss: 0.981690]\n",
      "epoch:0 step:780 [D loss: 0.701577, acc.: 53.12%] [G loss: 0.993381]\n",
      "epoch:0 step:781 [D loss: 0.828768, acc.: 42.97%] [G loss: 0.944233]\n",
      "epoch:0 step:782 [D loss: 0.775943, acc.: 48.44%] [G loss: 0.970810]\n",
      "epoch:0 step:783 [D loss: 0.719030, acc.: 51.56%] [G loss: 0.974213]\n",
      "epoch:0 step:784 [D loss: 0.746236, acc.: 54.69%] [G loss: 0.949707]\n",
      "epoch:0 step:785 [D loss: 0.723092, acc.: 53.12%] [G loss: 0.953275]\n",
      "epoch:0 step:786 [D loss: 0.675428, acc.: 61.72%] [G loss: 1.021890]\n",
      "epoch:0 step:787 [D loss: 0.726105, acc.: 58.59%] [G loss: 1.044428]\n",
      "epoch:0 step:788 [D loss: 0.765816, acc.: 43.75%] [G loss: 0.853585]\n",
      "epoch:0 step:789 [D loss: 0.776270, acc.: 49.22%] [G loss: 0.831839]\n",
      "epoch:0 step:790 [D loss: 0.707226, acc.: 53.91%] [G loss: 0.939687]\n",
      "epoch:0 step:791 [D loss: 0.751077, acc.: 44.53%] [G loss: 0.964787]\n",
      "epoch:0 step:792 [D loss: 0.713948, acc.: 57.81%] [G loss: 1.103156]\n",
      "epoch:0 step:793 [D loss: 0.741489, acc.: 53.12%] [G loss: 0.940441]\n",
      "epoch:0 step:794 [D loss: 0.756786, acc.: 50.78%] [G loss: 1.008517]\n",
      "epoch:0 step:795 [D loss: 0.773918, acc.: 47.66%] [G loss: 0.835726]\n",
      "epoch:0 step:796 [D loss: 0.663499, acc.: 62.50%] [G loss: 0.992156]\n",
      "epoch:0 step:797 [D loss: 0.726174, acc.: 55.47%] [G loss: 0.945912]\n",
      "epoch:0 step:798 [D loss: 0.736697, acc.: 51.56%] [G loss: 0.900181]\n",
      "epoch:0 step:799 [D loss: 0.738389, acc.: 46.09%] [G loss: 0.949193]\n",
      "epoch:0 step:800 [D loss: 0.693296, acc.: 57.03%] [G loss: 0.965588]\n",
      "epoch:0 step:801 [D loss: 0.776198, acc.: 49.22%] [G loss: 0.860630]\n",
      "epoch:0 step:802 [D loss: 0.727935, acc.: 52.34%] [G loss: 0.930368]\n",
      "epoch:0 step:803 [D loss: 0.791145, acc.: 44.53%] [G loss: 0.882944]\n",
      "epoch:0 step:804 [D loss: 0.698037, acc.: 61.72%] [G loss: 0.990416]\n",
      "epoch:0 step:805 [D loss: 0.704590, acc.: 57.03%] [G loss: 0.945851]\n",
      "epoch:0 step:806 [D loss: 0.685906, acc.: 60.94%] [G loss: 1.011071]\n",
      "epoch:0 step:807 [D loss: 0.682404, acc.: 61.72%] [G loss: 1.027455]\n",
      "epoch:0 step:808 [D loss: 0.752717, acc.: 50.78%] [G loss: 0.987118]\n",
      "epoch:0 step:809 [D loss: 0.717151, acc.: 48.44%] [G loss: 0.983175]\n",
      "epoch:0 step:810 [D loss: 0.760471, acc.: 48.44%] [G loss: 0.973833]\n",
      "epoch:0 step:811 [D loss: 0.724324, acc.: 56.25%] [G loss: 0.969870]\n",
      "epoch:0 step:812 [D loss: 0.697662, acc.: 56.25%] [G loss: 0.903156]\n",
      "epoch:0 step:813 [D loss: 0.683697, acc.: 62.50%] [G loss: 0.994399]\n",
      "epoch:0 step:814 [D loss: 0.731087, acc.: 53.91%] [G loss: 0.921596]\n",
      "epoch:0 step:815 [D loss: 0.708536, acc.: 51.56%] [G loss: 0.955385]\n",
      "epoch:0 step:816 [D loss: 0.685737, acc.: 58.59%] [G loss: 1.026934]\n",
      "epoch:0 step:817 [D loss: 0.721213, acc.: 53.91%] [G loss: 1.024124]\n",
      "epoch:0 step:818 [D loss: 0.701144, acc.: 62.50%] [G loss: 0.997527]\n",
      "epoch:0 step:819 [D loss: 0.668384, acc.: 62.50%] [G loss: 1.001885]\n",
      "epoch:0 step:820 [D loss: 0.809336, acc.: 46.88%] [G loss: 0.996874]\n",
      "epoch:0 step:821 [D loss: 0.734026, acc.: 50.78%] [G loss: 0.955350]\n",
      "epoch:0 step:822 [D loss: 0.654946, acc.: 57.03%] [G loss: 1.092549]\n",
      "epoch:0 step:823 [D loss: 0.675533, acc.: 60.94%] [G loss: 0.979673]\n",
      "epoch:0 step:824 [D loss: 0.690149, acc.: 56.25%] [G loss: 1.039296]\n",
      "epoch:0 step:825 [D loss: 0.653865, acc.: 61.72%] [G loss: 1.079878]\n",
      "epoch:0 step:826 [D loss: 0.740736, acc.: 53.91%] [G loss: 0.905364]\n",
      "epoch:0 step:827 [D loss: 0.692940, acc.: 58.59%] [G loss: 0.895032]\n",
      "epoch:0 step:828 [D loss: 0.758459, acc.: 52.34%] [G loss: 1.051066]\n",
      "epoch:0 step:829 [D loss: 0.816253, acc.: 45.31%] [G loss: 0.990488]\n",
      "epoch:0 step:830 [D loss: 0.694129, acc.: 55.47%] [G loss: 0.973073]\n",
      "epoch:0 step:831 [D loss: 0.732370, acc.: 49.22%] [G loss: 1.013247]\n",
      "epoch:0 step:832 [D loss: 0.779721, acc.: 46.88%] [G loss: 0.935068]\n",
      "epoch:0 step:833 [D loss: 0.709427, acc.: 59.38%] [G loss: 1.026023]\n",
      "epoch:0 step:834 [D loss: 0.702669, acc.: 52.34%] [G loss: 0.950259]\n",
      "epoch:0 step:835 [D loss: 0.697663, acc.: 58.59%] [G loss: 1.001909]\n",
      "epoch:0 step:836 [D loss: 0.724636, acc.: 52.34%] [G loss: 1.028047]\n",
      "epoch:0 step:837 [D loss: 0.794026, acc.: 50.78%] [G loss: 0.878305]\n",
      "epoch:0 step:838 [D loss: 0.674395, acc.: 56.25%] [G loss: 0.956769]\n",
      "epoch:0 step:839 [D loss: 0.727083, acc.: 53.91%] [G loss: 1.071823]\n",
      "epoch:0 step:840 [D loss: 0.745619, acc.: 48.44%] [G loss: 0.975957]\n",
      "epoch:0 step:841 [D loss: 0.740961, acc.: 52.34%] [G loss: 1.041451]\n",
      "epoch:0 step:842 [D loss: 0.659548, acc.: 59.38%] [G loss: 1.028210]\n",
      "epoch:0 step:843 [D loss: 0.820909, acc.: 41.41%] [G loss: 0.979766]\n",
      "epoch:0 step:844 [D loss: 0.746656, acc.: 52.34%] [G loss: 0.969527]\n",
      "epoch:0 step:845 [D loss: 0.818518, acc.: 44.53%] [G loss: 0.928938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:846 [D loss: 0.746474, acc.: 50.00%] [G loss: 1.022686]\n",
      "epoch:0 step:847 [D loss: 0.771156, acc.: 46.09%] [G loss: 0.899812]\n",
      "epoch:0 step:848 [D loss: 0.746438, acc.: 49.22%] [G loss: 0.909673]\n",
      "epoch:0 step:849 [D loss: 0.692255, acc.: 59.38%] [G loss: 0.920322]\n",
      "epoch:0 step:850 [D loss: 0.748468, acc.: 51.56%] [G loss: 1.028398]\n",
      "epoch:0 step:851 [D loss: 0.814027, acc.: 45.31%] [G loss: 0.956552]\n",
      "epoch:0 step:852 [D loss: 0.744543, acc.: 50.78%] [G loss: 0.954796]\n",
      "epoch:0 step:853 [D loss: 0.775431, acc.: 46.88%] [G loss: 0.882979]\n",
      "epoch:0 step:854 [D loss: 0.712702, acc.: 55.47%] [G loss: 0.894505]\n",
      "epoch:0 step:855 [D loss: 0.701088, acc.: 52.34%] [G loss: 1.000915]\n",
      "epoch:0 step:856 [D loss: 0.756080, acc.: 51.56%] [G loss: 0.978879]\n",
      "epoch:0 step:857 [D loss: 0.743307, acc.: 50.00%] [G loss: 0.908830]\n",
      "epoch:0 step:858 [D loss: 0.798197, acc.: 42.97%] [G loss: 0.842175]\n",
      "epoch:0 step:859 [D loss: 0.730776, acc.: 53.12%] [G loss: 0.897297]\n",
      "epoch:0 step:860 [D loss: 0.722311, acc.: 54.69%] [G loss: 0.950622]\n",
      "epoch:0 step:861 [D loss: 0.703496, acc.: 56.25%] [G loss: 0.883404]\n",
      "epoch:0 step:862 [D loss: 0.793052, acc.: 46.88%] [G loss: 1.010200]\n",
      "epoch:0 step:863 [D loss: 0.692322, acc.: 57.03%] [G loss: 0.909656]\n",
      "epoch:0 step:864 [D loss: 0.738741, acc.: 54.69%] [G loss: 1.006390]\n",
      "epoch:0 step:865 [D loss: 0.736570, acc.: 54.69%] [G loss: 0.957243]\n",
      "epoch:0 step:866 [D loss: 0.718785, acc.: 50.78%] [G loss: 1.025409]\n",
      "epoch:0 step:867 [D loss: 0.763238, acc.: 50.78%] [G loss: 0.856001]\n",
      "epoch:0 step:868 [D loss: 0.747001, acc.: 48.44%] [G loss: 0.895224]\n",
      "epoch:0 step:869 [D loss: 0.776357, acc.: 46.88%] [G loss: 0.885534]\n",
      "epoch:0 step:870 [D loss: 0.809228, acc.: 43.75%] [G loss: 0.812364]\n",
      "epoch:0 step:871 [D loss: 0.661838, acc.: 57.81%] [G loss: 0.902755]\n",
      "epoch:0 step:872 [D loss: 0.792643, acc.: 45.31%] [G loss: 0.955776]\n",
      "epoch:0 step:873 [D loss: 0.761891, acc.: 50.78%] [G loss: 0.933602]\n",
      "epoch:0 step:874 [D loss: 0.698343, acc.: 56.25%] [G loss: 0.914698]\n",
      "epoch:0 step:875 [D loss: 0.693256, acc.: 53.12%] [G loss: 0.955391]\n",
      "epoch:0 step:876 [D loss: 0.759861, acc.: 50.00%] [G loss: 0.953703]\n",
      "epoch:0 step:877 [D loss: 0.668888, acc.: 58.59%] [G loss: 0.976630]\n",
      "epoch:0 step:878 [D loss: 0.729504, acc.: 47.66%] [G loss: 0.981249]\n",
      "epoch:0 step:879 [D loss: 0.725312, acc.: 57.81%] [G loss: 0.890703]\n",
      "epoch:0 step:880 [D loss: 0.739640, acc.: 51.56%] [G loss: 0.985261]\n",
      "epoch:0 step:881 [D loss: 0.771071, acc.: 47.66%] [G loss: 0.962097]\n",
      "epoch:0 step:882 [D loss: 0.714338, acc.: 52.34%] [G loss: 0.933628]\n",
      "epoch:0 step:883 [D loss: 0.727602, acc.: 50.00%] [G loss: 0.911178]\n",
      "epoch:0 step:884 [D loss: 0.693551, acc.: 58.59%] [G loss: 1.062568]\n",
      "epoch:0 step:885 [D loss: 0.667561, acc.: 57.81%] [G loss: 1.040814]\n",
      "epoch:0 step:886 [D loss: 0.718296, acc.: 55.47%] [G loss: 1.008444]\n",
      "epoch:0 step:887 [D loss: 0.668340, acc.: 62.50%] [G loss: 0.903100]\n",
      "epoch:0 step:888 [D loss: 0.741861, acc.: 48.44%] [G loss: 0.999156]\n",
      "epoch:0 step:889 [D loss: 0.634304, acc.: 66.41%] [G loss: 0.992859]\n",
      "epoch:0 step:890 [D loss: 0.622646, acc.: 64.84%] [G loss: 1.103245]\n",
      "epoch:0 step:891 [D loss: 0.780743, acc.: 50.00%] [G loss: 0.958841]\n",
      "epoch:0 step:892 [D loss: 0.791816, acc.: 46.09%] [G loss: 0.878755]\n",
      "epoch:0 step:893 [D loss: 0.794779, acc.: 45.31%] [G loss: 0.834196]\n",
      "epoch:0 step:894 [D loss: 0.709261, acc.: 53.91%] [G loss: 0.987289]\n",
      "epoch:0 step:895 [D loss: 0.695003, acc.: 60.94%] [G loss: 1.054218]\n",
      "epoch:0 step:896 [D loss: 0.769119, acc.: 53.91%] [G loss: 0.874971]\n",
      "epoch:0 step:897 [D loss: 0.703484, acc.: 53.91%] [G loss: 0.890356]\n",
      "epoch:0 step:898 [D loss: 0.729379, acc.: 53.12%] [G loss: 0.866458]\n",
      "epoch:0 step:899 [D loss: 0.707245, acc.: 52.34%] [G loss: 1.016275]\n",
      "epoch:0 step:900 [D loss: 0.676704, acc.: 56.25%] [G loss: 0.958982]\n",
      "epoch:0 step:901 [D loss: 0.777394, acc.: 41.41%] [G loss: 1.012194]\n",
      "epoch:0 step:902 [D loss: 0.728171, acc.: 55.47%] [G loss: 0.983341]\n",
      "epoch:0 step:903 [D loss: 0.757981, acc.: 51.56%] [G loss: 0.912084]\n",
      "epoch:0 step:904 [D loss: 0.745085, acc.: 50.00%] [G loss: 0.914246]\n",
      "epoch:0 step:905 [D loss: 0.735648, acc.: 51.56%] [G loss: 0.903652]\n",
      "epoch:0 step:906 [D loss: 0.670439, acc.: 57.03%] [G loss: 0.984696]\n",
      "epoch:0 step:907 [D loss: 0.736070, acc.: 50.78%] [G loss: 0.968420]\n",
      "epoch:0 step:908 [D loss: 0.729341, acc.: 50.00%] [G loss: 1.040000]\n",
      "epoch:0 step:909 [D loss: 0.679095, acc.: 57.03%] [G loss: 0.992752]\n",
      "epoch:0 step:910 [D loss: 0.653702, acc.: 63.28%] [G loss: 1.011634]\n",
      "epoch:0 step:911 [D loss: 0.632416, acc.: 61.72%] [G loss: 0.958432]\n",
      "epoch:0 step:912 [D loss: 0.646958, acc.: 60.94%] [G loss: 1.079107]\n",
      "epoch:0 step:913 [D loss: 0.853163, acc.: 35.94%] [G loss: 0.871552]\n",
      "epoch:0 step:914 [D loss: 0.706840, acc.: 51.56%] [G loss: 0.849329]\n",
      "epoch:0 step:915 [D loss: 0.751475, acc.: 51.56%] [G loss: 0.957568]\n",
      "epoch:0 step:916 [D loss: 0.761600, acc.: 50.00%] [G loss: 0.959698]\n",
      "epoch:0 step:917 [D loss: 0.726918, acc.: 56.25%] [G loss: 0.943512]\n",
      "epoch:0 step:918 [D loss: 0.655246, acc.: 64.06%] [G loss: 0.979499]\n",
      "epoch:0 step:919 [D loss: 0.657327, acc.: 65.62%] [G loss: 0.998036]\n",
      "epoch:0 step:920 [D loss: 0.730910, acc.: 50.00%] [G loss: 1.006546]\n",
      "epoch:0 step:921 [D loss: 0.677086, acc.: 59.38%] [G loss: 0.968217]\n",
      "epoch:0 step:922 [D loss: 0.744736, acc.: 49.22%] [G loss: 0.886916]\n",
      "epoch:0 step:923 [D loss: 0.697797, acc.: 60.16%] [G loss: 0.889386]\n",
      "epoch:0 step:924 [D loss: 0.605662, acc.: 67.19%] [G loss: 0.989762]\n",
      "epoch:0 step:925 [D loss: 0.629024, acc.: 63.28%] [G loss: 0.897377]\n",
      "epoch:0 step:926 [D loss: 0.684203, acc.: 53.12%] [G loss: 0.990626]\n",
      "epoch:0 step:927 [D loss: 0.637658, acc.: 63.28%] [G loss: 1.063929]\n",
      "epoch:0 step:928 [D loss: 0.782766, acc.: 54.69%] [G loss: 1.055150]\n",
      "epoch:0 step:929 [D loss: 0.866319, acc.: 44.53%] [G loss: 0.915193]\n",
      "epoch:0 step:930 [D loss: 0.729379, acc.: 52.34%] [G loss: 0.954663]\n",
      "epoch:0 step:931 [D loss: 0.691547, acc.: 53.91%] [G loss: 1.016625]\n",
      "epoch:0 step:932 [D loss: 0.756828, acc.: 50.00%] [G loss: 0.985373]\n",
      "epoch:0 step:933 [D loss: 0.703597, acc.: 62.50%] [G loss: 1.033842]\n",
      "epoch:0 step:934 [D loss: 0.660322, acc.: 58.59%] [G loss: 0.926110]\n",
      "epoch:0 step:935 [D loss: 0.667550, acc.: 56.25%] [G loss: 0.983065]\n",
      "epoch:0 step:936 [D loss: 0.654411, acc.: 63.28%] [G loss: 1.060568]\n",
      "epoch:0 step:937 [D loss: 0.622952, acc.: 64.06%] [G loss: 1.118561]\n",
      "epoch:1 step:938 [D loss: 0.675517, acc.: 59.38%] [G loss: 1.065688]\n",
      "epoch:1 step:939 [D loss: 0.690083, acc.: 57.03%] [G loss: 0.963794]\n",
      "epoch:1 step:940 [D loss: 0.709987, acc.: 58.59%] [G loss: 0.982892]\n",
      "epoch:1 step:941 [D loss: 0.686057, acc.: 56.25%] [G loss: 0.989820]\n",
      "epoch:1 step:942 [D loss: 0.742223, acc.: 53.12%] [G loss: 0.902047]\n",
      "epoch:1 step:943 [D loss: 0.730678, acc.: 52.34%] [G loss: 0.944137]\n",
      "epoch:1 step:944 [D loss: 0.749684, acc.: 51.56%] [G loss: 0.999521]\n",
      "epoch:1 step:945 [D loss: 0.712891, acc.: 58.59%] [G loss: 1.006378]\n",
      "epoch:1 step:946 [D loss: 0.768903, acc.: 52.34%] [G loss: 0.901563]\n",
      "epoch:1 step:947 [D loss: 0.681918, acc.: 57.81%] [G loss: 1.075258]\n",
      "epoch:1 step:948 [D loss: 0.704160, acc.: 58.59%] [G loss: 1.022687]\n",
      "epoch:1 step:949 [D loss: 0.731755, acc.: 46.09%] [G loss: 0.918262]\n",
      "epoch:1 step:950 [D loss: 0.721531, acc.: 46.09%] [G loss: 0.911510]\n",
      "epoch:1 step:951 [D loss: 0.679712, acc.: 57.03%] [G loss: 0.911874]\n",
      "epoch:1 step:952 [D loss: 0.657164, acc.: 56.25%] [G loss: 0.960591]\n",
      "epoch:1 step:953 [D loss: 0.681790, acc.: 59.38%] [G loss: 0.997923]\n",
      "epoch:1 step:954 [D loss: 0.759847, acc.: 53.12%] [G loss: 0.945050]\n",
      "epoch:1 step:955 [D loss: 0.776760, acc.: 46.09%] [G loss: 0.992023]\n",
      "epoch:1 step:956 [D loss: 0.714275, acc.: 55.47%] [G loss: 1.062168]\n",
      "epoch:1 step:957 [D loss: 0.904325, acc.: 35.16%] [G loss: 0.959754]\n",
      "epoch:1 step:958 [D loss: 0.808670, acc.: 50.78%] [G loss: 0.968535]\n",
      "epoch:1 step:959 [D loss: 0.728914, acc.: 53.12%] [G loss: 0.929375]\n",
      "epoch:1 step:960 [D loss: 0.684701, acc.: 60.94%] [G loss: 1.105932]\n",
      "epoch:1 step:961 [D loss: 0.808319, acc.: 42.97%] [G loss: 1.173313]\n",
      "epoch:1 step:962 [D loss: 0.690028, acc.: 53.91%] [G loss: 1.054093]\n",
      "epoch:1 step:963 [D loss: 0.755583, acc.: 51.56%] [G loss: 1.023628]\n",
      "epoch:1 step:964 [D loss: 0.707749, acc.: 57.81%] [G loss: 1.067790]\n",
      "epoch:1 step:965 [D loss: 0.700018, acc.: 54.69%] [G loss: 0.991295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:966 [D loss: 0.675887, acc.: 51.56%] [G loss: 0.978735]\n",
      "epoch:1 step:967 [D loss: 0.718278, acc.: 54.69%] [G loss: 0.948364]\n",
      "epoch:1 step:968 [D loss: 0.734604, acc.: 49.22%] [G loss: 0.919884]\n",
      "epoch:1 step:969 [D loss: 0.729904, acc.: 53.91%] [G loss: 0.858134]\n",
      "epoch:1 step:970 [D loss: 0.716241, acc.: 51.56%] [G loss: 0.986998]\n",
      "epoch:1 step:971 [D loss: 0.693709, acc.: 55.47%] [G loss: 0.957879]\n",
      "epoch:1 step:972 [D loss: 0.624697, acc.: 67.97%] [G loss: 1.012163]\n",
      "epoch:1 step:973 [D loss: 0.643988, acc.: 64.06%] [G loss: 1.084766]\n",
      "epoch:1 step:974 [D loss: 0.668378, acc.: 65.62%] [G loss: 1.040715]\n",
      "epoch:1 step:975 [D loss: 0.805745, acc.: 45.31%] [G loss: 0.935905]\n",
      "epoch:1 step:976 [D loss: 0.756504, acc.: 47.66%] [G loss: 0.935501]\n",
      "epoch:1 step:977 [D loss: 0.735471, acc.: 51.56%] [G loss: 0.902331]\n",
      "epoch:1 step:978 [D loss: 0.696515, acc.: 56.25%] [G loss: 1.035576]\n",
      "epoch:1 step:979 [D loss: 0.662745, acc.: 60.16%] [G loss: 1.036747]\n",
      "epoch:1 step:980 [D loss: 0.692814, acc.: 53.91%] [G loss: 1.089490]\n",
      "epoch:1 step:981 [D loss: 0.757880, acc.: 51.56%] [G loss: 0.929533]\n",
      "epoch:1 step:982 [D loss: 0.740810, acc.: 52.34%] [G loss: 1.001432]\n",
      "epoch:1 step:983 [D loss: 0.752516, acc.: 57.81%] [G loss: 0.913158]\n",
      "epoch:1 step:984 [D loss: 0.743055, acc.: 49.22%] [G loss: 1.104497]\n",
      "epoch:1 step:985 [D loss: 0.714186, acc.: 53.91%] [G loss: 0.969205]\n",
      "epoch:1 step:986 [D loss: 0.725111, acc.: 55.47%] [G loss: 1.045526]\n",
      "epoch:1 step:987 [D loss: 0.723145, acc.: 51.56%] [G loss: 0.967053]\n",
      "epoch:1 step:988 [D loss: 0.735083, acc.: 48.44%] [G loss: 0.921421]\n",
      "epoch:1 step:989 [D loss: 0.669336, acc.: 55.47%] [G loss: 0.992732]\n",
      "epoch:1 step:990 [D loss: 0.618796, acc.: 64.06%] [G loss: 1.096811]\n",
      "epoch:1 step:991 [D loss: 0.673956, acc.: 61.72%] [G loss: 1.049763]\n",
      "epoch:1 step:992 [D loss: 0.642095, acc.: 67.97%] [G loss: 0.993986]\n",
      "epoch:1 step:993 [D loss: 0.686478, acc.: 58.59%] [G loss: 1.007516]\n",
      "epoch:1 step:994 [D loss: 0.768766, acc.: 50.78%] [G loss: 1.055007]\n",
      "epoch:1 step:995 [D loss: 0.721722, acc.: 53.12%] [G loss: 0.999576]\n",
      "epoch:1 step:996 [D loss: 0.738922, acc.: 57.03%] [G loss: 0.965772]\n",
      "epoch:1 step:997 [D loss: 0.708653, acc.: 56.25%] [G loss: 1.018324]\n",
      "epoch:1 step:998 [D loss: 0.732118, acc.: 50.78%] [G loss: 0.900877]\n",
      "epoch:1 step:999 [D loss: 0.675833, acc.: 56.25%] [G loss: 1.133850]\n",
      "epoch:1 step:1000 [D loss: 0.642989, acc.: 67.19%] [G loss: 1.049114]\n",
      "epoch:1 step:1001 [D loss: 0.717639, acc.: 59.38%] [G loss: 1.117064]\n",
      "epoch:1 step:1002 [D loss: 0.707694, acc.: 55.47%] [G loss: 1.045020]\n",
      "epoch:1 step:1003 [D loss: 0.687504, acc.: 61.72%] [G loss: 0.937392]\n",
      "epoch:1 step:1004 [D loss: 0.697882, acc.: 57.03%] [G loss: 0.974087]\n",
      "epoch:1 step:1005 [D loss: 0.715160, acc.: 57.81%] [G loss: 0.852924]\n",
      "epoch:1 step:1006 [D loss: 0.718533, acc.: 50.00%] [G loss: 0.955567]\n",
      "epoch:1 step:1007 [D loss: 0.670645, acc.: 59.38%] [G loss: 0.960424]\n",
      "epoch:1 step:1008 [D loss: 0.644594, acc.: 63.28%] [G loss: 1.016300]\n",
      "epoch:1 step:1009 [D loss: 0.705797, acc.: 57.03%] [G loss: 0.986717]\n",
      "epoch:1 step:1010 [D loss: 0.671414, acc.: 60.94%] [G loss: 0.972214]\n",
      "epoch:1 step:1011 [D loss: 0.705929, acc.: 53.12%] [G loss: 1.165547]\n",
      "epoch:1 step:1012 [D loss: 0.646286, acc.: 68.75%] [G loss: 1.079305]\n",
      "epoch:1 step:1013 [D loss: 0.621726, acc.: 67.19%] [G loss: 1.104318]\n",
      "epoch:1 step:1014 [D loss: 0.702474, acc.: 52.34%] [G loss: 1.030199]\n",
      "epoch:1 step:1015 [D loss: 0.763915, acc.: 52.34%] [G loss: 1.001552]\n",
      "epoch:1 step:1016 [D loss: 0.765192, acc.: 46.09%] [G loss: 1.056075]\n",
      "epoch:1 step:1017 [D loss: 0.825311, acc.: 44.53%] [G loss: 0.787006]\n",
      "epoch:1 step:1018 [D loss: 0.839233, acc.: 46.88%] [G loss: 0.823249]\n",
      "epoch:1 step:1019 [D loss: 0.769679, acc.: 49.22%] [G loss: 0.802763]\n",
      "epoch:1 step:1020 [D loss: 0.747766, acc.: 49.22%] [G loss: 0.869061]\n",
      "epoch:1 step:1021 [D loss: 0.703109, acc.: 52.34%] [G loss: 1.007016]\n",
      "epoch:1 step:1022 [D loss: 0.694693, acc.: 53.12%] [G loss: 0.865436]\n",
      "epoch:1 step:1023 [D loss: 0.736901, acc.: 49.22%] [G loss: 0.800029]\n",
      "epoch:1 step:1024 [D loss: 0.724666, acc.: 58.59%] [G loss: 0.939382]\n",
      "epoch:1 step:1025 [D loss: 0.706116, acc.: 57.03%] [G loss: 0.870572]\n",
      "epoch:1 step:1026 [D loss: 0.727213, acc.: 50.78%] [G loss: 1.109182]\n",
      "epoch:1 step:1027 [D loss: 0.729246, acc.: 46.88%] [G loss: 1.000408]\n",
      "epoch:1 step:1028 [D loss: 0.752782, acc.: 46.09%] [G loss: 0.933965]\n",
      "epoch:1 step:1029 [D loss: 0.711712, acc.: 57.03%] [G loss: 1.058713]\n",
      "epoch:1 step:1030 [D loss: 0.647561, acc.: 63.28%] [G loss: 1.186972]\n",
      "epoch:1 step:1031 [D loss: 0.723950, acc.: 57.03%] [G loss: 0.988585]\n",
      "epoch:1 step:1032 [D loss: 0.763997, acc.: 48.44%] [G loss: 0.852862]\n",
      "epoch:1 step:1033 [D loss: 0.697360, acc.: 60.16%] [G loss: 0.832605]\n",
      "epoch:1 step:1034 [D loss: 0.722348, acc.: 53.91%] [G loss: 0.943618]\n",
      "epoch:1 step:1035 [D loss: 0.760526, acc.: 50.00%] [G loss: 0.967792]\n",
      "epoch:1 step:1036 [D loss: 0.728987, acc.: 49.22%] [G loss: 0.930176]\n",
      "epoch:1 step:1037 [D loss: 0.689496, acc.: 51.56%] [G loss: 1.051575]\n",
      "epoch:1 step:1038 [D loss: 0.734366, acc.: 52.34%] [G loss: 0.931224]\n",
      "epoch:1 step:1039 [D loss: 0.721717, acc.: 55.47%] [G loss: 0.984709]\n",
      "epoch:1 step:1040 [D loss: 0.649654, acc.: 64.84%] [G loss: 1.013990]\n",
      "epoch:1 step:1041 [D loss: 0.653779, acc.: 60.16%] [G loss: 0.922171]\n",
      "epoch:1 step:1042 [D loss: 0.717525, acc.: 53.91%] [G loss: 1.016391]\n",
      "epoch:1 step:1043 [D loss: 0.712812, acc.: 55.47%] [G loss: 0.938093]\n",
      "epoch:1 step:1044 [D loss: 0.711019, acc.: 56.25%] [G loss: 0.966812]\n",
      "epoch:1 step:1045 [D loss: 0.773521, acc.: 46.09%] [G loss: 1.004194]\n",
      "epoch:1 step:1046 [D loss: 0.683652, acc.: 59.38%] [G loss: 0.970062]\n",
      "epoch:1 step:1047 [D loss: 0.748947, acc.: 50.78%] [G loss: 0.927320]\n",
      "epoch:1 step:1048 [D loss: 0.724219, acc.: 53.12%] [G loss: 0.855587]\n",
      "epoch:1 step:1049 [D loss: 0.670935, acc.: 59.38%] [G loss: 0.981683]\n",
      "epoch:1 step:1050 [D loss: 0.701002, acc.: 56.25%] [G loss: 0.922688]\n",
      "epoch:1 step:1051 [D loss: 0.709965, acc.: 53.12%] [G loss: 0.878742]\n",
      "epoch:1 step:1052 [D loss: 0.732990, acc.: 54.69%] [G loss: 0.955488]\n",
      "epoch:1 step:1053 [D loss: 0.693541, acc.: 53.91%] [G loss: 1.017061]\n",
      "epoch:1 step:1054 [D loss: 0.711513, acc.: 55.47%] [G loss: 0.993311]\n",
      "epoch:1 step:1055 [D loss: 0.710616, acc.: 60.94%] [G loss: 1.030843]\n",
      "epoch:1 step:1056 [D loss: 0.663885, acc.: 62.50%] [G loss: 0.955503]\n",
      "epoch:1 step:1057 [D loss: 0.761432, acc.: 50.00%] [G loss: 0.950584]\n",
      "epoch:1 step:1058 [D loss: 0.829438, acc.: 40.62%] [G loss: 0.854720]\n",
      "epoch:1 step:1059 [D loss: 0.731967, acc.: 53.12%] [G loss: 0.880258]\n",
      "epoch:1 step:1060 [D loss: 0.727893, acc.: 48.44%] [G loss: 0.899933]\n",
      "epoch:1 step:1061 [D loss: 0.766942, acc.: 46.88%] [G loss: 0.875250]\n",
      "epoch:1 step:1062 [D loss: 0.724241, acc.: 47.66%] [G loss: 0.858065]\n",
      "epoch:1 step:1063 [D loss: 0.691508, acc.: 57.03%] [G loss: 0.911924]\n",
      "epoch:1 step:1064 [D loss: 0.751964, acc.: 45.31%] [G loss: 0.815298]\n",
      "epoch:1 step:1065 [D loss: 0.703792, acc.: 54.69%] [G loss: 0.915050]\n",
      "epoch:1 step:1066 [D loss: 0.665622, acc.: 56.25%] [G loss: 0.997775]\n",
      "epoch:1 step:1067 [D loss: 0.746896, acc.: 48.44%] [G loss: 1.012508]\n",
      "epoch:1 step:1068 [D loss: 0.652296, acc.: 61.72%] [G loss: 0.975150]\n",
      "epoch:1 step:1069 [D loss: 0.657249, acc.: 61.72%] [G loss: 0.984319]\n",
      "epoch:1 step:1070 [D loss: 0.735298, acc.: 49.22%] [G loss: 0.933283]\n",
      "epoch:1 step:1071 [D loss: 0.742406, acc.: 53.12%] [G loss: 0.911603]\n",
      "epoch:1 step:1072 [D loss: 0.749191, acc.: 49.22%] [G loss: 0.871082]\n",
      "epoch:1 step:1073 [D loss: 0.761378, acc.: 46.88%] [G loss: 0.823951]\n",
      "epoch:1 step:1074 [D loss: 0.786734, acc.: 49.22%] [G loss: 0.899495]\n",
      "epoch:1 step:1075 [D loss: 0.744048, acc.: 53.91%] [G loss: 0.953918]\n",
      "epoch:1 step:1076 [D loss: 0.724628, acc.: 51.56%] [G loss: 0.846570]\n",
      "epoch:1 step:1077 [D loss: 0.752646, acc.: 46.09%] [G loss: 0.933650]\n",
      "epoch:1 step:1078 [D loss: 0.683864, acc.: 57.03%] [G loss: 0.925155]\n",
      "epoch:1 step:1079 [D loss: 0.714150, acc.: 53.91%] [G loss: 0.973656]\n",
      "epoch:1 step:1080 [D loss: 0.643440, acc.: 62.50%] [G loss: 0.994767]\n",
      "epoch:1 step:1081 [D loss: 0.686953, acc.: 55.47%] [G loss: 0.933784]\n",
      "epoch:1 step:1082 [D loss: 0.650551, acc.: 61.72%] [G loss: 0.980884]\n",
      "epoch:1 step:1083 [D loss: 0.714090, acc.: 56.25%] [G loss: 1.029342]\n",
      "epoch:1 step:1084 [D loss: 0.773124, acc.: 53.91%] [G loss: 0.944123]\n",
      "epoch:1 step:1085 [D loss: 0.740127, acc.: 49.22%] [G loss: 1.007528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1086 [D loss: 0.708718, acc.: 54.69%] [G loss: 0.921826]\n",
      "epoch:1 step:1087 [D loss: 0.740228, acc.: 49.22%] [G loss: 1.034095]\n",
      "epoch:1 step:1088 [D loss: 0.656877, acc.: 59.38%] [G loss: 0.910279]\n",
      "epoch:1 step:1089 [D loss: 0.590706, acc.: 68.75%] [G loss: 0.961159]\n",
      "epoch:1 step:1090 [D loss: 0.647921, acc.: 60.94%] [G loss: 0.979557]\n",
      "epoch:1 step:1091 [D loss: 0.710842, acc.: 57.81%] [G loss: 0.960750]\n",
      "epoch:1 step:1092 [D loss: 0.702086, acc.: 48.44%] [G loss: 0.922863]\n",
      "epoch:1 step:1093 [D loss: 0.666267, acc.: 61.72%] [G loss: 0.960357]\n",
      "epoch:1 step:1094 [D loss: 0.649353, acc.: 62.50%] [G loss: 0.951448]\n",
      "epoch:1 step:1095 [D loss: 0.701878, acc.: 61.72%] [G loss: 0.855494]\n",
      "epoch:1 step:1096 [D loss: 0.726823, acc.: 57.03%] [G loss: 0.926154]\n",
      "epoch:1 step:1097 [D loss: 0.776577, acc.: 42.97%] [G loss: 0.918748]\n",
      "epoch:1 step:1098 [D loss: 0.739109, acc.: 50.00%] [G loss: 1.035863]\n",
      "epoch:1 step:1099 [D loss: 0.716238, acc.: 54.69%] [G loss: 0.870203]\n",
      "epoch:1 step:1100 [D loss: 0.724476, acc.: 53.12%] [G loss: 0.871050]\n",
      "epoch:1 step:1101 [D loss: 0.772667, acc.: 49.22%] [G loss: 0.907447]\n",
      "epoch:1 step:1102 [D loss: 0.706163, acc.: 52.34%] [G loss: 0.933825]\n",
      "epoch:1 step:1103 [D loss: 0.676342, acc.: 61.72%] [G loss: 0.919989]\n",
      "epoch:1 step:1104 [D loss: 0.686108, acc.: 59.38%] [G loss: 1.004891]\n",
      "epoch:1 step:1105 [D loss: 0.699359, acc.: 57.81%] [G loss: 0.963979]\n",
      "epoch:1 step:1106 [D loss: 0.683690, acc.: 57.81%] [G loss: 0.981401]\n",
      "epoch:1 step:1107 [D loss: 0.774601, acc.: 41.41%] [G loss: 0.943923]\n",
      "epoch:1 step:1108 [D loss: 0.661654, acc.: 62.50%] [G loss: 0.990245]\n",
      "epoch:1 step:1109 [D loss: 0.782410, acc.: 43.75%] [G loss: 0.873425]\n",
      "epoch:1 step:1110 [D loss: 0.655035, acc.: 56.25%] [G loss: 0.922598]\n",
      "epoch:1 step:1111 [D loss: 0.715247, acc.: 53.12%] [G loss: 0.971801]\n",
      "epoch:1 step:1112 [D loss: 0.717187, acc.: 48.44%] [G loss: 0.896164]\n",
      "epoch:1 step:1113 [D loss: 0.747607, acc.: 44.53%] [G loss: 0.910725]\n",
      "epoch:1 step:1114 [D loss: 0.643573, acc.: 60.94%] [G loss: 0.879048]\n",
      "epoch:1 step:1115 [D loss: 0.677485, acc.: 63.28%] [G loss: 0.952441]\n",
      "epoch:1 step:1116 [D loss: 0.676799, acc.: 58.59%] [G loss: 0.922674]\n",
      "epoch:1 step:1117 [D loss: 0.701069, acc.: 54.69%] [G loss: 0.971872]\n",
      "epoch:1 step:1118 [D loss: 0.729610, acc.: 54.69%] [G loss: 0.973986]\n",
      "epoch:1 step:1119 [D loss: 0.741928, acc.: 49.22%] [G loss: 0.902808]\n",
      "epoch:1 step:1120 [D loss: 0.734591, acc.: 54.69%] [G loss: 0.974831]\n",
      "epoch:1 step:1121 [D loss: 0.668861, acc.: 56.25%] [G loss: 0.981012]\n",
      "epoch:1 step:1122 [D loss: 0.750449, acc.: 51.56%] [G loss: 0.933311]\n",
      "epoch:1 step:1123 [D loss: 0.688404, acc.: 51.56%] [G loss: 0.970685]\n",
      "epoch:1 step:1124 [D loss: 0.690880, acc.: 56.25%] [G loss: 0.963639]\n",
      "epoch:1 step:1125 [D loss: 0.695286, acc.: 56.25%] [G loss: 0.999543]\n",
      "epoch:1 step:1126 [D loss: 0.670185, acc.: 57.81%] [G loss: 0.922961]\n",
      "epoch:1 step:1127 [D loss: 0.638004, acc.: 63.28%] [G loss: 1.003886]\n",
      "epoch:1 step:1128 [D loss: 0.728753, acc.: 57.03%] [G loss: 0.960141]\n",
      "epoch:1 step:1129 [D loss: 0.675097, acc.: 60.16%] [G loss: 0.855981]\n",
      "epoch:1 step:1130 [D loss: 0.700552, acc.: 60.16%] [G loss: 0.978467]\n",
      "epoch:1 step:1131 [D loss: 0.641594, acc.: 60.16%] [G loss: 1.085876]\n",
      "epoch:1 step:1132 [D loss: 0.668690, acc.: 58.59%] [G loss: 1.038153]\n",
      "epoch:1 step:1133 [D loss: 0.771472, acc.: 46.88%] [G loss: 1.019226]\n",
      "epoch:1 step:1134 [D loss: 0.706933, acc.: 60.16%] [G loss: 0.947798]\n",
      "epoch:1 step:1135 [D loss: 0.670221, acc.: 60.16%] [G loss: 0.885280]\n",
      "epoch:1 step:1136 [D loss: 0.742669, acc.: 54.69%] [G loss: 0.918082]\n",
      "epoch:1 step:1137 [D loss: 0.762547, acc.: 48.44%] [G loss: 0.999578]\n",
      "epoch:1 step:1138 [D loss: 0.720796, acc.: 53.12%] [G loss: 1.025149]\n",
      "epoch:1 step:1139 [D loss: 0.727915, acc.: 56.25%] [G loss: 0.843270]\n",
      "epoch:1 step:1140 [D loss: 0.775645, acc.: 50.78%] [G loss: 0.847330]\n",
      "epoch:1 step:1141 [D loss: 0.667864, acc.: 57.03%] [G loss: 0.963519]\n",
      "epoch:1 step:1142 [D loss: 0.729721, acc.: 57.03%] [G loss: 0.866986]\n",
      "epoch:1 step:1143 [D loss: 0.647867, acc.: 64.84%] [G loss: 0.990284]\n",
      "epoch:1 step:1144 [D loss: 0.623165, acc.: 67.19%] [G loss: 1.076747]\n",
      "epoch:1 step:1145 [D loss: 0.664947, acc.: 62.50%] [G loss: 0.987504]\n",
      "epoch:1 step:1146 [D loss: 0.678075, acc.: 59.38%] [G loss: 0.928997]\n",
      "epoch:1 step:1147 [D loss: 0.712733, acc.: 53.91%] [G loss: 0.954800]\n",
      "epoch:1 step:1148 [D loss: 0.679505, acc.: 58.59%] [G loss: 0.926396]\n",
      "epoch:1 step:1149 [D loss: 0.755061, acc.: 47.66%] [G loss: 0.899464]\n",
      "epoch:1 step:1150 [D loss: 0.711696, acc.: 49.22%] [G loss: 0.930822]\n",
      "epoch:1 step:1151 [D loss: 0.751412, acc.: 50.00%] [G loss: 0.966426]\n",
      "epoch:1 step:1152 [D loss: 0.749561, acc.: 50.78%] [G loss: 0.977735]\n",
      "epoch:1 step:1153 [D loss: 0.687335, acc.: 57.81%] [G loss: 1.065321]\n",
      "epoch:1 step:1154 [D loss: 0.679569, acc.: 60.94%] [G loss: 1.029948]\n",
      "epoch:1 step:1155 [D loss: 0.691625, acc.: 57.03%] [G loss: 0.916574]\n",
      "epoch:1 step:1156 [D loss: 0.657522, acc.: 57.03%] [G loss: 1.026058]\n",
      "epoch:1 step:1157 [D loss: 0.754996, acc.: 53.12%] [G loss: 0.978320]\n",
      "epoch:1 step:1158 [D loss: 0.756634, acc.: 48.44%] [G loss: 0.973205]\n",
      "epoch:1 step:1159 [D loss: 0.723483, acc.: 50.78%] [G loss: 0.946671]\n",
      "epoch:1 step:1160 [D loss: 0.626332, acc.: 67.19%] [G loss: 0.882238]\n",
      "epoch:1 step:1161 [D loss: 0.762242, acc.: 50.00%] [G loss: 1.011501]\n",
      "epoch:1 step:1162 [D loss: 0.807893, acc.: 47.66%] [G loss: 0.815083]\n",
      "epoch:1 step:1163 [D loss: 0.731796, acc.: 53.12%] [G loss: 0.906927]\n",
      "epoch:1 step:1164 [D loss: 0.699629, acc.: 57.03%] [G loss: 0.849078]\n",
      "epoch:1 step:1165 [D loss: 0.688358, acc.: 55.47%] [G loss: 0.933095]\n",
      "epoch:1 step:1166 [D loss: 0.703185, acc.: 58.59%] [G loss: 0.960729]\n",
      "epoch:1 step:1167 [D loss: 0.652430, acc.: 63.28%] [G loss: 1.047629]\n",
      "epoch:1 step:1168 [D loss: 0.616245, acc.: 64.06%] [G loss: 1.172122]\n",
      "epoch:1 step:1169 [D loss: 0.562301, acc.: 71.88%] [G loss: 1.143604]\n",
      "epoch:1 step:1170 [D loss: 0.680746, acc.: 60.16%] [G loss: 1.090140]\n",
      "epoch:1 step:1171 [D loss: 0.781919, acc.: 50.00%] [G loss: 0.874628]\n",
      "epoch:1 step:1172 [D loss: 0.679533, acc.: 57.81%] [G loss: 1.034045]\n",
      "epoch:1 step:1173 [D loss: 0.693627, acc.: 60.16%] [G loss: 0.972169]\n",
      "epoch:1 step:1174 [D loss: 0.714346, acc.: 55.47%] [G loss: 0.963141]\n",
      "epoch:1 step:1175 [D loss: 0.670374, acc.: 61.72%] [G loss: 0.876096]\n",
      "epoch:1 step:1176 [D loss: 0.698653, acc.: 57.03%] [G loss: 0.975976]\n",
      "epoch:1 step:1177 [D loss: 0.791529, acc.: 48.44%] [G loss: 0.950028]\n",
      "epoch:1 step:1178 [D loss: 0.740582, acc.: 49.22%] [G loss: 0.957632]\n",
      "epoch:1 step:1179 [D loss: 0.700261, acc.: 53.91%] [G loss: 0.855015]\n",
      "epoch:1 step:1180 [D loss: 0.723912, acc.: 53.91%] [G loss: 0.879843]\n",
      "epoch:1 step:1181 [D loss: 0.639979, acc.: 67.97%] [G loss: 0.997281]\n",
      "epoch:1 step:1182 [D loss: 0.741514, acc.: 53.91%] [G loss: 0.966960]\n",
      "epoch:1 step:1183 [D loss: 0.728488, acc.: 53.12%] [G loss: 0.936285]\n",
      "epoch:1 step:1184 [D loss: 0.742932, acc.: 50.00%] [G loss: 0.998828]\n",
      "epoch:1 step:1185 [D loss: 0.681068, acc.: 60.16%] [G loss: 0.933688]\n",
      "epoch:1 step:1186 [D loss: 0.808607, acc.: 39.06%] [G loss: 0.874155]\n",
      "epoch:1 step:1187 [D loss: 0.694918, acc.: 57.81%] [G loss: 0.899987]\n",
      "epoch:1 step:1188 [D loss: 0.726160, acc.: 53.91%] [G loss: 0.871709]\n",
      "epoch:1 step:1189 [D loss: 0.679567, acc.: 60.94%] [G loss: 0.925595]\n",
      "epoch:1 step:1190 [D loss: 0.700117, acc.: 58.59%] [G loss: 0.991183]\n",
      "epoch:1 step:1191 [D loss: 0.620069, acc.: 67.19%] [G loss: 0.929079]\n",
      "epoch:1 step:1192 [D loss: 0.727626, acc.: 53.12%] [G loss: 0.998351]\n",
      "epoch:1 step:1193 [D loss: 0.735443, acc.: 54.69%] [G loss: 0.972694]\n",
      "epoch:1 step:1194 [D loss: 0.697160, acc.: 58.59%] [G loss: 0.919996]\n",
      "epoch:1 step:1195 [D loss: 0.649162, acc.: 64.84%] [G loss: 0.988565]\n",
      "epoch:1 step:1196 [D loss: 0.743060, acc.: 52.34%] [G loss: 1.013264]\n",
      "epoch:1 step:1197 [D loss: 0.759539, acc.: 44.53%] [G loss: 0.992945]\n",
      "epoch:1 step:1198 [D loss: 0.676668, acc.: 58.59%] [G loss: 1.048371]\n",
      "epoch:1 step:1199 [D loss: 0.729342, acc.: 52.34%] [G loss: 0.927190]\n",
      "epoch:1 step:1200 [D loss: 0.737211, acc.: 56.25%] [G loss: 0.907377]\n",
      "epoch:1 step:1201 [D loss: 0.698509, acc.: 63.28%] [G loss: 0.924883]\n",
      "epoch:1 step:1202 [D loss: 0.757554, acc.: 48.44%] [G loss: 1.021805]\n",
      "epoch:1 step:1203 [D loss: 0.661179, acc.: 63.28%] [G loss: 0.945872]\n",
      "epoch:1 step:1204 [D loss: 0.682858, acc.: 53.91%] [G loss: 1.015958]\n",
      "epoch:1 step:1205 [D loss: 0.761148, acc.: 52.34%] [G loss: 0.938442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1206 [D loss: 0.797694, acc.: 42.19%] [G loss: 1.018325]\n",
      "epoch:1 step:1207 [D loss: 0.740693, acc.: 52.34%] [G loss: 0.922870]\n",
      "epoch:1 step:1208 [D loss: 0.689178, acc.: 57.81%] [G loss: 0.910726]\n",
      "epoch:1 step:1209 [D loss: 0.671904, acc.: 64.84%] [G loss: 0.845155]\n",
      "epoch:1 step:1210 [D loss: 0.711332, acc.: 56.25%] [G loss: 0.897881]\n",
      "epoch:1 step:1211 [D loss: 0.781949, acc.: 46.88%] [G loss: 0.870075]\n",
      "epoch:1 step:1212 [D loss: 0.687804, acc.: 57.03%] [G loss: 1.018257]\n",
      "epoch:1 step:1213 [D loss: 0.699888, acc.: 53.91%] [G loss: 0.927004]\n",
      "epoch:1 step:1214 [D loss: 0.737628, acc.: 52.34%] [G loss: 0.893577]\n",
      "epoch:1 step:1215 [D loss: 0.748634, acc.: 50.00%] [G loss: 0.854547]\n",
      "epoch:1 step:1216 [D loss: 0.731626, acc.: 51.56%] [G loss: 0.997763]\n",
      "epoch:1 step:1217 [D loss: 0.695001, acc.: 54.69%] [G loss: 0.839992]\n",
      "epoch:1 step:1218 [D loss: 0.682360, acc.: 54.69%] [G loss: 0.973652]\n",
      "epoch:1 step:1219 [D loss: 0.727437, acc.: 54.69%] [G loss: 0.916788]\n",
      "epoch:1 step:1220 [D loss: 0.698697, acc.: 51.56%] [G loss: 0.911212]\n",
      "epoch:1 step:1221 [D loss: 0.657281, acc.: 63.28%] [G loss: 1.038846]\n",
      "epoch:1 step:1222 [D loss: 0.716931, acc.: 58.59%] [G loss: 0.912383]\n",
      "epoch:1 step:1223 [D loss: 0.619701, acc.: 60.16%] [G loss: 1.063700]\n",
      "epoch:1 step:1224 [D loss: 0.698746, acc.: 57.81%] [G loss: 0.970166]\n",
      "epoch:1 step:1225 [D loss: 0.755145, acc.: 52.34%] [G loss: 0.900761]\n",
      "epoch:1 step:1226 [D loss: 0.695273, acc.: 56.25%] [G loss: 1.010175]\n",
      "epoch:1 step:1227 [D loss: 0.690007, acc.: 56.25%] [G loss: 0.921700]\n",
      "epoch:1 step:1228 [D loss: 0.710088, acc.: 52.34%] [G loss: 0.868987]\n",
      "epoch:1 step:1229 [D loss: 0.671877, acc.: 60.94%] [G loss: 1.011101]\n",
      "epoch:1 step:1230 [D loss: 0.679256, acc.: 57.03%] [G loss: 1.067030]\n",
      "epoch:1 step:1231 [D loss: 0.766829, acc.: 56.25%] [G loss: 0.895665]\n",
      "epoch:1 step:1232 [D loss: 0.713774, acc.: 53.91%] [G loss: 0.917218]\n",
      "epoch:1 step:1233 [D loss: 0.680108, acc.: 60.16%] [G loss: 0.976467]\n",
      "epoch:1 step:1234 [D loss: 0.693084, acc.: 57.81%] [G loss: 1.044813]\n",
      "epoch:1 step:1235 [D loss: 0.688396, acc.: 57.03%] [G loss: 0.969306]\n",
      "epoch:1 step:1236 [D loss: 0.641730, acc.: 62.50%] [G loss: 0.962194]\n",
      "epoch:1 step:1237 [D loss: 0.667486, acc.: 59.38%] [G loss: 0.995287]\n",
      "epoch:1 step:1238 [D loss: 0.739184, acc.: 53.12%] [G loss: 0.871622]\n",
      "epoch:1 step:1239 [D loss: 0.753801, acc.: 46.09%] [G loss: 0.962559]\n",
      "epoch:1 step:1240 [D loss: 0.734074, acc.: 51.56%] [G loss: 0.834137]\n",
      "epoch:1 step:1241 [D loss: 0.674407, acc.: 61.72%] [G loss: 0.965593]\n",
      "epoch:1 step:1242 [D loss: 0.760270, acc.: 48.44%] [G loss: 0.874923]\n",
      "epoch:1 step:1243 [D loss: 0.693071, acc.: 57.81%] [G loss: 0.878688]\n",
      "epoch:1 step:1244 [D loss: 0.733985, acc.: 55.47%] [G loss: 0.884976]\n",
      "epoch:1 step:1245 [D loss: 0.664930, acc.: 56.25%] [G loss: 1.039495]\n",
      "epoch:1 step:1246 [D loss: 0.678902, acc.: 60.94%] [G loss: 1.005702]\n",
      "epoch:1 step:1247 [D loss: 0.717850, acc.: 54.69%] [G loss: 0.954714]\n",
      "epoch:1 step:1248 [D loss: 0.651020, acc.: 55.47%] [G loss: 0.987814]\n",
      "epoch:1 step:1249 [D loss: 0.643447, acc.: 60.16%] [G loss: 1.069855]\n",
      "epoch:1 step:1250 [D loss: 0.666355, acc.: 62.50%] [G loss: 1.029803]\n",
      "epoch:1 step:1251 [D loss: 0.683438, acc.: 55.47%] [G loss: 0.990387]\n",
      "epoch:1 step:1252 [D loss: 0.644744, acc.: 68.75%] [G loss: 1.072267]\n",
      "epoch:1 step:1253 [D loss: 0.764692, acc.: 51.56%] [G loss: 1.012079]\n",
      "epoch:1 step:1254 [D loss: 0.734492, acc.: 47.66%] [G loss: 1.050250]\n",
      "epoch:1 step:1255 [D loss: 0.685684, acc.: 55.47%] [G loss: 0.885621]\n",
      "epoch:1 step:1256 [D loss: 0.663453, acc.: 64.06%] [G loss: 0.985789]\n",
      "epoch:1 step:1257 [D loss: 0.672351, acc.: 60.16%] [G loss: 0.963166]\n",
      "epoch:1 step:1258 [D loss: 0.679776, acc.: 55.47%] [G loss: 0.958790]\n",
      "epoch:1 step:1259 [D loss: 0.708766, acc.: 54.69%] [G loss: 0.891923]\n",
      "epoch:1 step:1260 [D loss: 0.732721, acc.: 57.81%] [G loss: 1.026779]\n",
      "epoch:1 step:1261 [D loss: 0.666213, acc.: 60.16%] [G loss: 0.943363]\n",
      "epoch:1 step:1262 [D loss: 0.711650, acc.: 48.44%] [G loss: 0.938149]\n",
      "epoch:1 step:1263 [D loss: 0.673329, acc.: 63.28%] [G loss: 0.942116]\n",
      "epoch:1 step:1264 [D loss: 0.691146, acc.: 50.78%] [G loss: 0.935460]\n",
      "epoch:1 step:1265 [D loss: 0.682247, acc.: 56.25%] [G loss: 0.918075]\n",
      "epoch:1 step:1266 [D loss: 0.675836, acc.: 59.38%] [G loss: 0.926768]\n",
      "epoch:1 step:1267 [D loss: 0.627753, acc.: 64.84%] [G loss: 0.990400]\n",
      "epoch:1 step:1268 [D loss: 0.705562, acc.: 53.12%] [G loss: 0.883731]\n",
      "epoch:1 step:1269 [D loss: 0.709120, acc.: 53.91%] [G loss: 0.882330]\n",
      "epoch:1 step:1270 [D loss: 0.721115, acc.: 53.12%] [G loss: 0.940039]\n",
      "epoch:1 step:1271 [D loss: 0.739142, acc.: 50.78%] [G loss: 0.922365]\n",
      "epoch:1 step:1272 [D loss: 0.650851, acc.: 64.06%] [G loss: 1.048951]\n",
      "epoch:1 step:1273 [D loss: 0.676919, acc.: 57.81%] [G loss: 0.972897]\n",
      "epoch:1 step:1274 [D loss: 0.645950, acc.: 59.38%] [G loss: 0.922441]\n",
      "epoch:1 step:1275 [D loss: 0.750548, acc.: 52.34%] [G loss: 0.962474]\n",
      "epoch:1 step:1276 [D loss: 0.666495, acc.: 54.69%] [G loss: 0.992216]\n",
      "epoch:1 step:1277 [D loss: 0.701890, acc.: 56.25%] [G loss: 0.974324]\n",
      "epoch:1 step:1278 [D loss: 0.751631, acc.: 46.88%] [G loss: 0.879116]\n",
      "epoch:1 step:1279 [D loss: 0.700870, acc.: 55.47%] [G loss: 0.850254]\n",
      "epoch:1 step:1280 [D loss: 0.678101, acc.: 59.38%] [G loss: 0.920892]\n",
      "epoch:1 step:1281 [D loss: 0.668314, acc.: 60.16%] [G loss: 0.992350]\n",
      "epoch:1 step:1282 [D loss: 0.688849, acc.: 55.47%] [G loss: 0.993042]\n",
      "epoch:1 step:1283 [D loss: 0.698230, acc.: 59.38%] [G loss: 1.012582]\n",
      "epoch:1 step:1284 [D loss: 0.621933, acc.: 64.84%] [G loss: 1.164675]\n",
      "epoch:1 step:1285 [D loss: 0.693592, acc.: 52.34%] [G loss: 0.883956]\n",
      "epoch:1 step:1286 [D loss: 0.796803, acc.: 43.75%] [G loss: 0.890828]\n",
      "epoch:1 step:1287 [D loss: 0.631267, acc.: 68.75%] [G loss: 0.957801]\n",
      "epoch:1 step:1288 [D loss: 0.759830, acc.: 49.22%] [G loss: 0.946162]\n",
      "epoch:1 step:1289 [D loss: 0.792290, acc.: 46.09%] [G loss: 0.872567]\n",
      "epoch:1 step:1290 [D loss: 0.790220, acc.: 39.84%] [G loss: 0.973528]\n",
      "epoch:1 step:1291 [D loss: 0.706351, acc.: 56.25%] [G loss: 0.979137]\n",
      "epoch:1 step:1292 [D loss: 0.729231, acc.: 52.34%] [G loss: 1.034018]\n",
      "epoch:1 step:1293 [D loss: 0.674347, acc.: 60.16%] [G loss: 1.094396]\n",
      "epoch:1 step:1294 [D loss: 0.756417, acc.: 51.56%] [G loss: 0.831750]\n",
      "epoch:1 step:1295 [D loss: 0.632503, acc.: 65.62%] [G loss: 1.123845]\n",
      "epoch:1 step:1296 [D loss: 0.662433, acc.: 58.59%] [G loss: 1.016384]\n",
      "epoch:1 step:1297 [D loss: 0.636201, acc.: 64.06%] [G loss: 1.018451]\n",
      "epoch:1 step:1298 [D loss: 0.779312, acc.: 53.91%] [G loss: 0.933499]\n",
      "epoch:1 step:1299 [D loss: 0.738799, acc.: 52.34%] [G loss: 0.920125]\n",
      "epoch:1 step:1300 [D loss: 0.682258, acc.: 61.72%] [G loss: 0.842095]\n",
      "epoch:1 step:1301 [D loss: 0.739728, acc.: 49.22%] [G loss: 0.866032]\n",
      "epoch:1 step:1302 [D loss: 0.681953, acc.: 53.12%] [G loss: 0.949423]\n",
      "epoch:1 step:1303 [D loss: 0.619036, acc.: 66.41%] [G loss: 0.971508]\n",
      "epoch:1 step:1304 [D loss: 0.709127, acc.: 56.25%] [G loss: 0.941131]\n",
      "epoch:1 step:1305 [D loss: 0.725404, acc.: 56.25%] [G loss: 0.949266]\n",
      "epoch:1 step:1306 [D loss: 0.688873, acc.: 50.00%] [G loss: 0.936735]\n",
      "epoch:1 step:1307 [D loss: 0.674757, acc.: 61.72%] [G loss: 0.933390]\n",
      "epoch:1 step:1308 [D loss: 0.669279, acc.: 55.47%] [G loss: 1.092935]\n",
      "epoch:1 step:1309 [D loss: 0.652730, acc.: 63.28%] [G loss: 0.963098]\n",
      "epoch:1 step:1310 [D loss: 0.683576, acc.: 55.47%] [G loss: 0.831827]\n",
      "epoch:1 step:1311 [D loss: 0.662106, acc.: 61.72%] [G loss: 0.955109]\n",
      "epoch:1 step:1312 [D loss: 0.738432, acc.: 53.12%] [G loss: 1.034161]\n",
      "epoch:1 step:1313 [D loss: 0.748483, acc.: 53.12%] [G loss: 0.908046]\n",
      "epoch:1 step:1314 [D loss: 0.676621, acc.: 55.47%] [G loss: 0.966691]\n",
      "epoch:1 step:1315 [D loss: 0.686477, acc.: 59.38%] [G loss: 1.012855]\n",
      "epoch:1 step:1316 [D loss: 0.688931, acc.: 57.03%] [G loss: 0.976601]\n",
      "epoch:1 step:1317 [D loss: 0.723855, acc.: 52.34%] [G loss: 0.832355]\n",
      "epoch:1 step:1318 [D loss: 0.664832, acc.: 64.06%] [G loss: 0.976162]\n",
      "epoch:1 step:1319 [D loss: 0.763039, acc.: 46.09%] [G loss: 0.876576]\n",
      "epoch:1 step:1320 [D loss: 0.741553, acc.: 52.34%] [G loss: 0.887672]\n",
      "epoch:1 step:1321 [D loss: 0.681632, acc.: 59.38%] [G loss: 0.970403]\n",
      "epoch:1 step:1322 [D loss: 0.697202, acc.: 58.59%] [G loss: 0.956818]\n",
      "epoch:1 step:1323 [D loss: 0.734468, acc.: 48.44%] [G loss: 0.913699]\n",
      "epoch:1 step:1324 [D loss: 0.734994, acc.: 52.34%] [G loss: 0.851561]\n",
      "epoch:1 step:1325 [D loss: 0.692808, acc.: 55.47%] [G loss: 0.955991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1326 [D loss: 0.709053, acc.: 56.25%] [G loss: 0.983928]\n",
      "epoch:1 step:1327 [D loss: 0.710066, acc.: 54.69%] [G loss: 0.842921]\n",
      "epoch:1 step:1328 [D loss: 0.684863, acc.: 53.91%] [G loss: 0.990804]\n",
      "epoch:1 step:1329 [D loss: 0.646267, acc.: 65.62%] [G loss: 0.916106]\n",
      "epoch:1 step:1330 [D loss: 0.748229, acc.: 45.31%] [G loss: 0.895001]\n",
      "epoch:1 step:1331 [D loss: 0.650119, acc.: 66.41%] [G loss: 1.031847]\n",
      "epoch:1 step:1332 [D loss: 0.672996, acc.: 60.94%] [G loss: 1.023402]\n",
      "epoch:1 step:1333 [D loss: 0.798267, acc.: 46.09%] [G loss: 0.965709]\n",
      "epoch:1 step:1334 [D loss: 0.635511, acc.: 64.84%] [G loss: 0.980830]\n",
      "epoch:1 step:1335 [D loss: 0.651859, acc.: 64.06%] [G loss: 0.928936]\n",
      "epoch:1 step:1336 [D loss: 0.624052, acc.: 70.31%] [G loss: 0.937177]\n",
      "epoch:1 step:1337 [D loss: 0.680116, acc.: 57.81%] [G loss: 0.961850]\n",
      "epoch:1 step:1338 [D loss: 0.644122, acc.: 68.75%] [G loss: 0.928865]\n",
      "epoch:1 step:1339 [D loss: 0.675687, acc.: 58.59%] [G loss: 0.956610]\n",
      "epoch:1 step:1340 [D loss: 0.595350, acc.: 71.88%] [G loss: 1.042337]\n",
      "epoch:1 step:1341 [D loss: 0.671218, acc.: 62.50%] [G loss: 1.108114]\n",
      "epoch:1 step:1342 [D loss: 0.681555, acc.: 58.59%] [G loss: 1.015378]\n",
      "epoch:1 step:1343 [D loss: 0.686934, acc.: 55.47%] [G loss: 1.010880]\n",
      "epoch:1 step:1344 [D loss: 0.689424, acc.: 60.94%] [G loss: 0.981774]\n",
      "epoch:1 step:1345 [D loss: 0.771137, acc.: 50.00%] [G loss: 0.819026]\n",
      "epoch:1 step:1346 [D loss: 0.724199, acc.: 52.34%] [G loss: 1.017933]\n",
      "epoch:1 step:1347 [D loss: 0.705310, acc.: 57.81%] [G loss: 1.079453]\n",
      "epoch:1 step:1348 [D loss: 0.747331, acc.: 56.25%] [G loss: 0.896293]\n",
      "epoch:1 step:1349 [D loss: 0.715969, acc.: 53.91%] [G loss: 0.931664]\n",
      "epoch:1 step:1350 [D loss: 0.722095, acc.: 54.69%] [G loss: 0.975715]\n",
      "epoch:1 step:1351 [D loss: 0.706391, acc.: 54.69%] [G loss: 1.022057]\n",
      "epoch:1 step:1352 [D loss: 0.764338, acc.: 55.47%] [G loss: 0.967850]\n",
      "epoch:1 step:1353 [D loss: 0.704123, acc.: 56.25%] [G loss: 0.931049]\n",
      "epoch:1 step:1354 [D loss: 0.685779, acc.: 57.03%] [G loss: 0.887380]\n",
      "epoch:1 step:1355 [D loss: 0.664861, acc.: 62.50%] [G loss: 0.908419]\n",
      "epoch:1 step:1356 [D loss: 0.737474, acc.: 48.44%] [G loss: 0.899853]\n",
      "epoch:1 step:1357 [D loss: 0.665596, acc.: 60.16%] [G loss: 0.879326]\n",
      "epoch:1 step:1358 [D loss: 0.724364, acc.: 49.22%] [G loss: 0.953584]\n",
      "epoch:1 step:1359 [D loss: 0.643465, acc.: 57.81%] [G loss: 0.972481]\n",
      "epoch:1 step:1360 [D loss: 0.717007, acc.: 50.78%] [G loss: 1.010229]\n",
      "epoch:1 step:1361 [D loss: 0.700167, acc.: 58.59%] [G loss: 1.031299]\n",
      "epoch:1 step:1362 [D loss: 0.716146, acc.: 52.34%] [G loss: 0.969463]\n",
      "epoch:1 step:1363 [D loss: 0.726659, acc.: 52.34%] [G loss: 0.917807]\n",
      "epoch:1 step:1364 [D loss: 0.599525, acc.: 74.22%] [G loss: 0.951244]\n",
      "epoch:1 step:1365 [D loss: 0.629311, acc.: 62.50%] [G loss: 0.941098]\n",
      "epoch:1 step:1366 [D loss: 0.623508, acc.: 64.84%] [G loss: 1.155261]\n",
      "epoch:1 step:1367 [D loss: 0.673602, acc.: 54.69%] [G loss: 1.012704]\n",
      "epoch:1 step:1368 [D loss: 0.701447, acc.: 53.91%] [G loss: 1.101979]\n",
      "epoch:1 step:1369 [D loss: 0.732271, acc.: 54.69%] [G loss: 1.020582]\n",
      "epoch:1 step:1370 [D loss: 0.795000, acc.: 39.06%] [G loss: 0.951391]\n",
      "epoch:1 step:1371 [D loss: 0.674858, acc.: 57.81%] [G loss: 0.935176]\n",
      "epoch:1 step:1372 [D loss: 0.758300, acc.: 49.22%] [G loss: 0.875144]\n",
      "epoch:1 step:1373 [D loss: 0.699585, acc.: 52.34%] [G loss: 0.912616]\n",
      "epoch:1 step:1374 [D loss: 0.720899, acc.: 53.12%] [G loss: 0.999464]\n",
      "epoch:1 step:1375 [D loss: 0.709898, acc.: 53.12%] [G loss: 1.005337]\n",
      "epoch:1 step:1376 [D loss: 0.713425, acc.: 60.16%] [G loss: 0.975342]\n",
      "epoch:1 step:1377 [D loss: 0.714884, acc.: 50.78%] [G loss: 0.868682]\n",
      "epoch:1 step:1378 [D loss: 0.722293, acc.: 57.03%] [G loss: 1.011428]\n",
      "epoch:1 step:1379 [D loss: 0.793325, acc.: 42.19%] [G loss: 0.853425]\n",
      "epoch:1 step:1380 [D loss: 0.702816, acc.: 60.94%] [G loss: 0.857976]\n",
      "epoch:1 step:1381 [D loss: 0.716629, acc.: 51.56%] [G loss: 0.922127]\n",
      "epoch:1 step:1382 [D loss: 0.600284, acc.: 70.31%] [G loss: 0.980293]\n",
      "epoch:1 step:1383 [D loss: 0.762040, acc.: 50.00%] [G loss: 0.907867]\n",
      "epoch:1 step:1384 [D loss: 0.652060, acc.: 58.59%] [G loss: 0.906998]\n",
      "epoch:1 step:1385 [D loss: 0.705708, acc.: 57.03%] [G loss: 0.981093]\n",
      "epoch:1 step:1386 [D loss: 0.642926, acc.: 61.72%] [G loss: 0.984128]\n",
      "epoch:1 step:1387 [D loss: 0.693236, acc.: 55.47%] [G loss: 0.876146]\n",
      "epoch:1 step:1388 [D loss: 0.643042, acc.: 64.84%] [G loss: 1.052554]\n",
      "epoch:1 step:1389 [D loss: 0.680415, acc.: 60.94%] [G loss: 1.033761]\n",
      "epoch:1 step:1390 [D loss: 0.649291, acc.: 62.50%] [G loss: 1.045953]\n",
      "epoch:1 step:1391 [D loss: 0.709367, acc.: 64.06%] [G loss: 1.046975]\n",
      "epoch:1 step:1392 [D loss: 0.722986, acc.: 57.81%] [G loss: 0.987930]\n",
      "epoch:1 step:1393 [D loss: 0.726458, acc.: 54.69%] [G loss: 0.936783]\n",
      "epoch:1 step:1394 [D loss: 0.761281, acc.: 46.88%] [G loss: 1.010537]\n",
      "epoch:1 step:1395 [D loss: 0.772389, acc.: 51.56%] [G loss: 0.896546]\n",
      "epoch:1 step:1396 [D loss: 0.697398, acc.: 59.38%] [G loss: 0.979244]\n",
      "epoch:1 step:1397 [D loss: 0.635196, acc.: 63.28%] [G loss: 0.929536]\n",
      "epoch:1 step:1398 [D loss: 0.669909, acc.: 57.03%] [G loss: 1.014139]\n",
      "epoch:1 step:1399 [D loss: 0.706259, acc.: 54.69%] [G loss: 0.948894]\n",
      "epoch:1 step:1400 [D loss: 0.679540, acc.: 60.94%] [G loss: 0.986724]\n",
      "epoch:1 step:1401 [D loss: 0.738971, acc.: 56.25%] [G loss: 1.053311]\n",
      "epoch:1 step:1402 [D loss: 0.716910, acc.: 56.25%] [G loss: 1.006073]\n",
      "epoch:1 step:1403 [D loss: 0.653609, acc.: 62.50%] [G loss: 1.053785]\n",
      "epoch:1 step:1404 [D loss: 0.711583, acc.: 59.38%] [G loss: 0.959694]\n",
      "epoch:1 step:1405 [D loss: 0.774179, acc.: 50.78%] [G loss: 0.917296]\n",
      "epoch:1 step:1406 [D loss: 0.651680, acc.: 67.97%] [G loss: 1.047243]\n",
      "epoch:1 step:1407 [D loss: 0.687023, acc.: 60.16%] [G loss: 0.976232]\n",
      "epoch:1 step:1408 [D loss: 0.642680, acc.: 63.28%] [G loss: 0.957775]\n",
      "epoch:1 step:1409 [D loss: 0.751430, acc.: 46.09%] [G loss: 0.975877]\n",
      "epoch:1 step:1410 [D loss: 0.716067, acc.: 53.12%] [G loss: 0.947656]\n",
      "epoch:1 step:1411 [D loss: 0.757370, acc.: 50.00%] [G loss: 0.933730]\n",
      "epoch:1 step:1412 [D loss: 0.728710, acc.: 48.44%] [G loss: 0.893113]\n",
      "epoch:1 step:1413 [D loss: 0.666112, acc.: 57.81%] [G loss: 0.906668]\n",
      "epoch:1 step:1414 [D loss: 0.778371, acc.: 50.00%] [G loss: 0.823841]\n",
      "epoch:1 step:1415 [D loss: 0.627312, acc.: 64.84%] [G loss: 0.958593]\n",
      "epoch:1 step:1416 [D loss: 0.693906, acc.: 60.16%] [G loss: 0.965834]\n",
      "epoch:1 step:1417 [D loss: 0.731974, acc.: 57.03%] [G loss: 0.967978]\n",
      "epoch:1 step:1418 [D loss: 0.657576, acc.: 62.50%] [G loss: 1.003539]\n",
      "epoch:1 step:1419 [D loss: 0.687612, acc.: 57.81%] [G loss: 0.970915]\n",
      "epoch:1 step:1420 [D loss: 0.716094, acc.: 51.56%] [G loss: 0.983591]\n",
      "epoch:1 step:1421 [D loss: 0.674582, acc.: 60.94%] [G loss: 0.919715]\n",
      "epoch:1 step:1422 [D loss: 0.689039, acc.: 57.81%] [G loss: 0.966373]\n",
      "epoch:1 step:1423 [D loss: 0.747644, acc.: 50.78%] [G loss: 0.990017]\n",
      "epoch:1 step:1424 [D loss: 0.679955, acc.: 53.91%] [G loss: 1.006096]\n",
      "epoch:1 step:1425 [D loss: 0.688395, acc.: 60.16%] [G loss: 0.994269]\n",
      "epoch:1 step:1426 [D loss: 0.694386, acc.: 59.38%] [G loss: 0.927452]\n",
      "epoch:1 step:1427 [D loss: 0.676807, acc.: 57.03%] [G loss: 1.023783]\n",
      "epoch:1 step:1428 [D loss: 0.710045, acc.: 55.47%] [G loss: 0.991700]\n",
      "epoch:1 step:1429 [D loss: 0.663136, acc.: 62.50%] [G loss: 0.874159]\n",
      "epoch:1 step:1430 [D loss: 0.767863, acc.: 47.66%] [G loss: 0.890343]\n",
      "epoch:1 step:1431 [D loss: 0.681030, acc.: 56.25%] [G loss: 0.888842]\n",
      "epoch:1 step:1432 [D loss: 0.654661, acc.: 62.50%] [G loss: 0.923213]\n",
      "epoch:1 step:1433 [D loss: 0.758228, acc.: 47.66%] [G loss: 0.909467]\n",
      "epoch:1 step:1434 [D loss: 0.709784, acc.: 56.25%] [G loss: 0.965541]\n",
      "epoch:1 step:1435 [D loss: 0.643108, acc.: 68.75%] [G loss: 1.063835]\n",
      "epoch:1 step:1436 [D loss: 0.650449, acc.: 65.62%] [G loss: 1.012745]\n",
      "epoch:1 step:1437 [D loss: 0.743780, acc.: 49.22%] [G loss: 0.917767]\n",
      "epoch:1 step:1438 [D loss: 0.797665, acc.: 48.44%] [G loss: 0.862893]\n",
      "epoch:1 step:1439 [D loss: 0.732456, acc.: 53.12%] [G loss: 0.837346]\n",
      "epoch:1 step:1440 [D loss: 0.674554, acc.: 60.94%] [G loss: 0.960295]\n",
      "epoch:1 step:1441 [D loss: 0.651964, acc.: 59.38%] [G loss: 1.025636]\n",
      "epoch:1 step:1442 [D loss: 0.757643, acc.: 50.78%] [G loss: 0.982997]\n",
      "epoch:1 step:1443 [D loss: 0.717583, acc.: 53.12%] [G loss: 0.917782]\n",
      "epoch:1 step:1444 [D loss: 0.724384, acc.: 48.44%] [G loss: 0.994543]\n",
      "epoch:1 step:1445 [D loss: 0.687230, acc.: 57.81%] [G loss: 0.958852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1446 [D loss: 0.742635, acc.: 53.91%] [G loss: 1.004089]\n",
      "epoch:1 step:1447 [D loss: 0.682760, acc.: 60.16%] [G loss: 0.913206]\n",
      "epoch:1 step:1448 [D loss: 0.832814, acc.: 39.84%] [G loss: 0.838387]\n",
      "epoch:1 step:1449 [D loss: 0.709208, acc.: 52.34%] [G loss: 0.900801]\n",
      "epoch:1 step:1450 [D loss: 0.646359, acc.: 64.84%] [G loss: 0.951066]\n",
      "epoch:1 step:1451 [D loss: 0.713227, acc.: 49.22%] [G loss: 0.941228]\n",
      "epoch:1 step:1452 [D loss: 0.680693, acc.: 56.25%] [G loss: 0.958669]\n",
      "epoch:1 step:1453 [D loss: 0.619260, acc.: 69.53%] [G loss: 0.980072]\n",
      "epoch:1 step:1454 [D loss: 0.723237, acc.: 49.22%] [G loss: 0.981761]\n",
      "epoch:1 step:1455 [D loss: 0.704669, acc.: 57.03%] [G loss: 0.982184]\n",
      "epoch:1 step:1456 [D loss: 0.657536, acc.: 64.06%] [G loss: 0.927254]\n",
      "epoch:1 step:1457 [D loss: 0.645170, acc.: 60.94%] [G loss: 0.877949]\n",
      "epoch:1 step:1458 [D loss: 0.698569, acc.: 52.34%] [G loss: 0.885630]\n",
      "epoch:1 step:1459 [D loss: 0.621584, acc.: 62.50%] [G loss: 0.989115]\n",
      "epoch:1 step:1460 [D loss: 0.700366, acc.: 51.56%] [G loss: 0.938179]\n",
      "epoch:1 step:1461 [D loss: 0.739143, acc.: 46.88%] [G loss: 0.907055]\n",
      "epoch:1 step:1462 [D loss: 0.672796, acc.: 61.72%] [G loss: 0.980160]\n",
      "epoch:1 step:1463 [D loss: 0.738402, acc.: 53.12%] [G loss: 0.889157]\n",
      "epoch:1 step:1464 [D loss: 0.694600, acc.: 61.72%] [G loss: 0.864770]\n",
      "epoch:1 step:1465 [D loss: 0.758563, acc.: 46.09%] [G loss: 0.870740]\n",
      "epoch:1 step:1466 [D loss: 0.695932, acc.: 59.38%] [G loss: 0.904629]\n",
      "epoch:1 step:1467 [D loss: 0.673022, acc.: 60.94%] [G loss: 1.050333]\n",
      "epoch:1 step:1468 [D loss: 0.747420, acc.: 50.78%] [G loss: 0.935117]\n",
      "epoch:1 step:1469 [D loss: 0.685633, acc.: 54.69%] [G loss: 0.760537]\n",
      "epoch:1 step:1470 [D loss: 0.764058, acc.: 48.44%] [G loss: 0.968411]\n",
      "epoch:1 step:1471 [D loss: 0.647706, acc.: 57.81%] [G loss: 1.022200]\n",
      "epoch:1 step:1472 [D loss: 0.727149, acc.: 50.78%] [G loss: 0.904055]\n",
      "epoch:1 step:1473 [D loss: 0.693291, acc.: 60.16%] [G loss: 1.014919]\n",
      "epoch:1 step:1474 [D loss: 0.733771, acc.: 48.44%] [G loss: 0.870040]\n",
      "epoch:1 step:1475 [D loss: 0.671360, acc.: 61.72%] [G loss: 0.905846]\n",
      "epoch:1 step:1476 [D loss: 0.689429, acc.: 57.03%] [G loss: 0.839807]\n",
      "epoch:1 step:1477 [D loss: 0.710128, acc.: 55.47%] [G loss: 0.872414]\n",
      "epoch:1 step:1478 [D loss: 0.694907, acc.: 51.56%] [G loss: 1.000885]\n",
      "epoch:1 step:1479 [D loss: 0.763729, acc.: 48.44%] [G loss: 0.922868]\n",
      "epoch:1 step:1480 [D loss: 0.735625, acc.: 46.09%] [G loss: 0.969184]\n",
      "epoch:1 step:1481 [D loss: 0.751438, acc.: 48.44%] [G loss: 0.864770]\n",
      "epoch:1 step:1482 [D loss: 0.659387, acc.: 63.28%] [G loss: 0.984872]\n",
      "epoch:1 step:1483 [D loss: 0.686775, acc.: 57.81%] [G loss: 0.973896]\n",
      "epoch:1 step:1484 [D loss: 0.660758, acc.: 58.59%] [G loss: 0.991915]\n",
      "epoch:1 step:1485 [D loss: 0.687665, acc.: 55.47%] [G loss: 1.083393]\n",
      "epoch:1 step:1486 [D loss: 0.675001, acc.: 61.72%] [G loss: 0.976457]\n",
      "epoch:1 step:1487 [D loss: 0.670140, acc.: 63.28%] [G loss: 1.014362]\n",
      "epoch:1 step:1488 [D loss: 0.635596, acc.: 63.28%] [G loss: 1.000642]\n",
      "epoch:1 step:1489 [D loss: 0.660502, acc.: 60.16%] [G loss: 0.952730]\n",
      "epoch:1 step:1490 [D loss: 0.659473, acc.: 58.59%] [G loss: 1.000441]\n",
      "epoch:1 step:1491 [D loss: 0.608023, acc.: 65.62%] [G loss: 0.893967]\n",
      "epoch:1 step:1492 [D loss: 0.660257, acc.: 61.72%] [G loss: 1.040118]\n",
      "epoch:1 step:1493 [D loss: 0.625381, acc.: 64.84%] [G loss: 1.108308]\n",
      "epoch:1 step:1494 [D loss: 0.698233, acc.: 64.06%] [G loss: 0.884344]\n",
      "epoch:1 step:1495 [D loss: 0.623935, acc.: 64.06%] [G loss: 1.121746]\n",
      "epoch:1 step:1496 [D loss: 0.746711, acc.: 53.12%] [G loss: 0.980465]\n",
      "epoch:1 step:1497 [D loss: 0.675693, acc.: 57.81%] [G loss: 0.959180]\n",
      "epoch:1 step:1498 [D loss: 0.785496, acc.: 40.62%] [G loss: 1.022750]\n",
      "epoch:1 step:1499 [D loss: 0.729545, acc.: 55.47%] [G loss: 0.985733]\n",
      "epoch:1 step:1500 [D loss: 0.677415, acc.: 56.25%] [G loss: 1.072201]\n",
      "epoch:1 step:1501 [D loss: 0.691020, acc.: 52.34%] [G loss: 0.889164]\n",
      "epoch:1 step:1502 [D loss: 0.749636, acc.: 54.69%] [G loss: 0.994988]\n",
      "epoch:1 step:1503 [D loss: 0.630966, acc.: 57.03%] [G loss: 0.985502]\n",
      "epoch:1 step:1504 [D loss: 0.695265, acc.: 60.16%] [G loss: 1.020926]\n",
      "epoch:1 step:1505 [D loss: 0.684270, acc.: 56.25%] [G loss: 1.009299]\n",
      "epoch:1 step:1506 [D loss: 0.688010, acc.: 55.47%] [G loss: 0.901799]\n",
      "epoch:1 step:1507 [D loss: 0.701076, acc.: 57.03%] [G loss: 0.966695]\n",
      "epoch:1 step:1508 [D loss: 0.662705, acc.: 60.94%] [G loss: 0.838370]\n",
      "epoch:1 step:1509 [D loss: 0.704636, acc.: 56.25%] [G loss: 0.954913]\n",
      "epoch:1 step:1510 [D loss: 0.722948, acc.: 52.34%] [G loss: 0.947662]\n",
      "epoch:1 step:1511 [D loss: 0.677842, acc.: 57.81%] [G loss: 0.991442]\n",
      "epoch:1 step:1512 [D loss: 0.710670, acc.: 52.34%] [G loss: 0.805379]\n",
      "epoch:1 step:1513 [D loss: 0.688148, acc.: 53.91%] [G loss: 0.929263]\n",
      "epoch:1 step:1514 [D loss: 0.700767, acc.: 51.56%] [G loss: 0.928860]\n",
      "epoch:1 step:1515 [D loss: 0.690467, acc.: 57.03%] [G loss: 1.012708]\n",
      "epoch:1 step:1516 [D loss: 0.764707, acc.: 52.34%] [G loss: 0.942284]\n",
      "epoch:1 step:1517 [D loss: 0.721123, acc.: 50.78%] [G loss: 0.956911]\n",
      "epoch:1 step:1518 [D loss: 0.703251, acc.: 56.25%] [G loss: 0.983854]\n",
      "epoch:1 step:1519 [D loss: 0.667753, acc.: 55.47%] [G loss: 0.963001]\n",
      "epoch:1 step:1520 [D loss: 0.714475, acc.: 53.91%] [G loss: 0.822835]\n",
      "epoch:1 step:1521 [D loss: 0.730568, acc.: 50.00%] [G loss: 0.965947]\n",
      "epoch:1 step:1522 [D loss: 0.719405, acc.: 48.44%] [G loss: 0.962792]\n",
      "epoch:1 step:1523 [D loss: 0.705276, acc.: 51.56%] [G loss: 1.054708]\n",
      "epoch:1 step:1524 [D loss: 0.700282, acc.: 53.12%] [G loss: 1.042338]\n",
      "epoch:1 step:1525 [D loss: 0.679261, acc.: 60.16%] [G loss: 0.958533]\n",
      "epoch:1 step:1526 [D loss: 0.706327, acc.: 56.25%] [G loss: 1.012080]\n",
      "epoch:1 step:1527 [D loss: 0.700565, acc.: 56.25%] [G loss: 0.886178]\n",
      "epoch:1 step:1528 [D loss: 0.699878, acc.: 51.56%] [G loss: 0.855040]\n",
      "epoch:1 step:1529 [D loss: 0.699054, acc.: 53.91%] [G loss: 0.899348]\n",
      "epoch:1 step:1530 [D loss: 0.724652, acc.: 47.66%] [G loss: 0.917225]\n",
      "epoch:1 step:1531 [D loss: 0.679123, acc.: 54.69%] [G loss: 0.930944]\n",
      "epoch:1 step:1532 [D loss: 0.704685, acc.: 53.12%] [G loss: 0.944272]\n",
      "epoch:1 step:1533 [D loss: 0.678675, acc.: 56.25%] [G loss: 0.929886]\n",
      "epoch:1 step:1534 [D loss: 0.686639, acc.: 60.94%] [G loss: 0.972199]\n",
      "epoch:1 step:1535 [D loss: 0.680455, acc.: 59.38%] [G loss: 0.937808]\n",
      "epoch:1 step:1536 [D loss: 0.723107, acc.: 49.22%] [G loss: 0.948431]\n",
      "epoch:1 step:1537 [D loss: 0.692183, acc.: 53.12%] [G loss: 0.952310]\n",
      "epoch:1 step:1538 [D loss: 0.707361, acc.: 53.12%] [G loss: 0.902244]\n",
      "epoch:1 step:1539 [D loss: 0.691334, acc.: 58.59%] [G loss: 0.863272]\n",
      "epoch:1 step:1540 [D loss: 0.652677, acc.: 62.50%] [G loss: 1.048213]\n",
      "epoch:1 step:1541 [D loss: 0.698066, acc.: 57.03%] [G loss: 0.916486]\n",
      "epoch:1 step:1542 [D loss: 0.723305, acc.: 53.12%] [G loss: 0.903942]\n",
      "epoch:1 step:1543 [D loss: 0.680861, acc.: 54.69%] [G loss: 0.965457]\n",
      "epoch:1 step:1544 [D loss: 0.722821, acc.: 50.78%] [G loss: 1.064009]\n",
      "epoch:1 step:1545 [D loss: 0.644904, acc.: 64.06%] [G loss: 0.896078]\n",
      "epoch:1 step:1546 [D loss: 0.683675, acc.: 57.03%] [G loss: 1.044630]\n",
      "epoch:1 step:1547 [D loss: 0.668827, acc.: 57.81%] [G loss: 0.951149]\n",
      "epoch:1 step:1548 [D loss: 0.685789, acc.: 57.81%] [G loss: 1.026571]\n",
      "epoch:1 step:1549 [D loss: 0.667673, acc.: 61.72%] [G loss: 0.928640]\n",
      "epoch:1 step:1550 [D loss: 0.668827, acc.: 59.38%] [G loss: 0.867898]\n",
      "epoch:1 step:1551 [D loss: 0.728610, acc.: 47.66%] [G loss: 1.014786]\n",
      "epoch:1 step:1552 [D loss: 0.711322, acc.: 53.91%] [G loss: 0.865187]\n",
      "epoch:1 step:1553 [D loss: 0.704827, acc.: 53.91%] [G loss: 0.960765]\n",
      "epoch:1 step:1554 [D loss: 0.740232, acc.: 54.69%] [G loss: 0.891169]\n",
      "epoch:1 step:1555 [D loss: 0.744852, acc.: 52.34%] [G loss: 0.926546]\n",
      "epoch:1 step:1556 [D loss: 0.648076, acc.: 61.72%] [G loss: 0.879901]\n",
      "epoch:1 step:1557 [D loss: 0.687632, acc.: 52.34%] [G loss: 0.876120]\n",
      "epoch:1 step:1558 [D loss: 0.661121, acc.: 56.25%] [G loss: 0.916557]\n",
      "epoch:1 step:1559 [D loss: 0.722240, acc.: 50.00%] [G loss: 0.896590]\n",
      "epoch:1 step:1560 [D loss: 0.749875, acc.: 50.00%] [G loss: 0.942677]\n",
      "epoch:1 step:1561 [D loss: 0.702820, acc.: 53.12%] [G loss: 0.989305]\n",
      "epoch:1 step:1562 [D loss: 0.691085, acc.: 56.25%] [G loss: 0.952976]\n",
      "epoch:1 step:1563 [D loss: 0.701059, acc.: 46.09%] [G loss: 0.924191]\n",
      "epoch:1 step:1564 [D loss: 0.667134, acc.: 60.94%] [G loss: 0.950358]\n",
      "epoch:1 step:1565 [D loss: 0.674019, acc.: 60.94%] [G loss: 0.953074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1566 [D loss: 0.671468, acc.: 63.28%] [G loss: 0.920038]\n",
      "epoch:1 step:1567 [D loss: 0.685908, acc.: 57.81%] [G loss: 0.980144]\n",
      "epoch:1 step:1568 [D loss: 0.672710, acc.: 56.25%] [G loss: 1.061239]\n",
      "epoch:1 step:1569 [D loss: 0.740870, acc.: 54.69%] [G loss: 0.908270]\n",
      "epoch:1 step:1570 [D loss: 0.700618, acc.: 53.91%] [G loss: 0.856492]\n",
      "epoch:1 step:1571 [D loss: 0.606353, acc.: 66.41%] [G loss: 0.991952]\n",
      "epoch:1 step:1572 [D loss: 0.640988, acc.: 63.28%] [G loss: 0.908414]\n",
      "epoch:1 step:1573 [D loss: 0.639564, acc.: 65.62%] [G loss: 1.003692]\n",
      "epoch:1 step:1574 [D loss: 0.675722, acc.: 60.94%] [G loss: 0.939011]\n",
      "epoch:1 step:1575 [D loss: 0.743252, acc.: 44.53%] [G loss: 0.999080]\n",
      "epoch:1 step:1576 [D loss: 0.672775, acc.: 62.50%] [G loss: 0.962288]\n",
      "epoch:1 step:1577 [D loss: 0.671405, acc.: 58.59%] [G loss: 0.941578]\n",
      "epoch:1 step:1578 [D loss: 0.718106, acc.: 50.00%] [G loss: 0.960608]\n",
      "epoch:1 step:1579 [D loss: 0.657068, acc.: 60.16%] [G loss: 1.020377]\n",
      "epoch:1 step:1580 [D loss: 0.627265, acc.: 61.72%] [G loss: 0.973377]\n",
      "epoch:1 step:1581 [D loss: 0.791284, acc.: 42.19%] [G loss: 0.921659]\n",
      "epoch:1 step:1582 [D loss: 0.691436, acc.: 62.50%] [G loss: 0.936262]\n",
      "epoch:1 step:1583 [D loss: 0.642994, acc.: 65.62%] [G loss: 0.944326]\n",
      "epoch:1 step:1584 [D loss: 0.653376, acc.: 62.50%] [G loss: 0.962294]\n",
      "epoch:1 step:1585 [D loss: 0.630207, acc.: 65.62%] [G loss: 1.020457]\n",
      "epoch:1 step:1586 [D loss: 0.667677, acc.: 53.12%] [G loss: 0.973806]\n",
      "epoch:1 step:1587 [D loss: 0.691482, acc.: 59.38%] [G loss: 1.005078]\n",
      "epoch:1 step:1588 [D loss: 0.599730, acc.: 67.97%] [G loss: 0.982488]\n",
      "epoch:1 step:1589 [D loss: 0.701419, acc.: 57.81%] [G loss: 0.927419]\n",
      "epoch:1 step:1590 [D loss: 0.783118, acc.: 42.97%] [G loss: 0.879263]\n",
      "epoch:1 step:1591 [D loss: 0.727026, acc.: 55.47%] [G loss: 0.923715]\n",
      "epoch:1 step:1592 [D loss: 0.687534, acc.: 60.94%] [G loss: 0.959964]\n",
      "epoch:1 step:1593 [D loss: 0.664242, acc.: 58.59%] [G loss: 0.833640]\n",
      "epoch:1 step:1594 [D loss: 0.690076, acc.: 56.25%] [G loss: 0.899216]\n",
      "epoch:1 step:1595 [D loss: 0.704384, acc.: 57.03%] [G loss: 0.960307]\n",
      "epoch:1 step:1596 [D loss: 0.686055, acc.: 60.94%] [G loss: 0.952087]\n",
      "epoch:1 step:1597 [D loss: 0.656240, acc.: 59.38%] [G loss: 0.982143]\n",
      "epoch:1 step:1598 [D loss: 0.620359, acc.: 68.75%] [G loss: 0.899093]\n",
      "epoch:1 step:1599 [D loss: 0.725202, acc.: 50.78%] [G loss: 0.921423]\n",
      "epoch:1 step:1600 [D loss: 0.682544, acc.: 61.72%] [G loss: 0.998690]\n",
      "epoch:1 step:1601 [D loss: 0.646330, acc.: 59.38%] [G loss: 0.967564]\n",
      "epoch:1 step:1602 [D loss: 0.677988, acc.: 60.94%] [G loss: 0.950888]\n",
      "epoch:1 step:1603 [D loss: 0.735585, acc.: 57.03%] [G loss: 0.984577]\n",
      "epoch:1 step:1604 [D loss: 0.713475, acc.: 51.56%] [G loss: 0.880877]\n",
      "epoch:1 step:1605 [D loss: 0.678870, acc.: 54.69%] [G loss: 0.975141]\n",
      "epoch:1 step:1606 [D loss: 0.712247, acc.: 53.91%] [G loss: 0.936770]\n",
      "epoch:1 step:1607 [D loss: 0.747070, acc.: 47.66%] [G loss: 0.831984]\n",
      "epoch:1 step:1608 [D loss: 0.725748, acc.: 45.31%] [G loss: 0.980585]\n",
      "epoch:1 step:1609 [D loss: 0.738755, acc.: 53.91%] [G loss: 1.001907]\n",
      "epoch:1 step:1610 [D loss: 0.711746, acc.: 52.34%] [G loss: 0.984086]\n",
      "epoch:1 step:1611 [D loss: 0.722839, acc.: 55.47%] [G loss: 1.029056]\n",
      "epoch:1 step:1612 [D loss: 0.710094, acc.: 53.12%] [G loss: 1.017600]\n",
      "epoch:1 step:1613 [D loss: 0.665497, acc.: 60.94%] [G loss: 0.947582]\n",
      "epoch:1 step:1614 [D loss: 0.658225, acc.: 66.41%] [G loss: 0.924488]\n",
      "epoch:1 step:1615 [D loss: 0.669277, acc.: 60.16%] [G loss: 0.943686]\n",
      "epoch:1 step:1616 [D loss: 0.732258, acc.: 53.12%] [G loss: 0.977274]\n",
      "epoch:1 step:1617 [D loss: 0.733224, acc.: 53.12%] [G loss: 0.870639]\n",
      "epoch:1 step:1618 [D loss: 0.714152, acc.: 51.56%] [G loss: 0.892926]\n",
      "epoch:1 step:1619 [D loss: 0.673043, acc.: 59.38%] [G loss: 1.094746]\n",
      "epoch:1 step:1620 [D loss: 0.696325, acc.: 54.69%] [G loss: 0.935882]\n",
      "epoch:1 step:1621 [D loss: 0.703161, acc.: 57.81%] [G loss: 0.975891]\n",
      "epoch:1 step:1622 [D loss: 0.747456, acc.: 54.69%] [G loss: 0.923726]\n",
      "epoch:1 step:1623 [D loss: 0.667738, acc.: 62.50%] [G loss: 0.913432]\n",
      "epoch:1 step:1624 [D loss: 0.665029, acc.: 64.06%] [G loss: 1.055383]\n",
      "epoch:1 step:1625 [D loss: 0.665414, acc.: 59.38%] [G loss: 0.978972]\n",
      "epoch:1 step:1626 [D loss: 0.749121, acc.: 48.44%] [G loss: 0.877333]\n",
      "epoch:1 step:1627 [D loss: 0.672743, acc.: 60.16%] [G loss: 0.977023]\n",
      "epoch:1 step:1628 [D loss: 0.660394, acc.: 60.94%] [G loss: 1.010890]\n",
      "epoch:1 step:1629 [D loss: 0.704447, acc.: 53.91%] [G loss: 0.973554]\n",
      "epoch:1 step:1630 [D loss: 0.667109, acc.: 59.38%] [G loss: 1.017915]\n",
      "epoch:1 step:1631 [D loss: 0.641546, acc.: 60.16%] [G loss: 1.017589]\n",
      "epoch:1 step:1632 [D loss: 0.706683, acc.: 53.91%] [G loss: 0.937703]\n",
      "epoch:1 step:1633 [D loss: 0.683949, acc.: 55.47%] [G loss: 0.827509]\n",
      "epoch:1 step:1634 [D loss: 0.689998, acc.: 64.06%] [G loss: 1.044970]\n",
      "epoch:1 step:1635 [D loss: 0.683187, acc.: 58.59%] [G loss: 1.001436]\n",
      "epoch:1 step:1636 [D loss: 0.740961, acc.: 49.22%] [G loss: 0.935704]\n",
      "epoch:1 step:1637 [D loss: 0.633979, acc.: 64.06%] [G loss: 1.038899]\n",
      "epoch:1 step:1638 [D loss: 0.711558, acc.: 55.47%] [G loss: 1.008347]\n",
      "epoch:1 step:1639 [D loss: 0.697913, acc.: 53.12%] [G loss: 1.099336]\n",
      "epoch:1 step:1640 [D loss: 0.708975, acc.: 57.81%] [G loss: 0.954203]\n",
      "epoch:1 step:1641 [D loss: 0.670206, acc.: 58.59%] [G loss: 1.021722]\n",
      "epoch:1 step:1642 [D loss: 0.685272, acc.: 54.69%] [G loss: 0.935349]\n",
      "epoch:1 step:1643 [D loss: 0.604667, acc.: 69.53%] [G loss: 0.998239]\n",
      "epoch:1 step:1644 [D loss: 0.633343, acc.: 61.72%] [G loss: 1.031254]\n",
      "epoch:1 step:1645 [D loss: 0.675651, acc.: 53.91%] [G loss: 1.035657]\n",
      "epoch:1 step:1646 [D loss: 0.588279, acc.: 71.09%] [G loss: 0.985960]\n",
      "epoch:1 step:1647 [D loss: 0.731273, acc.: 52.34%] [G loss: 1.047211]\n",
      "epoch:1 step:1648 [D loss: 0.806770, acc.: 44.53%] [G loss: 0.900003]\n",
      "epoch:1 step:1649 [D loss: 0.620484, acc.: 63.28%] [G loss: 0.903266]\n",
      "epoch:1 step:1650 [D loss: 0.630736, acc.: 64.84%] [G loss: 0.985984]\n",
      "epoch:1 step:1651 [D loss: 0.617756, acc.: 67.19%] [G loss: 0.901785]\n",
      "epoch:1 step:1652 [D loss: 0.658111, acc.: 61.72%] [G loss: 1.098163]\n",
      "epoch:1 step:1653 [D loss: 0.742694, acc.: 55.47%] [G loss: 0.933821]\n",
      "epoch:1 step:1654 [D loss: 0.775225, acc.: 46.09%] [G loss: 0.847021]\n",
      "epoch:1 step:1655 [D loss: 0.701724, acc.: 53.91%] [G loss: 0.914928]\n",
      "epoch:1 step:1656 [D loss: 0.722736, acc.: 55.47%] [G loss: 0.871378]\n",
      "epoch:1 step:1657 [D loss: 0.730392, acc.: 51.56%] [G loss: 0.937015]\n",
      "epoch:1 step:1658 [D loss: 0.722506, acc.: 50.00%] [G loss: 0.860068]\n",
      "epoch:1 step:1659 [D loss: 0.707085, acc.: 59.38%] [G loss: 0.877075]\n",
      "epoch:1 step:1660 [D loss: 0.703898, acc.: 57.03%] [G loss: 0.989473]\n",
      "epoch:1 step:1661 [D loss: 0.747277, acc.: 51.56%] [G loss: 0.833930]\n",
      "epoch:1 step:1662 [D loss: 0.697242, acc.: 50.78%] [G loss: 0.916020]\n",
      "epoch:1 step:1663 [D loss: 0.730721, acc.: 52.34%] [G loss: 0.854695]\n",
      "epoch:1 step:1664 [D loss: 0.714164, acc.: 55.47%] [G loss: 1.001632]\n",
      "epoch:1 step:1665 [D loss: 0.578097, acc.: 71.09%] [G loss: 1.009439]\n",
      "epoch:1 step:1666 [D loss: 0.678550, acc.: 60.94%] [G loss: 0.972556]\n",
      "epoch:1 step:1667 [D loss: 0.658370, acc.: 63.28%] [G loss: 0.911097]\n",
      "epoch:1 step:1668 [D loss: 0.659102, acc.: 60.16%] [G loss: 0.985415]\n",
      "epoch:1 step:1669 [D loss: 0.601383, acc.: 75.00%] [G loss: 0.903408]\n",
      "epoch:1 step:1670 [D loss: 0.635088, acc.: 67.19%] [G loss: 1.008838]\n",
      "epoch:1 step:1671 [D loss: 0.765507, acc.: 53.12%] [G loss: 0.935545]\n",
      "epoch:1 step:1672 [D loss: 0.742958, acc.: 49.22%] [G loss: 1.003796]\n",
      "epoch:1 step:1673 [D loss: 0.667560, acc.: 62.50%] [G loss: 0.887448]\n",
      "epoch:1 step:1674 [D loss: 0.699677, acc.: 58.59%] [G loss: 0.931404]\n",
      "epoch:1 step:1675 [D loss: 0.664686, acc.: 60.94%] [G loss: 0.948446]\n",
      "epoch:1 step:1676 [D loss: 0.702092, acc.: 53.12%] [G loss: 0.874190]\n",
      "epoch:1 step:1677 [D loss: 0.682728, acc.: 59.38%] [G loss: 0.988601]\n",
      "epoch:1 step:1678 [D loss: 0.715999, acc.: 54.69%] [G loss: 0.993458]\n",
      "epoch:1 step:1679 [D loss: 0.687959, acc.: 58.59%] [G loss: 0.858361]\n",
      "epoch:1 step:1680 [D loss: 0.601398, acc.: 68.75%] [G loss: 0.934447]\n",
      "epoch:1 step:1681 [D loss: 0.761489, acc.: 49.22%] [G loss: 0.935264]\n",
      "epoch:1 step:1682 [D loss: 0.701510, acc.: 57.03%] [G loss: 0.881644]\n",
      "epoch:1 step:1683 [D loss: 0.673945, acc.: 60.16%] [G loss: 0.869792]\n",
      "epoch:1 step:1684 [D loss: 0.623011, acc.: 69.53%] [G loss: 1.015084]\n",
      "epoch:1 step:1685 [D loss: 0.655276, acc.: 59.38%] [G loss: 0.989707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1686 [D loss: 0.741991, acc.: 51.56%] [G loss: 0.880349]\n",
      "epoch:1 step:1687 [D loss: 0.639480, acc.: 60.94%] [G loss: 0.959967]\n",
      "epoch:1 step:1688 [D loss: 0.756974, acc.: 50.00%] [G loss: 0.972178]\n",
      "epoch:1 step:1689 [D loss: 0.676993, acc.: 57.81%] [G loss: 0.854790]\n",
      "epoch:1 step:1690 [D loss: 0.684182, acc.: 62.50%] [G loss: 0.852384]\n",
      "epoch:1 step:1691 [D loss: 0.696140, acc.: 51.56%] [G loss: 0.947613]\n",
      "epoch:1 step:1692 [D loss: 0.694195, acc.: 57.03%] [G loss: 0.988146]\n",
      "epoch:1 step:1693 [D loss: 0.700890, acc.: 54.69%] [G loss: 0.835435]\n",
      "epoch:1 step:1694 [D loss: 0.630758, acc.: 65.62%] [G loss: 0.991425]\n",
      "epoch:1 step:1695 [D loss: 0.671110, acc.: 58.59%] [G loss: 1.014925]\n",
      "epoch:1 step:1696 [D loss: 0.735636, acc.: 47.66%] [G loss: 0.940682]\n",
      "epoch:1 step:1697 [D loss: 0.686758, acc.: 58.59%] [G loss: 0.980138]\n",
      "epoch:1 step:1698 [D loss: 0.644286, acc.: 65.62%] [G loss: 0.964184]\n",
      "epoch:1 step:1699 [D loss: 0.710767, acc.: 54.69%] [G loss: 0.987772]\n",
      "epoch:1 step:1700 [D loss: 0.692790, acc.: 58.59%] [G loss: 0.942761]\n",
      "epoch:1 step:1701 [D loss: 0.648370, acc.: 61.72%] [G loss: 0.892402]\n",
      "epoch:1 step:1702 [D loss: 0.761255, acc.: 52.34%] [G loss: 0.778332]\n",
      "epoch:1 step:1703 [D loss: 0.740798, acc.: 48.44%] [G loss: 0.886538]\n",
      "epoch:1 step:1704 [D loss: 0.699477, acc.: 55.47%] [G loss: 0.954924]\n",
      "epoch:1 step:1705 [D loss: 0.737219, acc.: 51.56%] [G loss: 0.855534]\n",
      "epoch:1 step:1706 [D loss: 0.646008, acc.: 61.72%] [G loss: 0.926442]\n",
      "epoch:1 step:1707 [D loss: 0.646255, acc.: 59.38%] [G loss: 1.049054]\n",
      "epoch:1 step:1708 [D loss: 0.651063, acc.: 63.28%] [G loss: 0.952990]\n",
      "epoch:1 step:1709 [D loss: 0.715102, acc.: 53.91%] [G loss: 0.904478]\n",
      "epoch:1 step:1710 [D loss: 0.655233, acc.: 54.69%] [G loss: 1.051337]\n",
      "epoch:1 step:1711 [D loss: 0.676245, acc.: 57.81%] [G loss: 0.911867]\n",
      "epoch:1 step:1712 [D loss: 0.704571, acc.: 59.38%] [G loss: 0.946739]\n",
      "epoch:1 step:1713 [D loss: 0.728780, acc.: 53.91%] [G loss: 0.947118]\n",
      "epoch:1 step:1714 [D loss: 0.682619, acc.: 59.38%] [G loss: 0.946146]\n",
      "epoch:1 step:1715 [D loss: 0.714990, acc.: 57.03%] [G loss: 0.959288]\n",
      "epoch:1 step:1716 [D loss: 0.769655, acc.: 52.34%] [G loss: 0.987494]\n",
      "epoch:1 step:1717 [D loss: 0.823010, acc.: 39.84%] [G loss: 0.860921]\n",
      "epoch:1 step:1718 [D loss: 0.730690, acc.: 46.09%] [G loss: 0.967638]\n",
      "epoch:1 step:1719 [D loss: 0.635781, acc.: 59.38%] [G loss: 1.021681]\n",
      "epoch:1 step:1720 [D loss: 0.689714, acc.: 53.91%] [G loss: 0.943465]\n",
      "epoch:1 step:1721 [D loss: 0.719602, acc.: 48.44%] [G loss: 0.852798]\n",
      "epoch:1 step:1722 [D loss: 0.665689, acc.: 60.16%] [G loss: 1.003706]\n",
      "epoch:1 step:1723 [D loss: 0.668951, acc.: 60.94%] [G loss: 0.896373]\n",
      "epoch:1 step:1724 [D loss: 0.676394, acc.: 58.59%] [G loss: 0.981711]\n",
      "epoch:1 step:1725 [D loss: 0.786943, acc.: 44.53%] [G loss: 0.953872]\n",
      "epoch:1 step:1726 [D loss: 0.697480, acc.: 58.59%] [G loss: 0.962377]\n",
      "epoch:1 step:1727 [D loss: 0.671673, acc.: 62.50%] [G loss: 0.964053]\n",
      "epoch:1 step:1728 [D loss: 0.716091, acc.: 50.78%] [G loss: 0.917276]\n",
      "epoch:1 step:1729 [D loss: 0.663872, acc.: 56.25%] [G loss: 1.008048]\n",
      "epoch:1 step:1730 [D loss: 0.651474, acc.: 58.59%] [G loss: 0.964155]\n",
      "epoch:1 step:1731 [D loss: 0.733897, acc.: 55.47%] [G loss: 0.932778]\n",
      "epoch:1 step:1732 [D loss: 0.753013, acc.: 53.12%] [G loss: 0.879845]\n",
      "epoch:1 step:1733 [D loss: 0.690748, acc.: 62.50%] [G loss: 0.988448]\n",
      "epoch:1 step:1734 [D loss: 0.728726, acc.: 53.91%] [G loss: 0.981465]\n",
      "epoch:1 step:1735 [D loss: 0.616348, acc.: 64.84%] [G loss: 1.008089]\n",
      "epoch:1 step:1736 [D loss: 0.673256, acc.: 63.28%] [G loss: 0.863413]\n",
      "epoch:1 step:1737 [D loss: 0.681205, acc.: 54.69%] [G loss: 0.911575]\n",
      "epoch:1 step:1738 [D loss: 0.717418, acc.: 55.47%] [G loss: 0.874074]\n",
      "epoch:1 step:1739 [D loss: 0.733021, acc.: 48.44%] [G loss: 0.821461]\n",
      "epoch:1 step:1740 [D loss: 0.646120, acc.: 62.50%] [G loss: 0.907069]\n",
      "epoch:1 step:1741 [D loss: 0.686092, acc.: 57.81%] [G loss: 0.975853]\n",
      "epoch:1 step:1742 [D loss: 0.685454, acc.: 57.81%] [G loss: 0.958556]\n",
      "epoch:1 step:1743 [D loss: 0.688686, acc.: 50.78%] [G loss: 1.009258]\n",
      "epoch:1 step:1744 [D loss: 0.649295, acc.: 60.94%] [G loss: 1.055060]\n",
      "epoch:1 step:1745 [D loss: 0.758378, acc.: 50.00%] [G loss: 0.996580]\n",
      "epoch:1 step:1746 [D loss: 0.723052, acc.: 51.56%] [G loss: 0.929647]\n",
      "epoch:1 step:1747 [D loss: 0.666803, acc.: 55.47%] [G loss: 0.965357]\n",
      "epoch:1 step:1748 [D loss: 0.722181, acc.: 50.78%] [G loss: 0.944633]\n",
      "epoch:1 step:1749 [D loss: 0.659422, acc.: 61.72%] [G loss: 0.988048]\n",
      "epoch:1 step:1750 [D loss: 0.654513, acc.: 64.84%] [G loss: 1.045332]\n",
      "epoch:1 step:1751 [D loss: 0.695344, acc.: 60.16%] [G loss: 0.919247]\n",
      "epoch:1 step:1752 [D loss: 0.687372, acc.: 56.25%] [G loss: 1.036692]\n",
      "epoch:1 step:1753 [D loss: 0.665716, acc.: 56.25%] [G loss: 1.055185]\n",
      "epoch:1 step:1754 [D loss: 0.671922, acc.: 60.94%] [G loss: 0.968945]\n",
      "epoch:1 step:1755 [D loss: 0.713187, acc.: 57.03%] [G loss: 0.928935]\n",
      "epoch:1 step:1756 [D loss: 0.694785, acc.: 56.25%] [G loss: 0.879377]\n",
      "epoch:1 step:1757 [D loss: 0.693301, acc.: 57.81%] [G loss: 1.002151]\n",
      "epoch:1 step:1758 [D loss: 0.707052, acc.: 57.81%] [G loss: 0.890913]\n",
      "epoch:1 step:1759 [D loss: 0.690195, acc.: 57.03%] [G loss: 0.870530]\n",
      "epoch:1 step:1760 [D loss: 0.631767, acc.: 64.84%] [G loss: 1.071570]\n",
      "epoch:1 step:1761 [D loss: 0.687485, acc.: 54.69%] [G loss: 0.907957]\n",
      "epoch:1 step:1762 [D loss: 0.694940, acc.: 59.38%] [G loss: 0.912073]\n",
      "epoch:1 step:1763 [D loss: 0.715731, acc.: 57.81%] [G loss: 1.005174]\n",
      "epoch:1 step:1764 [D loss: 0.665956, acc.: 60.94%] [G loss: 0.938385]\n",
      "epoch:1 step:1765 [D loss: 0.688360, acc.: 60.94%] [G loss: 1.028184]\n",
      "epoch:1 step:1766 [D loss: 0.657283, acc.: 57.03%] [G loss: 0.975469]\n",
      "epoch:1 step:1767 [D loss: 0.620976, acc.: 67.97%] [G loss: 1.012858]\n",
      "epoch:1 step:1768 [D loss: 0.633970, acc.: 66.41%] [G loss: 0.938432]\n",
      "epoch:1 step:1769 [D loss: 0.624685, acc.: 63.28%] [G loss: 0.977114]\n",
      "epoch:1 step:1770 [D loss: 0.684721, acc.: 60.16%] [G loss: 1.032091]\n",
      "epoch:1 step:1771 [D loss: 0.719237, acc.: 53.12%] [G loss: 0.990877]\n",
      "epoch:1 step:1772 [D loss: 0.649680, acc.: 61.72%] [G loss: 0.969417]\n",
      "epoch:1 step:1773 [D loss: 0.717784, acc.: 54.69%] [G loss: 0.894641]\n",
      "epoch:1 step:1774 [D loss: 0.646165, acc.: 61.72%] [G loss: 0.895121]\n",
      "epoch:1 step:1775 [D loss: 0.681236, acc.: 58.59%] [G loss: 1.017163]\n",
      "epoch:1 step:1776 [D loss: 0.639633, acc.: 66.41%] [G loss: 0.921257]\n",
      "epoch:1 step:1777 [D loss: 0.670909, acc.: 60.16%] [G loss: 0.911868]\n",
      "epoch:1 step:1778 [D loss: 0.642933, acc.: 63.28%] [G loss: 0.951860]\n",
      "epoch:1 step:1779 [D loss: 0.642121, acc.: 64.84%] [G loss: 0.983000]\n",
      "epoch:1 step:1780 [D loss: 0.725708, acc.: 51.56%] [G loss: 0.918427]\n",
      "epoch:1 step:1781 [D loss: 0.724385, acc.: 53.12%] [G loss: 0.914278]\n",
      "epoch:1 step:1782 [D loss: 0.725178, acc.: 52.34%] [G loss: 0.859641]\n",
      "epoch:1 step:1783 [D loss: 0.609597, acc.: 67.19%] [G loss: 0.911138]\n",
      "epoch:1 step:1784 [D loss: 0.649984, acc.: 58.59%] [G loss: 0.982290]\n",
      "epoch:1 step:1785 [D loss: 0.710631, acc.: 56.25%] [G loss: 0.887990]\n",
      "epoch:1 step:1786 [D loss: 0.665954, acc.: 60.16%] [G loss: 0.899922]\n",
      "epoch:1 step:1787 [D loss: 0.732167, acc.: 57.03%] [G loss: 0.975672]\n",
      "epoch:1 step:1788 [D loss: 0.686680, acc.: 56.25%] [G loss: 0.928778]\n",
      "epoch:1 step:1789 [D loss: 0.700681, acc.: 60.94%] [G loss: 0.901680]\n",
      "epoch:1 step:1790 [D loss: 0.644797, acc.: 67.97%] [G loss: 0.950412]\n",
      "epoch:1 step:1791 [D loss: 0.597677, acc.: 71.88%] [G loss: 1.061136]\n",
      "epoch:1 step:1792 [D loss: 0.731736, acc.: 50.78%] [G loss: 0.917137]\n",
      "epoch:1 step:1793 [D loss: 0.761773, acc.: 47.66%] [G loss: 0.921676]\n",
      "epoch:1 step:1794 [D loss: 0.619314, acc.: 66.41%] [G loss: 1.089121]\n",
      "epoch:1 step:1795 [D loss: 0.792220, acc.: 40.62%] [G loss: 0.807075]\n",
      "epoch:1 step:1796 [D loss: 0.786101, acc.: 42.97%] [G loss: 0.931745]\n",
      "epoch:1 step:1797 [D loss: 0.716479, acc.: 59.38%] [G loss: 0.943077]\n",
      "epoch:1 step:1798 [D loss: 0.758477, acc.: 52.34%] [G loss: 0.959349]\n",
      "epoch:1 step:1799 [D loss: 0.674227, acc.: 54.69%] [G loss: 0.889478]\n",
      "epoch:1 step:1800 [D loss: 0.717562, acc.: 55.47%] [G loss: 0.879651]\n",
      "epoch:1 step:1801 [D loss: 0.714284, acc.: 51.56%] [G loss: 0.947539]\n",
      "epoch:1 step:1802 [D loss: 0.699375, acc.: 58.59%] [G loss: 0.991886]\n",
      "epoch:1 step:1803 [D loss: 0.696296, acc.: 60.16%] [G loss: 0.940469]\n",
      "epoch:1 step:1804 [D loss: 0.676706, acc.: 60.16%] [G loss: 0.951761]\n",
      "epoch:1 step:1805 [D loss: 0.723074, acc.: 49.22%] [G loss: 0.880658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1806 [D loss: 0.662299, acc.: 60.94%] [G loss: 0.797100]\n",
      "epoch:1 step:1807 [D loss: 0.724457, acc.: 46.88%] [G loss: 0.841444]\n",
      "epoch:1 step:1808 [D loss: 0.612135, acc.: 67.19%] [G loss: 0.931531]\n",
      "epoch:1 step:1809 [D loss: 0.659199, acc.: 63.28%] [G loss: 1.034190]\n",
      "epoch:1 step:1810 [D loss: 0.671608, acc.: 53.91%] [G loss: 0.934481]\n",
      "epoch:1 step:1811 [D loss: 0.636788, acc.: 63.28%] [G loss: 0.938353]\n",
      "epoch:1 step:1812 [D loss: 0.662785, acc.: 64.06%] [G loss: 0.935897]\n",
      "epoch:1 step:1813 [D loss: 0.621890, acc.: 64.06%] [G loss: 0.997698]\n",
      "epoch:1 step:1814 [D loss: 0.663745, acc.: 60.94%] [G loss: 0.938472]\n",
      "epoch:1 step:1815 [D loss: 0.644711, acc.: 62.50%] [G loss: 1.062744]\n",
      "epoch:1 step:1816 [D loss: 0.709594, acc.: 59.38%] [G loss: 0.924777]\n",
      "epoch:1 step:1817 [D loss: 0.706037, acc.: 53.12%] [G loss: 0.874825]\n",
      "epoch:1 step:1818 [D loss: 0.665244, acc.: 62.50%] [G loss: 0.959058]\n",
      "epoch:1 step:1819 [D loss: 0.734568, acc.: 50.78%] [G loss: 1.006765]\n",
      "epoch:1 step:1820 [D loss: 0.719104, acc.: 56.25%] [G loss: 0.993091]\n",
      "epoch:1 step:1821 [D loss: 0.650567, acc.: 62.50%] [G loss: 0.998918]\n",
      "epoch:1 step:1822 [D loss: 0.656576, acc.: 60.16%] [G loss: 0.992808]\n",
      "epoch:1 step:1823 [D loss: 0.672444, acc.: 57.81%] [G loss: 0.954623]\n",
      "epoch:1 step:1824 [D loss: 0.622993, acc.: 68.75%] [G loss: 1.041731]\n",
      "epoch:1 step:1825 [D loss: 0.625569, acc.: 62.50%] [G loss: 1.036088]\n",
      "epoch:1 step:1826 [D loss: 0.704715, acc.: 57.03%] [G loss: 0.962415]\n",
      "epoch:1 step:1827 [D loss: 0.623885, acc.: 64.06%] [G loss: 1.075501]\n",
      "epoch:1 step:1828 [D loss: 0.661738, acc.: 63.28%] [G loss: 0.978895]\n",
      "epoch:1 step:1829 [D loss: 0.790581, acc.: 46.09%] [G loss: 0.989112]\n",
      "epoch:1 step:1830 [D loss: 0.704417, acc.: 50.78%] [G loss: 0.918041]\n",
      "epoch:1 step:1831 [D loss: 0.698527, acc.: 57.81%] [G loss: 0.911415]\n",
      "epoch:1 step:1832 [D loss: 0.668753, acc.: 59.38%] [G loss: 0.889599]\n",
      "epoch:1 step:1833 [D loss: 0.749478, acc.: 48.44%] [G loss: 0.937825]\n",
      "epoch:1 step:1834 [D loss: 0.658327, acc.: 57.81%] [G loss: 1.007498]\n",
      "epoch:1 step:1835 [D loss: 0.727829, acc.: 58.59%] [G loss: 1.018960]\n",
      "epoch:1 step:1836 [D loss: 0.670361, acc.: 57.81%] [G loss: 1.044035]\n",
      "epoch:1 step:1837 [D loss: 0.678562, acc.: 59.38%] [G loss: 0.847558]\n",
      "epoch:1 step:1838 [D loss: 0.613298, acc.: 66.41%] [G loss: 0.989133]\n",
      "epoch:1 step:1839 [D loss: 0.730750, acc.: 57.03%] [G loss: 0.922821]\n",
      "epoch:1 step:1840 [D loss: 0.677387, acc.: 57.81%] [G loss: 0.884098]\n",
      "epoch:1 step:1841 [D loss: 0.751297, acc.: 46.88%] [G loss: 0.880986]\n",
      "epoch:1 step:1842 [D loss: 0.660924, acc.: 60.16%] [G loss: 0.984461]\n",
      "epoch:1 step:1843 [D loss: 0.655531, acc.: 64.84%] [G loss: 0.880354]\n",
      "epoch:1 step:1844 [D loss: 0.645764, acc.: 64.06%] [G loss: 1.001727]\n",
      "epoch:1 step:1845 [D loss: 0.718548, acc.: 50.00%] [G loss: 0.944652]\n",
      "epoch:1 step:1846 [D loss: 0.636854, acc.: 64.84%] [G loss: 0.987644]\n",
      "epoch:1 step:1847 [D loss: 0.621945, acc.: 64.84%] [G loss: 0.963781]\n",
      "epoch:1 step:1848 [D loss: 0.685588, acc.: 60.16%] [G loss: 1.001555]\n",
      "epoch:1 step:1849 [D loss: 0.696147, acc.: 60.94%] [G loss: 0.974341]\n",
      "epoch:1 step:1850 [D loss: 0.727561, acc.: 55.47%] [G loss: 1.059830]\n",
      "epoch:1 step:1851 [D loss: 0.720192, acc.: 55.47%] [G loss: 0.970851]\n",
      "epoch:1 step:1852 [D loss: 0.654212, acc.: 64.84%] [G loss: 0.998538]\n",
      "epoch:1 step:1853 [D loss: 0.683629, acc.: 59.38%] [G loss: 0.814567]\n",
      "epoch:1 step:1854 [D loss: 0.712526, acc.: 53.12%] [G loss: 0.963086]\n",
      "epoch:1 step:1855 [D loss: 0.626540, acc.: 69.53%] [G loss: 0.922803]\n",
      "epoch:1 step:1856 [D loss: 0.582034, acc.: 67.19%] [G loss: 0.940931]\n",
      "epoch:1 step:1857 [D loss: 0.818304, acc.: 52.34%] [G loss: 0.834239]\n",
      "epoch:1 step:1858 [D loss: 0.719089, acc.: 51.56%] [G loss: 0.902435]\n",
      "epoch:1 step:1859 [D loss: 0.583154, acc.: 70.31%] [G loss: 1.139941]\n",
      "epoch:1 step:1860 [D loss: 0.585305, acc.: 71.09%] [G loss: 1.081297]\n",
      "epoch:1 step:1861 [D loss: 0.550897, acc.: 74.22%] [G loss: 1.048281]\n",
      "epoch:1 step:1862 [D loss: 0.582570, acc.: 72.66%] [G loss: 1.075927]\n",
      "epoch:1 step:1863 [D loss: 0.648704, acc.: 64.84%] [G loss: 1.031556]\n",
      "epoch:1 step:1864 [D loss: 0.590114, acc.: 67.97%] [G loss: 1.063162]\n",
      "epoch:1 step:1865 [D loss: 0.763761, acc.: 53.91%] [G loss: 1.014218]\n",
      "epoch:1 step:1866 [D loss: 0.802877, acc.: 48.44%] [G loss: 0.968945]\n",
      "epoch:1 step:1867 [D loss: 0.569198, acc.: 68.75%] [G loss: 1.048181]\n",
      "epoch:1 step:1868 [D loss: 0.588783, acc.: 67.19%] [G loss: 1.050909]\n",
      "epoch:1 step:1869 [D loss: 0.661318, acc.: 59.38%] [G loss: 0.937131]\n",
      "epoch:1 step:1870 [D loss: 0.673739, acc.: 59.38%] [G loss: 1.052303]\n",
      "epoch:1 step:1871 [D loss: 0.689581, acc.: 56.25%] [G loss: 1.019694]\n",
      "epoch:1 step:1872 [D loss: 0.703852, acc.: 54.69%] [G loss: 1.027824]\n",
      "epoch:1 step:1873 [D loss: 0.611227, acc.: 61.72%] [G loss: 1.005617]\n",
      "epoch:1 step:1874 [D loss: 0.640906, acc.: 67.19%] [G loss: 1.015160]\n",
      "epoch:2 step:1875 [D loss: 0.698301, acc.: 60.94%] [G loss: 1.124944]\n",
      "epoch:2 step:1876 [D loss: 0.668837, acc.: 61.72%] [G loss: 0.898747]\n",
      "epoch:2 step:1877 [D loss: 0.657431, acc.: 59.38%] [G loss: 1.030589]\n",
      "epoch:2 step:1878 [D loss: 0.673331, acc.: 57.03%] [G loss: 1.076973]\n",
      "epoch:2 step:1879 [D loss: 0.711263, acc.: 60.16%] [G loss: 0.977192]\n",
      "epoch:2 step:1880 [D loss: 0.671525, acc.: 60.16%] [G loss: 0.972098]\n",
      "epoch:2 step:1881 [D loss: 0.616331, acc.: 68.75%] [G loss: 1.055753]\n",
      "epoch:2 step:1882 [D loss: 0.621250, acc.: 67.19%] [G loss: 1.056366]\n",
      "epoch:2 step:1883 [D loss: 0.632293, acc.: 64.06%] [G loss: 0.993063]\n",
      "epoch:2 step:1884 [D loss: 0.620594, acc.: 65.62%] [G loss: 1.051824]\n",
      "epoch:2 step:1885 [D loss: 0.595013, acc.: 67.97%] [G loss: 1.070881]\n",
      "epoch:2 step:1886 [D loss: 0.691368, acc.: 60.94%] [G loss: 0.847260]\n",
      "epoch:2 step:1887 [D loss: 0.635027, acc.: 64.06%] [G loss: 1.070248]\n",
      "epoch:2 step:1888 [D loss: 0.671179, acc.: 56.25%] [G loss: 0.974425]\n",
      "epoch:2 step:1889 [D loss: 0.598059, acc.: 63.28%] [G loss: 0.919876]\n",
      "epoch:2 step:1890 [D loss: 0.646123, acc.: 61.72%] [G loss: 1.050697]\n",
      "epoch:2 step:1891 [D loss: 0.648576, acc.: 59.38%] [G loss: 0.999169]\n",
      "epoch:2 step:1892 [D loss: 0.713647, acc.: 59.38%] [G loss: 0.900063]\n",
      "epoch:2 step:1893 [D loss: 0.644885, acc.: 60.94%] [G loss: 0.891142]\n",
      "epoch:2 step:1894 [D loss: 0.799118, acc.: 46.88%] [G loss: 0.873425]\n",
      "epoch:2 step:1895 [D loss: 0.680924, acc.: 56.25%] [G loss: 0.965922]\n",
      "epoch:2 step:1896 [D loss: 0.704831, acc.: 48.44%] [G loss: 0.934154]\n",
      "epoch:2 step:1897 [D loss: 0.724738, acc.: 53.12%] [G loss: 0.853454]\n",
      "epoch:2 step:1898 [D loss: 0.636231, acc.: 62.50%] [G loss: 1.057387]\n",
      "epoch:2 step:1899 [D loss: 0.649872, acc.: 64.84%] [G loss: 1.086125]\n",
      "epoch:2 step:1900 [D loss: 0.730052, acc.: 55.47%] [G loss: 1.043206]\n",
      "epoch:2 step:1901 [D loss: 0.754714, acc.: 46.88%] [G loss: 0.902265]\n",
      "epoch:2 step:1902 [D loss: 0.724175, acc.: 53.12%] [G loss: 0.898046]\n",
      "epoch:2 step:1903 [D loss: 0.668480, acc.: 60.94%] [G loss: 1.001924]\n",
      "epoch:2 step:1904 [D loss: 0.665654, acc.: 60.16%] [G loss: 0.985728]\n",
      "epoch:2 step:1905 [D loss: 0.763527, acc.: 48.44%] [G loss: 1.027568]\n",
      "epoch:2 step:1906 [D loss: 0.675130, acc.: 60.94%] [G loss: 1.022078]\n",
      "epoch:2 step:1907 [D loss: 0.661854, acc.: 63.28%] [G loss: 0.988143]\n",
      "epoch:2 step:1908 [D loss: 0.705376, acc.: 57.03%] [G loss: 0.928400]\n",
      "epoch:2 step:1909 [D loss: 0.660254, acc.: 55.47%] [G loss: 0.989457]\n",
      "epoch:2 step:1910 [D loss: 0.661817, acc.: 67.19%] [G loss: 1.010602]\n",
      "epoch:2 step:1911 [D loss: 0.646942, acc.: 63.28%] [G loss: 0.980799]\n",
      "epoch:2 step:1912 [D loss: 0.673278, acc.: 60.94%] [G loss: 0.900032]\n",
      "epoch:2 step:1913 [D loss: 0.754264, acc.: 49.22%] [G loss: 0.929191]\n",
      "epoch:2 step:1914 [D loss: 0.669322, acc.: 58.59%] [G loss: 0.879743]\n",
      "epoch:2 step:1915 [D loss: 0.647021, acc.: 64.06%] [G loss: 0.934017]\n",
      "epoch:2 step:1916 [D loss: 0.638133, acc.: 66.41%] [G loss: 0.989274]\n",
      "epoch:2 step:1917 [D loss: 0.718197, acc.: 57.03%] [G loss: 1.001701]\n",
      "epoch:2 step:1918 [D loss: 0.717980, acc.: 60.16%] [G loss: 0.971452]\n",
      "epoch:2 step:1919 [D loss: 0.647008, acc.: 64.06%] [G loss: 0.974789]\n",
      "epoch:2 step:1920 [D loss: 0.702281, acc.: 57.81%] [G loss: 1.007926]\n",
      "epoch:2 step:1921 [D loss: 0.737824, acc.: 50.78%] [G loss: 0.941401]\n",
      "epoch:2 step:1922 [D loss: 0.656998, acc.: 59.38%] [G loss: 1.018420]\n",
      "epoch:2 step:1923 [D loss: 0.667066, acc.: 61.72%] [G loss: 0.877672]\n",
      "epoch:2 step:1924 [D loss: 0.710542, acc.: 57.03%] [G loss: 0.895412]\n",
      "epoch:2 step:1925 [D loss: 0.631381, acc.: 64.06%] [G loss: 0.961468]\n",
      "epoch:2 step:1926 [D loss: 0.683340, acc.: 60.94%] [G loss: 0.891863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1927 [D loss: 0.657403, acc.: 61.72%] [G loss: 0.939601]\n",
      "epoch:2 step:1928 [D loss: 0.657393, acc.: 60.16%] [G loss: 0.997827]\n",
      "epoch:2 step:1929 [D loss: 0.666319, acc.: 60.16%] [G loss: 0.940350]\n",
      "epoch:2 step:1930 [D loss: 0.670623, acc.: 63.28%] [G loss: 1.136397]\n",
      "epoch:2 step:1931 [D loss: 0.715832, acc.: 53.91%] [G loss: 0.931140]\n",
      "epoch:2 step:1932 [D loss: 0.718850, acc.: 51.56%] [G loss: 1.006112]\n",
      "epoch:2 step:1933 [D loss: 0.707708, acc.: 50.78%] [G loss: 1.005949]\n",
      "epoch:2 step:1934 [D loss: 0.650594, acc.: 67.19%] [G loss: 0.968295]\n",
      "epoch:2 step:1935 [D loss: 0.661010, acc.: 60.16%] [G loss: 0.973011]\n",
      "epoch:2 step:1936 [D loss: 0.712224, acc.: 57.03%] [G loss: 0.883885]\n",
      "epoch:2 step:1937 [D loss: 0.641007, acc.: 65.62%] [G loss: 1.007081]\n",
      "epoch:2 step:1938 [D loss: 0.667045, acc.: 53.91%] [G loss: 0.888875]\n",
      "epoch:2 step:1939 [D loss: 0.726368, acc.: 50.78%] [G loss: 0.920165]\n",
      "epoch:2 step:1940 [D loss: 0.650319, acc.: 64.06%] [G loss: 0.972161]\n",
      "epoch:2 step:1941 [D loss: 0.641624, acc.: 60.94%] [G loss: 0.915131]\n",
      "epoch:2 step:1942 [D loss: 0.732548, acc.: 57.03%] [G loss: 0.870252]\n",
      "epoch:2 step:1943 [D loss: 0.731118, acc.: 51.56%] [G loss: 0.886282]\n",
      "epoch:2 step:1944 [D loss: 0.640146, acc.: 61.72%] [G loss: 0.988382]\n",
      "epoch:2 step:1945 [D loss: 0.609073, acc.: 69.53%] [G loss: 1.090347]\n",
      "epoch:2 step:1946 [D loss: 0.681735, acc.: 53.12%] [G loss: 0.990056]\n",
      "epoch:2 step:1947 [D loss: 0.645326, acc.: 61.72%] [G loss: 0.992242]\n",
      "epoch:2 step:1948 [D loss: 0.656334, acc.: 61.72%] [G loss: 1.052138]\n",
      "epoch:2 step:1949 [D loss: 0.587417, acc.: 71.09%] [G loss: 0.979509]\n",
      "epoch:2 step:1950 [D loss: 0.598925, acc.: 70.31%] [G loss: 1.015739]\n",
      "epoch:2 step:1951 [D loss: 0.524161, acc.: 78.12%] [G loss: 1.069488]\n",
      "epoch:2 step:1952 [D loss: 0.755314, acc.: 53.12%] [G loss: 0.855820]\n",
      "epoch:2 step:1953 [D loss: 0.744260, acc.: 50.78%] [G loss: 0.985177]\n",
      "epoch:2 step:1954 [D loss: 0.724519, acc.: 57.81%] [G loss: 0.872460]\n",
      "epoch:2 step:1955 [D loss: 0.741590, acc.: 53.12%] [G loss: 0.850071]\n",
      "epoch:2 step:1956 [D loss: 0.643829, acc.: 67.19%] [G loss: 1.024855]\n",
      "epoch:2 step:1957 [D loss: 0.706164, acc.: 55.47%] [G loss: 0.963716]\n",
      "epoch:2 step:1958 [D loss: 0.643373, acc.: 57.81%] [G loss: 0.890146]\n",
      "epoch:2 step:1959 [D loss: 0.675109, acc.: 56.25%] [G loss: 0.985756]\n",
      "epoch:2 step:1960 [D loss: 0.713464, acc.: 49.22%] [G loss: 0.950207]\n",
      "epoch:2 step:1961 [D loss: 0.622648, acc.: 64.84%] [G loss: 1.106260]\n",
      "epoch:2 step:1962 [D loss: 0.671274, acc.: 59.38%] [G loss: 1.009801]\n",
      "epoch:2 step:1963 [D loss: 0.602361, acc.: 67.97%] [G loss: 0.944431]\n",
      "epoch:2 step:1964 [D loss: 0.704461, acc.: 56.25%] [G loss: 0.990543]\n",
      "epoch:2 step:1965 [D loss: 0.705762, acc.: 56.25%] [G loss: 1.011358]\n",
      "epoch:2 step:1966 [D loss: 0.650196, acc.: 62.50%] [G loss: 1.010548]\n",
      "epoch:2 step:1967 [D loss: 0.585187, acc.: 68.75%] [G loss: 0.999890]\n",
      "epoch:2 step:1968 [D loss: 0.645146, acc.: 62.50%] [G loss: 1.068038]\n",
      "epoch:2 step:1969 [D loss: 0.650147, acc.: 59.38%] [G loss: 0.936667]\n",
      "epoch:2 step:1970 [D loss: 0.688723, acc.: 53.91%] [G loss: 0.922194]\n",
      "epoch:2 step:1971 [D loss: 0.666142, acc.: 67.19%] [G loss: 0.891366]\n",
      "epoch:2 step:1972 [D loss: 0.729735, acc.: 46.88%] [G loss: 0.888880]\n",
      "epoch:2 step:1973 [D loss: 0.671084, acc.: 61.72%] [G loss: 0.905711]\n",
      "epoch:2 step:1974 [D loss: 0.648733, acc.: 56.25%] [G loss: 0.994017]\n",
      "epoch:2 step:1975 [D loss: 0.715093, acc.: 54.69%] [G loss: 0.906114]\n",
      "epoch:2 step:1976 [D loss: 0.665548, acc.: 60.94%] [G loss: 0.967443]\n",
      "epoch:2 step:1977 [D loss: 0.572380, acc.: 71.88%] [G loss: 1.209193]\n",
      "epoch:2 step:1978 [D loss: 0.682494, acc.: 58.59%] [G loss: 1.003200]\n",
      "epoch:2 step:1979 [D loss: 0.666695, acc.: 64.84%] [G loss: 1.066108]\n",
      "epoch:2 step:1980 [D loss: 0.635802, acc.: 63.28%] [G loss: 1.037973]\n",
      "epoch:2 step:1981 [D loss: 0.663691, acc.: 57.03%] [G loss: 1.008066]\n",
      "epoch:2 step:1982 [D loss: 0.670936, acc.: 58.59%] [G loss: 1.010288]\n",
      "epoch:2 step:1983 [D loss: 0.677242, acc.: 63.28%] [G loss: 0.886679]\n",
      "epoch:2 step:1984 [D loss: 0.622514, acc.: 64.06%] [G loss: 1.000080]\n",
      "epoch:2 step:1985 [D loss: 0.649506, acc.: 62.50%] [G loss: 0.969226]\n",
      "epoch:2 step:1986 [D loss: 0.676457, acc.: 61.72%] [G loss: 0.884251]\n",
      "epoch:2 step:1987 [D loss: 0.661901, acc.: 57.03%] [G loss: 0.930907]\n",
      "epoch:2 step:1988 [D loss: 0.664161, acc.: 60.16%] [G loss: 1.036331]\n",
      "epoch:2 step:1989 [D loss: 0.763092, acc.: 50.78%] [G loss: 0.833354]\n",
      "epoch:2 step:1990 [D loss: 0.696736, acc.: 58.59%] [G loss: 1.027915]\n",
      "epoch:2 step:1991 [D loss: 0.686107, acc.: 57.03%] [G loss: 1.007490]\n",
      "epoch:2 step:1992 [D loss: 0.683078, acc.: 62.50%] [G loss: 0.933528]\n",
      "epoch:2 step:1993 [D loss: 0.621885, acc.: 73.44%] [G loss: 0.970960]\n",
      "epoch:2 step:1994 [D loss: 0.774086, acc.: 51.56%] [G loss: 0.950669]\n",
      "epoch:2 step:1995 [D loss: 0.727044, acc.: 52.34%] [G loss: 0.942402]\n",
      "epoch:2 step:1996 [D loss: 0.725978, acc.: 49.22%] [G loss: 0.900448]\n",
      "epoch:2 step:1997 [D loss: 0.714006, acc.: 49.22%] [G loss: 0.928927]\n",
      "epoch:2 step:1998 [D loss: 0.644128, acc.: 62.50%] [G loss: 0.811900]\n",
      "epoch:2 step:1999 [D loss: 0.662539, acc.: 61.72%] [G loss: 0.956952]\n",
      "epoch:2 step:2000 [D loss: 0.658301, acc.: 60.16%] [G loss: 0.992536]\n",
      "epoch:2 step:2001 [D loss: 0.627548, acc.: 59.38%] [G loss: 1.007714]\n",
      "epoch:2 step:2002 [D loss: 0.635488, acc.: 62.50%] [G loss: 0.983101]\n",
      "epoch:2 step:2003 [D loss: 0.700970, acc.: 56.25%] [G loss: 0.842001]\n",
      "epoch:2 step:2004 [D loss: 0.646429, acc.: 60.16%] [G loss: 0.956383]\n",
      "epoch:2 step:2005 [D loss: 0.607168, acc.: 67.97%] [G loss: 0.929266]\n",
      "epoch:2 step:2006 [D loss: 0.662778, acc.: 57.03%] [G loss: 0.967972]\n",
      "epoch:2 step:2007 [D loss: 0.696709, acc.: 55.47%] [G loss: 0.939099]\n",
      "epoch:2 step:2008 [D loss: 0.744720, acc.: 57.03%] [G loss: 0.992567]\n",
      "epoch:2 step:2009 [D loss: 0.705332, acc.: 51.56%] [G loss: 0.882345]\n",
      "epoch:2 step:2010 [D loss: 0.663029, acc.: 57.81%] [G loss: 0.954778]\n",
      "epoch:2 step:2011 [D loss: 0.673674, acc.: 60.94%] [G loss: 1.012594]\n",
      "epoch:2 step:2012 [D loss: 0.694763, acc.: 58.59%] [G loss: 0.853169]\n",
      "epoch:2 step:2013 [D loss: 0.703722, acc.: 53.12%] [G loss: 0.860036]\n",
      "epoch:2 step:2014 [D loss: 0.738799, acc.: 46.88%] [G loss: 0.986826]\n",
      "epoch:2 step:2015 [D loss: 0.673349, acc.: 57.03%] [G loss: 1.044367]\n",
      "epoch:2 step:2016 [D loss: 0.633314, acc.: 63.28%] [G loss: 1.034856]\n",
      "epoch:2 step:2017 [D loss: 0.698091, acc.: 53.91%] [G loss: 0.985570]\n",
      "epoch:2 step:2018 [D loss: 0.635072, acc.: 68.75%] [G loss: 0.947622]\n",
      "epoch:2 step:2019 [D loss: 0.693774, acc.: 60.94%] [G loss: 0.976291]\n",
      "epoch:2 step:2020 [D loss: 0.676905, acc.: 57.81%] [G loss: 0.955948]\n",
      "epoch:2 step:2021 [D loss: 0.650451, acc.: 62.50%] [G loss: 0.896816]\n",
      "epoch:2 step:2022 [D loss: 0.717652, acc.: 53.91%] [G loss: 0.931707]\n",
      "epoch:2 step:2023 [D loss: 0.634004, acc.: 60.94%] [G loss: 0.970228]\n",
      "epoch:2 step:2024 [D loss: 0.638882, acc.: 65.62%] [G loss: 0.885381]\n",
      "epoch:2 step:2025 [D loss: 0.678693, acc.: 58.59%] [G loss: 0.964731]\n",
      "epoch:2 step:2026 [D loss: 0.580095, acc.: 68.75%] [G loss: 1.159354]\n",
      "epoch:2 step:2027 [D loss: 0.693933, acc.: 59.38%] [G loss: 1.062568]\n",
      "epoch:2 step:2028 [D loss: 0.689246, acc.: 55.47%] [G loss: 0.884829]\n",
      "epoch:2 step:2029 [D loss: 0.647248, acc.: 64.06%] [G loss: 0.963238]\n",
      "epoch:2 step:2030 [D loss: 0.637922, acc.: 64.06%] [G loss: 0.971979]\n",
      "epoch:2 step:2031 [D loss: 0.644151, acc.: 60.94%] [G loss: 0.977768]\n",
      "epoch:2 step:2032 [D loss: 0.716733, acc.: 51.56%] [G loss: 0.947569]\n",
      "epoch:2 step:2033 [D loss: 0.672794, acc.: 59.38%] [G loss: 0.969937]\n",
      "epoch:2 step:2034 [D loss: 0.624443, acc.: 66.41%] [G loss: 0.973157]\n",
      "epoch:2 step:2035 [D loss: 0.661974, acc.: 62.50%] [G loss: 0.880687]\n",
      "epoch:2 step:2036 [D loss: 0.619768, acc.: 64.06%] [G loss: 1.053260]\n",
      "epoch:2 step:2037 [D loss: 0.671024, acc.: 53.91%] [G loss: 0.974741]\n",
      "epoch:2 step:2038 [D loss: 0.707145, acc.: 46.09%] [G loss: 1.007480]\n",
      "epoch:2 step:2039 [D loss: 0.653014, acc.: 65.62%] [G loss: 0.953931]\n",
      "epoch:2 step:2040 [D loss: 0.654338, acc.: 58.59%] [G loss: 1.037174]\n",
      "epoch:2 step:2041 [D loss: 0.674208, acc.: 60.94%] [G loss: 0.966252]\n",
      "epoch:2 step:2042 [D loss: 0.632012, acc.: 61.72%] [G loss: 1.107972]\n",
      "epoch:2 step:2043 [D loss: 0.662450, acc.: 60.94%] [G loss: 1.034568]\n",
      "epoch:2 step:2044 [D loss: 0.662377, acc.: 55.47%] [G loss: 0.984156]\n",
      "epoch:2 step:2045 [D loss: 0.633804, acc.: 64.84%] [G loss: 1.003241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2046 [D loss: 0.709682, acc.: 56.25%] [G loss: 0.888218]\n",
      "epoch:2 step:2047 [D loss: 0.669240, acc.: 60.16%] [G loss: 1.109824]\n",
      "epoch:2 step:2048 [D loss: 0.734615, acc.: 57.03%] [G loss: 0.987657]\n",
      "epoch:2 step:2049 [D loss: 0.648492, acc.: 62.50%] [G loss: 0.967197]\n",
      "epoch:2 step:2050 [D loss: 0.700540, acc.: 53.12%] [G loss: 1.032521]\n",
      "epoch:2 step:2051 [D loss: 0.645401, acc.: 58.59%] [G loss: 1.019179]\n",
      "epoch:2 step:2052 [D loss: 0.630376, acc.: 60.16%] [G loss: 0.912976]\n",
      "epoch:2 step:2053 [D loss: 0.689321, acc.: 55.47%] [G loss: 0.901210]\n",
      "epoch:2 step:2054 [D loss: 0.658072, acc.: 63.28%] [G loss: 0.927498]\n",
      "epoch:2 step:2055 [D loss: 0.672295, acc.: 60.16%] [G loss: 1.000739]\n",
      "epoch:2 step:2056 [D loss: 0.674269, acc.: 55.47%] [G loss: 1.073556]\n",
      "epoch:2 step:2057 [D loss: 0.673296, acc.: 58.59%] [G loss: 0.929447]\n",
      "epoch:2 step:2058 [D loss: 0.646715, acc.: 60.16%] [G loss: 0.868510]\n",
      "epoch:2 step:2059 [D loss: 0.665121, acc.: 57.81%] [G loss: 0.917523]\n",
      "epoch:2 step:2060 [D loss: 0.712952, acc.: 55.47%] [G loss: 0.860258]\n",
      "epoch:2 step:2061 [D loss: 0.647880, acc.: 58.59%] [G loss: 0.973367]\n",
      "epoch:2 step:2062 [D loss: 0.627229, acc.: 64.06%] [G loss: 0.972916]\n",
      "epoch:2 step:2063 [D loss: 0.687922, acc.: 58.59%] [G loss: 0.945110]\n",
      "epoch:2 step:2064 [D loss: 0.587354, acc.: 70.31%] [G loss: 1.057509]\n",
      "epoch:2 step:2065 [D loss: 0.640078, acc.: 65.62%] [G loss: 0.915269]\n",
      "epoch:2 step:2066 [D loss: 0.690912, acc.: 57.81%] [G loss: 0.974307]\n",
      "epoch:2 step:2067 [D loss: 0.726252, acc.: 55.47%] [G loss: 0.987250]\n",
      "epoch:2 step:2068 [D loss: 0.627811, acc.: 64.06%] [G loss: 1.003720]\n",
      "epoch:2 step:2069 [D loss: 0.688542, acc.: 56.25%] [G loss: 1.047101]\n",
      "epoch:2 step:2070 [D loss: 0.692586, acc.: 57.81%] [G loss: 1.175815]\n",
      "epoch:2 step:2071 [D loss: 0.645018, acc.: 64.84%] [G loss: 1.119904]\n",
      "epoch:2 step:2072 [D loss: 0.660460, acc.: 57.81%] [G loss: 0.937205]\n",
      "epoch:2 step:2073 [D loss: 0.686605, acc.: 56.25%] [G loss: 0.981239]\n",
      "epoch:2 step:2074 [D loss: 0.750707, acc.: 52.34%] [G loss: 0.832290]\n",
      "epoch:2 step:2075 [D loss: 0.779818, acc.: 49.22%] [G loss: 0.873437]\n",
      "epoch:2 step:2076 [D loss: 0.683534, acc.: 56.25%] [G loss: 0.965277]\n",
      "epoch:2 step:2077 [D loss: 0.704441, acc.: 50.00%] [G loss: 0.905137]\n",
      "epoch:2 step:2078 [D loss: 0.694884, acc.: 57.03%] [G loss: 0.944137]\n",
      "epoch:2 step:2079 [D loss: 0.739100, acc.: 55.47%] [G loss: 1.014115]\n",
      "epoch:2 step:2080 [D loss: 0.648319, acc.: 58.59%] [G loss: 1.050961]\n",
      "epoch:2 step:2081 [D loss: 0.605662, acc.: 70.31%] [G loss: 1.095889]\n",
      "epoch:2 step:2082 [D loss: 0.592884, acc.: 67.97%] [G loss: 1.074236]\n",
      "epoch:2 step:2083 [D loss: 0.609438, acc.: 64.06%] [G loss: 0.984577]\n",
      "epoch:2 step:2084 [D loss: 0.664104, acc.: 58.59%] [G loss: 1.015021]\n",
      "epoch:2 step:2085 [D loss: 0.682131, acc.: 60.16%] [G loss: 0.916536]\n",
      "epoch:2 step:2086 [D loss: 0.717676, acc.: 50.00%] [G loss: 0.964466]\n",
      "epoch:2 step:2087 [D loss: 0.670317, acc.: 58.59%] [G loss: 1.016785]\n",
      "epoch:2 step:2088 [D loss: 0.712600, acc.: 58.59%] [G loss: 0.951178]\n",
      "epoch:2 step:2089 [D loss: 0.770074, acc.: 39.84%] [G loss: 1.017379]\n",
      "epoch:2 step:2090 [D loss: 0.711829, acc.: 51.56%] [G loss: 0.979151]\n",
      "epoch:2 step:2091 [D loss: 0.639605, acc.: 63.28%] [G loss: 0.840083]\n",
      "epoch:2 step:2092 [D loss: 0.598372, acc.: 66.41%] [G loss: 1.027076]\n",
      "epoch:2 step:2093 [D loss: 0.734651, acc.: 53.91%] [G loss: 0.956269]\n",
      "epoch:2 step:2094 [D loss: 0.818090, acc.: 44.53%] [G loss: 0.974389]\n",
      "epoch:2 step:2095 [D loss: 0.694121, acc.: 57.81%] [G loss: 1.026032]\n",
      "epoch:2 step:2096 [D loss: 0.681967, acc.: 61.72%] [G loss: 0.934753]\n",
      "epoch:2 step:2097 [D loss: 0.734725, acc.: 53.91%] [G loss: 0.921289]\n",
      "epoch:2 step:2098 [D loss: 0.658132, acc.: 60.16%] [G loss: 1.050960]\n",
      "epoch:2 step:2099 [D loss: 0.698423, acc.: 58.59%] [G loss: 0.964697]\n",
      "epoch:2 step:2100 [D loss: 0.608965, acc.: 62.50%] [G loss: 0.959035]\n",
      "epoch:2 step:2101 [D loss: 0.726304, acc.: 59.38%] [G loss: 0.899522]\n",
      "epoch:2 step:2102 [D loss: 0.643884, acc.: 60.94%] [G loss: 0.841329]\n",
      "epoch:2 step:2103 [D loss: 0.676670, acc.: 58.59%] [G loss: 0.983487]\n",
      "epoch:2 step:2104 [D loss: 0.603525, acc.: 67.97%] [G loss: 0.996407]\n",
      "epoch:2 step:2105 [D loss: 0.594343, acc.: 70.31%] [G loss: 0.988797]\n",
      "epoch:2 step:2106 [D loss: 0.579894, acc.: 65.62%] [G loss: 1.187221]\n",
      "epoch:2 step:2107 [D loss: 0.764440, acc.: 53.12%] [G loss: 0.968618]\n",
      "epoch:2 step:2108 [D loss: 0.652109, acc.: 58.59%] [G loss: 1.085205]\n",
      "epoch:2 step:2109 [D loss: 0.692217, acc.: 54.69%] [G loss: 0.965954]\n",
      "epoch:2 step:2110 [D loss: 0.671278, acc.: 57.81%] [G loss: 0.940427]\n",
      "epoch:2 step:2111 [D loss: 0.643835, acc.: 62.50%] [G loss: 0.965089]\n",
      "epoch:2 step:2112 [D loss: 0.630122, acc.: 55.47%] [G loss: 0.870377]\n",
      "epoch:2 step:2113 [D loss: 0.616478, acc.: 67.19%] [G loss: 0.992693]\n",
      "epoch:2 step:2114 [D loss: 0.659800, acc.: 64.06%] [G loss: 1.010278]\n",
      "epoch:2 step:2115 [D loss: 0.629193, acc.: 64.84%] [G loss: 1.073651]\n",
      "epoch:2 step:2116 [D loss: 0.629291, acc.: 65.62%] [G loss: 1.103629]\n",
      "epoch:2 step:2117 [D loss: 0.660208, acc.: 57.03%] [G loss: 0.993036]\n",
      "epoch:2 step:2118 [D loss: 0.642057, acc.: 60.16%] [G loss: 1.057108]\n",
      "epoch:2 step:2119 [D loss: 0.734586, acc.: 51.56%] [G loss: 0.847864]\n",
      "epoch:2 step:2120 [D loss: 0.701193, acc.: 55.47%] [G loss: 0.899185]\n",
      "epoch:2 step:2121 [D loss: 0.680796, acc.: 61.72%] [G loss: 0.933477]\n",
      "epoch:2 step:2122 [D loss: 0.733403, acc.: 49.22%] [G loss: 0.909926]\n",
      "epoch:2 step:2123 [D loss: 0.768345, acc.: 48.44%] [G loss: 0.896063]\n",
      "epoch:2 step:2124 [D loss: 0.710837, acc.: 53.91%] [G loss: 0.953406]\n",
      "epoch:2 step:2125 [D loss: 0.717906, acc.: 52.34%] [G loss: 0.908864]\n",
      "epoch:2 step:2126 [D loss: 0.650650, acc.: 54.69%] [G loss: 0.908859]\n",
      "epoch:2 step:2127 [D loss: 0.639737, acc.: 63.28%] [G loss: 1.056287]\n",
      "epoch:2 step:2128 [D loss: 0.623526, acc.: 63.28%] [G loss: 0.998478]\n",
      "epoch:2 step:2129 [D loss: 0.724588, acc.: 53.91%] [G loss: 0.923470]\n",
      "epoch:2 step:2130 [D loss: 0.764483, acc.: 43.75%] [G loss: 0.852566]\n",
      "epoch:2 step:2131 [D loss: 0.754050, acc.: 52.34%] [G loss: 0.910918]\n",
      "epoch:2 step:2132 [D loss: 0.705897, acc.: 53.91%] [G loss: 1.014305]\n",
      "epoch:2 step:2133 [D loss: 0.676078, acc.: 52.34%] [G loss: 0.966106]\n",
      "epoch:2 step:2134 [D loss: 0.649723, acc.: 64.06%] [G loss: 0.958354]\n",
      "epoch:2 step:2135 [D loss: 0.627264, acc.: 66.41%] [G loss: 1.122922]\n",
      "epoch:2 step:2136 [D loss: 0.610680, acc.: 69.53%] [G loss: 1.104743]\n",
      "epoch:2 step:2137 [D loss: 0.646208, acc.: 65.62%] [G loss: 1.075787]\n",
      "epoch:2 step:2138 [D loss: 0.643723, acc.: 62.50%] [G loss: 1.035205]\n",
      "epoch:2 step:2139 [D loss: 0.675990, acc.: 57.81%] [G loss: 1.015496]\n",
      "epoch:2 step:2140 [D loss: 0.678092, acc.: 59.38%] [G loss: 1.024356]\n",
      "epoch:2 step:2141 [D loss: 0.687200, acc.: 60.94%] [G loss: 0.890854]\n",
      "epoch:2 step:2142 [D loss: 0.708361, acc.: 54.69%] [G loss: 0.896521]\n",
      "epoch:2 step:2143 [D loss: 0.741024, acc.: 56.25%] [G loss: 0.986504]\n",
      "epoch:2 step:2144 [D loss: 0.664711, acc.: 56.25%] [G loss: 0.942196]\n",
      "epoch:2 step:2145 [D loss: 0.749775, acc.: 46.09%] [G loss: 0.894915]\n",
      "epoch:2 step:2146 [D loss: 0.700110, acc.: 55.47%] [G loss: 0.941882]\n",
      "epoch:2 step:2147 [D loss: 0.649751, acc.: 60.16%] [G loss: 0.953986]\n",
      "epoch:2 step:2148 [D loss: 0.674384, acc.: 62.50%] [G loss: 0.937261]\n",
      "epoch:2 step:2149 [D loss: 0.736745, acc.: 49.22%] [G loss: 0.944708]\n",
      "epoch:2 step:2150 [D loss: 0.707121, acc.: 54.69%] [G loss: 0.928638]\n",
      "epoch:2 step:2151 [D loss: 0.698663, acc.: 55.47%] [G loss: 1.125773]\n",
      "epoch:2 step:2152 [D loss: 0.730014, acc.: 52.34%] [G loss: 0.970275]\n",
      "epoch:2 step:2153 [D loss: 0.710065, acc.: 55.47%] [G loss: 0.969812]\n",
      "epoch:2 step:2154 [D loss: 0.641019, acc.: 62.50%] [G loss: 0.942736]\n",
      "epoch:2 step:2155 [D loss: 0.691956, acc.: 55.47%] [G loss: 0.874703]\n",
      "epoch:2 step:2156 [D loss: 0.677516, acc.: 61.72%] [G loss: 0.947267]\n",
      "epoch:2 step:2157 [D loss: 0.623579, acc.: 62.50%] [G loss: 0.976709]\n",
      "epoch:2 step:2158 [D loss: 0.582162, acc.: 74.22%] [G loss: 0.949362]\n",
      "epoch:2 step:2159 [D loss: 0.662206, acc.: 62.50%] [G loss: 0.900371]\n",
      "epoch:2 step:2160 [D loss: 0.598915, acc.: 68.75%] [G loss: 1.004739]\n",
      "epoch:2 step:2161 [D loss: 0.672222, acc.: 60.16%] [G loss: 0.953046]\n",
      "epoch:2 step:2162 [D loss: 0.669316, acc.: 61.72%] [G loss: 0.945217]\n",
      "epoch:2 step:2163 [D loss: 0.691171, acc.: 60.16%] [G loss: 0.848703]\n",
      "epoch:2 step:2164 [D loss: 0.738276, acc.: 53.91%] [G loss: 0.939973]\n",
      "epoch:2 step:2165 [D loss: 0.707895, acc.: 57.81%] [G loss: 0.963331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2166 [D loss: 0.640713, acc.: 64.06%] [G loss: 0.983662]\n",
      "epoch:2 step:2167 [D loss: 0.698130, acc.: 54.69%] [G loss: 0.908608]\n",
      "epoch:2 step:2168 [D loss: 0.659014, acc.: 56.25%] [G loss: 0.928889]\n",
      "epoch:2 step:2169 [D loss: 0.692207, acc.: 53.12%] [G loss: 1.019547]\n",
      "epoch:2 step:2170 [D loss: 0.639851, acc.: 63.28%] [G loss: 0.995841]\n",
      "epoch:2 step:2171 [D loss: 0.650741, acc.: 61.72%] [G loss: 1.069527]\n",
      "epoch:2 step:2172 [D loss: 0.710587, acc.: 56.25%] [G loss: 0.990393]\n",
      "epoch:2 step:2173 [D loss: 0.667971, acc.: 63.28%] [G loss: 0.961565]\n",
      "epoch:2 step:2174 [D loss: 0.687122, acc.: 57.03%] [G loss: 1.035216]\n",
      "epoch:2 step:2175 [D loss: 0.687335, acc.: 58.59%] [G loss: 0.996415]\n",
      "epoch:2 step:2176 [D loss: 0.652990, acc.: 61.72%] [G loss: 0.951906]\n",
      "epoch:2 step:2177 [D loss: 0.664419, acc.: 64.06%] [G loss: 0.949192]\n",
      "epoch:2 step:2178 [D loss: 0.617736, acc.: 68.75%] [G loss: 0.961984]\n",
      "epoch:2 step:2179 [D loss: 0.687669, acc.: 58.59%] [G loss: 0.924758]\n",
      "epoch:2 step:2180 [D loss: 0.693840, acc.: 52.34%] [G loss: 0.903900]\n",
      "epoch:2 step:2181 [D loss: 0.655388, acc.: 64.06%] [G loss: 1.017633]\n",
      "epoch:2 step:2182 [D loss: 0.639338, acc.: 61.72%] [G loss: 1.039191]\n",
      "epoch:2 step:2183 [D loss: 0.661242, acc.: 64.06%] [G loss: 0.885890]\n",
      "epoch:2 step:2184 [D loss: 0.642229, acc.: 61.72%] [G loss: 1.004590]\n",
      "epoch:2 step:2185 [D loss: 0.656201, acc.: 58.59%] [G loss: 1.044806]\n",
      "epoch:2 step:2186 [D loss: 0.672415, acc.: 60.16%] [G loss: 1.062746]\n",
      "epoch:2 step:2187 [D loss: 0.613262, acc.: 71.09%] [G loss: 1.095222]\n",
      "epoch:2 step:2188 [D loss: 0.582551, acc.: 69.53%] [G loss: 1.160986]\n",
      "epoch:2 step:2189 [D loss: 0.582717, acc.: 71.09%] [G loss: 1.161370]\n",
      "epoch:2 step:2190 [D loss: 0.733600, acc.: 54.69%] [G loss: 1.094872]\n",
      "epoch:2 step:2191 [D loss: 0.751236, acc.: 45.31%] [G loss: 0.956530]\n",
      "epoch:2 step:2192 [D loss: 0.731490, acc.: 54.69%] [G loss: 0.928422]\n",
      "epoch:2 step:2193 [D loss: 0.742219, acc.: 56.25%] [G loss: 1.009948]\n",
      "epoch:2 step:2194 [D loss: 0.646946, acc.: 63.28%] [G loss: 0.971907]\n",
      "epoch:2 step:2195 [D loss: 0.691583, acc.: 54.69%] [G loss: 0.886064]\n",
      "epoch:2 step:2196 [D loss: 0.643576, acc.: 61.72%] [G loss: 0.951636]\n",
      "epoch:2 step:2197 [D loss: 0.715409, acc.: 57.81%] [G loss: 1.020537]\n",
      "epoch:2 step:2198 [D loss: 0.652509, acc.: 66.41%] [G loss: 0.997671]\n",
      "epoch:2 step:2199 [D loss: 0.725806, acc.: 54.69%] [G loss: 0.973410]\n",
      "epoch:2 step:2200 [D loss: 0.676393, acc.: 57.03%] [G loss: 0.967129]\n",
      "epoch:2 step:2201 [D loss: 0.580859, acc.: 72.66%] [G loss: 1.041331]\n",
      "epoch:2 step:2202 [D loss: 0.608806, acc.: 71.88%] [G loss: 1.068197]\n",
      "epoch:2 step:2203 [D loss: 0.647768, acc.: 64.06%] [G loss: 1.113378]\n",
      "epoch:2 step:2204 [D loss: 0.647023, acc.: 67.97%] [G loss: 0.990361]\n",
      "epoch:2 step:2205 [D loss: 0.672587, acc.: 65.62%] [G loss: 1.044886]\n",
      "epoch:2 step:2206 [D loss: 0.625412, acc.: 66.41%] [G loss: 1.062845]\n",
      "epoch:2 step:2207 [D loss: 0.679774, acc.: 56.25%] [G loss: 1.051967]\n",
      "epoch:2 step:2208 [D loss: 0.601874, acc.: 67.97%] [G loss: 1.047341]\n",
      "epoch:2 step:2209 [D loss: 0.641090, acc.: 60.94%] [G loss: 0.989026]\n",
      "epoch:2 step:2210 [D loss: 0.612135, acc.: 71.88%] [G loss: 1.014146]\n",
      "epoch:2 step:2211 [D loss: 0.660203, acc.: 58.59%] [G loss: 0.968986]\n",
      "epoch:2 step:2212 [D loss: 0.640282, acc.: 65.62%] [G loss: 1.019587]\n",
      "epoch:2 step:2213 [D loss: 0.706763, acc.: 55.47%] [G loss: 1.056532]\n",
      "epoch:2 step:2214 [D loss: 0.660239, acc.: 60.94%] [G loss: 1.012091]\n",
      "epoch:2 step:2215 [D loss: 0.704033, acc.: 60.16%] [G loss: 1.006582]\n",
      "epoch:2 step:2216 [D loss: 0.777587, acc.: 50.00%] [G loss: 0.907163]\n",
      "epoch:2 step:2217 [D loss: 0.558043, acc.: 71.09%] [G loss: 1.017027]\n",
      "epoch:2 step:2218 [D loss: 0.596322, acc.: 63.28%] [G loss: 0.947631]\n",
      "epoch:2 step:2219 [D loss: 0.596575, acc.: 67.97%] [G loss: 1.036658]\n",
      "epoch:2 step:2220 [D loss: 0.613279, acc.: 65.62%] [G loss: 1.029804]\n",
      "epoch:2 step:2221 [D loss: 0.616598, acc.: 65.62%] [G loss: 1.041433]\n",
      "epoch:2 step:2222 [D loss: 0.678953, acc.: 57.81%] [G loss: 0.946559]\n",
      "epoch:2 step:2223 [D loss: 0.757050, acc.: 51.56%] [G loss: 1.015996]\n",
      "epoch:2 step:2224 [D loss: 0.625587, acc.: 66.41%] [G loss: 1.019045]\n",
      "epoch:2 step:2225 [D loss: 0.672929, acc.: 65.62%] [G loss: 0.943638]\n",
      "epoch:2 step:2226 [D loss: 0.744643, acc.: 50.00%] [G loss: 0.845722]\n",
      "epoch:2 step:2227 [D loss: 0.702538, acc.: 53.12%] [G loss: 0.951508]\n",
      "epoch:2 step:2228 [D loss: 0.647676, acc.: 59.38%] [G loss: 0.886072]\n",
      "epoch:2 step:2229 [D loss: 0.696491, acc.: 51.56%] [G loss: 1.064761]\n",
      "epoch:2 step:2230 [D loss: 0.670652, acc.: 60.94%] [G loss: 0.981315]\n",
      "epoch:2 step:2231 [D loss: 0.623445, acc.: 62.50%] [G loss: 0.965867]\n",
      "epoch:2 step:2232 [D loss: 0.641118, acc.: 60.16%] [G loss: 1.035430]\n",
      "epoch:2 step:2233 [D loss: 0.685955, acc.: 54.69%] [G loss: 0.875612]\n",
      "epoch:2 step:2234 [D loss: 0.664516, acc.: 59.38%] [G loss: 1.153341]\n",
      "epoch:2 step:2235 [D loss: 0.744837, acc.: 51.56%] [G loss: 1.005370]\n",
      "epoch:2 step:2236 [D loss: 0.690318, acc.: 57.03%] [G loss: 1.024696]\n",
      "epoch:2 step:2237 [D loss: 0.640102, acc.: 65.62%] [G loss: 0.976735]\n",
      "epoch:2 step:2238 [D loss: 0.644159, acc.: 64.06%] [G loss: 1.043032]\n",
      "epoch:2 step:2239 [D loss: 0.677357, acc.: 58.59%] [G loss: 0.968475]\n",
      "epoch:2 step:2240 [D loss: 0.661228, acc.: 56.25%] [G loss: 1.060528]\n",
      "epoch:2 step:2241 [D loss: 0.702408, acc.: 60.16%] [G loss: 0.980516]\n",
      "epoch:2 step:2242 [D loss: 0.637074, acc.: 66.41%] [G loss: 0.994060]\n",
      "epoch:2 step:2243 [D loss: 0.711616, acc.: 57.03%] [G loss: 0.896829]\n",
      "epoch:2 step:2244 [D loss: 0.670611, acc.: 57.03%] [G loss: 1.007962]\n",
      "epoch:2 step:2245 [D loss: 0.637776, acc.: 62.50%] [G loss: 0.948742]\n",
      "epoch:2 step:2246 [D loss: 0.735922, acc.: 58.59%] [G loss: 0.987535]\n",
      "epoch:2 step:2247 [D loss: 0.695363, acc.: 55.47%] [G loss: 0.985750]\n",
      "epoch:2 step:2248 [D loss: 0.656762, acc.: 64.06%] [G loss: 0.925537]\n",
      "epoch:2 step:2249 [D loss: 0.697527, acc.: 56.25%] [G loss: 0.998127]\n",
      "epoch:2 step:2250 [D loss: 0.752344, acc.: 51.56%] [G loss: 1.022990]\n",
      "epoch:2 step:2251 [D loss: 0.741713, acc.: 49.22%] [G loss: 0.925473]\n",
      "epoch:2 step:2252 [D loss: 0.724397, acc.: 53.12%] [G loss: 0.968980]\n",
      "epoch:2 step:2253 [D loss: 0.650800, acc.: 64.06%] [G loss: 1.033822]\n",
      "epoch:2 step:2254 [D loss: 0.649368, acc.: 60.94%] [G loss: 0.914391]\n",
      "epoch:2 step:2255 [D loss: 0.654777, acc.: 62.50%] [G loss: 0.965689]\n",
      "epoch:2 step:2256 [D loss: 0.691838, acc.: 57.03%] [G loss: 0.960633]\n",
      "epoch:2 step:2257 [D loss: 0.737615, acc.: 51.56%] [G loss: 0.942795]\n",
      "epoch:2 step:2258 [D loss: 0.651025, acc.: 59.38%] [G loss: 0.992633]\n",
      "epoch:2 step:2259 [D loss: 0.684868, acc.: 55.47%] [G loss: 0.959337]\n",
      "epoch:2 step:2260 [D loss: 0.636496, acc.: 64.84%] [G loss: 0.970070]\n",
      "epoch:2 step:2261 [D loss: 0.664299, acc.: 59.38%] [G loss: 0.903876]\n",
      "epoch:2 step:2262 [D loss: 0.708888, acc.: 50.78%] [G loss: 0.973364]\n",
      "epoch:2 step:2263 [D loss: 0.638165, acc.: 66.41%] [G loss: 1.090460]\n",
      "epoch:2 step:2264 [D loss: 0.706944, acc.: 54.69%] [G loss: 0.957374]\n",
      "epoch:2 step:2265 [D loss: 0.704169, acc.: 54.69%] [G loss: 1.011634]\n",
      "epoch:2 step:2266 [D loss: 0.583169, acc.: 70.31%] [G loss: 0.915689]\n",
      "epoch:2 step:2267 [D loss: 0.657294, acc.: 62.50%] [G loss: 0.947707]\n",
      "epoch:2 step:2268 [D loss: 0.621134, acc.: 66.41%] [G loss: 0.941234]\n",
      "epoch:2 step:2269 [D loss: 0.592488, acc.: 64.06%] [G loss: 0.990073]\n",
      "epoch:2 step:2270 [D loss: 0.688668, acc.: 55.47%] [G loss: 0.970629]\n",
      "epoch:2 step:2271 [D loss: 0.622143, acc.: 69.53%] [G loss: 1.002560]\n",
      "epoch:2 step:2272 [D loss: 0.635743, acc.: 63.28%] [G loss: 1.083468]\n",
      "epoch:2 step:2273 [D loss: 0.590306, acc.: 68.75%] [G loss: 1.188406]\n",
      "epoch:2 step:2274 [D loss: 0.704887, acc.: 54.69%] [G loss: 0.909356]\n",
      "epoch:2 step:2275 [D loss: 0.658213, acc.: 60.94%] [G loss: 1.010318]\n",
      "epoch:2 step:2276 [D loss: 0.656181, acc.: 60.16%] [G loss: 0.908962]\n",
      "epoch:2 step:2277 [D loss: 0.666675, acc.: 57.81%] [G loss: 1.021981]\n",
      "epoch:2 step:2278 [D loss: 0.668665, acc.: 61.72%] [G loss: 0.950177]\n",
      "epoch:2 step:2279 [D loss: 0.650498, acc.: 60.16%] [G loss: 1.072469]\n",
      "epoch:2 step:2280 [D loss: 0.611496, acc.: 63.28%] [G loss: 1.090478]\n",
      "epoch:2 step:2281 [D loss: 0.653188, acc.: 63.28%] [G loss: 1.081482]\n",
      "epoch:2 step:2282 [D loss: 0.645326, acc.: 65.62%] [G loss: 1.090055]\n",
      "epoch:2 step:2283 [D loss: 0.568747, acc.: 68.75%] [G loss: 1.019566]\n",
      "epoch:2 step:2284 [D loss: 0.695646, acc.: 53.91%] [G loss: 1.059506]\n",
      "epoch:2 step:2285 [D loss: 0.714435, acc.: 53.12%] [G loss: 0.976581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2286 [D loss: 0.708247, acc.: 58.59%] [G loss: 0.945398]\n",
      "epoch:2 step:2287 [D loss: 0.671939, acc.: 58.59%] [G loss: 1.019087]\n",
      "epoch:2 step:2288 [D loss: 0.688328, acc.: 60.16%] [G loss: 0.974825]\n",
      "epoch:2 step:2289 [D loss: 0.691370, acc.: 58.59%] [G loss: 0.939318]\n",
      "epoch:2 step:2290 [D loss: 0.675792, acc.: 52.34%] [G loss: 0.992721]\n",
      "epoch:2 step:2291 [D loss: 0.715557, acc.: 56.25%] [G loss: 0.939312]\n",
      "epoch:2 step:2292 [D loss: 0.637025, acc.: 63.28%] [G loss: 1.089802]\n",
      "epoch:2 step:2293 [D loss: 0.626407, acc.: 63.28%] [G loss: 0.993607]\n",
      "epoch:2 step:2294 [D loss: 0.670489, acc.: 57.03%] [G loss: 1.071978]\n",
      "epoch:2 step:2295 [D loss: 0.750479, acc.: 45.31%] [G loss: 1.010655]\n",
      "epoch:2 step:2296 [D loss: 0.749452, acc.: 47.66%] [G loss: 0.860752]\n",
      "epoch:2 step:2297 [D loss: 0.719912, acc.: 53.91%] [G loss: 0.901161]\n",
      "epoch:2 step:2298 [D loss: 0.614261, acc.: 70.31%] [G loss: 1.018515]\n",
      "epoch:2 step:2299 [D loss: 0.673911, acc.: 53.12%] [G loss: 0.938999]\n",
      "epoch:2 step:2300 [D loss: 0.636739, acc.: 59.38%] [G loss: 0.927944]\n",
      "epoch:2 step:2301 [D loss: 0.635352, acc.: 66.41%] [G loss: 0.989355]\n",
      "epoch:2 step:2302 [D loss: 0.643163, acc.: 64.84%] [G loss: 1.050521]\n",
      "epoch:2 step:2303 [D loss: 0.625304, acc.: 61.72%] [G loss: 1.080500]\n",
      "epoch:2 step:2304 [D loss: 0.617130, acc.: 63.28%] [G loss: 1.050128]\n",
      "epoch:2 step:2305 [D loss: 0.704299, acc.: 57.81%] [G loss: 1.031672]\n",
      "epoch:2 step:2306 [D loss: 0.695262, acc.: 58.59%] [G loss: 1.031557]\n",
      "epoch:2 step:2307 [D loss: 0.684102, acc.: 57.81%] [G loss: 0.955966]\n",
      "epoch:2 step:2308 [D loss: 0.651440, acc.: 60.16%] [G loss: 0.937449]\n",
      "epoch:2 step:2309 [D loss: 0.651292, acc.: 62.50%] [G loss: 0.931657]\n",
      "epoch:2 step:2310 [D loss: 0.732056, acc.: 50.78%] [G loss: 0.930945]\n",
      "epoch:2 step:2311 [D loss: 0.703637, acc.: 54.69%] [G loss: 0.911233]\n",
      "epoch:2 step:2312 [D loss: 0.672507, acc.: 55.47%] [G loss: 0.999199]\n",
      "epoch:2 step:2313 [D loss: 0.623294, acc.: 67.97%] [G loss: 0.975167]\n",
      "epoch:2 step:2314 [D loss: 0.716743, acc.: 49.22%] [G loss: 0.952006]\n",
      "epoch:2 step:2315 [D loss: 0.678802, acc.: 57.03%] [G loss: 1.112024]\n",
      "epoch:2 step:2316 [D loss: 0.689984, acc.: 54.69%] [G loss: 0.991659]\n",
      "epoch:2 step:2317 [D loss: 0.684732, acc.: 59.38%] [G loss: 1.019960]\n",
      "epoch:2 step:2318 [D loss: 0.689485, acc.: 56.25%] [G loss: 0.982996]\n",
      "epoch:2 step:2319 [D loss: 0.601687, acc.: 63.28%] [G loss: 1.018393]\n",
      "epoch:2 step:2320 [D loss: 0.661814, acc.: 63.28%] [G loss: 0.999761]\n",
      "epoch:2 step:2321 [D loss: 0.648967, acc.: 63.28%] [G loss: 1.098063]\n",
      "epoch:2 step:2322 [D loss: 0.717942, acc.: 54.69%] [G loss: 1.020932]\n",
      "epoch:2 step:2323 [D loss: 0.685318, acc.: 56.25%] [G loss: 1.038908]\n",
      "epoch:2 step:2324 [D loss: 0.674535, acc.: 57.03%] [G loss: 1.084376]\n",
      "epoch:2 step:2325 [D loss: 0.623783, acc.: 71.88%] [G loss: 1.001465]\n",
      "epoch:2 step:2326 [D loss: 0.599894, acc.: 71.88%] [G loss: 1.095952]\n",
      "epoch:2 step:2327 [D loss: 0.581097, acc.: 70.31%] [G loss: 1.270174]\n",
      "epoch:2 step:2328 [D loss: 0.611525, acc.: 71.09%] [G loss: 1.013657]\n",
      "epoch:2 step:2329 [D loss: 0.629621, acc.: 60.16%] [G loss: 1.150741]\n",
      "epoch:2 step:2330 [D loss: 0.675834, acc.: 61.72%] [G loss: 0.993402]\n",
      "epoch:2 step:2331 [D loss: 0.693804, acc.: 57.81%] [G loss: 1.074755]\n",
      "epoch:2 step:2332 [D loss: 0.733169, acc.: 53.91%] [G loss: 0.975850]\n",
      "epoch:2 step:2333 [D loss: 0.737644, acc.: 47.66%] [G loss: 0.894831]\n",
      "epoch:2 step:2334 [D loss: 0.643111, acc.: 64.06%] [G loss: 0.969516]\n",
      "epoch:2 step:2335 [D loss: 0.697522, acc.: 55.47%] [G loss: 1.067195]\n",
      "epoch:2 step:2336 [D loss: 0.694019, acc.: 51.56%] [G loss: 0.939014]\n",
      "epoch:2 step:2337 [D loss: 0.697484, acc.: 54.69%] [G loss: 0.905244]\n",
      "epoch:2 step:2338 [D loss: 0.690925, acc.: 57.03%] [G loss: 0.893870]\n",
      "epoch:2 step:2339 [D loss: 0.650624, acc.: 62.50%] [G loss: 1.004879]\n",
      "epoch:2 step:2340 [D loss: 0.615725, acc.: 66.41%] [G loss: 1.049451]\n",
      "epoch:2 step:2341 [D loss: 0.689011, acc.: 57.81%] [G loss: 0.914131]\n",
      "epoch:2 step:2342 [D loss: 0.642596, acc.: 64.06%] [G loss: 1.071358]\n",
      "epoch:2 step:2343 [D loss: 0.675540, acc.: 55.47%] [G loss: 1.016839]\n",
      "epoch:2 step:2344 [D loss: 0.597505, acc.: 67.97%] [G loss: 1.148143]\n",
      "epoch:2 step:2345 [D loss: 0.584022, acc.: 66.41%] [G loss: 1.039831]\n",
      "epoch:2 step:2346 [D loss: 0.630216, acc.: 67.19%] [G loss: 1.115766]\n",
      "epoch:2 step:2347 [D loss: 0.804514, acc.: 42.19%] [G loss: 0.961331]\n",
      "epoch:2 step:2348 [D loss: 0.713805, acc.: 55.47%] [G loss: 0.932358]\n",
      "epoch:2 step:2349 [D loss: 0.720414, acc.: 50.78%] [G loss: 0.896262]\n",
      "epoch:2 step:2350 [D loss: 0.648614, acc.: 63.28%] [G loss: 0.937511]\n",
      "epoch:2 step:2351 [D loss: 0.705398, acc.: 56.25%] [G loss: 1.033031]\n",
      "epoch:2 step:2352 [D loss: 0.692928, acc.: 59.38%] [G loss: 0.896601]\n",
      "epoch:2 step:2353 [D loss: 0.695507, acc.: 54.69%] [G loss: 0.913407]\n",
      "epoch:2 step:2354 [D loss: 0.697149, acc.: 58.59%] [G loss: 0.965297]\n",
      "epoch:2 step:2355 [D loss: 0.611664, acc.: 67.97%] [G loss: 1.038179]\n",
      "epoch:2 step:2356 [D loss: 0.726653, acc.: 50.78%] [G loss: 0.907446]\n",
      "epoch:2 step:2357 [D loss: 0.717740, acc.: 53.12%] [G loss: 0.974384]\n",
      "epoch:2 step:2358 [D loss: 0.676903, acc.: 59.38%] [G loss: 0.957442]\n",
      "epoch:2 step:2359 [D loss: 0.677171, acc.: 58.59%] [G loss: 0.984328]\n",
      "epoch:2 step:2360 [D loss: 0.737981, acc.: 51.56%] [G loss: 0.819255]\n",
      "epoch:2 step:2361 [D loss: 0.653237, acc.: 63.28%] [G loss: 1.042382]\n",
      "epoch:2 step:2362 [D loss: 0.662944, acc.: 60.94%] [G loss: 1.038131]\n",
      "epoch:2 step:2363 [D loss: 0.636950, acc.: 66.41%] [G loss: 1.008053]\n",
      "epoch:2 step:2364 [D loss: 0.655745, acc.: 60.94%] [G loss: 0.925084]\n",
      "epoch:2 step:2365 [D loss: 0.608968, acc.: 64.84%] [G loss: 1.009000]\n",
      "epoch:2 step:2366 [D loss: 0.694516, acc.: 54.69%] [G loss: 0.884686]\n",
      "epoch:2 step:2367 [D loss: 0.746398, acc.: 50.78%] [G loss: 0.887451]\n",
      "epoch:2 step:2368 [D loss: 0.663908, acc.: 55.47%] [G loss: 0.951926]\n",
      "epoch:2 step:2369 [D loss: 0.607988, acc.: 67.97%] [G loss: 1.061450]\n",
      "epoch:2 step:2370 [D loss: 0.683807, acc.: 58.59%] [G loss: 0.916012]\n",
      "epoch:2 step:2371 [D loss: 0.676220, acc.: 59.38%] [G loss: 0.944249]\n",
      "epoch:2 step:2372 [D loss: 0.597037, acc.: 74.22%] [G loss: 1.017578]\n",
      "epoch:2 step:2373 [D loss: 0.589274, acc.: 72.66%] [G loss: 0.990246]\n",
      "epoch:2 step:2374 [D loss: 0.693525, acc.: 54.69%] [G loss: 1.019820]\n",
      "epoch:2 step:2375 [D loss: 0.712580, acc.: 53.12%] [G loss: 0.873449]\n",
      "epoch:2 step:2376 [D loss: 0.711620, acc.: 55.47%] [G loss: 0.905217]\n",
      "epoch:2 step:2377 [D loss: 0.710860, acc.: 52.34%] [G loss: 0.960730]\n",
      "epoch:2 step:2378 [D loss: 0.629003, acc.: 67.97%] [G loss: 0.981560]\n",
      "epoch:2 step:2379 [D loss: 0.673517, acc.: 60.16%] [G loss: 0.959299]\n",
      "epoch:2 step:2380 [D loss: 0.720623, acc.: 54.69%] [G loss: 0.932873]\n",
      "epoch:2 step:2381 [D loss: 0.672740, acc.: 60.16%] [G loss: 0.997361]\n",
      "epoch:2 step:2382 [D loss: 0.699168, acc.: 57.81%] [G loss: 1.031405]\n",
      "epoch:2 step:2383 [D loss: 0.740741, acc.: 49.22%] [G loss: 0.951696]\n",
      "epoch:2 step:2384 [D loss: 0.737527, acc.: 53.12%] [G loss: 1.003719]\n",
      "epoch:2 step:2385 [D loss: 0.770884, acc.: 50.00%] [G loss: 0.844155]\n",
      "epoch:2 step:2386 [D loss: 0.714972, acc.: 54.69%] [G loss: 0.920819]\n",
      "epoch:2 step:2387 [D loss: 0.660668, acc.: 60.16%] [G loss: 0.918707]\n",
      "epoch:2 step:2388 [D loss: 0.677582, acc.: 60.94%] [G loss: 0.838954]\n",
      "epoch:2 step:2389 [D loss: 0.647836, acc.: 64.06%] [G loss: 0.959485]\n",
      "epoch:2 step:2390 [D loss: 0.632426, acc.: 71.09%] [G loss: 0.956829]\n",
      "epoch:2 step:2391 [D loss: 0.682017, acc.: 55.47%] [G loss: 1.003982]\n",
      "epoch:2 step:2392 [D loss: 0.678417, acc.: 53.91%] [G loss: 0.896435]\n",
      "epoch:2 step:2393 [D loss: 0.633037, acc.: 67.19%] [G loss: 0.942509]\n",
      "epoch:2 step:2394 [D loss: 0.630718, acc.: 57.81%] [G loss: 0.923689]\n",
      "epoch:2 step:2395 [D loss: 0.648199, acc.: 61.72%] [G loss: 1.023196]\n",
      "epoch:2 step:2396 [D loss: 0.728986, acc.: 55.47%] [G loss: 0.941925]\n",
      "epoch:2 step:2397 [D loss: 0.687483, acc.: 57.03%] [G loss: 0.921396]\n",
      "epoch:2 step:2398 [D loss: 0.677534, acc.: 58.59%] [G loss: 0.999939]\n",
      "epoch:2 step:2399 [D loss: 0.715206, acc.: 50.00%] [G loss: 0.901967]\n",
      "epoch:2 step:2400 [D loss: 0.688358, acc.: 61.72%] [G loss: 0.965444]\n",
      "epoch:2 step:2401 [D loss: 0.684351, acc.: 57.81%] [G loss: 0.906523]\n",
      "epoch:2 step:2402 [D loss: 0.682520, acc.: 59.38%] [G loss: 1.071092]\n",
      "epoch:2 step:2403 [D loss: 0.675607, acc.: 57.81%] [G loss: 0.995853]\n",
      "epoch:2 step:2404 [D loss: 0.669737, acc.: 57.81%] [G loss: 0.955834]\n",
      "epoch:2 step:2405 [D loss: 0.691204, acc.: 57.81%] [G loss: 0.882905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2406 [D loss: 0.639858, acc.: 58.59%] [G loss: 1.137504]\n",
      "epoch:2 step:2407 [D loss: 0.655492, acc.: 60.16%] [G loss: 1.010852]\n",
      "epoch:2 step:2408 [D loss: 0.646952, acc.: 58.59%] [G loss: 0.900009]\n",
      "epoch:2 step:2409 [D loss: 0.661988, acc.: 57.81%] [G loss: 1.000582]\n",
      "epoch:2 step:2410 [D loss: 0.722761, acc.: 53.91%] [G loss: 0.986737]\n",
      "epoch:2 step:2411 [D loss: 0.717085, acc.: 52.34%] [G loss: 0.981939]\n",
      "epoch:2 step:2412 [D loss: 0.703289, acc.: 56.25%] [G loss: 1.041080]\n",
      "epoch:2 step:2413 [D loss: 0.667497, acc.: 57.03%] [G loss: 0.976991]\n",
      "epoch:2 step:2414 [D loss: 0.702586, acc.: 57.03%] [G loss: 0.944028]\n",
      "epoch:2 step:2415 [D loss: 0.645693, acc.: 64.06%] [G loss: 1.024635]\n",
      "epoch:2 step:2416 [D loss: 0.738295, acc.: 53.91%] [G loss: 0.929001]\n",
      "epoch:2 step:2417 [D loss: 0.727698, acc.: 53.12%] [G loss: 0.866893]\n",
      "epoch:2 step:2418 [D loss: 0.715490, acc.: 50.78%] [G loss: 0.969561]\n",
      "epoch:2 step:2419 [D loss: 0.661497, acc.: 62.50%] [G loss: 0.964223]\n",
      "epoch:2 step:2420 [D loss: 0.673304, acc.: 57.03%] [G loss: 0.964430]\n",
      "epoch:2 step:2421 [D loss: 0.652574, acc.: 58.59%] [G loss: 0.882723]\n",
      "epoch:2 step:2422 [D loss: 0.678645, acc.: 53.12%] [G loss: 0.962115]\n",
      "epoch:2 step:2423 [D loss: 0.623836, acc.: 64.06%] [G loss: 1.045061]\n",
      "epoch:2 step:2424 [D loss: 0.588776, acc.: 70.31%] [G loss: 1.048182]\n",
      "epoch:2 step:2425 [D loss: 0.675371, acc.: 58.59%] [G loss: 0.931382]\n",
      "epoch:2 step:2426 [D loss: 0.525333, acc.: 75.00%] [G loss: 1.015429]\n",
      "epoch:2 step:2427 [D loss: 0.678632, acc.: 61.72%] [G loss: 0.962513]\n",
      "epoch:2 step:2428 [D loss: 0.605496, acc.: 68.75%] [G loss: 1.117978]\n",
      "epoch:2 step:2429 [D loss: 0.642739, acc.: 60.94%] [G loss: 0.973992]\n",
      "epoch:2 step:2430 [D loss: 0.630523, acc.: 63.28%] [G loss: 0.992966]\n",
      "epoch:2 step:2431 [D loss: 0.604406, acc.: 65.62%] [G loss: 1.085675]\n",
      "epoch:2 step:2432 [D loss: 0.642462, acc.: 64.06%] [G loss: 1.030331]\n",
      "epoch:2 step:2433 [D loss: 0.688783, acc.: 56.25%] [G loss: 0.986738]\n",
      "epoch:2 step:2434 [D loss: 0.705528, acc.: 46.09%] [G loss: 0.964520]\n",
      "epoch:2 step:2435 [D loss: 0.718776, acc.: 53.91%] [G loss: 0.999993]\n",
      "epoch:2 step:2436 [D loss: 0.764412, acc.: 47.66%] [G loss: 0.838101]\n",
      "epoch:2 step:2437 [D loss: 0.706442, acc.: 53.91%] [G loss: 0.907889]\n",
      "epoch:2 step:2438 [D loss: 0.693525, acc.: 56.25%] [G loss: 0.855265]\n",
      "epoch:2 step:2439 [D loss: 0.677894, acc.: 56.25%] [G loss: 0.919432]\n",
      "epoch:2 step:2440 [D loss: 0.720758, acc.: 54.69%] [G loss: 1.054113]\n",
      "epoch:2 step:2441 [D loss: 0.694661, acc.: 56.25%] [G loss: 0.929778]\n",
      "epoch:2 step:2442 [D loss: 0.661658, acc.: 61.72%] [G loss: 0.971892]\n",
      "epoch:2 step:2443 [D loss: 0.655714, acc.: 60.16%] [G loss: 1.018189]\n",
      "epoch:2 step:2444 [D loss: 0.665344, acc.: 58.59%] [G loss: 1.085020]\n",
      "epoch:2 step:2445 [D loss: 0.634813, acc.: 55.47%] [G loss: 1.026336]\n",
      "epoch:2 step:2446 [D loss: 0.633767, acc.: 64.06%] [G loss: 0.926012]\n",
      "epoch:2 step:2447 [D loss: 0.641055, acc.: 64.06%] [G loss: 0.816991]\n",
      "epoch:2 step:2448 [D loss: 0.630606, acc.: 64.84%] [G loss: 0.919451]\n",
      "epoch:2 step:2449 [D loss: 0.656202, acc.: 64.06%] [G loss: 0.867791]\n",
      "epoch:2 step:2450 [D loss: 0.698832, acc.: 53.91%] [G loss: 0.947437]\n",
      "epoch:2 step:2451 [D loss: 0.710207, acc.: 50.78%] [G loss: 0.898692]\n",
      "epoch:2 step:2452 [D loss: 0.650645, acc.: 63.28%] [G loss: 0.910866]\n",
      "epoch:2 step:2453 [D loss: 0.732777, acc.: 53.91%] [G loss: 0.926248]\n",
      "epoch:2 step:2454 [D loss: 0.708757, acc.: 53.91%] [G loss: 0.855960]\n",
      "epoch:2 step:2455 [D loss: 0.712963, acc.: 57.03%] [G loss: 0.975532]\n",
      "epoch:2 step:2456 [D loss: 0.638459, acc.: 64.06%] [G loss: 0.795436]\n",
      "epoch:2 step:2457 [D loss: 0.636702, acc.: 59.38%] [G loss: 0.964179]\n",
      "epoch:2 step:2458 [D loss: 0.689296, acc.: 56.25%] [G loss: 0.949995]\n",
      "epoch:2 step:2459 [D loss: 0.660309, acc.: 60.94%] [G loss: 0.909620]\n",
      "epoch:2 step:2460 [D loss: 0.670700, acc.: 56.25%] [G loss: 0.939572]\n",
      "epoch:2 step:2461 [D loss: 0.691714, acc.: 55.47%] [G loss: 0.895180]\n",
      "epoch:2 step:2462 [D loss: 0.619263, acc.: 68.75%] [G loss: 0.997922]\n",
      "epoch:2 step:2463 [D loss: 0.667454, acc.: 60.16%] [G loss: 0.978605]\n",
      "epoch:2 step:2464 [D loss: 0.618137, acc.: 63.28%] [G loss: 1.083972]\n",
      "epoch:2 step:2465 [D loss: 0.723541, acc.: 53.12%] [G loss: 0.917368]\n",
      "epoch:2 step:2466 [D loss: 0.623238, acc.: 62.50%] [G loss: 0.995459]\n",
      "epoch:2 step:2467 [D loss: 0.648574, acc.: 64.84%] [G loss: 0.923527]\n",
      "epoch:2 step:2468 [D loss: 0.668613, acc.: 60.94%] [G loss: 1.008065]\n",
      "epoch:2 step:2469 [D loss: 0.673447, acc.: 57.81%] [G loss: 1.005312]\n",
      "epoch:2 step:2470 [D loss: 0.653493, acc.: 58.59%] [G loss: 0.995934]\n",
      "epoch:2 step:2471 [D loss: 0.582654, acc.: 67.97%] [G loss: 0.943608]\n",
      "epoch:2 step:2472 [D loss: 0.651733, acc.: 59.38%] [G loss: 0.987757]\n",
      "epoch:2 step:2473 [D loss: 0.645039, acc.: 66.41%] [G loss: 1.008178]\n",
      "epoch:2 step:2474 [D loss: 0.708320, acc.: 57.03%] [G loss: 0.961101]\n",
      "epoch:2 step:2475 [D loss: 0.720312, acc.: 52.34%] [G loss: 0.961915]\n",
      "epoch:2 step:2476 [D loss: 0.662480, acc.: 61.72%] [G loss: 0.900092]\n",
      "epoch:2 step:2477 [D loss: 0.650569, acc.: 63.28%] [G loss: 0.983805]\n",
      "epoch:2 step:2478 [D loss: 0.646503, acc.: 62.50%] [G loss: 1.043687]\n",
      "epoch:2 step:2479 [D loss: 0.652296, acc.: 62.50%] [G loss: 0.962943]\n",
      "epoch:2 step:2480 [D loss: 0.641060, acc.: 60.94%] [G loss: 0.990049]\n",
      "epoch:2 step:2481 [D loss: 0.700171, acc.: 55.47%] [G loss: 0.884506]\n",
      "epoch:2 step:2482 [D loss: 0.649095, acc.: 57.81%] [G loss: 0.872216]\n",
      "epoch:2 step:2483 [D loss: 0.678746, acc.: 61.72%] [G loss: 0.910167]\n",
      "epoch:2 step:2484 [D loss: 0.719832, acc.: 51.56%] [G loss: 0.890063]\n",
      "epoch:2 step:2485 [D loss: 0.676334, acc.: 57.81%] [G loss: 0.969686]\n",
      "epoch:2 step:2486 [D loss: 0.635940, acc.: 67.19%] [G loss: 0.919084]\n",
      "epoch:2 step:2487 [D loss: 0.647353, acc.: 64.84%] [G loss: 0.927204]\n",
      "epoch:2 step:2488 [D loss: 0.736702, acc.: 50.78%] [G loss: 0.994646]\n",
      "epoch:2 step:2489 [D loss: 0.745896, acc.: 50.00%] [G loss: 0.907055]\n",
      "epoch:2 step:2490 [D loss: 0.714411, acc.: 53.91%] [G loss: 0.967121]\n",
      "epoch:2 step:2491 [D loss: 0.676235, acc.: 59.38%] [G loss: 0.976532]\n",
      "epoch:2 step:2492 [D loss: 0.672956, acc.: 60.94%] [G loss: 1.048331]\n",
      "epoch:2 step:2493 [D loss: 0.752674, acc.: 49.22%] [G loss: 0.927398]\n",
      "epoch:2 step:2494 [D loss: 0.590191, acc.: 67.19%] [G loss: 1.035110]\n",
      "epoch:2 step:2495 [D loss: 0.697055, acc.: 59.38%] [G loss: 0.952506]\n",
      "epoch:2 step:2496 [D loss: 0.675184, acc.: 53.91%] [G loss: 0.936869]\n",
      "epoch:2 step:2497 [D loss: 0.628604, acc.: 64.06%] [G loss: 1.004151]\n",
      "epoch:2 step:2498 [D loss: 0.596783, acc.: 72.66%] [G loss: 0.928302]\n",
      "epoch:2 step:2499 [D loss: 0.680385, acc.: 59.38%] [G loss: 1.029310]\n",
      "epoch:2 step:2500 [D loss: 0.741145, acc.: 54.69%] [G loss: 0.964234]\n",
      "epoch:2 step:2501 [D loss: 0.694796, acc.: 52.34%] [G loss: 0.803665]\n",
      "epoch:2 step:2502 [D loss: 0.619359, acc.: 65.62%] [G loss: 0.913599]\n",
      "epoch:2 step:2503 [D loss: 0.669024, acc.: 59.38%] [G loss: 1.010586]\n",
      "epoch:2 step:2504 [D loss: 0.639852, acc.: 59.38%] [G loss: 0.934988]\n",
      "epoch:2 step:2505 [D loss: 0.634694, acc.: 64.84%] [G loss: 1.041786]\n",
      "epoch:2 step:2506 [D loss: 0.630593, acc.: 63.28%] [G loss: 1.045825]\n",
      "epoch:2 step:2507 [D loss: 0.707501, acc.: 50.78%] [G loss: 0.985905]\n",
      "epoch:2 step:2508 [D loss: 0.662567, acc.: 62.50%] [G loss: 1.002295]\n",
      "epoch:2 step:2509 [D loss: 0.570614, acc.: 73.44%] [G loss: 1.012806]\n",
      "epoch:2 step:2510 [D loss: 0.697052, acc.: 59.38%] [G loss: 0.990783]\n",
      "epoch:2 step:2511 [D loss: 0.646899, acc.: 57.03%] [G loss: 0.895520]\n",
      "epoch:2 step:2512 [D loss: 0.636120, acc.: 61.72%] [G loss: 0.979021]\n",
      "epoch:2 step:2513 [D loss: 0.655970, acc.: 59.38%] [G loss: 0.890023]\n",
      "epoch:2 step:2514 [D loss: 0.750707, acc.: 50.00%] [G loss: 0.943538]\n",
      "epoch:2 step:2515 [D loss: 0.686961, acc.: 60.94%] [G loss: 0.965154]\n",
      "epoch:2 step:2516 [D loss: 0.665866, acc.: 64.06%] [G loss: 0.988953]\n",
      "epoch:2 step:2517 [D loss: 0.705682, acc.: 52.34%] [G loss: 0.975449]\n",
      "epoch:2 step:2518 [D loss: 0.643749, acc.: 57.81%] [G loss: 0.890473]\n",
      "epoch:2 step:2519 [D loss: 0.728888, acc.: 53.91%] [G loss: 0.885865]\n",
      "epoch:2 step:2520 [D loss: 0.641171, acc.: 61.72%] [G loss: 0.849256]\n",
      "epoch:2 step:2521 [D loss: 0.631666, acc.: 63.28%] [G loss: 0.986507]\n",
      "epoch:2 step:2522 [D loss: 0.610526, acc.: 66.41%] [G loss: 1.005276]\n",
      "epoch:2 step:2523 [D loss: 0.619675, acc.: 67.19%] [G loss: 1.048910]\n",
      "epoch:2 step:2524 [D loss: 0.626263, acc.: 69.53%] [G loss: 1.014386]\n",
      "epoch:2 step:2525 [D loss: 0.638365, acc.: 58.59%] [G loss: 1.036825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2526 [D loss: 0.679148, acc.: 59.38%] [G loss: 0.882297]\n",
      "epoch:2 step:2527 [D loss: 0.739528, acc.: 50.00%] [G loss: 0.963743]\n",
      "epoch:2 step:2528 [D loss: 0.677261, acc.: 57.81%] [G loss: 0.906499]\n",
      "epoch:2 step:2529 [D loss: 0.723052, acc.: 54.69%] [G loss: 0.909339]\n",
      "epoch:2 step:2530 [D loss: 0.654527, acc.: 64.84%] [G loss: 1.117349]\n",
      "epoch:2 step:2531 [D loss: 0.689361, acc.: 57.03%] [G loss: 0.918448]\n",
      "epoch:2 step:2532 [D loss: 0.655423, acc.: 57.03%] [G loss: 0.881484]\n",
      "epoch:2 step:2533 [D loss: 0.671944, acc.: 55.47%] [G loss: 0.888972]\n",
      "epoch:2 step:2534 [D loss: 0.631560, acc.: 66.41%] [G loss: 0.964651]\n",
      "epoch:2 step:2535 [D loss: 0.624086, acc.: 61.72%] [G loss: 0.872782]\n",
      "epoch:2 step:2536 [D loss: 0.740839, acc.: 49.22%] [G loss: 0.923924]\n",
      "epoch:2 step:2537 [D loss: 0.702606, acc.: 52.34%] [G loss: 0.970356]\n",
      "epoch:2 step:2538 [D loss: 0.707711, acc.: 53.91%] [G loss: 0.974291]\n",
      "epoch:2 step:2539 [D loss: 0.695052, acc.: 57.81%] [G loss: 1.015328]\n",
      "epoch:2 step:2540 [D loss: 0.643890, acc.: 62.50%] [G loss: 1.059373]\n",
      "epoch:2 step:2541 [D loss: 0.753986, acc.: 50.78%] [G loss: 0.989623]\n",
      "epoch:2 step:2542 [D loss: 0.663360, acc.: 63.28%] [G loss: 0.958532]\n",
      "epoch:2 step:2543 [D loss: 0.649698, acc.: 60.16%] [G loss: 1.188449]\n",
      "epoch:2 step:2544 [D loss: 0.671539, acc.: 57.03%] [G loss: 0.985317]\n",
      "epoch:2 step:2545 [D loss: 0.678124, acc.: 58.59%] [G loss: 0.981909]\n",
      "epoch:2 step:2546 [D loss: 0.700115, acc.: 53.12%] [G loss: 0.956517]\n",
      "epoch:2 step:2547 [D loss: 0.726543, acc.: 57.81%] [G loss: 0.937591]\n",
      "epoch:2 step:2548 [D loss: 0.691022, acc.: 59.38%] [G loss: 0.877010]\n",
      "epoch:2 step:2549 [D loss: 0.707017, acc.: 55.47%] [G loss: 0.850927]\n",
      "epoch:2 step:2550 [D loss: 0.627199, acc.: 67.97%] [G loss: 1.026345]\n",
      "epoch:2 step:2551 [D loss: 0.664608, acc.: 59.38%] [G loss: 0.936852]\n",
      "epoch:2 step:2552 [D loss: 0.651271, acc.: 63.28%] [G loss: 0.946529]\n",
      "epoch:2 step:2553 [D loss: 0.653684, acc.: 60.94%] [G loss: 1.105390]\n",
      "epoch:2 step:2554 [D loss: 0.665215, acc.: 57.81%] [G loss: 1.030851]\n",
      "epoch:2 step:2555 [D loss: 0.721660, acc.: 47.66%] [G loss: 0.925397]\n",
      "epoch:2 step:2556 [D loss: 0.690977, acc.: 55.47%] [G loss: 0.974933]\n",
      "epoch:2 step:2557 [D loss: 0.651891, acc.: 61.72%] [G loss: 0.948855]\n",
      "epoch:2 step:2558 [D loss: 0.642861, acc.: 63.28%] [G loss: 1.015722]\n",
      "epoch:2 step:2559 [D loss: 0.588125, acc.: 74.22%] [G loss: 1.047684]\n",
      "epoch:2 step:2560 [D loss: 0.666478, acc.: 64.06%] [G loss: 0.952158]\n",
      "epoch:2 step:2561 [D loss: 0.668128, acc.: 59.38%] [G loss: 0.946092]\n",
      "epoch:2 step:2562 [D loss: 0.652681, acc.: 57.81%] [G loss: 0.993057]\n",
      "epoch:2 step:2563 [D loss: 0.653633, acc.: 63.28%] [G loss: 0.921462]\n",
      "epoch:2 step:2564 [D loss: 0.619839, acc.: 64.06%] [G loss: 0.966675]\n",
      "epoch:2 step:2565 [D loss: 0.620546, acc.: 66.41%] [G loss: 0.957585]\n",
      "epoch:2 step:2566 [D loss: 0.747296, acc.: 47.66%] [G loss: 0.912998]\n",
      "epoch:2 step:2567 [D loss: 0.624943, acc.: 68.75%] [G loss: 0.987845]\n",
      "epoch:2 step:2568 [D loss: 0.585254, acc.: 67.97%] [G loss: 1.076597]\n",
      "epoch:2 step:2569 [D loss: 0.737515, acc.: 51.56%] [G loss: 0.863047]\n",
      "epoch:2 step:2570 [D loss: 0.682041, acc.: 54.69%] [G loss: 0.979091]\n",
      "epoch:2 step:2571 [D loss: 0.724916, acc.: 53.91%] [G loss: 0.946683]\n",
      "epoch:2 step:2572 [D loss: 0.650844, acc.: 60.94%] [G loss: 0.975918]\n",
      "epoch:2 step:2573 [D loss: 0.696558, acc.: 55.47%] [G loss: 0.982981]\n",
      "epoch:2 step:2574 [D loss: 0.630438, acc.: 63.28%] [G loss: 0.947122]\n",
      "epoch:2 step:2575 [D loss: 0.679344, acc.: 57.03%] [G loss: 0.929727]\n",
      "epoch:2 step:2576 [D loss: 0.701971, acc.: 51.56%] [G loss: 0.932480]\n",
      "epoch:2 step:2577 [D loss: 0.712992, acc.: 54.69%] [G loss: 0.965740]\n",
      "epoch:2 step:2578 [D loss: 0.757990, acc.: 52.34%] [G loss: 0.889101]\n",
      "epoch:2 step:2579 [D loss: 0.666161, acc.: 62.50%] [G loss: 0.972635]\n",
      "epoch:2 step:2580 [D loss: 0.668051, acc.: 54.69%] [G loss: 1.044153]\n",
      "epoch:2 step:2581 [D loss: 0.698991, acc.: 57.81%] [G loss: 0.995286]\n",
      "epoch:2 step:2582 [D loss: 0.663823, acc.: 58.59%] [G loss: 0.994420]\n",
      "epoch:2 step:2583 [D loss: 0.569449, acc.: 71.88%] [G loss: 1.073669]\n",
      "epoch:2 step:2584 [D loss: 0.741392, acc.: 53.12%] [G loss: 0.973278]\n",
      "epoch:2 step:2585 [D loss: 0.786085, acc.: 46.09%] [G loss: 0.987023]\n",
      "epoch:2 step:2586 [D loss: 0.632878, acc.: 68.75%] [G loss: 0.914849]\n",
      "epoch:2 step:2587 [D loss: 0.586996, acc.: 71.88%] [G loss: 0.952720]\n",
      "epoch:2 step:2588 [D loss: 0.623354, acc.: 65.62%] [G loss: 1.007619]\n",
      "epoch:2 step:2589 [D loss: 0.689729, acc.: 56.25%] [G loss: 1.093213]\n",
      "epoch:2 step:2590 [D loss: 0.713702, acc.: 57.81%] [G loss: 1.027079]\n",
      "epoch:2 step:2591 [D loss: 0.753951, acc.: 46.88%] [G loss: 0.908546]\n",
      "epoch:2 step:2592 [D loss: 0.679179, acc.: 57.81%] [G loss: 0.947361]\n",
      "epoch:2 step:2593 [D loss: 0.681047, acc.: 61.72%] [G loss: 0.905578]\n",
      "epoch:2 step:2594 [D loss: 0.726373, acc.: 52.34%] [G loss: 0.883794]\n",
      "epoch:2 step:2595 [D loss: 0.654677, acc.: 59.38%] [G loss: 0.933667]\n",
      "epoch:2 step:2596 [D loss: 0.667917, acc.: 63.28%] [G loss: 1.058243]\n",
      "epoch:2 step:2597 [D loss: 0.691577, acc.: 56.25%] [G loss: 0.988148]\n",
      "epoch:2 step:2598 [D loss: 0.658934, acc.: 62.50%] [G loss: 0.998522]\n",
      "epoch:2 step:2599 [D loss: 0.678664, acc.: 57.81%] [G loss: 1.063928]\n",
      "epoch:2 step:2600 [D loss: 0.627904, acc.: 67.97%] [G loss: 0.942945]\n",
      "epoch:2 step:2601 [D loss: 0.679961, acc.: 55.47%] [G loss: 0.863172]\n",
      "epoch:2 step:2602 [D loss: 0.670222, acc.: 57.03%] [G loss: 0.934842]\n",
      "epoch:2 step:2603 [D loss: 0.706360, acc.: 56.25%] [G loss: 0.843681]\n",
      "epoch:2 step:2604 [D loss: 0.619001, acc.: 65.62%] [G loss: 0.969484]\n",
      "epoch:2 step:2605 [D loss: 0.630827, acc.: 67.19%] [G loss: 0.951070]\n",
      "epoch:2 step:2606 [D loss: 0.629742, acc.: 62.50%] [G loss: 1.007566]\n",
      "epoch:2 step:2607 [D loss: 0.653839, acc.: 59.38%] [G loss: 0.908572]\n",
      "epoch:2 step:2608 [D loss: 0.681760, acc.: 57.81%] [G loss: 1.028524]\n",
      "epoch:2 step:2609 [D loss: 0.652103, acc.: 58.59%] [G loss: 0.910900]\n",
      "epoch:2 step:2610 [D loss: 0.672334, acc.: 62.50%] [G loss: 0.908990]\n",
      "epoch:2 step:2611 [D loss: 0.668762, acc.: 60.16%] [G loss: 0.923476]\n",
      "epoch:2 step:2612 [D loss: 0.697648, acc.: 51.56%] [G loss: 0.902828]\n",
      "epoch:2 step:2613 [D loss: 0.650896, acc.: 65.62%] [G loss: 0.943930]\n",
      "epoch:2 step:2614 [D loss: 0.705819, acc.: 60.16%] [G loss: 0.936634]\n",
      "epoch:2 step:2615 [D loss: 0.700790, acc.: 57.03%] [G loss: 0.909930]\n",
      "epoch:2 step:2616 [D loss: 0.720414, acc.: 50.78%] [G loss: 0.886596]\n",
      "epoch:2 step:2617 [D loss: 0.666413, acc.: 64.06%] [G loss: 1.053045]\n",
      "epoch:2 step:2618 [D loss: 0.734347, acc.: 50.00%] [G loss: 0.832661]\n",
      "epoch:2 step:2619 [D loss: 0.623058, acc.: 63.28%] [G loss: 1.016487]\n",
      "epoch:2 step:2620 [D loss: 0.634165, acc.: 60.94%] [G loss: 0.907501]\n",
      "epoch:2 step:2621 [D loss: 0.584276, acc.: 71.88%] [G loss: 0.936683]\n",
      "epoch:2 step:2622 [D loss: 0.650165, acc.: 64.84%] [G loss: 0.876946]\n",
      "epoch:2 step:2623 [D loss: 0.674673, acc.: 56.25%] [G loss: 0.958797]\n",
      "epoch:2 step:2624 [D loss: 0.664861, acc.: 60.94%] [G loss: 1.056822]\n",
      "epoch:2 step:2625 [D loss: 0.717707, acc.: 54.69%] [G loss: 0.981604]\n",
      "epoch:2 step:2626 [D loss: 0.676610, acc.: 63.28%] [G loss: 0.896857]\n",
      "epoch:2 step:2627 [D loss: 0.691905, acc.: 53.12%] [G loss: 0.973413]\n",
      "epoch:2 step:2628 [D loss: 0.669538, acc.: 60.94%] [G loss: 0.989442]\n",
      "epoch:2 step:2629 [D loss: 0.612876, acc.: 67.97%] [G loss: 1.044217]\n",
      "epoch:2 step:2630 [D loss: 0.678596, acc.: 55.47%] [G loss: 1.004557]\n",
      "epoch:2 step:2631 [D loss: 0.697506, acc.: 56.25%] [G loss: 0.945422]\n",
      "epoch:2 step:2632 [D loss: 0.626587, acc.: 64.84%] [G loss: 0.936768]\n",
      "epoch:2 step:2633 [D loss: 0.632466, acc.: 61.72%] [G loss: 0.984945]\n",
      "epoch:2 step:2634 [D loss: 0.667117, acc.: 64.06%] [G loss: 1.025713]\n",
      "epoch:2 step:2635 [D loss: 0.663134, acc.: 63.28%] [G loss: 0.976434]\n",
      "epoch:2 step:2636 [D loss: 0.679117, acc.: 57.03%] [G loss: 1.009577]\n",
      "epoch:2 step:2637 [D loss: 0.657621, acc.: 60.94%] [G loss: 1.136855]\n",
      "epoch:2 step:2638 [D loss: 0.633167, acc.: 63.28%] [G loss: 1.069360]\n",
      "epoch:2 step:2639 [D loss: 0.719044, acc.: 52.34%] [G loss: 0.849939]\n",
      "epoch:2 step:2640 [D loss: 0.659977, acc.: 60.16%] [G loss: 1.001111]\n",
      "epoch:2 step:2641 [D loss: 0.666188, acc.: 65.62%] [G loss: 0.973622]\n",
      "epoch:2 step:2642 [D loss: 0.684959, acc.: 59.38%] [G loss: 0.952314]\n",
      "epoch:2 step:2643 [D loss: 0.680690, acc.: 58.59%] [G loss: 0.825720]\n",
      "epoch:2 step:2644 [D loss: 0.653357, acc.: 64.06%] [G loss: 0.932804]\n",
      "epoch:2 step:2645 [D loss: 0.643009, acc.: 60.94%] [G loss: 0.986570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2646 [D loss: 0.604350, acc.: 67.19%] [G loss: 1.005080]\n",
      "epoch:2 step:2647 [D loss: 0.621521, acc.: 67.97%] [G loss: 0.962705]\n",
      "epoch:2 step:2648 [D loss: 0.720124, acc.: 50.00%] [G loss: 0.981021]\n",
      "epoch:2 step:2649 [D loss: 0.670520, acc.: 57.81%] [G loss: 1.063936]\n",
      "epoch:2 step:2650 [D loss: 0.699874, acc.: 55.47%] [G loss: 0.895547]\n",
      "epoch:2 step:2651 [D loss: 0.629216, acc.: 63.28%] [G loss: 0.991378]\n",
      "epoch:2 step:2652 [D loss: 0.719078, acc.: 50.00%] [G loss: 0.947248]\n",
      "epoch:2 step:2653 [D loss: 0.631411, acc.: 61.72%] [G loss: 0.894353]\n",
      "epoch:2 step:2654 [D loss: 0.699266, acc.: 53.12%] [G loss: 0.943352]\n",
      "epoch:2 step:2655 [D loss: 0.686624, acc.: 61.72%] [G loss: 0.969675]\n",
      "epoch:2 step:2656 [D loss: 0.621623, acc.: 61.72%] [G loss: 0.947302]\n",
      "epoch:2 step:2657 [D loss: 0.620528, acc.: 65.62%] [G loss: 0.924654]\n",
      "epoch:2 step:2658 [D loss: 0.656165, acc.: 60.16%] [G loss: 0.977005]\n",
      "epoch:2 step:2659 [D loss: 0.620836, acc.: 67.19%] [G loss: 0.964666]\n",
      "epoch:2 step:2660 [D loss: 0.641993, acc.: 62.50%] [G loss: 0.923260]\n",
      "epoch:2 step:2661 [D loss: 0.672022, acc.: 60.16%] [G loss: 0.996834]\n",
      "epoch:2 step:2662 [D loss: 0.683437, acc.: 56.25%] [G loss: 1.003923]\n",
      "epoch:2 step:2663 [D loss: 0.649699, acc.: 66.41%] [G loss: 0.915272]\n",
      "epoch:2 step:2664 [D loss: 0.599998, acc.: 69.53%] [G loss: 0.974372]\n",
      "epoch:2 step:2665 [D loss: 0.655225, acc.: 60.94%] [G loss: 1.039048]\n",
      "epoch:2 step:2666 [D loss: 0.632266, acc.: 64.06%] [G loss: 1.008214]\n",
      "epoch:2 step:2667 [D loss: 0.643412, acc.: 65.62%] [G loss: 0.863873]\n",
      "epoch:2 step:2668 [D loss: 0.723684, acc.: 57.81%] [G loss: 0.935171]\n",
      "epoch:2 step:2669 [D loss: 0.655718, acc.: 63.28%] [G loss: 1.014123]\n",
      "epoch:2 step:2670 [D loss: 0.630164, acc.: 66.41%] [G loss: 0.914725]\n",
      "epoch:2 step:2671 [D loss: 0.621638, acc.: 67.19%] [G loss: 1.021372]\n",
      "epoch:2 step:2672 [D loss: 0.619444, acc.: 66.41%] [G loss: 0.886891]\n",
      "epoch:2 step:2673 [D loss: 0.707115, acc.: 60.16%] [G loss: 1.033196]\n",
      "epoch:2 step:2674 [D loss: 0.735945, acc.: 55.47%] [G loss: 1.052988]\n",
      "epoch:2 step:2675 [D loss: 0.723051, acc.: 47.66%] [G loss: 0.833868]\n",
      "epoch:2 step:2676 [D loss: 0.691412, acc.: 58.59%] [G loss: 0.954597]\n",
      "epoch:2 step:2677 [D loss: 0.686252, acc.: 53.91%] [G loss: 1.011885]\n",
      "epoch:2 step:2678 [D loss: 0.704608, acc.: 53.91%] [G loss: 0.966383]\n",
      "epoch:2 step:2679 [D loss: 0.640627, acc.: 64.06%] [G loss: 0.984622]\n",
      "epoch:2 step:2680 [D loss: 0.613196, acc.: 68.75%] [G loss: 0.933339]\n",
      "epoch:2 step:2681 [D loss: 0.629056, acc.: 66.41%] [G loss: 0.993480]\n",
      "epoch:2 step:2682 [D loss: 0.619794, acc.: 67.19%] [G loss: 1.056328]\n",
      "epoch:2 step:2683 [D loss: 0.605691, acc.: 69.53%] [G loss: 1.003116]\n",
      "epoch:2 step:2684 [D loss: 0.683989, acc.: 56.25%] [G loss: 0.962404]\n",
      "epoch:2 step:2685 [D loss: 0.655075, acc.: 56.25%] [G loss: 0.926879]\n",
      "epoch:2 step:2686 [D loss: 0.670289, acc.: 57.81%] [G loss: 0.934211]\n",
      "epoch:2 step:2687 [D loss: 0.643283, acc.: 64.06%] [G loss: 0.891482]\n",
      "epoch:2 step:2688 [D loss: 0.662432, acc.: 57.81%] [G loss: 0.943258]\n",
      "epoch:2 step:2689 [D loss: 0.687281, acc.: 55.47%] [G loss: 0.954901]\n",
      "epoch:2 step:2690 [D loss: 0.672202, acc.: 58.59%] [G loss: 1.006872]\n",
      "epoch:2 step:2691 [D loss: 0.721517, acc.: 57.81%] [G loss: 1.053971]\n",
      "epoch:2 step:2692 [D loss: 0.674961, acc.: 59.38%] [G loss: 0.907431]\n",
      "epoch:2 step:2693 [D loss: 0.616250, acc.: 63.28%] [G loss: 1.029910]\n",
      "epoch:2 step:2694 [D loss: 0.644619, acc.: 64.06%] [G loss: 1.030788]\n",
      "epoch:2 step:2695 [D loss: 0.616825, acc.: 70.31%] [G loss: 1.038154]\n",
      "epoch:2 step:2696 [D loss: 0.656584, acc.: 54.69%] [G loss: 0.984916]\n",
      "epoch:2 step:2697 [D loss: 0.605496, acc.: 68.75%] [G loss: 0.995708]\n",
      "epoch:2 step:2698 [D loss: 0.715577, acc.: 52.34%] [G loss: 0.942959]\n",
      "epoch:2 step:2699 [D loss: 0.680661, acc.: 61.72%] [G loss: 1.046614]\n",
      "epoch:2 step:2700 [D loss: 0.699233, acc.: 55.47%] [G loss: 0.969297]\n",
      "epoch:2 step:2701 [D loss: 0.730140, acc.: 54.69%] [G loss: 0.893656]\n",
      "epoch:2 step:2702 [D loss: 0.706660, acc.: 50.00%] [G loss: 0.890836]\n",
      "epoch:2 step:2703 [D loss: 0.648896, acc.: 59.38%] [G loss: 1.009484]\n",
      "epoch:2 step:2704 [D loss: 0.651045, acc.: 57.03%] [G loss: 0.920851]\n",
      "epoch:2 step:2705 [D loss: 0.642120, acc.: 64.84%] [G loss: 1.002413]\n",
      "epoch:2 step:2706 [D loss: 0.655641, acc.: 57.81%] [G loss: 0.975546]\n",
      "epoch:2 step:2707 [D loss: 0.618172, acc.: 64.84%] [G loss: 1.012475]\n",
      "epoch:2 step:2708 [D loss: 0.647690, acc.: 63.28%] [G loss: 1.059837]\n",
      "epoch:2 step:2709 [D loss: 0.707204, acc.: 58.59%] [G loss: 1.022839]\n",
      "epoch:2 step:2710 [D loss: 0.707885, acc.: 57.81%] [G loss: 1.051403]\n",
      "epoch:2 step:2711 [D loss: 0.636568, acc.: 64.84%] [G loss: 0.998130]\n",
      "epoch:2 step:2712 [D loss: 0.639079, acc.: 64.06%] [G loss: 0.920060]\n",
      "epoch:2 step:2713 [D loss: 0.694703, acc.: 61.72%] [G loss: 0.978918]\n",
      "epoch:2 step:2714 [D loss: 0.633429, acc.: 65.62%] [G loss: 1.028880]\n",
      "epoch:2 step:2715 [D loss: 0.624283, acc.: 67.19%] [G loss: 1.045155]\n",
      "epoch:2 step:2716 [D loss: 0.662560, acc.: 61.72%] [G loss: 0.924261]\n",
      "epoch:2 step:2717 [D loss: 0.683621, acc.: 61.72%] [G loss: 0.935285]\n",
      "epoch:2 step:2718 [D loss: 0.681470, acc.: 57.03%] [G loss: 1.031192]\n",
      "epoch:2 step:2719 [D loss: 0.692200, acc.: 59.38%] [G loss: 0.848426]\n",
      "epoch:2 step:2720 [D loss: 0.706561, acc.: 53.91%] [G loss: 0.826299]\n",
      "epoch:2 step:2721 [D loss: 0.738179, acc.: 46.09%] [G loss: 1.011898]\n",
      "epoch:2 step:2722 [D loss: 0.614228, acc.: 64.84%] [G loss: 0.961965]\n",
      "epoch:2 step:2723 [D loss: 0.706472, acc.: 55.47%] [G loss: 0.972926]\n",
      "epoch:2 step:2724 [D loss: 0.699458, acc.: 58.59%] [G loss: 0.918349]\n",
      "epoch:2 step:2725 [D loss: 0.659007, acc.: 60.94%] [G loss: 0.898099]\n",
      "epoch:2 step:2726 [D loss: 0.643050, acc.: 59.38%] [G loss: 1.069312]\n",
      "epoch:2 step:2727 [D loss: 0.628972, acc.: 59.38%] [G loss: 1.058760]\n",
      "epoch:2 step:2728 [D loss: 0.651803, acc.: 64.84%] [G loss: 0.891289]\n",
      "epoch:2 step:2729 [D loss: 0.639832, acc.: 60.16%] [G loss: 1.005419]\n",
      "epoch:2 step:2730 [D loss: 0.691429, acc.: 57.03%] [G loss: 0.904088]\n",
      "epoch:2 step:2731 [D loss: 0.641767, acc.: 63.28%] [G loss: 0.999550]\n",
      "epoch:2 step:2732 [D loss: 0.717665, acc.: 51.56%] [G loss: 0.878685]\n",
      "epoch:2 step:2733 [D loss: 0.733490, acc.: 50.78%] [G loss: 0.894142]\n",
      "epoch:2 step:2734 [D loss: 0.641788, acc.: 63.28%] [G loss: 0.921656]\n",
      "epoch:2 step:2735 [D loss: 0.587175, acc.: 67.19%] [G loss: 0.985472]\n",
      "epoch:2 step:2736 [D loss: 0.647184, acc.: 65.62%] [G loss: 0.862547]\n",
      "epoch:2 step:2737 [D loss: 0.607197, acc.: 65.62%] [G loss: 0.962903]\n",
      "epoch:2 step:2738 [D loss: 0.696069, acc.: 60.94%] [G loss: 0.886438]\n",
      "epoch:2 step:2739 [D loss: 0.714229, acc.: 53.91%] [G loss: 0.895551]\n",
      "epoch:2 step:2740 [D loss: 0.648284, acc.: 67.19%] [G loss: 0.959097]\n",
      "epoch:2 step:2741 [D loss: 0.670539, acc.: 60.16%] [G loss: 1.037589]\n",
      "epoch:2 step:2742 [D loss: 0.736116, acc.: 48.44%] [G loss: 0.965200]\n",
      "epoch:2 step:2743 [D loss: 0.633664, acc.: 61.72%] [G loss: 1.042088]\n",
      "epoch:2 step:2744 [D loss: 0.741179, acc.: 50.00%] [G loss: 0.945786]\n",
      "epoch:2 step:2745 [D loss: 0.690792, acc.: 54.69%] [G loss: 0.997672]\n",
      "epoch:2 step:2746 [D loss: 0.586092, acc.: 69.53%] [G loss: 0.994582]\n",
      "epoch:2 step:2747 [D loss: 0.619668, acc.: 67.19%] [G loss: 0.987253]\n",
      "epoch:2 step:2748 [D loss: 0.695171, acc.: 52.34%] [G loss: 1.106047]\n",
      "epoch:2 step:2749 [D loss: 0.641777, acc.: 61.72%] [G loss: 1.072305]\n",
      "epoch:2 step:2750 [D loss: 0.631831, acc.: 61.72%] [G loss: 0.997848]\n",
      "epoch:2 step:2751 [D loss: 0.624835, acc.: 69.53%] [G loss: 1.030090]\n",
      "epoch:2 step:2752 [D loss: 0.684402, acc.: 55.47%] [G loss: 0.985688]\n",
      "epoch:2 step:2753 [D loss: 0.697663, acc.: 55.47%] [G loss: 0.979918]\n",
      "epoch:2 step:2754 [D loss: 0.716947, acc.: 57.03%] [G loss: 1.088403]\n",
      "epoch:2 step:2755 [D loss: 0.717151, acc.: 53.91%] [G loss: 0.939222]\n",
      "epoch:2 step:2756 [D loss: 0.678354, acc.: 59.38%] [G loss: 1.001391]\n",
      "epoch:2 step:2757 [D loss: 0.740108, acc.: 50.78%] [G loss: 0.915261]\n",
      "epoch:2 step:2758 [D loss: 0.573382, acc.: 70.31%] [G loss: 1.024373]\n",
      "epoch:2 step:2759 [D loss: 0.688665, acc.: 54.69%] [G loss: 1.076830]\n",
      "epoch:2 step:2760 [D loss: 0.605279, acc.: 68.75%] [G loss: 1.062698]\n",
      "epoch:2 step:2761 [D loss: 0.618119, acc.: 70.31%] [G loss: 1.048568]\n",
      "epoch:2 step:2762 [D loss: 0.602563, acc.: 63.28%] [G loss: 1.064106]\n",
      "epoch:2 step:2763 [D loss: 0.633162, acc.: 63.28%] [G loss: 1.017163]\n",
      "epoch:2 step:2764 [D loss: 0.549512, acc.: 77.34%] [G loss: 1.104430]\n",
      "epoch:2 step:2765 [D loss: 0.682248, acc.: 57.81%] [G loss: 0.981560]\n",
      "epoch:2 step:2766 [D loss: 0.750895, acc.: 50.00%] [G loss: 1.003724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2767 [D loss: 0.712101, acc.: 57.03%] [G loss: 0.919088]\n",
      "epoch:2 step:2768 [D loss: 0.701639, acc.: 55.47%] [G loss: 0.934985]\n",
      "epoch:2 step:2769 [D loss: 0.646525, acc.: 64.06%] [G loss: 0.915645]\n",
      "epoch:2 step:2770 [D loss: 0.747397, acc.: 46.09%] [G loss: 1.024039]\n",
      "epoch:2 step:2771 [D loss: 0.583429, acc.: 67.19%] [G loss: 0.934275]\n",
      "epoch:2 step:2772 [D loss: 0.702149, acc.: 51.56%] [G loss: 0.934603]\n",
      "epoch:2 step:2773 [D loss: 0.660911, acc.: 59.38%] [G loss: 0.948505]\n",
      "epoch:2 step:2774 [D loss: 0.688878, acc.: 54.69%] [G loss: 0.995916]\n",
      "epoch:2 step:2775 [D loss: 0.669404, acc.: 62.50%] [G loss: 1.101737]\n",
      "epoch:2 step:2776 [D loss: 0.651432, acc.: 60.94%] [G loss: 1.013928]\n",
      "epoch:2 step:2777 [D loss: 0.696534, acc.: 60.16%] [G loss: 0.983329]\n",
      "epoch:2 step:2778 [D loss: 0.615649, acc.: 65.62%] [G loss: 0.973151]\n",
      "epoch:2 step:2779 [D loss: 0.654528, acc.: 59.38%] [G loss: 0.925803]\n",
      "epoch:2 step:2780 [D loss: 0.657495, acc.: 63.28%] [G loss: 0.997848]\n",
      "epoch:2 step:2781 [D loss: 0.611267, acc.: 67.19%] [G loss: 0.945465]\n",
      "epoch:2 step:2782 [D loss: 0.693910, acc.: 52.34%] [G loss: 0.941582]\n",
      "epoch:2 step:2783 [D loss: 0.592355, acc.: 68.75%] [G loss: 1.024864]\n",
      "epoch:2 step:2784 [D loss: 0.547547, acc.: 72.66%] [G loss: 0.944117]\n",
      "epoch:2 step:2785 [D loss: 0.606200, acc.: 69.53%] [G loss: 1.066786]\n",
      "epoch:2 step:2786 [D loss: 0.551075, acc.: 70.31%] [G loss: 1.046029]\n",
      "epoch:2 step:2787 [D loss: 0.703369, acc.: 53.91%] [G loss: 0.957697]\n",
      "epoch:2 step:2788 [D loss: 0.645441, acc.: 64.06%] [G loss: 0.968179]\n",
      "epoch:2 step:2789 [D loss: 0.663288, acc.: 64.06%] [G loss: 0.932802]\n",
      "epoch:2 step:2790 [D loss: 0.672133, acc.: 58.59%] [G loss: 0.877181]\n",
      "epoch:2 step:2791 [D loss: 0.646934, acc.: 65.62%] [G loss: 1.064756]\n",
      "epoch:2 step:2792 [D loss: 0.608557, acc.: 69.53%] [G loss: 1.040085]\n",
      "epoch:2 step:2793 [D loss: 0.581678, acc.: 71.09%] [G loss: 1.004672]\n",
      "epoch:2 step:2794 [D loss: 0.782161, acc.: 47.66%] [G loss: 0.945135]\n",
      "epoch:2 step:2795 [D loss: 0.677716, acc.: 60.16%] [G loss: 0.877875]\n",
      "epoch:2 step:2796 [D loss: 0.578470, acc.: 64.84%] [G loss: 0.904171]\n",
      "epoch:2 step:2797 [D loss: 0.568827, acc.: 70.31%] [G loss: 0.924061]\n",
      "epoch:2 step:2798 [D loss: 0.568955, acc.: 76.56%] [G loss: 0.964721]\n",
      "epoch:2 step:2799 [D loss: 0.581844, acc.: 70.31%] [G loss: 1.109720]\n",
      "epoch:2 step:2800 [D loss: 0.566230, acc.: 71.88%] [G loss: 1.048853]\n",
      "epoch:2 step:2801 [D loss: 0.665425, acc.: 61.72%] [G loss: 1.019423]\n",
      "epoch:2 step:2802 [D loss: 0.929811, acc.: 39.06%] [G loss: 0.960954]\n",
      "epoch:2 step:2803 [D loss: 0.742681, acc.: 53.91%] [G loss: 0.890135]\n",
      "epoch:2 step:2804 [D loss: 0.553636, acc.: 75.78%] [G loss: 0.932147]\n",
      "epoch:2 step:2805 [D loss: 0.639853, acc.: 65.62%] [G loss: 0.973102]\n",
      "epoch:2 step:2806 [D loss: 0.657855, acc.: 60.16%] [G loss: 0.984251]\n",
      "epoch:2 step:2807 [D loss: 0.695552, acc.: 54.69%] [G loss: 0.998812]\n",
      "epoch:2 step:2808 [D loss: 0.680821, acc.: 57.81%] [G loss: 0.961347]\n",
      "epoch:2 step:2809 [D loss: 0.653992, acc.: 61.72%] [G loss: 0.913982]\n",
      "epoch:2 step:2810 [D loss: 0.590284, acc.: 71.09%] [G loss: 0.993388]\n",
      "epoch:2 step:2811 [D loss: 0.536372, acc.: 73.44%] [G loss: 1.144711]\n",
      "epoch:3 step:2812 [D loss: 0.617944, acc.: 64.06%] [G loss: 1.049349]\n",
      "epoch:3 step:2813 [D loss: 0.624510, acc.: 66.41%] [G loss: 0.945769]\n",
      "epoch:3 step:2814 [D loss: 0.670673, acc.: 60.16%] [G loss: 0.957337]\n",
      "epoch:3 step:2815 [D loss: 0.672177, acc.: 59.38%] [G loss: 0.979317]\n",
      "epoch:3 step:2816 [D loss: 0.600633, acc.: 65.62%] [G loss: 1.054883]\n",
      "epoch:3 step:2817 [D loss: 0.665205, acc.: 62.50%] [G loss: 1.065539]\n",
      "epoch:3 step:2818 [D loss: 0.634221, acc.: 66.41%] [G loss: 0.934353]\n",
      "epoch:3 step:2819 [D loss: 0.640225, acc.: 57.81%] [G loss: 1.011190]\n",
      "epoch:3 step:2820 [D loss: 0.690978, acc.: 55.47%] [G loss: 1.017893]\n",
      "epoch:3 step:2821 [D loss: 0.684213, acc.: 60.16%] [G loss: 0.968035]\n",
      "epoch:3 step:2822 [D loss: 0.685456, acc.: 60.94%] [G loss: 0.952078]\n",
      "epoch:3 step:2823 [D loss: 0.707785, acc.: 55.47%] [G loss: 1.033214]\n",
      "epoch:3 step:2824 [D loss: 0.656202, acc.: 65.62%] [G loss: 1.000767]\n",
      "epoch:3 step:2825 [D loss: 0.695669, acc.: 60.16%] [G loss: 0.924420]\n",
      "epoch:3 step:2826 [D loss: 0.580908, acc.: 71.88%] [G loss: 1.099643]\n",
      "epoch:3 step:2827 [D loss: 0.652048, acc.: 59.38%] [G loss: 0.982336]\n",
      "epoch:3 step:2828 [D loss: 0.747674, acc.: 47.66%] [G loss: 0.938731]\n",
      "epoch:3 step:2829 [D loss: 0.774939, acc.: 52.34%] [G loss: 0.916881]\n",
      "epoch:3 step:2830 [D loss: 0.642966, acc.: 63.28%] [G loss: 0.975316]\n",
      "epoch:3 step:2831 [D loss: 0.825385, acc.: 42.97%] [G loss: 0.901633]\n",
      "epoch:3 step:2832 [D loss: 0.630278, acc.: 66.41%] [G loss: 0.946749]\n",
      "epoch:3 step:2833 [D loss: 0.720498, acc.: 46.09%] [G loss: 0.922123]\n",
      "epoch:3 step:2834 [D loss: 0.613626, acc.: 68.75%] [G loss: 0.961398]\n",
      "epoch:3 step:2835 [D loss: 0.677026, acc.: 59.38%] [G loss: 1.050383]\n",
      "epoch:3 step:2836 [D loss: 0.610596, acc.: 64.06%] [G loss: 0.976142]\n",
      "epoch:3 step:2837 [D loss: 0.673305, acc.: 57.81%] [G loss: 1.017190]\n",
      "epoch:3 step:2838 [D loss: 0.630786, acc.: 65.62%] [G loss: 1.033350]\n",
      "epoch:3 step:2839 [D loss: 0.678708, acc.: 54.69%] [G loss: 0.946316]\n",
      "epoch:3 step:2840 [D loss: 0.628949, acc.: 65.62%] [G loss: 1.034524]\n",
      "epoch:3 step:2841 [D loss: 0.764038, acc.: 44.53%] [G loss: 0.906153]\n",
      "epoch:3 step:2842 [D loss: 0.702619, acc.: 56.25%] [G loss: 0.924759]\n",
      "epoch:3 step:2843 [D loss: 0.694058, acc.: 53.91%] [G loss: 1.022240]\n",
      "epoch:3 step:2844 [D loss: 0.600896, acc.: 70.31%] [G loss: 0.961707]\n",
      "epoch:3 step:2845 [D loss: 0.645594, acc.: 67.19%] [G loss: 1.000873]\n",
      "epoch:3 step:2846 [D loss: 0.634839, acc.: 64.06%] [G loss: 1.045140]\n",
      "epoch:3 step:2847 [D loss: 0.638437, acc.: 61.72%] [G loss: 1.039372]\n",
      "epoch:3 step:2848 [D loss: 0.617033, acc.: 67.97%] [G loss: 1.018801]\n",
      "epoch:3 step:2849 [D loss: 0.685178, acc.: 64.84%] [G loss: 1.075623]\n",
      "epoch:3 step:2850 [D loss: 0.684625, acc.: 57.03%] [G loss: 0.893962]\n",
      "epoch:3 step:2851 [D loss: 0.657785, acc.: 63.28%] [G loss: 0.988544]\n",
      "epoch:3 step:2852 [D loss: 0.677716, acc.: 56.25%] [G loss: 0.921695]\n",
      "epoch:3 step:2853 [D loss: 0.644150, acc.: 63.28%] [G loss: 0.926812]\n",
      "epoch:3 step:2854 [D loss: 0.744587, acc.: 53.12%] [G loss: 1.043376]\n",
      "epoch:3 step:2855 [D loss: 0.729424, acc.: 52.34%] [G loss: 0.902224]\n",
      "epoch:3 step:2856 [D loss: 0.645820, acc.: 63.28%] [G loss: 1.055760]\n",
      "epoch:3 step:2857 [D loss: 0.655160, acc.: 60.16%] [G loss: 0.993199]\n",
      "epoch:3 step:2858 [D loss: 0.694349, acc.: 55.47%] [G loss: 0.915497]\n",
      "epoch:3 step:2859 [D loss: 0.587369, acc.: 68.75%] [G loss: 1.026870]\n",
      "epoch:3 step:2860 [D loss: 0.635315, acc.: 65.62%] [G loss: 0.935742]\n",
      "epoch:3 step:2861 [D loss: 0.630823, acc.: 70.31%] [G loss: 0.992757]\n",
      "epoch:3 step:2862 [D loss: 0.674720, acc.: 57.81%] [G loss: 1.122300]\n",
      "epoch:3 step:2863 [D loss: 0.658889, acc.: 60.94%] [G loss: 0.983553]\n",
      "epoch:3 step:2864 [D loss: 0.631364, acc.: 63.28%] [G loss: 0.999754]\n",
      "epoch:3 step:2865 [D loss: 0.599402, acc.: 63.28%] [G loss: 0.950108]\n",
      "epoch:3 step:2866 [D loss: 0.631540, acc.: 64.06%] [G loss: 1.024311]\n",
      "epoch:3 step:2867 [D loss: 0.712077, acc.: 59.38%] [G loss: 0.940300]\n",
      "epoch:3 step:2868 [D loss: 0.640139, acc.: 67.97%] [G loss: 1.072831]\n",
      "epoch:3 step:2869 [D loss: 0.678685, acc.: 58.59%] [G loss: 0.951607]\n",
      "epoch:3 step:2870 [D loss: 0.680223, acc.: 63.28%] [G loss: 0.988556]\n",
      "epoch:3 step:2871 [D loss: 0.688808, acc.: 60.94%] [G loss: 0.933354]\n",
      "epoch:3 step:2872 [D loss: 0.662142, acc.: 61.72%] [G loss: 1.024909]\n",
      "epoch:3 step:2873 [D loss: 0.695387, acc.: 55.47%] [G loss: 1.003960]\n",
      "epoch:3 step:2874 [D loss: 0.619039, acc.: 67.19%] [G loss: 1.036062]\n",
      "epoch:3 step:2875 [D loss: 0.693943, acc.: 55.47%] [G loss: 0.874481]\n",
      "epoch:3 step:2876 [D loss: 0.701994, acc.: 58.59%] [G loss: 1.042850]\n",
      "epoch:3 step:2877 [D loss: 0.697148, acc.: 53.12%] [G loss: 1.008088]\n",
      "epoch:3 step:2878 [D loss: 0.614463, acc.: 66.41%] [G loss: 0.997691]\n",
      "epoch:3 step:2879 [D loss: 0.661511, acc.: 59.38%] [G loss: 0.914666]\n",
      "epoch:3 step:2880 [D loss: 0.700695, acc.: 55.47%] [G loss: 0.983495]\n",
      "epoch:3 step:2881 [D loss: 0.657601, acc.: 57.81%] [G loss: 0.887186]\n",
      "epoch:3 step:2882 [D loss: 0.614397, acc.: 69.53%] [G loss: 0.946021]\n",
      "epoch:3 step:2883 [D loss: 0.618985, acc.: 61.72%] [G loss: 0.985069]\n",
      "epoch:3 step:2884 [D loss: 0.666724, acc.: 60.16%] [G loss: 0.978314]\n",
      "epoch:3 step:2885 [D loss: 0.760634, acc.: 47.66%] [G loss: 1.037231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2886 [D loss: 0.629104, acc.: 64.06%] [G loss: 1.128918]\n",
      "epoch:3 step:2887 [D loss: 0.612075, acc.: 68.75%] [G loss: 1.089867]\n",
      "epoch:3 step:2888 [D loss: 0.615687, acc.: 67.19%] [G loss: 1.114245]\n",
      "epoch:3 step:2889 [D loss: 0.640908, acc.: 62.50%] [G loss: 1.072398]\n",
      "epoch:3 step:2890 [D loss: 0.736206, acc.: 47.66%] [G loss: 0.949213]\n",
      "epoch:3 step:2891 [D loss: 0.717369, acc.: 50.78%] [G loss: 0.964204]\n",
      "epoch:3 step:2892 [D loss: 0.764995, acc.: 50.00%] [G loss: 0.973022]\n",
      "epoch:3 step:2893 [D loss: 0.667497, acc.: 59.38%] [G loss: 0.923704]\n",
      "epoch:3 step:2894 [D loss: 0.655252, acc.: 60.94%] [G loss: 0.995719]\n",
      "epoch:3 step:2895 [D loss: 0.637951, acc.: 61.72%] [G loss: 0.995571]\n",
      "epoch:3 step:2896 [D loss: 0.665182, acc.: 61.72%] [G loss: 0.890199]\n",
      "epoch:3 step:2897 [D loss: 0.681901, acc.: 57.03%] [G loss: 0.891257]\n",
      "epoch:3 step:2898 [D loss: 0.702029, acc.: 51.56%] [G loss: 0.899275]\n",
      "epoch:3 step:2899 [D loss: 0.646823, acc.: 64.84%] [G loss: 0.974107]\n",
      "epoch:3 step:2900 [D loss: 0.681399, acc.: 56.25%] [G loss: 0.910481]\n",
      "epoch:3 step:2901 [D loss: 0.694265, acc.: 61.72%] [G loss: 0.968166]\n",
      "epoch:3 step:2902 [D loss: 0.691525, acc.: 55.47%] [G loss: 0.934266]\n",
      "epoch:3 step:2903 [D loss: 0.665364, acc.: 59.38%] [G loss: 0.976356]\n",
      "epoch:3 step:2904 [D loss: 0.681543, acc.: 61.72%] [G loss: 1.002339]\n",
      "epoch:3 step:2905 [D loss: 0.650195, acc.: 60.94%] [G loss: 0.961607]\n",
      "epoch:3 step:2906 [D loss: 0.641090, acc.: 57.03%] [G loss: 0.917514]\n",
      "epoch:3 step:2907 [D loss: 0.614496, acc.: 64.84%] [G loss: 1.006753]\n",
      "epoch:3 step:2908 [D loss: 0.629944, acc.: 62.50%] [G loss: 1.056734]\n",
      "epoch:3 step:2909 [D loss: 0.667013, acc.: 60.16%] [G loss: 1.018953]\n",
      "epoch:3 step:2910 [D loss: 0.655882, acc.: 59.38%] [G loss: 0.842463]\n",
      "epoch:3 step:2911 [D loss: 0.644406, acc.: 64.84%] [G loss: 0.870451]\n",
      "epoch:3 step:2912 [D loss: 0.722626, acc.: 50.78%] [G loss: 1.042761]\n",
      "epoch:3 step:2913 [D loss: 0.649108, acc.: 63.28%] [G loss: 1.077122]\n",
      "epoch:3 step:2914 [D loss: 0.571816, acc.: 70.31%] [G loss: 0.995010]\n",
      "epoch:3 step:2915 [D loss: 0.679837, acc.: 60.94%] [G loss: 0.958197]\n",
      "epoch:3 step:2916 [D loss: 0.587876, acc.: 71.09%] [G loss: 1.132147]\n",
      "epoch:3 step:2917 [D loss: 0.624802, acc.: 66.41%] [G loss: 1.062017]\n",
      "epoch:3 step:2918 [D loss: 0.761640, acc.: 52.34%] [G loss: 1.050687]\n",
      "epoch:3 step:2919 [D loss: 0.782362, acc.: 44.53%] [G loss: 0.876898]\n",
      "epoch:3 step:2920 [D loss: 0.690850, acc.: 52.34%] [G loss: 0.982293]\n",
      "epoch:3 step:2921 [D loss: 0.693125, acc.: 53.91%] [G loss: 0.956218]\n",
      "epoch:3 step:2922 [D loss: 0.647005, acc.: 66.41%] [G loss: 1.061724]\n",
      "epoch:3 step:2923 [D loss: 0.664880, acc.: 60.94%] [G loss: 0.902759]\n",
      "epoch:3 step:2924 [D loss: 0.740302, acc.: 50.78%] [G loss: 0.934286]\n",
      "epoch:3 step:2925 [D loss: 0.683998, acc.: 59.38%] [G loss: 1.033082]\n",
      "epoch:3 step:2926 [D loss: 0.709101, acc.: 51.56%] [G loss: 0.819260]\n",
      "epoch:3 step:2927 [D loss: 0.595541, acc.: 64.06%] [G loss: 1.073004]\n",
      "epoch:3 step:2928 [D loss: 0.626276, acc.: 65.62%] [G loss: 0.901670]\n",
      "epoch:3 step:2929 [D loss: 0.657071, acc.: 61.72%] [G loss: 0.948954]\n",
      "epoch:3 step:2930 [D loss: 0.634152, acc.: 64.06%] [G loss: 1.049604]\n",
      "epoch:3 step:2931 [D loss: 0.689062, acc.: 57.03%] [G loss: 0.984994]\n",
      "epoch:3 step:2932 [D loss: 0.736815, acc.: 50.00%] [G loss: 0.898357]\n",
      "epoch:3 step:2933 [D loss: 0.678791, acc.: 62.50%] [G loss: 0.892537]\n",
      "epoch:3 step:2934 [D loss: 0.694494, acc.: 57.03%] [G loss: 0.905676]\n",
      "epoch:3 step:2935 [D loss: 0.682198, acc.: 56.25%] [G loss: 0.960355]\n",
      "epoch:3 step:2936 [D loss: 0.681418, acc.: 53.12%] [G loss: 0.959449]\n",
      "epoch:3 step:2937 [D loss: 0.676353, acc.: 64.84%] [G loss: 1.096237]\n",
      "epoch:3 step:2938 [D loss: 0.634566, acc.: 63.28%] [G loss: 0.922803]\n",
      "epoch:3 step:2939 [D loss: 0.670502, acc.: 58.59%] [G loss: 0.971543]\n",
      "epoch:3 step:2940 [D loss: 0.681816, acc.: 60.16%] [G loss: 0.970510]\n",
      "epoch:3 step:2941 [D loss: 0.628987, acc.: 60.94%] [G loss: 0.968497]\n",
      "epoch:3 step:2942 [D loss: 0.628503, acc.: 61.72%] [G loss: 0.931615]\n",
      "epoch:3 step:2943 [D loss: 0.695384, acc.: 55.47%] [G loss: 0.899436]\n",
      "epoch:3 step:2944 [D loss: 0.678962, acc.: 57.81%] [G loss: 0.953938]\n",
      "epoch:3 step:2945 [D loss: 0.657272, acc.: 63.28%] [G loss: 0.946921]\n",
      "epoch:3 step:2946 [D loss: 0.672138, acc.: 57.03%] [G loss: 1.128791]\n",
      "epoch:3 step:2947 [D loss: 0.636168, acc.: 60.94%] [G loss: 0.983674]\n",
      "epoch:3 step:2948 [D loss: 0.810919, acc.: 46.09%] [G loss: 0.896953]\n",
      "epoch:3 step:2949 [D loss: 0.679021, acc.: 54.69%] [G loss: 0.905311]\n",
      "epoch:3 step:2950 [D loss: 0.728218, acc.: 55.47%] [G loss: 0.995088]\n",
      "epoch:3 step:2951 [D loss: 0.616414, acc.: 62.50%] [G loss: 1.030327]\n",
      "epoch:3 step:2952 [D loss: 0.603755, acc.: 69.53%] [G loss: 1.027119]\n",
      "epoch:3 step:2953 [D loss: 0.654389, acc.: 64.06%] [G loss: 1.062164]\n",
      "epoch:3 step:2954 [D loss: 0.634601, acc.: 59.38%] [G loss: 0.988656]\n",
      "epoch:3 step:2955 [D loss: 0.661410, acc.: 60.16%] [G loss: 0.974218]\n",
      "epoch:3 step:2956 [D loss: 0.683951, acc.: 53.91%] [G loss: 1.043241]\n",
      "epoch:3 step:2957 [D loss: 0.639837, acc.: 63.28%] [G loss: 1.016465]\n",
      "epoch:3 step:2958 [D loss: 0.714561, acc.: 55.47%] [G loss: 1.005644]\n",
      "epoch:3 step:2959 [D loss: 0.723943, acc.: 53.12%] [G loss: 0.946979]\n",
      "epoch:3 step:2960 [D loss: 0.706720, acc.: 60.94%] [G loss: 0.972053]\n",
      "epoch:3 step:2961 [D loss: 0.654749, acc.: 65.62%] [G loss: 0.955359]\n",
      "epoch:3 step:2962 [D loss: 0.625985, acc.: 69.53%] [G loss: 1.070707]\n",
      "epoch:3 step:2963 [D loss: 0.601585, acc.: 69.53%] [G loss: 1.125784]\n",
      "epoch:3 step:2964 [D loss: 0.644661, acc.: 60.16%] [G loss: 1.129800]\n",
      "epoch:3 step:2965 [D loss: 0.615611, acc.: 64.06%] [G loss: 1.035490]\n",
      "epoch:3 step:2966 [D loss: 0.680963, acc.: 56.25%] [G loss: 0.972369]\n",
      "epoch:3 step:2967 [D loss: 0.597813, acc.: 67.19%] [G loss: 1.053554]\n",
      "epoch:3 step:2968 [D loss: 0.614740, acc.: 63.28%] [G loss: 1.057578]\n",
      "epoch:3 step:2969 [D loss: 0.617172, acc.: 60.16%] [G loss: 0.973865]\n",
      "epoch:3 step:2970 [D loss: 0.691925, acc.: 60.16%] [G loss: 0.902104]\n",
      "epoch:3 step:2971 [D loss: 0.742942, acc.: 51.56%] [G loss: 0.865137]\n",
      "epoch:3 step:2972 [D loss: 0.702876, acc.: 53.12%] [G loss: 0.951743]\n",
      "epoch:3 step:2973 [D loss: 0.621457, acc.: 65.62%] [G loss: 1.028986]\n",
      "epoch:3 step:2974 [D loss: 0.665649, acc.: 60.16%] [G loss: 0.949877]\n",
      "epoch:3 step:2975 [D loss: 0.750936, acc.: 50.00%] [G loss: 0.936851]\n",
      "epoch:3 step:2976 [D loss: 0.710505, acc.: 52.34%] [G loss: 0.960803]\n",
      "epoch:3 step:2977 [D loss: 0.666063, acc.: 61.72%] [G loss: 1.154532]\n",
      "epoch:3 step:2978 [D loss: 0.692644, acc.: 55.47%] [G loss: 1.025894]\n",
      "epoch:3 step:2979 [D loss: 0.627876, acc.: 60.16%] [G loss: 1.024353]\n",
      "epoch:3 step:2980 [D loss: 0.693634, acc.: 58.59%] [G loss: 0.962308]\n",
      "epoch:3 step:2981 [D loss: 0.684684, acc.: 57.03%] [G loss: 1.027359]\n",
      "epoch:3 step:2982 [D loss: 0.622995, acc.: 64.84%] [G loss: 1.003919]\n",
      "epoch:3 step:2983 [D loss: 0.768740, acc.: 49.22%] [G loss: 0.928521]\n",
      "epoch:3 step:2984 [D loss: 0.593390, acc.: 65.62%] [G loss: 0.979024]\n",
      "epoch:3 step:2985 [D loss: 0.636425, acc.: 62.50%] [G loss: 0.965549]\n",
      "epoch:3 step:2986 [D loss: 0.687982, acc.: 52.34%] [G loss: 0.912217]\n",
      "epoch:3 step:2987 [D loss: 0.678536, acc.: 57.03%] [G loss: 0.977074]\n",
      "epoch:3 step:2988 [D loss: 0.654425, acc.: 57.81%] [G loss: 0.899507]\n",
      "epoch:3 step:2989 [D loss: 0.646587, acc.: 63.28%] [G loss: 0.923900]\n",
      "epoch:3 step:2990 [D loss: 0.693186, acc.: 53.91%] [G loss: 1.041582]\n",
      "epoch:3 step:2991 [D loss: 0.691676, acc.: 54.69%] [G loss: 0.970318]\n",
      "epoch:3 step:2992 [D loss: 0.660296, acc.: 60.94%] [G loss: 0.886055]\n",
      "epoch:3 step:2993 [D loss: 0.720371, acc.: 59.38%] [G loss: 1.014393]\n",
      "epoch:3 step:2994 [D loss: 0.680402, acc.: 60.16%] [G loss: 0.852198]\n",
      "epoch:3 step:2995 [D loss: 0.648526, acc.: 62.50%] [G loss: 1.059412]\n",
      "epoch:3 step:2996 [D loss: 0.730446, acc.: 52.34%] [G loss: 0.948541]\n",
      "epoch:3 step:2997 [D loss: 0.752374, acc.: 51.56%] [G loss: 0.769206]\n",
      "epoch:3 step:2998 [D loss: 0.712826, acc.: 50.00%] [G loss: 0.962353]\n",
      "epoch:3 step:2999 [D loss: 0.650284, acc.: 63.28%] [G loss: 0.966690]\n",
      "epoch:3 step:3000 [D loss: 0.694815, acc.: 56.25%] [G loss: 0.887558]\n",
      "epoch:3 step:3001 [D loss: 0.607671, acc.: 67.97%] [G loss: 0.876520]\n",
      "epoch:3 step:3002 [D loss: 0.613143, acc.: 64.84%] [G loss: 1.118230]\n",
      "epoch:3 step:3003 [D loss: 0.663183, acc.: 58.59%] [G loss: 0.838507]\n",
      "epoch:3 step:3004 [D loss: 0.725372, acc.: 56.25%] [G loss: 1.034366]\n",
      "epoch:3 step:3005 [D loss: 0.609362, acc.: 70.31%] [G loss: 0.903693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3006 [D loss: 0.713361, acc.: 53.91%] [G loss: 0.921957]\n",
      "epoch:3 step:3007 [D loss: 0.673484, acc.: 58.59%] [G loss: 0.957522]\n",
      "epoch:3 step:3008 [D loss: 0.671358, acc.: 65.62%] [G loss: 0.976006]\n",
      "epoch:3 step:3009 [D loss: 0.633492, acc.: 60.94%] [G loss: 1.015691]\n",
      "epoch:3 step:3010 [D loss: 0.657596, acc.: 59.38%] [G loss: 0.955497]\n",
      "epoch:3 step:3011 [D loss: 0.707970, acc.: 53.91%] [G loss: 0.958105]\n",
      "epoch:3 step:3012 [D loss: 0.726085, acc.: 55.47%] [G loss: 0.923549]\n",
      "epoch:3 step:3013 [D loss: 0.673243, acc.: 64.06%] [G loss: 0.963134]\n",
      "epoch:3 step:3014 [D loss: 0.727531, acc.: 50.00%] [G loss: 0.910930]\n",
      "epoch:3 step:3015 [D loss: 0.632284, acc.: 65.62%] [G loss: 0.949760]\n",
      "epoch:3 step:3016 [D loss: 0.765754, acc.: 46.09%] [G loss: 0.882962]\n",
      "epoch:3 step:3017 [D loss: 0.661473, acc.: 56.25%] [G loss: 0.918030]\n",
      "epoch:3 step:3018 [D loss: 0.602910, acc.: 71.88%] [G loss: 0.991871]\n",
      "epoch:3 step:3019 [D loss: 0.617272, acc.: 68.75%] [G loss: 1.077742]\n",
      "epoch:3 step:3020 [D loss: 0.607963, acc.: 65.62%] [G loss: 1.094455]\n",
      "epoch:3 step:3021 [D loss: 0.743601, acc.: 51.56%] [G loss: 1.104049]\n",
      "epoch:3 step:3022 [D loss: 0.688997, acc.: 61.72%] [G loss: 1.029705]\n",
      "epoch:3 step:3023 [D loss: 0.713467, acc.: 51.56%] [G loss: 1.007912]\n",
      "epoch:3 step:3024 [D loss: 0.705049, acc.: 53.91%] [G loss: 0.945505]\n",
      "epoch:3 step:3025 [D loss: 0.672853, acc.: 60.94%] [G loss: 1.045418]\n",
      "epoch:3 step:3026 [D loss: 0.685049, acc.: 55.47%] [G loss: 1.063992]\n",
      "epoch:3 step:3027 [D loss: 0.706155, acc.: 54.69%] [G loss: 0.909850]\n",
      "epoch:3 step:3028 [D loss: 0.689026, acc.: 57.81%] [G loss: 0.821129]\n",
      "epoch:3 step:3029 [D loss: 0.597057, acc.: 70.31%] [G loss: 1.010639]\n",
      "epoch:3 step:3030 [D loss: 0.645912, acc.: 64.06%] [G loss: 0.849721]\n",
      "epoch:3 step:3031 [D loss: 0.718902, acc.: 51.56%] [G loss: 0.979940]\n",
      "epoch:3 step:3032 [D loss: 0.663908, acc.: 60.94%] [G loss: 1.040845]\n",
      "epoch:3 step:3033 [D loss: 0.657701, acc.: 57.81%] [G loss: 0.983879]\n",
      "epoch:3 step:3034 [D loss: 0.653642, acc.: 63.28%] [G loss: 0.964490]\n",
      "epoch:3 step:3035 [D loss: 0.703713, acc.: 58.59%] [G loss: 1.018962]\n",
      "epoch:3 step:3036 [D loss: 0.785178, acc.: 50.00%] [G loss: 0.903639]\n",
      "epoch:3 step:3037 [D loss: 0.669682, acc.: 58.59%] [G loss: 0.973215]\n",
      "epoch:3 step:3038 [D loss: 0.752146, acc.: 51.56%] [G loss: 0.833638]\n",
      "epoch:3 step:3039 [D loss: 0.688961, acc.: 52.34%] [G loss: 0.972714]\n",
      "epoch:3 step:3040 [D loss: 0.673545, acc.: 57.81%] [G loss: 1.039221]\n",
      "epoch:3 step:3041 [D loss: 0.651660, acc.: 64.06%] [G loss: 1.030947]\n",
      "epoch:3 step:3042 [D loss: 0.585561, acc.: 71.09%] [G loss: 1.044158]\n",
      "epoch:3 step:3043 [D loss: 0.640779, acc.: 63.28%] [G loss: 1.116182]\n",
      "epoch:3 step:3044 [D loss: 0.681477, acc.: 59.38%] [G loss: 0.972434]\n",
      "epoch:3 step:3045 [D loss: 0.720645, acc.: 60.16%] [G loss: 0.990257]\n",
      "epoch:3 step:3046 [D loss: 0.641755, acc.: 62.50%] [G loss: 1.035748]\n",
      "epoch:3 step:3047 [D loss: 0.648173, acc.: 64.06%] [G loss: 0.968179]\n",
      "epoch:3 step:3048 [D loss: 0.712209, acc.: 57.81%] [G loss: 0.920519]\n",
      "epoch:3 step:3049 [D loss: 0.701119, acc.: 59.38%] [G loss: 0.888507]\n",
      "epoch:3 step:3050 [D loss: 0.598453, acc.: 72.66%] [G loss: 1.007147]\n",
      "epoch:3 step:3051 [D loss: 0.715168, acc.: 46.88%] [G loss: 0.838395]\n",
      "epoch:3 step:3052 [D loss: 0.648757, acc.: 63.28%] [G loss: 0.949423]\n",
      "epoch:3 step:3053 [D loss: 0.642417, acc.: 64.06%] [G loss: 0.902394]\n",
      "epoch:3 step:3054 [D loss: 0.674169, acc.: 61.72%] [G loss: 1.031511]\n",
      "epoch:3 step:3055 [D loss: 0.682079, acc.: 55.47%] [G loss: 0.969693]\n",
      "epoch:3 step:3056 [D loss: 0.658819, acc.: 60.94%] [G loss: 0.932676]\n",
      "epoch:3 step:3057 [D loss: 0.706286, acc.: 54.69%] [G loss: 1.028540]\n",
      "epoch:3 step:3058 [D loss: 0.723015, acc.: 51.56%] [G loss: 0.945201]\n",
      "epoch:3 step:3059 [D loss: 0.737466, acc.: 54.69%] [G loss: 0.842944]\n",
      "epoch:3 step:3060 [D loss: 0.671316, acc.: 60.16%] [G loss: 1.021217]\n",
      "epoch:3 step:3061 [D loss: 0.676098, acc.: 54.69%] [G loss: 1.009048]\n",
      "epoch:3 step:3062 [D loss: 0.714268, acc.: 51.56%] [G loss: 0.924035]\n",
      "epoch:3 step:3063 [D loss: 0.653312, acc.: 60.94%] [G loss: 0.957918]\n",
      "epoch:3 step:3064 [D loss: 0.652117, acc.: 62.50%] [G loss: 0.921579]\n",
      "epoch:3 step:3065 [D loss: 0.610241, acc.: 67.19%] [G loss: 0.850022]\n",
      "epoch:3 step:3066 [D loss: 0.701381, acc.: 56.25%] [G loss: 0.978892]\n",
      "epoch:3 step:3067 [D loss: 0.697686, acc.: 57.03%] [G loss: 0.890778]\n",
      "epoch:3 step:3068 [D loss: 0.649993, acc.: 64.84%] [G loss: 0.950604]\n",
      "epoch:3 step:3069 [D loss: 0.601930, acc.: 68.75%] [G loss: 0.934319]\n",
      "epoch:3 step:3070 [D loss: 0.657579, acc.: 62.50%] [G loss: 0.941853]\n",
      "epoch:3 step:3071 [D loss: 0.669225, acc.: 58.59%] [G loss: 0.905369]\n",
      "epoch:3 step:3072 [D loss: 0.608780, acc.: 71.88%] [G loss: 0.911293]\n",
      "epoch:3 step:3073 [D loss: 0.615566, acc.: 69.53%] [G loss: 0.915831]\n",
      "epoch:3 step:3074 [D loss: 0.700532, acc.: 57.81%] [G loss: 1.028107]\n",
      "epoch:3 step:3075 [D loss: 0.666095, acc.: 58.59%] [G loss: 0.906416]\n",
      "epoch:3 step:3076 [D loss: 0.696540, acc.: 54.69%] [G loss: 0.881431]\n",
      "epoch:3 step:3077 [D loss: 0.680796, acc.: 55.47%] [G loss: 0.844552]\n",
      "epoch:3 step:3078 [D loss: 0.668125, acc.: 60.16%] [G loss: 1.017382]\n",
      "epoch:3 step:3079 [D loss: 0.666438, acc.: 58.59%] [G loss: 1.014016]\n",
      "epoch:3 step:3080 [D loss: 0.706356, acc.: 53.91%] [G loss: 1.001870]\n",
      "epoch:3 step:3081 [D loss: 0.646487, acc.: 58.59%] [G loss: 0.925332]\n",
      "epoch:3 step:3082 [D loss: 0.623452, acc.: 66.41%] [G loss: 0.944957]\n",
      "epoch:3 step:3083 [D loss: 0.615204, acc.: 71.88%] [G loss: 1.035384]\n",
      "epoch:3 step:3084 [D loss: 0.606396, acc.: 72.66%] [G loss: 0.947639]\n",
      "epoch:3 step:3085 [D loss: 0.667343, acc.: 61.72%] [G loss: 0.957295]\n",
      "epoch:3 step:3086 [D loss: 0.694115, acc.: 62.50%] [G loss: 1.061852]\n",
      "epoch:3 step:3087 [D loss: 0.655187, acc.: 61.72%] [G loss: 1.014954]\n",
      "epoch:3 step:3088 [D loss: 0.691115, acc.: 60.94%] [G loss: 0.954948]\n",
      "epoch:3 step:3089 [D loss: 0.721658, acc.: 47.66%] [G loss: 0.922292]\n",
      "epoch:3 step:3090 [D loss: 0.702913, acc.: 53.12%] [G loss: 0.861592]\n",
      "epoch:3 step:3091 [D loss: 0.623500, acc.: 69.53%] [G loss: 0.928206]\n",
      "epoch:3 step:3092 [D loss: 0.691867, acc.: 57.03%] [G loss: 0.860579]\n",
      "epoch:3 step:3093 [D loss: 0.689650, acc.: 57.81%] [G loss: 0.841877]\n",
      "epoch:3 step:3094 [D loss: 0.656809, acc.: 63.28%] [G loss: 0.859862]\n",
      "epoch:3 step:3095 [D loss: 0.662716, acc.: 59.38%] [G loss: 0.859519]\n",
      "epoch:3 step:3096 [D loss: 0.653831, acc.: 62.50%] [G loss: 0.929929]\n",
      "epoch:3 step:3097 [D loss: 0.620001, acc.: 64.06%] [G loss: 0.941018]\n",
      "epoch:3 step:3098 [D loss: 0.673573, acc.: 57.81%] [G loss: 0.922887]\n",
      "epoch:3 step:3099 [D loss: 0.646921, acc.: 59.38%] [G loss: 0.998810]\n",
      "epoch:3 step:3100 [D loss: 0.643495, acc.: 60.16%] [G loss: 1.040829]\n",
      "epoch:3 step:3101 [D loss: 0.601791, acc.: 68.75%] [G loss: 0.979952]\n",
      "epoch:3 step:3102 [D loss: 0.741587, acc.: 50.00%] [G loss: 0.987975]\n",
      "epoch:3 step:3103 [D loss: 0.693756, acc.: 55.47%] [G loss: 0.926866]\n",
      "epoch:3 step:3104 [D loss: 0.618493, acc.: 71.09%] [G loss: 0.993735]\n",
      "epoch:3 step:3105 [D loss: 0.740958, acc.: 46.88%] [G loss: 0.956787]\n",
      "epoch:3 step:3106 [D loss: 0.710167, acc.: 56.25%] [G loss: 1.009998]\n",
      "epoch:3 step:3107 [D loss: 0.671907, acc.: 60.94%] [G loss: 1.016837]\n",
      "epoch:3 step:3108 [D loss: 0.693392, acc.: 58.59%] [G loss: 0.976415]\n",
      "epoch:3 step:3109 [D loss: 0.701342, acc.: 59.38%] [G loss: 0.954661]\n",
      "epoch:3 step:3110 [D loss: 0.635512, acc.: 60.16%] [G loss: 0.950251]\n",
      "epoch:3 step:3111 [D loss: 0.605543, acc.: 68.75%] [G loss: 1.047648]\n",
      "epoch:3 step:3112 [D loss: 0.669930, acc.: 53.12%] [G loss: 0.981470]\n",
      "epoch:3 step:3113 [D loss: 0.656058, acc.: 61.72%] [G loss: 0.895305]\n",
      "epoch:3 step:3114 [D loss: 0.699000, acc.: 51.56%] [G loss: 0.958526]\n",
      "epoch:3 step:3115 [D loss: 0.644515, acc.: 64.06%] [G loss: 1.021810]\n",
      "epoch:3 step:3116 [D loss: 0.650638, acc.: 58.59%] [G loss: 0.986049]\n",
      "epoch:3 step:3117 [D loss: 0.653642, acc.: 60.16%] [G loss: 0.892092]\n",
      "epoch:3 step:3118 [D loss: 0.654528, acc.: 65.62%] [G loss: 0.980843]\n",
      "epoch:3 step:3119 [D loss: 0.666129, acc.: 60.16%] [G loss: 0.915983]\n",
      "epoch:3 step:3120 [D loss: 0.680685, acc.: 60.94%] [G loss: 0.872714]\n",
      "epoch:3 step:3121 [D loss: 0.603942, acc.: 68.75%] [G loss: 1.095293]\n",
      "epoch:3 step:3122 [D loss: 0.592868, acc.: 66.41%] [G loss: 0.992088]\n",
      "epoch:3 step:3123 [D loss: 0.678493, acc.: 57.81%] [G loss: 1.026186]\n",
      "epoch:3 step:3124 [D loss: 0.645666, acc.: 65.62%] [G loss: 1.053464]\n",
      "epoch:3 step:3125 [D loss: 0.573635, acc.: 67.19%] [G loss: 1.072042]\n",
      "epoch:3 step:3126 [D loss: 0.547472, acc.: 73.44%] [G loss: 1.159356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3127 [D loss: 0.690840, acc.: 51.56%] [G loss: 1.042032]\n",
      "epoch:3 step:3128 [D loss: 0.658158, acc.: 58.59%] [G loss: 1.040851]\n",
      "epoch:3 step:3129 [D loss: 0.641392, acc.: 67.97%] [G loss: 0.980585]\n",
      "epoch:3 step:3130 [D loss: 0.649673, acc.: 64.06%] [G loss: 0.909634]\n",
      "epoch:3 step:3131 [D loss: 0.712656, acc.: 50.00%] [G loss: 0.982837]\n",
      "epoch:3 step:3132 [D loss: 0.586845, acc.: 69.53%] [G loss: 1.142412]\n",
      "epoch:3 step:3133 [D loss: 0.676923, acc.: 60.94%] [G loss: 0.957957]\n",
      "epoch:3 step:3134 [D loss: 0.677268, acc.: 57.03%] [G loss: 1.045317]\n",
      "epoch:3 step:3135 [D loss: 0.674614, acc.: 59.38%] [G loss: 0.875504]\n",
      "epoch:3 step:3136 [D loss: 0.649372, acc.: 65.62%] [G loss: 1.005519]\n",
      "epoch:3 step:3137 [D loss: 0.661704, acc.: 60.94%] [G loss: 0.976829]\n",
      "epoch:3 step:3138 [D loss: 0.615894, acc.: 65.62%] [G loss: 0.974387]\n",
      "epoch:3 step:3139 [D loss: 0.700004, acc.: 58.59%] [G loss: 0.930082]\n",
      "epoch:3 step:3140 [D loss: 0.672220, acc.: 53.12%] [G loss: 0.930147]\n",
      "epoch:3 step:3141 [D loss: 0.620640, acc.: 64.06%] [G loss: 1.045879]\n",
      "epoch:3 step:3142 [D loss: 0.667440, acc.: 63.28%] [G loss: 1.066162]\n",
      "epoch:3 step:3143 [D loss: 0.684042, acc.: 66.41%] [G loss: 0.979177]\n",
      "epoch:3 step:3144 [D loss: 0.687646, acc.: 60.94%] [G loss: 0.911563]\n",
      "epoch:3 step:3145 [D loss: 0.643582, acc.: 58.59%] [G loss: 0.967219]\n",
      "epoch:3 step:3146 [D loss: 0.657780, acc.: 61.72%] [G loss: 1.134243]\n",
      "epoch:3 step:3147 [D loss: 0.646068, acc.: 64.06%] [G loss: 1.114749]\n",
      "epoch:3 step:3148 [D loss: 0.543926, acc.: 74.22%] [G loss: 1.080757]\n",
      "epoch:3 step:3149 [D loss: 0.648431, acc.: 61.72%] [G loss: 0.993374]\n",
      "epoch:3 step:3150 [D loss: 0.617191, acc.: 62.50%] [G loss: 1.044079]\n",
      "epoch:3 step:3151 [D loss: 0.596264, acc.: 68.75%] [G loss: 1.090497]\n",
      "epoch:3 step:3152 [D loss: 0.652274, acc.: 64.06%] [G loss: 0.945009]\n",
      "epoch:3 step:3153 [D loss: 0.739371, acc.: 53.12%] [G loss: 0.928366]\n",
      "epoch:3 step:3154 [D loss: 0.650943, acc.: 64.06%] [G loss: 0.935022]\n",
      "epoch:3 step:3155 [D loss: 0.635385, acc.: 62.50%] [G loss: 0.948721]\n",
      "epoch:3 step:3156 [D loss: 0.581557, acc.: 70.31%] [G loss: 1.003485]\n",
      "epoch:3 step:3157 [D loss: 0.655417, acc.: 64.06%] [G loss: 0.966950]\n",
      "epoch:3 step:3158 [D loss: 0.571948, acc.: 71.88%] [G loss: 1.143966]\n",
      "epoch:3 step:3159 [D loss: 0.686790, acc.: 56.25%] [G loss: 0.948340]\n",
      "epoch:3 step:3160 [D loss: 0.747970, acc.: 52.34%] [G loss: 0.995567]\n",
      "epoch:3 step:3161 [D loss: 0.653307, acc.: 61.72%] [G loss: 1.058234]\n",
      "epoch:3 step:3162 [D loss: 0.699600, acc.: 57.81%] [G loss: 1.070184]\n",
      "epoch:3 step:3163 [D loss: 0.722166, acc.: 55.47%] [G loss: 0.978156]\n",
      "epoch:3 step:3164 [D loss: 0.686538, acc.: 59.38%] [G loss: 0.864164]\n",
      "epoch:3 step:3165 [D loss: 0.664505, acc.: 57.03%] [G loss: 0.978803]\n",
      "epoch:3 step:3166 [D loss: 0.727265, acc.: 54.69%] [G loss: 0.888487]\n",
      "epoch:3 step:3167 [D loss: 0.654438, acc.: 62.50%] [G loss: 0.923683]\n",
      "epoch:3 step:3168 [D loss: 0.636846, acc.: 65.62%] [G loss: 1.019698]\n",
      "epoch:3 step:3169 [D loss: 0.607455, acc.: 60.94%] [G loss: 1.140641]\n",
      "epoch:3 step:3170 [D loss: 0.644703, acc.: 61.72%] [G loss: 1.027171]\n",
      "epoch:3 step:3171 [D loss: 0.658440, acc.: 61.72%] [G loss: 1.135177]\n",
      "epoch:3 step:3172 [D loss: 0.637287, acc.: 65.62%] [G loss: 0.978938]\n",
      "epoch:3 step:3173 [D loss: 0.684472, acc.: 63.28%] [G loss: 0.924812]\n",
      "epoch:3 step:3174 [D loss: 0.679254, acc.: 58.59%] [G loss: 0.966921]\n",
      "epoch:3 step:3175 [D loss: 0.684321, acc.: 57.03%] [G loss: 1.028003]\n",
      "epoch:3 step:3176 [D loss: 0.711021, acc.: 55.47%] [G loss: 0.988050]\n",
      "epoch:3 step:3177 [D loss: 0.661776, acc.: 61.72%] [G loss: 0.944484]\n",
      "epoch:3 step:3178 [D loss: 0.643533, acc.: 64.06%] [G loss: 1.018565]\n",
      "epoch:3 step:3179 [D loss: 0.647944, acc.: 64.06%] [G loss: 1.031860]\n",
      "epoch:3 step:3180 [D loss: 0.646639, acc.: 60.16%] [G loss: 1.047810]\n",
      "epoch:3 step:3181 [D loss: 0.578389, acc.: 71.88%] [G loss: 1.012273]\n",
      "epoch:3 step:3182 [D loss: 0.687927, acc.: 57.03%] [G loss: 1.022763]\n",
      "epoch:3 step:3183 [D loss: 0.685421, acc.: 60.94%] [G loss: 0.966439]\n",
      "epoch:3 step:3184 [D loss: 0.681596, acc.: 55.47%] [G loss: 0.947351]\n",
      "epoch:3 step:3185 [D loss: 0.678837, acc.: 57.03%] [G loss: 0.937089]\n",
      "epoch:3 step:3186 [D loss: 0.690238, acc.: 59.38%] [G loss: 0.889898]\n",
      "epoch:3 step:3187 [D loss: 0.761976, acc.: 44.53%] [G loss: 0.880367]\n",
      "epoch:3 step:3188 [D loss: 0.654067, acc.: 64.06%] [G loss: 0.938199]\n",
      "epoch:3 step:3189 [D loss: 0.577850, acc.: 67.19%] [G loss: 0.959185]\n",
      "epoch:3 step:3190 [D loss: 0.681494, acc.: 60.16%] [G loss: 0.895419]\n",
      "epoch:3 step:3191 [D loss: 0.626090, acc.: 63.28%] [G loss: 0.845542]\n",
      "epoch:3 step:3192 [D loss: 0.593922, acc.: 68.75%] [G loss: 0.980803]\n",
      "epoch:3 step:3193 [D loss: 0.659834, acc.: 60.16%] [G loss: 1.014773]\n",
      "epoch:3 step:3194 [D loss: 0.674843, acc.: 57.03%] [G loss: 0.974761]\n",
      "epoch:3 step:3195 [D loss: 0.612597, acc.: 65.62%] [G loss: 1.027959]\n",
      "epoch:3 step:3196 [D loss: 0.635435, acc.: 63.28%] [G loss: 0.958584]\n",
      "epoch:3 step:3197 [D loss: 0.661973, acc.: 60.16%] [G loss: 1.040898]\n",
      "epoch:3 step:3198 [D loss: 0.671819, acc.: 55.47%] [G loss: 0.882866]\n",
      "epoch:3 step:3199 [D loss: 0.708234, acc.: 57.81%] [G loss: 0.936830]\n",
      "epoch:3 step:3200 [D loss: 0.707090, acc.: 52.34%] [G loss: 0.961423]\n",
      "epoch:3 step:3201 [D loss: 0.659355, acc.: 64.06%] [G loss: 0.934945]\n",
      "epoch:3 step:3202 [D loss: 0.746627, acc.: 50.78%] [G loss: 0.918108]\n",
      "epoch:3 step:3203 [D loss: 0.631629, acc.: 63.28%] [G loss: 0.925784]\n",
      "epoch:3 step:3204 [D loss: 0.656641, acc.: 60.94%] [G loss: 1.041120]\n",
      "epoch:3 step:3205 [D loss: 0.681219, acc.: 57.81%] [G loss: 0.954534]\n",
      "epoch:3 step:3206 [D loss: 0.627334, acc.: 69.53%] [G loss: 1.049363]\n",
      "epoch:3 step:3207 [D loss: 0.664970, acc.: 63.28%] [G loss: 0.913649]\n",
      "epoch:3 step:3208 [D loss: 0.630461, acc.: 59.38%] [G loss: 0.896736]\n",
      "epoch:3 step:3209 [D loss: 0.615499, acc.: 68.75%] [G loss: 1.060411]\n",
      "epoch:3 step:3210 [D loss: 0.635258, acc.: 66.41%] [G loss: 1.107374]\n",
      "epoch:3 step:3211 [D loss: 0.662584, acc.: 62.50%] [G loss: 0.913522]\n",
      "epoch:3 step:3212 [D loss: 0.634080, acc.: 64.06%] [G loss: 0.995874]\n",
      "epoch:3 step:3213 [D loss: 0.634824, acc.: 64.84%] [G loss: 1.081227]\n",
      "epoch:3 step:3214 [D loss: 0.650746, acc.: 57.03%] [G loss: 1.055037]\n",
      "epoch:3 step:3215 [D loss: 0.647325, acc.: 65.62%] [G loss: 1.113247]\n",
      "epoch:3 step:3216 [D loss: 0.674032, acc.: 58.59%] [G loss: 1.025579]\n",
      "epoch:3 step:3217 [D loss: 0.591806, acc.: 71.88%] [G loss: 1.012976]\n",
      "epoch:3 step:3218 [D loss: 0.687652, acc.: 61.72%] [G loss: 0.972672]\n",
      "epoch:3 step:3219 [D loss: 0.699856, acc.: 58.59%] [G loss: 0.982195]\n",
      "epoch:3 step:3220 [D loss: 0.647418, acc.: 65.62%] [G loss: 0.917651]\n",
      "epoch:3 step:3221 [D loss: 0.652983, acc.: 63.28%] [G loss: 0.956523]\n",
      "epoch:3 step:3222 [D loss: 0.707282, acc.: 53.91%] [G loss: 0.925809]\n",
      "epoch:3 step:3223 [D loss: 0.674290, acc.: 60.16%] [G loss: 0.928488]\n",
      "epoch:3 step:3224 [D loss: 0.671042, acc.: 60.16%] [G loss: 0.943686]\n",
      "epoch:3 step:3225 [D loss: 0.671045, acc.: 60.16%] [G loss: 0.997147]\n",
      "epoch:3 step:3226 [D loss: 0.733659, acc.: 50.78%] [G loss: 0.846365]\n",
      "epoch:3 step:3227 [D loss: 0.635265, acc.: 67.97%] [G loss: 0.963887]\n",
      "epoch:3 step:3228 [D loss: 0.719879, acc.: 53.12%] [G loss: 0.978808]\n",
      "epoch:3 step:3229 [D loss: 0.631344, acc.: 63.28%] [G loss: 1.002328]\n",
      "epoch:3 step:3230 [D loss: 0.632818, acc.: 67.97%] [G loss: 0.909830]\n",
      "epoch:3 step:3231 [D loss: 0.619323, acc.: 66.41%] [G loss: 0.913133]\n",
      "epoch:3 step:3232 [D loss: 0.684002, acc.: 66.41%] [G loss: 0.977921]\n",
      "epoch:3 step:3233 [D loss: 0.723057, acc.: 50.78%] [G loss: 0.969314]\n",
      "epoch:3 step:3234 [D loss: 0.686076, acc.: 57.03%] [G loss: 0.999211]\n",
      "epoch:3 step:3235 [D loss: 0.690709, acc.: 57.03%] [G loss: 1.037879]\n",
      "epoch:3 step:3236 [D loss: 0.727351, acc.: 50.00%] [G loss: 1.047974]\n",
      "epoch:3 step:3237 [D loss: 0.636464, acc.: 67.97%] [G loss: 1.007164]\n",
      "epoch:3 step:3238 [D loss: 0.628464, acc.: 67.19%] [G loss: 0.936099]\n",
      "epoch:3 step:3239 [D loss: 0.542149, acc.: 75.00%] [G loss: 1.039604]\n",
      "epoch:3 step:3240 [D loss: 0.624240, acc.: 60.16%] [G loss: 1.058702]\n",
      "epoch:3 step:3241 [D loss: 0.618479, acc.: 65.62%] [G loss: 1.016090]\n",
      "epoch:3 step:3242 [D loss: 0.688704, acc.: 59.38%] [G loss: 1.070220]\n",
      "epoch:3 step:3243 [D loss: 0.735557, acc.: 50.78%] [G loss: 0.968772]\n",
      "epoch:3 step:3244 [D loss: 0.653156, acc.: 59.38%] [G loss: 0.976548]\n",
      "epoch:3 step:3245 [D loss: 0.640547, acc.: 64.06%] [G loss: 0.961256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3246 [D loss: 0.680113, acc.: 60.16%] [G loss: 0.906247]\n",
      "epoch:3 step:3247 [D loss: 0.681978, acc.: 59.38%] [G loss: 0.981631]\n",
      "epoch:3 step:3248 [D loss: 0.689933, acc.: 56.25%] [G loss: 0.950804]\n",
      "epoch:3 step:3249 [D loss: 0.638854, acc.: 63.28%] [G loss: 1.082798]\n",
      "epoch:3 step:3250 [D loss: 0.636617, acc.: 62.50%] [G loss: 0.966195]\n",
      "epoch:3 step:3251 [D loss: 0.661274, acc.: 59.38%] [G loss: 0.974040]\n",
      "epoch:3 step:3252 [D loss: 0.676750, acc.: 62.50%] [G loss: 0.957818]\n",
      "epoch:3 step:3253 [D loss: 0.685698, acc.: 60.16%] [G loss: 0.924687]\n",
      "epoch:3 step:3254 [D loss: 0.647209, acc.: 60.16%] [G loss: 1.033261]\n",
      "epoch:3 step:3255 [D loss: 0.607974, acc.: 67.97%] [G loss: 0.911110]\n",
      "epoch:3 step:3256 [D loss: 0.668909, acc.: 59.38%] [G loss: 0.906891]\n",
      "epoch:3 step:3257 [D loss: 0.682280, acc.: 55.47%] [G loss: 1.012473]\n",
      "epoch:3 step:3258 [D loss: 0.605266, acc.: 70.31%] [G loss: 0.969008]\n",
      "epoch:3 step:3259 [D loss: 0.730510, acc.: 55.47%] [G loss: 0.913052]\n",
      "epoch:3 step:3260 [D loss: 0.732300, acc.: 52.34%] [G loss: 1.032129]\n",
      "epoch:3 step:3261 [D loss: 0.707548, acc.: 53.91%] [G loss: 0.930735]\n",
      "epoch:3 step:3262 [D loss: 0.602985, acc.: 68.75%] [G loss: 1.141886]\n",
      "epoch:3 step:3263 [D loss: 0.692943, acc.: 57.81%] [G loss: 1.046684]\n",
      "epoch:3 step:3264 [D loss: 0.596989, acc.: 71.09%] [G loss: 0.978963]\n",
      "epoch:3 step:3265 [D loss: 0.668631, acc.: 60.94%] [G loss: 1.007921]\n",
      "epoch:3 step:3266 [D loss: 0.635784, acc.: 66.41%] [G loss: 0.909736]\n",
      "epoch:3 step:3267 [D loss: 0.704779, acc.: 53.91%] [G loss: 1.081952]\n",
      "epoch:3 step:3268 [D loss: 0.682468, acc.: 60.16%] [G loss: 1.031041]\n",
      "epoch:3 step:3269 [D loss: 0.739165, acc.: 54.69%] [G loss: 0.953169]\n",
      "epoch:3 step:3270 [D loss: 0.656872, acc.: 60.94%] [G loss: 1.036314]\n",
      "epoch:3 step:3271 [D loss: 0.612185, acc.: 69.53%] [G loss: 0.980563]\n",
      "epoch:3 step:3272 [D loss: 0.678189, acc.: 57.81%] [G loss: 0.987013]\n",
      "epoch:3 step:3273 [D loss: 0.736920, acc.: 45.31%] [G loss: 0.925869]\n",
      "epoch:3 step:3274 [D loss: 0.697966, acc.: 57.03%] [G loss: 0.896604]\n",
      "epoch:3 step:3275 [D loss: 0.643363, acc.: 61.72%] [G loss: 0.992404]\n",
      "epoch:3 step:3276 [D loss: 0.713656, acc.: 47.66%] [G loss: 0.948835]\n",
      "epoch:3 step:3277 [D loss: 0.673928, acc.: 57.03%] [G loss: 0.843377]\n",
      "epoch:3 step:3278 [D loss: 0.664517, acc.: 55.47%] [G loss: 1.043771]\n",
      "epoch:3 step:3279 [D loss: 0.604105, acc.: 64.84%] [G loss: 1.025352]\n",
      "epoch:3 step:3280 [D loss: 0.668175, acc.: 57.81%] [G loss: 1.060198]\n",
      "epoch:3 step:3281 [D loss: 0.619823, acc.: 61.72%] [G loss: 1.120897]\n",
      "epoch:3 step:3282 [D loss: 0.631576, acc.: 64.06%] [G loss: 1.058506]\n",
      "epoch:3 step:3283 [D loss: 0.637957, acc.: 64.06%] [G loss: 1.114945]\n",
      "epoch:3 step:3284 [D loss: 0.786743, acc.: 50.00%] [G loss: 0.896466]\n",
      "epoch:3 step:3285 [D loss: 0.695020, acc.: 54.69%] [G loss: 0.969953]\n",
      "epoch:3 step:3286 [D loss: 0.725026, acc.: 50.78%] [G loss: 0.795104]\n",
      "epoch:3 step:3287 [D loss: 0.659767, acc.: 60.94%] [G loss: 0.815516]\n",
      "epoch:3 step:3288 [D loss: 0.695708, acc.: 51.56%] [G loss: 1.112601]\n",
      "epoch:3 step:3289 [D loss: 0.651223, acc.: 61.72%] [G loss: 0.943446]\n",
      "epoch:3 step:3290 [D loss: 0.656341, acc.: 53.12%] [G loss: 0.964637]\n",
      "epoch:3 step:3291 [D loss: 0.697019, acc.: 55.47%] [G loss: 0.987319]\n",
      "epoch:3 step:3292 [D loss: 0.666810, acc.: 61.72%] [G loss: 0.904735]\n",
      "epoch:3 step:3293 [D loss: 0.631477, acc.: 65.62%] [G loss: 1.018439]\n",
      "epoch:3 step:3294 [D loss: 0.625112, acc.: 64.06%] [G loss: 0.983201]\n",
      "epoch:3 step:3295 [D loss: 0.630682, acc.: 65.62%] [G loss: 0.948180]\n",
      "epoch:3 step:3296 [D loss: 0.716429, acc.: 56.25%] [G loss: 0.958860]\n",
      "epoch:3 step:3297 [D loss: 0.717602, acc.: 53.91%] [G loss: 0.864392]\n",
      "epoch:3 step:3298 [D loss: 0.644477, acc.: 64.06%] [G loss: 0.818382]\n",
      "epoch:3 step:3299 [D loss: 0.649595, acc.: 62.50%] [G loss: 0.982881]\n",
      "epoch:3 step:3300 [D loss: 0.653652, acc.: 60.16%] [G loss: 0.977371]\n",
      "epoch:3 step:3301 [D loss: 0.670848, acc.: 56.25%] [G loss: 0.934414]\n",
      "epoch:3 step:3302 [D loss: 0.690352, acc.: 60.16%] [G loss: 1.046235]\n",
      "epoch:3 step:3303 [D loss: 0.686204, acc.: 53.12%] [G loss: 0.957122]\n",
      "epoch:3 step:3304 [D loss: 0.655944, acc.: 59.38%] [G loss: 1.102658]\n",
      "epoch:3 step:3305 [D loss: 0.641248, acc.: 63.28%] [G loss: 0.984590]\n",
      "epoch:3 step:3306 [D loss: 0.653517, acc.: 67.97%] [G loss: 0.959107]\n",
      "epoch:3 step:3307 [D loss: 0.632608, acc.: 62.50%] [G loss: 0.925364]\n",
      "epoch:3 step:3308 [D loss: 0.695848, acc.: 58.59%] [G loss: 0.867842]\n",
      "epoch:3 step:3309 [D loss: 0.726692, acc.: 51.56%] [G loss: 0.973034]\n",
      "epoch:3 step:3310 [D loss: 0.574430, acc.: 71.88%] [G loss: 1.001227]\n",
      "epoch:3 step:3311 [D loss: 0.670768, acc.: 60.16%] [G loss: 1.036796]\n",
      "epoch:3 step:3312 [D loss: 0.664785, acc.: 57.03%] [G loss: 1.005113]\n",
      "epoch:3 step:3313 [D loss: 0.628671, acc.: 65.62%] [G loss: 1.012621]\n",
      "epoch:3 step:3314 [D loss: 0.660064, acc.: 61.72%] [G loss: 0.855075]\n",
      "epoch:3 step:3315 [D loss: 0.620052, acc.: 63.28%] [G loss: 1.023408]\n",
      "epoch:3 step:3316 [D loss: 0.680850, acc.: 60.94%] [G loss: 0.923781]\n",
      "epoch:3 step:3317 [D loss: 0.705197, acc.: 53.12%] [G loss: 0.917060]\n",
      "epoch:3 step:3318 [D loss: 0.692427, acc.: 60.16%] [G loss: 0.964236]\n",
      "epoch:3 step:3319 [D loss: 0.629350, acc.: 68.75%] [G loss: 0.864762]\n",
      "epoch:3 step:3320 [D loss: 0.730705, acc.: 53.91%] [G loss: 0.980983]\n",
      "epoch:3 step:3321 [D loss: 0.672489, acc.: 59.38%] [G loss: 0.867808]\n",
      "epoch:3 step:3322 [D loss: 0.665430, acc.: 60.94%] [G loss: 0.976221]\n",
      "epoch:3 step:3323 [D loss: 0.673611, acc.: 60.16%] [G loss: 1.015512]\n",
      "epoch:3 step:3324 [D loss: 0.668693, acc.: 54.69%] [G loss: 0.920199]\n",
      "epoch:3 step:3325 [D loss: 0.689732, acc.: 54.69%] [G loss: 0.983867]\n",
      "epoch:3 step:3326 [D loss: 0.722812, acc.: 51.56%] [G loss: 0.826627]\n",
      "epoch:3 step:3327 [D loss: 0.630640, acc.: 68.75%] [G loss: 0.843439]\n",
      "epoch:3 step:3328 [D loss: 0.668299, acc.: 55.47%] [G loss: 0.951018]\n",
      "epoch:3 step:3329 [D loss: 0.668615, acc.: 59.38%] [G loss: 0.963385]\n",
      "epoch:3 step:3330 [D loss: 0.687375, acc.: 58.59%] [G loss: 0.883537]\n",
      "epoch:3 step:3331 [D loss: 0.656657, acc.: 57.81%] [G loss: 0.956373]\n",
      "epoch:3 step:3332 [D loss: 0.663874, acc.: 58.59%] [G loss: 0.968233]\n",
      "epoch:3 step:3333 [D loss: 0.716074, acc.: 57.03%] [G loss: 0.825238]\n",
      "epoch:3 step:3334 [D loss: 0.614874, acc.: 70.31%] [G loss: 0.908544]\n",
      "epoch:3 step:3335 [D loss: 0.665180, acc.: 55.47%] [G loss: 0.905368]\n",
      "epoch:3 step:3336 [D loss: 0.716060, acc.: 49.22%] [G loss: 0.968896]\n",
      "epoch:3 step:3337 [D loss: 0.650051, acc.: 60.16%] [G loss: 1.023989]\n",
      "epoch:3 step:3338 [D loss: 0.678201, acc.: 53.12%] [G loss: 0.940488]\n",
      "epoch:3 step:3339 [D loss: 0.621777, acc.: 65.62%] [G loss: 0.921650]\n",
      "epoch:3 step:3340 [D loss: 0.685706, acc.: 53.12%] [G loss: 0.871203]\n",
      "epoch:3 step:3341 [D loss: 0.707372, acc.: 58.59%] [G loss: 0.855784]\n",
      "epoch:3 step:3342 [D loss: 0.695344, acc.: 56.25%] [G loss: 0.949547]\n",
      "epoch:3 step:3343 [D loss: 0.612320, acc.: 73.44%] [G loss: 0.946528]\n",
      "epoch:3 step:3344 [D loss: 0.694551, acc.: 57.03%] [G loss: 0.990509]\n",
      "epoch:3 step:3345 [D loss: 0.689209, acc.: 57.03%] [G loss: 1.021196]\n",
      "epoch:3 step:3346 [D loss: 0.659855, acc.: 67.19%] [G loss: 1.047906]\n",
      "epoch:3 step:3347 [D loss: 0.659482, acc.: 60.16%] [G loss: 0.990504]\n",
      "epoch:3 step:3348 [D loss: 0.728621, acc.: 57.81%] [G loss: 0.950595]\n",
      "epoch:3 step:3349 [D loss: 0.739904, acc.: 50.00%] [G loss: 0.918901]\n",
      "epoch:3 step:3350 [D loss: 0.700403, acc.: 60.16%] [G loss: 0.905449]\n",
      "epoch:3 step:3351 [D loss: 0.635346, acc.: 63.28%] [G loss: 1.001666]\n",
      "epoch:3 step:3352 [D loss: 0.644829, acc.: 62.50%] [G loss: 0.890801]\n",
      "epoch:3 step:3353 [D loss: 0.757824, acc.: 50.00%] [G loss: 0.900495]\n",
      "epoch:3 step:3354 [D loss: 0.719563, acc.: 53.12%] [G loss: 0.941821]\n",
      "epoch:3 step:3355 [D loss: 0.666645, acc.: 57.03%] [G loss: 0.903703]\n",
      "epoch:3 step:3356 [D loss: 0.693335, acc.: 57.81%] [G loss: 0.905999]\n",
      "epoch:3 step:3357 [D loss: 0.619151, acc.: 68.75%] [G loss: 0.959389]\n",
      "epoch:3 step:3358 [D loss: 0.603240, acc.: 70.31%] [G loss: 1.067675]\n",
      "epoch:3 step:3359 [D loss: 0.656428, acc.: 63.28%] [G loss: 0.939701]\n",
      "epoch:3 step:3360 [D loss: 0.605496, acc.: 65.62%] [G loss: 0.990415]\n",
      "epoch:3 step:3361 [D loss: 0.626517, acc.: 63.28%] [G loss: 1.073289]\n",
      "epoch:3 step:3362 [D loss: 0.611471, acc.: 69.53%] [G loss: 1.022748]\n",
      "epoch:3 step:3363 [D loss: 0.616778, acc.: 68.75%] [G loss: 1.063855]\n",
      "epoch:3 step:3364 [D loss: 0.636112, acc.: 64.06%] [G loss: 1.057668]\n",
      "epoch:3 step:3365 [D loss: 0.619516, acc.: 67.97%] [G loss: 0.926150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3366 [D loss: 0.588199, acc.: 69.53%] [G loss: 1.032572]\n",
      "epoch:3 step:3367 [D loss: 0.596982, acc.: 67.19%] [G loss: 1.053772]\n",
      "epoch:3 step:3368 [D loss: 0.555272, acc.: 70.31%] [G loss: 1.076519]\n",
      "epoch:3 step:3369 [D loss: 0.606339, acc.: 69.53%] [G loss: 1.003378]\n",
      "epoch:3 step:3370 [D loss: 0.786561, acc.: 45.31%] [G loss: 0.919912]\n",
      "epoch:3 step:3371 [D loss: 0.670941, acc.: 56.25%] [G loss: 1.031566]\n",
      "epoch:3 step:3372 [D loss: 0.704155, acc.: 55.47%] [G loss: 0.901483]\n",
      "epoch:3 step:3373 [D loss: 0.791074, acc.: 42.19%] [G loss: 0.718408]\n",
      "epoch:3 step:3374 [D loss: 0.663009, acc.: 64.06%] [G loss: 0.988445]\n",
      "epoch:3 step:3375 [D loss: 0.691393, acc.: 61.72%] [G loss: 0.894211]\n",
      "epoch:3 step:3376 [D loss: 0.695902, acc.: 53.91%] [G loss: 1.039606]\n",
      "epoch:3 step:3377 [D loss: 0.704576, acc.: 50.78%] [G loss: 0.881682]\n",
      "epoch:3 step:3378 [D loss: 0.633978, acc.: 66.41%] [G loss: 0.963862]\n",
      "epoch:3 step:3379 [D loss: 0.677521, acc.: 63.28%] [G loss: 0.925272]\n",
      "epoch:3 step:3380 [D loss: 0.680591, acc.: 58.59%] [G loss: 1.015961]\n",
      "epoch:3 step:3381 [D loss: 0.704091, acc.: 54.69%] [G loss: 0.936008]\n",
      "epoch:3 step:3382 [D loss: 0.591195, acc.: 67.97%] [G loss: 1.094991]\n",
      "epoch:3 step:3383 [D loss: 0.666414, acc.: 55.47%] [G loss: 0.893903]\n",
      "epoch:3 step:3384 [D loss: 0.672992, acc.: 61.72%] [G loss: 0.961162]\n",
      "epoch:3 step:3385 [D loss: 0.623359, acc.: 64.06%] [G loss: 0.929257]\n",
      "epoch:3 step:3386 [D loss: 0.657757, acc.: 60.16%] [G loss: 0.988021]\n",
      "epoch:3 step:3387 [D loss: 0.692232, acc.: 55.47%] [G loss: 0.862538]\n",
      "epoch:3 step:3388 [D loss: 0.663451, acc.: 63.28%] [G loss: 0.985777]\n",
      "epoch:3 step:3389 [D loss: 0.693111, acc.: 59.38%] [G loss: 0.913010]\n",
      "epoch:3 step:3390 [D loss: 0.797944, acc.: 41.41%] [G loss: 0.904569]\n",
      "epoch:3 step:3391 [D loss: 0.676175, acc.: 57.03%] [G loss: 0.915494]\n",
      "epoch:3 step:3392 [D loss: 0.654988, acc.: 60.16%] [G loss: 1.026728]\n",
      "epoch:3 step:3393 [D loss: 0.669831, acc.: 55.47%] [G loss: 0.974082]\n",
      "epoch:3 step:3394 [D loss: 0.686907, acc.: 54.69%] [G loss: 0.967703]\n",
      "epoch:3 step:3395 [D loss: 0.647251, acc.: 69.53%] [G loss: 0.933265]\n",
      "epoch:3 step:3396 [D loss: 0.669849, acc.: 58.59%] [G loss: 0.934017]\n",
      "epoch:3 step:3397 [D loss: 0.655704, acc.: 62.50%] [G loss: 0.942911]\n",
      "epoch:3 step:3398 [D loss: 0.613893, acc.: 68.75%] [G loss: 1.011814]\n",
      "epoch:3 step:3399 [D loss: 0.660116, acc.: 62.50%] [G loss: 0.893952]\n",
      "epoch:3 step:3400 [D loss: 0.628565, acc.: 67.19%] [G loss: 1.039827]\n",
      "epoch:3 step:3401 [D loss: 0.643313, acc.: 62.50%] [G loss: 0.926311]\n",
      "epoch:3 step:3402 [D loss: 0.636451, acc.: 63.28%] [G loss: 0.917449]\n",
      "epoch:3 step:3403 [D loss: 0.611008, acc.: 67.19%] [G loss: 0.924778]\n",
      "epoch:3 step:3404 [D loss: 0.709710, acc.: 55.47%] [G loss: 0.982736]\n",
      "epoch:3 step:3405 [D loss: 0.688894, acc.: 57.03%] [G loss: 0.938777]\n",
      "epoch:3 step:3406 [D loss: 0.730542, acc.: 52.34%] [G loss: 1.048698]\n",
      "epoch:3 step:3407 [D loss: 0.671075, acc.: 60.16%] [G loss: 1.011395]\n",
      "epoch:3 step:3408 [D loss: 0.657217, acc.: 63.28%] [G loss: 0.956654]\n",
      "epoch:3 step:3409 [D loss: 0.606081, acc.: 66.41%] [G loss: 0.919248]\n",
      "epoch:3 step:3410 [D loss: 0.654526, acc.: 61.72%] [G loss: 0.810385]\n",
      "epoch:3 step:3411 [D loss: 0.734401, acc.: 49.22%] [G loss: 0.913804]\n",
      "epoch:3 step:3412 [D loss: 0.687174, acc.: 54.69%] [G loss: 0.931444]\n",
      "epoch:3 step:3413 [D loss: 0.611671, acc.: 67.97%] [G loss: 0.925929]\n",
      "epoch:3 step:3414 [D loss: 0.615318, acc.: 67.19%] [G loss: 0.949776]\n",
      "epoch:3 step:3415 [D loss: 0.682106, acc.: 61.72%] [G loss: 0.986179]\n",
      "epoch:3 step:3416 [D loss: 0.621795, acc.: 64.84%] [G loss: 1.037566]\n",
      "epoch:3 step:3417 [D loss: 0.633188, acc.: 62.50%] [G loss: 0.945443]\n",
      "epoch:3 step:3418 [D loss: 0.648459, acc.: 65.62%] [G loss: 0.899219]\n",
      "epoch:3 step:3419 [D loss: 0.609525, acc.: 62.50%] [G loss: 1.013044]\n",
      "epoch:3 step:3420 [D loss: 0.666129, acc.: 61.72%] [G loss: 0.941278]\n",
      "epoch:3 step:3421 [D loss: 0.639416, acc.: 64.06%] [G loss: 1.001687]\n",
      "epoch:3 step:3422 [D loss: 0.611917, acc.: 69.53%] [G loss: 1.058612]\n",
      "epoch:3 step:3423 [D loss: 0.657539, acc.: 65.62%] [G loss: 1.012098]\n",
      "epoch:3 step:3424 [D loss: 0.632877, acc.: 60.16%] [G loss: 0.984129]\n",
      "epoch:3 step:3425 [D loss: 0.683352, acc.: 59.38%] [G loss: 0.973030]\n",
      "epoch:3 step:3426 [D loss: 0.832873, acc.: 37.50%] [G loss: 0.871705]\n",
      "epoch:3 step:3427 [D loss: 0.681209, acc.: 60.94%] [G loss: 0.953140]\n",
      "epoch:3 step:3428 [D loss: 0.726870, acc.: 48.44%] [G loss: 0.942023]\n",
      "epoch:3 step:3429 [D loss: 0.655756, acc.: 63.28%] [G loss: 0.911435]\n",
      "epoch:3 step:3430 [D loss: 0.703885, acc.: 55.47%] [G loss: 0.834259]\n",
      "epoch:3 step:3431 [D loss: 0.689129, acc.: 60.94%] [G loss: 1.000205]\n",
      "epoch:3 step:3432 [D loss: 0.669037, acc.: 55.47%] [G loss: 0.991867]\n",
      "epoch:3 step:3433 [D loss: 0.673939, acc.: 57.81%] [G loss: 1.069661]\n",
      "epoch:3 step:3434 [D loss: 0.643492, acc.: 57.03%] [G loss: 0.937721]\n",
      "epoch:3 step:3435 [D loss: 0.604005, acc.: 65.62%] [G loss: 1.158348]\n",
      "epoch:3 step:3436 [D loss: 0.644162, acc.: 60.16%] [G loss: 0.918406]\n",
      "epoch:3 step:3437 [D loss: 0.648158, acc.: 62.50%] [G loss: 1.029613]\n",
      "epoch:3 step:3438 [D loss: 0.685690, acc.: 57.81%] [G loss: 0.909389]\n",
      "epoch:3 step:3439 [D loss: 0.704609, acc.: 53.12%] [G loss: 0.862685]\n",
      "epoch:3 step:3440 [D loss: 0.671089, acc.: 61.72%] [G loss: 1.016020]\n",
      "epoch:3 step:3441 [D loss: 0.665765, acc.: 64.06%] [G loss: 1.008310]\n",
      "epoch:3 step:3442 [D loss: 0.636034, acc.: 65.62%] [G loss: 1.135117]\n",
      "epoch:3 step:3443 [D loss: 0.616599, acc.: 67.97%] [G loss: 1.083587]\n",
      "epoch:3 step:3444 [D loss: 0.694518, acc.: 55.47%] [G loss: 1.030431]\n",
      "epoch:3 step:3445 [D loss: 0.675984, acc.: 56.25%] [G loss: 0.998640]\n",
      "epoch:3 step:3446 [D loss: 0.607405, acc.: 66.41%] [G loss: 1.035817]\n",
      "epoch:3 step:3447 [D loss: 0.696565, acc.: 59.38%] [G loss: 0.901989]\n",
      "epoch:3 step:3448 [D loss: 0.676631, acc.: 57.81%] [G loss: 1.057856]\n",
      "epoch:3 step:3449 [D loss: 0.650838, acc.: 60.16%] [G loss: 0.976451]\n",
      "epoch:3 step:3450 [D loss: 0.652589, acc.: 64.06%] [G loss: 0.975228]\n",
      "epoch:3 step:3451 [D loss: 0.674797, acc.: 57.81%] [G loss: 1.107012]\n",
      "epoch:3 step:3452 [D loss: 0.637664, acc.: 59.38%] [G loss: 1.163509]\n",
      "epoch:3 step:3453 [D loss: 0.603886, acc.: 64.84%] [G loss: 1.002351]\n",
      "epoch:3 step:3454 [D loss: 0.672447, acc.: 59.38%] [G loss: 0.959251]\n",
      "epoch:3 step:3455 [D loss: 0.661017, acc.: 57.81%] [G loss: 1.008552]\n",
      "epoch:3 step:3456 [D loss: 0.680164, acc.: 59.38%] [G loss: 0.892905]\n",
      "epoch:3 step:3457 [D loss: 0.647445, acc.: 60.94%] [G loss: 1.005978]\n",
      "epoch:3 step:3458 [D loss: 0.655448, acc.: 61.72%] [G loss: 0.945043]\n",
      "epoch:3 step:3459 [D loss: 0.624849, acc.: 65.62%] [G loss: 1.075114]\n",
      "epoch:3 step:3460 [D loss: 0.575285, acc.: 71.09%] [G loss: 0.971328]\n",
      "epoch:3 step:3461 [D loss: 0.664675, acc.: 56.25%] [G loss: 0.980693]\n",
      "epoch:3 step:3462 [D loss: 0.620960, acc.: 64.84%] [G loss: 0.957435]\n",
      "epoch:3 step:3463 [D loss: 0.715310, acc.: 54.69%] [G loss: 0.925368]\n",
      "epoch:3 step:3464 [D loss: 0.661702, acc.: 60.94%] [G loss: 0.850266]\n",
      "epoch:3 step:3465 [D loss: 0.645196, acc.: 63.28%] [G loss: 0.933046]\n",
      "epoch:3 step:3466 [D loss: 0.658572, acc.: 64.06%] [G loss: 0.966268]\n",
      "epoch:3 step:3467 [D loss: 0.692767, acc.: 57.03%] [G loss: 0.944522]\n",
      "epoch:3 step:3468 [D loss: 0.636676, acc.: 64.84%] [G loss: 0.966682]\n",
      "epoch:3 step:3469 [D loss: 0.657720, acc.: 55.47%] [G loss: 0.885956]\n",
      "epoch:3 step:3470 [D loss: 0.633869, acc.: 61.72%] [G loss: 0.947243]\n",
      "epoch:3 step:3471 [D loss: 0.588058, acc.: 71.09%] [G loss: 0.997694]\n",
      "epoch:3 step:3472 [D loss: 0.618416, acc.: 67.97%] [G loss: 0.942447]\n",
      "epoch:3 step:3473 [D loss: 0.627291, acc.: 66.41%] [G loss: 1.029340]\n",
      "epoch:3 step:3474 [D loss: 0.674386, acc.: 52.34%] [G loss: 0.894916]\n",
      "epoch:3 step:3475 [D loss: 0.791498, acc.: 43.75%] [G loss: 0.923833]\n",
      "epoch:3 step:3476 [D loss: 0.632709, acc.: 64.84%] [G loss: 0.980609]\n",
      "epoch:3 step:3477 [D loss: 0.673658, acc.: 60.94%] [G loss: 0.918489]\n",
      "epoch:3 step:3478 [D loss: 0.722834, acc.: 52.34%] [G loss: 0.939229]\n",
      "epoch:3 step:3479 [D loss: 0.660330, acc.: 59.38%] [G loss: 0.985989]\n",
      "epoch:3 step:3480 [D loss: 0.686340, acc.: 56.25%] [G loss: 0.926976]\n",
      "epoch:3 step:3481 [D loss: 0.616515, acc.: 64.06%] [G loss: 1.046592]\n",
      "epoch:3 step:3482 [D loss: 0.673378, acc.: 58.59%] [G loss: 1.087402]\n",
      "epoch:3 step:3483 [D loss: 0.651276, acc.: 60.94%] [G loss: 0.953347]\n",
      "epoch:3 step:3484 [D loss: 0.713069, acc.: 53.12%] [G loss: 1.050883]\n",
      "epoch:3 step:3485 [D loss: 0.672104, acc.: 58.59%] [G loss: 1.025371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3486 [D loss: 0.661127, acc.: 58.59%] [G loss: 1.001587]\n",
      "epoch:3 step:3487 [D loss: 0.678149, acc.: 57.03%] [G loss: 0.961905]\n",
      "epoch:3 step:3488 [D loss: 0.657666, acc.: 57.81%] [G loss: 0.861087]\n",
      "epoch:3 step:3489 [D loss: 0.649022, acc.: 62.50%] [G loss: 1.091468]\n",
      "epoch:3 step:3490 [D loss: 0.649656, acc.: 58.59%] [G loss: 0.993457]\n",
      "epoch:3 step:3491 [D loss: 0.616253, acc.: 66.41%] [G loss: 0.915916]\n",
      "epoch:3 step:3492 [D loss: 0.638369, acc.: 61.72%] [G loss: 0.898102]\n",
      "epoch:3 step:3493 [D loss: 0.582620, acc.: 72.66%] [G loss: 0.991215]\n",
      "epoch:3 step:3494 [D loss: 0.682709, acc.: 58.59%] [G loss: 1.056766]\n",
      "epoch:3 step:3495 [D loss: 0.615087, acc.: 69.53%] [G loss: 0.966281]\n",
      "epoch:3 step:3496 [D loss: 0.677041, acc.: 56.25%] [G loss: 0.910779]\n",
      "epoch:3 step:3497 [D loss: 0.591538, acc.: 71.09%] [G loss: 0.970353]\n",
      "epoch:3 step:3498 [D loss: 0.656690, acc.: 59.38%] [G loss: 0.904863]\n",
      "epoch:3 step:3499 [D loss: 0.701371, acc.: 60.16%] [G loss: 0.905654]\n",
      "epoch:3 step:3500 [D loss: 0.649673, acc.: 65.62%] [G loss: 0.993661]\n",
      "epoch:3 step:3501 [D loss: 0.676506, acc.: 61.72%] [G loss: 0.932298]\n",
      "epoch:3 step:3502 [D loss: 0.645235, acc.: 64.84%] [G loss: 1.074655]\n",
      "epoch:3 step:3503 [D loss: 0.712505, acc.: 55.47%] [G loss: 1.018623]\n",
      "epoch:3 step:3504 [D loss: 0.658559, acc.: 62.50%] [G loss: 0.963310]\n",
      "epoch:3 step:3505 [D loss: 0.562254, acc.: 73.44%] [G loss: 1.040917]\n",
      "epoch:3 step:3506 [D loss: 0.701794, acc.: 57.03%] [G loss: 0.903540]\n",
      "epoch:3 step:3507 [D loss: 0.673810, acc.: 56.25%] [G loss: 0.977739]\n",
      "epoch:3 step:3508 [D loss: 0.707266, acc.: 47.66%] [G loss: 0.960212]\n",
      "epoch:3 step:3509 [D loss: 0.659124, acc.: 55.47%] [G loss: 1.036789]\n",
      "epoch:3 step:3510 [D loss: 0.684221, acc.: 55.47%] [G loss: 0.978021]\n",
      "epoch:3 step:3511 [D loss: 0.717129, acc.: 52.34%] [G loss: 0.862798]\n",
      "epoch:3 step:3512 [D loss: 0.698592, acc.: 56.25%] [G loss: 0.994974]\n",
      "epoch:3 step:3513 [D loss: 0.725470, acc.: 50.78%] [G loss: 1.058585]\n",
      "epoch:3 step:3514 [D loss: 0.674450, acc.: 60.94%] [G loss: 1.099150]\n",
      "epoch:3 step:3515 [D loss: 0.715337, acc.: 52.34%] [G loss: 0.853807]\n",
      "epoch:3 step:3516 [D loss: 0.615536, acc.: 69.53%] [G loss: 0.887090]\n",
      "epoch:3 step:3517 [D loss: 0.582253, acc.: 69.53%] [G loss: 1.095035]\n",
      "epoch:3 step:3518 [D loss: 0.658240, acc.: 62.50%] [G loss: 1.065905]\n",
      "epoch:3 step:3519 [D loss: 0.631193, acc.: 64.84%] [G loss: 0.915770]\n",
      "epoch:3 step:3520 [D loss: 0.640978, acc.: 63.28%] [G loss: 1.012466]\n",
      "epoch:3 step:3521 [D loss: 0.738738, acc.: 46.88%] [G loss: 0.954238]\n",
      "epoch:3 step:3522 [D loss: 0.717425, acc.: 56.25%] [G loss: 0.988315]\n",
      "epoch:3 step:3523 [D loss: 0.627428, acc.: 64.06%] [G loss: 0.938933]\n",
      "epoch:3 step:3524 [D loss: 0.672544, acc.: 64.06%] [G loss: 0.903864]\n",
      "epoch:3 step:3525 [D loss: 0.683625, acc.: 57.03%] [G loss: 0.948592]\n",
      "epoch:3 step:3526 [D loss: 0.633414, acc.: 66.41%] [G loss: 0.964830]\n",
      "epoch:3 step:3527 [D loss: 0.727887, acc.: 55.47%] [G loss: 0.953110]\n",
      "epoch:3 step:3528 [D loss: 0.713752, acc.: 58.59%] [G loss: 0.952387]\n",
      "epoch:3 step:3529 [D loss: 0.639956, acc.: 63.28%] [G loss: 0.879764]\n",
      "epoch:3 step:3530 [D loss: 0.668180, acc.: 57.03%] [G loss: 0.960050]\n",
      "epoch:3 step:3531 [D loss: 0.691542, acc.: 54.69%] [G loss: 0.850454]\n",
      "epoch:3 step:3532 [D loss: 0.669397, acc.: 58.59%] [G loss: 0.989650]\n",
      "epoch:3 step:3533 [D loss: 0.647640, acc.: 60.94%] [G loss: 0.921741]\n",
      "epoch:3 step:3534 [D loss: 0.629626, acc.: 69.53%] [G loss: 0.973574]\n",
      "epoch:3 step:3535 [D loss: 0.615375, acc.: 64.06%] [G loss: 1.136026]\n",
      "epoch:3 step:3536 [D loss: 0.634298, acc.: 61.72%] [G loss: 0.947828]\n",
      "epoch:3 step:3537 [D loss: 0.694159, acc.: 56.25%] [G loss: 0.882247]\n",
      "epoch:3 step:3538 [D loss: 0.644455, acc.: 64.84%] [G loss: 0.983900]\n",
      "epoch:3 step:3539 [D loss: 0.682190, acc.: 59.38%] [G loss: 0.799766]\n",
      "epoch:3 step:3540 [D loss: 0.697483, acc.: 57.03%] [G loss: 0.928382]\n",
      "epoch:3 step:3541 [D loss: 0.615407, acc.: 67.97%] [G loss: 0.926230]\n",
      "epoch:3 step:3542 [D loss: 0.636426, acc.: 65.62%] [G loss: 1.013935]\n",
      "epoch:3 step:3543 [D loss: 0.660687, acc.: 64.84%] [G loss: 0.985125]\n",
      "epoch:3 step:3544 [D loss: 0.619234, acc.: 64.06%] [G loss: 1.014550]\n",
      "epoch:3 step:3545 [D loss: 0.690368, acc.: 53.12%] [G loss: 0.988304]\n",
      "epoch:3 step:3546 [D loss: 0.651817, acc.: 64.06%] [G loss: 1.010379]\n",
      "epoch:3 step:3547 [D loss: 0.605763, acc.: 67.19%] [G loss: 0.965014]\n",
      "epoch:3 step:3548 [D loss: 0.634565, acc.: 62.50%] [G loss: 0.881118]\n",
      "epoch:3 step:3549 [D loss: 0.699210, acc.: 52.34%] [G loss: 0.941042]\n",
      "epoch:3 step:3550 [D loss: 0.701749, acc.: 57.03%] [G loss: 0.966408]\n",
      "epoch:3 step:3551 [D loss: 0.727658, acc.: 49.22%] [G loss: 0.916684]\n",
      "epoch:3 step:3552 [D loss: 0.669651, acc.: 56.25%] [G loss: 0.955772]\n",
      "epoch:3 step:3553 [D loss: 0.716378, acc.: 52.34%] [G loss: 0.883023]\n",
      "epoch:3 step:3554 [D loss: 0.687829, acc.: 54.69%] [G loss: 0.912860]\n",
      "epoch:3 step:3555 [D loss: 0.651656, acc.: 57.03%] [G loss: 0.919459]\n",
      "epoch:3 step:3556 [D loss: 0.654787, acc.: 56.25%] [G loss: 0.902893]\n",
      "epoch:3 step:3557 [D loss: 0.633804, acc.: 68.75%] [G loss: 1.008839]\n",
      "epoch:3 step:3558 [D loss: 0.618736, acc.: 70.31%] [G loss: 0.972386]\n",
      "epoch:3 step:3559 [D loss: 0.674657, acc.: 54.69%] [G loss: 1.042727]\n",
      "epoch:3 step:3560 [D loss: 0.660760, acc.: 62.50%] [G loss: 0.887222]\n",
      "epoch:3 step:3561 [D loss: 0.671018, acc.: 59.38%] [G loss: 0.811887]\n",
      "epoch:3 step:3562 [D loss: 0.654262, acc.: 62.50%] [G loss: 0.927803]\n",
      "epoch:3 step:3563 [D loss: 0.666140, acc.: 60.94%] [G loss: 0.953139]\n",
      "epoch:3 step:3564 [D loss: 0.599756, acc.: 67.19%] [G loss: 0.951765]\n",
      "epoch:3 step:3565 [D loss: 0.659379, acc.: 57.03%] [G loss: 1.014693]\n",
      "epoch:3 step:3566 [D loss: 0.710171, acc.: 53.91%] [G loss: 0.866536]\n",
      "epoch:3 step:3567 [D loss: 0.685271, acc.: 57.03%] [G loss: 0.970006]\n",
      "epoch:3 step:3568 [D loss: 0.615605, acc.: 67.97%] [G loss: 0.997454]\n",
      "epoch:3 step:3569 [D loss: 0.682399, acc.: 55.47%] [G loss: 0.977309]\n",
      "epoch:3 step:3570 [D loss: 0.782075, acc.: 50.00%] [G loss: 0.998258]\n",
      "epoch:3 step:3571 [D loss: 0.628622, acc.: 66.41%] [G loss: 1.024813]\n",
      "epoch:3 step:3572 [D loss: 0.727879, acc.: 51.56%] [G loss: 0.911546]\n",
      "epoch:3 step:3573 [D loss: 0.698487, acc.: 55.47%] [G loss: 0.983883]\n",
      "epoch:3 step:3574 [D loss: 0.684883, acc.: 57.81%] [G loss: 1.010767]\n",
      "epoch:3 step:3575 [D loss: 0.624355, acc.: 60.94%] [G loss: 1.023039]\n",
      "epoch:3 step:3576 [D loss: 0.668091, acc.: 60.16%] [G loss: 1.008877]\n",
      "epoch:3 step:3577 [D loss: 0.702686, acc.: 54.69%] [G loss: 0.893757]\n",
      "epoch:3 step:3578 [D loss: 0.738597, acc.: 54.69%] [G loss: 0.898021]\n",
      "epoch:3 step:3579 [D loss: 0.651190, acc.: 65.62%] [G loss: 1.069852]\n",
      "epoch:3 step:3580 [D loss: 0.716947, acc.: 50.78%] [G loss: 0.880914]\n",
      "epoch:3 step:3581 [D loss: 0.721788, acc.: 47.66%] [G loss: 0.927114]\n",
      "epoch:3 step:3582 [D loss: 0.709014, acc.: 55.47%] [G loss: 0.887996]\n",
      "epoch:3 step:3583 [D loss: 0.614606, acc.: 66.41%] [G loss: 0.923058]\n",
      "epoch:3 step:3584 [D loss: 0.639351, acc.: 58.59%] [G loss: 0.979889]\n",
      "epoch:3 step:3585 [D loss: 0.644393, acc.: 60.94%] [G loss: 1.071793]\n",
      "epoch:3 step:3586 [D loss: 0.698488, acc.: 56.25%] [G loss: 0.881304]\n",
      "epoch:3 step:3587 [D loss: 0.659216, acc.: 66.41%] [G loss: 0.949243]\n",
      "epoch:3 step:3588 [D loss: 0.643485, acc.: 64.84%] [G loss: 1.028562]\n",
      "epoch:3 step:3589 [D loss: 0.697508, acc.: 52.34%] [G loss: 0.938125]\n",
      "epoch:3 step:3590 [D loss: 0.691790, acc.: 56.25%] [G loss: 1.007339]\n",
      "epoch:3 step:3591 [D loss: 0.662408, acc.: 59.38%] [G loss: 0.923660]\n",
      "epoch:3 step:3592 [D loss: 0.643044, acc.: 63.28%] [G loss: 0.876260]\n",
      "epoch:3 step:3593 [D loss: 0.625219, acc.: 62.50%] [G loss: 0.882408]\n",
      "epoch:3 step:3594 [D loss: 0.622912, acc.: 63.28%] [G loss: 0.953415]\n",
      "epoch:3 step:3595 [D loss: 0.617865, acc.: 67.97%] [G loss: 0.987892]\n",
      "epoch:3 step:3596 [D loss: 0.660314, acc.: 60.16%] [G loss: 0.902766]\n",
      "epoch:3 step:3597 [D loss: 0.624909, acc.: 63.28%] [G loss: 0.943052]\n",
      "epoch:3 step:3598 [D loss: 0.629299, acc.: 62.50%] [G loss: 0.973836]\n",
      "epoch:3 step:3599 [D loss: 0.661779, acc.: 58.59%] [G loss: 0.939360]\n",
      "epoch:3 step:3600 [D loss: 0.687902, acc.: 58.59%] [G loss: 0.937795]\n",
      "epoch:3 step:3601 [D loss: 0.565287, acc.: 75.00%] [G loss: 0.912508]\n",
      "epoch:3 step:3602 [D loss: 0.652288, acc.: 63.28%] [G loss: 0.866354]\n",
      "epoch:3 step:3603 [D loss: 0.662654, acc.: 59.38%] [G loss: 0.977177]\n",
      "epoch:3 step:3604 [D loss: 0.638652, acc.: 61.72%] [G loss: 1.063200]\n",
      "epoch:3 step:3605 [D loss: 0.636585, acc.: 63.28%] [G loss: 0.877004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3606 [D loss: 0.708439, acc.: 53.12%] [G loss: 0.827282]\n",
      "epoch:3 step:3607 [D loss: 0.679284, acc.: 60.16%] [G loss: 0.972935]\n",
      "epoch:3 step:3608 [D loss: 0.627373, acc.: 62.50%] [G loss: 0.967142]\n",
      "epoch:3 step:3609 [D loss: 0.631104, acc.: 64.84%] [G loss: 0.904821]\n",
      "epoch:3 step:3610 [D loss: 0.669470, acc.: 60.16%] [G loss: 0.970484]\n",
      "epoch:3 step:3611 [D loss: 0.725191, acc.: 51.56%] [G loss: 0.932013]\n",
      "epoch:3 step:3612 [D loss: 0.674328, acc.: 64.06%] [G loss: 0.901206]\n",
      "epoch:3 step:3613 [D loss: 0.655799, acc.: 63.28%] [G loss: 1.045183]\n",
      "epoch:3 step:3614 [D loss: 0.625149, acc.: 66.41%] [G loss: 0.985549]\n",
      "epoch:3 step:3615 [D loss: 0.642118, acc.: 64.84%] [G loss: 0.957008]\n",
      "epoch:3 step:3616 [D loss: 0.589646, acc.: 67.97%] [G loss: 0.782405]\n",
      "epoch:3 step:3617 [D loss: 0.626407, acc.: 60.94%] [G loss: 1.105745]\n",
      "epoch:3 step:3618 [D loss: 0.612169, acc.: 67.19%] [G loss: 1.034917]\n",
      "epoch:3 step:3619 [D loss: 0.639636, acc.: 60.94%] [G loss: 0.917594]\n",
      "epoch:3 step:3620 [D loss: 0.701285, acc.: 56.25%] [G loss: 0.952458]\n",
      "epoch:3 step:3621 [D loss: 0.645161, acc.: 59.38%] [G loss: 1.077469]\n",
      "epoch:3 step:3622 [D loss: 0.661395, acc.: 61.72%] [G loss: 0.968712]\n",
      "epoch:3 step:3623 [D loss: 0.731740, acc.: 50.00%] [G loss: 0.918432]\n",
      "epoch:3 step:3624 [D loss: 0.677086, acc.: 58.59%] [G loss: 0.960527]\n",
      "epoch:3 step:3625 [D loss: 0.619445, acc.: 63.28%] [G loss: 0.962272]\n",
      "epoch:3 step:3626 [D loss: 0.673036, acc.: 57.81%] [G loss: 0.832008]\n",
      "epoch:3 step:3627 [D loss: 0.712102, acc.: 53.91%] [G loss: 0.957414]\n",
      "epoch:3 step:3628 [D loss: 0.663901, acc.: 60.94%] [G loss: 0.957556]\n",
      "epoch:3 step:3629 [D loss: 0.647447, acc.: 64.84%] [G loss: 0.828640]\n",
      "epoch:3 step:3630 [D loss: 0.616090, acc.: 69.53%] [G loss: 0.987101]\n",
      "epoch:3 step:3631 [D loss: 0.720019, acc.: 46.88%] [G loss: 0.947044]\n",
      "epoch:3 step:3632 [D loss: 0.684049, acc.: 58.59%] [G loss: 0.927945]\n",
      "epoch:3 step:3633 [D loss: 0.632535, acc.: 61.72%] [G loss: 0.891671]\n",
      "epoch:3 step:3634 [D loss: 0.611822, acc.: 63.28%] [G loss: 0.978458]\n",
      "epoch:3 step:3635 [D loss: 0.685499, acc.: 57.81%] [G loss: 1.081277]\n",
      "epoch:3 step:3636 [D loss: 0.667328, acc.: 65.62%] [G loss: 1.008199]\n",
      "epoch:3 step:3637 [D loss: 0.669755, acc.: 59.38%] [G loss: 1.001282]\n",
      "epoch:3 step:3638 [D loss: 0.638535, acc.: 61.72%] [G loss: 0.988554]\n",
      "epoch:3 step:3639 [D loss: 0.692322, acc.: 54.69%] [G loss: 0.943354]\n",
      "epoch:3 step:3640 [D loss: 0.662516, acc.: 62.50%] [G loss: 0.999538]\n",
      "epoch:3 step:3641 [D loss: 0.576155, acc.: 66.41%] [G loss: 1.095645]\n",
      "epoch:3 step:3642 [D loss: 0.579950, acc.: 71.09%] [G loss: 0.978092]\n",
      "epoch:3 step:3643 [D loss: 0.600540, acc.: 66.41%] [G loss: 0.966327]\n",
      "epoch:3 step:3644 [D loss: 0.605921, acc.: 67.97%] [G loss: 1.058845]\n",
      "epoch:3 step:3645 [D loss: 0.631003, acc.: 63.28%] [G loss: 1.091099]\n",
      "epoch:3 step:3646 [D loss: 0.651726, acc.: 62.50%] [G loss: 0.985175]\n",
      "epoch:3 step:3647 [D loss: 0.685979, acc.: 58.59%] [G loss: 0.997222]\n",
      "epoch:3 step:3648 [D loss: 0.718661, acc.: 53.12%] [G loss: 1.027290]\n",
      "epoch:3 step:3649 [D loss: 0.671562, acc.: 54.69%] [G loss: 0.921923]\n",
      "epoch:3 step:3650 [D loss: 0.627745, acc.: 64.06%] [G loss: 0.905101]\n",
      "epoch:3 step:3651 [D loss: 0.659529, acc.: 60.16%] [G loss: 1.020082]\n",
      "epoch:3 step:3652 [D loss: 0.649274, acc.: 63.28%] [G loss: 1.077394]\n",
      "epoch:3 step:3653 [D loss: 0.597273, acc.: 72.66%] [G loss: 1.037645]\n",
      "epoch:3 step:3654 [D loss: 0.749535, acc.: 50.00%] [G loss: 0.932207]\n",
      "epoch:3 step:3655 [D loss: 0.681874, acc.: 57.03%] [G loss: 1.037271]\n",
      "epoch:3 step:3656 [D loss: 0.719383, acc.: 52.34%] [G loss: 1.012479]\n",
      "epoch:3 step:3657 [D loss: 0.651026, acc.: 64.84%] [G loss: 1.036267]\n",
      "epoch:3 step:3658 [D loss: 0.638726, acc.: 64.84%] [G loss: 1.023814]\n",
      "epoch:3 step:3659 [D loss: 0.604045, acc.: 70.31%] [G loss: 0.993994]\n",
      "epoch:3 step:3660 [D loss: 0.662398, acc.: 60.94%] [G loss: 1.001194]\n",
      "epoch:3 step:3661 [D loss: 0.717459, acc.: 59.38%] [G loss: 0.922440]\n",
      "epoch:3 step:3662 [D loss: 0.682943, acc.: 55.47%] [G loss: 0.931350]\n",
      "epoch:3 step:3663 [D loss: 0.651933, acc.: 58.59%] [G loss: 1.031973]\n",
      "epoch:3 step:3664 [D loss: 0.654392, acc.: 59.38%] [G loss: 0.979259]\n",
      "epoch:3 step:3665 [D loss: 0.628127, acc.: 67.19%] [G loss: 1.032495]\n",
      "epoch:3 step:3666 [D loss: 0.607151, acc.: 64.06%] [G loss: 0.938298]\n",
      "epoch:3 step:3667 [D loss: 0.718062, acc.: 54.69%] [G loss: 0.884020]\n",
      "epoch:3 step:3668 [D loss: 0.673646, acc.: 62.50%] [G loss: 0.940343]\n",
      "epoch:3 step:3669 [D loss: 0.775476, acc.: 46.88%] [G loss: 0.941818]\n",
      "epoch:3 step:3670 [D loss: 0.733134, acc.: 55.47%] [G loss: 0.896329]\n",
      "epoch:3 step:3671 [D loss: 0.638463, acc.: 65.62%] [G loss: 1.013560]\n",
      "epoch:3 step:3672 [D loss: 0.645530, acc.: 64.84%] [G loss: 0.968404]\n",
      "epoch:3 step:3673 [D loss: 0.640415, acc.: 59.38%] [G loss: 0.897865]\n",
      "epoch:3 step:3674 [D loss: 0.644888, acc.: 60.16%] [G loss: 0.965037]\n",
      "epoch:3 step:3675 [D loss: 0.720755, acc.: 57.81%] [G loss: 0.847312]\n",
      "epoch:3 step:3676 [D loss: 0.672445, acc.: 57.03%] [G loss: 0.897211]\n",
      "epoch:3 step:3677 [D loss: 0.674151, acc.: 55.47%] [G loss: 0.825354]\n",
      "epoch:3 step:3678 [D loss: 0.712351, acc.: 48.44%] [G loss: 0.843863]\n",
      "epoch:3 step:3679 [D loss: 0.677090, acc.: 58.59%] [G loss: 0.941756]\n",
      "epoch:3 step:3680 [D loss: 0.662347, acc.: 62.50%] [G loss: 0.937823]\n",
      "epoch:3 step:3681 [D loss: 0.733065, acc.: 52.34%] [G loss: 1.037301]\n",
      "epoch:3 step:3682 [D loss: 0.638018, acc.: 59.38%] [G loss: 0.929083]\n",
      "epoch:3 step:3683 [D loss: 0.641194, acc.: 60.16%] [G loss: 0.989140]\n",
      "epoch:3 step:3684 [D loss: 0.670620, acc.: 60.16%] [G loss: 0.854499]\n",
      "epoch:3 step:3685 [D loss: 0.702997, acc.: 55.47%] [G loss: 0.922429]\n",
      "epoch:3 step:3686 [D loss: 0.581668, acc.: 71.88%] [G loss: 1.022948]\n",
      "epoch:3 step:3687 [D loss: 0.642251, acc.: 66.41%] [G loss: 1.017051]\n",
      "epoch:3 step:3688 [D loss: 0.706422, acc.: 52.34%] [G loss: 0.952067]\n",
      "epoch:3 step:3689 [D loss: 0.642331, acc.: 66.41%] [G loss: 1.010905]\n",
      "epoch:3 step:3690 [D loss: 0.692946, acc.: 54.69%] [G loss: 0.878022]\n",
      "epoch:3 step:3691 [D loss: 0.706640, acc.: 57.03%] [G loss: 1.083301]\n",
      "epoch:3 step:3692 [D loss: 0.632609, acc.: 65.62%] [G loss: 0.929944]\n",
      "epoch:3 step:3693 [D loss: 0.683549, acc.: 53.91%] [G loss: 0.932359]\n",
      "epoch:3 step:3694 [D loss: 0.775306, acc.: 48.44%] [G loss: 0.918397]\n",
      "epoch:3 step:3695 [D loss: 0.662848, acc.: 61.72%] [G loss: 0.978983]\n",
      "epoch:3 step:3696 [D loss: 0.620632, acc.: 61.72%] [G loss: 1.049374]\n",
      "epoch:3 step:3697 [D loss: 0.594828, acc.: 67.97%] [G loss: 1.027705]\n",
      "epoch:3 step:3698 [D loss: 0.678636, acc.: 56.25%] [G loss: 0.950092]\n",
      "epoch:3 step:3699 [D loss: 0.676323, acc.: 55.47%] [G loss: 0.897104]\n",
      "epoch:3 step:3700 [D loss: 0.612700, acc.: 66.41%] [G loss: 1.075890]\n",
      "epoch:3 step:3701 [D loss: 0.630656, acc.: 65.62%] [G loss: 0.948487]\n",
      "epoch:3 step:3702 [D loss: 0.670537, acc.: 65.62%] [G loss: 1.047280]\n",
      "epoch:3 step:3703 [D loss: 0.729428, acc.: 56.25%] [G loss: 0.867160]\n",
      "epoch:3 step:3704 [D loss: 0.678872, acc.: 58.59%] [G loss: 0.890935]\n",
      "epoch:3 step:3705 [D loss: 0.561037, acc.: 75.78%] [G loss: 1.012982]\n",
      "epoch:3 step:3706 [D loss: 0.607651, acc.: 64.06%] [G loss: 0.872069]\n",
      "epoch:3 step:3707 [D loss: 0.660800, acc.: 61.72%] [G loss: 1.008692]\n",
      "epoch:3 step:3708 [D loss: 0.624352, acc.: 67.19%] [G loss: 0.844322]\n",
      "epoch:3 step:3709 [D loss: 0.609273, acc.: 61.72%] [G loss: 1.035900]\n",
      "epoch:3 step:3710 [D loss: 0.631759, acc.: 64.06%] [G loss: 0.880979]\n",
      "epoch:3 step:3711 [D loss: 0.676327, acc.: 57.81%] [G loss: 0.902199]\n",
      "epoch:3 step:3712 [D loss: 0.615286, acc.: 64.84%] [G loss: 0.970168]\n",
      "epoch:3 step:3713 [D loss: 0.698571, acc.: 57.03%] [G loss: 0.900421]\n",
      "epoch:3 step:3714 [D loss: 0.680698, acc.: 59.38%] [G loss: 0.992996]\n",
      "epoch:3 step:3715 [D loss: 0.622335, acc.: 63.28%] [G loss: 0.977947]\n",
      "epoch:3 step:3716 [D loss: 0.590382, acc.: 68.75%] [G loss: 0.963617]\n",
      "epoch:3 step:3717 [D loss: 0.639078, acc.: 64.06%] [G loss: 0.997093]\n",
      "epoch:3 step:3718 [D loss: 0.626453, acc.: 65.62%] [G loss: 1.052498]\n",
      "epoch:3 step:3719 [D loss: 0.702438, acc.: 55.47%] [G loss: 0.940918]\n",
      "epoch:3 step:3720 [D loss: 0.634597, acc.: 63.28%] [G loss: 0.907375]\n",
      "epoch:3 step:3721 [D loss: 0.535022, acc.: 78.91%] [G loss: 1.002973]\n",
      "epoch:3 step:3722 [D loss: 0.630124, acc.: 61.72%] [G loss: 1.081147]\n",
      "epoch:3 step:3723 [D loss: 0.603661, acc.: 66.41%] [G loss: 1.057843]\n",
      "epoch:3 step:3724 [D loss: 0.705341, acc.: 56.25%] [G loss: 0.971127]\n",
      "epoch:3 step:3725 [D loss: 0.612788, acc.: 66.41%] [G loss: 1.089447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3726 [D loss: 0.693034, acc.: 55.47%] [G loss: 0.939146]\n",
      "epoch:3 step:3727 [D loss: 0.673004, acc.: 57.81%] [G loss: 0.939280]\n",
      "epoch:3 step:3728 [D loss: 0.651637, acc.: 65.62%] [G loss: 0.920602]\n",
      "epoch:3 step:3729 [D loss: 0.579945, acc.: 68.75%] [G loss: 1.030497]\n",
      "epoch:3 step:3730 [D loss: 0.613502, acc.: 67.97%] [G loss: 0.963601]\n",
      "epoch:3 step:3731 [D loss: 0.720480, acc.: 52.34%] [G loss: 1.054959]\n",
      "epoch:3 step:3732 [D loss: 0.657639, acc.: 59.38%] [G loss: 0.886156]\n",
      "epoch:3 step:3733 [D loss: 0.648246, acc.: 56.25%] [G loss: 0.985835]\n",
      "epoch:3 step:3734 [D loss: 0.554580, acc.: 71.09%] [G loss: 1.055065]\n",
      "epoch:3 step:3735 [D loss: 0.568060, acc.: 69.53%] [G loss: 1.042181]\n",
      "epoch:3 step:3736 [D loss: 0.519988, acc.: 77.34%] [G loss: 1.262905]\n",
      "epoch:3 step:3737 [D loss: 0.573788, acc.: 67.97%] [G loss: 1.114803]\n",
      "epoch:3 step:3738 [D loss: 0.617113, acc.: 67.97%] [G loss: 1.060724]\n",
      "epoch:3 step:3739 [D loss: 0.860199, acc.: 50.00%] [G loss: 1.123729]\n",
      "epoch:3 step:3740 [D loss: 0.851554, acc.: 44.53%] [G loss: 0.908536]\n",
      "epoch:3 step:3741 [D loss: 0.611362, acc.: 64.84%] [G loss: 0.892862]\n",
      "epoch:3 step:3742 [D loss: 0.659269, acc.: 58.59%] [G loss: 0.960016]\n",
      "epoch:3 step:3743 [D loss: 0.621801, acc.: 65.62%] [G loss: 0.950776]\n",
      "epoch:3 step:3744 [D loss: 0.653493, acc.: 63.28%] [G loss: 1.016288]\n",
      "epoch:3 step:3745 [D loss: 0.696386, acc.: 50.78%] [G loss: 1.009750]\n",
      "epoch:3 step:3746 [D loss: 0.688186, acc.: 56.25%] [G loss: 0.968916]\n",
      "epoch:3 step:3747 [D loss: 0.524193, acc.: 78.12%] [G loss: 1.134676]\n",
      "epoch:3 step:3748 [D loss: 0.533759, acc.: 78.12%] [G loss: 1.040572]\n",
      "epoch:4 step:3749 [D loss: 0.656547, acc.: 64.06%] [G loss: 1.078162]\n",
      "epoch:4 step:3750 [D loss: 0.699083, acc.: 57.03%] [G loss: 1.062331]\n",
      "epoch:4 step:3751 [D loss: 0.648679, acc.: 66.41%] [G loss: 1.028532]\n",
      "epoch:4 step:3752 [D loss: 0.667096, acc.: 64.06%] [G loss: 0.988456]\n",
      "epoch:4 step:3753 [D loss: 0.568631, acc.: 68.75%] [G loss: 1.086418]\n",
      "epoch:4 step:3754 [D loss: 0.694191, acc.: 57.03%] [G loss: 0.971419]\n",
      "epoch:4 step:3755 [D loss: 0.586008, acc.: 69.53%] [G loss: 0.950773]\n",
      "epoch:4 step:3756 [D loss: 0.660340, acc.: 57.81%] [G loss: 1.069075]\n",
      "epoch:4 step:3757 [D loss: 0.657121, acc.: 63.28%] [G loss: 1.027761]\n",
      "epoch:4 step:3758 [D loss: 0.628849, acc.: 68.75%] [G loss: 1.077755]\n",
      "epoch:4 step:3759 [D loss: 0.605215, acc.: 68.75%] [G loss: 1.150914]\n",
      "epoch:4 step:3760 [D loss: 0.651211, acc.: 61.72%] [G loss: 0.954402]\n",
      "epoch:4 step:3761 [D loss: 0.651162, acc.: 61.72%] [G loss: 1.014773]\n",
      "epoch:4 step:3762 [D loss: 0.614636, acc.: 65.62%] [G loss: 0.851682]\n",
      "epoch:4 step:3763 [D loss: 0.602273, acc.: 66.41%] [G loss: 1.041070]\n",
      "epoch:4 step:3764 [D loss: 0.644535, acc.: 67.19%] [G loss: 0.983609]\n",
      "epoch:4 step:3765 [D loss: 0.728837, acc.: 52.34%] [G loss: 1.029563]\n",
      "epoch:4 step:3766 [D loss: 0.690187, acc.: 53.12%] [G loss: 1.027060]\n",
      "epoch:4 step:3767 [D loss: 0.665993, acc.: 59.38%] [G loss: 0.988677]\n",
      "epoch:4 step:3768 [D loss: 0.833395, acc.: 39.06%] [G loss: 0.983882]\n",
      "epoch:4 step:3769 [D loss: 0.698068, acc.: 58.59%] [G loss: 0.824039]\n",
      "epoch:4 step:3770 [D loss: 0.762128, acc.: 50.00%] [G loss: 0.877090]\n",
      "epoch:4 step:3771 [D loss: 0.612225, acc.: 67.97%] [G loss: 0.972538]\n",
      "epoch:4 step:3772 [D loss: 0.619332, acc.: 69.53%] [G loss: 1.100085]\n",
      "epoch:4 step:3773 [D loss: 0.650592, acc.: 56.25%] [G loss: 0.930181]\n",
      "epoch:4 step:3774 [D loss: 0.658311, acc.: 57.81%] [G loss: 0.953284]\n",
      "epoch:4 step:3775 [D loss: 0.648852, acc.: 57.03%] [G loss: 0.995955]\n",
      "epoch:4 step:3776 [D loss: 0.621830, acc.: 65.62%] [G loss: 0.900019]\n",
      "epoch:4 step:3777 [D loss: 0.617313, acc.: 62.50%] [G loss: 1.088655]\n",
      "epoch:4 step:3778 [D loss: 0.679658, acc.: 60.16%] [G loss: 1.061643]\n",
      "epoch:4 step:3779 [D loss: 0.752069, acc.: 49.22%] [G loss: 0.993304]\n",
      "epoch:4 step:3780 [D loss: 0.700905, acc.: 53.12%] [G loss: 0.911902]\n",
      "epoch:4 step:3781 [D loss: 0.626194, acc.: 65.62%] [G loss: 0.974986]\n",
      "epoch:4 step:3782 [D loss: 0.605044, acc.: 68.75%] [G loss: 1.044019]\n",
      "epoch:4 step:3783 [D loss: 0.631853, acc.: 67.19%] [G loss: 1.029994]\n",
      "epoch:4 step:3784 [D loss: 0.607449, acc.: 71.88%] [G loss: 1.028630]\n",
      "epoch:4 step:3785 [D loss: 0.647321, acc.: 66.41%] [G loss: 1.020896]\n",
      "epoch:4 step:3786 [D loss: 0.612859, acc.: 67.97%] [G loss: 0.940539]\n",
      "epoch:4 step:3787 [D loss: 0.641494, acc.: 61.72%] [G loss: 1.069157]\n",
      "epoch:4 step:3788 [D loss: 0.657115, acc.: 61.72%] [G loss: 0.987649]\n",
      "epoch:4 step:3789 [D loss: 0.644063, acc.: 64.06%] [G loss: 0.974183]\n",
      "epoch:4 step:3790 [D loss: 0.614082, acc.: 67.97%] [G loss: 1.018344]\n",
      "epoch:4 step:3791 [D loss: 0.631623, acc.: 64.06%] [G loss: 0.959254]\n",
      "epoch:4 step:3792 [D loss: 0.742395, acc.: 59.38%] [G loss: 0.944627]\n",
      "epoch:4 step:3793 [D loss: 0.725302, acc.: 55.47%] [G loss: 0.867082]\n",
      "epoch:4 step:3794 [D loss: 0.700341, acc.: 57.81%] [G loss: 0.954842]\n",
      "epoch:4 step:3795 [D loss: 0.605784, acc.: 67.19%] [G loss: 1.084362]\n",
      "epoch:4 step:3796 [D loss: 0.705955, acc.: 58.59%] [G loss: 0.920076]\n",
      "epoch:4 step:3797 [D loss: 0.578225, acc.: 71.88%] [G loss: 1.087334]\n",
      "epoch:4 step:3798 [D loss: 0.572182, acc.: 75.78%] [G loss: 1.020787]\n",
      "epoch:4 step:3799 [D loss: 0.633850, acc.: 65.62%] [G loss: 0.971329]\n",
      "epoch:4 step:3800 [D loss: 0.630299, acc.: 67.97%] [G loss: 0.989613]\n",
      "epoch:4 step:3801 [D loss: 0.686617, acc.: 53.91%] [G loss: 0.937409]\n",
      "epoch:4 step:3802 [D loss: 0.666862, acc.: 59.38%] [G loss: 1.025272]\n",
      "epoch:4 step:3803 [D loss: 0.669491, acc.: 57.03%] [G loss: 0.956419]\n",
      "epoch:4 step:3804 [D loss: 0.690998, acc.: 62.50%] [G loss: 0.951218]\n",
      "epoch:4 step:3805 [D loss: 0.720174, acc.: 51.56%] [G loss: 0.968273]\n",
      "epoch:4 step:3806 [D loss: 0.677721, acc.: 56.25%] [G loss: 0.935705]\n",
      "epoch:4 step:3807 [D loss: 0.686924, acc.: 53.91%] [G loss: 0.937615]\n",
      "epoch:4 step:3808 [D loss: 0.703647, acc.: 53.91%] [G loss: 0.962435]\n",
      "epoch:4 step:3809 [D loss: 0.670058, acc.: 56.25%] [G loss: 0.831059]\n",
      "epoch:4 step:3810 [D loss: 0.716376, acc.: 50.00%] [G loss: 0.925899]\n",
      "epoch:4 step:3811 [D loss: 0.673207, acc.: 62.50%] [G loss: 0.932848]\n",
      "epoch:4 step:3812 [D loss: 0.661556, acc.: 60.94%] [G loss: 0.841153]\n",
      "epoch:4 step:3813 [D loss: 0.654584, acc.: 57.03%] [G loss: 1.044032]\n",
      "epoch:4 step:3814 [D loss: 0.671507, acc.: 56.25%] [G loss: 0.977364]\n",
      "epoch:4 step:3815 [D loss: 0.664130, acc.: 58.59%] [G loss: 0.948997]\n",
      "epoch:4 step:3816 [D loss: 0.662667, acc.: 67.19%] [G loss: 0.941580]\n",
      "epoch:4 step:3817 [D loss: 0.595414, acc.: 71.88%] [G loss: 0.994863]\n",
      "epoch:4 step:3818 [D loss: 0.575871, acc.: 70.31%] [G loss: 0.958536]\n",
      "epoch:4 step:3819 [D loss: 0.680313, acc.: 57.03%] [G loss: 0.987830]\n",
      "epoch:4 step:3820 [D loss: 0.663464, acc.: 62.50%] [G loss: 0.904599]\n",
      "epoch:4 step:3821 [D loss: 0.647345, acc.: 65.62%] [G loss: 1.018183]\n",
      "epoch:4 step:3822 [D loss: 0.660841, acc.: 61.72%] [G loss: 0.940226]\n",
      "epoch:4 step:3823 [D loss: 0.594216, acc.: 71.09%] [G loss: 1.014390]\n",
      "epoch:4 step:3824 [D loss: 0.634413, acc.: 57.03%] [G loss: 0.968277]\n",
      "epoch:4 step:3825 [D loss: 0.607050, acc.: 64.06%] [G loss: 1.004356]\n",
      "epoch:4 step:3826 [D loss: 0.639747, acc.: 67.97%] [G loss: 1.019838]\n",
      "epoch:4 step:3827 [D loss: 0.748302, acc.: 49.22%] [G loss: 0.896540]\n",
      "epoch:4 step:3828 [D loss: 0.699057, acc.: 53.12%] [G loss: 1.037886]\n",
      "epoch:4 step:3829 [D loss: 0.731097, acc.: 52.34%] [G loss: 0.945184]\n",
      "epoch:4 step:3830 [D loss: 0.652272, acc.: 61.72%] [G loss: 1.012552]\n",
      "epoch:4 step:3831 [D loss: 0.671992, acc.: 61.72%] [G loss: 0.908237]\n",
      "epoch:4 step:3832 [D loss: 0.665734, acc.: 60.16%] [G loss: 1.074629]\n",
      "epoch:4 step:3833 [D loss: 0.668717, acc.: 63.28%] [G loss: 0.915174]\n",
      "epoch:4 step:3834 [D loss: 0.625966, acc.: 62.50%] [G loss: 1.049927]\n",
      "epoch:4 step:3835 [D loss: 0.686032, acc.: 61.72%] [G loss: 0.985469]\n",
      "epoch:4 step:3836 [D loss: 0.675313, acc.: 53.12%] [G loss: 0.923700]\n",
      "epoch:4 step:3837 [D loss: 0.643143, acc.: 66.41%] [G loss: 0.893304]\n",
      "epoch:4 step:3838 [D loss: 0.640037, acc.: 65.62%] [G loss: 0.965570]\n",
      "epoch:4 step:3839 [D loss: 0.682401, acc.: 59.38%] [G loss: 0.927668]\n",
      "epoch:4 step:3840 [D loss: 0.668315, acc.: 56.25%] [G loss: 0.883189]\n",
      "epoch:4 step:3841 [D loss: 0.729792, acc.: 51.56%] [G loss: 1.005470]\n",
      "epoch:4 step:3842 [D loss: 0.695226, acc.: 55.47%] [G loss: 0.906610]\n",
      "epoch:4 step:3843 [D loss: 0.673983, acc.: 55.47%] [G loss: 0.996700]\n",
      "epoch:4 step:3844 [D loss: 0.630577, acc.: 68.75%] [G loss: 1.073549]\n",
      "epoch:4 step:3845 [D loss: 0.708851, acc.: 56.25%] [G loss: 0.928916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3846 [D loss: 0.639430, acc.: 64.84%] [G loss: 0.947051]\n",
      "epoch:4 step:3847 [D loss: 0.654739, acc.: 62.50%] [G loss: 0.943618]\n",
      "epoch:4 step:3848 [D loss: 0.686374, acc.: 57.03%] [G loss: 0.901953]\n",
      "epoch:4 step:3849 [D loss: 0.712270, acc.: 55.47%] [G loss: 0.961449]\n",
      "epoch:4 step:3850 [D loss: 0.603063, acc.: 66.41%] [G loss: 1.080204]\n",
      "epoch:4 step:3851 [D loss: 0.617737, acc.: 69.53%] [G loss: 0.874449]\n",
      "epoch:4 step:3852 [D loss: 0.723659, acc.: 49.22%] [G loss: 0.995782]\n",
      "epoch:4 step:3853 [D loss: 0.688102, acc.: 57.81%] [G loss: 0.940183]\n",
      "epoch:4 step:3854 [D loss: 0.628833, acc.: 70.31%] [G loss: 1.054864]\n",
      "epoch:4 step:3855 [D loss: 0.710629, acc.: 57.03%] [G loss: 0.963652]\n",
      "epoch:4 step:3856 [D loss: 0.687696, acc.: 59.38%] [G loss: 0.961919]\n",
      "epoch:4 step:3857 [D loss: 0.676478, acc.: 60.16%] [G loss: 0.987947]\n",
      "epoch:4 step:3858 [D loss: 0.751035, acc.: 48.44%] [G loss: 0.864423]\n",
      "epoch:4 step:3859 [D loss: 0.722410, acc.: 53.12%] [G loss: 0.887044]\n",
      "epoch:4 step:3860 [D loss: 0.633488, acc.: 59.38%] [G loss: 1.091283]\n",
      "epoch:4 step:3861 [D loss: 0.638304, acc.: 59.38%] [G loss: 0.840245]\n",
      "epoch:4 step:3862 [D loss: 0.679532, acc.: 58.59%] [G loss: 0.873977]\n",
      "epoch:4 step:3863 [D loss: 0.710988, acc.: 56.25%] [G loss: 0.821035]\n",
      "epoch:4 step:3864 [D loss: 0.649454, acc.: 60.94%] [G loss: 1.086834]\n",
      "epoch:4 step:3865 [D loss: 0.609241, acc.: 68.75%] [G loss: 1.080531]\n",
      "epoch:4 step:3866 [D loss: 0.667993, acc.: 63.28%] [G loss: 1.124879]\n",
      "epoch:4 step:3867 [D loss: 0.676361, acc.: 56.25%] [G loss: 1.047782]\n",
      "epoch:4 step:3868 [D loss: 0.693936, acc.: 55.47%] [G loss: 0.996804]\n",
      "epoch:4 step:3869 [D loss: 0.730147, acc.: 54.69%] [G loss: 0.978633]\n",
      "epoch:4 step:3870 [D loss: 0.706439, acc.: 54.69%] [G loss: 0.916521]\n",
      "epoch:4 step:3871 [D loss: 0.659830, acc.: 53.91%] [G loss: 0.886008]\n",
      "epoch:4 step:3872 [D loss: 0.685273, acc.: 56.25%] [G loss: 0.866060]\n",
      "epoch:4 step:3873 [D loss: 0.597387, acc.: 70.31%] [G loss: 1.062786]\n",
      "epoch:4 step:3874 [D loss: 0.674852, acc.: 63.28%] [G loss: 0.886202]\n",
      "epoch:4 step:3875 [D loss: 0.616763, acc.: 69.53%] [G loss: 1.068036]\n",
      "epoch:4 step:3876 [D loss: 0.635485, acc.: 62.50%] [G loss: 1.087924]\n",
      "epoch:4 step:3877 [D loss: 0.684020, acc.: 57.81%] [G loss: 1.013154]\n",
      "epoch:4 step:3878 [D loss: 0.700848, acc.: 57.03%] [G loss: 0.892937]\n",
      "epoch:4 step:3879 [D loss: 0.723234, acc.: 56.25%] [G loss: 0.946517]\n",
      "epoch:4 step:3880 [D loss: 0.635342, acc.: 60.94%] [G loss: 1.038951]\n",
      "epoch:4 step:3881 [D loss: 0.725005, acc.: 51.56%] [G loss: 0.996395]\n",
      "epoch:4 step:3882 [D loss: 0.689790, acc.: 60.16%] [G loss: 0.922834]\n",
      "epoch:4 step:3883 [D loss: 0.705418, acc.: 55.47%] [G loss: 0.969798]\n",
      "epoch:4 step:3884 [D loss: 0.701680, acc.: 57.03%] [G loss: 0.908641]\n",
      "epoch:4 step:3885 [D loss: 0.708450, acc.: 57.03%] [G loss: 0.983938]\n",
      "epoch:4 step:3886 [D loss: 0.701539, acc.: 53.91%] [G loss: 0.853301]\n",
      "epoch:4 step:3887 [D loss: 0.666736, acc.: 61.72%] [G loss: 0.916074]\n",
      "epoch:4 step:3888 [D loss: 0.648453, acc.: 64.06%] [G loss: 1.023618]\n",
      "epoch:4 step:3889 [D loss: 0.698082, acc.: 51.56%] [G loss: 0.995634]\n",
      "epoch:4 step:3890 [D loss: 0.662473, acc.: 58.59%] [G loss: 1.048698]\n",
      "epoch:4 step:3891 [D loss: 0.628608, acc.: 64.06%] [G loss: 1.049272]\n",
      "epoch:4 step:3892 [D loss: 0.673821, acc.: 53.91%] [G loss: 0.903079]\n",
      "epoch:4 step:3893 [D loss: 0.603243, acc.: 65.62%] [G loss: 0.923044]\n",
      "epoch:4 step:3894 [D loss: 0.664711, acc.: 61.72%] [G loss: 0.940020]\n",
      "epoch:4 step:3895 [D loss: 0.631142, acc.: 70.31%] [G loss: 0.973231]\n",
      "epoch:4 step:3896 [D loss: 0.746578, acc.: 51.56%] [G loss: 0.901139]\n",
      "epoch:4 step:3897 [D loss: 0.688548, acc.: 55.47%] [G loss: 1.029996]\n",
      "epoch:4 step:3898 [D loss: 0.614924, acc.: 65.62%] [G loss: 0.970605]\n",
      "epoch:4 step:3899 [D loss: 0.646307, acc.: 61.72%] [G loss: 0.990657]\n",
      "epoch:4 step:3900 [D loss: 0.636021, acc.: 64.06%] [G loss: 1.033635]\n",
      "epoch:4 step:3901 [D loss: 0.619014, acc.: 63.28%] [G loss: 0.969887]\n",
      "epoch:4 step:3902 [D loss: 0.706101, acc.: 55.47%] [G loss: 1.106435]\n",
      "epoch:4 step:3903 [D loss: 0.663596, acc.: 61.72%] [G loss: 1.012062]\n",
      "epoch:4 step:3904 [D loss: 0.596490, acc.: 71.88%] [G loss: 1.056192]\n",
      "epoch:4 step:3905 [D loss: 0.639964, acc.: 60.94%] [G loss: 1.007142]\n",
      "epoch:4 step:3906 [D loss: 0.745358, acc.: 51.56%] [G loss: 0.957628]\n",
      "epoch:4 step:3907 [D loss: 0.706836, acc.: 54.69%] [G loss: 0.977829]\n",
      "epoch:4 step:3908 [D loss: 0.754558, acc.: 53.91%] [G loss: 0.857295]\n",
      "epoch:4 step:3909 [D loss: 0.772671, acc.: 42.19%] [G loss: 0.927544]\n",
      "epoch:4 step:3910 [D loss: 0.599072, acc.: 66.41%] [G loss: 0.999558]\n",
      "epoch:4 step:3911 [D loss: 0.616551, acc.: 67.19%] [G loss: 1.074819]\n",
      "epoch:4 step:3912 [D loss: 0.687159, acc.: 55.47%] [G loss: 0.922841]\n",
      "epoch:4 step:3913 [D loss: 0.636478, acc.: 58.59%] [G loss: 0.958627]\n",
      "epoch:4 step:3914 [D loss: 0.651579, acc.: 62.50%] [G loss: 0.945608]\n",
      "epoch:4 step:3915 [D loss: 0.689502, acc.: 57.81%] [G loss: 0.985385]\n",
      "epoch:4 step:3916 [D loss: 0.633564, acc.: 64.06%] [G loss: 1.067422]\n",
      "epoch:4 step:3917 [D loss: 0.657410, acc.: 62.50%] [G loss: 0.924637]\n",
      "epoch:4 step:3918 [D loss: 0.738304, acc.: 51.56%] [G loss: 1.029141]\n",
      "epoch:4 step:3919 [D loss: 0.593685, acc.: 69.53%] [G loss: 1.039044]\n",
      "epoch:4 step:3920 [D loss: 0.654326, acc.: 62.50%] [G loss: 1.018271]\n",
      "epoch:4 step:3921 [D loss: 0.597497, acc.: 68.75%] [G loss: 0.866351]\n",
      "epoch:4 step:3922 [D loss: 0.709636, acc.: 53.91%] [G loss: 0.887621]\n",
      "epoch:4 step:3923 [D loss: 0.641523, acc.: 67.19%] [G loss: 0.896291]\n",
      "epoch:4 step:3924 [D loss: 0.653437, acc.: 63.28%] [G loss: 0.963020]\n",
      "epoch:4 step:3925 [D loss: 0.660953, acc.: 64.84%] [G loss: 0.933404]\n",
      "epoch:4 step:3926 [D loss: 0.654561, acc.: 58.59%] [G loss: 0.997236]\n",
      "epoch:4 step:3927 [D loss: 0.707247, acc.: 54.69%] [G loss: 0.923555]\n",
      "epoch:4 step:3928 [D loss: 0.690553, acc.: 55.47%] [G loss: 0.937149]\n",
      "epoch:4 step:3929 [D loss: 0.605614, acc.: 64.84%] [G loss: 0.909959]\n",
      "epoch:4 step:3930 [D loss: 0.752657, acc.: 49.22%] [G loss: 0.930319]\n",
      "epoch:4 step:3931 [D loss: 0.724592, acc.: 57.03%] [G loss: 0.863323]\n",
      "epoch:4 step:3932 [D loss: 0.588102, acc.: 67.97%] [G loss: 1.045096]\n",
      "epoch:4 step:3933 [D loss: 0.661949, acc.: 60.94%] [G loss: 0.879392]\n",
      "epoch:4 step:3934 [D loss: 0.659058, acc.: 57.03%] [G loss: 0.959370]\n",
      "epoch:4 step:3935 [D loss: 0.657323, acc.: 60.16%] [G loss: 0.862553]\n",
      "epoch:4 step:3936 [D loss: 0.636633, acc.: 67.97%] [G loss: 0.934890]\n",
      "epoch:4 step:3937 [D loss: 0.724275, acc.: 53.12%] [G loss: 0.952871]\n",
      "epoch:4 step:3938 [D loss: 0.585492, acc.: 73.44%] [G loss: 0.958563]\n",
      "epoch:4 step:3939 [D loss: 0.666201, acc.: 57.03%] [G loss: 0.908035]\n",
      "epoch:4 step:3940 [D loss: 0.730329, acc.: 45.31%] [G loss: 0.934063]\n",
      "epoch:4 step:3941 [D loss: 0.601358, acc.: 67.19%] [G loss: 1.083777]\n",
      "epoch:4 step:3942 [D loss: 0.645644, acc.: 60.16%] [G loss: 1.003159]\n",
      "epoch:4 step:3943 [D loss: 0.672724, acc.: 60.16%] [G loss: 1.125701]\n",
      "epoch:4 step:3944 [D loss: 0.657774, acc.: 60.94%] [G loss: 1.033151]\n",
      "epoch:4 step:3945 [D loss: 0.600852, acc.: 71.09%] [G loss: 0.902034]\n",
      "epoch:4 step:3946 [D loss: 0.677563, acc.: 61.72%] [G loss: 0.977686]\n",
      "epoch:4 step:3947 [D loss: 0.642290, acc.: 59.38%] [G loss: 0.956393]\n",
      "epoch:4 step:3948 [D loss: 0.737229, acc.: 57.81%] [G loss: 0.961835]\n",
      "epoch:4 step:3949 [D loss: 0.700697, acc.: 53.91%] [G loss: 1.009289]\n",
      "epoch:4 step:3950 [D loss: 0.678534, acc.: 58.59%] [G loss: 0.952707]\n",
      "epoch:4 step:3951 [D loss: 0.714759, acc.: 51.56%] [G loss: 0.964154]\n",
      "epoch:4 step:3952 [D loss: 0.636992, acc.: 64.06%] [G loss: 0.859402]\n",
      "epoch:4 step:3953 [D loss: 0.737165, acc.: 48.44%] [G loss: 0.838393]\n",
      "epoch:4 step:3954 [D loss: 0.572471, acc.: 70.31%] [G loss: 1.090848]\n",
      "epoch:4 step:3955 [D loss: 0.622410, acc.: 66.41%] [G loss: 0.907804]\n",
      "epoch:4 step:3956 [D loss: 0.572852, acc.: 69.53%] [G loss: 1.010630]\n",
      "epoch:4 step:3957 [D loss: 0.665597, acc.: 62.50%] [G loss: 0.875481]\n",
      "epoch:4 step:3958 [D loss: 0.730538, acc.: 52.34%] [G loss: 0.908638]\n",
      "epoch:4 step:3959 [D loss: 0.655411, acc.: 62.50%] [G loss: 1.052124]\n",
      "epoch:4 step:3960 [D loss: 0.758482, acc.: 48.44%] [G loss: 0.905793]\n",
      "epoch:4 step:3961 [D loss: 0.708093, acc.: 56.25%] [G loss: 0.793087]\n",
      "epoch:4 step:3962 [D loss: 0.709182, acc.: 60.94%] [G loss: 0.851070]\n",
      "epoch:4 step:3963 [D loss: 0.691395, acc.: 49.22%] [G loss: 0.946546]\n",
      "epoch:4 step:3964 [D loss: 0.672301, acc.: 58.59%] [G loss: 0.863672]\n",
      "epoch:4 step:3965 [D loss: 0.654598, acc.: 60.94%] [G loss: 0.929286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3966 [D loss: 0.656340, acc.: 60.94%] [G loss: 0.888959]\n",
      "epoch:4 step:3967 [D loss: 0.669661, acc.: 60.16%] [G loss: 1.111345]\n",
      "epoch:4 step:3968 [D loss: 0.795094, acc.: 46.88%] [G loss: 0.933242]\n",
      "epoch:4 step:3969 [D loss: 0.653089, acc.: 61.72%] [G loss: 0.933015]\n",
      "epoch:4 step:3970 [D loss: 0.637318, acc.: 59.38%] [G loss: 0.920484]\n",
      "epoch:4 step:3971 [D loss: 0.710751, acc.: 56.25%] [G loss: 0.999020]\n",
      "epoch:4 step:3972 [D loss: 0.666126, acc.: 55.47%] [G loss: 0.966484]\n",
      "epoch:4 step:3973 [D loss: 0.753993, acc.: 51.56%] [G loss: 0.938274]\n",
      "epoch:4 step:3974 [D loss: 0.678111, acc.: 60.94%] [G loss: 0.908538]\n",
      "epoch:4 step:3975 [D loss: 0.680969, acc.: 55.47%] [G loss: 0.902950]\n",
      "epoch:4 step:3976 [D loss: 0.737075, acc.: 50.00%] [G loss: 0.796742]\n",
      "epoch:4 step:3977 [D loss: 0.598400, acc.: 70.31%] [G loss: 1.021020]\n",
      "epoch:4 step:3978 [D loss: 0.564722, acc.: 72.66%] [G loss: 0.978028]\n",
      "epoch:4 step:3979 [D loss: 0.618857, acc.: 69.53%] [G loss: 1.052791]\n",
      "epoch:4 step:3980 [D loss: 0.535844, acc.: 74.22%] [G loss: 1.142564]\n",
      "epoch:4 step:3981 [D loss: 0.674135, acc.: 63.28%] [G loss: 1.056706]\n",
      "epoch:4 step:3982 [D loss: 0.718048, acc.: 57.81%] [G loss: 0.906638]\n",
      "epoch:4 step:3983 [D loss: 0.720133, acc.: 60.16%] [G loss: 0.942866]\n",
      "epoch:4 step:3984 [D loss: 0.615418, acc.: 64.84%] [G loss: 0.972254]\n",
      "epoch:4 step:3985 [D loss: 0.638790, acc.: 64.84%] [G loss: 1.002589]\n",
      "epoch:4 step:3986 [D loss: 0.637458, acc.: 60.94%] [G loss: 1.057075]\n",
      "epoch:4 step:3987 [D loss: 0.707591, acc.: 49.22%] [G loss: 0.937254]\n",
      "epoch:4 step:3988 [D loss: 0.570312, acc.: 72.66%] [G loss: 1.053713]\n",
      "epoch:4 step:3989 [D loss: 0.601936, acc.: 67.19%] [G loss: 1.056305]\n",
      "epoch:4 step:3990 [D loss: 0.614818, acc.: 61.72%] [G loss: 1.064977]\n",
      "epoch:4 step:3991 [D loss: 0.702587, acc.: 60.94%] [G loss: 0.842510]\n",
      "epoch:4 step:3992 [D loss: 0.590662, acc.: 72.66%] [G loss: 0.906260]\n",
      "epoch:4 step:3993 [D loss: 0.635142, acc.: 65.62%] [G loss: 0.937277]\n",
      "epoch:4 step:3994 [D loss: 0.736513, acc.: 53.91%] [G loss: 0.871872]\n",
      "epoch:4 step:3995 [D loss: 0.707344, acc.: 60.94%] [G loss: 0.940168]\n",
      "epoch:4 step:3996 [D loss: 0.602956, acc.: 71.88%] [G loss: 1.095101]\n",
      "epoch:4 step:3997 [D loss: 0.668956, acc.: 63.28%] [G loss: 1.055567]\n",
      "epoch:4 step:3998 [D loss: 0.729721, acc.: 51.56%] [G loss: 0.916442]\n",
      "epoch:4 step:3999 [D loss: 0.666743, acc.: 59.38%] [G loss: 0.986876]\n",
      "epoch:4 step:4000 [D loss: 0.717994, acc.: 52.34%] [G loss: 0.896429]\n",
      "epoch:4 step:4001 [D loss: 0.671195, acc.: 55.47%] [G loss: 0.870108]\n",
      "epoch:4 step:4002 [D loss: 0.618167, acc.: 62.50%] [G loss: 0.956927]\n",
      "epoch:4 step:4003 [D loss: 0.675923, acc.: 60.16%] [G loss: 1.023078]\n",
      "epoch:4 step:4004 [D loss: 0.638361, acc.: 61.72%] [G loss: 0.857027]\n",
      "epoch:4 step:4005 [D loss: 0.671661, acc.: 57.81%] [G loss: 1.005512]\n",
      "epoch:4 step:4006 [D loss: 0.635071, acc.: 60.94%] [G loss: 1.012392]\n",
      "epoch:4 step:4007 [D loss: 0.615133, acc.: 64.84%] [G loss: 0.998476]\n",
      "epoch:4 step:4008 [D loss: 0.671557, acc.: 60.16%] [G loss: 1.024941]\n",
      "epoch:4 step:4009 [D loss: 0.682017, acc.: 62.50%] [G loss: 0.913215]\n",
      "epoch:4 step:4010 [D loss: 0.556693, acc.: 71.88%] [G loss: 1.078414]\n",
      "epoch:4 step:4011 [D loss: 0.672894, acc.: 60.16%] [G loss: 1.025584]\n",
      "epoch:4 step:4012 [D loss: 0.612572, acc.: 64.06%] [G loss: 0.985501]\n",
      "epoch:4 step:4013 [D loss: 0.678224, acc.: 60.16%] [G loss: 0.956649]\n",
      "epoch:4 step:4014 [D loss: 0.741850, acc.: 51.56%] [G loss: 0.850558]\n",
      "epoch:4 step:4015 [D loss: 0.619375, acc.: 61.72%] [G loss: 0.963206]\n",
      "epoch:4 step:4016 [D loss: 0.723973, acc.: 56.25%] [G loss: 0.977699]\n",
      "epoch:4 step:4017 [D loss: 0.681316, acc.: 52.34%] [G loss: 0.940259]\n",
      "epoch:4 step:4018 [D loss: 0.640890, acc.: 61.72%] [G loss: 1.021087]\n",
      "epoch:4 step:4019 [D loss: 0.641846, acc.: 63.28%] [G loss: 0.986333]\n",
      "epoch:4 step:4020 [D loss: 0.680306, acc.: 56.25%] [G loss: 1.038855]\n",
      "epoch:4 step:4021 [D loss: 0.589233, acc.: 68.75%] [G loss: 0.990928]\n",
      "epoch:4 step:4022 [D loss: 0.673375, acc.: 57.81%] [G loss: 1.025392]\n",
      "epoch:4 step:4023 [D loss: 0.689317, acc.: 54.69%] [G loss: 0.982171]\n",
      "epoch:4 step:4024 [D loss: 0.658619, acc.: 57.81%] [G loss: 1.070362]\n",
      "epoch:4 step:4025 [D loss: 0.662980, acc.: 60.94%] [G loss: 0.942628]\n",
      "epoch:4 step:4026 [D loss: 0.743344, acc.: 45.31%] [G loss: 0.899614]\n",
      "epoch:4 step:4027 [D loss: 0.750751, acc.: 44.53%] [G loss: 0.965192]\n",
      "epoch:4 step:4028 [D loss: 0.644524, acc.: 64.06%] [G loss: 1.003738]\n",
      "epoch:4 step:4029 [D loss: 0.712438, acc.: 58.59%] [G loss: 0.872107]\n",
      "epoch:4 step:4030 [D loss: 0.706645, acc.: 58.59%] [G loss: 0.996459]\n",
      "epoch:4 step:4031 [D loss: 0.639844, acc.: 59.38%] [G loss: 0.889625]\n",
      "epoch:4 step:4032 [D loss: 0.612946, acc.: 68.75%] [G loss: 1.058174]\n",
      "epoch:4 step:4033 [D loss: 0.668371, acc.: 53.91%] [G loss: 0.925495]\n",
      "epoch:4 step:4034 [D loss: 0.596183, acc.: 71.09%] [G loss: 1.040270]\n",
      "epoch:4 step:4035 [D loss: 0.707500, acc.: 56.25%] [G loss: 0.957565]\n",
      "epoch:4 step:4036 [D loss: 0.724837, acc.: 57.81%] [G loss: 0.952769]\n",
      "epoch:4 step:4037 [D loss: 0.661125, acc.: 60.16%] [G loss: 0.996249]\n",
      "epoch:4 step:4038 [D loss: 0.670041, acc.: 57.81%] [G loss: 0.973407]\n",
      "epoch:4 step:4039 [D loss: 0.707465, acc.: 53.12%] [G loss: 0.984605]\n",
      "epoch:4 step:4040 [D loss: 0.658080, acc.: 60.16%] [G loss: 0.937724]\n",
      "epoch:4 step:4041 [D loss: 0.636994, acc.: 64.06%] [G loss: 1.026794]\n",
      "epoch:4 step:4042 [D loss: 0.606529, acc.: 67.19%] [G loss: 1.021229]\n",
      "epoch:4 step:4043 [D loss: 0.655977, acc.: 64.84%] [G loss: 0.980867]\n",
      "epoch:4 step:4044 [D loss: 0.656643, acc.: 60.16%] [G loss: 0.905238]\n",
      "epoch:4 step:4045 [D loss: 0.673277, acc.: 59.38%] [G loss: 0.949458]\n",
      "epoch:4 step:4046 [D loss: 0.655953, acc.: 60.16%] [G loss: 0.869671]\n",
      "epoch:4 step:4047 [D loss: 0.622473, acc.: 68.75%] [G loss: 1.121042]\n",
      "epoch:4 step:4048 [D loss: 0.660368, acc.: 61.72%] [G loss: 1.062440]\n",
      "epoch:4 step:4049 [D loss: 0.670799, acc.: 61.72%] [G loss: 1.043708]\n",
      "epoch:4 step:4050 [D loss: 0.578239, acc.: 67.97%] [G loss: 0.984940]\n",
      "epoch:4 step:4051 [D loss: 0.647765, acc.: 64.84%] [G loss: 0.911013]\n",
      "epoch:4 step:4052 [D loss: 0.645793, acc.: 60.94%] [G loss: 0.905911]\n",
      "epoch:4 step:4053 [D loss: 0.598305, acc.: 71.88%] [G loss: 1.087256]\n",
      "epoch:4 step:4054 [D loss: 0.627432, acc.: 64.06%] [G loss: 1.032828]\n",
      "epoch:4 step:4055 [D loss: 0.567770, acc.: 74.22%] [G loss: 1.098231]\n",
      "epoch:4 step:4056 [D loss: 0.675091, acc.: 58.59%] [G loss: 1.026222]\n",
      "epoch:4 step:4057 [D loss: 0.637100, acc.: 62.50%] [G loss: 0.943298]\n",
      "epoch:4 step:4058 [D loss: 0.618852, acc.: 65.62%] [G loss: 0.960321]\n",
      "epoch:4 step:4059 [D loss: 0.580772, acc.: 67.97%] [G loss: 1.066408]\n",
      "epoch:4 step:4060 [D loss: 0.668477, acc.: 63.28%] [G loss: 1.025949]\n",
      "epoch:4 step:4061 [D loss: 0.552269, acc.: 76.56%] [G loss: 1.137034]\n",
      "epoch:4 step:4062 [D loss: 0.586530, acc.: 70.31%] [G loss: 1.155200]\n",
      "epoch:4 step:4063 [D loss: 0.557053, acc.: 67.97%] [G loss: 1.173370]\n",
      "epoch:4 step:4064 [D loss: 0.704247, acc.: 56.25%] [G loss: 1.195311]\n",
      "epoch:4 step:4065 [D loss: 0.740144, acc.: 50.00%] [G loss: 1.062204]\n",
      "epoch:4 step:4066 [D loss: 0.622622, acc.: 66.41%] [G loss: 0.982163]\n",
      "epoch:4 step:4067 [D loss: 0.644490, acc.: 64.84%] [G loss: 1.066099]\n",
      "epoch:4 step:4068 [D loss: 0.664962, acc.: 63.28%] [G loss: 0.990013]\n",
      "epoch:4 step:4069 [D loss: 0.619967, acc.: 67.97%] [G loss: 0.983049]\n",
      "epoch:4 step:4070 [D loss: 0.697302, acc.: 53.12%] [G loss: 0.935841]\n",
      "epoch:4 step:4071 [D loss: 0.639794, acc.: 62.50%] [G loss: 1.053456]\n",
      "epoch:4 step:4072 [D loss: 0.656567, acc.: 67.19%] [G loss: 0.891512]\n",
      "epoch:4 step:4073 [D loss: 0.680770, acc.: 57.03%] [G loss: 0.956154]\n",
      "epoch:4 step:4074 [D loss: 0.680467, acc.: 58.59%] [G loss: 1.029620]\n",
      "epoch:4 step:4075 [D loss: 0.661292, acc.: 60.94%] [G loss: 0.990103]\n",
      "epoch:4 step:4076 [D loss: 0.674356, acc.: 57.81%] [G loss: 0.865692]\n",
      "epoch:4 step:4077 [D loss: 0.676212, acc.: 61.72%] [G loss: 0.883944]\n",
      "epoch:4 step:4078 [D loss: 0.600381, acc.: 71.09%] [G loss: 0.974417]\n",
      "epoch:4 step:4079 [D loss: 0.644739, acc.: 63.28%] [G loss: 0.983167]\n",
      "epoch:4 step:4080 [D loss: 0.642678, acc.: 64.06%] [G loss: 0.904434]\n",
      "epoch:4 step:4081 [D loss: 0.574659, acc.: 72.66%] [G loss: 0.977018]\n",
      "epoch:4 step:4082 [D loss: 0.717531, acc.: 57.81%] [G loss: 0.949552]\n",
      "epoch:4 step:4083 [D loss: 0.620972, acc.: 67.97%] [G loss: 1.010956]\n",
      "epoch:4 step:4084 [D loss: 0.683512, acc.: 58.59%] [G loss: 0.975389]\n",
      "epoch:4 step:4085 [D loss: 0.623420, acc.: 72.66%] [G loss: 1.025575]\n",
      "epoch:4 step:4086 [D loss: 0.612511, acc.: 64.06%] [G loss: 0.904176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4087 [D loss: 0.673273, acc.: 57.03%] [G loss: 0.998066]\n",
      "epoch:4 step:4088 [D loss: 0.645808, acc.: 59.38%] [G loss: 0.953407]\n",
      "epoch:4 step:4089 [D loss: 0.683976, acc.: 53.91%] [G loss: 1.043945]\n",
      "epoch:4 step:4090 [D loss: 0.723631, acc.: 53.91%] [G loss: 0.952308]\n",
      "epoch:4 step:4091 [D loss: 0.606461, acc.: 69.53%] [G loss: 1.045874]\n",
      "epoch:4 step:4092 [D loss: 0.603915, acc.: 67.97%] [G loss: 0.945550]\n",
      "epoch:4 step:4093 [D loss: 0.585901, acc.: 67.97%] [G loss: 0.923292]\n",
      "epoch:4 step:4094 [D loss: 0.632628, acc.: 67.97%] [G loss: 0.980634]\n",
      "epoch:4 step:4095 [D loss: 0.653485, acc.: 59.38%] [G loss: 0.986120]\n",
      "epoch:4 step:4096 [D loss: 0.743621, acc.: 53.91%] [G loss: 1.007197]\n",
      "epoch:4 step:4097 [D loss: 0.753156, acc.: 56.25%] [G loss: 1.078299]\n",
      "epoch:4 step:4098 [D loss: 0.680143, acc.: 56.25%] [G loss: 0.966360]\n",
      "epoch:4 step:4099 [D loss: 0.707472, acc.: 57.03%] [G loss: 0.952623]\n",
      "epoch:4 step:4100 [D loss: 0.680395, acc.: 58.59%] [G loss: 0.842566]\n",
      "epoch:4 step:4101 [D loss: 0.696044, acc.: 53.12%] [G loss: 0.998134]\n",
      "epoch:4 step:4102 [D loss: 0.632092, acc.: 64.84%] [G loss: 0.942235]\n",
      "epoch:4 step:4103 [D loss: 0.662636, acc.: 55.47%] [G loss: 0.965180]\n",
      "epoch:4 step:4104 [D loss: 0.670731, acc.: 61.72%] [G loss: 0.953554]\n",
      "epoch:4 step:4105 [D loss: 0.740422, acc.: 53.91%] [G loss: 0.979756]\n",
      "epoch:4 step:4106 [D loss: 0.641154, acc.: 60.16%] [G loss: 0.993912]\n",
      "epoch:4 step:4107 [D loss: 0.612290, acc.: 72.66%] [G loss: 0.912411]\n",
      "epoch:4 step:4108 [D loss: 0.594816, acc.: 67.97%] [G loss: 0.963346]\n",
      "epoch:4 step:4109 [D loss: 0.648708, acc.: 60.94%] [G loss: 0.948366]\n",
      "epoch:4 step:4110 [D loss: 0.709323, acc.: 57.03%] [G loss: 0.962554]\n",
      "epoch:4 step:4111 [D loss: 0.628411, acc.: 63.28%] [G loss: 0.996221]\n",
      "epoch:4 step:4112 [D loss: 0.646906, acc.: 62.50%] [G loss: 0.944546]\n",
      "epoch:4 step:4113 [D loss: 0.732016, acc.: 46.88%] [G loss: 0.969685]\n",
      "epoch:4 step:4114 [D loss: 0.610666, acc.: 71.09%] [G loss: 1.069062]\n",
      "epoch:4 step:4115 [D loss: 0.705000, acc.: 56.25%] [G loss: 0.930350]\n",
      "epoch:4 step:4116 [D loss: 0.697596, acc.: 55.47%] [G loss: 0.921321]\n",
      "epoch:4 step:4117 [D loss: 0.651944, acc.: 57.81%] [G loss: 1.087344]\n",
      "epoch:4 step:4118 [D loss: 0.635316, acc.: 61.72%] [G loss: 0.993915]\n",
      "epoch:4 step:4119 [D loss: 0.694116, acc.: 53.12%] [G loss: 0.866541]\n",
      "epoch:4 step:4120 [D loss: 0.677976, acc.: 60.16%] [G loss: 0.971930]\n",
      "epoch:4 step:4121 [D loss: 0.748863, acc.: 53.12%] [G loss: 0.858625]\n",
      "epoch:4 step:4122 [D loss: 0.580374, acc.: 75.00%] [G loss: 1.048185]\n",
      "epoch:4 step:4123 [D loss: 0.609494, acc.: 70.31%] [G loss: 0.911231]\n",
      "epoch:4 step:4124 [D loss: 0.689499, acc.: 62.50%] [G loss: 0.926867]\n",
      "epoch:4 step:4125 [D loss: 0.691833, acc.: 60.16%] [G loss: 0.940630]\n",
      "epoch:4 step:4126 [D loss: 0.620977, acc.: 62.50%] [G loss: 0.941981]\n",
      "epoch:4 step:4127 [D loss: 0.600498, acc.: 73.44%] [G loss: 0.920565]\n",
      "epoch:4 step:4128 [D loss: 0.654621, acc.: 62.50%] [G loss: 0.987761]\n",
      "epoch:4 step:4129 [D loss: 0.644544, acc.: 66.41%] [G loss: 0.890378]\n",
      "epoch:4 step:4130 [D loss: 0.623591, acc.: 65.62%] [G loss: 0.978989]\n",
      "epoch:4 step:4131 [D loss: 0.645222, acc.: 60.16%] [G loss: 1.045452]\n",
      "epoch:4 step:4132 [D loss: 0.621956, acc.: 60.94%] [G loss: 0.992842]\n",
      "epoch:4 step:4133 [D loss: 0.719283, acc.: 50.78%] [G loss: 0.923288]\n",
      "epoch:4 step:4134 [D loss: 0.715432, acc.: 50.00%] [G loss: 1.004795]\n",
      "epoch:4 step:4135 [D loss: 0.673177, acc.: 58.59%] [G loss: 0.866912]\n",
      "epoch:4 step:4136 [D loss: 0.664217, acc.: 61.72%] [G loss: 1.067466]\n",
      "epoch:4 step:4137 [D loss: 0.608880, acc.: 68.75%] [G loss: 0.949026]\n",
      "epoch:4 step:4138 [D loss: 0.650403, acc.: 61.72%] [G loss: 1.031207]\n",
      "epoch:4 step:4139 [D loss: 0.702274, acc.: 53.91%] [G loss: 0.924672]\n",
      "epoch:4 step:4140 [D loss: 0.659092, acc.: 58.59%] [G loss: 0.923778]\n",
      "epoch:4 step:4141 [D loss: 0.634606, acc.: 65.62%] [G loss: 0.994164]\n",
      "epoch:4 step:4142 [D loss: 0.735043, acc.: 49.22%] [G loss: 1.008063]\n",
      "epoch:4 step:4143 [D loss: 0.678519, acc.: 60.16%] [G loss: 0.886392]\n",
      "epoch:4 step:4144 [D loss: 0.672326, acc.: 62.50%] [G loss: 1.087537]\n",
      "epoch:4 step:4145 [D loss: 0.618405, acc.: 65.62%] [G loss: 1.106267]\n",
      "epoch:4 step:4146 [D loss: 0.665763, acc.: 63.28%] [G loss: 0.894838]\n",
      "epoch:4 step:4147 [D loss: 0.660317, acc.: 58.59%] [G loss: 0.875108]\n",
      "epoch:4 step:4148 [D loss: 0.642234, acc.: 63.28%] [G loss: 0.977240]\n",
      "epoch:4 step:4149 [D loss: 0.624196, acc.: 65.62%] [G loss: 0.999966]\n",
      "epoch:4 step:4150 [D loss: 0.615213, acc.: 70.31%] [G loss: 0.996036]\n",
      "epoch:4 step:4151 [D loss: 0.592935, acc.: 70.31%] [G loss: 1.064551]\n",
      "epoch:4 step:4152 [D loss: 0.659004, acc.: 59.38%] [G loss: 1.031527]\n",
      "epoch:4 step:4153 [D loss: 0.643922, acc.: 60.94%] [G loss: 0.968372]\n",
      "epoch:4 step:4154 [D loss: 0.561490, acc.: 75.00%] [G loss: 1.046973]\n",
      "epoch:4 step:4155 [D loss: 0.720903, acc.: 51.56%] [G loss: 0.933171]\n",
      "epoch:4 step:4156 [D loss: 0.673594, acc.: 60.94%] [G loss: 1.036519]\n",
      "epoch:4 step:4157 [D loss: 0.597180, acc.: 66.41%] [G loss: 1.067506]\n",
      "epoch:4 step:4158 [D loss: 0.649211, acc.: 57.81%] [G loss: 0.979138]\n",
      "epoch:4 step:4159 [D loss: 0.694204, acc.: 55.47%] [G loss: 0.927521]\n",
      "epoch:4 step:4160 [D loss: 0.685023, acc.: 61.72%] [G loss: 0.903295]\n",
      "epoch:4 step:4161 [D loss: 0.658178, acc.: 60.16%] [G loss: 1.037923]\n",
      "epoch:4 step:4162 [D loss: 0.741314, acc.: 49.22%] [G loss: 0.976107]\n",
      "epoch:4 step:4163 [D loss: 0.638530, acc.: 66.41%] [G loss: 1.004982]\n",
      "epoch:4 step:4164 [D loss: 0.650151, acc.: 59.38%] [G loss: 0.923974]\n",
      "epoch:4 step:4165 [D loss: 0.622685, acc.: 64.06%] [G loss: 1.048587]\n",
      "epoch:4 step:4166 [D loss: 0.652873, acc.: 59.38%] [G loss: 0.924540]\n",
      "epoch:4 step:4167 [D loss: 0.644096, acc.: 58.59%] [G loss: 0.851671]\n",
      "epoch:4 step:4168 [D loss: 0.564485, acc.: 67.19%] [G loss: 1.165202]\n",
      "epoch:4 step:4169 [D loss: 0.662274, acc.: 63.28%] [G loss: 0.968791]\n",
      "epoch:4 step:4170 [D loss: 0.666440, acc.: 61.72%] [G loss: 0.988410]\n",
      "epoch:4 step:4171 [D loss: 0.719136, acc.: 57.03%] [G loss: 0.909616]\n",
      "epoch:4 step:4172 [D loss: 0.689843, acc.: 55.47%] [G loss: 0.934019]\n",
      "epoch:4 step:4173 [D loss: 0.666002, acc.: 56.25%] [G loss: 0.956486]\n",
      "epoch:4 step:4174 [D loss: 0.678512, acc.: 54.69%] [G loss: 0.892698]\n",
      "epoch:4 step:4175 [D loss: 0.584869, acc.: 69.53%] [G loss: 0.976690]\n",
      "epoch:4 step:4176 [D loss: 0.579383, acc.: 73.44%] [G loss: 1.078096]\n",
      "epoch:4 step:4177 [D loss: 0.641840, acc.: 58.59%] [G loss: 1.051269]\n",
      "epoch:4 step:4178 [D loss: 0.662455, acc.: 60.94%] [G loss: 1.053546]\n",
      "epoch:4 step:4179 [D loss: 0.660928, acc.: 58.59%] [G loss: 0.970934]\n",
      "epoch:4 step:4180 [D loss: 0.771688, acc.: 48.44%] [G loss: 0.861484]\n",
      "epoch:4 step:4181 [D loss: 0.667555, acc.: 60.16%] [G loss: 1.068395]\n",
      "epoch:4 step:4182 [D loss: 0.634404, acc.: 66.41%] [G loss: 1.003514]\n",
      "epoch:4 step:4183 [D loss: 0.727089, acc.: 55.47%] [G loss: 0.867758]\n",
      "epoch:4 step:4184 [D loss: 0.618866, acc.: 64.84%] [G loss: 0.955489]\n",
      "epoch:4 step:4185 [D loss: 0.722317, acc.: 53.91%] [G loss: 0.915547]\n",
      "epoch:4 step:4186 [D loss: 0.706822, acc.: 58.59%] [G loss: 0.915907]\n",
      "epoch:4 step:4187 [D loss: 0.685437, acc.: 59.38%] [G loss: 0.961719]\n",
      "epoch:4 step:4188 [D loss: 0.652831, acc.: 59.38%] [G loss: 0.968709]\n",
      "epoch:4 step:4189 [D loss: 0.673785, acc.: 61.72%] [G loss: 1.055826]\n",
      "epoch:4 step:4190 [D loss: 0.626205, acc.: 69.53%] [G loss: 0.992567]\n",
      "epoch:4 step:4191 [D loss: 0.631274, acc.: 64.06%] [G loss: 0.981269]\n",
      "epoch:4 step:4192 [D loss: 0.709442, acc.: 53.91%] [G loss: 0.897915]\n",
      "epoch:4 step:4193 [D loss: 0.657819, acc.: 61.72%] [G loss: 1.037519]\n",
      "epoch:4 step:4194 [D loss: 0.644204, acc.: 60.16%] [G loss: 0.948418]\n",
      "epoch:4 step:4195 [D loss: 0.606123, acc.: 67.19%] [G loss: 0.943111]\n",
      "epoch:4 step:4196 [D loss: 0.671409, acc.: 61.72%] [G loss: 1.035178]\n",
      "epoch:4 step:4197 [D loss: 0.750339, acc.: 47.66%] [G loss: 0.964428]\n",
      "epoch:4 step:4198 [D loss: 0.710506, acc.: 51.56%] [G loss: 0.889130]\n",
      "epoch:4 step:4199 [D loss: 0.656533, acc.: 62.50%] [G loss: 1.042723]\n",
      "epoch:4 step:4200 [D loss: 0.642561, acc.: 64.84%] [G loss: 1.132992]\n",
      "epoch:4 step:4201 [D loss: 0.597223, acc.: 62.50%] [G loss: 0.991884]\n",
      "epoch:4 step:4202 [D loss: 0.674127, acc.: 59.38%] [G loss: 1.031099]\n",
      "epoch:4 step:4203 [D loss: 0.611279, acc.: 63.28%] [G loss: 1.074251]\n",
      "epoch:4 step:4204 [D loss: 0.722412, acc.: 57.81%] [G loss: 0.947481]\n",
      "epoch:4 step:4205 [D loss: 0.591746, acc.: 69.53%] [G loss: 0.910202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4206 [D loss: 0.758414, acc.: 52.34%] [G loss: 0.885112]\n",
      "epoch:4 step:4207 [D loss: 0.687583, acc.: 59.38%] [G loss: 0.966938]\n",
      "epoch:4 step:4208 [D loss: 0.619654, acc.: 66.41%] [G loss: 0.983524]\n",
      "epoch:4 step:4209 [D loss: 0.713077, acc.: 50.78%] [G loss: 0.931798]\n",
      "epoch:4 step:4210 [D loss: 0.697867, acc.: 58.59%] [G loss: 0.841617]\n",
      "epoch:4 step:4211 [D loss: 0.702475, acc.: 53.91%] [G loss: 0.937089]\n",
      "epoch:4 step:4212 [D loss: 0.672008, acc.: 60.16%] [G loss: 1.029474]\n",
      "epoch:4 step:4213 [D loss: 0.719676, acc.: 50.78%] [G loss: 0.843334]\n",
      "epoch:4 step:4214 [D loss: 0.678154, acc.: 53.91%] [G loss: 0.899647]\n",
      "epoch:4 step:4215 [D loss: 0.589831, acc.: 67.19%] [G loss: 0.997017]\n",
      "epoch:4 step:4216 [D loss: 0.631928, acc.: 66.41%] [G loss: 1.107725]\n",
      "epoch:4 step:4217 [D loss: 0.691917, acc.: 61.72%] [G loss: 0.993544]\n",
      "epoch:4 step:4218 [D loss: 0.579216, acc.: 69.53%] [G loss: 1.113104]\n",
      "epoch:4 step:4219 [D loss: 0.677963, acc.: 64.06%] [G loss: 0.986674]\n",
      "epoch:4 step:4220 [D loss: 0.628450, acc.: 67.97%] [G loss: 1.073704]\n",
      "epoch:4 step:4221 [D loss: 0.789892, acc.: 46.09%] [G loss: 1.041202]\n",
      "epoch:4 step:4222 [D loss: 0.823334, acc.: 43.75%] [G loss: 0.773703]\n",
      "epoch:4 step:4223 [D loss: 0.700626, acc.: 59.38%] [G loss: 0.919322]\n",
      "epoch:4 step:4224 [D loss: 0.652054, acc.: 62.50%] [G loss: 0.816149]\n",
      "epoch:4 step:4225 [D loss: 0.711399, acc.: 50.78%] [G loss: 0.959153]\n",
      "epoch:4 step:4226 [D loss: 0.710496, acc.: 57.03%] [G loss: 0.931160]\n",
      "epoch:4 step:4227 [D loss: 0.758382, acc.: 51.56%] [G loss: 0.915401]\n",
      "epoch:4 step:4228 [D loss: 0.699843, acc.: 53.91%] [G loss: 0.874214]\n",
      "epoch:4 step:4229 [D loss: 0.611175, acc.: 69.53%] [G loss: 1.000155]\n",
      "epoch:4 step:4230 [D loss: 0.637220, acc.: 65.62%] [G loss: 1.018995]\n",
      "epoch:4 step:4231 [D loss: 0.669736, acc.: 57.03%] [G loss: 0.992241]\n",
      "epoch:4 step:4232 [D loss: 0.624683, acc.: 60.16%] [G loss: 0.943138]\n",
      "epoch:4 step:4233 [D loss: 0.618627, acc.: 64.84%] [G loss: 0.935089]\n",
      "epoch:4 step:4234 [D loss: 0.675031, acc.: 57.81%] [G loss: 1.033485]\n",
      "epoch:4 step:4235 [D loss: 0.626325, acc.: 67.19%] [G loss: 0.978377]\n",
      "epoch:4 step:4236 [D loss: 0.675076, acc.: 57.81%] [G loss: 0.850864]\n",
      "epoch:4 step:4237 [D loss: 0.665931, acc.: 59.38%] [G loss: 0.944494]\n",
      "epoch:4 step:4238 [D loss: 0.690240, acc.: 57.81%] [G loss: 1.048048]\n",
      "epoch:4 step:4239 [D loss: 0.639297, acc.: 64.84%] [G loss: 0.900140]\n",
      "epoch:4 step:4240 [D loss: 0.695837, acc.: 56.25%] [G loss: 0.947974]\n",
      "epoch:4 step:4241 [D loss: 0.672089, acc.: 60.16%] [G loss: 1.019243]\n",
      "epoch:4 step:4242 [D loss: 0.654988, acc.: 60.16%] [G loss: 0.907703]\n",
      "epoch:4 step:4243 [D loss: 0.664715, acc.: 57.03%] [G loss: 0.959298]\n",
      "epoch:4 step:4244 [D loss: 0.655063, acc.: 63.28%] [G loss: 1.059642]\n",
      "epoch:4 step:4245 [D loss: 0.625506, acc.: 65.62%] [G loss: 0.993505]\n",
      "epoch:4 step:4246 [D loss: 0.636627, acc.: 58.59%] [G loss: 1.065282]\n",
      "epoch:4 step:4247 [D loss: 0.568233, acc.: 69.53%] [G loss: 0.992764]\n",
      "epoch:4 step:4248 [D loss: 0.692648, acc.: 55.47%] [G loss: 0.964165]\n",
      "epoch:4 step:4249 [D loss: 0.670878, acc.: 59.38%] [G loss: 0.924180]\n",
      "epoch:4 step:4250 [D loss: 0.709458, acc.: 53.91%] [G loss: 0.919006]\n",
      "epoch:4 step:4251 [D loss: 0.658511, acc.: 60.16%] [G loss: 1.081539]\n",
      "epoch:4 step:4252 [D loss: 0.640326, acc.: 64.06%] [G loss: 1.005100]\n",
      "epoch:4 step:4253 [D loss: 0.698118, acc.: 53.91%] [G loss: 0.979171]\n",
      "epoch:4 step:4254 [D loss: 0.716622, acc.: 47.66%] [G loss: 0.885781]\n",
      "epoch:4 step:4255 [D loss: 0.726214, acc.: 52.34%] [G loss: 0.855129]\n",
      "epoch:4 step:4256 [D loss: 0.595800, acc.: 67.97%] [G loss: 1.000484]\n",
      "epoch:4 step:4257 [D loss: 0.777219, acc.: 48.44%] [G loss: 0.932436]\n",
      "epoch:4 step:4258 [D loss: 0.743135, acc.: 48.44%] [G loss: 0.844985]\n",
      "epoch:4 step:4259 [D loss: 0.717964, acc.: 46.88%] [G loss: 0.909949]\n",
      "epoch:4 step:4260 [D loss: 0.638911, acc.: 65.62%] [G loss: 1.069801]\n",
      "epoch:4 step:4261 [D loss: 0.656461, acc.: 60.94%] [G loss: 0.993735]\n",
      "epoch:4 step:4262 [D loss: 0.729631, acc.: 51.56%] [G loss: 0.886955]\n",
      "epoch:4 step:4263 [D loss: 0.603227, acc.: 70.31%] [G loss: 0.991757]\n",
      "epoch:4 step:4264 [D loss: 0.605132, acc.: 71.88%] [G loss: 0.797175]\n",
      "epoch:4 step:4265 [D loss: 0.686909, acc.: 60.16%] [G loss: 0.922653]\n",
      "epoch:4 step:4266 [D loss: 0.626564, acc.: 64.06%] [G loss: 0.993658]\n",
      "epoch:4 step:4267 [D loss: 0.611269, acc.: 67.97%] [G loss: 0.946640]\n",
      "epoch:4 step:4268 [D loss: 0.716355, acc.: 53.12%] [G loss: 0.921063]\n",
      "epoch:4 step:4269 [D loss: 0.645901, acc.: 67.97%] [G loss: 0.844902]\n",
      "epoch:4 step:4270 [D loss: 0.649091, acc.: 57.03%] [G loss: 0.951278]\n",
      "epoch:4 step:4271 [D loss: 0.657472, acc.: 58.59%] [G loss: 1.015664]\n",
      "epoch:4 step:4272 [D loss: 0.704950, acc.: 57.03%] [G loss: 1.006761]\n",
      "epoch:4 step:4273 [D loss: 0.666916, acc.: 57.03%] [G loss: 0.897337]\n",
      "epoch:4 step:4274 [D loss: 0.632538, acc.: 65.62%] [G loss: 1.005612]\n",
      "epoch:4 step:4275 [D loss: 0.664709, acc.: 61.72%] [G loss: 0.911761]\n",
      "epoch:4 step:4276 [D loss: 0.762479, acc.: 43.75%] [G loss: 0.885775]\n",
      "epoch:4 step:4277 [D loss: 0.650742, acc.: 62.50%] [G loss: 0.825790]\n",
      "epoch:4 step:4278 [D loss: 0.643764, acc.: 60.94%] [G loss: 0.945462]\n",
      "epoch:4 step:4279 [D loss: 0.675620, acc.: 62.50%] [G loss: 0.906543]\n",
      "epoch:4 step:4280 [D loss: 0.592639, acc.: 65.62%] [G loss: 0.885628]\n",
      "epoch:4 step:4281 [D loss: 0.620569, acc.: 62.50%] [G loss: 0.980417]\n",
      "epoch:4 step:4282 [D loss: 0.641609, acc.: 67.19%] [G loss: 0.951051]\n",
      "epoch:4 step:4283 [D loss: 0.659898, acc.: 63.28%] [G loss: 0.995144]\n",
      "epoch:4 step:4284 [D loss: 0.598208, acc.: 67.97%] [G loss: 0.959304]\n",
      "epoch:4 step:4285 [D loss: 0.682227, acc.: 66.41%] [G loss: 1.072896]\n",
      "epoch:4 step:4286 [D loss: 0.715463, acc.: 55.47%] [G loss: 0.937531]\n",
      "epoch:4 step:4287 [D loss: 0.666763, acc.: 59.38%] [G loss: 1.040178]\n",
      "epoch:4 step:4288 [D loss: 0.691002, acc.: 57.03%] [G loss: 0.869531]\n",
      "epoch:4 step:4289 [D loss: 0.648803, acc.: 56.25%] [G loss: 1.001589]\n",
      "epoch:4 step:4290 [D loss: 0.748657, acc.: 53.12%] [G loss: 0.941164]\n",
      "epoch:4 step:4291 [D loss: 0.707874, acc.: 56.25%] [G loss: 0.918089]\n",
      "epoch:4 step:4292 [D loss: 0.696453, acc.: 50.78%] [G loss: 0.946025]\n",
      "epoch:4 step:4293 [D loss: 0.691184, acc.: 59.38%] [G loss: 0.878528]\n",
      "epoch:4 step:4294 [D loss: 0.672819, acc.: 52.34%] [G loss: 1.021386]\n",
      "epoch:4 step:4295 [D loss: 0.615094, acc.: 68.75%] [G loss: 1.003484]\n",
      "epoch:4 step:4296 [D loss: 0.700924, acc.: 56.25%] [G loss: 0.965872]\n",
      "epoch:4 step:4297 [D loss: 0.650552, acc.: 61.72%] [G loss: 0.945162]\n",
      "epoch:4 step:4298 [D loss: 0.624832, acc.: 60.16%] [G loss: 0.976233]\n",
      "epoch:4 step:4299 [D loss: 0.644994, acc.: 66.41%] [G loss: 1.021080]\n",
      "epoch:4 step:4300 [D loss: 0.626361, acc.: 60.94%] [G loss: 1.022925]\n",
      "epoch:4 step:4301 [D loss: 0.635066, acc.: 67.97%] [G loss: 0.978468]\n",
      "epoch:4 step:4302 [D loss: 0.613158, acc.: 65.62%] [G loss: 0.965853]\n",
      "epoch:4 step:4303 [D loss: 0.666454, acc.: 53.91%] [G loss: 1.065406]\n",
      "epoch:4 step:4304 [D loss: 0.629977, acc.: 66.41%] [G loss: 1.000373]\n",
      "epoch:4 step:4305 [D loss: 0.619919, acc.: 68.75%] [G loss: 0.968766]\n",
      "epoch:4 step:4306 [D loss: 0.641500, acc.: 61.72%] [G loss: 1.012113]\n",
      "epoch:4 step:4307 [D loss: 0.685350, acc.: 59.38%] [G loss: 0.937490]\n",
      "epoch:4 step:4308 [D loss: 0.683111, acc.: 50.78%] [G loss: 0.840253]\n",
      "epoch:4 step:4309 [D loss: 0.658905, acc.: 60.94%] [G loss: 0.842255]\n",
      "epoch:4 step:4310 [D loss: 0.647091, acc.: 59.38%] [G loss: 0.911799]\n",
      "epoch:4 step:4311 [D loss: 0.715274, acc.: 48.44%] [G loss: 0.911174]\n",
      "epoch:4 step:4312 [D loss: 0.648611, acc.: 64.06%] [G loss: 0.931138]\n",
      "epoch:4 step:4313 [D loss: 0.672576, acc.: 54.69%] [G loss: 0.980355]\n",
      "epoch:4 step:4314 [D loss: 0.683076, acc.: 58.59%] [G loss: 0.899759]\n",
      "epoch:4 step:4315 [D loss: 0.670907, acc.: 56.25%] [G loss: 0.982886]\n",
      "epoch:4 step:4316 [D loss: 0.663785, acc.: 57.03%] [G loss: 0.962191]\n",
      "epoch:4 step:4317 [D loss: 0.669400, acc.: 52.34%] [G loss: 0.914246]\n",
      "epoch:4 step:4318 [D loss: 0.704138, acc.: 60.16%] [G loss: 0.966648]\n",
      "epoch:4 step:4319 [D loss: 0.599055, acc.: 71.09%] [G loss: 0.980337]\n",
      "epoch:4 step:4320 [D loss: 0.666260, acc.: 64.84%] [G loss: 0.918870]\n",
      "epoch:4 step:4321 [D loss: 0.714203, acc.: 54.69%] [G loss: 0.947689]\n",
      "epoch:4 step:4322 [D loss: 0.620783, acc.: 65.62%] [G loss: 1.020642]\n",
      "epoch:4 step:4323 [D loss: 0.679340, acc.: 57.81%] [G loss: 1.030498]\n",
      "epoch:4 step:4324 [D loss: 0.700113, acc.: 53.91%] [G loss: 0.906779]\n",
      "epoch:4 step:4325 [D loss: 0.643219, acc.: 62.50%] [G loss: 0.977733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4326 [D loss: 0.679540, acc.: 57.03%] [G loss: 0.908614]\n",
      "epoch:4 step:4327 [D loss: 0.728827, acc.: 53.12%] [G loss: 0.902014]\n",
      "epoch:4 step:4328 [D loss: 0.757861, acc.: 43.75%] [G loss: 0.899424]\n",
      "epoch:4 step:4329 [D loss: 0.728647, acc.: 52.34%] [G loss: 0.874521]\n",
      "epoch:4 step:4330 [D loss: 0.661350, acc.: 60.94%] [G loss: 0.911873]\n",
      "epoch:4 step:4331 [D loss: 0.695464, acc.: 53.12%] [G loss: 0.881133]\n",
      "epoch:4 step:4332 [D loss: 0.686569, acc.: 59.38%] [G loss: 1.005742]\n",
      "epoch:4 step:4333 [D loss: 0.606472, acc.: 67.19%] [G loss: 1.059369]\n",
      "epoch:4 step:4334 [D loss: 0.644069, acc.: 61.72%] [G loss: 1.145348]\n",
      "epoch:4 step:4335 [D loss: 0.685327, acc.: 65.62%] [G loss: 0.980111]\n",
      "epoch:4 step:4336 [D loss: 0.647934, acc.: 64.06%] [G loss: 0.900413]\n",
      "epoch:4 step:4337 [D loss: 0.618370, acc.: 64.06%] [G loss: 0.869213]\n",
      "epoch:4 step:4338 [D loss: 0.716524, acc.: 56.25%] [G loss: 0.952462]\n",
      "epoch:4 step:4339 [D loss: 0.649623, acc.: 60.94%] [G loss: 1.033134]\n",
      "epoch:4 step:4340 [D loss: 0.627364, acc.: 68.75%] [G loss: 0.889266]\n",
      "epoch:4 step:4341 [D loss: 0.676350, acc.: 55.47%] [G loss: 0.929332]\n",
      "epoch:4 step:4342 [D loss: 0.645578, acc.: 62.50%] [G loss: 1.011761]\n",
      "epoch:4 step:4343 [D loss: 0.697753, acc.: 58.59%] [G loss: 0.976866]\n",
      "epoch:4 step:4344 [D loss: 0.698920, acc.: 56.25%] [G loss: 0.897292]\n",
      "epoch:4 step:4345 [D loss: 0.637651, acc.: 65.62%] [G loss: 0.966137]\n",
      "epoch:4 step:4346 [D loss: 0.625666, acc.: 58.59%] [G loss: 0.870561]\n",
      "epoch:4 step:4347 [D loss: 0.668629, acc.: 57.03%] [G loss: 1.045772]\n",
      "epoch:4 step:4348 [D loss: 0.700451, acc.: 55.47%] [G loss: 0.894677]\n",
      "epoch:4 step:4349 [D loss: 0.674413, acc.: 60.16%] [G loss: 1.054873]\n",
      "epoch:4 step:4350 [D loss: 0.679095, acc.: 58.59%] [G loss: 0.904223]\n",
      "epoch:4 step:4351 [D loss: 0.649762, acc.: 64.06%] [G loss: 1.023756]\n",
      "epoch:4 step:4352 [D loss: 0.653331, acc.: 59.38%] [G loss: 0.935324]\n",
      "epoch:4 step:4353 [D loss: 0.604117, acc.: 68.75%] [G loss: 1.018071]\n",
      "epoch:4 step:4354 [D loss: 0.639024, acc.: 59.38%] [G loss: 1.040857]\n",
      "epoch:4 step:4355 [D loss: 0.632149, acc.: 63.28%] [G loss: 0.996312]\n",
      "epoch:4 step:4356 [D loss: 0.651136, acc.: 63.28%] [G loss: 1.001732]\n",
      "epoch:4 step:4357 [D loss: 0.654919, acc.: 58.59%] [G loss: 1.104894]\n",
      "epoch:4 step:4358 [D loss: 0.692482, acc.: 57.81%] [G loss: 0.957648]\n",
      "epoch:4 step:4359 [D loss: 0.641294, acc.: 66.41%] [G loss: 0.948809]\n",
      "epoch:4 step:4360 [D loss: 0.694966, acc.: 47.66%] [G loss: 0.955845]\n",
      "epoch:4 step:4361 [D loss: 0.637899, acc.: 61.72%] [G loss: 1.016142]\n",
      "epoch:4 step:4362 [D loss: 0.773070, acc.: 44.53%] [G loss: 0.982193]\n",
      "epoch:4 step:4363 [D loss: 0.708335, acc.: 57.81%] [G loss: 0.976198]\n",
      "epoch:4 step:4364 [D loss: 0.702963, acc.: 50.78%] [G loss: 0.926765]\n",
      "epoch:4 step:4365 [D loss: 0.643064, acc.: 60.94%] [G loss: 0.941690]\n",
      "epoch:4 step:4366 [D loss: 0.626319, acc.: 68.75%] [G loss: 0.929136]\n",
      "epoch:4 step:4367 [D loss: 0.679124, acc.: 61.72%] [G loss: 0.940129]\n",
      "epoch:4 step:4368 [D loss: 0.648787, acc.: 64.84%] [G loss: 0.955566]\n",
      "epoch:4 step:4369 [D loss: 0.752852, acc.: 51.56%] [G loss: 0.899132]\n",
      "epoch:4 step:4370 [D loss: 0.644648, acc.: 61.72%] [G loss: 1.004081]\n",
      "epoch:4 step:4371 [D loss: 0.676053, acc.: 62.50%] [G loss: 0.931745]\n",
      "epoch:4 step:4372 [D loss: 0.581052, acc.: 70.31%] [G loss: 0.999354]\n",
      "epoch:4 step:4373 [D loss: 0.710758, acc.: 54.69%] [G loss: 1.022888]\n",
      "epoch:4 step:4374 [D loss: 0.646546, acc.: 64.06%] [G loss: 0.981668]\n",
      "epoch:4 step:4375 [D loss: 0.678009, acc.: 61.72%] [G loss: 0.984991]\n",
      "epoch:4 step:4376 [D loss: 0.655294, acc.: 60.16%] [G loss: 0.925990]\n",
      "epoch:4 step:4377 [D loss: 0.622002, acc.: 69.53%] [G loss: 0.873250]\n",
      "epoch:4 step:4378 [D loss: 0.693010, acc.: 52.34%] [G loss: 0.924087]\n",
      "epoch:4 step:4379 [D loss: 0.640638, acc.: 66.41%] [G loss: 0.912744]\n",
      "epoch:4 step:4380 [D loss: 0.688076, acc.: 59.38%] [G loss: 0.872157]\n",
      "epoch:4 step:4381 [D loss: 0.628748, acc.: 62.50%] [G loss: 0.982027]\n",
      "epoch:4 step:4382 [D loss: 0.636552, acc.: 66.41%] [G loss: 1.008602]\n",
      "epoch:4 step:4383 [D loss: 0.610528, acc.: 67.97%] [G loss: 1.038067]\n",
      "epoch:4 step:4384 [D loss: 0.693772, acc.: 56.25%] [G loss: 0.988390]\n",
      "epoch:4 step:4385 [D loss: 0.671735, acc.: 60.16%] [G loss: 0.996363]\n",
      "epoch:4 step:4386 [D loss: 0.645997, acc.: 68.75%] [G loss: 0.919448]\n",
      "epoch:4 step:4387 [D loss: 0.646540, acc.: 60.94%] [G loss: 1.095510]\n",
      "epoch:4 step:4388 [D loss: 0.704075, acc.: 51.56%] [G loss: 0.970767]\n",
      "epoch:4 step:4389 [D loss: 0.674704, acc.: 59.38%] [G loss: 0.968000]\n",
      "epoch:4 step:4390 [D loss: 0.633186, acc.: 64.06%] [G loss: 1.000776]\n",
      "epoch:4 step:4391 [D loss: 0.587627, acc.: 64.06%] [G loss: 1.082366]\n",
      "epoch:4 step:4392 [D loss: 0.659902, acc.: 60.94%] [G loss: 0.998739]\n",
      "epoch:4 step:4393 [D loss: 0.631925, acc.: 67.97%] [G loss: 0.975981]\n",
      "epoch:4 step:4394 [D loss: 0.666839, acc.: 57.81%] [G loss: 0.872894]\n",
      "epoch:4 step:4395 [D loss: 0.709246, acc.: 54.69%] [G loss: 0.874042]\n",
      "epoch:4 step:4396 [D loss: 0.601080, acc.: 71.09%] [G loss: 0.967668]\n",
      "epoch:4 step:4397 [D loss: 0.615968, acc.: 67.19%] [G loss: 1.035746]\n",
      "epoch:4 step:4398 [D loss: 0.638384, acc.: 64.84%] [G loss: 0.927059]\n",
      "epoch:4 step:4399 [D loss: 0.647492, acc.: 63.28%] [G loss: 1.049762]\n",
      "epoch:4 step:4400 [D loss: 0.733055, acc.: 50.78%] [G loss: 0.943946]\n",
      "epoch:4 step:4401 [D loss: 0.665239, acc.: 57.81%] [G loss: 0.911752]\n",
      "epoch:4 step:4402 [D loss: 0.611549, acc.: 69.53%] [G loss: 0.959078]\n",
      "epoch:4 step:4403 [D loss: 0.659297, acc.: 58.59%] [G loss: 0.848314]\n",
      "epoch:4 step:4404 [D loss: 0.685705, acc.: 54.69%] [G loss: 1.012264]\n",
      "epoch:4 step:4405 [D loss: 0.784560, acc.: 50.78%] [G loss: 0.829809]\n",
      "epoch:4 step:4406 [D loss: 0.667505, acc.: 56.25%] [G loss: 0.886760]\n",
      "epoch:4 step:4407 [D loss: 0.652855, acc.: 60.94%] [G loss: 0.923342]\n",
      "epoch:4 step:4408 [D loss: 0.601975, acc.: 64.06%] [G loss: 0.906752]\n",
      "epoch:4 step:4409 [D loss: 0.627275, acc.: 64.84%] [G loss: 0.948617]\n",
      "epoch:4 step:4410 [D loss: 0.708789, acc.: 53.12%] [G loss: 0.976405]\n",
      "epoch:4 step:4411 [D loss: 0.674656, acc.: 60.94%] [G loss: 0.945605]\n",
      "epoch:4 step:4412 [D loss: 0.781515, acc.: 45.31%] [G loss: 0.925210]\n",
      "epoch:4 step:4413 [D loss: 0.697891, acc.: 53.12%] [G loss: 0.842451]\n",
      "epoch:4 step:4414 [D loss: 0.627478, acc.: 65.62%] [G loss: 0.991282]\n",
      "epoch:4 step:4415 [D loss: 0.720033, acc.: 53.12%] [G loss: 0.937767]\n",
      "epoch:4 step:4416 [D loss: 0.618821, acc.: 65.62%] [G loss: 0.978489]\n",
      "epoch:4 step:4417 [D loss: 0.687416, acc.: 60.16%] [G loss: 0.983029]\n",
      "epoch:4 step:4418 [D loss: 0.656923, acc.: 62.50%] [G loss: 0.945908]\n",
      "epoch:4 step:4419 [D loss: 0.663233, acc.: 57.81%] [G loss: 0.949076]\n",
      "epoch:4 step:4420 [D loss: 0.654912, acc.: 57.03%] [G loss: 0.948598]\n",
      "epoch:4 step:4421 [D loss: 0.689269, acc.: 60.16%] [G loss: 0.919495]\n",
      "epoch:4 step:4422 [D loss: 0.663568, acc.: 60.94%] [G loss: 0.858766]\n",
      "epoch:4 step:4423 [D loss: 0.678792, acc.: 62.50%] [G loss: 0.824822]\n",
      "epoch:4 step:4424 [D loss: 0.616670, acc.: 71.09%] [G loss: 1.027086]\n",
      "epoch:4 step:4425 [D loss: 0.646348, acc.: 63.28%] [G loss: 0.928836]\n",
      "epoch:4 step:4426 [D loss: 0.654464, acc.: 60.94%] [G loss: 0.896296]\n",
      "epoch:4 step:4427 [D loss: 0.617311, acc.: 64.84%] [G loss: 1.085772]\n",
      "epoch:4 step:4428 [D loss: 0.623317, acc.: 62.50%] [G loss: 0.947802]\n",
      "epoch:4 step:4429 [D loss: 0.614413, acc.: 67.19%] [G loss: 0.925335]\n",
      "epoch:4 step:4430 [D loss: 0.631180, acc.: 63.28%] [G loss: 0.953848]\n",
      "epoch:4 step:4431 [D loss: 0.680291, acc.: 56.25%] [G loss: 1.035705]\n",
      "epoch:4 step:4432 [D loss: 0.661686, acc.: 60.16%] [G loss: 0.847411]\n",
      "epoch:4 step:4433 [D loss: 0.669902, acc.: 57.03%] [G loss: 0.884101]\n",
      "epoch:4 step:4434 [D loss: 0.609724, acc.: 71.09%] [G loss: 0.997717]\n",
      "epoch:4 step:4435 [D loss: 0.619529, acc.: 67.19%] [G loss: 1.004895]\n",
      "epoch:4 step:4436 [D loss: 0.646905, acc.: 66.41%] [G loss: 0.938087]\n",
      "epoch:4 step:4437 [D loss: 0.629018, acc.: 67.97%] [G loss: 1.041402]\n",
      "epoch:4 step:4438 [D loss: 0.678650, acc.: 57.81%] [G loss: 0.877551]\n",
      "epoch:4 step:4439 [D loss: 0.643021, acc.: 60.94%] [G loss: 1.056370]\n",
      "epoch:4 step:4440 [D loss: 0.666912, acc.: 63.28%] [G loss: 0.904432]\n",
      "epoch:4 step:4441 [D loss: 0.662419, acc.: 62.50%] [G loss: 0.900463]\n",
      "epoch:4 step:4442 [D loss: 0.634093, acc.: 63.28%] [G loss: 0.881987]\n",
      "epoch:4 step:4443 [D loss: 0.662834, acc.: 61.72%] [G loss: 0.983612]\n",
      "epoch:4 step:4444 [D loss: 0.654524, acc.: 58.59%] [G loss: 0.910204]\n",
      "epoch:4 step:4445 [D loss: 0.644972, acc.: 65.62%] [G loss: 0.959288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4446 [D loss: 0.622741, acc.: 65.62%] [G loss: 1.032400]\n",
      "epoch:4 step:4447 [D loss: 0.664135, acc.: 58.59%] [G loss: 0.948601]\n",
      "epoch:4 step:4448 [D loss: 0.701167, acc.: 47.66%] [G loss: 0.889832]\n",
      "epoch:4 step:4449 [D loss: 0.636868, acc.: 60.94%] [G loss: 0.882569]\n",
      "epoch:4 step:4450 [D loss: 0.703994, acc.: 57.03%] [G loss: 0.879988]\n",
      "epoch:4 step:4451 [D loss: 0.623811, acc.: 64.06%] [G loss: 1.089988]\n",
      "epoch:4 step:4452 [D loss: 0.731832, acc.: 53.91%] [G loss: 0.960578]\n",
      "epoch:4 step:4453 [D loss: 0.644989, acc.: 57.81%] [G loss: 0.989175]\n",
      "epoch:4 step:4454 [D loss: 0.609543, acc.: 67.97%] [G loss: 0.927893]\n",
      "epoch:4 step:4455 [D loss: 0.610372, acc.: 65.62%] [G loss: 1.061293]\n",
      "epoch:4 step:4456 [D loss: 0.635746, acc.: 66.41%] [G loss: 1.109926]\n",
      "epoch:4 step:4457 [D loss: 0.650321, acc.: 64.84%] [G loss: 0.931876]\n",
      "epoch:4 step:4458 [D loss: 0.707210, acc.: 55.47%] [G loss: 1.155047]\n",
      "epoch:4 step:4459 [D loss: 0.703680, acc.: 57.81%] [G loss: 1.033565]\n",
      "epoch:4 step:4460 [D loss: 0.671690, acc.: 59.38%] [G loss: 0.890583]\n",
      "epoch:4 step:4461 [D loss: 0.607336, acc.: 67.19%] [G loss: 1.038617]\n",
      "epoch:4 step:4462 [D loss: 0.639828, acc.: 64.06%] [G loss: 0.768641]\n",
      "epoch:4 step:4463 [D loss: 0.670535, acc.: 62.50%] [G loss: 0.886983]\n",
      "epoch:4 step:4464 [D loss: 0.744676, acc.: 50.78%] [G loss: 0.896265]\n",
      "epoch:4 step:4465 [D loss: 0.707462, acc.: 53.91%] [G loss: 0.866758]\n",
      "epoch:4 step:4466 [D loss: 0.680749, acc.: 60.16%] [G loss: 0.927892]\n",
      "epoch:4 step:4467 [D loss: 0.649437, acc.: 60.94%] [G loss: 0.938284]\n",
      "epoch:4 step:4468 [D loss: 0.633961, acc.: 61.72%] [G loss: 1.024846]\n",
      "epoch:4 step:4469 [D loss: 0.678148, acc.: 60.16%] [G loss: 0.898627]\n",
      "epoch:4 step:4470 [D loss: 0.695617, acc.: 57.03%] [G loss: 0.972639]\n",
      "epoch:4 step:4471 [D loss: 0.670668, acc.: 62.50%] [G loss: 1.042670]\n",
      "epoch:4 step:4472 [D loss: 0.645913, acc.: 65.62%] [G loss: 0.974584]\n",
      "epoch:4 step:4473 [D loss: 0.714453, acc.: 53.91%] [G loss: 0.784193]\n",
      "epoch:4 step:4474 [D loss: 0.665573, acc.: 65.62%] [G loss: 0.957731]\n",
      "epoch:4 step:4475 [D loss: 0.683710, acc.: 52.34%] [G loss: 0.860570]\n",
      "epoch:4 step:4476 [D loss: 0.697428, acc.: 61.72%] [G loss: 0.915172]\n",
      "epoch:4 step:4477 [D loss: 0.653816, acc.: 59.38%] [G loss: 0.976030]\n",
      "epoch:4 step:4478 [D loss: 0.659156, acc.: 63.28%] [G loss: 1.057447]\n",
      "epoch:4 step:4479 [D loss: 0.617526, acc.: 68.75%] [G loss: 1.015412]\n",
      "epoch:4 step:4480 [D loss: 0.622851, acc.: 66.41%] [G loss: 0.878929]\n",
      "epoch:4 step:4481 [D loss: 0.619535, acc.: 70.31%] [G loss: 1.046554]\n",
      "epoch:4 step:4482 [D loss: 0.708115, acc.: 58.59%] [G loss: 1.007334]\n",
      "epoch:4 step:4483 [D loss: 0.659040, acc.: 61.72%] [G loss: 0.918926]\n",
      "epoch:4 step:4484 [D loss: 0.641646, acc.: 64.06%] [G loss: 0.968011]\n",
      "epoch:4 step:4485 [D loss: 0.664444, acc.: 58.59%] [G loss: 0.840776]\n",
      "epoch:4 step:4486 [D loss: 0.661469, acc.: 57.03%] [G loss: 0.968834]\n",
      "epoch:4 step:4487 [D loss: 0.642586, acc.: 65.62%] [G loss: 1.058561]\n",
      "epoch:4 step:4488 [D loss: 0.736950, acc.: 46.88%] [G loss: 0.900695]\n",
      "epoch:4 step:4489 [D loss: 0.689681, acc.: 53.12%] [G loss: 1.021569]\n",
      "epoch:4 step:4490 [D loss: 0.754644, acc.: 50.00%] [G loss: 0.949741]\n",
      "epoch:4 step:4491 [D loss: 0.678909, acc.: 60.16%] [G loss: 0.966529]\n",
      "epoch:4 step:4492 [D loss: 0.694915, acc.: 57.81%] [G loss: 0.923151]\n",
      "epoch:4 step:4493 [D loss: 0.672928, acc.: 60.94%] [G loss: 0.937293]\n",
      "epoch:4 step:4494 [D loss: 0.641390, acc.: 64.06%] [G loss: 0.972248]\n",
      "epoch:4 step:4495 [D loss: 0.579924, acc.: 71.88%] [G loss: 1.067595]\n",
      "epoch:4 step:4496 [D loss: 0.687110, acc.: 56.25%] [G loss: 1.060554]\n",
      "epoch:4 step:4497 [D loss: 0.683388, acc.: 56.25%] [G loss: 1.019477]\n",
      "epoch:4 step:4498 [D loss: 0.667166, acc.: 56.25%] [G loss: 0.987865]\n",
      "epoch:4 step:4499 [D loss: 0.638903, acc.: 64.06%] [G loss: 0.929525]\n",
      "epoch:4 step:4500 [D loss: 0.746999, acc.: 51.56%] [G loss: 0.894394]\n",
      "epoch:4 step:4501 [D loss: 0.664526, acc.: 62.50%] [G loss: 0.913688]\n",
      "epoch:4 step:4502 [D loss: 0.628564, acc.: 61.72%] [G loss: 0.968348]\n",
      "epoch:4 step:4503 [D loss: 0.605939, acc.: 69.53%] [G loss: 0.979010]\n",
      "epoch:4 step:4504 [D loss: 0.628941, acc.: 58.59%] [G loss: 1.033410]\n",
      "epoch:4 step:4505 [D loss: 0.650215, acc.: 63.28%] [G loss: 0.944099]\n",
      "epoch:4 step:4506 [D loss: 0.700669, acc.: 59.38%] [G loss: 1.015624]\n",
      "epoch:4 step:4507 [D loss: 0.674930, acc.: 58.59%] [G loss: 1.063999]\n",
      "epoch:4 step:4508 [D loss: 0.665919, acc.: 59.38%] [G loss: 0.871767]\n",
      "epoch:4 step:4509 [D loss: 0.667949, acc.: 60.16%] [G loss: 1.083201]\n",
      "epoch:4 step:4510 [D loss: 0.653158, acc.: 59.38%] [G loss: 0.868553]\n",
      "epoch:4 step:4511 [D loss: 0.700153, acc.: 54.69%] [G loss: 0.856998]\n",
      "epoch:4 step:4512 [D loss: 0.663266, acc.: 57.03%] [G loss: 0.969785]\n",
      "epoch:4 step:4513 [D loss: 0.642411, acc.: 63.28%] [G loss: 0.959842]\n",
      "epoch:4 step:4514 [D loss: 0.765189, acc.: 49.22%] [G loss: 0.837818]\n",
      "epoch:4 step:4515 [D loss: 0.606237, acc.: 66.41%] [G loss: 1.078166]\n",
      "epoch:4 step:4516 [D loss: 0.700201, acc.: 50.00%] [G loss: 1.028875]\n",
      "epoch:4 step:4517 [D loss: 0.713579, acc.: 57.03%] [G loss: 0.870122]\n",
      "epoch:4 step:4518 [D loss: 0.698773, acc.: 58.59%] [G loss: 0.906512]\n",
      "epoch:4 step:4519 [D loss: 0.661173, acc.: 53.91%] [G loss: 1.013046]\n",
      "epoch:4 step:4520 [D loss: 0.607311, acc.: 64.06%] [G loss: 1.022242]\n",
      "epoch:4 step:4521 [D loss: 0.709851, acc.: 54.69%] [G loss: 1.023922]\n",
      "epoch:4 step:4522 [D loss: 0.706188, acc.: 54.69%] [G loss: 0.983965]\n",
      "epoch:4 step:4523 [D loss: 0.683112, acc.: 59.38%] [G loss: 1.021716]\n",
      "epoch:4 step:4524 [D loss: 0.674155, acc.: 61.72%] [G loss: 0.952961]\n",
      "epoch:4 step:4525 [D loss: 0.630061, acc.: 59.38%] [G loss: 0.970362]\n",
      "epoch:4 step:4526 [D loss: 0.651418, acc.: 60.16%] [G loss: 0.953380]\n",
      "epoch:4 step:4527 [D loss: 0.647267, acc.: 59.38%] [G loss: 1.046884]\n",
      "epoch:4 step:4528 [D loss: 0.686657, acc.: 60.94%] [G loss: 0.903535]\n",
      "epoch:4 step:4529 [D loss: 0.614015, acc.: 63.28%] [G loss: 0.944957]\n",
      "epoch:4 step:4530 [D loss: 0.581298, acc.: 66.41%] [G loss: 0.921107]\n",
      "epoch:4 step:4531 [D loss: 0.661027, acc.: 62.50%] [G loss: 1.068259]\n",
      "epoch:4 step:4532 [D loss: 0.661873, acc.: 59.38%] [G loss: 0.955912]\n",
      "epoch:4 step:4533 [D loss: 0.651830, acc.: 60.16%] [G loss: 0.887753]\n",
      "epoch:4 step:4534 [D loss: 0.600348, acc.: 67.19%] [G loss: 0.945015]\n",
      "epoch:4 step:4535 [D loss: 0.717809, acc.: 51.56%] [G loss: 0.938351]\n",
      "epoch:4 step:4536 [D loss: 0.806471, acc.: 39.84%] [G loss: 0.907832]\n",
      "epoch:4 step:4537 [D loss: 0.620250, acc.: 65.62%] [G loss: 0.977564]\n",
      "epoch:4 step:4538 [D loss: 0.671766, acc.: 62.50%] [G loss: 1.047608]\n",
      "epoch:4 step:4539 [D loss: 0.683233, acc.: 60.94%] [G loss: 0.849845]\n",
      "epoch:4 step:4540 [D loss: 0.564187, acc.: 75.00%] [G loss: 1.012109]\n",
      "epoch:4 step:4541 [D loss: 0.657005, acc.: 64.84%] [G loss: 0.993794]\n",
      "epoch:4 step:4542 [D loss: 0.678001, acc.: 56.25%] [G loss: 0.954371]\n",
      "epoch:4 step:4543 [D loss: 0.727185, acc.: 54.69%] [G loss: 0.866202]\n",
      "epoch:4 step:4544 [D loss: 0.635419, acc.: 63.28%] [G loss: 1.029269]\n",
      "epoch:4 step:4545 [D loss: 0.632290, acc.: 66.41%] [G loss: 0.905791]\n",
      "epoch:4 step:4546 [D loss: 0.636992, acc.: 64.06%] [G loss: 1.035712]\n",
      "epoch:4 step:4547 [D loss: 0.630126, acc.: 61.72%] [G loss: 0.995060]\n",
      "epoch:4 step:4548 [D loss: 0.729884, acc.: 53.91%] [G loss: 0.929984]\n",
      "epoch:4 step:4549 [D loss: 0.652675, acc.: 61.72%] [G loss: 0.936913]\n",
      "epoch:4 step:4550 [D loss: 0.647707, acc.: 61.72%] [G loss: 0.927894]\n",
      "epoch:4 step:4551 [D loss: 0.652043, acc.: 67.19%] [G loss: 0.905572]\n",
      "epoch:4 step:4552 [D loss: 0.615081, acc.: 66.41%] [G loss: 1.025101]\n",
      "epoch:4 step:4553 [D loss: 0.682862, acc.: 57.81%] [G loss: 0.960804]\n",
      "epoch:4 step:4554 [D loss: 0.637423, acc.: 62.50%] [G loss: 0.972482]\n",
      "epoch:4 step:4555 [D loss: 0.637953, acc.: 61.72%] [G loss: 0.987932]\n",
      "epoch:4 step:4556 [D loss: 0.685492, acc.: 57.81%] [G loss: 0.924179]\n",
      "epoch:4 step:4557 [D loss: 0.662092, acc.: 59.38%] [G loss: 0.851333]\n",
      "epoch:4 step:4558 [D loss: 0.683875, acc.: 57.81%] [G loss: 0.973784]\n",
      "epoch:4 step:4559 [D loss: 0.640780, acc.: 64.06%] [G loss: 1.044356]\n",
      "epoch:4 step:4560 [D loss: 0.700449, acc.: 55.47%] [G loss: 1.006448]\n",
      "epoch:4 step:4561 [D loss: 0.639594, acc.: 68.75%] [G loss: 0.974338]\n",
      "epoch:4 step:4562 [D loss: 0.686825, acc.: 60.16%] [G loss: 0.884806]\n",
      "epoch:4 step:4563 [D loss: 0.713102, acc.: 54.69%] [G loss: 0.996911]\n",
      "epoch:4 step:4564 [D loss: 0.661818, acc.: 59.38%] [G loss: 1.033110]\n",
      "epoch:4 step:4565 [D loss: 0.726082, acc.: 48.44%] [G loss: 0.829186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4566 [D loss: 0.628118, acc.: 64.84%] [G loss: 1.055727]\n",
      "epoch:4 step:4567 [D loss: 0.669868, acc.: 53.12%] [G loss: 0.981725]\n",
      "epoch:4 step:4568 [D loss: 0.677005, acc.: 53.91%] [G loss: 0.833343]\n",
      "epoch:4 step:4569 [D loss: 0.639590, acc.: 61.72%] [G loss: 0.956549]\n",
      "epoch:4 step:4570 [D loss: 0.616758, acc.: 64.84%] [G loss: 0.954504]\n",
      "epoch:4 step:4571 [D loss: 0.611620, acc.: 67.19%] [G loss: 0.946378]\n",
      "epoch:4 step:4572 [D loss: 0.708135, acc.: 54.69%] [G loss: 0.864103]\n",
      "epoch:4 step:4573 [D loss: 0.672064, acc.: 62.50%] [G loss: 1.010241]\n",
      "epoch:4 step:4574 [D loss: 0.708726, acc.: 53.91%] [G loss: 1.015743]\n",
      "epoch:4 step:4575 [D loss: 0.664057, acc.: 62.50%] [G loss: 0.951386]\n",
      "epoch:4 step:4576 [D loss: 0.688048, acc.: 53.91%] [G loss: 0.978088]\n",
      "epoch:4 step:4577 [D loss: 0.587429, acc.: 70.31%] [G loss: 0.925147]\n",
      "epoch:4 step:4578 [D loss: 0.695345, acc.: 59.38%] [G loss: 0.915249]\n",
      "epoch:4 step:4579 [D loss: 0.618291, acc.: 64.84%] [G loss: 0.918292]\n",
      "epoch:4 step:4580 [D loss: 0.644627, acc.: 67.19%] [G loss: 0.882875]\n",
      "epoch:4 step:4581 [D loss: 0.615331, acc.: 67.19%] [G loss: 1.019606]\n",
      "epoch:4 step:4582 [D loss: 0.645194, acc.: 64.84%] [G loss: 0.839796]\n",
      "epoch:4 step:4583 [D loss: 0.663348, acc.: 59.38%] [G loss: 1.025521]\n",
      "epoch:4 step:4584 [D loss: 0.672548, acc.: 57.03%] [G loss: 1.027556]\n",
      "epoch:4 step:4585 [D loss: 0.661387, acc.: 57.81%] [G loss: 0.979790]\n",
      "epoch:4 step:4586 [D loss: 0.604123, acc.: 64.84%] [G loss: 0.936011]\n",
      "epoch:4 step:4587 [D loss: 0.686046, acc.: 58.59%] [G loss: 0.987459]\n",
      "epoch:4 step:4588 [D loss: 0.605872, acc.: 66.41%] [G loss: 0.992627]\n",
      "epoch:4 step:4589 [D loss: 0.685527, acc.: 54.69%] [G loss: 0.885051]\n",
      "epoch:4 step:4590 [D loss: 0.562242, acc.: 73.44%] [G loss: 0.950215]\n",
      "epoch:4 step:4591 [D loss: 0.651051, acc.: 62.50%] [G loss: 0.993303]\n",
      "epoch:4 step:4592 [D loss: 0.729734, acc.: 49.22%] [G loss: 0.878005]\n",
      "epoch:4 step:4593 [D loss: 0.707946, acc.: 57.81%] [G loss: 0.910825]\n",
      "epoch:4 step:4594 [D loss: 0.619935, acc.: 63.28%] [G loss: 1.015719]\n",
      "epoch:4 step:4595 [D loss: 0.649825, acc.: 64.84%] [G loss: 0.941554]\n",
      "epoch:4 step:4596 [D loss: 0.678086, acc.: 59.38%] [G loss: 0.896951]\n",
      "epoch:4 step:4597 [D loss: 0.662109, acc.: 60.94%] [G loss: 0.937065]\n",
      "epoch:4 step:4598 [D loss: 0.707641, acc.: 57.03%] [G loss: 0.914316]\n",
      "epoch:4 step:4599 [D loss: 0.755773, acc.: 43.75%] [G loss: 0.898603]\n",
      "epoch:4 step:4600 [D loss: 0.642412, acc.: 66.41%] [G loss: 0.928306]\n",
      "epoch:4 step:4601 [D loss: 0.639266, acc.: 60.94%] [G loss: 0.917030]\n",
      "epoch:4 step:4602 [D loss: 0.597979, acc.: 61.72%] [G loss: 0.930144]\n",
      "epoch:4 step:4603 [D loss: 0.662149, acc.: 61.72%] [G loss: 0.961266]\n",
      "epoch:4 step:4604 [D loss: 0.664141, acc.: 57.81%] [G loss: 1.014562]\n",
      "epoch:4 step:4605 [D loss: 0.647298, acc.: 64.06%] [G loss: 0.954049]\n",
      "epoch:4 step:4606 [D loss: 0.673726, acc.: 57.03%] [G loss: 0.967801]\n",
      "epoch:4 step:4607 [D loss: 0.792723, acc.: 46.09%] [G loss: 0.779971]\n",
      "epoch:4 step:4608 [D loss: 0.607388, acc.: 71.09%] [G loss: 0.889539]\n",
      "epoch:4 step:4609 [D loss: 0.668762, acc.: 55.47%] [G loss: 0.890302]\n",
      "epoch:4 step:4610 [D loss: 0.642750, acc.: 64.06%] [G loss: 0.904847]\n",
      "epoch:4 step:4611 [D loss: 0.648811, acc.: 59.38%] [G loss: 0.926966]\n",
      "epoch:4 step:4612 [D loss: 0.639726, acc.: 64.06%] [G loss: 0.915334]\n",
      "epoch:4 step:4613 [D loss: 0.696576, acc.: 52.34%] [G loss: 0.896908]\n",
      "epoch:4 step:4614 [D loss: 0.656330, acc.: 58.59%] [G loss: 0.978836]\n",
      "epoch:4 step:4615 [D loss: 0.700045, acc.: 52.34%] [G loss: 0.965413]\n",
      "epoch:4 step:4616 [D loss: 0.658198, acc.: 59.38%] [G loss: 1.027975]\n",
      "epoch:4 step:4617 [D loss: 0.670010, acc.: 59.38%] [G loss: 0.986796]\n",
      "epoch:4 step:4618 [D loss: 0.615166, acc.: 68.75%] [G loss: 1.051209]\n",
      "epoch:4 step:4619 [D loss: 0.674889, acc.: 55.47%] [G loss: 0.924626]\n",
      "epoch:4 step:4620 [D loss: 0.574355, acc.: 73.44%] [G loss: 1.002114]\n",
      "epoch:4 step:4621 [D loss: 0.656271, acc.: 64.06%] [G loss: 0.909671]\n",
      "epoch:4 step:4622 [D loss: 0.629158, acc.: 65.62%] [G loss: 0.925218]\n",
      "epoch:4 step:4623 [D loss: 0.648871, acc.: 58.59%] [G loss: 0.930028]\n",
      "epoch:4 step:4624 [D loss: 0.647793, acc.: 62.50%] [G loss: 1.012685]\n",
      "epoch:4 step:4625 [D loss: 0.616807, acc.: 65.62%] [G loss: 0.983488]\n",
      "epoch:4 step:4626 [D loss: 0.750598, acc.: 52.34%] [G loss: 1.025071]\n",
      "epoch:4 step:4627 [D loss: 0.670132, acc.: 64.84%] [G loss: 1.022842]\n",
      "epoch:4 step:4628 [D loss: 0.665934, acc.: 59.38%] [G loss: 1.077142]\n",
      "epoch:4 step:4629 [D loss: 0.647611, acc.: 61.72%] [G loss: 0.908654]\n",
      "epoch:4 step:4630 [D loss: 0.653100, acc.: 62.50%] [G loss: 0.897921]\n",
      "epoch:4 step:4631 [D loss: 0.645477, acc.: 60.94%] [G loss: 0.904425]\n",
      "epoch:4 step:4632 [D loss: 0.619341, acc.: 67.97%] [G loss: 0.935062]\n",
      "epoch:4 step:4633 [D loss: 0.668959, acc.: 57.81%] [G loss: 0.911669]\n",
      "epoch:4 step:4634 [D loss: 0.641996, acc.: 65.62%] [G loss: 0.960239]\n",
      "epoch:4 step:4635 [D loss: 0.622258, acc.: 68.75%] [G loss: 1.030566]\n",
      "epoch:4 step:4636 [D loss: 0.581467, acc.: 70.31%] [G loss: 1.040569]\n",
      "epoch:4 step:4637 [D loss: 0.609832, acc.: 69.53%] [G loss: 1.057457]\n",
      "epoch:4 step:4638 [D loss: 0.520265, acc.: 76.56%] [G loss: 1.105552]\n",
      "epoch:4 step:4639 [D loss: 0.751819, acc.: 52.34%] [G loss: 0.990970]\n",
      "epoch:4 step:4640 [D loss: 0.733927, acc.: 52.34%] [G loss: 0.835243]\n",
      "epoch:4 step:4641 [D loss: 0.738812, acc.: 47.66%] [G loss: 0.822852]\n",
      "epoch:4 step:4642 [D loss: 0.630277, acc.: 62.50%] [G loss: 1.065869]\n",
      "epoch:4 step:4643 [D loss: 0.640552, acc.: 66.41%] [G loss: 0.982412]\n",
      "epoch:4 step:4644 [D loss: 0.638370, acc.: 60.16%] [G loss: 1.075498]\n",
      "epoch:4 step:4645 [D loss: 0.640388, acc.: 59.38%] [G loss: 0.989108]\n",
      "epoch:4 step:4646 [D loss: 0.602201, acc.: 64.84%] [G loss: 0.937979]\n",
      "epoch:4 step:4647 [D loss: 0.721138, acc.: 55.47%] [G loss: 0.847703]\n",
      "epoch:4 step:4648 [D loss: 0.627223, acc.: 67.97%] [G loss: 0.981139]\n",
      "epoch:4 step:4649 [D loss: 0.649416, acc.: 60.16%] [G loss: 1.164032]\n",
      "epoch:4 step:4650 [D loss: 0.635694, acc.: 64.84%] [G loss: 1.153033]\n",
      "epoch:4 step:4651 [D loss: 0.657990, acc.: 61.72%] [G loss: 0.970170]\n",
      "epoch:4 step:4652 [D loss: 0.638981, acc.: 61.72%] [G loss: 0.989788]\n",
      "epoch:4 step:4653 [D loss: 0.669619, acc.: 62.50%] [G loss: 0.889806]\n",
      "epoch:4 step:4654 [D loss: 0.702085, acc.: 54.69%] [G loss: 0.796190]\n",
      "epoch:4 step:4655 [D loss: 0.653350, acc.: 57.81%] [G loss: 0.919866]\n",
      "epoch:4 step:4656 [D loss: 0.692886, acc.: 61.72%] [G loss: 0.837422]\n",
      "epoch:4 step:4657 [D loss: 0.646021, acc.: 68.75%] [G loss: 0.960829]\n",
      "epoch:4 step:4658 [D loss: 0.604967, acc.: 68.75%] [G loss: 0.981333]\n",
      "epoch:4 step:4659 [D loss: 0.615042, acc.: 65.62%] [G loss: 1.027340]\n",
      "epoch:4 step:4660 [D loss: 0.608937, acc.: 68.75%] [G loss: 0.968290]\n",
      "epoch:4 step:4661 [D loss: 0.688005, acc.: 58.59%] [G loss: 0.991859]\n",
      "epoch:4 step:4662 [D loss: 0.660090, acc.: 59.38%] [G loss: 0.909712]\n",
      "epoch:4 step:4663 [D loss: 0.657879, acc.: 64.06%] [G loss: 0.877564]\n",
      "epoch:4 step:4664 [D loss: 0.681185, acc.: 55.47%] [G loss: 1.014414]\n",
      "epoch:4 step:4665 [D loss: 0.745268, acc.: 58.59%] [G loss: 0.884682]\n",
      "epoch:4 step:4666 [D loss: 0.592617, acc.: 70.31%] [G loss: 0.839453]\n",
      "epoch:4 step:4667 [D loss: 0.563610, acc.: 70.31%] [G loss: 0.998719]\n",
      "epoch:4 step:4668 [D loss: 0.746779, acc.: 46.09%] [G loss: 0.968533]\n",
      "epoch:4 step:4669 [D loss: 0.581760, acc.: 74.22%] [G loss: 1.040346]\n",
      "epoch:4 step:4670 [D loss: 0.623081, acc.: 62.50%] [G loss: 1.006299]\n",
      "epoch:4 step:4671 [D loss: 0.544877, acc.: 75.00%] [G loss: 1.027303]\n",
      "epoch:4 step:4672 [D loss: 0.543965, acc.: 77.34%] [G loss: 1.091641]\n",
      "epoch:4 step:4673 [D loss: 0.589281, acc.: 68.75%] [G loss: 1.040993]\n",
      "epoch:4 step:4674 [D loss: 0.492427, acc.: 86.72%] [G loss: 1.097932]\n",
      "epoch:4 step:4675 [D loss: 0.680570, acc.: 59.38%] [G loss: 1.016224]\n",
      "epoch:4 step:4676 [D loss: 0.845109, acc.: 51.56%] [G loss: 0.999827]\n",
      "epoch:4 step:4677 [D loss: 0.802307, acc.: 42.97%] [G loss: 1.127953]\n",
      "epoch:4 step:4678 [D loss: 0.621741, acc.: 61.72%] [G loss: 0.961280]\n",
      "epoch:4 step:4679 [D loss: 0.672044, acc.: 64.06%] [G loss: 0.999020]\n",
      "epoch:4 step:4680 [D loss: 0.711851, acc.: 59.38%] [G loss: 0.883440]\n",
      "epoch:4 step:4681 [D loss: 0.601457, acc.: 69.53%] [G loss: 1.053874]\n",
      "epoch:4 step:4682 [D loss: 0.629170, acc.: 64.06%] [G loss: 0.985765]\n",
      "epoch:4 step:4683 [D loss: 0.674732, acc.: 58.59%] [G loss: 0.949260]\n",
      "epoch:4 step:4684 [D loss: 0.599411, acc.: 65.62%] [G loss: 0.898496]\n",
      "epoch:4 step:4685 [D loss: 0.521596, acc.: 79.69%] [G loss: 1.224187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4686 [D loss: 0.672094, acc.: 60.16%] [G loss: 1.040164]\n",
      "epoch:5 step:4687 [D loss: 0.680417, acc.: 61.72%] [G loss: 1.038521]\n",
      "epoch:5 step:4688 [D loss: 0.636882, acc.: 63.28%] [G loss: 1.051292]\n",
      "epoch:5 step:4689 [D loss: 0.721203, acc.: 57.81%] [G loss: 0.898727]\n",
      "epoch:5 step:4690 [D loss: 0.654324, acc.: 57.81%] [G loss: 0.955428]\n",
      "epoch:5 step:4691 [D loss: 0.654960, acc.: 59.38%] [G loss: 0.938114]\n",
      "epoch:5 step:4692 [D loss: 0.635019, acc.: 65.62%] [G loss: 1.119588]\n",
      "epoch:5 step:4693 [D loss: 0.658541, acc.: 61.72%] [G loss: 1.039882]\n",
      "epoch:5 step:4694 [D loss: 0.663455, acc.: 64.84%] [G loss: 1.153499]\n",
      "epoch:5 step:4695 [D loss: 0.631385, acc.: 65.62%] [G loss: 0.963397]\n",
      "epoch:5 step:4696 [D loss: 0.647983, acc.: 62.50%] [G loss: 1.048064]\n",
      "epoch:5 step:4697 [D loss: 0.599658, acc.: 66.41%] [G loss: 0.955181]\n",
      "epoch:5 step:4698 [D loss: 0.640712, acc.: 65.62%] [G loss: 1.072759]\n",
      "epoch:5 step:4699 [D loss: 0.643440, acc.: 63.28%] [G loss: 1.082006]\n",
      "epoch:5 step:4700 [D loss: 0.568967, acc.: 75.00%] [G loss: 0.988447]\n",
      "epoch:5 step:4701 [D loss: 0.602577, acc.: 71.09%] [G loss: 1.044782]\n",
      "epoch:5 step:4702 [D loss: 0.679564, acc.: 56.25%] [G loss: 1.113659]\n",
      "epoch:5 step:4703 [D loss: 0.739069, acc.: 49.22%] [G loss: 0.867606]\n",
      "epoch:5 step:4704 [D loss: 0.681807, acc.: 59.38%] [G loss: 0.924214]\n",
      "epoch:5 step:4705 [D loss: 0.736317, acc.: 51.56%] [G loss: 0.915579]\n",
      "epoch:5 step:4706 [D loss: 0.640316, acc.: 67.97%] [G loss: 0.893003]\n",
      "epoch:5 step:4707 [D loss: 0.731846, acc.: 53.12%] [G loss: 0.811308]\n",
      "epoch:5 step:4708 [D loss: 0.607929, acc.: 62.50%] [G loss: 0.887113]\n",
      "epoch:5 step:4709 [D loss: 0.658180, acc.: 61.72%] [G loss: 1.006994]\n",
      "epoch:5 step:4710 [D loss: 0.595853, acc.: 70.31%] [G loss: 0.972995]\n",
      "epoch:5 step:4711 [D loss: 0.655457, acc.: 58.59%] [G loss: 1.124279]\n",
      "epoch:5 step:4712 [D loss: 0.627328, acc.: 64.06%] [G loss: 0.940299]\n",
      "epoch:5 step:4713 [D loss: 0.621304, acc.: 64.84%] [G loss: 0.921944]\n",
      "epoch:5 step:4714 [D loss: 0.553884, acc.: 75.78%] [G loss: 0.891693]\n",
      "epoch:5 step:4715 [D loss: 0.683320, acc.: 58.59%] [G loss: 1.032771]\n",
      "epoch:5 step:4716 [D loss: 0.637977, acc.: 61.72%] [G loss: 1.015161]\n",
      "epoch:5 step:4717 [D loss: 0.635467, acc.: 69.53%] [G loss: 0.965771]\n",
      "epoch:5 step:4718 [D loss: 0.635675, acc.: 61.72%] [G loss: 0.969389]\n",
      "epoch:5 step:4719 [D loss: 0.589576, acc.: 69.53%] [G loss: 0.856478]\n",
      "epoch:5 step:4720 [D loss: 0.676663, acc.: 60.94%] [G loss: 1.060987]\n",
      "epoch:5 step:4721 [D loss: 0.562933, acc.: 76.56%] [G loss: 1.148385]\n",
      "epoch:5 step:4722 [D loss: 0.646471, acc.: 63.28%] [G loss: 0.978333]\n",
      "epoch:5 step:4723 [D loss: 0.711599, acc.: 55.47%] [G loss: 0.959442]\n",
      "epoch:5 step:4724 [D loss: 0.617344, acc.: 67.97%] [G loss: 0.923591]\n",
      "epoch:5 step:4725 [D loss: 0.651927, acc.: 61.72%] [G loss: 0.820325]\n",
      "epoch:5 step:4726 [D loss: 0.616361, acc.: 63.28%] [G loss: 1.041238]\n",
      "epoch:5 step:4727 [D loss: 0.598891, acc.: 67.19%] [G loss: 1.000473]\n",
      "epoch:5 step:4728 [D loss: 0.644076, acc.: 63.28%] [G loss: 0.997519]\n",
      "epoch:5 step:4729 [D loss: 0.663871, acc.: 61.72%] [G loss: 1.007055]\n",
      "epoch:5 step:4730 [D loss: 0.733172, acc.: 55.47%] [G loss: 0.932492]\n",
      "epoch:5 step:4731 [D loss: 0.629361, acc.: 60.94%] [G loss: 0.999021]\n",
      "epoch:5 step:4732 [D loss: 0.562496, acc.: 72.66%] [G loss: 1.018441]\n",
      "epoch:5 step:4733 [D loss: 0.692779, acc.: 57.81%] [G loss: 1.064057]\n",
      "epoch:5 step:4734 [D loss: 0.675692, acc.: 60.94%] [G loss: 1.075514]\n",
      "epoch:5 step:4735 [D loss: 0.634468, acc.: 65.62%] [G loss: 0.935899]\n",
      "epoch:5 step:4736 [D loss: 0.700235, acc.: 57.81%] [G loss: 0.943670]\n",
      "epoch:5 step:4737 [D loss: 0.632220, acc.: 65.62%] [G loss: 0.989556]\n",
      "epoch:5 step:4738 [D loss: 0.600166, acc.: 65.62%] [G loss: 1.024837]\n",
      "epoch:5 step:4739 [D loss: 0.635837, acc.: 62.50%] [G loss: 0.925650]\n",
      "epoch:5 step:4740 [D loss: 0.599147, acc.: 67.97%] [G loss: 0.870459]\n",
      "epoch:5 step:4741 [D loss: 0.687772, acc.: 57.81%] [G loss: 0.964670]\n",
      "epoch:5 step:4742 [D loss: 0.623642, acc.: 64.06%] [G loss: 1.026297]\n",
      "epoch:5 step:4743 [D loss: 0.636713, acc.: 60.94%] [G loss: 0.994918]\n",
      "epoch:5 step:4744 [D loss: 0.687115, acc.: 53.12%] [G loss: 0.901874]\n",
      "epoch:5 step:4745 [D loss: 0.689409, acc.: 59.38%] [G loss: 0.906600]\n",
      "epoch:5 step:4746 [D loss: 0.654369, acc.: 62.50%] [G loss: 0.936689]\n",
      "epoch:5 step:4747 [D loss: 0.674143, acc.: 60.16%] [G loss: 0.909962]\n",
      "epoch:5 step:4748 [D loss: 0.590876, acc.: 70.31%] [G loss: 1.008204]\n",
      "epoch:5 step:4749 [D loss: 0.677944, acc.: 60.94%] [G loss: 0.979756]\n",
      "epoch:5 step:4750 [D loss: 0.639360, acc.: 60.16%] [G loss: 0.982157]\n",
      "epoch:5 step:4751 [D loss: 0.609214, acc.: 64.06%] [G loss: 0.923513]\n",
      "epoch:5 step:4752 [D loss: 0.630451, acc.: 66.41%] [G loss: 0.907610]\n",
      "epoch:5 step:4753 [D loss: 0.665963, acc.: 60.94%] [G loss: 0.940159]\n",
      "epoch:5 step:4754 [D loss: 0.669668, acc.: 59.38%] [G loss: 0.948575]\n",
      "epoch:5 step:4755 [D loss: 0.705577, acc.: 55.47%] [G loss: 0.917269]\n",
      "epoch:5 step:4756 [D loss: 0.553295, acc.: 73.44%] [G loss: 1.098529]\n",
      "epoch:5 step:4757 [D loss: 0.620791, acc.: 64.84%] [G loss: 1.030234]\n",
      "epoch:5 step:4758 [D loss: 0.697178, acc.: 55.47%] [G loss: 0.948681]\n",
      "epoch:5 step:4759 [D loss: 0.614398, acc.: 67.97%] [G loss: 1.016403]\n",
      "epoch:5 step:4760 [D loss: 0.550403, acc.: 71.09%] [G loss: 1.026505]\n",
      "epoch:5 step:4761 [D loss: 0.560879, acc.: 73.44%] [G loss: 1.179679]\n",
      "epoch:5 step:4762 [D loss: 0.554257, acc.: 74.22%] [G loss: 1.076751]\n",
      "epoch:5 step:4763 [D loss: 0.714372, acc.: 57.03%] [G loss: 1.122429]\n",
      "epoch:5 step:4764 [D loss: 0.693021, acc.: 60.94%] [G loss: 0.997667]\n",
      "epoch:5 step:4765 [D loss: 0.668763, acc.: 58.59%] [G loss: 0.936320]\n",
      "epoch:5 step:4766 [D loss: 0.784888, acc.: 45.31%] [G loss: 0.793038]\n",
      "epoch:5 step:4767 [D loss: 0.675002, acc.: 57.03%] [G loss: 0.936261]\n",
      "epoch:5 step:4768 [D loss: 0.635167, acc.: 60.16%] [G loss: 0.967709]\n",
      "epoch:5 step:4769 [D loss: 0.709385, acc.: 59.38%] [G loss: 0.968268]\n",
      "epoch:5 step:4770 [D loss: 0.713188, acc.: 52.34%] [G loss: 0.870265]\n",
      "epoch:5 step:4771 [D loss: 0.660941, acc.: 58.59%] [G loss: 1.004742]\n",
      "epoch:5 step:4772 [D loss: 0.628530, acc.: 68.75%] [G loss: 0.947182]\n",
      "epoch:5 step:4773 [D loss: 0.558036, acc.: 73.44%] [G loss: 1.123099]\n",
      "epoch:5 step:4774 [D loss: 0.635914, acc.: 63.28%] [G loss: 0.896383]\n",
      "epoch:5 step:4775 [D loss: 0.626659, acc.: 67.19%] [G loss: 0.952736]\n",
      "epoch:5 step:4776 [D loss: 0.733739, acc.: 56.25%] [G loss: 0.943831]\n",
      "epoch:5 step:4777 [D loss: 0.633190, acc.: 60.94%] [G loss: 0.942948]\n",
      "epoch:5 step:4778 [D loss: 0.696277, acc.: 51.56%] [G loss: 0.923007]\n",
      "epoch:5 step:4779 [D loss: 0.658146, acc.: 59.38%] [G loss: 1.035426]\n",
      "epoch:5 step:4780 [D loss: 0.630156, acc.: 66.41%] [G loss: 1.072768]\n",
      "epoch:5 step:4781 [D loss: 0.591622, acc.: 67.19%] [G loss: 0.946361]\n",
      "epoch:5 step:4782 [D loss: 0.689214, acc.: 60.94%] [G loss: 0.931185]\n",
      "epoch:5 step:4783 [D loss: 0.657758, acc.: 59.38%] [G loss: 0.998548]\n",
      "epoch:5 step:4784 [D loss: 0.634852, acc.: 64.84%] [G loss: 0.904543]\n",
      "epoch:5 step:4785 [D loss: 0.602868, acc.: 68.75%] [G loss: 0.908090]\n",
      "epoch:5 step:4786 [D loss: 0.677025, acc.: 54.69%] [G loss: 0.959347]\n",
      "epoch:5 step:4787 [D loss: 0.681109, acc.: 56.25%] [G loss: 0.982523]\n",
      "epoch:5 step:4788 [D loss: 0.552505, acc.: 72.66%] [G loss: 1.139709]\n",
      "epoch:5 step:4789 [D loss: 0.647716, acc.: 58.59%] [G loss: 1.151904]\n",
      "epoch:5 step:4790 [D loss: 0.702957, acc.: 57.81%] [G loss: 1.052043]\n",
      "epoch:5 step:4791 [D loss: 0.643658, acc.: 59.38%] [G loss: 0.993680]\n",
      "epoch:5 step:4792 [D loss: 0.708614, acc.: 58.59%] [G loss: 1.048468]\n",
      "epoch:5 step:4793 [D loss: 0.773284, acc.: 46.88%] [G loss: 0.821509]\n",
      "epoch:5 step:4794 [D loss: 0.669065, acc.: 62.50%] [G loss: 0.906726]\n",
      "epoch:5 step:4795 [D loss: 0.618549, acc.: 68.75%] [G loss: 0.940441]\n",
      "epoch:5 step:4796 [D loss: 0.627085, acc.: 63.28%] [G loss: 0.881165]\n",
      "epoch:5 step:4797 [D loss: 0.676603, acc.: 56.25%] [G loss: 1.015856]\n",
      "epoch:5 step:4798 [D loss: 0.651475, acc.: 59.38%] [G loss: 1.019761]\n",
      "epoch:5 step:4799 [D loss: 0.677753, acc.: 59.38%] [G loss: 0.995999]\n",
      "epoch:5 step:4800 [D loss: 0.637787, acc.: 63.28%] [G loss: 0.940845]\n",
      "epoch:5 step:4801 [D loss: 0.639806, acc.: 64.06%] [G loss: 1.049213]\n",
      "epoch:5 step:4802 [D loss: 0.655842, acc.: 60.94%] [G loss: 1.141838]\n",
      "epoch:5 step:4803 [D loss: 0.713405, acc.: 53.12%] [G loss: 0.920385]\n",
      "epoch:5 step:4804 [D loss: 0.641730, acc.: 60.94%] [G loss: 0.992586]\n",
      "epoch:5 step:4805 [D loss: 0.675832, acc.: 63.28%] [G loss: 0.902394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4806 [D loss: 0.676191, acc.: 60.16%] [G loss: 0.924348]\n",
      "epoch:5 step:4807 [D loss: 0.734879, acc.: 49.22%] [G loss: 0.898194]\n",
      "epoch:5 step:4808 [D loss: 0.672726, acc.: 58.59%] [G loss: 0.988145]\n",
      "epoch:5 step:4809 [D loss: 0.676891, acc.: 55.47%] [G loss: 0.935139]\n",
      "epoch:5 step:4810 [D loss: 0.620864, acc.: 64.84%] [G loss: 1.018279]\n",
      "epoch:5 step:4811 [D loss: 0.684022, acc.: 55.47%] [G loss: 0.946886]\n",
      "epoch:5 step:4812 [D loss: 0.629389, acc.: 64.84%] [G loss: 0.907357]\n",
      "epoch:5 step:4813 [D loss: 0.677333, acc.: 57.81%] [G loss: 0.960536]\n",
      "epoch:5 step:4814 [D loss: 0.695873, acc.: 55.47%] [G loss: 0.895500]\n",
      "epoch:5 step:4815 [D loss: 0.626351, acc.: 64.06%] [G loss: 0.945909]\n",
      "epoch:5 step:4816 [D loss: 0.649739, acc.: 64.84%] [G loss: 0.986016]\n",
      "epoch:5 step:4817 [D loss: 0.659552, acc.: 64.06%] [G loss: 0.931145]\n",
      "epoch:5 step:4818 [D loss: 0.680886, acc.: 57.81%] [G loss: 1.074911]\n",
      "epoch:5 step:4819 [D loss: 0.663277, acc.: 59.38%] [G loss: 0.954430]\n",
      "epoch:5 step:4820 [D loss: 0.684483, acc.: 57.03%] [G loss: 0.856731]\n",
      "epoch:5 step:4821 [D loss: 0.651939, acc.: 57.03%] [G loss: 0.896776]\n",
      "epoch:5 step:4822 [D loss: 0.692175, acc.: 55.47%] [G loss: 0.962040]\n",
      "epoch:5 step:4823 [D loss: 0.760697, acc.: 48.44%] [G loss: 0.885531]\n",
      "epoch:5 step:4824 [D loss: 0.711308, acc.: 54.69%] [G loss: 1.007286]\n",
      "epoch:5 step:4825 [D loss: 0.667625, acc.: 62.50%] [G loss: 0.866611]\n",
      "epoch:5 step:4826 [D loss: 0.657113, acc.: 60.94%] [G loss: 0.891473]\n",
      "epoch:5 step:4827 [D loss: 0.603451, acc.: 67.19%] [G loss: 1.008477]\n",
      "epoch:5 step:4828 [D loss: 0.694350, acc.: 52.34%] [G loss: 0.960822]\n",
      "epoch:5 step:4829 [D loss: 0.622251, acc.: 70.31%] [G loss: 1.017629]\n",
      "epoch:5 step:4830 [D loss: 0.702660, acc.: 54.69%] [G loss: 0.944996]\n",
      "epoch:5 step:4831 [D loss: 0.678204, acc.: 58.59%] [G loss: 0.949004]\n",
      "epoch:5 step:4832 [D loss: 0.697944, acc.: 56.25%] [G loss: 0.994878]\n",
      "epoch:5 step:4833 [D loss: 0.712999, acc.: 53.12%] [G loss: 0.898513]\n",
      "epoch:5 step:4834 [D loss: 0.688504, acc.: 57.03%] [G loss: 0.940496]\n",
      "epoch:5 step:4835 [D loss: 0.650954, acc.: 59.38%] [G loss: 0.893727]\n",
      "epoch:5 step:4836 [D loss: 0.671697, acc.: 53.12%] [G loss: 0.853465]\n",
      "epoch:5 step:4837 [D loss: 0.589014, acc.: 69.53%] [G loss: 0.911779]\n",
      "epoch:5 step:4838 [D loss: 0.662888, acc.: 61.72%] [G loss: 0.864812]\n",
      "epoch:5 step:4839 [D loss: 0.674200, acc.: 60.16%] [G loss: 1.038023]\n",
      "epoch:5 step:4840 [D loss: 0.634253, acc.: 59.38%] [G loss: 0.944164]\n",
      "epoch:5 step:4841 [D loss: 0.679195, acc.: 54.69%] [G loss: 1.006961]\n",
      "epoch:5 step:4842 [D loss: 0.666012, acc.: 61.72%] [G loss: 0.898691]\n",
      "epoch:5 step:4843 [D loss: 0.697520, acc.: 54.69%] [G loss: 0.941670]\n",
      "epoch:5 step:4844 [D loss: 0.659735, acc.: 60.94%] [G loss: 1.000576]\n",
      "epoch:5 step:4845 [D loss: 0.741765, acc.: 45.31%] [G loss: 0.881542]\n",
      "epoch:5 step:4846 [D loss: 0.690719, acc.: 60.16%] [G loss: 0.897213]\n",
      "epoch:5 step:4847 [D loss: 0.622941, acc.: 64.06%] [G loss: 1.022243]\n",
      "epoch:5 step:4848 [D loss: 0.653465, acc.: 60.16%] [G loss: 0.925549]\n",
      "epoch:5 step:4849 [D loss: 0.614296, acc.: 65.62%] [G loss: 0.950416]\n",
      "epoch:5 step:4850 [D loss: 0.652352, acc.: 60.16%] [G loss: 0.940176]\n",
      "epoch:5 step:4851 [D loss: 0.631359, acc.: 64.84%] [G loss: 1.025071]\n",
      "epoch:5 step:4852 [D loss: 0.725268, acc.: 52.34%] [G loss: 0.970476]\n",
      "epoch:5 step:4853 [D loss: 0.640446, acc.: 64.06%] [G loss: 0.969152]\n",
      "epoch:5 step:4854 [D loss: 0.658455, acc.: 58.59%] [G loss: 0.931512]\n",
      "epoch:5 step:4855 [D loss: 0.649152, acc.: 58.59%] [G loss: 0.960718]\n",
      "epoch:5 step:4856 [D loss: 0.585026, acc.: 76.56%] [G loss: 0.945059]\n",
      "epoch:5 step:4857 [D loss: 0.645109, acc.: 61.72%] [G loss: 0.992086]\n",
      "epoch:5 step:4858 [D loss: 0.713191, acc.: 51.56%] [G loss: 0.934124]\n",
      "epoch:5 step:4859 [D loss: 0.704649, acc.: 53.91%] [G loss: 0.995231]\n",
      "epoch:5 step:4860 [D loss: 0.644650, acc.: 60.94%] [G loss: 1.093541]\n",
      "epoch:5 step:4861 [D loss: 0.673144, acc.: 60.94%] [G loss: 0.946417]\n",
      "epoch:5 step:4862 [D loss: 0.623534, acc.: 64.84%] [G loss: 0.959680]\n",
      "epoch:5 step:4863 [D loss: 0.621344, acc.: 61.72%] [G loss: 0.997540]\n",
      "epoch:5 step:4864 [D loss: 0.668866, acc.: 62.50%] [G loss: 1.034640]\n",
      "epoch:5 step:4865 [D loss: 0.689307, acc.: 59.38%] [G loss: 0.834758]\n",
      "epoch:5 step:4866 [D loss: 0.785864, acc.: 46.88%] [G loss: 0.897573]\n",
      "epoch:5 step:4867 [D loss: 0.753050, acc.: 47.66%] [G loss: 0.882118]\n",
      "epoch:5 step:4868 [D loss: 0.718741, acc.: 56.25%] [G loss: 0.958627]\n",
      "epoch:5 step:4869 [D loss: 0.753956, acc.: 48.44%] [G loss: 0.956647]\n",
      "epoch:5 step:4870 [D loss: 0.672070, acc.: 60.16%] [G loss: 1.039032]\n",
      "epoch:5 step:4871 [D loss: 0.656374, acc.: 64.06%] [G loss: 0.999377]\n",
      "epoch:5 step:4872 [D loss: 0.676652, acc.: 60.16%] [G loss: 0.796985]\n",
      "epoch:5 step:4873 [D loss: 0.677231, acc.: 58.59%] [G loss: 0.943026]\n",
      "epoch:5 step:4874 [D loss: 0.651722, acc.: 60.94%] [G loss: 0.886997]\n",
      "epoch:5 step:4875 [D loss: 0.614831, acc.: 67.97%] [G loss: 0.921898]\n",
      "epoch:5 step:4876 [D loss: 0.621041, acc.: 64.84%] [G loss: 0.997733]\n",
      "epoch:5 step:4877 [D loss: 0.562421, acc.: 74.22%] [G loss: 1.005318]\n",
      "epoch:5 step:4878 [D loss: 0.710645, acc.: 58.59%] [G loss: 0.913661]\n",
      "epoch:5 step:4879 [D loss: 0.610672, acc.: 67.19%] [G loss: 1.043790]\n",
      "epoch:5 step:4880 [D loss: 0.715671, acc.: 53.12%] [G loss: 0.823549]\n",
      "epoch:5 step:4881 [D loss: 0.696948, acc.: 60.94%] [G loss: 1.072160]\n",
      "epoch:5 step:4882 [D loss: 0.634132, acc.: 64.84%] [G loss: 0.891491]\n",
      "epoch:5 step:4883 [D loss: 0.623185, acc.: 64.84%] [G loss: 1.092579]\n",
      "epoch:5 step:4884 [D loss: 0.671797, acc.: 60.16%] [G loss: 0.748653]\n",
      "epoch:5 step:4885 [D loss: 0.770212, acc.: 47.66%] [G loss: 0.906378]\n",
      "epoch:5 step:4886 [D loss: 0.675982, acc.: 58.59%] [G loss: 0.905839]\n",
      "epoch:5 step:4887 [D loss: 0.662649, acc.: 60.94%] [G loss: 1.013929]\n",
      "epoch:5 step:4888 [D loss: 0.711764, acc.: 53.12%] [G loss: 0.869806]\n",
      "epoch:5 step:4889 [D loss: 0.601139, acc.: 66.41%] [G loss: 0.983062]\n",
      "epoch:5 step:4890 [D loss: 0.718883, acc.: 55.47%] [G loss: 0.866244]\n",
      "epoch:5 step:4891 [D loss: 0.661204, acc.: 57.03%] [G loss: 0.915035]\n",
      "epoch:5 step:4892 [D loss: 0.651455, acc.: 61.72%] [G loss: 1.033345]\n",
      "epoch:5 step:4893 [D loss: 0.605015, acc.: 63.28%] [G loss: 1.057605]\n",
      "epoch:5 step:4894 [D loss: 0.595907, acc.: 71.09%] [G loss: 1.005205]\n",
      "epoch:5 step:4895 [D loss: 0.623131, acc.: 67.97%] [G loss: 1.056173]\n",
      "epoch:5 step:4896 [D loss: 0.704718, acc.: 53.12%] [G loss: 0.873140]\n",
      "epoch:5 step:4897 [D loss: 0.605730, acc.: 67.19%] [G loss: 1.096576]\n",
      "epoch:5 step:4898 [D loss: 0.726588, acc.: 49.22%] [G loss: 0.842499]\n",
      "epoch:5 step:4899 [D loss: 0.667359, acc.: 55.47%] [G loss: 1.010748]\n",
      "epoch:5 step:4900 [D loss: 0.738857, acc.: 53.91%] [G loss: 0.982711]\n",
      "epoch:5 step:4901 [D loss: 0.668803, acc.: 61.72%] [G loss: 1.022119]\n",
      "epoch:5 step:4902 [D loss: 0.662891, acc.: 57.81%] [G loss: 1.014503]\n",
      "epoch:5 step:4903 [D loss: 0.584435, acc.: 71.88%] [G loss: 0.944743]\n",
      "epoch:5 step:4904 [D loss: 0.657023, acc.: 60.94%] [G loss: 1.013402]\n",
      "epoch:5 step:4905 [D loss: 0.754929, acc.: 47.66%] [G loss: 0.778751]\n",
      "epoch:5 step:4906 [D loss: 0.650576, acc.: 56.25%] [G loss: 0.993141]\n",
      "epoch:5 step:4907 [D loss: 0.628212, acc.: 64.06%] [G loss: 0.951436]\n",
      "epoch:5 step:4908 [D loss: 0.647212, acc.: 60.94%] [G loss: 0.999441]\n",
      "epoch:5 step:4909 [D loss: 0.717319, acc.: 53.91%] [G loss: 0.889731]\n",
      "epoch:5 step:4910 [D loss: 0.677995, acc.: 59.38%] [G loss: 0.923627]\n",
      "epoch:5 step:4911 [D loss: 0.728498, acc.: 50.00%] [G loss: 0.852526]\n",
      "epoch:5 step:4912 [D loss: 0.693350, acc.: 55.47%] [G loss: 0.970706]\n",
      "epoch:5 step:4913 [D loss: 0.716249, acc.: 53.91%] [G loss: 0.900598]\n",
      "epoch:5 step:4914 [D loss: 0.628963, acc.: 62.50%] [G loss: 0.969066]\n",
      "epoch:5 step:4915 [D loss: 0.627439, acc.: 64.84%] [G loss: 0.926162]\n",
      "epoch:5 step:4916 [D loss: 0.594204, acc.: 70.31%] [G loss: 0.998622]\n",
      "epoch:5 step:4917 [D loss: 0.540052, acc.: 75.00%] [G loss: 1.070942]\n",
      "epoch:5 step:4918 [D loss: 0.625175, acc.: 65.62%] [G loss: 1.057475]\n",
      "epoch:5 step:4919 [D loss: 0.710095, acc.: 57.03%] [G loss: 0.917354]\n",
      "epoch:5 step:4920 [D loss: 0.601868, acc.: 68.75%] [G loss: 0.982915]\n",
      "epoch:5 step:4921 [D loss: 0.665711, acc.: 61.72%] [G loss: 0.924715]\n",
      "epoch:5 step:4922 [D loss: 0.697965, acc.: 57.03%] [G loss: 1.023642]\n",
      "epoch:5 step:4923 [D loss: 0.705857, acc.: 52.34%] [G loss: 0.895453]\n",
      "epoch:5 step:4924 [D loss: 0.747901, acc.: 46.09%] [G loss: 0.896080]\n",
      "epoch:5 step:4925 [D loss: 0.619425, acc.: 65.62%] [G loss: 0.923470]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4926 [D loss: 0.684374, acc.: 54.69%] [G loss: 0.919583]\n",
      "epoch:5 step:4927 [D loss: 0.700151, acc.: 53.91%] [G loss: 0.892669]\n",
      "epoch:5 step:4928 [D loss: 0.656381, acc.: 60.16%] [G loss: 1.044164]\n",
      "epoch:5 step:4929 [D loss: 0.603148, acc.: 71.88%] [G loss: 1.025696]\n",
      "epoch:5 step:4930 [D loss: 0.627814, acc.: 64.84%] [G loss: 1.040276]\n",
      "epoch:5 step:4931 [D loss: 0.663924, acc.: 60.16%] [G loss: 1.003349]\n",
      "epoch:5 step:4932 [D loss: 0.684219, acc.: 60.16%] [G loss: 0.898117]\n",
      "epoch:5 step:4933 [D loss: 0.665873, acc.: 60.94%] [G loss: 0.927133]\n",
      "epoch:5 step:4934 [D loss: 0.699195, acc.: 53.91%] [G loss: 0.965716]\n",
      "epoch:5 step:4935 [D loss: 0.745429, acc.: 52.34%] [G loss: 0.963149]\n",
      "epoch:5 step:4936 [D loss: 0.671681, acc.: 60.16%] [G loss: 0.914458]\n",
      "epoch:5 step:4937 [D loss: 0.681330, acc.: 56.25%] [G loss: 0.946299]\n",
      "epoch:5 step:4938 [D loss: 0.679855, acc.: 60.16%] [G loss: 0.947830]\n",
      "epoch:5 step:4939 [D loss: 0.607863, acc.: 64.06%] [G loss: 1.040559]\n",
      "epoch:5 step:4940 [D loss: 0.710178, acc.: 59.38%] [G loss: 0.924339]\n",
      "epoch:5 step:4941 [D loss: 0.682400, acc.: 60.16%] [G loss: 0.973616]\n",
      "epoch:5 step:4942 [D loss: 0.671095, acc.: 58.59%] [G loss: 0.870505]\n",
      "epoch:5 step:4943 [D loss: 0.670768, acc.: 60.16%] [G loss: 0.915039]\n",
      "epoch:5 step:4944 [D loss: 0.643933, acc.: 59.38%] [G loss: 0.933797]\n",
      "epoch:5 step:4945 [D loss: 0.672622, acc.: 62.50%] [G loss: 0.952845]\n",
      "epoch:5 step:4946 [D loss: 0.582796, acc.: 67.19%] [G loss: 0.993887]\n",
      "epoch:5 step:4947 [D loss: 0.604285, acc.: 67.19%] [G loss: 0.886820]\n",
      "epoch:5 step:4948 [D loss: 0.638614, acc.: 59.38%] [G loss: 1.054239]\n",
      "epoch:5 step:4949 [D loss: 0.668032, acc.: 58.59%] [G loss: 0.981692]\n",
      "epoch:5 step:4950 [D loss: 0.678986, acc.: 53.91%] [G loss: 0.944403]\n",
      "epoch:5 step:4951 [D loss: 0.628448, acc.: 61.72%] [G loss: 0.967649]\n",
      "epoch:5 step:4952 [D loss: 0.691144, acc.: 53.91%] [G loss: 0.905134]\n",
      "epoch:5 step:4953 [D loss: 0.676440, acc.: 61.72%] [G loss: 0.906524]\n",
      "epoch:5 step:4954 [D loss: 0.687941, acc.: 55.47%] [G loss: 0.874941]\n",
      "epoch:5 step:4955 [D loss: 0.693553, acc.: 57.03%] [G loss: 1.014718]\n",
      "epoch:5 step:4956 [D loss: 0.669809, acc.: 59.38%] [G loss: 0.984827]\n",
      "epoch:5 step:4957 [D loss: 0.618414, acc.: 70.31%] [G loss: 1.067788]\n",
      "epoch:5 step:4958 [D loss: 0.634268, acc.: 60.16%] [G loss: 1.050482]\n",
      "epoch:5 step:4959 [D loss: 0.635667, acc.: 63.28%] [G loss: 0.936903]\n",
      "epoch:5 step:4960 [D loss: 0.709294, acc.: 52.34%] [G loss: 0.959386]\n",
      "epoch:5 step:4961 [D loss: 0.712281, acc.: 57.81%] [G loss: 0.993797]\n",
      "epoch:5 step:4962 [D loss: 0.720741, acc.: 53.12%] [G loss: 0.953940]\n",
      "epoch:5 step:4963 [D loss: 0.709770, acc.: 53.91%] [G loss: 0.958721]\n",
      "epoch:5 step:4964 [D loss: 0.663844, acc.: 60.16%] [G loss: 0.897723]\n",
      "epoch:5 step:4965 [D loss: 0.581200, acc.: 71.09%] [G loss: 0.953005]\n",
      "epoch:5 step:4966 [D loss: 0.648197, acc.: 60.16%] [G loss: 1.024772]\n",
      "epoch:5 step:4967 [D loss: 0.678153, acc.: 57.03%] [G loss: 0.926453]\n",
      "epoch:5 step:4968 [D loss: 0.676766, acc.: 58.59%] [G loss: 1.022850]\n",
      "epoch:5 step:4969 [D loss: 0.682359, acc.: 54.69%] [G loss: 0.852774]\n",
      "epoch:5 step:4970 [D loss: 0.666209, acc.: 60.16%] [G loss: 0.968689]\n",
      "epoch:5 step:4971 [D loss: 0.578350, acc.: 65.62%] [G loss: 1.133679]\n",
      "epoch:5 step:4972 [D loss: 0.680233, acc.: 61.72%] [G loss: 1.015169]\n",
      "epoch:5 step:4973 [D loss: 0.792680, acc.: 47.66%] [G loss: 0.865620]\n",
      "epoch:5 step:4974 [D loss: 0.629581, acc.: 60.94%] [G loss: 1.062979]\n",
      "epoch:5 step:4975 [D loss: 0.620350, acc.: 64.84%] [G loss: 0.932452]\n",
      "epoch:5 step:4976 [D loss: 0.702466, acc.: 57.81%] [G loss: 0.915770]\n",
      "epoch:5 step:4977 [D loss: 0.632451, acc.: 63.28%] [G loss: 0.953970]\n",
      "epoch:5 step:4978 [D loss: 0.563935, acc.: 68.75%] [G loss: 1.043686]\n",
      "epoch:5 step:4979 [D loss: 0.673806, acc.: 60.16%] [G loss: 0.936992]\n",
      "epoch:5 step:4980 [D loss: 0.677607, acc.: 52.34%] [G loss: 0.930443]\n",
      "epoch:5 step:4981 [D loss: 0.619349, acc.: 66.41%] [G loss: 0.992684]\n",
      "epoch:5 step:4982 [D loss: 0.651511, acc.: 64.84%] [G loss: 1.029000]\n",
      "epoch:5 step:4983 [D loss: 0.708411, acc.: 53.91%] [G loss: 0.934342]\n",
      "epoch:5 step:4984 [D loss: 0.630603, acc.: 66.41%] [G loss: 1.002993]\n",
      "epoch:5 step:4985 [D loss: 0.714120, acc.: 57.81%] [G loss: 0.918154]\n",
      "epoch:5 step:4986 [D loss: 0.726599, acc.: 50.78%] [G loss: 0.983152]\n",
      "epoch:5 step:4987 [D loss: 0.621249, acc.: 59.38%] [G loss: 1.043070]\n",
      "epoch:5 step:4988 [D loss: 0.704235, acc.: 63.28%] [G loss: 0.967834]\n",
      "epoch:5 step:4989 [D loss: 0.651170, acc.: 66.41%] [G loss: 1.008624]\n",
      "epoch:5 step:4990 [D loss: 0.638023, acc.: 61.72%] [G loss: 1.030874]\n",
      "epoch:5 step:4991 [D loss: 0.566312, acc.: 71.88%] [G loss: 1.044642]\n",
      "epoch:5 step:4992 [D loss: 0.650891, acc.: 63.28%] [G loss: 0.935098]\n",
      "epoch:5 step:4993 [D loss: 0.633303, acc.: 60.94%] [G loss: 1.061152]\n",
      "epoch:5 step:4994 [D loss: 0.632184, acc.: 65.62%] [G loss: 0.991617]\n",
      "epoch:5 step:4995 [D loss: 0.674295, acc.: 58.59%] [G loss: 0.980275]\n",
      "epoch:5 step:4996 [D loss: 0.622440, acc.: 64.84%] [G loss: 0.952643]\n",
      "epoch:5 step:4997 [D loss: 0.631837, acc.: 61.72%] [G loss: 0.932161]\n",
      "epoch:5 step:4998 [D loss: 0.599464, acc.: 71.88%] [G loss: 1.088137]\n",
      "epoch:5 step:4999 [D loss: 0.563391, acc.: 70.31%] [G loss: 1.162019]\n",
      "epoch:5 step:5000 [D loss: 0.528463, acc.: 76.56%] [G loss: 1.103656]\n",
      "epoch:5 step:5001 [D loss: 0.707821, acc.: 55.47%] [G loss: 1.019363]\n",
      "epoch:5 step:5002 [D loss: 0.693867, acc.: 61.72%] [G loss: 0.901476]\n",
      "epoch:5 step:5003 [D loss: 0.622628, acc.: 67.97%] [G loss: 0.876105]\n",
      "epoch:5 step:5004 [D loss: 0.640761, acc.: 63.28%] [G loss: 0.940419]\n",
      "epoch:5 step:5005 [D loss: 0.614361, acc.: 63.28%] [G loss: 1.000265]\n",
      "epoch:5 step:5006 [D loss: 0.678477, acc.: 57.03%] [G loss: 0.886514]\n",
      "epoch:5 step:5007 [D loss: 0.748963, acc.: 50.78%] [G loss: 0.803447]\n",
      "epoch:5 step:5008 [D loss: 0.705632, acc.: 49.22%] [G loss: 0.828464]\n",
      "epoch:5 step:5009 [D loss: 0.620928, acc.: 63.28%] [G loss: 0.895963]\n",
      "epoch:5 step:5010 [D loss: 0.723471, acc.: 55.47%] [G loss: 0.847847]\n",
      "epoch:5 step:5011 [D loss: 0.663471, acc.: 57.81%] [G loss: 0.936172]\n",
      "epoch:5 step:5012 [D loss: 0.703220, acc.: 57.81%] [G loss: 0.819240]\n",
      "epoch:5 step:5013 [D loss: 0.593449, acc.: 68.75%] [G loss: 1.048075]\n",
      "epoch:5 step:5014 [D loss: 0.603819, acc.: 67.19%] [G loss: 1.014376]\n",
      "epoch:5 step:5015 [D loss: 0.651025, acc.: 62.50%] [G loss: 0.911306]\n",
      "epoch:5 step:5016 [D loss: 0.608564, acc.: 66.41%] [G loss: 1.046661]\n",
      "epoch:5 step:5017 [D loss: 0.643524, acc.: 64.84%] [G loss: 1.019583]\n",
      "epoch:5 step:5018 [D loss: 0.616562, acc.: 71.09%] [G loss: 1.016971]\n",
      "epoch:5 step:5019 [D loss: 0.710495, acc.: 52.34%] [G loss: 1.052654]\n",
      "epoch:5 step:5020 [D loss: 0.610085, acc.: 64.06%] [G loss: 0.958063]\n",
      "epoch:5 step:5021 [D loss: 0.569723, acc.: 71.09%] [G loss: 1.025709]\n",
      "epoch:5 step:5022 [D loss: 0.595573, acc.: 73.44%] [G loss: 0.989963]\n",
      "epoch:5 step:5023 [D loss: 0.644336, acc.: 60.94%] [G loss: 1.020919]\n",
      "epoch:5 step:5024 [D loss: 0.619548, acc.: 65.62%] [G loss: 1.081068]\n",
      "epoch:5 step:5025 [D loss: 0.629067, acc.: 64.84%] [G loss: 1.003741]\n",
      "epoch:5 step:5026 [D loss: 0.682354, acc.: 61.72%] [G loss: 0.949551]\n",
      "epoch:5 step:5027 [D loss: 0.683984, acc.: 59.38%] [G loss: 0.913590]\n",
      "epoch:5 step:5028 [D loss: 0.558505, acc.: 75.00%] [G loss: 0.863726]\n",
      "epoch:5 step:5029 [D loss: 0.601228, acc.: 70.31%] [G loss: 0.813888]\n",
      "epoch:5 step:5030 [D loss: 0.612423, acc.: 64.84%] [G loss: 0.990723]\n",
      "epoch:5 step:5031 [D loss: 0.657927, acc.: 59.38%] [G loss: 0.992235]\n",
      "epoch:5 step:5032 [D loss: 0.719010, acc.: 53.12%] [G loss: 0.853484]\n",
      "epoch:5 step:5033 [D loss: 0.679797, acc.: 60.94%] [G loss: 1.022865]\n",
      "epoch:5 step:5034 [D loss: 0.690825, acc.: 53.91%] [G loss: 1.003365]\n",
      "epoch:5 step:5035 [D loss: 0.620693, acc.: 71.09%] [G loss: 1.069481]\n",
      "epoch:5 step:5036 [D loss: 0.657569, acc.: 57.81%] [G loss: 0.892352]\n",
      "epoch:5 step:5037 [D loss: 0.628164, acc.: 62.50%] [G loss: 1.018804]\n",
      "epoch:5 step:5038 [D loss: 0.708434, acc.: 49.22%] [G loss: 0.978014]\n",
      "epoch:5 step:5039 [D loss: 0.660145, acc.: 57.81%] [G loss: 0.886019]\n",
      "epoch:5 step:5040 [D loss: 0.641428, acc.: 67.19%] [G loss: 0.850734]\n",
      "epoch:5 step:5041 [D loss: 0.680498, acc.: 58.59%] [G loss: 0.904831]\n",
      "epoch:5 step:5042 [D loss: 0.640822, acc.: 59.38%] [G loss: 0.983084]\n",
      "epoch:5 step:5043 [D loss: 0.603854, acc.: 66.41%] [G loss: 0.975394]\n",
      "epoch:5 step:5044 [D loss: 0.567324, acc.: 67.97%] [G loss: 0.924832]\n",
      "epoch:5 step:5045 [D loss: 0.601562, acc.: 67.97%] [G loss: 1.017575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5046 [D loss: 0.600755, acc.: 66.41%] [G loss: 1.029917]\n",
      "epoch:5 step:5047 [D loss: 0.693646, acc.: 60.94%] [G loss: 1.010292]\n",
      "epoch:5 step:5048 [D loss: 0.656167, acc.: 60.16%] [G loss: 0.933051]\n",
      "epoch:5 step:5049 [D loss: 0.620008, acc.: 66.41%] [G loss: 1.053823]\n",
      "epoch:5 step:5050 [D loss: 0.641632, acc.: 57.03%] [G loss: 0.954879]\n",
      "epoch:5 step:5051 [D loss: 0.655360, acc.: 60.16%] [G loss: 0.862966]\n",
      "epoch:5 step:5052 [D loss: 0.610531, acc.: 64.06%] [G loss: 0.936522]\n",
      "epoch:5 step:5053 [D loss: 0.645157, acc.: 62.50%] [G loss: 0.833637]\n",
      "epoch:5 step:5054 [D loss: 0.704713, acc.: 54.69%] [G loss: 1.027590]\n",
      "epoch:5 step:5055 [D loss: 0.688743, acc.: 57.03%] [G loss: 0.902976]\n",
      "epoch:5 step:5056 [D loss: 0.607808, acc.: 67.97%] [G loss: 1.009788]\n",
      "epoch:5 step:5057 [D loss: 0.643007, acc.: 60.94%] [G loss: 1.127748]\n",
      "epoch:5 step:5058 [D loss: 0.722510, acc.: 53.91%] [G loss: 0.955873]\n",
      "epoch:5 step:5059 [D loss: 0.638709, acc.: 64.06%] [G loss: 0.930847]\n",
      "epoch:5 step:5060 [D loss: 0.711830, acc.: 55.47%] [G loss: 0.930466]\n",
      "epoch:5 step:5061 [D loss: 0.766924, acc.: 46.09%] [G loss: 0.857733]\n",
      "epoch:5 step:5062 [D loss: 0.737922, acc.: 47.66%] [G loss: 1.032700]\n",
      "epoch:5 step:5063 [D loss: 0.649545, acc.: 69.53%] [G loss: 1.045679]\n",
      "epoch:5 step:5064 [D loss: 0.635632, acc.: 63.28%] [G loss: 1.008651]\n",
      "epoch:5 step:5065 [D loss: 0.600090, acc.: 68.75%] [G loss: 0.901126]\n",
      "epoch:5 step:5066 [D loss: 0.608306, acc.: 71.88%] [G loss: 1.039236]\n",
      "epoch:5 step:5067 [D loss: 0.653115, acc.: 60.94%] [G loss: 0.955147]\n",
      "epoch:5 step:5068 [D loss: 0.625663, acc.: 64.06%] [G loss: 1.001395]\n",
      "epoch:5 step:5069 [D loss: 0.639243, acc.: 59.38%] [G loss: 0.886147]\n",
      "epoch:5 step:5070 [D loss: 0.659317, acc.: 64.84%] [G loss: 1.028685]\n",
      "epoch:5 step:5071 [D loss: 0.664580, acc.: 60.16%] [G loss: 0.991760]\n",
      "epoch:5 step:5072 [D loss: 0.699470, acc.: 59.38%] [G loss: 0.922320]\n",
      "epoch:5 step:5073 [D loss: 0.650621, acc.: 61.72%] [G loss: 0.894590]\n",
      "epoch:5 step:5074 [D loss: 0.667625, acc.: 57.81%] [G loss: 0.900262]\n",
      "epoch:5 step:5075 [D loss: 0.704353, acc.: 55.47%] [G loss: 0.892943]\n",
      "epoch:5 step:5076 [D loss: 0.656631, acc.: 60.16%] [G loss: 0.974612]\n",
      "epoch:5 step:5077 [D loss: 0.703216, acc.: 56.25%] [G loss: 1.058570]\n",
      "epoch:5 step:5078 [D loss: 0.718647, acc.: 52.34%] [G loss: 0.941637]\n",
      "epoch:5 step:5079 [D loss: 0.639112, acc.: 59.38%] [G loss: 1.018201]\n",
      "epoch:5 step:5080 [D loss: 0.645458, acc.: 60.16%] [G loss: 0.992640]\n",
      "epoch:5 step:5081 [D loss: 0.697459, acc.: 58.59%] [G loss: 0.956873]\n",
      "epoch:5 step:5082 [D loss: 0.651574, acc.: 62.50%] [G loss: 0.945976]\n",
      "epoch:5 step:5083 [D loss: 0.588273, acc.: 69.53%] [G loss: 1.084043]\n",
      "epoch:5 step:5084 [D loss: 0.610454, acc.: 62.50%] [G loss: 1.114952]\n",
      "epoch:5 step:5085 [D loss: 0.700822, acc.: 57.03%] [G loss: 0.831606]\n",
      "epoch:5 step:5086 [D loss: 0.618827, acc.: 64.84%] [G loss: 1.013027]\n",
      "epoch:5 step:5087 [D loss: 0.658530, acc.: 62.50%] [G loss: 0.993665]\n",
      "epoch:5 step:5088 [D loss: 0.688854, acc.: 64.84%] [G loss: 1.012556]\n",
      "epoch:5 step:5089 [D loss: 0.616877, acc.: 67.19%] [G loss: 1.114192]\n",
      "epoch:5 step:5090 [D loss: 0.616498, acc.: 64.84%] [G loss: 1.052647]\n",
      "epoch:5 step:5091 [D loss: 0.611156, acc.: 68.75%] [G loss: 0.982588]\n",
      "epoch:5 step:5092 [D loss: 0.623920, acc.: 67.19%] [G loss: 0.994433]\n",
      "epoch:5 step:5093 [D loss: 0.672324, acc.: 61.72%] [G loss: 0.915370]\n",
      "epoch:5 step:5094 [D loss: 0.607928, acc.: 70.31%] [G loss: 0.974397]\n",
      "epoch:5 step:5095 [D loss: 0.638922, acc.: 61.72%] [G loss: 1.038439]\n",
      "epoch:5 step:5096 [D loss: 0.610803, acc.: 67.19%] [G loss: 0.894397]\n",
      "epoch:5 step:5097 [D loss: 0.690436, acc.: 54.69%] [G loss: 0.972039]\n",
      "epoch:5 step:5098 [D loss: 0.679220, acc.: 60.94%] [G loss: 0.917953]\n",
      "epoch:5 step:5099 [D loss: 0.746015, acc.: 51.56%] [G loss: 0.887946]\n",
      "epoch:5 step:5100 [D loss: 0.663694, acc.: 57.03%] [G loss: 1.007302]\n",
      "epoch:5 step:5101 [D loss: 0.599403, acc.: 71.09%] [G loss: 1.014756]\n",
      "epoch:5 step:5102 [D loss: 0.659220, acc.: 63.28%] [G loss: 0.918099]\n",
      "epoch:5 step:5103 [D loss: 0.667413, acc.: 63.28%] [G loss: 1.125885]\n",
      "epoch:5 step:5104 [D loss: 0.558404, acc.: 76.56%] [G loss: 0.971739]\n",
      "epoch:5 step:5105 [D loss: 0.625929, acc.: 62.50%] [G loss: 0.975491]\n",
      "epoch:5 step:5106 [D loss: 0.659838, acc.: 62.50%] [G loss: 0.975048]\n",
      "epoch:5 step:5107 [D loss: 0.678502, acc.: 57.03%] [G loss: 0.907564]\n",
      "epoch:5 step:5108 [D loss: 0.712574, acc.: 56.25%] [G loss: 0.924839]\n",
      "epoch:5 step:5109 [D loss: 0.631709, acc.: 62.50%] [G loss: 1.000696]\n",
      "epoch:5 step:5110 [D loss: 0.742414, acc.: 49.22%] [G loss: 0.902057]\n",
      "epoch:5 step:5111 [D loss: 0.597979, acc.: 71.09%] [G loss: 1.011418]\n",
      "epoch:5 step:5112 [D loss: 0.673169, acc.: 57.03%] [G loss: 0.986112]\n",
      "epoch:5 step:5113 [D loss: 0.638630, acc.: 60.16%] [G loss: 0.914292]\n",
      "epoch:5 step:5114 [D loss: 0.678428, acc.: 60.16%] [G loss: 1.033686]\n",
      "epoch:5 step:5115 [D loss: 0.558435, acc.: 78.12%] [G loss: 0.991638]\n",
      "epoch:5 step:5116 [D loss: 0.667813, acc.: 60.16%] [G loss: 1.012773]\n",
      "epoch:5 step:5117 [D loss: 0.769031, acc.: 45.31%] [G loss: 0.937716]\n",
      "epoch:5 step:5118 [D loss: 0.735506, acc.: 46.88%] [G loss: 0.943501]\n",
      "epoch:5 step:5119 [D loss: 0.640613, acc.: 60.94%] [G loss: 0.991854]\n",
      "epoch:5 step:5120 [D loss: 0.734088, acc.: 54.69%] [G loss: 0.913521]\n",
      "epoch:5 step:5121 [D loss: 0.716195, acc.: 57.81%] [G loss: 0.917650]\n",
      "epoch:5 step:5122 [D loss: 0.665303, acc.: 59.38%] [G loss: 0.979067]\n",
      "epoch:5 step:5123 [D loss: 0.648620, acc.: 61.72%] [G loss: 0.915229]\n",
      "epoch:5 step:5124 [D loss: 0.686441, acc.: 56.25%] [G loss: 1.020707]\n",
      "epoch:5 step:5125 [D loss: 0.596889, acc.: 69.53%] [G loss: 1.001852]\n",
      "epoch:5 step:5126 [D loss: 0.715423, acc.: 50.00%] [G loss: 1.034737]\n",
      "epoch:5 step:5127 [D loss: 0.644898, acc.: 61.72%] [G loss: 0.978375]\n",
      "epoch:5 step:5128 [D loss: 0.642142, acc.: 64.06%] [G loss: 0.993026]\n",
      "epoch:5 step:5129 [D loss: 0.650134, acc.: 63.28%] [G loss: 0.934601]\n",
      "epoch:5 step:5130 [D loss: 0.581470, acc.: 73.44%] [G loss: 0.959443]\n",
      "epoch:5 step:5131 [D loss: 0.707920, acc.: 53.91%] [G loss: 0.933276]\n",
      "epoch:5 step:5132 [D loss: 0.635221, acc.: 57.81%] [G loss: 0.960166]\n",
      "epoch:5 step:5133 [D loss: 0.676862, acc.: 67.19%] [G loss: 0.954091]\n",
      "epoch:5 step:5134 [D loss: 0.651690, acc.: 62.50%] [G loss: 1.035892]\n",
      "epoch:5 step:5135 [D loss: 0.716680, acc.: 56.25%] [G loss: 1.110013]\n",
      "epoch:5 step:5136 [D loss: 0.661268, acc.: 60.16%] [G loss: 1.080922]\n",
      "epoch:5 step:5137 [D loss: 0.653088, acc.: 62.50%] [G loss: 1.014249]\n",
      "epoch:5 step:5138 [D loss: 0.591764, acc.: 72.66%] [G loss: 1.047137]\n",
      "epoch:5 step:5139 [D loss: 0.655809, acc.: 57.81%] [G loss: 0.995826]\n",
      "epoch:5 step:5140 [D loss: 0.634654, acc.: 67.19%] [G loss: 0.970180]\n",
      "epoch:5 step:5141 [D loss: 0.679054, acc.: 56.25%] [G loss: 0.915316]\n",
      "epoch:5 step:5142 [D loss: 0.595065, acc.: 71.09%] [G loss: 1.072563]\n",
      "epoch:5 step:5143 [D loss: 0.740564, acc.: 54.69%] [G loss: 0.929860]\n",
      "epoch:5 step:5144 [D loss: 0.695255, acc.: 55.47%] [G loss: 0.946312]\n",
      "epoch:5 step:5145 [D loss: 0.622516, acc.: 62.50%] [G loss: 1.020097]\n",
      "epoch:5 step:5146 [D loss: 0.698098, acc.: 55.47%] [G loss: 0.932141]\n",
      "epoch:5 step:5147 [D loss: 0.691764, acc.: 55.47%] [G loss: 0.906841]\n",
      "epoch:5 step:5148 [D loss: 0.646642, acc.: 61.72%] [G loss: 0.920925]\n",
      "epoch:5 step:5149 [D loss: 0.631968, acc.: 62.50%] [G loss: 0.888983]\n",
      "epoch:5 step:5150 [D loss: 0.666430, acc.: 60.16%] [G loss: 1.028968]\n",
      "epoch:5 step:5151 [D loss: 0.625621, acc.: 63.28%] [G loss: 0.988303]\n",
      "epoch:5 step:5152 [D loss: 0.630437, acc.: 66.41%] [G loss: 1.064564]\n",
      "epoch:5 step:5153 [D loss: 0.653594, acc.: 64.06%] [G loss: 0.965165]\n",
      "epoch:5 step:5154 [D loss: 0.601158, acc.: 67.19%] [G loss: 1.134497]\n",
      "epoch:5 step:5155 [D loss: 0.621332, acc.: 69.53%] [G loss: 0.972692]\n",
      "epoch:5 step:5156 [D loss: 0.579400, acc.: 71.09%] [G loss: 1.174801]\n",
      "epoch:5 step:5157 [D loss: 0.647288, acc.: 63.28%] [G loss: 1.068139]\n",
      "epoch:5 step:5158 [D loss: 0.772154, acc.: 43.75%] [G loss: 0.879710]\n",
      "epoch:5 step:5159 [D loss: 0.674217, acc.: 58.59%] [G loss: 0.997483]\n",
      "epoch:5 step:5160 [D loss: 0.717280, acc.: 50.78%] [G loss: 1.039675]\n",
      "epoch:5 step:5161 [D loss: 0.639539, acc.: 60.94%] [G loss: 0.962553]\n",
      "epoch:5 step:5162 [D loss: 0.707868, acc.: 56.25%] [G loss: 0.973161]\n",
      "epoch:5 step:5163 [D loss: 0.693252, acc.: 59.38%] [G loss: 0.962804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5164 [D loss: 0.619088, acc.: 67.19%] [G loss: 0.995595]\n",
      "epoch:5 step:5165 [D loss: 0.640780, acc.: 63.28%] [G loss: 1.045602]\n",
      "epoch:5 step:5166 [D loss: 0.597232, acc.: 71.09%] [G loss: 1.095766]\n",
      "epoch:5 step:5167 [D loss: 0.685713, acc.: 58.59%] [G loss: 1.077842]\n",
      "epoch:5 step:5168 [D loss: 0.681298, acc.: 61.72%] [G loss: 0.917021]\n",
      "epoch:5 step:5169 [D loss: 0.663636, acc.: 57.81%] [G loss: 0.934466]\n",
      "epoch:5 step:5170 [D loss: 0.695227, acc.: 55.47%] [G loss: 0.979648]\n",
      "epoch:5 step:5171 [D loss: 0.681403, acc.: 58.59%] [G loss: 0.891646]\n",
      "epoch:5 step:5172 [D loss: 0.650670, acc.: 58.59%] [G loss: 0.851105]\n",
      "epoch:5 step:5173 [D loss: 0.693140, acc.: 56.25%] [G loss: 0.897174]\n",
      "epoch:5 step:5174 [D loss: 0.568655, acc.: 75.00%] [G loss: 0.969503]\n",
      "epoch:5 step:5175 [D loss: 0.629602, acc.: 60.16%] [G loss: 0.940278]\n",
      "epoch:5 step:5176 [D loss: 0.653794, acc.: 60.94%] [G loss: 0.947089]\n",
      "epoch:5 step:5177 [D loss: 0.718931, acc.: 53.91%] [G loss: 0.782117]\n",
      "epoch:5 step:5178 [D loss: 0.671164, acc.: 53.12%] [G loss: 0.890083]\n",
      "epoch:5 step:5179 [D loss: 0.700480, acc.: 56.25%] [G loss: 0.924397]\n",
      "epoch:5 step:5180 [D loss: 0.567610, acc.: 76.56%] [G loss: 1.025347]\n",
      "epoch:5 step:5181 [D loss: 0.743929, acc.: 53.12%] [G loss: 0.885696]\n",
      "epoch:5 step:5182 [D loss: 0.684643, acc.: 57.81%] [G loss: 0.899074]\n",
      "epoch:5 step:5183 [D loss: 0.607647, acc.: 67.97%] [G loss: 1.033405]\n",
      "epoch:5 step:5184 [D loss: 0.609940, acc.: 65.62%] [G loss: 0.929909]\n",
      "epoch:5 step:5185 [D loss: 0.601236, acc.: 67.19%] [G loss: 0.940068]\n",
      "epoch:5 step:5186 [D loss: 0.653056, acc.: 60.16%] [G loss: 1.032050]\n",
      "epoch:5 step:5187 [D loss: 0.693877, acc.: 57.03%] [G loss: 0.840999]\n",
      "epoch:5 step:5188 [D loss: 0.687099, acc.: 57.03%] [G loss: 0.915086]\n",
      "epoch:5 step:5189 [D loss: 0.684940, acc.: 63.28%] [G loss: 0.919327]\n",
      "epoch:5 step:5190 [D loss: 0.653813, acc.: 60.16%] [G loss: 0.964682]\n",
      "epoch:5 step:5191 [D loss: 0.695220, acc.: 57.81%] [G loss: 0.903473]\n",
      "epoch:5 step:5192 [D loss: 0.705273, acc.: 53.91%] [G loss: 0.908752]\n",
      "epoch:5 step:5193 [D loss: 0.678442, acc.: 59.38%] [G loss: 0.959068]\n",
      "epoch:5 step:5194 [D loss: 0.670434, acc.: 65.62%] [G loss: 1.067601]\n",
      "epoch:5 step:5195 [D loss: 0.685298, acc.: 57.03%] [G loss: 0.973118]\n",
      "epoch:5 step:5196 [D loss: 0.717147, acc.: 49.22%] [G loss: 0.962824]\n",
      "epoch:5 step:5197 [D loss: 0.692432, acc.: 57.81%] [G loss: 0.927885]\n",
      "epoch:5 step:5198 [D loss: 0.625471, acc.: 64.06%] [G loss: 1.001920]\n",
      "epoch:5 step:5199 [D loss: 0.630424, acc.: 55.47%] [G loss: 1.005741]\n",
      "epoch:5 step:5200 [D loss: 0.609943, acc.: 67.97%] [G loss: 0.796356]\n",
      "epoch:5 step:5201 [D loss: 0.657336, acc.: 60.16%] [G loss: 0.887322]\n",
      "epoch:5 step:5202 [D loss: 0.657024, acc.: 57.81%] [G loss: 0.957502]\n",
      "epoch:5 step:5203 [D loss: 0.710448, acc.: 55.47%] [G loss: 1.029325]\n",
      "epoch:5 step:5204 [D loss: 0.674034, acc.: 57.03%] [G loss: 0.924307]\n",
      "epoch:5 step:5205 [D loss: 0.630728, acc.: 65.62%] [G loss: 1.093671]\n",
      "epoch:5 step:5206 [D loss: 0.624113, acc.: 62.50%] [G loss: 1.020437]\n",
      "epoch:5 step:5207 [D loss: 0.581700, acc.: 68.75%] [G loss: 1.091977]\n",
      "epoch:5 step:5208 [D loss: 0.552714, acc.: 77.34%] [G loss: 0.939405]\n",
      "epoch:5 step:5209 [D loss: 0.736650, acc.: 54.69%] [G loss: 0.932052]\n",
      "epoch:5 step:5210 [D loss: 0.701265, acc.: 56.25%] [G loss: 0.982501]\n",
      "epoch:5 step:5211 [D loss: 0.693536, acc.: 57.81%] [G loss: 0.991735]\n",
      "epoch:5 step:5212 [D loss: 0.636474, acc.: 67.19%] [G loss: 1.081718]\n",
      "epoch:5 step:5213 [D loss: 0.752132, acc.: 50.00%] [G loss: 0.827105]\n",
      "epoch:5 step:5214 [D loss: 0.661921, acc.: 59.38%] [G loss: 0.839775]\n",
      "epoch:5 step:5215 [D loss: 0.693892, acc.: 59.38%] [G loss: 0.977547]\n",
      "epoch:5 step:5216 [D loss: 0.764669, acc.: 46.09%] [G loss: 0.945678]\n",
      "epoch:5 step:5217 [D loss: 0.630629, acc.: 60.94%] [G loss: 0.911019]\n",
      "epoch:5 step:5218 [D loss: 0.674645, acc.: 61.72%] [G loss: 0.879623]\n",
      "epoch:5 step:5219 [D loss: 0.597860, acc.: 66.41%] [G loss: 1.008385]\n",
      "epoch:5 step:5220 [D loss: 0.658920, acc.: 62.50%] [G loss: 0.959925]\n",
      "epoch:5 step:5221 [D loss: 0.628496, acc.: 67.19%] [G loss: 0.922885]\n",
      "epoch:5 step:5222 [D loss: 0.682273, acc.: 57.81%] [G loss: 1.049720]\n",
      "epoch:5 step:5223 [D loss: 0.629968, acc.: 66.41%] [G loss: 0.925859]\n",
      "epoch:5 step:5224 [D loss: 0.707574, acc.: 53.12%] [G loss: 0.926444]\n",
      "epoch:5 step:5225 [D loss: 0.656344, acc.: 60.94%] [G loss: 0.985052]\n",
      "epoch:5 step:5226 [D loss: 0.684765, acc.: 56.25%] [G loss: 0.978410]\n",
      "epoch:5 step:5227 [D loss: 0.693568, acc.: 56.25%] [G loss: 0.877394]\n",
      "epoch:5 step:5228 [D loss: 0.780849, acc.: 39.84%] [G loss: 0.786569]\n",
      "epoch:5 step:5229 [D loss: 0.690120, acc.: 57.81%] [G loss: 1.007159]\n",
      "epoch:5 step:5230 [D loss: 0.636658, acc.: 62.50%] [G loss: 0.918534]\n",
      "epoch:5 step:5231 [D loss: 0.629011, acc.: 62.50%] [G loss: 1.036665]\n",
      "epoch:5 step:5232 [D loss: 0.644394, acc.: 66.41%] [G loss: 1.068752]\n",
      "epoch:5 step:5233 [D loss: 0.633597, acc.: 61.72%] [G loss: 1.013142]\n",
      "epoch:5 step:5234 [D loss: 0.566037, acc.: 68.75%] [G loss: 0.949961]\n",
      "epoch:5 step:5235 [D loss: 0.596122, acc.: 71.09%] [G loss: 1.020592]\n",
      "epoch:5 step:5236 [D loss: 0.659329, acc.: 63.28%] [G loss: 1.064013]\n",
      "epoch:5 step:5237 [D loss: 0.599417, acc.: 70.31%] [G loss: 1.123911]\n",
      "epoch:5 step:5238 [D loss: 0.614275, acc.: 65.62%] [G loss: 1.029921]\n",
      "epoch:5 step:5239 [D loss: 0.631535, acc.: 65.62%] [G loss: 1.000540]\n",
      "epoch:5 step:5240 [D loss: 0.614890, acc.: 66.41%] [G loss: 1.002484]\n",
      "epoch:5 step:5241 [D loss: 0.599085, acc.: 70.31%] [G loss: 1.053863]\n",
      "epoch:5 step:5242 [D loss: 0.630911, acc.: 62.50%] [G loss: 1.068195]\n",
      "epoch:5 step:5243 [D loss: 0.663545, acc.: 65.62%] [G loss: 1.058599]\n",
      "epoch:5 step:5244 [D loss: 0.843116, acc.: 37.50%] [G loss: 0.948434]\n",
      "epoch:5 step:5245 [D loss: 0.740809, acc.: 51.56%] [G loss: 0.917122]\n",
      "epoch:5 step:5246 [D loss: 0.682748, acc.: 59.38%] [G loss: 1.028608]\n",
      "epoch:5 step:5247 [D loss: 0.688001, acc.: 60.16%] [G loss: 1.029197]\n",
      "epoch:5 step:5248 [D loss: 0.651667, acc.: 62.50%] [G loss: 1.030464]\n",
      "epoch:5 step:5249 [D loss: 0.697652, acc.: 60.16%] [G loss: 0.886481]\n",
      "epoch:5 step:5250 [D loss: 0.671057, acc.: 57.81%] [G loss: 0.995617]\n",
      "epoch:5 step:5251 [D loss: 0.655880, acc.: 66.41%] [G loss: 0.959528]\n",
      "epoch:5 step:5252 [D loss: 0.650745, acc.: 60.94%] [G loss: 0.880718]\n",
      "epoch:5 step:5253 [D loss: 0.635716, acc.: 57.81%] [G loss: 0.950337]\n",
      "epoch:5 step:5254 [D loss: 0.710812, acc.: 52.34%] [G loss: 0.910655]\n",
      "epoch:5 step:5255 [D loss: 0.668011, acc.: 53.91%] [G loss: 1.005987]\n",
      "epoch:5 step:5256 [D loss: 0.724269, acc.: 51.56%] [G loss: 0.868308]\n",
      "epoch:5 step:5257 [D loss: 0.671928, acc.: 57.81%] [G loss: 0.970917]\n",
      "epoch:5 step:5258 [D loss: 0.626775, acc.: 62.50%] [G loss: 1.033864]\n",
      "epoch:5 step:5259 [D loss: 0.671188, acc.: 66.41%] [G loss: 0.971501]\n",
      "epoch:5 step:5260 [D loss: 0.607399, acc.: 67.97%] [G loss: 0.924219]\n",
      "epoch:5 step:5261 [D loss: 0.705795, acc.: 55.47%] [G loss: 1.031075]\n",
      "epoch:5 step:5262 [D loss: 0.693099, acc.: 60.16%] [G loss: 0.940604]\n",
      "epoch:5 step:5263 [D loss: 0.658997, acc.: 57.81%] [G loss: 0.977746]\n",
      "epoch:5 step:5264 [D loss: 0.703522, acc.: 53.12%] [G loss: 0.985266]\n",
      "epoch:5 step:5265 [D loss: 0.668477, acc.: 58.59%] [G loss: 0.905996]\n",
      "epoch:5 step:5266 [D loss: 0.727930, acc.: 56.25%] [G loss: 0.932092]\n",
      "epoch:5 step:5267 [D loss: 0.648372, acc.: 64.06%] [G loss: 0.996678]\n",
      "epoch:5 step:5268 [D loss: 0.676880, acc.: 56.25%] [G loss: 0.853441]\n",
      "epoch:5 step:5269 [D loss: 0.677007, acc.: 59.38%] [G loss: 0.883120]\n",
      "epoch:5 step:5270 [D loss: 0.683732, acc.: 59.38%] [G loss: 0.886712]\n",
      "epoch:5 step:5271 [D loss: 0.594489, acc.: 66.41%] [G loss: 0.977169]\n",
      "epoch:5 step:5272 [D loss: 0.619982, acc.: 64.84%] [G loss: 1.033739]\n",
      "epoch:5 step:5273 [D loss: 0.633538, acc.: 67.19%] [G loss: 1.019885]\n",
      "epoch:5 step:5274 [D loss: 0.647591, acc.: 63.28%] [G loss: 1.072022]\n",
      "epoch:5 step:5275 [D loss: 0.695627, acc.: 59.38%] [G loss: 1.046971]\n",
      "epoch:5 step:5276 [D loss: 0.717402, acc.: 55.47%] [G loss: 0.907920]\n",
      "epoch:5 step:5277 [D loss: 0.688934, acc.: 53.91%] [G loss: 0.863594]\n",
      "epoch:5 step:5278 [D loss: 0.673780, acc.: 61.72%] [G loss: 1.076730]\n",
      "epoch:5 step:5279 [D loss: 0.614598, acc.: 64.06%] [G loss: 0.906743]\n",
      "epoch:5 step:5280 [D loss: 0.640013, acc.: 60.16%] [G loss: 1.006226]\n",
      "epoch:5 step:5281 [D loss: 0.712158, acc.: 53.91%] [G loss: 0.876289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5282 [D loss: 0.660446, acc.: 63.28%] [G loss: 0.919589]\n",
      "epoch:5 step:5283 [D loss: 0.681220, acc.: 55.47%] [G loss: 0.933384]\n",
      "epoch:5 step:5284 [D loss: 0.639631, acc.: 64.06%] [G loss: 0.873716]\n",
      "epoch:5 step:5285 [D loss: 0.672594, acc.: 57.81%] [G loss: 0.965086]\n",
      "epoch:5 step:5286 [D loss: 0.634979, acc.: 60.94%] [G loss: 0.961885]\n",
      "epoch:5 step:5287 [D loss: 0.744392, acc.: 49.22%] [G loss: 0.927275]\n",
      "epoch:5 step:5288 [D loss: 0.628093, acc.: 67.97%] [G loss: 0.963977]\n",
      "epoch:5 step:5289 [D loss: 0.703274, acc.: 53.12%] [G loss: 0.964741]\n",
      "epoch:5 step:5290 [D loss: 0.652895, acc.: 64.06%] [G loss: 0.854100]\n",
      "epoch:5 step:5291 [D loss: 0.646847, acc.: 64.84%] [G loss: 0.959069]\n",
      "epoch:5 step:5292 [D loss: 0.604452, acc.: 67.19%] [G loss: 1.072196]\n",
      "epoch:5 step:5293 [D loss: 0.676132, acc.: 58.59%] [G loss: 1.001172]\n",
      "epoch:5 step:5294 [D loss: 0.615214, acc.: 62.50%] [G loss: 0.967925]\n",
      "epoch:5 step:5295 [D loss: 0.609372, acc.: 67.97%] [G loss: 0.952933]\n",
      "epoch:5 step:5296 [D loss: 0.577821, acc.: 74.22%] [G loss: 0.972676]\n",
      "epoch:5 step:5297 [D loss: 0.641702, acc.: 63.28%] [G loss: 0.846836]\n",
      "epoch:5 step:5298 [D loss: 0.618619, acc.: 64.84%] [G loss: 1.081463]\n",
      "epoch:5 step:5299 [D loss: 0.681807, acc.: 54.69%] [G loss: 0.962547]\n",
      "epoch:5 step:5300 [D loss: 0.706136, acc.: 51.56%] [G loss: 0.962783]\n",
      "epoch:5 step:5301 [D loss: 0.731569, acc.: 54.69%] [G loss: 0.929208]\n",
      "epoch:5 step:5302 [D loss: 0.709943, acc.: 53.91%] [G loss: 0.926897]\n",
      "epoch:5 step:5303 [D loss: 0.623114, acc.: 69.53%] [G loss: 0.879815]\n",
      "epoch:5 step:5304 [D loss: 0.681971, acc.: 57.81%] [G loss: 0.971706]\n",
      "epoch:5 step:5305 [D loss: 0.700367, acc.: 53.12%] [G loss: 0.876645]\n",
      "epoch:5 step:5306 [D loss: 0.624910, acc.: 62.50%] [G loss: 0.998937]\n",
      "epoch:5 step:5307 [D loss: 0.721151, acc.: 51.56%] [G loss: 0.879809]\n",
      "epoch:5 step:5308 [D loss: 0.710358, acc.: 53.12%] [G loss: 0.949021]\n",
      "epoch:5 step:5309 [D loss: 0.619536, acc.: 67.97%] [G loss: 0.934825]\n",
      "epoch:5 step:5310 [D loss: 0.661245, acc.: 61.72%] [G loss: 0.990558]\n",
      "epoch:5 step:5311 [D loss: 0.691694, acc.: 57.03%] [G loss: 0.958826]\n",
      "epoch:5 step:5312 [D loss: 0.643117, acc.: 64.06%] [G loss: 0.980027]\n",
      "epoch:5 step:5313 [D loss: 0.660301, acc.: 58.59%] [G loss: 0.960061]\n",
      "epoch:5 step:5314 [D loss: 0.619835, acc.: 70.31%] [G loss: 0.896054]\n",
      "epoch:5 step:5315 [D loss: 0.658733, acc.: 60.16%] [G loss: 0.931673]\n",
      "epoch:5 step:5316 [D loss: 0.624460, acc.: 64.84%] [G loss: 0.987641]\n",
      "epoch:5 step:5317 [D loss: 0.677658, acc.: 60.16%] [G loss: 0.958195]\n",
      "epoch:5 step:5318 [D loss: 0.667939, acc.: 53.91%] [G loss: 0.971173]\n",
      "epoch:5 step:5319 [D loss: 0.700347, acc.: 55.47%] [G loss: 0.841687]\n",
      "epoch:5 step:5320 [D loss: 0.595212, acc.: 68.75%] [G loss: 0.910909]\n",
      "epoch:5 step:5321 [D loss: 0.642128, acc.: 58.59%] [G loss: 0.923239]\n",
      "epoch:5 step:5322 [D loss: 0.604591, acc.: 68.75%] [G loss: 0.978393]\n",
      "epoch:5 step:5323 [D loss: 0.678226, acc.: 59.38%] [G loss: 0.974074]\n",
      "epoch:5 step:5324 [D loss: 0.640086, acc.: 65.62%] [G loss: 0.990471]\n",
      "epoch:5 step:5325 [D loss: 0.728313, acc.: 57.03%] [G loss: 0.941380]\n",
      "epoch:5 step:5326 [D loss: 0.632838, acc.: 63.28%] [G loss: 1.001230]\n",
      "epoch:5 step:5327 [D loss: 0.591087, acc.: 69.53%] [G loss: 1.045798]\n",
      "epoch:5 step:5328 [D loss: 0.660299, acc.: 59.38%] [G loss: 0.900404]\n",
      "epoch:5 step:5329 [D loss: 0.573049, acc.: 67.97%] [G loss: 0.883520]\n",
      "epoch:5 step:5330 [D loss: 0.630615, acc.: 67.97%] [G loss: 0.989675]\n",
      "epoch:5 step:5331 [D loss: 0.666404, acc.: 55.47%] [G loss: 1.101746]\n",
      "epoch:5 step:5332 [D loss: 0.617466, acc.: 66.41%] [G loss: 0.936315]\n",
      "epoch:5 step:5333 [D loss: 0.666607, acc.: 57.81%] [G loss: 0.890133]\n",
      "epoch:5 step:5334 [D loss: 0.610309, acc.: 65.62%] [G loss: 1.010233]\n",
      "epoch:5 step:5335 [D loss: 0.672424, acc.: 60.94%] [G loss: 1.067483]\n",
      "epoch:5 step:5336 [D loss: 0.696051, acc.: 50.78%] [G loss: 0.907615]\n",
      "epoch:5 step:5337 [D loss: 0.712686, acc.: 55.47%] [G loss: 1.011445]\n",
      "epoch:5 step:5338 [D loss: 0.741862, acc.: 52.34%] [G loss: 1.027510]\n",
      "epoch:5 step:5339 [D loss: 0.630781, acc.: 67.97%] [G loss: 0.926694]\n",
      "epoch:5 step:5340 [D loss: 0.706865, acc.: 52.34%] [G loss: 0.925704]\n",
      "epoch:5 step:5341 [D loss: 0.631901, acc.: 62.50%] [G loss: 0.980174]\n",
      "epoch:5 step:5342 [D loss: 0.674808, acc.: 54.69%] [G loss: 0.991245]\n",
      "epoch:5 step:5343 [D loss: 0.667593, acc.: 55.47%] [G loss: 0.857048]\n",
      "epoch:5 step:5344 [D loss: 0.573284, acc.: 71.09%] [G loss: 1.067776]\n",
      "epoch:5 step:5345 [D loss: 0.622917, acc.: 66.41%] [G loss: 0.987363]\n",
      "epoch:5 step:5346 [D loss: 0.613438, acc.: 67.97%] [G loss: 1.097056]\n",
      "epoch:5 step:5347 [D loss: 0.655760, acc.: 64.06%] [G loss: 1.018630]\n",
      "epoch:5 step:5348 [D loss: 0.705238, acc.: 57.81%] [G loss: 0.995155]\n",
      "epoch:5 step:5349 [D loss: 0.717647, acc.: 57.81%] [G loss: 0.923323]\n",
      "epoch:5 step:5350 [D loss: 0.687323, acc.: 62.50%] [G loss: 0.904185]\n",
      "epoch:5 step:5351 [D loss: 0.714484, acc.: 52.34%] [G loss: 0.982645]\n",
      "epoch:5 step:5352 [D loss: 0.740534, acc.: 49.22%] [G loss: 0.873320]\n",
      "epoch:5 step:5353 [D loss: 0.672184, acc.: 60.94%] [G loss: 1.040893]\n",
      "epoch:5 step:5354 [D loss: 0.618639, acc.: 65.62%] [G loss: 1.038518]\n",
      "epoch:5 step:5355 [D loss: 0.659857, acc.: 61.72%] [G loss: 0.895746]\n",
      "epoch:5 step:5356 [D loss: 0.675854, acc.: 61.72%] [G loss: 0.947302]\n",
      "epoch:5 step:5357 [D loss: 0.640078, acc.: 65.62%] [G loss: 1.047955]\n",
      "epoch:5 step:5358 [D loss: 0.681851, acc.: 57.81%] [G loss: 0.851540]\n",
      "epoch:5 step:5359 [D loss: 0.676954, acc.: 58.59%] [G loss: 0.934408]\n",
      "epoch:5 step:5360 [D loss: 0.604048, acc.: 67.19%] [G loss: 1.013386]\n",
      "epoch:5 step:5361 [D loss: 0.683800, acc.: 56.25%] [G loss: 0.865502]\n",
      "epoch:5 step:5362 [D loss: 0.598609, acc.: 69.53%] [G loss: 1.062613]\n",
      "epoch:5 step:5363 [D loss: 0.602399, acc.: 69.53%] [G loss: 0.961463]\n",
      "epoch:5 step:5364 [D loss: 0.614039, acc.: 67.19%] [G loss: 0.963349]\n",
      "epoch:5 step:5365 [D loss: 0.623009, acc.: 66.41%] [G loss: 1.055649]\n",
      "epoch:5 step:5366 [D loss: 0.643864, acc.: 64.06%] [G loss: 0.997496]\n",
      "epoch:5 step:5367 [D loss: 0.754608, acc.: 48.44%] [G loss: 1.004772]\n",
      "epoch:5 step:5368 [D loss: 0.634553, acc.: 64.84%] [G loss: 1.018937]\n",
      "epoch:5 step:5369 [D loss: 0.651108, acc.: 64.06%] [G loss: 1.004497]\n",
      "epoch:5 step:5370 [D loss: 0.655407, acc.: 62.50%] [G loss: 1.083639]\n",
      "epoch:5 step:5371 [D loss: 0.598194, acc.: 69.53%] [G loss: 0.907311]\n",
      "epoch:5 step:5372 [D loss: 0.601575, acc.: 67.19%] [G loss: 1.063558]\n",
      "epoch:5 step:5373 [D loss: 0.632515, acc.: 64.06%] [G loss: 1.043379]\n",
      "epoch:5 step:5374 [D loss: 0.677657, acc.: 56.25%] [G loss: 0.974789]\n",
      "epoch:5 step:5375 [D loss: 0.633620, acc.: 70.31%] [G loss: 1.078139]\n",
      "epoch:5 step:5376 [D loss: 0.624209, acc.: 63.28%] [G loss: 0.959274]\n",
      "epoch:5 step:5377 [D loss: 0.715398, acc.: 60.94%] [G loss: 0.954962]\n",
      "epoch:5 step:5378 [D loss: 0.679888, acc.: 57.81%] [G loss: 1.049046]\n",
      "epoch:5 step:5379 [D loss: 0.594097, acc.: 71.88%] [G loss: 0.981720]\n",
      "epoch:5 step:5380 [D loss: 0.648013, acc.: 57.81%] [G loss: 0.923554]\n",
      "epoch:5 step:5381 [D loss: 0.655998, acc.: 63.28%] [G loss: 0.989692]\n",
      "epoch:5 step:5382 [D loss: 0.628402, acc.: 66.41%] [G loss: 0.990851]\n",
      "epoch:5 step:5383 [D loss: 0.713730, acc.: 49.22%] [G loss: 0.795645]\n",
      "epoch:5 step:5384 [D loss: 0.664904, acc.: 58.59%] [G loss: 0.969164]\n",
      "epoch:5 step:5385 [D loss: 0.683107, acc.: 54.69%] [G loss: 0.949400]\n",
      "epoch:5 step:5386 [D loss: 0.636238, acc.: 63.28%] [G loss: 0.883686]\n",
      "epoch:5 step:5387 [D loss: 0.650799, acc.: 64.84%] [G loss: 1.035380]\n",
      "epoch:5 step:5388 [D loss: 0.748035, acc.: 49.22%] [G loss: 0.972248]\n",
      "epoch:5 step:5389 [D loss: 0.766543, acc.: 46.88%] [G loss: 0.862180]\n",
      "epoch:5 step:5390 [D loss: 0.641402, acc.: 64.06%] [G loss: 0.943117]\n",
      "epoch:5 step:5391 [D loss: 0.648878, acc.: 60.94%] [G loss: 1.019303]\n",
      "epoch:5 step:5392 [D loss: 0.600274, acc.: 64.84%] [G loss: 1.010121]\n",
      "epoch:5 step:5393 [D loss: 0.649513, acc.: 60.16%] [G loss: 0.949712]\n",
      "epoch:5 step:5394 [D loss: 0.563986, acc.: 69.53%] [G loss: 1.091739]\n",
      "epoch:5 step:5395 [D loss: 0.743496, acc.: 49.22%] [G loss: 1.008710]\n",
      "epoch:5 step:5396 [D loss: 0.743434, acc.: 55.47%] [G loss: 0.818624]\n",
      "epoch:5 step:5397 [D loss: 0.603237, acc.: 67.97%] [G loss: 1.021878]\n",
      "epoch:5 step:5398 [D loss: 0.668035, acc.: 56.25%] [G loss: 0.905192]\n",
      "epoch:5 step:5399 [D loss: 0.651507, acc.: 62.50%] [G loss: 0.913262]\n",
      "epoch:5 step:5400 [D loss: 0.658365, acc.: 60.94%] [G loss: 1.136218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5401 [D loss: 0.726609, acc.: 52.34%] [G loss: 0.861790]\n",
      "epoch:5 step:5402 [D loss: 0.697921, acc.: 59.38%] [G loss: 0.808487]\n",
      "epoch:5 step:5403 [D loss: 0.654263, acc.: 62.50%] [G loss: 0.897186]\n",
      "epoch:5 step:5404 [D loss: 0.635311, acc.: 65.62%] [G loss: 0.984015]\n",
      "epoch:5 step:5405 [D loss: 0.715425, acc.: 55.47%] [G loss: 0.909850]\n",
      "epoch:5 step:5406 [D loss: 0.790084, acc.: 46.09%] [G loss: 0.902140]\n",
      "epoch:5 step:5407 [D loss: 0.660538, acc.: 59.38%] [G loss: 1.009118]\n",
      "epoch:5 step:5408 [D loss: 0.667276, acc.: 60.94%] [G loss: 0.906478]\n",
      "epoch:5 step:5409 [D loss: 0.667804, acc.: 63.28%] [G loss: 1.031216]\n",
      "epoch:5 step:5410 [D loss: 0.675920, acc.: 57.81%] [G loss: 1.021505]\n",
      "epoch:5 step:5411 [D loss: 0.683414, acc.: 59.38%] [G loss: 0.929360]\n",
      "epoch:5 step:5412 [D loss: 0.686443, acc.: 56.25%] [G loss: 0.915238]\n",
      "epoch:5 step:5413 [D loss: 0.627362, acc.: 60.94%] [G loss: 0.997143]\n",
      "epoch:5 step:5414 [D loss: 0.758927, acc.: 47.66%] [G loss: 0.941789]\n",
      "epoch:5 step:5415 [D loss: 0.646713, acc.: 63.28%] [G loss: 0.942141]\n",
      "epoch:5 step:5416 [D loss: 0.658500, acc.: 62.50%] [G loss: 0.882832]\n",
      "epoch:5 step:5417 [D loss: 0.654151, acc.: 60.94%] [G loss: 1.016230]\n",
      "epoch:5 step:5418 [D loss: 0.591683, acc.: 66.41%] [G loss: 0.983418]\n",
      "epoch:5 step:5419 [D loss: 0.667527, acc.: 65.62%] [G loss: 0.955823]\n",
      "epoch:5 step:5420 [D loss: 0.700646, acc.: 59.38%] [G loss: 1.078063]\n",
      "epoch:5 step:5421 [D loss: 0.590148, acc.: 71.09%] [G loss: 1.038139]\n",
      "epoch:5 step:5422 [D loss: 0.658091, acc.: 61.72%] [G loss: 0.917632]\n",
      "epoch:5 step:5423 [D loss: 0.592481, acc.: 73.44%] [G loss: 0.939356]\n",
      "epoch:5 step:5424 [D loss: 0.727703, acc.: 53.91%] [G loss: 0.836049]\n",
      "epoch:5 step:5425 [D loss: 0.661397, acc.: 62.50%] [G loss: 1.014341]\n",
      "epoch:5 step:5426 [D loss: 0.716548, acc.: 55.47%] [G loss: 0.884744]\n",
      "epoch:5 step:5427 [D loss: 0.669015, acc.: 64.06%] [G loss: 0.973951]\n",
      "epoch:5 step:5428 [D loss: 0.713578, acc.: 55.47%] [G loss: 0.965658]\n",
      "epoch:5 step:5429 [D loss: 0.688544, acc.: 55.47%] [G loss: 0.885963]\n",
      "epoch:5 step:5430 [D loss: 0.640651, acc.: 58.59%] [G loss: 0.961606]\n",
      "epoch:5 step:5431 [D loss: 0.617150, acc.: 67.19%] [G loss: 0.850719]\n",
      "epoch:5 step:5432 [D loss: 0.569462, acc.: 73.44%] [G loss: 1.016312]\n",
      "epoch:5 step:5433 [D loss: 0.626462, acc.: 61.72%] [G loss: 0.924569]\n",
      "epoch:5 step:5434 [D loss: 0.709232, acc.: 56.25%] [G loss: 0.985727]\n",
      "epoch:5 step:5435 [D loss: 0.689150, acc.: 57.81%] [G loss: 0.874988]\n",
      "epoch:5 step:5436 [D loss: 0.627358, acc.: 62.50%] [G loss: 0.968421]\n",
      "epoch:5 step:5437 [D loss: 0.707196, acc.: 53.12%] [G loss: 0.989668]\n",
      "epoch:5 step:5438 [D loss: 0.651036, acc.: 60.94%] [G loss: 0.934355]\n",
      "epoch:5 step:5439 [D loss: 0.655294, acc.: 57.81%] [G loss: 0.971600]\n",
      "epoch:5 step:5440 [D loss: 0.645032, acc.: 62.50%] [G loss: 1.007008]\n",
      "epoch:5 step:5441 [D loss: 0.756691, acc.: 47.66%] [G loss: 0.874663]\n",
      "epoch:5 step:5442 [D loss: 0.575672, acc.: 71.09%] [G loss: 0.932674]\n",
      "epoch:5 step:5443 [D loss: 0.650306, acc.: 61.72%] [G loss: 0.981666]\n",
      "epoch:5 step:5444 [D loss: 0.731916, acc.: 51.56%] [G loss: 0.929665]\n",
      "epoch:5 step:5445 [D loss: 0.713294, acc.: 54.69%] [G loss: 0.932769]\n",
      "epoch:5 step:5446 [D loss: 0.638021, acc.: 65.62%] [G loss: 1.014224]\n",
      "epoch:5 step:5447 [D loss: 0.640680, acc.: 62.50%] [G loss: 1.076977]\n",
      "epoch:5 step:5448 [D loss: 0.689206, acc.: 62.50%] [G loss: 0.973504]\n",
      "epoch:5 step:5449 [D loss: 0.685361, acc.: 53.91%] [G loss: 0.888536]\n",
      "epoch:5 step:5450 [D loss: 0.698938, acc.: 54.69%] [G loss: 0.853959]\n",
      "epoch:5 step:5451 [D loss: 0.683559, acc.: 60.16%] [G loss: 1.000498]\n",
      "epoch:5 step:5452 [D loss: 0.670531, acc.: 60.94%] [G loss: 0.983282]\n",
      "epoch:5 step:5453 [D loss: 0.743063, acc.: 50.78%] [G loss: 0.921496]\n",
      "epoch:5 step:5454 [D loss: 0.674783, acc.: 57.81%] [G loss: 1.001350]\n",
      "epoch:5 step:5455 [D loss: 0.724640, acc.: 48.44%] [G loss: 1.039176]\n",
      "epoch:5 step:5456 [D loss: 0.718491, acc.: 50.78%] [G loss: 0.843529]\n",
      "epoch:5 step:5457 [D loss: 0.651732, acc.: 62.50%] [G loss: 0.996837]\n",
      "epoch:5 step:5458 [D loss: 0.666089, acc.: 61.72%] [G loss: 1.027139]\n",
      "epoch:5 step:5459 [D loss: 0.686151, acc.: 52.34%] [G loss: 0.890000]\n",
      "epoch:5 step:5460 [D loss: 0.612945, acc.: 64.06%] [G loss: 0.808338]\n",
      "epoch:5 step:5461 [D loss: 0.593946, acc.: 71.09%] [G loss: 1.100430]\n",
      "epoch:5 step:5462 [D loss: 0.607261, acc.: 64.84%] [G loss: 1.041940]\n",
      "epoch:5 step:5463 [D loss: 0.704543, acc.: 53.12%] [G loss: 0.856572]\n",
      "epoch:5 step:5464 [D loss: 0.736601, acc.: 49.22%] [G loss: 0.813878]\n",
      "epoch:5 step:5465 [D loss: 0.715700, acc.: 54.69%] [G loss: 0.895792]\n",
      "epoch:5 step:5466 [D loss: 0.651066, acc.: 63.28%] [G loss: 0.961561]\n",
      "epoch:5 step:5467 [D loss: 0.625451, acc.: 62.50%] [G loss: 0.947034]\n",
      "epoch:5 step:5468 [D loss: 0.647705, acc.: 64.84%] [G loss: 1.050511]\n",
      "epoch:5 step:5469 [D loss: 0.664125, acc.: 60.94%] [G loss: 0.949364]\n",
      "epoch:5 step:5470 [D loss: 0.639615, acc.: 62.50%] [G loss: 0.975956]\n",
      "epoch:5 step:5471 [D loss: 0.593411, acc.: 66.41%] [G loss: 0.914357]\n",
      "epoch:5 step:5472 [D loss: 0.682956, acc.: 56.25%] [G loss: 0.987416]\n",
      "epoch:5 step:5473 [D loss: 0.716335, acc.: 56.25%] [G loss: 0.802900]\n",
      "epoch:5 step:5474 [D loss: 0.644765, acc.: 61.72%] [G loss: 0.983971]\n",
      "epoch:5 step:5475 [D loss: 0.641153, acc.: 66.41%] [G loss: 1.012052]\n",
      "epoch:5 step:5476 [D loss: 0.642994, acc.: 60.16%] [G loss: 1.054660]\n",
      "epoch:5 step:5477 [D loss: 0.593253, acc.: 69.53%] [G loss: 1.012368]\n",
      "epoch:5 step:5478 [D loss: 0.652884, acc.: 60.94%] [G loss: 1.052600]\n",
      "epoch:5 step:5479 [D loss: 0.618470, acc.: 64.06%] [G loss: 0.945078]\n",
      "epoch:5 step:5480 [D loss: 0.644180, acc.: 64.84%] [G loss: 0.901743]\n",
      "epoch:5 step:5481 [D loss: 0.637666, acc.: 63.28%] [G loss: 1.021326]\n",
      "epoch:5 step:5482 [D loss: 0.674933, acc.: 60.16%] [G loss: 0.992951]\n",
      "epoch:5 step:5483 [D loss: 0.611409, acc.: 65.62%] [G loss: 1.024737]\n",
      "epoch:5 step:5484 [D loss: 0.640883, acc.: 66.41%] [G loss: 1.003760]\n",
      "epoch:5 step:5485 [D loss: 0.738539, acc.: 52.34%] [G loss: 0.878301]\n",
      "epoch:5 step:5486 [D loss: 0.710700, acc.: 52.34%] [G loss: 0.987156]\n",
      "epoch:5 step:5487 [D loss: 0.711392, acc.: 59.38%] [G loss: 0.859989]\n",
      "epoch:5 step:5488 [D loss: 0.581780, acc.: 70.31%] [G loss: 1.075804]\n",
      "epoch:5 step:5489 [D loss: 0.691325, acc.: 59.38%] [G loss: 0.923302]\n",
      "epoch:5 step:5490 [D loss: 0.654889, acc.: 67.97%] [G loss: 0.973922]\n",
      "epoch:5 step:5491 [D loss: 0.564219, acc.: 74.22%] [G loss: 0.998827]\n",
      "epoch:5 step:5492 [D loss: 0.646801, acc.: 64.06%] [G loss: 0.887923]\n",
      "epoch:5 step:5493 [D loss: 0.682010, acc.: 57.81%] [G loss: 0.981430]\n",
      "epoch:5 step:5494 [D loss: 0.698120, acc.: 57.81%] [G loss: 1.063970]\n",
      "epoch:5 step:5495 [D loss: 0.620230, acc.: 65.62%] [G loss: 1.053247]\n",
      "epoch:5 step:5496 [D loss: 0.659152, acc.: 60.94%] [G loss: 0.838910]\n",
      "epoch:5 step:5497 [D loss: 0.727336, acc.: 50.00%] [G loss: 1.008687]\n",
      "epoch:5 step:5498 [D loss: 0.638494, acc.: 64.84%] [G loss: 0.893717]\n",
      "epoch:5 step:5499 [D loss: 0.682237, acc.: 63.28%] [G loss: 0.900432]\n",
      "epoch:5 step:5500 [D loss: 0.674842, acc.: 60.16%] [G loss: 0.885418]\n",
      "epoch:5 step:5501 [D loss: 0.672257, acc.: 58.59%] [G loss: 0.918635]\n",
      "epoch:5 step:5502 [D loss: 0.745574, acc.: 46.88%] [G loss: 0.939764]\n",
      "epoch:5 step:5503 [D loss: 0.673984, acc.: 56.25%] [G loss: 0.987118]\n",
      "epoch:5 step:5504 [D loss: 0.634969, acc.: 64.84%] [G loss: 1.008157]\n",
      "epoch:5 step:5505 [D loss: 0.700769, acc.: 57.03%] [G loss: 0.957950]\n",
      "epoch:5 step:5506 [D loss: 0.639186, acc.: 64.84%] [G loss: 0.951763]\n",
      "epoch:5 step:5507 [D loss: 0.625901, acc.: 66.41%] [G loss: 0.951532]\n",
      "epoch:5 step:5508 [D loss: 0.675113, acc.: 57.03%] [G loss: 0.862539]\n",
      "epoch:5 step:5509 [D loss: 0.699443, acc.: 53.12%] [G loss: 0.876893]\n",
      "epoch:5 step:5510 [D loss: 0.617196, acc.: 68.75%] [G loss: 0.999135]\n",
      "epoch:5 step:5511 [D loss: 0.756709, acc.: 51.56%] [G loss: 1.030112]\n",
      "epoch:5 step:5512 [D loss: 0.709746, acc.: 57.03%] [G loss: 0.884909]\n",
      "epoch:5 step:5513 [D loss: 0.663038, acc.: 57.03%] [G loss: 0.944346]\n",
      "epoch:5 step:5514 [D loss: 0.726780, acc.: 57.03%] [G loss: 0.882752]\n",
      "epoch:5 step:5515 [D loss: 0.644866, acc.: 60.94%] [G loss: 0.951648]\n",
      "epoch:5 step:5516 [D loss: 0.666024, acc.: 60.16%] [G loss: 0.914364]\n",
      "epoch:5 step:5517 [D loss: 0.603013, acc.: 71.88%] [G loss: 0.915006]\n",
      "epoch:5 step:5518 [D loss: 0.644437, acc.: 63.28%] [G loss: 0.985614]\n",
      "epoch:5 step:5519 [D loss: 0.611373, acc.: 69.53%] [G loss: 0.978904]\n",
      "epoch:5 step:5520 [D loss: 0.638739, acc.: 64.84%] [G loss: 0.989953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5521 [D loss: 0.663022, acc.: 61.72%] [G loss: 1.030669]\n",
      "epoch:5 step:5522 [D loss: 0.630312, acc.: 65.62%] [G loss: 0.993483]\n",
      "epoch:5 step:5523 [D loss: 0.651707, acc.: 61.72%] [G loss: 0.958863]\n",
      "epoch:5 step:5524 [D loss: 0.620199, acc.: 65.62%] [G loss: 0.950268]\n",
      "epoch:5 step:5525 [D loss: 0.592173, acc.: 67.19%] [G loss: 1.000961]\n",
      "epoch:5 step:5526 [D loss: 0.571281, acc.: 72.66%] [G loss: 1.017302]\n",
      "epoch:5 step:5527 [D loss: 0.575205, acc.: 69.53%] [G loss: 0.970157]\n",
      "epoch:5 step:5528 [D loss: 0.622020, acc.: 63.28%] [G loss: 1.007972]\n",
      "epoch:5 step:5529 [D loss: 0.713874, acc.: 53.91%] [G loss: 0.892350]\n",
      "epoch:5 step:5530 [D loss: 0.727480, acc.: 51.56%] [G loss: 0.822575]\n",
      "epoch:5 step:5531 [D loss: 0.619339, acc.: 64.84%] [G loss: 0.996466]\n",
      "epoch:5 step:5532 [D loss: 0.642216, acc.: 59.38%] [G loss: 0.985664]\n",
      "epoch:5 step:5533 [D loss: 0.676549, acc.: 61.72%] [G loss: 0.876314]\n",
      "epoch:5 step:5534 [D loss: 0.623743, acc.: 62.50%] [G loss: 0.980887]\n",
      "epoch:5 step:5535 [D loss: 0.687347, acc.: 58.59%] [G loss: 0.919490]\n",
      "epoch:5 step:5536 [D loss: 0.671157, acc.: 62.50%] [G loss: 1.053292]\n",
      "epoch:5 step:5537 [D loss: 0.727174, acc.: 55.47%] [G loss: 0.953862]\n",
      "epoch:5 step:5538 [D loss: 0.674413, acc.: 55.47%] [G loss: 0.958859]\n",
      "epoch:5 step:5539 [D loss: 0.647508, acc.: 65.62%] [G loss: 1.041003]\n",
      "epoch:5 step:5540 [D loss: 0.577725, acc.: 72.66%] [G loss: 0.927838]\n",
      "epoch:5 step:5541 [D loss: 0.634798, acc.: 63.28%] [G loss: 0.980490]\n",
      "epoch:5 step:5542 [D loss: 0.619219, acc.: 65.62%] [G loss: 0.912263]\n",
      "epoch:5 step:5543 [D loss: 0.759726, acc.: 49.22%] [G loss: 0.987248]\n",
      "epoch:5 step:5544 [D loss: 0.765676, acc.: 50.00%] [G loss: 0.994677]\n",
      "epoch:5 step:5545 [D loss: 0.653124, acc.: 64.06%] [G loss: 0.915697]\n",
      "epoch:5 step:5546 [D loss: 0.645041, acc.: 60.94%] [G loss: 0.911515]\n",
      "epoch:5 step:5547 [D loss: 0.628394, acc.: 70.31%] [G loss: 0.942867]\n",
      "epoch:5 step:5548 [D loss: 0.597578, acc.: 70.31%] [G loss: 0.978263]\n",
      "epoch:5 step:5549 [D loss: 0.628763, acc.: 65.62%] [G loss: 0.887462]\n",
      "epoch:5 step:5550 [D loss: 0.709230, acc.: 48.44%] [G loss: 0.872834]\n",
      "epoch:5 step:5551 [D loss: 0.671981, acc.: 59.38%] [G loss: 0.990199]\n",
      "epoch:5 step:5552 [D loss: 0.733619, acc.: 46.09%] [G loss: 0.950057]\n",
      "epoch:5 step:5553 [D loss: 0.653550, acc.: 58.59%] [G loss: 0.903374]\n",
      "epoch:5 step:5554 [D loss: 0.685824, acc.: 55.47%] [G loss: 0.924166]\n",
      "epoch:5 step:5555 [D loss: 0.712768, acc.: 53.91%] [G loss: 0.848554]\n",
      "epoch:5 step:5556 [D loss: 0.602466, acc.: 69.53%] [G loss: 1.028987]\n",
      "epoch:5 step:5557 [D loss: 0.627037, acc.: 66.41%] [G loss: 1.061602]\n",
      "epoch:5 step:5558 [D loss: 0.658841, acc.: 59.38%] [G loss: 1.023171]\n",
      "epoch:5 step:5559 [D loss: 0.669481, acc.: 61.72%] [G loss: 0.895691]\n",
      "epoch:5 step:5560 [D loss: 0.613295, acc.: 63.28%] [G loss: 0.937201]\n",
      "epoch:5 step:5561 [D loss: 0.658193, acc.: 57.81%] [G loss: 0.919415]\n",
      "epoch:5 step:5562 [D loss: 0.661576, acc.: 60.94%] [G loss: 1.087224]\n",
      "epoch:5 step:5563 [D loss: 0.716305, acc.: 53.12%] [G loss: 1.030866]\n",
      "epoch:5 step:5564 [D loss: 0.662441, acc.: 63.28%] [G loss: 0.970663]\n",
      "epoch:5 step:5565 [D loss: 0.656138, acc.: 59.38%] [G loss: 1.072644]\n",
      "epoch:5 step:5566 [D loss: 0.757968, acc.: 45.31%] [G loss: 0.939205]\n",
      "epoch:5 step:5567 [D loss: 0.661151, acc.: 63.28%] [G loss: 0.892239]\n",
      "epoch:5 step:5568 [D loss: 0.677231, acc.: 60.16%] [G loss: 0.975943]\n",
      "epoch:5 step:5569 [D loss: 0.581278, acc.: 75.78%] [G loss: 1.025523]\n",
      "epoch:5 step:5570 [D loss: 0.627347, acc.: 64.84%] [G loss: 1.001402]\n",
      "epoch:5 step:5571 [D loss: 0.596906, acc.: 73.44%] [G loss: 0.982648]\n",
      "epoch:5 step:5572 [D loss: 0.609097, acc.: 64.06%] [G loss: 1.037295]\n",
      "epoch:5 step:5573 [D loss: 0.594002, acc.: 67.97%] [G loss: 1.066764]\n",
      "epoch:5 step:5574 [D loss: 0.599945, acc.: 67.97%] [G loss: 0.974328]\n",
      "epoch:5 step:5575 [D loss: 0.567473, acc.: 75.00%] [G loss: 1.080502]\n",
      "epoch:5 step:5576 [D loss: 0.765213, acc.: 47.66%] [G loss: 0.923208]\n",
      "epoch:5 step:5577 [D loss: 0.766304, acc.: 44.53%] [G loss: 0.927077]\n",
      "epoch:5 step:5578 [D loss: 0.702220, acc.: 57.81%] [G loss: 0.842882]\n",
      "epoch:5 step:5579 [D loss: 0.638180, acc.: 62.50%] [G loss: 0.891226]\n",
      "epoch:5 step:5580 [D loss: 0.614588, acc.: 70.31%] [G loss: 1.045769]\n",
      "epoch:5 step:5581 [D loss: 0.732638, acc.: 54.69%] [G loss: 0.798751]\n",
      "epoch:5 step:5582 [D loss: 0.640527, acc.: 61.72%] [G loss: 0.983919]\n",
      "epoch:5 step:5583 [D loss: 0.719096, acc.: 51.56%] [G loss: 0.828303]\n",
      "epoch:5 step:5584 [D loss: 0.618957, acc.: 65.62%] [G loss: 0.978230]\n",
      "epoch:5 step:5585 [D loss: 0.609648, acc.: 67.19%] [G loss: 1.068104]\n",
      "epoch:5 step:5586 [D loss: 0.711548, acc.: 53.91%] [G loss: 0.979092]\n",
      "epoch:5 step:5587 [D loss: 0.699214, acc.: 53.91%] [G loss: 0.948586]\n",
      "epoch:5 step:5588 [D loss: 0.669698, acc.: 60.16%] [G loss: 1.012926]\n",
      "epoch:5 step:5589 [D loss: 0.618798, acc.: 63.28%] [G loss: 1.003809]\n",
      "epoch:5 step:5590 [D loss: 0.631450, acc.: 68.75%] [G loss: 0.908085]\n",
      "epoch:5 step:5591 [D loss: 0.647924, acc.: 62.50%] [G loss: 0.998648]\n",
      "epoch:5 step:5592 [D loss: 0.639079, acc.: 63.28%] [G loss: 0.922811]\n",
      "epoch:5 step:5593 [D loss: 0.692195, acc.: 57.03%] [G loss: 1.020645]\n",
      "epoch:5 step:5594 [D loss: 0.636809, acc.: 67.97%] [G loss: 0.883565]\n",
      "epoch:5 step:5595 [D loss: 0.596029, acc.: 67.97%] [G loss: 0.928151]\n",
      "epoch:5 step:5596 [D loss: 0.617065, acc.: 65.62%] [G loss: 0.914464]\n",
      "epoch:5 step:5597 [D loss: 0.613477, acc.: 67.97%] [G loss: 0.935853]\n",
      "epoch:5 step:5598 [D loss: 0.641622, acc.: 60.94%] [G loss: 0.988755]\n",
      "epoch:5 step:5599 [D loss: 0.602561, acc.: 68.75%] [G loss: 0.984060]\n",
      "epoch:5 step:5600 [D loss: 0.596054, acc.: 70.31%] [G loss: 0.979272]\n",
      "epoch:5 step:5601 [D loss: 0.618419, acc.: 68.75%] [G loss: 0.929392]\n",
      "epoch:5 step:5602 [D loss: 0.583331, acc.: 75.00%] [G loss: 0.927751]\n",
      "epoch:5 step:5603 [D loss: 0.599472, acc.: 67.97%] [G loss: 0.927552]\n",
      "epoch:5 step:5604 [D loss: 0.587381, acc.: 71.09%] [G loss: 0.937757]\n",
      "epoch:5 step:5605 [D loss: 0.838399, acc.: 39.84%] [G loss: 0.945046]\n",
      "epoch:5 step:5606 [D loss: 0.699466, acc.: 57.81%] [G loss: 0.932731]\n",
      "epoch:5 step:5607 [D loss: 0.573575, acc.: 71.88%] [G loss: 0.983978]\n",
      "epoch:5 step:5608 [D loss: 0.570543, acc.: 74.22%] [G loss: 0.964777]\n",
      "epoch:5 step:5609 [D loss: 0.567789, acc.: 74.22%] [G loss: 0.914126]\n",
      "epoch:5 step:5610 [D loss: 0.589062, acc.: 70.31%] [G loss: 1.113471]\n",
      "epoch:5 step:5611 [D loss: 0.569582, acc.: 73.44%] [G loss: 1.092437]\n",
      "epoch:5 step:5612 [D loss: 0.607508, acc.: 67.97%] [G loss: 0.964539]\n",
      "epoch:5 step:5613 [D loss: 0.809032, acc.: 53.12%] [G loss: 1.064559]\n",
      "epoch:5 step:5614 [D loss: 0.800085, acc.: 46.88%] [G loss: 0.967188]\n",
      "epoch:5 step:5615 [D loss: 0.568815, acc.: 70.31%] [G loss: 1.113375]\n",
      "epoch:5 step:5616 [D loss: 0.568102, acc.: 73.44%] [G loss: 1.106766]\n",
      "epoch:5 step:5617 [D loss: 0.614850, acc.: 67.97%] [G loss: 0.918348]\n",
      "epoch:5 step:5618 [D loss: 0.610755, acc.: 66.41%] [G loss: 0.848829]\n",
      "epoch:5 step:5619 [D loss: 0.626164, acc.: 67.19%] [G loss: 0.848349]\n",
      "epoch:5 step:5620 [D loss: 0.601300, acc.: 65.62%] [G loss: 1.206979]\n",
      "epoch:5 step:5621 [D loss: 0.560426, acc.: 76.56%] [G loss: 1.051091]\n",
      "epoch:5 step:5622 [D loss: 0.496216, acc.: 77.34%] [G loss: 1.153385]\n",
      "epoch:6 step:5623 [D loss: 0.699916, acc.: 57.81%] [G loss: 1.080482]\n",
      "epoch:6 step:5624 [D loss: 0.593520, acc.: 68.75%] [G loss: 1.277314]\n",
      "epoch:6 step:5625 [D loss: 0.615102, acc.: 61.72%] [G loss: 1.096928]\n",
      "epoch:6 step:5626 [D loss: 0.689115, acc.: 57.81%] [G loss: 0.920649]\n",
      "epoch:6 step:5627 [D loss: 0.583401, acc.: 69.53%] [G loss: 0.972683]\n",
      "epoch:6 step:5628 [D loss: 0.636337, acc.: 67.19%] [G loss: 0.960739]\n",
      "epoch:6 step:5629 [D loss: 0.591935, acc.: 67.97%] [G loss: 1.069571]\n",
      "epoch:6 step:5630 [D loss: 0.601558, acc.: 67.19%] [G loss: 1.036413]\n",
      "epoch:6 step:5631 [D loss: 0.643618, acc.: 62.50%] [G loss: 1.015017]\n",
      "epoch:6 step:5632 [D loss: 0.669524, acc.: 60.16%] [G loss: 0.961494]\n",
      "epoch:6 step:5633 [D loss: 0.712103, acc.: 55.47%] [G loss: 0.924550]\n",
      "epoch:6 step:5634 [D loss: 0.705632, acc.: 58.59%] [G loss: 1.024482]\n",
      "epoch:6 step:5635 [D loss: 0.722998, acc.: 56.25%] [G loss: 0.986295]\n",
      "epoch:6 step:5636 [D loss: 0.653903, acc.: 59.38%] [G loss: 0.909440]\n",
      "epoch:6 step:5637 [D loss: 0.583489, acc.: 74.22%] [G loss: 0.989731]\n",
      "epoch:6 step:5638 [D loss: 0.666382, acc.: 62.50%] [G loss: 0.966761]\n",
      "epoch:6 step:5639 [D loss: 0.756457, acc.: 50.78%] [G loss: 1.024935]\n",
      "epoch:6 step:5640 [D loss: 0.796640, acc.: 42.97%] [G loss: 0.817515]\n",
      "epoch:6 step:5641 [D loss: 0.710440, acc.: 53.12%] [G loss: 0.995692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5642 [D loss: 0.771530, acc.: 48.44%] [G loss: 0.892917]\n",
      "epoch:6 step:5643 [D loss: 0.711432, acc.: 50.78%] [G loss: 0.998949]\n",
      "epoch:6 step:5644 [D loss: 0.664918, acc.: 58.59%] [G loss: 0.923871]\n",
      "epoch:6 step:5645 [D loss: 0.633497, acc.: 62.50%] [G loss: 0.938023]\n",
      "epoch:6 step:5646 [D loss: 0.659408, acc.: 61.72%] [G loss: 0.903035]\n",
      "epoch:6 step:5647 [D loss: 0.633866, acc.: 60.94%] [G loss: 0.989062]\n",
      "epoch:6 step:5648 [D loss: 0.630832, acc.: 64.06%] [G loss: 0.837480]\n",
      "epoch:6 step:5649 [D loss: 0.627358, acc.: 67.19%] [G loss: 0.982304]\n",
      "epoch:6 step:5650 [D loss: 0.624528, acc.: 64.06%] [G loss: 0.993064]\n",
      "epoch:6 step:5651 [D loss: 0.604774, acc.: 68.75%] [G loss: 1.057146]\n",
      "epoch:6 step:5652 [D loss: 0.630450, acc.: 66.41%] [G loss: 1.036420]\n",
      "epoch:6 step:5653 [D loss: 0.702429, acc.: 55.47%] [G loss: 0.979681]\n",
      "epoch:6 step:5654 [D loss: 0.655653, acc.: 61.72%] [G loss: 0.801248]\n",
      "epoch:6 step:5655 [D loss: 0.605290, acc.: 67.97%] [G loss: 1.045727]\n",
      "epoch:6 step:5656 [D loss: 0.645458, acc.: 63.28%] [G loss: 0.819605]\n",
      "epoch:6 step:5657 [D loss: 0.645404, acc.: 66.41%] [G loss: 0.892494]\n",
      "epoch:6 step:5658 [D loss: 0.563473, acc.: 71.88%] [G loss: 1.093580]\n",
      "epoch:6 step:5659 [D loss: 0.638678, acc.: 66.41%] [G loss: 1.082692]\n",
      "epoch:6 step:5660 [D loss: 0.708638, acc.: 59.38%] [G loss: 1.044478]\n",
      "epoch:6 step:5661 [D loss: 0.672143, acc.: 59.38%] [G loss: 0.948945]\n",
      "epoch:6 step:5662 [D loss: 0.687194, acc.: 57.81%] [G loss: 0.958873]\n",
      "epoch:6 step:5663 [D loss: 0.611971, acc.: 65.62%] [G loss: 0.972546]\n",
      "epoch:6 step:5664 [D loss: 0.591666, acc.: 67.97%] [G loss: 0.941446]\n",
      "epoch:6 step:5665 [D loss: 0.610828, acc.: 63.28%] [G loss: 1.130102]\n",
      "epoch:6 step:5666 [D loss: 0.628395, acc.: 62.50%] [G loss: 1.022995]\n",
      "epoch:6 step:5667 [D loss: 0.728249, acc.: 52.34%] [G loss: 0.898223]\n",
      "epoch:6 step:5668 [D loss: 0.617871, acc.: 61.72%] [G loss: 0.898613]\n",
      "epoch:6 step:5669 [D loss: 0.631731, acc.: 64.84%] [G loss: 0.908513]\n",
      "epoch:6 step:5670 [D loss: 0.687225, acc.: 55.47%] [G loss: 0.956290]\n",
      "epoch:6 step:5671 [D loss: 0.625521, acc.: 64.84%] [G loss: 0.910301]\n",
      "epoch:6 step:5672 [D loss: 0.590059, acc.: 69.53%] [G loss: 0.938221]\n",
      "epoch:6 step:5673 [D loss: 0.652589, acc.: 66.41%] [G loss: 0.864723]\n",
      "epoch:6 step:5674 [D loss: 0.676451, acc.: 55.47%] [G loss: 0.984102]\n",
      "epoch:6 step:5675 [D loss: 0.632993, acc.: 62.50%] [G loss: 1.084386]\n",
      "epoch:6 step:5676 [D loss: 0.662399, acc.: 59.38%] [G loss: 1.045614]\n",
      "epoch:6 step:5677 [D loss: 0.617654, acc.: 66.41%] [G loss: 0.983295]\n",
      "epoch:6 step:5678 [D loss: 0.584198, acc.: 68.75%] [G loss: 0.944784]\n",
      "epoch:6 step:5679 [D loss: 0.612460, acc.: 66.41%] [G loss: 1.107005]\n",
      "epoch:6 step:5680 [D loss: 0.626353, acc.: 66.41%] [G loss: 0.876806]\n",
      "epoch:6 step:5681 [D loss: 0.692341, acc.: 53.91%] [G loss: 0.973364]\n",
      "epoch:6 step:5682 [D loss: 0.738920, acc.: 50.78%] [G loss: 0.969571]\n",
      "epoch:6 step:5683 [D loss: 0.750445, acc.: 50.00%] [G loss: 0.992579]\n",
      "epoch:6 step:5684 [D loss: 0.706766, acc.: 52.34%] [G loss: 0.844727]\n",
      "epoch:6 step:5685 [D loss: 0.665313, acc.: 53.91%] [G loss: 1.029853]\n",
      "epoch:6 step:5686 [D loss: 0.658227, acc.: 55.47%] [G loss: 0.839210]\n",
      "epoch:6 step:5687 [D loss: 0.644469, acc.: 56.25%] [G loss: 0.954161]\n",
      "epoch:6 step:5688 [D loss: 0.704159, acc.: 50.00%] [G loss: 0.951891]\n",
      "epoch:6 step:5689 [D loss: 0.608407, acc.: 67.19%] [G loss: 1.083650]\n",
      "epoch:6 step:5690 [D loss: 0.653793, acc.: 59.38%] [G loss: 0.962038]\n",
      "epoch:6 step:5691 [D loss: 0.617950, acc.: 63.28%] [G loss: 0.928162]\n",
      "epoch:6 step:5692 [D loss: 0.662205, acc.: 57.03%] [G loss: 0.984858]\n",
      "epoch:6 step:5693 [D loss: 0.639312, acc.: 61.72%] [G loss: 0.938744]\n",
      "epoch:6 step:5694 [D loss: 0.673550, acc.: 60.94%] [G loss: 1.155124]\n",
      "epoch:6 step:5695 [D loss: 0.757950, acc.: 43.75%] [G loss: 0.950535]\n",
      "epoch:6 step:5696 [D loss: 0.609334, acc.: 66.41%] [G loss: 1.012486]\n",
      "epoch:6 step:5697 [D loss: 0.562835, acc.: 73.44%] [G loss: 1.085608]\n",
      "epoch:6 step:5698 [D loss: 0.587221, acc.: 68.75%] [G loss: 1.121955]\n",
      "epoch:6 step:5699 [D loss: 0.554085, acc.: 73.44%] [G loss: 1.102077]\n",
      "epoch:6 step:5700 [D loss: 0.674100, acc.: 60.16%] [G loss: 1.072184]\n",
      "epoch:6 step:5701 [D loss: 0.700580, acc.: 56.25%] [G loss: 0.927960]\n",
      "epoch:6 step:5702 [D loss: 0.760369, acc.: 50.00%] [G loss: 0.937067]\n",
      "epoch:6 step:5703 [D loss: 0.734158, acc.: 51.56%] [G loss: 1.035646]\n",
      "epoch:6 step:5704 [D loss: 0.635389, acc.: 63.28%] [G loss: 0.998781]\n",
      "epoch:6 step:5705 [D loss: 0.668058, acc.: 59.38%] [G loss: 0.920662]\n",
      "epoch:6 step:5706 [D loss: 0.610196, acc.: 70.31%] [G loss: 1.016311]\n",
      "epoch:6 step:5707 [D loss: 0.669541, acc.: 58.59%] [G loss: 0.938118]\n",
      "epoch:6 step:5708 [D loss: 0.743506, acc.: 53.12%] [G loss: 0.839929]\n",
      "epoch:6 step:5709 [D loss: 0.637683, acc.: 66.41%] [G loss: 0.962067]\n",
      "epoch:6 step:5710 [D loss: 0.632459, acc.: 64.84%] [G loss: 0.953062]\n",
      "epoch:6 step:5711 [D loss: 0.672523, acc.: 56.25%] [G loss: 1.007789]\n",
      "epoch:6 step:5712 [D loss: 0.625917, acc.: 60.16%] [G loss: 0.990535]\n",
      "epoch:6 step:5713 [D loss: 0.689895, acc.: 55.47%] [G loss: 1.074423]\n",
      "epoch:6 step:5714 [D loss: 0.661545, acc.: 61.72%] [G loss: 0.885320]\n",
      "epoch:6 step:5715 [D loss: 0.622121, acc.: 65.62%] [G loss: 1.049332]\n",
      "epoch:6 step:5716 [D loss: 0.675137, acc.: 57.81%] [G loss: 1.013548]\n",
      "epoch:6 step:5717 [D loss: 0.629359, acc.: 59.38%] [G loss: 0.992596]\n",
      "epoch:6 step:5718 [D loss: 0.604150, acc.: 68.75%] [G loss: 0.988075]\n",
      "epoch:6 step:5719 [D loss: 0.618521, acc.: 64.06%] [G loss: 0.875632]\n",
      "epoch:6 step:5720 [D loss: 0.610165, acc.: 64.84%] [G loss: 1.066997]\n",
      "epoch:6 step:5721 [D loss: 0.736417, acc.: 46.88%] [G loss: 0.901506]\n",
      "epoch:6 step:5722 [D loss: 0.582673, acc.: 71.88%] [G loss: 1.036034]\n",
      "epoch:6 step:5723 [D loss: 0.651303, acc.: 67.97%] [G loss: 1.028046]\n",
      "epoch:6 step:5724 [D loss: 0.629783, acc.: 64.84%] [G loss: 0.962445]\n",
      "epoch:6 step:5725 [D loss: 0.571116, acc.: 75.00%] [G loss: 1.008642]\n",
      "epoch:6 step:5726 [D loss: 0.636246, acc.: 62.50%] [G loss: 1.055716]\n",
      "epoch:6 step:5727 [D loss: 0.640997, acc.: 60.94%] [G loss: 1.023039]\n",
      "epoch:6 step:5728 [D loss: 0.545200, acc.: 71.88%] [G loss: 1.109385]\n",
      "epoch:6 step:5729 [D loss: 0.698506, acc.: 56.25%] [G loss: 0.909524]\n",
      "epoch:6 step:5730 [D loss: 0.735260, acc.: 48.44%] [G loss: 1.044180]\n",
      "epoch:6 step:5731 [D loss: 0.721378, acc.: 53.12%] [G loss: 0.783626]\n",
      "epoch:6 step:5732 [D loss: 0.664609, acc.: 59.38%] [G loss: 0.950690]\n",
      "epoch:6 step:5733 [D loss: 0.555487, acc.: 71.09%] [G loss: 1.011784]\n",
      "epoch:6 step:5734 [D loss: 0.603128, acc.: 64.06%] [G loss: 0.837682]\n",
      "epoch:6 step:5735 [D loss: 0.651491, acc.: 65.62%] [G loss: 1.092434]\n",
      "epoch:6 step:5736 [D loss: 0.679858, acc.: 57.81%] [G loss: 0.944424]\n",
      "epoch:6 step:5737 [D loss: 0.682057, acc.: 57.03%] [G loss: 1.009439]\n",
      "epoch:6 step:5738 [D loss: 0.769595, acc.: 47.66%] [G loss: 0.830250]\n",
      "epoch:6 step:5739 [D loss: 0.645234, acc.: 61.72%] [G loss: 0.924016]\n",
      "epoch:6 step:5740 [D loss: 0.652275, acc.: 60.94%] [G loss: 0.926060]\n",
      "epoch:6 step:5741 [D loss: 0.708730, acc.: 54.69%] [G loss: 0.980411]\n",
      "epoch:6 step:5742 [D loss: 0.752312, acc.: 46.88%] [G loss: 1.082869]\n",
      "epoch:6 step:5743 [D loss: 0.629022, acc.: 60.16%] [G loss: 1.018812]\n",
      "epoch:6 step:5744 [D loss: 0.754237, acc.: 46.88%] [G loss: 0.951589]\n",
      "epoch:6 step:5745 [D loss: 0.685502, acc.: 59.38%] [G loss: 0.958157]\n",
      "epoch:6 step:5746 [D loss: 0.702214, acc.: 57.03%] [G loss: 0.954918]\n",
      "epoch:6 step:5747 [D loss: 0.616068, acc.: 67.19%] [G loss: 0.969996]\n",
      "epoch:6 step:5748 [D loss: 0.638608, acc.: 61.72%] [G loss: 1.018952]\n",
      "epoch:6 step:5749 [D loss: 0.641515, acc.: 64.84%] [G loss: 0.930270]\n",
      "epoch:6 step:5750 [D loss: 0.681158, acc.: 58.59%] [G loss: 0.876988]\n",
      "epoch:6 step:5751 [D loss: 0.654518, acc.: 63.28%] [G loss: 0.922225]\n",
      "epoch:6 step:5752 [D loss: 0.627532, acc.: 64.06%] [G loss: 0.979481]\n",
      "epoch:6 step:5753 [D loss: 0.700338, acc.: 57.81%] [G loss: 1.001014]\n",
      "epoch:6 step:5754 [D loss: 0.601216, acc.: 71.09%] [G loss: 0.995939]\n",
      "epoch:6 step:5755 [D loss: 0.717483, acc.: 52.34%] [G loss: 1.136624]\n",
      "epoch:6 step:5756 [D loss: 0.686446, acc.: 60.16%] [G loss: 0.938035]\n",
      "epoch:6 step:5757 [D loss: 0.660832, acc.: 56.25%] [G loss: 1.024656]\n",
      "epoch:6 step:5758 [D loss: 0.678362, acc.: 59.38%] [G loss: 1.013333]\n",
      "epoch:6 step:5759 [D loss: 0.727388, acc.: 52.34%] [G loss: 0.886491]\n",
      "epoch:6 step:5760 [D loss: 0.616217, acc.: 64.84%] [G loss: 0.873394]\n",
      "epoch:6 step:5761 [D loss: 0.675358, acc.: 55.47%] [G loss: 0.918261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5762 [D loss: 0.673801, acc.: 54.69%] [G loss: 1.060498]\n",
      "epoch:6 step:5763 [D loss: 0.671197, acc.: 59.38%] [G loss: 0.921846]\n",
      "epoch:6 step:5764 [D loss: 0.667898, acc.: 55.47%] [G loss: 1.001732]\n",
      "epoch:6 step:5765 [D loss: 0.788683, acc.: 39.06%] [G loss: 0.860641]\n",
      "epoch:6 step:5766 [D loss: 0.650083, acc.: 60.16%] [G loss: 0.933709]\n",
      "epoch:6 step:5767 [D loss: 0.664279, acc.: 56.25%] [G loss: 0.944401]\n",
      "epoch:6 step:5768 [D loss: 0.617063, acc.: 67.97%] [G loss: 0.975820]\n",
      "epoch:6 step:5769 [D loss: 0.607454, acc.: 73.44%] [G loss: 1.065122]\n",
      "epoch:6 step:5770 [D loss: 0.723849, acc.: 53.91%] [G loss: 0.959708]\n",
      "epoch:6 step:5771 [D loss: 0.653096, acc.: 57.81%] [G loss: 0.959500]\n",
      "epoch:6 step:5772 [D loss: 0.608519, acc.: 67.97%] [G loss: 0.959439]\n",
      "epoch:6 step:5773 [D loss: 0.661571, acc.: 63.28%] [G loss: 0.979762]\n",
      "epoch:6 step:5774 [D loss: 0.638202, acc.: 62.50%] [G loss: 1.007125]\n",
      "epoch:6 step:5775 [D loss: 0.634162, acc.: 64.84%] [G loss: 1.023703]\n",
      "epoch:6 step:5776 [D loss: 0.697227, acc.: 55.47%] [G loss: 0.862056]\n",
      "epoch:6 step:5777 [D loss: 0.606418, acc.: 64.84%] [G loss: 0.970310]\n",
      "epoch:6 step:5778 [D loss: 0.696322, acc.: 58.59%] [G loss: 0.956721]\n",
      "epoch:6 step:5779 [D loss: 0.627715, acc.: 66.41%] [G loss: 1.002006]\n",
      "epoch:6 step:5780 [D loss: 0.690450, acc.: 60.16%] [G loss: 0.973732]\n",
      "epoch:6 step:5781 [D loss: 0.715018, acc.: 53.12%] [G loss: 0.868976]\n",
      "epoch:6 step:5782 [D loss: 0.828899, acc.: 42.97%] [G loss: 0.776407]\n",
      "epoch:6 step:5783 [D loss: 0.669664, acc.: 55.47%] [G loss: 0.974473]\n",
      "epoch:6 step:5784 [D loss: 0.570647, acc.: 72.66%] [G loss: 0.932318]\n",
      "epoch:6 step:5785 [D loss: 0.639316, acc.: 62.50%] [G loss: 1.024306]\n",
      "epoch:6 step:5786 [D loss: 0.798498, acc.: 44.53%] [G loss: 0.906474]\n",
      "epoch:6 step:5787 [D loss: 0.654454, acc.: 58.59%] [G loss: 0.901617]\n",
      "epoch:6 step:5788 [D loss: 0.683849, acc.: 57.03%] [G loss: 0.883582]\n",
      "epoch:6 step:5789 [D loss: 0.644442, acc.: 60.94%] [G loss: 1.022429]\n",
      "epoch:6 step:5790 [D loss: 0.561747, acc.: 68.75%] [G loss: 1.066722]\n",
      "epoch:6 step:5791 [D loss: 0.644871, acc.: 61.72%] [G loss: 0.998926]\n",
      "epoch:6 step:5792 [D loss: 0.716692, acc.: 53.91%] [G loss: 0.932662]\n",
      "epoch:6 step:5793 [D loss: 0.563347, acc.: 72.66%] [G loss: 0.833532]\n",
      "epoch:6 step:5794 [D loss: 0.638654, acc.: 65.62%] [G loss: 1.023342]\n",
      "epoch:6 step:5795 [D loss: 0.688844, acc.: 55.47%] [G loss: 0.897914]\n",
      "epoch:6 step:5796 [D loss: 0.733265, acc.: 51.56%] [G loss: 0.923307]\n",
      "epoch:6 step:5797 [D loss: 0.661114, acc.: 57.81%] [G loss: 0.837540]\n",
      "epoch:6 step:5798 [D loss: 0.703742, acc.: 57.03%] [G loss: 1.008603]\n",
      "epoch:6 step:5799 [D loss: 0.659204, acc.: 60.16%] [G loss: 0.984998]\n",
      "epoch:6 step:5800 [D loss: 0.636855, acc.: 69.53%] [G loss: 0.986008]\n",
      "epoch:6 step:5801 [D loss: 0.754369, acc.: 50.78%] [G loss: 0.925090]\n",
      "epoch:6 step:5802 [D loss: 0.691664, acc.: 60.94%] [G loss: 0.911609]\n",
      "epoch:6 step:5803 [D loss: 0.701017, acc.: 53.91%] [G loss: 0.885183]\n",
      "epoch:6 step:5804 [D loss: 0.624649, acc.: 64.84%] [G loss: 0.957161]\n",
      "epoch:6 step:5805 [D loss: 0.679108, acc.: 54.69%] [G loss: 0.917593]\n",
      "epoch:6 step:5806 [D loss: 0.651339, acc.: 62.50%] [G loss: 0.916642]\n",
      "epoch:6 step:5807 [D loss: 0.662889, acc.: 62.50%] [G loss: 0.946679]\n",
      "epoch:6 step:5808 [D loss: 0.685593, acc.: 60.16%] [G loss: 0.974289]\n",
      "epoch:6 step:5809 [D loss: 0.708571, acc.: 53.12%] [G loss: 0.949000]\n",
      "epoch:6 step:5810 [D loss: 0.613181, acc.: 62.50%] [G loss: 0.940620]\n",
      "epoch:6 step:5811 [D loss: 0.724364, acc.: 54.69%] [G loss: 0.909755]\n",
      "epoch:6 step:5812 [D loss: 0.585816, acc.: 67.19%] [G loss: 1.016074]\n",
      "epoch:6 step:5813 [D loss: 0.655916, acc.: 60.16%] [G loss: 0.974935]\n",
      "epoch:6 step:5814 [D loss: 0.666771, acc.: 64.06%] [G loss: 0.957316]\n",
      "epoch:6 step:5815 [D loss: 0.658798, acc.: 65.62%] [G loss: 0.989111]\n",
      "epoch:6 step:5816 [D loss: 0.592816, acc.: 72.66%] [G loss: 1.022635]\n",
      "epoch:6 step:5817 [D loss: 0.684698, acc.: 60.94%] [G loss: 0.984094]\n",
      "epoch:6 step:5818 [D loss: 0.682475, acc.: 54.69%] [G loss: 0.991937]\n",
      "epoch:6 step:5819 [D loss: 0.681328, acc.: 58.59%] [G loss: 0.948260]\n",
      "epoch:6 step:5820 [D loss: 0.636205, acc.: 64.06%] [G loss: 0.965477]\n",
      "epoch:6 step:5821 [D loss: 0.721599, acc.: 50.00%] [G loss: 0.955101]\n",
      "epoch:6 step:5822 [D loss: 0.775033, acc.: 52.34%] [G loss: 0.981551]\n",
      "epoch:6 step:5823 [D loss: 0.666544, acc.: 61.72%] [G loss: 0.869387]\n",
      "epoch:6 step:5824 [D loss: 0.725965, acc.: 53.91%] [G loss: 0.970125]\n",
      "epoch:6 step:5825 [D loss: 0.641363, acc.: 60.94%] [G loss: 1.021398]\n",
      "epoch:6 step:5826 [D loss: 0.607367, acc.: 65.62%] [G loss: 0.982919]\n",
      "epoch:6 step:5827 [D loss: 0.674219, acc.: 60.94%] [G loss: 0.887568]\n",
      "epoch:6 step:5828 [D loss: 0.670581, acc.: 58.59%] [G loss: 0.951771]\n",
      "epoch:6 step:5829 [D loss: 0.625261, acc.: 67.97%] [G loss: 0.978988]\n",
      "epoch:6 step:5830 [D loss: 0.603752, acc.: 66.41%] [G loss: 0.906679]\n",
      "epoch:6 step:5831 [D loss: 0.602466, acc.: 68.75%] [G loss: 0.938219]\n",
      "epoch:6 step:5832 [D loss: 0.715701, acc.: 52.34%] [G loss: 0.950779]\n",
      "epoch:6 step:5833 [D loss: 0.641086, acc.: 62.50%] [G loss: 1.063544]\n",
      "epoch:6 step:5834 [D loss: 0.644751, acc.: 65.62%] [G loss: 1.031734]\n",
      "epoch:6 step:5835 [D loss: 0.704969, acc.: 52.34%] [G loss: 1.046556]\n",
      "epoch:6 step:5836 [D loss: 0.707231, acc.: 57.81%] [G loss: 1.016648]\n",
      "epoch:6 step:5837 [D loss: 0.709537, acc.: 55.47%] [G loss: 0.974870]\n",
      "epoch:6 step:5838 [D loss: 0.699174, acc.: 52.34%] [G loss: 0.973980]\n",
      "epoch:6 step:5839 [D loss: 0.592088, acc.: 71.09%] [G loss: 0.971024]\n",
      "epoch:6 step:5840 [D loss: 0.683876, acc.: 55.47%] [G loss: 0.968481]\n",
      "epoch:6 step:5841 [D loss: 0.631305, acc.: 67.97%] [G loss: 1.050825]\n",
      "epoch:6 step:5842 [D loss: 0.657263, acc.: 60.16%] [G loss: 0.877200]\n",
      "epoch:6 step:5843 [D loss: 0.575074, acc.: 67.19%] [G loss: 1.081922]\n",
      "epoch:6 step:5844 [D loss: 0.659525, acc.: 60.16%] [G loss: 1.026674]\n",
      "epoch:6 step:5845 [D loss: 0.638867, acc.: 67.97%] [G loss: 1.076407]\n",
      "epoch:6 step:5846 [D loss: 0.753972, acc.: 49.22%] [G loss: 1.051450]\n",
      "epoch:6 step:5847 [D loss: 0.742535, acc.: 54.69%] [G loss: 0.912555]\n",
      "epoch:6 step:5848 [D loss: 0.634921, acc.: 62.50%] [G loss: 0.962904]\n",
      "epoch:6 step:5849 [D loss: 0.696058, acc.: 57.81%] [G loss: 0.824387]\n",
      "epoch:6 step:5850 [D loss: 0.766432, acc.: 46.09%] [G loss: 0.883778]\n",
      "epoch:6 step:5851 [D loss: 0.593466, acc.: 66.41%] [G loss: 0.953100]\n",
      "epoch:6 step:5852 [D loss: 0.583658, acc.: 66.41%] [G loss: 1.000971]\n",
      "epoch:6 step:5853 [D loss: 0.587774, acc.: 68.75%] [G loss: 1.184893]\n",
      "epoch:6 step:5854 [D loss: 0.478757, acc.: 79.69%] [G loss: 1.187744]\n",
      "epoch:6 step:5855 [D loss: 0.619092, acc.: 61.72%] [G loss: 1.135701]\n",
      "epoch:6 step:5856 [D loss: 0.674542, acc.: 57.81%] [G loss: 1.162923]\n",
      "epoch:6 step:5857 [D loss: 0.681651, acc.: 60.94%] [G loss: 0.987848]\n",
      "epoch:6 step:5858 [D loss: 0.717038, acc.: 52.34%] [G loss: 1.023266]\n",
      "epoch:6 step:5859 [D loss: 0.685193, acc.: 56.25%] [G loss: 1.010719]\n",
      "epoch:6 step:5860 [D loss: 0.665266, acc.: 61.72%] [G loss: 1.051536]\n",
      "epoch:6 step:5861 [D loss: 0.724077, acc.: 50.00%] [G loss: 0.876336]\n",
      "epoch:6 step:5862 [D loss: 0.761557, acc.: 48.44%] [G loss: 0.950733]\n",
      "epoch:6 step:5863 [D loss: 0.724939, acc.: 50.78%] [G loss: 1.030369]\n",
      "epoch:6 step:5864 [D loss: 0.700000, acc.: 57.03%] [G loss: 0.950191]\n",
      "epoch:6 step:5865 [D loss: 0.614139, acc.: 59.38%] [G loss: 0.931510]\n",
      "epoch:6 step:5866 [D loss: 0.671127, acc.: 54.69%] [G loss: 0.954594]\n",
      "epoch:6 step:5867 [D loss: 0.656431, acc.: 58.59%] [G loss: 0.909835]\n",
      "epoch:6 step:5868 [D loss: 0.724406, acc.: 53.12%] [G loss: 0.901452]\n",
      "epoch:6 step:5869 [D loss: 0.778060, acc.: 43.75%] [G loss: 0.915367]\n",
      "epoch:6 step:5870 [D loss: 0.695777, acc.: 57.03%] [G loss: 0.938993]\n",
      "epoch:6 step:5871 [D loss: 0.705375, acc.: 54.69%] [G loss: 0.950449]\n",
      "epoch:6 step:5872 [D loss: 0.736537, acc.: 51.56%] [G loss: 0.868354]\n",
      "epoch:6 step:5873 [D loss: 0.716242, acc.: 52.34%] [G loss: 0.919606]\n",
      "epoch:6 step:5874 [D loss: 0.685692, acc.: 61.72%] [G loss: 0.922185]\n",
      "epoch:6 step:5875 [D loss: 0.597240, acc.: 71.09%] [G loss: 0.894419]\n",
      "epoch:6 step:5876 [D loss: 0.576319, acc.: 70.31%] [G loss: 0.957518]\n",
      "epoch:6 step:5877 [D loss: 0.654875, acc.: 60.94%] [G loss: 0.894037]\n",
      "epoch:6 step:5878 [D loss: 0.670634, acc.: 57.03%] [G loss: 0.954942]\n",
      "epoch:6 step:5879 [D loss: 0.629758, acc.: 66.41%] [G loss: 0.923241]\n",
      "epoch:6 step:5880 [D loss: 0.623830, acc.: 64.84%] [G loss: 0.920398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5881 [D loss: 0.711253, acc.: 60.94%] [G loss: 0.958968]\n",
      "epoch:6 step:5882 [D loss: 0.696212, acc.: 60.16%] [G loss: 0.911904]\n",
      "epoch:6 step:5883 [D loss: 0.590013, acc.: 71.09%] [G loss: 1.109485]\n",
      "epoch:6 step:5884 [D loss: 0.621268, acc.: 61.72%] [G loss: 1.013749]\n",
      "epoch:6 step:5885 [D loss: 0.650693, acc.: 60.16%] [G loss: 0.989184]\n",
      "epoch:6 step:5886 [D loss: 0.629480, acc.: 63.28%] [G loss: 1.090050]\n",
      "epoch:6 step:5887 [D loss: 0.657176, acc.: 59.38%] [G loss: 0.993817]\n",
      "epoch:6 step:5888 [D loss: 0.717714, acc.: 53.12%] [G loss: 0.920829]\n",
      "epoch:6 step:5889 [D loss: 0.697007, acc.: 52.34%] [G loss: 0.878156]\n",
      "epoch:6 step:5890 [D loss: 0.659499, acc.: 60.94%] [G loss: 0.933849]\n",
      "epoch:6 step:5891 [D loss: 0.685786, acc.: 59.38%] [G loss: 1.125726]\n",
      "epoch:6 step:5892 [D loss: 0.740905, acc.: 49.22%] [G loss: 0.936029]\n",
      "epoch:6 step:5893 [D loss: 0.581820, acc.: 69.53%] [G loss: 1.002427]\n",
      "epoch:6 step:5894 [D loss: 0.711674, acc.: 53.91%] [G loss: 0.990350]\n",
      "epoch:6 step:5895 [D loss: 0.654113, acc.: 59.38%] [G loss: 1.028920]\n",
      "epoch:6 step:5896 [D loss: 0.654905, acc.: 60.16%] [G loss: 0.976822]\n",
      "epoch:6 step:5897 [D loss: 0.678240, acc.: 57.81%] [G loss: 0.959178]\n",
      "epoch:6 step:5898 [D loss: 0.718432, acc.: 59.38%] [G loss: 0.949038]\n",
      "epoch:6 step:5899 [D loss: 0.636507, acc.: 66.41%] [G loss: 0.973521]\n",
      "epoch:6 step:5900 [D loss: 0.697836, acc.: 56.25%] [G loss: 0.832913]\n",
      "epoch:6 step:5901 [D loss: 0.733793, acc.: 46.88%] [G loss: 0.964355]\n",
      "epoch:6 step:5902 [D loss: 0.678398, acc.: 60.94%] [G loss: 0.982701]\n",
      "epoch:6 step:5903 [D loss: 0.711157, acc.: 54.69%] [G loss: 1.118463]\n",
      "epoch:6 step:5904 [D loss: 0.662183, acc.: 57.81%] [G loss: 0.945177]\n",
      "epoch:6 step:5905 [D loss: 0.656281, acc.: 57.81%] [G loss: 0.937328]\n",
      "epoch:6 step:5906 [D loss: 0.620962, acc.: 66.41%] [G loss: 1.067591]\n",
      "epoch:6 step:5907 [D loss: 0.731933, acc.: 53.91%] [G loss: 0.857491]\n",
      "epoch:6 step:5908 [D loss: 0.583338, acc.: 69.53%] [G loss: 1.013268]\n",
      "epoch:6 step:5909 [D loss: 0.640729, acc.: 63.28%] [G loss: 1.017462]\n",
      "epoch:6 step:5910 [D loss: 0.715276, acc.: 54.69%] [G loss: 0.940641]\n",
      "epoch:6 step:5911 [D loss: 0.673204, acc.: 58.59%] [G loss: 1.006995]\n",
      "epoch:6 step:5912 [D loss: 0.619264, acc.: 64.06%] [G loss: 1.055357]\n",
      "epoch:6 step:5913 [D loss: 0.589097, acc.: 70.31%] [G loss: 1.002424]\n",
      "epoch:6 step:5914 [D loss: 0.608589, acc.: 67.97%] [G loss: 1.033983]\n",
      "epoch:6 step:5915 [D loss: 0.640547, acc.: 61.72%] [G loss: 0.895406]\n",
      "epoch:6 step:5916 [D loss: 0.661200, acc.: 60.94%] [G loss: 0.920060]\n",
      "epoch:6 step:5917 [D loss: 0.693710, acc.: 55.47%] [G loss: 1.138138]\n",
      "epoch:6 step:5918 [D loss: 0.680933, acc.: 56.25%] [G loss: 0.949271]\n",
      "epoch:6 step:5919 [D loss: 0.684330, acc.: 57.03%] [G loss: 0.839744]\n",
      "epoch:6 step:5920 [D loss: 0.654570, acc.: 60.16%] [G loss: 0.904336]\n",
      "epoch:6 step:5921 [D loss: 0.633186, acc.: 67.19%] [G loss: 0.816604]\n",
      "epoch:6 step:5922 [D loss: 0.676079, acc.: 57.03%] [G loss: 0.957541]\n",
      "epoch:6 step:5923 [D loss: 0.674000, acc.: 57.81%] [G loss: 0.905836]\n",
      "epoch:6 step:5924 [D loss: 0.587737, acc.: 67.97%] [G loss: 1.082859]\n",
      "epoch:6 step:5925 [D loss: 0.689885, acc.: 58.59%] [G loss: 0.886985]\n",
      "epoch:6 step:5926 [D loss: 0.592379, acc.: 67.97%] [G loss: 0.987518]\n",
      "epoch:6 step:5927 [D loss: 0.639694, acc.: 62.50%] [G loss: 1.043181]\n",
      "epoch:6 step:5928 [D loss: 0.653372, acc.: 58.59%] [G loss: 0.857443]\n",
      "epoch:6 step:5929 [D loss: 0.672433, acc.: 54.69%] [G loss: 0.965500]\n",
      "epoch:6 step:5930 [D loss: 0.597073, acc.: 71.09%] [G loss: 1.124419]\n",
      "epoch:6 step:5931 [D loss: 0.689565, acc.: 56.25%] [G loss: 0.984238]\n",
      "epoch:6 step:5932 [D loss: 0.644230, acc.: 63.28%] [G loss: 0.915797]\n",
      "epoch:6 step:5933 [D loss: 0.657809, acc.: 63.28%] [G loss: 0.996428]\n",
      "epoch:6 step:5934 [D loss: 0.603972, acc.: 67.97%] [G loss: 1.028152]\n",
      "epoch:6 step:5935 [D loss: 0.566266, acc.: 72.66%] [G loss: 1.075485]\n",
      "epoch:6 step:5936 [D loss: 0.604196, acc.: 60.94%] [G loss: 1.076627]\n",
      "epoch:6 step:5937 [D loss: 0.568135, acc.: 72.66%] [G loss: 1.220539]\n",
      "epoch:6 step:5938 [D loss: 0.633477, acc.: 67.97%] [G loss: 1.046807]\n",
      "epoch:6 step:5939 [D loss: 0.635466, acc.: 64.84%] [G loss: 1.047379]\n",
      "epoch:6 step:5940 [D loss: 0.659992, acc.: 58.59%] [G loss: 0.918507]\n",
      "epoch:6 step:5941 [D loss: 0.659337, acc.: 60.16%] [G loss: 1.019158]\n",
      "epoch:6 step:5942 [D loss: 0.650603, acc.: 57.03%] [G loss: 1.027185]\n",
      "epoch:6 step:5943 [D loss: 0.640025, acc.: 65.62%] [G loss: 1.011577]\n",
      "epoch:6 step:5944 [D loss: 0.606031, acc.: 66.41%] [G loss: 1.021674]\n",
      "epoch:6 step:5945 [D loss: 0.677292, acc.: 54.69%] [G loss: 0.870081]\n",
      "epoch:6 step:5946 [D loss: 0.657130, acc.: 59.38%] [G loss: 0.976780]\n",
      "epoch:6 step:5947 [D loss: 0.701652, acc.: 59.38%] [G loss: 0.880592]\n",
      "epoch:6 step:5948 [D loss: 0.632711, acc.: 66.41%] [G loss: 0.859113]\n",
      "epoch:6 step:5949 [D loss: 0.679640, acc.: 58.59%] [G loss: 0.947992]\n",
      "epoch:6 step:5950 [D loss: 0.646569, acc.: 59.38%] [G loss: 0.995731]\n",
      "epoch:6 step:5951 [D loss: 0.631356, acc.: 60.94%] [G loss: 0.931520]\n",
      "epoch:6 step:5952 [D loss: 0.593546, acc.: 67.19%] [G loss: 0.803778]\n",
      "epoch:6 step:5953 [D loss: 0.623592, acc.: 67.97%] [G loss: 0.989268]\n",
      "epoch:6 step:5954 [D loss: 0.594884, acc.: 71.09%] [G loss: 0.990971]\n",
      "epoch:6 step:5955 [D loss: 0.664548, acc.: 65.62%] [G loss: 0.910232]\n",
      "epoch:6 step:5956 [D loss: 0.689036, acc.: 60.94%] [G loss: 0.971537]\n",
      "epoch:6 step:5957 [D loss: 0.661872, acc.: 60.16%] [G loss: 0.919257]\n",
      "epoch:6 step:5958 [D loss: 0.601047, acc.: 67.97%] [G loss: 0.981631]\n",
      "epoch:6 step:5959 [D loss: 0.609830, acc.: 67.97%] [G loss: 0.883353]\n",
      "epoch:6 step:5960 [D loss: 0.700025, acc.: 59.38%] [G loss: 0.975483]\n",
      "epoch:6 step:5961 [D loss: 0.569056, acc.: 67.97%] [G loss: 1.102901]\n",
      "epoch:6 step:5962 [D loss: 0.602084, acc.: 67.97%] [G loss: 1.205428]\n",
      "epoch:6 step:5963 [D loss: 0.605838, acc.: 61.72%] [G loss: 0.962456]\n",
      "epoch:6 step:5964 [D loss: 0.666114, acc.: 55.47%] [G loss: 0.982778]\n",
      "epoch:6 step:5965 [D loss: 0.601923, acc.: 66.41%] [G loss: 0.919609]\n",
      "epoch:6 step:5966 [D loss: 0.619253, acc.: 66.41%] [G loss: 0.977096]\n",
      "epoch:6 step:5967 [D loss: 0.728184, acc.: 50.78%] [G loss: 0.987789]\n",
      "epoch:6 step:5968 [D loss: 0.544514, acc.: 75.00%] [G loss: 1.054067]\n",
      "epoch:6 step:5969 [D loss: 0.666480, acc.: 60.16%] [G loss: 0.896534]\n",
      "epoch:6 step:5970 [D loss: 0.701119, acc.: 57.81%] [G loss: 1.088357]\n",
      "epoch:6 step:5971 [D loss: 0.742980, acc.: 48.44%] [G loss: 0.940194]\n",
      "epoch:6 step:5972 [D loss: 0.643807, acc.: 58.59%] [G loss: 1.116467]\n",
      "epoch:6 step:5973 [D loss: 0.655390, acc.: 58.59%] [G loss: 0.796212]\n",
      "epoch:6 step:5974 [D loss: 0.752185, acc.: 52.34%] [G loss: 0.893198]\n",
      "epoch:6 step:5975 [D loss: 0.665766, acc.: 60.16%] [G loss: 0.883920]\n",
      "epoch:6 step:5976 [D loss: 0.669626, acc.: 56.25%] [G loss: 0.953344]\n",
      "epoch:6 step:5977 [D loss: 0.731965, acc.: 54.69%] [G loss: 0.982077]\n",
      "epoch:6 step:5978 [D loss: 0.638262, acc.: 56.25%] [G loss: 1.004741]\n",
      "epoch:6 step:5979 [D loss: 0.621527, acc.: 61.72%] [G loss: 0.919029]\n",
      "epoch:6 step:5980 [D loss: 0.633825, acc.: 63.28%] [G loss: 0.898800]\n",
      "epoch:6 step:5981 [D loss: 0.594057, acc.: 64.06%] [G loss: 1.039775]\n",
      "epoch:6 step:5982 [D loss: 0.602439, acc.: 68.75%] [G loss: 1.084391]\n",
      "epoch:6 step:5983 [D loss: 0.641941, acc.: 66.41%] [G loss: 0.971941]\n",
      "epoch:6 step:5984 [D loss: 0.671652, acc.: 55.47%] [G loss: 0.968502]\n",
      "epoch:6 step:5985 [D loss: 0.707232, acc.: 53.12%] [G loss: 0.967735]\n",
      "epoch:6 step:5986 [D loss: 0.713315, acc.: 55.47%] [G loss: 0.967621]\n",
      "epoch:6 step:5987 [D loss: 0.577162, acc.: 72.66%] [G loss: 0.950490]\n",
      "epoch:6 step:5988 [D loss: 0.599487, acc.: 64.84%] [G loss: 1.068311]\n",
      "epoch:6 step:5989 [D loss: 0.673407, acc.: 59.38%] [G loss: 1.068196]\n",
      "epoch:6 step:5990 [D loss: 0.672132, acc.: 62.50%] [G loss: 0.991058]\n",
      "epoch:6 step:5991 [D loss: 0.610867, acc.: 69.53%] [G loss: 1.001849]\n",
      "epoch:6 step:5992 [D loss: 0.623951, acc.: 67.19%] [G loss: 1.164107]\n",
      "epoch:6 step:5993 [D loss: 0.598925, acc.: 68.75%] [G loss: 1.019993]\n",
      "epoch:6 step:5994 [D loss: 0.713624, acc.: 54.69%] [G loss: 1.022610]\n",
      "epoch:6 step:5995 [D loss: 0.725283, acc.: 59.38%] [G loss: 0.900896]\n",
      "epoch:6 step:5996 [D loss: 0.661590, acc.: 63.28%] [G loss: 0.956809]\n",
      "epoch:6 step:5997 [D loss: 0.607521, acc.: 71.88%] [G loss: 0.919080]\n",
      "epoch:6 step:5998 [D loss: 0.705872, acc.: 52.34%] [G loss: 0.846207]\n",
      "epoch:6 step:5999 [D loss: 0.741699, acc.: 45.31%] [G loss: 0.861492]\n",
      "epoch:6 step:6000 [D loss: 0.645623, acc.: 62.50%] [G loss: 0.894087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6001 [D loss: 0.587626, acc.: 74.22%] [G loss: 0.924398]\n",
      "epoch:6 step:6002 [D loss: 0.646326, acc.: 65.62%] [G loss: 0.989590]\n",
      "epoch:6 step:6003 [D loss: 0.557166, acc.: 69.53%] [G loss: 0.875577]\n",
      "epoch:6 step:6004 [D loss: 0.619094, acc.: 62.50%] [G loss: 1.006283]\n",
      "epoch:6 step:6005 [D loss: 0.670676, acc.: 58.59%] [G loss: 1.045622]\n",
      "epoch:6 step:6006 [D loss: 0.610660, acc.: 61.72%] [G loss: 0.859746]\n",
      "epoch:6 step:6007 [D loss: 0.645779, acc.: 57.81%] [G loss: 1.080957]\n",
      "epoch:6 step:6008 [D loss: 0.699403, acc.: 57.03%] [G loss: 0.934192]\n",
      "epoch:6 step:6009 [D loss: 0.571862, acc.: 74.22%] [G loss: 0.911469]\n",
      "epoch:6 step:6010 [D loss: 0.632812, acc.: 63.28%] [G loss: 0.995424]\n",
      "epoch:6 step:6011 [D loss: 0.603211, acc.: 69.53%] [G loss: 0.900571]\n",
      "epoch:6 step:6012 [D loss: 0.686098, acc.: 59.38%] [G loss: 1.025471]\n",
      "epoch:6 step:6013 [D loss: 0.660810, acc.: 60.94%] [G loss: 0.949901]\n",
      "epoch:6 step:6014 [D loss: 0.638270, acc.: 62.50%] [G loss: 0.853984]\n",
      "epoch:6 step:6015 [D loss: 0.686958, acc.: 58.59%] [G loss: 0.951551]\n",
      "epoch:6 step:6016 [D loss: 0.649786, acc.: 63.28%] [G loss: 0.904167]\n",
      "epoch:6 step:6017 [D loss: 0.634711, acc.: 61.72%] [G loss: 0.955166]\n",
      "epoch:6 step:6018 [D loss: 0.638973, acc.: 56.25%] [G loss: 1.092877]\n",
      "epoch:6 step:6019 [D loss: 0.669600, acc.: 60.16%] [G loss: 1.021255]\n",
      "epoch:6 step:6020 [D loss: 0.547802, acc.: 78.12%] [G loss: 1.014953]\n",
      "epoch:6 step:6021 [D loss: 0.583957, acc.: 71.09%] [G loss: 1.050279]\n",
      "epoch:6 step:6022 [D loss: 0.643092, acc.: 60.94%] [G loss: 0.997194]\n",
      "epoch:6 step:6023 [D loss: 0.777262, acc.: 48.44%] [G loss: 0.871908]\n",
      "epoch:6 step:6024 [D loss: 0.590346, acc.: 70.31%] [G loss: 1.131233]\n",
      "epoch:6 step:6025 [D loss: 0.747076, acc.: 48.44%] [G loss: 0.965054]\n",
      "epoch:6 step:6026 [D loss: 0.665273, acc.: 63.28%] [G loss: 0.999427]\n",
      "epoch:6 step:6027 [D loss: 0.586500, acc.: 71.88%] [G loss: 1.082442]\n",
      "epoch:6 step:6028 [D loss: 0.570308, acc.: 73.44%] [G loss: 1.152861]\n",
      "epoch:6 step:6029 [D loss: 0.749118, acc.: 53.91%] [G loss: 0.934635]\n",
      "epoch:6 step:6030 [D loss: 0.649574, acc.: 59.38%] [G loss: 1.041468]\n",
      "epoch:6 step:6031 [D loss: 0.659587, acc.: 64.06%] [G loss: 0.887484]\n",
      "epoch:6 step:6032 [D loss: 0.689473, acc.: 60.16%] [G loss: 0.869501]\n",
      "epoch:6 step:6033 [D loss: 0.712305, acc.: 61.72%] [G loss: 1.007836]\n",
      "epoch:6 step:6034 [D loss: 0.717481, acc.: 53.91%] [G loss: 0.984772]\n",
      "epoch:6 step:6035 [D loss: 0.692821, acc.: 59.38%] [G loss: 0.930893]\n",
      "epoch:6 step:6036 [D loss: 0.729884, acc.: 50.00%] [G loss: 0.944083]\n",
      "epoch:6 step:6037 [D loss: 0.690834, acc.: 54.69%] [G loss: 1.016901]\n",
      "epoch:6 step:6038 [D loss: 0.688412, acc.: 54.69%] [G loss: 1.012470]\n",
      "epoch:6 step:6039 [D loss: 0.683377, acc.: 53.12%] [G loss: 0.963747]\n",
      "epoch:6 step:6040 [D loss: 0.621808, acc.: 63.28%] [G loss: 0.951737]\n",
      "epoch:6 step:6041 [D loss: 0.633187, acc.: 64.84%] [G loss: 0.826547]\n",
      "epoch:6 step:6042 [D loss: 0.687736, acc.: 49.22%] [G loss: 0.946194]\n",
      "epoch:6 step:6043 [D loss: 0.653625, acc.: 61.72%] [G loss: 0.925324]\n",
      "epoch:6 step:6044 [D loss: 0.760204, acc.: 49.22%] [G loss: 1.014161]\n",
      "epoch:6 step:6045 [D loss: 0.715166, acc.: 51.56%] [G loss: 0.932643]\n",
      "epoch:6 step:6046 [D loss: 0.694398, acc.: 53.91%] [G loss: 0.939968]\n",
      "epoch:6 step:6047 [D loss: 0.708845, acc.: 53.91%] [G loss: 0.975554]\n",
      "epoch:6 step:6048 [D loss: 0.669888, acc.: 62.50%] [G loss: 0.903789]\n",
      "epoch:6 step:6049 [D loss: 0.610944, acc.: 67.19%] [G loss: 0.998547]\n",
      "epoch:6 step:6050 [D loss: 0.618511, acc.: 67.97%] [G loss: 1.118669]\n",
      "epoch:6 step:6051 [D loss: 0.623613, acc.: 63.28%] [G loss: 0.956941]\n",
      "epoch:6 step:6052 [D loss: 0.635955, acc.: 60.16%] [G loss: 0.954599]\n",
      "epoch:6 step:6053 [D loss: 0.614168, acc.: 65.62%] [G loss: 0.992789]\n",
      "epoch:6 step:6054 [D loss: 0.767058, acc.: 47.66%] [G loss: 1.026278]\n",
      "epoch:6 step:6055 [D loss: 0.699561, acc.: 53.91%] [G loss: 0.944575]\n",
      "epoch:6 step:6056 [D loss: 0.593542, acc.: 71.09%] [G loss: 1.044395]\n",
      "epoch:6 step:6057 [D loss: 0.628338, acc.: 65.62%] [G loss: 1.020332]\n",
      "epoch:6 step:6058 [D loss: 0.706227, acc.: 56.25%] [G loss: 1.009254]\n",
      "epoch:6 step:6059 [D loss: 0.757039, acc.: 46.88%] [G loss: 0.922229]\n",
      "epoch:6 step:6060 [D loss: 0.664832, acc.: 59.38%] [G loss: 1.049263]\n",
      "epoch:6 step:6061 [D loss: 0.654801, acc.: 60.94%] [G loss: 1.023518]\n",
      "epoch:6 step:6062 [D loss: 0.633912, acc.: 61.72%] [G loss: 1.025821]\n",
      "epoch:6 step:6063 [D loss: 0.705172, acc.: 60.16%] [G loss: 0.975128]\n",
      "epoch:6 step:6064 [D loss: 0.658836, acc.: 59.38%] [G loss: 1.035857]\n",
      "epoch:6 step:6065 [D loss: 0.659724, acc.: 60.16%] [G loss: 0.917938]\n",
      "epoch:6 step:6066 [D loss: 0.688806, acc.: 50.00%] [G loss: 0.933059]\n",
      "epoch:6 step:6067 [D loss: 0.694752, acc.: 57.03%] [G loss: 0.930623]\n",
      "epoch:6 step:6068 [D loss: 0.697690, acc.: 56.25%] [G loss: 0.985350]\n",
      "epoch:6 step:6069 [D loss: 0.672245, acc.: 58.59%] [G loss: 1.008095]\n",
      "epoch:6 step:6070 [D loss: 0.676017, acc.: 55.47%] [G loss: 0.943117]\n",
      "epoch:6 step:6071 [D loss: 0.671739, acc.: 60.94%] [G loss: 0.958930]\n",
      "epoch:6 step:6072 [D loss: 0.656532, acc.: 57.03%] [G loss: 1.047896]\n",
      "epoch:6 step:6073 [D loss: 0.675331, acc.: 56.25%] [G loss: 0.907300]\n",
      "epoch:6 step:6074 [D loss: 0.671459, acc.: 56.25%] [G loss: 1.036841]\n",
      "epoch:6 step:6075 [D loss: 0.605318, acc.: 66.41%] [G loss: 0.950190]\n",
      "epoch:6 step:6076 [D loss: 0.661286, acc.: 56.25%] [G loss: 1.047365]\n",
      "epoch:6 step:6077 [D loss: 0.682411, acc.: 56.25%] [G loss: 0.984321]\n",
      "epoch:6 step:6078 [D loss: 0.596082, acc.: 69.53%] [G loss: 1.060977]\n",
      "epoch:6 step:6079 [D loss: 0.635790, acc.: 63.28%] [G loss: 0.852643]\n",
      "epoch:6 step:6080 [D loss: 0.750757, acc.: 54.69%] [G loss: 0.983341]\n",
      "epoch:6 step:6081 [D loss: 0.681854, acc.: 59.38%] [G loss: 1.012017]\n",
      "epoch:6 step:6082 [D loss: 0.676969, acc.: 61.72%] [G loss: 0.869150]\n",
      "epoch:6 step:6083 [D loss: 0.653168, acc.: 61.72%] [G loss: 0.913921]\n",
      "epoch:6 step:6084 [D loss: 0.677340, acc.: 58.59%] [G loss: 0.915481]\n",
      "epoch:6 step:6085 [D loss: 0.682093, acc.: 57.81%] [G loss: 1.015110]\n",
      "epoch:6 step:6086 [D loss: 0.679691, acc.: 56.25%] [G loss: 0.904760]\n",
      "epoch:6 step:6087 [D loss: 0.726141, acc.: 53.91%] [G loss: 0.863875]\n",
      "epoch:6 step:6088 [D loss: 0.643937, acc.: 63.28%] [G loss: 1.065343]\n",
      "epoch:6 step:6089 [D loss: 0.643580, acc.: 63.28%] [G loss: 1.036814]\n",
      "epoch:6 step:6090 [D loss: 0.600183, acc.: 71.09%] [G loss: 0.988307]\n",
      "epoch:6 step:6091 [D loss: 0.643274, acc.: 57.03%] [G loss: 0.923576]\n",
      "epoch:6 step:6092 [D loss: 0.600213, acc.: 67.97%] [G loss: 1.019311]\n",
      "epoch:6 step:6093 [D loss: 0.590124, acc.: 67.97%] [G loss: 1.002656]\n",
      "epoch:6 step:6094 [D loss: 0.656777, acc.: 60.16%] [G loss: 0.944263]\n",
      "epoch:6 step:6095 [D loss: 0.783503, acc.: 43.75%] [G loss: 0.888773]\n",
      "epoch:6 step:6096 [D loss: 0.694497, acc.: 55.47%] [G loss: 0.871162]\n",
      "epoch:6 step:6097 [D loss: 0.660028, acc.: 56.25%] [G loss: 0.932738]\n",
      "epoch:6 step:6098 [D loss: 0.622988, acc.: 63.28%] [G loss: 0.990475]\n",
      "epoch:6 step:6099 [D loss: 0.720335, acc.: 54.69%] [G loss: 1.080279]\n",
      "epoch:6 step:6100 [D loss: 0.642064, acc.: 64.84%] [G loss: 1.035512]\n",
      "epoch:6 step:6101 [D loss: 0.656887, acc.: 60.16%] [G loss: 1.039228]\n",
      "epoch:6 step:6102 [D loss: 0.695872, acc.: 53.12%] [G loss: 0.865429]\n",
      "epoch:6 step:6103 [D loss: 0.544715, acc.: 71.88%] [G loss: 0.892212]\n",
      "epoch:6 step:6104 [D loss: 0.674372, acc.: 58.59%] [G loss: 0.924155]\n",
      "epoch:6 step:6105 [D loss: 0.631506, acc.: 60.94%] [G loss: 1.058919]\n",
      "epoch:6 step:6106 [D loss: 0.616623, acc.: 67.19%] [G loss: 0.983640]\n",
      "epoch:6 step:6107 [D loss: 0.643307, acc.: 63.28%] [G loss: 0.977089]\n",
      "epoch:6 step:6108 [D loss: 0.650084, acc.: 64.06%] [G loss: 0.958848]\n",
      "epoch:6 step:6109 [D loss: 0.680270, acc.: 60.94%] [G loss: 0.966627]\n",
      "epoch:6 step:6110 [D loss: 0.659259, acc.: 57.03%] [G loss: 0.941483]\n",
      "epoch:6 step:6111 [D loss: 0.678123, acc.: 61.72%] [G loss: 1.015399]\n",
      "epoch:6 step:6112 [D loss: 0.722011, acc.: 53.12%] [G loss: 0.871700]\n",
      "epoch:6 step:6113 [D loss: 0.572326, acc.: 67.97%] [G loss: 0.978193]\n",
      "epoch:6 step:6114 [D loss: 0.666842, acc.: 57.81%] [G loss: 1.000414]\n",
      "epoch:6 step:6115 [D loss: 0.730999, acc.: 49.22%] [G loss: 0.919326]\n",
      "epoch:6 step:6116 [D loss: 0.661117, acc.: 60.16%] [G loss: 0.928348]\n",
      "epoch:6 step:6117 [D loss: 0.640734, acc.: 64.84%] [G loss: 0.948749]\n",
      "epoch:6 step:6118 [D loss: 0.664204, acc.: 62.50%] [G loss: 1.015535]\n",
      "epoch:6 step:6119 [D loss: 0.746013, acc.: 50.78%] [G loss: 0.906885]\n",
      "epoch:6 step:6120 [D loss: 0.661048, acc.: 60.94%] [G loss: 0.975710]\n",
      "epoch:6 step:6121 [D loss: 0.645422, acc.: 63.28%] [G loss: 0.930262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6122 [D loss: 0.713486, acc.: 51.56%] [G loss: 0.999790]\n",
      "epoch:6 step:6123 [D loss: 0.702109, acc.: 53.12%] [G loss: 0.920061]\n",
      "epoch:6 step:6124 [D loss: 0.718801, acc.: 52.34%] [G loss: 0.903318]\n",
      "epoch:6 step:6125 [D loss: 0.674629, acc.: 59.38%] [G loss: 0.993579]\n",
      "epoch:6 step:6126 [D loss: 0.629163, acc.: 63.28%] [G loss: 0.992122]\n",
      "epoch:6 step:6127 [D loss: 0.631742, acc.: 64.84%] [G loss: 0.942348]\n",
      "epoch:6 step:6128 [D loss: 0.669399, acc.: 59.38%] [G loss: 0.875023]\n",
      "epoch:6 step:6129 [D loss: 0.671361, acc.: 57.81%] [G loss: 0.987491]\n",
      "epoch:6 step:6130 [D loss: 0.613626, acc.: 64.84%] [G loss: 0.955738]\n",
      "epoch:6 step:6131 [D loss: 0.707651, acc.: 55.47%] [G loss: 0.880193]\n",
      "epoch:6 step:6132 [D loss: 0.681997, acc.: 57.03%] [G loss: 1.006769]\n",
      "epoch:6 step:6133 [D loss: 0.726466, acc.: 51.56%] [G loss: 0.935449]\n",
      "epoch:6 step:6134 [D loss: 0.709149, acc.: 54.69%] [G loss: 0.851359]\n",
      "epoch:6 step:6135 [D loss: 0.678220, acc.: 57.03%] [G loss: 0.898403]\n",
      "epoch:6 step:6136 [D loss: 0.650581, acc.: 60.94%] [G loss: 1.032082]\n",
      "epoch:6 step:6137 [D loss: 0.586250, acc.: 70.31%] [G loss: 0.933189]\n",
      "epoch:6 step:6138 [D loss: 0.574438, acc.: 72.66%] [G loss: 1.019006]\n",
      "epoch:6 step:6139 [D loss: 0.667199, acc.: 57.03%] [G loss: 0.861910]\n",
      "epoch:6 step:6140 [D loss: 0.745409, acc.: 50.78%] [G loss: 0.856458]\n",
      "epoch:6 step:6141 [D loss: 0.685803, acc.: 56.25%] [G loss: 0.892242]\n",
      "epoch:6 step:6142 [D loss: 0.628133, acc.: 63.28%] [G loss: 0.950748]\n",
      "epoch:6 step:6143 [D loss: 0.579585, acc.: 70.31%] [G loss: 0.957528]\n",
      "epoch:6 step:6144 [D loss: 0.631230, acc.: 61.72%] [G loss: 0.877496]\n",
      "epoch:6 step:6145 [D loss: 0.559961, acc.: 69.53%] [G loss: 1.038615]\n",
      "epoch:6 step:6146 [D loss: 0.710899, acc.: 54.69%] [G loss: 0.813595]\n",
      "epoch:6 step:6147 [D loss: 0.671324, acc.: 54.69%] [G loss: 0.923919]\n",
      "epoch:6 step:6148 [D loss: 0.602046, acc.: 68.75%] [G loss: 0.952601]\n",
      "epoch:6 step:6149 [D loss: 0.714223, acc.: 56.25%] [G loss: 0.909336]\n",
      "epoch:6 step:6150 [D loss: 0.699257, acc.: 58.59%] [G loss: 1.002830]\n",
      "epoch:6 step:6151 [D loss: 0.662521, acc.: 56.25%] [G loss: 0.927975]\n",
      "epoch:6 step:6152 [D loss: 0.667895, acc.: 59.38%] [G loss: 0.932006]\n",
      "epoch:6 step:6153 [D loss: 0.624828, acc.: 67.97%] [G loss: 0.912560]\n",
      "epoch:6 step:6154 [D loss: 0.600844, acc.: 69.53%] [G loss: 1.040685]\n",
      "epoch:6 step:6155 [D loss: 0.667481, acc.: 55.47%] [G loss: 0.891568]\n",
      "epoch:6 step:6156 [D loss: 0.632151, acc.: 62.50%] [G loss: 0.939815]\n",
      "epoch:6 step:6157 [D loss: 0.680931, acc.: 53.12%] [G loss: 0.863914]\n",
      "epoch:6 step:6158 [D loss: 0.642948, acc.: 65.62%] [G loss: 0.868317]\n",
      "epoch:6 step:6159 [D loss: 0.604982, acc.: 64.06%] [G loss: 0.938509]\n",
      "epoch:6 step:6160 [D loss: 0.729053, acc.: 53.12%] [G loss: 0.929955]\n",
      "epoch:6 step:6161 [D loss: 0.654830, acc.: 61.72%] [G loss: 0.915860]\n",
      "epoch:6 step:6162 [D loss: 0.637335, acc.: 61.72%] [G loss: 0.987545]\n",
      "epoch:6 step:6163 [D loss: 0.689124, acc.: 53.91%] [G loss: 1.036735]\n",
      "epoch:6 step:6164 [D loss: 0.838965, acc.: 35.94%] [G loss: 0.869544]\n",
      "epoch:6 step:6165 [D loss: 0.710535, acc.: 50.00%] [G loss: 0.982982]\n",
      "epoch:6 step:6166 [D loss: 0.743728, acc.: 45.31%] [G loss: 0.967012]\n",
      "epoch:6 step:6167 [D loss: 0.663177, acc.: 56.25%] [G loss: 0.920908]\n",
      "epoch:6 step:6168 [D loss: 0.723542, acc.: 55.47%] [G loss: 1.050728]\n",
      "epoch:6 step:6169 [D loss: 0.573076, acc.: 73.44%] [G loss: 0.958888]\n",
      "epoch:6 step:6170 [D loss: 0.607020, acc.: 63.28%] [G loss: 0.942633]\n",
      "epoch:6 step:6171 [D loss: 0.582824, acc.: 66.41%] [G loss: 1.048083]\n",
      "epoch:6 step:6172 [D loss: 0.600141, acc.: 69.53%] [G loss: 0.985552]\n",
      "epoch:6 step:6173 [D loss: 0.601654, acc.: 69.53%] [G loss: 1.029135]\n",
      "epoch:6 step:6174 [D loss: 0.628603, acc.: 67.19%] [G loss: 0.968708]\n",
      "epoch:6 step:6175 [D loss: 0.603315, acc.: 67.19%] [G loss: 1.040501]\n",
      "epoch:6 step:6176 [D loss: 0.581432, acc.: 69.53%] [G loss: 1.069472]\n",
      "epoch:6 step:6177 [D loss: 0.551704, acc.: 79.69%] [G loss: 1.072197]\n",
      "epoch:6 step:6178 [D loss: 0.584315, acc.: 71.88%] [G loss: 1.054501]\n",
      "epoch:6 step:6179 [D loss: 0.665768, acc.: 59.38%] [G loss: 0.920453]\n",
      "epoch:6 step:6180 [D loss: 0.670868, acc.: 55.47%] [G loss: 1.088335]\n",
      "epoch:6 step:6181 [D loss: 0.815305, acc.: 41.41%] [G loss: 0.943533]\n",
      "epoch:6 step:6182 [D loss: 0.695768, acc.: 57.81%] [G loss: 0.998055]\n",
      "epoch:6 step:6183 [D loss: 0.721987, acc.: 50.78%] [G loss: 0.864656]\n",
      "epoch:6 step:6184 [D loss: 0.723489, acc.: 52.34%] [G loss: 0.869142]\n",
      "epoch:6 step:6185 [D loss: 0.752563, acc.: 49.22%] [G loss: 0.904064]\n",
      "epoch:6 step:6186 [D loss: 0.649824, acc.: 64.84%] [G loss: 0.869626]\n",
      "epoch:6 step:6187 [D loss: 0.725801, acc.: 59.38%] [G loss: 0.979858]\n",
      "epoch:6 step:6188 [D loss: 0.687741, acc.: 50.78%] [G loss: 0.923871]\n",
      "epoch:6 step:6189 [D loss: 0.714708, acc.: 49.22%] [G loss: 0.958605]\n",
      "epoch:6 step:6190 [D loss: 0.654714, acc.: 63.28%] [G loss: 0.991399]\n",
      "epoch:6 step:6191 [D loss: 0.689893, acc.: 57.81%] [G loss: 0.941436]\n",
      "epoch:6 step:6192 [D loss: 0.648401, acc.: 62.50%] [G loss: 1.042241]\n",
      "epoch:6 step:6193 [D loss: 0.656558, acc.: 60.94%] [G loss: 0.950905]\n",
      "epoch:6 step:6194 [D loss: 0.655970, acc.: 62.50%] [G loss: 0.992119]\n",
      "epoch:6 step:6195 [D loss: 0.663995, acc.: 61.72%] [G loss: 0.882000]\n",
      "epoch:6 step:6196 [D loss: 0.766166, acc.: 47.66%] [G loss: 0.860758]\n",
      "epoch:6 step:6197 [D loss: 0.650201, acc.: 57.81%] [G loss: 1.062352]\n",
      "epoch:6 step:6198 [D loss: 0.723307, acc.: 51.56%] [G loss: 0.854790]\n",
      "epoch:6 step:6199 [D loss: 0.671517, acc.: 59.38%] [G loss: 0.894661]\n",
      "epoch:6 step:6200 [D loss: 0.570078, acc.: 73.44%] [G loss: 0.988473]\n",
      "epoch:6 step:6201 [D loss: 0.713950, acc.: 48.44%] [G loss: 0.893382]\n",
      "epoch:6 step:6202 [D loss: 0.747203, acc.: 44.53%] [G loss: 0.815747]\n",
      "epoch:6 step:6203 [D loss: 0.629068, acc.: 64.84%] [G loss: 0.912284]\n",
      "epoch:6 step:6204 [D loss: 0.682475, acc.: 61.72%] [G loss: 0.900047]\n",
      "epoch:6 step:6205 [D loss: 0.737580, acc.: 50.00%] [G loss: 0.955851]\n",
      "epoch:6 step:6206 [D loss: 0.624255, acc.: 61.72%] [G loss: 0.975753]\n",
      "epoch:6 step:6207 [D loss: 0.697188, acc.: 56.25%] [G loss: 0.944495]\n",
      "epoch:6 step:6208 [D loss: 0.697997, acc.: 54.69%] [G loss: 0.989219]\n",
      "epoch:6 step:6209 [D loss: 0.650191, acc.: 62.50%] [G loss: 1.029279]\n",
      "epoch:6 step:6210 [D loss: 0.642806, acc.: 61.72%] [G loss: 1.009038]\n",
      "epoch:6 step:6211 [D loss: 0.518081, acc.: 82.03%] [G loss: 1.138588]\n",
      "epoch:6 step:6212 [D loss: 0.763295, acc.: 49.22%] [G loss: 0.999939]\n",
      "epoch:6 step:6213 [D loss: 0.676129, acc.: 57.81%] [G loss: 0.977082]\n",
      "epoch:6 step:6214 [D loss: 0.710971, acc.: 55.47%] [G loss: 0.980567]\n",
      "epoch:6 step:6215 [D loss: 0.706276, acc.: 56.25%] [G loss: 0.936120]\n",
      "epoch:6 step:6216 [D loss: 0.606444, acc.: 64.06%] [G loss: 1.075418]\n",
      "epoch:6 step:6217 [D loss: 0.669756, acc.: 60.94%] [G loss: 0.921324]\n",
      "epoch:6 step:6218 [D loss: 0.664543, acc.: 61.72%] [G loss: 0.969742]\n",
      "epoch:6 step:6219 [D loss: 0.723929, acc.: 50.78%] [G loss: 0.941180]\n",
      "epoch:6 step:6220 [D loss: 0.646019, acc.: 60.94%] [G loss: 0.987430]\n",
      "epoch:6 step:6221 [D loss: 0.694796, acc.: 53.91%] [G loss: 0.912168]\n",
      "epoch:6 step:6222 [D loss: 0.646065, acc.: 64.84%] [G loss: 0.987380]\n",
      "epoch:6 step:6223 [D loss: 0.638019, acc.: 65.62%] [G loss: 0.953978]\n",
      "epoch:6 step:6224 [D loss: 0.689835, acc.: 60.16%] [G loss: 0.988824]\n",
      "epoch:6 step:6225 [D loss: 0.608360, acc.: 66.41%] [G loss: 1.035133]\n",
      "epoch:6 step:6226 [D loss: 0.640486, acc.: 62.50%] [G loss: 0.996865]\n",
      "epoch:6 step:6227 [D loss: 0.573892, acc.: 71.88%] [G loss: 0.918492]\n",
      "epoch:6 step:6228 [D loss: 0.725938, acc.: 53.12%] [G loss: 0.864395]\n",
      "epoch:6 step:6229 [D loss: 0.627805, acc.: 64.84%] [G loss: 0.988003]\n",
      "epoch:6 step:6230 [D loss: 0.660170, acc.: 60.16%] [G loss: 0.941157]\n",
      "epoch:6 step:6231 [D loss: 0.657637, acc.: 59.38%] [G loss: 0.938578]\n",
      "epoch:6 step:6232 [D loss: 0.628806, acc.: 60.16%] [G loss: 0.975955]\n",
      "epoch:6 step:6233 [D loss: 0.646093, acc.: 57.81%] [G loss: 0.943689]\n",
      "epoch:6 step:6234 [D loss: 0.579044, acc.: 72.66%] [G loss: 0.947863]\n",
      "epoch:6 step:6235 [D loss: 0.615624, acc.: 67.97%] [G loss: 1.029310]\n",
      "epoch:6 step:6236 [D loss: 0.724926, acc.: 50.00%] [G loss: 0.881588]\n",
      "epoch:6 step:6237 [D loss: 0.703673, acc.: 57.03%] [G loss: 1.022987]\n",
      "epoch:6 step:6238 [D loss: 0.718209, acc.: 50.78%] [G loss: 0.861512]\n",
      "epoch:6 step:6239 [D loss: 0.648275, acc.: 61.72%] [G loss: 0.893151]\n",
      "epoch:6 step:6240 [D loss: 0.652895, acc.: 60.16%] [G loss: 0.813809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6241 [D loss: 0.694826, acc.: 60.94%] [G loss: 1.036987]\n",
      "epoch:6 step:6242 [D loss: 0.659643, acc.: 57.81%] [G loss: 0.879974]\n",
      "epoch:6 step:6243 [D loss: 0.681333, acc.: 57.03%] [G loss: 0.945237]\n",
      "epoch:6 step:6244 [D loss: 0.606864, acc.: 63.28%] [G loss: 1.058017]\n",
      "epoch:6 step:6245 [D loss: 0.642078, acc.: 66.41%] [G loss: 0.936684]\n",
      "epoch:6 step:6246 [D loss: 0.573331, acc.: 66.41%] [G loss: 0.902819]\n",
      "epoch:6 step:6247 [D loss: 0.720880, acc.: 51.56%] [G loss: 0.876842]\n",
      "epoch:6 step:6248 [D loss: 0.697451, acc.: 55.47%] [G loss: 0.930729]\n",
      "epoch:6 step:6249 [D loss: 0.654654, acc.: 57.81%] [G loss: 1.010594]\n",
      "epoch:6 step:6250 [D loss: 0.682188, acc.: 54.69%] [G loss: 0.897649]\n",
      "epoch:6 step:6251 [D loss: 0.662738, acc.: 60.16%] [G loss: 0.931072]\n",
      "epoch:6 step:6252 [D loss: 0.656194, acc.: 59.38%] [G loss: 1.070636]\n",
      "epoch:6 step:6253 [D loss: 0.591611, acc.: 68.75%] [G loss: 1.183309]\n",
      "epoch:6 step:6254 [D loss: 0.694263, acc.: 56.25%] [G loss: 0.888308]\n",
      "epoch:6 step:6255 [D loss: 0.637218, acc.: 65.62%] [G loss: 1.165601]\n",
      "epoch:6 step:6256 [D loss: 0.630733, acc.: 63.28%] [G loss: 1.015586]\n",
      "epoch:6 step:6257 [D loss: 0.656180, acc.: 63.28%] [G loss: 0.969592]\n",
      "epoch:6 step:6258 [D loss: 0.685753, acc.: 57.03%] [G loss: 1.079224]\n",
      "epoch:6 step:6259 [D loss: 0.650791, acc.: 63.28%] [G loss: 0.919065]\n",
      "epoch:6 step:6260 [D loss: 0.608489, acc.: 67.97%] [G loss: 1.010378]\n",
      "epoch:6 step:6261 [D loss: 0.605894, acc.: 68.75%] [G loss: 0.984091]\n",
      "epoch:6 step:6262 [D loss: 0.595873, acc.: 69.53%] [G loss: 0.989574]\n",
      "epoch:6 step:6263 [D loss: 0.725678, acc.: 52.34%] [G loss: 0.807092]\n",
      "epoch:6 step:6264 [D loss: 0.568656, acc.: 76.56%] [G loss: 1.037000]\n",
      "epoch:6 step:6265 [D loss: 0.694948, acc.: 58.59%] [G loss: 0.984697]\n",
      "epoch:6 step:6266 [D loss: 0.651505, acc.: 57.03%] [G loss: 0.930198]\n",
      "epoch:6 step:6267 [D loss: 0.609916, acc.: 70.31%] [G loss: 0.996659]\n",
      "epoch:6 step:6268 [D loss: 0.642501, acc.: 61.72%] [G loss: 0.932959]\n",
      "epoch:6 step:6269 [D loss: 0.615877, acc.: 64.84%] [G loss: 1.040384]\n",
      "epoch:6 step:6270 [D loss: 0.641293, acc.: 64.06%] [G loss: 0.987074]\n",
      "epoch:6 step:6271 [D loss: 0.590343, acc.: 68.75%] [G loss: 1.135009]\n",
      "epoch:6 step:6272 [D loss: 0.629512, acc.: 61.72%] [G loss: 0.964163]\n",
      "epoch:6 step:6273 [D loss: 0.693860, acc.: 57.03%] [G loss: 0.995665]\n",
      "epoch:6 step:6274 [D loss: 0.683038, acc.: 60.16%] [G loss: 0.966208]\n",
      "epoch:6 step:6275 [D loss: 0.752794, acc.: 46.88%] [G loss: 0.852608]\n",
      "epoch:6 step:6276 [D loss: 0.678606, acc.: 58.59%] [G loss: 0.877510]\n",
      "epoch:6 step:6277 [D loss: 0.676071, acc.: 60.16%] [G loss: 1.015976]\n",
      "epoch:6 step:6278 [D loss: 0.633146, acc.: 64.84%] [G loss: 1.054718]\n",
      "epoch:6 step:6279 [D loss: 0.686227, acc.: 57.81%] [G loss: 0.972624]\n",
      "epoch:6 step:6280 [D loss: 0.720095, acc.: 55.47%] [G loss: 0.946394]\n",
      "epoch:6 step:6281 [D loss: 0.634983, acc.: 66.41%] [G loss: 0.925277]\n",
      "epoch:6 step:6282 [D loss: 0.617420, acc.: 66.41%] [G loss: 1.021944]\n",
      "epoch:6 step:6283 [D loss: 0.553340, acc.: 74.22%] [G loss: 1.053172]\n",
      "epoch:6 step:6284 [D loss: 0.572221, acc.: 71.09%] [G loss: 1.070304]\n",
      "epoch:6 step:6285 [D loss: 0.643070, acc.: 61.72%] [G loss: 0.957249]\n",
      "epoch:6 step:6286 [D loss: 0.747681, acc.: 50.78%] [G loss: 0.934887]\n",
      "epoch:6 step:6287 [D loss: 0.696332, acc.: 56.25%] [G loss: 0.994968]\n",
      "epoch:6 step:6288 [D loss: 0.683631, acc.: 61.72%] [G loss: 0.868623]\n",
      "epoch:6 step:6289 [D loss: 0.664824, acc.: 62.50%] [G loss: 0.937430]\n",
      "epoch:6 step:6290 [D loss: 0.599553, acc.: 65.62%] [G loss: 0.924282]\n",
      "epoch:6 step:6291 [D loss: 0.705247, acc.: 57.03%] [G loss: 0.834926]\n",
      "epoch:6 step:6292 [D loss: 0.675239, acc.: 59.38%] [G loss: 0.833575]\n",
      "epoch:6 step:6293 [D loss: 0.715420, acc.: 53.91%] [G loss: 0.927496]\n",
      "epoch:6 step:6294 [D loss: 0.692240, acc.: 57.81%] [G loss: 0.963652]\n",
      "epoch:6 step:6295 [D loss: 0.725593, acc.: 53.91%] [G loss: 0.938599]\n",
      "epoch:6 step:6296 [D loss: 0.724042, acc.: 55.47%] [G loss: 0.946611]\n",
      "epoch:6 step:6297 [D loss: 0.698979, acc.: 60.94%] [G loss: 0.934793]\n",
      "epoch:6 step:6298 [D loss: 0.671365, acc.: 56.25%] [G loss: 0.992212]\n",
      "epoch:6 step:6299 [D loss: 0.612595, acc.: 67.19%] [G loss: 0.974669]\n",
      "epoch:6 step:6300 [D loss: 0.666384, acc.: 61.72%] [G loss: 0.881346]\n",
      "epoch:6 step:6301 [D loss: 0.647330, acc.: 61.72%] [G loss: 0.798971]\n",
      "epoch:6 step:6302 [D loss: 0.640597, acc.: 61.72%] [G loss: 0.993250]\n",
      "epoch:6 step:6303 [D loss: 0.607216, acc.: 68.75%] [G loss: 1.034018]\n",
      "epoch:6 step:6304 [D loss: 0.627396, acc.: 66.41%] [G loss: 1.133950]\n",
      "epoch:6 step:6305 [D loss: 0.651338, acc.: 59.38%] [G loss: 1.055766]\n",
      "epoch:6 step:6306 [D loss: 0.650083, acc.: 60.94%] [G loss: 0.823271]\n",
      "epoch:6 step:6307 [D loss: 0.614234, acc.: 67.19%] [G loss: 0.982930]\n",
      "epoch:6 step:6308 [D loss: 0.670863, acc.: 57.81%] [G loss: 0.903867]\n",
      "epoch:6 step:6309 [D loss: 0.636336, acc.: 61.72%] [G loss: 0.948392]\n",
      "epoch:6 step:6310 [D loss: 0.680725, acc.: 56.25%] [G loss: 1.005174]\n",
      "epoch:6 step:6311 [D loss: 0.604448, acc.: 69.53%] [G loss: 1.007644]\n",
      "epoch:6 step:6312 [D loss: 0.675346, acc.: 54.69%] [G loss: 0.872541]\n",
      "epoch:6 step:6313 [D loss: 0.626764, acc.: 68.75%] [G loss: 0.897419]\n",
      "epoch:6 step:6314 [D loss: 0.618673, acc.: 64.84%] [G loss: 1.053703]\n",
      "epoch:6 step:6315 [D loss: 0.638766, acc.: 62.50%] [G loss: 1.015653]\n",
      "epoch:6 step:6316 [D loss: 0.650364, acc.: 61.72%] [G loss: 1.065408]\n",
      "epoch:6 step:6317 [D loss: 0.667648, acc.: 58.59%] [G loss: 1.029376]\n",
      "epoch:6 step:6318 [D loss: 0.590363, acc.: 69.53%] [G loss: 1.035744]\n",
      "epoch:6 step:6319 [D loss: 0.691794, acc.: 54.69%] [G loss: 0.922001]\n",
      "epoch:6 step:6320 [D loss: 0.724931, acc.: 47.66%] [G loss: 0.832951]\n",
      "epoch:6 step:6321 [D loss: 0.686509, acc.: 60.16%] [G loss: 0.877966]\n",
      "epoch:6 step:6322 [D loss: 0.716599, acc.: 52.34%] [G loss: 0.898600]\n",
      "epoch:6 step:6323 [D loss: 0.624464, acc.: 66.41%] [G loss: 1.057096]\n",
      "epoch:6 step:6324 [D loss: 0.758526, acc.: 46.88%] [G loss: 0.822327]\n",
      "epoch:6 step:6325 [D loss: 0.780325, acc.: 41.41%] [G loss: 0.877554]\n",
      "epoch:6 step:6326 [D loss: 0.691054, acc.: 55.47%] [G loss: 0.938199]\n",
      "epoch:6 step:6327 [D loss: 0.634134, acc.: 67.97%] [G loss: 0.997067]\n",
      "epoch:6 step:6328 [D loss: 0.610255, acc.: 65.62%] [G loss: 0.957378]\n",
      "epoch:6 step:6329 [D loss: 0.586398, acc.: 72.66%] [G loss: 0.890161]\n",
      "epoch:6 step:6330 [D loss: 0.601370, acc.: 67.19%] [G loss: 0.982511]\n",
      "epoch:6 step:6331 [D loss: 0.577798, acc.: 71.09%] [G loss: 0.911331]\n",
      "epoch:6 step:6332 [D loss: 0.709493, acc.: 53.91%] [G loss: 0.952047]\n",
      "epoch:6 step:6333 [D loss: 0.734057, acc.: 50.00%] [G loss: 0.886824]\n",
      "epoch:6 step:6334 [D loss: 0.592922, acc.: 70.31%] [G loss: 0.927108]\n",
      "epoch:6 step:6335 [D loss: 0.678788, acc.: 57.03%] [G loss: 0.834280]\n",
      "epoch:6 step:6336 [D loss: 0.639566, acc.: 67.19%] [G loss: 1.083122]\n",
      "epoch:6 step:6337 [D loss: 0.760090, acc.: 46.09%] [G loss: 0.936386]\n",
      "epoch:6 step:6338 [D loss: 0.652301, acc.: 66.41%] [G loss: 1.073079]\n",
      "epoch:6 step:6339 [D loss: 0.651853, acc.: 59.38%] [G loss: 1.078802]\n",
      "epoch:6 step:6340 [D loss: 0.695205, acc.: 56.25%] [G loss: 0.858033]\n",
      "epoch:6 step:6341 [D loss: 0.684419, acc.: 56.25%] [G loss: 0.859058]\n",
      "epoch:6 step:6342 [D loss: 0.669277, acc.: 58.59%] [G loss: 1.047675]\n",
      "epoch:6 step:6343 [D loss: 0.647984, acc.: 59.38%] [G loss: 0.837813]\n",
      "epoch:6 step:6344 [D loss: 0.728755, acc.: 51.56%] [G loss: 0.933130]\n",
      "epoch:6 step:6345 [D loss: 0.665778, acc.: 59.38%] [G loss: 0.937080]\n",
      "epoch:6 step:6346 [D loss: 0.623588, acc.: 65.62%] [G loss: 1.026890]\n",
      "epoch:6 step:6347 [D loss: 0.596848, acc.: 70.31%] [G loss: 1.091022]\n",
      "epoch:6 step:6348 [D loss: 0.620970, acc.: 67.97%] [G loss: 0.992311]\n",
      "epoch:6 step:6349 [D loss: 0.618614, acc.: 66.41%] [G loss: 0.993367]\n",
      "epoch:6 step:6350 [D loss: 0.704111, acc.: 50.00%] [G loss: 0.846879]\n",
      "epoch:6 step:6351 [D loss: 0.689115, acc.: 52.34%] [G loss: 0.927476]\n",
      "epoch:6 step:6352 [D loss: 0.618617, acc.: 69.53%] [G loss: 1.020915]\n",
      "epoch:6 step:6353 [D loss: 0.659503, acc.: 58.59%] [G loss: 0.907948]\n",
      "epoch:6 step:6354 [D loss: 0.585812, acc.: 70.31%] [G loss: 0.918134]\n",
      "epoch:6 step:6355 [D loss: 0.661174, acc.: 62.50%] [G loss: 0.969900]\n",
      "epoch:6 step:6356 [D loss: 0.724138, acc.: 50.78%] [G loss: 0.927927]\n",
      "epoch:6 step:6357 [D loss: 0.646951, acc.: 64.06%] [G loss: 0.957187]\n",
      "epoch:6 step:6358 [D loss: 0.624887, acc.: 65.62%] [G loss: 1.083074]\n",
      "epoch:6 step:6359 [D loss: 0.690297, acc.: 55.47%] [G loss: 1.007331]\n",
      "epoch:6 step:6360 [D loss: 0.712359, acc.: 53.91%] [G loss: 0.885936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6361 [D loss: 0.687528, acc.: 56.25%] [G loss: 0.968696]\n",
      "epoch:6 step:6362 [D loss: 0.651656, acc.: 60.16%] [G loss: 0.947759]\n",
      "epoch:6 step:6363 [D loss: 0.680768, acc.: 56.25%] [G loss: 0.938416]\n",
      "epoch:6 step:6364 [D loss: 0.847545, acc.: 35.94%] [G loss: 0.933784]\n",
      "epoch:6 step:6365 [D loss: 0.720555, acc.: 52.34%] [G loss: 0.954743]\n",
      "epoch:6 step:6366 [D loss: 0.736889, acc.: 53.12%] [G loss: 0.942845]\n",
      "epoch:6 step:6367 [D loss: 0.567831, acc.: 71.09%] [G loss: 0.979698]\n",
      "epoch:6 step:6368 [D loss: 0.614655, acc.: 66.41%] [G loss: 0.857605]\n",
      "epoch:6 step:6369 [D loss: 0.648745, acc.: 67.19%] [G loss: 1.084103]\n",
      "epoch:6 step:6370 [D loss: 0.604764, acc.: 71.09%] [G loss: 1.037562]\n",
      "epoch:6 step:6371 [D loss: 0.598829, acc.: 64.84%] [G loss: 0.934181]\n",
      "epoch:6 step:6372 [D loss: 0.669194, acc.: 57.81%] [G loss: 0.931011]\n",
      "epoch:6 step:6373 [D loss: 0.663293, acc.: 57.81%] [G loss: 0.816219]\n",
      "epoch:6 step:6374 [D loss: 0.745558, acc.: 46.88%] [G loss: 0.878210]\n",
      "epoch:6 step:6375 [D loss: 0.661703, acc.: 60.16%] [G loss: 0.916431]\n",
      "epoch:6 step:6376 [D loss: 0.604112, acc.: 63.28%] [G loss: 0.875426]\n",
      "epoch:6 step:6377 [D loss: 0.637423, acc.: 60.94%] [G loss: 1.022007]\n",
      "epoch:6 step:6378 [D loss: 0.603174, acc.: 69.53%] [G loss: 1.120640]\n",
      "epoch:6 step:6379 [D loss: 0.621572, acc.: 67.19%] [G loss: 0.940498]\n",
      "epoch:6 step:6380 [D loss: 0.636677, acc.: 63.28%] [G loss: 1.068904]\n",
      "epoch:6 step:6381 [D loss: 0.736478, acc.: 48.44%] [G loss: 1.003537]\n",
      "epoch:6 step:6382 [D loss: 0.694768, acc.: 57.03%] [G loss: 0.933078]\n",
      "epoch:6 step:6383 [D loss: 0.668895, acc.: 55.47%] [G loss: 0.986442]\n",
      "epoch:6 step:6384 [D loss: 0.632184, acc.: 62.50%] [G loss: 0.925233]\n",
      "epoch:6 step:6385 [D loss: 0.652655, acc.: 67.97%] [G loss: 0.895309]\n",
      "epoch:6 step:6386 [D loss: 0.672286, acc.: 57.81%] [G loss: 0.877933]\n",
      "epoch:6 step:6387 [D loss: 0.686000, acc.: 61.72%] [G loss: 0.831271]\n",
      "epoch:6 step:6388 [D loss: 0.752679, acc.: 50.78%] [G loss: 0.930653]\n",
      "epoch:6 step:6389 [D loss: 0.713992, acc.: 56.25%] [G loss: 0.988656]\n",
      "epoch:6 step:6390 [D loss: 0.715515, acc.: 52.34%] [G loss: 0.988311]\n",
      "epoch:6 step:6391 [D loss: 0.646397, acc.: 58.59%] [G loss: 0.951371]\n",
      "epoch:6 step:6392 [D loss: 0.686834, acc.: 56.25%] [G loss: 0.834298]\n",
      "epoch:6 step:6393 [D loss: 0.631479, acc.: 64.84%] [G loss: 1.024522]\n",
      "epoch:6 step:6394 [D loss: 0.694734, acc.: 56.25%] [G loss: 0.897642]\n",
      "epoch:6 step:6395 [D loss: 0.574557, acc.: 73.44%] [G loss: 0.932629]\n",
      "epoch:6 step:6396 [D loss: 0.640576, acc.: 61.72%] [G loss: 0.906399]\n",
      "epoch:6 step:6397 [D loss: 0.599575, acc.: 67.19%] [G loss: 0.970033]\n",
      "epoch:6 step:6398 [D loss: 0.661880, acc.: 57.81%] [G loss: 0.870894]\n",
      "epoch:6 step:6399 [D loss: 0.661713, acc.: 64.06%] [G loss: 0.988064]\n",
      "epoch:6 step:6400 [D loss: 0.686199, acc.: 58.59%] [G loss: 1.007164]\n",
      "epoch:6 step:6401 [D loss: 0.709799, acc.: 59.38%] [G loss: 0.827642]\n",
      "epoch:6 step:6402 [D loss: 0.678648, acc.: 60.16%] [G loss: 0.962674]\n",
      "epoch:6 step:6403 [D loss: 0.689197, acc.: 58.59%] [G loss: 1.024832]\n",
      "epoch:6 step:6404 [D loss: 0.679760, acc.: 59.38%] [G loss: 0.940694]\n",
      "epoch:6 step:6405 [D loss: 0.656745, acc.: 58.59%] [G loss: 0.936979]\n",
      "epoch:6 step:6406 [D loss: 0.603457, acc.: 65.62%] [G loss: 0.896317]\n",
      "epoch:6 step:6407 [D loss: 0.653970, acc.: 67.97%] [G loss: 1.017408]\n",
      "epoch:6 step:6408 [D loss: 0.584097, acc.: 70.31%] [G loss: 0.933276]\n",
      "epoch:6 step:6409 [D loss: 0.652016, acc.: 60.94%] [G loss: 0.918773]\n",
      "epoch:6 step:6410 [D loss: 0.758041, acc.: 46.09%] [G loss: 0.882975]\n",
      "epoch:6 step:6411 [D loss: 0.647232, acc.: 60.16%] [G loss: 0.938254]\n",
      "epoch:6 step:6412 [D loss: 0.607688, acc.: 67.97%] [G loss: 1.083402]\n",
      "epoch:6 step:6413 [D loss: 0.583555, acc.: 71.09%] [G loss: 0.995407]\n",
      "epoch:6 step:6414 [D loss: 0.610323, acc.: 69.53%] [G loss: 0.916766]\n",
      "epoch:6 step:6415 [D loss: 0.617495, acc.: 66.41%] [G loss: 1.035811]\n",
      "epoch:6 step:6416 [D loss: 0.724992, acc.: 53.91%] [G loss: 0.917042]\n",
      "epoch:6 step:6417 [D loss: 0.681350, acc.: 56.25%] [G loss: 0.972121]\n",
      "epoch:6 step:6418 [D loss: 0.647172, acc.: 64.06%] [G loss: 1.019344]\n",
      "epoch:6 step:6419 [D loss: 0.638330, acc.: 60.94%] [G loss: 0.825082]\n",
      "epoch:6 step:6420 [D loss: 0.644905, acc.: 66.41%] [G loss: 0.964586]\n",
      "epoch:6 step:6421 [D loss: 0.635527, acc.: 64.84%] [G loss: 0.935768]\n",
      "epoch:6 step:6422 [D loss: 0.693636, acc.: 61.72%] [G loss: 0.938785]\n",
      "epoch:6 step:6423 [D loss: 0.709172, acc.: 56.25%] [G loss: 0.891994]\n",
      "epoch:6 step:6424 [D loss: 0.690531, acc.: 55.47%] [G loss: 0.930234]\n",
      "epoch:6 step:6425 [D loss: 0.651170, acc.: 60.16%] [G loss: 0.799853]\n",
      "epoch:6 step:6426 [D loss: 0.646581, acc.: 61.72%] [G loss: 1.011929]\n",
      "epoch:6 step:6427 [D loss: 0.612122, acc.: 66.41%] [G loss: 0.961549]\n",
      "epoch:6 step:6428 [D loss: 0.623046, acc.: 65.62%] [G loss: 0.864117]\n",
      "epoch:6 step:6429 [D loss: 0.623724, acc.: 60.94%] [G loss: 0.951337]\n",
      "epoch:6 step:6430 [D loss: 0.643931, acc.: 60.16%] [G loss: 0.991565]\n",
      "epoch:6 step:6431 [D loss: 0.662735, acc.: 60.16%] [G loss: 1.017862]\n",
      "epoch:6 step:6432 [D loss: 0.724726, acc.: 52.34%] [G loss: 0.963531]\n",
      "epoch:6 step:6433 [D loss: 0.655475, acc.: 64.06%] [G loss: 1.040088]\n",
      "epoch:6 step:6434 [D loss: 0.755980, acc.: 47.66%] [G loss: 0.852475]\n",
      "epoch:6 step:6435 [D loss: 0.724021, acc.: 53.12%] [G loss: 0.889036]\n",
      "epoch:6 step:6436 [D loss: 0.676159, acc.: 57.81%] [G loss: 1.003937]\n",
      "epoch:6 step:6437 [D loss: 0.704845, acc.: 57.03%] [G loss: 0.821174]\n",
      "epoch:6 step:6438 [D loss: 0.655201, acc.: 60.94%] [G loss: 0.988836]\n",
      "epoch:6 step:6439 [D loss: 0.678690, acc.: 58.59%] [G loss: 0.967923]\n",
      "epoch:6 step:6440 [D loss: 0.630893, acc.: 67.19%] [G loss: 0.943962]\n",
      "epoch:6 step:6441 [D loss: 0.651972, acc.: 57.03%] [G loss: 0.888593]\n",
      "epoch:6 step:6442 [D loss: 0.694792, acc.: 60.16%] [G loss: 0.956313]\n",
      "epoch:6 step:6443 [D loss: 0.670933, acc.: 60.94%] [G loss: 0.901525]\n",
      "epoch:6 step:6444 [D loss: 0.642179, acc.: 64.84%] [G loss: 0.916506]\n",
      "epoch:6 step:6445 [D loss: 0.641464, acc.: 65.62%] [G loss: 0.931485]\n",
      "epoch:6 step:6446 [D loss: 0.631136, acc.: 66.41%] [G loss: 0.956839]\n",
      "epoch:6 step:6447 [D loss: 0.673871, acc.: 58.59%] [G loss: 0.912133]\n",
      "epoch:6 step:6448 [D loss: 0.720709, acc.: 52.34%] [G loss: 0.891812]\n",
      "epoch:6 step:6449 [D loss: 0.695618, acc.: 53.12%] [G loss: 0.907660]\n",
      "epoch:6 step:6450 [D loss: 0.717547, acc.: 54.69%] [G loss: 0.826398]\n",
      "epoch:6 step:6451 [D loss: 0.726992, acc.: 57.03%] [G loss: 0.854839]\n",
      "epoch:6 step:6452 [D loss: 0.630348, acc.: 62.50%] [G loss: 1.016478]\n",
      "epoch:6 step:6453 [D loss: 0.619610, acc.: 65.62%] [G loss: 0.883069]\n",
      "epoch:6 step:6454 [D loss: 0.590046, acc.: 69.53%] [G loss: 1.077177]\n",
      "epoch:6 step:6455 [D loss: 0.646737, acc.: 63.28%] [G loss: 1.081667]\n",
      "epoch:6 step:6456 [D loss: 0.637076, acc.: 60.16%] [G loss: 0.983518]\n",
      "epoch:6 step:6457 [D loss: 0.645832, acc.: 60.94%] [G loss: 0.996086]\n",
      "epoch:6 step:6458 [D loss: 0.692610, acc.: 53.91%] [G loss: 0.899182]\n",
      "epoch:6 step:6459 [D loss: 0.663155, acc.: 55.47%] [G loss: 0.933222]\n",
      "epoch:6 step:6460 [D loss: 0.606583, acc.: 67.19%] [G loss: 0.999178]\n",
      "epoch:6 step:6461 [D loss: 0.644168, acc.: 64.84%] [G loss: 0.941574]\n",
      "epoch:6 step:6462 [D loss: 0.653274, acc.: 64.84%] [G loss: 0.892421]\n",
      "epoch:6 step:6463 [D loss: 0.663554, acc.: 60.16%] [G loss: 0.971997]\n",
      "epoch:6 step:6464 [D loss: 0.628857, acc.: 64.06%] [G loss: 1.016384]\n",
      "epoch:6 step:6465 [D loss: 0.673282, acc.: 57.81%] [G loss: 0.915573]\n",
      "epoch:6 step:6466 [D loss: 0.671919, acc.: 64.06%] [G loss: 0.998261]\n",
      "epoch:6 step:6467 [D loss: 0.694598, acc.: 57.81%] [G loss: 0.973237]\n",
      "epoch:6 step:6468 [D loss: 0.640841, acc.: 62.50%] [G loss: 1.005050]\n",
      "epoch:6 step:6469 [D loss: 0.707575, acc.: 54.69%] [G loss: 1.021518]\n",
      "epoch:6 step:6470 [D loss: 0.677227, acc.: 59.38%] [G loss: 1.029219]\n",
      "epoch:6 step:6471 [D loss: 0.615530, acc.: 64.84%] [G loss: 1.021949]\n",
      "epoch:6 step:6472 [D loss: 0.569418, acc.: 77.34%] [G loss: 0.949503]\n",
      "epoch:6 step:6473 [D loss: 0.634043, acc.: 64.06%] [G loss: 1.002728]\n",
      "epoch:6 step:6474 [D loss: 0.662313, acc.: 62.50%] [G loss: 0.978985]\n",
      "epoch:6 step:6475 [D loss: 0.594651, acc.: 71.09%] [G loss: 0.996181]\n",
      "epoch:6 step:6476 [D loss: 0.621493, acc.: 65.62%] [G loss: 1.005022]\n",
      "epoch:6 step:6477 [D loss: 0.566637, acc.: 71.88%] [G loss: 1.048312]\n",
      "epoch:6 step:6478 [D loss: 0.689051, acc.: 63.28%] [G loss: 1.099759]\n",
      "epoch:6 step:6479 [D loss: 0.598730, acc.: 69.53%] [G loss: 0.944830]\n",
      "epoch:6 step:6480 [D loss: 0.770136, acc.: 53.12%] [G loss: 0.961014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6481 [D loss: 0.759767, acc.: 46.09%] [G loss: 0.895609]\n",
      "epoch:6 step:6482 [D loss: 0.595031, acc.: 67.19%] [G loss: 0.907034]\n",
      "epoch:6 step:6483 [D loss: 0.757806, acc.: 48.44%] [G loss: 0.979972]\n",
      "epoch:6 step:6484 [D loss: 0.638479, acc.: 58.59%] [G loss: 0.925572]\n",
      "epoch:6 step:6485 [D loss: 0.597431, acc.: 69.53%] [G loss: 0.963040]\n",
      "epoch:6 step:6486 [D loss: 0.660855, acc.: 58.59%] [G loss: 0.928129]\n",
      "epoch:6 step:6487 [D loss: 0.625030, acc.: 63.28%] [G loss: 0.888329]\n",
      "epoch:6 step:6488 [D loss: 0.639907, acc.: 57.03%] [G loss: 1.041332]\n",
      "epoch:6 step:6489 [D loss: 0.687682, acc.: 60.94%] [G loss: 0.878062]\n",
      "epoch:6 step:6490 [D loss: 0.593341, acc.: 70.31%] [G loss: 0.974287]\n",
      "epoch:6 step:6491 [D loss: 0.667271, acc.: 59.38%] [G loss: 0.931642]\n",
      "epoch:6 step:6492 [D loss: 0.699100, acc.: 55.47%] [G loss: 0.838639]\n",
      "epoch:6 step:6493 [D loss: 0.609567, acc.: 64.84%] [G loss: 0.927426]\n",
      "epoch:6 step:6494 [D loss: 0.614530, acc.: 64.84%] [G loss: 0.848460]\n",
      "epoch:6 step:6495 [D loss: 0.672023, acc.: 60.94%] [G loss: 0.885759]\n",
      "epoch:6 step:6496 [D loss: 0.706309, acc.: 57.81%] [G loss: 0.927147]\n",
      "epoch:6 step:6497 [D loss: 0.696815, acc.: 59.38%] [G loss: 0.871366]\n",
      "epoch:6 step:6498 [D loss: 0.615721, acc.: 66.41%] [G loss: 1.041386]\n",
      "epoch:6 step:6499 [D loss: 0.648422, acc.: 60.94%] [G loss: 0.956352]\n",
      "epoch:6 step:6500 [D loss: 0.643988, acc.: 63.28%] [G loss: 0.998977]\n",
      "epoch:6 step:6501 [D loss: 0.586196, acc.: 71.88%] [G loss: 0.978270]\n",
      "epoch:6 step:6502 [D loss: 0.646324, acc.: 63.28%] [G loss: 1.048720]\n",
      "epoch:6 step:6503 [D loss: 0.701127, acc.: 50.00%] [G loss: 0.918321]\n",
      "epoch:6 step:6504 [D loss: 0.637401, acc.: 64.06%] [G loss: 0.942254]\n",
      "epoch:6 step:6505 [D loss: 0.641909, acc.: 62.50%] [G loss: 0.940079]\n",
      "epoch:6 step:6506 [D loss: 0.633016, acc.: 61.72%] [G loss: 0.933028]\n",
      "epoch:6 step:6507 [D loss: 0.605611, acc.: 65.62%] [G loss: 0.926046]\n",
      "epoch:6 step:6508 [D loss: 0.620274, acc.: 67.19%] [G loss: 0.990908]\n",
      "epoch:6 step:6509 [D loss: 0.565620, acc.: 75.78%] [G loss: 1.004566]\n",
      "epoch:6 step:6510 [D loss: 0.575697, acc.: 71.88%] [G loss: 1.051967]\n",
      "epoch:6 step:6511 [D loss: 0.629755, acc.: 63.28%] [G loss: 1.054028]\n",
      "epoch:6 step:6512 [D loss: 0.567082, acc.: 74.22%] [G loss: 1.004027]\n",
      "epoch:6 step:6513 [D loss: 0.796607, acc.: 42.19%] [G loss: 1.008857]\n",
      "epoch:6 step:6514 [D loss: 0.795577, acc.: 47.66%] [G loss: 0.967613]\n",
      "epoch:6 step:6515 [D loss: 0.656118, acc.: 59.38%] [G loss: 0.945032]\n",
      "epoch:6 step:6516 [D loss: 0.562414, acc.: 73.44%] [G loss: 1.085942]\n",
      "epoch:6 step:6517 [D loss: 0.636979, acc.: 59.38%] [G loss: 0.928877]\n",
      "epoch:6 step:6518 [D loss: 0.613213, acc.: 65.62%] [G loss: 1.064955]\n",
      "epoch:6 step:6519 [D loss: 0.630376, acc.: 63.28%] [G loss: 0.881608]\n",
      "epoch:6 step:6520 [D loss: 0.620433, acc.: 62.50%] [G loss: 0.871851]\n",
      "epoch:6 step:6521 [D loss: 0.629817, acc.: 60.16%] [G loss: 0.957199]\n",
      "epoch:6 step:6522 [D loss: 0.622340, acc.: 61.72%] [G loss: 0.971466]\n",
      "epoch:6 step:6523 [D loss: 0.554477, acc.: 74.22%] [G loss: 1.176985]\n",
      "epoch:6 step:6524 [D loss: 0.670242, acc.: 57.81%] [G loss: 1.046780]\n",
      "epoch:6 step:6525 [D loss: 0.665952, acc.: 59.38%] [G loss: 0.985419]\n",
      "epoch:6 step:6526 [D loss: 0.693609, acc.: 57.81%] [G loss: 0.923046]\n",
      "epoch:6 step:6527 [D loss: 0.664511, acc.: 60.16%] [G loss: 1.110809]\n",
      "epoch:6 step:6528 [D loss: 0.646134, acc.: 62.50%] [G loss: 1.011486]\n",
      "epoch:6 step:6529 [D loss: 0.656200, acc.: 61.72%] [G loss: 0.873242]\n",
      "epoch:6 step:6530 [D loss: 0.707276, acc.: 57.81%] [G loss: 0.955754]\n",
      "epoch:6 step:6531 [D loss: 0.633128, acc.: 67.97%] [G loss: 0.930953]\n",
      "epoch:6 step:6532 [D loss: 0.539500, acc.: 75.78%] [G loss: 1.011589]\n",
      "epoch:6 step:6533 [D loss: 0.555531, acc.: 77.34%] [G loss: 0.925795]\n",
      "epoch:6 step:6534 [D loss: 0.608630, acc.: 67.19%] [G loss: 1.086203]\n",
      "epoch:6 step:6535 [D loss: 0.692967, acc.: 53.91%] [G loss: 1.094070]\n",
      "epoch:6 step:6536 [D loss: 0.718314, acc.: 57.03%] [G loss: 0.920171]\n",
      "epoch:6 step:6537 [D loss: 0.707413, acc.: 56.25%] [G loss: 0.984355]\n",
      "epoch:6 step:6538 [D loss: 0.659881, acc.: 56.25%] [G loss: 1.013045]\n",
      "epoch:6 step:6539 [D loss: 0.715097, acc.: 53.91%] [G loss: 0.811453]\n",
      "epoch:6 step:6540 [D loss: 0.620963, acc.: 65.62%] [G loss: 1.005060]\n",
      "epoch:6 step:6541 [D loss: 0.527524, acc.: 75.78%] [G loss: 1.078637]\n",
      "epoch:6 step:6542 [D loss: 0.769105, acc.: 53.91%] [G loss: 1.029531]\n",
      "epoch:6 step:6543 [D loss: 0.674229, acc.: 60.16%] [G loss: 1.069717]\n",
      "epoch:6 step:6544 [D loss: 0.590442, acc.: 75.78%] [G loss: 0.941776]\n",
      "epoch:6 step:6545 [D loss: 0.495065, acc.: 85.94%] [G loss: 0.980656]\n",
      "epoch:6 step:6546 [D loss: 0.545938, acc.: 78.12%] [G loss: 1.016171]\n",
      "epoch:6 step:6547 [D loss: 0.550315, acc.: 77.34%] [G loss: 1.133070]\n",
      "epoch:6 step:6548 [D loss: 0.610046, acc.: 67.97%] [G loss: 1.054108]\n",
      "epoch:6 step:6549 [D loss: 0.619793, acc.: 67.97%] [G loss: 1.116798]\n",
      "epoch:6 step:6550 [D loss: 0.829234, acc.: 43.75%] [G loss: 1.010906]\n",
      "epoch:6 step:6551 [D loss: 0.708855, acc.: 55.47%] [G loss: 0.908756]\n",
      "epoch:6 step:6552 [D loss: 0.535910, acc.: 77.34%] [G loss: 0.921095]\n",
      "epoch:6 step:6553 [D loss: 0.613255, acc.: 65.62%] [G loss: 0.925933]\n",
      "epoch:6 step:6554 [D loss: 0.700438, acc.: 54.69%] [G loss: 0.914151]\n",
      "epoch:6 step:6555 [D loss: 0.619285, acc.: 67.19%] [G loss: 1.030473]\n",
      "epoch:6 step:6556 [D loss: 0.645076, acc.: 66.41%] [G loss: 1.009500]\n",
      "epoch:6 step:6557 [D loss: 0.690213, acc.: 52.34%] [G loss: 0.935696]\n",
      "epoch:6 step:6558 [D loss: 0.618035, acc.: 65.62%] [G loss: 1.004642]\n",
      "epoch:6 step:6559 [D loss: 0.434808, acc.: 89.84%] [G loss: 1.302484]\n",
      "epoch:7 step:6560 [D loss: 0.682974, acc.: 57.81%] [G loss: 0.895322]\n",
      "epoch:7 step:6561 [D loss: 0.615855, acc.: 67.97%] [G loss: 1.136460]\n",
      "epoch:7 step:6562 [D loss: 0.702595, acc.: 54.69%] [G loss: 1.048087]\n",
      "epoch:7 step:6563 [D loss: 0.668721, acc.: 57.81%] [G loss: 1.008708]\n",
      "epoch:7 step:6564 [D loss: 0.599622, acc.: 70.31%] [G loss: 1.080680]\n",
      "epoch:7 step:6565 [D loss: 0.708102, acc.: 55.47%] [G loss: 0.882499]\n",
      "epoch:7 step:6566 [D loss: 0.636493, acc.: 64.06%] [G loss: 0.994001]\n",
      "epoch:7 step:6567 [D loss: 0.569625, acc.: 71.09%] [G loss: 1.124988]\n",
      "epoch:7 step:6568 [D loss: 0.628952, acc.: 64.84%] [G loss: 1.126967]\n",
      "epoch:7 step:6569 [D loss: 0.651621, acc.: 60.16%] [G loss: 1.086820]\n",
      "epoch:7 step:6570 [D loss: 0.637677, acc.: 63.28%] [G loss: 0.951387]\n",
      "epoch:7 step:6571 [D loss: 0.634077, acc.: 65.62%] [G loss: 0.945703]\n",
      "epoch:7 step:6572 [D loss: 0.681066, acc.: 54.69%] [G loss: 1.015570]\n",
      "epoch:7 step:6573 [D loss: 0.650424, acc.: 63.28%] [G loss: 0.933716]\n",
      "epoch:7 step:6574 [D loss: 0.604594, acc.: 68.75%] [G loss: 1.017091]\n",
      "epoch:7 step:6575 [D loss: 0.601621, acc.: 64.84%] [G loss: 1.062466]\n",
      "epoch:7 step:6576 [D loss: 0.762989, acc.: 52.34%] [G loss: 0.938667]\n",
      "epoch:7 step:6577 [D loss: 0.780704, acc.: 46.88%] [G loss: 0.887529]\n",
      "epoch:7 step:6578 [D loss: 0.596566, acc.: 69.53%] [G loss: 1.063371]\n",
      "epoch:7 step:6579 [D loss: 0.700361, acc.: 53.91%] [G loss: 1.066786]\n",
      "epoch:7 step:6580 [D loss: 0.680727, acc.: 57.03%] [G loss: 0.822626]\n",
      "epoch:7 step:6581 [D loss: 0.717928, acc.: 54.69%] [G loss: 0.825764]\n",
      "epoch:7 step:6582 [D loss: 0.677979, acc.: 57.81%] [G loss: 1.046503]\n",
      "epoch:7 step:6583 [D loss: 0.638101, acc.: 64.06%] [G loss: 1.032708]\n",
      "epoch:7 step:6584 [D loss: 0.631049, acc.: 60.16%] [G loss: 0.918954]\n",
      "epoch:7 step:6585 [D loss: 0.630021, acc.: 62.50%] [G loss: 1.144195]\n",
      "epoch:7 step:6586 [D loss: 0.608606, acc.: 66.41%] [G loss: 1.041273]\n",
      "epoch:7 step:6587 [D loss: 0.650060, acc.: 61.72%] [G loss: 0.926124]\n",
      "epoch:7 step:6588 [D loss: 0.611377, acc.: 67.97%] [G loss: 1.037513]\n",
      "epoch:7 step:6589 [D loss: 0.699356, acc.: 55.47%] [G loss: 0.937177]\n",
      "epoch:7 step:6590 [D loss: 0.661091, acc.: 58.59%] [G loss: 1.007616]\n",
      "epoch:7 step:6591 [D loss: 0.638955, acc.: 61.72%] [G loss: 0.864428]\n",
      "epoch:7 step:6592 [D loss: 0.606077, acc.: 71.88%] [G loss: 0.981880]\n",
      "epoch:7 step:6593 [D loss: 0.622354, acc.: 65.62%] [G loss: 1.009892]\n",
      "epoch:7 step:6594 [D loss: 0.646079, acc.: 60.94%] [G loss: 1.064041]\n",
      "epoch:7 step:6595 [D loss: 0.549839, acc.: 72.66%] [G loss: 0.984176]\n",
      "epoch:7 step:6596 [D loss: 0.641681, acc.: 61.72%] [G loss: 1.096374]\n",
      "epoch:7 step:6597 [D loss: 0.676654, acc.: 61.72%] [G loss: 1.072041]\n",
      "epoch:7 step:6598 [D loss: 0.755560, acc.: 50.00%] [G loss: 0.994948]\n",
      "epoch:7 step:6599 [D loss: 0.579499, acc.: 65.62%] [G loss: 1.050846]\n",
      "epoch:7 step:6600 [D loss: 0.709352, acc.: 52.34%] [G loss: 0.926356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6601 [D loss: 0.652871, acc.: 64.84%] [G loss: 0.907494]\n",
      "epoch:7 step:6602 [D loss: 0.583322, acc.: 69.53%] [G loss: 0.908081]\n",
      "epoch:7 step:6603 [D loss: 0.766563, acc.: 47.66%] [G loss: 0.876978]\n",
      "epoch:7 step:6604 [D loss: 0.690450, acc.: 53.12%] [G loss: 0.844809]\n",
      "epoch:7 step:6605 [D loss: 0.683205, acc.: 48.44%] [G loss: 1.032365]\n",
      "epoch:7 step:6606 [D loss: 0.592748, acc.: 69.53%] [G loss: 0.935732]\n",
      "epoch:7 step:6607 [D loss: 0.678867, acc.: 57.81%] [G loss: 0.964342]\n",
      "epoch:7 step:6608 [D loss: 0.619806, acc.: 68.75%] [G loss: 1.033898]\n",
      "epoch:7 step:6609 [D loss: 0.649695, acc.: 62.50%] [G loss: 0.955510]\n",
      "epoch:7 step:6610 [D loss: 0.625767, acc.: 67.19%] [G loss: 1.027209]\n",
      "epoch:7 step:6611 [D loss: 0.662484, acc.: 59.38%] [G loss: 0.926368]\n",
      "epoch:7 step:6612 [D loss: 0.670683, acc.: 60.16%] [G loss: 1.041796]\n",
      "epoch:7 step:6613 [D loss: 0.627477, acc.: 60.94%] [G loss: 0.997863]\n",
      "epoch:7 step:6614 [D loss: 0.611413, acc.: 63.28%] [G loss: 1.022645]\n",
      "epoch:7 step:6615 [D loss: 0.734285, acc.: 51.56%] [G loss: 0.939905]\n",
      "epoch:7 step:6616 [D loss: 0.721570, acc.: 55.47%] [G loss: 0.949709]\n",
      "epoch:7 step:6617 [D loss: 0.694177, acc.: 58.59%] [G loss: 0.956407]\n",
      "epoch:7 step:6618 [D loss: 0.724907, acc.: 56.25%] [G loss: 0.915714]\n",
      "epoch:7 step:6619 [D loss: 0.661067, acc.: 60.16%] [G loss: 0.899949]\n",
      "epoch:7 step:6620 [D loss: 0.628752, acc.: 66.41%] [G loss: 1.006741]\n",
      "epoch:7 step:6621 [D loss: 0.626503, acc.: 64.84%] [G loss: 0.892613]\n",
      "epoch:7 step:6622 [D loss: 0.711807, acc.: 53.12%] [G loss: 0.868332]\n",
      "epoch:7 step:6623 [D loss: 0.655865, acc.: 62.50%] [G loss: 0.978638]\n",
      "epoch:7 step:6624 [D loss: 0.670714, acc.: 57.81%] [G loss: 1.015589]\n",
      "epoch:7 step:6625 [D loss: 0.700400, acc.: 54.69%] [G loss: 0.844860]\n",
      "epoch:7 step:6626 [D loss: 0.649458, acc.: 62.50%] [G loss: 0.957479]\n",
      "epoch:7 step:6627 [D loss: 0.671899, acc.: 57.03%] [G loss: 0.975428]\n",
      "epoch:7 step:6628 [D loss: 0.596467, acc.: 69.53%] [G loss: 1.044823]\n",
      "epoch:7 step:6629 [D loss: 0.614227, acc.: 65.62%] [G loss: 0.988099]\n",
      "epoch:7 step:6630 [D loss: 0.596334, acc.: 69.53%] [G loss: 0.897402]\n",
      "epoch:7 step:6631 [D loss: 0.591291, acc.: 71.09%] [G loss: 0.935883]\n",
      "epoch:7 step:6632 [D loss: 0.672132, acc.: 61.72%] [G loss: 1.080309]\n",
      "epoch:7 step:6633 [D loss: 0.591319, acc.: 65.62%] [G loss: 1.087344]\n",
      "epoch:7 step:6634 [D loss: 0.602900, acc.: 67.19%] [G loss: 1.163359]\n",
      "epoch:7 step:6635 [D loss: 0.574664, acc.: 72.66%] [G loss: 0.989513]\n",
      "epoch:7 step:6636 [D loss: 0.553682, acc.: 67.19%] [G loss: 1.113508]\n",
      "epoch:7 step:6637 [D loss: 0.749118, acc.: 46.09%] [G loss: 0.934563]\n",
      "epoch:7 step:6638 [D loss: 0.676476, acc.: 64.84%] [G loss: 0.890454]\n",
      "epoch:7 step:6639 [D loss: 0.648075, acc.: 59.38%] [G loss: 0.860051]\n",
      "epoch:7 step:6640 [D loss: 0.761615, acc.: 46.09%] [G loss: 0.819335]\n",
      "epoch:7 step:6641 [D loss: 0.713937, acc.: 53.12%] [G loss: 0.937184]\n",
      "epoch:7 step:6642 [D loss: 0.658244, acc.: 60.94%] [G loss: 1.033468]\n",
      "epoch:7 step:6643 [D loss: 0.616707, acc.: 64.06%] [G loss: 1.015444]\n",
      "epoch:7 step:6644 [D loss: 0.693717, acc.: 50.00%] [G loss: 0.916717]\n",
      "epoch:7 step:6645 [D loss: 0.660806, acc.: 60.94%] [G loss: 0.912315]\n",
      "epoch:7 step:6646 [D loss: 0.689933, acc.: 57.81%] [G loss: 0.903556]\n",
      "epoch:7 step:6647 [D loss: 0.633611, acc.: 67.97%] [G loss: 0.999958]\n",
      "epoch:7 step:6648 [D loss: 0.732043, acc.: 53.12%] [G loss: 0.910173]\n",
      "epoch:7 step:6649 [D loss: 0.733792, acc.: 46.09%] [G loss: 0.836893]\n",
      "epoch:7 step:6650 [D loss: 0.620582, acc.: 69.53%] [G loss: 1.009614]\n",
      "epoch:7 step:6651 [D loss: 0.643906, acc.: 62.50%] [G loss: 0.882220]\n",
      "epoch:7 step:6652 [D loss: 0.617489, acc.: 67.19%] [G loss: 0.998496]\n",
      "epoch:7 step:6653 [D loss: 0.698320, acc.: 52.34%] [G loss: 0.935529]\n",
      "epoch:7 step:6654 [D loss: 0.703951, acc.: 50.00%] [G loss: 0.881183]\n",
      "epoch:7 step:6655 [D loss: 0.653155, acc.: 64.84%] [G loss: 0.937271]\n",
      "epoch:7 step:6656 [D loss: 0.594639, acc.: 68.75%] [G loss: 1.003945]\n",
      "epoch:7 step:6657 [D loss: 0.663966, acc.: 61.72%] [G loss: 0.900765]\n",
      "epoch:7 step:6658 [D loss: 0.709030, acc.: 53.91%] [G loss: 0.975436]\n",
      "epoch:7 step:6659 [D loss: 0.671975, acc.: 57.81%] [G loss: 0.897754]\n",
      "epoch:7 step:6660 [D loss: 0.651683, acc.: 60.16%] [G loss: 0.978059]\n",
      "epoch:7 step:6661 [D loss: 0.646754, acc.: 67.19%] [G loss: 0.957308]\n",
      "epoch:7 step:6662 [D loss: 0.568239, acc.: 73.44%] [G loss: 1.095343]\n",
      "epoch:7 step:6663 [D loss: 0.643952, acc.: 61.72%] [G loss: 1.147967]\n",
      "epoch:7 step:6664 [D loss: 0.717939, acc.: 53.12%] [G loss: 1.036433]\n",
      "epoch:7 step:6665 [D loss: 0.624569, acc.: 66.41%] [G loss: 0.987258]\n",
      "epoch:7 step:6666 [D loss: 0.696788, acc.: 55.47%] [G loss: 1.036951]\n",
      "epoch:7 step:6667 [D loss: 0.693999, acc.: 54.69%] [G loss: 0.941978]\n",
      "epoch:7 step:6668 [D loss: 0.754267, acc.: 47.66%] [G loss: 0.869343]\n",
      "epoch:7 step:6669 [D loss: 0.697665, acc.: 53.12%] [G loss: 0.881918]\n",
      "epoch:7 step:6670 [D loss: 0.574279, acc.: 70.31%] [G loss: 1.005946]\n",
      "epoch:7 step:6671 [D loss: 0.644207, acc.: 65.62%] [G loss: 0.869269]\n",
      "epoch:7 step:6672 [D loss: 0.637050, acc.: 60.94%] [G loss: 1.032225]\n",
      "epoch:7 step:6673 [D loss: 0.700498, acc.: 53.12%] [G loss: 1.010822]\n",
      "epoch:7 step:6674 [D loss: 0.693653, acc.: 57.81%] [G loss: 0.883751]\n",
      "epoch:7 step:6675 [D loss: 0.615429, acc.: 67.19%] [G loss: 0.930195]\n",
      "epoch:7 step:6676 [D loss: 0.671919, acc.: 60.94%] [G loss: 0.940634]\n",
      "epoch:7 step:6677 [D loss: 0.628399, acc.: 67.97%] [G loss: 0.912569]\n",
      "epoch:7 step:6678 [D loss: 0.662699, acc.: 61.72%] [G loss: 0.958983]\n",
      "epoch:7 step:6679 [D loss: 0.686384, acc.: 56.25%] [G loss: 1.024851]\n",
      "epoch:7 step:6680 [D loss: 0.635203, acc.: 65.62%] [G loss: 0.980512]\n",
      "epoch:7 step:6681 [D loss: 0.649055, acc.: 62.50%] [G loss: 0.957623]\n",
      "epoch:7 step:6682 [D loss: 0.620244, acc.: 66.41%] [G loss: 0.866937]\n",
      "epoch:7 step:6683 [D loss: 0.673647, acc.: 59.38%] [G loss: 0.948116]\n",
      "epoch:7 step:6684 [D loss: 0.703842, acc.: 49.22%] [G loss: 0.916944]\n",
      "epoch:7 step:6685 [D loss: 0.644830, acc.: 58.59%] [G loss: 0.870476]\n",
      "epoch:7 step:6686 [D loss: 0.666515, acc.: 59.38%] [G loss: 0.861468]\n",
      "epoch:7 step:6687 [D loss: 0.656079, acc.: 63.28%] [G loss: 0.936039]\n",
      "epoch:7 step:6688 [D loss: 0.714577, acc.: 54.69%] [G loss: 0.852137]\n",
      "epoch:7 step:6689 [D loss: 0.722922, acc.: 55.47%] [G loss: 1.012440]\n",
      "epoch:7 step:6690 [D loss: 0.615437, acc.: 67.19%] [G loss: 1.105986]\n",
      "epoch:7 step:6691 [D loss: 0.610084, acc.: 65.62%] [G loss: 0.900685]\n",
      "epoch:7 step:6692 [D loss: 0.765863, acc.: 46.88%] [G loss: 0.992744]\n",
      "epoch:7 step:6693 [D loss: 0.712276, acc.: 55.47%] [G loss: 0.853068]\n",
      "epoch:7 step:6694 [D loss: 0.675516, acc.: 60.94%] [G loss: 0.901198]\n",
      "epoch:7 step:6695 [D loss: 0.640969, acc.: 63.28%] [G loss: 1.040589]\n",
      "epoch:7 step:6696 [D loss: 0.637275, acc.: 66.41%] [G loss: 0.924094]\n",
      "epoch:7 step:6697 [D loss: 0.719372, acc.: 51.56%] [G loss: 0.928110]\n",
      "epoch:7 step:6698 [D loss: 0.694882, acc.: 58.59%] [G loss: 0.830734]\n",
      "epoch:7 step:6699 [D loss: 0.616440, acc.: 64.06%] [G loss: 0.909715]\n",
      "epoch:7 step:6700 [D loss: 0.669010, acc.: 56.25%] [G loss: 1.030245]\n",
      "epoch:7 step:6701 [D loss: 0.621483, acc.: 67.97%] [G loss: 1.137124]\n",
      "epoch:7 step:6702 [D loss: 0.677378, acc.: 57.81%] [G loss: 1.088401]\n",
      "epoch:7 step:6703 [D loss: 0.567780, acc.: 73.44%] [G loss: 1.168907]\n",
      "epoch:7 step:6704 [D loss: 0.709634, acc.: 53.91%] [G loss: 0.994685]\n",
      "epoch:7 step:6705 [D loss: 0.566056, acc.: 74.22%] [G loss: 0.924381]\n",
      "epoch:7 step:6706 [D loss: 0.687406, acc.: 54.69%] [G loss: 0.973361]\n",
      "epoch:7 step:6707 [D loss: 0.777369, acc.: 42.97%] [G loss: 0.845164]\n",
      "epoch:7 step:6708 [D loss: 0.651741, acc.: 64.84%] [G loss: 0.952057]\n",
      "epoch:7 step:6709 [D loss: 0.647640, acc.: 62.50%] [G loss: 0.925990]\n",
      "epoch:7 step:6710 [D loss: 0.627647, acc.: 68.75%] [G loss: 0.810187]\n",
      "epoch:7 step:6711 [D loss: 0.587445, acc.: 67.97%] [G loss: 0.874073]\n",
      "epoch:7 step:6712 [D loss: 0.710962, acc.: 54.69%] [G loss: 0.965552]\n",
      "epoch:7 step:6713 [D loss: 0.591538, acc.: 71.88%] [G loss: 0.982334]\n",
      "epoch:7 step:6714 [D loss: 0.663634, acc.: 57.81%] [G loss: 0.949025]\n",
      "epoch:7 step:6715 [D loss: 0.664216, acc.: 56.25%] [G loss: 1.182481]\n",
      "epoch:7 step:6716 [D loss: 0.725646, acc.: 56.25%] [G loss: 0.823360]\n",
      "epoch:7 step:6717 [D loss: 0.650339, acc.: 60.94%] [G loss: 1.079685]\n",
      "epoch:7 step:6718 [D loss: 0.674041, acc.: 61.72%] [G loss: 1.014513]\n",
      "epoch:7 step:6719 [D loss: 0.808403, acc.: 39.06%] [G loss: 1.037051]\n",
      "epoch:7 step:6720 [D loss: 0.647699, acc.: 63.28%] [G loss: 1.015054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6721 [D loss: 0.690528, acc.: 56.25%] [G loss: 0.918858]\n",
      "epoch:7 step:6722 [D loss: 0.642966, acc.: 66.41%] [G loss: 0.941075]\n",
      "epoch:7 step:6723 [D loss: 0.690275, acc.: 54.69%] [G loss: 0.992424]\n",
      "epoch:7 step:6724 [D loss: 0.700608, acc.: 57.03%] [G loss: 0.887566]\n",
      "epoch:7 step:6725 [D loss: 0.693038, acc.: 55.47%] [G loss: 0.867784]\n",
      "epoch:7 step:6726 [D loss: 0.773106, acc.: 45.31%] [G loss: 0.807227]\n",
      "epoch:7 step:6727 [D loss: 0.660859, acc.: 60.16%] [G loss: 0.978914]\n",
      "epoch:7 step:6728 [D loss: 0.680498, acc.: 60.94%] [G loss: 0.965871]\n",
      "epoch:7 step:6729 [D loss: 0.650970, acc.: 64.84%] [G loss: 1.023125]\n",
      "epoch:7 step:6730 [D loss: 0.580943, acc.: 68.75%] [G loss: 0.927509]\n",
      "epoch:7 step:6731 [D loss: 0.609243, acc.: 67.97%] [G loss: 1.056857]\n",
      "epoch:7 step:6732 [D loss: 0.650222, acc.: 60.94%] [G loss: 1.033068]\n",
      "epoch:7 step:6733 [D loss: 0.735376, acc.: 50.78%] [G loss: 0.910531]\n",
      "epoch:7 step:6734 [D loss: 0.662258, acc.: 60.94%] [G loss: 0.927686]\n",
      "epoch:7 step:6735 [D loss: 0.673225, acc.: 57.81%] [G loss: 0.915390]\n",
      "epoch:7 step:6736 [D loss: 0.648717, acc.: 63.28%] [G loss: 0.967683]\n",
      "epoch:7 step:6737 [D loss: 0.569731, acc.: 74.22%] [G loss: 0.987856]\n",
      "epoch:7 step:6738 [D loss: 0.654573, acc.: 66.41%] [G loss: 0.946808]\n",
      "epoch:7 step:6739 [D loss: 0.648546, acc.: 66.41%] [G loss: 0.916011]\n",
      "epoch:7 step:6740 [D loss: 0.623605, acc.: 63.28%] [G loss: 0.977300]\n",
      "epoch:7 step:6741 [D loss: 0.710560, acc.: 52.34%] [G loss: 0.962462]\n",
      "epoch:7 step:6742 [D loss: 0.700920, acc.: 54.69%] [G loss: 1.011519]\n",
      "epoch:7 step:6743 [D loss: 0.532124, acc.: 76.56%] [G loss: 0.942202]\n",
      "epoch:7 step:6744 [D loss: 0.681783, acc.: 56.25%] [G loss: 0.956120]\n",
      "epoch:7 step:6745 [D loss: 0.644202, acc.: 60.16%] [G loss: 0.925053]\n",
      "epoch:7 step:6746 [D loss: 0.726144, acc.: 53.12%] [G loss: 0.837760]\n",
      "epoch:7 step:6747 [D loss: 0.677499, acc.: 61.72%] [G loss: 0.904906]\n",
      "epoch:7 step:6748 [D loss: 0.653153, acc.: 61.72%] [G loss: 1.001523]\n",
      "epoch:7 step:6749 [D loss: 0.649254, acc.: 60.94%] [G loss: 0.921803]\n",
      "epoch:7 step:6750 [D loss: 0.587452, acc.: 67.97%] [G loss: 1.078644]\n",
      "epoch:7 step:6751 [D loss: 0.605515, acc.: 72.66%] [G loss: 0.998501]\n",
      "epoch:7 step:6752 [D loss: 0.656861, acc.: 56.25%] [G loss: 0.956144]\n",
      "epoch:7 step:6753 [D loss: 0.676539, acc.: 58.59%] [G loss: 1.033571]\n",
      "epoch:7 step:6754 [D loss: 0.650101, acc.: 58.59%] [G loss: 1.064897]\n",
      "epoch:7 step:6755 [D loss: 0.711303, acc.: 52.34%] [G loss: 0.930836]\n",
      "epoch:7 step:6756 [D loss: 0.697474, acc.: 56.25%] [G loss: 0.940071]\n",
      "epoch:7 step:6757 [D loss: 0.670563, acc.: 64.06%] [G loss: 0.900079]\n",
      "epoch:7 step:6758 [D loss: 0.720178, acc.: 46.88%] [G loss: 0.840510]\n",
      "epoch:7 step:6759 [D loss: 0.728752, acc.: 48.44%] [G loss: 0.919406]\n",
      "epoch:7 step:6760 [D loss: 0.705561, acc.: 60.16%] [G loss: 0.968271]\n",
      "epoch:7 step:6761 [D loss: 0.748090, acc.: 50.78%] [G loss: 0.859498]\n",
      "epoch:7 step:6762 [D loss: 0.676228, acc.: 56.25%] [G loss: 0.846812]\n",
      "epoch:7 step:6763 [D loss: 0.641700, acc.: 61.72%] [G loss: 0.864555]\n",
      "epoch:7 step:6764 [D loss: 0.714689, acc.: 49.22%] [G loss: 0.935396]\n",
      "epoch:7 step:6765 [D loss: 0.663471, acc.: 60.16%] [G loss: 0.912802]\n",
      "epoch:7 step:6766 [D loss: 0.620181, acc.: 70.31%] [G loss: 0.909957]\n",
      "epoch:7 step:6767 [D loss: 0.574738, acc.: 74.22%] [G loss: 0.961880]\n",
      "epoch:7 step:6768 [D loss: 0.580591, acc.: 71.09%] [G loss: 0.968668]\n",
      "epoch:7 step:6769 [D loss: 0.614861, acc.: 67.97%] [G loss: 0.989329]\n",
      "epoch:7 step:6770 [D loss: 0.646831, acc.: 61.72%] [G loss: 0.991178]\n",
      "epoch:7 step:6771 [D loss: 0.679993, acc.: 55.47%] [G loss: 0.922370]\n",
      "epoch:7 step:6772 [D loss: 0.720173, acc.: 53.12%] [G loss: 0.940570]\n",
      "epoch:7 step:6773 [D loss: 0.814348, acc.: 39.06%] [G loss: 1.010517]\n",
      "epoch:7 step:6774 [D loss: 0.736913, acc.: 57.81%] [G loss: 0.900611]\n",
      "epoch:7 step:6775 [D loss: 0.688752, acc.: 56.25%] [G loss: 0.879231]\n",
      "epoch:7 step:6776 [D loss: 0.648801, acc.: 64.84%] [G loss: 0.882011]\n",
      "epoch:7 step:6777 [D loss: 0.652955, acc.: 62.50%] [G loss: 0.761879]\n",
      "epoch:7 step:6778 [D loss: 0.556845, acc.: 75.78%] [G loss: 0.959561]\n",
      "epoch:7 step:6779 [D loss: 0.770268, acc.: 50.78%] [G loss: 0.860844]\n",
      "epoch:7 step:6780 [D loss: 0.670117, acc.: 56.25%] [G loss: 1.026486]\n",
      "epoch:7 step:6781 [D loss: 0.640865, acc.: 63.28%] [G loss: 1.043808]\n",
      "epoch:7 step:6782 [D loss: 0.640604, acc.: 63.28%] [G loss: 0.845183]\n",
      "epoch:7 step:6783 [D loss: 0.653782, acc.: 60.94%] [G loss: 1.043014]\n",
      "epoch:7 step:6784 [D loss: 0.722037, acc.: 55.47%] [G loss: 1.058341]\n",
      "epoch:7 step:6785 [D loss: 0.648530, acc.: 60.94%] [G loss: 0.974852]\n",
      "epoch:7 step:6786 [D loss: 0.604691, acc.: 67.19%] [G loss: 0.909454]\n",
      "epoch:7 step:6787 [D loss: 0.755556, acc.: 48.44%] [G loss: 0.897325]\n",
      "epoch:7 step:6788 [D loss: 0.618683, acc.: 67.19%] [G loss: 1.045784]\n",
      "epoch:7 step:6789 [D loss: 0.572322, acc.: 73.44%] [G loss: 1.018346]\n",
      "epoch:7 step:6790 [D loss: 0.578161, acc.: 69.53%] [G loss: 0.936811]\n",
      "epoch:7 step:6791 [D loss: 0.493584, acc.: 78.91%] [G loss: 1.217577]\n",
      "epoch:7 step:6792 [D loss: 0.695035, acc.: 62.50%] [G loss: 1.019801]\n",
      "epoch:7 step:6793 [D loss: 0.709839, acc.: 55.47%] [G loss: 1.009451]\n",
      "epoch:7 step:6794 [D loss: 0.677597, acc.: 55.47%] [G loss: 1.014325]\n",
      "epoch:7 step:6795 [D loss: 0.599707, acc.: 66.41%] [G loss: 0.986137]\n",
      "epoch:7 step:6796 [D loss: 0.674625, acc.: 62.50%] [G loss: 1.088133]\n",
      "epoch:7 step:6797 [D loss: 0.690451, acc.: 53.91%] [G loss: 0.918194]\n",
      "epoch:7 step:6798 [D loss: 0.696479, acc.: 57.81%] [G loss: 0.763227]\n",
      "epoch:7 step:6799 [D loss: 0.695042, acc.: 57.81%] [G loss: 0.985414]\n",
      "epoch:7 step:6800 [D loss: 0.672849, acc.: 58.59%] [G loss: 1.013802]\n",
      "epoch:7 step:6801 [D loss: 0.579480, acc.: 73.44%] [G loss: 0.969947]\n",
      "epoch:7 step:6802 [D loss: 0.646718, acc.: 67.19%] [G loss: 0.994417]\n",
      "epoch:7 step:6803 [D loss: 0.564349, acc.: 73.44%] [G loss: 0.884031]\n",
      "epoch:7 step:6804 [D loss: 0.643861, acc.: 64.06%] [G loss: 1.056211]\n",
      "epoch:7 step:6805 [D loss: 0.712582, acc.: 53.12%] [G loss: 0.941283]\n",
      "epoch:7 step:6806 [D loss: 0.726836, acc.: 49.22%] [G loss: 0.829553]\n",
      "epoch:7 step:6807 [D loss: 0.646583, acc.: 62.50%] [G loss: 0.989774]\n",
      "epoch:7 step:6808 [D loss: 0.674510, acc.: 57.81%] [G loss: 0.946345]\n",
      "epoch:7 step:6809 [D loss: 0.811958, acc.: 43.75%] [G loss: 0.876514]\n",
      "epoch:7 step:6810 [D loss: 0.730354, acc.: 51.56%] [G loss: 0.922557]\n",
      "epoch:7 step:6811 [D loss: 0.712298, acc.: 52.34%] [G loss: 0.863928]\n",
      "epoch:7 step:6812 [D loss: 0.662058, acc.: 60.94%] [G loss: 0.897891]\n",
      "epoch:7 step:6813 [D loss: 0.628248, acc.: 64.06%] [G loss: 0.920463]\n",
      "epoch:7 step:6814 [D loss: 0.673416, acc.: 63.28%] [G loss: 0.937721]\n",
      "epoch:7 step:6815 [D loss: 0.576787, acc.: 73.44%] [G loss: 0.915479]\n",
      "epoch:7 step:6816 [D loss: 0.688808, acc.: 53.91%] [G loss: 0.930793]\n",
      "epoch:7 step:6817 [D loss: 0.721350, acc.: 51.56%] [G loss: 0.780650]\n",
      "epoch:7 step:6818 [D loss: 0.640900, acc.: 63.28%] [G loss: 0.828932]\n",
      "epoch:7 step:6819 [D loss: 0.632845, acc.: 59.38%] [G loss: 1.004970]\n",
      "epoch:7 step:6820 [D loss: 0.624822, acc.: 69.53%] [G loss: 0.879945]\n",
      "epoch:7 step:6821 [D loss: 0.695344, acc.: 53.12%] [G loss: 0.813764]\n",
      "epoch:7 step:6822 [D loss: 0.636035, acc.: 64.84%] [G loss: 0.874429]\n",
      "epoch:7 step:6823 [D loss: 0.558017, acc.: 74.22%] [G loss: 1.064802]\n",
      "epoch:7 step:6824 [D loss: 0.677092, acc.: 62.50%] [G loss: 0.945178]\n",
      "epoch:7 step:6825 [D loss: 0.676631, acc.: 56.25%] [G loss: 0.934394]\n",
      "epoch:7 step:6826 [D loss: 0.747566, acc.: 51.56%] [G loss: 0.840568]\n",
      "epoch:7 step:6827 [D loss: 0.751843, acc.: 46.88%] [G loss: 0.933507]\n",
      "epoch:7 step:6828 [D loss: 0.666860, acc.: 57.03%] [G loss: 0.949738]\n",
      "epoch:7 step:6829 [D loss: 0.651958, acc.: 60.94%] [G loss: 0.818622]\n",
      "epoch:7 step:6830 [D loss: 0.627913, acc.: 59.38%] [G loss: 0.906708]\n",
      "epoch:7 step:6831 [D loss: 0.692690, acc.: 56.25%] [G loss: 0.923706]\n",
      "epoch:7 step:6832 [D loss: 0.622417, acc.: 65.62%] [G loss: 0.944360]\n",
      "epoch:7 step:6833 [D loss: 0.685624, acc.: 54.69%] [G loss: 0.921530]\n",
      "epoch:7 step:6834 [D loss: 0.675789, acc.: 57.03%] [G loss: 1.005842]\n",
      "epoch:7 step:6835 [D loss: 0.700932, acc.: 53.91%] [G loss: 0.955014]\n",
      "epoch:7 step:6836 [D loss: 0.701831, acc.: 53.12%] [G loss: 0.983011]\n",
      "epoch:7 step:6837 [D loss: 0.630408, acc.: 67.19%] [G loss: 0.881800]\n",
      "epoch:7 step:6838 [D loss: 0.684711, acc.: 59.38%] [G loss: 0.963616]\n",
      "epoch:7 step:6839 [D loss: 0.603237, acc.: 62.50%] [G loss: 0.977776]\n",
      "epoch:7 step:6840 [D loss: 0.696450, acc.: 50.00%] [G loss: 0.876358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6841 [D loss: 0.633030, acc.: 61.72%] [G loss: 1.102378]\n",
      "epoch:7 step:6842 [D loss: 0.691220, acc.: 57.03%] [G loss: 0.921953]\n",
      "epoch:7 step:6843 [D loss: 0.597721, acc.: 71.88%] [G loss: 0.950031]\n",
      "epoch:7 step:6844 [D loss: 0.691167, acc.: 55.47%] [G loss: 0.857028]\n",
      "epoch:7 step:6845 [D loss: 0.608888, acc.: 70.31%] [G loss: 0.909157]\n",
      "epoch:7 step:6846 [D loss: 0.700490, acc.: 57.03%] [G loss: 0.995404]\n",
      "epoch:7 step:6847 [D loss: 0.794106, acc.: 43.75%] [G loss: 0.814571]\n",
      "epoch:7 step:6848 [D loss: 0.586827, acc.: 70.31%] [G loss: 0.933651]\n",
      "epoch:7 step:6849 [D loss: 0.695222, acc.: 54.69%] [G loss: 0.865793]\n",
      "epoch:7 step:6850 [D loss: 0.703116, acc.: 56.25%] [G loss: 0.875156]\n",
      "epoch:7 step:6851 [D loss: 0.691366, acc.: 54.69%] [G loss: 0.942731]\n",
      "epoch:7 step:6852 [D loss: 0.569502, acc.: 71.88%] [G loss: 1.077308]\n",
      "epoch:7 step:6853 [D loss: 0.591854, acc.: 68.75%] [G loss: 1.104205]\n",
      "epoch:7 step:6854 [D loss: 0.624437, acc.: 67.19%] [G loss: 1.058764]\n",
      "epoch:7 step:6855 [D loss: 0.594852, acc.: 69.53%] [G loss: 0.964143]\n",
      "epoch:7 step:6856 [D loss: 0.664931, acc.: 60.94%] [G loss: 0.884685]\n",
      "epoch:7 step:6857 [D loss: 0.617890, acc.: 64.84%] [G loss: 0.828752]\n",
      "epoch:7 step:6858 [D loss: 0.602404, acc.: 73.44%] [G loss: 0.978682]\n",
      "epoch:7 step:6859 [D loss: 0.638252, acc.: 60.94%] [G loss: 0.996565]\n",
      "epoch:7 step:6860 [D loss: 0.733803, acc.: 52.34%] [G loss: 0.838630]\n",
      "epoch:7 step:6861 [D loss: 0.645635, acc.: 63.28%] [G loss: 1.059397]\n",
      "epoch:7 step:6862 [D loss: 0.671267, acc.: 60.94%] [G loss: 0.952528]\n",
      "epoch:7 step:6863 [D loss: 0.668293, acc.: 55.47%] [G loss: 1.001340]\n",
      "epoch:7 step:6864 [D loss: 0.681449, acc.: 56.25%] [G loss: 0.988605]\n",
      "epoch:7 step:6865 [D loss: 0.633004, acc.: 60.16%] [G loss: 0.944463]\n",
      "epoch:7 step:6866 [D loss: 0.636501, acc.: 62.50%] [G loss: 1.021733]\n",
      "epoch:7 step:6867 [D loss: 0.577729, acc.: 71.09%] [G loss: 1.010275]\n",
      "epoch:7 step:6868 [D loss: 0.609459, acc.: 68.75%] [G loss: 1.047499]\n",
      "epoch:7 step:6869 [D loss: 0.653178, acc.: 61.72%] [G loss: 0.914850]\n",
      "epoch:7 step:6870 [D loss: 0.547751, acc.: 78.91%] [G loss: 1.121932]\n",
      "epoch:7 step:6871 [D loss: 0.562433, acc.: 76.56%] [G loss: 0.951333]\n",
      "epoch:7 step:6872 [D loss: 0.560999, acc.: 69.53%] [G loss: 0.919372]\n",
      "epoch:7 step:6873 [D loss: 0.541777, acc.: 75.00%] [G loss: 1.129016]\n",
      "epoch:7 step:6874 [D loss: 0.637259, acc.: 63.28%] [G loss: 0.935065]\n",
      "epoch:7 step:6875 [D loss: 0.800391, acc.: 45.31%] [G loss: 0.930535]\n",
      "epoch:7 step:6876 [D loss: 0.668747, acc.: 58.59%] [G loss: 1.217280]\n",
      "epoch:7 step:6877 [D loss: 0.677041, acc.: 63.28%] [G loss: 0.933180]\n",
      "epoch:7 step:6878 [D loss: 0.667129, acc.: 60.16%] [G loss: 0.925052]\n",
      "epoch:7 step:6879 [D loss: 0.631623, acc.: 62.50%] [G loss: 0.965568]\n",
      "epoch:7 step:6880 [D loss: 0.609498, acc.: 67.19%] [G loss: 1.063973]\n",
      "epoch:7 step:6881 [D loss: 0.664200, acc.: 63.28%] [G loss: 1.058310]\n",
      "epoch:7 step:6882 [D loss: 0.694546, acc.: 57.81%] [G loss: 0.941108]\n",
      "epoch:7 step:6883 [D loss: 0.639161, acc.: 63.28%] [G loss: 0.965705]\n",
      "epoch:7 step:6884 [D loss: 0.610356, acc.: 67.97%] [G loss: 0.944257]\n",
      "epoch:7 step:6885 [D loss: 0.733967, acc.: 47.66%] [G loss: 0.890604]\n",
      "epoch:7 step:6886 [D loss: 0.706732, acc.: 57.03%] [G loss: 0.883231]\n",
      "epoch:7 step:6887 [D loss: 0.681420, acc.: 61.72%] [G loss: 0.928911]\n",
      "epoch:7 step:6888 [D loss: 0.658755, acc.: 58.59%] [G loss: 0.956062]\n",
      "epoch:7 step:6889 [D loss: 0.611674, acc.: 68.75%] [G loss: 0.948162]\n",
      "epoch:7 step:6890 [D loss: 0.647885, acc.: 60.94%] [G loss: 0.973772]\n",
      "epoch:7 step:6891 [D loss: 0.591083, acc.: 67.97%] [G loss: 0.861047]\n",
      "epoch:7 step:6892 [D loss: 0.679201, acc.: 55.47%] [G loss: 1.045379]\n",
      "epoch:7 step:6893 [D loss: 0.597925, acc.: 67.97%] [G loss: 1.126954]\n",
      "epoch:7 step:6894 [D loss: 0.665671, acc.: 57.03%] [G loss: 1.023740]\n",
      "epoch:7 step:6895 [D loss: 0.605288, acc.: 68.75%] [G loss: 0.993120]\n",
      "epoch:7 step:6896 [D loss: 0.603750, acc.: 67.19%] [G loss: 1.032912]\n",
      "epoch:7 step:6897 [D loss: 0.679529, acc.: 57.81%] [G loss: 0.945269]\n",
      "epoch:7 step:6898 [D loss: 0.570203, acc.: 71.88%] [G loss: 1.122390]\n",
      "epoch:7 step:6899 [D loss: 0.686837, acc.: 57.03%] [G loss: 0.992459]\n",
      "epoch:7 step:6900 [D loss: 0.618075, acc.: 63.28%] [G loss: 1.003039]\n",
      "epoch:7 step:6901 [D loss: 0.678325, acc.: 54.69%] [G loss: 0.905492]\n",
      "epoch:7 step:6902 [D loss: 0.611480, acc.: 69.53%] [G loss: 0.815461]\n",
      "epoch:7 step:6903 [D loss: 0.567127, acc.: 75.00%] [G loss: 1.031961]\n",
      "epoch:7 step:6904 [D loss: 0.575468, acc.: 68.75%] [G loss: 0.966884]\n",
      "epoch:7 step:6905 [D loss: 0.590789, acc.: 71.09%] [G loss: 1.168763]\n",
      "epoch:7 step:6906 [D loss: 0.615688, acc.: 67.19%] [G loss: 1.056865]\n",
      "epoch:7 step:6907 [D loss: 0.687944, acc.: 60.16%] [G loss: 0.947592]\n",
      "epoch:7 step:6908 [D loss: 0.731904, acc.: 48.44%] [G loss: 0.846099]\n",
      "epoch:7 step:6909 [D loss: 0.691470, acc.: 55.47%] [G loss: 0.878439]\n",
      "epoch:7 step:6910 [D loss: 0.689594, acc.: 53.12%] [G loss: 0.872104]\n",
      "epoch:7 step:6911 [D loss: 0.701798, acc.: 59.38%] [G loss: 0.983387]\n",
      "epoch:7 step:6912 [D loss: 0.658438, acc.: 61.72%] [G loss: 0.910409]\n",
      "epoch:7 step:6913 [D loss: 0.699280, acc.: 64.06%] [G loss: 0.952047]\n",
      "epoch:7 step:6914 [D loss: 0.633448, acc.: 64.06%] [G loss: 1.145151]\n",
      "epoch:7 step:6915 [D loss: 0.735741, acc.: 50.00%] [G loss: 0.846756]\n",
      "epoch:7 step:6916 [D loss: 0.589160, acc.: 73.44%] [G loss: 1.097685]\n",
      "epoch:7 step:6917 [D loss: 0.581217, acc.: 64.84%] [G loss: 1.049385]\n",
      "epoch:7 step:6918 [D loss: 0.603414, acc.: 67.19%] [G loss: 0.925119]\n",
      "epoch:7 step:6919 [D loss: 0.623793, acc.: 70.31%] [G loss: 0.952211]\n",
      "epoch:7 step:6920 [D loss: 0.692184, acc.: 53.91%] [G loss: 0.998432]\n",
      "epoch:7 step:6921 [D loss: 0.681152, acc.: 59.38%] [G loss: 0.987585]\n",
      "epoch:7 step:6922 [D loss: 0.660554, acc.: 57.81%] [G loss: 0.973402]\n",
      "epoch:7 step:6923 [D loss: 0.658160, acc.: 62.50%] [G loss: 1.054571]\n",
      "epoch:7 step:6924 [D loss: 0.641856, acc.: 60.94%] [G loss: 0.976850]\n",
      "epoch:7 step:6925 [D loss: 0.639033, acc.: 61.72%] [G loss: 1.000552]\n",
      "epoch:7 step:6926 [D loss: 0.586160, acc.: 67.97%] [G loss: 1.032839]\n",
      "epoch:7 step:6927 [D loss: 0.661775, acc.: 64.06%] [G loss: 1.108506]\n",
      "epoch:7 step:6928 [D loss: 0.713218, acc.: 50.78%] [G loss: 1.019178]\n",
      "epoch:7 step:6929 [D loss: 0.643551, acc.: 60.94%] [G loss: 1.193818]\n",
      "epoch:7 step:6930 [D loss: 0.568597, acc.: 71.09%] [G loss: 0.996941]\n",
      "epoch:7 step:6931 [D loss: 0.750119, acc.: 48.44%] [G loss: 0.873107]\n",
      "epoch:7 step:6932 [D loss: 0.696623, acc.: 55.47%] [G loss: 0.870219]\n",
      "epoch:7 step:6933 [D loss: 0.637443, acc.: 63.28%] [G loss: 0.905041]\n",
      "epoch:7 step:6934 [D loss: 0.709048, acc.: 49.22%] [G loss: 0.946271]\n",
      "epoch:7 step:6935 [D loss: 0.687515, acc.: 57.03%] [G loss: 0.977434]\n",
      "epoch:7 step:6936 [D loss: 0.736627, acc.: 53.12%] [G loss: 0.906350]\n",
      "epoch:7 step:6937 [D loss: 0.667816, acc.: 54.69%] [G loss: 0.940786]\n",
      "epoch:7 step:6938 [D loss: 0.619881, acc.: 64.84%] [G loss: 0.962306]\n",
      "epoch:7 step:6939 [D loss: 0.636611, acc.: 66.41%] [G loss: 0.981427]\n",
      "epoch:7 step:6940 [D loss: 0.566355, acc.: 75.00%] [G loss: 1.084215]\n",
      "epoch:7 step:6941 [D loss: 0.665246, acc.: 57.03%] [G loss: 0.876493]\n",
      "epoch:7 step:6942 [D loss: 0.605360, acc.: 66.41%] [G loss: 0.951475]\n",
      "epoch:7 step:6943 [D loss: 0.632234, acc.: 62.50%] [G loss: 1.042230]\n",
      "epoch:7 step:6944 [D loss: 0.592761, acc.: 66.41%] [G loss: 0.965489]\n",
      "epoch:7 step:6945 [D loss: 0.679868, acc.: 57.81%] [G loss: 0.962238]\n",
      "epoch:7 step:6946 [D loss: 0.615235, acc.: 66.41%] [G loss: 0.881460]\n",
      "epoch:7 step:6947 [D loss: 0.599444, acc.: 69.53%] [G loss: 0.999597]\n",
      "epoch:7 step:6948 [D loss: 0.643900, acc.: 61.72%] [G loss: 0.898292]\n",
      "epoch:7 step:6949 [D loss: 0.683533, acc.: 58.59%] [G loss: 0.884773]\n",
      "epoch:7 step:6950 [D loss: 0.576020, acc.: 70.31%] [G loss: 1.022168]\n",
      "epoch:7 step:6951 [D loss: 0.608211, acc.: 65.62%] [G loss: 0.937495]\n",
      "epoch:7 step:6952 [D loss: 0.667913, acc.: 56.25%] [G loss: 0.861406]\n",
      "epoch:7 step:6953 [D loss: 0.628677, acc.: 63.28%] [G loss: 1.057982]\n",
      "epoch:7 step:6954 [D loss: 0.660020, acc.: 61.72%] [G loss: 0.953705]\n",
      "epoch:7 step:6955 [D loss: 0.684294, acc.: 56.25%] [G loss: 0.855829]\n",
      "epoch:7 step:6956 [D loss: 0.636806, acc.: 69.53%] [G loss: 0.941659]\n",
      "epoch:7 step:6957 [D loss: 0.593283, acc.: 71.88%] [G loss: 1.005285]\n",
      "epoch:7 step:6958 [D loss: 0.613809, acc.: 66.41%] [G loss: 0.996226]\n",
      "epoch:7 step:6959 [D loss: 0.722733, acc.: 56.25%] [G loss: 0.829323]\n",
      "epoch:7 step:6960 [D loss: 0.608025, acc.: 70.31%] [G loss: 1.102304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6961 [D loss: 0.601418, acc.: 68.75%] [G loss: 0.973694]\n",
      "epoch:7 step:6962 [D loss: 0.607988, acc.: 68.75%] [G loss: 0.995896]\n",
      "epoch:7 step:6963 [D loss: 0.677068, acc.: 59.38%] [G loss: 0.961183]\n",
      "epoch:7 step:6964 [D loss: 0.640665, acc.: 64.06%] [G loss: 0.898532]\n",
      "epoch:7 step:6965 [D loss: 0.565204, acc.: 73.44%] [G loss: 1.051778]\n",
      "epoch:7 step:6966 [D loss: 0.694209, acc.: 59.38%] [G loss: 1.119188]\n",
      "epoch:7 step:6967 [D loss: 0.608596, acc.: 61.72%] [G loss: 1.090312]\n",
      "epoch:7 step:6968 [D loss: 0.663104, acc.: 59.38%] [G loss: 0.972552]\n",
      "epoch:7 step:6969 [D loss: 0.663979, acc.: 54.69%] [G loss: 0.960588]\n",
      "epoch:7 step:6970 [D loss: 0.745918, acc.: 52.34%] [G loss: 0.830757]\n",
      "epoch:7 step:6971 [D loss: 0.623540, acc.: 67.97%] [G loss: 1.095883]\n",
      "epoch:7 step:6972 [D loss: 0.701380, acc.: 50.78%] [G loss: 0.932240]\n",
      "epoch:7 step:6973 [D loss: 0.678667, acc.: 58.59%] [G loss: 0.982099]\n",
      "epoch:7 step:6974 [D loss: 0.668485, acc.: 64.84%] [G loss: 0.990490]\n",
      "epoch:7 step:6975 [D loss: 0.687111, acc.: 57.81%] [G loss: 0.831169]\n",
      "epoch:7 step:6976 [D loss: 0.699775, acc.: 55.47%] [G loss: 1.075168]\n",
      "epoch:7 step:6977 [D loss: 0.699637, acc.: 51.56%] [G loss: 0.895733]\n",
      "epoch:7 step:6978 [D loss: 0.672706, acc.: 57.81%] [G loss: 0.878331]\n",
      "epoch:7 step:6979 [D loss: 0.671162, acc.: 60.16%] [G loss: 1.006330]\n",
      "epoch:7 step:6980 [D loss: 0.737937, acc.: 46.09%] [G loss: 1.005969]\n",
      "epoch:7 step:6981 [D loss: 0.613290, acc.: 64.06%] [G loss: 0.967924]\n",
      "epoch:7 step:6982 [D loss: 0.736055, acc.: 55.47%] [G loss: 0.957845]\n",
      "epoch:7 step:6983 [D loss: 0.660212, acc.: 64.06%] [G loss: 0.925788]\n",
      "epoch:7 step:6984 [D loss: 0.696893, acc.: 57.03%] [G loss: 0.942760]\n",
      "epoch:7 step:6985 [D loss: 0.583196, acc.: 72.66%] [G loss: 1.002820]\n",
      "epoch:7 step:6986 [D loss: 0.615102, acc.: 70.31%] [G loss: 0.927291]\n",
      "epoch:7 step:6987 [D loss: 0.655539, acc.: 60.16%] [G loss: 0.956151]\n",
      "epoch:7 step:6988 [D loss: 0.633778, acc.: 64.06%] [G loss: 0.999698]\n",
      "epoch:7 step:6989 [D loss: 0.605096, acc.: 70.31%] [G loss: 1.054903]\n",
      "epoch:7 step:6990 [D loss: 0.714812, acc.: 56.25%] [G loss: 1.083723]\n",
      "epoch:7 step:6991 [D loss: 0.763596, acc.: 53.91%] [G loss: 0.869596]\n",
      "epoch:7 step:6992 [D loss: 0.651214, acc.: 62.50%] [G loss: 1.110344]\n",
      "epoch:7 step:6993 [D loss: 0.662138, acc.: 60.16%] [G loss: 0.912955]\n",
      "epoch:7 step:6994 [D loss: 0.722284, acc.: 56.25%] [G loss: 1.070905]\n",
      "epoch:7 step:6995 [D loss: 0.592142, acc.: 70.31%] [G loss: 1.056901]\n",
      "epoch:7 step:6996 [D loss: 0.602459, acc.: 64.84%] [G loss: 1.019262]\n",
      "epoch:7 step:6997 [D loss: 0.683437, acc.: 60.16%] [G loss: 0.880886]\n",
      "epoch:7 step:6998 [D loss: 0.651399, acc.: 59.38%] [G loss: 1.029610]\n",
      "epoch:7 step:6999 [D loss: 0.626969, acc.: 62.50%] [G loss: 1.030615]\n",
      "epoch:7 step:7000 [D loss: 0.590448, acc.: 75.00%] [G loss: 0.990952]\n",
      "epoch:7 step:7001 [D loss: 0.658066, acc.: 59.38%] [G loss: 1.076264]\n",
      "epoch:7 step:7002 [D loss: 0.627228, acc.: 70.31%] [G loss: 0.864700]\n",
      "epoch:7 step:7003 [D loss: 0.689181, acc.: 57.03%] [G loss: 1.042876]\n",
      "epoch:7 step:7004 [D loss: 0.684823, acc.: 53.91%] [G loss: 0.897570]\n",
      "epoch:7 step:7005 [D loss: 0.686510, acc.: 64.06%] [G loss: 0.945867]\n",
      "epoch:7 step:7006 [D loss: 0.624824, acc.: 65.62%] [G loss: 0.947162]\n",
      "epoch:7 step:7007 [D loss: 0.674971, acc.: 57.03%] [G loss: 1.096603]\n",
      "epoch:7 step:7008 [D loss: 0.655164, acc.: 60.16%] [G loss: 1.041473]\n",
      "epoch:7 step:7009 [D loss: 0.674039, acc.: 59.38%] [G loss: 0.973489]\n",
      "epoch:7 step:7010 [D loss: 0.705178, acc.: 50.00%] [G loss: 0.934118]\n",
      "epoch:7 step:7011 [D loss: 0.636663, acc.: 70.31%] [G loss: 0.910409]\n",
      "epoch:7 step:7012 [D loss: 0.571647, acc.: 71.88%] [G loss: 0.886446]\n",
      "epoch:7 step:7013 [D loss: 0.643243, acc.: 58.59%] [G loss: 1.036333]\n",
      "epoch:7 step:7014 [D loss: 0.661935, acc.: 64.06%] [G loss: 0.862007]\n",
      "epoch:7 step:7015 [D loss: 0.650795, acc.: 64.84%] [G loss: 1.056582]\n",
      "epoch:7 step:7016 [D loss: 0.563081, acc.: 71.88%] [G loss: 0.929473]\n",
      "epoch:7 step:7017 [D loss: 0.732934, acc.: 51.56%] [G loss: 1.044939]\n",
      "epoch:7 step:7018 [D loss: 0.742014, acc.: 50.00%] [G loss: 0.895436]\n",
      "epoch:7 step:7019 [D loss: 0.673635, acc.: 58.59%] [G loss: 0.970004]\n",
      "epoch:7 step:7020 [D loss: 0.663798, acc.: 60.16%] [G loss: 0.991798]\n",
      "epoch:7 step:7021 [D loss: 0.669361, acc.: 58.59%] [G loss: 0.993265]\n",
      "epoch:7 step:7022 [D loss: 0.688721, acc.: 57.81%] [G loss: 0.783544]\n",
      "epoch:7 step:7023 [D loss: 0.638358, acc.: 63.28%] [G loss: 1.084096]\n",
      "epoch:7 step:7024 [D loss: 0.681661, acc.: 57.81%] [G loss: 0.971145]\n",
      "epoch:7 step:7025 [D loss: 0.609327, acc.: 65.62%] [G loss: 0.976606]\n",
      "epoch:7 step:7026 [D loss: 0.610217, acc.: 68.75%] [G loss: 0.937217]\n",
      "epoch:7 step:7027 [D loss: 0.637429, acc.: 62.50%] [G loss: 0.990388]\n",
      "epoch:7 step:7028 [D loss: 0.650659, acc.: 61.72%] [G loss: 0.915964]\n",
      "epoch:7 step:7029 [D loss: 0.590424, acc.: 65.62%] [G loss: 0.998350]\n",
      "epoch:7 step:7030 [D loss: 0.565322, acc.: 70.31%] [G loss: 1.102156]\n",
      "epoch:7 step:7031 [D loss: 0.640856, acc.: 64.06%] [G loss: 1.045625]\n",
      "epoch:7 step:7032 [D loss: 0.852366, acc.: 40.62%] [G loss: 0.816356]\n",
      "epoch:7 step:7033 [D loss: 0.676682, acc.: 58.59%] [G loss: 0.951735]\n",
      "epoch:7 step:7034 [D loss: 0.702943, acc.: 52.34%] [G loss: 0.939603]\n",
      "epoch:7 step:7035 [D loss: 0.724369, acc.: 50.78%] [G loss: 0.861945]\n",
      "epoch:7 step:7036 [D loss: 0.698036, acc.: 54.69%] [G loss: 0.935513]\n",
      "epoch:7 step:7037 [D loss: 0.705943, acc.: 57.81%] [G loss: 0.911800]\n",
      "epoch:7 step:7038 [D loss: 0.683663, acc.: 64.84%] [G loss: 0.836952]\n",
      "epoch:7 step:7039 [D loss: 0.664969, acc.: 62.50%] [G loss: 1.048882]\n",
      "epoch:7 step:7040 [D loss: 0.623448, acc.: 62.50%] [G loss: 0.974525]\n",
      "epoch:7 step:7041 [D loss: 0.729839, acc.: 51.56%] [G loss: 0.908401]\n",
      "epoch:7 step:7042 [D loss: 0.753101, acc.: 45.31%] [G loss: 0.826830]\n",
      "epoch:7 step:7043 [D loss: 0.608348, acc.: 64.84%] [G loss: 0.906550]\n",
      "epoch:7 step:7044 [D loss: 0.695487, acc.: 52.34%] [G loss: 0.919941]\n",
      "epoch:7 step:7045 [D loss: 0.641160, acc.: 63.28%] [G loss: 0.975706]\n",
      "epoch:7 step:7046 [D loss: 0.620852, acc.: 64.84%] [G loss: 0.978139]\n",
      "epoch:7 step:7047 [D loss: 0.655082, acc.: 62.50%] [G loss: 0.970498]\n",
      "epoch:7 step:7048 [D loss: 0.663716, acc.: 53.91%] [G loss: 1.115755]\n",
      "epoch:7 step:7049 [D loss: 0.609260, acc.: 66.41%] [G loss: 0.968114]\n",
      "epoch:7 step:7050 [D loss: 0.648873, acc.: 64.06%] [G loss: 0.991417]\n",
      "epoch:7 step:7051 [D loss: 0.652694, acc.: 62.50%] [G loss: 0.909753]\n",
      "epoch:7 step:7052 [D loss: 0.650340, acc.: 64.06%] [G loss: 1.015398]\n",
      "epoch:7 step:7053 [D loss: 0.721135, acc.: 48.44%] [G loss: 0.962619]\n",
      "epoch:7 step:7054 [D loss: 0.556473, acc.: 74.22%] [G loss: 0.981700]\n",
      "epoch:7 step:7055 [D loss: 0.615017, acc.: 60.16%] [G loss: 1.068398]\n",
      "epoch:7 step:7056 [D loss: 0.674667, acc.: 61.72%] [G loss: 0.989530]\n",
      "epoch:7 step:7057 [D loss: 0.583188, acc.: 71.88%] [G loss: 1.058945]\n",
      "epoch:7 step:7058 [D loss: 0.619397, acc.: 66.41%] [G loss: 1.015298]\n",
      "epoch:7 step:7059 [D loss: 0.682351, acc.: 56.25%] [G loss: 0.976177]\n",
      "epoch:7 step:7060 [D loss: 0.643547, acc.: 65.62%] [G loss: 0.954775]\n",
      "epoch:7 step:7061 [D loss: 0.675317, acc.: 58.59%] [G loss: 1.049217]\n",
      "epoch:7 step:7062 [D loss: 0.684184, acc.: 55.47%] [G loss: 0.830924]\n",
      "epoch:7 step:7063 [D loss: 0.644015, acc.: 64.06%] [G loss: 1.015851]\n",
      "epoch:7 step:7064 [D loss: 0.648594, acc.: 62.50%] [G loss: 0.920604]\n",
      "epoch:7 step:7065 [D loss: 0.637925, acc.: 62.50%] [G loss: 1.020675]\n",
      "epoch:7 step:7066 [D loss: 0.682145, acc.: 53.91%] [G loss: 1.050511]\n",
      "epoch:7 step:7067 [D loss: 0.633828, acc.: 61.72%] [G loss: 0.963791]\n",
      "epoch:7 step:7068 [D loss: 0.718745, acc.: 57.03%] [G loss: 0.976794]\n",
      "epoch:7 step:7069 [D loss: 0.701972, acc.: 57.81%] [G loss: 0.943500]\n",
      "epoch:7 step:7070 [D loss: 0.702014, acc.: 50.00%] [G loss: 0.913506]\n",
      "epoch:7 step:7071 [D loss: 0.669735, acc.: 64.84%] [G loss: 0.930418]\n",
      "epoch:7 step:7072 [D loss: 0.606664, acc.: 67.97%] [G loss: 0.979091]\n",
      "epoch:7 step:7073 [D loss: 0.583162, acc.: 69.53%] [G loss: 0.934380]\n",
      "epoch:7 step:7074 [D loss: 0.659800, acc.: 61.72%] [G loss: 0.916628]\n",
      "epoch:7 step:7075 [D loss: 0.585921, acc.: 73.44%] [G loss: 0.910724]\n",
      "epoch:7 step:7076 [D loss: 0.678646, acc.: 58.59%] [G loss: 0.868619]\n",
      "epoch:7 step:7077 [D loss: 0.720034, acc.: 50.00%] [G loss: 0.905588]\n",
      "epoch:7 step:7078 [D loss: 0.684073, acc.: 59.38%] [G loss: 0.936365]\n",
      "epoch:7 step:7079 [D loss: 0.682525, acc.: 55.47%] [G loss: 0.951075]\n",
      "epoch:7 step:7080 [D loss: 0.615406, acc.: 61.72%] [G loss: 0.935033]\n",
      "epoch:7 step:7081 [D loss: 0.642121, acc.: 64.06%] [G loss: 1.010271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7082 [D loss: 0.615608, acc.: 62.50%] [G loss: 0.955968]\n",
      "epoch:7 step:7083 [D loss: 0.741362, acc.: 49.22%] [G loss: 0.923169]\n",
      "epoch:7 step:7084 [D loss: 0.676619, acc.: 62.50%] [G loss: 0.782666]\n",
      "epoch:7 step:7085 [D loss: 0.609499, acc.: 64.84%] [G loss: 0.905179]\n",
      "epoch:7 step:7086 [D loss: 0.715032, acc.: 50.78%] [G loss: 0.935615]\n",
      "epoch:7 step:7087 [D loss: 0.673595, acc.: 60.16%] [G loss: 0.874171]\n",
      "epoch:7 step:7088 [D loss: 0.704131, acc.: 52.34%] [G loss: 0.899910]\n",
      "epoch:7 step:7089 [D loss: 0.624642, acc.: 67.97%] [G loss: 0.852728]\n",
      "epoch:7 step:7090 [D loss: 0.637227, acc.: 64.84%] [G loss: 0.956967]\n",
      "epoch:7 step:7091 [D loss: 0.635849, acc.: 65.62%] [G loss: 1.085498]\n",
      "epoch:7 step:7092 [D loss: 0.611223, acc.: 64.84%] [G loss: 0.933296]\n",
      "epoch:7 step:7093 [D loss: 0.638655, acc.: 65.62%] [G loss: 0.973457]\n",
      "epoch:7 step:7094 [D loss: 0.580937, acc.: 70.31%] [G loss: 0.976525]\n",
      "epoch:7 step:7095 [D loss: 0.654876, acc.: 60.16%] [G loss: 0.904589]\n",
      "epoch:7 step:7096 [D loss: 0.665419, acc.: 63.28%] [G loss: 1.026799]\n",
      "epoch:7 step:7097 [D loss: 0.748820, acc.: 47.66%] [G loss: 0.978901]\n",
      "epoch:7 step:7098 [D loss: 0.649521, acc.: 57.81%] [G loss: 0.948288]\n",
      "epoch:7 step:7099 [D loss: 0.650401, acc.: 63.28%] [G loss: 0.866361]\n",
      "epoch:7 step:7100 [D loss: 0.613282, acc.: 66.41%] [G loss: 0.989159]\n",
      "epoch:7 step:7101 [D loss: 0.705341, acc.: 60.16%] [G loss: 0.883368]\n",
      "epoch:7 step:7102 [D loss: 0.703561, acc.: 55.47%] [G loss: 0.891554]\n",
      "epoch:7 step:7103 [D loss: 0.606804, acc.: 70.31%] [G loss: 0.919807]\n",
      "epoch:7 step:7104 [D loss: 0.650099, acc.: 61.72%] [G loss: 0.969368]\n",
      "epoch:7 step:7105 [D loss: 0.678876, acc.: 57.03%] [G loss: 0.960410]\n",
      "epoch:7 step:7106 [D loss: 0.635298, acc.: 62.50%] [G loss: 0.967088]\n",
      "epoch:7 step:7107 [D loss: 0.635529, acc.: 59.38%] [G loss: 0.903390]\n",
      "epoch:7 step:7108 [D loss: 0.581812, acc.: 67.19%] [G loss: 1.030638]\n",
      "epoch:7 step:7109 [D loss: 0.610871, acc.: 62.50%] [G loss: 1.092059]\n",
      "epoch:7 step:7110 [D loss: 0.623213, acc.: 67.97%] [G loss: 0.943142]\n",
      "epoch:7 step:7111 [D loss: 0.649492, acc.: 60.16%] [G loss: 1.006978]\n",
      "epoch:7 step:7112 [D loss: 0.645637, acc.: 67.19%] [G loss: 1.057414]\n",
      "epoch:7 step:7113 [D loss: 0.543926, acc.: 78.12%] [G loss: 0.936349]\n",
      "epoch:7 step:7114 [D loss: 0.602389, acc.: 67.19%] [G loss: 1.034871]\n",
      "epoch:7 step:7115 [D loss: 0.626072, acc.: 63.28%] [G loss: 1.098074]\n",
      "epoch:7 step:7116 [D loss: 0.598147, acc.: 73.44%] [G loss: 1.151990]\n",
      "epoch:7 step:7117 [D loss: 0.571612, acc.: 70.31%] [G loss: 1.034020]\n",
      "epoch:7 step:7118 [D loss: 0.782390, acc.: 46.09%] [G loss: 1.051676]\n",
      "epoch:7 step:7119 [D loss: 0.691647, acc.: 54.69%] [G loss: 0.922485]\n",
      "epoch:7 step:7120 [D loss: 0.737645, acc.: 50.00%] [G loss: 0.898309]\n",
      "epoch:7 step:7121 [D loss: 0.713967, acc.: 54.69%] [G loss: 0.913628]\n",
      "epoch:7 step:7122 [D loss: 0.711493, acc.: 52.34%] [G loss: 1.076233]\n",
      "epoch:7 step:7123 [D loss: 0.699441, acc.: 52.34%] [G loss: 1.010839]\n",
      "epoch:7 step:7124 [D loss: 0.644234, acc.: 59.38%] [G loss: 1.002172]\n",
      "epoch:7 step:7125 [D loss: 0.640412, acc.: 63.28%] [G loss: 1.088473]\n",
      "epoch:7 step:7126 [D loss: 0.662174, acc.: 60.94%] [G loss: 1.010375]\n",
      "epoch:7 step:7127 [D loss: 0.604822, acc.: 64.06%] [G loss: 0.975340]\n",
      "epoch:7 step:7128 [D loss: 0.703621, acc.: 54.69%] [G loss: 0.867153]\n",
      "epoch:7 step:7129 [D loss: 0.687838, acc.: 53.91%] [G loss: 0.959773]\n",
      "epoch:7 step:7130 [D loss: 0.670524, acc.: 60.16%] [G loss: 0.975984]\n",
      "epoch:7 step:7131 [D loss: 0.617345, acc.: 65.62%] [G loss: 0.884959]\n",
      "epoch:7 step:7132 [D loss: 0.688722, acc.: 54.69%] [G loss: 0.977339]\n",
      "epoch:7 step:7133 [D loss: 0.638519, acc.: 64.84%] [G loss: 0.984030]\n",
      "epoch:7 step:7134 [D loss: 0.662945, acc.: 59.38%] [G loss: 0.978659]\n",
      "epoch:7 step:7135 [D loss: 0.779685, acc.: 49.22%] [G loss: 0.823527]\n",
      "epoch:7 step:7136 [D loss: 0.745596, acc.: 51.56%] [G loss: 0.787200]\n",
      "epoch:7 step:7137 [D loss: 0.672482, acc.: 62.50%] [G loss: 0.940353]\n",
      "epoch:7 step:7138 [D loss: 0.696880, acc.: 53.91%] [G loss: 1.080737]\n",
      "epoch:7 step:7139 [D loss: 0.676696, acc.: 53.91%] [G loss: 0.933302]\n",
      "epoch:7 step:7140 [D loss: 0.698465, acc.: 55.47%] [G loss: 1.077463]\n",
      "epoch:7 step:7141 [D loss: 0.725631, acc.: 51.56%] [G loss: 1.017054]\n",
      "epoch:7 step:7142 [D loss: 0.725098, acc.: 53.91%] [G loss: 1.019524]\n",
      "epoch:7 step:7143 [D loss: 0.630670, acc.: 67.19%] [G loss: 0.820180]\n",
      "epoch:7 step:7144 [D loss: 0.655677, acc.: 60.16%] [G loss: 0.846810]\n",
      "epoch:7 step:7145 [D loss: 0.639924, acc.: 61.72%] [G loss: 0.950405]\n",
      "epoch:7 step:7146 [D loss: 0.649799, acc.: 63.28%] [G loss: 0.872176]\n",
      "epoch:7 step:7147 [D loss: 0.606629, acc.: 68.75%] [G loss: 1.034853]\n",
      "epoch:7 step:7148 [D loss: 0.619531, acc.: 63.28%] [G loss: 1.092770]\n",
      "epoch:7 step:7149 [D loss: 0.624232, acc.: 64.84%] [G loss: 1.009140]\n",
      "epoch:7 step:7150 [D loss: 0.661339, acc.: 55.47%] [G loss: 0.940439]\n",
      "epoch:7 step:7151 [D loss: 0.642163, acc.: 62.50%] [G loss: 0.987431]\n",
      "epoch:7 step:7152 [D loss: 0.706356, acc.: 58.59%] [G loss: 0.795022]\n",
      "epoch:7 step:7153 [D loss: 0.648110, acc.: 64.06%] [G loss: 0.989270]\n",
      "epoch:7 step:7154 [D loss: 0.778308, acc.: 50.78%] [G loss: 0.895348]\n",
      "epoch:7 step:7155 [D loss: 0.716412, acc.: 50.00%] [G loss: 0.914967]\n",
      "epoch:7 step:7156 [D loss: 0.708590, acc.: 57.03%] [G loss: 0.891368]\n",
      "epoch:7 step:7157 [D loss: 0.671055, acc.: 59.38%] [G loss: 1.038074]\n",
      "epoch:7 step:7158 [D loss: 0.660718, acc.: 59.38%] [G loss: 0.995372]\n",
      "epoch:7 step:7159 [D loss: 0.718586, acc.: 52.34%] [G loss: 0.961307]\n",
      "epoch:7 step:7160 [D loss: 0.698582, acc.: 56.25%] [G loss: 0.949988]\n",
      "epoch:7 step:7161 [D loss: 0.619157, acc.: 64.06%] [G loss: 1.043507]\n",
      "epoch:7 step:7162 [D loss: 0.628918, acc.: 69.53%] [G loss: 1.010118]\n",
      "epoch:7 step:7163 [D loss: 0.718099, acc.: 61.72%] [G loss: 0.865339]\n",
      "epoch:7 step:7164 [D loss: 0.673549, acc.: 56.25%] [G loss: 1.065340]\n",
      "epoch:7 step:7165 [D loss: 0.623058, acc.: 68.75%] [G loss: 1.006477]\n",
      "epoch:7 step:7166 [D loss: 0.588498, acc.: 74.22%] [G loss: 1.040223]\n",
      "epoch:7 step:7167 [D loss: 0.594692, acc.: 67.19%] [G loss: 0.899478]\n",
      "epoch:7 step:7168 [D loss: 0.594080, acc.: 69.53%] [G loss: 0.941464]\n",
      "epoch:7 step:7169 [D loss: 0.692926, acc.: 59.38%] [G loss: 0.891269]\n",
      "epoch:7 step:7170 [D loss: 0.637568, acc.: 61.72%] [G loss: 0.878322]\n",
      "epoch:7 step:7171 [D loss: 0.687860, acc.: 59.38%] [G loss: 0.982207]\n",
      "epoch:7 step:7172 [D loss: 0.647881, acc.: 63.28%] [G loss: 0.950254]\n",
      "epoch:7 step:7173 [D loss: 0.761274, acc.: 46.09%] [G loss: 0.854606]\n",
      "epoch:7 step:7174 [D loss: 0.713291, acc.: 54.69%] [G loss: 1.011122]\n",
      "epoch:7 step:7175 [D loss: 0.702940, acc.: 53.12%] [G loss: 0.938571]\n",
      "epoch:7 step:7176 [D loss: 0.647553, acc.: 63.28%] [G loss: 1.008968]\n",
      "epoch:7 step:7177 [D loss: 0.668748, acc.: 61.72%] [G loss: 0.905445]\n",
      "epoch:7 step:7178 [D loss: 0.650959, acc.: 64.06%] [G loss: 0.994988]\n",
      "epoch:7 step:7179 [D loss: 0.650516, acc.: 62.50%] [G loss: 0.924590]\n",
      "epoch:7 step:7180 [D loss: 0.686859, acc.: 60.94%] [G loss: 0.789343]\n",
      "epoch:7 step:7181 [D loss: 0.660518, acc.: 67.97%] [G loss: 0.982218]\n",
      "epoch:7 step:7182 [D loss: 0.629406, acc.: 68.75%] [G loss: 0.860943]\n",
      "epoch:7 step:7183 [D loss: 0.667509, acc.: 57.03%] [G loss: 0.895722]\n",
      "epoch:7 step:7184 [D loss: 0.742925, acc.: 50.78%] [G loss: 0.921260]\n",
      "epoch:7 step:7185 [D loss: 0.636574, acc.: 58.59%] [G loss: 0.976284]\n",
      "epoch:7 step:7186 [D loss: 0.701943, acc.: 57.03%] [G loss: 1.020053]\n",
      "epoch:7 step:7187 [D loss: 0.687616, acc.: 55.47%] [G loss: 0.855673]\n",
      "epoch:7 step:7188 [D loss: 0.617099, acc.: 65.62%] [G loss: 0.840650]\n",
      "epoch:7 step:7189 [D loss: 0.674114, acc.: 58.59%] [G loss: 0.877514]\n",
      "epoch:7 step:7190 [D loss: 0.576566, acc.: 69.53%] [G loss: 1.138552]\n",
      "epoch:7 step:7191 [D loss: 0.525023, acc.: 79.69%] [G loss: 1.047799]\n",
      "epoch:7 step:7192 [D loss: 0.599810, acc.: 73.44%] [G loss: 1.009249]\n",
      "epoch:7 step:7193 [D loss: 0.663030, acc.: 60.16%] [G loss: 0.859822]\n",
      "epoch:7 step:7194 [D loss: 0.513270, acc.: 79.69%] [G loss: 1.063633]\n",
      "epoch:7 step:7195 [D loss: 0.699477, acc.: 57.03%] [G loss: 0.878556]\n",
      "epoch:7 step:7196 [D loss: 0.615902, acc.: 69.53%] [G loss: 1.047705]\n",
      "epoch:7 step:7197 [D loss: 0.623973, acc.: 63.28%] [G loss: 0.904724]\n",
      "epoch:7 step:7198 [D loss: 0.616242, acc.: 67.19%] [G loss: 1.098436]\n",
      "epoch:7 step:7199 [D loss: 0.696134, acc.: 52.34%] [G loss: 0.857829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7200 [D loss: 0.665836, acc.: 55.47%] [G loss: 0.858817]\n",
      "epoch:7 step:7201 [D loss: 0.597010, acc.: 66.41%] [G loss: 0.940153]\n",
      "epoch:7 step:7202 [D loss: 0.604180, acc.: 67.19%] [G loss: 1.142964]\n",
      "epoch:7 step:7203 [D loss: 0.686339, acc.: 57.81%] [G loss: 0.916278]\n",
      "epoch:7 step:7204 [D loss: 0.612615, acc.: 67.19%] [G loss: 0.972587]\n",
      "epoch:7 step:7205 [D loss: 0.582830, acc.: 67.19%] [G loss: 0.860523]\n",
      "epoch:7 step:7206 [D loss: 0.621803, acc.: 64.06%] [G loss: 0.937606]\n",
      "epoch:7 step:7207 [D loss: 0.606009, acc.: 64.84%] [G loss: 1.001691]\n",
      "epoch:7 step:7208 [D loss: 0.615737, acc.: 64.84%] [G loss: 0.923886]\n",
      "epoch:7 step:7209 [D loss: 0.553847, acc.: 74.22%] [G loss: 1.180920]\n",
      "epoch:7 step:7210 [D loss: 0.630139, acc.: 64.06%] [G loss: 1.060202]\n",
      "epoch:7 step:7211 [D loss: 0.748474, acc.: 53.12%] [G loss: 0.901453]\n",
      "epoch:7 step:7212 [D loss: 0.645870, acc.: 60.94%] [G loss: 0.993111]\n",
      "epoch:7 step:7213 [D loss: 0.642049, acc.: 63.28%] [G loss: 0.910553]\n",
      "epoch:7 step:7214 [D loss: 0.652818, acc.: 58.59%] [G loss: 0.939260]\n",
      "epoch:7 step:7215 [D loss: 0.698046, acc.: 56.25%] [G loss: 1.123466]\n",
      "epoch:7 step:7216 [D loss: 0.704243, acc.: 55.47%] [G loss: 0.909606]\n",
      "epoch:7 step:7217 [D loss: 0.814017, acc.: 42.97%] [G loss: 0.938335]\n",
      "epoch:7 step:7218 [D loss: 0.654225, acc.: 63.28%] [G loss: 0.929710]\n",
      "epoch:7 step:7219 [D loss: 0.630433, acc.: 67.97%] [G loss: 0.850219]\n",
      "epoch:7 step:7220 [D loss: 0.579103, acc.: 74.22%] [G loss: 0.960784]\n",
      "epoch:7 step:7221 [D loss: 0.625477, acc.: 65.62%] [G loss: 0.992107]\n",
      "epoch:7 step:7222 [D loss: 0.621678, acc.: 64.06%] [G loss: 1.109167]\n",
      "epoch:7 step:7223 [D loss: 0.734412, acc.: 51.56%] [G loss: 1.018482]\n",
      "epoch:7 step:7224 [D loss: 0.640482, acc.: 66.41%] [G loss: 1.038337]\n",
      "epoch:7 step:7225 [D loss: 0.728273, acc.: 48.44%] [G loss: 0.961337]\n",
      "epoch:7 step:7226 [D loss: 0.699113, acc.: 53.91%] [G loss: 0.873146]\n",
      "epoch:7 step:7227 [D loss: 0.592223, acc.: 67.97%] [G loss: 0.977125]\n",
      "epoch:7 step:7228 [D loss: 0.616927, acc.: 68.75%] [G loss: 0.913998]\n",
      "epoch:7 step:7229 [D loss: 0.655942, acc.: 62.50%] [G loss: 1.090547]\n",
      "epoch:7 step:7230 [D loss: 0.707601, acc.: 59.38%] [G loss: 0.863500]\n",
      "epoch:7 step:7231 [D loss: 0.687505, acc.: 57.81%] [G loss: 1.099698]\n",
      "epoch:7 step:7232 [D loss: 0.698362, acc.: 50.78%] [G loss: 0.950147]\n",
      "epoch:7 step:7233 [D loss: 0.611473, acc.: 63.28%] [G loss: 0.883666]\n",
      "epoch:7 step:7234 [D loss: 0.645442, acc.: 60.94%] [G loss: 0.859689]\n",
      "epoch:7 step:7235 [D loss: 0.599998, acc.: 68.75%] [G loss: 1.094758]\n",
      "epoch:7 step:7236 [D loss: 0.614307, acc.: 70.31%] [G loss: 0.955968]\n",
      "epoch:7 step:7237 [D loss: 0.620181, acc.: 64.06%] [G loss: 1.078733]\n",
      "epoch:7 step:7238 [D loss: 0.586976, acc.: 66.41%] [G loss: 0.991490]\n",
      "epoch:7 step:7239 [D loss: 0.640046, acc.: 60.16%] [G loss: 0.964922]\n",
      "epoch:7 step:7240 [D loss: 0.565031, acc.: 70.31%] [G loss: 1.018853]\n",
      "epoch:7 step:7241 [D loss: 0.568768, acc.: 68.75%] [G loss: 1.091808]\n",
      "epoch:7 step:7242 [D loss: 0.664803, acc.: 59.38%] [G loss: 1.056661]\n",
      "epoch:7 step:7243 [D loss: 0.616434, acc.: 60.94%] [G loss: 1.101207]\n",
      "epoch:7 step:7244 [D loss: 0.659037, acc.: 62.50%] [G loss: 0.987917]\n",
      "epoch:7 step:7245 [D loss: 0.710900, acc.: 53.12%] [G loss: 0.923266]\n",
      "epoch:7 step:7246 [D loss: 0.699611, acc.: 57.81%] [G loss: 0.930388]\n",
      "epoch:7 step:7247 [D loss: 0.683334, acc.: 50.78%] [G loss: 0.860813]\n",
      "epoch:7 step:7248 [D loss: 0.590095, acc.: 75.00%] [G loss: 0.961337]\n",
      "epoch:7 step:7249 [D loss: 0.638146, acc.: 62.50%] [G loss: 0.941393]\n",
      "epoch:7 step:7250 [D loss: 0.587725, acc.: 71.09%] [G loss: 0.938978]\n",
      "epoch:7 step:7251 [D loss: 0.747357, acc.: 50.00%] [G loss: 0.788840]\n",
      "epoch:7 step:7252 [D loss: 0.685173, acc.: 56.25%] [G loss: 0.895494]\n",
      "epoch:7 step:7253 [D loss: 0.646548, acc.: 65.62%] [G loss: 0.969955]\n",
      "epoch:7 step:7254 [D loss: 0.591628, acc.: 67.97%] [G loss: 1.096219]\n",
      "epoch:7 step:7255 [D loss: 0.643067, acc.: 60.94%] [G loss: 1.025101]\n",
      "epoch:7 step:7256 [D loss: 0.626545, acc.: 65.62%] [G loss: 0.978440]\n",
      "epoch:7 step:7257 [D loss: 0.682419, acc.: 60.94%] [G loss: 0.954061]\n",
      "epoch:7 step:7258 [D loss: 0.657171, acc.: 60.16%] [G loss: 0.864809]\n",
      "epoch:7 step:7259 [D loss: 0.605202, acc.: 71.88%] [G loss: 1.001506]\n",
      "epoch:7 step:7260 [D loss: 0.613386, acc.: 66.41%] [G loss: 0.963000]\n",
      "epoch:7 step:7261 [D loss: 0.622742, acc.: 64.06%] [G loss: 1.188296]\n",
      "epoch:7 step:7262 [D loss: 0.697779, acc.: 59.38%] [G loss: 0.870009]\n",
      "epoch:7 step:7263 [D loss: 0.632844, acc.: 64.84%] [G loss: 1.097008]\n",
      "epoch:7 step:7264 [D loss: 0.655088, acc.: 59.38%] [G loss: 1.001017]\n",
      "epoch:7 step:7265 [D loss: 0.596909, acc.: 64.84%] [G loss: 1.115921]\n",
      "epoch:7 step:7266 [D loss: 0.578113, acc.: 65.62%] [G loss: 1.073532]\n",
      "epoch:7 step:7267 [D loss: 0.560892, acc.: 74.22%] [G loss: 1.079171]\n",
      "epoch:7 step:7268 [D loss: 0.574032, acc.: 67.19%] [G loss: 1.009306]\n",
      "epoch:7 step:7269 [D loss: 0.707722, acc.: 54.69%] [G loss: 0.984497]\n",
      "epoch:7 step:7270 [D loss: 0.696339, acc.: 56.25%] [G loss: 0.952984]\n",
      "epoch:7 step:7271 [D loss: 0.658550, acc.: 61.72%] [G loss: 0.923527]\n",
      "epoch:7 step:7272 [D loss: 0.522620, acc.: 83.59%] [G loss: 1.077789]\n",
      "epoch:7 step:7273 [D loss: 0.647822, acc.: 69.53%] [G loss: 0.962182]\n",
      "epoch:7 step:7274 [D loss: 0.667671, acc.: 57.81%] [G loss: 1.007867]\n",
      "epoch:7 step:7275 [D loss: 0.650449, acc.: 60.16%] [G loss: 1.027256]\n",
      "epoch:7 step:7276 [D loss: 0.733409, acc.: 53.12%] [G loss: 0.820678]\n",
      "epoch:7 step:7277 [D loss: 0.731856, acc.: 50.78%] [G loss: 0.814795]\n",
      "epoch:7 step:7278 [D loss: 0.633755, acc.: 67.19%] [G loss: 0.908426]\n",
      "epoch:7 step:7279 [D loss: 0.668741, acc.: 56.25%] [G loss: 0.917340]\n",
      "epoch:7 step:7280 [D loss: 0.722241, acc.: 53.91%] [G loss: 0.844537]\n",
      "epoch:7 step:7281 [D loss: 0.716522, acc.: 53.91%] [G loss: 0.829792]\n",
      "epoch:7 step:7282 [D loss: 0.693470, acc.: 54.69%] [G loss: 0.822623]\n",
      "epoch:7 step:7283 [D loss: 0.721153, acc.: 50.00%] [G loss: 0.883076]\n",
      "epoch:7 step:7284 [D loss: 0.652065, acc.: 61.72%] [G loss: 1.068785]\n",
      "epoch:7 step:7285 [D loss: 0.697748, acc.: 56.25%] [G loss: 0.912863]\n",
      "epoch:7 step:7286 [D loss: 0.668668, acc.: 58.59%] [G loss: 0.859836]\n",
      "epoch:7 step:7287 [D loss: 0.621425, acc.: 64.06%] [G loss: 1.063617]\n",
      "epoch:7 step:7288 [D loss: 0.606559, acc.: 67.19%] [G loss: 1.029744]\n",
      "epoch:7 step:7289 [D loss: 0.640388, acc.: 63.28%] [G loss: 0.862177]\n",
      "epoch:7 step:7290 [D loss: 0.624341, acc.: 63.28%] [G loss: 1.045120]\n",
      "epoch:7 step:7291 [D loss: 0.608256, acc.: 62.50%] [G loss: 1.018535]\n",
      "epoch:7 step:7292 [D loss: 0.620636, acc.: 64.06%] [G loss: 0.922736]\n",
      "epoch:7 step:7293 [D loss: 0.710474, acc.: 59.38%] [G loss: 0.873689]\n",
      "epoch:7 step:7294 [D loss: 0.612947, acc.: 66.41%] [G loss: 0.875573]\n",
      "epoch:7 step:7295 [D loss: 0.668938, acc.: 53.12%] [G loss: 0.988820]\n",
      "epoch:7 step:7296 [D loss: 0.679220, acc.: 62.50%] [G loss: 0.879448]\n",
      "epoch:7 step:7297 [D loss: 0.612649, acc.: 69.53%] [G loss: 1.092832]\n",
      "epoch:7 step:7298 [D loss: 0.666131, acc.: 62.50%] [G loss: 0.909817]\n",
      "epoch:7 step:7299 [D loss: 0.655427, acc.: 60.16%] [G loss: 0.994482]\n",
      "epoch:7 step:7300 [D loss: 0.727046, acc.: 51.56%] [G loss: 0.977660]\n",
      "epoch:7 step:7301 [D loss: 0.694096, acc.: 57.81%] [G loss: 0.939828]\n",
      "epoch:7 step:7302 [D loss: 0.736619, acc.: 52.34%] [G loss: 0.944290]\n",
      "epoch:7 step:7303 [D loss: 0.737770, acc.: 51.56%] [G loss: 0.813351]\n",
      "epoch:7 step:7304 [D loss: 0.548709, acc.: 75.00%] [G loss: 0.992422]\n",
      "epoch:7 step:7305 [D loss: 0.610624, acc.: 71.09%] [G loss: 0.966365]\n",
      "epoch:7 step:7306 [D loss: 0.641594, acc.: 64.06%] [G loss: 0.998126]\n",
      "epoch:7 step:7307 [D loss: 0.696290, acc.: 56.25%] [G loss: 0.924541]\n",
      "epoch:7 step:7308 [D loss: 0.673899, acc.: 62.50%] [G loss: 0.926323]\n",
      "epoch:7 step:7309 [D loss: 0.626797, acc.: 64.84%] [G loss: 1.051303]\n",
      "epoch:7 step:7310 [D loss: 0.662666, acc.: 61.72%] [G loss: 0.879051]\n",
      "epoch:7 step:7311 [D loss: 0.683025, acc.: 60.16%] [G loss: 0.943898]\n",
      "epoch:7 step:7312 [D loss: 0.672675, acc.: 60.94%] [G loss: 0.822226]\n",
      "epoch:7 step:7313 [D loss: 0.648808, acc.: 61.72%] [G loss: 0.866205]\n",
      "epoch:7 step:7314 [D loss: 0.625188, acc.: 66.41%] [G loss: 0.946938]\n",
      "epoch:7 step:7315 [D loss: 0.628452, acc.: 64.84%] [G loss: 1.185166]\n",
      "epoch:7 step:7316 [D loss: 0.646895, acc.: 60.94%] [G loss: 1.047012]\n",
      "epoch:7 step:7317 [D loss: 0.674166, acc.: 56.25%] [G loss: 0.942393]\n",
      "epoch:7 step:7318 [D loss: 0.757737, acc.: 42.97%] [G loss: 0.886073]\n",
      "epoch:7 step:7319 [D loss: 0.713435, acc.: 54.69%] [G loss: 0.889314]\n",
      "epoch:7 step:7320 [D loss: 0.644509, acc.: 65.62%] [G loss: 0.995681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7321 [D loss: 0.690874, acc.: 56.25%] [G loss: 1.012177]\n",
      "epoch:7 step:7322 [D loss: 0.645862, acc.: 64.06%] [G loss: 0.972681]\n",
      "epoch:7 step:7323 [D loss: 0.651904, acc.: 60.94%] [G loss: 1.018391]\n",
      "epoch:7 step:7324 [D loss: 0.602914, acc.: 65.62%] [G loss: 1.012636]\n",
      "epoch:7 step:7325 [D loss: 0.698261, acc.: 57.81%] [G loss: 1.051505]\n",
      "epoch:7 step:7326 [D loss: 0.595414, acc.: 73.44%] [G loss: 0.933571]\n",
      "epoch:7 step:7327 [D loss: 0.806963, acc.: 41.41%] [G loss: 0.837929]\n",
      "epoch:7 step:7328 [D loss: 0.739536, acc.: 50.00%] [G loss: 0.767083]\n",
      "epoch:7 step:7329 [D loss: 0.710574, acc.: 57.81%] [G loss: 0.939929]\n",
      "epoch:7 step:7330 [D loss: 0.689471, acc.: 57.81%] [G loss: 0.983809]\n",
      "epoch:7 step:7331 [D loss: 0.641945, acc.: 63.28%] [G loss: 0.935772]\n",
      "epoch:7 step:7332 [D loss: 0.594599, acc.: 67.97%] [G loss: 0.981908]\n",
      "epoch:7 step:7333 [D loss: 0.593896, acc.: 69.53%] [G loss: 0.992487]\n",
      "epoch:7 step:7334 [D loss: 0.662115, acc.: 59.38%] [G loss: 0.917611]\n",
      "epoch:7 step:7335 [D loss: 0.582578, acc.: 70.31%] [G loss: 0.866281]\n",
      "epoch:7 step:7336 [D loss: 0.645600, acc.: 60.94%] [G loss: 0.978881]\n",
      "epoch:7 step:7337 [D loss: 0.680175, acc.: 57.03%] [G loss: 1.107312]\n",
      "epoch:7 step:7338 [D loss: 0.660155, acc.: 59.38%] [G loss: 1.081219]\n",
      "epoch:7 step:7339 [D loss: 0.742207, acc.: 48.44%] [G loss: 0.840184]\n",
      "epoch:7 step:7340 [D loss: 0.621511, acc.: 63.28%] [G loss: 0.877239]\n",
      "epoch:7 step:7341 [D loss: 0.639902, acc.: 67.19%] [G loss: 1.014726]\n",
      "epoch:7 step:7342 [D loss: 0.689522, acc.: 60.16%] [G loss: 1.081044]\n",
      "epoch:7 step:7343 [D loss: 0.610155, acc.: 69.53%] [G loss: 1.023087]\n",
      "epoch:7 step:7344 [D loss: 0.634265, acc.: 69.53%] [G loss: 0.880796]\n",
      "epoch:7 step:7345 [D loss: 0.551337, acc.: 74.22%] [G loss: 1.010126]\n",
      "epoch:7 step:7346 [D loss: 0.741168, acc.: 50.00%] [G loss: 1.003895]\n",
      "epoch:7 step:7347 [D loss: 0.792755, acc.: 46.09%] [G loss: 0.945249]\n",
      "epoch:7 step:7348 [D loss: 0.657907, acc.: 59.38%] [G loss: 0.904266]\n",
      "epoch:7 step:7349 [D loss: 0.626690, acc.: 62.50%] [G loss: 0.950959]\n",
      "epoch:7 step:7350 [D loss: 0.565407, acc.: 71.09%] [G loss: 1.059142]\n",
      "epoch:7 step:7351 [D loss: 0.540968, acc.: 81.25%] [G loss: 0.936065]\n",
      "epoch:7 step:7352 [D loss: 0.580731, acc.: 68.75%] [G loss: 1.138221]\n",
      "epoch:7 step:7353 [D loss: 0.665730, acc.: 57.03%] [G loss: 0.958567]\n",
      "epoch:7 step:7354 [D loss: 0.677444, acc.: 56.25%] [G loss: 0.989903]\n",
      "epoch:7 step:7355 [D loss: 0.629455, acc.: 60.16%] [G loss: 0.980857]\n",
      "epoch:7 step:7356 [D loss: 0.632607, acc.: 64.06%] [G loss: 0.969329]\n",
      "epoch:7 step:7357 [D loss: 0.628884, acc.: 60.16%] [G loss: 1.042853]\n",
      "epoch:7 step:7358 [D loss: 0.703917, acc.: 52.34%] [G loss: 0.955636]\n",
      "epoch:7 step:7359 [D loss: 0.736666, acc.: 47.66%] [G loss: 0.894807]\n",
      "epoch:7 step:7360 [D loss: 0.680440, acc.: 60.16%] [G loss: 1.097345]\n",
      "epoch:7 step:7361 [D loss: 0.687096, acc.: 57.03%] [G loss: 1.013957]\n",
      "epoch:7 step:7362 [D loss: 0.644281, acc.: 64.84%] [G loss: 0.989064]\n",
      "epoch:7 step:7363 [D loss: 0.658989, acc.: 62.50%] [G loss: 0.922033]\n",
      "epoch:7 step:7364 [D loss: 0.652309, acc.: 64.84%] [G loss: 1.075382]\n",
      "epoch:7 step:7365 [D loss: 0.590972, acc.: 69.53%] [G loss: 1.041579]\n",
      "epoch:7 step:7366 [D loss: 0.654119, acc.: 61.72%] [G loss: 1.145279]\n",
      "epoch:7 step:7367 [D loss: 0.672301, acc.: 54.69%] [G loss: 0.908150]\n",
      "epoch:7 step:7368 [D loss: 0.581699, acc.: 74.22%] [G loss: 1.014947]\n",
      "epoch:7 step:7369 [D loss: 0.647302, acc.: 60.94%] [G loss: 0.927663]\n",
      "epoch:7 step:7370 [D loss: 0.671981, acc.: 58.59%] [G loss: 0.871657]\n",
      "epoch:7 step:7371 [D loss: 0.672120, acc.: 57.81%] [G loss: 0.970001]\n",
      "epoch:7 step:7372 [D loss: 0.688653, acc.: 60.16%] [G loss: 0.922719]\n",
      "epoch:7 step:7373 [D loss: 0.647750, acc.: 62.50%] [G loss: 0.898537]\n",
      "epoch:7 step:7374 [D loss: 0.625825, acc.: 64.06%] [G loss: 1.015830]\n",
      "epoch:7 step:7375 [D loss: 0.727756, acc.: 52.34%] [G loss: 0.970940]\n",
      "epoch:7 step:7376 [D loss: 0.667167, acc.: 57.03%] [G loss: 0.986331]\n",
      "epoch:7 step:7377 [D loss: 0.651669, acc.: 57.81%] [G loss: 1.070034]\n",
      "epoch:7 step:7378 [D loss: 0.606085, acc.: 67.19%] [G loss: 0.981111]\n",
      "epoch:7 step:7379 [D loss: 0.711275, acc.: 51.56%] [G loss: 0.961426]\n",
      "epoch:7 step:7380 [D loss: 0.695662, acc.: 50.78%] [G loss: 0.940221]\n",
      "epoch:7 step:7381 [D loss: 0.671026, acc.: 57.03%] [G loss: 0.812767]\n",
      "epoch:7 step:7382 [D loss: 0.624840, acc.: 64.84%] [G loss: 0.953043]\n",
      "epoch:7 step:7383 [D loss: 0.683218, acc.: 56.25%] [G loss: 1.051049]\n",
      "epoch:7 step:7384 [D loss: 0.666382, acc.: 64.06%] [G loss: 0.872086]\n",
      "epoch:7 step:7385 [D loss: 0.644237, acc.: 58.59%] [G loss: 0.941876]\n",
      "epoch:7 step:7386 [D loss: 0.710634, acc.: 56.25%] [G loss: 0.936336]\n",
      "epoch:7 step:7387 [D loss: 0.635742, acc.: 63.28%] [G loss: 1.056434]\n",
      "epoch:7 step:7388 [D loss: 0.684646, acc.: 57.81%] [G loss: 0.967377]\n",
      "epoch:7 step:7389 [D loss: 0.617606, acc.: 60.94%] [G loss: 0.901603]\n",
      "epoch:7 step:7390 [D loss: 0.632575, acc.: 60.94%] [G loss: 0.877681]\n",
      "epoch:7 step:7391 [D loss: 0.714336, acc.: 61.72%] [G loss: 0.836812]\n",
      "epoch:7 step:7392 [D loss: 0.629954, acc.: 57.03%] [G loss: 1.018685]\n",
      "epoch:7 step:7393 [D loss: 0.661046, acc.: 58.59%] [G loss: 1.029183]\n",
      "epoch:7 step:7394 [D loss: 0.604313, acc.: 69.53%] [G loss: 1.058422]\n",
      "epoch:7 step:7395 [D loss: 0.671794, acc.: 64.84%] [G loss: 1.021254]\n",
      "epoch:7 step:7396 [D loss: 0.689290, acc.: 54.69%] [G loss: 0.945402]\n",
      "epoch:7 step:7397 [D loss: 0.665925, acc.: 55.47%] [G loss: 0.986956]\n",
      "epoch:7 step:7398 [D loss: 0.643364, acc.: 65.62%] [G loss: 0.849797]\n",
      "epoch:7 step:7399 [D loss: 0.647586, acc.: 62.50%] [G loss: 0.907594]\n",
      "epoch:7 step:7400 [D loss: 0.574428, acc.: 71.88%] [G loss: 1.030420]\n",
      "epoch:7 step:7401 [D loss: 0.671574, acc.: 59.38%] [G loss: 0.942020]\n",
      "epoch:7 step:7402 [D loss: 0.664491, acc.: 62.50%] [G loss: 0.842200]\n",
      "epoch:7 step:7403 [D loss: 0.731479, acc.: 57.03%] [G loss: 0.952577]\n",
      "epoch:7 step:7404 [D loss: 0.644844, acc.: 64.84%] [G loss: 1.058465]\n",
      "epoch:7 step:7405 [D loss: 0.738806, acc.: 49.22%] [G loss: 0.863824]\n",
      "epoch:7 step:7406 [D loss: 0.679842, acc.: 59.38%] [G loss: 1.045210]\n",
      "epoch:7 step:7407 [D loss: 0.686234, acc.: 57.81%] [G loss: 0.952498]\n",
      "epoch:7 step:7408 [D loss: 0.603863, acc.: 69.53%] [G loss: 0.885546]\n",
      "epoch:7 step:7409 [D loss: 0.753245, acc.: 48.44%] [G loss: 0.895020]\n",
      "epoch:7 step:7410 [D loss: 0.613093, acc.: 68.75%] [G loss: 1.102439]\n",
      "epoch:7 step:7411 [D loss: 0.569190, acc.: 76.56%] [G loss: 1.087304]\n",
      "epoch:7 step:7412 [D loss: 0.582350, acc.: 64.84%] [G loss: 1.037477]\n",
      "epoch:7 step:7413 [D loss: 0.553495, acc.: 70.31%] [G loss: 0.990426]\n",
      "epoch:7 step:7414 [D loss: 0.644352, acc.: 63.28%] [G loss: 0.943756]\n",
      "epoch:7 step:7415 [D loss: 0.656190, acc.: 61.72%] [G loss: 0.980936]\n",
      "epoch:7 step:7416 [D loss: 0.584147, acc.: 72.66%] [G loss: 1.071618]\n",
      "epoch:7 step:7417 [D loss: 0.753540, acc.: 53.12%] [G loss: 0.972088]\n",
      "epoch:7 step:7418 [D loss: 0.783483, acc.: 42.19%] [G loss: 0.817954]\n",
      "epoch:7 step:7419 [D loss: 0.629969, acc.: 66.41%] [G loss: 0.841039]\n",
      "epoch:7 step:7420 [D loss: 0.668241, acc.: 58.59%] [G loss: 0.920899]\n",
      "epoch:7 step:7421 [D loss: 0.656114, acc.: 61.72%] [G loss: 0.884579]\n",
      "epoch:7 step:7422 [D loss: 0.689934, acc.: 58.59%] [G loss: 0.741428]\n",
      "epoch:7 step:7423 [D loss: 0.627029, acc.: 60.94%] [G loss: 0.937666]\n",
      "epoch:7 step:7424 [D loss: 0.698240, acc.: 56.25%] [G loss: 1.013283]\n",
      "epoch:7 step:7425 [D loss: 0.643372, acc.: 62.50%] [G loss: 0.955336]\n",
      "epoch:7 step:7426 [D loss: 0.666188, acc.: 60.16%] [G loss: 0.990563]\n",
      "epoch:7 step:7427 [D loss: 0.715337, acc.: 52.34%] [G loss: 0.928481]\n",
      "epoch:7 step:7428 [D loss: 0.719871, acc.: 53.91%] [G loss: 0.952349]\n",
      "epoch:7 step:7429 [D loss: 0.700177, acc.: 53.91%] [G loss: 0.932867]\n",
      "epoch:7 step:7430 [D loss: 0.632669, acc.: 60.94%] [G loss: 0.917722]\n",
      "epoch:7 step:7431 [D loss: 0.609943, acc.: 67.97%] [G loss: 0.961260]\n",
      "epoch:7 step:7432 [D loss: 0.683030, acc.: 60.16%] [G loss: 1.008939]\n",
      "epoch:7 step:7433 [D loss: 0.671722, acc.: 60.94%] [G loss: 0.930265]\n",
      "epoch:7 step:7434 [D loss: 0.648975, acc.: 64.06%] [G loss: 0.923797]\n",
      "epoch:7 step:7435 [D loss: 0.678650, acc.: 57.81%] [G loss: 0.862899]\n",
      "epoch:7 step:7436 [D loss: 0.598428, acc.: 71.09%] [G loss: 0.917903]\n",
      "epoch:7 step:7437 [D loss: 0.695659, acc.: 58.59%] [G loss: 1.016161]\n",
      "epoch:7 step:7438 [D loss: 0.639144, acc.: 61.72%] [G loss: 0.973580]\n",
      "epoch:7 step:7439 [D loss: 0.638899, acc.: 63.28%] [G loss: 0.982530]\n",
      "epoch:7 step:7440 [D loss: 0.652358, acc.: 56.25%] [G loss: 1.078202]\n",
      "epoch:7 step:7441 [D loss: 0.694492, acc.: 54.69%] [G loss: 0.965928]\n",
      "epoch:7 step:7442 [D loss: 0.778271, acc.: 46.09%] [G loss: 0.878082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7443 [D loss: 0.597098, acc.: 66.41%] [G loss: 0.931597]\n",
      "epoch:7 step:7444 [D loss: 0.632216, acc.: 62.50%] [G loss: 0.966209]\n",
      "epoch:7 step:7445 [D loss: 0.596918, acc.: 67.19%] [G loss: 1.062174]\n",
      "epoch:7 step:7446 [D loss: 0.637508, acc.: 60.94%] [G loss: 1.061164]\n",
      "epoch:7 step:7447 [D loss: 0.715943, acc.: 57.81%] [G loss: 0.860544]\n",
      "epoch:7 step:7448 [D loss: 0.646721, acc.: 61.72%] [G loss: 1.012307]\n",
      "epoch:7 step:7449 [D loss: 0.535952, acc.: 75.00%] [G loss: 1.194981]\n",
      "epoch:7 step:7450 [D loss: 0.716472, acc.: 54.69%] [G loss: 1.082555]\n",
      "epoch:7 step:7451 [D loss: 0.770987, acc.: 46.88%] [G loss: 1.030280]\n",
      "epoch:7 step:7452 [D loss: 0.618035, acc.: 67.97%] [G loss: 1.047421]\n",
      "epoch:7 step:7453 [D loss: 0.655102, acc.: 63.28%] [G loss: 0.848993]\n",
      "epoch:7 step:7454 [D loss: 0.651784, acc.: 63.28%] [G loss: 0.986311]\n",
      "epoch:7 step:7455 [D loss: 0.706147, acc.: 54.69%] [G loss: 0.867541]\n",
      "epoch:7 step:7456 [D loss: 0.631999, acc.: 57.81%] [G loss: 0.959073]\n",
      "epoch:7 step:7457 [D loss: 0.631144, acc.: 62.50%] [G loss: 0.991264]\n",
      "epoch:7 step:7458 [D loss: 0.530618, acc.: 74.22%] [G loss: 1.008777]\n",
      "epoch:7 step:7459 [D loss: 0.614096, acc.: 66.41%] [G loss: 0.954704]\n",
      "epoch:7 step:7460 [D loss: 0.602486, acc.: 66.41%] [G loss: 1.079715]\n",
      "epoch:7 step:7461 [D loss: 0.660038, acc.: 59.38%] [G loss: 1.028826]\n",
      "epoch:7 step:7462 [D loss: 0.715022, acc.: 53.91%] [G loss: 0.881115]\n",
      "epoch:7 step:7463 [D loss: 0.687721, acc.: 54.69%] [G loss: 0.918674]\n",
      "epoch:7 step:7464 [D loss: 0.631894, acc.: 65.62%] [G loss: 0.909214]\n",
      "epoch:7 step:7465 [D loss: 0.581835, acc.: 70.31%] [G loss: 1.000979]\n",
      "epoch:7 step:7466 [D loss: 0.651796, acc.: 60.94%] [G loss: 0.943191]\n",
      "epoch:7 step:7467 [D loss: 0.720933, acc.: 46.88%] [G loss: 0.842447]\n",
      "epoch:7 step:7468 [D loss: 0.752096, acc.: 43.75%] [G loss: 0.892878]\n",
      "epoch:7 step:7469 [D loss: 0.631002, acc.: 63.28%] [G loss: 0.980975]\n",
      "epoch:7 step:7470 [D loss: 0.580955, acc.: 71.09%] [G loss: 1.041461]\n",
      "epoch:7 step:7471 [D loss: 0.505610, acc.: 81.25%] [G loss: 0.958151]\n",
      "epoch:7 step:7472 [D loss: 0.654268, acc.: 63.28%] [G loss: 0.901641]\n",
      "epoch:7 step:7473 [D loss: 0.641845, acc.: 62.50%] [G loss: 1.001488]\n",
      "epoch:7 step:7474 [D loss: 0.668085, acc.: 60.94%] [G loss: 0.917049]\n",
      "epoch:7 step:7475 [D loss: 0.670709, acc.: 61.72%] [G loss: 0.947453]\n",
      "epoch:7 step:7476 [D loss: 0.678086, acc.: 58.59%] [G loss: 0.947641]\n",
      "epoch:7 step:7477 [D loss: 0.594684, acc.: 71.88%] [G loss: 1.016774]\n",
      "epoch:7 step:7478 [D loss: 0.596463, acc.: 68.75%] [G loss: 1.024143]\n",
      "epoch:7 step:7479 [D loss: 0.883492, acc.: 36.72%] [G loss: 0.984232]\n",
      "epoch:7 step:7480 [D loss: 0.664712, acc.: 60.94%] [G loss: 1.067715]\n",
      "epoch:7 step:7481 [D loss: 0.609727, acc.: 68.75%] [G loss: 0.998261]\n",
      "epoch:7 step:7482 [D loss: 0.613430, acc.: 70.31%] [G loss: 0.934453]\n",
      "epoch:7 step:7483 [D loss: 0.502494, acc.: 81.25%] [G loss: 1.073688]\n",
      "epoch:7 step:7484 [D loss: 0.547424, acc.: 75.00%] [G loss: 1.016932]\n",
      "epoch:7 step:7485 [D loss: 0.560504, acc.: 78.91%] [G loss: 1.125557]\n",
      "epoch:7 step:7486 [D loss: 0.516831, acc.: 79.69%] [G loss: 1.196891]\n",
      "epoch:7 step:7487 [D loss: 0.798018, acc.: 44.53%] [G loss: 1.065763]\n",
      "epoch:7 step:7488 [D loss: 0.854333, acc.: 37.50%] [G loss: 0.879407]\n",
      "epoch:7 step:7489 [D loss: 0.603993, acc.: 68.75%] [G loss: 0.964991]\n",
      "epoch:7 step:7490 [D loss: 0.610540, acc.: 64.84%] [G loss: 0.991524]\n",
      "epoch:7 step:7491 [D loss: 0.598109, acc.: 68.75%] [G loss: 0.880818]\n",
      "epoch:7 step:7492 [D loss: 0.645927, acc.: 65.62%] [G loss: 1.007074]\n",
      "epoch:7 step:7493 [D loss: 0.549846, acc.: 71.09%] [G loss: 1.018506]\n",
      "epoch:7 step:7494 [D loss: 0.618794, acc.: 68.75%] [G loss: 0.886586]\n",
      "epoch:7 step:7495 [D loss: 0.538053, acc.: 77.34%] [G loss: 0.977791]\n",
      "epoch:7 step:7496 [D loss: 0.435469, acc.: 85.94%] [G loss: 1.086809]\n",
      "epoch:8 step:7497 [D loss: 0.686565, acc.: 60.16%] [G loss: 1.175171]\n",
      "epoch:8 step:7498 [D loss: 0.650084, acc.: 64.06%] [G loss: 1.090954]\n",
      "epoch:8 step:7499 [D loss: 0.637320, acc.: 67.97%] [G loss: 1.021504]\n",
      "epoch:8 step:7500 [D loss: 0.597881, acc.: 67.97%] [G loss: 1.069587]\n",
      "epoch:8 step:7501 [D loss: 0.653681, acc.: 64.84%] [G loss: 1.111475]\n",
      "epoch:8 step:7502 [D loss: 0.618357, acc.: 66.41%] [G loss: 0.976111]\n",
      "epoch:8 step:7503 [D loss: 0.671638, acc.: 60.94%] [G loss: 0.951040]\n",
      "epoch:8 step:7504 [D loss: 0.710602, acc.: 53.12%] [G loss: 0.856305]\n",
      "epoch:8 step:7505 [D loss: 0.567877, acc.: 72.66%] [G loss: 1.059797]\n",
      "epoch:8 step:7506 [D loss: 0.550741, acc.: 77.34%] [G loss: 1.139787]\n",
      "epoch:8 step:7507 [D loss: 0.706119, acc.: 55.47%] [G loss: 1.006983]\n",
      "epoch:8 step:7508 [D loss: 0.685349, acc.: 56.25%] [G loss: 1.097267]\n",
      "epoch:8 step:7509 [D loss: 0.750749, acc.: 49.22%] [G loss: 0.869424]\n",
      "epoch:8 step:7510 [D loss: 0.562408, acc.: 73.44%] [G loss: 1.128336]\n",
      "epoch:8 step:7511 [D loss: 0.502927, acc.: 82.81%] [G loss: 1.234331]\n",
      "epoch:8 step:7512 [D loss: 0.649231, acc.: 60.94%] [G loss: 1.105801]\n",
      "epoch:8 step:7513 [D loss: 0.730349, acc.: 53.91%] [G loss: 0.937841]\n",
      "epoch:8 step:7514 [D loss: 0.665885, acc.: 57.81%] [G loss: 0.937620]\n",
      "epoch:8 step:7515 [D loss: 0.747825, acc.: 46.88%] [G loss: 0.914407]\n",
      "epoch:8 step:7516 [D loss: 0.765055, acc.: 47.66%] [G loss: 0.959557]\n",
      "epoch:8 step:7517 [D loss: 0.718103, acc.: 51.56%] [G loss: 0.968520]\n",
      "epoch:8 step:7518 [D loss: 0.658443, acc.: 62.50%] [G loss: 0.905823]\n",
      "epoch:8 step:7519 [D loss: 0.572102, acc.: 72.66%] [G loss: 1.086546]\n",
      "epoch:8 step:7520 [D loss: 0.685492, acc.: 52.34%] [G loss: 0.906817]\n",
      "epoch:8 step:7521 [D loss: 0.577497, acc.: 74.22%] [G loss: 0.997776]\n",
      "epoch:8 step:7522 [D loss: 0.732787, acc.: 46.88%] [G loss: 0.956575]\n",
      "epoch:8 step:7523 [D loss: 0.694781, acc.: 57.03%] [G loss: 0.919466]\n",
      "epoch:8 step:7524 [D loss: 0.631177, acc.: 66.41%] [G loss: 1.080058]\n",
      "epoch:8 step:7525 [D loss: 0.560616, acc.: 75.78%] [G loss: 0.963552]\n",
      "epoch:8 step:7526 [D loss: 0.628878, acc.: 59.38%] [G loss: 0.998346]\n",
      "epoch:8 step:7527 [D loss: 0.668685, acc.: 58.59%] [G loss: 0.956050]\n",
      "epoch:8 step:7528 [D loss: 0.706968, acc.: 53.12%] [G loss: 0.986475]\n",
      "epoch:8 step:7529 [D loss: 0.563918, acc.: 71.88%] [G loss: 1.028409]\n",
      "epoch:8 step:7530 [D loss: 0.657691, acc.: 55.47%] [G loss: 0.963037]\n",
      "epoch:8 step:7531 [D loss: 0.562336, acc.: 71.88%] [G loss: 1.019732]\n",
      "epoch:8 step:7532 [D loss: 0.519402, acc.: 78.12%] [G loss: 1.191993]\n",
      "epoch:8 step:7533 [D loss: 0.573496, acc.: 71.09%] [G loss: 1.239854]\n",
      "epoch:8 step:7534 [D loss: 0.623379, acc.: 68.75%] [G loss: 0.943193]\n",
      "epoch:8 step:7535 [D loss: 0.673605, acc.: 57.81%] [G loss: 0.994395]\n",
      "epoch:8 step:7536 [D loss: 0.631546, acc.: 63.28%] [G loss: 1.026487]\n",
      "epoch:8 step:7537 [D loss: 0.645175, acc.: 57.03%] [G loss: 0.955401]\n",
      "epoch:8 step:7538 [D loss: 0.567377, acc.: 73.44%] [G loss: 1.147990]\n",
      "epoch:8 step:7539 [D loss: 0.589636, acc.: 68.75%] [G loss: 1.016405]\n",
      "epoch:8 step:7540 [D loss: 0.703593, acc.: 54.69%] [G loss: 1.017835]\n",
      "epoch:8 step:7541 [D loss: 0.755683, acc.: 45.31%] [G loss: 0.864101]\n",
      "epoch:8 step:7542 [D loss: 0.681749, acc.: 60.16%] [G loss: 1.059433]\n",
      "epoch:8 step:7543 [D loss: 0.577150, acc.: 71.88%] [G loss: 0.911782]\n",
      "epoch:8 step:7544 [D loss: 0.646551, acc.: 62.50%] [G loss: 0.855623]\n",
      "epoch:8 step:7545 [D loss: 0.681683, acc.: 56.25%] [G loss: 1.048167]\n",
      "epoch:8 step:7546 [D loss: 0.581062, acc.: 70.31%] [G loss: 0.958013]\n",
      "epoch:8 step:7547 [D loss: 0.627833, acc.: 64.84%] [G loss: 1.110161]\n",
      "epoch:8 step:7548 [D loss: 0.611705, acc.: 67.97%] [G loss: 0.960918]\n",
      "epoch:8 step:7549 [D loss: 0.719540, acc.: 53.91%] [G loss: 0.808591]\n",
      "epoch:8 step:7550 [D loss: 0.593051, acc.: 67.97%] [G loss: 0.949431]\n",
      "epoch:8 step:7551 [D loss: 0.593777, acc.: 67.19%] [G loss: 1.057224]\n",
      "epoch:8 step:7552 [D loss: 0.706425, acc.: 60.94%] [G loss: 1.121888]\n",
      "epoch:8 step:7553 [D loss: 0.769032, acc.: 48.44%] [G loss: 1.015443]\n",
      "epoch:8 step:7554 [D loss: 0.720195, acc.: 51.56%] [G loss: 1.035867]\n",
      "epoch:8 step:7555 [D loss: 0.653249, acc.: 60.16%] [G loss: 1.006857]\n",
      "epoch:8 step:7556 [D loss: 0.632779, acc.: 61.72%] [G loss: 0.975633]\n",
      "epoch:8 step:7557 [D loss: 0.670856, acc.: 60.94%] [G loss: 0.885516]\n",
      "epoch:8 step:7558 [D loss: 0.667143, acc.: 57.81%] [G loss: 0.956630]\n",
      "epoch:8 step:7559 [D loss: 0.665266, acc.: 60.16%] [G loss: 0.925442]\n",
      "epoch:8 step:7560 [D loss: 0.641506, acc.: 62.50%] [G loss: 1.013906]\n",
      "epoch:8 step:7561 [D loss: 0.726840, acc.: 53.12%] [G loss: 0.963783]\n",
      "epoch:8 step:7562 [D loss: 0.675126, acc.: 58.59%] [G loss: 0.968590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7563 [D loss: 0.654381, acc.: 64.84%] [G loss: 0.952624]\n",
      "epoch:8 step:7564 [D loss: 0.732690, acc.: 52.34%] [G loss: 0.975876]\n",
      "epoch:8 step:7565 [D loss: 0.557269, acc.: 77.34%] [G loss: 1.119386]\n",
      "epoch:8 step:7566 [D loss: 0.629532, acc.: 64.06%] [G loss: 1.009364]\n",
      "epoch:8 step:7567 [D loss: 0.648330, acc.: 63.28%] [G loss: 1.038925]\n",
      "epoch:8 step:7568 [D loss: 0.655105, acc.: 60.94%] [G loss: 0.975533]\n",
      "epoch:8 step:7569 [D loss: 0.701249, acc.: 52.34%] [G loss: 0.988048]\n",
      "epoch:8 step:7570 [D loss: 0.584553, acc.: 73.44%] [G loss: 1.006062]\n",
      "epoch:8 step:7571 [D loss: 0.626569, acc.: 67.19%] [G loss: 1.065701]\n",
      "epoch:8 step:7572 [D loss: 0.691258, acc.: 53.91%] [G loss: 0.977471]\n",
      "epoch:8 step:7573 [D loss: 0.569393, acc.: 70.31%] [G loss: 1.040314]\n",
      "epoch:8 step:7574 [D loss: 0.754793, acc.: 47.66%] [G loss: 0.880707]\n",
      "epoch:8 step:7575 [D loss: 0.704132, acc.: 57.03%] [G loss: 0.891737]\n",
      "epoch:8 step:7576 [D loss: 0.622216, acc.: 64.06%] [G loss: 0.971555]\n",
      "epoch:8 step:7577 [D loss: 0.768864, acc.: 49.22%] [G loss: 0.808074]\n",
      "epoch:8 step:7578 [D loss: 0.648516, acc.: 64.06%] [G loss: 0.992586]\n",
      "epoch:8 step:7579 [D loss: 0.680788, acc.: 57.81%] [G loss: 1.065035]\n",
      "epoch:8 step:7580 [D loss: 0.665126, acc.: 54.69%] [G loss: 1.019271]\n",
      "epoch:8 step:7581 [D loss: 0.598168, acc.: 64.06%] [G loss: 0.958513]\n",
      "epoch:8 step:7582 [D loss: 0.659801, acc.: 60.16%] [G loss: 0.938035]\n",
      "epoch:8 step:7583 [D loss: 0.648048, acc.: 62.50%] [G loss: 0.980118]\n",
      "epoch:8 step:7584 [D loss: 0.577084, acc.: 67.97%] [G loss: 0.932673]\n",
      "epoch:8 step:7585 [D loss: 0.703100, acc.: 56.25%] [G loss: 0.952940]\n",
      "epoch:8 step:7586 [D loss: 0.701215, acc.: 55.47%] [G loss: 0.981552]\n",
      "epoch:8 step:7587 [D loss: 0.647289, acc.: 60.94%] [G loss: 0.907777]\n",
      "epoch:8 step:7588 [D loss: 0.604473, acc.: 66.41%] [G loss: 0.949471]\n",
      "epoch:8 step:7589 [D loss: 0.642592, acc.: 60.94%] [G loss: 0.991645]\n",
      "epoch:8 step:7590 [D loss: 0.665867, acc.: 60.94%] [G loss: 1.059386]\n",
      "epoch:8 step:7591 [D loss: 0.705394, acc.: 55.47%] [G loss: 0.907866]\n",
      "epoch:8 step:7592 [D loss: 0.667934, acc.: 63.28%] [G loss: 0.845508]\n",
      "epoch:8 step:7593 [D loss: 0.627993, acc.: 64.84%] [G loss: 0.874363]\n",
      "epoch:8 step:7594 [D loss: 0.700253, acc.: 53.12%] [G loss: 0.988453]\n",
      "epoch:8 step:7595 [D loss: 0.667137, acc.: 60.16%] [G loss: 1.137190]\n",
      "epoch:8 step:7596 [D loss: 0.649570, acc.: 60.94%] [G loss: 0.946609]\n",
      "epoch:8 step:7597 [D loss: 0.654806, acc.: 59.38%] [G loss: 0.860610]\n",
      "epoch:8 step:7598 [D loss: 0.601678, acc.: 70.31%] [G loss: 1.058261]\n",
      "epoch:8 step:7599 [D loss: 0.624630, acc.: 66.41%] [G loss: 1.023868]\n",
      "epoch:8 step:7600 [D loss: 0.668344, acc.: 63.28%] [G loss: 0.878507]\n",
      "epoch:8 step:7601 [D loss: 0.719007, acc.: 50.78%] [G loss: 1.046979]\n",
      "epoch:8 step:7602 [D loss: 0.598270, acc.: 72.66%] [G loss: 1.089591]\n",
      "epoch:8 step:7603 [D loss: 0.679234, acc.: 57.81%] [G loss: 1.057695]\n",
      "epoch:8 step:7604 [D loss: 0.625781, acc.: 63.28%] [G loss: 0.974182]\n",
      "epoch:8 step:7605 [D loss: 0.734264, acc.: 52.34%] [G loss: 0.761802]\n",
      "epoch:8 step:7606 [D loss: 0.731828, acc.: 52.34%] [G loss: 0.855133]\n",
      "epoch:8 step:7607 [D loss: 0.628633, acc.: 65.62%] [G loss: 0.859419]\n",
      "epoch:8 step:7608 [D loss: 0.619856, acc.: 64.84%] [G loss: 0.858898]\n",
      "epoch:8 step:7609 [D loss: 0.676323, acc.: 60.16%] [G loss: 1.049098]\n",
      "epoch:8 step:7610 [D loss: 0.696020, acc.: 54.69%] [G loss: 0.818384]\n",
      "epoch:8 step:7611 [D loss: 0.724549, acc.: 51.56%] [G loss: 0.919231]\n",
      "epoch:8 step:7612 [D loss: 0.614066, acc.: 64.06%] [G loss: 1.037799]\n",
      "epoch:8 step:7613 [D loss: 0.605363, acc.: 64.84%] [G loss: 0.989963]\n",
      "epoch:8 step:7614 [D loss: 0.662035, acc.: 55.47%] [G loss: 1.003322]\n",
      "epoch:8 step:7615 [D loss: 0.643701, acc.: 67.19%] [G loss: 1.019560]\n",
      "epoch:8 step:7616 [D loss: 0.758866, acc.: 50.00%] [G loss: 0.922920]\n",
      "epoch:8 step:7617 [D loss: 0.658113, acc.: 57.81%] [G loss: 0.936343]\n",
      "epoch:8 step:7618 [D loss: 0.659992, acc.: 60.94%] [G loss: 0.910343]\n",
      "epoch:8 step:7619 [D loss: 0.664975, acc.: 57.03%] [G loss: 0.955825]\n",
      "epoch:8 step:7620 [D loss: 0.693760, acc.: 53.12%] [G loss: 0.969169]\n",
      "epoch:8 step:7621 [D loss: 0.658875, acc.: 60.16%] [G loss: 0.926685]\n",
      "epoch:8 step:7622 [D loss: 0.698091, acc.: 52.34%] [G loss: 0.952841]\n",
      "epoch:8 step:7623 [D loss: 0.626136, acc.: 68.75%] [G loss: 0.855883]\n",
      "epoch:8 step:7624 [D loss: 0.648396, acc.: 61.72%] [G loss: 0.910555]\n",
      "epoch:8 step:7625 [D loss: 0.718636, acc.: 53.91%] [G loss: 0.845213]\n",
      "epoch:8 step:7626 [D loss: 0.724704, acc.: 59.38%] [G loss: 0.836556]\n",
      "epoch:8 step:7627 [D loss: 0.684119, acc.: 53.91%] [G loss: 0.856413]\n",
      "epoch:8 step:7628 [D loss: 0.605509, acc.: 68.75%] [G loss: 1.058801]\n",
      "epoch:8 step:7629 [D loss: 0.701142, acc.: 58.59%] [G loss: 0.885340]\n",
      "epoch:8 step:7630 [D loss: 0.692818, acc.: 57.03%] [G loss: 0.909383]\n",
      "epoch:8 step:7631 [D loss: 0.627444, acc.: 64.84%] [G loss: 1.075364]\n",
      "epoch:8 step:7632 [D loss: 0.643045, acc.: 57.03%] [G loss: 0.884306]\n",
      "epoch:8 step:7633 [D loss: 0.634685, acc.: 62.50%] [G loss: 1.077835]\n",
      "epoch:8 step:7634 [D loss: 0.690060, acc.: 57.81%] [G loss: 0.943627]\n",
      "epoch:8 step:7635 [D loss: 0.696079, acc.: 60.16%] [G loss: 1.032212]\n",
      "epoch:8 step:7636 [D loss: 0.623258, acc.: 64.06%] [G loss: 0.994512]\n",
      "epoch:8 step:7637 [D loss: 0.628438, acc.: 64.06%] [G loss: 1.080117]\n",
      "epoch:8 step:7638 [D loss: 0.655913, acc.: 62.50%] [G loss: 1.057707]\n",
      "epoch:8 step:7639 [D loss: 0.761970, acc.: 49.22%] [G loss: 0.986575]\n",
      "epoch:8 step:7640 [D loss: 0.592043, acc.: 70.31%] [G loss: 1.014134]\n",
      "epoch:8 step:7641 [D loss: 0.660671, acc.: 60.16%] [G loss: 1.027177]\n",
      "epoch:8 step:7642 [D loss: 0.628424, acc.: 62.50%] [G loss: 0.916301]\n",
      "epoch:8 step:7643 [D loss: 0.654776, acc.: 60.16%] [G loss: 0.876350]\n",
      "epoch:8 step:7644 [D loss: 0.628809, acc.: 59.38%] [G loss: 1.001298]\n",
      "epoch:8 step:7645 [D loss: 0.601596, acc.: 67.97%] [G loss: 0.979600]\n",
      "epoch:8 step:7646 [D loss: 0.634356, acc.: 64.84%] [G loss: 1.049088]\n",
      "epoch:8 step:7647 [D loss: 0.665291, acc.: 60.16%] [G loss: 1.006327]\n",
      "epoch:8 step:7648 [D loss: 0.571420, acc.: 71.88%] [G loss: 1.175963]\n",
      "epoch:8 step:7649 [D loss: 0.609162, acc.: 64.84%] [G loss: 1.192914]\n",
      "epoch:8 step:7650 [D loss: 0.665866, acc.: 58.59%] [G loss: 1.028190]\n",
      "epoch:8 step:7651 [D loss: 0.604181, acc.: 67.97%] [G loss: 1.022334]\n",
      "epoch:8 step:7652 [D loss: 0.738666, acc.: 49.22%] [G loss: 0.836945]\n",
      "epoch:8 step:7653 [D loss: 0.617791, acc.: 67.19%] [G loss: 0.997614]\n",
      "epoch:8 step:7654 [D loss: 0.694976, acc.: 52.34%] [G loss: 0.955087]\n",
      "epoch:8 step:7655 [D loss: 0.727970, acc.: 53.91%] [G loss: 0.894773]\n",
      "epoch:8 step:7656 [D loss: 0.664421, acc.: 65.62%] [G loss: 1.012672]\n",
      "epoch:8 step:7657 [D loss: 0.723181, acc.: 51.56%] [G loss: 0.843384]\n",
      "epoch:8 step:7658 [D loss: 0.608135, acc.: 65.62%] [G loss: 0.824846]\n",
      "epoch:8 step:7659 [D loss: 0.667124, acc.: 57.81%] [G loss: 0.880102]\n",
      "epoch:8 step:7660 [D loss: 0.665778, acc.: 60.94%] [G loss: 0.894642]\n",
      "epoch:8 step:7661 [D loss: 0.647963, acc.: 67.19%] [G loss: 0.922972]\n",
      "epoch:8 step:7662 [D loss: 0.716547, acc.: 53.12%] [G loss: 0.858090]\n",
      "epoch:8 step:7663 [D loss: 0.597235, acc.: 67.19%] [G loss: 1.049127]\n",
      "epoch:8 step:7664 [D loss: 0.650483, acc.: 65.62%] [G loss: 1.021583]\n",
      "epoch:8 step:7665 [D loss: 0.704180, acc.: 57.03%] [G loss: 0.976223]\n",
      "epoch:8 step:7666 [D loss: 0.621312, acc.: 60.94%] [G loss: 0.995179]\n",
      "epoch:8 step:7667 [D loss: 0.628305, acc.: 62.50%] [G loss: 0.870776]\n",
      "epoch:8 step:7668 [D loss: 0.682335, acc.: 56.25%] [G loss: 0.984381]\n",
      "epoch:8 step:7669 [D loss: 0.615467, acc.: 70.31%] [G loss: 0.919789]\n",
      "epoch:8 step:7670 [D loss: 0.676312, acc.: 53.91%] [G loss: 0.854162]\n",
      "epoch:8 step:7671 [D loss: 0.702783, acc.: 53.12%] [G loss: 0.816029]\n",
      "epoch:8 step:7672 [D loss: 0.648383, acc.: 60.16%] [G loss: 0.950602]\n",
      "epoch:8 step:7673 [D loss: 0.712554, acc.: 51.56%] [G loss: 0.950326]\n",
      "epoch:8 step:7674 [D loss: 0.619714, acc.: 67.19%] [G loss: 1.109352]\n",
      "epoch:8 step:7675 [D loss: 0.756281, acc.: 50.00%] [G loss: 0.940709]\n",
      "epoch:8 step:7676 [D loss: 0.657210, acc.: 64.06%] [G loss: 0.836755]\n",
      "epoch:8 step:7677 [D loss: 0.660272, acc.: 59.38%] [G loss: 0.817227]\n",
      "epoch:8 step:7678 [D loss: 0.657836, acc.: 60.16%] [G loss: 1.014694]\n",
      "epoch:8 step:7679 [D loss: 0.628748, acc.: 64.06%] [G loss: 0.997205]\n",
      "epoch:8 step:7680 [D loss: 0.721944, acc.: 50.00%] [G loss: 0.914390]\n",
      "epoch:8 step:7681 [D loss: 0.679067, acc.: 64.06%] [G loss: 0.956876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7682 [D loss: 0.741521, acc.: 50.78%] [G loss: 0.920542]\n",
      "epoch:8 step:7683 [D loss: 0.600491, acc.: 68.75%] [G loss: 1.004088]\n",
      "epoch:8 step:7684 [D loss: 0.678127, acc.: 61.72%] [G loss: 0.904031]\n",
      "epoch:8 step:7685 [D loss: 0.689748, acc.: 51.56%] [G loss: 0.889093]\n",
      "epoch:8 step:7686 [D loss: 0.580785, acc.: 75.00%] [G loss: 1.119130]\n",
      "epoch:8 step:7687 [D loss: 0.673055, acc.: 61.72%] [G loss: 0.998708]\n",
      "epoch:8 step:7688 [D loss: 0.663816, acc.: 62.50%] [G loss: 0.954856]\n",
      "epoch:8 step:7689 [D loss: 0.653499, acc.: 59.38%] [G loss: 0.855970]\n",
      "epoch:8 step:7690 [D loss: 0.641261, acc.: 64.84%] [G loss: 0.906796]\n",
      "epoch:8 step:7691 [D loss: 0.644415, acc.: 66.41%] [G loss: 1.099856]\n",
      "epoch:8 step:7692 [D loss: 0.719401, acc.: 50.00%] [G loss: 1.029861]\n",
      "epoch:8 step:7693 [D loss: 0.683530, acc.: 60.94%] [G loss: 0.936573]\n",
      "epoch:8 step:7694 [D loss: 0.674816, acc.: 61.72%] [G loss: 0.927750]\n",
      "epoch:8 step:7695 [D loss: 0.689367, acc.: 56.25%] [G loss: 0.963880]\n",
      "epoch:8 step:7696 [D loss: 0.673534, acc.: 54.69%] [G loss: 0.974665]\n",
      "epoch:8 step:7697 [D loss: 0.721416, acc.: 53.12%] [G loss: 0.940592]\n",
      "epoch:8 step:7698 [D loss: 0.721836, acc.: 48.44%] [G loss: 0.877824]\n",
      "epoch:8 step:7699 [D loss: 0.672220, acc.: 60.94%] [G loss: 0.984182]\n",
      "epoch:8 step:7700 [D loss: 0.661622, acc.: 57.03%] [G loss: 0.788456]\n",
      "epoch:8 step:7701 [D loss: 0.642163, acc.: 59.38%] [G loss: 0.974931]\n",
      "epoch:8 step:7702 [D loss: 0.624112, acc.: 67.19%] [G loss: 0.973087]\n",
      "epoch:8 step:7703 [D loss: 0.629046, acc.: 63.28%] [G loss: 0.988948]\n",
      "epoch:8 step:7704 [D loss: 0.566154, acc.: 75.00%] [G loss: 0.960025]\n",
      "epoch:8 step:7705 [D loss: 0.592968, acc.: 65.62%] [G loss: 0.936395]\n",
      "epoch:8 step:7706 [D loss: 0.679887, acc.: 59.38%] [G loss: 0.960260]\n",
      "epoch:8 step:7707 [D loss: 0.697831, acc.: 56.25%] [G loss: 0.794654]\n",
      "epoch:8 step:7708 [D loss: 0.689860, acc.: 58.59%] [G loss: 0.931269]\n",
      "epoch:8 step:7709 [D loss: 0.634248, acc.: 67.19%] [G loss: 0.890574]\n",
      "epoch:8 step:7710 [D loss: 0.817848, acc.: 42.19%] [G loss: 0.823414]\n",
      "epoch:8 step:7711 [D loss: 0.709793, acc.: 49.22%] [G loss: 0.900981]\n",
      "epoch:8 step:7712 [D loss: 0.754312, acc.: 46.09%] [G loss: 0.800971]\n",
      "epoch:8 step:7713 [D loss: 0.616031, acc.: 65.62%] [G loss: 0.973836]\n",
      "epoch:8 step:7714 [D loss: 0.569364, acc.: 73.44%] [G loss: 0.963755]\n",
      "epoch:8 step:7715 [D loss: 0.671118, acc.: 58.59%] [G loss: 0.961761]\n",
      "epoch:8 step:7716 [D loss: 0.682323, acc.: 57.03%] [G loss: 0.835641]\n",
      "epoch:8 step:7717 [D loss: 0.614288, acc.: 67.97%] [G loss: 0.943650]\n",
      "epoch:8 step:7718 [D loss: 0.621458, acc.: 67.97%] [G loss: 1.056751]\n",
      "epoch:8 step:7719 [D loss: 0.580148, acc.: 75.00%] [G loss: 1.023323]\n",
      "epoch:8 step:7720 [D loss: 0.721651, acc.: 54.69%] [G loss: 1.009807]\n",
      "epoch:8 step:7721 [D loss: 0.634521, acc.: 64.06%] [G loss: 0.982279]\n",
      "epoch:8 step:7722 [D loss: 0.693489, acc.: 55.47%] [G loss: 0.886053]\n",
      "epoch:8 step:7723 [D loss: 0.661866, acc.: 60.94%] [G loss: 0.828222]\n",
      "epoch:8 step:7724 [D loss: 0.711553, acc.: 59.38%] [G loss: 0.986580]\n",
      "epoch:8 step:7725 [D loss: 0.618818, acc.: 69.53%] [G loss: 0.985165]\n",
      "epoch:8 step:7726 [D loss: 0.551740, acc.: 72.66%] [G loss: 0.876023]\n",
      "epoch:8 step:7727 [D loss: 0.540400, acc.: 78.91%] [G loss: 0.923154]\n",
      "epoch:8 step:7728 [D loss: 0.547181, acc.: 73.44%] [G loss: 1.009051]\n",
      "epoch:8 step:7729 [D loss: 0.609635, acc.: 67.19%] [G loss: 1.259159]\n",
      "epoch:8 step:7730 [D loss: 0.714490, acc.: 56.25%] [G loss: 1.009350]\n",
      "epoch:8 step:7731 [D loss: 0.705429, acc.: 59.38%] [G loss: 0.849998]\n",
      "epoch:8 step:7732 [D loss: 0.716795, acc.: 50.78%] [G loss: 0.931779]\n",
      "epoch:8 step:7733 [D loss: 0.746852, acc.: 46.88%] [G loss: 0.915559]\n",
      "epoch:8 step:7734 [D loss: 0.684783, acc.: 58.59%] [G loss: 1.063892]\n",
      "epoch:8 step:7735 [D loss: 0.722508, acc.: 48.44%] [G loss: 0.921892]\n",
      "epoch:8 step:7736 [D loss: 0.657016, acc.: 60.16%] [G loss: 1.014034]\n",
      "epoch:8 step:7737 [D loss: 0.687712, acc.: 55.47%] [G loss: 0.980792]\n",
      "epoch:8 step:7738 [D loss: 0.740316, acc.: 52.34%] [G loss: 0.821325]\n",
      "epoch:8 step:7739 [D loss: 0.718193, acc.: 54.69%] [G loss: 0.886515]\n",
      "epoch:8 step:7740 [D loss: 0.572618, acc.: 72.66%] [G loss: 0.940970]\n",
      "epoch:8 step:7741 [D loss: 0.591458, acc.: 70.31%] [G loss: 1.030163]\n",
      "epoch:8 step:7742 [D loss: 0.682315, acc.: 55.47%] [G loss: 0.916940]\n",
      "epoch:8 step:7743 [D loss: 0.705230, acc.: 54.69%] [G loss: 0.967556]\n",
      "epoch:8 step:7744 [D loss: 0.658052, acc.: 62.50%] [G loss: 0.933982]\n",
      "epoch:8 step:7745 [D loss: 0.684806, acc.: 58.59%] [G loss: 0.884634]\n",
      "epoch:8 step:7746 [D loss: 0.769777, acc.: 46.09%] [G loss: 0.874352]\n",
      "epoch:8 step:7747 [D loss: 0.728821, acc.: 53.91%] [G loss: 0.875984]\n",
      "epoch:8 step:7748 [D loss: 0.658623, acc.: 60.16%] [G loss: 0.920206]\n",
      "epoch:8 step:7749 [D loss: 0.625707, acc.: 66.41%] [G loss: 1.000071]\n",
      "epoch:8 step:7750 [D loss: 0.637969, acc.: 60.94%] [G loss: 0.908563]\n",
      "epoch:8 step:7751 [D loss: 0.692201, acc.: 56.25%] [G loss: 0.972028]\n",
      "epoch:8 step:7752 [D loss: 0.608664, acc.: 67.97%] [G loss: 0.926026]\n",
      "epoch:8 step:7753 [D loss: 0.688114, acc.: 58.59%] [G loss: 0.836883]\n",
      "epoch:8 step:7754 [D loss: 0.629329, acc.: 67.19%] [G loss: 1.042955]\n",
      "epoch:8 step:7755 [D loss: 0.563773, acc.: 71.09%] [G loss: 1.018883]\n",
      "epoch:8 step:7756 [D loss: 0.598403, acc.: 64.06%] [G loss: 0.978510]\n",
      "epoch:8 step:7757 [D loss: 0.629996, acc.: 64.84%] [G loss: 0.952865]\n",
      "epoch:8 step:7758 [D loss: 0.646642, acc.: 54.69%] [G loss: 0.918890]\n",
      "epoch:8 step:7759 [D loss: 0.630414, acc.: 65.62%] [G loss: 0.961027]\n",
      "epoch:8 step:7760 [D loss: 0.598673, acc.: 70.31%] [G loss: 1.012885]\n",
      "epoch:8 step:7761 [D loss: 0.636709, acc.: 66.41%] [G loss: 1.016267]\n",
      "epoch:8 step:7762 [D loss: 0.696298, acc.: 57.81%] [G loss: 0.861797]\n",
      "epoch:8 step:7763 [D loss: 0.666975, acc.: 61.72%] [G loss: 0.985700]\n",
      "epoch:8 step:7764 [D loss: 0.651453, acc.: 60.16%] [G loss: 0.887683]\n",
      "epoch:8 step:7765 [D loss: 0.673974, acc.: 55.47%] [G loss: 0.867444]\n",
      "epoch:8 step:7766 [D loss: 0.650218, acc.: 66.41%] [G loss: 0.919359]\n",
      "epoch:8 step:7767 [D loss: 0.721430, acc.: 53.91%] [G loss: 0.966574]\n",
      "epoch:8 step:7768 [D loss: 0.668586, acc.: 61.72%] [G loss: 0.992474]\n",
      "epoch:8 step:7769 [D loss: 0.642749, acc.: 62.50%] [G loss: 0.937823]\n",
      "epoch:8 step:7770 [D loss: 0.670170, acc.: 62.50%] [G loss: 0.970629]\n",
      "epoch:8 step:7771 [D loss: 0.635890, acc.: 65.62%] [G loss: 0.958775]\n",
      "epoch:8 step:7772 [D loss: 0.660933, acc.: 60.16%] [G loss: 0.892652]\n",
      "epoch:8 step:7773 [D loss: 0.589243, acc.: 69.53%] [G loss: 0.986022]\n",
      "epoch:8 step:7774 [D loss: 0.608457, acc.: 63.28%] [G loss: 0.892347]\n",
      "epoch:8 step:7775 [D loss: 0.678090, acc.: 64.84%] [G loss: 0.906898]\n",
      "epoch:8 step:7776 [D loss: 0.708770, acc.: 53.91%] [G loss: 0.804025]\n",
      "epoch:8 step:7777 [D loss: 0.766238, acc.: 45.31%] [G loss: 0.928020]\n",
      "epoch:8 step:7778 [D loss: 0.677845, acc.: 59.38%] [G loss: 1.021321]\n",
      "epoch:8 step:7779 [D loss: 0.601786, acc.: 69.53%] [G loss: 0.927677]\n",
      "epoch:8 step:7780 [D loss: 0.624792, acc.: 67.19%] [G loss: 0.897692]\n",
      "epoch:8 step:7781 [D loss: 0.641993, acc.: 61.72%] [G loss: 0.891908]\n",
      "epoch:8 step:7782 [D loss: 0.641342, acc.: 67.97%] [G loss: 0.917591]\n",
      "epoch:8 step:7783 [D loss: 0.607624, acc.: 67.97%] [G loss: 0.947564]\n",
      "epoch:8 step:7784 [D loss: 0.674422, acc.: 60.94%] [G loss: 1.016960]\n",
      "epoch:8 step:7785 [D loss: 0.648092, acc.: 62.50%] [G loss: 0.969748]\n",
      "epoch:8 step:7786 [D loss: 0.701628, acc.: 53.12%] [G loss: 0.919937]\n",
      "epoch:8 step:7787 [D loss: 0.678351, acc.: 56.25%] [G loss: 0.919354]\n",
      "epoch:8 step:7788 [D loss: 0.676906, acc.: 57.03%] [G loss: 0.780314]\n",
      "epoch:8 step:7789 [D loss: 0.677000, acc.: 59.38%] [G loss: 0.957798]\n",
      "epoch:8 step:7790 [D loss: 0.631908, acc.: 62.50%] [G loss: 1.046526]\n",
      "epoch:8 step:7791 [D loss: 0.684208, acc.: 56.25%] [G loss: 0.973071]\n",
      "epoch:8 step:7792 [D loss: 0.649130, acc.: 58.59%] [G loss: 1.022410]\n",
      "epoch:8 step:7793 [D loss: 0.653175, acc.: 64.06%] [G loss: 0.972255]\n",
      "epoch:8 step:7794 [D loss: 0.615196, acc.: 62.50%] [G loss: 0.859823]\n",
      "epoch:8 step:7795 [D loss: 0.671736, acc.: 57.81%] [G loss: 0.936561]\n",
      "epoch:8 step:7796 [D loss: 0.610385, acc.: 68.75%] [G loss: 0.974920]\n",
      "epoch:8 step:7797 [D loss: 0.670810, acc.: 57.81%] [G loss: 0.911491]\n",
      "epoch:8 step:7798 [D loss: 0.601841, acc.: 71.88%] [G loss: 1.031166]\n",
      "epoch:8 step:7799 [D loss: 0.635273, acc.: 64.84%] [G loss: 0.941479]\n",
      "epoch:8 step:7800 [D loss: 0.667772, acc.: 53.12%] [G loss: 0.911588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7801 [D loss: 0.644499, acc.: 64.06%] [G loss: 0.997812]\n",
      "epoch:8 step:7802 [D loss: 0.589541, acc.: 72.66%] [G loss: 1.003640]\n",
      "epoch:8 step:7803 [D loss: 0.595475, acc.: 70.31%] [G loss: 0.916510]\n",
      "epoch:8 step:7804 [D loss: 0.559593, acc.: 71.09%] [G loss: 1.037530]\n",
      "epoch:8 step:7805 [D loss: 0.574763, acc.: 76.56%] [G loss: 1.048239]\n",
      "epoch:8 step:7806 [D loss: 0.655870, acc.: 61.72%] [G loss: 0.912143]\n",
      "epoch:8 step:7807 [D loss: 0.568897, acc.: 72.66%] [G loss: 0.879099]\n",
      "epoch:8 step:7808 [D loss: 0.628023, acc.: 64.84%] [G loss: 1.006378]\n",
      "epoch:8 step:7809 [D loss: 0.555383, acc.: 75.78%] [G loss: 1.018435]\n",
      "epoch:8 step:7810 [D loss: 0.536938, acc.: 77.34%] [G loss: 1.104786]\n",
      "epoch:8 step:7811 [D loss: 0.535823, acc.: 71.88%] [G loss: 1.189305]\n",
      "epoch:8 step:7812 [D loss: 0.739485, acc.: 53.12%] [G loss: 1.004853]\n",
      "epoch:8 step:7813 [D loss: 0.706796, acc.: 53.12%] [G loss: 1.027105]\n",
      "epoch:8 step:7814 [D loss: 0.640363, acc.: 61.72%] [G loss: 0.962721]\n",
      "epoch:8 step:7815 [D loss: 0.721117, acc.: 50.00%] [G loss: 0.827742]\n",
      "epoch:8 step:7816 [D loss: 0.668086, acc.: 57.03%] [G loss: 1.081012]\n",
      "epoch:8 step:7817 [D loss: 0.602792, acc.: 69.53%] [G loss: 0.888258]\n",
      "epoch:8 step:7818 [D loss: 0.658429, acc.: 55.47%] [G loss: 0.923697]\n",
      "epoch:8 step:7819 [D loss: 0.743038, acc.: 46.09%] [G loss: 0.848867]\n",
      "epoch:8 step:7820 [D loss: 0.628179, acc.: 64.84%] [G loss: 0.919896]\n",
      "epoch:8 step:7821 [D loss: 0.629716, acc.: 64.06%] [G loss: 0.915729]\n",
      "epoch:8 step:7822 [D loss: 0.704848, acc.: 60.94%] [G loss: 0.873344]\n",
      "epoch:8 step:7823 [D loss: 0.675224, acc.: 54.69%] [G loss: 0.882512]\n",
      "epoch:8 step:7824 [D loss: 0.573013, acc.: 72.66%] [G loss: 1.127779]\n",
      "epoch:8 step:7825 [D loss: 0.661044, acc.: 60.16%] [G loss: 0.830157]\n",
      "epoch:8 step:7826 [D loss: 0.594257, acc.: 69.53%] [G loss: 1.018493]\n",
      "epoch:8 step:7827 [D loss: 0.623704, acc.: 64.84%] [G loss: 1.013692]\n",
      "epoch:8 step:7828 [D loss: 0.613964, acc.: 65.62%] [G loss: 0.953405]\n",
      "epoch:8 step:7829 [D loss: 0.590659, acc.: 67.97%] [G loss: 0.939398]\n",
      "epoch:8 step:7830 [D loss: 0.701366, acc.: 50.78%] [G loss: 1.037846]\n",
      "epoch:8 step:7831 [D loss: 0.596277, acc.: 69.53%] [G loss: 0.838281]\n",
      "epoch:8 step:7832 [D loss: 0.585673, acc.: 68.75%] [G loss: 1.022402]\n",
      "epoch:8 step:7833 [D loss: 0.580264, acc.: 70.31%] [G loss: 1.135683]\n",
      "epoch:8 step:7834 [D loss: 0.565742, acc.: 77.34%] [G loss: 0.951644]\n",
      "epoch:8 step:7835 [D loss: 0.654788, acc.: 64.06%] [G loss: 1.101512]\n",
      "epoch:8 step:7836 [D loss: 0.614065, acc.: 60.16%] [G loss: 0.829763]\n",
      "epoch:8 step:7837 [D loss: 0.685715, acc.: 59.38%] [G loss: 0.978982]\n",
      "epoch:8 step:7838 [D loss: 0.717035, acc.: 56.25%] [G loss: 0.945213]\n",
      "epoch:8 step:7839 [D loss: 0.696117, acc.: 55.47%] [G loss: 0.962416]\n",
      "epoch:8 step:7840 [D loss: 0.606683, acc.: 71.09%] [G loss: 0.919129]\n",
      "epoch:8 step:7841 [D loss: 0.575458, acc.: 67.19%] [G loss: 0.886969]\n",
      "epoch:8 step:7842 [D loss: 0.554431, acc.: 71.88%] [G loss: 1.002250]\n",
      "epoch:8 step:7843 [D loss: 0.646991, acc.: 60.94%] [G loss: 1.026180]\n",
      "epoch:8 step:7844 [D loss: 0.718776, acc.: 49.22%] [G loss: 0.894545]\n",
      "epoch:8 step:7845 [D loss: 0.784024, acc.: 42.97%] [G loss: 0.779941]\n",
      "epoch:8 step:7846 [D loss: 0.721173, acc.: 50.78%] [G loss: 0.925181]\n",
      "epoch:8 step:7847 [D loss: 0.711432, acc.: 53.91%] [G loss: 0.786571]\n",
      "epoch:8 step:7848 [D loss: 0.692926, acc.: 54.69%] [G loss: 1.160449]\n",
      "epoch:8 step:7849 [D loss: 0.678088, acc.: 57.81%] [G loss: 0.896241]\n",
      "epoch:8 step:7850 [D loss: 0.600896, acc.: 65.62%] [G loss: 0.862549]\n",
      "epoch:8 step:7851 [D loss: 0.672118, acc.: 58.59%] [G loss: 0.941302]\n",
      "epoch:8 step:7852 [D loss: 0.685457, acc.: 53.91%] [G loss: 0.927575]\n",
      "epoch:8 step:7853 [D loss: 0.579592, acc.: 70.31%] [G loss: 1.074127]\n",
      "epoch:8 step:7854 [D loss: 0.656039, acc.: 63.28%] [G loss: 0.907243]\n",
      "epoch:8 step:7855 [D loss: 0.579383, acc.: 71.88%] [G loss: 1.015756]\n",
      "epoch:8 step:7856 [D loss: 0.601082, acc.: 66.41%] [G loss: 1.105365]\n",
      "epoch:8 step:7857 [D loss: 0.666561, acc.: 60.16%] [G loss: 0.904997]\n",
      "epoch:8 step:7858 [D loss: 0.725504, acc.: 56.25%] [G loss: 0.903267]\n",
      "epoch:8 step:7859 [D loss: 0.670284, acc.: 57.81%] [G loss: 0.932886]\n",
      "epoch:8 step:7860 [D loss: 0.643758, acc.: 64.06%] [G loss: 0.759339]\n",
      "epoch:8 step:7861 [D loss: 0.605661, acc.: 65.62%] [G loss: 0.965955]\n",
      "epoch:8 step:7862 [D loss: 0.653493, acc.: 64.84%] [G loss: 1.035058]\n",
      "epoch:8 step:7863 [D loss: 0.648090, acc.: 64.84%] [G loss: 1.028828]\n",
      "epoch:8 step:7864 [D loss: 0.663139, acc.: 61.72%] [G loss: 0.904130]\n",
      "epoch:8 step:7865 [D loss: 0.692802, acc.: 57.81%] [G loss: 0.900592]\n",
      "epoch:8 step:7866 [D loss: 0.539021, acc.: 76.56%] [G loss: 0.971655]\n",
      "epoch:8 step:7867 [D loss: 0.607610, acc.: 68.75%] [G loss: 1.009740]\n",
      "epoch:8 step:7868 [D loss: 0.667028, acc.: 57.03%] [G loss: 0.946939]\n",
      "epoch:8 step:7869 [D loss: 0.656231, acc.: 62.50%] [G loss: 0.985981]\n",
      "epoch:8 step:7870 [D loss: 0.673126, acc.: 57.81%] [G loss: 0.971112]\n",
      "epoch:8 step:7871 [D loss: 0.759316, acc.: 46.09%] [G loss: 0.860970]\n",
      "epoch:8 step:7872 [D loss: 0.735626, acc.: 47.66%] [G loss: 0.983169]\n",
      "epoch:8 step:7873 [D loss: 0.734028, acc.: 45.31%] [G loss: 0.845102]\n",
      "epoch:8 step:7874 [D loss: 0.667307, acc.: 60.16%] [G loss: 1.043162]\n",
      "epoch:8 step:7875 [D loss: 0.693875, acc.: 57.03%] [G loss: 0.993632]\n",
      "epoch:8 step:7876 [D loss: 0.627422, acc.: 65.62%] [G loss: 0.945087]\n",
      "epoch:8 step:7877 [D loss: 0.564246, acc.: 72.66%] [G loss: 1.114680]\n",
      "epoch:8 step:7878 [D loss: 0.583265, acc.: 71.88%] [G loss: 1.030342]\n",
      "epoch:8 step:7879 [D loss: 0.667444, acc.: 59.38%] [G loss: 0.978515]\n",
      "epoch:8 step:7880 [D loss: 0.590573, acc.: 69.53%] [G loss: 1.012785]\n",
      "epoch:8 step:7881 [D loss: 0.683915, acc.: 57.81%] [G loss: 0.936718]\n",
      "epoch:8 step:7882 [D loss: 0.709350, acc.: 55.47%] [G loss: 0.902284]\n",
      "epoch:8 step:7883 [D loss: 0.612596, acc.: 63.28%] [G loss: 1.003281]\n",
      "epoch:8 step:7884 [D loss: 0.613958, acc.: 71.09%] [G loss: 0.990925]\n",
      "epoch:8 step:7885 [D loss: 0.682725, acc.: 59.38%] [G loss: 0.985008]\n",
      "epoch:8 step:7886 [D loss: 0.652321, acc.: 60.94%] [G loss: 1.028498]\n",
      "epoch:8 step:7887 [D loss: 0.617750, acc.: 64.06%] [G loss: 1.132855]\n",
      "epoch:8 step:7888 [D loss: 0.632654, acc.: 65.62%] [G loss: 0.947019]\n",
      "epoch:8 step:7889 [D loss: 0.679582, acc.: 59.38%] [G loss: 0.823668]\n",
      "epoch:8 step:7890 [D loss: 0.733889, acc.: 53.91%] [G loss: 0.921688]\n",
      "epoch:8 step:7891 [D loss: 0.713155, acc.: 52.34%] [G loss: 0.922243]\n",
      "epoch:8 step:7892 [D loss: 0.621053, acc.: 62.50%] [G loss: 1.030529]\n",
      "epoch:8 step:7893 [D loss: 0.557698, acc.: 77.34%] [G loss: 1.116011]\n",
      "epoch:8 step:7894 [D loss: 0.451226, acc.: 86.72%] [G loss: 1.070146]\n",
      "epoch:8 step:7895 [D loss: 0.605372, acc.: 64.84%] [G loss: 0.909802]\n",
      "epoch:8 step:7896 [D loss: 0.694687, acc.: 50.00%] [G loss: 1.074972]\n",
      "epoch:8 step:7897 [D loss: 0.669080, acc.: 57.81%] [G loss: 0.861027]\n",
      "epoch:8 step:7898 [D loss: 0.555788, acc.: 72.66%] [G loss: 1.023920]\n",
      "epoch:8 step:7899 [D loss: 0.677961, acc.: 53.91%] [G loss: 0.932883]\n",
      "epoch:8 step:7900 [D loss: 0.651412, acc.: 57.03%] [G loss: 1.100501]\n",
      "epoch:8 step:7901 [D loss: 0.597999, acc.: 67.97%] [G loss: 1.070135]\n",
      "epoch:8 step:7902 [D loss: 0.625718, acc.: 64.06%] [G loss: 0.951468]\n",
      "epoch:8 step:7903 [D loss: 0.672487, acc.: 63.28%] [G loss: 0.894822]\n",
      "epoch:8 step:7904 [D loss: 0.616682, acc.: 67.19%] [G loss: 1.023312]\n",
      "epoch:8 step:7905 [D loss: 0.607208, acc.: 67.19%] [G loss: 0.982214]\n",
      "epoch:8 step:7906 [D loss: 0.605031, acc.: 64.06%] [G loss: 1.010403]\n",
      "epoch:8 step:7907 [D loss: 0.602289, acc.: 64.06%] [G loss: 0.952397]\n",
      "epoch:8 step:7908 [D loss: 0.661566, acc.: 61.72%] [G loss: 0.958649]\n",
      "epoch:8 step:7909 [D loss: 0.698108, acc.: 53.12%] [G loss: 0.904321]\n",
      "epoch:8 step:7910 [D loss: 0.672293, acc.: 60.16%] [G loss: 0.988150]\n",
      "epoch:8 step:7911 [D loss: 0.763655, acc.: 44.53%] [G loss: 0.856575]\n",
      "epoch:8 step:7912 [D loss: 0.610696, acc.: 65.62%] [G loss: 1.019488]\n",
      "epoch:8 step:7913 [D loss: 0.599025, acc.: 68.75%] [G loss: 0.860112]\n",
      "epoch:8 step:7914 [D loss: 0.597391, acc.: 67.97%] [G loss: 0.975139]\n",
      "epoch:8 step:7915 [D loss: 0.607078, acc.: 63.28%] [G loss: 1.009010]\n",
      "epoch:8 step:7916 [D loss: 0.594403, acc.: 65.62%] [G loss: 0.904809]\n",
      "epoch:8 step:7917 [D loss: 0.674752, acc.: 59.38%] [G loss: 1.077242]\n",
      "epoch:8 step:7918 [D loss: 0.802651, acc.: 38.28%] [G loss: 0.871794]\n",
      "epoch:8 step:7919 [D loss: 0.712394, acc.: 57.81%] [G loss: 0.955875]\n",
      "epoch:8 step:7920 [D loss: 0.631409, acc.: 63.28%] [G loss: 1.010982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7921 [D loss: 0.632319, acc.: 63.28%] [G loss: 1.095920]\n",
      "epoch:8 step:7922 [D loss: 0.565953, acc.: 72.66%] [G loss: 0.931641]\n",
      "epoch:8 step:7923 [D loss: 0.665677, acc.: 58.59%] [G loss: 0.869310]\n",
      "epoch:8 step:7924 [D loss: 0.611689, acc.: 67.97%] [G loss: 1.008501]\n",
      "epoch:8 step:7925 [D loss: 0.568975, acc.: 75.00%] [G loss: 1.084856]\n",
      "epoch:8 step:7926 [D loss: 0.570302, acc.: 67.97%] [G loss: 1.071615]\n",
      "epoch:8 step:7927 [D loss: 0.679272, acc.: 61.72%] [G loss: 1.009715]\n",
      "epoch:8 step:7928 [D loss: 0.756853, acc.: 46.88%] [G loss: 0.940046]\n",
      "epoch:8 step:7929 [D loss: 0.677712, acc.: 56.25%] [G loss: 0.970001]\n",
      "epoch:8 step:7930 [D loss: 0.662200, acc.: 57.03%] [G loss: 0.945042]\n",
      "epoch:8 step:7931 [D loss: 0.676263, acc.: 62.50%] [G loss: 0.868758]\n",
      "epoch:8 step:7932 [D loss: 0.636685, acc.: 62.50%] [G loss: 1.078139]\n",
      "epoch:8 step:7933 [D loss: 0.695179, acc.: 57.81%] [G loss: 0.902755]\n",
      "epoch:8 step:7934 [D loss: 0.622826, acc.: 64.06%] [G loss: 1.122245]\n",
      "epoch:8 step:7935 [D loss: 0.595032, acc.: 68.75%] [G loss: 0.933622]\n",
      "epoch:8 step:7936 [D loss: 0.649543, acc.: 65.62%] [G loss: 1.093467]\n",
      "epoch:8 step:7937 [D loss: 0.650166, acc.: 62.50%] [G loss: 0.893703]\n",
      "epoch:8 step:7938 [D loss: 0.620735, acc.: 63.28%] [G loss: 0.851508]\n",
      "epoch:8 step:7939 [D loss: 0.648776, acc.: 57.03%] [G loss: 0.939015]\n",
      "epoch:8 step:7940 [D loss: 0.683850, acc.: 59.38%] [G loss: 0.886599]\n",
      "epoch:8 step:7941 [D loss: 0.632071, acc.: 64.84%] [G loss: 0.952753]\n",
      "epoch:8 step:7942 [D loss: 0.680946, acc.: 59.38%] [G loss: 0.836258]\n",
      "epoch:8 step:7943 [D loss: 0.653630, acc.: 60.94%] [G loss: 0.990218]\n",
      "epoch:8 step:7944 [D loss: 0.684034, acc.: 53.91%] [G loss: 0.883279]\n",
      "epoch:8 step:7945 [D loss: 0.715406, acc.: 53.12%] [G loss: 0.979406]\n",
      "epoch:8 step:7946 [D loss: 0.619777, acc.: 65.62%] [G loss: 1.032710]\n",
      "epoch:8 step:7947 [D loss: 0.579404, acc.: 69.53%] [G loss: 1.045162]\n",
      "epoch:8 step:7948 [D loss: 0.616615, acc.: 67.97%] [G loss: 0.957944]\n",
      "epoch:8 step:7949 [D loss: 0.582092, acc.: 64.84%] [G loss: 1.064942]\n",
      "epoch:8 step:7950 [D loss: 0.566262, acc.: 72.66%] [G loss: 1.036894]\n",
      "epoch:8 step:7951 [D loss: 0.581901, acc.: 65.62%] [G loss: 1.054692]\n",
      "epoch:8 step:7952 [D loss: 0.625569, acc.: 65.62%] [G loss: 1.123602]\n",
      "epoch:8 step:7953 [D loss: 0.592232, acc.: 70.31%] [G loss: 1.011955]\n",
      "epoch:8 step:7954 [D loss: 0.788400, acc.: 46.09%] [G loss: 1.008614]\n",
      "epoch:8 step:7955 [D loss: 0.625337, acc.: 61.72%] [G loss: 0.942692]\n",
      "epoch:8 step:7956 [D loss: 0.604888, acc.: 71.09%] [G loss: 0.913042]\n",
      "epoch:8 step:7957 [D loss: 0.771847, acc.: 51.56%] [G loss: 0.951326]\n",
      "epoch:8 step:7958 [D loss: 0.771188, acc.: 50.00%] [G loss: 1.031066]\n",
      "epoch:8 step:7959 [D loss: 0.754110, acc.: 50.00%] [G loss: 0.997818]\n",
      "epoch:8 step:7960 [D loss: 0.611967, acc.: 70.31%] [G loss: 1.039258]\n",
      "epoch:8 step:7961 [D loss: 0.747256, acc.: 53.91%] [G loss: 0.945026]\n",
      "epoch:8 step:7962 [D loss: 0.593226, acc.: 66.41%] [G loss: 0.993734]\n",
      "epoch:8 step:7963 [D loss: 0.622633, acc.: 67.19%] [G loss: 0.917916]\n",
      "epoch:8 step:7964 [D loss: 0.581797, acc.: 74.22%] [G loss: 1.039142]\n",
      "epoch:8 step:7965 [D loss: 0.613183, acc.: 66.41%] [G loss: 0.978809]\n",
      "epoch:8 step:7966 [D loss: 0.543479, acc.: 78.91%] [G loss: 0.889508]\n",
      "epoch:8 step:7967 [D loss: 0.563528, acc.: 69.53%] [G loss: 1.043289]\n",
      "epoch:8 step:7968 [D loss: 0.695877, acc.: 54.69%] [G loss: 0.967427]\n",
      "epoch:8 step:7969 [D loss: 0.766382, acc.: 49.22%] [G loss: 0.941694]\n",
      "epoch:8 step:7970 [D loss: 0.719082, acc.: 54.69%] [G loss: 0.954111]\n",
      "epoch:8 step:7971 [D loss: 0.651627, acc.: 64.06%] [G loss: 1.117972]\n",
      "epoch:8 step:7972 [D loss: 0.653028, acc.: 62.50%] [G loss: 1.089301]\n",
      "epoch:8 step:7973 [D loss: 0.673289, acc.: 61.72%] [G loss: 1.130894]\n",
      "epoch:8 step:7974 [D loss: 0.655230, acc.: 66.41%] [G loss: 1.030906]\n",
      "epoch:8 step:7975 [D loss: 0.666054, acc.: 55.47%] [G loss: 0.996414]\n",
      "epoch:8 step:7976 [D loss: 0.731352, acc.: 53.12%] [G loss: 0.822135]\n",
      "epoch:8 step:7977 [D loss: 0.639673, acc.: 60.94%] [G loss: 0.887131]\n",
      "epoch:8 step:7978 [D loss: 0.727159, acc.: 55.47%] [G loss: 0.955094]\n",
      "epoch:8 step:7979 [D loss: 0.653406, acc.: 56.25%] [G loss: 0.917827]\n",
      "epoch:8 step:7980 [D loss: 0.654367, acc.: 64.84%] [G loss: 1.109018]\n",
      "epoch:8 step:7981 [D loss: 0.685607, acc.: 60.94%] [G loss: 0.920248]\n",
      "epoch:8 step:7982 [D loss: 0.692560, acc.: 58.59%] [G loss: 0.880290]\n",
      "epoch:8 step:7983 [D loss: 0.682341, acc.: 53.91%] [G loss: 1.015010]\n",
      "epoch:8 step:7984 [D loss: 0.625012, acc.: 63.28%] [G loss: 1.003350]\n",
      "epoch:8 step:7985 [D loss: 0.617598, acc.: 66.41%] [G loss: 0.983149]\n",
      "epoch:8 step:7986 [D loss: 0.615395, acc.: 64.84%] [G loss: 1.024446]\n",
      "epoch:8 step:7987 [D loss: 0.640762, acc.: 63.28%] [G loss: 0.932018]\n",
      "epoch:8 step:7988 [D loss: 0.656093, acc.: 62.50%] [G loss: 0.953856]\n",
      "epoch:8 step:7989 [D loss: 0.658116, acc.: 64.06%] [G loss: 0.858734]\n",
      "epoch:8 step:7990 [D loss: 0.699278, acc.: 53.91%] [G loss: 0.925988]\n",
      "epoch:8 step:7991 [D loss: 0.633142, acc.: 64.84%] [G loss: 0.966734]\n",
      "epoch:8 step:7992 [D loss: 0.664275, acc.: 56.25%] [G loss: 0.972642]\n",
      "epoch:8 step:7993 [D loss: 0.636392, acc.: 64.06%] [G loss: 1.037607]\n",
      "epoch:8 step:7994 [D loss: 0.596887, acc.: 66.41%] [G loss: 1.019593]\n",
      "epoch:8 step:7995 [D loss: 0.581007, acc.: 72.66%] [G loss: 0.937350]\n",
      "epoch:8 step:7996 [D loss: 0.660590, acc.: 58.59%] [G loss: 1.131380]\n",
      "epoch:8 step:7997 [D loss: 0.668865, acc.: 57.03%] [G loss: 0.962185]\n",
      "epoch:8 step:7998 [D loss: 0.685464, acc.: 57.81%] [G loss: 0.943125]\n",
      "epoch:8 step:7999 [D loss: 0.611690, acc.: 68.75%] [G loss: 0.944336]\n",
      "epoch:8 step:8000 [D loss: 0.625662, acc.: 65.62%] [G loss: 0.863411]\n",
      "epoch:8 step:8001 [D loss: 0.600691, acc.: 71.09%] [G loss: 0.946516]\n",
      "epoch:8 step:8002 [D loss: 0.730097, acc.: 53.12%] [G loss: 1.022429]\n",
      "epoch:8 step:8003 [D loss: 0.647640, acc.: 61.72%] [G loss: 0.989399]\n",
      "epoch:8 step:8004 [D loss: 0.654022, acc.: 57.03%] [G loss: 0.866046]\n",
      "epoch:8 step:8005 [D loss: 0.681026, acc.: 57.81%] [G loss: 0.909598]\n",
      "epoch:8 step:8006 [D loss: 0.674062, acc.: 57.81%] [G loss: 0.975591]\n",
      "epoch:8 step:8007 [D loss: 0.726302, acc.: 50.00%] [G loss: 1.023408]\n",
      "epoch:8 step:8008 [D loss: 0.657023, acc.: 63.28%] [G loss: 0.905823]\n",
      "epoch:8 step:8009 [D loss: 0.652577, acc.: 62.50%] [G loss: 0.978059]\n",
      "epoch:8 step:8010 [D loss: 0.698176, acc.: 53.91%] [G loss: 0.903916]\n",
      "epoch:8 step:8011 [D loss: 0.682642, acc.: 57.81%] [G loss: 0.876872]\n",
      "epoch:8 step:8012 [D loss: 0.571021, acc.: 70.31%] [G loss: 1.038163]\n",
      "epoch:8 step:8013 [D loss: 0.710552, acc.: 52.34%] [G loss: 0.890727]\n",
      "epoch:8 step:8014 [D loss: 0.692106, acc.: 56.25%] [G loss: 1.088505]\n",
      "epoch:8 step:8015 [D loss: 0.608084, acc.: 67.19%] [G loss: 0.894548]\n",
      "epoch:8 step:8016 [D loss: 0.743345, acc.: 50.00%] [G loss: 0.931476]\n",
      "epoch:8 step:8017 [D loss: 0.619911, acc.: 67.97%] [G loss: 0.875767]\n",
      "epoch:8 step:8018 [D loss: 0.609026, acc.: 66.41%] [G loss: 1.043277]\n",
      "epoch:8 step:8019 [D loss: 0.645891, acc.: 66.41%] [G loss: 0.955383]\n",
      "epoch:8 step:8020 [D loss: 0.710684, acc.: 58.59%] [G loss: 0.972825]\n",
      "epoch:8 step:8021 [D loss: 0.709613, acc.: 50.00%] [G loss: 0.870999]\n",
      "epoch:8 step:8022 [D loss: 0.711236, acc.: 50.78%] [G loss: 1.032539]\n",
      "epoch:8 step:8023 [D loss: 0.729809, acc.: 56.25%] [G loss: 0.935080]\n",
      "epoch:8 step:8024 [D loss: 0.717586, acc.: 55.47%] [G loss: 0.910301]\n",
      "epoch:8 step:8025 [D loss: 0.711933, acc.: 57.81%] [G loss: 0.845993]\n",
      "epoch:8 step:8026 [D loss: 0.721426, acc.: 50.78%] [G loss: 0.898674]\n",
      "epoch:8 step:8027 [D loss: 0.725408, acc.: 48.44%] [G loss: 0.905682]\n",
      "epoch:8 step:8028 [D loss: 0.643364, acc.: 64.84%] [G loss: 0.984650]\n",
      "epoch:8 step:8029 [D loss: 0.689553, acc.: 56.25%] [G loss: 0.855541]\n",
      "epoch:8 step:8030 [D loss: 0.671797, acc.: 57.03%] [G loss: 0.837048]\n",
      "epoch:8 step:8031 [D loss: 0.614969, acc.: 63.28%] [G loss: 1.070161]\n",
      "epoch:8 step:8032 [D loss: 0.600232, acc.: 64.84%] [G loss: 0.968137]\n",
      "epoch:8 step:8033 [D loss: 0.643112, acc.: 64.06%] [G loss: 1.094105]\n",
      "epoch:8 step:8034 [D loss: 0.626984, acc.: 63.28%] [G loss: 1.000021]\n",
      "epoch:8 step:8035 [D loss: 0.687838, acc.: 55.47%] [G loss: 0.952634]\n",
      "epoch:8 step:8036 [D loss: 0.687466, acc.: 54.69%] [G loss: 0.864527]\n",
      "epoch:8 step:8037 [D loss: 0.665296, acc.: 58.59%] [G loss: 0.878262]\n",
      "epoch:8 step:8038 [D loss: 0.661266, acc.: 60.94%] [G loss: 0.916215]\n",
      "epoch:8 step:8039 [D loss: 0.653561, acc.: 61.72%] [G loss: 0.876972]\n",
      "epoch:8 step:8040 [D loss: 0.703916, acc.: 55.47%] [G loss: 0.793043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8041 [D loss: 0.638055, acc.: 64.06%] [G loss: 0.828719]\n",
      "epoch:8 step:8042 [D loss: 0.682281, acc.: 48.44%] [G loss: 0.950467]\n",
      "epoch:8 step:8043 [D loss: 0.607779, acc.: 69.53%] [G loss: 0.935929]\n",
      "epoch:8 step:8044 [D loss: 0.622153, acc.: 66.41%] [G loss: 0.996557]\n",
      "epoch:8 step:8045 [D loss: 0.633362, acc.: 65.62%] [G loss: 0.941981]\n",
      "epoch:8 step:8046 [D loss: 0.584712, acc.: 67.19%] [G loss: 1.094901]\n",
      "epoch:8 step:8047 [D loss: 0.539701, acc.: 74.22%] [G loss: 0.969157]\n",
      "epoch:8 step:8048 [D loss: 0.555378, acc.: 68.75%] [G loss: 0.927028]\n",
      "epoch:8 step:8049 [D loss: 0.619752, acc.: 66.41%] [G loss: 1.080703]\n",
      "epoch:8 step:8050 [D loss: 0.600798, acc.: 65.62%] [G loss: 0.940681]\n",
      "epoch:8 step:8051 [D loss: 0.537569, acc.: 81.25%] [G loss: 1.066082]\n",
      "epoch:8 step:8052 [D loss: 0.569879, acc.: 75.00%] [G loss: 1.035386]\n",
      "epoch:8 step:8053 [D loss: 0.576325, acc.: 71.88%] [G loss: 1.032282]\n",
      "epoch:8 step:8054 [D loss: 0.603772, acc.: 69.53%] [G loss: 1.019257]\n",
      "epoch:8 step:8055 [D loss: 0.790576, acc.: 49.22%] [G loss: 0.999964]\n",
      "epoch:8 step:8056 [D loss: 0.772058, acc.: 49.22%] [G loss: 0.909045]\n",
      "epoch:8 step:8057 [D loss: 0.647920, acc.: 64.06%] [G loss: 1.098773]\n",
      "epoch:8 step:8058 [D loss: 0.726604, acc.: 55.47%] [G loss: 0.978266]\n",
      "epoch:8 step:8059 [D loss: 0.649123, acc.: 62.50%] [G loss: 0.988313]\n",
      "epoch:8 step:8060 [D loss: 0.616685, acc.: 66.41%] [G loss: 0.988654]\n",
      "epoch:8 step:8061 [D loss: 0.701915, acc.: 57.81%] [G loss: 0.829543]\n",
      "epoch:8 step:8062 [D loss: 0.724233, acc.: 46.09%] [G loss: 1.006530]\n",
      "epoch:8 step:8063 [D loss: 0.713633, acc.: 53.12%] [G loss: 0.935110]\n",
      "epoch:8 step:8064 [D loss: 0.577817, acc.: 67.19%] [G loss: 1.051272]\n",
      "epoch:8 step:8065 [D loss: 0.705572, acc.: 55.47%] [G loss: 0.879408]\n",
      "epoch:8 step:8066 [D loss: 0.642928, acc.: 61.72%] [G loss: 0.978061]\n",
      "epoch:8 step:8067 [D loss: 0.642359, acc.: 63.28%] [G loss: 0.975354]\n",
      "epoch:8 step:8068 [D loss: 0.753243, acc.: 46.88%] [G loss: 0.909435]\n",
      "epoch:8 step:8069 [D loss: 0.661361, acc.: 58.59%] [G loss: 0.773227]\n",
      "epoch:8 step:8070 [D loss: 0.642922, acc.: 61.72%] [G loss: 0.853222]\n",
      "epoch:8 step:8071 [D loss: 0.582211, acc.: 71.88%] [G loss: 1.119960]\n",
      "epoch:8 step:8072 [D loss: 0.662004, acc.: 57.81%] [G loss: 0.949649]\n",
      "epoch:8 step:8073 [D loss: 0.617546, acc.: 67.19%] [G loss: 0.939263]\n",
      "epoch:8 step:8074 [D loss: 0.709806, acc.: 55.47%] [G loss: 0.953114]\n",
      "epoch:8 step:8075 [D loss: 0.718754, acc.: 57.03%] [G loss: 0.860391]\n",
      "epoch:8 step:8076 [D loss: 0.658277, acc.: 63.28%] [G loss: 0.985093]\n",
      "epoch:8 step:8077 [D loss: 0.707216, acc.: 57.03%] [G loss: 0.840821]\n",
      "epoch:8 step:8078 [D loss: 0.715003, acc.: 48.44%] [G loss: 0.805017]\n",
      "epoch:8 step:8079 [D loss: 0.729763, acc.: 44.53%] [G loss: 0.982773]\n",
      "epoch:8 step:8080 [D loss: 0.697753, acc.: 56.25%] [G loss: 1.073643]\n",
      "epoch:8 step:8081 [D loss: 0.670702, acc.: 60.16%] [G loss: 0.922202]\n",
      "epoch:8 step:8082 [D loss: 0.635900, acc.: 62.50%] [G loss: 1.018416]\n",
      "epoch:8 step:8083 [D loss: 0.570478, acc.: 70.31%] [G loss: 1.013070]\n",
      "epoch:8 step:8084 [D loss: 0.601356, acc.: 65.62%] [G loss: 0.995707]\n",
      "epoch:8 step:8085 [D loss: 0.568683, acc.: 67.97%] [G loss: 1.139337]\n",
      "epoch:8 step:8086 [D loss: 0.646336, acc.: 60.94%] [G loss: 1.093909]\n",
      "epoch:8 step:8087 [D loss: 0.737894, acc.: 48.44%] [G loss: 0.943679]\n",
      "epoch:8 step:8088 [D loss: 0.628823, acc.: 64.84%] [G loss: 1.063714]\n",
      "epoch:8 step:8089 [D loss: 0.683723, acc.: 61.72%] [G loss: 0.959135]\n",
      "epoch:8 step:8090 [D loss: 0.654132, acc.: 59.38%] [G loss: 0.900960]\n",
      "epoch:8 step:8091 [D loss: 0.658091, acc.: 59.38%] [G loss: 1.078924]\n",
      "epoch:8 step:8092 [D loss: 0.671773, acc.: 61.72%] [G loss: 1.007820]\n",
      "epoch:8 step:8093 [D loss: 0.646351, acc.: 61.72%] [G loss: 1.121004]\n",
      "epoch:8 step:8094 [D loss: 0.607634, acc.: 63.28%] [G loss: 0.999553]\n",
      "epoch:8 step:8095 [D loss: 0.678144, acc.: 60.16%] [G loss: 0.930042]\n",
      "epoch:8 step:8096 [D loss: 0.676034, acc.: 59.38%] [G loss: 1.066048]\n",
      "epoch:8 step:8097 [D loss: 0.691921, acc.: 57.03%] [G loss: 0.973940]\n",
      "epoch:8 step:8098 [D loss: 0.620096, acc.: 67.97%] [G loss: 0.991715]\n",
      "epoch:8 step:8099 [D loss: 0.662665, acc.: 61.72%] [G loss: 0.955285]\n",
      "epoch:8 step:8100 [D loss: 0.658783, acc.: 60.16%] [G loss: 1.008011]\n",
      "epoch:8 step:8101 [D loss: 0.620652, acc.: 64.06%] [G loss: 1.085900]\n",
      "epoch:8 step:8102 [D loss: 0.649003, acc.: 66.41%] [G loss: 0.931789]\n",
      "epoch:8 step:8103 [D loss: 0.665530, acc.: 58.59%] [G loss: 0.917270]\n",
      "epoch:8 step:8104 [D loss: 0.641649, acc.: 65.62%] [G loss: 1.033522]\n",
      "epoch:8 step:8105 [D loss: 0.658496, acc.: 60.94%] [G loss: 0.836041]\n",
      "epoch:8 step:8106 [D loss: 0.667378, acc.: 64.84%] [G loss: 1.013777]\n",
      "epoch:8 step:8107 [D loss: 0.602906, acc.: 73.44%] [G loss: 0.993364]\n",
      "epoch:8 step:8108 [D loss: 0.616265, acc.: 63.28%] [G loss: 0.925939]\n",
      "epoch:8 step:8109 [D loss: 0.635015, acc.: 61.72%] [G loss: 0.975629]\n",
      "epoch:8 step:8110 [D loss: 0.669527, acc.: 58.59%] [G loss: 1.007399]\n",
      "epoch:8 step:8111 [D loss: 0.699465, acc.: 57.81%] [G loss: 0.882494]\n",
      "epoch:8 step:8112 [D loss: 0.698042, acc.: 56.25%] [G loss: 1.124887]\n",
      "epoch:8 step:8113 [D loss: 0.679381, acc.: 56.25%] [G loss: 0.832876]\n",
      "epoch:8 step:8114 [D loss: 0.714838, acc.: 55.47%] [G loss: 0.940045]\n",
      "epoch:8 step:8115 [D loss: 0.670304, acc.: 63.28%] [G loss: 0.965997]\n",
      "epoch:8 step:8116 [D loss: 0.696982, acc.: 54.69%] [G loss: 0.864235]\n",
      "epoch:8 step:8117 [D loss: 0.712237, acc.: 52.34%] [G loss: 0.887739]\n",
      "epoch:8 step:8118 [D loss: 0.756818, acc.: 49.22%] [G loss: 0.916135]\n",
      "epoch:8 step:8119 [D loss: 0.726456, acc.: 48.44%] [G loss: 0.962658]\n",
      "epoch:8 step:8120 [D loss: 0.613869, acc.: 67.97%] [G loss: 1.078670]\n",
      "epoch:8 step:8121 [D loss: 0.657415, acc.: 63.28%] [G loss: 1.094942]\n",
      "epoch:8 step:8122 [D loss: 0.680404, acc.: 55.47%] [G loss: 0.905173]\n",
      "epoch:8 step:8123 [D loss: 0.655336, acc.: 63.28%] [G loss: 0.770282]\n",
      "epoch:8 step:8124 [D loss: 0.668663, acc.: 63.28%] [G loss: 0.920012]\n",
      "epoch:8 step:8125 [D loss: 0.640065, acc.: 64.84%] [G loss: 0.921425]\n",
      "epoch:8 step:8126 [D loss: 0.594819, acc.: 67.19%] [G loss: 0.879706]\n",
      "epoch:8 step:8127 [D loss: 0.652400, acc.: 60.94%] [G loss: 1.046318]\n",
      "epoch:8 step:8128 [D loss: 0.631304, acc.: 63.28%] [G loss: 0.977249]\n",
      "epoch:8 step:8129 [D loss: 0.627754, acc.: 68.75%] [G loss: 0.952726]\n",
      "epoch:8 step:8130 [D loss: 0.656142, acc.: 59.38%] [G loss: 0.851716]\n",
      "epoch:8 step:8131 [D loss: 0.649019, acc.: 60.16%] [G loss: 1.024420]\n",
      "epoch:8 step:8132 [D loss: 0.657642, acc.: 52.34%] [G loss: 0.934747]\n",
      "epoch:8 step:8133 [D loss: 0.616365, acc.: 64.84%] [G loss: 0.924873]\n",
      "epoch:8 step:8134 [D loss: 0.662212, acc.: 57.81%] [G loss: 0.922238]\n",
      "epoch:8 step:8135 [D loss: 0.659720, acc.: 58.59%] [G loss: 0.980144]\n",
      "epoch:8 step:8136 [D loss: 0.711777, acc.: 55.47%] [G loss: 0.986018]\n",
      "epoch:8 step:8137 [D loss: 0.674359, acc.: 63.28%] [G loss: 1.075695]\n",
      "epoch:8 step:8138 [D loss: 0.604473, acc.: 65.62%] [G loss: 1.048971]\n",
      "epoch:8 step:8139 [D loss: 0.650436, acc.: 64.84%] [G loss: 0.886601]\n",
      "epoch:8 step:8140 [D loss: 0.595219, acc.: 72.66%] [G loss: 1.073286]\n",
      "epoch:8 step:8141 [D loss: 0.598839, acc.: 71.88%] [G loss: 1.040958]\n",
      "epoch:8 step:8142 [D loss: 0.587778, acc.: 75.78%] [G loss: 1.014020]\n",
      "epoch:8 step:8143 [D loss: 0.619175, acc.: 67.19%] [G loss: 1.012418]\n",
      "epoch:8 step:8144 [D loss: 0.607246, acc.: 65.62%] [G loss: 1.034060]\n",
      "epoch:8 step:8145 [D loss: 0.581445, acc.: 70.31%] [G loss: 0.946282]\n",
      "epoch:8 step:8146 [D loss: 0.599824, acc.: 69.53%] [G loss: 1.078708]\n",
      "epoch:8 step:8147 [D loss: 0.635256, acc.: 67.19%] [G loss: 0.868922]\n",
      "epoch:8 step:8148 [D loss: 0.690564, acc.: 54.69%] [G loss: 0.959900]\n",
      "epoch:8 step:8149 [D loss: 0.701347, acc.: 57.03%] [G loss: 0.872689]\n",
      "epoch:8 step:8150 [D loss: 0.668267, acc.: 61.72%] [G loss: 1.010984]\n",
      "epoch:8 step:8151 [D loss: 0.666367, acc.: 60.16%] [G loss: 0.877617]\n",
      "epoch:8 step:8152 [D loss: 0.702523, acc.: 53.12%] [G loss: 0.940645]\n",
      "epoch:8 step:8153 [D loss: 0.691422, acc.: 60.94%] [G loss: 0.897231]\n",
      "epoch:8 step:8154 [D loss: 0.716689, acc.: 53.91%] [G loss: 0.860430]\n",
      "epoch:8 step:8155 [D loss: 0.605130, acc.: 68.75%] [G loss: 1.037642]\n",
      "epoch:8 step:8156 [D loss: 0.586228, acc.: 73.44%] [G loss: 0.883899]\n",
      "epoch:8 step:8157 [D loss: 0.651610, acc.: 60.94%] [G loss: 1.108647]\n",
      "epoch:8 step:8158 [D loss: 0.622372, acc.: 69.53%] [G loss: 1.020530]\n",
      "epoch:8 step:8159 [D loss: 0.644110, acc.: 58.59%] [G loss: 0.972237]\n",
      "epoch:8 step:8160 [D loss: 0.737390, acc.: 50.00%] [G loss: 0.898394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8161 [D loss: 0.628763, acc.: 66.41%] [G loss: 0.922289]\n",
      "epoch:8 step:8162 [D loss: 0.605681, acc.: 65.62%] [G loss: 0.896798]\n",
      "epoch:8 step:8163 [D loss: 0.674393, acc.: 56.25%] [G loss: 1.025493]\n",
      "epoch:8 step:8164 [D loss: 0.626525, acc.: 63.28%] [G loss: 0.953053]\n",
      "epoch:8 step:8165 [D loss: 0.709490, acc.: 53.91%] [G loss: 0.890779]\n",
      "epoch:8 step:8166 [D loss: 0.675890, acc.: 55.47%] [G loss: 1.019062]\n",
      "epoch:8 step:8167 [D loss: 0.666302, acc.: 61.72%] [G loss: 1.005988]\n",
      "epoch:8 step:8168 [D loss: 0.657330, acc.: 62.50%] [G loss: 1.108896]\n",
      "epoch:8 step:8169 [D loss: 0.722846, acc.: 60.94%] [G loss: 1.003893]\n",
      "epoch:8 step:8170 [D loss: 0.616155, acc.: 64.84%] [G loss: 0.979268]\n",
      "epoch:8 step:8171 [D loss: 0.740708, acc.: 50.00%] [G loss: 0.944319]\n",
      "epoch:8 step:8172 [D loss: 0.619827, acc.: 65.62%] [G loss: 0.917956]\n",
      "epoch:8 step:8173 [D loss: 0.654619, acc.: 60.16%] [G loss: 0.891036]\n",
      "epoch:8 step:8174 [D loss: 0.598694, acc.: 65.62%] [G loss: 0.991253]\n",
      "epoch:8 step:8175 [D loss: 0.684182, acc.: 58.59%] [G loss: 1.021508]\n",
      "epoch:8 step:8176 [D loss: 0.644740, acc.: 64.06%] [G loss: 0.963567]\n",
      "epoch:8 step:8177 [D loss: 0.677559, acc.: 55.47%] [G loss: 0.841329]\n",
      "epoch:8 step:8178 [D loss: 0.674939, acc.: 60.94%] [G loss: 0.869821]\n",
      "epoch:8 step:8179 [D loss: 0.632351, acc.: 64.84%] [G loss: 0.920744]\n",
      "epoch:8 step:8180 [D loss: 0.704177, acc.: 60.16%] [G loss: 0.916391]\n",
      "epoch:8 step:8181 [D loss: 0.575180, acc.: 71.09%] [G loss: 0.851308]\n",
      "epoch:8 step:8182 [D loss: 0.653305, acc.: 56.25%] [G loss: 0.916466]\n",
      "epoch:8 step:8183 [D loss: 0.668318, acc.: 56.25%] [G loss: 0.886339]\n",
      "epoch:8 step:8184 [D loss: 0.669691, acc.: 58.59%] [G loss: 0.991952]\n",
      "epoch:8 step:8185 [D loss: 0.618273, acc.: 64.06%] [G loss: 1.001804]\n",
      "epoch:8 step:8186 [D loss: 0.652292, acc.: 64.84%] [G loss: 1.007688]\n",
      "epoch:8 step:8187 [D loss: 0.637215, acc.: 61.72%] [G loss: 0.912820]\n",
      "epoch:8 step:8188 [D loss: 0.661172, acc.: 52.34%] [G loss: 0.900381]\n",
      "epoch:8 step:8189 [D loss: 0.639630, acc.: 62.50%] [G loss: 0.968036]\n",
      "epoch:8 step:8190 [D loss: 0.598386, acc.: 71.09%] [G loss: 1.082812]\n",
      "epoch:8 step:8191 [D loss: 0.676815, acc.: 57.03%] [G loss: 0.918675]\n",
      "epoch:8 step:8192 [D loss: 0.583627, acc.: 71.88%] [G loss: 0.933967]\n",
      "epoch:8 step:8193 [D loss: 0.690234, acc.: 56.25%] [G loss: 0.878392]\n",
      "epoch:8 step:8194 [D loss: 0.713367, acc.: 53.91%] [G loss: 0.918464]\n",
      "epoch:8 step:8195 [D loss: 0.654519, acc.: 60.94%] [G loss: 0.937255]\n",
      "epoch:8 step:8196 [D loss: 0.617443, acc.: 67.97%] [G loss: 0.984493]\n",
      "epoch:8 step:8197 [D loss: 0.609162, acc.: 64.06%] [G loss: 0.999537]\n",
      "epoch:8 step:8198 [D loss: 0.669595, acc.: 58.59%] [G loss: 0.969934]\n",
      "epoch:8 step:8199 [D loss: 0.687953, acc.: 57.03%] [G loss: 0.921304]\n",
      "epoch:8 step:8200 [D loss: 0.599395, acc.: 67.19%] [G loss: 0.996126]\n",
      "epoch:8 step:8201 [D loss: 0.634932, acc.: 58.59%] [G loss: 0.838313]\n",
      "epoch:8 step:8202 [D loss: 0.587802, acc.: 70.31%] [G loss: 0.897332]\n",
      "epoch:8 step:8203 [D loss: 0.640410, acc.: 62.50%] [G loss: 0.814626]\n",
      "epoch:8 step:8204 [D loss: 0.555578, acc.: 75.00%] [G loss: 1.014580]\n",
      "epoch:8 step:8205 [D loss: 0.584914, acc.: 72.66%] [G loss: 1.152456]\n",
      "epoch:8 step:8206 [D loss: 0.705416, acc.: 56.25%] [G loss: 1.006436]\n",
      "epoch:8 step:8207 [D loss: 0.800512, acc.: 42.19%] [G loss: 0.963526]\n",
      "epoch:8 step:8208 [D loss: 0.690178, acc.: 54.69%] [G loss: 0.928910]\n",
      "epoch:8 step:8209 [D loss: 0.590968, acc.: 63.28%] [G loss: 1.034848]\n",
      "epoch:8 step:8210 [D loss: 0.639689, acc.: 62.50%] [G loss: 0.991542]\n",
      "epoch:8 step:8211 [D loss: 0.656554, acc.: 54.69%] [G loss: 1.020876]\n",
      "epoch:8 step:8212 [D loss: 0.814624, acc.: 39.84%] [G loss: 0.922420]\n",
      "epoch:8 step:8213 [D loss: 0.647038, acc.: 63.28%] [G loss: 0.973952]\n",
      "epoch:8 step:8214 [D loss: 0.713566, acc.: 55.47%] [G loss: 0.867470]\n",
      "epoch:8 step:8215 [D loss: 0.758302, acc.: 51.56%] [G loss: 0.834205]\n",
      "epoch:8 step:8216 [D loss: 0.666448, acc.: 60.16%] [G loss: 0.934209]\n",
      "epoch:8 step:8217 [D loss: 0.641944, acc.: 64.06%] [G loss: 0.966888]\n",
      "epoch:8 step:8218 [D loss: 0.686979, acc.: 53.91%] [G loss: 0.900585]\n",
      "epoch:8 step:8219 [D loss: 0.644518, acc.: 58.59%] [G loss: 0.876100]\n",
      "epoch:8 step:8220 [D loss: 0.547910, acc.: 76.56%] [G loss: 0.953604]\n",
      "epoch:8 step:8221 [D loss: 0.592843, acc.: 69.53%] [G loss: 0.861351]\n",
      "epoch:8 step:8222 [D loss: 0.662404, acc.: 54.69%] [G loss: 0.978114]\n",
      "epoch:8 step:8223 [D loss: 0.733226, acc.: 48.44%] [G loss: 0.850508]\n",
      "epoch:8 step:8224 [D loss: 0.656172, acc.: 60.16%] [G loss: 0.909205]\n",
      "epoch:8 step:8225 [D loss: 0.633243, acc.: 64.84%] [G loss: 0.981443]\n",
      "epoch:8 step:8226 [D loss: 0.659738, acc.: 60.94%] [G loss: 1.055765]\n",
      "epoch:8 step:8227 [D loss: 0.602456, acc.: 64.84%] [G loss: 0.942781]\n",
      "epoch:8 step:8228 [D loss: 0.630570, acc.: 61.72%] [G loss: 0.932061]\n",
      "epoch:8 step:8229 [D loss: 0.550931, acc.: 75.78%] [G loss: 0.917369]\n",
      "epoch:8 step:8230 [D loss: 0.592451, acc.: 70.31%] [G loss: 0.991821]\n",
      "epoch:8 step:8231 [D loss: 0.721111, acc.: 54.69%] [G loss: 1.002869]\n",
      "epoch:8 step:8232 [D loss: 0.638709, acc.: 62.50%] [G loss: 0.971642]\n",
      "epoch:8 step:8233 [D loss: 0.673941, acc.: 60.16%] [G loss: 0.894560]\n",
      "epoch:8 step:8234 [D loss: 0.718976, acc.: 51.56%] [G loss: 0.919583]\n",
      "epoch:8 step:8235 [D loss: 0.692405, acc.: 59.38%] [G loss: 1.113971]\n",
      "epoch:8 step:8236 [D loss: 0.705480, acc.: 54.69%] [G loss: 0.901893]\n",
      "epoch:8 step:8237 [D loss: 0.708587, acc.: 55.47%] [G loss: 0.932970]\n",
      "epoch:8 step:8238 [D loss: 0.840409, acc.: 39.84%] [G loss: 0.935975]\n",
      "epoch:8 step:8239 [D loss: 0.719814, acc.: 52.34%] [G loss: 0.855299]\n",
      "epoch:8 step:8240 [D loss: 0.731357, acc.: 53.12%] [G loss: 0.948757]\n",
      "epoch:8 step:8241 [D loss: 0.573536, acc.: 74.22%] [G loss: 1.158930]\n",
      "epoch:8 step:8242 [D loss: 0.652438, acc.: 62.50%] [G loss: 1.023584]\n",
      "epoch:8 step:8243 [D loss: 0.582113, acc.: 71.09%] [G loss: 1.103371]\n",
      "epoch:8 step:8244 [D loss: 0.616299, acc.: 66.41%] [G loss: 0.983827]\n",
      "epoch:8 step:8245 [D loss: 0.659240, acc.: 57.03%] [G loss: 0.970711]\n",
      "epoch:8 step:8246 [D loss: 0.619190, acc.: 65.62%] [G loss: 1.032921]\n",
      "epoch:8 step:8247 [D loss: 0.677606, acc.: 53.91%] [G loss: 0.999513]\n",
      "epoch:8 step:8248 [D loss: 0.702803, acc.: 57.03%] [G loss: 0.913889]\n",
      "epoch:8 step:8249 [D loss: 0.639975, acc.: 64.06%] [G loss: 0.941643]\n",
      "epoch:8 step:8250 [D loss: 0.593428, acc.: 67.97%] [G loss: 1.075897]\n",
      "epoch:8 step:8251 [D loss: 0.632282, acc.: 64.84%] [G loss: 0.929285]\n",
      "epoch:8 step:8252 [D loss: 0.673068, acc.: 61.72%] [G loss: 0.945857]\n",
      "epoch:8 step:8253 [D loss: 0.631503, acc.: 64.84%] [G loss: 0.979487]\n",
      "epoch:8 step:8254 [D loss: 0.664817, acc.: 57.03%] [G loss: 0.938808]\n",
      "epoch:8 step:8255 [D loss: 0.651040, acc.: 57.03%] [G loss: 1.001404]\n",
      "epoch:8 step:8256 [D loss: 0.663538, acc.: 57.03%] [G loss: 1.016439]\n",
      "epoch:8 step:8257 [D loss: 0.629380, acc.: 67.19%] [G loss: 1.050543]\n",
      "epoch:8 step:8258 [D loss: 0.676615, acc.: 54.69%] [G loss: 0.926705]\n",
      "epoch:8 step:8259 [D loss: 0.652652, acc.: 60.16%] [G loss: 0.893559]\n",
      "epoch:8 step:8260 [D loss: 0.610389, acc.: 67.97%] [G loss: 1.041424]\n",
      "epoch:8 step:8261 [D loss: 0.652903, acc.: 59.38%] [G loss: 0.861347]\n",
      "epoch:8 step:8262 [D loss: 0.667679, acc.: 60.94%] [G loss: 1.014358]\n",
      "epoch:8 step:8263 [D loss: 0.736794, acc.: 53.12%] [G loss: 0.872037]\n",
      "epoch:8 step:8264 [D loss: 0.666613, acc.: 57.81%] [G loss: 0.935114]\n",
      "epoch:8 step:8265 [D loss: 0.644125, acc.: 62.50%] [G loss: 0.785863]\n",
      "epoch:8 step:8266 [D loss: 0.660575, acc.: 62.50%] [G loss: 1.024907]\n",
      "epoch:8 step:8267 [D loss: 0.699665, acc.: 53.91%] [G loss: 0.989839]\n",
      "epoch:8 step:8268 [D loss: 0.721808, acc.: 53.12%] [G loss: 0.978056]\n",
      "epoch:8 step:8269 [D loss: 0.692790, acc.: 56.25%] [G loss: 0.949714]\n",
      "epoch:8 step:8270 [D loss: 0.580712, acc.: 78.91%] [G loss: 0.911669]\n",
      "epoch:8 step:8271 [D loss: 0.562869, acc.: 72.66%] [G loss: 0.930752]\n",
      "epoch:8 step:8272 [D loss: 0.598282, acc.: 67.97%] [G loss: 0.990261]\n",
      "epoch:8 step:8273 [D loss: 0.621083, acc.: 67.19%] [G loss: 0.908037]\n",
      "epoch:8 step:8274 [D loss: 0.680512, acc.: 58.59%] [G loss: 1.041722]\n",
      "epoch:8 step:8275 [D loss: 0.784823, acc.: 37.50%] [G loss: 0.799253]\n",
      "epoch:8 step:8276 [D loss: 0.729168, acc.: 46.09%] [G loss: 0.896332]\n",
      "epoch:8 step:8277 [D loss: 0.668828, acc.: 53.12%] [G loss: 0.989496]\n",
      "epoch:8 step:8278 [D loss: 0.574584, acc.: 72.66%] [G loss: 0.854435]\n",
      "epoch:8 step:8279 [D loss: 0.684845, acc.: 55.47%] [G loss: 0.946068]\n",
      "epoch:8 step:8280 [D loss: 0.710379, acc.: 59.38%] [G loss: 0.918714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8281 [D loss: 0.641288, acc.: 57.81%] [G loss: 0.908305]\n",
      "epoch:8 step:8282 [D loss: 0.623466, acc.: 67.19%] [G loss: 1.033043]\n",
      "epoch:8 step:8283 [D loss: 0.658443, acc.: 61.72%] [G loss: 0.963665]\n",
      "epoch:8 step:8284 [D loss: 0.697359, acc.: 54.69%] [G loss: 0.966054]\n",
      "epoch:8 step:8285 [D loss: 0.669976, acc.: 58.59%] [G loss: 0.992001]\n",
      "epoch:8 step:8286 [D loss: 0.599755, acc.: 69.53%] [G loss: 0.946638]\n",
      "epoch:8 step:8287 [D loss: 0.568540, acc.: 72.66%] [G loss: 1.187463]\n",
      "epoch:8 step:8288 [D loss: 0.558200, acc.: 75.00%] [G loss: 1.013365]\n",
      "epoch:8 step:8289 [D loss: 0.615085, acc.: 67.19%] [G loss: 1.156174]\n",
      "epoch:8 step:8290 [D loss: 0.596873, acc.: 67.19%] [G loss: 1.134379]\n",
      "epoch:8 step:8291 [D loss: 0.671490, acc.: 57.03%] [G loss: 1.082885]\n",
      "epoch:8 step:8292 [D loss: 0.677593, acc.: 59.38%] [G loss: 0.887164]\n",
      "epoch:8 step:8293 [D loss: 0.694721, acc.: 57.03%] [G loss: 1.039196]\n",
      "epoch:8 step:8294 [D loss: 0.650973, acc.: 65.62%] [G loss: 0.927012]\n",
      "epoch:8 step:8295 [D loss: 0.693710, acc.: 57.81%] [G loss: 0.971741]\n",
      "epoch:8 step:8296 [D loss: 0.756680, acc.: 48.44%] [G loss: 0.890667]\n",
      "epoch:8 step:8297 [D loss: 0.704772, acc.: 50.78%] [G loss: 0.887021]\n",
      "epoch:8 step:8298 [D loss: 0.727711, acc.: 54.69%] [G loss: 1.021952]\n",
      "epoch:8 step:8299 [D loss: 0.637194, acc.: 60.16%] [G loss: 1.050330]\n",
      "epoch:8 step:8300 [D loss: 0.648473, acc.: 57.81%] [G loss: 0.946854]\n",
      "epoch:8 step:8301 [D loss: 0.617032, acc.: 65.62%] [G loss: 0.988523]\n",
      "epoch:8 step:8302 [D loss: 0.600408, acc.: 64.84%] [G loss: 0.948415]\n",
      "epoch:8 step:8303 [D loss: 0.653273, acc.: 57.03%] [G loss: 1.118217]\n",
      "epoch:8 step:8304 [D loss: 0.657277, acc.: 59.38%] [G loss: 1.083617]\n",
      "epoch:8 step:8305 [D loss: 0.686796, acc.: 60.16%] [G loss: 0.986895]\n",
      "epoch:8 step:8306 [D loss: 0.635516, acc.: 63.28%] [G loss: 1.115151]\n",
      "epoch:8 step:8307 [D loss: 0.715293, acc.: 53.91%] [G loss: 0.866112]\n",
      "epoch:8 step:8308 [D loss: 0.789671, acc.: 42.97%] [G loss: 0.906271]\n",
      "epoch:8 step:8309 [D loss: 0.669576, acc.: 55.47%] [G loss: 0.941540]\n",
      "epoch:8 step:8310 [D loss: 0.682811, acc.: 57.03%] [G loss: 0.836729]\n",
      "epoch:8 step:8311 [D loss: 0.581396, acc.: 69.53%] [G loss: 0.998353]\n",
      "epoch:8 step:8312 [D loss: 0.713806, acc.: 52.34%] [G loss: 0.901421]\n",
      "epoch:8 step:8313 [D loss: 0.648074, acc.: 62.50%] [G loss: 1.010435]\n",
      "epoch:8 step:8314 [D loss: 0.633501, acc.: 60.16%] [G loss: 0.885136]\n",
      "epoch:8 step:8315 [D loss: 0.650557, acc.: 59.38%] [G loss: 0.904261]\n",
      "epoch:8 step:8316 [D loss: 0.752339, acc.: 50.78%] [G loss: 0.804575]\n",
      "epoch:8 step:8317 [D loss: 0.695911, acc.: 57.03%] [G loss: 0.887384]\n",
      "epoch:8 step:8318 [D loss: 0.669207, acc.: 57.81%] [G loss: 1.082854]\n",
      "epoch:8 step:8319 [D loss: 0.621170, acc.: 65.62%] [G loss: 0.944492]\n",
      "epoch:8 step:8320 [D loss: 0.696404, acc.: 56.25%] [G loss: 0.856279]\n",
      "epoch:8 step:8321 [D loss: 0.605812, acc.: 66.41%] [G loss: 1.010612]\n",
      "epoch:8 step:8322 [D loss: 0.643887, acc.: 61.72%] [G loss: 0.949513]\n",
      "epoch:8 step:8323 [D loss: 0.709821, acc.: 50.78%] [G loss: 0.827666]\n",
      "epoch:8 step:8324 [D loss: 0.667592, acc.: 57.03%] [G loss: 0.882608]\n",
      "epoch:8 step:8325 [D loss: 0.665954, acc.: 57.81%] [G loss: 0.884144]\n",
      "epoch:8 step:8326 [D loss: 0.647013, acc.: 59.38%] [G loss: 0.968948]\n",
      "epoch:8 step:8327 [D loss: 0.605277, acc.: 68.75%] [G loss: 1.037588]\n",
      "epoch:8 step:8328 [D loss: 0.606865, acc.: 65.62%] [G loss: 0.939134]\n",
      "epoch:8 step:8329 [D loss: 0.574088, acc.: 72.66%] [G loss: 0.986666]\n",
      "epoch:8 step:8330 [D loss: 0.635306, acc.: 64.84%] [G loss: 1.071611]\n",
      "epoch:8 step:8331 [D loss: 0.626712, acc.: 67.19%] [G loss: 0.915411]\n",
      "epoch:8 step:8332 [D loss: 0.717612, acc.: 56.25%] [G loss: 1.014472]\n",
      "epoch:8 step:8333 [D loss: 0.707078, acc.: 53.12%] [G loss: 0.982450]\n",
      "epoch:8 step:8334 [D loss: 0.604460, acc.: 66.41%] [G loss: 0.910031]\n",
      "epoch:8 step:8335 [D loss: 0.657379, acc.: 60.16%] [G loss: 0.973146]\n",
      "epoch:8 step:8336 [D loss: 0.587566, acc.: 75.00%] [G loss: 0.975368]\n",
      "epoch:8 step:8337 [D loss: 0.732086, acc.: 49.22%] [G loss: 0.902283]\n",
      "epoch:8 step:8338 [D loss: 0.625085, acc.: 62.50%] [G loss: 1.035501]\n",
      "epoch:8 step:8339 [D loss: 0.694171, acc.: 59.38%] [G loss: 1.019079]\n",
      "epoch:8 step:8340 [D loss: 0.858879, acc.: 42.97%] [G loss: 0.863585]\n",
      "epoch:8 step:8341 [D loss: 0.671419, acc.: 57.81%] [G loss: 0.923335]\n",
      "epoch:8 step:8342 [D loss: 0.768662, acc.: 41.41%] [G loss: 0.845735]\n",
      "epoch:8 step:8343 [D loss: 0.632350, acc.: 63.28%] [G loss: 0.958255]\n",
      "epoch:8 step:8344 [D loss: 0.649626, acc.: 61.72%] [G loss: 0.948056]\n",
      "epoch:8 step:8345 [D loss: 0.686968, acc.: 53.12%] [G loss: 1.042004]\n",
      "epoch:8 step:8346 [D loss: 0.695111, acc.: 57.03%] [G loss: 0.983666]\n",
      "epoch:8 step:8347 [D loss: 0.592054, acc.: 74.22%] [G loss: 0.959119]\n",
      "epoch:8 step:8348 [D loss: 0.616572, acc.: 70.31%] [G loss: 0.927921]\n",
      "epoch:8 step:8349 [D loss: 0.630605, acc.: 67.97%] [G loss: 1.035659]\n",
      "epoch:8 step:8350 [D loss: 0.638925, acc.: 64.06%] [G loss: 0.975517]\n",
      "epoch:8 step:8351 [D loss: 0.650851, acc.: 61.72%] [G loss: 0.846658]\n",
      "epoch:8 step:8352 [D loss: 0.744696, acc.: 48.44%] [G loss: 0.870691]\n",
      "epoch:8 step:8353 [D loss: 0.597292, acc.: 68.75%] [G loss: 0.988573]\n",
      "epoch:8 step:8354 [D loss: 0.720511, acc.: 50.78%] [G loss: 0.978472]\n",
      "epoch:8 step:8355 [D loss: 0.728810, acc.: 50.78%] [G loss: 1.064744]\n",
      "epoch:8 step:8356 [D loss: 0.702753, acc.: 54.69%] [G loss: 0.926415]\n",
      "epoch:8 step:8357 [D loss: 0.670245, acc.: 53.12%] [G loss: 0.790398]\n",
      "epoch:8 step:8358 [D loss: 0.606720, acc.: 71.88%] [G loss: 0.975653]\n",
      "epoch:8 step:8359 [D loss: 0.636874, acc.: 64.06%] [G loss: 0.965736]\n",
      "epoch:8 step:8360 [D loss: 0.691189, acc.: 53.91%] [G loss: 0.880608]\n",
      "epoch:8 step:8361 [D loss: 0.691005, acc.: 51.56%] [G loss: 0.951910]\n",
      "epoch:8 step:8362 [D loss: 0.642857, acc.: 64.06%] [G loss: 0.849190]\n",
      "epoch:8 step:8363 [D loss: 0.664546, acc.: 60.94%] [G loss: 0.924392]\n",
      "epoch:8 step:8364 [D loss: 0.658784, acc.: 58.59%] [G loss: 1.027940]\n",
      "epoch:8 step:8365 [D loss: 0.723504, acc.: 54.69%] [G loss: 0.801285]\n",
      "epoch:8 step:8366 [D loss: 0.641157, acc.: 64.06%] [G loss: 0.939276]\n",
      "epoch:8 step:8367 [D loss: 0.633599, acc.: 64.06%] [G loss: 1.033605]\n",
      "epoch:8 step:8368 [D loss: 0.580057, acc.: 73.44%] [G loss: 0.991365]\n",
      "epoch:8 step:8369 [D loss: 0.615837, acc.: 68.75%] [G loss: 1.157500]\n",
      "epoch:8 step:8370 [D loss: 0.756618, acc.: 46.88%] [G loss: 0.877037]\n",
      "epoch:8 step:8371 [D loss: 0.606418, acc.: 68.75%] [G loss: 0.879161]\n",
      "epoch:8 step:8372 [D loss: 0.695020, acc.: 60.94%] [G loss: 0.808168]\n",
      "epoch:8 step:8373 [D loss: 0.646915, acc.: 56.25%] [G loss: 0.863525]\n",
      "epoch:8 step:8374 [D loss: 0.628730, acc.: 60.94%] [G loss: 0.996875]\n",
      "epoch:8 step:8375 [D loss: 0.616056, acc.: 64.06%] [G loss: 0.931147]\n",
      "epoch:8 step:8376 [D loss: 0.700971, acc.: 53.12%] [G loss: 0.926306]\n",
      "epoch:8 step:8377 [D loss: 0.660504, acc.: 62.50%] [G loss: 0.970593]\n",
      "epoch:8 step:8378 [D loss: 0.591354, acc.: 71.88%] [G loss: 0.965263]\n",
      "epoch:8 step:8379 [D loss: 0.677112, acc.: 59.38%] [G loss: 0.906273]\n",
      "epoch:8 step:8380 [D loss: 0.681528, acc.: 63.28%] [G loss: 0.833363]\n",
      "epoch:8 step:8381 [D loss: 0.639639, acc.: 68.75%] [G loss: 0.924863]\n",
      "epoch:8 step:8382 [D loss: 0.608800, acc.: 66.41%] [G loss: 1.059912]\n",
      "epoch:8 step:8383 [D loss: 0.569387, acc.: 70.31%] [G loss: 1.145016]\n",
      "epoch:8 step:8384 [D loss: 0.583029, acc.: 71.88%] [G loss: 1.044826]\n",
      "epoch:8 step:8385 [D loss: 0.581777, acc.: 70.31%] [G loss: 0.957868]\n",
      "epoch:8 step:8386 [D loss: 0.599920, acc.: 66.41%] [G loss: 1.007501]\n",
      "epoch:8 step:8387 [D loss: 0.719242, acc.: 49.22%] [G loss: 1.056324]\n",
      "epoch:8 step:8388 [D loss: 0.726536, acc.: 50.00%] [G loss: 1.193825]\n",
      "epoch:8 step:8389 [D loss: 0.668910, acc.: 64.84%] [G loss: 0.946618]\n",
      "epoch:8 step:8390 [D loss: 0.614411, acc.: 61.72%] [G loss: 0.910787]\n",
      "epoch:8 step:8391 [D loss: 0.694411, acc.: 53.91%] [G loss: 0.984178]\n",
      "epoch:8 step:8392 [D loss: 0.636987, acc.: 60.16%] [G loss: 1.130691]\n",
      "epoch:8 step:8393 [D loss: 0.553913, acc.: 69.53%] [G loss: 1.000533]\n",
      "epoch:8 step:8394 [D loss: 0.620920, acc.: 65.62%] [G loss: 1.011467]\n",
      "epoch:8 step:8395 [D loss: 0.585320, acc.: 72.66%] [G loss: 1.043390]\n",
      "epoch:8 step:8396 [D loss: 0.558243, acc.: 73.44%] [G loss: 0.975995]\n",
      "epoch:8 step:8397 [D loss: 0.573271, acc.: 69.53%] [G loss: 1.039403]\n",
      "epoch:8 step:8398 [D loss: 0.674274, acc.: 59.38%] [G loss: 0.928717]\n",
      "epoch:8 step:8399 [D loss: 0.649242, acc.: 64.06%] [G loss: 0.928114]\n",
      "epoch:8 step:8400 [D loss: 0.613044, acc.: 65.62%] [G loss: 1.015255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8401 [D loss: 0.606255, acc.: 65.62%] [G loss: 1.006946]\n",
      "epoch:8 step:8402 [D loss: 0.732507, acc.: 48.44%] [G loss: 0.961332]\n",
      "epoch:8 step:8403 [D loss: 0.593671, acc.: 72.66%] [G loss: 0.977831]\n",
      "epoch:8 step:8404 [D loss: 0.675378, acc.: 56.25%] [G loss: 0.848008]\n",
      "epoch:8 step:8405 [D loss: 0.640442, acc.: 61.72%] [G loss: 0.847197]\n",
      "epoch:8 step:8406 [D loss: 0.535198, acc.: 73.44%] [G loss: 0.919436]\n",
      "epoch:8 step:8407 [D loss: 0.582989, acc.: 64.06%] [G loss: 0.899729]\n",
      "epoch:8 step:8408 [D loss: 0.466306, acc.: 82.81%] [G loss: 1.192178]\n",
      "epoch:8 step:8409 [D loss: 0.735490, acc.: 51.56%] [G loss: 1.095938]\n",
      "epoch:8 step:8410 [D loss: 0.692378, acc.: 56.25%] [G loss: 1.090765]\n",
      "epoch:8 step:8411 [D loss: 0.592991, acc.: 71.09%] [G loss: 0.991891]\n",
      "epoch:8 step:8412 [D loss: 0.622546, acc.: 67.19%] [G loss: 0.911642]\n",
      "epoch:8 step:8413 [D loss: 0.606457, acc.: 67.97%] [G loss: 0.925831]\n",
      "epoch:8 step:8414 [D loss: 0.570979, acc.: 71.88%] [G loss: 1.072446]\n",
      "epoch:8 step:8415 [D loss: 0.524217, acc.: 77.34%] [G loss: 1.109920]\n",
      "epoch:8 step:8416 [D loss: 0.749187, acc.: 46.88%] [G loss: 0.948945]\n",
      "epoch:8 step:8417 [D loss: 0.653425, acc.: 58.59%] [G loss: 0.914283]\n",
      "epoch:8 step:8418 [D loss: 0.607975, acc.: 67.19%] [G loss: 0.953311]\n",
      "epoch:8 step:8419 [D loss: 0.556528, acc.: 67.97%] [G loss: 0.976566]\n",
      "epoch:8 step:8420 [D loss: 0.508927, acc.: 79.69%] [G loss: 1.195603]\n",
      "epoch:8 step:8421 [D loss: 0.580778, acc.: 70.31%] [G loss: 1.046951]\n",
      "epoch:8 step:8422 [D loss: 0.543761, acc.: 75.78%] [G loss: 1.192795]\n",
      "epoch:8 step:8423 [D loss: 0.647855, acc.: 57.81%] [G loss: 0.950798]\n",
      "epoch:8 step:8424 [D loss: 0.841458, acc.: 46.09%] [G loss: 1.171577]\n",
      "epoch:8 step:8425 [D loss: 0.653976, acc.: 59.38%] [G loss: 1.118815]\n",
      "epoch:8 step:8426 [D loss: 0.614972, acc.: 60.94%] [G loss: 0.987796]\n",
      "epoch:8 step:8427 [D loss: 0.690952, acc.: 54.69%] [G loss: 0.920232]\n",
      "epoch:8 step:8428 [D loss: 0.575565, acc.: 66.41%] [G loss: 0.967966]\n",
      "epoch:8 step:8429 [D loss: 0.619985, acc.: 64.84%] [G loss: 0.833769]\n",
      "epoch:8 step:8430 [D loss: 0.592002, acc.: 72.66%] [G loss: 0.960547]\n",
      "epoch:8 step:8431 [D loss: 0.608132, acc.: 66.41%] [G loss: 0.998559]\n",
      "epoch:8 step:8432 [D loss: 0.505806, acc.: 82.03%] [G loss: 1.026471]\n",
      "epoch:8 step:8433 [D loss: 0.449775, acc.: 79.69%] [G loss: 0.983530]\n",
      "epoch:9 step:8434 [D loss: 0.603619, acc.: 69.53%] [G loss: 1.228855]\n",
      "epoch:9 step:8435 [D loss: 0.740997, acc.: 52.34%] [G loss: 1.064782]\n",
      "epoch:9 step:8436 [D loss: 0.700861, acc.: 54.69%] [G loss: 1.050934]\n",
      "epoch:9 step:8437 [D loss: 0.652473, acc.: 64.84%] [G loss: 0.953606]\n",
      "epoch:9 step:8438 [D loss: 0.693831, acc.: 54.69%] [G loss: 1.034194]\n",
      "epoch:9 step:8439 [D loss: 0.701207, acc.: 56.25%] [G loss: 0.953391]\n",
      "epoch:9 step:8440 [D loss: 0.679955, acc.: 54.69%] [G loss: 1.015451]\n",
      "epoch:9 step:8441 [D loss: 0.630971, acc.: 64.06%] [G loss: 1.079473]\n",
      "epoch:9 step:8442 [D loss: 0.636538, acc.: 61.72%] [G loss: 0.963796]\n",
      "epoch:9 step:8443 [D loss: 0.634843, acc.: 64.84%] [G loss: 1.062552]\n",
      "epoch:9 step:8444 [D loss: 0.618312, acc.: 66.41%] [G loss: 1.224289]\n",
      "epoch:9 step:8445 [D loss: 0.747393, acc.: 46.88%] [G loss: 1.074140]\n",
      "epoch:9 step:8446 [D loss: 0.704277, acc.: 52.34%] [G loss: 0.970197]\n",
      "epoch:9 step:8447 [D loss: 0.628357, acc.: 63.28%] [G loss: 0.931938]\n",
      "epoch:9 step:8448 [D loss: 0.628992, acc.: 64.06%] [G loss: 0.955564]\n",
      "epoch:9 step:8449 [D loss: 0.580961, acc.: 70.31%] [G loss: 1.162077]\n",
      "epoch:9 step:8450 [D loss: 0.767554, acc.: 49.22%] [G loss: 0.865595]\n",
      "epoch:9 step:8451 [D loss: 0.792768, acc.: 44.53%] [G loss: 0.858116]\n",
      "epoch:9 step:8452 [D loss: 0.690206, acc.: 55.47%] [G loss: 0.965221]\n",
      "epoch:9 step:8453 [D loss: 0.813508, acc.: 41.41%] [G loss: 0.821223]\n",
      "epoch:9 step:8454 [D loss: 0.688848, acc.: 56.25%] [G loss: 0.978056]\n",
      "epoch:9 step:8455 [D loss: 0.644622, acc.: 68.75%] [G loss: 0.904049]\n",
      "epoch:9 step:8456 [D loss: 0.626129, acc.: 68.75%] [G loss: 0.846589]\n",
      "epoch:9 step:8457 [D loss: 0.669899, acc.: 57.81%] [G loss: 0.977368]\n",
      "epoch:9 step:8458 [D loss: 0.622947, acc.: 67.97%] [G loss: 0.921289]\n",
      "epoch:9 step:8459 [D loss: 0.676247, acc.: 54.69%] [G loss: 0.859030]\n",
      "epoch:9 step:8460 [D loss: 0.640525, acc.: 63.28%] [G loss: 0.973639]\n",
      "epoch:9 step:8461 [D loss: 0.581171, acc.: 72.66%] [G loss: 1.024852]\n",
      "epoch:9 step:8462 [D loss: 0.587057, acc.: 68.75%] [G loss: 0.884036]\n",
      "epoch:9 step:8463 [D loss: 0.608927, acc.: 63.28%] [G loss: 1.066371]\n",
      "epoch:9 step:8464 [D loss: 0.662189, acc.: 57.03%] [G loss: 0.967240]\n",
      "epoch:9 step:8465 [D loss: 0.599807, acc.: 67.19%] [G loss: 0.938517]\n",
      "epoch:9 step:8466 [D loss: 0.623939, acc.: 69.53%] [G loss: 1.010055]\n",
      "epoch:9 step:8467 [D loss: 0.593828, acc.: 68.75%] [G loss: 0.974827]\n",
      "epoch:9 step:8468 [D loss: 0.577878, acc.: 69.53%] [G loss: 1.028790]\n",
      "epoch:9 step:8469 [D loss: 0.489377, acc.: 84.38%] [G loss: 1.171404]\n",
      "epoch:9 step:8470 [D loss: 0.618433, acc.: 68.75%] [G loss: 1.132016]\n",
      "epoch:9 step:8471 [D loss: 0.707776, acc.: 53.12%] [G loss: 1.065547]\n",
      "epoch:9 step:8472 [D loss: 0.644738, acc.: 66.41%] [G loss: 1.124626]\n",
      "epoch:9 step:8473 [D loss: 0.708198, acc.: 59.38%] [G loss: 1.091148]\n",
      "epoch:9 step:8474 [D loss: 0.611762, acc.: 64.84%] [G loss: 0.967277]\n",
      "epoch:9 step:8475 [D loss: 0.689621, acc.: 53.91%] [G loss: 0.897021]\n",
      "epoch:9 step:8476 [D loss: 0.627962, acc.: 66.41%] [G loss: 0.957651]\n",
      "epoch:9 step:8477 [D loss: 0.665574, acc.: 63.28%] [G loss: 0.996727]\n",
      "epoch:9 step:8478 [D loss: 0.717603, acc.: 52.34%] [G loss: 0.877932]\n",
      "epoch:9 step:8479 [D loss: 0.651991, acc.: 60.16%] [G loss: 1.166242]\n",
      "epoch:9 step:8480 [D loss: 0.617879, acc.: 67.19%] [G loss: 0.990196]\n",
      "epoch:9 step:8481 [D loss: 0.656385, acc.: 60.94%] [G loss: 1.063642]\n",
      "epoch:9 step:8482 [D loss: 0.660577, acc.: 58.59%] [G loss: 1.087952]\n",
      "epoch:9 step:8483 [D loss: 0.608298, acc.: 64.84%] [G loss: 1.156106]\n",
      "epoch:9 step:8484 [D loss: 0.667555, acc.: 61.72%] [G loss: 0.914936]\n",
      "epoch:9 step:8485 [D loss: 0.606817, acc.: 63.28%] [G loss: 0.854459]\n",
      "epoch:9 step:8486 [D loss: 0.665661, acc.: 61.72%] [G loss: 1.029446]\n",
      "epoch:9 step:8487 [D loss: 0.666842, acc.: 65.62%] [G loss: 1.036702]\n",
      "epoch:9 step:8488 [D loss: 0.590930, acc.: 69.53%] [G loss: 0.969223]\n",
      "epoch:9 step:8489 [D loss: 0.627531, acc.: 65.62%] [G loss: 0.938837]\n",
      "epoch:9 step:8490 [D loss: 0.785954, acc.: 42.97%] [G loss: 0.793503]\n",
      "epoch:9 step:8491 [D loss: 0.632568, acc.: 63.28%] [G loss: 1.051862]\n",
      "epoch:9 step:8492 [D loss: 0.701979, acc.: 57.03%] [G loss: 1.010527]\n",
      "epoch:9 step:8493 [D loss: 0.674799, acc.: 61.72%] [G loss: 0.852219]\n",
      "epoch:9 step:8494 [D loss: 0.715512, acc.: 55.47%] [G loss: 0.881956]\n",
      "epoch:9 step:8495 [D loss: 0.616818, acc.: 64.84%] [G loss: 0.953496]\n",
      "epoch:9 step:8496 [D loss: 0.632568, acc.: 62.50%] [G loss: 0.973002]\n",
      "epoch:9 step:8497 [D loss: 0.661010, acc.: 62.50%] [G loss: 0.959286]\n",
      "epoch:9 step:8498 [D loss: 0.667383, acc.: 62.50%] [G loss: 1.032042]\n",
      "epoch:9 step:8499 [D loss: 0.656987, acc.: 64.06%] [G loss: 1.142920]\n",
      "epoch:9 step:8500 [D loss: 0.654013, acc.: 65.62%] [G loss: 0.978731]\n",
      "epoch:9 step:8501 [D loss: 0.573335, acc.: 71.09%] [G loss: 1.006673]\n",
      "epoch:9 step:8502 [D loss: 0.661288, acc.: 60.16%] [G loss: 0.872440]\n",
      "epoch:9 step:8503 [D loss: 0.579996, acc.: 71.88%] [G loss: 1.015584]\n",
      "epoch:9 step:8504 [D loss: 0.613191, acc.: 68.75%] [G loss: 0.991699]\n",
      "epoch:9 step:8505 [D loss: 0.623500, acc.: 60.16%] [G loss: 1.035188]\n",
      "epoch:9 step:8506 [D loss: 0.652638, acc.: 64.84%] [G loss: 0.843827]\n",
      "epoch:9 step:8507 [D loss: 0.585877, acc.: 67.97%] [G loss: 1.023815]\n",
      "epoch:9 step:8508 [D loss: 0.527934, acc.: 78.12%] [G loss: 1.130401]\n",
      "epoch:9 step:8509 [D loss: 0.553240, acc.: 70.31%] [G loss: 0.914545]\n",
      "epoch:9 step:8510 [D loss: 0.527162, acc.: 73.44%] [G loss: 1.156645]\n",
      "epoch:9 step:8511 [D loss: 0.635314, acc.: 62.50%] [G loss: 1.057325]\n",
      "epoch:9 step:8512 [D loss: 0.704745, acc.: 56.25%] [G loss: 0.964280]\n",
      "epoch:9 step:8513 [D loss: 0.670560, acc.: 62.50%] [G loss: 0.940878]\n",
      "epoch:9 step:8514 [D loss: 0.716558, acc.: 49.22%] [G loss: 0.914234]\n",
      "epoch:9 step:8515 [D loss: 0.693883, acc.: 54.69%] [G loss: 0.832572]\n",
      "epoch:9 step:8516 [D loss: 0.684942, acc.: 64.06%] [G loss: 0.982426]\n",
      "epoch:9 step:8517 [D loss: 0.667775, acc.: 58.59%] [G loss: 0.815196]\n",
      "epoch:9 step:8518 [D loss: 0.699392, acc.: 57.03%] [G loss: 0.915920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8519 [D loss: 0.624307, acc.: 58.59%] [G loss: 1.035943]\n",
      "epoch:9 step:8520 [D loss: 0.668857, acc.: 55.47%] [G loss: 0.941516]\n",
      "epoch:9 step:8521 [D loss: 0.586407, acc.: 71.88%] [G loss: 0.898458]\n",
      "epoch:9 step:8522 [D loss: 0.665771, acc.: 60.16%] [G loss: 0.870276]\n",
      "epoch:9 step:8523 [D loss: 0.656375, acc.: 62.50%] [G loss: 0.959621]\n",
      "epoch:9 step:8524 [D loss: 0.754546, acc.: 42.97%] [G loss: 0.842438]\n",
      "epoch:9 step:8525 [D loss: 0.579454, acc.: 71.88%] [G loss: 0.998923]\n",
      "epoch:9 step:8526 [D loss: 0.650067, acc.: 62.50%] [G loss: 0.999299]\n",
      "epoch:9 step:8527 [D loss: 0.653186, acc.: 60.16%] [G loss: 1.029140]\n",
      "epoch:9 step:8528 [D loss: 0.707944, acc.: 52.34%] [G loss: 0.984035]\n",
      "epoch:9 step:8529 [D loss: 0.740348, acc.: 50.78%] [G loss: 0.824276]\n",
      "epoch:9 step:8530 [D loss: 0.643988, acc.: 60.16%] [G loss: 0.974198]\n",
      "epoch:9 step:8531 [D loss: 0.666883, acc.: 60.94%] [G loss: 0.957192]\n",
      "epoch:9 step:8532 [D loss: 0.666686, acc.: 62.50%] [G loss: 1.052384]\n",
      "epoch:9 step:8533 [D loss: 0.611298, acc.: 63.28%] [G loss: 1.015213]\n",
      "epoch:9 step:8534 [D loss: 0.646432, acc.: 65.62%] [G loss: 1.062438]\n",
      "epoch:9 step:8535 [D loss: 0.637941, acc.: 63.28%] [G loss: 1.055650]\n",
      "epoch:9 step:8536 [D loss: 0.603668, acc.: 66.41%] [G loss: 1.092047]\n",
      "epoch:9 step:8537 [D loss: 0.608513, acc.: 65.62%] [G loss: 0.993655]\n",
      "epoch:9 step:8538 [D loss: 0.723422, acc.: 56.25%] [G loss: 1.078579]\n",
      "epoch:9 step:8539 [D loss: 0.625852, acc.: 66.41%] [G loss: 0.905462]\n",
      "epoch:9 step:8540 [D loss: 0.725542, acc.: 56.25%] [G loss: 0.951280]\n",
      "epoch:9 step:8541 [D loss: 0.670820, acc.: 60.94%] [G loss: 0.986146]\n",
      "epoch:9 step:8542 [D loss: 0.673091, acc.: 55.47%] [G loss: 0.925870]\n",
      "epoch:9 step:8543 [D loss: 0.613312, acc.: 70.31%] [G loss: 0.873461]\n",
      "epoch:9 step:8544 [D loss: 0.635124, acc.: 66.41%] [G loss: 0.911350]\n",
      "epoch:9 step:8545 [D loss: 0.644296, acc.: 62.50%] [G loss: 0.957451]\n",
      "epoch:9 step:8546 [D loss: 0.734422, acc.: 50.00%] [G loss: 0.980572]\n",
      "epoch:9 step:8547 [D loss: 0.740449, acc.: 47.66%] [G loss: 0.864903]\n",
      "epoch:9 step:8548 [D loss: 0.619154, acc.: 65.62%] [G loss: 0.896167]\n",
      "epoch:9 step:8549 [D loss: 0.643550, acc.: 64.84%] [G loss: 1.042141]\n",
      "epoch:9 step:8550 [D loss: 0.627361, acc.: 64.84%] [G loss: 0.934123]\n",
      "epoch:9 step:8551 [D loss: 0.635686, acc.: 62.50%] [G loss: 1.168779]\n",
      "epoch:9 step:8552 [D loss: 0.525917, acc.: 77.34%] [G loss: 1.118525]\n",
      "epoch:9 step:8553 [D loss: 0.661013, acc.: 60.16%] [G loss: 0.904955]\n",
      "epoch:9 step:8554 [D loss: 0.607807, acc.: 69.53%] [G loss: 0.937544]\n",
      "epoch:9 step:8555 [D loss: 0.649631, acc.: 57.03%] [G loss: 0.999743]\n",
      "epoch:9 step:8556 [D loss: 0.663535, acc.: 59.38%] [G loss: 0.900980]\n",
      "epoch:9 step:8557 [D loss: 0.720556, acc.: 52.34%] [G loss: 0.901632]\n",
      "epoch:9 step:8558 [D loss: 0.594583, acc.: 68.75%] [G loss: 0.897285]\n",
      "epoch:9 step:8559 [D loss: 0.626241, acc.: 65.62%] [G loss: 1.154787]\n",
      "epoch:9 step:8560 [D loss: 0.671895, acc.: 56.25%] [G loss: 0.989300]\n",
      "epoch:9 step:8561 [D loss: 0.629986, acc.: 67.19%] [G loss: 0.904044]\n",
      "epoch:9 step:8562 [D loss: 0.729520, acc.: 53.12%] [G loss: 0.957653]\n",
      "epoch:9 step:8563 [D loss: 0.667148, acc.: 62.50%] [G loss: 1.003793]\n",
      "epoch:9 step:8564 [D loss: 0.584088, acc.: 67.97%] [G loss: 0.953929]\n",
      "epoch:9 step:8565 [D loss: 0.676531, acc.: 56.25%] [G loss: 0.993183]\n",
      "epoch:9 step:8566 [D loss: 0.760183, acc.: 48.44%] [G loss: 0.865547]\n",
      "epoch:9 step:8567 [D loss: 0.686373, acc.: 57.81%] [G loss: 1.037582]\n",
      "epoch:9 step:8568 [D loss: 0.662534, acc.: 60.94%] [G loss: 0.804725]\n",
      "epoch:9 step:8569 [D loss: 0.695059, acc.: 54.69%] [G loss: 0.953789]\n",
      "epoch:9 step:8570 [D loss: 0.727308, acc.: 50.78%] [G loss: 0.906864]\n",
      "epoch:9 step:8571 [D loss: 0.715399, acc.: 54.69%] [G loss: 0.917203]\n",
      "epoch:9 step:8572 [D loss: 0.585949, acc.: 70.31%] [G loss: 0.835700]\n",
      "epoch:9 step:8573 [D loss: 0.643586, acc.: 62.50%] [G loss: 0.935831]\n",
      "epoch:9 step:8574 [D loss: 0.678564, acc.: 63.28%] [G loss: 0.851862]\n",
      "epoch:9 step:8575 [D loss: 0.677537, acc.: 59.38%] [G loss: 0.840674]\n",
      "epoch:9 step:8576 [D loss: 0.764743, acc.: 42.19%] [G loss: 0.917883]\n",
      "epoch:9 step:8577 [D loss: 0.648205, acc.: 60.16%] [G loss: 0.961886]\n",
      "epoch:9 step:8578 [D loss: 0.708618, acc.: 53.12%] [G loss: 0.937480]\n",
      "epoch:9 step:8579 [D loss: 0.613899, acc.: 68.75%] [G loss: 0.898410]\n",
      "epoch:9 step:8580 [D loss: 0.629016, acc.: 67.19%] [G loss: 1.104242]\n",
      "epoch:9 step:8581 [D loss: 0.665036, acc.: 64.06%] [G loss: 0.945035]\n",
      "epoch:9 step:8582 [D loss: 0.585169, acc.: 75.78%] [G loss: 0.974669]\n",
      "epoch:9 step:8583 [D loss: 0.618750, acc.: 69.53%] [G loss: 0.992490]\n",
      "epoch:9 step:8584 [D loss: 0.623274, acc.: 63.28%] [G loss: 0.963218]\n",
      "epoch:9 step:8585 [D loss: 0.604755, acc.: 69.53%] [G loss: 0.957267]\n",
      "epoch:9 step:8586 [D loss: 0.680606, acc.: 60.16%] [G loss: 0.919880]\n",
      "epoch:9 step:8587 [D loss: 0.591414, acc.: 71.88%] [G loss: 0.958216]\n",
      "epoch:9 step:8588 [D loss: 0.643903, acc.: 64.84%] [G loss: 1.084999]\n",
      "epoch:9 step:8589 [D loss: 0.636092, acc.: 65.62%] [G loss: 0.863056]\n",
      "epoch:9 step:8590 [D loss: 0.600530, acc.: 70.31%] [G loss: 1.038255]\n",
      "epoch:9 step:8591 [D loss: 0.690597, acc.: 58.59%] [G loss: 0.808875]\n",
      "epoch:9 step:8592 [D loss: 0.681269, acc.: 59.38%] [G loss: 0.973604]\n",
      "epoch:9 step:8593 [D loss: 0.797328, acc.: 42.97%] [G loss: 0.881845]\n",
      "epoch:9 step:8594 [D loss: 0.697193, acc.: 57.81%] [G loss: 0.851143]\n",
      "epoch:9 step:8595 [D loss: 0.665469, acc.: 60.16%] [G loss: 1.010492]\n",
      "epoch:9 step:8596 [D loss: 0.657042, acc.: 67.97%] [G loss: 1.006699]\n",
      "epoch:9 step:8597 [D loss: 0.708817, acc.: 54.69%] [G loss: 1.033132]\n",
      "epoch:9 step:8598 [D loss: 0.659868, acc.: 59.38%] [G loss: 0.902660]\n",
      "epoch:9 step:8599 [D loss: 0.723337, acc.: 50.00%] [G loss: 0.846035]\n",
      "epoch:9 step:8600 [D loss: 0.684030, acc.: 57.03%] [G loss: 0.959416]\n",
      "epoch:9 step:8601 [D loss: 0.594927, acc.: 67.97%] [G loss: 0.995304]\n",
      "epoch:9 step:8602 [D loss: 0.647447, acc.: 64.06%] [G loss: 1.000309]\n",
      "epoch:9 step:8603 [D loss: 0.647576, acc.: 63.28%] [G loss: 0.863310]\n",
      "epoch:9 step:8604 [D loss: 0.627129, acc.: 62.50%] [G loss: 0.973286]\n",
      "epoch:9 step:8605 [D loss: 0.681429, acc.: 58.59%] [G loss: 0.850624]\n",
      "epoch:9 step:8606 [D loss: 0.634209, acc.: 67.97%] [G loss: 0.946141]\n",
      "epoch:9 step:8607 [D loss: 0.652469, acc.: 62.50%] [G loss: 1.057239]\n",
      "epoch:9 step:8608 [D loss: 0.698188, acc.: 52.34%] [G loss: 0.880818]\n",
      "epoch:9 step:8609 [D loss: 0.611640, acc.: 67.19%] [G loss: 1.042770]\n",
      "epoch:9 step:8610 [D loss: 0.651906, acc.: 64.06%] [G loss: 1.049369]\n",
      "epoch:9 step:8611 [D loss: 0.647353, acc.: 55.47%] [G loss: 0.940413]\n",
      "epoch:9 step:8612 [D loss: 0.697385, acc.: 58.59%] [G loss: 0.934061]\n",
      "epoch:9 step:8613 [D loss: 0.615354, acc.: 67.97%] [G loss: 1.131514]\n",
      "epoch:9 step:8614 [D loss: 0.656705, acc.: 57.03%] [G loss: 0.822014]\n",
      "epoch:9 step:8615 [D loss: 0.677845, acc.: 60.16%] [G loss: 1.068859]\n",
      "epoch:9 step:8616 [D loss: 0.682167, acc.: 57.81%] [G loss: 0.869460]\n",
      "epoch:9 step:8617 [D loss: 0.782676, acc.: 47.66%] [G loss: 0.849919]\n",
      "epoch:9 step:8618 [D loss: 0.742172, acc.: 50.78%] [G loss: 0.959011]\n",
      "epoch:9 step:8619 [D loss: 0.628311, acc.: 62.50%] [G loss: 1.034750]\n",
      "epoch:9 step:8620 [D loss: 0.639830, acc.: 62.50%] [G loss: 0.877424]\n",
      "epoch:9 step:8621 [D loss: 0.645812, acc.: 64.06%] [G loss: 1.010808]\n",
      "epoch:9 step:8622 [D loss: 0.733084, acc.: 52.34%] [G loss: 1.018278]\n",
      "epoch:9 step:8623 [D loss: 0.643583, acc.: 66.41%] [G loss: 0.916791]\n",
      "epoch:9 step:8624 [D loss: 0.617354, acc.: 64.84%] [G loss: 0.982177]\n",
      "epoch:9 step:8625 [D loss: 0.547078, acc.: 74.22%] [G loss: 1.024450]\n",
      "epoch:9 step:8626 [D loss: 0.734508, acc.: 50.78%] [G loss: 0.961354]\n",
      "epoch:9 step:8627 [D loss: 0.630700, acc.: 61.72%] [G loss: 1.000884]\n",
      "epoch:9 step:8628 [D loss: 0.620333, acc.: 70.31%] [G loss: 0.977514]\n",
      "epoch:9 step:8629 [D loss: 0.705285, acc.: 55.47%] [G loss: 1.031560]\n",
      "epoch:9 step:8630 [D loss: 0.650215, acc.: 60.94%] [G loss: 1.040731]\n",
      "epoch:9 step:8631 [D loss: 0.709357, acc.: 51.56%] [G loss: 0.948164]\n",
      "epoch:9 step:8632 [D loss: 0.668875, acc.: 61.72%] [G loss: 1.087829]\n",
      "epoch:9 step:8633 [D loss: 0.672231, acc.: 56.25%] [G loss: 1.016469]\n",
      "epoch:9 step:8634 [D loss: 0.769076, acc.: 45.31%] [G loss: 0.855704]\n",
      "epoch:9 step:8635 [D loss: 0.617599, acc.: 67.97%] [G loss: 0.908876]\n",
      "epoch:9 step:8636 [D loss: 0.708354, acc.: 53.12%] [G loss: 0.876516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8637 [D loss: 0.691816, acc.: 52.34%] [G loss: 1.053514]\n",
      "epoch:9 step:8638 [D loss: 0.701801, acc.: 56.25%] [G loss: 0.997319]\n",
      "epoch:9 step:8639 [D loss: 0.625974, acc.: 66.41%] [G loss: 0.903112]\n",
      "epoch:9 step:8640 [D loss: 0.592456, acc.: 66.41%] [G loss: 0.900444]\n",
      "epoch:9 step:8641 [D loss: 0.617453, acc.: 71.09%] [G loss: 0.966133]\n",
      "epoch:9 step:8642 [D loss: 0.639969, acc.: 66.41%] [G loss: 0.925942]\n",
      "epoch:9 step:8643 [D loss: 0.675543, acc.: 56.25%] [G loss: 0.929455]\n",
      "epoch:9 step:8644 [D loss: 0.758114, acc.: 43.75%] [G loss: 0.897994]\n",
      "epoch:9 step:8645 [D loss: 0.689309, acc.: 55.47%] [G loss: 1.077585]\n",
      "epoch:9 step:8646 [D loss: 0.693812, acc.: 50.78%] [G loss: 0.881405]\n",
      "epoch:9 step:8647 [D loss: 0.736508, acc.: 53.91%] [G loss: 0.834111]\n",
      "epoch:9 step:8648 [D loss: 0.774589, acc.: 46.09%] [G loss: 0.928609]\n",
      "epoch:9 step:8649 [D loss: 0.719128, acc.: 57.03%] [G loss: 0.833908]\n",
      "epoch:9 step:8650 [D loss: 0.641892, acc.: 62.50%] [G loss: 0.915280]\n",
      "epoch:9 step:8651 [D loss: 0.596881, acc.: 67.19%] [G loss: 0.973515]\n",
      "epoch:9 step:8652 [D loss: 0.631091, acc.: 70.31%] [G loss: 1.224762]\n",
      "epoch:9 step:8653 [D loss: 0.663737, acc.: 58.59%] [G loss: 1.006209]\n",
      "epoch:9 step:8654 [D loss: 0.591594, acc.: 70.31%] [G loss: 1.052257]\n",
      "epoch:9 step:8655 [D loss: 0.602063, acc.: 71.09%] [G loss: 0.988817]\n",
      "epoch:9 step:8656 [D loss: 0.631559, acc.: 64.84%] [G loss: 0.996135]\n",
      "epoch:9 step:8657 [D loss: 0.722084, acc.: 52.34%] [G loss: 0.954919]\n",
      "epoch:9 step:8658 [D loss: 0.670814, acc.: 59.38%] [G loss: 0.860067]\n",
      "epoch:9 step:8659 [D loss: 0.651294, acc.: 63.28%] [G loss: 0.932465]\n",
      "epoch:9 step:8660 [D loss: 0.730636, acc.: 52.34%] [G loss: 0.924727]\n",
      "epoch:9 step:8661 [D loss: 0.794241, acc.: 43.75%] [G loss: 0.807282]\n",
      "epoch:9 step:8662 [D loss: 0.695935, acc.: 53.12%] [G loss: 0.971386]\n",
      "epoch:9 step:8663 [D loss: 0.504642, acc.: 78.12%] [G loss: 0.918412]\n",
      "epoch:9 step:8664 [D loss: 0.547686, acc.: 75.00%] [G loss: 1.179164]\n",
      "epoch:9 step:8665 [D loss: 0.453099, acc.: 84.38%] [G loss: 1.228566]\n",
      "epoch:9 step:8666 [D loss: 0.654228, acc.: 60.16%] [G loss: 1.079017]\n",
      "epoch:9 step:8667 [D loss: 0.766866, acc.: 53.12%] [G loss: 0.913218]\n",
      "epoch:9 step:8668 [D loss: 0.765873, acc.: 47.66%] [G loss: 0.942067]\n",
      "epoch:9 step:8669 [D loss: 0.603448, acc.: 68.75%] [G loss: 0.977399]\n",
      "epoch:9 step:8670 [D loss: 0.641388, acc.: 61.72%] [G loss: 0.950932]\n",
      "epoch:9 step:8671 [D loss: 0.598042, acc.: 74.22%] [G loss: 1.291287]\n",
      "epoch:9 step:8672 [D loss: 0.612677, acc.: 68.75%] [G loss: 0.956690]\n",
      "epoch:9 step:8673 [D loss: 0.667838, acc.: 56.25%] [G loss: 1.061386]\n",
      "epoch:9 step:8674 [D loss: 0.618701, acc.: 63.28%] [G loss: 1.004470]\n",
      "epoch:9 step:8675 [D loss: 0.595264, acc.: 67.97%] [G loss: 1.089355]\n",
      "epoch:9 step:8676 [D loss: 0.642893, acc.: 61.72%] [G loss: 1.053145]\n",
      "epoch:9 step:8677 [D loss: 0.634726, acc.: 66.41%] [G loss: 1.090775]\n",
      "epoch:9 step:8678 [D loss: 0.681867, acc.: 56.25%] [G loss: 1.012804]\n",
      "epoch:9 step:8679 [D loss: 0.648803, acc.: 61.72%] [G loss: 0.887617]\n",
      "epoch:9 step:8680 [D loss: 0.628989, acc.: 66.41%] [G loss: 1.001386]\n",
      "epoch:9 step:8681 [D loss: 0.744722, acc.: 48.44%] [G loss: 0.967734]\n",
      "epoch:9 step:8682 [D loss: 0.700647, acc.: 53.91%] [G loss: 1.014581]\n",
      "epoch:9 step:8683 [D loss: 0.745945, acc.: 49.22%] [G loss: 0.860092]\n",
      "epoch:9 step:8684 [D loss: 0.721209, acc.: 57.03%] [G loss: 1.001426]\n",
      "epoch:9 step:8685 [D loss: 0.673702, acc.: 64.06%] [G loss: 0.942974]\n",
      "epoch:9 step:8686 [D loss: 0.592068, acc.: 70.31%] [G loss: 0.938263]\n",
      "epoch:9 step:8687 [D loss: 0.606577, acc.: 68.75%] [G loss: 0.955254]\n",
      "epoch:9 step:8688 [D loss: 0.648130, acc.: 63.28%] [G loss: 0.887830]\n",
      "epoch:9 step:8689 [D loss: 0.606330, acc.: 66.41%] [G loss: 1.061577]\n",
      "epoch:9 step:8690 [D loss: 0.649143, acc.: 59.38%] [G loss: 0.923377]\n",
      "epoch:9 step:8691 [D loss: 0.628078, acc.: 65.62%] [G loss: 0.843463]\n",
      "epoch:9 step:8692 [D loss: 0.573084, acc.: 73.44%] [G loss: 1.066142]\n",
      "epoch:9 step:8693 [D loss: 0.673364, acc.: 56.25%] [G loss: 0.981528]\n",
      "epoch:9 step:8694 [D loss: 0.566994, acc.: 67.97%] [G loss: 1.096324]\n",
      "epoch:9 step:8695 [D loss: 0.564652, acc.: 73.44%] [G loss: 1.064794]\n",
      "epoch:9 step:8696 [D loss: 0.770474, acc.: 44.53%] [G loss: 0.796658]\n",
      "epoch:9 step:8697 [D loss: 0.643747, acc.: 64.84%] [G loss: 0.919728]\n",
      "epoch:9 step:8698 [D loss: 0.658515, acc.: 59.38%] [G loss: 0.977150]\n",
      "epoch:9 step:8699 [D loss: 0.714014, acc.: 49.22%] [G loss: 0.886705]\n",
      "epoch:9 step:8700 [D loss: 0.596310, acc.: 68.75%] [G loss: 0.974758]\n",
      "epoch:9 step:8701 [D loss: 0.707678, acc.: 57.81%] [G loss: 0.851081]\n",
      "epoch:9 step:8702 [D loss: 0.711006, acc.: 56.25%] [G loss: 0.821407]\n",
      "epoch:9 step:8703 [D loss: 0.759751, acc.: 48.44%] [G loss: 0.906250]\n",
      "epoch:9 step:8704 [D loss: 0.706680, acc.: 52.34%] [G loss: 0.911456]\n",
      "epoch:9 step:8705 [D loss: 0.679235, acc.: 50.00%] [G loss: 0.935107]\n",
      "epoch:9 step:8706 [D loss: 0.624318, acc.: 65.62%] [G loss: 0.943936]\n",
      "epoch:9 step:8707 [D loss: 0.643370, acc.: 71.09%] [G loss: 1.124366]\n",
      "epoch:9 step:8708 [D loss: 0.729506, acc.: 52.34%] [G loss: 0.971958]\n",
      "epoch:9 step:8709 [D loss: 0.630374, acc.: 69.53%] [G loss: 1.009232]\n",
      "epoch:9 step:8710 [D loss: 0.663695, acc.: 57.03%] [G loss: 0.931493]\n",
      "epoch:9 step:8711 [D loss: 0.680180, acc.: 57.81%] [G loss: 1.052068]\n",
      "epoch:9 step:8712 [D loss: 0.632029, acc.: 66.41%] [G loss: 1.028236]\n",
      "epoch:9 step:8713 [D loss: 0.602223, acc.: 67.97%] [G loss: 0.934260]\n",
      "epoch:9 step:8714 [D loss: 0.736730, acc.: 53.12%] [G loss: 0.955893]\n",
      "epoch:9 step:8715 [D loss: 0.678867, acc.: 54.69%] [G loss: 0.883656]\n",
      "epoch:9 step:8716 [D loss: 0.640085, acc.: 64.84%] [G loss: 0.911089]\n",
      "epoch:9 step:8717 [D loss: 0.618922, acc.: 66.41%] [G loss: 0.947120]\n",
      "epoch:9 step:8718 [D loss: 0.594491, acc.: 67.19%] [G loss: 1.013228]\n",
      "epoch:9 step:8719 [D loss: 0.596425, acc.: 70.31%] [G loss: 1.080942]\n",
      "epoch:9 step:8720 [D loss: 0.662160, acc.: 62.50%] [G loss: 0.942927]\n",
      "epoch:9 step:8721 [D loss: 0.603492, acc.: 65.62%] [G loss: 1.192948]\n",
      "epoch:9 step:8722 [D loss: 0.596713, acc.: 67.97%] [G loss: 0.869689]\n",
      "epoch:9 step:8723 [D loss: 0.670141, acc.: 57.03%] [G loss: 0.963582]\n",
      "epoch:9 step:8724 [D loss: 0.641558, acc.: 61.72%] [G loss: 1.015893]\n",
      "epoch:9 step:8725 [D loss: 0.712175, acc.: 50.78%] [G loss: 0.890262]\n",
      "epoch:9 step:8726 [D loss: 0.661367, acc.: 60.16%] [G loss: 0.871810]\n",
      "epoch:9 step:8727 [D loss: 0.679880, acc.: 61.72%] [G loss: 1.054602]\n",
      "epoch:9 step:8728 [D loss: 0.632279, acc.: 65.62%] [G loss: 1.046189]\n",
      "epoch:9 step:8729 [D loss: 0.667522, acc.: 59.38%] [G loss: 0.934892]\n",
      "epoch:9 step:8730 [D loss: 0.682411, acc.: 57.81%] [G loss: 0.978367]\n",
      "epoch:9 step:8731 [D loss: 0.558192, acc.: 71.09%] [G loss: 1.068422]\n",
      "epoch:9 step:8732 [D loss: 0.621185, acc.: 64.06%] [G loss: 0.991590]\n",
      "epoch:9 step:8733 [D loss: 0.600519, acc.: 61.72%] [G loss: 1.030675]\n",
      "epoch:9 step:8734 [D loss: 0.704172, acc.: 52.34%] [G loss: 0.976359]\n",
      "epoch:9 step:8735 [D loss: 0.686725, acc.: 57.03%] [G loss: 0.940348]\n",
      "epoch:9 step:8736 [D loss: 0.665503, acc.: 62.50%] [G loss: 0.829857]\n",
      "epoch:9 step:8737 [D loss: 0.667112, acc.: 59.38%] [G loss: 1.015047]\n",
      "epoch:9 step:8738 [D loss: 0.612840, acc.: 65.62%] [G loss: 0.944645]\n",
      "epoch:9 step:8739 [D loss: 0.694437, acc.: 57.81%] [G loss: 1.091150]\n",
      "epoch:9 step:8740 [D loss: 0.676683, acc.: 55.47%] [G loss: 0.959142]\n",
      "epoch:9 step:8741 [D loss: 0.657560, acc.: 60.94%] [G loss: 0.911554]\n",
      "epoch:9 step:8742 [D loss: 0.593545, acc.: 72.66%] [G loss: 1.181791]\n",
      "epoch:9 step:8743 [D loss: 0.688386, acc.: 57.81%] [G loss: 0.989946]\n",
      "epoch:9 step:8744 [D loss: 0.582886, acc.: 75.78%] [G loss: 1.083117]\n",
      "epoch:9 step:8745 [D loss: 0.572552, acc.: 70.31%] [G loss: 1.064825]\n",
      "epoch:9 step:8746 [D loss: 0.521566, acc.: 79.69%] [G loss: 1.142034]\n",
      "epoch:9 step:8747 [D loss: 0.524903, acc.: 75.00%] [G loss: 1.034087]\n",
      "epoch:9 step:8748 [D loss: 0.580693, acc.: 69.53%] [G loss: 0.941986]\n",
      "epoch:9 step:8749 [D loss: 0.739102, acc.: 53.12%] [G loss: 1.045617]\n",
      "epoch:9 step:8750 [D loss: 0.735270, acc.: 56.25%] [G loss: 1.042414]\n",
      "epoch:9 step:8751 [D loss: 0.649565, acc.: 59.38%] [G loss: 1.093691]\n",
      "epoch:9 step:8752 [D loss: 0.625336, acc.: 65.62%] [G loss: 1.114991]\n",
      "epoch:9 step:8753 [D loss: 0.673336, acc.: 56.25%] [G loss: 0.942150]\n",
      "epoch:9 step:8754 [D loss: 0.624506, acc.: 64.84%] [G loss: 1.052541]\n",
      "epoch:9 step:8755 [D loss: 0.622526, acc.: 62.50%] [G loss: 1.057376]\n",
      "epoch:9 step:8756 [D loss: 0.777494, acc.: 46.88%] [G loss: 1.049332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8757 [D loss: 0.686901, acc.: 54.69%] [G loss: 0.961717]\n",
      "epoch:9 step:8758 [D loss: 0.645391, acc.: 65.62%] [G loss: 0.840313]\n",
      "epoch:9 step:8759 [D loss: 0.615556, acc.: 67.19%] [G loss: 0.964089]\n",
      "epoch:9 step:8760 [D loss: 0.629449, acc.: 62.50%] [G loss: 1.083263]\n",
      "epoch:9 step:8761 [D loss: 0.615281, acc.: 63.28%] [G loss: 0.922085]\n",
      "epoch:9 step:8762 [D loss: 0.613731, acc.: 62.50%] [G loss: 0.975649]\n",
      "epoch:9 step:8763 [D loss: 0.590470, acc.: 69.53%] [G loss: 0.968092]\n",
      "epoch:9 step:8764 [D loss: 0.688755, acc.: 58.59%] [G loss: 0.941438]\n",
      "epoch:9 step:8765 [D loss: 0.636249, acc.: 65.62%] [G loss: 0.910414]\n",
      "epoch:9 step:8766 [D loss: 0.625403, acc.: 62.50%] [G loss: 1.017902]\n",
      "epoch:9 step:8767 [D loss: 0.630852, acc.: 67.97%] [G loss: 0.838905]\n",
      "epoch:9 step:8768 [D loss: 0.632044, acc.: 61.72%] [G loss: 1.004008]\n",
      "epoch:9 step:8769 [D loss: 0.592412, acc.: 63.28%] [G loss: 1.069062]\n",
      "epoch:9 step:8770 [D loss: 0.611742, acc.: 64.06%] [G loss: 0.994198]\n",
      "epoch:9 step:8771 [D loss: 0.607497, acc.: 68.75%] [G loss: 0.963013]\n",
      "epoch:9 step:8772 [D loss: 0.628103, acc.: 67.19%] [G loss: 0.941669]\n",
      "epoch:9 step:8773 [D loss: 0.655513, acc.: 60.16%] [G loss: 1.017054]\n",
      "epoch:9 step:8774 [D loss: 0.730428, acc.: 50.00%] [G loss: 0.936615]\n",
      "epoch:9 step:8775 [D loss: 0.681850, acc.: 54.69%] [G loss: 0.869822]\n",
      "epoch:9 step:8776 [D loss: 0.596429, acc.: 71.09%] [G loss: 0.916328]\n",
      "epoch:9 step:8777 [D loss: 0.543110, acc.: 74.22%] [G loss: 1.011401]\n",
      "epoch:9 step:8778 [D loss: 0.609023, acc.: 63.28%] [G loss: 0.985878]\n",
      "epoch:9 step:8779 [D loss: 0.597393, acc.: 67.97%] [G loss: 0.882818]\n",
      "epoch:9 step:8780 [D loss: 0.571333, acc.: 74.22%] [G loss: 1.006790]\n",
      "epoch:9 step:8781 [D loss: 0.733473, acc.: 53.91%] [G loss: 0.982781]\n",
      "epoch:9 step:8782 [D loss: 0.710435, acc.: 55.47%] [G loss: 0.945337]\n",
      "epoch:9 step:8783 [D loss: 0.669506, acc.: 57.81%] [G loss: 0.945071]\n",
      "epoch:9 step:8784 [D loss: 0.616853, acc.: 63.28%] [G loss: 1.012409]\n",
      "epoch:9 step:8785 [D loss: 0.673126, acc.: 59.38%] [G loss: 0.908089]\n",
      "epoch:9 step:8786 [D loss: 0.633376, acc.: 67.19%] [G loss: 0.914854]\n",
      "epoch:9 step:8787 [D loss: 0.626475, acc.: 65.62%] [G loss: 0.989530]\n",
      "epoch:9 step:8788 [D loss: 0.705608, acc.: 55.47%] [G loss: 1.014208]\n",
      "epoch:9 step:8789 [D loss: 0.691395, acc.: 57.81%] [G loss: 0.952718]\n",
      "epoch:9 step:8790 [D loss: 0.664358, acc.: 57.81%] [G loss: 0.927141]\n",
      "epoch:9 step:8791 [D loss: 0.566664, acc.: 73.44%] [G loss: 0.902113]\n",
      "epoch:9 step:8792 [D loss: 0.644966, acc.: 60.16%] [G loss: 0.961285]\n",
      "epoch:9 step:8793 [D loss: 0.604058, acc.: 67.97%] [G loss: 1.033925]\n",
      "epoch:9 step:8794 [D loss: 0.609062, acc.: 67.97%] [G loss: 1.004275]\n",
      "epoch:9 step:8795 [D loss: 0.628711, acc.: 63.28%] [G loss: 1.011320]\n",
      "epoch:9 step:8796 [D loss: 0.614308, acc.: 64.06%] [G loss: 1.207592]\n",
      "epoch:9 step:8797 [D loss: 0.590881, acc.: 70.31%] [G loss: 0.990516]\n",
      "epoch:9 step:8798 [D loss: 0.717325, acc.: 54.69%] [G loss: 0.965871]\n",
      "epoch:9 step:8799 [D loss: 0.614720, acc.: 71.09%] [G loss: 1.074171]\n",
      "epoch:9 step:8800 [D loss: 0.652883, acc.: 60.94%] [G loss: 0.986075]\n",
      "epoch:9 step:8801 [D loss: 0.675999, acc.: 60.16%] [G loss: 1.041335]\n",
      "epoch:9 step:8802 [D loss: 0.722175, acc.: 53.12%] [G loss: 1.006780]\n",
      "epoch:9 step:8803 [D loss: 0.616710, acc.: 67.19%] [G loss: 1.044370]\n",
      "epoch:9 step:8804 [D loss: 0.601777, acc.: 66.41%] [G loss: 0.924876]\n",
      "epoch:9 step:8805 [D loss: 0.620028, acc.: 64.06%] [G loss: 0.957709]\n",
      "epoch:9 step:8806 [D loss: 0.658368, acc.: 61.72%] [G loss: 0.901699]\n",
      "epoch:9 step:8807 [D loss: 0.626738, acc.: 65.62%] [G loss: 1.165802]\n",
      "epoch:9 step:8808 [D loss: 0.687884, acc.: 60.16%] [G loss: 0.872609]\n",
      "epoch:9 step:8809 [D loss: 0.713814, acc.: 57.03%] [G loss: 1.005202]\n",
      "epoch:9 step:8810 [D loss: 0.723278, acc.: 49.22%] [G loss: 0.972588]\n",
      "epoch:9 step:8811 [D loss: 0.703278, acc.: 58.59%] [G loss: 1.048741]\n",
      "epoch:9 step:8812 [D loss: 0.603153, acc.: 65.62%] [G loss: 0.884099]\n",
      "epoch:9 step:8813 [D loss: 0.564401, acc.: 75.00%] [G loss: 1.085142]\n",
      "epoch:9 step:8814 [D loss: 0.592105, acc.: 67.97%] [G loss: 0.929069]\n",
      "epoch:9 step:8815 [D loss: 0.735074, acc.: 50.78%] [G loss: 1.045726]\n",
      "epoch:9 step:8816 [D loss: 0.609859, acc.: 67.19%] [G loss: 0.949763]\n",
      "epoch:9 step:8817 [D loss: 0.680944, acc.: 57.03%] [G loss: 0.898485]\n",
      "epoch:9 step:8818 [D loss: 0.631196, acc.: 61.72%] [G loss: 0.902033]\n",
      "epoch:9 step:8819 [D loss: 0.719115, acc.: 51.56%] [G loss: 0.883761]\n",
      "epoch:9 step:8820 [D loss: 0.587667, acc.: 72.66%] [G loss: 0.975481]\n",
      "epoch:9 step:8821 [D loss: 0.579260, acc.: 73.44%] [G loss: 1.104200]\n",
      "epoch:9 step:8822 [D loss: 0.651043, acc.: 57.03%] [G loss: 1.043021]\n",
      "epoch:9 step:8823 [D loss: 0.675348, acc.: 58.59%] [G loss: 0.982103]\n",
      "epoch:9 step:8824 [D loss: 0.710949, acc.: 58.59%] [G loss: 0.955149]\n",
      "epoch:9 step:8825 [D loss: 0.633302, acc.: 68.75%] [G loss: 0.910795]\n",
      "epoch:9 step:8826 [D loss: 0.735345, acc.: 50.78%] [G loss: 0.800083]\n",
      "epoch:9 step:8827 [D loss: 0.640046, acc.: 61.72%] [G loss: 1.047828]\n",
      "epoch:9 step:8828 [D loss: 0.619404, acc.: 67.19%] [G loss: 0.930612]\n",
      "epoch:9 step:8829 [D loss: 0.730734, acc.: 52.34%] [G loss: 1.030684]\n",
      "epoch:9 step:8830 [D loss: 0.622730, acc.: 60.94%] [G loss: 1.065217]\n",
      "epoch:9 step:8831 [D loss: 0.497730, acc.: 79.69%] [G loss: 0.946476]\n",
      "epoch:9 step:8832 [D loss: 0.558076, acc.: 71.88%] [G loss: 1.012950]\n",
      "epoch:9 step:8833 [D loss: 0.596236, acc.: 67.97%] [G loss: 1.184269]\n",
      "epoch:9 step:8834 [D loss: 0.696780, acc.: 55.47%] [G loss: 1.096380]\n",
      "epoch:9 step:8835 [D loss: 0.612763, acc.: 66.41%] [G loss: 1.094465]\n",
      "epoch:9 step:8836 [D loss: 0.664513, acc.: 64.84%] [G loss: 1.161290]\n",
      "epoch:9 step:8837 [D loss: 0.579922, acc.: 71.88%] [G loss: 1.065226]\n",
      "epoch:9 step:8838 [D loss: 0.706846, acc.: 58.59%] [G loss: 0.916888]\n",
      "epoch:9 step:8839 [D loss: 0.548486, acc.: 75.78%] [G loss: 1.052200]\n",
      "epoch:9 step:8840 [D loss: 0.628578, acc.: 60.94%] [G loss: 1.101640]\n",
      "epoch:9 step:8841 [D loss: 0.707934, acc.: 54.69%] [G loss: 1.135570]\n",
      "epoch:9 step:8842 [D loss: 0.629182, acc.: 66.41%] [G loss: 1.000855]\n",
      "epoch:9 step:8843 [D loss: 0.566744, acc.: 74.22%] [G loss: 1.097640]\n",
      "epoch:9 step:8844 [D loss: 0.639723, acc.: 64.84%] [G loss: 1.109601]\n",
      "epoch:9 step:8845 [D loss: 0.683548, acc.: 58.59%] [G loss: 0.890083]\n",
      "epoch:9 step:8846 [D loss: 0.701541, acc.: 57.03%] [G loss: 1.098231]\n",
      "epoch:9 step:8847 [D loss: 0.804290, acc.: 47.66%] [G loss: 0.817855]\n",
      "epoch:9 step:8848 [D loss: 0.630467, acc.: 59.38%] [G loss: 1.095080]\n",
      "epoch:9 step:8849 [D loss: 0.718193, acc.: 53.91%] [G loss: 0.910009]\n",
      "epoch:9 step:8850 [D loss: 0.780876, acc.: 42.97%] [G loss: 0.746637]\n",
      "epoch:9 step:8851 [D loss: 0.645060, acc.: 64.06%] [G loss: 0.858162]\n",
      "epoch:9 step:8852 [D loss: 0.630469, acc.: 63.28%] [G loss: 0.922221]\n",
      "epoch:9 step:8853 [D loss: 0.671452, acc.: 61.72%] [G loss: 1.049600]\n",
      "epoch:9 step:8854 [D loss: 0.759770, acc.: 50.78%] [G loss: 0.873490]\n",
      "epoch:9 step:8855 [D loss: 0.646196, acc.: 58.59%] [G loss: 0.919150]\n",
      "epoch:9 step:8856 [D loss: 0.663566, acc.: 62.50%] [G loss: 0.888665]\n",
      "epoch:9 step:8857 [D loss: 0.704899, acc.: 57.03%] [G loss: 0.987488]\n",
      "epoch:9 step:8858 [D loss: 0.701949, acc.: 60.16%] [G loss: 0.925911]\n",
      "epoch:9 step:8859 [D loss: 0.639686, acc.: 68.75%] [G loss: 0.987465]\n",
      "epoch:9 step:8860 [D loss: 0.598173, acc.: 64.84%] [G loss: 1.063417]\n",
      "epoch:9 step:8861 [D loss: 0.524784, acc.: 74.22%] [G loss: 1.127755]\n",
      "epoch:9 step:8862 [D loss: 0.601695, acc.: 67.19%] [G loss: 0.898486]\n",
      "epoch:9 step:8863 [D loss: 0.653344, acc.: 63.28%] [G loss: 0.978402]\n",
      "epoch:9 step:8864 [D loss: 0.681067, acc.: 58.59%] [G loss: 1.013040]\n",
      "epoch:9 step:8865 [D loss: 0.721412, acc.: 53.91%] [G loss: 0.968957]\n",
      "epoch:9 step:8866 [D loss: 0.654653, acc.: 63.28%] [G loss: 0.864547]\n",
      "epoch:9 step:8867 [D loss: 0.628783, acc.: 66.41%] [G loss: 1.222525]\n",
      "epoch:9 step:8868 [D loss: 0.620447, acc.: 67.19%] [G loss: 0.947641]\n",
      "epoch:9 step:8869 [D loss: 0.644783, acc.: 59.38%] [G loss: 1.058286]\n",
      "epoch:9 step:8870 [D loss: 0.684843, acc.: 57.81%] [G loss: 0.996047]\n",
      "epoch:9 step:8871 [D loss: 0.625649, acc.: 66.41%] [G loss: 0.891268]\n",
      "epoch:9 step:8872 [D loss: 0.621022, acc.: 66.41%] [G loss: 0.968605]\n",
      "epoch:9 step:8873 [D loss: 0.712861, acc.: 52.34%] [G loss: 0.875055]\n",
      "epoch:9 step:8874 [D loss: 0.699880, acc.: 59.38%] [G loss: 0.905527]\n",
      "epoch:9 step:8875 [D loss: 0.637496, acc.: 67.19%] [G loss: 0.928213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8876 [D loss: 0.633868, acc.: 61.72%] [G loss: 0.976546]\n",
      "epoch:9 step:8877 [D loss: 0.624827, acc.: 63.28%] [G loss: 1.003247]\n",
      "epoch:9 step:8878 [D loss: 0.648305, acc.: 65.62%] [G loss: 0.890302]\n",
      "epoch:9 step:8879 [D loss: 0.695910, acc.: 54.69%] [G loss: 1.084266]\n",
      "epoch:9 step:8880 [D loss: 0.673082, acc.: 59.38%] [G loss: 0.899348]\n",
      "epoch:9 step:8881 [D loss: 0.709084, acc.: 57.03%] [G loss: 0.788727]\n",
      "epoch:9 step:8882 [D loss: 0.592663, acc.: 66.41%] [G loss: 0.952224]\n",
      "epoch:9 step:8883 [D loss: 0.659558, acc.: 55.47%] [G loss: 1.049765]\n",
      "epoch:9 step:8884 [D loss: 0.606271, acc.: 68.75%] [G loss: 1.065091]\n",
      "epoch:9 step:8885 [D loss: 0.673045, acc.: 60.16%] [G loss: 1.024129]\n",
      "epoch:9 step:8886 [D loss: 0.649590, acc.: 63.28%] [G loss: 0.934425]\n",
      "epoch:9 step:8887 [D loss: 0.558738, acc.: 72.66%] [G loss: 0.923159]\n",
      "epoch:9 step:8888 [D loss: 0.636124, acc.: 64.84%] [G loss: 1.050414]\n",
      "epoch:9 step:8889 [D loss: 0.613437, acc.: 67.19%] [G loss: 1.067330]\n",
      "epoch:9 step:8890 [D loss: 0.619988, acc.: 64.06%] [G loss: 1.025068]\n",
      "epoch:9 step:8891 [D loss: 0.736914, acc.: 52.34%] [G loss: 0.894318]\n",
      "epoch:9 step:8892 [D loss: 0.764953, acc.: 46.88%] [G loss: 0.923962]\n",
      "epoch:9 step:8893 [D loss: 0.718063, acc.: 51.56%] [G loss: 0.975454]\n",
      "epoch:9 step:8894 [D loss: 0.721712, acc.: 52.34%] [G loss: 0.809478]\n",
      "epoch:9 step:8895 [D loss: 0.773857, acc.: 45.31%] [G loss: 0.986488]\n",
      "epoch:9 step:8896 [D loss: 0.666958, acc.: 61.72%] [G loss: 0.961185]\n",
      "epoch:9 step:8897 [D loss: 0.682661, acc.: 56.25%] [G loss: 0.933721]\n",
      "epoch:9 step:8898 [D loss: 0.670876, acc.: 60.16%] [G loss: 0.955325]\n",
      "epoch:9 step:8899 [D loss: 0.654224, acc.: 62.50%] [G loss: 0.981772]\n",
      "epoch:9 step:8900 [D loss: 0.701597, acc.: 50.78%] [G loss: 0.928949]\n",
      "epoch:9 step:8901 [D loss: 0.566796, acc.: 72.66%] [G loss: 0.988037]\n",
      "epoch:9 step:8902 [D loss: 0.534862, acc.: 74.22%] [G loss: 1.082463]\n",
      "epoch:9 step:8903 [D loss: 0.630173, acc.: 65.62%] [G loss: 1.023811]\n",
      "epoch:9 step:8904 [D loss: 0.553462, acc.: 69.53%] [G loss: 1.025995]\n",
      "epoch:9 step:8905 [D loss: 0.711911, acc.: 50.00%] [G loss: 1.075400]\n",
      "epoch:9 step:8906 [D loss: 0.786381, acc.: 45.31%] [G loss: 0.940006]\n",
      "epoch:9 step:8907 [D loss: 0.685317, acc.: 59.38%] [G loss: 1.236579]\n",
      "epoch:9 step:8908 [D loss: 0.685150, acc.: 60.94%] [G loss: 1.049501]\n",
      "epoch:9 step:8909 [D loss: 0.639542, acc.: 69.53%] [G loss: 1.009564]\n",
      "epoch:9 step:8910 [D loss: 0.718811, acc.: 50.78%] [G loss: 0.970941]\n",
      "epoch:9 step:8911 [D loss: 0.741314, acc.: 50.78%] [G loss: 0.868819]\n",
      "epoch:9 step:8912 [D loss: 0.587167, acc.: 71.88%] [G loss: 0.980697]\n",
      "epoch:9 step:8913 [D loss: 0.720570, acc.: 46.09%] [G loss: 0.921742]\n",
      "epoch:9 step:8914 [D loss: 0.569274, acc.: 73.44%] [G loss: 0.971593]\n",
      "epoch:9 step:8915 [D loss: 0.654065, acc.: 60.16%] [G loss: 1.001846]\n",
      "epoch:9 step:8916 [D loss: 0.597596, acc.: 63.28%] [G loss: 0.955063]\n",
      "epoch:9 step:8917 [D loss: 0.565311, acc.: 72.66%] [G loss: 1.010798]\n",
      "epoch:9 step:8918 [D loss: 0.688976, acc.: 55.47%] [G loss: 0.898743]\n",
      "epoch:9 step:8919 [D loss: 0.657127, acc.: 60.94%] [G loss: 0.902847]\n",
      "epoch:9 step:8920 [D loss: 0.649016, acc.: 57.81%] [G loss: 0.949020]\n",
      "epoch:9 step:8921 [D loss: 0.577405, acc.: 74.22%] [G loss: 1.060784]\n",
      "epoch:9 step:8922 [D loss: 0.661953, acc.: 60.16%] [G loss: 0.860840]\n",
      "epoch:9 step:8923 [D loss: 0.614465, acc.: 67.19%] [G loss: 0.927832]\n",
      "epoch:9 step:8924 [D loss: 0.688260, acc.: 56.25%] [G loss: 1.066132]\n",
      "epoch:9 step:8925 [D loss: 0.761058, acc.: 46.88%] [G loss: 0.964393]\n",
      "epoch:9 step:8926 [D loss: 0.747128, acc.: 51.56%] [G loss: 0.862641]\n",
      "epoch:9 step:8927 [D loss: 0.700996, acc.: 57.03%] [G loss: 0.856540]\n",
      "epoch:9 step:8928 [D loss: 0.719077, acc.: 52.34%] [G loss: 0.895912]\n",
      "epoch:9 step:8929 [D loss: 0.675912, acc.: 54.69%] [G loss: 0.985587]\n",
      "epoch:9 step:8930 [D loss: 0.636140, acc.: 64.06%] [G loss: 1.080973]\n",
      "epoch:9 step:8931 [D loss: 0.613437, acc.: 66.41%] [G loss: 0.885097]\n",
      "epoch:9 step:8932 [D loss: 0.484663, acc.: 85.94%] [G loss: 0.991427]\n",
      "epoch:9 step:8933 [D loss: 0.704807, acc.: 58.59%] [G loss: 0.988532]\n",
      "epoch:9 step:8934 [D loss: 0.728072, acc.: 50.78%] [G loss: 1.057111]\n",
      "epoch:9 step:8935 [D loss: 0.683997, acc.: 55.47%] [G loss: 0.957686]\n",
      "epoch:9 step:8936 [D loss: 0.648581, acc.: 62.50%] [G loss: 0.827143]\n",
      "epoch:9 step:8937 [D loss: 0.624029, acc.: 63.28%] [G loss: 0.977026]\n",
      "epoch:9 step:8938 [D loss: 0.673277, acc.: 57.03%] [G loss: 0.966405]\n",
      "epoch:9 step:8939 [D loss: 0.613593, acc.: 65.62%] [G loss: 1.094866]\n",
      "epoch:9 step:8940 [D loss: 0.661015, acc.: 59.38%] [G loss: 0.863701]\n",
      "epoch:9 step:8941 [D loss: 0.566247, acc.: 75.78%] [G loss: 1.136438]\n",
      "epoch:9 step:8942 [D loss: 0.671264, acc.: 53.91%] [G loss: 0.953687]\n",
      "epoch:9 step:8943 [D loss: 0.639648, acc.: 61.72%] [G loss: 0.989318]\n",
      "epoch:9 step:8944 [D loss: 0.673785, acc.: 56.25%] [G loss: 0.895332]\n",
      "epoch:9 step:8945 [D loss: 0.666527, acc.: 56.25%] [G loss: 0.975168]\n",
      "epoch:9 step:8946 [D loss: 0.606913, acc.: 63.28%] [G loss: 0.823741]\n",
      "epoch:9 step:8947 [D loss: 0.653165, acc.: 60.94%] [G loss: 0.920765]\n",
      "epoch:9 step:8948 [D loss: 0.707281, acc.: 52.34%] [G loss: 0.917906]\n",
      "epoch:9 step:8949 [D loss: 0.650281, acc.: 59.38%] [G loss: 0.981452]\n",
      "epoch:9 step:8950 [D loss: 0.682881, acc.: 59.38%] [G loss: 1.117177]\n",
      "epoch:9 step:8951 [D loss: 0.852842, acc.: 33.59%] [G loss: 0.924669]\n",
      "epoch:9 step:8952 [D loss: 0.639950, acc.: 64.06%] [G loss: 0.977305]\n",
      "epoch:9 step:8953 [D loss: 0.684287, acc.: 58.59%] [G loss: 1.053325]\n",
      "epoch:9 step:8954 [D loss: 0.606870, acc.: 64.84%] [G loss: 0.848717]\n",
      "epoch:9 step:8955 [D loss: 0.552136, acc.: 73.44%] [G loss: 1.010991]\n",
      "epoch:9 step:8956 [D loss: 0.527434, acc.: 79.69%] [G loss: 1.108916]\n",
      "epoch:9 step:8957 [D loss: 0.768789, acc.: 46.09%] [G loss: 0.902242]\n",
      "epoch:9 step:8958 [D loss: 0.650817, acc.: 62.50%] [G loss: 1.010588]\n",
      "epoch:9 step:8959 [D loss: 0.594605, acc.: 69.53%] [G loss: 1.049595]\n",
      "epoch:9 step:8960 [D loss: 0.686978, acc.: 57.03%] [G loss: 0.853148]\n",
      "epoch:9 step:8961 [D loss: 0.761263, acc.: 46.88%] [G loss: 0.947895]\n",
      "epoch:9 step:8962 [D loss: 0.703521, acc.: 53.12%] [G loss: 0.960065]\n",
      "epoch:9 step:8963 [D loss: 0.690039, acc.: 52.34%] [G loss: 0.938181]\n",
      "epoch:9 step:8964 [D loss: 0.682279, acc.: 56.25%] [G loss: 0.885417]\n",
      "epoch:9 step:8965 [D loss: 0.630567, acc.: 62.50%] [G loss: 0.941815]\n",
      "epoch:9 step:8966 [D loss: 0.630055, acc.: 64.84%] [G loss: 0.842903]\n",
      "epoch:9 step:8967 [D loss: 0.640585, acc.: 63.28%] [G loss: 1.097414]\n",
      "epoch:9 step:8968 [D loss: 0.592809, acc.: 69.53%] [G loss: 1.066657]\n",
      "epoch:9 step:8969 [D loss: 0.593188, acc.: 66.41%] [G loss: 1.181395]\n",
      "epoch:9 step:8970 [D loss: 0.600326, acc.: 70.31%] [G loss: 1.147352]\n",
      "epoch:9 step:8971 [D loss: 0.661085, acc.: 62.50%] [G loss: 0.805073]\n",
      "epoch:9 step:8972 [D loss: 0.635920, acc.: 63.28%] [G loss: 0.999305]\n",
      "epoch:9 step:8973 [D loss: 0.603591, acc.: 71.09%] [G loss: 0.936366]\n",
      "epoch:9 step:8974 [D loss: 0.596455, acc.: 71.88%] [G loss: 1.053751]\n",
      "epoch:9 step:8975 [D loss: 0.678625, acc.: 58.59%] [G loss: 1.049637]\n",
      "epoch:9 step:8976 [D loss: 0.653508, acc.: 58.59%] [G loss: 0.928528]\n",
      "epoch:9 step:8977 [D loss: 0.652124, acc.: 60.94%] [G loss: 0.975593]\n",
      "epoch:9 step:8978 [D loss: 0.743479, acc.: 49.22%] [G loss: 0.889675]\n",
      "epoch:9 step:8979 [D loss: 0.639606, acc.: 62.50%] [G loss: 0.910649]\n",
      "epoch:9 step:8980 [D loss: 0.697050, acc.: 53.12%] [G loss: 1.147244]\n",
      "epoch:9 step:8981 [D loss: 0.611945, acc.: 64.06%] [G loss: 0.984401]\n",
      "epoch:9 step:8982 [D loss: 0.594803, acc.: 63.28%] [G loss: 0.944206]\n",
      "epoch:9 step:8983 [D loss: 0.592917, acc.: 67.19%] [G loss: 1.058100]\n",
      "epoch:9 step:8984 [D loss: 0.525708, acc.: 73.44%] [G loss: 1.122483]\n",
      "epoch:9 step:8985 [D loss: 0.649480, acc.: 64.06%] [G loss: 0.992984]\n",
      "epoch:9 step:8986 [D loss: 0.593095, acc.: 63.28%] [G loss: 1.042758]\n",
      "epoch:9 step:8987 [D loss: 0.613186, acc.: 65.62%] [G loss: 1.009049]\n",
      "epoch:9 step:8988 [D loss: 0.639545, acc.: 64.84%] [G loss: 1.086128]\n",
      "epoch:9 step:8989 [D loss: 0.519293, acc.: 76.56%] [G loss: 1.080177]\n",
      "epoch:9 step:8990 [D loss: 0.596973, acc.: 67.19%] [G loss: 0.830042]\n",
      "epoch:9 step:8991 [D loss: 0.661672, acc.: 57.81%] [G loss: 1.148326]\n",
      "epoch:9 step:8992 [D loss: 0.643917, acc.: 63.28%] [G loss: 1.220459]\n",
      "epoch:9 step:8993 [D loss: 0.721812, acc.: 51.56%] [G loss: 0.915518]\n",
      "epoch:9 step:8994 [D loss: 0.619490, acc.: 64.06%] [G loss: 1.072651]\n",
      "epoch:9 step:8995 [D loss: 0.756270, acc.: 46.09%] [G loss: 0.990137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8996 [D loss: 0.701219, acc.: 53.91%] [G loss: 0.909289]\n",
      "epoch:9 step:8997 [D loss: 0.679310, acc.: 54.69%] [G loss: 0.910995]\n",
      "epoch:9 step:8998 [D loss: 0.660723, acc.: 57.81%] [G loss: 0.912533]\n",
      "epoch:9 step:8999 [D loss: 0.590132, acc.: 66.41%] [G loss: 0.929790]\n",
      "epoch:9 step:9000 [D loss: 0.575580, acc.: 67.97%] [G loss: 0.913281]\n",
      "epoch:9 step:9001 [D loss: 0.590350, acc.: 66.41%] [G loss: 1.002435]\n",
      "epoch:9 step:9002 [D loss: 0.763510, acc.: 42.97%] [G loss: 0.887156]\n",
      "epoch:9 step:9003 [D loss: 0.637436, acc.: 61.72%] [G loss: 1.112052]\n",
      "epoch:9 step:9004 [D loss: 0.665950, acc.: 60.94%] [G loss: 0.921506]\n",
      "epoch:9 step:9005 [D loss: 0.724341, acc.: 54.69%] [G loss: 1.084888]\n",
      "epoch:9 step:9006 [D loss: 0.655536, acc.: 59.38%] [G loss: 0.863899]\n",
      "epoch:9 step:9007 [D loss: 0.600333, acc.: 67.97%] [G loss: 1.055032]\n",
      "epoch:9 step:9008 [D loss: 0.629099, acc.: 67.97%] [G loss: 0.993849]\n",
      "epoch:9 step:9009 [D loss: 0.688570, acc.: 60.94%] [G loss: 0.917611]\n",
      "epoch:9 step:9010 [D loss: 0.592582, acc.: 71.88%] [G loss: 0.946661]\n",
      "epoch:9 step:9011 [D loss: 0.604937, acc.: 65.62%] [G loss: 0.913393]\n",
      "epoch:9 step:9012 [D loss: 0.763041, acc.: 52.34%] [G loss: 0.948748]\n",
      "epoch:9 step:9013 [D loss: 0.712427, acc.: 55.47%] [G loss: 1.036109]\n",
      "epoch:9 step:9014 [D loss: 0.719231, acc.: 57.03%] [G loss: 1.106245]\n",
      "epoch:9 step:9015 [D loss: 0.716176, acc.: 50.78%] [G loss: 0.966343]\n",
      "epoch:9 step:9016 [D loss: 0.705398, acc.: 59.38%] [G loss: 0.892133]\n",
      "epoch:9 step:9017 [D loss: 0.697628, acc.: 57.03%] [G loss: 0.770763]\n",
      "epoch:9 step:9018 [D loss: 0.655214, acc.: 57.81%] [G loss: 0.875548]\n",
      "epoch:9 step:9019 [D loss: 0.726026, acc.: 50.00%] [G loss: 0.895985]\n",
      "epoch:9 step:9020 [D loss: 0.558499, acc.: 69.53%] [G loss: 1.154822]\n",
      "epoch:9 step:9021 [D loss: 0.623240, acc.: 65.62%] [G loss: 1.113324]\n",
      "epoch:9 step:9022 [D loss: 0.583305, acc.: 75.00%] [G loss: 1.111459]\n",
      "epoch:9 step:9023 [D loss: 0.633232, acc.: 64.84%] [G loss: 1.169546]\n",
      "epoch:9 step:9024 [D loss: 0.691965, acc.: 55.47%] [G loss: 0.931631]\n",
      "epoch:9 step:9025 [D loss: 0.649503, acc.: 63.28%] [G loss: 1.015483]\n",
      "epoch:9 step:9026 [D loss: 0.675895, acc.: 57.81%] [G loss: 0.892815]\n",
      "epoch:9 step:9027 [D loss: 0.723780, acc.: 55.47%] [G loss: 1.049024]\n",
      "epoch:9 step:9028 [D loss: 0.596056, acc.: 71.88%] [G loss: 1.091759]\n",
      "epoch:9 step:9029 [D loss: 0.689916, acc.: 53.91%] [G loss: 0.931516]\n",
      "epoch:9 step:9030 [D loss: 0.780032, acc.: 36.72%] [G loss: 1.009791]\n",
      "epoch:9 step:9031 [D loss: 0.621361, acc.: 65.62%] [G loss: 1.076705]\n",
      "epoch:9 step:9032 [D loss: 0.716394, acc.: 50.78%] [G loss: 1.044248]\n",
      "epoch:9 step:9033 [D loss: 0.709427, acc.: 56.25%] [G loss: 0.971966]\n",
      "epoch:9 step:9034 [D loss: 0.677719, acc.: 60.94%] [G loss: 0.890009]\n",
      "epoch:9 step:9035 [D loss: 0.686904, acc.: 60.16%] [G loss: 0.907996]\n",
      "epoch:9 step:9036 [D loss: 0.602690, acc.: 61.72%] [G loss: 0.901019]\n",
      "epoch:9 step:9037 [D loss: 0.614285, acc.: 64.06%] [G loss: 0.930057]\n",
      "epoch:9 step:9038 [D loss: 0.579355, acc.: 75.00%] [G loss: 1.095672]\n",
      "epoch:9 step:9039 [D loss: 0.664942, acc.: 57.81%] [G loss: 0.906021]\n",
      "epoch:9 step:9040 [D loss: 0.667251, acc.: 58.59%] [G loss: 0.933443]\n",
      "epoch:9 step:9041 [D loss: 0.571677, acc.: 73.44%] [G loss: 0.982187]\n",
      "epoch:9 step:9042 [D loss: 0.711839, acc.: 50.78%] [G loss: 1.077570]\n",
      "epoch:9 step:9043 [D loss: 0.633946, acc.: 64.06%] [G loss: 1.028679]\n",
      "epoch:9 step:9044 [D loss: 0.623792, acc.: 66.41%] [G loss: 0.919242]\n",
      "epoch:9 step:9045 [D loss: 0.646305, acc.: 62.50%] [G loss: 1.003238]\n",
      "epoch:9 step:9046 [D loss: 0.625940, acc.: 67.19%] [G loss: 0.916198]\n",
      "epoch:9 step:9047 [D loss: 0.653985, acc.: 60.16%] [G loss: 0.879938]\n",
      "epoch:9 step:9048 [D loss: 0.686249, acc.: 57.81%] [G loss: 0.782874]\n",
      "epoch:9 step:9049 [D loss: 0.671388, acc.: 54.69%] [G loss: 0.938385]\n",
      "epoch:9 step:9050 [D loss: 0.645674, acc.: 62.50%] [G loss: 0.902035]\n",
      "epoch:9 step:9051 [D loss: 0.587700, acc.: 71.88%] [G loss: 0.944886]\n",
      "epoch:9 step:9052 [D loss: 0.724388, acc.: 50.78%] [G loss: 1.039095]\n",
      "epoch:9 step:9053 [D loss: 0.685237, acc.: 57.03%] [G loss: 0.849159]\n",
      "epoch:9 step:9054 [D loss: 0.634873, acc.: 61.72%] [G loss: 0.936063]\n",
      "epoch:9 step:9055 [D loss: 0.742659, acc.: 48.44%] [G loss: 0.907753]\n",
      "epoch:9 step:9056 [D loss: 0.598311, acc.: 68.75%] [G loss: 1.063950]\n",
      "epoch:9 step:9057 [D loss: 0.633933, acc.: 67.19%] [G loss: 0.987907]\n",
      "epoch:9 step:9058 [D loss: 0.719102, acc.: 57.03%] [G loss: 0.891457]\n",
      "epoch:9 step:9059 [D loss: 0.626992, acc.: 61.72%] [G loss: 1.039073]\n",
      "epoch:9 step:9060 [D loss: 0.721881, acc.: 52.34%] [G loss: 0.965565]\n",
      "epoch:9 step:9061 [D loss: 0.743454, acc.: 46.88%] [G loss: 0.951575]\n",
      "epoch:9 step:9062 [D loss: 0.624681, acc.: 64.84%] [G loss: 1.028290]\n",
      "epoch:9 step:9063 [D loss: 0.714112, acc.: 56.25%] [G loss: 0.899678]\n",
      "epoch:9 step:9064 [D loss: 0.645006, acc.: 61.72%] [G loss: 1.179443]\n",
      "epoch:9 step:9065 [D loss: 0.625320, acc.: 62.50%] [G loss: 1.153791]\n",
      "epoch:9 step:9066 [D loss: 0.640177, acc.: 64.84%] [G loss: 1.057255]\n",
      "epoch:9 step:9067 [D loss: 0.624178, acc.: 66.41%] [G loss: 1.157242]\n",
      "epoch:9 step:9068 [D loss: 0.603822, acc.: 64.84%] [G loss: 0.967895]\n",
      "epoch:9 step:9069 [D loss: 0.645306, acc.: 64.06%] [G loss: 0.933281]\n",
      "epoch:9 step:9070 [D loss: 0.618057, acc.: 62.50%] [G loss: 1.221175]\n",
      "epoch:9 step:9071 [D loss: 0.707581, acc.: 56.25%] [G loss: 0.875289]\n",
      "epoch:9 step:9072 [D loss: 0.705819, acc.: 57.03%] [G loss: 0.983541]\n",
      "epoch:9 step:9073 [D loss: 0.690091, acc.: 55.47%] [G loss: 0.985242]\n",
      "epoch:9 step:9074 [D loss: 0.615894, acc.: 64.84%] [G loss: 1.077275]\n",
      "epoch:9 step:9075 [D loss: 0.581495, acc.: 69.53%] [G loss: 0.930803]\n",
      "epoch:9 step:9076 [D loss: 0.654329, acc.: 62.50%] [G loss: 1.033618]\n",
      "epoch:9 step:9077 [D loss: 0.699385, acc.: 54.69%] [G loss: 0.925655]\n",
      "epoch:9 step:9078 [D loss: 0.651375, acc.: 60.16%] [G loss: 0.967963]\n",
      "epoch:9 step:9079 [D loss: 0.616464, acc.: 67.19%] [G loss: 0.894011]\n",
      "epoch:9 step:9080 [D loss: 0.627393, acc.: 66.41%] [G loss: 0.942737]\n",
      "epoch:9 step:9081 [D loss: 0.639785, acc.: 60.94%] [G loss: 1.033505]\n",
      "epoch:9 step:9082 [D loss: 0.565284, acc.: 77.34%] [G loss: 1.184199]\n",
      "epoch:9 step:9083 [D loss: 0.608796, acc.: 67.97%] [G loss: 0.928433]\n",
      "epoch:9 step:9084 [D loss: 0.648874, acc.: 57.81%] [G loss: 0.918824]\n",
      "epoch:9 step:9085 [D loss: 0.724094, acc.: 51.56%] [G loss: 0.955478]\n",
      "epoch:9 step:9086 [D loss: 0.748771, acc.: 50.00%] [G loss: 0.867326]\n",
      "epoch:9 step:9087 [D loss: 0.728757, acc.: 50.00%] [G loss: 0.856449]\n",
      "epoch:9 step:9088 [D loss: 0.670716, acc.: 61.72%] [G loss: 0.999843]\n",
      "epoch:9 step:9089 [D loss: 0.738847, acc.: 46.09%] [G loss: 0.928029]\n",
      "epoch:9 step:9090 [D loss: 0.724694, acc.: 52.34%] [G loss: 0.958262]\n",
      "epoch:9 step:9091 [D loss: 0.660880, acc.: 57.03%] [G loss: 0.991129]\n",
      "epoch:9 step:9092 [D loss: 0.615336, acc.: 69.53%] [G loss: 0.887842]\n",
      "epoch:9 step:9093 [D loss: 0.623234, acc.: 66.41%] [G loss: 1.064414]\n",
      "epoch:9 step:9094 [D loss: 0.633977, acc.: 65.62%] [G loss: 1.035647]\n",
      "epoch:9 step:9095 [D loss: 0.638497, acc.: 61.72%] [G loss: 1.116778]\n",
      "epoch:9 step:9096 [D loss: 0.614416, acc.: 64.84%] [G loss: 1.085980]\n",
      "epoch:9 step:9097 [D loss: 0.650303, acc.: 58.59%] [G loss: 1.087937]\n",
      "epoch:9 step:9098 [D loss: 0.613353, acc.: 67.19%] [G loss: 0.912737]\n",
      "epoch:9 step:9099 [D loss: 0.614041, acc.: 62.50%] [G loss: 1.016227]\n",
      "epoch:9 step:9100 [D loss: 0.683740, acc.: 57.81%] [G loss: 1.066273]\n",
      "epoch:9 step:9101 [D loss: 0.666366, acc.: 63.28%] [G loss: 0.969207]\n",
      "epoch:9 step:9102 [D loss: 0.637259, acc.: 64.84%] [G loss: 1.007885]\n",
      "epoch:9 step:9103 [D loss: 0.650287, acc.: 60.16%] [G loss: 0.953775]\n",
      "epoch:9 step:9104 [D loss: 0.654033, acc.: 60.16%] [G loss: 0.997039]\n",
      "epoch:9 step:9105 [D loss: 0.621941, acc.: 67.19%] [G loss: 0.947148]\n",
      "epoch:9 step:9106 [D loss: 0.796057, acc.: 43.75%] [G loss: 0.811931]\n",
      "epoch:9 step:9107 [D loss: 0.731684, acc.: 51.56%] [G loss: 0.899061]\n",
      "epoch:9 step:9108 [D loss: 0.709328, acc.: 48.44%] [G loss: 0.961308]\n",
      "epoch:9 step:9109 [D loss: 0.641354, acc.: 64.84%] [G loss: 1.037986]\n",
      "epoch:9 step:9110 [D loss: 0.706007, acc.: 57.03%] [G loss: 1.054424]\n",
      "epoch:9 step:9111 [D loss: 0.662564, acc.: 60.16%] [G loss: 1.004097]\n",
      "epoch:9 step:9112 [D loss: 0.582960, acc.: 64.06%] [G loss: 1.024359]\n",
      "epoch:9 step:9113 [D loss: 0.618884, acc.: 65.62%] [G loss: 0.922115]\n",
      "epoch:9 step:9114 [D loss: 0.652051, acc.: 56.25%] [G loss: 0.997465]\n",
      "epoch:9 step:9115 [D loss: 0.643384, acc.: 57.81%] [G loss: 1.045455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9116 [D loss: 0.640375, acc.: 64.84%] [G loss: 0.919282]\n",
      "epoch:9 step:9117 [D loss: 0.609149, acc.: 66.41%] [G loss: 0.963312]\n",
      "epoch:9 step:9118 [D loss: 0.637224, acc.: 60.94%] [G loss: 0.948649]\n",
      "epoch:9 step:9119 [D loss: 0.645929, acc.: 62.50%] [G loss: 0.988508]\n",
      "epoch:9 step:9120 [D loss: 0.661088, acc.: 60.94%] [G loss: 0.932403]\n",
      "epoch:9 step:9121 [D loss: 0.666726, acc.: 57.03%] [G loss: 0.977670]\n",
      "epoch:9 step:9122 [D loss: 0.553061, acc.: 73.44%] [G loss: 0.987046]\n",
      "epoch:9 step:9123 [D loss: 0.571606, acc.: 72.66%] [G loss: 0.942024]\n",
      "epoch:9 step:9124 [D loss: 0.575828, acc.: 70.31%] [G loss: 1.063642]\n",
      "epoch:9 step:9125 [D loss: 0.611292, acc.: 64.06%] [G loss: 1.050083]\n",
      "epoch:9 step:9126 [D loss: 0.563706, acc.: 74.22%] [G loss: 1.030497]\n",
      "epoch:9 step:9127 [D loss: 0.643101, acc.: 63.28%] [G loss: 0.985594]\n",
      "epoch:9 step:9128 [D loss: 0.665552, acc.: 58.59%] [G loss: 0.964134]\n",
      "epoch:9 step:9129 [D loss: 0.732423, acc.: 48.44%] [G loss: 0.912241]\n",
      "epoch:9 step:9130 [D loss: 0.646393, acc.: 64.84%] [G loss: 0.944150]\n",
      "epoch:9 step:9131 [D loss: 0.665100, acc.: 59.38%] [G loss: 0.967152]\n",
      "epoch:9 step:9132 [D loss: 0.692362, acc.: 60.16%] [G loss: 0.923659]\n",
      "epoch:9 step:9133 [D loss: 0.612849, acc.: 67.19%] [G loss: 0.989065]\n",
      "epoch:9 step:9134 [D loss: 0.614003, acc.: 66.41%] [G loss: 1.069467]\n",
      "epoch:9 step:9135 [D loss: 0.658348, acc.: 59.38%] [G loss: 1.006984]\n",
      "epoch:9 step:9136 [D loss: 0.681186, acc.: 60.16%] [G loss: 0.872472]\n",
      "epoch:9 step:9137 [D loss: 0.699742, acc.: 62.50%] [G loss: 0.945766]\n",
      "epoch:9 step:9138 [D loss: 0.694074, acc.: 54.69%] [G loss: 1.068542]\n",
      "epoch:9 step:9139 [D loss: 0.588598, acc.: 68.75%] [G loss: 1.099809]\n",
      "epoch:9 step:9140 [D loss: 0.487971, acc.: 81.25%] [G loss: 0.980136]\n",
      "epoch:9 step:9141 [D loss: 0.560689, acc.: 70.31%] [G loss: 1.138210]\n",
      "epoch:9 step:9142 [D loss: 0.527250, acc.: 75.00%] [G loss: 1.241250]\n",
      "epoch:9 step:9143 [D loss: 0.711852, acc.: 50.78%] [G loss: 1.161912]\n",
      "epoch:9 step:9144 [D loss: 0.685499, acc.: 58.59%] [G loss: 0.950797]\n",
      "epoch:9 step:9145 [D loss: 0.740785, acc.: 48.44%] [G loss: 0.826703]\n",
      "epoch:9 step:9146 [D loss: 0.551241, acc.: 70.31%] [G loss: 1.030492]\n",
      "epoch:9 step:9147 [D loss: 0.580299, acc.: 68.75%] [G loss: 1.135613]\n",
      "epoch:9 step:9148 [D loss: 0.732165, acc.: 50.00%] [G loss: 0.946307]\n",
      "epoch:9 step:9149 [D loss: 0.678512, acc.: 60.16%] [G loss: 0.987272]\n",
      "epoch:9 step:9150 [D loss: 0.682190, acc.: 55.47%] [G loss: 0.909549]\n",
      "epoch:9 step:9151 [D loss: 0.750334, acc.: 47.66%] [G loss: 0.863155]\n",
      "epoch:9 step:9152 [D loss: 0.680218, acc.: 56.25%] [G loss: 0.989880]\n",
      "epoch:9 step:9153 [D loss: 0.686508, acc.: 61.72%] [G loss: 0.917211]\n",
      "epoch:9 step:9154 [D loss: 0.611062, acc.: 65.62%] [G loss: 0.954939]\n",
      "epoch:9 step:9155 [D loss: 0.616063, acc.: 64.06%] [G loss: 0.903179]\n",
      "epoch:9 step:9156 [D loss: 0.638621, acc.: 64.06%] [G loss: 0.902602]\n",
      "epoch:9 step:9157 [D loss: 0.577959, acc.: 71.88%] [G loss: 1.008216]\n",
      "epoch:9 step:9158 [D loss: 0.639577, acc.: 65.62%] [G loss: 1.037078]\n",
      "epoch:9 step:9159 [D loss: 0.638323, acc.: 58.59%] [G loss: 0.981489]\n",
      "epoch:9 step:9160 [D loss: 0.695191, acc.: 52.34%] [G loss: 0.864392]\n",
      "epoch:9 step:9161 [D loss: 0.636632, acc.: 67.19%] [G loss: 0.923686]\n",
      "epoch:9 step:9162 [D loss: 0.583440, acc.: 67.97%] [G loss: 0.986031]\n",
      "epoch:9 step:9163 [D loss: 0.584867, acc.: 67.97%] [G loss: 1.090570]\n",
      "epoch:9 step:9164 [D loss: 0.635560, acc.: 64.06%] [G loss: 1.017887]\n",
      "epoch:9 step:9165 [D loss: 0.528061, acc.: 78.12%] [G loss: 1.036806]\n",
      "epoch:9 step:9166 [D loss: 0.549970, acc.: 73.44%] [G loss: 0.991081]\n",
      "epoch:9 step:9167 [D loss: 0.714125, acc.: 58.59%] [G loss: 0.860876]\n",
      "epoch:9 step:9168 [D loss: 0.710393, acc.: 53.91%] [G loss: 1.053558]\n",
      "epoch:9 step:9169 [D loss: 0.676972, acc.: 55.47%] [G loss: 0.972936]\n",
      "epoch:9 step:9170 [D loss: 0.612699, acc.: 65.62%] [G loss: 0.856455]\n",
      "epoch:9 step:9171 [D loss: 0.649704, acc.: 66.41%] [G loss: 0.974222]\n",
      "epoch:9 step:9172 [D loss: 0.688234, acc.: 57.81%] [G loss: 1.007721]\n",
      "epoch:9 step:9173 [D loss: 0.579279, acc.: 74.22%] [G loss: 1.000708]\n",
      "epoch:9 step:9174 [D loss: 0.686950, acc.: 56.25%] [G loss: 1.000947]\n",
      "epoch:9 step:9175 [D loss: 0.715035, acc.: 54.69%] [G loss: 0.949732]\n",
      "epoch:9 step:9176 [D loss: 0.678634, acc.: 52.34%] [G loss: 0.821800]\n",
      "epoch:9 step:9177 [D loss: 0.715774, acc.: 53.12%] [G loss: 0.879503]\n",
      "epoch:9 step:9178 [D loss: 0.575907, acc.: 67.97%] [G loss: 1.032230]\n",
      "epoch:9 step:9179 [D loss: 0.598428, acc.: 69.53%] [G loss: 0.960050]\n",
      "epoch:9 step:9180 [D loss: 0.744830, acc.: 51.56%] [G loss: 0.876920]\n",
      "epoch:9 step:9181 [D loss: 0.661795, acc.: 63.28%] [G loss: 0.914247]\n",
      "epoch:9 step:9182 [D loss: 0.694301, acc.: 53.12%] [G loss: 1.011065]\n",
      "epoch:9 step:9183 [D loss: 0.696173, acc.: 52.34%] [G loss: 0.992163]\n",
      "epoch:9 step:9184 [D loss: 0.687060, acc.: 58.59%] [G loss: 0.901424]\n",
      "epoch:9 step:9185 [D loss: 0.693554, acc.: 54.69%] [G loss: 0.989302]\n",
      "epoch:9 step:9186 [D loss: 0.669960, acc.: 60.16%] [G loss: 1.043757]\n",
      "epoch:9 step:9187 [D loss: 0.651347, acc.: 62.50%] [G loss: 0.848874]\n",
      "epoch:9 step:9188 [D loss: 0.615764, acc.: 65.62%] [G loss: 0.979527]\n",
      "epoch:9 step:9189 [D loss: 0.623093, acc.: 62.50%] [G loss: 0.995276]\n",
      "epoch:9 step:9190 [D loss: 0.634157, acc.: 65.62%] [G loss: 1.022686]\n",
      "epoch:9 step:9191 [D loss: 0.731528, acc.: 48.44%] [G loss: 1.010059]\n",
      "epoch:9 step:9192 [D loss: 0.712101, acc.: 53.12%] [G loss: 1.042086]\n",
      "epoch:9 step:9193 [D loss: 0.758453, acc.: 49.22%] [G loss: 0.802545]\n",
      "epoch:9 step:9194 [D loss: 0.658754, acc.: 61.72%] [G loss: 0.989113]\n",
      "epoch:9 step:9195 [D loss: 0.703302, acc.: 50.00%] [G loss: 0.895649]\n",
      "epoch:9 step:9196 [D loss: 0.596806, acc.: 70.31%] [G loss: 0.985969]\n",
      "epoch:9 step:9197 [D loss: 0.722975, acc.: 51.56%] [G loss: 0.914053]\n",
      "epoch:9 step:9198 [D loss: 0.688779, acc.: 57.03%] [G loss: 0.853876]\n",
      "epoch:9 step:9199 [D loss: 0.718026, acc.: 56.25%] [G loss: 0.962300]\n",
      "epoch:9 step:9200 [D loss: 0.636575, acc.: 60.94%] [G loss: 0.989799]\n",
      "epoch:9 step:9201 [D loss: 0.642270, acc.: 63.28%] [G loss: 0.888742]\n",
      "epoch:9 step:9202 [D loss: 0.601425, acc.: 67.97%] [G loss: 0.942627]\n",
      "epoch:9 step:9203 [D loss: 0.685929, acc.: 58.59%] [G loss: 0.986068]\n",
      "epoch:9 step:9204 [D loss: 0.670566, acc.: 64.06%] [G loss: 1.040111]\n",
      "epoch:9 step:9205 [D loss: 0.738279, acc.: 53.91%] [G loss: 0.859601]\n",
      "epoch:9 step:9206 [D loss: 0.664606, acc.: 61.72%] [G loss: 0.883452]\n",
      "epoch:9 step:9207 [D loss: 0.500014, acc.: 84.38%] [G loss: 0.974507]\n",
      "epoch:9 step:9208 [D loss: 0.562128, acc.: 71.09%] [G loss: 1.137468]\n",
      "epoch:9 step:9209 [D loss: 0.601824, acc.: 64.84%] [G loss: 1.062940]\n",
      "epoch:9 step:9210 [D loss: 0.645563, acc.: 63.28%] [G loss: 0.998050]\n",
      "epoch:9 step:9211 [D loss: 0.620366, acc.: 64.84%] [G loss: 1.011816]\n",
      "epoch:9 step:9212 [D loss: 0.689695, acc.: 53.91%] [G loss: 1.097699]\n",
      "epoch:9 step:9213 [D loss: 0.651124, acc.: 64.84%] [G loss: 1.092837]\n",
      "epoch:9 step:9214 [D loss: 0.681369, acc.: 60.94%] [G loss: 0.929531]\n",
      "epoch:9 step:9215 [D loss: 0.629711, acc.: 63.28%] [G loss: 0.929567]\n",
      "epoch:9 step:9216 [D loss: 0.719920, acc.: 55.47%] [G loss: 0.980199]\n",
      "epoch:9 step:9217 [D loss: 0.660766, acc.: 62.50%] [G loss: 0.989128]\n",
      "epoch:9 step:9218 [D loss: 0.683033, acc.: 61.72%] [G loss: 1.062265]\n",
      "epoch:9 step:9219 [D loss: 0.613526, acc.: 68.75%] [G loss: 1.105080]\n",
      "epoch:9 step:9220 [D loss: 0.710211, acc.: 54.69%] [G loss: 0.856899]\n",
      "epoch:9 step:9221 [D loss: 0.655331, acc.: 60.94%] [G loss: 0.984582]\n",
      "epoch:9 step:9222 [D loss: 0.643569, acc.: 61.72%] [G loss: 0.966504]\n",
      "epoch:9 step:9223 [D loss: 0.601351, acc.: 64.06%] [G loss: 0.995675]\n",
      "epoch:9 step:9224 [D loss: 0.586611, acc.: 70.31%] [G loss: 1.028628]\n",
      "epoch:9 step:9225 [D loss: 0.545175, acc.: 75.00%] [G loss: 1.116637]\n",
      "epoch:9 step:9226 [D loss: 0.665909, acc.: 62.50%] [G loss: 0.925958]\n",
      "epoch:9 step:9227 [D loss: 0.645703, acc.: 63.28%] [G loss: 0.952456]\n",
      "epoch:9 step:9228 [D loss: 0.622036, acc.: 64.84%] [G loss: 0.893279]\n",
      "epoch:9 step:9229 [D loss: 0.619296, acc.: 66.41%] [G loss: 0.909308]\n",
      "epoch:9 step:9230 [D loss: 0.730023, acc.: 53.12%] [G loss: 0.886627]\n",
      "epoch:9 step:9231 [D loss: 0.706518, acc.: 52.34%] [G loss: 0.969614]\n",
      "epoch:9 step:9232 [D loss: 0.648675, acc.: 60.94%] [G loss: 1.031981]\n",
      "epoch:9 step:9233 [D loss: 0.785910, acc.: 42.97%] [G loss: 0.947905]\n",
      "epoch:9 step:9234 [D loss: 0.692653, acc.: 56.25%] [G loss: 0.929039]\n",
      "epoch:9 step:9235 [D loss: 0.632487, acc.: 64.84%] [G loss: 1.025485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9236 [D loss: 0.602583, acc.: 66.41%] [G loss: 0.819420]\n",
      "epoch:9 step:9237 [D loss: 0.609449, acc.: 69.53%] [G loss: 1.009310]\n",
      "epoch:9 step:9238 [D loss: 0.609628, acc.: 71.09%] [G loss: 0.917858]\n",
      "epoch:9 step:9239 [D loss: 0.549999, acc.: 79.69%] [G loss: 1.083824]\n",
      "epoch:9 step:9240 [D loss: 0.621603, acc.: 69.53%] [G loss: 0.946662]\n",
      "epoch:9 step:9241 [D loss: 0.602439, acc.: 67.97%] [G loss: 1.096921]\n",
      "epoch:9 step:9242 [D loss: 0.656692, acc.: 60.16%] [G loss: 0.880737]\n",
      "epoch:9 step:9243 [D loss: 0.580240, acc.: 71.09%] [G loss: 0.999823]\n",
      "epoch:9 step:9244 [D loss: 0.631534, acc.: 64.06%] [G loss: 0.997348]\n",
      "epoch:9 step:9245 [D loss: 0.694201, acc.: 53.91%] [G loss: 0.892200]\n",
      "epoch:9 step:9246 [D loss: 0.715481, acc.: 53.91%] [G loss: 0.967213]\n",
      "epoch:9 step:9247 [D loss: 0.627675, acc.: 64.06%] [G loss: 0.899492]\n",
      "epoch:9 step:9248 [D loss: 0.613234, acc.: 67.19%] [G loss: 0.948975]\n",
      "epoch:9 step:9249 [D loss: 0.604842, acc.: 70.31%] [G loss: 1.100056]\n",
      "epoch:9 step:9250 [D loss: 0.647113, acc.: 61.72%] [G loss: 1.072939]\n",
      "epoch:9 step:9251 [D loss: 0.637412, acc.: 60.94%] [G loss: 1.104561]\n",
      "epoch:9 step:9252 [D loss: 0.680023, acc.: 57.81%] [G loss: 0.889114]\n",
      "epoch:9 step:9253 [D loss: 0.741810, acc.: 50.78%] [G loss: 1.051743]\n",
      "epoch:9 step:9254 [D loss: 0.632406, acc.: 65.62%] [G loss: 0.997087]\n",
      "epoch:9 step:9255 [D loss: 0.598531, acc.: 64.06%] [G loss: 0.992765]\n",
      "epoch:9 step:9256 [D loss: 0.588731, acc.: 71.88%] [G loss: 0.990485]\n",
      "epoch:9 step:9257 [D loss: 0.673184, acc.: 58.59%] [G loss: 0.950629]\n",
      "epoch:9 step:9258 [D loss: 0.522845, acc.: 79.69%] [G loss: 1.021048]\n",
      "epoch:9 step:9259 [D loss: 0.642363, acc.: 65.62%] [G loss: 0.863983]\n",
      "epoch:9 step:9260 [D loss: 0.751341, acc.: 46.88%] [G loss: 0.948701]\n",
      "epoch:9 step:9261 [D loss: 0.663552, acc.: 56.25%] [G loss: 0.866128]\n",
      "epoch:9 step:9262 [D loss: 0.710958, acc.: 54.69%] [G loss: 0.780984]\n",
      "epoch:9 step:9263 [D loss: 0.668397, acc.: 60.16%] [G loss: 1.102153]\n",
      "epoch:9 step:9264 [D loss: 0.644679, acc.: 59.38%] [G loss: 0.861890]\n",
      "epoch:9 step:9265 [D loss: 0.585776, acc.: 72.66%] [G loss: 1.101652]\n",
      "epoch:9 step:9266 [D loss: 0.585968, acc.: 67.19%] [G loss: 1.101830]\n",
      "epoch:9 step:9267 [D loss: 0.666042, acc.: 59.38%] [G loss: 1.039165]\n",
      "epoch:9 step:9268 [D loss: 0.613154, acc.: 64.84%] [G loss: 1.105897]\n",
      "epoch:9 step:9269 [D loss: 0.688076, acc.: 59.38%] [G loss: 1.019511]\n",
      "epoch:9 step:9270 [D loss: 0.670186, acc.: 63.28%] [G loss: 0.914803]\n",
      "epoch:9 step:9271 [D loss: 0.658960, acc.: 61.72%] [G loss: 1.108856]\n",
      "epoch:9 step:9272 [D loss: 0.634098, acc.: 65.62%] [G loss: 1.006330]\n",
      "epoch:9 step:9273 [D loss: 0.601724, acc.: 67.97%] [G loss: 1.038874]\n",
      "epoch:9 step:9274 [D loss: 0.799092, acc.: 43.75%] [G loss: 0.890813]\n",
      "epoch:9 step:9275 [D loss: 0.609705, acc.: 67.97%] [G loss: 0.862939]\n",
      "epoch:9 step:9276 [D loss: 0.630867, acc.: 60.94%] [G loss: 0.989000]\n",
      "epoch:9 step:9277 [D loss: 0.793322, acc.: 41.41%] [G loss: 0.917239]\n",
      "epoch:9 step:9278 [D loss: 0.729362, acc.: 47.66%] [G loss: 0.938259]\n",
      "epoch:9 step:9279 [D loss: 0.683209, acc.: 58.59%] [G loss: 0.965085]\n",
      "epoch:9 step:9280 [D loss: 0.656389, acc.: 64.06%] [G loss: 0.952716]\n",
      "epoch:9 step:9281 [D loss: 0.656379, acc.: 60.94%] [G loss: 0.937869]\n",
      "epoch:9 step:9282 [D loss: 0.578542, acc.: 75.78%] [G loss: 0.913142]\n",
      "epoch:9 step:9283 [D loss: 0.632666, acc.: 67.97%] [G loss: 0.877026]\n",
      "epoch:9 step:9284 [D loss: 0.617279, acc.: 64.84%] [G loss: 1.005909]\n",
      "epoch:9 step:9285 [D loss: 0.587619, acc.: 70.31%] [G loss: 0.990844]\n",
      "epoch:9 step:9286 [D loss: 0.601864, acc.: 67.19%] [G loss: 1.055383]\n",
      "epoch:9 step:9287 [D loss: 0.571478, acc.: 73.44%] [G loss: 1.151991]\n",
      "epoch:9 step:9288 [D loss: 0.596410, acc.: 68.75%] [G loss: 1.109293]\n",
      "epoch:9 step:9289 [D loss: 0.739153, acc.: 49.22%] [G loss: 0.924804]\n",
      "epoch:9 step:9290 [D loss: 0.587442, acc.: 66.41%] [G loss: 1.060087]\n",
      "epoch:9 step:9291 [D loss: 0.733468, acc.: 53.12%] [G loss: 1.082577]\n",
      "epoch:9 step:9292 [D loss: 0.730829, acc.: 52.34%] [G loss: 0.967200]\n",
      "epoch:9 step:9293 [D loss: 0.744760, acc.: 45.31%] [G loss: 0.965275]\n",
      "epoch:9 step:9294 [D loss: 0.679815, acc.: 57.81%] [G loss: 0.885643]\n",
      "epoch:9 step:9295 [D loss: 0.682554, acc.: 58.59%] [G loss: 0.847281]\n",
      "epoch:9 step:9296 [D loss: 0.625647, acc.: 57.81%] [G loss: 0.945691]\n",
      "epoch:9 step:9297 [D loss: 0.659803, acc.: 60.16%] [G loss: 0.929912]\n",
      "epoch:9 step:9298 [D loss: 0.734011, acc.: 53.12%] [G loss: 0.827727]\n",
      "epoch:9 step:9299 [D loss: 0.686448, acc.: 55.47%] [G loss: 0.916440]\n",
      "epoch:9 step:9300 [D loss: 0.682887, acc.: 57.81%] [G loss: 0.862028]\n",
      "epoch:9 step:9301 [D loss: 0.627341, acc.: 67.19%] [G loss: 0.965144]\n",
      "epoch:9 step:9302 [D loss: 0.679746, acc.: 56.25%] [G loss: 0.901267]\n",
      "epoch:9 step:9303 [D loss: 0.679020, acc.: 53.91%] [G loss: 0.855885]\n",
      "epoch:9 step:9304 [D loss: 0.731825, acc.: 52.34%] [G loss: 0.795219]\n",
      "epoch:9 step:9305 [D loss: 0.654227, acc.: 63.28%] [G loss: 1.051335]\n",
      "epoch:9 step:9306 [D loss: 0.746947, acc.: 53.12%] [G loss: 0.775330]\n",
      "epoch:9 step:9307 [D loss: 0.674481, acc.: 56.25%] [G loss: 1.012208]\n",
      "epoch:9 step:9308 [D loss: 0.620021, acc.: 60.94%] [G loss: 1.023479]\n",
      "epoch:9 step:9309 [D loss: 0.631379, acc.: 64.06%] [G loss: 0.931354]\n",
      "epoch:9 step:9310 [D loss: 0.630620, acc.: 66.41%] [G loss: 1.070815]\n",
      "epoch:9 step:9311 [D loss: 0.622555, acc.: 64.06%] [G loss: 1.051206]\n",
      "epoch:9 step:9312 [D loss: 0.612870, acc.: 65.62%] [G loss: 0.976030]\n",
      "epoch:9 step:9313 [D loss: 0.706872, acc.: 57.03%] [G loss: 0.927329]\n",
      "epoch:9 step:9314 [D loss: 0.722337, acc.: 59.38%] [G loss: 1.015741]\n",
      "epoch:9 step:9315 [D loss: 0.703907, acc.: 54.69%] [G loss: 0.977873]\n",
      "epoch:9 step:9316 [D loss: 0.663772, acc.: 63.28%] [G loss: 0.864897]\n",
      "epoch:9 step:9317 [D loss: 0.634368, acc.: 60.94%] [G loss: 1.058879]\n",
      "epoch:9 step:9318 [D loss: 0.602571, acc.: 65.62%] [G loss: 1.034960]\n",
      "epoch:9 step:9319 [D loss: 0.717065, acc.: 51.56%] [G loss: 0.938304]\n",
      "epoch:9 step:9320 [D loss: 0.610324, acc.: 65.62%] [G loss: 1.033709]\n",
      "epoch:9 step:9321 [D loss: 0.666164, acc.: 58.59%] [G loss: 1.137526]\n",
      "epoch:9 step:9322 [D loss: 0.620744, acc.: 64.06%] [G loss: 1.108043]\n",
      "epoch:9 step:9323 [D loss: 0.592799, acc.: 70.31%] [G loss: 0.966942]\n",
      "epoch:9 step:9324 [D loss: 0.773972, acc.: 45.31%] [G loss: 0.955243]\n",
      "epoch:9 step:9325 [D loss: 0.745145, acc.: 46.09%] [G loss: 1.032279]\n",
      "epoch:9 step:9326 [D loss: 0.669562, acc.: 62.50%] [G loss: 0.920302]\n",
      "epoch:9 step:9327 [D loss: 0.599349, acc.: 68.75%] [G loss: 0.887874]\n",
      "epoch:9 step:9328 [D loss: 0.663119, acc.: 59.38%] [G loss: 1.040095]\n",
      "epoch:9 step:9329 [D loss: 0.724891, acc.: 52.34%] [G loss: 0.952632]\n",
      "epoch:9 step:9330 [D loss: 0.599990, acc.: 67.97%] [G loss: 0.863231]\n",
      "epoch:9 step:9331 [D loss: 0.561668, acc.: 75.78%] [G loss: 1.022385]\n",
      "epoch:9 step:9332 [D loss: 0.533643, acc.: 74.22%] [G loss: 1.097996]\n",
      "epoch:9 step:9333 [D loss: 0.522994, acc.: 75.78%] [G loss: 1.146828]\n",
      "epoch:9 step:9334 [D loss: 0.584739, acc.: 67.19%] [G loss: 1.056271]\n",
      "epoch:9 step:9335 [D loss: 0.695683, acc.: 56.25%] [G loss: 1.047680]\n",
      "epoch:9 step:9336 [D loss: 0.672807, acc.: 60.16%] [G loss: 1.052559]\n",
      "epoch:9 step:9337 [D loss: 0.673930, acc.: 57.81%] [G loss: 1.037808]\n",
      "epoch:9 step:9338 [D loss: 0.711588, acc.: 50.78%] [G loss: 0.903423]\n",
      "epoch:9 step:9339 [D loss: 0.706428, acc.: 54.69%] [G loss: 0.931355]\n",
      "epoch:9 step:9340 [D loss: 0.620632, acc.: 68.75%] [G loss: 1.103757]\n",
      "epoch:9 step:9341 [D loss: 0.689981, acc.: 56.25%] [G loss: 0.997072]\n",
      "epoch:9 step:9342 [D loss: 0.616286, acc.: 67.19%] [G loss: 0.919917]\n",
      "epoch:9 step:9343 [D loss: 0.609836, acc.: 67.97%] [G loss: 0.951020]\n",
      "epoch:9 step:9344 [D loss: 0.565407, acc.: 72.66%] [G loss: 0.879562]\n",
      "epoch:9 step:9345 [D loss: 0.467238, acc.: 83.59%] [G loss: 1.042760]\n",
      "epoch:9 step:9346 [D loss: 0.737527, acc.: 52.34%] [G loss: 0.965646]\n",
      "epoch:9 step:9347 [D loss: 0.716004, acc.: 53.91%] [G loss: 1.000946]\n",
      "epoch:9 step:9348 [D loss: 0.602196, acc.: 67.97%] [G loss: 0.957116]\n",
      "epoch:9 step:9349 [D loss: 0.636106, acc.: 66.41%] [G loss: 0.918524]\n",
      "epoch:9 step:9350 [D loss: 0.700270, acc.: 57.81%] [G loss: 0.999840]\n",
      "epoch:9 step:9351 [D loss: 0.566632, acc.: 70.31%] [G loss: 0.913293]\n",
      "epoch:9 step:9352 [D loss: 0.567086, acc.: 75.78%] [G loss: 1.111522]\n",
      "epoch:9 step:9353 [D loss: 0.683015, acc.: 57.03%] [G loss: 0.980636]\n",
      "epoch:9 step:9354 [D loss: 0.610725, acc.: 64.84%] [G loss: 0.954189]\n",
      "epoch:9 step:9355 [D loss: 0.598691, acc.: 68.75%] [G loss: 0.903547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9356 [D loss: 0.653522, acc.: 60.16%] [G loss: 0.885110]\n",
      "epoch:9 step:9357 [D loss: 0.561363, acc.: 76.56%] [G loss: 0.984079]\n",
      "epoch:9 step:9358 [D loss: 0.601993, acc.: 69.53%] [G loss: 0.994940]\n",
      "epoch:9 step:9359 [D loss: 0.550878, acc.: 68.75%] [G loss: 1.038126]\n",
      "epoch:9 step:9360 [D loss: 0.564111, acc.: 72.66%] [G loss: 1.102467]\n",
      "epoch:9 step:9361 [D loss: 0.824173, acc.: 41.41%] [G loss: 0.978618]\n",
      "epoch:9 step:9362 [D loss: 0.656847, acc.: 57.81%] [G loss: 1.045355]\n",
      "epoch:9 step:9363 [D loss: 0.603028, acc.: 71.88%] [G loss: 1.088125]\n",
      "epoch:9 step:9364 [D loss: 0.584099, acc.: 74.22%] [G loss: 0.989665]\n",
      "epoch:9 step:9365 [D loss: 0.570139, acc.: 73.44%] [G loss: 1.137961]\n",
      "epoch:9 step:9366 [D loss: 0.614561, acc.: 68.75%] [G loss: 0.925518]\n",
      "epoch:9 step:9367 [D loss: 0.481859, acc.: 81.25%] [G loss: 0.988364]\n",
      "epoch:9 step:9368 [D loss: 0.596505, acc.: 67.97%] [G loss: 1.116374]\n",
      "epoch:9 step:9369 [D loss: 0.584689, acc.: 71.88%] [G loss: 0.972926]\n",
      "epoch:9 step:9370 [D loss: 0.443117, acc.: 78.12%] [G loss: 0.977052]\n",
      "epoch:10 step:9371 [D loss: 0.615945, acc.: 64.84%] [G loss: 1.216531]\n",
      "epoch:10 step:9372 [D loss: 0.709443, acc.: 59.38%] [G loss: 1.026289]\n",
      "epoch:10 step:9373 [D loss: 0.663301, acc.: 59.38%] [G loss: 0.940145]\n",
      "epoch:10 step:9374 [D loss: 0.584572, acc.: 69.53%] [G loss: 1.076535]\n",
      "epoch:10 step:9375 [D loss: 0.605384, acc.: 65.62%] [G loss: 1.146529]\n",
      "epoch:10 step:9376 [D loss: 0.665773, acc.: 60.16%] [G loss: 0.969038]\n",
      "epoch:10 step:9377 [D loss: 0.561107, acc.: 73.44%] [G loss: 0.971168]\n",
      "epoch:10 step:9378 [D loss: 0.711720, acc.: 56.25%] [G loss: 1.064326]\n",
      "epoch:10 step:9379 [D loss: 0.574378, acc.: 71.88%] [G loss: 1.193567]\n",
      "epoch:10 step:9380 [D loss: 0.633765, acc.: 60.16%] [G loss: 1.124744]\n",
      "epoch:10 step:9381 [D loss: 0.653442, acc.: 67.19%] [G loss: 0.874920]\n",
      "epoch:10 step:9382 [D loss: 0.736915, acc.: 49.22%] [G loss: 0.956798]\n",
      "epoch:10 step:9383 [D loss: 0.618080, acc.: 64.06%] [G loss: 1.048771]\n",
      "epoch:10 step:9384 [D loss: 0.581630, acc.: 71.09%] [G loss: 1.209858]\n",
      "epoch:10 step:9385 [D loss: 0.587584, acc.: 68.75%] [G loss: 1.054332]\n",
      "epoch:10 step:9386 [D loss: 0.632234, acc.: 60.94%] [G loss: 0.967075]\n",
      "epoch:10 step:9387 [D loss: 0.684522, acc.: 60.94%] [G loss: 1.080460]\n",
      "epoch:10 step:9388 [D loss: 0.695150, acc.: 57.03%] [G loss: 1.232679]\n",
      "epoch:10 step:9389 [D loss: 0.805209, acc.: 42.97%] [G loss: 0.888672]\n",
      "epoch:10 step:9390 [D loss: 0.779950, acc.: 40.62%] [G loss: 0.984243]\n",
      "epoch:10 step:9391 [D loss: 0.736444, acc.: 52.34%] [G loss: 0.736011]\n",
      "epoch:10 step:9392 [D loss: 0.582497, acc.: 69.53%] [G loss: 0.895169]\n",
      "epoch:10 step:9393 [D loss: 0.654805, acc.: 57.81%] [G loss: 1.026963]\n",
      "epoch:10 step:9394 [D loss: 0.694388, acc.: 54.69%] [G loss: 0.850837]\n",
      "epoch:10 step:9395 [D loss: 0.582753, acc.: 75.78%] [G loss: 0.965681]\n",
      "epoch:10 step:9396 [D loss: 0.702142, acc.: 58.59%] [G loss: 0.952482]\n",
      "epoch:10 step:9397 [D loss: 0.589977, acc.: 70.31%] [G loss: 0.936246]\n",
      "epoch:10 step:9398 [D loss: 0.663046, acc.: 60.94%] [G loss: 0.970694]\n",
      "epoch:10 step:9399 [D loss: 0.602394, acc.: 64.06%] [G loss: 1.079919]\n",
      "epoch:10 step:9400 [D loss: 0.587989, acc.: 71.09%] [G loss: 1.040180]\n",
      "epoch:10 step:9401 [D loss: 0.562925, acc.: 69.53%] [G loss: 1.241743]\n",
      "epoch:10 step:9402 [D loss: 0.597218, acc.: 68.75%] [G loss: 1.067929]\n",
      "epoch:10 step:9403 [D loss: 0.606353, acc.: 62.50%] [G loss: 1.128103]\n",
      "epoch:10 step:9404 [D loss: 0.591234, acc.: 69.53%] [G loss: 1.043682]\n",
      "epoch:10 step:9405 [D loss: 0.551262, acc.: 75.00%] [G loss: 1.054894]\n",
      "epoch:10 step:9406 [D loss: 0.487560, acc.: 82.81%] [G loss: 1.200132]\n",
      "epoch:10 step:9407 [D loss: 0.563639, acc.: 71.09%] [G loss: 1.133245]\n",
      "epoch:10 step:9408 [D loss: 0.651307, acc.: 62.50%] [G loss: 1.111928]\n",
      "epoch:10 step:9409 [D loss: 0.690464, acc.: 56.25%] [G loss: 1.138760]\n",
      "epoch:10 step:9410 [D loss: 0.653740, acc.: 64.06%] [G loss: 1.051306]\n",
      "epoch:10 step:9411 [D loss: 0.679464, acc.: 57.81%] [G loss: 1.042514]\n",
      "epoch:10 step:9412 [D loss: 0.624179, acc.: 64.06%] [G loss: 1.020801]\n",
      "epoch:10 step:9413 [D loss: 0.619143, acc.: 67.97%] [G loss: 1.068513]\n",
      "epoch:10 step:9414 [D loss: 0.647598, acc.: 63.28%] [G loss: 1.007234]\n",
      "epoch:10 step:9415 [D loss: 0.686831, acc.: 59.38%] [G loss: 0.967001]\n",
      "epoch:10 step:9416 [D loss: 0.669591, acc.: 57.03%] [G loss: 0.898575]\n",
      "epoch:10 step:9417 [D loss: 0.617216, acc.: 65.62%] [G loss: 1.014805]\n",
      "epoch:10 step:9418 [D loss: 0.655712, acc.: 64.06%] [G loss: 1.099841]\n",
      "epoch:10 step:9419 [D loss: 0.629939, acc.: 63.28%] [G loss: 0.971064]\n",
      "epoch:10 step:9420 [D loss: 0.601098, acc.: 64.84%] [G loss: 1.144037]\n",
      "epoch:10 step:9421 [D loss: 0.668716, acc.: 57.81%] [G loss: 0.987837]\n",
      "epoch:10 step:9422 [D loss: 0.642165, acc.: 63.28%] [G loss: 1.086511]\n",
      "epoch:10 step:9423 [D loss: 0.632960, acc.: 62.50%] [G loss: 1.082717]\n",
      "epoch:10 step:9424 [D loss: 0.650772, acc.: 59.38%] [G loss: 0.961382]\n",
      "epoch:10 step:9425 [D loss: 0.603956, acc.: 67.97%] [G loss: 1.010603]\n",
      "epoch:10 step:9426 [D loss: 0.709906, acc.: 59.38%] [G loss: 0.871791]\n",
      "epoch:10 step:9427 [D loss: 0.679423, acc.: 60.16%] [G loss: 0.942002]\n",
      "epoch:10 step:9428 [D loss: 0.567749, acc.: 66.41%] [G loss: 0.910222]\n",
      "epoch:10 step:9429 [D loss: 0.697120, acc.: 59.38%] [G loss: 0.906750]\n",
      "epoch:10 step:9430 [D loss: 0.644216, acc.: 64.84%] [G loss: 0.921879]\n",
      "epoch:10 step:9431 [D loss: 0.705556, acc.: 58.59%] [G loss: 0.915543]\n",
      "epoch:10 step:9432 [D loss: 0.750983, acc.: 49.22%] [G loss: 0.927078]\n",
      "epoch:10 step:9433 [D loss: 0.673357, acc.: 62.50%] [G loss: 0.888672]\n",
      "epoch:10 step:9434 [D loss: 0.680499, acc.: 58.59%] [G loss: 0.813758]\n",
      "epoch:10 step:9435 [D loss: 0.661178, acc.: 60.94%] [G loss: 0.964611]\n",
      "epoch:10 step:9436 [D loss: 0.586886, acc.: 72.66%] [G loss: 0.973005]\n",
      "epoch:10 step:9437 [D loss: 0.698537, acc.: 55.47%] [G loss: 0.923994]\n",
      "epoch:10 step:9438 [D loss: 0.670522, acc.: 63.28%] [G loss: 0.946955]\n",
      "epoch:10 step:9439 [D loss: 0.610305, acc.: 67.97%] [G loss: 0.950716]\n",
      "epoch:10 step:9440 [D loss: 0.668397, acc.: 57.81%] [G loss: 0.925715]\n",
      "epoch:10 step:9441 [D loss: 0.644306, acc.: 60.94%] [G loss: 1.051018]\n",
      "epoch:10 step:9442 [D loss: 0.647925, acc.: 67.97%] [G loss: 1.097744]\n",
      "epoch:10 step:9443 [D loss: 0.721888, acc.: 53.12%] [G loss: 0.921207]\n",
      "epoch:10 step:9444 [D loss: 0.563643, acc.: 74.22%] [G loss: 0.956078]\n",
      "epoch:10 step:9445 [D loss: 0.543303, acc.: 75.00%] [G loss: 1.039747]\n",
      "epoch:10 step:9446 [D loss: 0.581904, acc.: 73.44%] [G loss: 1.103692]\n",
      "epoch:10 step:9447 [D loss: 0.678015, acc.: 56.25%] [G loss: 0.901479]\n",
      "epoch:10 step:9448 [D loss: 0.672808, acc.: 54.69%] [G loss: 1.069739]\n",
      "epoch:10 step:9449 [D loss: 0.662091, acc.: 60.16%] [G loss: 0.976541]\n",
      "epoch:10 step:9450 [D loss: 0.650088, acc.: 60.94%] [G loss: 0.916859]\n",
      "epoch:10 step:9451 [D loss: 0.725769, acc.: 54.69%] [G loss: 0.929415]\n",
      "epoch:10 step:9452 [D loss: 0.618145, acc.: 67.97%] [G loss: 0.921031]\n",
      "epoch:10 step:9453 [D loss: 0.626128, acc.: 61.72%] [G loss: 0.890808]\n",
      "epoch:10 step:9454 [D loss: 0.699013, acc.: 53.91%] [G loss: 0.920929]\n",
      "epoch:10 step:9455 [D loss: 0.701713, acc.: 51.56%] [G loss: 0.881593]\n",
      "epoch:10 step:9456 [D loss: 0.777914, acc.: 45.31%] [G loss: 0.975961]\n",
      "epoch:10 step:9457 [D loss: 0.714629, acc.: 51.56%] [G loss: 0.890648]\n",
      "epoch:10 step:9458 [D loss: 0.635454, acc.: 61.72%] [G loss: 0.933061]\n",
      "epoch:10 step:9459 [D loss: 0.606332, acc.: 67.19%] [G loss: 0.953358]\n",
      "epoch:10 step:9460 [D loss: 0.677828, acc.: 64.06%] [G loss: 0.850009]\n",
      "epoch:10 step:9461 [D loss: 0.692270, acc.: 57.81%] [G loss: 0.956176]\n",
      "epoch:10 step:9462 [D loss: 0.570206, acc.: 75.00%] [G loss: 0.968478]\n",
      "epoch:10 step:9463 [D loss: 0.562360, acc.: 75.78%] [G loss: 1.082180]\n",
      "epoch:10 step:9464 [D loss: 0.710340, acc.: 50.78%] [G loss: 0.868365]\n",
      "epoch:10 step:9465 [D loss: 0.736281, acc.: 52.34%] [G loss: 1.035157]\n",
      "epoch:10 step:9466 [D loss: 0.672514, acc.: 57.81%] [G loss: 1.003875]\n",
      "epoch:10 step:9467 [D loss: 0.672569, acc.: 59.38%] [G loss: 0.781256]\n",
      "epoch:10 step:9468 [D loss: 0.717534, acc.: 57.03%] [G loss: 0.914869]\n",
      "epoch:10 step:9469 [D loss: 0.622922, acc.: 66.41%] [G loss: 1.062554]\n",
      "epoch:10 step:9470 [D loss: 0.587197, acc.: 68.75%] [G loss: 0.952190]\n",
      "epoch:10 step:9471 [D loss: 0.653214, acc.: 60.94%] [G loss: 1.029257]\n",
      "epoch:10 step:9472 [D loss: 0.657887, acc.: 64.06%] [G loss: 0.832360]\n",
      "epoch:10 step:9473 [D loss: 0.530276, acc.: 76.56%] [G loss: 0.952687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9474 [D loss: 0.694210, acc.: 57.03%] [G loss: 0.884063]\n",
      "epoch:10 step:9475 [D loss: 0.696411, acc.: 52.34%] [G loss: 0.997085]\n",
      "epoch:10 step:9476 [D loss: 0.656178, acc.: 57.03%] [G loss: 1.082795]\n",
      "epoch:10 step:9477 [D loss: 0.708229, acc.: 54.69%] [G loss: 1.120472]\n",
      "epoch:10 step:9478 [D loss: 0.706570, acc.: 51.56%] [G loss: 0.935376]\n",
      "epoch:10 step:9479 [D loss: 0.590293, acc.: 70.31%] [G loss: 0.910843]\n",
      "epoch:10 step:9480 [D loss: 0.773513, acc.: 42.97%] [G loss: 0.945677]\n",
      "epoch:10 step:9481 [D loss: 0.559202, acc.: 75.78%] [G loss: 1.024992]\n",
      "epoch:10 step:9482 [D loss: 0.646928, acc.: 57.03%] [G loss: 0.863545]\n",
      "epoch:10 step:9483 [D loss: 0.659184, acc.: 60.94%] [G loss: 0.993704]\n",
      "epoch:10 step:9484 [D loss: 0.731440, acc.: 52.34%] [G loss: 0.929135]\n",
      "epoch:10 step:9485 [D loss: 0.587917, acc.: 72.66%] [G loss: 1.086143]\n",
      "epoch:10 step:9486 [D loss: 0.615652, acc.: 71.88%] [G loss: 0.938767]\n",
      "epoch:10 step:9487 [D loss: 0.638406, acc.: 64.06%] [G loss: 1.127649]\n",
      "epoch:10 step:9488 [D loss: 0.800342, acc.: 42.97%] [G loss: 0.825328]\n",
      "epoch:10 step:9489 [D loss: 0.555734, acc.: 75.00%] [G loss: 1.011233]\n",
      "epoch:10 step:9490 [D loss: 0.667635, acc.: 58.59%] [G loss: 0.961220]\n",
      "epoch:10 step:9491 [D loss: 0.667935, acc.: 64.06%] [G loss: 0.854464]\n",
      "epoch:10 step:9492 [D loss: 0.593737, acc.: 68.75%] [G loss: 1.035132]\n",
      "epoch:10 step:9493 [D loss: 0.638599, acc.: 64.06%] [G loss: 1.057873]\n",
      "epoch:10 step:9494 [D loss: 0.632041, acc.: 61.72%] [G loss: 1.109202]\n",
      "epoch:10 step:9495 [D loss: 0.714714, acc.: 54.69%] [G loss: 1.061215]\n",
      "epoch:10 step:9496 [D loss: 0.675114, acc.: 56.25%] [G loss: 0.866570]\n",
      "epoch:10 step:9497 [D loss: 0.705780, acc.: 54.69%] [G loss: 0.929038]\n",
      "epoch:10 step:9498 [D loss: 0.732508, acc.: 53.12%] [G loss: 0.969564]\n",
      "epoch:10 step:9499 [D loss: 0.721198, acc.: 50.78%] [G loss: 0.917745]\n",
      "epoch:10 step:9500 [D loss: 0.640162, acc.: 64.06%] [G loss: 1.036678]\n",
      "epoch:10 step:9501 [D loss: 0.618704, acc.: 67.97%] [G loss: 0.877266]\n",
      "epoch:10 step:9502 [D loss: 0.567881, acc.: 72.66%] [G loss: 1.099997]\n",
      "epoch:10 step:9503 [D loss: 0.745569, acc.: 51.56%] [G loss: 0.862695]\n",
      "epoch:10 step:9504 [D loss: 0.675369, acc.: 57.03%] [G loss: 0.986508]\n",
      "epoch:10 step:9505 [D loss: 0.685102, acc.: 60.16%] [G loss: 0.978927]\n",
      "epoch:10 step:9506 [D loss: 0.717581, acc.: 57.03%] [G loss: 0.962319]\n",
      "epoch:10 step:9507 [D loss: 0.785955, acc.: 42.97%] [G loss: 0.977725]\n",
      "epoch:10 step:9508 [D loss: 0.641767, acc.: 63.28%] [G loss: 0.897157]\n",
      "epoch:10 step:9509 [D loss: 0.739745, acc.: 50.78%] [G loss: 0.891882]\n",
      "epoch:10 step:9510 [D loss: 0.630915, acc.: 67.19%] [G loss: 1.009106]\n",
      "epoch:10 step:9511 [D loss: 0.702497, acc.: 50.00%] [G loss: 1.058654]\n",
      "epoch:10 step:9512 [D loss: 0.596758, acc.: 71.09%] [G loss: 1.025172]\n",
      "epoch:10 step:9513 [D loss: 0.681110, acc.: 57.03%] [G loss: 1.074363]\n",
      "epoch:10 step:9514 [D loss: 0.598717, acc.: 73.44%] [G loss: 1.020838]\n",
      "epoch:10 step:9515 [D loss: 0.596980, acc.: 68.75%] [G loss: 1.012477]\n",
      "epoch:10 step:9516 [D loss: 0.638121, acc.: 60.16%] [G loss: 1.041090]\n",
      "epoch:10 step:9517 [D loss: 0.655011, acc.: 61.72%] [G loss: 1.011167]\n",
      "epoch:10 step:9518 [D loss: 0.697071, acc.: 59.38%] [G loss: 0.957853]\n",
      "epoch:10 step:9519 [D loss: 0.683582, acc.: 52.34%] [G loss: 0.956050]\n",
      "epoch:10 step:9520 [D loss: 0.575631, acc.: 74.22%] [G loss: 1.087566]\n",
      "epoch:10 step:9521 [D loss: 0.582704, acc.: 70.31%] [G loss: 1.225431]\n",
      "epoch:10 step:9522 [D loss: 0.476967, acc.: 83.59%] [G loss: 1.226442]\n",
      "epoch:10 step:9523 [D loss: 0.727900, acc.: 52.34%] [G loss: 1.003137]\n",
      "epoch:10 step:9524 [D loss: 0.653497, acc.: 59.38%] [G loss: 0.946278]\n",
      "epoch:10 step:9525 [D loss: 0.655441, acc.: 62.50%] [G loss: 1.035950]\n",
      "epoch:10 step:9526 [D loss: 0.598707, acc.: 71.09%] [G loss: 1.032805]\n",
      "epoch:10 step:9527 [D loss: 0.641647, acc.: 66.41%] [G loss: 1.043511]\n",
      "epoch:10 step:9528 [D loss: 0.657879, acc.: 60.94%] [G loss: 0.923686]\n",
      "epoch:10 step:9529 [D loss: 0.649435, acc.: 61.72%] [G loss: 1.023156]\n",
      "epoch:10 step:9530 [D loss: 0.755836, acc.: 46.88%] [G loss: 0.808303]\n",
      "epoch:10 step:9531 [D loss: 0.662873, acc.: 60.94%] [G loss: 0.940839]\n",
      "epoch:10 step:9532 [D loss: 0.639029, acc.: 60.94%] [G loss: 0.916359]\n",
      "epoch:10 step:9533 [D loss: 0.656668, acc.: 62.50%] [G loss: 0.938730]\n",
      "epoch:10 step:9534 [D loss: 0.676045, acc.: 58.59%] [G loss: 1.014696]\n",
      "epoch:10 step:9535 [D loss: 0.676724, acc.: 62.50%] [G loss: 0.975698]\n",
      "epoch:10 step:9536 [D loss: 0.685080, acc.: 57.03%] [G loss: 0.899722]\n",
      "epoch:10 step:9537 [D loss: 0.590703, acc.: 66.41%] [G loss: 0.888352]\n",
      "epoch:10 step:9538 [D loss: 0.675143, acc.: 57.03%] [G loss: 0.788437]\n",
      "epoch:10 step:9539 [D loss: 0.590032, acc.: 71.09%] [G loss: 1.027740]\n",
      "epoch:10 step:9540 [D loss: 0.706006, acc.: 55.47%] [G loss: 0.997113]\n",
      "epoch:10 step:9541 [D loss: 0.719860, acc.: 51.56%] [G loss: 0.822019]\n",
      "epoch:10 step:9542 [D loss: 0.690692, acc.: 57.03%] [G loss: 0.984273]\n",
      "epoch:10 step:9543 [D loss: 0.696324, acc.: 55.47%] [G loss: 0.940948]\n",
      "epoch:10 step:9544 [D loss: 0.717446, acc.: 52.34%] [G loss: 0.993385]\n",
      "epoch:10 step:9545 [D loss: 0.667980, acc.: 59.38%] [G loss: 1.024213]\n",
      "epoch:10 step:9546 [D loss: 0.647271, acc.: 62.50%] [G loss: 0.818681]\n",
      "epoch:10 step:9547 [D loss: 0.670533, acc.: 61.72%] [G loss: 1.000453]\n",
      "epoch:10 step:9548 [D loss: 0.668345, acc.: 54.69%] [G loss: 0.939947]\n",
      "epoch:10 step:9549 [D loss: 0.783598, acc.: 43.75%] [G loss: 0.917253]\n",
      "epoch:10 step:9550 [D loss: 0.726382, acc.: 53.12%] [G loss: 0.823148]\n",
      "epoch:10 step:9551 [D loss: 0.652712, acc.: 58.59%] [G loss: 0.890010]\n",
      "epoch:10 step:9552 [D loss: 0.714600, acc.: 53.12%] [G loss: 0.839954]\n",
      "epoch:10 step:9553 [D loss: 0.701217, acc.: 54.69%] [G loss: 0.909243]\n",
      "epoch:10 step:9554 [D loss: 0.690593, acc.: 55.47%] [G loss: 1.076135]\n",
      "epoch:10 step:9555 [D loss: 0.716422, acc.: 49.22%] [G loss: 0.950919]\n",
      "epoch:10 step:9556 [D loss: 0.643097, acc.: 62.50%] [G loss: 0.883116]\n",
      "epoch:10 step:9557 [D loss: 0.682764, acc.: 57.81%] [G loss: 0.878850]\n",
      "epoch:10 step:9558 [D loss: 0.674253, acc.: 59.38%] [G loss: 0.915311]\n",
      "epoch:10 step:9559 [D loss: 0.675511, acc.: 58.59%] [G loss: 0.850095]\n",
      "epoch:10 step:9560 [D loss: 0.611005, acc.: 65.62%] [G loss: 0.909442]\n",
      "epoch:10 step:9561 [D loss: 0.605115, acc.: 69.53%] [G loss: 1.090805]\n",
      "epoch:10 step:9562 [D loss: 0.645686, acc.: 62.50%] [G loss: 1.063718]\n",
      "epoch:10 step:9563 [D loss: 0.658547, acc.: 61.72%] [G loss: 0.930655]\n",
      "epoch:10 step:9564 [D loss: 0.585696, acc.: 70.31%] [G loss: 1.017976]\n",
      "epoch:10 step:9565 [D loss: 0.654571, acc.: 64.84%] [G loss: 1.015503]\n",
      "epoch:10 step:9566 [D loss: 0.688449, acc.: 56.25%] [G loss: 1.026097]\n",
      "epoch:10 step:9567 [D loss: 0.694478, acc.: 59.38%] [G loss: 0.988561]\n",
      "epoch:10 step:9568 [D loss: 0.648713, acc.: 57.81%] [G loss: 0.981568]\n",
      "epoch:10 step:9569 [D loss: 0.648602, acc.: 63.28%] [G loss: 0.945087]\n",
      "epoch:10 step:9570 [D loss: 0.736585, acc.: 50.78%] [G loss: 1.020038]\n",
      "epoch:10 step:9571 [D loss: 0.685777, acc.: 60.16%] [G loss: 0.925825]\n",
      "epoch:10 step:9572 [D loss: 0.732091, acc.: 50.00%] [G loss: 0.878850]\n",
      "epoch:10 step:9573 [D loss: 0.679354, acc.: 53.91%] [G loss: 0.994497]\n",
      "epoch:10 step:9574 [D loss: 0.647385, acc.: 64.06%] [G loss: 0.949568]\n",
      "epoch:10 step:9575 [D loss: 0.686017, acc.: 59.38%] [G loss: 0.982602]\n",
      "epoch:10 step:9576 [D loss: 0.651260, acc.: 60.94%] [G loss: 0.956537]\n",
      "epoch:10 step:9577 [D loss: 0.614679, acc.: 67.97%] [G loss: 0.865812]\n",
      "epoch:10 step:9578 [D loss: 0.654073, acc.: 58.59%] [G loss: 0.861367]\n",
      "epoch:10 step:9579 [D loss: 0.582384, acc.: 69.53%] [G loss: 0.935632]\n",
      "epoch:10 step:9580 [D loss: 0.652196, acc.: 61.72%] [G loss: 1.042235]\n",
      "epoch:10 step:9581 [D loss: 0.727231, acc.: 49.22%] [G loss: 0.884103]\n",
      "epoch:10 step:9582 [D loss: 0.665394, acc.: 59.38%] [G loss: 0.982650]\n",
      "epoch:10 step:9583 [D loss: 0.728146, acc.: 54.69%] [G loss: 0.886189]\n",
      "epoch:10 step:9584 [D loss: 0.716061, acc.: 54.69%] [G loss: 1.063540]\n",
      "epoch:10 step:9585 [D loss: 0.774245, acc.: 42.97%] [G loss: 0.815138]\n",
      "epoch:10 step:9586 [D loss: 0.591571, acc.: 74.22%] [G loss: 0.921913]\n",
      "epoch:10 step:9587 [D loss: 0.684943, acc.: 54.69%] [G loss: 0.995893]\n",
      "epoch:10 step:9588 [D loss: 0.670994, acc.: 58.59%] [G loss: 0.908599]\n",
      "epoch:10 step:9589 [D loss: 0.618087, acc.: 64.06%] [G loss: 0.999290]\n",
      "epoch:10 step:9590 [D loss: 0.571443, acc.: 78.91%] [G loss: 0.991872]\n",
      "epoch:10 step:9591 [D loss: 0.521857, acc.: 74.22%] [G loss: 1.178211]\n",
      "epoch:10 step:9592 [D loss: 0.587569, acc.: 64.06%] [G loss: 1.097515]\n",
      "epoch:10 step:9593 [D loss: 0.509990, acc.: 76.56%] [G loss: 1.067690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9594 [D loss: 0.788916, acc.: 46.09%] [G loss: 1.077358]\n",
      "epoch:10 step:9595 [D loss: 0.707736, acc.: 54.69%] [G loss: 0.893860]\n",
      "epoch:10 step:9596 [D loss: 0.631913, acc.: 64.06%] [G loss: 1.040834]\n",
      "epoch:10 step:9597 [D loss: 0.685385, acc.: 58.59%] [G loss: 0.889603]\n",
      "epoch:10 step:9598 [D loss: 0.650106, acc.: 61.72%] [G loss: 0.819769]\n",
      "epoch:10 step:9599 [D loss: 0.647764, acc.: 64.84%] [G loss: 0.902123]\n",
      "epoch:10 step:9600 [D loss: 0.540745, acc.: 74.22%] [G loss: 1.067502]\n",
      "epoch:10 step:9601 [D loss: 0.496183, acc.: 78.91%] [G loss: 1.289373]\n",
      "epoch:10 step:9602 [D loss: 0.517616, acc.: 76.56%] [G loss: 1.122231]\n",
      "epoch:10 step:9603 [D loss: 0.786177, acc.: 51.56%] [G loss: 0.980210]\n",
      "epoch:10 step:9604 [D loss: 0.694160, acc.: 57.03%] [G loss: 1.140571]\n",
      "epoch:10 step:9605 [D loss: 0.721023, acc.: 52.34%] [G loss: 0.946107]\n",
      "epoch:10 step:9606 [D loss: 0.743833, acc.: 51.56%] [G loss: 0.857712]\n",
      "epoch:10 step:9607 [D loss: 0.572898, acc.: 71.88%] [G loss: 0.950942]\n",
      "epoch:10 step:9608 [D loss: 0.643684, acc.: 62.50%] [G loss: 0.919532]\n",
      "epoch:10 step:9609 [D loss: 0.632096, acc.: 60.94%] [G loss: 0.954317]\n",
      "epoch:10 step:9610 [D loss: 0.669013, acc.: 61.72%] [G loss: 1.012434]\n",
      "epoch:10 step:9611 [D loss: 0.600910, acc.: 64.84%] [G loss: 1.156073]\n",
      "epoch:10 step:9612 [D loss: 0.693757, acc.: 59.38%] [G loss: 1.035180]\n",
      "epoch:10 step:9613 [D loss: 0.673088, acc.: 62.50%] [G loss: 0.971951]\n",
      "epoch:10 step:9614 [D loss: 0.548638, acc.: 78.12%] [G loss: 0.809106]\n",
      "epoch:10 step:9615 [D loss: 0.682215, acc.: 59.38%] [G loss: 0.987708]\n",
      "epoch:10 step:9616 [D loss: 0.578135, acc.: 68.75%] [G loss: 0.958781]\n",
      "epoch:10 step:9617 [D loss: 0.724129, acc.: 55.47%] [G loss: 0.901123]\n",
      "epoch:10 step:9618 [D loss: 0.628400, acc.: 63.28%] [G loss: 0.820506]\n",
      "epoch:10 step:9619 [D loss: 0.800965, acc.: 39.84%] [G loss: 0.853522]\n",
      "epoch:10 step:9620 [D loss: 0.672767, acc.: 61.72%] [G loss: 0.920865]\n",
      "epoch:10 step:9621 [D loss: 0.705988, acc.: 58.59%] [G loss: 0.990338]\n",
      "epoch:10 step:9622 [D loss: 0.696027, acc.: 55.47%] [G loss: 0.916294]\n",
      "epoch:10 step:9623 [D loss: 0.657455, acc.: 59.38%] [G loss: 0.936568]\n",
      "epoch:10 step:9624 [D loss: 0.623442, acc.: 66.41%] [G loss: 0.924070]\n",
      "epoch:10 step:9625 [D loss: 0.615477, acc.: 65.62%] [G loss: 0.829612]\n",
      "epoch:10 step:9626 [D loss: 0.665548, acc.: 54.69%] [G loss: 0.833273]\n",
      "epoch:10 step:9627 [D loss: 0.691977, acc.: 56.25%] [G loss: 0.932351]\n",
      "epoch:10 step:9628 [D loss: 0.652881, acc.: 66.41%] [G loss: 0.878862]\n",
      "epoch:10 step:9629 [D loss: 0.594689, acc.: 70.31%] [G loss: 0.908324]\n",
      "epoch:10 step:9630 [D loss: 0.659493, acc.: 62.50%] [G loss: 0.919423]\n",
      "epoch:10 step:9631 [D loss: 0.745762, acc.: 47.66%] [G loss: 0.789768]\n",
      "epoch:10 step:9632 [D loss: 0.625082, acc.: 65.62%] [G loss: 1.015212]\n",
      "epoch:10 step:9633 [D loss: 0.694182, acc.: 51.56%] [G loss: 1.104239]\n",
      "epoch:10 step:9634 [D loss: 0.604505, acc.: 72.66%] [G loss: 1.080710]\n",
      "epoch:10 step:9635 [D loss: 0.690123, acc.: 53.12%] [G loss: 1.061702]\n",
      "epoch:10 step:9636 [D loss: 0.726862, acc.: 51.56%] [G loss: 1.000944]\n",
      "epoch:10 step:9637 [D loss: 0.679997, acc.: 57.03%] [G loss: 0.984476]\n",
      "epoch:10 step:9638 [D loss: 0.649769, acc.: 61.72%] [G loss: 1.104636]\n",
      "epoch:10 step:9639 [D loss: 0.684801, acc.: 60.16%] [G loss: 0.992938]\n",
      "epoch:10 step:9640 [D loss: 0.632039, acc.: 65.62%] [G loss: 1.006147]\n",
      "epoch:10 step:9641 [D loss: 0.700957, acc.: 52.34%] [G loss: 0.967103]\n",
      "epoch:10 step:9642 [D loss: 0.638991, acc.: 64.84%] [G loss: 0.996766]\n",
      "epoch:10 step:9643 [D loss: 0.642249, acc.: 59.38%] [G loss: 0.973230]\n",
      "epoch:10 step:9644 [D loss: 0.676033, acc.: 54.69%] [G loss: 0.969457]\n",
      "epoch:10 step:9645 [D loss: 0.680855, acc.: 55.47%] [G loss: 0.848700]\n",
      "epoch:10 step:9646 [D loss: 0.719182, acc.: 49.22%] [G loss: 0.947415]\n",
      "epoch:10 step:9647 [D loss: 0.636171, acc.: 62.50%] [G loss: 0.894065]\n",
      "epoch:10 step:9648 [D loss: 0.702555, acc.: 55.47%] [G loss: 0.995685]\n",
      "epoch:10 step:9649 [D loss: 0.689794, acc.: 56.25%] [G loss: 0.893270]\n",
      "epoch:10 step:9650 [D loss: 0.660655, acc.: 60.94%] [G loss: 0.992312]\n",
      "epoch:10 step:9651 [D loss: 0.656015, acc.: 66.41%] [G loss: 0.990853]\n",
      "epoch:10 step:9652 [D loss: 0.684727, acc.: 59.38%] [G loss: 0.949805]\n",
      "epoch:10 step:9653 [D loss: 0.654857, acc.: 66.41%] [G loss: 0.927641]\n",
      "epoch:10 step:9654 [D loss: 0.665408, acc.: 57.03%] [G loss: 0.957364]\n",
      "epoch:10 step:9655 [D loss: 0.607143, acc.: 67.97%] [G loss: 1.049016]\n",
      "epoch:10 step:9656 [D loss: 0.615440, acc.: 67.97%] [G loss: 0.977419]\n",
      "epoch:10 step:9657 [D loss: 0.692994, acc.: 54.69%] [G loss: 0.943741]\n",
      "epoch:10 step:9658 [D loss: 0.745207, acc.: 46.09%] [G loss: 0.937043]\n",
      "epoch:10 step:9659 [D loss: 0.561806, acc.: 73.44%] [G loss: 1.090865]\n",
      "epoch:10 step:9660 [D loss: 0.696323, acc.: 51.56%] [G loss: 0.961419]\n",
      "epoch:10 step:9661 [D loss: 0.585559, acc.: 67.97%] [G loss: 0.962877]\n",
      "epoch:10 step:9662 [D loss: 0.673961, acc.: 53.91%] [G loss: 0.967447]\n",
      "epoch:10 step:9663 [D loss: 0.583041, acc.: 67.97%] [G loss: 0.926381]\n",
      "epoch:10 step:9664 [D loss: 0.730382, acc.: 51.56%] [G loss: 0.886962]\n",
      "epoch:10 step:9665 [D loss: 0.807840, acc.: 43.75%] [G loss: 0.991962]\n",
      "epoch:10 step:9666 [D loss: 0.667128, acc.: 57.81%] [G loss: 1.065169]\n",
      "epoch:10 step:9667 [D loss: 0.680663, acc.: 57.81%] [G loss: 0.969158]\n",
      "epoch:10 step:9668 [D loss: 0.679637, acc.: 62.50%] [G loss: 1.000992]\n",
      "epoch:10 step:9669 [D loss: 0.660688, acc.: 58.59%] [G loss: 1.037032]\n",
      "epoch:10 step:9670 [D loss: 0.662343, acc.: 59.38%] [G loss: 0.944307]\n",
      "epoch:10 step:9671 [D loss: 0.731138, acc.: 48.44%] [G loss: 0.969579]\n",
      "epoch:10 step:9672 [D loss: 0.556966, acc.: 74.22%] [G loss: 1.071885]\n",
      "epoch:10 step:9673 [D loss: 0.653056, acc.: 62.50%] [G loss: 0.963776]\n",
      "epoch:10 step:9674 [D loss: 0.683469, acc.: 60.16%] [G loss: 0.838040]\n",
      "epoch:10 step:9675 [D loss: 0.684005, acc.: 61.72%] [G loss: 0.985722]\n",
      "epoch:10 step:9676 [D loss: 0.572834, acc.: 73.44%] [G loss: 1.096753]\n",
      "epoch:10 step:9677 [D loss: 0.656042, acc.: 59.38%] [G loss: 0.942172]\n",
      "epoch:10 step:9678 [D loss: 0.546987, acc.: 78.91%] [G loss: 0.838161]\n",
      "epoch:10 step:9679 [D loss: 0.676891, acc.: 59.38%] [G loss: 0.981240]\n",
      "epoch:10 step:9680 [D loss: 0.509606, acc.: 80.47%] [G loss: 0.982232]\n",
      "epoch:10 step:9681 [D loss: 0.697996, acc.: 57.81%] [G loss: 0.856540]\n",
      "epoch:10 step:9682 [D loss: 0.615718, acc.: 68.75%] [G loss: 0.989992]\n",
      "epoch:10 step:9683 [D loss: 0.530967, acc.: 75.78%] [G loss: 1.127359]\n",
      "epoch:10 step:9684 [D loss: 0.487873, acc.: 78.91%] [G loss: 1.145507]\n",
      "epoch:10 step:9685 [D loss: 0.552970, acc.: 69.53%] [G loss: 1.099519]\n",
      "epoch:10 step:9686 [D loss: 0.714850, acc.: 56.25%] [G loss: 1.080858]\n",
      "epoch:10 step:9687 [D loss: 0.742106, acc.: 51.56%] [G loss: 0.952581]\n",
      "epoch:10 step:9688 [D loss: 0.672487, acc.: 59.38%] [G loss: 1.043723]\n",
      "epoch:10 step:9689 [D loss: 0.664017, acc.: 62.50%] [G loss: 1.048389]\n",
      "epoch:10 step:9690 [D loss: 0.557025, acc.: 74.22%] [G loss: 0.888104]\n",
      "epoch:10 step:9691 [D loss: 0.620334, acc.: 68.75%] [G loss: 0.892054]\n",
      "epoch:10 step:9692 [D loss: 0.712439, acc.: 59.38%] [G loss: 0.903060]\n",
      "epoch:10 step:9693 [D loss: 0.720018, acc.: 53.12%] [G loss: 0.796643]\n",
      "epoch:10 step:9694 [D loss: 0.747207, acc.: 45.31%] [G loss: 0.876864]\n",
      "epoch:10 step:9695 [D loss: 0.647092, acc.: 60.94%] [G loss: 0.971876]\n",
      "epoch:10 step:9696 [D loss: 0.664177, acc.: 60.94%] [G loss: 0.811698]\n",
      "epoch:10 step:9697 [D loss: 0.644987, acc.: 60.16%] [G loss: 0.916106]\n",
      "epoch:10 step:9698 [D loss: 0.599979, acc.: 72.66%] [G loss: 1.006447]\n",
      "epoch:10 step:9699 [D loss: 0.697166, acc.: 54.69%] [G loss: 0.965205]\n",
      "epoch:10 step:9700 [D loss: 0.689052, acc.: 56.25%] [G loss: 0.898116]\n",
      "epoch:10 step:9701 [D loss: 0.599849, acc.: 66.41%] [G loss: 1.002573]\n",
      "epoch:10 step:9702 [D loss: 0.665867, acc.: 58.59%] [G loss: 0.890464]\n",
      "epoch:10 step:9703 [D loss: 0.647678, acc.: 61.72%] [G loss: 0.898672]\n",
      "epoch:10 step:9704 [D loss: 0.670316, acc.: 64.06%] [G loss: 0.878760]\n",
      "epoch:10 step:9705 [D loss: 0.681449, acc.: 54.69%] [G loss: 0.972140]\n",
      "epoch:10 step:9706 [D loss: 0.580827, acc.: 67.97%] [G loss: 1.019064]\n",
      "epoch:10 step:9707 [D loss: 0.595446, acc.: 71.09%] [G loss: 1.113127]\n",
      "epoch:10 step:9708 [D loss: 0.573517, acc.: 67.97%] [G loss: 1.095511]\n",
      "epoch:10 step:9709 [D loss: 0.581809, acc.: 75.78%] [G loss: 0.912012]\n",
      "epoch:10 step:9710 [D loss: 0.623880, acc.: 64.06%] [G loss: 0.908691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9711 [D loss: 0.623230, acc.: 61.72%] [G loss: 1.140453]\n",
      "epoch:10 step:9712 [D loss: 0.652764, acc.: 60.16%] [G loss: 1.084334]\n",
      "epoch:10 step:9713 [D loss: 0.564897, acc.: 71.88%] [G loss: 0.925663]\n",
      "epoch:10 step:9714 [D loss: 0.576568, acc.: 69.53%] [G loss: 0.916127]\n",
      "epoch:10 step:9715 [D loss: 0.545492, acc.: 73.44%] [G loss: 1.146100]\n",
      "epoch:10 step:9716 [D loss: 0.534757, acc.: 75.00%] [G loss: 1.030785]\n",
      "epoch:10 step:9717 [D loss: 0.522615, acc.: 78.12%] [G loss: 1.087356]\n",
      "epoch:10 step:9718 [D loss: 0.671228, acc.: 62.50%] [G loss: 0.941783]\n",
      "epoch:10 step:9719 [D loss: 0.752549, acc.: 52.34%] [G loss: 0.900713]\n",
      "epoch:10 step:9720 [D loss: 0.634154, acc.: 67.97%] [G loss: 0.843060]\n",
      "epoch:10 step:9721 [D loss: 0.577170, acc.: 71.09%] [G loss: 1.077162]\n",
      "epoch:10 step:9722 [D loss: 0.630296, acc.: 68.75%] [G loss: 1.197388]\n",
      "epoch:10 step:9723 [D loss: 0.576837, acc.: 71.09%] [G loss: 0.935829]\n",
      "epoch:10 step:9724 [D loss: 0.605800, acc.: 67.19%] [G loss: 0.999892]\n",
      "epoch:10 step:9725 [D loss: 0.679915, acc.: 59.38%] [G loss: 0.840790]\n",
      "epoch:10 step:9726 [D loss: 0.698472, acc.: 58.59%] [G loss: 0.995654]\n",
      "epoch:10 step:9727 [D loss: 0.648368, acc.: 58.59%] [G loss: 0.930758]\n",
      "epoch:10 step:9728 [D loss: 0.548168, acc.: 77.34%] [G loss: 0.933853]\n",
      "epoch:10 step:9729 [D loss: 0.564653, acc.: 73.44%] [G loss: 1.048450]\n",
      "epoch:10 step:9730 [D loss: 0.746048, acc.: 50.78%] [G loss: 0.985628]\n",
      "epoch:10 step:9731 [D loss: 0.666581, acc.: 62.50%] [G loss: 0.933524]\n",
      "epoch:10 step:9732 [D loss: 0.668213, acc.: 55.47%] [G loss: 0.978578]\n",
      "epoch:10 step:9733 [D loss: 0.749121, acc.: 49.22%] [G loss: 0.753784]\n",
      "epoch:10 step:9734 [D loss: 0.683036, acc.: 60.16%] [G loss: 0.989619]\n",
      "epoch:10 step:9735 [D loss: 0.603748, acc.: 68.75%] [G loss: 1.095906]\n",
      "epoch:10 step:9736 [D loss: 0.662544, acc.: 63.28%] [G loss: 0.901319]\n",
      "epoch:10 step:9737 [D loss: 0.629177, acc.: 63.28%] [G loss: 1.068078]\n",
      "epoch:10 step:9738 [D loss: 0.685730, acc.: 62.50%] [G loss: 0.934566]\n",
      "epoch:10 step:9739 [D loss: 0.659189, acc.: 64.06%] [G loss: 0.960543]\n",
      "epoch:10 step:9740 [D loss: 0.696607, acc.: 53.91%] [G loss: 0.940257]\n",
      "epoch:10 step:9741 [D loss: 0.623433, acc.: 70.31%] [G loss: 0.920136]\n",
      "epoch:10 step:9742 [D loss: 0.651747, acc.: 64.06%] [G loss: 0.811069]\n",
      "epoch:10 step:9743 [D loss: 0.742828, acc.: 50.78%] [G loss: 0.887634]\n",
      "epoch:10 step:9744 [D loss: 0.599367, acc.: 67.97%] [G loss: 1.015320]\n",
      "epoch:10 step:9745 [D loss: 0.716144, acc.: 53.12%] [G loss: 0.766053]\n",
      "epoch:10 step:9746 [D loss: 0.737856, acc.: 51.56%] [G loss: 0.955837]\n",
      "epoch:10 step:9747 [D loss: 0.723574, acc.: 53.12%] [G loss: 0.979008]\n",
      "epoch:10 step:9748 [D loss: 0.765475, acc.: 48.44%] [G loss: 1.057993]\n",
      "epoch:10 step:9749 [D loss: 0.673057, acc.: 57.81%] [G loss: 0.788590]\n",
      "epoch:10 step:9750 [D loss: 0.614076, acc.: 66.41%] [G loss: 0.992949]\n",
      "epoch:10 step:9751 [D loss: 0.641505, acc.: 63.28%] [G loss: 0.907088]\n",
      "epoch:10 step:9752 [D loss: 0.615127, acc.: 67.19%] [G loss: 1.064212]\n",
      "epoch:10 step:9753 [D loss: 0.655336, acc.: 57.03%] [G loss: 1.003490]\n",
      "epoch:10 step:9754 [D loss: 0.561390, acc.: 76.56%] [G loss: 0.959405]\n",
      "epoch:10 step:9755 [D loss: 0.618785, acc.: 66.41%] [G loss: 1.081971]\n",
      "epoch:10 step:9756 [D loss: 0.704027, acc.: 49.22%] [G loss: 0.817331]\n",
      "epoch:10 step:9757 [D loss: 0.547859, acc.: 78.12%] [G loss: 0.938226]\n",
      "epoch:10 step:9758 [D loss: 0.598514, acc.: 71.88%] [G loss: 0.933908]\n",
      "epoch:10 step:9759 [D loss: 0.698763, acc.: 52.34%] [G loss: 1.073302]\n",
      "epoch:10 step:9760 [D loss: 0.751650, acc.: 51.56%] [G loss: 0.860972]\n",
      "epoch:10 step:9761 [D loss: 0.589095, acc.: 67.97%] [G loss: 0.970144]\n",
      "epoch:10 step:9762 [D loss: 0.637231, acc.: 59.38%] [G loss: 0.918589]\n",
      "epoch:10 step:9763 [D loss: 0.730593, acc.: 51.56%] [G loss: 0.925273]\n",
      "epoch:10 step:9764 [D loss: 0.592180, acc.: 76.56%] [G loss: 0.983845]\n",
      "epoch:10 step:9765 [D loss: 0.665529, acc.: 58.59%] [G loss: 0.987444]\n",
      "epoch:10 step:9766 [D loss: 0.648042, acc.: 58.59%] [G loss: 0.915711]\n",
      "epoch:10 step:9767 [D loss: 0.601201, acc.: 66.41%] [G loss: 1.052523]\n",
      "epoch:10 step:9768 [D loss: 0.485691, acc.: 82.03%] [G loss: 1.138936]\n",
      "epoch:10 step:9769 [D loss: 0.583199, acc.: 74.22%] [G loss: 1.205032]\n",
      "epoch:10 step:9770 [D loss: 0.530313, acc.: 75.78%] [G loss: 1.152816]\n",
      "epoch:10 step:9771 [D loss: 0.609745, acc.: 66.41%] [G loss: 1.064511]\n",
      "epoch:10 step:9772 [D loss: 0.599258, acc.: 68.75%] [G loss: 1.096404]\n",
      "epoch:10 step:9773 [D loss: 0.592878, acc.: 71.09%] [G loss: 1.112403]\n",
      "epoch:10 step:9774 [D loss: 0.527042, acc.: 73.44%] [G loss: 1.091923]\n",
      "epoch:10 step:9775 [D loss: 0.536759, acc.: 75.78%] [G loss: 1.136531]\n",
      "epoch:10 step:9776 [D loss: 0.608394, acc.: 69.53%] [G loss: 1.112280]\n",
      "epoch:10 step:9777 [D loss: 0.673788, acc.: 57.81%] [G loss: 1.096572]\n",
      "epoch:10 step:9778 [D loss: 0.571942, acc.: 67.97%] [G loss: 1.124576]\n",
      "epoch:10 step:9779 [D loss: 0.622146, acc.: 64.06%] [G loss: 1.109928]\n",
      "epoch:10 step:9780 [D loss: 0.592449, acc.: 69.53%] [G loss: 1.057267]\n",
      "epoch:10 step:9781 [D loss: 0.705792, acc.: 53.91%] [G loss: 0.998154]\n",
      "epoch:10 step:9782 [D loss: 0.729260, acc.: 56.25%] [G loss: 0.879620]\n",
      "epoch:10 step:9783 [D loss: 0.767309, acc.: 43.75%] [G loss: 0.849626]\n",
      "epoch:10 step:9784 [D loss: 0.778144, acc.: 48.44%] [G loss: 1.006154]\n",
      "epoch:10 step:9785 [D loss: 0.742106, acc.: 47.66%] [G loss: 1.048918]\n",
      "epoch:10 step:9786 [D loss: 0.752985, acc.: 48.44%] [G loss: 0.917719]\n",
      "epoch:10 step:9787 [D loss: 0.789373, acc.: 43.75%] [G loss: 0.863489]\n",
      "epoch:10 step:9788 [D loss: 0.756126, acc.: 48.44%] [G loss: 0.881991]\n",
      "epoch:10 step:9789 [D loss: 0.614830, acc.: 67.19%] [G loss: 0.960879]\n",
      "epoch:10 step:9790 [D loss: 0.591697, acc.: 71.09%] [G loss: 0.995907]\n",
      "epoch:10 step:9791 [D loss: 0.784699, acc.: 42.97%] [G loss: 1.035470]\n",
      "epoch:10 step:9792 [D loss: 0.866135, acc.: 39.06%] [G loss: 0.816308]\n",
      "epoch:10 step:9793 [D loss: 0.745799, acc.: 46.88%] [G loss: 0.878732]\n",
      "epoch:10 step:9794 [D loss: 0.644511, acc.: 59.38%] [G loss: 1.231847]\n",
      "epoch:10 step:9795 [D loss: 0.758105, acc.: 50.00%] [G loss: 1.041019]\n",
      "epoch:10 step:9796 [D loss: 0.589356, acc.: 67.19%] [G loss: 0.970728]\n",
      "epoch:10 step:9797 [D loss: 0.669394, acc.: 57.03%] [G loss: 1.042835]\n",
      "epoch:10 step:9798 [D loss: 0.657016, acc.: 60.16%] [G loss: 0.910935]\n",
      "epoch:10 step:9799 [D loss: 0.564326, acc.: 70.31%] [G loss: 1.098122]\n",
      "epoch:10 step:9800 [D loss: 0.619700, acc.: 64.06%] [G loss: 1.082015]\n",
      "epoch:10 step:9801 [D loss: 0.694598, acc.: 59.38%] [G loss: 0.894242]\n",
      "epoch:10 step:9802 [D loss: 0.670665, acc.: 61.72%] [G loss: 1.101331]\n",
      "epoch:10 step:9803 [D loss: 0.613173, acc.: 64.84%] [G loss: 1.096882]\n",
      "epoch:10 step:9804 [D loss: 0.689484, acc.: 55.47%] [G loss: 0.952818]\n",
      "epoch:10 step:9805 [D loss: 0.590487, acc.: 67.19%] [G loss: 1.058082]\n",
      "epoch:10 step:9806 [D loss: 0.497595, acc.: 82.81%] [G loss: 1.194825]\n",
      "epoch:10 step:9807 [D loss: 0.731766, acc.: 56.25%] [G loss: 1.027044]\n",
      "epoch:10 step:9808 [D loss: 0.714773, acc.: 53.91%] [G loss: 1.024439]\n",
      "epoch:10 step:9809 [D loss: 0.649805, acc.: 57.81%] [G loss: 1.039499]\n",
      "epoch:10 step:9810 [D loss: 0.713775, acc.: 56.25%] [G loss: 0.915146]\n",
      "epoch:10 step:9811 [D loss: 0.666826, acc.: 57.81%] [G loss: 0.957289]\n",
      "epoch:10 step:9812 [D loss: 0.578577, acc.: 72.66%] [G loss: 0.986259]\n",
      "epoch:10 step:9813 [D loss: 0.570586, acc.: 71.09%] [G loss: 1.046052]\n",
      "epoch:10 step:9814 [D loss: 0.576416, acc.: 71.88%] [G loss: 1.055402]\n",
      "epoch:10 step:9815 [D loss: 0.606584, acc.: 73.44%] [G loss: 1.060807]\n",
      "epoch:10 step:9816 [D loss: 0.713211, acc.: 58.59%] [G loss: 0.873894]\n",
      "epoch:10 step:9817 [D loss: 0.601877, acc.: 67.19%] [G loss: 0.924012]\n",
      "epoch:10 step:9818 [D loss: 0.555015, acc.: 78.12%] [G loss: 1.098801]\n",
      "epoch:10 step:9819 [D loss: 0.609261, acc.: 69.53%] [G loss: 1.049939]\n",
      "epoch:10 step:9820 [D loss: 0.638309, acc.: 63.28%] [G loss: 0.966484]\n",
      "epoch:10 step:9821 [D loss: 0.584455, acc.: 71.09%] [G loss: 1.094896]\n",
      "epoch:10 step:9822 [D loss: 0.592116, acc.: 70.31%] [G loss: 1.110462]\n",
      "epoch:10 step:9823 [D loss: 0.502975, acc.: 80.47%] [G loss: 1.267965]\n",
      "epoch:10 step:9824 [D loss: 0.598650, acc.: 65.62%] [G loss: 1.228161]\n",
      "epoch:10 step:9825 [D loss: 0.670550, acc.: 56.25%] [G loss: 0.990024]\n",
      "epoch:10 step:9826 [D loss: 0.673048, acc.: 53.91%] [G loss: 0.979694]\n",
      "epoch:10 step:9827 [D loss: 0.520950, acc.: 81.25%] [G loss: 1.277359]\n",
      "epoch:10 step:9828 [D loss: 0.812126, acc.: 41.41%] [G loss: 0.856994]\n",
      "epoch:10 step:9829 [D loss: 0.764482, acc.: 48.44%] [G loss: 0.843714]\n",
      "epoch:10 step:9830 [D loss: 0.704501, acc.: 53.12%] [G loss: 0.989522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9831 [D loss: 0.792939, acc.: 40.62%] [G loss: 0.817266]\n",
      "epoch:10 step:9832 [D loss: 0.797865, acc.: 42.19%] [G loss: 1.034905]\n",
      "epoch:10 step:9833 [D loss: 0.822585, acc.: 39.84%] [G loss: 0.875430]\n",
      "epoch:10 step:9834 [D loss: 0.787370, acc.: 46.88%] [G loss: 0.820553]\n",
      "epoch:10 step:9835 [D loss: 0.706249, acc.: 53.12%] [G loss: 0.965588]\n",
      "epoch:10 step:9836 [D loss: 0.641340, acc.: 64.06%] [G loss: 0.895194]\n",
      "epoch:10 step:9837 [D loss: 0.674736, acc.: 53.91%] [G loss: 1.020189]\n",
      "epoch:10 step:9838 [D loss: 0.575587, acc.: 67.97%] [G loss: 1.038533]\n",
      "epoch:10 step:9839 [D loss: 0.537075, acc.: 75.00%] [G loss: 0.992905]\n",
      "epoch:10 step:9840 [D loss: 0.591600, acc.: 70.31%] [G loss: 0.890123]\n",
      "epoch:10 step:9841 [D loss: 0.532373, acc.: 76.56%] [G loss: 0.989947]\n",
      "epoch:10 step:9842 [D loss: 0.708157, acc.: 57.03%] [G loss: 0.996117]\n",
      "epoch:10 step:9843 [D loss: 0.820565, acc.: 43.75%] [G loss: 1.155060]\n",
      "epoch:10 step:9844 [D loss: 0.614574, acc.: 69.53%] [G loss: 1.252603]\n",
      "epoch:10 step:9845 [D loss: 0.572867, acc.: 65.62%] [G loss: 1.128147]\n",
      "epoch:10 step:9846 [D loss: 0.624217, acc.: 67.97%] [G loss: 1.048713]\n",
      "epoch:10 step:9847 [D loss: 0.734106, acc.: 59.38%] [G loss: 0.932604]\n",
      "epoch:10 step:9848 [D loss: 0.694904, acc.: 51.56%] [G loss: 0.929886]\n",
      "epoch:10 step:9849 [D loss: 0.690617, acc.: 60.16%] [G loss: 0.794302]\n",
      "epoch:10 step:9850 [D loss: 0.665179, acc.: 58.59%] [G loss: 0.895086]\n",
      "epoch:10 step:9851 [D loss: 0.654204, acc.: 58.59%] [G loss: 0.792092]\n",
      "epoch:10 step:9852 [D loss: 0.675643, acc.: 58.59%] [G loss: 0.856093]\n",
      "epoch:10 step:9853 [D loss: 0.632506, acc.: 64.06%] [G loss: 0.883308]\n",
      "epoch:10 step:9854 [D loss: 0.656092, acc.: 57.03%] [G loss: 0.982225]\n",
      "epoch:10 step:9855 [D loss: 0.566882, acc.: 72.66%] [G loss: 1.122398]\n",
      "epoch:10 step:9856 [D loss: 0.597167, acc.: 71.09%] [G loss: 0.953656]\n",
      "epoch:10 step:9857 [D loss: 0.593366, acc.: 71.88%] [G loss: 1.099468]\n",
      "epoch:10 step:9858 [D loss: 0.638472, acc.: 60.94%] [G loss: 1.033210]\n",
      "epoch:10 step:9859 [D loss: 0.721856, acc.: 57.81%] [G loss: 1.006009]\n",
      "epoch:10 step:9860 [D loss: 0.656418, acc.: 59.38%] [G loss: 1.080801]\n",
      "epoch:10 step:9861 [D loss: 0.726331, acc.: 53.12%] [G loss: 0.905693]\n",
      "epoch:10 step:9862 [D loss: 0.713105, acc.: 51.56%] [G loss: 0.951609]\n",
      "epoch:10 step:9863 [D loss: 0.613939, acc.: 69.53%] [G loss: 0.922666]\n",
      "epoch:10 step:9864 [D loss: 0.660902, acc.: 57.81%] [G loss: 0.814323]\n",
      "epoch:10 step:9865 [D loss: 0.615301, acc.: 67.19%] [G loss: 1.040173]\n",
      "epoch:10 step:9866 [D loss: 0.636771, acc.: 63.28%] [G loss: 0.948012]\n",
      "epoch:10 step:9867 [D loss: 0.592772, acc.: 67.19%] [G loss: 1.077595]\n",
      "epoch:10 step:9868 [D loss: 0.467996, acc.: 82.81%] [G loss: 1.113693]\n",
      "epoch:10 step:9869 [D loss: 0.486654, acc.: 80.47%] [G loss: 1.221874]\n",
      "epoch:10 step:9870 [D loss: 0.644176, acc.: 59.38%] [G loss: 1.143705]\n",
      "epoch:10 step:9871 [D loss: 0.624187, acc.: 60.16%] [G loss: 1.103862]\n",
      "epoch:10 step:9872 [D loss: 0.770872, acc.: 49.22%] [G loss: 0.982290]\n",
      "epoch:10 step:9873 [D loss: 0.649734, acc.: 59.38%] [G loss: 1.063829]\n",
      "epoch:10 step:9874 [D loss: 0.643332, acc.: 63.28%] [G loss: 0.993809]\n",
      "epoch:10 step:9875 [D loss: 0.632882, acc.: 64.84%] [G loss: 1.020799]\n",
      "epoch:10 step:9876 [D loss: 0.746754, acc.: 52.34%] [G loss: 1.047857]\n",
      "epoch:10 step:9877 [D loss: 0.601233, acc.: 66.41%] [G loss: 0.976783]\n",
      "epoch:10 step:9878 [D loss: 0.573063, acc.: 71.09%] [G loss: 1.055062]\n",
      "epoch:10 step:9879 [D loss: 0.692522, acc.: 60.16%] [G loss: 1.085938]\n",
      "epoch:10 step:9880 [D loss: 0.770957, acc.: 47.66%] [G loss: 0.897407]\n",
      "epoch:10 step:9881 [D loss: 0.640673, acc.: 61.72%] [G loss: 0.861578]\n",
      "epoch:10 step:9882 [D loss: 0.693973, acc.: 52.34%] [G loss: 0.896665]\n",
      "epoch:10 step:9883 [D loss: 0.631373, acc.: 64.84%] [G loss: 0.876328]\n",
      "epoch:10 step:9884 [D loss: 0.656365, acc.: 61.72%] [G loss: 0.831354]\n",
      "epoch:10 step:9885 [D loss: 0.615357, acc.: 64.06%] [G loss: 0.857881]\n",
      "epoch:10 step:9886 [D loss: 0.573117, acc.: 69.53%] [G loss: 0.971734]\n",
      "epoch:10 step:9887 [D loss: 0.610028, acc.: 63.28%] [G loss: 1.004130]\n",
      "epoch:10 step:9888 [D loss: 0.640706, acc.: 63.28%] [G loss: 0.966980]\n",
      "epoch:10 step:9889 [D loss: 0.714682, acc.: 57.03%] [G loss: 0.961128]\n",
      "epoch:10 step:9890 [D loss: 0.556261, acc.: 78.12%] [G loss: 0.921721]\n",
      "epoch:10 step:9891 [D loss: 0.541211, acc.: 77.34%] [G loss: 1.225202]\n",
      "epoch:10 step:9892 [D loss: 0.532129, acc.: 78.12%] [G loss: 1.033760]\n",
      "epoch:10 step:9893 [D loss: 0.546771, acc.: 73.44%] [G loss: 0.946636]\n",
      "epoch:10 step:9894 [D loss: 0.715332, acc.: 55.47%] [G loss: 1.064905]\n",
      "epoch:10 step:9895 [D loss: 0.699154, acc.: 57.03%] [G loss: 0.960481]\n",
      "epoch:10 step:9896 [D loss: 0.669235, acc.: 61.72%] [G loss: 0.948355]\n",
      "epoch:10 step:9897 [D loss: 0.695453, acc.: 60.94%] [G loss: 0.966693]\n",
      "epoch:10 step:9898 [D loss: 0.759052, acc.: 47.66%] [G loss: 0.972503]\n",
      "epoch:10 step:9899 [D loss: 0.728307, acc.: 50.78%] [G loss: 0.930077]\n",
      "epoch:10 step:9900 [D loss: 0.685704, acc.: 61.72%] [G loss: 0.999259]\n",
      "epoch:10 step:9901 [D loss: 0.611082, acc.: 65.62%] [G loss: 0.825341]\n",
      "epoch:10 step:9902 [D loss: 0.580359, acc.: 70.31%] [G loss: 1.132257]\n",
      "epoch:10 step:9903 [D loss: 0.629563, acc.: 60.94%] [G loss: 1.003919]\n",
      "epoch:10 step:9904 [D loss: 0.626740, acc.: 66.41%] [G loss: 0.982865]\n",
      "epoch:10 step:9905 [D loss: 0.655861, acc.: 60.94%] [G loss: 1.014393]\n",
      "epoch:10 step:9906 [D loss: 0.585607, acc.: 74.22%] [G loss: 1.063184]\n",
      "epoch:10 step:9907 [D loss: 0.582133, acc.: 68.75%] [G loss: 1.057963]\n",
      "epoch:10 step:9908 [D loss: 0.655075, acc.: 61.72%] [G loss: 0.987855]\n",
      "epoch:10 step:9909 [D loss: 0.623012, acc.: 60.94%] [G loss: 1.094296]\n",
      "epoch:10 step:9910 [D loss: 0.641868, acc.: 62.50%] [G loss: 0.882596]\n",
      "epoch:10 step:9911 [D loss: 0.613778, acc.: 64.06%] [G loss: 0.896219]\n",
      "epoch:10 step:9912 [D loss: 0.707395, acc.: 60.16%] [G loss: 1.070246]\n",
      "epoch:10 step:9913 [D loss: 0.725277, acc.: 56.25%] [G loss: 0.912471]\n",
      "epoch:10 step:9914 [D loss: 0.678728, acc.: 55.47%] [G loss: 0.853073]\n",
      "epoch:10 step:9915 [D loss: 0.648727, acc.: 63.28%] [G loss: 0.908776]\n",
      "epoch:10 step:9916 [D loss: 0.589724, acc.: 75.00%] [G loss: 1.044440]\n",
      "epoch:10 step:9917 [D loss: 0.660117, acc.: 63.28%] [G loss: 0.990065]\n",
      "epoch:10 step:9918 [D loss: 0.634976, acc.: 60.94%] [G loss: 0.998125]\n",
      "epoch:10 step:9919 [D loss: 0.618369, acc.: 64.06%] [G loss: 0.964073]\n",
      "epoch:10 step:9920 [D loss: 0.570631, acc.: 72.66%] [G loss: 1.062488]\n",
      "epoch:10 step:9921 [D loss: 0.603571, acc.: 68.75%] [G loss: 1.023480]\n",
      "epoch:10 step:9922 [D loss: 0.551475, acc.: 76.56%] [G loss: 1.098052]\n",
      "epoch:10 step:9923 [D loss: 0.646932, acc.: 60.94%] [G loss: 1.052799]\n",
      "epoch:10 step:9924 [D loss: 0.570136, acc.: 74.22%] [G loss: 1.013473]\n",
      "epoch:10 step:9925 [D loss: 0.564541, acc.: 70.31%] [G loss: 1.243186]\n",
      "epoch:10 step:9926 [D loss: 0.580169, acc.: 71.09%] [G loss: 1.161474]\n",
      "epoch:10 step:9927 [D loss: 0.562895, acc.: 70.31%] [G loss: 0.953531]\n",
      "epoch:10 step:9928 [D loss: 0.567984, acc.: 72.66%] [G loss: 1.077589]\n",
      "epoch:10 step:9929 [D loss: 0.807895, acc.: 45.31%] [G loss: 1.077105]\n",
      "epoch:10 step:9930 [D loss: 0.750069, acc.: 46.09%] [G loss: 1.094181]\n",
      "epoch:10 step:9931 [D loss: 0.642185, acc.: 61.72%] [G loss: 1.147390]\n",
      "epoch:10 step:9932 [D loss: 0.771292, acc.: 45.31%] [G loss: 1.129891]\n",
      "epoch:10 step:9933 [D loss: 0.654967, acc.: 60.94%] [G loss: 1.091850]\n",
      "epoch:10 step:9934 [D loss: 0.672974, acc.: 58.59%] [G loss: 1.014453]\n",
      "epoch:10 step:9935 [D loss: 0.683366, acc.: 57.03%] [G loss: 0.926487]\n",
      "epoch:10 step:9936 [D loss: 0.584698, acc.: 74.22%] [G loss: 0.981110]\n",
      "epoch:10 step:9937 [D loss: 0.582191, acc.: 76.56%] [G loss: 1.028345]\n",
      "epoch:10 step:9938 [D loss: 0.616152, acc.: 65.62%] [G loss: 0.996352]\n",
      "epoch:10 step:9939 [D loss: 0.661251, acc.: 58.59%] [G loss: 0.916927]\n",
      "epoch:10 step:9940 [D loss: 0.606698, acc.: 68.75%] [G loss: 1.041649]\n",
      "epoch:10 step:9941 [D loss: 0.615744, acc.: 67.97%] [G loss: 0.942169]\n",
      "epoch:10 step:9942 [D loss: 0.660451, acc.: 58.59%] [G loss: 0.987052]\n",
      "epoch:10 step:9943 [D loss: 0.679344, acc.: 56.25%] [G loss: 0.931145]\n",
      "epoch:10 step:9944 [D loss: 0.659033, acc.: 62.50%] [G loss: 0.958121]\n",
      "epoch:10 step:9945 [D loss: 0.635784, acc.: 62.50%] [G loss: 0.904626]\n",
      "epoch:10 step:9946 [D loss: 0.686961, acc.: 60.94%] [G loss: 1.055155]\n",
      "epoch:10 step:9947 [D loss: 0.669446, acc.: 64.06%] [G loss: 0.946208]\n",
      "epoch:10 step:9948 [D loss: 0.548282, acc.: 76.56%] [G loss: 0.998334]\n",
      "epoch:10 step:9949 [D loss: 0.640716, acc.: 62.50%] [G loss: 0.978889]\n",
      "epoch:10 step:9950 [D loss: 0.756231, acc.: 46.09%] [G loss: 0.897201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9951 [D loss: 0.698626, acc.: 53.12%] [G loss: 0.927835]\n",
      "epoch:10 step:9952 [D loss: 0.717595, acc.: 55.47%] [G loss: 0.927200]\n",
      "epoch:10 step:9953 [D loss: 0.755580, acc.: 49.22%] [G loss: 0.833365]\n",
      "epoch:10 step:9954 [D loss: 0.618052, acc.: 64.06%] [G loss: 0.930108]\n",
      "epoch:10 step:9955 [D loss: 0.627766, acc.: 64.06%] [G loss: 1.068153]\n",
      "epoch:10 step:9956 [D loss: 0.643415, acc.: 59.38%] [G loss: 1.120740]\n",
      "epoch:10 step:9957 [D loss: 0.527641, acc.: 78.91%] [G loss: 1.075519]\n",
      "epoch:10 step:9958 [D loss: 0.538907, acc.: 76.56%] [G loss: 1.213931]\n",
      "epoch:10 step:9959 [D loss: 0.642599, acc.: 62.50%] [G loss: 0.919566]\n",
      "epoch:10 step:9960 [D loss: 0.727875, acc.: 53.12%] [G loss: 0.940285]\n",
      "epoch:10 step:9961 [D loss: 0.705905, acc.: 54.69%] [G loss: 0.915119]\n",
      "epoch:10 step:9962 [D loss: 0.634688, acc.: 65.62%] [G loss: 1.021707]\n",
      "epoch:10 step:9963 [D loss: 0.697670, acc.: 58.59%] [G loss: 0.878740]\n",
      "epoch:10 step:9964 [D loss: 0.743507, acc.: 47.66%] [G loss: 0.843554]\n",
      "epoch:10 step:9965 [D loss: 0.634828, acc.: 66.41%] [G loss: 1.032726]\n",
      "epoch:10 step:9966 [D loss: 0.755534, acc.: 48.44%] [G loss: 0.907787]\n",
      "epoch:10 step:9967 [D loss: 0.659431, acc.: 64.84%] [G loss: 1.009305]\n",
      "epoch:10 step:9968 [D loss: 0.495856, acc.: 78.12%] [G loss: 1.102828]\n",
      "epoch:10 step:9969 [D loss: 0.679099, acc.: 56.25%] [G loss: 0.931552]\n",
      "epoch:10 step:9970 [D loss: 0.686107, acc.: 53.12%] [G loss: 0.914489]\n",
      "epoch:10 step:9971 [D loss: 0.663412, acc.: 58.59%] [G loss: 1.002171]\n",
      "epoch:10 step:9972 [D loss: 0.680342, acc.: 58.59%] [G loss: 0.912003]\n",
      "epoch:10 step:9973 [D loss: 0.600450, acc.: 67.97%] [G loss: 0.961107]\n",
      "epoch:10 step:9974 [D loss: 0.566163, acc.: 71.88%] [G loss: 1.071227]\n",
      "epoch:10 step:9975 [D loss: 0.567128, acc.: 73.44%] [G loss: 0.949464]\n",
      "epoch:10 step:9976 [D loss: 0.683861, acc.: 53.12%] [G loss: 1.012494]\n",
      "epoch:10 step:9977 [D loss: 0.614460, acc.: 68.75%] [G loss: 0.845108]\n",
      "epoch:10 step:9978 [D loss: 0.647846, acc.: 61.72%] [G loss: 0.871739]\n",
      "epoch:10 step:9979 [D loss: 0.790016, acc.: 46.09%] [G loss: 0.844028]\n",
      "epoch:10 step:9980 [D loss: 0.688321, acc.: 57.81%] [G loss: 0.925674]\n",
      "epoch:10 step:9981 [D loss: 0.638637, acc.: 62.50%] [G loss: 1.046039]\n",
      "epoch:10 step:9982 [D loss: 0.611579, acc.: 67.19%] [G loss: 0.976680]\n",
      "epoch:10 step:9983 [D loss: 0.623936, acc.: 70.31%] [G loss: 0.902671]\n",
      "epoch:10 step:9984 [D loss: 0.654320, acc.: 62.50%] [G loss: 1.028670]\n",
      "epoch:10 step:9985 [D loss: 0.672965, acc.: 60.16%] [G loss: 0.911693]\n",
      "epoch:10 step:9986 [D loss: 0.537037, acc.: 76.56%] [G loss: 0.845520]\n",
      "epoch:10 step:9987 [D loss: 0.693003, acc.: 51.56%] [G loss: 0.900929]\n",
      "epoch:10 step:9988 [D loss: 0.646434, acc.: 63.28%] [G loss: 0.878151]\n",
      "epoch:10 step:9989 [D loss: 0.738267, acc.: 53.12%] [G loss: 0.937192]\n",
      "epoch:10 step:9990 [D loss: 0.737152, acc.: 53.12%] [G loss: 0.870954]\n",
      "epoch:10 step:9991 [D loss: 0.718399, acc.: 53.12%] [G loss: 0.839832]\n",
      "epoch:10 step:9992 [D loss: 0.600873, acc.: 71.88%] [G loss: 1.046259]\n",
      "epoch:10 step:9993 [D loss: 0.715894, acc.: 54.69%] [G loss: 1.099904]\n",
      "epoch:10 step:9994 [D loss: 0.579387, acc.: 69.53%] [G loss: 1.153659]\n",
      "epoch:10 step:9995 [D loss: 0.670193, acc.: 57.03%] [G loss: 1.045303]\n",
      "epoch:10 step:9996 [D loss: 0.659705, acc.: 59.38%] [G loss: 1.029926]\n",
      "epoch:10 step:9997 [D loss: 0.643577, acc.: 60.94%] [G loss: 0.887416]\n",
      "epoch:10 step:9998 [D loss: 0.657544, acc.: 56.25%] [G loss: 0.905793]\n",
      "epoch:10 step:9999 [D loss: 0.611018, acc.: 67.19%] [G loss: 0.951689]\n",
      "epoch:10 step:10000 [D loss: 0.609865, acc.: 63.28%] [G loss: 1.062360]\n",
      "epoch:10 step:10001 [D loss: 0.644929, acc.: 60.16%] [G loss: 0.895981]\n",
      "epoch:10 step:10002 [D loss: 0.642048, acc.: 59.38%] [G loss: 1.138445]\n",
      "epoch:10 step:10003 [D loss: 0.745875, acc.: 48.44%] [G loss: 0.902880]\n",
      "epoch:10 step:10004 [D loss: 0.595649, acc.: 71.88%] [G loss: 1.105126]\n",
      "epoch:10 step:10005 [D loss: 0.624898, acc.: 67.19%] [G loss: 1.142142]\n",
      "epoch:10 step:10006 [D loss: 0.710202, acc.: 48.44%] [G loss: 0.900736]\n",
      "epoch:10 step:10007 [D loss: 0.703018, acc.: 51.56%] [G loss: 0.994711]\n",
      "epoch:10 step:10008 [D loss: 0.619986, acc.: 66.41%] [G loss: 0.993327]\n",
      "epoch:10 step:10009 [D loss: 0.627904, acc.: 67.97%] [G loss: 1.082294]\n",
      "epoch:10 step:10010 [D loss: 0.667304, acc.: 58.59%] [G loss: 1.027105]\n",
      "epoch:10 step:10011 [D loss: 0.652099, acc.: 60.94%] [G loss: 1.000180]\n",
      "epoch:10 step:10012 [D loss: 0.522726, acc.: 78.12%] [G loss: 1.223326]\n",
      "epoch:10 step:10013 [D loss: 0.635810, acc.: 57.81%] [G loss: 1.097820]\n",
      "epoch:10 step:10014 [D loss: 0.603629, acc.: 65.62%] [G loss: 1.082686]\n",
      "epoch:10 step:10015 [D loss: 0.577410, acc.: 73.44%] [G loss: 1.123433]\n",
      "epoch:10 step:10016 [D loss: 0.624930, acc.: 66.41%] [G loss: 0.993637]\n",
      "epoch:10 step:10017 [D loss: 0.632989, acc.: 64.06%] [G loss: 0.968130]\n",
      "epoch:10 step:10018 [D loss: 0.561542, acc.: 76.56%] [G loss: 0.994149]\n",
      "epoch:10 step:10019 [D loss: 0.608134, acc.: 66.41%] [G loss: 0.860335]\n",
      "epoch:10 step:10020 [D loss: 0.585807, acc.: 63.28%] [G loss: 1.019326]\n",
      "epoch:10 step:10021 [D loss: 0.634711, acc.: 63.28%] [G loss: 1.121011]\n",
      "epoch:10 step:10022 [D loss: 0.762908, acc.: 50.78%] [G loss: 0.883271]\n",
      "epoch:10 step:10023 [D loss: 0.649845, acc.: 63.28%] [G loss: 1.071381]\n",
      "epoch:10 step:10024 [D loss: 0.709401, acc.: 50.78%] [G loss: 0.971778]\n",
      "epoch:10 step:10025 [D loss: 0.625150, acc.: 60.94%] [G loss: 1.038315]\n",
      "epoch:10 step:10026 [D loss: 0.656630, acc.: 60.16%] [G loss: 1.033241]\n",
      "epoch:10 step:10027 [D loss: 0.704372, acc.: 53.91%] [G loss: 0.913471]\n",
      "epoch:10 step:10028 [D loss: 0.700630, acc.: 51.56%] [G loss: 0.932086]\n",
      "epoch:10 step:10029 [D loss: 0.581947, acc.: 71.09%] [G loss: 0.911058]\n",
      "epoch:10 step:10030 [D loss: 0.636980, acc.: 62.50%] [G loss: 0.937441]\n",
      "epoch:10 step:10031 [D loss: 0.610112, acc.: 66.41%] [G loss: 1.098726]\n",
      "epoch:10 step:10032 [D loss: 0.602025, acc.: 66.41%] [G loss: 0.969080]\n",
      "epoch:10 step:10033 [D loss: 0.526672, acc.: 78.91%] [G loss: 0.950503]\n",
      "epoch:10 step:10034 [D loss: 0.593664, acc.: 71.88%] [G loss: 1.016042]\n",
      "epoch:10 step:10035 [D loss: 0.542751, acc.: 75.78%] [G loss: 0.997990]\n",
      "epoch:10 step:10036 [D loss: 0.538805, acc.: 73.44%] [G loss: 1.106274]\n",
      "epoch:10 step:10037 [D loss: 0.680521, acc.: 64.06%] [G loss: 0.820773]\n",
      "epoch:10 step:10038 [D loss: 0.634511, acc.: 60.94%] [G loss: 1.053054]\n",
      "epoch:10 step:10039 [D loss: 0.563839, acc.: 67.97%] [G loss: 1.100745]\n",
      "epoch:10 step:10040 [D loss: 0.605859, acc.: 67.19%] [G loss: 1.054295]\n",
      "epoch:10 step:10041 [D loss: 0.696484, acc.: 52.34%] [G loss: 0.858941]\n",
      "epoch:10 step:10042 [D loss: 0.649742, acc.: 61.72%] [G loss: 0.891611]\n",
      "epoch:10 step:10043 [D loss: 0.720004, acc.: 53.91%] [G loss: 0.970000]\n",
      "epoch:10 step:10044 [D loss: 0.793101, acc.: 48.44%] [G loss: 0.886891]\n",
      "epoch:10 step:10045 [D loss: 0.699683, acc.: 55.47%] [G loss: 1.047049]\n",
      "epoch:10 step:10046 [D loss: 0.602744, acc.: 69.53%] [G loss: 0.992068]\n",
      "epoch:10 step:10047 [D loss: 0.626575, acc.: 66.41%] [G loss: 0.999499]\n",
      "epoch:10 step:10048 [D loss: 0.698033, acc.: 47.66%] [G loss: 0.849557]\n",
      "epoch:10 step:10049 [D loss: 0.605706, acc.: 68.75%] [G loss: 1.074868]\n",
      "epoch:10 step:10050 [D loss: 0.599649, acc.: 69.53%] [G loss: 1.046946]\n",
      "epoch:10 step:10051 [D loss: 0.667273, acc.: 55.47%] [G loss: 0.894639]\n",
      "epoch:10 step:10052 [D loss: 0.668798, acc.: 61.72%] [G loss: 1.020349]\n",
      "epoch:10 step:10053 [D loss: 0.666147, acc.: 62.50%] [G loss: 0.922272]\n",
      "epoch:10 step:10054 [D loss: 0.655304, acc.: 64.06%] [G loss: 1.072645]\n",
      "epoch:10 step:10055 [D loss: 0.662678, acc.: 55.47%] [G loss: 0.906897]\n",
      "epoch:10 step:10056 [D loss: 0.683282, acc.: 57.81%] [G loss: 0.733622]\n",
      "epoch:10 step:10057 [D loss: 0.661801, acc.: 57.81%] [G loss: 0.990172]\n",
      "epoch:10 step:10058 [D loss: 0.712349, acc.: 55.47%] [G loss: 0.961705]\n",
      "epoch:10 step:10059 [D loss: 0.637543, acc.: 60.94%] [G loss: 0.938955]\n",
      "epoch:10 step:10060 [D loss: 0.520700, acc.: 75.78%] [G loss: 1.032941]\n",
      "epoch:10 step:10061 [D loss: 0.589968, acc.: 71.09%] [G loss: 1.015185]\n",
      "epoch:10 step:10062 [D loss: 0.721437, acc.: 52.34%] [G loss: 1.068496]\n",
      "epoch:10 step:10063 [D loss: 0.591196, acc.: 70.31%] [G loss: 1.033123]\n",
      "epoch:10 step:10064 [D loss: 0.529004, acc.: 76.56%] [G loss: 1.051923]\n",
      "epoch:10 step:10065 [D loss: 0.716999, acc.: 46.88%] [G loss: 0.950109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10066 [D loss: 0.731753, acc.: 49.22%] [G loss: 0.907845]\n",
      "epoch:10 step:10067 [D loss: 0.807342, acc.: 39.84%] [G loss: 0.809332]\n",
      "epoch:10 step:10068 [D loss: 0.722746, acc.: 51.56%] [G loss: 0.955938]\n",
      "epoch:10 step:10069 [D loss: 0.649212, acc.: 63.28%] [G loss: 0.868886]\n",
      "epoch:10 step:10070 [D loss: 0.578975, acc.: 67.97%] [G loss: 1.076775]\n",
      "epoch:10 step:10071 [D loss: 0.585050, acc.: 68.75%] [G loss: 0.952936]\n",
      "epoch:10 step:10072 [D loss: 0.657788, acc.: 62.50%] [G loss: 0.960800]\n",
      "epoch:10 step:10073 [D loss: 0.604295, acc.: 67.97%] [G loss: 1.041437]\n",
      "epoch:10 step:10074 [D loss: 0.670130, acc.: 60.16%] [G loss: 0.968684]\n",
      "epoch:10 step:10075 [D loss: 0.642626, acc.: 59.38%] [G loss: 0.947055]\n",
      "epoch:10 step:10076 [D loss: 0.564981, acc.: 71.88%] [G loss: 1.102624]\n",
      "epoch:10 step:10077 [D loss: 0.592244, acc.: 69.53%] [G loss: 1.088549]\n",
      "epoch:10 step:10078 [D loss: 0.610121, acc.: 68.75%] [G loss: 1.022926]\n",
      "epoch:10 step:10079 [D loss: 0.519242, acc.: 80.47%] [G loss: 1.031995]\n",
      "epoch:10 step:10080 [D loss: 0.642248, acc.: 62.50%] [G loss: 1.076851]\n",
      "epoch:10 step:10081 [D loss: 0.738509, acc.: 50.78%] [G loss: 0.965526]\n",
      "epoch:10 step:10082 [D loss: 0.678488, acc.: 58.59%] [G loss: 0.821849]\n",
      "epoch:10 step:10083 [D loss: 0.528080, acc.: 79.69%] [G loss: 1.107226]\n",
      "epoch:10 step:10084 [D loss: 0.615119, acc.: 67.97%] [G loss: 0.897254]\n",
      "epoch:10 step:10085 [D loss: 0.530201, acc.: 77.34%] [G loss: 1.108005]\n",
      "epoch:10 step:10086 [D loss: 0.719665, acc.: 51.56%] [G loss: 0.977994]\n",
      "epoch:10 step:10087 [D loss: 0.715649, acc.: 56.25%] [G loss: 0.868643]\n",
      "epoch:10 step:10088 [D loss: 0.753509, acc.: 44.53%] [G loss: 0.952611]\n",
      "epoch:10 step:10089 [D loss: 0.661255, acc.: 53.91%] [G loss: 0.861761]\n",
      "epoch:10 step:10090 [D loss: 0.647720, acc.: 57.81%] [G loss: 0.940760]\n",
      "epoch:10 step:10091 [D loss: 0.635448, acc.: 62.50%] [G loss: 0.860617]\n",
      "epoch:10 step:10092 [D loss: 0.754753, acc.: 52.34%] [G loss: 0.918369]\n",
      "epoch:10 step:10093 [D loss: 0.629739, acc.: 60.94%] [G loss: 1.043453]\n",
      "epoch:10 step:10094 [D loss: 0.616030, acc.: 61.72%] [G loss: 0.939467]\n",
      "epoch:10 step:10095 [D loss: 0.630140, acc.: 62.50%] [G loss: 0.898501]\n",
      "epoch:10 step:10096 [D loss: 0.632911, acc.: 61.72%] [G loss: 0.950443]\n",
      "epoch:10 step:10097 [D loss: 0.630612, acc.: 63.28%] [G loss: 0.954298]\n",
      "epoch:10 step:10098 [D loss: 0.645360, acc.: 63.28%] [G loss: 0.976737]\n",
      "epoch:10 step:10099 [D loss: 0.694588, acc.: 52.34%] [G loss: 1.032331]\n",
      "epoch:10 step:10100 [D loss: 0.677983, acc.: 53.12%] [G loss: 0.990581]\n",
      "epoch:10 step:10101 [D loss: 0.547440, acc.: 76.56%] [G loss: 1.084512]\n",
      "epoch:10 step:10102 [D loss: 0.618509, acc.: 62.50%] [G loss: 1.122984]\n",
      "epoch:10 step:10103 [D loss: 0.541442, acc.: 77.34%] [G loss: 1.002316]\n",
      "epoch:10 step:10104 [D loss: 0.593450, acc.: 69.53%] [G loss: 1.077733]\n",
      "epoch:10 step:10105 [D loss: 0.667741, acc.: 57.81%] [G loss: 0.988792]\n",
      "epoch:10 step:10106 [D loss: 0.827227, acc.: 46.09%] [G loss: 0.784991]\n",
      "epoch:10 step:10107 [D loss: 0.621259, acc.: 63.28%] [G loss: 1.133672]\n",
      "epoch:10 step:10108 [D loss: 0.668460, acc.: 60.16%] [G loss: 1.019367]\n",
      "epoch:10 step:10109 [D loss: 0.678452, acc.: 57.03%] [G loss: 1.118234]\n",
      "epoch:10 step:10110 [D loss: 0.712168, acc.: 51.56%] [G loss: 0.834878]\n",
      "epoch:10 step:10111 [D loss: 0.814095, acc.: 42.19%] [G loss: 0.999017]\n",
      "epoch:10 step:10112 [D loss: 0.716479, acc.: 51.56%] [G loss: 0.943489]\n",
      "epoch:10 step:10113 [D loss: 0.711476, acc.: 53.91%] [G loss: 0.877931]\n",
      "epoch:10 step:10114 [D loss: 0.791607, acc.: 44.53%] [G loss: 0.926882]\n",
      "epoch:10 step:10115 [D loss: 0.552250, acc.: 73.44%] [G loss: 1.015567]\n",
      "epoch:10 step:10116 [D loss: 0.652372, acc.: 60.94%] [G loss: 0.891874]\n",
      "epoch:10 step:10117 [D loss: 0.658731, acc.: 61.72%] [G loss: 1.000726]\n",
      "epoch:10 step:10118 [D loss: 0.692158, acc.: 59.38%] [G loss: 1.073488]\n",
      "epoch:10 step:10119 [D loss: 0.625293, acc.: 65.62%] [G loss: 0.905132]\n",
      "epoch:10 step:10120 [D loss: 0.662061, acc.: 64.84%] [G loss: 0.943012]\n",
      "epoch:10 step:10121 [D loss: 0.659463, acc.: 64.06%] [G loss: 0.879020]\n",
      "epoch:10 step:10122 [D loss: 0.796436, acc.: 44.53%] [G loss: 0.794371]\n",
      "epoch:10 step:10123 [D loss: 0.680764, acc.: 54.69%] [G loss: 0.857043]\n",
      "epoch:10 step:10124 [D loss: 0.715806, acc.: 52.34%] [G loss: 0.807212]\n",
      "epoch:10 step:10125 [D loss: 0.677279, acc.: 53.12%] [G loss: 0.936387]\n",
      "epoch:10 step:10126 [D loss: 0.582105, acc.: 70.31%] [G loss: 1.114592]\n",
      "epoch:10 step:10127 [D loss: 0.558536, acc.: 74.22%] [G loss: 1.163609]\n",
      "epoch:10 step:10128 [D loss: 0.717378, acc.: 49.22%] [G loss: 1.001572]\n",
      "epoch:10 step:10129 [D loss: 0.744056, acc.: 50.78%] [G loss: 0.957231]\n",
      "epoch:10 step:10130 [D loss: 0.694685, acc.: 57.03%] [G loss: 0.920401]\n",
      "epoch:10 step:10131 [D loss: 0.621687, acc.: 64.06%] [G loss: 1.083650]\n",
      "epoch:10 step:10132 [D loss: 0.798357, acc.: 47.66%] [G loss: 0.851275]\n",
      "epoch:10 step:10133 [D loss: 0.594050, acc.: 71.09%] [G loss: 1.097012]\n",
      "epoch:10 step:10134 [D loss: 0.632207, acc.: 66.41%] [G loss: 0.992722]\n",
      "epoch:10 step:10135 [D loss: 0.768578, acc.: 46.88%] [G loss: 0.936038]\n",
      "epoch:10 step:10136 [D loss: 0.674357, acc.: 63.28%] [G loss: 1.111531]\n",
      "epoch:10 step:10137 [D loss: 0.615807, acc.: 70.31%] [G loss: 0.962719]\n",
      "epoch:10 step:10138 [D loss: 0.571600, acc.: 70.31%] [G loss: 1.046900]\n",
      "epoch:10 step:10139 [D loss: 0.545443, acc.: 71.09%] [G loss: 0.933362]\n",
      "epoch:10 step:10140 [D loss: 0.593320, acc.: 72.66%] [G loss: 0.897400]\n",
      "epoch:10 step:10141 [D loss: 0.681795, acc.: 59.38%] [G loss: 0.946613]\n",
      "epoch:10 step:10142 [D loss: 0.669497, acc.: 63.28%] [G loss: 1.017301]\n",
      "epoch:10 step:10143 [D loss: 0.694238, acc.: 55.47%] [G loss: 0.915506]\n",
      "epoch:10 step:10144 [D loss: 0.469441, acc.: 79.69%] [G loss: 1.110518]\n",
      "epoch:10 step:10145 [D loss: 0.439913, acc.: 88.28%] [G loss: 1.181972]\n",
      "epoch:10 step:10146 [D loss: 0.560290, acc.: 70.31%] [G loss: 1.029360]\n",
      "epoch:10 step:10147 [D loss: 0.625214, acc.: 64.06%] [G loss: 0.868241]\n",
      "epoch:10 step:10148 [D loss: 0.733017, acc.: 53.12%] [G loss: 1.007003]\n",
      "epoch:10 step:10149 [D loss: 0.682053, acc.: 57.81%] [G loss: 1.228052]\n",
      "epoch:10 step:10150 [D loss: 0.729505, acc.: 53.91%] [G loss: 0.975378]\n",
      "epoch:10 step:10151 [D loss: 0.626376, acc.: 63.28%] [G loss: 1.006805]\n",
      "epoch:10 step:10152 [D loss: 0.670395, acc.: 58.59%] [G loss: 0.865771]\n",
      "epoch:10 step:10153 [D loss: 0.658838, acc.: 61.72%] [G loss: 1.009588]\n",
      "epoch:10 step:10154 [D loss: 0.614875, acc.: 63.28%] [G loss: 1.105147]\n",
      "epoch:10 step:10155 [D loss: 0.688445, acc.: 56.25%] [G loss: 0.857540]\n",
      "epoch:10 step:10156 [D loss: 0.576387, acc.: 69.53%] [G loss: 0.944324]\n",
      "epoch:10 step:10157 [D loss: 0.787501, acc.: 50.78%] [G loss: 0.914088]\n",
      "epoch:10 step:10158 [D loss: 0.755394, acc.: 45.31%] [G loss: 0.895741]\n",
      "epoch:10 step:10159 [D loss: 0.660093, acc.: 60.94%] [G loss: 0.938566]\n",
      "epoch:10 step:10160 [D loss: 0.583066, acc.: 69.53%] [G loss: 0.904183]\n",
      "epoch:10 step:10161 [D loss: 0.553767, acc.: 75.78%] [G loss: 1.142115]\n",
      "epoch:10 step:10162 [D loss: 0.542194, acc.: 72.66%] [G loss: 1.001906]\n",
      "epoch:10 step:10163 [D loss: 0.567077, acc.: 71.88%] [G loss: 1.073373]\n",
      "epoch:10 step:10164 [D loss: 0.592635, acc.: 67.97%] [G loss: 1.074704]\n",
      "epoch:10 step:10165 [D loss: 0.580699, acc.: 67.19%] [G loss: 1.159512]\n",
      "epoch:10 step:10166 [D loss: 0.638464, acc.: 63.28%] [G loss: 1.116365]\n",
      "epoch:10 step:10167 [D loss: 0.648887, acc.: 62.50%] [G loss: 1.019214]\n",
      "epoch:10 step:10168 [D loss: 0.692221, acc.: 54.69%] [G loss: 0.868231]\n",
      "epoch:10 step:10169 [D loss: 0.737811, acc.: 53.12%] [G loss: 0.731394]\n",
      "epoch:10 step:10170 [D loss: 0.712907, acc.: 53.91%] [G loss: 1.070615]\n",
      "epoch:10 step:10171 [D loss: 0.675294, acc.: 55.47%] [G loss: 1.047261]\n",
      "epoch:10 step:10172 [D loss: 0.680985, acc.: 57.81%] [G loss: 0.851310]\n",
      "epoch:10 step:10173 [D loss: 0.706787, acc.: 51.56%] [G loss: 0.943933]\n",
      "epoch:10 step:10174 [D loss: 0.635103, acc.: 62.50%] [G loss: 0.897643]\n",
      "epoch:10 step:10175 [D loss: 0.591098, acc.: 70.31%] [G loss: 0.975113]\n",
      "epoch:10 step:10176 [D loss: 0.585440, acc.: 67.97%] [G loss: 1.007857]\n",
      "epoch:10 step:10177 [D loss: 0.604972, acc.: 72.66%] [G loss: 0.983374]\n",
      "epoch:10 step:10178 [D loss: 0.711633, acc.: 53.91%] [G loss: 1.029343]\n",
      "epoch:10 step:10179 [D loss: 0.630325, acc.: 63.28%] [G loss: 1.112003]\n",
      "epoch:10 step:10180 [D loss: 0.559922, acc.: 72.66%] [G loss: 1.083153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10181 [D loss: 0.698027, acc.: 58.59%] [G loss: 0.898755]\n",
      "epoch:10 step:10182 [D loss: 0.692898, acc.: 58.59%] [G loss: 1.005554]\n",
      "epoch:10 step:10183 [D loss: 0.630694, acc.: 68.75%] [G loss: 0.961669]\n",
      "epoch:10 step:10184 [D loss: 0.701770, acc.: 56.25%] [G loss: 0.762323]\n",
      "epoch:10 step:10185 [D loss: 0.532162, acc.: 69.53%] [G loss: 1.038284]\n",
      "epoch:10 step:10186 [D loss: 0.610613, acc.: 68.75%] [G loss: 0.912180]\n",
      "epoch:10 step:10187 [D loss: 0.595596, acc.: 67.97%] [G loss: 1.130267]\n",
      "epoch:10 step:10188 [D loss: 0.666330, acc.: 60.94%] [G loss: 1.066754]\n",
      "epoch:10 step:10189 [D loss: 0.611250, acc.: 67.97%] [G loss: 0.892665]\n",
      "epoch:10 step:10190 [D loss: 0.680926, acc.: 54.69%] [G loss: 0.880865]\n",
      "epoch:10 step:10191 [D loss: 0.727514, acc.: 55.47%] [G loss: 0.864808]\n",
      "epoch:10 step:10192 [D loss: 0.739802, acc.: 46.88%] [G loss: 0.873397]\n",
      "epoch:10 step:10193 [D loss: 0.609269, acc.: 66.41%] [G loss: 0.964222]\n",
      "epoch:10 step:10194 [D loss: 0.643375, acc.: 60.16%] [G loss: 0.932613]\n",
      "epoch:10 step:10195 [D loss: 0.683466, acc.: 56.25%] [G loss: 0.884453]\n",
      "epoch:10 step:10196 [D loss: 0.705730, acc.: 57.81%] [G loss: 0.993934]\n",
      "epoch:10 step:10197 [D loss: 0.725864, acc.: 55.47%] [G loss: 0.891446]\n",
      "epoch:10 step:10198 [D loss: 0.687724, acc.: 53.91%] [G loss: 0.889398]\n",
      "epoch:10 step:10199 [D loss: 0.744165, acc.: 50.78%] [G loss: 0.758740]\n",
      "epoch:10 step:10200 [D loss: 0.585384, acc.: 70.31%] [G loss: 0.930102]\n",
      "epoch:10 step:10201 [D loss: 0.656646, acc.: 57.81%] [G loss: 0.897544]\n",
      "epoch:10 step:10202 [D loss: 0.601186, acc.: 65.62%] [G loss: 1.168326]\n",
      "epoch:10 step:10203 [D loss: 0.615315, acc.: 70.31%] [G loss: 1.015461]\n",
      "epoch:10 step:10204 [D loss: 0.652710, acc.: 58.59%] [G loss: 1.181096]\n",
      "epoch:10 step:10205 [D loss: 0.644969, acc.: 63.28%] [G loss: 1.115114]\n",
      "epoch:10 step:10206 [D loss: 0.767305, acc.: 46.88%] [G loss: 1.057338]\n",
      "epoch:10 step:10207 [D loss: 0.671721, acc.: 61.72%] [G loss: 1.082694]\n",
      "epoch:10 step:10208 [D loss: 0.589832, acc.: 67.97%] [G loss: 1.028060]\n",
      "epoch:10 step:10209 [D loss: 0.602447, acc.: 70.31%] [G loss: 1.027619]\n",
      "epoch:10 step:10210 [D loss: 0.607356, acc.: 67.19%] [G loss: 1.014396]\n",
      "epoch:10 step:10211 [D loss: 0.536897, acc.: 78.91%] [G loss: 0.877386]\n",
      "epoch:10 step:10212 [D loss: 0.510408, acc.: 77.34%] [G loss: 1.015846]\n",
      "epoch:10 step:10213 [D loss: 0.731723, acc.: 49.22%] [G loss: 0.862710]\n",
      "epoch:10 step:10214 [D loss: 0.785820, acc.: 47.66%] [G loss: 0.903205]\n",
      "epoch:10 step:10215 [D loss: 0.697870, acc.: 50.00%] [G loss: 0.770642]\n",
      "epoch:10 step:10216 [D loss: 0.607769, acc.: 64.84%] [G loss: 0.919998]\n",
      "epoch:10 step:10217 [D loss: 0.588531, acc.: 67.19%] [G loss: 0.955725]\n",
      "epoch:10 step:10218 [D loss: 0.571957, acc.: 73.44%] [G loss: 1.086737]\n",
      "epoch:10 step:10219 [D loss: 0.623736, acc.: 64.06%] [G loss: 0.956885]\n",
      "epoch:10 step:10220 [D loss: 0.644228, acc.: 66.41%] [G loss: 1.053693]\n",
      "epoch:10 step:10221 [D loss: 0.542057, acc.: 73.44%] [G loss: 0.980397]\n",
      "epoch:10 step:10222 [D loss: 0.472502, acc.: 82.03%] [G loss: 0.998423]\n",
      "epoch:10 step:10223 [D loss: 0.538809, acc.: 75.00%] [G loss: 0.990659]\n",
      "epoch:10 step:10224 [D loss: 0.482312, acc.: 82.81%] [G loss: 1.075472]\n",
      "epoch:10 step:10225 [D loss: 0.612219, acc.: 68.75%] [G loss: 0.951255]\n",
      "epoch:10 step:10226 [D loss: 0.608148, acc.: 66.41%] [G loss: 0.993844]\n",
      "epoch:10 step:10227 [D loss: 0.640880, acc.: 60.16%] [G loss: 0.946877]\n",
      "epoch:10 step:10228 [D loss: 0.792171, acc.: 48.44%] [G loss: 0.844191]\n",
      "epoch:10 step:10229 [D loss: 0.775227, acc.: 46.88%] [G loss: 0.970829]\n",
      "epoch:10 step:10230 [D loss: 0.583629, acc.: 72.66%] [G loss: 1.110334]\n",
      "epoch:10 step:10231 [D loss: 0.637779, acc.: 63.28%] [G loss: 0.958984]\n",
      "epoch:10 step:10232 [D loss: 0.690745, acc.: 60.16%] [G loss: 1.068617]\n",
      "epoch:10 step:10233 [D loss: 0.677214, acc.: 58.59%] [G loss: 0.850385]\n",
      "epoch:10 step:10234 [D loss: 0.687068, acc.: 53.91%] [G loss: 0.942575]\n",
      "epoch:10 step:10235 [D loss: 0.602360, acc.: 69.53%] [G loss: 0.976624]\n",
      "epoch:10 step:10236 [D loss: 0.668912, acc.: 59.38%] [G loss: 1.010322]\n",
      "epoch:10 step:10237 [D loss: 0.681782, acc.: 60.16%] [G loss: 0.873283]\n",
      "epoch:10 step:10238 [D loss: 0.638169, acc.: 59.38%] [G loss: 1.059769]\n",
      "epoch:10 step:10239 [D loss: 0.635687, acc.: 58.59%] [G loss: 0.950918]\n",
      "epoch:10 step:10240 [D loss: 0.694035, acc.: 50.78%] [G loss: 0.949935]\n",
      "epoch:10 step:10241 [D loss: 0.630972, acc.: 61.72%] [G loss: 0.889279]\n",
      "epoch:10 step:10242 [D loss: 0.693472, acc.: 57.03%] [G loss: 0.809225]\n",
      "epoch:10 step:10243 [D loss: 0.578635, acc.: 67.97%] [G loss: 1.057430]\n",
      "epoch:10 step:10244 [D loss: 0.554572, acc.: 72.66%] [G loss: 1.050804]\n",
      "epoch:10 step:10245 [D loss: 0.608671, acc.: 67.19%] [G loss: 0.836719]\n",
      "epoch:10 step:10246 [D loss: 0.633576, acc.: 66.41%] [G loss: 0.823406]\n",
      "epoch:10 step:10247 [D loss: 0.646076, acc.: 64.84%] [G loss: 0.952208]\n",
      "epoch:10 step:10248 [D loss: 0.573263, acc.: 74.22%] [G loss: 1.099349]\n",
      "epoch:10 step:10249 [D loss: 0.652858, acc.: 60.16%] [G loss: 1.027760]\n",
      "epoch:10 step:10250 [D loss: 0.741053, acc.: 53.91%] [G loss: 0.911097]\n",
      "epoch:10 step:10251 [D loss: 0.724347, acc.: 53.12%] [G loss: 0.875541]\n",
      "epoch:10 step:10252 [D loss: 0.642727, acc.: 57.03%] [G loss: 0.878584]\n",
      "epoch:10 step:10253 [D loss: 0.665930, acc.: 57.81%] [G loss: 0.940896]\n",
      "epoch:10 step:10254 [D loss: 0.640762, acc.: 64.06%] [G loss: 0.853884]\n",
      "epoch:10 step:10255 [D loss: 0.544405, acc.: 78.12%] [G loss: 0.969819]\n",
      "epoch:10 step:10256 [D loss: 0.586508, acc.: 69.53%] [G loss: 1.022787]\n",
      "epoch:10 step:10257 [D loss: 0.596150, acc.: 66.41%] [G loss: 1.045244]\n",
      "epoch:10 step:10258 [D loss: 0.561291, acc.: 75.00%] [G loss: 1.029617]\n",
      "epoch:10 step:10259 [D loss: 0.636326, acc.: 62.50%] [G loss: 0.894083]\n",
      "epoch:10 step:10260 [D loss: 0.574659, acc.: 73.44%] [G loss: 1.009945]\n",
      "epoch:10 step:10261 [D loss: 0.753587, acc.: 50.78%] [G loss: 0.988112]\n",
      "epoch:10 step:10262 [D loss: 0.660940, acc.: 57.81%] [G loss: 1.172249]\n",
      "epoch:10 step:10263 [D loss: 0.613864, acc.: 70.31%] [G loss: 0.986522]\n",
      "epoch:10 step:10264 [D loss: 0.561152, acc.: 75.00%] [G loss: 0.951741]\n",
      "epoch:10 step:10265 [D loss: 0.604751, acc.: 66.41%] [G loss: 1.111616]\n",
      "epoch:10 step:10266 [D loss: 0.668580, acc.: 55.47%] [G loss: 0.840892]\n",
      "epoch:10 step:10267 [D loss: 0.644556, acc.: 62.50%] [G loss: 1.019502]\n",
      "epoch:10 step:10268 [D loss: 0.618192, acc.: 65.62%] [G loss: 0.950036]\n",
      "epoch:10 step:10269 [D loss: 0.549982, acc.: 76.56%] [G loss: 1.085651]\n",
      "epoch:10 step:10270 [D loss: 0.500294, acc.: 78.12%] [G loss: 1.019037]\n",
      "epoch:10 step:10271 [D loss: 0.566955, acc.: 70.31%] [G loss: 1.110356]\n",
      "epoch:10 step:10272 [D loss: 0.650938, acc.: 61.72%] [G loss: 1.004350]\n",
      "epoch:10 step:10273 [D loss: 0.616243, acc.: 67.19%] [G loss: 1.000280]\n",
      "epoch:10 step:10274 [D loss: 0.754004, acc.: 53.91%] [G loss: 1.012175]\n",
      "epoch:10 step:10275 [D loss: 0.598636, acc.: 68.75%] [G loss: 1.017905]\n",
      "epoch:10 step:10276 [D loss: 0.616357, acc.: 64.84%] [G loss: 1.071079]\n",
      "epoch:10 step:10277 [D loss: 0.692970, acc.: 55.47%] [G loss: 1.025620]\n",
      "epoch:10 step:10278 [D loss: 0.679597, acc.: 56.25%] [G loss: 1.139237]\n",
      "epoch:10 step:10279 [D loss: 0.691991, acc.: 52.34%] [G loss: 0.943565]\n",
      "epoch:10 step:10280 [D loss: 0.508017, acc.: 82.81%] [G loss: 1.055199]\n",
      "epoch:10 step:10281 [D loss: 0.567198, acc.: 73.44%] [G loss: 1.000481]\n",
      "epoch:10 step:10282 [D loss: 0.457915, acc.: 83.59%] [G loss: 1.060601]\n",
      "epoch:10 step:10283 [D loss: 0.749963, acc.: 50.00%] [G loss: 0.977430]\n",
      "epoch:10 step:10284 [D loss: 0.715327, acc.: 54.69%] [G loss: 0.924852]\n",
      "epoch:10 step:10285 [D loss: 0.654136, acc.: 57.81%] [G loss: 0.913017]\n",
      "epoch:10 step:10286 [D loss: 0.626746, acc.: 65.62%] [G loss: 0.935374]\n",
      "epoch:10 step:10287 [D loss: 0.635826, acc.: 60.94%] [G loss: 0.890586]\n",
      "epoch:10 step:10288 [D loss: 0.553913, acc.: 72.66%] [G loss: 1.152219]\n",
      "epoch:10 step:10289 [D loss: 0.593873, acc.: 70.31%] [G loss: 0.958762]\n",
      "epoch:10 step:10290 [D loss: 0.643469, acc.: 60.94%] [G loss: 0.941599]\n",
      "epoch:10 step:10291 [D loss: 0.584543, acc.: 72.66%] [G loss: 1.156520]\n",
      "epoch:10 step:10292 [D loss: 0.553167, acc.: 71.88%] [G loss: 1.068121]\n",
      "epoch:10 step:10293 [D loss: 0.549719, acc.: 78.12%] [G loss: 1.025254]\n",
      "epoch:10 step:10294 [D loss: 0.456286, acc.: 85.16%] [G loss: 1.001070]\n",
      "epoch:10 step:10295 [D loss: 0.479543, acc.: 79.69%] [G loss: 1.225882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10296 [D loss: 0.444252, acc.: 85.16%] [G loss: 1.010689]\n",
      "epoch:10 step:10297 [D loss: 0.477701, acc.: 81.25%] [G loss: 1.148619]\n",
      "epoch:10 step:10298 [D loss: 0.819814, acc.: 46.88%] [G loss: 1.128401]\n",
      "epoch:10 step:10299 [D loss: 0.688591, acc.: 59.38%] [G loss: 0.932174]\n",
      "epoch:10 step:10300 [D loss: 0.580624, acc.: 72.66%] [G loss: 1.176590]\n",
      "epoch:10 step:10301 [D loss: 0.585786, acc.: 71.88%] [G loss: 1.142417]\n",
      "epoch:10 step:10302 [D loss: 0.603495, acc.: 70.31%] [G loss: 1.005057]\n",
      "epoch:10 step:10303 [D loss: 0.581366, acc.: 68.75%] [G loss: 1.022885]\n",
      "epoch:10 step:10304 [D loss: 0.553359, acc.: 72.66%] [G loss: 1.046916]\n",
      "epoch:10 step:10305 [D loss: 0.603074, acc.: 65.62%] [G loss: 0.917431]\n",
      "epoch:10 step:10306 [D loss: 0.516099, acc.: 78.12%] [G loss: 0.998520]\n",
      "epoch:10 step:10307 [D loss: 0.363446, acc.: 87.50%] [G loss: 1.214528]\n",
      "epoch:11 step:10308 [D loss: 0.640797, acc.: 60.16%] [G loss: 1.214166]\n",
      "epoch:11 step:10309 [D loss: 0.668530, acc.: 58.59%] [G loss: 1.237612]\n",
      "epoch:11 step:10310 [D loss: 0.755335, acc.: 51.56%] [G loss: 0.999649]\n",
      "epoch:11 step:10311 [D loss: 0.862112, acc.: 33.59%] [G loss: 0.880454]\n",
      "epoch:11 step:10312 [D loss: 0.642237, acc.: 64.06%] [G loss: 0.967419]\n",
      "epoch:11 step:10313 [D loss: 0.630059, acc.: 56.25%] [G loss: 1.046655]\n",
      "epoch:11 step:10314 [D loss: 0.588954, acc.: 68.75%] [G loss: 0.942356]\n",
      "epoch:11 step:10315 [D loss: 0.660717, acc.: 62.50%] [G loss: 0.868749]\n",
      "epoch:11 step:10316 [D loss: 0.566424, acc.: 73.44%] [G loss: 1.040301]\n",
      "epoch:11 step:10317 [D loss: 0.580696, acc.: 71.09%] [G loss: 1.050179]\n",
      "epoch:11 step:10318 [D loss: 0.608445, acc.: 64.06%] [G loss: 0.983151]\n",
      "epoch:11 step:10319 [D loss: 0.664384, acc.: 59.38%] [G loss: 0.996657]\n",
      "epoch:11 step:10320 [D loss: 0.780254, acc.: 43.75%] [G loss: 0.911333]\n",
      "epoch:11 step:10321 [D loss: 0.650093, acc.: 64.84%] [G loss: 1.095517]\n",
      "epoch:11 step:10322 [D loss: 0.589473, acc.: 64.84%] [G loss: 0.867773]\n",
      "epoch:11 step:10323 [D loss: 0.519474, acc.: 79.69%] [G loss: 1.192821]\n",
      "epoch:11 step:10324 [D loss: 0.633674, acc.: 62.50%] [G loss: 0.872803]\n",
      "epoch:11 step:10325 [D loss: 0.714730, acc.: 53.12%] [G loss: 1.032830]\n",
      "epoch:11 step:10326 [D loss: 0.643516, acc.: 57.03%] [G loss: 1.200591]\n",
      "epoch:11 step:10327 [D loss: 0.649865, acc.: 62.50%] [G loss: 1.032684]\n",
      "epoch:11 step:10328 [D loss: 0.666130, acc.: 58.59%] [G loss: 1.088807]\n",
      "epoch:11 step:10329 [D loss: 0.672297, acc.: 53.91%] [G loss: 1.053297]\n",
      "epoch:11 step:10330 [D loss: 0.629082, acc.: 64.84%] [G loss: 0.869545]\n",
      "epoch:11 step:10331 [D loss: 0.669776, acc.: 61.72%] [G loss: 0.913344]\n",
      "epoch:11 step:10332 [D loss: 0.581215, acc.: 67.97%] [G loss: 0.914021]\n",
      "epoch:11 step:10333 [D loss: 0.648370, acc.: 60.94%] [G loss: 0.860344]\n",
      "epoch:11 step:10334 [D loss: 0.520711, acc.: 78.12%] [G loss: 0.961785]\n",
      "epoch:11 step:10335 [D loss: 0.581129, acc.: 72.66%] [G loss: 1.205391]\n",
      "epoch:11 step:10336 [D loss: 0.522074, acc.: 75.00%] [G loss: 0.987819]\n",
      "epoch:11 step:10337 [D loss: 0.566328, acc.: 72.66%] [G loss: 0.918650]\n",
      "epoch:11 step:10338 [D loss: 0.561126, acc.: 71.88%] [G loss: 1.326232]\n",
      "epoch:11 step:10339 [D loss: 0.551301, acc.: 71.09%] [G loss: 1.249714]\n",
      "epoch:11 step:10340 [D loss: 0.682128, acc.: 53.91%] [G loss: 1.062680]\n",
      "epoch:11 step:10341 [D loss: 0.604469, acc.: 68.75%] [G loss: 1.224963]\n",
      "epoch:11 step:10342 [D loss: 0.476047, acc.: 82.03%] [G loss: 1.159706]\n",
      "epoch:11 step:10343 [D loss: 0.458447, acc.: 82.03%] [G loss: 1.291440]\n",
      "epoch:11 step:10344 [D loss: 0.654609, acc.: 61.72%] [G loss: 1.191205]\n",
      "epoch:11 step:10345 [D loss: 0.853575, acc.: 36.72%] [G loss: 0.945412]\n",
      "epoch:11 step:10346 [D loss: 0.652329, acc.: 62.50%] [G loss: 1.185170]\n",
      "epoch:11 step:10347 [D loss: 0.667533, acc.: 60.94%] [G loss: 1.050603]\n",
      "epoch:11 step:10348 [D loss: 0.579721, acc.: 70.31%] [G loss: 0.997377]\n",
      "epoch:11 step:10349 [D loss: 0.623410, acc.: 67.19%] [G loss: 0.966773]\n",
      "epoch:11 step:10350 [D loss: 0.626557, acc.: 63.28%] [G loss: 1.011618]\n",
      "epoch:11 step:10351 [D loss: 0.651166, acc.: 60.94%] [G loss: 1.088400]\n",
      "epoch:11 step:10352 [D loss: 0.798649, acc.: 39.06%] [G loss: 1.049393]\n",
      "epoch:11 step:10353 [D loss: 0.819487, acc.: 39.84%] [G loss: 0.949125]\n",
      "epoch:11 step:10354 [D loss: 0.565697, acc.: 72.66%] [G loss: 1.127761]\n",
      "epoch:11 step:10355 [D loss: 0.602081, acc.: 71.09%] [G loss: 1.057479]\n",
      "epoch:11 step:10356 [D loss: 0.537170, acc.: 77.34%] [G loss: 1.130459]\n",
      "epoch:11 step:10357 [D loss: 0.534824, acc.: 76.56%] [G loss: 1.160580]\n",
      "epoch:11 step:10358 [D loss: 0.614914, acc.: 64.06%] [G loss: 1.008510]\n",
      "epoch:11 step:10359 [D loss: 0.595211, acc.: 68.75%] [G loss: 1.100412]\n",
      "epoch:11 step:10360 [D loss: 0.636929, acc.: 67.19%] [G loss: 0.887762]\n",
      "epoch:11 step:10361 [D loss: 0.575373, acc.: 69.53%] [G loss: 0.908542]\n",
      "epoch:11 step:10362 [D loss: 0.568583, acc.: 70.31%] [G loss: 1.078158]\n",
      "epoch:11 step:10363 [D loss: 0.642125, acc.: 62.50%] [G loss: 0.933590]\n",
      "epoch:11 step:10364 [D loss: 0.744417, acc.: 51.56%] [G loss: 1.008588]\n",
      "epoch:11 step:10365 [D loss: 0.620115, acc.: 64.84%] [G loss: 0.928996]\n",
      "epoch:11 step:10366 [D loss: 0.660518, acc.: 58.59%] [G loss: 0.944272]\n",
      "epoch:11 step:10367 [D loss: 0.637474, acc.: 65.62%] [G loss: 0.983916]\n",
      "epoch:11 step:10368 [D loss: 0.664384, acc.: 58.59%] [G loss: 0.801052]\n",
      "epoch:11 step:10369 [D loss: 0.676059, acc.: 57.03%] [G loss: 0.753099]\n",
      "epoch:11 step:10370 [D loss: 0.615888, acc.: 70.31%] [G loss: 0.984694]\n",
      "epoch:11 step:10371 [D loss: 0.716020, acc.: 52.34%] [G loss: 1.049470]\n",
      "epoch:11 step:10372 [D loss: 0.620782, acc.: 64.84%] [G loss: 0.962952]\n",
      "epoch:11 step:10373 [D loss: 0.577935, acc.: 71.09%] [G loss: 0.942410]\n",
      "epoch:11 step:10374 [D loss: 0.609898, acc.: 64.84%] [G loss: 1.039830]\n",
      "epoch:11 step:10375 [D loss: 0.684669, acc.: 59.38%] [G loss: 0.898058]\n",
      "epoch:11 step:10376 [D loss: 0.460192, acc.: 85.16%] [G loss: 1.086557]\n",
      "epoch:11 step:10377 [D loss: 0.568338, acc.: 75.00%] [G loss: 1.028812]\n",
      "epoch:11 step:10378 [D loss: 0.687004, acc.: 59.38%] [G loss: 0.945122]\n",
      "epoch:11 step:10379 [D loss: 0.639148, acc.: 61.72%] [G loss: 0.896119]\n",
      "epoch:11 step:10380 [D loss: 0.678732, acc.: 60.94%] [G loss: 1.119746]\n",
      "epoch:11 step:10381 [D loss: 0.624534, acc.: 63.28%] [G loss: 0.954305]\n",
      "epoch:11 step:10382 [D loss: 0.499119, acc.: 83.59%] [G loss: 1.065796]\n",
      "epoch:11 step:10383 [D loss: 0.547668, acc.: 71.88%] [G loss: 1.055349]\n",
      "epoch:11 step:10384 [D loss: 0.495275, acc.: 82.81%] [G loss: 0.953762]\n",
      "epoch:11 step:10385 [D loss: 0.633558, acc.: 62.50%] [G loss: 1.073564]\n",
      "epoch:11 step:10386 [D loss: 0.730446, acc.: 48.44%] [G loss: 0.896578]\n",
      "epoch:11 step:10387 [D loss: 0.634502, acc.: 65.62%] [G loss: 1.050972]\n",
      "epoch:11 step:10388 [D loss: 0.838368, acc.: 39.84%] [G loss: 0.809498]\n",
      "epoch:11 step:10389 [D loss: 0.636862, acc.: 64.06%] [G loss: 1.011582]\n",
      "epoch:11 step:10390 [D loss: 0.578895, acc.: 71.88%] [G loss: 1.027152]\n",
      "epoch:11 step:10391 [D loss: 0.648635, acc.: 62.50%] [G loss: 0.990050]\n",
      "epoch:11 step:10392 [D loss: 0.664447, acc.: 60.94%] [G loss: 0.947132]\n",
      "epoch:11 step:10393 [D loss: 0.612848, acc.: 62.50%] [G loss: 0.998262]\n",
      "epoch:11 step:10394 [D loss: 0.645471, acc.: 61.72%] [G loss: 0.941026]\n",
      "epoch:11 step:10395 [D loss: 0.635080, acc.: 62.50%] [G loss: 0.951253]\n",
      "epoch:11 step:10396 [D loss: 0.711816, acc.: 50.78%] [G loss: 0.977007]\n",
      "epoch:11 step:10397 [D loss: 0.648566, acc.: 62.50%] [G loss: 0.865083]\n",
      "epoch:11 step:10398 [D loss: 0.627291, acc.: 64.84%] [G loss: 1.078721]\n",
      "epoch:11 step:10399 [D loss: 0.549517, acc.: 74.22%] [G loss: 0.952582]\n",
      "epoch:11 step:10400 [D loss: 0.627507, acc.: 63.28%] [G loss: 0.995313]\n",
      "epoch:11 step:10401 [D loss: 0.675929, acc.: 57.81%] [G loss: 0.885382]\n",
      "epoch:11 step:10402 [D loss: 0.773887, acc.: 46.09%] [G loss: 0.949737]\n",
      "epoch:11 step:10403 [D loss: 0.623199, acc.: 64.84%] [G loss: 0.961934]\n",
      "epoch:11 step:10404 [D loss: 0.649369, acc.: 60.94%] [G loss: 0.876423]\n",
      "epoch:11 step:10405 [D loss: 0.695054, acc.: 53.12%] [G loss: 1.003039]\n",
      "epoch:11 step:10406 [D loss: 0.680302, acc.: 60.16%] [G loss: 0.968746]\n",
      "epoch:11 step:10407 [D loss: 0.573657, acc.: 71.88%] [G loss: 0.965110]\n",
      "epoch:11 step:10408 [D loss: 0.593145, acc.: 70.31%] [G loss: 1.058136]\n",
      "epoch:11 step:10409 [D loss: 0.622297, acc.: 62.50%] [G loss: 1.014936]\n",
      "epoch:11 step:10410 [D loss: 0.620440, acc.: 64.84%] [G loss: 0.962834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10411 [D loss: 0.594225, acc.: 67.19%] [G loss: 1.011308]\n",
      "epoch:11 step:10412 [D loss: 0.719866, acc.: 54.69%] [G loss: 0.915535]\n",
      "epoch:11 step:10413 [D loss: 0.640866, acc.: 61.72%] [G loss: 1.157230]\n",
      "epoch:11 step:10414 [D loss: 0.581805, acc.: 69.53%] [G loss: 1.179273]\n",
      "epoch:11 step:10415 [D loss: 0.732285, acc.: 53.12%] [G loss: 0.978199]\n",
      "epoch:11 step:10416 [D loss: 0.636078, acc.: 67.97%] [G loss: 0.987791]\n",
      "epoch:11 step:10417 [D loss: 0.662995, acc.: 61.72%] [G loss: 0.886142]\n",
      "epoch:11 step:10418 [D loss: 0.616687, acc.: 69.53%] [G loss: 0.908631]\n",
      "epoch:11 step:10419 [D loss: 0.642702, acc.: 62.50%] [G loss: 0.971601]\n",
      "epoch:11 step:10420 [D loss: 0.716682, acc.: 56.25%] [G loss: 0.907714]\n",
      "epoch:11 step:10421 [D loss: 0.805059, acc.: 42.19%] [G loss: 0.846004]\n",
      "epoch:11 step:10422 [D loss: 0.600880, acc.: 71.88%] [G loss: 1.008604]\n",
      "epoch:11 step:10423 [D loss: 0.649946, acc.: 62.50%] [G loss: 0.859135]\n",
      "epoch:11 step:10424 [D loss: 0.642421, acc.: 64.84%] [G loss: 1.116458]\n",
      "epoch:11 step:10425 [D loss: 0.585495, acc.: 70.31%] [G loss: 0.972465]\n",
      "epoch:11 step:10426 [D loss: 0.474148, acc.: 80.47%] [G loss: 1.025789]\n",
      "epoch:11 step:10427 [D loss: 0.795120, acc.: 48.44%] [G loss: 0.973693]\n",
      "epoch:11 step:10428 [D loss: 0.627630, acc.: 67.97%] [G loss: 0.966900]\n",
      "epoch:11 step:10429 [D loss: 0.553748, acc.: 71.09%] [G loss: 1.000122]\n",
      "epoch:11 step:10430 [D loss: 0.630923, acc.: 65.62%] [G loss: 0.967773]\n",
      "epoch:11 step:10431 [D loss: 0.675314, acc.: 53.91%] [G loss: 0.812508]\n",
      "epoch:11 step:10432 [D loss: 0.607850, acc.: 66.41%] [G loss: 1.091070]\n",
      "epoch:11 step:10433 [D loss: 0.658137, acc.: 63.28%] [G loss: 0.935070]\n",
      "epoch:11 step:10434 [D loss: 0.658715, acc.: 58.59%] [G loss: 0.916256]\n",
      "epoch:11 step:10435 [D loss: 0.646892, acc.: 60.94%] [G loss: 0.949902]\n",
      "epoch:11 step:10436 [D loss: 0.730275, acc.: 58.59%] [G loss: 0.877233]\n",
      "epoch:11 step:10437 [D loss: 0.624166, acc.: 61.72%] [G loss: 0.980622]\n",
      "epoch:11 step:10438 [D loss: 0.522919, acc.: 79.69%] [G loss: 1.007700]\n",
      "epoch:11 step:10439 [D loss: 0.595474, acc.: 66.41%] [G loss: 0.929124]\n",
      "epoch:11 step:10440 [D loss: 0.702239, acc.: 55.47%] [G loss: 1.083500]\n",
      "epoch:11 step:10441 [D loss: 0.638193, acc.: 68.75%] [G loss: 1.162858]\n",
      "epoch:11 step:10442 [D loss: 0.677675, acc.: 55.47%] [G loss: 0.975199]\n",
      "epoch:11 step:10443 [D loss: 0.691219, acc.: 57.03%] [G loss: 0.914026]\n",
      "epoch:11 step:10444 [D loss: 0.737344, acc.: 52.34%] [G loss: 1.039480]\n",
      "epoch:11 step:10445 [D loss: 0.765814, acc.: 46.09%] [G loss: 0.966070]\n",
      "epoch:11 step:10446 [D loss: 0.543531, acc.: 75.00%] [G loss: 1.077258]\n",
      "epoch:11 step:10447 [D loss: 0.656165, acc.: 59.38%] [G loss: 1.009281]\n",
      "epoch:11 step:10448 [D loss: 0.587047, acc.: 69.53%] [G loss: 0.888135]\n",
      "epoch:11 step:10449 [D loss: 0.578188, acc.: 73.44%] [G loss: 1.077490]\n",
      "epoch:11 step:10450 [D loss: 0.670790, acc.: 57.03%] [G loss: 1.008911]\n",
      "epoch:11 step:10451 [D loss: 0.547248, acc.: 78.12%] [G loss: 1.231445]\n",
      "epoch:11 step:10452 [D loss: 0.586314, acc.: 71.88%] [G loss: 0.875490]\n",
      "epoch:11 step:10453 [D loss: 0.645518, acc.: 63.28%] [G loss: 0.956767]\n",
      "epoch:11 step:10454 [D loss: 0.648982, acc.: 57.81%] [G loss: 0.974030]\n",
      "epoch:11 step:10455 [D loss: 0.688247, acc.: 55.47%] [G loss: 0.954823]\n",
      "epoch:11 step:10456 [D loss: 0.727135, acc.: 52.34%] [G loss: 0.933322]\n",
      "epoch:11 step:10457 [D loss: 0.519623, acc.: 72.66%] [G loss: 1.026872]\n",
      "epoch:11 step:10458 [D loss: 0.490493, acc.: 82.03%] [G loss: 1.164700]\n",
      "epoch:11 step:10459 [D loss: 0.489277, acc.: 83.59%] [G loss: 1.135599]\n",
      "epoch:11 step:10460 [D loss: 0.796631, acc.: 51.56%] [G loss: 0.988601]\n",
      "epoch:11 step:10461 [D loss: 0.632416, acc.: 64.84%] [G loss: 0.985604]\n",
      "epoch:11 step:10462 [D loss: 0.676577, acc.: 60.16%] [G loss: 0.995380]\n",
      "epoch:11 step:10463 [D loss: 0.648311, acc.: 60.94%] [G loss: 1.092633]\n",
      "epoch:11 step:10464 [D loss: 0.662198, acc.: 61.72%] [G loss: 1.130086]\n",
      "epoch:11 step:10465 [D loss: 0.700089, acc.: 54.69%] [G loss: 0.934378]\n",
      "epoch:11 step:10466 [D loss: 0.625664, acc.: 66.41%] [G loss: 1.130791]\n",
      "epoch:11 step:10467 [D loss: 0.656842, acc.: 59.38%] [G loss: 1.008266]\n",
      "epoch:11 step:10468 [D loss: 0.718980, acc.: 53.12%] [G loss: 1.113641]\n",
      "epoch:11 step:10469 [D loss: 0.605328, acc.: 63.28%] [G loss: 1.102003]\n",
      "epoch:11 step:10470 [D loss: 0.642079, acc.: 61.72%] [G loss: 1.114088]\n",
      "epoch:11 step:10471 [D loss: 0.670032, acc.: 58.59%] [G loss: 0.911372]\n",
      "epoch:11 step:10472 [D loss: 0.641220, acc.: 62.50%] [G loss: 1.031981]\n",
      "epoch:11 step:10473 [D loss: 0.657518, acc.: 58.59%] [G loss: 1.112691]\n",
      "epoch:11 step:10474 [D loss: 0.681611, acc.: 55.47%] [G loss: 0.984299]\n",
      "epoch:11 step:10475 [D loss: 0.600179, acc.: 64.84%] [G loss: 1.123862]\n",
      "epoch:11 step:10476 [D loss: 0.772863, acc.: 48.44%] [G loss: 0.933186]\n",
      "epoch:11 step:10477 [D loss: 0.675739, acc.: 56.25%] [G loss: 0.980774]\n",
      "epoch:11 step:10478 [D loss: 0.642116, acc.: 62.50%] [G loss: 0.960342]\n",
      "epoch:11 step:10479 [D loss: 0.654363, acc.: 65.62%] [G loss: 1.068930]\n",
      "epoch:11 step:10480 [D loss: 0.606418, acc.: 69.53%] [G loss: 1.027064]\n",
      "epoch:11 step:10481 [D loss: 0.669040, acc.: 58.59%] [G loss: 0.993381]\n",
      "epoch:11 step:10482 [D loss: 0.715828, acc.: 52.34%] [G loss: 0.936303]\n",
      "epoch:11 step:10483 [D loss: 0.637266, acc.: 64.84%] [G loss: 1.040563]\n",
      "epoch:11 step:10484 [D loss: 0.643672, acc.: 59.38%] [G loss: 1.004401]\n",
      "epoch:11 step:10485 [D loss: 0.647284, acc.: 64.84%] [G loss: 0.995649]\n",
      "epoch:11 step:10486 [D loss: 0.683225, acc.: 58.59%] [G loss: 1.059114]\n",
      "epoch:11 step:10487 [D loss: 0.741499, acc.: 46.09%] [G loss: 0.904686]\n",
      "epoch:11 step:10488 [D loss: 0.598533, acc.: 68.75%] [G loss: 1.122921]\n",
      "epoch:11 step:10489 [D loss: 0.666633, acc.: 57.03%] [G loss: 0.819334]\n",
      "epoch:11 step:10490 [D loss: 0.751956, acc.: 48.44%] [G loss: 0.846125]\n",
      "epoch:11 step:10491 [D loss: 0.686647, acc.: 56.25%] [G loss: 0.895612]\n",
      "epoch:11 step:10492 [D loss: 0.756704, acc.: 49.22%] [G loss: 0.903132]\n",
      "epoch:11 step:10493 [D loss: 0.650942, acc.: 62.50%] [G loss: 1.097526]\n",
      "epoch:11 step:10494 [D loss: 0.749653, acc.: 39.84%] [G loss: 0.909722]\n",
      "epoch:11 step:10495 [D loss: 0.705835, acc.: 50.78%] [G loss: 0.950236]\n",
      "epoch:11 step:10496 [D loss: 0.692766, acc.: 53.91%] [G loss: 0.966718]\n",
      "epoch:11 step:10497 [D loss: 0.584084, acc.: 69.53%] [G loss: 0.987955]\n",
      "epoch:11 step:10498 [D loss: 0.704502, acc.: 56.25%] [G loss: 0.858376]\n",
      "epoch:11 step:10499 [D loss: 0.629487, acc.: 62.50%] [G loss: 0.997249]\n",
      "epoch:11 step:10500 [D loss: 0.657205, acc.: 60.16%] [G loss: 1.075118]\n",
      "epoch:11 step:10501 [D loss: 0.624996, acc.: 62.50%] [G loss: 1.158468]\n",
      "epoch:11 step:10502 [D loss: 0.586638, acc.: 69.53%] [G loss: 1.011638]\n",
      "epoch:11 step:10503 [D loss: 0.705773, acc.: 58.59%] [G loss: 1.073442]\n",
      "epoch:11 step:10504 [D loss: 0.666989, acc.: 57.81%] [G loss: 0.977589]\n",
      "epoch:11 step:10505 [D loss: 0.659215, acc.: 61.72%] [G loss: 1.005632]\n",
      "epoch:11 step:10506 [D loss: 0.677900, acc.: 57.03%] [G loss: 1.065477]\n",
      "epoch:11 step:10507 [D loss: 0.772916, acc.: 44.53%] [G loss: 0.791062]\n",
      "epoch:11 step:10508 [D loss: 0.667790, acc.: 59.38%] [G loss: 0.933722]\n",
      "epoch:11 step:10509 [D loss: 0.633328, acc.: 67.97%] [G loss: 1.026089]\n",
      "epoch:11 step:10510 [D loss: 0.786839, acc.: 43.75%] [G loss: 1.044000]\n",
      "epoch:11 step:10511 [D loss: 0.638795, acc.: 65.62%] [G loss: 0.915489]\n",
      "epoch:11 step:10512 [D loss: 0.683136, acc.: 56.25%] [G loss: 0.914556]\n",
      "epoch:11 step:10513 [D loss: 0.653083, acc.: 62.50%] [G loss: 0.959900]\n",
      "epoch:11 step:10514 [D loss: 0.665840, acc.: 55.47%] [G loss: 0.875562]\n",
      "epoch:11 step:10515 [D loss: 0.594349, acc.: 66.41%] [G loss: 0.950471]\n",
      "epoch:11 step:10516 [D loss: 0.640291, acc.: 63.28%] [G loss: 0.931041]\n",
      "epoch:11 step:10517 [D loss: 0.679060, acc.: 64.06%] [G loss: 0.904334]\n",
      "epoch:11 step:10518 [D loss: 0.689089, acc.: 57.03%] [G loss: 0.947803]\n",
      "epoch:11 step:10519 [D loss: 0.703122, acc.: 56.25%] [G loss: 0.927540]\n",
      "epoch:11 step:10520 [D loss: 0.588646, acc.: 67.19%] [G loss: 0.960367]\n",
      "epoch:11 step:10521 [D loss: 0.658471, acc.: 60.94%] [G loss: 0.994886]\n",
      "epoch:11 step:10522 [D loss: 0.705282, acc.: 55.47%] [G loss: 0.975519]\n",
      "epoch:11 step:10523 [D loss: 0.633022, acc.: 66.41%] [G loss: 0.998829]\n",
      "epoch:11 step:10524 [D loss: 0.585553, acc.: 68.75%] [G loss: 0.973899]\n",
      "epoch:11 step:10525 [D loss: 0.631616, acc.: 62.50%] [G loss: 1.060022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10526 [D loss: 0.672758, acc.: 57.03%] [G loss: 0.968859]\n",
      "epoch:11 step:10527 [D loss: 0.470606, acc.: 82.03%] [G loss: 1.094578]\n",
      "epoch:11 step:10528 [D loss: 0.547111, acc.: 72.66%] [G loss: 1.175014]\n",
      "epoch:11 step:10529 [D loss: 0.547056, acc.: 73.44%] [G loss: 1.026674]\n",
      "epoch:11 step:10530 [D loss: 0.533724, acc.: 76.56%] [G loss: 1.166930]\n",
      "epoch:11 step:10531 [D loss: 0.681397, acc.: 57.81%] [G loss: 1.030935]\n",
      "epoch:11 step:10532 [D loss: 0.716399, acc.: 50.00%] [G loss: 1.163974]\n",
      "epoch:11 step:10533 [D loss: 0.624300, acc.: 66.41%] [G loss: 0.973475]\n",
      "epoch:11 step:10534 [D loss: 0.682880, acc.: 56.25%] [G loss: 0.910937]\n",
      "epoch:11 step:10535 [D loss: 0.761455, acc.: 48.44%] [G loss: 0.812970]\n",
      "epoch:11 step:10536 [D loss: 0.591020, acc.: 68.75%] [G loss: 0.885009]\n",
      "epoch:11 step:10537 [D loss: 0.479389, acc.: 77.34%] [G loss: 0.984003]\n",
      "epoch:11 step:10538 [D loss: 0.514482, acc.: 76.56%] [G loss: 0.979067]\n",
      "epoch:11 step:10539 [D loss: 0.492872, acc.: 78.91%] [G loss: 1.160763]\n",
      "epoch:11 step:10540 [D loss: 0.674486, acc.: 60.94%] [G loss: 1.145877]\n",
      "epoch:11 step:10541 [D loss: 0.672072, acc.: 60.16%] [G loss: 1.094438]\n",
      "epoch:11 step:10542 [D loss: 0.631181, acc.: 69.53%] [G loss: 1.169647]\n",
      "epoch:11 step:10543 [D loss: 0.652247, acc.: 63.28%] [G loss: 0.922205]\n",
      "epoch:11 step:10544 [D loss: 0.614167, acc.: 67.19%] [G loss: 1.135101]\n",
      "epoch:11 step:10545 [D loss: 0.642635, acc.: 65.62%] [G loss: 1.097003]\n",
      "epoch:11 step:10546 [D loss: 0.546450, acc.: 71.09%] [G loss: 1.157564]\n",
      "epoch:11 step:10547 [D loss: 0.685512, acc.: 59.38%] [G loss: 1.019810]\n",
      "epoch:11 step:10548 [D loss: 0.644650, acc.: 58.59%] [G loss: 1.059994]\n",
      "epoch:11 step:10549 [D loss: 0.559110, acc.: 75.78%] [G loss: 0.996511]\n",
      "epoch:11 step:10550 [D loss: 0.668854, acc.: 59.38%] [G loss: 0.962892]\n",
      "epoch:11 step:10551 [D loss: 0.596607, acc.: 70.31%] [G loss: 0.951123]\n",
      "epoch:11 step:10552 [D loss: 0.621014, acc.: 62.50%] [G loss: 0.961444]\n",
      "epoch:11 step:10553 [D loss: 0.609840, acc.: 70.31%] [G loss: 1.048082]\n",
      "epoch:11 step:10554 [D loss: 0.651902, acc.: 69.53%] [G loss: 1.112549]\n",
      "epoch:11 step:10555 [D loss: 0.693307, acc.: 48.44%] [G loss: 1.076460]\n",
      "epoch:11 step:10556 [D loss: 0.699862, acc.: 57.81%] [G loss: 0.979383]\n",
      "epoch:11 step:10557 [D loss: 0.680121, acc.: 56.25%] [G loss: 1.090896]\n",
      "epoch:11 step:10558 [D loss: 0.710767, acc.: 54.69%] [G loss: 0.760652]\n",
      "epoch:11 step:10559 [D loss: 0.655743, acc.: 65.62%] [G loss: 0.954544]\n",
      "epoch:11 step:10560 [D loss: 0.654681, acc.: 59.38%] [G loss: 0.994401]\n",
      "epoch:11 step:10561 [D loss: 0.614819, acc.: 66.41%] [G loss: 1.042693]\n",
      "epoch:11 step:10562 [D loss: 0.698381, acc.: 56.25%] [G loss: 0.932287]\n",
      "epoch:11 step:10563 [D loss: 0.646023, acc.: 66.41%] [G loss: 0.999089]\n",
      "epoch:11 step:10564 [D loss: 0.651805, acc.: 64.84%] [G loss: 1.047900]\n",
      "epoch:11 step:10565 [D loss: 0.667967, acc.: 58.59%] [G loss: 0.935629]\n",
      "epoch:11 step:10566 [D loss: 0.607030, acc.: 66.41%] [G loss: 1.000443]\n",
      "epoch:11 step:10567 [D loss: 0.650290, acc.: 64.06%] [G loss: 1.156075]\n",
      "epoch:11 step:10568 [D loss: 0.697586, acc.: 56.25%] [G loss: 1.032487]\n",
      "epoch:11 step:10569 [D loss: 0.593231, acc.: 71.88%] [G loss: 0.991108]\n",
      "epoch:11 step:10570 [D loss: 0.707399, acc.: 50.78%] [G loss: 0.816127]\n",
      "epoch:11 step:10571 [D loss: 0.576961, acc.: 71.88%] [G loss: 1.054087]\n",
      "epoch:11 step:10572 [D loss: 0.629944, acc.: 59.38%] [G loss: 1.060408]\n",
      "epoch:11 step:10573 [D loss: 0.713886, acc.: 54.69%] [G loss: 1.140989]\n",
      "epoch:11 step:10574 [D loss: 0.622578, acc.: 59.38%] [G loss: 0.897351]\n",
      "epoch:11 step:10575 [D loss: 0.563117, acc.: 71.09%] [G loss: 1.156136]\n",
      "epoch:11 step:10576 [D loss: 0.632940, acc.: 66.41%] [G loss: 0.922911]\n",
      "epoch:11 step:10577 [D loss: 0.651290, acc.: 59.38%] [G loss: 0.940243]\n",
      "epoch:11 step:10578 [D loss: 0.666341, acc.: 54.69%] [G loss: 1.036864]\n",
      "epoch:11 step:10579 [D loss: 0.595292, acc.: 71.88%] [G loss: 1.016468]\n",
      "epoch:11 step:10580 [D loss: 0.622222, acc.: 67.19%] [G loss: 0.957742]\n",
      "epoch:11 step:10581 [D loss: 0.586453, acc.: 71.88%] [G loss: 1.046062]\n",
      "epoch:11 step:10582 [D loss: 0.725978, acc.: 57.81%] [G loss: 0.895114]\n",
      "epoch:11 step:10583 [D loss: 0.636612, acc.: 65.62%] [G loss: 1.218590]\n",
      "epoch:11 step:10584 [D loss: 0.679473, acc.: 54.69%] [G loss: 1.001069]\n",
      "epoch:11 step:10585 [D loss: 0.687930, acc.: 54.69%] [G loss: 0.962730]\n",
      "epoch:11 step:10586 [D loss: 0.574218, acc.: 73.44%] [G loss: 1.025554]\n",
      "epoch:11 step:10587 [D loss: 0.546296, acc.: 72.66%] [G loss: 1.163076]\n",
      "epoch:11 step:10588 [D loss: 0.716828, acc.: 50.78%] [G loss: 0.956230]\n",
      "epoch:11 step:10589 [D loss: 0.812473, acc.: 42.19%] [G loss: 0.854215]\n",
      "epoch:11 step:10590 [D loss: 0.750417, acc.: 48.44%] [G loss: 0.962560]\n",
      "epoch:11 step:10591 [D loss: 0.601498, acc.: 64.06%] [G loss: 1.057350]\n",
      "epoch:11 step:10592 [D loss: 0.598015, acc.: 67.97%] [G loss: 0.987822]\n",
      "epoch:11 step:10593 [D loss: 0.561599, acc.: 67.19%] [G loss: 0.963439]\n",
      "epoch:11 step:10594 [D loss: 0.664402, acc.: 58.59%] [G loss: 1.000278]\n",
      "epoch:11 step:10595 [D loss: 0.716104, acc.: 55.47%] [G loss: 1.165792]\n",
      "epoch:11 step:10596 [D loss: 0.627819, acc.: 67.97%] [G loss: 1.075513]\n",
      "epoch:11 step:10597 [D loss: 0.764954, acc.: 45.31%] [G loss: 0.796509]\n",
      "epoch:11 step:10598 [D loss: 0.619070, acc.: 65.62%] [G loss: 1.097240]\n",
      "epoch:11 step:10599 [D loss: 0.707988, acc.: 54.69%] [G loss: 1.024982]\n",
      "epoch:11 step:10600 [D loss: 0.586081, acc.: 64.84%] [G loss: 1.024067]\n",
      "epoch:11 step:10601 [D loss: 0.583039, acc.: 68.75%] [G loss: 1.086725]\n",
      "epoch:11 step:10602 [D loss: 0.640500, acc.: 64.84%] [G loss: 1.099131]\n",
      "epoch:11 step:10603 [D loss: 0.632055, acc.: 57.03%] [G loss: 0.943071]\n",
      "epoch:11 step:10604 [D loss: 0.674054, acc.: 57.03%] [G loss: 1.056276]\n",
      "epoch:11 step:10605 [D loss: 0.543762, acc.: 75.00%] [G loss: 1.090392]\n",
      "epoch:11 step:10606 [D loss: 0.589200, acc.: 71.09%] [G loss: 1.068065]\n",
      "epoch:11 step:10607 [D loss: 0.592439, acc.: 65.62%] [G loss: 1.068516]\n",
      "epoch:11 step:10608 [D loss: 0.729134, acc.: 53.12%] [G loss: 1.012660]\n",
      "epoch:11 step:10609 [D loss: 0.595227, acc.: 71.88%] [G loss: 0.994953]\n",
      "epoch:11 step:10610 [D loss: 0.651485, acc.: 61.72%] [G loss: 0.918632]\n",
      "epoch:11 step:10611 [D loss: 0.676718, acc.: 55.47%] [G loss: 0.883182]\n",
      "epoch:11 step:10612 [D loss: 0.694431, acc.: 56.25%] [G loss: 0.952051]\n",
      "epoch:11 step:10613 [D loss: 0.692197, acc.: 55.47%] [G loss: 0.889164]\n",
      "epoch:11 step:10614 [D loss: 0.662284, acc.: 58.59%] [G loss: 0.970766]\n",
      "epoch:11 step:10615 [D loss: 0.599789, acc.: 67.97%] [G loss: 1.088214]\n",
      "epoch:11 step:10616 [D loss: 0.575527, acc.: 72.66%] [G loss: 1.167207]\n",
      "epoch:11 step:10617 [D loss: 0.642773, acc.: 63.28%] [G loss: 0.944618]\n",
      "epoch:11 step:10618 [D loss: 0.688557, acc.: 63.28%] [G loss: 0.993207]\n",
      "epoch:11 step:10619 [D loss: 0.601657, acc.: 65.62%] [G loss: 0.866369]\n",
      "epoch:11 step:10620 [D loss: 0.468204, acc.: 82.03%] [G loss: 1.171058]\n",
      "epoch:11 step:10621 [D loss: 0.554058, acc.: 73.44%] [G loss: 1.176947]\n",
      "epoch:11 step:10622 [D loss: 0.487510, acc.: 79.69%] [G loss: 1.165762]\n",
      "epoch:11 step:10623 [D loss: 0.680073, acc.: 53.91%] [G loss: 1.105304]\n",
      "epoch:11 step:10624 [D loss: 0.724229, acc.: 54.69%] [G loss: 1.096815]\n",
      "epoch:11 step:10625 [D loss: 0.683202, acc.: 54.69%] [G loss: 0.789446]\n",
      "epoch:11 step:10626 [D loss: 0.768484, acc.: 43.75%] [G loss: 0.885242]\n",
      "epoch:11 step:10627 [D loss: 0.621392, acc.: 66.41%] [G loss: 1.050679]\n",
      "epoch:11 step:10628 [D loss: 0.564648, acc.: 73.44%] [G loss: 0.983171]\n",
      "epoch:11 step:10629 [D loss: 0.645889, acc.: 60.94%] [G loss: 1.042541]\n",
      "epoch:11 step:10630 [D loss: 0.667947, acc.: 64.06%] [G loss: 1.033132]\n",
      "epoch:11 step:10631 [D loss: 0.711888, acc.: 59.38%] [G loss: 1.104007]\n",
      "epoch:11 step:10632 [D loss: 0.731930, acc.: 51.56%] [G loss: 0.938175]\n",
      "epoch:11 step:10633 [D loss: 0.723404, acc.: 51.56%] [G loss: 0.907212]\n",
      "epoch:11 step:10634 [D loss: 0.573326, acc.: 71.09%] [G loss: 1.120135]\n",
      "epoch:11 step:10635 [D loss: 0.602295, acc.: 68.75%] [G loss: 1.050940]\n",
      "epoch:11 step:10636 [D loss: 0.693714, acc.: 57.81%] [G loss: 1.140221]\n",
      "epoch:11 step:10637 [D loss: 0.631761, acc.: 61.72%] [G loss: 0.994369]\n",
      "epoch:11 step:10638 [D loss: 0.626428, acc.: 65.62%] [G loss: 0.986347]\n",
      "epoch:11 step:10639 [D loss: 0.663329, acc.: 61.72%] [G loss: 0.995932]\n",
      "epoch:11 step:10640 [D loss: 0.603401, acc.: 64.84%] [G loss: 1.085183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10641 [D loss: 0.696102, acc.: 59.38%] [G loss: 0.916025]\n",
      "epoch:11 step:10642 [D loss: 0.650701, acc.: 60.16%] [G loss: 0.776636]\n",
      "epoch:11 step:10643 [D loss: 0.561845, acc.: 67.97%] [G loss: 0.990604]\n",
      "epoch:11 step:10644 [D loss: 0.598702, acc.: 67.97%] [G loss: 1.099003]\n",
      "epoch:11 step:10645 [D loss: 0.598773, acc.: 69.53%] [G loss: 1.030994]\n",
      "epoch:11 step:10646 [D loss: 0.632232, acc.: 64.06%] [G loss: 0.775169]\n",
      "epoch:11 step:10647 [D loss: 0.742011, acc.: 55.47%] [G loss: 0.900838]\n",
      "epoch:11 step:10648 [D loss: 0.723051, acc.: 51.56%] [G loss: 1.018591]\n",
      "epoch:11 step:10649 [D loss: 0.588863, acc.: 64.84%] [G loss: 1.075772]\n",
      "epoch:11 step:10650 [D loss: 0.567873, acc.: 67.97%] [G loss: 0.991277]\n",
      "epoch:11 step:10651 [D loss: 0.570769, acc.: 68.75%] [G loss: 1.182623]\n",
      "epoch:11 step:10652 [D loss: 0.597036, acc.: 68.75%] [G loss: 0.907740]\n",
      "epoch:11 step:10653 [D loss: 0.458205, acc.: 82.03%] [G loss: 1.121431]\n",
      "epoch:11 step:10654 [D loss: 0.524871, acc.: 77.34%] [G loss: 1.245818]\n",
      "epoch:11 step:10655 [D loss: 0.757103, acc.: 50.78%] [G loss: 1.029933]\n",
      "epoch:11 step:10656 [D loss: 0.780493, acc.: 47.66%] [G loss: 1.046863]\n",
      "epoch:11 step:10657 [D loss: 0.633955, acc.: 64.06%] [G loss: 1.055523]\n",
      "epoch:11 step:10658 [D loss: 0.595018, acc.: 65.62%] [G loss: 1.070905]\n",
      "epoch:11 step:10659 [D loss: 0.576942, acc.: 71.88%] [G loss: 1.082001]\n",
      "epoch:11 step:10660 [D loss: 0.598195, acc.: 66.41%] [G loss: 1.155357]\n",
      "epoch:11 step:10661 [D loss: 0.587404, acc.: 70.31%] [G loss: 1.049889]\n",
      "epoch:11 step:10662 [D loss: 0.729272, acc.: 54.69%] [G loss: 0.977283]\n",
      "epoch:11 step:10663 [D loss: 0.688064, acc.: 55.47%] [G loss: 1.042310]\n",
      "epoch:11 step:10664 [D loss: 0.579625, acc.: 69.53%] [G loss: 1.120304]\n",
      "epoch:11 step:10665 [D loss: 0.490467, acc.: 81.25%] [G loss: 1.037279]\n",
      "epoch:11 step:10666 [D loss: 0.567592, acc.: 73.44%] [G loss: 1.136568]\n",
      "epoch:11 step:10667 [D loss: 0.573067, acc.: 74.22%] [G loss: 1.120014]\n",
      "epoch:11 step:10668 [D loss: 0.713053, acc.: 53.91%] [G loss: 0.965148]\n",
      "epoch:11 step:10669 [D loss: 0.692726, acc.: 54.69%] [G loss: 0.923142]\n",
      "epoch:11 step:10670 [D loss: 0.727610, acc.: 55.47%] [G loss: 0.903411]\n",
      "epoch:11 step:10671 [D loss: 0.660428, acc.: 55.47%] [G loss: 1.170805]\n",
      "epoch:11 step:10672 [D loss: 0.640176, acc.: 61.72%] [G loss: 0.980197]\n",
      "epoch:11 step:10673 [D loss: 0.688995, acc.: 56.25%] [G loss: 0.955901]\n",
      "epoch:11 step:10674 [D loss: 0.585542, acc.: 70.31%] [G loss: 1.002822]\n",
      "epoch:11 step:10675 [D loss: 0.602530, acc.: 67.97%] [G loss: 1.059353]\n",
      "epoch:11 step:10676 [D loss: 0.643919, acc.: 59.38%] [G loss: 1.000871]\n",
      "epoch:11 step:10677 [D loss: 0.608251, acc.: 63.28%] [G loss: 0.929583]\n",
      "epoch:11 step:10678 [D loss: 0.618488, acc.: 66.41%] [G loss: 1.032653]\n",
      "epoch:11 step:10679 [D loss: 0.718423, acc.: 55.47%] [G loss: 0.943550]\n",
      "epoch:11 step:10680 [D loss: 0.706671, acc.: 53.91%] [G loss: 1.019110]\n",
      "epoch:11 step:10681 [D loss: 0.681863, acc.: 55.47%] [G loss: 0.956825]\n",
      "epoch:11 step:10682 [D loss: 0.769582, acc.: 46.88%] [G loss: 0.899547]\n",
      "epoch:11 step:10683 [D loss: 0.770362, acc.: 45.31%] [G loss: 0.781261]\n",
      "epoch:11 step:10684 [D loss: 0.635526, acc.: 66.41%] [G loss: 0.803060]\n",
      "epoch:11 step:10685 [D loss: 0.593679, acc.: 67.97%] [G loss: 1.026496]\n",
      "epoch:11 step:10686 [D loss: 0.731494, acc.: 52.34%] [G loss: 0.873048]\n",
      "epoch:11 step:10687 [D loss: 0.653254, acc.: 61.72%] [G loss: 0.981330]\n",
      "epoch:11 step:10688 [D loss: 0.546591, acc.: 74.22%] [G loss: 1.279938]\n",
      "epoch:11 step:10689 [D loss: 0.628505, acc.: 62.50%] [G loss: 0.998896]\n",
      "epoch:11 step:10690 [D loss: 0.622138, acc.: 64.84%] [G loss: 1.095358]\n",
      "epoch:11 step:10691 [D loss: 0.653622, acc.: 64.06%] [G loss: 1.016448]\n",
      "epoch:11 step:10692 [D loss: 0.639162, acc.: 63.28%] [G loss: 0.891041]\n",
      "epoch:11 step:10693 [D loss: 0.638683, acc.: 63.28%] [G loss: 0.923331]\n",
      "epoch:11 step:10694 [D loss: 0.536530, acc.: 80.47%] [G loss: 1.060837]\n",
      "epoch:11 step:10695 [D loss: 0.597619, acc.: 65.62%] [G loss: 0.869273]\n",
      "epoch:11 step:10696 [D loss: 0.580768, acc.: 72.66%] [G loss: 0.933391]\n",
      "epoch:11 step:10697 [D loss: 0.709833, acc.: 54.69%] [G loss: 0.833440]\n",
      "epoch:11 step:10698 [D loss: 0.648070, acc.: 63.28%] [G loss: 0.962996]\n",
      "epoch:11 step:10699 [D loss: 0.561232, acc.: 74.22%] [G loss: 1.087802]\n",
      "epoch:11 step:10700 [D loss: 0.790787, acc.: 49.22%] [G loss: 0.903962]\n",
      "epoch:11 step:10701 [D loss: 0.612937, acc.: 71.88%] [G loss: 0.983096]\n",
      "epoch:11 step:10702 [D loss: 0.671661, acc.: 59.38%] [G loss: 1.087229]\n",
      "epoch:11 step:10703 [D loss: 0.553722, acc.: 73.44%] [G loss: 1.049888]\n",
      "epoch:11 step:10704 [D loss: 0.606125, acc.: 64.06%] [G loss: 0.895221]\n",
      "epoch:11 step:10705 [D loss: 0.456596, acc.: 80.47%] [G loss: 1.159924]\n",
      "epoch:11 step:10706 [D loss: 0.479353, acc.: 83.59%] [G loss: 1.342805]\n",
      "epoch:11 step:10707 [D loss: 0.609395, acc.: 65.62%] [G loss: 1.143988]\n",
      "epoch:11 step:10708 [D loss: 0.510541, acc.: 78.12%] [G loss: 1.157872]\n",
      "epoch:11 step:10709 [D loss: 0.615541, acc.: 61.72%] [G loss: 1.146913]\n",
      "epoch:11 step:10710 [D loss: 0.544613, acc.: 75.78%] [G loss: 1.137545]\n",
      "epoch:11 step:10711 [D loss: 0.518732, acc.: 78.91%] [G loss: 0.951428]\n",
      "epoch:11 step:10712 [D loss: 0.483051, acc.: 80.47%] [G loss: 1.145938]\n",
      "epoch:11 step:10713 [D loss: 0.579322, acc.: 68.75%] [G loss: 1.028179]\n",
      "epoch:11 step:10714 [D loss: 0.548514, acc.: 74.22%] [G loss: 0.982298]\n",
      "epoch:11 step:10715 [D loss: 0.577012, acc.: 69.53%] [G loss: 1.181918]\n",
      "epoch:11 step:10716 [D loss: 0.692378, acc.: 57.81%] [G loss: 0.866250]\n",
      "epoch:11 step:10717 [D loss: 0.657795, acc.: 57.03%] [G loss: 1.097172]\n",
      "epoch:11 step:10718 [D loss: 0.774641, acc.: 45.31%] [G loss: 0.997717]\n",
      "epoch:11 step:10719 [D loss: 0.604530, acc.: 67.97%] [G loss: 1.074701]\n",
      "epoch:11 step:10720 [D loss: 0.719986, acc.: 47.66%] [G loss: 0.814180]\n",
      "epoch:11 step:10721 [D loss: 0.760568, acc.: 46.09%] [G loss: 0.891360]\n",
      "epoch:11 step:10722 [D loss: 0.691337, acc.: 56.25%] [G loss: 0.906712]\n",
      "epoch:11 step:10723 [D loss: 0.705748, acc.: 57.03%] [G loss: 0.961708]\n",
      "epoch:11 step:10724 [D loss: 0.731461, acc.: 47.66%] [G loss: 1.006452]\n",
      "epoch:11 step:10725 [D loss: 0.646301, acc.: 60.94%] [G loss: 0.890291]\n",
      "epoch:11 step:10726 [D loss: 0.490029, acc.: 78.12%] [G loss: 1.282915]\n",
      "epoch:11 step:10727 [D loss: 0.669292, acc.: 61.72%] [G loss: 0.986789]\n",
      "epoch:11 step:10728 [D loss: 0.808701, acc.: 39.84%] [G loss: 0.975129]\n",
      "epoch:11 step:10729 [D loss: 0.823343, acc.: 37.50%] [G loss: 0.864566]\n",
      "epoch:11 step:10730 [D loss: 0.855199, acc.: 41.41%] [G loss: 0.883995]\n",
      "epoch:11 step:10731 [D loss: 0.588644, acc.: 64.84%] [G loss: 0.962453]\n",
      "epoch:11 step:10732 [D loss: 0.729531, acc.: 53.12%] [G loss: 0.853749]\n",
      "epoch:11 step:10733 [D loss: 0.663863, acc.: 61.72%] [G loss: 0.843329]\n",
      "epoch:11 step:10734 [D loss: 0.659213, acc.: 54.69%] [G loss: 1.034516]\n",
      "epoch:11 step:10735 [D loss: 0.539390, acc.: 75.00%] [G loss: 1.174532]\n",
      "epoch:11 step:10736 [D loss: 0.672700, acc.: 60.16%] [G loss: 0.955492]\n",
      "epoch:11 step:10737 [D loss: 0.568027, acc.: 73.44%] [G loss: 1.056130]\n",
      "epoch:11 step:10738 [D loss: 0.815755, acc.: 41.41%] [G loss: 0.960831]\n",
      "epoch:11 step:10739 [D loss: 0.767047, acc.: 46.09%] [G loss: 0.841860]\n",
      "epoch:11 step:10740 [D loss: 0.662592, acc.: 60.94%] [G loss: 1.107523]\n",
      "epoch:11 step:10741 [D loss: 0.681715, acc.: 63.28%] [G loss: 1.053149]\n",
      "epoch:11 step:10742 [D loss: 0.633626, acc.: 66.41%] [G loss: 1.045575]\n",
      "epoch:11 step:10743 [D loss: 0.524963, acc.: 78.91%] [G loss: 1.279168]\n",
      "epoch:11 step:10744 [D loss: 0.659159, acc.: 66.41%] [G loss: 1.012044]\n",
      "epoch:11 step:10745 [D loss: 0.686262, acc.: 52.34%] [G loss: 0.893918]\n",
      "epoch:11 step:10746 [D loss: 0.686896, acc.: 54.69%] [G loss: 0.998701]\n",
      "epoch:11 step:10747 [D loss: 0.599645, acc.: 64.06%] [G loss: 1.032470]\n",
      "epoch:11 step:10748 [D loss: 0.624326, acc.: 70.31%] [G loss: 0.927189]\n",
      "epoch:11 step:10749 [D loss: 0.601164, acc.: 69.53%] [G loss: 1.010880]\n",
      "epoch:11 step:10750 [D loss: 0.571721, acc.: 78.12%] [G loss: 1.088615]\n",
      "epoch:11 step:10751 [D loss: 0.662477, acc.: 58.59%] [G loss: 1.048600]\n",
      "epoch:11 step:10752 [D loss: 0.637133, acc.: 64.06%] [G loss: 1.022557]\n",
      "epoch:11 step:10753 [D loss: 0.621802, acc.: 64.84%] [G loss: 1.022109]\n",
      "epoch:11 step:10754 [D loss: 0.655205, acc.: 60.94%] [G loss: 0.970392]\n",
      "epoch:11 step:10755 [D loss: 0.561013, acc.: 74.22%] [G loss: 1.128078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10756 [D loss: 0.525222, acc.: 73.44%] [G loss: 1.107764]\n",
      "epoch:11 step:10757 [D loss: 0.545153, acc.: 78.91%] [G loss: 1.088306]\n",
      "epoch:11 step:10758 [D loss: 0.540601, acc.: 75.00%] [G loss: 1.112783]\n",
      "epoch:11 step:10759 [D loss: 0.494881, acc.: 79.69%] [G loss: 1.244983]\n",
      "epoch:11 step:10760 [D loss: 0.490306, acc.: 76.56%] [G loss: 1.147316]\n",
      "epoch:11 step:10761 [D loss: 0.560469, acc.: 73.44%] [G loss: 1.171278]\n",
      "epoch:11 step:10762 [D loss: 0.579918, acc.: 65.62%] [G loss: 1.066691]\n",
      "epoch:11 step:10763 [D loss: 0.514239, acc.: 75.78%] [G loss: 1.010077]\n",
      "epoch:11 step:10764 [D loss: 0.494310, acc.: 76.56%] [G loss: 1.291968]\n",
      "epoch:11 step:10765 [D loss: 0.833621, acc.: 43.75%] [G loss: 1.022838]\n",
      "epoch:11 step:10766 [D loss: 0.696609, acc.: 52.34%] [G loss: 1.145637]\n",
      "epoch:11 step:10767 [D loss: 0.806111, acc.: 47.66%] [G loss: 0.988155]\n",
      "epoch:11 step:10768 [D loss: 0.866170, acc.: 35.94%] [G loss: 0.864409]\n",
      "epoch:11 step:10769 [D loss: 0.917519, acc.: 31.25%] [G loss: 0.863244]\n",
      "epoch:11 step:10770 [D loss: 0.758706, acc.: 53.12%] [G loss: 1.045395]\n",
      "epoch:11 step:10771 [D loss: 0.682855, acc.: 58.59%] [G loss: 0.929950]\n",
      "epoch:11 step:10772 [D loss: 0.726601, acc.: 57.03%] [G loss: 1.015448]\n",
      "epoch:11 step:10773 [D loss: 0.628630, acc.: 63.28%] [G loss: 0.978965]\n",
      "epoch:11 step:10774 [D loss: 0.769291, acc.: 48.44%] [G loss: 1.034785]\n",
      "epoch:11 step:10775 [D loss: 0.628149, acc.: 64.84%] [G loss: 1.074807]\n",
      "epoch:11 step:10776 [D loss: 0.605692, acc.: 71.09%] [G loss: 1.128543]\n",
      "epoch:11 step:10777 [D loss: 0.582022, acc.: 67.19%] [G loss: 1.146898]\n",
      "epoch:11 step:10778 [D loss: 0.570323, acc.: 72.66%] [G loss: 1.264233]\n",
      "epoch:11 step:10779 [D loss: 0.579231, acc.: 68.75%] [G loss: 1.261191]\n",
      "epoch:11 step:10780 [D loss: 0.801939, acc.: 46.09%] [G loss: 1.090180]\n",
      "epoch:11 step:10781 [D loss: 0.689528, acc.: 55.47%] [G loss: 0.937068]\n",
      "epoch:11 step:10782 [D loss: 0.649112, acc.: 61.72%] [G loss: 1.169249]\n",
      "epoch:11 step:10783 [D loss: 0.707624, acc.: 60.94%] [G loss: 1.200320]\n",
      "epoch:11 step:10784 [D loss: 0.671989, acc.: 60.94%] [G loss: 0.962758]\n",
      "epoch:11 step:10785 [D loss: 0.739307, acc.: 55.47%] [G loss: 1.002613]\n",
      "epoch:11 step:10786 [D loss: 0.611339, acc.: 65.62%] [G loss: 0.952089]\n",
      "epoch:11 step:10787 [D loss: 0.665881, acc.: 57.81%] [G loss: 1.044064]\n",
      "epoch:11 step:10788 [D loss: 0.654656, acc.: 62.50%] [G loss: 0.928734]\n",
      "epoch:11 step:10789 [D loss: 0.658381, acc.: 60.94%] [G loss: 1.057284]\n",
      "epoch:11 step:10790 [D loss: 0.700810, acc.: 53.91%] [G loss: 0.888039]\n",
      "epoch:11 step:10791 [D loss: 0.563007, acc.: 71.09%] [G loss: 1.098773]\n",
      "epoch:11 step:10792 [D loss: 0.558630, acc.: 70.31%] [G loss: 1.160843]\n",
      "epoch:11 step:10793 [D loss: 0.580330, acc.: 75.00%] [G loss: 1.262498]\n",
      "epoch:11 step:10794 [D loss: 0.574826, acc.: 71.88%] [G loss: 1.055759]\n",
      "epoch:11 step:10795 [D loss: 0.517902, acc.: 78.91%] [G loss: 0.959547]\n",
      "epoch:11 step:10796 [D loss: 0.715690, acc.: 53.12%] [G loss: 1.078079]\n",
      "epoch:11 step:10797 [D loss: 0.695316, acc.: 54.69%] [G loss: 0.931658]\n",
      "epoch:11 step:10798 [D loss: 0.651083, acc.: 66.41%] [G loss: 0.781243]\n",
      "epoch:11 step:10799 [D loss: 0.675623, acc.: 58.59%] [G loss: 0.914594]\n",
      "epoch:11 step:10800 [D loss: 0.708166, acc.: 50.78%] [G loss: 0.754139]\n",
      "epoch:11 step:10801 [D loss: 0.627636, acc.: 67.19%] [G loss: 0.865560]\n",
      "epoch:11 step:10802 [D loss: 0.611097, acc.: 63.28%] [G loss: 0.948544]\n",
      "epoch:11 step:10803 [D loss: 0.713965, acc.: 54.69%] [G loss: 0.899117]\n",
      "epoch:11 step:10804 [D loss: 0.522046, acc.: 77.34%] [G loss: 0.813022]\n",
      "epoch:11 step:10805 [D loss: 0.432347, acc.: 86.72%] [G loss: 0.938829]\n",
      "epoch:11 step:10806 [D loss: 0.511759, acc.: 75.00%] [G loss: 1.139405]\n",
      "epoch:11 step:10807 [D loss: 0.773263, acc.: 51.56%] [G loss: 1.079966]\n",
      "epoch:11 step:10808 [D loss: 0.680807, acc.: 56.25%] [G loss: 1.056235]\n",
      "epoch:11 step:10809 [D loss: 0.685528, acc.: 59.38%] [G loss: 0.994385]\n",
      "epoch:11 step:10810 [D loss: 0.674352, acc.: 60.94%] [G loss: 0.960624]\n",
      "epoch:11 step:10811 [D loss: 0.539130, acc.: 76.56%] [G loss: 1.127245]\n",
      "epoch:11 step:10812 [D loss: 0.768487, acc.: 48.44%] [G loss: 0.910678]\n",
      "epoch:11 step:10813 [D loss: 0.646602, acc.: 62.50%] [G loss: 1.024742]\n",
      "epoch:11 step:10814 [D loss: 0.636903, acc.: 64.84%] [G loss: 0.992711]\n",
      "epoch:11 step:10815 [D loss: 0.505694, acc.: 77.34%] [G loss: 0.985477]\n",
      "epoch:11 step:10816 [D loss: 0.703819, acc.: 58.59%] [G loss: 1.026337]\n",
      "epoch:11 step:10817 [D loss: 0.756212, acc.: 50.78%] [G loss: 0.991040]\n",
      "epoch:11 step:10818 [D loss: 0.679077, acc.: 60.16%] [G loss: 1.014618]\n",
      "epoch:11 step:10819 [D loss: 0.536489, acc.: 79.69%] [G loss: 0.991942]\n",
      "epoch:11 step:10820 [D loss: 0.567940, acc.: 73.44%] [G loss: 0.904955]\n",
      "epoch:11 step:10821 [D loss: 0.620696, acc.: 64.06%] [G loss: 0.905361]\n",
      "epoch:11 step:10822 [D loss: 0.582099, acc.: 71.09%] [G loss: 1.060237]\n",
      "epoch:11 step:10823 [D loss: 0.646514, acc.: 61.72%] [G loss: 0.864579]\n",
      "epoch:11 step:10824 [D loss: 0.779456, acc.: 46.88%] [G loss: 1.018965]\n",
      "epoch:11 step:10825 [D loss: 0.639454, acc.: 64.06%] [G loss: 0.982780]\n",
      "epoch:11 step:10826 [D loss: 0.565380, acc.: 70.31%] [G loss: 0.918454]\n",
      "epoch:11 step:10827 [D loss: 0.635502, acc.: 63.28%] [G loss: 0.940745]\n",
      "epoch:11 step:10828 [D loss: 0.605961, acc.: 65.62%] [G loss: 1.143015]\n",
      "epoch:11 step:10829 [D loss: 0.562640, acc.: 71.88%] [G loss: 1.025397]\n",
      "epoch:11 step:10830 [D loss: 0.562650, acc.: 74.22%] [G loss: 0.975062]\n",
      "epoch:11 step:10831 [D loss: 0.724784, acc.: 52.34%] [G loss: 1.066993]\n",
      "epoch:11 step:10832 [D loss: 0.672913, acc.: 60.16%] [G loss: 0.922609]\n",
      "epoch:11 step:10833 [D loss: 0.751148, acc.: 42.97%] [G loss: 1.088149]\n",
      "epoch:11 step:10834 [D loss: 0.665784, acc.: 62.50%] [G loss: 0.881919]\n",
      "epoch:11 step:10835 [D loss: 0.725250, acc.: 53.12%] [G loss: 0.959667]\n",
      "epoch:11 step:10836 [D loss: 0.615698, acc.: 62.50%] [G loss: 1.085641]\n",
      "epoch:11 step:10837 [D loss: 0.651071, acc.: 61.72%] [G loss: 1.034297]\n",
      "epoch:11 step:10838 [D loss: 0.660340, acc.: 66.41%] [G loss: 1.027650]\n",
      "epoch:11 step:10839 [D loss: 0.587421, acc.: 70.31%] [G loss: 1.033040]\n",
      "epoch:11 step:10840 [D loss: 0.572236, acc.: 76.56%] [G loss: 1.132341]\n",
      "epoch:11 step:10841 [D loss: 0.623899, acc.: 64.84%] [G loss: 0.940113]\n",
      "epoch:11 step:10842 [D loss: 0.579805, acc.: 71.88%] [G loss: 0.938462]\n",
      "epoch:11 step:10843 [D loss: 0.653965, acc.: 61.72%] [G loss: 0.878529]\n",
      "epoch:11 step:10844 [D loss: 0.630259, acc.: 67.19%] [G loss: 0.859548]\n",
      "epoch:11 step:10845 [D loss: 0.633069, acc.: 60.94%] [G loss: 1.168562]\n",
      "epoch:11 step:10846 [D loss: 0.651503, acc.: 64.06%] [G loss: 1.041985]\n",
      "epoch:11 step:10847 [D loss: 0.659364, acc.: 60.94%] [G loss: 1.000928]\n",
      "epoch:11 step:10848 [D loss: 0.683286, acc.: 56.25%] [G loss: 0.891137]\n",
      "epoch:11 step:10849 [D loss: 0.641963, acc.: 64.06%] [G loss: 1.043377]\n",
      "epoch:11 step:10850 [D loss: 0.741581, acc.: 50.78%] [G loss: 0.909474]\n",
      "epoch:11 step:10851 [D loss: 0.732750, acc.: 48.44%] [G loss: 0.805880]\n",
      "epoch:11 step:10852 [D loss: 0.588603, acc.: 69.53%] [G loss: 1.024709]\n",
      "epoch:11 step:10853 [D loss: 0.596911, acc.: 66.41%] [G loss: 0.935267]\n",
      "epoch:11 step:10854 [D loss: 0.544887, acc.: 75.00%] [G loss: 1.022659]\n",
      "epoch:11 step:10855 [D loss: 0.554204, acc.: 77.34%] [G loss: 0.991083]\n",
      "epoch:11 step:10856 [D loss: 0.529788, acc.: 76.56%] [G loss: 1.003296]\n",
      "epoch:11 step:10857 [D loss: 0.491751, acc.: 87.50%] [G loss: 1.172898]\n",
      "epoch:11 step:10858 [D loss: 0.551354, acc.: 75.00%] [G loss: 1.026685]\n",
      "epoch:11 step:10859 [D loss: 0.554168, acc.: 76.56%] [G loss: 1.088507]\n",
      "epoch:11 step:10860 [D loss: 0.608132, acc.: 67.19%] [G loss: 1.018211]\n",
      "epoch:11 step:10861 [D loss: 0.541003, acc.: 72.66%] [G loss: 1.104846]\n",
      "epoch:11 step:10862 [D loss: 0.488171, acc.: 82.81%] [G loss: 1.109389]\n",
      "epoch:11 step:10863 [D loss: 0.534704, acc.: 76.56%] [G loss: 1.048291]\n",
      "epoch:11 step:10864 [D loss: 0.522111, acc.: 78.91%] [G loss: 0.869789]\n",
      "epoch:11 step:10865 [D loss: 0.552072, acc.: 72.66%] [G loss: 1.158566]\n",
      "epoch:11 step:10866 [D loss: 0.688096, acc.: 55.47%] [G loss: 1.084344]\n",
      "epoch:11 step:10867 [D loss: 0.733162, acc.: 51.56%] [G loss: 1.030166]\n",
      "epoch:11 step:10868 [D loss: 0.600134, acc.: 68.75%] [G loss: 1.080736]\n",
      "epoch:11 step:10869 [D loss: 0.720508, acc.: 54.69%] [G loss: 0.951603]\n",
      "epoch:11 step:10870 [D loss: 0.635614, acc.: 64.06%] [G loss: 0.947131]\n",
      "epoch:11 step:10871 [D loss: 0.708886, acc.: 53.91%] [G loss: 0.922077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10872 [D loss: 0.605735, acc.: 72.66%] [G loss: 1.105643]\n",
      "epoch:11 step:10873 [D loss: 0.580232, acc.: 71.09%] [G loss: 0.918465]\n",
      "epoch:11 step:10874 [D loss: 0.602721, acc.: 64.06%] [G loss: 1.033714]\n",
      "epoch:11 step:10875 [D loss: 0.619069, acc.: 67.19%] [G loss: 0.993245]\n",
      "epoch:11 step:10876 [D loss: 0.773061, acc.: 43.75%] [G loss: 0.907516]\n",
      "epoch:11 step:10877 [D loss: 0.735916, acc.: 51.56%] [G loss: 0.926761]\n",
      "epoch:11 step:10878 [D loss: 0.667708, acc.: 60.16%] [G loss: 0.845504]\n",
      "epoch:11 step:10879 [D loss: 0.696088, acc.: 57.81%] [G loss: 0.907961]\n",
      "epoch:11 step:10880 [D loss: 0.692738, acc.: 57.81%] [G loss: 0.715371]\n",
      "epoch:11 step:10881 [D loss: 0.596633, acc.: 69.53%] [G loss: 0.987494]\n",
      "epoch:11 step:10882 [D loss: 0.718997, acc.: 50.00%] [G loss: 0.938955]\n",
      "epoch:11 step:10883 [D loss: 0.586033, acc.: 68.75%] [G loss: 1.126402]\n",
      "epoch:11 step:10884 [D loss: 0.662321, acc.: 57.81%] [G loss: 0.995968]\n",
      "epoch:11 step:10885 [D loss: 0.615470, acc.: 67.19%] [G loss: 0.946251]\n",
      "epoch:11 step:10886 [D loss: 0.709467, acc.: 53.91%] [G loss: 0.919153]\n",
      "epoch:11 step:10887 [D loss: 0.722616, acc.: 50.00%] [G loss: 0.833580]\n",
      "epoch:11 step:10888 [D loss: 0.706190, acc.: 54.69%] [G loss: 0.862746]\n",
      "epoch:11 step:10889 [D loss: 0.714157, acc.: 54.69%] [G loss: 0.931375]\n",
      "epoch:11 step:10890 [D loss: 0.698208, acc.: 55.47%] [G loss: 0.945417]\n",
      "epoch:11 step:10891 [D loss: 0.701447, acc.: 55.47%] [G loss: 1.018051]\n",
      "epoch:11 step:10892 [D loss: 0.661327, acc.: 60.16%] [G loss: 1.019221]\n",
      "epoch:11 step:10893 [D loss: 0.636249, acc.: 68.75%] [G loss: 0.920553]\n",
      "epoch:11 step:10894 [D loss: 0.551101, acc.: 73.44%] [G loss: 1.026583]\n",
      "epoch:11 step:10895 [D loss: 0.493754, acc.: 78.12%] [G loss: 1.074552]\n",
      "epoch:11 step:10896 [D loss: 0.467547, acc.: 80.47%] [G loss: 1.022853]\n",
      "epoch:11 step:10897 [D loss: 0.652188, acc.: 63.28%] [G loss: 1.161558]\n",
      "epoch:11 step:10898 [D loss: 0.675292, acc.: 57.81%] [G loss: 1.121145]\n",
      "epoch:11 step:10899 [D loss: 0.684940, acc.: 59.38%] [G loss: 0.966778]\n",
      "epoch:11 step:10900 [D loss: 0.617519, acc.: 67.97%] [G loss: 0.959490]\n",
      "epoch:11 step:10901 [D loss: 0.699730, acc.: 57.81%] [G loss: 1.023249]\n",
      "epoch:11 step:10902 [D loss: 0.699351, acc.: 56.25%] [G loss: 0.868379]\n",
      "epoch:11 step:10903 [D loss: 0.646076, acc.: 63.28%] [G loss: 0.947039]\n",
      "epoch:11 step:10904 [D loss: 0.566748, acc.: 70.31%] [G loss: 0.986594]\n",
      "epoch:11 step:10905 [D loss: 0.550829, acc.: 71.09%] [G loss: 0.964005]\n",
      "epoch:11 step:10906 [D loss: 0.705745, acc.: 50.00%] [G loss: 0.795930]\n",
      "epoch:11 step:10907 [D loss: 0.767312, acc.: 47.66%] [G loss: 0.803714]\n",
      "epoch:11 step:10908 [D loss: 0.676685, acc.: 63.28%] [G loss: 1.067215]\n",
      "epoch:11 step:10909 [D loss: 0.776935, acc.: 40.62%] [G loss: 0.848168]\n",
      "epoch:11 step:10910 [D loss: 0.584940, acc.: 68.75%] [G loss: 1.031881]\n",
      "epoch:11 step:10911 [D loss: 0.566133, acc.: 67.97%] [G loss: 1.104550]\n",
      "epoch:11 step:10912 [D loss: 0.526802, acc.: 76.56%] [G loss: 1.073106]\n",
      "epoch:11 step:10913 [D loss: 0.654200, acc.: 62.50%] [G loss: 1.101679]\n",
      "epoch:11 step:10914 [D loss: 0.624821, acc.: 64.06%] [G loss: 1.068331]\n",
      "epoch:11 step:10915 [D loss: 0.671439, acc.: 58.59%] [G loss: 0.995582]\n",
      "epoch:11 step:10916 [D loss: 0.667158, acc.: 57.03%] [G loss: 0.970560]\n",
      "epoch:11 step:10917 [D loss: 0.687807, acc.: 54.69%] [G loss: 0.922743]\n",
      "epoch:11 step:10918 [D loss: 0.666523, acc.: 59.38%] [G loss: 1.024944]\n",
      "epoch:11 step:10919 [D loss: 0.640132, acc.: 65.62%] [G loss: 1.088856]\n",
      "epoch:11 step:10920 [D loss: 0.596434, acc.: 68.75%] [G loss: 1.097737]\n",
      "epoch:11 step:10921 [D loss: 0.608087, acc.: 69.53%] [G loss: 1.089061]\n",
      "epoch:11 step:10922 [D loss: 0.564227, acc.: 71.09%] [G loss: 0.988463]\n",
      "epoch:11 step:10923 [D loss: 0.582505, acc.: 68.75%] [G loss: 1.177944]\n",
      "epoch:11 step:10924 [D loss: 0.595999, acc.: 68.75%] [G loss: 1.089083]\n",
      "epoch:11 step:10925 [D loss: 0.822874, acc.: 37.50%] [G loss: 0.975663]\n",
      "epoch:11 step:10926 [D loss: 0.810831, acc.: 45.31%] [G loss: 0.997218]\n",
      "epoch:11 step:10927 [D loss: 0.633699, acc.: 60.94%] [G loss: 1.125380]\n",
      "epoch:11 step:10928 [D loss: 0.798600, acc.: 40.62%] [G loss: 0.956101]\n",
      "epoch:11 step:10929 [D loss: 0.618589, acc.: 64.84%] [G loss: 0.852854]\n",
      "epoch:11 step:10930 [D loss: 0.656151, acc.: 60.94%] [G loss: 0.979293]\n",
      "epoch:11 step:10931 [D loss: 0.540034, acc.: 74.22%] [G loss: 1.213139]\n",
      "epoch:11 step:10932 [D loss: 0.642318, acc.: 63.28%] [G loss: 1.049749]\n",
      "epoch:11 step:10933 [D loss: 0.641235, acc.: 61.72%] [G loss: 0.837571]\n",
      "epoch:11 step:10934 [D loss: 0.589503, acc.: 70.31%] [G loss: 1.052709]\n",
      "epoch:11 step:10935 [D loss: 0.761456, acc.: 49.22%] [G loss: 0.955175]\n",
      "epoch:11 step:10936 [D loss: 0.589901, acc.: 67.97%] [G loss: 1.036338]\n",
      "epoch:11 step:10937 [D loss: 0.739393, acc.: 53.91%] [G loss: 0.896135]\n",
      "epoch:11 step:10938 [D loss: 0.683661, acc.: 57.03%] [G loss: 1.189394]\n",
      "epoch:11 step:10939 [D loss: 0.600257, acc.: 67.97%] [G loss: 1.119287]\n",
      "epoch:11 step:10940 [D loss: 0.617225, acc.: 66.41%] [G loss: 1.005888]\n",
      "epoch:11 step:10941 [D loss: 0.537538, acc.: 76.56%] [G loss: 0.965890]\n",
      "epoch:11 step:10942 [D loss: 0.525295, acc.: 77.34%] [G loss: 1.315971]\n",
      "epoch:11 step:10943 [D loss: 0.673437, acc.: 61.72%] [G loss: 0.932770]\n",
      "epoch:11 step:10944 [D loss: 0.921266, acc.: 25.00%] [G loss: 0.653758]\n",
      "epoch:11 step:10945 [D loss: 0.568133, acc.: 69.53%] [G loss: 1.133415]\n",
      "epoch:11 step:10946 [D loss: 0.731487, acc.: 52.34%] [G loss: 1.064597]\n",
      "epoch:11 step:10947 [D loss: 0.566740, acc.: 75.78%] [G loss: 1.115129]\n",
      "epoch:11 step:10948 [D loss: 0.522229, acc.: 75.00%] [G loss: 1.134553]\n",
      "epoch:11 step:10949 [D loss: 0.485993, acc.: 78.91%] [G loss: 1.376358]\n",
      "epoch:11 step:10950 [D loss: 0.623356, acc.: 60.16%] [G loss: 1.209539]\n",
      "epoch:11 step:10951 [D loss: 0.770877, acc.: 52.34%] [G loss: 1.241384]\n",
      "epoch:11 step:10952 [D loss: 0.562833, acc.: 73.44%] [G loss: 0.978382]\n",
      "epoch:11 step:10953 [D loss: 0.630363, acc.: 67.97%] [G loss: 0.998252]\n",
      "epoch:11 step:10954 [D loss: 0.576741, acc.: 73.44%] [G loss: 0.899088]\n",
      "epoch:11 step:10955 [D loss: 0.585619, acc.: 69.53%] [G loss: 1.153910]\n",
      "epoch:11 step:10956 [D loss: 0.477613, acc.: 82.03%] [G loss: 1.071169]\n",
      "epoch:11 step:10957 [D loss: 0.619243, acc.: 65.62%] [G loss: 0.927854]\n",
      "epoch:11 step:10958 [D loss: 0.592355, acc.: 66.41%] [G loss: 1.013461]\n",
      "epoch:11 step:10959 [D loss: 0.899611, acc.: 33.59%] [G loss: 0.911502]\n",
      "epoch:11 step:10960 [D loss: 0.756799, acc.: 40.62%] [G loss: 0.955919]\n",
      "epoch:11 step:10961 [D loss: 0.644434, acc.: 70.31%] [G loss: 0.986433]\n",
      "epoch:11 step:10962 [D loss: 0.698518, acc.: 51.56%] [G loss: 1.099501]\n",
      "epoch:11 step:10963 [D loss: 0.703824, acc.: 56.25%] [G loss: 0.977976]\n",
      "epoch:11 step:10964 [D loss: 0.692654, acc.: 57.03%] [G loss: 0.978032]\n",
      "epoch:11 step:10965 [D loss: 0.724461, acc.: 53.12%] [G loss: 0.981289]\n",
      "epoch:11 step:10966 [D loss: 0.602650, acc.: 62.50%] [G loss: 0.971362]\n",
      "epoch:11 step:10967 [D loss: 0.688544, acc.: 57.81%] [G loss: 0.897680]\n",
      "epoch:11 step:10968 [D loss: 0.612334, acc.: 67.19%] [G loss: 0.980244]\n",
      "epoch:11 step:10969 [D loss: 0.505376, acc.: 80.47%] [G loss: 1.123190]\n",
      "epoch:11 step:10970 [D loss: 0.447503, acc.: 84.38%] [G loss: 1.063620]\n",
      "epoch:11 step:10971 [D loss: 0.506824, acc.: 77.34%] [G loss: 1.234741]\n",
      "epoch:11 step:10972 [D loss: 0.515302, acc.: 75.78%] [G loss: 1.247214]\n",
      "epoch:11 step:10973 [D loss: 0.614686, acc.: 66.41%] [G loss: 1.032947]\n",
      "epoch:11 step:10974 [D loss: 0.689771, acc.: 56.25%] [G loss: 0.973262]\n",
      "epoch:11 step:10975 [D loss: 0.717516, acc.: 56.25%] [G loss: 0.911857]\n",
      "epoch:11 step:10976 [D loss: 0.636045, acc.: 64.84%] [G loss: 0.923459]\n",
      "epoch:11 step:10977 [D loss: 0.727318, acc.: 51.56%] [G loss: 0.840766]\n",
      "epoch:11 step:10978 [D loss: 0.703114, acc.: 55.47%] [G loss: 1.036259]\n",
      "epoch:11 step:10979 [D loss: 0.813693, acc.: 37.50%] [G loss: 0.875978]\n",
      "epoch:11 step:10980 [D loss: 0.789938, acc.: 41.41%] [G loss: 0.905907]\n",
      "epoch:11 step:10981 [D loss: 0.754368, acc.: 50.00%] [G loss: 0.973219]\n",
      "epoch:11 step:10982 [D loss: 0.632344, acc.: 61.72%] [G loss: 1.054669]\n",
      "epoch:11 step:10983 [D loss: 0.637164, acc.: 62.50%] [G loss: 1.118486]\n",
      "epoch:11 step:10984 [D loss: 0.619866, acc.: 67.97%] [G loss: 0.852234]\n",
      "epoch:11 step:10985 [D loss: 0.718536, acc.: 54.69%] [G loss: 0.943841]\n",
      "epoch:11 step:10986 [D loss: 0.665058, acc.: 60.94%] [G loss: 1.029482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10987 [D loss: 0.621962, acc.: 66.41%] [G loss: 1.019686]\n",
      "epoch:11 step:10988 [D loss: 0.637326, acc.: 64.84%] [G loss: 0.993349]\n",
      "epoch:11 step:10989 [D loss: 0.641149, acc.: 61.72%] [G loss: 1.026457]\n",
      "epoch:11 step:10990 [D loss: 0.533774, acc.: 75.00%] [G loss: 0.882040]\n",
      "epoch:11 step:10991 [D loss: 0.575438, acc.: 71.09%] [G loss: 0.893902]\n",
      "epoch:11 step:10992 [D loss: 0.586405, acc.: 72.66%] [G loss: 0.984382]\n",
      "epoch:11 step:10993 [D loss: 0.592014, acc.: 71.88%] [G loss: 1.003157]\n",
      "epoch:11 step:10994 [D loss: 0.638101, acc.: 60.16%] [G loss: 1.021268]\n",
      "epoch:11 step:10995 [D loss: 0.721402, acc.: 58.59%] [G loss: 1.107512]\n",
      "epoch:11 step:10996 [D loss: 0.614677, acc.: 65.62%] [G loss: 1.063383]\n",
      "epoch:11 step:10997 [D loss: 0.486163, acc.: 84.38%] [G loss: 1.163414]\n",
      "epoch:11 step:10998 [D loss: 0.496811, acc.: 78.91%] [G loss: 1.102365]\n",
      "epoch:11 step:10999 [D loss: 0.655930, acc.: 60.16%] [G loss: 0.911212]\n",
      "epoch:11 step:11000 [D loss: 0.552522, acc.: 71.88%] [G loss: 1.064426]\n",
      "epoch:11 step:11001 [D loss: 0.501847, acc.: 78.12%] [G loss: 1.123931]\n",
      "epoch:11 step:11002 [D loss: 0.613208, acc.: 67.19%] [G loss: 1.200103]\n",
      "epoch:11 step:11003 [D loss: 0.730174, acc.: 52.34%] [G loss: 1.015590]\n",
      "epoch:11 step:11004 [D loss: 0.681361, acc.: 57.03%] [G loss: 0.917222]\n",
      "epoch:11 step:11005 [D loss: 0.705795, acc.: 56.25%] [G loss: 0.829504]\n",
      "epoch:11 step:11006 [D loss: 0.754050, acc.: 53.12%] [G loss: 0.810939]\n",
      "epoch:11 step:11007 [D loss: 0.668962, acc.: 58.59%] [G loss: 0.945500]\n",
      "epoch:11 step:11008 [D loss: 0.650444, acc.: 62.50%] [G loss: 0.934618]\n",
      "epoch:11 step:11009 [D loss: 0.699084, acc.: 57.03%] [G loss: 0.846510]\n",
      "epoch:11 step:11010 [D loss: 0.678910, acc.: 56.25%] [G loss: 0.896151]\n",
      "epoch:11 step:11011 [D loss: 0.672281, acc.: 55.47%] [G loss: 0.956281]\n",
      "epoch:11 step:11012 [D loss: 0.664321, acc.: 57.81%] [G loss: 1.011131]\n",
      "epoch:11 step:11013 [D loss: 0.634328, acc.: 64.06%] [G loss: 0.849817]\n",
      "epoch:11 step:11014 [D loss: 0.557778, acc.: 73.44%] [G loss: 0.987875]\n",
      "epoch:11 step:11015 [D loss: 0.500618, acc.: 78.91%] [G loss: 1.251451]\n",
      "epoch:11 step:11016 [D loss: 0.465735, acc.: 82.81%] [G loss: 1.116316]\n",
      "epoch:11 step:11017 [D loss: 0.776187, acc.: 44.53%] [G loss: 0.972100]\n",
      "epoch:11 step:11018 [D loss: 0.736056, acc.: 47.66%] [G loss: 0.957654]\n",
      "epoch:11 step:11019 [D loss: 0.658263, acc.: 57.81%] [G loss: 0.989536]\n",
      "epoch:11 step:11020 [D loss: 0.478092, acc.: 82.03%] [G loss: 1.090607]\n",
      "epoch:11 step:11021 [D loss: 0.639171, acc.: 63.28%] [G loss: 1.091635]\n",
      "epoch:11 step:11022 [D loss: 0.602928, acc.: 68.75%] [G loss: 1.046050]\n",
      "epoch:11 step:11023 [D loss: 0.781183, acc.: 53.91%] [G loss: 0.903293]\n",
      "epoch:11 step:11024 [D loss: 0.731519, acc.: 52.34%] [G loss: 0.947197]\n",
      "epoch:11 step:11025 [D loss: 0.698831, acc.: 59.38%] [G loss: 0.839006]\n",
      "epoch:11 step:11026 [D loss: 0.593164, acc.: 67.97%] [G loss: 1.017484]\n",
      "epoch:11 step:11027 [D loss: 0.749857, acc.: 45.31%] [G loss: 0.888175]\n",
      "epoch:11 step:11028 [D loss: 0.670403, acc.: 60.16%] [G loss: 1.045678]\n",
      "epoch:11 step:11029 [D loss: 0.633626, acc.: 60.94%] [G loss: 0.902087]\n",
      "epoch:11 step:11030 [D loss: 0.558611, acc.: 71.88%] [G loss: 1.041801]\n",
      "epoch:11 step:11031 [D loss: 0.556784, acc.: 70.31%] [G loss: 0.929359]\n",
      "epoch:11 step:11032 [D loss: 0.608981, acc.: 68.75%] [G loss: 1.024984]\n",
      "epoch:11 step:11033 [D loss: 0.656951, acc.: 59.38%] [G loss: 0.935738]\n",
      "epoch:11 step:11034 [D loss: 0.782305, acc.: 46.09%] [G loss: 0.994368]\n",
      "epoch:11 step:11035 [D loss: 0.673911, acc.: 58.59%] [G loss: 1.017714]\n",
      "epoch:11 step:11036 [D loss: 0.669992, acc.: 57.03%] [G loss: 0.893267]\n",
      "epoch:11 step:11037 [D loss: 0.592244, acc.: 70.31%] [G loss: 0.906283]\n",
      "epoch:11 step:11038 [D loss: 0.572082, acc.: 71.88%] [G loss: 1.113904]\n",
      "epoch:11 step:11039 [D loss: 0.547639, acc.: 71.88%] [G loss: 1.137379]\n",
      "epoch:11 step:11040 [D loss: 0.551533, acc.: 71.88%] [G loss: 1.096906]\n",
      "epoch:11 step:11041 [D loss: 0.676710, acc.: 54.69%] [G loss: 0.971050]\n",
      "epoch:11 step:11042 [D loss: 0.687154, acc.: 51.56%] [G loss: 0.958990]\n",
      "epoch:11 step:11043 [D loss: 0.706481, acc.: 54.69%] [G loss: 1.005073]\n",
      "epoch:11 step:11044 [D loss: 0.675617, acc.: 62.50%] [G loss: 0.916330]\n",
      "epoch:11 step:11045 [D loss: 0.589074, acc.: 68.75%] [G loss: 1.241442]\n",
      "epoch:11 step:11046 [D loss: 0.730944, acc.: 57.03%] [G loss: 1.018254]\n",
      "epoch:11 step:11047 [D loss: 0.704341, acc.: 57.03%] [G loss: 1.032578]\n",
      "epoch:11 step:11048 [D loss: 0.593912, acc.: 75.00%] [G loss: 0.849801]\n",
      "epoch:11 step:11049 [D loss: 0.707990, acc.: 50.78%] [G loss: 0.953853]\n",
      "epoch:11 step:11050 [D loss: 0.668910, acc.: 56.25%] [G loss: 0.880641]\n",
      "epoch:11 step:11051 [D loss: 0.693088, acc.: 50.78%] [G loss: 1.012133]\n",
      "epoch:11 step:11052 [D loss: 0.535567, acc.: 75.00%] [G loss: 0.937989]\n",
      "epoch:11 step:11053 [D loss: 0.626505, acc.: 63.28%] [G loss: 0.983710]\n",
      "epoch:11 step:11054 [D loss: 0.666802, acc.: 57.03%] [G loss: 0.906047]\n",
      "epoch:11 step:11055 [D loss: 0.595366, acc.: 71.09%] [G loss: 0.992554]\n",
      "epoch:11 step:11056 [D loss: 0.642171, acc.: 61.72%] [G loss: 0.987339]\n",
      "epoch:11 step:11057 [D loss: 0.630037, acc.: 59.38%] [G loss: 1.023059]\n",
      "epoch:11 step:11058 [D loss: 0.612995, acc.: 65.62%] [G loss: 0.939764]\n",
      "epoch:11 step:11059 [D loss: 0.787978, acc.: 41.41%] [G loss: 0.900499]\n",
      "epoch:11 step:11060 [D loss: 0.636647, acc.: 64.06%] [G loss: 0.963210]\n",
      "epoch:11 step:11061 [D loss: 0.602184, acc.: 63.28%] [G loss: 1.026894]\n",
      "epoch:11 step:11062 [D loss: 0.600327, acc.: 64.84%] [G loss: 1.046629]\n",
      "epoch:11 step:11063 [D loss: 0.603204, acc.: 66.41%] [G loss: 1.037664]\n",
      "epoch:11 step:11064 [D loss: 0.668256, acc.: 60.16%] [G loss: 0.962491]\n",
      "epoch:11 step:11065 [D loss: 0.714389, acc.: 55.47%] [G loss: 1.077677]\n",
      "epoch:11 step:11066 [D loss: 0.787389, acc.: 45.31%] [G loss: 0.864581]\n",
      "epoch:11 step:11067 [D loss: 0.689026, acc.: 54.69%] [G loss: 0.895253]\n",
      "epoch:11 step:11068 [D loss: 0.708780, acc.: 55.47%] [G loss: 0.923553]\n",
      "epoch:11 step:11069 [D loss: 0.656045, acc.: 63.28%] [G loss: 1.142022]\n",
      "epoch:11 step:11070 [D loss: 0.715986, acc.: 53.12%] [G loss: 0.939872]\n",
      "epoch:11 step:11071 [D loss: 0.628104, acc.: 60.94%] [G loss: 0.919569]\n",
      "epoch:11 step:11072 [D loss: 0.710427, acc.: 55.47%] [G loss: 0.969971]\n",
      "epoch:11 step:11073 [D loss: 0.723103, acc.: 52.34%] [G loss: 0.967259]\n",
      "epoch:11 step:11074 [D loss: 0.572475, acc.: 75.00%] [G loss: 1.043522]\n",
      "epoch:11 step:11075 [D loss: 0.593674, acc.: 70.31%] [G loss: 1.023821]\n",
      "epoch:11 step:11076 [D loss: 0.574659, acc.: 73.44%] [G loss: 1.006848]\n",
      "epoch:11 step:11077 [D loss: 0.653141, acc.: 58.59%] [G loss: 1.098143]\n",
      "epoch:11 step:11078 [D loss: 0.613168, acc.: 70.31%] [G loss: 1.012855]\n",
      "epoch:11 step:11079 [D loss: 0.721178, acc.: 56.25%] [G loss: 1.083675]\n",
      "epoch:11 step:11080 [D loss: 0.694098, acc.: 53.91%] [G loss: 0.965613]\n",
      "epoch:11 step:11081 [D loss: 0.565034, acc.: 75.00%] [G loss: 0.916559]\n",
      "epoch:11 step:11082 [D loss: 0.393193, acc.: 90.62%] [G loss: 1.282486]\n",
      "epoch:11 step:11083 [D loss: 0.571324, acc.: 72.66%] [G loss: 1.339384]\n",
      "epoch:11 step:11084 [D loss: 0.575118, acc.: 71.09%] [G loss: 1.010950]\n",
      "epoch:11 step:11085 [D loss: 0.761533, acc.: 50.78%] [G loss: 0.928284]\n",
      "epoch:11 step:11086 [D loss: 0.792701, acc.: 48.44%] [G loss: 0.986581]\n",
      "epoch:11 step:11087 [D loss: 0.627998, acc.: 62.50%] [G loss: 1.140297]\n",
      "epoch:11 step:11088 [D loss: 0.600409, acc.: 67.97%] [G loss: 0.950544]\n",
      "epoch:11 step:11089 [D loss: 0.531738, acc.: 80.47%] [G loss: 1.194298]\n",
      "epoch:11 step:11090 [D loss: 0.717868, acc.: 53.12%] [G loss: 0.941962]\n",
      "epoch:11 step:11091 [D loss: 0.729028, acc.: 50.78%] [G loss: 1.037870]\n",
      "epoch:11 step:11092 [D loss: 0.607590, acc.: 68.75%] [G loss: 0.966281]\n",
      "epoch:11 step:11093 [D loss: 0.564533, acc.: 71.88%] [G loss: 1.070460]\n",
      "epoch:11 step:11094 [D loss: 0.648405, acc.: 65.62%] [G loss: 0.934122]\n",
      "epoch:11 step:11095 [D loss: 0.739660, acc.: 51.56%] [G loss: 0.728560]\n",
      "epoch:11 step:11096 [D loss: 0.654990, acc.: 64.06%] [G loss: 0.903462]\n",
      "epoch:11 step:11097 [D loss: 0.549492, acc.: 75.00%] [G loss: 1.118962]\n",
      "epoch:11 step:11098 [D loss: 0.552891, acc.: 71.88%] [G loss: 1.023026]\n",
      "epoch:11 step:11099 [D loss: 0.540963, acc.: 77.34%] [G loss: 1.160504]\n",
      "epoch:11 step:11100 [D loss: 0.501472, acc.: 81.25%] [G loss: 1.088264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11101 [D loss: 0.457078, acc.: 84.38%] [G loss: 1.263536]\n",
      "epoch:11 step:11102 [D loss: 0.568866, acc.: 71.09%] [G loss: 1.187673]\n",
      "epoch:11 step:11103 [D loss: 0.557149, acc.: 76.56%] [G loss: 1.319037]\n",
      "epoch:11 step:11104 [D loss: 0.727169, acc.: 53.12%] [G loss: 0.903296]\n",
      "epoch:11 step:11105 [D loss: 0.611699, acc.: 67.97%] [G loss: 1.021020]\n",
      "epoch:11 step:11106 [D loss: 0.700000, acc.: 53.12%] [G loss: 0.887829]\n",
      "epoch:11 step:11107 [D loss: 0.756065, acc.: 50.00%] [G loss: 0.948607]\n",
      "epoch:11 step:11108 [D loss: 0.830874, acc.: 36.72%] [G loss: 0.810595]\n",
      "epoch:11 step:11109 [D loss: 0.699193, acc.: 59.38%] [G loss: 0.874318]\n",
      "epoch:11 step:11110 [D loss: 0.695104, acc.: 54.69%] [G loss: 0.865927]\n",
      "epoch:11 step:11111 [D loss: 0.615909, acc.: 67.97%] [G loss: 0.911555]\n",
      "epoch:11 step:11112 [D loss: 0.615231, acc.: 60.94%] [G loss: 0.941455]\n",
      "epoch:11 step:11113 [D loss: 0.467065, acc.: 82.81%] [G loss: 0.997344]\n",
      "epoch:11 step:11114 [D loss: 0.786851, acc.: 50.00%] [G loss: 0.931978]\n",
      "epoch:11 step:11115 [D loss: 0.816119, acc.: 42.97%] [G loss: 1.007891]\n",
      "epoch:11 step:11116 [D loss: 0.633953, acc.: 61.72%] [G loss: 1.133530]\n",
      "epoch:11 step:11117 [D loss: 0.580149, acc.: 75.78%] [G loss: 1.309482]\n",
      "epoch:11 step:11118 [D loss: 0.725597, acc.: 54.69%] [G loss: 1.140443]\n",
      "epoch:11 step:11119 [D loss: 0.725912, acc.: 52.34%] [G loss: 0.991427]\n",
      "epoch:11 step:11120 [D loss: 0.722139, acc.: 53.91%] [G loss: 0.896912]\n",
      "epoch:11 step:11121 [D loss: 0.685131, acc.: 53.91%] [G loss: 0.873963]\n",
      "epoch:11 step:11122 [D loss: 0.464487, acc.: 75.78%] [G loss: 1.030898]\n",
      "epoch:11 step:11123 [D loss: 0.491355, acc.: 81.25%] [G loss: 1.113346]\n",
      "epoch:11 step:11124 [D loss: 0.636428, acc.: 61.72%] [G loss: 1.066652]\n",
      "epoch:11 step:11125 [D loss: 0.662906, acc.: 58.59%] [G loss: 1.046547]\n",
      "epoch:11 step:11126 [D loss: 0.603343, acc.: 70.31%] [G loss: 1.071387]\n",
      "epoch:11 step:11127 [D loss: 0.676519, acc.: 52.34%] [G loss: 1.044629]\n",
      "epoch:11 step:11128 [D loss: 0.828556, acc.: 40.62%] [G loss: 0.750645]\n",
      "epoch:11 step:11129 [D loss: 0.696695, acc.: 57.81%] [G loss: 0.937138]\n",
      "epoch:11 step:11130 [D loss: 0.563327, acc.: 73.44%] [G loss: 0.882707]\n",
      "epoch:11 step:11131 [D loss: 0.613986, acc.: 64.84%] [G loss: 0.967260]\n",
      "epoch:11 step:11132 [D loss: 0.616788, acc.: 64.84%] [G loss: 1.046842]\n",
      "epoch:11 step:11133 [D loss: 0.644285, acc.: 64.06%] [G loss: 1.062322]\n",
      "epoch:11 step:11134 [D loss: 0.795212, acc.: 40.62%] [G loss: 0.878756]\n",
      "epoch:11 step:11135 [D loss: 0.589695, acc.: 71.09%] [G loss: 1.124459]\n",
      "epoch:11 step:11136 [D loss: 0.668982, acc.: 61.72%] [G loss: 0.811890]\n",
      "epoch:11 step:11137 [D loss: 0.603632, acc.: 63.28%] [G loss: 1.041984]\n",
      "epoch:11 step:11138 [D loss: 0.518032, acc.: 73.44%] [G loss: 1.003912]\n",
      "epoch:11 step:11139 [D loss: 0.640253, acc.: 60.94%] [G loss: 1.003777]\n",
      "epoch:11 step:11140 [D loss: 0.593361, acc.: 66.41%] [G loss: 1.020938]\n",
      "epoch:11 step:11141 [D loss: 0.699734, acc.: 55.47%] [G loss: 1.131685]\n",
      "epoch:11 step:11142 [D loss: 0.708516, acc.: 50.78%] [G loss: 1.043504]\n",
      "epoch:11 step:11143 [D loss: 0.809427, acc.: 44.53%] [G loss: 0.939774]\n",
      "epoch:11 step:11144 [D loss: 0.781153, acc.: 44.53%] [G loss: 0.824500]\n",
      "epoch:11 step:11145 [D loss: 0.704540, acc.: 55.47%] [G loss: 1.047856]\n",
      "epoch:11 step:11146 [D loss: 0.637489, acc.: 64.84%] [G loss: 1.039320]\n",
      "epoch:11 step:11147 [D loss: 0.621735, acc.: 64.06%] [G loss: 1.134578]\n",
      "epoch:11 step:11148 [D loss: 0.638751, acc.: 67.19%] [G loss: 1.097224]\n",
      "epoch:11 step:11149 [D loss: 0.585659, acc.: 68.75%] [G loss: 1.080973]\n",
      "epoch:11 step:11150 [D loss: 0.692969, acc.: 53.91%] [G loss: 0.933735]\n",
      "epoch:11 step:11151 [D loss: 0.758704, acc.: 46.88%] [G loss: 0.915471]\n",
      "epoch:11 step:11152 [D loss: 0.656383, acc.: 62.50%] [G loss: 0.931560]\n",
      "epoch:11 step:11153 [D loss: 0.639825, acc.: 65.62%] [G loss: 1.084605]\n",
      "epoch:11 step:11154 [D loss: 0.698909, acc.: 56.25%] [G loss: 0.835060]\n",
      "epoch:11 step:11155 [D loss: 0.612917, acc.: 68.75%] [G loss: 1.081290]\n",
      "epoch:11 step:11156 [D loss: 0.559427, acc.: 71.88%] [G loss: 0.978458]\n",
      "epoch:11 step:11157 [D loss: 0.516031, acc.: 78.91%] [G loss: 1.039578]\n",
      "epoch:11 step:11158 [D loss: 0.560848, acc.: 72.66%] [G loss: 0.995521]\n",
      "epoch:11 step:11159 [D loss: 0.489187, acc.: 79.69%] [G loss: 1.203101]\n",
      "epoch:11 step:11160 [D loss: 0.508224, acc.: 82.81%] [G loss: 1.180549]\n",
      "epoch:11 step:11161 [D loss: 0.427420, acc.: 87.50%] [G loss: 1.189475]\n",
      "epoch:11 step:11162 [D loss: 0.611568, acc.: 65.62%] [G loss: 0.979899]\n",
      "epoch:11 step:11163 [D loss: 0.616904, acc.: 64.06%] [G loss: 1.066743]\n",
      "epoch:11 step:11164 [D loss: 0.655826, acc.: 62.50%] [G loss: 1.041749]\n",
      "epoch:11 step:11165 [D loss: 0.785100, acc.: 50.00%] [G loss: 1.070791]\n",
      "epoch:11 step:11166 [D loss: 0.716058, acc.: 50.00%] [G loss: 1.247207]\n",
      "epoch:11 step:11167 [D loss: 0.666132, acc.: 61.72%] [G loss: 1.043958]\n",
      "epoch:11 step:11168 [D loss: 0.687800, acc.: 53.91%] [G loss: 0.981534]\n",
      "epoch:11 step:11169 [D loss: 0.683141, acc.: 59.38%] [G loss: 1.017303]\n",
      "epoch:11 step:11170 [D loss: 0.550138, acc.: 79.69%] [G loss: 0.947512]\n",
      "epoch:11 step:11171 [D loss: 0.722669, acc.: 48.44%] [G loss: 0.819687]\n",
      "epoch:11 step:11172 [D loss: 0.687836, acc.: 59.38%] [G loss: 0.915714]\n",
      "epoch:11 step:11173 [D loss: 0.646101, acc.: 59.38%] [G loss: 1.016024]\n",
      "epoch:11 step:11174 [D loss: 0.682220, acc.: 57.81%] [G loss: 0.875830]\n",
      "epoch:11 step:11175 [D loss: 0.606548, acc.: 65.62%] [G loss: 0.985840]\n",
      "epoch:11 step:11176 [D loss: 0.713631, acc.: 53.12%] [G loss: 0.847875]\n",
      "epoch:11 step:11177 [D loss: 0.695696, acc.: 58.59%] [G loss: 0.766881]\n",
      "epoch:11 step:11178 [D loss: 0.648208, acc.: 58.59%] [G loss: 0.956530]\n",
      "epoch:11 step:11179 [D loss: 0.691848, acc.: 59.38%] [G loss: 0.977842]\n",
      "epoch:11 step:11180 [D loss: 0.608073, acc.: 64.06%] [G loss: 0.996533]\n",
      "epoch:11 step:11181 [D loss: 0.704180, acc.: 50.78%] [G loss: 0.951244]\n",
      "epoch:11 step:11182 [D loss: 0.561450, acc.: 71.88%] [G loss: 0.956917]\n",
      "epoch:11 step:11183 [D loss: 0.683956, acc.: 53.12%] [G loss: 0.806437]\n",
      "epoch:11 step:11184 [D loss: 0.626179, acc.: 67.97%] [G loss: 0.940009]\n",
      "epoch:11 step:11185 [D loss: 0.562812, acc.: 78.91%] [G loss: 1.060143]\n",
      "epoch:11 step:11186 [D loss: 0.576679, acc.: 68.75%] [G loss: 0.945978]\n",
      "epoch:11 step:11187 [D loss: 0.618963, acc.: 68.75%] [G loss: 0.952592]\n",
      "epoch:11 step:11188 [D loss: 0.663873, acc.: 57.03%] [G loss: 0.947891]\n",
      "epoch:11 step:11189 [D loss: 0.619390, acc.: 60.94%] [G loss: 0.990500]\n",
      "epoch:11 step:11190 [D loss: 0.628764, acc.: 67.19%] [G loss: 0.828603]\n",
      "epoch:11 step:11191 [D loss: 0.532155, acc.: 76.56%] [G loss: 0.966459]\n",
      "epoch:11 step:11192 [D loss: 0.473612, acc.: 85.16%] [G loss: 1.266866]\n",
      "epoch:11 step:11193 [D loss: 0.597382, acc.: 66.41%] [G loss: 1.187125]\n",
      "epoch:11 step:11194 [D loss: 0.486137, acc.: 80.47%] [G loss: 1.108970]\n",
      "epoch:11 step:11195 [D loss: 0.575991, acc.: 66.41%] [G loss: 1.311262]\n",
      "epoch:11 step:11196 [D loss: 0.515651, acc.: 75.00%] [G loss: 1.093762]\n",
      "epoch:11 step:11197 [D loss: 0.474600, acc.: 83.59%] [G loss: 1.242625]\n",
      "epoch:11 step:11198 [D loss: 0.830159, acc.: 35.16%] [G loss: 0.893129]\n",
      "epoch:11 step:11199 [D loss: 0.819222, acc.: 42.97%] [G loss: 1.009753]\n",
      "epoch:11 step:11200 [D loss: 0.809821, acc.: 39.06%] [G loss: 0.864240]\n",
      "epoch:11 step:11201 [D loss: 0.653275, acc.: 64.84%] [G loss: 0.883911]\n",
      "epoch:11 step:11202 [D loss: 0.754161, acc.: 47.66%] [G loss: 0.969095]\n",
      "epoch:11 step:11203 [D loss: 0.619052, acc.: 65.62%] [G loss: 0.999588]\n",
      "epoch:11 step:11204 [D loss: 0.549386, acc.: 74.22%] [G loss: 1.228792]\n",
      "epoch:11 step:11205 [D loss: 0.507711, acc.: 80.47%] [G loss: 1.120347]\n",
      "epoch:11 step:11206 [D loss: 0.444905, acc.: 87.50%] [G loss: 1.050763]\n",
      "epoch:11 step:11207 [D loss: 0.460366, acc.: 79.69%] [G loss: 1.290003]\n",
      "epoch:11 step:11208 [D loss: 0.607383, acc.: 67.97%] [G loss: 1.005873]\n",
      "epoch:11 step:11209 [D loss: 0.622437, acc.: 60.16%] [G loss: 1.018979]\n",
      "epoch:11 step:11210 [D loss: 0.579744, acc.: 68.75%] [G loss: 0.949126]\n",
      "epoch:11 step:11211 [D loss: 0.639713, acc.: 62.50%] [G loss: 1.090430]\n",
      "epoch:11 step:11212 [D loss: 0.587795, acc.: 67.19%] [G loss: 1.156639]\n",
      "epoch:11 step:11213 [D loss: 0.686391, acc.: 59.38%] [G loss: 1.066611]\n",
      "epoch:11 step:11214 [D loss: 0.614102, acc.: 66.41%] [G loss: 0.917493]\n",
      "epoch:11 step:11215 [D loss: 0.712067, acc.: 53.12%] [G loss: 1.030417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11216 [D loss: 0.586531, acc.: 68.75%] [G loss: 1.129901]\n",
      "epoch:11 step:11217 [D loss: 0.572394, acc.: 74.22%] [G loss: 1.050608]\n",
      "epoch:11 step:11218 [D loss: 0.478454, acc.: 79.69%] [G loss: 1.248343]\n",
      "epoch:11 step:11219 [D loss: 0.401989, acc.: 85.16%] [G loss: 1.087775]\n",
      "epoch:11 step:11220 [D loss: 0.696933, acc.: 55.47%] [G loss: 1.137364]\n",
      "epoch:11 step:11221 [D loss: 0.743162, acc.: 48.44%] [G loss: 0.937678]\n",
      "epoch:11 step:11222 [D loss: 0.710323, acc.: 53.12%] [G loss: 0.956231]\n",
      "epoch:11 step:11223 [D loss: 0.745038, acc.: 48.44%] [G loss: 0.906226]\n",
      "epoch:11 step:11224 [D loss: 0.640432, acc.: 65.62%] [G loss: 0.881608]\n",
      "epoch:11 step:11225 [D loss: 0.535386, acc.: 75.78%] [G loss: 1.007578]\n",
      "epoch:11 step:11226 [D loss: 0.547443, acc.: 75.78%] [G loss: 1.125762]\n",
      "epoch:11 step:11227 [D loss: 0.725236, acc.: 60.16%] [G loss: 1.119681]\n",
      "epoch:11 step:11228 [D loss: 0.694942, acc.: 55.47%] [G loss: 0.999498]\n",
      "epoch:11 step:11229 [D loss: 0.570823, acc.: 69.53%] [G loss: 0.984584]\n",
      "epoch:11 step:11230 [D loss: 0.581573, acc.: 71.09%] [G loss: 1.115071]\n",
      "epoch:11 step:11231 [D loss: 0.509839, acc.: 76.56%] [G loss: 1.014703]\n",
      "epoch:11 step:11232 [D loss: 0.616206, acc.: 61.72%] [G loss: 0.941142]\n",
      "epoch:11 step:11233 [D loss: 0.549111, acc.: 76.56%] [G loss: 1.114243]\n",
      "epoch:11 step:11234 [D loss: 0.469480, acc.: 78.91%] [G loss: 1.350852]\n",
      "epoch:11 step:11235 [D loss: 0.953819, acc.: 32.81%] [G loss: 0.916079]\n",
      "epoch:11 step:11236 [D loss: 0.691457, acc.: 57.81%] [G loss: 0.981516]\n",
      "epoch:11 step:11237 [D loss: 0.582349, acc.: 70.31%] [G loss: 1.227697]\n",
      "epoch:11 step:11238 [D loss: 0.659925, acc.: 53.91%] [G loss: 1.175339]\n",
      "epoch:11 step:11239 [D loss: 0.655185, acc.: 58.59%] [G loss: 0.968594]\n",
      "epoch:11 step:11240 [D loss: 0.610806, acc.: 70.31%] [G loss: 0.972886]\n",
      "epoch:11 step:11241 [D loss: 0.544165, acc.: 74.22%] [G loss: 1.095460]\n",
      "epoch:11 step:11242 [D loss: 0.677889, acc.: 59.38%] [G loss: 1.008065]\n",
      "epoch:11 step:11243 [D loss: 0.599690, acc.: 67.97%] [G loss: 1.213835]\n",
      "epoch:11 step:11244 [D loss: 0.368045, acc.: 89.84%] [G loss: 1.199076]\n",
      "epoch:12 step:11245 [D loss: 0.750204, acc.: 57.81%] [G loss: 0.985696]\n",
      "epoch:12 step:11246 [D loss: 0.673857, acc.: 60.16%] [G loss: 1.108952]\n",
      "epoch:12 step:11247 [D loss: 0.770385, acc.: 46.88%] [G loss: 1.091252]\n",
      "epoch:12 step:11248 [D loss: 0.693281, acc.: 56.25%] [G loss: 1.045977]\n",
      "epoch:12 step:11249 [D loss: 0.675331, acc.: 59.38%] [G loss: 0.990051]\n",
      "epoch:12 step:11250 [D loss: 0.675054, acc.: 57.03%] [G loss: 1.023975]\n",
      "epoch:12 step:11251 [D loss: 0.652513, acc.: 62.50%] [G loss: 0.912801]\n",
      "epoch:12 step:11252 [D loss: 0.554954, acc.: 74.22%] [G loss: 1.060577]\n",
      "epoch:12 step:11253 [D loss: 0.641971, acc.: 66.41%] [G loss: 1.031525]\n",
      "epoch:12 step:11254 [D loss: 0.656544, acc.: 57.03%] [G loss: 1.035773]\n",
      "epoch:12 step:11255 [D loss: 0.591123, acc.: 71.09%] [G loss: 1.088805]\n",
      "epoch:12 step:11256 [D loss: 0.665780, acc.: 57.81%] [G loss: 0.937579]\n",
      "epoch:12 step:11257 [D loss: 0.725327, acc.: 53.12%] [G loss: 0.965784]\n",
      "epoch:12 step:11258 [D loss: 0.609710, acc.: 64.84%] [G loss: 1.009815]\n",
      "epoch:12 step:11259 [D loss: 0.518066, acc.: 78.12%] [G loss: 1.145580]\n",
      "epoch:12 step:11260 [D loss: 0.629745, acc.: 63.28%] [G loss: 1.086542]\n",
      "epoch:12 step:11261 [D loss: 0.701443, acc.: 51.56%] [G loss: 1.067470]\n",
      "epoch:12 step:11262 [D loss: 0.754714, acc.: 53.91%] [G loss: 0.980257]\n",
      "epoch:12 step:11263 [D loss: 0.662456, acc.: 60.94%] [G loss: 1.043425]\n",
      "epoch:12 step:11264 [D loss: 0.715896, acc.: 50.00%] [G loss: 0.996789]\n",
      "epoch:12 step:11265 [D loss: 0.613026, acc.: 64.06%] [G loss: 0.973165]\n",
      "epoch:12 step:11266 [D loss: 0.644984, acc.: 64.84%] [G loss: 0.911697]\n",
      "epoch:12 step:11267 [D loss: 0.732662, acc.: 53.12%] [G loss: 0.899800]\n",
      "epoch:12 step:11268 [D loss: 0.660818, acc.: 57.81%] [G loss: 0.913005]\n",
      "epoch:12 step:11269 [D loss: 0.615546, acc.: 66.41%] [G loss: 1.114997]\n",
      "epoch:12 step:11270 [D loss: 0.619871, acc.: 67.19%] [G loss: 0.981524]\n",
      "epoch:12 step:11271 [D loss: 0.598165, acc.: 66.41%] [G loss: 1.136350]\n",
      "epoch:12 step:11272 [D loss: 0.627657, acc.: 70.31%] [G loss: 1.059779]\n",
      "epoch:12 step:11273 [D loss: 0.549257, acc.: 77.34%] [G loss: 1.071131]\n",
      "epoch:12 step:11274 [D loss: 0.597799, acc.: 65.62%] [G loss: 1.217418]\n",
      "epoch:12 step:11275 [D loss: 0.627784, acc.: 63.28%] [G loss: 1.078536]\n",
      "epoch:12 step:11276 [D loss: 0.485800, acc.: 81.25%] [G loss: 1.145579]\n",
      "epoch:12 step:11277 [D loss: 0.503376, acc.: 81.25%] [G loss: 1.201698]\n",
      "epoch:12 step:11278 [D loss: 0.538203, acc.: 78.91%] [G loss: 1.142876]\n",
      "epoch:12 step:11279 [D loss: 0.510191, acc.: 78.91%] [G loss: 1.164591]\n",
      "epoch:12 step:11280 [D loss: 0.468383, acc.: 78.12%] [G loss: 1.002400]\n",
      "epoch:12 step:11281 [D loss: 0.792984, acc.: 41.41%] [G loss: 1.082901]\n",
      "epoch:12 step:11282 [D loss: 0.765160, acc.: 50.78%] [G loss: 1.077452]\n",
      "epoch:12 step:11283 [D loss: 0.790641, acc.: 42.19%] [G loss: 0.967339]\n",
      "epoch:12 step:11284 [D loss: 0.615258, acc.: 64.06%] [G loss: 0.994914]\n",
      "epoch:12 step:11285 [D loss: 0.711311, acc.: 53.91%] [G loss: 1.050669]\n",
      "epoch:12 step:11286 [D loss: 0.670022, acc.: 60.94%] [G loss: 1.001053]\n",
      "epoch:12 step:11287 [D loss: 0.606900, acc.: 67.19%] [G loss: 1.087576]\n",
      "epoch:12 step:11288 [D loss: 0.714208, acc.: 50.78%] [G loss: 0.892070]\n",
      "epoch:12 step:11289 [D loss: 0.663720, acc.: 59.38%] [G loss: 0.723819]\n",
      "epoch:12 step:11290 [D loss: 0.751789, acc.: 48.44%] [G loss: 0.961401]\n",
      "epoch:12 step:11291 [D loss: 0.601828, acc.: 64.06%] [G loss: 1.078870]\n",
      "epoch:12 step:11292 [D loss: 0.587651, acc.: 70.31%] [G loss: 1.087427]\n",
      "epoch:12 step:11293 [D loss: 0.490547, acc.: 80.47%] [G loss: 1.091523]\n",
      "epoch:12 step:11294 [D loss: 0.538063, acc.: 77.34%] [G loss: 1.000008]\n",
      "epoch:12 step:11295 [D loss: 0.593377, acc.: 68.75%] [G loss: 0.850230]\n",
      "epoch:12 step:11296 [D loss: 0.668246, acc.: 57.81%] [G loss: 0.925712]\n",
      "epoch:12 step:11297 [D loss: 0.675215, acc.: 59.38%] [G loss: 0.948587]\n",
      "epoch:12 step:11298 [D loss: 0.577739, acc.: 70.31%] [G loss: 1.084400]\n",
      "epoch:12 step:11299 [D loss: 0.690533, acc.: 58.59%] [G loss: 1.049229]\n",
      "epoch:12 step:11300 [D loss: 0.638840, acc.: 63.28%] [G loss: 0.988878]\n",
      "epoch:12 step:11301 [D loss: 0.759069, acc.: 50.78%] [G loss: 1.049718]\n",
      "epoch:12 step:11302 [D loss: 0.705492, acc.: 53.12%] [G loss: 1.071848]\n",
      "epoch:12 step:11303 [D loss: 0.649425, acc.: 60.16%] [G loss: 1.064715]\n",
      "epoch:12 step:11304 [D loss: 0.712392, acc.: 54.69%] [G loss: 1.165409]\n",
      "epoch:12 step:11305 [D loss: 0.690180, acc.: 57.03%] [G loss: 0.896601]\n",
      "epoch:12 step:11306 [D loss: 0.644472, acc.: 67.19%] [G loss: 0.942033]\n",
      "epoch:12 step:11307 [D loss: 0.676214, acc.: 60.94%] [G loss: 0.911500]\n",
      "epoch:12 step:11308 [D loss: 0.621252, acc.: 70.31%] [G loss: 0.795397]\n",
      "epoch:12 step:11309 [D loss: 0.670988, acc.: 59.38%] [G loss: 0.901831]\n",
      "epoch:12 step:11310 [D loss: 0.653910, acc.: 60.16%] [G loss: 0.879191]\n",
      "epoch:12 step:11311 [D loss: 0.600534, acc.: 69.53%] [G loss: 1.025746]\n",
      "epoch:12 step:11312 [D loss: 0.662212, acc.: 59.38%] [G loss: 0.844151]\n",
      "epoch:12 step:11313 [D loss: 0.543952, acc.: 75.00%] [G loss: 0.974817]\n",
      "epoch:12 step:11314 [D loss: 0.612945, acc.: 65.62%] [G loss: 1.148411]\n",
      "epoch:12 step:11315 [D loss: 0.556192, acc.: 75.00%] [G loss: 1.036962]\n",
      "epoch:12 step:11316 [D loss: 0.629583, acc.: 61.72%] [G loss: 1.167100]\n",
      "epoch:12 step:11317 [D loss: 0.731810, acc.: 47.66%] [G loss: 0.873952]\n",
      "epoch:12 step:11318 [D loss: 0.513472, acc.: 80.47%] [G loss: 1.194110]\n",
      "epoch:12 step:11319 [D loss: 0.410868, acc.: 92.19%] [G loss: 1.131845]\n",
      "epoch:12 step:11320 [D loss: 0.550669, acc.: 71.09%] [G loss: 1.018625]\n",
      "epoch:12 step:11321 [D loss: 0.475436, acc.: 80.47%] [G loss: 1.354549]\n",
      "epoch:12 step:11322 [D loss: 0.647486, acc.: 60.94%] [G loss: 1.133052]\n",
      "epoch:12 step:11323 [D loss: 0.782406, acc.: 49.22%] [G loss: 0.864799]\n",
      "epoch:12 step:11324 [D loss: 0.684823, acc.: 60.94%] [G loss: 0.954701]\n",
      "epoch:12 step:11325 [D loss: 0.844878, acc.: 38.28%] [G loss: 0.788444]\n",
      "epoch:12 step:11326 [D loss: 0.711445, acc.: 54.69%] [G loss: 1.047727]\n",
      "epoch:12 step:11327 [D loss: 0.706022, acc.: 49.22%] [G loss: 0.937432]\n",
      "epoch:12 step:11328 [D loss: 0.644535, acc.: 62.50%] [G loss: 1.054655]\n",
      "epoch:12 step:11329 [D loss: 0.637942, acc.: 64.06%] [G loss: 1.007523]\n",
      "epoch:12 step:11330 [D loss: 0.657836, acc.: 64.84%] [G loss: 1.055386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11331 [D loss: 0.667771, acc.: 57.81%] [G loss: 0.913587]\n",
      "epoch:12 step:11332 [D loss: 0.569687, acc.: 75.00%] [G loss: 0.960844]\n",
      "epoch:12 step:11333 [D loss: 0.639537, acc.: 63.28%] [G loss: 1.057004]\n",
      "epoch:12 step:11334 [D loss: 0.497109, acc.: 80.47%] [G loss: 1.151886]\n",
      "epoch:12 step:11335 [D loss: 0.672552, acc.: 62.50%] [G loss: 0.989410]\n",
      "epoch:12 step:11336 [D loss: 0.556462, acc.: 71.88%] [G loss: 0.874679]\n",
      "epoch:12 step:11337 [D loss: 0.565931, acc.: 72.66%] [G loss: 0.941097]\n",
      "epoch:12 step:11338 [D loss: 0.612401, acc.: 64.84%] [G loss: 1.018888]\n",
      "epoch:12 step:11339 [D loss: 0.766284, acc.: 53.12%] [G loss: 0.887104]\n",
      "epoch:12 step:11340 [D loss: 0.641543, acc.: 62.50%] [G loss: 0.945465]\n",
      "epoch:12 step:11341 [D loss: 0.590297, acc.: 74.22%] [G loss: 1.153111]\n",
      "epoch:12 step:11342 [D loss: 0.636146, acc.: 66.41%] [G loss: 0.959527]\n",
      "epoch:12 step:11343 [D loss: 0.694837, acc.: 57.03%] [G loss: 0.981611]\n",
      "epoch:12 step:11344 [D loss: 0.557255, acc.: 74.22%] [G loss: 0.995771]\n",
      "epoch:12 step:11345 [D loss: 0.656725, acc.: 64.84%] [G loss: 1.153703]\n",
      "epoch:12 step:11346 [D loss: 0.636311, acc.: 61.72%] [G loss: 1.047760]\n",
      "epoch:12 step:11347 [D loss: 0.574178, acc.: 71.09%] [G loss: 1.068003]\n",
      "epoch:12 step:11348 [D loss: 0.652140, acc.: 65.62%] [G loss: 1.069821]\n",
      "epoch:12 step:11349 [D loss: 0.681428, acc.: 53.12%] [G loss: 1.111445]\n",
      "epoch:12 step:11350 [D loss: 0.667491, acc.: 59.38%] [G loss: 0.944650]\n",
      "epoch:12 step:11351 [D loss: 0.830257, acc.: 38.28%] [G loss: 0.935271]\n",
      "epoch:12 step:11352 [D loss: 0.562183, acc.: 73.44%] [G loss: 1.072112]\n",
      "epoch:12 step:11353 [D loss: 0.619348, acc.: 68.75%] [G loss: 0.888100]\n",
      "epoch:12 step:11354 [D loss: 0.653995, acc.: 56.25%] [G loss: 1.017062]\n",
      "epoch:12 step:11355 [D loss: 0.651393, acc.: 64.06%] [G loss: 0.892235]\n",
      "epoch:12 step:11356 [D loss: 0.629913, acc.: 64.06%] [G loss: 0.940613]\n",
      "epoch:12 step:11357 [D loss: 0.669615, acc.: 60.16%] [G loss: 0.996169]\n",
      "epoch:12 step:11358 [D loss: 0.761837, acc.: 50.00%] [G loss: 0.934366]\n",
      "epoch:12 step:11359 [D loss: 0.764097, acc.: 43.75%] [G loss: 0.871332]\n",
      "epoch:12 step:11360 [D loss: 0.589472, acc.: 71.88%] [G loss: 1.055779]\n",
      "epoch:12 step:11361 [D loss: 0.613919, acc.: 65.62%] [G loss: 1.074120]\n",
      "epoch:12 step:11362 [D loss: 0.612357, acc.: 64.84%] [G loss: 0.987492]\n",
      "epoch:12 step:11363 [D loss: 0.553717, acc.: 68.75%] [G loss: 0.987091]\n",
      "epoch:12 step:11364 [D loss: 0.717427, acc.: 50.78%] [G loss: 0.961880]\n",
      "epoch:12 step:11365 [D loss: 0.594159, acc.: 69.53%] [G loss: 0.852102]\n",
      "epoch:12 step:11366 [D loss: 0.583327, acc.: 67.19%] [G loss: 1.028756]\n",
      "epoch:12 step:11367 [D loss: 0.668658, acc.: 60.16%] [G loss: 0.884461]\n",
      "epoch:12 step:11368 [D loss: 0.685289, acc.: 57.81%] [G loss: 1.059150]\n",
      "epoch:12 step:11369 [D loss: 0.675505, acc.: 57.81%] [G loss: 0.846173]\n",
      "epoch:12 step:11370 [D loss: 0.662075, acc.: 60.16%] [G loss: 1.049987]\n",
      "epoch:12 step:11371 [D loss: 0.608290, acc.: 67.97%] [G loss: 1.060309]\n",
      "epoch:12 step:11372 [D loss: 0.660866, acc.: 59.38%] [G loss: 1.015171]\n",
      "epoch:12 step:11373 [D loss: 0.676605, acc.: 59.38%] [G loss: 0.996691]\n",
      "epoch:12 step:11374 [D loss: 0.577658, acc.: 71.88%] [G loss: 0.965476]\n",
      "epoch:12 step:11375 [D loss: 0.544695, acc.: 72.66%] [G loss: 1.106762]\n",
      "epoch:12 step:11376 [D loss: 0.549646, acc.: 77.34%] [G loss: 0.914591]\n",
      "epoch:12 step:11377 [D loss: 0.710770, acc.: 56.25%] [G loss: 0.933548]\n",
      "epoch:12 step:11378 [D loss: 0.689333, acc.: 57.03%] [G loss: 0.867895]\n",
      "epoch:12 step:11379 [D loss: 0.648207, acc.: 62.50%] [G loss: 0.943782]\n",
      "epoch:12 step:11380 [D loss: 0.652306, acc.: 60.94%] [G loss: 0.894992]\n",
      "epoch:12 step:11381 [D loss: 0.764000, acc.: 47.66%] [G loss: 0.696903]\n",
      "epoch:12 step:11382 [D loss: 0.709662, acc.: 54.69%] [G loss: 1.003295]\n",
      "epoch:12 step:11383 [D loss: 0.641254, acc.: 60.94%] [G loss: 1.004091]\n",
      "epoch:12 step:11384 [D loss: 0.677263, acc.: 57.03%] [G loss: 1.142898]\n",
      "epoch:12 step:11385 [D loss: 0.625727, acc.: 67.19%] [G loss: 1.019016]\n",
      "epoch:12 step:11386 [D loss: 0.624987, acc.: 59.38%] [G loss: 0.947946]\n",
      "epoch:12 step:11387 [D loss: 0.731693, acc.: 55.47%] [G loss: 0.967231]\n",
      "epoch:12 step:11388 [D loss: 0.642598, acc.: 59.38%] [G loss: 0.969751]\n",
      "epoch:12 step:11389 [D loss: 0.579694, acc.: 70.31%] [G loss: 0.996232]\n",
      "epoch:12 step:11390 [D loss: 0.631847, acc.: 59.38%] [G loss: 1.053166]\n",
      "epoch:12 step:11391 [D loss: 0.653699, acc.: 59.38%] [G loss: 0.994193]\n",
      "epoch:12 step:11392 [D loss: 0.704166, acc.: 56.25%] [G loss: 0.850157]\n",
      "epoch:12 step:11393 [D loss: 0.553427, acc.: 77.34%] [G loss: 0.955828]\n",
      "epoch:12 step:11394 [D loss: 0.630913, acc.: 57.81%] [G loss: 0.815720]\n",
      "epoch:12 step:11395 [D loss: 0.559916, acc.: 69.53%] [G loss: 0.915916]\n",
      "epoch:12 step:11396 [D loss: 0.494390, acc.: 85.16%] [G loss: 1.131156]\n",
      "epoch:12 step:11397 [D loss: 0.732505, acc.: 47.66%] [G loss: 1.106412]\n",
      "epoch:12 step:11398 [D loss: 0.598464, acc.: 66.41%] [G loss: 1.038547]\n",
      "epoch:12 step:11399 [D loss: 0.653819, acc.: 64.06%] [G loss: 0.975465]\n",
      "epoch:12 step:11400 [D loss: 0.591329, acc.: 66.41%] [G loss: 1.166726]\n",
      "epoch:12 step:11401 [D loss: 0.673064, acc.: 64.84%] [G loss: 0.878190]\n",
      "epoch:12 step:11402 [D loss: 0.626979, acc.: 62.50%] [G loss: 0.982874]\n",
      "epoch:12 step:11403 [D loss: 0.614899, acc.: 67.19%] [G loss: 0.953117]\n",
      "epoch:12 step:11404 [D loss: 0.738693, acc.: 50.78%] [G loss: 1.001412]\n",
      "epoch:12 step:11405 [D loss: 0.661871, acc.: 66.41%] [G loss: 0.979415]\n",
      "epoch:12 step:11406 [D loss: 0.641496, acc.: 67.97%] [G loss: 0.865027]\n",
      "epoch:12 step:11407 [D loss: 0.644453, acc.: 64.84%] [G loss: 1.023250]\n",
      "epoch:12 step:11408 [D loss: 0.657782, acc.: 58.59%] [G loss: 0.880591]\n",
      "epoch:12 step:11409 [D loss: 0.597785, acc.: 72.66%] [G loss: 0.948100]\n",
      "epoch:12 step:11410 [D loss: 0.659113, acc.: 64.84%] [G loss: 0.877402]\n",
      "epoch:12 step:11411 [D loss: 0.630697, acc.: 67.19%] [G loss: 0.924177]\n",
      "epoch:12 step:11412 [D loss: 0.600737, acc.: 67.97%] [G loss: 0.796789]\n",
      "epoch:12 step:11413 [D loss: 0.630695, acc.: 62.50%] [G loss: 1.195150]\n",
      "epoch:12 step:11414 [D loss: 0.602828, acc.: 67.19%] [G loss: 1.156678]\n",
      "epoch:12 step:11415 [D loss: 0.645661, acc.: 62.50%] [G loss: 0.880520]\n",
      "epoch:12 step:11416 [D loss: 0.589127, acc.: 65.62%] [G loss: 0.946391]\n",
      "epoch:12 step:11417 [D loss: 0.721829, acc.: 52.34%] [G loss: 1.055605]\n",
      "epoch:12 step:11418 [D loss: 0.654671, acc.: 60.16%] [G loss: 1.006562]\n",
      "epoch:12 step:11419 [D loss: 0.699066, acc.: 49.22%] [G loss: 0.962704]\n",
      "epoch:12 step:11420 [D loss: 0.653843, acc.: 62.50%] [G loss: 1.098258]\n",
      "epoch:12 step:11421 [D loss: 0.634856, acc.: 67.19%] [G loss: 1.063871]\n",
      "epoch:12 step:11422 [D loss: 0.662746, acc.: 62.50%] [G loss: 1.108927]\n",
      "epoch:12 step:11423 [D loss: 0.723200, acc.: 50.78%] [G loss: 0.953141]\n",
      "epoch:12 step:11424 [D loss: 0.713286, acc.: 53.91%] [G loss: 0.900168]\n",
      "epoch:12 step:11425 [D loss: 0.690573, acc.: 51.56%] [G loss: 0.936402]\n",
      "epoch:12 step:11426 [D loss: 0.698107, acc.: 57.03%] [G loss: 0.829817]\n",
      "epoch:12 step:11427 [D loss: 0.696993, acc.: 56.25%] [G loss: 0.999397]\n",
      "epoch:12 step:11428 [D loss: 0.622315, acc.: 66.41%] [G loss: 1.238194]\n",
      "epoch:12 step:11429 [D loss: 0.702239, acc.: 52.34%] [G loss: 0.985904]\n",
      "epoch:12 step:11430 [D loss: 0.760434, acc.: 50.78%] [G loss: 1.016755]\n",
      "epoch:12 step:11431 [D loss: 0.729494, acc.: 50.00%] [G loss: 0.955126]\n",
      "epoch:12 step:11432 [D loss: 0.646286, acc.: 60.94%] [G loss: 0.919275]\n",
      "epoch:12 step:11433 [D loss: 0.713995, acc.: 50.78%] [G loss: 0.961131]\n",
      "epoch:12 step:11434 [D loss: 0.609733, acc.: 64.84%] [G loss: 0.970373]\n",
      "epoch:12 step:11435 [D loss: 0.598484, acc.: 71.09%] [G loss: 0.909946]\n",
      "epoch:12 step:11436 [D loss: 0.622651, acc.: 66.41%] [G loss: 1.019787]\n",
      "epoch:12 step:11437 [D loss: 0.692830, acc.: 55.47%] [G loss: 0.985146]\n",
      "epoch:12 step:11438 [D loss: 0.602984, acc.: 67.19%] [G loss: 0.989205]\n",
      "epoch:12 step:11439 [D loss: 0.757397, acc.: 50.00%] [G loss: 0.942543]\n",
      "epoch:12 step:11440 [D loss: 0.604510, acc.: 65.62%] [G loss: 0.968917]\n",
      "epoch:12 step:11441 [D loss: 0.619712, acc.: 64.06%] [G loss: 0.963272]\n",
      "epoch:12 step:11442 [D loss: 0.637456, acc.: 61.72%] [G loss: 0.871539]\n",
      "epoch:12 step:11443 [D loss: 0.699826, acc.: 58.59%] [G loss: 0.984809]\n",
      "epoch:12 step:11444 [D loss: 0.747066, acc.: 50.00%] [G loss: 0.998710]\n",
      "epoch:12 step:11445 [D loss: 0.541236, acc.: 76.56%] [G loss: 0.967702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11446 [D loss: 0.761963, acc.: 51.56%] [G loss: 0.936871]\n",
      "epoch:12 step:11447 [D loss: 0.691092, acc.: 57.81%] [G loss: 0.945747]\n",
      "epoch:12 step:11448 [D loss: 0.691419, acc.: 57.03%] [G loss: 0.998275]\n",
      "epoch:12 step:11449 [D loss: 0.721627, acc.: 50.00%] [G loss: 0.930263]\n",
      "epoch:12 step:11450 [D loss: 0.617215, acc.: 64.06%] [G loss: 0.945826]\n",
      "epoch:12 step:11451 [D loss: 0.599888, acc.: 68.75%] [G loss: 1.058370]\n",
      "epoch:12 step:11452 [D loss: 0.606355, acc.: 68.75%] [G loss: 1.089298]\n",
      "epoch:12 step:11453 [D loss: 0.556401, acc.: 71.88%] [G loss: 1.074669]\n",
      "epoch:12 step:11454 [D loss: 0.616347, acc.: 71.09%] [G loss: 1.075196]\n",
      "epoch:12 step:11455 [D loss: 0.700362, acc.: 52.34%] [G loss: 0.936337]\n",
      "epoch:12 step:11456 [D loss: 0.703743, acc.: 60.16%] [G loss: 0.981309]\n",
      "epoch:12 step:11457 [D loss: 0.609353, acc.: 71.09%] [G loss: 1.035608]\n",
      "epoch:12 step:11458 [D loss: 0.728015, acc.: 53.91%] [G loss: 0.971864]\n",
      "epoch:12 step:11459 [D loss: 0.646548, acc.: 64.06%] [G loss: 0.929111]\n",
      "epoch:12 step:11460 [D loss: 0.646135, acc.: 61.72%] [G loss: 1.020351]\n",
      "epoch:12 step:11461 [D loss: 0.640791, acc.: 59.38%] [G loss: 1.174505]\n",
      "epoch:12 step:11462 [D loss: 0.762489, acc.: 46.09%] [G loss: 0.909292]\n",
      "epoch:12 step:11463 [D loss: 0.588951, acc.: 71.09%] [G loss: 1.056868]\n",
      "epoch:12 step:11464 [D loss: 0.494349, acc.: 77.34%] [G loss: 1.075431]\n",
      "epoch:12 step:11465 [D loss: 0.396506, acc.: 90.62%] [G loss: 1.249058]\n",
      "epoch:12 step:11466 [D loss: 0.623773, acc.: 58.59%] [G loss: 0.992953]\n",
      "epoch:12 step:11467 [D loss: 0.449451, acc.: 82.81%] [G loss: 1.149275]\n",
      "epoch:12 step:11468 [D loss: 0.804550, acc.: 49.22%] [G loss: 1.156747]\n",
      "epoch:12 step:11469 [D loss: 0.688988, acc.: 56.25%] [G loss: 1.176503]\n",
      "epoch:12 step:11470 [D loss: 0.715904, acc.: 53.12%] [G loss: 0.828296]\n",
      "epoch:12 step:11471 [D loss: 0.694799, acc.: 50.00%] [G loss: 0.964052]\n",
      "epoch:12 step:11472 [D loss: 0.744238, acc.: 46.88%] [G loss: 0.858851]\n",
      "epoch:12 step:11473 [D loss: 0.573161, acc.: 70.31%] [G loss: 0.999506]\n",
      "epoch:12 step:11474 [D loss: 0.451515, acc.: 79.69%] [G loss: 0.998004]\n",
      "epoch:12 step:11475 [D loss: 0.401594, acc.: 91.41%] [G loss: 1.224545]\n",
      "epoch:12 step:11476 [D loss: 0.460382, acc.: 82.81%] [G loss: 1.041115]\n",
      "epoch:12 step:11477 [D loss: 0.757066, acc.: 47.66%] [G loss: 1.156849]\n",
      "epoch:12 step:11478 [D loss: 0.747693, acc.: 47.66%] [G loss: 1.059173]\n",
      "epoch:12 step:11479 [D loss: 0.630608, acc.: 64.84%] [G loss: 1.106068]\n",
      "epoch:12 step:11480 [D loss: 0.624150, acc.: 64.84%] [G loss: 0.992486]\n",
      "epoch:12 step:11481 [D loss: 0.635649, acc.: 64.06%] [G loss: 0.938320]\n",
      "epoch:12 step:11482 [D loss: 0.637960, acc.: 65.62%] [G loss: 1.144552]\n",
      "epoch:12 step:11483 [D loss: 0.694309, acc.: 53.91%] [G loss: 1.135124]\n",
      "epoch:12 step:11484 [D loss: 0.637477, acc.: 62.50%] [G loss: 1.029169]\n",
      "epoch:12 step:11485 [D loss: 0.640967, acc.: 60.94%] [G loss: 0.936766]\n",
      "epoch:12 step:11486 [D loss: 0.708593, acc.: 56.25%] [G loss: 0.980000]\n",
      "epoch:12 step:11487 [D loss: 0.654267, acc.: 64.06%] [G loss: 0.985249]\n",
      "epoch:12 step:11488 [D loss: 0.589555, acc.: 67.97%] [G loss: 0.925405]\n",
      "epoch:12 step:11489 [D loss: 0.576544, acc.: 73.44%] [G loss: 1.146711]\n",
      "epoch:12 step:11490 [D loss: 0.578729, acc.: 71.09%] [G loss: 0.990921]\n",
      "epoch:12 step:11491 [D loss: 0.630371, acc.: 64.84%] [G loss: 0.954621]\n",
      "epoch:12 step:11492 [D loss: 0.595797, acc.: 68.75%] [G loss: 0.970202]\n",
      "epoch:12 step:11493 [D loss: 0.659316, acc.: 55.47%] [G loss: 0.978931]\n",
      "epoch:12 step:11494 [D loss: 0.661426, acc.: 58.59%] [G loss: 0.906492]\n",
      "epoch:12 step:11495 [D loss: 0.606884, acc.: 65.62%] [G loss: 1.034857]\n",
      "epoch:12 step:11496 [D loss: 0.703957, acc.: 54.69%] [G loss: 0.950834]\n",
      "epoch:12 step:11497 [D loss: 0.632357, acc.: 63.28%] [G loss: 0.982027]\n",
      "epoch:12 step:11498 [D loss: 0.675610, acc.: 58.59%] [G loss: 0.882897]\n",
      "epoch:12 step:11499 [D loss: 0.618257, acc.: 66.41%] [G loss: 0.925155]\n",
      "epoch:12 step:11500 [D loss: 0.767793, acc.: 49.22%] [G loss: 0.860859]\n",
      "epoch:12 step:11501 [D loss: 0.692938, acc.: 57.03%] [G loss: 0.805531]\n",
      "epoch:12 step:11502 [D loss: 0.694484, acc.: 57.81%] [G loss: 0.850884]\n",
      "epoch:12 step:11503 [D loss: 0.617864, acc.: 67.19%] [G loss: 0.938292]\n",
      "epoch:12 step:11504 [D loss: 0.651187, acc.: 59.38%] [G loss: 0.957907]\n",
      "epoch:12 step:11505 [D loss: 0.575641, acc.: 69.53%] [G loss: 1.081477]\n",
      "epoch:12 step:11506 [D loss: 0.659717, acc.: 59.38%] [G loss: 0.976132]\n",
      "epoch:12 step:11507 [D loss: 0.792673, acc.: 44.53%] [G loss: 0.828920]\n",
      "epoch:12 step:11508 [D loss: 0.587559, acc.: 71.88%] [G loss: 1.110468]\n",
      "epoch:12 step:11509 [D loss: 0.641087, acc.: 57.81%] [G loss: 0.965348]\n",
      "epoch:12 step:11510 [D loss: 0.728776, acc.: 50.00%] [G loss: 0.946712]\n",
      "epoch:12 step:11511 [D loss: 0.600424, acc.: 70.31%] [G loss: 0.831235]\n",
      "epoch:12 step:11512 [D loss: 0.667465, acc.: 59.38%] [G loss: 0.971376]\n",
      "epoch:12 step:11513 [D loss: 0.644733, acc.: 60.94%] [G loss: 0.942895]\n",
      "epoch:12 step:11514 [D loss: 0.693058, acc.: 61.72%] [G loss: 0.994319]\n",
      "epoch:12 step:11515 [D loss: 0.640184, acc.: 64.06%] [G loss: 0.915278]\n",
      "epoch:12 step:11516 [D loss: 0.544210, acc.: 77.34%] [G loss: 0.929453]\n",
      "epoch:12 step:11517 [D loss: 0.612117, acc.: 64.84%] [G loss: 0.928051]\n",
      "epoch:12 step:11518 [D loss: 0.656900, acc.: 60.16%] [G loss: 0.987569]\n",
      "epoch:12 step:11519 [D loss: 0.667712, acc.: 55.47%] [G loss: 0.975079]\n",
      "epoch:12 step:11520 [D loss: 0.729000, acc.: 54.69%] [G loss: 0.936178]\n",
      "epoch:12 step:11521 [D loss: 0.694488, acc.: 55.47%] [G loss: 1.060290]\n",
      "epoch:12 step:11522 [D loss: 0.592668, acc.: 64.84%] [G loss: 1.034357]\n",
      "epoch:12 step:11523 [D loss: 0.549753, acc.: 73.44%] [G loss: 1.027128]\n",
      "epoch:12 step:11524 [D loss: 0.500520, acc.: 81.25%] [G loss: 1.089131]\n",
      "epoch:12 step:11525 [D loss: 0.642584, acc.: 59.38%] [G loss: 1.204368]\n",
      "epoch:12 step:11526 [D loss: 0.721332, acc.: 51.56%] [G loss: 1.066865]\n",
      "epoch:12 step:11527 [D loss: 0.613198, acc.: 68.75%] [G loss: 1.133273]\n",
      "epoch:12 step:11528 [D loss: 0.681484, acc.: 60.16%] [G loss: 0.867212]\n",
      "epoch:12 step:11529 [D loss: 0.503134, acc.: 82.03%] [G loss: 1.195721]\n",
      "epoch:12 step:11530 [D loss: 0.570440, acc.: 72.66%] [G loss: 1.002567]\n",
      "epoch:12 step:11531 [D loss: 0.623476, acc.: 65.62%] [G loss: 1.144472]\n",
      "epoch:12 step:11532 [D loss: 0.719274, acc.: 51.56%] [G loss: 0.880277]\n",
      "epoch:12 step:11533 [D loss: 0.509230, acc.: 74.22%] [G loss: 0.981013]\n",
      "epoch:12 step:11534 [D loss: 0.600687, acc.: 65.62%] [G loss: 1.048708]\n",
      "epoch:12 step:11535 [D loss: 0.561376, acc.: 74.22%] [G loss: 0.997652]\n",
      "epoch:12 step:11536 [D loss: 0.684000, acc.: 57.81%] [G loss: 0.874106]\n",
      "epoch:12 step:11537 [D loss: 0.549082, acc.: 75.78%] [G loss: 0.979683]\n",
      "epoch:12 step:11538 [D loss: 0.667179, acc.: 58.59%] [G loss: 1.108011]\n",
      "epoch:12 step:11539 [D loss: 0.776186, acc.: 47.66%] [G loss: 0.912989]\n",
      "epoch:12 step:11540 [D loss: 0.682821, acc.: 61.72%] [G loss: 0.930189]\n",
      "epoch:12 step:11541 [D loss: 0.631530, acc.: 64.84%] [G loss: 1.063753]\n",
      "epoch:12 step:11542 [D loss: 0.546966, acc.: 72.66%] [G loss: 1.094722]\n",
      "epoch:12 step:11543 [D loss: 0.627200, acc.: 62.50%] [G loss: 1.013313]\n",
      "epoch:12 step:11544 [D loss: 0.566105, acc.: 74.22%] [G loss: 1.147237]\n",
      "epoch:12 step:11545 [D loss: 0.737566, acc.: 51.56%] [G loss: 0.953226]\n",
      "epoch:12 step:11546 [D loss: 0.657596, acc.: 63.28%] [G loss: 0.853003]\n",
      "epoch:12 step:11547 [D loss: 0.608469, acc.: 66.41%] [G loss: 1.212468]\n",
      "epoch:12 step:11548 [D loss: 0.683111, acc.: 56.25%] [G loss: 0.918968]\n",
      "epoch:12 step:11549 [D loss: 0.663379, acc.: 57.81%] [G loss: 0.969818]\n",
      "epoch:12 step:11550 [D loss: 0.740610, acc.: 50.78%] [G loss: 0.858360]\n",
      "epoch:12 step:11551 [D loss: 0.706978, acc.: 53.12%] [G loss: 0.874914]\n",
      "epoch:12 step:11552 [D loss: 0.610700, acc.: 70.31%] [G loss: 0.857024]\n",
      "epoch:12 step:11553 [D loss: 0.611090, acc.: 62.50%] [G loss: 1.049454]\n",
      "epoch:12 step:11554 [D loss: 0.615650, acc.: 64.06%] [G loss: 0.940605]\n",
      "epoch:12 step:11555 [D loss: 0.582138, acc.: 71.09%] [G loss: 1.036305]\n",
      "epoch:12 step:11556 [D loss: 0.629993, acc.: 68.75%] [G loss: 0.912132]\n",
      "epoch:12 step:11557 [D loss: 0.531336, acc.: 76.56%] [G loss: 1.067922]\n",
      "epoch:12 step:11558 [D loss: 0.528952, acc.: 77.34%] [G loss: 1.095009]\n",
      "epoch:12 step:11559 [D loss: 0.570016, acc.: 69.53%] [G loss: 0.998419]\n",
      "epoch:12 step:11560 [D loss: 0.764140, acc.: 49.22%] [G loss: 1.033908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11561 [D loss: 0.749924, acc.: 48.44%] [G loss: 0.938448]\n",
      "epoch:12 step:11562 [D loss: 0.644715, acc.: 60.16%] [G loss: 1.000364]\n",
      "epoch:12 step:11563 [D loss: 0.614342, acc.: 67.19%] [G loss: 1.123884]\n",
      "epoch:12 step:11564 [D loss: 0.689518, acc.: 58.59%] [G loss: 1.073855]\n",
      "epoch:12 step:11565 [D loss: 0.490775, acc.: 79.69%] [G loss: 1.230611]\n",
      "epoch:12 step:11566 [D loss: 0.664306, acc.: 60.16%] [G loss: 0.941708]\n",
      "epoch:12 step:11567 [D loss: 0.788820, acc.: 45.31%] [G loss: 1.017364]\n",
      "epoch:12 step:11568 [D loss: 0.685303, acc.: 55.47%] [G loss: 1.016121]\n",
      "epoch:12 step:11569 [D loss: 0.627164, acc.: 69.53%] [G loss: 1.216166]\n",
      "epoch:12 step:11570 [D loss: 0.687801, acc.: 59.38%] [G loss: 0.911014]\n",
      "epoch:12 step:11571 [D loss: 0.591997, acc.: 68.75%] [G loss: 0.945293]\n",
      "epoch:12 step:11572 [D loss: 0.537499, acc.: 75.00%] [G loss: 1.098104]\n",
      "epoch:12 step:11573 [D loss: 0.634443, acc.: 67.19%] [G loss: 1.058425]\n",
      "epoch:12 step:11574 [D loss: 0.715521, acc.: 48.44%] [G loss: 1.039144]\n",
      "epoch:12 step:11575 [D loss: 0.669091, acc.: 58.59%] [G loss: 1.051998]\n",
      "epoch:12 step:11576 [D loss: 0.651329, acc.: 58.59%] [G loss: 0.899518]\n",
      "epoch:12 step:11577 [D loss: 0.659752, acc.: 61.72%] [G loss: 0.970624]\n",
      "epoch:12 step:11578 [D loss: 0.658193, acc.: 55.47%] [G loss: 0.993934]\n",
      "epoch:12 step:11579 [D loss: 0.677645, acc.: 60.16%] [G loss: 0.936008]\n",
      "epoch:12 step:11580 [D loss: 0.596214, acc.: 66.41%] [G loss: 1.072675]\n",
      "epoch:12 step:11581 [D loss: 0.592785, acc.: 69.53%] [G loss: 1.022596]\n",
      "epoch:12 step:11582 [D loss: 0.691352, acc.: 53.91%] [G loss: 0.867091]\n",
      "epoch:12 step:11583 [D loss: 0.640482, acc.: 66.41%] [G loss: 1.070644]\n",
      "epoch:12 step:11584 [D loss: 0.719851, acc.: 48.44%] [G loss: 0.935116]\n",
      "epoch:12 step:11585 [D loss: 0.674969, acc.: 57.03%] [G loss: 0.945735]\n",
      "epoch:12 step:11586 [D loss: 0.643053, acc.: 63.28%] [G loss: 0.894499]\n",
      "epoch:12 step:11587 [D loss: 0.515820, acc.: 75.78%] [G loss: 1.113197]\n",
      "epoch:12 step:11588 [D loss: 0.548569, acc.: 75.00%] [G loss: 1.159125]\n",
      "epoch:12 step:11589 [D loss: 0.442663, acc.: 85.16%] [G loss: 1.181715]\n",
      "epoch:12 step:11590 [D loss: 0.446758, acc.: 86.72%] [G loss: 1.112393]\n",
      "epoch:12 step:11591 [D loss: 0.464416, acc.: 87.50%] [G loss: 1.104245]\n",
      "epoch:12 step:11592 [D loss: 0.691615, acc.: 61.72%] [G loss: 1.077500]\n",
      "epoch:12 step:11593 [D loss: 0.860864, acc.: 35.94%] [G loss: 0.907049]\n",
      "epoch:12 step:11594 [D loss: 0.658261, acc.: 58.59%] [G loss: 0.895129]\n",
      "epoch:12 step:11595 [D loss: 0.598749, acc.: 71.88%] [G loss: 0.961422]\n",
      "epoch:12 step:11596 [D loss: 0.700271, acc.: 52.34%] [G loss: 0.929359]\n",
      "epoch:12 step:11597 [D loss: 0.710631, acc.: 58.59%] [G loss: 0.976856]\n",
      "epoch:12 step:11598 [D loss: 0.652166, acc.: 57.81%] [G loss: 0.921131]\n",
      "epoch:12 step:11599 [D loss: 0.652083, acc.: 60.16%] [G loss: 1.061591]\n",
      "epoch:12 step:11600 [D loss: 0.699071, acc.: 53.12%] [G loss: 0.929491]\n",
      "epoch:12 step:11601 [D loss: 0.584862, acc.: 71.88%] [G loss: 1.030192]\n",
      "epoch:12 step:11602 [D loss: 0.497783, acc.: 78.91%] [G loss: 1.026350]\n",
      "epoch:12 step:11603 [D loss: 0.580563, acc.: 70.31%] [G loss: 1.176174]\n",
      "epoch:12 step:11604 [D loss: 0.598859, acc.: 67.19%] [G loss: 1.017512]\n",
      "epoch:12 step:11605 [D loss: 0.635887, acc.: 62.50%] [G loss: 1.019222]\n",
      "epoch:12 step:11606 [D loss: 0.774487, acc.: 50.78%] [G loss: 0.890414]\n",
      "epoch:12 step:11607 [D loss: 0.641366, acc.: 61.72%] [G loss: 0.857290]\n",
      "epoch:12 step:11608 [D loss: 0.692874, acc.: 57.81%] [G loss: 1.013303]\n",
      "epoch:12 step:11609 [D loss: 0.660875, acc.: 58.59%] [G loss: 0.917472]\n",
      "epoch:12 step:11610 [D loss: 0.685661, acc.: 55.47%] [G loss: 1.007742]\n",
      "epoch:12 step:11611 [D loss: 0.632074, acc.: 64.06%] [G loss: 1.093324]\n",
      "epoch:12 step:11612 [D loss: 0.606828, acc.: 68.75%] [G loss: 1.160712]\n",
      "epoch:12 step:11613 [D loss: 0.676615, acc.: 57.81%] [G loss: 1.019789]\n",
      "epoch:12 step:11614 [D loss: 0.569382, acc.: 75.00%] [G loss: 1.093783]\n",
      "epoch:12 step:11615 [D loss: 0.695432, acc.: 57.81%] [G loss: 0.929831]\n",
      "epoch:12 step:11616 [D loss: 0.699118, acc.: 54.69%] [G loss: 0.963346]\n",
      "epoch:12 step:11617 [D loss: 0.683082, acc.: 56.25%] [G loss: 1.091607]\n",
      "epoch:12 step:11618 [D loss: 0.572213, acc.: 72.66%] [G loss: 0.961266]\n",
      "epoch:12 step:11619 [D loss: 0.725881, acc.: 57.81%] [G loss: 0.901617]\n",
      "epoch:12 step:11620 [D loss: 0.765040, acc.: 39.84%] [G loss: 0.874685]\n",
      "epoch:12 step:11621 [D loss: 0.701550, acc.: 54.69%] [G loss: 0.860741]\n",
      "epoch:12 step:11622 [D loss: 0.682280, acc.: 55.47%] [G loss: 0.858429]\n",
      "epoch:12 step:11623 [D loss: 0.597123, acc.: 72.66%] [G loss: 0.902179]\n",
      "epoch:12 step:11624 [D loss: 0.642799, acc.: 64.06%] [G loss: 0.937988]\n",
      "epoch:12 step:11625 [D loss: 0.523275, acc.: 79.69%] [G loss: 1.080859]\n",
      "epoch:12 step:11626 [D loss: 0.631874, acc.: 64.06%] [G loss: 1.078469]\n",
      "epoch:12 step:11627 [D loss: 0.623674, acc.: 66.41%] [G loss: 0.925191]\n",
      "epoch:12 step:11628 [D loss: 0.696190, acc.: 60.16%] [G loss: 0.813331]\n",
      "epoch:12 step:11629 [D loss: 0.635116, acc.: 62.50%] [G loss: 0.940943]\n",
      "epoch:12 step:11630 [D loss: 0.621616, acc.: 67.97%] [G loss: 1.162492]\n",
      "epoch:12 step:11631 [D loss: 0.629377, acc.: 72.66%] [G loss: 0.909168]\n",
      "epoch:12 step:11632 [D loss: 0.558503, acc.: 70.31%] [G loss: 1.052266]\n",
      "epoch:12 step:11633 [D loss: 0.666139, acc.: 60.16%] [G loss: 0.995625]\n",
      "epoch:12 step:11634 [D loss: 0.618877, acc.: 63.28%] [G loss: 1.038954]\n",
      "epoch:12 step:11635 [D loss: 0.674563, acc.: 56.25%] [G loss: 0.948895]\n",
      "epoch:12 step:11636 [D loss: 0.636151, acc.: 65.62%] [G loss: 1.083156]\n",
      "epoch:12 step:11637 [D loss: 0.746831, acc.: 49.22%] [G loss: 0.895223]\n",
      "epoch:12 step:11638 [D loss: 0.615401, acc.: 67.19%] [G loss: 1.140366]\n",
      "epoch:12 step:11639 [D loss: 0.657936, acc.: 63.28%] [G loss: 0.872437]\n",
      "epoch:12 step:11640 [D loss: 0.494390, acc.: 78.12%] [G loss: 1.152440]\n",
      "epoch:12 step:11641 [D loss: 0.408706, acc.: 86.72%] [G loss: 1.126191]\n",
      "epoch:12 step:11642 [D loss: 0.461949, acc.: 79.69%] [G loss: 1.154702]\n",
      "epoch:12 step:11643 [D loss: 0.471095, acc.: 84.38%] [G loss: 1.087648]\n",
      "epoch:12 step:11644 [D loss: 0.593964, acc.: 70.31%] [G loss: 1.090355]\n",
      "epoch:12 step:11645 [D loss: 0.529234, acc.: 76.56%] [G loss: 1.463630]\n",
      "epoch:12 step:11646 [D loss: 0.632911, acc.: 60.94%] [G loss: 0.964203]\n",
      "epoch:12 step:11647 [D loss: 0.509567, acc.: 73.44%] [G loss: 1.209592]\n",
      "epoch:12 step:11648 [D loss: 0.509922, acc.: 76.56%] [G loss: 1.038906]\n",
      "epoch:12 step:11649 [D loss: 0.484476, acc.: 79.69%] [G loss: 1.208589]\n",
      "epoch:12 step:11650 [D loss: 0.476228, acc.: 82.03%] [G loss: 1.607293]\n",
      "epoch:12 step:11651 [D loss: 0.706170, acc.: 55.47%] [G loss: 1.103999]\n",
      "epoch:12 step:11652 [D loss: 0.680288, acc.: 60.94%] [G loss: 0.867121]\n",
      "epoch:12 step:11653 [D loss: 0.558290, acc.: 69.53%] [G loss: 1.112478]\n",
      "epoch:12 step:11654 [D loss: 0.753339, acc.: 50.78%] [G loss: 0.902578]\n",
      "epoch:12 step:11655 [D loss: 0.695703, acc.: 60.16%] [G loss: 1.147569]\n",
      "epoch:12 step:11656 [D loss: 0.882529, acc.: 32.03%] [G loss: 0.901795]\n",
      "epoch:12 step:11657 [D loss: 0.758673, acc.: 49.22%] [G loss: 1.084243]\n",
      "epoch:12 step:11658 [D loss: 0.782641, acc.: 43.75%] [G loss: 0.858115]\n",
      "epoch:12 step:11659 [D loss: 0.860022, acc.: 42.97%] [G loss: 0.842301]\n",
      "epoch:12 step:11660 [D loss: 0.798386, acc.: 45.31%] [G loss: 0.997565]\n",
      "epoch:12 step:11661 [D loss: 0.794776, acc.: 45.31%] [G loss: 0.806778]\n",
      "epoch:12 step:11662 [D loss: 0.729864, acc.: 50.00%] [G loss: 0.902409]\n",
      "epoch:12 step:11663 [D loss: 0.665949, acc.: 59.38%] [G loss: 0.962945]\n",
      "epoch:12 step:11664 [D loss: 0.694752, acc.: 53.91%] [G loss: 1.016554]\n",
      "epoch:12 step:11665 [D loss: 0.663669, acc.: 64.06%] [G loss: 0.908548]\n",
      "epoch:12 step:11666 [D loss: 0.675845, acc.: 53.91%] [G loss: 1.016032]\n",
      "epoch:12 step:11667 [D loss: 0.778317, acc.: 48.44%] [G loss: 0.924785]\n",
      "epoch:12 step:11668 [D loss: 0.730627, acc.: 51.56%] [G loss: 1.027193]\n",
      "epoch:12 step:11669 [D loss: 0.663055, acc.: 55.47%] [G loss: 1.111085]\n",
      "epoch:12 step:11670 [D loss: 0.620383, acc.: 68.75%] [G loss: 1.009261]\n",
      "epoch:12 step:11671 [D loss: 0.654219, acc.: 64.84%] [G loss: 0.894329]\n",
      "epoch:12 step:11672 [D loss: 0.646106, acc.: 63.28%] [G loss: 0.897781]\n",
      "epoch:12 step:11673 [D loss: 0.674011, acc.: 59.38%] [G loss: 1.012133]\n",
      "epoch:12 step:11674 [D loss: 0.577538, acc.: 70.31%] [G loss: 1.025899]\n",
      "epoch:12 step:11675 [D loss: 0.584346, acc.: 70.31%] [G loss: 1.182022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11676 [D loss: 0.691800, acc.: 53.91%] [G loss: 1.022758]\n",
      "epoch:12 step:11677 [D loss: 0.534868, acc.: 78.91%] [G loss: 1.060125]\n",
      "epoch:12 step:11678 [D loss: 0.520045, acc.: 76.56%] [G loss: 1.131002]\n",
      "epoch:12 step:11679 [D loss: 0.501807, acc.: 81.25%] [G loss: 1.054378]\n",
      "epoch:12 step:11680 [D loss: 0.430175, acc.: 87.50%] [G loss: 1.323477]\n",
      "epoch:12 step:11681 [D loss: 0.694939, acc.: 58.59%] [G loss: 1.083777]\n",
      "epoch:12 step:11682 [D loss: 0.773954, acc.: 41.41%] [G loss: 1.016753]\n",
      "epoch:12 step:11683 [D loss: 0.679058, acc.: 56.25%] [G loss: 1.102021]\n",
      "epoch:12 step:11684 [D loss: 0.621354, acc.: 67.19%] [G loss: 1.175876]\n",
      "epoch:12 step:11685 [D loss: 0.595705, acc.: 67.97%] [G loss: 0.921127]\n",
      "epoch:12 step:11686 [D loss: 0.590156, acc.: 71.09%] [G loss: 1.092862]\n",
      "epoch:12 step:11687 [D loss: 0.544129, acc.: 76.56%] [G loss: 1.086946]\n",
      "epoch:12 step:11688 [D loss: 0.686137, acc.: 59.38%] [G loss: 1.140056]\n",
      "epoch:12 step:11689 [D loss: 0.688442, acc.: 59.38%] [G loss: 0.966348]\n",
      "epoch:12 step:11690 [D loss: 0.614177, acc.: 62.50%] [G loss: 1.110341]\n",
      "epoch:12 step:11691 [D loss: 0.599828, acc.: 71.09%] [G loss: 1.009728]\n",
      "epoch:12 step:11692 [D loss: 0.562983, acc.: 70.31%] [G loss: 1.092193]\n",
      "epoch:12 step:11693 [D loss: 0.498863, acc.: 77.34%] [G loss: 1.189345]\n",
      "epoch:12 step:11694 [D loss: 0.505744, acc.: 81.25%] [G loss: 1.181035]\n",
      "epoch:12 step:11695 [D loss: 0.560424, acc.: 72.66%] [G loss: 1.181282]\n",
      "epoch:12 step:11696 [D loss: 0.529708, acc.: 71.88%] [G loss: 1.229434]\n",
      "epoch:12 step:11697 [D loss: 0.494964, acc.: 78.91%] [G loss: 1.388339]\n",
      "epoch:12 step:11698 [D loss: 0.630298, acc.: 61.72%] [G loss: 1.069607]\n",
      "epoch:12 step:11699 [D loss: 0.679052, acc.: 58.59%] [G loss: 0.976168]\n",
      "epoch:12 step:11700 [D loss: 0.551513, acc.: 71.09%] [G loss: 1.301980]\n",
      "epoch:12 step:11701 [D loss: 0.571928, acc.: 68.75%] [G loss: 1.076611]\n",
      "epoch:12 step:11702 [D loss: 0.815683, acc.: 46.09%] [G loss: 0.983732]\n",
      "epoch:12 step:11703 [D loss: 0.827056, acc.: 41.41%] [G loss: 0.819906]\n",
      "epoch:12 step:11704 [D loss: 0.880605, acc.: 39.84%] [G loss: 0.842528]\n",
      "epoch:12 step:11705 [D loss: 0.917473, acc.: 32.03%] [G loss: 0.863526]\n",
      "epoch:12 step:11706 [D loss: 0.891370, acc.: 35.94%] [G loss: 1.015971]\n",
      "epoch:12 step:11707 [D loss: 0.836673, acc.: 40.62%] [G loss: 0.952177]\n",
      "epoch:12 step:11708 [D loss: 0.753952, acc.: 49.22%] [G loss: 0.799723]\n",
      "epoch:12 step:11709 [D loss: 0.660792, acc.: 57.03%] [G loss: 1.086861]\n",
      "epoch:12 step:11710 [D loss: 0.625082, acc.: 66.41%] [G loss: 0.977845]\n",
      "epoch:12 step:11711 [D loss: 0.775918, acc.: 50.00%] [G loss: 0.746732]\n",
      "epoch:12 step:11712 [D loss: 0.785749, acc.: 50.78%] [G loss: 1.054921]\n",
      "epoch:12 step:11713 [D loss: 0.528834, acc.: 82.03%] [G loss: 1.085156]\n",
      "epoch:12 step:11714 [D loss: 0.618228, acc.: 67.19%] [G loss: 1.111708]\n",
      "epoch:12 step:11715 [D loss: 0.467232, acc.: 85.94%] [G loss: 1.148092]\n",
      "epoch:12 step:11716 [D loss: 0.614801, acc.: 66.41%] [G loss: 1.119063]\n",
      "epoch:12 step:11717 [D loss: 0.818985, acc.: 50.78%] [G loss: 1.174565]\n",
      "epoch:12 step:11718 [D loss: 0.602226, acc.: 67.97%] [G loss: 1.113006]\n",
      "epoch:12 step:11719 [D loss: 0.512699, acc.: 75.00%] [G loss: 1.385018]\n",
      "epoch:12 step:11720 [D loss: 0.712974, acc.: 55.47%] [G loss: 1.235826]\n",
      "epoch:12 step:11721 [D loss: 0.730101, acc.: 56.25%] [G loss: 1.214113]\n",
      "epoch:12 step:11722 [D loss: 0.624525, acc.: 68.75%] [G loss: 0.983018]\n",
      "epoch:12 step:11723 [D loss: 0.547877, acc.: 72.66%] [G loss: 1.012390]\n",
      "epoch:12 step:11724 [D loss: 0.621921, acc.: 65.62%] [G loss: 1.145078]\n",
      "epoch:12 step:11725 [D loss: 0.591749, acc.: 69.53%] [G loss: 0.895921]\n",
      "epoch:12 step:11726 [D loss: 0.629236, acc.: 62.50%] [G loss: 0.984777]\n",
      "epoch:12 step:11727 [D loss: 0.549871, acc.: 80.47%] [G loss: 0.997442]\n",
      "epoch:12 step:11728 [D loss: 0.456084, acc.: 79.69%] [G loss: 1.088602]\n",
      "epoch:12 step:11729 [D loss: 0.562377, acc.: 72.66%] [G loss: 1.329309]\n",
      "epoch:12 step:11730 [D loss: 0.501357, acc.: 83.59%] [G loss: 1.148268]\n",
      "epoch:12 step:11731 [D loss: 0.525133, acc.: 73.44%] [G loss: 1.094515]\n",
      "epoch:12 step:11732 [D loss: 0.561144, acc.: 71.88%] [G loss: 1.063847]\n",
      "epoch:12 step:11733 [D loss: 0.765439, acc.: 48.44%] [G loss: 1.210733]\n",
      "epoch:12 step:11734 [D loss: 0.648344, acc.: 61.72%] [G loss: 0.966222]\n",
      "epoch:12 step:11735 [D loss: 0.654731, acc.: 61.72%] [G loss: 0.933575]\n",
      "epoch:12 step:11736 [D loss: 0.689029, acc.: 55.47%] [G loss: 0.979145]\n",
      "epoch:12 step:11737 [D loss: 0.717406, acc.: 52.34%] [G loss: 0.948637]\n",
      "epoch:12 step:11738 [D loss: 0.680767, acc.: 50.78%] [G loss: 0.940091]\n",
      "epoch:12 step:11739 [D loss: 0.641025, acc.: 64.84%] [G loss: 0.860151]\n",
      "epoch:12 step:11740 [D loss: 0.573298, acc.: 74.22%] [G loss: 1.010818]\n",
      "epoch:12 step:11741 [D loss: 0.461475, acc.: 85.16%] [G loss: 1.068444]\n",
      "epoch:12 step:11742 [D loss: 0.451496, acc.: 81.25%] [G loss: 1.225607]\n",
      "epoch:12 step:11743 [D loss: 0.383795, acc.: 89.84%] [G loss: 1.403296]\n",
      "epoch:12 step:11744 [D loss: 0.841022, acc.: 43.75%] [G loss: 1.073879]\n",
      "epoch:12 step:11745 [D loss: 0.751811, acc.: 52.34%] [G loss: 0.984129]\n",
      "epoch:12 step:11746 [D loss: 0.773619, acc.: 45.31%] [G loss: 0.928703]\n",
      "epoch:12 step:11747 [D loss: 0.710871, acc.: 53.91%] [G loss: 0.916648]\n",
      "epoch:12 step:11748 [D loss: 0.623032, acc.: 66.41%] [G loss: 1.074959]\n",
      "epoch:12 step:11749 [D loss: 0.710660, acc.: 50.00%] [G loss: 0.951819]\n",
      "epoch:12 step:11750 [D loss: 0.666043, acc.: 63.28%] [G loss: 0.897520]\n",
      "epoch:12 step:11751 [D loss: 0.602328, acc.: 65.62%] [G loss: 0.946219]\n",
      "epoch:12 step:11752 [D loss: 0.518135, acc.: 78.12%] [G loss: 0.940421]\n",
      "epoch:12 step:11753 [D loss: 0.685558, acc.: 55.47%] [G loss: 0.855828]\n",
      "epoch:12 step:11754 [D loss: 0.665732, acc.: 55.47%] [G loss: 1.021447]\n",
      "epoch:12 step:11755 [D loss: 0.675984, acc.: 60.94%] [G loss: 0.863857]\n",
      "epoch:12 step:11756 [D loss: 0.648093, acc.: 62.50%] [G loss: 0.987527]\n",
      "epoch:12 step:11757 [D loss: 0.524959, acc.: 83.59%] [G loss: 1.014537]\n",
      "epoch:12 step:11758 [D loss: 0.604267, acc.: 71.09%] [G loss: 0.955222]\n",
      "epoch:12 step:11759 [D loss: 0.560418, acc.: 67.97%] [G loss: 1.045114]\n",
      "epoch:12 step:11760 [D loss: 0.599891, acc.: 72.66%] [G loss: 0.943520]\n",
      "epoch:12 step:11761 [D loss: 0.677669, acc.: 60.16%] [G loss: 1.071930]\n",
      "epoch:12 step:11762 [D loss: 0.720818, acc.: 51.56%] [G loss: 0.822413]\n",
      "epoch:12 step:11763 [D loss: 0.627032, acc.: 63.28%] [G loss: 0.863103]\n",
      "epoch:12 step:11764 [D loss: 0.678370, acc.: 53.91%] [G loss: 0.984793]\n",
      "epoch:12 step:11765 [D loss: 0.543701, acc.: 75.78%] [G loss: 0.989833]\n",
      "epoch:12 step:11766 [D loss: 0.599652, acc.: 65.62%] [G loss: 1.070694]\n",
      "epoch:12 step:11767 [D loss: 0.479989, acc.: 83.59%] [G loss: 1.202822]\n",
      "epoch:12 step:11768 [D loss: 0.626001, acc.: 69.53%] [G loss: 1.084164]\n",
      "epoch:12 step:11769 [D loss: 0.708310, acc.: 60.16%] [G loss: 0.862408]\n",
      "epoch:12 step:11770 [D loss: 0.706933, acc.: 55.47%] [G loss: 0.969971]\n",
      "epoch:12 step:11771 [D loss: 0.644414, acc.: 64.06%] [G loss: 0.950863]\n",
      "epoch:12 step:11772 [D loss: 0.722404, acc.: 50.78%] [G loss: 0.939528]\n",
      "epoch:12 step:11773 [D loss: 0.582057, acc.: 68.75%] [G loss: 1.123232]\n",
      "epoch:12 step:11774 [D loss: 0.688772, acc.: 57.03%] [G loss: 0.974890]\n",
      "epoch:12 step:11775 [D loss: 0.634567, acc.: 66.41%] [G loss: 0.950267]\n",
      "epoch:12 step:11776 [D loss: 0.617834, acc.: 64.06%] [G loss: 0.922877]\n",
      "epoch:12 step:11777 [D loss: 0.445802, acc.: 85.94%] [G loss: 1.004991]\n",
      "epoch:12 step:11778 [D loss: 0.593915, acc.: 67.97%] [G loss: 0.991607]\n",
      "epoch:12 step:11779 [D loss: 0.620648, acc.: 66.41%] [G loss: 1.190764]\n",
      "epoch:12 step:11780 [D loss: 0.625223, acc.: 64.06%] [G loss: 0.971418]\n",
      "epoch:12 step:11781 [D loss: 0.552437, acc.: 72.66%] [G loss: 1.044625]\n",
      "epoch:12 step:11782 [D loss: 0.680425, acc.: 58.59%] [G loss: 0.957898]\n",
      "epoch:12 step:11783 [D loss: 0.596413, acc.: 71.88%] [G loss: 0.997493]\n",
      "epoch:12 step:11784 [D loss: 0.630574, acc.: 63.28%] [G loss: 0.981135]\n",
      "epoch:12 step:11785 [D loss: 0.698897, acc.: 55.47%] [G loss: 1.138346]\n",
      "epoch:12 step:11786 [D loss: 0.749465, acc.: 52.34%] [G loss: 0.956586]\n",
      "epoch:12 step:11787 [D loss: 0.629664, acc.: 64.84%] [G loss: 1.051011]\n",
      "epoch:12 step:11788 [D loss: 0.633043, acc.: 62.50%] [G loss: 1.005959]\n",
      "epoch:12 step:11789 [D loss: 0.572210, acc.: 70.31%] [G loss: 0.876716]\n",
      "epoch:12 step:11790 [D loss: 0.537026, acc.: 73.44%] [G loss: 0.944940]\n",
      "epoch:12 step:11791 [D loss: 0.547093, acc.: 77.34%] [G loss: 1.044199]\n",
      "epoch:12 step:11792 [D loss: 0.622757, acc.: 64.84%] [G loss: 1.035487]\n",
      "epoch:12 step:11793 [D loss: 0.496621, acc.: 78.91%] [G loss: 1.115136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11794 [D loss: 0.489573, acc.: 80.47%] [G loss: 1.224287]\n",
      "epoch:12 step:11795 [D loss: 0.472312, acc.: 82.03%] [G loss: 1.251249]\n",
      "epoch:12 step:11796 [D loss: 0.505177, acc.: 80.47%] [G loss: 1.141884]\n",
      "epoch:12 step:11797 [D loss: 0.571730, acc.: 69.53%] [G loss: 1.100860]\n",
      "epoch:12 step:11798 [D loss: 0.492467, acc.: 78.12%] [G loss: 1.091316]\n",
      "epoch:12 step:11799 [D loss: 0.503929, acc.: 78.12%] [G loss: 1.069692]\n",
      "epoch:12 step:11800 [D loss: 0.520434, acc.: 74.22%] [G loss: 0.963255]\n",
      "epoch:12 step:11801 [D loss: 0.544743, acc.: 73.44%] [G loss: 1.129892]\n",
      "epoch:12 step:11802 [D loss: 0.552062, acc.: 72.66%] [G loss: 1.361782]\n",
      "epoch:12 step:11803 [D loss: 0.755082, acc.: 51.56%] [G loss: 1.327985]\n",
      "epoch:12 step:11804 [D loss: 0.815467, acc.: 42.97%] [G loss: 1.035751]\n",
      "epoch:12 step:11805 [D loss: 0.630370, acc.: 65.62%] [G loss: 0.942005]\n",
      "epoch:12 step:11806 [D loss: 0.720057, acc.: 51.56%] [G loss: 0.921653]\n",
      "epoch:12 step:11807 [D loss: 0.747049, acc.: 52.34%] [G loss: 0.866463]\n",
      "epoch:12 step:11808 [D loss: 0.621402, acc.: 62.50%] [G loss: 0.992213]\n",
      "epoch:12 step:11809 [D loss: 0.578453, acc.: 72.66%] [G loss: 0.959282]\n",
      "epoch:12 step:11810 [D loss: 0.511873, acc.: 79.69%] [G loss: 1.165253]\n",
      "epoch:12 step:11811 [D loss: 0.555921, acc.: 71.88%] [G loss: 1.045252]\n",
      "epoch:12 step:11812 [D loss: 0.554813, acc.: 75.78%] [G loss: 1.178033]\n",
      "epoch:12 step:11813 [D loss: 0.692395, acc.: 56.25%] [G loss: 1.009241]\n",
      "epoch:12 step:11814 [D loss: 0.678251, acc.: 57.03%] [G loss: 0.845140]\n",
      "epoch:12 step:11815 [D loss: 0.635362, acc.: 66.41%] [G loss: 0.912870]\n",
      "epoch:12 step:11816 [D loss: 0.728720, acc.: 53.12%] [G loss: 0.921819]\n",
      "epoch:12 step:11817 [D loss: 0.540108, acc.: 78.12%] [G loss: 1.291798]\n",
      "epoch:12 step:11818 [D loss: 0.568275, acc.: 72.66%] [G loss: 1.073060]\n",
      "epoch:12 step:11819 [D loss: 0.631376, acc.: 63.28%] [G loss: 0.821046]\n",
      "epoch:12 step:11820 [D loss: 0.638587, acc.: 63.28%] [G loss: 0.768257]\n",
      "epoch:12 step:11821 [D loss: 0.656903, acc.: 63.28%] [G loss: 0.934632]\n",
      "epoch:12 step:11822 [D loss: 0.562226, acc.: 71.88%] [G loss: 1.164224]\n",
      "epoch:12 step:11823 [D loss: 0.704537, acc.: 54.69%] [G loss: 0.747114]\n",
      "epoch:12 step:11824 [D loss: 0.802358, acc.: 45.31%] [G loss: 1.056380]\n",
      "epoch:12 step:11825 [D loss: 0.793816, acc.: 44.53%] [G loss: 0.943935]\n",
      "epoch:12 step:11826 [D loss: 0.795367, acc.: 44.53%] [G loss: 0.900775]\n",
      "epoch:12 step:11827 [D loss: 0.852225, acc.: 35.94%] [G loss: 1.014042]\n",
      "epoch:12 step:11828 [D loss: 0.759370, acc.: 46.88%] [G loss: 0.899297]\n",
      "epoch:12 step:11829 [D loss: 0.641261, acc.: 64.06%] [G loss: 1.105871]\n",
      "epoch:12 step:11830 [D loss: 0.642807, acc.: 62.50%] [G loss: 1.163340]\n",
      "epoch:12 step:11831 [D loss: 0.477557, acc.: 84.38%] [G loss: 1.388695]\n",
      "epoch:12 step:11832 [D loss: 0.418549, acc.: 90.62%] [G loss: 1.323000]\n",
      "epoch:12 step:11833 [D loss: 0.483134, acc.: 85.16%] [G loss: 1.149514]\n",
      "epoch:12 step:11834 [D loss: 0.647358, acc.: 60.16%] [G loss: 1.240081]\n",
      "epoch:12 step:11835 [D loss: 0.778085, acc.: 43.75%] [G loss: 0.837065]\n",
      "epoch:12 step:11836 [D loss: 0.681365, acc.: 57.03%] [G loss: 0.966572]\n",
      "epoch:12 step:11837 [D loss: 0.759861, acc.: 54.69%] [G loss: 0.977283]\n",
      "epoch:12 step:11838 [D loss: 0.612045, acc.: 64.84%] [G loss: 1.134302]\n",
      "epoch:12 step:11839 [D loss: 0.636112, acc.: 67.19%] [G loss: 1.143446]\n",
      "epoch:12 step:11840 [D loss: 0.767087, acc.: 48.44%] [G loss: 0.931688]\n",
      "epoch:12 step:11841 [D loss: 0.621772, acc.: 67.97%] [G loss: 1.069855]\n",
      "epoch:12 step:11842 [D loss: 0.467507, acc.: 83.59%] [G loss: 1.129061]\n",
      "epoch:12 step:11843 [D loss: 0.703558, acc.: 53.91%] [G loss: 1.025113]\n",
      "epoch:12 step:11844 [D loss: 0.765607, acc.: 49.22%] [G loss: 1.041717]\n",
      "epoch:12 step:11845 [D loss: 0.695601, acc.: 51.56%] [G loss: 0.858800]\n",
      "epoch:12 step:11846 [D loss: 0.667500, acc.: 59.38%] [G loss: 1.058636]\n",
      "epoch:12 step:11847 [D loss: 0.565823, acc.: 71.88%] [G loss: 0.888696]\n",
      "epoch:12 step:11848 [D loss: 0.408732, acc.: 88.28%] [G loss: 1.160824]\n",
      "epoch:12 step:11849 [D loss: 0.572173, acc.: 71.09%] [G loss: 1.004201]\n",
      "epoch:12 step:11850 [D loss: 0.622931, acc.: 68.75%] [G loss: 1.059094]\n",
      "epoch:12 step:11851 [D loss: 0.674231, acc.: 57.81%] [G loss: 1.084256]\n",
      "epoch:12 step:11852 [D loss: 0.698590, acc.: 54.69%] [G loss: 0.945811]\n",
      "epoch:12 step:11853 [D loss: 0.614343, acc.: 67.97%] [G loss: 0.960709]\n",
      "epoch:12 step:11854 [D loss: 0.739742, acc.: 46.09%] [G loss: 0.880992]\n",
      "epoch:12 step:11855 [D loss: 0.651972, acc.: 59.38%] [G loss: 1.080101]\n",
      "epoch:12 step:11856 [D loss: 0.684104, acc.: 55.47%] [G loss: 1.024615]\n",
      "epoch:12 step:11857 [D loss: 0.581164, acc.: 69.53%] [G loss: 1.165927]\n",
      "epoch:12 step:11858 [D loss: 0.639574, acc.: 67.97%] [G loss: 1.080596]\n",
      "epoch:12 step:11859 [D loss: 0.526495, acc.: 75.00%] [G loss: 1.004830]\n",
      "epoch:12 step:11860 [D loss: 0.534246, acc.: 76.56%] [G loss: 1.213968]\n",
      "epoch:12 step:11861 [D loss: 0.677698, acc.: 55.47%] [G loss: 0.960610]\n",
      "epoch:12 step:11862 [D loss: 0.688977, acc.: 52.34%] [G loss: 0.924922]\n",
      "epoch:12 step:11863 [D loss: 0.690113, acc.: 60.16%] [G loss: 1.124612]\n",
      "epoch:12 step:11864 [D loss: 0.695843, acc.: 55.47%] [G loss: 1.056183]\n",
      "epoch:12 step:11865 [D loss: 0.756345, acc.: 50.78%] [G loss: 0.934373]\n",
      "epoch:12 step:11866 [D loss: 0.705611, acc.: 51.56%] [G loss: 1.110886]\n",
      "epoch:12 step:11867 [D loss: 0.750597, acc.: 49.22%] [G loss: 0.866463]\n",
      "epoch:12 step:11868 [D loss: 0.582293, acc.: 71.88%] [G loss: 0.947020]\n",
      "epoch:12 step:11869 [D loss: 0.706466, acc.: 55.47%] [G loss: 0.972193]\n",
      "epoch:12 step:11870 [D loss: 0.698600, acc.: 52.34%] [G loss: 0.988108]\n",
      "epoch:12 step:11871 [D loss: 0.679840, acc.: 57.81%] [G loss: 0.814176]\n",
      "epoch:12 step:11872 [D loss: 0.657853, acc.: 59.38%] [G loss: 0.875414]\n",
      "epoch:12 step:11873 [D loss: 0.579073, acc.: 70.31%] [G loss: 1.005104]\n",
      "epoch:12 step:11874 [D loss: 0.584269, acc.: 72.66%] [G loss: 0.921262]\n",
      "epoch:12 step:11875 [D loss: 0.768168, acc.: 49.22%] [G loss: 0.892243]\n",
      "epoch:12 step:11876 [D loss: 0.659822, acc.: 60.94%] [G loss: 0.919019]\n",
      "epoch:12 step:11877 [D loss: 0.675650, acc.: 58.59%] [G loss: 1.024300]\n",
      "epoch:12 step:11878 [D loss: 0.581071, acc.: 72.66%] [G loss: 1.014806]\n",
      "epoch:12 step:11879 [D loss: 0.550844, acc.: 75.00%] [G loss: 1.011321]\n",
      "epoch:12 step:11880 [D loss: 0.700539, acc.: 56.25%] [G loss: 0.975482]\n",
      "epoch:12 step:11881 [D loss: 0.723294, acc.: 55.47%] [G loss: 1.125987]\n",
      "epoch:12 step:11882 [D loss: 0.587484, acc.: 71.88%] [G loss: 1.032838]\n",
      "epoch:12 step:11883 [D loss: 0.747406, acc.: 50.00%] [G loss: 0.861328]\n",
      "epoch:12 step:11884 [D loss: 0.600985, acc.: 68.75%] [G loss: 0.921856]\n",
      "epoch:12 step:11885 [D loss: 0.586193, acc.: 70.31%] [G loss: 1.075414]\n",
      "epoch:12 step:11886 [D loss: 0.485637, acc.: 81.25%] [G loss: 1.242710]\n",
      "epoch:12 step:11887 [D loss: 0.734217, acc.: 49.22%] [G loss: 1.025610]\n",
      "epoch:12 step:11888 [D loss: 0.652747, acc.: 58.59%] [G loss: 1.098873]\n",
      "epoch:12 step:11889 [D loss: 0.666168, acc.: 57.81%] [G loss: 1.111009]\n",
      "epoch:12 step:11890 [D loss: 0.648665, acc.: 55.47%] [G loss: 1.025149]\n",
      "epoch:12 step:11891 [D loss: 0.590431, acc.: 69.53%] [G loss: 0.984451]\n",
      "epoch:12 step:11892 [D loss: 0.626943, acc.: 71.09%] [G loss: 0.986908]\n",
      "epoch:12 step:11893 [D loss: 0.589759, acc.: 71.09%] [G loss: 1.003395]\n",
      "epoch:12 step:11894 [D loss: 0.558714, acc.: 73.44%] [G loss: 1.075232]\n",
      "epoch:12 step:11895 [D loss: 0.596983, acc.: 67.97%] [G loss: 0.829191]\n",
      "epoch:12 step:11896 [D loss: 0.668983, acc.: 57.81%] [G loss: 0.890922]\n",
      "epoch:12 step:11897 [D loss: 0.609656, acc.: 64.84%] [G loss: 1.112028]\n",
      "epoch:12 step:11898 [D loss: 0.606856, acc.: 69.53%] [G loss: 0.955050]\n",
      "epoch:12 step:11899 [D loss: 0.682962, acc.: 53.91%] [G loss: 1.010296]\n",
      "epoch:12 step:11900 [D loss: 0.676496, acc.: 60.16%] [G loss: 1.058137]\n",
      "epoch:12 step:11901 [D loss: 0.774001, acc.: 49.22%] [G loss: 0.960243]\n",
      "epoch:12 step:11902 [D loss: 0.668648, acc.: 57.81%] [G loss: 0.898033]\n",
      "epoch:12 step:11903 [D loss: 0.631787, acc.: 64.84%] [G loss: 0.992261]\n",
      "epoch:12 step:11904 [D loss: 0.647660, acc.: 63.28%] [G loss: 1.177473]\n",
      "epoch:12 step:11905 [D loss: 0.534842, acc.: 71.88%] [G loss: 0.970192]\n",
      "epoch:12 step:11906 [D loss: 0.560187, acc.: 74.22%] [G loss: 0.902552]\n",
      "epoch:12 step:11907 [D loss: 0.512534, acc.: 75.78%] [G loss: 1.052145]\n",
      "epoch:12 step:11908 [D loss: 0.464585, acc.: 81.25%] [G loss: 1.188958]\n",
      "epoch:12 step:11909 [D loss: 0.449103, acc.: 85.16%] [G loss: 1.099321]\n",
      "epoch:12 step:11910 [D loss: 0.595938, acc.: 68.75%] [G loss: 1.065375]\n",
      "epoch:12 step:11911 [D loss: 0.615091, acc.: 67.19%] [G loss: 1.020561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11912 [D loss: 0.762642, acc.: 50.00%] [G loss: 0.998265]\n",
      "epoch:12 step:11913 [D loss: 0.603885, acc.: 62.50%] [G loss: 1.035516]\n",
      "epoch:12 step:11914 [D loss: 0.703574, acc.: 52.34%] [G loss: 1.100605]\n",
      "epoch:12 step:11915 [D loss: 0.689643, acc.: 60.16%] [G loss: 0.986262]\n",
      "epoch:12 step:11916 [D loss: 0.810284, acc.: 43.75%] [G loss: 0.853769]\n",
      "epoch:12 step:11917 [D loss: 0.857354, acc.: 32.81%] [G loss: 0.828435]\n",
      "epoch:12 step:11918 [D loss: 0.906673, acc.: 36.72%] [G loss: 0.746105]\n",
      "epoch:12 step:11919 [D loss: 0.650155, acc.: 65.62%] [G loss: 1.022312]\n",
      "epoch:12 step:11920 [D loss: 0.713610, acc.: 58.59%] [G loss: 0.968110]\n",
      "epoch:12 step:11921 [D loss: 0.629069, acc.: 65.62%] [G loss: 1.017698]\n",
      "epoch:12 step:11922 [D loss: 0.822583, acc.: 45.31%] [G loss: 0.955919]\n",
      "epoch:12 step:11923 [D loss: 0.681326, acc.: 56.25%] [G loss: 0.926760]\n",
      "epoch:12 step:11924 [D loss: 0.836769, acc.: 40.62%] [G loss: 0.881959]\n",
      "epoch:12 step:11925 [D loss: 0.571829, acc.: 75.00%] [G loss: 1.231120]\n",
      "epoch:12 step:11926 [D loss: 0.607048, acc.: 67.19%] [G loss: 0.968185]\n",
      "epoch:12 step:11927 [D loss: 0.586593, acc.: 68.75%] [G loss: 1.052802]\n",
      "epoch:12 step:11928 [D loss: 0.693270, acc.: 56.25%] [G loss: 0.854824]\n",
      "epoch:12 step:11929 [D loss: 0.589500, acc.: 66.41%] [G loss: 1.207642]\n",
      "epoch:12 step:11930 [D loss: 0.673261, acc.: 60.94%] [G loss: 0.988150]\n",
      "epoch:12 step:11931 [D loss: 0.612560, acc.: 63.28%] [G loss: 0.951393]\n",
      "epoch:12 step:11932 [D loss: 0.755117, acc.: 45.31%] [G loss: 0.873450]\n",
      "epoch:12 step:11933 [D loss: 0.614230, acc.: 67.97%] [G loss: 0.991533]\n",
      "epoch:12 step:11934 [D loss: 0.502859, acc.: 80.47%] [G loss: 1.162234]\n",
      "epoch:12 step:11935 [D loss: 0.596016, acc.: 66.41%] [G loss: 0.891618]\n",
      "epoch:12 step:11936 [D loss: 0.691682, acc.: 60.94%] [G loss: 1.010414]\n",
      "epoch:12 step:11937 [D loss: 0.491554, acc.: 79.69%] [G loss: 1.032400]\n",
      "epoch:12 step:11938 [D loss: 0.384178, acc.: 93.75%] [G loss: 1.171059]\n",
      "epoch:12 step:11939 [D loss: 0.508729, acc.: 78.12%] [G loss: 1.139058]\n",
      "epoch:12 step:11940 [D loss: 0.823792, acc.: 39.06%] [G loss: 0.850386]\n",
      "epoch:12 step:11941 [D loss: 0.675983, acc.: 60.16%] [G loss: 1.048398]\n",
      "epoch:12 step:11942 [D loss: 0.747566, acc.: 50.00%] [G loss: 1.132578]\n",
      "epoch:12 step:11943 [D loss: 0.670866, acc.: 58.59%] [G loss: 0.852860]\n",
      "epoch:12 step:11944 [D loss: 0.647038, acc.: 61.72%] [G loss: 0.909386]\n",
      "epoch:12 step:11945 [D loss: 0.665761, acc.: 65.62%] [G loss: 0.861225]\n",
      "epoch:12 step:11946 [D loss: 0.668507, acc.: 60.94%] [G loss: 0.926378]\n",
      "epoch:12 step:11947 [D loss: 0.593116, acc.: 72.66%] [G loss: 1.026739]\n",
      "epoch:12 step:11948 [D loss: 0.648661, acc.: 64.84%] [G loss: 0.986474]\n",
      "epoch:12 step:11949 [D loss: 0.627275, acc.: 64.84%] [G loss: 1.174247]\n",
      "epoch:12 step:11950 [D loss: 0.556271, acc.: 71.09%] [G loss: 0.839271]\n",
      "epoch:12 step:11951 [D loss: 0.488633, acc.: 78.12%] [G loss: 1.121129]\n",
      "epoch:12 step:11952 [D loss: 0.498098, acc.: 86.72%] [G loss: 1.155261]\n",
      "epoch:12 step:11953 [D loss: 0.465462, acc.: 82.81%] [G loss: 1.291707]\n",
      "epoch:12 step:11954 [D loss: 0.713686, acc.: 53.91%] [G loss: 0.938411]\n",
      "epoch:12 step:11955 [D loss: 0.711686, acc.: 53.91%] [G loss: 1.025136]\n",
      "epoch:12 step:11956 [D loss: 0.565203, acc.: 75.00%] [G loss: 1.057553]\n",
      "epoch:12 step:11957 [D loss: 0.595111, acc.: 65.62%] [G loss: 1.067526]\n",
      "epoch:12 step:11958 [D loss: 0.586792, acc.: 71.09%] [G loss: 1.037452]\n",
      "epoch:12 step:11959 [D loss: 0.679544, acc.: 55.47%] [G loss: 1.082818]\n",
      "epoch:12 step:11960 [D loss: 0.804523, acc.: 50.00%] [G loss: 0.925305]\n",
      "epoch:12 step:11961 [D loss: 0.573580, acc.: 71.88%] [G loss: 1.012249]\n",
      "epoch:12 step:11962 [D loss: 0.726928, acc.: 52.34%] [G loss: 0.902129]\n",
      "epoch:12 step:11963 [D loss: 0.640824, acc.: 58.59%] [G loss: 0.882680]\n",
      "epoch:12 step:11964 [D loss: 0.585459, acc.: 72.66%] [G loss: 1.065746]\n",
      "epoch:12 step:11965 [D loss: 0.652238, acc.: 67.97%] [G loss: 1.044894]\n",
      "epoch:12 step:11966 [D loss: 0.740896, acc.: 45.31%] [G loss: 0.939928]\n",
      "epoch:12 step:11967 [D loss: 0.666077, acc.: 55.47%] [G loss: 1.021983]\n",
      "epoch:12 step:11968 [D loss: 0.536783, acc.: 74.22%] [G loss: 0.988819]\n",
      "epoch:12 step:11969 [D loss: 0.504352, acc.: 83.59%] [G loss: 1.090053]\n",
      "epoch:12 step:11970 [D loss: 0.730924, acc.: 50.00%] [G loss: 1.029628]\n",
      "epoch:12 step:11971 [D loss: 0.647336, acc.: 63.28%] [G loss: 1.105648]\n",
      "epoch:12 step:11972 [D loss: 0.681858, acc.: 57.03%] [G loss: 0.983119]\n",
      "epoch:12 step:11973 [D loss: 0.643582, acc.: 64.84%] [G loss: 1.115833]\n",
      "epoch:12 step:11974 [D loss: 0.497224, acc.: 76.56%] [G loss: 1.203890]\n",
      "epoch:12 step:11975 [D loss: 0.524470, acc.: 75.78%] [G loss: 1.053629]\n",
      "epoch:12 step:11976 [D loss: 0.439414, acc.: 83.59%] [G loss: 1.129982]\n",
      "epoch:12 step:11977 [D loss: 0.588907, acc.: 69.53%] [G loss: 1.065373]\n",
      "epoch:12 step:11978 [D loss: 0.612750, acc.: 63.28%] [G loss: 1.190990]\n",
      "epoch:12 step:11979 [D loss: 0.667561, acc.: 59.38%] [G loss: 1.057202]\n",
      "epoch:12 step:11980 [D loss: 0.610279, acc.: 67.19%] [G loss: 0.930232]\n",
      "epoch:12 step:11981 [D loss: 0.548671, acc.: 76.56%] [G loss: 0.938359]\n",
      "epoch:12 step:11982 [D loss: 0.570612, acc.: 68.75%] [G loss: 0.977353]\n",
      "epoch:12 step:11983 [D loss: 0.549871, acc.: 77.34%] [G loss: 1.016415]\n",
      "epoch:12 step:11984 [D loss: 0.587810, acc.: 64.84%] [G loss: 1.185180]\n",
      "epoch:12 step:11985 [D loss: 0.839409, acc.: 39.06%] [G loss: 0.822214]\n",
      "epoch:12 step:11986 [D loss: 0.779363, acc.: 47.66%] [G loss: 1.039180]\n",
      "epoch:12 step:11987 [D loss: 0.741747, acc.: 50.00%] [G loss: 0.966283]\n",
      "epoch:12 step:11988 [D loss: 0.649198, acc.: 64.06%] [G loss: 1.017836]\n",
      "epoch:12 step:11989 [D loss: 0.509842, acc.: 75.00%] [G loss: 1.030919]\n",
      "epoch:12 step:11990 [D loss: 0.565521, acc.: 70.31%] [G loss: 1.060947]\n",
      "epoch:12 step:11991 [D loss: 0.593789, acc.: 70.31%] [G loss: 1.121078]\n",
      "epoch:12 step:11992 [D loss: 0.690350, acc.: 64.06%] [G loss: 1.021698]\n",
      "epoch:12 step:11993 [D loss: 0.743851, acc.: 52.34%] [G loss: 0.989038]\n",
      "epoch:12 step:11994 [D loss: 0.649505, acc.: 62.50%] [G loss: 0.961787]\n",
      "epoch:12 step:11995 [D loss: 0.646924, acc.: 60.16%] [G loss: 0.834694]\n",
      "epoch:12 step:11996 [D loss: 0.798265, acc.: 42.97%] [G loss: 0.808785]\n",
      "epoch:12 step:11997 [D loss: 0.644830, acc.: 60.94%] [G loss: 1.108135]\n",
      "epoch:12 step:11998 [D loss: 0.643297, acc.: 64.06%] [G loss: 1.160962]\n",
      "epoch:12 step:11999 [D loss: 0.638168, acc.: 64.84%] [G loss: 0.864188]\n",
      "epoch:12 step:12000 [D loss: 0.654869, acc.: 61.72%] [G loss: 1.026482]\n",
      "epoch:12 step:12001 [D loss: 0.575583, acc.: 70.31%] [G loss: 1.016906]\n",
      "epoch:12 step:12002 [D loss: 0.688436, acc.: 58.59%] [G loss: 1.099671]\n",
      "epoch:12 step:12003 [D loss: 0.699385, acc.: 58.59%] [G loss: 0.955721]\n",
      "epoch:12 step:12004 [D loss: 0.761379, acc.: 46.09%] [G loss: 0.976045]\n",
      "epoch:12 step:12005 [D loss: 0.729320, acc.: 53.12%] [G loss: 0.898444]\n",
      "epoch:12 step:12006 [D loss: 0.673677, acc.: 57.81%] [G loss: 1.008858]\n",
      "epoch:12 step:12007 [D loss: 0.589581, acc.: 68.75%] [G loss: 1.030435]\n",
      "epoch:12 step:12008 [D loss: 0.702127, acc.: 53.12%] [G loss: 0.936413]\n",
      "epoch:12 step:12009 [D loss: 0.640439, acc.: 61.72%] [G loss: 0.982505]\n",
      "epoch:12 step:12010 [D loss: 0.748051, acc.: 44.53%] [G loss: 0.982889]\n",
      "epoch:12 step:12011 [D loss: 0.583724, acc.: 70.31%] [G loss: 1.141182]\n",
      "epoch:12 step:12012 [D loss: 0.495986, acc.: 77.34%] [G loss: 1.361194]\n",
      "epoch:12 step:12013 [D loss: 0.417940, acc.: 89.84%] [G loss: 1.180164]\n",
      "epoch:12 step:12014 [D loss: 0.524383, acc.: 73.44%] [G loss: 1.100122]\n",
      "epoch:12 step:12015 [D loss: 0.656135, acc.: 58.59%] [G loss: 1.123552]\n",
      "epoch:12 step:12016 [D loss: 0.742563, acc.: 46.88%] [G loss: 0.890467]\n",
      "epoch:12 step:12017 [D loss: 0.639197, acc.: 64.84%] [G loss: 0.922041]\n",
      "epoch:12 step:12018 [D loss: 0.424507, acc.: 82.03%] [G loss: 1.193979]\n",
      "epoch:12 step:12019 [D loss: 0.373173, acc.: 88.28%] [G loss: 1.344666]\n",
      "epoch:12 step:12020 [D loss: 0.534409, acc.: 74.22%] [G loss: 1.243937]\n",
      "epoch:12 step:12021 [D loss: 0.572105, acc.: 71.09%] [G loss: 1.299940]\n",
      "epoch:12 step:12022 [D loss: 0.580276, acc.: 68.75%] [G loss: 1.094984]\n",
      "epoch:12 step:12023 [D loss: 0.782988, acc.: 48.44%] [G loss: 1.104516]\n",
      "epoch:12 step:12024 [D loss: 0.878514, acc.: 33.59%] [G loss: 0.857221]\n",
      "epoch:12 step:12025 [D loss: 0.693286, acc.: 63.28%] [G loss: 0.967128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12026 [D loss: 0.667360, acc.: 57.81%] [G loss: 1.055660]\n",
      "epoch:12 step:12027 [D loss: 0.714783, acc.: 50.00%] [G loss: 1.115749]\n",
      "epoch:12 step:12028 [D loss: 0.746945, acc.: 47.66%] [G loss: 0.962712]\n",
      "epoch:12 step:12029 [D loss: 0.698009, acc.: 54.69%] [G loss: 1.031608]\n",
      "epoch:12 step:12030 [D loss: 0.635733, acc.: 60.94%] [G loss: 1.032301]\n",
      "epoch:12 step:12031 [D loss: 0.751661, acc.: 46.09%] [G loss: 0.987461]\n",
      "epoch:12 step:12032 [D loss: 0.734439, acc.: 51.56%] [G loss: 0.964354]\n",
      "epoch:12 step:12033 [D loss: 0.609600, acc.: 71.88%] [G loss: 1.046707]\n",
      "epoch:12 step:12034 [D loss: 0.627793, acc.: 64.84%] [G loss: 0.972541]\n",
      "epoch:12 step:12035 [D loss: 0.542734, acc.: 71.88%] [G loss: 1.064336]\n",
      "epoch:12 step:12036 [D loss: 0.482624, acc.: 81.25%] [G loss: 0.982850]\n",
      "epoch:12 step:12037 [D loss: 0.582523, acc.: 71.09%] [G loss: 1.146765]\n",
      "epoch:12 step:12038 [D loss: 0.496729, acc.: 78.12%] [G loss: 1.328970]\n",
      "epoch:12 step:12039 [D loss: 0.671318, acc.: 59.38%] [G loss: 1.048082]\n",
      "epoch:12 step:12040 [D loss: 0.712038, acc.: 56.25%] [G loss: 1.013093]\n",
      "epoch:12 step:12041 [D loss: 0.610125, acc.: 68.75%] [G loss: 1.324068]\n",
      "epoch:12 step:12042 [D loss: 0.579292, acc.: 70.31%] [G loss: 1.024782]\n",
      "epoch:12 step:12043 [D loss: 0.803658, acc.: 42.19%] [G loss: 0.849456]\n",
      "epoch:12 step:12044 [D loss: 0.760822, acc.: 44.53%] [G loss: 0.979253]\n",
      "epoch:12 step:12045 [D loss: 0.731108, acc.: 53.91%] [G loss: 1.025496]\n",
      "epoch:12 step:12046 [D loss: 0.606121, acc.: 71.09%] [G loss: 1.042814]\n",
      "epoch:12 step:12047 [D loss: 0.680113, acc.: 56.25%] [G loss: 0.927541]\n",
      "epoch:12 step:12048 [D loss: 0.625151, acc.: 60.94%] [G loss: 1.018940]\n",
      "epoch:12 step:12049 [D loss: 0.600488, acc.: 71.09%] [G loss: 0.904366]\n",
      "epoch:12 step:12050 [D loss: 0.577424, acc.: 71.09%] [G loss: 0.944217]\n",
      "epoch:12 step:12051 [D loss: 0.609480, acc.: 64.84%] [G loss: 1.013032]\n",
      "epoch:12 step:12052 [D loss: 0.677916, acc.: 59.38%] [G loss: 1.045109]\n",
      "epoch:12 step:12053 [D loss: 0.597251, acc.: 65.62%] [G loss: 1.042311]\n",
      "epoch:12 step:12054 [D loss: 0.640500, acc.: 65.62%] [G loss: 0.982630]\n",
      "epoch:12 step:12055 [D loss: 0.638595, acc.: 65.62%] [G loss: 1.017868]\n",
      "epoch:12 step:12056 [D loss: 0.674390, acc.: 57.81%] [G loss: 1.091215]\n",
      "epoch:12 step:12057 [D loss: 0.685449, acc.: 56.25%] [G loss: 1.004866]\n",
      "epoch:12 step:12058 [D loss: 0.674019, acc.: 63.28%] [G loss: 0.988753]\n",
      "epoch:12 step:12059 [D loss: 0.378000, acc.: 82.81%] [G loss: 1.088921]\n",
      "epoch:12 step:12060 [D loss: 0.563860, acc.: 70.31%] [G loss: 1.045162]\n",
      "epoch:12 step:12061 [D loss: 0.581345, acc.: 69.53%] [G loss: 1.195223]\n",
      "epoch:12 step:12062 [D loss: 0.601241, acc.: 71.88%] [G loss: 1.123051]\n",
      "epoch:12 step:12063 [D loss: 0.567504, acc.: 74.22%] [G loss: 1.026007]\n",
      "epoch:12 step:12064 [D loss: 0.848943, acc.: 37.50%] [G loss: 0.926573]\n",
      "epoch:12 step:12065 [D loss: 0.748176, acc.: 48.44%] [G loss: 0.895444]\n",
      "epoch:12 step:12066 [D loss: 0.609917, acc.: 68.75%] [G loss: 1.109657]\n",
      "epoch:12 step:12067 [D loss: 0.624090, acc.: 66.41%] [G loss: 0.917177]\n",
      "epoch:12 step:12068 [D loss: 0.589247, acc.: 71.09%] [G loss: 0.837879]\n",
      "epoch:12 step:12069 [D loss: 0.469331, acc.: 84.38%] [G loss: 1.278485]\n",
      "epoch:12 step:12070 [D loss: 0.709343, acc.: 55.47%] [G loss: 1.014743]\n",
      "epoch:12 step:12071 [D loss: 0.708308, acc.: 59.38%] [G loss: 0.945360]\n",
      "epoch:12 step:12072 [D loss: 0.728779, acc.: 51.56%] [G loss: 0.879379]\n",
      "epoch:12 step:12073 [D loss: 0.617297, acc.: 71.09%] [G loss: 1.101931]\n",
      "epoch:12 step:12074 [D loss: 0.616364, acc.: 66.41%] [G loss: 0.973601]\n",
      "epoch:12 step:12075 [D loss: 0.547560, acc.: 75.00%] [G loss: 1.066675]\n",
      "epoch:12 step:12076 [D loss: 0.497789, acc.: 78.91%] [G loss: 1.303154]\n",
      "epoch:12 step:12077 [D loss: 0.634471, acc.: 60.16%] [G loss: 1.113530]\n",
      "epoch:12 step:12078 [D loss: 0.802850, acc.: 39.84%] [G loss: 1.130579]\n",
      "epoch:12 step:12079 [D loss: 0.861605, acc.: 35.16%] [G loss: 1.136060]\n",
      "epoch:12 step:12080 [D loss: 0.888290, acc.: 39.06%] [G loss: 0.928088]\n",
      "epoch:12 step:12081 [D loss: 0.660247, acc.: 63.28%] [G loss: 0.997150]\n",
      "epoch:12 step:12082 [D loss: 0.658570, acc.: 63.28%] [G loss: 1.040908]\n",
      "epoch:12 step:12083 [D loss: 0.621135, acc.: 62.50%] [G loss: 1.114919]\n",
      "epoch:12 step:12084 [D loss: 0.573352, acc.: 71.09%] [G loss: 1.228951]\n",
      "epoch:12 step:12085 [D loss: 0.555471, acc.: 70.31%] [G loss: 1.105049]\n",
      "epoch:12 step:12086 [D loss: 0.496723, acc.: 81.25%] [G loss: 1.162575]\n",
      "epoch:12 step:12087 [D loss: 0.725391, acc.: 51.56%] [G loss: 0.935336]\n",
      "epoch:12 step:12088 [D loss: 0.686286, acc.: 59.38%] [G loss: 0.957745]\n",
      "epoch:12 step:12089 [D loss: 0.690342, acc.: 56.25%] [G loss: 0.905139]\n",
      "epoch:12 step:12090 [D loss: 0.585347, acc.: 71.88%] [G loss: 0.924568]\n",
      "epoch:12 step:12091 [D loss: 0.578318, acc.: 70.31%] [G loss: 1.026433]\n",
      "epoch:12 step:12092 [D loss: 0.610373, acc.: 66.41%] [G loss: 0.943135]\n",
      "epoch:12 step:12093 [D loss: 0.493915, acc.: 79.69%] [G loss: 1.029237]\n",
      "epoch:12 step:12094 [D loss: 0.513588, acc.: 76.56%] [G loss: 0.983306]\n",
      "epoch:12 step:12095 [D loss: 0.415295, acc.: 87.50%] [G loss: 1.242001]\n",
      "epoch:12 step:12096 [D loss: 0.416264, acc.: 89.06%] [G loss: 1.208973]\n",
      "epoch:12 step:12097 [D loss: 0.622096, acc.: 62.50%] [G loss: 1.139404]\n",
      "epoch:12 step:12098 [D loss: 0.372619, acc.: 92.19%] [G loss: 1.392699]\n",
      "epoch:12 step:12099 [D loss: 0.530015, acc.: 76.56%] [G loss: 1.190586]\n",
      "epoch:12 step:12100 [D loss: 0.585699, acc.: 70.31%] [G loss: 1.260309]\n",
      "epoch:12 step:12101 [D loss: 0.503448, acc.: 76.56%] [G loss: 1.083287]\n",
      "epoch:12 step:12102 [D loss: 0.711550, acc.: 57.81%] [G loss: 0.981074]\n",
      "epoch:12 step:12103 [D loss: 0.855499, acc.: 36.72%] [G loss: 0.899908]\n",
      "epoch:12 step:12104 [D loss: 0.672223, acc.: 55.47%] [G loss: 0.907713]\n",
      "epoch:12 step:12105 [D loss: 0.731695, acc.: 50.00%] [G loss: 0.971302]\n",
      "epoch:12 step:12106 [D loss: 0.716842, acc.: 59.38%] [G loss: 0.896161]\n",
      "epoch:12 step:12107 [D loss: 0.669691, acc.: 60.94%] [G loss: 0.888224]\n",
      "epoch:12 step:12108 [D loss: 0.652487, acc.: 58.59%] [G loss: 0.955339]\n",
      "epoch:12 step:12109 [D loss: 0.597817, acc.: 67.97%] [G loss: 1.075634]\n",
      "epoch:12 step:12110 [D loss: 0.709006, acc.: 56.25%] [G loss: 0.882170]\n",
      "epoch:12 step:12111 [D loss: 0.732857, acc.: 52.34%] [G loss: 0.892773]\n",
      "epoch:12 step:12112 [D loss: 0.630832, acc.: 58.59%] [G loss: 0.968404]\n",
      "epoch:12 step:12113 [D loss: 0.627726, acc.: 67.19%] [G loss: 1.062675]\n",
      "epoch:12 step:12114 [D loss: 0.685151, acc.: 57.81%] [G loss: 0.936753]\n",
      "epoch:12 step:12115 [D loss: 0.666579, acc.: 59.38%] [G loss: 0.921671]\n",
      "epoch:12 step:12116 [D loss: 0.699970, acc.: 58.59%] [G loss: 0.786944]\n",
      "epoch:12 step:12117 [D loss: 0.683421, acc.: 58.59%] [G loss: 1.100381]\n",
      "epoch:12 step:12118 [D loss: 0.632870, acc.: 67.19%] [G loss: 0.926548]\n",
      "epoch:12 step:12119 [D loss: 0.643990, acc.: 63.28%] [G loss: 0.697153]\n",
      "epoch:12 step:12120 [D loss: 0.641368, acc.: 61.72%] [G loss: 1.231935]\n",
      "epoch:12 step:12121 [D loss: 0.730113, acc.: 52.34%] [G loss: 0.800675]\n",
      "epoch:12 step:12122 [D loss: 0.642992, acc.: 64.06%] [G loss: 1.004850]\n",
      "epoch:12 step:12123 [D loss: 0.629277, acc.: 66.41%] [G loss: 1.123955]\n",
      "epoch:12 step:12124 [D loss: 0.723359, acc.: 50.00%] [G loss: 0.963437]\n",
      "epoch:12 step:12125 [D loss: 0.702157, acc.: 56.25%] [G loss: 0.899639]\n",
      "epoch:12 step:12126 [D loss: 0.643577, acc.: 62.50%] [G loss: 1.007159]\n",
      "epoch:12 step:12127 [D loss: 0.690234, acc.: 54.69%] [G loss: 0.988363]\n",
      "epoch:12 step:12128 [D loss: 0.704793, acc.: 57.03%] [G loss: 0.828097]\n",
      "epoch:12 step:12129 [D loss: 0.584684, acc.: 71.09%] [G loss: 0.880394]\n",
      "epoch:12 step:12130 [D loss: 0.502401, acc.: 77.34%] [G loss: 1.211113]\n",
      "epoch:12 step:12131 [D loss: 0.518890, acc.: 76.56%] [G loss: 1.187500]\n",
      "epoch:12 step:12132 [D loss: 0.600209, acc.: 69.53%] [G loss: 0.969579]\n",
      "epoch:12 step:12133 [D loss: 0.521837, acc.: 77.34%] [G loss: 1.121820]\n",
      "epoch:12 step:12134 [D loss: 0.494369, acc.: 79.69%] [G loss: 1.070134]\n",
      "epoch:12 step:12135 [D loss: 0.678611, acc.: 53.12%] [G loss: 1.232460]\n",
      "epoch:12 step:12136 [D loss: 0.748248, acc.: 49.22%] [G loss: 1.020246]\n",
      "epoch:12 step:12137 [D loss: 0.656827, acc.: 59.38%] [G loss: 1.075134]\n",
      "epoch:12 step:12138 [D loss: 0.515741, acc.: 79.69%] [G loss: 1.010587]\n",
      "epoch:12 step:12139 [D loss: 0.606277, acc.: 65.62%] [G loss: 1.047431]\n",
      "epoch:12 step:12140 [D loss: 0.603711, acc.: 64.06%] [G loss: 0.846640]\n",
      "epoch:12 step:12141 [D loss: 0.511052, acc.: 79.69%] [G loss: 0.974509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12142 [D loss: 0.446181, acc.: 85.94%] [G loss: 1.054222]\n",
      "epoch:12 step:12143 [D loss: 0.490198, acc.: 75.00%] [G loss: 1.080711]\n",
      "epoch:12 step:12144 [D loss: 0.460233, acc.: 82.81%] [G loss: 1.325202]\n",
      "epoch:12 step:12145 [D loss: 0.607109, acc.: 67.97%] [G loss: 1.198537]\n",
      "epoch:12 step:12146 [D loss: 0.578342, acc.: 71.88%] [G loss: 1.264919]\n",
      "epoch:12 step:12147 [D loss: 0.658814, acc.: 60.94%] [G loss: 1.214977]\n",
      "epoch:12 step:12148 [D loss: 0.720629, acc.: 53.91%] [G loss: 1.027256]\n",
      "epoch:12 step:12149 [D loss: 0.668279, acc.: 57.03%] [G loss: 0.857135]\n",
      "epoch:12 step:12150 [D loss: 0.605825, acc.: 67.19%] [G loss: 1.115499]\n",
      "epoch:12 step:12151 [D loss: 0.719059, acc.: 53.12%] [G loss: 0.888941]\n",
      "epoch:12 step:12152 [D loss: 0.658034, acc.: 64.06%] [G loss: 1.083038]\n",
      "epoch:12 step:12153 [D loss: 0.558174, acc.: 77.34%] [G loss: 1.065534]\n",
      "epoch:12 step:12154 [D loss: 0.605615, acc.: 68.75%] [G loss: 1.019679]\n",
      "epoch:12 step:12155 [D loss: 0.497382, acc.: 78.91%] [G loss: 1.146852]\n",
      "epoch:12 step:12156 [D loss: 0.297765, acc.: 92.97%] [G loss: 1.269729]\n",
      "epoch:12 step:12157 [D loss: 0.689784, acc.: 57.81%] [G loss: 1.365444]\n",
      "epoch:12 step:12158 [D loss: 0.808777, acc.: 38.28%] [G loss: 1.084442]\n",
      "epoch:12 step:12159 [D loss: 0.687559, acc.: 57.81%] [G loss: 1.042288]\n",
      "epoch:12 step:12160 [D loss: 0.696113, acc.: 55.47%] [G loss: 0.913280]\n",
      "epoch:12 step:12161 [D loss: 0.587836, acc.: 71.09%] [G loss: 1.078487]\n",
      "epoch:12 step:12162 [D loss: 0.598867, acc.: 70.31%] [G loss: 0.987668]\n",
      "epoch:12 step:12163 [D loss: 0.551708, acc.: 68.75%] [G loss: 1.077419]\n",
      "epoch:12 step:12164 [D loss: 0.676789, acc.: 57.81%] [G loss: 1.142722]\n",
      "epoch:12 step:12165 [D loss: 0.628448, acc.: 66.41%] [G loss: 1.102604]\n",
      "epoch:12 step:12166 [D loss: 0.554303, acc.: 73.44%] [G loss: 1.057523]\n",
      "epoch:12 step:12167 [D loss: 0.517072, acc.: 78.91%] [G loss: 1.151638]\n",
      "epoch:12 step:12168 [D loss: 0.623452, acc.: 68.75%] [G loss: 0.900575]\n",
      "epoch:12 step:12169 [D loss: 0.617151, acc.: 68.75%] [G loss: 0.832403]\n",
      "epoch:12 step:12170 [D loss: 0.469651, acc.: 84.38%] [G loss: 1.146772]\n",
      "epoch:12 step:12171 [D loss: 0.446216, acc.: 84.38%] [G loss: 1.182205]\n",
      "epoch:12 step:12172 [D loss: 0.872345, acc.: 39.06%] [G loss: 0.992102]\n",
      "epoch:12 step:12173 [D loss: 0.611107, acc.: 63.28%] [G loss: 1.019876]\n",
      "epoch:12 step:12174 [D loss: 0.565890, acc.: 72.66%] [G loss: 1.159326]\n",
      "epoch:12 step:12175 [D loss: 0.669628, acc.: 60.16%] [G loss: 1.068329]\n",
      "epoch:12 step:12176 [D loss: 0.647172, acc.: 65.62%] [G loss: 1.119206]\n",
      "epoch:12 step:12177 [D loss: 0.694506, acc.: 57.03%] [G loss: 0.911425]\n",
      "epoch:12 step:12178 [D loss: 0.489368, acc.: 78.12%] [G loss: 1.104018]\n",
      "epoch:12 step:12179 [D loss: 0.688193, acc.: 54.69%] [G loss: 0.979499]\n",
      "epoch:12 step:12180 [D loss: 0.432096, acc.: 87.50%] [G loss: 1.165478]\n",
      "epoch:12 step:12181 [D loss: 0.412012, acc.: 79.69%] [G loss: 1.076258]\n",
      "epoch:13 step:12182 [D loss: 0.694479, acc.: 58.59%] [G loss: 1.085400]\n",
      "epoch:13 step:12183 [D loss: 0.702740, acc.: 53.91%] [G loss: 1.197269]\n",
      "epoch:13 step:12184 [D loss: 0.698023, acc.: 53.12%] [G loss: 1.040395]\n",
      "epoch:13 step:12185 [D loss: 0.621389, acc.: 64.06%] [G loss: 1.012687]\n",
      "epoch:13 step:12186 [D loss: 0.635282, acc.: 66.41%] [G loss: 0.992112]\n",
      "epoch:13 step:12187 [D loss: 0.598852, acc.: 64.06%] [G loss: 1.016849]\n",
      "epoch:13 step:12188 [D loss: 0.637712, acc.: 66.41%] [G loss: 0.982515]\n",
      "epoch:13 step:12189 [D loss: 0.587147, acc.: 69.53%] [G loss: 1.078840]\n",
      "epoch:13 step:12190 [D loss: 0.574058, acc.: 68.75%] [G loss: 0.885007]\n",
      "epoch:13 step:12191 [D loss: 0.480512, acc.: 83.59%] [G loss: 1.043024]\n",
      "epoch:13 step:12192 [D loss: 0.610861, acc.: 67.19%] [G loss: 1.013084]\n",
      "epoch:13 step:12193 [D loss: 0.639699, acc.: 61.72%] [G loss: 1.067618]\n",
      "epoch:13 step:12194 [D loss: 0.628706, acc.: 67.97%] [G loss: 1.118500]\n",
      "epoch:13 step:12195 [D loss: 0.642437, acc.: 60.94%] [G loss: 1.010803]\n",
      "epoch:13 step:12196 [D loss: 0.582487, acc.: 68.75%] [G loss: 1.051359]\n",
      "epoch:13 step:12197 [D loss: 0.570530, acc.: 75.00%] [G loss: 0.993863]\n",
      "epoch:13 step:12198 [D loss: 0.632960, acc.: 64.06%] [G loss: 1.064794]\n",
      "epoch:13 step:12199 [D loss: 0.731698, acc.: 52.34%] [G loss: 0.889412]\n",
      "epoch:13 step:12200 [D loss: 0.840276, acc.: 33.59%] [G loss: 0.759705]\n",
      "epoch:13 step:12201 [D loss: 0.776146, acc.: 44.53%] [G loss: 0.974944]\n",
      "epoch:13 step:12202 [D loss: 0.677461, acc.: 60.16%] [G loss: 0.974153]\n",
      "epoch:13 step:12203 [D loss: 0.697892, acc.: 57.03%] [G loss: 1.076253]\n",
      "epoch:13 step:12204 [D loss: 0.670740, acc.: 60.16%] [G loss: 1.055074]\n",
      "epoch:13 step:12205 [D loss: 0.627732, acc.: 68.75%] [G loss: 0.967924]\n",
      "epoch:13 step:12206 [D loss: 0.587078, acc.: 70.31%] [G loss: 1.041977]\n",
      "epoch:13 step:12207 [D loss: 0.563551, acc.: 71.09%] [G loss: 1.056724]\n",
      "epoch:13 step:12208 [D loss: 0.566421, acc.: 71.09%] [G loss: 1.051282]\n",
      "epoch:13 step:12209 [D loss: 0.497400, acc.: 80.47%] [G loss: 1.210162]\n",
      "epoch:13 step:12210 [D loss: 0.535229, acc.: 73.44%] [G loss: 1.090930]\n",
      "epoch:13 step:12211 [D loss: 0.469416, acc.: 84.38%] [G loss: 1.105398]\n",
      "epoch:13 step:12212 [D loss: 0.512603, acc.: 78.12%] [G loss: 1.267793]\n",
      "epoch:13 step:12213 [D loss: 0.418032, acc.: 89.06%] [G loss: 1.467115]\n",
      "epoch:13 step:12214 [D loss: 0.487015, acc.: 81.25%] [G loss: 1.041973]\n",
      "epoch:13 step:12215 [D loss: 0.545070, acc.: 75.00%] [G loss: 1.117845]\n",
      "epoch:13 step:12216 [D loss: 0.364458, acc.: 90.62%] [G loss: 1.309359]\n",
      "epoch:13 step:12217 [D loss: 0.353166, acc.: 90.62%] [G loss: 1.450922]\n",
      "epoch:13 step:12218 [D loss: 0.739289, acc.: 51.56%] [G loss: 1.188727]\n",
      "epoch:13 step:12219 [D loss: 0.810204, acc.: 45.31%] [G loss: 1.157837]\n",
      "epoch:13 step:12220 [D loss: 0.769991, acc.: 45.31%] [G loss: 0.942876]\n",
      "epoch:13 step:12221 [D loss: 0.696896, acc.: 55.47%] [G loss: 1.114426]\n",
      "epoch:13 step:12222 [D loss: 0.709563, acc.: 51.56%] [G loss: 0.975845]\n",
      "epoch:13 step:12223 [D loss: 0.576027, acc.: 71.88%] [G loss: 0.999676]\n",
      "epoch:13 step:12224 [D loss: 0.596933, acc.: 69.53%] [G loss: 1.094995]\n",
      "epoch:13 step:12225 [D loss: 0.703980, acc.: 52.34%] [G loss: 1.067917]\n",
      "epoch:13 step:12226 [D loss: 0.714297, acc.: 54.69%] [G loss: 0.949431]\n",
      "epoch:13 step:12227 [D loss: 0.756687, acc.: 47.66%] [G loss: 0.972155]\n",
      "epoch:13 step:12228 [D loss: 0.718095, acc.: 49.22%] [G loss: 0.890531]\n",
      "epoch:13 step:12229 [D loss: 0.620793, acc.: 67.19%] [G loss: 1.047173]\n",
      "epoch:13 step:12230 [D loss: 0.562018, acc.: 72.66%] [G loss: 0.888650]\n",
      "epoch:13 step:12231 [D loss: 0.535697, acc.: 77.34%] [G loss: 1.037900]\n",
      "epoch:13 step:12232 [D loss: 0.682951, acc.: 53.91%] [G loss: 0.941401]\n",
      "epoch:13 step:12233 [D loss: 0.702057, acc.: 57.03%] [G loss: 0.909083]\n",
      "epoch:13 step:12234 [D loss: 0.594497, acc.: 67.97%] [G loss: 0.999672]\n",
      "epoch:13 step:12235 [D loss: 0.626381, acc.: 68.75%] [G loss: 1.034312]\n",
      "epoch:13 step:12236 [D loss: 0.639756, acc.: 60.16%] [G loss: 0.968094]\n",
      "epoch:13 step:12237 [D loss: 0.618509, acc.: 66.41%] [G loss: 0.841744]\n",
      "epoch:13 step:12238 [D loss: 0.774699, acc.: 42.97%] [G loss: 1.001179]\n",
      "epoch:13 step:12239 [D loss: 0.596784, acc.: 67.19%] [G loss: 0.814597]\n",
      "epoch:13 step:12240 [D loss: 0.709571, acc.: 54.69%] [G loss: 0.830756]\n",
      "epoch:13 step:12241 [D loss: 0.676462, acc.: 57.81%] [G loss: 0.964742]\n",
      "epoch:13 step:12242 [D loss: 0.721074, acc.: 50.00%] [G loss: 1.012774]\n",
      "epoch:13 step:12243 [D loss: 0.744810, acc.: 50.78%] [G loss: 0.965853]\n",
      "epoch:13 step:12244 [D loss: 0.623356, acc.: 67.97%] [G loss: 0.901770]\n",
      "epoch:13 step:12245 [D loss: 0.615028, acc.: 63.28%] [G loss: 0.991708]\n",
      "epoch:13 step:12246 [D loss: 0.731880, acc.: 50.00%] [G loss: 0.919433]\n",
      "epoch:13 step:12247 [D loss: 0.620184, acc.: 65.62%] [G loss: 1.033258]\n",
      "epoch:13 step:12248 [D loss: 0.704463, acc.: 55.47%] [G loss: 0.807700]\n",
      "epoch:13 step:12249 [D loss: 0.584674, acc.: 71.88%] [G loss: 0.983765]\n",
      "epoch:13 step:12250 [D loss: 0.630518, acc.: 61.72%] [G loss: 0.822790]\n",
      "epoch:13 step:12251 [D loss: 0.538633, acc.: 78.12%] [G loss: 1.350872]\n",
      "epoch:13 step:12252 [D loss: 0.663185, acc.: 60.94%] [G loss: 0.891951]\n",
      "epoch:13 step:12253 [D loss: 0.650545, acc.: 62.50%] [G loss: 0.972170]\n",
      "epoch:13 step:12254 [D loss: 0.705447, acc.: 61.72%] [G loss: 1.095762]\n",
      "epoch:13 step:12255 [D loss: 0.612432, acc.: 66.41%] [G loss: 1.019589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12256 [D loss: 0.505866, acc.: 77.34%] [G loss: 1.223719]\n",
      "epoch:13 step:12257 [D loss: 0.551448, acc.: 72.66%] [G loss: 1.001994]\n",
      "epoch:13 step:12258 [D loss: 0.517147, acc.: 73.44%] [G loss: 1.282153]\n",
      "epoch:13 step:12259 [D loss: 0.658282, acc.: 61.72%] [G loss: 1.204429]\n",
      "epoch:13 step:12260 [D loss: 0.907709, acc.: 35.16%] [G loss: 0.902765]\n",
      "epoch:13 step:12261 [D loss: 0.667677, acc.: 58.59%] [G loss: 1.026981]\n",
      "epoch:13 step:12262 [D loss: 0.637972, acc.: 57.81%] [G loss: 1.131351]\n",
      "epoch:13 step:12263 [D loss: 0.597955, acc.: 69.53%] [G loss: 0.991039]\n",
      "epoch:13 step:12264 [D loss: 0.662544, acc.: 57.81%] [G loss: 0.972534]\n",
      "epoch:13 step:12265 [D loss: 0.683027, acc.: 60.94%] [G loss: 0.912911]\n",
      "epoch:13 step:12266 [D loss: 0.661696, acc.: 59.38%] [G loss: 0.865066]\n",
      "epoch:13 step:12267 [D loss: 0.616135, acc.: 67.19%] [G loss: 0.993307]\n",
      "epoch:13 step:12268 [D loss: 0.617723, acc.: 65.62%] [G loss: 0.906074]\n",
      "epoch:13 step:12269 [D loss: 0.674949, acc.: 60.16%] [G loss: 0.954997]\n",
      "epoch:13 step:12270 [D loss: 0.625057, acc.: 62.50%] [G loss: 0.906789]\n",
      "epoch:13 step:12271 [D loss: 0.619772, acc.: 65.62%] [G loss: 1.004027]\n",
      "epoch:13 step:12272 [D loss: 0.821706, acc.: 39.84%] [G loss: 0.866726]\n",
      "epoch:13 step:12273 [D loss: 0.593719, acc.: 75.00%] [G loss: 1.115757]\n",
      "epoch:13 step:12274 [D loss: 0.600653, acc.: 68.75%] [G loss: 1.036836]\n",
      "epoch:13 step:12275 [D loss: 0.623392, acc.: 66.41%] [G loss: 1.094810]\n",
      "epoch:13 step:12276 [D loss: 0.734035, acc.: 56.25%] [G loss: 0.916070]\n",
      "epoch:13 step:12277 [D loss: 0.570397, acc.: 72.66%] [G loss: 0.932506]\n",
      "epoch:13 step:12278 [D loss: 0.805517, acc.: 39.84%] [G loss: 0.816303]\n",
      "epoch:13 step:12279 [D loss: 0.775920, acc.: 46.09%] [G loss: 0.901783]\n",
      "epoch:13 step:12280 [D loss: 0.626120, acc.: 62.50%] [G loss: 0.858577]\n",
      "epoch:13 step:12281 [D loss: 0.712761, acc.: 50.78%] [G loss: 0.843588]\n",
      "epoch:13 step:12282 [D loss: 0.559085, acc.: 72.66%] [G loss: 1.065783]\n",
      "epoch:13 step:12283 [D loss: 0.655498, acc.: 58.59%] [G loss: 1.123805]\n",
      "epoch:13 step:12284 [D loss: 0.629819, acc.: 64.84%] [G loss: 0.965304]\n",
      "epoch:13 step:12285 [D loss: 0.621005, acc.: 65.62%] [G loss: 1.089778]\n",
      "epoch:13 step:12286 [D loss: 0.659119, acc.: 65.62%] [G loss: 1.015040]\n",
      "epoch:13 step:12287 [D loss: 0.567042, acc.: 72.66%] [G loss: 1.048275]\n",
      "epoch:13 step:12288 [D loss: 0.763893, acc.: 47.66%] [G loss: 0.865300]\n",
      "epoch:13 step:12289 [D loss: 0.695265, acc.: 56.25%] [G loss: 1.027999]\n",
      "epoch:13 step:12290 [D loss: 0.686097, acc.: 58.59%] [G loss: 0.936061]\n",
      "epoch:13 step:12291 [D loss: 0.578955, acc.: 70.31%] [G loss: 0.842591]\n",
      "epoch:13 step:12292 [D loss: 0.628370, acc.: 65.62%] [G loss: 1.071489]\n",
      "epoch:13 step:12293 [D loss: 0.685470, acc.: 57.81%] [G loss: 0.833131]\n",
      "epoch:13 step:12294 [D loss: 0.738425, acc.: 49.22%] [G loss: 0.905753]\n",
      "epoch:13 step:12295 [D loss: 0.696817, acc.: 57.81%] [G loss: 0.944374]\n",
      "epoch:13 step:12296 [D loss: 0.719359, acc.: 53.91%] [G loss: 1.004700]\n",
      "epoch:13 step:12297 [D loss: 0.735683, acc.: 54.69%] [G loss: 0.854455]\n",
      "epoch:13 step:12298 [D loss: 0.509202, acc.: 79.69%] [G loss: 1.312382]\n",
      "epoch:13 step:12299 [D loss: 0.671779, acc.: 53.12%] [G loss: 1.119735]\n",
      "epoch:13 step:12300 [D loss: 0.510793, acc.: 75.78%] [G loss: 1.149773]\n",
      "epoch:13 step:12301 [D loss: 0.775195, acc.: 47.66%] [G loss: 1.121507]\n",
      "epoch:13 step:12302 [D loss: 0.571840, acc.: 73.44%] [G loss: 1.085832]\n",
      "epoch:13 step:12303 [D loss: 0.537252, acc.: 76.56%] [G loss: 1.056755]\n",
      "epoch:13 step:12304 [D loss: 0.582626, acc.: 70.31%] [G loss: 1.122862]\n",
      "epoch:13 step:12305 [D loss: 0.584544, acc.: 75.00%] [G loss: 0.968846]\n",
      "epoch:13 step:12306 [D loss: 0.607030, acc.: 67.97%] [G loss: 1.001205]\n",
      "epoch:13 step:12307 [D loss: 0.575346, acc.: 71.09%] [G loss: 0.980151]\n",
      "epoch:13 step:12308 [D loss: 0.753767, acc.: 44.53%] [G loss: 0.944833]\n",
      "epoch:13 step:12309 [D loss: 0.608355, acc.: 66.41%] [G loss: 1.013460]\n",
      "epoch:13 step:12310 [D loss: 0.650417, acc.: 60.94%] [G loss: 0.896312]\n",
      "epoch:13 step:12311 [D loss: 0.514429, acc.: 80.47%] [G loss: 1.130605]\n",
      "epoch:13 step:12312 [D loss: 0.566577, acc.: 72.66%] [G loss: 0.954217]\n",
      "epoch:13 step:12313 [D loss: 0.465199, acc.: 89.84%] [G loss: 1.051269]\n",
      "epoch:13 step:12314 [D loss: 0.698652, acc.: 56.25%] [G loss: 1.048476]\n",
      "epoch:13 step:12315 [D loss: 0.744172, acc.: 51.56%] [G loss: 0.987889]\n",
      "epoch:13 step:12316 [D loss: 0.688704, acc.: 54.69%] [G loss: 0.899586]\n",
      "epoch:13 step:12317 [D loss: 0.716524, acc.: 54.69%] [G loss: 0.800862]\n",
      "epoch:13 step:12318 [D loss: 0.656545, acc.: 58.59%] [G loss: 0.774307]\n",
      "epoch:13 step:12319 [D loss: 0.654881, acc.: 57.81%] [G loss: 0.929713]\n",
      "epoch:13 step:12320 [D loss: 0.511543, acc.: 75.78%] [G loss: 1.024161]\n",
      "epoch:13 step:12321 [D loss: 0.709034, acc.: 52.34%] [G loss: 0.871907]\n",
      "epoch:13 step:12322 [D loss: 0.719273, acc.: 58.59%] [G loss: 0.939866]\n",
      "epoch:13 step:12323 [D loss: 0.570025, acc.: 71.88%] [G loss: 1.048657]\n",
      "epoch:13 step:12324 [D loss: 0.744343, acc.: 53.91%] [G loss: 1.042357]\n",
      "epoch:13 step:12325 [D loss: 0.595111, acc.: 70.31%] [G loss: 1.112387]\n",
      "epoch:13 step:12326 [D loss: 0.497136, acc.: 82.03%] [G loss: 1.244280]\n",
      "epoch:13 step:12327 [D loss: 0.551772, acc.: 75.00%] [G loss: 0.998849]\n",
      "epoch:13 step:12328 [D loss: 0.684272, acc.: 52.34%] [G loss: 0.872137]\n",
      "epoch:13 step:12329 [D loss: 0.780983, acc.: 48.44%] [G loss: 0.859357]\n",
      "epoch:13 step:12330 [D loss: 0.670784, acc.: 60.94%] [G loss: 0.868893]\n",
      "epoch:13 step:12331 [D loss: 0.458596, acc.: 85.94%] [G loss: 1.145126]\n",
      "epoch:13 step:12332 [D loss: 0.448184, acc.: 85.16%] [G loss: 1.182497]\n",
      "epoch:13 step:12333 [D loss: 0.532503, acc.: 75.78%] [G loss: 1.178308]\n",
      "epoch:13 step:12334 [D loss: 0.682604, acc.: 60.16%] [G loss: 1.169757]\n",
      "epoch:13 step:12335 [D loss: 0.597486, acc.: 67.97%] [G loss: 1.076669]\n",
      "epoch:13 step:12336 [D loss: 0.602967, acc.: 66.41%] [G loss: 1.197414]\n",
      "epoch:13 step:12337 [D loss: 0.730724, acc.: 50.78%] [G loss: 1.000536]\n",
      "epoch:13 step:12338 [D loss: 0.700603, acc.: 58.59%] [G loss: 1.013467]\n",
      "epoch:13 step:12339 [D loss: 0.620747, acc.: 64.06%] [G loss: 1.132735]\n",
      "epoch:13 step:12340 [D loss: 0.614428, acc.: 64.06%] [G loss: 0.975431]\n",
      "epoch:13 step:12341 [D loss: 0.713692, acc.: 60.16%] [G loss: 1.006080]\n",
      "epoch:13 step:12342 [D loss: 0.641160, acc.: 59.38%] [G loss: 0.861166]\n",
      "epoch:13 step:12343 [D loss: 0.624412, acc.: 67.19%] [G loss: 0.885318]\n",
      "epoch:13 step:12344 [D loss: 0.750170, acc.: 50.78%] [G loss: 1.004649]\n",
      "epoch:13 step:12345 [D loss: 0.679256, acc.: 58.59%] [G loss: 0.945099]\n",
      "epoch:13 step:12346 [D loss: 0.685805, acc.: 58.59%] [G loss: 0.871655]\n",
      "epoch:13 step:12347 [D loss: 0.585507, acc.: 71.88%] [G loss: 0.975227]\n",
      "epoch:13 step:12348 [D loss: 0.522921, acc.: 75.78%] [G loss: 1.205508]\n",
      "epoch:13 step:12349 [D loss: 0.484776, acc.: 85.16%] [G loss: 1.191591]\n",
      "epoch:13 step:12350 [D loss: 0.599517, acc.: 65.62%] [G loss: 0.953041]\n",
      "epoch:13 step:12351 [D loss: 0.584358, acc.: 75.78%] [G loss: 1.086262]\n",
      "epoch:13 step:12352 [D loss: 0.654778, acc.: 58.59%] [G loss: 0.979130]\n",
      "epoch:13 step:12353 [D loss: 0.628000, acc.: 64.06%] [G loss: 0.939069]\n",
      "epoch:13 step:12354 [D loss: 0.659053, acc.: 58.59%] [G loss: 0.919792]\n",
      "epoch:13 step:12355 [D loss: 0.614689, acc.: 69.53%] [G loss: 1.073170]\n",
      "epoch:13 step:12356 [D loss: 0.717705, acc.: 48.44%] [G loss: 1.104733]\n",
      "epoch:13 step:12357 [D loss: 0.590954, acc.: 71.88%] [G loss: 1.090263]\n",
      "epoch:13 step:12358 [D loss: 0.737545, acc.: 47.66%] [G loss: 1.040051]\n",
      "epoch:13 step:12359 [D loss: 0.664514, acc.: 56.25%] [G loss: 1.163712]\n",
      "epoch:13 step:12360 [D loss: 0.712863, acc.: 56.25%] [G loss: 1.031345]\n",
      "epoch:13 step:12361 [D loss: 0.616163, acc.: 64.84%] [G loss: 1.004211]\n",
      "epoch:13 step:12362 [D loss: 0.733840, acc.: 50.78%] [G loss: 0.883862]\n",
      "epoch:13 step:12363 [D loss: 0.677980, acc.: 56.25%] [G loss: 0.785824]\n",
      "epoch:13 step:12364 [D loss: 0.664333, acc.: 57.03%] [G loss: 1.060249]\n",
      "epoch:13 step:12365 [D loss: 0.635882, acc.: 65.62%] [G loss: 0.902080]\n",
      "epoch:13 step:12366 [D loss: 0.971199, acc.: 26.56%] [G loss: 0.714039]\n",
      "epoch:13 step:12367 [D loss: 0.751526, acc.: 45.31%] [G loss: 0.975632]\n",
      "epoch:13 step:12368 [D loss: 0.702449, acc.: 54.69%] [G loss: 1.135176]\n",
      "epoch:13 step:12369 [D loss: 0.588405, acc.: 72.66%] [G loss: 1.048467]\n",
      "epoch:13 step:12370 [D loss: 0.805254, acc.: 40.62%] [G loss: 0.837727]\n",
      "epoch:13 step:12371 [D loss: 0.793128, acc.: 45.31%] [G loss: 0.896085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12372 [D loss: 0.657373, acc.: 62.50%] [G loss: 1.016452]\n",
      "epoch:13 step:12373 [D loss: 0.605390, acc.: 66.41%] [G loss: 1.040945]\n",
      "epoch:13 step:12374 [D loss: 0.676714, acc.: 58.59%] [G loss: 0.982876]\n",
      "epoch:13 step:12375 [D loss: 0.616864, acc.: 64.84%] [G loss: 1.128482]\n",
      "epoch:13 step:12376 [D loss: 0.709818, acc.: 52.34%] [G loss: 0.887626]\n",
      "epoch:13 step:12377 [D loss: 0.695614, acc.: 48.44%] [G loss: 1.013735]\n",
      "epoch:13 step:12378 [D loss: 0.733610, acc.: 53.91%] [G loss: 1.096170]\n",
      "epoch:13 step:12379 [D loss: 0.574235, acc.: 70.31%] [G loss: 1.255258]\n",
      "epoch:13 step:12380 [D loss: 0.584766, acc.: 73.44%] [G loss: 1.105011]\n",
      "epoch:13 step:12381 [D loss: 0.585571, acc.: 71.09%] [G loss: 1.047380]\n",
      "epoch:13 step:12382 [D loss: 0.516647, acc.: 77.34%] [G loss: 1.192022]\n",
      "epoch:13 step:12383 [D loss: 0.621636, acc.: 67.97%] [G loss: 1.187959]\n",
      "epoch:13 step:12384 [D loss: 0.702780, acc.: 55.47%] [G loss: 0.983512]\n",
      "epoch:13 step:12385 [D loss: 0.789453, acc.: 47.66%] [G loss: 0.868124]\n",
      "epoch:13 step:12386 [D loss: 0.652597, acc.: 60.94%] [G loss: 0.806757]\n",
      "epoch:13 step:12387 [D loss: 0.646510, acc.: 62.50%] [G loss: 1.086364]\n",
      "epoch:13 step:12388 [D loss: 0.606015, acc.: 66.41%] [G loss: 0.963689]\n",
      "epoch:13 step:12389 [D loss: 0.582160, acc.: 71.09%] [G loss: 0.977638]\n",
      "epoch:13 step:12390 [D loss: 0.555320, acc.: 75.78%] [G loss: 1.020765]\n",
      "epoch:13 step:12391 [D loss: 0.599493, acc.: 70.31%] [G loss: 0.999769]\n",
      "epoch:13 step:12392 [D loss: 0.584843, acc.: 71.09%] [G loss: 0.983399]\n",
      "epoch:13 step:12393 [D loss: 0.688069, acc.: 55.47%] [G loss: 1.150982]\n",
      "epoch:13 step:12394 [D loss: 0.616881, acc.: 67.19%] [G loss: 0.956533]\n",
      "epoch:13 step:12395 [D loss: 0.694427, acc.: 53.91%] [G loss: 0.976537]\n",
      "epoch:13 step:12396 [D loss: 0.736242, acc.: 53.91%] [G loss: 0.683283]\n",
      "epoch:13 step:12397 [D loss: 0.603649, acc.: 71.09%] [G loss: 0.940356]\n",
      "epoch:13 step:12398 [D loss: 0.661134, acc.: 61.72%] [G loss: 1.025844]\n",
      "epoch:13 step:12399 [D loss: 0.581629, acc.: 70.31%] [G loss: 1.127509]\n",
      "epoch:13 step:12400 [D loss: 0.598746, acc.: 67.19%] [G loss: 1.132330]\n",
      "epoch:13 step:12401 [D loss: 0.407567, acc.: 89.84%] [G loss: 1.081265]\n",
      "epoch:13 step:12402 [D loss: 0.426066, acc.: 82.81%] [G loss: 1.194708]\n",
      "epoch:13 step:12403 [D loss: 0.566667, acc.: 71.09%] [G loss: 1.137524]\n",
      "epoch:13 step:12404 [D loss: 0.434368, acc.: 85.16%] [G loss: 1.138567]\n",
      "epoch:13 step:12405 [D loss: 0.767603, acc.: 54.69%] [G loss: 1.130340]\n",
      "epoch:13 step:12406 [D loss: 0.674194, acc.: 60.94%] [G loss: 1.010437]\n",
      "epoch:13 step:12407 [D loss: 0.595440, acc.: 69.53%] [G loss: 0.950114]\n",
      "epoch:13 step:12408 [D loss: 0.665608, acc.: 57.81%] [G loss: 0.908878]\n",
      "epoch:13 step:12409 [D loss: 0.762172, acc.: 46.09%] [G loss: 0.794856]\n",
      "epoch:13 step:12410 [D loss: 0.705210, acc.: 55.47%] [G loss: 0.996651]\n",
      "epoch:13 step:12411 [D loss: 0.418554, acc.: 86.72%] [G loss: 1.250631]\n",
      "epoch:13 step:12412 [D loss: 0.484957, acc.: 82.81%] [G loss: 1.261455]\n",
      "epoch:13 step:12413 [D loss: 0.509232, acc.: 81.25%] [G loss: 1.280597]\n",
      "epoch:13 step:12414 [D loss: 0.777426, acc.: 52.34%] [G loss: 1.212118]\n",
      "epoch:13 step:12415 [D loss: 0.739311, acc.: 51.56%] [G loss: 1.000281]\n",
      "epoch:13 step:12416 [D loss: 0.688977, acc.: 56.25%] [G loss: 1.067246]\n",
      "epoch:13 step:12417 [D loss: 0.686547, acc.: 57.03%] [G loss: 0.885695]\n",
      "epoch:13 step:12418 [D loss: 0.705828, acc.: 55.47%] [G loss: 0.848504]\n",
      "epoch:13 step:12419 [D loss: 0.697156, acc.: 53.91%] [G loss: 1.173019]\n",
      "epoch:13 step:12420 [D loss: 0.561844, acc.: 71.88%] [G loss: 1.073027]\n",
      "epoch:13 step:12421 [D loss: 0.728153, acc.: 50.78%] [G loss: 1.016100]\n",
      "epoch:13 step:12422 [D loss: 0.661760, acc.: 58.59%] [G loss: 1.030437]\n",
      "epoch:13 step:12423 [D loss: 0.649486, acc.: 58.59%] [G loss: 1.038796]\n",
      "epoch:13 step:12424 [D loss: 0.698248, acc.: 59.38%] [G loss: 0.857904]\n",
      "epoch:13 step:12425 [D loss: 0.520634, acc.: 75.78%] [G loss: 0.971412]\n",
      "epoch:13 step:12426 [D loss: 0.604921, acc.: 64.84%] [G loss: 0.883114]\n",
      "epoch:13 step:12427 [D loss: 0.550054, acc.: 69.53%] [G loss: 1.180180]\n",
      "epoch:13 step:12428 [D loss: 0.625833, acc.: 64.06%] [G loss: 1.020608]\n",
      "epoch:13 step:12429 [D loss: 0.559052, acc.: 70.31%] [G loss: 1.248302]\n",
      "epoch:13 step:12430 [D loss: 0.652444, acc.: 65.62%] [G loss: 1.027215]\n",
      "epoch:13 step:12431 [D loss: 0.543132, acc.: 72.66%] [G loss: 0.952229]\n",
      "epoch:13 step:12432 [D loss: 0.691301, acc.: 60.94%] [G loss: 0.994151]\n",
      "epoch:13 step:12433 [D loss: 0.671099, acc.: 56.25%] [G loss: 1.158833]\n",
      "epoch:13 step:12434 [D loss: 0.651543, acc.: 59.38%] [G loss: 0.920097]\n",
      "epoch:13 step:12435 [D loss: 0.660336, acc.: 63.28%] [G loss: 1.101827]\n",
      "epoch:13 step:12436 [D loss: 0.728485, acc.: 46.88%] [G loss: 0.981557]\n",
      "epoch:13 step:12437 [D loss: 0.700127, acc.: 57.03%] [G loss: 1.054363]\n",
      "epoch:13 step:12438 [D loss: 0.761338, acc.: 47.66%] [G loss: 0.707664]\n",
      "epoch:13 step:12439 [D loss: 0.683952, acc.: 57.03%] [G loss: 1.006023]\n",
      "epoch:13 step:12440 [D loss: 0.657383, acc.: 59.38%] [G loss: 0.903925]\n",
      "epoch:13 step:12441 [D loss: 0.660637, acc.: 60.94%] [G loss: 1.057488]\n",
      "epoch:13 step:12442 [D loss: 0.673478, acc.: 57.81%] [G loss: 0.912434]\n",
      "epoch:13 step:12443 [D loss: 0.633193, acc.: 63.28%] [G loss: 0.964999]\n",
      "epoch:13 step:12444 [D loss: 0.681573, acc.: 57.81%] [G loss: 0.982259]\n",
      "epoch:13 step:12445 [D loss: 0.598876, acc.: 67.97%] [G loss: 1.037078]\n",
      "epoch:13 step:12446 [D loss: 0.529085, acc.: 80.47%] [G loss: 1.111747]\n",
      "epoch:13 step:12447 [D loss: 0.763651, acc.: 49.22%] [G loss: 0.926574]\n",
      "epoch:13 step:12448 [D loss: 0.598393, acc.: 67.19%] [G loss: 0.938001]\n",
      "epoch:13 step:12449 [D loss: 0.630587, acc.: 65.62%] [G loss: 0.984657]\n",
      "epoch:13 step:12450 [D loss: 0.710532, acc.: 49.22%] [G loss: 0.867425]\n",
      "epoch:13 step:12451 [D loss: 0.780400, acc.: 46.88%] [G loss: 0.896322]\n",
      "epoch:13 step:12452 [D loss: 0.621536, acc.: 65.62%] [G loss: 1.051962]\n",
      "epoch:13 step:12453 [D loss: 0.557954, acc.: 73.44%] [G loss: 1.016655]\n",
      "epoch:13 step:12454 [D loss: 0.643163, acc.: 61.72%] [G loss: 0.988598]\n",
      "epoch:13 step:12455 [D loss: 0.715655, acc.: 48.44%] [G loss: 0.983392]\n",
      "epoch:13 step:12456 [D loss: 0.663069, acc.: 58.59%] [G loss: 0.946626]\n",
      "epoch:13 step:12457 [D loss: 0.757876, acc.: 46.88%] [G loss: 0.859534]\n",
      "epoch:13 step:12458 [D loss: 0.582131, acc.: 67.19%] [G loss: 1.175779]\n",
      "epoch:13 step:12459 [D loss: 0.583261, acc.: 67.19%] [G loss: 0.975947]\n",
      "epoch:13 step:12460 [D loss: 0.483477, acc.: 81.25%] [G loss: 1.083752]\n",
      "epoch:13 step:12461 [D loss: 0.509065, acc.: 78.12%] [G loss: 1.127408]\n",
      "epoch:13 step:12462 [D loss: 0.719362, acc.: 57.81%] [G loss: 0.972733]\n",
      "epoch:13 step:12463 [D loss: 0.691295, acc.: 54.69%] [G loss: 0.995478]\n",
      "epoch:13 step:12464 [D loss: 0.618181, acc.: 65.62%] [G loss: 0.947650]\n",
      "epoch:13 step:12465 [D loss: 0.591329, acc.: 70.31%] [G loss: 1.013198]\n",
      "epoch:13 step:12466 [D loss: 0.583377, acc.: 68.75%] [G loss: 0.900366]\n",
      "epoch:13 step:12467 [D loss: 0.502911, acc.: 81.25%] [G loss: 1.110935]\n",
      "epoch:13 step:12468 [D loss: 0.602629, acc.: 67.19%] [G loss: 1.059715]\n",
      "epoch:13 step:12469 [D loss: 0.635996, acc.: 67.97%] [G loss: 0.979280]\n",
      "epoch:13 step:12470 [D loss: 0.564103, acc.: 71.88%] [G loss: 1.141973]\n",
      "epoch:13 step:12471 [D loss: 0.733710, acc.: 57.81%] [G loss: 1.074328]\n",
      "epoch:13 step:12472 [D loss: 0.622640, acc.: 64.84%] [G loss: 1.002037]\n",
      "epoch:13 step:12473 [D loss: 0.647117, acc.: 60.94%] [G loss: 0.955147]\n",
      "epoch:13 step:12474 [D loss: 0.531204, acc.: 77.34%] [G loss: 1.268211]\n",
      "epoch:13 step:12475 [D loss: 0.690362, acc.: 57.03%] [G loss: 0.925794]\n",
      "epoch:13 step:12476 [D loss: 0.896311, acc.: 35.16%] [G loss: 0.819699]\n",
      "epoch:13 step:12477 [D loss: 0.686514, acc.: 60.16%] [G loss: 1.118963]\n",
      "epoch:13 step:12478 [D loss: 0.712083, acc.: 53.91%] [G loss: 1.134799]\n",
      "epoch:13 step:12479 [D loss: 0.594166, acc.: 68.75%] [G loss: 1.088213]\n",
      "epoch:13 step:12480 [D loss: 0.525453, acc.: 72.66%] [G loss: 1.207271]\n",
      "epoch:13 step:12481 [D loss: 0.592804, acc.: 70.31%] [G loss: 1.166252]\n",
      "epoch:13 step:12482 [D loss: 0.742805, acc.: 53.12%] [G loss: 0.831615]\n",
      "epoch:13 step:12483 [D loss: 0.600397, acc.: 70.31%] [G loss: 1.096271]\n",
      "epoch:13 step:12484 [D loss: 0.710082, acc.: 57.81%] [G loss: 0.874707]\n",
      "epoch:13 step:12485 [D loss: 0.630233, acc.: 64.84%] [G loss: 0.951875]\n",
      "epoch:13 step:12486 [D loss: 0.578754, acc.: 75.00%] [G loss: 1.113042]\n",
      "epoch:13 step:12487 [D loss: 0.649228, acc.: 63.28%] [G loss: 0.930153]\n",
      "epoch:13 step:12488 [D loss: 0.579219, acc.: 68.75%] [G loss: 1.198424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12489 [D loss: 0.683473, acc.: 59.38%] [G loss: 0.900310]\n",
      "epoch:13 step:12490 [D loss: 0.715404, acc.: 50.00%] [G loss: 0.897469]\n",
      "epoch:13 step:12491 [D loss: 0.667437, acc.: 61.72%] [G loss: 0.838523]\n",
      "epoch:13 step:12492 [D loss: 0.635449, acc.: 59.38%] [G loss: 0.974432]\n",
      "epoch:13 step:12493 [D loss: 0.675950, acc.: 60.16%] [G loss: 0.983057]\n",
      "epoch:13 step:12494 [D loss: 0.532676, acc.: 77.34%] [G loss: 1.093200]\n",
      "epoch:13 step:12495 [D loss: 0.488365, acc.: 83.59%] [G loss: 1.322968]\n",
      "epoch:13 step:12496 [D loss: 0.498485, acc.: 79.69%] [G loss: 1.033295]\n",
      "epoch:13 step:12497 [D loss: 0.688894, acc.: 59.38%] [G loss: 1.051010]\n",
      "epoch:13 step:12498 [D loss: 0.752936, acc.: 43.75%] [G loss: 1.026018]\n",
      "epoch:13 step:12499 [D loss: 0.562221, acc.: 75.78%] [G loss: 1.093048]\n",
      "epoch:13 step:12500 [D loss: 0.737911, acc.: 49.22%] [G loss: 0.973287]\n",
      "epoch:13 step:12501 [D loss: 0.574690, acc.: 74.22%] [G loss: 1.031117]\n",
      "epoch:13 step:12502 [D loss: 0.548381, acc.: 74.22%] [G loss: 0.911712]\n",
      "epoch:13 step:12503 [D loss: 0.565399, acc.: 71.09%] [G loss: 1.060206]\n",
      "epoch:13 step:12504 [D loss: 0.676434, acc.: 58.59%] [G loss: 0.991024]\n",
      "epoch:13 step:12505 [D loss: 0.707771, acc.: 60.16%] [G loss: 0.850905]\n",
      "epoch:13 step:12506 [D loss: 0.700615, acc.: 54.69%] [G loss: 0.925555]\n",
      "epoch:13 step:12507 [D loss: 0.645334, acc.: 62.50%] [G loss: 0.941073]\n",
      "epoch:13 step:12508 [D loss: 0.506020, acc.: 81.25%] [G loss: 1.030297]\n",
      "epoch:13 step:12509 [D loss: 0.631374, acc.: 64.84%] [G loss: 1.161060]\n",
      "epoch:13 step:12510 [D loss: 0.729788, acc.: 50.00%] [G loss: 0.936993]\n",
      "epoch:13 step:12511 [D loss: 0.681175, acc.: 53.12%] [G loss: 1.179346]\n",
      "epoch:13 step:12512 [D loss: 0.672440, acc.: 55.47%] [G loss: 1.037454]\n",
      "epoch:13 step:12513 [D loss: 0.616040, acc.: 70.31%] [G loss: 1.122773]\n",
      "epoch:13 step:12514 [D loss: 0.635110, acc.: 62.50%] [G loss: 1.184106]\n",
      "epoch:13 step:12515 [D loss: 0.609533, acc.: 66.41%] [G loss: 1.017454]\n",
      "epoch:13 step:12516 [D loss: 0.582938, acc.: 73.44%] [G loss: 1.050044]\n",
      "epoch:13 step:12517 [D loss: 0.572282, acc.: 75.78%] [G loss: 1.142909]\n",
      "epoch:13 step:12518 [D loss: 0.566863, acc.: 74.22%] [G loss: 0.965961]\n",
      "epoch:13 step:12519 [D loss: 0.548788, acc.: 71.88%] [G loss: 1.075528]\n",
      "epoch:13 step:12520 [D loss: 0.667079, acc.: 59.38%] [G loss: 1.039225]\n",
      "epoch:13 step:12521 [D loss: 0.708817, acc.: 54.69%] [G loss: 1.039118]\n",
      "epoch:13 step:12522 [D loss: 0.608075, acc.: 61.72%] [G loss: 1.105429]\n",
      "epoch:13 step:12523 [D loss: 0.512170, acc.: 78.12%] [G loss: 1.276001]\n",
      "epoch:13 step:12524 [D loss: 0.569329, acc.: 71.88%] [G loss: 1.067038]\n",
      "epoch:13 step:12525 [D loss: 0.458183, acc.: 82.03%] [G loss: 1.371188]\n",
      "epoch:13 step:12526 [D loss: 0.441075, acc.: 83.59%] [G loss: 1.337666]\n",
      "epoch:13 step:12527 [D loss: 0.437369, acc.: 84.38%] [G loss: 1.245376]\n",
      "epoch:13 step:12528 [D loss: 0.433863, acc.: 82.81%] [G loss: 1.169883]\n",
      "epoch:13 step:12529 [D loss: 0.699965, acc.: 58.59%] [G loss: 1.152105]\n",
      "epoch:13 step:12530 [D loss: 0.806018, acc.: 50.00%] [G loss: 1.060201]\n",
      "epoch:13 step:12531 [D loss: 0.651681, acc.: 60.94%] [G loss: 1.022008]\n",
      "epoch:13 step:12532 [D loss: 0.707100, acc.: 53.91%] [G loss: 0.912067]\n",
      "epoch:13 step:12533 [D loss: 0.627342, acc.: 64.84%] [G loss: 1.038240]\n",
      "epoch:13 step:12534 [D loss: 0.613926, acc.: 67.19%] [G loss: 0.907336]\n",
      "epoch:13 step:12535 [D loss: 0.585794, acc.: 66.41%] [G loss: 0.902744]\n",
      "epoch:13 step:12536 [D loss: 0.572680, acc.: 75.00%] [G loss: 1.085950]\n",
      "epoch:13 step:12537 [D loss: 0.596619, acc.: 65.62%] [G loss: 0.989910]\n",
      "epoch:13 step:12538 [D loss: 0.557463, acc.: 75.00%] [G loss: 0.994171]\n",
      "epoch:13 step:12539 [D loss: 0.529244, acc.: 73.44%] [G loss: 1.027459]\n",
      "epoch:13 step:12540 [D loss: 0.510022, acc.: 75.78%] [G loss: 1.130085]\n",
      "epoch:13 step:12541 [D loss: 0.552209, acc.: 72.66%] [G loss: 1.165153]\n",
      "epoch:13 step:12542 [D loss: 0.642789, acc.: 62.50%] [G loss: 0.967633]\n",
      "epoch:13 step:12543 [D loss: 0.759116, acc.: 50.00%] [G loss: 1.003750]\n",
      "epoch:13 step:12544 [D loss: 0.716386, acc.: 51.56%] [G loss: 0.860705]\n",
      "epoch:13 step:12545 [D loss: 0.693339, acc.: 56.25%] [G loss: 0.882866]\n",
      "epoch:13 step:12546 [D loss: 0.715538, acc.: 50.00%] [G loss: 0.921289]\n",
      "epoch:13 step:12547 [D loss: 0.609725, acc.: 65.62%] [G loss: 1.051655]\n",
      "epoch:13 step:12548 [D loss: 0.636932, acc.: 64.06%] [G loss: 1.103777]\n",
      "epoch:13 step:12549 [D loss: 0.739489, acc.: 48.44%] [G loss: 1.037491]\n",
      "epoch:13 step:12550 [D loss: 0.588616, acc.: 70.31%] [G loss: 1.124073]\n",
      "epoch:13 step:12551 [D loss: 0.626764, acc.: 60.16%] [G loss: 1.071737]\n",
      "epoch:13 step:12552 [D loss: 0.539496, acc.: 74.22%] [G loss: 1.190857]\n",
      "epoch:13 step:12553 [D loss: 0.633226, acc.: 60.16%] [G loss: 1.145138]\n",
      "epoch:13 step:12554 [D loss: 0.825733, acc.: 41.41%] [G loss: 0.934648]\n",
      "epoch:13 step:12555 [D loss: 0.667434, acc.: 53.12%] [G loss: 0.887671]\n",
      "epoch:13 step:12556 [D loss: 0.726601, acc.: 52.34%] [G loss: 0.794455]\n",
      "epoch:13 step:12557 [D loss: 0.833683, acc.: 35.94%] [G loss: 0.948637]\n",
      "epoch:13 step:12558 [D loss: 0.741767, acc.: 53.12%] [G loss: 0.893868]\n",
      "epoch:13 step:12559 [D loss: 0.600118, acc.: 64.06%] [G loss: 1.019730]\n",
      "epoch:13 step:12560 [D loss: 0.667251, acc.: 60.16%] [G loss: 1.078375]\n",
      "epoch:13 step:12561 [D loss: 0.588003, acc.: 67.97%] [G loss: 1.044125]\n",
      "epoch:13 step:12562 [D loss: 0.553146, acc.: 72.66%] [G loss: 1.060664]\n",
      "epoch:13 step:12563 [D loss: 0.666717, acc.: 58.59%] [G loss: 1.207434]\n",
      "epoch:13 step:12564 [D loss: 0.571141, acc.: 70.31%] [G loss: 1.328535]\n",
      "epoch:13 step:12565 [D loss: 0.627481, acc.: 63.28%] [G loss: 1.082422]\n",
      "epoch:13 step:12566 [D loss: 0.572940, acc.: 69.53%] [G loss: 0.977958]\n",
      "epoch:13 step:12567 [D loss: 0.702919, acc.: 59.38%] [G loss: 0.931321]\n",
      "epoch:13 step:12568 [D loss: 0.692240, acc.: 55.47%] [G loss: 0.933645]\n",
      "epoch:13 step:12569 [D loss: 0.610036, acc.: 63.28%] [G loss: 1.005689]\n",
      "epoch:13 step:12570 [D loss: 0.686641, acc.: 59.38%] [G loss: 1.001142]\n",
      "epoch:13 step:12571 [D loss: 0.582573, acc.: 68.75%] [G loss: 0.996450]\n",
      "epoch:13 step:12572 [D loss: 0.563101, acc.: 70.31%] [G loss: 1.100608]\n",
      "epoch:13 step:12573 [D loss: 0.599486, acc.: 71.09%] [G loss: 1.026041]\n",
      "epoch:13 step:12574 [D loss: 0.701125, acc.: 55.47%] [G loss: 1.046525]\n",
      "epoch:13 step:12575 [D loss: 0.658385, acc.: 60.16%] [G loss: 0.930846]\n",
      "epoch:13 step:12576 [D loss: 0.659633, acc.: 57.81%] [G loss: 0.955367]\n",
      "epoch:13 step:12577 [D loss: 0.544936, acc.: 75.78%] [G loss: 0.985582]\n",
      "epoch:13 step:12578 [D loss: 0.462329, acc.: 82.03%] [G loss: 1.245589]\n",
      "epoch:13 step:12579 [D loss: 0.481207, acc.: 83.59%] [G loss: 1.106818]\n",
      "epoch:13 step:12580 [D loss: 0.514763, acc.: 77.34%] [G loss: 1.315037]\n",
      "epoch:13 step:12581 [D loss: 0.523882, acc.: 77.34%] [G loss: 1.319771]\n",
      "epoch:13 step:12582 [D loss: 0.544052, acc.: 73.44%] [G loss: 1.145743]\n",
      "epoch:13 step:12583 [D loss: 0.613788, acc.: 63.28%] [G loss: 1.212954]\n",
      "epoch:13 step:12584 [D loss: 0.630942, acc.: 61.72%] [G loss: 1.145269]\n",
      "epoch:13 step:12585 [D loss: 0.577587, acc.: 72.66%] [G loss: 1.262297]\n",
      "epoch:13 step:12586 [D loss: 0.388454, acc.: 86.72%] [G loss: 1.411744]\n",
      "epoch:13 step:12587 [D loss: 0.481849, acc.: 82.81%] [G loss: 1.213953]\n",
      "epoch:13 step:12588 [D loss: 0.587490, acc.: 67.97%] [G loss: 1.241361]\n",
      "epoch:13 step:12589 [D loss: 0.644435, acc.: 64.06%] [G loss: 1.125607]\n",
      "epoch:13 step:12590 [D loss: 0.608628, acc.: 64.06%] [G loss: 1.124792]\n",
      "epoch:13 step:12591 [D loss: 0.673144, acc.: 61.72%] [G loss: 0.980354]\n",
      "epoch:13 step:12592 [D loss: 0.771746, acc.: 48.44%] [G loss: 0.931304]\n",
      "epoch:13 step:12593 [D loss: 0.691692, acc.: 54.69%] [G loss: 0.951565]\n",
      "epoch:13 step:12594 [D loss: 0.903907, acc.: 39.84%] [G loss: 0.819560]\n",
      "epoch:13 step:12595 [D loss: 0.724914, acc.: 50.00%] [G loss: 1.054532]\n",
      "epoch:13 step:12596 [D loss: 0.873002, acc.: 42.19%] [G loss: 0.897015]\n",
      "epoch:13 step:12597 [D loss: 0.819859, acc.: 48.44%] [G loss: 0.688884]\n",
      "epoch:13 step:12598 [D loss: 0.780724, acc.: 50.00%] [G loss: 1.007300]\n",
      "epoch:13 step:12599 [D loss: 0.607357, acc.: 68.75%] [G loss: 1.120546]\n",
      "epoch:13 step:12600 [D loss: 0.606170, acc.: 67.19%] [G loss: 1.043987]\n",
      "epoch:13 step:12601 [D loss: 0.604141, acc.: 65.62%] [G loss: 1.212348]\n",
      "epoch:13 step:12602 [D loss: 0.910420, acc.: 33.59%] [G loss: 0.734793]\n",
      "epoch:13 step:12603 [D loss: 0.852552, acc.: 41.41%] [G loss: 0.942338]\n",
      "epoch:13 step:12604 [D loss: 0.720513, acc.: 53.12%] [G loss: 1.087742]\n",
      "epoch:13 step:12605 [D loss: 0.564804, acc.: 67.97%] [G loss: 1.084035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12606 [D loss: 0.711869, acc.: 55.47%] [G loss: 0.945533]\n",
      "epoch:13 step:12607 [D loss: 0.634354, acc.: 61.72%] [G loss: 0.909045]\n",
      "epoch:13 step:12608 [D loss: 0.700273, acc.: 57.03%] [G loss: 0.924530]\n",
      "epoch:13 step:12609 [D loss: 0.626609, acc.: 63.28%] [G loss: 0.992696]\n",
      "epoch:13 step:12610 [D loss: 0.569914, acc.: 71.09%] [G loss: 1.088158]\n",
      "epoch:13 step:12611 [D loss: 0.692525, acc.: 60.16%] [G loss: 1.097096]\n",
      "epoch:13 step:12612 [D loss: 0.689436, acc.: 59.38%] [G loss: 1.245998]\n",
      "epoch:13 step:12613 [D loss: 0.772871, acc.: 50.78%] [G loss: 1.192343]\n",
      "epoch:13 step:12614 [D loss: 0.729785, acc.: 47.66%] [G loss: 0.949940]\n",
      "epoch:13 step:12615 [D loss: 0.643439, acc.: 64.06%] [G loss: 1.246116]\n",
      "epoch:13 step:12616 [D loss: 0.565198, acc.: 75.00%] [G loss: 1.088196]\n",
      "epoch:13 step:12617 [D loss: 0.470698, acc.: 85.16%] [G loss: 1.086331]\n",
      "epoch:13 step:12618 [D loss: 0.645281, acc.: 63.28%] [G loss: 1.111629]\n",
      "epoch:13 step:12619 [D loss: 0.589369, acc.: 66.41%] [G loss: 0.950338]\n",
      "epoch:13 step:12620 [D loss: 0.598898, acc.: 66.41%] [G loss: 0.972885]\n",
      "epoch:13 step:12621 [D loss: 0.556244, acc.: 71.09%] [G loss: 1.029355]\n",
      "epoch:13 step:12622 [D loss: 0.596419, acc.: 62.50%] [G loss: 1.105492]\n",
      "epoch:13 step:12623 [D loss: 0.712616, acc.: 64.84%] [G loss: 0.990529]\n",
      "epoch:13 step:12624 [D loss: 0.556728, acc.: 70.31%] [G loss: 0.949731]\n",
      "epoch:13 step:12625 [D loss: 0.664683, acc.: 60.16%] [G loss: 0.732458]\n",
      "epoch:13 step:12626 [D loss: 0.604004, acc.: 69.53%] [G loss: 1.116702]\n",
      "epoch:13 step:12627 [D loss: 0.672815, acc.: 57.03%] [G loss: 1.093943]\n",
      "epoch:13 step:12628 [D loss: 0.532442, acc.: 78.12%] [G loss: 1.126545]\n",
      "epoch:13 step:12629 [D loss: 0.503499, acc.: 78.12%] [G loss: 1.123968]\n",
      "epoch:13 step:12630 [D loss: 0.417677, acc.: 87.50%] [G loss: 1.217152]\n",
      "epoch:13 step:12631 [D loss: 0.532592, acc.: 79.69%] [G loss: 1.199245]\n",
      "epoch:13 step:12632 [D loss: 0.549059, acc.: 71.88%] [G loss: 1.111031]\n",
      "epoch:13 step:12633 [D loss: 0.564285, acc.: 70.31%] [G loss: 1.003695]\n",
      "epoch:13 step:12634 [D loss: 0.437477, acc.: 87.50%] [G loss: 1.453549]\n",
      "epoch:13 step:12635 [D loss: 0.550330, acc.: 76.56%] [G loss: 1.397440]\n",
      "epoch:13 step:12636 [D loss: 0.648089, acc.: 59.38%] [G loss: 1.080398]\n",
      "epoch:13 step:12637 [D loss: 0.499773, acc.: 80.47%] [G loss: 1.118559]\n",
      "epoch:13 step:12638 [D loss: 0.502926, acc.: 80.47%] [G loss: 1.171255]\n",
      "epoch:13 step:12639 [D loss: 0.873059, acc.: 43.75%] [G loss: 0.915497]\n",
      "epoch:13 step:12640 [D loss: 0.753824, acc.: 55.47%] [G loss: 1.022078]\n",
      "epoch:13 step:12641 [D loss: 0.885997, acc.: 35.16%] [G loss: 0.936887]\n",
      "epoch:13 step:12642 [D loss: 0.918875, acc.: 28.91%] [G loss: 0.790019]\n",
      "epoch:13 step:12643 [D loss: 0.870928, acc.: 38.28%] [G loss: 0.981877]\n",
      "epoch:13 step:12644 [D loss: 0.773095, acc.: 47.66%] [G loss: 1.066546]\n",
      "epoch:13 step:12645 [D loss: 0.656102, acc.: 62.50%] [G loss: 1.053811]\n",
      "epoch:13 step:12646 [D loss: 0.633103, acc.: 66.41%] [G loss: 1.002230]\n",
      "epoch:13 step:12647 [D loss: 0.789782, acc.: 47.66%] [G loss: 0.910167]\n",
      "epoch:13 step:12648 [D loss: 0.679407, acc.: 60.16%] [G loss: 1.209298]\n",
      "epoch:13 step:12649 [D loss: 0.571868, acc.: 72.66%] [G loss: 1.123758]\n",
      "epoch:13 step:12650 [D loss: 0.574417, acc.: 72.66%] [G loss: 1.008247]\n",
      "epoch:13 step:12651 [D loss: 0.583701, acc.: 66.41%] [G loss: 1.116042]\n",
      "epoch:13 step:12652 [D loss: 0.499212, acc.: 73.44%] [G loss: 1.086585]\n",
      "epoch:13 step:12653 [D loss: 0.605502, acc.: 66.41%] [G loss: 1.100481]\n",
      "epoch:13 step:12654 [D loss: 0.731568, acc.: 50.78%] [G loss: 1.230091]\n",
      "epoch:13 step:12655 [D loss: 0.624301, acc.: 64.84%] [G loss: 1.297288]\n",
      "epoch:13 step:12656 [D loss: 0.620085, acc.: 68.75%] [G loss: 1.121582]\n",
      "epoch:13 step:12657 [D loss: 0.679982, acc.: 58.59%] [G loss: 1.197017]\n",
      "epoch:13 step:12658 [D loss: 0.718076, acc.: 57.81%] [G loss: 1.139302]\n",
      "epoch:13 step:12659 [D loss: 0.618814, acc.: 64.84%] [G loss: 1.010624]\n",
      "epoch:13 step:12660 [D loss: 0.691291, acc.: 56.25%] [G loss: 1.020557]\n",
      "epoch:13 step:12661 [D loss: 0.653680, acc.: 65.62%] [G loss: 0.960736]\n",
      "epoch:13 step:12662 [D loss: 0.601518, acc.: 64.84%] [G loss: 0.878978]\n",
      "epoch:13 step:12663 [D loss: 0.557884, acc.: 75.78%] [G loss: 0.929288]\n",
      "epoch:13 step:12664 [D loss: 0.624961, acc.: 64.84%] [G loss: 0.961940]\n",
      "epoch:13 step:12665 [D loss: 0.507178, acc.: 78.91%] [G loss: 1.227084]\n",
      "epoch:13 step:12666 [D loss: 0.488567, acc.: 75.78%] [G loss: 1.134019]\n",
      "epoch:13 step:12667 [D loss: 0.615996, acc.: 67.19%] [G loss: 1.119408]\n",
      "epoch:13 step:12668 [D loss: 0.496885, acc.: 77.34%] [G loss: 1.177363]\n",
      "epoch:13 step:12669 [D loss: 0.505728, acc.: 74.22%] [G loss: 1.282504]\n",
      "epoch:13 step:12670 [D loss: 0.737047, acc.: 59.38%] [G loss: 1.139394]\n",
      "epoch:13 step:12671 [D loss: 0.732358, acc.: 53.12%] [G loss: 0.821421]\n",
      "epoch:13 step:12672 [D loss: 0.643984, acc.: 59.38%] [G loss: 0.956758]\n",
      "epoch:13 step:12673 [D loss: 0.605204, acc.: 65.62%] [G loss: 0.958395]\n",
      "epoch:13 step:12674 [D loss: 0.579302, acc.: 75.78%] [G loss: 0.960143]\n",
      "epoch:13 step:12675 [D loss: 0.649911, acc.: 62.50%] [G loss: 0.933208]\n",
      "epoch:13 step:12676 [D loss: 0.551548, acc.: 74.22%] [G loss: 1.029284]\n",
      "epoch:13 step:12677 [D loss: 0.577433, acc.: 71.88%] [G loss: 1.042880]\n",
      "epoch:13 step:12678 [D loss: 0.509398, acc.: 72.66%] [G loss: 1.051096]\n",
      "epoch:13 step:12679 [D loss: 0.545088, acc.: 76.56%] [G loss: 1.139422]\n",
      "epoch:13 step:12680 [D loss: 0.334011, acc.: 93.75%] [G loss: 1.377588]\n",
      "epoch:13 step:12681 [D loss: 0.725538, acc.: 54.69%] [G loss: 1.120143]\n",
      "epoch:13 step:12682 [D loss: 0.639089, acc.: 62.50%] [G loss: 1.096211]\n",
      "epoch:13 step:12683 [D loss: 0.684936, acc.: 60.16%] [G loss: 0.865972]\n",
      "epoch:13 step:12684 [D loss: 0.594728, acc.: 67.19%] [G loss: 1.063481]\n",
      "epoch:13 step:12685 [D loss: 0.580564, acc.: 70.31%] [G loss: 1.156546]\n",
      "epoch:13 step:12686 [D loss: 0.636470, acc.: 60.16%] [G loss: 1.242583]\n",
      "epoch:13 step:12687 [D loss: 0.650395, acc.: 66.41%] [G loss: 1.153484]\n",
      "epoch:13 step:12688 [D loss: 0.589555, acc.: 70.31%] [G loss: 1.006612]\n",
      "epoch:13 step:12689 [D loss: 0.497325, acc.: 81.25%] [G loss: 1.030296]\n",
      "epoch:13 step:12690 [D loss: 0.710642, acc.: 56.25%] [G loss: 1.208518]\n",
      "epoch:13 step:12691 [D loss: 0.650164, acc.: 62.50%] [G loss: 0.920171]\n",
      "epoch:13 step:12692 [D loss: 0.661701, acc.: 56.25%] [G loss: 0.947220]\n",
      "epoch:13 step:12693 [D loss: 0.709277, acc.: 48.44%] [G loss: 0.932763]\n",
      "epoch:13 step:12694 [D loss: 0.599548, acc.: 67.19%] [G loss: 0.960787]\n",
      "epoch:13 step:12695 [D loss: 0.470676, acc.: 82.81%] [G loss: 1.081841]\n",
      "epoch:13 step:12696 [D loss: 0.598201, acc.: 67.19%] [G loss: 1.155879]\n",
      "epoch:13 step:12697 [D loss: 0.642138, acc.: 65.62%] [G loss: 1.013228]\n",
      "epoch:13 step:12698 [D loss: 0.615388, acc.: 65.62%] [G loss: 0.844951]\n",
      "epoch:13 step:12699 [D loss: 0.655040, acc.: 60.94%] [G loss: 1.086399]\n",
      "epoch:13 step:12700 [D loss: 0.499019, acc.: 78.12%] [G loss: 1.096491]\n",
      "epoch:13 step:12701 [D loss: 0.606288, acc.: 64.06%] [G loss: 0.805718]\n",
      "epoch:13 step:12702 [D loss: 0.504799, acc.: 78.91%] [G loss: 1.253097]\n",
      "epoch:13 step:12703 [D loss: 0.547486, acc.: 72.66%] [G loss: 1.098310]\n",
      "epoch:13 step:12704 [D loss: 0.569400, acc.: 73.44%] [G loss: 1.061634]\n",
      "epoch:13 step:12705 [D loss: 0.668483, acc.: 59.38%] [G loss: 1.124118]\n",
      "epoch:13 step:12706 [D loss: 0.682306, acc.: 57.03%] [G loss: 1.046483]\n",
      "epoch:13 step:12707 [D loss: 0.705124, acc.: 50.78%] [G loss: 0.992647]\n",
      "epoch:13 step:12708 [D loss: 0.701591, acc.: 55.47%] [G loss: 0.915329]\n",
      "epoch:13 step:12709 [D loss: 0.694041, acc.: 55.47%] [G loss: 0.990281]\n",
      "epoch:13 step:12710 [D loss: 0.646668, acc.: 62.50%] [G loss: 0.958778]\n",
      "epoch:13 step:12711 [D loss: 0.628271, acc.: 67.97%] [G loss: 0.905808]\n",
      "epoch:13 step:12712 [D loss: 0.664283, acc.: 61.72%] [G loss: 0.993816]\n",
      "epoch:13 step:12713 [D loss: 0.603804, acc.: 69.53%] [G loss: 0.954935]\n",
      "epoch:13 step:12714 [D loss: 0.495906, acc.: 78.91%] [G loss: 1.048659]\n",
      "epoch:13 step:12715 [D loss: 0.602334, acc.: 66.41%] [G loss: 0.977118]\n",
      "epoch:13 step:12716 [D loss: 0.619923, acc.: 66.41%] [G loss: 1.028016]\n",
      "epoch:13 step:12717 [D loss: 0.524086, acc.: 75.00%] [G loss: 1.014369]\n",
      "epoch:13 step:12718 [D loss: 0.499024, acc.: 86.72%] [G loss: 1.197395]\n",
      "epoch:13 step:12719 [D loss: 0.626716, acc.: 66.41%] [G loss: 0.956585]\n",
      "epoch:13 step:12720 [D loss: 0.696530, acc.: 54.69%] [G loss: 0.828835]\n",
      "epoch:13 step:12721 [D loss: 0.787915, acc.: 45.31%] [G loss: 0.981626]\n",
      "epoch:13 step:12722 [D loss: 0.596717, acc.: 69.53%] [G loss: 0.973403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12723 [D loss: 0.709571, acc.: 55.47%] [G loss: 1.207840]\n",
      "epoch:13 step:12724 [D loss: 0.642025, acc.: 58.59%] [G loss: 0.961574]\n",
      "epoch:13 step:12725 [D loss: 0.652538, acc.: 60.94%] [G loss: 1.001794]\n",
      "epoch:13 step:12726 [D loss: 0.535807, acc.: 76.56%] [G loss: 1.063369]\n",
      "epoch:13 step:12727 [D loss: 0.597436, acc.: 68.75%] [G loss: 1.040177]\n",
      "epoch:13 step:12728 [D loss: 0.505213, acc.: 75.00%] [G loss: 1.030343]\n",
      "epoch:13 step:12729 [D loss: 0.616882, acc.: 64.84%] [G loss: 1.093032]\n",
      "epoch:13 step:12730 [D loss: 0.434092, acc.: 85.94%] [G loss: 1.183588]\n",
      "epoch:13 step:12731 [D loss: 0.504935, acc.: 75.00%] [G loss: 1.240270]\n",
      "epoch:13 step:12732 [D loss: 0.443743, acc.: 82.81%] [G loss: 1.183346]\n",
      "epoch:13 step:12733 [D loss: 0.482658, acc.: 81.25%] [G loss: 1.240016]\n",
      "epoch:13 step:12734 [D loss: 0.547189, acc.: 74.22%] [G loss: 1.125596]\n",
      "epoch:13 step:12735 [D loss: 0.482060, acc.: 78.91%] [G loss: 1.185941]\n",
      "epoch:13 step:12736 [D loss: 0.490536, acc.: 82.03%] [G loss: 1.220871]\n",
      "epoch:13 step:12737 [D loss: 0.518914, acc.: 75.00%] [G loss: 1.165500]\n",
      "epoch:13 step:12738 [D loss: 0.491581, acc.: 77.34%] [G loss: 1.171533]\n",
      "epoch:13 step:12739 [D loss: 0.574610, acc.: 71.09%] [G loss: 1.248827]\n",
      "epoch:13 step:12740 [D loss: 0.775938, acc.: 53.91%] [G loss: 1.189564]\n",
      "epoch:13 step:12741 [D loss: 0.863196, acc.: 36.72%] [G loss: 0.995874]\n",
      "epoch:13 step:12742 [D loss: 0.586410, acc.: 71.88%] [G loss: 1.146352]\n",
      "epoch:13 step:12743 [D loss: 0.695786, acc.: 59.38%] [G loss: 1.144822]\n",
      "epoch:13 step:12744 [D loss: 0.719334, acc.: 52.34%] [G loss: 1.120569]\n",
      "epoch:13 step:12745 [D loss: 0.609105, acc.: 69.53%] [G loss: 1.175785]\n",
      "epoch:13 step:12746 [D loss: 0.537859, acc.: 75.78%] [G loss: 1.263752]\n",
      "epoch:13 step:12747 [D loss: 0.475777, acc.: 80.47%] [G loss: 1.200548]\n",
      "epoch:13 step:12748 [D loss: 0.446467, acc.: 85.16%] [G loss: 1.313678]\n",
      "epoch:13 step:12749 [D loss: 0.640399, acc.: 60.94%] [G loss: 1.000933]\n",
      "epoch:13 step:12750 [D loss: 0.638066, acc.: 64.84%] [G loss: 1.181194]\n",
      "epoch:13 step:12751 [D loss: 0.645716, acc.: 61.72%] [G loss: 0.975341]\n",
      "epoch:13 step:12752 [D loss: 0.689823, acc.: 54.69%] [G loss: 0.929963]\n",
      "epoch:13 step:12753 [D loss: 0.718054, acc.: 56.25%] [G loss: 0.948821]\n",
      "epoch:13 step:12754 [D loss: 0.578390, acc.: 73.44%] [G loss: 0.912221]\n",
      "epoch:13 step:12755 [D loss: 0.658640, acc.: 60.94%] [G loss: 0.913965]\n",
      "epoch:13 step:12756 [D loss: 0.611836, acc.: 65.62%] [G loss: 0.981189]\n",
      "epoch:13 step:12757 [D loss: 0.617502, acc.: 68.75%] [G loss: 0.988962]\n",
      "epoch:13 step:12758 [D loss: 0.597309, acc.: 66.41%] [G loss: 0.917343]\n",
      "epoch:13 step:12759 [D loss: 0.632396, acc.: 64.06%] [G loss: 0.826893]\n",
      "epoch:13 step:12760 [D loss: 0.748216, acc.: 50.00%] [G loss: 0.921232]\n",
      "epoch:13 step:12761 [D loss: 0.751413, acc.: 48.44%] [G loss: 0.872338]\n",
      "epoch:13 step:12762 [D loss: 0.618008, acc.: 64.84%] [G loss: 1.091560]\n",
      "epoch:13 step:12763 [D loss: 0.691656, acc.: 54.69%] [G loss: 0.943231]\n",
      "epoch:13 step:12764 [D loss: 0.673636, acc.: 57.03%] [G loss: 0.860770]\n",
      "epoch:13 step:12765 [D loss: 0.796762, acc.: 41.41%] [G loss: 0.816490]\n",
      "epoch:13 step:12766 [D loss: 0.660751, acc.: 61.72%] [G loss: 0.897064]\n",
      "epoch:13 step:12767 [D loss: 0.612060, acc.: 64.06%] [G loss: 1.038976]\n",
      "epoch:13 step:12768 [D loss: 0.577624, acc.: 66.41%] [G loss: 1.149807]\n",
      "epoch:13 step:12769 [D loss: 0.561089, acc.: 72.66%] [G loss: 1.055240]\n",
      "epoch:13 step:12770 [D loss: 0.489290, acc.: 78.12%] [G loss: 1.351674]\n",
      "epoch:13 step:12771 [D loss: 0.638511, acc.: 64.06%] [G loss: 1.247033]\n",
      "epoch:13 step:12772 [D loss: 0.838172, acc.: 43.75%] [G loss: 0.975413]\n",
      "epoch:13 step:12773 [D loss: 0.687003, acc.: 55.47%] [G loss: 1.154814]\n",
      "epoch:13 step:12774 [D loss: 0.629969, acc.: 63.28%] [G loss: 1.080706]\n",
      "epoch:13 step:12775 [D loss: 0.715669, acc.: 55.47%] [G loss: 0.958873]\n",
      "epoch:13 step:12776 [D loss: 0.688649, acc.: 54.69%] [G loss: 0.916263]\n",
      "epoch:13 step:12777 [D loss: 0.702139, acc.: 57.03%] [G loss: 1.132140]\n",
      "epoch:13 step:12778 [D loss: 0.495039, acc.: 81.25%] [G loss: 1.049308]\n",
      "epoch:13 step:12779 [D loss: 0.436939, acc.: 85.16%] [G loss: 1.073336]\n",
      "epoch:13 step:12780 [D loss: 0.578360, acc.: 68.75%] [G loss: 1.042616]\n",
      "epoch:13 step:12781 [D loss: 0.705809, acc.: 60.94%] [G loss: 0.983393]\n",
      "epoch:13 step:12782 [D loss: 0.675319, acc.: 58.59%] [G loss: 0.898016]\n",
      "epoch:13 step:12783 [D loss: 0.701787, acc.: 57.03%] [G loss: 0.958593]\n",
      "epoch:13 step:12784 [D loss: 0.497436, acc.: 81.25%] [G loss: 1.095214]\n",
      "epoch:13 step:12785 [D loss: 0.466942, acc.: 81.25%] [G loss: 1.214200]\n",
      "epoch:13 step:12786 [D loss: 0.507778, acc.: 74.22%] [G loss: 1.178348]\n",
      "epoch:13 step:12787 [D loss: 0.658424, acc.: 60.94%] [G loss: 1.049615]\n",
      "epoch:13 step:12788 [D loss: 0.634548, acc.: 62.50%] [G loss: 1.128381]\n",
      "epoch:13 step:12789 [D loss: 0.546002, acc.: 75.78%] [G loss: 0.907273]\n",
      "epoch:13 step:12790 [D loss: 0.719240, acc.: 52.34%] [G loss: 0.713586]\n",
      "epoch:13 step:12791 [D loss: 0.664255, acc.: 58.59%] [G loss: 0.949833]\n",
      "epoch:13 step:12792 [D loss: 0.701824, acc.: 52.34%] [G loss: 0.904604]\n",
      "epoch:13 step:12793 [D loss: 0.763971, acc.: 45.31%] [G loss: 0.883991]\n",
      "epoch:13 step:12794 [D loss: 0.513585, acc.: 79.69%] [G loss: 1.214995]\n",
      "epoch:13 step:12795 [D loss: 0.595584, acc.: 65.62%] [G loss: 0.946548]\n",
      "epoch:13 step:12796 [D loss: 0.546450, acc.: 75.78%] [G loss: 1.169460]\n",
      "epoch:13 step:12797 [D loss: 0.503673, acc.: 77.34%] [G loss: 1.125921]\n",
      "epoch:13 step:12798 [D loss: 0.646566, acc.: 62.50%] [G loss: 1.016173]\n",
      "epoch:13 step:12799 [D loss: 0.662218, acc.: 63.28%] [G loss: 0.998204]\n",
      "epoch:13 step:12800 [D loss: 0.651081, acc.: 59.38%] [G loss: 0.936893]\n",
      "epoch:13 step:12801 [D loss: 0.715559, acc.: 51.56%] [G loss: 1.110596]\n",
      "epoch:13 step:12802 [D loss: 0.752818, acc.: 53.91%] [G loss: 0.839475]\n",
      "epoch:13 step:12803 [D loss: 0.665624, acc.: 59.38%] [G loss: 1.128821]\n",
      "epoch:13 step:12804 [D loss: 0.723054, acc.: 55.47%] [G loss: 0.835221]\n",
      "epoch:13 step:12805 [D loss: 0.695539, acc.: 57.03%] [G loss: 0.910044]\n",
      "epoch:13 step:12806 [D loss: 0.682303, acc.: 59.38%] [G loss: 1.015358]\n",
      "epoch:13 step:12807 [D loss: 0.799643, acc.: 44.53%] [G loss: 0.967593]\n",
      "epoch:13 step:12808 [D loss: 0.706605, acc.: 58.59%] [G loss: 0.949912]\n",
      "epoch:13 step:12809 [D loss: 0.572015, acc.: 70.31%] [G loss: 1.199384]\n",
      "epoch:13 step:12810 [D loss: 0.555792, acc.: 71.09%] [G loss: 1.037585]\n",
      "epoch:13 step:12811 [D loss: 0.653939, acc.: 57.03%] [G loss: 1.220025]\n",
      "epoch:13 step:12812 [D loss: 0.615423, acc.: 67.19%] [G loss: 1.097670]\n",
      "epoch:13 step:12813 [D loss: 0.763684, acc.: 46.09%] [G loss: 0.988653]\n",
      "epoch:13 step:12814 [D loss: 0.532434, acc.: 71.88%] [G loss: 1.180892]\n",
      "epoch:13 step:12815 [D loss: 0.660404, acc.: 57.03%] [G loss: 0.833172]\n",
      "epoch:13 step:12816 [D loss: 0.580507, acc.: 69.53%] [G loss: 0.841756]\n",
      "epoch:13 step:12817 [D loss: 0.608920, acc.: 66.41%] [G loss: 0.960953]\n",
      "epoch:13 step:12818 [D loss: 0.792708, acc.: 42.97%] [G loss: 0.924512]\n",
      "epoch:13 step:12819 [D loss: 0.708313, acc.: 54.69%] [G loss: 0.913837]\n",
      "epoch:13 step:12820 [D loss: 0.656722, acc.: 61.72%] [G loss: 1.119245]\n",
      "epoch:13 step:12821 [D loss: 0.554473, acc.: 74.22%] [G loss: 1.049681]\n",
      "epoch:13 step:12822 [D loss: 0.496721, acc.: 82.81%] [G loss: 1.238368]\n",
      "epoch:13 step:12823 [D loss: 0.473440, acc.: 81.25%] [G loss: 1.028875]\n",
      "epoch:13 step:12824 [D loss: 0.688945, acc.: 57.03%] [G loss: 1.082309]\n",
      "epoch:13 step:12825 [D loss: 0.616069, acc.: 65.62%] [G loss: 1.166345]\n",
      "epoch:13 step:12826 [D loss: 0.705693, acc.: 55.47%] [G loss: 0.886335]\n",
      "epoch:13 step:12827 [D loss: 0.622578, acc.: 61.72%] [G loss: 1.158992]\n",
      "epoch:13 step:12828 [D loss: 0.543809, acc.: 74.22%] [G loss: 1.061922]\n",
      "epoch:13 step:12829 [D loss: 0.567764, acc.: 75.00%] [G loss: 1.108599]\n",
      "epoch:13 step:12830 [D loss: 0.647931, acc.: 64.06%] [G loss: 0.947744]\n",
      "epoch:13 step:12831 [D loss: 0.600062, acc.: 68.75%] [G loss: 1.239220]\n",
      "epoch:13 step:12832 [D loss: 0.570631, acc.: 69.53%] [G loss: 1.209847]\n",
      "epoch:13 step:12833 [D loss: 0.784005, acc.: 50.78%] [G loss: 0.977719]\n",
      "epoch:13 step:12834 [D loss: 0.706954, acc.: 52.34%] [G loss: 0.999850]\n",
      "epoch:13 step:12835 [D loss: 0.592169, acc.: 68.75%] [G loss: 1.024236]\n",
      "epoch:13 step:12836 [D loss: 0.700649, acc.: 53.91%] [G loss: 1.022591]\n",
      "epoch:13 step:12837 [D loss: 0.662906, acc.: 57.03%] [G loss: 1.027602]\n",
      "epoch:13 step:12838 [D loss: 0.713510, acc.: 51.56%] [G loss: 0.908334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12839 [D loss: 0.699925, acc.: 53.12%] [G loss: 1.063857]\n",
      "epoch:13 step:12840 [D loss: 0.611631, acc.: 65.62%] [G loss: 0.913851]\n",
      "epoch:13 step:12841 [D loss: 0.549659, acc.: 75.78%] [G loss: 1.029162]\n",
      "epoch:13 step:12842 [D loss: 0.598658, acc.: 69.53%] [G loss: 0.966673]\n",
      "epoch:13 step:12843 [D loss: 0.545460, acc.: 72.66%] [G loss: 1.026046]\n",
      "epoch:13 step:12844 [D loss: 0.513168, acc.: 78.12%] [G loss: 1.109341]\n",
      "epoch:13 step:12845 [D loss: 0.541896, acc.: 76.56%] [G loss: 0.984473]\n",
      "epoch:13 step:12846 [D loss: 0.462620, acc.: 83.59%] [G loss: 1.100513]\n",
      "epoch:13 step:12847 [D loss: 0.611844, acc.: 72.66%] [G loss: 1.149480]\n",
      "epoch:13 step:12848 [D loss: 0.682469, acc.: 59.38%] [G loss: 1.045133]\n",
      "epoch:13 step:12849 [D loss: 0.744751, acc.: 50.78%] [G loss: 0.937372]\n",
      "epoch:13 step:12850 [D loss: 0.608601, acc.: 64.84%] [G loss: 1.166297]\n",
      "epoch:13 step:12851 [D loss: 0.724895, acc.: 53.91%] [G loss: 0.913983]\n",
      "epoch:13 step:12852 [D loss: 0.685930, acc.: 59.38%] [G loss: 0.984185]\n",
      "epoch:13 step:12853 [D loss: 0.767905, acc.: 50.00%] [G loss: 1.070566]\n",
      "epoch:13 step:12854 [D loss: 0.672555, acc.: 57.03%] [G loss: 1.093114]\n",
      "epoch:13 step:12855 [D loss: 0.719968, acc.: 52.34%] [G loss: 0.954237]\n",
      "epoch:13 step:12856 [D loss: 0.662031, acc.: 62.50%] [G loss: 0.971576]\n",
      "epoch:13 step:12857 [D loss: 0.701292, acc.: 56.25%] [G loss: 0.978858]\n",
      "epoch:13 step:12858 [D loss: 0.626052, acc.: 59.38%] [G loss: 0.861022]\n",
      "epoch:13 step:12859 [D loss: 0.763532, acc.: 46.88%] [G loss: 0.945588]\n",
      "epoch:13 step:12860 [D loss: 0.711215, acc.: 51.56%] [G loss: 0.933691]\n",
      "epoch:13 step:12861 [D loss: 0.737136, acc.: 50.00%] [G loss: 0.968687]\n",
      "epoch:13 step:12862 [D loss: 0.722504, acc.: 50.78%] [G loss: 0.819669]\n",
      "epoch:13 step:12863 [D loss: 0.590382, acc.: 72.66%] [G loss: 1.257579]\n",
      "epoch:13 step:12864 [D loss: 0.686160, acc.: 56.25%] [G loss: 0.995275]\n",
      "epoch:13 step:12865 [D loss: 0.720472, acc.: 53.91%] [G loss: 0.981939]\n",
      "epoch:13 step:12866 [D loss: 0.652929, acc.: 59.38%] [G loss: 0.954827]\n",
      "epoch:13 step:12867 [D loss: 0.667435, acc.: 62.50%] [G loss: 0.979680]\n",
      "epoch:13 step:12868 [D loss: 0.802348, acc.: 45.31%] [G loss: 0.854576]\n",
      "epoch:13 step:12869 [D loss: 0.664141, acc.: 58.59%] [G loss: 1.124843]\n",
      "epoch:13 step:12870 [D loss: 0.563042, acc.: 74.22%] [G loss: 0.963282]\n",
      "epoch:13 step:12871 [D loss: 0.448537, acc.: 82.03%] [G loss: 1.179995]\n",
      "epoch:13 step:12872 [D loss: 0.489697, acc.: 79.69%] [G loss: 1.134777]\n",
      "epoch:13 step:12873 [D loss: 0.618980, acc.: 64.84%] [G loss: 0.995915]\n",
      "epoch:13 step:12874 [D loss: 0.427935, acc.: 84.38%] [G loss: 1.238520]\n",
      "epoch:13 step:12875 [D loss: 0.414422, acc.: 88.28%] [G loss: 1.136754]\n",
      "epoch:13 step:12876 [D loss: 0.533944, acc.: 71.09%] [G loss: 1.089556]\n",
      "epoch:13 step:12877 [D loss: 0.654634, acc.: 59.38%] [G loss: 1.288258]\n",
      "epoch:13 step:12878 [D loss: 0.685379, acc.: 57.03%] [G loss: 1.084199]\n",
      "epoch:13 step:12879 [D loss: 0.704752, acc.: 53.91%] [G loss: 0.841908]\n",
      "epoch:13 step:12880 [D loss: 0.628502, acc.: 63.28%] [G loss: 1.018720]\n",
      "epoch:13 step:12881 [D loss: 0.606535, acc.: 64.84%] [G loss: 1.155179]\n",
      "epoch:13 step:12882 [D loss: 0.630785, acc.: 64.84%] [G loss: 0.933619]\n",
      "epoch:13 step:12883 [D loss: 0.721184, acc.: 52.34%] [G loss: 1.103325]\n",
      "epoch:13 step:12884 [D loss: 0.677407, acc.: 55.47%] [G loss: 1.027474]\n",
      "epoch:13 step:12885 [D loss: 0.737795, acc.: 50.78%] [G loss: 0.940031]\n",
      "epoch:13 step:12886 [D loss: 0.601995, acc.: 73.44%] [G loss: 1.015784]\n",
      "epoch:13 step:12887 [D loss: 0.547385, acc.: 75.00%] [G loss: 0.929473]\n",
      "epoch:13 step:12888 [D loss: 0.527068, acc.: 78.91%] [G loss: 1.050507]\n",
      "epoch:13 step:12889 [D loss: 0.514714, acc.: 77.34%] [G loss: 1.113887]\n",
      "epoch:13 step:12890 [D loss: 0.404094, acc.: 86.72%] [G loss: 1.142736]\n",
      "epoch:13 step:12891 [D loss: 0.690657, acc.: 53.91%] [G loss: 1.193553]\n",
      "epoch:13 step:12892 [D loss: 0.743872, acc.: 49.22%] [G loss: 1.076597]\n",
      "epoch:13 step:12893 [D loss: 0.571680, acc.: 65.62%] [G loss: 1.097564]\n",
      "epoch:13 step:12894 [D loss: 0.631380, acc.: 65.62%] [G loss: 0.878806]\n",
      "epoch:13 step:12895 [D loss: 0.572728, acc.: 70.31%] [G loss: 1.016774]\n",
      "epoch:13 step:12896 [D loss: 0.600746, acc.: 64.84%] [G loss: 1.068784]\n",
      "epoch:13 step:12897 [D loss: 0.803939, acc.: 44.53%] [G loss: 0.828617]\n",
      "epoch:13 step:12898 [D loss: 0.695270, acc.: 60.16%] [G loss: 1.027125]\n",
      "epoch:13 step:12899 [D loss: 0.669526, acc.: 59.38%] [G loss: 0.915846]\n",
      "epoch:13 step:12900 [D loss: 0.644482, acc.: 64.06%] [G loss: 0.953876]\n",
      "epoch:13 step:12901 [D loss: 0.674106, acc.: 53.91%] [G loss: 0.998025]\n",
      "epoch:13 step:12902 [D loss: 0.612521, acc.: 67.97%] [G loss: 1.053529]\n",
      "epoch:13 step:12903 [D loss: 0.624744, acc.: 63.28%] [G loss: 0.969352]\n",
      "epoch:13 step:12904 [D loss: 0.662167, acc.: 60.94%] [G loss: 0.913638]\n",
      "epoch:13 step:12905 [D loss: 0.613981, acc.: 67.19%] [G loss: 0.911256]\n",
      "epoch:13 step:12906 [D loss: 0.672177, acc.: 63.28%] [G loss: 0.892283]\n",
      "epoch:13 step:12907 [D loss: 0.642993, acc.: 59.38%] [G loss: 1.048076]\n",
      "epoch:13 step:12908 [D loss: 0.643649, acc.: 65.62%] [G loss: 0.938056]\n",
      "epoch:13 step:12909 [D loss: 0.481269, acc.: 83.59%] [G loss: 1.071417]\n",
      "epoch:13 step:12910 [D loss: 0.497052, acc.: 80.47%] [G loss: 1.177093]\n",
      "epoch:13 step:12911 [D loss: 0.555018, acc.: 73.44%] [G loss: 0.900805]\n",
      "epoch:13 step:12912 [D loss: 0.420674, acc.: 86.72%] [G loss: 1.079838]\n",
      "epoch:13 step:12913 [D loss: 0.592081, acc.: 69.53%] [G loss: 0.927085]\n",
      "epoch:13 step:12914 [D loss: 0.556197, acc.: 77.34%] [G loss: 1.022424]\n",
      "epoch:13 step:12915 [D loss: 0.627019, acc.: 66.41%] [G loss: 1.158784]\n",
      "epoch:13 step:12916 [D loss: 0.744048, acc.: 49.22%] [G loss: 0.866108]\n",
      "epoch:13 step:12917 [D loss: 0.712335, acc.: 52.34%] [G loss: 0.920487]\n",
      "epoch:13 step:12918 [D loss: 0.617785, acc.: 62.50%] [G loss: 0.891217]\n",
      "epoch:13 step:12919 [D loss: 0.623013, acc.: 65.62%] [G loss: 0.958324]\n",
      "epoch:13 step:12920 [D loss: 0.773624, acc.: 50.78%] [G loss: 0.885134]\n",
      "epoch:13 step:12921 [D loss: 0.680410, acc.: 57.03%] [G loss: 0.942260]\n",
      "epoch:13 step:12922 [D loss: 0.749427, acc.: 44.53%] [G loss: 0.932022]\n",
      "epoch:13 step:12923 [D loss: 0.593576, acc.: 71.88%] [G loss: 1.159553]\n",
      "epoch:13 step:12924 [D loss: 0.620142, acc.: 67.19%] [G loss: 1.037618]\n",
      "epoch:13 step:12925 [D loss: 0.671387, acc.: 56.25%] [G loss: 0.895292]\n",
      "epoch:13 step:12926 [D loss: 0.521116, acc.: 79.69%] [G loss: 1.054220]\n",
      "epoch:13 step:12927 [D loss: 0.619905, acc.: 61.72%] [G loss: 1.036762]\n",
      "epoch:13 step:12928 [D loss: 0.667015, acc.: 61.72%] [G loss: 0.996696]\n",
      "epoch:13 step:12929 [D loss: 0.601686, acc.: 69.53%] [G loss: 1.066795]\n",
      "epoch:13 step:12930 [D loss: 0.566482, acc.: 74.22%] [G loss: 0.996990]\n",
      "epoch:13 step:12931 [D loss: 0.571745, acc.: 70.31%] [G loss: 0.917129]\n",
      "epoch:13 step:12932 [D loss: 0.768502, acc.: 46.88%] [G loss: 0.980423]\n",
      "epoch:13 step:12933 [D loss: 0.718369, acc.: 53.91%] [G loss: 0.970923]\n",
      "epoch:13 step:12934 [D loss: 0.682749, acc.: 58.59%] [G loss: 0.917697]\n",
      "epoch:13 step:12935 [D loss: 0.659110, acc.: 57.81%] [G loss: 1.089718]\n",
      "epoch:13 step:12936 [D loss: 0.678124, acc.: 64.06%] [G loss: 0.890401]\n",
      "epoch:13 step:12937 [D loss: 0.614178, acc.: 64.06%] [G loss: 1.218911]\n",
      "epoch:13 step:12938 [D loss: 0.616271, acc.: 65.62%] [G loss: 0.920825]\n",
      "epoch:13 step:12939 [D loss: 0.677179, acc.: 61.72%] [G loss: 1.034081]\n",
      "epoch:13 step:12940 [D loss: 0.747741, acc.: 43.75%] [G loss: 0.781649]\n",
      "epoch:13 step:12941 [D loss: 0.678526, acc.: 57.03%] [G loss: 0.913189]\n",
      "epoch:13 step:12942 [D loss: 0.620268, acc.: 66.41%] [G loss: 0.965430]\n",
      "epoch:13 step:12943 [D loss: 0.695153, acc.: 56.25%] [G loss: 1.044682]\n",
      "epoch:13 step:12944 [D loss: 0.666192, acc.: 57.03%] [G loss: 1.044200]\n",
      "epoch:13 step:12945 [D loss: 0.659032, acc.: 58.59%] [G loss: 1.083299]\n",
      "epoch:13 step:12946 [D loss: 0.615631, acc.: 60.94%] [G loss: 1.045966]\n",
      "epoch:13 step:12947 [D loss: 0.622623, acc.: 67.97%] [G loss: 1.207793]\n",
      "epoch:13 step:12948 [D loss: 0.546462, acc.: 76.56%] [G loss: 1.107699]\n",
      "epoch:13 step:12949 [D loss: 0.598465, acc.: 71.09%] [G loss: 1.188042]\n",
      "epoch:13 step:12950 [D loss: 0.423119, acc.: 85.94%] [G loss: 1.068716]\n",
      "epoch:13 step:12951 [D loss: 0.604219, acc.: 67.97%] [G loss: 0.995142]\n",
      "epoch:13 step:12952 [D loss: 0.738422, acc.: 53.91%] [G loss: 0.998287]\n",
      "epoch:13 step:12953 [D loss: 0.695651, acc.: 50.00%] [G loss: 1.059116]\n",
      "epoch:13 step:12954 [D loss: 0.638962, acc.: 60.16%] [G loss: 0.849294]\n",
      "epoch:13 step:12955 [D loss: 0.542116, acc.: 69.53%] [G loss: 0.990044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12956 [D loss: 0.387948, acc.: 90.62%] [G loss: 1.248328]\n",
      "epoch:13 step:12957 [D loss: 0.614561, acc.: 67.97%] [G loss: 1.317979]\n",
      "epoch:13 step:12958 [D loss: 0.651893, acc.: 60.94%] [G loss: 1.071160]\n",
      "epoch:13 step:12959 [D loss: 0.644567, acc.: 63.28%] [G loss: 1.052952]\n",
      "epoch:13 step:12960 [D loss: 0.686533, acc.: 60.94%] [G loss: 1.143618]\n",
      "epoch:13 step:12961 [D loss: 0.695234, acc.: 54.69%] [G loss: 0.981950]\n",
      "epoch:13 step:12962 [D loss: 0.529174, acc.: 74.22%] [G loss: 1.211194]\n",
      "epoch:13 step:12963 [D loss: 0.429668, acc.: 84.38%] [G loss: 1.224566]\n",
      "epoch:13 step:12964 [D loss: 0.661511, acc.: 57.03%] [G loss: 1.046472]\n",
      "epoch:13 step:12965 [D loss: 0.659915, acc.: 57.81%] [G loss: 0.957500]\n",
      "epoch:13 step:12966 [D loss: 0.531976, acc.: 74.22%] [G loss: 1.046328]\n",
      "epoch:13 step:12967 [D loss: 0.441113, acc.: 84.38%] [G loss: 1.193030]\n",
      "epoch:13 step:12968 [D loss: 0.739445, acc.: 56.25%] [G loss: 0.977998]\n",
      "epoch:13 step:12969 [D loss: 0.637351, acc.: 64.84%] [G loss: 1.077449]\n",
      "epoch:13 step:12970 [D loss: 0.619601, acc.: 67.19%] [G loss: 1.056916]\n",
      "epoch:13 step:12971 [D loss: 0.590947, acc.: 71.09%] [G loss: 0.916053]\n",
      "epoch:13 step:12972 [D loss: 0.468570, acc.: 83.59%] [G loss: 1.281378]\n",
      "epoch:13 step:12973 [D loss: 0.361267, acc.: 89.06%] [G loss: 1.188586]\n",
      "epoch:13 step:12974 [D loss: 0.476940, acc.: 81.25%] [G loss: 1.177612]\n",
      "epoch:13 step:12975 [D loss: 0.416176, acc.: 88.28%] [G loss: 1.410282]\n",
      "epoch:13 step:12976 [D loss: 0.623040, acc.: 68.75%] [G loss: 1.051325]\n",
      "epoch:13 step:12977 [D loss: 0.551481, acc.: 72.66%] [G loss: 1.426822]\n",
      "epoch:13 step:12978 [D loss: 0.633705, acc.: 65.62%] [G loss: 0.959416]\n",
      "epoch:13 step:12979 [D loss: 0.603202, acc.: 66.41%] [G loss: 1.113000]\n",
      "epoch:13 step:12980 [D loss: 0.651332, acc.: 60.94%] [G loss: 1.003974]\n",
      "epoch:13 step:12981 [D loss: 0.874893, acc.: 35.16%] [G loss: 0.885398]\n",
      "epoch:13 step:12982 [D loss: 0.713036, acc.: 52.34%] [G loss: 0.998421]\n",
      "epoch:13 step:12983 [D loss: 0.808788, acc.: 39.06%] [G loss: 0.968685]\n",
      "epoch:13 step:12984 [D loss: 0.720591, acc.: 50.78%] [G loss: 0.977333]\n",
      "epoch:13 step:12985 [D loss: 0.625739, acc.: 65.62%] [G loss: 1.036748]\n",
      "epoch:13 step:12986 [D loss: 0.480689, acc.: 79.69%] [G loss: 1.035873]\n",
      "epoch:13 step:12987 [D loss: 0.488875, acc.: 77.34%] [G loss: 1.164066]\n",
      "epoch:13 step:12988 [D loss: 0.598091, acc.: 72.66%] [G loss: 1.034749]\n",
      "epoch:13 step:12989 [D loss: 0.629966, acc.: 61.72%] [G loss: 1.087891]\n",
      "epoch:13 step:12990 [D loss: 0.637341, acc.: 64.84%] [G loss: 1.097091]\n",
      "epoch:13 step:12991 [D loss: 0.537256, acc.: 77.34%] [G loss: 1.205640]\n",
      "epoch:13 step:12992 [D loss: 0.664452, acc.: 62.50%] [G loss: 1.205862]\n",
      "epoch:13 step:12993 [D loss: 0.682357, acc.: 58.59%] [G loss: 1.162827]\n",
      "epoch:13 step:12994 [D loss: 0.654737, acc.: 58.59%] [G loss: 1.132628]\n",
      "epoch:13 step:12995 [D loss: 0.718858, acc.: 55.47%] [G loss: 0.999641]\n",
      "epoch:13 step:12996 [D loss: 0.362372, acc.: 90.62%] [G loss: 1.280007]\n",
      "epoch:13 step:12997 [D loss: 0.517247, acc.: 75.00%] [G loss: 1.093117]\n",
      "epoch:13 step:12998 [D loss: 0.613388, acc.: 68.75%] [G loss: 1.053392]\n",
      "epoch:13 step:12999 [D loss: 0.622706, acc.: 66.41%] [G loss: 1.091485]\n",
      "epoch:13 step:13000 [D loss: 0.579713, acc.: 71.09%] [G loss: 1.085600]\n",
      "epoch:13 step:13001 [D loss: 0.730571, acc.: 50.78%] [G loss: 0.967997]\n",
      "epoch:13 step:13002 [D loss: 0.694574, acc.: 54.69%] [G loss: 0.969680]\n",
      "epoch:13 step:13003 [D loss: 0.725559, acc.: 49.22%] [G loss: 0.997934]\n",
      "epoch:13 step:13004 [D loss: 0.624360, acc.: 61.72%] [G loss: 1.126648]\n",
      "epoch:13 step:13005 [D loss: 0.529909, acc.: 76.56%] [G loss: 1.056633]\n",
      "epoch:13 step:13006 [D loss: 0.615908, acc.: 65.62%] [G loss: 0.991826]\n",
      "epoch:13 step:13007 [D loss: 0.616000, acc.: 68.75%] [G loss: 0.966271]\n",
      "epoch:13 step:13008 [D loss: 0.646929, acc.: 64.84%] [G loss: 0.997680]\n",
      "epoch:13 step:13009 [D loss: 0.562274, acc.: 71.09%] [G loss: 1.269519]\n",
      "epoch:13 step:13010 [D loss: 0.738533, acc.: 50.78%] [G loss: 0.934093]\n",
      "epoch:13 step:13011 [D loss: 0.667544, acc.: 58.59%] [G loss: 1.020634]\n",
      "epoch:13 step:13012 [D loss: 0.458912, acc.: 83.59%] [G loss: 1.242574]\n",
      "epoch:13 step:13013 [D loss: 0.578653, acc.: 71.09%] [G loss: 1.067688]\n",
      "epoch:13 step:13014 [D loss: 0.684959, acc.: 57.03%] [G loss: 1.005753]\n",
      "epoch:13 step:13015 [D loss: 0.795952, acc.: 46.09%] [G loss: 1.381382]\n",
      "epoch:13 step:13016 [D loss: 0.762014, acc.: 50.00%] [G loss: 0.924028]\n",
      "epoch:13 step:13017 [D loss: 0.781490, acc.: 46.09%] [G loss: 0.898548]\n",
      "epoch:13 step:13018 [D loss: 0.754881, acc.: 52.34%] [G loss: 0.864887]\n",
      "epoch:13 step:13019 [D loss: 0.774933, acc.: 43.75%] [G loss: 0.930307]\n",
      "epoch:13 step:13020 [D loss: 0.587644, acc.: 66.41%] [G loss: 1.244367]\n",
      "epoch:13 step:13021 [D loss: 0.647648, acc.: 64.84%] [G loss: 1.018565]\n",
      "epoch:13 step:13022 [D loss: 0.530551, acc.: 71.88%] [G loss: 1.135384]\n",
      "epoch:13 step:13023 [D loss: 0.597495, acc.: 69.53%] [G loss: 1.003273]\n",
      "epoch:13 step:13024 [D loss: 0.668767, acc.: 59.38%] [G loss: 1.011031]\n",
      "epoch:13 step:13025 [D loss: 0.749213, acc.: 47.66%] [G loss: 0.996204]\n",
      "epoch:13 step:13026 [D loss: 0.662534, acc.: 58.59%] [G loss: 0.935695]\n",
      "epoch:13 step:13027 [D loss: 0.705147, acc.: 57.03%] [G loss: 0.814847]\n",
      "epoch:13 step:13028 [D loss: 0.580766, acc.: 73.44%] [G loss: 0.937698]\n",
      "epoch:13 step:13029 [D loss: 0.599992, acc.: 66.41%] [G loss: 1.065536]\n",
      "epoch:13 step:13030 [D loss: 0.498596, acc.: 79.69%] [G loss: 1.152972]\n",
      "epoch:13 step:13031 [D loss: 0.451971, acc.: 82.03%] [G loss: 1.217115]\n",
      "epoch:13 step:13032 [D loss: 0.465799, acc.: 81.25%] [G loss: 1.186553]\n",
      "epoch:13 step:13033 [D loss: 0.385652, acc.: 89.84%] [G loss: 1.211795]\n",
      "epoch:13 step:13034 [D loss: 0.602888, acc.: 64.84%] [G loss: 1.148244]\n",
      "epoch:13 step:13035 [D loss: 0.409397, acc.: 89.06%] [G loss: 1.596078]\n",
      "epoch:13 step:13036 [D loss: 0.569570, acc.: 71.88%] [G loss: 1.087120]\n",
      "epoch:13 step:13037 [D loss: 0.544905, acc.: 71.09%] [G loss: 1.111268]\n",
      "epoch:13 step:13038 [D loss: 0.577590, acc.: 67.19%] [G loss: 1.171862]\n",
      "epoch:13 step:13039 [D loss: 0.938022, acc.: 32.03%] [G loss: 0.976564]\n",
      "epoch:13 step:13040 [D loss: 0.754008, acc.: 48.44%] [G loss: 0.986291]\n",
      "epoch:13 step:13041 [D loss: 0.665728, acc.: 61.72%] [G loss: 1.100665]\n",
      "epoch:13 step:13042 [D loss: 0.664712, acc.: 67.97%] [G loss: 1.029989]\n",
      "epoch:13 step:13043 [D loss: 0.724746, acc.: 53.12%] [G loss: 0.916093]\n",
      "epoch:13 step:13044 [D loss: 0.737105, acc.: 50.78%] [G loss: 0.928177]\n",
      "epoch:13 step:13045 [D loss: 0.728293, acc.: 50.00%] [G loss: 0.795682]\n",
      "epoch:13 step:13046 [D loss: 0.653135, acc.: 60.94%] [G loss: 0.935640]\n",
      "epoch:13 step:13047 [D loss: 0.633729, acc.: 67.19%] [G loss: 0.856450]\n",
      "epoch:13 step:13048 [D loss: 0.682819, acc.: 58.59%] [G loss: 0.900778]\n",
      "epoch:13 step:13049 [D loss: 0.714438, acc.: 55.47%] [G loss: 0.986254]\n",
      "epoch:13 step:13050 [D loss: 0.628180, acc.: 68.75%] [G loss: 0.852024]\n",
      "epoch:13 step:13051 [D loss: 0.690976, acc.: 56.25%] [G loss: 0.870830]\n",
      "epoch:13 step:13052 [D loss: 0.727080, acc.: 59.38%] [G loss: 0.831364]\n",
      "epoch:13 step:13053 [D loss: 0.733746, acc.: 52.34%] [G loss: 0.953715]\n",
      "epoch:13 step:13054 [D loss: 0.612520, acc.: 67.97%] [G loss: 1.118265]\n",
      "epoch:13 step:13055 [D loss: 0.718606, acc.: 47.66%] [G loss: 1.122720]\n",
      "epoch:13 step:13056 [D loss: 0.571142, acc.: 70.31%] [G loss: 1.135424]\n",
      "epoch:13 step:13057 [D loss: 0.610658, acc.: 67.19%] [G loss: 0.988995]\n",
      "epoch:13 step:13058 [D loss: 0.677025, acc.: 57.03%] [G loss: 1.088467]\n",
      "epoch:13 step:13059 [D loss: 0.618577, acc.: 66.41%] [G loss: 0.969721]\n",
      "epoch:13 step:13060 [D loss: 0.699741, acc.: 56.25%] [G loss: 0.951572]\n",
      "epoch:13 step:13061 [D loss: 0.718828, acc.: 53.12%] [G loss: 0.892301]\n",
      "epoch:13 step:13062 [D loss: 0.634615, acc.: 64.84%] [G loss: 1.168951]\n",
      "epoch:13 step:13063 [D loss: 0.599212, acc.: 67.19%] [G loss: 0.948025]\n",
      "epoch:13 step:13064 [D loss: 0.701758, acc.: 55.47%] [G loss: 0.836434]\n",
      "epoch:13 step:13065 [D loss: 0.498824, acc.: 76.56%] [G loss: 1.064066]\n",
      "epoch:13 step:13066 [D loss: 0.680652, acc.: 61.72%] [G loss: 0.848865]\n",
      "epoch:13 step:13067 [D loss: 0.636853, acc.: 67.19%] [G loss: 1.176565]\n",
      "epoch:13 step:13068 [D loss: 0.583425, acc.: 67.97%] [G loss: 1.123018]\n",
      "epoch:13 step:13069 [D loss: 0.608748, acc.: 67.19%] [G loss: 1.015534]\n",
      "epoch:13 step:13070 [D loss: 0.559260, acc.: 71.09%] [G loss: 1.071021]\n",
      "epoch:13 step:13071 [D loss: 0.558578, acc.: 75.00%] [G loss: 1.114346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13072 [D loss: 0.717567, acc.: 53.91%] [G loss: 1.070452]\n",
      "epoch:13 step:13073 [D loss: 0.583320, acc.: 71.88%] [G loss: 1.146704]\n",
      "epoch:13 step:13074 [D loss: 0.522171, acc.: 79.69%] [G loss: 1.271084]\n",
      "epoch:13 step:13075 [D loss: 0.466553, acc.: 86.72%] [G loss: 1.256183]\n",
      "epoch:13 step:13076 [D loss: 0.514569, acc.: 78.12%] [G loss: 1.064969]\n",
      "epoch:13 step:13077 [D loss: 0.594748, acc.: 67.19%] [G loss: 1.029034]\n",
      "epoch:13 step:13078 [D loss: 0.408453, acc.: 84.38%] [G loss: 1.437085]\n",
      "epoch:13 step:13079 [D loss: 0.423561, acc.: 89.84%] [G loss: 1.178585]\n",
      "epoch:13 step:13080 [D loss: 0.372648, acc.: 87.50%] [G loss: 1.420903]\n",
      "epoch:13 step:13081 [D loss: 0.380732, acc.: 89.06%] [G loss: 1.268163]\n",
      "epoch:13 step:13082 [D loss: 0.511454, acc.: 82.81%] [G loss: 1.143113]\n",
      "epoch:13 step:13083 [D loss: 0.672172, acc.: 56.25%] [G loss: 0.994306]\n",
      "epoch:13 step:13084 [D loss: 0.757461, acc.: 49.22%] [G loss: 0.982420]\n",
      "epoch:13 step:13085 [D loss: 0.782161, acc.: 49.22%] [G loss: 1.176174]\n",
      "epoch:13 step:13086 [D loss: 0.676715, acc.: 57.03%] [G loss: 0.783361]\n",
      "epoch:13 step:13087 [D loss: 0.757446, acc.: 46.09%] [G loss: 1.234558]\n",
      "epoch:13 step:13088 [D loss: 0.720573, acc.: 58.59%] [G loss: 1.168537]\n",
      "epoch:13 step:13089 [D loss: 0.624669, acc.: 67.97%] [G loss: 1.027113]\n",
      "epoch:13 step:13090 [D loss: 0.432807, acc.: 86.72%] [G loss: 0.988014]\n",
      "epoch:13 step:13091 [D loss: 0.670977, acc.: 58.59%] [G loss: 1.048838]\n",
      "epoch:13 step:13092 [D loss: 0.414015, acc.: 86.72%] [G loss: 1.114301]\n",
      "epoch:13 step:13093 [D loss: 0.333918, acc.: 90.62%] [G loss: 1.236735]\n",
      "epoch:13 step:13094 [D loss: 0.837503, acc.: 48.44%] [G loss: 1.245962]\n",
      "epoch:13 step:13095 [D loss: 0.685900, acc.: 59.38%] [G loss: 1.248708]\n",
      "epoch:13 step:13096 [D loss: 0.603847, acc.: 64.84%] [G loss: 1.114070]\n",
      "epoch:13 step:13097 [D loss: 0.693748, acc.: 58.59%] [G loss: 0.960286]\n",
      "epoch:13 step:13098 [D loss: 0.692572, acc.: 60.94%] [G loss: 1.066020]\n",
      "epoch:13 step:13099 [D loss: 0.596915, acc.: 67.97%] [G loss: 1.043308]\n",
      "epoch:13 step:13100 [D loss: 0.552758, acc.: 71.09%] [G loss: 1.188098]\n",
      "epoch:13 step:13101 [D loss: 0.827203, acc.: 45.31%] [G loss: 1.025391]\n",
      "epoch:13 step:13102 [D loss: 0.587462, acc.: 71.09%] [G loss: 1.157547]\n",
      "epoch:13 step:13103 [D loss: 0.570955, acc.: 71.88%] [G loss: 1.269828]\n",
      "epoch:13 step:13104 [D loss: 0.531743, acc.: 78.12%] [G loss: 0.994245]\n",
      "epoch:13 step:13105 [D loss: 0.494957, acc.: 78.91%] [G loss: 0.969146]\n",
      "epoch:13 step:13106 [D loss: 0.595161, acc.: 69.53%] [G loss: 1.058575]\n",
      "epoch:13 step:13107 [D loss: 0.609328, acc.: 67.19%] [G loss: 1.013826]\n",
      "epoch:13 step:13108 [D loss: 0.599261, acc.: 67.97%] [G loss: 1.019428]\n",
      "epoch:13 step:13109 [D loss: 0.756756, acc.: 53.91%] [G loss: 1.296612]\n",
      "epoch:13 step:13110 [D loss: 0.552499, acc.: 73.44%] [G loss: 1.109365]\n",
      "epoch:13 step:13111 [D loss: 0.516914, acc.: 80.47%] [G loss: 1.195970]\n",
      "epoch:13 step:13112 [D loss: 0.578345, acc.: 73.44%] [G loss: 1.146555]\n",
      "epoch:13 step:13113 [D loss: 0.712102, acc.: 55.47%] [G loss: 0.949249]\n",
      "epoch:13 step:13114 [D loss: 0.650696, acc.: 57.03%] [G loss: 0.990253]\n",
      "epoch:13 step:13115 [D loss: 0.481776, acc.: 82.81%] [G loss: 0.947966]\n",
      "epoch:13 step:13116 [D loss: 0.698761, acc.: 56.25%] [G loss: 0.972807]\n",
      "epoch:13 step:13117 [D loss: 0.534548, acc.: 75.78%] [G loss: 0.982946]\n",
      "epoch:13 step:13118 [D loss: 0.316994, acc.: 89.06%] [G loss: 1.300873]\n",
      "epoch:14 step:13119 [D loss: 0.698659, acc.: 57.81%] [G loss: 1.255994]\n",
      "epoch:14 step:13120 [D loss: 0.700976, acc.: 57.81%] [G loss: 0.940489]\n",
      "epoch:14 step:13121 [D loss: 0.769552, acc.: 46.09%] [G loss: 0.962344]\n",
      "epoch:14 step:13122 [D loss: 0.570393, acc.: 73.44%] [G loss: 1.013628]\n",
      "epoch:14 step:13123 [D loss: 0.644416, acc.: 62.50%] [G loss: 0.895422]\n",
      "epoch:14 step:13124 [D loss: 0.531418, acc.: 75.00%] [G loss: 1.174837]\n",
      "epoch:14 step:13125 [D loss: 0.580621, acc.: 71.09%] [G loss: 1.213133]\n",
      "epoch:14 step:13126 [D loss: 0.725364, acc.: 53.12%] [G loss: 0.934431]\n",
      "epoch:14 step:13127 [D loss: 0.558200, acc.: 71.09%] [G loss: 1.175836]\n",
      "epoch:14 step:13128 [D loss: 0.637357, acc.: 62.50%] [G loss: 0.961292]\n",
      "epoch:14 step:13129 [D loss: 0.667931, acc.: 63.28%] [G loss: 0.975573]\n",
      "epoch:14 step:13130 [D loss: 0.754353, acc.: 43.75%] [G loss: 0.967393]\n",
      "epoch:14 step:13131 [D loss: 0.680778, acc.: 57.81%] [G loss: 0.948643]\n",
      "epoch:14 step:13132 [D loss: 0.739406, acc.: 53.91%] [G loss: 0.815632]\n",
      "epoch:14 step:13133 [D loss: 0.444056, acc.: 84.38%] [G loss: 1.116888]\n",
      "epoch:14 step:13134 [D loss: 0.598436, acc.: 67.97%] [G loss: 1.189147]\n",
      "epoch:14 step:13135 [D loss: 0.716889, acc.: 60.94%] [G loss: 0.998595]\n",
      "epoch:14 step:13136 [D loss: 0.637912, acc.: 63.28%] [G loss: 0.977185]\n",
      "epoch:14 step:13137 [D loss: 0.764296, acc.: 46.88%] [G loss: 0.922359]\n",
      "epoch:14 step:13138 [D loss: 0.768928, acc.: 43.75%] [G loss: 0.977103]\n",
      "epoch:14 step:13139 [D loss: 0.639193, acc.: 63.28%] [G loss: 0.918100]\n",
      "epoch:14 step:13140 [D loss: 0.615212, acc.: 68.75%] [G loss: 1.117337]\n",
      "epoch:14 step:13141 [D loss: 0.623324, acc.: 67.97%] [G loss: 0.960990]\n",
      "epoch:14 step:13142 [D loss: 0.642485, acc.: 64.06%] [G loss: 1.002956]\n",
      "epoch:14 step:13143 [D loss: 0.630993, acc.: 64.84%] [G loss: 1.121346]\n",
      "epoch:14 step:13144 [D loss: 0.579333, acc.: 67.97%] [G loss: 0.961866]\n",
      "epoch:14 step:13145 [D loss: 0.465093, acc.: 83.59%] [G loss: 1.138600]\n",
      "epoch:14 step:13146 [D loss: 0.482299, acc.: 82.03%] [G loss: 1.149316]\n",
      "epoch:14 step:13147 [D loss: 0.526662, acc.: 72.66%] [G loss: 1.118494]\n",
      "epoch:14 step:13148 [D loss: 0.667377, acc.: 61.72%] [G loss: 1.129263]\n",
      "epoch:14 step:13149 [D loss: 0.477315, acc.: 77.34%] [G loss: 1.271836]\n",
      "epoch:14 step:13150 [D loss: 0.517748, acc.: 75.78%] [G loss: 1.060632]\n",
      "epoch:14 step:13151 [D loss: 0.500747, acc.: 78.12%] [G loss: 1.420898]\n",
      "epoch:14 step:13152 [D loss: 0.515136, acc.: 80.47%] [G loss: 1.170439]\n",
      "epoch:14 step:13153 [D loss: 0.504440, acc.: 78.12%] [G loss: 1.216504]\n",
      "epoch:14 step:13154 [D loss: 0.522053, acc.: 74.22%] [G loss: 1.031659]\n",
      "epoch:14 step:13155 [D loss: 0.836198, acc.: 44.53%] [G loss: 1.171749]\n",
      "epoch:14 step:13156 [D loss: 0.697689, acc.: 61.72%] [G loss: 1.208441]\n",
      "epoch:14 step:13157 [D loss: 0.793154, acc.: 48.44%] [G loss: 1.081118]\n",
      "epoch:14 step:13158 [D loss: 0.520552, acc.: 78.91%] [G loss: 1.106062]\n",
      "epoch:14 step:13159 [D loss: 0.641275, acc.: 64.06%] [G loss: 1.166297]\n",
      "epoch:14 step:13160 [D loss: 0.656650, acc.: 58.59%] [G loss: 0.986242]\n",
      "epoch:14 step:13161 [D loss: 0.584764, acc.: 67.97%] [G loss: 1.081694]\n",
      "epoch:14 step:13162 [D loss: 0.746223, acc.: 49.22%] [G loss: 0.888215]\n",
      "epoch:14 step:13163 [D loss: 0.672642, acc.: 57.81%] [G loss: 0.893671]\n",
      "epoch:14 step:13164 [D loss: 0.619635, acc.: 66.41%] [G loss: 0.927283]\n",
      "epoch:14 step:13165 [D loss: 0.526088, acc.: 77.34%] [G loss: 1.026966]\n",
      "epoch:14 step:13166 [D loss: 0.551503, acc.: 71.09%] [G loss: 0.906465]\n",
      "epoch:14 step:13167 [D loss: 0.465678, acc.: 83.59%] [G loss: 0.961334]\n",
      "epoch:14 step:13168 [D loss: 0.497766, acc.: 80.47%] [G loss: 1.020371]\n",
      "epoch:14 step:13169 [D loss: 0.626373, acc.: 66.41%] [G loss: 1.042014]\n",
      "epoch:14 step:13170 [D loss: 0.572965, acc.: 76.56%] [G loss: 0.858452]\n",
      "epoch:14 step:13171 [D loss: 0.728811, acc.: 54.69%] [G loss: 0.873175]\n",
      "epoch:14 step:13172 [D loss: 0.622198, acc.: 64.84%] [G loss: 1.127187]\n",
      "epoch:14 step:13173 [D loss: 0.595203, acc.: 71.88%] [G loss: 0.986193]\n",
      "epoch:14 step:13174 [D loss: 0.619350, acc.: 67.97%] [G loss: 1.085282]\n",
      "epoch:14 step:13175 [D loss: 0.720261, acc.: 53.12%] [G loss: 0.880492]\n",
      "epoch:14 step:13176 [D loss: 0.828568, acc.: 34.38%] [G loss: 0.963125]\n",
      "epoch:14 step:13177 [D loss: 0.768996, acc.: 49.22%] [G loss: 0.809224]\n",
      "epoch:14 step:13178 [D loss: 0.806597, acc.: 45.31%] [G loss: 0.804339]\n",
      "epoch:14 step:13179 [D loss: 0.683934, acc.: 60.94%] [G loss: 1.116047]\n",
      "epoch:14 step:13180 [D loss: 0.644178, acc.: 62.50%] [G loss: 0.921058]\n",
      "epoch:14 step:13181 [D loss: 0.707567, acc.: 55.47%] [G loss: 0.940234]\n",
      "epoch:14 step:13182 [D loss: 0.671504, acc.: 58.59%] [G loss: 0.907384]\n",
      "epoch:14 step:13183 [D loss: 0.647203, acc.: 61.72%] [G loss: 1.067696]\n",
      "epoch:14 step:13184 [D loss: 0.722284, acc.: 54.69%] [G loss: 0.827406]\n",
      "epoch:14 step:13185 [D loss: 0.621914, acc.: 67.19%] [G loss: 0.915648]\n",
      "epoch:14 step:13186 [D loss: 0.674201, acc.: 54.69%] [G loss: 0.891700]\n",
      "epoch:14 step:13187 [D loss: 0.675142, acc.: 64.84%] [G loss: 0.956089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13188 [D loss: 0.579256, acc.: 71.88%] [G loss: 0.963567]\n",
      "epoch:14 step:13189 [D loss: 0.560497, acc.: 72.66%] [G loss: 1.043381]\n",
      "epoch:14 step:13190 [D loss: 0.550928, acc.: 74.22%] [G loss: 1.021495]\n",
      "epoch:14 step:13191 [D loss: 0.667743, acc.: 57.81%] [G loss: 1.181767]\n",
      "epoch:14 step:13192 [D loss: 0.567890, acc.: 74.22%] [G loss: 1.083633]\n",
      "epoch:14 step:13193 [D loss: 0.367045, acc.: 89.06%] [G loss: 1.275367]\n",
      "epoch:14 step:13194 [D loss: 0.427626, acc.: 85.94%] [G loss: 1.404635]\n",
      "epoch:14 step:13195 [D loss: 0.515992, acc.: 76.56%] [G loss: 1.276474]\n",
      "epoch:14 step:13196 [D loss: 0.659927, acc.: 59.38%] [G loss: 1.308330]\n",
      "epoch:14 step:13197 [D loss: 0.700305, acc.: 59.38%] [G loss: 1.000102]\n",
      "epoch:14 step:13198 [D loss: 0.620808, acc.: 58.59%] [G loss: 1.004726]\n",
      "epoch:14 step:13199 [D loss: 0.738491, acc.: 50.00%] [G loss: 1.027670]\n",
      "epoch:14 step:13200 [D loss: 0.671327, acc.: 61.72%] [G loss: 0.949558]\n",
      "epoch:14 step:13201 [D loss: 0.734269, acc.: 50.78%] [G loss: 0.743876]\n",
      "epoch:14 step:13202 [D loss: 0.667235, acc.: 62.50%] [G loss: 0.966805]\n",
      "epoch:14 step:13203 [D loss: 0.609695, acc.: 66.41%] [G loss: 0.971855]\n",
      "epoch:14 step:13204 [D loss: 0.610277, acc.: 67.97%] [G loss: 1.008955]\n",
      "epoch:14 step:13205 [D loss: 0.635718, acc.: 60.16%] [G loss: 0.827787]\n",
      "epoch:14 step:13206 [D loss: 0.654367, acc.: 59.38%] [G loss: 0.894640]\n",
      "epoch:14 step:13207 [D loss: 0.650186, acc.: 59.38%] [G loss: 0.957467]\n",
      "epoch:14 step:13208 [D loss: 0.553118, acc.: 75.78%] [G loss: 1.079256]\n",
      "epoch:14 step:13209 [D loss: 0.651929, acc.: 60.94%] [G loss: 1.045501]\n",
      "epoch:14 step:13210 [D loss: 0.499449, acc.: 80.47%] [G loss: 1.167485]\n",
      "epoch:14 step:13211 [D loss: 0.589758, acc.: 68.75%] [G loss: 1.073790]\n",
      "epoch:14 step:13212 [D loss: 0.726586, acc.: 52.34%] [G loss: 0.939284]\n",
      "epoch:14 step:13213 [D loss: 0.636373, acc.: 63.28%] [G loss: 1.129274]\n",
      "epoch:14 step:13214 [D loss: 0.766589, acc.: 42.19%] [G loss: 0.790959]\n",
      "epoch:14 step:13215 [D loss: 0.654337, acc.: 62.50%] [G loss: 0.832623]\n",
      "epoch:14 step:13216 [D loss: 0.840120, acc.: 35.16%] [G loss: 0.816367]\n",
      "epoch:14 step:13217 [D loss: 0.692937, acc.: 53.12%] [G loss: 1.015901]\n",
      "epoch:14 step:13218 [D loss: 0.723262, acc.: 57.03%] [G loss: 1.077993]\n",
      "epoch:14 step:13219 [D loss: 0.618651, acc.: 62.50%] [G loss: 0.885594]\n",
      "epoch:14 step:13220 [D loss: 0.726022, acc.: 58.59%] [G loss: 1.023164]\n",
      "epoch:14 step:13221 [D loss: 0.585036, acc.: 72.66%] [G loss: 1.144093]\n",
      "epoch:14 step:13222 [D loss: 0.669462, acc.: 61.72%] [G loss: 0.870694]\n",
      "epoch:14 step:13223 [D loss: 0.681863, acc.: 56.25%] [G loss: 1.047513]\n",
      "epoch:14 step:13224 [D loss: 0.676933, acc.: 60.16%] [G loss: 0.897408]\n",
      "epoch:14 step:13225 [D loss: 0.568624, acc.: 69.53%] [G loss: 1.197858]\n",
      "epoch:14 step:13226 [D loss: 0.803507, acc.: 43.75%] [G loss: 1.065766]\n",
      "epoch:14 step:13227 [D loss: 0.580511, acc.: 71.88%] [G loss: 1.184949]\n",
      "epoch:14 step:13228 [D loss: 0.526288, acc.: 74.22%] [G loss: 1.069941]\n",
      "epoch:14 step:13229 [D loss: 0.586314, acc.: 68.75%] [G loss: 1.037986]\n",
      "epoch:14 step:13230 [D loss: 0.657375, acc.: 63.28%] [G loss: 1.013242]\n",
      "epoch:14 step:13231 [D loss: 0.678491, acc.: 56.25%] [G loss: 1.016421]\n",
      "epoch:14 step:13232 [D loss: 0.726142, acc.: 53.91%] [G loss: 0.899785]\n",
      "epoch:14 step:13233 [D loss: 0.702319, acc.: 58.59%] [G loss: 1.065994]\n",
      "epoch:14 step:13234 [D loss: 0.631605, acc.: 65.62%] [G loss: 0.983927]\n",
      "epoch:14 step:13235 [D loss: 0.639043, acc.: 62.50%] [G loss: 1.036960]\n",
      "epoch:14 step:13236 [D loss: 0.524364, acc.: 78.12%] [G loss: 1.018874]\n",
      "epoch:14 step:13237 [D loss: 0.462952, acc.: 80.47%] [G loss: 1.100142]\n",
      "epoch:14 step:13238 [D loss: 0.809698, acc.: 44.53%] [G loss: 1.096884]\n",
      "epoch:14 step:13239 [D loss: 0.677795, acc.: 55.47%] [G loss: 1.147236]\n",
      "epoch:14 step:13240 [D loss: 0.577032, acc.: 75.00%] [G loss: 1.237511]\n",
      "epoch:14 step:13241 [D loss: 0.651961, acc.: 57.81%] [G loss: 1.180042]\n",
      "epoch:14 step:13242 [D loss: 0.704811, acc.: 54.69%] [G loss: 0.936993]\n",
      "epoch:14 step:13243 [D loss: 0.745810, acc.: 50.00%] [G loss: 0.968874]\n",
      "epoch:14 step:13244 [D loss: 0.662608, acc.: 60.16%] [G loss: 0.893089]\n",
      "epoch:14 step:13245 [D loss: 0.673940, acc.: 57.81%] [G loss: 1.050516]\n",
      "epoch:14 step:13246 [D loss: 0.601912, acc.: 67.97%] [G loss: 1.023432]\n",
      "epoch:14 step:13247 [D loss: 0.704444, acc.: 53.91%] [G loss: 0.914742]\n",
      "epoch:14 step:13248 [D loss: 0.562762, acc.: 71.88%] [G loss: 1.019180]\n",
      "epoch:14 step:13249 [D loss: 0.526354, acc.: 77.34%] [G loss: 1.069738]\n",
      "epoch:14 step:13250 [D loss: 0.585420, acc.: 71.09%] [G loss: 1.091259]\n",
      "epoch:14 step:13251 [D loss: 0.756563, acc.: 52.34%] [G loss: 0.880015]\n",
      "epoch:14 step:13252 [D loss: 0.720813, acc.: 54.69%] [G loss: 0.985188]\n",
      "epoch:14 step:13253 [D loss: 0.657529, acc.: 62.50%] [G loss: 1.068106]\n",
      "epoch:14 step:13254 [D loss: 0.643567, acc.: 64.06%] [G loss: 1.033266]\n",
      "epoch:14 step:13255 [D loss: 0.717972, acc.: 56.25%] [G loss: 0.861525]\n",
      "epoch:14 step:13256 [D loss: 0.667624, acc.: 60.16%] [G loss: 0.927125]\n",
      "epoch:14 step:13257 [D loss: 0.632220, acc.: 59.38%] [G loss: 1.124429]\n",
      "epoch:14 step:13258 [D loss: 0.632916, acc.: 61.72%] [G loss: 1.013395]\n",
      "epoch:14 step:13259 [D loss: 0.650638, acc.: 57.03%] [G loss: 1.063986]\n",
      "epoch:14 step:13260 [D loss: 0.601397, acc.: 67.19%] [G loss: 1.040468]\n",
      "epoch:14 step:13261 [D loss: 0.704327, acc.: 58.59%] [G loss: 1.067669]\n",
      "epoch:14 step:13262 [D loss: 0.617925, acc.: 66.41%] [G loss: 1.196272]\n",
      "epoch:14 step:13263 [D loss: 0.570932, acc.: 71.09%] [G loss: 0.979635]\n",
      "epoch:14 step:13264 [D loss: 0.619767, acc.: 65.62%] [G loss: 1.105981]\n",
      "epoch:14 step:13265 [D loss: 0.715957, acc.: 52.34%] [G loss: 1.095100]\n",
      "epoch:14 step:13266 [D loss: 0.816157, acc.: 39.06%] [G loss: 0.971244]\n",
      "epoch:14 step:13267 [D loss: 0.791930, acc.: 49.22%] [G loss: 0.858723]\n",
      "epoch:14 step:13268 [D loss: 0.546701, acc.: 76.56%] [G loss: 1.084134]\n",
      "epoch:14 step:13269 [D loss: 0.559557, acc.: 72.66%] [G loss: 1.106050]\n",
      "epoch:14 step:13270 [D loss: 0.399439, acc.: 88.28%] [G loss: 1.240346]\n",
      "epoch:14 step:13271 [D loss: 0.715050, acc.: 54.69%] [G loss: 0.968540]\n",
      "epoch:14 step:13272 [D loss: 0.699884, acc.: 59.38%] [G loss: 0.981665]\n",
      "epoch:14 step:13273 [D loss: 0.627188, acc.: 64.84%] [G loss: 0.961769]\n",
      "epoch:14 step:13274 [D loss: 0.562517, acc.: 73.44%] [G loss: 0.968607]\n",
      "epoch:14 step:13275 [D loss: 0.743716, acc.: 53.12%] [G loss: 1.032544]\n",
      "epoch:14 step:13276 [D loss: 0.582636, acc.: 74.22%] [G loss: 1.189870]\n",
      "epoch:14 step:13277 [D loss: 0.486373, acc.: 85.16%] [G loss: 1.297543]\n",
      "epoch:14 step:13278 [D loss: 0.792154, acc.: 46.88%] [G loss: 1.045771]\n",
      "epoch:14 step:13279 [D loss: 0.722996, acc.: 53.91%] [G loss: 0.883169]\n",
      "epoch:14 step:13280 [D loss: 0.653576, acc.: 56.25%] [G loss: 0.906197]\n",
      "epoch:14 step:13281 [D loss: 0.654579, acc.: 62.50%] [G loss: 0.991589]\n",
      "epoch:14 step:13282 [D loss: 0.579758, acc.: 71.09%] [G loss: 0.930491]\n",
      "epoch:14 step:13283 [D loss: 0.687970, acc.: 54.69%] [G loss: 0.854305]\n",
      "epoch:14 step:13284 [D loss: 0.617970, acc.: 63.28%] [G loss: 1.092974]\n",
      "epoch:14 step:13285 [D loss: 0.562780, acc.: 75.78%] [G loss: 1.207462]\n",
      "epoch:14 step:13286 [D loss: 0.572759, acc.: 71.09%] [G loss: 1.122204]\n",
      "epoch:14 step:13287 [D loss: 0.569407, acc.: 71.88%] [G loss: 1.029210]\n",
      "epoch:14 step:13288 [D loss: 0.789306, acc.: 46.09%] [G loss: 0.868997]\n",
      "epoch:14 step:13289 [D loss: 0.682750, acc.: 56.25%] [G loss: 1.077323]\n",
      "epoch:14 step:13290 [D loss: 0.688583, acc.: 57.03%] [G loss: 0.937470]\n",
      "epoch:14 step:13291 [D loss: 0.690107, acc.: 59.38%] [G loss: 0.930730]\n",
      "epoch:14 step:13292 [D loss: 0.772461, acc.: 49.22%] [G loss: 1.032827]\n",
      "epoch:14 step:13293 [D loss: 0.800185, acc.: 41.41%] [G loss: 0.788937]\n",
      "epoch:14 step:13294 [D loss: 0.750409, acc.: 49.22%] [G loss: 0.899539]\n",
      "epoch:14 step:13295 [D loss: 0.858644, acc.: 45.31%] [G loss: 1.000030]\n",
      "epoch:14 step:13296 [D loss: 0.809792, acc.: 42.97%] [G loss: 1.024126]\n",
      "epoch:14 step:13297 [D loss: 0.820940, acc.: 40.62%] [G loss: 0.884654]\n",
      "epoch:14 step:13298 [D loss: 0.739347, acc.: 52.34%] [G loss: 0.945679]\n",
      "epoch:14 step:13299 [D loss: 0.579859, acc.: 71.09%] [G loss: 1.141695]\n",
      "epoch:14 step:13300 [D loss: 0.651312, acc.: 61.72%] [G loss: 0.955979]\n",
      "epoch:14 step:13301 [D loss: 0.739062, acc.: 51.56%] [G loss: 0.894531]\n",
      "epoch:14 step:13302 [D loss: 0.764947, acc.: 45.31%] [G loss: 0.967580]\n",
      "epoch:14 step:13303 [D loss: 0.761767, acc.: 43.75%] [G loss: 0.983550]\n",
      "epoch:14 step:13304 [D loss: 0.836347, acc.: 41.41%] [G loss: 0.790469]\n",
      "epoch:14 step:13305 [D loss: 0.726820, acc.: 53.91%] [G loss: 0.845066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13306 [D loss: 0.649238, acc.: 63.28%] [G loss: 0.844627]\n",
      "epoch:14 step:13307 [D loss: 0.759633, acc.: 49.22%] [G loss: 0.967531]\n",
      "epoch:14 step:13308 [D loss: 0.618229, acc.: 67.97%] [G loss: 1.232090]\n",
      "epoch:14 step:13309 [D loss: 0.643885, acc.: 61.72%] [G loss: 0.984907]\n",
      "epoch:14 step:13310 [D loss: 0.487421, acc.: 78.91%] [G loss: 1.208318]\n",
      "epoch:14 step:13311 [D loss: 0.763943, acc.: 48.44%] [G loss: 0.867091]\n",
      "epoch:14 step:13312 [D loss: 0.614720, acc.: 61.72%] [G loss: 1.136554]\n",
      "epoch:14 step:13313 [D loss: 0.585655, acc.: 71.09%] [G loss: 1.100138]\n",
      "epoch:14 step:13314 [D loss: 0.865952, acc.: 36.72%] [G loss: 0.929432]\n",
      "epoch:14 step:13315 [D loss: 0.616705, acc.: 67.97%] [G loss: 0.908003]\n",
      "epoch:14 step:13316 [D loss: 0.621872, acc.: 63.28%] [G loss: 1.007017]\n",
      "epoch:14 step:13317 [D loss: 0.648266, acc.: 57.03%] [G loss: 0.931666]\n",
      "epoch:14 step:13318 [D loss: 0.584227, acc.: 70.31%] [G loss: 0.883402]\n",
      "epoch:14 step:13319 [D loss: 0.565803, acc.: 72.66%] [G loss: 1.093248]\n",
      "epoch:14 step:13320 [D loss: 0.632309, acc.: 70.31%] [G loss: 1.150398]\n",
      "epoch:14 step:13321 [D loss: 0.790388, acc.: 43.75%] [G loss: 0.935924]\n",
      "epoch:14 step:13322 [D loss: 0.774941, acc.: 44.53%] [G loss: 0.882722]\n",
      "epoch:14 step:13323 [D loss: 0.723830, acc.: 53.12%] [G loss: 0.786318]\n",
      "epoch:14 step:13324 [D loss: 0.610914, acc.: 64.84%] [G loss: 1.004778]\n",
      "epoch:14 step:13325 [D loss: 0.650041, acc.: 58.59%] [G loss: 0.855252]\n",
      "epoch:14 step:13326 [D loss: 0.646925, acc.: 61.72%] [G loss: 0.950039]\n",
      "epoch:14 step:13327 [D loss: 0.558666, acc.: 72.66%] [G loss: 0.933901]\n",
      "epoch:14 step:13328 [D loss: 0.718448, acc.: 54.69%] [G loss: 0.886018]\n",
      "epoch:14 step:13329 [D loss: 0.740388, acc.: 53.12%] [G loss: 0.967897]\n",
      "epoch:14 step:13330 [D loss: 0.719647, acc.: 49.22%] [G loss: 0.919806]\n",
      "epoch:14 step:13331 [D loss: 0.596093, acc.: 66.41%] [G loss: 0.995788]\n",
      "epoch:14 step:13332 [D loss: 0.750243, acc.: 47.66%] [G loss: 1.009531]\n",
      "epoch:14 step:13333 [D loss: 0.732795, acc.: 52.34%] [G loss: 0.754640]\n",
      "epoch:14 step:13334 [D loss: 0.623906, acc.: 66.41%] [G loss: 0.967320]\n",
      "epoch:14 step:13335 [D loss: 0.657306, acc.: 57.81%] [G loss: 0.942487]\n",
      "epoch:14 step:13336 [D loss: 0.648941, acc.: 61.72%] [G loss: 1.051208]\n",
      "epoch:14 step:13337 [D loss: 0.612789, acc.: 70.31%] [G loss: 1.017847]\n",
      "epoch:14 step:13338 [D loss: 0.429443, acc.: 85.16%] [G loss: 1.217826]\n",
      "epoch:14 step:13339 [D loss: 0.479321, acc.: 80.47%] [G loss: 1.073717]\n",
      "epoch:14 step:13340 [D loss: 0.441417, acc.: 86.72%] [G loss: 1.344251]\n",
      "epoch:14 step:13341 [D loss: 0.454935, acc.: 85.94%] [G loss: 1.030061]\n",
      "epoch:14 step:13342 [D loss: 0.684190, acc.: 56.25%] [G loss: 1.174396]\n",
      "epoch:14 step:13343 [D loss: 0.686402, acc.: 53.91%] [G loss: 1.117248]\n",
      "epoch:14 step:13344 [D loss: 0.603151, acc.: 64.84%] [G loss: 1.073314]\n",
      "epoch:14 step:13345 [D loss: 0.665763, acc.: 60.94%] [G loss: 1.000285]\n",
      "epoch:14 step:13346 [D loss: 0.675686, acc.: 59.38%] [G loss: 1.013514]\n",
      "epoch:14 step:13347 [D loss: 0.536605, acc.: 73.44%] [G loss: 1.007802]\n",
      "epoch:14 step:13348 [D loss: 0.368776, acc.: 85.94%] [G loss: 1.054220]\n",
      "epoch:14 step:13349 [D loss: 0.361021, acc.: 92.19%] [G loss: 1.173787]\n",
      "epoch:14 step:13350 [D loss: 0.434712, acc.: 82.03%] [G loss: 1.409452]\n",
      "epoch:14 step:13351 [D loss: 0.747473, acc.: 53.12%] [G loss: 1.282156]\n",
      "epoch:14 step:13352 [D loss: 0.807314, acc.: 52.34%] [G loss: 1.100389]\n",
      "epoch:14 step:13353 [D loss: 0.643962, acc.: 62.50%] [G loss: 0.919912]\n",
      "epoch:14 step:13354 [D loss: 0.622872, acc.: 64.06%] [G loss: 0.990452]\n",
      "epoch:14 step:13355 [D loss: 0.627536, acc.: 62.50%] [G loss: 0.934379]\n",
      "epoch:14 step:13356 [D loss: 0.688610, acc.: 60.16%] [G loss: 0.962008]\n",
      "epoch:14 step:13357 [D loss: 0.612787, acc.: 67.19%] [G loss: 1.179804]\n",
      "epoch:14 step:13358 [D loss: 0.750504, acc.: 50.78%] [G loss: 0.850118]\n",
      "epoch:14 step:13359 [D loss: 0.789812, acc.: 46.09%] [G loss: 1.018769]\n",
      "epoch:14 step:13360 [D loss: 0.634272, acc.: 63.28%] [G loss: 1.020124]\n",
      "epoch:14 step:13361 [D loss: 0.765625, acc.: 48.44%] [G loss: 1.007286]\n",
      "epoch:14 step:13362 [D loss: 0.681665, acc.: 50.78%] [G loss: 0.766184]\n",
      "epoch:14 step:13363 [D loss: 0.766421, acc.: 47.66%] [G loss: 0.936911]\n",
      "epoch:14 step:13364 [D loss: 0.774381, acc.: 53.12%] [G loss: 0.943495]\n",
      "epoch:14 step:13365 [D loss: 0.640460, acc.: 65.62%] [G loss: 1.004271]\n",
      "epoch:14 step:13366 [D loss: 0.616227, acc.: 67.19%] [G loss: 1.002688]\n",
      "epoch:14 step:13367 [D loss: 0.693097, acc.: 57.03%] [G loss: 0.929654]\n",
      "epoch:14 step:13368 [D loss: 0.608942, acc.: 63.28%] [G loss: 1.136708]\n",
      "epoch:14 step:13369 [D loss: 0.643487, acc.: 57.81%] [G loss: 0.913825]\n",
      "epoch:14 step:13370 [D loss: 0.720944, acc.: 50.00%] [G loss: 0.861197]\n",
      "epoch:14 step:13371 [D loss: 0.585429, acc.: 73.44%] [G loss: 1.031602]\n",
      "epoch:14 step:13372 [D loss: 0.628611, acc.: 68.75%] [G loss: 0.947923]\n",
      "epoch:14 step:13373 [D loss: 0.602877, acc.: 67.19%] [G loss: 0.977055]\n",
      "epoch:14 step:13374 [D loss: 0.687102, acc.: 59.38%] [G loss: 0.973904]\n",
      "epoch:14 step:13375 [D loss: 0.718623, acc.: 51.56%] [G loss: 0.869894]\n",
      "epoch:14 step:13376 [D loss: 0.682414, acc.: 54.69%] [G loss: 0.913471]\n",
      "epoch:14 step:13377 [D loss: 0.621687, acc.: 65.62%] [G loss: 0.925822]\n",
      "epoch:14 step:13378 [D loss: 0.735066, acc.: 53.91%] [G loss: 0.928428]\n",
      "epoch:14 step:13379 [D loss: 0.694629, acc.: 61.72%] [G loss: 0.913430]\n",
      "epoch:14 step:13380 [D loss: 0.637415, acc.: 60.94%] [G loss: 1.211928]\n",
      "epoch:14 step:13381 [D loss: 0.652201, acc.: 60.16%] [G loss: 0.841712]\n",
      "epoch:14 step:13382 [D loss: 0.621260, acc.: 65.62%] [G loss: 1.060286]\n",
      "epoch:14 step:13383 [D loss: 0.617763, acc.: 65.62%] [G loss: 0.998082]\n",
      "epoch:14 step:13384 [D loss: 0.640240, acc.: 61.72%] [G loss: 1.019747]\n",
      "epoch:14 step:13385 [D loss: 0.691441, acc.: 60.16%] [G loss: 0.941828]\n",
      "epoch:14 step:13386 [D loss: 0.651124, acc.: 59.38%] [G loss: 0.896621]\n",
      "epoch:14 step:13387 [D loss: 0.636385, acc.: 64.06%] [G loss: 0.929782]\n",
      "epoch:14 step:13388 [D loss: 0.710451, acc.: 52.34%] [G loss: 0.828641]\n",
      "epoch:14 step:13389 [D loss: 0.676861, acc.: 57.81%] [G loss: 0.904848]\n",
      "epoch:14 step:13390 [D loss: 0.626094, acc.: 65.62%] [G loss: 0.883159]\n",
      "epoch:14 step:13391 [D loss: 0.563937, acc.: 73.44%] [G loss: 1.005056]\n",
      "epoch:14 step:13392 [D loss: 0.684894, acc.: 57.03%] [G loss: 0.863245]\n",
      "epoch:14 step:13393 [D loss: 0.717532, acc.: 60.94%] [G loss: 0.995781]\n",
      "epoch:14 step:13394 [D loss: 0.793771, acc.: 44.53%] [G loss: 0.924565]\n",
      "epoch:14 step:13395 [D loss: 0.793129, acc.: 48.44%] [G loss: 0.879274]\n",
      "epoch:14 step:13396 [D loss: 0.596863, acc.: 67.19%] [G loss: 1.002670]\n",
      "epoch:14 step:13397 [D loss: 0.501863, acc.: 81.25%] [G loss: 1.110614]\n",
      "epoch:14 step:13398 [D loss: 0.531892, acc.: 80.47%] [G loss: 0.990790]\n",
      "epoch:14 step:13399 [D loss: 0.711043, acc.: 53.91%] [G loss: 0.848720]\n",
      "epoch:14 step:13400 [D loss: 0.622527, acc.: 67.19%] [G loss: 1.123206]\n",
      "epoch:14 step:13401 [D loss: 0.658377, acc.: 64.06%] [G loss: 1.095701]\n",
      "epoch:14 step:13402 [D loss: 0.503111, acc.: 80.47%] [G loss: 1.031234]\n",
      "epoch:14 step:13403 [D loss: 0.589674, acc.: 69.53%] [G loss: 1.021864]\n",
      "epoch:14 step:13404 [D loss: 0.433545, acc.: 89.06%] [G loss: 1.511129]\n",
      "epoch:14 step:13405 [D loss: 0.567481, acc.: 72.66%] [G loss: 1.063362]\n",
      "epoch:14 step:13406 [D loss: 0.538142, acc.: 75.00%] [G loss: 1.140143]\n",
      "epoch:14 step:13407 [D loss: 0.488993, acc.: 79.69%] [G loss: 1.052670]\n",
      "epoch:14 step:13408 [D loss: 0.821449, acc.: 42.97%] [G loss: 0.830832]\n",
      "epoch:14 step:13409 [D loss: 0.468030, acc.: 79.69%] [G loss: 1.299186]\n",
      "epoch:14 step:13410 [D loss: 0.630977, acc.: 59.38%] [G loss: 1.141661]\n",
      "epoch:14 step:13411 [D loss: 0.448203, acc.: 79.69%] [G loss: 1.059679]\n",
      "epoch:14 step:13412 [D loss: 0.632535, acc.: 65.62%] [G loss: 0.880526]\n",
      "epoch:14 step:13413 [D loss: 0.779439, acc.: 53.12%] [G loss: 0.984388]\n",
      "epoch:14 step:13414 [D loss: 0.677643, acc.: 60.16%] [G loss: 0.904091]\n",
      "epoch:14 step:13415 [D loss: 0.836021, acc.: 37.50%] [G loss: 1.037773]\n",
      "epoch:14 step:13416 [D loss: 0.712036, acc.: 54.69%] [G loss: 0.945331]\n",
      "epoch:14 step:13417 [D loss: 0.671107, acc.: 61.72%] [G loss: 1.005736]\n",
      "epoch:14 step:13418 [D loss: 0.647800, acc.: 64.84%] [G loss: 0.875046]\n",
      "epoch:14 step:13419 [D loss: 0.718520, acc.: 52.34%] [G loss: 0.808112]\n",
      "epoch:14 step:13420 [D loss: 0.470614, acc.: 83.59%] [G loss: 1.160853]\n",
      "epoch:14 step:13421 [D loss: 0.638948, acc.: 63.28%] [G loss: 0.955086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13422 [D loss: 0.747518, acc.: 49.22%] [G loss: 0.969950]\n",
      "epoch:14 step:13423 [D loss: 0.625394, acc.: 65.62%] [G loss: 0.933733]\n",
      "epoch:14 step:13424 [D loss: 0.666765, acc.: 59.38%] [G loss: 1.035462]\n",
      "epoch:14 step:13425 [D loss: 0.712392, acc.: 56.25%] [G loss: 0.918894]\n",
      "epoch:14 step:13426 [D loss: 0.597341, acc.: 67.97%] [G loss: 0.910275]\n",
      "epoch:14 step:13427 [D loss: 0.540445, acc.: 72.66%] [G loss: 1.115449]\n",
      "epoch:14 step:13428 [D loss: 0.709572, acc.: 57.03%] [G loss: 0.884548]\n",
      "epoch:14 step:13429 [D loss: 0.657812, acc.: 62.50%] [G loss: 0.981360]\n",
      "epoch:14 step:13430 [D loss: 0.473426, acc.: 78.91%] [G loss: 1.053902]\n",
      "epoch:14 step:13431 [D loss: 0.484131, acc.: 78.12%] [G loss: 1.077873]\n",
      "epoch:14 step:13432 [D loss: 0.539623, acc.: 74.22%] [G loss: 1.086607]\n",
      "epoch:14 step:13433 [D loss: 0.670506, acc.: 60.94%] [G loss: 1.000606]\n",
      "epoch:14 step:13434 [D loss: 0.661932, acc.: 54.69%] [G loss: 1.287292]\n",
      "epoch:14 step:13435 [D loss: 0.670962, acc.: 61.72%] [G loss: 1.066502]\n",
      "epoch:14 step:13436 [D loss: 0.601804, acc.: 66.41%] [G loss: 1.183746]\n",
      "epoch:14 step:13437 [D loss: 0.605646, acc.: 67.19%] [G loss: 0.853269]\n",
      "epoch:14 step:13438 [D loss: 0.561208, acc.: 72.66%] [G loss: 1.124050]\n",
      "epoch:14 step:13439 [D loss: 0.567442, acc.: 69.53%] [G loss: 1.066590]\n",
      "epoch:14 step:13440 [D loss: 0.506579, acc.: 78.12%] [G loss: 1.132758]\n",
      "epoch:14 step:13441 [D loss: 0.771502, acc.: 49.22%] [G loss: 1.091340]\n",
      "epoch:14 step:13442 [D loss: 0.686239, acc.: 54.69%] [G loss: 0.936433]\n",
      "epoch:14 step:13443 [D loss: 0.663138, acc.: 60.16%] [G loss: 0.838410]\n",
      "epoch:14 step:13444 [D loss: 0.565967, acc.: 67.19%] [G loss: 1.039369]\n",
      "epoch:14 step:13445 [D loss: 0.494740, acc.: 76.56%] [G loss: 0.999551]\n",
      "epoch:14 step:13446 [D loss: 0.475809, acc.: 83.59%] [G loss: 1.166587]\n",
      "epoch:14 step:13447 [D loss: 0.642622, acc.: 62.50%] [G loss: 1.136596]\n",
      "epoch:14 step:13448 [D loss: 0.704987, acc.: 56.25%] [G loss: 1.170409]\n",
      "epoch:14 step:13449 [D loss: 0.735196, acc.: 52.34%] [G loss: 0.836520]\n",
      "epoch:14 step:13450 [D loss: 0.705775, acc.: 57.03%] [G loss: 0.903685]\n",
      "epoch:14 step:13451 [D loss: 0.632382, acc.: 67.19%] [G loss: 0.954030]\n",
      "epoch:14 step:13452 [D loss: 0.730937, acc.: 51.56%] [G loss: 0.934040]\n",
      "epoch:14 step:13453 [D loss: 0.676406, acc.: 58.59%] [G loss: 0.871725]\n",
      "epoch:14 step:13454 [D loss: 0.600453, acc.: 67.97%] [G loss: 1.040673]\n",
      "epoch:14 step:13455 [D loss: 0.629937, acc.: 57.81%] [G loss: 1.030903]\n",
      "epoch:14 step:13456 [D loss: 0.632675, acc.: 66.41%] [G loss: 1.015579]\n",
      "epoch:14 step:13457 [D loss: 0.624126, acc.: 64.84%] [G loss: 0.988836]\n",
      "epoch:14 step:13458 [D loss: 0.596384, acc.: 70.31%] [G loss: 1.011901]\n",
      "epoch:14 step:13459 [D loss: 0.728291, acc.: 48.44%] [G loss: 1.186965]\n",
      "epoch:14 step:13460 [D loss: 0.661121, acc.: 57.03%] [G loss: 0.941407]\n",
      "epoch:14 step:13461 [D loss: 0.465938, acc.: 77.34%] [G loss: 1.072340]\n",
      "epoch:14 step:13462 [D loss: 0.514601, acc.: 77.34%] [G loss: 1.158844]\n",
      "epoch:14 step:13463 [D loss: 0.457614, acc.: 82.81%] [G loss: 1.326834]\n",
      "epoch:14 step:13464 [D loss: 0.319634, acc.: 94.53%] [G loss: 1.366284]\n",
      "epoch:14 step:13465 [D loss: 0.554743, acc.: 67.19%] [G loss: 1.273394]\n",
      "epoch:14 step:13466 [D loss: 0.738252, acc.: 55.47%] [G loss: 1.305856]\n",
      "epoch:14 step:13467 [D loss: 0.737287, acc.: 53.12%] [G loss: 1.100881]\n",
      "epoch:14 step:13468 [D loss: 0.699510, acc.: 53.91%] [G loss: 0.859734]\n",
      "epoch:14 step:13469 [D loss: 0.669294, acc.: 60.94%] [G loss: 0.805235]\n",
      "epoch:14 step:13470 [D loss: 0.608066, acc.: 70.31%] [G loss: 0.982662]\n",
      "epoch:14 step:13471 [D loss: 0.630934, acc.: 61.72%] [G loss: 0.835934]\n",
      "epoch:14 step:13472 [D loss: 0.580002, acc.: 75.78%] [G loss: 0.915593]\n",
      "epoch:14 step:13473 [D loss: 0.727999, acc.: 49.22%] [G loss: 0.881989]\n",
      "epoch:14 step:13474 [D loss: 0.647151, acc.: 63.28%] [G loss: 0.861510]\n",
      "epoch:14 step:13475 [D loss: 0.592847, acc.: 69.53%] [G loss: 1.004117]\n",
      "epoch:14 step:13476 [D loss: 0.577193, acc.: 72.66%] [G loss: 1.032443]\n",
      "epoch:14 step:13477 [D loss: 0.607291, acc.: 69.53%] [G loss: 0.990419]\n",
      "epoch:14 step:13478 [D loss: 0.574868, acc.: 66.41%] [G loss: 1.231316]\n",
      "epoch:14 step:13479 [D loss: 0.672576, acc.: 57.03%] [G loss: 1.157896]\n",
      "epoch:14 step:13480 [D loss: 0.724940, acc.: 55.47%] [G loss: 0.855526]\n",
      "epoch:14 step:13481 [D loss: 0.627044, acc.: 63.28%] [G loss: 0.899390]\n",
      "epoch:14 step:13482 [D loss: 0.698522, acc.: 56.25%] [G loss: 0.946598]\n",
      "epoch:14 step:13483 [D loss: 0.650202, acc.: 65.62%] [G loss: 1.060718]\n",
      "epoch:14 step:13484 [D loss: 0.564985, acc.: 75.00%] [G loss: 1.013870]\n",
      "epoch:14 step:13485 [D loss: 0.586107, acc.: 67.19%] [G loss: 1.140977]\n",
      "epoch:14 step:13486 [D loss: 0.636170, acc.: 64.06%] [G loss: 1.110775]\n",
      "epoch:14 step:13487 [D loss: 0.649333, acc.: 63.28%] [G loss: 1.033838]\n",
      "epoch:14 step:13488 [D loss: 0.560013, acc.: 70.31%] [G loss: 1.047255]\n",
      "epoch:14 step:13489 [D loss: 0.666072, acc.: 54.69%] [G loss: 1.090152]\n",
      "epoch:14 step:13490 [D loss: 0.619569, acc.: 63.28%] [G loss: 0.946697]\n",
      "epoch:14 step:13491 [D loss: 0.777137, acc.: 47.66%] [G loss: 1.006872]\n",
      "epoch:14 step:13492 [D loss: 0.778970, acc.: 43.75%] [G loss: 0.863602]\n",
      "epoch:14 step:13493 [D loss: 0.717653, acc.: 60.16%] [G loss: 0.888024]\n",
      "epoch:14 step:13494 [D loss: 0.742193, acc.: 53.91%] [G loss: 0.856145]\n",
      "epoch:14 step:13495 [D loss: 0.732530, acc.: 47.66%] [G loss: 0.948541]\n",
      "epoch:14 step:13496 [D loss: 0.505937, acc.: 80.47%] [G loss: 0.975437]\n",
      "epoch:14 step:13497 [D loss: 0.723464, acc.: 51.56%] [G loss: 1.119787]\n",
      "epoch:14 step:13498 [D loss: 0.699960, acc.: 57.81%] [G loss: 1.009069]\n",
      "epoch:14 step:13499 [D loss: 0.557835, acc.: 73.44%] [G loss: 0.986720]\n",
      "epoch:14 step:13500 [D loss: 0.637439, acc.: 64.84%] [G loss: 0.833106]\n",
      "epoch:14 step:13501 [D loss: 0.718180, acc.: 50.00%] [G loss: 0.984141]\n",
      "epoch:14 step:13502 [D loss: 0.645752, acc.: 59.38%] [G loss: 0.976300]\n",
      "epoch:14 step:13503 [D loss: 0.676406, acc.: 57.81%] [G loss: 1.003593]\n",
      "epoch:14 step:13504 [D loss: 0.699040, acc.: 55.47%] [G loss: 1.093753]\n",
      "epoch:14 step:13505 [D loss: 0.600247, acc.: 69.53%] [G loss: 0.974600]\n",
      "epoch:14 step:13506 [D loss: 0.625998, acc.: 67.19%] [G loss: 0.924565]\n",
      "epoch:14 step:13507 [D loss: 0.690071, acc.: 50.00%] [G loss: 1.105070]\n",
      "epoch:14 step:13508 [D loss: 0.520139, acc.: 78.12%] [G loss: 1.155482]\n",
      "epoch:14 step:13509 [D loss: 0.613660, acc.: 65.62%] [G loss: 0.960110]\n",
      "epoch:14 step:13510 [D loss: 0.532173, acc.: 78.12%] [G loss: 1.087688]\n",
      "epoch:14 step:13511 [D loss: 0.653770, acc.: 63.28%] [G loss: 0.926336]\n",
      "epoch:14 step:13512 [D loss: 0.526041, acc.: 77.34%] [G loss: 0.970653]\n",
      "epoch:14 step:13513 [D loss: 0.743934, acc.: 48.44%] [G loss: 0.738370]\n",
      "epoch:14 step:13514 [D loss: 0.643032, acc.: 60.16%] [G loss: 1.026275]\n",
      "epoch:14 step:13515 [D loss: 0.494070, acc.: 76.56%] [G loss: 1.061727]\n",
      "epoch:14 step:13516 [D loss: 0.415097, acc.: 85.94%] [G loss: 1.228451]\n",
      "epoch:14 step:13517 [D loss: 0.459879, acc.: 85.16%] [G loss: 1.436611]\n",
      "epoch:14 step:13518 [D loss: 0.579230, acc.: 69.53%] [G loss: 1.220114]\n",
      "epoch:14 step:13519 [D loss: 0.553748, acc.: 75.78%] [G loss: 1.141994]\n",
      "epoch:14 step:13520 [D loss: 0.538008, acc.: 76.56%] [G loss: 1.119543]\n",
      "epoch:14 step:13521 [D loss: 0.764467, acc.: 50.78%] [G loss: 1.007386]\n",
      "epoch:14 step:13522 [D loss: 0.476528, acc.: 82.81%] [G loss: 1.313301]\n",
      "epoch:14 step:13523 [D loss: 0.461807, acc.: 84.38%] [G loss: 1.324664]\n",
      "epoch:14 step:13524 [D loss: 0.527786, acc.: 76.56%] [G loss: 1.136650]\n",
      "epoch:14 step:13525 [D loss: 0.587980, acc.: 67.97%] [G loss: 1.369769]\n",
      "epoch:14 step:13526 [D loss: 0.877250, acc.: 39.84%] [G loss: 0.907361]\n",
      "epoch:14 step:13527 [D loss: 0.857760, acc.: 47.66%] [G loss: 0.825029]\n",
      "epoch:14 step:13528 [D loss: 0.578154, acc.: 71.09%] [G loss: 1.209613]\n",
      "epoch:14 step:13529 [D loss: 0.923399, acc.: 26.56%] [G loss: 0.765738]\n",
      "epoch:14 step:13530 [D loss: 0.811792, acc.: 43.75%] [G loss: 1.012155]\n",
      "epoch:14 step:13531 [D loss: 0.930192, acc.: 34.38%] [G loss: 0.824441]\n",
      "epoch:14 step:13532 [D loss: 0.815218, acc.: 46.88%] [G loss: 1.040054]\n",
      "epoch:14 step:13533 [D loss: 0.782375, acc.: 46.88%] [G loss: 0.863357]\n",
      "epoch:14 step:13534 [D loss: 0.640933, acc.: 61.72%] [G loss: 1.066824]\n",
      "epoch:14 step:13535 [D loss: 0.790216, acc.: 42.97%] [G loss: 0.902810]\n",
      "epoch:14 step:13536 [D loss: 0.564480, acc.: 73.44%] [G loss: 0.851045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13537 [D loss: 0.712176, acc.: 56.25%] [G loss: 0.815250]\n",
      "epoch:14 step:13538 [D loss: 0.748015, acc.: 50.78%] [G loss: 0.889317]\n",
      "epoch:14 step:13539 [D loss: 0.763395, acc.: 50.78%] [G loss: 0.992600]\n",
      "epoch:14 step:13540 [D loss: 0.633309, acc.: 61.72%] [G loss: 1.150045]\n",
      "epoch:14 step:13541 [D loss: 0.735037, acc.: 50.78%] [G loss: 1.296121]\n",
      "epoch:14 step:13542 [D loss: 0.709722, acc.: 56.25%] [G loss: 1.004069]\n",
      "epoch:14 step:13543 [D loss: 0.622624, acc.: 66.41%] [G loss: 1.024290]\n",
      "epoch:14 step:13544 [D loss: 0.579887, acc.: 74.22%] [G loss: 1.244459]\n",
      "epoch:14 step:13545 [D loss: 0.623636, acc.: 70.31%] [G loss: 0.878509]\n",
      "epoch:14 step:13546 [D loss: 0.585486, acc.: 67.97%] [G loss: 1.016496]\n",
      "epoch:14 step:13547 [D loss: 0.687533, acc.: 64.84%] [G loss: 0.920397]\n",
      "epoch:14 step:13548 [D loss: 0.581844, acc.: 68.75%] [G loss: 1.130564]\n",
      "epoch:14 step:13549 [D loss: 0.593184, acc.: 68.75%] [G loss: 1.046321]\n",
      "epoch:14 step:13550 [D loss: 0.537811, acc.: 71.09%] [G loss: 1.055022]\n",
      "epoch:14 step:13551 [D loss: 0.432852, acc.: 85.94%] [G loss: 1.467387]\n",
      "epoch:14 step:13552 [D loss: 0.463320, acc.: 78.91%] [G loss: 1.237428]\n",
      "epoch:14 step:13553 [D loss: 0.359817, acc.: 92.19%] [G loss: 1.240813]\n",
      "epoch:14 step:13554 [D loss: 0.520280, acc.: 77.34%] [G loss: 1.187315]\n",
      "epoch:14 step:13555 [D loss: 0.742929, acc.: 53.12%] [G loss: 0.913952]\n",
      "epoch:14 step:13556 [D loss: 0.613162, acc.: 67.19%] [G loss: 1.194086]\n",
      "epoch:14 step:13557 [D loss: 0.635954, acc.: 60.94%] [G loss: 1.151508]\n",
      "epoch:14 step:13558 [D loss: 0.592146, acc.: 68.75%] [G loss: 1.185506]\n",
      "epoch:14 step:13559 [D loss: 0.610890, acc.: 63.28%] [G loss: 0.971348]\n",
      "epoch:14 step:13560 [D loss: 0.641903, acc.: 62.50%] [G loss: 1.190283]\n",
      "epoch:14 step:13561 [D loss: 0.546990, acc.: 76.56%] [G loss: 1.112503]\n",
      "epoch:14 step:13562 [D loss: 0.733607, acc.: 53.91%] [G loss: 1.061065]\n",
      "epoch:14 step:13563 [D loss: 0.630091, acc.: 64.06%] [G loss: 0.994328]\n",
      "epoch:14 step:13564 [D loss: 0.750968, acc.: 51.56%] [G loss: 1.050911]\n",
      "epoch:14 step:13565 [D loss: 0.652140, acc.: 63.28%] [G loss: 1.031000]\n",
      "epoch:14 step:13566 [D loss: 0.535066, acc.: 76.56%] [G loss: 1.063542]\n",
      "epoch:14 step:13567 [D loss: 0.402394, acc.: 89.06%] [G loss: 1.191021]\n",
      "epoch:14 step:13568 [D loss: 0.539717, acc.: 77.34%] [G loss: 1.071161]\n",
      "epoch:14 step:13569 [D loss: 0.515123, acc.: 75.78%] [G loss: 1.135857]\n",
      "epoch:14 step:13570 [D loss: 0.423028, acc.: 89.06%] [G loss: 1.369589]\n",
      "epoch:14 step:13571 [D loss: 0.463150, acc.: 85.16%] [G loss: 1.345169]\n",
      "epoch:14 step:13572 [D loss: 0.649422, acc.: 64.06%] [G loss: 0.879199]\n",
      "epoch:14 step:13573 [D loss: 0.462389, acc.: 82.03%] [G loss: 1.456290]\n",
      "epoch:14 step:13574 [D loss: 0.618587, acc.: 62.50%] [G loss: 1.056765]\n",
      "epoch:14 step:13575 [D loss: 0.385136, acc.: 88.28%] [G loss: 1.215091]\n",
      "epoch:14 step:13576 [D loss: 0.912406, acc.: 42.97%] [G loss: 1.024808]\n",
      "epoch:14 step:13577 [D loss: 0.910602, acc.: 35.16%] [G loss: 0.725312]\n",
      "epoch:14 step:13578 [D loss: 0.849142, acc.: 42.19%] [G loss: 0.913089]\n",
      "epoch:14 step:13579 [D loss: 0.901254, acc.: 28.91%] [G loss: 0.828115]\n",
      "epoch:14 step:13580 [D loss: 1.067878, acc.: 21.88%] [G loss: 0.729531]\n",
      "epoch:14 step:13581 [D loss: 0.814871, acc.: 42.97%] [G loss: 0.955444]\n",
      "epoch:14 step:13582 [D loss: 0.630490, acc.: 64.84%] [G loss: 1.048261]\n",
      "epoch:14 step:13583 [D loss: 0.690822, acc.: 60.94%] [G loss: 1.240308]\n",
      "epoch:14 step:13584 [D loss: 0.764373, acc.: 50.78%] [G loss: 1.042029]\n",
      "epoch:14 step:13585 [D loss: 0.705207, acc.: 53.12%] [G loss: 0.956354]\n",
      "epoch:14 step:13586 [D loss: 0.553968, acc.: 71.88%] [G loss: 1.125023]\n",
      "epoch:14 step:13587 [D loss: 0.622089, acc.: 66.41%] [G loss: 1.043708]\n",
      "epoch:14 step:13588 [D loss: 0.587444, acc.: 71.09%] [G loss: 1.087054]\n",
      "epoch:14 step:13589 [D loss: 0.458024, acc.: 78.12%] [G loss: 1.109288]\n",
      "epoch:14 step:13590 [D loss: 0.611066, acc.: 67.19%] [G loss: 1.099917]\n",
      "epoch:14 step:13591 [D loss: 0.832938, acc.: 43.75%] [G loss: 1.101808]\n",
      "epoch:14 step:13592 [D loss: 0.572573, acc.: 71.09%] [G loss: 1.190283]\n",
      "epoch:14 step:13593 [D loss: 0.596707, acc.: 66.41%] [G loss: 1.159108]\n",
      "epoch:14 step:13594 [D loss: 0.745841, acc.: 50.78%] [G loss: 1.214212]\n",
      "epoch:14 step:13595 [D loss: 0.766871, acc.: 50.00%] [G loss: 1.001103]\n",
      "epoch:14 step:13596 [D loss: 0.663082, acc.: 60.94%] [G loss: 1.029249]\n",
      "epoch:14 step:13597 [D loss: 0.612571, acc.: 68.75%] [G loss: 1.191847]\n",
      "epoch:14 step:13598 [D loss: 0.637219, acc.: 66.41%] [G loss: 0.898218]\n",
      "epoch:14 step:13599 [D loss: 0.652573, acc.: 60.94%] [G loss: 0.998890]\n",
      "epoch:14 step:13600 [D loss: 0.466739, acc.: 82.81%] [G loss: 1.067290]\n",
      "epoch:14 step:13601 [D loss: 0.455662, acc.: 83.59%] [G loss: 1.235896]\n",
      "epoch:14 step:13602 [D loss: 0.395590, acc.: 84.38%] [G loss: 1.264751]\n",
      "epoch:14 step:13603 [D loss: 0.473486, acc.: 82.03%] [G loss: 1.447289]\n",
      "epoch:14 step:13604 [D loss: 0.624318, acc.: 66.41%] [G loss: 1.103257]\n",
      "epoch:14 step:13605 [D loss: 0.483107, acc.: 79.69%] [G loss: 1.386647]\n",
      "epoch:14 step:13606 [D loss: 0.452930, acc.: 85.94%] [G loss: 1.265811]\n",
      "epoch:14 step:13607 [D loss: 0.863049, acc.: 39.06%] [G loss: 1.039210]\n",
      "epoch:14 step:13608 [D loss: 0.729630, acc.: 50.00%] [G loss: 1.104992]\n",
      "epoch:14 step:13609 [D loss: 0.588854, acc.: 70.31%] [G loss: 0.984925]\n",
      "epoch:14 step:13610 [D loss: 0.545415, acc.: 75.78%] [G loss: 1.048219]\n",
      "epoch:14 step:13611 [D loss: 0.645384, acc.: 60.94%] [G loss: 0.938898]\n",
      "epoch:14 step:13612 [D loss: 0.757393, acc.: 50.78%] [G loss: 0.912711]\n",
      "epoch:14 step:13613 [D loss: 0.545923, acc.: 75.78%] [G loss: 1.112386]\n",
      "epoch:14 step:13614 [D loss: 0.566810, acc.: 71.09%] [G loss: 0.958702]\n",
      "epoch:14 step:13615 [D loss: 0.473965, acc.: 78.12%] [G loss: 1.135430]\n",
      "epoch:14 step:13616 [D loss: 0.320054, acc.: 98.44%] [G loss: 1.210436]\n",
      "epoch:14 step:13617 [D loss: 0.330620, acc.: 93.75%] [G loss: 1.497540]\n",
      "epoch:14 step:13618 [D loss: 0.780618, acc.: 45.31%] [G loss: 1.109432]\n",
      "epoch:14 step:13619 [D loss: 0.718642, acc.: 47.66%] [G loss: 1.133475]\n",
      "epoch:14 step:13620 [D loss: 0.787012, acc.: 42.97%] [G loss: 0.997103]\n",
      "epoch:14 step:13621 [D loss: 0.752613, acc.: 50.00%] [G loss: 1.007613]\n",
      "epoch:14 step:13622 [D loss: 0.578786, acc.: 71.88%] [G loss: 1.005689]\n",
      "epoch:14 step:13623 [D loss: 0.591940, acc.: 69.53%] [G loss: 1.043865]\n",
      "epoch:14 step:13624 [D loss: 0.671747, acc.: 60.16%] [G loss: 1.033240]\n",
      "epoch:14 step:13625 [D loss: 0.719677, acc.: 60.16%] [G loss: 1.133853]\n",
      "epoch:14 step:13626 [D loss: 0.546278, acc.: 78.12%] [G loss: 1.167009]\n",
      "epoch:14 step:13627 [D loss: 0.707983, acc.: 50.78%] [G loss: 0.858631]\n",
      "epoch:14 step:13628 [D loss: 0.663386, acc.: 59.38%] [G loss: 0.970152]\n",
      "epoch:14 step:13629 [D loss: 0.602548, acc.: 64.06%] [G loss: 1.068031]\n",
      "epoch:14 step:13630 [D loss: 0.637794, acc.: 64.06%] [G loss: 0.945853]\n",
      "epoch:14 step:13631 [D loss: 0.483675, acc.: 83.59%] [G loss: 1.069597]\n",
      "epoch:14 step:13632 [D loss: 0.602872, acc.: 68.75%] [G loss: 1.186395]\n",
      "epoch:14 step:13633 [D loss: 0.531385, acc.: 74.22%] [G loss: 0.981544]\n",
      "epoch:14 step:13634 [D loss: 0.578249, acc.: 69.53%] [G loss: 1.144251]\n",
      "epoch:14 step:13635 [D loss: 0.721205, acc.: 49.22%] [G loss: 0.918151]\n",
      "epoch:14 step:13636 [D loss: 0.710711, acc.: 46.88%] [G loss: 0.877558]\n",
      "epoch:14 step:13637 [D loss: 0.556089, acc.: 75.00%] [G loss: 0.951203]\n",
      "epoch:14 step:13638 [D loss: 0.617575, acc.: 64.06%] [G loss: 0.890588]\n",
      "epoch:14 step:13639 [D loss: 0.611212, acc.: 66.41%] [G loss: 0.977761]\n",
      "epoch:14 step:13640 [D loss: 0.504592, acc.: 78.12%] [G loss: 1.109316]\n",
      "epoch:14 step:13641 [D loss: 0.496195, acc.: 82.03%] [G loss: 1.145988]\n",
      "epoch:14 step:13642 [D loss: 0.686879, acc.: 55.47%] [G loss: 1.036571]\n",
      "epoch:14 step:13643 [D loss: 0.715668, acc.: 53.12%] [G loss: 1.219489]\n",
      "epoch:14 step:13644 [D loss: 0.608067, acc.: 64.84%] [G loss: 1.072499]\n",
      "epoch:14 step:13645 [D loss: 0.649434, acc.: 61.72%] [G loss: 1.142570]\n",
      "epoch:14 step:13646 [D loss: 0.778251, acc.: 49.22%] [G loss: 1.001633]\n",
      "epoch:14 step:13647 [D loss: 0.629453, acc.: 66.41%] [G loss: 0.929607]\n",
      "epoch:14 step:13648 [D loss: 0.596770, acc.: 67.97%] [G loss: 0.840554]\n",
      "epoch:14 step:13649 [D loss: 0.725323, acc.: 52.34%] [G loss: 1.004376]\n",
      "epoch:14 step:13650 [D loss: 0.591949, acc.: 70.31%] [G loss: 1.059656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13651 [D loss: 0.463903, acc.: 82.81%] [G loss: 1.084000]\n",
      "epoch:14 step:13652 [D loss: 0.588179, acc.: 68.75%] [G loss: 1.247090]\n",
      "epoch:14 step:13653 [D loss: 0.601719, acc.: 67.19%] [G loss: 0.967389]\n",
      "epoch:14 step:13654 [D loss: 0.520401, acc.: 79.69%] [G loss: 1.078921]\n",
      "epoch:14 step:13655 [D loss: 0.581061, acc.: 67.19%] [G loss: 1.100797]\n",
      "epoch:14 step:13656 [D loss: 0.656797, acc.: 60.16%] [G loss: 1.141809]\n",
      "epoch:14 step:13657 [D loss: 0.625919, acc.: 64.06%] [G loss: 1.088632]\n",
      "epoch:14 step:13658 [D loss: 0.627662, acc.: 61.72%] [G loss: 1.087261]\n",
      "epoch:14 step:13659 [D loss: 0.737748, acc.: 50.00%] [G loss: 0.855141]\n",
      "epoch:14 step:13660 [D loss: 0.625144, acc.: 66.41%] [G loss: 0.879361]\n",
      "epoch:14 step:13661 [D loss: 0.562816, acc.: 75.00%] [G loss: 0.972845]\n",
      "epoch:14 step:13662 [D loss: 0.654529, acc.: 60.16%] [G loss: 0.930612]\n",
      "epoch:14 step:13663 [D loss: 0.509672, acc.: 78.12%] [G loss: 1.029034]\n",
      "epoch:14 step:13664 [D loss: 0.555747, acc.: 72.66%] [G loss: 1.019512]\n",
      "epoch:14 step:13665 [D loss: 0.467309, acc.: 84.38%] [G loss: 1.090431]\n",
      "epoch:14 step:13666 [D loss: 0.530868, acc.: 72.66%] [G loss: 1.217366]\n",
      "epoch:14 step:13667 [D loss: 0.378980, acc.: 92.19%] [G loss: 1.186273]\n",
      "epoch:14 step:13668 [D loss: 0.413828, acc.: 87.50%] [G loss: 1.120183]\n",
      "epoch:14 step:13669 [D loss: 0.379104, acc.: 92.97%] [G loss: 1.379497]\n",
      "epoch:14 step:13670 [D loss: 0.512607, acc.: 78.12%] [G loss: 1.270116]\n",
      "epoch:14 step:13671 [D loss: 0.576824, acc.: 73.44%] [G loss: 1.011061]\n",
      "epoch:14 step:13672 [D loss: 0.414329, acc.: 89.84%] [G loss: 0.986765]\n",
      "epoch:14 step:13673 [D loss: 0.458135, acc.: 85.94%] [G loss: 1.090058]\n",
      "epoch:14 step:13674 [D loss: 0.418248, acc.: 85.16%] [G loss: 1.409131]\n",
      "epoch:14 step:13675 [D loss: 0.514803, acc.: 72.66%] [G loss: 1.188683]\n",
      "epoch:14 step:13676 [D loss: 0.556990, acc.: 72.66%] [G loss: 1.330821]\n",
      "epoch:14 step:13677 [D loss: 0.801819, acc.: 46.88%] [G loss: 1.286337]\n",
      "epoch:14 step:13678 [D loss: 0.870160, acc.: 47.66%] [G loss: 1.096241]\n",
      "epoch:14 step:13679 [D loss: 0.647439, acc.: 61.72%] [G loss: 0.938926]\n",
      "epoch:14 step:13680 [D loss: 0.653259, acc.: 58.59%] [G loss: 1.148686]\n",
      "epoch:14 step:13681 [D loss: 0.708807, acc.: 56.25%] [G loss: 0.947789]\n",
      "epoch:14 step:13682 [D loss: 0.628972, acc.: 66.41%] [G loss: 1.276681]\n",
      "epoch:14 step:13683 [D loss: 0.628381, acc.: 67.19%] [G loss: 0.992257]\n",
      "epoch:14 step:13684 [D loss: 0.535233, acc.: 70.31%] [G loss: 1.116718]\n",
      "epoch:14 step:13685 [D loss: 0.464616, acc.: 79.69%] [G loss: 1.225558]\n",
      "epoch:14 step:13686 [D loss: 0.657896, acc.: 64.84%] [G loss: 1.215783]\n",
      "epoch:14 step:13687 [D loss: 0.694608, acc.: 54.69%] [G loss: 0.979789]\n",
      "epoch:14 step:13688 [D loss: 0.658124, acc.: 60.94%] [G loss: 0.872800]\n",
      "epoch:14 step:13689 [D loss: 0.641239, acc.: 66.41%] [G loss: 1.019526]\n",
      "epoch:14 step:13690 [D loss: 0.635298, acc.: 58.59%] [G loss: 0.980772]\n",
      "epoch:14 step:13691 [D loss: 0.632573, acc.: 62.50%] [G loss: 0.937120]\n",
      "epoch:14 step:13692 [D loss: 0.618126, acc.: 69.53%] [G loss: 0.995660]\n",
      "epoch:14 step:13693 [D loss: 0.530093, acc.: 81.25%] [G loss: 0.967154]\n",
      "epoch:14 step:13694 [D loss: 0.604712, acc.: 68.75%] [G loss: 1.062224]\n",
      "epoch:14 step:13695 [D loss: 0.708201, acc.: 55.47%] [G loss: 0.902751]\n",
      "epoch:14 step:13696 [D loss: 0.544014, acc.: 75.78%] [G loss: 1.016461]\n",
      "epoch:14 step:13697 [D loss: 0.650613, acc.: 60.94%] [G loss: 1.009212]\n",
      "epoch:14 step:13698 [D loss: 0.831671, acc.: 41.41%] [G loss: 0.995801]\n",
      "epoch:14 step:13699 [D loss: 0.658037, acc.: 59.38%] [G loss: 0.922906]\n",
      "epoch:14 step:13700 [D loss: 0.820270, acc.: 42.19%] [G loss: 0.921624]\n",
      "epoch:14 step:13701 [D loss: 0.652412, acc.: 59.38%] [G loss: 0.907562]\n",
      "epoch:14 step:13702 [D loss: 0.732625, acc.: 54.69%] [G loss: 0.959578]\n",
      "epoch:14 step:13703 [D loss: 0.691222, acc.: 53.91%] [G loss: 0.892602]\n",
      "epoch:14 step:13704 [D loss: 0.568632, acc.: 74.22%] [G loss: 1.022438]\n",
      "epoch:14 step:13705 [D loss: 0.438198, acc.: 85.16%] [G loss: 1.090161]\n",
      "epoch:14 step:13706 [D loss: 0.525613, acc.: 76.56%] [G loss: 1.129205]\n",
      "epoch:14 step:13707 [D loss: 0.477293, acc.: 78.91%] [G loss: 1.268031]\n",
      "epoch:14 step:13708 [D loss: 0.650011, acc.: 60.94%] [G loss: 1.237414]\n",
      "epoch:14 step:13709 [D loss: 0.660536, acc.: 64.84%] [G loss: 1.065724]\n",
      "epoch:14 step:13710 [D loss: 0.559449, acc.: 73.44%] [G loss: 1.366305]\n",
      "epoch:14 step:13711 [D loss: 0.611173, acc.: 66.41%] [G loss: 1.001595]\n",
      "epoch:14 step:13712 [D loss: 0.763715, acc.: 54.69%] [G loss: 0.765650]\n",
      "epoch:14 step:13713 [D loss: 0.714365, acc.: 50.78%] [G loss: 0.891577]\n",
      "epoch:14 step:13714 [D loss: 0.579540, acc.: 70.31%] [G loss: 1.151991]\n",
      "epoch:14 step:13715 [D loss: 0.564097, acc.: 71.09%] [G loss: 1.027894]\n",
      "epoch:14 step:13716 [D loss: 0.372256, acc.: 88.28%] [G loss: 1.050508]\n",
      "epoch:14 step:13717 [D loss: 0.597265, acc.: 71.88%] [G loss: 1.114728]\n",
      "epoch:14 step:13718 [D loss: 0.707474, acc.: 53.91%] [G loss: 0.940805]\n",
      "epoch:14 step:13719 [D loss: 0.694226, acc.: 54.69%] [G loss: 1.011422]\n",
      "epoch:14 step:13720 [D loss: 0.643218, acc.: 60.16%] [G loss: 1.051163]\n",
      "epoch:14 step:13721 [D loss: 0.437850, acc.: 87.50%] [G loss: 1.191860]\n",
      "epoch:14 step:13722 [D loss: 0.483699, acc.: 78.12%] [G loss: 0.898211]\n",
      "epoch:14 step:13723 [D loss: 0.417817, acc.: 87.50%] [G loss: 1.218247]\n",
      "epoch:14 step:13724 [D loss: 0.664920, acc.: 57.03%] [G loss: 1.157860]\n",
      "epoch:14 step:13725 [D loss: 0.750867, acc.: 51.56%] [G loss: 1.100618]\n",
      "epoch:14 step:13726 [D loss: 0.645305, acc.: 64.06%] [G loss: 0.813527]\n",
      "epoch:14 step:13727 [D loss: 0.813626, acc.: 39.84%] [G loss: 0.905827]\n",
      "epoch:14 step:13728 [D loss: 0.705513, acc.: 57.81%] [G loss: 0.901283]\n",
      "epoch:14 step:13729 [D loss: 0.576071, acc.: 74.22%] [G loss: 1.245552]\n",
      "epoch:14 step:13730 [D loss: 0.699969, acc.: 56.25%] [G loss: 0.965672]\n",
      "epoch:14 step:13731 [D loss: 0.609528, acc.: 66.41%] [G loss: 0.957185]\n",
      "epoch:14 step:13732 [D loss: 0.542977, acc.: 75.00%] [G loss: 1.373123]\n",
      "epoch:14 step:13733 [D loss: 0.472921, acc.: 78.91%] [G loss: 1.095314]\n",
      "epoch:14 step:13734 [D loss: 0.448219, acc.: 82.03%] [G loss: 1.213549]\n",
      "epoch:14 step:13735 [D loss: 0.609493, acc.: 69.53%] [G loss: 0.985064]\n",
      "epoch:14 step:13736 [D loss: 0.816415, acc.: 43.75%] [G loss: 0.797265]\n",
      "epoch:14 step:13737 [D loss: 0.740210, acc.: 53.12%] [G loss: 1.095542]\n",
      "epoch:14 step:13738 [D loss: 0.760107, acc.: 42.19%] [G loss: 1.198024]\n",
      "epoch:14 step:13739 [D loss: 0.824669, acc.: 42.19%] [G loss: 0.857982]\n",
      "epoch:14 step:13740 [D loss: 0.752323, acc.: 52.34%] [G loss: 0.858933]\n",
      "epoch:14 step:13741 [D loss: 0.567767, acc.: 68.75%] [G loss: 1.141325]\n",
      "epoch:14 step:13742 [D loss: 0.585944, acc.: 66.41%] [G loss: 0.876852]\n",
      "epoch:14 step:13743 [D loss: 0.759074, acc.: 51.56%] [G loss: 1.014523]\n",
      "epoch:14 step:13744 [D loss: 0.805934, acc.: 44.53%] [G loss: 0.824237]\n",
      "epoch:14 step:13745 [D loss: 0.684875, acc.: 61.72%] [G loss: 1.209752]\n",
      "epoch:14 step:13746 [D loss: 0.772356, acc.: 44.53%] [G loss: 0.995798]\n",
      "epoch:14 step:13747 [D loss: 0.439246, acc.: 84.38%] [G loss: 1.042069]\n",
      "epoch:14 step:13748 [D loss: 0.477931, acc.: 78.91%] [G loss: 1.332292]\n",
      "epoch:14 step:13749 [D loss: 0.871495, acc.: 42.97%] [G loss: 0.969202]\n",
      "epoch:14 step:13750 [D loss: 0.624188, acc.: 63.28%] [G loss: 1.137396]\n",
      "epoch:14 step:13751 [D loss: 0.649599, acc.: 65.62%] [G loss: 1.237324]\n",
      "epoch:14 step:13752 [D loss: 0.511987, acc.: 77.34%] [G loss: 1.321342]\n",
      "epoch:14 step:13753 [D loss: 0.612031, acc.: 61.72%] [G loss: 0.985227]\n",
      "epoch:14 step:13754 [D loss: 0.718580, acc.: 56.25%] [G loss: 0.942129]\n",
      "epoch:14 step:13755 [D loss: 0.735890, acc.: 51.56%] [G loss: 1.020270]\n",
      "epoch:14 step:13756 [D loss: 0.667296, acc.: 60.16%] [G loss: 1.203977]\n",
      "epoch:14 step:13757 [D loss: 0.791761, acc.: 43.75%] [G loss: 1.002170]\n",
      "epoch:14 step:13758 [D loss: 0.575502, acc.: 68.75%] [G loss: 0.947612]\n",
      "epoch:14 step:13759 [D loss: 0.536540, acc.: 75.00%] [G loss: 1.138539]\n",
      "epoch:14 step:13760 [D loss: 0.397014, acc.: 85.94%] [G loss: 1.256935]\n",
      "epoch:14 step:13761 [D loss: 0.641336, acc.: 62.50%] [G loss: 1.288910]\n",
      "epoch:14 step:13762 [D loss: 0.722993, acc.: 54.69%] [G loss: 0.955363]\n",
      "epoch:14 step:13763 [D loss: 0.598621, acc.: 68.75%] [G loss: 1.106503]\n",
      "epoch:14 step:13764 [D loss: 0.651642, acc.: 63.28%] [G loss: 0.914391]\n",
      "epoch:14 step:13765 [D loss: 0.603751, acc.: 64.06%] [G loss: 0.880754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13766 [D loss: 0.602017, acc.: 71.09%] [G loss: 0.914809]\n",
      "epoch:14 step:13767 [D loss: 0.682091, acc.: 60.16%] [G loss: 0.971881]\n",
      "epoch:14 step:13768 [D loss: 0.652738, acc.: 65.62%] [G loss: 0.957713]\n",
      "epoch:14 step:13769 [D loss: 0.769260, acc.: 53.12%] [G loss: 0.856185]\n",
      "epoch:14 step:13770 [D loss: 0.666062, acc.: 58.59%] [G loss: 0.883367]\n",
      "epoch:14 step:13771 [D loss: 0.609164, acc.: 65.62%] [G loss: 1.080049]\n",
      "epoch:14 step:13772 [D loss: 0.526157, acc.: 79.69%] [G loss: 1.100118]\n",
      "epoch:14 step:13773 [D loss: 0.587508, acc.: 69.53%] [G loss: 1.203494]\n",
      "epoch:14 step:13774 [D loss: 0.527028, acc.: 80.47%] [G loss: 0.991373]\n",
      "epoch:14 step:13775 [D loss: 0.583951, acc.: 73.44%] [G loss: 1.212612]\n",
      "epoch:14 step:13776 [D loss: 0.572206, acc.: 71.88%] [G loss: 0.946389]\n",
      "epoch:14 step:13777 [D loss: 0.691492, acc.: 55.47%] [G loss: 0.980405]\n",
      "epoch:14 step:13778 [D loss: 0.622443, acc.: 62.50%] [G loss: 0.918961]\n",
      "epoch:14 step:13779 [D loss: 0.667395, acc.: 61.72%] [G loss: 1.070633]\n",
      "epoch:14 step:13780 [D loss: 0.606934, acc.: 67.19%] [G loss: 0.948397]\n",
      "epoch:14 step:13781 [D loss: 0.308582, acc.: 96.09%] [G loss: 1.384928]\n",
      "epoch:14 step:13782 [D loss: 0.401956, acc.: 86.72%] [G loss: 1.201083]\n",
      "epoch:14 step:13783 [D loss: 0.448120, acc.: 82.81%] [G loss: 1.343337]\n",
      "epoch:14 step:13784 [D loss: 0.586737, acc.: 67.19%] [G loss: 1.244078]\n",
      "epoch:14 step:13785 [D loss: 0.545548, acc.: 73.44%] [G loss: 1.116915]\n",
      "epoch:14 step:13786 [D loss: 0.740096, acc.: 48.44%] [G loss: 0.947489]\n",
      "epoch:14 step:13787 [D loss: 0.670305, acc.: 57.81%] [G loss: 0.912502]\n",
      "epoch:14 step:13788 [D loss: 0.663758, acc.: 59.38%] [G loss: 1.079208]\n",
      "epoch:14 step:13789 [D loss: 0.774175, acc.: 50.78%] [G loss: 0.865583]\n",
      "epoch:14 step:13790 [D loss: 0.780395, acc.: 45.31%] [G loss: 0.996765]\n",
      "epoch:14 step:13791 [D loss: 1.094949, acc.: 23.44%] [G loss: 0.795372]\n",
      "epoch:14 step:13792 [D loss: 0.710029, acc.: 57.81%] [G loss: 1.013347]\n",
      "epoch:14 step:13793 [D loss: 0.867992, acc.: 35.16%] [G loss: 0.814070]\n",
      "epoch:14 step:13794 [D loss: 0.598174, acc.: 71.09%] [G loss: 1.070476]\n",
      "epoch:14 step:13795 [D loss: 0.730192, acc.: 50.00%] [G loss: 0.975055]\n",
      "epoch:14 step:13796 [D loss: 0.763192, acc.: 49.22%] [G loss: 0.906336]\n",
      "epoch:14 step:13797 [D loss: 0.737020, acc.: 50.78%] [G loss: 1.054702]\n",
      "epoch:14 step:13798 [D loss: 0.643942, acc.: 61.72%] [G loss: 1.061728]\n",
      "epoch:14 step:13799 [D loss: 0.738147, acc.: 59.38%] [G loss: 0.895827]\n",
      "epoch:14 step:13800 [D loss: 0.764484, acc.: 50.78%] [G loss: 1.027016]\n",
      "epoch:14 step:13801 [D loss: 0.660357, acc.: 63.28%] [G loss: 1.082604]\n",
      "epoch:14 step:13802 [D loss: 0.701750, acc.: 56.25%] [G loss: 1.043215]\n",
      "epoch:14 step:13803 [D loss: 0.598235, acc.: 72.66%] [G loss: 1.138311]\n",
      "epoch:14 step:13804 [D loss: 0.725540, acc.: 52.34%] [G loss: 0.968533]\n",
      "epoch:14 step:13805 [D loss: 0.646360, acc.: 64.84%] [G loss: 1.103061]\n",
      "epoch:14 step:13806 [D loss: 0.526942, acc.: 82.81%] [G loss: 1.090292]\n",
      "epoch:14 step:13807 [D loss: 0.449442, acc.: 83.59%] [G loss: 1.211839]\n",
      "epoch:14 step:13808 [D loss: 0.356016, acc.: 90.62%] [G loss: 1.285108]\n",
      "epoch:14 step:13809 [D loss: 0.530680, acc.: 76.56%] [G loss: 1.290090]\n",
      "epoch:14 step:13810 [D loss: 0.523461, acc.: 72.66%] [G loss: 1.300162]\n",
      "epoch:14 step:13811 [D loss: 0.353501, acc.: 94.53%] [G loss: 1.473854]\n",
      "epoch:14 step:13812 [D loss: 0.388757, acc.: 90.62%] [G loss: 1.251443]\n",
      "epoch:14 step:13813 [D loss: 0.435606, acc.: 82.03%] [G loss: 1.253875]\n",
      "epoch:14 step:13814 [D loss: 0.734707, acc.: 53.91%] [G loss: 1.104323]\n",
      "epoch:14 step:13815 [D loss: 0.830764, acc.: 40.62%] [G loss: 0.887060]\n",
      "epoch:14 step:13816 [D loss: 0.843723, acc.: 39.84%] [G loss: 0.907310]\n",
      "epoch:14 step:13817 [D loss: 0.782839, acc.: 48.44%] [G loss: 0.970878]\n",
      "epoch:14 step:13818 [D loss: 0.769382, acc.: 45.31%] [G loss: 0.745496]\n",
      "epoch:14 step:13819 [D loss: 0.801744, acc.: 42.97%] [G loss: 0.796762]\n",
      "epoch:14 step:13820 [D loss: 0.728492, acc.: 55.47%] [G loss: 1.003331]\n",
      "epoch:14 step:13821 [D loss: 0.775756, acc.: 43.75%] [G loss: 0.869342]\n",
      "epoch:14 step:13822 [D loss: 0.763878, acc.: 46.88%] [G loss: 0.872401]\n",
      "epoch:14 step:13823 [D loss: 0.690799, acc.: 53.12%] [G loss: 1.085661]\n",
      "epoch:14 step:13824 [D loss: 0.600127, acc.: 66.41%] [G loss: 1.019788]\n",
      "epoch:14 step:13825 [D loss: 0.557594, acc.: 68.75%] [G loss: 0.977783]\n",
      "epoch:14 step:13826 [D loss: 0.494194, acc.: 78.12%] [G loss: 1.360202]\n",
      "epoch:14 step:13827 [D loss: 0.471533, acc.: 82.81%] [G loss: 1.165971]\n",
      "epoch:14 step:13828 [D loss: 0.721491, acc.: 55.47%] [G loss: 1.154395]\n",
      "epoch:14 step:13829 [D loss: 0.753809, acc.: 44.53%] [G loss: 0.888369]\n",
      "epoch:14 step:13830 [D loss: 0.596654, acc.: 66.41%] [G loss: 1.137386]\n",
      "epoch:14 step:13831 [D loss: 0.607756, acc.: 71.88%] [G loss: 0.999792]\n",
      "epoch:14 step:13832 [D loss: 0.616967, acc.: 67.97%] [G loss: 1.175980]\n",
      "epoch:14 step:13833 [D loss: 0.656672, acc.: 59.38%] [G loss: 0.982554]\n",
      "epoch:14 step:13834 [D loss: 0.900966, acc.: 34.38%] [G loss: 0.915088]\n",
      "epoch:14 step:13835 [D loss: 0.646822, acc.: 65.62%] [G loss: 0.921138]\n",
      "epoch:14 step:13836 [D loss: 0.839417, acc.: 37.50%] [G loss: 0.836887]\n",
      "epoch:14 step:13837 [D loss: 0.646153, acc.: 62.50%] [G loss: 0.970864]\n",
      "epoch:14 step:13838 [D loss: 0.618958, acc.: 66.41%] [G loss: 1.120561]\n",
      "epoch:14 step:13839 [D loss: 0.661816, acc.: 57.81%] [G loss: 1.015223]\n",
      "epoch:14 step:13840 [D loss: 0.641787, acc.: 59.38%] [G loss: 0.912435]\n",
      "epoch:14 step:13841 [D loss: 0.654286, acc.: 60.94%] [G loss: 0.870640]\n",
      "epoch:14 step:13842 [D loss: 0.553055, acc.: 78.12%] [G loss: 1.001440]\n",
      "epoch:14 step:13843 [D loss: 0.568694, acc.: 70.31%] [G loss: 1.161371]\n",
      "epoch:14 step:13844 [D loss: 0.611961, acc.: 63.28%] [G loss: 0.998370]\n",
      "epoch:14 step:13845 [D loss: 0.626597, acc.: 67.19%] [G loss: 0.966109]\n",
      "epoch:14 step:13846 [D loss: 0.478191, acc.: 82.81%] [G loss: 1.191943]\n",
      "epoch:14 step:13847 [D loss: 0.585469, acc.: 72.66%] [G loss: 1.078069]\n",
      "epoch:14 step:13848 [D loss: 0.561791, acc.: 75.00%] [G loss: 1.134300]\n",
      "epoch:14 step:13849 [D loss: 0.598261, acc.: 66.41%] [G loss: 0.985935]\n",
      "epoch:14 step:13850 [D loss: 0.482992, acc.: 80.47%] [G loss: 1.294732]\n",
      "epoch:14 step:13851 [D loss: 0.445366, acc.: 82.81%] [G loss: 1.253891]\n",
      "epoch:14 step:13852 [D loss: 0.783127, acc.: 43.75%] [G loss: 1.223528]\n",
      "epoch:14 step:13853 [D loss: 0.647473, acc.: 62.50%] [G loss: 1.123105]\n",
      "epoch:14 step:13854 [D loss: 0.684260, acc.: 57.03%] [G loss: 1.062666]\n",
      "epoch:14 step:13855 [D loss: 0.602976, acc.: 69.53%] [G loss: 1.049462]\n",
      "epoch:14 step:13856 [D loss: 0.541679, acc.: 75.78%] [G loss: 1.105543]\n",
      "epoch:14 step:13857 [D loss: 0.630737, acc.: 63.28%] [G loss: 0.797657]\n",
      "epoch:14 step:13858 [D loss: 0.609104, acc.: 61.72%] [G loss: 0.979747]\n",
      "epoch:14 step:13859 [D loss: 0.652848, acc.: 59.38%] [G loss: 1.030732]\n",
      "epoch:14 step:13860 [D loss: 0.723008, acc.: 52.34%] [G loss: 0.891452]\n",
      "epoch:14 step:13861 [D loss: 0.550228, acc.: 73.44%] [G loss: 0.975411]\n",
      "epoch:14 step:13862 [D loss: 0.596548, acc.: 73.44%] [G loss: 1.011358]\n",
      "epoch:14 step:13863 [D loss: 0.519323, acc.: 82.03%] [G loss: 1.218916]\n",
      "epoch:14 step:13864 [D loss: 0.489792, acc.: 86.72%] [G loss: 1.081230]\n",
      "epoch:14 step:13865 [D loss: 0.593181, acc.: 72.66%] [G loss: 1.126023]\n",
      "epoch:14 step:13866 [D loss: 0.657059, acc.: 65.62%] [G loss: 0.892872]\n",
      "epoch:14 step:13867 [D loss: 0.683895, acc.: 56.25%] [G loss: 1.072232]\n",
      "epoch:14 step:13868 [D loss: 0.538766, acc.: 74.22%] [G loss: 1.122601]\n",
      "epoch:14 step:13869 [D loss: 0.680088, acc.: 53.12%] [G loss: 1.143657]\n",
      "epoch:14 step:13870 [D loss: 0.789447, acc.: 46.88%] [G loss: 1.094968]\n",
      "epoch:14 step:13871 [D loss: 0.583205, acc.: 71.88%] [G loss: 0.991141]\n",
      "epoch:14 step:13872 [D loss: 0.696990, acc.: 58.59%] [G loss: 0.817119]\n",
      "epoch:14 step:13873 [D loss: 0.582303, acc.: 69.53%] [G loss: 0.971006]\n",
      "epoch:14 step:13874 [D loss: 0.629378, acc.: 66.41%] [G loss: 1.061095]\n",
      "epoch:14 step:13875 [D loss: 0.615079, acc.: 68.75%] [G loss: 0.951277]\n",
      "epoch:14 step:13876 [D loss: 0.733834, acc.: 55.47%] [G loss: 0.939668]\n",
      "epoch:14 step:13877 [D loss: 0.769036, acc.: 45.31%] [G loss: 0.891494]\n",
      "epoch:14 step:13878 [D loss: 0.623641, acc.: 61.72%] [G loss: 1.143219]\n",
      "epoch:14 step:13879 [D loss: 0.720497, acc.: 54.69%] [G loss: 0.992606]\n",
      "epoch:14 step:13880 [D loss: 0.723193, acc.: 54.69%] [G loss: 0.991816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13881 [D loss: 0.640933, acc.: 64.84%] [G loss: 0.884594]\n",
      "epoch:14 step:13882 [D loss: 0.685462, acc.: 57.03%] [G loss: 0.900328]\n",
      "epoch:14 step:13883 [D loss: 0.700416, acc.: 58.59%] [G loss: 1.036435]\n",
      "epoch:14 step:13884 [D loss: 0.674591, acc.: 59.38%] [G loss: 1.009918]\n",
      "epoch:14 step:13885 [D loss: 0.467664, acc.: 82.03%] [G loss: 0.992834]\n",
      "epoch:14 step:13886 [D loss: 0.537814, acc.: 79.69%] [G loss: 1.190374]\n",
      "epoch:14 step:13887 [D loss: 0.339833, acc.: 90.62%] [G loss: 1.387468]\n",
      "epoch:14 step:13888 [D loss: 0.637046, acc.: 60.16%] [G loss: 1.247984]\n",
      "epoch:14 step:13889 [D loss: 0.801642, acc.: 50.00%] [G loss: 0.984633]\n",
      "epoch:14 step:13890 [D loss: 0.758089, acc.: 45.31%] [G loss: 0.999616]\n",
      "epoch:14 step:13891 [D loss: 0.623602, acc.: 64.84%] [G loss: 1.102905]\n",
      "epoch:14 step:13892 [D loss: 0.337211, acc.: 89.84%] [G loss: 1.160257]\n",
      "epoch:14 step:13893 [D loss: 0.375302, acc.: 85.94%] [G loss: 1.080265]\n",
      "epoch:14 step:13894 [D loss: 0.642045, acc.: 64.06%] [G loss: 1.169003]\n",
      "epoch:14 step:13895 [D loss: 0.585190, acc.: 69.53%] [G loss: 1.211642]\n",
      "epoch:14 step:13896 [D loss: 0.790945, acc.: 46.09%] [G loss: 1.051160]\n",
      "epoch:14 step:13897 [D loss: 0.792300, acc.: 47.66%] [G loss: 1.128597]\n",
      "epoch:14 step:13898 [D loss: 0.692299, acc.: 57.03%] [G loss: 1.135582]\n",
      "epoch:14 step:13899 [D loss: 0.561196, acc.: 74.22%] [G loss: 1.000717]\n",
      "epoch:14 step:13900 [D loss: 0.507718, acc.: 79.69%] [G loss: 1.244519]\n",
      "epoch:14 step:13901 [D loss: 0.635457, acc.: 62.50%] [G loss: 1.133201]\n",
      "epoch:14 step:13902 [D loss: 0.716410, acc.: 51.56%] [G loss: 1.146343]\n",
      "epoch:14 step:13903 [D loss: 0.720557, acc.: 53.12%] [G loss: 0.836430]\n",
      "epoch:14 step:13904 [D loss: 0.508363, acc.: 81.25%] [G loss: 0.998451]\n",
      "epoch:14 step:13905 [D loss: 0.633538, acc.: 60.16%] [G loss: 1.151480]\n",
      "epoch:14 step:13906 [D loss: 0.712758, acc.: 55.47%] [G loss: 0.901513]\n",
      "epoch:14 step:13907 [D loss: 0.623464, acc.: 62.50%] [G loss: 1.164258]\n",
      "epoch:14 step:13908 [D loss: 0.524869, acc.: 73.44%] [G loss: 1.040591]\n",
      "epoch:14 step:13909 [D loss: 0.537715, acc.: 71.88%] [G loss: 1.088924]\n",
      "epoch:14 step:13910 [D loss: 0.388854, acc.: 88.28%] [G loss: 1.296065]\n",
      "epoch:14 step:13911 [D loss: 0.594141, acc.: 70.31%] [G loss: 1.075073]\n",
      "epoch:14 step:13912 [D loss: 0.398779, acc.: 89.06%] [G loss: 1.432869]\n",
      "epoch:14 step:13913 [D loss: 0.678985, acc.: 54.69%] [G loss: 1.222549]\n",
      "epoch:14 step:13914 [D loss: 0.644516, acc.: 57.81%] [G loss: 1.154946]\n",
      "epoch:14 step:13915 [D loss: 0.648550, acc.: 65.62%] [G loss: 1.160535]\n",
      "epoch:14 step:13916 [D loss: 0.691978, acc.: 54.69%] [G loss: 1.145208]\n",
      "epoch:14 step:13917 [D loss: 0.770559, acc.: 53.12%] [G loss: 1.033610]\n",
      "epoch:14 step:13918 [D loss: 0.701795, acc.: 50.78%] [G loss: 1.124866]\n",
      "epoch:14 step:13919 [D loss: 0.763353, acc.: 51.56%] [G loss: 0.836364]\n",
      "epoch:14 step:13920 [D loss: 0.776961, acc.: 44.53%] [G loss: 0.920433]\n",
      "epoch:14 step:13921 [D loss: 0.694157, acc.: 53.12%] [G loss: 1.141555]\n",
      "epoch:14 step:13922 [D loss: 0.576647, acc.: 70.31%] [G loss: 0.991280]\n",
      "epoch:14 step:13923 [D loss: 0.533745, acc.: 78.12%] [G loss: 1.056950]\n",
      "epoch:14 step:13924 [D loss: 0.525880, acc.: 72.66%] [G loss: 1.033529]\n",
      "epoch:14 step:13925 [D loss: 0.605820, acc.: 65.62%] [G loss: 0.980954]\n",
      "epoch:14 step:13926 [D loss: 0.540007, acc.: 73.44%] [G loss: 1.181698]\n",
      "epoch:14 step:13927 [D loss: 0.582573, acc.: 71.09%] [G loss: 0.950213]\n",
      "epoch:14 step:13928 [D loss: 0.559939, acc.: 75.00%] [G loss: 1.379479]\n",
      "epoch:14 step:13929 [D loss: 0.687209, acc.: 57.81%] [G loss: 1.127986]\n",
      "epoch:14 step:13930 [D loss: 0.712039, acc.: 56.25%] [G loss: 1.034035]\n",
      "epoch:14 step:13931 [D loss: 0.620283, acc.: 65.62%] [G loss: 0.990578]\n",
      "epoch:14 step:13932 [D loss: 0.658008, acc.: 58.59%] [G loss: 1.051606]\n",
      "epoch:14 step:13933 [D loss: 0.363017, acc.: 88.28%] [G loss: 1.093870]\n",
      "epoch:14 step:13934 [D loss: 0.454694, acc.: 86.72%] [G loss: 1.304685]\n",
      "epoch:14 step:13935 [D loss: 0.751468, acc.: 50.00%] [G loss: 1.064440]\n",
      "epoch:14 step:13936 [D loss: 0.626307, acc.: 64.84%] [G loss: 0.968875]\n",
      "epoch:14 step:13937 [D loss: 0.615936, acc.: 66.41%] [G loss: 1.062501]\n",
      "epoch:14 step:13938 [D loss: 0.743028, acc.: 49.22%] [G loss: 1.014491]\n",
      "epoch:14 step:13939 [D loss: 0.802546, acc.: 42.19%] [G loss: 0.827539]\n",
      "epoch:14 step:13940 [D loss: 0.667050, acc.: 57.03%] [G loss: 0.824440]\n",
      "epoch:14 step:13941 [D loss: 0.672281, acc.: 55.47%] [G loss: 0.997598]\n",
      "epoch:14 step:13942 [D loss: 0.523658, acc.: 78.91%] [G loss: 1.128020]\n",
      "epoch:14 step:13943 [D loss: 0.479981, acc.: 82.03%] [G loss: 1.149590]\n",
      "epoch:14 step:13944 [D loss: 0.765635, acc.: 50.00%] [G loss: 1.027170]\n",
      "epoch:14 step:13945 [D loss: 0.750803, acc.: 52.34%] [G loss: 1.180887]\n",
      "epoch:14 step:13946 [D loss: 0.640800, acc.: 67.19%] [G loss: 0.958793]\n",
      "epoch:14 step:13947 [D loss: 0.674243, acc.: 57.03%] [G loss: 0.875383]\n",
      "epoch:14 step:13948 [D loss: 0.625943, acc.: 64.06%] [G loss: 0.931871]\n",
      "epoch:14 step:13949 [D loss: 0.556878, acc.: 69.53%] [G loss: 1.083245]\n",
      "epoch:14 step:13950 [D loss: 0.532446, acc.: 74.22%] [G loss: 1.025330]\n",
      "epoch:14 step:13951 [D loss: 0.499088, acc.: 78.12%] [G loss: 1.285519]\n",
      "epoch:14 step:13952 [D loss: 0.686220, acc.: 55.47%] [G loss: 1.114770]\n",
      "epoch:14 step:13953 [D loss: 0.700389, acc.: 57.81%] [G loss: 0.934276]\n",
      "epoch:14 step:13954 [D loss: 0.687618, acc.: 57.03%] [G loss: 1.010845]\n",
      "epoch:14 step:13955 [D loss: 0.706369, acc.: 50.78%] [G loss: 0.941971]\n",
      "epoch:14 step:13956 [D loss: 0.657739, acc.: 64.06%] [G loss: 1.002403]\n",
      "epoch:14 step:13957 [D loss: 0.618090, acc.: 67.19%] [G loss: 1.142162]\n",
      "epoch:14 step:13958 [D loss: 0.568410, acc.: 69.53%] [G loss: 1.033932]\n",
      "epoch:14 step:13959 [D loss: 0.523258, acc.: 75.78%] [G loss: 1.154579]\n",
      "epoch:14 step:13960 [D loss: 0.519505, acc.: 77.34%] [G loss: 1.236702]\n",
      "epoch:14 step:13961 [D loss: 0.776161, acc.: 50.00%] [G loss: 1.007241]\n",
      "epoch:14 step:13962 [D loss: 0.740335, acc.: 54.69%] [G loss: 1.048848]\n",
      "epoch:14 step:13963 [D loss: 0.690195, acc.: 60.16%] [G loss: 0.881388]\n",
      "epoch:14 step:13964 [D loss: 0.587124, acc.: 65.62%] [G loss: 1.085278]\n",
      "epoch:14 step:13965 [D loss: 0.684913, acc.: 56.25%] [G loss: 0.945583]\n",
      "epoch:14 step:13966 [D loss: 0.685848, acc.: 59.38%] [G loss: 1.174513]\n",
      "epoch:14 step:13967 [D loss: 0.494904, acc.: 80.47%] [G loss: 1.173615]\n",
      "epoch:14 step:13968 [D loss: 0.519525, acc.: 79.69%] [G loss: 1.350560]\n",
      "epoch:14 step:13969 [D loss: 0.490298, acc.: 81.25%] [G loss: 1.150961]\n",
      "epoch:14 step:13970 [D loss: 0.353621, acc.: 94.53%] [G loss: 1.287694]\n",
      "epoch:14 step:13971 [D loss: 0.677170, acc.: 58.59%] [G loss: 0.977207]\n",
      "epoch:14 step:13972 [D loss: 0.535879, acc.: 75.00%] [G loss: 1.029096]\n",
      "epoch:14 step:13973 [D loss: 0.637609, acc.: 60.94%] [G loss: 1.406240]\n",
      "epoch:14 step:13974 [D loss: 0.579950, acc.: 69.53%] [G loss: 1.191459]\n",
      "epoch:14 step:13975 [D loss: 0.461125, acc.: 85.16%] [G loss: 1.287514]\n",
      "epoch:14 step:13976 [D loss: 0.918392, acc.: 39.84%] [G loss: 0.924008]\n",
      "epoch:14 step:13977 [D loss: 0.713462, acc.: 56.25%] [G loss: 0.981226]\n",
      "epoch:14 step:13978 [D loss: 0.682796, acc.: 60.16%] [G loss: 1.093752]\n",
      "epoch:14 step:13979 [D loss: 0.656838, acc.: 61.72%] [G loss: 1.008997]\n",
      "epoch:14 step:13980 [D loss: 0.744034, acc.: 51.56%] [G loss: 0.943532]\n",
      "epoch:14 step:13981 [D loss: 0.660394, acc.: 64.84%] [G loss: 0.934852]\n",
      "epoch:14 step:13982 [D loss: 0.669560, acc.: 61.72%] [G loss: 0.845869]\n",
      "epoch:14 step:13983 [D loss: 0.748103, acc.: 49.22%] [G loss: 1.019747]\n",
      "epoch:14 step:13984 [D loss: 0.609735, acc.: 63.28%] [G loss: 0.931746]\n",
      "epoch:14 step:13985 [D loss: 0.639271, acc.: 62.50%] [G loss: 0.992495]\n",
      "epoch:14 step:13986 [D loss: 0.578286, acc.: 70.31%] [G loss: 1.001463]\n",
      "epoch:14 step:13987 [D loss: 0.788641, acc.: 43.75%] [G loss: 0.808858]\n",
      "epoch:14 step:13988 [D loss: 0.711183, acc.: 57.03%] [G loss: 0.990291]\n",
      "epoch:14 step:13989 [D loss: 0.675235, acc.: 60.16%] [G loss: 0.844407]\n",
      "epoch:14 step:13990 [D loss: 0.668207, acc.: 59.38%] [G loss: 1.100233]\n",
      "epoch:14 step:13991 [D loss: 0.619533, acc.: 62.50%] [G loss: 1.030565]\n",
      "epoch:14 step:13992 [D loss: 0.572215, acc.: 71.09%] [G loss: 0.912502]\n",
      "epoch:14 step:13993 [D loss: 0.692362, acc.: 57.81%] [G loss: 0.781239]\n",
      "epoch:14 step:13994 [D loss: 0.614815, acc.: 66.41%] [G loss: 0.983495]\n",
      "epoch:14 step:13995 [D loss: 0.550350, acc.: 75.78%] [G loss: 1.214164]\n",
      "epoch:14 step:13996 [D loss: 0.536497, acc.: 77.34%] [G loss: 1.052834]\n",
      "epoch:14 step:13997 [D loss: 0.727202, acc.: 56.25%] [G loss: 1.107050]\n",
      "epoch:14 step:13998 [D loss: 0.694067, acc.: 58.59%] [G loss: 1.119255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13999 [D loss: 0.620027, acc.: 65.62%] [G loss: 0.818828]\n",
      "epoch:14 step:14000 [D loss: 0.707803, acc.: 46.88%] [G loss: 0.868705]\n",
      "epoch:14 step:14001 [D loss: 0.654663, acc.: 62.50%] [G loss: 0.988738]\n",
      "epoch:14 step:14002 [D loss: 0.618446, acc.: 61.72%] [G loss: 1.143144]\n",
      "epoch:14 step:14003 [D loss: 0.426280, acc.: 88.28%] [G loss: 1.241741]\n",
      "epoch:14 step:14004 [D loss: 0.512564, acc.: 80.47%] [G loss: 1.158806]\n",
      "epoch:14 step:14005 [D loss: 0.462780, acc.: 85.16%] [G loss: 1.246495]\n",
      "epoch:14 step:14006 [D loss: 0.498056, acc.: 80.47%] [G loss: 1.253139]\n",
      "epoch:14 step:14007 [D loss: 0.459248, acc.: 85.16%] [G loss: 1.190576]\n",
      "epoch:14 step:14008 [D loss: 0.451295, acc.: 82.81%] [G loss: 1.282960]\n",
      "epoch:14 step:14009 [D loss: 0.804514, acc.: 50.00%] [G loss: 1.152459]\n",
      "epoch:14 step:14010 [D loss: 0.674799, acc.: 60.94%] [G loss: 0.878255]\n",
      "epoch:14 step:14011 [D loss: 0.612373, acc.: 60.94%] [G loss: 1.193975]\n",
      "epoch:14 step:14012 [D loss: 0.518131, acc.: 77.34%] [G loss: 1.087469]\n",
      "epoch:14 step:14013 [D loss: 0.554617, acc.: 73.44%] [G loss: 1.078642]\n",
      "epoch:14 step:14014 [D loss: 0.546692, acc.: 72.66%] [G loss: 1.113238]\n",
      "epoch:14 step:14015 [D loss: 0.576545, acc.: 71.09%] [G loss: 1.107654]\n",
      "epoch:14 step:14016 [D loss: 0.424677, acc.: 84.38%] [G loss: 1.102117]\n",
      "epoch:14 step:14017 [D loss: 0.376595, acc.: 92.19%] [G loss: 1.129224]\n",
      "epoch:14 step:14018 [D loss: 0.404865, acc.: 86.72%] [G loss: 1.142092]\n",
      "epoch:14 step:14019 [D loss: 0.582271, acc.: 72.66%] [G loss: 1.046110]\n",
      "epoch:14 step:14020 [D loss: 0.643303, acc.: 60.94%] [G loss: 1.129185]\n",
      "epoch:14 step:14021 [D loss: 0.597895, acc.: 65.62%] [G loss: 1.056833]\n",
      "epoch:14 step:14022 [D loss: 0.800007, acc.: 43.75%] [G loss: 1.093205]\n",
      "epoch:14 step:14023 [D loss: 0.589627, acc.: 67.97%] [G loss: 1.116650]\n",
      "epoch:14 step:14024 [D loss: 0.782660, acc.: 47.66%] [G loss: 0.857205]\n",
      "epoch:14 step:14025 [D loss: 0.762099, acc.: 50.78%] [G loss: 0.957135]\n",
      "epoch:14 step:14026 [D loss: 0.774649, acc.: 48.44%] [G loss: 0.971715]\n",
      "epoch:14 step:14027 [D loss: 0.607700, acc.: 67.97%] [G loss: 0.985053]\n",
      "epoch:14 step:14028 [D loss: 0.532397, acc.: 75.00%] [G loss: 1.280100]\n",
      "epoch:14 step:14029 [D loss: 0.417466, acc.: 85.16%] [G loss: 1.103879]\n",
      "epoch:14 step:14030 [D loss: 0.308461, acc.: 89.06%] [G loss: 1.317886]\n",
      "epoch:14 step:14031 [D loss: 0.681036, acc.: 60.94%] [G loss: 1.408746]\n",
      "epoch:14 step:14032 [D loss: 0.735696, acc.: 48.44%] [G loss: 0.892169]\n",
      "epoch:14 step:14033 [D loss: 0.756369, acc.: 50.00%] [G loss: 0.830121]\n",
      "epoch:14 step:14034 [D loss: 0.729049, acc.: 58.59%] [G loss: 0.937567]\n",
      "epoch:14 step:14035 [D loss: 0.668371, acc.: 59.38%] [G loss: 1.030560]\n",
      "epoch:14 step:14036 [D loss: 0.600795, acc.: 67.97%] [G loss: 1.016418]\n",
      "epoch:14 step:14037 [D loss: 0.638578, acc.: 58.59%] [G loss: 0.887671]\n",
      "epoch:14 step:14038 [D loss: 0.458037, acc.: 85.94%] [G loss: 1.090345]\n",
      "epoch:14 step:14039 [D loss: 0.477174, acc.: 80.47%] [G loss: 1.236426]\n",
      "epoch:14 step:14040 [D loss: 0.586765, acc.: 68.75%] [G loss: 1.149451]\n",
      "epoch:14 step:14041 [D loss: 0.671574, acc.: 59.38%] [G loss: 0.911786]\n",
      "epoch:14 step:14042 [D loss: 0.509422, acc.: 76.56%] [G loss: 1.190395]\n",
      "epoch:14 step:14043 [D loss: 0.497249, acc.: 81.25%] [G loss: 1.185227]\n",
      "epoch:14 step:14044 [D loss: 0.518879, acc.: 75.78%] [G loss: 1.161434]\n",
      "epoch:14 step:14045 [D loss: 0.484514, acc.: 75.00%] [G loss: 0.928311]\n",
      "epoch:14 step:14046 [D loss: 0.796703, acc.: 49.22%] [G loss: 1.002813]\n",
      "epoch:14 step:14047 [D loss: 0.503650, acc.: 78.12%] [G loss: 1.185877]\n",
      "epoch:14 step:14048 [D loss: 0.513338, acc.: 76.56%] [G loss: 0.988618]\n",
      "epoch:14 step:14049 [D loss: 0.588079, acc.: 71.09%] [G loss: 1.053370]\n",
      "epoch:14 step:14050 [D loss: 0.593466, acc.: 68.75%] [G loss: 1.132601]\n",
      "epoch:14 step:14051 [D loss: 0.585598, acc.: 70.31%] [G loss: 1.117929]\n",
      "epoch:14 step:14052 [D loss: 0.447769, acc.: 81.25%] [G loss: 1.055376]\n",
      "epoch:14 step:14053 [D loss: 0.631397, acc.: 65.62%] [G loss: 0.983483]\n",
      "epoch:14 step:14054 [D loss: 0.517314, acc.: 78.12%] [G loss: 1.068668]\n",
      "epoch:14 step:14055 [D loss: 0.313742, acc.: 86.72%] [G loss: 1.437591]\n",
      "epoch:15 step:14056 [D loss: 0.715777, acc.: 56.25%] [G loss: 1.135745]\n",
      "epoch:15 step:14057 [D loss: 0.858144, acc.: 42.97%] [G loss: 0.945435]\n",
      "epoch:15 step:14058 [D loss: 0.754865, acc.: 46.88%] [G loss: 1.005083]\n",
      "epoch:15 step:14059 [D loss: 0.632697, acc.: 65.62%] [G loss: 1.109549]\n",
      "epoch:15 step:14060 [D loss: 0.697228, acc.: 57.03%] [G loss: 0.956721]\n",
      "epoch:15 step:14061 [D loss: 0.629140, acc.: 62.50%] [G loss: 1.105683]\n",
      "epoch:15 step:14062 [D loss: 0.581773, acc.: 67.19%] [G loss: 1.042202]\n",
      "epoch:15 step:14063 [D loss: 0.701653, acc.: 59.38%] [G loss: 0.890793]\n",
      "epoch:15 step:14064 [D loss: 0.523485, acc.: 78.12%] [G loss: 1.079345]\n",
      "epoch:15 step:14065 [D loss: 0.595972, acc.: 62.50%] [G loss: 0.973957]\n",
      "epoch:15 step:14066 [D loss: 0.617694, acc.: 71.88%] [G loss: 1.132586]\n",
      "epoch:15 step:14067 [D loss: 0.603467, acc.: 62.50%] [G loss: 0.877221]\n",
      "epoch:15 step:14068 [D loss: 0.634368, acc.: 63.28%] [G loss: 0.956612]\n",
      "epoch:15 step:14069 [D loss: 0.562175, acc.: 76.56%] [G loss: 1.056327]\n",
      "epoch:15 step:14070 [D loss: 0.507995, acc.: 75.00%] [G loss: 1.128930]\n",
      "epoch:15 step:14071 [D loss: 0.541677, acc.: 77.34%] [G loss: 1.224318]\n",
      "epoch:15 step:14072 [D loss: 0.731247, acc.: 57.03%] [G loss: 0.947679]\n",
      "epoch:15 step:14073 [D loss: 0.741162, acc.: 52.34%] [G loss: 1.144482]\n",
      "epoch:15 step:14074 [D loss: 0.688029, acc.: 55.47%] [G loss: 0.996417]\n",
      "epoch:15 step:14075 [D loss: 0.667364, acc.: 60.16%] [G loss: 0.837185]\n",
      "epoch:15 step:14076 [D loss: 0.716993, acc.: 55.47%] [G loss: 0.996543]\n",
      "epoch:15 step:14077 [D loss: 0.686592, acc.: 55.47%] [G loss: 0.869278]\n",
      "epoch:15 step:14078 [D loss: 0.608961, acc.: 64.84%] [G loss: 0.952878]\n",
      "epoch:15 step:14079 [D loss: 0.660443, acc.: 60.94%] [G loss: 0.910511]\n",
      "epoch:15 step:14080 [D loss: 0.563889, acc.: 71.09%] [G loss: 1.175747]\n",
      "epoch:15 step:14081 [D loss: 0.555209, acc.: 73.44%] [G loss: 1.079891]\n",
      "epoch:15 step:14082 [D loss: 0.522303, acc.: 75.78%] [G loss: 1.114233]\n",
      "epoch:15 step:14083 [D loss: 0.449154, acc.: 83.59%] [G loss: 1.176426]\n",
      "epoch:15 step:14084 [D loss: 0.514950, acc.: 75.00%] [G loss: 1.089007]\n",
      "epoch:15 step:14085 [D loss: 0.499717, acc.: 77.34%] [G loss: 1.166522]\n",
      "epoch:15 step:14086 [D loss: 0.495589, acc.: 80.47%] [G loss: 1.415424]\n",
      "epoch:15 step:14087 [D loss: 0.359950, acc.: 88.28%] [G loss: 1.539572]\n",
      "epoch:15 step:14088 [D loss: 0.469796, acc.: 77.34%] [G loss: 1.297049]\n",
      "epoch:15 step:14089 [D loss: 0.424710, acc.: 89.84%] [G loss: 1.274947]\n",
      "epoch:15 step:14090 [D loss: 0.416779, acc.: 85.94%] [G loss: 1.201886]\n",
      "epoch:15 step:14091 [D loss: 0.402719, acc.: 81.25%] [G loss: 1.167923]\n",
      "epoch:15 step:14092 [D loss: 0.879827, acc.: 39.06%] [G loss: 1.032654]\n",
      "epoch:15 step:14093 [D loss: 0.745774, acc.: 53.91%] [G loss: 1.070798]\n",
      "epoch:15 step:14094 [D loss: 0.670799, acc.: 56.25%] [G loss: 1.318212]\n",
      "epoch:15 step:14095 [D loss: 0.579614, acc.: 72.66%] [G loss: 1.017496]\n",
      "epoch:15 step:14096 [D loss: 0.759290, acc.: 47.66%] [G loss: 0.796463]\n",
      "epoch:15 step:14097 [D loss: 0.534360, acc.: 75.78%] [G loss: 1.055838]\n",
      "epoch:15 step:14098 [D loss: 0.638081, acc.: 63.28%] [G loss: 0.962600]\n",
      "epoch:15 step:14099 [D loss: 0.615474, acc.: 69.53%] [G loss: 1.247282]\n",
      "epoch:15 step:14100 [D loss: 0.789876, acc.: 46.09%] [G loss: 0.885017]\n",
      "epoch:15 step:14101 [D loss: 0.710308, acc.: 55.47%] [G loss: 1.101016]\n",
      "epoch:15 step:14102 [D loss: 0.694046, acc.: 57.03%] [G loss: 0.945655]\n",
      "epoch:15 step:14103 [D loss: 0.624600, acc.: 67.19%] [G loss: 1.029287]\n",
      "epoch:15 step:14104 [D loss: 0.530428, acc.: 74.22%] [G loss: 0.969491]\n",
      "epoch:15 step:14105 [D loss: 0.481690, acc.: 83.59%] [G loss: 1.222870]\n",
      "epoch:15 step:14106 [D loss: 0.624524, acc.: 64.84%] [G loss: 0.900269]\n",
      "epoch:15 step:14107 [D loss: 0.638731, acc.: 60.16%] [G loss: 0.848588]\n",
      "epoch:15 step:14108 [D loss: 0.613007, acc.: 64.84%] [G loss: 1.048555]\n",
      "epoch:15 step:14109 [D loss: 0.695643, acc.: 60.94%] [G loss: 0.886756]\n",
      "epoch:15 step:14110 [D loss: 0.609788, acc.: 64.06%] [G loss: 1.123098]\n",
      "epoch:15 step:14111 [D loss: 0.698948, acc.: 57.03%] [G loss: 1.074858]\n",
      "epoch:15 step:14112 [D loss: 0.698713, acc.: 58.59%] [G loss: 1.157218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14113 [D loss: 0.712091, acc.: 54.69%] [G loss: 1.013370]\n",
      "epoch:15 step:14114 [D loss: 0.656906, acc.: 57.81%] [G loss: 1.034897]\n",
      "epoch:15 step:14115 [D loss: 0.722524, acc.: 52.34%] [G loss: 1.205832]\n",
      "epoch:15 step:14116 [D loss: 0.657217, acc.: 60.16%] [G loss: 0.984171]\n",
      "epoch:15 step:14117 [D loss: 0.683203, acc.: 57.03%] [G loss: 0.805634]\n",
      "epoch:15 step:14118 [D loss: 0.687494, acc.: 63.28%] [G loss: 0.989652]\n",
      "epoch:15 step:14119 [D loss: 0.621962, acc.: 65.62%] [G loss: 0.921604]\n",
      "epoch:15 step:14120 [D loss: 0.651604, acc.: 62.50%] [G loss: 1.000483]\n",
      "epoch:15 step:14121 [D loss: 0.604351, acc.: 74.22%] [G loss: 1.129263]\n",
      "epoch:15 step:14122 [D loss: 0.621866, acc.: 64.06%] [G loss: 0.907090]\n",
      "epoch:15 step:14123 [D loss: 0.751296, acc.: 53.12%] [G loss: 0.787096]\n",
      "epoch:15 step:14124 [D loss: 0.597142, acc.: 73.44%] [G loss: 1.099462]\n",
      "epoch:15 step:14125 [D loss: 0.640875, acc.: 59.38%] [G loss: 1.089831]\n",
      "epoch:15 step:14126 [D loss: 0.700501, acc.: 53.91%] [G loss: 0.980934]\n",
      "epoch:15 step:14127 [D loss: 0.720539, acc.: 51.56%] [G loss: 0.986476]\n",
      "epoch:15 step:14128 [D loss: 0.660926, acc.: 60.16%] [G loss: 1.216172]\n",
      "epoch:15 step:14129 [D loss: 0.508328, acc.: 79.69%] [G loss: 1.227408]\n",
      "epoch:15 step:14130 [D loss: 0.374750, acc.: 88.28%] [G loss: 1.156963]\n",
      "epoch:15 step:14131 [D loss: 0.435187, acc.: 85.94%] [G loss: 1.402546]\n",
      "epoch:15 step:14132 [D loss: 0.451220, acc.: 79.69%] [G loss: 1.280379]\n",
      "epoch:15 step:14133 [D loss: 0.663069, acc.: 63.28%] [G loss: 1.149706]\n",
      "epoch:15 step:14134 [D loss: 0.672731, acc.: 57.03%] [G loss: 1.174702]\n",
      "epoch:15 step:14135 [D loss: 0.714082, acc.: 51.56%] [G loss: 0.865830]\n",
      "epoch:15 step:14136 [D loss: 0.705029, acc.: 54.69%] [G loss: 1.116466]\n",
      "epoch:15 step:14137 [D loss: 0.704989, acc.: 50.78%] [G loss: 0.992531]\n",
      "epoch:15 step:14138 [D loss: 0.606273, acc.: 68.75%] [G loss: 1.131494]\n",
      "epoch:15 step:14139 [D loss: 0.578036, acc.: 71.09%] [G loss: 1.056322]\n",
      "epoch:15 step:14140 [D loss: 0.608343, acc.: 64.06%] [G loss: 0.917847]\n",
      "epoch:15 step:14141 [D loss: 0.629975, acc.: 61.72%] [G loss: 0.977373]\n",
      "epoch:15 step:14142 [D loss: 0.656972, acc.: 64.06%] [G loss: 0.900671]\n",
      "epoch:15 step:14143 [D loss: 0.594764, acc.: 67.19%] [G loss: 0.935310]\n",
      "epoch:15 step:14144 [D loss: 0.703614, acc.: 57.03%] [G loss: 0.998527]\n",
      "epoch:15 step:14145 [D loss: 0.492091, acc.: 81.25%] [G loss: 1.131132]\n",
      "epoch:15 step:14146 [D loss: 0.680237, acc.: 58.59%] [G loss: 1.014548]\n",
      "epoch:15 step:14147 [D loss: 0.582885, acc.: 73.44%] [G loss: 1.123897]\n",
      "epoch:15 step:14148 [D loss: 0.608244, acc.: 64.06%] [G loss: 0.959422]\n",
      "epoch:15 step:14149 [D loss: 0.695981, acc.: 58.59%] [G loss: 0.827491]\n",
      "epoch:15 step:14150 [D loss: 0.653226, acc.: 60.16%] [G loss: 1.070695]\n",
      "epoch:15 step:14151 [D loss: 0.816779, acc.: 46.88%] [G loss: 0.787701]\n",
      "epoch:15 step:14152 [D loss: 0.628468, acc.: 64.06%] [G loss: 1.030393]\n",
      "epoch:15 step:14153 [D loss: 0.593013, acc.: 70.31%] [G loss: 1.179069]\n",
      "epoch:15 step:14154 [D loss: 0.703265, acc.: 53.91%] [G loss: 0.988349]\n",
      "epoch:15 step:14155 [D loss: 0.678534, acc.: 57.03%] [G loss: 1.043976]\n",
      "epoch:15 step:14156 [D loss: 0.659690, acc.: 62.50%] [G loss: 0.749455]\n",
      "epoch:15 step:14157 [D loss: 0.714766, acc.: 54.69%] [G loss: 1.096163]\n",
      "epoch:15 step:14158 [D loss: 0.565256, acc.: 70.31%] [G loss: 1.007201]\n",
      "epoch:15 step:14159 [D loss: 0.610108, acc.: 70.31%] [G loss: 1.075923]\n",
      "epoch:15 step:14160 [D loss: 0.653555, acc.: 60.94%] [G loss: 1.030982]\n",
      "epoch:15 step:14161 [D loss: 0.625083, acc.: 67.97%] [G loss: 1.139538]\n",
      "epoch:15 step:14162 [D loss: 0.723470, acc.: 54.69%] [G loss: 1.103437]\n",
      "epoch:15 step:14163 [D loss: 0.608989, acc.: 64.84%] [G loss: 1.048450]\n",
      "epoch:15 step:14164 [D loss: 0.502455, acc.: 78.91%] [G loss: 0.993226]\n",
      "epoch:15 step:14165 [D loss: 0.837976, acc.: 47.66%] [G loss: 0.873390]\n",
      "epoch:15 step:14166 [D loss: 0.694185, acc.: 59.38%] [G loss: 1.060432]\n",
      "epoch:15 step:14167 [D loss: 0.690265, acc.: 60.94%] [G loss: 1.125792]\n",
      "epoch:15 step:14168 [D loss: 0.701565, acc.: 57.81%] [G loss: 1.058583]\n",
      "epoch:15 step:14169 [D loss: 0.618647, acc.: 62.50%] [G loss: 1.083813]\n",
      "epoch:15 step:14170 [D loss: 0.518113, acc.: 77.34%] [G loss: 1.235766]\n",
      "epoch:15 step:14171 [D loss: 0.567379, acc.: 73.44%] [G loss: 0.972833]\n",
      "epoch:15 step:14172 [D loss: 0.595877, acc.: 62.50%] [G loss: 1.035874]\n",
      "epoch:15 step:14173 [D loss: 0.542427, acc.: 75.00%] [G loss: 1.087889]\n",
      "epoch:15 step:14174 [D loss: 0.475466, acc.: 80.47%] [G loss: 1.166857]\n",
      "epoch:15 step:14175 [D loss: 0.723914, acc.: 58.59%] [G loss: 0.888905]\n",
      "epoch:15 step:14176 [D loss: 0.544958, acc.: 73.44%] [G loss: 1.091561]\n",
      "epoch:15 step:14177 [D loss: 0.508266, acc.: 73.44%] [G loss: 1.197494]\n",
      "epoch:15 step:14178 [D loss: 0.655367, acc.: 60.94%] [G loss: 1.126752]\n",
      "epoch:15 step:14179 [D loss: 0.595550, acc.: 71.09%] [G loss: 1.140448]\n",
      "epoch:15 step:14180 [D loss: 0.692450, acc.: 59.38%] [G loss: 0.979027]\n",
      "epoch:15 step:14181 [D loss: 0.581654, acc.: 70.31%] [G loss: 0.988970]\n",
      "epoch:15 step:14182 [D loss: 0.712392, acc.: 54.69%] [G loss: 0.910946]\n",
      "epoch:15 step:14183 [D loss: 0.689059, acc.: 51.56%] [G loss: 0.983066]\n",
      "epoch:15 step:14184 [D loss: 0.620295, acc.: 68.75%] [G loss: 1.055624]\n",
      "epoch:15 step:14185 [D loss: 0.609440, acc.: 64.06%] [G loss: 0.825531]\n",
      "epoch:15 step:14186 [D loss: 0.562403, acc.: 71.88%] [G loss: 1.155549]\n",
      "epoch:15 step:14187 [D loss: 0.539985, acc.: 74.22%] [G loss: 1.081089]\n",
      "epoch:15 step:14188 [D loss: 0.660115, acc.: 61.72%] [G loss: 1.045095]\n",
      "epoch:15 step:14189 [D loss: 0.607669, acc.: 67.97%] [G loss: 1.142899]\n",
      "epoch:15 step:14190 [D loss: 0.656250, acc.: 54.69%] [G loss: 1.217402]\n",
      "epoch:15 step:14191 [D loss: 0.668317, acc.: 57.03%] [G loss: 1.038354]\n",
      "epoch:15 step:14192 [D loss: 0.769905, acc.: 43.75%] [G loss: 0.854628]\n",
      "epoch:15 step:14193 [D loss: 0.703327, acc.: 58.59%] [G loss: 0.973051]\n",
      "epoch:15 step:14194 [D loss: 0.631238, acc.: 60.94%] [G loss: 0.908329]\n",
      "epoch:15 step:14195 [D loss: 0.682517, acc.: 57.03%] [G loss: 1.054894]\n",
      "epoch:15 step:14196 [D loss: 0.601945, acc.: 66.41%] [G loss: 0.855440]\n",
      "epoch:15 step:14197 [D loss: 0.587883, acc.: 70.31%] [G loss: 1.020602]\n",
      "epoch:15 step:14198 [D loss: 0.717778, acc.: 50.78%] [G loss: 0.969325]\n",
      "epoch:15 step:14199 [D loss: 0.578464, acc.: 68.75%] [G loss: 1.269084]\n",
      "epoch:15 step:14200 [D loss: 0.499941, acc.: 81.25%] [G loss: 1.136256]\n",
      "epoch:15 step:14201 [D loss: 0.559992, acc.: 74.22%] [G loss: 1.221515]\n",
      "epoch:15 step:14202 [D loss: 0.712794, acc.: 57.81%] [G loss: 1.143846]\n",
      "epoch:15 step:14203 [D loss: 0.707616, acc.: 56.25%] [G loss: 0.882500]\n",
      "epoch:15 step:14204 [D loss: 0.645905, acc.: 57.81%] [G loss: 0.885849]\n",
      "epoch:15 step:14205 [D loss: 0.434031, acc.: 82.03%] [G loss: 1.163847]\n",
      "epoch:15 step:14206 [D loss: 0.613937, acc.: 65.62%] [G loss: 0.902211]\n",
      "epoch:15 step:14207 [D loss: 0.365300, acc.: 88.28%] [G loss: 1.246127]\n",
      "epoch:15 step:14208 [D loss: 0.711561, acc.: 52.34%] [G loss: 1.175664]\n",
      "epoch:15 step:14209 [D loss: 0.813761, acc.: 40.62%] [G loss: 0.998812]\n",
      "epoch:15 step:14210 [D loss: 0.645453, acc.: 63.28%] [G loss: 0.969957]\n",
      "epoch:15 step:14211 [D loss: 0.667696, acc.: 61.72%] [G loss: 1.024634]\n",
      "epoch:15 step:14212 [D loss: 0.633567, acc.: 64.06%] [G loss: 1.013766]\n",
      "epoch:15 step:14213 [D loss: 0.862790, acc.: 35.16%] [G loss: 0.855199]\n",
      "epoch:15 step:14214 [D loss: 0.566949, acc.: 75.00%] [G loss: 1.004384]\n",
      "epoch:15 step:14215 [D loss: 0.706942, acc.: 52.34%] [G loss: 1.035363]\n",
      "epoch:15 step:14216 [D loss: 0.753755, acc.: 50.78%] [G loss: 0.828060]\n",
      "epoch:15 step:14217 [D loss: 0.638241, acc.: 60.16%] [G loss: 1.124635]\n",
      "epoch:15 step:14218 [D loss: 0.619213, acc.: 65.62%] [G loss: 0.917605]\n",
      "epoch:15 step:14219 [D loss: 0.673632, acc.: 58.59%] [G loss: 0.870591]\n",
      "epoch:15 step:14220 [D loss: 0.663089, acc.: 58.59%] [G loss: 0.918079]\n",
      "epoch:15 step:14221 [D loss: 0.513716, acc.: 77.34%] [G loss: 0.948050]\n",
      "epoch:15 step:14222 [D loss: 0.572171, acc.: 71.09%] [G loss: 1.075999]\n",
      "epoch:15 step:14223 [D loss: 0.509445, acc.: 75.00%] [G loss: 1.066731]\n",
      "epoch:15 step:14224 [D loss: 0.590880, acc.: 67.19%] [G loss: 0.966205]\n",
      "epoch:15 step:14225 [D loss: 0.707367, acc.: 57.81%] [G loss: 0.988802]\n",
      "epoch:15 step:14226 [D loss: 0.635498, acc.: 60.16%] [G loss: 1.067018]\n",
      "epoch:15 step:14227 [D loss: 0.647639, acc.: 62.50%] [G loss: 0.944542]\n",
      "epoch:15 step:14228 [D loss: 0.676776, acc.: 57.81%] [G loss: 1.000053]\n",
      "epoch:15 step:14229 [D loss: 0.782884, acc.: 42.97%] [G loss: 0.777184]\n",
      "epoch:15 step:14230 [D loss: 0.606769, acc.: 68.75%] [G loss: 1.071166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14231 [D loss: 0.672979, acc.: 55.47%] [G loss: 0.787942]\n",
      "epoch:15 step:14232 [D loss: 0.773026, acc.: 51.56%] [G loss: 1.037322]\n",
      "epoch:15 step:14233 [D loss: 0.600209, acc.: 74.22%] [G loss: 1.013338]\n",
      "epoch:15 step:14234 [D loss: 0.655693, acc.: 62.50%] [G loss: 1.057477]\n",
      "epoch:15 step:14235 [D loss: 0.769788, acc.: 47.66%] [G loss: 0.909518]\n",
      "epoch:15 step:14236 [D loss: 0.609466, acc.: 63.28%] [G loss: 0.974902]\n",
      "epoch:15 step:14237 [D loss: 0.733050, acc.: 52.34%] [G loss: 0.879192]\n",
      "epoch:15 step:14238 [D loss: 0.744747, acc.: 50.78%] [G loss: 0.797796]\n",
      "epoch:15 step:14239 [D loss: 0.740205, acc.: 54.69%] [G loss: 0.902677]\n",
      "epoch:15 step:14240 [D loss: 0.846246, acc.: 38.28%] [G loss: 1.079416]\n",
      "epoch:15 step:14241 [D loss: 0.633752, acc.: 60.16%] [G loss: 1.042674]\n",
      "epoch:15 step:14242 [D loss: 0.710093, acc.: 52.34%] [G loss: 0.966716]\n",
      "epoch:15 step:14243 [D loss: 0.634355, acc.: 63.28%] [G loss: 1.145315]\n",
      "epoch:15 step:14244 [D loss: 0.760934, acc.: 52.34%] [G loss: 0.856469]\n",
      "epoch:15 step:14245 [D loss: 0.603933, acc.: 66.41%] [G loss: 1.058816]\n",
      "epoch:15 step:14246 [D loss: 0.736642, acc.: 48.44%] [G loss: 0.818041]\n",
      "epoch:15 step:14247 [D loss: 0.514436, acc.: 81.25%] [G loss: 1.061395]\n",
      "epoch:15 step:14248 [D loss: 0.646489, acc.: 64.06%] [G loss: 1.052184]\n",
      "epoch:15 step:14249 [D loss: 0.639244, acc.: 60.16%] [G loss: 1.061192]\n",
      "epoch:15 step:14250 [D loss: 0.687401, acc.: 57.03%] [G loss: 0.931912]\n",
      "epoch:15 step:14251 [D loss: 0.791296, acc.: 46.09%] [G loss: 1.079696]\n",
      "epoch:15 step:14252 [D loss: 0.693345, acc.: 60.16%] [G loss: 1.026127]\n",
      "epoch:15 step:14253 [D loss: 0.708426, acc.: 55.47%] [G loss: 0.862939]\n",
      "epoch:15 step:14254 [D loss: 0.701596, acc.: 60.94%] [G loss: 0.995180]\n",
      "epoch:15 step:14255 [D loss: 0.634235, acc.: 66.41%] [G loss: 1.131907]\n",
      "epoch:15 step:14256 [D loss: 0.487912, acc.: 83.59%] [G loss: 1.233545]\n",
      "epoch:15 step:14257 [D loss: 0.683861, acc.: 63.28%] [G loss: 1.118541]\n",
      "epoch:15 step:14258 [D loss: 0.792572, acc.: 44.53%] [G loss: 1.070037]\n",
      "epoch:15 step:14259 [D loss: 0.677115, acc.: 60.16%] [G loss: 1.027658]\n",
      "epoch:15 step:14260 [D loss: 0.792554, acc.: 49.22%] [G loss: 0.926583]\n",
      "epoch:15 step:14261 [D loss: 0.641814, acc.: 58.59%] [G loss: 0.839066]\n",
      "epoch:15 step:14262 [D loss: 0.631032, acc.: 67.19%] [G loss: 0.993225]\n",
      "epoch:15 step:14263 [D loss: 0.624699, acc.: 64.84%] [G loss: 1.062304]\n",
      "epoch:15 step:14264 [D loss: 0.540722, acc.: 71.09%] [G loss: 0.973579]\n",
      "epoch:15 step:14265 [D loss: 0.615893, acc.: 66.41%] [G loss: 1.031406]\n",
      "epoch:15 step:14266 [D loss: 0.598610, acc.: 68.75%] [G loss: 0.945860]\n",
      "epoch:15 step:14267 [D loss: 0.646023, acc.: 56.25%] [G loss: 0.889561]\n",
      "epoch:15 step:14268 [D loss: 0.623648, acc.: 63.28%] [G loss: 0.978663]\n",
      "epoch:15 step:14269 [D loss: 0.628132, acc.: 67.19%] [G loss: 1.106970]\n",
      "epoch:15 step:14270 [D loss: 0.575276, acc.: 71.09%] [G loss: 1.041956]\n",
      "epoch:15 step:14271 [D loss: 0.644773, acc.: 60.94%] [G loss: 0.960040]\n",
      "epoch:15 step:14272 [D loss: 0.772308, acc.: 48.44%] [G loss: 0.976061]\n",
      "epoch:15 step:14273 [D loss: 0.664490, acc.: 60.16%] [G loss: 0.954058]\n",
      "epoch:15 step:14274 [D loss: 0.615830, acc.: 66.41%] [G loss: 0.961929]\n",
      "epoch:15 step:14275 [D loss: 0.459237, acc.: 77.34%] [G loss: 1.101513]\n",
      "epoch:15 step:14276 [D loss: 0.391887, acc.: 90.62%] [G loss: 1.290267]\n",
      "epoch:15 step:14277 [D loss: 0.453972, acc.: 82.03%] [G loss: 1.303165]\n",
      "epoch:15 step:14278 [D loss: 0.332061, acc.: 92.97%] [G loss: 1.292688]\n",
      "epoch:15 step:14279 [D loss: 0.735395, acc.: 56.25%] [G loss: 1.321046]\n",
      "epoch:15 step:14280 [D loss: 0.701181, acc.: 56.25%] [G loss: 1.145236]\n",
      "epoch:15 step:14281 [D loss: 0.491474, acc.: 81.25%] [G loss: 1.125178]\n",
      "epoch:15 step:14282 [D loss: 0.667672, acc.: 53.91%] [G loss: 1.015942]\n",
      "epoch:15 step:14283 [D loss: 0.646171, acc.: 63.28%] [G loss: 1.002599]\n",
      "epoch:15 step:14284 [D loss: 0.667488, acc.: 64.06%] [G loss: 0.934687]\n",
      "epoch:15 step:14285 [D loss: 0.354614, acc.: 85.16%] [G loss: 1.255454]\n",
      "epoch:15 step:14286 [D loss: 0.337864, acc.: 91.41%] [G loss: 1.539131]\n",
      "epoch:15 step:14287 [D loss: 0.343347, acc.: 91.41%] [G loss: 1.558941]\n",
      "epoch:15 step:14288 [D loss: 0.762348, acc.: 56.25%] [G loss: 1.373999]\n",
      "epoch:15 step:14289 [D loss: 0.850385, acc.: 38.28%] [G loss: 0.960911]\n",
      "epoch:15 step:14290 [D loss: 0.627819, acc.: 63.28%] [G loss: 0.927474]\n",
      "epoch:15 step:14291 [D loss: 0.785136, acc.: 49.22%] [G loss: 0.813631]\n",
      "epoch:15 step:14292 [D loss: 0.708844, acc.: 52.34%] [G loss: 1.054297]\n",
      "epoch:15 step:14293 [D loss: 0.682245, acc.: 55.47%] [G loss: 0.920501]\n",
      "epoch:15 step:14294 [D loss: 0.763661, acc.: 52.34%] [G loss: 1.148248]\n",
      "epoch:15 step:14295 [D loss: 0.750546, acc.: 50.00%] [G loss: 0.964957]\n",
      "epoch:15 step:14296 [D loss: 0.651184, acc.: 62.50%] [G loss: 1.006086]\n",
      "epoch:15 step:14297 [D loss: 0.861513, acc.: 42.19%] [G loss: 0.830548]\n",
      "epoch:15 step:14298 [D loss: 0.783047, acc.: 50.00%] [G loss: 0.950806]\n",
      "epoch:15 step:14299 [D loss: 0.720093, acc.: 49.22%] [G loss: 1.018622]\n",
      "epoch:15 step:14300 [D loss: 0.709039, acc.: 54.69%] [G loss: 1.029787]\n",
      "epoch:15 step:14301 [D loss: 0.532156, acc.: 75.78%] [G loss: 1.256510]\n",
      "epoch:15 step:14302 [D loss: 0.564643, acc.: 71.09%] [G loss: 1.264974]\n",
      "epoch:15 step:14303 [D loss: 0.525605, acc.: 76.56%] [G loss: 1.218970]\n",
      "epoch:15 step:14304 [D loss: 0.592819, acc.: 70.31%] [G loss: 0.986489]\n",
      "epoch:15 step:14305 [D loss: 0.603494, acc.: 63.28%] [G loss: 0.971076]\n",
      "epoch:15 step:14306 [D loss: 0.575472, acc.: 70.31%] [G loss: 1.163335]\n",
      "epoch:15 step:14307 [D loss: 0.622864, acc.: 67.97%] [G loss: 1.013298]\n",
      "epoch:15 step:14308 [D loss: 0.593044, acc.: 67.19%] [G loss: 0.973910]\n",
      "epoch:15 step:14309 [D loss: 0.537679, acc.: 70.31%] [G loss: 1.187608]\n",
      "epoch:15 step:14310 [D loss: 0.659971, acc.: 53.91%] [G loss: 0.894559]\n",
      "epoch:15 step:14311 [D loss: 0.651045, acc.: 61.72%] [G loss: 1.212105]\n",
      "epoch:15 step:14312 [D loss: 0.546353, acc.: 78.12%] [G loss: 0.999970]\n",
      "epoch:15 step:14313 [D loss: 0.604398, acc.: 69.53%] [G loss: 1.064882]\n",
      "epoch:15 step:14314 [D loss: 0.671391, acc.: 57.03%] [G loss: 1.059250]\n",
      "epoch:15 step:14315 [D loss: 0.620292, acc.: 62.50%] [G loss: 0.813106]\n",
      "epoch:15 step:14316 [D loss: 0.745716, acc.: 50.00%] [G loss: 0.969817]\n",
      "epoch:15 step:14317 [D loss: 0.723803, acc.: 53.91%] [G loss: 0.766486]\n",
      "epoch:15 step:14318 [D loss: 0.447511, acc.: 83.59%] [G loss: 1.166782]\n",
      "epoch:15 step:14319 [D loss: 0.488762, acc.: 78.91%] [G loss: 1.076170]\n",
      "epoch:15 step:14320 [D loss: 0.679002, acc.: 57.03%] [G loss: 1.150919]\n",
      "epoch:15 step:14321 [D loss: 0.692891, acc.: 55.47%] [G loss: 1.042060]\n",
      "epoch:15 step:14322 [D loss: 0.670861, acc.: 58.59%] [G loss: 1.027417]\n",
      "epoch:15 step:14323 [D loss: 0.711525, acc.: 57.03%] [G loss: 0.776255]\n",
      "epoch:15 step:14324 [D loss: 0.434580, acc.: 83.59%] [G loss: 1.191633]\n",
      "epoch:15 step:14325 [D loss: 0.588877, acc.: 67.97%] [G loss: 0.993045]\n",
      "epoch:15 step:14326 [D loss: 0.533813, acc.: 75.78%] [G loss: 0.852348]\n",
      "epoch:15 step:14327 [D loss: 0.418798, acc.: 87.50%] [G loss: 1.247651]\n",
      "epoch:15 step:14328 [D loss: 0.470711, acc.: 82.81%] [G loss: 1.192870]\n",
      "epoch:15 step:14329 [D loss: 0.498833, acc.: 81.25%] [G loss: 1.290908]\n",
      "epoch:15 step:14330 [D loss: 0.627771, acc.: 62.50%] [G loss: 1.122322]\n",
      "epoch:15 step:14331 [D loss: 0.562303, acc.: 77.34%] [G loss: 1.199909]\n",
      "epoch:15 step:14332 [D loss: 0.885783, acc.: 34.38%] [G loss: 0.721102]\n",
      "epoch:15 step:14333 [D loss: 0.941943, acc.: 32.03%] [G loss: 0.890316]\n",
      "epoch:15 step:14334 [D loss: 0.818587, acc.: 38.28%] [G loss: 0.888863]\n",
      "epoch:15 step:14335 [D loss: 0.604021, acc.: 67.97%] [G loss: 1.283374]\n",
      "epoch:15 step:14336 [D loss: 0.677582, acc.: 54.69%] [G loss: 0.881789]\n",
      "epoch:15 step:14337 [D loss: 0.627931, acc.: 64.06%] [G loss: 0.955497]\n",
      "epoch:15 step:14338 [D loss: 0.603912, acc.: 67.97%] [G loss: 1.187497]\n",
      "epoch:15 step:14339 [D loss: 0.604991, acc.: 65.62%] [G loss: 1.009697]\n",
      "epoch:15 step:14340 [D loss: 0.637214, acc.: 64.06%] [G loss: 1.152950]\n",
      "epoch:15 step:14341 [D loss: 0.468371, acc.: 84.38%] [G loss: 1.412401]\n",
      "epoch:15 step:14342 [D loss: 0.588224, acc.: 68.75%] [G loss: 0.943334]\n",
      "epoch:15 step:14343 [D loss: 0.536921, acc.: 76.56%] [G loss: 1.335728]\n",
      "epoch:15 step:14344 [D loss: 0.459741, acc.: 80.47%] [G loss: 1.229372]\n",
      "epoch:15 step:14345 [D loss: 0.645293, acc.: 65.62%] [G loss: 1.126013]\n",
      "epoch:15 step:14346 [D loss: 0.541853, acc.: 74.22%] [G loss: 0.930337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14347 [D loss: 0.548406, acc.: 75.00%] [G loss: 1.487671]\n",
      "epoch:15 step:14348 [D loss: 0.491609, acc.: 76.56%] [G loss: 1.288754]\n",
      "epoch:15 step:14349 [D loss: 0.546038, acc.: 71.09%] [G loss: 1.097381]\n",
      "epoch:15 step:14350 [D loss: 0.709055, acc.: 53.12%] [G loss: 1.233340]\n",
      "epoch:15 step:14351 [D loss: 0.563210, acc.: 68.75%] [G loss: 1.187706]\n",
      "epoch:15 step:14352 [D loss: 0.678480, acc.: 57.03%] [G loss: 0.930663]\n",
      "epoch:15 step:14353 [D loss: 0.618766, acc.: 67.97%] [G loss: 1.135387]\n",
      "epoch:15 step:14354 [D loss: 0.656374, acc.: 60.94%] [G loss: 0.882132]\n",
      "epoch:15 step:14355 [D loss: 0.639240, acc.: 60.94%] [G loss: 1.098804]\n",
      "epoch:15 step:14356 [D loss: 0.693842, acc.: 58.59%] [G loss: 0.916136]\n",
      "epoch:15 step:14357 [D loss: 0.600812, acc.: 67.19%] [G loss: 1.015383]\n",
      "epoch:15 step:14358 [D loss: 0.730986, acc.: 46.09%] [G loss: 1.133574]\n",
      "epoch:15 step:14359 [D loss: 0.800593, acc.: 44.53%] [G loss: 0.751909]\n",
      "epoch:15 step:14360 [D loss: 0.577458, acc.: 75.00%] [G loss: 0.975256]\n",
      "epoch:15 step:14361 [D loss: 0.627668, acc.: 67.97%] [G loss: 1.164253]\n",
      "epoch:15 step:14362 [D loss: 0.616942, acc.: 65.62%] [G loss: 0.959712]\n",
      "epoch:15 step:14363 [D loss: 0.472647, acc.: 81.25%] [G loss: 1.006980]\n",
      "epoch:15 step:14364 [D loss: 0.552555, acc.: 75.78%] [G loss: 1.110799]\n",
      "epoch:15 step:14365 [D loss: 0.621620, acc.: 65.62%] [G loss: 1.017918]\n",
      "epoch:15 step:14366 [D loss: 0.502261, acc.: 80.47%] [G loss: 1.009900]\n",
      "epoch:15 step:14367 [D loss: 0.502333, acc.: 76.56%] [G loss: 1.009441]\n",
      "epoch:15 step:14368 [D loss: 0.569789, acc.: 71.88%] [G loss: 0.998553]\n",
      "epoch:15 step:14369 [D loss: 0.498771, acc.: 81.25%] [G loss: 1.455014]\n",
      "epoch:15 step:14370 [D loss: 0.573583, acc.: 73.44%] [G loss: 1.182835]\n",
      "epoch:15 step:14371 [D loss: 0.824708, acc.: 48.44%] [G loss: 1.222120]\n",
      "epoch:15 step:14372 [D loss: 0.597779, acc.: 69.53%] [G loss: 0.959890]\n",
      "epoch:15 step:14373 [D loss: 0.600192, acc.: 66.41%] [G loss: 1.028402]\n",
      "epoch:15 step:14374 [D loss: 0.649394, acc.: 64.06%] [G loss: 1.085603]\n",
      "epoch:15 step:14375 [D loss: 0.541882, acc.: 75.00%] [G loss: 1.184830]\n",
      "epoch:15 step:14376 [D loss: 0.502457, acc.: 85.16%] [G loss: 1.070591]\n",
      "epoch:15 step:14377 [D loss: 0.530571, acc.: 74.22%] [G loss: 0.953028]\n",
      "epoch:15 step:14378 [D loss: 0.701106, acc.: 51.56%] [G loss: 1.142621]\n",
      "epoch:15 step:14379 [D loss: 0.608506, acc.: 65.62%] [G loss: 0.907270]\n",
      "epoch:15 step:14380 [D loss: 0.584459, acc.: 70.31%] [G loss: 1.027968]\n",
      "epoch:15 step:14381 [D loss: 0.570617, acc.: 70.31%] [G loss: 1.082152]\n",
      "epoch:15 step:14382 [D loss: 0.385640, acc.: 88.28%] [G loss: 1.013661]\n",
      "epoch:15 step:14383 [D loss: 0.413333, acc.: 89.84%] [G loss: 1.168587]\n",
      "epoch:15 step:14384 [D loss: 0.607900, acc.: 66.41%] [G loss: 1.194782]\n",
      "epoch:15 step:14385 [D loss: 0.682696, acc.: 56.25%] [G loss: 1.025748]\n",
      "epoch:15 step:14386 [D loss: 0.749697, acc.: 50.00%] [G loss: 0.923701]\n",
      "epoch:15 step:14387 [D loss: 0.712594, acc.: 55.47%] [G loss: 0.846229]\n",
      "epoch:15 step:14388 [D loss: 0.664465, acc.: 58.59%] [G loss: 1.045168]\n",
      "epoch:15 step:14389 [D loss: 0.841955, acc.: 30.47%] [G loss: 0.740740]\n",
      "epoch:15 step:14390 [D loss: 0.693853, acc.: 53.91%] [G loss: 0.995506]\n",
      "epoch:15 step:14391 [D loss: 0.620300, acc.: 64.84%] [G loss: 1.165881]\n",
      "epoch:15 step:14392 [D loss: 0.693756, acc.: 52.34%] [G loss: 0.985478]\n",
      "epoch:15 step:14393 [D loss: 0.635851, acc.: 64.84%] [G loss: 1.027016]\n",
      "epoch:15 step:14394 [D loss: 0.677859, acc.: 57.03%] [G loss: 1.071117]\n",
      "epoch:15 step:14395 [D loss: 0.591201, acc.: 69.53%] [G loss: 1.088649]\n",
      "epoch:15 step:14396 [D loss: 0.809853, acc.: 39.84%] [G loss: 0.904685]\n",
      "epoch:15 step:14397 [D loss: 0.682831, acc.: 60.16%] [G loss: 1.033473]\n",
      "epoch:15 step:14398 [D loss: 0.438682, acc.: 88.28%] [G loss: 1.355286]\n",
      "epoch:15 step:14399 [D loss: 0.441373, acc.: 81.25%] [G loss: 1.296641]\n",
      "epoch:15 step:14400 [D loss: 0.405037, acc.: 89.06%] [G loss: 1.502609]\n",
      "epoch:15 step:14401 [D loss: 0.327454, acc.: 92.97%] [G loss: 1.571187]\n",
      "epoch:15 step:14402 [D loss: 0.364972, acc.: 92.97%] [G loss: 1.375699]\n",
      "epoch:15 step:14403 [D loss: 0.709836, acc.: 53.12%] [G loss: 1.276180]\n",
      "epoch:15 step:14404 [D loss: 0.990689, acc.: 27.34%] [G loss: 0.824007]\n",
      "epoch:15 step:14405 [D loss: 0.669419, acc.: 59.38%] [G loss: 0.959785]\n",
      "epoch:15 step:14406 [D loss: 0.654920, acc.: 61.72%] [G loss: 1.081045]\n",
      "epoch:15 step:14407 [D loss: 0.603769, acc.: 67.97%] [G loss: 1.135834]\n",
      "epoch:15 step:14408 [D loss: 0.539367, acc.: 76.56%] [G loss: 1.134462]\n",
      "epoch:15 step:14409 [D loss: 0.546169, acc.: 71.88%] [G loss: 1.029408]\n",
      "epoch:15 step:14410 [D loss: 0.705978, acc.: 57.81%] [G loss: 0.955667]\n",
      "epoch:15 step:14411 [D loss: 0.670968, acc.: 60.16%] [G loss: 0.997009]\n",
      "epoch:15 step:14412 [D loss: 0.621899, acc.: 69.53%] [G loss: 1.061841]\n",
      "epoch:15 step:14413 [D loss: 0.579990, acc.: 69.53%] [G loss: 1.033767]\n",
      "epoch:15 step:14414 [D loss: 0.588479, acc.: 67.97%] [G loss: 1.127400]\n",
      "epoch:15 step:14415 [D loss: 0.673897, acc.: 61.72%] [G loss: 0.807158]\n",
      "epoch:15 step:14416 [D loss: 0.663850, acc.: 56.25%] [G loss: 0.838544]\n",
      "epoch:15 step:14417 [D loss: 0.689096, acc.: 57.81%] [G loss: 0.938483]\n",
      "epoch:15 step:14418 [D loss: 0.688049, acc.: 62.50%] [G loss: 0.999080]\n",
      "epoch:15 step:14419 [D loss: 0.631350, acc.: 64.84%] [G loss: 1.158744]\n",
      "epoch:15 step:14420 [D loss: 0.604575, acc.: 68.75%] [G loss: 1.056989]\n",
      "epoch:15 step:14421 [D loss: 0.443465, acc.: 82.03%] [G loss: 1.224030]\n",
      "epoch:15 step:14422 [D loss: 0.499427, acc.: 80.47%] [G loss: 1.170575]\n",
      "epoch:15 step:14423 [D loss: 0.592657, acc.: 63.28%] [G loss: 1.230525]\n",
      "epoch:15 step:14424 [D loss: 0.690700, acc.: 55.47%] [G loss: 0.896007]\n",
      "epoch:15 step:14425 [D loss: 0.600220, acc.: 71.09%] [G loss: 1.075036]\n",
      "epoch:15 step:14426 [D loss: 0.580532, acc.: 72.66%] [G loss: 1.115353]\n",
      "epoch:15 step:14427 [D loss: 0.673241, acc.: 59.38%] [G loss: 0.914097]\n",
      "epoch:15 step:14428 [D loss: 0.745125, acc.: 51.56%] [G loss: 0.937157]\n",
      "epoch:15 step:14429 [D loss: 0.787573, acc.: 42.19%] [G loss: 1.034396]\n",
      "epoch:15 step:14430 [D loss: 0.684329, acc.: 54.69%] [G loss: 0.851974]\n",
      "epoch:15 step:14431 [D loss: 0.685777, acc.: 58.59%] [G loss: 0.941156]\n",
      "epoch:15 step:14432 [D loss: 0.785515, acc.: 45.31%] [G loss: 0.832539]\n",
      "epoch:15 step:14433 [D loss: 0.519258, acc.: 78.91%] [G loss: 0.972422]\n",
      "epoch:15 step:14434 [D loss: 0.708332, acc.: 51.56%] [G loss: 0.860645]\n",
      "epoch:15 step:14435 [D loss: 0.591677, acc.: 72.66%] [G loss: 1.150088]\n",
      "epoch:15 step:14436 [D loss: 0.577981, acc.: 72.66%] [G loss: 0.902234]\n",
      "epoch:15 step:14437 [D loss: 0.645431, acc.: 64.84%] [G loss: 0.924918]\n",
      "epoch:15 step:14438 [D loss: 0.594864, acc.: 71.09%] [G loss: 0.893226]\n",
      "epoch:15 step:14439 [D loss: 0.649341, acc.: 61.72%] [G loss: 0.949926]\n",
      "epoch:15 step:14440 [D loss: 0.782377, acc.: 46.09%] [G loss: 0.822171]\n",
      "epoch:15 step:14441 [D loss: 0.633857, acc.: 59.38%] [G loss: 1.012622]\n",
      "epoch:15 step:14442 [D loss: 0.572310, acc.: 69.53%] [G loss: 1.018982]\n",
      "epoch:15 step:14443 [D loss: 0.591140, acc.: 65.62%] [G loss: 0.904941]\n",
      "epoch:15 step:14444 [D loss: 0.615067, acc.: 67.97%] [G loss: 1.174551]\n",
      "epoch:15 step:14445 [D loss: 0.598597, acc.: 69.53%] [G loss: 0.981020]\n",
      "epoch:15 step:14446 [D loss: 0.639078, acc.: 60.16%] [G loss: 0.923080]\n",
      "epoch:15 step:14447 [D loss: 0.705022, acc.: 55.47%] [G loss: 0.912829]\n",
      "epoch:15 step:14448 [D loss: 0.607697, acc.: 64.06%] [G loss: 1.004104]\n",
      "epoch:15 step:14449 [D loss: 0.563468, acc.: 72.66%] [G loss: 1.008933]\n",
      "epoch:15 step:14450 [D loss: 0.642918, acc.: 63.28%] [G loss: 0.885797]\n",
      "epoch:15 step:14451 [D loss: 0.457983, acc.: 87.50%] [G loss: 1.231717]\n",
      "epoch:15 step:14452 [D loss: 0.383938, acc.: 87.50%] [G loss: 1.180040]\n",
      "epoch:15 step:14453 [D loss: 0.405835, acc.: 83.59%] [G loss: 1.410291]\n",
      "epoch:15 step:14454 [D loss: 0.428946, acc.: 84.38%] [G loss: 1.310292]\n",
      "epoch:15 step:14455 [D loss: 0.589035, acc.: 67.97%] [G loss: 1.439695]\n",
      "epoch:15 step:14456 [D loss: 0.557344, acc.: 69.53%] [G loss: 1.421984]\n",
      "epoch:15 step:14457 [D loss: 0.651638, acc.: 65.62%] [G loss: 0.979866]\n",
      "epoch:15 step:14458 [D loss: 0.489055, acc.: 79.69%] [G loss: 1.468942]\n",
      "epoch:15 step:14459 [D loss: 0.457582, acc.: 82.81%] [G loss: 1.258633]\n",
      "epoch:15 step:14460 [D loss: 0.394862, acc.: 88.28%] [G loss: 1.307056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14461 [D loss: 0.504457, acc.: 75.78%] [G loss: 1.042941]\n",
      "epoch:15 step:14462 [D loss: 0.530262, acc.: 73.44%] [G loss: 1.116103]\n",
      "epoch:15 step:14463 [D loss: 0.585440, acc.: 71.88%] [G loss: 1.222697]\n",
      "epoch:15 step:14464 [D loss: 0.588118, acc.: 65.62%] [G loss: 0.987685]\n",
      "epoch:15 step:14465 [D loss: 0.806218, acc.: 42.19%] [G loss: 0.781535]\n",
      "epoch:15 step:14466 [D loss: 0.781677, acc.: 44.53%] [G loss: 1.052880]\n",
      "epoch:15 step:14467 [D loss: 0.762169, acc.: 56.25%] [G loss: 1.079446]\n",
      "epoch:15 step:14468 [D loss: 0.925410, acc.: 38.28%] [G loss: 0.714310]\n",
      "epoch:15 step:14469 [D loss: 0.758637, acc.: 46.09%] [G loss: 0.820293]\n",
      "epoch:15 step:14470 [D loss: 0.830915, acc.: 44.53%] [G loss: 0.774311]\n",
      "epoch:15 step:14471 [D loss: 0.849203, acc.: 39.84%] [G loss: 0.704318]\n",
      "epoch:15 step:14472 [D loss: 0.851085, acc.: 33.59%] [G loss: 0.903393]\n",
      "epoch:15 step:14473 [D loss: 0.707731, acc.: 62.50%] [G loss: 0.924223]\n",
      "epoch:15 step:14474 [D loss: 0.718410, acc.: 52.34%] [G loss: 1.055787]\n",
      "epoch:15 step:14475 [D loss: 0.745874, acc.: 53.12%] [G loss: 1.148948]\n",
      "epoch:15 step:14476 [D loss: 0.909568, acc.: 34.38%] [G loss: 0.982505]\n",
      "epoch:15 step:14477 [D loss: 0.833931, acc.: 46.09%] [G loss: 1.084925]\n",
      "epoch:15 step:14478 [D loss: 0.821492, acc.: 42.19%] [G loss: 1.010548]\n",
      "epoch:15 step:14479 [D loss: 0.606807, acc.: 66.41%] [G loss: 1.042846]\n",
      "epoch:15 step:14480 [D loss: 0.842984, acc.: 39.06%] [G loss: 0.836925]\n",
      "epoch:15 step:14481 [D loss: 0.551518, acc.: 76.56%] [G loss: 1.225450]\n",
      "epoch:15 step:14482 [D loss: 0.662948, acc.: 60.94%] [G loss: 1.108027]\n",
      "epoch:15 step:14483 [D loss: 0.534834, acc.: 76.56%] [G loss: 1.085369]\n",
      "epoch:15 step:14484 [D loss: 0.710986, acc.: 50.78%] [G loss: 1.107077]\n",
      "epoch:15 step:14485 [D loss: 0.611340, acc.: 69.53%] [G loss: 1.013153]\n",
      "epoch:15 step:14486 [D loss: 0.706032, acc.: 56.25%] [G loss: 1.025306]\n",
      "epoch:15 step:14487 [D loss: 0.592855, acc.: 67.97%] [G loss: 1.471472]\n",
      "epoch:15 step:14488 [D loss: 0.497175, acc.: 79.69%] [G loss: 1.411991]\n",
      "epoch:15 step:14489 [D loss: 0.441197, acc.: 79.69%] [G loss: 1.315523]\n",
      "epoch:15 step:14490 [D loss: 0.366399, acc.: 87.50%] [G loss: 1.482391]\n",
      "epoch:15 step:14491 [D loss: 0.379016, acc.: 91.41%] [G loss: 1.221264]\n",
      "epoch:15 step:14492 [D loss: 0.668047, acc.: 63.28%] [G loss: 1.211299]\n",
      "epoch:15 step:14493 [D loss: 0.577538, acc.: 62.50%] [G loss: 1.065361]\n",
      "epoch:15 step:14494 [D loss: 0.642851, acc.: 57.03%] [G loss: 1.056130]\n",
      "epoch:15 step:14495 [D loss: 0.651603, acc.: 57.81%] [G loss: 0.987801]\n",
      "epoch:15 step:14496 [D loss: 0.591929, acc.: 69.53%] [G loss: 1.138998]\n",
      "epoch:15 step:14497 [D loss: 0.665678, acc.: 57.03%] [G loss: 1.102696]\n",
      "epoch:15 step:14498 [D loss: 0.382754, acc.: 87.50%] [G loss: 1.362005]\n",
      "epoch:15 step:14499 [D loss: 0.547666, acc.: 75.00%] [G loss: 1.086558]\n",
      "epoch:15 step:14500 [D loss: 0.592755, acc.: 70.31%] [G loss: 1.066020]\n",
      "epoch:15 step:14501 [D loss: 0.590416, acc.: 65.62%] [G loss: 1.211586]\n",
      "epoch:15 step:14502 [D loss: 0.605037, acc.: 66.41%] [G loss: 1.125157]\n",
      "epoch:15 step:14503 [D loss: 0.609135, acc.: 67.19%] [G loss: 0.835674]\n",
      "epoch:15 step:14504 [D loss: 0.370582, acc.: 89.84%] [G loss: 1.311006]\n",
      "epoch:15 step:14505 [D loss: 0.531609, acc.: 76.56%] [G loss: 1.074860]\n",
      "epoch:15 step:14506 [D loss: 0.580522, acc.: 67.97%] [G loss: 1.067934]\n",
      "epoch:15 step:14507 [D loss: 0.455141, acc.: 82.81%] [G loss: 1.290537]\n",
      "epoch:15 step:14508 [D loss: 0.383537, acc.: 85.94%] [G loss: 1.327051]\n",
      "epoch:15 step:14509 [D loss: 0.461560, acc.: 85.16%] [G loss: 1.305080]\n",
      "epoch:15 step:14510 [D loss: 0.633476, acc.: 63.28%] [G loss: 1.244304]\n",
      "epoch:15 step:14511 [D loss: 0.628535, acc.: 64.84%] [G loss: 1.078006]\n",
      "epoch:15 step:14512 [D loss: 0.467595, acc.: 78.91%] [G loss: 1.266682]\n",
      "epoch:15 step:14513 [D loss: 1.012910, acc.: 29.69%] [G loss: 0.885970]\n",
      "epoch:15 step:14514 [D loss: 0.919340, acc.: 40.62%] [G loss: 1.018839]\n",
      "epoch:15 step:14515 [D loss: 0.961834, acc.: 27.34%] [G loss: 0.799446]\n",
      "epoch:15 step:14516 [D loss: 0.885218, acc.: 37.50%] [G loss: 0.898647]\n",
      "epoch:15 step:14517 [D loss: 0.971215, acc.: 29.69%] [G loss: 0.981617]\n",
      "epoch:15 step:14518 [D loss: 0.802194, acc.: 50.00%] [G loss: 0.702657]\n",
      "epoch:15 step:14519 [D loss: 0.762415, acc.: 51.56%] [G loss: 1.000202]\n",
      "epoch:15 step:14520 [D loss: 0.609580, acc.: 67.97%] [G loss: 1.230469]\n",
      "epoch:15 step:14521 [D loss: 0.731858, acc.: 53.12%] [G loss: 0.999573]\n",
      "epoch:15 step:14522 [D loss: 0.928983, acc.: 39.06%] [G loss: 0.716058]\n",
      "epoch:15 step:14523 [D loss: 0.507594, acc.: 76.56%] [G loss: 1.082647]\n",
      "epoch:15 step:14524 [D loss: 0.639203, acc.: 59.38%] [G loss: 1.202154]\n",
      "epoch:15 step:14525 [D loss: 0.657504, acc.: 59.38%] [G loss: 0.748644]\n",
      "epoch:15 step:14526 [D loss: 0.514671, acc.: 77.34%] [G loss: 1.036883]\n",
      "epoch:15 step:14527 [D loss: 0.660017, acc.: 60.16%] [G loss: 1.093560]\n",
      "epoch:15 step:14528 [D loss: 1.052516, acc.: 32.03%] [G loss: 1.054745]\n",
      "epoch:15 step:14529 [D loss: 0.778705, acc.: 50.78%] [G loss: 1.094132]\n",
      "epoch:15 step:14530 [D loss: 0.613265, acc.: 66.41%] [G loss: 1.328987]\n",
      "epoch:15 step:14531 [D loss: 0.762654, acc.: 57.81%] [G loss: 1.213028]\n",
      "epoch:15 step:14532 [D loss: 0.790374, acc.: 45.31%] [G loss: 0.796787]\n",
      "epoch:15 step:14533 [D loss: 0.675033, acc.: 60.94%] [G loss: 1.012685]\n",
      "epoch:15 step:14534 [D loss: 0.683059, acc.: 57.81%] [G loss: 0.844056]\n",
      "epoch:15 step:14535 [D loss: 0.683698, acc.: 59.38%] [G loss: 1.130566]\n",
      "epoch:15 step:14536 [D loss: 0.725518, acc.: 51.56%] [G loss: 0.997228]\n",
      "epoch:15 step:14537 [D loss: 0.572789, acc.: 69.53%] [G loss: 1.296037]\n",
      "epoch:15 step:14538 [D loss: 0.550012, acc.: 72.66%] [G loss: 1.421453]\n",
      "epoch:15 step:14539 [D loss: 0.412976, acc.: 84.38%] [G loss: 1.480962]\n",
      "epoch:15 step:14540 [D loss: 0.374648, acc.: 89.84%] [G loss: 1.655025]\n",
      "epoch:15 step:14541 [D loss: 0.417795, acc.: 85.94%] [G loss: 1.419822]\n",
      "epoch:15 step:14542 [D loss: 0.365173, acc.: 88.28%] [G loss: 1.342744]\n",
      "epoch:15 step:14543 [D loss: 0.484307, acc.: 82.81%] [G loss: 1.348368]\n",
      "epoch:15 step:14544 [D loss: 0.708671, acc.: 57.81%] [G loss: 1.084237]\n",
      "epoch:15 step:14545 [D loss: 0.736243, acc.: 50.78%] [G loss: 0.899304]\n",
      "epoch:15 step:14546 [D loss: 0.718931, acc.: 50.78%] [G loss: 0.966901]\n",
      "epoch:15 step:14547 [D loss: 0.639246, acc.: 64.06%] [G loss: 0.997695]\n",
      "epoch:15 step:14548 [D loss: 0.490396, acc.: 80.47%] [G loss: 1.116861]\n",
      "epoch:15 step:14549 [D loss: 0.628724, acc.: 63.28%] [G loss: 1.005774]\n",
      "epoch:15 step:14550 [D loss: 0.586809, acc.: 70.31%] [G loss: 1.135458]\n",
      "epoch:15 step:14551 [D loss: 0.559261, acc.: 70.31%] [G loss: 1.001218]\n",
      "epoch:15 step:14552 [D loss: 0.363609, acc.: 87.50%] [G loss: 1.371032]\n",
      "epoch:15 step:14553 [D loss: 0.344432, acc.: 93.75%] [G loss: 1.451165]\n",
      "epoch:15 step:14554 [D loss: 0.304796, acc.: 92.19%] [G loss: 1.568100]\n",
      "epoch:15 step:14555 [D loss: 0.784347, acc.: 53.12%] [G loss: 1.293291]\n",
      "epoch:15 step:14556 [D loss: 0.691161, acc.: 60.94%] [G loss: 0.986677]\n",
      "epoch:15 step:14557 [D loss: 0.682204, acc.: 56.25%] [G loss: 0.955552]\n",
      "epoch:15 step:14558 [D loss: 0.835428, acc.: 36.72%] [G loss: 0.876090]\n",
      "epoch:15 step:14559 [D loss: 0.756937, acc.: 49.22%] [G loss: 1.260341]\n",
      "epoch:15 step:14560 [D loss: 0.614430, acc.: 62.50%] [G loss: 1.126086]\n",
      "epoch:15 step:14561 [D loss: 0.722430, acc.: 56.25%] [G loss: 1.137254]\n",
      "epoch:15 step:14562 [D loss: 0.644314, acc.: 62.50%] [G loss: 0.943865]\n",
      "epoch:15 step:14563 [D loss: 0.561800, acc.: 69.53%] [G loss: 0.914145]\n",
      "epoch:15 step:14564 [D loss: 0.699860, acc.: 61.72%] [G loss: 0.963168]\n",
      "epoch:15 step:14565 [D loss: 0.665888, acc.: 64.06%] [G loss: 0.866735]\n",
      "epoch:15 step:14566 [D loss: 0.574656, acc.: 73.44%] [G loss: 1.020697]\n",
      "epoch:15 step:14567 [D loss: 0.630504, acc.: 57.81%] [G loss: 0.992708]\n",
      "epoch:15 step:14568 [D loss: 0.576145, acc.: 67.97%] [G loss: 0.988117]\n",
      "epoch:15 step:14569 [D loss: 0.550434, acc.: 75.78%] [G loss: 1.068844]\n",
      "epoch:15 step:14570 [D loss: 0.494557, acc.: 78.91%] [G loss: 1.089215]\n",
      "epoch:15 step:14571 [D loss: 0.680727, acc.: 60.16%] [G loss: 0.985424]\n",
      "epoch:15 step:14572 [D loss: 0.700537, acc.: 53.91%] [G loss: 1.193251]\n",
      "epoch:15 step:14573 [D loss: 0.701638, acc.: 57.03%] [G loss: 1.078094]\n",
      "epoch:15 step:14574 [D loss: 0.536736, acc.: 73.44%] [G loss: 0.962009]\n",
      "epoch:15 step:14575 [D loss: 0.543029, acc.: 75.00%] [G loss: 0.992991]\n",
      "epoch:15 step:14576 [D loss: 0.546971, acc.: 75.78%] [G loss: 1.250497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14577 [D loss: 0.484787, acc.: 77.34%] [G loss: 1.198310]\n",
      "epoch:15 step:14578 [D loss: 0.483235, acc.: 82.03%] [G loss: 1.214918]\n",
      "epoch:15 step:14579 [D loss: 0.717370, acc.: 48.44%] [G loss: 0.970813]\n",
      "epoch:15 step:14580 [D loss: 0.594372, acc.: 65.62%] [G loss: 0.886721]\n",
      "epoch:15 step:14581 [D loss: 0.690512, acc.: 59.38%] [G loss: 0.968912]\n",
      "epoch:15 step:14582 [D loss: 0.685205, acc.: 60.16%] [G loss: 0.991601]\n",
      "epoch:15 step:14583 [D loss: 0.675723, acc.: 57.03%] [G loss: 1.052334]\n",
      "epoch:15 step:14584 [D loss: 0.678201, acc.: 59.38%] [G loss: 1.067033]\n",
      "epoch:15 step:14585 [D loss: 0.696056, acc.: 53.12%] [G loss: 0.913722]\n",
      "epoch:15 step:14586 [D loss: 0.594157, acc.: 73.44%] [G loss: 0.951713]\n",
      "epoch:15 step:14587 [D loss: 0.575190, acc.: 69.53%] [G loss: 1.000744]\n",
      "epoch:15 step:14588 [D loss: 0.432999, acc.: 85.16%] [G loss: 1.158212]\n",
      "epoch:15 step:14589 [D loss: 0.537964, acc.: 77.34%] [G loss: 1.116935]\n",
      "epoch:15 step:14590 [D loss: 0.641631, acc.: 64.06%] [G loss: 1.078343]\n",
      "epoch:15 step:14591 [D loss: 0.661554, acc.: 62.50%] [G loss: 1.182580]\n",
      "epoch:15 step:14592 [D loss: 0.492752, acc.: 83.59%] [G loss: 1.047883]\n",
      "epoch:15 step:14593 [D loss: 0.705165, acc.: 56.25%] [G loss: 1.142870]\n",
      "epoch:15 step:14594 [D loss: 0.613370, acc.: 64.84%] [G loss: 1.009395]\n",
      "epoch:15 step:14595 [D loss: 0.664800, acc.: 59.38%] [G loss: 1.125222]\n",
      "epoch:15 step:14596 [D loss: 0.648896, acc.: 60.16%] [G loss: 1.072008]\n",
      "epoch:15 step:14597 [D loss: 0.576623, acc.: 71.88%] [G loss: 1.063760]\n",
      "epoch:15 step:14598 [D loss: 0.639636, acc.: 62.50%] [G loss: 1.078232]\n",
      "epoch:15 step:14599 [D loss: 0.584576, acc.: 68.75%] [G loss: 0.891732]\n",
      "epoch:15 step:14600 [D loss: 0.577431, acc.: 68.75%] [G loss: 1.027871]\n",
      "epoch:15 step:14601 [D loss: 0.499217, acc.: 82.03%] [G loss: 1.224029]\n",
      "epoch:15 step:14602 [D loss: 0.446365, acc.: 87.50%] [G loss: 1.444343]\n",
      "epoch:15 step:14603 [D loss: 0.598588, acc.: 66.41%] [G loss: 1.079610]\n",
      "epoch:15 step:14604 [D loss: 0.485199, acc.: 80.47%] [G loss: 1.213927]\n",
      "epoch:15 step:14605 [D loss: 0.468342, acc.: 79.69%] [G loss: 1.305876]\n",
      "epoch:15 step:14606 [D loss: 0.316799, acc.: 95.31%] [G loss: 1.357061]\n",
      "epoch:15 step:14607 [D loss: 0.413690, acc.: 87.50%] [G loss: 1.338937]\n",
      "epoch:15 step:14608 [D loss: 0.561067, acc.: 71.09%] [G loss: 1.053149]\n",
      "epoch:15 step:14609 [D loss: 0.393730, acc.: 89.06%] [G loss: 1.311496]\n",
      "epoch:15 step:14610 [D loss: 0.630141, acc.: 67.19%] [G loss: 0.983102]\n",
      "epoch:15 step:14611 [D loss: 0.453860, acc.: 82.03%] [G loss: 1.345030]\n",
      "epoch:15 step:14612 [D loss: 0.411339, acc.: 87.50%] [G loss: 1.456861]\n",
      "epoch:15 step:14613 [D loss: 0.435044, acc.: 82.03%] [G loss: 1.591009]\n",
      "epoch:15 step:14614 [D loss: 0.993334, acc.: 28.91%] [G loss: 0.847622]\n",
      "epoch:15 step:14615 [D loss: 0.863883, acc.: 35.94%] [G loss: 1.037298]\n",
      "epoch:15 step:14616 [D loss: 0.542516, acc.: 75.00%] [G loss: 1.426815]\n",
      "epoch:15 step:14617 [D loss: 0.674835, acc.: 57.03%] [G loss: 1.294791]\n",
      "epoch:15 step:14618 [D loss: 0.700959, acc.: 56.25%] [G loss: 1.095012]\n",
      "epoch:15 step:14619 [D loss: 0.654876, acc.: 58.59%] [G loss: 1.141090]\n",
      "epoch:15 step:14620 [D loss: 0.523125, acc.: 76.56%] [G loss: 1.130152]\n",
      "epoch:15 step:14621 [D loss: 0.520831, acc.: 73.44%] [G loss: 1.033217]\n",
      "epoch:15 step:14622 [D loss: 0.451806, acc.: 79.69%] [G loss: 1.355770]\n",
      "epoch:15 step:14623 [D loss: 0.663100, acc.: 64.06%] [G loss: 1.147161]\n",
      "epoch:15 step:14624 [D loss: 0.693815, acc.: 57.03%] [G loss: 1.270634]\n",
      "epoch:15 step:14625 [D loss: 0.735403, acc.: 52.34%] [G loss: 0.981439]\n",
      "epoch:15 step:14626 [D loss: 0.533621, acc.: 76.56%] [G loss: 0.809860]\n",
      "epoch:15 step:14627 [D loss: 0.610995, acc.: 67.19%] [G loss: 1.036911]\n",
      "epoch:15 step:14628 [D loss: 0.646114, acc.: 65.62%] [G loss: 0.875805]\n",
      "epoch:15 step:14629 [D loss: 0.570891, acc.: 75.78%] [G loss: 1.082563]\n",
      "epoch:15 step:14630 [D loss: 0.573296, acc.: 71.09%] [G loss: 0.998282]\n",
      "epoch:15 step:14631 [D loss: 0.509871, acc.: 80.47%] [G loss: 1.116597]\n",
      "epoch:15 step:14632 [D loss: 0.625704, acc.: 64.84%] [G loss: 1.060863]\n",
      "epoch:15 step:14633 [D loss: 0.528351, acc.: 75.78%] [G loss: 1.102100]\n",
      "epoch:15 step:14634 [D loss: 0.629383, acc.: 60.94%] [G loss: 1.070928]\n",
      "epoch:15 step:14635 [D loss: 0.708158, acc.: 52.34%] [G loss: 1.013793]\n",
      "epoch:15 step:14636 [D loss: 0.687369, acc.: 51.56%] [G loss: 0.951823]\n",
      "epoch:15 step:14637 [D loss: 0.739532, acc.: 50.78%] [G loss: 0.804465]\n",
      "epoch:15 step:14638 [D loss: 0.737250, acc.: 51.56%] [G loss: 0.924630]\n",
      "epoch:15 step:14639 [D loss: 0.816936, acc.: 45.31%] [G loss: 0.742493]\n",
      "epoch:15 step:14640 [D loss: 0.659433, acc.: 66.41%] [G loss: 0.913450]\n",
      "epoch:15 step:14641 [D loss: 0.657172, acc.: 58.59%] [G loss: 1.056129]\n",
      "epoch:15 step:14642 [D loss: 0.441597, acc.: 79.69%] [G loss: 1.080201]\n",
      "epoch:15 step:14643 [D loss: 0.431673, acc.: 82.81%] [G loss: 1.346934]\n",
      "epoch:15 step:14644 [D loss: 0.411687, acc.: 87.50%] [G loss: 1.367459]\n",
      "epoch:15 step:14645 [D loss: 0.741763, acc.: 48.44%] [G loss: 1.068392]\n",
      "epoch:15 step:14646 [D loss: 0.782949, acc.: 47.66%] [G loss: 1.256746]\n",
      "epoch:15 step:14647 [D loss: 0.634258, acc.: 67.19%] [G loss: 1.235334]\n",
      "epoch:15 step:14648 [D loss: 0.753159, acc.: 46.88%] [G loss: 1.139334]\n",
      "epoch:15 step:14649 [D loss: 0.576404, acc.: 67.19%] [G loss: 1.173648]\n",
      "epoch:15 step:14650 [D loss: 0.651244, acc.: 62.50%] [G loss: 1.079028]\n",
      "epoch:15 step:14651 [D loss: 0.535645, acc.: 78.91%] [G loss: 1.046786]\n",
      "epoch:15 step:14652 [D loss: 0.529077, acc.: 75.78%] [G loss: 1.190239]\n",
      "epoch:15 step:14653 [D loss: 0.394597, acc.: 85.94%] [G loss: 1.261153]\n",
      "epoch:15 step:14654 [D loss: 0.684027, acc.: 57.81%] [G loss: 1.245515]\n",
      "epoch:15 step:14655 [D loss: 0.773345, acc.: 46.09%] [G loss: 0.916934]\n",
      "epoch:15 step:14656 [D loss: 0.672109, acc.: 58.59%] [G loss: 0.978851]\n",
      "epoch:15 step:14657 [D loss: 0.552885, acc.: 73.44%] [G loss: 1.108186]\n",
      "epoch:15 step:14658 [D loss: 0.548664, acc.: 75.78%] [G loss: 0.971319]\n",
      "epoch:15 step:14659 [D loss: 0.453593, acc.: 84.38%] [G loss: 1.385840]\n",
      "epoch:15 step:14660 [D loss: 0.452440, acc.: 83.59%] [G loss: 1.400271]\n",
      "epoch:15 step:14661 [D loss: 0.604347, acc.: 67.19%] [G loss: 0.961871]\n",
      "epoch:15 step:14662 [D loss: 0.641435, acc.: 64.06%] [G loss: 1.305401]\n",
      "epoch:15 step:14663 [D loss: 0.700461, acc.: 56.25%] [G loss: 0.988808]\n",
      "epoch:15 step:14664 [D loss: 0.757656, acc.: 52.34%] [G loss: 0.816818]\n",
      "epoch:15 step:14665 [D loss: 0.666323, acc.: 56.25%] [G loss: 1.081820]\n",
      "epoch:15 step:14666 [D loss: 0.582406, acc.: 67.19%] [G loss: 1.150300]\n",
      "epoch:15 step:14667 [D loss: 0.746349, acc.: 53.12%] [G loss: 1.080532]\n",
      "epoch:15 step:14668 [D loss: 0.631568, acc.: 61.72%] [G loss: 1.037640]\n",
      "epoch:15 step:14669 [D loss: 0.503278, acc.: 75.78%] [G loss: 1.119420]\n",
      "epoch:15 step:14670 [D loss: 0.579347, acc.: 69.53%] [G loss: 1.001381]\n",
      "epoch:15 step:14671 [D loss: 0.492644, acc.: 82.81%] [G loss: 1.065312]\n",
      "epoch:15 step:14672 [D loss: 0.679124, acc.: 63.28%] [G loss: 1.091533]\n",
      "epoch:15 step:14673 [D loss: 0.751391, acc.: 50.78%] [G loss: 1.161108]\n",
      "epoch:15 step:14674 [D loss: 0.706865, acc.: 58.59%] [G loss: 1.157101]\n",
      "epoch:15 step:14675 [D loss: 0.735166, acc.: 55.47%] [G loss: 0.858747]\n",
      "epoch:15 step:14676 [D loss: 0.724545, acc.: 50.78%] [G loss: 1.013765]\n",
      "epoch:15 step:14677 [D loss: 0.684046, acc.: 57.03%] [G loss: 1.102001]\n",
      "epoch:15 step:14678 [D loss: 0.708779, acc.: 50.78%] [G loss: 1.047914]\n",
      "epoch:15 step:14679 [D loss: 0.614942, acc.: 68.75%] [G loss: 0.971986]\n",
      "epoch:15 step:14680 [D loss: 0.739631, acc.: 53.91%] [G loss: 1.031878]\n",
      "epoch:15 step:14681 [D loss: 0.618051, acc.: 62.50%] [G loss: 1.193094]\n",
      "epoch:15 step:14682 [D loss: 0.630417, acc.: 62.50%] [G loss: 1.010152]\n",
      "epoch:15 step:14683 [D loss: 0.636509, acc.: 62.50%] [G loss: 1.002547]\n",
      "epoch:15 step:14684 [D loss: 0.528385, acc.: 74.22%] [G loss: 1.229392]\n",
      "epoch:15 step:14685 [D loss: 0.744458, acc.: 53.91%] [G loss: 0.968062]\n",
      "epoch:15 step:14686 [D loss: 0.652929, acc.: 63.28%] [G loss: 1.129270]\n",
      "epoch:15 step:14687 [D loss: 0.703337, acc.: 56.25%] [G loss: 0.947891]\n",
      "epoch:15 step:14688 [D loss: 0.621272, acc.: 67.19%] [G loss: 1.128693]\n",
      "epoch:15 step:14689 [D loss: 0.673443, acc.: 60.16%] [G loss: 0.873651]\n",
      "epoch:15 step:14690 [D loss: 0.600429, acc.: 65.62%] [G loss: 1.096696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14691 [D loss: 0.715531, acc.: 55.47%] [G loss: 0.854106]\n",
      "epoch:15 step:14692 [D loss: 0.544226, acc.: 75.00%] [G loss: 1.319369]\n",
      "epoch:15 step:14693 [D loss: 0.604647, acc.: 68.75%] [G loss: 1.005213]\n",
      "epoch:15 step:14694 [D loss: 0.566459, acc.: 71.88%] [G loss: 1.117001]\n",
      "epoch:15 step:14695 [D loss: 0.597916, acc.: 67.97%] [G loss: 0.958068]\n",
      "epoch:15 step:14696 [D loss: 0.441603, acc.: 81.25%] [G loss: 1.111815]\n",
      "epoch:15 step:14697 [D loss: 0.372429, acc.: 92.19%] [G loss: 1.437729]\n",
      "epoch:15 step:14698 [D loss: 0.651277, acc.: 63.28%] [G loss: 1.176757]\n",
      "epoch:15 step:14699 [D loss: 0.776526, acc.: 46.88%] [G loss: 1.041222]\n",
      "epoch:15 step:14700 [D loss: 0.669519, acc.: 57.81%] [G loss: 0.862276]\n",
      "epoch:15 step:14701 [D loss: 0.608372, acc.: 67.97%] [G loss: 1.176714]\n",
      "epoch:15 step:14702 [D loss: 0.570073, acc.: 74.22%] [G loss: 0.985761]\n",
      "epoch:15 step:14703 [D loss: 0.575867, acc.: 71.88%] [G loss: 0.992002]\n",
      "epoch:15 step:14704 [D loss: 0.532763, acc.: 76.56%] [G loss: 1.218315]\n",
      "epoch:15 step:14705 [D loss: 0.508413, acc.: 77.34%] [G loss: 1.209666]\n",
      "epoch:15 step:14706 [D loss: 0.564168, acc.: 72.66%] [G loss: 1.261018]\n",
      "epoch:15 step:14707 [D loss: 0.817935, acc.: 47.66%] [G loss: 0.997444]\n",
      "epoch:15 step:14708 [D loss: 0.710239, acc.: 53.12%] [G loss: 1.018546]\n",
      "epoch:15 step:14709 [D loss: 0.633270, acc.: 66.41%] [G loss: 1.115666]\n",
      "epoch:15 step:14710 [D loss: 0.690929, acc.: 60.94%] [G loss: 0.902394]\n",
      "epoch:15 step:14711 [D loss: 0.638116, acc.: 61.72%] [G loss: 1.023505]\n",
      "epoch:15 step:14712 [D loss: 0.810203, acc.: 40.62%] [G loss: 0.945746]\n",
      "epoch:15 step:14713 [D loss: 0.653848, acc.: 60.16%] [G loss: 0.998730]\n",
      "epoch:15 step:14714 [D loss: 0.678623, acc.: 59.38%] [G loss: 0.907179]\n",
      "epoch:15 step:14715 [D loss: 0.634351, acc.: 63.28%] [G loss: 1.021151]\n",
      "epoch:15 step:14716 [D loss: 0.739638, acc.: 50.00%] [G loss: 0.935133]\n",
      "epoch:15 step:14717 [D loss: 0.592775, acc.: 65.62%] [G loss: 1.220202]\n",
      "epoch:15 step:14718 [D loss: 0.424768, acc.: 81.25%] [G loss: 1.318525]\n",
      "epoch:15 step:14719 [D loss: 0.458552, acc.: 78.91%] [G loss: 1.156049]\n",
      "epoch:15 step:14720 [D loss: 0.372758, acc.: 93.75%] [G loss: 1.489725]\n",
      "epoch:15 step:14721 [D loss: 0.581786, acc.: 69.53%] [G loss: 1.240874]\n",
      "epoch:15 step:14722 [D loss: 0.566328, acc.: 71.09%] [G loss: 1.041100]\n",
      "epoch:15 step:14723 [D loss: 0.622180, acc.: 63.28%] [G loss: 1.033368]\n",
      "epoch:15 step:14724 [D loss: 0.753288, acc.: 53.12%] [G loss: 1.003311]\n",
      "epoch:15 step:14725 [D loss: 0.636851, acc.: 63.28%] [G loss: 0.800112]\n",
      "epoch:15 step:14726 [D loss: 0.680490, acc.: 52.34%] [G loss: 0.970297]\n",
      "epoch:15 step:14727 [D loss: 0.657817, acc.: 58.59%] [G loss: 1.160575]\n",
      "epoch:15 step:14728 [D loss: 0.761149, acc.: 53.12%] [G loss: 1.080892]\n",
      "epoch:15 step:14729 [D loss: 0.725450, acc.: 53.91%] [G loss: 0.934418]\n",
      "epoch:15 step:14730 [D loss: 0.738458, acc.: 52.34%] [G loss: 0.961493]\n",
      "epoch:15 step:14731 [D loss: 0.623985, acc.: 60.94%] [G loss: 0.936963]\n",
      "epoch:15 step:14732 [D loss: 0.650050, acc.: 60.94%] [G loss: 1.042737]\n",
      "epoch:15 step:14733 [D loss: 0.672941, acc.: 58.59%] [G loss: 1.019038]\n",
      "epoch:15 step:14734 [D loss: 0.544800, acc.: 75.78%] [G loss: 1.043690]\n",
      "epoch:15 step:14735 [D loss: 0.737771, acc.: 53.12%] [G loss: 0.953908]\n",
      "epoch:15 step:14736 [D loss: 0.584779, acc.: 70.31%] [G loss: 1.116610]\n",
      "epoch:15 step:14737 [D loss: 0.731658, acc.: 52.34%] [G loss: 1.098804]\n",
      "epoch:15 step:14738 [D loss: 0.705299, acc.: 58.59%] [G loss: 0.970714]\n",
      "epoch:15 step:14739 [D loss: 0.634976, acc.: 66.41%] [G loss: 0.948273]\n",
      "epoch:15 step:14740 [D loss: 0.500035, acc.: 78.12%] [G loss: 1.198440]\n",
      "epoch:15 step:14741 [D loss: 0.694494, acc.: 55.47%] [G loss: 1.085845]\n",
      "epoch:15 step:14742 [D loss: 0.706188, acc.: 56.25%] [G loss: 1.061579]\n",
      "epoch:15 step:14743 [D loss: 0.658821, acc.: 66.41%] [G loss: 0.991904]\n",
      "epoch:15 step:14744 [D loss: 0.590194, acc.: 68.75%] [G loss: 1.035679]\n",
      "epoch:15 step:14745 [D loss: 0.377087, acc.: 91.41%] [G loss: 1.165303]\n",
      "epoch:15 step:14746 [D loss: 0.480109, acc.: 82.03%] [G loss: 1.190230]\n",
      "epoch:15 step:14747 [D loss: 0.575467, acc.: 70.31%] [G loss: 1.027221]\n",
      "epoch:15 step:14748 [D loss: 0.560633, acc.: 69.53%] [G loss: 0.952591]\n",
      "epoch:15 step:14749 [D loss: 0.438116, acc.: 81.25%] [G loss: 1.077960]\n",
      "epoch:15 step:14750 [D loss: 0.562654, acc.: 68.75%] [G loss: 1.202033]\n",
      "epoch:15 step:14751 [D loss: 0.729274, acc.: 53.91%] [G loss: 1.082345]\n",
      "epoch:15 step:14752 [D loss: 0.604921, acc.: 60.94%] [G loss: 1.022632]\n",
      "epoch:15 step:14753 [D loss: 0.655740, acc.: 63.28%] [G loss: 1.076800]\n",
      "epoch:15 step:14754 [D loss: 0.610424, acc.: 68.75%] [G loss: 1.140713]\n",
      "epoch:15 step:14755 [D loss: 0.487093, acc.: 79.69%] [G loss: 1.138367]\n",
      "epoch:15 step:14756 [D loss: 0.508742, acc.: 75.78%] [G loss: 1.051209]\n",
      "epoch:15 step:14757 [D loss: 0.532753, acc.: 75.00%] [G loss: 1.099297]\n",
      "epoch:15 step:14758 [D loss: 0.707595, acc.: 60.16%] [G loss: 0.895760]\n",
      "epoch:15 step:14759 [D loss: 0.645989, acc.: 62.50%] [G loss: 1.072023]\n",
      "epoch:15 step:14760 [D loss: 0.449833, acc.: 85.16%] [G loss: 1.141068]\n",
      "epoch:15 step:14761 [D loss: 0.519751, acc.: 69.53%] [G loss: 1.160830]\n",
      "epoch:15 step:14762 [D loss: 0.509886, acc.: 72.66%] [G loss: 1.149057]\n",
      "epoch:15 step:14763 [D loss: 0.443706, acc.: 84.38%] [G loss: 1.279229]\n",
      "epoch:15 step:14764 [D loss: 0.342729, acc.: 92.19%] [G loss: 1.782112]\n",
      "epoch:15 step:14765 [D loss: 0.778776, acc.: 48.44%] [G loss: 1.292577]\n",
      "epoch:15 step:14766 [D loss: 0.652309, acc.: 60.94%] [G loss: 1.300089]\n",
      "epoch:15 step:14767 [D loss: 0.740042, acc.: 55.47%] [G loss: 0.768661]\n",
      "epoch:15 step:14768 [D loss: 0.414491, acc.: 82.81%] [G loss: 1.006691]\n",
      "epoch:15 step:14769 [D loss: 0.493032, acc.: 79.69%] [G loss: 1.290881]\n",
      "epoch:15 step:14770 [D loss: 0.537570, acc.: 75.78%] [G loss: 1.327850]\n",
      "epoch:15 step:14771 [D loss: 0.996342, acc.: 31.25%] [G loss: 0.892643]\n",
      "epoch:15 step:14772 [D loss: 0.647604, acc.: 61.72%] [G loss: 0.856454]\n",
      "epoch:15 step:14773 [D loss: 0.824781, acc.: 43.75%] [G loss: 0.805658]\n",
      "epoch:15 step:14774 [D loss: 0.681266, acc.: 55.47%] [G loss: 1.072643]\n",
      "epoch:15 step:14775 [D loss: 0.890918, acc.: 32.03%] [G loss: 0.938211]\n",
      "epoch:15 step:14776 [D loss: 0.710639, acc.: 52.34%] [G loss: 0.924521]\n",
      "epoch:15 step:14777 [D loss: 0.773796, acc.: 39.84%] [G loss: 0.899917]\n",
      "epoch:15 step:14778 [D loss: 0.651587, acc.: 63.28%] [G loss: 1.041151]\n",
      "epoch:15 step:14779 [D loss: 0.564950, acc.: 75.78%] [G loss: 1.164387]\n",
      "epoch:15 step:14780 [D loss: 0.532294, acc.: 76.56%] [G loss: 1.104290]\n",
      "epoch:15 step:14781 [D loss: 0.529539, acc.: 77.34%] [G loss: 1.117778]\n",
      "epoch:15 step:14782 [D loss: 0.748343, acc.: 55.47%] [G loss: 1.255767]\n",
      "epoch:15 step:14783 [D loss: 0.660516, acc.: 64.84%] [G loss: 1.154553]\n",
      "epoch:15 step:14784 [D loss: 0.602046, acc.: 64.84%] [G loss: 1.111089]\n",
      "epoch:15 step:14785 [D loss: 0.717209, acc.: 56.25%] [G loss: 1.029932]\n",
      "epoch:15 step:14786 [D loss: 0.623020, acc.: 67.97%] [G loss: 1.061588]\n",
      "epoch:15 step:14787 [D loss: 0.508467, acc.: 76.56%] [G loss: 1.150282]\n",
      "epoch:15 step:14788 [D loss: 0.526931, acc.: 77.34%] [G loss: 1.024310]\n",
      "epoch:15 step:14789 [D loss: 0.630333, acc.: 62.50%] [G loss: 0.985441]\n",
      "epoch:15 step:14790 [D loss: 0.675395, acc.: 62.50%] [G loss: 1.049310]\n",
      "epoch:15 step:14791 [D loss: 0.628813, acc.: 67.19%] [G loss: 1.011501]\n",
      "epoch:15 step:14792 [D loss: 0.610427, acc.: 67.19%] [G loss: 0.997854]\n",
      "epoch:15 step:14793 [D loss: 0.699734, acc.: 56.25%] [G loss: 1.068319]\n",
      "epoch:15 step:14794 [D loss: 0.658834, acc.: 60.94%] [G loss: 0.968121]\n",
      "epoch:15 step:14795 [D loss: 0.815510, acc.: 38.28%] [G loss: 0.788024]\n",
      "epoch:15 step:14796 [D loss: 0.541902, acc.: 76.56%] [G loss: 1.092644]\n",
      "epoch:15 step:14797 [D loss: 0.561490, acc.: 71.88%] [G loss: 1.126158]\n",
      "epoch:15 step:14798 [D loss: 0.541644, acc.: 69.53%] [G loss: 0.990957]\n",
      "epoch:15 step:14799 [D loss: 0.656631, acc.: 60.94%] [G loss: 1.060587]\n",
      "epoch:15 step:14800 [D loss: 0.645275, acc.: 59.38%] [G loss: 0.917221]\n",
      "epoch:15 step:14801 [D loss: 0.607319, acc.: 71.09%] [G loss: 1.109423]\n",
      "epoch:15 step:14802 [D loss: 0.626139, acc.: 66.41%] [G loss: 1.128249]\n",
      "epoch:15 step:14803 [D loss: 0.597061, acc.: 68.75%] [G loss: 1.066369]\n",
      "epoch:15 step:14804 [D loss: 0.555470, acc.: 71.09%] [G loss: 1.222752]\n",
      "epoch:15 step:14805 [D loss: 0.636795, acc.: 61.72%] [G loss: 1.059324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14806 [D loss: 0.658132, acc.: 58.59%] [G loss: 0.899355]\n",
      "epoch:15 step:14807 [D loss: 0.783380, acc.: 45.31%] [G loss: 0.869266]\n",
      "epoch:15 step:14808 [D loss: 0.673193, acc.: 63.28%] [G loss: 0.990923]\n",
      "epoch:15 step:14809 [D loss: 0.605139, acc.: 69.53%] [G loss: 1.032686]\n",
      "epoch:15 step:14810 [D loss: 0.504861, acc.: 78.12%] [G loss: 1.064659]\n",
      "epoch:15 step:14811 [D loss: 0.567677, acc.: 71.88%] [G loss: 1.033786]\n",
      "epoch:15 step:14812 [D loss: 0.532958, acc.: 76.56%] [G loss: 1.190753]\n",
      "epoch:15 step:14813 [D loss: 0.756180, acc.: 50.00%] [G loss: 0.963473]\n",
      "epoch:15 step:14814 [D loss: 0.714579, acc.: 50.78%] [G loss: 0.964520]\n",
      "epoch:15 step:14815 [D loss: 0.720577, acc.: 49.22%] [G loss: 1.049474]\n",
      "epoch:15 step:14816 [D loss: 0.678779, acc.: 52.34%] [G loss: 0.987478]\n",
      "epoch:15 step:14817 [D loss: 0.679947, acc.: 57.03%] [G loss: 1.018093]\n",
      "epoch:15 step:14818 [D loss: 0.688854, acc.: 57.03%] [G loss: 0.919365]\n",
      "epoch:15 step:14819 [D loss: 0.561437, acc.: 73.44%] [G loss: 0.953413]\n",
      "epoch:15 step:14820 [D loss: 0.660918, acc.: 57.03%] [G loss: 1.103572]\n",
      "epoch:15 step:14821 [D loss: 0.716532, acc.: 57.81%] [G loss: 0.983385]\n",
      "epoch:15 step:14822 [D loss: 0.604831, acc.: 64.84%] [G loss: 1.052090]\n",
      "epoch:15 step:14823 [D loss: 0.543727, acc.: 72.66%] [G loss: 1.233699]\n",
      "epoch:15 step:14824 [D loss: 0.436386, acc.: 83.59%] [G loss: 1.413345]\n",
      "epoch:15 step:14825 [D loss: 0.617358, acc.: 67.19%] [G loss: 0.883320]\n",
      "epoch:15 step:14826 [D loss: 0.625902, acc.: 64.06%] [G loss: 1.088206]\n",
      "epoch:15 step:14827 [D loss: 0.634433, acc.: 64.06%] [G loss: 0.934250]\n",
      "epoch:15 step:14828 [D loss: 0.579215, acc.: 68.75%] [G loss: 0.902644]\n",
      "epoch:15 step:14829 [D loss: 0.513358, acc.: 66.41%] [G loss: 1.016343]\n",
      "epoch:15 step:14830 [D loss: 0.300285, acc.: 94.53%] [G loss: 1.432555]\n",
      "epoch:15 step:14831 [D loss: 0.502382, acc.: 73.44%] [G loss: 1.200348]\n",
      "epoch:15 step:14832 [D loss: 0.483256, acc.: 81.25%] [G loss: 1.174104]\n",
      "epoch:15 step:14833 [D loss: 0.726550, acc.: 53.12%] [G loss: 0.948590]\n",
      "epoch:15 step:14834 [D loss: 0.886910, acc.: 39.06%] [G loss: 0.777766]\n",
      "epoch:15 step:14835 [D loss: 0.764167, acc.: 55.47%] [G loss: 1.141525]\n",
      "epoch:15 step:14836 [D loss: 0.678131, acc.: 57.03%] [G loss: 1.067317]\n",
      "epoch:15 step:14837 [D loss: 0.518162, acc.: 76.56%] [G loss: 1.240947]\n",
      "epoch:15 step:14838 [D loss: 0.651674, acc.: 67.19%] [G loss: 1.014527]\n",
      "epoch:15 step:14839 [D loss: 0.736882, acc.: 56.25%] [G loss: 1.189541]\n",
      "epoch:15 step:14840 [D loss: 0.702034, acc.: 52.34%] [G loss: 0.947223]\n",
      "epoch:15 step:14841 [D loss: 0.587851, acc.: 66.41%] [G loss: 0.979905]\n",
      "epoch:15 step:14842 [D loss: 0.600086, acc.: 71.09%] [G loss: 1.041400]\n",
      "epoch:15 step:14843 [D loss: 0.678378, acc.: 60.94%] [G loss: 1.003756]\n",
      "epoch:15 step:14844 [D loss: 0.718421, acc.: 53.91%] [G loss: 0.827295]\n",
      "epoch:15 step:14845 [D loss: 0.552268, acc.: 72.66%] [G loss: 1.013239]\n",
      "epoch:15 step:14846 [D loss: 0.484752, acc.: 78.91%] [G loss: 1.253431]\n",
      "epoch:15 step:14847 [D loss: 0.403512, acc.: 89.84%] [G loss: 1.169771]\n",
      "epoch:15 step:14848 [D loss: 0.615517, acc.: 66.41%] [G loss: 1.094977]\n",
      "epoch:15 step:14849 [D loss: 0.483940, acc.: 81.25%] [G loss: 1.220883]\n",
      "epoch:15 step:14850 [D loss: 0.557498, acc.: 74.22%] [G loss: 1.100133]\n",
      "epoch:15 step:14851 [D loss: 0.547750, acc.: 77.34%] [G loss: 1.128363]\n",
      "epoch:15 step:14852 [D loss: 0.563937, acc.: 72.66%] [G loss: 1.281922]\n",
      "epoch:15 step:14853 [D loss: 0.640434, acc.: 61.72%] [G loss: 0.965340]\n",
      "epoch:15 step:14854 [D loss: 0.754079, acc.: 48.44%] [G loss: 0.850600]\n",
      "epoch:15 step:14855 [D loss: 0.846079, acc.: 38.28%] [G loss: 0.956730]\n",
      "epoch:15 step:14856 [D loss: 0.694221, acc.: 54.69%] [G loss: 1.011435]\n",
      "epoch:15 step:14857 [D loss: 0.732788, acc.: 55.47%] [G loss: 0.778764]\n",
      "epoch:15 step:14858 [D loss: 0.604993, acc.: 66.41%] [G loss: 1.157447]\n",
      "epoch:15 step:14859 [D loss: 0.578490, acc.: 67.19%] [G loss: 1.063510]\n",
      "epoch:15 step:14860 [D loss: 0.635444, acc.: 64.84%] [G loss: 1.106358]\n",
      "epoch:15 step:14861 [D loss: 0.522802, acc.: 78.12%] [G loss: 1.065124]\n",
      "epoch:15 step:14862 [D loss: 0.495222, acc.: 83.59%] [G loss: 1.061351]\n",
      "epoch:15 step:14863 [D loss: 0.470302, acc.: 82.81%] [G loss: 1.133091]\n",
      "epoch:15 step:14864 [D loss: 0.437002, acc.: 87.50%] [G loss: 1.267527]\n",
      "epoch:15 step:14865 [D loss: 0.489873, acc.: 82.81%] [G loss: 1.362969]\n",
      "epoch:15 step:14866 [D loss: 0.694529, acc.: 58.59%] [G loss: 1.234542]\n",
      "epoch:15 step:14867 [D loss: 0.633368, acc.: 67.19%] [G loss: 0.905200]\n",
      "epoch:15 step:14868 [D loss: 0.508409, acc.: 81.25%] [G loss: 1.164638]\n",
      "epoch:15 step:14869 [D loss: 0.669608, acc.: 66.41%] [G loss: 1.063328]\n",
      "epoch:15 step:14870 [D loss: 0.277061, acc.: 91.41%] [G loss: 1.262897]\n",
      "epoch:15 step:14871 [D loss: 0.568700, acc.: 68.75%] [G loss: 1.037859]\n",
      "epoch:15 step:14872 [D loss: 0.643708, acc.: 62.50%] [G loss: 1.303445]\n",
      "epoch:15 step:14873 [D loss: 0.565783, acc.: 72.66%] [G loss: 1.170697]\n",
      "epoch:15 step:14874 [D loss: 0.847100, acc.: 41.41%] [G loss: 0.961176]\n",
      "epoch:15 step:14875 [D loss: 0.899633, acc.: 41.41%] [G loss: 1.027881]\n",
      "epoch:15 step:14876 [D loss: 0.817420, acc.: 42.19%] [G loss: 0.749454]\n",
      "epoch:15 step:14877 [D loss: 0.758740, acc.: 49.22%] [G loss: 1.116308]\n",
      "epoch:15 step:14878 [D loss: 0.694249, acc.: 57.03%] [G loss: 0.927101]\n",
      "epoch:15 step:14879 [D loss: 0.483460, acc.: 80.47%] [G loss: 1.193013]\n",
      "epoch:15 step:14880 [D loss: 0.524639, acc.: 74.22%] [G loss: 1.071691]\n",
      "epoch:15 step:14881 [D loss: 0.721033, acc.: 51.56%] [G loss: 0.966770]\n",
      "epoch:15 step:14882 [D loss: 0.911098, acc.: 32.81%] [G loss: 0.962436]\n",
      "epoch:15 step:14883 [D loss: 0.790032, acc.: 45.31%] [G loss: 1.028764]\n",
      "epoch:15 step:14884 [D loss: 0.717305, acc.: 57.03%] [G loss: 1.174467]\n",
      "epoch:15 step:14885 [D loss: 0.763859, acc.: 46.88%] [G loss: 0.852571]\n",
      "epoch:15 step:14886 [D loss: 0.466855, acc.: 78.91%] [G loss: 1.200326]\n",
      "epoch:15 step:14887 [D loss: 0.642740, acc.: 58.59%] [G loss: 1.407353]\n",
      "epoch:15 step:14888 [D loss: 0.551622, acc.: 72.66%] [G loss: 1.342139]\n",
      "epoch:15 step:14889 [D loss: 0.794053, acc.: 45.31%] [G loss: 1.006072]\n",
      "epoch:15 step:14890 [D loss: 0.671851, acc.: 59.38%] [G loss: 1.130358]\n",
      "epoch:15 step:14891 [D loss: 0.730947, acc.: 53.12%] [G loss: 1.024538]\n",
      "epoch:15 step:14892 [D loss: 0.634555, acc.: 62.50%] [G loss: 1.003817]\n",
      "epoch:15 step:14893 [D loss: 0.688494, acc.: 61.72%] [G loss: 1.038433]\n",
      "epoch:15 step:14894 [D loss: 0.592544, acc.: 69.53%] [G loss: 1.135490]\n",
      "epoch:15 step:14895 [D loss: 0.507804, acc.: 78.91%] [G loss: 1.113501]\n",
      "epoch:15 step:14896 [D loss: 0.406150, acc.: 89.06%] [G loss: 1.322204]\n",
      "epoch:15 step:14897 [D loss: 0.494683, acc.: 78.91%] [G loss: 1.218464]\n",
      "epoch:15 step:14898 [D loss: 0.756548, acc.: 53.91%] [G loss: 1.123151]\n",
      "epoch:15 step:14899 [D loss: 0.821138, acc.: 45.31%] [G loss: 0.857198]\n",
      "epoch:15 step:14900 [D loss: 0.613363, acc.: 67.19%] [G loss: 0.840770]\n",
      "epoch:15 step:14901 [D loss: 0.584150, acc.: 67.97%] [G loss: 0.955687]\n",
      "epoch:15 step:14902 [D loss: 0.495872, acc.: 78.91%] [G loss: 1.261764]\n",
      "epoch:15 step:14903 [D loss: 0.620960, acc.: 67.19%] [G loss: 1.110501]\n",
      "epoch:15 step:14904 [D loss: 0.475898, acc.: 83.59%] [G loss: 1.377257]\n",
      "epoch:15 step:14905 [D loss: 0.486786, acc.: 85.94%] [G loss: 1.067511]\n",
      "epoch:15 step:14906 [D loss: 0.391275, acc.: 85.94%] [G loss: 1.224295]\n",
      "epoch:15 step:14907 [D loss: 0.371844, acc.: 89.06%] [G loss: 1.139452]\n",
      "epoch:15 step:14908 [D loss: 0.384883, acc.: 88.28%] [G loss: 1.414430]\n",
      "epoch:15 step:14909 [D loss: 0.368903, acc.: 93.75%] [G loss: 1.310571]\n",
      "epoch:15 step:14910 [D loss: 0.526379, acc.: 75.78%] [G loss: 1.193442]\n",
      "epoch:15 step:14911 [D loss: 0.628151, acc.: 64.06%] [G loss: 1.324372]\n",
      "epoch:15 step:14912 [D loss: 0.603440, acc.: 67.97%] [G loss: 1.101974]\n",
      "epoch:15 step:14913 [D loss: 0.935382, acc.: 28.91%] [G loss: 0.937235]\n",
      "epoch:15 step:14914 [D loss: 0.776935, acc.: 46.88%] [G loss: 1.022440]\n",
      "epoch:15 step:14915 [D loss: 0.531698, acc.: 80.47%] [G loss: 1.121211]\n",
      "epoch:15 step:14916 [D loss: 0.669698, acc.: 59.38%] [G loss: 1.132444]\n",
      "epoch:15 step:14917 [D loss: 0.667330, acc.: 61.72%] [G loss: 0.886472]\n",
      "epoch:15 step:14918 [D loss: 0.611881, acc.: 68.75%] [G loss: 1.012490]\n",
      "epoch:15 step:14919 [D loss: 0.748472, acc.: 52.34%] [G loss: 0.786803]\n",
      "epoch:15 step:14920 [D loss: 0.704067, acc.: 53.12%] [G loss: 0.850708]\n",
      "epoch:15 step:14921 [D loss: 0.616364, acc.: 64.06%] [G loss: 1.037260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14922 [D loss: 0.681091, acc.: 55.47%] [G loss: 1.083587]\n",
      "epoch:15 step:14923 [D loss: 0.506658, acc.: 81.25%] [G loss: 1.025673]\n",
      "epoch:15 step:14924 [D loss: 0.684047, acc.: 59.38%] [G loss: 1.174487]\n",
      "epoch:15 step:14925 [D loss: 0.764254, acc.: 47.66%] [G loss: 0.958873]\n",
      "epoch:15 step:14926 [D loss: 0.587366, acc.: 71.09%] [G loss: 0.945318]\n",
      "epoch:15 step:14927 [D loss: 0.693156, acc.: 56.25%] [G loss: 1.018750]\n",
      "epoch:15 step:14928 [D loss: 0.690457, acc.: 54.69%] [G loss: 1.064059]\n",
      "epoch:15 step:14929 [D loss: 0.617867, acc.: 64.84%] [G loss: 1.052421]\n",
      "epoch:15 step:14930 [D loss: 0.562233, acc.: 74.22%] [G loss: 1.141274]\n",
      "epoch:15 step:14931 [D loss: 0.704408, acc.: 56.25%] [G loss: 0.939643]\n",
      "epoch:15 step:14932 [D loss: 0.591577, acc.: 70.31%] [G loss: 0.976460]\n",
      "epoch:15 step:14933 [D loss: 0.537504, acc.: 74.22%] [G loss: 1.123962]\n",
      "epoch:15 step:14934 [D loss: 0.711604, acc.: 53.12%] [G loss: 1.141383]\n",
      "epoch:15 step:14935 [D loss: 0.807068, acc.: 37.50%] [G loss: 0.917838]\n",
      "epoch:15 step:14936 [D loss: 0.696136, acc.: 56.25%] [G loss: 0.969998]\n",
      "epoch:15 step:14937 [D loss: 0.612734, acc.: 61.72%] [G loss: 1.062586]\n",
      "epoch:15 step:14938 [D loss: 0.613220, acc.: 64.84%] [G loss: 0.943013]\n",
      "epoch:15 step:14939 [D loss: 0.527308, acc.: 73.44%] [G loss: 1.030886]\n",
      "epoch:15 step:14940 [D loss: 0.479363, acc.: 81.25%] [G loss: 1.084473]\n",
      "epoch:15 step:14941 [D loss: 0.457654, acc.: 83.59%] [G loss: 1.297983]\n",
      "epoch:15 step:14942 [D loss: 0.390868, acc.: 88.28%] [G loss: 1.345007]\n",
      "epoch:15 step:14943 [D loss: 0.509126, acc.: 82.81%] [G loss: 1.385010]\n",
      "epoch:15 step:14944 [D loss: 0.379440, acc.: 88.28%] [G loss: 1.263490]\n",
      "epoch:15 step:14945 [D loss: 0.428723, acc.: 85.16%] [G loss: 1.121414]\n",
      "epoch:15 step:14946 [D loss: 0.967806, acc.: 34.38%] [G loss: 1.099139]\n",
      "epoch:15 step:14947 [D loss: 0.753584, acc.: 53.12%] [G loss: 0.956609]\n",
      "epoch:15 step:14948 [D loss: 0.665312, acc.: 58.59%] [G loss: 0.935613]\n",
      "epoch:15 step:14949 [D loss: 0.607491, acc.: 66.41%] [G loss: 1.239113]\n",
      "epoch:15 step:14950 [D loss: 0.661437, acc.: 62.50%] [G loss: 1.048300]\n",
      "epoch:15 step:14951 [D loss: 0.565117, acc.: 73.44%] [G loss: 1.016663]\n",
      "epoch:15 step:14952 [D loss: 0.555280, acc.: 70.31%] [G loss: 1.019414]\n",
      "epoch:15 step:14953 [D loss: 0.495237, acc.: 76.56%] [G loss: 1.046654]\n",
      "epoch:15 step:14954 [D loss: 0.343280, acc.: 90.62%] [G loss: 1.399518]\n",
      "epoch:15 step:14955 [D loss: 0.363572, acc.: 90.62%] [G loss: 1.331059]\n",
      "epoch:15 step:14956 [D loss: 0.465548, acc.: 82.81%] [G loss: 1.395500]\n",
      "epoch:15 step:14957 [D loss: 0.673710, acc.: 63.28%] [G loss: 1.005052]\n",
      "epoch:15 step:14958 [D loss: 0.678305, acc.: 63.28%] [G loss: 0.952205]\n",
      "epoch:15 step:14959 [D loss: 0.788247, acc.: 45.31%] [G loss: 1.020449]\n",
      "epoch:15 step:14960 [D loss: 0.717111, acc.: 53.91%] [G loss: 1.103678]\n",
      "epoch:15 step:14961 [D loss: 0.714213, acc.: 58.59%] [G loss: 1.039439]\n",
      "epoch:15 step:14962 [D loss: 0.688648, acc.: 56.25%] [G loss: 1.041499]\n",
      "epoch:15 step:14963 [D loss: 0.756693, acc.: 50.00%] [G loss: 0.850201]\n",
      "epoch:15 step:14964 [D loss: 0.638550, acc.: 64.84%] [G loss: 0.757418]\n",
      "epoch:15 step:14965 [D loss: 0.561275, acc.: 73.44%] [G loss: 1.111470]\n",
      "epoch:15 step:14966 [D loss: 0.423231, acc.: 91.41%] [G loss: 1.284406]\n",
      "epoch:15 step:14967 [D loss: 0.420159, acc.: 78.12%] [G loss: 1.109830]\n",
      "epoch:15 step:14968 [D loss: 0.694993, acc.: 57.03%] [G loss: 1.365357]\n",
      "epoch:15 step:14969 [D loss: 0.799917, acc.: 46.09%] [G loss: 1.183195]\n",
      "epoch:15 step:14970 [D loss: 0.703985, acc.: 58.59%] [G loss: 0.991019]\n",
      "epoch:15 step:14971 [D loss: 0.678726, acc.: 56.25%] [G loss: 0.964479]\n",
      "epoch:15 step:14972 [D loss: 0.736825, acc.: 48.44%] [G loss: 0.981556]\n",
      "epoch:15 step:14973 [D loss: 0.605554, acc.: 68.75%] [G loss: 0.866842]\n",
      "epoch:15 step:14974 [D loss: 0.511598, acc.: 78.12%] [G loss: 1.130969]\n",
      "epoch:15 step:14975 [D loss: 0.584322, acc.: 66.41%] [G loss: 1.167377]\n",
      "epoch:15 step:14976 [D loss: 0.431148, acc.: 89.06%] [G loss: 1.316374]\n",
      "epoch:15 step:14977 [D loss: 0.523985, acc.: 77.34%] [G loss: 1.336170]\n",
      "epoch:15 step:14978 [D loss: 0.508232, acc.: 83.59%] [G loss: 1.493999]\n",
      "epoch:15 step:14979 [D loss: 0.552046, acc.: 72.66%] [G loss: 1.034961]\n",
      "epoch:15 step:14980 [D loss: 0.568353, acc.: 74.22%] [G loss: 1.256483]\n",
      "epoch:15 step:14981 [D loss: 0.509661, acc.: 75.78%] [G loss: 1.132077]\n",
      "epoch:15 step:14982 [D loss: 0.445888, acc.: 89.06%] [G loss: 1.096224]\n",
      "epoch:15 step:14983 [D loss: 0.849565, acc.: 47.66%] [G loss: 1.280710]\n",
      "epoch:15 step:14984 [D loss: 0.386524, acc.: 88.28%] [G loss: 1.253861]\n",
      "epoch:15 step:14985 [D loss: 0.425381, acc.: 88.28%] [G loss: 1.158091]\n",
      "epoch:15 step:14986 [D loss: 0.547989, acc.: 75.00%] [G loss: 0.986316]\n",
      "epoch:15 step:14987 [D loss: 0.698814, acc.: 58.59%] [G loss: 1.072263]\n",
      "epoch:15 step:14988 [D loss: 0.614371, acc.: 65.62%] [G loss: 1.041590]\n",
      "epoch:15 step:14989 [D loss: 0.522075, acc.: 77.34%] [G loss: 1.074370]\n",
      "epoch:15 step:14990 [D loss: 0.634185, acc.: 64.06%] [G loss: 0.972479]\n",
      "epoch:15 step:14991 [D loss: 0.518517, acc.: 71.88%] [G loss: 1.016137]\n",
      "epoch:15 step:14992 [D loss: 0.274421, acc.: 92.97%] [G loss: 1.362753]\n",
      "epoch:16 step:14993 [D loss: 0.711174, acc.: 60.16%] [G loss: 1.080759]\n",
      "epoch:16 step:14994 [D loss: 0.732361, acc.: 53.12%] [G loss: 1.128854]\n",
      "epoch:16 step:14995 [D loss: 1.077593, acc.: 23.44%] [G loss: 0.625662]\n",
      "epoch:16 step:14996 [D loss: 0.637315, acc.: 64.84%] [G loss: 1.165885]\n",
      "epoch:16 step:14997 [D loss: 0.577828, acc.: 69.53%] [G loss: 1.040734]\n",
      "epoch:16 step:14998 [D loss: 0.676020, acc.: 58.59%] [G loss: 1.022391]\n",
      "epoch:16 step:14999 [D loss: 0.563181, acc.: 71.09%] [G loss: 1.164527]\n",
      "epoch:16 step:15000 [D loss: 0.550452, acc.: 73.44%] [G loss: 0.814139]\n",
      "epoch:16 step:15001 [D loss: 0.582404, acc.: 69.53%] [G loss: 0.958295]\n",
      "epoch:16 step:15002 [D loss: 0.448937, acc.: 88.28%] [G loss: 1.124217]\n",
      "epoch:16 step:15003 [D loss: 0.652083, acc.: 61.72%] [G loss: 0.953979]\n",
      "epoch:16 step:15004 [D loss: 0.737192, acc.: 53.91%] [G loss: 0.904256]\n",
      "epoch:16 step:15005 [D loss: 0.754790, acc.: 53.12%] [G loss: 1.122612]\n",
      "epoch:16 step:15006 [D loss: 0.602152, acc.: 67.19%] [G loss: 1.017179]\n",
      "epoch:16 step:15007 [D loss: 0.498842, acc.: 79.69%] [G loss: 1.050740]\n",
      "epoch:16 step:15008 [D loss: 0.495977, acc.: 78.91%] [G loss: 1.153109]\n",
      "epoch:16 step:15009 [D loss: 0.698388, acc.: 60.16%] [G loss: 1.128821]\n",
      "epoch:16 step:15010 [D loss: 0.759761, acc.: 49.22%] [G loss: 1.002713]\n",
      "epoch:16 step:15011 [D loss: 0.687042, acc.: 60.16%] [G loss: 0.902283]\n",
      "epoch:16 step:15012 [D loss: 0.769081, acc.: 50.78%] [G loss: 1.066446]\n",
      "epoch:16 step:15013 [D loss: 0.623649, acc.: 67.19%] [G loss: 1.231623]\n",
      "epoch:16 step:15014 [D loss: 0.567954, acc.: 70.31%] [G loss: 1.119017]\n",
      "epoch:16 step:15015 [D loss: 0.573167, acc.: 67.97%] [G loss: 1.195849]\n",
      "epoch:16 step:15016 [D loss: 0.627834, acc.: 63.28%] [G loss: 1.097695]\n",
      "epoch:16 step:15017 [D loss: 0.545466, acc.: 71.88%] [G loss: 0.997599]\n",
      "epoch:16 step:15018 [D loss: 0.402438, acc.: 89.84%] [G loss: 1.092473]\n",
      "epoch:16 step:15019 [D loss: 0.397042, acc.: 82.81%] [G loss: 1.345062]\n",
      "epoch:16 step:15020 [D loss: 0.431096, acc.: 85.16%] [G loss: 1.253609]\n",
      "epoch:16 step:15021 [D loss: 0.473896, acc.: 83.59%] [G loss: 1.215933]\n",
      "epoch:16 step:15022 [D loss: 0.437396, acc.: 85.94%] [G loss: 1.295696]\n",
      "epoch:16 step:15023 [D loss: 0.423323, acc.: 83.59%] [G loss: 1.355437]\n",
      "epoch:16 step:15024 [D loss: 0.313686, acc.: 92.97%] [G loss: 1.621687]\n",
      "epoch:16 step:15025 [D loss: 0.392001, acc.: 89.84%] [G loss: 1.548220]\n",
      "epoch:16 step:15026 [D loss: 0.406042, acc.: 86.72%] [G loss: 1.362527]\n",
      "epoch:16 step:15027 [D loss: 0.311082, acc.: 94.53%] [G loss: 1.339438]\n",
      "epoch:16 step:15028 [D loss: 0.322830, acc.: 87.50%] [G loss: 1.321088]\n",
      "epoch:16 step:15029 [D loss: 0.782476, acc.: 49.22%] [G loss: 0.830673]\n",
      "epoch:16 step:15030 [D loss: 0.948231, acc.: 37.50%] [G loss: 1.058594]\n",
      "epoch:16 step:15031 [D loss: 0.802168, acc.: 48.44%] [G loss: 1.188856]\n",
      "epoch:16 step:15032 [D loss: 0.638391, acc.: 65.62%] [G loss: 1.161896]\n",
      "epoch:16 step:15033 [D loss: 0.698568, acc.: 57.81%] [G loss: 1.006824]\n",
      "epoch:16 step:15034 [D loss: 0.481518, acc.: 82.03%] [G loss: 1.223997]\n",
      "epoch:16 step:15035 [D loss: 0.675734, acc.: 64.06%] [G loss: 1.022622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15036 [D loss: 0.651436, acc.: 56.25%] [G loss: 1.071647]\n",
      "epoch:16 step:15037 [D loss: 0.880319, acc.: 42.97%] [G loss: 0.888143]\n",
      "epoch:16 step:15038 [D loss: 0.983321, acc.: 25.00%] [G loss: 0.763894]\n",
      "epoch:16 step:15039 [D loss: 0.631183, acc.: 62.50%] [G loss: 1.060964]\n",
      "epoch:16 step:15040 [D loss: 0.739574, acc.: 48.44%] [G loss: 1.161987]\n",
      "epoch:16 step:15041 [D loss: 0.535071, acc.: 79.69%] [G loss: 1.256888]\n",
      "epoch:16 step:15042 [D loss: 0.548306, acc.: 74.22%] [G loss: 0.917527]\n",
      "epoch:16 step:15043 [D loss: 0.622791, acc.: 63.28%] [G loss: 1.205632]\n",
      "epoch:16 step:15044 [D loss: 0.622279, acc.: 64.06%] [G loss: 1.222292]\n",
      "epoch:16 step:15045 [D loss: 0.571396, acc.: 71.88%] [G loss: 0.970092]\n",
      "epoch:16 step:15046 [D loss: 0.549795, acc.: 71.88%] [G loss: 1.019867]\n",
      "epoch:16 step:15047 [D loss: 0.514617, acc.: 83.59%] [G loss: 1.189709]\n",
      "epoch:16 step:15048 [D loss: 0.629483, acc.: 64.06%] [G loss: 1.139656]\n",
      "epoch:16 step:15049 [D loss: 0.683280, acc.: 55.47%] [G loss: 1.143759]\n",
      "epoch:16 step:15050 [D loss: 0.633763, acc.: 63.28%] [G loss: 1.120838]\n",
      "epoch:16 step:15051 [D loss: 0.772638, acc.: 39.84%] [G loss: 0.924586]\n",
      "epoch:16 step:15052 [D loss: 0.782497, acc.: 48.44%] [G loss: 0.854485]\n",
      "epoch:16 step:15053 [D loss: 0.795419, acc.: 47.66%] [G loss: 0.930596]\n",
      "epoch:16 step:15054 [D loss: 0.751392, acc.: 53.12%] [G loss: 0.884630]\n",
      "epoch:16 step:15055 [D loss: 0.709485, acc.: 50.00%] [G loss: 1.004697]\n",
      "epoch:16 step:15056 [D loss: 0.609787, acc.: 67.19%] [G loss: 1.032046]\n",
      "epoch:16 step:15057 [D loss: 0.611442, acc.: 64.06%] [G loss: 1.199229]\n",
      "epoch:16 step:15058 [D loss: 0.733395, acc.: 54.69%] [G loss: 0.961194]\n",
      "epoch:16 step:15059 [D loss: 0.694050, acc.: 51.56%] [G loss: 0.877936]\n",
      "epoch:16 step:15060 [D loss: 0.725931, acc.: 53.91%] [G loss: 0.867142]\n",
      "epoch:16 step:15061 [D loss: 0.465841, acc.: 84.38%] [G loss: 1.088685]\n",
      "epoch:16 step:15062 [D loss: 0.666469, acc.: 54.69%] [G loss: 1.022550]\n",
      "epoch:16 step:15063 [D loss: 0.629503, acc.: 67.19%] [G loss: 1.099560]\n",
      "epoch:16 step:15064 [D loss: 0.649403, acc.: 62.50%] [G loss: 0.931274]\n",
      "epoch:16 step:15065 [D loss: 0.732856, acc.: 51.56%] [G loss: 0.949366]\n",
      "epoch:16 step:15066 [D loss: 0.499777, acc.: 82.03%] [G loss: 1.039073]\n",
      "epoch:16 step:15067 [D loss: 0.474714, acc.: 76.56%] [G loss: 1.045305]\n",
      "epoch:16 step:15068 [D loss: 0.474607, acc.: 76.56%] [G loss: 1.228404]\n",
      "epoch:16 step:15069 [D loss: 0.455098, acc.: 83.59%] [G loss: 1.264179]\n",
      "epoch:16 step:15070 [D loss: 0.575538, acc.: 71.09%] [G loss: 1.201499]\n",
      "epoch:16 step:15071 [D loss: 0.699195, acc.: 58.59%] [G loss: 1.004850]\n",
      "epoch:16 step:15072 [D loss: 0.711208, acc.: 54.69%] [G loss: 1.078892]\n",
      "epoch:16 step:15073 [D loss: 0.760538, acc.: 46.09%] [G loss: 0.717325]\n",
      "epoch:16 step:15074 [D loss: 0.642057, acc.: 64.06%] [G loss: 0.800130]\n",
      "epoch:16 step:15075 [D loss: 0.702547, acc.: 53.91%] [G loss: 0.787078]\n",
      "epoch:16 step:15076 [D loss: 0.700126, acc.: 54.69%] [G loss: 1.118366]\n",
      "epoch:16 step:15077 [D loss: 0.580931, acc.: 75.78%] [G loss: 1.144387]\n",
      "epoch:16 step:15078 [D loss: 0.660851, acc.: 64.06%] [G loss: 1.025706]\n",
      "epoch:16 step:15079 [D loss: 0.638376, acc.: 61.72%] [G loss: 1.048290]\n",
      "epoch:16 step:15080 [D loss: 0.611639, acc.: 65.62%] [G loss: 0.869690]\n",
      "epoch:16 step:15081 [D loss: 0.716379, acc.: 52.34%] [G loss: 0.926814]\n",
      "epoch:16 step:15082 [D loss: 0.575375, acc.: 75.00%] [G loss: 0.902003]\n",
      "epoch:16 step:15083 [D loss: 0.600368, acc.: 68.75%] [G loss: 1.020082]\n",
      "epoch:16 step:15084 [D loss: 0.565942, acc.: 73.44%] [G loss: 1.055951]\n",
      "epoch:16 step:15085 [D loss: 0.690111, acc.: 60.16%] [G loss: 0.873273]\n",
      "epoch:16 step:15086 [D loss: 0.658993, acc.: 60.94%] [G loss: 0.974858]\n",
      "epoch:16 step:15087 [D loss: 0.744953, acc.: 49.22%] [G loss: 0.904525]\n",
      "epoch:16 step:15088 [D loss: 0.609691, acc.: 67.19%] [G loss: 0.948788]\n",
      "epoch:16 step:15089 [D loss: 0.563989, acc.: 73.44%] [G loss: 1.253100]\n",
      "epoch:16 step:15090 [D loss: 0.593324, acc.: 66.41%] [G loss: 0.946690]\n",
      "epoch:16 step:15091 [D loss: 0.721275, acc.: 55.47%] [G loss: 1.061136]\n",
      "epoch:16 step:15092 [D loss: 0.691009, acc.: 60.16%] [G loss: 1.035088]\n",
      "epoch:16 step:15093 [D loss: 0.641672, acc.: 61.72%] [G loss: 1.028945]\n",
      "epoch:16 step:15094 [D loss: 0.622248, acc.: 68.75%] [G loss: 0.988698]\n",
      "epoch:16 step:15095 [D loss: 0.510323, acc.: 78.12%] [G loss: 1.027739]\n",
      "epoch:16 step:15096 [D loss: 0.623295, acc.: 64.06%] [G loss: 0.988081]\n",
      "epoch:16 step:15097 [D loss: 0.620778, acc.: 67.97%] [G loss: 0.936505]\n",
      "epoch:16 step:15098 [D loss: 0.508665, acc.: 77.34%] [G loss: 1.271150]\n",
      "epoch:16 step:15099 [D loss: 0.698705, acc.: 56.25%] [G loss: 1.082062]\n",
      "epoch:16 step:15100 [D loss: 0.640164, acc.: 61.72%] [G loss: 0.948884]\n",
      "epoch:16 step:15101 [D loss: 0.568360, acc.: 71.09%] [G loss: 1.144784]\n",
      "epoch:16 step:15102 [D loss: 0.669655, acc.: 57.03%] [G loss: 0.966396]\n",
      "epoch:16 step:15103 [D loss: 0.653082, acc.: 64.84%] [G loss: 1.210699]\n",
      "epoch:16 step:15104 [D loss: 0.638313, acc.: 64.84%] [G loss: 1.132682]\n",
      "epoch:16 step:15105 [D loss: 0.871406, acc.: 35.94%] [G loss: 0.728426]\n",
      "epoch:16 step:15106 [D loss: 0.805601, acc.: 39.84%] [G loss: 0.817786]\n",
      "epoch:16 step:15107 [D loss: 0.721046, acc.: 50.78%] [G loss: 0.883614]\n",
      "epoch:16 step:15108 [D loss: 0.571429, acc.: 71.09%] [G loss: 1.036593]\n",
      "epoch:16 step:15109 [D loss: 0.585785, acc.: 73.44%] [G loss: 0.997160]\n",
      "epoch:16 step:15110 [D loss: 0.562196, acc.: 73.44%] [G loss: 0.990500]\n",
      "epoch:16 step:15111 [D loss: 0.501791, acc.: 75.78%] [G loss: 1.035726]\n",
      "epoch:16 step:15112 [D loss: 0.770228, acc.: 49.22%] [G loss: 1.169346]\n",
      "epoch:16 step:15113 [D loss: 0.676483, acc.: 60.16%] [G loss: 1.372673]\n",
      "epoch:16 step:15114 [D loss: 0.462559, acc.: 81.25%] [G loss: 1.245432]\n",
      "epoch:16 step:15115 [D loss: 0.601932, acc.: 65.62%] [G loss: 1.170506]\n",
      "epoch:16 step:15116 [D loss: 0.736269, acc.: 51.56%] [G loss: 1.053325]\n",
      "epoch:16 step:15117 [D loss: 0.590008, acc.: 69.53%] [G loss: 1.001006]\n",
      "epoch:16 step:15118 [D loss: 0.648860, acc.: 64.06%] [G loss: 0.973446]\n",
      "epoch:16 step:15119 [D loss: 0.585240, acc.: 71.09%] [G loss: 1.142737]\n",
      "epoch:16 step:15120 [D loss: 0.679625, acc.: 60.94%] [G loss: 0.678963]\n",
      "epoch:16 step:15121 [D loss: 0.538226, acc.: 73.44%] [G loss: 1.063974]\n",
      "epoch:16 step:15122 [D loss: 0.354996, acc.: 92.97%] [G loss: 1.182644]\n",
      "epoch:16 step:15123 [D loss: 0.443552, acc.: 83.59%] [G loss: 0.928439]\n",
      "epoch:16 step:15124 [D loss: 0.460609, acc.: 85.94%] [G loss: 1.529440]\n",
      "epoch:16 step:15125 [D loss: 0.849537, acc.: 51.56%] [G loss: 0.944679]\n",
      "epoch:16 step:15126 [D loss: 0.709060, acc.: 51.56%] [G loss: 0.900102]\n",
      "epoch:16 step:15127 [D loss: 0.727488, acc.: 53.91%] [G loss: 0.771434]\n",
      "epoch:16 step:15128 [D loss: 0.689267, acc.: 58.59%] [G loss: 0.960683]\n",
      "epoch:16 step:15129 [D loss: 0.604333, acc.: 64.84%] [G loss: 0.879530]\n",
      "epoch:16 step:15130 [D loss: 0.559651, acc.: 75.00%] [G loss: 1.103812]\n",
      "epoch:16 step:15131 [D loss: 0.411007, acc.: 88.28%] [G loss: 1.092794]\n",
      "epoch:16 step:15132 [D loss: 0.695776, acc.: 56.25%] [G loss: 1.028337]\n",
      "epoch:16 step:15133 [D loss: 0.742511, acc.: 53.91%] [G loss: 1.037621]\n",
      "epoch:16 step:15134 [D loss: 0.728960, acc.: 53.91%] [G loss: 1.026732]\n",
      "epoch:16 step:15135 [D loss: 0.601342, acc.: 66.41%] [G loss: 1.151850]\n",
      "epoch:16 step:15136 [D loss: 0.594513, acc.: 68.75%] [G loss: 1.280456]\n",
      "epoch:16 step:15137 [D loss: 0.541690, acc.: 75.00%] [G loss: 1.361315]\n",
      "epoch:16 step:15138 [D loss: 0.584199, acc.: 71.09%] [G loss: 1.043068]\n",
      "epoch:16 step:15139 [D loss: 0.697924, acc.: 54.69%] [G loss: 1.088709]\n",
      "epoch:16 step:15140 [D loss: 0.676573, acc.: 61.72%] [G loss: 1.059230]\n",
      "epoch:16 step:15141 [D loss: 0.605654, acc.: 67.19%] [G loss: 0.946302]\n",
      "epoch:16 step:15142 [D loss: 0.596722, acc.: 64.06%] [G loss: 0.994600]\n",
      "epoch:16 step:15143 [D loss: 0.496629, acc.: 81.25%] [G loss: 1.017315]\n",
      "epoch:16 step:15144 [D loss: 0.560188, acc.: 68.75%] [G loss: 1.418826]\n",
      "epoch:16 step:15145 [D loss: 0.664614, acc.: 60.94%] [G loss: 1.276588]\n",
      "epoch:16 step:15146 [D loss: 0.695104, acc.: 56.25%] [G loss: 0.962949]\n",
      "epoch:16 step:15147 [D loss: 0.631893, acc.: 62.50%] [G loss: 1.233764]\n",
      "epoch:16 step:15148 [D loss: 0.511713, acc.: 81.25%] [G loss: 1.030217]\n",
      "epoch:16 step:15149 [D loss: 0.610947, acc.: 64.84%] [G loss: 1.061764]\n",
      "epoch:16 step:15150 [D loss: 0.596875, acc.: 66.41%] [G loss: 1.043128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15151 [D loss: 0.556745, acc.: 72.66%] [G loss: 1.054707]\n",
      "epoch:16 step:15152 [D loss: 0.658972, acc.: 62.50%] [G loss: 1.103870]\n",
      "epoch:16 step:15153 [D loss: 0.681667, acc.: 59.38%] [G loss: 1.043766]\n",
      "epoch:16 step:15154 [D loss: 0.634664, acc.: 64.06%] [G loss: 1.081993]\n",
      "epoch:16 step:15155 [D loss: 0.561860, acc.: 71.09%] [G loss: 0.932559]\n",
      "epoch:16 step:15156 [D loss: 0.668741, acc.: 58.59%] [G loss: 0.982858]\n",
      "epoch:16 step:15157 [D loss: 0.659664, acc.: 55.47%] [G loss: 1.087427]\n",
      "epoch:16 step:15158 [D loss: 0.591581, acc.: 68.75%] [G loss: 0.801881]\n",
      "epoch:16 step:15159 [D loss: 0.591739, acc.: 64.84%] [G loss: 1.093152]\n",
      "epoch:16 step:15160 [D loss: 0.501009, acc.: 79.69%] [G loss: 1.091965]\n",
      "epoch:16 step:15161 [D loss: 0.570509, acc.: 73.44%] [G loss: 1.216034]\n",
      "epoch:16 step:15162 [D loss: 0.876816, acc.: 39.06%] [G loss: 0.860530]\n",
      "epoch:16 step:15163 [D loss: 0.585081, acc.: 69.53%] [G loss: 1.102211]\n",
      "epoch:16 step:15164 [D loss: 0.713707, acc.: 50.78%] [G loss: 0.782485]\n",
      "epoch:16 step:15165 [D loss: 0.711064, acc.: 57.03%] [G loss: 1.192100]\n",
      "epoch:16 step:15166 [D loss: 0.693829, acc.: 54.69%] [G loss: 1.149395]\n",
      "epoch:16 step:15167 [D loss: 0.652479, acc.: 60.94%] [G loss: 0.913422]\n",
      "epoch:16 step:15168 [D loss: 0.694648, acc.: 57.81%] [G loss: 0.985147]\n",
      "epoch:16 step:15169 [D loss: 0.788811, acc.: 43.75%] [G loss: 0.856143]\n",
      "epoch:16 step:15170 [D loss: 0.720249, acc.: 52.34%] [G loss: 0.957169]\n",
      "epoch:16 step:15171 [D loss: 0.750696, acc.: 50.78%] [G loss: 1.074476]\n",
      "epoch:16 step:15172 [D loss: 0.722561, acc.: 50.78%] [G loss: 0.892118]\n",
      "epoch:16 step:15173 [D loss: 0.775360, acc.: 49.22%] [G loss: 0.884284]\n",
      "epoch:16 step:15174 [D loss: 0.591593, acc.: 65.62%] [G loss: 1.129515]\n",
      "epoch:16 step:15175 [D loss: 0.798285, acc.: 43.75%] [G loss: 0.860973]\n",
      "epoch:16 step:15176 [D loss: 0.653178, acc.: 58.59%] [G loss: 1.071412]\n",
      "epoch:16 step:15177 [D loss: 0.806963, acc.: 43.75%] [G loss: 0.847544]\n",
      "epoch:16 step:15178 [D loss: 0.790904, acc.: 42.19%] [G loss: 1.002584]\n",
      "epoch:16 step:15179 [D loss: 0.726500, acc.: 49.22%] [G loss: 1.076616]\n",
      "epoch:16 step:15180 [D loss: 0.769058, acc.: 47.66%] [G loss: 0.894524]\n",
      "epoch:16 step:15181 [D loss: 0.638029, acc.: 62.50%] [G loss: 0.970749]\n",
      "epoch:16 step:15182 [D loss: 0.583854, acc.: 67.97%] [G loss: 0.980308]\n",
      "epoch:16 step:15183 [D loss: 0.627736, acc.: 64.06%] [G loss: 1.084708]\n",
      "epoch:16 step:15184 [D loss: 0.631070, acc.: 64.84%] [G loss: 0.912720]\n",
      "epoch:16 step:15185 [D loss: 0.665623, acc.: 60.94%] [G loss: 0.951764]\n",
      "epoch:16 step:15186 [D loss: 0.531934, acc.: 71.88%] [G loss: 1.078722]\n",
      "epoch:16 step:15187 [D loss: 0.704530, acc.: 50.00%] [G loss: 0.959935]\n",
      "epoch:16 step:15188 [D loss: 0.687073, acc.: 56.25%] [G loss: 0.971590]\n",
      "epoch:16 step:15189 [D loss: 0.575140, acc.: 70.31%] [G loss: 1.143238]\n",
      "epoch:16 step:15190 [D loss: 0.679004, acc.: 56.25%] [G loss: 0.982318]\n",
      "epoch:16 step:15191 [D loss: 0.667343, acc.: 61.72%] [G loss: 1.060953]\n",
      "epoch:16 step:15192 [D loss: 0.504525, acc.: 78.12%] [G loss: 1.100265]\n",
      "epoch:16 step:15193 [D loss: 0.522905, acc.: 73.44%] [G loss: 1.001199]\n",
      "epoch:16 step:15194 [D loss: 0.596630, acc.: 69.53%] [G loss: 1.173140]\n",
      "epoch:16 step:15195 [D loss: 0.871712, acc.: 35.94%] [G loss: 0.980255]\n",
      "epoch:16 step:15196 [D loss: 0.947330, acc.: 32.03%] [G loss: 0.755423]\n",
      "epoch:16 step:15197 [D loss: 0.681222, acc.: 57.03%] [G loss: 1.123775]\n",
      "epoch:16 step:15198 [D loss: 0.710209, acc.: 52.34%] [G loss: 0.774520]\n",
      "epoch:16 step:15199 [D loss: 0.499985, acc.: 79.69%] [G loss: 1.127658]\n",
      "epoch:16 step:15200 [D loss: 0.629492, acc.: 67.97%] [G loss: 0.996572]\n",
      "epoch:16 step:15201 [D loss: 0.480851, acc.: 85.94%] [G loss: 1.081028]\n",
      "epoch:16 step:15202 [D loss: 0.730805, acc.: 54.69%] [G loss: 1.263298]\n",
      "epoch:16 step:15203 [D loss: 0.651588, acc.: 67.97%] [G loss: 0.998266]\n",
      "epoch:16 step:15204 [D loss: 0.679071, acc.: 56.25%] [G loss: 1.039273]\n",
      "epoch:16 step:15205 [D loss: 0.640363, acc.: 62.50%] [G loss: 0.908409]\n",
      "epoch:16 step:15206 [D loss: 0.712154, acc.: 55.47%] [G loss: 1.080212]\n",
      "epoch:16 step:15207 [D loss: 0.681085, acc.: 54.69%] [G loss: 0.801275]\n",
      "epoch:16 step:15208 [D loss: 0.654465, acc.: 60.94%] [G loss: 1.154538]\n",
      "epoch:16 step:15209 [D loss: 0.678080, acc.: 56.25%] [G loss: 0.957750]\n",
      "epoch:16 step:15210 [D loss: 0.580003, acc.: 67.97%] [G loss: 0.992333]\n",
      "epoch:16 step:15211 [D loss: 0.558600, acc.: 71.88%] [G loss: 1.065196]\n",
      "epoch:16 step:15212 [D loss: 0.451862, acc.: 82.03%] [G loss: 1.144500]\n",
      "epoch:16 step:15213 [D loss: 0.346797, acc.: 92.97%] [G loss: 1.468751]\n",
      "epoch:16 step:15214 [D loss: 0.435287, acc.: 86.72%] [G loss: 1.056423]\n",
      "epoch:16 step:15215 [D loss: 0.389751, acc.: 83.59%] [G loss: 1.165017]\n",
      "epoch:16 step:15216 [D loss: 0.699984, acc.: 62.50%] [G loss: 1.223605]\n",
      "epoch:16 step:15217 [D loss: 0.732327, acc.: 53.12%] [G loss: 0.962138]\n",
      "epoch:16 step:15218 [D loss: 0.653906, acc.: 59.38%] [G loss: 0.965583]\n",
      "epoch:16 step:15219 [D loss: 0.822866, acc.: 44.53%] [G loss: 0.831862]\n",
      "epoch:16 step:15220 [D loss: 0.621926, acc.: 60.94%] [G loss: 1.029944]\n",
      "epoch:16 step:15221 [D loss: 0.558397, acc.: 71.88%] [G loss: 1.036869]\n",
      "epoch:16 step:15222 [D loss: 0.367183, acc.: 85.16%] [G loss: 1.112375]\n",
      "epoch:16 step:15223 [D loss: 0.339779, acc.: 92.97%] [G loss: 1.361041]\n",
      "epoch:16 step:15224 [D loss: 0.369945, acc.: 87.50%] [G loss: 1.341792]\n",
      "epoch:16 step:15225 [D loss: 0.654418, acc.: 63.28%] [G loss: 1.513686]\n",
      "epoch:16 step:15226 [D loss: 0.814863, acc.: 44.53%] [G loss: 1.065640]\n",
      "epoch:16 step:15227 [D loss: 0.561209, acc.: 69.53%] [G loss: 0.880723]\n",
      "epoch:16 step:15228 [D loss: 0.719215, acc.: 55.47%] [G loss: 0.953840]\n",
      "epoch:16 step:15229 [D loss: 0.619883, acc.: 62.50%] [G loss: 1.111041]\n",
      "epoch:16 step:15230 [D loss: 0.735332, acc.: 53.12%] [G loss: 0.786353]\n",
      "epoch:16 step:15231 [D loss: 0.714923, acc.: 56.25%] [G loss: 1.008405]\n",
      "epoch:16 step:15232 [D loss: 0.735716, acc.: 52.34%] [G loss: 1.005015]\n",
      "epoch:16 step:15233 [D loss: 0.839907, acc.: 42.19%] [G loss: 0.842494]\n",
      "epoch:16 step:15234 [D loss: 0.785875, acc.: 47.66%] [G loss: 1.039371]\n",
      "epoch:16 step:15235 [D loss: 0.808629, acc.: 40.62%] [G loss: 0.881467]\n",
      "epoch:16 step:15236 [D loss: 0.632921, acc.: 60.94%] [G loss: 1.073393]\n",
      "epoch:16 step:15237 [D loss: 0.565801, acc.: 67.19%] [G loss: 1.073165]\n",
      "epoch:16 step:15238 [D loss: 0.438030, acc.: 82.81%] [G loss: 1.554444]\n",
      "epoch:16 step:15239 [D loss: 0.512169, acc.: 78.12%] [G loss: 1.023907]\n",
      "epoch:16 step:15240 [D loss: 0.463679, acc.: 85.16%] [G loss: 1.143079]\n",
      "epoch:16 step:15241 [D loss: 0.601036, acc.: 67.19%] [G loss: 1.164392]\n",
      "epoch:16 step:15242 [D loss: 0.523221, acc.: 74.22%] [G loss: 1.160687]\n",
      "epoch:16 step:15243 [D loss: 0.614998, acc.: 65.62%] [G loss: 0.916378]\n",
      "epoch:16 step:15244 [D loss: 0.558944, acc.: 68.75%] [G loss: 0.884128]\n",
      "epoch:16 step:15245 [D loss: 0.571506, acc.: 71.09%] [G loss: 1.057732]\n",
      "epoch:16 step:15246 [D loss: 0.653934, acc.: 66.41%] [G loss: 0.988910]\n",
      "epoch:16 step:15247 [D loss: 0.848011, acc.: 38.28%] [G loss: 0.820254]\n",
      "epoch:16 step:15248 [D loss: 0.721500, acc.: 51.56%] [G loss: 1.060698]\n",
      "epoch:16 step:15249 [D loss: 0.718331, acc.: 57.81%] [G loss: 0.921056]\n",
      "epoch:16 step:15250 [D loss: 0.618076, acc.: 65.62%] [G loss: 1.055153]\n",
      "epoch:16 step:15251 [D loss: 0.733672, acc.: 50.00%] [G loss: 0.916746]\n",
      "epoch:16 step:15252 [D loss: 0.706222, acc.: 56.25%] [G loss: 1.033786]\n",
      "epoch:16 step:15253 [D loss: 0.697420, acc.: 54.69%] [G loss: 1.160219]\n",
      "epoch:16 step:15254 [D loss: 0.639115, acc.: 59.38%] [G loss: 1.028763]\n",
      "epoch:16 step:15255 [D loss: 0.561109, acc.: 73.44%] [G loss: 0.992671]\n",
      "epoch:16 step:15256 [D loss: 0.554462, acc.: 75.00%] [G loss: 0.993190]\n",
      "epoch:16 step:15257 [D loss: 0.646167, acc.: 63.28%] [G loss: 1.210184]\n",
      "epoch:16 step:15258 [D loss: 0.802418, acc.: 41.41%] [G loss: 0.987676]\n",
      "epoch:16 step:15259 [D loss: 0.604385, acc.: 71.09%] [G loss: 1.025856]\n",
      "epoch:16 step:15260 [D loss: 0.598683, acc.: 72.66%] [G loss: 0.973286]\n",
      "epoch:16 step:15261 [D loss: 0.620303, acc.: 66.41%] [G loss: 1.031960]\n",
      "epoch:16 step:15262 [D loss: 0.660535, acc.: 57.03%] [G loss: 1.042888]\n",
      "epoch:16 step:15263 [D loss: 0.641358, acc.: 61.72%] [G loss: 0.875507]\n",
      "epoch:16 step:15264 [D loss: 0.545636, acc.: 71.88%] [G loss: 1.045047]\n",
      "epoch:16 step:15265 [D loss: 0.580069, acc.: 71.88%] [G loss: 1.196803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15266 [D loss: 0.621280, acc.: 64.84%] [G loss: 1.257016]\n",
      "epoch:16 step:15267 [D loss: 0.715876, acc.: 55.47%] [G loss: 0.976280]\n",
      "epoch:16 step:15268 [D loss: 0.759393, acc.: 48.44%] [G loss: 0.951180]\n",
      "epoch:16 step:15269 [D loss: 0.710931, acc.: 50.78%] [G loss: 0.840215]\n",
      "epoch:16 step:15270 [D loss: 0.620704, acc.: 60.94%] [G loss: 1.060795]\n",
      "epoch:16 step:15271 [D loss: 0.527723, acc.: 79.69%] [G loss: 1.039068]\n",
      "epoch:16 step:15272 [D loss: 0.584865, acc.: 71.88%] [G loss: 1.077399]\n",
      "epoch:16 step:15273 [D loss: 0.609870, acc.: 64.06%] [G loss: 0.981286]\n",
      "epoch:16 step:15274 [D loss: 0.690867, acc.: 57.81%] [G loss: 0.938260]\n",
      "epoch:16 step:15275 [D loss: 0.662795, acc.: 61.72%] [G loss: 1.046594]\n",
      "epoch:16 step:15276 [D loss: 0.610990, acc.: 69.53%] [G loss: 0.833692]\n",
      "epoch:16 step:15277 [D loss: 0.691435, acc.: 54.69%] [G loss: 1.055925]\n",
      "epoch:16 step:15278 [D loss: 0.429592, acc.: 85.94%] [G loss: 1.189415]\n",
      "epoch:16 step:15279 [D loss: 0.572876, acc.: 71.09%] [G loss: 1.222907]\n",
      "epoch:16 step:15280 [D loss: 0.550162, acc.: 74.22%] [G loss: 1.012185]\n",
      "epoch:16 step:15281 [D loss: 0.450636, acc.: 85.16%] [G loss: 1.392234]\n",
      "epoch:16 step:15282 [D loss: 0.774504, acc.: 49.22%] [G loss: 0.985887]\n",
      "epoch:16 step:15283 [D loss: 0.421981, acc.: 86.72%] [G loss: 1.425121]\n",
      "epoch:16 step:15284 [D loss: 0.523280, acc.: 75.78%] [G loss: 0.968068]\n",
      "epoch:16 step:15285 [D loss: 0.674131, acc.: 60.94%] [G loss: 0.875165]\n",
      "epoch:16 step:15286 [D loss: 0.620323, acc.: 68.75%] [G loss: 1.072102]\n",
      "epoch:16 step:15287 [D loss: 0.817921, acc.: 44.53%] [G loss: 1.012741]\n",
      "epoch:16 step:15288 [D loss: 0.852761, acc.: 38.28%] [G loss: 0.785896]\n",
      "epoch:16 step:15289 [D loss: 0.790142, acc.: 45.31%] [G loss: 1.117724]\n",
      "epoch:16 step:15290 [D loss: 0.559811, acc.: 75.78%] [G loss: 1.094942]\n",
      "epoch:16 step:15291 [D loss: 0.582422, acc.: 71.09%] [G loss: 1.171269]\n",
      "epoch:16 step:15292 [D loss: 0.539953, acc.: 79.69%] [G loss: 1.285796]\n",
      "epoch:16 step:15293 [D loss: 0.702771, acc.: 60.16%] [G loss: 1.189129]\n",
      "epoch:16 step:15294 [D loss: 0.574840, acc.: 71.88%] [G loss: 0.907377]\n",
      "epoch:16 step:15295 [D loss: 0.662328, acc.: 65.62%] [G loss: 0.893533]\n",
      "epoch:16 step:15296 [D loss: 0.685289, acc.: 54.69%] [G loss: 1.051134]\n",
      "epoch:16 step:15297 [D loss: 0.684851, acc.: 58.59%] [G loss: 1.010955]\n",
      "epoch:16 step:15298 [D loss: 0.642157, acc.: 64.06%] [G loss: 0.964286]\n",
      "epoch:16 step:15299 [D loss: 0.684277, acc.: 50.00%] [G loss: 1.031215]\n",
      "epoch:16 step:15300 [D loss: 0.515631, acc.: 75.78%] [G loss: 1.066440]\n",
      "epoch:16 step:15301 [D loss: 0.424125, acc.: 91.41%] [G loss: 1.105624]\n",
      "epoch:16 step:15302 [D loss: 0.545369, acc.: 75.00%] [G loss: 1.005299]\n",
      "epoch:16 step:15303 [D loss: 0.560346, acc.: 70.31%] [G loss: 1.180414]\n",
      "epoch:16 step:15304 [D loss: 0.425121, acc.: 88.28%] [G loss: 1.117072]\n",
      "epoch:16 step:15305 [D loss: 0.469485, acc.: 78.91%] [G loss: 1.124875]\n",
      "epoch:16 step:15306 [D loss: 0.347900, acc.: 92.97%] [G loss: 1.584856]\n",
      "epoch:16 step:15307 [D loss: 0.412584, acc.: 85.16%] [G loss: 1.404811]\n",
      "epoch:16 step:15308 [D loss: 0.834699, acc.: 51.56%] [G loss: 1.146290]\n",
      "epoch:16 step:15309 [D loss: 0.861888, acc.: 36.72%] [G loss: 0.821576]\n",
      "epoch:16 step:15310 [D loss: 0.636839, acc.: 59.38%] [G loss: 1.156665]\n",
      "epoch:16 step:15311 [D loss: 0.620964, acc.: 66.41%] [G loss: 1.049782]\n",
      "epoch:16 step:15312 [D loss: 0.660625, acc.: 59.38%] [G loss: 0.965875]\n",
      "epoch:16 step:15313 [D loss: 0.551200, acc.: 80.47%] [G loss: 1.079802]\n",
      "epoch:16 step:15314 [D loss: 0.641855, acc.: 62.50%] [G loss: 1.061160]\n",
      "epoch:16 step:15315 [D loss: 0.665771, acc.: 61.72%] [G loss: 1.005332]\n",
      "epoch:16 step:15316 [D loss: 0.623126, acc.: 61.72%] [G loss: 0.953925]\n",
      "epoch:16 step:15317 [D loss: 0.655543, acc.: 60.94%] [G loss: 0.993111]\n",
      "epoch:16 step:15318 [D loss: 0.605489, acc.: 66.41%] [G loss: 0.989970]\n",
      "epoch:16 step:15319 [D loss: 0.570306, acc.: 67.97%] [G loss: 0.968229]\n",
      "epoch:16 step:15320 [D loss: 0.397308, acc.: 89.06%] [G loss: 1.212983]\n",
      "epoch:16 step:15321 [D loss: 0.544633, acc.: 75.00%] [G loss: 1.236743]\n",
      "epoch:16 step:15322 [D loss: 0.615871, acc.: 67.97%] [G loss: 1.057852]\n",
      "epoch:16 step:15323 [D loss: 0.804946, acc.: 42.97%] [G loss: 0.959440]\n",
      "epoch:16 step:15324 [D loss: 0.745755, acc.: 50.00%] [G loss: 0.908472]\n",
      "epoch:16 step:15325 [D loss: 0.684550, acc.: 53.91%] [G loss: 0.945781]\n",
      "epoch:16 step:15326 [D loss: 0.681044, acc.: 61.72%] [G loss: 0.983410]\n",
      "epoch:16 step:15327 [D loss: 0.627040, acc.: 63.28%] [G loss: 0.958040]\n",
      "epoch:16 step:15328 [D loss: 0.685693, acc.: 51.56%] [G loss: 0.764794]\n",
      "epoch:16 step:15329 [D loss: 0.598226, acc.: 66.41%] [G loss: 1.093801]\n",
      "epoch:16 step:15330 [D loss: 0.677149, acc.: 57.81%] [G loss: 1.022630]\n",
      "epoch:16 step:15331 [D loss: 0.600537, acc.: 71.88%] [G loss: 1.080283]\n",
      "epoch:16 step:15332 [D loss: 0.574663, acc.: 71.09%] [G loss: 1.284221]\n",
      "epoch:16 step:15333 [D loss: 0.748002, acc.: 48.44%] [G loss: 0.904374]\n",
      "epoch:16 step:15334 [D loss: 0.585054, acc.: 71.09%] [G loss: 1.263254]\n",
      "epoch:16 step:15335 [D loss: 0.527289, acc.: 77.34%] [G loss: 1.000604]\n",
      "epoch:16 step:15336 [D loss: 0.498893, acc.: 75.78%] [G loss: 1.193596]\n",
      "epoch:16 step:15337 [D loss: 0.339383, acc.: 92.19%] [G loss: 1.331948]\n",
      "epoch:16 step:15338 [D loss: 0.413884, acc.: 84.38%] [G loss: 1.307929]\n",
      "epoch:16 step:15339 [D loss: 0.353292, acc.: 90.62%] [G loss: 1.247899]\n",
      "epoch:16 step:15340 [D loss: 0.723373, acc.: 57.81%] [G loss: 1.195579]\n",
      "epoch:16 step:15341 [D loss: 0.751561, acc.: 46.09%] [G loss: 1.010756]\n",
      "epoch:16 step:15342 [D loss: 0.684482, acc.: 57.81%] [G loss: 0.953407]\n",
      "epoch:16 step:15343 [D loss: 0.643986, acc.: 61.72%] [G loss: 0.930317]\n",
      "epoch:16 step:15344 [D loss: 0.647152, acc.: 64.84%] [G loss: 0.994756]\n",
      "epoch:16 step:15345 [D loss: 0.674330, acc.: 60.16%] [G loss: 0.919210]\n",
      "epoch:16 step:15346 [D loss: 0.644664, acc.: 56.25%] [G loss: 0.832026]\n",
      "epoch:16 step:15347 [D loss: 0.693628, acc.: 56.25%] [G loss: 1.133907]\n",
      "epoch:16 step:15348 [D loss: 0.680453, acc.: 57.81%] [G loss: 0.822042]\n",
      "epoch:16 step:15349 [D loss: 0.704195, acc.: 53.12%] [G loss: 0.931241]\n",
      "epoch:16 step:15350 [D loss: 0.654547, acc.: 60.94%] [G loss: 0.920093]\n",
      "epoch:16 step:15351 [D loss: 0.600812, acc.: 64.84%] [G loss: 0.983970]\n",
      "epoch:16 step:15352 [D loss: 0.639128, acc.: 65.62%] [G loss: 1.028432]\n",
      "epoch:16 step:15353 [D loss: 0.620390, acc.: 64.84%] [G loss: 1.172554]\n",
      "epoch:16 step:15354 [D loss: 0.773291, acc.: 51.56%] [G loss: 0.715847]\n",
      "epoch:16 step:15355 [D loss: 0.640741, acc.: 60.94%] [G loss: 0.818988]\n",
      "epoch:16 step:15356 [D loss: 0.654757, acc.: 60.16%] [G loss: 1.028420]\n",
      "epoch:16 step:15357 [D loss: 0.567392, acc.: 74.22%] [G loss: 0.980800]\n",
      "epoch:16 step:15358 [D loss: 0.535721, acc.: 71.88%] [G loss: 1.088609]\n",
      "epoch:16 step:15359 [D loss: 0.377604, acc.: 91.41%] [G loss: 1.360730]\n",
      "epoch:16 step:15360 [D loss: 0.665082, acc.: 59.38%] [G loss: 0.965456]\n",
      "epoch:16 step:15361 [D loss: 0.678023, acc.: 60.16%] [G loss: 1.181105]\n",
      "epoch:16 step:15362 [D loss: 0.562995, acc.: 73.44%] [G loss: 1.111746]\n",
      "epoch:16 step:15363 [D loss: 0.576913, acc.: 66.41%] [G loss: 1.022112]\n",
      "epoch:16 step:15364 [D loss: 0.608728, acc.: 63.28%] [G loss: 1.048628]\n",
      "epoch:16 step:15365 [D loss: 0.676114, acc.: 56.25%] [G loss: 0.898072]\n",
      "epoch:16 step:15366 [D loss: 0.638590, acc.: 62.50%] [G loss: 1.001925]\n",
      "epoch:16 step:15367 [D loss: 0.681460, acc.: 52.34%] [G loss: 0.769705]\n",
      "epoch:16 step:15368 [D loss: 0.672737, acc.: 55.47%] [G loss: 0.880494]\n",
      "epoch:16 step:15369 [D loss: 0.571749, acc.: 69.53%] [G loss: 0.941151]\n",
      "epoch:16 step:15370 [D loss: 0.523008, acc.: 76.56%] [G loss: 0.769442]\n",
      "epoch:16 step:15371 [D loss: 0.674203, acc.: 58.59%] [G loss: 1.046447]\n",
      "epoch:16 step:15372 [D loss: 0.763277, acc.: 51.56%] [G loss: 0.977408]\n",
      "epoch:16 step:15373 [D loss: 0.585065, acc.: 67.97%] [G loss: 0.979215]\n",
      "epoch:16 step:15374 [D loss: 0.780369, acc.: 43.75%] [G loss: 1.044778]\n",
      "epoch:16 step:15375 [D loss: 0.587227, acc.: 67.19%] [G loss: 1.090135]\n",
      "epoch:16 step:15376 [D loss: 0.558284, acc.: 74.22%] [G loss: 1.064598]\n",
      "epoch:16 step:15377 [D loss: 0.642619, acc.: 60.94%] [G loss: 0.988539]\n",
      "epoch:16 step:15378 [D loss: 0.658192, acc.: 62.50%] [G loss: 1.055876]\n",
      "epoch:16 step:15379 [D loss: 0.597519, acc.: 67.19%] [G loss: 1.128746]\n",
      "epoch:16 step:15380 [D loss: 0.540166, acc.: 78.91%] [G loss: 1.075356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15381 [D loss: 0.747194, acc.: 46.09%] [G loss: 0.981268]\n",
      "epoch:16 step:15382 [D loss: 0.712298, acc.: 54.69%] [G loss: 0.846360]\n",
      "epoch:16 step:15383 [D loss: 0.594675, acc.: 71.09%] [G loss: 1.043103]\n",
      "epoch:16 step:15384 [D loss: 0.660434, acc.: 57.03%] [G loss: 1.185300]\n",
      "epoch:16 step:15385 [D loss: 0.644724, acc.: 60.94%] [G loss: 1.004388]\n",
      "epoch:16 step:15386 [D loss: 0.575772, acc.: 75.00%] [G loss: 1.057421]\n",
      "epoch:16 step:15387 [D loss: 0.717452, acc.: 55.47%] [G loss: 0.787440]\n",
      "epoch:16 step:15388 [D loss: 0.474654, acc.: 87.50%] [G loss: 1.318920]\n",
      "epoch:16 step:15389 [D loss: 0.373232, acc.: 87.50%] [G loss: 1.263516]\n",
      "epoch:16 step:15390 [D loss: 0.377322, acc.: 85.94%] [G loss: 1.103861]\n",
      "epoch:16 step:15391 [D loss: 0.444073, acc.: 85.16%] [G loss: 1.612208]\n",
      "epoch:16 step:15392 [D loss: 0.438211, acc.: 86.72%] [G loss: 1.208574]\n",
      "epoch:16 step:15393 [D loss: 0.485091, acc.: 80.47%] [G loss: 1.228489]\n",
      "epoch:16 step:15394 [D loss: 0.444400, acc.: 82.81%] [G loss: 1.164785]\n",
      "epoch:16 step:15395 [D loss: 0.580834, acc.: 65.62%] [G loss: 1.190689]\n",
      "epoch:16 step:15396 [D loss: 0.528001, acc.: 71.88%] [G loss: 1.172201]\n",
      "epoch:16 step:15397 [D loss: 0.355747, acc.: 92.19%] [G loss: 1.541888]\n",
      "epoch:16 step:15398 [D loss: 0.580693, acc.: 69.53%] [G loss: 1.168298]\n",
      "epoch:16 step:15399 [D loss: 0.468903, acc.: 81.25%] [G loss: 1.323385]\n",
      "epoch:16 step:15400 [D loss: 0.718114, acc.: 53.91%] [G loss: 0.993452]\n",
      "epoch:16 step:15401 [D loss: 0.647576, acc.: 60.94%] [G loss: 1.043736]\n",
      "epoch:16 step:15402 [D loss: 0.751570, acc.: 53.91%] [G loss: 0.795017]\n",
      "epoch:16 step:15403 [D loss: 1.048394, acc.: 20.31%] [G loss: 0.656831]\n",
      "epoch:16 step:15404 [D loss: 0.880363, acc.: 33.59%] [G loss: 0.942814]\n",
      "epoch:16 step:15405 [D loss: 0.906878, acc.: 31.25%] [G loss: 1.026033]\n",
      "epoch:16 step:15406 [D loss: 0.722598, acc.: 52.34%] [G loss: 1.126278]\n",
      "epoch:16 step:15407 [D loss: 0.839191, acc.: 39.84%] [G loss: 0.983438]\n",
      "epoch:16 step:15408 [D loss: 0.712111, acc.: 51.56%] [G loss: 0.992587]\n",
      "epoch:16 step:15409 [D loss: 0.796011, acc.: 44.53%] [G loss: 0.851069]\n",
      "epoch:16 step:15410 [D loss: 0.848815, acc.: 47.66%] [G loss: 0.596551]\n",
      "epoch:16 step:15411 [D loss: 0.626686, acc.: 62.50%] [G loss: 0.855513]\n",
      "epoch:16 step:15412 [D loss: 0.768076, acc.: 49.22%] [G loss: 1.012206]\n",
      "epoch:16 step:15413 [D loss: 0.858477, acc.: 38.28%] [G loss: 1.011974]\n",
      "epoch:16 step:15414 [D loss: 0.936609, acc.: 32.81%] [G loss: 0.987575]\n",
      "epoch:16 step:15415 [D loss: 0.868239, acc.: 36.72%] [G loss: 0.932814]\n",
      "epoch:16 step:15416 [D loss: 0.715940, acc.: 57.81%] [G loss: 0.992593]\n",
      "epoch:16 step:15417 [D loss: 0.738258, acc.: 53.12%] [G loss: 1.248810]\n",
      "epoch:16 step:15418 [D loss: 0.655778, acc.: 60.94%] [G loss: 0.955707]\n",
      "epoch:16 step:15419 [D loss: 0.689409, acc.: 59.38%] [G loss: 1.219519]\n",
      "epoch:16 step:15420 [D loss: 0.594094, acc.: 71.09%] [G loss: 1.259528]\n",
      "epoch:16 step:15421 [D loss: 0.599822, acc.: 66.41%] [G loss: 1.073655]\n",
      "epoch:16 step:15422 [D loss: 0.523117, acc.: 78.12%] [G loss: 1.191868]\n",
      "epoch:16 step:15423 [D loss: 0.661646, acc.: 55.47%] [G loss: 0.994260]\n",
      "epoch:16 step:15424 [D loss: 0.615574, acc.: 63.28%] [G loss: 1.010849]\n",
      "epoch:16 step:15425 [D loss: 0.658564, acc.: 60.16%] [G loss: 1.047675]\n",
      "epoch:16 step:15426 [D loss: 0.579650, acc.: 69.53%] [G loss: 1.235569]\n",
      "epoch:16 step:15427 [D loss: 0.585789, acc.: 66.41%] [G loss: 1.279244]\n",
      "epoch:16 step:15428 [D loss: 0.468386, acc.: 82.81%] [G loss: 1.447341]\n",
      "epoch:16 step:15429 [D loss: 0.734731, acc.: 58.59%] [G loss: 1.176649]\n",
      "epoch:16 step:15430 [D loss: 0.609986, acc.: 66.41%] [G loss: 0.993628]\n",
      "epoch:16 step:15431 [D loss: 0.745930, acc.: 53.12%] [G loss: 0.958763]\n",
      "epoch:16 step:15432 [D loss: 0.705054, acc.: 52.34%] [G loss: 1.116925]\n",
      "epoch:16 step:15433 [D loss: 0.630909, acc.: 61.72%] [G loss: 1.130687]\n",
      "epoch:16 step:15434 [D loss: 0.600314, acc.: 69.53%] [G loss: 1.127684]\n",
      "epoch:16 step:15435 [D loss: 0.467813, acc.: 80.47%] [G loss: 1.264640]\n",
      "epoch:16 step:15436 [D loss: 0.466960, acc.: 83.59%] [G loss: 1.229176]\n",
      "epoch:16 step:15437 [D loss: 0.664791, acc.: 62.50%] [G loss: 1.122288]\n",
      "epoch:16 step:15438 [D loss: 0.763575, acc.: 43.75%] [G loss: 0.914366]\n",
      "epoch:16 step:15439 [D loss: 0.565172, acc.: 69.53%] [G loss: 0.867783]\n",
      "epoch:16 step:15440 [D loss: 0.474578, acc.: 77.34%] [G loss: 1.098330]\n",
      "epoch:16 step:15441 [D loss: 0.343170, acc.: 91.41%] [G loss: 1.643288]\n",
      "epoch:16 step:15442 [D loss: 0.545791, acc.: 71.09%] [G loss: 1.161339]\n",
      "epoch:16 step:15443 [D loss: 0.406337, acc.: 86.72%] [G loss: 1.124848]\n",
      "epoch:16 step:15444 [D loss: 0.383572, acc.: 89.84%] [G loss: 1.474344]\n",
      "epoch:16 step:15445 [D loss: 0.316951, acc.: 96.09%] [G loss: 1.596915]\n",
      "epoch:16 step:15446 [D loss: 0.447381, acc.: 83.59%] [G loss: 1.578617]\n",
      "epoch:16 step:15447 [D loss: 0.569203, acc.: 71.09%] [G loss: 1.209369]\n",
      "epoch:16 step:15448 [D loss: 0.519075, acc.: 74.22%] [G loss: 1.352464]\n",
      "epoch:16 step:15449 [D loss: 0.404978, acc.: 83.59%] [G loss: 1.525459]\n",
      "epoch:16 step:15450 [D loss: 1.022520, acc.: 49.22%] [G loss: 1.116172]\n",
      "epoch:16 step:15451 [D loss: 0.922258, acc.: 36.72%] [G loss: 0.810486]\n",
      "epoch:16 step:15452 [D loss: 1.067346, acc.: 21.09%] [G loss: 0.918165]\n",
      "epoch:16 step:15453 [D loss: 0.900416, acc.: 31.25%] [G loss: 1.191832]\n",
      "epoch:16 step:15454 [D loss: 0.968140, acc.: 34.38%] [G loss: 1.181813]\n",
      "epoch:16 step:15455 [D loss: 0.969581, acc.: 28.91%] [G loss: 0.803376]\n",
      "epoch:16 step:15456 [D loss: 0.909213, acc.: 34.38%] [G loss: 0.989468]\n",
      "epoch:16 step:15457 [D loss: 0.624053, acc.: 60.16%] [G loss: 1.198266]\n",
      "epoch:16 step:15458 [D loss: 0.858991, acc.: 44.53%] [G loss: 1.004304]\n",
      "epoch:16 step:15459 [D loss: 0.669075, acc.: 62.50%] [G loss: 1.263828]\n",
      "epoch:16 step:15460 [D loss: 0.713324, acc.: 56.25%] [G loss: 0.889431]\n",
      "epoch:16 step:15461 [D loss: 0.481180, acc.: 78.91%] [G loss: 1.236379]\n",
      "epoch:16 step:15462 [D loss: 0.510363, acc.: 73.44%] [G loss: 1.200639]\n",
      "epoch:16 step:15463 [D loss: 0.442668, acc.: 79.69%] [G loss: 1.328404]\n",
      "epoch:16 step:15464 [D loss: 0.595111, acc.: 71.88%] [G loss: 1.291284]\n",
      "epoch:16 step:15465 [D loss: 0.780269, acc.: 48.44%] [G loss: 1.116992]\n",
      "epoch:16 step:15466 [D loss: 0.642979, acc.: 63.28%] [G loss: 1.417479]\n",
      "epoch:16 step:15467 [D loss: 0.717003, acc.: 58.59%] [G loss: 1.557895]\n",
      "epoch:16 step:15468 [D loss: 0.737271, acc.: 50.00%] [G loss: 1.237898]\n",
      "epoch:16 step:15469 [D loss: 0.764138, acc.: 53.91%] [G loss: 1.214631]\n",
      "epoch:16 step:15470 [D loss: 0.571396, acc.: 72.66%] [G loss: 1.130500]\n",
      "epoch:16 step:15471 [D loss: 0.591901, acc.: 67.97%] [G loss: 1.110212]\n",
      "epoch:16 step:15472 [D loss: 0.614391, acc.: 68.75%] [G loss: 1.049103]\n",
      "epoch:16 step:15473 [D loss: 0.599459, acc.: 71.09%] [G loss: 0.997438]\n",
      "epoch:16 step:15474 [D loss: 0.541464, acc.: 73.44%] [G loss: 1.177780]\n",
      "epoch:16 step:15475 [D loss: 0.554099, acc.: 73.44%] [G loss: 1.266382]\n",
      "epoch:16 step:15476 [D loss: 0.397228, acc.: 91.41%] [G loss: 1.419685]\n",
      "epoch:16 step:15477 [D loss: 0.524592, acc.: 75.00%] [G loss: 1.200304]\n",
      "epoch:16 step:15478 [D loss: 0.490819, acc.: 80.47%] [G loss: 1.187757]\n",
      "epoch:16 step:15479 [D loss: 0.442798, acc.: 83.59%] [G loss: 1.324171]\n",
      "epoch:16 step:15480 [D loss: 0.651686, acc.: 64.06%] [G loss: 1.182237]\n",
      "epoch:16 step:15481 [D loss: 0.721305, acc.: 54.69%] [G loss: 1.085310]\n",
      "epoch:16 step:15482 [D loss: 0.686274, acc.: 56.25%] [G loss: 0.975657]\n",
      "epoch:16 step:15483 [D loss: 0.796592, acc.: 49.22%] [G loss: 0.926166]\n",
      "epoch:16 step:15484 [D loss: 0.638617, acc.: 61.72%] [G loss: 0.974557]\n",
      "epoch:16 step:15485 [D loss: 0.597735, acc.: 65.62%] [G loss: 1.002306]\n",
      "epoch:16 step:15486 [D loss: 0.676215, acc.: 59.38%] [G loss: 1.130635]\n",
      "epoch:16 step:15487 [D loss: 0.532474, acc.: 77.34%] [G loss: 1.124348]\n",
      "epoch:16 step:15488 [D loss: 0.654381, acc.: 58.59%] [G loss: 0.947587]\n",
      "epoch:16 step:15489 [D loss: 0.457282, acc.: 81.25%] [G loss: 1.405392]\n",
      "epoch:16 step:15490 [D loss: 0.385108, acc.: 92.97%] [G loss: 1.745753]\n",
      "epoch:16 step:15491 [D loss: 0.403851, acc.: 80.47%] [G loss: 1.042860]\n",
      "epoch:16 step:15492 [D loss: 0.749767, acc.: 53.12%] [G loss: 1.456924]\n",
      "epoch:16 step:15493 [D loss: 0.686570, acc.: 57.03%] [G loss: 1.083418]\n",
      "epoch:16 step:15494 [D loss: 0.667064, acc.: 56.25%] [G loss: 1.000818]\n",
      "epoch:16 step:15495 [D loss: 0.577631, acc.: 69.53%] [G loss: 1.213102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15496 [D loss: 0.604951, acc.: 67.97%] [G loss: 1.042378]\n",
      "epoch:16 step:15497 [D loss: 0.653249, acc.: 64.84%] [G loss: 0.992606]\n",
      "epoch:16 step:15498 [D loss: 0.676582, acc.: 58.59%] [G loss: 0.910844]\n",
      "epoch:16 step:15499 [D loss: 0.623866, acc.: 62.50%] [G loss: 0.900739]\n",
      "epoch:16 step:15500 [D loss: 0.484276, acc.: 76.56%] [G loss: 1.086483]\n",
      "epoch:16 step:15501 [D loss: 0.673815, acc.: 60.94%] [G loss: 1.198686]\n",
      "epoch:16 step:15502 [D loss: 0.646648, acc.: 61.72%] [G loss: 1.279857]\n",
      "epoch:16 step:15503 [D loss: 0.554351, acc.: 69.53%] [G loss: 1.234375]\n",
      "epoch:16 step:15504 [D loss: 0.568848, acc.: 70.31%] [G loss: 1.081736]\n",
      "epoch:16 step:15505 [D loss: 0.445256, acc.: 82.03%] [G loss: 1.130696]\n",
      "epoch:16 step:15506 [D loss: 0.587910, acc.: 73.44%] [G loss: 1.215396]\n",
      "epoch:16 step:15507 [D loss: 0.529596, acc.: 77.34%] [G loss: 1.222706]\n",
      "epoch:16 step:15508 [D loss: 0.565518, acc.: 67.97%] [G loss: 1.383453]\n",
      "epoch:16 step:15509 [D loss: 0.717154, acc.: 50.78%] [G loss: 1.149190]\n",
      "epoch:16 step:15510 [D loss: 0.723752, acc.: 51.56%] [G loss: 0.918508]\n",
      "epoch:16 step:15511 [D loss: 0.754285, acc.: 53.12%] [G loss: 0.887399]\n",
      "epoch:16 step:15512 [D loss: 0.526096, acc.: 74.22%] [G loss: 0.924300]\n",
      "epoch:16 step:15513 [D loss: 0.649884, acc.: 61.72%] [G loss: 0.901695]\n",
      "epoch:16 step:15514 [D loss: 0.546508, acc.: 74.22%] [G loss: 1.140603]\n",
      "epoch:16 step:15515 [D loss: 0.490934, acc.: 81.25%] [G loss: 1.087006]\n",
      "epoch:16 step:15516 [D loss: 0.587072, acc.: 68.75%] [G loss: 1.245848]\n",
      "epoch:16 step:15517 [D loss: 0.666778, acc.: 60.94%] [G loss: 0.964914]\n",
      "epoch:16 step:15518 [D loss: 0.670957, acc.: 57.03%] [G loss: 0.991787]\n",
      "epoch:16 step:15519 [D loss: 0.667274, acc.: 60.94%] [G loss: 0.915068]\n",
      "epoch:16 step:15520 [D loss: 0.642109, acc.: 62.50%] [G loss: 0.896950]\n",
      "epoch:16 step:15521 [D loss: 0.732311, acc.: 50.78%] [G loss: 1.028253]\n",
      "epoch:16 step:15522 [D loss: 0.677260, acc.: 57.81%] [G loss: 0.870955]\n",
      "epoch:16 step:15523 [D loss: 0.604400, acc.: 71.09%] [G loss: 1.029512]\n",
      "epoch:16 step:15524 [D loss: 0.557928, acc.: 75.00%] [G loss: 1.032760]\n",
      "epoch:16 step:15525 [D loss: 0.506969, acc.: 75.78%] [G loss: 1.137872]\n",
      "epoch:16 step:15526 [D loss: 0.560006, acc.: 71.88%] [G loss: 1.174680]\n",
      "epoch:16 step:15527 [D loss: 0.546890, acc.: 73.44%] [G loss: 1.190396]\n",
      "epoch:16 step:15528 [D loss: 0.512442, acc.: 77.34%] [G loss: 1.180681]\n",
      "epoch:16 step:15529 [D loss: 0.541835, acc.: 75.78%] [G loss: 1.191457]\n",
      "epoch:16 step:15530 [D loss: 0.729595, acc.: 53.91%] [G loss: 1.007021]\n",
      "epoch:16 step:15531 [D loss: 0.647584, acc.: 62.50%] [G loss: 1.171781]\n",
      "epoch:16 step:15532 [D loss: 0.689692, acc.: 55.47%] [G loss: 1.037163]\n",
      "epoch:16 step:15533 [D loss: 0.795886, acc.: 44.53%] [G loss: 0.748390]\n",
      "epoch:16 step:15534 [D loss: 0.567532, acc.: 69.53%] [G loss: 1.009227]\n",
      "epoch:16 step:15535 [D loss: 0.556543, acc.: 71.88%] [G loss: 1.131163]\n",
      "epoch:16 step:15536 [D loss: 0.628205, acc.: 64.84%] [G loss: 1.117112]\n",
      "epoch:16 step:15537 [D loss: 0.415197, acc.: 88.28%] [G loss: 1.274957]\n",
      "epoch:16 step:15538 [D loss: 0.355902, acc.: 91.41%] [G loss: 1.268102]\n",
      "epoch:16 step:15539 [D loss: 0.444541, acc.: 86.72%] [G loss: 1.385569]\n",
      "epoch:16 step:15540 [D loss: 0.498259, acc.: 82.81%] [G loss: 1.139906]\n",
      "epoch:16 step:15541 [D loss: 0.396922, acc.: 86.72%] [G loss: 1.088958]\n",
      "epoch:16 step:15542 [D loss: 0.423211, acc.: 83.59%] [G loss: 1.386470]\n",
      "epoch:16 step:15543 [D loss: 0.365763, acc.: 92.19%] [G loss: 1.425312]\n",
      "epoch:16 step:15544 [D loss: 0.440535, acc.: 83.59%] [G loss: 1.156484]\n",
      "epoch:16 step:15545 [D loss: 0.486248, acc.: 81.25%] [G loss: 1.278144]\n",
      "epoch:16 step:15546 [D loss: 0.401230, acc.: 89.06%] [G loss: 1.169283]\n",
      "epoch:16 step:15547 [D loss: 0.409447, acc.: 87.50%] [G loss: 1.525593]\n",
      "epoch:16 step:15548 [D loss: 0.309215, acc.: 94.53%] [G loss: 1.302837]\n",
      "epoch:16 step:15549 [D loss: 0.284961, acc.: 95.31%] [G loss: 1.697827]\n",
      "epoch:16 step:15550 [D loss: 0.511520, acc.: 78.12%] [G loss: 1.269523]\n",
      "epoch:16 step:15551 [D loss: 1.025945, acc.: 35.94%] [G loss: 1.217852]\n",
      "epoch:16 step:15552 [D loss: 0.906376, acc.: 42.19%] [G loss: 1.242654]\n",
      "epoch:16 step:15553 [D loss: 0.720346, acc.: 50.78%] [G loss: 1.128315]\n",
      "epoch:16 step:15554 [D loss: 0.704850, acc.: 54.69%] [G loss: 1.334342]\n",
      "epoch:16 step:15555 [D loss: 0.666798, acc.: 65.62%] [G loss: 1.089306]\n",
      "epoch:16 step:15556 [D loss: 0.632983, acc.: 67.97%] [G loss: 1.018299]\n",
      "epoch:16 step:15557 [D loss: 0.570375, acc.: 73.44%] [G loss: 1.258612]\n",
      "epoch:16 step:15558 [D loss: 0.451172, acc.: 84.38%] [G loss: 1.106952]\n",
      "epoch:16 step:15559 [D loss: 0.385894, acc.: 91.41%] [G loss: 1.358157]\n",
      "epoch:16 step:15560 [D loss: 0.636762, acc.: 67.97%] [G loss: 1.301941]\n",
      "epoch:16 step:15561 [D loss: 0.651663, acc.: 60.94%] [G loss: 1.113281]\n",
      "epoch:16 step:15562 [D loss: 0.709970, acc.: 55.47%] [G loss: 1.024629]\n",
      "epoch:16 step:15563 [D loss: 0.549533, acc.: 71.88%] [G loss: 0.934563]\n",
      "epoch:16 step:15564 [D loss: 0.581722, acc.: 71.09%] [G loss: 1.021242]\n",
      "epoch:16 step:15565 [D loss: 0.535006, acc.: 75.78%] [G loss: 1.124205]\n",
      "epoch:16 step:15566 [D loss: 0.506816, acc.: 78.12%] [G loss: 1.234308]\n",
      "epoch:16 step:15567 [D loss: 0.487005, acc.: 78.12%] [G loss: 0.999366]\n",
      "epoch:16 step:15568 [D loss: 0.554529, acc.: 76.56%] [G loss: 1.144338]\n",
      "epoch:16 step:15569 [D loss: 0.388826, acc.: 88.28%] [G loss: 1.220232]\n",
      "epoch:16 step:15570 [D loss: 0.545678, acc.: 70.31%] [G loss: 0.951378]\n",
      "epoch:16 step:15571 [D loss: 0.630789, acc.: 64.84%] [G loss: 1.183751]\n",
      "epoch:16 step:15572 [D loss: 0.659889, acc.: 58.59%] [G loss: 1.070775]\n",
      "epoch:16 step:15573 [D loss: 0.681214, acc.: 60.16%] [G loss: 0.805481]\n",
      "epoch:16 step:15574 [D loss: 0.892589, acc.: 39.06%] [G loss: 0.736910]\n",
      "epoch:16 step:15575 [D loss: 0.711050, acc.: 57.81%] [G loss: 0.952899]\n",
      "epoch:16 step:15576 [D loss: 0.960141, acc.: 29.69%] [G loss: 0.878733]\n",
      "epoch:16 step:15577 [D loss: 0.662155, acc.: 57.81%] [G loss: 0.891515]\n",
      "epoch:16 step:15578 [D loss: 0.587884, acc.: 71.09%] [G loss: 0.921776]\n",
      "epoch:16 step:15579 [D loss: 0.518579, acc.: 74.22%] [G loss: 1.178034]\n",
      "epoch:16 step:15580 [D loss: 0.520262, acc.: 75.00%] [G loss: 1.107433]\n",
      "epoch:16 step:15581 [D loss: 0.530068, acc.: 76.56%] [G loss: 1.178332]\n",
      "epoch:16 step:15582 [D loss: 0.654189, acc.: 59.38%] [G loss: 1.449861]\n",
      "epoch:16 step:15583 [D loss: 0.698831, acc.: 54.69%] [G loss: 1.103633]\n",
      "epoch:16 step:15584 [D loss: 0.540773, acc.: 74.22%] [G loss: 1.525321]\n",
      "epoch:16 step:15585 [D loss: 0.612405, acc.: 62.50%] [G loss: 1.165857]\n",
      "epoch:16 step:15586 [D loss: 0.539643, acc.: 74.22%] [G loss: 0.886126]\n",
      "epoch:16 step:15587 [D loss: 0.505182, acc.: 82.03%] [G loss: 1.240883]\n",
      "epoch:16 step:15588 [D loss: 0.650577, acc.: 60.16%] [G loss: 0.804626]\n",
      "epoch:16 step:15589 [D loss: 0.606817, acc.: 69.53%] [G loss: 1.062181]\n",
      "epoch:16 step:15590 [D loss: 0.369750, acc.: 89.06%] [G loss: 1.144691]\n",
      "epoch:16 step:15591 [D loss: 0.741824, acc.: 48.44%] [G loss: 0.957873]\n",
      "epoch:16 step:15592 [D loss: 0.693383, acc.: 57.81%] [G loss: 1.057061]\n",
      "epoch:16 step:15593 [D loss: 0.604627, acc.: 69.53%] [G loss: 0.852265]\n",
      "epoch:16 step:15594 [D loss: 0.686449, acc.: 54.69%] [G loss: 0.981808]\n",
      "epoch:16 step:15595 [D loss: 0.426695, acc.: 82.81%] [G loss: 0.997899]\n",
      "epoch:16 step:15596 [D loss: 0.476264, acc.: 75.78%] [G loss: 1.087415]\n",
      "epoch:16 step:15597 [D loss: 0.418096, acc.: 88.28%] [G loss: 1.358638]\n",
      "epoch:16 step:15598 [D loss: 0.667492, acc.: 60.16%] [G loss: 1.163564]\n",
      "epoch:16 step:15599 [D loss: 0.644966, acc.: 64.06%] [G loss: 1.242881]\n",
      "epoch:16 step:15600 [D loss: 0.628044, acc.: 67.19%] [G loss: 0.868873]\n",
      "epoch:16 step:15601 [D loss: 0.913416, acc.: 42.97%] [G loss: 0.745594]\n",
      "epoch:16 step:15602 [D loss: 0.649709, acc.: 60.94%] [G loss: 1.230464]\n",
      "epoch:16 step:15603 [D loss: 0.920130, acc.: 25.78%] [G loss: 0.920789]\n",
      "epoch:16 step:15604 [D loss: 0.767773, acc.: 48.44%] [G loss: 1.115359]\n",
      "epoch:16 step:15605 [D loss: 0.485107, acc.: 82.03%] [G loss: 1.541480]\n",
      "epoch:16 step:15606 [D loss: 0.572359, acc.: 69.53%] [G loss: 0.995017]\n",
      "epoch:16 step:15607 [D loss: 0.615103, acc.: 65.62%] [G loss: 0.973911]\n",
      "epoch:16 step:15608 [D loss: 0.480548, acc.: 78.91%] [G loss: 1.267640]\n",
      "epoch:16 step:15609 [D loss: 0.555303, acc.: 71.88%] [G loss: 1.511776]\n",
      "epoch:16 step:15610 [D loss: 0.797879, acc.: 49.22%] [G loss: 1.032038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15611 [D loss: 0.818645, acc.: 39.84%] [G loss: 0.910190]\n",
      "epoch:16 step:15612 [D loss: 0.648598, acc.: 60.94%] [G loss: 0.987757]\n",
      "epoch:16 step:15613 [D loss: 0.918690, acc.: 35.94%] [G loss: 0.934714]\n",
      "epoch:16 step:15614 [D loss: 0.633763, acc.: 68.75%] [G loss: 1.128837]\n",
      "epoch:16 step:15615 [D loss: 0.735366, acc.: 50.78%] [G loss: 0.977781]\n",
      "epoch:16 step:15616 [D loss: 0.539734, acc.: 73.44%] [G loss: 1.195129]\n",
      "epoch:16 step:15617 [D loss: 0.627414, acc.: 67.19%] [G loss: 1.214490]\n",
      "epoch:16 step:15618 [D loss: 0.687314, acc.: 56.25%] [G loss: 0.769215]\n",
      "epoch:16 step:15619 [D loss: 0.801249, acc.: 43.75%] [G loss: 0.733464]\n",
      "epoch:16 step:15620 [D loss: 0.689251, acc.: 57.03%] [G loss: 0.988890]\n",
      "epoch:16 step:15621 [D loss: 0.424474, acc.: 84.38%] [G loss: 1.095899]\n",
      "epoch:16 step:15622 [D loss: 0.444604, acc.: 84.38%] [G loss: 1.047091]\n",
      "epoch:16 step:15623 [D loss: 0.572334, acc.: 75.78%] [G loss: 1.058695]\n",
      "epoch:16 step:15624 [D loss: 0.666134, acc.: 58.59%] [G loss: 0.956589]\n",
      "epoch:16 step:15625 [D loss: 0.588374, acc.: 71.09%] [G loss: 0.984651]\n",
      "epoch:16 step:15626 [D loss: 0.578835, acc.: 71.88%] [G loss: 0.956464]\n",
      "epoch:16 step:15627 [D loss: 0.702125, acc.: 53.91%] [G loss: 1.032793]\n",
      "epoch:16 step:15628 [D loss: 0.766796, acc.: 51.56%] [G loss: 0.922939]\n",
      "epoch:16 step:15629 [D loss: 0.637021, acc.: 62.50%] [G loss: 1.392612]\n",
      "epoch:16 step:15630 [D loss: 0.732236, acc.: 50.78%] [G loss: 0.959575]\n",
      "epoch:16 step:15631 [D loss: 0.897521, acc.: 34.38%] [G loss: 0.806247]\n",
      "epoch:16 step:15632 [D loss: 0.480924, acc.: 79.69%] [G loss: 1.502861]\n",
      "epoch:16 step:15633 [D loss: 0.397467, acc.: 89.06%] [G loss: 1.419042]\n",
      "epoch:16 step:15634 [D loss: 0.435515, acc.: 85.94%] [G loss: 1.432877]\n",
      "epoch:16 step:15635 [D loss: 0.703156, acc.: 59.38%] [G loss: 1.316138]\n",
      "epoch:16 step:15636 [D loss: 0.708147, acc.: 53.91%] [G loss: 1.200130]\n",
      "epoch:16 step:15637 [D loss: 0.608146, acc.: 64.06%] [G loss: 1.125062]\n",
      "epoch:16 step:15638 [D loss: 0.720865, acc.: 51.56%] [G loss: 0.993820]\n",
      "epoch:16 step:15639 [D loss: 0.610804, acc.: 69.53%] [G loss: 0.985987]\n",
      "epoch:16 step:15640 [D loss: 0.613749, acc.: 68.75%] [G loss: 0.951138]\n",
      "epoch:16 step:15641 [D loss: 0.636151, acc.: 66.41%] [G loss: 0.889493]\n",
      "epoch:16 step:15642 [D loss: 0.643784, acc.: 64.84%] [G loss: 1.169427]\n",
      "epoch:16 step:15643 [D loss: 0.701574, acc.: 60.16%] [G loss: 0.957460]\n",
      "epoch:16 step:15644 [D loss: 0.684540, acc.: 59.38%] [G loss: 1.037622]\n",
      "epoch:16 step:15645 [D loss: 0.547110, acc.: 78.12%] [G loss: 1.010134]\n",
      "epoch:16 step:15646 [D loss: 0.650795, acc.: 62.50%] [G loss: 0.986784]\n",
      "epoch:16 step:15647 [D loss: 0.658278, acc.: 64.84%] [G loss: 1.088800]\n",
      "epoch:16 step:15648 [D loss: 0.601746, acc.: 66.41%] [G loss: 1.022280]\n",
      "epoch:16 step:15649 [D loss: 0.663409, acc.: 60.94%] [G loss: 1.091725]\n",
      "epoch:16 step:15650 [D loss: 0.515222, acc.: 78.12%] [G loss: 1.046411]\n",
      "epoch:16 step:15651 [D loss: 0.652943, acc.: 60.16%] [G loss: 0.991618]\n",
      "epoch:16 step:15652 [D loss: 0.730881, acc.: 50.78%] [G loss: 0.949951]\n",
      "epoch:16 step:15653 [D loss: 0.807557, acc.: 42.19%] [G loss: 0.818987]\n",
      "epoch:16 step:15654 [D loss: 0.425264, acc.: 86.72%] [G loss: 1.403334]\n",
      "epoch:16 step:15655 [D loss: 0.343266, acc.: 92.19%] [G loss: 1.330516]\n",
      "epoch:16 step:15656 [D loss: 0.324656, acc.: 92.19%] [G loss: 1.328493]\n",
      "epoch:16 step:15657 [D loss: 0.347338, acc.: 89.06%] [G loss: 1.391801]\n",
      "epoch:16 step:15658 [D loss: 0.538703, acc.: 73.44%] [G loss: 1.355126]\n",
      "epoch:16 step:15659 [D loss: 0.523850, acc.: 72.66%] [G loss: 1.218461]\n",
      "epoch:16 step:15660 [D loss: 0.707861, acc.: 56.25%] [G loss: 1.045907]\n",
      "epoch:16 step:15661 [D loss: 0.717849, acc.: 55.47%] [G loss: 0.893712]\n",
      "epoch:16 step:15662 [D loss: 0.828187, acc.: 42.97%] [G loss: 1.126201]\n",
      "epoch:16 step:15663 [D loss: 0.711680, acc.: 58.59%] [G loss: 1.089792]\n",
      "epoch:16 step:15664 [D loss: 0.832944, acc.: 44.53%] [G loss: 0.970120]\n",
      "epoch:16 step:15665 [D loss: 0.942557, acc.: 28.91%] [G loss: 0.851396]\n",
      "epoch:16 step:15666 [D loss: 0.682224, acc.: 64.84%] [G loss: 0.912387]\n",
      "epoch:16 step:15667 [D loss: 0.727565, acc.: 53.12%] [G loss: 1.005092]\n",
      "epoch:16 step:15668 [D loss: 0.767996, acc.: 50.78%] [G loss: 0.966789]\n",
      "epoch:16 step:15669 [D loss: 0.755248, acc.: 52.34%] [G loss: 0.964434]\n",
      "epoch:16 step:15670 [D loss: 0.657563, acc.: 54.69%] [G loss: 1.166095]\n",
      "epoch:16 step:15671 [D loss: 0.693231, acc.: 58.59%] [G loss: 1.019501]\n",
      "epoch:16 step:15672 [D loss: 0.703889, acc.: 55.47%] [G loss: 1.095584]\n",
      "epoch:16 step:15673 [D loss: 0.704598, acc.: 56.25%] [G loss: 1.250416]\n",
      "epoch:16 step:15674 [D loss: 0.630875, acc.: 61.72%] [G loss: 1.025227]\n",
      "epoch:16 step:15675 [D loss: 0.668733, acc.: 61.72%] [G loss: 1.058405]\n",
      "epoch:16 step:15676 [D loss: 0.578352, acc.: 69.53%] [G loss: 1.041110]\n",
      "epoch:16 step:15677 [D loss: 0.641382, acc.: 64.84%] [G loss: 1.075964]\n",
      "epoch:16 step:15678 [D loss: 0.646141, acc.: 64.06%] [G loss: 0.967982]\n",
      "epoch:16 step:15679 [D loss: 0.669449, acc.: 58.59%] [G loss: 0.967884]\n",
      "epoch:16 step:15680 [D loss: 0.693681, acc.: 57.81%] [G loss: 1.208067]\n",
      "epoch:16 step:15681 [D loss: 0.583310, acc.: 69.53%] [G loss: 1.052286]\n",
      "epoch:16 step:15682 [D loss: 0.403278, acc.: 85.16%] [G loss: 1.448370]\n",
      "epoch:16 step:15683 [D loss: 0.422675, acc.: 83.59%] [G loss: 1.255107]\n",
      "epoch:16 step:15684 [D loss: 0.424869, acc.: 86.72%] [G loss: 1.183307]\n",
      "epoch:16 step:15685 [D loss: 0.526688, acc.: 76.56%] [G loss: 1.208866]\n",
      "epoch:16 step:15686 [D loss: 0.384148, acc.: 87.50%] [G loss: 1.399489]\n",
      "epoch:16 step:15687 [D loss: 0.525936, acc.: 75.00%] [G loss: 1.267934]\n",
      "epoch:16 step:15688 [D loss: 0.790477, acc.: 47.66%] [G loss: 1.190381]\n",
      "epoch:16 step:15689 [D loss: 0.681326, acc.: 53.91%] [G loss: 1.254348]\n",
      "epoch:16 step:15690 [D loss: 0.662238, acc.: 60.16%] [G loss: 1.147556]\n",
      "epoch:16 step:15691 [D loss: 0.675684, acc.: 57.03%] [G loss: 0.966895]\n",
      "epoch:16 step:15692 [D loss: 0.646338, acc.: 65.62%] [G loss: 1.185091]\n",
      "epoch:16 step:15693 [D loss: 0.580763, acc.: 67.97%] [G loss: 1.087736]\n",
      "epoch:16 step:15694 [D loss: 0.635729, acc.: 63.28%] [G loss: 1.114691]\n",
      "epoch:16 step:15695 [D loss: 0.732442, acc.: 46.09%] [G loss: 0.865893]\n",
      "epoch:16 step:15696 [D loss: 0.729856, acc.: 56.25%] [G loss: 0.977156]\n",
      "epoch:16 step:15697 [D loss: 0.600616, acc.: 67.19%] [G loss: 1.088969]\n",
      "epoch:16 step:15698 [D loss: 0.623563, acc.: 64.84%] [G loss: 1.017472]\n",
      "epoch:16 step:15699 [D loss: 0.569029, acc.: 70.31%] [G loss: 1.054013]\n",
      "epoch:16 step:15700 [D loss: 0.446447, acc.: 85.16%] [G loss: 1.270211]\n",
      "epoch:16 step:15701 [D loss: 0.482602, acc.: 75.78%] [G loss: 1.060521]\n",
      "epoch:16 step:15702 [D loss: 0.666819, acc.: 59.38%] [G loss: 1.198037]\n",
      "epoch:16 step:15703 [D loss: 0.563119, acc.: 74.22%] [G loss: 1.251559]\n",
      "epoch:16 step:15704 [D loss: 0.577084, acc.: 75.78%] [G loss: 1.036136]\n",
      "epoch:16 step:15705 [D loss: 0.563059, acc.: 73.44%] [G loss: 1.042239]\n",
      "epoch:16 step:15706 [D loss: 0.548562, acc.: 71.88%] [G loss: 1.152219]\n",
      "epoch:16 step:15707 [D loss: 0.680132, acc.: 61.72%] [G loss: 1.037491]\n",
      "epoch:16 step:15708 [D loss: 0.802698, acc.: 48.44%] [G loss: 1.007132]\n",
      "epoch:16 step:15709 [D loss: 0.652255, acc.: 57.81%] [G loss: 0.868737]\n",
      "epoch:16 step:15710 [D loss: 0.703613, acc.: 56.25%] [G loss: 1.003501]\n",
      "epoch:16 step:15711 [D loss: 0.653392, acc.: 66.41%] [G loss: 0.885894]\n",
      "epoch:16 step:15712 [D loss: 0.567115, acc.: 67.97%] [G loss: 1.042727]\n",
      "epoch:16 step:15713 [D loss: 0.712063, acc.: 49.22%] [G loss: 0.886223]\n",
      "epoch:16 step:15714 [D loss: 0.722560, acc.: 57.81%] [G loss: 0.907395]\n",
      "epoch:16 step:15715 [D loss: 0.622023, acc.: 65.62%] [G loss: 1.050906]\n",
      "epoch:16 step:15716 [D loss: 0.523963, acc.: 77.34%] [G loss: 0.976761]\n",
      "epoch:16 step:15717 [D loss: 0.575283, acc.: 70.31%] [G loss: 1.075172]\n",
      "epoch:16 step:15718 [D loss: 0.554193, acc.: 71.88%] [G loss: 1.201149]\n",
      "epoch:16 step:15719 [D loss: 0.610228, acc.: 66.41%] [G loss: 1.114471]\n",
      "epoch:16 step:15720 [D loss: 0.548515, acc.: 68.75%] [G loss: 1.301357]\n",
      "epoch:16 step:15721 [D loss: 0.694366, acc.: 54.69%] [G loss: 0.977374]\n",
      "epoch:16 step:15722 [D loss: 0.603719, acc.: 68.75%] [G loss: 0.968853]\n",
      "epoch:16 step:15723 [D loss: 0.457252, acc.: 83.59%] [G loss: 1.126136]\n",
      "epoch:16 step:15724 [D loss: 0.503165, acc.: 78.12%] [G loss: 1.120569]\n",
      "epoch:16 step:15725 [D loss: 0.397019, acc.: 91.41%] [G loss: 1.340084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15726 [D loss: 0.788442, acc.: 50.00%] [G loss: 0.985108]\n",
      "epoch:16 step:15727 [D loss: 0.671863, acc.: 58.59%] [G loss: 1.071598]\n",
      "epoch:16 step:15728 [D loss: 0.739228, acc.: 52.34%] [G loss: 0.910969]\n",
      "epoch:16 step:15729 [D loss: 0.526781, acc.: 78.12%] [G loss: 1.055737]\n",
      "epoch:16 step:15730 [D loss: 0.582445, acc.: 66.41%] [G loss: 0.943026]\n",
      "epoch:16 step:15731 [D loss: 0.534180, acc.: 75.00%] [G loss: 1.024158]\n",
      "epoch:16 step:15732 [D loss: 0.590346, acc.: 68.75%] [G loss: 0.865007]\n",
      "epoch:16 step:15733 [D loss: 0.648483, acc.: 64.06%] [G loss: 1.021666]\n",
      "epoch:16 step:15734 [D loss: 0.671722, acc.: 61.72%] [G loss: 1.016028]\n",
      "epoch:16 step:15735 [D loss: 0.653056, acc.: 62.50%] [G loss: 0.971354]\n",
      "epoch:16 step:15736 [D loss: 0.783707, acc.: 42.97%] [G loss: 1.018837]\n",
      "epoch:16 step:15737 [D loss: 0.441861, acc.: 78.91%] [G loss: 1.085197]\n",
      "epoch:16 step:15738 [D loss: 0.387430, acc.: 90.62%] [G loss: 1.140896]\n",
      "epoch:16 step:15739 [D loss: 0.623038, acc.: 61.72%] [G loss: 1.241466]\n",
      "epoch:16 step:15740 [D loss: 0.757030, acc.: 52.34%] [G loss: 1.137272]\n",
      "epoch:16 step:15741 [D loss: 0.671555, acc.: 60.16%] [G loss: 0.971646]\n",
      "epoch:16 step:15742 [D loss: 0.575973, acc.: 75.00%] [G loss: 1.222940]\n",
      "epoch:16 step:15743 [D loss: 0.728939, acc.: 53.91%] [G loss: 0.998111]\n",
      "epoch:16 step:15744 [D loss: 0.709332, acc.: 57.81%] [G loss: 0.771072]\n",
      "epoch:16 step:15745 [D loss: 0.627787, acc.: 64.84%] [G loss: 1.014660]\n",
      "epoch:16 step:15746 [D loss: 0.556147, acc.: 70.31%] [G loss: 0.865991]\n",
      "epoch:16 step:15747 [D loss: 0.613082, acc.: 66.41%] [G loss: 1.020699]\n",
      "epoch:16 step:15748 [D loss: 0.515490, acc.: 71.88%] [G loss: 1.259801]\n",
      "epoch:16 step:15749 [D loss: 0.702455, acc.: 53.12%] [G loss: 0.877313]\n",
      "epoch:16 step:15750 [D loss: 0.620539, acc.: 65.62%] [G loss: 1.166547]\n",
      "epoch:16 step:15751 [D loss: 0.804216, acc.: 43.75%] [G loss: 0.975838]\n",
      "epoch:16 step:15752 [D loss: 0.692374, acc.: 57.81%] [G loss: 0.999691]\n",
      "epoch:16 step:15753 [D loss: 0.683869, acc.: 58.59%] [G loss: 1.047497]\n",
      "epoch:16 step:15754 [D loss: 0.768208, acc.: 50.78%] [G loss: 1.066913]\n",
      "epoch:16 step:15755 [D loss: 0.652537, acc.: 60.16%] [G loss: 0.981916]\n",
      "epoch:16 step:15756 [D loss: 0.575586, acc.: 71.88%] [G loss: 1.011602]\n",
      "epoch:16 step:15757 [D loss: 0.739329, acc.: 51.56%] [G loss: 1.259808]\n",
      "epoch:16 step:15758 [D loss: 0.741217, acc.: 49.22%] [G loss: 1.057195]\n",
      "epoch:16 step:15759 [D loss: 0.498254, acc.: 82.03%] [G loss: 0.913089]\n",
      "epoch:16 step:15760 [D loss: 0.415029, acc.: 85.16%] [G loss: 1.383709]\n",
      "epoch:16 step:15761 [D loss: 0.395532, acc.: 89.06%] [G loss: 1.260522]\n",
      "epoch:16 step:15762 [D loss: 0.495974, acc.: 78.12%] [G loss: 1.342345]\n",
      "epoch:16 step:15763 [D loss: 0.638507, acc.: 60.16%] [G loss: 1.199049]\n",
      "epoch:16 step:15764 [D loss: 0.575375, acc.: 74.22%] [G loss: 1.009416]\n",
      "epoch:16 step:15765 [D loss: 0.658066, acc.: 59.38%] [G loss: 1.011833]\n",
      "epoch:16 step:15766 [D loss: 0.361123, acc.: 83.59%] [G loss: 1.173632]\n",
      "epoch:16 step:15767 [D loss: 0.295719, acc.: 93.75%] [G loss: 1.407096]\n",
      "epoch:16 step:15768 [D loss: 0.450194, acc.: 83.59%] [G loss: 1.432538]\n",
      "epoch:16 step:15769 [D loss: 0.547900, acc.: 71.88%] [G loss: 1.336278]\n",
      "epoch:16 step:15770 [D loss: 0.619910, acc.: 64.84%] [G loss: 1.465239]\n",
      "epoch:16 step:15771 [D loss: 0.962680, acc.: 31.25%] [G loss: 0.929897]\n",
      "epoch:16 step:15772 [D loss: 0.845446, acc.: 38.28%] [G loss: 0.905474]\n",
      "epoch:16 step:15773 [D loss: 0.646241, acc.: 59.38%] [G loss: 1.027521]\n",
      "epoch:16 step:15774 [D loss: 0.550107, acc.: 73.44%] [G loss: 1.205954]\n",
      "epoch:16 step:15775 [D loss: 0.695440, acc.: 53.12%] [G loss: 0.947851]\n",
      "epoch:16 step:15776 [D loss: 0.654800, acc.: 62.50%] [G loss: 1.126135]\n",
      "epoch:16 step:15777 [D loss: 0.655430, acc.: 60.16%] [G loss: 0.885918]\n",
      "epoch:16 step:15778 [D loss: 0.610817, acc.: 66.41%] [G loss: 0.971836]\n",
      "epoch:16 step:15779 [D loss: 0.657641, acc.: 60.16%] [G loss: 0.970782]\n",
      "epoch:16 step:15780 [D loss: 0.731811, acc.: 58.59%] [G loss: 0.999925]\n",
      "epoch:16 step:15781 [D loss: 0.771685, acc.: 47.66%] [G loss: 0.724544]\n",
      "epoch:16 step:15782 [D loss: 0.623464, acc.: 64.84%] [G loss: 0.972375]\n",
      "epoch:16 step:15783 [D loss: 0.466798, acc.: 78.12%] [G loss: 1.154155]\n",
      "epoch:16 step:15784 [D loss: 0.378062, acc.: 89.06%] [G loss: 1.164970]\n",
      "epoch:16 step:15785 [D loss: 0.469171, acc.: 88.28%] [G loss: 1.336559]\n",
      "epoch:16 step:15786 [D loss: 0.425001, acc.: 83.59%] [G loss: 1.294110]\n",
      "epoch:16 step:15787 [D loss: 0.593700, acc.: 65.62%] [G loss: 1.188315]\n",
      "epoch:16 step:15788 [D loss: 0.532510, acc.: 71.88%] [G loss: 1.252877]\n",
      "epoch:16 step:15789 [D loss: 0.586930, acc.: 75.78%] [G loss: 1.042428]\n",
      "epoch:16 step:15790 [D loss: 0.586342, acc.: 66.41%] [G loss: 1.108775]\n",
      "epoch:16 step:15791 [D loss: 0.667113, acc.: 62.50%] [G loss: 1.176448]\n",
      "epoch:16 step:15792 [D loss: 0.850560, acc.: 39.84%] [G loss: 0.872280]\n",
      "epoch:16 step:15793 [D loss: 0.780975, acc.: 39.06%] [G loss: 0.882421]\n",
      "epoch:16 step:15794 [D loss: 0.710720, acc.: 54.69%] [G loss: 0.817364]\n",
      "epoch:16 step:15795 [D loss: 0.677470, acc.: 59.38%] [G loss: 0.904882]\n",
      "epoch:16 step:15796 [D loss: 0.599897, acc.: 67.19%] [G loss: 1.122634]\n",
      "epoch:16 step:15797 [D loss: 0.506226, acc.: 75.78%] [G loss: 1.126168]\n",
      "epoch:16 step:15798 [D loss: 0.466535, acc.: 81.25%] [G loss: 1.080676]\n",
      "epoch:16 step:15799 [D loss: 0.606752, acc.: 71.09%] [G loss: 1.095469]\n",
      "epoch:16 step:15800 [D loss: 0.593687, acc.: 66.41%] [G loss: 0.990791]\n",
      "epoch:16 step:15801 [D loss: 0.568480, acc.: 69.53%] [G loss: 1.091979]\n",
      "epoch:16 step:15802 [D loss: 0.611132, acc.: 64.84%] [G loss: 0.933498]\n",
      "epoch:16 step:15803 [D loss: 0.838368, acc.: 39.06%] [G loss: 0.994654]\n",
      "epoch:16 step:15804 [D loss: 0.679345, acc.: 56.25%] [G loss: 1.168184]\n",
      "epoch:16 step:15805 [D loss: 0.703407, acc.: 59.38%] [G loss: 0.869332]\n",
      "epoch:16 step:15806 [D loss: 0.582756, acc.: 69.53%] [G loss: 0.994028]\n",
      "epoch:16 step:15807 [D loss: 0.393938, acc.: 77.34%] [G loss: 1.118286]\n",
      "epoch:16 step:15808 [D loss: 0.455705, acc.: 82.81%] [G loss: 1.105044]\n",
      "epoch:16 step:15809 [D loss: 0.680093, acc.: 57.03%] [G loss: 0.860972]\n",
      "epoch:16 step:15810 [D loss: 0.610993, acc.: 66.41%] [G loss: 1.128403]\n",
      "epoch:16 step:15811 [D loss: 0.591117, acc.: 71.09%] [G loss: 1.083534]\n",
      "epoch:16 step:15812 [D loss: 0.865891, acc.: 38.28%] [G loss: 0.848714]\n",
      "epoch:16 step:15813 [D loss: 0.873314, acc.: 32.03%] [G loss: 0.805051]\n",
      "epoch:16 step:15814 [D loss: 0.697936, acc.: 55.47%] [G loss: 1.060021]\n",
      "epoch:16 step:15815 [D loss: 0.585704, acc.: 70.31%] [G loss: 0.979226]\n",
      "epoch:16 step:15816 [D loss: 0.585173, acc.: 68.75%] [G loss: 0.935677]\n",
      "epoch:16 step:15817 [D loss: 0.536267, acc.: 75.00%] [G loss: 1.011202]\n",
      "epoch:16 step:15818 [D loss: 0.570267, acc.: 69.53%] [G loss: 1.096125]\n",
      "epoch:16 step:15819 [D loss: 0.661702, acc.: 60.94%] [G loss: 0.868457]\n",
      "epoch:16 step:15820 [D loss: 0.633985, acc.: 62.50%] [G loss: 1.077324]\n",
      "epoch:16 step:15821 [D loss: 0.780469, acc.: 51.56%] [G loss: 0.787361]\n",
      "epoch:16 step:15822 [D loss: 0.645949, acc.: 67.97%] [G loss: 0.907730]\n",
      "epoch:16 step:15823 [D loss: 0.447447, acc.: 85.94%] [G loss: 1.249806]\n",
      "epoch:16 step:15824 [D loss: 0.476409, acc.: 84.38%] [G loss: 0.856648]\n",
      "epoch:16 step:15825 [D loss: 0.532121, acc.: 73.44%] [G loss: 1.116961]\n",
      "epoch:16 step:15826 [D loss: 0.783658, acc.: 43.75%] [G loss: 1.259618]\n",
      "epoch:16 step:15827 [D loss: 0.559178, acc.: 74.22%] [G loss: 1.339046]\n",
      "epoch:16 step:15828 [D loss: 0.660038, acc.: 59.38%] [G loss: 1.167808]\n",
      "epoch:16 step:15829 [D loss: 0.614279, acc.: 69.53%] [G loss: 0.983607]\n",
      "epoch:16 step:15830 [D loss: 0.701070, acc.: 60.94%] [G loss: 0.919084]\n",
      "epoch:16 step:15831 [D loss: 0.658194, acc.: 60.16%] [G loss: 1.080555]\n",
      "epoch:16 step:15832 [D loss: 0.474343, acc.: 80.47%] [G loss: 1.135621]\n",
      "epoch:16 step:15833 [D loss: 0.551797, acc.: 74.22%] [G loss: 1.117139]\n",
      "epoch:16 step:15834 [D loss: 0.490997, acc.: 78.12%] [G loss: 1.302704]\n",
      "epoch:16 step:15835 [D loss: 0.626214, acc.: 60.16%] [G loss: 1.057334]\n",
      "epoch:16 step:15836 [D loss: 0.737093, acc.: 48.44%] [G loss: 0.872303]\n",
      "epoch:16 step:15837 [D loss: 0.638487, acc.: 61.72%] [G loss: 0.816267]\n",
      "epoch:16 step:15838 [D loss: 0.686456, acc.: 60.94%] [G loss: 0.729981]\n",
      "epoch:16 step:15839 [D loss: 0.558553, acc.: 71.09%] [G loss: 0.993683]\n",
      "epoch:16 step:15840 [D loss: 0.598066, acc.: 68.75%] [G loss: 1.036638]\n",
      "epoch:16 step:15841 [D loss: 0.703453, acc.: 59.38%] [G loss: 1.064494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15842 [D loss: 0.508079, acc.: 75.00%] [G loss: 1.224175]\n",
      "epoch:16 step:15843 [D loss: 0.440159, acc.: 82.03%] [G loss: 1.409955]\n",
      "epoch:16 step:15844 [D loss: 0.389377, acc.: 89.06%] [G loss: 1.368298]\n",
      "epoch:16 step:15845 [D loss: 0.590717, acc.: 68.75%] [G loss: 1.072752]\n",
      "epoch:16 step:15846 [D loss: 0.312167, acc.: 96.88%] [G loss: 1.588405]\n",
      "epoch:16 step:15847 [D loss: 0.494650, acc.: 78.12%] [G loss: 1.211802]\n",
      "epoch:16 step:15848 [D loss: 0.670115, acc.: 62.50%] [G loss: 1.022641]\n",
      "epoch:16 step:15849 [D loss: 0.501404, acc.: 78.91%] [G loss: 1.155524]\n",
      "epoch:16 step:15850 [D loss: 0.867978, acc.: 40.62%] [G loss: 0.986407]\n",
      "epoch:16 step:15851 [D loss: 0.646484, acc.: 65.62%] [G loss: 1.052682]\n",
      "epoch:16 step:15852 [D loss: 0.622995, acc.: 63.28%] [G loss: 1.256141]\n",
      "epoch:16 step:15853 [D loss: 0.586145, acc.: 71.88%] [G loss: 1.234636]\n",
      "epoch:16 step:15854 [D loss: 0.704599, acc.: 55.47%] [G loss: 0.881885]\n",
      "epoch:16 step:15855 [D loss: 0.594518, acc.: 72.66%] [G loss: 0.931354]\n",
      "epoch:16 step:15856 [D loss: 0.709299, acc.: 53.91%] [G loss: 0.883294]\n",
      "epoch:16 step:15857 [D loss: 0.631274, acc.: 64.06%] [G loss: 1.070575]\n",
      "epoch:16 step:15858 [D loss: 0.591230, acc.: 71.09%] [G loss: 1.047697]\n",
      "epoch:16 step:15859 [D loss: 0.573716, acc.: 71.09%] [G loss: 1.119810]\n",
      "epoch:16 step:15860 [D loss: 0.671720, acc.: 63.28%] [G loss: 0.940388]\n",
      "epoch:16 step:15861 [D loss: 0.631042, acc.: 65.62%] [G loss: 0.873477]\n",
      "epoch:16 step:15862 [D loss: 0.647195, acc.: 64.06%] [G loss: 0.916345]\n",
      "epoch:16 step:15863 [D loss: 0.649394, acc.: 60.16%] [G loss: 0.992773]\n",
      "epoch:16 step:15864 [D loss: 0.645219, acc.: 68.75%] [G loss: 1.046101]\n",
      "epoch:16 step:15865 [D loss: 0.711025, acc.: 52.34%] [G loss: 0.896818]\n",
      "epoch:16 step:15866 [D loss: 0.676798, acc.: 56.25%] [G loss: 1.069740]\n",
      "epoch:16 step:15867 [D loss: 0.750224, acc.: 53.91%] [G loss: 0.914874]\n",
      "epoch:16 step:15868 [D loss: 0.660139, acc.: 65.62%] [G loss: 0.956094]\n",
      "epoch:16 step:15869 [D loss: 0.619663, acc.: 67.19%] [G loss: 0.875792]\n",
      "epoch:16 step:15870 [D loss: 0.436449, acc.: 84.38%] [G loss: 1.060182]\n",
      "epoch:16 step:15871 [D loss: 0.615853, acc.: 65.62%] [G loss: 1.161640]\n",
      "epoch:16 step:15872 [D loss: 0.784457, acc.: 42.97%] [G loss: 0.951521]\n",
      "epoch:16 step:15873 [D loss: 0.729435, acc.: 53.12%] [G loss: 0.970166]\n",
      "epoch:16 step:15874 [D loss: 0.694794, acc.: 55.47%] [G loss: 1.017509]\n",
      "epoch:16 step:15875 [D loss: 0.565780, acc.: 69.53%] [G loss: 0.955876]\n",
      "epoch:16 step:15876 [D loss: 0.467263, acc.: 82.81%] [G loss: 1.137727]\n",
      "epoch:16 step:15877 [D loss: 0.486767, acc.: 81.25%] [G loss: 1.191661]\n",
      "epoch:16 step:15878 [D loss: 0.550750, acc.: 73.44%] [G loss: 0.892601]\n",
      "epoch:16 step:15879 [D loss: 0.444171, acc.: 80.47%] [G loss: 1.122888]\n",
      "epoch:16 step:15880 [D loss: 0.529540, acc.: 78.12%] [G loss: 1.246937]\n",
      "epoch:16 step:15881 [D loss: 0.437436, acc.: 84.38%] [G loss: 1.238653]\n",
      "epoch:16 step:15882 [D loss: 0.541082, acc.: 78.12%] [G loss: 1.231505]\n",
      "epoch:16 step:15883 [D loss: 0.772339, acc.: 47.66%] [G loss: 0.920445]\n",
      "epoch:16 step:15884 [D loss: 0.776079, acc.: 46.88%] [G loss: 1.078706]\n",
      "epoch:16 step:15885 [D loss: 0.508145, acc.: 79.69%] [G loss: 0.944957]\n",
      "epoch:16 step:15886 [D loss: 0.613814, acc.: 63.28%] [G loss: 0.999588]\n",
      "epoch:16 step:15887 [D loss: 0.527779, acc.: 76.56%] [G loss: 1.043536]\n",
      "epoch:16 step:15888 [D loss: 0.557084, acc.: 71.88%] [G loss: 1.143554]\n",
      "epoch:16 step:15889 [D loss: 0.492717, acc.: 85.16%] [G loss: 1.075934]\n",
      "epoch:16 step:15890 [D loss: 0.331176, acc.: 93.75%] [G loss: 1.289429]\n",
      "epoch:16 step:15891 [D loss: 0.401157, acc.: 86.72%] [G loss: 1.210052]\n",
      "epoch:16 step:15892 [D loss: 0.302736, acc.: 95.31%] [G loss: 1.397462]\n",
      "epoch:16 step:15893 [D loss: 0.465135, acc.: 82.81%] [G loss: 1.375650]\n",
      "epoch:16 step:15894 [D loss: 0.725857, acc.: 55.47%] [G loss: 1.179958]\n",
      "epoch:16 step:15895 [D loss: 0.646735, acc.: 67.19%] [G loss: 0.999398]\n",
      "epoch:16 step:15896 [D loss: 0.765238, acc.: 50.78%] [G loss: 1.286898]\n",
      "epoch:16 step:15897 [D loss: 0.676268, acc.: 57.03%] [G loss: 0.948535]\n",
      "epoch:16 step:15898 [D loss: 0.660940, acc.: 60.16%] [G loss: 1.118632]\n",
      "epoch:16 step:15899 [D loss: 0.699119, acc.: 57.81%] [G loss: 0.969925]\n",
      "epoch:16 step:15900 [D loss: 0.722604, acc.: 51.56%] [G loss: 1.012526]\n",
      "epoch:16 step:15901 [D loss: 0.484644, acc.: 80.47%] [G loss: 1.039146]\n",
      "epoch:16 step:15902 [D loss: 0.509850, acc.: 76.56%] [G loss: 1.244291]\n",
      "epoch:16 step:15903 [D loss: 0.425353, acc.: 89.84%] [G loss: 1.187995]\n",
      "epoch:16 step:15904 [D loss: 0.327950, acc.: 85.16%] [G loss: 1.198113]\n",
      "epoch:16 step:15905 [D loss: 0.905514, acc.: 42.97%] [G loss: 1.017892]\n",
      "epoch:16 step:15906 [D loss: 0.727866, acc.: 53.12%] [G loss: 1.023657]\n",
      "epoch:16 step:15907 [D loss: 0.649333, acc.: 60.94%] [G loss: 1.033032]\n",
      "epoch:16 step:15908 [D loss: 0.719782, acc.: 51.56%] [G loss: 0.872026]\n",
      "epoch:16 step:15909 [D loss: 0.552395, acc.: 78.12%] [G loss: 0.984501]\n",
      "epoch:16 step:15910 [D loss: 0.573608, acc.: 72.66%] [G loss: 0.935908]\n",
      "epoch:16 step:15911 [D loss: 0.586130, acc.: 67.19%] [G loss: 1.032374]\n",
      "epoch:16 step:15912 [D loss: 0.448187, acc.: 85.16%] [G loss: 1.149600]\n",
      "epoch:16 step:15913 [D loss: 0.368226, acc.: 90.62%] [G loss: 1.244723]\n",
      "epoch:16 step:15914 [D loss: 0.680980, acc.: 55.47%] [G loss: 1.154169]\n",
      "epoch:16 step:15915 [D loss: 0.480904, acc.: 79.69%] [G loss: 1.241288]\n",
      "epoch:16 step:15916 [D loss: 0.532499, acc.: 75.78%] [G loss: 0.988657]\n",
      "epoch:16 step:15917 [D loss: 0.529850, acc.: 75.78%] [G loss: 1.047520]\n",
      "epoch:16 step:15918 [D loss: 0.432390, acc.: 85.94%] [G loss: 1.034241]\n",
      "epoch:16 step:15919 [D loss: 0.495274, acc.: 78.91%] [G loss: 1.075043]\n",
      "epoch:16 step:15920 [D loss: 0.801923, acc.: 50.00%] [G loss: 1.021406]\n",
      "epoch:16 step:15921 [D loss: 0.434612, acc.: 82.03%] [G loss: 1.283078]\n",
      "epoch:16 step:15922 [D loss: 0.605141, acc.: 66.41%] [G loss: 1.039011]\n",
      "epoch:16 step:15923 [D loss: 0.501097, acc.: 79.69%] [G loss: 1.233754]\n",
      "epoch:16 step:15924 [D loss: 0.662911, acc.: 58.59%] [G loss: 1.071598]\n",
      "epoch:16 step:15925 [D loss: 0.639520, acc.: 64.84%] [G loss: 0.893222]\n",
      "epoch:16 step:15926 [D loss: 0.583745, acc.: 69.53%] [G loss: 0.877372]\n",
      "epoch:16 step:15927 [D loss: 0.605063, acc.: 68.75%] [G loss: 1.051707]\n",
      "epoch:16 step:15928 [D loss: 0.537376, acc.: 75.00%] [G loss: 1.079484]\n",
      "epoch:16 step:15929 [D loss: 0.297910, acc.: 88.28%] [G loss: 1.160614]\n",
      "epoch:17 step:15930 [D loss: 0.698148, acc.: 53.91%] [G loss: 1.229001]\n",
      "epoch:17 step:15931 [D loss: 0.747466, acc.: 48.44%] [G loss: 0.918537]\n",
      "epoch:17 step:15932 [D loss: 0.778789, acc.: 46.88%] [G loss: 0.904480]\n",
      "epoch:17 step:15933 [D loss: 0.657920, acc.: 64.06%] [G loss: 1.030977]\n",
      "epoch:17 step:15934 [D loss: 0.726433, acc.: 50.00%] [G loss: 0.922681]\n",
      "epoch:17 step:15935 [D loss: 0.614445, acc.: 62.50%] [G loss: 1.003136]\n",
      "epoch:17 step:15936 [D loss: 0.660214, acc.: 57.81%] [G loss: 1.072151]\n",
      "epoch:17 step:15937 [D loss: 0.649981, acc.: 63.28%] [G loss: 1.049214]\n",
      "epoch:17 step:15938 [D loss: 0.661476, acc.: 59.38%] [G loss: 1.009416]\n",
      "epoch:17 step:15939 [D loss: 0.484960, acc.: 84.38%] [G loss: 1.239848]\n",
      "epoch:17 step:15940 [D loss: 0.600558, acc.: 67.97%] [G loss: 0.953123]\n",
      "epoch:17 step:15941 [D loss: 0.623297, acc.: 70.31%] [G loss: 1.151431]\n",
      "epoch:17 step:15942 [D loss: 0.693506, acc.: 51.56%] [G loss: 1.144876]\n",
      "epoch:17 step:15943 [D loss: 0.652859, acc.: 60.16%] [G loss: 0.865119]\n",
      "epoch:17 step:15944 [D loss: 0.488956, acc.: 76.56%] [G loss: 1.113438]\n",
      "epoch:17 step:15945 [D loss: 0.475156, acc.: 85.16%] [G loss: 1.009824]\n",
      "epoch:17 step:15946 [D loss: 0.706178, acc.: 55.47%] [G loss: 0.992101]\n",
      "epoch:17 step:15947 [D loss: 0.681619, acc.: 57.81%] [G loss: 1.191119]\n",
      "epoch:17 step:15948 [D loss: 0.772258, acc.: 50.78%] [G loss: 1.051045]\n",
      "epoch:17 step:15949 [D loss: 0.745068, acc.: 54.69%] [G loss: 0.902201]\n",
      "epoch:17 step:15950 [D loss: 0.730661, acc.: 51.56%] [G loss: 1.076339]\n",
      "epoch:17 step:15951 [D loss: 0.555737, acc.: 75.00%] [G loss: 1.189787]\n",
      "epoch:17 step:15952 [D loss: 0.577246, acc.: 71.88%] [G loss: 1.201647]\n",
      "epoch:17 step:15953 [D loss: 0.667393, acc.: 60.16%] [G loss: 0.958040]\n",
      "epoch:17 step:15954 [D loss: 0.577660, acc.: 67.19%] [G loss: 0.974854]\n",
      "epoch:17 step:15955 [D loss: 0.613977, acc.: 65.62%] [G loss: 1.123088]\n",
      "epoch:17 step:15956 [D loss: 0.425241, acc.: 84.38%] [G loss: 1.104334]\n",
      "epoch:17 step:15957 [D loss: 0.549801, acc.: 74.22%] [G loss: 1.293659]\n",
      "epoch:17 step:15958 [D loss: 0.540403, acc.: 75.78%] [G loss: 1.142650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:15959 [D loss: 0.504575, acc.: 75.78%] [G loss: 1.383822]\n",
      "epoch:17 step:15960 [D loss: 0.424237, acc.: 82.81%] [G loss: 1.415541]\n",
      "epoch:17 step:15961 [D loss: 0.366733, acc.: 91.41%] [G loss: 1.374973]\n",
      "epoch:17 step:15962 [D loss: 0.495878, acc.: 76.56%] [G loss: 1.020436]\n",
      "epoch:17 step:15963 [D loss: 0.555553, acc.: 75.00%] [G loss: 1.211021]\n",
      "epoch:17 step:15964 [D loss: 0.363973, acc.: 90.62%] [G loss: 1.549882]\n",
      "epoch:17 step:15965 [D loss: 0.291803, acc.: 93.75%] [G loss: 1.569117]\n",
      "epoch:17 step:15966 [D loss: 0.875241, acc.: 50.78%] [G loss: 1.191129]\n",
      "epoch:17 step:15967 [D loss: 0.989660, acc.: 32.03%] [G loss: 0.929052]\n",
      "epoch:17 step:15968 [D loss: 0.718668, acc.: 51.56%] [G loss: 1.202483]\n",
      "epoch:17 step:15969 [D loss: 0.560592, acc.: 73.44%] [G loss: 1.359561]\n",
      "epoch:17 step:15970 [D loss: 0.624409, acc.: 64.06%] [G loss: 1.130768]\n",
      "epoch:17 step:15971 [D loss: 0.566445, acc.: 72.66%] [G loss: 1.081363]\n",
      "epoch:17 step:15972 [D loss: 0.592308, acc.: 66.41%] [G loss: 0.899387]\n",
      "epoch:17 step:15973 [D loss: 0.710487, acc.: 53.12%] [G loss: 1.055201]\n",
      "epoch:17 step:15974 [D loss: 0.797130, acc.: 39.84%] [G loss: 0.902784]\n",
      "epoch:17 step:15975 [D loss: 0.703434, acc.: 53.91%] [G loss: 0.841161]\n",
      "epoch:17 step:15976 [D loss: 0.643690, acc.: 58.59%] [G loss: 0.929775]\n",
      "epoch:17 step:15977 [D loss: 0.574046, acc.: 70.31%] [G loss: 1.078120]\n",
      "epoch:17 step:15978 [D loss: 0.468356, acc.: 82.81%] [G loss: 1.070763]\n",
      "epoch:17 step:15979 [D loss: 0.379252, acc.: 93.75%] [G loss: 1.305336]\n",
      "epoch:17 step:15980 [D loss: 0.623833, acc.: 63.28%] [G loss: 0.816467]\n",
      "epoch:17 step:15981 [D loss: 0.644740, acc.: 64.84%] [G loss: 0.995777]\n",
      "epoch:17 step:15982 [D loss: 0.596674, acc.: 69.53%] [G loss: 1.041949]\n",
      "epoch:17 step:15983 [D loss: 0.616286, acc.: 64.06%] [G loss: 0.843468]\n",
      "epoch:17 step:15984 [D loss: 0.479097, acc.: 79.69%] [G loss: 1.301704]\n",
      "epoch:17 step:15985 [D loss: 0.628448, acc.: 64.06%] [G loss: 1.001597]\n",
      "epoch:17 step:15986 [D loss: 0.885701, acc.: 33.59%] [G loss: 0.834577]\n",
      "epoch:17 step:15987 [D loss: 0.639549, acc.: 61.72%] [G loss: 1.173988]\n",
      "epoch:17 step:15988 [D loss: 0.703295, acc.: 57.03%] [G loss: 0.971542]\n",
      "epoch:17 step:15989 [D loss: 0.703578, acc.: 54.69%] [G loss: 0.840832]\n",
      "epoch:17 step:15990 [D loss: 0.685087, acc.: 57.81%] [G loss: 1.314357]\n",
      "epoch:17 step:15991 [D loss: 0.713792, acc.: 55.47%] [G loss: 0.754774]\n",
      "epoch:17 step:15992 [D loss: 0.690433, acc.: 59.38%] [G loss: 0.957368]\n",
      "epoch:17 step:15993 [D loss: 0.607337, acc.: 64.84%] [G loss: 0.970901]\n",
      "epoch:17 step:15994 [D loss: 0.673669, acc.: 59.38%] [G loss: 0.858389]\n",
      "epoch:17 step:15995 [D loss: 0.739607, acc.: 53.91%] [G loss: 1.128247]\n",
      "epoch:17 step:15996 [D loss: 0.610362, acc.: 70.31%] [G loss: 1.024859]\n",
      "epoch:17 step:15997 [D loss: 0.714702, acc.: 54.69%] [G loss: 0.969240]\n",
      "epoch:17 step:15998 [D loss: 0.521756, acc.: 78.12%] [G loss: 1.259669]\n",
      "epoch:17 step:15999 [D loss: 0.758439, acc.: 48.44%] [G loss: 1.064385]\n",
      "epoch:17 step:16000 [D loss: 0.565268, acc.: 71.09%] [G loss: 1.126780]\n",
      "epoch:17 step:16001 [D loss: 0.578781, acc.: 69.53%] [G loss: 1.519303]\n",
      "epoch:17 step:16002 [D loss: 0.683791, acc.: 54.69%] [G loss: 1.066396]\n",
      "epoch:17 step:16003 [D loss: 0.545901, acc.: 75.00%] [G loss: 1.185373]\n",
      "epoch:17 step:16004 [D loss: 0.304611, acc.: 93.75%] [G loss: 1.424974]\n",
      "epoch:17 step:16005 [D loss: 0.383893, acc.: 89.06%] [G loss: 1.459292]\n",
      "epoch:17 step:16006 [D loss: 0.494743, acc.: 75.78%] [G loss: 1.500905]\n",
      "epoch:17 step:16007 [D loss: 0.727965, acc.: 62.50%] [G loss: 1.245874]\n",
      "epoch:17 step:16008 [D loss: 0.729709, acc.: 53.91%] [G loss: 0.918105]\n",
      "epoch:17 step:16009 [D loss: 0.723872, acc.: 53.91%] [G loss: 1.139907]\n",
      "epoch:17 step:16010 [D loss: 0.783995, acc.: 46.09%] [G loss: 0.935058]\n",
      "epoch:17 step:16011 [D loss: 0.598276, acc.: 67.19%] [G loss: 0.920223]\n",
      "epoch:17 step:16012 [D loss: 0.646674, acc.: 64.06%] [G loss: 0.953260]\n",
      "epoch:17 step:16013 [D loss: 0.646766, acc.: 63.28%] [G loss: 0.948126]\n",
      "epoch:17 step:16014 [D loss: 0.583297, acc.: 70.31%] [G loss: 0.999146]\n",
      "epoch:17 step:16015 [D loss: 0.659524, acc.: 62.50%] [G loss: 0.958432]\n",
      "epoch:17 step:16016 [D loss: 0.567687, acc.: 71.09%] [G loss: 0.999821]\n",
      "epoch:17 step:16017 [D loss: 0.736942, acc.: 53.91%] [G loss: 0.992224]\n",
      "epoch:17 step:16018 [D loss: 0.654377, acc.: 63.28%] [G loss: 0.978157]\n",
      "epoch:17 step:16019 [D loss: 0.595007, acc.: 69.53%] [G loss: 1.102605]\n",
      "epoch:17 step:16020 [D loss: 0.789317, acc.: 43.75%] [G loss: 0.995800]\n",
      "epoch:17 step:16021 [D loss: 0.594893, acc.: 67.97%] [G loss: 0.997033]\n",
      "epoch:17 step:16022 [D loss: 0.745485, acc.: 46.09%] [G loss: 0.899982]\n",
      "epoch:17 step:16023 [D loss: 0.670335, acc.: 58.59%] [G loss: 1.161922]\n",
      "epoch:17 step:16024 [D loss: 0.712470, acc.: 53.12%] [G loss: 1.070458]\n",
      "epoch:17 step:16025 [D loss: 0.644144, acc.: 64.84%] [G loss: 1.123721]\n",
      "epoch:17 step:16026 [D loss: 0.673485, acc.: 57.03%] [G loss: 0.956489]\n",
      "epoch:17 step:16027 [D loss: 0.756792, acc.: 46.88%] [G loss: 0.983552]\n",
      "epoch:17 step:16028 [D loss: 0.599559, acc.: 67.97%] [G loss: 1.070631]\n",
      "epoch:17 step:16029 [D loss: 0.510435, acc.: 81.25%] [G loss: 1.012887]\n",
      "epoch:17 step:16030 [D loss: 0.594560, acc.: 70.31%] [G loss: 1.023358]\n",
      "epoch:17 step:16031 [D loss: 0.728527, acc.: 53.12%] [G loss: 0.938970]\n",
      "epoch:17 step:16032 [D loss: 0.556199, acc.: 71.88%] [G loss: 0.985213]\n",
      "epoch:17 step:16033 [D loss: 0.614643, acc.: 64.06%] [G loss: 0.992040]\n",
      "epoch:17 step:16034 [D loss: 0.658251, acc.: 56.25%] [G loss: 1.142286]\n",
      "epoch:17 step:16035 [D loss: 0.504947, acc.: 74.22%] [G loss: 1.197693]\n",
      "epoch:17 step:16036 [D loss: 0.660630, acc.: 59.38%] [G loss: 1.051995]\n",
      "epoch:17 step:16037 [D loss: 0.638224, acc.: 67.97%] [G loss: 1.084002]\n",
      "epoch:17 step:16038 [D loss: 0.566582, acc.: 70.31%] [G loss: 1.088937]\n",
      "epoch:17 step:16039 [D loss: 0.577122, acc.: 71.88%] [G loss: 1.066038]\n",
      "epoch:17 step:16040 [D loss: 0.694252, acc.: 57.81%] [G loss: 1.002209]\n",
      "epoch:17 step:16041 [D loss: 0.554237, acc.: 71.09%] [G loss: 1.069286]\n",
      "epoch:17 step:16042 [D loss: 0.831259, acc.: 43.75%] [G loss: 0.859859]\n",
      "epoch:17 step:16043 [D loss: 0.751343, acc.: 48.44%] [G loss: 0.990120]\n",
      "epoch:17 step:16044 [D loss: 0.760300, acc.: 48.44%] [G loss: 0.923410]\n",
      "epoch:17 step:16045 [D loss: 0.710965, acc.: 50.00%] [G loss: 1.030827]\n",
      "epoch:17 step:16046 [D loss: 0.518236, acc.: 75.78%] [G loss: 0.938501]\n",
      "epoch:17 step:16047 [D loss: 0.618412, acc.: 66.41%] [G loss: 1.047209]\n",
      "epoch:17 step:16048 [D loss: 0.578522, acc.: 72.66%] [G loss: 1.022440]\n",
      "epoch:17 step:16049 [D loss: 0.803947, acc.: 42.19%] [G loss: 0.962922]\n",
      "epoch:17 step:16050 [D loss: 0.562467, acc.: 70.31%] [G loss: 1.261710]\n",
      "epoch:17 step:16051 [D loss: 0.347729, acc.: 95.31%] [G loss: 1.346277]\n",
      "epoch:17 step:16052 [D loss: 0.597976, acc.: 67.97%] [G loss: 1.104049]\n",
      "epoch:17 step:16053 [D loss: 0.660816, acc.: 64.84%] [G loss: 1.153979]\n",
      "epoch:17 step:16054 [D loss: 0.755810, acc.: 49.22%] [G loss: 0.923393]\n",
      "epoch:17 step:16055 [D loss: 0.720238, acc.: 54.69%] [G loss: 0.975843]\n",
      "epoch:17 step:16056 [D loss: 0.624382, acc.: 64.06%] [G loss: 0.978007]\n",
      "epoch:17 step:16057 [D loss: 0.637038, acc.: 62.50%] [G loss: 0.908864]\n",
      "epoch:17 step:16058 [D loss: 0.558513, acc.: 71.09%] [G loss: 0.954562]\n",
      "epoch:17 step:16059 [D loss: 0.435593, acc.: 78.91%] [G loss: 0.953958]\n",
      "epoch:17 step:16060 [D loss: 0.399910, acc.: 89.06%] [G loss: 1.126610]\n",
      "epoch:17 step:16061 [D loss: 0.532648, acc.: 77.34%] [G loss: 1.185951]\n",
      "epoch:17 step:16062 [D loss: 0.892327, acc.: 40.62%] [G loss: 1.108737]\n",
      "epoch:17 step:16063 [D loss: 0.681182, acc.: 57.81%] [G loss: 1.159058]\n",
      "epoch:17 step:16064 [D loss: 0.632763, acc.: 64.06%] [G loss: 1.126792]\n",
      "epoch:17 step:16065 [D loss: 0.690289, acc.: 50.78%] [G loss: 1.053477]\n",
      "epoch:17 step:16066 [D loss: 0.653087, acc.: 65.62%] [G loss: 0.852248]\n",
      "epoch:17 step:16067 [D loss: 0.517281, acc.: 80.47%] [G loss: 1.086628]\n",
      "epoch:17 step:16068 [D loss: 0.423119, acc.: 82.03%] [G loss: 1.376246]\n",
      "epoch:17 step:16069 [D loss: 0.727621, acc.: 55.47%] [G loss: 0.961653]\n",
      "epoch:17 step:16070 [D loss: 0.764585, acc.: 41.41%] [G loss: 0.987007]\n",
      "epoch:17 step:16071 [D loss: 0.606304, acc.: 68.75%] [G loss: 1.374481]\n",
      "epoch:17 step:16072 [D loss: 0.679843, acc.: 60.94%] [G loss: 1.014963]\n",
      "epoch:17 step:16073 [D loss: 0.561473, acc.: 75.00%] [G loss: 1.084296]\n",
      "epoch:17 step:16074 [D loss: 0.503512, acc.: 78.91%] [G loss: 1.121851]\n",
      "epoch:17 step:16075 [D loss: 0.567128, acc.: 69.53%] [G loss: 0.840719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16076 [D loss: 0.635894, acc.: 64.06%] [G loss: 1.192623]\n",
      "epoch:17 step:16077 [D loss: 0.691623, acc.: 58.59%] [G loss: 0.960997]\n",
      "epoch:17 step:16078 [D loss: 0.622045, acc.: 67.97%] [G loss: 1.018579]\n",
      "epoch:17 step:16079 [D loss: 0.540719, acc.: 71.09%] [G loss: 0.982140]\n",
      "epoch:17 step:16080 [D loss: 0.464496, acc.: 81.25%] [G loss: 1.326483]\n",
      "epoch:17 step:16081 [D loss: 0.462178, acc.: 80.47%] [G loss: 1.200339]\n",
      "epoch:17 step:16082 [D loss: 0.825754, acc.: 49.22%] [G loss: 1.075734]\n",
      "epoch:17 step:16083 [D loss: 0.699019, acc.: 50.78%] [G loss: 0.837488]\n",
      "epoch:17 step:16084 [D loss: 0.702752, acc.: 56.25%] [G loss: 1.051744]\n",
      "epoch:17 step:16085 [D loss: 0.611815, acc.: 63.28%] [G loss: 1.161002]\n",
      "epoch:17 step:16086 [D loss: 0.665953, acc.: 57.81%] [G loss: 0.889374]\n",
      "epoch:17 step:16087 [D loss: 0.679736, acc.: 52.34%] [G loss: 1.056372]\n",
      "epoch:17 step:16088 [D loss: 0.577477, acc.: 73.44%] [G loss: 1.031501]\n",
      "epoch:17 step:16089 [D loss: 0.861737, acc.: 36.72%] [G loss: 0.943711]\n",
      "epoch:17 step:16090 [D loss: 0.690059, acc.: 60.94%] [G loss: 1.250191]\n",
      "epoch:17 step:16091 [D loss: 0.588533, acc.: 64.06%] [G loss: 0.981780]\n",
      "epoch:17 step:16092 [D loss: 0.656095, acc.: 58.59%] [G loss: 1.158509]\n",
      "epoch:17 step:16093 [D loss: 0.705566, acc.: 56.25%] [G loss: 0.688838]\n",
      "epoch:17 step:16094 [D loss: 0.654333, acc.: 59.38%] [G loss: 0.914040]\n",
      "epoch:17 step:16095 [D loss: 0.542270, acc.: 74.22%] [G loss: 1.080292]\n",
      "epoch:17 step:16096 [D loss: 0.641026, acc.: 63.28%] [G loss: 0.906642]\n",
      "epoch:17 step:16097 [D loss: 0.495669, acc.: 79.69%] [G loss: 1.038789]\n",
      "epoch:17 step:16098 [D loss: 0.611646, acc.: 65.62%] [G loss: 0.904438]\n",
      "epoch:17 step:16099 [D loss: 0.660774, acc.: 60.16%] [G loss: 1.061476]\n",
      "epoch:17 step:16100 [D loss: 0.610562, acc.: 61.72%] [G loss: 0.961905]\n",
      "epoch:17 step:16101 [D loss: 0.628818, acc.: 62.50%] [G loss: 0.917203]\n",
      "epoch:17 step:16102 [D loss: 0.630526, acc.: 62.50%] [G loss: 1.030127]\n",
      "epoch:17 step:16103 [D loss: 0.694145, acc.: 57.81%] [G loss: 1.052783]\n",
      "epoch:17 step:16104 [D loss: 0.646447, acc.: 60.94%] [G loss: 1.047968]\n",
      "epoch:17 step:16105 [D loss: 0.685466, acc.: 58.59%] [G loss: 1.023757]\n",
      "epoch:17 step:16106 [D loss: 0.776902, acc.: 50.00%] [G loss: 0.781021]\n",
      "epoch:17 step:16107 [D loss: 0.857918, acc.: 39.84%] [G loss: 0.795542]\n",
      "epoch:17 step:16108 [D loss: 0.658071, acc.: 64.06%] [G loss: 1.253843]\n",
      "epoch:17 step:16109 [D loss: 0.584645, acc.: 74.22%] [G loss: 1.158738]\n",
      "epoch:17 step:16110 [D loss: 0.771676, acc.: 51.56%] [G loss: 0.982887]\n",
      "epoch:17 step:16111 [D loss: 0.635038, acc.: 58.59%] [G loss: 1.114782]\n",
      "epoch:17 step:16112 [D loss: 0.618947, acc.: 64.84%] [G loss: 1.244023]\n",
      "epoch:17 step:16113 [D loss: 0.696915, acc.: 54.69%] [G loss: 0.962186]\n",
      "epoch:17 step:16114 [D loss: 0.719195, acc.: 53.12%] [G loss: 1.119537]\n",
      "epoch:17 step:16115 [D loss: 0.683176, acc.: 51.56%] [G loss: 1.223917]\n",
      "epoch:17 step:16116 [D loss: 0.634443, acc.: 63.28%] [G loss: 1.224320]\n",
      "epoch:17 step:16117 [D loss: 0.676029, acc.: 59.38%] [G loss: 0.925933]\n",
      "epoch:17 step:16118 [D loss: 0.799792, acc.: 44.53%] [G loss: 1.056298]\n",
      "epoch:17 step:16119 [D loss: 0.580356, acc.: 75.78%] [G loss: 1.094557]\n",
      "epoch:17 step:16120 [D loss: 0.642796, acc.: 63.28%] [G loss: 1.007613]\n",
      "epoch:17 step:16121 [D loss: 0.605687, acc.: 66.41%] [G loss: 0.938916]\n",
      "epoch:17 step:16122 [D loss: 0.607102, acc.: 69.53%] [G loss: 1.190153]\n",
      "epoch:17 step:16123 [D loss: 0.611333, acc.: 70.31%] [G loss: 1.011835]\n",
      "epoch:17 step:16124 [D loss: 0.615883, acc.: 64.06%] [G loss: 1.171824]\n",
      "epoch:17 step:16125 [D loss: 0.807007, acc.: 43.75%] [G loss: 0.774095]\n",
      "epoch:17 step:16126 [D loss: 0.580558, acc.: 72.66%] [G loss: 1.187556]\n",
      "epoch:17 step:16127 [D loss: 0.830374, acc.: 39.06%] [G loss: 0.808186]\n",
      "epoch:17 step:16128 [D loss: 0.707833, acc.: 56.25%] [G loss: 1.057266]\n",
      "epoch:17 step:16129 [D loss: 0.639605, acc.: 63.28%] [G loss: 0.987027]\n",
      "epoch:17 step:16130 [D loss: 0.515929, acc.: 74.22%] [G loss: 1.037820]\n",
      "epoch:17 step:16131 [D loss: 0.690616, acc.: 62.50%] [G loss: 1.174745]\n",
      "epoch:17 step:16132 [D loss: 0.750306, acc.: 47.66%] [G loss: 0.912939]\n",
      "epoch:17 step:16133 [D loss: 0.798181, acc.: 44.53%] [G loss: 0.889418]\n",
      "epoch:17 step:16134 [D loss: 0.671692, acc.: 50.78%] [G loss: 0.842858]\n",
      "epoch:17 step:16135 [D loss: 0.665530, acc.: 57.03%] [G loss: 0.930893]\n",
      "epoch:17 step:16136 [D loss: 0.536388, acc.: 75.00%] [G loss: 1.083599]\n",
      "epoch:17 step:16137 [D loss: 0.706692, acc.: 50.78%] [G loss: 1.166674]\n",
      "epoch:17 step:16138 [D loss: 0.528195, acc.: 74.22%] [G loss: 0.928657]\n",
      "epoch:17 step:16139 [D loss: 0.581756, acc.: 71.09%] [G loss: 0.962850]\n",
      "epoch:17 step:16140 [D loss: 0.565244, acc.: 74.22%] [G loss: 0.885504]\n",
      "epoch:17 step:16141 [D loss: 0.669740, acc.: 56.25%] [G loss: 1.126972]\n",
      "epoch:17 step:16142 [D loss: 0.569776, acc.: 71.09%] [G loss: 0.930385]\n",
      "epoch:17 step:16143 [D loss: 0.656035, acc.: 61.72%] [G loss: 1.103019]\n",
      "epoch:17 step:16144 [D loss: 0.496105, acc.: 76.56%] [G loss: 1.135037]\n",
      "epoch:17 step:16145 [D loss: 0.767317, acc.: 50.00%] [G loss: 1.034459]\n",
      "epoch:17 step:16146 [D loss: 0.773243, acc.: 55.47%] [G loss: 1.084228]\n",
      "epoch:17 step:16147 [D loss: 0.629889, acc.: 64.84%] [G loss: 1.104746]\n",
      "epoch:17 step:16148 [D loss: 0.594695, acc.: 72.66%] [G loss: 1.041525]\n",
      "epoch:17 step:16149 [D loss: 0.340906, acc.: 92.97%] [G loss: 1.280302]\n",
      "epoch:17 step:16150 [D loss: 0.456210, acc.: 78.91%] [G loss: 1.119304]\n",
      "epoch:17 step:16151 [D loss: 0.462665, acc.: 83.59%] [G loss: 1.071771]\n",
      "epoch:17 step:16152 [D loss: 0.324256, acc.: 93.75%] [G loss: 1.519722]\n",
      "epoch:17 step:16153 [D loss: 0.821094, acc.: 47.66%] [G loss: 0.939446]\n",
      "epoch:17 step:16154 [D loss: 0.751732, acc.: 50.78%] [G loss: 1.052269]\n",
      "epoch:17 step:16155 [D loss: 0.689986, acc.: 63.28%] [G loss: 0.914925]\n",
      "epoch:17 step:16156 [D loss: 0.672301, acc.: 61.72%] [G loss: 0.882575]\n",
      "epoch:17 step:16157 [D loss: 0.768667, acc.: 47.66%] [G loss: 1.012067]\n",
      "epoch:17 step:16158 [D loss: 0.639625, acc.: 64.06%] [G loss: 1.060488]\n",
      "epoch:17 step:16159 [D loss: 0.343245, acc.: 92.19%] [G loss: 1.207848]\n",
      "epoch:17 step:16160 [D loss: 0.483694, acc.: 80.47%] [G loss: 0.976272]\n",
      "epoch:17 step:16161 [D loss: 0.514995, acc.: 71.88%] [G loss: 1.098059]\n",
      "epoch:17 step:16162 [D loss: 0.845029, acc.: 46.88%] [G loss: 1.190600]\n",
      "epoch:17 step:16163 [D loss: 0.895502, acc.: 39.06%] [G loss: 1.146111]\n",
      "epoch:17 step:16164 [D loss: 0.672254, acc.: 59.38%] [G loss: 1.059268]\n",
      "epoch:17 step:16165 [D loss: 0.763056, acc.: 49.22%] [G loss: 0.946905]\n",
      "epoch:17 step:16166 [D loss: 0.857483, acc.: 40.62%] [G loss: 0.717470]\n",
      "epoch:17 step:16167 [D loss: 0.703259, acc.: 54.69%] [G loss: 1.018289]\n",
      "epoch:17 step:16168 [D loss: 0.601777, acc.: 67.19%] [G loss: 1.135020]\n",
      "epoch:17 step:16169 [D loss: 0.640093, acc.: 64.06%] [G loss: 1.092338]\n",
      "epoch:17 step:16170 [D loss: 0.587547, acc.: 69.53%] [G loss: 1.195746]\n",
      "epoch:17 step:16171 [D loss: 0.599552, acc.: 72.66%] [G loss: 1.110361]\n",
      "epoch:17 step:16172 [D loss: 0.595597, acc.: 68.75%] [G loss: 1.004804]\n",
      "epoch:17 step:16173 [D loss: 0.560359, acc.: 74.22%] [G loss: 1.165551]\n",
      "epoch:17 step:16174 [D loss: 0.518128, acc.: 75.78%] [G loss: 1.257399]\n",
      "epoch:17 step:16175 [D loss: 0.470441, acc.: 84.38%] [G loss: 1.058813]\n",
      "epoch:17 step:16176 [D loss: 0.600631, acc.: 71.09%] [G loss: 1.108987]\n",
      "epoch:17 step:16177 [D loss: 0.570464, acc.: 74.22%] [G loss: 1.020782]\n",
      "epoch:17 step:16178 [D loss: 0.669421, acc.: 53.12%] [G loss: 1.004092]\n",
      "epoch:17 step:16179 [D loss: 0.643904, acc.: 64.06%] [G loss: 1.040621]\n",
      "epoch:17 step:16180 [D loss: 0.535950, acc.: 72.66%] [G loss: 1.250957]\n",
      "epoch:17 step:16181 [D loss: 0.685369, acc.: 56.25%] [G loss: 1.026389]\n",
      "epoch:17 step:16182 [D loss: 0.540013, acc.: 76.56%] [G loss: 1.094940]\n",
      "epoch:17 step:16183 [D loss: 0.644876, acc.: 60.16%] [G loss: 0.910719]\n",
      "epoch:17 step:16184 [D loss: 0.640731, acc.: 64.84%] [G loss: 0.992243]\n",
      "epoch:17 step:16185 [D loss: 0.703123, acc.: 53.12%] [G loss: 0.907645]\n",
      "epoch:17 step:16186 [D loss: 0.707335, acc.: 58.59%] [G loss: 1.032993]\n",
      "epoch:17 step:16187 [D loss: 0.619991, acc.: 65.62%] [G loss: 0.950405]\n",
      "epoch:17 step:16188 [D loss: 0.487988, acc.: 80.47%] [G loss: 1.068634]\n",
      "epoch:17 step:16189 [D loss: 0.547377, acc.: 75.00%] [G loss: 1.160419]\n",
      "epoch:17 step:16190 [D loss: 0.473059, acc.: 81.25%] [G loss: 1.171444]\n",
      "epoch:17 step:16191 [D loss: 0.566439, acc.: 71.88%] [G loss: 0.989044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16192 [D loss: 0.741849, acc.: 52.34%] [G loss: 1.019220]\n",
      "epoch:17 step:16193 [D loss: 0.550827, acc.: 72.66%] [G loss: 0.934222]\n",
      "epoch:17 step:16194 [D loss: 0.596837, acc.: 67.97%] [G loss: 1.125440]\n",
      "epoch:17 step:16195 [D loss: 0.688718, acc.: 57.03%] [G loss: 1.087171]\n",
      "epoch:17 step:16196 [D loss: 0.529126, acc.: 74.22%] [G loss: 1.065566]\n",
      "epoch:17 step:16197 [D loss: 0.618494, acc.: 67.97%] [G loss: 1.136014]\n",
      "epoch:17 step:16198 [D loss: 0.708155, acc.: 49.22%] [G loss: 0.930292]\n",
      "epoch:17 step:16199 [D loss: 0.793176, acc.: 46.88%] [G loss: 0.805008]\n",
      "epoch:17 step:16200 [D loss: 0.735587, acc.: 53.91%] [G loss: 0.943686]\n",
      "epoch:17 step:16201 [D loss: 0.504193, acc.: 77.34%] [G loss: 1.193627]\n",
      "epoch:17 step:16202 [D loss: 0.537012, acc.: 74.22%] [G loss: 1.000878]\n",
      "epoch:17 step:16203 [D loss: 0.745401, acc.: 48.44%] [G loss: 0.938022]\n",
      "epoch:17 step:16204 [D loss: 0.657188, acc.: 62.50%] [G loss: 0.951183]\n",
      "epoch:17 step:16205 [D loss: 0.702461, acc.: 58.59%] [G loss: 1.012344]\n",
      "epoch:17 step:16206 [D loss: 0.633888, acc.: 62.50%] [G loss: 0.956660]\n",
      "epoch:17 step:16207 [D loss: 0.508764, acc.: 80.47%] [G loss: 0.999652]\n",
      "epoch:17 step:16208 [D loss: 0.497005, acc.: 79.69%] [G loss: 1.001829]\n",
      "epoch:17 step:16209 [D loss: 0.536606, acc.: 72.66%] [G loss: 1.065490]\n",
      "epoch:17 step:16210 [D loss: 0.659652, acc.: 64.06%] [G loss: 1.281866]\n",
      "epoch:17 step:16211 [D loss: 0.650257, acc.: 62.50%] [G loss: 1.063566]\n",
      "epoch:17 step:16212 [D loss: 0.622795, acc.: 65.62%] [G loss: 1.168430]\n",
      "epoch:17 step:16213 [D loss: 0.553095, acc.: 74.22%] [G loss: 1.077020]\n",
      "epoch:17 step:16214 [D loss: 0.478755, acc.: 85.94%] [G loss: 1.165049]\n",
      "epoch:17 step:16215 [D loss: 0.454102, acc.: 83.59%] [G loss: 1.343516]\n",
      "epoch:17 step:16216 [D loss: 0.576501, acc.: 72.66%] [G loss: 1.025912]\n",
      "epoch:17 step:16217 [D loss: 0.583265, acc.: 71.09%] [G loss: 1.143770]\n",
      "epoch:17 step:16218 [D loss: 0.538958, acc.: 74.22%] [G loss: 1.126639]\n",
      "epoch:17 step:16219 [D loss: 0.651858, acc.: 59.38%] [G loss: 1.215917]\n",
      "epoch:17 step:16220 [D loss: 0.494655, acc.: 83.59%] [G loss: 1.087916]\n",
      "epoch:17 step:16221 [D loss: 0.549972, acc.: 76.56%] [G loss: 0.869670]\n",
      "epoch:17 step:16222 [D loss: 0.411759, acc.: 81.25%] [G loss: 1.271203]\n",
      "epoch:17 step:16223 [D loss: 0.660031, acc.: 57.03%] [G loss: 0.922322]\n",
      "epoch:17 step:16224 [D loss: 0.997067, acc.: 28.91%] [G loss: 0.764900]\n",
      "epoch:17 step:16225 [D loss: 0.685585, acc.: 58.59%] [G loss: 1.067139]\n",
      "epoch:17 step:16226 [D loss: 0.638793, acc.: 62.50%] [G loss: 1.070672]\n",
      "epoch:17 step:16227 [D loss: 0.637188, acc.: 62.50%] [G loss: 0.942599]\n",
      "epoch:17 step:16228 [D loss: 0.723325, acc.: 49.22%] [G loss: 0.917841]\n",
      "epoch:17 step:16229 [D loss: 0.565788, acc.: 71.09%] [G loss: 1.209774]\n",
      "epoch:17 step:16230 [D loss: 0.709108, acc.: 51.56%] [G loss: 1.124024]\n",
      "epoch:17 step:16231 [D loss: 0.608799, acc.: 60.16%] [G loss: 1.019315]\n",
      "epoch:17 step:16232 [D loss: 0.576644, acc.: 72.66%] [G loss: 1.167770]\n",
      "epoch:17 step:16233 [D loss: 0.634069, acc.: 65.62%] [G loss: 1.016258]\n",
      "epoch:17 step:16234 [D loss: 0.649462, acc.: 64.84%] [G loss: 0.932046]\n",
      "epoch:17 step:16235 [D loss: 0.616512, acc.: 68.75%] [G loss: 0.884566]\n",
      "epoch:17 step:16236 [D loss: 0.638014, acc.: 65.62%] [G loss: 1.023201]\n",
      "epoch:17 step:16237 [D loss: 0.696366, acc.: 53.91%] [G loss: 0.746469]\n",
      "epoch:17 step:16238 [D loss: 0.488353, acc.: 79.69%] [G loss: 1.238975]\n",
      "epoch:17 step:16239 [D loss: 0.625242, acc.: 67.97%] [G loss: 1.018979]\n",
      "epoch:17 step:16240 [D loss: 0.653744, acc.: 60.94%] [G loss: 1.004844]\n",
      "epoch:17 step:16241 [D loss: 0.369277, acc.: 89.06%] [G loss: 1.310446]\n",
      "epoch:17 step:16242 [D loss: 0.470905, acc.: 79.69%] [G loss: 1.360746]\n",
      "epoch:17 step:16243 [D loss: 0.432624, acc.: 86.72%] [G loss: 1.399572]\n",
      "epoch:17 step:16244 [D loss: 0.511555, acc.: 77.34%] [G loss: 1.406316]\n",
      "epoch:17 step:16245 [D loss: 0.714620, acc.: 58.59%] [G loss: 1.173670]\n",
      "epoch:17 step:16246 [D loss: 0.711684, acc.: 50.78%] [G loss: 1.079844]\n",
      "epoch:17 step:16247 [D loss: 0.634719, acc.: 57.81%] [G loss: 0.998126]\n",
      "epoch:17 step:16248 [D loss: 0.747534, acc.: 47.66%] [G loss: 1.175829]\n",
      "epoch:17 step:16249 [D loss: 0.601869, acc.: 64.06%] [G loss: 0.961224]\n",
      "epoch:17 step:16250 [D loss: 0.502260, acc.: 74.22%] [G loss: 1.191509]\n",
      "epoch:17 step:16251 [D loss: 0.610506, acc.: 63.28%] [G loss: 1.145921]\n",
      "epoch:17 step:16252 [D loss: 0.655064, acc.: 57.03%] [G loss: 1.011474]\n",
      "epoch:17 step:16253 [D loss: 0.688865, acc.: 57.81%] [G loss: 1.091631]\n",
      "epoch:17 step:16254 [D loss: 0.642140, acc.: 62.50%] [G loss: 1.152361]\n",
      "epoch:17 step:16255 [D loss: 0.649176, acc.: 60.16%] [G loss: 0.918151]\n",
      "epoch:17 step:16256 [D loss: 0.428021, acc.: 83.59%] [G loss: 1.184017]\n",
      "epoch:17 step:16257 [D loss: 0.456727, acc.: 82.81%] [G loss: 1.193204]\n",
      "epoch:17 step:16258 [D loss: 0.668383, acc.: 60.16%] [G loss: 0.940403]\n",
      "epoch:17 step:16259 [D loss: 0.650362, acc.: 62.50%] [G loss: 1.229158]\n",
      "epoch:17 step:16260 [D loss: 0.676331, acc.: 60.94%] [G loss: 1.187274]\n",
      "epoch:17 step:16261 [D loss: 0.623601, acc.: 66.41%] [G loss: 0.956832]\n",
      "epoch:17 step:16262 [D loss: 0.637955, acc.: 59.38%] [G loss: 1.162915]\n",
      "epoch:17 step:16263 [D loss: 0.697764, acc.: 57.03%] [G loss: 0.992440]\n",
      "epoch:17 step:16264 [D loss: 0.555506, acc.: 73.44%] [G loss: 1.040942]\n",
      "epoch:17 step:16265 [D loss: 0.654476, acc.: 61.72%] [G loss: 0.889945]\n",
      "epoch:17 step:16266 [D loss: 0.534600, acc.: 75.78%] [G loss: 1.270302]\n",
      "epoch:17 step:16267 [D loss: 0.612773, acc.: 67.19%] [G loss: 0.980141]\n",
      "epoch:17 step:16268 [D loss: 0.615729, acc.: 66.41%] [G loss: 1.034466]\n",
      "epoch:17 step:16269 [D loss: 0.615310, acc.: 65.62%] [G loss: 0.894503]\n",
      "epoch:17 step:16270 [D loss: 0.573736, acc.: 64.84%] [G loss: 0.954056]\n",
      "epoch:17 step:16271 [D loss: 0.505466, acc.: 75.78%] [G loss: 0.932537]\n",
      "epoch:17 step:16272 [D loss: 0.396541, acc.: 85.94%] [G loss: 1.392895]\n",
      "epoch:17 step:16273 [D loss: 0.435709, acc.: 84.38%] [G loss: 1.408356]\n",
      "epoch:17 step:16274 [D loss: 0.369697, acc.: 88.28%] [G loss: 1.433870]\n",
      "epoch:17 step:16275 [D loss: 0.260980, acc.: 94.53%] [G loss: 1.558904]\n",
      "epoch:17 step:16276 [D loss: 0.331175, acc.: 90.62%] [G loss: 1.489647]\n",
      "epoch:17 step:16277 [D loss: 0.681089, acc.: 57.81%] [G loss: 1.531403]\n",
      "epoch:17 step:16278 [D loss: 0.780072, acc.: 47.66%] [G loss: 1.047523]\n",
      "epoch:17 step:16279 [D loss: 0.838024, acc.: 39.06%] [G loss: 0.913093]\n",
      "epoch:17 step:16280 [D loss: 0.618035, acc.: 65.62%] [G loss: 1.029008]\n",
      "epoch:17 step:16281 [D loss: 0.472972, acc.: 83.59%] [G loss: 1.010250]\n",
      "epoch:17 step:16282 [D loss: 0.560104, acc.: 72.66%] [G loss: 1.064861]\n",
      "epoch:17 step:16283 [D loss: 0.637867, acc.: 59.38%] [G loss: 1.069179]\n",
      "epoch:17 step:16284 [D loss: 0.762803, acc.: 50.00%] [G loss: 1.097860]\n",
      "epoch:17 step:16285 [D loss: 0.624422, acc.: 67.97%] [G loss: 1.153602]\n",
      "epoch:17 step:16286 [D loss: 0.640587, acc.: 67.19%] [G loss: 0.822974]\n",
      "epoch:17 step:16287 [D loss: 0.468203, acc.: 83.59%] [G loss: 0.896812]\n",
      "epoch:17 step:16288 [D loss: 0.578868, acc.: 67.19%] [G loss: 0.968741]\n",
      "epoch:17 step:16289 [D loss: 0.530643, acc.: 77.34%] [G loss: 1.187552]\n",
      "epoch:17 step:16290 [D loss: 0.634853, acc.: 63.28%] [G loss: 0.977266]\n",
      "epoch:17 step:16291 [D loss: 0.724777, acc.: 53.12%] [G loss: 0.960508]\n",
      "epoch:17 step:16292 [D loss: 0.933623, acc.: 24.22%] [G loss: 1.012996]\n",
      "epoch:17 step:16293 [D loss: 0.762359, acc.: 48.44%] [G loss: 1.012288]\n",
      "epoch:17 step:16294 [D loss: 0.664476, acc.: 62.50%] [G loss: 0.963574]\n",
      "epoch:17 step:16295 [D loss: 0.523981, acc.: 72.66%] [G loss: 1.195531]\n",
      "epoch:17 step:16296 [D loss: 0.403414, acc.: 88.28%] [G loss: 1.275754]\n",
      "epoch:17 step:16297 [D loss: 0.579007, acc.: 73.44%] [G loss: 1.375606]\n",
      "epoch:17 step:16298 [D loss: 0.657523, acc.: 64.06%] [G loss: 1.205219]\n",
      "epoch:17 step:16299 [D loss: 0.592378, acc.: 69.53%] [G loss: 1.190500]\n",
      "epoch:17 step:16300 [D loss: 0.651064, acc.: 62.50%] [G loss: 0.992638]\n",
      "epoch:17 step:16301 [D loss: 0.646491, acc.: 64.06%] [G loss: 1.055855]\n",
      "epoch:17 step:16302 [D loss: 0.662759, acc.: 57.03%] [G loss: 1.081388]\n",
      "epoch:17 step:16303 [D loss: 0.645428, acc.: 62.50%] [G loss: 0.928260]\n",
      "epoch:17 step:16304 [D loss: 0.645952, acc.: 64.84%] [G loss: 0.823616]\n",
      "epoch:17 step:16305 [D loss: 0.662718, acc.: 55.47%] [G loss: 0.850237]\n",
      "epoch:17 step:16306 [D loss: 0.574130, acc.: 68.75%] [G loss: 0.976906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16307 [D loss: 0.401796, acc.: 85.94%] [G loss: 1.263786]\n",
      "epoch:17 step:16308 [D loss: 0.729088, acc.: 57.03%] [G loss: 1.171473]\n",
      "epoch:17 step:16309 [D loss: 0.589946, acc.: 68.75%] [G loss: 1.066524]\n",
      "epoch:17 step:16310 [D loss: 0.661283, acc.: 59.38%] [G loss: 1.036705]\n",
      "epoch:17 step:16311 [D loss: 0.733537, acc.: 57.03%] [G loss: 0.936163]\n",
      "epoch:17 step:16312 [D loss: 0.696696, acc.: 59.38%] [G loss: 0.937709]\n",
      "epoch:17 step:16313 [D loss: 0.585979, acc.: 71.88%] [G loss: 1.027643]\n",
      "epoch:17 step:16314 [D loss: 0.581324, acc.: 73.44%] [G loss: 1.092699]\n",
      "epoch:17 step:16315 [D loss: 0.711840, acc.: 51.56%] [G loss: 1.117763]\n",
      "epoch:17 step:16316 [D loss: 0.727232, acc.: 55.47%] [G loss: 0.812942]\n",
      "epoch:17 step:16317 [D loss: 0.731760, acc.: 54.69%] [G loss: 0.916108]\n",
      "epoch:17 step:16318 [D loss: 0.619250, acc.: 62.50%] [G loss: 0.925212]\n",
      "epoch:17 step:16319 [D loss: 0.480847, acc.: 78.12%] [G loss: 1.148260]\n",
      "epoch:17 step:16320 [D loss: 0.499065, acc.: 76.56%] [G loss: 1.064277]\n",
      "epoch:17 step:16321 [D loss: 0.673022, acc.: 60.94%] [G loss: 0.909252]\n",
      "epoch:17 step:16322 [D loss: 0.671827, acc.: 59.38%] [G loss: 1.046049]\n",
      "epoch:17 step:16323 [D loss: 0.437187, acc.: 88.28%] [G loss: 1.284589]\n",
      "epoch:17 step:16324 [D loss: 0.701901, acc.: 57.03%] [G loss: 1.097337]\n",
      "epoch:17 step:16325 [D loss: 0.436542, acc.: 77.34%] [G loss: 1.146176]\n",
      "epoch:17 step:16326 [D loss: 0.266458, acc.: 93.75%] [G loss: 1.637011]\n",
      "epoch:17 step:16327 [D loss: 0.537073, acc.: 68.75%] [G loss: 1.264199]\n",
      "epoch:17 step:16328 [D loss: 0.446855, acc.: 85.94%] [G loss: 1.576468]\n",
      "epoch:17 step:16329 [D loss: 0.378184, acc.: 85.16%] [G loss: 1.483453]\n",
      "epoch:17 step:16330 [D loss: 0.684881, acc.: 61.72%] [G loss: 1.130642]\n",
      "epoch:17 step:16331 [D loss: 0.535342, acc.: 72.66%] [G loss: 1.147892]\n",
      "epoch:17 step:16332 [D loss: 0.716073, acc.: 55.47%] [G loss: 0.872422]\n",
      "epoch:17 step:16333 [D loss: 0.401026, acc.: 92.97%] [G loss: 1.354641]\n",
      "epoch:17 step:16334 [D loss: 0.438352, acc.: 85.16%] [G loss: 1.291324]\n",
      "epoch:17 step:16335 [D loss: 0.599222, acc.: 65.62%] [G loss: 0.899660]\n",
      "epoch:17 step:16336 [D loss: 0.720709, acc.: 53.91%] [G loss: 0.883044]\n",
      "epoch:17 step:16337 [D loss: 0.916316, acc.: 35.94%] [G loss: 0.795042]\n",
      "epoch:17 step:16338 [D loss: 0.618621, acc.: 62.50%] [G loss: 1.182390]\n",
      "epoch:17 step:16339 [D loss: 0.792674, acc.: 40.62%] [G loss: 1.025050]\n",
      "epoch:17 step:16340 [D loss: 1.011911, acc.: 24.22%] [G loss: 0.864277]\n",
      "epoch:17 step:16341 [D loss: 0.802115, acc.: 44.53%] [G loss: 0.971468]\n",
      "epoch:17 step:16342 [D loss: 0.867138, acc.: 39.06%] [G loss: 0.975543]\n",
      "epoch:17 step:16343 [D loss: 0.787095, acc.: 46.88%] [G loss: 0.997700]\n",
      "epoch:17 step:16344 [D loss: 0.952232, acc.: 28.12%] [G loss: 1.074350]\n",
      "epoch:17 step:16345 [D loss: 0.597476, acc.: 66.41%] [G loss: 1.264145]\n",
      "epoch:17 step:16346 [D loss: 0.989568, acc.: 31.25%] [G loss: 0.686370]\n",
      "epoch:17 step:16347 [D loss: 0.756426, acc.: 48.44%] [G loss: 0.925919]\n",
      "epoch:17 step:16348 [D loss: 0.670982, acc.: 56.25%] [G loss: 1.057621]\n",
      "epoch:17 step:16349 [D loss: 0.855300, acc.: 39.06%] [G loss: 1.030364]\n",
      "epoch:17 step:16350 [D loss: 0.792958, acc.: 45.31%] [G loss: 1.227461]\n",
      "epoch:17 step:16351 [D loss: 0.795897, acc.: 44.53%] [G loss: 0.970426]\n",
      "epoch:17 step:16352 [D loss: 0.724665, acc.: 50.78%] [G loss: 1.264870]\n",
      "epoch:17 step:16353 [D loss: 0.702154, acc.: 55.47%] [G loss: 1.021718]\n",
      "epoch:17 step:16354 [D loss: 0.680653, acc.: 58.59%] [G loss: 1.277591]\n",
      "epoch:17 step:16355 [D loss: 0.642750, acc.: 63.28%] [G loss: 0.889264]\n",
      "epoch:17 step:16356 [D loss: 0.572478, acc.: 75.00%] [G loss: 0.984454]\n",
      "epoch:17 step:16357 [D loss: 0.499529, acc.: 79.69%] [G loss: 1.244656]\n",
      "epoch:17 step:16358 [D loss: 0.571703, acc.: 70.31%] [G loss: 1.193382]\n",
      "epoch:17 step:16359 [D loss: 0.486392, acc.: 79.69%] [G loss: 1.171156]\n",
      "epoch:17 step:16360 [D loss: 0.574761, acc.: 67.19%] [G loss: 1.213290]\n",
      "epoch:17 step:16361 [D loss: 0.612063, acc.: 64.06%] [G loss: 1.052709]\n",
      "epoch:17 step:16362 [D loss: 0.640181, acc.: 66.41%] [G loss: 1.194194]\n",
      "epoch:17 step:16363 [D loss: 0.552936, acc.: 73.44%] [G loss: 1.010858]\n",
      "epoch:17 step:16364 [D loss: 0.570975, acc.: 67.19%] [G loss: 1.035943]\n",
      "epoch:17 step:16365 [D loss: 0.466204, acc.: 85.16%] [G loss: 1.319368]\n",
      "epoch:17 step:16366 [D loss: 0.753537, acc.: 53.12%] [G loss: 1.010222]\n",
      "epoch:17 step:16367 [D loss: 0.657762, acc.: 60.94%] [G loss: 0.912430]\n",
      "epoch:17 step:16368 [D loss: 0.694570, acc.: 53.12%] [G loss: 1.157401]\n",
      "epoch:17 step:16369 [D loss: 0.697786, acc.: 55.47%] [G loss: 0.835913]\n",
      "epoch:17 step:16370 [D loss: 0.647400, acc.: 64.06%] [G loss: 1.026238]\n",
      "epoch:17 step:16371 [D loss: 0.548318, acc.: 71.88%] [G loss: 1.196078]\n",
      "epoch:17 step:16372 [D loss: 0.580486, acc.: 67.97%] [G loss: 1.158690]\n",
      "epoch:17 step:16373 [D loss: 0.634421, acc.: 62.50%] [G loss: 1.013337]\n",
      "epoch:17 step:16374 [D loss: 0.675568, acc.: 59.38%] [G loss: 1.063671]\n",
      "epoch:17 step:16375 [D loss: 0.671295, acc.: 64.06%] [G loss: 1.082550]\n",
      "epoch:17 step:16376 [D loss: 0.546361, acc.: 74.22%] [G loss: 1.035739]\n",
      "epoch:17 step:16377 [D loss: 0.633702, acc.: 60.94%] [G loss: 1.207374]\n",
      "epoch:17 step:16378 [D loss: 0.572498, acc.: 68.75%] [G loss: 1.057402]\n",
      "epoch:17 step:16379 [D loss: 0.678439, acc.: 58.59%] [G loss: 1.060738]\n",
      "epoch:17 step:16380 [D loss: 0.526645, acc.: 75.78%] [G loss: 1.461832]\n",
      "epoch:17 step:16381 [D loss: 0.448788, acc.: 82.81%] [G loss: 1.549130]\n",
      "epoch:17 step:16382 [D loss: 0.411407, acc.: 82.81%] [G loss: 1.446149]\n",
      "epoch:17 step:16383 [D loss: 0.599947, acc.: 64.06%] [G loss: 1.199615]\n",
      "epoch:17 step:16384 [D loss: 0.537290, acc.: 73.44%] [G loss: 1.379799]\n",
      "epoch:17 step:16385 [D loss: 0.605428, acc.: 70.31%] [G loss: 1.127771]\n",
      "epoch:17 step:16386 [D loss: 0.387087, acc.: 88.28%] [G loss: 1.232470]\n",
      "epoch:17 step:16387 [D loss: 0.829014, acc.: 49.22%] [G loss: 1.104887]\n",
      "epoch:17 step:16388 [D loss: 0.966691, acc.: 34.38%] [G loss: 0.799965]\n",
      "epoch:17 step:16389 [D loss: 0.839734, acc.: 39.06%] [G loss: 0.919795]\n",
      "epoch:17 step:16390 [D loss: 1.029839, acc.: 25.78%] [G loss: 0.867309]\n",
      "epoch:17 step:16391 [D loss: 0.817752, acc.: 43.75%] [G loss: 0.989935]\n",
      "epoch:17 step:16392 [D loss: 0.703443, acc.: 54.69%] [G loss: 1.017777]\n",
      "epoch:17 step:16393 [D loss: 0.545580, acc.: 70.31%] [G loss: 1.214029]\n",
      "epoch:17 step:16394 [D loss: 0.594338, acc.: 68.75%] [G loss: 1.088154]\n",
      "epoch:17 step:16395 [D loss: 0.571650, acc.: 69.53%] [G loss: 1.333096]\n",
      "epoch:17 step:16396 [D loss: 0.571821, acc.: 71.09%] [G loss: 1.444893]\n",
      "epoch:17 step:16397 [D loss: 0.577885, acc.: 64.06%] [G loss: 1.210584]\n",
      "epoch:17 step:16398 [D loss: 0.501844, acc.: 77.34%] [G loss: 1.394928]\n",
      "epoch:17 step:16399 [D loss: 0.426538, acc.: 81.25%] [G loss: 1.515813]\n",
      "epoch:17 step:16400 [D loss: 0.275929, acc.: 93.75%] [G loss: 1.684874]\n",
      "epoch:17 step:16401 [D loss: 0.459176, acc.: 81.25%] [G loss: 1.536895]\n",
      "epoch:17 step:16402 [D loss: 0.952904, acc.: 43.75%] [G loss: 1.270025]\n",
      "epoch:17 step:16403 [D loss: 0.584758, acc.: 70.31%] [G loss: 1.407735]\n",
      "epoch:17 step:16404 [D loss: 0.768319, acc.: 52.34%] [G loss: 1.252007]\n",
      "epoch:17 step:16405 [D loss: 0.750598, acc.: 52.34%] [G loss: 1.333361]\n",
      "epoch:17 step:16406 [D loss: 0.664559, acc.: 59.38%] [G loss: 1.120307]\n",
      "epoch:17 step:16407 [D loss: 0.661579, acc.: 58.59%] [G loss: 0.983629]\n",
      "epoch:17 step:16408 [D loss: 0.631194, acc.: 62.50%] [G loss: 0.937845]\n",
      "epoch:17 step:16409 [D loss: 0.774167, acc.: 50.00%] [G loss: 1.054172]\n",
      "epoch:17 step:16410 [D loss: 0.524829, acc.: 75.78%] [G loss: 1.170455]\n",
      "epoch:17 step:16411 [D loss: 0.729747, acc.: 53.91%] [G loss: 1.184448]\n",
      "epoch:17 step:16412 [D loss: 0.561060, acc.: 67.19%] [G loss: 1.278782]\n",
      "epoch:17 step:16413 [D loss: 0.494018, acc.: 81.25%] [G loss: 1.279425]\n",
      "epoch:17 step:16414 [D loss: 0.511151, acc.: 80.47%] [G loss: 1.418322]\n",
      "epoch:17 step:16415 [D loss: 0.574631, acc.: 72.66%] [G loss: 1.373793]\n",
      "epoch:17 step:16416 [D loss: 0.589190, acc.: 71.88%] [G loss: 1.212066]\n",
      "epoch:17 step:16417 [D loss: 0.556302, acc.: 74.22%] [G loss: 1.284844]\n",
      "epoch:17 step:16418 [D loss: 0.639447, acc.: 67.97%] [G loss: 0.961968]\n",
      "epoch:17 step:16419 [D loss: 0.497603, acc.: 81.25%] [G loss: 1.106685]\n",
      "epoch:17 step:16420 [D loss: 0.590531, acc.: 67.19%] [G loss: 1.052309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16421 [D loss: 0.592491, acc.: 68.75%] [G loss: 1.176901]\n",
      "epoch:17 step:16422 [D loss: 0.606112, acc.: 68.75%] [G loss: 1.094749]\n",
      "epoch:17 step:16423 [D loss: 0.663290, acc.: 61.72%] [G loss: 1.041801]\n",
      "epoch:17 step:16424 [D loss: 0.645806, acc.: 65.62%] [G loss: 1.138421]\n",
      "epoch:17 step:16425 [D loss: 0.583771, acc.: 67.97%] [G loss: 1.066496]\n",
      "epoch:17 step:16426 [D loss: 0.470536, acc.: 82.81%] [G loss: 1.269794]\n",
      "epoch:17 step:16427 [D loss: 0.355247, acc.: 92.19%] [G loss: 1.290535]\n",
      "epoch:17 step:16428 [D loss: 0.305579, acc.: 95.31%] [G loss: 1.362695]\n",
      "epoch:17 step:16429 [D loss: 0.758560, acc.: 54.69%] [G loss: 1.284466]\n",
      "epoch:17 step:16430 [D loss: 0.751179, acc.: 54.69%] [G loss: 1.149704]\n",
      "epoch:17 step:16431 [D loss: 0.740158, acc.: 55.47%] [G loss: 0.866899]\n",
      "epoch:17 step:16432 [D loss: 0.686968, acc.: 60.94%] [G loss: 0.940949]\n",
      "epoch:17 step:16433 [D loss: 0.428919, acc.: 81.25%] [G loss: 1.230000]\n",
      "epoch:17 step:16434 [D loss: 0.620611, acc.: 60.94%] [G loss: 1.114345]\n",
      "epoch:17 step:16435 [D loss: 0.646301, acc.: 67.97%] [G loss: 1.172729]\n",
      "epoch:17 step:16436 [D loss: 0.607889, acc.: 67.19%] [G loss: 1.093819]\n",
      "epoch:17 step:16437 [D loss: 0.496016, acc.: 71.88%] [G loss: 1.186422]\n",
      "epoch:17 step:16438 [D loss: 0.645474, acc.: 58.59%] [G loss: 0.945892]\n",
      "epoch:17 step:16439 [D loss: 0.773059, acc.: 45.31%] [G loss: 0.977176]\n",
      "epoch:17 step:16440 [D loss: 0.472751, acc.: 78.12%] [G loss: 1.014213]\n",
      "epoch:17 step:16441 [D loss: 0.542869, acc.: 77.34%] [G loss: 1.249565]\n",
      "epoch:17 step:16442 [D loss: 0.494890, acc.: 76.56%] [G loss: 1.282977]\n",
      "epoch:17 step:16443 [D loss: 0.455485, acc.: 83.59%] [G loss: 1.461340]\n",
      "epoch:17 step:16444 [D loss: 0.490893, acc.: 80.47%] [G loss: 1.320224]\n",
      "epoch:17 step:16445 [D loss: 0.592735, acc.: 70.31%] [G loss: 1.083778]\n",
      "epoch:17 step:16446 [D loss: 0.847928, acc.: 43.75%] [G loss: 1.049830]\n",
      "epoch:17 step:16447 [D loss: 0.623103, acc.: 60.16%] [G loss: 1.239818]\n",
      "epoch:17 step:16448 [D loss: 0.655764, acc.: 60.94%] [G loss: 1.195692]\n",
      "epoch:17 step:16449 [D loss: 0.657527, acc.: 54.69%] [G loss: 1.058274]\n",
      "epoch:17 step:16450 [D loss: 0.486318, acc.: 78.91%] [G loss: 1.345992]\n",
      "epoch:17 step:16451 [D loss: 0.508246, acc.: 76.56%] [G loss: 1.122040]\n",
      "epoch:17 step:16452 [D loss: 0.453122, acc.: 79.69%] [G loss: 1.056656]\n",
      "epoch:17 step:16453 [D loss: 0.829573, acc.: 42.97%] [G loss: 1.044381]\n",
      "epoch:17 step:16454 [D loss: 0.768412, acc.: 46.88%] [G loss: 1.071640]\n",
      "epoch:17 step:16455 [D loss: 0.616108, acc.: 67.97%] [G loss: 1.148901]\n",
      "epoch:17 step:16456 [D loss: 0.630163, acc.: 64.06%] [G loss: 1.089515]\n",
      "epoch:17 step:16457 [D loss: 0.790084, acc.: 47.66%] [G loss: 0.795404]\n",
      "epoch:17 step:16458 [D loss: 0.674929, acc.: 58.59%] [G loss: 1.059509]\n",
      "epoch:17 step:16459 [D loss: 0.606255, acc.: 69.53%] [G loss: 1.004242]\n",
      "epoch:17 step:16460 [D loss: 0.762301, acc.: 48.44%] [G loss: 0.992948]\n",
      "epoch:17 step:16461 [D loss: 0.557522, acc.: 75.00%] [G loss: 1.186693]\n",
      "epoch:17 step:16462 [D loss: 0.368288, acc.: 91.41%] [G loss: 1.202024]\n",
      "epoch:17 step:16463 [D loss: 0.472532, acc.: 81.25%] [G loss: 1.168329]\n",
      "epoch:17 step:16464 [D loss: 0.550602, acc.: 71.09%] [G loss: 1.336530]\n",
      "epoch:17 step:16465 [D loss: 0.614931, acc.: 70.31%] [G loss: 1.241445]\n",
      "epoch:17 step:16466 [D loss: 0.595975, acc.: 71.88%] [G loss: 1.216937]\n",
      "epoch:17 step:16467 [D loss: 0.545693, acc.: 71.88%] [G loss: 1.274570]\n",
      "epoch:17 step:16468 [D loss: 0.661739, acc.: 61.72%] [G loss: 1.121439]\n",
      "epoch:17 step:16469 [D loss: 0.745793, acc.: 46.09%] [G loss: 0.862173]\n",
      "epoch:17 step:16470 [D loss: 0.716734, acc.: 46.88%] [G loss: 1.131440]\n",
      "epoch:17 step:16471 [D loss: 0.612851, acc.: 64.06%] [G loss: 1.019694]\n",
      "epoch:17 step:16472 [D loss: 0.477741, acc.: 85.16%] [G loss: 1.177592]\n",
      "epoch:17 step:16473 [D loss: 0.592899, acc.: 70.31%] [G loss: 0.935172]\n",
      "epoch:17 step:16474 [D loss: 0.438533, acc.: 88.28%] [G loss: 1.300688]\n",
      "epoch:17 step:16475 [D loss: 0.393530, acc.: 89.06%] [G loss: 1.322673]\n",
      "epoch:17 step:16476 [D loss: 0.361470, acc.: 89.84%] [G loss: 1.318330]\n",
      "epoch:17 step:16477 [D loss: 0.527489, acc.: 75.78%] [G loss: 1.072886]\n",
      "epoch:17 step:16478 [D loss: 0.367613, acc.: 89.84%] [G loss: 1.253497]\n",
      "epoch:17 step:16479 [D loss: 0.444975, acc.: 82.03%] [G loss: 1.563263]\n",
      "epoch:17 step:16480 [D loss: 0.329307, acc.: 90.62%] [G loss: 1.306375]\n",
      "epoch:17 step:16481 [D loss: 0.396216, acc.: 86.72%] [G loss: 1.448653]\n",
      "epoch:17 step:16482 [D loss: 0.502104, acc.: 75.00%] [G loss: 1.215031]\n",
      "epoch:17 step:16483 [D loss: 0.410240, acc.: 83.59%] [G loss: 1.517579]\n",
      "epoch:17 step:16484 [D loss: 0.424256, acc.: 83.59%] [G loss: 1.432046]\n",
      "epoch:17 step:16485 [D loss: 0.488425, acc.: 74.22%] [G loss: 1.520409]\n",
      "epoch:17 step:16486 [D loss: 0.444400, acc.: 82.03%] [G loss: 1.758456]\n",
      "epoch:17 step:16487 [D loss: 0.499718, acc.: 78.91%] [G loss: 1.383608]\n",
      "epoch:17 step:16488 [D loss: 1.069354, acc.: 34.38%] [G loss: 1.305300]\n",
      "epoch:17 step:16489 [D loss: 0.982698, acc.: 37.50%] [G loss: 1.186888]\n",
      "epoch:17 step:16490 [D loss: 0.554148, acc.: 69.53%] [G loss: 1.553934]\n",
      "epoch:17 step:16491 [D loss: 0.743808, acc.: 52.34%] [G loss: 1.253706]\n",
      "epoch:17 step:16492 [D loss: 0.675048, acc.: 62.50%] [G loss: 1.210146]\n",
      "epoch:17 step:16493 [D loss: 0.639369, acc.: 60.16%] [G loss: 1.115632]\n",
      "epoch:17 step:16494 [D loss: 0.792982, acc.: 50.78%] [G loss: 0.922385]\n",
      "epoch:17 step:16495 [D loss: 0.485079, acc.: 81.25%] [G loss: 1.501087]\n",
      "epoch:17 step:16496 [D loss: 0.404857, acc.: 84.38%] [G loss: 1.513349]\n",
      "epoch:17 step:16497 [D loss: 0.622684, acc.: 66.41%] [G loss: 1.330500]\n",
      "epoch:17 step:16498 [D loss: 0.705975, acc.: 57.03%] [G loss: 1.239058]\n",
      "epoch:17 step:16499 [D loss: 0.719861, acc.: 50.78%] [G loss: 0.977780]\n",
      "epoch:17 step:16500 [D loss: 0.708624, acc.: 55.47%] [G loss: 0.843323]\n",
      "epoch:17 step:16501 [D loss: 0.650003, acc.: 58.59%] [G loss: 1.145371]\n",
      "epoch:17 step:16502 [D loss: 0.549964, acc.: 75.00%] [G loss: 1.267686]\n",
      "epoch:17 step:16503 [D loss: 0.499600, acc.: 81.25%] [G loss: 1.429571]\n",
      "epoch:17 step:16504 [D loss: 0.456384, acc.: 86.72%] [G loss: 1.407492]\n",
      "epoch:17 step:16505 [D loss: 0.461249, acc.: 80.47%] [G loss: 1.061145]\n",
      "epoch:17 step:16506 [D loss: 0.461614, acc.: 82.03%] [G loss: 1.284491]\n",
      "epoch:17 step:16507 [D loss: 0.402892, acc.: 87.50%] [G loss: 1.347158]\n",
      "epoch:17 step:16508 [D loss: 0.573861, acc.: 71.09%] [G loss: 1.462546]\n",
      "epoch:17 step:16509 [D loss: 0.808556, acc.: 42.19%] [G loss: 1.023543]\n",
      "epoch:17 step:16510 [D loss: 0.715784, acc.: 56.25%] [G loss: 0.796697]\n",
      "epoch:17 step:16511 [D loss: 0.751067, acc.: 50.00%] [G loss: 0.876867]\n",
      "epoch:17 step:16512 [D loss: 0.639027, acc.: 62.50%] [G loss: 1.092046]\n",
      "epoch:17 step:16513 [D loss: 0.777153, acc.: 43.75%] [G loss: 0.846678]\n",
      "epoch:17 step:16514 [D loss: 0.705733, acc.: 57.03%] [G loss: 0.752018]\n",
      "epoch:17 step:16515 [D loss: 0.684078, acc.: 65.62%] [G loss: 1.209696]\n",
      "epoch:17 step:16516 [D loss: 0.500838, acc.: 75.78%] [G loss: 1.028837]\n",
      "epoch:17 step:16517 [D loss: 0.370400, acc.: 89.84%] [G loss: 1.728754]\n",
      "epoch:17 step:16518 [D loss: 0.372305, acc.: 86.72%] [G loss: 1.862536]\n",
      "epoch:17 step:16519 [D loss: 0.842802, acc.: 43.75%] [G loss: 1.043940]\n",
      "epoch:17 step:16520 [D loss: 0.888768, acc.: 40.62%] [G loss: 1.099805]\n",
      "epoch:17 step:16521 [D loss: 0.952332, acc.: 33.59%] [G loss: 0.859456]\n",
      "epoch:17 step:16522 [D loss: 0.724444, acc.: 46.09%] [G loss: 0.998016]\n",
      "epoch:17 step:16523 [D loss: 0.572746, acc.: 73.44%] [G loss: 1.131386]\n",
      "epoch:17 step:16524 [D loss: 0.689084, acc.: 60.94%] [G loss: 0.825960]\n",
      "epoch:17 step:16525 [D loss: 0.724569, acc.: 57.03%] [G loss: 0.918845]\n",
      "epoch:17 step:16526 [D loss: 0.695919, acc.: 55.47%] [G loss: 1.047323]\n",
      "epoch:17 step:16527 [D loss: 0.416361, acc.: 83.59%] [G loss: 1.181721]\n",
      "epoch:17 step:16528 [D loss: 0.700990, acc.: 54.69%] [G loss: 1.122382]\n",
      "epoch:17 step:16529 [D loss: 0.727921, acc.: 57.81%] [G loss: 0.976801]\n",
      "epoch:17 step:16530 [D loss: 0.682526, acc.: 61.72%] [G loss: 1.074821]\n",
      "epoch:17 step:16531 [D loss: 0.671467, acc.: 54.69%] [G loss: 0.991697]\n",
      "epoch:17 step:16532 [D loss: 0.519843, acc.: 75.78%] [G loss: 1.248342]\n",
      "epoch:17 step:16533 [D loss: 0.419112, acc.: 82.03%] [G loss: 1.226237]\n",
      "epoch:17 step:16534 [D loss: 0.412817, acc.: 85.94%] [G loss: 1.445890]\n",
      "epoch:17 step:16535 [D loss: 0.606949, acc.: 69.53%] [G loss: 1.400207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16536 [D loss: 0.613429, acc.: 65.62%] [G loss: 1.112743]\n",
      "epoch:17 step:16537 [D loss: 0.651643, acc.: 62.50%] [G loss: 1.006691]\n",
      "epoch:17 step:16538 [D loss: 0.592355, acc.: 67.97%] [G loss: 1.094368]\n",
      "epoch:17 step:16539 [D loss: 0.549783, acc.: 73.44%] [G loss: 1.055696]\n",
      "epoch:17 step:16540 [D loss: 0.685791, acc.: 59.38%] [G loss: 0.954723]\n",
      "epoch:17 step:16541 [D loss: 0.736531, acc.: 53.12%] [G loss: 0.805356]\n",
      "epoch:17 step:16542 [D loss: 0.418609, acc.: 85.16%] [G loss: 1.075657]\n",
      "epoch:17 step:16543 [D loss: 0.447202, acc.: 80.47%] [G loss: 1.153672]\n",
      "epoch:17 step:16544 [D loss: 0.409124, acc.: 86.72%] [G loss: 1.575775]\n",
      "epoch:17 step:16545 [D loss: 0.489574, acc.: 82.81%] [G loss: 1.490567]\n",
      "epoch:17 step:16546 [D loss: 0.629413, acc.: 61.72%] [G loss: 1.323624]\n",
      "epoch:17 step:16547 [D loss: 0.896851, acc.: 35.94%] [G loss: 0.987554]\n",
      "epoch:17 step:16548 [D loss: 0.780108, acc.: 41.41%] [G loss: 1.079614]\n",
      "epoch:17 step:16549 [D loss: 0.666570, acc.: 61.72%] [G loss: 1.096441]\n",
      "epoch:17 step:16550 [D loss: 0.736682, acc.: 52.34%] [G loss: 0.934778]\n",
      "epoch:17 step:16551 [D loss: 0.849538, acc.: 39.84%] [G loss: 0.794713]\n",
      "epoch:17 step:16552 [D loss: 0.556279, acc.: 71.09%] [G loss: 1.322788]\n",
      "epoch:17 step:16553 [D loss: 0.449410, acc.: 85.94%] [G loss: 1.312593]\n",
      "epoch:17 step:16554 [D loss: 0.715498, acc.: 55.47%] [G loss: 1.172029]\n",
      "epoch:17 step:16555 [D loss: 0.736685, acc.: 50.00%] [G loss: 1.047312]\n",
      "epoch:17 step:16556 [D loss: 1.020414, acc.: 35.94%] [G loss: 0.627877]\n",
      "epoch:17 step:16557 [D loss: 0.631402, acc.: 65.62%] [G loss: 1.148926]\n",
      "epoch:17 step:16558 [D loss: 0.352416, acc.: 92.19%] [G loss: 1.364555]\n",
      "epoch:17 step:16559 [D loss: 0.498456, acc.: 79.69%] [G loss: 1.243305]\n",
      "epoch:17 step:16560 [D loss: 0.708666, acc.: 55.47%] [G loss: 0.994133]\n",
      "epoch:17 step:16561 [D loss: 0.776474, acc.: 53.12%] [G loss: 0.669647]\n",
      "epoch:17 step:16562 [D loss: 0.532545, acc.: 76.56%] [G loss: 1.124289]\n",
      "epoch:17 step:16563 [D loss: 0.644212, acc.: 59.38%] [G loss: 1.120835]\n",
      "epoch:17 step:16564 [D loss: 0.801843, acc.: 48.44%] [G loss: 1.069517]\n",
      "epoch:17 step:16565 [D loss: 0.737947, acc.: 52.34%] [G loss: 1.014871]\n",
      "epoch:17 step:16566 [D loss: 0.841148, acc.: 43.75%] [G loss: 0.950795]\n",
      "epoch:17 step:16567 [D loss: 0.635403, acc.: 62.50%] [G loss: 1.049968]\n",
      "epoch:17 step:16568 [D loss: 0.809126, acc.: 51.56%] [G loss: 1.144530]\n",
      "epoch:17 step:16569 [D loss: 0.589380, acc.: 67.19%] [G loss: 1.248876]\n",
      "epoch:17 step:16570 [D loss: 0.429276, acc.: 85.94%] [G loss: 1.590966]\n",
      "epoch:17 step:16571 [D loss: 0.347559, acc.: 92.19%] [G loss: 1.839559]\n",
      "epoch:17 step:16572 [D loss: 0.655346, acc.: 57.81%] [G loss: 1.399280]\n",
      "epoch:17 step:16573 [D loss: 0.690527, acc.: 55.47%] [G loss: 0.940663]\n",
      "epoch:17 step:16574 [D loss: 0.555474, acc.: 74.22%] [G loss: 1.028887]\n",
      "epoch:17 step:16575 [D loss: 0.568501, acc.: 71.09%] [G loss: 1.230063]\n",
      "epoch:17 step:16576 [D loss: 0.564873, acc.: 71.88%] [G loss: 1.014644]\n",
      "epoch:17 step:16577 [D loss: 0.633987, acc.: 63.28%] [G loss: 0.931736]\n",
      "epoch:17 step:16578 [D loss: 0.676972, acc.: 64.06%] [G loss: 0.829672]\n",
      "epoch:17 step:16579 [D loss: 0.496785, acc.: 79.69%] [G loss: 1.265779]\n",
      "epoch:17 step:16580 [D loss: 0.640576, acc.: 64.84%] [G loss: 1.153347]\n",
      "epoch:17 step:16581 [D loss: 0.673507, acc.: 57.81%] [G loss: 0.880260]\n",
      "epoch:17 step:16582 [D loss: 0.574192, acc.: 69.53%] [G loss: 1.106359]\n",
      "epoch:17 step:16583 [D loss: 0.454078, acc.: 82.81%] [G loss: 1.218790]\n",
      "epoch:17 step:16584 [D loss: 0.618153, acc.: 64.84%] [G loss: 1.274924]\n",
      "epoch:17 step:16585 [D loss: 0.694752, acc.: 52.34%] [G loss: 1.129417]\n",
      "epoch:17 step:16586 [D loss: 0.658919, acc.: 57.81%] [G loss: 1.085328]\n",
      "epoch:17 step:16587 [D loss: 0.601587, acc.: 67.19%] [G loss: 1.215040]\n",
      "epoch:17 step:16588 [D loss: 0.661771, acc.: 64.84%] [G loss: 1.025559]\n",
      "epoch:17 step:16589 [D loss: 0.630453, acc.: 67.19%] [G loss: 1.153006]\n",
      "epoch:17 step:16590 [D loss: 0.673302, acc.: 59.38%] [G loss: 1.040281]\n",
      "epoch:17 step:16591 [D loss: 0.571053, acc.: 72.66%] [G loss: 1.045613]\n",
      "epoch:17 step:16592 [D loss: 0.404513, acc.: 81.25%] [G loss: 1.131206]\n",
      "epoch:17 step:16593 [D loss: 0.345326, acc.: 89.84%] [G loss: 1.473266]\n",
      "epoch:17 step:16594 [D loss: 0.294409, acc.: 94.53%] [G loss: 1.611609]\n",
      "epoch:17 step:16595 [D loss: 0.564254, acc.: 72.66%] [G loss: 1.173098]\n",
      "epoch:17 step:16596 [D loss: 0.505088, acc.: 80.47%] [G loss: 1.282177]\n",
      "epoch:17 step:16597 [D loss: 0.737108, acc.: 55.47%] [G loss: 1.106054]\n",
      "epoch:17 step:16598 [D loss: 0.745700, acc.: 48.44%] [G loss: 0.864954]\n",
      "epoch:17 step:16599 [D loss: 0.738925, acc.: 51.56%] [G loss: 1.174595]\n",
      "epoch:17 step:16600 [D loss: 0.617606, acc.: 64.06%] [G loss: 1.334110]\n",
      "epoch:17 step:16601 [D loss: 0.932067, acc.: 32.81%] [G loss: 0.731711]\n",
      "epoch:17 step:16602 [D loss: 0.703483, acc.: 59.38%] [G loss: 1.148661]\n",
      "epoch:17 step:16603 [D loss: 0.703594, acc.: 57.03%] [G loss: 0.876046]\n",
      "epoch:17 step:16604 [D loss: 0.974191, acc.: 35.94%] [G loss: 0.648991]\n",
      "epoch:17 step:16605 [D loss: 0.769043, acc.: 56.25%] [G loss: 0.808373]\n",
      "epoch:17 step:16606 [D loss: 0.759888, acc.: 50.00%] [G loss: 1.004802]\n",
      "epoch:17 step:16607 [D loss: 0.742188, acc.: 47.66%] [G loss: 0.891112]\n",
      "epoch:17 step:16608 [D loss: 0.783941, acc.: 48.44%] [G loss: 1.035077]\n",
      "epoch:17 step:16609 [D loss: 0.571823, acc.: 63.28%] [G loss: 1.119074]\n",
      "epoch:17 step:16610 [D loss: 0.658762, acc.: 60.94%] [G loss: 0.972408]\n",
      "epoch:17 step:16611 [D loss: 0.689179, acc.: 59.38%] [G loss: 1.040256]\n",
      "epoch:17 step:16612 [D loss: 0.712915, acc.: 52.34%] [G loss: 1.093141]\n",
      "epoch:17 step:16613 [D loss: 0.627579, acc.: 61.72%] [G loss: 0.960307]\n",
      "epoch:17 step:16614 [D loss: 0.726370, acc.: 50.00%] [G loss: 0.781525]\n",
      "epoch:17 step:16615 [D loss: 0.578501, acc.: 71.09%] [G loss: 1.106878]\n",
      "epoch:17 step:16616 [D loss: 0.742084, acc.: 50.78%] [G loss: 1.200755]\n",
      "epoch:17 step:16617 [D loss: 0.552493, acc.: 70.31%] [G loss: 1.005738]\n",
      "epoch:17 step:16618 [D loss: 0.476293, acc.: 79.69%] [G loss: 0.982179]\n",
      "epoch:17 step:16619 [D loss: 0.343697, acc.: 89.84%] [G loss: 1.223209]\n",
      "epoch:17 step:16620 [D loss: 0.453069, acc.: 84.38%] [G loss: 1.518800]\n",
      "epoch:17 step:16621 [D loss: 0.444348, acc.: 83.59%] [G loss: 1.195178]\n",
      "epoch:17 step:16622 [D loss: 0.511285, acc.: 73.44%] [G loss: 1.272230]\n",
      "epoch:17 step:16623 [D loss: 0.312372, acc.: 92.97%] [G loss: 1.525346]\n",
      "epoch:17 step:16624 [D loss: 0.459124, acc.: 84.38%] [G loss: 1.385702]\n",
      "epoch:17 step:16625 [D loss: 0.752686, acc.: 50.00%] [G loss: 1.073308]\n",
      "epoch:17 step:16626 [D loss: 0.633110, acc.: 60.16%] [G loss: 1.273388]\n",
      "epoch:17 step:16627 [D loss: 0.766158, acc.: 51.56%] [G loss: 0.862797]\n",
      "epoch:17 step:16628 [D loss: 0.664185, acc.: 61.72%] [G loss: 0.917350]\n",
      "epoch:17 step:16629 [D loss: 0.608591, acc.: 68.75%] [G loss: 0.995602]\n",
      "epoch:17 step:16630 [D loss: 0.704762, acc.: 53.91%] [G loss: 0.942261]\n",
      "epoch:17 step:16631 [D loss: 0.671718, acc.: 61.72%] [G loss: 1.092927]\n",
      "epoch:17 step:16632 [D loss: 0.789003, acc.: 44.53%] [G loss: 0.840043]\n",
      "epoch:17 step:16633 [D loss: 0.712895, acc.: 50.78%] [G loss: 1.041373]\n",
      "epoch:17 step:16634 [D loss: 0.602686, acc.: 72.66%] [G loss: 1.022586]\n",
      "epoch:17 step:16635 [D loss: 0.608828, acc.: 63.28%] [G loss: 1.097972]\n",
      "epoch:17 step:16636 [D loss: 0.519101, acc.: 76.56%] [G loss: 1.122462]\n",
      "epoch:17 step:16637 [D loss: 0.523971, acc.: 75.00%] [G loss: 1.216550]\n",
      "epoch:17 step:16638 [D loss: 0.453848, acc.: 80.47%] [G loss: 1.303853]\n",
      "epoch:17 step:16639 [D loss: 0.740487, acc.: 54.69%] [G loss: 1.067206]\n",
      "epoch:17 step:16640 [D loss: 0.657809, acc.: 67.19%] [G loss: 1.225688]\n",
      "epoch:17 step:16641 [D loss: 0.578264, acc.: 71.09%] [G loss: 1.021527]\n",
      "epoch:17 step:16642 [D loss: 0.490693, acc.: 78.91%] [G loss: 1.066905]\n",
      "epoch:17 step:16643 [D loss: 0.577533, acc.: 70.31%] [G loss: 1.343645]\n",
      "epoch:17 step:16644 [D loss: 0.662414, acc.: 53.91%] [G loss: 1.062515]\n",
      "epoch:17 step:16645 [D loss: 0.614806, acc.: 68.75%] [G loss: 1.119131]\n",
      "epoch:17 step:16646 [D loss: 0.627628, acc.: 66.41%] [G loss: 0.913318]\n",
      "epoch:17 step:16647 [D loss: 0.667148, acc.: 57.03%] [G loss: 0.936478]\n",
      "epoch:17 step:16648 [D loss: 0.682106, acc.: 58.59%] [G loss: 0.803497]\n",
      "epoch:17 step:16649 [D loss: 0.628580, acc.: 64.84%] [G loss: 1.089985]\n",
      "epoch:17 step:16650 [D loss: 0.567817, acc.: 74.22%] [G loss: 0.946688]\n",
      "epoch:17 step:16651 [D loss: 0.684915, acc.: 55.47%] [G loss: 1.157773]\n",
      "epoch:17 step:16652 [D loss: 0.635455, acc.: 66.41%] [G loss: 0.924932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16653 [D loss: 0.506768, acc.: 76.56%] [G loss: 0.909327]\n",
      "epoch:17 step:16654 [D loss: 0.519195, acc.: 77.34%] [G loss: 1.094907]\n",
      "epoch:17 step:16655 [D loss: 0.608264, acc.: 70.31%] [G loss: 0.951403]\n",
      "epoch:17 step:16656 [D loss: 0.666363, acc.: 60.94%] [G loss: 1.236783]\n",
      "epoch:17 step:16657 [D loss: 0.518781, acc.: 78.91%] [G loss: 1.341574]\n",
      "epoch:17 step:16658 [D loss: 0.662447, acc.: 61.72%] [G loss: 1.128734]\n",
      "epoch:17 step:16659 [D loss: 0.622812, acc.: 66.41%] [G loss: 1.210378]\n",
      "epoch:17 step:16660 [D loss: 0.591120, acc.: 67.19%] [G loss: 1.042234]\n",
      "epoch:17 step:16661 [D loss: 0.538648, acc.: 74.22%] [G loss: 1.159336]\n",
      "epoch:17 step:16662 [D loss: 0.516590, acc.: 78.12%] [G loss: 1.263577]\n",
      "epoch:17 step:16663 [D loss: 0.754746, acc.: 55.47%] [G loss: 1.172427]\n",
      "epoch:17 step:16664 [D loss: 0.595639, acc.: 68.75%] [G loss: 0.945489]\n",
      "epoch:17 step:16665 [D loss: 0.800050, acc.: 39.84%] [G loss: 0.946104]\n",
      "epoch:17 step:16666 [D loss: 0.695518, acc.: 55.47%] [G loss: 0.895560]\n",
      "epoch:17 step:16667 [D loss: 0.747115, acc.: 50.78%] [G loss: 1.035685]\n",
      "epoch:17 step:16668 [D loss: 0.686621, acc.: 57.03%] [G loss: 1.182832]\n",
      "epoch:17 step:16669 [D loss: 0.651305, acc.: 59.38%] [G loss: 0.987337]\n",
      "epoch:17 step:16670 [D loss: 0.681485, acc.: 60.94%] [G loss: 0.906083]\n",
      "epoch:17 step:16671 [D loss: 0.552693, acc.: 73.44%] [G loss: 1.020154]\n",
      "epoch:17 step:16672 [D loss: 0.460801, acc.: 85.94%] [G loss: 1.225256]\n",
      "epoch:17 step:16673 [D loss: 0.700196, acc.: 51.56%] [G loss: 1.102359]\n",
      "epoch:17 step:16674 [D loss: 0.491645, acc.: 76.56%] [G loss: 1.120039]\n",
      "epoch:17 step:16675 [D loss: 0.528512, acc.: 75.78%] [G loss: 1.439465]\n",
      "epoch:17 step:16676 [D loss: 0.642803, acc.: 66.41%] [G loss: 1.008384]\n",
      "epoch:17 step:16677 [D loss: 0.639535, acc.: 62.50%] [G loss: 0.925445]\n",
      "epoch:17 step:16678 [D loss: 0.619109, acc.: 66.41%] [G loss: 0.897658]\n",
      "epoch:17 step:16679 [D loss: 0.617655, acc.: 60.16%] [G loss: 1.070985]\n",
      "epoch:17 step:16680 [D loss: 0.726551, acc.: 48.44%] [G loss: 0.970950]\n",
      "epoch:17 step:16681 [D loss: 0.690234, acc.: 54.69%] [G loss: 1.070686]\n",
      "epoch:17 step:16682 [D loss: 0.646874, acc.: 57.03%] [G loss: 0.977487]\n",
      "epoch:17 step:16683 [D loss: 0.682293, acc.: 57.03%] [G loss: 1.059015]\n",
      "epoch:17 step:16684 [D loss: 0.536228, acc.: 74.22%] [G loss: 1.117868]\n",
      "epoch:17 step:16685 [D loss: 0.586526, acc.: 71.09%] [G loss: 1.104648]\n",
      "epoch:17 step:16686 [D loss: 0.622263, acc.: 61.72%] [G loss: 1.103452]\n",
      "epoch:17 step:16687 [D loss: 0.679013, acc.: 60.16%] [G loss: 1.085264]\n",
      "epoch:17 step:16688 [D loss: 0.644345, acc.: 62.50%] [G loss: 0.990817]\n",
      "epoch:17 step:16689 [D loss: 0.563534, acc.: 74.22%] [G loss: 1.036288]\n",
      "epoch:17 step:16690 [D loss: 0.652037, acc.: 64.06%] [G loss: 1.154863]\n",
      "epoch:17 step:16691 [D loss: 0.663319, acc.: 63.28%] [G loss: 0.833965]\n",
      "epoch:17 step:16692 [D loss: 0.637598, acc.: 64.06%] [G loss: 0.893362]\n",
      "epoch:17 step:16693 [D loss: 0.632744, acc.: 62.50%] [G loss: 0.852235]\n",
      "epoch:17 step:16694 [D loss: 0.668865, acc.: 57.81%] [G loss: 1.045475]\n",
      "epoch:17 step:16695 [D loss: 0.825092, acc.: 41.41%] [G loss: 0.983807]\n",
      "epoch:17 step:16696 [D loss: 0.747461, acc.: 47.66%] [G loss: 0.915641]\n",
      "epoch:17 step:16697 [D loss: 0.526111, acc.: 74.22%] [G loss: 1.183613]\n",
      "epoch:17 step:16698 [D loss: 0.406553, acc.: 85.94%] [G loss: 1.154243]\n",
      "epoch:17 step:16699 [D loss: 0.556857, acc.: 75.78%] [G loss: 1.243539]\n",
      "epoch:17 step:16700 [D loss: 0.708488, acc.: 53.91%] [G loss: 1.004092]\n",
      "epoch:17 step:16701 [D loss: 0.700360, acc.: 56.25%] [G loss: 1.127221]\n",
      "epoch:17 step:16702 [D loss: 0.640753, acc.: 64.84%] [G loss: 1.072026]\n",
      "epoch:17 step:16703 [D loss: 0.297137, acc.: 89.84%] [G loss: 1.347519]\n",
      "epoch:17 step:16704 [D loss: 0.265926, acc.: 94.53%] [G loss: 1.523119]\n",
      "epoch:17 step:16705 [D loss: 0.451890, acc.: 82.03%] [G loss: 1.345677]\n",
      "epoch:17 step:16706 [D loss: 0.480832, acc.: 80.47%] [G loss: 1.348451]\n",
      "epoch:17 step:16707 [D loss: 0.731603, acc.: 54.69%] [G loss: 0.916055]\n",
      "epoch:17 step:16708 [D loss: 0.770925, acc.: 47.66%] [G loss: 1.114458]\n",
      "epoch:17 step:16709 [D loss: 0.728061, acc.: 51.56%] [G loss: 0.745942]\n",
      "epoch:17 step:16710 [D loss: 0.609102, acc.: 67.97%] [G loss: 1.080392]\n",
      "epoch:17 step:16711 [D loss: 0.520375, acc.: 75.78%] [G loss: 1.210192]\n",
      "epoch:17 step:16712 [D loss: 0.830788, acc.: 41.41%] [G loss: 0.893426]\n",
      "epoch:17 step:16713 [D loss: 0.675383, acc.: 58.59%] [G loss: 1.013219]\n",
      "epoch:17 step:16714 [D loss: 0.698726, acc.: 61.72%] [G loss: 1.022217]\n",
      "epoch:17 step:16715 [D loss: 0.443601, acc.: 87.50%] [G loss: 1.255040]\n",
      "epoch:17 step:16716 [D loss: 0.693100, acc.: 54.69%] [G loss: 0.912404]\n",
      "epoch:17 step:16717 [D loss: 0.607511, acc.: 68.75%] [G loss: 0.982107]\n",
      "epoch:17 step:16718 [D loss: 0.780579, acc.: 42.97%] [G loss: 0.870621]\n",
      "epoch:17 step:16719 [D loss: 0.482704, acc.: 81.25%] [G loss: 1.032529]\n",
      "epoch:17 step:16720 [D loss: 0.441287, acc.: 83.59%] [G loss: 1.023588]\n",
      "epoch:17 step:16721 [D loss: 0.338746, acc.: 92.97%] [G loss: 1.293658]\n",
      "epoch:17 step:16722 [D loss: 0.438316, acc.: 85.94%] [G loss: 1.284001]\n",
      "epoch:17 step:16723 [D loss: 0.290906, acc.: 94.53%] [G loss: 1.380594]\n",
      "epoch:17 step:16724 [D loss: 0.545477, acc.: 72.66%] [G loss: 1.208777]\n",
      "epoch:17 step:16725 [D loss: 0.573063, acc.: 71.09%] [G loss: 1.350399]\n",
      "epoch:17 step:16726 [D loss: 0.632936, acc.: 66.41%] [G loss: 1.085263]\n",
      "epoch:17 step:16727 [D loss: 0.670667, acc.: 60.16%] [G loss: 1.078244]\n",
      "epoch:17 step:16728 [D loss: 0.636605, acc.: 67.97%] [G loss: 1.212901]\n",
      "epoch:17 step:16729 [D loss: 0.712052, acc.: 59.38%] [G loss: 0.965647]\n",
      "epoch:17 step:16730 [D loss: 0.738149, acc.: 49.22%] [G loss: 1.015091]\n",
      "epoch:17 step:16731 [D loss: 0.626307, acc.: 66.41%] [G loss: 1.044681]\n",
      "epoch:17 step:16732 [D loss: 0.643834, acc.: 61.72%] [G loss: 1.141725]\n",
      "epoch:17 step:16733 [D loss: 0.591531, acc.: 71.09%] [G loss: 1.056708]\n",
      "epoch:17 step:16734 [D loss: 0.473214, acc.: 81.25%] [G loss: 1.224650]\n",
      "epoch:17 step:16735 [D loss: 0.468707, acc.: 81.25%] [G loss: 1.002651]\n",
      "epoch:17 step:16736 [D loss: 0.641970, acc.: 61.72%] [G loss: 1.011865]\n",
      "epoch:17 step:16737 [D loss: 0.515982, acc.: 80.47%] [G loss: 1.062464]\n",
      "epoch:17 step:16738 [D loss: 0.502225, acc.: 78.12%] [G loss: 1.110126]\n",
      "epoch:17 step:16739 [D loss: 0.598265, acc.: 69.53%] [G loss: 1.129623]\n",
      "epoch:17 step:16740 [D loss: 0.818573, acc.: 41.41%] [G loss: 0.938735]\n",
      "epoch:17 step:16741 [D loss: 0.655812, acc.: 60.94%] [G loss: 0.895663]\n",
      "epoch:17 step:16742 [D loss: 0.600596, acc.: 67.19%] [G loss: 0.930200]\n",
      "epoch:17 step:16743 [D loss: 0.569620, acc.: 75.00%] [G loss: 1.107335]\n",
      "epoch:17 step:16744 [D loss: 0.333975, acc.: 82.81%] [G loss: 1.061866]\n",
      "epoch:17 step:16745 [D loss: 0.354935, acc.: 92.97%] [G loss: 1.550651]\n",
      "epoch:17 step:16746 [D loss: 0.604854, acc.: 68.75%] [G loss: 1.110930]\n",
      "epoch:17 step:16747 [D loss: 0.558119, acc.: 72.66%] [G loss: 1.033293]\n",
      "epoch:17 step:16748 [D loss: 0.666602, acc.: 62.50%] [G loss: 1.120566]\n",
      "epoch:17 step:16749 [D loss: 0.963738, acc.: 35.94%] [G loss: 0.697841]\n",
      "epoch:17 step:16750 [D loss: 0.798077, acc.: 39.84%] [G loss: 0.857324]\n",
      "epoch:17 step:16751 [D loss: 0.791766, acc.: 44.53%] [G loss: 1.012783]\n",
      "epoch:17 step:16752 [D loss: 0.555905, acc.: 73.44%] [G loss: 0.967245]\n",
      "epoch:17 step:16753 [D loss: 0.535351, acc.: 74.22%] [G loss: 0.907696]\n",
      "epoch:17 step:16754 [D loss: 0.566551, acc.: 75.00%] [G loss: 0.998515]\n",
      "epoch:17 step:16755 [D loss: 0.672660, acc.: 57.81%] [G loss: 1.126969]\n",
      "epoch:17 step:16756 [D loss: 0.769545, acc.: 53.12%] [G loss: 1.182098]\n",
      "epoch:17 step:16757 [D loss: 0.837676, acc.: 41.41%] [G loss: 0.796692]\n",
      "epoch:17 step:16758 [D loss: 0.858171, acc.: 42.19%] [G loss: 0.838055]\n",
      "epoch:17 step:16759 [D loss: 0.604485, acc.: 67.97%] [G loss: 1.131156]\n",
      "epoch:17 step:16760 [D loss: 0.459350, acc.: 81.25%] [G loss: 1.257709]\n",
      "epoch:17 step:16761 [D loss: 0.580987, acc.: 67.19%] [G loss: 1.011425]\n",
      "epoch:17 step:16762 [D loss: 0.403004, acc.: 93.75%] [G loss: 1.432795]\n",
      "epoch:17 step:16763 [D loss: 0.768079, acc.: 48.44%] [G loss: 1.072904]\n",
      "epoch:17 step:16764 [D loss: 0.686236, acc.: 57.03%] [G loss: 1.017076]\n",
      "epoch:17 step:16765 [D loss: 0.788007, acc.: 46.88%] [G loss: 1.099645]\n",
      "epoch:17 step:16766 [D loss: 0.606888, acc.: 63.28%] [G loss: 1.207805]\n",
      "epoch:17 step:16767 [D loss: 0.611500, acc.: 64.84%] [G loss: 1.123775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16768 [D loss: 0.607341, acc.: 65.62%] [G loss: 1.061056]\n",
      "epoch:17 step:16769 [D loss: 0.454877, acc.: 84.38%] [G loss: 1.355545]\n",
      "epoch:17 step:16770 [D loss: 0.393100, acc.: 89.06%] [G loss: 1.262227]\n",
      "epoch:17 step:16771 [D loss: 0.455137, acc.: 85.94%] [G loss: 1.386047]\n",
      "epoch:17 step:16772 [D loss: 0.710173, acc.: 49.22%] [G loss: 1.170451]\n",
      "epoch:17 step:16773 [D loss: 0.640539, acc.: 70.31%] [G loss: 1.071629]\n",
      "epoch:17 step:16774 [D loss: 0.764142, acc.: 42.19%] [G loss: 0.802467]\n",
      "epoch:17 step:16775 [D loss: 0.582227, acc.: 69.53%] [G loss: 0.767155]\n",
      "epoch:17 step:16776 [D loss: 0.467605, acc.: 78.91%] [G loss: 1.165653]\n",
      "epoch:17 step:16777 [D loss: 0.598565, acc.: 71.09%] [G loss: 1.248283]\n",
      "epoch:17 step:16778 [D loss: 0.475103, acc.: 78.91%] [G loss: 0.972569]\n",
      "epoch:17 step:16779 [D loss: 0.430943, acc.: 85.16%] [G loss: 1.388439]\n",
      "epoch:17 step:16780 [D loss: 0.280897, acc.: 96.09%] [G loss: 1.627541]\n",
      "epoch:17 step:16781 [D loss: 0.382301, acc.: 83.59%] [G loss: 1.246313]\n",
      "epoch:17 step:16782 [D loss: 0.377225, acc.: 89.84%] [G loss: 1.296731]\n",
      "epoch:17 step:16783 [D loss: 0.352151, acc.: 89.06%] [G loss: 1.534919]\n",
      "epoch:17 step:16784 [D loss: 0.402580, acc.: 85.94%] [G loss: 1.436395]\n",
      "epoch:17 step:16785 [D loss: 0.591462, acc.: 66.41%] [G loss: 1.424778]\n",
      "epoch:17 step:16786 [D loss: 0.361232, acc.: 86.72%] [G loss: 1.429341]\n",
      "epoch:17 step:16787 [D loss: 0.928096, acc.: 46.09%] [G loss: 1.011162]\n",
      "epoch:17 step:16788 [D loss: 0.764595, acc.: 50.78%] [G loss: 1.150328]\n",
      "epoch:17 step:16789 [D loss: 0.627062, acc.: 68.75%] [G loss: 0.875188]\n",
      "epoch:17 step:16790 [D loss: 0.623888, acc.: 67.19%] [G loss: 1.218879]\n",
      "epoch:17 step:16791 [D loss: 0.733089, acc.: 57.03%] [G loss: 0.923988]\n",
      "epoch:17 step:16792 [D loss: 0.678951, acc.: 57.03%] [G loss: 0.902438]\n",
      "epoch:17 step:16793 [D loss: 0.681053, acc.: 57.81%] [G loss: 0.989660]\n",
      "epoch:17 step:16794 [D loss: 0.741008, acc.: 53.12%] [G loss: 0.717775]\n",
      "epoch:17 step:16795 [D loss: 0.602479, acc.: 66.41%] [G loss: 0.965835]\n",
      "epoch:17 step:16796 [D loss: 0.639082, acc.: 64.06%] [G loss: 1.090964]\n",
      "epoch:17 step:16797 [D loss: 0.606845, acc.: 70.31%] [G loss: 1.053673]\n",
      "epoch:17 step:16798 [D loss: 0.724581, acc.: 50.78%] [G loss: 1.147805]\n",
      "epoch:17 step:16799 [D loss: 0.717718, acc.: 52.34%] [G loss: 0.827365]\n",
      "epoch:17 step:16800 [D loss: 0.633654, acc.: 65.62%] [G loss: 0.981803]\n",
      "epoch:17 step:16801 [D loss: 0.537766, acc.: 72.66%] [G loss: 1.065877]\n",
      "epoch:17 step:16802 [D loss: 0.594996, acc.: 70.31%] [G loss: 0.968215]\n",
      "epoch:17 step:16803 [D loss: 0.715119, acc.: 55.47%] [G loss: 1.041182]\n",
      "epoch:17 step:16804 [D loss: 0.586514, acc.: 67.97%] [G loss: 1.210485]\n",
      "epoch:17 step:16805 [D loss: 0.573326, acc.: 67.97%] [G loss: 0.972991]\n",
      "epoch:17 step:16806 [D loss: 0.565170, acc.: 69.53%] [G loss: 1.158379]\n",
      "epoch:17 step:16807 [D loss: 0.447154, acc.: 82.81%] [G loss: 1.045425]\n",
      "epoch:17 step:16808 [D loss: 0.594151, acc.: 68.75%] [G loss: 1.083460]\n",
      "epoch:17 step:16809 [D loss: 0.700953, acc.: 53.91%] [G loss: 1.054139]\n",
      "epoch:17 step:16810 [D loss: 0.698578, acc.: 54.69%] [G loss: 1.082835]\n",
      "epoch:17 step:16811 [D loss: 0.646193, acc.: 63.28%] [G loss: 0.842473]\n",
      "epoch:17 step:16812 [D loss: 0.645415, acc.: 64.06%] [G loss: 1.031874]\n",
      "epoch:17 step:16813 [D loss: 0.580781, acc.: 67.19%] [G loss: 0.828493]\n",
      "epoch:17 step:16814 [D loss: 0.546130, acc.: 71.88%] [G loss: 1.236133]\n",
      "epoch:17 step:16815 [D loss: 0.471627, acc.: 82.81%] [G loss: 1.155298]\n",
      "epoch:17 step:16816 [D loss: 0.448716, acc.: 82.81%] [G loss: 1.094695]\n",
      "epoch:17 step:16817 [D loss: 0.489913, acc.: 77.34%] [G loss: 1.130564]\n",
      "epoch:17 step:16818 [D loss: 0.402018, acc.: 88.28%] [G loss: 1.156839]\n",
      "epoch:17 step:16819 [D loss: 0.363419, acc.: 92.19%] [G loss: 1.639152]\n",
      "epoch:17 step:16820 [D loss: 0.913316, acc.: 41.41%] [G loss: 1.205986]\n",
      "epoch:17 step:16821 [D loss: 0.788267, acc.: 47.66%] [G loss: 0.993512]\n",
      "epoch:17 step:16822 [D loss: 0.649821, acc.: 61.72%] [G loss: 0.979387]\n",
      "epoch:17 step:16823 [D loss: 0.698403, acc.: 61.72%] [G loss: 0.886935]\n",
      "epoch:17 step:16824 [D loss: 0.620605, acc.: 63.28%] [G loss: 1.260262]\n",
      "epoch:17 step:16825 [D loss: 0.651899, acc.: 62.50%] [G loss: 0.903171]\n",
      "epoch:17 step:16826 [D loss: 0.442403, acc.: 86.72%] [G loss: 0.890512]\n",
      "epoch:17 step:16827 [D loss: 0.372014, acc.: 89.06%] [G loss: 1.178255]\n",
      "epoch:17 step:16828 [D loss: 0.376417, acc.: 90.62%] [G loss: 1.521711]\n",
      "epoch:17 step:16829 [D loss: 0.285123, acc.: 96.88%] [G loss: 1.489139]\n",
      "epoch:17 step:16830 [D loss: 0.433670, acc.: 83.59%] [G loss: 1.395508]\n",
      "epoch:17 step:16831 [D loss: 0.643556, acc.: 67.97%] [G loss: 1.329489]\n",
      "epoch:17 step:16832 [D loss: 0.502448, acc.: 79.69%] [G loss: 1.134302]\n",
      "epoch:17 step:16833 [D loss: 0.699451, acc.: 57.03%] [G loss: 1.090198]\n",
      "epoch:17 step:16834 [D loss: 0.631831, acc.: 64.06%] [G loss: 1.281134]\n",
      "epoch:17 step:16835 [D loss: 0.786200, acc.: 45.31%] [G loss: 0.912252]\n",
      "epoch:17 step:16836 [D loss: 0.708617, acc.: 50.78%] [G loss: 1.180771]\n",
      "epoch:17 step:16837 [D loss: 0.675563, acc.: 56.25%] [G loss: 1.088023]\n",
      "epoch:17 step:16838 [D loss: 0.435235, acc.: 88.28%] [G loss: 1.135840]\n",
      "epoch:17 step:16839 [D loss: 0.610476, acc.: 58.59%] [G loss: 0.920571]\n",
      "epoch:17 step:16840 [D loss: 0.353454, acc.: 88.28%] [G loss: 1.395241]\n",
      "epoch:17 step:16841 [D loss: 0.281745, acc.: 91.41%] [G loss: 1.409913]\n",
      "epoch:17 step:16842 [D loss: 0.765970, acc.: 54.69%] [G loss: 1.331654]\n",
      "epoch:17 step:16843 [D loss: 0.653287, acc.: 64.06%] [G loss: 1.139054]\n",
      "epoch:17 step:16844 [D loss: 0.608080, acc.: 64.84%] [G loss: 0.947652]\n",
      "epoch:17 step:16845 [D loss: 0.723794, acc.: 50.78%] [G loss: 0.903813]\n",
      "epoch:17 step:16846 [D loss: 1.004272, acc.: 28.91%] [G loss: 0.741701]\n",
      "epoch:17 step:16847 [D loss: 0.606991, acc.: 67.19%] [G loss: 1.091226]\n",
      "epoch:17 step:16848 [D loss: 0.529458, acc.: 76.56%] [G loss: 1.122221]\n",
      "epoch:17 step:16849 [D loss: 0.488168, acc.: 77.34%] [G loss: 1.303396]\n",
      "epoch:17 step:16850 [D loss: 0.533540, acc.: 74.22%] [G loss: 1.141852]\n",
      "epoch:17 step:16851 [D loss: 0.560402, acc.: 71.09%] [G loss: 1.367819]\n",
      "epoch:17 step:16852 [D loss: 0.566626, acc.: 71.88%] [G loss: 1.168611]\n",
      "epoch:17 step:16853 [D loss: 0.557602, acc.: 72.66%] [G loss: 1.009792]\n",
      "epoch:17 step:16854 [D loss: 0.581247, acc.: 69.53%] [G loss: 1.102691]\n",
      "epoch:17 step:16855 [D loss: 0.455541, acc.: 83.59%] [G loss: 1.246318]\n",
      "epoch:17 step:16856 [D loss: 0.518548, acc.: 71.88%] [G loss: 1.154558]\n",
      "epoch:17 step:16857 [D loss: 0.864698, acc.: 46.88%] [G loss: 1.277028]\n",
      "epoch:17 step:16858 [D loss: 0.362855, acc.: 92.97%] [G loss: 1.307713]\n",
      "epoch:17 step:16859 [D loss: 0.470681, acc.: 83.59%] [G loss: 1.244086]\n",
      "epoch:17 step:16860 [D loss: 0.662564, acc.: 60.94%] [G loss: 1.045107]\n",
      "epoch:17 step:16861 [D loss: 0.567383, acc.: 74.22%] [G loss: 1.185243]\n",
      "epoch:17 step:16862 [D loss: 0.645674, acc.: 61.72%] [G loss: 0.957808]\n",
      "epoch:17 step:16863 [D loss: 0.682782, acc.: 56.25%] [G loss: 1.003167]\n",
      "epoch:17 step:16864 [D loss: 0.646240, acc.: 62.50%] [G loss: 1.020190]\n",
      "epoch:17 step:16865 [D loss: 0.617419, acc.: 68.75%] [G loss: 0.888575]\n",
      "epoch:17 step:16866 [D loss: 0.289256, acc.: 91.41%] [G loss: 1.187297]\n",
      "epoch:18 step:16867 [D loss: 0.656392, acc.: 60.16%] [G loss: 1.074210]\n",
      "epoch:18 step:16868 [D loss: 0.778884, acc.: 44.53%] [G loss: 0.882918]\n",
      "epoch:18 step:16869 [D loss: 0.784079, acc.: 49.22%] [G loss: 1.142662]\n",
      "epoch:18 step:16870 [D loss: 0.567680, acc.: 69.53%] [G loss: 1.217055]\n",
      "epoch:18 step:16871 [D loss: 0.594922, acc.: 68.75%] [G loss: 1.159616]\n",
      "epoch:18 step:16872 [D loss: 0.552605, acc.: 75.78%] [G loss: 1.118373]\n",
      "epoch:18 step:16873 [D loss: 0.583797, acc.: 70.31%] [G loss: 1.191807]\n",
      "epoch:18 step:16874 [D loss: 0.590981, acc.: 66.41%] [G loss: 1.283796]\n",
      "epoch:18 step:16875 [D loss: 0.667571, acc.: 59.38%] [G loss: 1.383160]\n",
      "epoch:18 step:16876 [D loss: 0.514635, acc.: 75.00%] [G loss: 1.136838]\n",
      "epoch:18 step:16877 [D loss: 0.745432, acc.: 46.09%] [G loss: 0.990732]\n",
      "epoch:18 step:16878 [D loss: 0.575512, acc.: 71.09%] [G loss: 1.085661]\n",
      "epoch:18 step:16879 [D loss: 0.551889, acc.: 75.00%] [G loss: 0.897496]\n",
      "epoch:18 step:16880 [D loss: 0.703271, acc.: 58.59%] [G loss: 0.838037]\n",
      "epoch:18 step:16881 [D loss: 0.670322, acc.: 59.38%] [G loss: 0.816067]\n",
      "epoch:18 step:16882 [D loss: 0.589875, acc.: 67.97%] [G loss: 1.010615]\n",
      "epoch:18 step:16883 [D loss: 0.777297, acc.: 49.22%] [G loss: 1.152562]\n",
      "epoch:18 step:16884 [D loss: 0.658750, acc.: 61.72%] [G loss: 1.037453]\n",
      "epoch:18 step:16885 [D loss: 0.704875, acc.: 53.91%] [G loss: 1.041611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16886 [D loss: 0.559491, acc.: 75.00%] [G loss: 0.924248]\n",
      "epoch:18 step:16887 [D loss: 0.614067, acc.: 63.28%] [G loss: 1.149202]\n",
      "epoch:18 step:16888 [D loss: 0.651948, acc.: 63.28%] [G loss: 1.137352]\n",
      "epoch:18 step:16889 [D loss: 0.624335, acc.: 67.97%] [G loss: 1.178925]\n",
      "epoch:18 step:16890 [D loss: 0.675971, acc.: 57.81%] [G loss: 0.956916]\n",
      "epoch:18 step:16891 [D loss: 0.544546, acc.: 78.91%] [G loss: 1.050432]\n",
      "epoch:18 step:16892 [D loss: 0.509652, acc.: 75.78%] [G loss: 1.008624]\n",
      "epoch:18 step:16893 [D loss: 0.435268, acc.: 82.81%] [G loss: 1.168156]\n",
      "epoch:18 step:16894 [D loss: 0.405793, acc.: 87.50%] [G loss: 1.166778]\n",
      "epoch:18 step:16895 [D loss: 0.440483, acc.: 84.38%] [G loss: 1.321690]\n",
      "epoch:18 step:16896 [D loss: 0.501058, acc.: 76.56%] [G loss: 0.871717]\n",
      "epoch:18 step:16897 [D loss: 0.434068, acc.: 85.16%] [G loss: 1.173822]\n",
      "epoch:18 step:16898 [D loss: 0.406537, acc.: 88.28%] [G loss: 1.216645]\n",
      "epoch:18 step:16899 [D loss: 0.354208, acc.: 92.19%] [G loss: 1.172686]\n",
      "epoch:18 step:16900 [D loss: 0.474488, acc.: 82.03%] [G loss: 1.272879]\n",
      "epoch:18 step:16901 [D loss: 0.470311, acc.: 78.12%] [G loss: 1.221272]\n",
      "epoch:18 step:16902 [D loss: 0.507321, acc.: 72.66%] [G loss: 1.230658]\n",
      "epoch:18 step:16903 [D loss: 0.791438, acc.: 51.56%] [G loss: 1.302166]\n",
      "epoch:18 step:16904 [D loss: 0.899570, acc.: 46.88%] [G loss: 1.190535]\n",
      "epoch:18 step:16905 [D loss: 0.717126, acc.: 57.81%] [G loss: 1.069084]\n",
      "epoch:18 step:16906 [D loss: 0.736648, acc.: 52.34%] [G loss: 1.054206]\n",
      "epoch:18 step:16907 [D loss: 0.702922, acc.: 58.59%] [G loss: 1.064722]\n",
      "epoch:18 step:16908 [D loss: 0.615544, acc.: 65.62%] [G loss: 1.003691]\n",
      "epoch:18 step:16909 [D loss: 0.666111, acc.: 57.03%] [G loss: 0.850044]\n",
      "epoch:18 step:16910 [D loss: 0.571795, acc.: 68.75%] [G loss: 1.050108]\n",
      "epoch:18 step:16911 [D loss: 0.645334, acc.: 60.94%] [G loss: 1.072068]\n",
      "epoch:18 step:16912 [D loss: 0.754802, acc.: 50.00%] [G loss: 0.682858]\n",
      "epoch:18 step:16913 [D loss: 0.595851, acc.: 67.19%] [G loss: 0.909576]\n",
      "epoch:18 step:16914 [D loss: 0.713555, acc.: 55.47%] [G loss: 0.944179]\n",
      "epoch:18 step:16915 [D loss: 0.577669, acc.: 71.09%] [G loss: 1.013911]\n",
      "epoch:18 step:16916 [D loss: 0.559218, acc.: 73.44%] [G loss: 0.959733]\n",
      "epoch:18 step:16917 [D loss: 0.609663, acc.: 64.84%] [G loss: 1.209537]\n",
      "epoch:18 step:16918 [D loss: 0.615792, acc.: 67.97%] [G loss: 1.083415]\n",
      "epoch:18 step:16919 [D loss: 0.532313, acc.: 77.34%] [G loss: 1.159132]\n",
      "epoch:18 step:16920 [D loss: 0.444708, acc.: 84.38%] [G loss: 1.257288]\n",
      "epoch:18 step:16921 [D loss: 0.612159, acc.: 66.41%] [G loss: 1.039236]\n",
      "epoch:18 step:16922 [D loss: 0.591227, acc.: 68.75%] [G loss: 1.239978]\n",
      "epoch:18 step:16923 [D loss: 0.689100, acc.: 60.16%] [G loss: 1.042726]\n",
      "epoch:18 step:16924 [D loss: 0.726657, acc.: 49.22%] [G loss: 0.877206]\n",
      "epoch:18 step:16925 [D loss: 0.751561, acc.: 53.91%] [G loss: 0.933006]\n",
      "epoch:18 step:16926 [D loss: 0.701701, acc.: 57.03%] [G loss: 1.019895]\n",
      "epoch:18 step:16927 [D loss: 0.598059, acc.: 67.19%] [G loss: 1.005529]\n",
      "epoch:18 step:16928 [D loss: 0.653770, acc.: 63.28%] [G loss: 1.141249]\n",
      "epoch:18 step:16929 [D loss: 0.729299, acc.: 56.25%] [G loss: 0.858846]\n",
      "epoch:18 step:16930 [D loss: 0.491586, acc.: 78.91%] [G loss: 1.274848]\n",
      "epoch:18 step:16931 [D loss: 0.602243, acc.: 65.62%] [G loss: 0.868979]\n",
      "epoch:18 step:16932 [D loss: 0.643592, acc.: 61.72%] [G loss: 1.077543]\n",
      "epoch:18 step:16933 [D loss: 0.731760, acc.: 50.78%] [G loss: 1.008978]\n",
      "epoch:18 step:16934 [D loss: 0.546211, acc.: 75.00%] [G loss: 1.019984]\n",
      "epoch:18 step:16935 [D loss: 0.537830, acc.: 75.00%] [G loss: 1.051997]\n",
      "epoch:18 step:16936 [D loss: 0.750821, acc.: 46.88%] [G loss: 0.988287]\n",
      "epoch:18 step:16937 [D loss: 0.605008, acc.: 68.75%] [G loss: 1.238587]\n",
      "epoch:18 step:16938 [D loss: 0.552315, acc.: 67.19%] [G loss: 1.260406]\n",
      "epoch:18 step:16939 [D loss: 0.454691, acc.: 83.59%] [G loss: 1.107995]\n",
      "epoch:18 step:16940 [D loss: 0.393127, acc.: 90.62%] [G loss: 1.275107]\n",
      "epoch:18 step:16941 [D loss: 0.317055, acc.: 91.41%] [G loss: 1.335337]\n",
      "epoch:18 step:16942 [D loss: 0.290798, acc.: 94.53%] [G loss: 1.541345]\n",
      "epoch:18 step:16943 [D loss: 0.351151, acc.: 93.75%] [G loss: 1.542486]\n",
      "epoch:18 step:16944 [D loss: 0.670992, acc.: 57.81%] [G loss: 1.317240]\n",
      "epoch:18 step:16945 [D loss: 0.623804, acc.: 65.62%] [G loss: 1.080654]\n",
      "epoch:18 step:16946 [D loss: 0.598843, acc.: 67.19%] [G loss: 0.990924]\n",
      "epoch:18 step:16947 [D loss: 0.685398, acc.: 55.47%] [G loss: 0.943694]\n",
      "epoch:18 step:16948 [D loss: 0.812806, acc.: 49.22%] [G loss: 0.917887]\n",
      "epoch:18 step:16949 [D loss: 0.758630, acc.: 43.75%] [G loss: 0.921132]\n",
      "epoch:18 step:16950 [D loss: 0.720181, acc.: 50.00%] [G loss: 1.030841]\n",
      "epoch:18 step:16951 [D loss: 0.575033, acc.: 68.75%] [G loss: 1.073653]\n",
      "epoch:18 step:16952 [D loss: 0.628701, acc.: 63.28%] [G loss: 1.033082]\n",
      "epoch:18 step:16953 [D loss: 0.802055, acc.: 47.66%] [G loss: 0.989424]\n",
      "epoch:18 step:16954 [D loss: 0.716520, acc.: 56.25%] [G loss: 1.051015]\n",
      "epoch:18 step:16955 [D loss: 0.752203, acc.: 50.00%] [G loss: 1.043887]\n",
      "epoch:18 step:16956 [D loss: 0.838464, acc.: 35.94%] [G loss: 1.038518]\n",
      "epoch:18 step:16957 [D loss: 0.636432, acc.: 64.84%] [G loss: 1.113510]\n",
      "epoch:18 step:16958 [D loss: 0.583443, acc.: 71.09%] [G loss: 1.176605]\n",
      "epoch:18 step:16959 [D loss: 0.579733, acc.: 68.75%] [G loss: 0.948307]\n",
      "epoch:18 step:16960 [D loss: 0.599001, acc.: 70.31%] [G loss: 1.043335]\n",
      "epoch:18 step:16961 [D loss: 0.713173, acc.: 56.25%] [G loss: 0.870909]\n",
      "epoch:18 step:16962 [D loss: 0.741093, acc.: 49.22%] [G loss: 0.906798]\n",
      "epoch:18 step:16963 [D loss: 0.635421, acc.: 60.94%] [G loss: 0.986905]\n",
      "epoch:18 step:16964 [D loss: 0.608591, acc.: 71.09%] [G loss: 0.930424]\n",
      "epoch:18 step:16965 [D loss: 0.704860, acc.: 48.44%] [G loss: 0.920617]\n",
      "epoch:18 step:16966 [D loss: 0.542995, acc.: 80.47%] [G loss: 1.049584]\n",
      "epoch:18 step:16967 [D loss: 0.643434, acc.: 64.06%] [G loss: 0.900544]\n",
      "epoch:18 step:16968 [D loss: 0.552553, acc.: 73.44%] [G loss: 1.027421]\n",
      "epoch:18 step:16969 [D loss: 0.511780, acc.: 76.56%] [G loss: 1.127298]\n",
      "epoch:18 step:16970 [D loss: 0.634730, acc.: 64.84%] [G loss: 0.884496]\n",
      "epoch:18 step:16971 [D loss: 0.586311, acc.: 71.09%] [G loss: 1.145643]\n",
      "epoch:18 step:16972 [D loss: 0.686729, acc.: 53.91%] [G loss: 1.192137]\n",
      "epoch:18 step:16973 [D loss: 0.745572, acc.: 49.22%] [G loss: 1.143836]\n",
      "epoch:18 step:16974 [D loss: 0.682648, acc.: 61.72%] [G loss: 0.736321]\n",
      "epoch:18 step:16975 [D loss: 0.696064, acc.: 59.38%] [G loss: 1.012177]\n",
      "epoch:18 step:16976 [D loss: 0.599061, acc.: 65.62%] [G loss: 1.039070]\n",
      "epoch:18 step:16977 [D loss: 0.635973, acc.: 63.28%] [G loss: 0.990809]\n",
      "epoch:18 step:16978 [D loss: 0.621531, acc.: 72.66%] [G loss: 0.853892]\n",
      "epoch:18 step:16979 [D loss: 0.641801, acc.: 64.84%] [G loss: 1.120957]\n",
      "epoch:18 step:16980 [D loss: 0.723150, acc.: 52.34%] [G loss: 0.913496]\n",
      "epoch:18 step:16981 [D loss: 0.628667, acc.: 67.97%] [G loss: 1.101062]\n",
      "epoch:18 step:16982 [D loss: 0.640653, acc.: 60.94%] [G loss: 0.996117]\n",
      "epoch:18 step:16983 [D loss: 0.740277, acc.: 48.44%] [G loss: 1.244090]\n",
      "epoch:18 step:16984 [D loss: 0.718240, acc.: 56.25%] [G loss: 0.916443]\n",
      "epoch:18 step:16985 [D loss: 0.435613, acc.: 88.28%] [G loss: 0.861354]\n",
      "epoch:18 step:16986 [D loss: 0.531051, acc.: 72.66%] [G loss: 1.155836]\n",
      "epoch:18 step:16987 [D loss: 0.316229, acc.: 93.75%] [G loss: 1.190735]\n",
      "epoch:18 step:16988 [D loss: 0.355111, acc.: 89.06%] [G loss: 1.003407]\n",
      "epoch:18 step:16989 [D loss: 0.676231, acc.: 57.81%] [G loss: 1.264654]\n",
      "epoch:18 step:16990 [D loss: 0.780619, acc.: 46.88%] [G loss: 1.021575]\n",
      "epoch:18 step:16991 [D loss: 0.826202, acc.: 42.97%] [G loss: 0.836390]\n",
      "epoch:18 step:16992 [D loss: 0.662628, acc.: 60.94%] [G loss: 1.046818]\n",
      "epoch:18 step:16993 [D loss: 0.686314, acc.: 53.12%] [G loss: 0.967031]\n",
      "epoch:18 step:16994 [D loss: 0.576457, acc.: 72.66%] [G loss: 0.946291]\n",
      "epoch:18 step:16995 [D loss: 0.571960, acc.: 70.31%] [G loss: 1.028816]\n",
      "epoch:18 step:16996 [D loss: 0.491109, acc.: 79.69%] [G loss: 1.186847]\n",
      "epoch:18 step:16997 [D loss: 0.440589, acc.: 85.16%] [G loss: 1.273620]\n",
      "epoch:18 step:16998 [D loss: 0.557825, acc.: 71.09%] [G loss: 1.163393]\n",
      "epoch:18 step:16999 [D loss: 0.765980, acc.: 47.66%] [G loss: 0.997948]\n",
      "epoch:18 step:17000 [D loss: 0.625795, acc.: 63.28%] [G loss: 0.999336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17001 [D loss: 0.682582, acc.: 57.81%] [G loss: 0.968454]\n",
      "epoch:18 step:17002 [D loss: 0.710531, acc.: 50.78%] [G loss: 1.059157]\n",
      "epoch:18 step:17003 [D loss: 0.667422, acc.: 58.59%] [G loss: 1.112998]\n",
      "epoch:18 step:17004 [D loss: 0.672094, acc.: 56.25%] [G loss: 0.997947]\n",
      "epoch:18 step:17005 [D loss: 0.661915, acc.: 61.72%] [G loss: 0.993419]\n",
      "epoch:18 step:17006 [D loss: 0.671712, acc.: 57.81%] [G loss: 0.841883]\n",
      "epoch:18 step:17007 [D loss: 0.721206, acc.: 48.44%] [G loss: 0.965941]\n",
      "epoch:18 step:17008 [D loss: 0.483670, acc.: 78.91%] [G loss: 1.140885]\n",
      "epoch:18 step:17009 [D loss: 0.492684, acc.: 81.25%] [G loss: 1.333110]\n",
      "epoch:18 step:17010 [D loss: 0.500197, acc.: 80.47%] [G loss: 1.279050]\n",
      "epoch:18 step:17011 [D loss: 0.425682, acc.: 89.84%] [G loss: 1.381270]\n",
      "epoch:18 step:17012 [D loss: 0.506519, acc.: 79.69%] [G loss: 1.600637]\n",
      "epoch:18 step:17013 [D loss: 0.757099, acc.: 50.00%] [G loss: 0.956309]\n",
      "epoch:18 step:17014 [D loss: 0.957916, acc.: 30.47%] [G loss: 0.876983]\n",
      "epoch:18 step:17015 [D loss: 0.523283, acc.: 76.56%] [G loss: 1.352763]\n",
      "epoch:18 step:17016 [D loss: 0.401549, acc.: 87.50%] [G loss: 1.148053]\n",
      "epoch:18 step:17017 [D loss: 0.488926, acc.: 75.78%] [G loss: 1.033752]\n",
      "epoch:18 step:17018 [D loss: 0.466058, acc.: 78.12%] [G loss: 1.287921]\n",
      "epoch:18 step:17019 [D loss: 0.831046, acc.: 46.09%] [G loss: 0.959300]\n",
      "epoch:18 step:17020 [D loss: 0.719651, acc.: 56.25%] [G loss: 1.448622]\n",
      "epoch:18 step:17021 [D loss: 0.782945, acc.: 40.62%] [G loss: 0.927293]\n",
      "epoch:18 step:17022 [D loss: 0.675002, acc.: 57.81%] [G loss: 1.174137]\n",
      "epoch:18 step:17023 [D loss: 0.729130, acc.: 52.34%] [G loss: 1.152661]\n",
      "epoch:18 step:17024 [D loss: 0.696235, acc.: 53.91%] [G loss: 0.863305]\n",
      "epoch:18 step:17025 [D loss: 0.626100, acc.: 66.41%] [G loss: 1.043915]\n",
      "epoch:18 step:17026 [D loss: 0.708817, acc.: 48.44%] [G loss: 1.104740]\n",
      "epoch:18 step:17027 [D loss: 0.791228, acc.: 48.44%] [G loss: 0.860885]\n",
      "epoch:18 step:17028 [D loss: 0.534469, acc.: 76.56%] [G loss: 1.109883]\n",
      "epoch:18 step:17029 [D loss: 0.586076, acc.: 69.53%] [G loss: 0.954165]\n",
      "epoch:18 step:17030 [D loss: 0.540958, acc.: 76.56%] [G loss: 1.021930]\n",
      "epoch:18 step:17031 [D loss: 0.550615, acc.: 74.22%] [G loss: 0.850543]\n",
      "epoch:18 step:17032 [D loss: 0.465451, acc.: 83.59%] [G loss: 1.054410]\n",
      "epoch:18 step:17033 [D loss: 0.515098, acc.: 72.66%] [G loss: 1.063706]\n",
      "epoch:18 step:17034 [D loss: 0.503279, acc.: 77.34%] [G loss: 1.038006]\n",
      "epoch:18 step:17035 [D loss: 0.572052, acc.: 68.75%] [G loss: 1.178140]\n",
      "epoch:18 step:17036 [D loss: 0.614361, acc.: 64.06%] [G loss: 1.315308]\n",
      "epoch:18 step:17037 [D loss: 0.638449, acc.: 62.50%] [G loss: 0.972203]\n",
      "epoch:18 step:17038 [D loss: 0.454416, acc.: 86.72%] [G loss: 0.862076]\n",
      "epoch:18 step:17039 [D loss: 0.671756, acc.: 55.47%] [G loss: 1.144082]\n",
      "epoch:18 step:17040 [D loss: 0.648850, acc.: 64.84%] [G loss: 1.098275]\n",
      "epoch:18 step:17041 [D loss: 0.633607, acc.: 64.06%] [G loss: 0.876259]\n",
      "epoch:18 step:17042 [D loss: 0.615519, acc.: 66.41%] [G loss: 0.983839]\n",
      "epoch:18 step:17043 [D loss: 0.729587, acc.: 50.00%] [G loss: 1.276522]\n",
      "epoch:18 step:17044 [D loss: 0.836568, acc.: 43.75%] [G loss: 0.911509]\n",
      "epoch:18 step:17045 [D loss: 0.900427, acc.: 35.94%] [G loss: 0.840923]\n",
      "epoch:18 step:17046 [D loss: 0.673030, acc.: 57.81%] [G loss: 0.840870]\n",
      "epoch:18 step:17047 [D loss: 0.809697, acc.: 39.06%] [G loss: 0.710240]\n",
      "epoch:18 step:17048 [D loss: 0.665514, acc.: 60.94%] [G loss: 1.011077]\n",
      "epoch:18 step:17049 [D loss: 0.752447, acc.: 56.25%] [G loss: 1.035100]\n",
      "epoch:18 step:17050 [D loss: 0.791968, acc.: 46.09%] [G loss: 0.918270]\n",
      "epoch:18 step:17051 [D loss: 0.991521, acc.: 34.38%] [G loss: 0.801489]\n",
      "epoch:18 step:17052 [D loss: 0.854146, acc.: 35.16%] [G loss: 1.002451]\n",
      "epoch:18 step:17053 [D loss: 1.043005, acc.: 26.56%] [G loss: 0.804965]\n",
      "epoch:18 step:17054 [D loss: 0.558656, acc.: 71.88%] [G loss: 1.314395]\n",
      "epoch:18 step:17055 [D loss: 0.857182, acc.: 38.28%] [G loss: 0.888872]\n",
      "epoch:18 step:17056 [D loss: 0.777286, acc.: 48.44%] [G loss: 1.078576]\n",
      "epoch:18 step:17057 [D loss: 0.650216, acc.: 60.16%] [G loss: 0.957577]\n",
      "epoch:18 step:17058 [D loss: 0.413389, acc.: 88.28%] [G loss: 1.211917]\n",
      "epoch:18 step:17059 [D loss: 0.656801, acc.: 63.28%] [G loss: 0.821386]\n",
      "epoch:18 step:17060 [D loss: 0.631729, acc.: 57.81%] [G loss: 0.887385]\n",
      "epoch:18 step:17061 [D loss: 0.752334, acc.: 54.69%] [G loss: 0.927087]\n",
      "epoch:18 step:17062 [D loss: 0.854264, acc.: 35.94%] [G loss: 1.039429]\n",
      "epoch:18 step:17063 [D loss: 0.711420, acc.: 53.91%] [G loss: 0.925870]\n",
      "epoch:18 step:17064 [D loss: 0.749415, acc.: 54.69%] [G loss: 1.349894]\n",
      "epoch:18 step:17065 [D loss: 0.793206, acc.: 46.88%] [G loss: 1.082976]\n",
      "epoch:18 step:17066 [D loss: 0.817797, acc.: 39.84%] [G loss: 1.041423]\n",
      "epoch:18 step:17067 [D loss: 0.597856, acc.: 67.19%] [G loss: 1.145932]\n",
      "epoch:18 step:17068 [D loss: 0.768604, acc.: 50.00%] [G loss: 1.114695]\n",
      "epoch:18 step:17069 [D loss: 0.719946, acc.: 52.34%] [G loss: 0.992902]\n",
      "epoch:18 step:17070 [D loss: 0.729191, acc.: 51.56%] [G loss: 0.808947]\n",
      "epoch:18 step:17071 [D loss: 0.652461, acc.: 62.50%] [G loss: 1.120727]\n",
      "epoch:18 step:17072 [D loss: 0.582982, acc.: 71.88%] [G loss: 0.921266]\n",
      "epoch:18 step:17073 [D loss: 0.667914, acc.: 60.94%] [G loss: 0.782588]\n",
      "epoch:18 step:17074 [D loss: 0.673859, acc.: 60.94%] [G loss: 1.000234]\n",
      "epoch:18 step:17075 [D loss: 0.695511, acc.: 58.59%] [G loss: 1.075101]\n",
      "epoch:18 step:17076 [D loss: 0.606899, acc.: 66.41%] [G loss: 0.928273]\n",
      "epoch:18 step:17077 [D loss: 0.535156, acc.: 73.44%] [G loss: 1.078437]\n",
      "epoch:18 step:17078 [D loss: 0.593463, acc.: 68.75%] [G loss: 1.152112]\n",
      "epoch:18 step:17079 [D loss: 0.485096, acc.: 78.91%] [G loss: 0.960593]\n",
      "epoch:18 step:17080 [D loss: 0.659628, acc.: 58.59%] [G loss: 1.101850]\n",
      "epoch:18 step:17081 [D loss: 0.383226, acc.: 85.16%] [G loss: 1.511484]\n",
      "epoch:18 step:17082 [D loss: 0.391011, acc.: 90.62%] [G loss: 1.354824]\n",
      "epoch:18 step:17083 [D loss: 0.733879, acc.: 53.91%] [G loss: 1.023365]\n",
      "epoch:18 step:17084 [D loss: 0.778431, acc.: 47.66%] [G loss: 1.016886]\n",
      "epoch:18 step:17085 [D loss: 0.714657, acc.: 53.12%] [G loss: 0.919407]\n",
      "epoch:18 step:17086 [D loss: 0.425680, acc.: 75.00%] [G loss: 0.989343]\n",
      "epoch:18 step:17087 [D loss: 0.287412, acc.: 92.97%] [G loss: 1.433282]\n",
      "epoch:18 step:17088 [D loss: 0.298429, acc.: 93.75%] [G loss: 1.664975]\n",
      "epoch:18 step:17089 [D loss: 0.268966, acc.: 96.88%] [G loss: 1.575219]\n",
      "epoch:18 step:17090 [D loss: 0.758682, acc.: 57.81%] [G loss: 1.134392]\n",
      "epoch:18 step:17091 [D loss: 0.725256, acc.: 57.81%] [G loss: 1.125950]\n",
      "epoch:18 step:17092 [D loss: 0.581894, acc.: 64.06%] [G loss: 0.938934]\n",
      "epoch:18 step:17093 [D loss: 0.677382, acc.: 54.69%] [G loss: 1.041601]\n",
      "epoch:18 step:17094 [D loss: 0.615878, acc.: 62.50%] [G loss: 1.052486]\n",
      "epoch:18 step:17095 [D loss: 0.491586, acc.: 77.34%] [G loss: 1.139873]\n",
      "epoch:18 step:17096 [D loss: 0.387736, acc.: 81.25%] [G loss: 1.138522]\n",
      "epoch:18 step:17097 [D loss: 0.294155, acc.: 94.53%] [G loss: 1.430707]\n",
      "epoch:18 step:17098 [D loss: 0.373413, acc.: 85.16%] [G loss: 1.505506]\n",
      "epoch:18 step:17099 [D loss: 0.901841, acc.: 48.44%] [G loss: 1.205286]\n",
      "epoch:18 step:17100 [D loss: 0.913695, acc.: 39.84%] [G loss: 0.981394]\n",
      "epoch:18 step:17101 [D loss: 0.553502, acc.: 74.22%] [G loss: 1.167955]\n",
      "epoch:18 step:17102 [D loss: 0.713531, acc.: 56.25%] [G loss: 0.990811]\n",
      "epoch:18 step:17103 [D loss: 0.597553, acc.: 70.31%] [G loss: 1.095393]\n",
      "epoch:18 step:17104 [D loss: 0.738704, acc.: 53.91%] [G loss: 0.821066]\n",
      "epoch:18 step:17105 [D loss: 0.894443, acc.: 34.38%] [G loss: 0.834283]\n",
      "epoch:18 step:17106 [D loss: 0.822272, acc.: 42.97%] [G loss: 0.998314]\n",
      "epoch:18 step:17107 [D loss: 0.764549, acc.: 50.78%] [G loss: 1.317435]\n",
      "epoch:18 step:17108 [D loss: 1.019289, acc.: 32.03%] [G loss: 0.822714]\n",
      "epoch:18 step:17109 [D loss: 0.526373, acc.: 72.66%] [G loss: 1.263769]\n",
      "epoch:18 step:17110 [D loss: 0.613822, acc.: 65.62%] [G loss: 1.199290]\n",
      "epoch:18 step:17111 [D loss: 0.632274, acc.: 65.62%] [G loss: 1.101030]\n",
      "epoch:18 step:17112 [D loss: 0.490060, acc.: 82.03%] [G loss: 1.222969]\n",
      "epoch:18 step:17113 [D loss: 0.576544, acc.: 72.66%] [G loss: 1.221413]\n",
      "epoch:18 step:17114 [D loss: 0.423145, acc.: 86.72%] [G loss: 1.186754]\n",
      "epoch:18 step:17115 [D loss: 0.580924, acc.: 74.22%] [G loss: 1.287141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17116 [D loss: 0.575813, acc.: 71.09%] [G loss: 1.075777]\n",
      "epoch:18 step:17117 [D loss: 0.508829, acc.: 82.03%] [G loss: 1.187624]\n",
      "epoch:18 step:17118 [D loss: 0.504976, acc.: 78.91%] [G loss: 1.048586]\n",
      "epoch:18 step:17119 [D loss: 0.638622, acc.: 67.97%] [G loss: 0.872208]\n",
      "epoch:18 step:17120 [D loss: 0.542355, acc.: 69.53%] [G loss: 1.039547]\n",
      "epoch:18 step:17121 [D loss: 0.694016, acc.: 60.16%] [G loss: 0.914524]\n",
      "epoch:18 step:17122 [D loss: 0.691069, acc.: 56.25%] [G loss: 1.065927]\n",
      "epoch:18 step:17123 [D loss: 0.664419, acc.: 57.03%] [G loss: 0.950028]\n",
      "epoch:18 step:17124 [D loss: 0.634508, acc.: 61.72%] [G loss: 0.839601]\n",
      "epoch:18 step:17125 [D loss: 0.635900, acc.: 67.19%] [G loss: 1.126589]\n",
      "epoch:18 step:17126 [D loss: 0.674026, acc.: 60.94%] [G loss: 1.098390]\n",
      "epoch:18 step:17127 [D loss: 0.616884, acc.: 64.84%] [G loss: 1.119155]\n",
      "epoch:18 step:17128 [D loss: 0.690344, acc.: 61.72%] [G loss: 1.122905]\n",
      "epoch:18 step:17129 [D loss: 0.466975, acc.: 79.69%] [G loss: 1.053095]\n",
      "epoch:18 step:17130 [D loss: 0.532439, acc.: 73.44%] [G loss: 1.100560]\n",
      "epoch:18 step:17131 [D loss: 0.671975, acc.: 55.47%] [G loss: 1.140729]\n",
      "epoch:18 step:17132 [D loss: 0.794855, acc.: 42.19%] [G loss: 1.122923]\n",
      "epoch:18 step:17133 [D loss: 0.714145, acc.: 51.56%] [G loss: 1.076191]\n",
      "epoch:18 step:17134 [D loss: 0.626314, acc.: 61.72%] [G loss: 1.109988]\n",
      "epoch:18 step:17135 [D loss: 0.536040, acc.: 72.66%] [G loss: 1.049602]\n",
      "epoch:18 step:17136 [D loss: 0.538029, acc.: 76.56%] [G loss: 1.108294]\n",
      "epoch:18 step:17137 [D loss: 0.577170, acc.: 72.66%] [G loss: 1.022266]\n",
      "epoch:18 step:17138 [D loss: 0.471361, acc.: 75.00%] [G loss: 1.253891]\n",
      "epoch:18 step:17139 [D loss: 0.592419, acc.: 70.31%] [G loss: 1.156228]\n",
      "epoch:18 step:17140 [D loss: 0.578758, acc.: 71.09%] [G loss: 1.276165]\n",
      "epoch:18 step:17141 [D loss: 0.678708, acc.: 59.38%] [G loss: 1.108338]\n",
      "epoch:18 step:17142 [D loss: 0.848397, acc.: 42.19%] [G loss: 0.855861]\n",
      "epoch:18 step:17143 [D loss: 0.789241, acc.: 48.44%] [G loss: 1.134419]\n",
      "epoch:18 step:17144 [D loss: 0.706303, acc.: 56.25%] [G loss: 0.898408]\n",
      "epoch:18 step:17145 [D loss: 0.450521, acc.: 85.94%] [G loss: 1.250247]\n",
      "epoch:18 step:17146 [D loss: 0.586932, acc.: 71.09%] [G loss: 1.219483]\n",
      "epoch:18 step:17147 [D loss: 0.787456, acc.: 45.31%] [G loss: 1.058542]\n",
      "epoch:18 step:17148 [D loss: 0.514800, acc.: 77.34%] [G loss: 1.012974]\n",
      "epoch:18 step:17149 [D loss: 0.641563, acc.: 64.84%] [G loss: 1.056353]\n",
      "epoch:18 step:17150 [D loss: 0.487582, acc.: 78.12%] [G loss: 1.097179]\n",
      "epoch:18 step:17151 [D loss: 0.458609, acc.: 80.47%] [G loss: 1.014770]\n",
      "epoch:18 step:17152 [D loss: 0.404220, acc.: 89.84%] [G loss: 1.114973]\n",
      "epoch:18 step:17153 [D loss: 0.544747, acc.: 75.78%] [G loss: 1.166000]\n",
      "epoch:18 step:17154 [D loss: 0.634304, acc.: 60.16%] [G loss: 0.990493]\n",
      "epoch:18 step:17155 [D loss: 0.455922, acc.: 85.16%] [G loss: 1.106208]\n",
      "epoch:18 step:17156 [D loss: 0.736267, acc.: 49.22%] [G loss: 1.032600]\n",
      "epoch:18 step:17157 [D loss: 0.398892, acc.: 87.50%] [G loss: 1.339517]\n",
      "epoch:18 step:17158 [D loss: 0.535971, acc.: 74.22%] [G loss: 1.368598]\n",
      "epoch:18 step:17159 [D loss: 0.661661, acc.: 54.69%] [G loss: 1.146721]\n",
      "epoch:18 step:17160 [D loss: 0.683998, acc.: 64.06%] [G loss: 1.101666]\n",
      "epoch:18 step:17161 [D loss: 0.805971, acc.: 51.56%] [G loss: 1.165913]\n",
      "epoch:18 step:17162 [D loss: 0.652251, acc.: 59.38%] [G loss: 0.992666]\n",
      "epoch:18 step:17163 [D loss: 0.722805, acc.: 56.25%] [G loss: 0.859808]\n",
      "epoch:18 step:17164 [D loss: 0.592738, acc.: 65.62%] [G loss: 1.273342]\n",
      "epoch:18 step:17165 [D loss: 0.638560, acc.: 60.94%] [G loss: 0.966607]\n",
      "epoch:18 step:17166 [D loss: 0.649021, acc.: 64.84%] [G loss: 1.104414]\n",
      "epoch:18 step:17167 [D loss: 0.704591, acc.: 57.81%] [G loss: 1.183473]\n",
      "epoch:18 step:17168 [D loss: 0.696182, acc.: 53.12%] [G loss: 0.943901]\n",
      "epoch:18 step:17169 [D loss: 0.736471, acc.: 50.78%] [G loss: 0.961754]\n",
      "epoch:18 step:17170 [D loss: 0.535909, acc.: 75.78%] [G loss: 1.129455]\n",
      "epoch:18 step:17171 [D loss: 0.772956, acc.: 47.66%] [G loss: 0.910538]\n",
      "epoch:18 step:17172 [D loss: 0.729172, acc.: 53.12%] [G loss: 0.982367]\n",
      "epoch:18 step:17173 [D loss: 0.649705, acc.: 62.50%] [G loss: 0.899951]\n",
      "epoch:18 step:17174 [D loss: 0.542393, acc.: 75.78%] [G loss: 0.965966]\n",
      "epoch:18 step:17175 [D loss: 0.639468, acc.: 61.72%] [G loss: 0.971347]\n",
      "epoch:18 step:17176 [D loss: 0.647368, acc.: 57.03%] [G loss: 1.052564]\n",
      "epoch:18 step:17177 [D loss: 0.587882, acc.: 69.53%] [G loss: 1.031262]\n",
      "epoch:18 step:17178 [D loss: 0.523793, acc.: 77.34%] [G loss: 0.946637]\n",
      "epoch:18 step:17179 [D loss: 0.459187, acc.: 79.69%] [G loss: 1.301219]\n",
      "epoch:18 step:17180 [D loss: 0.357100, acc.: 90.62%] [G loss: 1.306766]\n",
      "epoch:18 step:17181 [D loss: 0.563881, acc.: 70.31%] [G loss: 1.138538]\n",
      "epoch:18 step:17182 [D loss: 0.942084, acc.: 32.03%] [G loss: 1.054512]\n",
      "epoch:18 step:17183 [D loss: 0.608507, acc.: 66.41%] [G loss: 1.140442]\n",
      "epoch:18 step:17184 [D loss: 0.571001, acc.: 70.31%] [G loss: 1.223410]\n",
      "epoch:18 step:17185 [D loss: 0.540973, acc.: 74.22%] [G loss: 1.085293]\n",
      "epoch:18 step:17186 [D loss: 0.595289, acc.: 71.88%] [G loss: 1.057956]\n",
      "epoch:18 step:17187 [D loss: 0.513143, acc.: 79.69%] [G loss: 1.027942]\n",
      "epoch:18 step:17188 [D loss: 0.524963, acc.: 78.12%] [G loss: 1.040713]\n",
      "epoch:18 step:17189 [D loss: 0.837684, acc.: 41.41%] [G loss: 1.124201]\n",
      "epoch:18 step:17190 [D loss: 0.798256, acc.: 42.19%] [G loss: 0.887861]\n",
      "epoch:18 step:17191 [D loss: 0.602345, acc.: 66.41%] [G loss: 0.930059]\n",
      "epoch:18 step:17192 [D loss: 0.653653, acc.: 64.06%] [G loss: 1.023256]\n",
      "epoch:18 step:17193 [D loss: 0.458264, acc.: 84.38%] [G loss: 1.075318]\n",
      "epoch:18 step:17194 [D loss: 0.478776, acc.: 82.03%] [G loss: 1.146871]\n",
      "epoch:18 step:17195 [D loss: 0.681296, acc.: 64.84%] [G loss: 1.328420]\n",
      "epoch:18 step:17196 [D loss: 0.662671, acc.: 57.03%] [G loss: 1.298838]\n",
      "epoch:18 step:17197 [D loss: 0.826777, acc.: 42.19%] [G loss: 0.978327]\n",
      "epoch:18 step:17198 [D loss: 0.618087, acc.: 61.72%] [G loss: 0.951321]\n",
      "epoch:18 step:17199 [D loss: 0.704722, acc.: 53.91%] [G loss: 1.096909]\n",
      "epoch:18 step:17200 [D loss: 0.720341, acc.: 55.47%] [G loss: 1.151341]\n",
      "epoch:18 step:17201 [D loss: 0.655945, acc.: 59.38%] [G loss: 1.003606]\n",
      "epoch:18 step:17202 [D loss: 0.620567, acc.: 67.19%] [G loss: 0.990731]\n",
      "epoch:18 step:17203 [D loss: 0.624849, acc.: 64.84%] [G loss: 1.169092]\n",
      "epoch:18 step:17204 [D loss: 0.630994, acc.: 65.62%] [G loss: 1.073182]\n",
      "epoch:18 step:17205 [D loss: 0.672045, acc.: 60.16%] [G loss: 0.836710]\n",
      "epoch:18 step:17206 [D loss: 0.629745, acc.: 67.19%] [G loss: 0.797278]\n",
      "epoch:18 step:17207 [D loss: 0.603672, acc.: 65.62%] [G loss: 1.122311]\n",
      "epoch:18 step:17208 [D loss: 0.447585, acc.: 81.25%] [G loss: 1.188284]\n",
      "epoch:18 step:17209 [D loss: 0.333040, acc.: 93.75%] [G loss: 1.282898]\n",
      "epoch:18 step:17210 [D loss: 0.442823, acc.: 84.38%] [G loss: 1.201004]\n",
      "epoch:18 step:17211 [D loss: 0.340172, acc.: 88.28%] [G loss: 1.148831]\n",
      "epoch:18 step:17212 [D loss: 0.396729, acc.: 91.41%] [G loss: 1.374715]\n",
      "epoch:18 step:17213 [D loss: 0.379750, acc.: 89.06%] [G loss: 1.286189]\n",
      "epoch:18 step:17214 [D loss: 0.742835, acc.: 54.69%] [G loss: 1.354789]\n",
      "epoch:18 step:17215 [D loss: 1.007034, acc.: 26.56%] [G loss: 0.949097]\n",
      "epoch:18 step:17216 [D loss: 0.667571, acc.: 53.12%] [G loss: 1.111192]\n",
      "epoch:18 step:17217 [D loss: 0.502108, acc.: 79.69%] [G loss: 1.138234]\n",
      "epoch:18 step:17218 [D loss: 0.567963, acc.: 71.88%] [G loss: 1.070269]\n",
      "epoch:18 step:17219 [D loss: 0.567144, acc.: 70.31%] [G loss: 1.117699]\n",
      "epoch:18 step:17220 [D loss: 0.390445, acc.: 86.72%] [G loss: 1.335935]\n",
      "epoch:18 step:17221 [D loss: 0.734889, acc.: 51.56%] [G loss: 1.123967]\n",
      "epoch:18 step:17222 [D loss: 0.604076, acc.: 70.31%] [G loss: 1.169426]\n",
      "epoch:18 step:17223 [D loss: 0.507464, acc.: 76.56%] [G loss: 1.152944]\n",
      "epoch:18 step:17224 [D loss: 0.619594, acc.: 64.06%] [G loss: 1.069657]\n",
      "epoch:18 step:17225 [D loss: 0.412309, acc.: 87.50%] [G loss: 1.364734]\n",
      "epoch:18 step:17226 [D loss: 0.557673, acc.: 72.66%] [G loss: 0.975925]\n",
      "epoch:18 step:17227 [D loss: 0.828175, acc.: 39.84%] [G loss: 0.881608]\n",
      "epoch:18 step:17228 [D loss: 0.759659, acc.: 46.88%] [G loss: 1.037962]\n",
      "epoch:18 step:17229 [D loss: 0.748911, acc.: 48.44%] [G loss: 0.947222]\n",
      "epoch:18 step:17230 [D loss: 0.717877, acc.: 54.69%] [G loss: 1.001628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17231 [D loss: 0.667080, acc.: 64.84%] [G loss: 0.943215]\n",
      "epoch:18 step:17232 [D loss: 0.611871, acc.: 64.06%] [G loss: 1.130157]\n",
      "epoch:18 step:17233 [D loss: 0.487911, acc.: 83.59%] [G loss: 1.251338]\n",
      "epoch:18 step:17234 [D loss: 0.651934, acc.: 60.16%] [G loss: 1.143412]\n",
      "epoch:18 step:17235 [D loss: 0.744663, acc.: 48.44%] [G loss: 0.989591]\n",
      "epoch:18 step:17236 [D loss: 0.552718, acc.: 72.66%] [G loss: 1.214247]\n",
      "epoch:18 step:17237 [D loss: 0.539663, acc.: 75.00%] [G loss: 1.166503]\n",
      "epoch:18 step:17238 [D loss: 0.621946, acc.: 64.06%] [G loss: 1.229021]\n",
      "epoch:18 step:17239 [D loss: 0.792601, acc.: 42.19%] [G loss: 0.967982]\n",
      "epoch:18 step:17240 [D loss: 0.681914, acc.: 56.25%] [G loss: 0.811539]\n",
      "epoch:18 step:17241 [D loss: 0.777599, acc.: 43.75%] [G loss: 0.835878]\n",
      "epoch:18 step:17242 [D loss: 0.688792, acc.: 56.25%] [G loss: 1.067368]\n",
      "epoch:18 step:17243 [D loss: 0.570364, acc.: 76.56%] [G loss: 0.907836]\n",
      "epoch:18 step:17244 [D loss: 0.437077, acc.: 83.59%] [G loss: 1.048125]\n",
      "epoch:18 step:17245 [D loss: 0.639201, acc.: 63.28%] [G loss: 0.948031]\n",
      "epoch:18 step:17246 [D loss: 0.565419, acc.: 74.22%] [G loss: 0.986331]\n",
      "epoch:18 step:17247 [D loss: 0.573960, acc.: 71.88%] [G loss: 1.008139]\n",
      "epoch:18 step:17248 [D loss: 0.706790, acc.: 56.25%] [G loss: 1.117257]\n",
      "epoch:18 step:17249 [D loss: 0.562177, acc.: 69.53%] [G loss: 1.201765]\n",
      "epoch:18 step:17250 [D loss: 0.569395, acc.: 72.66%] [G loss: 0.903862]\n",
      "epoch:18 step:17251 [D loss: 0.523123, acc.: 75.00%] [G loss: 0.918522]\n",
      "epoch:18 step:17252 [D loss: 0.692284, acc.: 61.72%] [G loss: 1.099291]\n",
      "epoch:18 step:17253 [D loss: 0.605541, acc.: 66.41%] [G loss: 1.122651]\n",
      "epoch:18 step:17254 [D loss: 0.617444, acc.: 61.72%] [G loss: 0.868647]\n",
      "epoch:18 step:17255 [D loss: 0.654522, acc.: 60.16%] [G loss: 1.120251]\n",
      "epoch:18 step:17256 [D loss: 0.571492, acc.: 74.22%] [G loss: 0.733433]\n",
      "epoch:18 step:17257 [D loss: 0.603697, acc.: 73.44%] [G loss: 0.940553]\n",
      "epoch:18 step:17258 [D loss: 0.492394, acc.: 82.03%] [G loss: 1.253389]\n",
      "epoch:18 step:17259 [D loss: 0.788339, acc.: 46.88%] [G loss: 0.796898]\n",
      "epoch:18 step:17260 [D loss: 0.747332, acc.: 50.78%] [G loss: 0.968935]\n",
      "epoch:18 step:17261 [D loss: 0.572182, acc.: 67.97%] [G loss: 1.226844]\n",
      "epoch:18 step:17262 [D loss: 0.470481, acc.: 82.81%] [G loss: 1.002728]\n",
      "epoch:18 step:17263 [D loss: 0.262288, acc.: 97.66%] [G loss: 1.508969]\n",
      "epoch:18 step:17264 [D loss: 0.329270, acc.: 90.62%] [G loss: 1.436145]\n",
      "epoch:18 step:17265 [D loss: 0.384035, acc.: 85.94%] [G loss: 1.362781]\n",
      "epoch:18 step:17266 [D loss: 0.554311, acc.: 71.88%] [G loss: 1.309160]\n",
      "epoch:18 step:17267 [D loss: 0.419002, acc.: 89.06%] [G loss: 1.404275]\n",
      "epoch:18 step:17268 [D loss: 0.536257, acc.: 72.66%] [G loss: 1.181226]\n",
      "epoch:18 step:17269 [D loss: 0.598421, acc.: 66.41%] [G loss: 1.196627]\n",
      "epoch:18 step:17270 [D loss: 0.539594, acc.: 75.78%] [G loss: 0.954125]\n",
      "epoch:18 step:17271 [D loss: 0.476490, acc.: 75.00%] [G loss: 1.275015]\n",
      "epoch:18 step:17272 [D loss: 0.496380, acc.: 77.34%] [G loss: 1.404238]\n",
      "epoch:18 step:17273 [D loss: 0.565624, acc.: 65.62%] [G loss: 1.230704]\n",
      "epoch:18 step:17274 [D loss: 0.763501, acc.: 47.66%] [G loss: 0.951865]\n",
      "epoch:18 step:17275 [D loss: 0.764643, acc.: 52.34%] [G loss: 0.995295]\n",
      "epoch:18 step:17276 [D loss: 0.757442, acc.: 53.91%] [G loss: 0.890375]\n",
      "epoch:18 step:17277 [D loss: 0.885274, acc.: 32.81%] [G loss: 1.044917]\n",
      "epoch:18 step:17278 [D loss: 0.735313, acc.: 56.25%] [G loss: 0.981207]\n",
      "epoch:18 step:17279 [D loss: 0.777961, acc.: 50.78%] [G loss: 0.959687]\n",
      "epoch:18 step:17280 [D loss: 0.980503, acc.: 31.25%] [G loss: 0.899597]\n",
      "epoch:18 step:17281 [D loss: 0.845965, acc.: 42.97%] [G loss: 0.767468]\n",
      "epoch:18 step:17282 [D loss: 0.628531, acc.: 64.84%] [G loss: 1.413293]\n",
      "epoch:18 step:17283 [D loss: 0.975805, acc.: 38.28%] [G loss: 0.818935]\n",
      "epoch:18 step:17284 [D loss: 0.758196, acc.: 48.44%] [G loss: 0.912937]\n",
      "epoch:18 step:17285 [D loss: 0.578956, acc.: 69.53%] [G loss: 1.045335]\n",
      "epoch:18 step:17286 [D loss: 0.606991, acc.: 69.53%] [G loss: 1.282761]\n",
      "epoch:18 step:17287 [D loss: 0.694394, acc.: 53.12%] [G loss: 1.066610]\n",
      "epoch:18 step:17288 [D loss: 0.681522, acc.: 60.16%] [G loss: 1.042405]\n",
      "epoch:18 step:17289 [D loss: 0.745499, acc.: 50.78%] [G loss: 1.265868]\n",
      "epoch:18 step:17290 [D loss: 0.622229, acc.: 64.84%] [G loss: 0.983286]\n",
      "epoch:18 step:17291 [D loss: 0.578630, acc.: 71.09%] [G loss: 1.124237]\n",
      "epoch:18 step:17292 [D loss: 0.587841, acc.: 69.53%] [G loss: 1.123258]\n",
      "epoch:18 step:17293 [D loss: 0.631554, acc.: 65.62%] [G loss: 1.075629]\n",
      "epoch:18 step:17294 [D loss: 0.504920, acc.: 81.25%] [G loss: 1.302479]\n",
      "epoch:18 step:17295 [D loss: 0.613930, acc.: 64.84%] [G loss: 1.058164]\n",
      "epoch:18 step:17296 [D loss: 0.622200, acc.: 62.50%] [G loss: 0.994157]\n",
      "epoch:18 step:17297 [D loss: 0.670404, acc.: 55.47%] [G loss: 0.993481]\n",
      "epoch:18 step:17298 [D loss: 0.671378, acc.: 57.03%] [G loss: 1.331320]\n",
      "epoch:18 step:17299 [D loss: 0.472958, acc.: 79.69%] [G loss: 1.346065]\n",
      "epoch:18 step:17300 [D loss: 0.521613, acc.: 77.34%] [G loss: 1.377686]\n",
      "epoch:18 step:17301 [D loss: 0.650129, acc.: 62.50%] [G loss: 1.248419]\n",
      "epoch:18 step:17302 [D loss: 0.491271, acc.: 78.91%] [G loss: 1.196466]\n",
      "epoch:18 step:17303 [D loss: 0.720750, acc.: 57.81%] [G loss: 1.154417]\n",
      "epoch:18 step:17304 [D loss: 0.594402, acc.: 65.62%] [G loss: 1.052015]\n",
      "epoch:18 step:17305 [D loss: 0.674359, acc.: 60.94%] [G loss: 1.004346]\n",
      "epoch:18 step:17306 [D loss: 0.677076, acc.: 57.81%] [G loss: 0.979545]\n",
      "epoch:18 step:17307 [D loss: 0.673940, acc.: 58.59%] [G loss: 1.169605]\n",
      "epoch:18 step:17308 [D loss: 0.676586, acc.: 55.47%] [G loss: 1.100541]\n",
      "epoch:18 step:17309 [D loss: 0.560337, acc.: 71.88%] [G loss: 1.190728]\n",
      "epoch:18 step:17310 [D loss: 0.668044, acc.: 55.47%] [G loss: 1.266766]\n",
      "epoch:18 step:17311 [D loss: 0.691606, acc.: 60.16%] [G loss: 0.990940]\n",
      "epoch:18 step:17312 [D loss: 0.787479, acc.: 46.09%] [G loss: 0.986536]\n",
      "epoch:18 step:17313 [D loss: 0.614386, acc.: 67.19%] [G loss: 1.031879]\n",
      "epoch:18 step:17314 [D loss: 0.493528, acc.: 81.25%] [G loss: 1.307705]\n",
      "epoch:18 step:17315 [D loss: 0.473177, acc.: 82.81%] [G loss: 1.238207]\n",
      "epoch:18 step:17316 [D loss: 0.625384, acc.: 69.53%] [G loss: 1.229268]\n",
      "epoch:18 step:17317 [D loss: 0.508690, acc.: 74.22%] [G loss: 1.288985]\n",
      "epoch:18 step:17318 [D loss: 0.505604, acc.: 77.34%] [G loss: 1.259403]\n",
      "epoch:18 step:17319 [D loss: 0.517527, acc.: 75.00%] [G loss: 1.067955]\n",
      "epoch:18 step:17320 [D loss: 0.478457, acc.: 85.16%] [G loss: 1.362345]\n",
      "epoch:18 step:17321 [D loss: 0.543041, acc.: 75.00%] [G loss: 1.125398]\n",
      "epoch:18 step:17322 [D loss: 0.591826, acc.: 66.41%] [G loss: 1.275223]\n",
      "epoch:18 step:17323 [D loss: 0.464535, acc.: 82.03%] [G loss: 1.152943]\n",
      "epoch:18 step:17324 [D loss: 1.138591, acc.: 24.22%] [G loss: 0.848191]\n",
      "epoch:18 step:17325 [D loss: 0.888535, acc.: 36.72%] [G loss: 1.144320]\n",
      "epoch:18 step:17326 [D loss: 0.949254, acc.: 28.91%] [G loss: 0.984446]\n",
      "epoch:18 step:17327 [D loss: 0.899454, acc.: 39.06%] [G loss: 1.058010]\n",
      "epoch:18 step:17328 [D loss: 1.001098, acc.: 32.03%] [G loss: 0.985306]\n",
      "epoch:18 step:17329 [D loss: 0.689341, acc.: 58.59%] [G loss: 1.084612]\n",
      "epoch:18 step:17330 [D loss: 0.705807, acc.: 57.03%] [G loss: 0.932137]\n",
      "epoch:18 step:17331 [D loss: 0.746950, acc.: 54.69%] [G loss: 0.950801]\n",
      "epoch:18 step:17332 [D loss: 0.640323, acc.: 63.28%] [G loss: 1.254037]\n",
      "epoch:18 step:17333 [D loss: 0.620185, acc.: 63.28%] [G loss: 1.185956]\n",
      "epoch:18 step:17334 [D loss: 0.556687, acc.: 71.09%] [G loss: 1.129425]\n",
      "epoch:18 step:17335 [D loss: 0.479967, acc.: 82.03%] [G loss: 1.227584]\n",
      "epoch:18 step:17336 [D loss: 0.503019, acc.: 81.25%] [G loss: 1.011788]\n",
      "epoch:18 step:17337 [D loss: 0.411938, acc.: 77.34%] [G loss: 1.413174]\n",
      "epoch:18 step:17338 [D loss: 0.516411, acc.: 71.88%] [G loss: 1.469634]\n",
      "epoch:18 step:17339 [D loss: 0.638389, acc.: 60.94%] [G loss: 1.355602]\n",
      "epoch:18 step:17340 [D loss: 0.556785, acc.: 74.22%] [G loss: 1.324011]\n",
      "epoch:18 step:17341 [D loss: 0.598357, acc.: 67.19%] [G loss: 1.368940]\n",
      "epoch:18 step:17342 [D loss: 0.598383, acc.: 67.19%] [G loss: 1.403996]\n",
      "epoch:18 step:17343 [D loss: 0.846771, acc.: 46.09%] [G loss: 1.255147]\n",
      "epoch:18 step:17344 [D loss: 0.669612, acc.: 58.59%] [G loss: 1.175414]\n",
      "epoch:18 step:17345 [D loss: 0.597121, acc.: 71.88%] [G loss: 1.142134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17346 [D loss: 0.584655, acc.: 74.22%] [G loss: 1.023905]\n",
      "epoch:18 step:17347 [D loss: 0.506870, acc.: 78.91%] [G loss: 1.132881]\n",
      "epoch:18 step:17348 [D loss: 0.510734, acc.: 73.44%] [G loss: 1.293078]\n",
      "epoch:18 step:17349 [D loss: 0.536487, acc.: 75.00%] [G loss: 1.073769]\n",
      "epoch:18 step:17350 [D loss: 0.358144, acc.: 89.06%] [G loss: 1.397770]\n",
      "epoch:18 step:17351 [D loss: 0.400553, acc.: 85.16%] [G loss: 1.308904]\n",
      "epoch:18 step:17352 [D loss: 0.527424, acc.: 78.91%] [G loss: 1.272659]\n",
      "epoch:18 step:17353 [D loss: 0.546172, acc.: 75.78%] [G loss: 1.016923]\n",
      "epoch:18 step:17354 [D loss: 0.503606, acc.: 80.47%] [G loss: 1.382130]\n",
      "epoch:18 step:17355 [D loss: 0.678100, acc.: 59.38%] [G loss: 1.127976]\n",
      "epoch:18 step:17356 [D loss: 0.552075, acc.: 74.22%] [G loss: 1.051661]\n",
      "epoch:18 step:17357 [D loss: 0.586392, acc.: 66.41%] [G loss: 1.038341]\n",
      "epoch:18 step:17358 [D loss: 0.600964, acc.: 64.06%] [G loss: 1.166523]\n",
      "epoch:18 step:17359 [D loss: 0.600264, acc.: 67.19%] [G loss: 0.854077]\n",
      "epoch:18 step:17360 [D loss: 0.679755, acc.: 57.81%] [G loss: 0.836789]\n",
      "epoch:18 step:17361 [D loss: 0.529914, acc.: 74.22%] [G loss: 1.155336]\n",
      "epoch:18 step:17362 [D loss: 0.607386, acc.: 69.53%] [G loss: 1.148964]\n",
      "epoch:18 step:17363 [D loss: 0.481813, acc.: 80.47%] [G loss: 1.014751]\n",
      "epoch:18 step:17364 [D loss: 0.418690, acc.: 86.72%] [G loss: 1.340036]\n",
      "epoch:18 step:17365 [D loss: 0.309437, acc.: 94.53%] [G loss: 1.527455]\n",
      "epoch:18 step:17366 [D loss: 0.862280, acc.: 47.66%] [G loss: 1.190964]\n",
      "epoch:18 step:17367 [D loss: 0.863295, acc.: 45.31%] [G loss: 0.976183]\n",
      "epoch:18 step:17368 [D loss: 0.675156, acc.: 58.59%] [G loss: 0.952188]\n",
      "epoch:18 step:17369 [D loss: 0.553801, acc.: 67.97%] [G loss: 1.031023]\n",
      "epoch:18 step:17370 [D loss: 0.433331, acc.: 82.03%] [G loss: 1.189566]\n",
      "epoch:18 step:17371 [D loss: 0.652111, acc.: 57.03%] [G loss: 1.142220]\n",
      "epoch:18 step:17372 [D loss: 0.612924, acc.: 64.84%] [G loss: 1.117918]\n",
      "epoch:18 step:17373 [D loss: 0.492505, acc.: 81.25%] [G loss: 1.339688]\n",
      "epoch:18 step:17374 [D loss: 0.308748, acc.: 92.19%] [G loss: 1.281734]\n",
      "epoch:18 step:17375 [D loss: 0.694351, acc.: 56.25%] [G loss: 1.210387]\n",
      "epoch:18 step:17376 [D loss: 0.797047, acc.: 46.88%] [G loss: 1.171524]\n",
      "epoch:18 step:17377 [D loss: 0.649577, acc.: 60.16%] [G loss: 1.172550]\n",
      "epoch:18 step:17378 [D loss: 0.633466, acc.: 60.94%] [G loss: 1.057670]\n",
      "epoch:18 step:17379 [D loss: 0.525125, acc.: 75.00%] [G loss: 1.009536]\n",
      "epoch:18 step:17380 [D loss: 0.511810, acc.: 80.47%] [G loss: 1.158963]\n",
      "epoch:18 step:17381 [D loss: 0.531188, acc.: 79.69%] [G loss: 1.343963]\n",
      "epoch:18 step:17382 [D loss: 0.641623, acc.: 60.94%] [G loss: 1.055576]\n",
      "epoch:18 step:17383 [D loss: 0.481858, acc.: 81.25%] [G loss: 1.062414]\n",
      "epoch:18 step:17384 [D loss: 0.527848, acc.: 79.69%] [G loss: 1.032803]\n",
      "epoch:18 step:17385 [D loss: 0.553839, acc.: 71.09%] [G loss: 1.162357]\n",
      "epoch:18 step:17386 [D loss: 0.529207, acc.: 69.53%] [G loss: 1.006215]\n",
      "epoch:18 step:17387 [D loss: 0.471924, acc.: 81.25%] [G loss: 1.438092]\n",
      "epoch:18 step:17388 [D loss: 0.391601, acc.: 92.19%] [G loss: 1.339578]\n",
      "epoch:18 step:17389 [D loss: 0.490093, acc.: 75.00%] [G loss: 1.209316]\n",
      "epoch:18 step:17390 [D loss: 0.842118, acc.: 51.56%] [G loss: 1.240038]\n",
      "epoch:18 step:17391 [D loss: 0.760323, acc.: 47.66%] [G loss: 0.860955]\n",
      "epoch:18 step:17392 [D loss: 0.674102, acc.: 61.72%] [G loss: 0.975924]\n",
      "epoch:18 step:17393 [D loss: 0.700484, acc.: 57.03%] [G loss: 0.962218]\n",
      "epoch:18 step:17394 [D loss: 0.756592, acc.: 53.91%] [G loss: 1.029194]\n",
      "epoch:18 step:17395 [D loss: 0.672907, acc.: 57.03%] [G loss: 1.011378]\n",
      "epoch:18 step:17396 [D loss: 0.793353, acc.: 49.22%] [G loss: 0.869045]\n",
      "epoch:18 step:17397 [D loss: 0.616004, acc.: 66.41%] [G loss: 1.081945]\n",
      "epoch:18 step:17398 [D loss: 0.607741, acc.: 67.19%] [G loss: 0.918415]\n",
      "epoch:18 step:17399 [D loss: 0.387776, acc.: 85.94%] [G loss: 1.214478]\n",
      "epoch:18 step:17400 [D loss: 0.431611, acc.: 82.81%] [G loss: 1.338940]\n",
      "epoch:18 step:17401 [D loss: 0.557569, acc.: 69.53%] [G loss: 1.142428]\n",
      "epoch:18 step:17402 [D loss: 0.489755, acc.: 78.91%] [G loss: 1.138788]\n",
      "epoch:18 step:17403 [D loss: 0.517576, acc.: 75.78%] [G loss: 1.152040]\n",
      "epoch:18 step:17404 [D loss: 0.676669, acc.: 57.81%] [G loss: 0.974782]\n",
      "epoch:18 step:17405 [D loss: 0.729738, acc.: 54.69%] [G loss: 0.884616]\n",
      "epoch:18 step:17406 [D loss: 0.611885, acc.: 67.19%] [G loss: 1.053236]\n",
      "epoch:18 step:17407 [D loss: 0.596069, acc.: 70.31%] [G loss: 1.072116]\n",
      "epoch:18 step:17408 [D loss: 0.695112, acc.: 54.69%] [G loss: 1.090244]\n",
      "epoch:18 step:17409 [D loss: 0.622060, acc.: 66.41%] [G loss: 0.930761]\n",
      "epoch:18 step:17410 [D loss: 0.581846, acc.: 70.31%] [G loss: 1.127367]\n",
      "epoch:18 step:17411 [D loss: 0.439355, acc.: 89.06%] [G loss: 1.315732]\n",
      "epoch:18 step:17412 [D loss: 0.461844, acc.: 80.47%] [G loss: 1.405051]\n",
      "epoch:18 step:17413 [D loss: 0.484485, acc.: 81.25%] [G loss: 0.999122]\n",
      "epoch:18 step:17414 [D loss: 0.504854, acc.: 77.34%] [G loss: 1.050728]\n",
      "epoch:18 step:17415 [D loss: 0.382332, acc.: 89.06%] [G loss: 1.205301]\n",
      "epoch:18 step:17416 [D loss: 0.362838, acc.: 92.19%] [G loss: 1.496761]\n",
      "epoch:18 step:17417 [D loss: 0.269846, acc.: 97.66%] [G loss: 1.444346]\n",
      "epoch:18 step:17418 [D loss: 0.417696, acc.: 87.50%] [G loss: 1.206477]\n",
      "epoch:18 step:17419 [D loss: 0.534172, acc.: 76.56%] [G loss: 1.083609]\n",
      "epoch:18 step:17420 [D loss: 0.490532, acc.: 77.34%] [G loss: 1.331881]\n",
      "epoch:18 step:17421 [D loss: 0.307166, acc.: 94.53%] [G loss: 1.637786]\n",
      "epoch:18 step:17422 [D loss: 0.392413, acc.: 89.06%] [G loss: 1.568323]\n",
      "epoch:18 step:17423 [D loss: 0.320090, acc.: 95.31%] [G loss: 1.604384]\n",
      "epoch:18 step:17424 [D loss: 0.679932, acc.: 60.94%] [G loss: 1.089612]\n",
      "epoch:18 step:17425 [D loss: 0.852551, acc.: 46.09%] [G loss: 1.233017]\n",
      "epoch:18 step:17426 [D loss: 0.770671, acc.: 54.69%] [G loss: 1.577768]\n",
      "epoch:18 step:17427 [D loss: 0.611812, acc.: 63.28%] [G loss: 1.117578]\n",
      "epoch:18 step:17428 [D loss: 0.689169, acc.: 56.25%] [G loss: 1.097612]\n",
      "epoch:18 step:17429 [D loss: 0.596076, acc.: 67.97%] [G loss: 1.285343]\n",
      "epoch:18 step:17430 [D loss: 0.676624, acc.: 61.72%] [G loss: 1.036287]\n",
      "epoch:18 step:17431 [D loss: 0.471372, acc.: 82.81%] [G loss: 1.113901]\n",
      "epoch:18 step:17432 [D loss: 0.347383, acc.: 92.97%] [G loss: 1.433308]\n",
      "epoch:18 step:17433 [D loss: 0.322588, acc.: 93.75%] [G loss: 1.451682]\n",
      "epoch:18 step:17434 [D loss: 0.581220, acc.: 67.19%] [G loss: 1.394809]\n",
      "epoch:18 step:17435 [D loss: 0.712385, acc.: 53.91%] [G loss: 0.913694]\n",
      "epoch:18 step:17436 [D loss: 0.766278, acc.: 47.66%] [G loss: 0.866354]\n",
      "epoch:18 step:17437 [D loss: 0.563665, acc.: 69.53%] [G loss: 1.174498]\n",
      "epoch:18 step:17438 [D loss: 0.525811, acc.: 75.78%] [G loss: 1.096447]\n",
      "epoch:18 step:17439 [D loss: 0.613147, acc.: 68.75%] [G loss: 1.101310]\n",
      "epoch:18 step:17440 [D loss: 0.454088, acc.: 87.50%] [G loss: 1.396472]\n",
      "epoch:18 step:17441 [D loss: 0.516126, acc.: 78.12%] [G loss: 1.159324]\n",
      "epoch:18 step:17442 [D loss: 0.432802, acc.: 85.16%] [G loss: 1.406776]\n",
      "epoch:18 step:17443 [D loss: 0.547038, acc.: 76.56%] [G loss: 1.435033]\n",
      "epoch:18 step:17444 [D loss: 0.455593, acc.: 82.03%] [G loss: 1.242376]\n",
      "epoch:18 step:17445 [D loss: 0.646694, acc.: 62.50%] [G loss: 0.982091]\n",
      "epoch:18 step:17446 [D loss: 0.696012, acc.: 55.47%] [G loss: 1.087180]\n",
      "epoch:18 step:17447 [D loss: 0.781158, acc.: 48.44%] [G loss: 0.767283]\n",
      "epoch:18 step:17448 [D loss: 0.957476, acc.: 25.78%] [G loss: 0.763846]\n",
      "epoch:18 step:17449 [D loss: 0.693374, acc.: 57.81%] [G loss: 0.711943]\n",
      "epoch:18 step:17450 [D loss: 0.864714, acc.: 38.28%] [G loss: 0.940183]\n",
      "epoch:18 step:17451 [D loss: 0.636837, acc.: 62.50%] [G loss: 1.318645]\n",
      "epoch:18 step:17452 [D loss: 0.641600, acc.: 58.59%] [G loss: 1.087353]\n",
      "epoch:18 step:17453 [D loss: 0.443366, acc.: 83.59%] [G loss: 1.110912]\n",
      "epoch:18 step:17454 [D loss: 0.384248, acc.: 89.84%] [G loss: 1.349766]\n",
      "epoch:18 step:17455 [D loss: 0.563104, acc.: 71.88%] [G loss: 1.312246]\n",
      "epoch:18 step:17456 [D loss: 0.770514, acc.: 49.22%] [G loss: 1.412578]\n",
      "epoch:18 step:17457 [D loss: 0.691900, acc.: 57.03%] [G loss: 1.115575]\n",
      "epoch:18 step:17458 [D loss: 0.599027, acc.: 68.75%] [G loss: 1.134614]\n",
      "epoch:18 step:17459 [D loss: 0.621231, acc.: 67.19%] [G loss: 1.006186]\n",
      "epoch:18 step:17460 [D loss: 0.609856, acc.: 67.97%] [G loss: 1.187497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17461 [D loss: 0.682712, acc.: 58.59%] [G loss: 1.192226]\n",
      "epoch:18 step:17462 [D loss: 0.530620, acc.: 77.34%] [G loss: 1.280005]\n",
      "epoch:18 step:17463 [D loss: 0.487674, acc.: 81.25%] [G loss: 1.064384]\n",
      "epoch:18 step:17464 [D loss: 0.317836, acc.: 92.19%] [G loss: 1.395983]\n",
      "epoch:18 step:17465 [D loss: 0.652124, acc.: 63.28%] [G loss: 1.190598]\n",
      "epoch:18 step:17466 [D loss: 0.712114, acc.: 55.47%] [G loss: 1.086554]\n",
      "epoch:18 step:17467 [D loss: 0.701374, acc.: 57.81%] [G loss: 1.033248]\n",
      "epoch:18 step:17468 [D loss: 0.576544, acc.: 65.62%] [G loss: 1.200304]\n",
      "epoch:18 step:17469 [D loss: 0.379634, acc.: 85.94%] [G loss: 1.279017]\n",
      "epoch:18 step:17470 [D loss: 0.323233, acc.: 93.75%] [G loss: 1.581491]\n",
      "epoch:18 step:17471 [D loss: 0.321723, acc.: 93.75%] [G loss: 1.625458]\n",
      "epoch:18 step:17472 [D loss: 0.766885, acc.: 54.69%] [G loss: 1.241522]\n",
      "epoch:18 step:17473 [D loss: 0.629759, acc.: 66.41%] [G loss: 1.319859]\n",
      "epoch:18 step:17474 [D loss: 0.727851, acc.: 53.91%] [G loss: 0.869210]\n",
      "epoch:18 step:17475 [D loss: 0.846089, acc.: 42.19%] [G loss: 0.809202]\n",
      "epoch:18 step:17476 [D loss: 0.501100, acc.: 79.69%] [G loss: 1.213972]\n",
      "epoch:18 step:17477 [D loss: 0.660297, acc.: 60.94%] [G loss: 1.186013]\n",
      "epoch:18 step:17478 [D loss: 0.709527, acc.: 50.00%] [G loss: 0.998953]\n",
      "epoch:18 step:17479 [D loss: 0.420127, acc.: 87.50%] [G loss: 1.258058]\n",
      "epoch:18 step:17480 [D loss: 0.571402, acc.: 67.97%] [G loss: 0.882758]\n",
      "epoch:18 step:17481 [D loss: 0.381182, acc.: 85.94%] [G loss: 1.611334]\n",
      "epoch:18 step:17482 [D loss: 0.333095, acc.: 93.75%] [G loss: 1.494228]\n",
      "epoch:18 step:17483 [D loss: 0.636763, acc.: 67.19%] [G loss: 0.916913]\n",
      "epoch:18 step:17484 [D loss: 1.014812, acc.: 42.19%] [G loss: 0.936143]\n",
      "epoch:18 step:17485 [D loss: 0.922465, acc.: 38.28%] [G loss: 0.994005]\n",
      "epoch:18 step:17486 [D loss: 0.964187, acc.: 32.81%] [G loss: 0.734031]\n",
      "epoch:18 step:17487 [D loss: 0.728740, acc.: 52.34%] [G loss: 1.044986]\n",
      "epoch:18 step:17488 [D loss: 0.667027, acc.: 60.16%] [G loss: 0.801960]\n",
      "epoch:18 step:17489 [D loss: 0.589473, acc.: 67.19%] [G loss: 1.524865]\n",
      "epoch:18 step:17490 [D loss: 0.690967, acc.: 58.59%] [G loss: 1.245053]\n",
      "epoch:18 step:17491 [D loss: 0.727953, acc.: 55.47%] [G loss: 1.304855]\n",
      "epoch:18 step:17492 [D loss: 0.698402, acc.: 61.72%] [G loss: 0.881122]\n",
      "epoch:18 step:17493 [D loss: 0.850712, acc.: 46.88%] [G loss: 0.916013]\n",
      "epoch:18 step:17494 [D loss: 0.667789, acc.: 60.16%] [G loss: 0.860723]\n",
      "epoch:18 step:17495 [D loss: 0.502855, acc.: 75.00%] [G loss: 0.856633]\n",
      "epoch:18 step:17496 [D loss: 0.579602, acc.: 71.09%] [G loss: 1.061013]\n",
      "epoch:18 step:17497 [D loss: 0.580635, acc.: 71.88%] [G loss: 1.124738]\n",
      "epoch:18 step:17498 [D loss: 0.657910, acc.: 60.94%] [G loss: 0.999391]\n",
      "epoch:18 step:17499 [D loss: 0.591835, acc.: 63.28%] [G loss: 1.043485]\n",
      "epoch:18 step:17500 [D loss: 0.687483, acc.: 57.81%] [G loss: 0.990943]\n",
      "epoch:18 step:17501 [D loss: 0.721565, acc.: 53.12%] [G loss: 1.018114]\n",
      "epoch:18 step:17502 [D loss: 0.662916, acc.: 57.03%] [G loss: 1.092891]\n",
      "epoch:18 step:17503 [D loss: 0.604439, acc.: 64.84%] [G loss: 1.436053]\n",
      "epoch:18 step:17504 [D loss: 0.824114, acc.: 42.97%] [G loss: 0.929018]\n",
      "epoch:18 step:17505 [D loss: 0.590386, acc.: 67.97%] [G loss: 1.327927]\n",
      "epoch:18 step:17506 [D loss: 0.506068, acc.: 77.34%] [G loss: 1.012280]\n",
      "epoch:18 step:17507 [D loss: 0.321405, acc.: 94.53%] [G loss: 1.751842]\n",
      "epoch:18 step:17508 [D loss: 0.339730, acc.: 92.97%] [G loss: 1.641094]\n",
      "epoch:18 step:17509 [D loss: 0.590260, acc.: 71.09%] [G loss: 1.248679]\n",
      "epoch:18 step:17510 [D loss: 0.697948, acc.: 61.72%] [G loss: 1.142117]\n",
      "epoch:18 step:17511 [D loss: 0.555934, acc.: 71.09%] [G loss: 1.186309]\n",
      "epoch:18 step:17512 [D loss: 0.695680, acc.: 57.03%] [G loss: 0.974027]\n",
      "epoch:18 step:17513 [D loss: 0.648278, acc.: 61.72%] [G loss: 1.065276]\n",
      "epoch:18 step:17514 [D loss: 0.630268, acc.: 67.97%] [G loss: 1.137046]\n",
      "epoch:18 step:17515 [D loss: 0.566001, acc.: 70.31%] [G loss: 1.187484]\n",
      "epoch:18 step:17516 [D loss: 0.552207, acc.: 75.00%] [G loss: 0.919939]\n",
      "epoch:18 step:17517 [D loss: 0.562872, acc.: 73.44%] [G loss: 1.241828]\n",
      "epoch:18 step:17518 [D loss: 0.596321, acc.: 71.88%] [G loss: 1.113433]\n",
      "epoch:18 step:17519 [D loss: 0.602752, acc.: 68.75%] [G loss: 1.071504]\n",
      "epoch:18 step:17520 [D loss: 0.532091, acc.: 75.00%] [G loss: 1.216164]\n",
      "epoch:18 step:17521 [D loss: 0.789536, acc.: 46.88%] [G loss: 1.011389]\n",
      "epoch:18 step:17522 [D loss: 0.710050, acc.: 53.91%] [G loss: 0.938608]\n",
      "epoch:18 step:17523 [D loss: 0.709700, acc.: 53.91%] [G loss: 1.195163]\n",
      "epoch:18 step:17524 [D loss: 0.645449, acc.: 60.16%] [G loss: 0.973101]\n",
      "epoch:18 step:17525 [D loss: 0.778699, acc.: 51.56%] [G loss: 0.889803]\n",
      "epoch:18 step:17526 [D loss: 0.766484, acc.: 47.66%] [G loss: 0.988490]\n",
      "epoch:18 step:17527 [D loss: 0.671165, acc.: 64.84%] [G loss: 1.018826]\n",
      "epoch:18 step:17528 [D loss: 0.653692, acc.: 64.06%] [G loss: 1.103875]\n",
      "epoch:18 step:17529 [D loss: 0.421952, acc.: 83.59%] [G loss: 1.245555]\n",
      "epoch:18 step:17530 [D loss: 0.369279, acc.: 89.84%] [G loss: 1.233390]\n",
      "epoch:18 step:17531 [D loss: 0.393941, acc.: 88.28%] [G loss: 1.301916]\n",
      "epoch:18 step:17532 [D loss: 0.612731, acc.: 67.19%] [G loss: 1.217514]\n",
      "epoch:18 step:17533 [D loss: 0.645650, acc.: 61.72%] [G loss: 1.213266]\n",
      "epoch:18 step:17534 [D loss: 0.752506, acc.: 49.22%] [G loss: 0.941964]\n",
      "epoch:18 step:17535 [D loss: 0.595582, acc.: 67.19%] [G loss: 1.074690]\n",
      "epoch:18 step:17536 [D loss: 0.562921, acc.: 70.31%] [G loss: 0.957511]\n",
      "epoch:18 step:17537 [D loss: 0.688803, acc.: 60.16%] [G loss: 1.077789]\n",
      "epoch:18 step:17538 [D loss: 0.705194, acc.: 55.47%] [G loss: 0.833726]\n",
      "epoch:18 step:17539 [D loss: 1.132418, acc.: 17.97%] [G loss: 0.555645]\n",
      "epoch:18 step:17540 [D loss: 0.688401, acc.: 57.03%] [G loss: 1.031105]\n",
      "epoch:18 step:17541 [D loss: 0.949362, acc.: 28.12%] [G loss: 0.851226]\n",
      "epoch:18 step:17542 [D loss: 0.727674, acc.: 53.12%] [G loss: 0.832196]\n",
      "epoch:18 step:17543 [D loss: 0.655083, acc.: 64.84%] [G loss: 0.949857]\n",
      "epoch:18 step:17544 [D loss: 0.592138, acc.: 71.09%] [G loss: 1.316490]\n",
      "epoch:18 step:17545 [D loss: 0.644952, acc.: 61.72%] [G loss: 1.291887]\n",
      "epoch:18 step:17546 [D loss: 0.683445, acc.: 63.28%] [G loss: 0.959718]\n",
      "epoch:18 step:17547 [D loss: 0.626353, acc.: 64.06%] [G loss: 1.174739]\n",
      "epoch:18 step:17548 [D loss: 0.605914, acc.: 67.97%] [G loss: 1.204308]\n",
      "epoch:18 step:17549 [D loss: 0.590697, acc.: 71.09%] [G loss: 0.979809]\n",
      "epoch:18 step:17550 [D loss: 0.662915, acc.: 61.72%] [G loss: 1.020362]\n",
      "epoch:18 step:17551 [D loss: 0.544484, acc.: 74.22%] [G loss: 1.061235]\n",
      "epoch:18 step:17552 [D loss: 0.664513, acc.: 60.16%] [G loss: 1.083801]\n",
      "epoch:18 step:17553 [D loss: 0.676929, acc.: 61.72%] [G loss: 0.954005]\n",
      "epoch:18 step:17554 [D loss: 0.533362, acc.: 70.31%] [G loss: 1.220592]\n",
      "epoch:18 step:17555 [D loss: 0.443757, acc.: 85.16%] [G loss: 1.081458]\n",
      "epoch:18 step:17556 [D loss: 0.288545, acc.: 93.75%] [G loss: 1.521829]\n",
      "epoch:18 step:17557 [D loss: 0.456126, acc.: 85.16%] [G loss: 1.226807]\n",
      "epoch:18 step:17558 [D loss: 0.441682, acc.: 87.50%] [G loss: 1.432486]\n",
      "epoch:18 step:17559 [D loss: 0.420032, acc.: 86.72%] [G loss: 1.587377]\n",
      "epoch:18 step:17560 [D loss: 0.363250, acc.: 87.50%] [G loss: 1.474537]\n",
      "epoch:18 step:17561 [D loss: 0.392626, acc.: 86.72%] [G loss: 1.716702]\n",
      "epoch:18 step:17562 [D loss: 0.903359, acc.: 37.50%] [G loss: 0.950445]\n",
      "epoch:18 step:17563 [D loss: 0.683596, acc.: 52.34%] [G loss: 1.128196]\n",
      "epoch:18 step:17564 [D loss: 0.834220, acc.: 38.28%] [G loss: 0.765738]\n",
      "epoch:18 step:17565 [D loss: 0.745274, acc.: 53.91%] [G loss: 0.824655]\n",
      "epoch:18 step:17566 [D loss: 0.509923, acc.: 78.91%] [G loss: 1.322701]\n",
      "epoch:18 step:17567 [D loss: 0.621732, acc.: 64.84%] [G loss: 1.088991]\n",
      "epoch:18 step:17568 [D loss: 0.682372, acc.: 57.81%] [G loss: 1.140573]\n",
      "epoch:18 step:17569 [D loss: 0.657651, acc.: 58.59%] [G loss: 1.213268]\n",
      "epoch:18 step:17570 [D loss: 0.615555, acc.: 65.62%] [G loss: 0.972462]\n",
      "epoch:18 step:17571 [D loss: 0.560944, acc.: 73.44%] [G loss: 1.058423]\n",
      "epoch:18 step:17572 [D loss: 0.385814, acc.: 88.28%] [G loss: 1.056638]\n",
      "epoch:18 step:17573 [D loss: 0.359174, acc.: 91.41%] [G loss: 1.347448]\n",
      "epoch:18 step:17574 [D loss: 0.430530, acc.: 85.16%] [G loss: 1.319353]\n",
      "epoch:18 step:17575 [D loss: 0.369444, acc.: 89.06%] [G loss: 1.387720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17576 [D loss: 0.641804, acc.: 59.38%] [G loss: 1.541610]\n",
      "epoch:18 step:17577 [D loss: 0.791388, acc.: 49.22%] [G loss: 0.825771]\n",
      "epoch:18 step:17578 [D loss: 0.561487, acc.: 74.22%] [G loss: 0.978042]\n",
      "epoch:18 step:17579 [D loss: 0.393970, acc.: 83.59%] [G loss: 1.124171]\n",
      "epoch:18 step:17580 [D loss: 0.411221, acc.: 84.38%] [G loss: 1.389897]\n",
      "epoch:18 step:17581 [D loss: 0.595631, acc.: 72.66%] [G loss: 1.218546]\n",
      "epoch:18 step:17582 [D loss: 0.764026, acc.: 49.22%] [G loss: 1.116367]\n",
      "epoch:18 step:17583 [D loss: 0.718060, acc.: 52.34%] [G loss: 0.753880]\n",
      "epoch:18 step:17584 [D loss: 0.663515, acc.: 61.72%] [G loss: 0.901133]\n",
      "epoch:18 step:17585 [D loss: 0.662083, acc.: 57.81%] [G loss: 0.930699]\n",
      "epoch:18 step:17586 [D loss: 0.747474, acc.: 47.66%] [G loss: 0.903223]\n",
      "epoch:18 step:17587 [D loss: 0.682173, acc.: 59.38%] [G loss: 0.830791]\n",
      "epoch:18 step:17588 [D loss: 0.643671, acc.: 62.50%] [G loss: 0.917558]\n",
      "epoch:18 step:17589 [D loss: 0.691862, acc.: 55.47%] [G loss: 1.050489]\n",
      "epoch:18 step:17590 [D loss: 0.662657, acc.: 60.94%] [G loss: 0.936544]\n",
      "epoch:18 step:17591 [D loss: 0.481097, acc.: 81.25%] [G loss: 0.930548]\n",
      "epoch:18 step:17592 [D loss: 0.662713, acc.: 60.16%] [G loss: 1.139382]\n",
      "epoch:18 step:17593 [D loss: 0.524381, acc.: 77.34%] [G loss: 1.277351]\n",
      "epoch:18 step:17594 [D loss: 0.534230, acc.: 75.78%] [G loss: 1.222988]\n",
      "epoch:18 step:17595 [D loss: 0.565958, acc.: 74.22%] [G loss: 1.152802]\n",
      "epoch:18 step:17596 [D loss: 0.536320, acc.: 71.09%] [G loss: 1.205011]\n",
      "epoch:18 step:17597 [D loss: 0.488512, acc.: 81.25%] [G loss: 1.283061]\n",
      "epoch:18 step:17598 [D loss: 0.470472, acc.: 79.69%] [G loss: 1.193849]\n",
      "epoch:18 step:17599 [D loss: 0.532885, acc.: 77.34%] [G loss: 1.110028]\n",
      "epoch:18 step:17600 [D loss: 0.760627, acc.: 47.66%] [G loss: 1.070036]\n",
      "epoch:18 step:17601 [D loss: 0.869856, acc.: 32.03%] [G loss: 1.074831]\n",
      "epoch:18 step:17602 [D loss: 0.725539, acc.: 50.00%] [G loss: 1.051313]\n",
      "epoch:18 step:17603 [D loss: 0.678343, acc.: 57.03%] [G loss: 1.014063]\n",
      "epoch:18 step:17604 [D loss: 0.602683, acc.: 66.41%] [G loss: 1.018950]\n",
      "epoch:18 step:17605 [D loss: 0.738561, acc.: 52.34%] [G loss: 0.949963]\n",
      "epoch:18 step:17606 [D loss: 0.633262, acc.: 64.06%] [G loss: 1.252069]\n",
      "epoch:18 step:17607 [D loss: 0.604119, acc.: 71.88%] [G loss: 0.986529]\n",
      "epoch:18 step:17608 [D loss: 0.656080, acc.: 61.72%] [G loss: 0.920062]\n",
      "epoch:18 step:17609 [D loss: 0.523810, acc.: 76.56%] [G loss: 1.010108]\n",
      "epoch:18 step:17610 [D loss: 0.595922, acc.: 67.19%] [G loss: 1.182926]\n",
      "epoch:18 step:17611 [D loss: 0.507881, acc.: 81.25%] [G loss: 1.348423]\n",
      "epoch:18 step:17612 [D loss: 0.511236, acc.: 78.12%] [G loss: 1.076300]\n",
      "epoch:18 step:17613 [D loss: 0.670967, acc.: 55.47%] [G loss: 1.015332]\n",
      "epoch:18 step:17614 [D loss: 0.567735, acc.: 73.44%] [G loss: 0.996410]\n",
      "epoch:18 step:17615 [D loss: 0.566579, acc.: 71.88%] [G loss: 1.118514]\n",
      "epoch:18 step:17616 [D loss: 0.551814, acc.: 74.22%] [G loss: 1.095013]\n",
      "epoch:18 step:17617 [D loss: 0.716950, acc.: 57.03%] [G loss: 0.782430]\n",
      "epoch:18 step:17618 [D loss: 0.736298, acc.: 53.91%] [G loss: 0.766408]\n",
      "epoch:18 step:17619 [D loss: 0.645903, acc.: 64.84%] [G loss: 0.982095]\n",
      "epoch:18 step:17620 [D loss: 0.814617, acc.: 40.62%] [G loss: 0.991810]\n",
      "epoch:18 step:17621 [D loss: 0.498830, acc.: 78.12%] [G loss: 1.241068]\n",
      "epoch:18 step:17622 [D loss: 0.628785, acc.: 62.50%] [G loss: 1.071997]\n",
      "epoch:18 step:17623 [D loss: 0.698298, acc.: 53.12%] [G loss: 0.887801]\n",
      "epoch:18 step:17624 [D loss: 0.613972, acc.: 67.97%] [G loss: 1.151011]\n",
      "epoch:18 step:17625 [D loss: 0.696686, acc.: 50.78%] [G loss: 1.023766]\n",
      "epoch:18 step:17626 [D loss: 0.593297, acc.: 63.28%] [G loss: 0.907256]\n",
      "epoch:18 step:17627 [D loss: 0.736235, acc.: 46.09%] [G loss: 0.879343]\n",
      "epoch:18 step:17628 [D loss: 0.717178, acc.: 56.25%] [G loss: 1.053283]\n",
      "epoch:18 step:17629 [D loss: 0.554978, acc.: 74.22%] [G loss: 0.945721]\n",
      "epoch:18 step:17630 [D loss: 0.648480, acc.: 60.16%] [G loss: 0.993585]\n",
      "epoch:18 step:17631 [D loss: 0.698853, acc.: 51.56%] [G loss: 0.978409]\n",
      "epoch:18 step:17632 [D loss: 0.653805, acc.: 62.50%] [G loss: 0.886970]\n",
      "epoch:18 step:17633 [D loss: 0.532541, acc.: 75.00%] [G loss: 1.208045]\n",
      "epoch:18 step:17634 [D loss: 0.379149, acc.: 89.06%] [G loss: 1.126377]\n",
      "epoch:18 step:17635 [D loss: 0.388150, acc.: 85.16%] [G loss: 1.271422]\n",
      "epoch:18 step:17636 [D loss: 0.495535, acc.: 80.47%] [G loss: 1.382699]\n",
      "epoch:18 step:17637 [D loss: 0.816989, acc.: 42.19%] [G loss: 1.037429]\n",
      "epoch:18 step:17638 [D loss: 0.679469, acc.: 54.69%] [G loss: 0.908945]\n",
      "epoch:18 step:17639 [D loss: 0.600399, acc.: 71.09%] [G loss: 0.922506]\n",
      "epoch:18 step:17640 [D loss: 0.383133, acc.: 78.12%] [G loss: 1.215957]\n",
      "epoch:18 step:17641 [D loss: 0.334875, acc.: 88.28%] [G loss: 1.311714]\n",
      "epoch:18 step:17642 [D loss: 0.486701, acc.: 77.34%] [G loss: 1.492958]\n",
      "epoch:18 step:17643 [D loss: 0.637415, acc.: 64.06%] [G loss: 1.057506]\n",
      "epoch:18 step:17644 [D loss: 0.759208, acc.: 53.91%] [G loss: 1.027287]\n",
      "epoch:18 step:17645 [D loss: 0.785479, acc.: 50.78%] [G loss: 1.020844]\n",
      "epoch:18 step:17646 [D loss: 0.710305, acc.: 51.56%] [G loss: 1.272806]\n",
      "epoch:18 step:17647 [D loss: 0.570759, acc.: 64.84%] [G loss: 1.210653]\n",
      "epoch:18 step:17648 [D loss: 0.478380, acc.: 81.25%] [G loss: 1.257751]\n",
      "epoch:18 step:17649 [D loss: 0.714178, acc.: 55.47%] [G loss: 1.342196]\n",
      "epoch:18 step:17650 [D loss: 0.683608, acc.: 60.94%] [G loss: 1.087489]\n",
      "epoch:18 step:17651 [D loss: 0.526697, acc.: 81.25%] [G loss: 1.231441]\n",
      "epoch:18 step:17652 [D loss: 0.404074, acc.: 85.94%] [G loss: 1.141067]\n",
      "epoch:18 step:17653 [D loss: 0.655262, acc.: 62.50%] [G loss: 1.200265]\n",
      "epoch:18 step:17654 [D loss: 0.703324, acc.: 53.91%] [G loss: 0.902921]\n",
      "epoch:18 step:17655 [D loss: 0.757639, acc.: 49.22%] [G loss: 1.007577]\n",
      "epoch:18 step:17656 [D loss: 0.464345, acc.: 77.34%] [G loss: 0.954593]\n",
      "epoch:18 step:17657 [D loss: 0.541001, acc.: 71.09%] [G loss: 1.289061]\n",
      "epoch:18 step:17658 [D loss: 0.274720, acc.: 96.88%] [G loss: 1.812334]\n",
      "epoch:18 step:17659 [D loss: 0.461994, acc.: 82.81%] [G loss: 1.449963]\n",
      "epoch:18 step:17660 [D loss: 0.460731, acc.: 78.91%] [G loss: 1.284774]\n",
      "epoch:18 step:17661 [D loss: 0.478632, acc.: 74.22%] [G loss: 1.660255]\n",
      "epoch:18 step:17662 [D loss: 0.404369, acc.: 87.50%] [G loss: 1.608137]\n",
      "epoch:18 step:17663 [D loss: 0.752423, acc.: 51.56%] [G loss: 0.941479]\n",
      "epoch:18 step:17664 [D loss: 0.568502, acc.: 71.09%] [G loss: 1.353268]\n",
      "epoch:18 step:17665 [D loss: 0.692501, acc.: 52.34%] [G loss: 0.926397]\n",
      "epoch:18 step:17666 [D loss: 0.891730, acc.: 31.25%] [G loss: 0.909090]\n",
      "epoch:18 step:17667 [D loss: 0.717169, acc.: 55.47%] [G loss: 0.744089]\n",
      "epoch:18 step:17668 [D loss: 0.651155, acc.: 63.28%] [G loss: 0.904688]\n",
      "epoch:18 step:17669 [D loss: 0.739693, acc.: 51.56%] [G loss: 1.176212]\n",
      "epoch:18 step:17670 [D loss: 0.548617, acc.: 75.00%] [G loss: 0.984214]\n",
      "epoch:18 step:17671 [D loss: 0.621044, acc.: 66.41%] [G loss: 0.662791]\n",
      "epoch:18 step:17672 [D loss: 0.502463, acc.: 78.91%] [G loss: 1.317516]\n",
      "epoch:18 step:17673 [D loss: 0.667581, acc.: 57.81%] [G loss: 1.027625]\n",
      "epoch:18 step:17674 [D loss: 0.690352, acc.: 56.25%] [G loss: 1.138960]\n",
      "epoch:18 step:17675 [D loss: 0.587824, acc.: 68.75%] [G loss: 1.206116]\n",
      "epoch:18 step:17676 [D loss: 0.649132, acc.: 65.62%] [G loss: 1.084862]\n",
      "epoch:18 step:17677 [D loss: 0.720942, acc.: 56.25%] [G loss: 1.222437]\n",
      "epoch:18 step:17678 [D loss: 0.615578, acc.: 60.16%] [G loss: 1.171261]\n",
      "epoch:18 step:17679 [D loss: 0.568866, acc.: 71.88%] [G loss: 1.046639]\n",
      "epoch:18 step:17680 [D loss: 0.536204, acc.: 75.78%] [G loss: 1.105175]\n",
      "epoch:18 step:17681 [D loss: 0.202094, acc.: 97.66%] [G loss: 1.368940]\n",
      "epoch:18 step:17682 [D loss: 0.335269, acc.: 91.41%] [G loss: 1.341384]\n",
      "epoch:18 step:17683 [D loss: 0.493005, acc.: 79.69%] [G loss: 1.222502]\n",
      "epoch:18 step:17684 [D loss: 0.457963, acc.: 83.59%] [G loss: 1.312448]\n",
      "epoch:18 step:17685 [D loss: 0.533625, acc.: 76.56%] [G loss: 1.267573]\n",
      "epoch:18 step:17686 [D loss: 0.826687, acc.: 41.41%] [G loss: 1.071592]\n",
      "epoch:18 step:17687 [D loss: 0.813785, acc.: 39.06%] [G loss: 0.711474]\n",
      "epoch:18 step:17688 [D loss: 0.794753, acc.: 41.41%] [G loss: 0.904969]\n",
      "epoch:18 step:17689 [D loss: 0.580467, acc.: 71.88%] [G loss: 1.140534]\n",
      "epoch:18 step:17690 [D loss: 0.507291, acc.: 79.69%] [G loss: 1.295323]\n",
      "epoch:18 step:17691 [D loss: 0.359615, acc.: 92.19%] [G loss: 1.224540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17692 [D loss: 0.578061, acc.: 66.41%] [G loss: 1.492963]\n",
      "epoch:18 step:17693 [D loss: 0.787835, acc.: 46.88%] [G loss: 1.177165]\n",
      "epoch:18 step:17694 [D loss: 0.627515, acc.: 64.84%] [G loss: 0.822952]\n",
      "epoch:18 step:17695 [D loss: 0.627580, acc.: 67.97%] [G loss: 1.057679]\n",
      "epoch:18 step:17696 [D loss: 0.663473, acc.: 65.62%] [G loss: 0.955009]\n",
      "epoch:18 step:17697 [D loss: 0.583150, acc.: 67.19%] [G loss: 0.938506]\n",
      "epoch:18 step:17698 [D loss: 0.458854, acc.: 80.47%] [G loss: 1.588919]\n",
      "epoch:18 step:17699 [D loss: 0.678433, acc.: 57.03%] [G loss: 1.071802]\n",
      "epoch:18 step:17700 [D loss: 0.802887, acc.: 54.69%] [G loss: 1.347250]\n",
      "epoch:18 step:17701 [D loss: 0.810168, acc.: 46.09%] [G loss: 1.263176]\n",
      "epoch:18 step:17702 [D loss: 0.963626, acc.: 35.94%] [G loss: 1.045775]\n",
      "epoch:18 step:17703 [D loss: 0.694251, acc.: 58.59%] [G loss: 1.100225]\n",
      "epoch:18 step:17704 [D loss: 0.778976, acc.: 43.75%] [G loss: 0.951205]\n",
      "epoch:18 step:17705 [D loss: 0.600524, acc.: 70.31%] [G loss: 1.229295]\n",
      "epoch:18 step:17706 [D loss: 0.532809, acc.: 75.00%] [G loss: 1.029560]\n",
      "epoch:18 step:17707 [D loss: 0.392058, acc.: 89.84%] [G loss: 1.272571]\n",
      "epoch:18 step:17708 [D loss: 0.533960, acc.: 74.22%] [G loss: 1.344554]\n",
      "epoch:18 step:17709 [D loss: 0.660560, acc.: 59.38%] [G loss: 1.151311]\n",
      "epoch:18 step:17710 [D loss: 0.694552, acc.: 54.69%] [G loss: 0.953625]\n",
      "epoch:18 step:17711 [D loss: 0.655686, acc.: 67.97%] [G loss: 0.900741]\n",
      "epoch:18 step:17712 [D loss: 0.561542, acc.: 75.78%] [G loss: 1.006914]\n",
      "epoch:18 step:17713 [D loss: 0.478004, acc.: 82.81%] [G loss: 1.189339]\n",
      "epoch:18 step:17714 [D loss: 0.611787, acc.: 64.84%] [G loss: 0.865869]\n",
      "epoch:18 step:17715 [D loss: 0.404059, acc.: 89.84%] [G loss: 1.489216]\n",
      "epoch:18 step:17716 [D loss: 0.439590, acc.: 82.03%] [G loss: 1.111655]\n",
      "epoch:18 step:17717 [D loss: 0.319024, acc.: 94.53%] [G loss: 1.481684]\n",
      "epoch:18 step:17718 [D loss: 0.291613, acc.: 93.75%] [G loss: 1.547440]\n",
      "epoch:18 step:17719 [D loss: 0.397214, acc.: 89.84%] [G loss: 1.537834]\n",
      "epoch:18 step:17720 [D loss: 0.268651, acc.: 93.75%] [G loss: 1.614661]\n",
      "epoch:18 step:17721 [D loss: 0.349494, acc.: 91.41%] [G loss: 1.742083]\n",
      "epoch:18 step:17722 [D loss: 0.596300, acc.: 64.84%] [G loss: 1.171025]\n",
      "epoch:18 step:17723 [D loss: 0.378911, acc.: 88.28%] [G loss: 1.171893]\n",
      "epoch:18 step:17724 [D loss: 0.979973, acc.: 39.06%] [G loss: 1.114503]\n",
      "epoch:18 step:17725 [D loss: 0.741239, acc.: 50.00%] [G loss: 1.150973]\n",
      "epoch:18 step:17726 [D loss: 0.596570, acc.: 67.19%] [G loss: 0.963989]\n",
      "epoch:18 step:17727 [D loss: 0.622403, acc.: 61.72%] [G loss: 1.278458]\n",
      "epoch:18 step:17728 [D loss: 0.688421, acc.: 57.03%] [G loss: 1.120672]\n",
      "epoch:18 step:17729 [D loss: 0.547202, acc.: 71.88%] [G loss: 1.107320]\n",
      "epoch:18 step:17730 [D loss: 0.654148, acc.: 57.81%] [G loss: 1.021762]\n",
      "epoch:18 step:17731 [D loss: 0.774218, acc.: 45.31%] [G loss: 0.856353]\n",
      "epoch:18 step:17732 [D loss: 0.820951, acc.: 45.31%] [G loss: 0.829531]\n",
      "epoch:18 step:17733 [D loss: 0.752321, acc.: 52.34%] [G loss: 0.859885]\n",
      "epoch:18 step:17734 [D loss: 0.734568, acc.: 54.69%] [G loss: 1.020161]\n",
      "epoch:18 step:17735 [D loss: 0.625616, acc.: 61.72%] [G loss: 1.137758]\n",
      "epoch:18 step:17736 [D loss: 0.678491, acc.: 60.94%] [G loss: 1.021164]\n",
      "epoch:18 step:17737 [D loss: 0.639527, acc.: 62.50%] [G loss: 1.038548]\n",
      "epoch:18 step:17738 [D loss: 0.715050, acc.: 53.91%] [G loss: 0.913860]\n",
      "epoch:18 step:17739 [D loss: 0.660390, acc.: 57.81%] [G loss: 1.022011]\n",
      "epoch:18 step:17740 [D loss: 0.588295, acc.: 70.31%] [G loss: 0.979853]\n",
      "epoch:18 step:17741 [D loss: 0.543898, acc.: 77.34%] [G loss: 1.082267]\n",
      "epoch:18 step:17742 [D loss: 0.579154, acc.: 69.53%] [G loss: 1.141049]\n",
      "epoch:18 step:17743 [D loss: 0.483670, acc.: 81.25%] [G loss: 1.453804]\n",
      "epoch:18 step:17744 [D loss: 0.406662, acc.: 86.72%] [G loss: 1.281531]\n",
      "epoch:18 step:17745 [D loss: 0.527135, acc.: 74.22%] [G loss: 1.145079]\n",
      "epoch:18 step:17746 [D loss: 0.919908, acc.: 40.62%] [G loss: 1.122445]\n",
      "epoch:18 step:17747 [D loss: 0.758431, acc.: 49.22%] [G loss: 0.923373]\n",
      "epoch:18 step:17748 [D loss: 0.705765, acc.: 53.12%] [G loss: 1.024531]\n",
      "epoch:18 step:17749 [D loss: 0.721621, acc.: 50.00%] [G loss: 0.993051]\n",
      "epoch:18 step:17750 [D loss: 0.536015, acc.: 75.78%] [G loss: 1.141650]\n",
      "epoch:18 step:17751 [D loss: 0.611618, acc.: 67.19%] [G loss: 1.035854]\n",
      "epoch:18 step:17752 [D loss: 0.596439, acc.: 64.06%] [G loss: 0.903531]\n",
      "epoch:18 step:17753 [D loss: 0.491634, acc.: 80.47%] [G loss: 1.149428]\n",
      "epoch:18 step:17754 [D loss: 0.557834, acc.: 73.44%] [G loss: 1.273296]\n",
      "epoch:18 step:17755 [D loss: 0.453758, acc.: 84.38%] [G loss: 1.171623]\n",
      "epoch:18 step:17756 [D loss: 0.425463, acc.: 88.28%] [G loss: 1.479411]\n",
      "epoch:18 step:17757 [D loss: 0.867604, acc.: 35.16%] [G loss: 0.839476]\n",
      "epoch:18 step:17758 [D loss: 0.648446, acc.: 63.28%] [G loss: 1.046518]\n",
      "epoch:18 step:17759 [D loss: 0.583798, acc.: 68.75%] [G loss: 1.260054]\n",
      "epoch:18 step:17760 [D loss: 0.437431, acc.: 85.16%] [G loss: 1.196959]\n",
      "epoch:18 step:17761 [D loss: 0.520019, acc.: 78.12%] [G loss: 1.142387]\n",
      "epoch:18 step:17762 [D loss: 0.549968, acc.: 74.22%] [G loss: 1.015045]\n",
      "epoch:18 step:17763 [D loss: 0.425018, acc.: 84.38%] [G loss: 1.251042]\n",
      "epoch:18 step:17764 [D loss: 0.338209, acc.: 87.50%] [G loss: 1.368330]\n",
      "epoch:18 step:17765 [D loss: 0.334856, acc.: 92.97%] [G loss: 1.484499]\n",
      "epoch:18 step:17766 [D loss: 0.360283, acc.: 88.28%] [G loss: 1.555701]\n",
      "epoch:18 step:17767 [D loss: 0.479814, acc.: 79.69%] [G loss: 1.425143]\n",
      "epoch:18 step:17768 [D loss: 0.795234, acc.: 49.22%] [G loss: 1.302304]\n",
      "epoch:18 step:17769 [D loss: 0.712729, acc.: 56.25%] [G loss: 1.054648]\n",
      "epoch:18 step:17770 [D loss: 0.839138, acc.: 44.53%] [G loss: 1.086785]\n",
      "epoch:18 step:17771 [D loss: 0.630942, acc.: 59.38%] [G loss: 1.141480]\n",
      "epoch:18 step:17772 [D loss: 0.586253, acc.: 65.62%] [G loss: 1.085241]\n",
      "epoch:18 step:17773 [D loss: 0.642778, acc.: 57.03%] [G loss: 1.190262]\n",
      "epoch:18 step:17774 [D loss: 0.675671, acc.: 59.38%] [G loss: 0.742381]\n",
      "epoch:18 step:17775 [D loss: 0.503384, acc.: 75.78%] [G loss: 1.173087]\n",
      "epoch:18 step:17776 [D loss: 0.610323, acc.: 71.09%] [G loss: 1.088882]\n",
      "epoch:18 step:17777 [D loss: 0.392803, acc.: 89.84%] [G loss: 1.164725]\n",
      "epoch:18 step:17778 [D loss: 0.216250, acc.: 96.88%] [G loss: 1.339100]\n",
      "epoch:18 step:17779 [D loss: 0.818532, acc.: 50.00%] [G loss: 1.343274]\n",
      "epoch:18 step:17780 [D loss: 0.765293, acc.: 53.12%] [G loss: 1.179339]\n",
      "epoch:18 step:17781 [D loss: 0.863093, acc.: 43.75%] [G loss: 1.006850]\n",
      "epoch:18 step:17782 [D loss: 0.880382, acc.: 39.84%] [G loss: 0.728196]\n",
      "epoch:18 step:17783 [D loss: 0.771253, acc.: 49.22%] [G loss: 0.988219]\n",
      "epoch:18 step:17784 [D loss: 0.621806, acc.: 64.84%] [G loss: 1.092289]\n",
      "epoch:18 step:17785 [D loss: 0.637092, acc.: 59.38%] [G loss: 1.271845]\n",
      "epoch:18 step:17786 [D loss: 0.380603, acc.: 90.62%] [G loss: 1.461586]\n",
      "epoch:18 step:17787 [D loss: 0.395538, acc.: 83.59%] [G loss: 1.459927]\n",
      "epoch:18 step:17788 [D loss: 0.623018, acc.: 62.50%] [G loss: 1.254475]\n",
      "epoch:18 step:17789 [D loss: 0.477754, acc.: 81.25%] [G loss: 1.173926]\n",
      "epoch:18 step:17790 [D loss: 0.602130, acc.: 66.41%] [G loss: 1.023936]\n",
      "epoch:18 step:17791 [D loss: 0.549231, acc.: 74.22%] [G loss: 1.198403]\n",
      "epoch:18 step:17792 [D loss: 0.516999, acc.: 78.91%] [G loss: 1.005693]\n",
      "epoch:18 step:17793 [D loss: 0.476645, acc.: 81.25%] [G loss: 1.211957]\n",
      "epoch:18 step:17794 [D loss: 0.870799, acc.: 41.41%] [G loss: 1.003139]\n",
      "epoch:18 step:17795 [D loss: 0.401944, acc.: 85.94%] [G loss: 1.239871]\n",
      "epoch:18 step:17796 [D loss: 0.365886, acc.: 88.28%] [G loss: 1.249145]\n",
      "epoch:18 step:17797 [D loss: 0.508375, acc.: 79.69%] [G loss: 1.277211]\n",
      "epoch:18 step:17798 [D loss: 0.572201, acc.: 72.66%] [G loss: 1.137017]\n",
      "epoch:18 step:17799 [D loss: 0.686490, acc.: 59.38%] [G loss: 1.064341]\n",
      "epoch:18 step:17800 [D loss: 0.432191, acc.: 85.16%] [G loss: 1.176829]\n",
      "epoch:18 step:17801 [D loss: 0.654664, acc.: 63.28%] [G loss: 1.184685]\n",
      "epoch:18 step:17802 [D loss: 0.425270, acc.: 85.16%] [G loss: 1.299483]\n",
      "epoch:18 step:17803 [D loss: 0.382857, acc.: 77.34%] [G loss: 1.126205]\n",
      "epoch:19 step:17804 [D loss: 0.618249, acc.: 61.72%] [G loss: 1.119167]\n",
      "epoch:19 step:17805 [D loss: 0.746205, acc.: 57.81%] [G loss: 1.228566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17806 [D loss: 0.717933, acc.: 57.81%] [G loss: 0.918133]\n",
      "epoch:19 step:17807 [D loss: 0.716195, acc.: 53.12%] [G loss: 0.922960]\n",
      "epoch:19 step:17808 [D loss: 0.602883, acc.: 67.97%] [G loss: 1.009326]\n",
      "epoch:19 step:17809 [D loss: 0.575697, acc.: 75.78%] [G loss: 0.886514]\n",
      "epoch:19 step:17810 [D loss: 0.645900, acc.: 63.28%] [G loss: 1.068333]\n",
      "epoch:19 step:17811 [D loss: 0.565485, acc.: 72.66%] [G loss: 1.256489]\n",
      "epoch:19 step:17812 [D loss: 0.590967, acc.: 67.97%] [G loss: 1.085300]\n",
      "epoch:19 step:17813 [D loss: 0.601396, acc.: 63.28%] [G loss: 1.104137]\n",
      "epoch:19 step:17814 [D loss: 0.521981, acc.: 78.12%] [G loss: 0.971532]\n",
      "epoch:19 step:17815 [D loss: 0.681906, acc.: 60.16%] [G loss: 0.782468]\n",
      "epoch:19 step:17816 [D loss: 0.609356, acc.: 64.84%] [G loss: 1.100046]\n",
      "epoch:19 step:17817 [D loss: 0.643299, acc.: 60.16%] [G loss: 0.957305]\n",
      "epoch:19 step:17818 [D loss: 0.385739, acc.: 91.41%] [G loss: 1.161691]\n",
      "epoch:19 step:17819 [D loss: 0.494594, acc.: 79.69%] [G loss: 1.246095]\n",
      "epoch:19 step:17820 [D loss: 0.665448, acc.: 61.72%] [G loss: 1.138099]\n",
      "epoch:19 step:17821 [D loss: 0.845135, acc.: 41.41%] [G loss: 0.739356]\n",
      "epoch:19 step:17822 [D loss: 0.807625, acc.: 44.53%] [G loss: 0.944750]\n",
      "epoch:19 step:17823 [D loss: 1.162330, acc.: 21.88%] [G loss: 0.671722]\n",
      "epoch:19 step:17824 [D loss: 0.707986, acc.: 58.59%] [G loss: 1.115432]\n",
      "epoch:19 step:17825 [D loss: 0.591020, acc.: 68.75%] [G loss: 1.246918]\n",
      "epoch:19 step:17826 [D loss: 0.583348, acc.: 69.53%] [G loss: 1.200279]\n",
      "epoch:19 step:17827 [D loss: 0.642074, acc.: 59.38%] [G loss: 0.938026]\n",
      "epoch:19 step:17828 [D loss: 0.527732, acc.: 77.34%] [G loss: 1.193763]\n",
      "epoch:19 step:17829 [D loss: 0.569582, acc.: 70.31%] [G loss: 1.065196]\n",
      "epoch:19 step:17830 [D loss: 0.436502, acc.: 82.81%] [G loss: 1.213149]\n",
      "epoch:19 step:17831 [D loss: 0.349804, acc.: 92.97%] [G loss: 1.298511]\n",
      "epoch:19 step:17832 [D loss: 0.470687, acc.: 82.81%] [G loss: 1.510759]\n",
      "epoch:19 step:17833 [D loss: 0.490922, acc.: 78.91%] [G loss: 1.465181]\n",
      "epoch:19 step:17834 [D loss: 0.350509, acc.: 92.97%] [G loss: 1.659889]\n",
      "epoch:19 step:17835 [D loss: 0.350177, acc.: 89.84%] [G loss: 1.699457]\n",
      "epoch:19 step:17836 [D loss: 0.553878, acc.: 75.00%] [G loss: 0.926982]\n",
      "epoch:19 step:17837 [D loss: 0.369959, acc.: 90.62%] [G loss: 1.689013]\n",
      "epoch:19 step:17838 [D loss: 0.357878, acc.: 91.41%] [G loss: 1.442590]\n",
      "epoch:19 step:17839 [D loss: 0.233995, acc.: 98.44%] [G loss: 1.885306]\n",
      "epoch:19 step:17840 [D loss: 0.765417, acc.: 50.78%] [G loss: 1.430711]\n",
      "epoch:19 step:17841 [D loss: 0.787178, acc.: 50.78%] [G loss: 1.276831]\n",
      "epoch:19 step:17842 [D loss: 0.837741, acc.: 35.16%] [G loss: 0.899153]\n",
      "epoch:19 step:17843 [D loss: 0.650019, acc.: 62.50%] [G loss: 0.929144]\n",
      "epoch:19 step:17844 [D loss: 0.693447, acc.: 57.81%] [G loss: 0.876798]\n",
      "epoch:19 step:17845 [D loss: 0.476640, acc.: 81.25%] [G loss: 1.245276]\n",
      "epoch:19 step:17846 [D loss: 0.690590, acc.: 62.50%] [G loss: 1.022064]\n",
      "epoch:19 step:17847 [D loss: 0.514756, acc.: 79.69%] [G loss: 1.075763]\n",
      "epoch:19 step:17848 [D loss: 0.708834, acc.: 57.03%] [G loss: 1.241707]\n",
      "epoch:19 step:17849 [D loss: 0.728686, acc.: 53.12%] [G loss: 0.902873]\n",
      "epoch:19 step:17850 [D loss: 0.535212, acc.: 75.78%] [G loss: 1.170655]\n",
      "epoch:19 step:17851 [D loss: 0.610814, acc.: 67.19%] [G loss: 1.087987]\n",
      "epoch:19 step:17852 [D loss: 0.613688, acc.: 64.06%] [G loss: 1.135718]\n",
      "epoch:19 step:17853 [D loss: 0.501106, acc.: 78.12%] [G loss: 1.144550]\n",
      "epoch:19 step:17854 [D loss: 0.623291, acc.: 65.62%] [G loss: 1.116719]\n",
      "epoch:19 step:17855 [D loss: 0.706476, acc.: 50.78%] [G loss: 1.151386]\n",
      "epoch:19 step:17856 [D loss: 0.527551, acc.: 78.91%] [G loss: 1.065147]\n",
      "epoch:19 step:17857 [D loss: 0.496410, acc.: 81.25%] [G loss: 1.056244]\n",
      "epoch:19 step:17858 [D loss: 0.449817, acc.: 83.59%] [G loss: 1.225362]\n",
      "epoch:19 step:17859 [D loss: 0.577542, acc.: 67.97%] [G loss: 1.180395]\n",
      "epoch:19 step:17860 [D loss: 0.690548, acc.: 57.81%] [G loss: 1.049918]\n",
      "epoch:19 step:17861 [D loss: 0.642928, acc.: 63.28%] [G loss: 0.950569]\n",
      "epoch:19 step:17862 [D loss: 0.839274, acc.: 42.97%] [G loss: 0.903914]\n",
      "epoch:19 step:17863 [D loss: 0.624316, acc.: 64.06%] [G loss: 1.000399]\n",
      "epoch:19 step:17864 [D loss: 0.664336, acc.: 63.28%] [G loss: 0.919591]\n",
      "epoch:19 step:17865 [D loss: 0.511732, acc.: 74.22%] [G loss: 1.272907]\n",
      "epoch:19 step:17866 [D loss: 0.687766, acc.: 60.94%] [G loss: 1.072360]\n",
      "epoch:19 step:17867 [D loss: 0.520837, acc.: 73.44%] [G loss: 1.104654]\n",
      "epoch:19 step:17868 [D loss: 0.631074, acc.: 67.97%] [G loss: 1.006084]\n",
      "epoch:19 step:17869 [D loss: 0.620221, acc.: 68.75%] [G loss: 1.021677]\n",
      "epoch:19 step:17870 [D loss: 0.713173, acc.: 59.38%] [G loss: 0.952001]\n",
      "epoch:19 step:17871 [D loss: 0.592725, acc.: 64.06%] [G loss: 1.050902]\n",
      "epoch:19 step:17872 [D loss: 0.465127, acc.: 82.03%] [G loss: 1.033794]\n",
      "epoch:19 step:17873 [D loss: 0.748998, acc.: 45.31%] [G loss: 1.018358]\n",
      "epoch:19 step:17874 [D loss: 0.729655, acc.: 56.25%] [G loss: 1.323743]\n",
      "epoch:19 step:17875 [D loss: 0.765518, acc.: 51.56%] [G loss: 0.944154]\n",
      "epoch:19 step:17876 [D loss: 0.886648, acc.: 34.38%] [G loss: 0.906051]\n",
      "epoch:19 step:17877 [D loss: 0.663986, acc.: 58.59%] [G loss: 0.922961]\n",
      "epoch:19 step:17878 [D loss: 0.360700, acc.: 92.97%] [G loss: 0.989538]\n",
      "epoch:19 step:17879 [D loss: 0.365532, acc.: 91.41%] [G loss: 1.428210]\n",
      "epoch:19 step:17880 [D loss: 0.462256, acc.: 83.59%] [G loss: 1.141406]\n",
      "epoch:19 step:17881 [D loss: 0.670848, acc.: 61.72%] [G loss: 1.353395]\n",
      "epoch:19 step:17882 [D loss: 0.684005, acc.: 55.47%] [G loss: 1.476046]\n",
      "epoch:19 step:17883 [D loss: 0.647402, acc.: 57.81%] [G loss: 0.815951]\n",
      "epoch:19 step:17884 [D loss: 0.748647, acc.: 50.78%] [G loss: 0.839801]\n",
      "epoch:19 step:17885 [D loss: 0.671768, acc.: 63.28%] [G loss: 0.885087]\n",
      "epoch:19 step:17886 [D loss: 0.739615, acc.: 54.69%] [G loss: 0.865177]\n",
      "epoch:19 step:17887 [D loss: 0.654052, acc.: 64.06%] [G loss: 1.127461]\n",
      "epoch:19 step:17888 [D loss: 0.613419, acc.: 67.97%] [G loss: 1.090072]\n",
      "epoch:19 step:17889 [D loss: 0.678320, acc.: 54.69%] [G loss: 1.036578]\n",
      "epoch:19 step:17890 [D loss: 0.721979, acc.: 51.56%] [G loss: 1.136741]\n",
      "epoch:19 step:17891 [D loss: 0.702183, acc.: 56.25%] [G loss: 1.088104]\n",
      "epoch:19 step:17892 [D loss: 0.570226, acc.: 71.09%] [G loss: 1.124343]\n",
      "epoch:19 step:17893 [D loss: 0.661020, acc.: 60.16%] [G loss: 1.112183]\n",
      "epoch:19 step:17894 [D loss: 0.730645, acc.: 53.12%] [G loss: 0.959735]\n",
      "epoch:19 step:17895 [D loss: 0.517734, acc.: 76.56%] [G loss: 0.880946]\n",
      "epoch:19 step:17896 [D loss: 0.667866, acc.: 60.94%] [G loss: 1.024110]\n",
      "epoch:19 step:17897 [D loss: 0.653588, acc.: 58.59%] [G loss: 0.978312]\n",
      "epoch:19 step:17898 [D loss: 0.658841, acc.: 61.72%] [G loss: 0.910409]\n",
      "epoch:19 step:17899 [D loss: 0.682141, acc.: 57.81%] [G loss: 0.879458]\n",
      "epoch:19 step:17900 [D loss: 0.528326, acc.: 81.25%] [G loss: 1.135920]\n",
      "epoch:19 step:17901 [D loss: 0.668868, acc.: 60.16%] [G loss: 0.958795]\n",
      "epoch:19 step:17902 [D loss: 0.613886, acc.: 71.88%] [G loss: 1.121542]\n",
      "epoch:19 step:17903 [D loss: 0.675442, acc.: 54.69%] [G loss: 1.060929]\n",
      "epoch:19 step:17904 [D loss: 0.551530, acc.: 71.09%] [G loss: 1.065039]\n",
      "epoch:19 step:17905 [D loss: 0.574221, acc.: 74.22%] [G loss: 1.017036]\n",
      "epoch:19 step:17906 [D loss: 0.533692, acc.: 79.69%] [G loss: 1.127951]\n",
      "epoch:19 step:17907 [D loss: 0.622548, acc.: 67.19%] [G loss: 0.911186]\n",
      "epoch:19 step:17908 [D loss: 0.559165, acc.: 69.53%] [G loss: 0.935820]\n",
      "epoch:19 step:17909 [D loss: 0.595555, acc.: 69.53%] [G loss: 1.274357]\n",
      "epoch:19 step:17910 [D loss: 0.691960, acc.: 60.16%] [G loss: 0.944655]\n",
      "epoch:19 step:17911 [D loss: 0.757326, acc.: 49.22%] [G loss: 1.026126]\n",
      "epoch:19 step:17912 [D loss: 0.588235, acc.: 67.97%] [G loss: 1.136196]\n",
      "epoch:19 step:17913 [D loss: 0.502888, acc.: 80.47%] [G loss: 1.097257]\n",
      "epoch:19 step:17914 [D loss: 0.579700, acc.: 71.09%] [G loss: 1.195564]\n",
      "epoch:19 step:17915 [D loss: 0.577640, acc.: 67.97%] [G loss: 1.059135]\n",
      "epoch:19 step:17916 [D loss: 0.724521, acc.: 50.00%] [G loss: 1.158402]\n",
      "epoch:19 step:17917 [D loss: 0.698336, acc.: 58.59%] [G loss: 0.880443]\n",
      "epoch:19 step:17918 [D loss: 0.596051, acc.: 65.62%] [G loss: 1.080531]\n",
      "epoch:19 step:17919 [D loss: 0.619464, acc.: 64.06%] [G loss: 1.177652]\n",
      "epoch:19 step:17920 [D loss: 0.622983, acc.: 63.28%] [G loss: 0.943737]\n",
      "epoch:19 step:17921 [D loss: 0.520439, acc.: 74.22%] [G loss: 1.167707]\n",
      "epoch:19 step:17922 [D loss: 0.474539, acc.: 80.47%] [G loss: 0.935849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17923 [D loss: 0.669392, acc.: 57.81%] [G loss: 1.157066]\n",
      "epoch:19 step:17924 [D loss: 0.480790, acc.: 81.25%] [G loss: 1.130338]\n",
      "epoch:19 step:17925 [D loss: 0.382623, acc.: 88.28%] [G loss: 1.320832]\n",
      "epoch:19 step:17926 [D loss: 0.594928, acc.: 64.06%] [G loss: 1.342552]\n",
      "epoch:19 step:17927 [D loss: 0.725009, acc.: 51.56%] [G loss: 1.042873]\n",
      "epoch:19 step:17928 [D loss: 0.754230, acc.: 51.56%] [G loss: 0.881000]\n",
      "epoch:19 step:17929 [D loss: 0.582248, acc.: 71.88%] [G loss: 1.082358]\n",
      "epoch:19 step:17930 [D loss: 0.716193, acc.: 54.69%] [G loss: 1.203080]\n",
      "epoch:19 step:17931 [D loss: 0.630227, acc.: 64.06%] [G loss: 0.682057]\n",
      "epoch:19 step:17932 [D loss: 0.485898, acc.: 76.56%] [G loss: 1.057798]\n",
      "epoch:19 step:17933 [D loss: 0.381111, acc.: 84.38%] [G loss: 1.113073]\n",
      "epoch:19 step:17934 [D loss: 0.329627, acc.: 95.31%] [G loss: 1.044883]\n",
      "epoch:19 step:17935 [D loss: 0.431437, acc.: 88.28%] [G loss: 1.410006]\n",
      "epoch:19 step:17936 [D loss: 0.872455, acc.: 42.97%] [G loss: 1.067596]\n",
      "epoch:19 step:17937 [D loss: 0.785994, acc.: 48.44%] [G loss: 0.994564]\n",
      "epoch:19 step:17938 [D loss: 0.724128, acc.: 59.38%] [G loss: 0.831416]\n",
      "epoch:19 step:17939 [D loss: 0.626771, acc.: 62.50%] [G loss: 0.943711]\n",
      "epoch:19 step:17940 [D loss: 0.745820, acc.: 53.91%] [G loss: 0.854587]\n",
      "epoch:19 step:17941 [D loss: 0.610900, acc.: 65.62%] [G loss: 1.040090]\n",
      "epoch:19 step:17942 [D loss: 0.443462, acc.: 85.94%] [G loss: 1.176667]\n",
      "epoch:19 step:17943 [D loss: 0.947824, acc.: 28.12%] [G loss: 0.883412]\n",
      "epoch:19 step:17944 [D loss: 0.738249, acc.: 53.91%] [G loss: 1.134275]\n",
      "epoch:19 step:17945 [D loss: 0.642010, acc.: 65.62%] [G loss: 1.089704]\n",
      "epoch:19 step:17946 [D loss: 0.562372, acc.: 70.31%] [G loss: 1.157398]\n",
      "epoch:19 step:17947 [D loss: 0.554090, acc.: 71.88%] [G loss: 1.271499]\n",
      "epoch:19 step:17948 [D loss: 0.403085, acc.: 90.62%] [G loss: 1.383769]\n",
      "epoch:19 step:17949 [D loss: 0.624140, acc.: 62.50%] [G loss: 1.161728]\n",
      "epoch:19 step:17950 [D loss: 0.558497, acc.: 70.31%] [G loss: 1.318708]\n",
      "epoch:19 step:17951 [D loss: 0.658656, acc.: 62.50%] [G loss: 0.868403]\n",
      "epoch:19 step:17952 [D loss: 0.664601, acc.: 61.72%] [G loss: 0.982698]\n",
      "epoch:19 step:17953 [D loss: 0.472875, acc.: 78.12%] [G loss: 1.107887]\n",
      "epoch:19 step:17954 [D loss: 0.337289, acc.: 94.53%] [G loss: 1.231789]\n",
      "epoch:19 step:17955 [D loss: 0.495129, acc.: 76.56%] [G loss: 1.263707]\n",
      "epoch:19 step:17956 [D loss: 0.790603, acc.: 50.78%] [G loss: 1.173508]\n",
      "epoch:19 step:17957 [D loss: 0.704475, acc.: 55.47%] [G loss: 1.047067]\n",
      "epoch:19 step:17958 [D loss: 0.608572, acc.: 62.50%] [G loss: 1.094750]\n",
      "epoch:19 step:17959 [D loss: 0.521980, acc.: 78.12%] [G loss: 1.070947]\n",
      "epoch:19 step:17960 [D loss: 0.674515, acc.: 59.38%] [G loss: 0.910697]\n",
      "epoch:19 step:17961 [D loss: 0.683577, acc.: 56.25%] [G loss: 0.989626]\n",
      "epoch:19 step:17962 [D loss: 0.583458, acc.: 68.75%] [G loss: 1.066919]\n",
      "epoch:19 step:17963 [D loss: 0.761448, acc.: 53.12%] [G loss: 1.123764]\n",
      "epoch:19 step:17964 [D loss: 0.683143, acc.: 60.16%] [G loss: 0.860752]\n",
      "epoch:19 step:17965 [D loss: 0.682594, acc.: 57.03%] [G loss: 0.945046]\n",
      "epoch:19 step:17966 [D loss: 0.752420, acc.: 54.69%] [G loss: 0.913570]\n",
      "epoch:19 step:17967 [D loss: 0.649237, acc.: 56.25%] [G loss: 0.954949]\n",
      "epoch:19 step:17968 [D loss: 0.551862, acc.: 77.34%] [G loss: 1.016730]\n",
      "epoch:19 step:17969 [D loss: 0.636712, acc.: 64.06%] [G loss: 1.100037]\n",
      "epoch:19 step:17970 [D loss: 0.634204, acc.: 66.41%] [G loss: 0.985593]\n",
      "epoch:19 step:17971 [D loss: 0.514781, acc.: 77.34%] [G loss: 1.323810]\n",
      "epoch:19 step:17972 [D loss: 0.685003, acc.: 58.59%] [G loss: 1.139151]\n",
      "epoch:19 step:17973 [D loss: 0.664470, acc.: 60.16%] [G loss: 0.913155]\n",
      "epoch:19 step:17974 [D loss: 0.564497, acc.: 71.09%] [G loss: 1.078790]\n",
      "epoch:19 step:17975 [D loss: 0.602473, acc.: 72.66%] [G loss: 1.010574]\n",
      "epoch:19 step:17976 [D loss: 0.627738, acc.: 64.84%] [G loss: 0.996814]\n",
      "epoch:19 step:17977 [D loss: 0.652727, acc.: 59.38%] [G loss: 0.799367]\n",
      "epoch:19 step:17978 [D loss: 0.718565, acc.: 62.50%] [G loss: 0.916025]\n",
      "epoch:19 step:17979 [D loss: 0.612144, acc.: 62.50%] [G loss: 0.993182]\n",
      "epoch:19 step:17980 [D loss: 0.716124, acc.: 48.44%] [G loss: 1.001215]\n",
      "epoch:19 step:17981 [D loss: 0.771918, acc.: 49.22%] [G loss: 0.925359]\n",
      "epoch:19 step:17982 [D loss: 0.693159, acc.: 54.69%] [G loss: 0.898152]\n",
      "epoch:19 step:17983 [D loss: 0.689995, acc.: 52.34%] [G loss: 0.901059]\n",
      "epoch:19 step:17984 [D loss: 0.645636, acc.: 65.62%] [G loss: 1.047797]\n",
      "epoch:19 step:17985 [D loss: 0.827952, acc.: 49.22%] [G loss: 0.674596]\n",
      "epoch:19 step:17986 [D loss: 0.641127, acc.: 63.28%] [G loss: 1.012121]\n",
      "epoch:19 step:17987 [D loss: 0.734632, acc.: 50.00%] [G loss: 1.035223]\n",
      "epoch:19 step:17988 [D loss: 0.706060, acc.: 55.47%] [G loss: 1.005597]\n",
      "epoch:19 step:17989 [D loss: 0.711588, acc.: 47.66%] [G loss: 1.073807]\n",
      "epoch:19 step:17990 [D loss: 0.624747, acc.: 63.28%] [G loss: 1.156871]\n",
      "epoch:19 step:17991 [D loss: 0.627839, acc.: 67.97%] [G loss: 1.128377]\n",
      "epoch:19 step:17992 [D loss: 0.598749, acc.: 70.31%] [G loss: 0.961497]\n",
      "epoch:19 step:17993 [D loss: 0.667801, acc.: 62.50%] [G loss: 1.010438]\n",
      "epoch:19 step:17994 [D loss: 0.597440, acc.: 69.53%] [G loss: 1.031687]\n",
      "epoch:19 step:17995 [D loss: 0.472486, acc.: 86.72%] [G loss: 1.132726]\n",
      "epoch:19 step:17996 [D loss: 0.561637, acc.: 71.88%] [G loss: 1.188913]\n",
      "epoch:19 step:17997 [D loss: 0.551283, acc.: 67.97%] [G loss: 1.034675]\n",
      "epoch:19 step:17998 [D loss: 0.646610, acc.: 60.94%] [G loss: 0.916115]\n",
      "epoch:19 step:17999 [D loss: 0.591559, acc.: 68.75%] [G loss: 1.114803]\n",
      "epoch:19 step:18000 [D loss: 0.614225, acc.: 67.97%] [G loss: 1.080123]\n",
      "epoch:19 step:18001 [D loss: 0.718730, acc.: 57.03%] [G loss: 0.901528]\n",
      "epoch:19 step:18002 [D loss: 0.677120, acc.: 60.94%] [G loss: 1.011266]\n",
      "epoch:19 step:18003 [D loss: 0.505784, acc.: 76.56%] [G loss: 1.171113]\n",
      "epoch:19 step:18004 [D loss: 0.335489, acc.: 93.75%] [G loss: 1.544402]\n",
      "epoch:19 step:18005 [D loss: 0.606342, acc.: 61.72%] [G loss: 1.362985]\n",
      "epoch:19 step:18006 [D loss: 0.625293, acc.: 63.28%] [G loss: 1.335542]\n",
      "epoch:19 step:18007 [D loss: 0.672752, acc.: 55.47%] [G loss: 1.084374]\n",
      "epoch:19 step:18008 [D loss: 0.777898, acc.: 41.41%] [G loss: 1.051852]\n",
      "epoch:19 step:18009 [D loss: 0.740179, acc.: 56.25%] [G loss: 0.685960]\n",
      "epoch:19 step:18010 [D loss: 0.560228, acc.: 72.66%] [G loss: 1.116503]\n",
      "epoch:19 step:18011 [D loss: 0.612466, acc.: 63.28%] [G loss: 0.925375]\n",
      "epoch:19 step:18012 [D loss: 0.574882, acc.: 70.31%] [G loss: 0.951679]\n",
      "epoch:19 step:18013 [D loss: 0.654134, acc.: 61.72%] [G loss: 1.149877]\n",
      "epoch:19 step:18014 [D loss: 0.489668, acc.: 79.69%] [G loss: 1.085669]\n",
      "epoch:19 step:18015 [D loss: 0.736409, acc.: 54.69%] [G loss: 0.728276]\n",
      "epoch:19 step:18016 [D loss: 0.580927, acc.: 66.41%] [G loss: 1.063747]\n",
      "epoch:19 step:18017 [D loss: 0.938267, acc.: 30.47%] [G loss: 0.968636]\n",
      "epoch:19 step:18018 [D loss: 0.570915, acc.: 67.97%] [G loss: 1.003589]\n",
      "epoch:19 step:18019 [D loss: 0.672469, acc.: 61.72%] [G loss: 0.889563]\n",
      "epoch:19 step:18020 [D loss: 0.838104, acc.: 40.62%] [G loss: 0.944715]\n",
      "epoch:19 step:18021 [D loss: 0.445340, acc.: 86.72%] [G loss: 1.168111]\n",
      "epoch:19 step:18022 [D loss: 0.536125, acc.: 72.66%] [G loss: 0.988403]\n",
      "epoch:19 step:18023 [D loss: 0.438839, acc.: 78.91%] [G loss: 1.173814]\n",
      "epoch:19 step:18024 [D loss: 0.355061, acc.: 92.97%] [G loss: 1.535151]\n",
      "epoch:19 step:18025 [D loss: 0.406505, acc.: 89.06%] [G loss: 1.454759]\n",
      "epoch:19 step:18026 [D loss: 0.342567, acc.: 89.84%] [G loss: 1.343737]\n",
      "epoch:19 step:18027 [D loss: 0.818396, acc.: 48.44%] [G loss: 1.224242]\n",
      "epoch:19 step:18028 [D loss: 0.749209, acc.: 52.34%] [G loss: 0.858205]\n",
      "epoch:19 step:18029 [D loss: 0.603560, acc.: 63.28%] [G loss: 1.227431]\n",
      "epoch:19 step:18030 [D loss: 0.756511, acc.: 50.00%] [G loss: 1.044334]\n",
      "epoch:19 step:18031 [D loss: 0.694790, acc.: 53.91%] [G loss: 1.121862]\n",
      "epoch:19 step:18032 [D loss: 0.633715, acc.: 66.41%] [G loss: 0.932927]\n",
      "epoch:19 step:18033 [D loss: 0.292707, acc.: 92.19%] [G loss: 1.312429]\n",
      "epoch:19 step:18034 [D loss: 0.451280, acc.: 83.59%] [G loss: 1.246238]\n",
      "epoch:19 step:18035 [D loss: 0.336736, acc.: 92.19%] [G loss: 1.299205]\n",
      "epoch:19 step:18036 [D loss: 0.783261, acc.: 49.22%] [G loss: 1.100225]\n",
      "epoch:19 step:18037 [D loss: 0.574497, acc.: 73.44%] [G loss: 1.369947]\n",
      "epoch:19 step:18038 [D loss: 0.462825, acc.: 81.25%] [G loss: 1.175738]\n",
      "epoch:19 step:18039 [D loss: 0.870264, acc.: 39.06%] [G loss: 0.689498]\n",
      "epoch:19 step:18040 [D loss: 0.501767, acc.: 78.12%] [G loss: 1.381793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18041 [D loss: 0.488964, acc.: 85.16%] [G loss: 1.082895]\n",
      "epoch:19 step:18042 [D loss: 0.624581, acc.: 64.06%] [G loss: 1.146620]\n",
      "epoch:19 step:18043 [D loss: 0.864904, acc.: 39.06%] [G loss: 0.832926]\n",
      "epoch:19 step:18044 [D loss: 0.582706, acc.: 69.53%] [G loss: 0.997344]\n",
      "epoch:19 step:18045 [D loss: 0.910312, acc.: 34.38%] [G loss: 0.798796]\n",
      "epoch:19 step:18046 [D loss: 0.810662, acc.: 38.28%] [G loss: 1.036122]\n",
      "epoch:19 step:18047 [D loss: 0.658022, acc.: 64.06%] [G loss: 0.865945]\n",
      "epoch:19 step:18048 [D loss: 0.690124, acc.: 60.16%] [G loss: 1.049779]\n",
      "epoch:19 step:18049 [D loss: 0.647921, acc.: 67.19%] [G loss: 1.123806]\n",
      "epoch:19 step:18050 [D loss: 0.516020, acc.: 77.34%] [G loss: 1.113953]\n",
      "epoch:19 step:18051 [D loss: 0.446014, acc.: 85.16%] [G loss: 1.288667]\n",
      "epoch:19 step:18052 [D loss: 0.653271, acc.: 65.62%] [G loss: 1.162763]\n",
      "epoch:19 step:18053 [D loss: 0.510974, acc.: 82.03%] [G loss: 1.365285]\n",
      "epoch:19 step:18054 [D loss: 0.577584, acc.: 71.88%] [G loss: 1.160119]\n",
      "epoch:19 step:18055 [D loss: 0.653865, acc.: 65.62%] [G loss: 1.012132]\n",
      "epoch:19 step:18056 [D loss: 0.636833, acc.: 63.28%] [G loss: 0.913600]\n",
      "epoch:19 step:18057 [D loss: 0.617081, acc.: 64.84%] [G loss: 1.175916]\n",
      "epoch:19 step:18058 [D loss: 0.943058, acc.: 27.34%] [G loss: 0.826147]\n",
      "epoch:19 step:18059 [D loss: 0.769371, acc.: 53.91%] [G loss: 1.105225]\n",
      "epoch:19 step:18060 [D loss: 0.939485, acc.: 26.56%] [G loss: 0.623596]\n",
      "epoch:19 step:18061 [D loss: 0.627604, acc.: 63.28%] [G loss: 1.195072]\n",
      "epoch:19 step:18062 [D loss: 0.498823, acc.: 78.12%] [G loss: 1.157046]\n",
      "epoch:19 step:18063 [D loss: 0.664258, acc.: 66.41%] [G loss: 1.083851]\n",
      "epoch:19 step:18064 [D loss: 0.455022, acc.: 85.16%] [G loss: 1.371260]\n",
      "epoch:19 step:18065 [D loss: 0.586527, acc.: 64.06%] [G loss: 1.042232]\n",
      "epoch:19 step:18066 [D loss: 0.678135, acc.: 59.38%] [G loss: 1.017771]\n",
      "epoch:19 step:18067 [D loss: 0.534294, acc.: 74.22%] [G loss: 0.854191]\n",
      "epoch:19 step:18068 [D loss: 0.621648, acc.: 66.41%] [G loss: 0.975848]\n",
      "epoch:19 step:18069 [D loss: 0.626670, acc.: 61.72%] [G loss: 1.025299]\n",
      "epoch:19 step:18070 [D loss: 0.476710, acc.: 82.03%] [G loss: 1.221437]\n",
      "epoch:19 step:18071 [D loss: 0.762951, acc.: 50.78%] [G loss: 1.021351]\n",
      "epoch:19 step:18072 [D loss: 0.659940, acc.: 62.50%] [G loss: 1.077109]\n",
      "epoch:19 step:18073 [D loss: 0.656907, acc.: 60.94%] [G loss: 1.027689]\n",
      "epoch:19 step:18074 [D loss: 0.556924, acc.: 73.44%] [G loss: 0.954213]\n",
      "epoch:19 step:18075 [D loss: 0.469386, acc.: 78.91%] [G loss: 1.103573]\n",
      "epoch:19 step:18076 [D loss: 0.538903, acc.: 76.56%] [G loss: 1.074296]\n",
      "epoch:19 step:18077 [D loss: 0.618458, acc.: 67.19%] [G loss: 1.101616]\n",
      "epoch:19 step:18078 [D loss: 0.715643, acc.: 54.69%] [G loss: 0.767046]\n",
      "epoch:19 step:18079 [D loss: 0.715735, acc.: 52.34%] [G loss: 0.931225]\n",
      "epoch:19 step:18080 [D loss: 0.654278, acc.: 59.38%] [G loss: 0.952645]\n",
      "epoch:19 step:18081 [D loss: 0.600502, acc.: 66.41%] [G loss: 1.109378]\n",
      "epoch:19 step:18082 [D loss: 0.471495, acc.: 78.91%] [G loss: 1.310819]\n",
      "epoch:19 step:18083 [D loss: 0.528261, acc.: 72.66%] [G loss: 1.221639]\n",
      "epoch:19 step:18084 [D loss: 0.733049, acc.: 54.69%] [G loss: 1.202663]\n",
      "epoch:19 step:18085 [D loss: 0.562504, acc.: 73.44%] [G loss: 1.132396]\n",
      "epoch:19 step:18086 [D loss: 0.605987, acc.: 66.41%] [G loss: 1.163067]\n",
      "epoch:19 step:18087 [D loss: 0.514015, acc.: 78.12%] [G loss: 1.158152]\n",
      "epoch:19 step:18088 [D loss: 0.421780, acc.: 88.28%] [G loss: 1.202227]\n",
      "epoch:19 step:18089 [D loss: 0.503479, acc.: 80.47%] [G loss: 1.201259]\n",
      "epoch:19 step:18090 [D loss: 0.608253, acc.: 66.41%] [G loss: 1.178370]\n",
      "epoch:19 step:18091 [D loss: 0.604222, acc.: 64.06%] [G loss: 1.090950]\n",
      "epoch:19 step:18092 [D loss: 0.438640, acc.: 83.59%] [G loss: 1.319416]\n",
      "epoch:19 step:18093 [D loss: 0.660038, acc.: 61.72%] [G loss: 1.144449]\n",
      "epoch:19 step:18094 [D loss: 0.387850, acc.: 82.81%] [G loss: 1.218495]\n",
      "epoch:19 step:18095 [D loss: 0.536862, acc.: 71.88%] [G loss: 1.089730]\n",
      "epoch:19 step:18096 [D loss: 0.392725, acc.: 84.38%] [G loss: 1.182252]\n",
      "epoch:19 step:18097 [D loss: 0.645713, acc.: 64.06%] [G loss: 1.069744]\n",
      "epoch:19 step:18098 [D loss: 0.798947, acc.: 44.53%] [G loss: 1.031315]\n",
      "epoch:19 step:18099 [D loss: 0.549869, acc.: 75.78%] [G loss: 1.279570]\n",
      "epoch:19 step:18100 [D loss: 0.744868, acc.: 55.47%] [G loss: 0.830156]\n",
      "epoch:19 step:18101 [D loss: 0.509515, acc.: 78.91%] [G loss: 1.115899]\n",
      "epoch:19 step:18102 [D loss: 0.618219, acc.: 66.41%] [G loss: 1.053738]\n",
      "epoch:19 step:18103 [D loss: 0.601054, acc.: 72.66%] [G loss: 1.002805]\n",
      "epoch:19 step:18104 [D loss: 0.802267, acc.: 43.75%] [G loss: 1.143193]\n",
      "epoch:19 step:18105 [D loss: 0.664208, acc.: 58.59%] [G loss: 0.966628]\n",
      "epoch:19 step:18106 [D loss: 0.625921, acc.: 68.75%] [G loss: 0.949880]\n",
      "epoch:19 step:18107 [D loss: 0.684277, acc.: 62.50%] [G loss: 1.079169]\n",
      "epoch:19 step:18108 [D loss: 0.755738, acc.: 50.00%] [G loss: 1.049539]\n",
      "epoch:19 step:18109 [D loss: 0.583141, acc.: 67.19%] [G loss: 1.214080]\n",
      "epoch:19 step:18110 [D loss: 0.553178, acc.: 76.56%] [G loss: 0.988370]\n",
      "epoch:19 step:18111 [D loss: 0.723382, acc.: 53.12%] [G loss: 1.096035]\n",
      "epoch:19 step:18112 [D loss: 0.552118, acc.: 75.78%] [G loss: 1.005930]\n",
      "epoch:19 step:18113 [D loss: 0.580173, acc.: 64.84%] [G loss: 0.867833]\n",
      "epoch:19 step:18114 [D loss: 0.643269, acc.: 61.72%] [G loss: 0.909741]\n",
      "epoch:19 step:18115 [D loss: 0.586519, acc.: 71.09%] [G loss: 1.076566]\n",
      "epoch:19 step:18116 [D loss: 0.511064, acc.: 76.56%] [G loss: 1.236963]\n",
      "epoch:19 step:18117 [D loss: 0.528881, acc.: 78.12%] [G loss: 1.256840]\n",
      "epoch:19 step:18118 [D loss: 0.603619, acc.: 70.31%] [G loss: 1.162311]\n",
      "epoch:19 step:18119 [D loss: 0.581554, acc.: 68.75%] [G loss: 1.263799]\n",
      "epoch:19 step:18120 [D loss: 0.495807, acc.: 82.81%] [G loss: 1.175498]\n",
      "epoch:19 step:18121 [D loss: 0.474534, acc.: 79.69%] [G loss: 1.192563]\n",
      "epoch:19 step:18122 [D loss: 0.494742, acc.: 82.81%] [G loss: 1.264631]\n",
      "epoch:19 step:18123 [D loss: 0.432967, acc.: 83.59%] [G loss: 1.136403]\n",
      "epoch:19 step:18124 [D loss: 0.383966, acc.: 89.06%] [G loss: 1.296525]\n",
      "epoch:19 step:18125 [D loss: 0.430493, acc.: 86.72%] [G loss: 1.136384]\n",
      "epoch:19 step:18126 [D loss: 0.804552, acc.: 50.78%] [G loss: 1.175803]\n",
      "epoch:19 step:18127 [D loss: 0.650051, acc.: 62.50%] [G loss: 1.131531]\n",
      "epoch:19 step:18128 [D loss: 0.664297, acc.: 60.16%] [G loss: 1.050310]\n",
      "epoch:19 step:18129 [D loss: 0.473877, acc.: 81.25%] [G loss: 1.319329]\n",
      "epoch:19 step:18130 [D loss: 0.408573, acc.: 84.38%] [G loss: 1.295912]\n",
      "epoch:19 step:18131 [D loss: 0.357135, acc.: 89.06%] [G loss: 1.719998]\n",
      "epoch:19 step:18132 [D loss: 0.707984, acc.: 52.34%] [G loss: 0.926681]\n",
      "epoch:19 step:18133 [D loss: 1.047762, acc.: 17.97%] [G loss: 0.873186]\n",
      "epoch:19 step:18134 [D loss: 0.955521, acc.: 35.16%] [G loss: 0.844084]\n",
      "epoch:19 step:18135 [D loss: 0.808394, acc.: 39.84%] [G loss: 1.011503]\n",
      "epoch:19 step:18136 [D loss: 0.867087, acc.: 39.84%] [G loss: 0.817571]\n",
      "epoch:19 step:18137 [D loss: 0.824151, acc.: 39.06%] [G loss: 0.892685]\n",
      "epoch:19 step:18138 [D loss: 1.003895, acc.: 25.00%] [G loss: 0.725051]\n",
      "epoch:19 step:18139 [D loss: 0.584341, acc.: 69.53%] [G loss: 1.360812]\n",
      "epoch:19 step:18140 [D loss: 0.661280, acc.: 58.59%] [G loss: 1.293248]\n",
      "epoch:19 step:18141 [D loss: 0.663774, acc.: 57.81%] [G loss: 1.086421]\n",
      "epoch:19 step:18142 [D loss: 0.660177, acc.: 59.38%] [G loss: 1.106998]\n",
      "epoch:19 step:18143 [D loss: 0.755753, acc.: 50.00%] [G loss: 0.931514]\n",
      "epoch:19 step:18144 [D loss: 0.646423, acc.: 62.50%] [G loss: 0.939394]\n",
      "epoch:19 step:18145 [D loss: 0.424745, acc.: 82.03%] [G loss: 1.163324]\n",
      "epoch:19 step:18146 [D loss: 0.259820, acc.: 98.44%] [G loss: 1.503378]\n",
      "epoch:19 step:18147 [D loss: 0.357591, acc.: 92.97%] [G loss: 1.599044]\n",
      "epoch:19 step:18148 [D loss: 0.285927, acc.: 93.75%] [G loss: 1.542515]\n",
      "epoch:19 step:18149 [D loss: 0.217438, acc.: 98.44%] [G loss: 1.844926]\n",
      "epoch:19 step:18150 [D loss: 0.306992, acc.: 92.19%] [G loss: 1.710971]\n",
      "epoch:19 step:18151 [D loss: 0.831573, acc.: 46.88%] [G loss: 1.201725]\n",
      "epoch:19 step:18152 [D loss: 0.838314, acc.: 43.75%] [G loss: 1.249821]\n",
      "epoch:19 step:18153 [D loss: 0.693752, acc.: 51.56%] [G loss: 1.118757]\n",
      "epoch:19 step:18154 [D loss: 0.622723, acc.: 67.19%] [G loss: 1.008803]\n",
      "epoch:19 step:18155 [D loss: 0.591749, acc.: 71.09%] [G loss: 1.027079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18156 [D loss: 0.685467, acc.: 56.25%] [G loss: 1.053576]\n",
      "epoch:19 step:18157 [D loss: 0.717471, acc.: 55.47%] [G loss: 0.982528]\n",
      "epoch:19 step:18158 [D loss: 0.654282, acc.: 60.16%] [G loss: 0.907493]\n",
      "epoch:19 step:18159 [D loss: 0.625248, acc.: 64.84%] [G loss: 0.858788]\n",
      "epoch:19 step:18160 [D loss: 0.711149, acc.: 54.69%] [G loss: 1.021611]\n",
      "epoch:19 step:18161 [D loss: 0.467197, acc.: 83.59%] [G loss: 1.005510]\n",
      "epoch:19 step:18162 [D loss: 0.600151, acc.: 67.19%] [G loss: 1.047100]\n",
      "epoch:19 step:18163 [D loss: 0.647097, acc.: 60.16%] [G loss: 1.013881]\n",
      "epoch:19 step:18164 [D loss: 0.716383, acc.: 55.47%] [G loss: 0.908706]\n",
      "epoch:19 step:18165 [D loss: 0.662562, acc.: 57.81%] [G loss: 0.832640]\n",
      "epoch:19 step:18166 [D loss: 0.500349, acc.: 75.00%] [G loss: 1.156845]\n",
      "epoch:19 step:18167 [D loss: 0.488478, acc.: 81.25%] [G loss: 1.329805]\n",
      "epoch:19 step:18168 [D loss: 0.517023, acc.: 72.66%] [G loss: 1.114745]\n",
      "epoch:19 step:18169 [D loss: 0.289540, acc.: 96.88%] [G loss: 1.339410]\n",
      "epoch:19 step:18170 [D loss: 0.398283, acc.: 86.72%] [G loss: 1.323874]\n",
      "epoch:19 step:18171 [D loss: 0.695764, acc.: 57.03%] [G loss: 1.504806]\n",
      "epoch:19 step:18172 [D loss: 0.697502, acc.: 53.12%] [G loss: 1.067779]\n",
      "epoch:19 step:18173 [D loss: 0.597220, acc.: 67.19%] [G loss: 1.198729]\n",
      "epoch:19 step:18174 [D loss: 0.599294, acc.: 69.53%] [G loss: 0.935708]\n",
      "epoch:19 step:18175 [D loss: 0.684016, acc.: 59.38%] [G loss: 1.046750]\n",
      "epoch:19 step:18176 [D loss: 0.774743, acc.: 47.66%] [G loss: 1.050720]\n",
      "epoch:19 step:18177 [D loss: 0.633209, acc.: 66.41%] [G loss: 1.032396]\n",
      "epoch:19 step:18178 [D loss: 0.757779, acc.: 50.00%] [G loss: 0.866626]\n",
      "epoch:19 step:18179 [D loss: 0.645327, acc.: 61.72%] [G loss: 1.004475]\n",
      "epoch:19 step:18180 [D loss: 0.657632, acc.: 57.03%] [G loss: 0.923848]\n",
      "epoch:19 step:18181 [D loss: 0.502370, acc.: 73.44%] [G loss: 0.998371]\n",
      "epoch:19 step:18182 [D loss: 0.645770, acc.: 57.81%] [G loss: 1.172851]\n",
      "epoch:19 step:18183 [D loss: 0.459018, acc.: 83.59%] [G loss: 1.094045]\n",
      "epoch:19 step:18184 [D loss: 0.577321, acc.: 72.66%] [G loss: 1.070421]\n",
      "epoch:19 step:18185 [D loss: 0.705612, acc.: 60.16%] [G loss: 1.028801]\n",
      "epoch:19 step:18186 [D loss: 0.628181, acc.: 64.06%] [G loss: 0.990812]\n",
      "epoch:19 step:18187 [D loss: 0.606245, acc.: 62.50%] [G loss: 0.971646]\n",
      "epoch:19 step:18188 [D loss: 0.644824, acc.: 64.06%] [G loss: 1.077837]\n",
      "epoch:19 step:18189 [D loss: 0.724617, acc.: 50.00%] [G loss: 0.891644]\n",
      "epoch:19 step:18190 [D loss: 0.725651, acc.: 49.22%] [G loss: 0.979557]\n",
      "epoch:19 step:18191 [D loss: 0.697570, acc.: 56.25%] [G loss: 1.023774]\n",
      "epoch:19 step:18192 [D loss: 0.698792, acc.: 53.12%] [G loss: 1.140683]\n",
      "epoch:19 step:18193 [D loss: 0.543643, acc.: 74.22%] [G loss: 1.027948]\n",
      "epoch:19 step:18194 [D loss: 0.616556, acc.: 66.41%] [G loss: 1.078886]\n",
      "epoch:19 step:18195 [D loss: 0.516638, acc.: 76.56%] [G loss: 1.038826]\n",
      "epoch:19 step:18196 [D loss: 0.600085, acc.: 67.97%] [G loss: 1.057814]\n",
      "epoch:19 step:18197 [D loss: 0.603192, acc.: 67.97%] [G loss: 0.886592]\n",
      "epoch:19 step:18198 [D loss: 0.605667, acc.: 69.53%] [G loss: 1.119763]\n",
      "epoch:19 step:18199 [D loss: 0.489586, acc.: 82.03%] [G loss: 0.995031]\n",
      "epoch:19 step:18200 [D loss: 0.484119, acc.: 72.66%] [G loss: 0.980973]\n",
      "epoch:19 step:18201 [D loss: 0.357688, acc.: 90.62%] [G loss: 1.722973]\n",
      "epoch:19 step:18202 [D loss: 0.510189, acc.: 77.34%] [G loss: 1.478432]\n",
      "epoch:19 step:18203 [D loss: 0.500188, acc.: 77.34%] [G loss: 1.171051]\n",
      "epoch:19 step:18204 [D loss: 0.625331, acc.: 67.97%] [G loss: 1.354523]\n",
      "epoch:19 step:18205 [D loss: 0.435847, acc.: 81.25%] [G loss: 1.614899]\n",
      "epoch:19 step:18206 [D loss: 0.493387, acc.: 78.91%] [G loss: 1.422321]\n",
      "epoch:19 step:18207 [D loss: 0.716175, acc.: 60.16%] [G loss: 0.884495]\n",
      "epoch:19 step:18208 [D loss: 0.598568, acc.: 63.28%] [G loss: 1.122201]\n",
      "epoch:19 step:18209 [D loss: 0.463650, acc.: 82.03%] [G loss: 1.243107]\n",
      "epoch:19 step:18210 [D loss: 0.530754, acc.: 77.34%] [G loss: 1.174869]\n",
      "epoch:19 step:18211 [D loss: 0.957905, acc.: 30.47%] [G loss: 0.850134]\n",
      "epoch:19 step:18212 [D loss: 0.724451, acc.: 57.03%] [G loss: 0.959119]\n",
      "epoch:19 step:18213 [D loss: 0.637735, acc.: 68.75%] [G loss: 1.275815]\n",
      "epoch:19 step:18214 [D loss: 1.006922, acc.: 23.44%] [G loss: 0.650743]\n",
      "epoch:19 step:18215 [D loss: 0.737244, acc.: 56.25%] [G loss: 1.070698]\n",
      "epoch:19 step:18216 [D loss: 0.934672, acc.: 32.03%] [G loss: 1.120705]\n",
      "epoch:19 step:18217 [D loss: 0.864821, acc.: 46.88%] [G loss: 1.091268]\n",
      "epoch:19 step:18218 [D loss: 0.885435, acc.: 39.84%] [G loss: 1.247985]\n",
      "epoch:19 step:18219 [D loss: 0.759314, acc.: 56.25%] [G loss: 1.071539]\n",
      "epoch:19 step:18220 [D loss: 0.943725, acc.: 35.16%] [G loss: 1.208700]\n",
      "epoch:19 step:18221 [D loss: 0.708643, acc.: 51.56%] [G loss: 0.999306]\n",
      "epoch:19 step:18222 [D loss: 0.726857, acc.: 55.47%] [G loss: 0.859815]\n",
      "epoch:19 step:18223 [D loss: 0.657069, acc.: 60.16%] [G loss: 0.851851]\n",
      "epoch:19 step:18224 [D loss: 0.756533, acc.: 47.66%] [G loss: 1.057052]\n",
      "epoch:19 step:18225 [D loss: 0.669740, acc.: 61.72%] [G loss: 1.163739]\n",
      "epoch:19 step:18226 [D loss: 0.668417, acc.: 63.28%] [G loss: 1.567346]\n",
      "epoch:19 step:18227 [D loss: 0.817780, acc.: 42.19%] [G loss: 0.919512]\n",
      "epoch:19 step:18228 [D loss: 0.549919, acc.: 71.88%] [G loss: 1.377973]\n",
      "epoch:19 step:18229 [D loss: 0.637245, acc.: 62.50%] [G loss: 1.125240]\n",
      "epoch:19 step:18230 [D loss: 0.686618, acc.: 58.59%] [G loss: 0.926491]\n",
      "epoch:19 step:18231 [D loss: 0.532738, acc.: 75.00%] [G loss: 0.998127]\n",
      "epoch:19 step:18232 [D loss: 0.574056, acc.: 75.78%] [G loss: 1.316710]\n",
      "epoch:19 step:18233 [D loss: 0.628312, acc.: 63.28%] [G loss: 1.119939]\n",
      "epoch:19 step:18234 [D loss: 0.535382, acc.: 75.00%] [G loss: 1.226720]\n",
      "epoch:19 step:18235 [D loss: 0.519389, acc.: 77.34%] [G loss: 1.357516]\n",
      "epoch:19 step:18236 [D loss: 0.545863, acc.: 73.44%] [G loss: 1.354485]\n",
      "epoch:19 step:18237 [D loss: 0.619089, acc.: 67.19%] [G loss: 1.262186]\n",
      "epoch:19 step:18238 [D loss: 0.585808, acc.: 69.53%] [G loss: 1.336037]\n",
      "epoch:19 step:18239 [D loss: 0.504044, acc.: 74.22%] [G loss: 1.279967]\n",
      "epoch:19 step:18240 [D loss: 0.726227, acc.: 57.03%] [G loss: 0.906451]\n",
      "epoch:19 step:18241 [D loss: 0.667176, acc.: 60.94%] [G loss: 1.133991]\n",
      "epoch:19 step:18242 [D loss: 0.719700, acc.: 57.03%] [G loss: 1.042036]\n",
      "epoch:19 step:18243 [D loss: 0.850816, acc.: 38.28%] [G loss: 0.985234]\n",
      "epoch:19 step:18244 [D loss: 0.595385, acc.: 68.75%] [G loss: 1.216687]\n",
      "epoch:19 step:18245 [D loss: 0.751604, acc.: 51.56%] [G loss: 0.922999]\n",
      "epoch:19 step:18246 [D loss: 0.586401, acc.: 67.97%] [G loss: 1.100724]\n",
      "epoch:19 step:18247 [D loss: 0.594358, acc.: 67.97%] [G loss: 1.036393]\n",
      "epoch:19 step:18248 [D loss: 0.738806, acc.: 53.12%] [G loss: 0.960893]\n",
      "epoch:19 step:18249 [D loss: 0.806745, acc.: 43.75%] [G loss: 0.745874]\n",
      "epoch:19 step:18250 [D loss: 0.754342, acc.: 50.78%] [G loss: 1.038858]\n",
      "epoch:19 step:18251 [D loss: 0.440406, acc.: 79.69%] [G loss: 1.182930]\n",
      "epoch:19 step:18252 [D loss: 0.522701, acc.: 75.00%] [G loss: 1.245064]\n",
      "epoch:19 step:18253 [D loss: 0.603677, acc.: 69.53%] [G loss: 1.400576]\n",
      "epoch:19 step:18254 [D loss: 0.610058, acc.: 66.41%] [G loss: 1.261256]\n",
      "epoch:19 step:18255 [D loss: 0.566815, acc.: 72.66%] [G loss: 1.325429]\n",
      "epoch:19 step:18256 [D loss: 0.518414, acc.: 77.34%] [G loss: 1.277872]\n",
      "epoch:19 step:18257 [D loss: 0.486100, acc.: 82.81%] [G loss: 1.486716]\n",
      "epoch:19 step:18258 [D loss: 0.646612, acc.: 64.06%] [G loss: 1.095468]\n",
      "epoch:19 step:18259 [D loss: 0.603649, acc.: 68.75%] [G loss: 1.265914]\n",
      "epoch:19 step:18260 [D loss: 0.477322, acc.: 78.91%] [G loss: 1.234442]\n",
      "epoch:19 step:18261 [D loss: 1.004370, acc.: 35.94%] [G loss: 1.055700]\n",
      "epoch:19 step:18262 [D loss: 0.812152, acc.: 48.44%] [G loss: 0.844432]\n",
      "epoch:19 step:18263 [D loss: 0.755544, acc.: 50.78%] [G loss: 0.933379]\n",
      "epoch:19 step:18264 [D loss: 1.180099, acc.: 20.31%] [G loss: 0.794893]\n",
      "epoch:19 step:18265 [D loss: 0.943552, acc.: 25.00%] [G loss: 0.967319]\n",
      "epoch:19 step:18266 [D loss: 0.758288, acc.: 50.00%] [G loss: 0.900275]\n",
      "epoch:19 step:18267 [D loss: 0.618529, acc.: 67.97%] [G loss: 1.245802]\n",
      "epoch:19 step:18268 [D loss: 0.580760, acc.: 68.75%] [G loss: 0.983688]\n",
      "epoch:19 step:18269 [D loss: 0.680420, acc.: 62.50%] [G loss: 1.000117]\n",
      "epoch:19 step:18270 [D loss: 0.554911, acc.: 73.44%] [G loss: 0.964420]\n",
      "epoch:19 step:18271 [D loss: 0.435427, acc.: 85.16%] [G loss: 1.179581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18272 [D loss: 0.595892, acc.: 67.97%] [G loss: 0.950071]\n",
      "epoch:19 step:18273 [D loss: 0.451702, acc.: 81.25%] [G loss: 1.273522]\n",
      "epoch:19 step:18274 [D loss: 0.327538, acc.: 90.62%] [G loss: 1.368302]\n",
      "epoch:19 step:18275 [D loss: 0.389071, acc.: 90.62%] [G loss: 1.474411]\n",
      "epoch:19 step:18276 [D loss: 0.676226, acc.: 62.50%] [G loss: 1.369414]\n",
      "epoch:19 step:18277 [D loss: 0.518212, acc.: 77.34%] [G loss: 1.409096]\n",
      "epoch:19 step:18278 [D loss: 0.393288, acc.: 89.06%] [G loss: 1.544106]\n",
      "epoch:19 step:18279 [D loss: 0.752863, acc.: 50.78%] [G loss: 1.103577]\n",
      "epoch:19 step:18280 [D loss: 0.645115, acc.: 60.94%] [G loss: 1.091395]\n",
      "epoch:19 step:18281 [D loss: 0.640104, acc.: 66.41%] [G loss: 0.978735]\n",
      "epoch:19 step:18282 [D loss: 0.611348, acc.: 66.41%] [G loss: 1.071949]\n",
      "epoch:19 step:18283 [D loss: 0.543974, acc.: 71.09%] [G loss: 1.254257]\n",
      "epoch:19 step:18284 [D loss: 0.669500, acc.: 63.28%] [G loss: 0.836256]\n",
      "epoch:19 step:18285 [D loss: 0.595277, acc.: 67.97%] [G loss: 1.153831]\n",
      "epoch:19 step:18286 [D loss: 0.488915, acc.: 79.69%] [G loss: 1.240332]\n",
      "epoch:19 step:18287 [D loss: 0.404480, acc.: 87.50%] [G loss: 1.358108]\n",
      "epoch:19 step:18288 [D loss: 0.488085, acc.: 78.91%] [G loss: 1.426665]\n",
      "epoch:19 step:18289 [D loss: 0.586359, acc.: 66.41%] [G loss: 0.953207]\n",
      "epoch:19 step:18290 [D loss: 0.756316, acc.: 52.34%] [G loss: 1.138400]\n",
      "epoch:19 step:18291 [D loss: 0.618778, acc.: 67.19%] [G loss: 1.283766]\n",
      "epoch:19 step:18292 [D loss: 0.698587, acc.: 53.91%] [G loss: 1.197795]\n",
      "epoch:19 step:18293 [D loss: 0.523745, acc.: 76.56%] [G loss: 1.109593]\n",
      "epoch:19 step:18294 [D loss: 0.592424, acc.: 65.62%] [G loss: 1.054904]\n",
      "epoch:19 step:18295 [D loss: 0.697767, acc.: 58.59%] [G loss: 0.977011]\n",
      "epoch:19 step:18296 [D loss: 0.555234, acc.: 74.22%] [G loss: 1.073279]\n",
      "epoch:19 step:18297 [D loss: 0.673148, acc.: 58.59%] [G loss: 0.983746]\n",
      "epoch:19 step:18298 [D loss: 0.590720, acc.: 64.84%] [G loss: 1.094185]\n",
      "epoch:19 step:18299 [D loss: 0.626544, acc.: 68.75%] [G loss: 0.968406]\n",
      "epoch:19 step:18300 [D loss: 0.423422, acc.: 82.81%] [G loss: 1.266028]\n",
      "epoch:19 step:18301 [D loss: 0.384562, acc.: 90.62%] [G loss: 1.177857]\n",
      "epoch:19 step:18302 [D loss: 0.289902, acc.: 96.09%] [G loss: 1.381934]\n",
      "epoch:19 step:18303 [D loss: 0.804678, acc.: 44.53%] [G loss: 0.943334]\n",
      "epoch:19 step:18304 [D loss: 0.833498, acc.: 42.97%] [G loss: 1.032144]\n",
      "epoch:19 step:18305 [D loss: 0.815605, acc.: 38.28%] [G loss: 1.072941]\n",
      "epoch:19 step:18306 [D loss: 0.433283, acc.: 84.38%] [G loss: 1.077474]\n",
      "epoch:19 step:18307 [D loss: 0.449691, acc.: 80.47%] [G loss: 1.233491]\n",
      "epoch:19 step:18308 [D loss: 0.457310, acc.: 78.91%] [G loss: 1.383963]\n",
      "epoch:19 step:18309 [D loss: 0.572965, acc.: 70.31%] [G loss: 1.372120]\n",
      "epoch:19 step:18310 [D loss: 0.428064, acc.: 82.81%] [G loss: 1.296348]\n",
      "epoch:19 step:18311 [D loss: 0.323244, acc.: 92.19%] [G loss: 1.357463]\n",
      "epoch:19 step:18312 [D loss: 0.664525, acc.: 58.59%] [G loss: 1.336107]\n",
      "epoch:19 step:18313 [D loss: 0.715219, acc.: 53.91%] [G loss: 1.135383]\n",
      "epoch:19 step:18314 [D loss: 0.647034, acc.: 60.94%] [G loss: 1.208519]\n",
      "epoch:19 step:18315 [D loss: 0.627862, acc.: 65.62%] [G loss: 1.019554]\n",
      "epoch:19 step:18316 [D loss: 0.508804, acc.: 78.12%] [G loss: 1.174745]\n",
      "epoch:19 step:18317 [D loss: 0.491173, acc.: 82.81%] [G loss: 1.138931]\n",
      "epoch:19 step:18318 [D loss: 0.594570, acc.: 67.97%] [G loss: 1.142105]\n",
      "epoch:19 step:18319 [D loss: 0.615058, acc.: 67.19%] [G loss: 0.939293]\n",
      "epoch:19 step:18320 [D loss: 0.490155, acc.: 78.91%] [G loss: 1.169000]\n",
      "epoch:19 step:18321 [D loss: 0.447535, acc.: 87.50%] [G loss: 1.408374]\n",
      "epoch:19 step:18322 [D loss: 0.478163, acc.: 81.25%] [G loss: 1.376546]\n",
      "epoch:19 step:18323 [D loss: 0.393696, acc.: 90.62%] [G loss: 1.291897]\n",
      "epoch:19 step:18324 [D loss: 0.496516, acc.: 76.56%] [G loss: 1.290454]\n",
      "epoch:19 step:18325 [D loss: 0.533850, acc.: 72.66%] [G loss: 1.312297]\n",
      "epoch:19 step:18326 [D loss: 0.376569, acc.: 89.84%] [G loss: 1.664853]\n",
      "epoch:19 step:18327 [D loss: 0.781711, acc.: 49.22%] [G loss: 0.904019]\n",
      "epoch:19 step:18328 [D loss: 0.705206, acc.: 53.91%] [G loss: 0.893794]\n",
      "epoch:19 step:18329 [D loss: 0.738622, acc.: 55.47%] [G loss: 1.225685]\n",
      "epoch:19 step:18330 [D loss: 0.586779, acc.: 69.53%] [G loss: 1.184414]\n",
      "epoch:19 step:18331 [D loss: 0.851729, acc.: 41.41%] [G loss: 1.096704]\n",
      "epoch:19 step:18332 [D loss: 0.655281, acc.: 62.50%] [G loss: 1.286762]\n",
      "epoch:19 step:18333 [D loss: 0.562611, acc.: 75.00%] [G loss: 1.230766]\n",
      "epoch:19 step:18334 [D loss: 0.675119, acc.: 57.03%] [G loss: 1.067995]\n",
      "epoch:19 step:18335 [D loss: 0.462570, acc.: 86.72%] [G loss: 1.076450]\n",
      "epoch:19 step:18336 [D loss: 0.390557, acc.: 82.03%] [G loss: 1.162242]\n",
      "epoch:19 step:18337 [D loss: 0.474976, acc.: 80.47%] [G loss: 1.306884]\n",
      "epoch:19 step:18338 [D loss: 0.539599, acc.: 75.00%] [G loss: 1.340565]\n",
      "epoch:19 step:18339 [D loss: 0.418363, acc.: 89.84%] [G loss: 1.177805]\n",
      "epoch:19 step:18340 [D loss: 0.403708, acc.: 85.94%] [G loss: 1.475138]\n",
      "epoch:19 step:18341 [D loss: 0.645032, acc.: 57.03%] [G loss: 1.129745]\n",
      "epoch:19 step:18342 [D loss: 0.595015, acc.: 72.66%] [G loss: 1.276547]\n",
      "epoch:19 step:18343 [D loss: 0.597947, acc.: 64.84%] [G loss: 1.033849]\n",
      "epoch:19 step:18344 [D loss: 0.814074, acc.: 46.09%] [G loss: 0.907116]\n",
      "epoch:19 step:18345 [D loss: 0.722177, acc.: 57.03%] [G loss: 0.989432]\n",
      "epoch:19 step:18346 [D loss: 0.613898, acc.: 65.62%] [G loss: 1.117462]\n",
      "epoch:19 step:18347 [D loss: 0.609782, acc.: 66.41%] [G loss: 0.994383]\n",
      "epoch:19 step:18348 [D loss: 0.478792, acc.: 82.81%] [G loss: 1.225914]\n",
      "epoch:19 step:18349 [D loss: 0.408733, acc.: 87.50%] [G loss: 1.289984]\n",
      "epoch:19 step:18350 [D loss: 0.376099, acc.: 88.28%] [G loss: 1.264885]\n",
      "epoch:19 step:18351 [D loss: 0.513776, acc.: 77.34%] [G loss: 1.557197]\n",
      "epoch:19 step:18352 [D loss: 0.311543, acc.: 94.53%] [G loss: 1.280444]\n",
      "epoch:19 step:18353 [D loss: 0.299331, acc.: 94.53%] [G loss: 1.341911]\n",
      "epoch:19 step:18354 [D loss: 0.263744, acc.: 93.75%] [G loss: 1.357915]\n",
      "epoch:19 step:18355 [D loss: 0.520634, acc.: 75.78%] [G loss: 1.175150]\n",
      "epoch:19 step:18356 [D loss: 0.370995, acc.: 89.84%] [G loss: 1.588629]\n",
      "epoch:19 step:18357 [D loss: 0.327727, acc.: 89.06%] [G loss: 1.265215]\n",
      "epoch:19 step:18358 [D loss: 0.347669, acc.: 94.53%] [G loss: 1.835804]\n",
      "epoch:19 step:18359 [D loss: 0.308249, acc.: 92.19%] [G loss: 1.314474]\n",
      "epoch:19 step:18360 [D loss: 0.359451, acc.: 92.19%] [G loss: 1.825143]\n",
      "epoch:19 step:18361 [D loss: 0.750155, acc.: 50.00%] [G loss: 1.244173]\n",
      "epoch:19 step:18362 [D loss: 0.901503, acc.: 47.66%] [G loss: 1.266657]\n",
      "epoch:19 step:18363 [D loss: 0.891703, acc.: 53.91%] [G loss: 1.382251]\n",
      "epoch:19 step:18364 [D loss: 0.438474, acc.: 84.38%] [G loss: 1.541473]\n",
      "epoch:19 step:18365 [D loss: 0.714685, acc.: 56.25%] [G loss: 1.285391]\n",
      "epoch:19 step:18366 [D loss: 0.636600, acc.: 65.62%] [G loss: 1.163708]\n",
      "epoch:19 step:18367 [D loss: 0.658311, acc.: 58.59%] [G loss: 0.908238]\n",
      "epoch:19 step:18368 [D loss: 0.618536, acc.: 67.19%] [G loss: 1.084515]\n",
      "epoch:19 step:18369 [D loss: 0.430342, acc.: 85.94%] [G loss: 1.246476]\n",
      "epoch:19 step:18370 [D loss: 0.373597, acc.: 89.84%] [G loss: 1.473905]\n",
      "epoch:19 step:18371 [D loss: 0.533606, acc.: 71.09%] [G loss: 1.538561]\n",
      "epoch:19 step:18372 [D loss: 0.847688, acc.: 46.09%] [G loss: 1.110983]\n",
      "epoch:19 step:18373 [D loss: 0.553247, acc.: 75.00%] [G loss: 1.266217]\n",
      "epoch:19 step:18374 [D loss: 0.521352, acc.: 73.44%] [G loss: 1.366602]\n",
      "epoch:19 step:18375 [D loss: 0.524665, acc.: 76.56%] [G loss: 1.168459]\n",
      "epoch:19 step:18376 [D loss: 0.455832, acc.: 83.59%] [G loss: 1.396650]\n",
      "epoch:19 step:18377 [D loss: 0.579389, acc.: 71.09%] [G loss: 0.904414]\n",
      "epoch:19 step:18378 [D loss: 0.571500, acc.: 75.78%] [G loss: 1.078173]\n",
      "epoch:19 step:18379 [D loss: 0.373048, acc.: 89.06%] [G loss: 1.603149]\n",
      "epoch:19 step:18380 [D loss: 0.465074, acc.: 82.03%] [G loss: 1.273558]\n",
      "epoch:19 step:18381 [D loss: 0.498672, acc.: 73.44%] [G loss: 0.989006]\n",
      "epoch:19 step:18382 [D loss: 0.422206, acc.: 86.72%] [G loss: 1.733758]\n",
      "epoch:19 step:18383 [D loss: 0.954195, acc.: 35.16%] [G loss: 0.734228]\n",
      "epoch:19 step:18384 [D loss: 0.423654, acc.: 91.41%] [G loss: 1.337345]\n",
      "epoch:19 step:18385 [D loss: 1.071466, acc.: 28.91%] [G loss: 0.585232]\n",
      "epoch:19 step:18386 [D loss: 0.676021, acc.: 57.81%] [G loss: 1.229828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18387 [D loss: 0.753785, acc.: 50.78%] [G loss: 0.728060]\n",
      "epoch:19 step:18388 [D loss: 0.652618, acc.: 64.84%] [G loss: 1.161923]\n",
      "epoch:19 step:18389 [D loss: 0.620260, acc.: 63.28%] [G loss: 1.082915]\n",
      "epoch:19 step:18390 [D loss: 0.443693, acc.: 82.81%] [G loss: 1.366135]\n",
      "epoch:19 step:18391 [D loss: 0.361393, acc.: 91.41%] [G loss: 1.756077]\n",
      "epoch:19 step:18392 [D loss: 0.465958, acc.: 79.69%] [G loss: 1.541032]\n",
      "epoch:19 step:18393 [D loss: 0.847993, acc.: 45.31%] [G loss: 1.158782]\n",
      "epoch:19 step:18394 [D loss: 0.797218, acc.: 50.00%] [G loss: 1.355220]\n",
      "epoch:19 step:18395 [D loss: 0.796467, acc.: 39.84%] [G loss: 1.133295]\n",
      "epoch:19 step:18396 [D loss: 0.621234, acc.: 64.84%] [G loss: 1.103194]\n",
      "epoch:19 step:18397 [D loss: 0.630749, acc.: 66.41%] [G loss: 0.976362]\n",
      "epoch:19 step:18398 [D loss: 0.485090, acc.: 82.03%] [G loss: 1.418419]\n",
      "epoch:19 step:18399 [D loss: 0.776067, acc.: 47.66%] [G loss: 1.398669]\n",
      "epoch:19 step:18400 [D loss: 0.613725, acc.: 68.75%] [G loss: 1.141065]\n",
      "epoch:19 step:18401 [D loss: 0.363022, acc.: 89.84%] [G loss: 1.104165]\n",
      "epoch:19 step:18402 [D loss: 0.617983, acc.: 65.62%] [G loss: 0.967833]\n",
      "epoch:19 step:18403 [D loss: 0.663545, acc.: 61.72%] [G loss: 1.052442]\n",
      "epoch:19 step:18404 [D loss: 0.686048, acc.: 59.38%] [G loss: 0.714190]\n",
      "epoch:19 step:18405 [D loss: 0.660768, acc.: 67.19%] [G loss: 0.967157]\n",
      "epoch:19 step:18406 [D loss: 0.544590, acc.: 73.44%] [G loss: 1.219953]\n",
      "epoch:19 step:18407 [D loss: 0.347380, acc.: 90.62%] [G loss: 1.581720]\n",
      "epoch:19 step:18408 [D loss: 0.375492, acc.: 91.41%] [G loss: 1.558185]\n",
      "epoch:19 step:18409 [D loss: 0.516274, acc.: 75.00%] [G loss: 1.302048]\n",
      "epoch:19 step:18410 [D loss: 0.660366, acc.: 59.38%] [G loss: 1.109876]\n",
      "epoch:19 step:18411 [D loss: 0.565382, acc.: 71.88%] [G loss: 1.185502]\n",
      "epoch:19 step:18412 [D loss: 0.560854, acc.: 75.78%] [G loss: 1.391448]\n",
      "epoch:19 step:18413 [D loss: 0.686709, acc.: 61.72%] [G loss: 1.168809]\n",
      "epoch:19 step:18414 [D loss: 0.721906, acc.: 57.03%] [G loss: 0.938385]\n",
      "epoch:19 step:18415 [D loss: 0.632197, acc.: 63.28%] [G loss: 1.598111]\n",
      "epoch:19 step:18416 [D loss: 0.329825, acc.: 89.84%] [G loss: 1.165498]\n",
      "epoch:19 step:18417 [D loss: 0.337116, acc.: 90.62%] [G loss: 1.272800]\n",
      "epoch:19 step:18418 [D loss: 0.278139, acc.: 94.53%] [G loss: 1.448297]\n",
      "epoch:19 step:18419 [D loss: 0.499134, acc.: 75.00%] [G loss: 1.137591]\n",
      "epoch:19 step:18420 [D loss: 0.370168, acc.: 91.41%] [G loss: 1.495032]\n",
      "epoch:19 step:18421 [D loss: 0.841796, acc.: 49.22%] [G loss: 1.219089]\n",
      "epoch:19 step:18422 [D loss: 0.884530, acc.: 40.62%] [G loss: 0.928754]\n",
      "epoch:19 step:18423 [D loss: 0.913650, acc.: 36.72%] [G loss: 0.996274]\n",
      "epoch:19 step:18424 [D loss: 0.755111, acc.: 46.09%] [G loss: 1.159964]\n",
      "epoch:19 step:18425 [D loss: 0.636997, acc.: 59.38%] [G loss: 1.234919]\n",
      "epoch:19 step:18426 [D loss: 0.516959, acc.: 77.34%] [G loss: 1.605432]\n",
      "epoch:19 step:18427 [D loss: 0.402799, acc.: 90.62%] [G loss: 1.346009]\n",
      "epoch:19 step:18428 [D loss: 0.713258, acc.: 54.69%] [G loss: 1.149645]\n",
      "epoch:19 step:18429 [D loss: 0.705840, acc.: 52.34%] [G loss: 0.886903]\n",
      "epoch:19 step:18430 [D loss: 0.925268, acc.: 31.25%] [G loss: 1.031602]\n",
      "epoch:19 step:18431 [D loss: 0.939237, acc.: 33.59%] [G loss: 0.730560]\n",
      "epoch:19 step:18432 [D loss: 0.369772, acc.: 85.16%] [G loss: 1.355037]\n",
      "epoch:19 step:18433 [D loss: 0.555238, acc.: 72.66%] [G loss: 1.259306]\n",
      "epoch:19 step:18434 [D loss: 0.848068, acc.: 50.00%] [G loss: 0.734090]\n",
      "epoch:19 step:18435 [D loss: 0.726555, acc.: 50.78%] [G loss: 0.851726]\n",
      "epoch:19 step:18436 [D loss: 0.587617, acc.: 67.19%] [G loss: 1.079273]\n",
      "epoch:19 step:18437 [D loss: 0.517967, acc.: 78.91%] [G loss: 1.517081]\n",
      "epoch:19 step:18438 [D loss: 0.616308, acc.: 63.28%] [G loss: 1.144187]\n",
      "epoch:19 step:18439 [D loss: 0.980443, acc.: 25.00%] [G loss: 0.677299]\n",
      "epoch:19 step:18440 [D loss: 0.748001, acc.: 55.47%] [G loss: 1.049845]\n",
      "epoch:19 step:18441 [D loss: 0.865070, acc.: 44.53%] [G loss: 1.130641]\n",
      "epoch:19 step:18442 [D loss: 1.024172, acc.: 27.34%] [G loss: 1.008685]\n",
      "epoch:19 step:18443 [D loss: 0.362236, acc.: 89.84%] [G loss: 1.765444]\n",
      "epoch:19 step:18444 [D loss: 0.359645, acc.: 91.41%] [G loss: 1.692687]\n",
      "epoch:19 step:18445 [D loss: 0.320373, acc.: 91.41%] [G loss: 1.665179]\n",
      "epoch:19 step:18446 [D loss: 0.571672, acc.: 65.62%] [G loss: 1.590360]\n",
      "epoch:19 step:18447 [D loss: 0.737848, acc.: 56.25%] [G loss: 1.061471]\n",
      "epoch:19 step:18448 [D loss: 0.667427, acc.: 58.59%] [G loss: 0.948182]\n",
      "epoch:19 step:18449 [D loss: 0.717954, acc.: 57.03%] [G loss: 0.976286]\n",
      "epoch:19 step:18450 [D loss: 0.551252, acc.: 75.00%] [G loss: 1.157229]\n",
      "epoch:19 step:18451 [D loss: 0.571264, acc.: 71.09%] [G loss: 1.205202]\n",
      "epoch:19 step:18452 [D loss: 0.497565, acc.: 81.25%] [G loss: 0.899932]\n",
      "epoch:19 step:18453 [D loss: 0.598036, acc.: 68.75%] [G loss: 0.901019]\n",
      "epoch:19 step:18454 [D loss: 0.567864, acc.: 68.75%] [G loss: 1.321276]\n",
      "epoch:19 step:18455 [D loss: 0.718910, acc.: 54.69%] [G loss: 1.039397]\n",
      "epoch:19 step:18456 [D loss: 0.562529, acc.: 70.31%] [G loss: 1.043806]\n",
      "epoch:19 step:18457 [D loss: 0.565425, acc.: 72.66%] [G loss: 0.959764]\n",
      "epoch:19 step:18458 [D loss: 0.692069, acc.: 57.03%] [G loss: 0.949186]\n",
      "epoch:19 step:18459 [D loss: 0.618646, acc.: 64.06%] [G loss: 1.221175]\n",
      "epoch:19 step:18460 [D loss: 0.716290, acc.: 52.34%] [G loss: 0.920708]\n",
      "epoch:19 step:18461 [D loss: 0.468444, acc.: 77.34%] [G loss: 1.216387]\n",
      "epoch:19 step:18462 [D loss: 0.604240, acc.: 68.75%] [G loss: 1.049358]\n",
      "epoch:19 step:18463 [D loss: 0.674736, acc.: 59.38%] [G loss: 0.969552]\n",
      "epoch:19 step:18464 [D loss: 0.639416, acc.: 67.97%] [G loss: 1.067274]\n",
      "epoch:19 step:18465 [D loss: 0.479047, acc.: 79.69%] [G loss: 1.136455]\n",
      "epoch:19 step:18466 [D loss: 0.349075, acc.: 88.28%] [G loss: 1.289166]\n",
      "epoch:19 step:18467 [D loss: 0.223279, acc.: 96.88%] [G loss: 1.596093]\n",
      "epoch:19 step:18468 [D loss: 0.301167, acc.: 93.75%] [G loss: 1.596326]\n",
      "epoch:19 step:18469 [D loss: 0.546914, acc.: 73.44%] [G loss: 1.463563]\n",
      "epoch:19 step:18470 [D loss: 0.445249, acc.: 80.47%] [G loss: 1.532265]\n",
      "epoch:19 step:18471 [D loss: 0.735973, acc.: 54.69%] [G loss: 1.182182]\n",
      "epoch:19 step:18472 [D loss: 0.685998, acc.: 57.03%] [G loss: 0.925955]\n",
      "epoch:19 step:18473 [D loss: 0.570180, acc.: 71.09%] [G loss: 1.284854]\n",
      "epoch:19 step:18474 [D loss: 0.678312, acc.: 55.47%] [G loss: 1.091292]\n",
      "epoch:19 step:18475 [D loss: 0.834897, acc.: 50.00%] [G loss: 0.831218]\n",
      "epoch:19 step:18476 [D loss: 0.990641, acc.: 30.47%] [G loss: 0.678632]\n",
      "epoch:19 step:18477 [D loss: 0.704223, acc.: 58.59%] [G loss: 1.122901]\n",
      "epoch:19 step:18478 [D loss: 0.773627, acc.: 47.66%] [G loss: 0.861137]\n",
      "epoch:19 step:18479 [D loss: 0.577799, acc.: 74.22%] [G loss: 0.901836]\n",
      "epoch:19 step:18480 [D loss: 0.624492, acc.: 64.06%] [G loss: 0.898607]\n",
      "epoch:19 step:18481 [D loss: 0.819530, acc.: 48.44%] [G loss: 0.909246]\n",
      "epoch:19 step:18482 [D loss: 0.682007, acc.: 64.06%] [G loss: 1.037640]\n",
      "epoch:19 step:18483 [D loss: 0.742364, acc.: 51.56%] [G loss: 0.871450]\n",
      "epoch:19 step:18484 [D loss: 0.638438, acc.: 64.06%] [G loss: 0.971912]\n",
      "epoch:19 step:18485 [D loss: 0.584249, acc.: 65.62%] [G loss: 0.936053]\n",
      "epoch:19 step:18486 [D loss: 0.585299, acc.: 67.19%] [G loss: 1.050325]\n",
      "epoch:19 step:18487 [D loss: 0.747959, acc.: 54.69%] [G loss: 0.798652]\n",
      "epoch:19 step:18488 [D loss: 0.571532, acc.: 76.56%] [G loss: 0.789098]\n",
      "epoch:19 step:18489 [D loss: 0.671213, acc.: 58.59%] [G loss: 1.189347]\n",
      "epoch:19 step:18490 [D loss: 0.728055, acc.: 50.78%] [G loss: 1.010690]\n",
      "epoch:19 step:18491 [D loss: 0.600568, acc.: 74.22%] [G loss: 0.971578]\n",
      "epoch:19 step:18492 [D loss: 0.659141, acc.: 61.72%] [G loss: 0.985346]\n",
      "epoch:19 step:18493 [D loss: 0.414068, acc.: 84.38%] [G loss: 1.337596]\n",
      "epoch:19 step:18494 [D loss: 0.460102, acc.: 85.16%] [G loss: 1.519919]\n",
      "epoch:19 step:18495 [D loss: 0.612284, acc.: 66.41%] [G loss: 1.273172]\n",
      "epoch:19 step:18496 [D loss: 0.437719, acc.: 81.25%] [G loss: 1.318243]\n",
      "epoch:19 step:18497 [D loss: 0.321651, acc.: 93.75%] [G loss: 1.163428]\n",
      "epoch:19 step:18498 [D loss: 0.532242, acc.: 77.34%] [G loss: 1.180780]\n",
      "epoch:19 step:18499 [D loss: 0.776406, acc.: 47.66%] [G loss: 1.065338]\n",
      "epoch:19 step:18500 [D loss: 0.791980, acc.: 46.88%] [G loss: 1.016223]\n",
      "epoch:19 step:18501 [D loss: 0.732602, acc.: 46.09%] [G loss: 0.817008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18502 [D loss: 0.707509, acc.: 56.25%] [G loss: 0.916779]\n",
      "epoch:19 step:18503 [D loss: 0.608902, acc.: 67.97%] [G loss: 0.934194]\n",
      "epoch:19 step:18504 [D loss: 0.663820, acc.: 62.50%] [G loss: 0.928353]\n",
      "epoch:19 step:18505 [D loss: 0.710649, acc.: 60.94%] [G loss: 0.903689]\n",
      "epoch:19 step:18506 [D loss: 0.587057, acc.: 67.97%] [G loss: 1.257322]\n",
      "epoch:19 step:18507 [D loss: 0.688324, acc.: 56.25%] [G loss: 1.091454]\n",
      "epoch:19 step:18508 [D loss: 0.731023, acc.: 51.56%] [G loss: 0.995253]\n",
      "epoch:19 step:18509 [D loss: 0.463216, acc.: 83.59%] [G loss: 1.145686]\n",
      "epoch:19 step:18510 [D loss: 0.629630, acc.: 67.97%] [G loss: 0.954016]\n",
      "epoch:19 step:18511 [D loss: 0.409208, acc.: 88.28%] [G loss: 1.253040]\n",
      "epoch:19 step:18512 [D loss: 0.413010, acc.: 81.25%] [G loss: 1.174735]\n",
      "epoch:19 step:18513 [D loss: 0.657563, acc.: 64.84%] [G loss: 1.515384]\n",
      "epoch:19 step:18514 [D loss: 0.676075, acc.: 60.94%] [G loss: 1.248774]\n",
      "epoch:19 step:18515 [D loss: 0.705587, acc.: 58.59%] [G loss: 1.100350]\n",
      "epoch:19 step:18516 [D loss: 0.458834, acc.: 77.34%] [G loss: 1.125011]\n",
      "epoch:19 step:18517 [D loss: 0.621540, acc.: 65.62%] [G loss: 0.996006]\n",
      "epoch:19 step:18518 [D loss: 0.615181, acc.: 65.62%] [G loss: 1.043009]\n",
      "epoch:19 step:18519 [D loss: 0.834757, acc.: 39.06%] [G loss: 0.922593]\n",
      "epoch:19 step:18520 [D loss: 0.708836, acc.: 51.56%] [G loss: 0.917764]\n",
      "epoch:19 step:18521 [D loss: 0.742384, acc.: 52.34%] [G loss: 0.960567]\n",
      "epoch:19 step:18522 [D loss: 0.666825, acc.: 56.25%] [G loss: 0.881431]\n",
      "epoch:19 step:18523 [D loss: 0.618358, acc.: 65.62%] [G loss: 1.029900]\n",
      "epoch:19 step:18524 [D loss: 0.536219, acc.: 78.12%] [G loss: 0.962479]\n",
      "epoch:19 step:18525 [D loss: 0.694705, acc.: 54.69%] [G loss: 0.908929]\n",
      "epoch:19 step:18526 [D loss: 0.663881, acc.: 60.94%] [G loss: 0.930374]\n",
      "epoch:19 step:18527 [D loss: 0.467642, acc.: 78.12%] [G loss: 1.036066]\n",
      "epoch:19 step:18528 [D loss: 0.482032, acc.: 79.69%] [G loss: 1.099084]\n",
      "epoch:19 step:18529 [D loss: 0.521233, acc.: 76.56%] [G loss: 1.251147]\n",
      "epoch:19 step:18530 [D loss: 0.558644, acc.: 75.78%] [G loss: 1.274811]\n",
      "epoch:19 step:18531 [D loss: 0.580972, acc.: 68.75%] [G loss: 1.299452]\n",
      "epoch:19 step:18532 [D loss: 0.567045, acc.: 71.09%] [G loss: 1.096389]\n",
      "epoch:19 step:18533 [D loss: 0.464551, acc.: 85.94%] [G loss: 1.320480]\n",
      "epoch:19 step:18534 [D loss: 0.356898, acc.: 90.62%] [G loss: 1.237365]\n",
      "epoch:19 step:18535 [D loss: 0.418468, acc.: 91.41%] [G loss: 1.290830]\n",
      "epoch:19 step:18536 [D loss: 0.345832, acc.: 94.53%] [G loss: 1.241359]\n",
      "epoch:19 step:18537 [D loss: 0.716724, acc.: 54.69%] [G loss: 1.071569]\n",
      "epoch:19 step:18538 [D loss: 0.776961, acc.: 48.44%] [G loss: 1.053643]\n",
      "epoch:19 step:18539 [D loss: 0.664282, acc.: 55.47%] [G loss: 1.015364]\n",
      "epoch:19 step:18540 [D loss: 0.667931, acc.: 60.16%] [G loss: 0.916271]\n",
      "epoch:19 step:18541 [D loss: 0.573792, acc.: 69.53%] [G loss: 0.974854]\n",
      "epoch:19 step:18542 [D loss: 0.561059, acc.: 75.78%] [G loss: 1.079398]\n",
      "epoch:19 step:18543 [D loss: 0.492441, acc.: 76.56%] [G loss: 0.918916]\n",
      "epoch:19 step:18544 [D loss: 0.711890, acc.: 53.91%] [G loss: 1.235529]\n",
      "epoch:19 step:18545 [D loss: 0.665185, acc.: 60.94%] [G loss: 1.313915]\n",
      "epoch:19 step:18546 [D loss: 0.694052, acc.: 56.25%] [G loss: 0.908387]\n",
      "epoch:19 step:18547 [D loss: 0.627535, acc.: 66.41%] [G loss: 1.008173]\n",
      "epoch:19 step:18548 [D loss: 0.397343, acc.: 89.84%] [G loss: 0.981038]\n",
      "epoch:19 step:18549 [D loss: 0.576922, acc.: 71.09%] [G loss: 0.950070]\n",
      "epoch:19 step:18550 [D loss: 0.561044, acc.: 72.66%] [G loss: 1.171620]\n",
      "epoch:19 step:18551 [D loss: 0.666039, acc.: 59.38%] [G loss: 1.125181]\n",
      "epoch:19 step:18552 [D loss: 0.575091, acc.: 73.44%] [G loss: 1.167694]\n",
      "epoch:19 step:18553 [D loss: 0.642649, acc.: 60.94%] [G loss: 0.973755]\n",
      "epoch:19 step:18554 [D loss: 0.625428, acc.: 64.06%] [G loss: 0.980018]\n",
      "epoch:19 step:18555 [D loss: 0.690859, acc.: 57.81%] [G loss: 1.019635]\n",
      "epoch:19 step:18556 [D loss: 0.599433, acc.: 66.41%] [G loss: 0.884442]\n",
      "epoch:19 step:18557 [D loss: 0.675561, acc.: 56.25%] [G loss: 0.889367]\n",
      "epoch:19 step:18558 [D loss: 0.508012, acc.: 78.12%] [G loss: 0.990293]\n",
      "epoch:19 step:18559 [D loss: 0.580124, acc.: 71.09%] [G loss: 1.110334]\n",
      "epoch:19 step:18560 [D loss: 0.604807, acc.: 66.41%] [G loss: 1.051153]\n",
      "epoch:19 step:18561 [D loss: 0.635852, acc.: 61.72%] [G loss: 1.331526]\n",
      "epoch:19 step:18562 [D loss: 0.655628, acc.: 60.94%] [G loss: 1.042300]\n",
      "epoch:19 step:18563 [D loss: 0.656471, acc.: 54.69%] [G loss: 1.143533]\n",
      "epoch:19 step:18564 [D loss: 0.649015, acc.: 61.72%] [G loss: 1.158338]\n",
      "epoch:19 step:18565 [D loss: 0.722693, acc.: 52.34%] [G loss: 0.934086]\n",
      "epoch:19 step:18566 [D loss: 0.691781, acc.: 57.81%] [G loss: 0.970293]\n",
      "epoch:19 step:18567 [D loss: 0.644693, acc.: 62.50%] [G loss: 1.124561]\n",
      "epoch:19 step:18568 [D loss: 0.639868, acc.: 63.28%] [G loss: 1.006106]\n",
      "epoch:19 step:18569 [D loss: 0.606433, acc.: 70.31%] [G loss: 1.113018]\n",
      "epoch:19 step:18570 [D loss: 0.593596, acc.: 66.41%] [G loss: 1.129901]\n",
      "epoch:19 step:18571 [D loss: 0.434006, acc.: 82.81%] [G loss: 1.293416]\n",
      "epoch:19 step:18572 [D loss: 0.364121, acc.: 90.62%] [G loss: 1.357199]\n",
      "epoch:19 step:18573 [D loss: 0.511014, acc.: 76.56%] [G loss: 1.267431]\n",
      "epoch:19 step:18574 [D loss: 0.691101, acc.: 57.81%] [G loss: 1.201792]\n",
      "epoch:19 step:18575 [D loss: 0.654736, acc.: 65.62%] [G loss: 1.270332]\n",
      "epoch:19 step:18576 [D loss: 0.701069, acc.: 57.03%] [G loss: 0.745865]\n",
      "epoch:19 step:18577 [D loss: 0.230140, acc.: 97.66%] [G loss: 1.453863]\n",
      "epoch:19 step:18578 [D loss: 0.312825, acc.: 92.19%] [G loss: 1.427776]\n",
      "epoch:19 step:18579 [D loss: 0.401581, acc.: 86.72%] [G loss: 1.664633]\n",
      "epoch:19 step:18580 [D loss: 0.512059, acc.: 79.69%] [G loss: 1.489343]\n",
      "epoch:19 step:18581 [D loss: 0.611537, acc.: 61.72%] [G loss: 1.320814]\n",
      "epoch:19 step:18582 [D loss: 0.882945, acc.: 40.62%] [G loss: 0.903985]\n",
      "epoch:19 step:18583 [D loss: 0.716704, acc.: 49.22%] [G loss: 1.196034]\n",
      "epoch:19 step:18584 [D loss: 0.689797, acc.: 59.38%] [G loss: 1.129634]\n",
      "epoch:19 step:18585 [D loss: 0.465301, acc.: 85.16%] [G loss: 1.230463]\n",
      "epoch:19 step:18586 [D loss: 0.784883, acc.: 51.56%] [G loss: 0.955379]\n",
      "epoch:19 step:18587 [D loss: 0.690821, acc.: 58.59%] [G loss: 1.259389]\n",
      "epoch:19 step:18588 [D loss: 0.567670, acc.: 67.97%] [G loss: 1.183656]\n",
      "epoch:19 step:18589 [D loss: 0.442774, acc.: 83.59%] [G loss: 0.997389]\n",
      "epoch:19 step:18590 [D loss: 0.717121, acc.: 53.91%] [G loss: 1.322953]\n",
      "epoch:19 step:18591 [D loss: 0.694569, acc.: 59.38%] [G loss: 0.869917]\n",
      "epoch:19 step:18592 [D loss: 0.800573, acc.: 45.31%] [G loss: 0.899287]\n",
      "epoch:19 step:18593 [D loss: 0.510727, acc.: 74.22%] [G loss: 1.125497]\n",
      "epoch:19 step:18594 [D loss: 0.311000, acc.: 93.75%] [G loss: 1.469172]\n",
      "epoch:19 step:18595 [D loss: 0.360124, acc.: 87.50%] [G loss: 1.257666]\n",
      "epoch:19 step:18596 [D loss: 0.350081, acc.: 92.19%] [G loss: 1.513347]\n",
      "epoch:19 step:18597 [D loss: 0.305489, acc.: 92.97%] [G loss: 1.736125]\n",
      "epoch:19 step:18598 [D loss: 0.546093, acc.: 77.34%] [G loss: 1.533653]\n",
      "epoch:19 step:18599 [D loss: 0.407326, acc.: 86.72%] [G loss: 1.325034]\n",
      "epoch:19 step:18600 [D loss: 0.583499, acc.: 66.41%] [G loss: 1.221021]\n",
      "epoch:19 step:18601 [D loss: 0.728228, acc.: 52.34%] [G loss: 0.802056]\n",
      "epoch:19 step:18602 [D loss: 0.624183, acc.: 63.28%] [G loss: 1.015438]\n",
      "epoch:19 step:18603 [D loss: 0.787180, acc.: 57.03%] [G loss: 1.127180]\n",
      "epoch:19 step:18604 [D loss: 0.831280, acc.: 44.53%] [G loss: 0.892563]\n",
      "epoch:19 step:18605 [D loss: 0.516209, acc.: 82.03%] [G loss: 1.179282]\n",
      "epoch:19 step:18606 [D loss: 0.733020, acc.: 50.78%] [G loss: 0.832693]\n",
      "epoch:19 step:18607 [D loss: 0.503678, acc.: 78.91%] [G loss: 0.893117]\n",
      "epoch:19 step:18608 [D loss: 0.443634, acc.: 82.03%] [G loss: 1.025672]\n",
      "epoch:19 step:18609 [D loss: 0.554831, acc.: 72.66%] [G loss: 0.924774]\n",
      "epoch:19 step:18610 [D loss: 0.706075, acc.: 58.59%] [G loss: 1.280904]\n",
      "epoch:19 step:18611 [D loss: 0.668800, acc.: 58.59%] [G loss: 1.203334]\n",
      "epoch:19 step:18612 [D loss: 0.602022, acc.: 66.41%] [G loss: 1.262773]\n",
      "epoch:19 step:18613 [D loss: 0.543630, acc.: 77.34%] [G loss: 1.111699]\n",
      "epoch:19 step:18614 [D loss: 0.710429, acc.: 53.12%] [G loss: 1.003868]\n",
      "epoch:19 step:18615 [D loss: 0.558187, acc.: 72.66%] [G loss: 1.227762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18616 [D loss: 0.588364, acc.: 71.88%] [G loss: 1.017463]\n",
      "epoch:19 step:18617 [D loss: 0.504338, acc.: 76.56%] [G loss: 1.045356]\n",
      "epoch:19 step:18618 [D loss: 0.262231, acc.: 89.06%] [G loss: 1.385071]\n",
      "epoch:19 step:18619 [D loss: 0.376197, acc.: 90.62%] [G loss: 1.556811]\n",
      "epoch:19 step:18620 [D loss: 0.458327, acc.: 83.59%] [G loss: 1.249707]\n",
      "epoch:19 step:18621 [D loss: 0.480644, acc.: 75.00%] [G loss: 1.253566]\n",
      "epoch:19 step:18622 [D loss: 0.754863, acc.: 50.00%] [G loss: 0.991732]\n",
      "epoch:19 step:18623 [D loss: 0.912136, acc.: 42.97%] [G loss: 1.229238]\n",
      "epoch:19 step:18624 [D loss: 0.742387, acc.: 54.69%] [G loss: 1.127494]\n",
      "epoch:19 step:18625 [D loss: 0.768784, acc.: 48.44%] [G loss: 1.007751]\n",
      "epoch:19 step:18626 [D loss: 0.642258, acc.: 66.41%] [G loss: 1.057403]\n",
      "epoch:19 step:18627 [D loss: 0.453188, acc.: 82.03%] [G loss: 1.094564]\n",
      "epoch:19 step:18628 [D loss: 0.543032, acc.: 74.22%] [G loss: 1.089638]\n",
      "epoch:19 step:18629 [D loss: 0.790445, acc.: 45.31%] [G loss: 0.995165]\n",
      "epoch:19 step:18630 [D loss: 0.742173, acc.: 51.56%] [G loss: 1.478635]\n",
      "epoch:19 step:18631 [D loss: 0.671540, acc.: 56.25%] [G loss: 1.349813]\n",
      "epoch:19 step:18632 [D loss: 0.579352, acc.: 68.75%] [G loss: 1.092862]\n",
      "epoch:19 step:18633 [D loss: 0.926562, acc.: 46.88%] [G loss: 0.668089]\n",
      "epoch:19 step:18634 [D loss: 0.426003, acc.: 84.38%] [G loss: 1.427385]\n",
      "epoch:19 step:18635 [D loss: 0.674521, acc.: 57.81%] [G loss: 1.071455]\n",
      "epoch:19 step:18636 [D loss: 0.499892, acc.: 80.47%] [G loss: 1.356193]\n",
      "epoch:19 step:18637 [D loss: 0.812129, acc.: 54.69%] [G loss: 1.606355]\n",
      "epoch:19 step:18638 [D loss: 0.854556, acc.: 38.28%] [G loss: 0.845214]\n",
      "epoch:19 step:18639 [D loss: 0.829645, acc.: 46.88%] [G loss: 1.085084]\n",
      "epoch:19 step:18640 [D loss: 0.706785, acc.: 55.47%] [G loss: 1.141614]\n",
      "epoch:19 step:18641 [D loss: 0.556376, acc.: 74.22%] [G loss: 1.293767]\n",
      "epoch:19 step:18642 [D loss: 0.597952, acc.: 69.53%] [G loss: 1.220522]\n",
      "epoch:19 step:18643 [D loss: 0.427500, acc.: 85.94%] [G loss: 1.187422]\n",
      "epoch:19 step:18644 [D loss: 0.375434, acc.: 86.72%] [G loss: 1.054660]\n",
      "epoch:19 step:18645 [D loss: 0.381964, acc.: 91.41%] [G loss: 1.379423]\n",
      "epoch:19 step:18646 [D loss: 0.870070, acc.: 33.59%] [G loss: 1.132118]\n",
      "epoch:19 step:18647 [D loss: 0.826424, acc.: 45.31%] [G loss: 1.227761]\n",
      "epoch:19 step:18648 [D loss: 0.948579, acc.: 30.47%] [G loss: 0.823354]\n",
      "epoch:19 step:18649 [D loss: 0.549851, acc.: 75.00%] [G loss: 0.790576]\n",
      "epoch:19 step:18650 [D loss: 0.519255, acc.: 72.66%] [G loss: 1.252495]\n",
      "epoch:19 step:18651 [D loss: 0.514630, acc.: 78.91%] [G loss: 1.535912]\n",
      "epoch:19 step:18652 [D loss: 0.413291, acc.: 86.72%] [G loss: 1.281844]\n",
      "epoch:19 step:18653 [D loss: 0.326736, acc.: 92.97%] [G loss: 1.487026]\n",
      "epoch:19 step:18654 [D loss: 0.362285, acc.: 87.50%] [G loss: 1.480943]\n",
      "epoch:19 step:18655 [D loss: 0.188567, acc.: 97.66%] [G loss: 2.030337]\n",
      "epoch:19 step:18656 [D loss: 0.343678, acc.: 94.53%] [G loss: 1.547734]\n",
      "epoch:19 step:18657 [D loss: 0.275682, acc.: 93.75%] [G loss: 1.658637]\n",
      "epoch:19 step:18658 [D loss: 0.506525, acc.: 78.91%] [G loss: 1.191966]\n",
      "epoch:19 step:18659 [D loss: 0.574917, acc.: 71.09%] [G loss: 1.413278]\n",
      "epoch:19 step:18660 [D loss: 0.401572, acc.: 84.38%] [G loss: 1.504910]\n",
      "epoch:19 step:18661 [D loss: 1.139567, acc.: 30.47%] [G loss: 1.040452]\n",
      "epoch:19 step:18662 [D loss: 0.861735, acc.: 35.94%] [G loss: 0.892412]\n",
      "epoch:19 step:18663 [D loss: 0.532508, acc.: 76.56%] [G loss: 1.159495]\n",
      "epoch:19 step:18664 [D loss: 0.670584, acc.: 60.16%] [G loss: 1.184512]\n",
      "epoch:19 step:18665 [D loss: 0.738349, acc.: 52.34%] [G loss: 1.179715]\n",
      "epoch:19 step:18666 [D loss: 0.596620, acc.: 66.41%] [G loss: 0.996142]\n",
      "epoch:19 step:18667 [D loss: 0.808071, acc.: 42.19%] [G loss: 0.893645]\n",
      "epoch:19 step:18668 [D loss: 0.725596, acc.: 55.47%] [G loss: 0.957906]\n",
      "epoch:19 step:18669 [D loss: 0.675813, acc.: 52.34%] [G loss: 0.879636]\n",
      "epoch:19 step:18670 [D loss: 0.622257, acc.: 64.84%] [G loss: 1.113308]\n",
      "epoch:19 step:18671 [D loss: 0.674234, acc.: 57.81%] [G loss: 1.031637]\n",
      "epoch:19 step:18672 [D loss: 0.670659, acc.: 56.25%] [G loss: 1.069406]\n",
      "epoch:19 step:18673 [D loss: 0.601034, acc.: 67.19%] [G loss: 1.070141]\n",
      "epoch:19 step:18674 [D loss: 0.707635, acc.: 53.12%] [G loss: 0.971719]\n",
      "epoch:19 step:18675 [D loss: 0.607993, acc.: 64.06%] [G loss: 0.960012]\n",
      "epoch:19 step:18676 [D loss: 0.561726, acc.: 72.66%] [G loss: 0.967382]\n",
      "epoch:19 step:18677 [D loss: 0.683404, acc.: 57.81%] [G loss: 0.807863]\n",
      "epoch:19 step:18678 [D loss: 0.565567, acc.: 71.09%] [G loss: 0.902653]\n",
      "epoch:19 step:18679 [D loss: 0.499259, acc.: 80.47%] [G loss: 1.127641]\n",
      "epoch:19 step:18680 [D loss: 0.494704, acc.: 78.12%] [G loss: 1.073836]\n",
      "epoch:19 step:18681 [D loss: 0.374531, acc.: 93.75%] [G loss: 0.998477]\n",
      "epoch:19 step:18682 [D loss: 0.597096, acc.: 64.84%] [G loss: 1.144286]\n",
      "epoch:19 step:18683 [D loss: 0.793392, acc.: 46.88%] [G loss: 0.878161]\n",
      "epoch:19 step:18684 [D loss: 0.652431, acc.: 62.50%] [G loss: 0.981399]\n",
      "epoch:19 step:18685 [D loss: 0.759526, acc.: 47.66%] [G loss: 0.809240]\n",
      "epoch:19 step:18686 [D loss: 0.588880, acc.: 67.97%] [G loss: 0.901278]\n",
      "epoch:19 step:18687 [D loss: 0.565453, acc.: 70.31%] [G loss: 1.124209]\n",
      "epoch:19 step:18688 [D loss: 0.531426, acc.: 75.00%] [G loss: 0.994317]\n",
      "epoch:19 step:18689 [D loss: 0.532101, acc.: 77.34%] [G loss: 1.190549]\n",
      "epoch:19 step:18690 [D loss: 0.484659, acc.: 80.47%] [G loss: 1.219237]\n",
      "epoch:19 step:18691 [D loss: 0.672001, acc.: 62.50%] [G loss: 0.879169]\n",
      "epoch:19 step:18692 [D loss: 0.410217, acc.: 88.28%] [G loss: 1.299102]\n",
      "epoch:19 step:18693 [D loss: 0.473443, acc.: 82.03%] [G loss: 1.227152]\n",
      "epoch:19 step:18694 [D loss: 0.813821, acc.: 48.44%] [G loss: 1.079732]\n",
      "epoch:19 step:18695 [D loss: 0.631115, acc.: 60.94%] [G loss: 1.157951]\n",
      "epoch:19 step:18696 [D loss: 0.592562, acc.: 70.31%] [G loss: 1.223162]\n",
      "epoch:19 step:18697 [D loss: 0.601526, acc.: 71.09%] [G loss: 1.262726]\n",
      "epoch:19 step:18698 [D loss: 0.580470, acc.: 71.88%] [G loss: 1.156175]\n",
      "epoch:19 step:18699 [D loss: 0.460682, acc.: 82.03%] [G loss: 1.102193]\n",
      "epoch:19 step:18700 [D loss: 0.475618, acc.: 80.47%] [G loss: 1.196205]\n",
      "epoch:19 step:18701 [D loss: 0.327561, acc.: 89.06%] [G loss: 1.517620]\n",
      "epoch:19 step:18702 [D loss: 0.346075, acc.: 88.28%] [G loss: 1.211721]\n",
      "epoch:19 step:18703 [D loss: 0.234836, acc.: 100.00%] [G loss: 1.470168]\n",
      "epoch:19 step:18704 [D loss: 0.481529, acc.: 78.12%] [G loss: 1.285699]\n",
      "epoch:19 step:18705 [D loss: 0.637238, acc.: 64.84%] [G loss: 1.197072]\n",
      "epoch:19 step:18706 [D loss: 0.607279, acc.: 67.97%] [G loss: 0.856184]\n",
      "epoch:19 step:18707 [D loss: 0.868834, acc.: 35.94%] [G loss: 1.031441]\n",
      "epoch:19 step:18708 [D loss: 0.598108, acc.: 68.75%] [G loss: 1.227788]\n",
      "epoch:19 step:18709 [D loss: 0.644072, acc.: 58.59%] [G loss: 1.143919]\n",
      "epoch:19 step:18710 [D loss: 0.641060, acc.: 64.84%] [G loss: 1.044994]\n",
      "epoch:19 step:18711 [D loss: 0.758312, acc.: 46.88%] [G loss: 1.111271]\n",
      "epoch:19 step:18712 [D loss: 0.493170, acc.: 78.12%] [G loss: 1.112372]\n",
      "epoch:19 step:18713 [D loss: 0.527470, acc.: 75.78%] [G loss: 1.050818]\n",
      "epoch:19 step:18714 [D loss: 0.331462, acc.: 89.84%] [G loss: 1.265345]\n",
      "epoch:19 step:18715 [D loss: 0.182918, acc.: 97.66%] [G loss: 1.285325]\n",
      "epoch:19 step:18716 [D loss: 0.806220, acc.: 52.34%] [G loss: 1.192431]\n",
      "epoch:19 step:18717 [D loss: 0.668506, acc.: 57.03%] [G loss: 1.169328]\n",
      "epoch:19 step:18718 [D loss: 0.739502, acc.: 51.56%] [G loss: 0.847940]\n",
      "epoch:19 step:18719 [D loss: 0.583557, acc.: 73.44%] [G loss: 1.085322]\n",
      "epoch:19 step:18720 [D loss: 0.739742, acc.: 53.12%] [G loss: 0.804663]\n",
      "epoch:19 step:18721 [D loss: 0.577146, acc.: 71.88%] [G loss: 0.998207]\n",
      "epoch:19 step:18722 [D loss: 0.536602, acc.: 74.22%] [G loss: 0.999580]\n",
      "epoch:19 step:18723 [D loss: 0.375159, acc.: 89.06%] [G loss: 1.181511]\n",
      "epoch:19 step:18724 [D loss: 0.363579, acc.: 92.97%] [G loss: 1.542723]\n",
      "epoch:19 step:18725 [D loss: 0.542433, acc.: 73.44%] [G loss: 1.164540]\n",
      "epoch:19 step:18726 [D loss: 0.640823, acc.: 64.84%] [G loss: 0.962901]\n",
      "epoch:19 step:18727 [D loss: 0.486910, acc.: 81.25%] [G loss: 1.073420]\n",
      "epoch:19 step:18728 [D loss: 0.401695, acc.: 90.62%] [G loss: 1.363291]\n",
      "epoch:19 step:18729 [D loss: 0.447044, acc.: 85.16%] [G loss: 1.318717]\n",
      "epoch:19 step:18730 [D loss: 0.320243, acc.: 92.19%] [G loss: 1.419215]\n",
      "epoch:19 step:18731 [D loss: 0.931559, acc.: 34.38%] [G loss: 1.160096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18732 [D loss: 0.330905, acc.: 90.62%] [G loss: 1.350316]\n",
      "epoch:19 step:18733 [D loss: 0.404288, acc.: 86.72%] [G loss: 1.205129]\n",
      "epoch:19 step:18734 [D loss: 0.550173, acc.: 71.88%] [G loss: 1.193874]\n",
      "epoch:19 step:18735 [D loss: 0.565601, acc.: 73.44%] [G loss: 1.353138]\n",
      "epoch:19 step:18736 [D loss: 0.544099, acc.: 78.91%] [G loss: 1.204887]\n",
      "epoch:19 step:18737 [D loss: 0.440150, acc.: 79.69%] [G loss: 1.212611]\n",
      "epoch:19 step:18738 [D loss: 0.653844, acc.: 62.50%] [G loss: 1.252664]\n",
      "epoch:19 step:18739 [D loss: 0.443668, acc.: 82.03%] [G loss: 1.252054]\n",
      "epoch:19 step:18740 [D loss: 0.175738, acc.: 98.44%] [G loss: 1.878739]\n",
      "epoch:20 step:18741 [D loss: 0.756399, acc.: 54.69%] [G loss: 1.215562]\n",
      "epoch:20 step:18742 [D loss: 0.730283, acc.: 58.59%] [G loss: 1.184911]\n",
      "epoch:20 step:18743 [D loss: 0.730252, acc.: 59.38%] [G loss: 1.179572]\n",
      "epoch:20 step:18744 [D loss: 0.912692, acc.: 30.47%] [G loss: 0.770761]\n",
      "epoch:20 step:18745 [D loss: 0.812427, acc.: 43.75%] [G loss: 1.050848]\n",
      "epoch:20 step:18746 [D loss: 0.597803, acc.: 68.75%] [G loss: 1.072993]\n",
      "epoch:20 step:18747 [D loss: 0.617632, acc.: 61.72%] [G loss: 0.943814]\n",
      "epoch:20 step:18748 [D loss: 0.640363, acc.: 62.50%] [G loss: 1.147572]\n",
      "epoch:20 step:18749 [D loss: 0.577531, acc.: 68.75%] [G loss: 0.837087]\n",
      "epoch:20 step:18750 [D loss: 0.464073, acc.: 84.38%] [G loss: 1.279403]\n",
      "epoch:20 step:18751 [D loss: 0.572161, acc.: 69.53%] [G loss: 1.024880]\n",
      "epoch:20 step:18752 [D loss: 0.712019, acc.: 61.72%] [G loss: 0.922635]\n",
      "epoch:20 step:18753 [D loss: 0.779379, acc.: 51.56%] [G loss: 0.924311]\n",
      "epoch:20 step:18754 [D loss: 0.691413, acc.: 60.16%] [G loss: 1.263016]\n",
      "epoch:20 step:18755 [D loss: 0.443877, acc.: 82.81%] [G loss: 1.301079]\n",
      "epoch:20 step:18756 [D loss: 0.633059, acc.: 62.50%] [G loss: 1.056948]\n",
      "epoch:20 step:18757 [D loss: 0.685425, acc.: 58.59%] [G loss: 1.057078]\n",
      "epoch:20 step:18758 [D loss: 0.813453, acc.: 46.09%] [G loss: 0.978477]\n",
      "epoch:20 step:18759 [D loss: 0.751970, acc.: 50.78%] [G loss: 0.955316]\n",
      "epoch:20 step:18760 [D loss: 0.608946, acc.: 69.53%] [G loss: 1.018522]\n",
      "epoch:20 step:18761 [D loss: 0.510593, acc.: 78.91%] [G loss: 1.149426]\n",
      "epoch:20 step:18762 [D loss: 0.521705, acc.: 78.12%] [G loss: 1.223253]\n",
      "epoch:20 step:18763 [D loss: 0.583661, acc.: 69.53%] [G loss: 1.096041]\n",
      "epoch:20 step:18764 [D loss: 0.725009, acc.: 58.59%] [G loss: 0.957925]\n",
      "epoch:20 step:18765 [D loss: 0.547863, acc.: 72.66%] [G loss: 1.140331]\n",
      "epoch:20 step:18766 [D loss: 0.453465, acc.: 84.38%] [G loss: 1.142707]\n",
      "epoch:20 step:18767 [D loss: 0.374714, acc.: 85.16%] [G loss: 1.271920]\n",
      "epoch:20 step:18768 [D loss: 0.373932, acc.: 90.62%] [G loss: 1.424320]\n",
      "epoch:20 step:18769 [D loss: 0.407100, acc.: 89.06%] [G loss: 1.746110]\n",
      "epoch:20 step:18770 [D loss: 0.308779, acc.: 92.19%] [G loss: 1.611900]\n",
      "epoch:20 step:18771 [D loss: 0.294480, acc.: 96.09%] [G loss: 1.420852]\n",
      "epoch:20 step:18772 [D loss: 0.290724, acc.: 95.31%] [G loss: 1.737694]\n",
      "epoch:20 step:18773 [D loss: 0.236302, acc.: 97.66%] [G loss: 1.580702]\n",
      "epoch:20 step:18774 [D loss: 0.476072, acc.: 77.34%] [G loss: 1.420450]\n",
      "epoch:20 step:18775 [D loss: 0.182263, acc.: 99.22%] [G loss: 2.020414]\n",
      "epoch:20 step:18776 [D loss: 0.259727, acc.: 93.75%] [G loss: 1.759295]\n",
      "epoch:20 step:18777 [D loss: 0.944270, acc.: 50.00%] [G loss: 1.107829]\n",
      "epoch:20 step:18778 [D loss: 0.855175, acc.: 45.31%] [G loss: 1.112159]\n",
      "epoch:20 step:18779 [D loss: 0.681386, acc.: 57.81%] [G loss: 1.082860]\n",
      "epoch:20 step:18780 [D loss: 0.573041, acc.: 71.88%] [G loss: 1.242364]\n",
      "epoch:20 step:18781 [D loss: 0.648951, acc.: 62.50%] [G loss: 1.115504]\n",
      "epoch:20 step:18782 [D loss: 0.664682, acc.: 58.59%] [G loss: 0.989608]\n",
      "epoch:20 step:18783 [D loss: 0.610822, acc.: 64.84%] [G loss: 0.991930]\n",
      "epoch:20 step:18784 [D loss: 0.491519, acc.: 77.34%] [G loss: 1.234382]\n",
      "epoch:20 step:18785 [D loss: 0.684856, acc.: 52.34%] [G loss: 0.956620]\n",
      "epoch:20 step:18786 [D loss: 0.967136, acc.: 37.50%] [G loss: 0.682189]\n",
      "epoch:20 step:18787 [D loss: 0.775813, acc.: 49.22%] [G loss: 0.940229]\n",
      "epoch:20 step:18788 [D loss: 0.792680, acc.: 49.22%] [G loss: 1.049082]\n",
      "epoch:20 step:18789 [D loss: 0.584766, acc.: 68.75%] [G loss: 1.193359]\n",
      "epoch:20 step:18790 [D loss: 0.689703, acc.: 58.59%] [G loss: 1.122285]\n",
      "epoch:20 step:18791 [D loss: 0.745974, acc.: 49.22%] [G loss: 1.151892]\n",
      "epoch:20 step:18792 [D loss: 0.669137, acc.: 59.38%] [G loss: 1.113723]\n",
      "epoch:20 step:18793 [D loss: 0.665064, acc.: 64.84%] [G loss: 0.910795]\n",
      "epoch:20 step:18794 [D loss: 0.639944, acc.: 59.38%] [G loss: 1.168231]\n",
      "epoch:20 step:18795 [D loss: 0.519216, acc.: 74.22%] [G loss: 1.026093]\n",
      "epoch:20 step:18796 [D loss: 0.598649, acc.: 67.19%] [G loss: 1.148654]\n",
      "epoch:20 step:18797 [D loss: 0.878187, acc.: 38.28%] [G loss: 0.830216]\n",
      "epoch:20 step:18798 [D loss: 0.569018, acc.: 75.00%] [G loss: 0.963175]\n",
      "epoch:20 step:18799 [D loss: 0.601371, acc.: 69.53%] [G loss: 0.978366]\n",
      "epoch:20 step:18800 [D loss: 0.665511, acc.: 58.59%] [G loss: 1.050574]\n",
      "epoch:20 step:18801 [D loss: 0.569288, acc.: 75.78%] [G loss: 1.050942]\n",
      "epoch:20 step:18802 [D loss: 0.588583, acc.: 70.31%] [G loss: 0.824909]\n",
      "epoch:20 step:18803 [D loss: 0.805832, acc.: 40.62%] [G loss: 0.885083]\n",
      "epoch:20 step:18804 [D loss: 0.624593, acc.: 61.72%] [G loss: 0.941302]\n",
      "epoch:20 step:18805 [D loss: 0.637267, acc.: 64.06%] [G loss: 1.078157]\n",
      "epoch:20 step:18806 [D loss: 0.651389, acc.: 65.62%] [G loss: 0.964308]\n",
      "epoch:20 step:18807 [D loss: 0.816269, acc.: 44.53%] [G loss: 0.696886]\n",
      "epoch:20 step:18808 [D loss: 0.458583, acc.: 85.16%] [G loss: 1.297913]\n",
      "epoch:20 step:18809 [D loss: 0.456294, acc.: 83.59%] [G loss: 1.159902]\n",
      "epoch:20 step:18810 [D loss: 0.607795, acc.: 65.62%] [G loss: 1.137527]\n",
      "epoch:20 step:18811 [D loss: 0.677414, acc.: 61.72%] [G loss: 0.876445]\n",
      "epoch:20 step:18812 [D loss: 0.825474, acc.: 42.19%] [G loss: 0.981894]\n",
      "epoch:20 step:18813 [D loss: 0.681412, acc.: 60.16%] [G loss: 0.960333]\n",
      "epoch:20 step:18814 [D loss: 0.543463, acc.: 73.44%] [G loss: 1.288996]\n",
      "epoch:20 step:18815 [D loss: 0.304877, acc.: 90.62%] [G loss: 1.305403]\n",
      "epoch:20 step:18816 [D loss: 0.394622, acc.: 85.94%] [G loss: 1.465059]\n",
      "epoch:20 step:18817 [D loss: 0.434177, acc.: 86.72%] [G loss: 1.324220]\n",
      "epoch:20 step:18818 [D loss: 0.691180, acc.: 61.72%] [G loss: 1.363470]\n",
      "epoch:20 step:18819 [D loss: 0.704576, acc.: 62.50%] [G loss: 1.367539]\n",
      "epoch:20 step:18820 [D loss: 0.692065, acc.: 54.69%] [G loss: 0.955277]\n",
      "epoch:20 step:18821 [D loss: 0.666236, acc.: 63.28%] [G loss: 1.218320]\n",
      "epoch:20 step:18822 [D loss: 0.723622, acc.: 53.12%] [G loss: 0.796024]\n",
      "epoch:20 step:18823 [D loss: 0.652749, acc.: 60.94%] [G loss: 1.123061]\n",
      "epoch:20 step:18824 [D loss: 0.743033, acc.: 50.00%] [G loss: 1.074867]\n",
      "epoch:20 step:18825 [D loss: 0.557356, acc.: 71.88%] [G loss: 1.222041]\n",
      "epoch:20 step:18826 [D loss: 0.609626, acc.: 70.31%] [G loss: 1.037151]\n",
      "epoch:20 step:18827 [D loss: 0.727635, acc.: 52.34%] [G loss: 0.952532]\n",
      "epoch:20 step:18828 [D loss: 0.616661, acc.: 64.84%] [G loss: 1.066087]\n",
      "epoch:20 step:18829 [D loss: 0.608793, acc.: 65.62%] [G loss: 0.930678]\n",
      "epoch:20 step:18830 [D loss: 0.613742, acc.: 64.84%] [G loss: 1.109363]\n",
      "epoch:20 step:18831 [D loss: 0.719351, acc.: 53.91%] [G loss: 1.031962]\n",
      "epoch:20 step:18832 [D loss: 0.768886, acc.: 49.22%] [G loss: 1.025148]\n",
      "epoch:20 step:18833 [D loss: 0.655971, acc.: 57.81%] [G loss: 0.992473]\n",
      "epoch:20 step:18834 [D loss: 0.796863, acc.: 47.66%] [G loss: 0.875222]\n",
      "epoch:20 step:18835 [D loss: 0.599466, acc.: 69.53%] [G loss: 1.011508]\n",
      "epoch:20 step:18836 [D loss: 0.742897, acc.: 49.22%] [G loss: 1.068083]\n",
      "epoch:20 step:18837 [D loss: 0.665179, acc.: 62.50%] [G loss: 0.828469]\n",
      "epoch:20 step:18838 [D loss: 0.583218, acc.: 67.97%] [G loss: 0.924030]\n",
      "epoch:20 step:18839 [D loss: 0.627751, acc.: 64.06%] [G loss: 1.038742]\n",
      "epoch:20 step:18840 [D loss: 0.540880, acc.: 74.22%] [G loss: 0.897859]\n",
      "epoch:20 step:18841 [D loss: 0.709723, acc.: 51.56%] [G loss: 1.058876]\n",
      "epoch:20 step:18842 [D loss: 0.519846, acc.: 77.34%] [G loss: 1.164960]\n",
      "epoch:20 step:18843 [D loss: 0.547392, acc.: 76.56%] [G loss: 1.080583]\n",
      "epoch:20 step:18844 [D loss: 0.660488, acc.: 61.72%] [G loss: 1.166388]\n",
      "epoch:20 step:18845 [D loss: 0.614604, acc.: 65.62%] [G loss: 1.102568]\n",
      "epoch:20 step:18846 [D loss: 0.773370, acc.: 49.22%] [G loss: 0.951526]\n",
      "epoch:20 step:18847 [D loss: 0.712625, acc.: 52.34%] [G loss: 1.034467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18848 [D loss: 0.801866, acc.: 40.62%] [G loss: 0.928031]\n",
      "epoch:20 step:18849 [D loss: 0.638806, acc.: 67.97%] [G loss: 1.253353]\n",
      "epoch:20 step:18850 [D loss: 0.679780, acc.: 60.16%] [G loss: 0.965408]\n",
      "epoch:20 step:18851 [D loss: 0.869096, acc.: 40.62%] [G loss: 0.818342]\n",
      "epoch:20 step:18852 [D loss: 0.784007, acc.: 50.00%] [G loss: 1.045137]\n",
      "epoch:20 step:18853 [D loss: 0.568524, acc.: 68.75%] [G loss: 1.280656]\n",
      "epoch:20 step:18854 [D loss: 0.534302, acc.: 77.34%] [G loss: 1.146516]\n",
      "epoch:20 step:18855 [D loss: 0.487393, acc.: 78.91%] [G loss: 1.171133]\n",
      "epoch:20 step:18856 [D loss: 0.704139, acc.: 53.91%] [G loss: 1.407248]\n",
      "epoch:20 step:18857 [D loss: 0.681231, acc.: 56.25%] [G loss: 1.242607]\n",
      "epoch:20 step:18858 [D loss: 0.727140, acc.: 48.44%] [G loss: 0.963682]\n",
      "epoch:20 step:18859 [D loss: 0.549312, acc.: 69.53%] [G loss: 1.015478]\n",
      "epoch:20 step:18860 [D loss: 0.561061, acc.: 72.66%] [G loss: 1.043632]\n",
      "epoch:20 step:18861 [D loss: 0.333535, acc.: 91.41%] [G loss: 1.382717]\n",
      "epoch:20 step:18862 [D loss: 0.303113, acc.: 90.62%] [G loss: 1.413552]\n",
      "epoch:20 step:18863 [D loss: 0.669125, acc.: 55.47%] [G loss: 0.940468]\n",
      "epoch:20 step:18864 [D loss: 0.738941, acc.: 50.78%] [G loss: 1.226882]\n",
      "epoch:20 step:18865 [D loss: 0.717864, acc.: 54.69%] [G loss: 0.957376]\n",
      "epoch:20 step:18866 [D loss: 0.644584, acc.: 65.62%] [G loss: 1.040204]\n",
      "epoch:20 step:18867 [D loss: 0.653215, acc.: 60.16%] [G loss: 1.025815]\n",
      "epoch:20 step:18868 [D loss: 0.547663, acc.: 76.56%] [G loss: 1.041783]\n",
      "epoch:20 step:18869 [D loss: 0.546277, acc.: 69.53%] [G loss: 0.966710]\n",
      "epoch:20 step:18870 [D loss: 0.329225, acc.: 93.75%] [G loss: 1.370886]\n",
      "epoch:20 step:18871 [D loss: 0.277878, acc.: 95.31%] [G loss: 1.554043]\n",
      "epoch:20 step:18872 [D loss: 0.447685, acc.: 86.72%] [G loss: 1.217791]\n",
      "epoch:20 step:18873 [D loss: 1.054922, acc.: 26.56%] [G loss: 0.897929]\n",
      "epoch:20 step:18874 [D loss: 0.629879, acc.: 60.94%] [G loss: 1.198777]\n",
      "epoch:20 step:18875 [D loss: 0.602089, acc.: 67.97%] [G loss: 1.051332]\n",
      "epoch:20 step:18876 [D loss: 0.648520, acc.: 61.72%] [G loss: 1.005939]\n",
      "epoch:20 step:18877 [D loss: 0.655834, acc.: 64.06%] [G loss: 0.973064]\n",
      "epoch:20 step:18878 [D loss: 0.656960, acc.: 58.59%] [G loss: 0.818429]\n",
      "epoch:20 step:18879 [D loss: 0.436931, acc.: 80.47%] [G loss: 1.005444]\n",
      "epoch:20 step:18880 [D loss: 0.747362, acc.: 46.09%] [G loss: 1.281222]\n",
      "epoch:20 step:18881 [D loss: 0.651475, acc.: 60.94%] [G loss: 1.167960]\n",
      "epoch:20 step:18882 [D loss: 0.551298, acc.: 76.56%] [G loss: 1.315549]\n",
      "epoch:20 step:18883 [D loss: 0.595268, acc.: 71.09%] [G loss: 1.239760]\n",
      "epoch:20 step:18884 [D loss: 0.514660, acc.: 73.44%] [G loss: 1.255156]\n",
      "epoch:20 step:18885 [D loss: 0.504176, acc.: 77.34%] [G loss: 1.044889]\n",
      "epoch:20 step:18886 [D loss: 0.468120, acc.: 80.47%] [G loss: 1.277916]\n",
      "epoch:20 step:18887 [D loss: 0.542350, acc.: 74.22%] [G loss: 1.051317]\n",
      "epoch:20 step:18888 [D loss: 0.764118, acc.: 51.56%] [G loss: 0.928003]\n",
      "epoch:20 step:18889 [D loss: 0.711015, acc.: 48.44%] [G loss: 0.847985]\n",
      "epoch:20 step:18890 [D loss: 0.501254, acc.: 78.12%] [G loss: 1.069871]\n",
      "epoch:20 step:18891 [D loss: 0.398612, acc.: 92.19%] [G loss: 1.243017]\n",
      "epoch:20 step:18892 [D loss: 0.523303, acc.: 77.34%] [G loss: 1.209213]\n",
      "epoch:20 step:18893 [D loss: 0.840566, acc.: 47.66%] [G loss: 1.094973]\n",
      "epoch:20 step:18894 [D loss: 0.804996, acc.: 46.09%] [G loss: 0.937030]\n",
      "epoch:20 step:18895 [D loss: 0.568647, acc.: 74.22%] [G loss: 1.120659]\n",
      "epoch:20 step:18896 [D loss: 0.470454, acc.: 82.03%] [G loss: 1.243288]\n",
      "epoch:20 step:18897 [D loss: 0.720455, acc.: 50.78%] [G loss: 0.989996]\n",
      "epoch:20 step:18898 [D loss: 0.612211, acc.: 67.19%] [G loss: 1.105601]\n",
      "epoch:20 step:18899 [D loss: 0.452178, acc.: 84.38%] [G loss: 1.204265]\n",
      "epoch:20 step:18900 [D loss: 0.754246, acc.: 50.78%] [G loss: 0.973366]\n",
      "epoch:20 step:18901 [D loss: 0.676430, acc.: 58.59%] [G loss: 1.196587]\n",
      "epoch:20 step:18902 [D loss: 0.666554, acc.: 61.72%] [G loss: 1.154159]\n",
      "epoch:20 step:18903 [D loss: 0.595048, acc.: 67.97%] [G loss: 1.065703]\n",
      "epoch:20 step:18904 [D loss: 0.587469, acc.: 72.66%] [G loss: 1.156523]\n",
      "epoch:20 step:18905 [D loss: 0.658507, acc.: 60.16%] [G loss: 0.920360]\n",
      "epoch:20 step:18906 [D loss: 0.516836, acc.: 71.09%] [G loss: 1.038346]\n",
      "epoch:20 step:18907 [D loss: 0.450644, acc.: 84.38%] [G loss: 1.239493]\n",
      "epoch:20 step:18908 [D loss: 0.588291, acc.: 69.53%] [G loss: 0.857232]\n",
      "epoch:20 step:18909 [D loss: 0.570429, acc.: 70.31%] [G loss: 1.290067]\n",
      "epoch:20 step:18910 [D loss: 0.711678, acc.: 53.12%] [G loss: 1.031977]\n",
      "epoch:20 step:18911 [D loss: 0.657200, acc.: 56.25%] [G loss: 1.075733]\n",
      "epoch:20 step:18912 [D loss: 0.533531, acc.: 73.44%] [G loss: 1.109308]\n",
      "epoch:20 step:18913 [D loss: 0.724669, acc.: 53.91%] [G loss: 1.105813]\n",
      "epoch:20 step:18914 [D loss: 0.882860, acc.: 35.94%] [G loss: 0.797801]\n",
      "epoch:20 step:18915 [D loss: 0.609363, acc.: 62.50%] [G loss: 1.065012]\n",
      "epoch:20 step:18916 [D loss: 0.692770, acc.: 53.91%] [G loss: 0.812830]\n",
      "epoch:20 step:18917 [D loss: 0.786373, acc.: 47.66%] [G loss: 0.981427]\n",
      "epoch:20 step:18918 [D loss: 0.676878, acc.: 50.78%] [G loss: 0.872958]\n",
      "epoch:20 step:18919 [D loss: 0.873370, acc.: 36.72%] [G loss: 0.907937]\n",
      "epoch:20 step:18920 [D loss: 0.590405, acc.: 68.75%] [G loss: 0.973517]\n",
      "epoch:20 step:18921 [D loss: 0.607469, acc.: 68.75%] [G loss: 0.854873]\n",
      "epoch:20 step:18922 [D loss: 0.865038, acc.: 41.41%] [G loss: 0.654461]\n",
      "epoch:20 step:18923 [D loss: 0.688256, acc.: 59.38%] [G loss: 1.547025]\n",
      "epoch:20 step:18924 [D loss: 0.851650, acc.: 43.75%] [G loss: 0.574136]\n",
      "epoch:20 step:18925 [D loss: 0.830452, acc.: 45.31%] [G loss: 0.777080]\n",
      "epoch:20 step:18926 [D loss: 0.775401, acc.: 47.66%] [G loss: 0.888799]\n",
      "epoch:20 step:18927 [D loss: 0.720152, acc.: 52.34%] [G loss: 0.917659]\n",
      "epoch:20 step:18928 [D loss: 0.759081, acc.: 46.09%] [G loss: 0.925002]\n",
      "epoch:20 step:18929 [D loss: 0.701760, acc.: 58.59%] [G loss: 1.150913]\n",
      "epoch:20 step:18930 [D loss: 0.643383, acc.: 64.06%] [G loss: 1.183823]\n",
      "epoch:20 step:18931 [D loss: 0.608577, acc.: 68.75%] [G loss: 1.187440]\n",
      "epoch:20 step:18932 [D loss: 0.554073, acc.: 70.31%] [G loss: 1.099947]\n",
      "epoch:20 step:18933 [D loss: 0.626757, acc.: 60.94%] [G loss: 1.049913]\n",
      "epoch:20 step:18934 [D loss: 0.580202, acc.: 69.53%] [G loss: 1.099164]\n",
      "epoch:20 step:18935 [D loss: 0.625821, acc.: 62.50%] [G loss: 1.154333]\n",
      "epoch:20 step:18936 [D loss: 0.781170, acc.: 50.78%] [G loss: 0.953478]\n",
      "epoch:20 step:18937 [D loss: 0.682718, acc.: 60.94%] [G loss: 0.955515]\n",
      "epoch:20 step:18938 [D loss: 0.998745, acc.: 29.69%] [G loss: 0.660479]\n",
      "epoch:20 step:18939 [D loss: 0.748457, acc.: 50.00%] [G loss: 1.052129]\n",
      "epoch:20 step:18940 [D loss: 0.566883, acc.: 72.66%] [G loss: 1.404452]\n",
      "epoch:20 step:18941 [D loss: 0.471532, acc.: 78.12%] [G loss: 1.223548]\n",
      "epoch:20 step:18942 [D loss: 0.708186, acc.: 57.81%] [G loss: 1.274906]\n",
      "epoch:20 step:18943 [D loss: 0.843442, acc.: 45.31%] [G loss: 0.919811]\n",
      "epoch:20 step:18944 [D loss: 0.694181, acc.: 62.50%] [G loss: 1.106221]\n",
      "epoch:20 step:18945 [D loss: 0.753030, acc.: 53.12%] [G loss: 0.934497]\n",
      "epoch:20 step:18946 [D loss: 0.631758, acc.: 60.94%] [G loss: 0.973456]\n",
      "epoch:20 step:18947 [D loss: 0.530894, acc.: 74.22%] [G loss: 0.901382]\n",
      "epoch:20 step:18948 [D loss: 0.673864, acc.: 60.16%] [G loss: 0.968850]\n",
      "epoch:20 step:18949 [D loss: 0.618870, acc.: 64.84%] [G loss: 0.854445]\n",
      "epoch:20 step:18950 [D loss: 0.659208, acc.: 64.06%] [G loss: 0.955025]\n",
      "epoch:20 step:18951 [D loss: 0.476977, acc.: 78.91%] [G loss: 1.291391]\n",
      "epoch:20 step:18952 [D loss: 0.672685, acc.: 54.69%] [G loss: 1.045208]\n",
      "epoch:20 step:18953 [D loss: 0.394656, acc.: 88.28%] [G loss: 1.279653]\n",
      "epoch:20 step:18954 [D loss: 0.651618, acc.: 63.28%] [G loss: 1.087243]\n",
      "epoch:20 step:18955 [D loss: 0.633579, acc.: 63.28%] [G loss: 1.132435]\n",
      "epoch:20 step:18956 [D loss: 0.576125, acc.: 74.22%] [G loss: 1.536762]\n",
      "epoch:20 step:18957 [D loss: 0.834754, acc.: 39.84%] [G loss: 1.004085]\n",
      "epoch:20 step:18958 [D loss: 0.650139, acc.: 64.06%] [G loss: 0.924654]\n",
      "epoch:20 step:18959 [D loss: 0.701729, acc.: 56.25%] [G loss: 1.016396]\n",
      "epoch:20 step:18960 [D loss: 0.281152, acc.: 92.97%] [G loss: 1.164698]\n",
      "epoch:20 step:18961 [D loss: 0.322921, acc.: 95.31%] [G loss: 1.292617]\n",
      "epoch:20 step:18962 [D loss: 0.296922, acc.: 93.75%] [G loss: 1.704463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18963 [D loss: 0.363213, acc.: 89.06%] [G loss: 1.454104]\n",
      "epoch:20 step:18964 [D loss: 0.840661, acc.: 46.88%] [G loss: 1.156703]\n",
      "epoch:20 step:18965 [D loss: 0.881057, acc.: 42.19%] [G loss: 0.937845]\n",
      "epoch:20 step:18966 [D loss: 0.577982, acc.: 67.19%] [G loss: 1.044489]\n",
      "epoch:20 step:18967 [D loss: 0.717991, acc.: 56.25%] [G loss: 0.987513]\n",
      "epoch:20 step:18968 [D loss: 0.703341, acc.: 55.47%] [G loss: 0.791423]\n",
      "epoch:20 step:18969 [D loss: 0.769782, acc.: 56.25%] [G loss: 0.730127]\n",
      "epoch:20 step:18970 [D loss: 0.272156, acc.: 95.31%] [G loss: 1.328959]\n",
      "epoch:20 step:18971 [D loss: 0.285580, acc.: 93.75%] [G loss: 1.743147]\n",
      "epoch:20 step:18972 [D loss: 0.358435, acc.: 91.41%] [G loss: 1.476934]\n",
      "epoch:20 step:18973 [D loss: 0.911060, acc.: 43.75%] [G loss: 1.083428]\n",
      "epoch:20 step:18974 [D loss: 0.856761, acc.: 42.19%] [G loss: 1.224806]\n",
      "epoch:20 step:18975 [D loss: 0.631850, acc.: 67.97%] [G loss: 1.083350]\n",
      "epoch:20 step:18976 [D loss: 0.905250, acc.: 38.28%] [G loss: 1.005204]\n",
      "epoch:20 step:18977 [D loss: 0.797137, acc.: 51.56%] [G loss: 0.824799]\n",
      "epoch:20 step:18978 [D loss: 0.798540, acc.: 41.41%] [G loss: 0.870186]\n",
      "epoch:20 step:18979 [D loss: 0.794571, acc.: 42.97%] [G loss: 1.026619]\n",
      "epoch:20 step:18980 [D loss: 0.783679, acc.: 42.97%] [G loss: 1.084115]\n",
      "epoch:20 step:18981 [D loss: 0.667223, acc.: 61.72%] [G loss: 0.862342]\n",
      "epoch:20 step:18982 [D loss: 0.599905, acc.: 69.53%] [G loss: 1.199338]\n",
      "epoch:20 step:18983 [D loss: 0.712411, acc.: 56.25%] [G loss: 1.161725]\n",
      "epoch:20 step:18984 [D loss: 0.519561, acc.: 80.47%] [G loss: 1.169168]\n",
      "epoch:20 step:18985 [D loss: 0.530096, acc.: 76.56%] [G loss: 1.201102]\n",
      "epoch:20 step:18986 [D loss: 0.393046, acc.: 85.94%] [G loss: 1.392997]\n",
      "epoch:20 step:18987 [D loss: 0.637620, acc.: 61.72%] [G loss: 1.179133]\n",
      "epoch:20 step:18988 [D loss: 0.503941, acc.: 78.91%] [G loss: 1.074001]\n",
      "epoch:20 step:18989 [D loss: 0.820112, acc.: 41.41%] [G loss: 1.201383]\n",
      "epoch:20 step:18990 [D loss: 0.442231, acc.: 85.16%] [G loss: 1.380763]\n",
      "epoch:20 step:18991 [D loss: 0.538449, acc.: 75.78%] [G loss: 1.035748]\n",
      "epoch:20 step:18992 [D loss: 0.475441, acc.: 80.47%] [G loss: 1.418437]\n",
      "epoch:20 step:18993 [D loss: 0.586008, acc.: 67.97%] [G loss: 0.928939]\n",
      "epoch:20 step:18994 [D loss: 0.541246, acc.: 75.78%] [G loss: 1.109154]\n",
      "epoch:20 step:18995 [D loss: 0.914616, acc.: 28.91%] [G loss: 0.903581]\n",
      "epoch:20 step:18996 [D loss: 0.840770, acc.: 40.62%] [G loss: 0.616058]\n",
      "epoch:20 step:18997 [D loss: 0.730293, acc.: 51.56%] [G loss: 0.959277]\n",
      "epoch:20 step:18998 [D loss: 0.759729, acc.: 46.09%] [G loss: 0.800206]\n",
      "epoch:20 step:18999 [D loss: 0.809233, acc.: 49.22%] [G loss: 1.047633]\n",
      "epoch:20 step:19000 [D loss: 0.730220, acc.: 54.69%] [G loss: 0.872751]\n",
      "epoch:20 step:19001 [D loss: 0.637691, acc.: 64.06%] [G loss: 1.073066]\n",
      "epoch:20 step:19002 [D loss: 0.833786, acc.: 42.97%] [G loss: 0.902382]\n",
      "epoch:20 step:19003 [D loss: 0.550563, acc.: 76.56%] [G loss: 1.061504]\n",
      "epoch:20 step:19004 [D loss: 0.501083, acc.: 78.91%] [G loss: 1.044705]\n",
      "epoch:20 step:19005 [D loss: 0.646279, acc.: 65.62%] [G loss: 1.021864]\n",
      "epoch:20 step:19006 [D loss: 0.759269, acc.: 47.66%] [G loss: 1.132108]\n",
      "epoch:20 step:19007 [D loss: 0.481442, acc.: 81.25%] [G loss: 1.148489]\n",
      "epoch:20 step:19008 [D loss: 0.622335, acc.: 62.50%] [G loss: 0.870976]\n",
      "epoch:20 step:19009 [D loss: 0.519530, acc.: 80.47%] [G loss: 0.978057]\n",
      "epoch:20 step:19010 [D loss: 0.709421, acc.: 53.12%] [G loss: 0.905558]\n",
      "epoch:20 step:19011 [D loss: 0.650768, acc.: 62.50%] [G loss: 1.126214]\n",
      "epoch:20 step:19012 [D loss: 0.477582, acc.: 82.81%] [G loss: 1.139225]\n",
      "epoch:20 step:19013 [D loss: 0.577585, acc.: 74.22%] [G loss: 1.226206]\n",
      "epoch:20 step:19014 [D loss: 0.620242, acc.: 66.41%] [G loss: 1.198098]\n",
      "epoch:20 step:19015 [D loss: 0.629068, acc.: 67.97%] [G loss: 1.077216]\n",
      "epoch:20 step:19016 [D loss: 0.693383, acc.: 57.03%] [G loss: 0.920429]\n",
      "epoch:20 step:19017 [D loss: 0.582770, acc.: 69.53%] [G loss: 0.833676]\n",
      "epoch:20 step:19018 [D loss: 0.534273, acc.: 70.31%] [G loss: 0.974557]\n",
      "epoch:20 step:19019 [D loss: 0.433088, acc.: 79.69%] [G loss: 0.998648]\n",
      "epoch:20 step:19020 [D loss: 0.430880, acc.: 80.47%] [G loss: 1.401338]\n",
      "epoch:20 step:19021 [D loss: 0.663864, acc.: 63.28%] [G loss: 1.304234]\n",
      "epoch:20 step:19022 [D loss: 0.572422, acc.: 67.97%] [G loss: 1.106542]\n",
      "epoch:20 step:19023 [D loss: 0.639463, acc.: 60.94%] [G loss: 1.155806]\n",
      "epoch:20 step:19024 [D loss: 0.646886, acc.: 63.28%] [G loss: 0.976543]\n",
      "epoch:20 step:19025 [D loss: 0.525393, acc.: 76.56%] [G loss: 1.181613]\n",
      "epoch:20 step:19026 [D loss: 0.496272, acc.: 77.34%] [G loss: 0.931077]\n",
      "epoch:20 step:19027 [D loss: 0.600148, acc.: 67.19%] [G loss: 1.123999]\n",
      "epoch:20 step:19028 [D loss: 0.534191, acc.: 77.34%] [G loss: 1.217097]\n",
      "epoch:20 step:19029 [D loss: 0.582595, acc.: 69.53%] [G loss: 1.241410]\n",
      "epoch:20 step:19030 [D loss: 0.647555, acc.: 60.94%] [G loss: 1.353797]\n",
      "epoch:20 step:19031 [D loss: 0.433331, acc.: 77.34%] [G loss: 1.083876]\n",
      "epoch:20 step:19032 [D loss: 0.434697, acc.: 86.72%] [G loss: 1.204541]\n",
      "epoch:20 step:19033 [D loss: 0.440781, acc.: 82.81%] [G loss: 1.203261]\n",
      "epoch:20 step:19034 [D loss: 0.744660, acc.: 57.03%] [G loss: 0.897382]\n",
      "epoch:20 step:19035 [D loss: 0.915336, acc.: 37.50%] [G loss: 1.061603]\n",
      "epoch:20 step:19036 [D loss: 0.618711, acc.: 63.28%] [G loss: 1.205641]\n",
      "epoch:20 step:19037 [D loss: 0.848292, acc.: 37.50%] [G loss: 0.830698]\n",
      "epoch:20 step:19038 [D loss: 0.608860, acc.: 70.31%] [G loss: 1.015204]\n",
      "epoch:20 step:19039 [D loss: 0.591931, acc.: 67.19%] [G loss: 1.304882]\n",
      "epoch:20 step:19040 [D loss: 0.568524, acc.: 76.56%] [G loss: 1.201370]\n",
      "epoch:20 step:19041 [D loss: 0.739143, acc.: 55.47%] [G loss: 1.361146]\n",
      "epoch:20 step:19042 [D loss: 0.506150, acc.: 80.47%] [G loss: 1.058652]\n",
      "epoch:20 step:19043 [D loss: 0.738662, acc.: 50.00%] [G loss: 1.024609]\n",
      "epoch:20 step:19044 [D loss: 0.687421, acc.: 57.03%] [G loss: 1.023481]\n",
      "epoch:20 step:19045 [D loss: 0.733705, acc.: 55.47%] [G loss: 1.063370]\n",
      "epoch:20 step:19046 [D loss: 0.586101, acc.: 68.75%] [G loss: 1.055923]\n",
      "epoch:20 step:19047 [D loss: 0.603744, acc.: 70.31%] [G loss: 1.089354]\n",
      "epoch:20 step:19048 [D loss: 0.644744, acc.: 61.72%] [G loss: 0.966503]\n",
      "epoch:20 step:19049 [D loss: 0.511238, acc.: 75.78%] [G loss: 1.219893]\n",
      "epoch:20 step:19050 [D loss: 0.538962, acc.: 73.44%] [G loss: 1.138660]\n",
      "epoch:20 step:19051 [D loss: 0.547109, acc.: 75.00%] [G loss: 0.990849]\n",
      "epoch:20 step:19052 [D loss: 0.390395, acc.: 88.28%] [G loss: 1.057674]\n",
      "epoch:20 step:19053 [D loss: 0.478466, acc.: 78.91%] [G loss: 1.068397]\n",
      "epoch:20 step:19054 [D loss: 0.373063, acc.: 88.28%] [G loss: 1.538456]\n",
      "epoch:20 step:19055 [D loss: 0.501367, acc.: 78.12%] [G loss: 1.212721]\n",
      "epoch:20 step:19056 [D loss: 0.862348, acc.: 41.41%] [G loss: 0.884693]\n",
      "epoch:20 step:19057 [D loss: 0.643984, acc.: 64.06%] [G loss: 1.252006]\n",
      "epoch:20 step:19058 [D loss: 0.605893, acc.: 64.06%] [G loss: 1.012857]\n",
      "epoch:20 step:19059 [D loss: 0.593236, acc.: 67.19%] [G loss: 1.218725]\n",
      "epoch:20 step:19060 [D loss: 0.441123, acc.: 88.28%] [G loss: 1.289535]\n",
      "epoch:20 step:19061 [D loss: 0.459504, acc.: 85.94%] [G loss: 1.198016]\n",
      "epoch:20 step:19062 [D loss: 0.441220, acc.: 86.72%] [G loss: 1.286448]\n",
      "epoch:20 step:19063 [D loss: 0.766307, acc.: 49.22%] [G loss: 1.058749]\n",
      "epoch:20 step:19064 [D loss: 0.582826, acc.: 69.53%] [G loss: 0.926793]\n",
      "epoch:20 step:19065 [D loss: 0.604898, acc.: 64.06%] [G loss: 0.842508]\n",
      "epoch:20 step:19066 [D loss: 0.433112, acc.: 85.16%] [G loss: 1.067775]\n",
      "epoch:20 step:19067 [D loss: 0.375172, acc.: 85.94%] [G loss: 1.140300]\n",
      "epoch:20 step:19068 [D loss: 0.293925, acc.: 95.31%] [G loss: 1.548624]\n",
      "epoch:20 step:19069 [D loss: 0.729905, acc.: 53.12%] [G loss: 0.758310]\n",
      "epoch:20 step:19070 [D loss: 0.643761, acc.: 64.06%] [G loss: 1.072657]\n",
      "epoch:20 step:19071 [D loss: 0.950232, acc.: 31.25%] [G loss: 0.990640]\n",
      "epoch:20 step:19072 [D loss: 0.843465, acc.: 41.41%] [G loss: 0.760754]\n",
      "epoch:20 step:19073 [D loss: 0.836173, acc.: 45.31%] [G loss: 0.815552]\n",
      "epoch:20 step:19074 [D loss: 0.774660, acc.: 52.34%] [G loss: 0.991109]\n",
      "epoch:20 step:19075 [D loss: 0.615062, acc.: 63.28%] [G loss: 1.202521]\n",
      "epoch:20 step:19076 [D loss: 0.648803, acc.: 62.50%] [G loss: 1.020231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19077 [D loss: 0.613742, acc.: 63.28%] [G loss: 1.059946]\n",
      "epoch:20 step:19078 [D loss: 0.668711, acc.: 61.72%] [G loss: 1.075268]\n",
      "epoch:20 step:19079 [D loss: 0.696468, acc.: 55.47%] [G loss: 1.126658]\n",
      "epoch:20 step:19080 [D loss: 0.640794, acc.: 61.72%] [G loss: 1.035875]\n",
      "epoch:20 step:19081 [D loss: 0.720145, acc.: 58.59%] [G loss: 1.322029]\n",
      "epoch:20 step:19082 [D loss: 0.547385, acc.: 72.66%] [G loss: 1.176757]\n",
      "epoch:20 step:19083 [D loss: 0.413556, acc.: 79.69%] [G loss: 1.279808]\n",
      "epoch:20 step:19084 [D loss: 0.412619, acc.: 88.28%] [G loss: 1.142075]\n",
      "epoch:20 step:19085 [D loss: 0.349248, acc.: 89.84%] [G loss: 1.543084]\n",
      "epoch:20 step:19086 [D loss: 0.287056, acc.: 93.75%] [G loss: 1.373365]\n",
      "epoch:20 step:19087 [D loss: 0.243907, acc.: 97.66%] [G loss: 1.563057]\n",
      "epoch:20 step:19088 [D loss: 0.763548, acc.: 53.12%] [G loss: 1.403423]\n",
      "epoch:20 step:19089 [D loss: 0.896514, acc.: 44.53%] [G loss: 0.961166]\n",
      "epoch:20 step:19090 [D loss: 0.693630, acc.: 56.25%] [G loss: 1.109874]\n",
      "epoch:20 step:19091 [D loss: 0.698907, acc.: 60.94%] [G loss: 0.772212]\n",
      "epoch:20 step:19092 [D loss: 0.721975, acc.: 52.34%] [G loss: 1.019904]\n",
      "epoch:20 step:19093 [D loss: 0.726543, acc.: 51.56%] [G loss: 1.012403]\n",
      "epoch:20 step:19094 [D loss: 0.538913, acc.: 75.00%] [G loss: 0.965312]\n",
      "epoch:20 step:19095 [D loss: 0.772679, acc.: 44.53%] [G loss: 1.041173]\n",
      "epoch:20 step:19096 [D loss: 0.732805, acc.: 52.34%] [G loss: 1.087066]\n",
      "epoch:20 step:19097 [D loss: 0.727040, acc.: 53.12%] [G loss: 0.900517]\n",
      "epoch:20 step:19098 [D loss: 0.509425, acc.: 75.00%] [G loss: 0.988368]\n",
      "epoch:20 step:19099 [D loss: 0.535714, acc.: 77.34%] [G loss: 1.110411]\n",
      "epoch:20 step:19100 [D loss: 0.700579, acc.: 54.69%] [G loss: 1.072439]\n",
      "epoch:20 step:19101 [D loss: 0.672446, acc.: 57.03%] [G loss: 1.085957]\n",
      "epoch:20 step:19102 [D loss: 0.718169, acc.: 50.00%] [G loss: 0.895079]\n",
      "epoch:20 step:19103 [D loss: 0.636645, acc.: 64.06%] [G loss: 1.068957]\n",
      "epoch:20 step:19104 [D loss: 0.536353, acc.: 72.66%] [G loss: 0.873663]\n",
      "epoch:20 step:19105 [D loss: 0.527893, acc.: 71.88%] [G loss: 0.970007]\n",
      "epoch:20 step:19106 [D loss: 0.300783, acc.: 96.09%] [G loss: 1.463674]\n",
      "epoch:20 step:19107 [D loss: 0.290453, acc.: 94.53%] [G loss: 1.272209]\n",
      "epoch:20 step:19108 [D loss: 0.675932, acc.: 62.50%] [G loss: 1.208231]\n",
      "epoch:20 step:19109 [D loss: 0.759184, acc.: 46.88%] [G loss: 1.347417]\n",
      "epoch:20 step:19110 [D loss: 0.664634, acc.: 60.16%] [G loss: 1.059265]\n",
      "epoch:20 step:19111 [D loss: 0.669498, acc.: 54.69%] [G loss: 1.025151]\n",
      "epoch:20 step:19112 [D loss: 0.803603, acc.: 45.31%] [G loss: 1.039445]\n",
      "epoch:20 step:19113 [D loss: 0.694677, acc.: 53.91%] [G loss: 1.044619]\n",
      "epoch:20 step:19114 [D loss: 0.519055, acc.: 81.25%] [G loss: 0.915074]\n",
      "epoch:20 step:19115 [D loss: 0.783846, acc.: 51.56%] [G loss: 0.969618]\n",
      "epoch:20 step:19116 [D loss: 0.681548, acc.: 58.59%] [G loss: 0.827736]\n",
      "epoch:20 step:19117 [D loss: 0.472937, acc.: 78.12%] [G loss: 1.144048]\n",
      "epoch:20 step:19118 [D loss: 0.339831, acc.: 92.19%] [G loss: 1.203547]\n",
      "epoch:20 step:19119 [D loss: 0.803272, acc.: 46.09%] [G loss: 1.098845]\n",
      "epoch:20 step:19120 [D loss: 0.721116, acc.: 56.25%] [G loss: 0.966911]\n",
      "epoch:20 step:19121 [D loss: 0.504794, acc.: 82.03%] [G loss: 1.027201]\n",
      "epoch:20 step:19122 [D loss: 0.737079, acc.: 50.00%] [G loss: 1.058385]\n",
      "epoch:20 step:19123 [D loss: 0.661913, acc.: 57.03%] [G loss: 1.050699]\n",
      "epoch:20 step:19124 [D loss: 0.576688, acc.: 73.44%] [G loss: 1.027223]\n",
      "epoch:20 step:19125 [D loss: 0.591113, acc.: 73.44%] [G loss: 0.855623]\n",
      "epoch:20 step:19126 [D loss: 0.563737, acc.: 72.66%] [G loss: 1.066704]\n",
      "epoch:20 step:19127 [D loss: 0.559565, acc.: 76.56%] [G loss: 1.081041]\n",
      "epoch:20 step:19128 [D loss: 0.530889, acc.: 76.56%] [G loss: 1.158568]\n",
      "epoch:20 step:19129 [D loss: 0.754806, acc.: 51.56%] [G loss: 0.923503]\n",
      "epoch:20 step:19130 [D loss: 0.619102, acc.: 67.97%] [G loss: 1.184493]\n",
      "epoch:20 step:19131 [D loss: 0.606837, acc.: 70.31%] [G loss: 1.101244]\n",
      "epoch:20 step:19132 [D loss: 0.514963, acc.: 78.91%] [G loss: 1.220453]\n",
      "epoch:20 step:19133 [D loss: 0.712801, acc.: 56.25%] [G loss: 1.154642]\n",
      "epoch:20 step:19134 [D loss: 0.511322, acc.: 74.22%] [G loss: 0.894756]\n",
      "epoch:20 step:19135 [D loss: 0.457444, acc.: 85.94%] [G loss: 1.071249]\n",
      "epoch:20 step:19136 [D loss: 0.370123, acc.: 87.50%] [G loss: 1.202286]\n",
      "epoch:20 step:19137 [D loss: 0.336544, acc.: 86.72%] [G loss: 1.264788]\n",
      "epoch:20 step:19138 [D loss: 0.335668, acc.: 90.62%] [G loss: 1.234210]\n",
      "epoch:20 step:19139 [D loss: 0.409898, acc.: 84.38%] [G loss: 1.597800]\n",
      "epoch:20 step:19140 [D loss: 0.487043, acc.: 75.78%] [G loss: 1.169132]\n",
      "epoch:20 step:19141 [D loss: 0.454860, acc.: 79.69%] [G loss: 1.617863]\n",
      "epoch:20 step:19142 [D loss: 0.530995, acc.: 71.88%] [G loss: 1.138543]\n",
      "epoch:20 step:19143 [D loss: 0.512215, acc.: 74.22%] [G loss: 1.355834]\n",
      "epoch:20 step:19144 [D loss: 0.456655, acc.: 79.69%] [G loss: 1.345067]\n",
      "epoch:20 step:19145 [D loss: 0.282912, acc.: 92.19%] [G loss: 1.608169]\n",
      "epoch:20 step:19146 [D loss: 0.652655, acc.: 69.53%] [G loss: 1.045053]\n",
      "epoch:20 step:19147 [D loss: 0.501984, acc.: 76.56%] [G loss: 1.398694]\n",
      "epoch:20 step:19148 [D loss: 0.631053, acc.: 64.84%] [G loss: 1.098715]\n",
      "epoch:20 step:19149 [D loss: 0.788499, acc.: 50.78%] [G loss: 1.077595]\n",
      "epoch:20 step:19150 [D loss: 0.616029, acc.: 66.41%] [G loss: 1.209475]\n",
      "epoch:20 step:19151 [D loss: 1.171175, acc.: 24.22%] [G loss: 0.927994]\n",
      "epoch:20 step:19152 [D loss: 0.911967, acc.: 32.81%] [G loss: 0.819477]\n",
      "epoch:20 step:19153 [D loss: 1.143274, acc.: 21.88%] [G loss: 0.769382]\n",
      "epoch:20 step:19154 [D loss: 0.639770, acc.: 64.06%] [G loss: 1.089259]\n",
      "epoch:20 step:19155 [D loss: 0.937624, acc.: 31.25%] [G loss: 0.967973]\n",
      "epoch:20 step:19156 [D loss: 0.754121, acc.: 51.56%] [G loss: 1.102117]\n",
      "epoch:20 step:19157 [D loss: 0.997787, acc.: 36.72%] [G loss: 1.239836]\n",
      "epoch:20 step:19158 [D loss: 0.764397, acc.: 50.00%] [G loss: 0.966879]\n",
      "epoch:20 step:19159 [D loss: 0.738429, acc.: 50.78%] [G loss: 0.861721]\n",
      "epoch:20 step:19160 [D loss: 0.646173, acc.: 66.41%] [G loss: 1.279674]\n",
      "epoch:20 step:19161 [D loss: 0.685848, acc.: 57.03%] [G loss: 1.089922]\n",
      "epoch:20 step:19162 [D loss: 0.729485, acc.: 57.03%] [G loss: 1.344261]\n",
      "epoch:20 step:19163 [D loss: 0.610431, acc.: 63.28%] [G loss: 1.240435]\n",
      "epoch:20 step:19164 [D loss: 0.670093, acc.: 62.50%] [G loss: 1.020700]\n",
      "epoch:20 step:19165 [D loss: 0.761726, acc.: 50.00%] [G loss: 1.063422]\n",
      "epoch:20 step:19166 [D loss: 0.585105, acc.: 65.62%] [G loss: 1.047513]\n",
      "epoch:20 step:19167 [D loss: 0.626362, acc.: 59.38%] [G loss: 1.321346]\n",
      "epoch:20 step:19168 [D loss: 0.692280, acc.: 57.03%] [G loss: 0.932745]\n",
      "epoch:20 step:19169 [D loss: 0.621388, acc.: 67.97%] [G loss: 1.205915]\n",
      "epoch:20 step:19170 [D loss: 0.661723, acc.: 58.59%] [G loss: 1.281872]\n",
      "epoch:20 step:19171 [D loss: 0.513068, acc.: 82.03%] [G loss: 1.178563]\n",
      "epoch:20 step:19172 [D loss: 0.524734, acc.: 72.66%] [G loss: 1.133104]\n",
      "epoch:20 step:19173 [D loss: 0.415447, acc.: 85.16%] [G loss: 1.541089]\n",
      "epoch:20 step:19174 [D loss: 0.552499, acc.: 73.44%] [G loss: 1.281596]\n",
      "epoch:20 step:19175 [D loss: 0.498479, acc.: 78.91%] [G loss: 1.340718]\n",
      "epoch:20 step:19176 [D loss: 0.375544, acc.: 93.75%] [G loss: 1.482227]\n",
      "epoch:20 step:19177 [D loss: 0.786321, acc.: 53.91%] [G loss: 1.408740]\n",
      "epoch:20 step:19178 [D loss: 0.826493, acc.: 42.19%] [G loss: 0.795923]\n",
      "epoch:20 step:19179 [D loss: 0.674845, acc.: 57.81%] [G loss: 0.901350]\n",
      "epoch:20 step:19180 [D loss: 0.717360, acc.: 59.38%] [G loss: 0.993215]\n",
      "epoch:20 step:19181 [D loss: 0.865725, acc.: 43.75%] [G loss: 0.791473]\n",
      "epoch:20 step:19182 [D loss: 0.662303, acc.: 60.94%] [G loss: 1.010798]\n",
      "epoch:20 step:19183 [D loss: 0.518542, acc.: 78.12%] [G loss: 1.308377]\n",
      "epoch:20 step:19184 [D loss: 0.757167, acc.: 48.44%] [G loss: 0.841568]\n",
      "epoch:20 step:19185 [D loss: 0.629751, acc.: 67.97%] [G loss: 1.265261]\n",
      "epoch:20 step:19186 [D loss: 0.847441, acc.: 43.75%] [G loss: 0.933832]\n",
      "epoch:20 step:19187 [D loss: 0.670421, acc.: 61.72%] [G loss: 1.228396]\n",
      "epoch:20 step:19188 [D loss: 0.624887, acc.: 64.84%] [G loss: 1.174989]\n",
      "epoch:20 step:19189 [D loss: 0.647392, acc.: 64.06%] [G loss: 1.234760]\n",
      "epoch:20 step:19190 [D loss: 0.595019, acc.: 67.19%] [G loss: 1.152252]\n",
      "epoch:20 step:19191 [D loss: 0.454122, acc.: 85.94%] [G loss: 1.216044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19192 [D loss: 0.608511, acc.: 67.97%] [G loss: 1.186544]\n",
      "epoch:20 step:19193 [D loss: 0.410516, acc.: 88.28%] [G loss: 1.281107]\n",
      "epoch:20 step:19194 [D loss: 0.616830, acc.: 67.97%] [G loss: 1.059469]\n",
      "epoch:20 step:19195 [D loss: 0.594686, acc.: 70.31%] [G loss: 1.495316]\n",
      "epoch:20 step:19196 [D loss: 0.669352, acc.: 67.19%] [G loss: 1.054216]\n",
      "epoch:20 step:19197 [D loss: 0.529653, acc.: 73.44%] [G loss: 1.307741]\n",
      "epoch:20 step:19198 [D loss: 1.133364, acc.: 29.69%] [G loss: 0.842496]\n",
      "epoch:20 step:19199 [D loss: 0.909929, acc.: 34.38%] [G loss: 0.895142]\n",
      "epoch:20 step:19200 [D loss: 0.989276, acc.: 35.16%] [G loss: 0.653227]\n",
      "epoch:20 step:19201 [D loss: 0.934670, acc.: 29.69%] [G loss: 0.874830]\n",
      "epoch:20 step:19202 [D loss: 0.791380, acc.: 45.31%] [G loss: 0.878322]\n",
      "epoch:20 step:19203 [D loss: 0.712345, acc.: 51.56%] [G loss: 0.949020]\n",
      "epoch:20 step:19204 [D loss: 0.593356, acc.: 68.75%] [G loss: 1.032120]\n",
      "epoch:20 step:19205 [D loss: 0.686632, acc.: 52.34%] [G loss: 1.029119]\n",
      "epoch:20 step:19206 [D loss: 0.631547, acc.: 67.19%] [G loss: 0.960806]\n",
      "epoch:20 step:19207 [D loss: 0.661560, acc.: 58.59%] [G loss: 1.224148]\n",
      "epoch:20 step:19208 [D loss: 0.591154, acc.: 68.75%] [G loss: 1.039456]\n",
      "epoch:20 step:19209 [D loss: 0.489114, acc.: 79.69%] [G loss: 1.245545]\n",
      "epoch:20 step:19210 [D loss: 0.456299, acc.: 85.94%] [G loss: 1.259991]\n",
      "epoch:20 step:19211 [D loss: 0.303308, acc.: 92.97%] [G loss: 1.489324]\n",
      "epoch:20 step:19212 [D loss: 0.616397, acc.: 67.19%] [G loss: 1.101543]\n",
      "epoch:20 step:19213 [D loss: 0.494243, acc.: 75.78%] [G loss: 1.397736]\n",
      "epoch:20 step:19214 [D loss: 0.512292, acc.: 80.47%] [G loss: 1.278009]\n",
      "epoch:20 step:19215 [D loss: 0.545129, acc.: 69.53%] [G loss: 1.341842]\n",
      "epoch:20 step:19216 [D loss: 0.656830, acc.: 60.94%] [G loss: 1.167049]\n",
      "epoch:20 step:19217 [D loss: 0.639610, acc.: 62.50%] [G loss: 1.279604]\n",
      "epoch:20 step:19218 [D loss: 0.641470, acc.: 60.16%] [G loss: 1.004758]\n",
      "epoch:20 step:19219 [D loss: 0.580991, acc.: 66.41%] [G loss: 0.975582]\n",
      "epoch:20 step:19220 [D loss: 0.646454, acc.: 60.16%] [G loss: 1.263757]\n",
      "epoch:20 step:19221 [D loss: 0.531322, acc.: 75.00%] [G loss: 1.151164]\n",
      "epoch:20 step:19222 [D loss: 0.534868, acc.: 75.00%] [G loss: 1.089073]\n",
      "epoch:20 step:19223 [D loss: 0.563412, acc.: 76.56%] [G loss: 1.128463]\n",
      "epoch:20 step:19224 [D loss: 0.350211, acc.: 92.19%] [G loss: 1.308900]\n",
      "epoch:20 step:19225 [D loss: 0.392392, acc.: 89.84%] [G loss: 1.372360]\n",
      "epoch:20 step:19226 [D loss: 0.393823, acc.: 92.19%] [G loss: 1.143613]\n",
      "epoch:20 step:19227 [D loss: 0.504288, acc.: 79.69%] [G loss: 1.264173]\n",
      "epoch:20 step:19228 [D loss: 0.574029, acc.: 66.41%] [G loss: 1.222347]\n",
      "epoch:20 step:19229 [D loss: 0.790888, acc.: 52.34%] [G loss: 1.186308]\n",
      "epoch:20 step:19230 [D loss: 0.608328, acc.: 67.19%] [G loss: 0.959157]\n",
      "epoch:20 step:19231 [D loss: 0.682543, acc.: 58.59%] [G loss: 1.111972]\n",
      "epoch:20 step:19232 [D loss: 0.733051, acc.: 59.38%] [G loss: 1.348486]\n",
      "epoch:20 step:19233 [D loss: 0.690962, acc.: 59.38%] [G loss: 0.989828]\n",
      "epoch:20 step:19234 [D loss: 0.611535, acc.: 66.41%] [G loss: 0.938787]\n",
      "epoch:20 step:19235 [D loss: 0.609597, acc.: 64.06%] [G loss: 0.780564]\n",
      "epoch:20 step:19236 [D loss: 0.576691, acc.: 71.88%] [G loss: 1.181648]\n",
      "epoch:20 step:19237 [D loss: 0.416813, acc.: 82.03%] [G loss: 1.338291]\n",
      "epoch:20 step:19238 [D loss: 0.463676, acc.: 78.12%] [G loss: 1.346132]\n",
      "epoch:20 step:19239 [D loss: 0.301057, acc.: 92.19%] [G loss: 1.565396]\n",
      "epoch:20 step:19240 [D loss: 0.704647, acc.: 59.38%] [G loss: 1.447532]\n",
      "epoch:20 step:19241 [D loss: 0.922313, acc.: 34.38%] [G loss: 1.004779]\n",
      "epoch:20 step:19242 [D loss: 0.801114, acc.: 46.09%] [G loss: 1.140650]\n",
      "epoch:20 step:19243 [D loss: 0.395884, acc.: 85.16%] [G loss: 1.201168]\n",
      "epoch:20 step:19244 [D loss: 0.293433, acc.: 92.97%] [G loss: 1.135364]\n",
      "epoch:20 step:19245 [D loss: 0.469630, acc.: 83.59%] [G loss: 1.208446]\n",
      "epoch:20 step:19246 [D loss: 0.519239, acc.: 77.34%] [G loss: 1.250938]\n",
      "epoch:20 step:19247 [D loss: 0.443717, acc.: 82.03%] [G loss: 1.064748]\n",
      "epoch:20 step:19248 [D loss: 0.354925, acc.: 87.50%] [G loss: 0.924874]\n",
      "epoch:20 step:19249 [D loss: 0.688333, acc.: 56.25%] [G loss: 1.167993]\n",
      "epoch:20 step:19250 [D loss: 0.748541, acc.: 48.44%] [G loss: 1.123494]\n",
      "epoch:20 step:19251 [D loss: 0.485010, acc.: 78.91%] [G loss: 1.037556]\n",
      "epoch:20 step:19252 [D loss: 0.361751, acc.: 91.41%] [G loss: 1.257221]\n",
      "epoch:20 step:19253 [D loss: 0.455580, acc.: 85.16%] [G loss: 1.351907]\n",
      "epoch:20 step:19254 [D loss: 0.436532, acc.: 90.62%] [G loss: 1.199168]\n",
      "epoch:20 step:19255 [D loss: 0.488395, acc.: 78.12%] [G loss: 1.162416]\n",
      "epoch:20 step:19256 [D loss: 0.554586, acc.: 71.09%] [G loss: 1.165999]\n",
      "epoch:20 step:19257 [D loss: 0.596979, acc.: 66.41%] [G loss: 1.189864]\n",
      "epoch:20 step:19258 [D loss: 0.624033, acc.: 63.28%] [G loss: 0.905657]\n",
      "epoch:20 step:19259 [D loss: 0.560059, acc.: 72.66%] [G loss: 1.094764]\n",
      "epoch:20 step:19260 [D loss: 0.478907, acc.: 75.78%] [G loss: 1.052363]\n",
      "epoch:20 step:19261 [D loss: 0.515874, acc.: 72.66%] [G loss: 1.154241]\n",
      "epoch:20 step:19262 [D loss: 0.409755, acc.: 88.28%] [G loss: 1.349025]\n",
      "epoch:20 step:19263 [D loss: 0.512311, acc.: 75.78%] [G loss: 1.172277]\n",
      "epoch:20 step:19264 [D loss: 0.903099, acc.: 35.16%] [G loss: 1.082904]\n",
      "epoch:20 step:19265 [D loss: 0.623779, acc.: 67.97%] [G loss: 1.070314]\n",
      "epoch:20 step:19266 [D loss: 0.573220, acc.: 71.88%] [G loss: 1.122441]\n",
      "epoch:20 step:19267 [D loss: 0.624718, acc.: 63.28%] [G loss: 1.282931]\n",
      "epoch:20 step:19268 [D loss: 0.710529, acc.: 55.47%] [G loss: 0.997545]\n",
      "epoch:20 step:19269 [D loss: 0.652769, acc.: 59.38%] [G loss: 0.927382]\n",
      "epoch:20 step:19270 [D loss: 0.496348, acc.: 77.34%] [G loss: 1.021381]\n",
      "epoch:20 step:19271 [D loss: 0.790374, acc.: 52.34%] [G loss: 1.205732]\n",
      "epoch:20 step:19272 [D loss: 0.527239, acc.: 73.44%] [G loss: 1.332559]\n",
      "epoch:20 step:19273 [D loss: 0.323820, acc.: 94.53%] [G loss: 1.319066]\n",
      "epoch:20 step:19274 [D loss: 0.507484, acc.: 80.47%] [G loss: 1.099229]\n",
      "epoch:20 step:19275 [D loss: 0.509540, acc.: 78.91%] [G loss: 1.222945]\n",
      "epoch:20 step:19276 [D loss: 0.368426, acc.: 91.41%] [G loss: 1.160088]\n",
      "epoch:20 step:19277 [D loss: 0.576156, acc.: 70.31%] [G loss: 1.135134]\n",
      "epoch:20 step:19278 [D loss: 0.586120, acc.: 70.31%] [G loss: 1.038787]\n",
      "epoch:20 step:19279 [D loss: 0.704767, acc.: 49.22%] [G loss: 0.912391]\n",
      "epoch:20 step:19280 [D loss: 0.665582, acc.: 58.59%] [G loss: 1.122673]\n",
      "epoch:20 step:19281 [D loss: 0.653589, acc.: 57.03%] [G loss: 0.925873]\n",
      "epoch:20 step:19282 [D loss: 0.675456, acc.: 54.69%] [G loss: 0.796216]\n",
      "epoch:20 step:19283 [D loss: 0.584842, acc.: 71.09%] [G loss: 1.000437]\n",
      "epoch:20 step:19284 [D loss: 0.602114, acc.: 67.19%] [G loss: 0.905328]\n",
      "epoch:20 step:19285 [D loss: 0.352310, acc.: 95.31%] [G loss: 1.195300]\n",
      "epoch:20 step:19286 [D loss: 0.363220, acc.: 90.62%] [G loss: 1.098898]\n",
      "epoch:20 step:19287 [D loss: 0.467706, acc.: 88.28%] [G loss: 0.879127]\n",
      "epoch:20 step:19288 [D loss: 0.456175, acc.: 83.59%] [G loss: 1.271089]\n",
      "epoch:20 step:19289 [D loss: 0.488106, acc.: 75.78%] [G loss: 1.133035]\n",
      "epoch:20 step:19290 [D loss: 0.338118, acc.: 94.53%] [G loss: 1.348915]\n",
      "epoch:20 step:19291 [D loss: 0.323430, acc.: 94.53%] [G loss: 1.380532]\n",
      "epoch:20 step:19292 [D loss: 0.493556, acc.: 81.25%] [G loss: 1.259544]\n",
      "epoch:20 step:19293 [D loss: 0.404580, acc.: 88.28%] [G loss: 1.440140]\n",
      "epoch:20 step:19294 [D loss: 0.483117, acc.: 75.78%] [G loss: 1.116918]\n",
      "epoch:20 step:19295 [D loss: 0.347967, acc.: 96.09%] [G loss: 1.561237]\n",
      "epoch:20 step:19296 [D loss: 0.358779, acc.: 89.06%] [G loss: 1.631049]\n",
      "epoch:20 step:19297 [D loss: 0.426212, acc.: 87.50%] [G loss: 1.381571]\n",
      "epoch:20 step:19298 [D loss: 0.568630, acc.: 72.66%] [G loss: 0.867716]\n",
      "epoch:20 step:19299 [D loss: 0.820750, acc.: 46.88%] [G loss: 1.654401]\n",
      "epoch:20 step:19300 [D loss: 0.792095, acc.: 52.34%] [G loss: 1.449343]\n",
      "epoch:20 step:19301 [D loss: 0.437690, acc.: 86.72%] [G loss: 1.519988]\n",
      "epoch:20 step:19302 [D loss: 0.687103, acc.: 58.59%] [G loss: 1.396501]\n",
      "epoch:20 step:19303 [D loss: 0.689206, acc.: 57.03%] [G loss: 1.180269]\n",
      "epoch:20 step:19304 [D loss: 0.655171, acc.: 64.84%] [G loss: 1.196778]\n",
      "epoch:20 step:19305 [D loss: 0.456060, acc.: 82.03%] [G loss: 1.196163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19306 [D loss: 0.379284, acc.: 88.28%] [G loss: 1.421403]\n",
      "epoch:20 step:19307 [D loss: 0.279437, acc.: 96.09%] [G loss: 1.958183]\n",
      "epoch:20 step:19308 [D loss: 0.695662, acc.: 62.50%] [G loss: 1.384632]\n",
      "epoch:20 step:19309 [D loss: 0.715371, acc.: 53.12%] [G loss: 1.126221]\n",
      "epoch:20 step:19310 [D loss: 0.698892, acc.: 55.47%] [G loss: 0.992790]\n",
      "epoch:20 step:19311 [D loss: 0.528742, acc.: 69.53%] [G loss: 1.207921]\n",
      "epoch:20 step:19312 [D loss: 0.502049, acc.: 80.47%] [G loss: 0.949291]\n",
      "epoch:20 step:19313 [D loss: 0.567644, acc.: 68.75%] [G loss: 1.203596]\n",
      "epoch:20 step:19314 [D loss: 0.402698, acc.: 86.72%] [G loss: 1.447273]\n",
      "epoch:20 step:19315 [D loss: 0.449713, acc.: 82.81%] [G loss: 1.394886]\n",
      "epoch:20 step:19316 [D loss: 0.357391, acc.: 92.19%] [G loss: 1.391468]\n",
      "epoch:20 step:19317 [D loss: 0.505193, acc.: 72.66%] [G loss: 1.055997]\n",
      "epoch:20 step:19318 [D loss: 0.321784, acc.: 95.31%] [G loss: 1.258157]\n",
      "epoch:20 step:19319 [D loss: 0.666120, acc.: 57.81%] [G loss: 1.281209]\n",
      "epoch:20 step:19320 [D loss: 0.798773, acc.: 48.44%] [G loss: 0.949848]\n",
      "epoch:20 step:19321 [D loss: 1.092180, acc.: 35.16%] [G loss: 0.528802]\n",
      "epoch:20 step:19322 [D loss: 0.792580, acc.: 46.09%] [G loss: 0.614135]\n",
      "epoch:20 step:19323 [D loss: 0.774752, acc.: 50.78%] [G loss: 1.022286]\n",
      "epoch:20 step:19324 [D loss: 0.658325, acc.: 59.38%] [G loss: 1.075714]\n",
      "epoch:20 step:19325 [D loss: 0.797040, acc.: 42.97%] [G loss: 0.837040]\n",
      "epoch:20 step:19326 [D loss: 0.766310, acc.: 46.09%] [G loss: 0.649272]\n",
      "epoch:20 step:19327 [D loss: 0.521717, acc.: 68.75%] [G loss: 1.009716]\n",
      "epoch:20 step:19328 [D loss: 0.379375, acc.: 89.06%] [G loss: 1.592090]\n",
      "epoch:20 step:19329 [D loss: 0.336916, acc.: 92.19%] [G loss: 1.558743]\n",
      "epoch:20 step:19330 [D loss: 0.843635, acc.: 48.44%] [G loss: 1.324739]\n",
      "epoch:20 step:19331 [D loss: 0.977421, acc.: 32.03%] [G loss: 1.018920]\n",
      "epoch:20 step:19332 [D loss: 0.613852, acc.: 64.06%] [G loss: 1.404814]\n",
      "epoch:20 step:19333 [D loss: 0.574417, acc.: 67.19%] [G loss: 1.563921]\n",
      "epoch:20 step:19334 [D loss: 0.632511, acc.: 63.28%] [G loss: 1.782415]\n",
      "epoch:20 step:19335 [D loss: 0.439995, acc.: 83.59%] [G loss: 1.479576]\n",
      "epoch:20 step:19336 [D loss: 0.527666, acc.: 68.75%] [G loss: 1.381006]\n",
      "epoch:20 step:19337 [D loss: 0.649657, acc.: 65.62%] [G loss: 1.257695]\n",
      "epoch:20 step:19338 [D loss: 0.288076, acc.: 93.75%] [G loss: 1.040835]\n",
      "epoch:20 step:19339 [D loss: 0.556202, acc.: 75.78%] [G loss: 1.447540]\n",
      "epoch:20 step:19340 [D loss: 0.584678, acc.: 61.72%] [G loss: 1.196755]\n",
      "epoch:20 step:19341 [D loss: 0.609975, acc.: 68.75%] [G loss: 0.762929]\n",
      "epoch:20 step:19342 [D loss: 0.663852, acc.: 57.03%] [G loss: 0.919953]\n",
      "epoch:20 step:19343 [D loss: 0.425293, acc.: 82.03%] [G loss: 1.337507]\n",
      "epoch:20 step:19344 [D loss: 0.294724, acc.: 91.41%] [G loss: 1.535381]\n",
      "epoch:20 step:19345 [D loss: 0.380159, acc.: 89.84%] [G loss: 1.578475]\n",
      "epoch:20 step:19346 [D loss: 0.703972, acc.: 57.81%] [G loss: 1.238484]\n",
      "epoch:20 step:19347 [D loss: 0.602874, acc.: 67.97%] [G loss: 1.345249]\n",
      "epoch:20 step:19348 [D loss: 0.654299, acc.: 62.50%] [G loss: 0.949908]\n",
      "epoch:20 step:19349 [D loss: 0.539492, acc.: 71.88%] [G loss: 1.098142]\n",
      "epoch:20 step:19350 [D loss: 0.454695, acc.: 83.59%] [G loss: 1.089568]\n",
      "epoch:20 step:19351 [D loss: 0.734384, acc.: 57.03%] [G loss: 1.082200]\n",
      "epoch:20 step:19352 [D loss: 0.634942, acc.: 65.62%] [G loss: 0.875109]\n",
      "epoch:20 step:19353 [D loss: 0.500293, acc.: 71.88%] [G loss: 1.079842]\n",
      "epoch:20 step:19354 [D loss: 0.294536, acc.: 95.31%] [G loss: 1.560006]\n",
      "epoch:20 step:19355 [D loss: 0.221362, acc.: 99.22%] [G loss: 1.814499]\n",
      "epoch:20 step:19356 [D loss: 0.244543, acc.: 95.31%] [G loss: 1.895241]\n",
      "epoch:20 step:19357 [D loss: 0.341518, acc.: 91.41%] [G loss: 1.446626]\n",
      "epoch:20 step:19358 [D loss: 0.621544, acc.: 68.75%] [G loss: 1.265129]\n",
      "epoch:20 step:19359 [D loss: 0.906592, acc.: 39.06%] [G loss: 0.720552]\n",
      "epoch:20 step:19360 [D loss: 1.050422, acc.: 31.25%] [G loss: 0.788229]\n",
      "epoch:20 step:19361 [D loss: 0.729652, acc.: 54.69%] [G loss: 0.987324]\n",
      "epoch:20 step:19362 [D loss: 0.529860, acc.: 76.56%] [G loss: 1.266006]\n",
      "epoch:20 step:19363 [D loss: 0.905654, acc.: 39.84%] [G loss: 1.188257]\n",
      "epoch:20 step:19364 [D loss: 0.518021, acc.: 71.88%] [G loss: 1.225553]\n",
      "epoch:20 step:19365 [D loss: 1.286674, acc.: 14.84%] [G loss: 0.888458]\n",
      "epoch:20 step:19366 [D loss: 0.848275, acc.: 51.56%] [G loss: 1.412310]\n",
      "epoch:20 step:19367 [D loss: 0.939683, acc.: 32.03%] [G loss: 0.755729]\n",
      "epoch:20 step:19368 [D loss: 1.191828, acc.: 17.97%] [G loss: 0.625718]\n",
      "epoch:20 step:19369 [D loss: 0.424696, acc.: 84.38%] [G loss: 1.421196]\n",
      "epoch:20 step:19370 [D loss: 0.741143, acc.: 51.56%] [G loss: 0.872312]\n",
      "epoch:20 step:19371 [D loss: 0.599035, acc.: 65.62%] [G loss: 1.247650]\n",
      "epoch:20 step:19372 [D loss: 0.568856, acc.: 65.62%] [G loss: 1.291983]\n",
      "epoch:20 step:19373 [D loss: 0.641451, acc.: 64.06%] [G loss: 1.191232]\n",
      "epoch:20 step:19374 [D loss: 0.800396, acc.: 53.12%] [G loss: 0.879080]\n",
      "epoch:20 step:19375 [D loss: 0.712302, acc.: 59.38%] [G loss: 1.502485]\n",
      "epoch:20 step:19376 [D loss: 0.546919, acc.: 72.66%] [G loss: 1.659271]\n",
      "epoch:20 step:19377 [D loss: 0.912357, acc.: 28.12%] [G loss: 1.310617]\n",
      "epoch:20 step:19378 [D loss: 0.994821, acc.: 37.50%] [G loss: 0.881633]\n",
      "epoch:20 step:19379 [D loss: 0.792719, acc.: 50.00%] [G loss: 1.203698]\n",
      "epoch:20 step:19380 [D loss: 0.467666, acc.: 80.47%] [G loss: 1.507712]\n",
      "epoch:20 step:19381 [D loss: 0.500726, acc.: 80.47%] [G loss: 1.512055]\n",
      "epoch:20 step:19382 [D loss: 0.429335, acc.: 84.38%] [G loss: 1.700824]\n",
      "epoch:20 step:19383 [D loss: 0.615372, acc.: 61.72%] [G loss: 1.599691]\n",
      "epoch:20 step:19384 [D loss: 0.810429, acc.: 44.53%] [G loss: 0.980264]\n",
      "epoch:20 step:19385 [D loss: 0.514806, acc.: 76.56%] [G loss: 1.189900]\n",
      "epoch:20 step:19386 [D loss: 0.573784, acc.: 72.66%] [G loss: 1.008401]\n",
      "epoch:20 step:19387 [D loss: 0.480053, acc.: 83.59%] [G loss: 1.278422]\n",
      "epoch:20 step:19388 [D loss: 0.489454, acc.: 81.25%] [G loss: 1.085067]\n",
      "epoch:20 step:19389 [D loss: 0.467571, acc.: 85.94%] [G loss: 1.406684]\n",
      "epoch:20 step:19390 [D loss: 0.644840, acc.: 59.38%] [G loss: 1.196095]\n",
      "epoch:20 step:19391 [D loss: 0.618332, acc.: 64.06%] [G loss: 1.202099]\n",
      "epoch:20 step:19392 [D loss: 0.515993, acc.: 74.22%] [G loss: 1.401794]\n",
      "epoch:20 step:19393 [D loss: 0.375377, acc.: 87.50%] [G loss: 1.438938]\n",
      "epoch:20 step:19394 [D loss: 0.351788, acc.: 90.62%] [G loss: 1.769935]\n",
      "epoch:20 step:19395 [D loss: 0.561884, acc.: 71.09%] [G loss: 1.582732]\n",
      "epoch:20 step:19396 [D loss: 0.428883, acc.: 87.50%] [G loss: 1.231802]\n",
      "epoch:20 step:19397 [D loss: 0.599213, acc.: 71.88%] [G loss: 1.513882]\n",
      "epoch:20 step:19398 [D loss: 0.465006, acc.: 78.12%] [G loss: 1.238025]\n",
      "epoch:20 step:19399 [D loss: 0.531758, acc.: 71.88%] [G loss: 1.138253]\n",
      "epoch:20 step:19400 [D loss: 0.550964, acc.: 71.09%] [G loss: 1.198331]\n",
      "epoch:20 step:19401 [D loss: 0.492755, acc.: 80.47%] [G loss: 1.126771]\n",
      "epoch:20 step:19402 [D loss: 0.450322, acc.: 80.47%] [G loss: 1.272692]\n",
      "epoch:20 step:19403 [D loss: 0.342358, acc.: 84.38%] [G loss: 1.136687]\n",
      "epoch:20 step:19404 [D loss: 0.362080, acc.: 83.59%] [G loss: 1.437063]\n",
      "epoch:20 step:19405 [D loss: 0.235874, acc.: 96.88%] [G loss: 1.895566]\n",
      "epoch:20 step:19406 [D loss: 0.533762, acc.: 71.09%] [G loss: 1.798060]\n",
      "epoch:20 step:19407 [D loss: 0.473989, acc.: 81.25%] [G loss: 1.534364]\n",
      "epoch:20 step:19408 [D loss: 0.767185, acc.: 52.34%] [G loss: 1.271675]\n",
      "epoch:20 step:19409 [D loss: 0.545870, acc.: 67.97%] [G loss: 0.989743]\n",
      "epoch:20 step:19410 [D loss: 0.641443, acc.: 61.72%] [G loss: 1.133424]\n",
      "epoch:20 step:19411 [D loss: 0.530704, acc.: 73.44%] [G loss: 1.048004]\n",
      "epoch:20 step:19412 [D loss: 0.785171, acc.: 52.34%] [G loss: 0.866902]\n",
      "epoch:20 step:19413 [D loss: 0.956565, acc.: 30.47%] [G loss: 0.860832]\n",
      "epoch:20 step:19414 [D loss: 1.026561, acc.: 35.16%] [G loss: 0.788791]\n",
      "epoch:20 step:19415 [D loss: 0.825367, acc.: 41.41%] [G loss: 0.866484]\n",
      "epoch:20 step:19416 [D loss: 0.648882, acc.: 67.19%] [G loss: 1.093637]\n",
      "epoch:20 step:19417 [D loss: 0.718453, acc.: 51.56%] [G loss: 1.261475]\n",
      "epoch:20 step:19418 [D loss: 0.712589, acc.: 54.69%] [G loss: 1.006658]\n",
      "epoch:20 step:19419 [D loss: 0.690620, acc.: 60.16%] [G loss: 0.952106]\n",
      "epoch:20 step:19420 [D loss: 0.722957, acc.: 54.69%] [G loss: 1.052240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19421 [D loss: 0.655053, acc.: 60.16%] [G loss: 0.867291]\n",
      "epoch:20 step:19422 [D loss: 0.671288, acc.: 56.25%] [G loss: 1.057737]\n",
      "epoch:20 step:19423 [D loss: 0.613263, acc.: 66.41%] [G loss: 1.201359]\n",
      "epoch:20 step:19424 [D loss: 0.745066, acc.: 51.56%] [G loss: 0.911737]\n",
      "epoch:20 step:19425 [D loss: 0.625007, acc.: 63.28%] [G loss: 1.068682]\n",
      "epoch:20 step:19426 [D loss: 0.565404, acc.: 69.53%] [G loss: 1.282459]\n",
      "epoch:20 step:19427 [D loss: 0.540377, acc.: 75.00%] [G loss: 1.034683]\n",
      "epoch:20 step:19428 [D loss: 0.511905, acc.: 81.25%] [G loss: 1.058219]\n",
      "epoch:20 step:19429 [D loss: 0.601303, acc.: 71.09%] [G loss: 1.235999]\n",
      "epoch:20 step:19430 [D loss: 0.540982, acc.: 70.31%] [G loss: 1.180100]\n",
      "epoch:20 step:19431 [D loss: 0.483974, acc.: 81.25%] [G loss: 1.342966]\n",
      "epoch:20 step:19432 [D loss: 0.557695, acc.: 71.88%] [G loss: 1.375899]\n",
      "epoch:20 step:19433 [D loss: 0.552972, acc.: 72.66%] [G loss: 1.159004]\n",
      "epoch:20 step:19434 [D loss: 0.338935, acc.: 96.09%] [G loss: 1.632106]\n",
      "epoch:20 step:19435 [D loss: 0.533534, acc.: 73.44%] [G loss: 1.158742]\n",
      "epoch:20 step:19436 [D loss: 0.719067, acc.: 54.69%] [G loss: 1.024411]\n",
      "epoch:20 step:19437 [D loss: 0.671138, acc.: 55.47%] [G loss: 1.232605]\n",
      "epoch:20 step:19438 [D loss: 0.754583, acc.: 53.12%] [G loss: 0.963198]\n",
      "epoch:20 step:19439 [D loss: 0.749174, acc.: 50.78%] [G loss: 1.130121]\n",
      "epoch:20 step:19440 [D loss: 0.606030, acc.: 70.31%] [G loss: 1.247486]\n",
      "epoch:20 step:19441 [D loss: 0.571971, acc.: 66.41%] [G loss: 1.058996]\n",
      "epoch:20 step:19442 [D loss: 0.731376, acc.: 58.59%] [G loss: 1.046113]\n",
      "epoch:20 step:19443 [D loss: 0.766681, acc.: 45.31%] [G loss: 0.971425]\n",
      "epoch:20 step:19444 [D loss: 0.793275, acc.: 44.53%] [G loss: 1.045954]\n",
      "epoch:20 step:19445 [D loss: 0.681001, acc.: 60.16%] [G loss: 0.957124]\n",
      "epoch:20 step:19446 [D loss: 0.529133, acc.: 75.00%] [G loss: 1.055292]\n",
      "epoch:20 step:19447 [D loss: 0.487457, acc.: 79.69%] [G loss: 1.235165]\n",
      "epoch:20 step:19448 [D loss: 0.464944, acc.: 84.38%] [G loss: 1.435258]\n",
      "epoch:20 step:19449 [D loss: 0.395316, acc.: 89.06%] [G loss: 1.197695]\n",
      "epoch:20 step:19450 [D loss: 0.774865, acc.: 45.31%] [G loss: 1.028161]\n",
      "epoch:20 step:19451 [D loss: 0.614754, acc.: 67.19%] [G loss: 1.371317]\n",
      "epoch:20 step:19452 [D loss: 0.557879, acc.: 75.00%] [G loss: 1.030642]\n",
      "epoch:20 step:19453 [D loss: 0.445075, acc.: 82.81%] [G loss: 1.356713]\n",
      "epoch:20 step:19454 [D loss: 0.696831, acc.: 60.16%] [G loss: 0.996545]\n",
      "epoch:20 step:19455 [D loss: 0.491880, acc.: 78.12%] [G loss: 1.311012]\n",
      "epoch:20 step:19456 [D loss: 0.922394, acc.: 35.94%] [G loss: 1.153241]\n",
      "epoch:20 step:19457 [D loss: 0.853601, acc.: 38.28%] [G loss: 1.036655]\n",
      "epoch:20 step:19458 [D loss: 0.916144, acc.: 27.34%] [G loss: 1.017183]\n",
      "epoch:20 step:19459 [D loss: 0.711801, acc.: 53.12%] [G loss: 1.042184]\n",
      "epoch:20 step:19460 [D loss: 0.613695, acc.: 68.75%] [G loss: 0.953918]\n",
      "epoch:20 step:19461 [D loss: 0.633388, acc.: 63.28%] [G loss: 1.226697]\n",
      "epoch:20 step:19462 [D loss: 0.780179, acc.: 49.22%] [G loss: 0.885490]\n",
      "epoch:20 step:19463 [D loss: 0.577846, acc.: 67.19%] [G loss: 1.104773]\n",
      "epoch:20 step:19464 [D loss: 0.628931, acc.: 62.50%] [G loss: 1.173644]\n",
      "epoch:20 step:19465 [D loss: 0.476912, acc.: 85.16%] [G loss: 1.319850]\n",
      "epoch:20 step:19466 [D loss: 0.560376, acc.: 71.09%] [G loss: 1.090617]\n",
      "epoch:20 step:19467 [D loss: 0.678746, acc.: 60.94%] [G loss: 1.129182]\n",
      "epoch:20 step:19468 [D loss: 0.543118, acc.: 78.12%] [G loss: 1.357599]\n",
      "epoch:20 step:19469 [D loss: 0.511285, acc.: 75.00%] [G loss: 1.170013]\n",
      "epoch:20 step:19470 [D loss: 0.670136, acc.: 58.59%] [G loss: 0.993427]\n",
      "epoch:20 step:19471 [D loss: 0.482230, acc.: 78.12%] [G loss: 1.192727]\n",
      "epoch:20 step:19472 [D loss: 0.414350, acc.: 91.41%] [G loss: 1.412224]\n",
      "epoch:20 step:19473 [D loss: 0.449559, acc.: 84.38%] [G loss: 1.378822]\n",
      "epoch:20 step:19474 [D loss: 0.655505, acc.: 63.28%] [G loss: 1.171841]\n",
      "epoch:20 step:19475 [D loss: 0.702714, acc.: 52.34%] [G loss: 0.951360]\n",
      "epoch:20 step:19476 [D loss: 0.816835, acc.: 54.69%] [G loss: 0.821761]\n",
      "epoch:20 step:19477 [D loss: 0.672453, acc.: 58.59%] [G loss: 1.307624]\n",
      "epoch:20 step:19478 [D loss: 0.559318, acc.: 71.88%] [G loss: 0.900942]\n",
      "epoch:20 step:19479 [D loss: 0.682892, acc.: 55.47%] [G loss: 0.920168]\n",
      "epoch:20 step:19480 [D loss: 0.546416, acc.: 72.66%] [G loss: 1.030727]\n",
      "epoch:20 step:19481 [D loss: 0.528024, acc.: 74.22%] [G loss: 1.073674]\n",
      "epoch:20 step:19482 [D loss: 0.612307, acc.: 65.62%] [G loss: 1.014300]\n",
      "epoch:20 step:19483 [D loss: 0.443809, acc.: 82.81%] [G loss: 1.151949]\n",
      "epoch:20 step:19484 [D loss: 0.797931, acc.: 47.66%] [G loss: 1.001138]\n",
      "epoch:20 step:19485 [D loss: 0.445858, acc.: 85.16%] [G loss: 1.004486]\n",
      "epoch:20 step:19486 [D loss: 0.614740, acc.: 68.75%] [G loss: 1.363835]\n",
      "epoch:20 step:19487 [D loss: 0.676120, acc.: 59.38%] [G loss: 1.122491]\n",
      "epoch:20 step:19488 [D loss: 0.543941, acc.: 77.34%] [G loss: 1.216067]\n",
      "epoch:20 step:19489 [D loss: 0.518056, acc.: 79.69%] [G loss: 1.135666]\n",
      "epoch:20 step:19490 [D loss: 0.523795, acc.: 74.22%] [G loss: 1.041322]\n",
      "epoch:20 step:19491 [D loss: 0.540356, acc.: 72.66%] [G loss: 1.227371]\n",
      "epoch:20 step:19492 [D loss: 0.773584, acc.: 47.66%] [G loss: 0.914653]\n",
      "epoch:20 step:19493 [D loss: 0.665270, acc.: 61.72%] [G loss: 0.953350]\n",
      "epoch:20 step:19494 [D loss: 0.618513, acc.: 68.75%] [G loss: 0.778883]\n",
      "epoch:20 step:19495 [D loss: 0.610489, acc.: 71.09%] [G loss: 1.108974]\n",
      "epoch:20 step:19496 [D loss: 0.746256, acc.: 49.22%] [G loss: 0.895059]\n",
      "epoch:20 step:19497 [D loss: 0.567787, acc.: 73.44%] [G loss: 1.049737]\n",
      "epoch:20 step:19498 [D loss: 0.669997, acc.: 59.38%] [G loss: 0.965262]\n",
      "epoch:20 step:19499 [D loss: 0.972526, acc.: 32.03%] [G loss: 0.808002]\n",
      "epoch:20 step:19500 [D loss: 0.741278, acc.: 50.78%] [G loss: 1.295136]\n",
      "epoch:20 step:19501 [D loss: 0.696285, acc.: 55.47%] [G loss: 1.151991]\n",
      "epoch:20 step:19502 [D loss: 0.765696, acc.: 50.00%] [G loss: 1.155499]\n",
      "epoch:20 step:19503 [D loss: 0.647090, acc.: 66.41%] [G loss: 0.977894]\n",
      "epoch:20 step:19504 [D loss: 0.640396, acc.: 61.72%] [G loss: 0.790576]\n",
      "epoch:20 step:19505 [D loss: 0.651662, acc.: 60.94%] [G loss: 1.048112]\n",
      "epoch:20 step:19506 [D loss: 0.610478, acc.: 66.41%] [G loss: 1.026205]\n",
      "epoch:20 step:19507 [D loss: 0.511046, acc.: 75.00%] [G loss: 1.310437]\n",
      "epoch:20 step:19508 [D loss: 0.456715, acc.: 81.25%] [G loss: 1.349445]\n",
      "epoch:20 step:19509 [D loss: 0.322352, acc.: 91.41%] [G loss: 1.275820]\n",
      "epoch:20 step:19510 [D loss: 0.511498, acc.: 78.91%] [G loss: 1.324845]\n",
      "epoch:20 step:19511 [D loss: 0.803219, acc.: 49.22%] [G loss: 0.760067]\n",
      "epoch:20 step:19512 [D loss: 0.648731, acc.: 66.41%] [G loss: 1.172663]\n",
      "epoch:20 step:19513 [D loss: 0.667013, acc.: 60.94%] [G loss: 0.961146]\n",
      "epoch:20 step:19514 [D loss: 0.294927, acc.: 92.19%] [G loss: 1.215644]\n",
      "epoch:20 step:19515 [D loss: 0.359910, acc.: 84.38%] [G loss: 1.188529]\n",
      "epoch:20 step:19516 [D loss: 0.528998, acc.: 78.12%] [G loss: 1.354720]\n",
      "epoch:20 step:19517 [D loss: 0.510196, acc.: 77.34%] [G loss: 1.257709]\n",
      "epoch:20 step:19518 [D loss: 0.916818, acc.: 35.94%] [G loss: 0.800934]\n",
      "epoch:20 step:19519 [D loss: 0.871141, acc.: 39.06%] [G loss: 1.139025]\n",
      "epoch:20 step:19520 [D loss: 0.635251, acc.: 65.62%] [G loss: 1.129080]\n",
      "epoch:20 step:19521 [D loss: 0.483490, acc.: 75.00%] [G loss: 1.685124]\n",
      "epoch:20 step:19522 [D loss: 0.374722, acc.: 90.62%] [G loss: 1.630359]\n",
      "epoch:20 step:19523 [D loss: 0.807062, acc.: 50.78%] [G loss: 1.195628]\n",
      "epoch:20 step:19524 [D loss: 0.760657, acc.: 48.44%] [G loss: 1.109186]\n",
      "epoch:20 step:19525 [D loss: 0.607601, acc.: 66.41%] [G loss: 0.867368]\n",
      "epoch:20 step:19526 [D loss: 0.540175, acc.: 69.53%] [G loss: 1.123874]\n",
      "epoch:20 step:19527 [D loss: 0.836189, acc.: 42.97%] [G loss: 1.250095]\n",
      "epoch:20 step:19528 [D loss: 0.643772, acc.: 64.06%] [G loss: 1.062571]\n",
      "epoch:20 step:19529 [D loss: 0.712021, acc.: 52.34%] [G loss: 0.953147]\n",
      "epoch:20 step:19530 [D loss: 0.393917, acc.: 92.19%] [G loss: 1.248765]\n",
      "epoch:20 step:19531 [D loss: 0.396189, acc.: 82.81%] [G loss: 1.189640]\n",
      "epoch:20 step:19532 [D loss: 0.322808, acc.: 96.09%] [G loss: 1.450843]\n",
      "epoch:20 step:19533 [D loss: 0.476495, acc.: 81.25%] [G loss: 1.162087]\n",
      "epoch:20 step:19534 [D loss: 0.264574, acc.: 96.88%] [G loss: 1.544912]\n",
      "epoch:20 step:19535 [D loss: 0.344705, acc.: 89.06%] [G loss: 1.572906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19536 [D loss: 0.379508, acc.: 87.50%] [G loss: 1.354439]\n",
      "epoch:20 step:19537 [D loss: 0.609952, acc.: 67.97%] [G loss: 1.143148]\n",
      "epoch:20 step:19538 [D loss: 0.419037, acc.: 88.28%] [G loss: 1.395179]\n",
      "epoch:20 step:19539 [D loss: 0.675701, acc.: 64.06%] [G loss: 0.663062]\n",
      "epoch:20 step:19540 [D loss: 0.983960, acc.: 31.25%] [G loss: 1.059152]\n",
      "epoch:20 step:19541 [D loss: 0.999910, acc.: 25.00%] [G loss: 0.937420]\n",
      "epoch:20 step:19542 [D loss: 0.731390, acc.: 53.91%] [G loss: 1.246776]\n",
      "epoch:20 step:19543 [D loss: 0.833587, acc.: 39.84%] [G loss: 1.187752]\n",
      "epoch:20 step:19544 [D loss: 0.502893, acc.: 79.69%] [G loss: 1.319475]\n",
      "epoch:20 step:19545 [D loss: 0.473185, acc.: 81.25%] [G loss: 1.144069]\n",
      "epoch:20 step:19546 [D loss: 0.473171, acc.: 82.81%] [G loss: 1.271615]\n",
      "epoch:20 step:19547 [D loss: 0.717231, acc.: 56.25%] [G loss: 0.789399]\n",
      "epoch:20 step:19548 [D loss: 0.525782, acc.: 76.56%] [G loss: 1.118190]\n",
      "epoch:20 step:19549 [D loss: 0.408628, acc.: 89.84%] [G loss: 1.242586]\n",
      "epoch:20 step:19550 [D loss: 0.584571, acc.: 73.44%] [G loss: 1.064654]\n",
      "epoch:20 step:19551 [D loss: 0.694200, acc.: 54.69%] [G loss: 0.908198]\n",
      "epoch:20 step:19552 [D loss: 0.728829, acc.: 52.34%] [G loss: 0.926304]\n",
      "epoch:20 step:19553 [D loss: 0.613890, acc.: 67.97%] [G loss: 1.027411]\n",
      "epoch:20 step:19554 [D loss: 0.566181, acc.: 74.22%] [G loss: 0.995110]\n",
      "epoch:20 step:19555 [D loss: 0.265946, acc.: 92.97%] [G loss: 1.576165]\n",
      "epoch:20 step:19556 [D loss: 0.336371, acc.: 93.75%] [G loss: 1.651052]\n",
      "epoch:20 step:19557 [D loss: 0.474878, acc.: 80.47%] [G loss: 1.262750]\n",
      "epoch:20 step:19558 [D loss: 0.520368, acc.: 78.12%] [G loss: 1.129378]\n",
      "epoch:20 step:19559 [D loss: 0.631077, acc.: 62.50%] [G loss: 0.659243]\n",
      "epoch:20 step:19560 [D loss: 0.801266, acc.: 45.31%] [G loss: 1.085309]\n",
      "epoch:20 step:19561 [D loss: 0.595585, acc.: 67.97%] [G loss: 0.919017]\n",
      "epoch:20 step:19562 [D loss: 0.796993, acc.: 47.66%] [G loss: 0.765737]\n",
      "epoch:20 step:19563 [D loss: 0.704297, acc.: 57.81%] [G loss: 0.949955]\n",
      "epoch:20 step:19564 [D loss: 0.390678, acc.: 85.94%] [G loss: 1.529127]\n",
      "epoch:20 step:19565 [D loss: 0.597727, acc.: 74.22%] [G loss: 1.128901]\n",
      "epoch:20 step:19566 [D loss: 0.777806, acc.: 49.22%] [G loss: 0.763116]\n",
      "epoch:20 step:19567 [D loss: 0.755292, acc.: 48.44%] [G loss: 1.322920]\n",
      "epoch:20 step:19568 [D loss: 0.719020, acc.: 57.03%] [G loss: 1.068937]\n",
      "epoch:20 step:19569 [D loss: 0.887734, acc.: 42.97%] [G loss: 0.565938]\n",
      "epoch:20 step:19570 [D loss: 0.546851, acc.: 71.88%] [G loss: 1.208564]\n",
      "epoch:20 step:19571 [D loss: 0.397444, acc.: 87.50%] [G loss: 1.404825]\n",
      "epoch:20 step:19572 [D loss: 0.542972, acc.: 70.31%] [G loss: 1.268304]\n",
      "epoch:20 step:19573 [D loss: 0.536499, acc.: 73.44%] [G loss: 1.490673]\n",
      "epoch:20 step:19574 [D loss: 1.050527, acc.: 28.12%] [G loss: 1.057446]\n",
      "epoch:20 step:19575 [D loss: 0.858295, acc.: 42.97%] [G loss: 1.080316]\n",
      "epoch:20 step:19576 [D loss: 0.852487, acc.: 39.84%] [G loss: 0.965546]\n",
      "epoch:20 step:19577 [D loss: 0.756043, acc.: 46.88%] [G loss: 1.031190]\n",
      "epoch:20 step:19578 [D loss: 0.675575, acc.: 57.03%] [G loss: 1.234563]\n",
      "epoch:20 step:19579 [D loss: 0.772795, acc.: 46.88%] [G loss: 1.237671]\n",
      "epoch:20 step:19580 [D loss: 0.587195, acc.: 67.97%] [G loss: 1.010003]\n",
      "epoch:20 step:19581 [D loss: 0.404372, acc.: 89.84%] [G loss: 1.289537]\n",
      "epoch:20 step:19582 [D loss: 0.418668, acc.: 88.28%] [G loss: 1.286097]\n",
      "epoch:20 step:19583 [D loss: 0.653240, acc.: 62.50%] [G loss: 1.293087]\n",
      "epoch:20 step:19584 [D loss: 0.658082, acc.: 57.03%] [G loss: 0.972021]\n",
      "epoch:20 step:19585 [D loss: 0.600638, acc.: 71.09%] [G loss: 1.084323]\n",
      "epoch:20 step:19586 [D loss: 0.686559, acc.: 63.28%] [G loss: 0.991891]\n",
      "epoch:20 step:19587 [D loss: 0.586985, acc.: 69.53%] [G loss: 1.179897]\n",
      "epoch:20 step:19588 [D loss: 0.422931, acc.: 87.50%] [G loss: 1.247561]\n",
      "epoch:20 step:19589 [D loss: 0.360989, acc.: 89.06%] [G loss: 1.643869]\n",
      "epoch:20 step:19590 [D loss: 0.298728, acc.: 92.97%] [G loss: 1.496651]\n",
      "epoch:20 step:19591 [D loss: 0.317724, acc.: 94.53%] [G loss: 1.480801]\n",
      "epoch:20 step:19592 [D loss: 0.249422, acc.: 95.31%] [G loss: 1.768803]\n",
      "epoch:20 step:19593 [D loss: 0.284313, acc.: 96.88%] [G loss: 1.478937]\n",
      "epoch:20 step:19594 [D loss: 0.342628, acc.: 89.06%] [G loss: 1.697428]\n",
      "epoch:20 step:19595 [D loss: 0.490861, acc.: 77.34%] [G loss: 1.425763]\n",
      "epoch:20 step:19596 [D loss: 0.676960, acc.: 57.03%] [G loss: 1.204750]\n",
      "epoch:20 step:19597 [D loss: 0.295304, acc.: 94.53%] [G loss: 1.486467]\n",
      "epoch:20 step:19598 [D loss: 0.893301, acc.: 50.00%] [G loss: 1.290787]\n",
      "epoch:20 step:19599 [D loss: 0.760448, acc.: 43.75%] [G loss: 1.129209]\n",
      "epoch:20 step:19600 [D loss: 0.662777, acc.: 56.25%] [G loss: 1.143127]\n",
      "epoch:20 step:19601 [D loss: 0.605823, acc.: 68.75%] [G loss: 0.990954]\n",
      "epoch:20 step:19602 [D loss: 0.797640, acc.: 44.53%] [G loss: 1.104220]\n",
      "epoch:20 step:19603 [D loss: 0.686796, acc.: 58.59%] [G loss: 1.213548]\n",
      "epoch:20 step:19604 [D loss: 0.764545, acc.: 49.22%] [G loss: 1.101889]\n",
      "epoch:20 step:19605 [D loss: 0.570864, acc.: 70.31%] [G loss: 1.185534]\n",
      "epoch:20 step:19606 [D loss: 0.672631, acc.: 60.94%] [G loss: 0.884662]\n",
      "epoch:20 step:19607 [D loss: 0.689600, acc.: 62.50%] [G loss: 0.839126]\n",
      "epoch:20 step:19608 [D loss: 0.645714, acc.: 58.59%] [G loss: 0.847065]\n",
      "epoch:20 step:19609 [D loss: 0.561371, acc.: 71.09%] [G loss: 1.058370]\n",
      "epoch:20 step:19610 [D loss: 0.749718, acc.: 52.34%] [G loss: 0.881679]\n",
      "epoch:20 step:19611 [D loss: 0.575147, acc.: 64.84%] [G loss: 1.098302]\n",
      "epoch:20 step:19612 [D loss: 0.574870, acc.: 67.97%] [G loss: 1.055918]\n",
      "epoch:20 step:19613 [D loss: 0.654815, acc.: 59.38%] [G loss: 0.955470]\n",
      "epoch:20 step:19614 [D loss: 0.680844, acc.: 59.38%] [G loss: 0.901091]\n",
      "epoch:20 step:19615 [D loss: 0.555310, acc.: 76.56%] [G loss: 0.898650]\n",
      "epoch:20 step:19616 [D loss: 0.781673, acc.: 50.00%] [G loss: 0.874522]\n",
      "epoch:20 step:19617 [D loss: 0.880583, acc.: 39.84%] [G loss: 0.850277]\n",
      "epoch:20 step:19618 [D loss: 0.681240, acc.: 56.25%] [G loss: 1.182832]\n",
      "epoch:20 step:19619 [D loss: 0.642732, acc.: 63.28%] [G loss: 1.241490]\n",
      "epoch:20 step:19620 [D loss: 0.694414, acc.: 57.81%] [G loss: 0.973508]\n",
      "epoch:20 step:19621 [D loss: 0.599055, acc.: 67.19%] [G loss: 1.291196]\n",
      "epoch:20 step:19622 [D loss: 0.700974, acc.: 57.81%] [G loss: 0.995967]\n",
      "epoch:20 step:19623 [D loss: 0.581058, acc.: 65.62%] [G loss: 0.910530]\n",
      "epoch:20 step:19624 [D loss: 0.385118, acc.: 91.41%] [G loss: 1.047861]\n",
      "epoch:20 step:19625 [D loss: 0.411137, acc.: 88.28%] [G loss: 1.045257]\n",
      "epoch:20 step:19626 [D loss: 0.675379, acc.: 54.69%] [G loss: 1.095143]\n",
      "epoch:20 step:19627 [D loss: 0.486355, acc.: 80.47%] [G loss: 1.088481]\n",
      "epoch:20 step:19628 [D loss: 0.621938, acc.: 63.28%] [G loss: 1.085969]\n",
      "epoch:20 step:19629 [D loss: 0.625411, acc.: 63.28%] [G loss: 1.127736]\n",
      "epoch:20 step:19630 [D loss: 0.478366, acc.: 80.47%] [G loss: 1.244935]\n",
      "epoch:20 step:19631 [D loss: 0.788257, acc.: 47.66%] [G loss: 1.333513]\n",
      "epoch:20 step:19632 [D loss: 0.563844, acc.: 75.00%] [G loss: 1.278347]\n",
      "epoch:20 step:19633 [D loss: 0.468358, acc.: 85.94%] [G loss: 1.356205]\n",
      "epoch:20 step:19634 [D loss: 0.365799, acc.: 90.62%] [G loss: 1.407025]\n",
      "epoch:20 step:19635 [D loss: 0.352608, acc.: 92.97%] [G loss: 1.508114]\n",
      "epoch:20 step:19636 [D loss: 0.323185, acc.: 92.19%] [G loss: 1.222904]\n",
      "epoch:20 step:19637 [D loss: 0.255703, acc.: 96.88%] [G loss: 1.670283]\n",
      "epoch:20 step:19638 [D loss: 0.293378, acc.: 93.75%] [G loss: 1.461853]\n",
      "epoch:20 step:19639 [D loss: 0.262156, acc.: 95.31%] [G loss: 1.706494]\n",
      "epoch:20 step:19640 [D loss: 0.205096, acc.: 100.00%] [G loss: 1.836350]\n",
      "epoch:20 step:19641 [D loss: 0.275430, acc.: 96.09%] [G loss: 1.670469]\n",
      "epoch:20 step:19642 [D loss: 0.495504, acc.: 78.12%] [G loss: 1.620733]\n",
      "epoch:20 step:19643 [D loss: 0.575841, acc.: 70.31%] [G loss: 0.986291]\n",
      "epoch:20 step:19644 [D loss: 0.851829, acc.: 38.28%] [G loss: 1.081047]\n",
      "epoch:20 step:19645 [D loss: 0.655470, acc.: 62.50%] [G loss: 1.027810]\n",
      "epoch:20 step:19646 [D loss: 0.745496, acc.: 49.22%] [G loss: 0.995172]\n",
      "epoch:20 step:19647 [D loss: 0.758437, acc.: 48.44%] [G loss: 0.956875]\n",
      "epoch:20 step:19648 [D loss: 0.545925, acc.: 71.09%] [G loss: 1.205531]\n",
      "epoch:20 step:19649 [D loss: 0.322491, acc.: 91.41%] [G loss: 1.157642]\n",
      "epoch:20 step:19650 [D loss: 0.642874, acc.: 64.06%] [G loss: 1.362274]\n",
      "epoch:20 step:19651 [D loss: 0.344780, acc.: 87.50%] [G loss: 1.500204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19652 [D loss: 0.177510, acc.: 97.66%] [G loss: 1.495813]\n",
      "epoch:20 step:19653 [D loss: 0.878428, acc.: 45.31%] [G loss: 0.896260]\n",
      "epoch:20 step:19654 [D loss: 0.835463, acc.: 38.28%] [G loss: 0.927390]\n",
      "epoch:20 step:19655 [D loss: 0.686577, acc.: 54.69%] [G loss: 0.891363]\n",
      "epoch:20 step:19656 [D loss: 0.991276, acc.: 32.03%] [G loss: 0.839438]\n",
      "epoch:20 step:19657 [D loss: 0.931334, acc.: 41.41%] [G loss: 1.197784]\n",
      "epoch:20 step:19658 [D loss: 0.739202, acc.: 57.03%] [G loss: 0.926106]\n",
      "epoch:20 step:19659 [D loss: 0.454361, acc.: 77.34%] [G loss: 1.242251]\n",
      "epoch:20 step:19660 [D loss: 0.632047, acc.: 59.38%] [G loss: 1.502631]\n",
      "epoch:20 step:19661 [D loss: 0.811937, acc.: 42.19%] [G loss: 0.854373]\n",
      "epoch:20 step:19662 [D loss: 0.529638, acc.: 78.12%] [G loss: 1.413409]\n",
      "epoch:20 step:19663 [D loss: 0.738416, acc.: 45.31%] [G loss: 0.934507]\n",
      "epoch:20 step:19664 [D loss: 0.431681, acc.: 82.03%] [G loss: 1.281561]\n",
      "epoch:20 step:19665 [D loss: 0.422003, acc.: 88.28%] [G loss: 1.283517]\n",
      "epoch:20 step:19666 [D loss: 0.560302, acc.: 69.53%] [G loss: 1.311224]\n",
      "epoch:20 step:19667 [D loss: 0.392475, acc.: 85.94%] [G loss: 1.600506]\n",
      "epoch:20 step:19668 [D loss: 0.975740, acc.: 37.50%] [G loss: 1.269824]\n",
      "epoch:20 step:19669 [D loss: 0.389816, acc.: 89.06%] [G loss: 1.194872]\n",
      "epoch:20 step:19670 [D loss: 0.504328, acc.: 76.56%] [G loss: 1.261183]\n",
      "epoch:20 step:19671 [D loss: 0.645373, acc.: 62.50%] [G loss: 0.950895]\n",
      "epoch:20 step:19672 [D loss: 0.624470, acc.: 64.84%] [G loss: 1.153600]\n",
      "epoch:20 step:19673 [D loss: 0.518662, acc.: 77.34%] [G loss: 1.039731]\n",
      "epoch:20 step:19674 [D loss: 0.481860, acc.: 77.34%] [G loss: 1.121419]\n",
      "epoch:20 step:19675 [D loss: 0.622876, acc.: 66.41%] [G loss: 1.242769]\n",
      "epoch:20 step:19676 [D loss: 0.442885, acc.: 85.16%] [G loss: 1.154263]\n",
      "epoch:20 step:19677 [D loss: 0.290428, acc.: 88.28%] [G loss: 1.503959]\n",
      "epoch:21 step:19678 [D loss: 0.759061, acc.: 50.78%] [G loss: 1.069606]\n",
      "epoch:21 step:19679 [D loss: 0.743919, acc.: 53.91%] [G loss: 1.260932]\n",
      "epoch:21 step:19680 [D loss: 0.773608, acc.: 50.00%] [G loss: 1.170729]\n",
      "epoch:21 step:19681 [D loss: 0.656645, acc.: 62.50%] [G loss: 0.931688]\n",
      "epoch:21 step:19682 [D loss: 0.591388, acc.: 69.53%] [G loss: 1.206124]\n",
      "epoch:21 step:19683 [D loss: 0.514819, acc.: 78.12%] [G loss: 1.397912]\n",
      "epoch:21 step:19684 [D loss: 0.513982, acc.: 81.25%] [G loss: 1.316432]\n",
      "epoch:21 step:19685 [D loss: 0.641798, acc.: 62.50%] [G loss: 1.002859]\n",
      "epoch:21 step:19686 [D loss: 0.702522, acc.: 53.12%] [G loss: 0.879750]\n",
      "epoch:21 step:19687 [D loss: 0.528260, acc.: 75.78%] [G loss: 1.254391]\n",
      "epoch:21 step:19688 [D loss: 0.645520, acc.: 64.06%] [G loss: 1.197333]\n",
      "epoch:21 step:19689 [D loss: 0.756651, acc.: 50.78%] [G loss: 0.965356]\n",
      "epoch:21 step:19690 [D loss: 0.645807, acc.: 62.50%] [G loss: 1.056998]\n",
      "epoch:21 step:19691 [D loss: 0.478038, acc.: 82.81%] [G loss: 0.996612]\n",
      "epoch:21 step:19692 [D loss: 0.581131, acc.: 64.06%] [G loss: 0.873199]\n",
      "epoch:21 step:19693 [D loss: 0.502888, acc.: 78.12%] [G loss: 1.341973]\n",
      "epoch:21 step:19694 [D loss: 0.708606, acc.: 54.69%] [G loss: 1.190052]\n",
      "epoch:21 step:19695 [D loss: 0.788079, acc.: 50.00%] [G loss: 1.052058]\n",
      "epoch:21 step:19696 [D loss: 0.880162, acc.: 39.06%] [G loss: 0.848879]\n",
      "epoch:21 step:19697 [D loss: 0.608458, acc.: 62.50%] [G loss: 1.050647]\n",
      "epoch:21 step:19698 [D loss: 0.600853, acc.: 71.09%] [G loss: 1.180425]\n",
      "epoch:21 step:19699 [D loss: 0.559687, acc.: 71.88%] [G loss: 0.943098]\n",
      "epoch:21 step:19700 [D loss: 0.749985, acc.: 47.66%] [G loss: 1.077784]\n",
      "epoch:21 step:19701 [D loss: 0.637518, acc.: 62.50%] [G loss: 1.103758]\n",
      "epoch:21 step:19702 [D loss: 0.770810, acc.: 46.88%] [G loss: 1.063223]\n",
      "epoch:21 step:19703 [D loss: 0.395032, acc.: 87.50%] [G loss: 1.157088]\n",
      "epoch:21 step:19704 [D loss: 0.363735, acc.: 90.62%] [G loss: 1.230534]\n",
      "epoch:21 step:19705 [D loss: 0.344288, acc.: 90.62%] [G loss: 1.563411]\n",
      "epoch:21 step:19706 [D loss: 0.390502, acc.: 89.84%] [G loss: 1.331089]\n",
      "epoch:21 step:19707 [D loss: 0.375425, acc.: 89.84%] [G loss: 1.477771]\n",
      "epoch:21 step:19708 [D loss: 0.312417, acc.: 90.62%] [G loss: 1.494178]\n",
      "epoch:21 step:19709 [D loss: 0.317065, acc.: 92.19%] [G loss: 1.644388]\n",
      "epoch:21 step:19710 [D loss: 0.380454, acc.: 87.50%] [G loss: 1.542302]\n",
      "epoch:21 step:19711 [D loss: 0.275910, acc.: 96.88%] [G loss: 1.943228]\n",
      "epoch:21 step:19712 [D loss: 0.330296, acc.: 92.19%] [G loss: 1.365897]\n",
      "epoch:21 step:19713 [D loss: 0.164178, acc.: 99.22%] [G loss: 1.670085]\n",
      "epoch:21 step:19714 [D loss: 1.154329, acc.: 31.25%] [G loss: 0.936745]\n",
      "epoch:21 step:19715 [D loss: 1.067434, acc.: 30.47%] [G loss: 1.024639]\n",
      "epoch:21 step:19716 [D loss: 0.823073, acc.: 43.75%] [G loss: 1.078069]\n",
      "epoch:21 step:19717 [D loss: 0.555329, acc.: 77.34%] [G loss: 1.134333]\n",
      "epoch:21 step:19718 [D loss: 0.639941, acc.: 67.97%] [G loss: 1.203766]\n",
      "epoch:21 step:19719 [D loss: 0.535073, acc.: 77.34%] [G loss: 0.965338]\n",
      "epoch:21 step:19720 [D loss: 0.579377, acc.: 67.97%] [G loss: 1.065266]\n",
      "epoch:21 step:19721 [D loss: 0.530112, acc.: 73.44%] [G loss: 1.347679]\n",
      "epoch:21 step:19722 [D loss: 0.641295, acc.: 67.19%] [G loss: 1.068196]\n",
      "epoch:21 step:19723 [D loss: 0.757291, acc.: 54.69%] [G loss: 0.717177]\n",
      "epoch:21 step:19724 [D loss: 0.643829, acc.: 58.59%] [G loss: 1.012816]\n",
      "epoch:21 step:19725 [D loss: 0.618196, acc.: 62.50%] [G loss: 1.020953]\n",
      "epoch:21 step:19726 [D loss: 0.662462, acc.: 58.59%] [G loss: 1.011363]\n",
      "epoch:21 step:19727 [D loss: 0.474505, acc.: 86.72%] [G loss: 1.000277]\n",
      "epoch:21 step:19728 [D loss: 0.684638, acc.: 54.69%] [G loss: 0.980677]\n",
      "epoch:21 step:19729 [D loss: 0.790296, acc.: 42.97%] [G loss: 0.700947]\n",
      "epoch:21 step:19730 [D loss: 0.716791, acc.: 53.91%] [G loss: 1.005021]\n",
      "epoch:21 step:19731 [D loss: 0.658325, acc.: 60.94%] [G loss: 1.007794]\n",
      "epoch:21 step:19732 [D loss: 0.556512, acc.: 74.22%] [G loss: 0.966299]\n",
      "epoch:21 step:19733 [D loss: 0.666360, acc.: 63.28%] [G loss: 1.036209]\n",
      "epoch:21 step:19734 [D loss: 0.684697, acc.: 57.81%] [G loss: 1.267394]\n",
      "epoch:21 step:19735 [D loss: 0.791049, acc.: 46.09%] [G loss: 1.144704]\n",
      "epoch:21 step:19736 [D loss: 0.643521, acc.: 61.72%] [G loss: 0.999463]\n",
      "epoch:21 step:19737 [D loss: 0.681691, acc.: 63.28%] [G loss: 1.079705]\n",
      "epoch:21 step:19738 [D loss: 0.549803, acc.: 72.66%] [G loss: 1.069497]\n",
      "epoch:21 step:19739 [D loss: 0.724206, acc.: 54.69%] [G loss: 0.833555]\n",
      "epoch:21 step:19740 [D loss: 0.681391, acc.: 57.03%] [G loss: 0.999941]\n",
      "epoch:21 step:19741 [D loss: 0.491584, acc.: 79.69%] [G loss: 1.138442]\n",
      "epoch:21 step:19742 [D loss: 0.582713, acc.: 73.44%] [G loss: 1.201224]\n",
      "epoch:21 step:19743 [D loss: 0.517271, acc.: 78.12%] [G loss: 0.987517]\n",
      "epoch:21 step:19744 [D loss: 0.670667, acc.: 64.06%] [G loss: 0.926962]\n",
      "epoch:21 step:19745 [D loss: 0.562602, acc.: 71.88%] [G loss: 1.175191]\n",
      "epoch:21 step:19746 [D loss: 0.394917, acc.: 87.50%] [G loss: 1.349459]\n",
      "epoch:21 step:19747 [D loss: 0.632891, acc.: 64.84%] [G loss: 1.236628]\n",
      "epoch:21 step:19748 [D loss: 0.787038, acc.: 45.31%] [G loss: 1.242060]\n",
      "epoch:21 step:19749 [D loss: 0.612516, acc.: 67.97%] [G loss: 1.295670]\n",
      "epoch:21 step:19750 [D loss: 0.740550, acc.: 51.56%] [G loss: 1.051576]\n",
      "epoch:21 step:19751 [D loss: 0.551188, acc.: 75.78%] [G loss: 1.167078]\n",
      "epoch:21 step:19752 [D loss: 0.416511, acc.: 87.50%] [G loss: 1.077772]\n",
      "epoch:21 step:19753 [D loss: 0.508535, acc.: 78.91%] [G loss: 1.207587]\n",
      "epoch:21 step:19754 [D loss: 0.489168, acc.: 78.91%] [G loss: 1.272248]\n",
      "epoch:21 step:19755 [D loss: 0.725899, acc.: 56.25%] [G loss: 1.296005]\n",
      "epoch:21 step:19756 [D loss: 0.870867, acc.: 42.19%] [G loss: 1.274492]\n",
      "epoch:21 step:19757 [D loss: 0.573628, acc.: 71.88%] [G loss: 1.301363]\n",
      "epoch:21 step:19758 [D loss: 0.689066, acc.: 57.03%] [G loss: 1.105943]\n",
      "epoch:21 step:19759 [D loss: 0.633241, acc.: 64.06%] [G loss: 0.967659]\n",
      "epoch:21 step:19760 [D loss: 0.489731, acc.: 82.03%] [G loss: 0.966304]\n",
      "epoch:21 step:19761 [D loss: 0.642255, acc.: 61.72%] [G loss: 1.080559]\n",
      "epoch:21 step:19762 [D loss: 0.657752, acc.: 60.94%] [G loss: 0.917045]\n",
      "epoch:21 step:19763 [D loss: 0.692104, acc.: 55.47%] [G loss: 0.932422]\n",
      "epoch:21 step:19764 [D loss: 0.524836, acc.: 71.09%] [G loss: 1.119967]\n",
      "epoch:21 step:19765 [D loss: 0.525865, acc.: 77.34%] [G loss: 1.116714]\n",
      "epoch:21 step:19766 [D loss: 0.665251, acc.: 60.94%] [G loss: 1.132658]\n",
      "epoch:21 step:19767 [D loss: 0.675640, acc.: 59.38%] [G loss: 1.135026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19768 [D loss: 0.912666, acc.: 34.38%] [G loss: 0.694699]\n",
      "epoch:21 step:19769 [D loss: 0.668570, acc.: 58.59%] [G loss: 0.967589]\n",
      "epoch:21 step:19770 [D loss: 0.538083, acc.: 71.88%] [G loss: 1.437017]\n",
      "epoch:21 step:19771 [D loss: 0.614076, acc.: 62.50%] [G loss: 1.277303]\n",
      "epoch:21 step:19772 [D loss: 0.693641, acc.: 58.59%] [G loss: 1.121204]\n",
      "epoch:21 step:19773 [D loss: 0.713092, acc.: 53.12%] [G loss: 1.086171]\n",
      "epoch:21 step:19774 [D loss: 0.586986, acc.: 69.53%] [G loss: 1.067371]\n",
      "epoch:21 step:19775 [D loss: 0.627788, acc.: 64.06%] [G loss: 0.966454]\n",
      "epoch:21 step:19776 [D loss: 0.702685, acc.: 54.69%] [G loss: 0.981624]\n",
      "epoch:21 step:19777 [D loss: 0.551538, acc.: 71.09%] [G loss: 1.083385]\n",
      "epoch:21 step:19778 [D loss: 0.571321, acc.: 70.31%] [G loss: 0.950833]\n",
      "epoch:21 step:19779 [D loss: 0.518953, acc.: 73.44%] [G loss: 1.047977]\n",
      "epoch:21 step:19780 [D loss: 0.428782, acc.: 83.59%] [G loss: 1.230745]\n",
      "epoch:21 step:19781 [D loss: 0.474523, acc.: 86.72%] [G loss: 1.085825]\n",
      "epoch:21 step:19782 [D loss: 0.466670, acc.: 78.12%] [G loss: 1.094496]\n",
      "epoch:21 step:19783 [D loss: 0.380713, acc.: 90.62%] [G loss: 1.533287]\n",
      "epoch:21 step:19784 [D loss: 0.754081, acc.: 50.00%] [G loss: 1.079010]\n",
      "epoch:21 step:19785 [D loss: 0.628444, acc.: 67.19%] [G loss: 1.203535]\n",
      "epoch:21 step:19786 [D loss: 0.493702, acc.: 78.12%] [G loss: 1.273283]\n",
      "epoch:21 step:19787 [D loss: 0.467140, acc.: 82.81%] [G loss: 1.422392]\n",
      "epoch:21 step:19788 [D loss: 0.608490, acc.: 71.88%] [G loss: 0.958389]\n",
      "epoch:21 step:19789 [D loss: 0.554417, acc.: 72.66%] [G loss: 1.238780]\n",
      "epoch:21 step:19790 [D loss: 0.912550, acc.: 38.28%] [G loss: 0.824191]\n",
      "epoch:21 step:19791 [D loss: 0.672459, acc.: 59.38%] [G loss: 1.253571]\n",
      "epoch:21 step:19792 [D loss: 0.833607, acc.: 41.41%] [G loss: 0.817636]\n",
      "epoch:21 step:19793 [D loss: 0.627921, acc.: 65.62%] [G loss: 1.070499]\n",
      "epoch:21 step:19794 [D loss: 0.454367, acc.: 82.81%] [G loss: 1.191511]\n",
      "epoch:21 step:19795 [D loss: 0.729395, acc.: 55.47%] [G loss: 0.976953]\n",
      "epoch:21 step:19796 [D loss: 0.394339, acc.: 84.38%] [G loss: 1.612713]\n",
      "epoch:21 step:19797 [D loss: 0.848084, acc.: 51.56%] [G loss: 1.615825]\n",
      "epoch:21 step:19798 [D loss: 0.772905, acc.: 47.66%] [G loss: 1.025232]\n",
      "epoch:21 step:19799 [D loss: 0.441415, acc.: 85.16%] [G loss: 1.451503]\n",
      "epoch:21 step:19800 [D loss: 0.728776, acc.: 51.56%] [G loss: 1.329750]\n",
      "epoch:21 step:19801 [D loss: 0.617344, acc.: 67.97%] [G loss: 1.137049]\n",
      "epoch:21 step:19802 [D loss: 0.686315, acc.: 53.12%] [G loss: 1.333213]\n",
      "epoch:21 step:19803 [D loss: 0.687898, acc.: 56.25%] [G loss: 0.976825]\n",
      "epoch:21 step:19804 [D loss: 0.580454, acc.: 72.66%] [G loss: 1.101747]\n",
      "epoch:21 step:19805 [D loss: 0.561064, acc.: 73.44%] [G loss: 0.947449]\n",
      "epoch:21 step:19806 [D loss: 0.463841, acc.: 82.03%] [G loss: 1.262216]\n",
      "epoch:21 step:19807 [D loss: 0.393310, acc.: 82.81%] [G loss: 1.218482]\n",
      "epoch:21 step:19808 [D loss: 0.353839, acc.: 88.28%] [G loss: 1.428718]\n",
      "epoch:21 step:19809 [D loss: 0.451972, acc.: 82.81%] [G loss: 1.547740]\n",
      "epoch:21 step:19810 [D loss: 0.729310, acc.: 53.91%] [G loss: 1.172749]\n",
      "epoch:21 step:19811 [D loss: 0.926464, acc.: 30.47%] [G loss: 0.868073]\n",
      "epoch:21 step:19812 [D loss: 0.615211, acc.: 64.06%] [G loss: 1.030332]\n",
      "epoch:21 step:19813 [D loss: 0.712346, acc.: 57.03%] [G loss: 1.042153]\n",
      "epoch:21 step:19814 [D loss: 0.636324, acc.: 64.06%] [G loss: 1.098050]\n",
      "epoch:21 step:19815 [D loss: 0.504407, acc.: 76.56%] [G loss: 0.983181]\n",
      "epoch:21 step:19816 [D loss: 0.387631, acc.: 84.38%] [G loss: 1.193521]\n",
      "epoch:21 step:19817 [D loss: 0.748294, acc.: 49.22%] [G loss: 0.996521]\n",
      "epoch:21 step:19818 [D loss: 0.794189, acc.: 50.00%] [G loss: 1.126440]\n",
      "epoch:21 step:19819 [D loss: 0.631851, acc.: 57.03%] [G loss: 1.017374]\n",
      "epoch:21 step:19820 [D loss: 0.681131, acc.: 57.81%] [G loss: 0.937074]\n",
      "epoch:21 step:19821 [D loss: 0.590507, acc.: 67.19%] [G loss: 1.009193]\n",
      "epoch:21 step:19822 [D loss: 0.449615, acc.: 88.28%] [G loss: 1.012991]\n",
      "epoch:21 step:19823 [D loss: 0.607723, acc.: 63.28%] [G loss: 1.267077]\n",
      "epoch:21 step:19824 [D loss: 0.552313, acc.: 77.34%] [G loss: 1.201478]\n",
      "epoch:21 step:19825 [D loss: 0.793613, acc.: 49.22%] [G loss: 0.790590]\n",
      "epoch:21 step:19826 [D loss: 0.572761, acc.: 70.31%] [G loss: 0.873870]\n",
      "epoch:21 step:19827 [D loss: 0.371737, acc.: 87.50%] [G loss: 1.049042]\n",
      "epoch:21 step:19828 [D loss: 0.380252, acc.: 90.62%] [G loss: 1.027377]\n",
      "epoch:21 step:19829 [D loss: 0.349179, acc.: 90.62%] [G loss: 1.377787]\n",
      "epoch:21 step:19830 [D loss: 0.672864, acc.: 56.25%] [G loss: 1.035470]\n",
      "epoch:21 step:19831 [D loss: 0.497092, acc.: 82.03%] [G loss: 1.286023]\n",
      "epoch:21 step:19832 [D loss: 0.628744, acc.: 62.50%] [G loss: 1.032575]\n",
      "epoch:21 step:19833 [D loss: 0.804578, acc.: 50.78%] [G loss: 1.014535]\n",
      "epoch:21 step:19834 [D loss: 0.632018, acc.: 65.62%] [G loss: 0.895400]\n",
      "epoch:21 step:19835 [D loss: 0.532085, acc.: 76.56%] [G loss: 1.220729]\n",
      "epoch:21 step:19836 [D loss: 0.570615, acc.: 70.31%] [G loss: 1.262368]\n",
      "epoch:21 step:19837 [D loss: 0.774812, acc.: 45.31%] [G loss: 1.052664]\n",
      "epoch:21 step:19838 [D loss: 0.845687, acc.: 39.84%] [G loss: 0.805434]\n",
      "epoch:21 step:19839 [D loss: 0.667936, acc.: 57.03%] [G loss: 1.045154]\n",
      "epoch:21 step:19840 [D loss: 0.633215, acc.: 59.38%] [G loss: 1.098542]\n",
      "epoch:21 step:19841 [D loss: 0.600305, acc.: 65.62%] [G loss: 1.142072]\n",
      "epoch:21 step:19842 [D loss: 0.545550, acc.: 71.09%] [G loss: 1.119951]\n",
      "epoch:21 step:19843 [D loss: 0.625279, acc.: 63.28%] [G loss: 1.000215]\n",
      "epoch:21 step:19844 [D loss: 0.526120, acc.: 75.00%] [G loss: 1.244061]\n",
      "epoch:21 step:19845 [D loss: 0.516424, acc.: 75.00%] [G loss: 1.149380]\n",
      "epoch:21 step:19846 [D loss: 0.555701, acc.: 75.78%] [G loss: 1.086708]\n",
      "epoch:21 step:19847 [D loss: 0.678262, acc.: 55.47%] [G loss: 0.935785]\n",
      "epoch:21 step:19848 [D loss: 0.610457, acc.: 60.94%] [G loss: 1.066797]\n",
      "epoch:21 step:19849 [D loss: 0.657207, acc.: 60.94%] [G loss: 0.785701]\n",
      "epoch:21 step:19850 [D loss: 0.573671, acc.: 65.62%] [G loss: 1.156677]\n",
      "epoch:21 step:19851 [D loss: 0.794609, acc.: 42.97%] [G loss: 0.771439]\n",
      "epoch:21 step:19852 [D loss: 0.741786, acc.: 51.56%] [G loss: 0.907916]\n",
      "epoch:21 step:19853 [D loss: 0.721958, acc.: 52.34%] [G loss: 0.950429]\n",
      "epoch:21 step:19854 [D loss: 0.664683, acc.: 64.06%] [G loss: 1.078689]\n",
      "epoch:21 step:19855 [D loss: 0.708756, acc.: 54.69%] [G loss: 0.981666]\n",
      "epoch:21 step:19856 [D loss: 0.745900, acc.: 46.09%] [G loss: 0.804353]\n",
      "epoch:21 step:19857 [D loss: 0.667944, acc.: 60.16%] [G loss: 0.963214]\n",
      "epoch:21 step:19858 [D loss: 0.860084, acc.: 41.41%] [G loss: 0.765357]\n",
      "epoch:21 step:19859 [D loss: 0.609802, acc.: 67.19%] [G loss: 1.153967]\n",
      "epoch:21 step:19860 [D loss: 0.789226, acc.: 48.44%] [G loss: 1.156277]\n",
      "epoch:21 step:19861 [D loss: 0.629755, acc.: 59.38%] [G loss: 0.860105]\n",
      "epoch:21 step:19862 [D loss: 0.721290, acc.: 53.91%] [G loss: 0.864302]\n",
      "epoch:21 step:19863 [D loss: 0.701668, acc.: 54.69%] [G loss: 0.885984]\n",
      "epoch:21 step:19864 [D loss: 0.721486, acc.: 51.56%] [G loss: 0.927973]\n",
      "epoch:21 step:19865 [D loss: 0.573596, acc.: 71.09%] [G loss: 0.984190]\n",
      "epoch:21 step:19866 [D loss: 0.687125, acc.: 60.94%] [G loss: 0.946950]\n",
      "epoch:21 step:19867 [D loss: 0.686914, acc.: 59.38%] [G loss: 1.112723]\n",
      "epoch:21 step:19868 [D loss: 0.622563, acc.: 59.38%] [G loss: 0.777697]\n",
      "epoch:21 step:19869 [D loss: 0.461673, acc.: 78.12%] [G loss: 1.008917]\n",
      "epoch:21 step:19870 [D loss: 0.511740, acc.: 76.56%] [G loss: 1.117844]\n",
      "epoch:21 step:19871 [D loss: 0.492602, acc.: 82.81%] [G loss: 1.110798]\n",
      "epoch:21 step:19872 [D loss: 0.548917, acc.: 76.56%] [G loss: 1.122217]\n",
      "epoch:21 step:19873 [D loss: 0.755516, acc.: 50.78%] [G loss: 0.899826]\n",
      "epoch:21 step:19874 [D loss: 0.547281, acc.: 75.78%] [G loss: 1.121764]\n",
      "epoch:21 step:19875 [D loss: 0.697899, acc.: 60.16%] [G loss: 0.961042]\n",
      "epoch:21 step:19876 [D loss: 0.729813, acc.: 56.25%] [G loss: 1.149214]\n",
      "epoch:21 step:19877 [D loss: 0.672515, acc.: 58.59%] [G loss: 0.996903]\n",
      "epoch:21 step:19878 [D loss: 0.436176, acc.: 85.94%] [G loss: 1.376505]\n",
      "epoch:21 step:19879 [D loss: 0.632152, acc.: 64.06%] [G loss: 1.177007]\n",
      "epoch:21 step:19880 [D loss: 0.760061, acc.: 48.44%] [G loss: 1.156312]\n",
      "epoch:21 step:19881 [D loss: 0.713122, acc.: 51.56%] [G loss: 0.838614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19882 [D loss: 0.647732, acc.: 58.59%] [G loss: 0.973268]\n",
      "epoch:21 step:19883 [D loss: 0.633022, acc.: 67.19%] [G loss: 1.015030]\n",
      "epoch:21 step:19884 [D loss: 0.505040, acc.: 78.12%] [G loss: 1.183324]\n",
      "epoch:21 step:19885 [D loss: 0.682803, acc.: 60.16%] [G loss: 0.989438]\n",
      "epoch:21 step:19886 [D loss: 0.466145, acc.: 84.38%] [G loss: 1.100409]\n",
      "epoch:21 step:19887 [D loss: 0.671333, acc.: 57.81%] [G loss: 1.259835]\n",
      "epoch:21 step:19888 [D loss: 0.609028, acc.: 65.62%] [G loss: 1.201281]\n",
      "epoch:21 step:19889 [D loss: 0.681887, acc.: 49.22%] [G loss: 0.898934]\n",
      "epoch:21 step:19890 [D loss: 0.539279, acc.: 71.88%] [G loss: 0.973283]\n",
      "epoch:21 step:19891 [D loss: 0.725679, acc.: 53.12%] [G loss: 0.736759]\n",
      "epoch:21 step:19892 [D loss: 0.485917, acc.: 79.69%] [G loss: 0.945594]\n",
      "epoch:21 step:19893 [D loss: 0.551944, acc.: 72.66%] [G loss: 1.159963]\n",
      "epoch:21 step:19894 [D loss: 0.663242, acc.: 58.59%] [G loss: 1.169140]\n",
      "epoch:21 step:19895 [D loss: 0.552967, acc.: 72.66%] [G loss: 1.044244]\n",
      "epoch:21 step:19896 [D loss: 0.659289, acc.: 61.72%] [G loss: 0.911878]\n",
      "epoch:21 step:19897 [D loss: 0.331583, acc.: 85.94%] [G loss: 1.299863]\n",
      "epoch:21 step:19898 [D loss: 0.313824, acc.: 90.62%] [G loss: 1.510895]\n",
      "epoch:21 step:19899 [D loss: 0.369063, acc.: 92.19%] [G loss: 1.305574]\n",
      "epoch:21 step:19900 [D loss: 0.265751, acc.: 96.88%] [G loss: 1.362466]\n",
      "epoch:21 step:19901 [D loss: 0.718807, acc.: 56.25%] [G loss: 1.293027]\n",
      "epoch:21 step:19902 [D loss: 0.990727, acc.: 28.91%] [G loss: 0.931464]\n",
      "epoch:21 step:19903 [D loss: 0.606945, acc.: 66.41%] [G loss: 1.098742]\n",
      "epoch:21 step:19904 [D loss: 0.597735, acc.: 65.62%] [G loss: 1.116940]\n",
      "epoch:21 step:19905 [D loss: 0.601981, acc.: 67.19%] [G loss: 0.981840]\n",
      "epoch:21 step:19906 [D loss: 0.631759, acc.: 63.28%] [G loss: 0.776253]\n",
      "epoch:21 step:19907 [D loss: 0.226266, acc.: 97.66%] [G loss: 1.549829]\n",
      "epoch:21 step:19908 [D loss: 0.329920, acc.: 92.97%] [G loss: 1.430121]\n",
      "epoch:21 step:19909 [D loss: 0.253312, acc.: 96.09%] [G loss: 1.714610]\n",
      "epoch:21 step:19910 [D loss: 0.804697, acc.: 50.00%] [G loss: 1.049036]\n",
      "epoch:21 step:19911 [D loss: 0.830309, acc.: 42.97%] [G loss: 0.976884]\n",
      "epoch:21 step:19912 [D loss: 0.467255, acc.: 77.34%] [G loss: 1.139725]\n",
      "epoch:21 step:19913 [D loss: 0.724274, acc.: 52.34%] [G loss: 1.132007]\n",
      "epoch:21 step:19914 [D loss: 0.517909, acc.: 75.78%] [G loss: 1.217091]\n",
      "epoch:21 step:19915 [D loss: 0.727180, acc.: 51.56%] [G loss: 0.714474]\n",
      "epoch:21 step:19916 [D loss: 0.754007, acc.: 57.81%] [G loss: 1.094632]\n",
      "epoch:21 step:19917 [D loss: 0.663260, acc.: 64.06%] [G loss: 1.028984]\n",
      "epoch:21 step:19918 [D loss: 0.816958, acc.: 41.41%] [G loss: 0.981011]\n",
      "epoch:21 step:19919 [D loss: 0.702450, acc.: 54.69%] [G loss: 0.831674]\n",
      "epoch:21 step:19920 [D loss: 0.634654, acc.: 62.50%] [G loss: 1.151502]\n",
      "epoch:21 step:19921 [D loss: 0.706838, acc.: 60.94%] [G loss: 1.275394]\n",
      "epoch:21 step:19922 [D loss: 0.669168, acc.: 57.81%] [G loss: 0.948190]\n",
      "epoch:21 step:19923 [D loss: 0.713584, acc.: 57.03%] [G loss: 1.027587]\n",
      "epoch:21 step:19924 [D loss: 0.636828, acc.: 65.62%] [G loss: 1.079677]\n",
      "epoch:21 step:19925 [D loss: 0.555012, acc.: 74.22%] [G loss: 1.317670]\n",
      "epoch:21 step:19926 [D loss: 0.741395, acc.: 53.12%] [G loss: 1.120484]\n",
      "epoch:21 step:19927 [D loss: 0.590994, acc.: 66.41%] [G loss: 1.120352]\n",
      "epoch:21 step:19928 [D loss: 0.663961, acc.: 58.59%] [G loss: 1.154665]\n",
      "epoch:21 step:19929 [D loss: 0.566046, acc.: 75.00%] [G loss: 1.026406]\n",
      "epoch:21 step:19930 [D loss: 0.618087, acc.: 63.28%] [G loss: 1.021663]\n",
      "epoch:21 step:19931 [D loss: 0.723421, acc.: 50.00%] [G loss: 0.912473]\n",
      "epoch:21 step:19932 [D loss: 0.834094, acc.: 35.16%] [G loss: 1.033698]\n",
      "epoch:21 step:19933 [D loss: 0.623281, acc.: 64.06%] [G loss: 0.891084]\n",
      "epoch:21 step:19934 [D loss: 0.643485, acc.: 64.06%] [G loss: 1.129357]\n",
      "epoch:21 step:19935 [D loss: 0.641153, acc.: 65.62%] [G loss: 0.884073]\n",
      "epoch:21 step:19936 [D loss: 0.655076, acc.: 60.94%] [G loss: 1.004709]\n",
      "epoch:21 step:19937 [D loss: 0.593937, acc.: 67.97%] [G loss: 0.920047]\n",
      "epoch:21 step:19938 [D loss: 0.621159, acc.: 63.28%] [G loss: 1.179098]\n",
      "epoch:21 step:19939 [D loss: 0.591207, acc.: 74.22%] [G loss: 1.080353]\n",
      "epoch:21 step:19940 [D loss: 0.442973, acc.: 84.38%] [G loss: 1.113660]\n",
      "epoch:21 step:19941 [D loss: 0.491302, acc.: 78.12%] [G loss: 0.951260]\n",
      "epoch:21 step:19942 [D loss: 0.810647, acc.: 42.19%] [G loss: 1.180783]\n",
      "epoch:21 step:19943 [D loss: 0.643249, acc.: 60.94%] [G loss: 1.017591]\n",
      "epoch:21 step:19944 [D loss: 0.548095, acc.: 78.12%] [G loss: 1.128866]\n",
      "epoch:21 step:19945 [D loss: 0.694844, acc.: 57.81%] [G loss: 0.948791]\n",
      "epoch:21 step:19946 [D loss: 0.559644, acc.: 71.09%] [G loss: 0.930558]\n",
      "epoch:21 step:19947 [D loss: 0.576405, acc.: 67.19%] [G loss: 0.962571]\n",
      "epoch:21 step:19948 [D loss: 0.563422, acc.: 75.00%] [G loss: 1.136473]\n",
      "epoch:21 step:19949 [D loss: 0.399405, acc.: 86.72%] [G loss: 1.131409]\n",
      "epoch:21 step:19950 [D loss: 0.481863, acc.: 81.25%] [G loss: 1.577074]\n",
      "epoch:21 step:19951 [D loss: 0.568835, acc.: 71.09%] [G loss: 1.490959]\n",
      "epoch:21 step:19952 [D loss: 0.749920, acc.: 47.66%] [G loss: 0.965522]\n",
      "epoch:21 step:19953 [D loss: 0.610231, acc.: 65.62%] [G loss: 1.075645]\n",
      "epoch:21 step:19954 [D loss: 0.771217, acc.: 42.97%] [G loss: 1.021601]\n",
      "epoch:21 step:19955 [D loss: 0.717477, acc.: 51.56%] [G loss: 1.263860]\n",
      "epoch:21 step:19956 [D loss: 0.443278, acc.: 85.16%] [G loss: 1.385533]\n",
      "epoch:21 step:19957 [D loss: 0.473650, acc.: 81.25%] [G loss: 1.290540]\n",
      "epoch:21 step:19958 [D loss: 0.827694, acc.: 44.53%] [G loss: 0.917011]\n",
      "epoch:21 step:19959 [D loss: 0.644592, acc.: 60.16%] [G loss: 1.054660]\n",
      "epoch:21 step:19960 [D loss: 0.666082, acc.: 55.47%] [G loss: 1.091300]\n",
      "epoch:21 step:19961 [D loss: 0.507652, acc.: 78.12%] [G loss: 1.123423]\n",
      "epoch:21 step:19962 [D loss: 0.505456, acc.: 78.91%] [G loss: 1.143880]\n",
      "epoch:21 step:19963 [D loss: 0.398572, acc.: 92.97%] [G loss: 1.180587]\n",
      "epoch:21 step:19964 [D loss: 0.502887, acc.: 82.81%] [G loss: 1.143994]\n",
      "epoch:21 step:19965 [D loss: 0.635215, acc.: 64.84%] [G loss: 0.993277]\n",
      "epoch:21 step:19966 [D loss: 0.517471, acc.: 77.34%] [G loss: 1.185395]\n",
      "epoch:21 step:19967 [D loss: 0.665708, acc.: 60.16%] [G loss: 1.081184]\n",
      "epoch:21 step:19968 [D loss: 0.521471, acc.: 75.78%] [G loss: 1.104339]\n",
      "epoch:21 step:19969 [D loss: 0.493633, acc.: 81.25%] [G loss: 1.304912]\n",
      "epoch:21 step:19970 [D loss: 0.504769, acc.: 78.12%] [G loss: 1.173728]\n",
      "epoch:21 step:19971 [D loss: 0.600653, acc.: 67.19%] [G loss: 1.049832]\n",
      "epoch:21 step:19972 [D loss: 0.751555, acc.: 51.56%] [G loss: 0.897296]\n",
      "epoch:21 step:19973 [D loss: 0.633004, acc.: 64.84%] [G loss: 0.950279]\n",
      "epoch:21 step:19974 [D loss: 0.751259, acc.: 54.69%] [G loss: 1.058758]\n",
      "epoch:21 step:19975 [D loss: 0.450839, acc.: 85.16%] [G loss: 1.110450]\n",
      "epoch:21 step:19976 [D loss: 0.585129, acc.: 69.53%] [G loss: 1.171941]\n",
      "epoch:21 step:19977 [D loss: 0.691095, acc.: 60.94%] [G loss: 1.110390]\n",
      "epoch:21 step:19978 [D loss: 0.645854, acc.: 59.38%] [G loss: 1.107768]\n",
      "epoch:21 step:19979 [D loss: 0.601301, acc.: 66.41%] [G loss: 1.093974]\n",
      "epoch:21 step:19980 [D loss: 0.745540, acc.: 46.88%] [G loss: 0.775379]\n",
      "epoch:21 step:19981 [D loss: 0.623253, acc.: 64.84%] [G loss: 1.220838]\n",
      "epoch:21 step:19982 [D loss: 0.606921, acc.: 67.19%] [G loss: 1.105990]\n",
      "epoch:21 step:19983 [D loss: 0.600168, acc.: 67.97%] [G loss: 0.947145]\n",
      "epoch:21 step:19984 [D loss: 0.849322, acc.: 39.06%] [G loss: 0.865765]\n",
      "epoch:21 step:19985 [D loss: 0.600888, acc.: 67.19%] [G loss: 1.025721]\n",
      "epoch:21 step:19986 [D loss: 0.542305, acc.: 69.53%] [G loss: 1.098563]\n",
      "epoch:21 step:19987 [D loss: 0.555743, acc.: 73.44%] [G loss: 0.951653]\n",
      "epoch:21 step:19988 [D loss: 0.540369, acc.: 73.44%] [G loss: 1.309379]\n",
      "epoch:21 step:19989 [D loss: 0.437034, acc.: 80.47%] [G loss: 1.372288]\n",
      "epoch:21 step:19990 [D loss: 0.404906, acc.: 85.94%] [G loss: 1.262423]\n",
      "epoch:21 step:19991 [D loss: 0.341644, acc.: 92.97%] [G loss: 1.565220]\n",
      "epoch:21 step:19992 [D loss: 0.655055, acc.: 57.81%] [G loss: 1.149931]\n",
      "epoch:21 step:19993 [D loss: 0.789619, acc.: 47.66%] [G loss: 1.494823]\n",
      "epoch:21 step:19994 [D loss: 0.741260, acc.: 48.44%] [G loss: 1.009839]\n",
      "epoch:21 step:19995 [D loss: 0.576057, acc.: 71.09%] [G loss: 1.376667]\n",
      "epoch:21 step:19996 [D loss: 0.620240, acc.: 66.41%] [G loss: 1.105467]\n",
      "epoch:21 step:19997 [D loss: 0.553294, acc.: 75.00%] [G loss: 1.308904]\n",
      "epoch:21 step:19998 [D loss: 0.533057, acc.: 76.56%] [G loss: 1.021596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19999 [D loss: 0.347639, acc.: 95.31%] [G loss: 1.462875]\n",
      "epoch:21 step:20000 [D loss: 0.783147, acc.: 49.22%] [G loss: 1.107450]\n",
      "epoch:21 step:20001 [D loss: 0.628830, acc.: 60.94%] [G loss: 1.086059]\n",
      "epoch:21 step:20002 [D loss: 0.633406, acc.: 64.84%] [G loss: 0.871954]\n",
      "epoch:21 step:20003 [D loss: 0.431976, acc.: 85.94%] [G loss: 1.049028]\n",
      "epoch:21 step:20004 [D loss: 0.291058, acc.: 93.75%] [G loss: 1.300479]\n",
      "epoch:21 step:20005 [D loss: 0.336064, acc.: 92.19%] [G loss: 1.241317]\n",
      "epoch:21 step:20006 [D loss: 0.547635, acc.: 71.09%] [G loss: 1.282330]\n",
      "epoch:21 step:20007 [D loss: 0.742394, acc.: 50.78%] [G loss: 0.789207]\n",
      "epoch:21 step:20008 [D loss: 0.793331, acc.: 46.09%] [G loss: 0.687099]\n",
      "epoch:21 step:20009 [D loss: 0.726488, acc.: 53.12%] [G loss: 0.892942]\n",
      "epoch:21 step:20010 [D loss: 0.668887, acc.: 64.06%] [G loss: 1.033346]\n",
      "epoch:21 step:20011 [D loss: 0.998267, acc.: 35.94%] [G loss: 0.713191]\n",
      "epoch:21 step:20012 [D loss: 0.545942, acc.: 76.56%] [G loss: 1.179448]\n",
      "epoch:21 step:20013 [D loss: 0.562268, acc.: 75.78%] [G loss: 1.288306]\n",
      "epoch:21 step:20014 [D loss: 0.657087, acc.: 61.72%] [G loss: 1.112381]\n",
      "epoch:21 step:20015 [D loss: 0.591234, acc.: 74.22%] [G loss: 0.921524]\n",
      "epoch:21 step:20016 [D loss: 0.704138, acc.: 57.81%] [G loss: 1.004673]\n",
      "epoch:21 step:20017 [D loss: 0.809697, acc.: 35.94%] [G loss: 0.913570]\n",
      "epoch:21 step:20018 [D loss: 0.854796, acc.: 39.06%] [G loss: 0.824009]\n",
      "epoch:21 step:20019 [D loss: 0.594732, acc.: 68.75%] [G loss: 1.122627]\n",
      "epoch:21 step:20020 [D loss: 0.344339, acc.: 96.09%] [G loss: 1.356063]\n",
      "epoch:21 step:20021 [D loss: 0.486059, acc.: 82.03%] [G loss: 1.446213]\n",
      "epoch:21 step:20022 [D loss: 0.320434, acc.: 92.97%] [G loss: 1.416649]\n",
      "epoch:21 step:20023 [D loss: 0.332271, acc.: 89.84%] [G loss: 1.537053]\n",
      "epoch:21 step:20024 [D loss: 0.374308, acc.: 87.50%] [G loss: 1.612489]\n",
      "epoch:21 step:20025 [D loss: 0.725715, acc.: 56.25%] [G loss: 1.242585]\n",
      "epoch:21 step:20026 [D loss: 0.828513, acc.: 44.53%] [G loss: 1.111935]\n",
      "epoch:21 step:20027 [D loss: 0.776495, acc.: 48.44%] [G loss: 0.960267]\n",
      "epoch:21 step:20028 [D loss: 0.504200, acc.: 79.69%] [G loss: 1.051607]\n",
      "epoch:21 step:20029 [D loss: 0.572365, acc.: 71.09%] [G loss: 1.316640]\n",
      "epoch:21 step:20030 [D loss: 0.514241, acc.: 75.00%] [G loss: 1.123929]\n",
      "epoch:21 step:20031 [D loss: 0.484075, acc.: 85.16%] [G loss: 1.028443]\n",
      "epoch:21 step:20032 [D loss: 0.629451, acc.: 57.81%] [G loss: 1.128296]\n",
      "epoch:21 step:20033 [D loss: 0.679229, acc.: 60.16%] [G loss: 0.977737]\n",
      "epoch:21 step:20034 [D loss: 0.579998, acc.: 70.31%] [G loss: 0.911306]\n",
      "epoch:21 step:20035 [D loss: 0.650552, acc.: 65.62%] [G loss: 0.983100]\n",
      "epoch:21 step:20036 [D loss: 0.508307, acc.: 80.47%] [G loss: 1.216338]\n",
      "epoch:21 step:20037 [D loss: 0.633343, acc.: 61.72%] [G loss: 1.077491]\n",
      "epoch:21 step:20038 [D loss: 0.750411, acc.: 50.00%] [G loss: 1.149306]\n",
      "epoch:21 step:20039 [D loss: 0.801851, acc.: 44.53%] [G loss: 1.037850]\n",
      "epoch:21 step:20040 [D loss: 0.680011, acc.: 53.91%] [G loss: 1.164593]\n",
      "epoch:21 step:20041 [D loss: 0.717395, acc.: 49.22%] [G loss: 1.013400]\n",
      "epoch:21 step:20042 [D loss: 0.681857, acc.: 59.38%] [G loss: 0.991806]\n",
      "epoch:21 step:20043 [D loss: 0.344115, acc.: 92.19%] [G loss: 1.107774]\n",
      "epoch:21 step:20044 [D loss: 0.450775, acc.: 78.12%] [G loss: 1.220287]\n",
      "epoch:21 step:20045 [D loss: 0.586385, acc.: 67.97%] [G loss: 1.371216]\n",
      "epoch:21 step:20046 [D loss: 0.629008, acc.: 64.06%] [G loss: 1.157682]\n",
      "epoch:21 step:20047 [D loss: 0.489260, acc.: 82.81%] [G loss: 1.049525]\n",
      "epoch:21 step:20048 [D loss: 0.561681, acc.: 72.66%] [G loss: 1.149356]\n",
      "epoch:21 step:20049 [D loss: 0.602323, acc.: 68.75%] [G loss: 1.152058]\n",
      "epoch:21 step:20050 [D loss: 0.850729, acc.: 37.50%] [G loss: 0.737276]\n",
      "epoch:21 step:20051 [D loss: 0.781198, acc.: 46.88%] [G loss: 0.852446]\n",
      "epoch:21 step:20052 [D loss: 0.940932, acc.: 32.81%] [G loss: 0.827278]\n",
      "epoch:21 step:20053 [D loss: 0.547413, acc.: 71.88%] [G loss: 1.157810]\n",
      "epoch:21 step:20054 [D loss: 0.649202, acc.: 65.62%] [G loss: 0.843658]\n",
      "epoch:21 step:20055 [D loss: 0.321483, acc.: 92.97%] [G loss: 1.272257]\n",
      "epoch:21 step:20056 [D loss: 0.822876, acc.: 43.75%] [G loss: 1.001385]\n",
      "epoch:21 step:20057 [D loss: 0.604934, acc.: 68.75%] [G loss: 0.907638]\n",
      "epoch:21 step:20058 [D loss: 0.534989, acc.: 77.34%] [G loss: 1.224363]\n",
      "epoch:21 step:20059 [D loss: 0.612330, acc.: 65.62%] [G loss: 1.035302]\n",
      "epoch:21 step:20060 [D loss: 0.555362, acc.: 71.09%] [G loss: 0.904806]\n",
      "epoch:21 step:20061 [D loss: 0.531786, acc.: 75.78%] [G loss: 1.035836]\n",
      "epoch:21 step:20062 [D loss: 0.570702, acc.: 71.09%] [G loss: 0.881060]\n",
      "epoch:21 step:20063 [D loss: 0.648396, acc.: 64.06%] [G loss: 1.090427]\n",
      "epoch:21 step:20064 [D loss: 0.751810, acc.: 48.44%] [G loss: 1.169130]\n",
      "epoch:21 step:20065 [D loss: 0.664206, acc.: 60.16%] [G loss: 0.701124]\n",
      "epoch:21 step:20066 [D loss: 0.615835, acc.: 66.41%] [G loss: 0.995589]\n",
      "epoch:21 step:20067 [D loss: 0.429388, acc.: 80.47%] [G loss: 0.936150]\n",
      "epoch:21 step:20068 [D loss: 0.412021, acc.: 87.50%] [G loss: 1.198452]\n",
      "epoch:21 step:20069 [D loss: 0.534482, acc.: 72.66%] [G loss: 1.326433]\n",
      "epoch:21 step:20070 [D loss: 0.677995, acc.: 62.50%] [G loss: 1.013496]\n",
      "epoch:21 step:20071 [D loss: 0.357463, acc.: 91.41%] [G loss: 1.155748]\n",
      "epoch:21 step:20072 [D loss: 0.559020, acc.: 71.88%] [G loss: 1.057932]\n",
      "epoch:21 step:20073 [D loss: 0.318206, acc.: 89.06%] [G loss: 1.172399]\n",
      "epoch:21 step:20074 [D loss: 0.244372, acc.: 97.66%] [G loss: 1.460635]\n",
      "epoch:21 step:20075 [D loss: 0.349649, acc.: 85.16%] [G loss: 1.569418]\n",
      "epoch:21 step:20076 [D loss: 0.378160, acc.: 88.28%] [G loss: 1.475971]\n",
      "epoch:21 step:20077 [D loss: 0.416773, acc.: 86.72%] [G loss: 1.297018]\n",
      "epoch:21 step:20078 [D loss: 0.573197, acc.: 71.09%] [G loss: 1.255772]\n",
      "epoch:21 step:20079 [D loss: 0.525259, acc.: 77.34%] [G loss: 1.455672]\n",
      "epoch:21 step:20080 [D loss: 0.736040, acc.: 57.81%] [G loss: 1.019577]\n",
      "epoch:21 step:20081 [D loss: 0.320804, acc.: 93.75%] [G loss: 1.645863]\n",
      "epoch:21 step:20082 [D loss: 0.461519, acc.: 81.25%] [G loss: 1.343885]\n",
      "epoch:21 step:20083 [D loss: 0.548712, acc.: 67.97%] [G loss: 1.124666]\n",
      "epoch:21 step:20084 [D loss: 0.846026, acc.: 47.66%] [G loss: 1.106259]\n",
      "epoch:21 step:20085 [D loss: 0.858132, acc.: 39.06%] [G loss: 0.857514]\n",
      "epoch:21 step:20086 [D loss: 0.850720, acc.: 46.88%] [G loss: 0.821312]\n",
      "epoch:21 step:20087 [D loss: 0.904142, acc.: 35.16%] [G loss: 0.872812]\n",
      "epoch:21 step:20088 [D loss: 0.921937, acc.: 37.50%] [G loss: 1.033085]\n",
      "epoch:21 step:20089 [D loss: 0.902830, acc.: 39.06%] [G loss: 1.056037]\n",
      "epoch:21 step:20090 [D loss: 0.843419, acc.: 39.84%] [G loss: 1.179294]\n",
      "epoch:21 step:20091 [D loss: 0.722049, acc.: 50.78%] [G loss: 1.280420]\n",
      "epoch:21 step:20092 [D loss: 0.589865, acc.: 67.19%] [G loss: 1.344683]\n",
      "epoch:21 step:20093 [D loss: 0.611049, acc.: 64.06%] [G loss: 1.325620]\n",
      "epoch:21 step:20094 [D loss: 0.858278, acc.: 42.97%] [G loss: 1.025967]\n",
      "epoch:21 step:20095 [D loss: 0.726043, acc.: 50.78%] [G loss: 1.115068]\n",
      "epoch:21 step:20096 [D loss: 0.689837, acc.: 56.25%] [G loss: 0.966680]\n",
      "epoch:21 step:20097 [D loss: 0.723287, acc.: 51.56%] [G loss: 1.039875]\n",
      "epoch:21 step:20098 [D loss: 0.545009, acc.: 76.56%] [G loss: 1.412621]\n",
      "epoch:21 step:20099 [D loss: 0.597065, acc.: 68.75%] [G loss: 1.113024]\n",
      "epoch:21 step:20100 [D loss: 0.682966, acc.: 60.94%] [G loss: 1.237134]\n",
      "epoch:21 step:20101 [D loss: 0.680679, acc.: 60.16%] [G loss: 0.964417]\n",
      "epoch:21 step:20102 [D loss: 0.581220, acc.: 66.41%] [G loss: 1.280304]\n",
      "epoch:21 step:20103 [D loss: 0.632521, acc.: 67.19%] [G loss: 1.053026]\n",
      "epoch:21 step:20104 [D loss: 0.610718, acc.: 65.62%] [G loss: 1.047228]\n",
      "epoch:21 step:20105 [D loss: 0.553307, acc.: 74.22%] [G loss: 1.049604]\n",
      "epoch:21 step:20106 [D loss: 0.546431, acc.: 73.44%] [G loss: 0.975560]\n",
      "epoch:21 step:20107 [D loss: 0.573767, acc.: 73.44%] [G loss: 1.068180]\n",
      "epoch:21 step:20108 [D loss: 0.619772, acc.: 66.41%] [G loss: 1.114063]\n",
      "epoch:21 step:20109 [D loss: 0.474160, acc.: 83.59%] [G loss: 1.485904]\n",
      "epoch:21 step:20110 [D loss: 0.524121, acc.: 75.00%] [G loss: 1.271007]\n",
      "epoch:21 step:20111 [D loss: 0.620772, acc.: 64.06%] [G loss: 1.156480]\n",
      "epoch:21 step:20112 [D loss: 0.469499, acc.: 84.38%] [G loss: 1.036889]\n",
      "epoch:21 step:20113 [D loss: 0.509160, acc.: 76.56%] [G loss: 1.150549]\n",
      "epoch:21 step:20114 [D loss: 0.763872, acc.: 50.78%] [G loss: 1.039886]\n",
      "epoch:21 step:20115 [D loss: 0.752405, acc.: 54.69%] [G loss: 0.900863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20116 [D loss: 0.765733, acc.: 50.78%] [G loss: 1.153508]\n",
      "epoch:21 step:20117 [D loss: 0.838321, acc.: 39.06%] [G loss: 0.990680]\n",
      "epoch:21 step:20118 [D loss: 0.803834, acc.: 42.97%] [G loss: 0.991447]\n",
      "epoch:21 step:20119 [D loss: 0.689443, acc.: 59.38%] [G loss: 0.916318]\n",
      "epoch:21 step:20120 [D loss: 0.566394, acc.: 71.88%] [G loss: 1.287493]\n",
      "epoch:21 step:20121 [D loss: 0.734299, acc.: 57.81%] [G loss: 0.977045]\n",
      "epoch:21 step:20122 [D loss: 0.722077, acc.: 53.12%] [G loss: 0.893154]\n",
      "epoch:21 step:20123 [D loss: 0.800319, acc.: 44.53%] [G loss: 1.029114]\n",
      "epoch:21 step:20124 [D loss: 0.700087, acc.: 54.69%] [G loss: 0.884576]\n",
      "epoch:21 step:20125 [D loss: 0.603595, acc.: 64.06%] [G loss: 0.925920]\n",
      "epoch:21 step:20126 [D loss: 0.432237, acc.: 83.59%] [G loss: 1.246660]\n",
      "epoch:21 step:20127 [D loss: 0.646520, acc.: 61.72%] [G loss: 1.100273]\n",
      "epoch:21 step:20128 [D loss: 0.631840, acc.: 60.94%] [G loss: 1.096962]\n",
      "epoch:21 step:20129 [D loss: 0.631580, acc.: 62.50%] [G loss: 0.842819]\n",
      "epoch:21 step:20130 [D loss: 0.555771, acc.: 71.88%] [G loss: 1.229394]\n",
      "epoch:21 step:20131 [D loss: 0.582355, acc.: 67.97%] [G loss: 1.195946]\n",
      "epoch:21 step:20132 [D loss: 0.611879, acc.: 63.28%] [G loss: 1.436604]\n",
      "epoch:21 step:20133 [D loss: 0.792782, acc.: 49.22%] [G loss: 0.998752]\n",
      "epoch:21 step:20134 [D loss: 0.431947, acc.: 85.94%] [G loss: 1.175741]\n",
      "epoch:21 step:20135 [D loss: 0.913850, acc.: 46.09%] [G loss: 1.102150]\n",
      "epoch:21 step:20136 [D loss: 0.933088, acc.: 33.59%] [G loss: 0.980045]\n",
      "epoch:21 step:20137 [D loss: 0.838664, acc.: 38.28%] [G loss: 0.863674]\n",
      "epoch:21 step:20138 [D loss: 0.784773, acc.: 48.44%] [G loss: 1.132895]\n",
      "epoch:21 step:20139 [D loss: 0.727861, acc.: 50.00%] [G loss: 1.085779]\n",
      "epoch:21 step:20140 [D loss: 0.674811, acc.: 60.16%] [G loss: 1.115393]\n",
      "epoch:21 step:20141 [D loss: 0.681077, acc.: 55.47%] [G loss: 1.080256]\n",
      "epoch:21 step:20142 [D loss: 0.800621, acc.: 42.97%] [G loss: 0.948693]\n",
      "epoch:21 step:20143 [D loss: 0.694595, acc.: 55.47%] [G loss: 1.029442]\n",
      "epoch:21 step:20144 [D loss: 0.515851, acc.: 78.91%] [G loss: 0.986244]\n",
      "epoch:21 step:20145 [D loss: 0.521973, acc.: 74.22%] [G loss: 1.186306]\n",
      "epoch:21 step:20146 [D loss: 0.426408, acc.: 82.81%] [G loss: 1.388918]\n",
      "epoch:21 step:20147 [D loss: 0.527584, acc.: 79.69%] [G loss: 1.165110]\n",
      "epoch:21 step:20148 [D loss: 0.291866, acc.: 93.75%] [G loss: 1.389162]\n",
      "epoch:21 step:20149 [D loss: 0.446536, acc.: 83.59%] [G loss: 1.408512]\n",
      "epoch:21 step:20150 [D loss: 0.669988, acc.: 59.38%] [G loss: 1.402922]\n",
      "epoch:21 step:20151 [D loss: 0.439401, acc.: 85.16%] [G loss: 1.388306]\n",
      "epoch:21 step:20152 [D loss: 0.494603, acc.: 77.34%] [G loss: 1.518071]\n",
      "epoch:21 step:20153 [D loss: 0.633974, acc.: 63.28%] [G loss: 1.156710]\n",
      "epoch:21 step:20154 [D loss: 0.758762, acc.: 47.66%] [G loss: 0.961309]\n",
      "epoch:21 step:20155 [D loss: 0.654945, acc.: 61.72%] [G loss: 0.859586]\n",
      "epoch:21 step:20156 [D loss: 0.508159, acc.: 74.22%] [G loss: 1.213577]\n",
      "epoch:21 step:20157 [D loss: 0.661588, acc.: 67.97%] [G loss: 1.174208]\n",
      "epoch:21 step:20158 [D loss: 0.467220, acc.: 84.38%] [G loss: 1.168133]\n",
      "epoch:21 step:20159 [D loss: 0.570483, acc.: 70.31%] [G loss: 1.275837]\n",
      "epoch:21 step:20160 [D loss: 0.546231, acc.: 74.22%] [G loss: 1.198911]\n",
      "epoch:21 step:20161 [D loss: 0.424005, acc.: 82.81%] [G loss: 1.230364]\n",
      "epoch:21 step:20162 [D loss: 0.488990, acc.: 79.69%] [G loss: 1.401343]\n",
      "epoch:21 step:20163 [D loss: 0.580471, acc.: 68.75%] [G loss: 1.273914]\n",
      "epoch:21 step:20164 [D loss: 0.460620, acc.: 82.81%] [G loss: 1.189023]\n",
      "epoch:21 step:20165 [D loss: 0.570434, acc.: 72.66%] [G loss: 0.913822]\n",
      "epoch:21 step:20166 [D loss: 0.531315, acc.: 77.34%] [G loss: 1.155554]\n",
      "epoch:21 step:20167 [D loss: 0.412528, acc.: 89.84%] [G loss: 1.272496]\n",
      "epoch:21 step:20168 [D loss: 0.619283, acc.: 67.19%] [G loss: 1.284589]\n",
      "epoch:21 step:20169 [D loss: 0.754900, acc.: 51.56%] [G loss: 1.154908]\n",
      "epoch:21 step:20170 [D loss: 0.743975, acc.: 51.56%] [G loss: 0.878882]\n",
      "epoch:21 step:20171 [D loss: 0.658177, acc.: 61.72%] [G loss: 0.980572]\n",
      "epoch:21 step:20172 [D loss: 0.678670, acc.: 59.38%] [G loss: 0.923613]\n",
      "epoch:21 step:20173 [D loss: 0.558819, acc.: 68.75%] [G loss: 1.039570]\n",
      "epoch:21 step:20174 [D loss: 0.417311, acc.: 85.94%] [G loss: 1.152520]\n",
      "epoch:21 step:20175 [D loss: 0.538108, acc.: 74.22%] [G loss: 0.898739]\n",
      "epoch:21 step:20176 [D loss: 0.282249, acc.: 93.75%] [G loss: 1.671279]\n",
      "epoch:21 step:20177 [D loss: 0.801528, acc.: 50.78%] [G loss: 1.287126]\n",
      "epoch:21 step:20178 [D loss: 0.786517, acc.: 49.22%] [G loss: 1.023499]\n",
      "epoch:21 step:20179 [D loss: 0.815520, acc.: 43.75%] [G loss: 0.958108]\n",
      "epoch:21 step:20180 [D loss: 0.422434, acc.: 75.00%] [G loss: 1.185265]\n",
      "epoch:21 step:20181 [D loss: 0.328070, acc.: 90.62%] [G loss: 1.358763]\n",
      "epoch:21 step:20182 [D loss: 0.606536, acc.: 67.97%] [G loss: 1.351124]\n",
      "epoch:21 step:20183 [D loss: 0.614624, acc.: 68.75%] [G loss: 1.370712]\n",
      "epoch:21 step:20184 [D loss: 0.383597, acc.: 89.06%] [G loss: 1.215362]\n",
      "epoch:21 step:20185 [D loss: 0.338562, acc.: 91.41%] [G loss: 1.144675]\n",
      "epoch:21 step:20186 [D loss: 0.768445, acc.: 52.34%] [G loss: 1.387454]\n",
      "epoch:21 step:20187 [D loss: 0.834339, acc.: 38.28%] [G loss: 1.139352]\n",
      "epoch:21 step:20188 [D loss: 0.504942, acc.: 80.47%] [G loss: 1.242047]\n",
      "epoch:21 step:20189 [D loss: 0.558347, acc.: 70.31%] [G loss: 0.946902]\n",
      "epoch:21 step:20190 [D loss: 0.503932, acc.: 76.56%] [G loss: 1.134182]\n",
      "epoch:21 step:20191 [D loss: 0.531199, acc.: 74.22%] [G loss: 1.192646]\n",
      "epoch:21 step:20192 [D loss: 0.529166, acc.: 74.22%] [G loss: 1.087598]\n",
      "epoch:21 step:20193 [D loss: 0.715295, acc.: 55.47%] [G loss: 0.937174]\n",
      "epoch:21 step:20194 [D loss: 0.537754, acc.: 71.09%] [G loss: 1.070562]\n",
      "epoch:21 step:20195 [D loss: 0.562355, acc.: 76.56%] [G loss: 1.386460]\n",
      "epoch:21 step:20196 [D loss: 0.358197, acc.: 92.19%] [G loss: 1.444743]\n",
      "epoch:21 step:20197 [D loss: 0.456937, acc.: 81.25%] [G loss: 1.398572]\n",
      "epoch:21 step:20198 [D loss: 0.541450, acc.: 76.56%] [G loss: 1.392583]\n",
      "epoch:21 step:20199 [D loss: 0.309857, acc.: 95.31%] [G loss: 1.527583]\n",
      "epoch:21 step:20200 [D loss: 0.489949, acc.: 75.00%] [G loss: 1.325468]\n",
      "epoch:21 step:20201 [D loss: 0.800075, acc.: 50.00%] [G loss: 1.389595]\n",
      "epoch:21 step:20202 [D loss: 1.050170, acc.: 25.78%] [G loss: 0.857016]\n",
      "epoch:21 step:20203 [D loss: 0.556821, acc.: 74.22%] [G loss: 1.180145]\n",
      "epoch:21 step:20204 [D loss: 0.614223, acc.: 70.31%] [G loss: 0.958787]\n",
      "epoch:21 step:20205 [D loss: 0.619823, acc.: 67.97%] [G loss: 1.055452]\n",
      "epoch:21 step:20206 [D loss: 0.603091, acc.: 66.41%] [G loss: 0.731179]\n",
      "epoch:21 step:20207 [D loss: 0.591769, acc.: 68.75%] [G loss: 0.870957]\n",
      "epoch:21 step:20208 [D loss: 0.585869, acc.: 68.75%] [G loss: 1.095302]\n",
      "epoch:21 step:20209 [D loss: 0.625469, acc.: 66.41%] [G loss: 1.062982]\n",
      "epoch:21 step:20210 [D loss: 0.358953, acc.: 91.41%] [G loss: 1.373066]\n",
      "epoch:21 step:20211 [D loss: 0.558503, acc.: 74.22%] [G loss: 1.239059]\n",
      "epoch:21 step:20212 [D loss: 0.642525, acc.: 62.50%] [G loss: 1.245196]\n",
      "epoch:21 step:20213 [D loss: 0.504359, acc.: 78.91%] [G loss: 1.407270]\n",
      "epoch:21 step:20214 [D loss: 0.425237, acc.: 85.16%] [G loss: 1.270000]\n",
      "epoch:21 step:20215 [D loss: 0.575464, acc.: 71.09%] [G loss: 1.465236]\n",
      "epoch:21 step:20216 [D loss: 0.577058, acc.: 70.31%] [G loss: 1.479466]\n",
      "epoch:21 step:20217 [D loss: 0.485671, acc.: 82.03%] [G loss: 1.231688]\n",
      "epoch:21 step:20218 [D loss: 0.820123, acc.: 46.88%] [G loss: 0.716794]\n",
      "epoch:21 step:20219 [D loss: 0.752642, acc.: 49.22%] [G loss: 1.414300]\n",
      "epoch:21 step:20220 [D loss: 0.602526, acc.: 67.97%] [G loss: 0.973115]\n",
      "epoch:21 step:20221 [D loss: 0.578477, acc.: 67.97%] [G loss: 0.877045]\n",
      "epoch:21 step:20222 [D loss: 0.615465, acc.: 64.84%] [G loss: 1.233208]\n",
      "epoch:21 step:20223 [D loss: 0.503275, acc.: 78.91%] [G loss: 1.450295]\n",
      "epoch:21 step:20224 [D loss: 0.375472, acc.: 89.84%] [G loss: 1.421983]\n",
      "epoch:21 step:20225 [D loss: 0.459624, acc.: 81.25%] [G loss: 1.355959]\n",
      "epoch:21 step:20226 [D loss: 0.281174, acc.: 95.31%] [G loss: 1.309794]\n",
      "epoch:21 step:20227 [D loss: 0.376825, acc.: 86.72%] [G loss: 1.366792]\n",
      "epoch:21 step:20228 [D loss: 0.218080, acc.: 97.66%] [G loss: 1.219007]\n",
      "epoch:21 step:20229 [D loss: 0.399108, acc.: 85.94%] [G loss: 1.577959]\n",
      "epoch:21 step:20230 [D loss: 0.505762, acc.: 78.12%] [G loss: 1.328719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20231 [D loss: 0.379802, acc.: 86.72%] [G loss: 1.552658]\n",
      "epoch:21 step:20232 [D loss: 0.365760, acc.: 89.84%] [G loss: 1.622985]\n",
      "epoch:21 step:20233 [D loss: 0.233420, acc.: 100.00%] [G loss: 1.779199]\n",
      "epoch:21 step:20234 [D loss: 0.272328, acc.: 96.88%] [G loss: 1.711737]\n",
      "epoch:21 step:20235 [D loss: 0.383193, acc.: 91.41%] [G loss: 1.590107]\n",
      "epoch:21 step:20236 [D loss: 0.828327, acc.: 52.34%] [G loss: 1.306924]\n",
      "epoch:21 step:20237 [D loss: 1.087084, acc.: 23.44%] [G loss: 1.026994]\n",
      "epoch:21 step:20238 [D loss: 0.495068, acc.: 79.69%] [G loss: 1.746346]\n",
      "epoch:21 step:20239 [D loss: 0.863160, acc.: 51.56%] [G loss: 1.333199]\n",
      "epoch:21 step:20240 [D loss: 0.700448, acc.: 50.00%] [G loss: 1.113991]\n",
      "epoch:21 step:20241 [D loss: 0.541280, acc.: 75.00%] [G loss: 1.041337]\n",
      "epoch:21 step:20242 [D loss: 0.610376, acc.: 66.41%] [G loss: 1.124959]\n",
      "epoch:21 step:20243 [D loss: 0.433390, acc.: 82.81%] [G loss: 1.238356]\n",
      "epoch:21 step:20244 [D loss: 0.343165, acc.: 91.41%] [G loss: 1.387372]\n",
      "epoch:21 step:20245 [D loss: 0.644103, acc.: 61.72%] [G loss: 1.131867]\n",
      "epoch:21 step:20246 [D loss: 0.655918, acc.: 64.84%] [G loss: 1.019872]\n",
      "epoch:21 step:20247 [D loss: 0.750404, acc.: 50.00%] [G loss: 0.936247]\n",
      "epoch:21 step:20248 [D loss: 0.608977, acc.: 67.97%] [G loss: 0.998026]\n",
      "epoch:21 step:20249 [D loss: 0.632593, acc.: 64.06%] [G loss: 1.087679]\n",
      "epoch:21 step:20250 [D loss: 0.483434, acc.: 85.16%] [G loss: 1.249487]\n",
      "epoch:21 step:20251 [D loss: 0.433881, acc.: 85.94%] [G loss: 1.153198]\n",
      "epoch:21 step:20252 [D loss: 0.629896, acc.: 66.41%] [G loss: 1.137917]\n",
      "epoch:21 step:20253 [D loss: 0.436756, acc.: 84.38%] [G loss: 1.279673]\n",
      "epoch:21 step:20254 [D loss: 0.445871, acc.: 89.06%] [G loss: 1.280954]\n",
      "epoch:21 step:20255 [D loss: 0.414249, acc.: 89.06%] [G loss: 0.989897]\n",
      "epoch:21 step:20256 [D loss: 0.455379, acc.: 84.38%] [G loss: 1.525087]\n",
      "epoch:21 step:20257 [D loss: 0.837996, acc.: 39.06%] [G loss: 0.887939]\n",
      "epoch:21 step:20258 [D loss: 0.760074, acc.: 50.00%] [G loss: 0.784854]\n",
      "epoch:21 step:20259 [D loss: 0.732701, acc.: 51.56%] [G loss: 0.927580]\n",
      "epoch:21 step:20260 [D loss: 0.621124, acc.: 68.75%] [G loss: 1.023425]\n",
      "epoch:21 step:20261 [D loss: 0.726663, acc.: 56.25%] [G loss: 0.801310]\n",
      "epoch:21 step:20262 [D loss: 0.695314, acc.: 57.03%] [G loss: 0.870039]\n",
      "epoch:21 step:20263 [D loss: 0.491551, acc.: 77.34%] [G loss: 1.210518]\n",
      "epoch:21 step:20264 [D loss: 0.638833, acc.: 62.50%] [G loss: 0.901864]\n",
      "epoch:21 step:20265 [D loss: 0.334805, acc.: 93.75%] [G loss: 1.467611]\n",
      "epoch:21 step:20266 [D loss: 0.388597, acc.: 86.72%] [G loss: 1.414054]\n",
      "epoch:21 step:20267 [D loss: 0.843867, acc.: 50.78%] [G loss: 1.461932]\n",
      "epoch:21 step:20268 [D loss: 0.802492, acc.: 46.88%] [G loss: 1.142366]\n",
      "epoch:21 step:20269 [D loss: 0.550375, acc.: 69.53%] [G loss: 1.380958]\n",
      "epoch:21 step:20270 [D loss: 0.538205, acc.: 73.44%] [G loss: 1.086619]\n",
      "epoch:21 step:20271 [D loss: 0.482755, acc.: 77.34%] [G loss: 1.406134]\n",
      "epoch:21 step:20272 [D loss: 0.486648, acc.: 79.69%] [G loss: 1.633651]\n",
      "epoch:21 step:20273 [D loss: 0.581753, acc.: 68.75%] [G loss: 1.462648]\n",
      "epoch:21 step:20274 [D loss: 0.600710, acc.: 68.75%] [G loss: 1.113376]\n",
      "epoch:21 step:20275 [D loss: 0.307737, acc.: 91.41%] [G loss: 1.331374]\n",
      "epoch:21 step:20276 [D loss: 0.537046, acc.: 77.34%] [G loss: 1.338877]\n",
      "epoch:21 step:20277 [D loss: 0.547366, acc.: 78.12%] [G loss: 1.334935]\n",
      "epoch:21 step:20278 [D loss: 0.537683, acc.: 75.00%] [G loss: 1.073640]\n",
      "epoch:21 step:20279 [D loss: 0.591290, acc.: 63.28%] [G loss: 1.155666]\n",
      "epoch:21 step:20280 [D loss: 0.404260, acc.: 82.81%] [G loss: 0.998564]\n",
      "epoch:21 step:20281 [D loss: 0.370942, acc.: 86.72%] [G loss: 1.188040]\n",
      "epoch:21 step:20282 [D loss: 0.397099, acc.: 84.38%] [G loss: 1.211949]\n",
      "epoch:21 step:20283 [D loss: 0.663680, acc.: 59.38%] [G loss: 1.021701]\n",
      "epoch:21 step:20284 [D loss: 0.787917, acc.: 46.88%] [G loss: 1.250083]\n",
      "epoch:21 step:20285 [D loss: 0.741029, acc.: 46.88%] [G loss: 1.101104]\n",
      "epoch:21 step:20286 [D loss: 0.800995, acc.: 55.47%] [G loss: 0.985781]\n",
      "epoch:21 step:20287 [D loss: 0.544000, acc.: 76.56%] [G loss: 1.691228]\n",
      "epoch:21 step:20288 [D loss: 0.779175, acc.: 47.66%] [G loss: 1.146363]\n",
      "epoch:21 step:20289 [D loss: 0.703378, acc.: 57.81%] [G loss: 1.229513]\n",
      "epoch:21 step:20290 [D loss: 0.505394, acc.: 73.44%] [G loss: 1.114533]\n",
      "epoch:21 step:20291 [D loss: 0.303083, acc.: 96.88%] [G loss: 1.622415]\n",
      "epoch:21 step:20292 [D loss: 0.485336, acc.: 70.31%] [G loss: 1.189415]\n",
      "epoch:21 step:20293 [D loss: 0.250394, acc.: 99.22%] [G loss: 1.896877]\n",
      "epoch:21 step:20294 [D loss: 0.422670, acc.: 85.94%] [G loss: 1.662593]\n",
      "epoch:21 step:20295 [D loss: 0.870736, acc.: 44.53%] [G loss: 1.166987]\n",
      "epoch:21 step:20296 [D loss: 0.800775, acc.: 50.00%] [G loss: 0.952492]\n",
      "epoch:21 step:20297 [D loss: 0.708546, acc.: 57.03%] [G loss: 0.930810]\n",
      "epoch:21 step:20298 [D loss: 0.727534, acc.: 53.12%] [G loss: 0.896672]\n",
      "epoch:21 step:20299 [D loss: 0.603571, acc.: 66.41%] [G loss: 1.166004]\n",
      "epoch:21 step:20300 [D loss: 0.619273, acc.: 67.19%] [G loss: 1.378610]\n",
      "epoch:21 step:20301 [D loss: 0.524487, acc.: 75.78%] [G loss: 1.130558]\n",
      "epoch:21 step:20302 [D loss: 0.661506, acc.: 58.59%] [G loss: 1.421331]\n",
      "epoch:21 step:20303 [D loss: 1.094101, acc.: 30.47%] [G loss: 0.664422]\n",
      "epoch:21 step:20304 [D loss: 0.695465, acc.: 58.59%] [G loss: 1.416645]\n",
      "epoch:21 step:20305 [D loss: 0.613487, acc.: 62.50%] [G loss: 1.209332]\n",
      "epoch:21 step:20306 [D loss: 0.343919, acc.: 85.94%] [G loss: 1.345010]\n",
      "epoch:21 step:20307 [D loss: 0.672988, acc.: 60.94%] [G loss: 1.008984]\n",
      "epoch:21 step:20308 [D loss: 0.671099, acc.: 64.06%] [G loss: 1.358487]\n",
      "epoch:21 step:20309 [D loss: 0.615414, acc.: 67.19%] [G loss: 1.182684]\n",
      "epoch:21 step:20310 [D loss: 0.774862, acc.: 56.25%] [G loss: 0.850001]\n",
      "epoch:21 step:20311 [D loss: 0.529779, acc.: 76.56%] [G loss: 1.690347]\n",
      "epoch:21 step:20312 [D loss: 0.730583, acc.: 50.00%] [G loss: 1.140558]\n",
      "epoch:21 step:20313 [D loss: 0.712801, acc.: 57.03%] [G loss: 1.253527]\n",
      "epoch:21 step:20314 [D loss: 0.905277, acc.: 34.38%] [G loss: 0.920938]\n",
      "epoch:21 step:20315 [D loss: 0.758929, acc.: 50.78%] [G loss: 0.803398]\n",
      "epoch:21 step:20316 [D loss: 0.955148, acc.: 28.91%] [G loss: 0.830563]\n",
      "epoch:21 step:20317 [D loss: 0.691190, acc.: 53.91%] [G loss: 1.308346]\n",
      "epoch:21 step:20318 [D loss: 0.495704, acc.: 81.25%] [G loss: 1.477588]\n",
      "epoch:21 step:20319 [D loss: 0.472060, acc.: 82.03%] [G loss: 1.527709]\n",
      "epoch:21 step:20320 [D loss: 0.818076, acc.: 44.53%] [G loss: 1.461873]\n",
      "epoch:21 step:20321 [D loss: 0.816294, acc.: 50.78%] [G loss: 1.134826]\n",
      "epoch:21 step:20322 [D loss: 0.558029, acc.: 73.44%] [G loss: 1.208333]\n",
      "epoch:21 step:20323 [D loss: 0.678367, acc.: 59.38%] [G loss: 0.837572]\n",
      "epoch:21 step:20324 [D loss: 0.540929, acc.: 74.22%] [G loss: 1.027550]\n",
      "epoch:21 step:20325 [D loss: 0.492478, acc.: 81.25%] [G loss: 1.136174]\n",
      "epoch:21 step:20326 [D loss: 0.615789, acc.: 62.50%] [G loss: 1.153923]\n",
      "epoch:21 step:20327 [D loss: 0.559703, acc.: 70.31%] [G loss: 1.028542]\n",
      "epoch:21 step:20328 [D loss: 0.577694, acc.: 68.75%] [G loss: 1.072396]\n",
      "epoch:21 step:20329 [D loss: 0.637241, acc.: 65.62%] [G loss: 1.178226]\n",
      "epoch:21 step:20330 [D loss: 0.466490, acc.: 84.38%] [G loss: 1.099380]\n",
      "epoch:21 step:20331 [D loss: 0.545239, acc.: 72.66%] [G loss: 1.311936]\n",
      "epoch:21 step:20332 [D loss: 0.724643, acc.: 56.25%] [G loss: 1.338717]\n",
      "epoch:21 step:20333 [D loss: 0.615775, acc.: 65.62%] [G loss: 1.040764]\n",
      "epoch:21 step:20334 [D loss: 0.641185, acc.: 60.94%] [G loss: 1.151896]\n",
      "epoch:21 step:20335 [D loss: 0.590852, acc.: 68.75%] [G loss: 1.158935]\n",
      "epoch:21 step:20336 [D loss: 0.583894, acc.: 74.22%] [G loss: 1.358503]\n",
      "epoch:21 step:20337 [D loss: 0.620722, acc.: 68.75%] [G loss: 0.971102]\n",
      "epoch:21 step:20338 [D loss: 0.532951, acc.: 71.09%] [G loss: 1.356944]\n",
      "epoch:21 step:20339 [D loss: 0.426508, acc.: 84.38%] [G loss: 1.202194]\n",
      "epoch:21 step:20340 [D loss: 0.279885, acc.: 92.97%] [G loss: 1.536417]\n",
      "epoch:21 step:20341 [D loss: 0.205283, acc.: 96.09%] [G loss: 2.105470]\n",
      "epoch:21 step:20342 [D loss: 0.229103, acc.: 97.66%] [G loss: 1.782992]\n",
      "epoch:21 step:20343 [D loss: 0.430296, acc.: 79.69%] [G loss: 1.421763]\n",
      "epoch:21 step:20344 [D loss: 0.758421, acc.: 52.34%] [G loss: 1.018396]\n",
      "epoch:21 step:20345 [D loss: 0.585123, acc.: 67.19%] [G loss: 1.365375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20346 [D loss: 0.589344, acc.: 61.72%] [G loss: 1.404161]\n",
      "epoch:21 step:20347 [D loss: 0.758286, acc.: 53.12%] [G loss: 0.708055]\n",
      "epoch:21 step:20348 [D loss: 0.761557, acc.: 47.66%] [G loss: 0.903313]\n",
      "epoch:21 step:20349 [D loss: 0.642237, acc.: 62.50%] [G loss: 1.222695]\n",
      "epoch:21 step:20350 [D loss: 0.865448, acc.: 46.09%] [G loss: 1.279862]\n",
      "epoch:21 step:20351 [D loss: 0.776448, acc.: 48.44%] [G loss: 0.885560]\n",
      "epoch:21 step:20352 [D loss: 1.092180, acc.: 27.34%] [G loss: 0.482193]\n",
      "epoch:21 step:20353 [D loss: 0.725984, acc.: 52.34%] [G loss: 1.030408]\n",
      "epoch:21 step:20354 [D loss: 0.713247, acc.: 57.81%] [G loss: 1.351058]\n",
      "epoch:21 step:20355 [D loss: 0.758930, acc.: 50.00%] [G loss: 1.102968]\n",
      "epoch:21 step:20356 [D loss: 0.819752, acc.: 45.31%] [G loss: 0.924155]\n",
      "epoch:21 step:20357 [D loss: 0.823965, acc.: 46.88%] [G loss: 1.035161]\n",
      "epoch:21 step:20358 [D loss: 0.771383, acc.: 50.00%] [G loss: 1.011533]\n",
      "epoch:21 step:20359 [D loss: 0.588301, acc.: 64.06%] [G loss: 1.335770]\n",
      "epoch:21 step:20360 [D loss: 0.575016, acc.: 72.66%] [G loss: 1.211336]\n",
      "epoch:21 step:20361 [D loss: 0.761931, acc.: 51.56%] [G loss: 1.186592]\n",
      "epoch:21 step:20362 [D loss: 0.632050, acc.: 60.94%] [G loss: 1.114048]\n",
      "epoch:21 step:20363 [D loss: 0.655598, acc.: 57.03%] [G loss: 1.295040]\n",
      "epoch:21 step:20364 [D loss: 0.583204, acc.: 72.66%] [G loss: 1.138410]\n",
      "epoch:21 step:20365 [D loss: 0.501298, acc.: 78.12%] [G loss: 1.120468]\n",
      "epoch:21 step:20366 [D loss: 0.627121, acc.: 71.09%] [G loss: 0.929031]\n",
      "epoch:21 step:20367 [D loss: 0.502928, acc.: 81.25%] [G loss: 1.257008]\n",
      "epoch:21 step:20368 [D loss: 0.610544, acc.: 66.41%] [G loss: 1.212288]\n",
      "epoch:21 step:20369 [D loss: 0.535339, acc.: 77.34%] [G loss: 1.245390]\n",
      "epoch:21 step:20370 [D loss: 0.422414, acc.: 86.72%] [G loss: 1.697063]\n",
      "epoch:21 step:20371 [D loss: 0.390833, acc.: 88.28%] [G loss: 1.049291]\n",
      "epoch:21 step:20372 [D loss: 0.480744, acc.: 78.91%] [G loss: 1.551740]\n",
      "epoch:21 step:20373 [D loss: 0.689132, acc.: 62.50%] [G loss: 1.165373]\n",
      "epoch:21 step:20374 [D loss: 0.666005, acc.: 57.81%] [G loss: 1.095527]\n",
      "epoch:21 step:20375 [D loss: 0.703010, acc.: 57.03%] [G loss: 0.993538]\n",
      "epoch:21 step:20376 [D loss: 0.700960, acc.: 52.34%] [G loss: 1.174804]\n",
      "epoch:21 step:20377 [D loss: 0.647281, acc.: 64.84%] [G loss: 1.093689]\n",
      "epoch:21 step:20378 [D loss: 0.657010, acc.: 61.72%] [G loss: 1.053568]\n",
      "epoch:21 step:20379 [D loss: 0.710031, acc.: 58.59%] [G loss: 1.027659]\n",
      "epoch:21 step:20380 [D loss: 0.634291, acc.: 65.62%] [G loss: 0.920287]\n",
      "epoch:21 step:20381 [D loss: 0.852612, acc.: 41.41%] [G loss: 0.763298]\n",
      "epoch:21 step:20382 [D loss: 0.706509, acc.: 60.16%] [G loss: 1.077519]\n",
      "epoch:21 step:20383 [D loss: 0.604275, acc.: 67.97%] [G loss: 0.896559]\n",
      "epoch:21 step:20384 [D loss: 0.505332, acc.: 78.12%] [G loss: 1.291189]\n",
      "epoch:21 step:20385 [D loss: 0.454180, acc.: 83.59%] [G loss: 1.184118]\n",
      "epoch:21 step:20386 [D loss: 0.530910, acc.: 78.91%] [G loss: 1.007083]\n",
      "epoch:21 step:20387 [D loss: 0.657359, acc.: 57.81%] [G loss: 1.122640]\n",
      "epoch:21 step:20388 [D loss: 0.608770, acc.: 65.62%] [G loss: 1.245030]\n",
      "epoch:21 step:20389 [D loss: 0.618377, acc.: 63.28%] [G loss: 1.218326]\n",
      "epoch:21 step:20390 [D loss: 0.448458, acc.: 85.94%] [G loss: 1.184742]\n",
      "epoch:21 step:20391 [D loss: 0.576303, acc.: 71.09%] [G loss: 1.198819]\n",
      "epoch:21 step:20392 [D loss: 0.703887, acc.: 55.47%] [G loss: 1.231669]\n",
      "epoch:21 step:20393 [D loss: 0.882763, acc.: 42.19%] [G loss: 1.063283]\n",
      "epoch:21 step:20394 [D loss: 0.634933, acc.: 65.62%] [G loss: 1.086727]\n",
      "epoch:21 step:20395 [D loss: 0.667346, acc.: 57.81%] [G loss: 1.096915]\n",
      "epoch:21 step:20396 [D loss: 0.723731, acc.: 54.69%] [G loss: 0.753315]\n",
      "epoch:21 step:20397 [D loss: 0.590853, acc.: 72.66%] [G loss: 0.810028]\n",
      "epoch:21 step:20398 [D loss: 0.555333, acc.: 71.88%] [G loss: 1.151608]\n",
      "epoch:21 step:20399 [D loss: 0.811161, acc.: 45.31%] [G loss: 0.707866]\n",
      "epoch:21 step:20400 [D loss: 0.686156, acc.: 58.59%] [G loss: 0.984639]\n",
      "epoch:21 step:20401 [D loss: 0.452653, acc.: 81.25%] [G loss: 1.152560]\n",
      "epoch:21 step:20402 [D loss: 0.510050, acc.: 76.56%] [G loss: 1.187947]\n",
      "epoch:21 step:20403 [D loss: 0.475757, acc.: 81.25%] [G loss: 1.289976]\n",
      "epoch:21 step:20404 [D loss: 0.640023, acc.: 63.28%] [G loss: 1.184512]\n",
      "epoch:21 step:20405 [D loss: 0.604196, acc.: 65.62%] [G loss: 0.856890]\n",
      "epoch:21 step:20406 [D loss: 0.554583, acc.: 72.66%] [G loss: 1.114166]\n",
      "epoch:21 step:20407 [D loss: 0.475020, acc.: 81.25%] [G loss: 1.051370]\n",
      "epoch:21 step:20408 [D loss: 0.439105, acc.: 82.03%] [G loss: 1.253380]\n",
      "epoch:21 step:20409 [D loss: 0.471641, acc.: 82.81%] [G loss: 1.231520]\n",
      "epoch:21 step:20410 [D loss: 0.459366, acc.: 81.25%] [G loss: 1.324520]\n",
      "epoch:21 step:20411 [D loss: 0.718174, acc.: 56.25%] [G loss: 1.118246]\n",
      "epoch:21 step:20412 [D loss: 0.712215, acc.: 57.03%] [G loss: 0.941992]\n",
      "epoch:21 step:20413 [D loss: 0.767058, acc.: 52.34%] [G loss: 0.792425]\n",
      "epoch:21 step:20414 [D loss: 0.645830, acc.: 63.28%] [G loss: 0.981682]\n",
      "epoch:21 step:20415 [D loss: 0.588289, acc.: 68.75%] [G loss: 1.063015]\n",
      "epoch:21 step:20416 [D loss: 0.825846, acc.: 40.62%] [G loss: 0.871822]\n",
      "epoch:21 step:20417 [D loss: 0.563493, acc.: 75.00%] [G loss: 1.044273]\n",
      "epoch:21 step:20418 [D loss: 0.539404, acc.: 75.00%] [G loss: 1.071220]\n",
      "epoch:21 step:20419 [D loss: 0.665663, acc.: 59.38%] [G loss: 1.056204]\n",
      "epoch:21 step:20420 [D loss: 0.419930, acc.: 86.72%] [G loss: 1.190814]\n",
      "epoch:21 step:20421 [D loss: 0.635925, acc.: 58.59%] [G loss: 1.320612]\n",
      "epoch:21 step:20422 [D loss: 0.429756, acc.: 85.16%] [G loss: 1.165373]\n",
      "epoch:21 step:20423 [D loss: 0.585560, acc.: 72.66%] [G loss: 1.152508]\n",
      "epoch:21 step:20424 [D loss: 0.613186, acc.: 62.50%] [G loss: 1.192502]\n",
      "epoch:21 step:20425 [D loss: 0.573771, acc.: 73.44%] [G loss: 1.111606]\n",
      "epoch:21 step:20426 [D loss: 0.583473, acc.: 69.53%] [G loss: 1.068103]\n",
      "epoch:21 step:20427 [D loss: 0.582265, acc.: 71.88%] [G loss: 0.974010]\n",
      "epoch:21 step:20428 [D loss: 0.630151, acc.: 61.72%] [G loss: 1.088492]\n",
      "epoch:21 step:20429 [D loss: 0.817929, acc.: 46.09%] [G loss: 0.816295]\n",
      "epoch:21 step:20430 [D loss: 0.695618, acc.: 57.81%] [G loss: 1.218134]\n",
      "epoch:21 step:20431 [D loss: 0.741087, acc.: 50.78%] [G loss: 1.095437]\n",
      "epoch:21 step:20432 [D loss: 0.606151, acc.: 63.28%] [G loss: 0.888944]\n",
      "epoch:21 step:20433 [D loss: 0.550439, acc.: 74.22%] [G loss: 1.076197]\n",
      "epoch:21 step:20434 [D loss: 0.608832, acc.: 66.41%] [G loss: 1.399962]\n",
      "epoch:21 step:20435 [D loss: 0.681881, acc.: 55.47%] [G loss: 1.139442]\n",
      "epoch:21 step:20436 [D loss: 0.754041, acc.: 49.22%] [G loss: 0.993441]\n",
      "epoch:21 step:20437 [D loss: 0.606470, acc.: 70.31%] [G loss: 1.249192]\n",
      "epoch:21 step:20438 [D loss: 0.664694, acc.: 56.25%] [G loss: 0.982645]\n",
      "epoch:21 step:20439 [D loss: 0.701661, acc.: 56.25%] [G loss: 1.110578]\n",
      "epoch:21 step:20440 [D loss: 0.634933, acc.: 62.50%] [G loss: 0.853126]\n",
      "epoch:21 step:20441 [D loss: 0.645538, acc.: 64.06%] [G loss: 0.964619]\n",
      "epoch:21 step:20442 [D loss: 0.619377, acc.: 64.84%] [G loss: 1.143715]\n",
      "epoch:21 step:20443 [D loss: 0.598339, acc.: 68.75%] [G loss: 1.041099]\n",
      "epoch:21 step:20444 [D loss: 0.476002, acc.: 81.25%] [G loss: 1.116199]\n",
      "epoch:21 step:20445 [D loss: 0.354125, acc.: 93.75%] [G loss: 1.259456]\n",
      "epoch:21 step:20446 [D loss: 0.302855, acc.: 92.97%] [G loss: 1.319456]\n",
      "epoch:21 step:20447 [D loss: 0.577179, acc.: 71.88%] [G loss: 1.211961]\n",
      "epoch:21 step:20448 [D loss: 0.687705, acc.: 53.91%] [G loss: 1.231505]\n",
      "epoch:21 step:20449 [D loss: 0.689042, acc.: 58.59%] [G loss: 1.319510]\n",
      "epoch:21 step:20450 [D loss: 0.774263, acc.: 56.25%] [G loss: 0.672951]\n",
      "epoch:21 step:20451 [D loss: 0.255648, acc.: 92.97%] [G loss: 1.381893]\n",
      "epoch:21 step:20452 [D loss: 0.222254, acc.: 96.88%] [G loss: 1.483878]\n",
      "epoch:21 step:20453 [D loss: 0.491262, acc.: 78.91%] [G loss: 1.516940]\n",
      "epoch:21 step:20454 [D loss: 0.465144, acc.: 82.03%] [G loss: 1.191708]\n",
      "epoch:21 step:20455 [D loss: 0.742542, acc.: 55.47%] [G loss: 1.004985]\n",
      "epoch:21 step:20456 [D loss: 0.840651, acc.: 46.09%] [G loss: 1.122663]\n",
      "epoch:21 step:20457 [D loss: 0.555610, acc.: 71.09%] [G loss: 1.272868]\n",
      "epoch:21 step:20458 [D loss: 0.612003, acc.: 66.41%] [G loss: 1.172882]\n",
      "epoch:21 step:20459 [D loss: 0.477774, acc.: 82.03%] [G loss: 1.353219]\n",
      "epoch:21 step:20460 [D loss: 0.591154, acc.: 66.41%] [G loss: 1.268628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20461 [D loss: 0.726772, acc.: 53.91%] [G loss: 0.947309]\n",
      "epoch:21 step:20462 [D loss: 0.554346, acc.: 69.53%] [G loss: 1.031385]\n",
      "epoch:21 step:20463 [D loss: 0.405933, acc.: 89.84%] [G loss: 1.281788]\n",
      "epoch:21 step:20464 [D loss: 0.734693, acc.: 50.78%] [G loss: 1.088604]\n",
      "epoch:21 step:20465 [D loss: 0.643497, acc.: 57.81%] [G loss: 1.174127]\n",
      "epoch:21 step:20466 [D loss: 0.704870, acc.: 52.34%] [G loss: 1.087905]\n",
      "epoch:21 step:20467 [D loss: 0.406332, acc.: 87.50%] [G loss: 1.417118]\n",
      "epoch:21 step:20468 [D loss: 0.341997, acc.: 88.28%] [G loss: 1.042975]\n",
      "epoch:21 step:20469 [D loss: 0.301592, acc.: 93.75%] [G loss: 1.670169]\n",
      "epoch:21 step:20470 [D loss: 0.436868, acc.: 84.38%] [G loss: 1.353531]\n",
      "epoch:21 step:20471 [D loss: 0.211676, acc.: 96.88%] [G loss: 1.666251]\n",
      "epoch:21 step:20472 [D loss: 0.479273, acc.: 82.03%] [G loss: 1.326049]\n",
      "epoch:21 step:20473 [D loss: 0.513466, acc.: 74.22%] [G loss: 1.217873]\n",
      "epoch:21 step:20474 [D loss: 0.692382, acc.: 59.38%] [G loss: 1.252570]\n",
      "epoch:21 step:20475 [D loss: 0.541724, acc.: 74.22%] [G loss: 1.216255]\n",
      "epoch:21 step:20476 [D loss: 0.628294, acc.: 63.28%] [G loss: 0.906683]\n",
      "epoch:21 step:20477 [D loss: 1.082976, acc.: 22.66%] [G loss: 0.818069]\n",
      "epoch:21 step:20478 [D loss: 0.727230, acc.: 50.78%] [G loss: 1.083514]\n",
      "epoch:21 step:20479 [D loss: 0.768554, acc.: 46.88%] [G loss: 1.133204]\n",
      "epoch:21 step:20480 [D loss: 0.608621, acc.: 65.62%] [G loss: 1.389314]\n",
      "epoch:21 step:20481 [D loss: 0.517918, acc.: 72.66%] [G loss: 0.982913]\n",
      "epoch:21 step:20482 [D loss: 0.491207, acc.: 78.91%] [G loss: 1.215587]\n",
      "epoch:21 step:20483 [D loss: 0.358636, acc.: 88.28%] [G loss: 1.373414]\n",
      "epoch:21 step:20484 [D loss: 0.634163, acc.: 64.06%] [G loss: 1.224505]\n",
      "epoch:21 step:20485 [D loss: 0.663888, acc.: 57.81%] [G loss: 0.990083]\n",
      "epoch:21 step:20486 [D loss: 0.613455, acc.: 65.62%] [G loss: 1.204564]\n",
      "epoch:21 step:20487 [D loss: 0.497283, acc.: 76.56%] [G loss: 1.344530]\n",
      "epoch:21 step:20488 [D loss: 0.539325, acc.: 71.88%] [G loss: 1.460769]\n",
      "epoch:21 step:20489 [D loss: 0.628204, acc.: 56.25%] [G loss: 1.232028]\n",
      "epoch:21 step:20490 [D loss: 0.402000, acc.: 88.28%] [G loss: 1.345984]\n",
      "epoch:21 step:20491 [D loss: 0.448495, acc.: 85.16%] [G loss: 1.236014]\n",
      "epoch:21 step:20492 [D loss: 0.232507, acc.: 92.19%] [G loss: 1.987504]\n",
      "epoch:21 step:20493 [D loss: 0.198257, acc.: 96.09%] [G loss: 1.728935]\n",
      "epoch:21 step:20494 [D loss: 0.527575, acc.: 73.44%] [G loss: 1.541591]\n",
      "epoch:21 step:20495 [D loss: 0.362803, acc.: 92.19%] [G loss: 1.594290]\n",
      "epoch:21 step:20496 [D loss: 0.454255, acc.: 82.03%] [G loss: 1.088306]\n",
      "epoch:21 step:20497 [D loss: 0.861731, acc.: 35.94%] [G loss: 1.032069]\n",
      "epoch:21 step:20498 [D loss: 0.618536, acc.: 67.19%] [G loss: 1.196644]\n",
      "epoch:21 step:20499 [D loss: 0.713323, acc.: 56.25%] [G loss: 0.857245]\n",
      "epoch:21 step:20500 [D loss: 0.755489, acc.: 59.38%] [G loss: 0.726911]\n",
      "epoch:21 step:20501 [D loss: 0.486063, acc.: 75.78%] [G loss: 1.393742]\n",
      "epoch:21 step:20502 [D loss: 0.429898, acc.: 82.81%] [G loss: 1.675278]\n",
      "epoch:21 step:20503 [D loss: 0.623371, acc.: 69.53%] [G loss: 1.356851]\n",
      "epoch:21 step:20504 [D loss: 0.764292, acc.: 44.53%] [G loss: 0.849546]\n",
      "epoch:21 step:20505 [D loss: 0.613941, acc.: 64.84%] [G loss: 0.968589]\n",
      "epoch:21 step:20506 [D loss: 0.670369, acc.: 57.81%] [G loss: 0.984855]\n",
      "epoch:21 step:20507 [D loss: 0.836269, acc.: 46.88%] [G loss: 0.855849]\n",
      "epoch:21 step:20508 [D loss: 0.511498, acc.: 71.88%] [G loss: 1.170113]\n",
      "epoch:21 step:20509 [D loss: 0.632516, acc.: 64.06%] [G loss: 1.322075]\n",
      "epoch:21 step:20510 [D loss: 0.590605, acc.: 64.84%] [G loss: 1.450363]\n",
      "epoch:21 step:20511 [D loss: 1.112596, acc.: 40.62%] [G loss: 1.263293]\n",
      "epoch:21 step:20512 [D loss: 0.961776, acc.: 32.81%] [G loss: 1.104355]\n",
      "epoch:21 step:20513 [D loss: 0.969454, acc.: 28.91%] [G loss: 0.757648]\n",
      "epoch:21 step:20514 [D loss: 1.063776, acc.: 21.09%] [G loss: 0.838267]\n",
      "epoch:21 step:20515 [D loss: 0.766270, acc.: 53.12%] [G loss: 1.118464]\n",
      "epoch:21 step:20516 [D loss: 0.861901, acc.: 47.66%] [G loss: 0.929395]\n",
      "epoch:21 step:20517 [D loss: 0.552633, acc.: 77.34%] [G loss: 1.240199]\n",
      "epoch:21 step:20518 [D loss: 0.434227, acc.: 83.59%] [G loss: 1.138277]\n",
      "epoch:21 step:20519 [D loss: 0.531482, acc.: 75.78%] [G loss: 1.399609]\n",
      "epoch:21 step:20520 [D loss: 0.816091, acc.: 43.75%] [G loss: 1.107956]\n",
      "epoch:21 step:20521 [D loss: 0.660522, acc.: 61.72%] [G loss: 1.262902]\n",
      "epoch:21 step:20522 [D loss: 0.623816, acc.: 68.75%] [G loss: 0.751892]\n",
      "epoch:21 step:20523 [D loss: 0.649072, acc.: 65.62%] [G loss: 0.990904]\n",
      "epoch:21 step:20524 [D loss: 0.457723, acc.: 81.25%] [G loss: 1.195387]\n",
      "epoch:21 step:20525 [D loss: 0.465018, acc.: 79.69%] [G loss: 1.048575]\n",
      "epoch:21 step:20526 [D loss: 0.411168, acc.: 88.28%] [G loss: 1.372368]\n",
      "epoch:21 step:20527 [D loss: 0.355323, acc.: 92.97%] [G loss: 1.416595]\n",
      "epoch:21 step:20528 [D loss: 0.269050, acc.: 92.97%] [G loss: 1.637103]\n",
      "epoch:21 step:20529 [D loss: 0.290825, acc.: 92.19%] [G loss: 1.519872]\n",
      "epoch:21 step:20530 [D loss: 0.287964, acc.: 95.31%] [G loss: 1.661349]\n",
      "epoch:21 step:20531 [D loss: 0.208419, acc.: 98.44%] [G loss: 1.932441]\n",
      "epoch:21 step:20532 [D loss: 0.477072, acc.: 78.12%] [G loss: 1.348065]\n",
      "epoch:21 step:20533 [D loss: 0.535679, acc.: 72.66%] [G loss: 1.341244]\n",
      "epoch:21 step:20534 [D loss: 0.487946, acc.: 77.34%] [G loss: 1.399358]\n",
      "epoch:21 step:20535 [D loss: 1.019758, acc.: 39.06%] [G loss: 1.131151]\n",
      "epoch:21 step:20536 [D loss: 0.725703, acc.: 56.25%] [G loss: 1.085684]\n",
      "epoch:21 step:20537 [D loss: 0.515667, acc.: 75.00%] [G loss: 1.239237]\n",
      "epoch:21 step:20538 [D loss: 0.692946, acc.: 63.28%] [G loss: 1.105369]\n",
      "epoch:21 step:20539 [D loss: 0.736315, acc.: 50.00%] [G loss: 0.956574]\n",
      "epoch:21 step:20540 [D loss: 0.583131, acc.: 69.53%] [G loss: 1.131363]\n",
      "epoch:21 step:20541 [D loss: 0.797757, acc.: 46.88%] [G loss: 0.985072]\n",
      "epoch:21 step:20542 [D loss: 0.755286, acc.: 43.75%] [G loss: 0.981559]\n",
      "epoch:21 step:20543 [D loss: 0.660334, acc.: 58.59%] [G loss: 1.055450]\n",
      "epoch:21 step:20544 [D loss: 0.635298, acc.: 65.62%] [G loss: 1.081744]\n",
      "epoch:21 step:20545 [D loss: 0.621414, acc.: 63.28%] [G loss: 0.896059]\n",
      "epoch:21 step:20546 [D loss: 0.593132, acc.: 70.31%] [G loss: 1.140414]\n",
      "epoch:21 step:20547 [D loss: 0.633517, acc.: 64.84%] [G loss: 1.031165]\n",
      "epoch:21 step:20548 [D loss: 0.546902, acc.: 71.88%] [G loss: 0.793648]\n",
      "epoch:21 step:20549 [D loss: 0.599214, acc.: 66.41%] [G loss: 0.999196]\n",
      "epoch:21 step:20550 [D loss: 0.561132, acc.: 72.66%] [G loss: 1.140228]\n",
      "epoch:21 step:20551 [D loss: 0.662685, acc.: 55.47%] [G loss: 1.008637]\n",
      "epoch:21 step:20552 [D loss: 0.546827, acc.: 73.44%] [G loss: 1.080825]\n",
      "epoch:21 step:20553 [D loss: 0.659145, acc.: 57.81%] [G loss: 0.944372]\n",
      "epoch:21 step:20554 [D loss: 0.626438, acc.: 58.59%] [G loss: 1.118527]\n",
      "epoch:21 step:20555 [D loss: 0.576848, acc.: 68.75%] [G loss: 1.165895]\n",
      "epoch:21 step:20556 [D loss: 0.695352, acc.: 58.59%] [G loss: 1.031238]\n",
      "epoch:21 step:20557 [D loss: 0.772613, acc.: 49.22%] [G loss: 1.285647]\n",
      "epoch:21 step:20558 [D loss: 0.704948, acc.: 53.91%] [G loss: 0.939973]\n",
      "epoch:21 step:20559 [D loss: 0.540192, acc.: 75.78%] [G loss: 0.792044]\n",
      "epoch:21 step:20560 [D loss: 0.507767, acc.: 78.12%] [G loss: 0.888082]\n",
      "epoch:21 step:20561 [D loss: 0.463207, acc.: 82.03%] [G loss: 1.056138]\n",
      "epoch:21 step:20562 [D loss: 0.364728, acc.: 90.62%] [G loss: 1.283072]\n",
      "epoch:21 step:20563 [D loss: 0.454231, acc.: 85.16%] [G loss: 1.268841]\n",
      "epoch:21 step:20564 [D loss: 0.401583, acc.: 88.28%] [G loss: 1.466182]\n",
      "epoch:21 step:20565 [D loss: 0.466378, acc.: 81.25%] [G loss: 1.243316]\n",
      "epoch:21 step:20566 [D loss: 0.518010, acc.: 78.91%] [G loss: 1.245259]\n",
      "epoch:21 step:20567 [D loss: 0.430795, acc.: 82.81%] [G loss: 1.316085]\n",
      "epoch:21 step:20568 [D loss: 0.861624, acc.: 43.75%] [G loss: 1.198118]\n",
      "epoch:21 step:20569 [D loss: 0.547398, acc.: 75.78%] [G loss: 1.127382]\n",
      "epoch:21 step:20570 [D loss: 0.526281, acc.: 76.56%] [G loss: 1.207051]\n",
      "epoch:21 step:20571 [D loss: 0.506143, acc.: 78.12%] [G loss: 0.907148]\n",
      "epoch:21 step:20572 [D loss: 0.485951, acc.: 81.25%] [G loss: 1.132027]\n",
      "epoch:21 step:20573 [D loss: 0.530913, acc.: 75.78%] [G loss: 1.291782]\n",
      "epoch:21 step:20574 [D loss: 0.379531, acc.: 87.50%] [G loss: 0.965277]\n",
      "epoch:21 step:20575 [D loss: 0.261045, acc.: 97.66%] [G loss: 1.457088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20576 [D loss: 0.231647, acc.: 95.31%] [G loss: 1.590358]\n",
      "epoch:21 step:20577 [D loss: 0.259084, acc.: 96.09%] [G loss: 1.407535]\n",
      "epoch:21 step:20578 [D loss: 0.451146, acc.: 85.16%] [G loss: 1.375070]\n",
      "epoch:21 step:20579 [D loss: 0.635127, acc.: 62.50%] [G loss: 1.208438]\n",
      "epoch:21 step:20580 [D loss: 0.491155, acc.: 80.47%] [G loss: 1.338667]\n",
      "epoch:21 step:20581 [D loss: 1.043008, acc.: 21.09%] [G loss: 0.857914]\n",
      "epoch:21 step:20582 [D loss: 0.678234, acc.: 64.06%] [G loss: 1.252494]\n",
      "epoch:21 step:20583 [D loss: 0.626856, acc.: 63.28%] [G loss: 1.176681]\n",
      "epoch:21 step:20584 [D loss: 0.743197, acc.: 53.91%] [G loss: 1.166590]\n",
      "epoch:21 step:20585 [D loss: 0.874270, acc.: 34.38%] [G loss: 1.023765]\n",
      "epoch:21 step:20586 [D loss: 0.452458, acc.: 85.94%] [G loss: 1.102662]\n",
      "epoch:21 step:20587 [D loss: 0.613235, acc.: 65.62%] [G loss: 1.274870]\n",
      "epoch:21 step:20588 [D loss: 0.427420, acc.: 87.50%] [G loss: 1.300426]\n",
      "epoch:21 step:20589 [D loss: 0.178674, acc.: 99.22%] [G loss: 1.518225]\n",
      "epoch:21 step:20590 [D loss: 0.774657, acc.: 49.22%] [G loss: 1.294989]\n",
      "epoch:21 step:20591 [D loss: 0.797279, acc.: 46.09%] [G loss: 1.157637]\n",
      "epoch:21 step:20592 [D loss: 0.696872, acc.: 58.59%] [G loss: 1.027957]\n",
      "epoch:21 step:20593 [D loss: 0.680120, acc.: 56.25%] [G loss: 0.859744]\n",
      "epoch:21 step:20594 [D loss: 0.615876, acc.: 65.62%] [G loss: 1.113469]\n",
      "epoch:21 step:20595 [D loss: 0.579652, acc.: 71.09%] [G loss: 1.099358]\n",
      "epoch:21 step:20596 [D loss: 0.559616, acc.: 71.88%] [G loss: 0.989705]\n",
      "epoch:21 step:20597 [D loss: 0.496257, acc.: 74.22%] [G loss: 1.114020]\n",
      "epoch:21 step:20598 [D loss: 0.452946, acc.: 82.81%] [G loss: 1.303990]\n",
      "epoch:21 step:20599 [D loss: 0.523033, acc.: 77.34%] [G loss: 1.380401]\n",
      "epoch:21 step:20600 [D loss: 0.599036, acc.: 66.41%] [G loss: 1.190993]\n",
      "epoch:21 step:20601 [D loss: 0.557584, acc.: 71.09%] [G loss: 1.068793]\n",
      "epoch:21 step:20602 [D loss: 0.444785, acc.: 83.59%] [G loss: 1.035572]\n",
      "epoch:21 step:20603 [D loss: 0.383742, acc.: 89.84%] [G loss: 1.320260]\n",
      "epoch:21 step:20604 [D loss: 0.285588, acc.: 96.09%] [G loss: 1.495304]\n",
      "epoch:21 step:20605 [D loss: 1.034466, acc.: 29.69%] [G loss: 0.990291]\n",
      "epoch:21 step:20606 [D loss: 0.344042, acc.: 89.84%] [G loss: 1.315134]\n",
      "epoch:21 step:20607 [D loss: 0.623681, acc.: 67.19%] [G loss: 1.203324]\n",
      "epoch:21 step:20608 [D loss: 0.626521, acc.: 60.94%] [G loss: 1.109163]\n",
      "epoch:21 step:20609 [D loss: 0.570702, acc.: 71.88%] [G loss: 1.120023]\n",
      "epoch:21 step:20610 [D loss: 0.456491, acc.: 85.16%] [G loss: 1.222454]\n",
      "epoch:21 step:20611 [D loss: 0.330476, acc.: 87.50%] [G loss: 1.173914]\n",
      "epoch:21 step:20612 [D loss: 0.653301, acc.: 60.16%] [G loss: 1.081300]\n",
      "epoch:21 step:20613 [D loss: 0.416525, acc.: 85.94%] [G loss: 1.429482]\n",
      "epoch:21 step:20614 [D loss: 0.140931, acc.: 98.44%] [G loss: 1.799448]\n",
      "epoch:22 step:20615 [D loss: 0.851739, acc.: 46.09%] [G loss: 1.159716]\n",
      "epoch:22 step:20616 [D loss: 0.706670, acc.: 57.81%] [G loss: 1.065106]\n",
      "epoch:22 step:20617 [D loss: 0.748516, acc.: 53.91%] [G loss: 0.934351]\n",
      "epoch:22 step:20618 [D loss: 0.677040, acc.: 58.59%] [G loss: 1.170323]\n",
      "epoch:22 step:20619 [D loss: 0.781784, acc.: 46.09%] [G loss: 1.044620]\n",
      "epoch:22 step:20620 [D loss: 0.627169, acc.: 64.84%] [G loss: 1.164220]\n",
      "epoch:22 step:20621 [D loss: 0.702990, acc.: 60.16%] [G loss: 1.180703]\n",
      "epoch:22 step:20622 [D loss: 0.514014, acc.: 77.34%] [G loss: 1.150337]\n",
      "epoch:22 step:20623 [D loss: 0.536253, acc.: 78.12%] [G loss: 1.329734]\n",
      "epoch:22 step:20624 [D loss: 0.420875, acc.: 82.03%] [G loss: 1.165420]\n",
      "epoch:22 step:20625 [D loss: 0.465640, acc.: 82.03%] [G loss: 1.142097]\n",
      "epoch:22 step:20626 [D loss: 0.529555, acc.: 72.66%] [G loss: 1.563539]\n",
      "epoch:22 step:20627 [D loss: 0.565797, acc.: 75.00%] [G loss: 1.354005]\n",
      "epoch:22 step:20628 [D loss: 0.568165, acc.: 75.00%] [G loss: 1.150262]\n",
      "epoch:22 step:20629 [D loss: 0.433503, acc.: 81.25%] [G loss: 1.170952]\n",
      "epoch:22 step:20630 [D loss: 0.368761, acc.: 93.75%] [G loss: 1.448761]\n",
      "epoch:22 step:20631 [D loss: 0.669670, acc.: 57.81%] [G loss: 1.160433]\n",
      "epoch:22 step:20632 [D loss: 0.843396, acc.: 42.97%] [G loss: 0.977874]\n",
      "epoch:22 step:20633 [D loss: 0.759099, acc.: 50.78%] [G loss: 0.900626]\n",
      "epoch:22 step:20634 [D loss: 0.642205, acc.: 64.84%] [G loss: 1.002223]\n",
      "epoch:22 step:20635 [D loss: 0.587275, acc.: 67.19%] [G loss: 1.438189]\n",
      "epoch:22 step:20636 [D loss: 0.649592, acc.: 63.28%] [G loss: 1.154871]\n",
      "epoch:22 step:20637 [D loss: 0.504477, acc.: 77.34%] [G loss: 1.169628]\n",
      "epoch:22 step:20638 [D loss: 0.600603, acc.: 65.62%] [G loss: 1.137221]\n",
      "epoch:22 step:20639 [D loss: 0.659715, acc.: 58.59%] [G loss: 0.891301]\n",
      "epoch:22 step:20640 [D loss: 0.516251, acc.: 78.12%] [G loss: 1.139763]\n",
      "epoch:22 step:20641 [D loss: 0.268647, acc.: 98.44%] [G loss: 1.479755]\n",
      "epoch:22 step:20642 [D loss: 0.372476, acc.: 89.84%] [G loss: 1.564086]\n",
      "epoch:22 step:20643 [D loss: 0.375677, acc.: 88.28%] [G loss: 1.635796]\n",
      "epoch:22 step:20644 [D loss: 0.336587, acc.: 90.62%] [G loss: 1.514339]\n",
      "epoch:22 step:20645 [D loss: 0.406195, acc.: 84.38%] [G loss: 1.278491]\n",
      "epoch:22 step:20646 [D loss: 0.243098, acc.: 98.44%] [G loss: 1.881556]\n",
      "epoch:22 step:20647 [D loss: 0.265832, acc.: 98.44%] [G loss: 1.890664]\n",
      "epoch:22 step:20648 [D loss: 0.350450, acc.: 89.06%] [G loss: 1.518180]\n",
      "epoch:22 step:20649 [D loss: 0.267957, acc.: 92.97%] [G loss: 1.643672]\n",
      "epoch:22 step:20650 [D loss: 0.189670, acc.: 96.88%] [G loss: 2.235077]\n",
      "epoch:22 step:20651 [D loss: 0.978683, acc.: 50.00%] [G loss: 1.341882]\n",
      "epoch:22 step:20652 [D loss: 1.044215, acc.: 34.38%] [G loss: 1.277051]\n",
      "epoch:22 step:20653 [D loss: 0.945258, acc.: 33.59%] [G loss: 1.106355]\n",
      "epoch:22 step:20654 [D loss: 0.745287, acc.: 54.69%] [G loss: 1.103086]\n",
      "epoch:22 step:20655 [D loss: 0.495634, acc.: 82.81%] [G loss: 1.313918]\n",
      "epoch:22 step:20656 [D loss: 0.756685, acc.: 51.56%] [G loss: 1.182832]\n",
      "epoch:22 step:20657 [D loss: 0.479815, acc.: 83.59%] [G loss: 1.446115]\n",
      "epoch:22 step:20658 [D loss: 0.610541, acc.: 60.94%] [G loss: 1.196652]\n",
      "epoch:22 step:20659 [D loss: 0.491016, acc.: 78.12%] [G loss: 1.522507]\n",
      "epoch:22 step:20660 [D loss: 0.708995, acc.: 53.91%] [G loss: 1.209435]\n",
      "epoch:22 step:20661 [D loss: 0.641340, acc.: 60.94%] [G loss: 0.947514]\n",
      "epoch:22 step:20662 [D loss: 0.812051, acc.: 43.75%] [G loss: 1.019308]\n",
      "epoch:22 step:20663 [D loss: 0.657500, acc.: 62.50%] [G loss: 0.926152]\n",
      "epoch:22 step:20664 [D loss: 0.676656, acc.: 60.94%] [G loss: 1.121106]\n",
      "epoch:22 step:20665 [D loss: 0.731746, acc.: 54.69%] [G loss: 0.863439]\n",
      "epoch:22 step:20666 [D loss: 0.657706, acc.: 60.16%] [G loss: 0.960693]\n",
      "epoch:22 step:20667 [D loss: 0.730653, acc.: 55.47%] [G loss: 0.844339]\n",
      "epoch:22 step:20668 [D loss: 0.502356, acc.: 75.00%] [G loss: 1.178367]\n",
      "epoch:22 step:20669 [D loss: 0.442995, acc.: 86.72%] [G loss: 1.304288]\n",
      "epoch:22 step:20670 [D loss: 0.565791, acc.: 70.31%] [G loss: 1.140982]\n",
      "epoch:22 step:20671 [D loss: 0.821019, acc.: 45.31%] [G loss: 0.998491]\n",
      "epoch:22 step:20672 [D loss: 0.661843, acc.: 61.72%] [G loss: 1.008499]\n",
      "epoch:22 step:20673 [D loss: 0.671177, acc.: 60.16%] [G loss: 0.893731]\n",
      "epoch:22 step:20674 [D loss: 0.741829, acc.: 53.12%] [G loss: 0.927343]\n",
      "epoch:22 step:20675 [D loss: 0.490597, acc.: 81.25%] [G loss: 1.177467]\n",
      "epoch:22 step:20676 [D loss: 0.560223, acc.: 74.22%] [G loss: 1.146277]\n",
      "epoch:22 step:20677 [D loss: 0.655832, acc.: 58.59%] [G loss: 1.100389]\n",
      "epoch:22 step:20678 [D loss: 0.661071, acc.: 60.94%] [G loss: 1.148728]\n",
      "epoch:22 step:20679 [D loss: 0.520502, acc.: 72.66%] [G loss: 1.078114]\n",
      "epoch:22 step:20680 [D loss: 0.564135, acc.: 72.66%] [G loss: 1.321639]\n",
      "epoch:22 step:20681 [D loss: 0.535518, acc.: 71.88%] [G loss: 1.231333]\n",
      "epoch:22 step:20682 [D loss: 0.623694, acc.: 60.16%] [G loss: 0.778439]\n",
      "epoch:22 step:20683 [D loss: 0.302523, acc.: 97.66%] [G loss: 1.564508]\n",
      "epoch:22 step:20684 [D loss: 0.469920, acc.: 78.91%] [G loss: 1.534104]\n",
      "epoch:22 step:20685 [D loss: 1.066816, acc.: 23.44%] [G loss: 1.004655]\n",
      "epoch:22 step:20686 [D loss: 0.861231, acc.: 37.50%] [G loss: 1.106032]\n",
      "epoch:22 step:20687 [D loss: 0.797798, acc.: 47.66%] [G loss: 1.109202]\n",
      "epoch:22 step:20688 [D loss: 0.636145, acc.: 61.72%] [G loss: 1.052223]\n",
      "epoch:22 step:20689 [D loss: 0.348967, acc.: 87.50%] [G loss: 1.426912]\n",
      "epoch:22 step:20690 [D loss: 0.513204, acc.: 75.00%] [G loss: 1.430753]\n",
      "epoch:22 step:20691 [D loss: 0.316415, acc.: 91.41%] [G loss: 1.723766]\n",
      "epoch:22 step:20692 [D loss: 0.640508, acc.: 60.16%] [G loss: 1.410710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20693 [D loss: 0.617578, acc.: 67.97%] [G loss: 1.349354]\n",
      "epoch:22 step:20694 [D loss: 0.605055, acc.: 65.62%] [G loss: 1.074624]\n",
      "epoch:22 step:20695 [D loss: 0.714085, acc.: 54.69%] [G loss: 0.920043]\n",
      "epoch:22 step:20696 [D loss: 0.665086, acc.: 60.94%] [G loss: 1.155696]\n",
      "epoch:22 step:20697 [D loss: 0.617369, acc.: 66.41%] [G loss: 1.024133]\n",
      "epoch:22 step:20698 [D loss: 0.724118, acc.: 53.91%] [G loss: 1.015477]\n",
      "epoch:22 step:20699 [D loss: 0.488191, acc.: 79.69%] [G loss: 0.915951]\n",
      "epoch:22 step:20700 [D loss: 0.671868, acc.: 56.25%] [G loss: 1.127369]\n",
      "epoch:22 step:20701 [D loss: 0.680279, acc.: 60.94%] [G loss: 0.956977]\n",
      "epoch:22 step:20702 [D loss: 0.571732, acc.: 70.31%] [G loss: 1.164396]\n",
      "epoch:22 step:20703 [D loss: 0.614827, acc.: 65.62%] [G loss: 1.203147]\n",
      "epoch:22 step:20704 [D loss: 0.698432, acc.: 58.59%] [G loss: 0.869058]\n",
      "epoch:22 step:20705 [D loss: 0.601827, acc.: 65.62%] [G loss: 0.956893]\n",
      "epoch:22 step:20706 [D loss: 0.715558, acc.: 57.03%] [G loss: 0.887702]\n",
      "epoch:22 step:20707 [D loss: 0.647606, acc.: 67.19%] [G loss: 1.004392]\n",
      "epoch:22 step:20708 [D loss: 0.621122, acc.: 65.62%] [G loss: 0.953652]\n",
      "epoch:22 step:20709 [D loss: 0.619748, acc.: 64.06%] [G loss: 1.057847]\n",
      "epoch:22 step:20710 [D loss: 0.581527, acc.: 72.66%] [G loss: 1.312843]\n",
      "epoch:22 step:20711 [D loss: 0.421700, acc.: 82.03%] [G loss: 1.266764]\n",
      "epoch:22 step:20712 [D loss: 0.482479, acc.: 82.81%] [G loss: 1.256412]\n",
      "epoch:22 step:20713 [D loss: 0.455135, acc.: 83.59%] [G loss: 1.154094]\n",
      "epoch:22 step:20714 [D loss: 0.632932, acc.: 61.72%] [G loss: 0.740159]\n",
      "epoch:22 step:20715 [D loss: 0.755999, acc.: 52.34%] [G loss: 1.247817]\n",
      "epoch:22 step:20716 [D loss: 0.597367, acc.: 68.75%] [G loss: 1.205828]\n",
      "epoch:22 step:20717 [D loss: 0.465261, acc.: 81.25%] [G loss: 1.172627]\n",
      "epoch:22 step:20718 [D loss: 0.952273, acc.: 33.59%] [G loss: 0.661283]\n",
      "epoch:22 step:20719 [D loss: 0.502265, acc.: 78.91%] [G loss: 0.891205]\n",
      "epoch:22 step:20720 [D loss: 0.646097, acc.: 66.41%] [G loss: 1.174462]\n",
      "epoch:22 step:20721 [D loss: 0.774180, acc.: 55.47%] [G loss: 1.112478]\n",
      "epoch:22 step:20722 [D loss: 0.838198, acc.: 45.31%] [G loss: 0.799681]\n",
      "epoch:22 step:20723 [D loss: 0.598160, acc.: 68.75%] [G loss: 1.092606]\n",
      "epoch:22 step:20724 [D loss: 0.709444, acc.: 56.25%] [G loss: 1.006593]\n",
      "epoch:22 step:20725 [D loss: 0.748646, acc.: 54.69%] [G loss: 1.023874]\n",
      "epoch:22 step:20726 [D loss: 0.673318, acc.: 57.03%] [G loss: 1.113560]\n",
      "epoch:22 step:20727 [D loss: 0.784807, acc.: 49.22%] [G loss: 1.048460]\n",
      "epoch:22 step:20728 [D loss: 0.718875, acc.: 54.69%] [G loss: 1.065343]\n",
      "epoch:22 step:20729 [D loss: 0.780315, acc.: 50.00%] [G loss: 0.643532]\n",
      "epoch:22 step:20730 [D loss: 0.541240, acc.: 75.78%] [G loss: 1.093389]\n",
      "epoch:22 step:20731 [D loss: 0.554796, acc.: 75.00%] [G loss: 1.160484]\n",
      "epoch:22 step:20732 [D loss: 0.576182, acc.: 69.53%] [G loss: 0.938460]\n",
      "epoch:22 step:20733 [D loss: 0.506576, acc.: 77.34%] [G loss: 1.224491]\n",
      "epoch:22 step:20734 [D loss: 0.591034, acc.: 67.19%] [G loss: 1.309683]\n",
      "epoch:22 step:20735 [D loss: 0.474835, acc.: 78.91%] [G loss: 1.163887]\n",
      "epoch:22 step:20736 [D loss: 0.290080, acc.: 93.75%] [G loss: 1.610610]\n",
      "epoch:22 step:20737 [D loss: 0.710055, acc.: 57.03%] [G loss: 1.191594]\n",
      "epoch:22 step:20738 [D loss: 0.714628, acc.: 55.47%] [G loss: 1.144007]\n",
      "epoch:22 step:20739 [D loss: 0.777173, acc.: 53.91%] [G loss: 0.967172]\n",
      "epoch:22 step:20740 [D loss: 0.652679, acc.: 59.38%] [G loss: 0.948467]\n",
      "epoch:22 step:20741 [D loss: 0.550633, acc.: 71.88%] [G loss: 1.186064]\n",
      "epoch:22 step:20742 [D loss: 0.601509, acc.: 64.06%] [G loss: 1.020718]\n",
      "epoch:22 step:20743 [D loss: 0.305435, acc.: 92.19%] [G loss: 1.348598]\n",
      "epoch:22 step:20744 [D loss: 0.243493, acc.: 95.31%] [G loss: 1.641535]\n",
      "epoch:22 step:20745 [D loss: 0.227014, acc.: 97.66%] [G loss: 1.892593]\n",
      "epoch:22 step:20746 [D loss: 0.271044, acc.: 96.88%] [G loss: 1.539004]\n",
      "epoch:22 step:20747 [D loss: 0.900523, acc.: 46.88%] [G loss: 1.173215]\n",
      "epoch:22 step:20748 [D loss: 0.695128, acc.: 55.47%] [G loss: 0.922893]\n",
      "epoch:22 step:20749 [D loss: 0.682000, acc.: 59.38%] [G loss: 1.148628]\n",
      "epoch:22 step:20750 [D loss: 0.632885, acc.: 62.50%] [G loss: 0.864876]\n",
      "epoch:22 step:20751 [D loss: 0.472888, acc.: 78.12%] [G loss: 1.118556]\n",
      "epoch:22 step:20752 [D loss: 0.493573, acc.: 74.22%] [G loss: 1.431366]\n",
      "epoch:22 step:20753 [D loss: 0.313391, acc.: 94.53%] [G loss: 1.394615]\n",
      "epoch:22 step:20754 [D loss: 1.224680, acc.: 18.75%] [G loss: 0.960847]\n",
      "epoch:22 step:20755 [D loss: 0.972871, acc.: 41.41%] [G loss: 0.991606]\n",
      "epoch:22 step:20756 [D loss: 0.879327, acc.: 42.97%] [G loss: 1.181565]\n",
      "epoch:22 step:20757 [D loss: 0.907652, acc.: 40.62%] [G loss: 0.995386]\n",
      "epoch:22 step:20758 [D loss: 0.705379, acc.: 56.25%] [G loss: 1.009730]\n",
      "epoch:22 step:20759 [D loss: 0.660737, acc.: 59.38%] [G loss: 1.146559]\n",
      "epoch:22 step:20760 [D loss: 0.696626, acc.: 54.69%] [G loss: 1.181668]\n",
      "epoch:22 step:20761 [D loss: 0.646191, acc.: 60.94%] [G loss: 1.057351]\n",
      "epoch:22 step:20762 [D loss: 0.703660, acc.: 60.94%] [G loss: 1.210323]\n",
      "epoch:22 step:20763 [D loss: 0.807035, acc.: 46.88%] [G loss: 1.141085]\n",
      "epoch:22 step:20764 [D loss: 0.395323, acc.: 84.38%] [G loss: 1.233281]\n",
      "epoch:22 step:20765 [D loss: 0.310159, acc.: 94.53%] [G loss: 1.662999]\n",
      "epoch:22 step:20766 [D loss: 0.288533, acc.: 96.09%] [G loss: 1.606215]\n",
      "epoch:22 step:20767 [D loss: 0.666966, acc.: 63.28%] [G loss: 1.380067]\n",
      "epoch:22 step:20768 [D loss: 0.560203, acc.: 71.09%] [G loss: 1.287111]\n",
      "epoch:22 step:20769 [D loss: 0.607818, acc.: 66.41%] [G loss: 1.001884]\n",
      "epoch:22 step:20770 [D loss: 0.809766, acc.: 49.22%] [G loss: 0.788416]\n",
      "epoch:22 step:20771 [D loss: 0.822547, acc.: 41.41%] [G loss: 0.939845]\n",
      "epoch:22 step:20772 [D loss: 0.572195, acc.: 72.66%] [G loss: 1.381659]\n",
      "epoch:22 step:20773 [D loss: 0.608687, acc.: 72.66%] [G loss: 0.917422]\n",
      "epoch:22 step:20774 [D loss: 0.674627, acc.: 54.69%] [G loss: 1.151873]\n",
      "epoch:22 step:20775 [D loss: 0.595946, acc.: 64.84%] [G loss: 1.066741]\n",
      "epoch:22 step:20776 [D loss: 0.520681, acc.: 73.44%] [G loss: 1.137125]\n",
      "epoch:22 step:20777 [D loss: 0.899620, acc.: 38.28%] [G loss: 0.916871]\n",
      "epoch:22 step:20778 [D loss: 0.737144, acc.: 52.34%] [G loss: 1.090284]\n",
      "epoch:22 step:20779 [D loss: 0.717183, acc.: 55.47%] [G loss: 1.341570]\n",
      "epoch:22 step:20780 [D loss: 0.621417, acc.: 64.84%] [G loss: 1.077057]\n",
      "epoch:22 step:20781 [D loss: 0.556242, acc.: 77.34%] [G loss: 1.128118]\n",
      "epoch:22 step:20782 [D loss: 0.663911, acc.: 58.59%] [G loss: 0.973404]\n",
      "epoch:22 step:20783 [D loss: 0.527812, acc.: 75.00%] [G loss: 1.003872]\n",
      "epoch:22 step:20784 [D loss: 0.551177, acc.: 75.00%] [G loss: 0.994422]\n",
      "epoch:22 step:20785 [D loss: 0.735631, acc.: 53.91%] [G loss: 0.839724]\n",
      "epoch:22 step:20786 [D loss: 0.643169, acc.: 64.06%] [G loss: 1.030038]\n",
      "epoch:22 step:20787 [D loss: 0.760350, acc.: 51.56%] [G loss: 1.164953]\n",
      "epoch:22 step:20788 [D loss: 0.782839, acc.: 46.88%] [G loss: 0.946494]\n",
      "epoch:22 step:20789 [D loss: 0.731975, acc.: 52.34%] [G loss: 1.036331]\n",
      "epoch:22 step:20790 [D loss: 0.655768, acc.: 60.94%] [G loss: 0.916771]\n",
      "epoch:22 step:20791 [D loss: 0.702503, acc.: 53.91%] [G loss: 0.970778]\n",
      "epoch:22 step:20792 [D loss: 0.653171, acc.: 57.81%] [G loss: 1.045007]\n",
      "epoch:22 step:20793 [D loss: 0.761758, acc.: 43.75%] [G loss: 0.896350]\n",
      "epoch:22 step:20794 [D loss: 0.675786, acc.: 59.38%] [G loss: 1.050404]\n",
      "epoch:22 step:20795 [D loss: 0.727455, acc.: 56.25%] [G loss: 1.066459]\n",
      "epoch:22 step:20796 [D loss: 0.562174, acc.: 71.88%] [G loss: 0.964321]\n",
      "epoch:22 step:20797 [D loss: 0.751639, acc.: 47.66%] [G loss: 1.045782]\n",
      "epoch:22 step:20798 [D loss: 0.611416, acc.: 66.41%] [G loss: 0.947031]\n",
      "epoch:22 step:20799 [D loss: 0.634517, acc.: 62.50%] [G loss: 1.269124]\n",
      "epoch:22 step:20800 [D loss: 0.585139, acc.: 67.97%] [G loss: 1.117799]\n",
      "epoch:22 step:20801 [D loss: 0.714186, acc.: 52.34%] [G loss: 0.853769]\n",
      "epoch:22 step:20802 [D loss: 0.600524, acc.: 64.06%] [G loss: 1.025181]\n",
      "epoch:22 step:20803 [D loss: 0.699866, acc.: 56.25%] [G loss: 0.900586]\n",
      "epoch:22 step:20804 [D loss: 0.390161, acc.: 89.84%] [G loss: 1.217266]\n",
      "epoch:22 step:20805 [D loss: 0.565933, acc.: 70.31%] [G loss: 0.842001]\n",
      "epoch:22 step:20806 [D loss: 0.384279, acc.: 84.38%] [G loss: 1.393327]\n",
      "epoch:22 step:20807 [D loss: 0.411988, acc.: 85.16%] [G loss: 1.256913]\n",
      "epoch:22 step:20808 [D loss: 0.459125, acc.: 81.25%] [G loss: 1.159555]\n",
      "epoch:22 step:20809 [D loss: 0.522778, acc.: 73.44%] [G loss: 1.485755]\n",
      "epoch:22 step:20810 [D loss: 0.849125, acc.: 39.84%] [G loss: 0.888281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20811 [D loss: 0.417224, acc.: 85.94%] [G loss: 1.212630]\n",
      "epoch:22 step:20812 [D loss: 0.580961, acc.: 68.75%] [G loss: 0.908582]\n",
      "epoch:22 step:20813 [D loss: 0.808704, acc.: 48.44%] [G loss: 1.016695]\n",
      "epoch:22 step:20814 [D loss: 0.815672, acc.: 45.31%] [G loss: 1.226393]\n",
      "epoch:22 step:20815 [D loss: 0.845635, acc.: 39.06%] [G loss: 0.845027]\n",
      "epoch:22 step:20816 [D loss: 0.841808, acc.: 44.53%] [G loss: 0.864230]\n",
      "epoch:22 step:20817 [D loss: 0.702233, acc.: 53.12%] [G loss: 0.882853]\n",
      "epoch:22 step:20818 [D loss: 0.446521, acc.: 84.38%] [G loss: 1.597554]\n",
      "epoch:22 step:20819 [D loss: 0.516016, acc.: 73.44%] [G loss: 1.317774]\n",
      "epoch:22 step:20820 [D loss: 0.525272, acc.: 75.78%] [G loss: 0.795936]\n",
      "epoch:22 step:20821 [D loss: 0.406797, acc.: 78.91%] [G loss: 1.387243]\n",
      "epoch:22 step:20822 [D loss: 0.578439, acc.: 64.84%] [G loss: 1.429973]\n",
      "epoch:22 step:20823 [D loss: 0.588884, acc.: 65.62%] [G loss: 0.894847]\n",
      "epoch:22 step:20824 [D loss: 0.715417, acc.: 55.47%] [G loss: 1.266486]\n",
      "epoch:22 step:20825 [D loss: 0.890007, acc.: 44.53%] [G loss: 1.192752]\n",
      "epoch:22 step:20826 [D loss: 0.672422, acc.: 57.81%] [G loss: 0.968884]\n",
      "epoch:22 step:20827 [D loss: 0.662505, acc.: 56.25%] [G loss: 0.943151]\n",
      "epoch:22 step:20828 [D loss: 0.891919, acc.: 35.16%] [G loss: 0.697833]\n",
      "epoch:22 step:20829 [D loss: 0.764849, acc.: 46.88%] [G loss: 0.929102]\n",
      "epoch:22 step:20830 [D loss: 0.526210, acc.: 76.56%] [G loss: 1.073053]\n",
      "epoch:22 step:20831 [D loss: 0.738317, acc.: 50.00%] [G loss: 0.769291]\n",
      "epoch:22 step:20832 [D loss: 0.474707, acc.: 82.03%] [G loss: 1.138634]\n",
      "epoch:22 step:20833 [D loss: 0.531590, acc.: 69.53%] [G loss: 1.220396]\n",
      "epoch:22 step:20834 [D loss: 0.476753, acc.: 82.03%] [G loss: 1.200521]\n",
      "epoch:22 step:20835 [D loss: 0.278350, acc.: 95.31%] [G loss: 1.644727]\n",
      "epoch:22 step:20836 [D loss: 0.371933, acc.: 89.06%] [G loss: 1.464765]\n",
      "epoch:22 step:20837 [D loss: 0.302770, acc.: 96.09%] [G loss: 1.517979]\n",
      "epoch:22 step:20838 [D loss: 0.922464, acc.: 52.34%] [G loss: 1.337550]\n",
      "epoch:22 step:20839 [D loss: 0.736291, acc.: 51.56%] [G loss: 1.137113]\n",
      "epoch:22 step:20840 [D loss: 0.483335, acc.: 79.69%] [G loss: 1.227551]\n",
      "epoch:22 step:20841 [D loss: 0.588562, acc.: 69.53%] [G loss: 1.155420]\n",
      "epoch:22 step:20842 [D loss: 0.477302, acc.: 78.12%] [G loss: 1.325157]\n",
      "epoch:22 step:20843 [D loss: 0.372376, acc.: 89.84%] [G loss: 1.411964]\n",
      "epoch:22 step:20844 [D loss: 0.208907, acc.: 93.75%] [G loss: 1.532473]\n",
      "epoch:22 step:20845 [D loss: 0.255672, acc.: 93.75%] [G loss: 1.607330]\n",
      "epoch:22 step:20846 [D loss: 0.312780, acc.: 88.28%] [G loss: 1.788686]\n",
      "epoch:22 step:20847 [D loss: 0.776950, acc.: 53.91%] [G loss: 1.481614]\n",
      "epoch:22 step:20848 [D loss: 0.714321, acc.: 57.03%] [G loss: 1.097590]\n",
      "epoch:22 step:20849 [D loss: 0.310629, acc.: 95.31%] [G loss: 1.323184]\n",
      "epoch:22 step:20850 [D loss: 0.536869, acc.: 75.78%] [G loss: 1.351043]\n",
      "epoch:22 step:20851 [D loss: 0.489193, acc.: 80.47%] [G loss: 1.152921]\n",
      "epoch:22 step:20852 [D loss: 0.525955, acc.: 77.34%] [G loss: 1.077167]\n",
      "epoch:22 step:20853 [D loss: 0.795987, acc.: 46.09%] [G loss: 1.149857]\n",
      "epoch:22 step:20854 [D loss: 0.808082, acc.: 49.22%] [G loss: 0.998961]\n",
      "epoch:22 step:20855 [D loss: 0.950635, acc.: 35.94%] [G loss: 1.020163]\n",
      "epoch:22 step:20856 [D loss: 0.622978, acc.: 64.84%] [G loss: 1.283908]\n",
      "epoch:22 step:20857 [D loss: 0.577476, acc.: 67.19%] [G loss: 1.016874]\n",
      "epoch:22 step:20858 [D loss: 0.875710, acc.: 37.50%] [G loss: 0.864796]\n",
      "epoch:22 step:20859 [D loss: 0.730456, acc.: 53.12%] [G loss: 0.891514]\n",
      "epoch:22 step:20860 [D loss: 0.726675, acc.: 52.34%] [G loss: 0.842591]\n",
      "epoch:22 step:20861 [D loss: 0.665022, acc.: 60.16%] [G loss: 0.999563]\n",
      "epoch:22 step:20862 [D loss: 0.607963, acc.: 66.41%] [G loss: 1.023789]\n",
      "epoch:22 step:20863 [D loss: 0.618179, acc.: 67.19%] [G loss: 1.070867]\n",
      "epoch:22 step:20864 [D loss: 0.719313, acc.: 55.47%] [G loss: 1.178820]\n",
      "epoch:22 step:20865 [D loss: 0.752502, acc.: 53.12%] [G loss: 0.997398]\n",
      "epoch:22 step:20866 [D loss: 0.609313, acc.: 70.31%] [G loss: 1.077347]\n",
      "epoch:22 step:20867 [D loss: 0.573526, acc.: 68.75%] [G loss: 1.104275]\n",
      "epoch:22 step:20868 [D loss: 0.590035, acc.: 70.31%] [G loss: 1.182352]\n",
      "epoch:22 step:20869 [D loss: 0.768070, acc.: 45.31%] [G loss: 0.951431]\n",
      "epoch:22 step:20870 [D loss: 0.686368, acc.: 56.25%] [G loss: 1.099711]\n",
      "epoch:22 step:20871 [D loss: 0.625841, acc.: 63.28%] [G loss: 1.182563]\n",
      "epoch:22 step:20872 [D loss: 0.600716, acc.: 64.84%] [G loss: 1.029713]\n",
      "epoch:22 step:20873 [D loss: 0.533880, acc.: 76.56%] [G loss: 0.890232]\n",
      "epoch:22 step:20874 [D loss: 0.550496, acc.: 75.78%] [G loss: 1.181069]\n",
      "epoch:22 step:20875 [D loss: 0.588339, acc.: 67.97%] [G loss: 1.157211]\n",
      "epoch:22 step:20876 [D loss: 0.621855, acc.: 66.41%] [G loss: 1.289844]\n",
      "epoch:22 step:20877 [D loss: 0.681725, acc.: 62.50%] [G loss: 0.872786]\n",
      "epoch:22 step:20878 [D loss: 0.478518, acc.: 82.81%] [G loss: 1.140795]\n",
      "epoch:22 step:20879 [D loss: 0.701767, acc.: 60.16%] [G loss: 1.130304]\n",
      "epoch:22 step:20880 [D loss: 0.804305, acc.: 42.19%] [G loss: 1.194637]\n",
      "epoch:22 step:20881 [D loss: 0.628454, acc.: 61.72%] [G loss: 0.956155]\n",
      "epoch:22 step:20882 [D loss: 0.736606, acc.: 51.56%] [G loss: 1.088938]\n",
      "epoch:22 step:20883 [D loss: 0.505272, acc.: 77.34%] [G loss: 1.148729]\n",
      "epoch:22 step:20884 [D loss: 0.697332, acc.: 53.91%] [G loss: 1.292002]\n",
      "epoch:22 step:20885 [D loss: 0.549127, acc.: 75.00%] [G loss: 0.871615]\n",
      "epoch:22 step:20886 [D loss: 0.337678, acc.: 89.84%] [G loss: 1.190172]\n",
      "epoch:22 step:20887 [D loss: 0.516837, acc.: 75.78%] [G loss: 1.097892]\n",
      "epoch:22 step:20888 [D loss: 0.556298, acc.: 71.09%] [G loss: 1.218883]\n",
      "epoch:22 step:20889 [D loss: 0.701100, acc.: 55.47%] [G loss: 1.002331]\n",
      "epoch:22 step:20890 [D loss: 0.527651, acc.: 78.12%] [G loss: 1.034256]\n",
      "epoch:22 step:20891 [D loss: 0.864044, acc.: 37.50%] [G loss: 0.977888]\n",
      "epoch:22 step:20892 [D loss: 0.717535, acc.: 58.59%] [G loss: 1.025707]\n",
      "epoch:22 step:20893 [D loss: 0.438089, acc.: 78.91%] [G loss: 1.309174]\n",
      "epoch:22 step:20894 [D loss: 0.525814, acc.: 79.69%] [G loss: 1.207502]\n",
      "epoch:22 step:20895 [D loss: 0.742939, acc.: 53.12%] [G loss: 1.144418]\n",
      "epoch:22 step:20896 [D loss: 0.656346, acc.: 60.94%] [G loss: 1.217895]\n",
      "epoch:22 step:20897 [D loss: 0.668121, acc.: 62.50%] [G loss: 0.984764]\n",
      "epoch:22 step:20898 [D loss: 0.465588, acc.: 82.81%] [G loss: 1.112847]\n",
      "epoch:22 step:20899 [D loss: 0.448887, acc.: 82.03%] [G loss: 1.127041]\n",
      "epoch:22 step:20900 [D loss: 0.336646, acc.: 89.06%] [G loss: 1.403209]\n",
      "epoch:22 step:20901 [D loss: 0.668895, acc.: 61.72%] [G loss: 1.054054]\n",
      "epoch:22 step:20902 [D loss: 0.589975, acc.: 66.41%] [G loss: 1.180475]\n",
      "epoch:22 step:20903 [D loss: 0.424392, acc.: 85.94%] [G loss: 1.231247]\n",
      "epoch:22 step:20904 [D loss: 0.587595, acc.: 69.53%] [G loss: 1.312098]\n",
      "epoch:22 step:20905 [D loss: 0.410929, acc.: 85.16%] [G loss: 1.217958]\n",
      "epoch:22 step:20906 [D loss: 0.448004, acc.: 82.03%] [G loss: 1.213227]\n",
      "epoch:22 step:20907 [D loss: 0.528972, acc.: 76.56%] [G loss: 0.849967]\n",
      "epoch:22 step:20908 [D loss: 0.529620, acc.: 74.22%] [G loss: 1.092632]\n",
      "epoch:22 step:20909 [D loss: 0.875573, acc.: 32.81%] [G loss: 0.900099]\n",
      "epoch:22 step:20910 [D loss: 0.638531, acc.: 63.28%] [G loss: 0.957053]\n",
      "epoch:22 step:20911 [D loss: 0.620265, acc.: 60.16%] [G loss: 1.112992]\n",
      "epoch:22 step:20912 [D loss: 0.741572, acc.: 52.34%] [G loss: 0.924602]\n",
      "epoch:22 step:20913 [D loss: 0.609621, acc.: 64.06%] [G loss: 1.307618]\n",
      "epoch:22 step:20914 [D loss: 0.598721, acc.: 66.41%] [G loss: 1.092594]\n",
      "epoch:22 step:20915 [D loss: 0.626045, acc.: 63.28%] [G loss: 1.038078]\n",
      "epoch:22 step:20916 [D loss: 0.665050, acc.: 56.25%] [G loss: 0.809875]\n",
      "epoch:22 step:20917 [D loss: 0.665145, acc.: 60.16%] [G loss: 1.033798]\n",
      "epoch:22 step:20918 [D loss: 0.518185, acc.: 81.25%] [G loss: 1.008757]\n",
      "epoch:22 step:20919 [D loss: 0.557863, acc.: 76.56%] [G loss: 1.108976]\n",
      "epoch:22 step:20920 [D loss: 0.686337, acc.: 56.25%] [G loss: 1.054873]\n",
      "epoch:22 step:20921 [D loss: 0.736627, acc.: 48.44%] [G loss: 1.128329]\n",
      "epoch:22 step:20922 [D loss: 0.448575, acc.: 84.38%] [G loss: 1.055869]\n",
      "epoch:22 step:20923 [D loss: 0.493789, acc.: 78.12%] [G loss: 1.243066]\n",
      "epoch:22 step:20924 [D loss: 0.612747, acc.: 69.53%] [G loss: 1.332163]\n",
      "epoch:22 step:20925 [D loss: 0.395958, acc.: 87.50%] [G loss: 1.217484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20926 [D loss: 0.370186, acc.: 87.50%] [G loss: 1.129286]\n",
      "epoch:22 step:20927 [D loss: 0.377449, acc.: 87.50%] [G loss: 1.552472]\n",
      "epoch:22 step:20928 [D loss: 0.455971, acc.: 82.03%] [G loss: 1.065172]\n",
      "epoch:22 step:20929 [D loss: 0.539122, acc.: 75.78%] [G loss: 1.248650]\n",
      "epoch:22 step:20930 [D loss: 0.801389, acc.: 49.22%] [G loss: 1.274353]\n",
      "epoch:22 step:20931 [D loss: 0.766888, acc.: 46.88%] [G loss: 0.947062]\n",
      "epoch:22 step:20932 [D loss: 0.666090, acc.: 58.59%] [G loss: 1.257867]\n",
      "epoch:22 step:20933 [D loss: 0.687301, acc.: 60.94%] [G loss: 1.150468]\n",
      "epoch:22 step:20934 [D loss: 0.552305, acc.: 72.66%] [G loss: 1.055022]\n",
      "epoch:22 step:20935 [D loss: 0.429792, acc.: 89.06%] [G loss: 1.313647]\n",
      "epoch:22 step:20936 [D loss: 0.486304, acc.: 82.03%] [G loss: 1.167657]\n",
      "epoch:22 step:20937 [D loss: 0.785787, acc.: 51.56%] [G loss: 1.142058]\n",
      "epoch:22 step:20938 [D loss: 0.560014, acc.: 75.78%] [G loss: 1.202081]\n",
      "epoch:22 step:20939 [D loss: 0.685678, acc.: 55.47%] [G loss: 1.011354]\n",
      "epoch:22 step:20940 [D loss: 0.552108, acc.: 69.53%] [G loss: 1.103225]\n",
      "epoch:22 step:20941 [D loss: 0.326102, acc.: 86.72%] [G loss: 1.150687]\n",
      "epoch:22 step:20942 [D loss: 0.297939, acc.: 96.88%] [G loss: 1.534716]\n",
      "epoch:22 step:20943 [D loss: 0.703884, acc.: 57.03%] [G loss: 1.516103]\n",
      "epoch:22 step:20944 [D loss: 0.794939, acc.: 51.56%] [G loss: 1.113436]\n",
      "epoch:22 step:20945 [D loss: 0.818325, acc.: 41.41%] [G loss: 1.160193]\n",
      "epoch:22 step:20946 [D loss: 0.635373, acc.: 59.38%] [G loss: 1.202653]\n",
      "epoch:22 step:20947 [D loss: 0.782602, acc.: 52.34%] [G loss: 0.774333]\n",
      "epoch:22 step:20948 [D loss: 0.686936, acc.: 54.69%] [G loss: 0.907385]\n",
      "epoch:22 step:20949 [D loss: 0.933087, acc.: 34.38%] [G loss: 0.840973]\n",
      "epoch:22 step:20950 [D loss: 0.480105, acc.: 82.81%] [G loss: 1.210450]\n",
      "epoch:22 step:20951 [D loss: 0.731198, acc.: 52.34%] [G loss: 0.874277]\n",
      "epoch:22 step:20952 [D loss: 0.659382, acc.: 56.25%] [G loss: 0.979976]\n",
      "epoch:22 step:20953 [D loss: 0.705096, acc.: 54.69%] [G loss: 0.905087]\n",
      "epoch:22 step:20954 [D loss: 0.728639, acc.: 48.44%] [G loss: 1.182764]\n",
      "epoch:22 step:20955 [D loss: 0.732107, acc.: 47.66%] [G loss: 0.875584]\n",
      "epoch:22 step:20956 [D loss: 0.479602, acc.: 82.03%] [G loss: 1.130340]\n",
      "epoch:22 step:20957 [D loss: 0.417857, acc.: 84.38%] [G loss: 1.523373]\n",
      "epoch:22 step:20958 [D loss: 0.408837, acc.: 84.38%] [G loss: 1.403098]\n",
      "epoch:22 step:20959 [D loss: 0.270093, acc.: 94.53%] [G loss: 1.383980]\n",
      "epoch:22 step:20960 [D loss: 0.230051, acc.: 98.44%] [G loss: 1.706519]\n",
      "epoch:22 step:20961 [D loss: 0.235933, acc.: 96.88%] [G loss: 1.696513]\n",
      "epoch:22 step:20962 [D loss: 0.661490, acc.: 61.72%] [G loss: 1.626894]\n",
      "epoch:22 step:20963 [D loss: 0.916870, acc.: 41.41%] [G loss: 1.307570]\n",
      "epoch:22 step:20964 [D loss: 0.782945, acc.: 44.53%] [G loss: 1.052596]\n",
      "epoch:22 step:20965 [D loss: 0.708764, acc.: 53.12%] [G loss: 0.965836]\n",
      "epoch:22 step:20966 [D loss: 0.572936, acc.: 71.09%] [G loss: 1.113231]\n",
      "epoch:22 step:20967 [D loss: 0.558473, acc.: 69.53%] [G loss: 1.179147]\n",
      "epoch:22 step:20968 [D loss: 0.563572, acc.: 71.09%] [G loss: 0.980161]\n",
      "epoch:22 step:20969 [D loss: 0.813860, acc.: 39.06%] [G loss: 1.013519]\n",
      "epoch:22 step:20970 [D loss: 0.652750, acc.: 57.81%] [G loss: 0.943203]\n",
      "epoch:22 step:20971 [D loss: 0.683346, acc.: 58.59%] [G loss: 0.847657]\n",
      "epoch:22 step:20972 [D loss: 0.497247, acc.: 78.91%] [G loss: 1.031642]\n",
      "epoch:22 step:20973 [D loss: 0.507517, acc.: 73.44%] [G loss: 1.072623]\n",
      "epoch:22 step:20974 [D loss: 0.502758, acc.: 84.38%] [G loss: 1.223516]\n",
      "epoch:22 step:20975 [D loss: 0.627952, acc.: 58.59%] [G loss: 1.231768]\n",
      "epoch:22 step:20976 [D loss: 0.687129, acc.: 60.94%] [G loss: 1.172589]\n",
      "epoch:22 step:20977 [D loss: 0.623813, acc.: 66.41%] [G loss: 1.002286]\n",
      "epoch:22 step:20978 [D loss: 0.656662, acc.: 62.50%] [G loss: 0.962378]\n",
      "epoch:22 step:20979 [D loss: 0.535280, acc.: 75.78%] [G loss: 1.042187]\n",
      "epoch:22 step:20980 [D loss: 0.373767, acc.: 88.28%] [G loss: 1.355433]\n",
      "epoch:22 step:20981 [D loss: 0.316745, acc.: 91.41%] [G loss: 1.365409]\n",
      "epoch:22 step:20982 [D loss: 0.501120, acc.: 78.12%] [G loss: 1.388343]\n",
      "epoch:22 step:20983 [D loss: 0.606295, acc.: 69.53%] [G loss: 1.173790]\n",
      "epoch:22 step:20984 [D loss: 0.576458, acc.: 68.75%] [G loss: 1.007518]\n",
      "epoch:22 step:20985 [D loss: 0.578335, acc.: 69.53%] [G loss: 1.271916]\n",
      "epoch:22 step:20986 [D loss: 0.626513, acc.: 66.41%] [G loss: 1.022000]\n",
      "epoch:22 step:20987 [D loss: 0.733302, acc.: 48.44%] [G loss: 0.984345]\n",
      "epoch:22 step:20988 [D loss: 0.712691, acc.: 57.81%] [G loss: 0.706631]\n",
      "epoch:22 step:20989 [D loss: 0.730314, acc.: 53.12%] [G loss: 0.988779]\n",
      "epoch:22 step:20990 [D loss: 0.616913, acc.: 66.41%] [G loss: 1.020109]\n",
      "epoch:22 step:20991 [D loss: 0.552420, acc.: 71.09%] [G loss: 1.116046]\n",
      "epoch:22 step:20992 [D loss: 0.442069, acc.: 78.12%] [G loss: 1.325227]\n",
      "epoch:22 step:20993 [D loss: 0.641008, acc.: 63.28%] [G loss: 1.292945]\n",
      "epoch:22 step:20994 [D loss: 0.604291, acc.: 66.41%] [G loss: 0.921663]\n",
      "epoch:22 step:20995 [D loss: 0.546727, acc.: 74.22%] [G loss: 1.063662]\n",
      "epoch:22 step:20996 [D loss: 0.613216, acc.: 64.06%] [G loss: 1.054970]\n",
      "epoch:22 step:20997 [D loss: 0.595585, acc.: 72.66%] [G loss: 0.867742]\n",
      "epoch:22 step:20998 [D loss: 0.604967, acc.: 67.19%] [G loss: 1.046336]\n",
      "epoch:22 step:20999 [D loss: 0.560389, acc.: 72.66%] [G loss: 0.994238]\n",
      "epoch:22 step:21000 [D loss: 0.693837, acc.: 55.47%] [G loss: 1.207743]\n",
      "epoch:22 step:21001 [D loss: 0.594639, acc.: 62.50%] [G loss: 1.161165]\n",
      "epoch:22 step:21002 [D loss: 0.624297, acc.: 64.84%] [G loss: 0.926201]\n",
      "epoch:22 step:21003 [D loss: 0.618829, acc.: 64.06%] [G loss: 0.957912]\n",
      "epoch:22 step:21004 [D loss: 0.490911, acc.: 75.78%] [G loss: 0.984990]\n",
      "epoch:22 step:21005 [D loss: 0.497549, acc.: 80.47%] [G loss: 1.059225]\n",
      "epoch:22 step:21006 [D loss: 0.609979, acc.: 70.31%] [G loss: 1.095652]\n",
      "epoch:22 step:21007 [D loss: 0.521653, acc.: 73.44%] [G loss: 1.151231]\n",
      "epoch:22 step:21008 [D loss: 0.541253, acc.: 75.78%] [G loss: 1.143706]\n",
      "epoch:22 step:21009 [D loss: 0.544348, acc.: 71.09%] [G loss: 1.249561]\n",
      "epoch:22 step:21010 [D loss: 0.401068, acc.: 82.03%] [G loss: 1.242586]\n",
      "epoch:22 step:21011 [D loss: 0.301506, acc.: 89.06%] [G loss: 1.303793]\n",
      "epoch:22 step:21012 [D loss: 0.232786, acc.: 98.44%] [G loss: 1.885246]\n",
      "epoch:22 step:21013 [D loss: 0.260844, acc.: 96.09%] [G loss: 2.193429]\n",
      "epoch:22 step:21014 [D loss: 0.369739, acc.: 91.41%] [G loss: 1.696305]\n",
      "epoch:22 step:21015 [D loss: 0.488711, acc.: 79.69%] [G loss: 1.266343]\n",
      "epoch:22 step:21016 [D loss: 0.414736, acc.: 87.50%] [G loss: 1.366615]\n",
      "epoch:22 step:21017 [D loss: 0.594348, acc.: 71.88%] [G loss: 1.442390]\n",
      "epoch:22 step:21018 [D loss: 0.285714, acc.: 95.31%] [G loss: 1.562937]\n",
      "epoch:22 step:21019 [D loss: 0.406234, acc.: 82.81%] [G loss: 1.376897]\n",
      "epoch:22 step:21020 [D loss: 0.568374, acc.: 71.88%] [G loss: 1.303260]\n",
      "epoch:22 step:21021 [D loss: 0.576862, acc.: 67.97%] [G loss: 1.790179]\n",
      "epoch:22 step:21022 [D loss: 0.545827, acc.: 74.22%] [G loss: 1.465929]\n",
      "epoch:22 step:21023 [D loss: 0.695505, acc.: 53.91%] [G loss: 0.759452]\n",
      "epoch:22 step:21024 [D loss: 0.586760, acc.: 67.97%] [G loss: 1.202906]\n",
      "epoch:22 step:21025 [D loss: 0.998613, acc.: 30.47%] [G loss: 0.697184]\n",
      "epoch:22 step:21026 [D loss: 0.911836, acc.: 42.19%] [G loss: 0.770743]\n",
      "epoch:22 step:21027 [D loss: 0.834484, acc.: 45.31%] [G loss: 0.886190]\n",
      "epoch:22 step:21028 [D loss: 0.743359, acc.: 50.78%] [G loss: 0.823052]\n",
      "epoch:22 step:21029 [D loss: 0.895495, acc.: 40.62%] [G loss: 1.166619]\n",
      "epoch:22 step:21030 [D loss: 0.731492, acc.: 54.69%] [G loss: 0.942817]\n",
      "epoch:22 step:21031 [D loss: 0.979096, acc.: 28.91%] [G loss: 1.134757]\n",
      "epoch:22 step:21032 [D loss: 0.616511, acc.: 66.41%] [G loss: 1.300196]\n",
      "epoch:22 step:21033 [D loss: 0.665875, acc.: 60.16%] [G loss: 1.199117]\n",
      "epoch:22 step:21034 [D loss: 0.546823, acc.: 71.09%] [G loss: 1.411525]\n",
      "epoch:22 step:21035 [D loss: 0.687160, acc.: 56.25%] [G loss: 1.166987]\n",
      "epoch:22 step:21036 [D loss: 0.785175, acc.: 50.00%] [G loss: 1.233966]\n",
      "epoch:22 step:21037 [D loss: 0.814525, acc.: 46.88%] [G loss: 1.113535]\n",
      "epoch:22 step:21038 [D loss: 0.608893, acc.: 64.06%] [G loss: 1.251821]\n",
      "epoch:22 step:21039 [D loss: 0.710531, acc.: 57.81%] [G loss: 1.176285]\n",
      "epoch:22 step:21040 [D loss: 0.544724, acc.: 75.78%] [G loss: 1.098109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21041 [D loss: 0.549768, acc.: 71.88%] [G loss: 1.196420]\n",
      "epoch:22 step:21042 [D loss: 0.545821, acc.: 72.66%] [G loss: 1.362612]\n",
      "epoch:22 step:21043 [D loss: 0.574265, acc.: 68.75%] [G loss: 1.366597]\n",
      "epoch:22 step:21044 [D loss: 0.466552, acc.: 82.03%] [G loss: 1.412692]\n",
      "epoch:22 step:21045 [D loss: 0.627028, acc.: 66.41%] [G loss: 1.205927]\n",
      "epoch:22 step:21046 [D loss: 0.520649, acc.: 77.34%] [G loss: 1.348856]\n",
      "epoch:22 step:21047 [D loss: 0.668624, acc.: 57.81%] [G loss: 1.076411]\n",
      "epoch:22 step:21048 [D loss: 0.577155, acc.: 71.88%] [G loss: 0.956160]\n",
      "epoch:22 step:21049 [D loss: 0.608128, acc.: 69.53%] [G loss: 1.305130]\n",
      "epoch:22 step:21050 [D loss: 0.499314, acc.: 78.12%] [G loss: 1.544859]\n",
      "epoch:22 step:21051 [D loss: 0.886126, acc.: 40.62%] [G loss: 1.124206]\n",
      "epoch:22 step:21052 [D loss: 0.652242, acc.: 62.50%] [G loss: 1.180097]\n",
      "epoch:22 step:21053 [D loss: 0.715691, acc.: 52.34%] [G loss: 1.045236]\n",
      "epoch:22 step:21054 [D loss: 0.671352, acc.: 64.06%] [G loss: 0.945450]\n",
      "epoch:22 step:21055 [D loss: 0.592906, acc.: 68.75%] [G loss: 1.319267]\n",
      "epoch:22 step:21056 [D loss: 0.762873, acc.: 53.12%] [G loss: 1.164202]\n",
      "epoch:22 step:21057 [D loss: 0.574748, acc.: 72.66%] [G loss: 1.236968]\n",
      "epoch:22 step:21058 [D loss: 0.572801, acc.: 68.75%] [G loss: 1.353140]\n",
      "epoch:22 step:21059 [D loss: 0.814277, acc.: 43.75%] [G loss: 0.933619]\n",
      "epoch:22 step:21060 [D loss: 0.840149, acc.: 46.09%] [G loss: 0.926408]\n",
      "epoch:22 step:21061 [D loss: 0.647810, acc.: 64.84%] [G loss: 1.163662]\n",
      "epoch:22 step:21062 [D loss: 0.419227, acc.: 83.59%] [G loss: 1.257098]\n",
      "epoch:22 step:21063 [D loss: 0.442316, acc.: 85.16%] [G loss: 1.190738]\n",
      "epoch:22 step:21064 [D loss: 0.695526, acc.: 57.03%] [G loss: 1.110210]\n",
      "epoch:22 step:21065 [D loss: 0.553597, acc.: 72.66%] [G loss: 1.270399]\n",
      "epoch:22 step:21066 [D loss: 0.502975, acc.: 78.12%] [G loss: 1.491412]\n",
      "epoch:22 step:21067 [D loss: 0.509100, acc.: 73.44%] [G loss: 1.372574]\n",
      "epoch:22 step:21068 [D loss: 0.502943, acc.: 76.56%] [G loss: 1.422812]\n",
      "epoch:22 step:21069 [D loss: 0.661287, acc.: 62.50%] [G loss: 1.169563]\n",
      "epoch:22 step:21070 [D loss: 0.520605, acc.: 77.34%] [G loss: 1.309611]\n",
      "epoch:22 step:21071 [D loss: 0.377166, acc.: 91.41%] [G loss: 1.657838]\n",
      "epoch:22 step:21072 [D loss: 0.947982, acc.: 38.28%] [G loss: 0.981655]\n",
      "epoch:22 step:21073 [D loss: 0.891476, acc.: 35.16%] [G loss: 0.967845]\n",
      "epoch:22 step:21074 [D loss: 0.810563, acc.: 46.88%] [G loss: 1.108073]\n",
      "epoch:22 step:21075 [D loss: 1.179515, acc.: 17.19%] [G loss: 0.824050]\n",
      "epoch:22 step:21076 [D loss: 0.814467, acc.: 44.53%] [G loss: 0.907755]\n",
      "epoch:22 step:21077 [D loss: 0.800757, acc.: 42.97%] [G loss: 1.019059]\n",
      "epoch:22 step:21078 [D loss: 0.625992, acc.: 63.28%] [G loss: 0.800316]\n",
      "epoch:22 step:21079 [D loss: 0.815044, acc.: 43.75%] [G loss: 1.161215]\n",
      "epoch:22 step:21080 [D loss: 0.582789, acc.: 66.41%] [G loss: 1.069496]\n",
      "epoch:22 step:21081 [D loss: 0.790566, acc.: 47.66%] [G loss: 0.930634]\n",
      "epoch:22 step:21082 [D loss: 0.486115, acc.: 83.59%] [G loss: 1.032277]\n",
      "epoch:22 step:21083 [D loss: 0.469996, acc.: 78.91%] [G loss: 1.248606]\n",
      "epoch:22 step:21084 [D loss: 0.351342, acc.: 89.06%] [G loss: 1.445030]\n",
      "epoch:22 step:21085 [D loss: 0.332717, acc.: 88.28%] [G loss: 1.451756]\n",
      "epoch:22 step:21086 [D loss: 0.428673, acc.: 85.16%] [G loss: 1.682505]\n",
      "epoch:22 step:21087 [D loss: 0.801323, acc.: 49.22%] [G loss: 1.194347]\n",
      "epoch:22 step:21088 [D loss: 0.565216, acc.: 74.22%] [G loss: 0.993881]\n",
      "epoch:22 step:21089 [D loss: 0.515883, acc.: 73.44%] [G loss: 1.241536]\n",
      "epoch:22 step:21090 [D loss: 0.634899, acc.: 64.06%] [G loss: 1.294051]\n",
      "epoch:22 step:21091 [D loss: 0.704824, acc.: 57.03%] [G loss: 1.081195]\n",
      "epoch:22 step:21092 [D loss: 0.733141, acc.: 47.66%] [G loss: 0.982852]\n",
      "epoch:22 step:21093 [D loss: 0.392525, acc.: 91.41%] [G loss: 0.988679]\n",
      "epoch:22 step:21094 [D loss: 0.496887, acc.: 79.69%] [G loss: 1.246240]\n",
      "epoch:22 step:21095 [D loss: 0.480294, acc.: 71.88%] [G loss: 1.027461]\n",
      "epoch:22 step:21096 [D loss: 0.692418, acc.: 60.16%] [G loss: 1.155000]\n",
      "epoch:22 step:21097 [D loss: 0.564662, acc.: 67.19%] [G loss: 1.335603]\n",
      "epoch:22 step:21098 [D loss: 0.386292, acc.: 87.50%] [G loss: 1.393831]\n",
      "epoch:22 step:21099 [D loss: 0.472153, acc.: 77.34%] [G loss: 1.290604]\n",
      "epoch:22 step:21100 [D loss: 0.621842, acc.: 60.94%] [G loss: 1.304230]\n",
      "epoch:22 step:21101 [D loss: 0.528492, acc.: 77.34%] [G loss: 1.128703]\n",
      "epoch:22 step:21102 [D loss: 0.516960, acc.: 75.78%] [G loss: 1.199257]\n",
      "epoch:22 step:21103 [D loss: 0.560941, acc.: 71.09%] [G loss: 1.160869]\n",
      "epoch:22 step:21104 [D loss: 0.561188, acc.: 70.31%] [G loss: 1.275349]\n",
      "epoch:22 step:21105 [D loss: 0.636887, acc.: 61.72%] [G loss: 1.020201]\n",
      "epoch:22 step:21106 [D loss: 0.757596, acc.: 53.91%] [G loss: 0.894796]\n",
      "epoch:22 step:21107 [D loss: 0.631495, acc.: 60.16%] [G loss: 1.040895]\n",
      "epoch:22 step:21108 [D loss: 0.653141, acc.: 65.62%] [G loss: 0.936595]\n",
      "epoch:22 step:21109 [D loss: 0.604737, acc.: 64.84%] [G loss: 1.014570]\n",
      "epoch:22 step:21110 [D loss: 0.728213, acc.: 48.44%] [G loss: 0.908322]\n",
      "epoch:22 step:21111 [D loss: 0.392342, acc.: 86.72%] [G loss: 1.240430]\n",
      "epoch:22 step:21112 [D loss: 0.458746, acc.: 79.69%] [G loss: 1.059631]\n",
      "epoch:22 step:21113 [D loss: 0.288727, acc.: 92.97%] [G loss: 1.532200]\n",
      "epoch:22 step:21114 [D loss: 0.786135, acc.: 55.47%] [G loss: 1.360136]\n",
      "epoch:22 step:21115 [D loss: 0.856473, acc.: 48.44%] [G loss: 1.277777]\n",
      "epoch:22 step:21116 [D loss: 0.666869, acc.: 62.50%] [G loss: 0.956617]\n",
      "epoch:22 step:21117 [D loss: 0.405965, acc.: 82.03%] [G loss: 1.185244]\n",
      "epoch:22 step:21118 [D loss: 0.352698, acc.: 89.84%] [G loss: 1.420130]\n",
      "epoch:22 step:21119 [D loss: 0.519468, acc.: 76.56%] [G loss: 1.346597]\n",
      "epoch:22 step:21120 [D loss: 0.721536, acc.: 52.34%] [G loss: 1.256706]\n",
      "epoch:22 step:21121 [D loss: 0.368429, acc.: 90.62%] [G loss: 1.334098]\n",
      "epoch:22 step:21122 [D loss: 0.276198, acc.: 96.09%] [G loss: 1.525797]\n",
      "epoch:22 step:21123 [D loss: 0.965617, acc.: 32.03%] [G loss: 1.080855]\n",
      "epoch:22 step:21124 [D loss: 0.772248, acc.: 46.88%] [G loss: 1.169651]\n",
      "epoch:22 step:21125 [D loss: 0.387343, acc.: 90.62%] [G loss: 1.320492]\n",
      "epoch:22 step:21126 [D loss: 0.446848, acc.: 81.25%] [G loss: 1.158899]\n",
      "epoch:22 step:21127 [D loss: 0.421943, acc.: 84.38%] [G loss: 1.578781]\n",
      "epoch:22 step:21128 [D loss: 0.354069, acc.: 92.97%] [G loss: 1.544105]\n",
      "epoch:22 step:21129 [D loss: 0.496296, acc.: 80.47%] [G loss: 1.365746]\n",
      "epoch:22 step:21130 [D loss: 0.466179, acc.: 80.47%] [G loss: 1.490465]\n",
      "epoch:22 step:21131 [D loss: 0.570194, acc.: 70.31%] [G loss: 1.161787]\n",
      "epoch:22 step:21132 [D loss: 0.594892, acc.: 66.41%] [G loss: 1.113990]\n",
      "epoch:22 step:21133 [D loss: 0.587139, acc.: 69.53%] [G loss: 0.861732]\n",
      "epoch:22 step:21134 [D loss: 0.565231, acc.: 67.97%] [G loss: 1.109048]\n",
      "epoch:22 step:21135 [D loss: 0.539448, acc.: 73.44%] [G loss: 1.184421]\n",
      "epoch:22 step:21136 [D loss: 0.516088, acc.: 78.91%] [G loss: 1.100647]\n",
      "epoch:22 step:21137 [D loss: 0.490607, acc.: 78.12%] [G loss: 1.110455]\n",
      "epoch:22 step:21138 [D loss: 0.643593, acc.: 67.19%] [G loss: 1.095255]\n",
      "epoch:22 step:21139 [D loss: 0.550495, acc.: 71.88%] [G loss: 0.927382]\n",
      "epoch:22 step:21140 [D loss: 0.458776, acc.: 81.25%] [G loss: 1.548603]\n",
      "epoch:22 step:21141 [D loss: 0.650661, acc.: 57.81%] [G loss: 1.075891]\n",
      "epoch:22 step:21142 [D loss: 0.615882, acc.: 67.97%] [G loss: 1.165000]\n",
      "epoch:22 step:21143 [D loss: 0.586490, acc.: 65.62%] [G loss: 1.106869]\n",
      "epoch:22 step:21144 [D loss: 0.588587, acc.: 69.53%] [G loss: 1.046587]\n",
      "epoch:22 step:21145 [D loss: 0.727814, acc.: 55.47%] [G loss: 1.053213]\n",
      "epoch:22 step:21146 [D loss: 0.499899, acc.: 81.25%] [G loss: 1.074253]\n",
      "epoch:22 step:21147 [D loss: 0.426154, acc.: 84.38%] [G loss: 1.351342]\n",
      "epoch:22 step:21148 [D loss: 0.364189, acc.: 91.41%] [G loss: 1.462438]\n",
      "epoch:22 step:21149 [D loss: 0.450870, acc.: 84.38%] [G loss: 1.227616]\n",
      "epoch:22 step:21150 [D loss: 0.392944, acc.: 87.50%] [G loss: 1.399197]\n",
      "epoch:22 step:21151 [D loss: 0.450754, acc.: 84.38%] [G loss: 1.372693]\n",
      "epoch:22 step:21152 [D loss: 0.649189, acc.: 60.94%] [G loss: 1.298496]\n",
      "epoch:22 step:21153 [D loss: 0.595460, acc.: 65.62%] [G loss: 1.003446]\n",
      "epoch:22 step:21154 [D loss: 0.598045, acc.: 68.75%] [G loss: 0.942269]\n",
      "epoch:22 step:21155 [D loss: 0.567539, acc.: 74.22%] [G loss: 0.930927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21156 [D loss: 0.578774, acc.: 68.75%] [G loss: 1.287245]\n",
      "epoch:22 step:21157 [D loss: 0.514254, acc.: 79.69%] [G loss: 1.368467]\n",
      "epoch:22 step:21158 [D loss: 0.552755, acc.: 74.22%] [G loss: 1.055640]\n",
      "epoch:22 step:21159 [D loss: 0.422774, acc.: 85.94%] [G loss: 1.178773]\n",
      "epoch:22 step:21160 [D loss: 0.333553, acc.: 92.19%] [G loss: 1.341736]\n",
      "epoch:22 step:21161 [D loss: 0.398493, acc.: 89.84%] [G loss: 1.473762]\n",
      "epoch:22 step:21162 [D loss: 0.413900, acc.: 91.41%] [G loss: 1.504404]\n",
      "epoch:22 step:21163 [D loss: 0.276603, acc.: 96.88%] [G loss: 1.624137]\n",
      "epoch:22 step:21164 [D loss: 0.297470, acc.: 92.19%] [G loss: 1.368660]\n",
      "epoch:22 step:21165 [D loss: 0.205490, acc.: 99.22%] [G loss: 1.938061]\n",
      "epoch:22 step:21166 [D loss: 0.356460, acc.: 91.41%] [G loss: 1.604589]\n",
      "epoch:22 step:21167 [D loss: 0.330385, acc.: 94.53%] [G loss: 1.909667]\n",
      "epoch:22 step:21168 [D loss: 0.265114, acc.: 96.88%] [G loss: 1.228161]\n",
      "epoch:22 step:21169 [D loss: 0.328599, acc.: 95.31%] [G loss: 1.893514]\n",
      "epoch:22 step:21170 [D loss: 0.262192, acc.: 96.88%] [G loss: 1.349672]\n",
      "epoch:22 step:21171 [D loss: 0.396931, acc.: 87.50%] [G loss: 1.404607]\n",
      "epoch:22 step:21172 [D loss: 0.507849, acc.: 75.00%] [G loss: 1.319359]\n",
      "epoch:22 step:21173 [D loss: 0.706528, acc.: 60.16%] [G loss: 1.616455]\n",
      "epoch:22 step:21174 [D loss: 1.147132, acc.: 18.75%] [G loss: 1.041893]\n",
      "epoch:22 step:21175 [D loss: 0.641357, acc.: 67.19%] [G loss: 1.447120]\n",
      "epoch:22 step:21176 [D loss: 0.855870, acc.: 50.00%] [G loss: 1.342692]\n",
      "epoch:22 step:21177 [D loss: 0.697946, acc.: 60.16%] [G loss: 1.112780]\n",
      "epoch:22 step:21178 [D loss: 0.674622, acc.: 57.81%] [G loss: 0.972594]\n",
      "epoch:22 step:21179 [D loss: 0.513386, acc.: 75.00%] [G loss: 1.011210]\n",
      "epoch:22 step:21180 [D loss: 0.340852, acc.: 89.84%] [G loss: 1.555523]\n",
      "epoch:22 step:21181 [D loss: 0.300789, acc.: 96.09%] [G loss: 1.394478]\n",
      "epoch:22 step:21182 [D loss: 0.505799, acc.: 80.47%] [G loss: 1.651454]\n",
      "epoch:22 step:21183 [D loss: 0.706760, acc.: 54.69%] [G loss: 1.350668]\n",
      "epoch:22 step:21184 [D loss: 0.609519, acc.: 67.19%] [G loss: 0.998872]\n",
      "epoch:22 step:21185 [D loss: 0.486904, acc.: 80.47%] [G loss: 1.201602]\n",
      "epoch:22 step:21186 [D loss: 0.647610, acc.: 59.38%] [G loss: 0.832327]\n",
      "epoch:22 step:21187 [D loss: 0.596632, acc.: 68.75%] [G loss: 0.904208]\n",
      "epoch:22 step:21188 [D loss: 0.438006, acc.: 86.72%] [G loss: 1.101457]\n",
      "epoch:22 step:21189 [D loss: 0.465368, acc.: 82.81%] [G loss: 1.353721]\n",
      "epoch:22 step:21190 [D loss: 0.353196, acc.: 92.19%] [G loss: 1.400011]\n",
      "epoch:22 step:21191 [D loss: 0.607537, acc.: 67.19%] [G loss: 1.182333]\n",
      "epoch:22 step:21192 [D loss: 0.702343, acc.: 55.47%] [G loss: 0.840380]\n",
      "epoch:22 step:21193 [D loss: 0.633105, acc.: 71.09%] [G loss: 1.430303]\n",
      "epoch:22 step:21194 [D loss: 0.707796, acc.: 52.34%] [G loss: 1.151750]\n",
      "epoch:22 step:21195 [D loss: 0.607229, acc.: 65.62%] [G loss: 1.110692]\n",
      "epoch:22 step:21196 [D loss: 0.801485, acc.: 40.62%] [G loss: 0.606957]\n",
      "epoch:22 step:21197 [D loss: 0.770407, acc.: 52.34%] [G loss: 1.026944]\n",
      "epoch:22 step:21198 [D loss: 0.685308, acc.: 60.16%] [G loss: 0.746380]\n",
      "epoch:22 step:21199 [D loss: 0.647160, acc.: 62.50%] [G loss: 0.727894]\n",
      "epoch:22 step:21200 [D loss: 0.772057, acc.: 52.34%] [G loss: 0.691887]\n",
      "epoch:22 step:21201 [D loss: 0.637583, acc.: 64.06%] [G loss: 0.801130]\n",
      "epoch:22 step:21202 [D loss: 0.361621, acc.: 89.84%] [G loss: 1.119190]\n",
      "epoch:22 step:21203 [D loss: 0.425972, acc.: 82.03%] [G loss: 1.337072]\n",
      "epoch:22 step:21204 [D loss: 1.022650, acc.: 35.16%] [G loss: 1.046071]\n",
      "epoch:22 step:21205 [D loss: 0.806319, acc.: 45.31%] [G loss: 0.985182]\n",
      "epoch:22 step:21206 [D loss: 0.549645, acc.: 71.09%] [G loss: 1.007875]\n",
      "epoch:22 step:21207 [D loss: 0.744773, acc.: 52.34%] [G loss: 1.160851]\n",
      "epoch:22 step:21208 [D loss: 0.558664, acc.: 74.22%] [G loss: 1.276829]\n",
      "epoch:22 step:21209 [D loss: 0.641438, acc.: 64.84%] [G loss: 1.016169]\n",
      "epoch:22 step:21210 [D loss: 0.572969, acc.: 75.00%] [G loss: 1.238256]\n",
      "epoch:22 step:21211 [D loss: 0.461696, acc.: 86.72%] [G loss: 1.591073]\n",
      "epoch:22 step:21212 [D loss: 0.244068, acc.: 93.75%] [G loss: 1.714472]\n",
      "epoch:22 step:21213 [D loss: 0.404874, acc.: 82.81%] [G loss: 1.750656]\n",
      "epoch:22 step:21214 [D loss: 0.524204, acc.: 74.22%] [G loss: 1.204229]\n",
      "epoch:22 step:21215 [D loss: 0.395338, acc.: 89.84%] [G loss: 1.252140]\n",
      "epoch:22 step:21216 [D loss: 0.507875, acc.: 76.56%] [G loss: 1.114949]\n",
      "epoch:22 step:21217 [D loss: 0.309263, acc.: 91.41%] [G loss: 1.385796]\n",
      "epoch:22 step:21218 [D loss: 0.248674, acc.: 93.75%] [G loss: 1.505598]\n",
      "epoch:22 step:21219 [D loss: 0.260816, acc.: 95.31%] [G loss: 1.592624]\n",
      "epoch:22 step:21220 [D loss: 0.688891, acc.: 62.50%] [G loss: 0.975395]\n",
      "epoch:22 step:21221 [D loss: 0.575910, acc.: 71.09%] [G loss: 1.076810]\n",
      "epoch:22 step:21222 [D loss: 0.606602, acc.: 65.62%] [G loss: 1.037259]\n",
      "epoch:22 step:21223 [D loss: 0.761611, acc.: 49.22%] [G loss: 0.868579]\n",
      "epoch:22 step:21224 [D loss: 0.581774, acc.: 70.31%] [G loss: 1.148538]\n",
      "epoch:22 step:21225 [D loss: 0.797431, acc.: 47.66%] [G loss: 1.484659]\n",
      "epoch:22 step:21226 [D loss: 0.732047, acc.: 53.12%] [G loss: 1.064842]\n",
      "epoch:22 step:21227 [D loss: 0.498959, acc.: 74.22%] [G loss: 1.232706]\n",
      "epoch:22 step:21228 [D loss: 0.375739, acc.: 87.50%] [G loss: 1.240743]\n",
      "epoch:22 step:21229 [D loss: 0.280792, acc.: 94.53%] [G loss: 1.606531]\n",
      "epoch:22 step:21230 [D loss: 0.309771, acc.: 94.53%] [G loss: 1.702978]\n",
      "epoch:22 step:21231 [D loss: 0.410205, acc.: 87.50%] [G loss: 1.311993]\n",
      "epoch:22 step:21232 [D loss: 0.771568, acc.: 52.34%] [G loss: 1.114585]\n",
      "epoch:22 step:21233 [D loss: 0.901187, acc.: 35.94%] [G loss: 0.745756]\n",
      "epoch:22 step:21234 [D loss: 0.752635, acc.: 57.03%] [G loss: 1.100879]\n",
      "epoch:22 step:21235 [D loss: 0.940296, acc.: 37.50%] [G loss: 0.815072]\n",
      "epoch:22 step:21236 [D loss: 0.774349, acc.: 48.44%] [G loss: 1.309324]\n",
      "epoch:22 step:21237 [D loss: 0.762357, acc.: 47.66%] [G loss: 1.058784]\n",
      "epoch:22 step:21238 [D loss: 0.455832, acc.: 85.16%] [G loss: 1.690056]\n",
      "epoch:22 step:21239 [D loss: 0.776990, acc.: 47.66%] [G loss: 1.030286]\n",
      "epoch:22 step:21240 [D loss: 0.809386, acc.: 45.31%] [G loss: 0.976011]\n",
      "epoch:22 step:21241 [D loss: 0.813471, acc.: 47.66%] [G loss: 1.364040]\n",
      "epoch:22 step:21242 [D loss: 0.764059, acc.: 51.56%] [G loss: 0.933300]\n",
      "epoch:22 step:21243 [D loss: 0.491223, acc.: 75.78%] [G loss: 1.226874]\n",
      "epoch:22 step:21244 [D loss: 0.649092, acc.: 58.59%] [G loss: 1.416496]\n",
      "epoch:22 step:21245 [D loss: 0.742281, acc.: 50.78%] [G loss: 1.559686]\n",
      "epoch:22 step:21246 [D loss: 0.691156, acc.: 60.16%] [G loss: 1.030776]\n",
      "epoch:22 step:21247 [D loss: 0.478131, acc.: 78.12%] [G loss: 1.408975]\n",
      "epoch:22 step:21248 [D loss: 0.693547, acc.: 57.03%] [G loss: 0.891813]\n",
      "epoch:22 step:21249 [D loss: 0.621917, acc.: 68.75%] [G loss: 1.420272]\n",
      "epoch:22 step:21250 [D loss: 0.724449, acc.: 52.34%] [G loss: 1.153824]\n",
      "epoch:22 step:21251 [D loss: 1.020121, acc.: 28.91%] [G loss: 0.706439]\n",
      "epoch:22 step:21252 [D loss: 0.702265, acc.: 58.59%] [G loss: 1.082126]\n",
      "epoch:22 step:21253 [D loss: 0.735678, acc.: 53.91%] [G loss: 0.908410]\n",
      "epoch:22 step:21254 [D loss: 0.402235, acc.: 89.06%] [G loss: 1.371234]\n",
      "epoch:22 step:21255 [D loss: 0.489644, acc.: 77.34%] [G loss: 1.472354]\n",
      "epoch:22 step:21256 [D loss: 0.340228, acc.: 92.97%] [G loss: 1.561106]\n",
      "epoch:22 step:21257 [D loss: 0.623159, acc.: 64.06%] [G loss: 1.459867]\n",
      "epoch:22 step:21258 [D loss: 0.719367, acc.: 51.56%] [G loss: 1.001177]\n",
      "epoch:22 step:21259 [D loss: 0.602270, acc.: 67.19%] [G loss: 1.118780]\n",
      "epoch:22 step:21260 [D loss: 0.682206, acc.: 54.69%] [G loss: 1.123693]\n",
      "epoch:22 step:21261 [D loss: 0.635630, acc.: 64.84%] [G loss: 1.233814]\n",
      "epoch:22 step:21262 [D loss: 0.427780, acc.: 85.16%] [G loss: 1.277991]\n",
      "epoch:22 step:21263 [D loss: 0.644105, acc.: 60.94%] [G loss: 1.030386]\n",
      "epoch:22 step:21264 [D loss: 0.539683, acc.: 73.44%] [G loss: 1.280491]\n",
      "epoch:22 step:21265 [D loss: 0.595363, acc.: 62.50%] [G loss: 1.095651]\n",
      "epoch:22 step:21266 [D loss: 0.772671, acc.: 53.91%] [G loss: 1.238675]\n",
      "epoch:22 step:21267 [D loss: 0.566296, acc.: 71.09%] [G loss: 1.018485]\n",
      "epoch:22 step:21268 [D loss: 0.575550, acc.: 70.31%] [G loss: 1.087445]\n",
      "epoch:22 step:21269 [D loss: 0.637999, acc.: 64.06%] [G loss: 1.114377]\n",
      "epoch:22 step:21270 [D loss: 0.601247, acc.: 68.75%] [G loss: 0.991664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21271 [D loss: 0.627896, acc.: 64.84%] [G loss: 0.853250]\n",
      "epoch:22 step:21272 [D loss: 0.442448, acc.: 84.38%] [G loss: 0.966674]\n",
      "epoch:22 step:21273 [D loss: 0.622273, acc.: 65.62%] [G loss: 0.901920]\n",
      "epoch:22 step:21274 [D loss: 0.598075, acc.: 69.53%] [G loss: 1.314978]\n",
      "epoch:22 step:21275 [D loss: 0.570583, acc.: 67.97%] [G loss: 1.171990]\n",
      "epoch:22 step:21276 [D loss: 0.457526, acc.: 78.91%] [G loss: 1.220763]\n",
      "epoch:22 step:21277 [D loss: 0.216610, acc.: 96.09%] [G loss: 1.647804]\n",
      "epoch:22 step:21278 [D loss: 0.264589, acc.: 93.75%] [G loss: 1.703557]\n",
      "epoch:22 step:21279 [D loss: 0.256912, acc.: 96.88%] [G loss: 1.594110]\n",
      "epoch:22 step:21280 [D loss: 0.378703, acc.: 87.50%] [G loss: 1.923675]\n",
      "epoch:22 step:21281 [D loss: 0.449098, acc.: 82.03%] [G loss: 1.872206]\n",
      "epoch:22 step:21282 [D loss: 0.974231, acc.: 35.94%] [G loss: 0.863661]\n",
      "epoch:22 step:21283 [D loss: 0.551761, acc.: 71.88%] [G loss: 1.266395]\n",
      "epoch:22 step:21284 [D loss: 0.624457, acc.: 63.28%] [G loss: 1.200551]\n",
      "epoch:22 step:21285 [D loss: 0.635791, acc.: 62.50%] [G loss: 1.046902]\n",
      "epoch:22 step:21286 [D loss: 0.758148, acc.: 50.00%] [G loss: 1.302237]\n",
      "epoch:22 step:21287 [D loss: 0.790910, acc.: 49.22%] [G loss: 1.309006]\n",
      "epoch:22 step:21288 [D loss: 0.706043, acc.: 60.16%] [G loss: 0.942250]\n",
      "epoch:22 step:21289 [D loss: 1.113756, acc.: 26.56%] [G loss: 0.600327]\n",
      "epoch:22 step:21290 [D loss: 0.825752, acc.: 42.97%] [G loss: 1.055004]\n",
      "epoch:22 step:21291 [D loss: 0.679082, acc.: 57.03%] [G loss: 1.148107]\n",
      "epoch:22 step:21292 [D loss: 0.794462, acc.: 48.44%] [G loss: 0.842011]\n",
      "epoch:22 step:21293 [D loss: 0.825965, acc.: 43.75%] [G loss: 0.989087]\n",
      "epoch:22 step:21294 [D loss: 0.736921, acc.: 48.44%] [G loss: 1.040823]\n",
      "epoch:22 step:21295 [D loss: 0.603359, acc.: 66.41%] [G loss: 1.005873]\n",
      "epoch:22 step:21296 [D loss: 0.654985, acc.: 59.38%] [G loss: 0.832539]\n",
      "epoch:22 step:21297 [D loss: 0.671640, acc.: 57.81%] [G loss: 1.148280]\n",
      "epoch:22 step:21298 [D loss: 0.715835, acc.: 54.69%] [G loss: 1.059002]\n",
      "epoch:22 step:21299 [D loss: 0.600235, acc.: 71.88%] [G loss: 1.211362]\n",
      "epoch:22 step:21300 [D loss: 0.709922, acc.: 55.47%] [G loss: 1.013196]\n",
      "epoch:22 step:21301 [D loss: 0.578511, acc.: 69.53%] [G loss: 1.066657]\n",
      "epoch:22 step:21302 [D loss: 0.596884, acc.: 70.31%] [G loss: 1.151677]\n",
      "epoch:22 step:21303 [D loss: 0.554871, acc.: 68.75%] [G loss: 1.092833]\n",
      "epoch:22 step:21304 [D loss: 0.361344, acc.: 90.62%] [G loss: 1.330392]\n",
      "epoch:22 step:21305 [D loss: 0.527637, acc.: 79.69%] [G loss: 1.261430]\n",
      "epoch:22 step:21306 [D loss: 0.505188, acc.: 79.69%] [G loss: 1.064404]\n",
      "epoch:22 step:21307 [D loss: 0.436930, acc.: 84.38%] [G loss: 1.470966]\n",
      "epoch:22 step:21308 [D loss: 0.334454, acc.: 92.19%] [G loss: 1.369264]\n",
      "epoch:22 step:21309 [D loss: 0.478080, acc.: 82.81%] [G loss: 1.482406]\n",
      "epoch:22 step:21310 [D loss: 0.721063, acc.: 60.16%] [G loss: 1.343795]\n",
      "epoch:22 step:21311 [D loss: 0.771443, acc.: 49.22%] [G loss: 0.934460]\n",
      "epoch:22 step:21312 [D loss: 0.680643, acc.: 61.72%] [G loss: 1.122865]\n",
      "epoch:22 step:21313 [D loss: 0.684737, acc.: 61.72%] [G loss: 1.058005]\n",
      "epoch:22 step:21314 [D loss: 0.550164, acc.: 72.66%] [G loss: 1.133138]\n",
      "epoch:22 step:21315 [D loss: 0.754426, acc.: 53.12%] [G loss: 1.005848]\n",
      "epoch:22 step:21316 [D loss: 0.485720, acc.: 81.25%] [G loss: 1.061507]\n",
      "epoch:22 step:21317 [D loss: 0.682392, acc.: 59.38%] [G loss: 0.956538]\n",
      "epoch:22 step:21318 [D loss: 0.693710, acc.: 57.81%] [G loss: 1.038570]\n",
      "epoch:22 step:21319 [D loss: 0.748157, acc.: 50.78%] [G loss: 1.004294]\n",
      "epoch:22 step:21320 [D loss: 0.393022, acc.: 87.50%] [G loss: 1.235920]\n",
      "epoch:22 step:21321 [D loss: 0.483972, acc.: 78.91%] [G loss: 1.138804]\n",
      "epoch:22 step:21322 [D loss: 0.412985, acc.: 85.94%] [G loss: 1.410798]\n",
      "epoch:22 step:21323 [D loss: 0.458150, acc.: 79.69%] [G loss: 1.397694]\n",
      "epoch:22 step:21324 [D loss: 0.723130, acc.: 55.47%] [G loss: 1.694556]\n",
      "epoch:22 step:21325 [D loss: 0.611464, acc.: 64.84%] [G loss: 1.130412]\n",
      "epoch:22 step:21326 [D loss: 0.621400, acc.: 67.19%] [G loss: 1.271450]\n",
      "epoch:22 step:21327 [D loss: 0.382783, acc.: 87.50%] [G loss: 1.332666]\n",
      "epoch:22 step:21328 [D loss: 0.512377, acc.: 75.00%] [G loss: 1.412898]\n",
      "epoch:22 step:21329 [D loss: 0.606936, acc.: 59.38%] [G loss: 1.255334]\n",
      "epoch:22 step:21330 [D loss: 0.815155, acc.: 44.53%] [G loss: 1.005868]\n",
      "epoch:22 step:21331 [D loss: 0.715606, acc.: 53.12%] [G loss: 0.949879]\n",
      "epoch:22 step:21332 [D loss: 0.613034, acc.: 64.06%] [G loss: 0.966244]\n",
      "epoch:22 step:21333 [D loss: 0.700662, acc.: 58.59%] [G loss: 1.147402]\n",
      "epoch:22 step:21334 [D loss: 0.634234, acc.: 64.06%] [G loss: 1.042394]\n",
      "epoch:22 step:21335 [D loss: 0.799929, acc.: 42.97%] [G loss: 1.048992]\n",
      "epoch:22 step:21336 [D loss: 0.599537, acc.: 67.19%] [G loss: 1.115944]\n",
      "epoch:22 step:21337 [D loss: 0.725280, acc.: 52.34%] [G loss: 1.156840]\n",
      "epoch:22 step:21338 [D loss: 0.437036, acc.: 82.81%] [G loss: 1.063549]\n",
      "epoch:22 step:21339 [D loss: 0.482080, acc.: 76.56%] [G loss: 1.177869]\n",
      "epoch:22 step:21340 [D loss: 0.537725, acc.: 78.91%] [G loss: 1.019231]\n",
      "epoch:22 step:21341 [D loss: 0.611808, acc.: 65.62%] [G loss: 1.236885]\n",
      "epoch:22 step:21342 [D loss: 0.558096, acc.: 73.44%] [G loss: 1.407472]\n",
      "epoch:22 step:21343 [D loss: 0.493527, acc.: 71.88%] [G loss: 1.399279]\n",
      "epoch:22 step:21344 [D loss: 0.483283, acc.: 83.59%] [G loss: 1.127019]\n",
      "epoch:22 step:21345 [D loss: 0.373893, acc.: 88.28%] [G loss: 1.490289]\n",
      "epoch:22 step:21346 [D loss: 0.433890, acc.: 83.59%] [G loss: 1.208089]\n",
      "epoch:22 step:21347 [D loss: 0.436973, acc.: 91.41%] [G loss: 1.151253]\n",
      "epoch:22 step:21348 [D loss: 0.803981, acc.: 50.00%] [G loss: 1.125301]\n",
      "epoch:22 step:21349 [D loss: 0.651986, acc.: 64.84%] [G loss: 1.303760]\n",
      "epoch:22 step:21350 [D loss: 0.642005, acc.: 65.62%] [G loss: 1.096057]\n",
      "epoch:22 step:21351 [D loss: 0.647677, acc.: 64.06%] [G loss: 0.893032]\n",
      "epoch:22 step:21352 [D loss: 0.574740, acc.: 74.22%] [G loss: 1.104653]\n",
      "epoch:22 step:21353 [D loss: 0.584723, acc.: 72.66%] [G loss: 1.081831]\n",
      "epoch:22 step:21354 [D loss: 0.503351, acc.: 78.12%] [G loss: 1.229908]\n",
      "epoch:22 step:21355 [D loss: 0.652473, acc.: 56.25%] [G loss: 0.932679]\n",
      "epoch:22 step:21356 [D loss: 0.632464, acc.: 67.19%] [G loss: 1.390037]\n",
      "epoch:22 step:21357 [D loss: 0.541285, acc.: 73.44%] [G loss: 1.154010]\n",
      "epoch:22 step:21358 [D loss: 0.639751, acc.: 59.38%] [G loss: 1.173554]\n",
      "epoch:22 step:21359 [D loss: 0.413588, acc.: 84.38%] [G loss: 1.197721]\n",
      "epoch:22 step:21360 [D loss: 0.566448, acc.: 69.53%] [G loss: 1.350540]\n",
      "epoch:22 step:21361 [D loss: 0.626036, acc.: 64.84%] [G loss: 1.362720]\n",
      "epoch:22 step:21362 [D loss: 0.644004, acc.: 61.72%] [G loss: 1.265235]\n",
      "epoch:22 step:21363 [D loss: 0.730672, acc.: 53.12%] [G loss: 1.115517]\n",
      "epoch:22 step:21364 [D loss: 0.609641, acc.: 67.19%] [G loss: 0.995065]\n",
      "epoch:22 step:21365 [D loss: 0.569442, acc.: 74.22%] [G loss: 1.172742]\n",
      "epoch:22 step:21366 [D loss: 0.740890, acc.: 48.44%] [G loss: 0.985317]\n",
      "epoch:22 step:21367 [D loss: 0.608483, acc.: 65.62%] [G loss: 1.022354]\n",
      "epoch:22 step:21368 [D loss: 0.535785, acc.: 78.12%] [G loss: 1.104162]\n",
      "epoch:22 step:21369 [D loss: 0.495398, acc.: 75.78%] [G loss: 0.971393]\n",
      "epoch:22 step:21370 [D loss: 0.573833, acc.: 67.19%] [G loss: 1.066712]\n",
      "epoch:22 step:21371 [D loss: 0.470012, acc.: 84.38%] [G loss: 1.115376]\n",
      "epoch:22 step:21372 [D loss: 0.521392, acc.: 75.00%] [G loss: 1.181831]\n",
      "epoch:22 step:21373 [D loss: 0.899751, acc.: 32.81%] [G loss: 0.832932]\n",
      "epoch:22 step:21374 [D loss: 0.688550, acc.: 54.69%] [G loss: 1.084042]\n",
      "epoch:22 step:21375 [D loss: 0.818151, acc.: 41.41%] [G loss: 0.953735]\n",
      "epoch:22 step:21376 [D loss: 0.862179, acc.: 35.16%] [G loss: 0.836382]\n",
      "epoch:22 step:21377 [D loss: 0.549628, acc.: 74.22%] [G loss: 1.214274]\n",
      "epoch:22 step:21378 [D loss: 0.666995, acc.: 63.28%] [G loss: 1.000893]\n",
      "epoch:22 step:21379 [D loss: 0.877304, acc.: 33.59%] [G loss: 1.175704]\n",
      "epoch:22 step:21380 [D loss: 0.789188, acc.: 49.22%] [G loss: 1.326801]\n",
      "epoch:22 step:21381 [D loss: 0.380207, acc.: 91.41%] [G loss: 1.298507]\n",
      "epoch:22 step:21382 [D loss: 0.378500, acc.: 88.28%] [G loss: 1.219266]\n",
      "epoch:22 step:21383 [D loss: 0.213593, acc.: 97.66%] [G loss: 1.505309]\n",
      "epoch:22 step:21384 [D loss: 0.474185, acc.: 81.25%] [G loss: 1.496109]\n",
      "epoch:22 step:21385 [D loss: 0.624841, acc.: 64.06%] [G loss: 1.329395]\n",
      "epoch:22 step:21386 [D loss: 0.684241, acc.: 57.81%] [G loss: 1.042958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21387 [D loss: 0.511890, acc.: 77.34%] [G loss: 1.042268]\n",
      "epoch:22 step:21388 [D loss: 0.259561, acc.: 92.97%] [G loss: 1.328782]\n",
      "epoch:22 step:21389 [D loss: 0.272873, acc.: 92.19%] [G loss: 1.384563]\n",
      "epoch:22 step:21390 [D loss: 0.428764, acc.: 85.16%] [G loss: 1.210337]\n",
      "epoch:22 step:21391 [D loss: 0.492889, acc.: 80.47%] [G loss: 1.280778]\n",
      "epoch:22 step:21392 [D loss: 0.692134, acc.: 64.06%] [G loss: 1.318323]\n",
      "epoch:22 step:21393 [D loss: 1.205572, acc.: 13.28%] [G loss: 0.747101]\n",
      "epoch:22 step:21394 [D loss: 0.700716, acc.: 60.16%] [G loss: 1.079758]\n",
      "epoch:22 step:21395 [D loss: 0.633890, acc.: 63.28%] [G loss: 1.262047]\n",
      "epoch:22 step:21396 [D loss: 0.468552, acc.: 81.25%] [G loss: 1.336318]\n",
      "epoch:22 step:21397 [D loss: 0.701628, acc.: 60.16%] [G loss: 1.479325]\n",
      "epoch:22 step:21398 [D loss: 0.619501, acc.: 63.28%] [G loss: 1.229516]\n",
      "epoch:22 step:21399 [D loss: 0.616963, acc.: 64.84%] [G loss: 1.046037]\n",
      "epoch:22 step:21400 [D loss: 0.363001, acc.: 91.41%] [G loss: 1.097564]\n",
      "epoch:22 step:21401 [D loss: 0.629066, acc.: 63.28%] [G loss: 1.180879]\n",
      "epoch:22 step:21402 [D loss: 0.515509, acc.: 76.56%] [G loss: 1.084205]\n",
      "epoch:22 step:21403 [D loss: 0.762120, acc.: 53.91%] [G loss: 0.538700]\n",
      "epoch:22 step:21404 [D loss: 0.584811, acc.: 70.31%] [G loss: 1.029378]\n",
      "epoch:22 step:21405 [D loss: 0.330910, acc.: 89.84%] [G loss: 1.501271]\n",
      "epoch:22 step:21406 [D loss: 0.338128, acc.: 90.62%] [G loss: 1.468863]\n",
      "epoch:22 step:21407 [D loss: 0.388137, acc.: 88.28%] [G loss: 1.332342]\n",
      "epoch:22 step:21408 [D loss: 0.266476, acc.: 97.66%] [G loss: 1.424108]\n",
      "epoch:22 step:21409 [D loss: 0.553377, acc.: 72.66%] [G loss: 1.152993]\n",
      "epoch:22 step:21410 [D loss: 0.511005, acc.: 78.91%] [G loss: 1.419628]\n",
      "epoch:22 step:21411 [D loss: 0.854521, acc.: 46.09%] [G loss: 1.061550]\n",
      "epoch:22 step:21412 [D loss: 0.499534, acc.: 78.91%] [G loss: 1.261710]\n",
      "epoch:22 step:21413 [D loss: 0.623268, acc.: 68.75%] [G loss: 1.016988]\n",
      "epoch:22 step:21414 [D loss: 0.917432, acc.: 35.94%] [G loss: 1.010772]\n",
      "epoch:22 step:21415 [D loss: 0.721119, acc.: 55.47%] [G loss: 1.308364]\n",
      "epoch:22 step:21416 [D loss: 0.872642, acc.: 39.06%] [G loss: 0.821629]\n",
      "epoch:22 step:21417 [D loss: 0.725092, acc.: 52.34%] [G loss: 1.139779]\n",
      "epoch:22 step:21418 [D loss: 0.482472, acc.: 80.47%] [G loss: 1.281340]\n",
      "epoch:22 step:21419 [D loss: 0.447744, acc.: 82.81%] [G loss: 1.266326]\n",
      "epoch:22 step:21420 [D loss: 0.525246, acc.: 78.12%] [G loss: 1.069586]\n",
      "epoch:22 step:21421 [D loss: 0.672216, acc.: 60.94%] [G loss: 1.303835]\n",
      "epoch:22 step:21422 [D loss: 0.628840, acc.: 59.38%] [G loss: 1.186003]\n",
      "epoch:22 step:21423 [D loss: 0.496115, acc.: 82.03%] [G loss: 1.463784]\n",
      "epoch:22 step:21424 [D loss: 0.445207, acc.: 88.28%] [G loss: 1.486001]\n",
      "epoch:22 step:21425 [D loss: 0.826119, acc.: 46.09%] [G loss: 1.042011]\n",
      "epoch:22 step:21426 [D loss: 0.510559, acc.: 77.34%] [G loss: 1.084889]\n",
      "epoch:22 step:21427 [D loss: 0.530264, acc.: 76.56%] [G loss: 1.318362]\n",
      "epoch:22 step:21428 [D loss: 0.488334, acc.: 79.69%] [G loss: 1.344505]\n",
      "epoch:22 step:21429 [D loss: 0.272476, acc.: 91.41%] [G loss: 1.543182]\n",
      "epoch:22 step:21430 [D loss: 0.280457, acc.: 96.09%] [G loss: 1.490049]\n",
      "epoch:22 step:21431 [D loss: 0.530469, acc.: 75.00%] [G loss: 1.521641]\n",
      "epoch:22 step:21432 [D loss: 0.335580, acc.: 92.19%] [G loss: 1.357811]\n",
      "epoch:22 step:21433 [D loss: 0.517115, acc.: 74.22%] [G loss: 1.133351]\n",
      "epoch:22 step:21434 [D loss: 0.857007, acc.: 42.19%] [G loss: 0.851424]\n",
      "epoch:22 step:21435 [D loss: 0.870938, acc.: 40.62%] [G loss: 0.928384]\n",
      "epoch:22 step:21436 [D loss: 0.829010, acc.: 42.19%] [G loss: 0.873860]\n",
      "epoch:22 step:21437 [D loss: 0.641388, acc.: 64.84%] [G loss: 0.953101]\n",
      "epoch:22 step:21438 [D loss: 0.337246, acc.: 90.62%] [G loss: 1.440128]\n",
      "epoch:22 step:21439 [D loss: 0.539374, acc.: 76.56%] [G loss: 1.074209]\n",
      "epoch:22 step:21440 [D loss: 0.681251, acc.: 59.38%] [G loss: 1.018802]\n",
      "epoch:22 step:21441 [D loss: 0.769136, acc.: 50.78%] [G loss: 1.422676]\n",
      "epoch:22 step:21442 [D loss: 0.606259, acc.: 68.75%] [G loss: 1.208749]\n",
      "epoch:22 step:21443 [D loss: 0.677889, acc.: 62.50%] [G loss: 1.000427]\n",
      "epoch:22 step:21444 [D loss: 0.628480, acc.: 67.19%] [G loss: 0.785081]\n",
      "epoch:22 step:21445 [D loss: 0.512318, acc.: 68.75%] [G loss: 1.023983]\n",
      "epoch:22 step:21446 [D loss: 0.339013, acc.: 96.09%] [G loss: 1.423950]\n",
      "epoch:22 step:21447 [D loss: 0.537622, acc.: 77.34%] [G loss: 1.259348]\n",
      "epoch:22 step:21448 [D loss: 1.144443, acc.: 29.69%] [G loss: 0.848013]\n",
      "epoch:22 step:21449 [D loss: 0.824566, acc.: 42.97%] [G loss: 1.146004]\n",
      "epoch:22 step:21450 [D loss: 0.892123, acc.: 38.28%] [G loss: 0.980391]\n",
      "epoch:22 step:21451 [D loss: 0.557112, acc.: 72.66%] [G loss: 1.134611]\n",
      "epoch:22 step:21452 [D loss: 0.701330, acc.: 58.59%] [G loss: 1.314923]\n",
      "epoch:22 step:21453 [D loss: 0.570310, acc.: 71.88%] [G loss: 1.367199]\n",
      "epoch:22 step:21454 [D loss: 0.402380, acc.: 89.84%] [G loss: 1.199222]\n",
      "epoch:22 step:21455 [D loss: 0.342601, acc.: 92.19%] [G loss: 1.446488]\n",
      "epoch:22 step:21456 [D loss: 0.361354, acc.: 88.28%] [G loss: 1.362704]\n",
      "epoch:22 step:21457 [D loss: 0.701483, acc.: 59.38%] [G loss: 0.942519]\n",
      "epoch:22 step:21458 [D loss: 0.733366, acc.: 56.25%] [G loss: 1.107312]\n",
      "epoch:22 step:21459 [D loss: 0.591742, acc.: 68.75%] [G loss: 0.905840]\n",
      "epoch:22 step:21460 [D loss: 0.684192, acc.: 60.16%] [G loss: 1.010485]\n",
      "epoch:22 step:21461 [D loss: 0.415292, acc.: 86.72%] [G loss: 0.882099]\n",
      "epoch:22 step:21462 [D loss: 0.540479, acc.: 72.66%] [G loss: 1.407048]\n",
      "epoch:22 step:21463 [D loss: 0.397112, acc.: 86.72%] [G loss: 1.317865]\n",
      "epoch:22 step:21464 [D loss: 0.344626, acc.: 92.97%] [G loss: 1.680506]\n",
      "epoch:22 step:21465 [D loss: 0.196069, acc.: 99.22%] [G loss: 1.649983]\n",
      "epoch:22 step:21466 [D loss: 0.212918, acc.: 96.09%] [G loss: 2.069041]\n",
      "epoch:22 step:21467 [D loss: 0.359877, acc.: 92.19%] [G loss: 1.486055]\n",
      "epoch:22 step:21468 [D loss: 0.192439, acc.: 98.44%] [G loss: 2.129786]\n",
      "epoch:22 step:21469 [D loss: 0.329777, acc.: 92.19%] [G loss: 1.611794]\n",
      "epoch:22 step:21470 [D loss: 0.399336, acc.: 85.16%] [G loss: 1.562397]\n",
      "epoch:22 step:21471 [D loss: 0.278478, acc.: 95.31%] [G loss: 1.919123]\n",
      "epoch:22 step:21472 [D loss: 0.843465, acc.: 44.53%] [G loss: 1.485374]\n",
      "epoch:22 step:21473 [D loss: 0.742638, acc.: 51.56%] [G loss: 1.055123]\n",
      "epoch:22 step:21474 [D loss: 0.546068, acc.: 74.22%] [G loss: 0.940244]\n",
      "epoch:22 step:21475 [D loss: 0.577765, acc.: 69.53%] [G loss: 1.123583]\n",
      "epoch:22 step:21476 [D loss: 0.659578, acc.: 62.50%] [G loss: 1.087674]\n",
      "epoch:22 step:21477 [D loss: 0.659029, acc.: 64.06%] [G loss: 0.803091]\n",
      "epoch:22 step:21478 [D loss: 0.686526, acc.: 56.25%] [G loss: 0.796596]\n",
      "epoch:22 step:21479 [D loss: 0.604753, acc.: 67.19%] [G loss: 1.184844]\n",
      "epoch:22 step:21480 [D loss: 0.604421, acc.: 71.09%] [G loss: 1.165772]\n",
      "epoch:22 step:21481 [D loss: 0.613091, acc.: 66.41%] [G loss: 1.004900]\n",
      "epoch:22 step:21482 [D loss: 0.639387, acc.: 64.06%] [G loss: 0.885654]\n",
      "epoch:22 step:21483 [D loss: 0.525521, acc.: 77.34%] [G loss: 0.963441]\n",
      "epoch:22 step:21484 [D loss: 0.785075, acc.: 44.53%] [G loss: 0.803366]\n",
      "epoch:22 step:21485 [D loss: 0.514359, acc.: 78.91%] [G loss: 1.292383]\n",
      "epoch:22 step:21486 [D loss: 0.521734, acc.: 75.78%] [G loss: 1.015549]\n",
      "epoch:22 step:21487 [D loss: 0.819456, acc.: 42.19%] [G loss: 0.866906]\n",
      "epoch:22 step:21488 [D loss: 0.973835, acc.: 37.50%] [G loss: 0.849595]\n",
      "epoch:22 step:21489 [D loss: 0.658854, acc.: 60.94%] [G loss: 0.798322]\n",
      "epoch:22 step:21490 [D loss: 0.736665, acc.: 54.69%] [G loss: 0.845013]\n",
      "epoch:22 step:21491 [D loss: 0.694649, acc.: 55.47%] [G loss: 1.044852]\n",
      "epoch:22 step:21492 [D loss: 0.404044, acc.: 86.72%] [G loss: 1.287627]\n",
      "epoch:22 step:21493 [D loss: 0.656591, acc.: 62.50%] [G loss: 1.221598]\n",
      "epoch:22 step:21494 [D loss: 0.902685, acc.: 36.72%] [G loss: 0.804715]\n",
      "epoch:22 step:21495 [D loss: 0.669571, acc.: 62.50%] [G loss: 1.352328]\n",
      "epoch:22 step:21496 [D loss: 0.581796, acc.: 66.41%] [G loss: 1.174788]\n",
      "epoch:22 step:21497 [D loss: 0.617394, acc.: 65.62%] [G loss: 0.923904]\n",
      "epoch:22 step:21498 [D loss: 0.680096, acc.: 56.25%] [G loss: 1.046615]\n",
      "epoch:22 step:21499 [D loss: 0.529124, acc.: 71.88%] [G loss: 1.207456]\n",
      "epoch:22 step:21500 [D loss: 0.605160, acc.: 63.28%] [G loss: 1.061061]\n",
      "epoch:22 step:21501 [D loss: 0.693916, acc.: 57.03%] [G loss: 1.119237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21502 [D loss: 0.617686, acc.: 66.41%] [G loss: 1.182027]\n",
      "epoch:22 step:21503 [D loss: 0.641335, acc.: 64.06%] [G loss: 1.103769]\n",
      "epoch:22 step:21504 [D loss: 0.678752, acc.: 59.38%] [G loss: 1.141177]\n",
      "epoch:22 step:21505 [D loss: 0.554838, acc.: 70.31%] [G loss: 1.292596]\n",
      "epoch:22 step:21506 [D loss: 0.379770, acc.: 86.72%] [G loss: 1.324088]\n",
      "epoch:22 step:21507 [D loss: 0.361190, acc.: 93.75%] [G loss: 1.386379]\n",
      "epoch:22 step:21508 [D loss: 0.283437, acc.: 95.31%] [G loss: 1.590515]\n",
      "epoch:22 step:21509 [D loss: 0.372637, acc.: 88.28%] [G loss: 1.876585]\n",
      "epoch:22 step:21510 [D loss: 0.311427, acc.: 95.31%] [G loss: 1.412030]\n",
      "epoch:22 step:21511 [D loss: 0.250621, acc.: 97.66%] [G loss: 1.818335]\n",
      "epoch:22 step:21512 [D loss: 0.232980, acc.: 94.53%] [G loss: 1.275402]\n",
      "epoch:22 step:21513 [D loss: 0.136302, acc.: 99.22%] [G loss: 1.984486]\n",
      "epoch:22 step:21514 [D loss: 0.144825, acc.: 100.00%] [G loss: 2.067638]\n",
      "epoch:22 step:21515 [D loss: 0.291710, acc.: 93.75%] [G loss: 1.776403]\n",
      "epoch:22 step:21516 [D loss: 0.484238, acc.: 77.34%] [G loss: 1.666190]\n",
      "epoch:22 step:21517 [D loss: 0.380167, acc.: 87.50%] [G loss: 1.717932]\n",
      "epoch:22 step:21518 [D loss: 0.912369, acc.: 39.06%] [G loss: 0.778097]\n",
      "epoch:22 step:21519 [D loss: 1.029976, acc.: 39.84%] [G loss: 0.588179]\n",
      "epoch:22 step:21520 [D loss: 0.804171, acc.: 40.62%] [G loss: 1.136835]\n",
      "epoch:22 step:21521 [D loss: 0.655098, acc.: 65.62%] [G loss: 1.339137]\n",
      "epoch:22 step:21522 [D loss: 0.653714, acc.: 64.84%] [G loss: 0.914984]\n",
      "epoch:22 step:21523 [D loss: 0.301542, acc.: 89.06%] [G loss: 1.343383]\n",
      "epoch:22 step:21524 [D loss: 0.762845, acc.: 47.66%] [G loss: 1.080022]\n",
      "epoch:22 step:21525 [D loss: 0.254385, acc.: 92.97%] [G loss: 1.524498]\n",
      "epoch:22 step:21526 [D loss: 0.273106, acc.: 83.59%] [G loss: 1.200800]\n",
      "epoch:22 step:21527 [D loss: 0.904512, acc.: 44.53%] [G loss: 1.452384]\n",
      "epoch:22 step:21528 [D loss: 0.727454, acc.: 50.78%] [G loss: 1.563932]\n",
      "epoch:22 step:21529 [D loss: 0.825190, acc.: 42.97%] [G loss: 0.979527]\n",
      "epoch:22 step:21530 [D loss: 0.682959, acc.: 60.16%] [G loss: 1.284756]\n",
      "epoch:22 step:21531 [D loss: 0.826965, acc.: 45.31%] [G loss: 1.145701]\n",
      "epoch:22 step:21532 [D loss: 0.818676, acc.: 53.12%] [G loss: 0.994256]\n",
      "epoch:22 step:21533 [D loss: 0.753531, acc.: 57.03%] [G loss: 0.858891]\n",
      "epoch:22 step:21534 [D loss: 0.943780, acc.: 43.75%] [G loss: 1.158765]\n",
      "epoch:22 step:21535 [D loss: 0.712189, acc.: 59.38%] [G loss: 1.634715]\n",
      "epoch:22 step:21536 [D loss: 0.575873, acc.: 70.31%] [G loss: 1.292350]\n",
      "epoch:22 step:21537 [D loss: 0.561375, acc.: 72.66%] [G loss: 1.205553]\n",
      "epoch:22 step:21538 [D loss: 0.510821, acc.: 73.44%] [G loss: 0.866728]\n",
      "epoch:22 step:21539 [D loss: 0.476127, acc.: 80.47%] [G loss: 1.566031]\n",
      "epoch:22 step:21540 [D loss: 0.486473, acc.: 82.81%] [G loss: 1.368456]\n",
      "epoch:22 step:21541 [D loss: 0.535646, acc.: 71.09%] [G loss: 1.191338]\n",
      "epoch:22 step:21542 [D loss: 0.987111, acc.: 35.16%] [G loss: 0.983181]\n",
      "epoch:22 step:21543 [D loss: 0.347938, acc.: 86.72%] [G loss: 1.494011]\n",
      "epoch:22 step:21544 [D loss: 0.429560, acc.: 84.38%] [G loss: 1.578526]\n",
      "epoch:22 step:21545 [D loss: 0.634238, acc.: 64.06%] [G loss: 1.109532]\n",
      "epoch:22 step:21546 [D loss: 0.605216, acc.: 65.62%] [G loss: 1.030600]\n",
      "epoch:22 step:21547 [D loss: 0.780026, acc.: 51.56%] [G loss: 0.985969]\n",
      "epoch:22 step:21548 [D loss: 0.567555, acc.: 71.88%] [G loss: 1.193199]\n",
      "epoch:22 step:21549 [D loss: 0.659436, acc.: 60.16%] [G loss: 1.181915]\n",
      "epoch:22 step:21550 [D loss: 0.581610, acc.: 70.31%] [G loss: 1.094695]\n",
      "epoch:22 step:21551 [D loss: 0.290071, acc.: 89.06%] [G loss: 1.473126]\n",
      "epoch:23 step:21552 [D loss: 0.759529, acc.: 56.25%] [G loss: 1.001402]\n",
      "epoch:23 step:21553 [D loss: 0.617307, acc.: 64.06%] [G loss: 1.348872]\n",
      "epoch:23 step:21554 [D loss: 0.771012, acc.: 48.44%] [G loss: 1.025982]\n",
      "epoch:23 step:21555 [D loss: 0.454148, acc.: 80.47%] [G loss: 1.289329]\n",
      "epoch:23 step:21556 [D loss: 0.544195, acc.: 75.78%] [G loss: 1.113976]\n",
      "epoch:23 step:21557 [D loss: 0.352681, acc.: 92.19%] [G loss: 1.782892]\n",
      "epoch:23 step:21558 [D loss: 0.603528, acc.: 66.41%] [G loss: 1.275526]\n",
      "epoch:23 step:21559 [D loss: 0.614568, acc.: 63.28%] [G loss: 1.292588]\n",
      "epoch:23 step:21560 [D loss: 0.572120, acc.: 71.88%] [G loss: 1.360397]\n",
      "epoch:23 step:21561 [D loss: 0.547691, acc.: 76.56%] [G loss: 1.043167]\n",
      "epoch:23 step:21562 [D loss: 0.778061, acc.: 49.22%] [G loss: 1.194782]\n",
      "epoch:23 step:21563 [D loss: 0.772309, acc.: 51.56%] [G loss: 0.800143]\n",
      "epoch:23 step:21564 [D loss: 0.569225, acc.: 71.88%] [G loss: 1.110744]\n",
      "epoch:23 step:21565 [D loss: 0.607433, acc.: 67.19%] [G loss: 1.307518]\n",
      "epoch:23 step:21566 [D loss: 0.619817, acc.: 63.28%] [G loss: 1.106906]\n",
      "epoch:23 step:21567 [D loss: 0.527774, acc.: 71.88%] [G loss: 1.152655]\n",
      "epoch:23 step:21568 [D loss: 0.529535, acc.: 78.91%] [G loss: 1.120797]\n",
      "epoch:23 step:21569 [D loss: 0.645117, acc.: 61.72%] [G loss: 0.966439]\n",
      "epoch:23 step:21570 [D loss: 0.703045, acc.: 54.69%] [G loss: 0.907852]\n",
      "epoch:23 step:21571 [D loss: 0.512126, acc.: 71.88%] [G loss: 1.304858]\n",
      "epoch:23 step:21572 [D loss: 0.524926, acc.: 78.91%] [G loss: 0.977648]\n",
      "epoch:23 step:21573 [D loss: 0.587313, acc.: 78.12%] [G loss: 1.109266]\n",
      "epoch:23 step:21574 [D loss: 0.529223, acc.: 78.12%] [G loss: 1.242547]\n",
      "epoch:23 step:21575 [D loss: 0.651328, acc.: 60.94%] [G loss: 1.074541]\n",
      "epoch:23 step:21576 [D loss: 0.522352, acc.: 78.91%] [G loss: 0.858740]\n",
      "epoch:23 step:21577 [D loss: 0.480620, acc.: 82.03%] [G loss: 1.083635]\n",
      "epoch:23 step:21578 [D loss: 0.316049, acc.: 95.31%] [G loss: 1.244775]\n",
      "epoch:23 step:21579 [D loss: 0.622269, acc.: 67.19%] [G loss: 1.154569]\n",
      "epoch:23 step:21580 [D loss: 0.468198, acc.: 79.69%] [G loss: 1.302366]\n",
      "epoch:23 step:21581 [D loss: 0.523562, acc.: 82.03%] [G loss: 1.235204]\n",
      "epoch:23 step:21582 [D loss: 0.393238, acc.: 84.38%] [G loss: 1.278852]\n",
      "epoch:23 step:21583 [D loss: 0.371207, acc.: 89.06%] [G loss: 1.389969]\n",
      "epoch:23 step:21584 [D loss: 0.434944, acc.: 84.38%] [G loss: 1.363418]\n",
      "epoch:23 step:21585 [D loss: 0.348455, acc.: 90.62%] [G loss: 1.776160]\n",
      "epoch:23 step:21586 [D loss: 0.309479, acc.: 92.97%] [G loss: 1.753048]\n",
      "epoch:23 step:21587 [D loss: 0.194543, acc.: 97.66%] [G loss: 1.885443]\n",
      "epoch:23 step:21588 [D loss: 0.900584, acc.: 49.22%] [G loss: 1.239233]\n",
      "epoch:23 step:21589 [D loss: 1.003601, acc.: 30.47%] [G loss: 0.748950]\n",
      "epoch:23 step:21590 [D loss: 0.535951, acc.: 78.12%] [G loss: 1.198510]\n",
      "epoch:23 step:21591 [D loss: 0.638522, acc.: 60.16%] [G loss: 1.232266]\n",
      "epoch:23 step:21592 [D loss: 0.640066, acc.: 61.72%] [G loss: 1.097449]\n",
      "epoch:23 step:21593 [D loss: 0.670109, acc.: 64.06%] [G loss: 1.094468]\n",
      "epoch:23 step:21594 [D loss: 0.798997, acc.: 40.62%] [G loss: 1.392020]\n",
      "epoch:23 step:21595 [D loss: 0.597879, acc.: 65.62%] [G loss: 1.273055]\n",
      "epoch:23 step:21596 [D loss: 0.835175, acc.: 42.19%] [G loss: 0.983524]\n",
      "epoch:23 step:21597 [D loss: 0.768165, acc.: 44.53%] [G loss: 1.221105]\n",
      "epoch:23 step:21598 [D loss: 0.515817, acc.: 82.03%] [G loss: 1.182362]\n",
      "epoch:23 step:21599 [D loss: 0.510358, acc.: 78.12%] [G loss: 1.419577]\n",
      "epoch:23 step:21600 [D loss: 0.366089, acc.: 89.06%] [G loss: 1.517787]\n",
      "epoch:23 step:21601 [D loss: 0.500283, acc.: 78.91%] [G loss: 1.237974]\n",
      "epoch:23 step:21602 [D loss: 0.612752, acc.: 67.19%] [G loss: 1.036529]\n",
      "epoch:23 step:21603 [D loss: 0.648007, acc.: 63.28%] [G loss: 1.057198]\n",
      "epoch:23 step:21604 [D loss: 0.460116, acc.: 87.50%] [G loss: 1.172763]\n",
      "epoch:23 step:21605 [D loss: 0.511257, acc.: 77.34%] [G loss: 0.929260]\n",
      "epoch:23 step:21606 [D loss: 0.553344, acc.: 72.66%] [G loss: 1.287234]\n",
      "epoch:23 step:21607 [D loss: 0.746395, acc.: 48.44%] [G loss: 0.856221]\n",
      "epoch:23 step:21608 [D loss: 0.764510, acc.: 54.69%] [G loss: 1.213897]\n",
      "epoch:23 step:21609 [D loss: 0.818192, acc.: 46.09%] [G loss: 0.947424]\n",
      "epoch:23 step:21610 [D loss: 0.760822, acc.: 50.78%] [G loss: 0.805564]\n",
      "epoch:23 step:21611 [D loss: 0.876674, acc.: 34.38%] [G loss: 0.870732]\n",
      "epoch:23 step:21612 [D loss: 0.643404, acc.: 60.94%] [G loss: 1.111585]\n",
      "epoch:23 step:21613 [D loss: 0.707261, acc.: 57.03%] [G loss: 0.985167]\n",
      "epoch:23 step:21614 [D loss: 0.680994, acc.: 57.03%] [G loss: 0.742380]\n",
      "epoch:23 step:21615 [D loss: 0.734634, acc.: 45.31%] [G loss: 1.042982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21616 [D loss: 0.684965, acc.: 57.81%] [G loss: 0.944269]\n",
      "epoch:23 step:21617 [D loss: 0.594702, acc.: 64.84%] [G loss: 1.037578]\n",
      "epoch:23 step:21618 [D loss: 0.706336, acc.: 55.47%] [G loss: 0.868296]\n",
      "epoch:23 step:21619 [D loss: 0.495787, acc.: 75.78%] [G loss: 1.225355]\n",
      "epoch:23 step:21620 [D loss: 0.533658, acc.: 74.22%] [G loss: 0.919221]\n",
      "epoch:23 step:21621 [D loss: 0.766269, acc.: 48.44%] [G loss: 1.012563]\n",
      "epoch:23 step:21622 [D loss: 0.496746, acc.: 79.69%] [G loss: 0.935613]\n",
      "epoch:23 step:21623 [D loss: 0.512702, acc.: 77.34%] [G loss: 1.329606]\n",
      "epoch:23 step:21624 [D loss: 0.431113, acc.: 88.28%] [G loss: 1.278370]\n",
      "epoch:23 step:21625 [D loss: 0.325190, acc.: 94.53%] [G loss: 1.467606]\n",
      "epoch:23 step:21626 [D loss: 0.204388, acc.: 96.09%] [G loss: 1.827855]\n",
      "epoch:23 step:21627 [D loss: 0.288297, acc.: 94.53%] [G loss: 1.825231]\n",
      "epoch:23 step:21628 [D loss: 0.327662, acc.: 90.62%] [G loss: 1.604814]\n",
      "epoch:23 step:21629 [D loss: 0.758208, acc.: 53.12%] [G loss: 1.565870]\n",
      "epoch:23 step:21630 [D loss: 0.626882, acc.: 66.41%] [G loss: 1.348860]\n",
      "epoch:23 step:21631 [D loss: 0.802374, acc.: 49.22%] [G loss: 0.733598]\n",
      "epoch:23 step:21632 [D loss: 0.768127, acc.: 48.44%] [G loss: 1.308142]\n",
      "epoch:23 step:21633 [D loss: 0.790945, acc.: 42.19%] [G loss: 1.088004]\n",
      "epoch:23 step:21634 [D loss: 0.604295, acc.: 63.28%] [G loss: 1.091124]\n",
      "epoch:23 step:21635 [D loss: 0.553659, acc.: 75.00%] [G loss: 0.987055]\n",
      "epoch:23 step:21636 [D loss: 0.635971, acc.: 67.19%] [G loss: 0.773861]\n",
      "epoch:23 step:21637 [D loss: 0.760768, acc.: 47.66%] [G loss: 0.947565]\n",
      "epoch:23 step:21638 [D loss: 0.587368, acc.: 67.97%] [G loss: 1.112922]\n",
      "epoch:23 step:21639 [D loss: 0.708689, acc.: 51.56%] [G loss: 0.991177]\n",
      "epoch:23 step:21640 [D loss: 0.677553, acc.: 60.16%] [G loss: 0.736153]\n",
      "epoch:23 step:21641 [D loss: 0.669670, acc.: 60.16%] [G loss: 1.032372]\n",
      "epoch:23 step:21642 [D loss: 0.710010, acc.: 53.91%] [G loss: 1.116520]\n",
      "epoch:23 step:21643 [D loss: 0.517834, acc.: 80.47%] [G loss: 1.243625]\n",
      "epoch:23 step:21644 [D loss: 0.506086, acc.: 82.03%] [G loss: 1.407057]\n",
      "epoch:23 step:21645 [D loss: 0.599757, acc.: 64.84%] [G loss: 1.121915]\n",
      "epoch:23 step:21646 [D loss: 0.660697, acc.: 59.38%] [G loss: 1.280029]\n",
      "epoch:23 step:21647 [D loss: 0.660905, acc.: 61.72%] [G loss: 1.174251]\n",
      "epoch:23 step:21648 [D loss: 0.759367, acc.: 46.88%] [G loss: 1.143702]\n",
      "epoch:23 step:21649 [D loss: 0.801600, acc.: 44.53%] [G loss: 0.907067]\n",
      "epoch:23 step:21650 [D loss: 0.581269, acc.: 75.00%] [G loss: 1.020268]\n",
      "epoch:23 step:21651 [D loss: 0.555341, acc.: 75.00%] [G loss: 0.940622]\n",
      "epoch:23 step:21652 [D loss: 0.543926, acc.: 74.22%] [G loss: 1.280305]\n",
      "epoch:23 step:21653 [D loss: 0.582920, acc.: 67.97%] [G loss: 1.062490]\n",
      "epoch:23 step:21654 [D loss: 0.661310, acc.: 58.59%] [G loss: 0.989241]\n",
      "epoch:23 step:21655 [D loss: 0.663267, acc.: 58.59%] [G loss: 0.995088]\n",
      "epoch:23 step:21656 [D loss: 0.521051, acc.: 71.88%] [G loss: 1.018715]\n",
      "epoch:23 step:21657 [D loss: 0.535113, acc.: 73.44%] [G loss: 1.134425]\n",
      "epoch:23 step:21658 [D loss: 0.549138, acc.: 75.78%] [G loss: 0.886740]\n",
      "epoch:23 step:21659 [D loss: 0.485820, acc.: 83.59%] [G loss: 0.999715]\n",
      "epoch:23 step:21660 [D loss: 0.460904, acc.: 82.81%] [G loss: 1.043513]\n",
      "epoch:23 step:21661 [D loss: 0.633840, acc.: 63.28%] [G loss: 0.703086]\n",
      "epoch:23 step:21662 [D loss: 0.567964, acc.: 71.88%] [G loss: 0.967382]\n",
      "epoch:23 step:21663 [D loss: 0.643672, acc.: 63.28%] [G loss: 0.970215]\n",
      "epoch:23 step:21664 [D loss: 0.690599, acc.: 57.81%] [G loss: 1.149846]\n",
      "epoch:23 step:21665 [D loss: 0.637129, acc.: 57.81%] [G loss: 1.218944]\n",
      "epoch:23 step:21666 [D loss: 0.730647, acc.: 54.69%] [G loss: 1.035153]\n",
      "epoch:23 step:21667 [D loss: 0.516011, acc.: 80.47%] [G loss: 1.222103]\n",
      "epoch:23 step:21668 [D loss: 0.542309, acc.: 70.31%] [G loss: 1.040224]\n",
      "epoch:23 step:21669 [D loss: 0.549551, acc.: 70.31%] [G loss: 1.200129]\n",
      "epoch:23 step:21670 [D loss: 0.287687, acc.: 94.53%] [G loss: 1.469071]\n",
      "epoch:23 step:21671 [D loss: 0.717602, acc.: 53.91%] [G loss: 1.047606]\n",
      "epoch:23 step:21672 [D loss: 0.551212, acc.: 74.22%] [G loss: 1.150705]\n",
      "epoch:23 step:21673 [D loss: 0.364356, acc.: 92.19%] [G loss: 1.243078]\n",
      "epoch:23 step:21674 [D loss: 0.662952, acc.: 63.28%] [G loss: 0.927973]\n",
      "epoch:23 step:21675 [D loss: 0.720196, acc.: 54.69%] [G loss: 0.983490]\n",
      "epoch:23 step:21676 [D loss: 0.737403, acc.: 52.34%] [G loss: 0.963737]\n",
      "epoch:23 step:21677 [D loss: 0.623847, acc.: 62.50%] [G loss: 1.021637]\n",
      "epoch:23 step:21678 [D loss: 0.591975, acc.: 67.19%] [G loss: 1.385186]\n",
      "epoch:23 step:21679 [D loss: 0.753737, acc.: 50.00%] [G loss: 0.885036]\n",
      "epoch:23 step:21680 [D loss: 0.662154, acc.: 60.94%] [G loss: 0.898059]\n",
      "epoch:23 step:21681 [D loss: 0.598325, acc.: 66.41%] [G loss: 0.860245]\n",
      "epoch:23 step:21682 [D loss: 0.320760, acc.: 94.53%] [G loss: 1.332397]\n",
      "epoch:23 step:21683 [D loss: 0.553121, acc.: 73.44%] [G loss: 1.192934]\n",
      "epoch:23 step:21684 [D loss: 0.578080, acc.: 67.97%] [G loss: 1.158059]\n",
      "epoch:23 step:21685 [D loss: 0.749868, acc.: 48.44%] [G loss: 0.784591]\n",
      "epoch:23 step:21686 [D loss: 0.624467, acc.: 64.84%] [G loss: 0.859172]\n",
      "epoch:23 step:21687 [D loss: 0.595477, acc.: 67.19%] [G loss: 1.184508]\n",
      "epoch:23 step:21688 [D loss: 0.760754, acc.: 46.09%] [G loss: 1.034445]\n",
      "epoch:23 step:21689 [D loss: 0.612011, acc.: 64.84%] [G loss: 1.213658]\n",
      "epoch:23 step:21690 [D loss: 0.532469, acc.: 75.78%] [G loss: 1.108188]\n",
      "epoch:23 step:21691 [D loss: 0.704158, acc.: 53.91%] [G loss: 1.097394]\n",
      "epoch:23 step:21692 [D loss: 0.630887, acc.: 60.16%] [G loss: 1.035306]\n",
      "epoch:23 step:21693 [D loss: 0.504358, acc.: 76.56%] [G loss: 1.390775]\n",
      "epoch:23 step:21694 [D loss: 0.635472, acc.: 63.28%] [G loss: 1.214761]\n",
      "epoch:23 step:21695 [D loss: 0.620135, acc.: 62.50%] [G loss: 1.009559]\n",
      "epoch:23 step:21696 [D loss: 0.509875, acc.: 78.12%] [G loss: 0.942969]\n",
      "epoch:23 step:21697 [D loss: 0.871524, acc.: 43.75%] [G loss: 1.024800]\n",
      "epoch:23 step:21698 [D loss: 0.762879, acc.: 49.22%] [G loss: 1.173366]\n",
      "epoch:23 step:21699 [D loss: 0.717239, acc.: 55.47%] [G loss: 1.068675]\n",
      "epoch:23 step:21700 [D loss: 0.759595, acc.: 50.00%] [G loss: 0.999164]\n",
      "epoch:23 step:21701 [D loss: 0.586218, acc.: 64.06%] [G loss: 1.004477]\n",
      "epoch:23 step:21702 [D loss: 0.452542, acc.: 82.81%] [G loss: 1.331096]\n",
      "epoch:23 step:21703 [D loss: 0.512920, acc.: 73.44%] [G loss: 1.268514]\n",
      "epoch:23 step:21704 [D loss: 0.772727, acc.: 51.56%] [G loss: 1.461705]\n",
      "epoch:23 step:21705 [D loss: 0.516592, acc.: 76.56%] [G loss: 1.249069]\n",
      "epoch:23 step:21706 [D loss: 0.520992, acc.: 75.00%] [G loss: 1.029168]\n",
      "epoch:23 step:21707 [D loss: 0.307722, acc.: 91.41%] [G loss: 1.201813]\n",
      "epoch:23 step:21708 [D loss: 0.469740, acc.: 80.47%] [G loss: 1.193924]\n",
      "epoch:23 step:21709 [D loss: 0.452116, acc.: 82.03%] [G loss: 0.884053]\n",
      "epoch:23 step:21710 [D loss: 0.305848, acc.: 90.62%] [G loss: 1.699294]\n",
      "epoch:23 step:21711 [D loss: 0.684047, acc.: 56.25%] [G loss: 1.240771]\n",
      "epoch:23 step:21712 [D loss: 0.816996, acc.: 41.41%] [G loss: 1.208797]\n",
      "epoch:23 step:21713 [D loss: 0.655185, acc.: 59.38%] [G loss: 0.999386]\n",
      "epoch:23 step:21714 [D loss: 0.510205, acc.: 78.12%] [G loss: 1.134757]\n",
      "epoch:23 step:21715 [D loss: 0.463810, acc.: 82.81%] [G loss: 1.095577]\n",
      "epoch:23 step:21716 [D loss: 0.424063, acc.: 84.38%] [G loss: 1.304260]\n",
      "epoch:23 step:21717 [D loss: 0.445391, acc.: 88.28%] [G loss: 1.422720]\n",
      "epoch:23 step:21718 [D loss: 0.322280, acc.: 92.97%] [G loss: 1.509013]\n",
      "epoch:23 step:21719 [D loss: 0.497760, acc.: 78.91%] [G loss: 1.368216]\n",
      "epoch:23 step:21720 [D loss: 0.602298, acc.: 62.50%] [G loss: 1.214406]\n",
      "epoch:23 step:21721 [D loss: 0.602280, acc.: 64.06%] [G loss: 1.426767]\n",
      "epoch:23 step:21722 [D loss: 0.889141, acc.: 43.75%] [G loss: 0.580657]\n",
      "epoch:23 step:21723 [D loss: 0.404843, acc.: 90.62%] [G loss: 1.463851]\n",
      "epoch:23 step:21724 [D loss: 0.867525, acc.: 37.50%] [G loss: 0.979239]\n",
      "epoch:23 step:21725 [D loss: 0.878331, acc.: 35.16%] [G loss: 0.967834]\n",
      "epoch:23 step:21726 [D loss: 0.970578, acc.: 37.50%] [G loss: 0.888424]\n",
      "epoch:23 step:21727 [D loss: 0.840336, acc.: 39.06%] [G loss: 0.736568]\n",
      "epoch:23 step:21728 [D loss: 1.100124, acc.: 19.53%] [G loss: 0.944889]\n",
      "epoch:23 step:21729 [D loss: 0.868130, acc.: 42.19%] [G loss: 1.003191]\n",
      "epoch:23 step:21730 [D loss: 0.820020, acc.: 42.97%] [G loss: 1.144127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21731 [D loss: 0.815762, acc.: 37.50%] [G loss: 1.089404]\n",
      "epoch:23 step:21732 [D loss: 0.617213, acc.: 63.28%] [G loss: 1.041746]\n",
      "epoch:23 step:21733 [D loss: 0.568037, acc.: 72.66%] [G loss: 0.965159]\n",
      "epoch:23 step:21734 [D loss: 1.267559, acc.: 13.28%] [G loss: 0.725320]\n",
      "epoch:23 step:21735 [D loss: 0.828168, acc.: 43.75%] [G loss: 0.893073]\n",
      "epoch:23 step:21736 [D loss: 0.932173, acc.: 39.84%] [G loss: 1.198529]\n",
      "epoch:23 step:21737 [D loss: 0.893415, acc.: 41.41%] [G loss: 0.940044]\n",
      "epoch:23 step:21738 [D loss: 0.759731, acc.: 52.34%] [G loss: 0.903915]\n",
      "epoch:23 step:21739 [D loss: 0.708778, acc.: 54.69%] [G loss: 0.969530]\n",
      "epoch:23 step:21740 [D loss: 0.895970, acc.: 36.72%] [G loss: 0.916003]\n",
      "epoch:23 step:21741 [D loss: 0.549132, acc.: 69.53%] [G loss: 1.239121]\n",
      "epoch:23 step:21742 [D loss: 0.613674, acc.: 71.09%] [G loss: 1.294670]\n",
      "epoch:23 step:21743 [D loss: 0.540965, acc.: 70.31%] [G loss: 0.971997]\n",
      "epoch:23 step:21744 [D loss: 0.649267, acc.: 60.16%] [G loss: 1.277351]\n",
      "epoch:23 step:21745 [D loss: 0.660370, acc.: 62.50%] [G loss: 1.233973]\n",
      "epoch:23 step:21746 [D loss: 0.797062, acc.: 46.88%] [G loss: 0.879288]\n",
      "epoch:23 step:21747 [D loss: 0.750467, acc.: 51.56%] [G loss: 1.075758]\n",
      "epoch:23 step:21748 [D loss: 0.835190, acc.: 41.41%] [G loss: 0.838973]\n",
      "epoch:23 step:21749 [D loss: 0.712357, acc.: 56.25%] [G loss: 1.060043]\n",
      "epoch:23 step:21750 [D loss: 0.811136, acc.: 46.88%] [G loss: 1.050306]\n",
      "epoch:23 step:21751 [D loss: 0.547390, acc.: 73.44%] [G loss: 1.058318]\n",
      "epoch:23 step:21752 [D loss: 0.492624, acc.: 78.91%] [G loss: 1.338687]\n",
      "epoch:23 step:21753 [D loss: 0.577166, acc.: 71.09%] [G loss: 1.311397]\n",
      "epoch:23 step:21754 [D loss: 0.782209, acc.: 50.78%] [G loss: 1.129365]\n",
      "epoch:23 step:21755 [D loss: 0.623987, acc.: 66.41%] [G loss: 1.251621]\n",
      "epoch:23 step:21756 [D loss: 0.804528, acc.: 40.62%] [G loss: 1.092164]\n",
      "epoch:23 step:21757 [D loss: 0.672006, acc.: 61.72%] [G loss: 0.941168]\n",
      "epoch:23 step:21758 [D loss: 0.599403, acc.: 71.09%] [G loss: 0.922524]\n",
      "epoch:23 step:21759 [D loss: 0.582918, acc.: 71.88%] [G loss: 0.998046]\n",
      "epoch:23 step:21760 [D loss: 0.618936, acc.: 62.50%] [G loss: 0.974940]\n",
      "epoch:23 step:21761 [D loss: 0.630130, acc.: 64.06%] [G loss: 0.803764]\n",
      "epoch:23 step:21762 [D loss: 0.563734, acc.: 71.09%] [G loss: 1.264641]\n",
      "epoch:23 step:21763 [D loss: 0.538671, acc.: 75.00%] [G loss: 1.242141]\n",
      "epoch:23 step:21764 [D loss: 0.418948, acc.: 80.47%] [G loss: 1.143561]\n",
      "epoch:23 step:21765 [D loss: 0.599540, acc.: 68.75%] [G loss: 1.380927]\n",
      "epoch:23 step:21766 [D loss: 0.363163, acc.: 94.53%] [G loss: 1.489972]\n",
      "epoch:23 step:21767 [D loss: 0.597327, acc.: 66.41%] [G loss: 1.355230]\n",
      "epoch:23 step:21768 [D loss: 0.825359, acc.: 46.88%] [G loss: 1.163500]\n",
      "epoch:23 step:21769 [D loss: 0.713864, acc.: 53.91%] [G loss: 1.082090]\n",
      "epoch:23 step:21770 [D loss: 0.931417, acc.: 32.81%] [G loss: 0.962816]\n",
      "epoch:23 step:21771 [D loss: 0.237919, acc.: 92.97%] [G loss: 1.284202]\n",
      "epoch:23 step:21772 [D loss: 0.293421, acc.: 86.72%] [G loss: 1.394418]\n",
      "epoch:23 step:21773 [D loss: 0.272819, acc.: 94.53%] [G loss: 1.950644]\n",
      "epoch:23 step:21774 [D loss: 0.207296, acc.: 96.88%] [G loss: 1.860395]\n",
      "epoch:23 step:21775 [D loss: 0.870256, acc.: 46.88%] [G loss: 1.652211]\n",
      "epoch:23 step:21776 [D loss: 0.771109, acc.: 51.56%] [G loss: 1.008265]\n",
      "epoch:23 step:21777 [D loss: 0.442560, acc.: 79.69%] [G loss: 1.021993]\n",
      "epoch:23 step:21778 [D loss: 0.650409, acc.: 63.28%] [G loss: 0.877206]\n",
      "epoch:23 step:21779 [D loss: 0.654005, acc.: 63.28%] [G loss: 1.001285]\n",
      "epoch:23 step:21780 [D loss: 0.686730, acc.: 58.59%] [G loss: 1.034235]\n",
      "epoch:23 step:21781 [D loss: 0.167834, acc.: 100.00%] [G loss: 1.506425]\n",
      "epoch:23 step:21782 [D loss: 0.244657, acc.: 96.09%] [G loss: 1.380343]\n",
      "epoch:23 step:21783 [D loss: 0.261627, acc.: 94.53%] [G loss: 1.724097]\n",
      "epoch:23 step:21784 [D loss: 1.025842, acc.: 38.28%] [G loss: 1.105167]\n",
      "epoch:23 step:21785 [D loss: 0.828969, acc.: 46.88%] [G loss: 0.981310]\n",
      "epoch:23 step:21786 [D loss: 0.724363, acc.: 58.59%] [G loss: 0.787296]\n",
      "epoch:23 step:21787 [D loss: 0.771584, acc.: 50.00%] [G loss: 1.223389]\n",
      "epoch:23 step:21788 [D loss: 0.957407, acc.: 36.72%] [G loss: 0.777186]\n",
      "epoch:23 step:21789 [D loss: 0.639223, acc.: 64.06%] [G loss: 1.501825]\n",
      "epoch:23 step:21790 [D loss: 0.819918, acc.: 40.62%] [G loss: 0.969632]\n",
      "epoch:23 step:21791 [D loss: 0.772175, acc.: 45.31%] [G loss: 0.773637]\n",
      "epoch:23 step:21792 [D loss: 0.600143, acc.: 64.06%] [G loss: 1.161922]\n",
      "epoch:23 step:21793 [D loss: 0.725687, acc.: 51.56%] [G loss: 1.250810]\n",
      "epoch:23 step:21794 [D loss: 0.509978, acc.: 76.56%] [G loss: 1.396483]\n",
      "epoch:23 step:21795 [D loss: 0.509172, acc.: 78.12%] [G loss: 1.107573]\n",
      "epoch:23 step:21796 [D loss: 0.425477, acc.: 85.16%] [G loss: 1.269047]\n",
      "epoch:23 step:21797 [D loss: 0.456582, acc.: 81.25%] [G loss: 1.334859]\n",
      "epoch:23 step:21798 [D loss: 0.529274, acc.: 78.12%] [G loss: 1.153781]\n",
      "epoch:23 step:21799 [D loss: 0.396120, acc.: 88.28%] [G loss: 1.246984]\n",
      "epoch:23 step:21800 [D loss: 0.600178, acc.: 71.88%] [G loss: 1.173262]\n",
      "epoch:23 step:21801 [D loss: 0.500795, acc.: 78.91%] [G loss: 1.319793]\n",
      "epoch:23 step:21802 [D loss: 0.559540, acc.: 73.44%] [G loss: 1.319152]\n",
      "epoch:23 step:21803 [D loss: 0.592323, acc.: 65.62%] [G loss: 1.150970]\n",
      "epoch:23 step:21804 [D loss: 0.513986, acc.: 70.31%] [G loss: 1.176692]\n",
      "epoch:23 step:21805 [D loss: 0.582629, acc.: 67.19%] [G loss: 0.780904]\n",
      "epoch:23 step:21806 [D loss: 0.686600, acc.: 57.81%] [G loss: 0.944441]\n",
      "epoch:23 step:21807 [D loss: 0.639463, acc.: 63.28%] [G loss: 1.063828]\n",
      "epoch:23 step:21808 [D loss: 0.598948, acc.: 64.06%] [G loss: 0.874569]\n",
      "epoch:23 step:21809 [D loss: 0.582225, acc.: 68.75%] [G loss: 0.966114]\n",
      "epoch:23 step:21810 [D loss: 0.632499, acc.: 61.72%] [G loss: 0.974352]\n",
      "epoch:23 step:21811 [D loss: 0.701904, acc.: 55.47%] [G loss: 1.041253]\n",
      "epoch:23 step:21812 [D loss: 0.596230, acc.: 65.62%] [G loss: 1.145820]\n",
      "epoch:23 step:21813 [D loss: 0.619375, acc.: 62.50%] [G loss: 1.103451]\n",
      "epoch:23 step:21814 [D loss: 0.588560, acc.: 70.31%] [G loss: 0.987943]\n",
      "epoch:23 step:21815 [D loss: 0.359206, acc.: 92.19%] [G loss: 1.197278]\n",
      "epoch:23 step:21816 [D loss: 0.819418, acc.: 39.84%] [G loss: 0.873114]\n",
      "epoch:23 step:21817 [D loss: 0.719664, acc.: 53.12%] [G loss: 1.194031]\n",
      "epoch:23 step:21818 [D loss: 0.681264, acc.: 57.03%] [G loss: 0.872085]\n",
      "epoch:23 step:21819 [D loss: 0.667767, acc.: 59.38%] [G loss: 1.039179]\n",
      "epoch:23 step:21820 [D loss: 0.494224, acc.: 81.25%] [G loss: 0.960003]\n",
      "epoch:23 step:21821 [D loss: 0.636302, acc.: 63.28%] [G loss: 0.806272]\n",
      "epoch:23 step:21822 [D loss: 0.584443, acc.: 69.53%] [G loss: 0.953714]\n",
      "epoch:23 step:21823 [D loss: 0.418859, acc.: 85.16%] [G loss: 1.082866]\n",
      "epoch:23 step:21824 [D loss: 0.624906, acc.: 68.75%] [G loss: 1.146890]\n",
      "epoch:23 step:21825 [D loss: 0.592216, acc.: 74.22%] [G loss: 1.057563]\n",
      "epoch:23 step:21826 [D loss: 0.786524, acc.: 42.97%] [G loss: 1.063966]\n",
      "epoch:23 step:21827 [D loss: 0.727193, acc.: 47.66%] [G loss: 0.976799]\n",
      "epoch:23 step:21828 [D loss: 0.742420, acc.: 50.00%] [G loss: 1.159858]\n",
      "epoch:23 step:21829 [D loss: 0.624450, acc.: 64.84%] [G loss: 0.932748]\n",
      "epoch:23 step:21830 [D loss: 0.361708, acc.: 92.19%] [G loss: 1.263715]\n",
      "epoch:23 step:21831 [D loss: 0.337821, acc.: 92.97%] [G loss: 1.235955]\n",
      "epoch:23 step:21832 [D loss: 0.715690, acc.: 53.91%] [G loss: 1.068265]\n",
      "epoch:23 step:21833 [D loss: 0.646605, acc.: 60.94%] [G loss: 1.027159]\n",
      "epoch:23 step:21834 [D loss: 0.752910, acc.: 50.78%] [G loss: 1.245189]\n",
      "epoch:23 step:21835 [D loss: 0.338648, acc.: 92.19%] [G loss: 1.593436]\n",
      "epoch:23 step:21836 [D loss: 0.497687, acc.: 77.34%] [G loss: 1.025545]\n",
      "epoch:23 step:21837 [D loss: 0.347383, acc.: 95.31%] [G loss: 1.119154]\n",
      "epoch:23 step:21838 [D loss: 0.572664, acc.: 67.97%] [G loss: 1.229900]\n",
      "epoch:23 step:21839 [D loss: 0.510010, acc.: 75.00%] [G loss: 1.190797]\n",
      "epoch:23 step:21840 [D loss: 0.453926, acc.: 77.34%] [G loss: 1.194646]\n",
      "epoch:23 step:21841 [D loss: 0.576990, acc.: 69.53%] [G loss: 1.160671]\n",
      "epoch:23 step:21842 [D loss: 0.325918, acc.: 87.50%] [G loss: 1.256268]\n",
      "epoch:23 step:21843 [D loss: 0.415686, acc.: 85.16%] [G loss: 1.298452]\n",
      "epoch:23 step:21844 [D loss: 0.257434, acc.: 96.88%] [G loss: 1.424882]\n",
      "epoch:23 step:21845 [D loss: 0.541857, acc.: 74.22%] [G loss: 1.192916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21846 [D loss: 0.728736, acc.: 54.69%] [G loss: 1.409783]\n",
      "epoch:23 step:21847 [D loss: 0.584410, acc.: 69.53%] [G loss: 1.046997]\n",
      "epoch:23 step:21848 [D loss: 0.909474, acc.: 34.38%] [G loss: 0.954044]\n",
      "epoch:23 step:21849 [D loss: 0.720680, acc.: 56.25%] [G loss: 0.991648]\n",
      "epoch:23 step:21850 [D loss: 0.652997, acc.: 60.16%] [G loss: 1.410601]\n",
      "epoch:23 step:21851 [D loss: 0.693677, acc.: 53.12%] [G loss: 1.097287]\n",
      "epoch:23 step:21852 [D loss: 0.651002, acc.: 65.62%] [G loss: 1.014587]\n",
      "epoch:23 step:21853 [D loss: 0.552115, acc.: 77.34%] [G loss: 1.195632]\n",
      "epoch:23 step:21854 [D loss: 0.611725, acc.: 64.06%] [G loss: 1.290486]\n",
      "epoch:23 step:21855 [D loss: 0.575968, acc.: 64.06%] [G loss: 1.176858]\n",
      "epoch:23 step:21856 [D loss: 0.494763, acc.: 78.91%] [G loss: 1.149909]\n",
      "epoch:23 step:21857 [D loss: 0.536691, acc.: 73.44%] [G loss: 1.194886]\n",
      "epoch:23 step:21858 [D loss: 0.775286, acc.: 53.12%] [G loss: 1.056613]\n",
      "epoch:23 step:21859 [D loss: 0.318960, acc.: 92.97%] [G loss: 1.132150]\n",
      "epoch:23 step:21860 [D loss: 0.383324, acc.: 88.28%] [G loss: 1.364820]\n",
      "epoch:23 step:21861 [D loss: 0.472928, acc.: 82.81%] [G loss: 1.435825]\n",
      "epoch:23 step:21862 [D loss: 0.723170, acc.: 50.78%] [G loss: 0.827839]\n",
      "epoch:23 step:21863 [D loss: 0.338446, acc.: 89.06%] [G loss: 1.889972]\n",
      "epoch:23 step:21864 [D loss: 0.327767, acc.: 92.97%] [G loss: 1.362330]\n",
      "epoch:23 step:21865 [D loss: 0.461910, acc.: 79.69%] [G loss: 1.537500]\n",
      "epoch:23 step:21866 [D loss: 0.520790, acc.: 76.56%] [G loss: 1.550262]\n",
      "epoch:23 step:21867 [D loss: 1.097064, acc.: 37.50%] [G loss: 0.935769]\n",
      "epoch:23 step:21868 [D loss: 0.950112, acc.: 24.22%] [G loss: 0.983931]\n",
      "epoch:23 step:21869 [D loss: 0.703145, acc.: 55.47%] [G loss: 1.035715]\n",
      "epoch:23 step:21870 [D loss: 0.574148, acc.: 71.88%] [G loss: 1.297581]\n",
      "epoch:23 step:21871 [D loss: 0.581437, acc.: 70.31%] [G loss: 1.393468]\n",
      "epoch:23 step:21872 [D loss: 0.464080, acc.: 79.69%] [G loss: 1.477079]\n",
      "epoch:23 step:21873 [D loss: 0.390496, acc.: 89.06%] [G loss: 1.539987]\n",
      "epoch:23 step:21874 [D loss: 0.688504, acc.: 59.38%] [G loss: 1.073092]\n",
      "epoch:23 step:21875 [D loss: 0.399681, acc.: 89.84%] [G loss: 1.464405]\n",
      "epoch:23 step:21876 [D loss: 0.486494, acc.: 82.81%] [G loss: 1.129952]\n",
      "epoch:23 step:21877 [D loss: 0.387829, acc.: 87.50%] [G loss: 1.046160]\n",
      "epoch:23 step:21878 [D loss: 0.265449, acc.: 94.53%] [G loss: 1.272581]\n",
      "epoch:23 step:21879 [D loss: 0.230512, acc.: 99.22%] [G loss: 1.795814]\n",
      "epoch:23 step:21880 [D loss: 0.514282, acc.: 71.88%] [G loss: 1.565356]\n",
      "epoch:23 step:21881 [D loss: 0.520765, acc.: 76.56%] [G loss: 1.207942]\n",
      "epoch:23 step:21882 [D loss: 0.665046, acc.: 61.72%] [G loss: 1.312150]\n",
      "epoch:23 step:21883 [D loss: 0.585046, acc.: 67.97%] [G loss: 0.902964]\n",
      "epoch:23 step:21884 [D loss: 0.742998, acc.: 58.59%] [G loss: 0.929042]\n",
      "epoch:23 step:21885 [D loss: 0.642420, acc.: 64.06%] [G loss: 1.136727]\n",
      "epoch:23 step:21886 [D loss: 0.721297, acc.: 57.81%] [G loss: 1.095921]\n",
      "epoch:23 step:21887 [D loss: 0.644525, acc.: 64.06%] [G loss: 1.067948]\n",
      "epoch:23 step:21888 [D loss: 0.623680, acc.: 67.19%] [G loss: 1.201209]\n",
      "epoch:23 step:21889 [D loss: 0.439564, acc.: 83.59%] [G loss: 1.331019]\n",
      "epoch:23 step:21890 [D loss: 0.524720, acc.: 75.00%] [G loss: 1.389436]\n",
      "epoch:23 step:21891 [D loss: 0.618323, acc.: 65.62%] [G loss: 1.002660]\n",
      "epoch:23 step:21892 [D loss: 0.962792, acc.: 35.16%] [G loss: 1.179962]\n",
      "epoch:23 step:21893 [D loss: 0.861930, acc.: 45.31%] [G loss: 1.436673]\n",
      "epoch:23 step:21894 [D loss: 0.496309, acc.: 78.12%] [G loss: 1.065403]\n",
      "epoch:23 step:21895 [D loss: 0.532146, acc.: 71.88%] [G loss: 1.064380]\n",
      "epoch:23 step:21896 [D loss: 0.414180, acc.: 83.59%] [G loss: 1.418498]\n",
      "epoch:23 step:21897 [D loss: 0.392803, acc.: 90.62%] [G loss: 1.478184]\n",
      "epoch:23 step:21898 [D loss: 0.285446, acc.: 96.88%] [G loss: 1.541450]\n",
      "epoch:23 step:21899 [D loss: 0.735530, acc.: 53.91%] [G loss: 1.255500]\n",
      "epoch:23 step:21900 [D loss: 0.789920, acc.: 47.66%] [G loss: 0.977282]\n",
      "epoch:23 step:21901 [D loss: 0.659825, acc.: 62.50%] [G loss: 0.850417]\n",
      "epoch:23 step:21902 [D loss: 0.529816, acc.: 75.78%] [G loss: 0.944400]\n",
      "epoch:23 step:21903 [D loss: 0.535859, acc.: 77.34%] [G loss: 1.195903]\n",
      "epoch:23 step:21904 [D loss: 0.575747, acc.: 71.09%] [G loss: 1.042777]\n",
      "epoch:23 step:21905 [D loss: 0.410244, acc.: 90.62%] [G loss: 1.207554]\n",
      "epoch:23 step:21906 [D loss: 0.850670, acc.: 41.41%] [G loss: 0.882446]\n",
      "epoch:23 step:21907 [D loss: 0.607668, acc.: 67.97%] [G loss: 1.329553]\n",
      "epoch:23 step:21908 [D loss: 0.728711, acc.: 49.22%] [G loss: 0.891655]\n",
      "epoch:23 step:21909 [D loss: 0.477556, acc.: 78.91%] [G loss: 1.160347]\n",
      "epoch:23 step:21910 [D loss: 0.391257, acc.: 89.84%] [G loss: 1.245496]\n",
      "epoch:23 step:21911 [D loss: 0.716006, acc.: 53.12%] [G loss: 1.099408]\n",
      "epoch:23 step:21912 [D loss: 0.817198, acc.: 43.75%] [G loss: 1.096344]\n",
      "epoch:23 step:21913 [D loss: 0.798755, acc.: 46.88%] [G loss: 1.113044]\n",
      "epoch:23 step:21914 [D loss: 0.609609, acc.: 65.62%] [G loss: 1.291724]\n",
      "epoch:23 step:21915 [D loss: 0.696094, acc.: 59.38%] [G loss: 1.082284]\n",
      "epoch:23 step:21916 [D loss: 0.446652, acc.: 81.25%] [G loss: 1.340891]\n",
      "epoch:23 step:21917 [D loss: 0.306327, acc.: 90.62%] [G loss: 1.653007]\n",
      "epoch:23 step:21918 [D loss: 0.198705, acc.: 99.22%] [G loss: 1.890142]\n",
      "epoch:23 step:21919 [D loss: 0.629189, acc.: 65.62%] [G loss: 1.292727]\n",
      "epoch:23 step:21920 [D loss: 0.723772, acc.: 53.91%] [G loss: 1.117386]\n",
      "epoch:23 step:21921 [D loss: 0.566417, acc.: 70.31%] [G loss: 0.996651]\n",
      "epoch:23 step:21922 [D loss: 0.613708, acc.: 66.41%] [G loss: 0.942099]\n",
      "epoch:23 step:21923 [D loss: 0.537992, acc.: 75.78%] [G loss: 1.191601]\n",
      "epoch:23 step:21924 [D loss: 0.793207, acc.: 48.44%] [G loss: 1.152352]\n",
      "epoch:23 step:21925 [D loss: 0.493408, acc.: 78.91%] [G loss: 1.287593]\n",
      "epoch:23 step:21926 [D loss: 0.673568, acc.: 60.94%] [G loss: 1.205242]\n",
      "epoch:23 step:21927 [D loss: 0.437379, acc.: 80.47%] [G loss: 1.262541]\n",
      "epoch:23 step:21928 [D loss: 0.394694, acc.: 85.16%] [G loss: 1.126468]\n",
      "epoch:23 step:21929 [D loss: 0.292890, acc.: 93.75%] [G loss: 1.415275]\n",
      "epoch:23 step:21930 [D loss: 0.773199, acc.: 46.09%] [G loss: 1.074725]\n",
      "epoch:23 step:21931 [D loss: 0.755980, acc.: 46.88%] [G loss: 1.148454]\n",
      "epoch:23 step:21932 [D loss: 0.590579, acc.: 67.19%] [G loss: 1.016299]\n",
      "epoch:23 step:21933 [D loss: 0.606964, acc.: 69.53%] [G loss: 0.924743]\n",
      "epoch:23 step:21934 [D loss: 0.749761, acc.: 43.75%] [G loss: 0.842565]\n",
      "epoch:23 step:21935 [D loss: 0.504713, acc.: 79.69%] [G loss: 1.112773]\n",
      "epoch:23 step:21936 [D loss: 0.477834, acc.: 83.59%] [G loss: 1.272490]\n",
      "epoch:23 step:21937 [D loss: 0.836834, acc.: 44.53%] [G loss: 0.813023]\n",
      "epoch:23 step:21938 [D loss: 0.646540, acc.: 62.50%] [G loss: 1.253418]\n",
      "epoch:23 step:21939 [D loss: 0.705230, acc.: 60.16%] [G loss: 1.134617]\n",
      "epoch:23 step:21940 [D loss: 0.740323, acc.: 53.91%] [G loss: 1.038409]\n",
      "epoch:23 step:21941 [D loss: 0.487508, acc.: 73.44%] [G loss: 1.254000]\n",
      "epoch:23 step:21942 [D loss: 0.481958, acc.: 79.69%] [G loss: 1.337387]\n",
      "epoch:23 step:21943 [D loss: 0.545581, acc.: 75.00%] [G loss: 1.113939]\n",
      "epoch:23 step:21944 [D loss: 0.635220, acc.: 67.97%] [G loss: 0.994309]\n",
      "epoch:23 step:21945 [D loss: 0.755353, acc.: 55.47%] [G loss: 0.876358]\n",
      "epoch:23 step:21946 [D loss: 0.724926, acc.: 53.91%] [G loss: 0.989333]\n",
      "epoch:23 step:21947 [D loss: 0.385359, acc.: 83.59%] [G loss: 1.064141]\n",
      "epoch:23 step:21948 [D loss: 0.417642, acc.: 73.44%] [G loss: 1.137776]\n",
      "epoch:23 step:21949 [D loss: 0.390632, acc.: 85.16%] [G loss: 1.276588]\n",
      "epoch:23 step:21950 [D loss: 0.388268, acc.: 86.72%] [G loss: 1.740355]\n",
      "epoch:23 step:21951 [D loss: 0.499907, acc.: 75.78%] [G loss: 1.254306]\n",
      "epoch:23 step:21952 [D loss: 0.567819, acc.: 72.66%] [G loss: 1.091319]\n",
      "epoch:23 step:21953 [D loss: 0.712632, acc.: 53.91%] [G loss: 1.141314]\n",
      "epoch:23 step:21954 [D loss: 0.589405, acc.: 64.06%] [G loss: 1.459002]\n",
      "epoch:23 step:21955 [D loss: 0.425057, acc.: 80.47%] [G loss: 1.717621]\n",
      "epoch:23 step:21956 [D loss: 0.477255, acc.: 78.12%] [G loss: 1.372711]\n",
      "epoch:23 step:21957 [D loss: 0.741525, acc.: 60.94%] [G loss: 0.941318]\n",
      "epoch:23 step:21958 [D loss: 0.851705, acc.: 41.41%] [G loss: 1.106524]\n",
      "epoch:23 step:21959 [D loss: 0.819686, acc.: 45.31%] [G loss: 1.016837]\n",
      "epoch:23 step:21960 [D loss: 0.710789, acc.: 58.59%] [G loss: 1.077616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21961 [D loss: 0.919503, acc.: 37.50%] [G loss: 0.889910]\n",
      "epoch:23 step:21962 [D loss: 0.991003, acc.: 35.16%] [G loss: 0.922513]\n",
      "epoch:23 step:21963 [D loss: 0.749002, acc.: 53.91%] [G loss: 1.272876]\n",
      "epoch:23 step:21964 [D loss: 0.688490, acc.: 63.28%] [G loss: 1.426909]\n",
      "epoch:23 step:21965 [D loss: 0.594785, acc.: 69.53%] [G loss: 1.072665]\n",
      "epoch:23 step:21966 [D loss: 0.564197, acc.: 71.88%] [G loss: 1.325090]\n",
      "epoch:23 step:21967 [D loss: 0.636744, acc.: 65.62%] [G loss: 1.280174]\n",
      "epoch:23 step:21968 [D loss: 0.859850, acc.: 42.97%] [G loss: 0.977137]\n",
      "epoch:23 step:21969 [D loss: 0.521944, acc.: 75.78%] [G loss: 1.072993]\n",
      "epoch:23 step:21970 [D loss: 0.782999, acc.: 51.56%] [G loss: 1.097183]\n",
      "epoch:23 step:21971 [D loss: 0.769798, acc.: 56.25%] [G loss: 1.113424]\n",
      "epoch:23 step:21972 [D loss: 0.522099, acc.: 76.56%] [G loss: 1.204446]\n",
      "epoch:23 step:21973 [D loss: 0.456390, acc.: 79.69%] [G loss: 1.431226]\n",
      "epoch:23 step:21974 [D loss: 0.567695, acc.: 69.53%] [G loss: 1.411884]\n",
      "epoch:23 step:21975 [D loss: 0.778071, acc.: 48.44%] [G loss: 1.056125]\n",
      "epoch:23 step:21976 [D loss: 0.676205, acc.: 60.16%] [G loss: 0.977128]\n",
      "epoch:23 step:21977 [D loss: 0.669836, acc.: 60.16%] [G loss: 0.938634]\n",
      "epoch:23 step:21978 [D loss: 0.617299, acc.: 69.53%] [G loss: 1.226439]\n",
      "epoch:23 step:21979 [D loss: 0.560404, acc.: 69.53%] [G loss: 1.317905]\n",
      "epoch:23 step:21980 [D loss: 0.574569, acc.: 70.31%] [G loss: 1.252247]\n",
      "epoch:23 step:21981 [D loss: 0.593034, acc.: 65.62%] [G loss: 1.106535]\n",
      "epoch:23 step:21982 [D loss: 0.515077, acc.: 75.78%] [G loss: 1.209361]\n",
      "epoch:23 step:21983 [D loss: 0.567409, acc.: 70.31%] [G loss: 1.719929]\n",
      "epoch:23 step:21984 [D loss: 0.453066, acc.: 84.38%] [G loss: 1.314049]\n",
      "epoch:23 step:21985 [D loss: 0.675439, acc.: 59.38%] [G loss: 1.234968]\n",
      "epoch:23 step:21986 [D loss: 0.454147, acc.: 85.16%] [G loss: 1.199124]\n",
      "epoch:23 step:21987 [D loss: 0.521220, acc.: 76.56%] [G loss: 0.892385]\n",
      "epoch:23 step:21988 [D loss: 0.851138, acc.: 44.53%] [G loss: 0.822716]\n",
      "epoch:23 step:21989 [D loss: 0.755512, acc.: 48.44%] [G loss: 0.975393]\n",
      "epoch:23 step:21990 [D loss: 0.813185, acc.: 39.84%] [G loss: 1.189745]\n",
      "epoch:23 step:21991 [D loss: 0.593006, acc.: 67.19%] [G loss: 1.310509]\n",
      "epoch:23 step:21992 [D loss: 0.880671, acc.: 35.94%] [G loss: 0.828713]\n",
      "epoch:23 step:21993 [D loss: 0.556467, acc.: 66.41%] [G loss: 1.615763]\n",
      "epoch:23 step:21994 [D loss: 0.552976, acc.: 72.66%] [G loss: 1.183320]\n",
      "epoch:23 step:21995 [D loss: 0.661173, acc.: 62.50%] [G loss: 1.078452]\n",
      "epoch:23 step:21996 [D loss: 0.907724, acc.: 39.06%] [G loss: 0.681806]\n",
      "epoch:23 step:21997 [D loss: 0.735573, acc.: 52.34%] [G loss: 1.109799]\n",
      "epoch:23 step:21998 [D loss: 0.696788, acc.: 57.03%] [G loss: 1.204883]\n",
      "epoch:23 step:21999 [D loss: 0.617719, acc.: 66.41%] [G loss: 1.138674]\n",
      "epoch:23 step:22000 [D loss: 0.588971, acc.: 72.66%] [G loss: 1.201759]\n",
      "epoch:23 step:22001 [D loss: 0.572363, acc.: 69.53%] [G loss: 1.423884]\n",
      "epoch:23 step:22002 [D loss: 0.556853, acc.: 71.09%] [G loss: 1.078364]\n",
      "epoch:23 step:22003 [D loss: 0.539256, acc.: 74.22%] [G loss: 1.349087]\n",
      "epoch:23 step:22004 [D loss: 0.494794, acc.: 78.12%] [G loss: 1.350075]\n",
      "epoch:23 step:22005 [D loss: 0.539933, acc.: 70.31%] [G loss: 1.408002]\n",
      "epoch:23 step:22006 [D loss: 0.577929, acc.: 70.31%] [G loss: 1.123303]\n",
      "epoch:23 step:22007 [D loss: 0.667792, acc.: 62.50%] [G loss: 1.138213]\n",
      "epoch:23 step:22008 [D loss: 0.543756, acc.: 71.88%] [G loss: 1.076459]\n",
      "epoch:23 step:22009 [D loss: 0.951681, acc.: 42.19%] [G loss: 1.451818]\n",
      "epoch:23 step:22010 [D loss: 0.921837, acc.: 34.38%] [G loss: 0.723960]\n",
      "epoch:23 step:22011 [D loss: 0.628170, acc.: 68.75%] [G loss: 1.107154]\n",
      "epoch:23 step:22012 [D loss: 1.047464, acc.: 28.91%] [G loss: 0.861921]\n",
      "epoch:23 step:22013 [D loss: 0.830873, acc.: 42.97%] [G loss: 0.736198]\n",
      "epoch:23 step:22014 [D loss: 0.774797, acc.: 49.22%] [G loss: 0.925473]\n",
      "epoch:23 step:22015 [D loss: 0.643380, acc.: 61.72%] [G loss: 1.066053]\n",
      "epoch:23 step:22016 [D loss: 0.675760, acc.: 60.16%] [G loss: 1.091503]\n",
      "epoch:23 step:22017 [D loss: 0.639331, acc.: 62.50%] [G loss: 1.118021]\n",
      "epoch:23 step:22018 [D loss: 0.682306, acc.: 61.72%] [G loss: 1.221737]\n",
      "epoch:23 step:22019 [D loss: 0.626970, acc.: 60.16%] [G loss: 1.076138]\n",
      "epoch:23 step:22020 [D loss: 0.577826, acc.: 71.88%] [G loss: 0.936588]\n",
      "epoch:23 step:22021 [D loss: 0.581499, acc.: 68.75%] [G loss: 1.437198]\n",
      "epoch:23 step:22022 [D loss: 0.257221, acc.: 96.88%] [G loss: 1.585814]\n",
      "epoch:23 step:22023 [D loss: 0.560784, acc.: 71.09%] [G loss: 1.458387]\n",
      "epoch:23 step:22024 [D loss: 0.565079, acc.: 65.62%] [G loss: 1.661858]\n",
      "epoch:23 step:22025 [D loss: 0.523401, acc.: 78.91%] [G loss: 1.136019]\n",
      "epoch:23 step:22026 [D loss: 0.408044, acc.: 85.16%] [G loss: 1.755987]\n",
      "epoch:23 step:22027 [D loss: 0.828706, acc.: 46.88%] [G loss: 1.320863]\n",
      "epoch:23 step:22028 [D loss: 0.618508, acc.: 66.41%] [G loss: 1.079943]\n",
      "epoch:23 step:22029 [D loss: 0.696472, acc.: 61.72%] [G loss: 1.052517]\n",
      "epoch:23 step:22030 [D loss: 0.518681, acc.: 76.56%] [G loss: 1.050884]\n",
      "epoch:23 step:22031 [D loss: 0.561349, acc.: 71.88%] [G loss: 1.004146]\n",
      "epoch:23 step:22032 [D loss: 0.522440, acc.: 76.56%] [G loss: 1.059290]\n",
      "epoch:23 step:22033 [D loss: 0.595593, acc.: 72.66%] [G loss: 1.026096]\n",
      "epoch:23 step:22034 [D loss: 0.554249, acc.: 74.22%] [G loss: 0.993256]\n",
      "epoch:23 step:22035 [D loss: 0.398969, acc.: 85.94%] [G loss: 1.422769]\n",
      "epoch:23 step:22036 [D loss: 0.444990, acc.: 81.25%] [G loss: 1.762539]\n",
      "epoch:23 step:22037 [D loss: 0.605087, acc.: 71.09%] [G loss: 1.189912]\n",
      "epoch:23 step:22038 [D loss: 0.551353, acc.: 68.75%] [G loss: 1.151051]\n",
      "epoch:23 step:22039 [D loss: 0.497672, acc.: 78.12%] [G loss: 1.338495]\n",
      "epoch:23 step:22040 [D loss: 0.393066, acc.: 90.62%] [G loss: 1.220376]\n",
      "epoch:23 step:22041 [D loss: 0.479574, acc.: 82.03%] [G loss: 0.909016]\n",
      "epoch:23 step:22042 [D loss: 0.642750, acc.: 60.94%] [G loss: 1.281943]\n",
      "epoch:23 step:22043 [D loss: 0.643005, acc.: 62.50%] [G loss: 1.107516]\n",
      "epoch:23 step:22044 [D loss: 0.611809, acc.: 67.19%] [G loss: 1.009963]\n",
      "epoch:23 step:22045 [D loss: 0.578117, acc.: 75.00%] [G loss: 1.301650]\n",
      "epoch:23 step:22046 [D loss: 0.582527, acc.: 70.31%] [G loss: 0.868815]\n",
      "epoch:23 step:22047 [D loss: 0.588891, acc.: 73.44%] [G loss: 1.153104]\n",
      "epoch:23 step:22048 [D loss: 0.388852, acc.: 86.72%] [G loss: 1.105562]\n",
      "epoch:23 step:22049 [D loss: 0.326765, acc.: 92.19%] [G loss: 1.418392]\n",
      "epoch:23 step:22050 [D loss: 0.265999, acc.: 92.97%] [G loss: 1.542028]\n",
      "epoch:23 step:22051 [D loss: 0.840743, acc.: 47.66%] [G loss: 1.160349]\n",
      "epoch:23 step:22052 [D loss: 0.921654, acc.: 37.50%] [G loss: 0.867187]\n",
      "epoch:23 step:22053 [D loss: 0.738131, acc.: 50.78%] [G loss: 1.166428]\n",
      "epoch:23 step:22054 [D loss: 0.335021, acc.: 86.72%] [G loss: 1.180274]\n",
      "epoch:23 step:22055 [D loss: 0.389169, acc.: 82.03%] [G loss: 1.464550]\n",
      "epoch:23 step:22056 [D loss: 0.479962, acc.: 78.91%] [G loss: 1.204783]\n",
      "epoch:23 step:22057 [D loss: 0.559550, acc.: 73.44%] [G loss: 1.324950]\n",
      "epoch:23 step:22058 [D loss: 0.472684, acc.: 78.91%] [G loss: 1.318159]\n",
      "epoch:23 step:22059 [D loss: 0.280711, acc.: 92.97%] [G loss: 1.456591]\n",
      "epoch:23 step:22060 [D loss: 0.806206, acc.: 54.69%] [G loss: 1.096717]\n",
      "epoch:23 step:22061 [D loss: 0.734841, acc.: 52.34%] [G loss: 0.907945]\n",
      "epoch:23 step:22062 [D loss: 0.379687, acc.: 90.62%] [G loss: 1.077341]\n",
      "epoch:23 step:22063 [D loss: 0.397596, acc.: 85.94%] [G loss: 1.150493]\n",
      "epoch:23 step:22064 [D loss: 0.329440, acc.: 92.97%] [G loss: 1.297852]\n",
      "epoch:23 step:22065 [D loss: 0.489867, acc.: 79.69%] [G loss: 1.120837]\n",
      "epoch:23 step:22066 [D loss: 0.532556, acc.: 75.78%] [G loss: 1.299623]\n",
      "epoch:23 step:22067 [D loss: 0.715136, acc.: 52.34%] [G loss: 1.070676]\n",
      "epoch:23 step:22068 [D loss: 0.529059, acc.: 75.78%] [G loss: 1.590525]\n",
      "epoch:23 step:22069 [D loss: 0.532073, acc.: 73.44%] [G loss: 1.002707]\n",
      "epoch:23 step:22070 [D loss: 0.592786, acc.: 64.84%] [G loss: 0.943155]\n",
      "epoch:23 step:22071 [D loss: 0.521520, acc.: 78.12%] [G loss: 1.203874]\n",
      "epoch:23 step:22072 [D loss: 0.602628, acc.: 69.53%] [G loss: 1.055218]\n",
      "epoch:23 step:22073 [D loss: 0.418934, acc.: 85.16%] [G loss: 1.547255]\n",
      "epoch:23 step:22074 [D loss: 0.565928, acc.: 66.41%] [G loss: 1.138918]\n",
      "epoch:23 step:22075 [D loss: 0.602438, acc.: 70.31%] [G loss: 1.254830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22076 [D loss: 0.501892, acc.: 78.91%] [G loss: 1.166061]\n",
      "epoch:23 step:22077 [D loss: 0.488846, acc.: 78.91%] [G loss: 1.193135]\n",
      "epoch:23 step:22078 [D loss: 0.543826, acc.: 73.44%] [G loss: 0.912280]\n",
      "epoch:23 step:22079 [D loss: 0.682769, acc.: 58.59%] [G loss: 1.129718]\n",
      "epoch:23 step:22080 [D loss: 0.587406, acc.: 63.28%] [G loss: 1.302649]\n",
      "epoch:23 step:22081 [D loss: 0.459164, acc.: 82.81%] [G loss: 1.207761]\n",
      "epoch:23 step:22082 [D loss: 0.710590, acc.: 58.59%] [G loss: 0.975641]\n",
      "epoch:23 step:22083 [D loss: 0.492537, acc.: 79.69%] [G loss: 1.328274]\n",
      "epoch:23 step:22084 [D loss: 0.262450, acc.: 93.75%] [G loss: 1.242954]\n",
      "epoch:23 step:22085 [D loss: 0.461904, acc.: 84.38%] [G loss: 1.108567]\n",
      "epoch:23 step:22086 [D loss: 0.539214, acc.: 76.56%] [G loss: 1.245789]\n",
      "epoch:23 step:22087 [D loss: 0.484090, acc.: 82.03%] [G loss: 1.134836]\n",
      "epoch:23 step:22088 [D loss: 0.527940, acc.: 77.34%] [G loss: 1.193888]\n",
      "epoch:23 step:22089 [D loss: 0.621927, acc.: 65.62%] [G loss: 0.957655]\n",
      "epoch:23 step:22090 [D loss: 0.533431, acc.: 75.00%] [G loss: 1.196763]\n",
      "epoch:23 step:22091 [D loss: 0.642618, acc.: 61.72%] [G loss: 0.916028]\n",
      "epoch:23 step:22092 [D loss: 0.783767, acc.: 47.66%] [G loss: 1.089378]\n",
      "epoch:23 step:22093 [D loss: 0.563785, acc.: 76.56%] [G loss: 1.099231]\n",
      "epoch:23 step:22094 [D loss: 0.643006, acc.: 62.50%] [G loss: 1.101838]\n",
      "epoch:23 step:22095 [D loss: 0.482731, acc.: 76.56%] [G loss: 0.951617]\n",
      "epoch:23 step:22096 [D loss: 0.409133, acc.: 87.50%] [G loss: 1.394549]\n",
      "epoch:23 step:22097 [D loss: 0.407888, acc.: 85.94%] [G loss: 1.169098]\n",
      "epoch:23 step:22098 [D loss: 0.373385, acc.: 93.75%] [G loss: 1.198661]\n",
      "epoch:23 step:22099 [D loss: 0.416995, acc.: 85.16%] [G loss: 1.318386]\n",
      "epoch:23 step:22100 [D loss: 0.338937, acc.: 90.62%] [G loss: 1.232771]\n",
      "epoch:23 step:22101 [D loss: 0.294798, acc.: 96.09%] [G loss: 1.620365]\n",
      "epoch:23 step:22102 [D loss: 0.205173, acc.: 97.66%] [G loss: 1.815832]\n",
      "epoch:23 step:22103 [D loss: 0.275314, acc.: 94.53%] [G loss: 1.636593]\n",
      "epoch:23 step:22104 [D loss: 0.334977, acc.: 94.53%] [G loss: 1.503510]\n",
      "epoch:23 step:22105 [D loss: 0.274280, acc.: 95.31%] [G loss: 1.223489]\n",
      "epoch:23 step:22106 [D loss: 0.312516, acc.: 91.41%] [G loss: 1.335272]\n",
      "epoch:23 step:22107 [D loss: 0.202550, acc.: 99.22%] [G loss: 1.806668]\n",
      "epoch:23 step:22108 [D loss: 0.327607, acc.: 92.97%] [G loss: 1.950198]\n",
      "epoch:23 step:22109 [D loss: 0.354262, acc.: 89.84%] [G loss: 1.510272]\n",
      "epoch:23 step:22110 [D loss: 0.935091, acc.: 44.53%] [G loss: 1.252909]\n",
      "epoch:23 step:22111 [D loss: 0.891872, acc.: 51.56%] [G loss: 1.164560]\n",
      "epoch:23 step:22112 [D loss: 0.809435, acc.: 44.53%] [G loss: 1.143281]\n",
      "epoch:23 step:22113 [D loss: 0.703763, acc.: 59.38%] [G loss: 1.122618]\n",
      "epoch:23 step:22114 [D loss: 0.723086, acc.: 55.47%] [G loss: 1.089904]\n",
      "epoch:23 step:22115 [D loss: 0.543464, acc.: 72.66%] [G loss: 1.037142]\n",
      "epoch:23 step:22116 [D loss: 0.586280, acc.: 70.31%] [G loss: 1.044474]\n",
      "epoch:23 step:22117 [D loss: 0.463124, acc.: 74.22%] [G loss: 1.396991]\n",
      "epoch:23 step:22118 [D loss: 0.353059, acc.: 91.41%] [G loss: 1.480774]\n",
      "epoch:23 step:22119 [D loss: 0.726878, acc.: 55.47%] [G loss: 1.184328]\n",
      "epoch:23 step:22120 [D loss: 0.751402, acc.: 53.91%] [G loss: 1.101920]\n",
      "epoch:23 step:22121 [D loss: 0.691093, acc.: 60.16%] [G loss: 0.899913]\n",
      "epoch:23 step:22122 [D loss: 0.765072, acc.: 48.44%] [G loss: 0.886607]\n",
      "epoch:23 step:22123 [D loss: 0.709211, acc.: 57.81%] [G loss: 0.943313]\n",
      "epoch:23 step:22124 [D loss: 0.534764, acc.: 78.12%] [G loss: 1.228637]\n",
      "epoch:23 step:22125 [D loss: 0.552983, acc.: 74.22%] [G loss: 0.903950]\n",
      "epoch:23 step:22126 [D loss: 0.570650, acc.: 66.41%] [G loss: 1.180972]\n",
      "epoch:23 step:22127 [D loss: 0.425929, acc.: 86.72%] [G loss: 1.352461]\n",
      "epoch:23 step:22128 [D loss: 0.448607, acc.: 85.16%] [G loss: 1.185062]\n",
      "epoch:23 step:22129 [D loss: 0.408616, acc.: 84.38%] [G loss: 0.981353]\n",
      "epoch:23 step:22130 [D loss: 0.545343, acc.: 71.09%] [G loss: 0.933224]\n",
      "epoch:23 step:22131 [D loss: 0.730203, acc.: 56.25%] [G loss: 1.065696]\n",
      "epoch:23 step:22132 [D loss: 0.546223, acc.: 76.56%] [G loss: 0.952891]\n",
      "epoch:23 step:22133 [D loss: 0.716338, acc.: 49.22%] [G loss: 1.033817]\n",
      "epoch:23 step:22134 [D loss: 0.718609, acc.: 54.69%] [G loss: 1.163007]\n",
      "epoch:23 step:22135 [D loss: 0.637248, acc.: 64.84%] [G loss: 1.242350]\n",
      "epoch:23 step:22136 [D loss: 0.685194, acc.: 57.03%] [G loss: 0.695369]\n",
      "epoch:23 step:22137 [D loss: 0.712064, acc.: 55.47%] [G loss: 0.672762]\n",
      "epoch:23 step:22138 [D loss: 0.322270, acc.: 91.41%] [G loss: 1.365642]\n",
      "epoch:23 step:22139 [D loss: 0.282315, acc.: 95.31%] [G loss: 1.509178]\n",
      "epoch:23 step:22140 [D loss: 0.319689, acc.: 92.97%] [G loss: 1.703763]\n",
      "epoch:23 step:22141 [D loss: 0.801814, acc.: 50.78%] [G loss: 1.601570]\n",
      "epoch:23 step:22142 [D loss: 0.713462, acc.: 55.47%] [G loss: 1.200930]\n",
      "epoch:23 step:22143 [D loss: 0.487284, acc.: 80.47%] [G loss: 1.326182]\n",
      "epoch:23 step:22144 [D loss: 0.689483, acc.: 62.50%] [G loss: 1.085831]\n",
      "epoch:23 step:22145 [D loss: 0.564931, acc.: 66.41%] [G loss: 0.932185]\n",
      "epoch:23 step:22146 [D loss: 0.670360, acc.: 59.38%] [G loss: 1.356275]\n",
      "epoch:23 step:22147 [D loss: 0.676808, acc.: 61.72%] [G loss: 1.530620]\n",
      "epoch:23 step:22148 [D loss: 0.616661, acc.: 64.06%] [G loss: 1.087501]\n",
      "epoch:23 step:22149 [D loss: 0.393139, acc.: 85.16%] [G loss: 1.287698]\n",
      "epoch:23 step:22150 [D loss: 0.688991, acc.: 62.50%] [G loss: 1.132890]\n",
      "epoch:23 step:22151 [D loss: 0.715429, acc.: 59.38%] [G loss: 0.828350]\n",
      "epoch:23 step:22152 [D loss: 0.747821, acc.: 50.78%] [G loss: 0.740784]\n",
      "epoch:23 step:22153 [D loss: 0.696297, acc.: 51.56%] [G loss: 1.078624]\n",
      "epoch:23 step:22154 [D loss: 0.362491, acc.: 86.72%] [G loss: 1.326232]\n",
      "epoch:23 step:22155 [D loss: 0.290047, acc.: 89.84%] [G loss: 1.560315]\n",
      "epoch:23 step:22156 [D loss: 0.246105, acc.: 96.88%] [G loss: 1.811522]\n",
      "epoch:23 step:22157 [D loss: 0.596238, acc.: 65.62%] [G loss: 1.561419]\n",
      "epoch:23 step:22158 [D loss: 0.726159, acc.: 53.91%] [G loss: 1.284533]\n",
      "epoch:23 step:22159 [D loss: 0.564172, acc.: 71.09%] [G loss: 0.948106]\n",
      "epoch:23 step:22160 [D loss: 0.539096, acc.: 72.66%] [G loss: 1.177842]\n",
      "epoch:23 step:22161 [D loss: 0.554646, acc.: 71.88%] [G loss: 1.144760]\n",
      "epoch:23 step:22162 [D loss: 0.579277, acc.: 75.00%] [G loss: 1.280930]\n",
      "epoch:23 step:22163 [D loss: 0.837001, acc.: 42.97%] [G loss: 0.994931]\n",
      "epoch:23 step:22164 [D loss: 0.382443, acc.: 81.25%] [G loss: 1.441152]\n",
      "epoch:23 step:22165 [D loss: 0.208540, acc.: 98.44%] [G loss: 1.776097]\n",
      "epoch:23 step:22166 [D loss: 0.209975, acc.: 99.22%] [G loss: 1.879858]\n",
      "epoch:23 step:22167 [D loss: 0.311226, acc.: 92.19%] [G loss: 1.364074]\n",
      "epoch:23 step:22168 [D loss: 0.381618, acc.: 86.72%] [G loss: 1.417308]\n",
      "epoch:23 step:22169 [D loss: 0.697313, acc.: 59.38%] [G loss: 1.165603]\n",
      "epoch:23 step:22170 [D loss: 0.694845, acc.: 54.69%] [G loss: 0.776685]\n",
      "epoch:23 step:22171 [D loss: 0.852994, acc.: 38.28%] [G loss: 0.760900]\n",
      "epoch:23 step:22172 [D loss: 0.560776, acc.: 72.66%] [G loss: 1.366583]\n",
      "epoch:23 step:22173 [D loss: 0.657152, acc.: 63.28%] [G loss: 0.958471]\n",
      "epoch:23 step:22174 [D loss: 0.832134, acc.: 44.53%] [G loss: 0.862240]\n",
      "epoch:23 step:22175 [D loss: 0.372903, acc.: 90.62%] [G loss: 1.704845]\n",
      "epoch:23 step:22176 [D loss: 0.939480, acc.: 49.22%] [G loss: 1.360603]\n",
      "epoch:23 step:22177 [D loss: 0.614604, acc.: 67.19%] [G loss: 0.879593]\n",
      "epoch:23 step:22178 [D loss: 0.988160, acc.: 31.25%] [G loss: 0.650442]\n",
      "epoch:23 step:22179 [D loss: 0.850467, acc.: 41.41%] [G loss: 0.974989]\n",
      "epoch:23 step:22180 [D loss: 0.634588, acc.: 60.94%] [G loss: 0.868535]\n",
      "epoch:23 step:22181 [D loss: 0.522119, acc.: 74.22%] [G loss: 1.557585]\n",
      "epoch:23 step:22182 [D loss: 0.840288, acc.: 43.75%] [G loss: 0.883114]\n",
      "epoch:23 step:22183 [D loss: 0.481531, acc.: 82.03%] [G loss: 1.328297]\n",
      "epoch:23 step:22184 [D loss: 0.636523, acc.: 63.28%] [G loss: 0.931785]\n",
      "epoch:23 step:22185 [D loss: 0.896991, acc.: 42.19%] [G loss: 0.633698]\n",
      "epoch:23 step:22186 [D loss: 0.698553, acc.: 54.69%] [G loss: 1.377375]\n",
      "epoch:23 step:22187 [D loss: 0.713186, acc.: 53.12%] [G loss: 1.213641]\n",
      "epoch:23 step:22188 [D loss: 1.033772, acc.: 27.34%] [G loss: 0.813382]\n",
      "epoch:23 step:22189 [D loss: 0.759107, acc.: 52.34%] [G loss: 0.922775]\n",
      "epoch:23 step:22190 [D loss: 1.017221, acc.: 33.59%] [G loss: 1.156923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22191 [D loss: 1.080410, acc.: 30.47%] [G loss: 1.108512]\n",
      "epoch:23 step:22192 [D loss: 0.752921, acc.: 54.69%] [G loss: 1.266600]\n",
      "epoch:23 step:22193 [D loss: 0.682115, acc.: 57.03%] [G loss: 1.509166]\n",
      "epoch:23 step:22194 [D loss: 0.753253, acc.: 51.56%] [G loss: 1.214730]\n",
      "epoch:23 step:22195 [D loss: 0.781324, acc.: 47.66%] [G loss: 0.922903]\n",
      "epoch:23 step:22196 [D loss: 0.831319, acc.: 37.50%] [G loss: 0.891453]\n",
      "epoch:23 step:22197 [D loss: 0.613188, acc.: 67.97%] [G loss: 1.347089]\n",
      "epoch:23 step:22198 [D loss: 0.441379, acc.: 81.25%] [G loss: 1.141899]\n",
      "epoch:23 step:22199 [D loss: 0.565821, acc.: 68.75%] [G loss: 1.142222]\n",
      "epoch:23 step:22200 [D loss: 0.520500, acc.: 77.34%] [G loss: 1.328581]\n",
      "epoch:23 step:22201 [D loss: 0.503381, acc.: 76.56%] [G loss: 1.149735]\n",
      "epoch:23 step:22202 [D loss: 0.657355, acc.: 64.84%] [G loss: 1.210481]\n",
      "epoch:23 step:22203 [D loss: 0.810756, acc.: 44.53%] [G loss: 1.013020]\n",
      "epoch:23 step:22204 [D loss: 0.757474, acc.: 50.78%] [G loss: 1.302559]\n",
      "epoch:23 step:22205 [D loss: 0.625757, acc.: 66.41%] [G loss: 1.185109]\n",
      "epoch:23 step:22206 [D loss: 0.637379, acc.: 63.28%] [G loss: 1.282508]\n",
      "epoch:23 step:22207 [D loss: 0.545690, acc.: 75.00%] [G loss: 1.041525]\n",
      "epoch:23 step:22208 [D loss: 0.731561, acc.: 55.47%] [G loss: 1.042583]\n",
      "epoch:23 step:22209 [D loss: 0.509648, acc.: 75.00%] [G loss: 1.209310]\n",
      "epoch:23 step:22210 [D loss: 0.734276, acc.: 56.25%] [G loss: 1.106813]\n",
      "epoch:23 step:22211 [D loss: 0.612922, acc.: 67.97%] [G loss: 1.111261]\n",
      "epoch:23 step:22212 [D loss: 0.500501, acc.: 81.25%] [G loss: 1.316117]\n",
      "epoch:23 step:22213 [D loss: 0.499768, acc.: 78.12%] [G loss: 1.168774]\n",
      "epoch:23 step:22214 [D loss: 0.216974, acc.: 92.97%] [G loss: 1.764465]\n",
      "epoch:23 step:22215 [D loss: 0.163572, acc.: 99.22%] [G loss: 1.945725]\n",
      "epoch:23 step:22216 [D loss: 0.218148, acc.: 96.09%] [G loss: 2.258805]\n",
      "epoch:23 step:22217 [D loss: 0.380124, acc.: 89.06%] [G loss: 1.910732]\n",
      "epoch:23 step:22218 [D loss: 0.404796, acc.: 85.16%] [G loss: 1.867802]\n",
      "epoch:23 step:22219 [D loss: 0.521062, acc.: 73.44%] [G loss: 1.257172]\n",
      "epoch:23 step:22220 [D loss: 0.374934, acc.: 84.38%] [G loss: 1.346626]\n",
      "epoch:23 step:22221 [D loss: 0.521869, acc.: 75.00%] [G loss: 1.232607]\n",
      "epoch:23 step:22222 [D loss: 0.549817, acc.: 71.88%] [G loss: 1.300406]\n",
      "epoch:23 step:22223 [D loss: 0.597533, acc.: 65.62%] [G loss: 1.599628]\n",
      "epoch:23 step:22224 [D loss: 0.687231, acc.: 60.94%] [G loss: 1.179632]\n",
      "epoch:23 step:22225 [D loss: 0.517591, acc.: 75.78%] [G loss: 1.083177]\n",
      "epoch:23 step:22226 [D loss: 1.115778, acc.: 29.69%] [G loss: 0.489378]\n",
      "epoch:23 step:22227 [D loss: 0.583401, acc.: 71.88%] [G loss: 1.052624]\n",
      "epoch:23 step:22228 [D loss: 0.852033, acc.: 42.19%] [G loss: 1.211115]\n",
      "epoch:23 step:22229 [D loss: 0.905218, acc.: 37.50%] [G loss: 0.907167]\n",
      "epoch:23 step:22230 [D loss: 0.740673, acc.: 54.69%] [G loss: 0.932763]\n",
      "epoch:23 step:22231 [D loss: 0.773916, acc.: 43.75%] [G loss: 0.946271]\n",
      "epoch:23 step:22232 [D loss: 0.756181, acc.: 57.81%] [G loss: 0.923326]\n",
      "epoch:23 step:22233 [D loss: 0.523669, acc.: 71.09%] [G loss: 1.051255]\n",
      "epoch:23 step:22234 [D loss: 0.674325, acc.: 57.81%] [G loss: 0.972304]\n",
      "epoch:23 step:22235 [D loss: 0.912973, acc.: 46.09%] [G loss: 0.798691]\n",
      "epoch:23 step:22236 [D loss: 0.639997, acc.: 64.84%] [G loss: 1.440728]\n",
      "epoch:23 step:22237 [D loss: 1.004540, acc.: 32.03%] [G loss: 1.024188]\n",
      "epoch:23 step:22238 [D loss: 0.937752, acc.: 36.72%] [G loss: 0.675780]\n",
      "epoch:23 step:22239 [D loss: 1.100684, acc.: 17.97%] [G loss: 0.968118]\n",
      "epoch:23 step:22240 [D loss: 0.752654, acc.: 58.59%] [G loss: 1.421576]\n",
      "epoch:23 step:22241 [D loss: 0.591171, acc.: 68.75%] [G loss: 1.186344]\n",
      "epoch:23 step:22242 [D loss: 0.540509, acc.: 74.22%] [G loss: 1.218382]\n",
      "epoch:23 step:22243 [D loss: 0.536331, acc.: 75.00%] [G loss: 1.046758]\n",
      "epoch:23 step:22244 [D loss: 0.479378, acc.: 79.69%] [G loss: 1.155070]\n",
      "epoch:23 step:22245 [D loss: 0.357008, acc.: 87.50%] [G loss: 1.525577]\n",
      "epoch:23 step:22246 [D loss: 0.423745, acc.: 85.94%] [G loss: 1.432746]\n",
      "epoch:23 step:22247 [D loss: 0.531396, acc.: 69.53%] [G loss: 1.423932]\n",
      "epoch:23 step:22248 [D loss: 0.563459, acc.: 75.00%] [G loss: 1.255796]\n",
      "epoch:23 step:22249 [D loss: 0.620360, acc.: 61.72%] [G loss: 1.098327]\n",
      "epoch:23 step:22250 [D loss: 0.683286, acc.: 62.50%] [G loss: 1.185971]\n",
      "epoch:23 step:22251 [D loss: 0.546340, acc.: 75.00%] [G loss: 0.953176]\n",
      "epoch:23 step:22252 [D loss: 0.522913, acc.: 77.34%] [G loss: 1.308042]\n",
      "epoch:23 step:22253 [D loss: 0.650065, acc.: 60.16%] [G loss: 1.131712]\n",
      "epoch:23 step:22254 [D loss: 0.663356, acc.: 57.81%] [G loss: 1.139353]\n",
      "epoch:23 step:22255 [D loss: 0.860884, acc.: 35.94%] [G loss: 1.028974]\n",
      "epoch:23 step:22256 [D loss: 0.727358, acc.: 50.78%] [G loss: 0.892738]\n",
      "epoch:23 step:22257 [D loss: 0.628843, acc.: 64.84%] [G loss: 1.339195]\n",
      "epoch:23 step:22258 [D loss: 0.533605, acc.: 78.91%] [G loss: 1.324404]\n",
      "epoch:23 step:22259 [D loss: 0.584501, acc.: 69.53%] [G loss: 1.178737]\n",
      "epoch:23 step:22260 [D loss: 0.472816, acc.: 79.69%] [G loss: 1.061744]\n",
      "epoch:23 step:22261 [D loss: 0.436272, acc.: 86.72%] [G loss: 1.267405]\n",
      "epoch:23 step:22262 [D loss: 0.352953, acc.: 92.19%] [G loss: 1.486830]\n",
      "epoch:23 step:22263 [D loss: 0.646291, acc.: 63.28%] [G loss: 1.253506]\n",
      "epoch:23 step:22264 [D loss: 0.649862, acc.: 65.62%] [G loss: 0.959325]\n",
      "epoch:23 step:22265 [D loss: 0.578721, acc.: 71.88%] [G loss: 1.175516]\n",
      "epoch:23 step:22266 [D loss: 0.602616, acc.: 67.19%] [G loss: 1.241694]\n",
      "epoch:23 step:22267 [D loss: 0.556788, acc.: 74.22%] [G loss: 1.032262]\n",
      "epoch:23 step:22268 [D loss: 0.395408, acc.: 89.06%] [G loss: 1.086557]\n",
      "epoch:23 step:22269 [D loss: 0.661029, acc.: 67.97%] [G loss: 1.200907]\n",
      "epoch:23 step:22270 [D loss: 0.723949, acc.: 55.47%] [G loss: 0.768217]\n",
      "epoch:23 step:22271 [D loss: 0.376664, acc.: 89.84%] [G loss: 1.530714]\n",
      "epoch:23 step:22272 [D loss: 0.635503, acc.: 62.50%] [G loss: 1.068288]\n",
      "epoch:23 step:22273 [D loss: 0.795980, acc.: 45.31%] [G loss: 1.285538]\n",
      "epoch:23 step:22274 [D loss: 0.586018, acc.: 69.53%] [G loss: 0.819013]\n",
      "epoch:23 step:22275 [D loss: 0.386479, acc.: 84.38%] [G loss: 0.983896]\n",
      "epoch:23 step:22276 [D loss: 0.436364, acc.: 83.59%] [G loss: 0.956634]\n",
      "epoch:23 step:22277 [D loss: 0.722875, acc.: 53.91%] [G loss: 0.868692]\n",
      "epoch:23 step:22278 [D loss: 0.788999, acc.: 48.44%] [G loss: 1.161800]\n",
      "epoch:23 step:22279 [D loss: 0.605138, acc.: 65.62%] [G loss: 1.338893]\n",
      "epoch:23 step:22280 [D loss: 0.640835, acc.: 64.84%] [G loss: 1.272866]\n",
      "epoch:23 step:22281 [D loss: 0.549122, acc.: 73.44%] [G loss: 1.037883]\n",
      "epoch:23 step:22282 [D loss: 0.369894, acc.: 89.06%] [G loss: 1.365848]\n",
      "epoch:23 step:22283 [D loss: 0.345607, acc.: 90.62%] [G loss: 1.470122]\n",
      "epoch:23 step:22284 [D loss: 0.427072, acc.: 82.81%] [G loss: 1.334457]\n",
      "epoch:23 step:22285 [D loss: 0.566816, acc.: 67.97%] [G loss: 1.624012]\n",
      "epoch:23 step:22286 [D loss: 0.787762, acc.: 46.09%] [G loss: 1.104346]\n",
      "epoch:23 step:22287 [D loss: 0.740225, acc.: 47.66%] [G loss: 0.958441]\n",
      "epoch:23 step:22288 [D loss: 0.570392, acc.: 72.66%] [G loss: 0.905995]\n",
      "epoch:23 step:22289 [D loss: 0.560662, acc.: 71.09%] [G loss: 1.169921]\n",
      "epoch:23 step:22290 [D loss: 0.501166, acc.: 79.69%] [G loss: 1.258263]\n",
      "epoch:23 step:22291 [D loss: 0.531737, acc.: 73.44%] [G loss: 1.040649]\n",
      "epoch:23 step:22292 [D loss: 0.691893, acc.: 56.25%] [G loss: 1.258524]\n",
      "epoch:23 step:22293 [D loss: 0.733375, acc.: 53.91%] [G loss: 1.240901]\n",
      "epoch:23 step:22294 [D loss: 0.661278, acc.: 67.19%] [G loss: 0.983397]\n",
      "epoch:23 step:22295 [D loss: 0.621624, acc.: 60.94%] [G loss: 0.929836]\n",
      "epoch:23 step:22296 [D loss: 0.276036, acc.: 91.41%] [G loss: 1.165975]\n",
      "epoch:23 step:22297 [D loss: 0.444039, acc.: 78.12%] [G loss: 1.072948]\n",
      "epoch:23 step:22298 [D loss: 0.634465, acc.: 67.19%] [G loss: 1.264786]\n",
      "epoch:23 step:22299 [D loss: 0.668092, acc.: 62.50%] [G loss: 1.356611]\n",
      "epoch:23 step:22300 [D loss: 0.757602, acc.: 46.88%] [G loss: 1.125795]\n",
      "epoch:23 step:22301 [D loss: 0.562739, acc.: 73.44%] [G loss: 1.072840]\n",
      "epoch:23 step:22302 [D loss: 0.463328, acc.: 82.03%] [G loss: 1.054717]\n",
      "epoch:23 step:22303 [D loss: 0.855123, acc.: 39.84%] [G loss: 1.022772]\n",
      "epoch:23 step:22304 [D loss: 0.666568, acc.: 60.16%] [G loss: 0.929654]\n",
      "epoch:23 step:22305 [D loss: 0.538119, acc.: 76.56%] [G loss: 1.002136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22306 [D loss: 0.431502, acc.: 81.25%] [G loss: 1.212995]\n",
      "epoch:23 step:22307 [D loss: 0.602625, acc.: 68.75%] [G loss: 1.244639]\n",
      "epoch:23 step:22308 [D loss: 0.377820, acc.: 91.41%] [G loss: 1.171217]\n",
      "epoch:23 step:22309 [D loss: 0.651947, acc.: 60.16%] [G loss: 1.118889]\n",
      "epoch:23 step:22310 [D loss: 0.643264, acc.: 62.50%] [G loss: 1.313148]\n",
      "epoch:23 step:22311 [D loss: 0.758598, acc.: 52.34%] [G loss: 0.915945]\n",
      "epoch:23 step:22312 [D loss: 0.588151, acc.: 72.66%] [G loss: 1.163187]\n",
      "epoch:23 step:22313 [D loss: 0.689806, acc.: 55.47%] [G loss: 0.811448]\n",
      "epoch:23 step:22314 [D loss: 0.424421, acc.: 85.16%] [G loss: 0.900108]\n",
      "epoch:23 step:22315 [D loss: 0.603921, acc.: 66.41%] [G loss: 1.137363]\n",
      "epoch:23 step:22316 [D loss: 0.920087, acc.: 35.16%] [G loss: 0.957142]\n",
      "epoch:23 step:22317 [D loss: 1.069161, acc.: 30.47%] [G loss: 0.690056]\n",
      "epoch:23 step:22318 [D loss: 0.747896, acc.: 53.91%] [G loss: 1.319940]\n",
      "epoch:23 step:22319 [D loss: 0.530396, acc.: 76.56%] [G loss: 1.189662]\n",
      "epoch:23 step:22320 [D loss: 0.384093, acc.: 91.41%] [G loss: 1.504252]\n",
      "epoch:23 step:22321 [D loss: 0.565972, acc.: 73.44%] [G loss: 1.500467]\n",
      "epoch:23 step:22322 [D loss: 0.774074, acc.: 51.56%] [G loss: 1.002921]\n",
      "epoch:23 step:22323 [D loss: 0.682882, acc.: 59.38%] [G loss: 1.107396]\n",
      "epoch:23 step:22324 [D loss: 0.549519, acc.: 77.34%] [G loss: 1.524821]\n",
      "epoch:23 step:22325 [D loss: 0.407338, acc.: 74.22%] [G loss: 1.140445]\n",
      "epoch:23 step:22326 [D loss: 0.177395, acc.: 98.44%] [G loss: 1.612178]\n",
      "epoch:23 step:22327 [D loss: 0.403821, acc.: 87.50%] [G loss: 1.443420]\n",
      "epoch:23 step:22328 [D loss: 0.376631, acc.: 89.06%] [G loss: 1.467564]\n",
      "epoch:23 step:22329 [D loss: 0.513597, acc.: 75.78%] [G loss: 1.369799]\n",
      "epoch:23 step:22330 [D loss: 0.739430, acc.: 54.69%] [G loss: 1.250405]\n",
      "epoch:23 step:22331 [D loss: 0.720500, acc.: 53.12%] [G loss: 1.070181]\n",
      "epoch:23 step:22332 [D loss: 0.643104, acc.: 57.03%] [G loss: 1.180554]\n",
      "epoch:23 step:22333 [D loss: 0.613885, acc.: 67.97%] [G loss: 0.998060]\n",
      "epoch:23 step:22334 [D loss: 0.689231, acc.: 53.12%] [G loss: 1.188028]\n",
      "epoch:23 step:22335 [D loss: 0.751454, acc.: 47.66%] [G loss: 0.983056]\n",
      "epoch:23 step:22336 [D loss: 0.628151, acc.: 65.62%] [G loss: 1.101308]\n",
      "epoch:23 step:22337 [D loss: 0.529747, acc.: 72.66%] [G loss: 0.956485]\n",
      "epoch:23 step:22338 [D loss: 0.620434, acc.: 64.84%] [G loss: 1.078968]\n",
      "epoch:23 step:22339 [D loss: 0.769815, acc.: 49.22%] [G loss: 0.929520]\n",
      "epoch:23 step:22340 [D loss: 0.682952, acc.: 56.25%] [G loss: 1.016370]\n",
      "epoch:23 step:22341 [D loss: 0.569669, acc.: 71.09%] [G loss: 1.020533]\n",
      "epoch:23 step:22342 [D loss: 0.452755, acc.: 79.69%] [G loss: 1.137353]\n",
      "epoch:23 step:22343 [D loss: 0.374545, acc.: 87.50%] [G loss: 1.355840]\n",
      "epoch:23 step:22344 [D loss: 0.492136, acc.: 81.25%] [G loss: 1.402872]\n",
      "epoch:23 step:22345 [D loss: 0.309595, acc.: 93.75%] [G loss: 1.545281]\n",
      "epoch:23 step:22346 [D loss: 0.533338, acc.: 71.88%] [G loss: 1.369831]\n",
      "epoch:23 step:22347 [D loss: 0.418102, acc.: 83.59%] [G loss: 1.315486]\n",
      "epoch:23 step:22348 [D loss: 0.617291, acc.: 67.97%] [G loss: 1.011921]\n",
      "epoch:23 step:22349 [D loss: 0.546830, acc.: 73.44%] [G loss: 1.039902]\n",
      "epoch:23 step:22350 [D loss: 0.727574, acc.: 53.12%] [G loss: 0.823044]\n",
      "epoch:23 step:22351 [D loss: 0.632934, acc.: 62.50%] [G loss: 1.089437]\n",
      "epoch:23 step:22352 [D loss: 0.788737, acc.: 53.91%] [G loss: 0.892573]\n",
      "epoch:23 step:22353 [D loss: 0.608248, acc.: 70.31%] [G loss: 1.076385]\n",
      "epoch:23 step:22354 [D loss: 0.699753, acc.: 53.91%] [G loss: 1.128701]\n",
      "epoch:23 step:22355 [D loss: 0.495222, acc.: 80.47%] [G loss: 1.347898]\n",
      "epoch:23 step:22356 [D loss: 0.619159, acc.: 64.06%] [G loss: 1.147778]\n",
      "epoch:23 step:22357 [D loss: 0.411125, acc.: 85.16%] [G loss: 1.168977]\n",
      "epoch:23 step:22358 [D loss: 0.635440, acc.: 60.94%] [G loss: 1.171329]\n",
      "epoch:23 step:22359 [D loss: 0.483113, acc.: 84.38%] [G loss: 0.948576]\n",
      "epoch:23 step:22360 [D loss: 0.465463, acc.: 81.25%] [G loss: 1.525374]\n",
      "epoch:23 step:22361 [D loss: 0.527133, acc.: 75.00%] [G loss: 1.224023]\n",
      "epoch:23 step:22362 [D loss: 0.695257, acc.: 62.50%] [G loss: 1.117446]\n",
      "epoch:23 step:22363 [D loss: 0.604331, acc.: 68.75%] [G loss: 1.044195]\n",
      "epoch:23 step:22364 [D loss: 0.602402, acc.: 65.62%] [G loss: 1.192178]\n",
      "epoch:23 step:22365 [D loss: 0.552887, acc.: 75.78%] [G loss: 1.224794]\n",
      "epoch:23 step:22366 [D loss: 0.219600, acc.: 95.31%] [G loss: 1.436917]\n",
      "epoch:23 step:22367 [D loss: 0.362107, acc.: 91.41%] [G loss: 1.382901]\n",
      "epoch:23 step:22368 [D loss: 0.650607, acc.: 56.25%] [G loss: 1.391872]\n",
      "epoch:23 step:22369 [D loss: 0.493737, acc.: 81.25%] [G loss: 1.493341]\n",
      "epoch:23 step:22370 [D loss: 0.525259, acc.: 78.12%] [G loss: 1.022782]\n",
      "epoch:23 step:22371 [D loss: 0.772168, acc.: 42.97%] [G loss: 0.890791]\n",
      "epoch:23 step:22372 [D loss: 1.040945, acc.: 30.47%] [G loss: 0.634251]\n",
      "epoch:23 step:22373 [D loss: 0.995323, acc.: 27.34%] [G loss: 0.710315]\n",
      "epoch:23 step:22374 [D loss: 0.629294, acc.: 63.28%] [G loss: 1.080169]\n",
      "epoch:23 step:22375 [D loss: 0.465520, acc.: 85.16%] [G loss: 1.039726]\n",
      "epoch:23 step:22376 [D loss: 0.432982, acc.: 85.16%] [G loss: 1.277777]\n",
      "epoch:23 step:22377 [D loss: 0.602498, acc.: 71.09%] [G loss: 1.367660]\n",
      "epoch:23 step:22378 [D loss: 0.877380, acc.: 36.72%] [G loss: 0.954682]\n",
      "epoch:23 step:22379 [D loss: 0.870497, acc.: 41.41%] [G loss: 0.783002]\n",
      "epoch:23 step:22380 [D loss: 0.452496, acc.: 82.03%] [G loss: 1.172138]\n",
      "epoch:23 step:22381 [D loss: 0.501474, acc.: 77.34%] [G loss: 0.870164]\n",
      "epoch:23 step:22382 [D loss: 0.501145, acc.: 73.44%] [G loss: 1.424331]\n",
      "epoch:23 step:22383 [D loss: 0.461140, acc.: 83.59%] [G loss: 1.371839]\n",
      "epoch:23 step:22384 [D loss: 0.445250, acc.: 84.38%] [G loss: 1.477882]\n",
      "epoch:23 step:22385 [D loss: 0.617698, acc.: 62.50%] [G loss: 1.258595]\n",
      "epoch:23 step:22386 [D loss: 0.626238, acc.: 59.38%] [G loss: 1.304410]\n",
      "epoch:23 step:22387 [D loss: 1.047432, acc.: 23.44%] [G loss: 0.514453]\n",
      "epoch:23 step:22388 [D loss: 0.592988, acc.: 68.75%] [G loss: 1.132317]\n",
      "epoch:23 step:22389 [D loss: 0.575981, acc.: 71.88%] [G loss: 1.235641]\n",
      "epoch:23 step:22390 [D loss: 0.669453, acc.: 55.47%] [G loss: 1.105841]\n",
      "epoch:23 step:22391 [D loss: 0.659733, acc.: 60.16%] [G loss: 0.918647]\n",
      "epoch:23 step:22392 [D loss: 0.443059, acc.: 85.16%] [G loss: 1.408442]\n",
      "epoch:23 step:22393 [D loss: 0.526376, acc.: 72.66%] [G loss: 1.425703]\n",
      "epoch:23 step:22394 [D loss: 0.629255, acc.: 69.53%] [G loss: 1.361578]\n",
      "epoch:23 step:22395 [D loss: 0.677814, acc.: 57.81%] [G loss: 1.188007]\n",
      "epoch:23 step:22396 [D loss: 0.507370, acc.: 76.56%] [G loss: 1.349391]\n",
      "epoch:23 step:22397 [D loss: 0.623468, acc.: 67.97%] [G loss: 1.191969]\n",
      "epoch:23 step:22398 [D loss: 0.635599, acc.: 67.19%] [G loss: 1.178639]\n",
      "epoch:23 step:22399 [D loss: 0.665680, acc.: 63.28%] [G loss: 1.193743]\n",
      "epoch:23 step:22400 [D loss: 0.569275, acc.: 71.09%] [G loss: 1.178321]\n",
      "epoch:23 step:22401 [D loss: 0.382054, acc.: 89.84%] [G loss: 1.058637]\n",
      "epoch:23 step:22402 [D loss: 0.318046, acc.: 92.19%] [G loss: 1.494450]\n",
      "epoch:23 step:22403 [D loss: 0.246334, acc.: 98.44%] [G loss: 1.745849]\n",
      "epoch:23 step:22404 [D loss: 0.322951, acc.: 93.75%] [G loss: 1.541322]\n",
      "epoch:23 step:22405 [D loss: 0.229637, acc.: 95.31%] [G loss: 1.646569]\n",
      "epoch:23 step:22406 [D loss: 0.482714, acc.: 78.91%] [G loss: 1.213046]\n",
      "epoch:23 step:22407 [D loss: 0.410924, acc.: 88.28%] [G loss: 1.337342]\n",
      "epoch:23 step:22408 [D loss: 0.343457, acc.: 92.19%] [G loss: 1.671358]\n",
      "epoch:23 step:22409 [D loss: 0.761696, acc.: 53.91%] [G loss: 1.421572]\n",
      "epoch:23 step:22410 [D loss: 0.981638, acc.: 29.69%] [G loss: 0.975356]\n",
      "epoch:23 step:22411 [D loss: 0.510126, acc.: 78.12%] [G loss: 1.309553]\n",
      "epoch:23 step:22412 [D loss: 0.574030, acc.: 73.44%] [G loss: 0.870653]\n",
      "epoch:23 step:22413 [D loss: 0.814723, acc.: 42.97%] [G loss: 0.687021]\n",
      "epoch:23 step:22414 [D loss: 0.644607, acc.: 61.72%] [G loss: 1.099719]\n",
      "epoch:23 step:22415 [D loss: 0.735771, acc.: 50.78%] [G loss: 0.870433]\n",
      "epoch:23 step:22416 [D loss: 0.625223, acc.: 64.06%] [G loss: 1.060701]\n",
      "epoch:23 step:22417 [D loss: 0.601960, acc.: 67.97%] [G loss: 1.062121]\n",
      "epoch:23 step:22418 [D loss: 0.599816, acc.: 66.41%] [G loss: 1.008328]\n",
      "epoch:23 step:22419 [D loss: 0.684363, acc.: 54.69%] [G loss: 0.691144]\n",
      "epoch:23 step:22420 [D loss: 0.564786, acc.: 72.66%] [G loss: 1.029125]\n",
      "epoch:23 step:22421 [D loss: 0.643930, acc.: 61.72%] [G loss: 1.106533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22422 [D loss: 0.522385, acc.: 75.00%] [G loss: 0.920716]\n",
      "epoch:23 step:22423 [D loss: 0.673944, acc.: 54.69%] [G loss: 1.075900]\n",
      "epoch:23 step:22424 [D loss: 0.573642, acc.: 71.88%] [G loss: 1.042908]\n",
      "epoch:23 step:22425 [D loss: 0.565002, acc.: 76.56%] [G loss: 1.275066]\n",
      "epoch:23 step:22426 [D loss: 0.549363, acc.: 78.12%] [G loss: 1.019397]\n",
      "epoch:23 step:22427 [D loss: 0.721422, acc.: 50.78%] [G loss: 0.861108]\n",
      "epoch:23 step:22428 [D loss: 0.625178, acc.: 61.72%] [G loss: 1.042786]\n",
      "epoch:23 step:22429 [D loss: 0.509102, acc.: 79.69%] [G loss: 1.036311]\n",
      "epoch:23 step:22430 [D loss: 0.663362, acc.: 59.38%] [G loss: 1.044071]\n",
      "epoch:23 step:22431 [D loss: 0.574809, acc.: 69.53%] [G loss: 1.179454]\n",
      "epoch:23 step:22432 [D loss: 0.775059, acc.: 49.22%] [G loss: 0.791836]\n",
      "epoch:23 step:22433 [D loss: 0.807477, acc.: 45.31%] [G loss: 0.808969]\n",
      "epoch:23 step:22434 [D loss: 0.712599, acc.: 60.16%] [G loss: 0.946742]\n",
      "epoch:23 step:22435 [D loss: 0.516194, acc.: 74.22%] [G loss: 1.666252]\n",
      "epoch:23 step:22436 [D loss: 0.415177, acc.: 87.50%] [G loss: 1.272747]\n",
      "epoch:23 step:22437 [D loss: 0.607088, acc.: 68.75%] [G loss: 1.238676]\n",
      "epoch:23 step:22438 [D loss: 0.484354, acc.: 76.56%] [G loss: 1.274065]\n",
      "epoch:23 step:22439 [D loss: 0.679887, acc.: 60.16%] [G loss: 1.190401]\n",
      "epoch:23 step:22440 [D loss: 0.678886, acc.: 59.38%] [G loss: 0.904660]\n",
      "epoch:23 step:22441 [D loss: 0.414666, acc.: 88.28%] [G loss: 1.480303]\n",
      "epoch:23 step:22442 [D loss: 0.782176, acc.: 46.88%] [G loss: 1.515105]\n",
      "epoch:23 step:22443 [D loss: 0.556691, acc.: 75.78%] [G loss: 1.029708]\n",
      "epoch:23 step:22444 [D loss: 0.659693, acc.: 61.72%] [G loss: 1.351390]\n",
      "epoch:23 step:22445 [D loss: 0.383024, acc.: 89.84%] [G loss: 1.434610]\n",
      "epoch:23 step:22446 [D loss: 0.327176, acc.: 92.19%] [G loss: 1.333002]\n",
      "epoch:23 step:22447 [D loss: 0.272729, acc.: 93.75%] [G loss: 1.583265]\n",
      "epoch:23 step:22448 [D loss: 0.278432, acc.: 94.53%] [G loss: 1.773703]\n",
      "epoch:23 step:22449 [D loss: 0.254413, acc.: 96.88%] [G loss: 1.749825]\n",
      "epoch:23 step:22450 [D loss: 0.190239, acc.: 97.66%] [G loss: 1.653514]\n",
      "epoch:23 step:22451 [D loss: 0.183509, acc.: 98.44%] [G loss: 1.843264]\n",
      "epoch:23 step:22452 [D loss: 0.269332, acc.: 95.31%] [G loss: 2.131951]\n",
      "epoch:23 step:22453 [D loss: 0.501288, acc.: 74.22%] [G loss: 1.385649]\n",
      "epoch:23 step:22454 [D loss: 0.308885, acc.: 96.88%] [G loss: 1.410459]\n",
      "epoch:23 step:22455 [D loss: 0.800518, acc.: 46.09%] [G loss: 0.853986]\n",
      "epoch:23 step:22456 [D loss: 0.688942, acc.: 59.38%] [G loss: 1.068035]\n",
      "epoch:23 step:22457 [D loss: 0.764068, acc.: 51.56%] [G loss: 0.961818]\n",
      "epoch:23 step:22458 [D loss: 0.696912, acc.: 60.94%] [G loss: 0.858957]\n",
      "epoch:23 step:22459 [D loss: 0.465155, acc.: 80.47%] [G loss: 1.396582]\n",
      "epoch:23 step:22460 [D loss: 0.325532, acc.: 92.19%] [G loss: 1.400131]\n",
      "epoch:23 step:22461 [D loss: 0.602556, acc.: 64.84%] [G loss: 1.254435]\n",
      "epoch:23 step:22462 [D loss: 0.248876, acc.: 96.09%] [G loss: 1.267944]\n",
      "epoch:23 step:22463 [D loss: 0.259738, acc.: 85.94%] [G loss: 1.569563]\n",
      "epoch:23 step:22464 [D loss: 0.842516, acc.: 53.12%] [G loss: 1.303622]\n",
      "epoch:23 step:22465 [D loss: 1.055898, acc.: 17.97%] [G loss: 0.753550]\n",
      "epoch:23 step:22466 [D loss: 0.695310, acc.: 53.91%] [G loss: 1.304794]\n",
      "epoch:23 step:22467 [D loss: 0.635810, acc.: 59.38%] [G loss: 0.998363]\n",
      "epoch:23 step:22468 [D loss: 0.890059, acc.: 39.06%] [G loss: 1.133368]\n",
      "epoch:23 step:22469 [D loss: 0.591487, acc.: 68.75%] [G loss: 1.126284]\n",
      "epoch:23 step:22470 [D loss: 0.477927, acc.: 75.78%] [G loss: 0.996223]\n",
      "epoch:23 step:22471 [D loss: 0.792000, acc.: 48.44%] [G loss: 1.138926]\n",
      "epoch:23 step:22472 [D loss: 0.567487, acc.: 68.75%] [G loss: 1.400772]\n",
      "epoch:23 step:22473 [D loss: 0.431314, acc.: 83.59%] [G loss: 1.535462]\n",
      "epoch:23 step:22474 [D loss: 0.639859, acc.: 59.38%] [G loss: 1.253365]\n",
      "epoch:23 step:22475 [D loss: 0.423955, acc.: 85.94%] [G loss: 1.263126]\n",
      "epoch:23 step:22476 [D loss: 0.477242, acc.: 81.25%] [G loss: 1.520062]\n",
      "epoch:23 step:22477 [D loss: 0.549239, acc.: 72.66%] [G loss: 1.206312]\n",
      "epoch:23 step:22478 [D loss: 0.471917, acc.: 82.03%] [G loss: 1.278730]\n",
      "epoch:23 step:22479 [D loss: 0.966936, acc.: 46.09%] [G loss: 1.360496]\n",
      "epoch:23 step:22480 [D loss: 0.459331, acc.: 77.34%] [G loss: 1.120670]\n",
      "epoch:23 step:22481 [D loss: 0.363935, acc.: 92.19%] [G loss: 1.593663]\n",
      "epoch:23 step:22482 [D loss: 0.582967, acc.: 64.06%] [G loss: 1.614617]\n",
      "epoch:23 step:22483 [D loss: 0.632896, acc.: 65.62%] [G loss: 0.990064]\n",
      "epoch:23 step:22484 [D loss: 0.764733, acc.: 53.12%] [G loss: 1.192520]\n",
      "epoch:23 step:22485 [D loss: 0.500308, acc.: 74.22%] [G loss: 1.139173]\n",
      "epoch:23 step:22486 [D loss: 0.505233, acc.: 78.12%] [G loss: 1.547751]\n",
      "epoch:23 step:22487 [D loss: 0.410686, acc.: 85.16%] [G loss: 1.267291]\n",
      "epoch:23 step:22488 [D loss: 0.272439, acc.: 91.41%] [G loss: 1.422825]\n",
      "epoch:24 step:22489 [D loss: 0.655473, acc.: 60.94%] [G loss: 1.485694]\n",
      "epoch:24 step:22490 [D loss: 0.906706, acc.: 32.03%] [G loss: 0.756454]\n",
      "epoch:24 step:22491 [D loss: 0.788990, acc.: 46.09%] [G loss: 1.144800]\n",
      "epoch:24 step:22492 [D loss: 0.602183, acc.: 61.72%] [G loss: 0.960649]\n",
      "epoch:24 step:22493 [D loss: 0.580915, acc.: 71.88%] [G loss: 1.130076]\n",
      "epoch:24 step:22494 [D loss: 0.514092, acc.: 76.56%] [G loss: 1.215997]\n",
      "epoch:24 step:22495 [D loss: 0.593997, acc.: 69.53%] [G loss: 1.074220]\n",
      "epoch:24 step:22496 [D loss: 0.512234, acc.: 78.12%] [G loss: 1.117313]\n",
      "epoch:24 step:22497 [D loss: 0.562379, acc.: 71.88%] [G loss: 1.187207]\n",
      "epoch:24 step:22498 [D loss: 0.551783, acc.: 66.41%] [G loss: 1.008413]\n",
      "epoch:24 step:22499 [D loss: 0.470871, acc.: 79.69%] [G loss: 1.467478]\n",
      "epoch:24 step:22500 [D loss: 0.592225, acc.: 72.66%] [G loss: 0.985957]\n",
      "epoch:24 step:22501 [D loss: 0.901773, acc.: 40.62%] [G loss: 0.618443]\n",
      "epoch:24 step:22502 [D loss: 0.733000, acc.: 60.94%] [G loss: 1.200934]\n",
      "epoch:24 step:22503 [D loss: 0.459312, acc.: 82.03%] [G loss: 1.088509]\n",
      "epoch:24 step:22504 [D loss: 0.456002, acc.: 78.91%] [G loss: 1.584955]\n",
      "epoch:24 step:22505 [D loss: 0.612322, acc.: 67.19%] [G loss: 1.661229]\n",
      "epoch:24 step:22506 [D loss: 0.729146, acc.: 49.22%] [G loss: 1.081574]\n",
      "epoch:24 step:22507 [D loss: 0.652541, acc.: 64.06%] [G loss: 1.014410]\n",
      "epoch:24 step:22508 [D loss: 0.639812, acc.: 60.16%] [G loss: 1.034427]\n",
      "epoch:24 step:22509 [D loss: 0.632709, acc.: 70.31%] [G loss: 1.288926]\n",
      "epoch:24 step:22510 [D loss: 0.580181, acc.: 67.97%] [G loss: 1.372018]\n",
      "epoch:24 step:22511 [D loss: 0.596216, acc.: 67.97%] [G loss: 1.021904]\n",
      "epoch:24 step:22512 [D loss: 0.651586, acc.: 64.06%] [G loss: 1.016244]\n",
      "epoch:24 step:22513 [D loss: 0.693185, acc.: 59.38%] [G loss: 0.923314]\n",
      "epoch:24 step:22514 [D loss: 0.427157, acc.: 82.03%] [G loss: 1.154670]\n",
      "epoch:24 step:22515 [D loss: 0.353828, acc.: 89.84%] [G loss: 1.469706]\n",
      "epoch:24 step:22516 [D loss: 0.417607, acc.: 87.50%] [G loss: 1.359629]\n",
      "epoch:24 step:22517 [D loss: 0.530810, acc.: 77.34%] [G loss: 1.240695]\n",
      "epoch:24 step:22518 [D loss: 0.351500, acc.: 89.06%] [G loss: 1.490125]\n",
      "epoch:24 step:22519 [D loss: 0.353786, acc.: 90.62%] [G loss: 1.617470]\n",
      "epoch:24 step:22520 [D loss: 0.229660, acc.: 98.44%] [G loss: 1.419318]\n",
      "epoch:24 step:22521 [D loss: 0.224483, acc.: 97.66%] [G loss: 1.633594]\n",
      "epoch:24 step:22522 [D loss: 0.258049, acc.: 96.09%] [G loss: 1.584469]\n",
      "epoch:24 step:22523 [D loss: 0.170344, acc.: 98.44%] [G loss: 2.024729]\n",
      "epoch:24 step:22524 [D loss: 0.132144, acc.: 100.00%] [G loss: 1.779304]\n",
      "epoch:24 step:22525 [D loss: 0.766088, acc.: 53.91%] [G loss: 1.306151]\n",
      "epoch:24 step:22526 [D loss: 0.915964, acc.: 38.28%] [G loss: 0.753081]\n",
      "epoch:24 step:22527 [D loss: 0.729654, acc.: 54.69%] [G loss: 1.012932]\n",
      "epoch:24 step:22528 [D loss: 0.637185, acc.: 60.94%] [G loss: 0.979010]\n",
      "epoch:24 step:22529 [D loss: 0.643593, acc.: 61.72%] [G loss: 1.054400]\n",
      "epoch:24 step:22530 [D loss: 0.496802, acc.: 76.56%] [G loss: 1.084192]\n",
      "epoch:24 step:22531 [D loss: 0.527076, acc.: 79.69%] [G loss: 0.980275]\n",
      "epoch:24 step:22532 [D loss: 0.669966, acc.: 60.16%] [G loss: 0.862881]\n",
      "epoch:24 step:22533 [D loss: 0.643750, acc.: 64.84%] [G loss: 1.189051]\n",
      "epoch:24 step:22534 [D loss: 0.774398, acc.: 50.78%] [G loss: 1.083847]\n",
      "epoch:24 step:22535 [D loss: 0.754849, acc.: 47.66%] [G loss: 1.124383]\n",
      "epoch:24 step:22536 [D loss: 0.800188, acc.: 44.53%] [G loss: 0.799339]\n",
      "epoch:24 step:22537 [D loss: 0.875369, acc.: 42.97%] [G loss: 0.958168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22538 [D loss: 0.616688, acc.: 65.62%] [G loss: 1.408360]\n",
      "epoch:24 step:22539 [D loss: 0.627229, acc.: 66.41%] [G loss: 0.921943]\n",
      "epoch:24 step:22540 [D loss: 0.594439, acc.: 68.75%] [G loss: 1.024595]\n",
      "epoch:24 step:22541 [D loss: 0.759353, acc.: 50.00%] [G loss: 0.848477]\n",
      "epoch:24 step:22542 [D loss: 0.548632, acc.: 71.09%] [G loss: 1.010426]\n",
      "epoch:24 step:22543 [D loss: 0.589870, acc.: 64.84%] [G loss: 1.168869]\n",
      "epoch:24 step:22544 [D loss: 0.584772, acc.: 67.97%] [G loss: 1.266941]\n",
      "epoch:24 step:22545 [D loss: 0.684835, acc.: 60.16%] [G loss: 0.771889]\n",
      "epoch:24 step:22546 [D loss: 0.699958, acc.: 57.81%] [G loss: 1.041512]\n",
      "epoch:24 step:22547 [D loss: 0.598760, acc.: 67.19%] [G loss: 1.046020]\n",
      "epoch:24 step:22548 [D loss: 0.752422, acc.: 46.09%] [G loss: 0.913731]\n",
      "epoch:24 step:22549 [D loss: 0.708516, acc.: 53.12%] [G loss: 0.966553]\n",
      "epoch:24 step:22550 [D loss: 0.875575, acc.: 40.62%] [G loss: 0.657143]\n",
      "epoch:24 step:22551 [D loss: 0.588706, acc.: 67.19%] [G loss: 0.964762]\n",
      "epoch:24 step:22552 [D loss: 0.461976, acc.: 80.47%] [G loss: 1.196619]\n",
      "epoch:24 step:22553 [D loss: 0.529532, acc.: 76.56%] [G loss: 1.345905]\n",
      "epoch:24 step:22554 [D loss: 0.552893, acc.: 71.09%] [G loss: 1.179235]\n",
      "epoch:24 step:22555 [D loss: 0.583068, acc.: 73.44%] [G loss: 1.132563]\n",
      "epoch:24 step:22556 [D loss: 0.407778, acc.: 87.50%] [G loss: 1.322675]\n",
      "epoch:24 step:22557 [D loss: 0.313514, acc.: 92.97%] [G loss: 1.149884]\n",
      "epoch:24 step:22558 [D loss: 0.408407, acc.: 84.38%] [G loss: 1.680943]\n",
      "epoch:24 step:22559 [D loss: 0.855014, acc.: 36.72%] [G loss: 0.898477]\n",
      "epoch:24 step:22560 [D loss: 0.690235, acc.: 55.47%] [G loss: 0.921305]\n",
      "epoch:24 step:22561 [D loss: 0.711609, acc.: 58.59%] [G loss: 1.070599]\n",
      "epoch:24 step:22562 [D loss: 0.521696, acc.: 72.66%] [G loss: 1.007574]\n",
      "epoch:24 step:22563 [D loss: 0.368783, acc.: 86.72%] [G loss: 1.238997]\n",
      "epoch:24 step:22564 [D loss: 0.483022, acc.: 77.34%] [G loss: 1.512423]\n",
      "epoch:24 step:22565 [D loss: 0.434326, acc.: 87.50%] [G loss: 1.170414]\n",
      "epoch:24 step:22566 [D loss: 0.752308, acc.: 51.56%] [G loss: 1.136137]\n",
      "epoch:24 step:22567 [D loss: 0.775842, acc.: 48.44%] [G loss: 0.994962]\n",
      "epoch:24 step:22568 [D loss: 0.484752, acc.: 82.81%] [G loss: 1.183762]\n",
      "epoch:24 step:22569 [D loss: 0.494962, acc.: 77.34%] [G loss: 1.177345]\n",
      "epoch:24 step:22570 [D loss: 0.494938, acc.: 81.25%] [G loss: 1.085383]\n",
      "epoch:24 step:22571 [D loss: 0.555706, acc.: 73.44%] [G loss: 0.926406]\n",
      "epoch:24 step:22572 [D loss: 0.606107, acc.: 66.41%] [G loss: 1.274533]\n",
      "epoch:24 step:22573 [D loss: 0.646444, acc.: 60.94%] [G loss: 1.275061]\n",
      "epoch:24 step:22574 [D loss: 0.644896, acc.: 59.38%] [G loss: 0.909920]\n",
      "epoch:24 step:22575 [D loss: 0.502698, acc.: 80.47%] [G loss: 1.224288]\n",
      "epoch:24 step:22576 [D loss: 0.556986, acc.: 76.56%] [G loss: 1.086605]\n",
      "epoch:24 step:22577 [D loss: 0.620191, acc.: 67.97%] [G loss: 1.261600]\n",
      "epoch:24 step:22578 [D loss: 0.505371, acc.: 77.34%] [G loss: 1.013974]\n",
      "epoch:24 step:22579 [D loss: 0.591161, acc.: 67.19%] [G loss: 1.249620]\n",
      "epoch:24 step:22580 [D loss: 0.527384, acc.: 76.56%] [G loss: 1.281318]\n",
      "epoch:24 step:22581 [D loss: 0.498879, acc.: 80.47%] [G loss: 1.285588]\n",
      "epoch:24 step:22582 [D loss: 0.774000, acc.: 49.22%] [G loss: 0.929586]\n",
      "epoch:24 step:22583 [D loss: 1.045851, acc.: 21.09%] [G loss: 0.584613]\n",
      "epoch:24 step:22584 [D loss: 0.756026, acc.: 51.56%] [G loss: 1.034259]\n",
      "epoch:24 step:22585 [D loss: 0.890361, acc.: 42.97%] [G loss: 0.762630]\n",
      "epoch:24 step:22586 [D loss: 0.686979, acc.: 53.91%] [G loss: 1.033426]\n",
      "epoch:24 step:22587 [D loss: 0.831096, acc.: 39.84%] [G loss: 1.044475]\n",
      "epoch:24 step:22588 [D loss: 0.638787, acc.: 59.38%] [G loss: 1.289082]\n",
      "epoch:24 step:22589 [D loss: 0.690092, acc.: 53.91%] [G loss: 1.020972]\n",
      "epoch:24 step:22590 [D loss: 0.561554, acc.: 77.34%] [G loss: 1.275467]\n",
      "epoch:24 step:22591 [D loss: 0.523079, acc.: 75.78%] [G loss: 1.253941]\n",
      "epoch:24 step:22592 [D loss: 0.516016, acc.: 78.91%] [G loss: 1.295329]\n",
      "epoch:24 step:22593 [D loss: 0.445989, acc.: 78.12%] [G loss: 1.254070]\n",
      "epoch:24 step:22594 [D loss: 0.432247, acc.: 84.38%] [G loss: 1.628722]\n",
      "epoch:24 step:22595 [D loss: 0.514909, acc.: 73.44%] [G loss: 1.587030]\n",
      "epoch:24 step:22596 [D loss: 0.439170, acc.: 84.38%] [G loss: 1.346851]\n",
      "epoch:24 step:22597 [D loss: 0.359422, acc.: 90.62%] [G loss: 1.510197]\n",
      "epoch:24 step:22598 [D loss: 0.562522, acc.: 71.09%] [G loss: 1.078157]\n",
      "epoch:24 step:22599 [D loss: 0.813781, acc.: 46.88%] [G loss: 0.885442]\n",
      "epoch:24 step:22600 [D loss: 0.469130, acc.: 78.12%] [G loss: 1.357988]\n",
      "epoch:24 step:22601 [D loss: 0.639502, acc.: 61.72%] [G loss: 1.471981]\n",
      "epoch:24 step:22602 [D loss: 0.846878, acc.: 38.28%] [G loss: 0.823339]\n",
      "epoch:24 step:22603 [D loss: 0.570603, acc.: 79.69%] [G loss: 1.041668]\n",
      "epoch:24 step:22604 [D loss: 0.492942, acc.: 77.34%] [G loss: 1.071501]\n",
      "epoch:24 step:22605 [D loss: 0.433455, acc.: 79.69%] [G loss: 0.932369]\n",
      "epoch:24 step:22606 [D loss: 0.304222, acc.: 96.09%] [G loss: 1.684023]\n",
      "epoch:24 step:22607 [D loss: 0.359964, acc.: 89.06%] [G loss: 1.455132]\n",
      "epoch:24 step:22608 [D loss: 1.099616, acc.: 34.38%] [G loss: 1.500354]\n",
      "epoch:24 step:22609 [D loss: 0.881686, acc.: 35.16%] [G loss: 1.086529]\n",
      "epoch:24 step:22610 [D loss: 0.425619, acc.: 87.50%] [G loss: 1.714388]\n",
      "epoch:24 step:22611 [D loss: 0.704918, acc.: 58.59%] [G loss: 1.011309]\n",
      "epoch:24 step:22612 [D loss: 0.614669, acc.: 67.19%] [G loss: 1.237515]\n",
      "epoch:24 step:22613 [D loss: 0.605106, acc.: 63.28%] [G loss: 1.147079]\n",
      "epoch:24 step:22614 [D loss: 0.562799, acc.: 71.88%] [G loss: 1.168588]\n",
      "epoch:24 step:22615 [D loss: 0.550796, acc.: 76.56%] [G loss: 1.040719]\n",
      "epoch:24 step:22616 [D loss: 0.627357, acc.: 62.50%] [G loss: 0.933319]\n",
      "epoch:24 step:22617 [D loss: 0.583737, acc.: 67.97%] [G loss: 0.927683]\n",
      "epoch:24 step:22618 [D loss: 0.428215, acc.: 88.28%] [G loss: 1.257711]\n",
      "epoch:24 step:22619 [D loss: 0.504382, acc.: 75.78%] [G loss: 1.152817]\n",
      "epoch:24 step:22620 [D loss: 0.648735, acc.: 62.50%] [G loss: 1.056434]\n",
      "epoch:24 step:22621 [D loss: 0.698028, acc.: 57.81%] [G loss: 1.169366]\n",
      "epoch:24 step:22622 [D loss: 0.725593, acc.: 53.91%] [G loss: 1.064810]\n",
      "epoch:24 step:22623 [D loss: 0.644000, acc.: 62.50%] [G loss: 1.205511]\n",
      "epoch:24 step:22624 [D loss: 0.624079, acc.: 63.28%] [G loss: 0.987472]\n",
      "epoch:24 step:22625 [D loss: 0.583613, acc.: 70.31%] [G loss: 0.882087]\n",
      "epoch:24 step:22626 [D loss: 0.557507, acc.: 71.88%] [G loss: 1.030333]\n",
      "epoch:24 step:22627 [D loss: 0.436548, acc.: 81.25%] [G loss: 1.037405]\n",
      "epoch:24 step:22628 [D loss: 0.651089, acc.: 60.94%] [G loss: 1.135499]\n",
      "epoch:24 step:22629 [D loss: 0.715295, acc.: 56.25%] [G loss: 1.179396]\n",
      "epoch:24 step:22630 [D loss: 0.594833, acc.: 65.62%] [G loss: 1.080886]\n",
      "epoch:24 step:22631 [D loss: 0.554497, acc.: 73.44%] [G loss: 1.152402]\n",
      "epoch:24 step:22632 [D loss: 0.628187, acc.: 64.84%] [G loss: 0.993051]\n",
      "epoch:24 step:22633 [D loss: 0.566493, acc.: 71.88%] [G loss: 1.213286]\n",
      "epoch:24 step:22634 [D loss: 0.747046, acc.: 49.22%] [G loss: 1.225682]\n",
      "epoch:24 step:22635 [D loss: 0.595726, acc.: 70.31%] [G loss: 1.200319]\n",
      "epoch:24 step:22636 [D loss: 0.649519, acc.: 61.72%] [G loss: 1.149120]\n",
      "epoch:24 step:22637 [D loss: 0.573919, acc.: 72.66%] [G loss: 1.072527]\n",
      "epoch:24 step:22638 [D loss: 0.444371, acc.: 82.03%] [G loss: 1.498452]\n",
      "epoch:24 step:22639 [D loss: 0.487431, acc.: 82.03%] [G loss: 1.265284]\n",
      "epoch:24 step:22640 [D loss: 0.324050, acc.: 92.97%] [G loss: 1.301304]\n",
      "epoch:24 step:22641 [D loss: 0.607417, acc.: 67.19%] [G loss: 1.263559]\n",
      "epoch:24 step:22642 [D loss: 0.543819, acc.: 76.56%] [G loss: 1.002709]\n",
      "epoch:24 step:22643 [D loss: 0.627268, acc.: 62.50%] [G loss: 1.242450]\n",
      "epoch:24 step:22644 [D loss: 0.480782, acc.: 80.47%] [G loss: 1.162710]\n",
      "epoch:24 step:22645 [D loss: 0.599715, acc.: 66.41%] [G loss: 1.234690]\n",
      "epoch:24 step:22646 [D loss: 0.520116, acc.: 76.56%] [G loss: 1.093178]\n",
      "epoch:24 step:22647 [D loss: 0.282430, acc.: 97.66%] [G loss: 1.457905]\n",
      "epoch:24 step:22648 [D loss: 0.811148, acc.: 40.62%] [G loss: 1.141166]\n",
      "epoch:24 step:22649 [D loss: 0.851815, acc.: 44.53%] [G loss: 1.185601]\n",
      "epoch:24 step:22650 [D loss: 0.673041, acc.: 60.16%] [G loss: 0.923925]\n",
      "epoch:24 step:22651 [D loss: 0.764072, acc.: 49.22%] [G loss: 0.926948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22652 [D loss: 0.638174, acc.: 59.38%] [G loss: 0.924572]\n",
      "epoch:24 step:22653 [D loss: 0.798719, acc.: 42.19%] [G loss: 0.872824]\n",
      "epoch:24 step:22654 [D loss: 0.452909, acc.: 82.03%] [G loss: 0.911091]\n",
      "epoch:24 step:22655 [D loss: 0.570242, acc.: 73.44%] [G loss: 1.281603]\n",
      "epoch:24 step:22656 [D loss: 0.532429, acc.: 75.00%] [G loss: 1.066126]\n",
      "epoch:24 step:22657 [D loss: 0.417553, acc.: 85.16%] [G loss: 1.267207]\n",
      "epoch:24 step:22658 [D loss: 0.592878, acc.: 64.84%] [G loss: 1.463014]\n",
      "epoch:24 step:22659 [D loss: 0.884958, acc.: 41.41%] [G loss: 1.056445]\n",
      "epoch:24 step:22660 [D loss: 0.461226, acc.: 84.38%] [G loss: 1.217857]\n",
      "epoch:24 step:22661 [D loss: 0.687997, acc.: 58.59%] [G loss: 1.296893]\n",
      "epoch:24 step:22662 [D loss: 0.826122, acc.: 41.41%] [G loss: 0.980180]\n",
      "epoch:24 step:22663 [D loss: 0.733399, acc.: 50.78%] [G loss: 0.877616]\n",
      "epoch:24 step:22664 [D loss: 0.762445, acc.: 46.09%] [G loss: 0.937335]\n",
      "epoch:24 step:22665 [D loss: 0.828691, acc.: 49.22%] [G loss: 0.916634]\n",
      "epoch:24 step:22666 [D loss: 0.891632, acc.: 38.28%] [G loss: 0.800810]\n",
      "epoch:24 step:22667 [D loss: 0.767913, acc.: 51.56%] [G loss: 0.946741]\n",
      "epoch:24 step:22668 [D loss: 0.782114, acc.: 50.00%] [G loss: 0.704312]\n",
      "epoch:24 step:22669 [D loss: 0.613046, acc.: 68.75%] [G loss: 1.021554]\n",
      "epoch:24 step:22670 [D loss: 0.474170, acc.: 82.81%] [G loss: 1.210883]\n",
      "epoch:24 step:22671 [D loss: 0.679946, acc.: 60.94%] [G loss: 0.872828]\n",
      "epoch:24 step:22672 [D loss: 0.585030, acc.: 73.44%] [G loss: 0.783361]\n",
      "epoch:24 step:22673 [D loss: 0.734347, acc.: 53.12%] [G loss: 0.976537]\n",
      "epoch:24 step:22674 [D loss: 1.100333, acc.: 22.66%] [G loss: 0.753016]\n",
      "epoch:24 step:22675 [D loss: 0.881346, acc.: 33.59%] [G loss: 0.790543]\n",
      "epoch:24 step:22676 [D loss: 0.682677, acc.: 60.16%] [G loss: 0.946550]\n",
      "epoch:24 step:22677 [D loss: 0.940363, acc.: 28.91%] [G loss: 0.770943]\n",
      "epoch:24 step:22678 [D loss: 0.575239, acc.: 72.66%] [G loss: 1.444796]\n",
      "epoch:24 step:22679 [D loss: 0.823972, acc.: 41.41%] [G loss: 1.240559]\n",
      "epoch:24 step:22680 [D loss: 0.513560, acc.: 78.12%] [G loss: 1.213827]\n",
      "epoch:24 step:22681 [D loss: 0.660546, acc.: 58.59%] [G loss: 1.051535]\n",
      "epoch:24 step:22682 [D loss: 0.646250, acc.: 65.62%] [G loss: 1.020591]\n",
      "epoch:24 step:22683 [D loss: 0.568103, acc.: 74.22%] [G loss: 1.207941]\n",
      "epoch:24 step:22684 [D loss: 0.694794, acc.: 59.38%] [G loss: 0.899876]\n",
      "epoch:24 step:22685 [D loss: 0.542429, acc.: 75.00%] [G loss: 1.134138]\n",
      "epoch:24 step:22686 [D loss: 0.686633, acc.: 60.16%] [G loss: 0.998654]\n",
      "epoch:24 step:22687 [D loss: 0.698221, acc.: 62.50%] [G loss: 1.064017]\n",
      "epoch:24 step:22688 [D loss: 0.561201, acc.: 67.97%] [G loss: 1.132928]\n",
      "epoch:24 step:22689 [D loss: 0.355266, acc.: 93.75%] [G loss: 1.318246]\n",
      "epoch:24 step:22690 [D loss: 0.662140, acc.: 60.94%] [G loss: 1.139206]\n",
      "epoch:24 step:22691 [D loss: 0.872105, acc.: 36.72%] [G loss: 1.109593]\n",
      "epoch:24 step:22692 [D loss: 0.697793, acc.: 53.91%] [G loss: 0.828537]\n",
      "epoch:24 step:22693 [D loss: 0.663651, acc.: 60.94%] [G loss: 1.077791]\n",
      "epoch:24 step:22694 [D loss: 0.555059, acc.: 75.00%] [G loss: 1.046119]\n",
      "epoch:24 step:22695 [D loss: 0.499022, acc.: 79.69%] [G loss: 0.959051]\n",
      "epoch:24 step:22696 [D loss: 0.588605, acc.: 68.75%] [G loss: 1.261213]\n",
      "epoch:24 step:22697 [D loss: 0.573117, acc.: 68.75%] [G loss: 0.837267]\n",
      "epoch:24 step:22698 [D loss: 0.736533, acc.: 52.34%] [G loss: 0.900590]\n",
      "epoch:24 step:22699 [D loss: 0.631188, acc.: 59.38%] [G loss: 0.958513]\n",
      "epoch:24 step:22700 [D loss: 0.687034, acc.: 60.94%] [G loss: 1.133294]\n",
      "epoch:24 step:22701 [D loss: 0.494744, acc.: 82.81%] [G loss: 1.376810]\n",
      "epoch:24 step:22702 [D loss: 0.660944, acc.: 57.81%] [G loss: 0.968993]\n",
      "epoch:24 step:22703 [D loss: 0.512073, acc.: 74.22%] [G loss: 0.906756]\n",
      "epoch:24 step:22704 [D loss: 0.548093, acc.: 76.56%] [G loss: 0.968156]\n",
      "epoch:24 step:22705 [D loss: 0.709216, acc.: 57.03%] [G loss: 1.120840]\n",
      "epoch:24 step:22706 [D loss: 0.654925, acc.: 61.72%] [G loss: 1.070272]\n",
      "epoch:24 step:22707 [D loss: 0.568035, acc.: 71.88%] [G loss: 1.102830]\n",
      "epoch:24 step:22708 [D loss: 0.296841, acc.: 92.19%] [G loss: 1.309573]\n",
      "epoch:24 step:22709 [D loss: 0.197442, acc.: 96.88%] [G loss: 1.454684]\n",
      "epoch:24 step:22710 [D loss: 0.302790, acc.: 92.97%] [G loss: 1.503576]\n",
      "epoch:24 step:22711 [D loss: 0.279732, acc.: 95.31%] [G loss: 1.542998]\n",
      "epoch:24 step:22712 [D loss: 0.777683, acc.: 50.00%] [G loss: 1.041036]\n",
      "epoch:24 step:22713 [D loss: 0.670174, acc.: 63.28%] [G loss: 1.070048]\n",
      "epoch:24 step:22714 [D loss: 0.504957, acc.: 78.91%] [G loss: 1.130691]\n",
      "epoch:24 step:22715 [D loss: 0.576321, acc.: 72.66%] [G loss: 0.982443]\n",
      "epoch:24 step:22716 [D loss: 0.600616, acc.: 68.75%] [G loss: 1.170013]\n",
      "epoch:24 step:22717 [D loss: 0.514053, acc.: 78.91%] [G loss: 1.037314]\n",
      "epoch:24 step:22718 [D loss: 0.247345, acc.: 92.19%] [G loss: 1.719672]\n",
      "epoch:24 step:22719 [D loss: 0.183087, acc.: 97.66%] [G loss: 1.777804]\n",
      "epoch:24 step:22720 [D loss: 0.199477, acc.: 96.88%] [G loss: 1.896567]\n",
      "epoch:24 step:22721 [D loss: 0.708407, acc.: 59.38%] [G loss: 1.472197]\n",
      "epoch:24 step:22722 [D loss: 0.776094, acc.: 47.66%] [G loss: 1.095404]\n",
      "epoch:24 step:22723 [D loss: 0.423821, acc.: 83.59%] [G loss: 1.409959]\n",
      "epoch:24 step:22724 [D loss: 0.710901, acc.: 53.12%] [G loss: 1.179615]\n",
      "epoch:24 step:22725 [D loss: 0.823802, acc.: 46.09%] [G loss: 0.847769]\n",
      "epoch:24 step:22726 [D loss: 0.484425, acc.: 80.47%] [G loss: 1.432393]\n",
      "epoch:24 step:22727 [D loss: 0.742040, acc.: 50.78%] [G loss: 0.640923]\n",
      "epoch:24 step:22728 [D loss: 0.866809, acc.: 39.06%] [G loss: 0.957014]\n",
      "epoch:24 step:22729 [D loss: 0.888101, acc.: 37.50%] [G loss: 1.141719]\n",
      "epoch:24 step:22730 [D loss: 0.954139, acc.: 28.12%] [G loss: 0.722812]\n",
      "epoch:24 step:22731 [D loss: 0.772441, acc.: 50.78%] [G loss: 1.082743]\n",
      "epoch:24 step:22732 [D loss: 0.710164, acc.: 57.03%] [G loss: 1.270331]\n",
      "epoch:24 step:22733 [D loss: 0.735205, acc.: 50.78%] [G loss: 1.160131]\n",
      "epoch:24 step:22734 [D loss: 0.646229, acc.: 61.72%] [G loss: 1.043457]\n",
      "epoch:24 step:22735 [D loss: 0.686721, acc.: 59.38%] [G loss: 1.189361]\n",
      "epoch:24 step:22736 [D loss: 0.566251, acc.: 71.88%] [G loss: 1.312872]\n",
      "epoch:24 step:22737 [D loss: 0.665882, acc.: 58.59%] [G loss: 1.053716]\n",
      "epoch:24 step:22738 [D loss: 0.635728, acc.: 62.50%] [G loss: 1.063989]\n",
      "epoch:24 step:22739 [D loss: 0.669161, acc.: 60.16%] [G loss: 1.212802]\n",
      "epoch:24 step:22740 [D loss: 0.542830, acc.: 75.00%] [G loss: 1.047208]\n",
      "epoch:24 step:22741 [D loss: 0.507271, acc.: 78.12%] [G loss: 1.038157]\n",
      "epoch:24 step:22742 [D loss: 0.655983, acc.: 63.28%] [G loss: 0.836425]\n",
      "epoch:24 step:22743 [D loss: 0.736974, acc.: 53.12%] [G loss: 1.086799]\n",
      "epoch:24 step:22744 [D loss: 0.793630, acc.: 46.88%] [G loss: 0.873935]\n",
      "epoch:24 step:22745 [D loss: 0.676208, acc.: 59.38%] [G loss: 1.060036]\n",
      "epoch:24 step:22746 [D loss: 0.607725, acc.: 63.28%] [G loss: 1.210479]\n",
      "epoch:24 step:22747 [D loss: 0.670313, acc.: 56.25%] [G loss: 1.172011]\n",
      "epoch:24 step:22748 [D loss: 0.654732, acc.: 60.94%] [G loss: 0.915547]\n",
      "epoch:24 step:22749 [D loss: 0.528503, acc.: 75.00%] [G loss: 1.152496]\n",
      "epoch:24 step:22750 [D loss: 0.546876, acc.: 73.44%] [G loss: 1.151759]\n",
      "epoch:24 step:22751 [D loss: 0.552594, acc.: 72.66%] [G loss: 1.302130]\n",
      "epoch:24 step:22752 [D loss: 0.487011, acc.: 80.47%] [G loss: 1.230530]\n",
      "epoch:24 step:22753 [D loss: 0.722044, acc.: 52.34%] [G loss: 1.131147]\n",
      "epoch:24 step:22754 [D loss: 0.696042, acc.: 54.69%] [G loss: 1.083066]\n",
      "epoch:24 step:22755 [D loss: 0.716308, acc.: 52.34%] [G loss: 1.144588]\n",
      "epoch:24 step:22756 [D loss: 0.656721, acc.: 58.59%] [G loss: 1.075958]\n",
      "epoch:24 step:22757 [D loss: 0.578835, acc.: 69.53%] [G loss: 0.973470]\n",
      "epoch:24 step:22758 [D loss: 0.703424, acc.: 58.59%] [G loss: 1.015475]\n",
      "epoch:24 step:22759 [D loss: 0.491979, acc.: 80.47%] [G loss: 1.422743]\n",
      "epoch:24 step:22760 [D loss: 0.351299, acc.: 92.97%] [G loss: 1.210419]\n",
      "epoch:24 step:22761 [D loss: 0.426578, acc.: 89.06%] [G loss: 1.592112]\n",
      "epoch:24 step:22762 [D loss: 0.675504, acc.: 64.84%] [G loss: 1.084405]\n",
      "epoch:24 step:22763 [D loss: 0.659010, acc.: 61.72%] [G loss: 1.124910]\n",
      "epoch:24 step:22764 [D loss: 0.667849, acc.: 59.38%] [G loss: 0.950806]\n",
      "epoch:24 step:22765 [D loss: 0.736380, acc.: 47.66%] [G loss: 1.178098]\n",
      "epoch:24 step:22766 [D loss: 0.628907, acc.: 64.84%] [G loss: 0.979501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22767 [D loss: 0.440514, acc.: 78.91%] [G loss: 1.264987]\n",
      "epoch:24 step:22768 [D loss: 0.447249, acc.: 87.50%] [G loss: 1.155736]\n",
      "epoch:24 step:22769 [D loss: 0.685004, acc.: 58.59%] [G loss: 1.188302]\n",
      "epoch:24 step:22770 [D loss: 0.462239, acc.: 87.50%] [G loss: 1.195028]\n",
      "epoch:24 step:22771 [D loss: 0.625993, acc.: 65.62%] [G loss: 1.120893]\n",
      "epoch:24 step:22772 [D loss: 0.505949, acc.: 78.12%] [G loss: 1.136968]\n",
      "epoch:24 step:22773 [D loss: 0.453729, acc.: 84.38%] [G loss: 1.306234]\n",
      "epoch:24 step:22774 [D loss: 0.355239, acc.: 91.41%] [G loss: 1.304293]\n",
      "epoch:24 step:22775 [D loss: 0.406282, acc.: 89.84%] [G loss: 1.338767]\n",
      "epoch:24 step:22776 [D loss: 0.534629, acc.: 75.78%] [G loss: 0.994856]\n",
      "epoch:24 step:22777 [D loss: 0.534401, acc.: 70.31%] [G loss: 0.971069]\n",
      "epoch:24 step:22778 [D loss: 0.573274, acc.: 67.97%] [G loss: 1.319104]\n",
      "epoch:24 step:22779 [D loss: 0.515212, acc.: 71.09%] [G loss: 0.952253]\n",
      "epoch:24 step:22780 [D loss: 0.563930, acc.: 66.41%] [G loss: 1.350020]\n",
      "epoch:24 step:22781 [D loss: 0.458652, acc.: 80.47%] [G loss: 1.573427]\n",
      "epoch:24 step:22782 [D loss: 0.579051, acc.: 64.84%] [G loss: 1.539120]\n",
      "epoch:24 step:22783 [D loss: 0.954145, acc.: 35.16%] [G loss: 0.979879]\n",
      "epoch:24 step:22784 [D loss: 0.631459, acc.: 67.97%] [G loss: 1.164095]\n",
      "epoch:24 step:22785 [D loss: 0.625598, acc.: 65.62%] [G loss: 1.190325]\n",
      "epoch:24 step:22786 [D loss: 0.649392, acc.: 55.47%] [G loss: 1.223913]\n",
      "epoch:24 step:22787 [D loss: 0.711771, acc.: 52.34%] [G loss: 1.192820]\n",
      "epoch:24 step:22788 [D loss: 0.640293, acc.: 58.59%] [G loss: 1.064197]\n",
      "epoch:24 step:22789 [D loss: 0.667428, acc.: 61.72%] [G loss: 1.451932]\n",
      "epoch:24 step:22790 [D loss: 0.603481, acc.: 69.53%] [G loss: 1.217961]\n",
      "epoch:24 step:22791 [D loss: 0.560811, acc.: 69.53%] [G loss: 1.044579]\n",
      "epoch:24 step:22792 [D loss: 0.602736, acc.: 63.28%] [G loss: 1.050579]\n",
      "epoch:24 step:22793 [D loss: 0.595749, acc.: 66.41%] [G loss: 1.068298]\n",
      "epoch:24 step:22794 [D loss: 0.490226, acc.: 82.81%] [G loss: 1.239368]\n",
      "epoch:24 step:22795 [D loss: 0.692552, acc.: 50.00%] [G loss: 0.878512]\n",
      "epoch:24 step:22796 [D loss: 0.553231, acc.: 74.22%] [G loss: 0.926423]\n",
      "epoch:24 step:22797 [D loss: 0.420722, acc.: 89.06%] [G loss: 1.251160]\n",
      "epoch:24 step:22798 [D loss: 0.651146, acc.: 60.94%] [G loss: 1.042632]\n",
      "epoch:24 step:22799 [D loss: 0.553104, acc.: 71.09%] [G loss: 1.188368]\n",
      "epoch:24 step:22800 [D loss: 0.424999, acc.: 85.16%] [G loss: 1.260776]\n",
      "epoch:24 step:22801 [D loss: 0.410663, acc.: 90.62%] [G loss: 1.213101]\n",
      "epoch:24 step:22802 [D loss: 0.508667, acc.: 79.69%] [G loss: 1.178171]\n",
      "epoch:24 step:22803 [D loss: 0.528297, acc.: 78.91%] [G loss: 1.211614]\n",
      "epoch:24 step:22804 [D loss: 0.802985, acc.: 48.44%] [G loss: 1.401961]\n",
      "epoch:24 step:22805 [D loss: 0.592637, acc.: 67.97%] [G loss: 1.211445]\n",
      "epoch:24 step:22806 [D loss: 0.504406, acc.: 78.12%] [G loss: 1.132937]\n",
      "epoch:24 step:22807 [D loss: 0.633609, acc.: 61.72%] [G loss: 1.286299]\n",
      "epoch:24 step:22808 [D loss: 0.517540, acc.: 78.12%] [G loss: 1.108326]\n",
      "epoch:24 step:22809 [D loss: 0.534762, acc.: 67.97%] [G loss: 1.029041]\n",
      "epoch:24 step:22810 [D loss: 0.382785, acc.: 92.19%] [G loss: 1.242839]\n",
      "epoch:24 step:22811 [D loss: 0.707907, acc.: 59.38%] [G loss: 1.234203]\n",
      "epoch:24 step:22812 [D loss: 0.716803, acc.: 52.34%] [G loss: 0.743069]\n",
      "epoch:24 step:22813 [D loss: 0.628366, acc.: 64.84%] [G loss: 1.039578]\n",
      "epoch:24 step:22814 [D loss: 0.596426, acc.: 65.62%] [G loss: 0.945082]\n",
      "epoch:24 step:22815 [D loss: 0.348332, acc.: 87.50%] [G loss: 1.455876]\n",
      "epoch:24 step:22816 [D loss: 0.528031, acc.: 71.09%] [G loss: 1.168353]\n",
      "epoch:24 step:22817 [D loss: 0.805271, acc.: 48.44%] [G loss: 1.041329]\n",
      "epoch:24 step:22818 [D loss: 0.706549, acc.: 55.47%] [G loss: 1.134472]\n",
      "epoch:24 step:22819 [D loss: 0.712411, acc.: 57.03%] [G loss: 1.231052]\n",
      "epoch:24 step:22820 [D loss: 0.591709, acc.: 67.19%] [G loss: 0.917359]\n",
      "epoch:24 step:22821 [D loss: 0.529042, acc.: 77.34%] [G loss: 1.075671]\n",
      "epoch:24 step:22822 [D loss: 0.633146, acc.: 61.72%] [G loss: 1.043128]\n",
      "epoch:24 step:22823 [D loss: 0.553095, acc.: 70.31%] [G loss: 1.133024]\n",
      "epoch:24 step:22824 [D loss: 0.609068, acc.: 67.19%] [G loss: 1.043817]\n",
      "epoch:24 step:22825 [D loss: 0.492735, acc.: 78.12%] [G loss: 0.936865]\n",
      "epoch:24 step:22826 [D loss: 0.623111, acc.: 67.19%] [G loss: 1.109331]\n",
      "epoch:24 step:22827 [D loss: 0.646155, acc.: 63.28%] [G loss: 0.923872]\n",
      "epoch:24 step:22828 [D loss: 0.598801, acc.: 69.53%] [G loss: 0.948144]\n",
      "epoch:24 step:22829 [D loss: 0.466994, acc.: 82.03%] [G loss: 1.243567]\n",
      "epoch:24 step:22830 [D loss: 0.332790, acc.: 89.06%] [G loss: 1.094423]\n",
      "epoch:24 step:22831 [D loss: 0.244713, acc.: 91.41%] [G loss: 1.643041]\n",
      "epoch:24 step:22832 [D loss: 0.361018, acc.: 92.19%] [G loss: 1.305038]\n",
      "epoch:24 step:22833 [D loss: 0.258201, acc.: 95.31%] [G loss: 1.546188]\n",
      "epoch:24 step:22834 [D loss: 0.193404, acc.: 98.44%] [G loss: 2.161089]\n",
      "epoch:24 step:22835 [D loss: 0.192022, acc.: 98.44%] [G loss: 1.756948]\n",
      "epoch:24 step:22836 [D loss: 0.915627, acc.: 42.97%] [G loss: 1.042961]\n",
      "epoch:24 step:22837 [D loss: 0.878536, acc.: 42.19%] [G loss: 1.140551]\n",
      "epoch:24 step:22838 [D loss: 0.629827, acc.: 66.41%] [G loss: 1.362190]\n",
      "epoch:24 step:22839 [D loss: 0.592851, acc.: 73.44%] [G loss: 0.788520]\n",
      "epoch:24 step:22840 [D loss: 0.494676, acc.: 82.03%] [G loss: 1.132168]\n",
      "epoch:24 step:22841 [D loss: 0.518719, acc.: 77.34%] [G loss: 1.246953]\n",
      "epoch:24 step:22842 [D loss: 0.407260, acc.: 86.72%] [G loss: 1.350799]\n",
      "epoch:24 step:22843 [D loss: 0.647951, acc.: 66.41%] [G loss: 1.039906]\n",
      "epoch:24 step:22844 [D loss: 0.540309, acc.: 71.88%] [G loss: 0.871156]\n",
      "epoch:24 step:22845 [D loss: 0.473123, acc.: 84.38%] [G loss: 1.269655]\n",
      "epoch:24 step:22846 [D loss: 0.384182, acc.: 90.62%] [G loss: 1.304770]\n",
      "epoch:24 step:22847 [D loss: 0.308129, acc.: 92.19%] [G loss: 1.402393]\n",
      "epoch:24 step:22848 [D loss: 0.383624, acc.: 91.41%] [G loss: 1.302724]\n",
      "epoch:24 step:22849 [D loss: 0.429763, acc.: 89.84%] [G loss: 1.275574]\n",
      "epoch:24 step:22850 [D loss: 0.649806, acc.: 59.38%] [G loss: 1.013130]\n",
      "epoch:24 step:22851 [D loss: 0.657634, acc.: 62.50%] [G loss: 1.063107]\n",
      "epoch:24 step:22852 [D loss: 0.750779, acc.: 48.44%] [G loss: 1.124722]\n",
      "epoch:24 step:22853 [D loss: 0.817631, acc.: 45.31%] [G loss: 1.053685]\n",
      "epoch:24 step:22854 [D loss: 0.623114, acc.: 62.50%] [G loss: 1.005411]\n",
      "epoch:24 step:22855 [D loss: 0.560334, acc.: 71.09%] [G loss: 1.324262]\n",
      "epoch:24 step:22856 [D loss: 0.706226, acc.: 60.94%] [G loss: 0.936487]\n",
      "epoch:24 step:22857 [D loss: 0.389838, acc.: 92.19%] [G loss: 1.409168]\n",
      "epoch:24 step:22858 [D loss: 0.458385, acc.: 85.16%] [G loss: 1.085347]\n",
      "epoch:24 step:22859 [D loss: 0.395680, acc.: 89.84%] [G loss: 1.270916]\n",
      "epoch:24 step:22860 [D loss: 0.630072, acc.: 64.06%] [G loss: 1.416523]\n",
      "epoch:24 step:22861 [D loss: 0.732060, acc.: 50.78%] [G loss: 1.184082]\n",
      "epoch:24 step:22862 [D loss: 0.710483, acc.: 57.81%] [G loss: 0.736843]\n",
      "epoch:24 step:22863 [D loss: 0.684245, acc.: 56.25%] [G loss: 0.998110]\n",
      "epoch:24 step:22864 [D loss: 0.801689, acc.: 42.19%] [G loss: 0.841128]\n",
      "epoch:24 step:22865 [D loss: 0.794329, acc.: 46.88%] [G loss: 0.930690]\n",
      "epoch:24 step:22866 [D loss: 0.572673, acc.: 68.75%] [G loss: 1.218791]\n",
      "epoch:24 step:22867 [D loss: 0.516483, acc.: 79.69%] [G loss: 1.340895]\n",
      "epoch:24 step:22868 [D loss: 0.388236, acc.: 84.38%] [G loss: 1.487478]\n",
      "epoch:24 step:22869 [D loss: 0.408379, acc.: 85.94%] [G loss: 1.433871]\n",
      "epoch:24 step:22870 [D loss: 0.700962, acc.: 55.47%] [G loss: 1.139142]\n",
      "epoch:24 step:22871 [D loss: 0.703212, acc.: 56.25%] [G loss: 1.092968]\n",
      "epoch:24 step:22872 [D loss: 0.658904, acc.: 58.59%] [G loss: 1.198207]\n",
      "epoch:24 step:22873 [D loss: 0.485074, acc.: 78.91%] [G loss: 1.183715]\n",
      "epoch:24 step:22874 [D loss: 0.612012, acc.: 66.41%] [G loss: 1.192887]\n",
      "epoch:24 step:22875 [D loss: 0.564742, acc.: 65.62%] [G loss: 0.956476]\n",
      "epoch:24 step:22876 [D loss: 0.612384, acc.: 59.38%] [G loss: 1.246610]\n",
      "epoch:24 step:22877 [D loss: 0.669803, acc.: 64.06%] [G loss: 1.023033]\n",
      "epoch:24 step:22878 [D loss: 0.424955, acc.: 86.72%] [G loss: 1.389120]\n",
      "epoch:24 step:22879 [D loss: 0.533280, acc.: 78.12%] [G loss: 1.003641]\n",
      "epoch:24 step:22880 [D loss: 0.527676, acc.: 77.34%] [G loss: 1.536438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22881 [D loss: 0.738685, acc.: 52.34%] [G loss: 1.049718]\n",
      "epoch:24 step:22882 [D loss: 0.495581, acc.: 76.56%] [G loss: 1.209952]\n",
      "epoch:24 step:22883 [D loss: 0.620634, acc.: 69.53%] [G loss: 1.267180]\n",
      "epoch:24 step:22884 [D loss: 0.328273, acc.: 89.06%] [G loss: 1.359801]\n",
      "epoch:24 step:22885 [D loss: 0.168231, acc.: 98.44%] [G loss: 1.832779]\n",
      "epoch:24 step:22886 [D loss: 0.151378, acc.: 99.22%] [G loss: 2.134131]\n",
      "epoch:24 step:22887 [D loss: 0.260758, acc.: 96.09%] [G loss: 1.879335]\n",
      "epoch:24 step:22888 [D loss: 0.353355, acc.: 89.06%] [G loss: 1.748109]\n",
      "epoch:24 step:22889 [D loss: 0.280587, acc.: 93.75%] [G loss: 1.899778]\n",
      "epoch:24 step:22890 [D loss: 0.445405, acc.: 78.91%] [G loss: 1.515914]\n",
      "epoch:24 step:22891 [D loss: 0.496098, acc.: 78.12%] [G loss: 1.624426]\n",
      "epoch:24 step:22892 [D loss: 0.219565, acc.: 96.09%] [G loss: 1.877939]\n",
      "epoch:24 step:22893 [D loss: 0.267994, acc.: 92.19%] [G loss: 1.592810]\n",
      "epoch:24 step:22894 [D loss: 0.293450, acc.: 95.31%] [G loss: 2.035944]\n",
      "epoch:24 step:22895 [D loss: 0.387532, acc.: 85.94%] [G loss: 1.688038]\n",
      "epoch:24 step:22896 [D loss: 0.466673, acc.: 83.59%] [G loss: 1.426361]\n",
      "epoch:24 step:22897 [D loss: 0.816933, acc.: 50.78%] [G loss: 0.792783]\n",
      "epoch:24 step:22898 [D loss: 0.657127, acc.: 64.84%] [G loss: 1.098751]\n",
      "epoch:24 step:22899 [D loss: 0.908088, acc.: 49.22%] [G loss: 1.445253]\n",
      "epoch:24 step:22900 [D loss: 0.992764, acc.: 33.59%] [G loss: 0.666873]\n",
      "epoch:24 step:22901 [D loss: 0.900073, acc.: 48.44%] [G loss: 0.560707]\n",
      "epoch:24 step:22902 [D loss: 0.607818, acc.: 70.31%] [G loss: 0.822070]\n",
      "epoch:24 step:22903 [D loss: 1.060344, acc.: 27.34%] [G loss: 1.097127]\n",
      "epoch:24 step:22904 [D loss: 0.745192, acc.: 53.12%] [G loss: 0.973745]\n",
      "epoch:24 step:22905 [D loss: 0.991256, acc.: 27.34%] [G loss: 1.005290]\n",
      "epoch:24 step:22906 [D loss: 0.577339, acc.: 75.78%] [G loss: 1.189787]\n",
      "epoch:24 step:22907 [D loss: 0.529930, acc.: 72.66%] [G loss: 1.303830]\n",
      "epoch:24 step:22908 [D loss: 0.629054, acc.: 62.50%] [G loss: 1.392347]\n",
      "epoch:24 step:22909 [D loss: 0.883261, acc.: 46.09%] [G loss: 1.175530]\n",
      "epoch:24 step:22910 [D loss: 0.809375, acc.: 46.09%] [G loss: 1.386366]\n",
      "epoch:24 step:22911 [D loss: 0.662480, acc.: 60.94%] [G loss: 1.343369]\n",
      "epoch:24 step:22912 [D loss: 0.613403, acc.: 64.06%] [G loss: 1.057811]\n",
      "epoch:24 step:22913 [D loss: 0.588519, acc.: 68.75%] [G loss: 1.098638]\n",
      "epoch:24 step:22914 [D loss: 0.739090, acc.: 49.22%] [G loss: 1.125549]\n",
      "epoch:24 step:22915 [D loss: 0.876355, acc.: 41.41%] [G loss: 1.170677]\n",
      "epoch:24 step:22916 [D loss: 0.605378, acc.: 64.84%] [G loss: 1.344994]\n",
      "epoch:24 step:22917 [D loss: 0.578086, acc.: 65.62%] [G loss: 1.662778]\n",
      "epoch:24 step:22918 [D loss: 0.597112, acc.: 65.62%] [G loss: 1.375474]\n",
      "epoch:24 step:22919 [D loss: 0.664877, acc.: 58.59%] [G loss: 1.193545]\n",
      "epoch:24 step:22920 [D loss: 0.596938, acc.: 63.28%] [G loss: 1.559081]\n",
      "epoch:24 step:22921 [D loss: 0.555894, acc.: 68.75%] [G loss: 1.225309]\n",
      "epoch:24 step:22922 [D loss: 0.565363, acc.: 67.97%] [G loss: 1.241692]\n",
      "epoch:24 step:22923 [D loss: 0.664369, acc.: 59.38%] [G loss: 1.061646]\n",
      "epoch:24 step:22924 [D loss: 0.497607, acc.: 76.56%] [G loss: 1.127472]\n",
      "epoch:24 step:22925 [D loss: 0.847320, acc.: 46.88%] [G loss: 1.321066]\n",
      "epoch:24 step:22926 [D loss: 0.616830, acc.: 67.19%] [G loss: 1.211584]\n",
      "epoch:24 step:22927 [D loss: 0.742730, acc.: 51.56%] [G loss: 1.236892]\n",
      "epoch:24 step:22928 [D loss: 0.621055, acc.: 64.84%] [G loss: 1.151171]\n",
      "epoch:24 step:22929 [D loss: 0.655534, acc.: 62.50%] [G loss: 1.112690]\n",
      "epoch:24 step:22930 [D loss: 0.810554, acc.: 50.00%] [G loss: 1.116457]\n",
      "epoch:24 step:22931 [D loss: 0.531791, acc.: 73.44%] [G loss: 1.535162]\n",
      "epoch:24 step:22932 [D loss: 0.609148, acc.: 63.28%] [G loss: 1.100384]\n",
      "epoch:24 step:22933 [D loss: 0.640008, acc.: 59.38%] [G loss: 1.027921]\n",
      "epoch:24 step:22934 [D loss: 0.647094, acc.: 67.19%] [G loss: 0.993123]\n",
      "epoch:24 step:22935 [D loss: 0.614582, acc.: 69.53%] [G loss: 1.275813]\n",
      "epoch:24 step:22936 [D loss: 0.471602, acc.: 81.25%] [G loss: 1.609885]\n",
      "epoch:24 step:22937 [D loss: 0.346481, acc.: 90.62%] [G loss: 1.650574]\n",
      "epoch:24 step:22938 [D loss: 0.510346, acc.: 71.88%] [G loss: 1.275193]\n",
      "epoch:24 step:22939 [D loss: 0.577120, acc.: 67.97%] [G loss: 1.308740]\n",
      "epoch:24 step:22940 [D loss: 0.391166, acc.: 85.94%] [G loss: 1.528774]\n",
      "epoch:24 step:22941 [D loss: 0.461905, acc.: 83.59%] [G loss: 1.407766]\n",
      "epoch:24 step:22942 [D loss: 0.379612, acc.: 89.84%] [G loss: 1.868049]\n",
      "epoch:24 step:22943 [D loss: 0.731842, acc.: 53.12%] [G loss: 0.971867]\n",
      "epoch:24 step:22944 [D loss: 0.558032, acc.: 67.19%] [G loss: 1.103210]\n",
      "epoch:24 step:22945 [D loss: 0.391471, acc.: 83.59%] [G loss: 1.599858]\n",
      "epoch:24 step:22946 [D loss: 1.109341, acc.: 25.00%] [G loss: 0.744599]\n",
      "epoch:24 step:22947 [D loss: 0.747807, acc.: 53.91%] [G loss: 1.147424]\n",
      "epoch:24 step:22948 [D loss: 0.903608, acc.: 32.03%] [G loss: 0.890609]\n",
      "epoch:24 step:22949 [D loss: 0.940199, acc.: 32.81%] [G loss: 0.973319]\n",
      "epoch:24 step:22950 [D loss: 1.023000, acc.: 25.78%] [G loss: 0.948497]\n",
      "epoch:24 step:22951 [D loss: 0.745373, acc.: 49.22%] [G loss: 1.067694]\n",
      "epoch:24 step:22952 [D loss: 0.595184, acc.: 66.41%] [G loss: 1.123523]\n",
      "epoch:24 step:22953 [D loss: 0.563759, acc.: 66.41%] [G loss: 1.223580]\n",
      "epoch:24 step:22954 [D loss: 0.660596, acc.: 65.62%] [G loss: 0.981016]\n",
      "epoch:24 step:22955 [D loss: 0.619190, acc.: 67.19%] [G loss: 1.174333]\n",
      "epoch:24 step:22956 [D loss: 0.551275, acc.: 73.44%] [G loss: 1.237982]\n",
      "epoch:24 step:22957 [D loss: 0.545784, acc.: 69.53%] [G loss: 1.330912]\n",
      "epoch:24 step:22958 [D loss: 0.401030, acc.: 86.72%] [G loss: 1.523935]\n",
      "epoch:24 step:22959 [D loss: 0.262593, acc.: 96.09%] [G loss: 1.506294]\n",
      "epoch:24 step:22960 [D loss: 0.566058, acc.: 73.44%] [G loss: 1.857138]\n",
      "epoch:24 step:22961 [D loss: 1.042312, acc.: 37.50%] [G loss: 1.394947]\n",
      "epoch:24 step:22962 [D loss: 0.572503, acc.: 67.97%] [G loss: 1.451148]\n",
      "epoch:24 step:22963 [D loss: 0.571795, acc.: 71.88%] [G loss: 1.703798]\n",
      "epoch:24 step:22964 [D loss: 0.730778, acc.: 60.94%] [G loss: 1.412885]\n",
      "epoch:24 step:22965 [D loss: 0.766422, acc.: 46.88%] [G loss: 1.095070]\n",
      "epoch:24 step:22966 [D loss: 0.631066, acc.: 61.72%] [G loss: 1.262759]\n",
      "epoch:24 step:22967 [D loss: 0.647181, acc.: 61.72%] [G loss: 0.795800]\n",
      "epoch:24 step:22968 [D loss: 0.577380, acc.: 67.97%] [G loss: 0.956618]\n",
      "epoch:24 step:22969 [D loss: 0.468756, acc.: 80.47%] [G loss: 1.147141]\n",
      "epoch:24 step:22970 [D loss: 0.485941, acc.: 78.12%] [G loss: 1.254408]\n",
      "epoch:24 step:22971 [D loss: 0.331837, acc.: 92.19%] [G loss: 1.072416]\n",
      "epoch:24 step:22972 [D loss: 0.264397, acc.: 96.09%] [G loss: 1.428316]\n",
      "epoch:24 step:22973 [D loss: 0.385417, acc.: 90.62%] [G loss: 1.625806]\n",
      "epoch:24 step:22974 [D loss: 0.534977, acc.: 71.88%] [G loss: 1.215770]\n",
      "epoch:24 step:22975 [D loss: 0.399275, acc.: 84.38%] [G loss: 1.090696]\n",
      "epoch:24 step:22976 [D loss: 0.599918, acc.: 67.97%] [G loss: 1.100010]\n",
      "epoch:24 step:22977 [D loss: 0.545843, acc.: 67.97%] [G loss: 1.239181]\n",
      "epoch:24 step:22978 [D loss: 0.592490, acc.: 67.19%] [G loss: 1.187438]\n",
      "epoch:24 step:22979 [D loss: 0.623448, acc.: 62.50%] [G loss: 1.200853]\n",
      "epoch:24 step:22980 [D loss: 0.796832, acc.: 41.41%] [G loss: 0.994961]\n",
      "epoch:24 step:22981 [D loss: 0.792266, acc.: 49.22%] [G loss: 1.064210]\n",
      "epoch:24 step:22982 [D loss: 0.714243, acc.: 55.47%] [G loss: 1.001695]\n",
      "epoch:24 step:22983 [D loss: 0.626291, acc.: 64.84%] [G loss: 0.866791]\n",
      "epoch:24 step:22984 [D loss: 0.557880, acc.: 74.22%] [G loss: 1.253121]\n",
      "epoch:24 step:22985 [D loss: 0.345218, acc.: 90.62%] [G loss: 1.382583]\n",
      "epoch:24 step:22986 [D loss: 0.296755, acc.: 95.31%] [G loss: 1.569707]\n",
      "epoch:24 step:22987 [D loss: 0.269076, acc.: 95.31%] [G loss: 1.672158]\n",
      "epoch:24 step:22988 [D loss: 0.811192, acc.: 51.56%] [G loss: 1.412755]\n",
      "epoch:24 step:22989 [D loss: 0.571164, acc.: 71.09%] [G loss: 1.323529]\n",
      "epoch:24 step:22990 [D loss: 0.686990, acc.: 58.59%] [G loss: 1.089928]\n",
      "epoch:24 step:22991 [D loss: 0.451826, acc.: 82.03%] [G loss: 1.004226]\n",
      "epoch:24 step:22992 [D loss: 0.439732, acc.: 78.12%] [G loss: 1.294836]\n",
      "epoch:24 step:22993 [D loss: 0.515173, acc.: 71.88%] [G loss: 1.446484]\n",
      "epoch:24 step:22994 [D loss: 0.613016, acc.: 67.19%] [G loss: 1.216801]\n",
      "epoch:24 step:22995 [D loss: 0.381495, acc.: 92.19%] [G loss: 1.392141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22996 [D loss: 0.284715, acc.: 95.31%] [G loss: 1.419122]\n",
      "epoch:24 step:22997 [D loss: 0.680483, acc.: 62.50%] [G loss: 1.287069]\n",
      "epoch:24 step:22998 [D loss: 0.698890, acc.: 57.03%] [G loss: 1.022603]\n",
      "epoch:24 step:22999 [D loss: 0.615762, acc.: 63.28%] [G loss: 0.832461]\n",
      "epoch:24 step:23000 [D loss: 0.592670, acc.: 70.31%] [G loss: 1.158777]\n",
      "epoch:24 step:23001 [D loss: 0.403736, acc.: 84.38%] [G loss: 1.273864]\n",
      "epoch:24 step:23002 [D loss: 0.540379, acc.: 78.12%] [G loss: 1.608388]\n",
      "epoch:24 step:23003 [D loss: 0.477527, acc.: 82.03%] [G loss: 1.199747]\n",
      "epoch:24 step:23004 [D loss: 0.647281, acc.: 60.94%] [G loss: 1.606728]\n",
      "epoch:24 step:23005 [D loss: 0.519592, acc.: 75.78%] [G loss: 1.276012]\n",
      "epoch:24 step:23006 [D loss: 0.542111, acc.: 77.34%] [G loss: 1.099808]\n",
      "epoch:24 step:23007 [D loss: 0.336412, acc.: 93.75%] [G loss: 1.340974]\n",
      "epoch:24 step:23008 [D loss: 0.474710, acc.: 81.25%] [G loss: 1.323231]\n",
      "epoch:24 step:23009 [D loss: 0.490759, acc.: 80.47%] [G loss: 1.357717]\n",
      "epoch:24 step:23010 [D loss: 0.322763, acc.: 95.31%] [G loss: 1.287008]\n",
      "epoch:24 step:23011 [D loss: 0.441384, acc.: 87.50%] [G loss: 1.518622]\n",
      "epoch:24 step:23012 [D loss: 0.776818, acc.: 53.91%] [G loss: 1.446627]\n",
      "epoch:24 step:23013 [D loss: 0.667803, acc.: 61.72%] [G loss: 1.108963]\n",
      "epoch:24 step:23014 [D loss: 0.539992, acc.: 76.56%] [G loss: 1.061220]\n",
      "epoch:24 step:23015 [D loss: 0.681812, acc.: 53.91%] [G loss: 1.210438]\n",
      "epoch:24 step:23016 [D loss: 0.789528, acc.: 45.31%] [G loss: 0.737415]\n",
      "epoch:24 step:23017 [D loss: 0.702838, acc.: 54.69%] [G loss: 1.305010]\n",
      "epoch:24 step:23018 [D loss: 0.697476, acc.: 51.56%] [G loss: 0.810305]\n",
      "epoch:24 step:23019 [D loss: 0.609412, acc.: 66.41%] [G loss: 1.323116]\n",
      "epoch:24 step:23020 [D loss: 0.492165, acc.: 78.12%] [G loss: 1.037236]\n",
      "epoch:24 step:23021 [D loss: 0.217591, acc.: 97.66%] [G loss: 1.800272]\n",
      "epoch:24 step:23022 [D loss: 0.473929, acc.: 81.25%] [G loss: 1.415917]\n",
      "epoch:24 step:23023 [D loss: 0.451562, acc.: 81.25%] [G loss: 1.338024]\n",
      "epoch:24 step:23024 [D loss: 0.574347, acc.: 65.62%] [G loss: 1.114993]\n",
      "epoch:24 step:23025 [D loss: 0.391458, acc.: 90.62%] [G loss: 1.280680]\n",
      "epoch:24 step:23026 [D loss: 0.728109, acc.: 53.12%] [G loss: 1.234550]\n",
      "epoch:24 step:23027 [D loss: 0.710912, acc.: 57.81%] [G loss: 1.091310]\n",
      "epoch:24 step:23028 [D loss: 0.780761, acc.: 52.34%] [G loss: 0.598621]\n",
      "epoch:24 step:23029 [D loss: 0.641372, acc.: 57.81%] [G loss: 1.115817]\n",
      "epoch:24 step:23030 [D loss: 0.772944, acc.: 46.88%] [G loss: 1.083791]\n",
      "epoch:24 step:23031 [D loss: 0.537808, acc.: 72.66%] [G loss: 1.360261]\n",
      "epoch:24 step:23032 [D loss: 0.398797, acc.: 89.84%] [G loss: 1.296047]\n",
      "epoch:24 step:23033 [D loss: 0.421358, acc.: 87.50%] [G loss: 1.380419]\n",
      "epoch:24 step:23034 [D loss: 0.295470, acc.: 97.66%] [G loss: 1.402096]\n",
      "epoch:24 step:23035 [D loss: 0.353168, acc.: 89.84%] [G loss: 1.244288]\n",
      "epoch:24 step:23036 [D loss: 0.498230, acc.: 78.12%] [G loss: 0.998338]\n",
      "epoch:24 step:23037 [D loss: 0.278263, acc.: 96.09%] [G loss: 1.700448]\n",
      "epoch:24 step:23038 [D loss: 0.339490, acc.: 92.19%] [G loss: 1.666678]\n",
      "epoch:24 step:23039 [D loss: 0.197949, acc.: 96.09%] [G loss: 1.823010]\n",
      "epoch:24 step:23040 [D loss: 0.298896, acc.: 92.97%] [G loss: 1.715674]\n",
      "epoch:24 step:23041 [D loss: 0.373149, acc.: 92.97%] [G loss: 1.377280]\n",
      "epoch:24 step:23042 [D loss: 0.195045, acc.: 97.66%] [G loss: 1.558521]\n",
      "epoch:24 step:23043 [D loss: 0.277204, acc.: 95.31%] [G loss: 1.568867]\n",
      "epoch:24 step:23044 [D loss: 0.205564, acc.: 96.88%] [G loss: 1.756386]\n",
      "epoch:24 step:23045 [D loss: 0.207384, acc.: 98.44%] [G loss: 1.666030]\n",
      "epoch:24 step:23046 [D loss: 0.341126, acc.: 93.75%] [G loss: 1.732480]\n",
      "epoch:24 step:23047 [D loss: 0.991621, acc.: 38.28%] [G loss: 1.313956]\n",
      "epoch:24 step:23048 [D loss: 0.955809, acc.: 45.31%] [G loss: 1.365876]\n",
      "epoch:24 step:23049 [D loss: 0.398622, acc.: 84.38%] [G loss: 1.334802]\n",
      "epoch:24 step:23050 [D loss: 0.840201, acc.: 46.88%] [G loss: 1.219459]\n",
      "epoch:24 step:23051 [D loss: 0.581473, acc.: 71.88%] [G loss: 1.112949]\n",
      "epoch:24 step:23052 [D loss: 0.554234, acc.: 77.34%] [G loss: 1.236251]\n",
      "epoch:24 step:23053 [D loss: 0.596437, acc.: 71.09%] [G loss: 0.988270]\n",
      "epoch:24 step:23054 [D loss: 0.439712, acc.: 83.59%] [G loss: 1.243164]\n",
      "epoch:24 step:23055 [D loss: 0.325105, acc.: 92.19%] [G loss: 1.614137]\n",
      "epoch:24 step:23056 [D loss: 0.641216, acc.: 63.28%] [G loss: 1.338826]\n",
      "epoch:24 step:23057 [D loss: 0.765347, acc.: 51.56%] [G loss: 1.253715]\n",
      "epoch:24 step:23058 [D loss: 0.631643, acc.: 65.62%] [G loss: 1.127870]\n",
      "epoch:24 step:23059 [D loss: 0.468257, acc.: 83.59%] [G loss: 1.206511]\n",
      "epoch:24 step:23060 [D loss: 0.656597, acc.: 61.72%] [G loss: 0.943093]\n",
      "epoch:24 step:23061 [D loss: 0.393146, acc.: 92.19%] [G loss: 1.607430]\n",
      "epoch:24 step:23062 [D loss: 0.513875, acc.: 73.44%] [G loss: 1.017524]\n",
      "epoch:24 step:23063 [D loss: 0.449391, acc.: 83.59%] [G loss: 1.290183]\n",
      "epoch:24 step:23064 [D loss: 0.411323, acc.: 83.59%] [G loss: 1.293337]\n",
      "epoch:24 step:23065 [D loss: 0.402561, acc.: 84.38%] [G loss: 1.701294]\n",
      "epoch:24 step:23066 [D loss: 0.277209, acc.: 95.31%] [G loss: 1.496030]\n",
      "epoch:24 step:23067 [D loss: 0.334110, acc.: 89.84%] [G loss: 1.513986]\n",
      "epoch:24 step:23068 [D loss: 0.562256, acc.: 68.75%] [G loss: 1.575481]\n",
      "epoch:24 step:23069 [D loss: 0.359762, acc.: 88.28%] [G loss: 1.118905]\n",
      "epoch:24 step:23070 [D loss: 0.863829, acc.: 38.28%] [G loss: 0.729371]\n",
      "epoch:24 step:23071 [D loss: 0.560193, acc.: 68.75%] [G loss: 1.073893]\n",
      "epoch:24 step:23072 [D loss: 0.510511, acc.: 77.34%] [G loss: 1.052945]\n",
      "epoch:24 step:23073 [D loss: 0.877840, acc.: 47.66%] [G loss: 0.737576]\n",
      "epoch:24 step:23074 [D loss: 0.636625, acc.: 60.94%] [G loss: 0.811664]\n",
      "epoch:24 step:23075 [D loss: 0.654478, acc.: 60.94%] [G loss: 0.823381]\n",
      "epoch:24 step:23076 [D loss: 0.312749, acc.: 89.06%] [G loss: 1.297844]\n",
      "epoch:24 step:23077 [D loss: 0.348800, acc.: 89.06%] [G loss: 1.759595]\n",
      "epoch:24 step:23078 [D loss: 0.904741, acc.: 41.41%] [G loss: 1.511476]\n",
      "epoch:24 step:23079 [D loss: 1.064362, acc.: 31.25%] [G loss: 1.122113]\n",
      "epoch:24 step:23080 [D loss: 0.588885, acc.: 69.53%] [G loss: 1.549254]\n",
      "epoch:24 step:23081 [D loss: 0.757837, acc.: 50.78%] [G loss: 1.316420]\n",
      "epoch:24 step:23082 [D loss: 0.569861, acc.: 71.09%] [G loss: 1.369844]\n",
      "epoch:24 step:23083 [D loss: 0.506505, acc.: 81.25%] [G loss: 1.383139]\n",
      "epoch:24 step:23084 [D loss: 0.596276, acc.: 67.19%] [G loss: 1.584800]\n",
      "epoch:24 step:23085 [D loss: 0.443713, acc.: 82.03%] [G loss: 1.384436]\n",
      "epoch:24 step:23086 [D loss: 0.253851, acc.: 93.75%] [G loss: 1.715817]\n",
      "epoch:24 step:23087 [D loss: 0.436347, acc.: 82.03%] [G loss: 1.286380]\n",
      "epoch:24 step:23088 [D loss: 0.438543, acc.: 81.25%] [G loss: 1.313982]\n",
      "epoch:24 step:23089 [D loss: 0.596156, acc.: 70.31%] [G loss: 0.811106]\n",
      "epoch:24 step:23090 [D loss: 0.525182, acc.: 75.78%] [G loss: 0.929123]\n",
      "epoch:24 step:23091 [D loss: 0.430822, acc.: 77.34%] [G loss: 0.864809]\n",
      "epoch:24 step:23092 [D loss: 0.325426, acc.: 86.72%] [G loss: 1.259004]\n",
      "epoch:24 step:23093 [D loss: 0.350113, acc.: 90.62%] [G loss: 1.171069]\n",
      "epoch:24 step:23094 [D loss: 0.622687, acc.: 64.84%] [G loss: 1.275183]\n",
      "epoch:24 step:23095 [D loss: 0.616155, acc.: 64.84%] [G loss: 1.381181]\n",
      "epoch:24 step:23096 [D loss: 0.621778, acc.: 65.62%] [G loss: 1.111337]\n",
      "epoch:24 step:23097 [D loss: 0.632059, acc.: 62.50%] [G loss: 1.276099]\n",
      "epoch:24 step:23098 [D loss: 0.518186, acc.: 71.88%] [G loss: 1.204211]\n",
      "epoch:24 step:23099 [D loss: 0.850120, acc.: 42.19%] [G loss: 1.486295]\n",
      "epoch:24 step:23100 [D loss: 0.692501, acc.: 53.12%] [G loss: 1.360178]\n",
      "epoch:24 step:23101 [D loss: 0.368914, acc.: 87.50%] [G loss: 1.269027]\n",
      "epoch:24 step:23102 [D loss: 0.355437, acc.: 88.28%] [G loss: 1.521810]\n",
      "epoch:24 step:23103 [D loss: 0.233508, acc.: 96.09%] [G loss: 1.598963]\n",
      "epoch:24 step:23104 [D loss: 0.278988, acc.: 92.19%] [G loss: 1.866636]\n",
      "epoch:24 step:23105 [D loss: 0.417696, acc.: 85.16%] [G loss: 1.454881]\n",
      "epoch:24 step:23106 [D loss: 0.815653, acc.: 50.78%] [G loss: 1.036414]\n",
      "epoch:24 step:23107 [D loss: 0.665682, acc.: 54.69%] [G loss: 1.182576]\n",
      "epoch:24 step:23108 [D loss: 1.036444, acc.: 28.91%] [G loss: 0.709041]\n",
      "epoch:24 step:23109 [D loss: 0.899274, acc.: 35.16%] [G loss: 0.908502]\n",
      "epoch:24 step:23110 [D loss: 0.662552, acc.: 67.19%] [G loss: 1.137203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23111 [D loss: 0.654435, acc.: 59.38%] [G loss: 1.449734]\n",
      "epoch:24 step:23112 [D loss: 0.501661, acc.: 77.34%] [G loss: 1.400755]\n",
      "epoch:24 step:23113 [D loss: 0.586974, acc.: 64.84%] [G loss: 1.698133]\n",
      "epoch:24 step:23114 [D loss: 0.863033, acc.: 42.19%] [G loss: 0.694081]\n",
      "epoch:24 step:23115 [D loss: 0.988588, acc.: 36.72%] [G loss: 0.808169]\n",
      "epoch:24 step:23116 [D loss: 0.885300, acc.: 39.06%] [G loss: 1.110923]\n",
      "epoch:24 step:23117 [D loss: 0.224904, acc.: 95.31%] [G loss: 1.335144]\n",
      "epoch:24 step:23118 [D loss: 0.729400, acc.: 55.47%] [G loss: 1.066174]\n",
      "epoch:24 step:23119 [D loss: 0.780583, acc.: 49.22%] [G loss: 1.178728]\n",
      "epoch:24 step:23120 [D loss: 0.905333, acc.: 39.84%] [G loss: 0.781865]\n",
      "epoch:24 step:23121 [D loss: 0.456344, acc.: 82.03%] [G loss: 1.399031]\n",
      "epoch:24 step:23122 [D loss: 0.652150, acc.: 66.41%] [G loss: 1.440618]\n",
      "epoch:24 step:23123 [D loss: 0.745156, acc.: 50.78%] [G loss: 1.103268]\n",
      "epoch:24 step:23124 [D loss: 0.841158, acc.: 41.41%] [G loss: 1.056392]\n",
      "epoch:24 step:23125 [D loss: 0.774182, acc.: 47.66%] [G loss: 1.367225]\n",
      "epoch:24 step:23126 [D loss: 0.572917, acc.: 69.53%] [G loss: 0.942225]\n",
      "epoch:24 step:23127 [D loss: 1.250948, acc.: 17.19%] [G loss: 0.755867]\n",
      "epoch:24 step:23128 [D loss: 0.395522, acc.: 89.06%] [G loss: 1.575021]\n",
      "epoch:24 step:23129 [D loss: 0.366596, acc.: 89.84%] [G loss: 1.502241]\n",
      "epoch:24 step:23130 [D loss: 0.662557, acc.: 60.16%] [G loss: 1.294708]\n",
      "epoch:24 step:23131 [D loss: 0.773165, acc.: 57.03%] [G loss: 1.806893]\n",
      "epoch:24 step:23132 [D loss: 0.728581, acc.: 55.47%] [G loss: 1.378005]\n",
      "epoch:24 step:23133 [D loss: 0.436593, acc.: 84.38%] [G loss: 1.175002]\n",
      "epoch:24 step:23134 [D loss: 0.478958, acc.: 80.47%] [G loss: 1.175360]\n",
      "epoch:24 step:23135 [D loss: 0.392392, acc.: 89.06%] [G loss: 1.408441]\n",
      "epoch:24 step:23136 [D loss: 0.507735, acc.: 76.56%] [G loss: 1.167983]\n",
      "epoch:24 step:23137 [D loss: 0.565049, acc.: 71.09%] [G loss: 0.957407]\n",
      "epoch:24 step:23138 [D loss: 0.628271, acc.: 64.84%] [G loss: 1.105121]\n",
      "epoch:24 step:23139 [D loss: 0.618098, acc.: 67.97%] [G loss: 1.356384]\n",
      "epoch:24 step:23140 [D loss: 0.534121, acc.: 75.00%] [G loss: 1.544303]\n",
      "epoch:24 step:23141 [D loss: 0.605920, acc.: 70.31%] [G loss: 1.223275]\n",
      "epoch:24 step:23142 [D loss: 0.330749, acc.: 90.62%] [G loss: 1.626299]\n",
      "epoch:24 step:23143 [D loss: 0.636488, acc.: 63.28%] [G loss: 1.195653]\n",
      "epoch:24 step:23144 [D loss: 0.361926, acc.: 89.84%] [G loss: 1.445850]\n",
      "epoch:24 step:23145 [D loss: 0.691264, acc.: 57.03%] [G loss: 1.146027]\n",
      "epoch:24 step:23146 [D loss: 0.452101, acc.: 83.59%] [G loss: 1.301936]\n",
      "epoch:24 step:23147 [D loss: 0.484547, acc.: 75.78%] [G loss: 1.484167]\n",
      "epoch:24 step:23148 [D loss: 0.667078, acc.: 60.94%] [G loss: 1.056112]\n",
      "epoch:24 step:23149 [D loss: 0.630016, acc.: 65.62%] [G loss: 0.954826]\n",
      "epoch:24 step:23150 [D loss: 0.427819, acc.: 84.38%] [G loss: 1.349306]\n",
      "epoch:24 step:23151 [D loss: 0.118883, acc.: 100.00%] [G loss: 2.085744]\n",
      "epoch:24 step:23152 [D loss: 0.154229, acc.: 99.22%] [G loss: 1.949740]\n",
      "epoch:24 step:23153 [D loss: 0.216257, acc.: 96.09%] [G loss: 2.275708]\n",
      "epoch:24 step:23154 [D loss: 0.280992, acc.: 94.53%] [G loss: 1.791216]\n",
      "epoch:24 step:23155 [D loss: 0.288974, acc.: 93.75%] [G loss: 1.721709]\n",
      "epoch:24 step:23156 [D loss: 0.498554, acc.: 71.09%] [G loss: 1.349144]\n",
      "epoch:24 step:23157 [D loss: 0.434665, acc.: 83.59%] [G loss: 1.103623]\n",
      "epoch:24 step:23158 [D loss: 0.459423, acc.: 81.25%] [G loss: 1.362947]\n",
      "epoch:24 step:23159 [D loss: 0.786809, acc.: 51.56%] [G loss: 1.271518]\n",
      "epoch:24 step:23160 [D loss: 0.772686, acc.: 50.00%] [G loss: 1.363997]\n",
      "epoch:24 step:23161 [D loss: 0.982979, acc.: 39.84%] [G loss: 1.048981]\n",
      "epoch:24 step:23162 [D loss: 1.273893, acc.: 31.25%] [G loss: 0.427561]\n",
      "epoch:24 step:23163 [D loss: 0.884685, acc.: 35.16%] [G loss: 0.918437]\n",
      "epoch:24 step:23164 [D loss: 0.685941, acc.: 56.25%] [G loss: 1.304705]\n",
      "epoch:24 step:23165 [D loss: 0.879041, acc.: 39.84%] [G loss: 0.647862]\n",
      "epoch:24 step:23166 [D loss: 0.773401, acc.: 47.66%] [G loss: 0.816067]\n",
      "epoch:24 step:23167 [D loss: 0.816736, acc.: 48.44%] [G loss: 1.123626]\n",
      "epoch:24 step:23168 [D loss: 0.973508, acc.: 32.81%] [G loss: 0.794511]\n",
      "epoch:24 step:23169 [D loss: 0.733922, acc.: 52.34%] [G loss: 1.022452]\n",
      "epoch:24 step:23170 [D loss: 0.643009, acc.: 62.50%] [G loss: 0.958460]\n",
      "epoch:24 step:23171 [D loss: 0.598432, acc.: 68.75%] [G loss: 1.260655]\n",
      "epoch:24 step:23172 [D loss: 0.885568, acc.: 39.84%] [G loss: 0.800026]\n",
      "epoch:24 step:23173 [D loss: 0.527204, acc.: 74.22%] [G loss: 1.585398]\n",
      "epoch:24 step:23174 [D loss: 0.667062, acc.: 61.72%] [G loss: 1.088457]\n",
      "epoch:24 step:23175 [D loss: 0.579775, acc.: 78.12%] [G loss: 1.149382]\n",
      "epoch:24 step:23176 [D loss: 0.696250, acc.: 60.94%] [G loss: 1.365731]\n",
      "epoch:24 step:23177 [D loss: 0.747488, acc.: 42.97%] [G loss: 1.158692]\n",
      "epoch:24 step:23178 [D loss: 0.398262, acc.: 89.84%] [G loss: 1.289446]\n",
      "epoch:24 step:23179 [D loss: 0.572811, acc.: 73.44%] [G loss: 1.296608]\n",
      "epoch:24 step:23180 [D loss: 0.623051, acc.: 62.50%] [G loss: 1.227221]\n",
      "epoch:24 step:23181 [D loss: 0.631282, acc.: 62.50%] [G loss: 1.056935]\n",
      "epoch:24 step:23182 [D loss: 0.379609, acc.: 87.50%] [G loss: 1.457513]\n",
      "epoch:24 step:23183 [D loss: 0.604136, acc.: 69.53%] [G loss: 1.070509]\n",
      "epoch:24 step:23184 [D loss: 0.712910, acc.: 54.69%] [G loss: 1.285487]\n",
      "epoch:24 step:23185 [D loss: 0.703018, acc.: 53.91%] [G loss: 0.934304]\n",
      "epoch:24 step:23186 [D loss: 0.662459, acc.: 62.50%] [G loss: 1.068230]\n",
      "epoch:24 step:23187 [D loss: 0.715842, acc.: 55.47%] [G loss: 0.988011]\n",
      "epoch:24 step:23188 [D loss: 0.624268, acc.: 61.72%] [G loss: 0.927334]\n",
      "epoch:24 step:23189 [D loss: 0.641049, acc.: 60.94%] [G loss: 1.145123]\n",
      "epoch:24 step:23190 [D loss: 0.496846, acc.: 81.25%] [G loss: 1.186350]\n",
      "epoch:24 step:23191 [D loss: 0.675180, acc.: 58.59%] [G loss: 1.080269]\n",
      "epoch:24 step:23192 [D loss: 0.667913, acc.: 57.81%] [G loss: 1.114568]\n",
      "epoch:24 step:23193 [D loss: 0.815513, acc.: 45.31%] [G loss: 0.850164]\n",
      "epoch:24 step:23194 [D loss: 0.486775, acc.: 81.25%] [G loss: 1.003867]\n",
      "epoch:24 step:23195 [D loss: 0.339287, acc.: 90.62%] [G loss: 1.257476]\n",
      "epoch:24 step:23196 [D loss: 0.393065, acc.: 92.97%] [G loss: 1.384870]\n",
      "epoch:24 step:23197 [D loss: 0.387956, acc.: 89.06%] [G loss: 1.459291]\n",
      "epoch:24 step:23198 [D loss: 0.830237, acc.: 43.75%] [G loss: 0.924160]\n",
      "epoch:24 step:23199 [D loss: 0.823567, acc.: 46.88%] [G loss: 1.193725]\n",
      "epoch:24 step:23200 [D loss: 0.630073, acc.: 66.41%] [G loss: 1.004151]\n",
      "epoch:24 step:23201 [D loss: 0.512021, acc.: 73.44%] [G loss: 1.351821]\n",
      "epoch:24 step:23202 [D loss: 0.545357, acc.: 75.78%] [G loss: 1.324559]\n",
      "epoch:24 step:23203 [D loss: 0.615844, acc.: 65.62%] [G loss: 1.293363]\n",
      "epoch:24 step:23204 [D loss: 0.898829, acc.: 42.19%] [G loss: 0.989407]\n",
      "epoch:24 step:23205 [D loss: 0.690254, acc.: 57.03%] [G loss: 0.905362]\n",
      "epoch:24 step:23206 [D loss: 0.715756, acc.: 53.91%] [G loss: 0.964629]\n",
      "epoch:24 step:23207 [D loss: 0.738361, acc.: 56.25%] [G loss: 0.889829]\n",
      "epoch:24 step:23208 [D loss: 0.557162, acc.: 74.22%] [G loss: 1.011566]\n",
      "epoch:24 step:23209 [D loss: 0.617450, acc.: 67.97%] [G loss: 0.988710]\n",
      "epoch:24 step:23210 [D loss: 0.691318, acc.: 54.69%] [G loss: 1.101254]\n",
      "epoch:24 step:23211 [D loss: 0.556147, acc.: 74.22%] [G loss: 0.950683]\n",
      "epoch:24 step:23212 [D loss: 0.378542, acc.: 88.28%] [G loss: 1.021807]\n",
      "epoch:24 step:23213 [D loss: 0.435199, acc.: 83.59%] [G loss: 1.196010]\n",
      "epoch:24 step:23214 [D loss: 0.603532, acc.: 64.84%] [G loss: 1.090927]\n",
      "epoch:24 step:23215 [D loss: 0.643006, acc.: 61.72%] [G loss: 1.323060]\n",
      "epoch:24 step:23216 [D loss: 0.557803, acc.: 74.22%] [G loss: 1.094272]\n",
      "epoch:24 step:23217 [D loss: 0.551447, acc.: 75.00%] [G loss: 1.184627]\n",
      "epoch:24 step:23218 [D loss: 0.602958, acc.: 68.75%] [G loss: 1.013862]\n",
      "epoch:24 step:23219 [D loss: 0.449864, acc.: 82.81%] [G loss: 1.163054]\n",
      "epoch:24 step:23220 [D loss: 0.632865, acc.: 64.84%] [G loss: 1.067846]\n",
      "epoch:24 step:23221 [D loss: 0.519708, acc.: 75.00%] [G loss: 1.270219]\n",
      "epoch:24 step:23222 [D loss: 0.826753, acc.: 54.69%] [G loss: 1.450026]\n",
      "epoch:24 step:23223 [D loss: 0.682681, acc.: 59.38%] [G loss: 1.160955]\n",
      "epoch:24 step:23224 [D loss: 0.727802, acc.: 52.34%] [G loss: 1.009286]\n",
      "epoch:24 step:23225 [D loss: 0.604876, acc.: 64.84%] [G loss: 0.971625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23226 [D loss: 0.706409, acc.: 56.25%] [G loss: 1.179937]\n",
      "epoch:24 step:23227 [D loss: 0.795421, acc.: 43.75%] [G loss: 0.805266]\n",
      "epoch:24 step:23228 [D loss: 0.637178, acc.: 64.06%] [G loss: 1.052977]\n",
      "epoch:24 step:23229 [D loss: 0.432853, acc.: 83.59%] [G loss: 1.368134]\n",
      "epoch:24 step:23230 [D loss: 0.437559, acc.: 85.94%] [G loss: 1.155426]\n",
      "epoch:24 step:23231 [D loss: 0.341658, acc.: 93.75%] [G loss: 1.476801]\n",
      "epoch:24 step:23232 [D loss: 0.716411, acc.: 60.94%] [G loss: 1.012357]\n",
      "epoch:24 step:23233 [D loss: 0.389817, acc.: 89.84%] [G loss: 1.323206]\n",
      "epoch:24 step:23234 [D loss: 0.561216, acc.: 71.09%] [G loss: 1.198850]\n",
      "epoch:24 step:23235 [D loss: 0.561947, acc.: 68.75%] [G loss: 1.054338]\n",
      "epoch:24 step:23236 [D loss: 0.582962, acc.: 70.31%] [G loss: 1.082501]\n",
      "epoch:24 step:23237 [D loss: 0.543109, acc.: 74.22%] [G loss: 1.180807]\n",
      "epoch:24 step:23238 [D loss: 0.493472, acc.: 82.03%] [G loss: 1.260757]\n",
      "epoch:24 step:23239 [D loss: 0.617797, acc.: 64.84%] [G loss: 1.089593]\n",
      "epoch:24 step:23240 [D loss: 0.734910, acc.: 45.31%] [G loss: 1.193003]\n",
      "epoch:24 step:23241 [D loss: 0.768533, acc.: 52.34%] [G loss: 1.043975]\n",
      "epoch:24 step:23242 [D loss: 0.669274, acc.: 58.59%] [G loss: 0.947914]\n",
      "epoch:24 step:23243 [D loss: 0.475066, acc.: 78.12%] [G loss: 1.261780]\n",
      "epoch:24 step:23244 [D loss: 0.572629, acc.: 71.88%] [G loss: 1.198701]\n",
      "epoch:24 step:23245 [D loss: 0.424931, acc.: 84.38%] [G loss: 1.339358]\n",
      "epoch:24 step:23246 [D loss: 0.576856, acc.: 73.44%] [G loss: 1.014023]\n",
      "epoch:24 step:23247 [D loss: 0.683956, acc.: 57.03%] [G loss: 1.083159]\n",
      "epoch:24 step:23248 [D loss: 0.653395, acc.: 63.28%] [G loss: 0.902135]\n",
      "epoch:24 step:23249 [D loss: 0.733496, acc.: 53.91%] [G loss: 1.069796]\n",
      "epoch:24 step:23250 [D loss: 0.696203, acc.: 55.47%] [G loss: 1.200364]\n",
      "epoch:24 step:23251 [D loss: 0.529281, acc.: 73.44%] [G loss: 1.313643]\n",
      "epoch:24 step:23252 [D loss: 0.568953, acc.: 69.53%] [G loss: 0.938077]\n",
      "epoch:24 step:23253 [D loss: 0.990794, acc.: 28.91%] [G loss: 1.044753]\n",
      "epoch:24 step:23254 [D loss: 0.741082, acc.: 53.91%] [G loss: 1.011320]\n",
      "epoch:24 step:23255 [D loss: 0.578482, acc.: 71.09%] [G loss: 1.030786]\n",
      "epoch:24 step:23256 [D loss: 0.480371, acc.: 82.81%] [G loss: 1.195848]\n",
      "epoch:24 step:23257 [D loss: 0.259879, acc.: 96.88%] [G loss: 1.420028]\n",
      "epoch:24 step:23258 [D loss: 0.474561, acc.: 79.69%] [G loss: 1.213466]\n",
      "epoch:24 step:23259 [D loss: 0.626662, acc.: 60.94%] [G loss: 0.991679]\n",
      "epoch:24 step:23260 [D loss: 0.754237, acc.: 50.78%] [G loss: 0.970824]\n",
      "epoch:24 step:23261 [D loss: 0.615429, acc.: 66.41%] [G loss: 0.957753]\n",
      "epoch:24 step:23262 [D loss: 0.317182, acc.: 84.38%] [G loss: 1.048374]\n",
      "epoch:24 step:23263 [D loss: 0.303235, acc.: 88.28%] [G loss: 1.386630]\n",
      "epoch:24 step:23264 [D loss: 0.472841, acc.: 74.22%] [G loss: 1.844085]\n",
      "epoch:24 step:23265 [D loss: 0.451611, acc.: 84.38%] [G loss: 1.489393]\n",
      "epoch:24 step:23266 [D loss: 0.464976, acc.: 84.38%] [G loss: 1.188727]\n",
      "epoch:24 step:23267 [D loss: 0.776190, acc.: 42.97%] [G loss: 1.067796]\n",
      "epoch:24 step:23268 [D loss: 0.531617, acc.: 74.22%] [G loss: 1.307837]\n",
      "epoch:24 step:23269 [D loss: 0.440737, acc.: 83.59%] [G loss: 1.616929]\n",
      "epoch:24 step:23270 [D loss: 0.353114, acc.: 91.41%] [G loss: 1.442813]\n",
      "epoch:24 step:23271 [D loss: 0.686726, acc.: 58.59%] [G loss: 1.097447]\n",
      "epoch:24 step:23272 [D loss: 0.793082, acc.: 44.53%] [G loss: 0.988661]\n",
      "epoch:24 step:23273 [D loss: 0.612494, acc.: 67.97%] [G loss: 1.152616]\n",
      "epoch:24 step:23274 [D loss: 0.432987, acc.: 81.25%] [G loss: 1.811156]\n",
      "epoch:24 step:23275 [D loss: 0.752237, acc.: 50.78%] [G loss: 1.137050]\n",
      "epoch:24 step:23276 [D loss: 0.589090, acc.: 70.31%] [G loss: 1.043381]\n",
      "epoch:24 step:23277 [D loss: 0.690768, acc.: 57.81%] [G loss: 0.851667]\n",
      "epoch:24 step:23278 [D loss: 0.519199, acc.: 75.78%] [G loss: 1.184833]\n",
      "epoch:24 step:23279 [D loss: 0.407245, acc.: 84.38%] [G loss: 1.060598]\n",
      "epoch:24 step:23280 [D loss: 0.360671, acc.: 82.81%] [G loss: 1.413649]\n",
      "epoch:24 step:23281 [D loss: 0.246827, acc.: 96.09%] [G loss: 1.751506]\n",
      "epoch:24 step:23282 [D loss: 0.251803, acc.: 94.53%] [G loss: 1.716148]\n",
      "epoch:24 step:23283 [D loss: 0.532547, acc.: 73.44%] [G loss: 1.204287]\n",
      "epoch:24 step:23284 [D loss: 0.467062, acc.: 81.25%] [G loss: 1.402739]\n",
      "epoch:24 step:23285 [D loss: 0.680972, acc.: 57.81%] [G loss: 1.257579]\n",
      "epoch:24 step:23286 [D loss: 0.682884, acc.: 56.25%] [G loss: 0.970780]\n",
      "epoch:24 step:23287 [D loss: 0.672355, acc.: 57.81%] [G loss: 1.094864]\n",
      "epoch:24 step:23288 [D loss: 0.818881, acc.: 46.88%] [G loss: 1.241737]\n",
      "epoch:24 step:23289 [D loss: 0.992315, acc.: 30.47%] [G loss: 0.753422]\n",
      "epoch:24 step:23290 [D loss: 0.515306, acc.: 75.78%] [G loss: 1.465656]\n",
      "epoch:24 step:23291 [D loss: 0.691528, acc.: 62.50%] [G loss: 1.193475]\n",
      "epoch:24 step:23292 [D loss: 0.689361, acc.: 61.72%] [G loss: 1.104365]\n",
      "epoch:24 step:23293 [D loss: 0.482564, acc.: 81.25%] [G loss: 1.202391]\n",
      "epoch:24 step:23294 [D loss: 0.353811, acc.: 89.06%] [G loss: 1.161700]\n",
      "epoch:24 step:23295 [D loss: 0.843138, acc.: 39.84%] [G loss: 0.987625]\n",
      "epoch:24 step:23296 [D loss: 0.447980, acc.: 84.38%] [G loss: 1.035112]\n",
      "epoch:24 step:23297 [D loss: 0.364842, acc.: 89.06%] [G loss: 1.540878]\n",
      "epoch:24 step:23298 [D loss: 0.321186, acc.: 95.31%] [G loss: 1.643530]\n",
      "epoch:24 step:23299 [D loss: 0.709516, acc.: 64.06%] [G loss: 1.406203]\n",
      "epoch:24 step:23300 [D loss: 0.658808, acc.: 57.81%] [G loss: 1.175389]\n",
      "epoch:24 step:23301 [D loss: 0.541997, acc.: 78.12%] [G loss: 1.199058]\n",
      "epoch:24 step:23302 [D loss: 0.453213, acc.: 81.25%] [G loss: 1.346729]\n",
      "epoch:24 step:23303 [D loss: 0.432186, acc.: 67.97%] [G loss: 0.995551]\n",
      "epoch:24 step:23304 [D loss: 0.185082, acc.: 98.44%] [G loss: 1.932795]\n",
      "epoch:24 step:23305 [D loss: 0.492295, acc.: 79.69%] [G loss: 1.295391]\n",
      "epoch:24 step:23306 [D loss: 0.365325, acc.: 89.84%] [G loss: 1.441939]\n",
      "epoch:24 step:23307 [D loss: 0.575239, acc.: 72.66%] [G loss: 1.180832]\n",
      "epoch:24 step:23308 [D loss: 1.174276, acc.: 19.53%] [G loss: 0.570199]\n",
      "epoch:24 step:23309 [D loss: 0.665544, acc.: 60.94%] [G loss: 1.247629]\n",
      "epoch:24 step:23310 [D loss: 1.303288, acc.: 12.50%] [G loss: 0.537491]\n",
      "epoch:24 step:23311 [D loss: 0.609038, acc.: 60.16%] [G loss: 1.148719]\n",
      "epoch:24 step:23312 [D loss: 0.423126, acc.: 86.72%] [G loss: 1.462390]\n",
      "epoch:24 step:23313 [D loss: 0.395833, acc.: 85.94%] [G loss: 1.391451]\n",
      "epoch:24 step:23314 [D loss: 0.776073, acc.: 45.31%] [G loss: 0.913290]\n",
      "epoch:24 step:23315 [D loss: 0.868368, acc.: 33.59%] [G loss: 0.981072]\n",
      "epoch:24 step:23316 [D loss: 1.109925, acc.: 35.16%] [G loss: 0.611233]\n",
      "epoch:24 step:23317 [D loss: 0.803888, acc.: 46.88%] [G loss: 1.064849]\n",
      "epoch:24 step:23318 [D loss: 0.723402, acc.: 53.12%] [G loss: 1.096049]\n",
      "epoch:24 step:23319 [D loss: 0.350558, acc.: 89.06%] [G loss: 1.341048]\n",
      "epoch:24 step:23320 [D loss: 0.368399, acc.: 89.84%] [G loss: 1.612495]\n",
      "epoch:24 step:23321 [D loss: 0.363338, acc.: 92.97%] [G loss: 1.571788]\n",
      "epoch:24 step:23322 [D loss: 1.057524, acc.: 27.34%] [G loss: 1.058875]\n",
      "epoch:24 step:23323 [D loss: 0.811278, acc.: 54.69%] [G loss: 1.705453]\n",
      "epoch:24 step:23324 [D loss: 1.262940, acc.: 10.94%] [G loss: 0.901134]\n",
      "epoch:24 step:23325 [D loss: 0.880800, acc.: 35.16%] [G loss: 1.166851]\n",
      "epoch:24 step:23326 [D loss: 0.691258, acc.: 57.03%] [G loss: 1.266171]\n",
      "epoch:24 step:23327 [D loss: 0.704273, acc.: 57.81%] [G loss: 1.154250]\n",
      "epoch:24 step:23328 [D loss: 0.633242, acc.: 67.97%] [G loss: 1.205807]\n",
      "epoch:24 step:23329 [D loss: 0.379863, acc.: 91.41%] [G loss: 1.578168]\n",
      "epoch:24 step:23330 [D loss: 0.458637, acc.: 78.91%] [G loss: 1.537061]\n",
      "epoch:24 step:23331 [D loss: 0.761609, acc.: 52.34%] [G loss: 1.076505]\n",
      "epoch:24 step:23332 [D loss: 0.820822, acc.: 41.41%] [G loss: 1.023043]\n",
      "epoch:24 step:23333 [D loss: 0.603789, acc.: 67.97%] [G loss: 0.879538]\n",
      "epoch:24 step:23334 [D loss: 0.488715, acc.: 77.34%] [G loss: 0.885556]\n",
      "epoch:24 step:23335 [D loss: 0.444614, acc.: 84.38%] [G loss: 0.949012]\n",
      "epoch:24 step:23336 [D loss: 0.468171, acc.: 86.72%] [G loss: 1.244868]\n",
      "epoch:24 step:23337 [D loss: 0.347905, acc.: 96.88%] [G loss: 1.297364]\n",
      "epoch:24 step:23338 [D loss: 0.295166, acc.: 93.75%] [G loss: 1.371909]\n",
      "epoch:24 step:23339 [D loss: 0.205290, acc.: 97.66%] [G loss: 1.902606]\n",
      "epoch:24 step:23340 [D loss: 0.227762, acc.: 96.09%] [G loss: 1.757013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23341 [D loss: 0.233949, acc.: 96.88%] [G loss: 1.706096]\n",
      "epoch:24 step:23342 [D loss: 0.184228, acc.: 97.66%] [G loss: 2.094344]\n",
      "epoch:24 step:23343 [D loss: 0.393004, acc.: 85.94%] [G loss: 1.360874]\n",
      "epoch:24 step:23344 [D loss: 0.729477, acc.: 51.56%] [G loss: 1.062854]\n",
      "epoch:24 step:23345 [D loss: 0.349214, acc.: 83.59%] [G loss: 1.226611]\n",
      "epoch:24 step:23346 [D loss: 0.869689, acc.: 47.66%] [G loss: 1.209739]\n",
      "epoch:24 step:23347 [D loss: 0.623050, acc.: 64.84%] [G loss: 1.282866]\n",
      "epoch:24 step:23348 [D loss: 0.543388, acc.: 77.34%] [G loss: 1.145211]\n",
      "epoch:24 step:23349 [D loss: 0.606796, acc.: 68.75%] [G loss: 0.945214]\n",
      "epoch:24 step:23350 [D loss: 0.636399, acc.: 65.62%] [G loss: 1.245956]\n",
      "epoch:24 step:23351 [D loss: 0.560844, acc.: 72.66%] [G loss: 1.081039]\n",
      "epoch:24 step:23352 [D loss: 0.733521, acc.: 56.25%] [G loss: 0.929607]\n",
      "epoch:24 step:23353 [D loss: 0.559858, acc.: 71.88%] [G loss: 0.950044]\n",
      "epoch:24 step:23354 [D loss: 0.512268, acc.: 78.91%] [G loss: 1.071471]\n",
      "epoch:24 step:23355 [D loss: 0.445780, acc.: 82.03%] [G loss: 1.234380]\n",
      "epoch:24 step:23356 [D loss: 0.706523, acc.: 55.47%] [G loss: 1.095830]\n",
      "epoch:24 step:23357 [D loss: 0.464620, acc.: 81.25%] [G loss: 1.308819]\n",
      "epoch:24 step:23358 [D loss: 0.770845, acc.: 45.31%] [G loss: 1.121147]\n",
      "epoch:24 step:23359 [D loss: 0.647869, acc.: 65.62%] [G loss: 0.700242]\n",
      "epoch:24 step:23360 [D loss: 0.493202, acc.: 82.03%] [G loss: 1.338647]\n",
      "epoch:24 step:23361 [D loss: 0.802677, acc.: 46.09%] [G loss: 0.851847]\n",
      "epoch:24 step:23362 [D loss: 0.538996, acc.: 70.31%] [G loss: 1.492889]\n",
      "epoch:24 step:23363 [D loss: 0.782186, acc.: 54.69%] [G loss: 0.949989]\n",
      "epoch:24 step:23364 [D loss: 0.700888, acc.: 55.47%] [G loss: 1.147702]\n",
      "epoch:24 step:23365 [D loss: 0.761365, acc.: 50.00%] [G loss: 1.147757]\n",
      "epoch:24 step:23366 [D loss: 0.780891, acc.: 44.53%] [G loss: 0.948132]\n",
      "epoch:24 step:23367 [D loss: 0.907206, acc.: 28.91%] [G loss: 0.691412]\n",
      "epoch:24 step:23368 [D loss: 0.498021, acc.: 82.81%] [G loss: 1.253908]\n",
      "epoch:24 step:23369 [D loss: 0.568629, acc.: 70.31%] [G loss: 0.874228]\n",
      "epoch:24 step:23370 [D loss: 0.637513, acc.: 64.84%] [G loss: 0.997742]\n",
      "epoch:24 step:23371 [D loss: 0.627729, acc.: 64.84%] [G loss: 1.184843]\n",
      "epoch:24 step:23372 [D loss: 0.661992, acc.: 59.38%] [G loss: 0.846528]\n",
      "epoch:24 step:23373 [D loss: 0.397547, acc.: 85.94%] [G loss: 1.264723]\n",
      "epoch:24 step:23374 [D loss: 0.679196, acc.: 54.69%] [G loss: 1.258500]\n",
      "epoch:24 step:23375 [D loss: 0.494196, acc.: 77.34%] [G loss: 1.258842]\n",
      "epoch:24 step:23376 [D loss: 0.704673, acc.: 53.12%] [G loss: 1.453261]\n",
      "epoch:24 step:23377 [D loss: 0.601490, acc.: 60.94%] [G loss: 1.031791]\n",
      "epoch:24 step:23378 [D loss: 0.507964, acc.: 76.56%] [G loss: 1.529120]\n",
      "epoch:24 step:23379 [D loss: 0.769564, acc.: 54.69%] [G loss: 1.265357]\n",
      "epoch:24 step:23380 [D loss: 0.639696, acc.: 58.59%] [G loss: 1.277517]\n",
      "epoch:24 step:23381 [D loss: 0.552430, acc.: 75.78%] [G loss: 1.175752]\n",
      "epoch:24 step:23382 [D loss: 0.380808, acc.: 89.84%] [G loss: 1.348621]\n",
      "epoch:24 step:23383 [D loss: 0.356270, acc.: 93.75%] [G loss: 1.666032]\n",
      "epoch:24 step:23384 [D loss: 0.344487, acc.: 92.97%] [G loss: 1.470251]\n",
      "epoch:24 step:23385 [D loss: 0.260232, acc.: 96.88%] [G loss: 1.947246]\n",
      "epoch:24 step:23386 [D loss: 0.196654, acc.: 98.44%] [G loss: 2.124562]\n",
      "epoch:24 step:23387 [D loss: 0.143371, acc.: 98.44%] [G loss: 2.238349]\n",
      "epoch:24 step:23388 [D loss: 0.114585, acc.: 100.00%] [G loss: 2.469058]\n",
      "epoch:24 step:23389 [D loss: 0.241421, acc.: 96.09%] [G loss: 2.025408]\n",
      "epoch:24 step:23390 [D loss: 0.357301, acc.: 90.62%] [G loss: 1.812201]\n",
      "epoch:24 step:23391 [D loss: 0.381302, acc.: 88.28%] [G loss: 1.703729]\n",
      "epoch:24 step:23392 [D loss: 0.599324, acc.: 64.06%] [G loss: 1.398424]\n",
      "epoch:24 step:23393 [D loss: 0.639856, acc.: 60.16%] [G loss: 1.127185]\n",
      "epoch:24 step:23394 [D loss: 0.908050, acc.: 35.16%] [G loss: 1.080403]\n",
      "epoch:24 step:23395 [D loss: 0.459863, acc.: 82.03%] [G loss: 1.293018]\n",
      "epoch:24 step:23396 [D loss: 0.387472, acc.: 91.41%] [G loss: 1.340004]\n",
      "epoch:24 step:23397 [D loss: 0.236355, acc.: 95.31%] [G loss: 1.579632]\n",
      "epoch:24 step:23398 [D loss: 0.584061, acc.: 66.41%] [G loss: 1.412853]\n",
      "epoch:24 step:23399 [D loss: 0.164658, acc.: 98.44%] [G loss: 1.725789]\n",
      "epoch:24 step:23400 [D loss: 0.205042, acc.: 94.53%] [G loss: 1.663343]\n",
      "epoch:24 step:23401 [D loss: 0.678173, acc.: 59.38%] [G loss: 1.740726]\n",
      "epoch:24 step:23402 [D loss: 0.634822, acc.: 62.50%] [G loss: 1.320471]\n",
      "epoch:24 step:23403 [D loss: 0.418202, acc.: 88.28%] [G loss: 1.218253]\n",
      "epoch:24 step:23404 [D loss: 0.941551, acc.: 47.66%] [G loss: 0.568014]\n",
      "epoch:24 step:23405 [D loss: 0.604993, acc.: 66.41%] [G loss: 1.216893]\n",
      "epoch:24 step:23406 [D loss: 0.711681, acc.: 60.94%] [G loss: 0.744986]\n",
      "epoch:24 step:23407 [D loss: 0.321263, acc.: 88.28%] [G loss: 1.431780]\n",
      "epoch:24 step:23408 [D loss: 1.068986, acc.: 49.22%] [G loss: 1.545491]\n",
      "epoch:24 step:23409 [D loss: 0.963373, acc.: 42.97%] [G loss: 0.997533]\n",
      "epoch:24 step:23410 [D loss: 0.455708, acc.: 81.25%] [G loss: 1.287595]\n",
      "epoch:24 step:23411 [D loss: 0.458282, acc.: 83.59%] [G loss: 1.392625]\n",
      "epoch:24 step:23412 [D loss: 0.390681, acc.: 85.16%] [G loss: 1.207112]\n",
      "epoch:24 step:23413 [D loss: 0.334754, acc.: 93.75%] [G loss: 1.240180]\n",
      "epoch:24 step:23414 [D loss: 0.469110, acc.: 82.81%] [G loss: 1.396025]\n",
      "epoch:24 step:23415 [D loss: 0.445373, acc.: 77.34%] [G loss: 1.400065]\n",
      "epoch:24 step:23416 [D loss: 1.539786, acc.: 28.12%] [G loss: 1.164858]\n",
      "epoch:24 step:23417 [D loss: 0.684491, acc.: 58.59%] [G loss: 1.237083]\n",
      "epoch:24 step:23418 [D loss: 0.719344, acc.: 57.03%] [G loss: 1.716164]\n",
      "epoch:24 step:23419 [D loss: 0.906751, acc.: 38.28%] [G loss: 1.279930]\n",
      "epoch:24 step:23420 [D loss: 0.767703, acc.: 56.25%] [G loss: 1.072382]\n",
      "epoch:24 step:23421 [D loss: 0.761497, acc.: 46.09%] [G loss: 1.163511]\n",
      "epoch:24 step:23422 [D loss: 0.515562, acc.: 72.66%] [G loss: 1.217720]\n",
      "epoch:24 step:23423 [D loss: 0.817061, acc.: 37.50%] [G loss: 1.317410]\n",
      "epoch:24 step:23424 [D loss: 0.463964, acc.: 82.81%] [G loss: 1.337348]\n",
      "epoch:24 step:23425 [D loss: 0.318640, acc.: 86.72%] [G loss: 1.553803]\n",
      "epoch:25 step:23426 [D loss: 0.893428, acc.: 42.19%] [G loss: 1.061687]\n",
      "epoch:25 step:23427 [D loss: 0.773243, acc.: 50.00%] [G loss: 1.228211]\n",
      "epoch:25 step:23428 [D loss: 0.643187, acc.: 60.94%] [G loss: 1.224742]\n",
      "epoch:25 step:23429 [D loss: 0.425894, acc.: 89.06%] [G loss: 1.378331]\n",
      "epoch:25 step:23430 [D loss: 0.609862, acc.: 61.72%] [G loss: 1.405629]\n",
      "epoch:25 step:23431 [D loss: 0.504621, acc.: 75.78%] [G loss: 1.319878]\n",
      "epoch:25 step:23432 [D loss: 0.462841, acc.: 82.81%] [G loss: 1.373708]\n",
      "epoch:25 step:23433 [D loss: 0.619953, acc.: 63.28%] [G loss: 1.320278]\n",
      "epoch:25 step:23434 [D loss: 0.656023, acc.: 64.06%] [G loss: 1.102211]\n",
      "epoch:25 step:23435 [D loss: 0.565084, acc.: 74.22%] [G loss: 1.130388]\n",
      "epoch:25 step:23436 [D loss: 0.631423, acc.: 64.84%] [G loss: 1.179638]\n",
      "epoch:25 step:23437 [D loss: 0.678059, acc.: 62.50%] [G loss: 1.036166]\n",
      "epoch:25 step:23438 [D loss: 0.672979, acc.: 54.69%] [G loss: 1.046693]\n",
      "epoch:25 step:23439 [D loss: 0.636153, acc.: 60.94%] [G loss: 1.229326]\n",
      "epoch:25 step:23440 [D loss: 0.523556, acc.: 78.12%] [G loss: 1.079571]\n",
      "epoch:25 step:23441 [D loss: 0.575203, acc.: 66.41%] [G loss: 1.046192]\n",
      "epoch:25 step:23442 [D loss: 0.676083, acc.: 58.59%] [G loss: 1.184894]\n",
      "epoch:25 step:23443 [D loss: 0.688197, acc.: 62.50%] [G loss: 1.248868]\n",
      "epoch:25 step:23444 [D loss: 0.664130, acc.: 55.47%] [G loss: 1.083186]\n",
      "epoch:25 step:23445 [D loss: 0.521455, acc.: 79.69%] [G loss: 1.107836]\n",
      "epoch:25 step:23446 [D loss: 0.571457, acc.: 71.09%] [G loss: 1.153519]\n",
      "epoch:25 step:23447 [D loss: 0.639670, acc.: 62.50%] [G loss: 1.178830]\n",
      "epoch:25 step:23448 [D loss: 0.477666, acc.: 79.69%] [G loss: 1.009003]\n",
      "epoch:25 step:23449 [D loss: 0.528738, acc.: 78.12%] [G loss: 1.169292]\n",
      "epoch:25 step:23450 [D loss: 0.627107, acc.: 60.94%] [G loss: 1.180059]\n",
      "epoch:25 step:23451 [D loss: 0.440875, acc.: 82.81%] [G loss: 1.201218]\n",
      "epoch:25 step:23452 [D loss: 0.233726, acc.: 97.66%] [G loss: 1.226202]\n",
      "epoch:25 step:23453 [D loss: 0.332071, acc.: 92.19%] [G loss: 1.596732]\n",
      "epoch:25 step:23454 [D loss: 0.418533, acc.: 89.06%] [G loss: 1.364337]\n",
      "epoch:25 step:23455 [D loss: 0.388022, acc.: 87.50%] [G loss: 1.271025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23456 [D loss: 0.281807, acc.: 95.31%] [G loss: 1.750848]\n",
      "epoch:25 step:23457 [D loss: 0.314124, acc.: 94.53%] [G loss: 1.641816]\n",
      "epoch:25 step:23458 [D loss: 0.230709, acc.: 98.44%] [G loss: 1.528605]\n",
      "epoch:25 step:23459 [D loss: 0.303299, acc.: 94.53%] [G loss: 1.676148]\n",
      "epoch:25 step:23460 [D loss: 0.284895, acc.: 89.84%] [G loss: 1.386210]\n",
      "epoch:25 step:23461 [D loss: 0.206291, acc.: 96.88%] [G loss: 1.941709]\n",
      "epoch:25 step:23462 [D loss: 0.942102, acc.: 50.78%] [G loss: 1.480026]\n",
      "epoch:25 step:23463 [D loss: 1.096876, acc.: 28.12%] [G loss: 0.955562]\n",
      "epoch:25 step:23464 [D loss: 1.039369, acc.: 30.47%] [G loss: 0.760279]\n",
      "epoch:25 step:23465 [D loss: 0.557845, acc.: 71.09%] [G loss: 1.354208]\n",
      "epoch:25 step:23466 [D loss: 0.766163, acc.: 51.56%] [G loss: 0.984096]\n",
      "epoch:25 step:23467 [D loss: 0.536201, acc.: 78.12%] [G loss: 1.023378]\n",
      "epoch:25 step:23468 [D loss: 0.601222, acc.: 71.09%] [G loss: 1.205165]\n",
      "epoch:25 step:23469 [D loss: 0.647343, acc.: 62.50%] [G loss: 0.843817]\n",
      "epoch:25 step:23470 [D loss: 0.671949, acc.: 56.25%] [G loss: 1.104147]\n",
      "epoch:25 step:23471 [D loss: 0.731802, acc.: 52.34%] [G loss: 1.036814]\n",
      "epoch:25 step:23472 [D loss: 0.699028, acc.: 56.25%] [G loss: 0.773672]\n",
      "epoch:25 step:23473 [D loss: 0.660797, acc.: 63.28%] [G loss: 1.111066]\n",
      "epoch:25 step:23474 [D loss: 0.561126, acc.: 67.97%] [G loss: 1.135005]\n",
      "epoch:25 step:23475 [D loss: 0.460063, acc.: 84.38%] [G loss: 1.423194]\n",
      "epoch:25 step:23476 [D loss: 0.621907, acc.: 65.62%] [G loss: 1.308508]\n",
      "epoch:25 step:23477 [D loss: 0.580755, acc.: 68.75%] [G loss: 1.017153]\n",
      "epoch:25 step:23478 [D loss: 0.555008, acc.: 75.00%] [G loss: 0.884624]\n",
      "epoch:25 step:23479 [D loss: 0.429193, acc.: 83.59%] [G loss: 1.481805]\n",
      "epoch:25 step:23480 [D loss: 0.405787, acc.: 85.16%] [G loss: 1.250962]\n",
      "epoch:25 step:23481 [D loss: 0.515363, acc.: 76.56%] [G loss: 1.235581]\n",
      "epoch:25 step:23482 [D loss: 0.868478, acc.: 42.19%] [G loss: 1.117019]\n",
      "epoch:25 step:23483 [D loss: 0.798977, acc.: 42.19%] [G loss: 1.264273]\n",
      "epoch:25 step:23484 [D loss: 0.699621, acc.: 53.91%] [G loss: 1.378551]\n",
      "epoch:25 step:23485 [D loss: 0.737405, acc.: 51.56%] [G loss: 1.120834]\n",
      "epoch:25 step:23486 [D loss: 0.706069, acc.: 60.16%] [G loss: 0.932554]\n",
      "epoch:25 step:23487 [D loss: 0.526184, acc.: 75.78%] [G loss: 1.118397]\n",
      "epoch:25 step:23488 [D loss: 0.707796, acc.: 51.56%] [G loss: 0.727547]\n",
      "epoch:25 step:23489 [D loss: 0.701148, acc.: 57.81%] [G loss: 0.874732]\n",
      "epoch:25 step:23490 [D loss: 0.613858, acc.: 66.41%] [G loss: 0.989234]\n",
      "epoch:25 step:23491 [D loss: 0.680208, acc.: 57.03%] [G loss: 1.055643]\n",
      "epoch:25 step:23492 [D loss: 0.802649, acc.: 46.09%] [G loss: 1.009762]\n",
      "epoch:25 step:23493 [D loss: 0.554962, acc.: 73.44%] [G loss: 1.133697]\n",
      "epoch:25 step:23494 [D loss: 0.523903, acc.: 73.44%] [G loss: 1.160075]\n",
      "epoch:25 step:23495 [D loss: 0.757901, acc.: 49.22%] [G loss: 0.858171]\n",
      "epoch:25 step:23496 [D loss: 0.413384, acc.: 86.72%] [G loss: 1.368750]\n",
      "epoch:25 step:23497 [D loss: 0.567721, acc.: 70.31%] [G loss: 1.231193]\n",
      "epoch:25 step:23498 [D loss: 0.585578, acc.: 67.97%] [G loss: 1.354899]\n",
      "epoch:25 step:23499 [D loss: 0.497431, acc.: 72.66%] [G loss: 1.127556]\n",
      "epoch:25 step:23500 [D loss: 0.212468, acc.: 96.09%] [G loss: 1.847288]\n",
      "epoch:25 step:23501 [D loss: 0.237794, acc.: 96.09%] [G loss: 2.064665]\n",
      "epoch:25 step:23502 [D loss: 0.310133, acc.: 92.19%] [G loss: 1.207579]\n",
      "epoch:25 step:23503 [D loss: 0.702568, acc.: 58.59%] [G loss: 1.373066]\n",
      "epoch:25 step:23504 [D loss: 0.562817, acc.: 73.44%] [G loss: 1.115275]\n",
      "epoch:25 step:23505 [D loss: 0.649011, acc.: 64.84%] [G loss: 0.931181]\n",
      "epoch:25 step:23506 [D loss: 0.665166, acc.: 61.72%] [G loss: 0.794625]\n",
      "epoch:25 step:23507 [D loss: 0.772285, acc.: 50.00%] [G loss: 0.765667]\n",
      "epoch:25 step:23508 [D loss: 0.631658, acc.: 67.97%] [G loss: 1.032610]\n",
      "epoch:25 step:23509 [D loss: 0.624908, acc.: 64.84%] [G loss: 0.957716]\n",
      "epoch:25 step:23510 [D loss: 0.662236, acc.: 55.47%] [G loss: 0.880933]\n",
      "epoch:25 step:23511 [D loss: 0.572703, acc.: 67.97%] [G loss: 0.996838]\n",
      "epoch:25 step:23512 [D loss: 0.593154, acc.: 69.53%] [G loss: 1.093590]\n",
      "epoch:25 step:23513 [D loss: 0.725226, acc.: 57.81%] [G loss: 1.203255]\n",
      "epoch:25 step:23514 [D loss: 0.679501, acc.: 60.16%] [G loss: 1.005540]\n",
      "epoch:25 step:23515 [D loss: 0.674576, acc.: 60.16%] [G loss: 1.033452]\n",
      "epoch:25 step:23516 [D loss: 0.695256, acc.: 55.47%] [G loss: 0.913711]\n",
      "epoch:25 step:23517 [D loss: 0.570775, acc.: 72.66%] [G loss: 1.145341]\n",
      "epoch:25 step:23518 [D loss: 0.567036, acc.: 69.53%] [G loss: 1.143711]\n",
      "epoch:25 step:23519 [D loss: 0.742745, acc.: 50.78%] [G loss: 0.858199]\n",
      "epoch:25 step:23520 [D loss: 0.640797, acc.: 56.25%] [G loss: 1.079592]\n",
      "epoch:25 step:23521 [D loss: 0.635882, acc.: 65.62%] [G loss: 1.137208]\n",
      "epoch:25 step:23522 [D loss: 0.543648, acc.: 71.88%] [G loss: 1.099998]\n",
      "epoch:25 step:23523 [D loss: 0.727097, acc.: 51.56%] [G loss: 0.916069]\n",
      "epoch:25 step:23524 [D loss: 0.731252, acc.: 52.34%] [G loss: 0.922022]\n",
      "epoch:25 step:23525 [D loss: 0.606001, acc.: 67.19%] [G loss: 1.073481]\n",
      "epoch:25 step:23526 [D loss: 0.554200, acc.: 72.66%] [G loss: 1.297218]\n",
      "epoch:25 step:23527 [D loss: 0.531980, acc.: 77.34%] [G loss: 1.163221]\n",
      "epoch:25 step:23528 [D loss: 0.529566, acc.: 75.00%] [G loss: 0.966578]\n",
      "epoch:25 step:23529 [D loss: 0.570626, acc.: 71.09%] [G loss: 1.258716]\n",
      "epoch:25 step:23530 [D loss: 0.410612, acc.: 89.84%] [G loss: 1.196381]\n",
      "epoch:25 step:23531 [D loss: 0.421289, acc.: 85.94%] [G loss: 1.379897]\n",
      "epoch:25 step:23532 [D loss: 0.804310, acc.: 45.31%] [G loss: 1.065546]\n",
      "epoch:25 step:23533 [D loss: 0.636660, acc.: 65.62%] [G loss: 1.068917]\n",
      "epoch:25 step:23534 [D loss: 0.671063, acc.: 60.94%] [G loss: 1.041385]\n",
      "epoch:25 step:23535 [D loss: 0.503554, acc.: 77.34%] [G loss: 1.276703]\n",
      "epoch:25 step:23536 [D loss: 0.606387, acc.: 64.84%] [G loss: 1.399706]\n",
      "epoch:25 step:23537 [D loss: 0.595464, acc.: 69.53%] [G loss: 0.921556]\n",
      "epoch:25 step:23538 [D loss: 0.797610, acc.: 50.00%] [G loss: 1.129226]\n",
      "epoch:25 step:23539 [D loss: 0.779756, acc.: 48.44%] [G loss: 1.061388]\n",
      "epoch:25 step:23540 [D loss: 0.555079, acc.: 71.09%] [G loss: 1.199129]\n",
      "epoch:25 step:23541 [D loss: 0.534354, acc.: 75.00%] [G loss: 1.150763]\n",
      "epoch:25 step:23542 [D loss: 0.446335, acc.: 82.03%] [G loss: 1.119748]\n",
      "epoch:25 step:23543 [D loss: 0.497347, acc.: 77.34%] [G loss: 1.387355]\n",
      "epoch:25 step:23544 [D loss: 0.320384, acc.: 91.41%] [G loss: 1.431272]\n",
      "epoch:25 step:23545 [D loss: 0.725752, acc.: 53.12%] [G loss: 1.227327]\n",
      "epoch:25 step:23546 [D loss: 0.724486, acc.: 60.16%] [G loss: 1.098682]\n",
      "epoch:25 step:23547 [D loss: 0.337425, acc.: 91.41%] [G loss: 1.653753]\n",
      "epoch:25 step:23548 [D loss: 0.599939, acc.: 70.31%] [G loss: 1.646852]\n",
      "epoch:25 step:23549 [D loss: 0.662558, acc.: 60.16%] [G loss: 1.360703]\n",
      "epoch:25 step:23550 [D loss: 0.724562, acc.: 52.34%] [G loss: 1.091862]\n",
      "epoch:25 step:23551 [D loss: 0.779573, acc.: 46.09%] [G loss: 0.986601]\n",
      "epoch:25 step:23552 [D loss: 0.643764, acc.: 58.59%] [G loss: 0.980986]\n",
      "epoch:25 step:23553 [D loss: 0.569511, acc.: 72.66%] [G loss: 1.059774]\n",
      "epoch:25 step:23554 [D loss: 0.608987, acc.: 67.97%] [G loss: 1.210114]\n",
      "epoch:25 step:23555 [D loss: 0.331318, acc.: 92.97%] [G loss: 1.119156]\n",
      "epoch:25 step:23556 [D loss: 0.352742, acc.: 90.62%] [G loss: 1.103687]\n",
      "epoch:25 step:23557 [D loss: 0.411421, acc.: 87.50%] [G loss: 1.182563]\n",
      "epoch:25 step:23558 [D loss: 0.776253, acc.: 49.22%] [G loss: 1.143147]\n",
      "epoch:25 step:23559 [D loss: 0.658673, acc.: 61.72%] [G loss: 0.960230]\n",
      "epoch:25 step:23560 [D loss: 0.714429, acc.: 54.69%] [G loss: 0.862944]\n",
      "epoch:25 step:23561 [D loss: 0.634954, acc.: 67.97%] [G loss: 1.189315]\n",
      "epoch:25 step:23562 [D loss: 0.635311, acc.: 66.41%] [G loss: 1.194014]\n",
      "epoch:25 step:23563 [D loss: 0.470617, acc.: 83.59%] [G loss: 1.429241]\n",
      "epoch:25 step:23564 [D loss: 0.408219, acc.: 86.72%] [G loss: 1.003018]\n",
      "epoch:25 step:23565 [D loss: 0.740548, acc.: 53.91%] [G loss: 0.937539]\n",
      "epoch:25 step:23566 [D loss: 0.518692, acc.: 76.56%] [G loss: 1.205441]\n",
      "epoch:25 step:23567 [D loss: 0.435354, acc.: 85.16%] [G loss: 1.228480]\n",
      "epoch:25 step:23568 [D loss: 0.599559, acc.: 64.84%] [G loss: 1.214944]\n",
      "epoch:25 step:23569 [D loss: 0.658767, acc.: 60.16%] [G loss: 0.884977]\n",
      "epoch:25 step:23570 [D loss: 0.448497, acc.: 85.94%] [G loss: 1.055517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23571 [D loss: 0.664321, acc.: 60.94%] [G loss: 1.121400]\n",
      "epoch:25 step:23572 [D loss: 0.760347, acc.: 47.66%] [G loss: 0.991637]\n",
      "epoch:25 step:23573 [D loss: 0.801344, acc.: 42.97%] [G loss: 1.010916]\n",
      "epoch:25 step:23574 [D loss: 0.576681, acc.: 73.44%] [G loss: 1.114022]\n",
      "epoch:25 step:23575 [D loss: 0.524530, acc.: 77.34%] [G loss: 1.085974]\n",
      "epoch:25 step:23576 [D loss: 0.527443, acc.: 75.00%] [G loss: 1.198433]\n",
      "epoch:25 step:23577 [D loss: 0.486759, acc.: 81.25%] [G loss: 1.354605]\n",
      "epoch:25 step:23578 [D loss: 0.706767, acc.: 57.03%] [G loss: 1.051125]\n",
      "epoch:25 step:23579 [D loss: 0.652789, acc.: 60.16%] [G loss: 1.257498]\n",
      "epoch:25 step:23580 [D loss: 0.815807, acc.: 48.44%] [G loss: 1.113464]\n",
      "epoch:25 step:23581 [D loss: 0.394528, acc.: 90.62%] [G loss: 1.183601]\n",
      "epoch:25 step:23582 [D loss: 0.693823, acc.: 59.38%] [G loss: 1.517610]\n",
      "epoch:25 step:23583 [D loss: 0.489884, acc.: 79.69%] [G loss: 1.295550]\n",
      "epoch:25 step:23584 [D loss: 0.332406, acc.: 93.75%] [G loss: 1.384131]\n",
      "epoch:25 step:23585 [D loss: 0.786119, acc.: 46.88%] [G loss: 1.280694]\n",
      "epoch:25 step:23586 [D loss: 0.810881, acc.: 51.56%] [G loss: 1.205454]\n",
      "epoch:25 step:23587 [D loss: 0.656644, acc.: 64.06%] [G loss: 1.103700]\n",
      "epoch:25 step:23588 [D loss: 0.531582, acc.: 75.00%] [G loss: 1.040913]\n",
      "epoch:25 step:23589 [D loss: 0.562655, acc.: 71.88%] [G loss: 1.358767]\n",
      "epoch:25 step:23590 [D loss: 0.451588, acc.: 85.16%] [G loss: 1.004258]\n",
      "epoch:25 step:23591 [D loss: 0.480588, acc.: 78.12%] [G loss: 0.896988]\n",
      "epoch:25 step:23592 [D loss: 0.380332, acc.: 89.84%] [G loss: 1.336020]\n",
      "epoch:25 step:23593 [D loss: 0.414663, acc.: 85.94%] [G loss: 1.706847]\n",
      "epoch:25 step:23594 [D loss: 0.598338, acc.: 69.53%] [G loss: 1.062195]\n",
      "epoch:25 step:23595 [D loss: 0.711993, acc.: 55.47%] [G loss: 1.129195]\n",
      "epoch:25 step:23596 [D loss: 0.689134, acc.: 60.16%] [G loss: 1.010136]\n",
      "epoch:25 step:23597 [D loss: 0.608183, acc.: 62.50%] [G loss: 1.421815]\n",
      "epoch:25 step:23598 [D loss: 0.625825, acc.: 67.19%] [G loss: 1.357916]\n",
      "epoch:25 step:23599 [D loss: 1.110656, acc.: 19.53%] [G loss: 0.805476]\n",
      "epoch:25 step:23600 [D loss: 0.759666, acc.: 46.88%] [G loss: 1.110805]\n",
      "epoch:25 step:23601 [D loss: 0.825154, acc.: 46.88%] [G loss: 1.052880]\n",
      "epoch:25 step:23602 [D loss: 0.982399, acc.: 31.25%] [G loss: 1.024601]\n",
      "epoch:25 step:23603 [D loss: 0.675948, acc.: 62.50%] [G loss: 1.130238]\n",
      "epoch:25 step:23604 [D loss: 0.960068, acc.: 28.12%] [G loss: 0.789732]\n",
      "epoch:25 step:23605 [D loss: 0.823971, acc.: 38.28%] [G loss: 1.027102]\n",
      "epoch:25 step:23606 [D loss: 0.795927, acc.: 44.53%] [G loss: 0.848033]\n",
      "epoch:25 step:23607 [D loss: 0.630904, acc.: 64.06%] [G loss: 1.100394]\n",
      "epoch:25 step:23608 [D loss: 0.795894, acc.: 42.19%] [G loss: 0.866198]\n",
      "epoch:25 step:23609 [D loss: 1.042307, acc.: 31.25%] [G loss: 0.645028]\n",
      "epoch:25 step:23610 [D loss: 0.840785, acc.: 43.75%] [G loss: 0.909874]\n",
      "epoch:25 step:23611 [D loss: 0.710493, acc.: 56.25%] [G loss: 1.428020]\n",
      "epoch:25 step:23612 [D loss: 0.830252, acc.: 42.19%] [G loss: 1.098645]\n",
      "epoch:25 step:23613 [D loss: 0.817007, acc.: 46.09%] [G loss: 0.967149]\n",
      "epoch:25 step:23614 [D loss: 0.578223, acc.: 68.75%] [G loss: 1.203662]\n",
      "epoch:25 step:23615 [D loss: 0.699216, acc.: 52.34%] [G loss: 0.846732]\n",
      "epoch:25 step:23616 [D loss: 0.661319, acc.: 60.94%] [G loss: 1.235162]\n",
      "epoch:25 step:23617 [D loss: 0.620592, acc.: 67.97%] [G loss: 1.180671]\n",
      "epoch:25 step:23618 [D loss: 0.694050, acc.: 57.81%] [G loss: 1.073643]\n",
      "epoch:25 step:23619 [D loss: 0.574507, acc.: 73.44%] [G loss: 1.394141]\n",
      "epoch:25 step:23620 [D loss: 0.634633, acc.: 68.75%] [G loss: 1.230083]\n",
      "epoch:25 step:23621 [D loss: 0.677069, acc.: 60.16%] [G loss: 1.216514]\n",
      "epoch:25 step:23622 [D loss: 0.680408, acc.: 59.38%] [G loss: 0.766399]\n",
      "epoch:25 step:23623 [D loss: 0.694320, acc.: 60.94%] [G loss: 0.897982]\n",
      "epoch:25 step:23624 [D loss: 0.701871, acc.: 58.59%] [G loss: 1.016755]\n",
      "epoch:25 step:23625 [D loss: 0.453626, acc.: 87.50%] [G loss: 1.141877]\n",
      "epoch:25 step:23626 [D loss: 0.467425, acc.: 80.47%] [G loss: 1.449636]\n",
      "epoch:25 step:23627 [D loss: 0.622644, acc.: 67.19%] [G loss: 1.132532]\n",
      "epoch:25 step:23628 [D loss: 0.721187, acc.: 51.56%] [G loss: 1.141412]\n",
      "epoch:25 step:23629 [D loss: 0.812409, acc.: 48.44%] [G loss: 0.941180]\n",
      "epoch:25 step:23630 [D loss: 0.734682, acc.: 53.91%] [G loss: 1.073963]\n",
      "epoch:25 step:23631 [D loss: 0.601757, acc.: 67.19%] [G loss: 1.101972]\n",
      "epoch:25 step:23632 [D loss: 0.540149, acc.: 77.34%] [G loss: 1.052938]\n",
      "epoch:25 step:23633 [D loss: 0.593254, acc.: 67.97%] [G loss: 1.251120]\n",
      "epoch:25 step:23634 [D loss: 0.487539, acc.: 76.56%] [G loss: 1.096450]\n",
      "epoch:25 step:23635 [D loss: 0.826454, acc.: 45.31%] [G loss: 0.775293]\n",
      "epoch:25 step:23636 [D loss: 0.492901, acc.: 83.59%] [G loss: 1.089367]\n",
      "epoch:25 step:23637 [D loss: 0.602762, acc.: 66.41%] [G loss: 1.043212]\n",
      "epoch:25 step:23638 [D loss: 0.453020, acc.: 78.12%] [G loss: 1.181339]\n",
      "epoch:25 step:23639 [D loss: 0.634045, acc.: 67.97%] [G loss: 1.274464]\n",
      "epoch:25 step:23640 [D loss: 0.427961, acc.: 85.16%] [G loss: 1.312585]\n",
      "epoch:25 step:23641 [D loss: 0.642193, acc.: 59.38%] [G loss: 1.073083]\n",
      "epoch:25 step:23642 [D loss: 0.781335, acc.: 45.31%] [G loss: 1.069672]\n",
      "epoch:25 step:23643 [D loss: 0.767227, acc.: 48.44%] [G loss: 0.806070]\n",
      "epoch:25 step:23644 [D loss: 0.677557, acc.: 58.59%] [G loss: 1.392285]\n",
      "epoch:25 step:23645 [D loss: 0.279634, acc.: 90.62%] [G loss: 1.440193]\n",
      "epoch:25 step:23646 [D loss: 0.294664, acc.: 93.75%] [G loss: 1.403521]\n",
      "epoch:25 step:23647 [D loss: 0.321421, acc.: 92.19%] [G loss: 1.780156]\n",
      "epoch:25 step:23648 [D loss: 0.177328, acc.: 97.66%] [G loss: 1.776217]\n",
      "epoch:25 step:23649 [D loss: 0.995470, acc.: 28.12%] [G loss: 1.352435]\n",
      "epoch:25 step:23650 [D loss: 0.746631, acc.: 55.47%] [G loss: 1.351689]\n",
      "epoch:25 step:23651 [D loss: 0.534487, acc.: 70.31%] [G loss: 1.095812]\n",
      "epoch:25 step:23652 [D loss: 0.666343, acc.: 60.94%] [G loss: 1.049697]\n",
      "epoch:25 step:23653 [D loss: 0.602975, acc.: 65.62%] [G loss: 0.950911]\n",
      "epoch:25 step:23654 [D loss: 0.531948, acc.: 78.12%] [G loss: 1.277826]\n",
      "epoch:25 step:23655 [D loss: 0.282617, acc.: 92.19%] [G loss: 1.411834]\n",
      "epoch:25 step:23656 [D loss: 0.336960, acc.: 89.84%] [G loss: 1.439155]\n",
      "epoch:25 step:23657 [D loss: 0.276006, acc.: 94.53%] [G loss: 1.755778]\n",
      "epoch:25 step:23658 [D loss: 0.723199, acc.: 57.81%] [G loss: 1.415261]\n",
      "epoch:25 step:23659 [D loss: 0.617944, acc.: 65.62%] [G loss: 1.289388]\n",
      "epoch:25 step:23660 [D loss: 0.528722, acc.: 73.44%] [G loss: 1.036425]\n",
      "epoch:25 step:23661 [D loss: 0.847669, acc.: 43.75%] [G loss: 0.968418]\n",
      "epoch:25 step:23662 [D loss: 0.593854, acc.: 64.84%] [G loss: 1.297293]\n",
      "epoch:25 step:23663 [D loss: 0.557391, acc.: 71.09%] [G loss: 1.122034]\n",
      "epoch:25 step:23664 [D loss: 0.773951, acc.: 54.69%] [G loss: 0.781776]\n",
      "epoch:25 step:23665 [D loss: 0.732359, acc.: 53.12%] [G loss: 1.150471]\n",
      "epoch:25 step:23666 [D loss: 0.727158, acc.: 56.25%] [G loss: 1.249198]\n",
      "epoch:25 step:23667 [D loss: 0.708913, acc.: 57.03%] [G loss: 1.069870]\n",
      "epoch:25 step:23668 [D loss: 0.728072, acc.: 60.16%] [G loss: 0.847864]\n",
      "epoch:25 step:23669 [D loss: 0.815607, acc.: 46.88%] [G loss: 1.012717]\n",
      "epoch:25 step:23670 [D loss: 0.641103, acc.: 62.50%] [G loss: 1.527157]\n",
      "epoch:25 step:23671 [D loss: 0.360278, acc.: 92.97%] [G loss: 1.454154]\n",
      "epoch:25 step:23672 [D loss: 0.559270, acc.: 72.66%] [G loss: 1.368102]\n",
      "epoch:25 step:23673 [D loss: 0.475704, acc.: 82.03%] [G loss: 1.318413]\n",
      "epoch:25 step:23674 [D loss: 0.613382, acc.: 63.28%] [G loss: 1.084525]\n",
      "epoch:25 step:23675 [D loss: 0.533237, acc.: 75.00%] [G loss: 1.330820]\n",
      "epoch:25 step:23676 [D loss: 0.735510, acc.: 56.25%] [G loss: 0.738650]\n",
      "epoch:25 step:23677 [D loss: 0.608804, acc.: 64.06%] [G loss: 1.121447]\n",
      "epoch:25 step:23678 [D loss: 0.540914, acc.: 71.88%] [G loss: 1.268585]\n",
      "epoch:25 step:23679 [D loss: 0.816351, acc.: 45.31%] [G loss: 0.806258]\n",
      "epoch:25 step:23680 [D loss: 0.861132, acc.: 45.31%] [G loss: 1.123091]\n",
      "epoch:25 step:23681 [D loss: 0.782416, acc.: 45.31%] [G loss: 0.711741]\n",
      "epoch:25 step:23682 [D loss: 0.826022, acc.: 39.84%] [G loss: 0.967508]\n",
      "epoch:25 step:23683 [D loss: 0.646629, acc.: 63.28%] [G loss: 0.818900]\n",
      "epoch:25 step:23684 [D loss: 0.715191, acc.: 55.47%] [G loss: 0.950615]\n",
      "epoch:25 step:23685 [D loss: 0.567434, acc.: 72.66%] [G loss: 1.016879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23686 [D loss: 0.563507, acc.: 73.44%] [G loss: 1.083384]\n",
      "epoch:25 step:23687 [D loss: 0.645329, acc.: 64.84%] [G loss: 1.088727]\n",
      "epoch:25 step:23688 [D loss: 0.522672, acc.: 80.47%] [G loss: 1.059479]\n",
      "epoch:25 step:23689 [D loss: 0.497072, acc.: 75.78%] [G loss: 1.326313]\n",
      "epoch:25 step:23690 [D loss: 0.698617, acc.: 55.47%] [G loss: 0.910835]\n",
      "epoch:25 step:23691 [D loss: 0.829543, acc.: 41.41%] [G loss: 1.055914]\n",
      "epoch:25 step:23692 [D loss: 0.574725, acc.: 70.31%] [G loss: 1.097229]\n",
      "epoch:25 step:23693 [D loss: 0.656766, acc.: 60.94%] [G loss: 0.987809]\n",
      "epoch:25 step:23694 [D loss: 0.606500, acc.: 69.53%] [G loss: 1.077570]\n",
      "epoch:25 step:23695 [D loss: 0.655756, acc.: 62.50%] [G loss: 1.108083]\n",
      "epoch:25 step:23696 [D loss: 0.649012, acc.: 56.25%] [G loss: 0.986045]\n",
      "epoch:25 step:23697 [D loss: 0.485238, acc.: 79.69%] [G loss: 1.254635]\n",
      "epoch:25 step:23698 [D loss: 0.519017, acc.: 78.91%] [G loss: 1.070876]\n",
      "epoch:25 step:23699 [D loss: 0.603935, acc.: 68.75%] [G loss: 1.375281]\n",
      "epoch:25 step:23700 [D loss: 0.745386, acc.: 47.66%] [G loss: 1.092095]\n",
      "epoch:25 step:23701 [D loss: 0.573075, acc.: 72.66%] [G loss: 0.923571]\n",
      "epoch:25 step:23702 [D loss: 0.858744, acc.: 44.53%] [G loss: 0.881739]\n",
      "epoch:25 step:23703 [D loss: 0.445828, acc.: 84.38%] [G loss: 1.145947]\n",
      "epoch:25 step:23704 [D loss: 0.351533, acc.: 89.84%] [G loss: 1.372793]\n",
      "epoch:25 step:23705 [D loss: 0.384305, acc.: 89.84%] [G loss: 1.346457]\n",
      "epoch:25 step:23706 [D loss: 0.884622, acc.: 41.41%] [G loss: 1.088605]\n",
      "epoch:25 step:23707 [D loss: 0.573848, acc.: 67.97%] [G loss: 1.079941]\n",
      "epoch:25 step:23708 [D loss: 0.630536, acc.: 63.28%] [G loss: 1.006569]\n",
      "epoch:25 step:23709 [D loss: 0.458630, acc.: 83.59%] [G loss: 1.249501]\n",
      "epoch:25 step:23710 [D loss: 0.360607, acc.: 92.19%] [G loss: 1.350299]\n",
      "epoch:25 step:23711 [D loss: 0.408703, acc.: 86.72%] [G loss: 1.190153]\n",
      "epoch:25 step:23712 [D loss: 0.616792, acc.: 63.28%] [G loss: 1.071696]\n",
      "epoch:25 step:23713 [D loss: 0.505000, acc.: 78.91%] [G loss: 1.395439]\n",
      "epoch:25 step:23714 [D loss: 0.420791, acc.: 82.81%] [G loss: 1.257737]\n",
      "epoch:25 step:23715 [D loss: 0.689443, acc.: 57.03%] [G loss: 1.000630]\n",
      "epoch:25 step:23716 [D loss: 0.259673, acc.: 95.31%] [G loss: 1.540851]\n",
      "epoch:25 step:23717 [D loss: 0.372067, acc.: 92.97%] [G loss: 1.326035]\n",
      "epoch:25 step:23718 [D loss: 0.341530, acc.: 88.28%] [G loss: 1.427276]\n",
      "epoch:25 step:23719 [D loss: 0.600710, acc.: 67.97%] [G loss: 1.198924]\n",
      "epoch:25 step:23720 [D loss: 0.858649, acc.: 48.44%] [G loss: 1.525067]\n",
      "epoch:25 step:23721 [D loss: 0.754743, acc.: 51.56%] [G loss: 0.851063]\n",
      "epoch:25 step:23722 [D loss: 0.789194, acc.: 50.78%] [G loss: 1.057895]\n",
      "epoch:25 step:23723 [D loss: 0.561577, acc.: 70.31%] [G loss: 0.977486]\n",
      "epoch:25 step:23724 [D loss: 0.557045, acc.: 71.09%] [G loss: 1.397162]\n",
      "epoch:25 step:23725 [D loss: 0.621149, acc.: 66.41%] [G loss: 1.130334]\n",
      "epoch:25 step:23726 [D loss: 0.729020, acc.: 50.78%] [G loss: 0.920622]\n",
      "epoch:25 step:23727 [D loss: 0.650087, acc.: 57.03%] [G loss: 1.066404]\n",
      "epoch:25 step:23728 [D loss: 0.697379, acc.: 58.59%] [G loss: 1.272017]\n",
      "epoch:25 step:23729 [D loss: 0.644155, acc.: 64.06%] [G loss: 0.845914]\n",
      "epoch:25 step:23730 [D loss: 0.638479, acc.: 62.50%] [G loss: 1.173167]\n",
      "epoch:25 step:23731 [D loss: 0.644373, acc.: 65.62%] [G loss: 0.876038]\n",
      "epoch:25 step:23732 [D loss: 0.547641, acc.: 70.31%] [G loss: 1.136058]\n",
      "epoch:25 step:23733 [D loss: 0.560069, acc.: 72.66%] [G loss: 1.077896]\n",
      "epoch:25 step:23734 [D loss: 0.536986, acc.: 76.56%] [G loss: 1.150427]\n",
      "epoch:25 step:23735 [D loss: 0.559427, acc.: 71.88%] [G loss: 1.195967]\n",
      "epoch:25 step:23736 [D loss: 0.639066, acc.: 67.97%] [G loss: 1.174625]\n",
      "epoch:25 step:23737 [D loss: 0.469130, acc.: 79.69%] [G loss: 1.278287]\n",
      "epoch:25 step:23738 [D loss: 0.503877, acc.: 77.34%] [G loss: 1.409055]\n",
      "epoch:25 step:23739 [D loss: 0.594882, acc.: 66.41%] [G loss: 1.216850]\n",
      "epoch:25 step:23740 [D loss: 0.466727, acc.: 82.81%] [G loss: 1.580801]\n",
      "epoch:25 step:23741 [D loss: 0.790304, acc.: 51.56%] [G loss: 0.990817]\n",
      "epoch:25 step:23742 [D loss: 0.698372, acc.: 56.25%] [G loss: 0.917136]\n",
      "epoch:25 step:23743 [D loss: 0.505281, acc.: 78.91%] [G loss: 0.977513]\n",
      "epoch:25 step:23744 [D loss: 0.499729, acc.: 82.81%] [G loss: 1.355752]\n",
      "epoch:25 step:23745 [D loss: 0.451543, acc.: 82.03%] [G loss: 1.127576]\n",
      "epoch:25 step:23746 [D loss: 0.363810, acc.: 86.72%] [G loss: 1.255234]\n",
      "epoch:25 step:23747 [D loss: 0.388944, acc.: 87.50%] [G loss: 1.393512]\n",
      "epoch:25 step:23748 [D loss: 0.769562, acc.: 52.34%] [G loss: 1.042065]\n",
      "epoch:25 step:23749 [D loss: 0.514679, acc.: 78.91%] [G loss: 1.154515]\n",
      "epoch:25 step:23750 [D loss: 0.515587, acc.: 74.22%] [G loss: 0.915498]\n",
      "epoch:25 step:23751 [D loss: 0.421269, acc.: 88.28%] [G loss: 1.212242]\n",
      "epoch:25 step:23752 [D loss: 0.326155, acc.: 91.41%] [G loss: 1.217753]\n",
      "epoch:25 step:23753 [D loss: 0.363460, acc.: 86.72%] [G loss: 1.260203]\n",
      "epoch:25 step:23754 [D loss: 0.514589, acc.: 77.34%] [G loss: 1.241047]\n",
      "epoch:25 step:23755 [D loss: 0.683147, acc.: 55.47%] [G loss: 1.561271]\n",
      "epoch:25 step:23756 [D loss: 0.692029, acc.: 61.72%] [G loss: 1.143373]\n",
      "epoch:25 step:23757 [D loss: 0.954003, acc.: 29.69%] [G loss: 0.580670]\n",
      "epoch:25 step:23758 [D loss: 0.613549, acc.: 67.97%] [G loss: 0.968115]\n",
      "epoch:25 step:23759 [D loss: 0.859811, acc.: 42.19%] [G loss: 0.873783]\n",
      "epoch:25 step:23760 [D loss: 0.591873, acc.: 67.97%] [G loss: 1.301003]\n",
      "epoch:25 step:23761 [D loss: 0.479355, acc.: 82.03%] [G loss: 1.114912]\n",
      "epoch:25 step:23762 [D loss: 0.710264, acc.: 59.38%] [G loss: 0.984705]\n",
      "epoch:25 step:23763 [D loss: 0.589795, acc.: 69.53%] [G loss: 0.850596]\n",
      "epoch:25 step:23764 [D loss: 0.500221, acc.: 79.69%] [G loss: 1.164609]\n",
      "epoch:25 step:23765 [D loss: 0.602736, acc.: 67.97%] [G loss: 1.004769]\n",
      "epoch:25 step:23766 [D loss: 0.722748, acc.: 50.78%] [G loss: 0.948044]\n",
      "epoch:25 step:23767 [D loss: 0.406950, acc.: 85.94%] [G loss: 1.168951]\n",
      "epoch:25 step:23768 [D loss: 0.414416, acc.: 83.59%] [G loss: 0.942820]\n",
      "epoch:25 step:23769 [D loss: 0.475419, acc.: 80.47%] [G loss: 1.145298]\n",
      "epoch:25 step:23770 [D loss: 0.289956, acc.: 94.53%] [G loss: 1.391984]\n",
      "epoch:25 step:23771 [D loss: 0.234182, acc.: 93.75%] [G loss: 1.580392]\n",
      "epoch:25 step:23772 [D loss: 0.218032, acc.: 100.00%] [G loss: 1.960857]\n",
      "epoch:25 step:23773 [D loss: 0.631451, acc.: 62.50%] [G loss: 1.760361]\n",
      "epoch:25 step:23774 [D loss: 0.723162, acc.: 53.91%] [G loss: 1.167329]\n",
      "epoch:25 step:23775 [D loss: 0.649337, acc.: 64.06%] [G loss: 0.995376]\n",
      "epoch:25 step:23776 [D loss: 0.640949, acc.: 64.06%] [G loss: 1.077981]\n",
      "epoch:25 step:23777 [D loss: 0.538371, acc.: 75.78%] [G loss: 1.245879]\n",
      "epoch:25 step:23778 [D loss: 0.466230, acc.: 87.50%] [G loss: 1.183364]\n",
      "epoch:25 step:23779 [D loss: 0.613952, acc.: 60.94%] [G loss: 1.007568]\n",
      "epoch:25 step:23780 [D loss: 0.702564, acc.: 57.03%] [G loss: 1.308021]\n",
      "epoch:25 step:23781 [D loss: 0.750947, acc.: 51.56%] [G loss: 0.943411]\n",
      "epoch:25 step:23782 [D loss: 0.512408, acc.: 76.56%] [G loss: 1.131830]\n",
      "epoch:25 step:23783 [D loss: 0.583775, acc.: 69.53%] [G loss: 1.201410]\n",
      "epoch:25 step:23784 [D loss: 0.554963, acc.: 73.44%] [G loss: 0.978734]\n",
      "epoch:25 step:23785 [D loss: 0.651821, acc.: 60.16%] [G loss: 0.975811]\n",
      "epoch:25 step:23786 [D loss: 0.702496, acc.: 54.69%] [G loss: 0.716952]\n",
      "epoch:25 step:23787 [D loss: 0.661621, acc.: 60.94%] [G loss: 1.045234]\n",
      "epoch:25 step:23788 [D loss: 0.463882, acc.: 81.25%] [G loss: 0.941745]\n",
      "epoch:25 step:23789 [D loss: 0.552379, acc.: 73.44%] [G loss: 1.094887]\n",
      "epoch:25 step:23790 [D loss: 0.411629, acc.: 89.84%] [G loss: 1.281356]\n",
      "epoch:25 step:23791 [D loss: 0.223084, acc.: 96.09%] [G loss: 1.582114]\n",
      "epoch:25 step:23792 [D loss: 0.293162, acc.: 92.97%] [G loss: 1.455149]\n",
      "epoch:25 step:23793 [D loss: 0.521797, acc.: 71.88%] [G loss: 1.487118]\n",
      "epoch:25 step:23794 [D loss: 0.777704, acc.: 51.56%] [G loss: 0.955695]\n",
      "epoch:25 step:23795 [D loss: 0.850347, acc.: 46.88%] [G loss: 0.951206]\n",
      "epoch:25 step:23796 [D loss: 0.612926, acc.: 63.28%] [G loss: 1.120546]\n",
      "epoch:25 step:23797 [D loss: 0.669516, acc.: 59.38%] [G loss: 0.954007]\n",
      "epoch:25 step:23798 [D loss: 0.666140, acc.: 62.50%] [G loss: 0.994356]\n",
      "epoch:25 step:23799 [D loss: 0.506847, acc.: 80.47%] [G loss: 0.992890]\n",
      "epoch:25 step:23800 [D loss: 0.723539, acc.: 53.91%] [G loss: 0.797363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23801 [D loss: 0.778098, acc.: 50.78%] [G loss: 0.845689]\n",
      "epoch:25 step:23802 [D loss: 0.496119, acc.: 79.69%] [G loss: 1.343646]\n",
      "epoch:25 step:23803 [D loss: 0.493890, acc.: 69.53%] [G loss: 1.163398]\n",
      "epoch:25 step:23804 [D loss: 0.676484, acc.: 57.03%] [G loss: 1.219631]\n",
      "epoch:25 step:23805 [D loss: 0.532998, acc.: 72.66%] [G loss: 1.240614]\n",
      "epoch:25 step:23806 [D loss: 0.540495, acc.: 74.22%] [G loss: 1.220437]\n",
      "epoch:25 step:23807 [D loss: 0.666714, acc.: 61.72%] [G loss: 1.158151]\n",
      "epoch:25 step:23808 [D loss: 0.574210, acc.: 71.88%] [G loss: 0.928941]\n",
      "epoch:25 step:23809 [D loss: 0.505824, acc.: 78.91%] [G loss: 1.067509]\n",
      "epoch:25 step:23810 [D loss: 0.702253, acc.: 53.91%] [G loss: 1.105573]\n",
      "epoch:25 step:23811 [D loss: 0.758789, acc.: 53.12%] [G loss: 0.991668]\n",
      "epoch:25 step:23812 [D loss: 0.530286, acc.: 75.78%] [G loss: 1.364563]\n",
      "epoch:25 step:23813 [D loss: 0.599483, acc.: 64.84%] [G loss: 1.143710]\n",
      "epoch:25 step:23814 [D loss: 0.620812, acc.: 66.41%] [G loss: 1.090612]\n",
      "epoch:25 step:23815 [D loss: 0.381308, acc.: 87.50%] [G loss: 1.087234]\n",
      "epoch:25 step:23816 [D loss: 0.490630, acc.: 78.12%] [G loss: 1.269323]\n",
      "epoch:25 step:23817 [D loss: 0.502155, acc.: 79.69%] [G loss: 1.110009]\n",
      "epoch:25 step:23818 [D loss: 0.765210, acc.: 43.75%] [G loss: 0.926702]\n",
      "epoch:25 step:23819 [D loss: 0.504902, acc.: 75.78%] [G loss: 0.986162]\n",
      "epoch:25 step:23820 [D loss: 0.736638, acc.: 57.81%] [G loss: 0.910644]\n",
      "epoch:25 step:23821 [D loss: 0.386367, acc.: 87.50%] [G loss: 1.305003]\n",
      "epoch:25 step:23822 [D loss: 0.328205, acc.: 85.16%] [G loss: 1.441737]\n",
      "epoch:25 step:23823 [D loss: 0.215202, acc.: 99.22%] [G loss: 1.732055]\n",
      "epoch:25 step:23824 [D loss: 0.310395, acc.: 95.31%] [G loss: 1.919260]\n",
      "epoch:25 step:23825 [D loss: 0.402299, acc.: 85.94%] [G loss: 1.253854]\n",
      "epoch:25 step:23826 [D loss: 0.368281, acc.: 89.84%] [G loss: 1.536197]\n",
      "epoch:25 step:23827 [D loss: 0.340313, acc.: 90.62%] [G loss: 1.638342]\n",
      "epoch:25 step:23828 [D loss: 0.545626, acc.: 73.44%] [G loss: 1.451609]\n",
      "epoch:25 step:23829 [D loss: 0.260013, acc.: 96.88%] [G loss: 1.564993]\n",
      "epoch:25 step:23830 [D loss: 0.372969, acc.: 85.94%] [G loss: 1.372696]\n",
      "epoch:25 step:23831 [D loss: 0.460276, acc.: 78.91%] [G loss: 1.189009]\n",
      "epoch:25 step:23832 [D loss: 0.588034, acc.: 70.31%] [G loss: 1.531432]\n",
      "epoch:25 step:23833 [D loss: 0.599000, acc.: 67.97%] [G loss: 1.051533]\n",
      "epoch:25 step:23834 [D loss: 0.662706, acc.: 69.53%] [G loss: 0.804984]\n",
      "epoch:25 step:23835 [D loss: 0.662226, acc.: 59.38%] [G loss: 1.228025]\n",
      "epoch:25 step:23836 [D loss: 0.824078, acc.: 42.19%] [G loss: 1.071395]\n",
      "epoch:25 step:23837 [D loss: 1.019475, acc.: 32.81%] [G loss: 0.613479]\n",
      "epoch:25 step:23838 [D loss: 1.024337, acc.: 27.34%] [G loss: 0.877915]\n",
      "epoch:25 step:23839 [D loss: 0.805134, acc.: 47.66%] [G loss: 0.941128]\n",
      "epoch:25 step:23840 [D loss: 1.174507, acc.: 23.44%] [G loss: 0.923718]\n",
      "epoch:25 step:23841 [D loss: 0.811741, acc.: 47.66%] [G loss: 1.490330]\n",
      "epoch:25 step:23842 [D loss: 0.925680, acc.: 41.41%] [G loss: 0.859232]\n",
      "epoch:25 step:23843 [D loss: 0.916874, acc.: 41.41%] [G loss: 0.937896]\n",
      "epoch:25 step:23844 [D loss: 0.556030, acc.: 75.00%] [G loss: 1.270231]\n",
      "epoch:25 step:23845 [D loss: 0.704558, acc.: 56.25%] [G loss: 1.212001]\n",
      "epoch:25 step:23846 [D loss: 0.807160, acc.: 46.09%] [G loss: 0.836543]\n",
      "epoch:25 step:23847 [D loss: 0.655976, acc.: 59.38%] [G loss: 1.340024]\n",
      "epoch:25 step:23848 [D loss: 0.617500, acc.: 62.50%] [G loss: 1.210349]\n",
      "epoch:25 step:23849 [D loss: 0.599371, acc.: 69.53%] [G loss: 1.210597]\n",
      "epoch:25 step:23850 [D loss: 0.603076, acc.: 63.28%] [G loss: 1.243586]\n",
      "epoch:25 step:23851 [D loss: 0.714121, acc.: 54.69%] [G loss: 0.826570]\n",
      "epoch:25 step:23852 [D loss: 0.603373, acc.: 66.41%] [G loss: 1.039960]\n",
      "epoch:25 step:23853 [D loss: 0.584853, acc.: 70.31%] [G loss: 1.313462]\n",
      "epoch:25 step:23854 [D loss: 0.559044, acc.: 70.31%] [G loss: 1.149001]\n",
      "epoch:25 step:23855 [D loss: 0.551546, acc.: 75.00%] [G loss: 1.050335]\n",
      "epoch:25 step:23856 [D loss: 0.520281, acc.: 75.00%] [G loss: 1.364838]\n",
      "epoch:25 step:23857 [D loss: 0.586333, acc.: 71.09%] [G loss: 1.361422]\n",
      "epoch:25 step:23858 [D loss: 0.433600, acc.: 84.38%] [G loss: 1.504539]\n",
      "epoch:25 step:23859 [D loss: 0.496163, acc.: 81.25%] [G loss: 1.433350]\n",
      "epoch:25 step:23860 [D loss: 0.499830, acc.: 79.69%] [G loss: 1.592564]\n",
      "epoch:25 step:23861 [D loss: 0.452544, acc.: 82.81%] [G loss: 1.286487]\n",
      "epoch:25 step:23862 [D loss: 0.754194, acc.: 59.38%] [G loss: 1.050703]\n",
      "epoch:25 step:23863 [D loss: 0.723901, acc.: 54.69%] [G loss: 1.035759]\n",
      "epoch:25 step:23864 [D loss: 0.573426, acc.: 71.88%] [G loss: 1.164565]\n",
      "epoch:25 step:23865 [D loss: 0.514134, acc.: 78.91%] [G loss: 1.245623]\n",
      "epoch:25 step:23866 [D loss: 0.693220, acc.: 57.03%] [G loss: 0.965618]\n",
      "epoch:25 step:23867 [D loss: 0.696673, acc.: 61.72%] [G loss: 1.030213]\n",
      "epoch:25 step:23868 [D loss: 0.455913, acc.: 80.47%] [G loss: 1.296036]\n",
      "epoch:25 step:23869 [D loss: 0.534947, acc.: 74.22%] [G loss: 1.365305]\n",
      "epoch:25 step:23870 [D loss: 0.753098, acc.: 52.34%] [G loss: 1.146872]\n",
      "epoch:25 step:23871 [D loss: 0.817684, acc.: 48.44%] [G loss: 1.124884]\n",
      "epoch:25 step:23872 [D loss: 0.687936, acc.: 60.16%] [G loss: 1.041437]\n",
      "epoch:25 step:23873 [D loss: 0.416727, acc.: 85.16%] [G loss: 1.187836]\n",
      "epoch:25 step:23874 [D loss: 0.369036, acc.: 88.28%] [G loss: 1.609270]\n",
      "epoch:25 step:23875 [D loss: 0.518854, acc.: 77.34%] [G loss: 1.127824]\n",
      "epoch:25 step:23876 [D loss: 0.307746, acc.: 89.84%] [G loss: 1.575892]\n",
      "epoch:25 step:23877 [D loss: 0.326018, acc.: 93.75%] [G loss: 1.344077]\n",
      "epoch:25 step:23878 [D loss: 0.505328, acc.: 78.12%] [G loss: 1.420209]\n",
      "epoch:25 step:23879 [D loss: 0.589916, acc.: 67.19%] [G loss: 1.245263]\n",
      "epoch:25 step:23880 [D loss: 0.607060, acc.: 71.09%] [G loss: 1.476072]\n",
      "epoch:25 step:23881 [D loss: 0.616042, acc.: 69.53%] [G loss: 1.248357]\n",
      "epoch:25 step:23882 [D loss: 0.469844, acc.: 78.12%] [G loss: 1.129584]\n",
      "epoch:25 step:23883 [D loss: 1.137623, acc.: 35.16%] [G loss: 0.889695]\n",
      "epoch:25 step:23884 [D loss: 0.920870, acc.: 36.72%] [G loss: 0.798034]\n",
      "epoch:25 step:23885 [D loss: 0.922117, acc.: 31.25%] [G loss: 0.876011]\n",
      "epoch:25 step:23886 [D loss: 1.122149, acc.: 19.53%] [G loss: 0.803664]\n",
      "epoch:25 step:23887 [D loss: 0.962386, acc.: 32.03%] [G loss: 0.843126]\n",
      "epoch:25 step:23888 [D loss: 0.786866, acc.: 46.88%] [G loss: 0.814109]\n",
      "epoch:25 step:23889 [D loss: 0.741761, acc.: 54.69%] [G loss: 1.177476]\n",
      "epoch:25 step:23890 [D loss: 0.656376, acc.: 57.81%] [G loss: 0.950178]\n",
      "epoch:25 step:23891 [D loss: 0.737684, acc.: 53.91%] [G loss: 1.089318]\n",
      "epoch:25 step:23892 [D loss: 0.533283, acc.: 71.88%] [G loss: 1.025946]\n",
      "epoch:25 step:23893 [D loss: 0.490025, acc.: 78.91%] [G loss: 1.269679]\n",
      "epoch:25 step:23894 [D loss: 0.386709, acc.: 88.28%] [G loss: 1.452973]\n",
      "epoch:25 step:23895 [D loss: 0.352971, acc.: 92.19%] [G loss: 1.565191]\n",
      "epoch:25 step:23896 [D loss: 0.240345, acc.: 97.66%] [G loss: 1.450564]\n",
      "epoch:25 step:23897 [D loss: 0.423606, acc.: 85.94%] [G loss: 1.328522]\n",
      "epoch:25 step:23898 [D loss: 1.017326, acc.: 38.28%] [G loss: 1.273216]\n",
      "epoch:25 step:23899 [D loss: 0.563204, acc.: 71.09%] [G loss: 1.522569]\n",
      "epoch:25 step:23900 [D loss: 0.300073, acc.: 92.97%] [G loss: 1.873495]\n",
      "epoch:25 step:23901 [D loss: 0.649211, acc.: 61.72%] [G loss: 1.612967]\n",
      "epoch:25 step:23902 [D loss: 0.709689, acc.: 57.03%] [G loss: 1.394149]\n",
      "epoch:25 step:23903 [D loss: 0.593417, acc.: 66.41%] [G loss: 1.460855]\n",
      "epoch:25 step:23904 [D loss: 0.475048, acc.: 78.91%] [G loss: 1.027876]\n",
      "epoch:25 step:23905 [D loss: 0.641082, acc.: 66.41%] [G loss: 1.179389]\n",
      "epoch:25 step:23906 [D loss: 0.688686, acc.: 53.12%] [G loss: 1.118376]\n",
      "epoch:25 step:23907 [D loss: 0.371160, acc.: 90.62%] [G loss: 1.113032]\n",
      "epoch:25 step:23908 [D loss: 0.306455, acc.: 96.88%] [G loss: 1.291833]\n",
      "epoch:25 step:23909 [D loss: 0.253624, acc.: 96.88%] [G loss: 1.596359]\n",
      "epoch:25 step:23910 [D loss: 0.318052, acc.: 90.62%] [G loss: 1.616442]\n",
      "epoch:25 step:23911 [D loss: 0.479991, acc.: 78.91%] [G loss: 1.416860]\n",
      "epoch:25 step:23912 [D loss: 0.350159, acc.: 92.19%] [G loss: 1.319130]\n",
      "epoch:25 step:23913 [D loss: 0.555492, acc.: 71.09%] [G loss: 1.691005]\n",
      "epoch:25 step:23914 [D loss: 0.646917, acc.: 62.50%] [G loss: 1.216249]\n",
      "epoch:25 step:23915 [D loss: 0.597665, acc.: 71.88%] [G loss: 1.373864]\n",
      "epoch:25 step:23916 [D loss: 0.574189, acc.: 64.84%] [G loss: 1.059880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23917 [D loss: 0.620163, acc.: 67.19%] [G loss: 0.851235]\n",
      "epoch:25 step:23918 [D loss: 0.597013, acc.: 65.62%] [G loss: 1.120499]\n",
      "epoch:25 step:23919 [D loss: 0.672496, acc.: 63.28%] [G loss: 0.862804]\n",
      "epoch:25 step:23920 [D loss: 0.479875, acc.: 80.47%] [G loss: 1.014300]\n",
      "epoch:25 step:23921 [D loss: 0.544474, acc.: 71.09%] [G loss: 1.006298]\n",
      "epoch:25 step:23922 [D loss: 0.312619, acc.: 89.06%] [G loss: 1.176324]\n",
      "epoch:25 step:23923 [D loss: 0.306607, acc.: 90.62%] [G loss: 1.606218]\n",
      "epoch:25 step:23924 [D loss: 0.150220, acc.: 98.44%] [G loss: 2.068043]\n",
      "epoch:25 step:23925 [D loss: 0.776143, acc.: 54.69%] [G loss: 1.346209]\n",
      "epoch:25 step:23926 [D loss: 0.784821, acc.: 52.34%] [G loss: 1.029791]\n",
      "epoch:25 step:23927 [D loss: 0.848299, acc.: 39.06%] [G loss: 0.821614]\n",
      "epoch:25 step:23928 [D loss: 0.605137, acc.: 67.97%] [G loss: 0.975681]\n",
      "epoch:25 step:23929 [D loss: 0.461318, acc.: 82.81%] [G loss: 1.442511]\n",
      "epoch:25 step:23930 [D loss: 0.727864, acc.: 52.34%] [G loss: 0.894706]\n",
      "epoch:25 step:23931 [D loss: 0.556821, acc.: 71.88%] [G loss: 1.083542]\n",
      "epoch:25 step:23932 [D loss: 0.432734, acc.: 86.72%] [G loss: 1.349797]\n",
      "epoch:25 step:23933 [D loss: 0.397815, acc.: 83.59%] [G loss: 1.391341]\n",
      "epoch:25 step:23934 [D loss: 0.641421, acc.: 60.16%] [G loss: 1.502101]\n",
      "epoch:25 step:23935 [D loss: 0.658094, acc.: 64.84%] [G loss: 1.131708]\n",
      "epoch:25 step:23936 [D loss: 0.360691, acc.: 88.28%] [G loss: 1.175602]\n",
      "epoch:25 step:23937 [D loss: 0.407608, acc.: 84.38%] [G loss: 1.219708]\n",
      "epoch:25 step:23938 [D loss: 0.263808, acc.: 95.31%] [G loss: 1.587232]\n",
      "epoch:25 step:23939 [D loss: 0.447512, acc.: 86.72%] [G loss: 1.417438]\n",
      "epoch:25 step:23940 [D loss: 0.451572, acc.: 84.38%] [G loss: 1.549130]\n",
      "epoch:25 step:23941 [D loss: 0.646831, acc.: 63.28%] [G loss: 1.242320]\n",
      "epoch:25 step:23942 [D loss: 0.560818, acc.: 66.41%] [G loss: 1.346062]\n",
      "epoch:25 step:23943 [D loss: 0.546220, acc.: 70.31%] [G loss: 1.528124]\n",
      "epoch:25 step:23944 [D loss: 0.476258, acc.: 82.81%] [G loss: 1.286578]\n",
      "epoch:25 step:23945 [D loss: 0.455611, acc.: 85.16%] [G loss: 1.199832]\n",
      "epoch:25 step:23946 [D loss: 0.630801, acc.: 59.38%] [G loss: 0.991371]\n",
      "epoch:25 step:23947 [D loss: 0.468756, acc.: 79.69%] [G loss: 1.278175]\n",
      "epoch:25 step:23948 [D loss: 0.399260, acc.: 87.50%] [G loss: 1.295898]\n",
      "epoch:25 step:23949 [D loss: 0.637504, acc.: 64.06%] [G loss: 1.008183]\n",
      "epoch:25 step:23950 [D loss: 0.695783, acc.: 60.94%] [G loss: 1.028595]\n",
      "epoch:25 step:23951 [D loss: 0.522495, acc.: 79.69%] [G loss: 1.275877]\n",
      "epoch:25 step:23952 [D loss: 0.591972, acc.: 66.41%] [G loss: 1.164867]\n",
      "epoch:25 step:23953 [D loss: 0.658027, acc.: 62.50%] [G loss: 0.733629]\n",
      "epoch:25 step:23954 [D loss: 0.664290, acc.: 60.16%] [G loss: 1.016303]\n",
      "epoch:25 step:23955 [D loss: 0.632822, acc.: 65.62%] [G loss: 1.153036]\n",
      "epoch:25 step:23956 [D loss: 0.555116, acc.: 76.56%] [G loss: 1.085314]\n",
      "epoch:25 step:23957 [D loss: 0.469943, acc.: 82.81%] [G loss: 1.216623]\n",
      "epoch:25 step:23958 [D loss: 0.316612, acc.: 87.50%] [G loss: 1.385098]\n",
      "epoch:25 step:23959 [D loss: 0.421347, acc.: 89.06%] [G loss: 1.517010]\n",
      "epoch:25 step:23960 [D loss: 0.504631, acc.: 75.78%] [G loss: 1.452017]\n",
      "epoch:25 step:23961 [D loss: 0.405635, acc.: 89.06%] [G loss: 1.716677]\n",
      "epoch:25 step:23962 [D loss: 0.497626, acc.: 78.12%] [G loss: 1.241931]\n",
      "epoch:25 step:23963 [D loss: 0.637618, acc.: 67.97%] [G loss: 1.281508]\n",
      "epoch:25 step:23964 [D loss: 0.646081, acc.: 62.50%] [G loss: 1.045453]\n",
      "epoch:25 step:23965 [D loss: 0.694078, acc.: 52.34%] [G loss: 0.827307]\n",
      "epoch:25 step:23966 [D loss: 0.709639, acc.: 59.38%] [G loss: 0.823382]\n",
      "epoch:25 step:23967 [D loss: 0.573097, acc.: 71.09%] [G loss: 0.974329]\n",
      "epoch:25 step:23968 [D loss: 0.441483, acc.: 85.94%] [G loss: 1.296011]\n",
      "epoch:25 step:23969 [D loss: 0.510755, acc.: 72.66%] [G loss: 1.027731]\n",
      "epoch:25 step:23970 [D loss: 0.392847, acc.: 89.84%] [G loss: 1.219668]\n",
      "epoch:25 step:23971 [D loss: 0.276899, acc.: 93.75%] [G loss: 1.418453]\n",
      "epoch:25 step:23972 [D loss: 0.326283, acc.: 88.28%] [G loss: 1.802449]\n",
      "epoch:25 step:23973 [D loss: 0.492625, acc.: 76.56%] [G loss: 1.682584]\n",
      "epoch:25 step:23974 [D loss: 0.266387, acc.: 94.53%] [G loss: 1.476127]\n",
      "epoch:25 step:23975 [D loss: 0.260051, acc.: 96.88%] [G loss: 1.702858]\n",
      "epoch:25 step:23976 [D loss: 0.211795, acc.: 99.22%] [G loss: 1.949236]\n",
      "epoch:25 step:23977 [D loss: 0.275479, acc.: 96.09%] [G loss: 1.611159]\n",
      "epoch:25 step:23978 [D loss: 0.376834, acc.: 88.28%] [G loss: 1.292907]\n",
      "epoch:25 step:23979 [D loss: 0.302402, acc.: 92.19%] [G loss: 1.459521]\n",
      "epoch:25 step:23980 [D loss: 0.264945, acc.: 96.88%] [G loss: 1.760390]\n",
      "epoch:25 step:23981 [D loss: 0.209615, acc.: 99.22%] [G loss: 1.787050]\n",
      "epoch:25 step:23982 [D loss: 0.428726, acc.: 81.25%] [G loss: 1.129292]\n",
      "epoch:25 step:23983 [D loss: 0.345336, acc.: 89.84%] [G loss: 1.749123]\n",
      "epoch:25 step:23984 [D loss: 0.819572, acc.: 50.78%] [G loss: 1.984577]\n",
      "epoch:25 step:23985 [D loss: 0.849020, acc.: 50.78%] [G loss: 1.309098]\n",
      "epoch:25 step:23986 [D loss: 0.458900, acc.: 82.81%] [G loss: 1.081990]\n",
      "epoch:25 step:23987 [D loss: 0.818028, acc.: 46.09%] [G loss: 1.211831]\n",
      "epoch:25 step:23988 [D loss: 0.675475, acc.: 60.94%] [G loss: 1.013908]\n",
      "epoch:25 step:23989 [D loss: 0.602429, acc.: 71.88%] [G loss: 0.930826]\n",
      "epoch:25 step:23990 [D loss: 0.567640, acc.: 71.09%] [G loss: 0.934957]\n",
      "epoch:25 step:23991 [D loss: 0.340711, acc.: 90.62%] [G loss: 1.047352]\n",
      "epoch:25 step:23992 [D loss: 0.302921, acc.: 94.53%] [G loss: 1.465275]\n",
      "epoch:25 step:23993 [D loss: 0.589437, acc.: 66.41%] [G loss: 1.552610]\n",
      "epoch:25 step:23994 [D loss: 0.732693, acc.: 56.25%] [G loss: 1.028432]\n",
      "epoch:25 step:23995 [D loss: 0.677336, acc.: 59.38%] [G loss: 1.075972]\n",
      "epoch:25 step:23996 [D loss: 0.578800, acc.: 72.66%] [G loss: 1.182058]\n",
      "epoch:25 step:23997 [D loss: 0.561901, acc.: 74.22%] [G loss: 1.424244]\n",
      "epoch:25 step:23998 [D loss: 0.497399, acc.: 81.25%] [G loss: 1.133492]\n",
      "epoch:25 step:23999 [D loss: 0.565005, acc.: 71.88%] [G loss: 1.232908]\n",
      "epoch:25 step:24000 [D loss: 0.529119, acc.: 78.12%] [G loss: 1.562650]\n",
      "epoch:25 step:24001 [D loss: 0.409110, acc.: 82.81%] [G loss: 1.232966]\n",
      "epoch:25 step:24002 [D loss: 0.371577, acc.: 90.62%] [G loss: 1.731564]\n",
      "epoch:25 step:24003 [D loss: 0.296443, acc.: 95.31%] [G loss: 1.568297]\n",
      "epoch:25 step:24004 [D loss: 0.514609, acc.: 75.00%] [G loss: 1.201866]\n",
      "epoch:25 step:24005 [D loss: 0.755119, acc.: 56.25%] [G loss: 1.086198]\n",
      "epoch:25 step:24006 [D loss: 0.695524, acc.: 53.91%] [G loss: 1.003655]\n",
      "epoch:25 step:24007 [D loss: 0.747718, acc.: 51.56%] [G loss: 0.941118]\n",
      "epoch:25 step:24008 [D loss: 0.681011, acc.: 60.16%] [G loss: 0.898958]\n",
      "epoch:25 step:24009 [D loss: 0.754791, acc.: 52.34%] [G loss: 0.585093]\n",
      "epoch:25 step:24010 [D loss: 1.093112, acc.: 28.91%] [G loss: 0.808630]\n",
      "epoch:25 step:24011 [D loss: 0.691057, acc.: 58.59%] [G loss: 0.920489]\n",
      "epoch:25 step:24012 [D loss: 0.422825, acc.: 78.12%] [G loss: 1.306076]\n",
      "epoch:25 step:24013 [D loss: 0.401961, acc.: 86.72%] [G loss: 1.725961]\n",
      "epoch:25 step:24014 [D loss: 0.335542, acc.: 88.28%] [G loss: 1.476593]\n",
      "epoch:25 step:24015 [D loss: 0.805601, acc.: 51.56%] [G loss: 1.104418]\n",
      "epoch:25 step:24016 [D loss: 1.030787, acc.: 31.25%] [G loss: 0.661996]\n",
      "epoch:25 step:24017 [D loss: 0.565357, acc.: 73.44%] [G loss: 1.053223]\n",
      "epoch:25 step:24018 [D loss: 0.606926, acc.: 67.97%] [G loss: 1.380396]\n",
      "epoch:25 step:24019 [D loss: 0.572685, acc.: 69.53%] [G loss: 0.859074]\n",
      "epoch:25 step:24020 [D loss: 0.690383, acc.: 60.16%] [G loss: 1.349275]\n",
      "epoch:25 step:24021 [D loss: 0.846908, acc.: 39.06%] [G loss: 0.951140]\n",
      "epoch:25 step:24022 [D loss: 0.622460, acc.: 65.62%] [G loss: 1.269036]\n",
      "epoch:25 step:24023 [D loss: 0.261231, acc.: 93.75%] [G loss: 1.677706]\n",
      "epoch:25 step:24024 [D loss: 0.595135, acc.: 73.44%] [G loss: 1.607696]\n",
      "epoch:25 step:24025 [D loss: 0.686293, acc.: 50.78%] [G loss: 1.382415]\n",
      "epoch:25 step:24026 [D loss: 0.513554, acc.: 75.78%] [G loss: 1.208242]\n",
      "epoch:25 step:24027 [D loss: 0.560411, acc.: 73.44%] [G loss: 1.038378]\n",
      "epoch:25 step:24028 [D loss: 0.250797, acc.: 93.75%] [G loss: 1.268132]\n",
      "epoch:25 step:24029 [D loss: 0.213616, acc.: 97.66%] [G loss: 1.609973]\n",
      "epoch:25 step:24030 [D loss: 0.245535, acc.: 96.88%] [G loss: 1.762864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24031 [D loss: 0.657843, acc.: 62.50%] [G loss: 1.332159]\n",
      "epoch:25 step:24032 [D loss: 0.655158, acc.: 62.50%] [G loss: 1.209748]\n",
      "epoch:25 step:24033 [D loss: 0.485930, acc.: 78.91%] [G loss: 1.150212]\n",
      "epoch:25 step:24034 [D loss: 0.651217, acc.: 61.72%] [G loss: 1.283723]\n",
      "epoch:25 step:24035 [D loss: 0.558311, acc.: 71.09%] [G loss: 1.036654]\n",
      "epoch:25 step:24036 [D loss: 0.770274, acc.: 54.69%] [G loss: 1.117813]\n",
      "epoch:25 step:24037 [D loss: 0.697258, acc.: 55.47%] [G loss: 1.200280]\n",
      "epoch:25 step:24038 [D loss: 0.411635, acc.: 78.91%] [G loss: 1.170320]\n",
      "epoch:25 step:24039 [D loss: 0.424429, acc.: 82.03%] [G loss: 1.548469]\n",
      "epoch:25 step:24040 [D loss: 0.306870, acc.: 93.75%] [G loss: 1.482983]\n",
      "epoch:25 step:24041 [D loss: 0.338015, acc.: 87.50%] [G loss: 1.705900]\n",
      "epoch:25 step:24042 [D loss: 0.573994, acc.: 71.09%] [G loss: 1.461906]\n",
      "epoch:25 step:24043 [D loss: 0.990713, acc.: 34.38%] [G loss: 1.250594]\n",
      "epoch:25 step:24044 [D loss: 0.904532, acc.: 43.75%] [G loss: 0.856291]\n",
      "epoch:25 step:24045 [D loss: 0.779869, acc.: 50.00%] [G loss: 1.120301]\n",
      "epoch:25 step:24046 [D loss: 0.752218, acc.: 45.31%] [G loss: 0.863662]\n",
      "epoch:25 step:24047 [D loss: 0.916943, acc.: 46.09%] [G loss: 0.789611]\n",
      "epoch:25 step:24048 [D loss: 0.771625, acc.: 48.44%] [G loss: 1.273762]\n",
      "epoch:25 step:24049 [D loss: 0.406036, acc.: 89.84%] [G loss: 1.591739]\n",
      "epoch:25 step:24050 [D loss: 0.926877, acc.: 45.31%] [G loss: 1.077419]\n",
      "epoch:25 step:24051 [D loss: 0.650840, acc.: 65.62%] [G loss: 1.120415]\n",
      "epoch:25 step:24052 [D loss: 1.106324, acc.: 30.47%] [G loss: 0.689916]\n",
      "epoch:25 step:24053 [D loss: 0.883025, acc.: 32.81%] [G loss: 0.878693]\n",
      "epoch:25 step:24054 [D loss: 0.267629, acc.: 93.75%] [G loss: 1.732455]\n",
      "epoch:25 step:24055 [D loss: 0.541661, acc.: 76.56%] [G loss: 1.207056]\n",
      "epoch:25 step:24056 [D loss: 0.659237, acc.: 61.72%] [G loss: 1.283749]\n",
      "epoch:25 step:24057 [D loss: 0.673088, acc.: 66.41%] [G loss: 0.876542]\n",
      "epoch:25 step:24058 [D loss: 0.434334, acc.: 80.47%] [G loss: 1.343444]\n",
      "epoch:25 step:24059 [D loss: 0.581903, acc.: 72.66%] [G loss: 1.206273]\n",
      "epoch:25 step:24060 [D loss: 0.739964, acc.: 47.66%] [G loss: 1.526609]\n",
      "epoch:25 step:24061 [D loss: 0.882467, acc.: 38.28%] [G loss: 0.976228]\n",
      "epoch:25 step:24062 [D loss: 0.805190, acc.: 46.88%] [G loss: 1.393986]\n",
      "epoch:25 step:24063 [D loss: 0.868732, acc.: 41.41%] [G loss: 1.050522]\n",
      "epoch:25 step:24064 [D loss: 0.684664, acc.: 61.72%] [G loss: 1.171844]\n",
      "epoch:25 step:24065 [D loss: 0.511800, acc.: 74.22%] [G loss: 1.329071]\n",
      "epoch:25 step:24066 [D loss: 0.332946, acc.: 92.97%] [G loss: 1.709398]\n",
      "epoch:25 step:24067 [D loss: 0.313184, acc.: 93.75%] [G loss: 1.927684]\n",
      "epoch:25 step:24068 [D loss: 0.771853, acc.: 53.91%] [G loss: 1.326816]\n",
      "epoch:25 step:24069 [D loss: 0.952914, acc.: 28.91%] [G loss: 0.985801]\n",
      "epoch:25 step:24070 [D loss: 0.565347, acc.: 71.88%] [G loss: 1.209436]\n",
      "epoch:25 step:24071 [D loss: 0.497379, acc.: 75.78%] [G loss: 1.195322]\n",
      "epoch:25 step:24072 [D loss: 0.492305, acc.: 75.00%] [G loss: 1.291767]\n",
      "epoch:25 step:24073 [D loss: 0.493837, acc.: 80.47%] [G loss: 1.173800]\n",
      "epoch:25 step:24074 [D loss: 0.589715, acc.: 66.41%] [G loss: 1.285583]\n",
      "epoch:25 step:24075 [D loss: 0.619996, acc.: 65.62%] [G loss: 1.203180]\n",
      "epoch:25 step:24076 [D loss: 0.695156, acc.: 53.12%] [G loss: 1.332689]\n",
      "epoch:25 step:24077 [D loss: 0.619186, acc.: 63.28%] [G loss: 1.196001]\n",
      "epoch:25 step:24078 [D loss: 0.288776, acc.: 92.97%] [G loss: 1.376974]\n",
      "epoch:25 step:24079 [D loss: 0.493371, acc.: 82.03%] [G loss: 1.736699]\n",
      "epoch:25 step:24080 [D loss: 0.570165, acc.: 72.66%] [G loss: 1.452601]\n",
      "epoch:25 step:24081 [D loss: 0.503786, acc.: 78.91%] [G loss: 1.095432]\n",
      "epoch:25 step:24082 [D loss: 0.547901, acc.: 74.22%] [G loss: 1.062846]\n",
      "epoch:25 step:24083 [D loss: 0.518935, acc.: 75.78%] [G loss: 1.369291]\n",
      "epoch:25 step:24084 [D loss: 0.635164, acc.: 61.72%] [G loss: 1.175940]\n",
      "epoch:25 step:24085 [D loss: 0.573043, acc.: 69.53%] [G loss: 1.208987]\n",
      "epoch:25 step:24086 [D loss: 0.563557, acc.: 70.31%] [G loss: 1.141252]\n",
      "epoch:25 step:24087 [D loss: 0.327239, acc.: 89.06%] [G loss: 1.424297]\n",
      "epoch:25 step:24088 [D loss: 0.248224, acc.: 90.62%] [G loss: 1.459666]\n",
      "epoch:25 step:24089 [D loss: 0.138243, acc.: 98.44%] [G loss: 2.072361]\n",
      "epoch:25 step:24090 [D loss: 0.149924, acc.: 97.66%] [G loss: 2.194095]\n",
      "epoch:25 step:24091 [D loss: 0.340008, acc.: 89.84%] [G loss: 1.462470]\n",
      "epoch:25 step:24092 [D loss: 0.437794, acc.: 81.25%] [G loss: 1.506154]\n",
      "epoch:25 step:24093 [D loss: 0.702111, acc.: 51.56%] [G loss: 1.147622]\n",
      "epoch:25 step:24094 [D loss: 0.517365, acc.: 77.34%] [G loss: 1.320451]\n",
      "epoch:25 step:24095 [D loss: 0.729329, acc.: 52.34%] [G loss: 0.931964]\n",
      "epoch:25 step:24096 [D loss: 0.618312, acc.: 65.62%] [G loss: 0.947566]\n",
      "epoch:25 step:24097 [D loss: 1.102918, acc.: 27.34%] [G loss: 0.598425]\n",
      "epoch:25 step:24098 [D loss: 0.988595, acc.: 36.72%] [G loss: 1.093604]\n",
      "epoch:25 step:24099 [D loss: 0.901389, acc.: 42.19%] [G loss: 0.670074]\n",
      "epoch:25 step:24100 [D loss: 0.869298, acc.: 37.50%] [G loss: 0.880495]\n",
      "epoch:25 step:24101 [D loss: 0.516300, acc.: 81.25%] [G loss: 1.539586]\n",
      "epoch:25 step:24102 [D loss: 0.959608, acc.: 29.69%] [G loss: 0.918600]\n",
      "epoch:25 step:24103 [D loss: 0.678832, acc.: 61.72%] [G loss: 1.257430]\n",
      "epoch:25 step:24104 [D loss: 0.527222, acc.: 75.00%] [G loss: 1.267742]\n",
      "epoch:25 step:24105 [D loss: 0.924486, acc.: 32.03%] [G loss: 0.996148]\n",
      "epoch:25 step:24106 [D loss: 0.833726, acc.: 39.84%] [G loss: 1.044590]\n",
      "epoch:25 step:24107 [D loss: 0.475086, acc.: 83.59%] [G loss: 1.197528]\n",
      "epoch:25 step:24108 [D loss: 0.651679, acc.: 60.94%] [G loss: 0.993284]\n",
      "epoch:25 step:24109 [D loss: 0.643189, acc.: 60.16%] [G loss: 1.177470]\n",
      "epoch:25 step:24110 [D loss: 0.663269, acc.: 62.50%] [G loss: 0.913052]\n",
      "epoch:25 step:24111 [D loss: 0.588962, acc.: 67.97%] [G loss: 1.643126]\n",
      "epoch:25 step:24112 [D loss: 0.715994, acc.: 51.56%] [G loss: 1.165738]\n",
      "epoch:25 step:24113 [D loss: 0.654022, acc.: 59.38%] [G loss: 1.199169]\n",
      "epoch:25 step:24114 [D loss: 0.416248, acc.: 84.38%] [G loss: 1.682524]\n",
      "epoch:25 step:24115 [D loss: 0.319497, acc.: 92.19%] [G loss: 1.509665]\n",
      "epoch:25 step:24116 [D loss: 0.483160, acc.: 78.12%] [G loss: 1.440832]\n",
      "epoch:25 step:24117 [D loss: 0.442749, acc.: 78.91%] [G loss: 1.359624]\n",
      "epoch:25 step:24118 [D loss: 0.457780, acc.: 82.03%] [G loss: 1.445107]\n",
      "epoch:25 step:24119 [D loss: 0.246526, acc.: 98.44%] [G loss: 1.699730]\n",
      "epoch:25 step:24120 [D loss: 0.397954, acc.: 85.94%] [G loss: 1.624958]\n",
      "epoch:25 step:24121 [D loss: 0.666803, acc.: 61.72%] [G loss: 1.224544]\n",
      "epoch:25 step:24122 [D loss: 0.793382, acc.: 46.88%] [G loss: 0.751106]\n",
      "epoch:25 step:24123 [D loss: 0.756645, acc.: 53.12%] [G loss: 0.784239]\n",
      "epoch:25 step:24124 [D loss: 0.681574, acc.: 61.72%] [G loss: 1.135511]\n",
      "epoch:25 step:24125 [D loss: 0.530362, acc.: 73.44%] [G loss: 1.103945]\n",
      "epoch:25 step:24126 [D loss: 0.593004, acc.: 68.75%] [G loss: 1.123816]\n",
      "epoch:25 step:24127 [D loss: 0.733838, acc.: 53.91%] [G loss: 1.137962]\n",
      "epoch:25 step:24128 [D loss: 0.666157, acc.: 57.81%] [G loss: 1.166997]\n",
      "epoch:25 step:24129 [D loss: 0.674182, acc.: 64.84%] [G loss: 1.058046]\n",
      "epoch:25 step:24130 [D loss: 0.786151, acc.: 47.66%] [G loss: 0.853034]\n",
      "epoch:25 step:24131 [D loss: 0.522535, acc.: 75.78%] [G loss: 1.158961]\n",
      "epoch:25 step:24132 [D loss: 0.441473, acc.: 81.25%] [G loss: 0.960925]\n",
      "epoch:25 step:24133 [D loss: 0.368195, acc.: 89.84%] [G loss: 1.389681]\n",
      "epoch:25 step:24134 [D loss: 0.325980, acc.: 92.97%] [G loss: 1.521194]\n",
      "epoch:25 step:24135 [D loss: 0.502763, acc.: 75.78%] [G loss: 1.463875]\n",
      "epoch:25 step:24136 [D loss: 0.570868, acc.: 67.19%] [G loss: 1.521046]\n",
      "epoch:25 step:24137 [D loss: 0.557219, acc.: 67.97%] [G loss: 1.305158]\n",
      "epoch:25 step:24138 [D loss: 0.382052, acc.: 91.41%] [G loss: 1.300589]\n",
      "epoch:25 step:24139 [D loss: 0.456260, acc.: 81.25%] [G loss: 1.482386]\n",
      "epoch:25 step:24140 [D loss: 0.683949, acc.: 61.72%] [G loss: 1.197914]\n",
      "epoch:25 step:24141 [D loss: 0.690995, acc.: 53.91%] [G loss: 1.330226]\n",
      "epoch:25 step:24142 [D loss: 0.708165, acc.: 56.25%] [G loss: 0.836150]\n",
      "epoch:25 step:24143 [D loss: 0.660363, acc.: 60.94%] [G loss: 1.005916]\n",
      "epoch:25 step:24144 [D loss: 0.602166, acc.: 68.75%] [G loss: 1.089965]\n",
      "epoch:25 step:24145 [D loss: 0.490390, acc.: 77.34%] [G loss: 0.978443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24146 [D loss: 0.576759, acc.: 72.66%] [G loss: 1.241663]\n",
      "epoch:25 step:24147 [D loss: 0.698875, acc.: 54.69%] [G loss: 0.973517]\n",
      "epoch:25 step:24148 [D loss: 0.769914, acc.: 54.69%] [G loss: 0.682453]\n",
      "epoch:25 step:24149 [D loss: 0.415670, acc.: 80.47%] [G loss: 1.281975]\n",
      "epoch:25 step:24150 [D loss: 0.442636, acc.: 83.59%] [G loss: 1.594716]\n",
      "epoch:25 step:24151 [D loss: 0.454786, acc.: 82.03%] [G loss: 1.568530]\n",
      "epoch:25 step:24152 [D loss: 0.552068, acc.: 72.66%] [G loss: 1.534488]\n",
      "epoch:25 step:24153 [D loss: 0.416187, acc.: 85.16%] [G loss: 1.427242]\n",
      "epoch:25 step:24154 [D loss: 0.603992, acc.: 64.84%] [G loss: 1.085728]\n",
      "epoch:25 step:24155 [D loss: 0.526113, acc.: 74.22%] [G loss: 1.095461]\n",
      "epoch:25 step:24156 [D loss: 0.329564, acc.: 94.53%] [G loss: 1.372580]\n",
      "epoch:25 step:24157 [D loss: 0.407639, acc.: 85.94%] [G loss: 1.421253]\n",
      "epoch:25 step:24158 [D loss: 0.438793, acc.: 82.81%] [G loss: 1.213594]\n",
      "epoch:25 step:24159 [D loss: 0.690947, acc.: 57.81%] [G loss: 1.275727]\n",
      "epoch:25 step:24160 [D loss: 0.848157, acc.: 46.88%] [G loss: 1.059770]\n",
      "epoch:25 step:24161 [D loss: 0.642144, acc.: 60.94%] [G loss: 1.149470]\n",
      "epoch:25 step:24162 [D loss: 0.492529, acc.: 85.16%] [G loss: 0.948067]\n",
      "epoch:25 step:24163 [D loss: 0.534571, acc.: 74.22%] [G loss: 1.470068]\n",
      "epoch:25 step:24164 [D loss: 0.527898, acc.: 78.12%] [G loss: 1.166964]\n",
      "epoch:25 step:24165 [D loss: 0.553638, acc.: 70.31%] [G loss: 0.972597]\n",
      "epoch:25 step:24166 [D loss: 0.767692, acc.: 48.44%] [G loss: 1.077207]\n",
      "epoch:25 step:24167 [D loss: 0.684562, acc.: 59.38%] [G loss: 1.217791]\n",
      "epoch:25 step:24168 [D loss: 0.517344, acc.: 78.91%] [G loss: 1.084973]\n",
      "epoch:25 step:24169 [D loss: 0.631729, acc.: 63.28%] [G loss: 1.316863]\n",
      "epoch:25 step:24170 [D loss: 0.390540, acc.: 82.03%] [G loss: 1.349690]\n",
      "epoch:25 step:24171 [D loss: 0.553400, acc.: 72.66%] [G loss: 0.964912]\n",
      "epoch:25 step:24172 [D loss: 0.537915, acc.: 73.44%] [G loss: 1.110571]\n",
      "epoch:25 step:24173 [D loss: 0.557314, acc.: 74.22%] [G loss: 1.251069]\n",
      "epoch:25 step:24174 [D loss: 0.636930, acc.: 63.28%] [G loss: 1.013847]\n",
      "epoch:25 step:24175 [D loss: 0.520414, acc.: 76.56%] [G loss: 1.024660]\n",
      "epoch:25 step:24176 [D loss: 0.559643, acc.: 69.53%] [G loss: 0.897736]\n",
      "epoch:25 step:24177 [D loss: 0.824012, acc.: 44.53%] [G loss: 1.161406]\n",
      "epoch:25 step:24178 [D loss: 0.523875, acc.: 75.00%] [G loss: 1.082227]\n",
      "epoch:25 step:24179 [D loss: 0.531141, acc.: 76.56%] [G loss: 1.214448]\n",
      "epoch:25 step:24180 [D loss: 0.333729, acc.: 89.06%] [G loss: 1.453529]\n",
      "epoch:25 step:24181 [D loss: 0.424996, acc.: 87.50%] [G loss: 1.434657]\n",
      "epoch:25 step:24182 [D loss: 0.542065, acc.: 69.53%] [G loss: 1.025712]\n",
      "epoch:25 step:24183 [D loss: 0.372422, acc.: 87.50%] [G loss: 1.649225]\n",
      "epoch:25 step:24184 [D loss: 0.908668, acc.: 34.38%] [G loss: 0.738021]\n",
      "epoch:25 step:24185 [D loss: 0.757951, acc.: 48.44%] [G loss: 0.971285]\n",
      "epoch:25 step:24186 [D loss: 0.867017, acc.: 42.19%] [G loss: 0.882440]\n",
      "epoch:25 step:24187 [D loss: 0.748782, acc.: 53.91%] [G loss: 1.023968]\n",
      "epoch:25 step:24188 [D loss: 0.819865, acc.: 48.44%] [G loss: 0.575261]\n",
      "epoch:25 step:24189 [D loss: 0.556823, acc.: 71.09%] [G loss: 1.347970]\n",
      "epoch:25 step:24190 [D loss: 0.726247, acc.: 51.56%] [G loss: 1.137313]\n",
      "epoch:25 step:24191 [D loss: 0.574092, acc.: 66.41%] [G loss: 1.182580]\n",
      "epoch:25 step:24192 [D loss: 0.449551, acc.: 83.59%] [G loss: 0.957264]\n",
      "epoch:25 step:24193 [D loss: 0.356189, acc.: 92.19%] [G loss: 1.462798]\n",
      "epoch:25 step:24194 [D loss: 0.264948, acc.: 96.88%] [G loss: 1.503596]\n",
      "epoch:25 step:24195 [D loss: 0.441589, acc.: 85.16%] [G loss: 1.472269]\n",
      "epoch:25 step:24196 [D loss: 0.846743, acc.: 47.66%] [G loss: 1.342091]\n",
      "epoch:25 step:24197 [D loss: 0.606472, acc.: 65.62%] [G loss: 0.854982]\n",
      "epoch:25 step:24198 [D loss: 0.516056, acc.: 76.56%] [G loss: 1.241090]\n",
      "epoch:25 step:24199 [D loss: 0.297461, acc.: 85.94%] [G loss: 1.091600]\n",
      "epoch:25 step:24200 [D loss: 0.257432, acc.: 91.41%] [G loss: 1.251647]\n",
      "epoch:25 step:24201 [D loss: 0.327381, acc.: 90.62%] [G loss: 1.678502]\n",
      "epoch:25 step:24202 [D loss: 0.395291, acc.: 88.28%] [G loss: 1.233416]\n",
      "epoch:25 step:24203 [D loss: 0.621263, acc.: 66.41%] [G loss: 0.883038]\n",
      "epoch:25 step:24204 [D loss: 1.083152, acc.: 20.31%] [G loss: 0.822603]\n",
      "epoch:25 step:24205 [D loss: 0.542157, acc.: 77.34%] [G loss: 1.375228]\n",
      "epoch:25 step:24206 [D loss: 0.489224, acc.: 76.56%] [G loss: 1.178118]\n",
      "epoch:25 step:24207 [D loss: 0.577534, acc.: 67.19%] [G loss: 1.065093]\n",
      "epoch:25 step:24208 [D loss: 0.867502, acc.: 41.41%] [G loss: 1.652645]\n",
      "epoch:25 step:24209 [D loss: 0.837714, acc.: 43.75%] [G loss: 1.203505]\n",
      "epoch:25 step:24210 [D loss: 0.586072, acc.: 70.31%] [G loss: 0.886772]\n",
      "epoch:25 step:24211 [D loss: 0.492552, acc.: 68.75%] [G loss: 1.097839]\n",
      "epoch:25 step:24212 [D loss: 0.600590, acc.: 72.66%] [G loss: 1.147591]\n",
      "epoch:25 step:24213 [D loss: 0.637075, acc.: 66.41%] [G loss: 1.020041]\n",
      "epoch:25 step:24214 [D loss: 0.592619, acc.: 64.84%] [G loss: 1.244535]\n",
      "epoch:25 step:24215 [D loss: 0.400422, acc.: 86.72%] [G loss: 1.245261]\n",
      "epoch:25 step:24216 [D loss: 0.242389, acc.: 92.97%] [G loss: 1.656189]\n",
      "epoch:25 step:24217 [D loss: 0.269813, acc.: 93.75%] [G loss: 1.481931]\n",
      "epoch:25 step:24218 [D loss: 0.256743, acc.: 96.88%] [G loss: 1.759223]\n",
      "epoch:25 step:24219 [D loss: 0.168241, acc.: 98.44%] [G loss: 1.863385]\n",
      "epoch:25 step:24220 [D loss: 0.356653, acc.: 91.41%] [G loss: 1.785763]\n",
      "epoch:25 step:24221 [D loss: 0.361677, acc.: 88.28%] [G loss: 1.193630]\n",
      "epoch:25 step:24222 [D loss: 0.812924, acc.: 49.22%] [G loss: 1.115687]\n",
      "epoch:25 step:24223 [D loss: 0.353523, acc.: 90.62%] [G loss: 1.347105]\n",
      "epoch:25 step:24224 [D loss: 0.739515, acc.: 56.25%] [G loss: 1.137457]\n",
      "epoch:25 step:24225 [D loss: 1.004427, acc.: 37.50%] [G loss: 0.717603]\n",
      "epoch:25 step:24226 [D loss: 0.859207, acc.: 35.94%] [G loss: 0.921930]\n",
      "epoch:25 step:24227 [D loss: 0.800791, acc.: 49.22%] [G loss: 0.799486]\n",
      "epoch:25 step:24228 [D loss: 0.706987, acc.: 53.91%] [G loss: 1.174956]\n",
      "epoch:25 step:24229 [D loss: 0.618934, acc.: 61.72%] [G loss: 1.167935]\n",
      "epoch:25 step:24230 [D loss: 0.461410, acc.: 85.16%] [G loss: 1.178389]\n",
      "epoch:25 step:24231 [D loss: 0.304751, acc.: 96.09%] [G loss: 1.625932]\n",
      "epoch:25 step:24232 [D loss: 0.635519, acc.: 62.50%] [G loss: 1.255397]\n",
      "epoch:25 step:24233 [D loss: 0.727836, acc.: 55.47%] [G loss: 1.183680]\n",
      "epoch:25 step:24234 [D loss: 0.641490, acc.: 60.16%] [G loss: 1.378832]\n",
      "epoch:25 step:24235 [D loss: 0.487744, acc.: 78.91%] [G loss: 1.345652]\n",
      "epoch:25 step:24236 [D loss: 0.602279, acc.: 60.94%] [G loss: 1.254318]\n",
      "epoch:25 step:24237 [D loss: 0.610763, acc.: 64.06%] [G loss: 1.099932]\n",
      "epoch:25 step:24238 [D loss: 0.526209, acc.: 74.22%] [G loss: 1.092126]\n",
      "epoch:25 step:24239 [D loss: 0.415599, acc.: 82.03%] [G loss: 1.149232]\n",
      "epoch:25 step:24240 [D loss: 0.212239, acc.: 96.09%] [G loss: 1.648592]\n",
      "epoch:25 step:24241 [D loss: 0.164998, acc.: 98.44%] [G loss: 1.545345]\n",
      "epoch:25 step:24242 [D loss: 0.352548, acc.: 94.53%] [G loss: 1.967748]\n",
      "epoch:25 step:24243 [D loss: 0.362491, acc.: 89.06%] [G loss: 1.639545]\n",
      "epoch:25 step:24244 [D loss: 0.378032, acc.: 92.19%] [G loss: 1.319384]\n",
      "epoch:25 step:24245 [D loss: 0.854958, acc.: 42.97%] [G loss: 1.077029]\n",
      "epoch:25 step:24246 [D loss: 0.656038, acc.: 60.16%] [G loss: 1.092257]\n",
      "epoch:25 step:24247 [D loss: 0.755893, acc.: 51.56%] [G loss: 0.963324]\n",
      "epoch:25 step:24248 [D loss: 0.434891, acc.: 81.25%] [G loss: 1.563898]\n",
      "epoch:25 step:24249 [D loss: 0.403520, acc.: 75.78%] [G loss: 0.911834]\n",
      "epoch:25 step:24250 [D loss: 0.445041, acc.: 85.16%] [G loss: 1.840553]\n",
      "epoch:25 step:24251 [D loss: 0.656690, acc.: 60.94%] [G loss: 1.511945]\n",
      "epoch:25 step:24252 [D loss: 0.584155, acc.: 68.75%] [G loss: 1.338210]\n",
      "epoch:25 step:24253 [D loss: 0.595913, acc.: 71.09%] [G loss: 1.060882]\n",
      "epoch:25 step:24254 [D loss: 0.863163, acc.: 50.78%] [G loss: 0.731880]\n",
      "epoch:25 step:24255 [D loss: 0.522474, acc.: 75.00%] [G loss: 1.323436]\n",
      "epoch:25 step:24256 [D loss: 0.270235, acc.: 96.09%] [G loss: 1.311041]\n",
      "epoch:25 step:24257 [D loss: 0.378348, acc.: 90.62%] [G loss: 1.290761]\n",
      "epoch:25 step:24258 [D loss: 0.478799, acc.: 82.81%] [G loss: 1.278013]\n",
      "epoch:25 step:24259 [D loss: 1.050931, acc.: 39.06%] [G loss: 1.084240]\n",
      "epoch:25 step:24260 [D loss: 0.918488, acc.: 41.41%] [G loss: 1.111554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24261 [D loss: 0.865417, acc.: 41.41%] [G loss: 0.955997]\n",
      "epoch:25 step:24262 [D loss: 1.038678, acc.: 28.91%] [G loss: 0.855821]\n",
      "epoch:25 step:24263 [D loss: 0.745247, acc.: 53.12%] [G loss: 1.068469]\n",
      "epoch:25 step:24264 [D loss: 1.049404, acc.: 28.12%] [G loss: 1.023332]\n",
      "epoch:25 step:24265 [D loss: 0.590773, acc.: 68.75%] [G loss: 1.378753]\n",
      "epoch:25 step:24266 [D loss: 0.410088, acc.: 86.72%] [G loss: 1.678479]\n",
      "epoch:25 step:24267 [D loss: 0.412270, acc.: 88.28%] [G loss: 1.318492]\n",
      "epoch:25 step:24268 [D loss: 0.634208, acc.: 64.06%] [G loss: 1.124836]\n",
      "epoch:25 step:24269 [D loss: 0.753952, acc.: 49.22%] [G loss: 1.153823]\n",
      "epoch:25 step:24270 [D loss: 0.626607, acc.: 64.06%] [G loss: 1.039768]\n",
      "epoch:25 step:24271 [D loss: 0.641497, acc.: 64.84%] [G loss: 1.079368]\n",
      "epoch:25 step:24272 [D loss: 0.539455, acc.: 73.44%] [G loss: 1.094978]\n",
      "epoch:25 step:24273 [D loss: 0.455562, acc.: 80.47%] [G loss: 1.277637]\n",
      "epoch:25 step:24274 [D loss: 0.280012, acc.: 96.09%] [G loss: 1.648047]\n",
      "epoch:25 step:24275 [D loss: 0.297417, acc.: 92.97%] [G loss: 1.601692]\n",
      "epoch:25 step:24276 [D loss: 0.285921, acc.: 92.19%] [G loss: 2.059255]\n",
      "epoch:25 step:24277 [D loss: 0.166839, acc.: 99.22%] [G loss: 2.078544]\n",
      "epoch:25 step:24278 [D loss: 0.234082, acc.: 98.44%] [G loss: 2.076564]\n",
      "epoch:25 step:24279 [D loss: 0.173786, acc.: 100.00%] [G loss: 2.278431]\n",
      "epoch:25 step:24280 [D loss: 0.224614, acc.: 96.09%] [G loss: 1.560575]\n",
      "epoch:25 step:24281 [D loss: 0.357391, acc.: 91.41%] [G loss: 1.435724]\n",
      "epoch:25 step:24282 [D loss: 0.283463, acc.: 95.31%] [G loss: 1.581260]\n",
      "epoch:25 step:24283 [D loss: 0.978160, acc.: 47.66%] [G loss: 1.504429]\n",
      "epoch:25 step:24284 [D loss: 0.736104, acc.: 53.12%] [G loss: 1.121571]\n",
      "epoch:25 step:24285 [D loss: 0.554602, acc.: 71.09%] [G loss: 1.015060]\n",
      "epoch:25 step:24286 [D loss: 0.386731, acc.: 90.62%] [G loss: 1.300831]\n",
      "epoch:25 step:24287 [D loss: 0.744720, acc.: 53.12%] [G loss: 0.769160]\n",
      "epoch:25 step:24288 [D loss: 0.570107, acc.: 68.75%] [G loss: 1.205849]\n",
      "epoch:25 step:24289 [D loss: 0.695483, acc.: 57.81%] [G loss: 1.055642]\n",
      "epoch:25 step:24290 [D loss: 0.562073, acc.: 70.31%] [G loss: 1.058511]\n",
      "epoch:25 step:24291 [D loss: 0.497901, acc.: 79.69%] [G loss: 1.189157]\n",
      "epoch:25 step:24292 [D loss: 0.554587, acc.: 75.78%] [G loss: 1.160359]\n",
      "epoch:25 step:24293 [D loss: 0.536684, acc.: 74.22%] [G loss: 0.845768]\n",
      "epoch:25 step:24294 [D loss: 0.412187, acc.: 78.12%] [G loss: 1.110472]\n",
      "epoch:25 step:24295 [D loss: 0.718015, acc.: 50.00%] [G loss: 1.275377]\n",
      "epoch:25 step:24296 [D loss: 0.445407, acc.: 82.81%] [G loss: 1.115041]\n",
      "epoch:25 step:24297 [D loss: 0.410522, acc.: 84.38%] [G loss: 1.537556]\n",
      "epoch:25 step:24298 [D loss: 0.622313, acc.: 64.84%] [G loss: 1.135922]\n",
      "epoch:25 step:24299 [D loss: 0.793293, acc.: 49.22%] [G loss: 0.660734]\n",
      "epoch:25 step:24300 [D loss: 0.844423, acc.: 49.22%] [G loss: 1.053080]\n",
      "epoch:25 step:24301 [D loss: 0.816908, acc.: 38.28%] [G loss: 1.004222]\n",
      "epoch:25 step:24302 [D loss: 0.797385, acc.: 41.41%] [G loss: 1.416199]\n",
      "epoch:25 step:24303 [D loss: 0.583652, acc.: 68.75%] [G loss: 1.421968]\n",
      "epoch:25 step:24304 [D loss: 0.784449, acc.: 46.88%] [G loss: 1.100889]\n",
      "epoch:25 step:24305 [D loss: 0.516652, acc.: 74.22%] [G loss: 1.495985]\n",
      "epoch:25 step:24306 [D loss: 0.560999, acc.: 75.00%] [G loss: 1.175822]\n",
      "epoch:25 step:24307 [D loss: 0.744684, acc.: 51.56%] [G loss: 0.964140]\n",
      "epoch:25 step:24308 [D loss: 0.602235, acc.: 69.53%] [G loss: 1.631017]\n",
      "epoch:25 step:24309 [D loss: 0.517344, acc.: 71.09%] [G loss: 1.315661]\n",
      "epoch:25 step:24310 [D loss: 0.553791, acc.: 71.09%] [G loss: 1.066805]\n",
      "epoch:25 step:24311 [D loss: 0.600357, acc.: 71.09%] [G loss: 1.303446]\n",
      "epoch:25 step:24312 [D loss: 0.539728, acc.: 68.75%] [G loss: 1.555133]\n",
      "epoch:25 step:24313 [D loss: 0.661726, acc.: 63.28%] [G loss: 1.544658]\n",
      "epoch:25 step:24314 [D loss: 0.792792, acc.: 47.66%] [G loss: 0.891758]\n",
      "epoch:25 step:24315 [D loss: 0.675519, acc.: 60.16%] [G loss: 0.915785]\n",
      "epoch:25 step:24316 [D loss: 1.114689, acc.: 29.69%] [G loss: 1.042327]\n",
      "epoch:25 step:24317 [D loss: 0.539907, acc.: 73.44%] [G loss: 1.176113]\n",
      "epoch:25 step:24318 [D loss: 0.335857, acc.: 92.97%] [G loss: 1.719111]\n",
      "epoch:25 step:24319 [D loss: 0.323817, acc.: 94.53%] [G loss: 1.617161]\n",
      "epoch:25 step:24320 [D loss: 0.355831, acc.: 89.84%] [G loss: 1.708290]\n",
      "epoch:25 step:24321 [D loss: 0.192229, acc.: 100.00%] [G loss: 2.046911]\n",
      "epoch:25 step:24322 [D loss: 0.266486, acc.: 96.09%] [G loss: 1.335743]\n",
      "epoch:25 step:24323 [D loss: 0.156559, acc.: 98.44%] [G loss: 1.994790]\n",
      "epoch:25 step:24324 [D loss: 0.141428, acc.: 99.22%] [G loss: 2.115565]\n",
      "epoch:25 step:24325 [D loss: 0.144168, acc.: 99.22%] [G loss: 1.985528]\n",
      "epoch:25 step:24326 [D loss: 0.250447, acc.: 95.31%] [G loss: 1.915971]\n",
      "epoch:25 step:24327 [D loss: 0.462235, acc.: 82.03%] [G loss: 1.673581]\n",
      "epoch:25 step:24328 [D loss: 0.231885, acc.: 96.09%] [G loss: 2.114567]\n",
      "epoch:25 step:24329 [D loss: 0.936344, acc.: 45.31%] [G loss: 0.985895]\n",
      "epoch:25 step:24330 [D loss: 0.641785, acc.: 64.84%] [G loss: 1.027716]\n",
      "epoch:25 step:24331 [D loss: 0.857569, acc.: 42.19%] [G loss: 0.857218]\n",
      "epoch:25 step:24332 [D loss: 0.528495, acc.: 71.09%] [G loss: 1.127816]\n",
      "epoch:25 step:24333 [D loss: 0.512505, acc.: 76.56%] [G loss: 1.256833]\n",
      "epoch:25 step:24334 [D loss: 0.303361, acc.: 92.19%] [G loss: 1.504625]\n",
      "epoch:25 step:24335 [D loss: 0.707361, acc.: 57.81%] [G loss: 1.254625]\n",
      "epoch:25 step:24336 [D loss: 0.287585, acc.: 88.28%] [G loss: 1.250357]\n",
      "epoch:25 step:24337 [D loss: 0.251384, acc.: 88.28%] [G loss: 1.409187]\n",
      "epoch:25 step:24338 [D loss: 0.774919, acc.: 54.69%] [G loss: 1.691632]\n",
      "epoch:25 step:24339 [D loss: 1.148237, acc.: 23.44%] [G loss: 0.681319]\n",
      "epoch:25 step:24340 [D loss: 0.751192, acc.: 51.56%] [G loss: 1.232939]\n",
      "epoch:25 step:24341 [D loss: 0.928735, acc.: 36.72%] [G loss: 0.771536]\n",
      "epoch:25 step:24342 [D loss: 1.036864, acc.: 21.09%] [G loss: 0.445659]\n",
      "epoch:25 step:24343 [D loss: 0.834602, acc.: 46.09%] [G loss: 0.807650]\n",
      "epoch:25 step:24344 [D loss: 0.506508, acc.: 72.66%] [G loss: 1.008175]\n",
      "epoch:25 step:24345 [D loss: 0.749410, acc.: 58.59%] [G loss: 1.335182]\n",
      "epoch:25 step:24346 [D loss: 0.686396, acc.: 57.03%] [G loss: 1.580242]\n",
      "epoch:25 step:24347 [D loss: 0.815945, acc.: 45.31%] [G loss: 1.088188]\n",
      "epoch:25 step:24348 [D loss: 0.665725, acc.: 57.81%] [G loss: 0.931350]\n",
      "epoch:25 step:24349 [D loss: 0.498220, acc.: 80.47%] [G loss: 1.366903]\n",
      "epoch:25 step:24350 [D loss: 0.636894, acc.: 66.41%] [G loss: 1.431198]\n",
      "epoch:25 step:24351 [D loss: 0.472104, acc.: 78.91%] [G loss: 1.565663]\n",
      "epoch:25 step:24352 [D loss: 0.506278, acc.: 77.34%] [G loss: 1.213613]\n",
      "epoch:25 step:24353 [D loss: 0.973976, acc.: 50.00%] [G loss: 1.737936]\n",
      "epoch:25 step:24354 [D loss: 0.546095, acc.: 76.56%] [G loss: 1.232384]\n",
      "epoch:25 step:24355 [D loss: 0.494608, acc.: 76.56%] [G loss: 1.443881]\n",
      "epoch:25 step:24356 [D loss: 0.779200, acc.: 49.22%] [G loss: 1.208728]\n",
      "epoch:25 step:24357 [D loss: 0.635221, acc.: 60.16%] [G loss: 1.267200]\n",
      "epoch:25 step:24358 [D loss: 0.644008, acc.: 65.62%] [G loss: 1.053638]\n",
      "epoch:25 step:24359 [D loss: 0.467509, acc.: 78.12%] [G loss: 1.255917]\n",
      "epoch:25 step:24360 [D loss: 0.655921, acc.: 57.81%] [G loss: 1.007206]\n",
      "epoch:25 step:24361 [D loss: 0.474085, acc.: 80.47%] [G loss: 1.092571]\n",
      "epoch:25 step:24362 [D loss: 0.242497, acc.: 91.41%] [G loss: 1.237896]\n",
      "epoch:26 step:24363 [D loss: 0.852642, acc.: 48.44%] [G loss: 1.267613]\n",
      "epoch:26 step:24364 [D loss: 0.742768, acc.: 52.34%] [G loss: 1.259412]\n",
      "epoch:26 step:24365 [D loss: 0.690852, acc.: 57.03%] [G loss: 0.890776]\n",
      "epoch:26 step:24366 [D loss: 0.488997, acc.: 80.47%] [G loss: 1.124973]\n",
      "epoch:26 step:24367 [D loss: 0.577387, acc.: 69.53%] [G loss: 1.316874]\n",
      "epoch:26 step:24368 [D loss: 0.450862, acc.: 84.38%] [G loss: 1.051460]\n",
      "epoch:26 step:24369 [D loss: 0.652502, acc.: 65.62%] [G loss: 1.155364]\n",
      "epoch:26 step:24370 [D loss: 0.659183, acc.: 62.50%] [G loss: 1.060060]\n",
      "epoch:26 step:24371 [D loss: 0.600431, acc.: 70.31%] [G loss: 1.213913]\n",
      "epoch:26 step:24372 [D loss: 0.761492, acc.: 53.91%] [G loss: 1.065082]\n",
      "epoch:26 step:24373 [D loss: 0.737889, acc.: 51.56%] [G loss: 1.093435]\n",
      "epoch:26 step:24374 [D loss: 0.724279, acc.: 51.56%] [G loss: 0.798373]\n",
      "epoch:26 step:24375 [D loss: 0.581281, acc.: 67.97%] [G loss: 1.228096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24376 [D loss: 0.625403, acc.: 62.50%] [G loss: 1.170688]\n",
      "epoch:26 step:24377 [D loss: 0.490813, acc.: 77.34%] [G loss: 1.115275]\n",
      "epoch:26 step:24378 [D loss: 0.475240, acc.: 81.25%] [G loss: 1.231938]\n",
      "epoch:26 step:24379 [D loss: 0.646699, acc.: 65.62%] [G loss: 1.098318]\n",
      "epoch:26 step:24380 [D loss: 0.681166, acc.: 57.81%] [G loss: 1.041842]\n",
      "epoch:26 step:24381 [D loss: 0.731718, acc.: 52.34%] [G loss: 1.139366]\n",
      "epoch:26 step:24382 [D loss: 0.520698, acc.: 71.09%] [G loss: 1.023539]\n",
      "epoch:26 step:24383 [D loss: 0.563006, acc.: 71.88%] [G loss: 1.191442]\n",
      "epoch:26 step:24384 [D loss: 0.625154, acc.: 65.62%] [G loss: 1.043325]\n",
      "epoch:26 step:24385 [D loss: 0.551302, acc.: 72.66%] [G loss: 1.131202]\n",
      "epoch:26 step:24386 [D loss: 0.668167, acc.: 60.16%] [G loss: 0.846567]\n",
      "epoch:26 step:24387 [D loss: 0.587026, acc.: 67.19%] [G loss: 1.049256]\n",
      "epoch:26 step:24388 [D loss: 0.414109, acc.: 86.72%] [G loss: 0.864911]\n",
      "epoch:26 step:24389 [D loss: 0.417847, acc.: 82.03%] [G loss: 1.411141]\n",
      "epoch:26 step:24390 [D loss: 0.378381, acc.: 91.41%] [G loss: 1.373932]\n",
      "epoch:26 step:24391 [D loss: 0.350860, acc.: 94.53%] [G loss: 1.626971]\n",
      "epoch:26 step:24392 [D loss: 0.339719, acc.: 92.97%] [G loss: 1.569657]\n",
      "epoch:26 step:24393 [D loss: 0.285906, acc.: 94.53%] [G loss: 1.763079]\n",
      "epoch:26 step:24394 [D loss: 0.270438, acc.: 93.75%] [G loss: 1.620474]\n",
      "epoch:26 step:24395 [D loss: 0.162836, acc.: 100.00%] [G loss: 1.949970]\n",
      "epoch:26 step:24396 [D loss: 0.301356, acc.: 90.62%] [G loss: 1.832742]\n",
      "epoch:26 step:24397 [D loss: 0.297348, acc.: 88.28%] [G loss: 1.719247]\n",
      "epoch:26 step:24398 [D loss: 0.133841, acc.: 99.22%] [G loss: 2.319386]\n",
      "epoch:26 step:24399 [D loss: 0.985305, acc.: 45.31%] [G loss: 1.320796]\n",
      "epoch:26 step:24400 [D loss: 0.899933, acc.: 43.75%] [G loss: 0.930762]\n",
      "epoch:26 step:24401 [D loss: 0.647440, acc.: 62.50%] [G loss: 1.040799]\n",
      "epoch:26 step:24402 [D loss: 0.674177, acc.: 60.16%] [G loss: 0.914461]\n",
      "epoch:26 step:24403 [D loss: 0.699446, acc.: 62.50%] [G loss: 1.178144]\n",
      "epoch:26 step:24404 [D loss: 0.432150, acc.: 87.50%] [G loss: 1.206942]\n",
      "epoch:26 step:24405 [D loss: 0.461207, acc.: 81.25%] [G loss: 1.033266]\n",
      "epoch:26 step:24406 [D loss: 0.521710, acc.: 74.22%] [G loss: 1.221227]\n",
      "epoch:26 step:24407 [D loss: 0.510674, acc.: 78.12%] [G loss: 1.164276]\n",
      "epoch:26 step:24408 [D loss: 0.708406, acc.: 53.91%] [G loss: 0.983101]\n",
      "epoch:26 step:24409 [D loss: 0.935325, acc.: 35.94%] [G loss: 0.763645]\n",
      "epoch:26 step:24410 [D loss: 0.681522, acc.: 57.81%] [G loss: 1.216505]\n",
      "epoch:26 step:24411 [D loss: 0.833721, acc.: 40.62%] [G loss: 1.012661]\n",
      "epoch:26 step:24412 [D loss: 0.646943, acc.: 63.28%] [G loss: 1.544860]\n",
      "epoch:26 step:24413 [D loss: 0.589319, acc.: 71.88%] [G loss: 1.142971]\n",
      "epoch:26 step:24414 [D loss: 0.770069, acc.: 47.66%] [G loss: 0.927989]\n",
      "epoch:26 step:24415 [D loss: 0.631105, acc.: 61.72%] [G loss: 1.074264]\n",
      "epoch:26 step:24416 [D loss: 0.659862, acc.: 57.03%] [G loss: 1.104079]\n",
      "epoch:26 step:24417 [D loss: 0.487722, acc.: 78.91%] [G loss: 1.068363]\n",
      "epoch:26 step:24418 [D loss: 0.557554, acc.: 70.31%] [G loss: 1.217391]\n",
      "epoch:26 step:24419 [D loss: 0.781978, acc.: 47.66%] [G loss: 1.173098]\n",
      "epoch:26 step:24420 [D loss: 0.710483, acc.: 51.56%] [G loss: 1.078371]\n",
      "epoch:26 step:24421 [D loss: 0.591840, acc.: 67.19%] [G loss: 1.250264]\n",
      "epoch:26 step:24422 [D loss: 0.653824, acc.: 56.25%] [G loss: 1.049889]\n",
      "epoch:26 step:24423 [D loss: 0.667288, acc.: 59.38%] [G loss: 1.028984]\n",
      "epoch:26 step:24424 [D loss: 0.599544, acc.: 73.44%] [G loss: 1.075821]\n",
      "epoch:26 step:24425 [D loss: 0.654295, acc.: 60.16%] [G loss: 1.236348]\n",
      "epoch:26 step:24426 [D loss: 0.628436, acc.: 67.97%] [G loss: 0.935006]\n",
      "epoch:26 step:24427 [D loss: 0.587548, acc.: 74.22%] [G loss: 1.172820]\n",
      "epoch:26 step:24428 [D loss: 0.628432, acc.: 63.28%] [G loss: 0.970026]\n",
      "epoch:26 step:24429 [D loss: 0.582871, acc.: 72.66%] [G loss: 1.007496]\n",
      "epoch:26 step:24430 [D loss: 0.463288, acc.: 78.91%] [G loss: 1.247865]\n",
      "epoch:26 step:24431 [D loss: 0.427870, acc.: 83.59%] [G loss: 1.263665]\n",
      "epoch:26 step:24432 [D loss: 0.398818, acc.: 89.84%] [G loss: 1.450374]\n",
      "epoch:26 step:24433 [D loss: 0.669870, acc.: 62.50%] [G loss: 1.122424]\n",
      "epoch:26 step:24434 [D loss: 0.600302, acc.: 69.53%] [G loss: 1.062135]\n",
      "epoch:26 step:24435 [D loss: 0.664309, acc.: 64.06%] [G loss: 1.258126]\n",
      "epoch:26 step:24436 [D loss: 0.625922, acc.: 71.09%] [G loss: 0.779290]\n",
      "epoch:26 step:24437 [D loss: 0.245006, acc.: 94.53%] [G loss: 1.425372]\n",
      "epoch:26 step:24438 [D loss: 0.333371, acc.: 92.19%] [G loss: 1.492568]\n",
      "epoch:26 step:24439 [D loss: 0.369489, acc.: 90.62%] [G loss: 1.729337]\n",
      "epoch:26 step:24440 [D loss: 0.636392, acc.: 61.72%] [G loss: 1.499350]\n",
      "epoch:26 step:24441 [D loss: 0.691559, acc.: 52.34%] [G loss: 1.184181]\n",
      "epoch:26 step:24442 [D loss: 0.795520, acc.: 44.53%] [G loss: 1.010089]\n",
      "epoch:26 step:24443 [D loss: 0.553992, acc.: 77.34%] [G loss: 1.133121]\n",
      "epoch:26 step:24444 [D loss: 0.569314, acc.: 73.44%] [G loss: 1.028434]\n",
      "epoch:26 step:24445 [D loss: 0.507747, acc.: 80.47%] [G loss: 0.954201]\n",
      "epoch:26 step:24446 [D loss: 0.659736, acc.: 62.50%] [G loss: 1.055889]\n",
      "epoch:26 step:24447 [D loss: 0.680469, acc.: 58.59%] [G loss: 0.777003]\n",
      "epoch:26 step:24448 [D loss: 0.625491, acc.: 63.28%] [G loss: 1.068419]\n",
      "epoch:26 step:24449 [D loss: 0.532008, acc.: 77.34%] [G loss: 0.997188]\n",
      "epoch:26 step:24450 [D loss: 0.491744, acc.: 78.91%] [G loss: 1.343884]\n",
      "epoch:26 step:24451 [D loss: 0.507409, acc.: 79.69%] [G loss: 1.239936]\n",
      "epoch:26 step:24452 [D loss: 0.528775, acc.: 79.69%] [G loss: 1.364120]\n",
      "epoch:26 step:24453 [D loss: 0.577767, acc.: 74.22%] [G loss: 1.326763]\n",
      "epoch:26 step:24454 [D loss: 0.570598, acc.: 70.31%] [G loss: 1.008653]\n",
      "epoch:26 step:24455 [D loss: 0.535382, acc.: 79.69%] [G loss: 1.128929]\n",
      "epoch:26 step:24456 [D loss: 0.574033, acc.: 68.75%] [G loss: 1.171786]\n",
      "epoch:26 step:24457 [D loss: 0.767895, acc.: 49.22%] [G loss: 1.033662]\n",
      "epoch:26 step:24458 [D loss: 0.646889, acc.: 66.41%] [G loss: 0.971277]\n",
      "epoch:26 step:24459 [D loss: 0.699768, acc.: 62.50%] [G loss: 1.109308]\n",
      "epoch:26 step:24460 [D loss: 0.736758, acc.: 53.12%] [G loss: 0.967765]\n",
      "epoch:26 step:24461 [D loss: 0.848673, acc.: 40.62%] [G loss: 1.026327]\n",
      "epoch:26 step:24462 [D loss: 0.623733, acc.: 63.28%] [G loss: 0.980275]\n",
      "epoch:26 step:24463 [D loss: 0.686847, acc.: 56.25%] [G loss: 1.024490]\n",
      "epoch:26 step:24464 [D loss: 0.495022, acc.: 82.03%] [G loss: 1.156440]\n",
      "epoch:26 step:24465 [D loss: 0.668681, acc.: 63.28%] [G loss: 0.927007]\n",
      "epoch:26 step:24466 [D loss: 0.648898, acc.: 62.50%] [G loss: 0.933806]\n",
      "epoch:26 step:24467 [D loss: 0.461097, acc.: 79.69%] [G loss: 0.992177]\n",
      "epoch:26 step:24468 [D loss: 0.530189, acc.: 77.34%] [G loss: 1.112009]\n",
      "epoch:26 step:24469 [D loss: 0.780142, acc.: 53.91%] [G loss: 0.910273]\n",
      "epoch:26 step:24470 [D loss: 0.452898, acc.: 83.59%] [G loss: 1.292704]\n",
      "epoch:26 step:24471 [D loss: 0.504379, acc.: 79.69%] [G loss: 1.048034]\n",
      "epoch:26 step:24472 [D loss: 0.499772, acc.: 80.47%] [G loss: 1.400332]\n",
      "epoch:26 step:24473 [D loss: 0.542870, acc.: 73.44%] [G loss: 1.486938]\n",
      "epoch:26 step:24474 [D loss: 0.627974, acc.: 62.50%] [G loss: 1.011028]\n",
      "epoch:26 step:24475 [D loss: 0.694258, acc.: 60.16%] [G loss: 1.136370]\n",
      "epoch:26 step:24476 [D loss: 0.980586, acc.: 34.38%] [G loss: 1.086759]\n",
      "epoch:26 step:24477 [D loss: 0.948995, acc.: 28.91%] [G loss: 0.796140]\n",
      "epoch:26 step:24478 [D loss: 0.533603, acc.: 73.44%] [G loss: 1.234051]\n",
      "epoch:26 step:24479 [D loss: 0.323107, acc.: 92.19%] [G loss: 1.290525]\n",
      "epoch:26 step:24480 [D loss: 0.423633, acc.: 87.50%] [G loss: 1.782855]\n",
      "epoch:26 step:24481 [D loss: 0.203469, acc.: 97.66%] [G loss: 1.882256]\n",
      "epoch:26 step:24482 [D loss: 0.918411, acc.: 47.66%] [G loss: 1.309880]\n",
      "epoch:26 step:24483 [D loss: 0.647378, acc.: 64.06%] [G loss: 1.253736]\n",
      "epoch:26 step:24484 [D loss: 0.516656, acc.: 72.66%] [G loss: 1.538695]\n",
      "epoch:26 step:24485 [D loss: 0.671345, acc.: 57.81%] [G loss: 1.750011]\n",
      "epoch:26 step:24486 [D loss: 0.593244, acc.: 67.97%] [G loss: 1.223054]\n",
      "epoch:26 step:24487 [D loss: 0.601336, acc.: 68.75%] [G loss: 1.163070]\n",
      "epoch:26 step:24488 [D loss: 0.567536, acc.: 72.66%] [G loss: 1.059996]\n",
      "epoch:26 step:24489 [D loss: 0.677285, acc.: 61.72%] [G loss: 1.246683]\n",
      "epoch:26 step:24490 [D loss: 0.722138, acc.: 61.72%] [G loss: 1.037614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24491 [D loss: 0.534907, acc.: 73.44%] [G loss: 1.135617]\n",
      "epoch:26 step:24492 [D loss: 0.414618, acc.: 80.47%] [G loss: 1.120509]\n",
      "epoch:26 step:24493 [D loss: 0.390081, acc.: 89.06%] [G loss: 1.560450]\n",
      "epoch:26 step:24494 [D loss: 0.389295, acc.: 89.06%] [G loss: 1.613008]\n",
      "epoch:26 step:24495 [D loss: 0.762937, acc.: 53.91%] [G loss: 1.398685]\n",
      "epoch:26 step:24496 [D loss: 0.812819, acc.: 41.41%] [G loss: 1.005909]\n",
      "epoch:26 step:24497 [D loss: 0.831042, acc.: 42.97%] [G loss: 0.999860]\n",
      "epoch:26 step:24498 [D loss: 0.711350, acc.: 53.12%] [G loss: 0.967550]\n",
      "epoch:26 step:24499 [D loss: 0.510437, acc.: 78.12%] [G loss: 0.931320]\n",
      "epoch:26 step:24500 [D loss: 0.517692, acc.: 75.00%] [G loss: 1.288390]\n",
      "epoch:26 step:24501 [D loss: 0.363222, acc.: 88.28%] [G loss: 1.138273]\n",
      "epoch:26 step:24502 [D loss: 0.735590, acc.: 53.91%] [G loss: 0.959350]\n",
      "epoch:26 step:24503 [D loss: 0.775683, acc.: 46.09%] [G loss: 0.859981]\n",
      "epoch:26 step:24504 [D loss: 0.684091, acc.: 55.47%] [G loss: 0.912918]\n",
      "epoch:26 step:24505 [D loss: 0.450418, acc.: 84.38%] [G loss: 1.208855]\n",
      "epoch:26 step:24506 [D loss: 0.619692, acc.: 61.72%] [G loss: 1.108736]\n",
      "epoch:26 step:24507 [D loss: 0.454704, acc.: 84.38%] [G loss: 1.200454]\n",
      "epoch:26 step:24508 [D loss: 0.651898, acc.: 57.81%] [G loss: 1.074045]\n",
      "epoch:26 step:24509 [D loss: 0.690763, acc.: 59.38%] [G loss: 1.170460]\n",
      "epoch:26 step:24510 [D loss: 0.711369, acc.: 58.59%] [G loss: 1.090541]\n",
      "epoch:26 step:24511 [D loss: 0.799146, acc.: 44.53%] [G loss: 0.751453]\n",
      "epoch:26 step:24512 [D loss: 0.427112, acc.: 84.38%] [G loss: 1.388839]\n",
      "epoch:26 step:24513 [D loss: 0.336717, acc.: 90.62%] [G loss: 1.492317]\n",
      "epoch:26 step:24514 [D loss: 0.380438, acc.: 86.72%] [G loss: 1.504359]\n",
      "epoch:26 step:24515 [D loss: 0.714494, acc.: 54.69%] [G loss: 1.263252]\n",
      "epoch:26 step:24516 [D loss: 0.661076, acc.: 58.59%] [G loss: 1.061593]\n",
      "epoch:26 step:24517 [D loss: 0.608634, acc.: 67.97%] [G loss: 1.125301]\n",
      "epoch:26 step:24518 [D loss: 0.511285, acc.: 75.78%] [G loss: 1.171353]\n",
      "epoch:26 step:24519 [D loss: 0.646538, acc.: 62.50%] [G loss: 1.477022]\n",
      "epoch:26 step:24520 [D loss: 0.550175, acc.: 70.31%] [G loss: 0.996299]\n",
      "epoch:26 step:24521 [D loss: 0.450645, acc.: 83.59%] [G loss: 1.332732]\n",
      "epoch:26 step:24522 [D loss: 0.782276, acc.: 50.78%] [G loss: 1.239936]\n",
      "epoch:26 step:24523 [D loss: 0.645369, acc.: 63.28%] [G loss: 1.026095]\n",
      "epoch:26 step:24524 [D loss: 0.694399, acc.: 54.69%] [G loss: 1.086622]\n",
      "epoch:26 step:24525 [D loss: 0.685634, acc.: 58.59%] [G loss: 0.906756]\n",
      "epoch:26 step:24526 [D loss: 0.554565, acc.: 72.66%] [G loss: 1.026400]\n",
      "epoch:26 step:24527 [D loss: 0.532230, acc.: 77.34%] [G loss: 1.020615]\n",
      "epoch:26 step:24528 [D loss: 0.594668, acc.: 65.62%] [G loss: 1.177755]\n",
      "epoch:26 step:24529 [D loss: 0.513817, acc.: 79.69%] [G loss: 1.153067]\n",
      "epoch:26 step:24530 [D loss: 0.582094, acc.: 68.75%] [G loss: 1.333442]\n",
      "epoch:26 step:24531 [D loss: 0.609828, acc.: 67.97%] [G loss: 1.073808]\n",
      "epoch:26 step:24532 [D loss: 0.976380, acc.: 31.25%] [G loss: 0.760835]\n",
      "epoch:26 step:24533 [D loss: 0.580793, acc.: 72.66%] [G loss: 1.115153]\n",
      "epoch:26 step:24534 [D loss: 0.560284, acc.: 71.09%] [G loss: 1.166370]\n",
      "epoch:26 step:24535 [D loss: 0.924178, acc.: 39.84%] [G loss: 0.738206]\n",
      "epoch:26 step:24536 [D loss: 0.747981, acc.: 46.88%] [G loss: 0.961537]\n",
      "epoch:26 step:24537 [D loss: 0.663088, acc.: 59.38%] [G loss: 0.976628]\n",
      "epoch:26 step:24538 [D loss: 0.779059, acc.: 43.75%] [G loss: 0.669521]\n",
      "epoch:26 step:24539 [D loss: 0.800079, acc.: 40.62%] [G loss: 0.847708]\n",
      "epoch:26 step:24540 [D loss: 0.672633, acc.: 65.62%] [G loss: 1.254296]\n",
      "epoch:26 step:24541 [D loss: 0.705554, acc.: 53.12%] [G loss: 0.982870]\n",
      "epoch:26 step:24542 [D loss: 0.610281, acc.: 65.62%] [G loss: 1.214869]\n",
      "epoch:26 step:24543 [D loss: 0.697344, acc.: 57.03%] [G loss: 0.929799]\n",
      "epoch:26 step:24544 [D loss: 0.556937, acc.: 75.78%] [G loss: 0.964961]\n",
      "epoch:26 step:24545 [D loss: 0.659321, acc.: 62.50%] [G loss: 0.959137]\n",
      "epoch:26 step:24546 [D loss: 0.685395, acc.: 60.94%] [G loss: 0.843265]\n",
      "epoch:26 step:24547 [D loss: 0.671678, acc.: 57.03%] [G loss: 1.476288]\n",
      "epoch:26 step:24548 [D loss: 0.790261, acc.: 40.62%] [G loss: 0.804498]\n",
      "epoch:26 step:24549 [D loss: 0.700389, acc.: 52.34%] [G loss: 1.280673]\n",
      "epoch:26 step:24550 [D loss: 0.632814, acc.: 64.06%] [G loss: 0.761132]\n",
      "epoch:26 step:24551 [D loss: 0.645268, acc.: 60.94%] [G loss: 1.108976]\n",
      "epoch:26 step:24552 [D loss: 0.509681, acc.: 79.69%] [G loss: 1.286257]\n",
      "epoch:26 step:24553 [D loss: 0.714452, acc.: 50.00%] [G loss: 1.160593]\n",
      "epoch:26 step:24554 [D loss: 0.498923, acc.: 71.88%] [G loss: 1.043193]\n",
      "epoch:26 step:24555 [D loss: 0.639915, acc.: 64.84%] [G loss: 0.913524]\n",
      "epoch:26 step:24556 [D loss: 0.578668, acc.: 70.31%] [G loss: 1.358564]\n",
      "epoch:26 step:24557 [D loss: 0.646121, acc.: 57.81%] [G loss: 1.186890]\n",
      "epoch:26 step:24558 [D loss: 0.728762, acc.: 53.91%] [G loss: 1.064000]\n",
      "epoch:26 step:24559 [D loss: 0.617638, acc.: 67.19%] [G loss: 1.093955]\n",
      "epoch:26 step:24560 [D loss: 0.717299, acc.: 57.81%] [G loss: 0.996262]\n",
      "epoch:26 step:24561 [D loss: 0.974213, acc.: 25.00%] [G loss: 0.846022]\n",
      "epoch:26 step:24562 [D loss: 0.708200, acc.: 56.25%] [G loss: 0.860475]\n",
      "epoch:26 step:24563 [D loss: 0.449524, acc.: 80.47%] [G loss: 1.148495]\n",
      "epoch:26 step:24564 [D loss: 0.710055, acc.: 52.34%] [G loss: 1.622541]\n",
      "epoch:26 step:24565 [D loss: 0.732813, acc.: 48.44%] [G loss: 1.095663]\n",
      "epoch:26 step:24566 [D loss: 0.846925, acc.: 42.19%] [G loss: 0.628076]\n",
      "epoch:26 step:24567 [D loss: 0.718894, acc.: 56.25%] [G loss: 1.188837]\n",
      "epoch:26 step:24568 [D loss: 0.575281, acc.: 70.31%] [G loss: 1.068093]\n",
      "epoch:26 step:24569 [D loss: 0.451813, acc.: 85.16%] [G loss: 1.131817]\n",
      "epoch:26 step:24570 [D loss: 0.581199, acc.: 71.88%] [G loss: 1.112337]\n",
      "epoch:26 step:24571 [D loss: 0.548151, acc.: 74.22%] [G loss: 1.422579]\n",
      "epoch:26 step:24572 [D loss: 0.719723, acc.: 51.56%] [G loss: 1.115378]\n",
      "epoch:26 step:24573 [D loss: 0.523979, acc.: 75.00%] [G loss: 1.093142]\n",
      "epoch:26 step:24574 [D loss: 0.713837, acc.: 50.78%] [G loss: 0.980203]\n",
      "epoch:26 step:24575 [D loss: 0.524412, acc.: 78.91%] [G loss: 1.102498]\n",
      "epoch:26 step:24576 [D loss: 0.670183, acc.: 57.81%] [G loss: 1.053009]\n",
      "epoch:26 step:24577 [D loss: 0.523687, acc.: 72.66%] [G loss: 0.794959]\n",
      "epoch:26 step:24578 [D loss: 0.536406, acc.: 73.44%] [G loss: 1.457153]\n",
      "epoch:26 step:24579 [D loss: 0.772883, acc.: 46.88%] [G loss: 0.986960]\n",
      "epoch:26 step:24580 [D loss: 0.548156, acc.: 77.34%] [G loss: 1.155442]\n",
      "epoch:26 step:24581 [D loss: 0.627726, acc.: 65.62%] [G loss: 1.099689]\n",
      "epoch:26 step:24582 [D loss: 0.249723, acc.: 94.53%] [G loss: 1.613499]\n",
      "epoch:26 step:24583 [D loss: 0.294372, acc.: 91.41%] [G loss: 1.393191]\n",
      "epoch:26 step:24584 [D loss: 0.295458, acc.: 94.53%] [G loss: 1.651591]\n",
      "epoch:26 step:24585 [D loss: 0.250359, acc.: 95.31%] [G loss: 1.521951]\n",
      "epoch:26 step:24586 [D loss: 0.727521, acc.: 59.38%] [G loss: 1.581096]\n",
      "epoch:26 step:24587 [D loss: 0.764672, acc.: 53.91%] [G loss: 1.504177]\n",
      "epoch:26 step:24588 [D loss: 0.533144, acc.: 75.00%] [G loss: 1.178091]\n",
      "epoch:26 step:24589 [D loss: 0.737605, acc.: 45.31%] [G loss: 0.946525]\n",
      "epoch:26 step:24590 [D loss: 0.521270, acc.: 78.91%] [G loss: 1.080327]\n",
      "epoch:26 step:24591 [D loss: 0.602942, acc.: 69.53%] [G loss: 1.273470]\n",
      "epoch:26 step:24592 [D loss: 0.217840, acc.: 92.97%] [G loss: 1.578019]\n",
      "epoch:26 step:24593 [D loss: 0.281987, acc.: 94.53%] [G loss: 1.877250]\n",
      "epoch:26 step:24594 [D loss: 0.442603, acc.: 82.03%] [G loss: 1.435159]\n",
      "epoch:26 step:24595 [D loss: 0.979532, acc.: 50.00%] [G loss: 1.733735]\n",
      "epoch:26 step:24596 [D loss: 0.870102, acc.: 49.22%] [G loss: 1.237340]\n",
      "epoch:26 step:24597 [D loss: 0.363781, acc.: 89.06%] [G loss: 1.410971]\n",
      "epoch:26 step:24598 [D loss: 0.623624, acc.: 60.94%] [G loss: 0.879537]\n",
      "epoch:26 step:24599 [D loss: 0.658295, acc.: 60.94%] [G loss: 0.778177]\n",
      "epoch:26 step:24600 [D loss: 0.770464, acc.: 53.91%] [G loss: 0.891676]\n",
      "epoch:26 step:24601 [D loss: 0.726055, acc.: 53.91%] [G loss: 1.094180]\n",
      "epoch:26 step:24602 [D loss: 0.846663, acc.: 37.50%] [G loss: 1.039994]\n",
      "epoch:26 step:24603 [D loss: 0.727972, acc.: 57.81%] [G loss: 1.275179]\n",
      "epoch:26 step:24604 [D loss: 0.720968, acc.: 53.91%] [G loss: 1.356959]\n",
      "epoch:26 step:24605 [D loss: 0.797475, acc.: 46.88%] [G loss: 1.057268]\n",
      "epoch:26 step:24606 [D loss: 0.709171, acc.: 57.81%] [G loss: 1.029914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24607 [D loss: 0.530639, acc.: 76.56%] [G loss: 1.074721]\n",
      "epoch:26 step:24608 [D loss: 0.593143, acc.: 68.75%] [G loss: 1.150601]\n",
      "epoch:26 step:24609 [D loss: 0.722578, acc.: 55.47%] [G loss: 1.268231]\n",
      "epoch:26 step:24610 [D loss: 0.538022, acc.: 75.78%] [G loss: 1.527485]\n",
      "epoch:26 step:24611 [D loss: 0.702391, acc.: 53.91%] [G loss: 1.197215]\n",
      "epoch:26 step:24612 [D loss: 0.455619, acc.: 85.94%] [G loss: 1.450340]\n",
      "epoch:26 step:24613 [D loss: 0.625734, acc.: 67.19%] [G loss: 1.268132]\n",
      "epoch:26 step:24614 [D loss: 0.905451, acc.: 43.75%] [G loss: 0.902099]\n",
      "epoch:26 step:24615 [D loss: 0.551321, acc.: 75.78%] [G loss: 1.295334]\n",
      "epoch:26 step:24616 [D loss: 0.622088, acc.: 64.84%] [G loss: 1.438423]\n",
      "epoch:26 step:24617 [D loss: 0.838825, acc.: 45.31%] [G loss: 1.018857]\n",
      "epoch:26 step:24618 [D loss: 0.555748, acc.: 68.75%] [G loss: 1.196679]\n",
      "epoch:26 step:24619 [D loss: 0.561875, acc.: 70.31%] [G loss: 0.961100]\n",
      "epoch:26 step:24620 [D loss: 0.678813, acc.: 51.56%] [G loss: 0.901841]\n",
      "epoch:26 step:24621 [D loss: 0.777499, acc.: 46.88%] [G loss: 1.015038]\n",
      "epoch:26 step:24622 [D loss: 0.573005, acc.: 70.31%] [G loss: 1.371187]\n",
      "epoch:26 step:24623 [D loss: 0.709932, acc.: 54.69%] [G loss: 1.303101]\n",
      "epoch:26 step:24624 [D loss: 0.623624, acc.: 60.94%] [G loss: 1.372249]\n",
      "epoch:26 step:24625 [D loss: 0.551287, acc.: 71.09%] [G loss: 1.276227]\n",
      "epoch:26 step:24626 [D loss: 0.415606, acc.: 88.28%] [G loss: 1.447434]\n",
      "epoch:26 step:24627 [D loss: 0.730492, acc.: 55.47%] [G loss: 1.220603]\n",
      "epoch:26 step:24628 [D loss: 0.773720, acc.: 49.22%] [G loss: 0.852513]\n",
      "epoch:26 step:24629 [D loss: 0.637589, acc.: 61.72%] [G loss: 0.927523]\n",
      "epoch:26 step:24630 [D loss: 0.596218, acc.: 70.31%] [G loss: 1.218469]\n",
      "epoch:26 step:24631 [D loss: 0.655286, acc.: 57.03%] [G loss: 1.018940]\n",
      "epoch:26 step:24632 [D loss: 0.543706, acc.: 69.53%] [G loss: 1.428494]\n",
      "epoch:26 step:24633 [D loss: 0.608725, acc.: 67.19%] [G loss: 0.906909]\n",
      "epoch:26 step:24634 [D loss: 0.391557, acc.: 87.50%] [G loss: 1.214891]\n",
      "epoch:26 step:24635 [D loss: 0.742189, acc.: 56.25%] [G loss: 0.897790]\n",
      "epoch:26 step:24636 [D loss: 0.477410, acc.: 82.81%] [G loss: 1.540414]\n",
      "epoch:26 step:24637 [D loss: 0.726795, acc.: 55.47%] [G loss: 1.220033]\n",
      "epoch:26 step:24638 [D loss: 0.802001, acc.: 48.44%] [G loss: 0.858782]\n",
      "epoch:26 step:24639 [D loss: 0.816309, acc.: 43.75%] [G loss: 1.087715]\n",
      "epoch:26 step:24640 [D loss: 0.602242, acc.: 60.94%] [G loss: 1.219622]\n",
      "epoch:26 step:24641 [D loss: 0.327005, acc.: 89.06%] [G loss: 1.436162]\n",
      "epoch:26 step:24642 [D loss: 0.372588, acc.: 89.84%] [G loss: 1.654541]\n",
      "epoch:26 step:24643 [D loss: 0.735340, acc.: 57.81%] [G loss: 1.196145]\n",
      "epoch:26 step:24644 [D loss: 0.612062, acc.: 65.62%] [G loss: 1.280748]\n",
      "epoch:26 step:24645 [D loss: 0.619233, acc.: 64.06%] [G loss: 1.196888]\n",
      "epoch:26 step:24646 [D loss: 0.354281, acc.: 88.28%] [G loss: 1.152682]\n",
      "epoch:26 step:24647 [D loss: 0.330140, acc.: 94.53%] [G loss: 1.073799]\n",
      "epoch:26 step:24648 [D loss: 0.445944, acc.: 82.81%] [G loss: 1.298034]\n",
      "epoch:26 step:24649 [D loss: 0.434192, acc.: 82.81%] [G loss: 1.550935]\n",
      "epoch:26 step:24650 [D loss: 0.595068, acc.: 63.28%] [G loss: 1.151186]\n",
      "epoch:26 step:24651 [D loss: 0.460762, acc.: 78.12%] [G loss: 1.106126]\n",
      "epoch:26 step:24652 [D loss: 0.577531, acc.: 69.53%] [G loss: 1.381941]\n",
      "epoch:26 step:24653 [D loss: 0.251192, acc.: 96.88%] [G loss: 1.815070]\n",
      "epoch:26 step:24654 [D loss: 0.504133, acc.: 72.66%] [G loss: 1.085668]\n",
      "epoch:26 step:24655 [D loss: 0.289155, acc.: 92.19%] [G loss: 1.673827]\n",
      "epoch:26 step:24656 [D loss: 0.459519, acc.: 83.59%] [G loss: 1.419266]\n",
      "epoch:26 step:24657 [D loss: 0.828004, acc.: 46.88%] [G loss: 0.936465]\n",
      "epoch:26 step:24658 [D loss: 0.688284, acc.: 59.38%] [G loss: 1.396463]\n",
      "epoch:26 step:24659 [D loss: 0.731696, acc.: 53.91%] [G loss: 0.810563]\n",
      "epoch:26 step:24660 [D loss: 0.623173, acc.: 66.41%] [G loss: 1.264523]\n",
      "epoch:26 step:24661 [D loss: 0.792549, acc.: 46.88%] [G loss: 1.483262]\n",
      "epoch:26 step:24662 [D loss: 0.729589, acc.: 50.78%] [G loss: 0.820174]\n",
      "epoch:26 step:24663 [D loss: 0.768156, acc.: 57.81%] [G loss: 0.638149]\n",
      "epoch:26 step:24664 [D loss: 0.643359, acc.: 62.50%] [G loss: 1.238043]\n",
      "epoch:26 step:24665 [D loss: 0.862166, acc.: 40.62%] [G loss: 0.916784]\n",
      "epoch:26 step:24666 [D loss: 0.506727, acc.: 78.91%] [G loss: 1.116222]\n",
      "epoch:26 step:24667 [D loss: 0.668948, acc.: 61.72%] [G loss: 1.072592]\n",
      "epoch:26 step:24668 [D loss: 0.586592, acc.: 65.62%] [G loss: 1.340040]\n",
      "epoch:26 step:24669 [D loss: 0.586738, acc.: 69.53%] [G loss: 0.920529]\n",
      "epoch:26 step:24670 [D loss: 0.498458, acc.: 78.12%] [G loss: 0.953571]\n",
      "epoch:26 step:24671 [D loss: 0.490877, acc.: 81.25%] [G loss: 1.213383]\n",
      "epoch:26 step:24672 [D loss: 0.665955, acc.: 56.25%] [G loss: 0.934735]\n",
      "epoch:26 step:24673 [D loss: 0.478067, acc.: 81.25%] [G loss: 1.097390]\n",
      "epoch:26 step:24674 [D loss: 0.408826, acc.: 83.59%] [G loss: 1.378637]\n",
      "epoch:26 step:24675 [D loss: 0.457615, acc.: 81.25%] [G loss: 1.305295]\n",
      "epoch:26 step:24676 [D loss: 0.380710, acc.: 85.16%] [G loss: 1.384965]\n",
      "epoch:26 step:24677 [D loss: 0.441536, acc.: 82.03%] [G loss: 1.749115]\n",
      "epoch:26 step:24678 [D loss: 0.856897, acc.: 45.31%] [G loss: 1.284924]\n",
      "epoch:26 step:24679 [D loss: 0.638624, acc.: 60.94%] [G loss: 1.249536]\n",
      "epoch:26 step:24680 [D loss: 0.453075, acc.: 82.03%] [G loss: 1.500531]\n",
      "epoch:26 step:24681 [D loss: 0.520889, acc.: 76.56%] [G loss: 1.388464]\n",
      "epoch:26 step:24682 [D loss: 0.371543, acc.: 92.19%] [G loss: 1.538073]\n",
      "epoch:26 step:24683 [D loss: 0.379790, acc.: 89.06%] [G loss: 1.117079]\n",
      "epoch:26 step:24684 [D loss: 0.398488, acc.: 88.28%] [G loss: 1.398275]\n",
      "epoch:26 step:24685 [D loss: 0.629518, acc.: 66.41%] [G loss: 1.307909]\n",
      "epoch:26 step:24686 [D loss: 0.453082, acc.: 83.59%] [G loss: 1.354038]\n",
      "epoch:26 step:24687 [D loss: 0.497123, acc.: 78.91%] [G loss: 0.909309]\n",
      "epoch:26 step:24688 [D loss: 0.486025, acc.: 79.69%] [G loss: 1.359140]\n",
      "epoch:26 step:24689 [D loss: 0.286986, acc.: 89.84%] [G loss: 1.782887]\n",
      "epoch:26 step:24690 [D loss: 0.251047, acc.: 97.66%] [G loss: 1.681479]\n",
      "epoch:26 step:24691 [D loss: 0.512522, acc.: 75.00%] [G loss: 1.730640]\n",
      "epoch:26 step:24692 [D loss: 0.746261, acc.: 49.22%] [G loss: 1.215785]\n",
      "epoch:26 step:24693 [D loss: 0.793068, acc.: 48.44%] [G loss: 0.814925]\n",
      "epoch:26 step:24694 [D loss: 0.702615, acc.: 57.81%] [G loss: 0.741163]\n",
      "epoch:26 step:24695 [D loss: 0.793493, acc.: 47.66%] [G loss: 0.890521]\n",
      "epoch:26 step:24696 [D loss: 0.728516, acc.: 53.12%] [G loss: 0.835985]\n",
      "epoch:26 step:24697 [D loss: 0.580169, acc.: 71.09%] [G loss: 1.455311]\n",
      "epoch:26 step:24698 [D loss: 0.590502, acc.: 68.75%] [G loss: 1.151224]\n",
      "epoch:26 step:24699 [D loss: 0.751694, acc.: 48.44%] [G loss: 1.106444]\n",
      "epoch:26 step:24700 [D loss: 0.656387, acc.: 59.38%] [G loss: 0.844988]\n",
      "epoch:26 step:24701 [D loss: 0.487125, acc.: 83.59%] [G loss: 1.142460]\n",
      "epoch:26 step:24702 [D loss: 0.761540, acc.: 49.22%] [G loss: 1.035106]\n",
      "epoch:26 step:24703 [D loss: 0.881854, acc.: 39.84%] [G loss: 0.962000]\n",
      "epoch:26 step:24704 [D loss: 0.753376, acc.: 51.56%] [G loss: 0.845012]\n",
      "epoch:26 step:24705 [D loss: 0.481285, acc.: 83.59%] [G loss: 1.097119]\n",
      "epoch:26 step:24706 [D loss: 0.516243, acc.: 72.66%] [G loss: 1.206995]\n",
      "epoch:26 step:24707 [D loss: 0.380854, acc.: 88.28%] [G loss: 1.441771]\n",
      "epoch:26 step:24708 [D loss: 0.213637, acc.: 98.44%] [G loss: 1.508522]\n",
      "epoch:26 step:24709 [D loss: 0.225147, acc.: 97.66%] [G loss: 1.778986]\n",
      "epoch:26 step:24710 [D loss: 0.747269, acc.: 56.25%] [G loss: 1.400238]\n",
      "epoch:26 step:24711 [D loss: 0.891236, acc.: 43.75%] [G loss: 1.002002]\n",
      "epoch:26 step:24712 [D loss: 0.653644, acc.: 61.72%] [G loss: 1.014052]\n",
      "epoch:26 step:24713 [D loss: 0.595017, acc.: 64.84%] [G loss: 1.012532]\n",
      "epoch:26 step:24714 [D loss: 0.445367, acc.: 85.94%] [G loss: 1.237353]\n",
      "epoch:26 step:24715 [D loss: 0.589922, acc.: 68.75%] [G loss: 1.080187]\n",
      "epoch:26 step:24716 [D loss: 0.475938, acc.: 82.81%] [G loss: 1.293242]\n",
      "epoch:26 step:24717 [D loss: 0.852918, acc.: 42.97%] [G loss: 0.933024]\n",
      "epoch:26 step:24718 [D loss: 0.699188, acc.: 54.69%] [G loss: 0.978106]\n",
      "epoch:26 step:24719 [D loss: 0.645686, acc.: 60.94%] [G loss: 1.197894]\n",
      "epoch:26 step:24720 [D loss: 0.370384, acc.: 92.19%] [G loss: 1.372423]\n",
      "epoch:26 step:24721 [D loss: 0.483805, acc.: 82.81%] [G loss: 1.164350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24722 [D loss: 0.644090, acc.: 63.28%] [G loss: 1.027812]\n",
      "epoch:26 step:24723 [D loss: 0.623558, acc.: 64.84%] [G loss: 1.143368]\n",
      "epoch:26 step:24724 [D loss: 0.625669, acc.: 71.09%] [G loss: 1.004646]\n",
      "epoch:26 step:24725 [D loss: 0.434827, acc.: 83.59%] [G loss: 1.046674]\n",
      "epoch:26 step:24726 [D loss: 0.535616, acc.: 75.00%] [G loss: 1.070957]\n",
      "epoch:26 step:24727 [D loss: 0.452699, acc.: 82.81%] [G loss: 1.390689]\n",
      "epoch:26 step:24728 [D loss: 0.306547, acc.: 89.06%] [G loss: 1.520630]\n",
      "epoch:26 step:24729 [D loss: 0.290598, acc.: 96.09%] [G loss: 1.835286]\n",
      "epoch:26 step:24730 [D loss: 0.483890, acc.: 78.12%] [G loss: 1.636962]\n",
      "epoch:26 step:24731 [D loss: 0.697808, acc.: 54.69%] [G loss: 1.122612]\n",
      "epoch:26 step:24732 [D loss: 0.788799, acc.: 44.53%] [G loss: 0.903661]\n",
      "epoch:26 step:24733 [D loss: 0.602669, acc.: 67.19%] [G loss: 1.220267]\n",
      "epoch:26 step:24734 [D loss: 0.756560, acc.: 48.44%] [G loss: 1.186647]\n",
      "epoch:26 step:24735 [D loss: 0.832417, acc.: 42.97%] [G loss: 0.887139]\n",
      "epoch:26 step:24736 [D loss: 0.713281, acc.: 58.59%] [G loss: 1.102317]\n",
      "epoch:26 step:24737 [D loss: 0.723740, acc.: 57.81%] [G loss: 0.846143]\n",
      "epoch:26 step:24738 [D loss: 0.736346, acc.: 50.78%] [G loss: 0.864729]\n",
      "epoch:26 step:24739 [D loss: 0.698642, acc.: 60.16%] [G loss: 0.682467]\n",
      "epoch:26 step:24740 [D loss: 0.248802, acc.: 97.66%] [G loss: 1.495792]\n",
      "epoch:26 step:24741 [D loss: 0.775868, acc.: 54.69%] [G loss: 1.321835]\n",
      "epoch:26 step:24742 [D loss: 0.591496, acc.: 73.44%] [G loss: 1.427734]\n",
      "epoch:26 step:24743 [D loss: 0.459999, acc.: 84.38%] [G loss: 1.266074]\n",
      "epoch:26 step:24744 [D loss: 0.894815, acc.: 39.84%] [G loss: 1.096675]\n",
      "epoch:26 step:24745 [D loss: 0.524999, acc.: 79.69%] [G loss: 1.214121]\n",
      "epoch:26 step:24746 [D loss: 0.664228, acc.: 62.50%] [G loss: 1.234936]\n",
      "epoch:26 step:24747 [D loss: 0.533648, acc.: 73.44%] [G loss: 1.077042]\n",
      "epoch:26 step:24748 [D loss: 0.701507, acc.: 57.81%] [G loss: 0.870025]\n",
      "epoch:26 step:24749 [D loss: 0.719912, acc.: 47.66%] [G loss: 0.921083]\n",
      "epoch:26 step:24750 [D loss: 0.528703, acc.: 77.34%] [G loss: 0.896415]\n",
      "epoch:26 step:24751 [D loss: 0.578587, acc.: 71.09%] [G loss: 0.826122]\n",
      "epoch:26 step:24752 [D loss: 0.357478, acc.: 89.06%] [G loss: 1.290700]\n",
      "epoch:26 step:24753 [D loss: 0.478263, acc.: 82.03%] [G loss: 0.943357]\n",
      "epoch:26 step:24754 [D loss: 0.547358, acc.: 73.44%] [G loss: 1.045555]\n",
      "epoch:26 step:24755 [D loss: 0.605361, acc.: 66.41%] [G loss: 0.982640]\n",
      "epoch:26 step:24756 [D loss: 0.323448, acc.: 92.19%] [G loss: 1.538371]\n",
      "epoch:26 step:24757 [D loss: 0.625355, acc.: 58.59%] [G loss: 1.025854]\n",
      "epoch:26 step:24758 [D loss: 0.366665, acc.: 86.72%] [G loss: 1.293195]\n",
      "epoch:26 step:24759 [D loss: 0.214390, acc.: 95.31%] [G loss: 1.745030]\n",
      "epoch:26 step:24760 [D loss: 0.155956, acc.: 99.22%] [G loss: 2.087180]\n",
      "epoch:26 step:24761 [D loss: 0.309080, acc.: 94.53%] [G loss: 1.544173]\n",
      "epoch:26 step:24762 [D loss: 0.311498, acc.: 93.75%] [G loss: 1.707896]\n",
      "epoch:26 step:24763 [D loss: 0.319996, acc.: 90.62%] [G loss: 1.356015]\n",
      "epoch:26 step:24764 [D loss: 0.307770, acc.: 92.97%] [G loss: 1.896062]\n",
      "epoch:26 step:24765 [D loss: 0.483555, acc.: 78.91%] [G loss: 1.166983]\n",
      "epoch:26 step:24766 [D loss: 0.222305, acc.: 96.88%] [G loss: 1.625324]\n",
      "epoch:26 step:24767 [D loss: 0.246275, acc.: 97.66%] [G loss: 1.563573]\n",
      "epoch:26 step:24768 [D loss: 0.374426, acc.: 87.50%] [G loss: 1.242017]\n",
      "epoch:26 step:24769 [D loss: 0.605198, acc.: 64.84%] [G loss: 0.865801]\n",
      "epoch:26 step:24770 [D loss: 0.433654, acc.: 77.34%] [G loss: 1.532211]\n",
      "epoch:26 step:24771 [D loss: 0.626754, acc.: 66.41%] [G loss: 0.967762]\n",
      "epoch:26 step:24772 [D loss: 0.455052, acc.: 79.69%] [G loss: 1.220460]\n",
      "epoch:26 step:24773 [D loss: 0.757273, acc.: 56.25%] [G loss: 1.354343]\n",
      "epoch:26 step:24774 [D loss: 0.957486, acc.: 39.06%] [G loss: 0.830938]\n",
      "epoch:26 step:24775 [D loss: 0.779988, acc.: 49.22%] [G loss: 1.077597]\n",
      "epoch:26 step:24776 [D loss: 0.837710, acc.: 52.34%] [G loss: 0.843137]\n",
      "epoch:26 step:24777 [D loss: 0.980021, acc.: 28.91%] [G loss: 0.826943]\n",
      "epoch:26 step:24778 [D loss: 0.801737, acc.: 50.00%] [G loss: 1.256872]\n",
      "epoch:26 step:24779 [D loss: 1.043175, acc.: 28.91%] [G loss: 0.884885]\n",
      "epoch:26 step:24780 [D loss: 0.634027, acc.: 61.72%] [G loss: 1.018058]\n",
      "epoch:26 step:24781 [D loss: 0.675226, acc.: 64.84%] [G loss: 1.071691]\n",
      "epoch:26 step:24782 [D loss: 0.731009, acc.: 55.47%] [G loss: 1.257584]\n",
      "epoch:26 step:24783 [D loss: 0.707809, acc.: 60.94%] [G loss: 1.495018]\n",
      "epoch:26 step:24784 [D loss: 0.751740, acc.: 52.34%] [G loss: 1.526286]\n",
      "epoch:26 step:24785 [D loss: 0.840018, acc.: 45.31%] [G loss: 1.177502]\n",
      "epoch:26 step:24786 [D loss: 0.598449, acc.: 66.41%] [G loss: 1.360304]\n",
      "epoch:26 step:24787 [D loss: 0.826205, acc.: 43.75%] [G loss: 1.040444]\n",
      "epoch:26 step:24788 [D loss: 0.526585, acc.: 72.66%] [G loss: 1.083880]\n",
      "epoch:26 step:24789 [D loss: 0.659172, acc.: 60.94%] [G loss: 1.427584]\n",
      "epoch:26 step:24790 [D loss: 0.578385, acc.: 64.84%] [G loss: 1.216666]\n",
      "epoch:26 step:24791 [D loss: 0.624919, acc.: 66.41%] [G loss: 1.510938]\n",
      "epoch:26 step:24792 [D loss: 0.490251, acc.: 78.12%] [G loss: 1.290829]\n",
      "epoch:26 step:24793 [D loss: 0.679896, acc.: 60.16%] [G loss: 1.298032]\n",
      "epoch:26 step:24794 [D loss: 0.669615, acc.: 61.72%] [G loss: 1.239158]\n",
      "epoch:26 step:24795 [D loss: 0.570328, acc.: 71.09%] [G loss: 1.529160]\n",
      "epoch:26 step:24796 [D loss: 0.490469, acc.: 75.78%] [G loss: 1.547036]\n",
      "epoch:26 step:24797 [D loss: 0.517296, acc.: 74.22%] [G loss: 1.311448]\n",
      "epoch:26 step:24798 [D loss: 0.487251, acc.: 81.25%] [G loss: 1.199640]\n",
      "epoch:26 step:24799 [D loss: 0.901726, acc.: 39.06%] [G loss: 1.253481]\n",
      "epoch:26 step:24800 [D loss: 0.631896, acc.: 65.62%] [G loss: 0.952580]\n",
      "epoch:26 step:24801 [D loss: 0.580564, acc.: 69.53%] [G loss: 1.166574]\n",
      "epoch:26 step:24802 [D loss: 0.623762, acc.: 59.38%] [G loss: 1.351429]\n",
      "epoch:26 step:24803 [D loss: 0.550918, acc.: 71.09%] [G loss: 1.422786]\n",
      "epoch:26 step:24804 [D loss: 0.655248, acc.: 62.50%] [G loss: 1.049970]\n",
      "epoch:26 step:24805 [D loss: 0.423338, acc.: 82.03%] [G loss: 1.481624]\n",
      "epoch:26 step:24806 [D loss: 0.568736, acc.: 70.31%] [G loss: 1.354419]\n",
      "epoch:26 step:24807 [D loss: 0.679576, acc.: 57.03%] [G loss: 1.180201]\n",
      "epoch:26 step:24808 [D loss: 0.770057, acc.: 46.88%] [G loss: 1.017139]\n",
      "epoch:26 step:24809 [D loss: 0.555787, acc.: 73.44%] [G loss: 1.106569]\n",
      "epoch:26 step:24810 [D loss: 0.370766, acc.: 84.38%] [G loss: 0.936524]\n",
      "epoch:26 step:24811 [D loss: 0.318458, acc.: 92.97%] [G loss: 1.499156]\n",
      "epoch:26 step:24812 [D loss: 0.480075, acc.: 76.56%] [G loss: 1.244741]\n",
      "epoch:26 step:24813 [D loss: 0.409593, acc.: 82.81%] [G loss: 1.848606]\n",
      "epoch:26 step:24814 [D loss: 0.348395, acc.: 88.28%] [G loss: 1.256285]\n",
      "epoch:26 step:24815 [D loss: 0.382679, acc.: 89.84%] [G loss: 1.502974]\n",
      "epoch:26 step:24816 [D loss: 0.427641, acc.: 82.81%] [G loss: 1.504021]\n",
      "epoch:26 step:24817 [D loss: 0.602885, acc.: 73.44%] [G loss: 1.547560]\n",
      "epoch:26 step:24818 [D loss: 0.530585, acc.: 69.53%] [G loss: 1.553295]\n",
      "epoch:26 step:24819 [D loss: 0.375485, acc.: 89.84%] [G loss: 1.496269]\n",
      "epoch:26 step:24820 [D loss: 1.083595, acc.: 37.50%] [G loss: 1.123837]\n",
      "epoch:26 step:24821 [D loss: 0.985847, acc.: 35.16%] [G loss: 0.803530]\n",
      "epoch:26 step:24822 [D loss: 1.051815, acc.: 28.91%] [G loss: 0.684823]\n",
      "epoch:26 step:24823 [D loss: 1.006240, acc.: 36.72%] [G loss: 0.880303]\n",
      "epoch:26 step:24824 [D loss: 1.139509, acc.: 21.88%] [G loss: 0.872295]\n",
      "epoch:26 step:24825 [D loss: 1.163996, acc.: 20.31%] [G loss: 0.597185]\n",
      "epoch:26 step:24826 [D loss: 0.660033, acc.: 64.84%] [G loss: 0.831198]\n",
      "epoch:26 step:24827 [D loss: 0.640621, acc.: 65.62%] [G loss: 1.115445]\n",
      "epoch:26 step:24828 [D loss: 0.579747, acc.: 71.88%] [G loss: 1.293303]\n",
      "epoch:26 step:24829 [D loss: 0.657197, acc.: 61.72%] [G loss: 1.211619]\n",
      "epoch:26 step:24830 [D loss: 0.548062, acc.: 73.44%] [G loss: 0.947948]\n",
      "epoch:26 step:24831 [D loss: 0.587334, acc.: 67.19%] [G loss: 1.311496]\n",
      "epoch:26 step:24832 [D loss: 0.504375, acc.: 78.12%] [G loss: 1.242610]\n",
      "epoch:26 step:24833 [D loss: 0.235920, acc.: 96.88%] [G loss: 1.423874]\n",
      "epoch:26 step:24834 [D loss: 0.544969, acc.: 76.56%] [G loss: 1.616460]\n",
      "epoch:26 step:24835 [D loss: 1.056269, acc.: 25.00%] [G loss: 1.304980]\n",
      "epoch:26 step:24836 [D loss: 0.503813, acc.: 77.34%] [G loss: 1.582830]\n",
      "epoch:26 step:24837 [D loss: 0.350379, acc.: 91.41%] [G loss: 1.826581]\n",
      "epoch:26 step:24838 [D loss: 0.769560, acc.: 56.25%] [G loss: 1.193723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24839 [D loss: 0.755419, acc.: 52.34%] [G loss: 1.024847]\n",
      "epoch:26 step:24840 [D loss: 0.658774, acc.: 64.84%] [G loss: 0.947315]\n",
      "epoch:26 step:24841 [D loss: 0.559334, acc.: 74.22%] [G loss: 0.958174]\n",
      "epoch:26 step:24842 [D loss: 0.585882, acc.: 66.41%] [G loss: 1.270129]\n",
      "epoch:26 step:24843 [D loss: 0.582107, acc.: 69.53%] [G loss: 0.901290]\n",
      "epoch:26 step:24844 [D loss: 0.539693, acc.: 71.88%] [G loss: 1.339610]\n",
      "epoch:26 step:24845 [D loss: 0.510507, acc.: 75.78%] [G loss: 1.397880]\n",
      "epoch:26 step:24846 [D loss: 0.388804, acc.: 86.72%] [G loss: 1.404251]\n",
      "epoch:26 step:24847 [D loss: 0.344257, acc.: 90.62%] [G loss: 1.681882]\n",
      "epoch:26 step:24848 [D loss: 0.466024, acc.: 76.56%] [G loss: 1.308723]\n",
      "epoch:26 step:24849 [D loss: 0.318632, acc.: 89.84%] [G loss: 1.635479]\n",
      "epoch:26 step:24850 [D loss: 0.530812, acc.: 71.09%] [G loss: 1.315871]\n",
      "epoch:26 step:24851 [D loss: 0.768795, acc.: 52.34%] [G loss: 1.088604]\n",
      "epoch:26 step:24852 [D loss: 0.599652, acc.: 67.19%] [G loss: 1.363046]\n",
      "epoch:26 step:24853 [D loss: 0.602880, acc.: 66.41%] [G loss: 1.182436]\n",
      "epoch:26 step:24854 [D loss: 0.606155, acc.: 69.53%] [G loss: 1.183987]\n",
      "epoch:26 step:24855 [D loss: 0.629557, acc.: 62.50%] [G loss: 1.080521]\n",
      "epoch:26 step:24856 [D loss: 0.671719, acc.: 61.72%] [G loss: 1.014575]\n",
      "epoch:26 step:24857 [D loss: 0.491209, acc.: 78.91%] [G loss: 0.971891]\n",
      "epoch:26 step:24858 [D loss: 0.396756, acc.: 90.62%] [G loss: 1.266601]\n",
      "epoch:26 step:24859 [D loss: 0.296524, acc.: 94.53%] [G loss: 1.332415]\n",
      "epoch:26 step:24860 [D loss: 0.250028, acc.: 95.31%] [G loss: 1.566856]\n",
      "epoch:26 step:24861 [D loss: 0.213278, acc.: 99.22%] [G loss: 1.320729]\n",
      "epoch:26 step:24862 [D loss: 0.776222, acc.: 53.91%] [G loss: 1.215175]\n",
      "epoch:26 step:24863 [D loss: 0.825900, acc.: 48.44%] [G loss: 1.089914]\n",
      "epoch:26 step:24864 [D loss: 0.686488, acc.: 56.25%] [G loss: 0.887817]\n",
      "epoch:26 step:24865 [D loss: 0.549119, acc.: 71.88%] [G loss: 0.872323]\n",
      "epoch:26 step:24866 [D loss: 0.486667, acc.: 78.12%] [G loss: 1.254265]\n",
      "epoch:26 step:24867 [D loss: 0.582798, acc.: 67.97%] [G loss: 1.102354]\n",
      "epoch:26 step:24868 [D loss: 0.646048, acc.: 66.41%] [G loss: 1.164555]\n",
      "epoch:26 step:24869 [D loss: 0.470906, acc.: 83.59%] [G loss: 1.437692]\n",
      "epoch:26 step:24870 [D loss: 0.272597, acc.: 96.88%] [G loss: 1.526018]\n",
      "epoch:26 step:24871 [D loss: 0.658464, acc.: 62.50%] [G loss: 1.247455]\n",
      "epoch:26 step:24872 [D loss: 0.747533, acc.: 51.56%] [G loss: 1.114460]\n",
      "epoch:26 step:24873 [D loss: 0.409562, acc.: 78.91%] [G loss: 1.298635]\n",
      "epoch:26 step:24874 [D loss: 0.347362, acc.: 90.62%] [G loss: 1.144556]\n",
      "epoch:26 step:24875 [D loss: 0.354384, acc.: 92.19%] [G loss: 1.269947]\n",
      "epoch:26 step:24876 [D loss: 0.350831, acc.: 93.75%] [G loss: 1.245420]\n",
      "epoch:26 step:24877 [D loss: 0.462013, acc.: 84.38%] [G loss: 1.549300]\n",
      "epoch:26 step:24878 [D loss: 0.707120, acc.: 57.03%] [G loss: 1.113693]\n",
      "epoch:26 step:24879 [D loss: 0.600085, acc.: 67.19%] [G loss: 1.111972]\n",
      "epoch:26 step:24880 [D loss: 0.498603, acc.: 78.91%] [G loss: 1.191001]\n",
      "epoch:26 step:24881 [D loss: 0.403505, acc.: 89.84%] [G loss: 1.044030]\n",
      "epoch:26 step:24882 [D loss: 0.410865, acc.: 88.28%] [G loss: 1.312758]\n",
      "epoch:26 step:24883 [D loss: 0.462877, acc.: 85.16%] [G loss: 1.366305]\n",
      "epoch:26 step:24884 [D loss: 0.316200, acc.: 92.97%] [G loss: 1.189092]\n",
      "epoch:26 step:24885 [D loss: 0.326541, acc.: 95.31%] [G loss: 1.481629]\n",
      "epoch:26 step:24886 [D loss: 0.711918, acc.: 57.81%] [G loss: 1.245694]\n",
      "epoch:26 step:24887 [D loss: 0.767956, acc.: 44.53%] [G loss: 1.123068]\n",
      "epoch:26 step:24888 [D loss: 0.745804, acc.: 51.56%] [G loss: 1.274263]\n",
      "epoch:26 step:24889 [D loss: 0.646590, acc.: 60.16%] [G loss: 1.217707]\n",
      "epoch:26 step:24890 [D loss: 0.713580, acc.: 56.25%] [G loss: 0.937964]\n",
      "epoch:26 step:24891 [D loss: 0.747543, acc.: 46.88%] [G loss: 0.892823]\n",
      "epoch:26 step:24892 [D loss: 0.649498, acc.: 64.06%] [G loss: 0.831611]\n",
      "epoch:26 step:24893 [D loss: 0.419037, acc.: 89.06%] [G loss: 1.184268]\n",
      "epoch:26 step:24894 [D loss: 0.305564, acc.: 96.09%] [G loss: 1.305830]\n",
      "epoch:26 step:24895 [D loss: 0.247703, acc.: 92.19%] [G loss: 1.682086]\n",
      "epoch:26 step:24896 [D loss: 0.328177, acc.: 93.75%] [G loss: 1.731615]\n",
      "epoch:26 step:24897 [D loss: 0.598419, acc.: 65.62%] [G loss: 1.417326]\n",
      "epoch:26 step:24898 [D loss: 0.492654, acc.: 78.91%] [G loss: 1.496028]\n",
      "epoch:26 step:24899 [D loss: 0.409311, acc.: 85.94%] [G loss: 1.313463]\n",
      "epoch:26 step:24900 [D loss: 0.599538, acc.: 70.31%] [G loss: 1.067297]\n",
      "epoch:26 step:24901 [D loss: 0.669803, acc.: 62.50%] [G loss: 1.123399]\n",
      "epoch:26 step:24902 [D loss: 0.752221, acc.: 52.34%] [G loss: 1.336194]\n",
      "epoch:26 step:24903 [D loss: 0.577727, acc.: 71.88%] [G loss: 0.929674]\n",
      "epoch:26 step:24904 [D loss: 0.507174, acc.: 77.34%] [G loss: 1.108737]\n",
      "epoch:26 step:24905 [D loss: 0.361174, acc.: 92.97%] [G loss: 1.498525]\n",
      "epoch:26 step:24906 [D loss: 0.483297, acc.: 78.91%] [G loss: 1.464509]\n",
      "epoch:26 step:24907 [D loss: 0.285104, acc.: 96.09%] [G loss: 1.611275]\n",
      "epoch:26 step:24908 [D loss: 0.253563, acc.: 97.66%] [G loss: 1.290340]\n",
      "epoch:26 step:24909 [D loss: 0.277645, acc.: 95.31%] [G loss: 1.406686]\n",
      "epoch:26 step:24910 [D loss: 0.401748, acc.: 88.28%] [G loss: 1.247928]\n",
      "epoch:26 step:24911 [D loss: 0.167158, acc.: 100.00%] [G loss: 1.838927]\n",
      "epoch:26 step:24912 [D loss: 0.381284, acc.: 85.16%] [G loss: 1.185240]\n",
      "epoch:26 step:24913 [D loss: 0.335829, acc.: 88.28%] [G loss: 1.570490]\n",
      "epoch:26 step:24914 [D loss: 0.344772, acc.: 90.62%] [G loss: 1.988475]\n",
      "epoch:26 step:24915 [D loss: 0.411366, acc.: 83.59%] [G loss: 1.800711]\n",
      "epoch:26 step:24916 [D loss: 0.204520, acc.: 98.44%] [G loss: 1.649429]\n",
      "epoch:26 step:24917 [D loss: 0.335380, acc.: 92.19%] [G loss: 1.493996]\n",
      "epoch:26 step:24918 [D loss: 0.191915, acc.: 98.44%] [G loss: 1.746139]\n",
      "epoch:26 step:24919 [D loss: 0.297215, acc.: 93.75%] [G loss: 1.486362]\n",
      "epoch:26 step:24920 [D loss: 0.358889, acc.: 90.62%] [G loss: 1.782623]\n",
      "epoch:26 step:24921 [D loss: 0.825712, acc.: 48.44%] [G loss: 1.126474]\n",
      "epoch:26 step:24922 [D loss: 1.227494, acc.: 32.81%] [G loss: 1.156358]\n",
      "epoch:26 step:24923 [D loss: 0.479451, acc.: 79.69%] [G loss: 1.351972]\n",
      "epoch:26 step:24924 [D loss: 0.776501, acc.: 46.88%] [G loss: 1.008642]\n",
      "epoch:26 step:24925 [D loss: 0.749391, acc.: 57.81%] [G loss: 0.893398]\n",
      "epoch:26 step:24926 [D loss: 0.616463, acc.: 63.28%] [G loss: 1.261477]\n",
      "epoch:26 step:24927 [D loss: 0.550460, acc.: 71.88%] [G loss: 1.054098]\n",
      "epoch:26 step:24928 [D loss: 0.334546, acc.: 90.62%] [G loss: 1.294605]\n",
      "epoch:26 step:24929 [D loss: 0.367739, acc.: 91.41%] [G loss: 1.458902]\n",
      "epoch:26 step:24930 [D loss: 0.658064, acc.: 62.50%] [G loss: 1.594693]\n",
      "epoch:26 step:24931 [D loss: 0.747452, acc.: 53.12%] [G loss: 1.169904]\n",
      "epoch:26 step:24932 [D loss: 0.713096, acc.: 50.78%] [G loss: 1.029841]\n",
      "epoch:26 step:24933 [D loss: 0.589746, acc.: 66.41%] [G loss: 0.809196]\n",
      "epoch:26 step:24934 [D loss: 0.510699, acc.: 79.69%] [G loss: 1.450804]\n",
      "epoch:26 step:24935 [D loss: 0.494557, acc.: 80.47%] [G loss: 1.065487]\n",
      "epoch:26 step:24936 [D loss: 0.433277, acc.: 84.38%] [G loss: 1.106861]\n",
      "epoch:26 step:24937 [D loss: 0.386801, acc.: 90.62%] [G loss: 1.164483]\n",
      "epoch:26 step:24938 [D loss: 0.416998, acc.: 82.81%] [G loss: 1.242541]\n",
      "epoch:26 step:24939 [D loss: 0.606974, acc.: 66.41%] [G loss: 0.845317]\n",
      "epoch:26 step:24940 [D loss: 0.355608, acc.: 90.62%] [G loss: 1.477456]\n",
      "epoch:26 step:24941 [D loss: 0.463932, acc.: 81.25%] [G loss: 1.740724]\n",
      "epoch:26 step:24942 [D loss: 0.772435, acc.: 49.22%] [G loss: 0.889806]\n",
      "epoch:26 step:24943 [D loss: 0.809106, acc.: 53.12%] [G loss: 0.999556]\n",
      "epoch:26 step:24944 [D loss: 0.841845, acc.: 40.62%] [G loss: 1.040012]\n",
      "epoch:26 step:24945 [D loss: 0.571742, acc.: 72.66%] [G loss: 1.134134]\n",
      "epoch:26 step:24946 [D loss: 0.763803, acc.: 50.00%] [G loss: 1.010630]\n",
      "epoch:26 step:24947 [D loss: 0.613441, acc.: 66.41%] [G loss: 1.051955]\n",
      "epoch:26 step:24948 [D loss: 0.833340, acc.: 43.75%] [G loss: 0.924677]\n",
      "epoch:26 step:24949 [D loss: 0.426208, acc.: 78.12%] [G loss: 1.137790]\n",
      "epoch:26 step:24950 [D loss: 0.382105, acc.: 86.72%] [G loss: 1.644223]\n",
      "epoch:26 step:24951 [D loss: 0.255715, acc.: 95.31%] [G loss: 1.623929]\n",
      "epoch:26 step:24952 [D loss: 0.923888, acc.: 40.62%] [G loss: 1.599599]\n",
      "epoch:26 step:24953 [D loss: 0.640149, acc.: 63.28%] [G loss: 1.353304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24954 [D loss: 0.483866, acc.: 82.03%] [G loss: 1.546858]\n",
      "epoch:26 step:24955 [D loss: 0.682058, acc.: 56.25%] [G loss: 1.415857]\n",
      "epoch:26 step:24956 [D loss: 0.472167, acc.: 82.81%] [G loss: 1.308988]\n",
      "epoch:26 step:24957 [D loss: 0.523539, acc.: 75.00%] [G loss: 1.090687]\n",
      "epoch:26 step:24958 [D loss: 0.704211, acc.: 57.81%] [G loss: 1.477917]\n",
      "epoch:26 step:24959 [D loss: 0.469388, acc.: 78.91%] [G loss: 1.519432]\n",
      "epoch:26 step:24960 [D loss: 0.244497, acc.: 96.88%] [G loss: 1.372558]\n",
      "epoch:26 step:24961 [D loss: 0.559771, acc.: 70.31%] [G loss: 1.033623]\n",
      "epoch:26 step:24962 [D loss: 0.578067, acc.: 70.31%] [G loss: 0.873871]\n",
      "epoch:26 step:24963 [D loss: 0.635632, acc.: 64.06%] [G loss: 0.932904]\n",
      "epoch:26 step:24964 [D loss: 0.605946, acc.: 65.62%] [G loss: 1.077333]\n",
      "epoch:26 step:24965 [D loss: 0.387660, acc.: 88.28%] [G loss: 0.980787]\n",
      "epoch:26 step:24966 [D loss: 0.349558, acc.: 85.94%] [G loss: 1.267720]\n",
      "epoch:26 step:24967 [D loss: 0.449569, acc.: 81.25%] [G loss: 1.187119]\n",
      "epoch:26 step:24968 [D loss: 0.795911, acc.: 48.44%] [G loss: 1.293145]\n",
      "epoch:26 step:24969 [D loss: 0.798989, acc.: 50.00%] [G loss: 1.167293]\n",
      "epoch:26 step:24970 [D loss: 0.656768, acc.: 59.38%] [G loss: 1.100590]\n",
      "epoch:26 step:24971 [D loss: 0.576741, acc.: 74.22%] [G loss: 1.180000]\n",
      "epoch:26 step:24972 [D loss: 0.431761, acc.: 84.38%] [G loss: 1.165501]\n",
      "epoch:26 step:24973 [D loss: 0.791886, acc.: 44.53%] [G loss: 1.115137]\n",
      "epoch:26 step:24974 [D loss: 0.690878, acc.: 58.59%] [G loss: 1.067979]\n",
      "epoch:26 step:24975 [D loss: 0.368311, acc.: 86.72%] [G loss: 1.297641]\n",
      "epoch:26 step:24976 [D loss: 0.340415, acc.: 89.84%] [G loss: 1.264482]\n",
      "epoch:26 step:24977 [D loss: 0.239104, acc.: 97.66%] [G loss: 1.580574]\n",
      "epoch:26 step:24978 [D loss: 0.255442, acc.: 94.53%] [G loss: 1.601452]\n",
      "epoch:26 step:24979 [D loss: 0.434963, acc.: 82.81%] [G loss: 1.321035]\n",
      "epoch:26 step:24980 [D loss: 0.901258, acc.: 37.50%] [G loss: 0.914089]\n",
      "epoch:26 step:24981 [D loss: 0.707630, acc.: 54.69%] [G loss: 1.648164]\n",
      "epoch:26 step:24982 [D loss: 0.847613, acc.: 38.28%] [G loss: 0.984512]\n",
      "epoch:26 step:24983 [D loss: 0.835971, acc.: 42.19%] [G loss: 0.806682]\n",
      "epoch:26 step:24984 [D loss: 0.569497, acc.: 71.09%] [G loss: 1.210621]\n",
      "epoch:26 step:24985 [D loss: 0.768694, acc.: 53.12%] [G loss: 1.263728]\n",
      "epoch:26 step:24986 [D loss: 0.335835, acc.: 88.28%] [G loss: 1.658447]\n",
      "epoch:26 step:24987 [D loss: 0.849474, acc.: 46.09%] [G loss: 1.061776]\n",
      "epoch:26 step:24988 [D loss: 0.783349, acc.: 42.97%] [G loss: 0.786003]\n",
      "epoch:26 step:24989 [D loss: 0.776069, acc.: 46.09%] [G loss: 0.819287]\n",
      "epoch:26 step:24990 [D loss: 0.734188, acc.: 54.69%] [G loss: 1.248505]\n",
      "epoch:26 step:24991 [D loss: 0.429151, acc.: 74.22%] [G loss: 1.223467]\n",
      "epoch:26 step:24992 [D loss: 0.589419, acc.: 70.31%] [G loss: 1.309999]\n",
      "epoch:26 step:24993 [D loss: 0.567458, acc.: 71.09%] [G loss: 1.277680]\n",
      "epoch:26 step:24994 [D loss: 0.682894, acc.: 63.28%] [G loss: 1.048045]\n",
      "epoch:26 step:24995 [D loss: 0.573389, acc.: 68.75%] [G loss: 1.377086]\n",
      "epoch:26 step:24996 [D loss: 0.636177, acc.: 68.75%] [G loss: 1.286715]\n",
      "epoch:26 step:24997 [D loss: 0.574461, acc.: 70.31%] [G loss: 1.551921]\n",
      "epoch:26 step:24998 [D loss: 1.121448, acc.: 29.69%] [G loss: 0.857200]\n",
      "epoch:26 step:24999 [D loss: 0.857675, acc.: 45.31%] [G loss: 1.321316]\n",
      "epoch:26 step:25000 [D loss: 1.042734, acc.: 32.81%] [G loss: 0.791858]\n",
      "epoch:26 step:25001 [D loss: 0.946190, acc.: 39.06%] [G loss: 1.045547]\n",
      "epoch:26 step:25002 [D loss: 0.669324, acc.: 64.06%] [G loss: 1.570900]\n",
      "epoch:26 step:25003 [D loss: 0.399726, acc.: 85.16%] [G loss: 1.542817]\n",
      "epoch:26 step:25004 [D loss: 0.409729, acc.: 92.19%] [G loss: 1.887153]\n",
      "epoch:26 step:25005 [D loss: 0.771515, acc.: 51.56%] [G loss: 1.239892]\n",
      "epoch:26 step:25006 [D loss: 0.754122, acc.: 53.91%] [G loss: 1.014498]\n",
      "epoch:26 step:25007 [D loss: 0.662160, acc.: 58.59%] [G loss: 1.091571]\n",
      "epoch:26 step:25008 [D loss: 0.419229, acc.: 84.38%] [G loss: 1.665396]\n",
      "epoch:26 step:25009 [D loss: 0.425406, acc.: 85.94%] [G loss: 1.262928]\n",
      "epoch:26 step:25010 [D loss: 0.498490, acc.: 79.69%] [G loss: 1.240479]\n",
      "epoch:26 step:25011 [D loss: 0.680397, acc.: 59.38%] [G loss: 1.080117]\n",
      "epoch:26 step:25012 [D loss: 0.542561, acc.: 71.88%] [G loss: 1.194829]\n",
      "epoch:26 step:25013 [D loss: 0.510712, acc.: 76.56%] [G loss: 1.233032]\n",
      "epoch:26 step:25014 [D loss: 0.706383, acc.: 56.25%] [G loss: 1.298804]\n",
      "epoch:26 step:25015 [D loss: 0.572423, acc.: 69.53%] [G loss: 1.252137]\n",
      "epoch:26 step:25016 [D loss: 0.473669, acc.: 82.03%] [G loss: 1.467845]\n",
      "epoch:26 step:25017 [D loss: 0.567164, acc.: 71.09%] [G loss: 1.342156]\n",
      "epoch:26 step:25018 [D loss: 0.652847, acc.: 61.72%] [G loss: 0.935491]\n",
      "epoch:26 step:25019 [D loss: 0.736611, acc.: 51.56%] [G loss: 1.136449]\n",
      "epoch:26 step:25020 [D loss: 0.465973, acc.: 82.81%] [G loss: 1.355292]\n",
      "epoch:26 step:25021 [D loss: 0.443815, acc.: 83.59%] [G loss: 1.361668]\n",
      "epoch:26 step:25022 [D loss: 0.584446, acc.: 73.44%] [G loss: 1.053309]\n",
      "epoch:26 step:25023 [D loss: 0.550432, acc.: 75.00%] [G loss: 1.219803]\n",
      "epoch:26 step:25024 [D loss: 0.441471, acc.: 80.47%] [G loss: 1.393380]\n",
      "epoch:26 step:25025 [D loss: 0.158215, acc.: 97.66%] [G loss: 1.908193]\n",
      "epoch:26 step:25026 [D loss: 0.152622, acc.: 98.44%] [G loss: 2.173071]\n",
      "epoch:26 step:25027 [D loss: 0.106790, acc.: 99.22%] [G loss: 2.738435]\n",
      "epoch:26 step:25028 [D loss: 0.346426, acc.: 91.41%] [G loss: 1.323824]\n",
      "epoch:26 step:25029 [D loss: 0.361267, acc.: 89.84%] [G loss: 1.519189]\n",
      "epoch:26 step:25030 [D loss: 0.512207, acc.: 76.56%] [G loss: 1.459523]\n",
      "epoch:26 step:25031 [D loss: 0.334951, acc.: 92.19%] [G loss: 1.254076]\n",
      "epoch:26 step:25032 [D loss: 0.582690, acc.: 71.88%] [G loss: 1.375524]\n",
      "epoch:26 step:25033 [D loss: 0.554043, acc.: 67.97%] [G loss: 1.081161]\n",
      "epoch:26 step:25034 [D loss: 0.547252, acc.: 71.88%] [G loss: 1.763096]\n",
      "epoch:26 step:25035 [D loss: 1.419906, acc.: 13.28%] [G loss: 0.681840]\n",
      "epoch:26 step:25036 [D loss: 0.904204, acc.: 41.41%] [G loss: 0.876797]\n",
      "epoch:26 step:25037 [D loss: 0.829361, acc.: 46.09%] [G loss: 1.128551]\n",
      "epoch:26 step:25038 [D loss: 0.534722, acc.: 74.22%] [G loss: 1.243500]\n",
      "epoch:26 step:25039 [D loss: 0.734724, acc.: 53.91%] [G loss: 1.159295]\n",
      "epoch:26 step:25040 [D loss: 1.017481, acc.: 32.03%] [G loss: 0.799727]\n",
      "epoch:26 step:25041 [D loss: 0.738395, acc.: 54.69%] [G loss: 0.835145]\n",
      "epoch:26 step:25042 [D loss: 1.086968, acc.: 25.78%] [G loss: 0.563684]\n",
      "epoch:26 step:25043 [D loss: 0.812515, acc.: 43.75%] [G loss: 1.051677]\n",
      "epoch:26 step:25044 [D loss: 0.526302, acc.: 74.22%] [G loss: 1.220876]\n",
      "epoch:26 step:25045 [D loss: 0.763265, acc.: 45.31%] [G loss: 1.004368]\n",
      "epoch:26 step:25046 [D loss: 0.742324, acc.: 47.66%] [G loss: 0.903242]\n",
      "epoch:26 step:25047 [D loss: 0.588812, acc.: 68.75%] [G loss: 1.378821]\n",
      "epoch:26 step:25048 [D loss: 0.877998, acc.: 39.84%] [G loss: 0.989381]\n",
      "epoch:26 step:25049 [D loss: 0.821259, acc.: 46.09%] [G loss: 0.606196]\n",
      "epoch:26 step:25050 [D loss: 0.675072, acc.: 60.16%] [G loss: 1.478156]\n",
      "epoch:26 step:25051 [D loss: 0.682358, acc.: 60.94%] [G loss: 1.097033]\n",
      "epoch:26 step:25052 [D loss: 0.388802, acc.: 85.94%] [G loss: 1.388634]\n",
      "epoch:26 step:25053 [D loss: 0.454048, acc.: 83.59%] [G loss: 1.247589]\n",
      "epoch:26 step:25054 [D loss: 0.544629, acc.: 71.88%] [G loss: 1.186092]\n",
      "epoch:26 step:25055 [D loss: 0.430492, acc.: 78.12%] [G loss: 1.326052]\n",
      "epoch:26 step:25056 [D loss: 0.268386, acc.: 96.09%] [G loss: 1.696228]\n",
      "epoch:26 step:25057 [D loss: 0.422152, acc.: 86.72%] [G loss: 1.343423]\n",
      "epoch:26 step:25058 [D loss: 0.547533, acc.: 71.88%] [G loss: 1.296767]\n",
      "epoch:26 step:25059 [D loss: 0.770553, acc.: 55.47%] [G loss: 1.300540]\n",
      "epoch:26 step:25060 [D loss: 0.712738, acc.: 58.59%] [G loss: 1.043728]\n",
      "epoch:26 step:25061 [D loss: 0.583801, acc.: 64.84%] [G loss: 0.966103]\n",
      "epoch:26 step:25062 [D loss: 0.526382, acc.: 75.00%] [G loss: 1.180306]\n",
      "epoch:26 step:25063 [D loss: 0.489642, acc.: 82.81%] [G loss: 1.285539]\n",
      "epoch:26 step:25064 [D loss: 0.769186, acc.: 47.66%] [G loss: 1.144508]\n",
      "epoch:26 step:25065 [D loss: 0.718894, acc.: 51.56%] [G loss: 1.253679]\n",
      "epoch:26 step:25066 [D loss: 0.703576, acc.: 54.69%] [G loss: 1.061615]\n",
      "epoch:26 step:25067 [D loss: 0.704828, acc.: 57.81%] [G loss: 1.008225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25068 [D loss: 0.581081, acc.: 67.19%] [G loss: 1.031427]\n",
      "epoch:26 step:25069 [D loss: 0.460189, acc.: 82.03%] [G loss: 1.101559]\n",
      "epoch:26 step:25070 [D loss: 0.399383, acc.: 89.06%] [G loss: 1.391878]\n",
      "epoch:26 step:25071 [D loss: 0.471073, acc.: 76.56%] [G loss: 1.032428]\n",
      "epoch:26 step:25072 [D loss: 0.596991, acc.: 67.19%] [G loss: 0.977648]\n",
      "epoch:26 step:25073 [D loss: 0.666369, acc.: 58.59%] [G loss: 1.102277]\n",
      "epoch:26 step:25074 [D loss: 0.574811, acc.: 68.75%] [G loss: 1.447286]\n",
      "epoch:26 step:25075 [D loss: 0.602503, acc.: 67.97%] [G loss: 1.206849]\n",
      "epoch:26 step:25076 [D loss: 0.500607, acc.: 78.12%] [G loss: 1.380134]\n",
      "epoch:26 step:25077 [D loss: 0.549317, acc.: 73.44%] [G loss: 1.220721]\n",
      "epoch:26 step:25078 [D loss: 0.631276, acc.: 59.38%] [G loss: 0.976149]\n",
      "epoch:26 step:25079 [D loss: 0.757395, acc.: 50.00%] [G loss: 0.754421]\n",
      "epoch:26 step:25080 [D loss: 0.806004, acc.: 42.19%] [G loss: 0.904322]\n",
      "epoch:26 step:25081 [D loss: 0.645932, acc.: 60.94%] [G loss: 1.053355]\n",
      "epoch:26 step:25082 [D loss: 0.499945, acc.: 78.91%] [G loss: 1.011804]\n",
      "epoch:26 step:25083 [D loss: 0.600038, acc.: 67.19%] [G loss: 1.388006]\n",
      "epoch:26 step:25084 [D loss: 0.611272, acc.: 61.72%] [G loss: 1.221178]\n",
      "epoch:26 step:25085 [D loss: 0.593526, acc.: 71.09%] [G loss: 1.104447]\n",
      "epoch:26 step:25086 [D loss: 0.441919, acc.: 80.47%] [G loss: 1.157491]\n",
      "epoch:26 step:25087 [D loss: 0.492497, acc.: 75.78%] [G loss: 1.349622]\n",
      "epoch:26 step:25088 [D loss: 0.593050, acc.: 71.09%] [G loss: 1.527201]\n",
      "epoch:26 step:25089 [D loss: 0.601425, acc.: 64.84%] [G loss: 1.732100]\n",
      "epoch:26 step:25090 [D loss: 0.592469, acc.: 68.75%] [G loss: 1.225677]\n",
      "epoch:26 step:25091 [D loss: 0.457405, acc.: 85.94%] [G loss: 1.510477]\n",
      "epoch:26 step:25092 [D loss: 0.545110, acc.: 76.56%] [G loss: 1.542017]\n",
      "epoch:26 step:25093 [D loss: 0.425416, acc.: 85.16%] [G loss: 1.347795]\n",
      "epoch:26 step:25094 [D loss: 0.264255, acc.: 97.66%] [G loss: 1.598505]\n",
      "epoch:26 step:25095 [D loss: 0.292215, acc.: 94.53%] [G loss: 1.813102]\n",
      "epoch:26 step:25096 [D loss: 0.750223, acc.: 53.91%] [G loss: 1.069946]\n",
      "epoch:26 step:25097 [D loss: 0.846869, acc.: 46.09%] [G loss: 1.298826]\n",
      "epoch:26 step:25098 [D loss: 0.720757, acc.: 54.69%] [G loss: 0.955941]\n",
      "epoch:26 step:25099 [D loss: 0.593609, acc.: 69.53%] [G loss: 0.992324]\n",
      "epoch:26 step:25100 [D loss: 0.550834, acc.: 77.34%] [G loss: 1.077171]\n",
      "epoch:26 step:25101 [D loss: 0.669834, acc.: 60.16%] [G loss: 1.159256]\n",
      "epoch:26 step:25102 [D loss: 0.527857, acc.: 69.53%] [G loss: 1.054457]\n",
      "epoch:26 step:25103 [D loss: 0.721792, acc.: 57.03%] [G loss: 1.404402]\n",
      "epoch:26 step:25104 [D loss: 0.665313, acc.: 60.16%] [G loss: 1.130130]\n",
      "epoch:26 step:25105 [D loss: 0.605068, acc.: 67.19%] [G loss: 1.113119]\n",
      "epoch:26 step:25106 [D loss: 0.747721, acc.: 53.12%] [G loss: 1.011587]\n",
      "epoch:26 step:25107 [D loss: 0.293165, acc.: 90.62%] [G loss: 1.144321]\n",
      "epoch:26 step:25108 [D loss: 0.433323, acc.: 85.16%] [G loss: 1.184245]\n",
      "epoch:26 step:25109 [D loss: 0.523195, acc.: 76.56%] [G loss: 1.509188]\n",
      "epoch:26 step:25110 [D loss: 0.543332, acc.: 72.66%] [G loss: 1.206435]\n",
      "epoch:26 step:25111 [D loss: 0.647454, acc.: 60.16%] [G loss: 1.125075]\n",
      "epoch:26 step:25112 [D loss: 0.478163, acc.: 82.81%] [G loss: 1.225103]\n",
      "epoch:26 step:25113 [D loss: 0.530924, acc.: 72.66%] [G loss: 0.792539]\n",
      "epoch:26 step:25114 [D loss: 0.588966, acc.: 65.62%] [G loss: 1.143846]\n",
      "epoch:26 step:25115 [D loss: 0.614490, acc.: 65.62%] [G loss: 0.902658]\n",
      "epoch:26 step:25116 [D loss: 0.540567, acc.: 78.12%] [G loss: 1.154366]\n",
      "epoch:26 step:25117 [D loss: 0.313422, acc.: 92.19%] [G loss: 1.445096]\n",
      "epoch:26 step:25118 [D loss: 0.435053, acc.: 83.59%] [G loss: 0.951407]\n",
      "epoch:26 step:25119 [D loss: 0.529861, acc.: 73.44%] [G loss: 1.370416]\n",
      "epoch:26 step:25120 [D loss: 0.558876, acc.: 73.44%] [G loss: 1.037792]\n",
      "epoch:26 step:25121 [D loss: 0.950038, acc.: 25.00%] [G loss: 1.026195]\n",
      "epoch:26 step:25122 [D loss: 0.922764, acc.: 35.94%] [G loss: 1.202554]\n",
      "epoch:26 step:25123 [D loss: 0.794017, acc.: 49.22%] [G loss: 0.837107]\n",
      "epoch:26 step:25124 [D loss: 0.663982, acc.: 57.81%] [G loss: 1.000489]\n",
      "epoch:26 step:25125 [D loss: 0.942438, acc.: 46.09%] [G loss: 0.877023]\n",
      "epoch:26 step:25126 [D loss: 0.410251, acc.: 89.06%] [G loss: 1.421810]\n",
      "epoch:26 step:25127 [D loss: 1.058457, acc.: 28.12%] [G loss: 1.297761]\n",
      "epoch:26 step:25128 [D loss: 0.751292, acc.: 52.34%] [G loss: 1.330019]\n",
      "epoch:26 step:25129 [D loss: 0.406291, acc.: 84.38%] [G loss: 1.322664]\n",
      "epoch:26 step:25130 [D loss: 0.266785, acc.: 96.88%] [G loss: 1.674411]\n",
      "epoch:26 step:25131 [D loss: 0.208001, acc.: 98.44%] [G loss: 1.501909]\n",
      "epoch:26 step:25132 [D loss: 0.512157, acc.: 74.22%] [G loss: 1.262251]\n",
      "epoch:26 step:25133 [D loss: 0.590993, acc.: 66.41%] [G loss: 1.248961]\n",
      "epoch:26 step:25134 [D loss: 0.476210, acc.: 78.12%] [G loss: 1.331565]\n",
      "epoch:26 step:25135 [D loss: 0.477877, acc.: 79.69%] [G loss: 0.930349]\n",
      "epoch:26 step:25136 [D loss: 0.323699, acc.: 83.59%] [G loss: 1.490655]\n",
      "epoch:26 step:25137 [D loss: 0.195827, acc.: 97.66%] [G loss: 1.774175]\n",
      "epoch:26 step:25138 [D loss: 0.376769, acc.: 86.72%] [G loss: 1.540673]\n",
      "epoch:26 step:25139 [D loss: 0.317059, acc.: 92.97%] [G loss: 2.180712]\n",
      "epoch:26 step:25140 [D loss: 0.699808, acc.: 57.03%] [G loss: 1.071201]\n",
      "epoch:26 step:25141 [D loss: 0.760753, acc.: 52.34%] [G loss: 0.802458]\n",
      "epoch:26 step:25142 [D loss: 0.763183, acc.: 56.25%] [G loss: 1.275279]\n",
      "epoch:26 step:25143 [D loss: 0.580521, acc.: 67.97%] [G loss: 1.211460]\n",
      "epoch:26 step:25144 [D loss: 0.481523, acc.: 79.69%] [G loss: 1.604801]\n",
      "epoch:26 step:25145 [D loss: 0.600548, acc.: 69.53%] [G loss: 1.397692]\n",
      "epoch:26 step:25146 [D loss: 0.677804, acc.: 60.94%] [G loss: 1.032144]\n",
      "epoch:26 step:25147 [D loss: 0.589415, acc.: 71.88%] [G loss: 0.759050]\n",
      "epoch:26 step:25148 [D loss: 0.513767, acc.: 75.78%] [G loss: 0.886549]\n",
      "epoch:26 step:25149 [D loss: 0.852337, acc.: 37.50%] [G loss: 0.983113]\n",
      "epoch:26 step:25150 [D loss: 0.605615, acc.: 69.53%] [G loss: 1.214085]\n",
      "epoch:26 step:25151 [D loss: 0.832353, acc.: 39.06%] [G loss: 1.075586]\n",
      "epoch:26 step:25152 [D loss: 0.538664, acc.: 72.66%] [G loss: 0.996160]\n",
      "epoch:26 step:25153 [D loss: 0.405911, acc.: 82.81%] [G loss: 1.273684]\n",
      "epoch:26 step:25154 [D loss: 0.307671, acc.: 92.19%] [G loss: 1.653008]\n",
      "epoch:26 step:25155 [D loss: 0.439208, acc.: 83.59%] [G loss: 1.530701]\n",
      "epoch:26 step:25156 [D loss: 0.271613, acc.: 98.44%] [G loss: 1.707491]\n",
      "epoch:26 step:25157 [D loss: 0.488441, acc.: 77.34%] [G loss: 1.597771]\n",
      "epoch:26 step:25158 [D loss: 0.452317, acc.: 82.03%] [G loss: 1.363443]\n",
      "epoch:26 step:25159 [D loss: 0.543327, acc.: 71.88%] [G loss: 1.007371]\n",
      "epoch:26 step:25160 [D loss: 0.596576, acc.: 67.19%] [G loss: 1.279799]\n",
      "epoch:26 step:25161 [D loss: 0.718758, acc.: 54.69%] [G loss: 1.303027]\n",
      "epoch:26 step:25162 [D loss: 0.588180, acc.: 68.75%] [G loss: 1.242941]\n",
      "epoch:26 step:25163 [D loss: 0.808295, acc.: 50.00%] [G loss: 0.746801]\n",
      "epoch:26 step:25164 [D loss: 0.438806, acc.: 82.81%] [G loss: 1.174620]\n",
      "epoch:26 step:25165 [D loss: 0.619190, acc.: 65.62%] [G loss: 1.116047]\n",
      "epoch:26 step:25166 [D loss: 0.538542, acc.: 75.00%] [G loss: 1.156134]\n",
      "epoch:26 step:25167 [D loss: 0.436020, acc.: 79.69%] [G loss: 1.374320]\n",
      "epoch:26 step:25168 [D loss: 0.317969, acc.: 92.19%] [G loss: 1.346367]\n",
      "epoch:26 step:25169 [D loss: 0.672901, acc.: 60.94%] [G loss: 1.358002]\n",
      "epoch:26 step:25170 [D loss: 0.462325, acc.: 86.72%] [G loss: 1.472148]\n",
      "epoch:26 step:25171 [D loss: 0.620353, acc.: 64.06%] [G loss: 1.215448]\n",
      "epoch:26 step:25172 [D loss: 0.497057, acc.: 75.78%] [G loss: 1.214154]\n",
      "epoch:26 step:25173 [D loss: 0.809623, acc.: 42.19%] [G loss: 1.172838]\n",
      "epoch:26 step:25174 [D loss: 0.747309, acc.: 51.56%] [G loss: 1.333698]\n",
      "epoch:26 step:25175 [D loss: 0.582159, acc.: 68.75%] [G loss: 1.097801]\n",
      "epoch:26 step:25176 [D loss: 0.492196, acc.: 79.69%] [G loss: 1.445292]\n",
      "epoch:26 step:25177 [D loss: 0.290842, acc.: 83.59%] [G loss: 1.178912]\n",
      "epoch:26 step:25178 [D loss: 0.269849, acc.: 95.31%] [G loss: 1.563750]\n",
      "epoch:26 step:25179 [D loss: 0.512713, acc.: 76.56%] [G loss: 1.420336]\n",
      "epoch:26 step:25180 [D loss: 0.421682, acc.: 86.72%] [G loss: 1.517775]\n",
      "epoch:26 step:25181 [D loss: 0.641201, acc.: 61.72%] [G loss: 0.969198]\n",
      "epoch:26 step:25182 [D loss: 1.078177, acc.: 25.78%] [G loss: 0.699460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25183 [D loss: 0.666394, acc.: 57.81%] [G loss: 0.980113]\n",
      "epoch:26 step:25184 [D loss: 0.691877, acc.: 58.59%] [G loss: 1.285684]\n",
      "epoch:26 step:25185 [D loss: 0.682049, acc.: 60.94%] [G loss: 0.939007]\n",
      "epoch:26 step:25186 [D loss: 0.399270, acc.: 86.72%] [G loss: 1.358172]\n",
      "epoch:26 step:25187 [D loss: 0.409436, acc.: 89.06%] [G loss: 1.804189]\n",
      "epoch:26 step:25188 [D loss: 0.646428, acc.: 60.94%] [G loss: 1.266553]\n",
      "epoch:26 step:25189 [D loss: 0.905096, acc.: 36.72%] [G loss: 1.154874]\n",
      "epoch:26 step:25190 [D loss: 0.751851, acc.: 46.88%] [G loss: 0.825470]\n",
      "epoch:26 step:25191 [D loss: 0.501123, acc.: 81.25%] [G loss: 1.115517]\n",
      "epoch:26 step:25192 [D loss: 0.681146, acc.: 62.50%] [G loss: 0.892202]\n",
      "epoch:26 step:25193 [D loss: 0.299109, acc.: 91.41%] [G loss: 1.908902]\n",
      "epoch:26 step:25194 [D loss: 0.375081, acc.: 91.41%] [G loss: 1.679512]\n",
      "epoch:26 step:25195 [D loss: 0.374520, acc.: 88.28%] [G loss: 1.634629]\n",
      "epoch:26 step:25196 [D loss: 1.281504, acc.: 10.94%] [G loss: 0.772029]\n",
      "epoch:26 step:25197 [D loss: 0.789995, acc.: 47.66%] [G loss: 1.503292]\n",
      "epoch:26 step:25198 [D loss: 1.036859, acc.: 24.22%] [G loss: 0.820820]\n",
      "epoch:26 step:25199 [D loss: 0.678132, acc.: 57.03%] [G loss: 1.238624]\n",
      "epoch:26 step:25200 [D loss: 0.800690, acc.: 46.09%] [G loss: 1.250873]\n",
      "epoch:26 step:25201 [D loss: 0.686878, acc.: 57.81%] [G loss: 1.204514]\n",
      "epoch:26 step:25202 [D loss: 0.417544, acc.: 85.16%] [G loss: 1.325078]\n",
      "epoch:26 step:25203 [D loss: 0.375882, acc.: 90.62%] [G loss: 1.542863]\n",
      "epoch:26 step:25204 [D loss: 0.439303, acc.: 83.59%] [G loss: 1.780418]\n",
      "epoch:26 step:25205 [D loss: 0.784711, acc.: 49.22%] [G loss: 1.033422]\n",
      "epoch:26 step:25206 [D loss: 0.838776, acc.: 43.75%] [G loss: 1.327459]\n",
      "epoch:26 step:25207 [D loss: 0.655755, acc.: 59.38%] [G loss: 1.079675]\n",
      "epoch:26 step:25208 [D loss: 0.498108, acc.: 74.22%] [G loss: 1.263073]\n",
      "epoch:26 step:25209 [D loss: 0.605538, acc.: 67.19%] [G loss: 1.115572]\n",
      "epoch:26 step:25210 [D loss: 0.496188, acc.: 80.47%] [G loss: 1.257947]\n",
      "epoch:26 step:25211 [D loss: 0.445410, acc.: 84.38%] [G loss: 1.100886]\n",
      "epoch:26 step:25212 [D loss: 0.293970, acc.: 96.88%] [G loss: 1.588358]\n",
      "epoch:26 step:25213 [D loss: 0.223873, acc.: 97.66%] [G loss: 1.776269]\n",
      "epoch:26 step:25214 [D loss: 0.174198, acc.: 100.00%] [G loss: 2.244362]\n",
      "epoch:26 step:25215 [D loss: 0.261835, acc.: 97.66%] [G loss: 2.002239]\n",
      "epoch:26 step:25216 [D loss: 0.286937, acc.: 95.31%] [G loss: 1.628599]\n",
      "epoch:26 step:25217 [D loss: 0.424671, acc.: 82.03%] [G loss: 1.831151]\n",
      "epoch:26 step:25218 [D loss: 0.367131, acc.: 86.72%] [G loss: 1.224260]\n",
      "epoch:26 step:25219 [D loss: 0.277845, acc.: 93.75%] [G loss: 1.765358]\n",
      "epoch:26 step:25220 [D loss: 0.800116, acc.: 46.09%] [G loss: 1.200032]\n",
      "epoch:26 step:25221 [D loss: 0.812985, acc.: 42.97%] [G loss: 1.289888]\n",
      "epoch:26 step:25222 [D loss: 0.610832, acc.: 67.97%] [G loss: 0.964907]\n",
      "epoch:26 step:25223 [D loss: 0.470883, acc.: 78.12%] [G loss: 1.158578]\n",
      "epoch:26 step:25224 [D loss: 0.668181, acc.: 62.50%] [G loss: 1.190784]\n",
      "epoch:26 step:25225 [D loss: 0.623553, acc.: 66.41%] [G loss: 1.113332]\n",
      "epoch:26 step:25226 [D loss: 0.747865, acc.: 52.34%] [G loss: 0.862983]\n",
      "epoch:26 step:25227 [D loss: 0.565578, acc.: 71.09%] [G loss: 0.907753]\n",
      "epoch:26 step:25228 [D loss: 0.548322, acc.: 74.22%] [G loss: 1.071053]\n",
      "epoch:26 step:25229 [D loss: 0.515952, acc.: 80.47%] [G loss: 0.969730]\n",
      "epoch:26 step:25230 [D loss: 0.738618, acc.: 51.56%] [G loss: 1.071536]\n",
      "epoch:26 step:25231 [D loss: 0.537562, acc.: 73.44%] [G loss: 1.054161]\n",
      "epoch:26 step:25232 [D loss: 0.868629, acc.: 40.62%] [G loss: 0.988931]\n",
      "epoch:26 step:25233 [D loss: 0.505060, acc.: 78.91%] [G loss: 1.414918]\n",
      "epoch:26 step:25234 [D loss: 0.793543, acc.: 44.53%] [G loss: 0.976966]\n",
      "epoch:26 step:25235 [D loss: 0.557095, acc.: 70.31%] [G loss: 1.330280]\n",
      "epoch:26 step:25236 [D loss: 0.965654, acc.: 33.59%] [G loss: 0.821846]\n",
      "epoch:26 step:25237 [D loss: 0.581423, acc.: 69.53%] [G loss: 1.253491]\n",
      "epoch:26 step:25238 [D loss: 0.728415, acc.: 53.12%] [G loss: 0.960334]\n",
      "epoch:26 step:25239 [D loss: 0.911733, acc.: 35.94%] [G loss: 0.737647]\n",
      "epoch:26 step:25240 [D loss: 0.460009, acc.: 85.94%] [G loss: 1.339837]\n",
      "epoch:26 step:25241 [D loss: 0.585726, acc.: 68.75%] [G loss: 1.437642]\n",
      "epoch:26 step:25242 [D loss: 0.642900, acc.: 67.19%] [G loss: 1.193297]\n",
      "epoch:26 step:25243 [D loss: 0.715594, acc.: 57.03%] [G loss: 1.138285]\n",
      "epoch:26 step:25244 [D loss: 0.524887, acc.: 76.56%] [G loss: 1.086489]\n",
      "epoch:26 step:25245 [D loss: 0.561906, acc.: 68.75%] [G loss: 1.191048]\n",
      "epoch:26 step:25246 [D loss: 0.537637, acc.: 72.66%] [G loss: 1.026835]\n",
      "epoch:26 step:25247 [D loss: 0.277176, acc.: 92.97%] [G loss: 1.190036]\n",
      "epoch:26 step:25248 [D loss: 0.547997, acc.: 75.78%] [G loss: 1.326062]\n",
      "epoch:26 step:25249 [D loss: 0.398336, acc.: 87.50%] [G loss: 1.585811]\n",
      "epoch:26 step:25250 [D loss: 0.469631, acc.: 80.47%] [G loss: 1.425189]\n",
      "epoch:26 step:25251 [D loss: 0.317940, acc.: 91.41%] [G loss: 0.908376]\n",
      "epoch:26 step:25252 [D loss: 0.605838, acc.: 69.53%] [G loss: 0.986578]\n",
      "epoch:26 step:25253 [D loss: 0.826748, acc.: 47.66%] [G loss: 1.478875]\n",
      "epoch:26 step:25254 [D loss: 0.580592, acc.: 72.66%] [G loss: 1.002404]\n",
      "epoch:26 step:25255 [D loss: 0.473227, acc.: 82.81%] [G loss: 1.319187]\n",
      "epoch:26 step:25256 [D loss: 0.400900, acc.: 87.50%] [G loss: 1.243691]\n",
      "epoch:26 step:25257 [D loss: 0.352695, acc.: 89.06%] [G loss: 1.627868]\n",
      "epoch:26 step:25258 [D loss: 0.364153, acc.: 87.50%] [G loss: 1.730814]\n",
      "epoch:26 step:25259 [D loss: 0.341644, acc.: 92.97%] [G loss: 1.518299]\n",
      "epoch:26 step:25260 [D loss: 0.259055, acc.: 93.75%] [G loss: 1.804780]\n",
      "epoch:26 step:25261 [D loss: 0.158088, acc.: 100.00%] [G loss: 1.908254]\n",
      "epoch:26 step:25262 [D loss: 0.192858, acc.: 98.44%] [G loss: 1.641151]\n",
      "epoch:26 step:25263 [D loss: 0.233219, acc.: 96.88%] [G loss: 2.084315]\n",
      "epoch:26 step:25264 [D loss: 0.586936, acc.: 67.19%] [G loss: 1.425977]\n",
      "epoch:26 step:25265 [D loss: 0.487508, acc.: 77.34%] [G loss: 1.427598]\n",
      "epoch:26 step:25266 [D loss: 0.854323, acc.: 46.09%] [G loss: 1.203788]\n",
      "epoch:26 step:25267 [D loss: 0.677302, acc.: 63.28%] [G loss: 1.215630]\n",
      "epoch:26 step:25268 [D loss: 0.728475, acc.: 52.34%] [G loss: 1.078633]\n",
      "epoch:26 step:25269 [D loss: 0.744168, acc.: 56.25%] [G loss: 0.961619]\n",
      "epoch:26 step:25270 [D loss: 0.501875, acc.: 77.34%] [G loss: 0.826632]\n",
      "epoch:26 step:25271 [D loss: 0.370077, acc.: 82.81%] [G loss: 1.342882]\n",
      "epoch:26 step:25272 [D loss: 0.626454, acc.: 71.88%] [G loss: 1.268109]\n",
      "epoch:26 step:25273 [D loss: 0.239290, acc.: 95.31%] [G loss: 1.637236]\n",
      "epoch:26 step:25274 [D loss: 0.179293, acc.: 97.66%] [G loss: 1.609989]\n",
      "epoch:26 step:25275 [D loss: 0.752658, acc.: 57.81%] [G loss: 1.531929]\n",
      "epoch:26 step:25276 [D loss: 0.800556, acc.: 50.00%] [G loss: 1.181432]\n",
      "epoch:26 step:25277 [D loss: 0.783215, acc.: 50.00%] [G loss: 0.707462]\n",
      "epoch:26 step:25278 [D loss: 0.640759, acc.: 62.50%] [G loss: 1.264019]\n",
      "epoch:26 step:25279 [D loss: 0.741127, acc.: 57.81%] [G loss: 1.116001]\n",
      "epoch:26 step:25280 [D loss: 0.483272, acc.: 80.47%] [G loss: 0.948880]\n",
      "epoch:26 step:25281 [D loss: 0.524088, acc.: 66.41%] [G loss: 1.005365]\n",
      "epoch:26 step:25282 [D loss: 0.601667, acc.: 67.19%] [G loss: 0.998488]\n",
      "epoch:26 step:25283 [D loss: 0.529747, acc.: 72.66%] [G loss: 1.533214]\n",
      "epoch:26 step:25284 [D loss: 0.667861, acc.: 62.50%] [G loss: 1.432821]\n",
      "epoch:26 step:25285 [D loss: 0.634683, acc.: 60.94%] [G loss: 1.189800]\n",
      "epoch:26 step:25286 [D loss: 0.604320, acc.: 64.06%] [G loss: 1.159996]\n",
      "epoch:26 step:25287 [D loss: 0.466683, acc.: 82.03%] [G loss: 1.529345]\n",
      "epoch:26 step:25288 [D loss: 0.473092, acc.: 85.16%] [G loss: 1.406042]\n",
      "epoch:26 step:25289 [D loss: 0.241668, acc.: 96.09%] [G loss: 1.341834]\n",
      "epoch:26 step:25290 [D loss: 0.953966, acc.: 44.53%] [G loss: 1.275269]\n",
      "epoch:26 step:25291 [D loss: 0.389907, acc.: 84.38%] [G loss: 1.059663]\n",
      "epoch:26 step:25292 [D loss: 0.440391, acc.: 84.38%] [G loss: 1.195400]\n",
      "epoch:26 step:25293 [D loss: 0.682029, acc.: 61.72%] [G loss: 1.117257]\n",
      "epoch:26 step:25294 [D loss: 0.569369, acc.: 71.09%] [G loss: 1.097806]\n",
      "epoch:26 step:25295 [D loss: 0.677231, acc.: 60.16%] [G loss: 1.038974]\n",
      "epoch:26 step:25296 [D loss: 0.309532, acc.: 94.53%] [G loss: 1.456065]\n",
      "epoch:26 step:25297 [D loss: 0.639887, acc.: 58.59%] [G loss: 1.173457]\n",
      "epoch:26 step:25298 [D loss: 0.461416, acc.: 83.59%] [G loss: 1.133476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25299 [D loss: 0.219494, acc.: 94.53%] [G loss: 1.693466]\n",
      "epoch:27 step:25300 [D loss: 0.704487, acc.: 60.16%] [G loss: 1.331036]\n",
      "epoch:27 step:25301 [D loss: 0.812931, acc.: 42.97%] [G loss: 1.003072]\n",
      "epoch:27 step:25302 [D loss: 0.831331, acc.: 43.75%] [G loss: 0.984831]\n",
      "epoch:27 step:25303 [D loss: 0.640975, acc.: 60.94%] [G loss: 1.040666]\n",
      "epoch:27 step:25304 [D loss: 0.597501, acc.: 68.75%] [G loss: 1.354967]\n",
      "epoch:27 step:25305 [D loss: 0.710522, acc.: 60.16%] [G loss: 0.893552]\n",
      "epoch:27 step:25306 [D loss: 0.544302, acc.: 74.22%] [G loss: 1.380324]\n",
      "epoch:27 step:25307 [D loss: 0.711612, acc.: 53.91%] [G loss: 1.074484]\n",
      "epoch:27 step:25308 [D loss: 0.544130, acc.: 76.56%] [G loss: 1.240198]\n",
      "epoch:27 step:25309 [D loss: 0.438254, acc.: 85.94%] [G loss: 1.169018]\n",
      "epoch:27 step:25310 [D loss: 0.603774, acc.: 62.50%] [G loss: 1.176586]\n",
      "epoch:27 step:25311 [D loss: 0.683847, acc.: 62.50%] [G loss: 0.980051]\n",
      "epoch:27 step:25312 [D loss: 0.654809, acc.: 64.84%] [G loss: 0.930972]\n",
      "epoch:27 step:25313 [D loss: 0.713327, acc.: 51.56%] [G loss: 0.890821]\n",
      "epoch:27 step:25314 [D loss: 0.545932, acc.: 69.53%] [G loss: 0.966367]\n",
      "epoch:27 step:25315 [D loss: 0.426640, acc.: 88.28%] [G loss: 1.284157]\n",
      "epoch:27 step:25316 [D loss: 0.645025, acc.: 61.72%] [G loss: 1.271772]\n",
      "epoch:27 step:25317 [D loss: 0.756636, acc.: 52.34%] [G loss: 0.894164]\n",
      "epoch:27 step:25318 [D loss: 0.882573, acc.: 35.94%] [G loss: 0.962579]\n",
      "epoch:27 step:25319 [D loss: 0.392638, acc.: 89.84%] [G loss: 1.311000]\n",
      "epoch:27 step:25320 [D loss: 0.498781, acc.: 77.34%] [G loss: 1.306526]\n",
      "epoch:27 step:25321 [D loss: 0.566109, acc.: 71.09%] [G loss: 1.261741]\n",
      "epoch:27 step:25322 [D loss: 0.557856, acc.: 71.88%] [G loss: 1.281645]\n",
      "epoch:27 step:25323 [D loss: 0.654703, acc.: 61.72%] [G loss: 1.088431]\n",
      "epoch:27 step:25324 [D loss: 0.472123, acc.: 79.69%] [G loss: 0.982283]\n",
      "epoch:27 step:25325 [D loss: 0.398521, acc.: 86.72%] [G loss: 1.177788]\n",
      "epoch:27 step:25326 [D loss: 0.244264, acc.: 94.53%] [G loss: 1.824235]\n",
      "epoch:27 step:25327 [D loss: 0.351144, acc.: 91.41%] [G loss: 1.652087]\n",
      "epoch:27 step:25328 [D loss: 0.346395, acc.: 89.06%] [G loss: 1.448005]\n",
      "epoch:27 step:25329 [D loss: 0.286781, acc.: 95.31%] [G loss: 1.788464]\n",
      "epoch:27 step:25330 [D loss: 0.225544, acc.: 99.22%] [G loss: 1.760464]\n",
      "epoch:27 step:25331 [D loss: 0.341150, acc.: 88.28%] [G loss: 1.345054]\n",
      "epoch:27 step:25332 [D loss: 0.304454, acc.: 92.97%] [G loss: 1.559065]\n",
      "epoch:27 step:25333 [D loss: 0.265924, acc.: 93.75%] [G loss: 1.947870]\n",
      "epoch:27 step:25334 [D loss: 0.159841, acc.: 99.22%] [G loss: 2.325830]\n",
      "epoch:27 step:25335 [D loss: 0.152953, acc.: 98.44%] [G loss: 2.069444]\n",
      "epoch:27 step:25336 [D loss: 0.973638, acc.: 33.59%] [G loss: 1.053820]\n",
      "epoch:27 step:25337 [D loss: 0.854075, acc.: 50.00%] [G loss: 1.191497]\n",
      "epoch:27 step:25338 [D loss: 0.660140, acc.: 64.06%] [G loss: 1.366189]\n",
      "epoch:27 step:25339 [D loss: 0.497402, acc.: 74.22%] [G loss: 1.315037]\n",
      "epoch:27 step:25340 [D loss: 0.685682, acc.: 55.47%] [G loss: 1.180749]\n",
      "epoch:27 step:25341 [D loss: 0.656387, acc.: 66.41%] [G loss: 0.977422]\n",
      "epoch:27 step:25342 [D loss: 0.533013, acc.: 74.22%] [G loss: 1.218161]\n",
      "epoch:27 step:25343 [D loss: 0.601379, acc.: 65.62%] [G loss: 1.033211]\n",
      "epoch:27 step:25344 [D loss: 0.586168, acc.: 65.62%] [G loss: 0.962720]\n",
      "epoch:27 step:25345 [D loss: 0.937649, acc.: 29.69%] [G loss: 1.049549]\n",
      "epoch:27 step:25346 [D loss: 0.623284, acc.: 63.28%] [G loss: 1.241261]\n",
      "epoch:27 step:25347 [D loss: 0.739084, acc.: 50.78%] [G loss: 1.047035]\n",
      "epoch:27 step:25348 [D loss: 0.596285, acc.: 65.62%] [G loss: 1.479603]\n",
      "epoch:27 step:25349 [D loss: 0.602419, acc.: 65.62%] [G loss: 1.352773]\n",
      "epoch:27 step:25350 [D loss: 0.739122, acc.: 53.91%] [G loss: 0.978233]\n",
      "epoch:27 step:25351 [D loss: 0.607193, acc.: 69.53%] [G loss: 1.210582]\n",
      "epoch:27 step:25352 [D loss: 0.575971, acc.: 70.31%] [G loss: 0.996599]\n",
      "epoch:27 step:25353 [D loss: 0.436346, acc.: 83.59%] [G loss: 1.314337]\n",
      "epoch:27 step:25354 [D loss: 0.375545, acc.: 91.41%] [G loss: 1.256697]\n",
      "epoch:27 step:25355 [D loss: 0.612297, acc.: 67.19%] [G loss: 1.316925]\n",
      "epoch:27 step:25356 [D loss: 0.831848, acc.: 42.19%] [G loss: 0.949630]\n",
      "epoch:27 step:25357 [D loss: 0.837219, acc.: 38.28%] [G loss: 1.149935]\n",
      "epoch:27 step:25358 [D loss: 0.780036, acc.: 47.66%] [G loss: 1.066989]\n",
      "epoch:27 step:25359 [D loss: 0.671761, acc.: 60.94%] [G loss: 0.749472]\n",
      "epoch:27 step:25360 [D loss: 0.674671, acc.: 58.59%] [G loss: 0.869921]\n",
      "epoch:27 step:25361 [D loss: 0.657883, acc.: 54.69%] [G loss: 0.774041]\n",
      "epoch:27 step:25362 [D loss: 0.554483, acc.: 75.00%] [G loss: 0.983984]\n",
      "epoch:27 step:25363 [D loss: 0.555349, acc.: 72.66%] [G loss: 1.180011]\n",
      "epoch:27 step:25364 [D loss: 0.678047, acc.: 60.16%] [G loss: 0.829090]\n",
      "epoch:27 step:25365 [D loss: 0.613363, acc.: 61.72%] [G loss: 1.198540]\n",
      "epoch:27 step:25366 [D loss: 0.691446, acc.: 57.81%] [G loss: 0.971693]\n",
      "epoch:27 step:25367 [D loss: 0.495862, acc.: 82.81%] [G loss: 1.035331]\n",
      "epoch:27 step:25368 [D loss: 0.366141, acc.: 90.62%] [G loss: 1.204083]\n",
      "epoch:27 step:25369 [D loss: 0.526310, acc.: 78.12%] [G loss: 1.335884]\n",
      "epoch:27 step:25370 [D loss: 0.844769, acc.: 50.00%] [G loss: 1.093520]\n",
      "epoch:27 step:25371 [D loss: 0.624553, acc.: 63.28%] [G loss: 1.333382]\n",
      "epoch:27 step:25372 [D loss: 0.882516, acc.: 40.62%] [G loss: 1.037775]\n",
      "epoch:27 step:25373 [D loss: 0.551241, acc.: 71.88%] [G loss: 1.135551]\n",
      "epoch:27 step:25374 [D loss: 0.247811, acc.: 94.53%] [G loss: 1.878369]\n",
      "epoch:27 step:25375 [D loss: 0.246266, acc.: 99.22%] [G loss: 1.477905]\n",
      "epoch:27 step:25376 [D loss: 0.332383, acc.: 91.41%] [G loss: 1.663775]\n",
      "epoch:27 step:25377 [D loss: 0.823813, acc.: 50.00%] [G loss: 1.544696]\n",
      "epoch:27 step:25378 [D loss: 0.649786, acc.: 62.50%] [G loss: 1.255058]\n",
      "epoch:27 step:25379 [D loss: 0.523555, acc.: 75.00%] [G loss: 0.769088]\n",
      "epoch:27 step:25380 [D loss: 0.620632, acc.: 61.72%] [G loss: 1.201381]\n",
      "epoch:27 step:25381 [D loss: 0.583331, acc.: 73.44%] [G loss: 0.958868]\n",
      "epoch:27 step:25382 [D loss: 0.625743, acc.: 64.84%] [G loss: 0.896945]\n",
      "epoch:27 step:25383 [D loss: 0.797000, acc.: 49.22%] [G loss: 0.920962]\n",
      "epoch:27 step:25384 [D loss: 0.649963, acc.: 59.38%] [G loss: 1.074810]\n",
      "epoch:27 step:25385 [D loss: 0.545748, acc.: 75.78%] [G loss: 0.985899]\n",
      "epoch:27 step:25386 [D loss: 0.693859, acc.: 56.25%] [G loss: 0.715126]\n",
      "epoch:27 step:25387 [D loss: 0.483670, acc.: 79.69%] [G loss: 1.018449]\n",
      "epoch:27 step:25388 [D loss: 0.790020, acc.: 46.09%] [G loss: 1.016855]\n",
      "epoch:27 step:25389 [D loss: 0.583752, acc.: 71.09%] [G loss: 1.240553]\n",
      "epoch:27 step:25390 [D loss: 0.626179, acc.: 61.72%] [G loss: 0.908846]\n",
      "epoch:27 step:25391 [D loss: 0.474911, acc.: 86.72%] [G loss: 1.309368]\n",
      "epoch:27 step:25392 [D loss: 0.687732, acc.: 57.81%] [G loss: 0.788382]\n",
      "epoch:27 step:25393 [D loss: 0.750288, acc.: 50.00%] [G loss: 0.903675]\n",
      "epoch:27 step:25394 [D loss: 0.712901, acc.: 55.47%] [G loss: 1.164516]\n",
      "epoch:27 step:25395 [D loss: 0.669383, acc.: 60.94%] [G loss: 1.040832]\n",
      "epoch:27 step:25396 [D loss: 0.516501, acc.: 78.12%] [G loss: 1.477174]\n",
      "epoch:27 step:25397 [D loss: 0.575223, acc.: 69.53%] [G loss: 1.436435]\n",
      "epoch:27 step:25398 [D loss: 0.608900, acc.: 69.53%] [G loss: 1.272589]\n",
      "epoch:27 step:25399 [D loss: 0.552415, acc.: 72.66%] [G loss: 1.073020]\n",
      "epoch:27 step:25400 [D loss: 0.559701, acc.: 70.31%] [G loss: 1.249779]\n",
      "epoch:27 step:25401 [D loss: 0.544662, acc.: 72.66%] [G loss: 1.220531]\n",
      "epoch:27 step:25402 [D loss: 0.474004, acc.: 78.91%] [G loss: 1.065837]\n",
      "epoch:27 step:25403 [D loss: 0.587565, acc.: 68.75%] [G loss: 1.168117]\n",
      "epoch:27 step:25404 [D loss: 0.256162, acc.: 97.66%] [G loss: 1.536924]\n",
      "epoch:27 step:25405 [D loss: 0.327109, acc.: 92.19%] [G loss: 1.625732]\n",
      "epoch:27 step:25406 [D loss: 0.799387, acc.: 49.22%] [G loss: 0.764397]\n",
      "epoch:27 step:25407 [D loss: 0.523897, acc.: 74.22%] [G loss: 1.532844]\n",
      "epoch:27 step:25408 [D loss: 0.474246, acc.: 78.12%] [G loss: 1.320090]\n",
      "epoch:27 step:25409 [D loss: 0.612384, acc.: 67.19%] [G loss: 1.067793]\n",
      "epoch:27 step:25410 [D loss: 0.745042, acc.: 47.66%] [G loss: 0.826828]\n",
      "epoch:27 step:25411 [D loss: 0.566616, acc.: 69.53%] [G loss: 1.347846]\n",
      "epoch:27 step:25412 [D loss: 0.917511, acc.: 37.50%] [G loss: 0.911166]\n",
      "epoch:27 step:25413 [D loss: 0.739265, acc.: 57.03%] [G loss: 1.123775]\n",
      "epoch:27 step:25414 [D loss: 0.670240, acc.: 62.50%] [G loss: 1.222584]\n",
      "epoch:27 step:25415 [D loss: 0.515830, acc.: 75.78%] [G loss: 1.268764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25416 [D loss: 0.420126, acc.: 81.25%] [G loss: 1.288880]\n",
      "epoch:27 step:25417 [D loss: 0.334306, acc.: 93.75%] [G loss: 1.377283]\n",
      "epoch:27 step:25418 [D loss: 0.420667, acc.: 79.69%] [G loss: 1.088346]\n",
      "epoch:27 step:25419 [D loss: 0.790175, acc.: 46.88%] [G loss: 1.567323]\n",
      "epoch:27 step:25420 [D loss: 0.610022, acc.: 64.84%] [G loss: 1.087496]\n",
      "epoch:27 step:25421 [D loss: 0.262780, acc.: 96.88%] [G loss: 1.972340]\n",
      "epoch:27 step:25422 [D loss: 0.713021, acc.: 53.12%] [G loss: 1.635084]\n",
      "epoch:27 step:25423 [D loss: 0.765936, acc.: 49.22%] [G loss: 1.186307]\n",
      "epoch:27 step:25424 [D loss: 0.717476, acc.: 50.00%] [G loss: 1.061847]\n",
      "epoch:27 step:25425 [D loss: 0.649558, acc.: 64.84%] [G loss: 1.358935]\n",
      "epoch:27 step:25426 [D loss: 0.540131, acc.: 78.12%] [G loss: 1.066990]\n",
      "epoch:27 step:25427 [D loss: 0.539305, acc.: 74.22%] [G loss: 0.886594]\n",
      "epoch:27 step:25428 [D loss: 0.387098, acc.: 90.62%] [G loss: 1.377539]\n",
      "epoch:27 step:25429 [D loss: 0.320137, acc.: 92.97%] [G loss: 1.175192]\n",
      "epoch:27 step:25430 [D loss: 0.400867, acc.: 78.91%] [G loss: 0.983228]\n",
      "epoch:27 step:25431 [D loss: 0.394660, acc.: 88.28%] [G loss: 1.771952]\n",
      "epoch:27 step:25432 [D loss: 0.946649, acc.: 46.09%] [G loss: 1.332485]\n",
      "epoch:27 step:25433 [D loss: 0.756558, acc.: 49.22%] [G loss: 1.382221]\n",
      "epoch:27 step:25434 [D loss: 0.577782, acc.: 71.09%] [G loss: 1.114389]\n",
      "epoch:27 step:25435 [D loss: 0.730980, acc.: 49.22%] [G loss: 0.927093]\n",
      "epoch:27 step:25436 [D loss: 0.550114, acc.: 75.78%] [G loss: 1.178662]\n",
      "epoch:27 step:25437 [D loss: 0.699205, acc.: 57.81%] [G loss: 0.676294]\n",
      "epoch:27 step:25438 [D loss: 0.289044, acc.: 92.97%] [G loss: 1.721306]\n",
      "epoch:27 step:25439 [D loss: 0.689559, acc.: 60.16%] [G loss: 1.266912]\n",
      "epoch:27 step:25440 [D loss: 0.712656, acc.: 58.59%] [G loss: 1.264238]\n",
      "epoch:27 step:25441 [D loss: 0.646976, acc.: 64.06%] [G loss: 1.052548]\n",
      "epoch:27 step:25442 [D loss: 0.697825, acc.: 58.59%] [G loss: 1.117793]\n",
      "epoch:27 step:25443 [D loss: 0.456191, acc.: 82.81%] [G loss: 1.345600]\n",
      "epoch:27 step:25444 [D loss: 0.479507, acc.: 80.47%] [G loss: 1.313722]\n",
      "epoch:27 step:25445 [D loss: 0.485183, acc.: 82.81%] [G loss: 1.218793]\n",
      "epoch:27 step:25446 [D loss: 0.505115, acc.: 74.22%] [G loss: 1.188989]\n",
      "epoch:27 step:25447 [D loss: 0.665733, acc.: 63.28%] [G loss: 0.949032]\n",
      "epoch:27 step:25448 [D loss: 0.686306, acc.: 57.03%] [G loss: 0.908458]\n",
      "epoch:27 step:25449 [D loss: 0.419754, acc.: 88.28%] [G loss: 1.360530]\n",
      "epoch:27 step:25450 [D loss: 0.489166, acc.: 75.78%] [G loss: 1.435980]\n",
      "epoch:27 step:25451 [D loss: 0.447449, acc.: 82.81%] [G loss: 1.247307]\n",
      "epoch:27 step:25452 [D loss: 0.722488, acc.: 56.25%] [G loss: 1.272891]\n",
      "epoch:27 step:25453 [D loss: 0.665775, acc.: 59.38%] [G loss: 0.900916]\n",
      "epoch:27 step:25454 [D loss: 0.660942, acc.: 56.25%] [G loss: 1.291627]\n",
      "epoch:27 step:25455 [D loss: 0.422593, acc.: 79.69%] [G loss: 1.375432]\n",
      "epoch:27 step:25456 [D loss: 0.680047, acc.: 60.94%] [G loss: 1.106765]\n",
      "epoch:27 step:25457 [D loss: 0.538188, acc.: 75.00%] [G loss: 1.222029]\n",
      "epoch:27 step:25458 [D loss: 0.301776, acc.: 92.19%] [G loss: 1.609279]\n",
      "epoch:27 step:25459 [D loss: 0.847236, acc.: 43.75%] [G loss: 1.400421]\n",
      "epoch:27 step:25460 [D loss: 0.790819, acc.: 50.00%] [G loss: 0.947478]\n",
      "epoch:27 step:25461 [D loss: 0.809059, acc.: 41.41%] [G loss: 1.097038]\n",
      "epoch:27 step:25462 [D loss: 0.645463, acc.: 63.28%] [G loss: 0.965908]\n",
      "epoch:27 step:25463 [D loss: 0.572851, acc.: 69.53%] [G loss: 0.947570]\n",
      "epoch:27 step:25464 [D loss: 0.575413, acc.: 67.97%] [G loss: 1.109172]\n",
      "epoch:27 step:25465 [D loss: 0.640412, acc.: 58.59%] [G loss: 1.172513]\n",
      "epoch:27 step:25466 [D loss: 0.717459, acc.: 60.16%] [G loss: 1.006191]\n",
      "epoch:27 step:25467 [D loss: 0.630693, acc.: 65.62%] [G loss: 1.048998]\n",
      "epoch:27 step:25468 [D loss: 0.546408, acc.: 75.78%] [G loss: 1.251087]\n",
      "epoch:27 step:25469 [D loss: 0.727022, acc.: 55.47%] [G loss: 1.112728]\n",
      "epoch:27 step:25470 [D loss: 0.589313, acc.: 66.41%] [G loss: 1.226812]\n",
      "epoch:27 step:25471 [D loss: 0.641873, acc.: 65.62%] [G loss: 0.876135]\n",
      "epoch:27 step:25472 [D loss: 0.889539, acc.: 35.94%] [G loss: 0.646553]\n",
      "epoch:27 step:25473 [D loss: 0.709077, acc.: 54.69%] [G loss: 1.016129]\n",
      "epoch:27 step:25474 [D loss: 0.824874, acc.: 45.31%] [G loss: 1.083971]\n",
      "epoch:27 step:25475 [D loss: 0.642176, acc.: 63.28%] [G loss: 1.190274]\n",
      "epoch:27 step:25476 [D loss: 0.502520, acc.: 78.91%] [G loss: 1.178569]\n",
      "epoch:27 step:25477 [D loss: 0.701018, acc.: 53.12%] [G loss: 1.080104]\n",
      "epoch:27 step:25478 [D loss: 0.546516, acc.: 67.97%] [G loss: 0.932497]\n",
      "epoch:27 step:25479 [D loss: 0.529110, acc.: 73.44%] [G loss: 1.036048]\n",
      "epoch:27 step:25480 [D loss: 0.645989, acc.: 65.62%] [G loss: 1.400945]\n",
      "epoch:27 step:25481 [D loss: 0.702697, acc.: 55.47%] [G loss: 0.917531]\n",
      "epoch:27 step:25482 [D loss: 0.711411, acc.: 54.69%] [G loss: 1.037645]\n",
      "epoch:27 step:25483 [D loss: 0.768323, acc.: 48.44%] [G loss: 1.095381]\n",
      "epoch:27 step:25484 [D loss: 0.615637, acc.: 67.19%] [G loss: 1.108330]\n",
      "epoch:27 step:25485 [D loss: 0.650422, acc.: 60.16%] [G loss: 1.125140]\n",
      "epoch:27 step:25486 [D loss: 0.585868, acc.: 71.09%] [G loss: 1.135634]\n",
      "epoch:27 step:25487 [D loss: 0.700479, acc.: 57.81%] [G loss: 1.216165]\n",
      "epoch:27 step:25488 [D loss: 0.472412, acc.: 78.91%] [G loss: 1.119795]\n",
      "epoch:27 step:25489 [D loss: 0.498982, acc.: 78.91%] [G loss: 1.046118]\n",
      "epoch:27 step:25490 [D loss: 0.534303, acc.: 74.22%] [G loss: 1.131731]\n",
      "epoch:27 step:25491 [D loss: 0.476998, acc.: 85.94%] [G loss: 1.279872]\n",
      "epoch:27 step:25492 [D loss: 0.677844, acc.: 60.94%] [G loss: 1.053297]\n",
      "epoch:27 step:25493 [D loss: 0.660642, acc.: 64.06%] [G loss: 0.905773]\n",
      "epoch:27 step:25494 [D loss: 0.608130, acc.: 60.16%] [G loss: 0.910862]\n",
      "epoch:27 step:25495 [D loss: 0.925129, acc.: 37.50%] [G loss: 0.750954]\n",
      "epoch:27 step:25496 [D loss: 0.606076, acc.: 68.75%] [G loss: 1.172182]\n",
      "epoch:27 step:25497 [D loss: 0.717291, acc.: 54.69%] [G loss: 1.146701]\n",
      "epoch:27 step:25498 [D loss: 0.780485, acc.: 52.34%] [G loss: 0.959932]\n",
      "epoch:27 step:25499 [D loss: 0.442861, acc.: 76.56%] [G loss: 1.122983]\n",
      "epoch:27 step:25500 [D loss: 0.380955, acc.: 86.72%] [G loss: 1.199198]\n",
      "epoch:27 step:25501 [D loss: 0.744018, acc.: 50.00%] [G loss: 1.267154]\n",
      "epoch:27 step:25502 [D loss: 0.758856, acc.: 53.12%] [G loss: 0.983557]\n",
      "epoch:27 step:25503 [D loss: 0.655539, acc.: 62.50%] [G loss: 1.007871]\n",
      "epoch:27 step:25504 [D loss: 0.595153, acc.: 67.97%] [G loss: 1.093804]\n",
      "epoch:27 step:25505 [D loss: 0.671869, acc.: 62.50%] [G loss: 1.285974]\n",
      "epoch:27 step:25506 [D loss: 0.468703, acc.: 83.59%] [G loss: 1.195955]\n",
      "epoch:27 step:25507 [D loss: 0.478981, acc.: 82.81%] [G loss: 1.468511]\n",
      "epoch:27 step:25508 [D loss: 0.384424, acc.: 89.06%] [G loss: 1.239408]\n",
      "epoch:27 step:25509 [D loss: 0.819910, acc.: 49.22%] [G loss: 1.121872]\n",
      "epoch:27 step:25510 [D loss: 0.618380, acc.: 64.06%] [G loss: 1.179080]\n",
      "epoch:27 step:25511 [D loss: 0.751277, acc.: 53.12%] [G loss: 1.165987]\n",
      "epoch:27 step:25512 [D loss: 0.436240, acc.: 83.59%] [G loss: 1.276668]\n",
      "epoch:27 step:25513 [D loss: 0.659100, acc.: 59.38%] [G loss: 0.993204]\n",
      "epoch:27 step:25514 [D loss: 0.571376, acc.: 67.19%] [G loss: 1.205636]\n",
      "epoch:27 step:25515 [D loss: 0.468185, acc.: 83.59%] [G loss: 1.232408]\n",
      "epoch:27 step:25516 [D loss: 0.697289, acc.: 55.47%] [G loss: 1.168214]\n",
      "epoch:27 step:25517 [D loss: 0.455730, acc.: 84.38%] [G loss: 1.192377]\n",
      "epoch:27 step:25518 [D loss: 0.556272, acc.: 71.09%] [G loss: 1.244490]\n",
      "epoch:27 step:25519 [D loss: 0.306481, acc.: 90.62%] [G loss: 1.279373]\n",
      "epoch:27 step:25520 [D loss: 0.378913, acc.: 86.72%] [G loss: 1.700102]\n",
      "epoch:27 step:25521 [D loss: 0.433112, acc.: 83.59%] [G loss: 1.746409]\n",
      "epoch:27 step:25522 [D loss: 0.288057, acc.: 91.41%] [G loss: 2.033484]\n",
      "epoch:27 step:25523 [D loss: 0.920478, acc.: 46.88%] [G loss: 1.600686]\n",
      "epoch:27 step:25524 [D loss: 0.670333, acc.: 63.28%] [G loss: 1.351871]\n",
      "epoch:27 step:25525 [D loss: 0.694705, acc.: 54.69%] [G loss: 1.221827]\n",
      "epoch:27 step:25526 [D loss: 0.749208, acc.: 45.31%] [G loss: 1.030334]\n",
      "epoch:27 step:25527 [D loss: 0.677831, acc.: 60.16%] [G loss: 0.831873]\n",
      "epoch:27 step:25528 [D loss: 0.589412, acc.: 70.31%] [G loss: 0.955486]\n",
      "epoch:27 step:25529 [D loss: 0.223500, acc.: 94.53%] [G loss: 1.284550]\n",
      "epoch:27 step:25530 [D loss: 0.280421, acc.: 92.97%] [G loss: 1.500576]\n",
      "epoch:27 step:25531 [D loss: 0.350712, acc.: 89.84%] [G loss: 1.186235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25532 [D loss: 0.835351, acc.: 50.00%] [G loss: 1.513957]\n",
      "epoch:27 step:25533 [D loss: 0.754109, acc.: 53.12%] [G loss: 1.144030]\n",
      "epoch:27 step:25534 [D loss: 0.469162, acc.: 80.47%] [G loss: 0.934986]\n",
      "epoch:27 step:25535 [D loss: 0.758803, acc.: 44.53%] [G loss: 1.113162]\n",
      "epoch:27 step:25536 [D loss: 0.514743, acc.: 72.66%] [G loss: 1.106798]\n",
      "epoch:27 step:25537 [D loss: 0.494981, acc.: 79.69%] [G loss: 1.145101]\n",
      "epoch:27 step:25538 [D loss: 0.863543, acc.: 35.94%] [G loss: 0.998656]\n",
      "epoch:27 step:25539 [D loss: 0.815315, acc.: 41.41%] [G loss: 0.762264]\n",
      "epoch:27 step:25540 [D loss: 0.417591, acc.: 85.16%] [G loss: 1.215160]\n",
      "epoch:27 step:25541 [D loss: 0.634515, acc.: 66.41%] [G loss: 1.089254]\n",
      "epoch:27 step:25542 [D loss: 0.550309, acc.: 75.78%] [G loss: 1.148324]\n",
      "epoch:27 step:25543 [D loss: 0.424079, acc.: 84.38%] [G loss: 1.243584]\n",
      "epoch:27 step:25544 [D loss: 0.494891, acc.: 79.69%] [G loss: 1.255165]\n",
      "epoch:27 step:25545 [D loss: 0.351232, acc.: 85.94%] [G loss: 1.477340]\n",
      "epoch:27 step:25546 [D loss: 0.477348, acc.: 78.12%] [G loss: 1.350292]\n",
      "epoch:27 step:25547 [D loss: 0.330194, acc.: 93.75%] [G loss: 1.504574]\n",
      "epoch:27 step:25548 [D loss: 0.717804, acc.: 52.34%] [G loss: 1.060388]\n",
      "epoch:27 step:25549 [D loss: 0.561931, acc.: 66.41%] [G loss: 1.148784]\n",
      "epoch:27 step:25550 [D loss: 0.594919, acc.: 67.19%] [G loss: 1.335819]\n",
      "epoch:27 step:25551 [D loss: 0.547084, acc.: 71.09%] [G loss: 1.272592]\n",
      "epoch:27 step:25552 [D loss: 0.407502, acc.: 87.50%] [G loss: 1.312073]\n",
      "epoch:27 step:25553 [D loss: 0.902465, acc.: 41.41%] [G loss: 0.652697]\n",
      "epoch:27 step:25554 [D loss: 0.811862, acc.: 45.31%] [G loss: 1.320227]\n",
      "epoch:27 step:25555 [D loss: 0.685138, acc.: 54.69%] [G loss: 1.158713]\n",
      "epoch:27 step:25556 [D loss: 0.798604, acc.: 46.09%] [G loss: 0.988892]\n",
      "epoch:27 step:25557 [D loss: 0.678503, acc.: 53.91%] [G loss: 1.116413]\n",
      "epoch:27 step:25558 [D loss: 0.681675, acc.: 60.16%] [G loss: 0.995596]\n",
      "epoch:27 step:25559 [D loss: 0.565748, acc.: 71.09%] [G loss: 1.381920]\n",
      "epoch:27 step:25560 [D loss: 0.400214, acc.: 85.94%] [G loss: 1.145404]\n",
      "epoch:27 step:25561 [D loss: 0.505302, acc.: 77.34%] [G loss: 1.258503]\n",
      "epoch:27 step:25562 [D loss: 0.495069, acc.: 78.91%] [G loss: 1.343111]\n",
      "epoch:27 step:25563 [D loss: 0.481360, acc.: 82.81%] [G loss: 1.179813]\n",
      "epoch:27 step:25564 [D loss: 0.667309, acc.: 63.28%] [G loss: 0.983603]\n",
      "epoch:27 step:25565 [D loss: 0.691785, acc.: 60.94%] [G loss: 1.100262]\n",
      "epoch:27 step:25566 [D loss: 0.408401, acc.: 90.62%] [G loss: 1.233079]\n",
      "epoch:27 step:25567 [D loss: 0.507811, acc.: 79.69%] [G loss: 1.447952]\n",
      "epoch:27 step:25568 [D loss: 0.547824, acc.: 72.66%] [G loss: 1.164633]\n",
      "epoch:27 step:25569 [D loss: 0.680697, acc.: 55.47%] [G loss: 1.077114]\n",
      "epoch:27 step:25570 [D loss: 0.528357, acc.: 79.69%] [G loss: 1.274099]\n",
      "epoch:27 step:25571 [D loss: 0.375840, acc.: 91.41%] [G loss: 1.420618]\n",
      "epoch:27 step:25572 [D loss: 0.526100, acc.: 75.78%] [G loss: 1.130128]\n",
      "epoch:27 step:25573 [D loss: 0.582211, acc.: 67.19%] [G loss: 1.255297]\n",
      "epoch:27 step:25574 [D loss: 0.590469, acc.: 67.97%] [G loss: 1.485471]\n",
      "epoch:27 step:25575 [D loss: 0.778841, acc.: 47.66%] [G loss: 0.720600]\n",
      "epoch:27 step:25576 [D loss: 0.696705, acc.: 57.03%] [G loss: 1.158002]\n",
      "epoch:27 step:25577 [D loss: 0.437800, acc.: 83.59%] [G loss: 1.002303]\n",
      "epoch:27 step:25578 [D loss: 0.328240, acc.: 88.28%] [G loss: 1.381705]\n",
      "epoch:27 step:25579 [D loss: 0.372064, acc.: 89.06%] [G loss: 1.143749]\n",
      "epoch:27 step:25580 [D loss: 0.715430, acc.: 60.16%] [G loss: 1.258075]\n",
      "epoch:27 step:25581 [D loss: 0.408896, acc.: 85.16%] [G loss: 1.521647]\n",
      "epoch:27 step:25582 [D loss: 0.703382, acc.: 57.81%] [G loss: 1.048180]\n",
      "epoch:27 step:25583 [D loss: 0.417626, acc.: 83.59%] [G loss: 0.929069]\n",
      "epoch:27 step:25584 [D loss: 0.447439, acc.: 82.81%] [G loss: 1.312154]\n",
      "epoch:27 step:25585 [D loss: 0.398383, acc.: 86.72%] [G loss: 1.097079]\n",
      "epoch:27 step:25586 [D loss: 0.502847, acc.: 78.12%] [G loss: 1.092131]\n",
      "epoch:27 step:25587 [D loss: 0.576015, acc.: 68.75%] [G loss: 0.972268]\n",
      "epoch:27 step:25588 [D loss: 0.445478, acc.: 78.91%] [G loss: 0.946820]\n",
      "epoch:27 step:25589 [D loss: 0.704489, acc.: 57.03%] [G loss: 1.000345]\n",
      "epoch:27 step:25590 [D loss: 0.344989, acc.: 89.06%] [G loss: 1.098490]\n",
      "epoch:27 step:25591 [D loss: 0.468356, acc.: 78.91%] [G loss: 1.325577]\n",
      "epoch:27 step:25592 [D loss: 0.332782, acc.: 94.53%] [G loss: 1.671778]\n",
      "epoch:27 step:25593 [D loss: 0.650557, acc.: 62.50%] [G loss: 0.847277]\n",
      "epoch:27 step:25594 [D loss: 0.672855, acc.: 55.47%] [G loss: 0.835918]\n",
      "epoch:27 step:25595 [D loss: 0.565461, acc.: 71.88%] [G loss: 1.055976]\n",
      "epoch:27 step:25596 [D loss: 0.551365, acc.: 74.22%] [G loss: 1.216446]\n",
      "epoch:27 step:25597 [D loss: 0.440913, acc.: 83.59%] [G loss: 1.171432]\n",
      "epoch:27 step:25598 [D loss: 0.690019, acc.: 57.81%] [G loss: 1.254531]\n",
      "epoch:27 step:25599 [D loss: 0.560326, acc.: 71.09%] [G loss: 1.373662]\n",
      "epoch:27 step:25600 [D loss: 0.753743, acc.: 50.78%] [G loss: 1.325620]\n",
      "epoch:27 step:25601 [D loss: 0.689497, acc.: 56.25%] [G loss: 1.175622]\n",
      "epoch:27 step:25602 [D loss: 0.829448, acc.: 41.41%] [G loss: 0.960653]\n",
      "epoch:27 step:25603 [D loss: 0.656872, acc.: 60.94%] [G loss: 1.000080]\n",
      "epoch:27 step:25604 [D loss: 0.733828, acc.: 50.78%] [G loss: 1.075295]\n",
      "epoch:27 step:25605 [D loss: 0.666178, acc.: 63.28%] [G loss: 1.073594]\n",
      "epoch:27 step:25606 [D loss: 0.547622, acc.: 74.22%] [G loss: 1.359545]\n",
      "epoch:27 step:25607 [D loss: 0.530611, acc.: 71.88%] [G loss: 1.231106]\n",
      "epoch:27 step:25608 [D loss: 0.514865, acc.: 77.34%] [G loss: 1.195100]\n",
      "epoch:27 step:25609 [D loss: 0.516445, acc.: 74.22%] [G loss: 1.204707]\n",
      "epoch:27 step:25610 [D loss: 0.556430, acc.: 75.78%] [G loss: 1.030231]\n",
      "epoch:27 step:25611 [D loss: 0.395166, acc.: 86.72%] [G loss: 1.231374]\n",
      "epoch:27 step:25612 [D loss: 0.340079, acc.: 92.19%] [G loss: 1.350770]\n",
      "epoch:27 step:25613 [D loss: 0.300791, acc.: 92.97%] [G loss: 1.719321]\n",
      "epoch:27 step:25614 [D loss: 0.479269, acc.: 77.34%] [G loss: 1.282449]\n",
      "epoch:27 step:25615 [D loss: 0.918041, acc.: 35.94%] [G loss: 1.105542]\n",
      "epoch:27 step:25616 [D loss: 0.705888, acc.: 53.91%] [G loss: 0.926411]\n",
      "epoch:27 step:25617 [D loss: 0.655116, acc.: 64.06%] [G loss: 1.008827]\n",
      "epoch:27 step:25618 [D loss: 0.631991, acc.: 64.06%] [G loss: 0.988001]\n",
      "epoch:27 step:25619 [D loss: 0.521295, acc.: 78.91%] [G loss: 1.258381]\n",
      "epoch:27 step:25620 [D loss: 0.404755, acc.: 87.50%] [G loss: 1.255743]\n",
      "epoch:27 step:25621 [D loss: 0.364204, acc.: 89.84%] [G loss: 1.465969]\n",
      "epoch:27 step:25622 [D loss: 0.693385, acc.: 59.38%] [G loss: 1.023140]\n",
      "epoch:27 step:25623 [D loss: 0.687256, acc.: 62.50%] [G loss: 1.075620]\n",
      "epoch:27 step:25624 [D loss: 0.664377, acc.: 58.59%] [G loss: 0.964696]\n",
      "epoch:27 step:25625 [D loss: 0.423730, acc.: 86.72%] [G loss: 1.291708]\n",
      "epoch:27 step:25626 [D loss: 0.380005, acc.: 89.06%] [G loss: 1.188144]\n",
      "epoch:27 step:25627 [D loss: 0.260925, acc.: 96.09%] [G loss: 1.251546]\n",
      "epoch:27 step:25628 [D loss: 0.558514, acc.: 69.53%] [G loss: 1.259628]\n",
      "epoch:27 step:25629 [D loss: 0.708247, acc.: 53.12%] [G loss: 1.075624]\n",
      "epoch:27 step:25630 [D loss: 0.714786, acc.: 50.78%] [G loss: 1.103185]\n",
      "epoch:27 step:25631 [D loss: 0.683013, acc.: 58.59%] [G loss: 1.049778]\n",
      "epoch:27 step:25632 [D loss: 0.698907, acc.: 53.91%] [G loss: 1.031662]\n",
      "epoch:27 step:25633 [D loss: 0.783309, acc.: 46.88%] [G loss: 0.725015]\n",
      "epoch:27 step:25634 [D loss: 0.611014, acc.: 67.19%] [G loss: 1.029496]\n",
      "epoch:27 step:25635 [D loss: 0.548269, acc.: 71.88%] [G loss: 0.992196]\n",
      "epoch:27 step:25636 [D loss: 0.810361, acc.: 50.00%] [G loss: 0.734569]\n",
      "epoch:27 step:25637 [D loss: 0.424490, acc.: 88.28%] [G loss: 1.273844]\n",
      "epoch:27 step:25638 [D loss: 0.747925, acc.: 52.34%] [G loss: 1.028402]\n",
      "epoch:27 step:25639 [D loss: 0.875279, acc.: 35.16%] [G loss: 0.994314]\n",
      "epoch:27 step:25640 [D loss: 0.901090, acc.: 40.62%] [G loss: 1.079770]\n",
      "epoch:27 step:25641 [D loss: 0.487590, acc.: 81.25%] [G loss: 1.352605]\n",
      "epoch:27 step:25642 [D loss: 0.334630, acc.: 88.28%] [G loss: 1.503748]\n",
      "epoch:27 step:25643 [D loss: 0.393007, acc.: 89.06%] [G loss: 1.380697]\n",
      "epoch:27 step:25644 [D loss: 0.187520, acc.: 99.22%] [G loss: 1.965932]\n",
      "epoch:27 step:25645 [D loss: 0.135359, acc.: 100.00%] [G loss: 2.102889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25646 [D loss: 0.212231, acc.: 97.66%] [G loss: 2.065073]\n",
      "epoch:27 step:25647 [D loss: 0.707994, acc.: 54.69%] [G loss: 1.664239]\n",
      "epoch:27 step:25648 [D loss: 0.901539, acc.: 45.31%] [G loss: 1.310873]\n",
      "epoch:27 step:25649 [D loss: 0.665947, acc.: 57.81%] [G loss: 0.954591]\n",
      "epoch:27 step:25650 [D loss: 0.555732, acc.: 75.78%] [G loss: 1.201528]\n",
      "epoch:27 step:25651 [D loss: 0.619364, acc.: 64.06%] [G loss: 1.148190]\n",
      "epoch:27 step:25652 [D loss: 0.632525, acc.: 61.72%] [G loss: 1.279777]\n",
      "epoch:27 step:25653 [D loss: 0.634547, acc.: 64.06%] [G loss: 0.919301]\n",
      "epoch:27 step:25654 [D loss: 0.715500, acc.: 57.81%] [G loss: 1.276332]\n",
      "epoch:27 step:25655 [D loss: 0.818223, acc.: 47.66%] [G loss: 1.401422]\n",
      "epoch:27 step:25656 [D loss: 0.589785, acc.: 70.31%] [G loss: 1.037454]\n",
      "epoch:27 step:25657 [D loss: 0.608263, acc.: 64.84%] [G loss: 1.075794]\n",
      "epoch:27 step:25658 [D loss: 0.600881, acc.: 64.06%] [G loss: 1.169703]\n",
      "epoch:27 step:25659 [D loss: 0.643869, acc.: 66.41%] [G loss: 1.239218]\n",
      "epoch:27 step:25660 [D loss: 0.648409, acc.: 63.28%] [G loss: 1.258320]\n",
      "epoch:27 step:25661 [D loss: 0.625946, acc.: 62.50%] [G loss: 1.025094]\n",
      "epoch:27 step:25662 [D loss: 0.578274, acc.: 65.62%] [G loss: 0.985055]\n",
      "epoch:27 step:25663 [D loss: 0.476118, acc.: 83.59%] [G loss: 1.236809]\n",
      "epoch:27 step:25664 [D loss: 0.343239, acc.: 91.41%] [G loss: 1.343055]\n",
      "epoch:27 step:25665 [D loss: 0.250223, acc.: 92.19%] [G loss: 1.311864]\n",
      "epoch:27 step:25666 [D loss: 0.217032, acc.: 97.66%] [G loss: 1.597309]\n",
      "epoch:27 step:25667 [D loss: 0.685723, acc.: 60.94%] [G loss: 1.104134]\n",
      "epoch:27 step:25668 [D loss: 0.721571, acc.: 56.25%] [G loss: 1.548069]\n",
      "epoch:27 step:25669 [D loss: 0.619755, acc.: 68.75%] [G loss: 1.264899]\n",
      "epoch:27 step:25670 [D loss: 0.552251, acc.: 72.66%] [G loss: 0.960574]\n",
      "epoch:27 step:25671 [D loss: 0.770885, acc.: 55.47%] [G loss: 1.209537]\n",
      "epoch:27 step:25672 [D loss: 0.611449, acc.: 70.31%] [G loss: 0.891817]\n",
      "epoch:27 step:25673 [D loss: 0.501283, acc.: 81.25%] [G loss: 1.059062]\n",
      "epoch:27 step:25674 [D loss: 0.717940, acc.: 54.69%] [G loss: 0.801708]\n",
      "epoch:27 step:25675 [D loss: 0.564602, acc.: 71.88%] [G loss: 1.022612]\n",
      "epoch:27 step:25676 [D loss: 0.659226, acc.: 60.16%] [G loss: 0.854290]\n",
      "epoch:27 step:25677 [D loss: 0.269040, acc.: 95.31%] [G loss: 1.380522]\n",
      "epoch:27 step:25678 [D loss: 0.908269, acc.: 39.84%] [G loss: 1.034564]\n",
      "epoch:27 step:25679 [D loss: 0.500361, acc.: 76.56%] [G loss: 1.256226]\n",
      "epoch:27 step:25680 [D loss: 0.411660, acc.: 86.72%] [G loss: 1.083489]\n",
      "epoch:27 step:25681 [D loss: 0.752240, acc.: 58.59%] [G loss: 0.975148]\n",
      "epoch:27 step:25682 [D loss: 0.687572, acc.: 58.59%] [G loss: 0.964231]\n",
      "epoch:27 step:25683 [D loss: 0.596017, acc.: 63.28%] [G loss: 0.902021]\n",
      "epoch:27 step:25684 [D loss: 0.621006, acc.: 61.72%] [G loss: 1.161356]\n",
      "epoch:27 step:25685 [D loss: 0.734225, acc.: 54.69%] [G loss: 0.800579]\n",
      "epoch:27 step:25686 [D loss: 0.539986, acc.: 76.56%] [G loss: 1.209475]\n",
      "epoch:27 step:25687 [D loss: 0.525039, acc.: 78.12%] [G loss: 1.148237]\n",
      "epoch:27 step:25688 [D loss: 0.630380, acc.: 65.62%] [G loss: 1.223846]\n",
      "epoch:27 step:25689 [D loss: 0.508422, acc.: 73.44%] [G loss: 1.256323]\n",
      "epoch:27 step:25690 [D loss: 0.447577, acc.: 83.59%] [G loss: 1.023452]\n",
      "epoch:27 step:25691 [D loss: 0.705356, acc.: 59.38%] [G loss: 0.846987]\n",
      "epoch:27 step:25692 [D loss: 0.710486, acc.: 51.56%] [G loss: 1.179331]\n",
      "epoch:27 step:25693 [D loss: 0.543467, acc.: 72.66%] [G loss: 0.928699]\n",
      "epoch:27 step:25694 [D loss: 0.804154, acc.: 47.66%] [G loss: 0.962263]\n",
      "epoch:27 step:25695 [D loss: 0.360845, acc.: 87.50%] [G loss: 1.581125]\n",
      "epoch:27 step:25696 [D loss: 0.146037, acc.: 99.22%] [G loss: 1.916777]\n",
      "epoch:27 step:25697 [D loss: 0.174715, acc.: 99.22%] [G loss: 2.215489]\n",
      "epoch:27 step:25698 [D loss: 0.282182, acc.: 92.97%] [G loss: 1.589421]\n",
      "epoch:27 step:25699 [D loss: 0.303973, acc.: 93.75%] [G loss: 1.693716]\n",
      "epoch:27 step:25700 [D loss: 0.355720, acc.: 89.84%] [G loss: 1.486361]\n",
      "epoch:27 step:25701 [D loss: 0.272132, acc.: 97.66%] [G loss: 1.292079]\n",
      "epoch:27 step:25702 [D loss: 0.462879, acc.: 78.12%] [G loss: 1.606634]\n",
      "epoch:27 step:25703 [D loss: 0.267386, acc.: 93.75%] [G loss: 1.419092]\n",
      "epoch:27 step:25704 [D loss: 0.182711, acc.: 97.66%] [G loss: 1.876519]\n",
      "epoch:27 step:25705 [D loss: 0.221281, acc.: 95.31%] [G loss: 1.721419]\n",
      "epoch:27 step:25706 [D loss: 0.544620, acc.: 65.62%] [G loss: 1.131044]\n",
      "epoch:27 step:25707 [D loss: 0.393474, acc.: 84.38%] [G loss: 1.896438]\n",
      "epoch:27 step:25708 [D loss: 0.407466, acc.: 78.91%] [G loss: 0.982934]\n",
      "epoch:27 step:25709 [D loss: 0.570884, acc.: 67.19%] [G loss: 0.897334]\n",
      "epoch:27 step:25710 [D loss: 0.782297, acc.: 52.34%] [G loss: 1.378208]\n",
      "epoch:27 step:25711 [D loss: 0.864488, acc.: 48.44%] [G loss: 0.530112]\n",
      "epoch:27 step:25712 [D loss: 0.999660, acc.: 44.53%] [G loss: 0.715720]\n",
      "epoch:27 step:25713 [D loss: 0.763717, acc.: 57.03%] [G loss: 0.809688]\n",
      "epoch:27 step:25714 [D loss: 0.663309, acc.: 63.28%] [G loss: 1.633779]\n",
      "epoch:27 step:25715 [D loss: 1.070451, acc.: 30.47%] [G loss: 0.939766]\n",
      "epoch:27 step:25716 [D loss: 0.981112, acc.: 32.81%] [G loss: 1.115782]\n",
      "epoch:27 step:25717 [D loss: 0.549237, acc.: 72.66%] [G loss: 1.525207]\n",
      "epoch:27 step:25718 [D loss: 0.496134, acc.: 78.12%] [G loss: 1.601117]\n",
      "epoch:27 step:25719 [D loss: 0.528825, acc.: 77.34%] [G loss: 0.930573]\n",
      "epoch:27 step:25720 [D loss: 0.831271, acc.: 45.31%] [G loss: 1.239794]\n",
      "epoch:27 step:25721 [D loss: 1.039618, acc.: 29.69%] [G loss: 1.227225]\n",
      "epoch:27 step:25722 [D loss: 0.707409, acc.: 56.25%] [G loss: 1.017101]\n",
      "epoch:27 step:25723 [D loss: 0.697289, acc.: 60.94%] [G loss: 1.144573]\n",
      "epoch:27 step:25724 [D loss: 0.561249, acc.: 74.22%] [G loss: 1.619263]\n",
      "epoch:27 step:25725 [D loss: 0.647834, acc.: 60.94%] [G loss: 1.055252]\n",
      "epoch:27 step:25726 [D loss: 0.764210, acc.: 53.12%] [G loss: 1.065049]\n",
      "epoch:27 step:25727 [D loss: 0.415413, acc.: 86.72%] [G loss: 1.830343]\n",
      "epoch:27 step:25728 [D loss: 0.685468, acc.: 56.25%] [G loss: 1.420155]\n",
      "epoch:27 step:25729 [D loss: 0.502383, acc.: 75.00%] [G loss: 1.306384]\n",
      "epoch:27 step:25730 [D loss: 0.585068, acc.: 69.53%] [G loss: 1.249667]\n",
      "epoch:27 step:25731 [D loss: 0.582967, acc.: 70.31%] [G loss: 1.504400]\n",
      "epoch:27 step:25732 [D loss: 0.569400, acc.: 75.00%] [G loss: 1.313327]\n",
      "epoch:27 step:25733 [D loss: 0.563598, acc.: 69.53%] [G loss: 1.256477]\n",
      "epoch:27 step:25734 [D loss: 0.552232, acc.: 73.44%] [G loss: 1.494368]\n",
      "epoch:27 step:25735 [D loss: 0.459497, acc.: 81.25%] [G loss: 1.446633]\n",
      "epoch:27 step:25736 [D loss: 0.859047, acc.: 46.88%] [G loss: 1.167828]\n",
      "epoch:27 step:25737 [D loss: 0.692711, acc.: 57.81%] [G loss: 1.180776]\n",
      "epoch:27 step:25738 [D loss: 0.688467, acc.: 57.03%] [G loss: 1.039817]\n",
      "epoch:27 step:25739 [D loss: 0.634496, acc.: 63.28%] [G loss: 1.210842]\n",
      "epoch:27 step:25740 [D loss: 0.674622, acc.: 64.84%] [G loss: 1.139231]\n",
      "epoch:27 step:25741 [D loss: 0.601009, acc.: 71.88%] [G loss: 1.184876]\n",
      "epoch:27 step:25742 [D loss: 0.543583, acc.: 73.44%] [G loss: 1.407491]\n",
      "epoch:27 step:25743 [D loss: 0.525238, acc.: 71.88%] [G loss: 1.446245]\n",
      "epoch:27 step:25744 [D loss: 0.753261, acc.: 46.09%] [G loss: 0.936586]\n",
      "epoch:27 step:25745 [D loss: 1.039293, acc.: 33.59%] [G loss: 0.735033]\n",
      "epoch:27 step:25746 [D loss: 0.592371, acc.: 66.41%] [G loss: 1.473890]\n",
      "epoch:27 step:25747 [D loss: 0.491854, acc.: 81.25%] [G loss: 1.664978]\n",
      "epoch:27 step:25748 [D loss: 0.362038, acc.: 87.50%] [G loss: 1.528882]\n",
      "epoch:27 step:25749 [D loss: 0.525187, acc.: 75.00%] [G loss: 1.566208]\n",
      "epoch:27 step:25750 [D loss: 0.520833, acc.: 74.22%] [G loss: 1.691289]\n",
      "epoch:27 step:25751 [D loss: 0.281191, acc.: 95.31%] [G loss: 1.824863]\n",
      "epoch:27 step:25752 [D loss: 0.397312, acc.: 84.38%] [G loss: 1.656848]\n",
      "epoch:27 step:25753 [D loss: 0.303367, acc.: 93.75%] [G loss: 1.644893]\n",
      "epoch:27 step:25754 [D loss: 0.481635, acc.: 81.25%] [G loss: 1.520868]\n",
      "epoch:27 step:25755 [D loss: 0.624834, acc.: 64.06%] [G loss: 1.515063]\n",
      "epoch:27 step:25756 [D loss: 0.271981, acc.: 93.75%] [G loss: 1.833732]\n",
      "epoch:27 step:25757 [D loss: 0.999991, acc.: 39.84%] [G loss: 1.406305]\n",
      "epoch:27 step:25758 [D loss: 0.944775, acc.: 42.19%] [G loss: 0.805406]\n",
      "epoch:27 step:25759 [D loss: 0.818335, acc.: 46.09%] [G loss: 0.885065]\n",
      "epoch:27 step:25760 [D loss: 0.836499, acc.: 45.31%] [G loss: 1.098670]\n",
      "epoch:27 step:25761 [D loss: 1.341970, acc.: 15.62%] [G loss: 0.666597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25762 [D loss: 1.014766, acc.: 35.94%] [G loss: 0.734203]\n",
      "epoch:27 step:25763 [D loss: 0.884445, acc.: 44.53%] [G loss: 0.797553]\n",
      "epoch:27 step:25764 [D loss: 0.588976, acc.: 67.97%] [G loss: 1.074222]\n",
      "epoch:27 step:25765 [D loss: 0.694880, acc.: 60.16%] [G loss: 0.806304]\n",
      "epoch:27 step:25766 [D loss: 0.743787, acc.: 53.12%] [G loss: 1.114993]\n",
      "epoch:27 step:25767 [D loss: 0.552592, acc.: 75.78%] [G loss: 1.205116]\n",
      "epoch:27 step:25768 [D loss: 0.489636, acc.: 78.12%] [G loss: 0.958673]\n",
      "epoch:27 step:25769 [D loss: 0.435083, acc.: 87.50%] [G loss: 1.442236]\n",
      "epoch:27 step:25770 [D loss: 0.284033, acc.: 92.97%] [G loss: 1.478072]\n",
      "epoch:27 step:25771 [D loss: 0.507859, acc.: 75.00%] [G loss: 1.658559]\n",
      "epoch:27 step:25772 [D loss: 1.130620, acc.: 35.94%] [G loss: 1.324091]\n",
      "epoch:27 step:25773 [D loss: 0.704043, acc.: 59.38%] [G loss: 1.393198]\n",
      "epoch:27 step:25774 [D loss: 0.509594, acc.: 78.12%] [G loss: 1.609423]\n",
      "epoch:27 step:25775 [D loss: 0.647600, acc.: 59.38%] [G loss: 1.477403]\n",
      "epoch:27 step:25776 [D loss: 0.641304, acc.: 64.84%] [G loss: 1.473960]\n",
      "epoch:27 step:25777 [D loss: 0.733847, acc.: 54.69%] [G loss: 1.148977]\n",
      "epoch:27 step:25778 [D loss: 0.421094, acc.: 86.72%] [G loss: 0.913316]\n",
      "epoch:27 step:25779 [D loss: 0.531456, acc.: 79.69%] [G loss: 1.136989]\n",
      "epoch:27 step:25780 [D loss: 0.519066, acc.: 78.91%] [G loss: 1.129844]\n",
      "epoch:27 step:25781 [D loss: 0.419002, acc.: 86.72%] [G loss: 1.192026]\n",
      "epoch:27 step:25782 [D loss: 0.360374, acc.: 89.06%] [G loss: 1.275375]\n",
      "epoch:27 step:25783 [D loss: 0.235210, acc.: 94.53%] [G loss: 1.643707]\n",
      "epoch:27 step:25784 [D loss: 0.375515, acc.: 85.94%] [G loss: 1.758071]\n",
      "epoch:27 step:25785 [D loss: 0.488898, acc.: 78.12%] [G loss: 1.136773]\n",
      "epoch:27 step:25786 [D loss: 0.260421, acc.: 96.88%] [G loss: 1.646196]\n",
      "epoch:27 step:25787 [D loss: 0.488521, acc.: 83.59%] [G loss: 1.507078]\n",
      "epoch:27 step:25788 [D loss: 0.647999, acc.: 67.19%] [G loss: 1.551445]\n",
      "epoch:27 step:25789 [D loss: 0.474346, acc.: 83.59%] [G loss: 1.288736]\n",
      "epoch:27 step:25790 [D loss: 0.558252, acc.: 72.66%] [G loss: 1.533955]\n",
      "epoch:27 step:25791 [D loss: 0.657140, acc.: 59.38%] [G loss: 1.492399]\n",
      "epoch:27 step:25792 [D loss: 0.483808, acc.: 78.12%] [G loss: 1.213099]\n",
      "epoch:27 step:25793 [D loss: 0.628828, acc.: 64.84%] [G loss: 0.956910]\n",
      "epoch:27 step:25794 [D loss: 0.538356, acc.: 75.00%] [G loss: 1.075480]\n",
      "epoch:27 step:25795 [D loss: 0.363446, acc.: 91.41%] [G loss: 1.565906]\n",
      "epoch:27 step:25796 [D loss: 0.181601, acc.: 99.22%] [G loss: 1.428228]\n",
      "epoch:27 step:25797 [D loss: 0.290930, acc.: 93.75%] [G loss: 1.341576]\n",
      "epoch:27 step:25798 [D loss: 0.142162, acc.: 99.22%] [G loss: 1.961250]\n",
      "epoch:27 step:25799 [D loss: 0.858262, acc.: 48.44%] [G loss: 1.102733]\n",
      "epoch:27 step:25800 [D loss: 0.909165, acc.: 38.28%] [G loss: 0.987811]\n",
      "epoch:27 step:25801 [D loss: 0.853837, acc.: 45.31%] [G loss: 1.124249]\n",
      "epoch:27 step:25802 [D loss: 0.567609, acc.: 71.09%] [G loss: 1.249833]\n",
      "epoch:27 step:25803 [D loss: 0.313820, acc.: 90.62%] [G loss: 1.506486]\n",
      "epoch:27 step:25804 [D loss: 0.460900, acc.: 77.34%] [G loss: 1.850510]\n",
      "epoch:27 step:25805 [D loss: 0.555635, acc.: 72.66%] [G loss: 1.340399]\n",
      "epoch:27 step:25806 [D loss: 0.400667, acc.: 88.28%] [G loss: 1.232003]\n",
      "epoch:27 step:25807 [D loss: 0.272489, acc.: 96.88%] [G loss: 1.297379]\n",
      "epoch:27 step:25808 [D loss: 0.783741, acc.: 46.88%] [G loss: 1.232730]\n",
      "epoch:27 step:25809 [D loss: 0.711973, acc.: 52.34%] [G loss: 1.156988]\n",
      "epoch:27 step:25810 [D loss: 0.502487, acc.: 77.34%] [G loss: 1.079897]\n",
      "epoch:27 step:25811 [D loss: 0.358827, acc.: 89.06%] [G loss: 1.369504]\n",
      "epoch:27 step:25812 [D loss: 0.426823, acc.: 82.81%] [G loss: 1.525390]\n",
      "epoch:27 step:25813 [D loss: 0.335932, acc.: 93.75%] [G loss: 1.592623]\n",
      "epoch:27 step:25814 [D loss: 0.472078, acc.: 81.25%] [G loss: 1.269678]\n",
      "epoch:27 step:25815 [D loss: 0.509211, acc.: 73.44%] [G loss: 1.438143]\n",
      "epoch:27 step:25816 [D loss: 0.456055, acc.: 82.81%] [G loss: 1.376999]\n",
      "epoch:27 step:25817 [D loss: 0.437775, acc.: 81.25%] [G loss: 1.276069]\n",
      "epoch:27 step:25818 [D loss: 0.435404, acc.: 83.59%] [G loss: 1.401878]\n",
      "epoch:27 step:25819 [D loss: 0.438914, acc.: 88.28%] [G loss: 1.171259]\n",
      "epoch:27 step:25820 [D loss: 0.538107, acc.: 73.44%] [G loss: 1.395097]\n",
      "epoch:27 step:25821 [D loss: 0.362644, acc.: 91.41%] [G loss: 1.442906]\n",
      "epoch:27 step:25822 [D loss: 0.420296, acc.: 89.84%] [G loss: 1.466419]\n",
      "epoch:27 step:25823 [D loss: 0.583398, acc.: 67.19%] [G loss: 1.587859]\n",
      "epoch:27 step:25824 [D loss: 0.624233, acc.: 61.72%] [G loss: 1.181029]\n",
      "epoch:27 step:25825 [D loss: 0.564812, acc.: 67.19%] [G loss: 0.793091]\n",
      "epoch:27 step:25826 [D loss: 0.577497, acc.: 67.97%] [G loss: 1.495469]\n",
      "epoch:27 step:25827 [D loss: 0.756848, acc.: 49.22%] [G loss: 0.950015]\n",
      "epoch:27 step:25828 [D loss: 0.672710, acc.: 59.38%] [G loss: 1.120565]\n",
      "epoch:27 step:25829 [D loss: 0.555210, acc.: 72.66%] [G loss: 1.098168]\n",
      "epoch:27 step:25830 [D loss: 0.636264, acc.: 64.84%] [G loss: 1.053410]\n",
      "epoch:27 step:25831 [D loss: 0.507796, acc.: 78.12%] [G loss: 1.228925]\n",
      "epoch:27 step:25832 [D loss: 0.229193, acc.: 96.88%] [G loss: 1.524874]\n",
      "epoch:27 step:25833 [D loss: 0.397007, acc.: 85.16%] [G loss: 1.743779]\n",
      "epoch:27 step:25834 [D loss: 0.613505, acc.: 62.50%] [G loss: 1.494959]\n",
      "epoch:27 step:25835 [D loss: 0.471793, acc.: 78.91%] [G loss: 1.394142]\n",
      "epoch:27 step:25836 [D loss: 0.350007, acc.: 89.84%] [G loss: 1.566857]\n",
      "epoch:27 step:25837 [D loss: 0.650332, acc.: 59.38%] [G loss: 0.712668]\n",
      "epoch:27 step:25838 [D loss: 0.656934, acc.: 57.81%] [G loss: 1.267494]\n",
      "epoch:27 step:25839 [D loss: 0.588652, acc.: 67.97%] [G loss: 1.201147]\n",
      "epoch:27 step:25840 [D loss: 0.627324, acc.: 63.28%] [G loss: 1.019153]\n",
      "epoch:27 step:25841 [D loss: 0.635684, acc.: 65.62%] [G loss: 0.761381]\n",
      "epoch:27 step:25842 [D loss: 0.454252, acc.: 85.94%] [G loss: 1.416778]\n",
      "epoch:27 step:25843 [D loss: 0.450928, acc.: 80.47%] [G loss: 1.537602]\n",
      "epoch:27 step:25844 [D loss: 0.316394, acc.: 96.09%] [G loss: 1.398802]\n",
      "epoch:27 step:25845 [D loss: 0.279082, acc.: 95.31%] [G loss: 1.472115]\n",
      "epoch:27 step:25846 [D loss: 0.294185, acc.: 94.53%] [G loss: 1.573323]\n",
      "epoch:27 step:25847 [D loss: 0.348558, acc.: 94.53%] [G loss: 1.610904]\n",
      "epoch:27 step:25848 [D loss: 0.220219, acc.: 98.44%] [G loss: 1.729250]\n",
      "epoch:27 step:25849 [D loss: 0.225035, acc.: 99.22%] [G loss: 1.311255]\n",
      "epoch:27 step:25850 [D loss: 0.214529, acc.: 98.44%] [G loss: 1.597671]\n",
      "epoch:27 step:25851 [D loss: 0.274399, acc.: 93.75%] [G loss: 1.891191]\n",
      "epoch:27 step:25852 [D loss: 0.290433, acc.: 94.53%] [G loss: 1.572515]\n",
      "epoch:27 step:25853 [D loss: 0.213689, acc.: 97.66%] [G loss: 1.620786]\n",
      "epoch:27 step:25854 [D loss: 0.237095, acc.: 96.09%] [G loss: 1.734811]\n",
      "epoch:27 step:25855 [D loss: 0.282237, acc.: 90.62%] [G loss: 1.784752]\n",
      "epoch:27 step:25856 [D loss: 0.222332, acc.: 96.88%] [G loss: 2.365649]\n",
      "epoch:27 step:25857 [D loss: 0.426475, acc.: 88.28%] [G loss: 1.219226]\n",
      "epoch:27 step:25858 [D loss: 0.628423, acc.: 65.62%] [G loss: 1.882757]\n",
      "epoch:27 step:25859 [D loss: 0.794711, acc.: 57.03%] [G loss: 1.483488]\n",
      "epoch:27 step:25860 [D loss: 0.417251, acc.: 93.75%] [G loss: 1.314138]\n",
      "epoch:27 step:25861 [D loss: 0.717222, acc.: 53.91%] [G loss: 1.094887]\n",
      "epoch:27 step:25862 [D loss: 0.719063, acc.: 54.69%] [G loss: 0.893004]\n",
      "epoch:27 step:25863 [D loss: 0.573845, acc.: 71.09%] [G loss: 1.150053]\n",
      "epoch:27 step:25864 [D loss: 0.572181, acc.: 71.88%] [G loss: 1.324823]\n",
      "epoch:27 step:25865 [D loss: 0.532252, acc.: 71.88%] [G loss: 1.158210]\n",
      "epoch:27 step:25866 [D loss: 0.317626, acc.: 92.19%] [G loss: 1.814934]\n",
      "epoch:27 step:25867 [D loss: 0.704995, acc.: 55.47%] [G loss: 1.471223]\n",
      "epoch:27 step:25868 [D loss: 0.726279, acc.: 57.81%] [G loss: 0.883545]\n",
      "epoch:27 step:25869 [D loss: 0.844239, acc.: 41.41%] [G loss: 0.841905]\n",
      "epoch:27 step:25870 [D loss: 0.518534, acc.: 78.12%] [G loss: 1.180253]\n",
      "epoch:27 step:25871 [D loss: 0.773596, acc.: 49.22%] [G loss: 1.019683]\n",
      "epoch:27 step:25872 [D loss: 0.499430, acc.: 77.34%] [G loss: 1.031960]\n",
      "epoch:27 step:25873 [D loss: 0.573243, acc.: 70.31%] [G loss: 1.184949]\n",
      "epoch:27 step:25874 [D loss: 0.754658, acc.: 45.31%] [G loss: 1.225607]\n",
      "epoch:27 step:25875 [D loss: 0.351719, acc.: 90.62%] [G loss: 1.398468]\n",
      "epoch:27 step:25876 [D loss: 0.452769, acc.: 82.81%] [G loss: 1.344054]\n",
      "epoch:27 step:25877 [D loss: 0.493350, acc.: 78.91%] [G loss: 1.347839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25878 [D loss: 0.513129, acc.: 73.44%] [G loss: 1.047928]\n",
      "epoch:27 step:25879 [D loss: 0.809113, acc.: 45.31%] [G loss: 0.753625]\n",
      "epoch:27 step:25880 [D loss: 0.712397, acc.: 59.38%] [G loss: 0.863099]\n",
      "epoch:27 step:25881 [D loss: 0.841656, acc.: 39.84%] [G loss: 1.110768]\n",
      "epoch:27 step:25882 [D loss: 0.637999, acc.: 63.28%] [G loss: 1.082913]\n",
      "epoch:27 step:25883 [D loss: 0.773619, acc.: 44.53%] [G loss: 0.989838]\n",
      "epoch:27 step:25884 [D loss: 0.690702, acc.: 60.16%] [G loss: 1.091218]\n",
      "epoch:27 step:25885 [D loss: 0.640248, acc.: 63.28%] [G loss: 1.106807]\n",
      "epoch:27 step:25886 [D loss: 0.372040, acc.: 82.03%] [G loss: 1.140661]\n",
      "epoch:27 step:25887 [D loss: 0.362857, acc.: 85.16%] [G loss: 1.338356]\n",
      "epoch:27 step:25888 [D loss: 0.232220, acc.: 96.09%] [G loss: 2.178649]\n",
      "epoch:27 step:25889 [D loss: 0.742202, acc.: 51.56%] [G loss: 1.028121]\n",
      "epoch:27 step:25890 [D loss: 0.603480, acc.: 66.41%] [G loss: 1.228080]\n",
      "epoch:27 step:25891 [D loss: 0.605573, acc.: 66.41%] [G loss: 1.286981]\n",
      "epoch:27 step:25892 [D loss: 0.704514, acc.: 56.25%] [G loss: 1.843834]\n",
      "epoch:27 step:25893 [D loss: 0.745421, acc.: 51.56%] [G loss: 1.225356]\n",
      "epoch:27 step:25894 [D loss: 0.593664, acc.: 64.84%] [G loss: 1.500443]\n",
      "epoch:27 step:25895 [D loss: 0.495469, acc.: 75.78%] [G loss: 1.184531]\n",
      "epoch:27 step:25896 [D loss: 0.328491, acc.: 91.41%] [G loss: 1.336893]\n",
      "epoch:27 step:25897 [D loss: 0.284509, acc.: 90.62%] [G loss: 1.510937]\n",
      "epoch:27 step:25898 [D loss: 0.666000, acc.: 60.16%] [G loss: 1.237399]\n",
      "epoch:27 step:25899 [D loss: 0.598361, acc.: 66.41%] [G loss: 1.313569]\n",
      "epoch:27 step:25900 [D loss: 0.734932, acc.: 57.03%] [G loss: 1.238619]\n",
      "epoch:27 step:25901 [D loss: 0.642490, acc.: 60.94%] [G loss: 1.195524]\n",
      "epoch:27 step:25902 [D loss: 0.316280, acc.: 91.41%] [G loss: 1.236210]\n",
      "epoch:27 step:25903 [D loss: 0.325711, acc.: 89.06%] [G loss: 1.328094]\n",
      "epoch:27 step:25904 [D loss: 0.373792, acc.: 88.28%] [G loss: 1.406308]\n",
      "epoch:27 step:25905 [D loss: 0.708719, acc.: 55.47%] [G loss: 1.402552]\n",
      "epoch:27 step:25906 [D loss: 0.650241, acc.: 63.28%] [G loss: 1.244696]\n",
      "epoch:27 step:25907 [D loss: 0.626723, acc.: 64.84%] [G loss: 1.123397]\n",
      "epoch:27 step:25908 [D loss: 0.621559, acc.: 68.75%] [G loss: 0.809948]\n",
      "epoch:27 step:25909 [D loss: 0.586429, acc.: 71.09%] [G loss: 1.150999]\n",
      "epoch:27 step:25910 [D loss: 0.738466, acc.: 50.78%] [G loss: 1.243068]\n",
      "epoch:27 step:25911 [D loss: 0.869829, acc.: 39.84%] [G loss: 0.904082]\n",
      "epoch:27 step:25912 [D loss: 0.285622, acc.: 94.53%] [G loss: 1.213297]\n",
      "epoch:27 step:25913 [D loss: 0.394750, acc.: 82.03%] [G loss: 0.961718]\n",
      "epoch:27 step:25914 [D loss: 0.448271, acc.: 77.34%] [G loss: 1.312579]\n",
      "epoch:27 step:25915 [D loss: 0.211964, acc.: 98.44%] [G loss: 2.086470]\n",
      "epoch:27 step:25916 [D loss: 0.539855, acc.: 71.09%] [G loss: 1.506267]\n",
      "epoch:27 step:25917 [D loss: 0.907702, acc.: 38.28%] [G loss: 1.089249]\n",
      "epoch:27 step:25918 [D loss: 0.763152, acc.: 53.91%] [G loss: 1.126189]\n",
      "epoch:27 step:25919 [D loss: 0.849691, acc.: 38.28%] [G loss: 0.958364]\n",
      "epoch:27 step:25920 [D loss: 1.002756, acc.: 40.62%] [G loss: 0.853808]\n",
      "epoch:27 step:25921 [D loss: 0.720388, acc.: 54.69%] [G loss: 1.127602]\n",
      "epoch:27 step:25922 [D loss: 0.674922, acc.: 57.03%] [G loss: 1.381250]\n",
      "epoch:27 step:25923 [D loss: 0.408298, acc.: 89.06%] [G loss: 1.466498]\n",
      "epoch:27 step:25924 [D loss: 0.866725, acc.: 38.28%] [G loss: 0.858767]\n",
      "epoch:27 step:25925 [D loss: 0.616831, acc.: 65.62%] [G loss: 1.459312]\n",
      "epoch:27 step:25926 [D loss: 0.944518, acc.: 30.47%] [G loss: 0.754334]\n",
      "epoch:27 step:25927 [D loss: 0.949082, acc.: 33.59%] [G loss: 0.685884]\n",
      "epoch:27 step:25928 [D loss: 0.244406, acc.: 96.88%] [G loss: 1.267337]\n",
      "epoch:27 step:25929 [D loss: 0.501890, acc.: 77.34%] [G loss: 1.304589]\n",
      "epoch:27 step:25930 [D loss: 0.796377, acc.: 47.66%] [G loss: 0.851262]\n",
      "epoch:27 step:25931 [D loss: 0.477037, acc.: 78.91%] [G loss: 1.566887]\n",
      "epoch:27 step:25932 [D loss: 0.531393, acc.: 72.66%] [G loss: 1.205968]\n",
      "epoch:27 step:25933 [D loss: 0.518225, acc.: 75.78%] [G loss: 1.302356]\n",
      "epoch:27 step:25934 [D loss: 0.514091, acc.: 75.00%] [G loss: 1.107256]\n",
      "epoch:27 step:25935 [D loss: 0.607352, acc.: 68.75%] [G loss: 1.135449]\n",
      "epoch:27 step:25936 [D loss: 0.876969, acc.: 37.50%] [G loss: 1.068427]\n",
      "epoch:27 step:25937 [D loss: 0.758148, acc.: 53.12%] [G loss: 1.461141]\n",
      "epoch:27 step:25938 [D loss: 1.103178, acc.: 27.34%] [G loss: 0.771071]\n",
      "epoch:27 step:25939 [D loss: 0.416287, acc.: 86.72%] [G loss: 1.577330]\n",
      "epoch:27 step:25940 [D loss: 0.450865, acc.: 81.25%] [G loss: 1.359363]\n",
      "epoch:27 step:25941 [D loss: 0.313652, acc.: 92.97%] [G loss: 1.872857]\n",
      "epoch:27 step:25942 [D loss: 0.793248, acc.: 54.69%] [G loss: 1.294863]\n",
      "epoch:27 step:25943 [D loss: 0.725052, acc.: 57.81%] [G loss: 0.935395]\n",
      "epoch:27 step:25944 [D loss: 0.701364, acc.: 54.69%] [G loss: 1.201466]\n",
      "epoch:27 step:25945 [D loss: 0.445216, acc.: 86.72%] [G loss: 1.394872]\n",
      "epoch:27 step:25946 [D loss: 0.395680, acc.: 90.62%] [G loss: 1.133249]\n",
      "epoch:27 step:25947 [D loss: 0.596113, acc.: 69.53%] [G loss: 1.554965]\n",
      "epoch:27 step:25948 [D loss: 0.490505, acc.: 78.12%] [G loss: 1.330959]\n",
      "epoch:27 step:25949 [D loss: 0.719435, acc.: 57.03%] [G loss: 1.295888]\n",
      "epoch:27 step:25950 [D loss: 0.732383, acc.: 53.91%] [G loss: 1.132424]\n",
      "epoch:27 step:25951 [D loss: 0.602564, acc.: 67.97%] [G loss: 1.405415]\n",
      "epoch:27 step:25952 [D loss: 0.351750, acc.: 88.28%] [G loss: 1.647635]\n",
      "epoch:27 step:25953 [D loss: 0.456163, acc.: 80.47%] [G loss: 1.264050]\n",
      "epoch:27 step:25954 [D loss: 0.479887, acc.: 78.12%] [G loss: 1.579246]\n",
      "epoch:27 step:25955 [D loss: 0.461001, acc.: 80.47%] [G loss: 1.398234]\n",
      "epoch:27 step:25956 [D loss: 0.476193, acc.: 78.12%] [G loss: 1.495445]\n",
      "epoch:27 step:25957 [D loss: 0.306413, acc.: 92.19%] [G loss: 1.880702]\n",
      "epoch:27 step:25958 [D loss: 0.414615, acc.: 85.16%] [G loss: 2.114912]\n",
      "epoch:27 step:25959 [D loss: 0.747843, acc.: 48.44%] [G loss: 1.125649]\n",
      "epoch:27 step:25960 [D loss: 0.380693, acc.: 90.62%] [G loss: 1.628857]\n",
      "epoch:27 step:25961 [D loss: 0.277954, acc.: 93.75%] [G loss: 1.658250]\n",
      "epoch:27 step:25962 [D loss: 0.171040, acc.: 99.22%] [G loss: 1.737577]\n",
      "epoch:27 step:25963 [D loss: 0.062106, acc.: 100.00%] [G loss: 2.513011]\n",
      "epoch:27 step:25964 [D loss: 0.112118, acc.: 100.00%] [G loss: 2.283972]\n",
      "epoch:27 step:25965 [D loss: 0.247434, acc.: 91.41%] [G loss: 2.459525]\n",
      "epoch:27 step:25966 [D loss: 0.242150, acc.: 94.53%] [G loss: 2.215003]\n",
      "epoch:27 step:25967 [D loss: 0.578395, acc.: 69.53%] [G loss: 0.882148]\n",
      "epoch:27 step:25968 [D loss: 0.380455, acc.: 85.16%] [G loss: 1.379781]\n",
      "epoch:27 step:25969 [D loss: 0.541986, acc.: 72.66%] [G loss: 1.322797]\n",
      "epoch:27 step:25970 [D loss: 0.422099, acc.: 83.59%] [G loss: 1.611724]\n",
      "epoch:27 step:25971 [D loss: 0.640484, acc.: 67.19%] [G loss: 1.433839]\n",
      "epoch:27 step:25972 [D loss: 0.934669, acc.: 37.50%] [G loss: 0.959885]\n",
      "epoch:27 step:25973 [D loss: 0.921562, acc.: 50.00%] [G loss: 0.653959]\n",
      "epoch:27 step:25974 [D loss: 1.134145, acc.: 32.03%] [G loss: 0.977854]\n",
      "epoch:27 step:25975 [D loss: 0.802906, acc.: 50.00%] [G loss: 0.694788]\n",
      "epoch:27 step:25976 [D loss: 1.056256, acc.: 27.34%] [G loss: 1.095499]\n",
      "epoch:27 step:25977 [D loss: 0.993949, acc.: 33.59%] [G loss: 1.147127]\n",
      "epoch:27 step:25978 [D loss: 0.697701, acc.: 56.25%] [G loss: 1.020235]\n",
      "epoch:27 step:25979 [D loss: 0.904220, acc.: 40.62%] [G loss: 0.827130]\n",
      "epoch:27 step:25980 [D loss: 0.811534, acc.: 39.84%] [G loss: 1.050324]\n",
      "epoch:27 step:25981 [D loss: 0.526823, acc.: 71.88%] [G loss: 1.229163]\n",
      "epoch:27 step:25982 [D loss: 0.766660, acc.: 56.25%] [G loss: 1.378786]\n",
      "epoch:27 step:25983 [D loss: 0.782182, acc.: 50.78%] [G loss: 0.964726]\n",
      "epoch:27 step:25984 [D loss: 0.536867, acc.: 75.78%] [G loss: 1.257456]\n",
      "epoch:27 step:25985 [D loss: 0.899837, acc.: 40.62%] [G loss: 0.997365]\n",
      "epoch:27 step:25986 [D loss: 0.693263, acc.: 53.12%] [G loss: 1.131067]\n",
      "epoch:27 step:25987 [D loss: 0.653363, acc.: 63.28%] [G loss: 1.051097]\n",
      "epoch:27 step:25988 [D loss: 1.023441, acc.: 30.47%] [G loss: 1.202088]\n",
      "epoch:27 step:25989 [D loss: 0.693870, acc.: 59.38%] [G loss: 1.131426]\n",
      "epoch:27 step:25990 [D loss: 0.525964, acc.: 71.09%] [G loss: 1.617956]\n",
      "epoch:27 step:25991 [D loss: 0.619951, acc.: 60.16%] [G loss: 1.288302]\n",
      "epoch:27 step:25992 [D loss: 0.412084, acc.: 83.59%] [G loss: 1.354362]\n",
      "epoch:27 step:25993 [D loss: 0.270774, acc.: 95.31%] [G loss: 1.958941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25994 [D loss: 0.632565, acc.: 63.28%] [G loss: 1.416607]\n",
      "epoch:27 step:25995 [D loss: 0.685350, acc.: 62.50%] [G loss: 0.934866]\n",
      "epoch:27 step:25996 [D loss: 0.704735, acc.: 57.03%] [G loss: 1.320084]\n",
      "epoch:27 step:25997 [D loss: 0.737416, acc.: 56.25%] [G loss: 1.197823]\n",
      "epoch:27 step:25998 [D loss: 0.756449, acc.: 47.66%] [G loss: 1.228598]\n",
      "epoch:27 step:25999 [D loss: 0.572173, acc.: 71.09%] [G loss: 1.086909]\n",
      "epoch:27 step:26000 [D loss: 0.773389, acc.: 53.91%] [G loss: 1.089996]\n",
      "epoch:27 step:26001 [D loss: 0.648915, acc.: 68.75%] [G loss: 1.153154]\n",
      "epoch:27 step:26002 [D loss: 0.635618, acc.: 64.84%] [G loss: 1.251683]\n",
      "epoch:27 step:26003 [D loss: 0.652012, acc.: 63.28%] [G loss: 0.959303]\n",
      "epoch:27 step:26004 [D loss: 0.794706, acc.: 47.66%] [G loss: 0.891169]\n",
      "epoch:27 step:26005 [D loss: 0.613096, acc.: 71.88%] [G loss: 0.995206]\n",
      "epoch:27 step:26006 [D loss: 0.449153, acc.: 81.25%] [G loss: 1.328395]\n",
      "epoch:27 step:26007 [D loss: 0.519828, acc.: 75.78%] [G loss: 1.175516]\n",
      "epoch:27 step:26008 [D loss: 0.463818, acc.: 82.03%] [G loss: 0.982021]\n",
      "epoch:27 step:26009 [D loss: 0.591588, acc.: 64.84%] [G loss: 1.427954]\n",
      "epoch:27 step:26010 [D loss: 0.464026, acc.: 82.81%] [G loss: 1.247575]\n",
      "epoch:27 step:26011 [D loss: 0.699615, acc.: 58.59%] [G loss: 1.165923]\n",
      "epoch:27 step:26012 [D loss: 0.575616, acc.: 74.22%] [G loss: 0.829647]\n",
      "epoch:27 step:26013 [D loss: 0.648903, acc.: 64.84%] [G loss: 1.106292]\n",
      "epoch:27 step:26014 [D loss: 0.608280, acc.: 64.06%] [G loss: 0.859456]\n",
      "epoch:27 step:26015 [D loss: 0.750729, acc.: 54.69%] [G loss: 0.995372]\n",
      "epoch:27 step:26016 [D loss: 0.621699, acc.: 65.62%] [G loss: 1.060512]\n",
      "epoch:27 step:26017 [D loss: 0.757683, acc.: 51.56%] [G loss: 0.913404]\n",
      "epoch:27 step:26018 [D loss: 0.663195, acc.: 64.06%] [G loss: 0.962790]\n",
      "epoch:27 step:26019 [D loss: 0.405836, acc.: 86.72%] [G loss: 1.200533]\n",
      "epoch:27 step:26020 [D loss: 0.582810, acc.: 68.75%] [G loss: 1.292814]\n",
      "epoch:27 step:26021 [D loss: 0.604294, acc.: 65.62%] [G loss: 1.116262]\n",
      "epoch:27 step:26022 [D loss: 0.548944, acc.: 71.09%] [G loss: 1.132489]\n",
      "epoch:27 step:26023 [D loss: 0.403506, acc.: 84.38%] [G loss: 1.177357]\n",
      "epoch:27 step:26024 [D loss: 0.553859, acc.: 69.53%] [G loss: 1.143932]\n",
      "epoch:27 step:26025 [D loss: 0.558953, acc.: 71.09%] [G loss: 1.582722]\n",
      "epoch:27 step:26026 [D loss: 0.738369, acc.: 50.00%] [G loss: 1.135186]\n",
      "epoch:27 step:26027 [D loss: 0.630650, acc.: 66.41%] [G loss: 1.043803]\n",
      "epoch:27 step:26028 [D loss: 0.557415, acc.: 71.09%] [G loss: 1.163116]\n",
      "epoch:27 step:26029 [D loss: 0.552234, acc.: 70.31%] [G loss: 1.214000]\n",
      "epoch:27 step:26030 [D loss: 0.421618, acc.: 85.94%] [G loss: 1.566189]\n",
      "epoch:27 step:26031 [D loss: 0.403323, acc.: 87.50%] [G loss: 1.318476]\n",
      "epoch:27 step:26032 [D loss: 0.348268, acc.: 91.41%] [G loss: 1.738412]\n",
      "epoch:27 step:26033 [D loss: 0.846996, acc.: 47.66%] [G loss: 1.281104]\n",
      "epoch:27 step:26034 [D loss: 0.761740, acc.: 48.44%] [G loss: 1.183050]\n",
      "epoch:27 step:26035 [D loss: 0.658932, acc.: 59.38%] [G loss: 1.078348]\n",
      "epoch:27 step:26036 [D loss: 0.637926, acc.: 60.16%] [G loss: 0.927250]\n",
      "epoch:27 step:26037 [D loss: 0.613657, acc.: 67.19%] [G loss: 0.923045]\n",
      "epoch:27 step:26038 [D loss: 0.617586, acc.: 63.28%] [G loss: 1.011941]\n",
      "epoch:27 step:26039 [D loss: 0.733840, acc.: 55.47%] [G loss: 0.817045]\n",
      "epoch:27 step:26040 [D loss: 0.629617, acc.: 64.84%] [G loss: 1.172854]\n",
      "epoch:27 step:26041 [D loss: 0.490321, acc.: 78.12%] [G loss: 1.295278]\n",
      "epoch:27 step:26042 [D loss: 0.493215, acc.: 77.34%] [G loss: 1.209854]\n",
      "epoch:27 step:26043 [D loss: 0.624863, acc.: 66.41%] [G loss: 1.432610]\n",
      "epoch:27 step:26044 [D loss: 0.358728, acc.: 89.84%] [G loss: 1.349882]\n",
      "epoch:27 step:26045 [D loss: 0.502679, acc.: 78.12%] [G loss: 1.421554]\n",
      "epoch:27 step:26046 [D loss: 0.579565, acc.: 71.09%] [G loss: 1.190648]\n",
      "epoch:27 step:26047 [D loss: 0.564303, acc.: 71.88%] [G loss: 1.330094]\n",
      "epoch:27 step:26048 [D loss: 0.627187, acc.: 64.06%] [G loss: 1.100594]\n",
      "epoch:27 step:26049 [D loss: 0.600645, acc.: 66.41%] [G loss: 1.215996]\n",
      "epoch:27 step:26050 [D loss: 0.567457, acc.: 70.31%] [G loss: 0.989297]\n",
      "epoch:27 step:26051 [D loss: 0.642484, acc.: 61.72%] [G loss: 1.007146]\n",
      "epoch:27 step:26052 [D loss: 0.504876, acc.: 78.91%] [G loss: 0.929069]\n",
      "epoch:27 step:26053 [D loss: 0.641523, acc.: 63.28%] [G loss: 1.129530]\n",
      "epoch:27 step:26054 [D loss: 0.316440, acc.: 93.75%] [G loss: 1.373699]\n",
      "epoch:27 step:26055 [D loss: 0.459618, acc.: 83.59%] [G loss: 1.371635]\n",
      "epoch:27 step:26056 [D loss: 0.485959, acc.: 77.34%] [G loss: 1.166133]\n",
      "epoch:27 step:26057 [D loss: 0.543568, acc.: 70.31%] [G loss: 1.186719]\n",
      "epoch:27 step:26058 [D loss: 0.666321, acc.: 57.03%] [G loss: 1.072220]\n",
      "epoch:27 step:26059 [D loss: 0.690413, acc.: 56.25%] [G loss: 1.208142]\n",
      "epoch:27 step:26060 [D loss: 0.610845, acc.: 68.75%] [G loss: 1.243256]\n",
      "epoch:27 step:26061 [D loss: 0.678690, acc.: 60.16%] [G loss: 1.064927]\n",
      "epoch:27 step:26062 [D loss: 0.619360, acc.: 62.50%] [G loss: 1.019934]\n",
      "epoch:27 step:26063 [D loss: 0.444683, acc.: 81.25%] [G loss: 0.982282]\n",
      "epoch:27 step:26064 [D loss: 0.917259, acc.: 28.91%] [G loss: 1.128243]\n",
      "epoch:27 step:26065 [D loss: 0.909054, acc.: 42.19%] [G loss: 1.177024]\n",
      "epoch:27 step:26066 [D loss: 0.558983, acc.: 72.66%] [G loss: 1.101011]\n",
      "epoch:27 step:26067 [D loss: 0.287258, acc.: 95.31%] [G loss: 1.695456]\n",
      "epoch:27 step:26068 [D loss: 0.170408, acc.: 99.22%] [G loss: 1.902769]\n",
      "epoch:27 step:26069 [D loss: 0.474234, acc.: 77.34%] [G loss: 1.818628]\n",
      "epoch:27 step:26070 [D loss: 0.738036, acc.: 60.16%] [G loss: 1.198934]\n",
      "epoch:27 step:26071 [D loss: 0.704650, acc.: 58.59%] [G loss: 0.890582]\n",
      "epoch:27 step:26072 [D loss: 0.529757, acc.: 72.66%] [G loss: 0.845911]\n",
      "epoch:27 step:26073 [D loss: 0.241837, acc.: 92.19%] [G loss: 1.422423]\n",
      "epoch:27 step:26074 [D loss: 0.134841, acc.: 98.44%] [G loss: 1.979971]\n",
      "epoch:27 step:26075 [D loss: 0.306817, acc.: 90.62%] [G loss: 1.654127]\n",
      "epoch:27 step:26076 [D loss: 0.306723, acc.: 94.53%] [G loss: 1.587904]\n",
      "epoch:27 step:26077 [D loss: 0.553176, acc.: 71.88%] [G loss: 1.002522]\n",
      "epoch:27 step:26078 [D loss: 0.912574, acc.: 44.53%] [G loss: 0.864376]\n",
      "epoch:27 step:26079 [D loss: 0.602229, acc.: 67.97%] [G loss: 1.169477]\n",
      "epoch:27 step:26080 [D loss: 0.496679, acc.: 82.81%] [G loss: 1.202805]\n",
      "epoch:27 step:26081 [D loss: 0.443891, acc.: 84.38%] [G loss: 1.417046]\n",
      "epoch:27 step:26082 [D loss: 0.750510, acc.: 54.69%] [G loss: 1.115775]\n",
      "epoch:27 step:26083 [D loss: 0.633319, acc.: 66.41%] [G loss: 1.454141]\n",
      "epoch:27 step:26084 [D loss: 0.741194, acc.: 50.00%] [G loss: 0.850673]\n",
      "epoch:27 step:26085 [D loss: 0.614525, acc.: 67.97%] [G loss: 0.899319]\n",
      "epoch:27 step:26086 [D loss: 0.857784, acc.: 34.38%] [G loss: 1.151817]\n",
      "epoch:27 step:26087 [D loss: 0.659524, acc.: 67.19%] [G loss: 0.979191]\n",
      "epoch:27 step:26088 [D loss: 0.659168, acc.: 58.59%] [G loss: 0.933849]\n",
      "epoch:27 step:26089 [D loss: 0.459500, acc.: 79.69%] [G loss: 1.298695]\n",
      "epoch:27 step:26090 [D loss: 0.260717, acc.: 92.97%] [G loss: 1.446359]\n",
      "epoch:27 step:26091 [D loss: 0.203133, acc.: 96.88%] [G loss: 1.434883]\n",
      "epoch:27 step:26092 [D loss: 0.318951, acc.: 92.97%] [G loss: 1.554434]\n",
      "epoch:27 step:26093 [D loss: 0.148997, acc.: 100.00%] [G loss: 2.031955]\n",
      "epoch:27 step:26094 [D loss: 0.359087, acc.: 88.28%] [G loss: 1.743312]\n",
      "epoch:27 step:26095 [D loss: 0.538504, acc.: 70.31%] [G loss: 1.006847]\n",
      "epoch:27 step:26096 [D loss: 0.754592, acc.: 49.22%] [G loss: 1.328593]\n",
      "epoch:27 step:26097 [D loss: 0.464178, acc.: 82.81%] [G loss: 1.408987]\n",
      "epoch:27 step:26098 [D loss: 0.527247, acc.: 75.78%] [G loss: 1.305017]\n",
      "epoch:27 step:26099 [D loss: 0.799914, acc.: 51.56%] [G loss: 0.887949]\n",
      "epoch:27 step:26100 [D loss: 0.713831, acc.: 53.12%] [G loss: 1.246914]\n",
      "epoch:27 step:26101 [D loss: 0.624575, acc.: 63.28%] [G loss: 1.279277]\n",
      "epoch:27 step:26102 [D loss: 0.536680, acc.: 75.78%] [G loss: 1.194881]\n",
      "epoch:27 step:26103 [D loss: 0.477223, acc.: 79.69%] [G loss: 1.138032]\n",
      "epoch:27 step:26104 [D loss: 0.358906, acc.: 89.84%] [G loss: 1.227584]\n",
      "epoch:27 step:26105 [D loss: 0.482153, acc.: 75.00%] [G loss: 1.424000]\n",
      "epoch:27 step:26106 [D loss: 0.772765, acc.: 51.56%] [G loss: 1.503465]\n",
      "epoch:27 step:26107 [D loss: 0.392918, acc.: 92.19%] [G loss: 1.058829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26108 [D loss: 0.535673, acc.: 70.31%] [G loss: 1.418268]\n",
      "epoch:27 step:26109 [D loss: 0.419897, acc.: 83.59%] [G loss: 1.359813]\n",
      "epoch:27 step:26110 [D loss: 0.906698, acc.: 38.28%] [G loss: 1.365446]\n",
      "epoch:27 step:26111 [D loss: 0.659545, acc.: 58.59%] [G loss: 0.821259]\n",
      "epoch:27 step:26112 [D loss: 0.734484, acc.: 51.56%] [G loss: 1.140865]\n",
      "epoch:27 step:26113 [D loss: 0.514539, acc.: 74.22%] [G loss: 1.179137]\n",
      "epoch:27 step:26114 [D loss: 0.223671, acc.: 93.75%] [G loss: 1.286732]\n",
      "epoch:27 step:26115 [D loss: 0.288044, acc.: 93.75%] [G loss: 1.566583]\n",
      "epoch:27 step:26116 [D loss: 0.441145, acc.: 87.50%] [G loss: 1.491455]\n",
      "epoch:27 step:26117 [D loss: 0.306843, acc.: 96.88%] [G loss: 1.826213]\n",
      "epoch:27 step:26118 [D loss: 0.343491, acc.: 95.31%] [G loss: 1.131568]\n",
      "epoch:27 step:26119 [D loss: 0.760368, acc.: 51.56%] [G loss: 1.126655]\n",
      "epoch:27 step:26120 [D loss: 1.092789, acc.: 25.00%] [G loss: 0.574421]\n",
      "epoch:27 step:26121 [D loss: 0.827985, acc.: 44.53%] [G loss: 0.798448]\n",
      "epoch:27 step:26122 [D loss: 0.518590, acc.: 77.34%] [G loss: 1.212723]\n",
      "epoch:27 step:26123 [D loss: 0.306031, acc.: 91.41%] [G loss: 1.696589]\n",
      "epoch:27 step:26124 [D loss: 0.410986, acc.: 87.50%] [G loss: 1.287596]\n",
      "epoch:27 step:26125 [D loss: 0.601669, acc.: 67.97%] [G loss: 1.590144]\n",
      "epoch:27 step:26126 [D loss: 0.771259, acc.: 45.31%] [G loss: 1.178679]\n",
      "epoch:27 step:26127 [D loss: 0.595645, acc.: 67.97%] [G loss: 1.180146]\n",
      "epoch:27 step:26128 [D loss: 0.598460, acc.: 65.62%] [G loss: 1.330716]\n",
      "epoch:27 step:26129 [D loss: 0.410197, acc.: 86.72%] [G loss: 1.304121]\n",
      "epoch:27 step:26130 [D loss: 0.323700, acc.: 86.72%] [G loss: 1.038138]\n",
      "epoch:27 step:26131 [D loss: 0.200649, acc.: 98.44%] [G loss: 1.786594]\n",
      "epoch:27 step:26132 [D loss: 0.246165, acc.: 96.88%] [G loss: 2.170956]\n",
      "epoch:27 step:26133 [D loss: 1.210094, acc.: 22.66%] [G loss: 0.632824]\n",
      "epoch:27 step:26134 [D loss: 0.663684, acc.: 59.38%] [G loss: 1.356549]\n",
      "epoch:27 step:26135 [D loss: 0.792185, acc.: 45.31%] [G loss: 1.264408]\n",
      "epoch:27 step:26136 [D loss: 0.989559, acc.: 33.59%] [G loss: 0.858315]\n",
      "epoch:27 step:26137 [D loss: 0.728097, acc.: 53.12%] [G loss: 1.106759]\n",
      "epoch:27 step:26138 [D loss: 0.732909, acc.: 47.66%] [G loss: 1.018645]\n",
      "epoch:27 step:26139 [D loss: 0.643668, acc.: 61.72%] [G loss: 1.431332]\n",
      "epoch:27 step:26140 [D loss: 0.753061, acc.: 50.00%] [G loss: 1.130706]\n",
      "epoch:27 step:26141 [D loss: 0.566638, acc.: 73.44%] [G loss: 1.740458]\n",
      "epoch:27 step:26142 [D loss: 0.516665, acc.: 75.78%] [G loss: 1.230406]\n",
      "epoch:27 step:26143 [D loss: 0.590689, acc.: 74.22%] [G loss: 1.056892]\n",
      "epoch:27 step:26144 [D loss: 0.485033, acc.: 78.91%] [G loss: 0.923584]\n",
      "epoch:27 step:26145 [D loss: 0.711423, acc.: 57.81%] [G loss: 1.163433]\n",
      "epoch:27 step:26146 [D loss: 0.513919, acc.: 76.56%] [G loss: 0.997545]\n",
      "epoch:27 step:26147 [D loss: 0.492076, acc.: 77.34%] [G loss: 1.140311]\n",
      "epoch:27 step:26148 [D loss: 0.403818, acc.: 85.16%] [G loss: 1.369760]\n",
      "epoch:27 step:26149 [D loss: 0.313116, acc.: 93.75%] [G loss: 1.654881]\n",
      "epoch:27 step:26150 [D loss: 0.236006, acc.: 97.66%] [G loss: 1.635425]\n",
      "epoch:27 step:26151 [D loss: 0.202274, acc.: 98.44%] [G loss: 2.082416]\n",
      "epoch:27 step:26152 [D loss: 0.253872, acc.: 95.31%] [G loss: 2.174553]\n",
      "epoch:27 step:26153 [D loss: 0.205501, acc.: 97.66%] [G loss: 1.904936]\n",
      "epoch:27 step:26154 [D loss: 0.291758, acc.: 91.41%] [G loss: 1.793542]\n",
      "epoch:27 step:26155 [D loss: 0.283835, acc.: 94.53%] [G loss: 1.893496]\n",
      "epoch:27 step:26156 [D loss: 0.251582, acc.: 97.66%] [G loss: 1.465484]\n",
      "epoch:27 step:26157 [D loss: 0.839724, acc.: 44.53%] [G loss: 0.986536]\n",
      "epoch:27 step:26158 [D loss: 0.625402, acc.: 62.50%] [G loss: 1.400203]\n",
      "epoch:27 step:26159 [D loss: 0.473822, acc.: 80.47%] [G loss: 1.406941]\n",
      "epoch:27 step:26160 [D loss: 0.513225, acc.: 78.12%] [G loss: 1.114428]\n",
      "epoch:27 step:26161 [D loss: 0.723779, acc.: 54.69%] [G loss: 0.951871]\n",
      "epoch:27 step:26162 [D loss: 0.613095, acc.: 64.06%] [G loss: 1.278564]\n",
      "epoch:27 step:26163 [D loss: 0.644581, acc.: 64.84%] [G loss: 1.221584]\n",
      "epoch:27 step:26164 [D loss: 0.440969, acc.: 78.12%] [G loss: 1.221530]\n",
      "epoch:27 step:26165 [D loss: 0.548290, acc.: 73.44%] [G loss: 0.892406]\n",
      "epoch:27 step:26166 [D loss: 0.508598, acc.: 78.91%] [G loss: 1.340922]\n",
      "epoch:27 step:26167 [D loss: 0.705314, acc.: 53.91%] [G loss: 1.276428]\n",
      "epoch:27 step:26168 [D loss: 0.296498, acc.: 93.75%] [G loss: 1.567916]\n",
      "epoch:27 step:26169 [D loss: 0.829194, acc.: 41.41%] [G loss: 1.249163]\n",
      "epoch:27 step:26170 [D loss: 0.442950, acc.: 83.59%] [G loss: 1.384663]\n",
      "epoch:27 step:26171 [D loss: 0.508364, acc.: 77.34%] [G loss: 1.160291]\n",
      "epoch:27 step:26172 [D loss: 0.467060, acc.: 78.91%] [G loss: 1.467360]\n",
      "epoch:27 step:26173 [D loss: 0.774633, acc.: 50.00%] [G loss: 1.056420]\n",
      "epoch:27 step:26174 [D loss: 0.348686, acc.: 90.62%] [G loss: 1.599319]\n",
      "epoch:27 step:26175 [D loss: 0.805197, acc.: 47.66%] [G loss: 1.108979]\n",
      "epoch:27 step:26176 [D loss: 0.687629, acc.: 59.38%] [G loss: 1.303730]\n",
      "epoch:27 step:26177 [D loss: 0.977542, acc.: 32.81%] [G loss: 0.894305]\n",
      "epoch:27 step:26178 [D loss: 0.821778, acc.: 42.97%] [G loss: 1.025254]\n",
      "epoch:27 step:26179 [D loss: 0.405761, acc.: 84.38%] [G loss: 1.469812]\n",
      "epoch:27 step:26180 [D loss: 0.695840, acc.: 57.03%] [G loss: 1.165961]\n",
      "epoch:27 step:26181 [D loss: 0.736630, acc.: 50.00%] [G loss: 1.130128]\n",
      "epoch:27 step:26182 [D loss: 0.571142, acc.: 70.31%] [G loss: 1.128057]\n",
      "epoch:27 step:26183 [D loss: 0.544872, acc.: 70.31%] [G loss: 0.960176]\n",
      "epoch:27 step:26184 [D loss: 0.331661, acc.: 89.84%] [G loss: 1.607072]\n",
      "epoch:27 step:26185 [D loss: 0.483896, acc.: 78.91%] [G loss: 1.573582]\n",
      "epoch:27 step:26186 [D loss: 0.515827, acc.: 75.00%] [G loss: 1.040989]\n",
      "epoch:27 step:26187 [D loss: 0.855696, acc.: 41.41%] [G loss: 1.180023]\n",
      "epoch:27 step:26188 [D loss: 0.442100, acc.: 82.81%] [G loss: 1.470253]\n",
      "epoch:27 step:26189 [D loss: 0.477399, acc.: 78.12%] [G loss: 1.063023]\n",
      "epoch:27 step:26190 [D loss: 1.600498, acc.: 10.94%] [G loss: 0.773437]\n",
      "epoch:27 step:26191 [D loss: 0.551129, acc.: 70.31%] [G loss: 1.613155]\n",
      "epoch:27 step:26192 [D loss: 0.688507, acc.: 59.38%] [G loss: 1.652040]\n",
      "epoch:27 step:26193 [D loss: 0.450433, acc.: 85.94%] [G loss: 1.696898]\n",
      "epoch:27 step:26194 [D loss: 0.338939, acc.: 92.97%] [G loss: 1.747381]\n",
      "epoch:27 step:26195 [D loss: 0.216356, acc.: 96.88%] [G loss: 1.867779]\n",
      "epoch:27 step:26196 [D loss: 0.267874, acc.: 95.31%] [G loss: 2.102464]\n",
      "epoch:27 step:26197 [D loss: 0.123087, acc.: 99.22%] [G loss: 2.156063]\n",
      "epoch:27 step:26198 [D loss: 0.147948, acc.: 98.44%] [G loss: 2.418531]\n",
      "epoch:27 step:26199 [D loss: 0.104609, acc.: 99.22%] [G loss: 2.438963]\n",
      "epoch:27 step:26200 [D loss: 0.226231, acc.: 96.09%] [G loss: 1.982041]\n",
      "epoch:27 step:26201 [D loss: 0.288474, acc.: 92.97%] [G loss: 2.051127]\n",
      "epoch:27 step:26202 [D loss: 0.285153, acc.: 94.53%] [G loss: 1.594879]\n",
      "epoch:27 step:26203 [D loss: 0.906155, acc.: 43.75%] [G loss: 1.179690]\n",
      "epoch:27 step:26204 [D loss: 0.618422, acc.: 64.84%] [G loss: 1.131273]\n",
      "epoch:27 step:26205 [D loss: 0.810436, acc.: 46.09%] [G loss: 1.174699]\n",
      "epoch:27 step:26206 [D loss: 0.509398, acc.: 76.56%] [G loss: 1.237982]\n",
      "epoch:27 step:26207 [D loss: 0.277626, acc.: 95.31%] [G loss: 1.231979]\n",
      "epoch:27 step:26208 [D loss: 0.252239, acc.: 89.84%] [G loss: 2.064439]\n",
      "epoch:27 step:26209 [D loss: 0.514946, acc.: 74.22%] [G loss: 1.719866]\n",
      "epoch:27 step:26210 [D loss: 0.263099, acc.: 91.41%] [G loss: 1.778078]\n",
      "epoch:27 step:26211 [D loss: 0.100989, acc.: 99.22%] [G loss: 2.251921]\n",
      "epoch:27 step:26212 [D loss: 0.661101, acc.: 60.94%] [G loss: 1.393642]\n",
      "epoch:27 step:26213 [D loss: 0.561068, acc.: 72.66%] [G loss: 1.367242]\n",
      "epoch:27 step:26214 [D loss: 0.468929, acc.: 80.47%] [G loss: 1.215814]\n",
      "epoch:27 step:26215 [D loss: 0.454720, acc.: 82.03%] [G loss: 1.292648]\n",
      "epoch:27 step:26216 [D loss: 0.894772, acc.: 42.97%] [G loss: 0.898060]\n",
      "epoch:27 step:26217 [D loss: 0.444987, acc.: 75.00%] [G loss: 1.444009]\n",
      "epoch:27 step:26218 [D loss: 0.233441, acc.: 97.66%] [G loss: 1.817446]\n",
      "epoch:27 step:26219 [D loss: 1.095589, acc.: 50.78%] [G loss: 1.743620]\n",
      "epoch:27 step:26220 [D loss: 0.931756, acc.: 41.41%] [G loss: 1.239229]\n",
      "epoch:27 step:26221 [D loss: 0.320759, acc.: 90.62%] [G loss: 1.326031]\n",
      "epoch:27 step:26222 [D loss: 0.459328, acc.: 77.34%] [G loss: 1.419434]\n",
      "epoch:27 step:26223 [D loss: 0.307842, acc.: 89.06%] [G loss: 1.600889]\n",
      "epoch:27 step:26224 [D loss: 0.412690, acc.: 83.59%] [G loss: 1.689165]\n",
      "epoch:27 step:26225 [D loss: 0.302606, acc.: 92.97%] [G loss: 2.205092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26226 [D loss: 0.253529, acc.: 93.75%] [G loss: 1.690521]\n",
      "epoch:27 step:26227 [D loss: 1.085562, acc.: 46.88%] [G loss: 1.566825]\n",
      "epoch:27 step:26228 [D loss: 0.817357, acc.: 48.44%] [G loss: 1.049223]\n",
      "epoch:27 step:26229 [D loss: 0.586999, acc.: 69.53%] [G loss: 1.480589]\n",
      "epoch:27 step:26230 [D loss: 0.918665, acc.: 35.16%] [G loss: 0.752114]\n",
      "epoch:27 step:26231 [D loss: 0.661888, acc.: 62.50%] [G loss: 0.828658]\n",
      "epoch:27 step:26232 [D loss: 0.983997, acc.: 43.75%] [G loss: 0.678845]\n",
      "epoch:27 step:26233 [D loss: 0.288963, acc.: 95.31%] [G loss: 1.843876]\n",
      "epoch:27 step:26234 [D loss: 0.661944, acc.: 63.28%] [G loss: 1.062193]\n",
      "epoch:27 step:26235 [D loss: 0.550777, acc.: 75.78%] [G loss: 1.250296]\n",
      "epoch:27 step:26236 [D loss: 0.203321, acc.: 93.75%] [G loss: 1.625572]\n",
      "epoch:28 step:26237 [D loss: 0.823299, acc.: 42.97%] [G loss: 1.216718]\n",
      "epoch:28 step:26238 [D loss: 0.934706, acc.: 37.50%] [G loss: 1.393080]\n",
      "epoch:28 step:26239 [D loss: 1.102419, acc.: 22.66%] [G loss: 1.124809]\n",
      "epoch:28 step:26240 [D loss: 0.558741, acc.: 69.53%] [G loss: 1.292431]\n",
      "epoch:28 step:26241 [D loss: 0.663347, acc.: 56.25%] [G loss: 1.233577]\n",
      "epoch:28 step:26242 [D loss: 0.413520, acc.: 85.94%] [G loss: 1.721354]\n",
      "epoch:28 step:26243 [D loss: 0.531667, acc.: 74.22%] [G loss: 1.127470]\n",
      "epoch:28 step:26244 [D loss: 0.607908, acc.: 67.19%] [G loss: 1.169001]\n",
      "epoch:28 step:26245 [D loss: 0.530160, acc.: 76.56%] [G loss: 1.143300]\n",
      "epoch:28 step:26246 [D loss: 0.536497, acc.: 73.44%] [G loss: 0.954011]\n",
      "epoch:28 step:26247 [D loss: 0.501209, acc.: 79.69%] [G loss: 1.173998]\n",
      "epoch:28 step:26248 [D loss: 0.661017, acc.: 59.38%] [G loss: 1.320325]\n",
      "epoch:28 step:26249 [D loss: 0.571172, acc.: 67.97%] [G loss: 1.237234]\n",
      "epoch:28 step:26250 [D loss: 0.661915, acc.: 60.16%] [G loss: 1.154462]\n",
      "epoch:28 step:26251 [D loss: 0.411157, acc.: 86.72%] [G loss: 1.205844]\n",
      "epoch:28 step:26252 [D loss: 0.493443, acc.: 80.47%] [G loss: 1.125454]\n",
      "epoch:28 step:26253 [D loss: 0.692208, acc.: 57.81%] [G loss: 1.344386]\n",
      "epoch:28 step:26254 [D loss: 0.566067, acc.: 75.78%] [G loss: 1.130042]\n",
      "epoch:28 step:26255 [D loss: 0.661131, acc.: 60.94%] [G loss: 1.157816]\n",
      "epoch:28 step:26256 [D loss: 0.339996, acc.: 90.62%] [G loss: 1.157622]\n",
      "epoch:28 step:26257 [D loss: 0.496027, acc.: 78.12%] [G loss: 1.204234]\n",
      "epoch:28 step:26258 [D loss: 0.517517, acc.: 78.12%] [G loss: 1.649133]\n",
      "epoch:28 step:26259 [D loss: 0.654021, acc.: 58.59%] [G loss: 1.011410]\n",
      "epoch:28 step:26260 [D loss: 0.569280, acc.: 68.75%] [G loss: 0.826854]\n",
      "epoch:28 step:26261 [D loss: 0.556782, acc.: 73.44%] [G loss: 0.979180]\n",
      "epoch:28 step:26262 [D loss: 0.379816, acc.: 89.06%] [G loss: 1.232773]\n",
      "epoch:28 step:26263 [D loss: 0.181435, acc.: 100.00%] [G loss: 1.975665]\n",
      "epoch:28 step:26264 [D loss: 0.342241, acc.: 89.84%] [G loss: 1.270540]\n",
      "epoch:28 step:26265 [D loss: 0.437173, acc.: 85.94%] [G loss: 1.318362]\n",
      "epoch:28 step:26266 [D loss: 0.315231, acc.: 96.88%] [G loss: 1.800335]\n",
      "epoch:28 step:26267 [D loss: 0.261911, acc.: 96.09%] [G loss: 1.867483]\n",
      "epoch:28 step:26268 [D loss: 0.153044, acc.: 100.00%] [G loss: 1.807108]\n",
      "epoch:28 step:26269 [D loss: 0.255465, acc.: 91.41%] [G loss: 1.598450]\n",
      "epoch:28 step:26270 [D loss: 0.246793, acc.: 96.09%] [G loss: 1.820935]\n",
      "epoch:28 step:26271 [D loss: 0.166603, acc.: 98.44%] [G loss: 2.104020]\n",
      "epoch:28 step:26272 [D loss: 0.188639, acc.: 96.88%] [G loss: 1.775868]\n",
      "epoch:28 step:26273 [D loss: 0.797796, acc.: 53.12%] [G loss: 1.674992]\n",
      "epoch:28 step:26274 [D loss: 1.557250, acc.: 11.72%] [G loss: 0.574812]\n",
      "epoch:28 step:26275 [D loss: 0.605073, acc.: 65.62%] [G loss: 1.510747]\n",
      "epoch:28 step:26276 [D loss: 0.651049, acc.: 62.50%] [G loss: 1.290435]\n",
      "epoch:28 step:26277 [D loss: 0.735227, acc.: 54.69%] [G loss: 1.115723]\n",
      "epoch:28 step:26278 [D loss: 0.567790, acc.: 69.53%] [G loss: 1.319963]\n",
      "epoch:28 step:26279 [D loss: 0.411667, acc.: 87.50%] [G loss: 1.225819]\n",
      "epoch:28 step:26280 [D loss: 0.505486, acc.: 70.31%] [G loss: 0.850205]\n",
      "epoch:28 step:26281 [D loss: 0.486177, acc.: 78.91%] [G loss: 1.089050]\n",
      "epoch:28 step:26282 [D loss: 0.907396, acc.: 36.72%] [G loss: 0.995578]\n",
      "epoch:28 step:26283 [D loss: 0.667490, acc.: 59.38%] [G loss: 0.974550]\n",
      "epoch:28 step:26284 [D loss: 0.824192, acc.: 43.75%] [G loss: 0.903894]\n",
      "epoch:28 step:26285 [D loss: 0.633220, acc.: 60.94%] [G loss: 1.052791]\n",
      "epoch:28 step:26286 [D loss: 0.476745, acc.: 80.47%] [G loss: 1.080402]\n",
      "epoch:28 step:26287 [D loss: 0.708938, acc.: 54.69%] [G loss: 1.009108]\n",
      "epoch:28 step:26288 [D loss: 0.667596, acc.: 62.50%] [G loss: 1.046531]\n",
      "epoch:28 step:26289 [D loss: 0.654041, acc.: 64.06%] [G loss: 0.933749]\n",
      "epoch:28 step:26290 [D loss: 0.609903, acc.: 68.75%] [G loss: 1.041524]\n",
      "epoch:28 step:26291 [D loss: 0.505568, acc.: 78.91%] [G loss: 1.351187]\n",
      "epoch:28 step:26292 [D loss: 0.627304, acc.: 65.62%] [G loss: 0.998367]\n",
      "epoch:28 step:26293 [D loss: 0.819817, acc.: 46.09%] [G loss: 1.273728]\n",
      "epoch:28 step:26294 [D loss: 0.723070, acc.: 61.72%] [G loss: 1.059318]\n",
      "epoch:28 step:26295 [D loss: 0.669445, acc.: 60.16%] [G loss: 1.087436]\n",
      "epoch:28 step:26296 [D loss: 0.693407, acc.: 58.59%] [G loss: 0.884033]\n",
      "epoch:28 step:26297 [D loss: 0.609624, acc.: 67.19%] [G loss: 0.883255]\n",
      "epoch:28 step:26298 [D loss: 0.568124, acc.: 69.53%] [G loss: 1.086379]\n",
      "epoch:28 step:26299 [D loss: 0.773919, acc.: 50.00%] [G loss: 0.932697]\n",
      "epoch:28 step:26300 [D loss: 0.620963, acc.: 66.41%] [G loss: 1.044688]\n",
      "epoch:28 step:26301 [D loss: 0.393589, acc.: 90.62%] [G loss: 1.368460]\n",
      "epoch:28 step:26302 [D loss: 0.613293, acc.: 64.06%] [G loss: 1.139189]\n",
      "epoch:28 step:26303 [D loss: 0.629584, acc.: 69.53%] [G loss: 1.032760]\n",
      "epoch:28 step:26304 [D loss: 0.388192, acc.: 86.72%] [G loss: 1.506783]\n",
      "epoch:28 step:26305 [D loss: 0.347283, acc.: 90.62%] [G loss: 1.656413]\n",
      "epoch:28 step:26306 [D loss: 0.412154, acc.: 88.28%] [G loss: 1.746913]\n",
      "epoch:28 step:26307 [D loss: 0.747606, acc.: 55.47%] [G loss: 1.302631]\n",
      "epoch:28 step:26308 [D loss: 0.774254, acc.: 53.91%] [G loss: 1.122450]\n",
      "epoch:28 step:26309 [D loss: 0.651144, acc.: 57.03%] [G loss: 0.837971]\n",
      "epoch:28 step:26310 [D loss: 0.510270, acc.: 77.34%] [G loss: 1.097286]\n",
      "epoch:28 step:26311 [D loss: 0.309691, acc.: 88.28%] [G loss: 1.137500]\n",
      "epoch:28 step:26312 [D loss: 0.580736, acc.: 71.09%] [G loss: 1.216576]\n",
      "epoch:28 step:26313 [D loss: 0.329609, acc.: 92.19%] [G loss: 1.639032]\n",
      "epoch:28 step:26314 [D loss: 0.668727, acc.: 62.50%] [G loss: 1.477269]\n",
      "epoch:28 step:26315 [D loss: 0.648864, acc.: 61.72%] [G loss: 1.075762]\n",
      "epoch:28 step:26316 [D loss: 0.624362, acc.: 60.94%] [G loss: 0.950450]\n",
      "epoch:28 step:26317 [D loss: 0.654317, acc.: 59.38%] [G loss: 1.460564]\n",
      "epoch:28 step:26318 [D loss: 0.740029, acc.: 53.12%] [G loss: 0.913423]\n",
      "epoch:28 step:26319 [D loss: 0.412952, acc.: 87.50%] [G loss: 1.235382]\n",
      "epoch:28 step:26320 [D loss: 0.761365, acc.: 51.56%] [G loss: 1.121992]\n",
      "epoch:28 step:26321 [D loss: 0.538852, acc.: 77.34%] [G loss: 1.106776]\n",
      "epoch:28 step:26322 [D loss: 0.514650, acc.: 76.56%] [G loss: 1.009414]\n",
      "epoch:28 step:26323 [D loss: 0.592692, acc.: 69.53%] [G loss: 1.083081]\n",
      "epoch:28 step:26324 [D loss: 0.613102, acc.: 62.50%] [G loss: 1.297268]\n",
      "epoch:28 step:26325 [D loss: 0.648293, acc.: 64.84%] [G loss: 1.120547]\n",
      "epoch:28 step:26326 [D loss: 0.556107, acc.: 78.12%] [G loss: 1.304759]\n",
      "epoch:28 step:26327 [D loss: 0.647969, acc.: 60.16%] [G loss: 1.111859]\n",
      "epoch:28 step:26328 [D loss: 0.448332, acc.: 82.81%] [G loss: 1.467075]\n",
      "epoch:28 step:26329 [D loss: 0.663861, acc.: 59.38%] [G loss: 1.220850]\n",
      "epoch:28 step:26330 [D loss: 0.636756, acc.: 61.72%] [G loss: 1.079878]\n",
      "epoch:28 step:26331 [D loss: 0.708721, acc.: 54.69%] [G loss: 1.054975]\n",
      "epoch:28 step:26332 [D loss: 0.679562, acc.: 61.72%] [G loss: 1.189372]\n",
      "epoch:28 step:26333 [D loss: 0.647764, acc.: 62.50%] [G loss: 1.122684]\n",
      "epoch:28 step:26334 [D loss: 0.706926, acc.: 55.47%] [G loss: 0.730965]\n",
      "epoch:28 step:26335 [D loss: 0.591583, acc.: 64.06%] [G loss: 1.021419]\n",
      "epoch:28 step:26336 [D loss: 0.691522, acc.: 60.94%] [G loss: 1.020959]\n",
      "epoch:28 step:26337 [D loss: 0.542521, acc.: 72.66%] [G loss: 1.048088]\n",
      "epoch:28 step:26338 [D loss: 0.629439, acc.: 61.72%] [G loss: 1.195641]\n",
      "epoch:28 step:26339 [D loss: 0.473539, acc.: 76.56%] [G loss: 1.068102]\n",
      "epoch:28 step:26340 [D loss: 0.507431, acc.: 78.12%] [G loss: 0.956311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26341 [D loss: 0.414456, acc.: 85.16%] [G loss: 1.055817]\n",
      "epoch:28 step:26342 [D loss: 0.382495, acc.: 90.62%] [G loss: 1.208804]\n",
      "epoch:28 step:26343 [D loss: 0.521141, acc.: 77.34%] [G loss: 1.259779]\n",
      "epoch:28 step:26344 [D loss: 0.493378, acc.: 76.56%] [G loss: 1.192226]\n",
      "epoch:28 step:26345 [D loss: 0.450293, acc.: 83.59%] [G loss: 1.440375]\n",
      "epoch:28 step:26346 [D loss: 0.429018, acc.: 85.16%] [G loss: 1.216123]\n",
      "epoch:28 step:26347 [D loss: 0.493081, acc.: 79.69%] [G loss: 1.157285]\n",
      "epoch:28 step:26348 [D loss: 0.627199, acc.: 66.41%] [G loss: 1.112973]\n",
      "epoch:28 step:26349 [D loss: 0.692119, acc.: 55.47%] [G loss: 0.876092]\n",
      "epoch:28 step:26350 [D loss: 0.793471, acc.: 52.34%] [G loss: 0.733064]\n",
      "epoch:28 step:26351 [D loss: 0.877353, acc.: 39.84%] [G loss: 0.859048]\n",
      "epoch:28 step:26352 [D loss: 0.521885, acc.: 75.00%] [G loss: 1.026521]\n",
      "epoch:28 step:26353 [D loss: 0.477021, acc.: 78.91%] [G loss: 0.920698]\n",
      "epoch:28 step:26354 [D loss: 0.447470, acc.: 85.16%] [G loss: 1.417169]\n",
      "epoch:28 step:26355 [D loss: 0.304757, acc.: 94.53%] [G loss: 1.566126]\n",
      "epoch:28 step:26356 [D loss: 0.987960, acc.: 44.53%] [G loss: 1.378397]\n",
      "epoch:28 step:26357 [D loss: 0.643372, acc.: 59.38%] [G loss: 1.289703]\n",
      "epoch:28 step:26358 [D loss: 0.492000, acc.: 77.34%] [G loss: 1.211586]\n",
      "epoch:28 step:26359 [D loss: 0.817680, acc.: 50.78%] [G loss: 1.546174]\n",
      "epoch:28 step:26360 [D loss: 0.562930, acc.: 73.44%] [G loss: 1.372489]\n",
      "epoch:28 step:26361 [D loss: 0.670874, acc.: 60.16%] [G loss: 1.208084]\n",
      "epoch:28 step:26362 [D loss: 0.685348, acc.: 59.38%] [G loss: 0.929454]\n",
      "epoch:28 step:26363 [D loss: 0.745516, acc.: 57.03%] [G loss: 0.915869]\n",
      "epoch:28 step:26364 [D loss: 0.471011, acc.: 83.59%] [G loss: 1.637664]\n",
      "epoch:28 step:26365 [D loss: 0.576856, acc.: 67.19%] [G loss: 0.986105]\n",
      "epoch:28 step:26366 [D loss: 0.368184, acc.: 88.28%] [G loss: 1.569968]\n",
      "epoch:28 step:26367 [D loss: 0.256380, acc.: 98.44%] [G loss: 1.590033]\n",
      "epoch:28 step:26368 [D loss: 0.443924, acc.: 86.72%] [G loss: 1.575636]\n",
      "epoch:28 step:26369 [D loss: 0.630851, acc.: 62.50%] [G loss: 1.126339]\n",
      "epoch:28 step:26370 [D loss: 0.723362, acc.: 54.69%] [G loss: 1.033052]\n",
      "epoch:28 step:26371 [D loss: 0.591968, acc.: 65.62%] [G loss: 1.031985]\n",
      "epoch:28 step:26372 [D loss: 0.568956, acc.: 71.09%] [G loss: 1.038577]\n",
      "epoch:28 step:26373 [D loss: 0.520662, acc.: 75.00%] [G loss: 0.915543]\n",
      "epoch:28 step:26374 [D loss: 0.518430, acc.: 73.44%] [G loss: 0.990609]\n",
      "epoch:28 step:26375 [D loss: 0.346830, acc.: 84.38%] [G loss: 1.477955]\n",
      "epoch:28 step:26376 [D loss: 0.761208, acc.: 49.22%] [G loss: 1.307806]\n",
      "epoch:28 step:26377 [D loss: 0.832012, acc.: 42.19%] [G loss: 0.913547]\n",
      "epoch:28 step:26378 [D loss: 0.468265, acc.: 80.47%] [G loss: 1.303418]\n",
      "epoch:28 step:26379 [D loss: 0.618290, acc.: 61.72%] [G loss: 1.093467]\n",
      "epoch:28 step:26380 [D loss: 0.638979, acc.: 64.84%] [G loss: 1.026542]\n",
      "epoch:28 step:26381 [D loss: 0.485532, acc.: 82.03%] [G loss: 1.490549]\n",
      "epoch:28 step:26382 [D loss: 0.626807, acc.: 64.84%] [G loss: 1.120039]\n",
      "epoch:28 step:26383 [D loss: 0.735452, acc.: 53.12%] [G loss: 1.013573]\n",
      "epoch:28 step:26384 [D loss: 0.887358, acc.: 45.31%] [G loss: 1.026548]\n",
      "epoch:28 step:26385 [D loss: 0.924920, acc.: 33.59%] [G loss: 0.970615]\n",
      "epoch:28 step:26386 [D loss: 0.418067, acc.: 84.38%] [G loss: 1.201403]\n",
      "epoch:28 step:26387 [D loss: 0.502509, acc.: 78.91%] [G loss: 1.242801]\n",
      "epoch:28 step:26388 [D loss: 0.632567, acc.: 60.94%] [G loss: 0.866471]\n",
      "epoch:28 step:26389 [D loss: 0.573879, acc.: 64.84%] [G loss: 1.374487]\n",
      "epoch:28 step:26390 [D loss: 0.656915, acc.: 57.81%] [G loss: 1.053337]\n",
      "epoch:28 step:26391 [D loss: 0.597527, acc.: 71.09%] [G loss: 1.139101]\n",
      "epoch:28 step:26392 [D loss: 0.335519, acc.: 92.19%] [G loss: 1.303645]\n",
      "epoch:28 step:26393 [D loss: 0.443529, acc.: 80.47%] [G loss: 1.749706]\n",
      "epoch:28 step:26394 [D loss: 0.465253, acc.: 84.38%] [G loss: 1.387403]\n",
      "epoch:28 step:26395 [D loss: 0.276501, acc.: 90.62%] [G loss: 1.523999]\n",
      "epoch:28 step:26396 [D loss: 0.630215, acc.: 70.31%] [G loss: 1.269760]\n",
      "epoch:28 step:26397 [D loss: 0.737680, acc.: 53.91%] [G loss: 1.241178]\n",
      "epoch:28 step:26398 [D loss: 0.631178, acc.: 63.28%] [G loss: 1.262555]\n",
      "epoch:28 step:26399 [D loss: 0.496831, acc.: 78.12%] [G loss: 1.091833]\n",
      "epoch:28 step:26400 [D loss: 0.542464, acc.: 75.78%] [G loss: 1.143982]\n",
      "epoch:28 step:26401 [D loss: 0.529648, acc.: 73.44%] [G loss: 1.551410]\n",
      "epoch:28 step:26402 [D loss: 0.441902, acc.: 82.81%] [G loss: 1.177241]\n",
      "epoch:28 step:26403 [D loss: 0.464122, acc.: 82.03%] [G loss: 1.529834]\n",
      "epoch:28 step:26404 [D loss: 0.617986, acc.: 64.84%] [G loss: 1.187381]\n",
      "epoch:28 step:26405 [D loss: 0.596147, acc.: 68.75%] [G loss: 1.422357]\n",
      "epoch:28 step:26406 [D loss: 0.741239, acc.: 54.69%] [G loss: 1.522362]\n",
      "epoch:28 step:26407 [D loss: 0.633050, acc.: 63.28%] [G loss: 0.959469]\n",
      "epoch:28 step:26408 [D loss: 0.504825, acc.: 76.56%] [G loss: 1.420341]\n",
      "epoch:28 step:26409 [D loss: 0.795241, acc.: 44.53%] [G loss: 0.919268]\n",
      "epoch:28 step:26410 [D loss: 1.134702, acc.: 20.31%] [G loss: 0.886157]\n",
      "epoch:28 step:26411 [D loss: 0.869672, acc.: 38.28%] [G loss: 1.125434]\n",
      "epoch:28 step:26412 [D loss: 0.988207, acc.: 32.03%] [G loss: 1.023955]\n",
      "epoch:28 step:26413 [D loss: 0.864172, acc.: 39.06%] [G loss: 1.029130]\n",
      "epoch:28 step:26414 [D loss: 0.958307, acc.: 33.59%] [G loss: 0.602519]\n",
      "epoch:28 step:26415 [D loss: 0.823615, acc.: 45.31%] [G loss: 1.306166]\n",
      "epoch:28 step:26416 [D loss: 0.977082, acc.: 23.44%] [G loss: 0.878017]\n",
      "epoch:28 step:26417 [D loss: 0.774930, acc.: 47.66%] [G loss: 0.841668]\n",
      "epoch:28 step:26418 [D loss: 0.706430, acc.: 53.91%] [G loss: 1.115720]\n",
      "epoch:28 step:26419 [D loss: 0.961549, acc.: 31.25%] [G loss: 0.875301]\n",
      "epoch:28 step:26420 [D loss: 0.876064, acc.: 37.50%] [G loss: 0.727663]\n",
      "epoch:28 step:26421 [D loss: 1.020262, acc.: 29.69%] [G loss: 0.887911]\n",
      "epoch:28 step:26422 [D loss: 0.607427, acc.: 64.06%] [G loss: 1.250899]\n",
      "epoch:28 step:26423 [D loss: 0.706631, acc.: 57.81%] [G loss: 1.415194]\n",
      "epoch:28 step:26424 [D loss: 0.789273, acc.: 46.09%] [G loss: 0.959848]\n",
      "epoch:28 step:26425 [D loss: 0.827262, acc.: 46.09%] [G loss: 1.050078]\n",
      "epoch:28 step:26426 [D loss: 0.549798, acc.: 67.97%] [G loss: 1.376897]\n",
      "epoch:28 step:26427 [D loss: 0.709251, acc.: 51.56%] [G loss: 1.271276]\n",
      "epoch:28 step:26428 [D loss: 0.493710, acc.: 79.69%] [G loss: 1.155136]\n",
      "epoch:28 step:26429 [D loss: 0.773586, acc.: 50.78%] [G loss: 0.899580]\n",
      "epoch:28 step:26430 [D loss: 0.466658, acc.: 78.91%] [G loss: 1.369995]\n",
      "epoch:28 step:26431 [D loss: 0.644246, acc.: 65.62%] [G loss: 1.160838]\n",
      "epoch:28 step:26432 [D loss: 0.804411, acc.: 46.09%] [G loss: 1.182684]\n",
      "epoch:28 step:26433 [D loss: 0.583566, acc.: 69.53%] [G loss: 1.025292]\n",
      "epoch:28 step:26434 [D loss: 0.770520, acc.: 50.00%] [G loss: 0.898673]\n",
      "epoch:28 step:26435 [D loss: 0.709748, acc.: 53.91%] [G loss: 0.909363]\n",
      "epoch:28 step:26436 [D loss: 0.530246, acc.: 78.12%] [G loss: 1.176722]\n",
      "epoch:28 step:26437 [D loss: 0.351920, acc.: 91.41%] [G loss: 1.634378]\n",
      "epoch:28 step:26438 [D loss: 0.746077, acc.: 57.81%] [G loss: 1.293573]\n",
      "epoch:28 step:26439 [D loss: 0.691991, acc.: 51.56%] [G loss: 1.277176]\n",
      "epoch:28 step:26440 [D loss: 0.679802, acc.: 59.38%] [G loss: 1.189749]\n",
      "epoch:28 step:26441 [D loss: 0.685592, acc.: 61.72%] [G loss: 1.053419]\n",
      "epoch:28 step:26442 [D loss: 0.632849, acc.: 63.28%] [G loss: 0.969400]\n",
      "epoch:28 step:26443 [D loss: 0.707363, acc.: 57.03%] [G loss: 1.054785]\n",
      "epoch:28 step:26444 [D loss: 0.616456, acc.: 64.06%] [G loss: 0.976341]\n",
      "epoch:28 step:26445 [D loss: 0.564001, acc.: 74.22%] [G loss: 1.077693]\n",
      "epoch:28 step:26446 [D loss: 0.707609, acc.: 55.47%] [G loss: 1.186308]\n",
      "epoch:28 step:26447 [D loss: 0.441218, acc.: 82.81%] [G loss: 1.628930]\n",
      "epoch:28 step:26448 [D loss: 0.689332, acc.: 60.94%] [G loss: 1.169514]\n",
      "epoch:28 step:26449 [D loss: 0.401218, acc.: 82.03%] [G loss: 1.242399]\n",
      "epoch:28 step:26450 [D loss: 0.733916, acc.: 60.16%] [G loss: 1.327234]\n",
      "epoch:28 step:26451 [D loss: 0.269308, acc.: 95.31%] [G loss: 1.393942]\n",
      "epoch:28 step:26452 [D loss: 0.401529, acc.: 85.94%] [G loss: 1.612998]\n",
      "epoch:28 step:26453 [D loss: 0.829534, acc.: 50.78%] [G loss: 1.051913]\n",
      "epoch:28 step:26454 [D loss: 0.772242, acc.: 50.00%] [G loss: 0.879426]\n",
      "epoch:28 step:26455 [D loss: 0.700973, acc.: 52.34%] [G loss: 0.714415]\n",
      "epoch:28 step:26456 [D loss: 0.259962, acc.: 90.62%] [G loss: 1.380739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26457 [D loss: 0.243319, acc.: 96.09%] [G loss: 1.819105]\n",
      "epoch:28 step:26458 [D loss: 0.264405, acc.: 93.75%] [G loss: 1.686177]\n",
      "epoch:28 step:26459 [D loss: 0.307467, acc.: 90.62%] [G loss: 1.567536]\n",
      "epoch:28 step:26460 [D loss: 0.935536, acc.: 50.78%] [G loss: 1.171113]\n",
      "epoch:28 step:26461 [D loss: 0.820989, acc.: 47.66%] [G loss: 1.378463]\n",
      "epoch:28 step:26462 [D loss: 0.764313, acc.: 51.56%] [G loss: 0.694096]\n",
      "epoch:28 step:26463 [D loss: 0.909905, acc.: 32.03%] [G loss: 1.027943]\n",
      "epoch:28 step:26464 [D loss: 0.653692, acc.: 64.84%] [G loss: 1.279108]\n",
      "epoch:28 step:26465 [D loss: 0.819827, acc.: 49.22%] [G loss: 1.141035]\n",
      "epoch:28 step:26466 [D loss: 0.157461, acc.: 97.66%] [G loss: 1.783758]\n",
      "epoch:28 step:26467 [D loss: 0.252489, acc.: 96.09%] [G loss: 1.578067]\n",
      "epoch:28 step:26468 [D loss: 0.232200, acc.: 96.88%] [G loss: 1.928783]\n",
      "epoch:28 step:26469 [D loss: 0.893463, acc.: 49.22%] [G loss: 1.209699]\n",
      "epoch:28 step:26470 [D loss: 0.807265, acc.: 44.53%] [G loss: 1.259609]\n",
      "epoch:28 step:26471 [D loss: 0.462794, acc.: 78.91%] [G loss: 1.122531]\n",
      "epoch:28 step:26472 [D loss: 0.647782, acc.: 61.72%] [G loss: 1.188562]\n",
      "epoch:28 step:26473 [D loss: 0.582652, acc.: 71.09%] [G loss: 0.947285]\n",
      "epoch:28 step:26474 [D loss: 0.630011, acc.: 63.28%] [G loss: 1.005334]\n",
      "epoch:28 step:26475 [D loss: 0.612571, acc.: 69.53%] [G loss: 1.119061]\n",
      "epoch:28 step:26476 [D loss: 0.778725, acc.: 48.44%] [G loss: 0.860220]\n",
      "epoch:28 step:26477 [D loss: 0.736743, acc.: 53.12%] [G loss: 0.846969]\n",
      "epoch:28 step:26478 [D loss: 0.714785, acc.: 53.91%] [G loss: 1.103261]\n",
      "epoch:28 step:26479 [D loss: 0.644934, acc.: 59.38%] [G loss: 1.512773]\n",
      "epoch:28 step:26480 [D loss: 0.468191, acc.: 84.38%] [G loss: 1.142792]\n",
      "epoch:28 step:26481 [D loss: 0.460039, acc.: 82.81%] [G loss: 1.089083]\n",
      "epoch:28 step:26482 [D loss: 0.385037, acc.: 85.16%] [G loss: 1.222199]\n",
      "epoch:28 step:26483 [D loss: 0.464086, acc.: 82.03%] [G loss: 1.244593]\n",
      "epoch:28 step:26484 [D loss: 0.448256, acc.: 81.25%] [G loss: 1.438130]\n",
      "epoch:28 step:26485 [D loss: 0.654946, acc.: 60.94%] [G loss: 1.184758]\n",
      "epoch:28 step:26486 [D loss: 0.438598, acc.: 82.81%] [G loss: 1.040697]\n",
      "epoch:28 step:26487 [D loss: 0.645132, acc.: 63.28%] [G loss: 1.220906]\n",
      "epoch:28 step:26488 [D loss: 0.580875, acc.: 72.66%] [G loss: 1.105041]\n",
      "epoch:28 step:26489 [D loss: 0.530157, acc.: 75.00%] [G loss: 1.180244]\n",
      "epoch:28 step:26490 [D loss: 0.802840, acc.: 46.88%] [G loss: 1.016627]\n",
      "epoch:28 step:26491 [D loss: 0.743614, acc.: 48.44%] [G loss: 1.170039]\n",
      "epoch:28 step:26492 [D loss: 0.609061, acc.: 67.97%] [G loss: 1.351216]\n",
      "epoch:28 step:26493 [D loss: 0.661558, acc.: 57.81%] [G loss: 1.343653]\n",
      "epoch:28 step:26494 [D loss: 0.641561, acc.: 66.41%] [G loss: 1.262130]\n",
      "epoch:28 step:26495 [D loss: 0.501192, acc.: 78.91%] [G loss: 1.197900]\n",
      "epoch:28 step:26496 [D loss: 0.534363, acc.: 76.56%] [G loss: 1.211182]\n",
      "epoch:28 step:26497 [D loss: 0.486888, acc.: 79.69%] [G loss: 1.062713]\n",
      "epoch:28 step:26498 [D loss: 0.700175, acc.: 55.47%] [G loss: 1.302021]\n",
      "epoch:28 step:26499 [D loss: 0.349791, acc.: 88.28%] [G loss: 1.340747]\n",
      "epoch:28 step:26500 [D loss: 0.332137, acc.: 92.97%] [G loss: 1.564393]\n",
      "epoch:28 step:26501 [D loss: 0.707554, acc.: 56.25%] [G loss: 1.392630]\n",
      "epoch:28 step:26502 [D loss: 0.702882, acc.: 52.34%] [G loss: 0.980481]\n",
      "epoch:28 step:26503 [D loss: 0.535281, acc.: 78.12%] [G loss: 1.052730]\n",
      "epoch:28 step:26504 [D loss: 0.716238, acc.: 52.34%] [G loss: 0.837802]\n",
      "epoch:28 step:26505 [D loss: 0.435884, acc.: 83.59%] [G loss: 1.214391]\n",
      "epoch:28 step:26506 [D loss: 0.635856, acc.: 63.28%] [G loss: 1.058148]\n",
      "epoch:28 step:26507 [D loss: 0.499425, acc.: 82.03%] [G loss: 1.451461]\n",
      "epoch:28 step:26508 [D loss: 0.400525, acc.: 85.16%] [G loss: 1.162289]\n",
      "epoch:28 step:26509 [D loss: 0.350767, acc.: 90.62%] [G loss: 1.332789]\n",
      "epoch:28 step:26510 [D loss: 0.592450, acc.: 66.41%] [G loss: 1.248497]\n",
      "epoch:28 step:26511 [D loss: 0.544911, acc.: 74.22%] [G loss: 1.061141]\n",
      "epoch:28 step:26512 [D loss: 0.615553, acc.: 66.41%] [G loss: 1.065843]\n",
      "epoch:28 step:26513 [D loss: 0.867652, acc.: 41.41%] [G loss: 0.993548]\n",
      "epoch:28 step:26514 [D loss: 0.582505, acc.: 69.53%] [G loss: 1.296295]\n",
      "epoch:28 step:26515 [D loss: 0.348023, acc.: 89.84%] [G loss: 1.327898]\n",
      "epoch:28 step:26516 [D loss: 0.366763, acc.: 92.97%] [G loss: 1.826910]\n",
      "epoch:28 step:26517 [D loss: 0.684926, acc.: 60.94%] [G loss: 1.210804]\n",
      "epoch:28 step:26518 [D loss: 0.576430, acc.: 70.31%] [G loss: 1.263820]\n",
      "epoch:28 step:26519 [D loss: 0.710925, acc.: 57.03%] [G loss: 1.346837]\n",
      "epoch:28 step:26520 [D loss: 0.493096, acc.: 74.22%] [G loss: 0.929050]\n",
      "epoch:28 step:26521 [D loss: 0.381456, acc.: 88.28%] [G loss: 1.198741]\n",
      "epoch:28 step:26522 [D loss: 0.449373, acc.: 79.69%] [G loss: 1.355690]\n",
      "epoch:28 step:26523 [D loss: 0.470756, acc.: 81.25%] [G loss: 1.639915]\n",
      "epoch:28 step:26524 [D loss: 0.615316, acc.: 70.31%] [G loss: 1.361230]\n",
      "epoch:28 step:26525 [D loss: 0.420255, acc.: 85.94%] [G loss: 0.990741]\n",
      "epoch:28 step:26526 [D loss: 0.558059, acc.: 73.44%] [G loss: 1.087746]\n",
      "epoch:28 step:26527 [D loss: 0.370715, acc.: 85.94%] [G loss: 1.417869]\n",
      "epoch:28 step:26528 [D loss: 0.620842, acc.: 64.84%] [G loss: 1.303307]\n",
      "epoch:28 step:26529 [D loss: 0.327015, acc.: 93.75%] [G loss: 1.430029]\n",
      "epoch:28 step:26530 [D loss: 0.452570, acc.: 83.59%] [G loss: 1.236016]\n",
      "epoch:28 step:26531 [D loss: 0.695567, acc.: 55.47%] [G loss: 1.832565]\n",
      "epoch:28 step:26532 [D loss: 0.631679, acc.: 61.72%] [G loss: 0.881585]\n",
      "epoch:28 step:26533 [D loss: 0.624121, acc.: 67.97%] [G loss: 1.248593]\n",
      "epoch:28 step:26534 [D loss: 0.741207, acc.: 53.91%] [G loss: 0.928286]\n",
      "epoch:28 step:26535 [D loss: 0.538576, acc.: 75.78%] [G loss: 1.432925]\n",
      "epoch:28 step:26536 [D loss: 0.694282, acc.: 53.91%] [G loss: 1.185507]\n",
      "epoch:28 step:26537 [D loss: 0.728692, acc.: 58.59%] [G loss: 1.146001]\n",
      "epoch:28 step:26538 [D loss: 0.661160, acc.: 62.50%] [G loss: 1.064800]\n",
      "epoch:28 step:26539 [D loss: 0.655274, acc.: 57.03%] [G loss: 1.291055]\n",
      "epoch:28 step:26540 [D loss: 0.511145, acc.: 79.69%] [G loss: 1.555307]\n",
      "epoch:28 step:26541 [D loss: 0.518531, acc.: 74.22%] [G loss: 0.840830]\n",
      "epoch:28 step:26542 [D loss: 0.563479, acc.: 73.44%] [G loss: 0.918770]\n",
      "epoch:28 step:26543 [D loss: 0.797168, acc.: 48.44%] [G loss: 0.875215]\n",
      "epoch:28 step:26544 [D loss: 0.312914, acc.: 89.84%] [G loss: 1.380482]\n",
      "epoch:28 step:26545 [D loss: 0.351213, acc.: 83.59%] [G loss: 1.301562]\n",
      "epoch:28 step:26546 [D loss: 0.474630, acc.: 79.69%] [G loss: 1.629311]\n",
      "epoch:28 step:26547 [D loss: 0.554355, acc.: 71.09%] [G loss: 1.095970]\n",
      "epoch:28 step:26548 [D loss: 0.234857, acc.: 96.88%] [G loss: 1.928028]\n",
      "epoch:28 step:26549 [D loss: 0.248755, acc.: 97.66%] [G loss: 1.474060]\n",
      "epoch:28 step:26550 [D loss: 0.390974, acc.: 89.06%] [G loss: 1.523729]\n",
      "epoch:28 step:26551 [D loss: 0.413268, acc.: 83.59%] [G loss: 1.639987]\n",
      "epoch:28 step:26552 [D loss: 0.876233, acc.: 47.66%] [G loss: 1.245158]\n",
      "epoch:28 step:26553 [D loss: 0.743438, acc.: 54.69%] [G loss: 0.941302]\n",
      "epoch:28 step:26554 [D loss: 0.664847, acc.: 64.06%] [G loss: 1.338718]\n",
      "epoch:28 step:26555 [D loss: 0.651165, acc.: 58.59%] [G loss: 1.103828]\n",
      "epoch:28 step:26556 [D loss: 0.611838, acc.: 72.66%] [G loss: 1.062935]\n",
      "epoch:28 step:26557 [D loss: 0.385956, acc.: 91.41%] [G loss: 1.435264]\n",
      "epoch:28 step:26558 [D loss: 0.482339, acc.: 77.34%] [G loss: 1.095916]\n",
      "epoch:28 step:26559 [D loss: 0.728848, acc.: 58.59%] [G loss: 1.048671]\n",
      "epoch:28 step:26560 [D loss: 0.573699, acc.: 70.31%] [G loss: 1.140268]\n",
      "epoch:28 step:26561 [D loss: 0.452604, acc.: 84.38%] [G loss: 1.178555]\n",
      "epoch:28 step:26562 [D loss: 0.412361, acc.: 83.59%] [G loss: 1.096463]\n",
      "epoch:28 step:26563 [D loss: 0.299351, acc.: 91.41%] [G loss: 1.506795]\n",
      "epoch:28 step:26564 [D loss: 0.313128, acc.: 92.19%] [G loss: 1.530602]\n",
      "epoch:28 step:26565 [D loss: 0.597017, acc.: 69.53%] [G loss: 1.372626]\n",
      "epoch:28 step:26566 [D loss: 0.731790, acc.: 51.56%] [G loss: 1.171430]\n",
      "epoch:28 step:26567 [D loss: 0.765648, acc.: 49.22%] [G loss: 0.972131]\n",
      "epoch:28 step:26568 [D loss: 0.717820, acc.: 51.56%] [G loss: 1.020660]\n",
      "epoch:28 step:26569 [D loss: 0.855335, acc.: 46.88%] [G loss: 0.635705]\n",
      "epoch:28 step:26570 [D loss: 0.719415, acc.: 53.12%] [G loss: 0.853315]\n",
      "epoch:28 step:26571 [D loss: 0.607309, acc.: 67.19%] [G loss: 1.146497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26572 [D loss: 0.668347, acc.: 61.72%] [G loss: 1.231390]\n",
      "epoch:28 step:26573 [D loss: 0.689245, acc.: 60.94%] [G loss: 1.182390]\n",
      "epoch:28 step:26574 [D loss: 0.462491, acc.: 80.47%] [G loss: 1.309309]\n",
      "epoch:28 step:26575 [D loss: 0.670885, acc.: 60.94%] [G loss: 0.914148]\n",
      "epoch:28 step:26576 [D loss: 0.686851, acc.: 61.72%] [G loss: 1.375463]\n",
      "epoch:28 step:26577 [D loss: 0.957717, acc.: 33.59%] [G loss: 1.204343]\n",
      "epoch:28 step:26578 [D loss: 0.546378, acc.: 72.66%] [G loss: 1.010646]\n",
      "epoch:28 step:26579 [D loss: 0.374332, acc.: 88.28%] [G loss: 1.609095]\n",
      "epoch:28 step:26580 [D loss: 0.384611, acc.: 89.06%] [G loss: 1.220714]\n",
      "epoch:28 step:26581 [D loss: 0.231752, acc.: 97.66%] [G loss: 1.299471]\n",
      "epoch:28 step:26582 [D loss: 0.182311, acc.: 98.44%] [G loss: 1.820867]\n",
      "epoch:28 step:26583 [D loss: 0.201448, acc.: 98.44%] [G loss: 1.680753]\n",
      "epoch:28 step:26584 [D loss: 0.780864, acc.: 53.91%] [G loss: 1.517797]\n",
      "epoch:28 step:26585 [D loss: 0.818056, acc.: 45.31%] [G loss: 1.269479]\n",
      "epoch:28 step:26586 [D loss: 0.651529, acc.: 60.16%] [G loss: 0.941547]\n",
      "epoch:28 step:26587 [D loss: 0.468719, acc.: 82.03%] [G loss: 0.808064]\n",
      "epoch:28 step:26588 [D loss: 0.504120, acc.: 74.22%] [G loss: 1.329859]\n",
      "epoch:28 step:26589 [D loss: 0.453928, acc.: 84.38%] [G loss: 1.414881]\n",
      "epoch:28 step:26590 [D loss: 0.451462, acc.: 85.16%] [G loss: 1.198266]\n",
      "epoch:28 step:26591 [D loss: 0.732367, acc.: 52.34%] [G loss: 1.044110]\n",
      "epoch:28 step:26592 [D loss: 0.699873, acc.: 53.91%] [G loss: 1.141749]\n",
      "epoch:28 step:26593 [D loss: 0.776408, acc.: 43.75%] [G loss: 0.880181]\n",
      "epoch:28 step:26594 [D loss: 0.536067, acc.: 70.31%] [G loss: 0.805526]\n",
      "epoch:28 step:26595 [D loss: 0.443493, acc.: 87.50%] [G loss: 1.482102]\n",
      "epoch:28 step:26596 [D loss: 0.566186, acc.: 72.66%] [G loss: 1.391147]\n",
      "epoch:28 step:26597 [D loss: 0.620185, acc.: 68.75%] [G loss: 1.380648]\n",
      "epoch:28 step:26598 [D loss: 0.802516, acc.: 51.56%] [G loss: 1.096045]\n",
      "epoch:28 step:26599 [D loss: 0.686080, acc.: 57.03%] [G loss: 0.955301]\n",
      "epoch:28 step:26600 [D loss: 0.444105, acc.: 85.94%] [G loss: 1.307610]\n",
      "epoch:28 step:26601 [D loss: 0.378880, acc.: 89.84%] [G loss: 1.645163]\n",
      "epoch:28 step:26602 [D loss: 0.309165, acc.: 88.28%] [G loss: 1.379310]\n",
      "epoch:28 step:26603 [D loss: 0.285077, acc.: 94.53%] [G loss: 1.949644]\n",
      "epoch:28 step:26604 [D loss: 0.668202, acc.: 59.38%] [G loss: 1.520170]\n",
      "epoch:28 step:26605 [D loss: 0.554419, acc.: 71.09%] [G loss: 1.538497]\n",
      "epoch:28 step:26606 [D loss: 0.621691, acc.: 66.41%] [G loss: 1.242377]\n",
      "epoch:28 step:26607 [D loss: 0.574103, acc.: 69.53%] [G loss: 1.056135]\n",
      "epoch:28 step:26608 [D loss: 0.741742, acc.: 53.12%] [G loss: 0.956873]\n",
      "epoch:28 step:26609 [D loss: 0.731679, acc.: 52.34%] [G loss: 1.016804]\n",
      "epoch:28 step:26610 [D loss: 0.728083, acc.: 53.12%] [G loss: 0.914024]\n",
      "epoch:28 step:26611 [D loss: 0.598737, acc.: 66.41%] [G loss: 1.218450]\n",
      "epoch:28 step:26612 [D loss: 0.595252, acc.: 70.31%] [G loss: 1.167097]\n",
      "epoch:28 step:26613 [D loss: 0.548541, acc.: 67.19%] [G loss: 1.157674]\n",
      "epoch:28 step:26614 [D loss: 0.375174, acc.: 83.59%] [G loss: 1.611995]\n",
      "epoch:28 step:26615 [D loss: 0.798743, acc.: 52.34%] [G loss: 1.072760]\n",
      "epoch:28 step:26616 [D loss: 0.566306, acc.: 71.88%] [G loss: 1.325651]\n",
      "epoch:28 step:26617 [D loss: 0.483383, acc.: 77.34%] [G loss: 1.490086]\n",
      "epoch:28 step:26618 [D loss: 0.622914, acc.: 64.06%] [G loss: 1.098512]\n",
      "epoch:28 step:26619 [D loss: 0.576706, acc.: 74.22%] [G loss: 1.134065]\n",
      "epoch:28 step:26620 [D loss: 0.641073, acc.: 61.72%] [G loss: 0.969703]\n",
      "epoch:28 step:26621 [D loss: 0.603991, acc.: 67.97%] [G loss: 1.332793]\n",
      "epoch:28 step:26622 [D loss: 0.611907, acc.: 67.97%] [G loss: 1.205174]\n",
      "epoch:28 step:26623 [D loss: 0.698384, acc.: 60.94%] [G loss: 0.868874]\n",
      "epoch:28 step:26624 [D loss: 0.604018, acc.: 65.62%] [G loss: 0.995657]\n",
      "epoch:28 step:26625 [D loss: 0.519136, acc.: 78.91%] [G loss: 1.156715]\n",
      "epoch:28 step:26626 [D loss: 0.416099, acc.: 82.03%] [G loss: 1.262619]\n",
      "epoch:28 step:26627 [D loss: 0.348260, acc.: 92.97%] [G loss: 1.767902]\n",
      "epoch:28 step:26628 [D loss: 0.433716, acc.: 84.38%] [G loss: 1.455060]\n",
      "epoch:28 step:26629 [D loss: 0.408160, acc.: 83.59%] [G loss: 1.390322]\n",
      "epoch:28 step:26630 [D loss: 0.582800, acc.: 64.06%] [G loss: 0.660804]\n",
      "epoch:28 step:26631 [D loss: 0.652840, acc.: 59.38%] [G loss: 1.782717]\n",
      "epoch:28 step:26632 [D loss: 0.262736, acc.: 95.31%] [G loss: 1.833485]\n",
      "epoch:28 step:26633 [D loss: 0.118848, acc.: 100.00%] [G loss: 2.279523]\n",
      "epoch:28 step:26634 [D loss: 0.218669, acc.: 95.31%] [G loss: 1.304674]\n",
      "epoch:28 step:26635 [D loss: 0.250787, acc.: 95.31%] [G loss: 1.629963]\n",
      "epoch:28 step:26636 [D loss: 0.303938, acc.: 94.53%] [G loss: 1.710156]\n",
      "epoch:28 step:26637 [D loss: 0.225493, acc.: 96.88%] [G loss: 2.255061]\n",
      "epoch:28 step:26638 [D loss: 0.296450, acc.: 92.97%] [G loss: 1.768622]\n",
      "epoch:28 step:26639 [D loss: 0.391974, acc.: 86.72%] [G loss: 1.340549]\n",
      "epoch:28 step:26640 [D loss: 0.210134, acc.: 95.31%] [G loss: 1.516311]\n",
      "epoch:28 step:26641 [D loss: 0.554221, acc.: 71.88%] [G loss: 0.802855]\n",
      "epoch:28 step:26642 [D loss: 0.284231, acc.: 91.41%] [G loss: 1.846781]\n",
      "epoch:28 step:26643 [D loss: 0.507176, acc.: 75.78%] [G loss: 1.265349]\n",
      "epoch:28 step:26644 [D loss: 0.770167, acc.: 51.56%] [G loss: 1.439617]\n",
      "epoch:28 step:26645 [D loss: 0.376937, acc.: 84.38%] [G loss: 1.968569]\n",
      "epoch:28 step:26646 [D loss: 0.777679, acc.: 60.16%] [G loss: 1.226281]\n",
      "epoch:28 step:26647 [D loss: 0.930403, acc.: 45.31%] [G loss: 1.164908]\n",
      "epoch:28 step:26648 [D loss: 1.271097, acc.: 23.44%] [G loss: 0.376732]\n",
      "epoch:28 step:26649 [D loss: 0.827672, acc.: 46.88%] [G loss: 0.844544]\n",
      "epoch:28 step:26650 [D loss: 0.545337, acc.: 77.34%] [G loss: 1.257566]\n",
      "epoch:28 step:26651 [D loss: 0.993572, acc.: 37.50%] [G loss: 0.886802]\n",
      "epoch:28 step:26652 [D loss: 0.957936, acc.: 39.06%] [G loss: 0.858249]\n",
      "epoch:28 step:26653 [D loss: 0.851638, acc.: 45.31%] [G loss: 1.277985]\n",
      "epoch:28 step:26654 [D loss: 0.749233, acc.: 53.12%] [G loss: 0.965481]\n",
      "epoch:28 step:26655 [D loss: 0.679922, acc.: 65.62%] [G loss: 1.064087]\n",
      "epoch:28 step:26656 [D loss: 0.719604, acc.: 52.34%] [G loss: 1.290279]\n",
      "epoch:28 step:26657 [D loss: 0.926190, acc.: 43.75%] [G loss: 1.427896]\n",
      "epoch:28 step:26658 [D loss: 0.944259, acc.: 38.28%] [G loss: 1.146418]\n",
      "epoch:28 step:26659 [D loss: 0.875568, acc.: 43.75%] [G loss: 1.294918]\n",
      "epoch:28 step:26660 [D loss: 0.625000, acc.: 64.84%] [G loss: 1.082086]\n",
      "epoch:28 step:26661 [D loss: 0.899197, acc.: 44.53%] [G loss: 1.075589]\n",
      "epoch:28 step:26662 [D loss: 0.647090, acc.: 64.84%] [G loss: 1.217823]\n",
      "epoch:28 step:26663 [D loss: 0.640209, acc.: 62.50%] [G loss: 1.535241]\n",
      "epoch:28 step:26664 [D loss: 0.634539, acc.: 62.50%] [G loss: 1.036690]\n",
      "epoch:28 step:26665 [D loss: 0.625441, acc.: 63.28%] [G loss: 1.384734]\n",
      "epoch:28 step:26666 [D loss: 0.485475, acc.: 78.91%] [G loss: 1.241222]\n",
      "epoch:28 step:26667 [D loss: 0.582642, acc.: 67.19%] [G loss: 1.458841]\n",
      "epoch:28 step:26668 [D loss: 0.837333, acc.: 50.00%] [G loss: 1.444269]\n",
      "epoch:28 step:26669 [D loss: 0.593247, acc.: 67.19%] [G loss: 1.228386]\n",
      "epoch:28 step:26670 [D loss: 0.534982, acc.: 68.75%] [G loss: 1.554700]\n",
      "epoch:28 step:26671 [D loss: 0.489923, acc.: 80.47%] [G loss: 1.616014]\n",
      "epoch:28 step:26672 [D loss: 0.463854, acc.: 83.59%] [G loss: 1.322906]\n",
      "epoch:28 step:26673 [D loss: 0.712143, acc.: 58.59%] [G loss: 1.137740]\n",
      "epoch:28 step:26674 [D loss: 0.763611, acc.: 50.00%] [G loss: 0.840104]\n",
      "epoch:28 step:26675 [D loss: 0.752223, acc.: 48.44%] [G loss: 1.167772]\n",
      "epoch:28 step:26676 [D loss: 0.773146, acc.: 52.34%] [G loss: 1.267216]\n",
      "epoch:28 step:26677 [D loss: 0.742440, acc.: 50.78%] [G loss: 1.408567]\n",
      "epoch:28 step:26678 [D loss: 0.643121, acc.: 60.94%] [G loss: 1.072028]\n",
      "epoch:28 step:26679 [D loss: 0.462672, acc.: 78.91%] [G loss: 1.578405]\n",
      "epoch:28 step:26680 [D loss: 0.618004, acc.: 60.94%] [G loss: 0.988706]\n",
      "epoch:28 step:26681 [D loss: 0.688744, acc.: 58.59%] [G loss: 1.252017]\n",
      "epoch:28 step:26682 [D loss: 0.796093, acc.: 50.00%] [G loss: 1.140883]\n",
      "epoch:28 step:26683 [D loss: 0.499759, acc.: 77.34%] [G loss: 1.516581]\n",
      "epoch:28 step:26684 [D loss: 0.392688, acc.: 86.72%] [G loss: 1.472207]\n",
      "epoch:28 step:26685 [D loss: 0.341318, acc.: 88.28%] [G loss: 1.393553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26686 [D loss: 0.458426, acc.: 82.03%] [G loss: 1.922809]\n",
      "epoch:28 step:26687 [D loss: 0.430302, acc.: 84.38%] [G loss: 1.060035]\n",
      "epoch:28 step:26688 [D loss: 0.402603, acc.: 80.47%] [G loss: 1.424834]\n",
      "epoch:28 step:26689 [D loss: 0.408079, acc.: 82.81%] [G loss: 1.560107]\n",
      "epoch:28 step:26690 [D loss: 0.542832, acc.: 74.22%] [G loss: 1.209671]\n",
      "epoch:28 step:26691 [D loss: 0.875754, acc.: 44.53%] [G loss: 0.847006]\n",
      "epoch:28 step:26692 [D loss: 0.509523, acc.: 73.44%] [G loss: 1.455640]\n",
      "epoch:28 step:26693 [D loss: 0.530560, acc.: 71.88%] [G loss: 1.376832]\n",
      "epoch:28 step:26694 [D loss: 1.255669, acc.: 21.88%] [G loss: 1.101916]\n",
      "epoch:28 step:26695 [D loss: 0.864735, acc.: 43.75%] [G loss: 1.096949]\n",
      "epoch:28 step:26696 [D loss: 0.907600, acc.: 42.19%] [G loss: 0.873818]\n",
      "epoch:28 step:26697 [D loss: 1.327093, acc.: 19.53%] [G loss: 0.885034]\n",
      "epoch:28 step:26698 [D loss: 1.243995, acc.: 18.75%] [G loss: 0.796186]\n",
      "epoch:28 step:26699 [D loss: 0.806827, acc.: 49.22%] [G loss: 0.804804]\n",
      "epoch:28 step:26700 [D loss: 0.561636, acc.: 71.88%] [G loss: 1.156166]\n",
      "epoch:28 step:26701 [D loss: 0.633365, acc.: 60.94%] [G loss: 1.242295]\n",
      "epoch:28 step:26702 [D loss: 0.652737, acc.: 61.72%] [G loss: 1.485898]\n",
      "epoch:28 step:26703 [D loss: 0.614202, acc.: 66.41%] [G loss: 1.226776]\n",
      "epoch:28 step:26704 [D loss: 0.433844, acc.: 84.38%] [G loss: 1.328785]\n",
      "epoch:28 step:26705 [D loss: 0.465978, acc.: 77.34%] [G loss: 1.177816]\n",
      "epoch:28 step:26706 [D loss: 0.452512, acc.: 81.25%] [G loss: 1.710271]\n",
      "epoch:28 step:26707 [D loss: 0.357636, acc.: 89.84%] [G loss: 1.388306]\n",
      "epoch:28 step:26708 [D loss: 0.563736, acc.: 68.75%] [G loss: 1.896017]\n",
      "epoch:28 step:26709 [D loss: 1.157370, acc.: 36.72%] [G loss: 1.241852]\n",
      "epoch:28 step:26710 [D loss: 0.976241, acc.: 41.41%] [G loss: 1.342385]\n",
      "epoch:28 step:26711 [D loss: 0.645105, acc.: 64.06%] [G loss: 1.470764]\n",
      "epoch:28 step:26712 [D loss: 0.674177, acc.: 59.38%] [G loss: 1.331000]\n",
      "epoch:28 step:26713 [D loss: 0.643041, acc.: 62.50%] [G loss: 1.308229]\n",
      "epoch:28 step:26714 [D loss: 0.696823, acc.: 56.25%] [G loss: 1.289060]\n",
      "epoch:28 step:26715 [D loss: 0.654592, acc.: 57.03%] [G loss: 1.094842]\n",
      "epoch:28 step:26716 [D loss: 0.679703, acc.: 57.81%] [G loss: 1.230079]\n",
      "epoch:28 step:26717 [D loss: 0.640627, acc.: 65.62%] [G loss: 1.152511]\n",
      "epoch:28 step:26718 [D loss: 0.436199, acc.: 80.47%] [G loss: 1.498144]\n",
      "epoch:28 step:26719 [D loss: 0.352743, acc.: 90.62%] [G loss: 1.704140]\n",
      "epoch:28 step:26720 [D loss: 0.258930, acc.: 95.31%] [G loss: 1.812575]\n",
      "epoch:28 step:26721 [D loss: 0.282079, acc.: 96.88%] [G loss: 1.757297]\n",
      "epoch:28 step:26722 [D loss: 0.367815, acc.: 89.06%] [G loss: 1.523855]\n",
      "epoch:28 step:26723 [D loss: 0.371565, acc.: 89.84%] [G loss: 1.517215]\n",
      "epoch:28 step:26724 [D loss: 0.456275, acc.: 83.59%] [G loss: 1.653651]\n",
      "epoch:28 step:26725 [D loss: 0.625492, acc.: 67.97%] [G loss: 1.209233]\n",
      "epoch:28 step:26726 [D loss: 0.446853, acc.: 80.47%] [G loss: 1.806304]\n",
      "epoch:28 step:26727 [D loss: 0.635544, acc.: 67.97%] [G loss: 1.470024]\n",
      "epoch:28 step:26728 [D loss: 0.686980, acc.: 57.03%] [G loss: 1.120022]\n",
      "epoch:28 step:26729 [D loss: 0.617473, acc.: 66.41%] [G loss: 1.016879]\n",
      "epoch:28 step:26730 [D loss: 0.631636, acc.: 60.94%] [G loss: 0.879797]\n",
      "epoch:28 step:26731 [D loss: 0.524389, acc.: 80.47%] [G loss: 1.428524]\n",
      "epoch:28 step:26732 [D loss: 0.630487, acc.: 64.06%] [G loss: 1.299756]\n",
      "epoch:28 step:26733 [D loss: 0.407541, acc.: 80.47%] [G loss: 1.390259]\n",
      "epoch:28 step:26734 [D loss: 0.288198, acc.: 95.31%] [G loss: 1.902319]\n",
      "epoch:28 step:26735 [D loss: 0.204530, acc.: 98.44%] [G loss: 1.848059]\n",
      "epoch:28 step:26736 [D loss: 0.918928, acc.: 44.53%] [G loss: 1.646751]\n",
      "epoch:28 step:26737 [D loss: 0.708831, acc.: 57.03%] [G loss: 1.059415]\n",
      "epoch:28 step:26738 [D loss: 0.761424, acc.: 53.12%] [G loss: 0.588046]\n",
      "epoch:28 step:26739 [D loss: 0.384571, acc.: 84.38%] [G loss: 1.249498]\n",
      "epoch:28 step:26740 [D loss: 0.208356, acc.: 98.44%] [G loss: 1.558185]\n",
      "epoch:28 step:26741 [D loss: 0.526309, acc.: 71.88%] [G loss: 1.482213]\n",
      "epoch:28 step:26742 [D loss: 0.547044, acc.: 78.12%] [G loss: 1.146609]\n",
      "epoch:28 step:26743 [D loss: 0.449371, acc.: 80.47%] [G loss: 1.488078]\n",
      "epoch:28 step:26744 [D loss: 0.216202, acc.: 96.88%] [G loss: 1.590478]\n",
      "epoch:28 step:26745 [D loss: 0.703815, acc.: 58.59%] [G loss: 1.417553]\n",
      "epoch:28 step:26746 [D loss: 0.772392, acc.: 51.56%] [G loss: 1.027622]\n",
      "epoch:28 step:26747 [D loss: 0.379121, acc.: 79.69%] [G loss: 1.031454]\n",
      "epoch:28 step:26748 [D loss: 0.325050, acc.: 92.97%] [G loss: 1.314189]\n",
      "epoch:28 step:26749 [D loss: 0.270551, acc.: 94.53%] [G loss: 1.473972]\n",
      "epoch:28 step:26750 [D loss: 0.425024, acc.: 82.81%] [G loss: 1.315579]\n",
      "epoch:28 step:26751 [D loss: 0.344726, acc.: 90.62%] [G loss: 1.321582]\n",
      "epoch:28 step:26752 [D loss: 0.820715, acc.: 39.84%] [G loss: 1.379552]\n",
      "epoch:28 step:26753 [D loss: 0.362383, acc.: 92.19%] [G loss: 1.536719]\n",
      "epoch:28 step:26754 [D loss: 0.479898, acc.: 83.59%] [G loss: 1.522279]\n",
      "epoch:28 step:26755 [D loss: 0.418683, acc.: 85.94%] [G loss: 1.428783]\n",
      "epoch:28 step:26756 [D loss: 0.384900, acc.: 90.62%] [G loss: 1.333960]\n",
      "epoch:28 step:26757 [D loss: 0.524563, acc.: 75.78%] [G loss: 1.336635]\n",
      "epoch:28 step:26758 [D loss: 0.386431, acc.: 87.50%] [G loss: 1.094831]\n",
      "epoch:28 step:26759 [D loss: 0.428992, acc.: 87.50%] [G loss: 1.550151]\n",
      "epoch:28 step:26760 [D loss: 0.536237, acc.: 71.09%] [G loss: 1.593917]\n",
      "epoch:28 step:26761 [D loss: 0.547460, acc.: 71.09%] [G loss: 1.208834]\n",
      "epoch:28 step:26762 [D loss: 0.655500, acc.: 62.50%] [G loss: 1.177397]\n",
      "epoch:28 step:26763 [D loss: 0.719627, acc.: 57.03%] [G loss: 0.988157]\n",
      "epoch:28 step:26764 [D loss: 0.706196, acc.: 56.25%] [G loss: 1.001018]\n",
      "epoch:28 step:26765 [D loss: 0.857337, acc.: 36.72%] [G loss: 0.872332]\n",
      "epoch:28 step:26766 [D loss: 0.559847, acc.: 71.09%] [G loss: 1.437484]\n",
      "epoch:28 step:26767 [D loss: 0.587236, acc.: 71.09%] [G loss: 1.180998]\n",
      "epoch:28 step:26768 [D loss: 0.502912, acc.: 75.78%] [G loss: 1.273865]\n",
      "epoch:28 step:26769 [D loss: 0.234678, acc.: 96.09%] [G loss: 1.965330]\n",
      "epoch:28 step:26770 [D loss: 0.307991, acc.: 91.41%] [G loss: 1.326128]\n",
      "epoch:28 step:26771 [D loss: 0.421862, acc.: 85.94%] [G loss: 1.434016]\n",
      "epoch:28 step:26772 [D loss: 0.421712, acc.: 84.38%] [G loss: 1.175701]\n",
      "epoch:28 step:26773 [D loss: 0.308293, acc.: 92.97%] [G loss: 1.750007]\n",
      "epoch:28 step:26774 [D loss: 0.584857, acc.: 64.84%] [G loss: 1.101879]\n",
      "epoch:28 step:26775 [D loss: 0.717023, acc.: 57.03%] [G loss: 1.174998]\n",
      "epoch:28 step:26776 [D loss: 0.757086, acc.: 53.12%] [G loss: 0.917588]\n",
      "epoch:28 step:26777 [D loss: 0.784423, acc.: 50.78%] [G loss: 0.674545]\n",
      "epoch:28 step:26778 [D loss: 0.701925, acc.: 57.03%] [G loss: 0.654306]\n",
      "epoch:28 step:26779 [D loss: 0.455397, acc.: 85.94%] [G loss: 1.259408]\n",
      "epoch:28 step:26780 [D loss: 0.399361, acc.: 89.06%] [G loss: 1.460759]\n",
      "epoch:28 step:26781 [D loss: 0.358747, acc.: 92.97%] [G loss: 1.632260]\n",
      "epoch:28 step:26782 [D loss: 0.346942, acc.: 92.97%] [G loss: 1.179421]\n",
      "epoch:28 step:26783 [D loss: 0.302829, acc.: 92.19%] [G loss: 1.602588]\n",
      "epoch:28 step:26784 [D loss: 0.332157, acc.: 94.53%] [G loss: 1.462664]\n",
      "epoch:28 step:26785 [D loss: 0.192932, acc.: 97.66%] [G loss: 1.742924]\n",
      "epoch:28 step:26786 [D loss: 0.235176, acc.: 96.09%] [G loss: 1.880672]\n",
      "epoch:28 step:26787 [D loss: 0.160289, acc.: 99.22%] [G loss: 1.725116]\n",
      "epoch:28 step:26788 [D loss: 0.230474, acc.: 97.66%] [G loss: 2.130808]\n",
      "epoch:28 step:26789 [D loss: 0.356951, acc.: 91.41%] [G loss: 1.732825]\n",
      "epoch:28 step:26790 [D loss: 0.322127, acc.: 85.16%] [G loss: 1.585018]\n",
      "epoch:28 step:26791 [D loss: 0.220705, acc.: 97.66%] [G loss: 1.731777]\n",
      "epoch:28 step:26792 [D loss: 0.319760, acc.: 89.84%] [G loss: 1.286995]\n",
      "epoch:28 step:26793 [D loss: 0.177665, acc.: 98.44%] [G loss: 2.387636]\n",
      "epoch:28 step:26794 [D loss: 0.434708, acc.: 82.81%] [G loss: 1.634448]\n",
      "epoch:28 step:26795 [D loss: 0.633372, acc.: 62.50%] [G loss: 2.245945]\n",
      "epoch:28 step:26796 [D loss: 0.720865, acc.: 53.91%] [G loss: 1.579861]\n",
      "epoch:28 step:26797 [D loss: 0.407950, acc.: 85.16%] [G loss: 1.122318]\n",
      "epoch:28 step:26798 [D loss: 1.001660, acc.: 25.78%] [G loss: 0.923972]\n",
      "epoch:28 step:26799 [D loss: 0.704226, acc.: 56.25%] [G loss: 1.219198]\n",
      "epoch:28 step:26800 [D loss: 0.598283, acc.: 72.66%] [G loss: 1.064742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26801 [D loss: 0.577165, acc.: 70.31%] [G loss: 1.303234]\n",
      "epoch:28 step:26802 [D loss: 0.312511, acc.: 96.09%] [G loss: 1.227940]\n",
      "epoch:28 step:26803 [D loss: 0.298854, acc.: 94.53%] [G loss: 1.891264]\n",
      "epoch:28 step:26804 [D loss: 0.686993, acc.: 58.59%] [G loss: 1.323224]\n",
      "epoch:28 step:26805 [D loss: 0.774434, acc.: 52.34%] [G loss: 1.078583]\n",
      "epoch:28 step:26806 [D loss: 0.758046, acc.: 50.78%] [G loss: 0.964159]\n",
      "epoch:28 step:26807 [D loss: 0.631568, acc.: 65.62%] [G loss: 1.103104]\n",
      "epoch:28 step:26808 [D loss: 0.484004, acc.: 82.81%] [G loss: 1.170998]\n",
      "epoch:28 step:26809 [D loss: 0.487456, acc.: 80.47%] [G loss: 1.430050]\n",
      "epoch:28 step:26810 [D loss: 0.366503, acc.: 90.62%] [G loss: 1.572937]\n",
      "epoch:28 step:26811 [D loss: 0.429909, acc.: 86.72%] [G loss: 1.033286]\n",
      "epoch:28 step:26812 [D loss: 0.459791, acc.: 77.34%] [G loss: 1.230856]\n",
      "epoch:28 step:26813 [D loss: 0.332719, acc.: 93.75%] [G loss: 1.396462]\n",
      "epoch:28 step:26814 [D loss: 0.285221, acc.: 94.53%] [G loss: 1.601665]\n",
      "epoch:28 step:26815 [D loss: 0.673447, acc.: 58.59%] [G loss: 1.141017]\n",
      "epoch:28 step:26816 [D loss: 1.023784, acc.: 25.78%] [G loss: 0.720455]\n",
      "epoch:28 step:26817 [D loss: 0.496911, acc.: 78.12%] [G loss: 1.240629]\n",
      "epoch:28 step:26818 [D loss: 0.842690, acc.: 42.19%] [G loss: 0.989293]\n",
      "epoch:28 step:26819 [D loss: 0.450619, acc.: 78.12%] [G loss: 1.102265]\n",
      "epoch:28 step:26820 [D loss: 0.963553, acc.: 32.03%] [G loss: 0.685373]\n",
      "epoch:28 step:26821 [D loss: 0.725865, acc.: 51.56%] [G loss: 1.144542]\n",
      "epoch:28 step:26822 [D loss: 0.830584, acc.: 52.34%] [G loss: 0.844312]\n",
      "epoch:28 step:26823 [D loss: 0.221938, acc.: 97.66%] [G loss: 1.555395]\n",
      "epoch:28 step:26824 [D loss: 0.431210, acc.: 80.47%] [G loss: 1.269444]\n",
      "epoch:28 step:26825 [D loss: 0.270180, acc.: 93.75%] [G loss: 2.084443]\n",
      "epoch:28 step:26826 [D loss: 0.881214, acc.: 51.56%] [G loss: 1.616172]\n",
      "epoch:28 step:26827 [D loss: 0.770982, acc.: 49.22%] [G loss: 1.324810]\n",
      "epoch:28 step:26828 [D loss: 0.454958, acc.: 82.03%] [G loss: 1.275872]\n",
      "epoch:28 step:26829 [D loss: 0.928587, acc.: 35.16%] [G loss: 1.007083]\n",
      "epoch:28 step:26830 [D loss: 0.541037, acc.: 70.31%] [G loss: 1.144187]\n",
      "epoch:28 step:26831 [D loss: 0.729664, acc.: 53.12%] [G loss: 1.121014]\n",
      "epoch:28 step:26832 [D loss: 0.612057, acc.: 65.62%] [G loss: 1.131667]\n",
      "epoch:28 step:26833 [D loss: 0.508965, acc.: 77.34%] [G loss: 1.265936]\n",
      "epoch:28 step:26834 [D loss: 0.281317, acc.: 93.75%] [G loss: 1.522951]\n",
      "epoch:28 step:26835 [D loss: 0.663874, acc.: 67.19%] [G loss: 1.208591]\n",
      "epoch:28 step:26836 [D loss: 0.589352, acc.: 73.44%] [G loss: 1.133855]\n",
      "epoch:28 step:26837 [D loss: 0.566030, acc.: 72.66%] [G loss: 1.186648]\n",
      "epoch:28 step:26838 [D loss: 0.510938, acc.: 74.22%] [G loss: 1.125830]\n",
      "epoch:28 step:26839 [D loss: 0.438133, acc.: 82.03%] [G loss: 1.164124]\n",
      "epoch:28 step:26840 [D loss: 0.275151, acc.: 92.19%] [G loss: 0.991752]\n",
      "epoch:28 step:26841 [D loss: 0.401096, acc.: 89.84%] [G loss: 1.228398]\n",
      "epoch:28 step:26842 [D loss: 0.827291, acc.: 49.22%] [G loss: 1.244339]\n",
      "epoch:28 step:26843 [D loss: 0.795019, acc.: 46.88%] [G loss: 1.009702]\n",
      "epoch:28 step:26844 [D loss: 0.604145, acc.: 70.31%] [G loss: 1.013219]\n",
      "epoch:28 step:26845 [D loss: 0.640351, acc.: 63.28%] [G loss: 1.072209]\n",
      "epoch:28 step:26846 [D loss: 0.633703, acc.: 64.84%] [G loss: 1.201647]\n",
      "epoch:28 step:26847 [D loss: 0.923491, acc.: 32.81%] [G loss: 1.097649]\n",
      "epoch:28 step:26848 [D loss: 0.753277, acc.: 48.44%] [G loss: 1.101249]\n",
      "epoch:28 step:26849 [D loss: 0.467080, acc.: 82.81%] [G loss: 1.215910]\n",
      "epoch:28 step:26850 [D loss: 0.325533, acc.: 89.84%] [G loss: 1.322236]\n",
      "epoch:28 step:26851 [D loss: 0.368299, acc.: 86.72%] [G loss: 1.321951]\n",
      "epoch:28 step:26852 [D loss: 0.269812, acc.: 96.88%] [G loss: 1.537531]\n",
      "epoch:28 step:26853 [D loss: 0.320289, acc.: 96.09%] [G loss: 1.602324]\n",
      "epoch:28 step:26854 [D loss: 0.675413, acc.: 61.72%] [G loss: 1.091981]\n",
      "epoch:28 step:26855 [D loss: 1.030774, acc.: 26.56%] [G loss: 1.027884]\n",
      "epoch:28 step:26856 [D loss: 0.659425, acc.: 58.59%] [G loss: 0.821621]\n",
      "epoch:28 step:26857 [D loss: 0.674346, acc.: 53.91%] [G loss: 0.830121]\n",
      "epoch:28 step:26858 [D loss: 0.477562, acc.: 82.03%] [G loss: 1.168740]\n",
      "epoch:28 step:26859 [D loss: 0.498144, acc.: 78.91%] [G loss: 1.111354]\n",
      "epoch:28 step:26860 [D loss: 0.415470, acc.: 86.72%] [G loss: 1.169567]\n",
      "epoch:28 step:26861 [D loss: 0.863663, acc.: 39.84%] [G loss: 0.971910]\n",
      "epoch:28 step:26862 [D loss: 0.542349, acc.: 71.09%] [G loss: 1.122183]\n",
      "epoch:28 step:26863 [D loss: 0.721966, acc.: 57.03%] [G loss: 0.756845]\n",
      "epoch:28 step:26864 [D loss: 0.588874, acc.: 66.41%] [G loss: 1.121114]\n",
      "epoch:28 step:26865 [D loss: 0.273182, acc.: 90.62%] [G loss: 1.364085]\n",
      "epoch:28 step:26866 [D loss: 0.310291, acc.: 92.97%] [G loss: 1.352775]\n",
      "epoch:28 step:26867 [D loss: 0.627006, acc.: 68.75%] [G loss: 1.284216]\n",
      "epoch:28 step:26868 [D loss: 0.330605, acc.: 92.19%] [G loss: 1.688338]\n",
      "epoch:28 step:26869 [D loss: 0.341588, acc.: 89.84%] [G loss: 1.655828]\n",
      "epoch:28 step:26870 [D loss: 0.498769, acc.: 75.00%] [G loss: 1.633183]\n",
      "epoch:28 step:26871 [D loss: 0.594466, acc.: 71.88%] [G loss: 1.228042]\n",
      "epoch:28 step:26872 [D loss: 0.827448, acc.: 47.66%] [G loss: 1.138994]\n",
      "epoch:28 step:26873 [D loss: 0.816486, acc.: 52.34%] [G loss: 0.892834]\n",
      "epoch:28 step:26874 [D loss: 0.573425, acc.: 67.97%] [G loss: 0.980590]\n",
      "epoch:28 step:26875 [D loss: 1.095526, acc.: 23.44%] [G loss: 0.689801]\n",
      "epoch:28 step:26876 [D loss: 0.955825, acc.: 32.81%] [G loss: 1.059853]\n",
      "epoch:28 step:26877 [D loss: 0.760117, acc.: 50.78%] [G loss: 1.106007]\n",
      "epoch:28 step:26878 [D loss: 0.609288, acc.: 70.31%] [G loss: 1.831273]\n",
      "epoch:28 step:26879 [D loss: 0.858770, acc.: 52.34%] [G loss: 1.803058]\n",
      "epoch:28 step:26880 [D loss: 0.804737, acc.: 49.22%] [G loss: 1.417315]\n",
      "epoch:28 step:26881 [D loss: 0.679547, acc.: 60.94%] [G loss: 1.168776]\n",
      "epoch:28 step:26882 [D loss: 0.491090, acc.: 79.69%] [G loss: 1.344017]\n",
      "epoch:28 step:26883 [D loss: 0.388839, acc.: 85.16%] [G loss: 1.344061]\n",
      "epoch:28 step:26884 [D loss: 0.468726, acc.: 82.81%] [G loss: 1.261995]\n",
      "epoch:28 step:26885 [D loss: 0.513237, acc.: 81.25%] [G loss: 1.301956]\n",
      "epoch:28 step:26886 [D loss: 0.511945, acc.: 77.34%] [G loss: 1.153960]\n",
      "epoch:28 step:26887 [D loss: 0.488931, acc.: 82.81%] [G loss: 1.409949]\n",
      "epoch:28 step:26888 [D loss: 0.665968, acc.: 62.50%] [G loss: 1.233774]\n",
      "epoch:28 step:26889 [D loss: 0.514598, acc.: 78.91%] [G loss: 1.439733]\n",
      "epoch:28 step:26890 [D loss: 0.460938, acc.: 81.25%] [G loss: 1.219870]\n",
      "epoch:28 step:26891 [D loss: 0.625744, acc.: 63.28%] [G loss: 1.174518]\n",
      "epoch:28 step:26892 [D loss: 0.604590, acc.: 67.19%] [G loss: 0.977835]\n",
      "epoch:28 step:26893 [D loss: 0.477624, acc.: 81.25%] [G loss: 1.468229]\n",
      "epoch:28 step:26894 [D loss: 0.461552, acc.: 78.12%] [G loss: 1.179530]\n",
      "epoch:28 step:26895 [D loss: 0.590401, acc.: 69.53%] [G loss: 1.345781]\n",
      "epoch:28 step:26896 [D loss: 0.648334, acc.: 59.38%] [G loss: 1.466134]\n",
      "epoch:28 step:26897 [D loss: 0.495143, acc.: 80.47%] [G loss: 1.254205]\n",
      "epoch:28 step:26898 [D loss: 0.384535, acc.: 82.81%] [G loss: 1.335540]\n",
      "epoch:28 step:26899 [D loss: 0.142701, acc.: 99.22%] [G loss: 1.582168]\n",
      "epoch:28 step:26900 [D loss: 0.122400, acc.: 99.22%] [G loss: 2.126454]\n",
      "epoch:28 step:26901 [D loss: 0.184578, acc.: 97.66%] [G loss: 1.810200]\n",
      "epoch:28 step:26902 [D loss: 0.221809, acc.: 94.53%] [G loss: 1.953357]\n",
      "epoch:28 step:26903 [D loss: 0.339637, acc.: 88.28%] [G loss: 1.639682]\n",
      "epoch:28 step:26904 [D loss: 0.479288, acc.: 77.34%] [G loss: 1.804526]\n",
      "epoch:28 step:26905 [D loss: 0.403205, acc.: 85.94%] [G loss: 1.334557]\n",
      "epoch:28 step:26906 [D loss: 0.494669, acc.: 76.56%] [G loss: 1.199164]\n",
      "epoch:28 step:26907 [D loss: 0.380486, acc.: 85.16%] [G loss: 1.454742]\n",
      "epoch:28 step:26908 [D loss: 0.759439, acc.: 51.56%] [G loss: 1.016304]\n",
      "epoch:28 step:26909 [D loss: 1.169987, acc.: 16.41%] [G loss: 0.536839]\n",
      "epoch:28 step:26910 [D loss: 0.628389, acc.: 60.16%] [G loss: 0.956811]\n",
      "epoch:28 step:26911 [D loss: 1.137607, acc.: 18.75%] [G loss: 0.669340]\n",
      "epoch:28 step:26912 [D loss: 0.643372, acc.: 59.38%] [G loss: 0.876726]\n",
      "epoch:28 step:26913 [D loss: 0.768459, acc.: 51.56%] [G loss: 1.088291]\n",
      "epoch:28 step:26914 [D loss: 0.698710, acc.: 60.16%] [G loss: 0.752192]\n",
      "epoch:28 step:26915 [D loss: 0.658933, acc.: 59.38%] [G loss: 0.853551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26916 [D loss: 0.750447, acc.: 46.09%] [G loss: 0.986785]\n",
      "epoch:28 step:26917 [D loss: 0.619639, acc.: 64.84%] [G loss: 0.962558]\n",
      "epoch:28 step:26918 [D loss: 0.516575, acc.: 75.78%] [G loss: 1.091918]\n",
      "epoch:28 step:26919 [D loss: 0.604265, acc.: 65.62%] [G loss: 1.089236]\n",
      "epoch:28 step:26920 [D loss: 0.549828, acc.: 74.22%] [G loss: 1.017480]\n",
      "epoch:28 step:26921 [D loss: 0.518748, acc.: 76.56%] [G loss: 1.236385]\n",
      "epoch:28 step:26922 [D loss: 0.971682, acc.: 32.03%] [G loss: 1.006728]\n",
      "epoch:28 step:26923 [D loss: 0.558848, acc.: 69.53%] [G loss: 1.063573]\n",
      "epoch:28 step:26924 [D loss: 1.084895, acc.: 25.00%] [G loss: 0.925550]\n",
      "epoch:28 step:26925 [D loss: 1.056697, acc.: 31.25%] [G loss: 1.048832]\n",
      "epoch:28 step:26926 [D loss: 0.633948, acc.: 64.06%] [G loss: 1.178044]\n",
      "epoch:28 step:26927 [D loss: 0.739666, acc.: 51.56%] [G loss: 1.185864]\n",
      "epoch:28 step:26928 [D loss: 0.567913, acc.: 74.22%] [G loss: 1.476808]\n",
      "epoch:28 step:26929 [D loss: 0.519377, acc.: 76.56%] [G loss: 1.345561]\n",
      "epoch:28 step:26930 [D loss: 0.289347, acc.: 92.97%] [G loss: 1.388423]\n",
      "epoch:28 step:26931 [D loss: 0.533592, acc.: 73.44%] [G loss: 1.374596]\n",
      "epoch:28 step:26932 [D loss: 0.660272, acc.: 56.25%] [G loss: 1.334849]\n",
      "epoch:28 step:26933 [D loss: 0.686705, acc.: 51.56%] [G loss: 1.206239]\n",
      "epoch:28 step:26934 [D loss: 0.634887, acc.: 68.75%] [G loss: 1.312482]\n",
      "epoch:28 step:26935 [D loss: 0.609563, acc.: 65.62%] [G loss: 0.990884]\n",
      "epoch:28 step:26936 [D loss: 0.595820, acc.: 62.50%] [G loss: 0.944847]\n",
      "epoch:28 step:26937 [D loss: 0.705449, acc.: 55.47%] [G loss: 0.839956]\n",
      "epoch:28 step:26938 [D loss: 0.594050, acc.: 65.62%] [G loss: 1.238118]\n",
      "epoch:28 step:26939 [D loss: 0.684771, acc.: 58.59%] [G loss: 1.017827]\n",
      "epoch:28 step:26940 [D loss: 0.496331, acc.: 77.34%] [G loss: 1.145432]\n",
      "epoch:28 step:26941 [D loss: 0.748166, acc.: 53.91%] [G loss: 1.027187]\n",
      "epoch:28 step:26942 [D loss: 0.445171, acc.: 82.81%] [G loss: 1.129219]\n",
      "epoch:28 step:26943 [D loss: 0.428331, acc.: 80.47%] [G loss: 1.390825]\n",
      "epoch:28 step:26944 [D loss: 0.402702, acc.: 85.94%] [G loss: 1.428623]\n",
      "epoch:28 step:26945 [D loss: 0.294900, acc.: 93.75%] [G loss: 1.420360]\n",
      "epoch:28 step:26946 [D loss: 0.713203, acc.: 55.47%] [G loss: 1.239826]\n",
      "epoch:28 step:26947 [D loss: 0.588131, acc.: 65.62%] [G loss: 1.188720]\n",
      "epoch:28 step:26948 [D loss: 0.530454, acc.: 79.69%] [G loss: 1.024291]\n",
      "epoch:28 step:26949 [D loss: 0.452689, acc.: 84.38%] [G loss: 1.139603]\n",
      "epoch:28 step:26950 [D loss: 0.661716, acc.: 64.06%] [G loss: 1.057241]\n",
      "epoch:28 step:26951 [D loss: 0.627388, acc.: 64.06%] [G loss: 0.922848]\n",
      "epoch:28 step:26952 [D loss: 0.685220, acc.: 62.50%] [G loss: 1.013990]\n",
      "epoch:28 step:26953 [D loss: 0.755974, acc.: 47.66%] [G loss: 1.199859]\n",
      "epoch:28 step:26954 [D loss: 0.661811, acc.: 61.72%] [G loss: 1.182387]\n",
      "epoch:28 step:26955 [D loss: 0.518398, acc.: 78.91%] [G loss: 1.154566]\n",
      "epoch:28 step:26956 [D loss: 0.630209, acc.: 65.62%] [G loss: 1.033598]\n",
      "epoch:28 step:26957 [D loss: 0.506070, acc.: 75.00%] [G loss: 0.982518]\n",
      "epoch:28 step:26958 [D loss: 0.653095, acc.: 65.62%] [G loss: 1.106002]\n",
      "epoch:28 step:26959 [D loss: 0.751504, acc.: 50.78%] [G loss: 1.039587]\n",
      "epoch:28 step:26960 [D loss: 0.360264, acc.: 89.06%] [G loss: 1.428981]\n",
      "epoch:28 step:26961 [D loss: 0.418933, acc.: 84.38%] [G loss: 1.383465]\n",
      "epoch:28 step:26962 [D loss: 0.452073, acc.: 82.81%] [G loss: 1.506543]\n",
      "epoch:28 step:26963 [D loss: 0.642806, acc.: 64.84%] [G loss: 1.399003]\n",
      "epoch:28 step:26964 [D loss: 0.607634, acc.: 67.19%] [G loss: 1.080987]\n",
      "epoch:28 step:26965 [D loss: 0.554040, acc.: 74.22%] [G loss: 1.044986]\n",
      "epoch:28 step:26966 [D loss: 0.528958, acc.: 77.34%] [G loss: 1.160185]\n",
      "epoch:28 step:26967 [D loss: 0.556902, acc.: 67.97%] [G loss: 0.876684]\n",
      "epoch:28 step:26968 [D loss: 0.504791, acc.: 75.78%] [G loss: 1.330345]\n",
      "epoch:28 step:26969 [D loss: 0.335940, acc.: 89.06%] [G loss: 1.614780]\n",
      "epoch:28 step:26970 [D loss: 0.716645, acc.: 53.12%] [G loss: 0.876335]\n",
      "epoch:28 step:26971 [D loss: 0.747991, acc.: 47.66%] [G loss: 0.903044]\n",
      "epoch:28 step:26972 [D loss: 0.744016, acc.: 57.03%] [G loss: 1.177290]\n",
      "epoch:28 step:26973 [D loss: 0.510929, acc.: 76.56%] [G loss: 1.195703]\n",
      "epoch:28 step:26974 [D loss: 0.630676, acc.: 65.62%] [G loss: 1.040442]\n",
      "epoch:28 step:26975 [D loss: 0.836938, acc.: 45.31%] [G loss: 1.122152]\n",
      "epoch:28 step:26976 [D loss: 0.546271, acc.: 73.44%] [G loss: 1.259252]\n",
      "epoch:28 step:26977 [D loss: 0.391181, acc.: 85.16%] [G loss: 1.271322]\n",
      "epoch:28 step:26978 [D loss: 0.482851, acc.: 80.47%] [G loss: 1.402039]\n",
      "epoch:28 step:26979 [D loss: 0.474165, acc.: 78.12%] [G loss: 1.370542]\n",
      "epoch:28 step:26980 [D loss: 0.836568, acc.: 39.84%] [G loss: 0.895573]\n",
      "epoch:28 step:26981 [D loss: 0.318420, acc.: 92.97%] [G loss: 1.384961]\n",
      "epoch:28 step:26982 [D loss: 0.467037, acc.: 81.25%] [G loss: 1.090380]\n",
      "epoch:28 step:26983 [D loss: 0.612009, acc.: 60.94%] [G loss: 1.253222]\n",
      "epoch:28 step:26984 [D loss: 0.499550, acc.: 78.91%] [G loss: 1.145230]\n",
      "epoch:28 step:26985 [D loss: 0.527199, acc.: 73.44%] [G loss: 1.113321]\n",
      "epoch:28 step:26986 [D loss: 0.460639, acc.: 78.91%] [G loss: 1.437969]\n",
      "epoch:28 step:26987 [D loss: 0.618359, acc.: 65.62%] [G loss: 1.064704]\n",
      "epoch:28 step:26988 [D loss: 0.893594, acc.: 39.06%] [G loss: 0.812619]\n",
      "epoch:28 step:26989 [D loss: 0.595060, acc.: 64.84%] [G loss: 0.877705]\n",
      "epoch:28 step:26990 [D loss: 0.733408, acc.: 54.69%] [G loss: 0.892124]\n",
      "epoch:28 step:26991 [D loss: 0.610538, acc.: 65.62%] [G loss: 1.108614]\n",
      "epoch:28 step:26992 [D loss: 0.574570, acc.: 71.88%] [G loss: 1.206792]\n",
      "epoch:28 step:26993 [D loss: 0.645749, acc.: 66.41%] [G loss: 1.221995]\n",
      "epoch:28 step:26994 [D loss: 0.852582, acc.: 44.53%] [G loss: 0.827526]\n",
      "epoch:28 step:26995 [D loss: 0.664190, acc.: 58.59%] [G loss: 1.232207]\n",
      "epoch:28 step:26996 [D loss: 0.704091, acc.: 58.59%] [G loss: 1.044355]\n",
      "epoch:28 step:26997 [D loss: 0.721796, acc.: 50.78%] [G loss: 1.222373]\n",
      "epoch:28 step:26998 [D loss: 0.746628, acc.: 49.22%] [G loss: 1.184637]\n",
      "epoch:28 step:26999 [D loss: 0.570058, acc.: 71.09%] [G loss: 0.920583]\n",
      "epoch:28 step:27000 [D loss: 0.546303, acc.: 71.09%] [G loss: 1.081851]\n",
      "epoch:28 step:27001 [D loss: 0.552864, acc.: 67.97%] [G loss: 1.095910]\n",
      "epoch:28 step:27002 [D loss: 0.504331, acc.: 74.22%] [G loss: 1.329538]\n",
      "epoch:28 step:27003 [D loss: 0.369128, acc.: 92.97%] [G loss: 1.131032]\n",
      "epoch:28 step:27004 [D loss: 0.239608, acc.: 94.53%] [G loss: 1.977011]\n",
      "epoch:28 step:27005 [D loss: 0.162637, acc.: 98.44%] [G loss: 1.816187]\n",
      "epoch:28 step:27006 [D loss: 0.619788, acc.: 64.06%] [G loss: 1.119480]\n",
      "epoch:28 step:27007 [D loss: 0.640734, acc.: 61.72%] [G loss: 1.326992]\n",
      "epoch:28 step:27008 [D loss: 0.935330, acc.: 39.06%] [G loss: 0.932789]\n",
      "epoch:28 step:27009 [D loss: 0.720186, acc.: 57.03%] [G loss: 0.974037]\n",
      "epoch:28 step:27010 [D loss: 0.397768, acc.: 72.66%] [G loss: 1.339688]\n",
      "epoch:28 step:27011 [D loss: 0.206082, acc.: 96.88%] [G loss: 1.741848]\n",
      "epoch:28 step:27012 [D loss: 0.472112, acc.: 78.12%] [G loss: 1.485031]\n",
      "epoch:28 step:27013 [D loss: 0.289712, acc.: 89.06%] [G loss: 1.864470]\n",
      "epoch:28 step:27014 [D loss: 0.561453, acc.: 70.31%] [G loss: 1.416602]\n",
      "epoch:28 step:27015 [D loss: 0.929802, acc.: 39.84%] [G loss: 1.098047]\n",
      "epoch:28 step:27016 [D loss: 0.463972, acc.: 81.25%] [G loss: 1.544080]\n",
      "epoch:28 step:27017 [D loss: 0.432650, acc.: 80.47%] [G loss: 1.494545]\n",
      "epoch:28 step:27018 [D loss: 0.302102, acc.: 93.75%] [G loss: 1.619320]\n",
      "epoch:28 step:27019 [D loss: 0.839248, acc.: 50.78%] [G loss: 1.563443]\n",
      "epoch:28 step:27020 [D loss: 0.638713, acc.: 60.94%] [G loss: 1.447044]\n",
      "epoch:28 step:27021 [D loss: 0.558289, acc.: 71.88%] [G loss: 0.876349]\n",
      "epoch:28 step:27022 [D loss: 0.404649, acc.: 78.91%] [G loss: 1.271699]\n",
      "epoch:28 step:27023 [D loss: 0.650063, acc.: 62.50%] [G loss: 1.441480]\n",
      "epoch:28 step:27024 [D loss: 0.618653, acc.: 64.84%] [G loss: 1.262187]\n",
      "epoch:28 step:27025 [D loss: 0.516318, acc.: 70.31%] [G loss: 1.262549]\n",
      "epoch:28 step:27026 [D loss: 0.370986, acc.: 86.72%] [G loss: 1.274057]\n",
      "epoch:28 step:27027 [D loss: 0.225358, acc.: 96.88%] [G loss: 1.279954]\n",
      "epoch:28 step:27028 [D loss: 0.383282, acc.: 83.59%] [G loss: 1.113975]\n",
      "epoch:28 step:27029 [D loss: 0.199962, acc.: 98.44%] [G loss: 2.439161]\n",
      "epoch:28 step:27030 [D loss: 0.184798, acc.: 98.44%] [G loss: 1.945709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27031 [D loss: 0.347684, acc.: 89.84%] [G loss: 2.098269]\n",
      "epoch:28 step:27032 [D loss: 0.306383, acc.: 90.62%] [G loss: 1.779298]\n",
      "epoch:28 step:27033 [D loss: 0.617754, acc.: 67.97%] [G loss: 1.042183]\n",
      "epoch:28 step:27034 [D loss: 0.495897, acc.: 77.34%] [G loss: 1.136987]\n",
      "epoch:28 step:27035 [D loss: 0.712719, acc.: 57.03%] [G loss: 1.455194]\n",
      "epoch:28 step:27036 [D loss: 0.799809, acc.: 51.56%] [G loss: 1.130122]\n",
      "epoch:28 step:27037 [D loss: 0.782552, acc.: 45.31%] [G loss: 1.304100]\n",
      "epoch:28 step:27038 [D loss: 0.739326, acc.: 53.12%] [G loss: 1.058784]\n",
      "epoch:28 step:27039 [D loss: 0.636415, acc.: 60.94%] [G loss: 1.424013]\n",
      "epoch:28 step:27040 [D loss: 0.428740, acc.: 82.81%] [G loss: 1.494219]\n",
      "epoch:28 step:27041 [D loss: 0.457672, acc.: 76.56%] [G loss: 1.233391]\n",
      "epoch:28 step:27042 [D loss: 0.318558, acc.: 92.19%] [G loss: 1.367730]\n",
      "epoch:28 step:27043 [D loss: 0.811188, acc.: 49.22%] [G loss: 1.250256]\n",
      "epoch:28 step:27044 [D loss: 0.493311, acc.: 75.78%] [G loss: 1.193681]\n",
      "epoch:28 step:27045 [D loss: 0.484549, acc.: 83.59%] [G loss: 1.047981]\n",
      "epoch:28 step:27046 [D loss: 0.538883, acc.: 74.22%] [G loss: 1.165476]\n",
      "epoch:28 step:27047 [D loss: 0.698225, acc.: 57.81%] [G loss: 1.098128]\n",
      "epoch:28 step:27048 [D loss: 0.696713, acc.: 54.69%] [G loss: 0.938365]\n",
      "epoch:28 step:27049 [D loss: 0.812265, acc.: 42.19%] [G loss: 0.864665]\n",
      "epoch:28 step:27050 [D loss: 0.546434, acc.: 77.34%] [G loss: 1.217818]\n",
      "epoch:28 step:27051 [D loss: 0.381334, acc.: 76.56%] [G loss: 1.376566]\n",
      "epoch:28 step:27052 [D loss: 0.279777, acc.: 96.09%] [G loss: 1.508059]\n",
      "epoch:28 step:27053 [D loss: 0.745891, acc.: 57.81%] [G loss: 1.209621]\n",
      "epoch:28 step:27054 [D loss: 0.455153, acc.: 86.72%] [G loss: 1.274474]\n",
      "epoch:28 step:27055 [D loss: 0.533979, acc.: 75.78%] [G loss: 1.197162]\n",
      "epoch:28 step:27056 [D loss: 0.977749, acc.: 32.03%] [G loss: 0.741607]\n",
      "epoch:28 step:27057 [D loss: 0.713665, acc.: 57.81%] [G loss: 1.258967]\n",
      "epoch:28 step:27058 [D loss: 0.575269, acc.: 67.97%] [G loss: 1.008020]\n",
      "epoch:28 step:27059 [D loss: 0.701584, acc.: 53.91%] [G loss: 1.160244]\n",
      "epoch:28 step:27060 [D loss: 0.428536, acc.: 86.72%] [G loss: 1.223407]\n",
      "epoch:28 step:27061 [D loss: 0.428845, acc.: 82.03%] [G loss: 1.147574]\n",
      "epoch:28 step:27062 [D loss: 0.587765, acc.: 67.19%] [G loss: 1.329163]\n",
      "epoch:28 step:27063 [D loss: 0.840482, acc.: 38.28%] [G loss: 1.133430]\n",
      "epoch:28 step:27064 [D loss: 0.625664, acc.: 60.94%] [G loss: 1.136050]\n",
      "epoch:28 step:27065 [D loss: 0.568901, acc.: 75.78%] [G loss: 0.879901]\n",
      "epoch:28 step:27066 [D loss: 0.704546, acc.: 57.03%] [G loss: 1.027941]\n",
      "epoch:28 step:27067 [D loss: 0.327588, acc.: 90.62%] [G loss: 1.299572]\n",
      "epoch:28 step:27068 [D loss: 0.369912, acc.: 92.97%] [G loss: 1.531379]\n",
      "epoch:28 step:27069 [D loss: 0.432473, acc.: 82.03%] [G loss: 1.443027]\n",
      "epoch:28 step:27070 [D loss: 0.727740, acc.: 56.25%] [G loss: 1.374568]\n",
      "epoch:28 step:27071 [D loss: 0.753616, acc.: 52.34%] [G loss: 1.263994]\n",
      "epoch:28 step:27072 [D loss: 0.670204, acc.: 57.81%] [G loss: 0.865827]\n",
      "epoch:28 step:27073 [D loss: 0.448749, acc.: 82.03%] [G loss: 1.461434]\n",
      "epoch:28 step:27074 [D loss: 0.632185, acc.: 63.28%] [G loss: 1.301378]\n",
      "epoch:28 step:27075 [D loss: 0.506526, acc.: 75.00%] [G loss: 0.950014]\n",
      "epoch:28 step:27076 [D loss: 0.543230, acc.: 74.22%] [G loss: 1.022499]\n",
      "epoch:28 step:27077 [D loss: 0.529702, acc.: 78.91%] [G loss: 1.188313]\n",
      "epoch:28 step:27078 [D loss: 0.384352, acc.: 89.84%] [G loss: 1.477716]\n",
      "epoch:28 step:27079 [D loss: 0.828613, acc.: 46.09%] [G loss: 1.275910]\n",
      "epoch:28 step:27080 [D loss: 0.783580, acc.: 44.53%] [G loss: 0.721179]\n",
      "epoch:28 step:27081 [D loss: 0.569714, acc.: 69.53%] [G loss: 1.188032]\n",
      "epoch:28 step:27082 [D loss: 0.600006, acc.: 69.53%] [G loss: 0.953588]\n",
      "epoch:28 step:27083 [D loss: 0.562949, acc.: 68.75%] [G loss: 1.434270]\n",
      "epoch:28 step:27084 [D loss: 0.617693, acc.: 64.06%] [G loss: 1.406692]\n",
      "epoch:28 step:27085 [D loss: 0.455587, acc.: 80.47%] [G loss: 1.260607]\n",
      "epoch:28 step:27086 [D loss: 0.435926, acc.: 79.69%] [G loss: 1.310557]\n",
      "epoch:28 step:27087 [D loss: 0.300207, acc.: 86.72%] [G loss: 1.326348]\n",
      "epoch:28 step:27088 [D loss: 0.245019, acc.: 96.88%] [G loss: 1.666939]\n",
      "epoch:28 step:27089 [D loss: 0.275655, acc.: 97.66%] [G loss: 1.963583]\n",
      "epoch:28 step:27090 [D loss: 0.346624, acc.: 86.72%] [G loss: 1.303183]\n",
      "epoch:28 step:27091 [D loss: 0.415757, acc.: 83.59%] [G loss: 1.775943]\n",
      "epoch:28 step:27092 [D loss: 0.754751, acc.: 51.56%] [G loss: 0.990165]\n",
      "epoch:28 step:27093 [D loss: 0.433278, acc.: 82.03%] [G loss: 1.612327]\n",
      "epoch:28 step:27094 [D loss: 0.544417, acc.: 71.88%] [G loss: 1.676671]\n",
      "epoch:28 step:27095 [D loss: 0.518941, acc.: 75.78%] [G loss: 1.277067]\n",
      "epoch:28 step:27096 [D loss: 0.414174, acc.: 85.94%] [G loss: 1.460856]\n",
      "epoch:28 step:27097 [D loss: 0.750732, acc.: 60.16%] [G loss: 1.497442]\n",
      "epoch:28 step:27098 [D loss: 0.806258, acc.: 46.88%] [G loss: 1.234699]\n",
      "epoch:28 step:27099 [D loss: 0.617586, acc.: 68.75%] [G loss: 0.959043]\n",
      "epoch:28 step:27100 [D loss: 0.655528, acc.: 62.50%] [G loss: 1.069008]\n",
      "epoch:28 step:27101 [D loss: 0.553081, acc.: 70.31%] [G loss: 0.971979]\n",
      "epoch:28 step:27102 [D loss: 0.712231, acc.: 55.47%] [G loss: 0.995114]\n",
      "epoch:28 step:27103 [D loss: 0.518974, acc.: 80.47%] [G loss: 1.147520]\n",
      "epoch:28 step:27104 [D loss: 0.675175, acc.: 57.81%] [G loss: 1.065700]\n",
      "epoch:28 step:27105 [D loss: 0.556594, acc.: 72.66%] [G loss: 1.145128]\n",
      "epoch:28 step:27106 [D loss: 0.735392, acc.: 50.00%] [G loss: 1.024827]\n",
      "epoch:28 step:27107 [D loss: 0.660370, acc.: 59.38%] [G loss: 0.819124]\n",
      "epoch:28 step:27108 [D loss: 0.550423, acc.: 71.09%] [G loss: 1.002027]\n",
      "epoch:28 step:27109 [D loss: 0.669753, acc.: 60.94%] [G loss: 1.344059]\n",
      "epoch:28 step:27110 [D loss: 0.625298, acc.: 62.50%] [G loss: 1.152614]\n",
      "epoch:28 step:27111 [D loss: 0.580334, acc.: 71.88%] [G loss: 0.999360]\n",
      "epoch:28 step:27112 [D loss: 1.005414, acc.: 38.28%] [G loss: 0.681534]\n",
      "epoch:28 step:27113 [D loss: 0.477805, acc.: 82.03%] [G loss: 1.599249]\n",
      "epoch:28 step:27114 [D loss: 0.257346, acc.: 95.31%] [G loss: 1.744131]\n",
      "epoch:28 step:27115 [D loss: 0.502213, acc.: 76.56%] [G loss: 1.322105]\n",
      "epoch:28 step:27116 [D loss: 0.741093, acc.: 56.25%] [G loss: 1.289828]\n",
      "epoch:28 step:27117 [D loss: 0.720210, acc.: 55.47%] [G loss: 1.158935]\n",
      "epoch:28 step:27118 [D loss: 0.754715, acc.: 52.34%] [G loss: 1.006470]\n",
      "epoch:28 step:27119 [D loss: 0.600378, acc.: 65.62%] [G loss: 0.775798]\n",
      "epoch:28 step:27120 [D loss: 0.423067, acc.: 82.81%] [G loss: 1.321136]\n",
      "epoch:28 step:27121 [D loss: 0.325283, acc.: 95.31%] [G loss: 1.375875]\n",
      "epoch:28 step:27122 [D loss: 0.442890, acc.: 82.03%] [G loss: 1.456211]\n",
      "epoch:28 step:27123 [D loss: 0.330548, acc.: 93.75%] [G loss: 1.277192]\n",
      "epoch:28 step:27124 [D loss: 0.468689, acc.: 82.03%] [G loss: 1.574233]\n",
      "epoch:28 step:27125 [D loss: 0.290421, acc.: 92.19%] [G loss: 1.251444]\n",
      "epoch:28 step:27126 [D loss: 0.352823, acc.: 91.41%] [G loss: 1.391693]\n",
      "epoch:28 step:27127 [D loss: 0.848851, acc.: 46.88%] [G loss: 1.210769]\n",
      "epoch:28 step:27128 [D loss: 0.459064, acc.: 84.38%] [G loss: 1.003347]\n",
      "epoch:28 step:27129 [D loss: 0.429540, acc.: 86.72%] [G loss: 1.119682]\n",
      "epoch:28 step:27130 [D loss: 0.443030, acc.: 85.16%] [G loss: 1.075896]\n",
      "epoch:28 step:27131 [D loss: 0.412216, acc.: 85.16%] [G loss: 1.367100]\n",
      "epoch:28 step:27132 [D loss: 0.378433, acc.: 89.84%] [G loss: 1.226789]\n",
      "epoch:28 step:27133 [D loss: 0.373012, acc.: 89.06%] [G loss: 1.445460]\n",
      "epoch:28 step:27134 [D loss: 0.251319, acc.: 95.31%] [G loss: 1.536476]\n",
      "epoch:28 step:27135 [D loss: 0.243838, acc.: 96.88%] [G loss: 1.791987]\n",
      "epoch:28 step:27136 [D loss: 0.156132, acc.: 100.00%] [G loss: 1.713587]\n",
      "epoch:28 step:27137 [D loss: 0.427581, acc.: 81.25%] [G loss: 1.735589]\n",
      "epoch:28 step:27138 [D loss: 0.962681, acc.: 35.16%] [G loss: 0.807557]\n",
      "epoch:28 step:27139 [D loss: 0.424505, acc.: 83.59%] [G loss: 1.646199]\n",
      "epoch:28 step:27140 [D loss: 0.543065, acc.: 72.66%] [G loss: 1.812221]\n",
      "epoch:28 step:27141 [D loss: 0.602320, acc.: 67.19%] [G loss: 1.222957]\n",
      "epoch:28 step:27142 [D loss: 0.622343, acc.: 68.75%] [G loss: 1.411291]\n",
      "epoch:28 step:27143 [D loss: 0.810036, acc.: 41.41%] [G loss: 1.330501]\n",
      "epoch:28 step:27144 [D loss: 0.861312, acc.: 36.72%] [G loss: 1.042143]\n",
      "epoch:28 step:27145 [D loss: 0.412462, acc.: 83.59%] [G loss: 1.092531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27146 [D loss: 0.560692, acc.: 66.41%] [G loss: 0.947531]\n",
      "epoch:28 step:27147 [D loss: 0.295204, acc.: 94.53%] [G loss: 1.424130]\n",
      "epoch:28 step:27148 [D loss: 0.147027, acc.: 99.22%] [G loss: 1.471057]\n",
      "epoch:28 step:27149 [D loss: 1.149463, acc.: 41.41%] [G loss: 1.496024]\n",
      "epoch:28 step:27150 [D loss: 0.836690, acc.: 45.31%] [G loss: 1.207256]\n",
      "epoch:28 step:27151 [D loss: 0.734744, acc.: 56.25%] [G loss: 0.955087]\n",
      "epoch:28 step:27152 [D loss: 0.480712, acc.: 80.47%] [G loss: 1.146729]\n",
      "epoch:28 step:27153 [D loss: 0.388975, acc.: 88.28%] [G loss: 1.024575]\n",
      "epoch:28 step:27154 [D loss: 0.528227, acc.: 78.91%] [G loss: 1.119721]\n",
      "epoch:28 step:27155 [D loss: 0.557599, acc.: 72.66%] [G loss: 1.312656]\n",
      "epoch:28 step:27156 [D loss: 0.318676, acc.: 89.84%] [G loss: 1.543433]\n",
      "epoch:28 step:27157 [D loss: 0.252783, acc.: 96.09%] [G loss: 1.709908]\n",
      "epoch:28 step:27158 [D loss: 0.616859, acc.: 66.41%] [G loss: 1.572093]\n",
      "epoch:28 step:27159 [D loss: 0.563121, acc.: 70.31%] [G loss: 1.156465]\n",
      "epoch:28 step:27160 [D loss: 0.516489, acc.: 78.12%] [G loss: 1.478141]\n",
      "epoch:28 step:27161 [D loss: 0.376994, acc.: 86.72%] [G loss: 1.561463]\n",
      "epoch:28 step:27162 [D loss: 0.368609, acc.: 85.94%] [G loss: 1.279255]\n",
      "epoch:28 step:27163 [D loss: 0.283685, acc.: 92.97%] [G loss: 1.502055]\n",
      "epoch:28 step:27164 [D loss: 1.049562, acc.: 49.22%] [G loss: 1.576283]\n",
      "epoch:28 step:27165 [D loss: 0.303389, acc.: 92.19%] [G loss: 1.665751]\n",
      "epoch:28 step:27166 [D loss: 0.721410, acc.: 49.22%] [G loss: 1.131420]\n",
      "epoch:28 step:27167 [D loss: 0.707181, acc.: 53.91%] [G loss: 1.562043]\n",
      "epoch:28 step:27168 [D loss: 0.600715, acc.: 65.62%] [G loss: 1.227159]\n",
      "epoch:28 step:27169 [D loss: 0.474522, acc.: 78.12%] [G loss: 1.398122]\n",
      "epoch:28 step:27170 [D loss: 0.293943, acc.: 89.84%] [G loss: 1.324333]\n",
      "epoch:28 step:27171 [D loss: 0.471273, acc.: 80.47%] [G loss: 1.482467]\n",
      "epoch:28 step:27172 [D loss: 0.448567, acc.: 82.03%] [G loss: 1.323925]\n",
      "epoch:28 step:27173 [D loss: 0.132958, acc.: 100.00%] [G loss: 1.404922]\n",
      "epoch:29 step:27174 [D loss: 0.749697, acc.: 56.25%] [G loss: 1.494505]\n",
      "epoch:29 step:27175 [D loss: 0.651694, acc.: 64.06%] [G loss: 1.523255]\n",
      "epoch:29 step:27176 [D loss: 0.592007, acc.: 65.62%] [G loss: 1.277293]\n",
      "epoch:29 step:27177 [D loss: 0.921529, acc.: 33.59%] [G loss: 1.006538]\n",
      "epoch:29 step:27178 [D loss: 0.659462, acc.: 57.81%] [G loss: 1.005529]\n",
      "epoch:29 step:27179 [D loss: 0.590536, acc.: 66.41%] [G loss: 1.337184]\n",
      "epoch:29 step:27180 [D loss: 0.758689, acc.: 50.78%] [G loss: 0.929590]\n",
      "epoch:29 step:27181 [D loss: 0.333290, acc.: 94.53%] [G loss: 1.140519]\n",
      "epoch:29 step:27182 [D loss: 0.312038, acc.: 91.41%] [G loss: 1.331629]\n",
      "epoch:29 step:27183 [D loss: 0.615828, acc.: 63.28%] [G loss: 1.087125]\n",
      "epoch:29 step:27184 [D loss: 0.508661, acc.: 77.34%] [G loss: 1.433110]\n",
      "epoch:29 step:27185 [D loss: 0.638205, acc.: 64.06%] [G loss: 1.659467]\n",
      "epoch:29 step:27186 [D loss: 0.750328, acc.: 57.03%] [G loss: 0.976609]\n",
      "epoch:29 step:27187 [D loss: 0.744026, acc.: 51.56%] [G loss: 1.030802]\n",
      "epoch:29 step:27188 [D loss: 0.372533, acc.: 87.50%] [G loss: 1.136466]\n",
      "epoch:29 step:27189 [D loss: 0.458334, acc.: 82.03%] [G loss: 1.152710]\n",
      "epoch:29 step:27190 [D loss: 0.661131, acc.: 59.38%] [G loss: 1.440870]\n",
      "epoch:29 step:27191 [D loss: 0.734541, acc.: 53.91%] [G loss: 1.362039]\n",
      "epoch:29 step:27192 [D loss: 0.797886, acc.: 41.41%] [G loss: 0.988754]\n",
      "epoch:29 step:27193 [D loss: 0.703671, acc.: 58.59%] [G loss: 0.908243]\n",
      "epoch:29 step:27194 [D loss: 0.602816, acc.: 65.62%] [G loss: 1.438399]\n",
      "epoch:29 step:27195 [D loss: 0.482086, acc.: 80.47%] [G loss: 1.352788]\n",
      "epoch:29 step:27196 [D loss: 0.541485, acc.: 67.97%] [G loss: 1.028481]\n",
      "epoch:29 step:27197 [D loss: 0.596614, acc.: 64.84%] [G loss: 1.111660]\n",
      "epoch:29 step:27198 [D loss: 0.857834, acc.: 43.75%] [G loss: 0.705575]\n",
      "epoch:29 step:27199 [D loss: 0.410851, acc.: 82.81%] [G loss: 1.129620]\n",
      "epoch:29 step:27200 [D loss: 0.237259, acc.: 95.31%] [G loss: 1.779524]\n",
      "epoch:29 step:27201 [D loss: 0.299168, acc.: 94.53%] [G loss: 1.410462]\n",
      "epoch:29 step:27202 [D loss: 0.390870, acc.: 85.94%] [G loss: 1.990916]\n",
      "epoch:29 step:27203 [D loss: 0.225317, acc.: 96.88%] [G loss: 1.825069]\n",
      "epoch:29 step:27204 [D loss: 0.258560, acc.: 96.09%] [G loss: 1.602209]\n",
      "epoch:29 step:27205 [D loss: 0.176748, acc.: 97.66%] [G loss: 1.931792]\n",
      "epoch:29 step:27206 [D loss: 0.236393, acc.: 95.31%] [G loss: 1.999305]\n",
      "epoch:29 step:27207 [D loss: 0.147512, acc.: 98.44%] [G loss: 2.534727]\n",
      "epoch:29 step:27208 [D loss: 0.285067, acc.: 89.06%] [G loss: 1.703509]\n",
      "epoch:29 step:27209 [D loss: 0.092730, acc.: 100.00%] [G loss: 2.450029]\n",
      "epoch:29 step:27210 [D loss: 0.916200, acc.: 51.56%] [G loss: 1.649950]\n",
      "epoch:29 step:27211 [D loss: 0.828524, acc.: 52.34%] [G loss: 1.103682]\n",
      "epoch:29 step:27212 [D loss: 0.705694, acc.: 60.94%] [G loss: 1.378423]\n",
      "epoch:29 step:27213 [D loss: 0.642995, acc.: 60.16%] [G loss: 1.028866]\n",
      "epoch:29 step:27214 [D loss: 0.425719, acc.: 86.72%] [G loss: 1.249069]\n",
      "epoch:29 step:27215 [D loss: 0.367568, acc.: 89.84%] [G loss: 0.912540]\n",
      "epoch:29 step:27216 [D loss: 0.441708, acc.: 83.59%] [G loss: 0.966358]\n",
      "epoch:29 step:27217 [D loss: 0.294594, acc.: 92.97%] [G loss: 1.672487]\n",
      "epoch:29 step:27218 [D loss: 0.551084, acc.: 70.31%] [G loss: 0.932601]\n",
      "epoch:29 step:27219 [D loss: 0.810935, acc.: 42.97%] [G loss: 1.077770]\n",
      "epoch:29 step:27220 [D loss: 0.517980, acc.: 71.09%] [G loss: 1.345505]\n",
      "epoch:29 step:27221 [D loss: 0.812218, acc.: 46.88%] [G loss: 0.948341]\n",
      "epoch:29 step:27222 [D loss: 0.720695, acc.: 57.03%] [G loss: 0.643520]\n",
      "epoch:29 step:27223 [D loss: 0.640353, acc.: 60.94%] [G loss: 1.261042]\n",
      "epoch:29 step:27224 [D loss: 0.695704, acc.: 57.03%] [G loss: 0.781928]\n",
      "epoch:29 step:27225 [D loss: 0.728630, acc.: 51.56%] [G loss: 1.074233]\n",
      "epoch:29 step:27226 [D loss: 0.694946, acc.: 60.16%] [G loss: 1.214973]\n",
      "epoch:29 step:27227 [D loss: 0.567469, acc.: 71.88%] [G loss: 0.928043]\n",
      "epoch:29 step:27228 [D loss: 0.555937, acc.: 71.88%] [G loss: 0.937785]\n",
      "epoch:29 step:27229 [D loss: 0.754555, acc.: 53.12%] [G loss: 1.083494]\n",
      "epoch:29 step:27230 [D loss: 0.696388, acc.: 60.16%] [G loss: 1.128591]\n",
      "epoch:29 step:27231 [D loss: 0.629218, acc.: 60.94%] [G loss: 0.988788]\n",
      "epoch:29 step:27232 [D loss: 0.650434, acc.: 60.94%] [G loss: 1.049945]\n",
      "epoch:29 step:27233 [D loss: 0.642824, acc.: 61.72%] [G loss: 1.313419]\n",
      "epoch:29 step:27234 [D loss: 0.704079, acc.: 53.91%] [G loss: 1.255197]\n",
      "epoch:29 step:27235 [D loss: 0.768550, acc.: 51.56%] [G loss: 1.091316]\n",
      "epoch:29 step:27236 [D loss: 0.708483, acc.: 58.59%] [G loss: 0.811722]\n",
      "epoch:29 step:27237 [D loss: 0.676201, acc.: 59.38%] [G loss: 1.200120]\n",
      "epoch:29 step:27238 [D loss: 0.922456, acc.: 36.72%] [G loss: 0.876578]\n",
      "epoch:29 step:27239 [D loss: 0.836284, acc.: 40.62%] [G loss: 0.858100]\n",
      "epoch:29 step:27240 [D loss: 0.610427, acc.: 64.06%] [G loss: 1.298561]\n",
      "epoch:29 step:27241 [D loss: 0.425850, acc.: 85.94%] [G loss: 1.262823]\n",
      "epoch:29 step:27242 [D loss: 0.354508, acc.: 89.84%] [G loss: 1.638803]\n",
      "epoch:29 step:27243 [D loss: 0.479666, acc.: 79.69%] [G loss: 1.404970]\n",
      "epoch:29 step:27244 [D loss: 0.518561, acc.: 75.00%] [G loss: 1.317377]\n",
      "epoch:29 step:27245 [D loss: 0.786475, acc.: 48.44%] [G loss: 0.985333]\n",
      "epoch:29 step:27246 [D loss: 0.668054, acc.: 58.59%] [G loss: 1.024002]\n",
      "epoch:29 step:27247 [D loss: 0.572021, acc.: 71.88%] [G loss: 1.065804]\n",
      "epoch:29 step:27248 [D loss: 0.383316, acc.: 85.16%] [G loss: 0.995999]\n",
      "epoch:29 step:27249 [D loss: 0.381768, acc.: 85.94%] [G loss: 1.273741]\n",
      "epoch:29 step:27250 [D loss: 0.461650, acc.: 85.16%] [G loss: 1.724259]\n",
      "epoch:29 step:27251 [D loss: 0.740134, acc.: 53.91%] [G loss: 1.296364]\n",
      "epoch:29 step:27252 [D loss: 0.701817, acc.: 55.47%] [G loss: 1.128840]\n",
      "epoch:29 step:27253 [D loss: 0.369416, acc.: 86.72%] [G loss: 1.223836]\n",
      "epoch:29 step:27254 [D loss: 0.455571, acc.: 81.25%] [G loss: 1.038827]\n",
      "epoch:29 step:27255 [D loss: 0.329021, acc.: 90.62%] [G loss: 1.381158]\n",
      "epoch:29 step:27256 [D loss: 0.263366, acc.: 97.66%] [G loss: 1.947109]\n",
      "epoch:29 step:27257 [D loss: 0.501303, acc.: 75.78%] [G loss: 1.627032]\n",
      "epoch:29 step:27258 [D loss: 0.563702, acc.: 74.22%] [G loss: 1.289124]\n",
      "epoch:29 step:27259 [D loss: 0.376104, acc.: 89.84%] [G loss: 1.401523]\n",
      "epoch:29 step:27260 [D loss: 0.349738, acc.: 85.16%] [G loss: 1.189426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27261 [D loss: 0.366367, acc.: 88.28%] [G loss: 1.480850]\n",
      "epoch:29 step:27262 [D loss: 0.446822, acc.: 80.47%] [G loss: 1.987815]\n",
      "epoch:29 step:27263 [D loss: 0.517849, acc.: 75.00%] [G loss: 1.433906]\n",
      "epoch:29 step:27264 [D loss: 0.481687, acc.: 80.47%] [G loss: 1.628363]\n",
      "epoch:29 step:27265 [D loss: 0.355214, acc.: 89.06%] [G loss: 1.424387]\n",
      "epoch:29 step:27266 [D loss: 0.355242, acc.: 90.62%] [G loss: 1.244039]\n",
      "epoch:29 step:27267 [D loss: 0.554427, acc.: 72.66%] [G loss: 1.677377]\n",
      "epoch:29 step:27268 [D loss: 1.276955, acc.: 12.50%] [G loss: 0.815248]\n",
      "epoch:29 step:27269 [D loss: 0.706329, acc.: 60.16%] [G loss: 0.828982]\n",
      "epoch:29 step:27270 [D loss: 0.700705, acc.: 57.81%] [G loss: 1.249253]\n",
      "epoch:29 step:27271 [D loss: 1.061276, acc.: 25.00%] [G loss: 1.179093]\n",
      "epoch:29 step:27272 [D loss: 0.902493, acc.: 35.94%] [G loss: 0.707788]\n",
      "epoch:29 step:27273 [D loss: 0.845081, acc.: 44.53%] [G loss: 0.800519]\n",
      "epoch:29 step:27274 [D loss: 0.762440, acc.: 54.69%] [G loss: 0.978749]\n",
      "epoch:29 step:27275 [D loss: 0.973556, acc.: 39.06%] [G loss: 1.104054]\n",
      "epoch:29 step:27276 [D loss: 1.120389, acc.: 17.97%] [G loss: 0.938666]\n",
      "epoch:29 step:27277 [D loss: 0.904461, acc.: 35.94%] [G loss: 0.969810]\n",
      "epoch:29 step:27278 [D loss: 0.771916, acc.: 53.12%] [G loss: 0.979860]\n",
      "epoch:29 step:27279 [D loss: 0.628911, acc.: 67.97%] [G loss: 1.119653]\n",
      "epoch:29 step:27280 [D loss: 0.677890, acc.: 55.47%] [G loss: 1.209646]\n",
      "epoch:29 step:27281 [D loss: 0.576575, acc.: 67.19%] [G loss: 1.298304]\n",
      "epoch:29 step:27282 [D loss: 0.647167, acc.: 66.41%] [G loss: 1.299645]\n",
      "epoch:29 step:27283 [D loss: 0.480290, acc.: 82.03%] [G loss: 1.018021]\n",
      "epoch:29 step:27284 [D loss: 0.472776, acc.: 80.47%] [G loss: 1.173990]\n",
      "epoch:29 step:27285 [D loss: 0.445247, acc.: 80.47%] [G loss: 1.416759]\n",
      "epoch:29 step:27286 [D loss: 0.658970, acc.: 65.62%] [G loss: 1.112964]\n",
      "epoch:29 step:27287 [D loss: 0.711112, acc.: 55.47%] [G loss: 0.962913]\n",
      "epoch:29 step:27288 [D loss: 0.676181, acc.: 57.81%] [G loss: 0.900496]\n",
      "epoch:29 step:27289 [D loss: 0.559122, acc.: 71.09%] [G loss: 1.409396]\n",
      "epoch:29 step:27290 [D loss: 0.297005, acc.: 91.41%] [G loss: 1.796197]\n",
      "epoch:29 step:27291 [D loss: 0.195630, acc.: 97.66%] [G loss: 1.966975]\n",
      "epoch:29 step:27292 [D loss: 0.220737, acc.: 97.66%] [G loss: 2.042032]\n",
      "epoch:29 step:27293 [D loss: 0.988949, acc.: 48.44%] [G loss: 1.430966]\n",
      "epoch:29 step:27294 [D loss: 0.636160, acc.: 64.84%] [G loss: 1.401020]\n",
      "epoch:29 step:27295 [D loss: 0.377702, acc.: 89.06%] [G loss: 1.045195]\n",
      "epoch:29 step:27296 [D loss: 0.487740, acc.: 78.12%] [G loss: 1.374088]\n",
      "epoch:29 step:27297 [D loss: 0.301584, acc.: 91.41%] [G loss: 1.598110]\n",
      "epoch:29 step:27298 [D loss: 0.373884, acc.: 85.16%] [G loss: 1.622442]\n",
      "epoch:29 step:27299 [D loss: 0.287459, acc.: 96.09%] [G loss: 1.463331]\n",
      "epoch:29 step:27300 [D loss: 0.313791, acc.: 96.09%] [G loss: 1.598520]\n",
      "epoch:29 step:27301 [D loss: 0.488096, acc.: 79.69%] [G loss: 1.390227]\n",
      "epoch:29 step:27302 [D loss: 0.772003, acc.: 53.91%] [G loss: 1.298362]\n",
      "epoch:29 step:27303 [D loss: 0.553499, acc.: 70.31%] [G loss: 1.131943]\n",
      "epoch:29 step:27304 [D loss: 0.565561, acc.: 69.53%] [G loss: 1.219650]\n",
      "epoch:29 step:27305 [D loss: 0.658398, acc.: 54.69%] [G loss: 0.924121]\n",
      "epoch:29 step:27306 [D loss: 0.318917, acc.: 89.06%] [G loss: 1.326976]\n",
      "epoch:29 step:27307 [D loss: 0.347321, acc.: 89.06%] [G loss: 1.684305]\n",
      "epoch:29 step:27308 [D loss: 0.225655, acc.: 99.22%] [G loss: 1.516532]\n",
      "epoch:29 step:27309 [D loss: 0.544625, acc.: 73.44%] [G loss: 1.363014]\n",
      "epoch:29 step:27310 [D loss: 0.798342, acc.: 48.44%] [G loss: 1.057385]\n",
      "epoch:29 step:27311 [D loss: 0.875651, acc.: 47.66%] [G loss: 0.724150]\n",
      "epoch:29 step:27312 [D loss: 0.775918, acc.: 49.22%] [G loss: 0.889490]\n",
      "epoch:29 step:27313 [D loss: 0.479441, acc.: 75.78%] [G loss: 1.088379]\n",
      "epoch:29 step:27314 [D loss: 0.362745, acc.: 90.62%] [G loss: 1.202514]\n",
      "epoch:29 step:27315 [D loss: 0.336125, acc.: 90.62%] [G loss: 1.404573]\n",
      "epoch:29 step:27316 [D loss: 0.239226, acc.: 98.44%] [G loss: 2.194244]\n",
      "epoch:29 step:27317 [D loss: 0.408067, acc.: 89.84%] [G loss: 1.443968]\n",
      "epoch:29 step:27318 [D loss: 0.214537, acc.: 97.66%] [G loss: 1.820494]\n",
      "epoch:29 step:27319 [D loss: 0.506337, acc.: 77.34%] [G loss: 1.696364]\n",
      "epoch:29 step:27320 [D loss: 0.738092, acc.: 53.91%] [G loss: 0.837564]\n",
      "epoch:29 step:27321 [D loss: 0.954397, acc.: 36.72%] [G loss: 1.171051]\n",
      "epoch:29 step:27322 [D loss: 0.552191, acc.: 67.19%] [G loss: 1.336701]\n",
      "epoch:29 step:27323 [D loss: 0.311100, acc.: 89.84%] [G loss: 1.830925]\n",
      "epoch:29 step:27324 [D loss: 0.207341, acc.: 97.66%] [G loss: 2.423141]\n",
      "epoch:29 step:27325 [D loss: 0.359623, acc.: 86.72%] [G loss: 1.490617]\n",
      "epoch:29 step:27326 [D loss: 0.970154, acc.: 53.12%] [G loss: 1.448153]\n",
      "epoch:29 step:27327 [D loss: 0.929792, acc.: 35.16%] [G loss: 0.746415]\n",
      "epoch:29 step:27328 [D loss: 0.689350, acc.: 57.03%] [G loss: 1.217831]\n",
      "epoch:29 step:27329 [D loss: 0.999365, acc.: 32.03%] [G loss: 0.716354]\n",
      "epoch:29 step:27330 [D loss: 1.151055, acc.: 21.09%] [G loss: 1.199990]\n",
      "epoch:29 step:27331 [D loss: 0.936144, acc.: 38.28%] [G loss: 0.895511]\n",
      "epoch:29 step:27332 [D loss: 0.623692, acc.: 67.97%] [G loss: 1.274039]\n",
      "epoch:29 step:27333 [D loss: 1.310829, acc.: 14.84%] [G loss: 0.946593]\n",
      "epoch:29 step:27334 [D loss: 1.078004, acc.: 23.44%] [G loss: 0.902265]\n",
      "epoch:29 step:27335 [D loss: 0.692090, acc.: 60.16%] [G loss: 1.298821]\n",
      "epoch:29 step:27336 [D loss: 0.524190, acc.: 73.44%] [G loss: 1.561516]\n",
      "epoch:29 step:27337 [D loss: 0.669801, acc.: 57.03%] [G loss: 1.268152]\n",
      "epoch:29 step:27338 [D loss: 0.480808, acc.: 82.03%] [G loss: 1.282669]\n",
      "epoch:29 step:27339 [D loss: 0.484890, acc.: 80.47%] [G loss: 0.978427]\n",
      "epoch:29 step:27340 [D loss: 0.419164, acc.: 81.25%] [G loss: 1.222466]\n",
      "epoch:29 step:27341 [D loss: 0.373727, acc.: 89.06%] [G loss: 1.406829]\n",
      "epoch:29 step:27342 [D loss: 0.455441, acc.: 78.12%] [G loss: 1.378737]\n",
      "epoch:29 step:27343 [D loss: 0.587265, acc.: 71.88%] [G loss: 1.271232]\n",
      "epoch:29 step:27344 [D loss: 0.547881, acc.: 75.78%] [G loss: 1.149827]\n",
      "epoch:29 step:27345 [D loss: 0.428114, acc.: 83.59%] [G loss: 1.300753]\n",
      "epoch:29 step:27346 [D loss: 0.349157, acc.: 94.53%] [G loss: 1.525306]\n",
      "epoch:29 step:27347 [D loss: 0.678221, acc.: 57.03%] [G loss: 1.239392]\n",
      "epoch:29 step:27348 [D loss: 0.573629, acc.: 68.75%] [G loss: 1.132782]\n",
      "epoch:29 step:27349 [D loss: 0.519650, acc.: 76.56%] [G loss: 1.291881]\n",
      "epoch:29 step:27350 [D loss: 0.732124, acc.: 54.69%] [G loss: 1.187115]\n",
      "epoch:29 step:27351 [D loss: 0.530317, acc.: 75.00%] [G loss: 1.012553]\n",
      "epoch:29 step:27352 [D loss: 0.574064, acc.: 72.66%] [G loss: 1.132247]\n",
      "epoch:29 step:27353 [D loss: 0.532410, acc.: 73.44%] [G loss: 1.380764]\n",
      "epoch:29 step:27354 [D loss: 0.332522, acc.: 94.53%] [G loss: 1.436681]\n",
      "epoch:29 step:27355 [D loss: 0.224577, acc.: 96.09%] [G loss: 1.575821]\n",
      "epoch:29 step:27356 [D loss: 0.429488, acc.: 82.81%] [G loss: 1.192249]\n",
      "epoch:29 step:27357 [D loss: 0.633774, acc.: 65.62%] [G loss: 0.877213]\n",
      "epoch:29 step:27358 [D loss: 0.945224, acc.: 42.97%] [G loss: 1.501017]\n",
      "epoch:29 step:27359 [D loss: 1.289994, acc.: 14.06%] [G loss: 0.892044]\n",
      "epoch:29 step:27360 [D loss: 0.621372, acc.: 68.75%] [G loss: 1.017269]\n",
      "epoch:29 step:27361 [D loss: 0.679526, acc.: 60.16%] [G loss: 1.202677]\n",
      "epoch:29 step:27362 [D loss: 0.841219, acc.: 45.31%] [G loss: 1.221026]\n",
      "epoch:29 step:27363 [D loss: 0.808154, acc.: 47.66%] [G loss: 1.251534]\n",
      "epoch:29 step:27364 [D loss: 0.769807, acc.: 46.88%] [G loss: 0.966421]\n",
      "epoch:29 step:27365 [D loss: 0.261609, acc.: 94.53%] [G loss: 1.664590]\n",
      "epoch:29 step:27366 [D loss: 0.832287, acc.: 43.75%] [G loss: 1.403944]\n",
      "epoch:29 step:27367 [D loss: 0.362930, acc.: 88.28%] [G loss: 1.628589]\n",
      "epoch:29 step:27368 [D loss: 0.514448, acc.: 75.00%] [G loss: 1.322501]\n",
      "epoch:29 step:27369 [D loss: 1.064162, acc.: 23.44%] [G loss: 0.816069]\n",
      "epoch:29 step:27370 [D loss: 0.574366, acc.: 72.66%] [G loss: 1.366629]\n",
      "epoch:29 step:27371 [D loss: 0.904998, acc.: 31.25%] [G loss: 0.914389]\n",
      "epoch:29 step:27372 [D loss: 1.051382, acc.: 28.12%] [G loss: 0.859690]\n",
      "epoch:29 step:27373 [D loss: 1.206429, acc.: 21.09%] [G loss: 0.854546]\n",
      "epoch:29 step:27374 [D loss: 0.835103, acc.: 41.41%] [G loss: 1.370914]\n",
      "epoch:29 step:27375 [D loss: 0.724212, acc.: 60.94%] [G loss: 1.135499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27376 [D loss: 0.633253, acc.: 62.50%] [G loss: 1.223690]\n",
      "epoch:29 step:27377 [D loss: 0.538825, acc.: 72.66%] [G loss: 1.113854]\n",
      "epoch:29 step:27378 [D loss: 0.663958, acc.: 63.28%] [G loss: 0.849842]\n",
      "epoch:29 step:27379 [D loss: 0.528826, acc.: 73.44%] [G loss: 1.447202]\n",
      "epoch:29 step:27380 [D loss: 0.414807, acc.: 87.50%] [G loss: 1.467810]\n",
      "epoch:29 step:27381 [D loss: 0.747744, acc.: 51.56%] [G loss: 1.010054]\n",
      "epoch:29 step:27382 [D loss: 0.356158, acc.: 86.72%] [G loss: 1.248581]\n",
      "epoch:29 step:27383 [D loss: 0.761924, acc.: 50.78%] [G loss: 1.346067]\n",
      "epoch:29 step:27384 [D loss: 1.052507, acc.: 28.91%] [G loss: 0.678126]\n",
      "epoch:29 step:27385 [D loss: 0.760997, acc.: 52.34%] [G loss: 1.134878]\n",
      "epoch:29 step:27386 [D loss: 0.292332, acc.: 93.75%] [G loss: 1.841553]\n",
      "epoch:29 step:27387 [D loss: 0.574340, acc.: 70.31%] [G loss: 1.415167]\n",
      "epoch:29 step:27388 [D loss: 0.388004, acc.: 89.06%] [G loss: 1.340533]\n",
      "epoch:29 step:27389 [D loss: 0.539004, acc.: 75.00%] [G loss: 1.274379]\n",
      "epoch:29 step:27390 [D loss: 0.630385, acc.: 64.06%] [G loss: 1.122964]\n",
      "epoch:29 step:27391 [D loss: 0.631018, acc.: 63.28%] [G loss: 0.999075]\n",
      "epoch:29 step:27392 [D loss: 0.625348, acc.: 64.06%] [G loss: 1.065889]\n",
      "epoch:29 step:27393 [D loss: 0.283660, acc.: 88.28%] [G loss: 1.765030]\n",
      "epoch:29 step:27394 [D loss: 0.230232, acc.: 94.53%] [G loss: 1.956887]\n",
      "epoch:29 step:27395 [D loss: 0.196503, acc.: 97.66%] [G loss: 2.466817]\n",
      "epoch:29 step:27396 [D loss: 0.129196, acc.: 99.22%] [G loss: 2.490335]\n",
      "epoch:29 step:27397 [D loss: 0.787265, acc.: 55.47%] [G loss: 1.741130]\n",
      "epoch:29 step:27398 [D loss: 0.586061, acc.: 67.97%] [G loss: 1.122474]\n",
      "epoch:29 step:27399 [D loss: 0.411814, acc.: 78.91%] [G loss: 1.186857]\n",
      "epoch:29 step:27400 [D loss: 0.347258, acc.: 94.53%] [G loss: 1.651393]\n",
      "epoch:29 step:27401 [D loss: 0.395064, acc.: 87.50%] [G loss: 1.459717]\n",
      "epoch:29 step:27402 [D loss: 0.309856, acc.: 92.97%] [G loss: 1.755639]\n",
      "epoch:29 step:27403 [D loss: 0.120259, acc.: 99.22%] [G loss: 2.151610]\n",
      "epoch:29 step:27404 [D loss: 0.129427, acc.: 99.22%] [G loss: 2.132900]\n",
      "epoch:29 step:27405 [D loss: 0.152533, acc.: 96.88%] [G loss: 2.262351]\n",
      "epoch:29 step:27406 [D loss: 0.501389, acc.: 75.00%] [G loss: 1.810972]\n",
      "epoch:29 step:27407 [D loss: 0.431722, acc.: 82.81%] [G loss: 1.198255]\n",
      "epoch:29 step:27408 [D loss: 0.244002, acc.: 92.97%] [G loss: 1.427866]\n",
      "epoch:29 step:27409 [D loss: 0.401281, acc.: 83.59%] [G loss: 1.431664]\n",
      "epoch:29 step:27410 [D loss: 0.360293, acc.: 92.97%] [G loss: 1.402067]\n",
      "epoch:29 step:27411 [D loss: 0.617107, acc.: 71.09%] [G loss: 1.196884]\n",
      "epoch:29 step:27412 [D loss: 0.507287, acc.: 75.78%] [G loss: 1.802846]\n",
      "epoch:29 step:27413 [D loss: 0.628999, acc.: 64.06%] [G loss: 1.156608]\n",
      "epoch:29 step:27414 [D loss: 1.436390, acc.: 11.72%] [G loss: 0.951865]\n",
      "epoch:29 step:27415 [D loss: 0.853793, acc.: 49.22%] [G loss: 0.710299]\n",
      "epoch:29 step:27416 [D loss: 0.813771, acc.: 56.25%] [G loss: 1.001431]\n",
      "epoch:29 step:27417 [D loss: 1.091006, acc.: 32.03%] [G loss: 1.373096]\n",
      "epoch:29 step:27418 [D loss: 0.728256, acc.: 50.00%] [G loss: 1.287212]\n",
      "epoch:29 step:27419 [D loss: 1.089584, acc.: 28.91%] [G loss: 1.052675]\n",
      "epoch:29 step:27420 [D loss: 0.664188, acc.: 59.38%] [G loss: 0.970525]\n",
      "epoch:29 step:27421 [D loss: 0.743948, acc.: 46.09%] [G loss: 0.964601]\n",
      "epoch:29 step:27422 [D loss: 0.766603, acc.: 51.56%] [G loss: 1.144002]\n",
      "epoch:29 step:27423 [D loss: 0.842485, acc.: 41.41%] [G loss: 0.960386]\n",
      "epoch:29 step:27424 [D loss: 0.756501, acc.: 54.69%] [G loss: 1.065118]\n",
      "epoch:29 step:27425 [D loss: 0.763158, acc.: 52.34%] [G loss: 1.152925]\n",
      "epoch:29 step:27426 [D loss: 0.627481, acc.: 62.50%] [G loss: 0.986313]\n",
      "epoch:29 step:27427 [D loss: 0.559446, acc.: 71.88%] [G loss: 1.126117]\n",
      "epoch:29 step:27428 [D loss: 0.547418, acc.: 70.31%] [G loss: 1.134985]\n",
      "epoch:29 step:27429 [D loss: 0.468237, acc.: 80.47%] [G loss: 1.179592]\n",
      "epoch:29 step:27430 [D loss: 0.691679, acc.: 58.59%] [G loss: 0.819470]\n",
      "epoch:29 step:27431 [D loss: 0.541418, acc.: 73.44%] [G loss: 1.317207]\n",
      "epoch:29 step:27432 [D loss: 0.397594, acc.: 84.38%] [G loss: 0.978826]\n",
      "epoch:29 step:27433 [D loss: 0.417897, acc.: 82.03%] [G loss: 1.531610]\n",
      "epoch:29 step:27434 [D loss: 0.361495, acc.: 91.41%] [G loss: 1.437768]\n",
      "epoch:29 step:27435 [D loss: 0.707859, acc.: 59.38%] [G loss: 1.533076]\n",
      "epoch:29 step:27436 [D loss: 0.732742, acc.: 53.91%] [G loss: 1.192084]\n",
      "epoch:29 step:27437 [D loss: 0.618690, acc.: 66.41%] [G loss: 1.043970]\n",
      "epoch:29 step:27438 [D loss: 0.728692, acc.: 59.38%] [G loss: 1.359437]\n",
      "epoch:29 step:27439 [D loss: 0.692579, acc.: 51.56%] [G loss: 1.269905]\n",
      "epoch:29 step:27440 [D loss: 0.746701, acc.: 50.78%] [G loss: 0.895128]\n",
      "epoch:29 step:27441 [D loss: 0.834003, acc.: 48.44%] [G loss: 0.879733]\n",
      "epoch:29 step:27442 [D loss: 0.659706, acc.: 62.50%] [G loss: 1.121891]\n",
      "epoch:29 step:27443 [D loss: 0.732887, acc.: 53.91%] [G loss: 1.244720]\n",
      "epoch:29 step:27444 [D loss: 0.506371, acc.: 80.47%] [G loss: 1.362464]\n",
      "epoch:29 step:27445 [D loss: 0.387967, acc.: 86.72%] [G loss: 1.333683]\n",
      "epoch:29 step:27446 [D loss: 0.557531, acc.: 71.88%] [G loss: 1.226877]\n",
      "epoch:29 step:27447 [D loss: 0.529732, acc.: 75.78%] [G loss: 1.300282]\n",
      "epoch:29 step:27448 [D loss: 0.495367, acc.: 76.56%] [G loss: 1.416809]\n",
      "epoch:29 step:27449 [D loss: 0.631585, acc.: 59.38%] [G loss: 1.180411]\n",
      "epoch:29 step:27450 [D loss: 0.819282, acc.: 42.97%] [G loss: 0.858117]\n",
      "epoch:29 step:27451 [D loss: 0.750545, acc.: 51.56%] [G loss: 1.164924]\n",
      "epoch:29 step:27452 [D loss: 0.687432, acc.: 61.72%] [G loss: 0.834073]\n",
      "epoch:29 step:27453 [D loss: 0.637861, acc.: 65.62%] [G loss: 1.045939]\n",
      "epoch:29 step:27454 [D loss: 0.695799, acc.: 54.69%] [G loss: 1.341614]\n",
      "epoch:29 step:27455 [D loss: 0.570718, acc.: 69.53%] [G loss: 1.301466]\n",
      "epoch:29 step:27456 [D loss: 0.646216, acc.: 63.28%] [G loss: 1.021502]\n",
      "epoch:29 step:27457 [D loss: 0.568498, acc.: 70.31%] [G loss: 1.196165]\n",
      "epoch:29 step:27458 [D loss: 0.677376, acc.: 60.16%] [G loss: 1.182153]\n",
      "epoch:29 step:27459 [D loss: 0.636416, acc.: 60.16%] [G loss: 1.029414]\n",
      "epoch:29 step:27460 [D loss: 0.606635, acc.: 66.41%] [G loss: 1.105912]\n",
      "epoch:29 step:27461 [D loss: 0.682213, acc.: 61.72%] [G loss: 1.205447]\n",
      "epoch:29 step:27462 [D loss: 0.562288, acc.: 69.53%] [G loss: 1.228575]\n",
      "epoch:29 step:27463 [D loss: 0.676080, acc.: 59.38%] [G loss: 1.039099]\n",
      "epoch:29 step:27464 [D loss: 0.437424, acc.: 82.81%] [G loss: 1.320765]\n",
      "epoch:29 step:27465 [D loss: 0.530308, acc.: 72.66%] [G loss: 1.211424]\n",
      "epoch:29 step:27466 [D loss: 0.567125, acc.: 71.88%] [G loss: 0.983583]\n",
      "epoch:29 step:27467 [D loss: 0.634071, acc.: 63.28%] [G loss: 1.227906]\n",
      "epoch:29 step:27468 [D loss: 0.938858, acc.: 30.47%] [G loss: 0.843594]\n",
      "epoch:29 step:27469 [D loss: 0.645498, acc.: 67.19%] [G loss: 1.418758]\n",
      "epoch:29 step:27470 [D loss: 0.575302, acc.: 70.31%] [G loss: 0.956247]\n",
      "epoch:29 step:27471 [D loss: 0.267483, acc.: 96.88%] [G loss: 1.577427]\n",
      "epoch:29 step:27472 [D loss: 0.516668, acc.: 74.22%] [G loss: 1.440019]\n",
      "epoch:29 step:27473 [D loss: 0.591894, acc.: 70.31%] [G loss: 1.251682]\n",
      "epoch:29 step:27474 [D loss: 0.696548, acc.: 57.03%] [G loss: 1.132967]\n",
      "epoch:29 step:27475 [D loss: 0.869789, acc.: 52.34%] [G loss: 0.927337]\n",
      "epoch:29 step:27476 [D loss: 0.527564, acc.: 76.56%] [G loss: 1.260951]\n",
      "epoch:29 step:27477 [D loss: 0.605539, acc.: 67.19%] [G loss: 1.147365]\n",
      "epoch:29 step:27478 [D loss: 0.607056, acc.: 67.97%] [G loss: 1.123637]\n",
      "epoch:29 step:27479 [D loss: 0.603407, acc.: 67.19%] [G loss: 0.822025]\n",
      "epoch:29 step:27480 [D loss: 0.616919, acc.: 67.97%] [G loss: 1.254681]\n",
      "epoch:29 step:27481 [D loss: 0.542064, acc.: 74.22%] [G loss: 1.243472]\n",
      "epoch:29 step:27482 [D loss: 0.435863, acc.: 85.94%] [G loss: 1.262524]\n",
      "epoch:29 step:27483 [D loss: 0.655377, acc.: 59.38%] [G loss: 1.315096]\n",
      "epoch:29 step:27484 [D loss: 0.534789, acc.: 75.78%] [G loss: 1.278686]\n",
      "epoch:29 step:27485 [D loss: 0.354318, acc.: 92.19%] [G loss: 1.256176]\n",
      "epoch:29 step:27486 [D loss: 0.365797, acc.: 88.28%] [G loss: 1.551203]\n",
      "epoch:29 step:27487 [D loss: 0.357641, acc.: 87.50%] [G loss: 1.355415]\n",
      "epoch:29 step:27488 [D loss: 0.452833, acc.: 77.34%] [G loss: 1.664924]\n",
      "epoch:29 step:27489 [D loss: 0.829308, acc.: 45.31%] [G loss: 1.139531]\n",
      "epoch:29 step:27490 [D loss: 0.994337, acc.: 30.47%] [G loss: 1.026130]\n",
      "epoch:29 step:27491 [D loss: 0.395644, acc.: 89.84%] [G loss: 1.063205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27492 [D loss: 0.577022, acc.: 70.31%] [G loss: 1.230410]\n",
      "epoch:29 step:27493 [D loss: 0.604163, acc.: 68.75%] [G loss: 1.207047]\n",
      "epoch:29 step:27494 [D loss: 0.398072, acc.: 87.50%] [G loss: 1.236622]\n",
      "epoch:29 step:27495 [D loss: 0.427032, acc.: 86.72%] [G loss: 1.213812]\n",
      "epoch:29 step:27496 [D loss: 0.694443, acc.: 59.38%] [G loss: 1.175854]\n",
      "epoch:29 step:27497 [D loss: 0.644010, acc.: 61.72%] [G loss: 1.129954]\n",
      "epoch:29 step:27498 [D loss: 0.605515, acc.: 67.19%] [G loss: 0.991802]\n",
      "epoch:29 step:27499 [D loss: 0.488711, acc.: 81.25%] [G loss: 1.044174]\n",
      "epoch:29 step:27500 [D loss: 0.312775, acc.: 89.84%] [G loss: 1.182019]\n",
      "epoch:29 step:27501 [D loss: 0.304470, acc.: 94.53%] [G loss: 1.452440]\n",
      "epoch:29 step:27502 [D loss: 0.674101, acc.: 60.16%] [G loss: 1.458402]\n",
      "epoch:29 step:27503 [D loss: 0.662047, acc.: 62.50%] [G loss: 1.357719]\n",
      "epoch:29 step:27504 [D loss: 0.743482, acc.: 49.22%] [G loss: 1.262940]\n",
      "epoch:29 step:27505 [D loss: 0.707360, acc.: 50.00%] [G loss: 0.819695]\n",
      "epoch:29 step:27506 [D loss: 0.679017, acc.: 53.91%] [G loss: 0.715714]\n",
      "epoch:29 step:27507 [D loss: 0.717086, acc.: 57.03%] [G loss: 0.900637]\n",
      "epoch:29 step:27508 [D loss: 0.632795, acc.: 66.41%] [G loss: 0.874434]\n",
      "epoch:29 step:27509 [D loss: 0.649603, acc.: 61.72%] [G loss: 0.941633]\n",
      "epoch:29 step:27510 [D loss: 0.657496, acc.: 62.50%] [G loss: 1.028798]\n",
      "epoch:29 step:27511 [D loss: 0.652966, acc.: 64.06%] [G loss: 0.958904]\n",
      "epoch:29 step:27512 [D loss: 0.650934, acc.: 64.06%] [G loss: 0.861640]\n",
      "epoch:29 step:27513 [D loss: 0.723729, acc.: 55.47%] [G loss: 0.883895]\n",
      "epoch:29 step:27514 [D loss: 0.704816, acc.: 58.59%] [G loss: 1.069709]\n",
      "epoch:29 step:27515 [D loss: 0.357324, acc.: 89.84%] [G loss: 1.305663]\n",
      "epoch:29 step:27516 [D loss: 0.270684, acc.: 96.09%] [G loss: 1.508707]\n",
      "epoch:29 step:27517 [D loss: 0.316506, acc.: 93.75%] [G loss: 1.861272]\n",
      "epoch:29 step:27518 [D loss: 0.245512, acc.: 98.44%] [G loss: 1.890671]\n",
      "epoch:29 step:27519 [D loss: 0.145451, acc.: 100.00%] [G loss: 1.590868]\n",
      "epoch:29 step:27520 [D loss: 0.244012, acc.: 96.09%] [G loss: 1.729793]\n",
      "epoch:29 step:27521 [D loss: 0.895079, acc.: 50.78%] [G loss: 1.752074]\n",
      "epoch:29 step:27522 [D loss: 0.795830, acc.: 49.22%] [G loss: 0.976715]\n",
      "epoch:29 step:27523 [D loss: 0.738286, acc.: 51.56%] [G loss: 0.893047]\n",
      "epoch:29 step:27524 [D loss: 0.636741, acc.: 60.94%] [G loss: 1.144615]\n",
      "epoch:29 step:27525 [D loss: 0.319889, acc.: 92.97%] [G loss: 1.426235]\n",
      "epoch:29 step:27526 [D loss: 0.397447, acc.: 85.16%] [G loss: 1.321385]\n",
      "epoch:29 step:27527 [D loss: 0.372038, acc.: 92.19%] [G loss: 1.227199]\n",
      "epoch:29 step:27528 [D loss: 0.702500, acc.: 57.03%] [G loss: 1.222032]\n",
      "epoch:29 step:27529 [D loss: 0.634609, acc.: 66.41%] [G loss: 1.011331]\n",
      "epoch:29 step:27530 [D loss: 0.470773, acc.: 81.25%] [G loss: 1.280535]\n",
      "epoch:29 step:27531 [D loss: 0.386422, acc.: 81.25%] [G loss: 1.194453]\n",
      "epoch:29 step:27532 [D loss: 0.426425, acc.: 85.94%] [G loss: 0.919867]\n",
      "epoch:29 step:27533 [D loss: 0.544514, acc.: 74.22%] [G loss: 1.082810]\n",
      "epoch:29 step:27534 [D loss: 0.707945, acc.: 57.81%] [G loss: 1.172858]\n",
      "epoch:29 step:27535 [D loss: 0.687573, acc.: 59.38%] [G loss: 1.166781]\n",
      "epoch:29 step:27536 [D loss: 0.594593, acc.: 71.88%] [G loss: 1.045027]\n",
      "epoch:29 step:27537 [D loss: 0.628611, acc.: 67.97%] [G loss: 1.013758]\n",
      "epoch:29 step:27538 [D loss: 0.544524, acc.: 75.78%] [G loss: 1.158920]\n",
      "epoch:29 step:27539 [D loss: 0.368739, acc.: 84.38%] [G loss: 1.369978]\n",
      "epoch:29 step:27540 [D loss: 0.322061, acc.: 94.53%] [G loss: 1.204114]\n",
      "epoch:29 step:27541 [D loss: 0.621822, acc.: 64.84%] [G loss: 1.401427]\n",
      "epoch:29 step:27542 [D loss: 0.623195, acc.: 63.28%] [G loss: 1.551737]\n",
      "epoch:29 step:27543 [D loss: 0.519569, acc.: 77.34%] [G loss: 1.052229]\n",
      "epoch:29 step:27544 [D loss: 0.461265, acc.: 82.81%] [G loss: 1.379249]\n",
      "epoch:29 step:27545 [D loss: 0.746216, acc.: 54.69%] [G loss: 0.950032]\n",
      "epoch:29 step:27546 [D loss: 0.651893, acc.: 57.81%] [G loss: 1.105793]\n",
      "epoch:29 step:27547 [D loss: 0.789205, acc.: 46.09%] [G loss: 0.963009]\n",
      "epoch:29 step:27548 [D loss: 0.767253, acc.: 45.31%] [G loss: 0.899635]\n",
      "epoch:29 step:27549 [D loss: 0.778993, acc.: 50.78%] [G loss: 1.016774]\n",
      "epoch:29 step:27550 [D loss: 0.664252, acc.: 59.38%] [G loss: 0.868515]\n",
      "epoch:29 step:27551 [D loss: 0.351513, acc.: 85.94%] [G loss: 1.399924]\n",
      "epoch:29 step:27552 [D loss: 0.674452, acc.: 55.47%] [G loss: 1.089453]\n",
      "epoch:29 step:27553 [D loss: 0.568865, acc.: 71.09%] [G loss: 1.119952]\n",
      "epoch:29 step:27554 [D loss: 0.655424, acc.: 60.16%] [G loss: 1.172245]\n",
      "epoch:29 step:27555 [D loss: 0.510441, acc.: 80.47%] [G loss: 1.256485]\n",
      "epoch:29 step:27556 [D loss: 0.450302, acc.: 84.38%] [G loss: 1.366391]\n",
      "epoch:29 step:27557 [D loss: 0.447133, acc.: 87.50%] [G loss: 1.417712]\n",
      "epoch:29 step:27558 [D loss: 0.758356, acc.: 54.69%] [G loss: 0.613667]\n",
      "epoch:29 step:27559 [D loss: 0.620991, acc.: 63.28%] [G loss: 1.026790]\n",
      "epoch:29 step:27560 [D loss: 0.693853, acc.: 60.94%] [G loss: 1.323414]\n",
      "epoch:29 step:27561 [D loss: 0.616213, acc.: 67.97%] [G loss: 0.927304]\n",
      "epoch:29 step:27562 [D loss: 0.504410, acc.: 78.91%] [G loss: 1.156530]\n",
      "epoch:29 step:27563 [D loss: 0.321787, acc.: 92.97%] [G loss: 1.174276]\n",
      "epoch:29 step:27564 [D loss: 0.489861, acc.: 78.12%] [G loss: 1.273300]\n",
      "epoch:29 step:27565 [D loss: 0.461377, acc.: 81.25%] [G loss: 1.239397]\n",
      "epoch:29 step:27566 [D loss: 0.785515, acc.: 51.56%] [G loss: 0.819210]\n",
      "epoch:29 step:27567 [D loss: 0.371842, acc.: 86.72%] [G loss: 1.850792]\n",
      "epoch:29 step:27568 [D loss: 0.653284, acc.: 57.81%] [G loss: 1.379470]\n",
      "epoch:29 step:27569 [D loss: 0.349496, acc.: 80.47%] [G loss: 1.173606]\n",
      "epoch:29 step:27570 [D loss: 0.211436, acc.: 96.88%] [G loss: 1.462372]\n",
      "epoch:29 step:27571 [D loss: 0.154142, acc.: 99.22%] [G loss: 2.106602]\n",
      "epoch:29 step:27572 [D loss: 0.153907, acc.: 100.00%] [G loss: 2.244306]\n",
      "epoch:29 step:27573 [D loss: 0.287165, acc.: 92.19%] [G loss: 1.837598]\n",
      "epoch:29 step:27574 [D loss: 0.382050, acc.: 86.72%] [G loss: 1.906982]\n",
      "epoch:29 step:27575 [D loss: 0.259738, acc.: 96.09%] [G loss: 1.601460]\n",
      "epoch:29 step:27576 [D loss: 0.738596, acc.: 52.34%] [G loss: 1.057417]\n",
      "epoch:29 step:27577 [D loss: 0.224612, acc.: 98.44%] [G loss: 1.960229]\n",
      "epoch:29 step:27578 [D loss: 0.389739, acc.: 77.34%] [G loss: 1.270963]\n",
      "epoch:29 step:27579 [D loss: 0.178401, acc.: 99.22%] [G loss: 2.635809]\n",
      "epoch:29 step:27580 [D loss: 0.538654, acc.: 72.66%] [G loss: 1.409139]\n",
      "epoch:29 step:27581 [D loss: 0.710750, acc.: 57.03%] [G loss: 1.213679]\n",
      "epoch:29 step:27582 [D loss: 0.321745, acc.: 91.41%] [G loss: 1.242475]\n",
      "epoch:29 step:27583 [D loss: 0.706517, acc.: 55.47%] [G loss: 0.919930]\n",
      "epoch:29 step:27584 [D loss: 1.020382, acc.: 28.91%] [G loss: 0.910995]\n",
      "epoch:29 step:27585 [D loss: 0.953570, acc.: 36.72%] [G loss: 0.936977]\n",
      "epoch:29 step:27586 [D loss: 0.810870, acc.: 47.66%] [G loss: 1.287246]\n",
      "epoch:29 step:27587 [D loss: 0.617240, acc.: 62.50%] [G loss: 1.092702]\n",
      "epoch:29 step:27588 [D loss: 1.046222, acc.: 37.50%] [G loss: 0.679514]\n",
      "epoch:29 step:27589 [D loss: 0.743937, acc.: 53.91%] [G loss: 1.069882]\n",
      "epoch:29 step:27590 [D loss: 1.052635, acc.: 27.34%] [G loss: 1.039426]\n",
      "epoch:29 step:27591 [D loss: 0.551969, acc.: 72.66%] [G loss: 1.459260]\n",
      "epoch:29 step:27592 [D loss: 0.522343, acc.: 77.34%] [G loss: 1.460398]\n",
      "epoch:29 step:27593 [D loss: 0.756975, acc.: 49.22%] [G loss: 1.106848]\n",
      "epoch:29 step:27594 [D loss: 0.719910, acc.: 53.12%] [G loss: 1.297843]\n",
      "epoch:29 step:27595 [D loss: 0.844455, acc.: 44.53%] [G loss: 1.310410]\n",
      "epoch:29 step:27596 [D loss: 0.652159, acc.: 64.06%] [G loss: 1.310155]\n",
      "epoch:29 step:27597 [D loss: 0.751825, acc.: 49.22%] [G loss: 1.058264]\n",
      "epoch:29 step:27598 [D loss: 0.559768, acc.: 72.66%] [G loss: 0.999066]\n",
      "epoch:29 step:27599 [D loss: 0.548573, acc.: 75.00%] [G loss: 1.471957]\n",
      "epoch:29 step:27600 [D loss: 0.493302, acc.: 76.56%] [G loss: 1.044571]\n",
      "epoch:29 step:27601 [D loss: 0.635398, acc.: 64.06%] [G loss: 0.942420]\n",
      "epoch:29 step:27602 [D loss: 0.658148, acc.: 60.94%] [G loss: 1.373164]\n",
      "epoch:29 step:27603 [D loss: 0.599134, acc.: 65.62%] [G loss: 1.199468]\n",
      "epoch:29 step:27604 [D loss: 0.460902, acc.: 80.47%] [G loss: 1.705419]\n",
      "epoch:29 step:27605 [D loss: 0.598437, acc.: 67.19%] [G loss: 1.452310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27606 [D loss: 0.442308, acc.: 83.59%] [G loss: 1.382840]\n",
      "epoch:29 step:27607 [D loss: 0.542967, acc.: 67.97%] [G loss: 1.332847]\n",
      "epoch:29 step:27608 [D loss: 0.403834, acc.: 88.28%] [G loss: 1.451610]\n",
      "epoch:29 step:27609 [D loss: 0.573017, acc.: 71.88%] [G loss: 1.542407]\n",
      "epoch:29 step:27610 [D loss: 0.805540, acc.: 50.78%] [G loss: 1.287800]\n",
      "epoch:29 step:27611 [D loss: 0.788479, acc.: 47.66%] [G loss: 1.237721]\n",
      "epoch:29 step:27612 [D loss: 0.557492, acc.: 70.31%] [G loss: 1.331928]\n",
      "epoch:29 step:27613 [D loss: 0.638589, acc.: 62.50%] [G loss: 1.107356]\n",
      "epoch:29 step:27614 [D loss: 0.597036, acc.: 66.41%] [G loss: 1.363875]\n",
      "epoch:29 step:27615 [D loss: 0.725462, acc.: 57.03%] [G loss: 1.127663]\n",
      "epoch:29 step:27616 [D loss: 0.350313, acc.: 90.62%] [G loss: 1.751356]\n",
      "epoch:29 step:27617 [D loss: 0.598985, acc.: 63.28%] [G loss: 1.382268]\n",
      "epoch:29 step:27618 [D loss: 0.781463, acc.: 49.22%] [G loss: 0.925449]\n",
      "epoch:29 step:27619 [D loss: 0.718834, acc.: 60.16%] [G loss: 1.001547]\n",
      "epoch:29 step:27620 [D loss: 0.493833, acc.: 75.78%] [G loss: 1.202816]\n",
      "epoch:29 step:27621 [D loss: 0.475942, acc.: 75.00%] [G loss: 1.246073]\n",
      "epoch:29 step:27622 [D loss: 0.347300, acc.: 88.28%] [G loss: 1.825954]\n",
      "epoch:29 step:27623 [D loss: 0.565808, acc.: 71.09%] [G loss: 1.409793]\n",
      "epoch:29 step:27624 [D loss: 0.422979, acc.: 82.03%] [G loss: 1.517238]\n",
      "epoch:29 step:27625 [D loss: 0.343770, acc.: 89.84%] [G loss: 1.466418]\n",
      "epoch:29 step:27626 [D loss: 0.525688, acc.: 73.44%] [G loss: 1.486601]\n",
      "epoch:29 step:27627 [D loss: 0.510999, acc.: 73.44%] [G loss: 1.570575]\n",
      "epoch:29 step:27628 [D loss: 0.757262, acc.: 53.91%] [G loss: 1.064726]\n",
      "epoch:29 step:27629 [D loss: 0.485248, acc.: 78.91%] [G loss: 1.407677]\n",
      "epoch:29 step:27630 [D loss: 0.341623, acc.: 93.75%] [G loss: 1.382490]\n",
      "epoch:29 step:27631 [D loss: 1.113064, acc.: 26.56%] [G loss: 1.237843]\n",
      "epoch:29 step:27632 [D loss: 0.981222, acc.: 38.28%] [G loss: 0.997293]\n",
      "epoch:29 step:27633 [D loss: 0.948303, acc.: 35.16%] [G loss: 1.022356]\n",
      "epoch:29 step:27634 [D loss: 1.013884, acc.: 31.25%] [G loss: 0.705743]\n",
      "epoch:29 step:27635 [D loss: 1.209789, acc.: 19.53%] [G loss: 1.089657]\n",
      "epoch:29 step:27636 [D loss: 0.919043, acc.: 35.16%] [G loss: 0.505411]\n",
      "epoch:29 step:27637 [D loss: 0.648807, acc.: 64.06%] [G loss: 0.691278]\n",
      "epoch:29 step:27638 [D loss: 0.555225, acc.: 71.88%] [G loss: 1.636274]\n",
      "epoch:29 step:27639 [D loss: 0.630476, acc.: 62.50%] [G loss: 1.251348]\n",
      "epoch:29 step:27640 [D loss: 0.542162, acc.: 68.75%] [G loss: 1.237963]\n",
      "epoch:29 step:27641 [D loss: 0.460389, acc.: 77.34%] [G loss: 1.440659]\n",
      "epoch:29 step:27642 [D loss: 0.433370, acc.: 82.03%] [G loss: 1.351175]\n",
      "epoch:29 step:27643 [D loss: 0.539275, acc.: 75.00%] [G loss: 1.325610]\n",
      "epoch:29 step:27644 [D loss: 0.267481, acc.: 95.31%] [G loss: 1.584693]\n",
      "epoch:29 step:27645 [D loss: 0.625842, acc.: 65.62%] [G loss: 1.496391]\n",
      "epoch:29 step:27646 [D loss: 0.856517, acc.: 49.22%] [G loss: 1.586287]\n",
      "epoch:29 step:27647 [D loss: 0.585586, acc.: 71.88%] [G loss: 1.420366]\n",
      "epoch:29 step:27648 [D loss: 0.461026, acc.: 84.38%] [G loss: 1.449525]\n",
      "epoch:29 step:27649 [D loss: 0.586024, acc.: 69.53%] [G loss: 1.362557]\n",
      "epoch:29 step:27650 [D loss: 0.775646, acc.: 53.91%] [G loss: 1.369181]\n",
      "epoch:29 step:27651 [D loss: 0.809555, acc.: 46.88%] [G loss: 0.909461]\n",
      "epoch:29 step:27652 [D loss: 0.651889, acc.: 64.06%] [G loss: 1.145156]\n",
      "epoch:29 step:27653 [D loss: 0.570431, acc.: 75.78%] [G loss: 1.478031]\n",
      "epoch:29 step:27654 [D loss: 0.450261, acc.: 84.38%] [G loss: 1.304545]\n",
      "epoch:29 step:27655 [D loss: 0.543903, acc.: 75.00%] [G loss: 1.634751]\n",
      "epoch:29 step:27656 [D loss: 0.592763, acc.: 71.88%] [G loss: 1.415693]\n",
      "epoch:29 step:27657 [D loss: 0.249478, acc.: 98.44%] [G loss: 1.870743]\n",
      "epoch:29 step:27658 [D loss: 0.365051, acc.: 89.06%] [G loss: 1.577054]\n",
      "epoch:29 step:27659 [D loss: 0.567087, acc.: 68.75%] [G loss: 1.657579]\n",
      "epoch:29 step:27660 [D loss: 0.455267, acc.: 83.59%] [G loss: 1.474907]\n",
      "epoch:29 step:27661 [D loss: 0.511276, acc.: 82.81%] [G loss: 1.326275]\n",
      "epoch:29 step:27662 [D loss: 0.707396, acc.: 47.66%] [G loss: 1.045963]\n",
      "epoch:29 step:27663 [D loss: 0.431355, acc.: 85.16%] [G loss: 1.304950]\n",
      "epoch:29 step:27664 [D loss: 0.541148, acc.: 76.56%] [G loss: 1.393296]\n",
      "epoch:29 step:27665 [D loss: 0.652721, acc.: 61.72%] [G loss: 1.111696]\n",
      "epoch:29 step:27666 [D loss: 0.577042, acc.: 69.53%] [G loss: 1.091395]\n",
      "epoch:29 step:27667 [D loss: 0.808358, acc.: 46.09%] [G loss: 1.063928]\n",
      "epoch:29 step:27668 [D loss: 0.501214, acc.: 80.47%] [G loss: 1.219791]\n",
      "epoch:29 step:27669 [D loss: 0.519155, acc.: 74.22%] [G loss: 1.133538]\n",
      "epoch:29 step:27670 [D loss: 0.233109, acc.: 94.53%] [G loss: 1.574655]\n",
      "epoch:29 step:27671 [D loss: 0.199888, acc.: 98.44%] [G loss: 1.907011]\n",
      "epoch:29 step:27672 [D loss: 0.194607, acc.: 97.66%] [G loss: 1.848413]\n",
      "epoch:29 step:27673 [D loss: 0.853122, acc.: 53.12%] [G loss: 1.635469]\n",
      "epoch:29 step:27674 [D loss: 0.750254, acc.: 52.34%] [G loss: 1.156486]\n",
      "epoch:29 step:27675 [D loss: 0.631686, acc.: 64.06%] [G loss: 0.891112]\n",
      "epoch:29 step:27676 [D loss: 0.409274, acc.: 82.81%] [G loss: 0.800055]\n",
      "epoch:29 step:27677 [D loss: 0.380273, acc.: 84.38%] [G loss: 1.389358]\n",
      "epoch:29 step:27678 [D loss: 0.474106, acc.: 81.25%] [G loss: 1.598686]\n",
      "epoch:29 step:27679 [D loss: 0.597740, acc.: 67.19%] [G loss: 1.061473]\n",
      "epoch:29 step:27680 [D loss: 0.691218, acc.: 61.72%] [G loss: 1.239192]\n",
      "epoch:29 step:27681 [D loss: 0.352802, acc.: 89.84%] [G loss: 1.360882]\n",
      "epoch:29 step:27682 [D loss: 0.570480, acc.: 67.97%] [G loss: 1.435328]\n",
      "epoch:29 step:27683 [D loss: 0.598282, acc.: 66.41%] [G loss: 1.143648]\n",
      "epoch:29 step:27684 [D loss: 0.300571, acc.: 95.31%] [G loss: 1.301980]\n",
      "epoch:29 step:27685 [D loss: 0.287615, acc.: 96.09%] [G loss: 1.415746]\n",
      "epoch:29 step:27686 [D loss: 0.366374, acc.: 87.50%] [G loss: 1.429176]\n",
      "epoch:29 step:27687 [D loss: 0.343992, acc.: 89.84%] [G loss: 1.568296]\n",
      "epoch:29 step:27688 [D loss: 0.410408, acc.: 87.50%] [G loss: 1.482138]\n",
      "epoch:29 step:27689 [D loss: 0.690043, acc.: 60.16%] [G loss: 1.109447]\n",
      "epoch:29 step:27690 [D loss: 0.484539, acc.: 82.81%] [G loss: 1.499272]\n",
      "epoch:29 step:27691 [D loss: 0.465452, acc.: 80.47%] [G loss: 1.336657]\n",
      "epoch:29 step:27692 [D loss: 0.322815, acc.: 92.97%] [G loss: 1.900542]\n",
      "epoch:29 step:27693 [D loss: 0.385242, acc.: 87.50%] [G loss: 1.281380]\n",
      "epoch:29 step:27694 [D loss: 0.604799, acc.: 66.41%] [G loss: 1.297955]\n",
      "epoch:29 step:27695 [D loss: 0.392871, acc.: 86.72%] [G loss: 1.427372]\n",
      "epoch:29 step:27696 [D loss: 0.368938, acc.: 96.09%] [G loss: 1.405859]\n",
      "epoch:29 step:27697 [D loss: 0.528711, acc.: 78.12%] [G loss: 1.657029]\n",
      "epoch:29 step:27698 [D loss: 0.685109, acc.: 56.25%] [G loss: 1.022648]\n",
      "epoch:29 step:27699 [D loss: 0.645927, acc.: 59.38%] [G loss: 1.098641]\n",
      "epoch:29 step:27700 [D loss: 0.580563, acc.: 67.97%] [G loss: 1.094616]\n",
      "epoch:29 step:27701 [D loss: 0.650659, acc.: 63.28%] [G loss: 1.067960]\n",
      "epoch:29 step:27702 [D loss: 0.736910, acc.: 51.56%] [G loss: 0.918226]\n",
      "epoch:29 step:27703 [D loss: 0.439503, acc.: 85.94%] [G loss: 1.233468]\n",
      "epoch:29 step:27704 [D loss: 0.522348, acc.: 76.56%] [G loss: 1.100990]\n",
      "epoch:29 step:27705 [D loss: 0.410444, acc.: 78.91%] [G loss: 1.132128]\n",
      "epoch:29 step:27706 [D loss: 0.239254, acc.: 95.31%] [G loss: 1.686005]\n",
      "epoch:29 step:27707 [D loss: 0.290344, acc.: 96.09%] [G loss: 1.508759]\n",
      "epoch:29 step:27708 [D loss: 0.513116, acc.: 76.56%] [G loss: 1.334274]\n",
      "epoch:29 step:27709 [D loss: 0.280194, acc.: 97.66%] [G loss: 1.683822]\n",
      "epoch:29 step:27710 [D loss: 0.394153, acc.: 88.28%] [G loss: 1.746341]\n",
      "epoch:29 step:27711 [D loss: 0.552159, acc.: 67.97%] [G loss: 1.317705]\n",
      "epoch:29 step:27712 [D loss: 0.540644, acc.: 74.22%] [G loss: 1.308854]\n",
      "epoch:29 step:27713 [D loss: 0.649587, acc.: 63.28%] [G loss: 1.094406]\n",
      "epoch:29 step:27714 [D loss: 0.885378, acc.: 39.06%] [G loss: 0.729667]\n",
      "epoch:29 step:27715 [D loss: 0.701582, acc.: 59.38%] [G loss: 1.053080]\n",
      "epoch:29 step:27716 [D loss: 0.406900, acc.: 86.72%] [G loss: 1.436763]\n",
      "epoch:29 step:27717 [D loss: 0.434939, acc.: 82.03%] [G loss: 1.383470]\n",
      "epoch:29 step:27718 [D loss: 0.314132, acc.: 94.53%] [G loss: 1.545202]\n",
      "epoch:29 step:27719 [D loss: 0.235139, acc.: 98.44%] [G loss: 1.527094]\n",
      "epoch:29 step:27720 [D loss: 0.258500, acc.: 94.53%] [G loss: 1.789907]\n",
      "epoch:29 step:27721 [D loss: 0.358912, acc.: 89.84%] [G loss: 1.284092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27722 [D loss: 0.186591, acc.: 98.44%] [G loss: 1.722144]\n",
      "epoch:29 step:27723 [D loss: 0.295684, acc.: 93.75%] [G loss: 1.894420]\n",
      "epoch:29 step:27724 [D loss: 0.245623, acc.: 96.09%] [G loss: 1.833690]\n",
      "epoch:29 step:27725 [D loss: 0.293265, acc.: 94.53%] [G loss: 1.739692]\n",
      "epoch:29 step:27726 [D loss: 0.338001, acc.: 90.62%] [G loss: 1.712299]\n",
      "epoch:29 step:27727 [D loss: 0.268901, acc.: 90.62%] [G loss: 1.399071]\n",
      "epoch:29 step:27728 [D loss: 0.277509, acc.: 96.88%] [G loss: 1.945883]\n",
      "epoch:29 step:27729 [D loss: 0.373709, acc.: 85.94%] [G loss: 1.652862]\n",
      "epoch:29 step:27730 [D loss: 0.407971, acc.: 86.72%] [G loss: 1.736150]\n",
      "epoch:29 step:27731 [D loss: 0.359976, acc.: 86.72%] [G loss: 2.166854]\n",
      "epoch:29 step:27732 [D loss: 1.059564, acc.: 37.50%] [G loss: 1.291322]\n",
      "epoch:29 step:27733 [D loss: 0.888270, acc.: 49.22%] [G loss: 1.250522]\n",
      "epoch:29 step:27734 [D loss: 0.327416, acc.: 91.41%] [G loss: 1.576167]\n",
      "epoch:29 step:27735 [D loss: 0.834096, acc.: 46.88%] [G loss: 1.129422]\n",
      "epoch:29 step:27736 [D loss: 0.652228, acc.: 60.16%] [G loss: 1.064698]\n",
      "epoch:29 step:27737 [D loss: 0.476474, acc.: 82.03%] [G loss: 1.254346]\n",
      "epoch:29 step:27738 [D loss: 0.614273, acc.: 67.97%] [G loss: 1.151326]\n",
      "epoch:29 step:27739 [D loss: 0.349376, acc.: 89.84%] [G loss: 1.351465]\n",
      "epoch:29 step:27740 [D loss: 0.254862, acc.: 93.75%] [G loss: 1.602726]\n",
      "epoch:29 step:27741 [D loss: 0.610831, acc.: 64.84%] [G loss: 1.655244]\n",
      "epoch:29 step:27742 [D loss: 0.890978, acc.: 38.28%] [G loss: 1.062920]\n",
      "epoch:29 step:27743 [D loss: 0.738884, acc.: 54.69%] [G loss: 0.981317]\n",
      "epoch:29 step:27744 [D loss: 0.442577, acc.: 84.38%] [G loss: 1.207145]\n",
      "epoch:29 step:27745 [D loss: 0.611742, acc.: 68.75%] [G loss: 1.156019]\n",
      "epoch:29 step:27746 [D loss: 0.436660, acc.: 83.59%] [G loss: 1.205438]\n",
      "epoch:29 step:27747 [D loss: 0.356151, acc.: 88.28%] [G loss: 1.317836]\n",
      "epoch:29 step:27748 [D loss: 0.574883, acc.: 62.50%] [G loss: 1.290883]\n",
      "epoch:29 step:27749 [D loss: 0.303870, acc.: 95.31%] [G loss: 1.701622]\n",
      "epoch:29 step:27750 [D loss: 0.470951, acc.: 80.47%] [G loss: 0.981994]\n",
      "epoch:29 step:27751 [D loss: 0.190095, acc.: 99.22%] [G loss: 1.824220]\n",
      "epoch:29 step:27752 [D loss: 0.305194, acc.: 91.41%] [G loss: 1.534913]\n",
      "epoch:29 step:27753 [D loss: 0.783838, acc.: 48.44%] [G loss: 0.761019]\n",
      "epoch:29 step:27754 [D loss: 0.551717, acc.: 73.44%] [G loss: 0.797498]\n",
      "epoch:29 step:27755 [D loss: 0.828580, acc.: 46.88%] [G loss: 1.017212]\n",
      "epoch:29 step:27756 [D loss: 0.828992, acc.: 47.66%] [G loss: 0.845173]\n",
      "epoch:29 step:27757 [D loss: 0.903190, acc.: 37.50%] [G loss: 1.003375]\n",
      "epoch:29 step:27758 [D loss: 0.677574, acc.: 60.94%] [G loss: 0.933100]\n",
      "epoch:29 step:27759 [D loss: 0.494201, acc.: 78.91%] [G loss: 1.325252]\n",
      "epoch:29 step:27760 [D loss: 0.405535, acc.: 76.56%] [G loss: 1.442413]\n",
      "epoch:29 step:27761 [D loss: 0.175330, acc.: 97.66%] [G loss: 1.664662]\n",
      "epoch:29 step:27762 [D loss: 0.230864, acc.: 97.66%] [G loss: 1.609636]\n",
      "epoch:29 step:27763 [D loss: 0.835146, acc.: 44.53%] [G loss: 1.173905]\n",
      "epoch:29 step:27764 [D loss: 1.032144, acc.: 35.94%] [G loss: 0.869579]\n",
      "epoch:29 step:27765 [D loss: 0.768750, acc.: 56.25%] [G loss: 1.036252]\n",
      "epoch:29 step:27766 [D loss: 0.720796, acc.: 49.22%] [G loss: 1.509018]\n",
      "epoch:29 step:27767 [D loss: 0.481344, acc.: 78.91%] [G loss: 1.328673]\n",
      "epoch:29 step:27768 [D loss: 0.458121, acc.: 79.69%] [G loss: 1.308337]\n",
      "epoch:29 step:27769 [D loss: 0.719321, acc.: 54.69%] [G loss: 1.168672]\n",
      "epoch:29 step:27770 [D loss: 0.597991, acc.: 67.97%] [G loss: 1.250455]\n",
      "epoch:29 step:27771 [D loss: 0.273505, acc.: 95.31%] [G loss: 1.583360]\n",
      "epoch:29 step:27772 [D loss: 0.603752, acc.: 68.75%] [G loss: 1.612468]\n",
      "epoch:29 step:27773 [D loss: 0.418357, acc.: 84.38%] [G loss: 1.361356]\n",
      "epoch:29 step:27774 [D loss: 0.496444, acc.: 78.12%] [G loss: 1.601803]\n",
      "epoch:29 step:27775 [D loss: 0.630083, acc.: 63.28%] [G loss: 1.195115]\n",
      "epoch:29 step:27776 [D loss: 0.351277, acc.: 91.41%] [G loss: 1.350746]\n",
      "epoch:29 step:27777 [D loss: 0.233662, acc.: 96.09%] [G loss: 1.527040]\n",
      "epoch:29 step:27778 [D loss: 0.270766, acc.: 93.75%] [G loss: 1.482264]\n",
      "epoch:29 step:27779 [D loss: 0.738692, acc.: 58.59%] [G loss: 1.269873]\n",
      "epoch:29 step:27780 [D loss: 0.620764, acc.: 63.28%] [G loss: 1.056097]\n",
      "epoch:29 step:27781 [D loss: 0.615984, acc.: 66.41%] [G loss: 1.019105]\n",
      "epoch:29 step:27782 [D loss: 0.511726, acc.: 80.47%] [G loss: 1.079335]\n",
      "epoch:29 step:27783 [D loss: 0.437678, acc.: 83.59%] [G loss: 1.141845]\n",
      "epoch:29 step:27784 [D loss: 0.759959, acc.: 50.00%] [G loss: 1.307939]\n",
      "epoch:29 step:27785 [D loss: 0.514777, acc.: 78.91%] [G loss: 1.763579]\n",
      "epoch:29 step:27786 [D loss: 0.225327, acc.: 97.66%] [G loss: 1.984522]\n",
      "epoch:29 step:27787 [D loss: 0.290366, acc.: 89.84%] [G loss: 1.085669]\n",
      "epoch:29 step:27788 [D loss: 0.235723, acc.: 93.75%] [G loss: 1.852067]\n",
      "epoch:29 step:27789 [D loss: 0.234520, acc.: 94.53%] [G loss: 1.417904]\n",
      "epoch:29 step:27790 [D loss: 0.247362, acc.: 95.31%] [G loss: 2.322860]\n",
      "epoch:29 step:27791 [D loss: 0.649742, acc.: 61.72%] [G loss: 1.698034]\n",
      "epoch:29 step:27792 [D loss: 0.527407, acc.: 72.66%] [G loss: 1.253227]\n",
      "epoch:29 step:27793 [D loss: 0.537600, acc.: 75.00%] [G loss: 1.071395]\n",
      "epoch:29 step:27794 [D loss: 0.501020, acc.: 78.91%] [G loss: 1.184208]\n",
      "epoch:29 step:27795 [D loss: 0.361894, acc.: 90.62%] [G loss: 1.665546]\n",
      "epoch:29 step:27796 [D loss: 0.552204, acc.: 67.19%] [G loss: 1.189535]\n",
      "epoch:29 step:27797 [D loss: 0.305634, acc.: 93.75%] [G loss: 1.858133]\n",
      "epoch:29 step:27798 [D loss: 0.432317, acc.: 85.16%] [G loss: 1.618680]\n",
      "epoch:29 step:27799 [D loss: 0.483167, acc.: 78.12%] [G loss: 1.389192]\n",
      "epoch:29 step:27800 [D loss: 0.544815, acc.: 71.09%] [G loss: 1.474793]\n",
      "epoch:29 step:27801 [D loss: 0.689216, acc.: 66.41%] [G loss: 0.755059]\n",
      "epoch:29 step:27802 [D loss: 0.476677, acc.: 70.31%] [G loss: 0.911923]\n",
      "epoch:29 step:27803 [D loss: 0.454242, acc.: 82.03%] [G loss: 1.259509]\n",
      "epoch:29 step:27804 [D loss: 0.593370, acc.: 59.38%] [G loss: 1.869990]\n",
      "epoch:29 step:27805 [D loss: 0.453860, acc.: 80.47%] [G loss: 0.981868]\n",
      "epoch:29 step:27806 [D loss: 0.182466, acc.: 99.22%] [G loss: 2.562459]\n",
      "epoch:29 step:27807 [D loss: 0.301125, acc.: 93.75%] [G loss: 1.941400]\n",
      "epoch:29 step:27808 [D loss: 0.459624, acc.: 79.69%] [G loss: 1.256936]\n",
      "epoch:29 step:27809 [D loss: 1.493723, acc.: 28.12%] [G loss: 0.543662]\n",
      "epoch:29 step:27810 [D loss: 1.035110, acc.: 27.34%] [G loss: 1.233805]\n",
      "epoch:29 step:27811 [D loss: 0.639644, acc.: 63.28%] [G loss: 0.799808]\n",
      "epoch:29 step:27812 [D loss: 1.444642, acc.: 20.31%] [G loss: 0.836068]\n",
      "epoch:29 step:27813 [D loss: 1.640867, acc.: 3.91%] [G loss: 0.678012]\n",
      "epoch:29 step:27814 [D loss: 1.331604, acc.: 18.75%] [G loss: 0.890324]\n",
      "epoch:29 step:27815 [D loss: 0.790623, acc.: 57.81%] [G loss: 1.703332]\n",
      "epoch:29 step:27816 [D loss: 0.866559, acc.: 46.88%] [G loss: 1.165786]\n",
      "epoch:29 step:27817 [D loss: 0.861196, acc.: 49.22%] [G loss: 1.224280]\n",
      "epoch:29 step:27818 [D loss: 0.984690, acc.: 34.38%] [G loss: 1.081416]\n",
      "epoch:29 step:27819 [D loss: 0.432472, acc.: 82.81%] [G loss: 1.601936]\n",
      "epoch:29 step:27820 [D loss: 0.282125, acc.: 96.88%] [G loss: 1.710727]\n",
      "epoch:29 step:27821 [D loss: 0.458823, acc.: 81.25%] [G loss: 1.481205]\n",
      "epoch:29 step:27822 [D loss: 0.378390, acc.: 87.50%] [G loss: 1.896782]\n",
      "epoch:29 step:27823 [D loss: 0.487088, acc.: 79.69%] [G loss: 1.315740]\n",
      "epoch:29 step:27824 [D loss: 1.161141, acc.: 28.12%] [G loss: 1.012493]\n",
      "epoch:29 step:27825 [D loss: 0.762692, acc.: 54.69%] [G loss: 1.874163]\n",
      "epoch:29 step:27826 [D loss: 0.705512, acc.: 58.59%] [G loss: 1.283426]\n",
      "epoch:29 step:27827 [D loss: 0.635857, acc.: 64.06%] [G loss: 1.161121]\n",
      "epoch:29 step:27828 [D loss: 0.735396, acc.: 58.59%] [G loss: 1.100369]\n",
      "epoch:29 step:27829 [D loss: 0.670654, acc.: 64.06%] [G loss: 1.115288]\n",
      "epoch:29 step:27830 [D loss: 0.799976, acc.: 46.09%] [G loss: 0.971264]\n",
      "epoch:29 step:27831 [D loss: 0.510660, acc.: 78.12%] [G loss: 0.965518]\n",
      "epoch:29 step:27832 [D loss: 0.585183, acc.: 70.31%] [G loss: 1.160450]\n",
      "epoch:29 step:27833 [D loss: 0.562626, acc.: 73.44%] [G loss: 1.496891]\n",
      "epoch:29 step:27834 [D loss: 0.362138, acc.: 94.53%] [G loss: 1.231649]\n",
      "epoch:29 step:27835 [D loss: 0.309546, acc.: 91.41%] [G loss: 1.602163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27836 [D loss: 0.161275, acc.: 98.44%] [G loss: 1.648754]\n",
      "epoch:29 step:27837 [D loss: 0.151311, acc.: 98.44%] [G loss: 1.921358]\n",
      "epoch:29 step:27838 [D loss: 0.156735, acc.: 98.44%] [G loss: 1.870427]\n",
      "epoch:29 step:27839 [D loss: 0.235050, acc.: 96.88%] [G loss: 2.268838]\n",
      "epoch:29 step:27840 [D loss: 0.351085, acc.: 86.72%] [G loss: 2.077252]\n",
      "epoch:29 step:27841 [D loss: 0.520585, acc.: 76.56%] [G loss: 1.421867]\n",
      "epoch:29 step:27842 [D loss: 0.309468, acc.: 92.97%] [G loss: 1.659785]\n",
      "epoch:29 step:27843 [D loss: 0.303004, acc.: 92.97%] [G loss: 1.567686]\n",
      "epoch:29 step:27844 [D loss: 0.368230, acc.: 85.16%] [G loss: 1.758974]\n",
      "epoch:29 step:27845 [D loss: 0.395543, acc.: 81.25%] [G loss: 1.845025]\n",
      "epoch:29 step:27846 [D loss: 1.275882, acc.: 17.97%] [G loss: 0.656735]\n",
      "epoch:29 step:27847 [D loss: 0.405544, acc.: 81.25%] [G loss: 1.325673]\n",
      "epoch:29 step:27848 [D loss: 0.855149, acc.: 46.09%] [G loss: 1.035455]\n",
      "epoch:29 step:27849 [D loss: 0.446500, acc.: 79.69%] [G loss: 1.297903]\n",
      "epoch:29 step:27850 [D loss: 0.513449, acc.: 75.78%] [G loss: 1.733528]\n",
      "epoch:29 step:27851 [D loss: 0.782073, acc.: 48.44%] [G loss: 1.150535]\n",
      "epoch:29 step:27852 [D loss: 0.758445, acc.: 59.38%] [G loss: 0.775632]\n",
      "epoch:29 step:27853 [D loss: 0.572480, acc.: 67.97%] [G loss: 1.459969]\n",
      "epoch:29 step:27854 [D loss: 0.688744, acc.: 59.38%] [G loss: 1.010110]\n",
      "epoch:29 step:27855 [D loss: 0.269595, acc.: 94.53%] [G loss: 1.155952]\n",
      "epoch:29 step:27856 [D loss: 0.405251, acc.: 89.84%] [G loss: 1.113928]\n",
      "epoch:29 step:27857 [D loss: 0.336323, acc.: 91.41%] [G loss: 1.135931]\n",
      "epoch:29 step:27858 [D loss: 0.460560, acc.: 79.69%] [G loss: 1.697450]\n",
      "epoch:29 step:27859 [D loss: 0.685092, acc.: 57.03%] [G loss: 1.053135]\n",
      "epoch:29 step:27860 [D loss: 1.078774, acc.: 37.50%] [G loss: 0.901081]\n",
      "epoch:29 step:27861 [D loss: 0.999011, acc.: 35.94%] [G loss: 0.904370]\n",
      "epoch:29 step:27862 [D loss: 1.367117, acc.: 15.62%] [G loss: 0.954997]\n",
      "epoch:29 step:27863 [D loss: 1.030051, acc.: 32.03%] [G loss: 0.840821]\n",
      "epoch:29 step:27864 [D loss: 0.637570, acc.: 65.62%] [G loss: 1.364159]\n",
      "epoch:29 step:27865 [D loss: 0.559061, acc.: 77.34%] [G loss: 1.277056]\n",
      "epoch:29 step:27866 [D loss: 0.808955, acc.: 43.75%] [G loss: 1.089759]\n",
      "epoch:29 step:27867 [D loss: 0.601807, acc.: 63.28%] [G loss: 1.431631]\n",
      "epoch:29 step:27868 [D loss: 0.561502, acc.: 71.09%] [G loss: 1.234135]\n",
      "epoch:29 step:27869 [D loss: 0.607950, acc.: 67.19%] [G loss: 1.165342]\n",
      "epoch:29 step:27870 [D loss: 0.523361, acc.: 76.56%] [G loss: 1.027853]\n",
      "epoch:29 step:27871 [D loss: 0.665827, acc.: 61.72%] [G loss: 0.986467]\n",
      "epoch:29 step:27872 [D loss: 0.670652, acc.: 61.72%] [G loss: 0.859058]\n",
      "epoch:29 step:27873 [D loss: 0.540220, acc.: 71.88%] [G loss: 1.108381]\n",
      "epoch:29 step:27874 [D loss: 0.476648, acc.: 78.12%] [G loss: 1.152833]\n",
      "epoch:29 step:27875 [D loss: 0.652664, acc.: 61.72%] [G loss: 1.050415]\n",
      "epoch:29 step:27876 [D loss: 0.549020, acc.: 71.09%] [G loss: 1.316797]\n",
      "epoch:29 step:27877 [D loss: 0.552797, acc.: 73.44%] [G loss: 1.107090]\n",
      "epoch:29 step:27878 [D loss: 0.690711, acc.: 53.91%] [G loss: 0.868503]\n",
      "epoch:29 step:27879 [D loss: 0.553566, acc.: 74.22%] [G loss: 1.140444]\n",
      "epoch:29 step:27880 [D loss: 0.432506, acc.: 81.25%] [G loss: 1.323606]\n",
      "epoch:29 step:27881 [D loss: 0.322320, acc.: 95.31%] [G loss: 1.422798]\n",
      "epoch:29 step:27882 [D loss: 0.464430, acc.: 83.59%] [G loss: 1.158214]\n",
      "epoch:29 step:27883 [D loss: 0.744712, acc.: 52.34%] [G loss: 1.088006]\n",
      "epoch:29 step:27884 [D loss: 0.771146, acc.: 52.34%] [G loss: 1.329629]\n",
      "epoch:29 step:27885 [D loss: 0.688336, acc.: 57.81%] [G loss: 1.526261]\n",
      "epoch:29 step:27886 [D loss: 0.665681, acc.: 60.16%] [G loss: 1.207323]\n",
      "epoch:29 step:27887 [D loss: 0.679343, acc.: 58.59%] [G loss: 1.355668]\n",
      "epoch:29 step:27888 [D loss: 0.827729, acc.: 43.75%] [G loss: 1.194087]\n",
      "epoch:29 step:27889 [D loss: 0.698429, acc.: 60.16%] [G loss: 1.096508]\n",
      "epoch:29 step:27890 [D loss: 0.437704, acc.: 84.38%] [G loss: 1.329305]\n",
      "epoch:29 step:27891 [D loss: 0.807546, acc.: 43.75%] [G loss: 1.107039]\n",
      "epoch:29 step:27892 [D loss: 0.581746, acc.: 68.75%] [G loss: 0.965817]\n",
      "epoch:29 step:27893 [D loss: 0.476907, acc.: 77.34%] [G loss: 1.159249]\n",
      "epoch:29 step:27894 [D loss: 0.579243, acc.: 67.97%] [G loss: 1.209537]\n",
      "epoch:29 step:27895 [D loss: 0.805757, acc.: 45.31%] [G loss: 1.080946]\n",
      "epoch:29 step:27896 [D loss: 0.584835, acc.: 71.88%] [G loss: 1.068247]\n",
      "epoch:29 step:27897 [D loss: 0.381385, acc.: 88.28%] [G loss: 1.089589]\n",
      "epoch:29 step:27898 [D loss: 0.389167, acc.: 87.50%] [G loss: 1.369524]\n",
      "epoch:29 step:27899 [D loss: 0.512127, acc.: 79.69%] [G loss: 1.364761]\n",
      "epoch:29 step:27900 [D loss: 0.750627, acc.: 51.56%] [G loss: 1.347038]\n",
      "epoch:29 step:27901 [D loss: 0.648298, acc.: 58.59%] [G loss: 1.077118]\n",
      "epoch:29 step:27902 [D loss: 0.530694, acc.: 75.78%] [G loss: 1.176918]\n",
      "epoch:29 step:27903 [D loss: 0.656955, acc.: 62.50%] [G loss: 1.040698]\n",
      "epoch:29 step:27904 [D loss: 0.464055, acc.: 78.91%] [G loss: 1.210135]\n",
      "epoch:29 step:27905 [D loss: 0.419770, acc.: 86.72%] [G loss: 1.076220]\n",
      "epoch:29 step:27906 [D loss: 0.535983, acc.: 72.66%] [G loss: 1.138490]\n",
      "epoch:29 step:27907 [D loss: 0.827594, acc.: 45.31%] [G loss: 0.973609]\n",
      "epoch:29 step:27908 [D loss: 0.687333, acc.: 57.81%] [G loss: 1.278749]\n",
      "epoch:29 step:27909 [D loss: 0.620054, acc.: 64.84%] [G loss: 1.432633]\n",
      "epoch:29 step:27910 [D loss: 0.682765, acc.: 57.03%] [G loss: 1.024518]\n",
      "epoch:29 step:27911 [D loss: 0.647330, acc.: 64.84%] [G loss: 0.852832]\n",
      "epoch:29 step:27912 [D loss: 0.754159, acc.: 51.56%] [G loss: 0.913466]\n",
      "epoch:29 step:27913 [D loss: 0.708536, acc.: 52.34%] [G loss: 1.039196]\n",
      "epoch:29 step:27914 [D loss: 0.487118, acc.: 78.91%] [G loss: 0.865297]\n",
      "epoch:29 step:27915 [D loss: 0.557255, acc.: 71.88%] [G loss: 1.270585]\n",
      "epoch:29 step:27916 [D loss: 0.389246, acc.: 85.94%] [G loss: 1.312173]\n",
      "epoch:29 step:27917 [D loss: 0.855426, acc.: 46.88%] [G loss: 1.054074]\n",
      "epoch:29 step:27918 [D loss: 0.670005, acc.: 60.94%] [G loss: 1.185721]\n",
      "epoch:29 step:27919 [D loss: 0.635534, acc.: 66.41%] [G loss: 1.157541]\n",
      "epoch:29 step:27920 [D loss: 0.619178, acc.: 68.75%] [G loss: 1.072934]\n",
      "epoch:29 step:27921 [D loss: 0.520331, acc.: 76.56%] [G loss: 1.339610]\n",
      "epoch:29 step:27922 [D loss: 0.549472, acc.: 74.22%] [G loss: 0.882002]\n",
      "epoch:29 step:27923 [D loss: 0.690322, acc.: 57.81%] [G loss: 1.231490]\n",
      "epoch:29 step:27924 [D loss: 0.702848, acc.: 57.03%] [G loss: 1.028117]\n",
      "epoch:29 step:27925 [D loss: 0.753193, acc.: 47.66%] [G loss: 1.078907]\n",
      "epoch:29 step:27926 [D loss: 0.679009, acc.: 55.47%] [G loss: 1.115807]\n",
      "epoch:29 step:27927 [D loss: 0.613964, acc.: 68.75%] [G loss: 1.083550]\n",
      "epoch:29 step:27928 [D loss: 0.423717, acc.: 82.81%] [G loss: 1.172169]\n",
      "epoch:29 step:27929 [D loss: 0.610523, acc.: 61.72%] [G loss: 1.212402]\n",
      "epoch:29 step:27930 [D loss: 0.657566, acc.: 57.03%] [G loss: 0.968335]\n",
      "epoch:29 step:27931 [D loss: 0.693660, acc.: 59.38%] [G loss: 1.025440]\n",
      "epoch:29 step:27932 [D loss: 0.613128, acc.: 64.06%] [G loss: 1.257064]\n",
      "epoch:29 step:27933 [D loss: 0.662313, acc.: 59.38%] [G loss: 1.067242]\n",
      "epoch:29 step:27934 [D loss: 0.574283, acc.: 74.22%] [G loss: 1.129269]\n",
      "epoch:29 step:27935 [D loss: 0.868678, acc.: 36.72%] [G loss: 0.880309]\n",
      "epoch:29 step:27936 [D loss: 0.619724, acc.: 64.84%] [G loss: 0.863069]\n",
      "epoch:29 step:27937 [D loss: 0.547588, acc.: 69.53%] [G loss: 1.091142]\n",
      "epoch:29 step:27938 [D loss: 0.711237, acc.: 54.69%] [G loss: 0.985699]\n",
      "epoch:29 step:27939 [D loss: 0.612999, acc.: 70.31%] [G loss: 1.154590]\n",
      "epoch:29 step:27940 [D loss: 0.486930, acc.: 76.56%] [G loss: 1.173713]\n",
      "epoch:29 step:27941 [D loss: 0.331032, acc.: 90.62%] [G loss: 1.481254]\n",
      "epoch:29 step:27942 [D loss: 0.298938, acc.: 93.75%] [G loss: 1.378966]\n",
      "epoch:29 step:27943 [D loss: 0.568612, acc.: 68.75%] [G loss: 1.301370]\n",
      "epoch:29 step:27944 [D loss: 0.800057, acc.: 50.00%] [G loss: 1.108514]\n",
      "epoch:29 step:27945 [D loss: 0.768080, acc.: 48.44%] [G loss: 0.933413]\n",
      "epoch:29 step:27946 [D loss: 0.559651, acc.: 72.66%] [G loss: 0.907882]\n",
      "epoch:29 step:27947 [D loss: 0.302856, acc.: 84.38%] [G loss: 1.546665]\n",
      "epoch:29 step:27948 [D loss: 0.257558, acc.: 92.19%] [G loss: 1.464441]\n",
      "epoch:29 step:27949 [D loss: 0.546579, acc.: 71.09%] [G loss: 1.224173]\n",
      "epoch:29 step:27950 [D loss: 0.478710, acc.: 75.78%] [G loss: 1.312711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27951 [D loss: 0.902155, acc.: 36.72%] [G loss: 1.108048]\n",
      "epoch:29 step:27952 [D loss: 0.749869, acc.: 48.44%] [G loss: 0.865093]\n",
      "epoch:29 step:27953 [D loss: 0.495237, acc.: 78.12%] [G loss: 1.420124]\n",
      "epoch:29 step:27954 [D loss: 0.503426, acc.: 79.69%] [G loss: 1.239594]\n",
      "epoch:29 step:27955 [D loss: 0.450241, acc.: 80.47%] [G loss: 1.311278]\n",
      "epoch:29 step:27956 [D loss: 0.695983, acc.: 60.94%] [G loss: 1.264130]\n",
      "epoch:29 step:27957 [D loss: 0.767227, acc.: 44.53%] [G loss: 0.942273]\n",
      "epoch:29 step:27958 [D loss: 0.556600, acc.: 70.31%] [G loss: 1.049411]\n",
      "epoch:29 step:27959 [D loss: 0.496718, acc.: 79.69%] [G loss: 1.130657]\n",
      "epoch:29 step:27960 [D loss: 0.877007, acc.: 39.84%] [G loss: 1.071839]\n",
      "epoch:29 step:27961 [D loss: 0.675426, acc.: 62.50%] [G loss: 0.925036]\n",
      "epoch:29 step:27962 [D loss: 0.728630, acc.: 53.91%] [G loss: 1.034126]\n",
      "epoch:29 step:27963 [D loss: 0.521548, acc.: 76.56%] [G loss: 0.843694]\n",
      "epoch:29 step:27964 [D loss: 0.309049, acc.: 90.62%] [G loss: 1.372833]\n",
      "epoch:29 step:27965 [D loss: 0.297867, acc.: 89.84%] [G loss: 1.250003]\n",
      "epoch:29 step:27966 [D loss: 0.323126, acc.: 92.19%] [G loss: 1.487275]\n",
      "epoch:29 step:27967 [D loss: 0.325635, acc.: 87.50%] [G loss: 1.396306]\n",
      "epoch:29 step:27968 [D loss: 0.428951, acc.: 81.25%] [G loss: 1.734720]\n",
      "epoch:29 step:27969 [D loss: 0.394786, acc.: 88.28%] [G loss: 1.653861]\n",
      "epoch:29 step:27970 [D loss: 0.692142, acc.: 57.81%] [G loss: 1.090769]\n",
      "epoch:29 step:27971 [D loss: 0.595550, acc.: 66.41%] [G loss: 1.002338]\n",
      "epoch:29 step:27972 [D loss: 0.616654, acc.: 65.62%] [G loss: 1.136444]\n",
      "epoch:29 step:27973 [D loss: 0.716227, acc.: 53.12%] [G loss: 0.964194]\n",
      "epoch:29 step:27974 [D loss: 0.836640, acc.: 40.62%] [G loss: 1.122994]\n",
      "epoch:29 step:27975 [D loss: 0.587854, acc.: 68.75%] [G loss: 1.236233]\n",
      "epoch:29 step:27976 [D loss: 0.730728, acc.: 51.56%] [G loss: 0.958540]\n",
      "epoch:29 step:27977 [D loss: 0.505448, acc.: 76.56%] [G loss: 1.117358]\n",
      "epoch:29 step:27978 [D loss: 0.527594, acc.: 76.56%] [G loss: 1.174016]\n",
      "epoch:29 step:27979 [D loss: 0.400874, acc.: 82.81%] [G loss: 1.261322]\n",
      "epoch:29 step:27980 [D loss: 0.782363, acc.: 48.44%] [G loss: 1.029464]\n",
      "epoch:29 step:27981 [D loss: 0.341532, acc.: 95.31%] [G loss: 1.461128]\n",
      "epoch:29 step:27982 [D loss: 0.458713, acc.: 84.38%] [G loss: 1.359662]\n",
      "epoch:29 step:27983 [D loss: 0.576909, acc.: 71.88%] [G loss: 1.314551]\n",
      "epoch:29 step:27984 [D loss: 0.734402, acc.: 50.78%] [G loss: 1.117384]\n",
      "epoch:29 step:27985 [D loss: 0.786821, acc.: 46.88%] [G loss: 1.330874]\n",
      "epoch:29 step:27986 [D loss: 0.672778, acc.: 59.38%] [G loss: 1.072412]\n",
      "epoch:29 step:27987 [D loss: 0.689625, acc.: 55.47%] [G loss: 0.765884]\n",
      "epoch:29 step:27988 [D loss: 0.247785, acc.: 90.62%] [G loss: 1.374450]\n",
      "epoch:29 step:27989 [D loss: 0.258609, acc.: 92.97%] [G loss: 1.587757]\n",
      "epoch:29 step:27990 [D loss: 0.444381, acc.: 85.16%] [G loss: 1.526292]\n",
      "epoch:29 step:27991 [D loss: 0.435451, acc.: 89.06%] [G loss: 1.533186]\n",
      "epoch:29 step:27992 [D loss: 0.591645, acc.: 70.31%] [G loss: 1.115714]\n",
      "epoch:29 step:27993 [D loss: 0.576850, acc.: 69.53%] [G loss: 1.118590]\n",
      "epoch:29 step:27994 [D loss: 0.845139, acc.: 45.31%] [G loss: 0.900739]\n",
      "epoch:29 step:27995 [D loss: 0.829654, acc.: 47.66%] [G loss: 0.710087]\n",
      "epoch:29 step:27996 [D loss: 0.400520, acc.: 88.28%] [G loss: 1.189757]\n",
      "epoch:29 step:27997 [D loss: 0.237014, acc.: 94.53%] [G loss: 1.467309]\n",
      "epoch:29 step:27998 [D loss: 0.494396, acc.: 71.88%] [G loss: 0.933549]\n",
      "epoch:29 step:27999 [D loss: 0.818584, acc.: 48.44%] [G loss: 1.049899]\n",
      "epoch:29 step:28000 [D loss: 0.724678, acc.: 59.38%] [G loss: 1.392236]\n",
      "epoch:29 step:28001 [D loss: 0.858565, acc.: 45.31%] [G loss: 0.718209]\n",
      "epoch:29 step:28002 [D loss: 0.525792, acc.: 75.78%] [G loss: 1.227038]\n",
      "epoch:29 step:28003 [D loss: 0.445731, acc.: 85.16%] [G loss: 1.143423]\n",
      "epoch:29 step:28004 [D loss: 0.263300, acc.: 92.97%] [G loss: 1.666984]\n",
      "epoch:29 step:28005 [D loss: 0.569890, acc.: 60.94%] [G loss: 1.240839]\n",
      "epoch:29 step:28006 [D loss: 0.317643, acc.: 93.75%] [G loss: 1.398160]\n",
      "epoch:29 step:28007 [D loss: 1.020351, acc.: 46.09%] [G loss: 1.314440]\n",
      "epoch:29 step:28008 [D loss: 0.898541, acc.: 40.62%] [G loss: 1.147295]\n",
      "epoch:29 step:28009 [D loss: 0.862994, acc.: 40.62%] [G loss: 0.799505]\n",
      "epoch:29 step:28010 [D loss: 1.143222, acc.: 24.22%] [G loss: 0.559214]\n",
      "epoch:29 step:28011 [D loss: 0.667415, acc.: 61.72%] [G loss: 1.305831]\n",
      "epoch:29 step:28012 [D loss: 0.601937, acc.: 68.75%] [G loss: 1.126520]\n",
      "epoch:29 step:28013 [D loss: 0.786908, acc.: 46.88%] [G loss: 1.013618]\n",
      "epoch:29 step:28014 [D loss: 0.385581, acc.: 89.06%] [G loss: 1.420357]\n",
      "epoch:29 step:28015 [D loss: 0.518385, acc.: 77.34%] [G loss: 1.113206]\n",
      "epoch:29 step:28016 [D loss: 0.556633, acc.: 72.66%] [G loss: 1.045791]\n",
      "epoch:29 step:28017 [D loss: 0.677647, acc.: 58.59%] [G loss: 1.012356]\n",
      "epoch:29 step:28018 [D loss: 0.616147, acc.: 67.19%] [G loss: 1.121157]\n",
      "epoch:29 step:28019 [D loss: 0.583952, acc.: 70.31%] [G loss: 1.242825]\n",
      "epoch:29 step:28020 [D loss: 0.476182, acc.: 79.69%] [G loss: 1.232199]\n",
      "epoch:29 step:28021 [D loss: 0.460044, acc.: 78.91%] [G loss: 1.107478]\n",
      "epoch:29 step:28022 [D loss: 0.337034, acc.: 89.84%] [G loss: 1.107481]\n",
      "epoch:29 step:28023 [D loss: 0.250843, acc.: 97.66%] [G loss: 1.479222]\n",
      "epoch:29 step:28024 [D loss: 0.190856, acc.: 97.66%] [G loss: 1.609721]\n",
      "epoch:29 step:28025 [D loss: 0.195844, acc.: 98.44%] [G loss: 1.943327]\n",
      "epoch:29 step:28026 [D loss: 0.240701, acc.: 95.31%] [G loss: 1.894066]\n",
      "epoch:29 step:28027 [D loss: 0.179181, acc.: 98.44%] [G loss: 1.910663]\n",
      "epoch:29 step:28028 [D loss: 0.254307, acc.: 96.09%] [G loss: 2.382446]\n",
      "epoch:29 step:28029 [D loss: 0.506798, acc.: 71.09%] [G loss: 1.243799]\n",
      "epoch:29 step:28030 [D loss: 0.312781, acc.: 93.75%] [G loss: 1.249497]\n",
      "epoch:29 step:28031 [D loss: 0.707223, acc.: 55.47%] [G loss: 1.484679]\n",
      "epoch:29 step:28032 [D loss: 0.711107, acc.: 57.03%] [G loss: 1.099147]\n",
      "epoch:29 step:28033 [D loss: 0.583526, acc.: 65.62%] [G loss: 1.144716]\n",
      "epoch:29 step:28034 [D loss: 0.465742, acc.: 75.78%] [G loss: 1.229338]\n",
      "epoch:29 step:28035 [D loss: 0.560925, acc.: 69.53%] [G loss: 1.703241]\n",
      "epoch:29 step:28036 [D loss: 0.687773, acc.: 58.59%] [G loss: 1.015996]\n",
      "epoch:29 step:28037 [D loss: 0.676006, acc.: 60.16%] [G loss: 1.112624]\n",
      "epoch:29 step:28038 [D loss: 0.496828, acc.: 73.44%] [G loss: 1.469152]\n",
      "epoch:29 step:28039 [D loss: 0.562411, acc.: 71.09%] [G loss: 1.160153]\n",
      "epoch:29 step:28040 [D loss: 0.325084, acc.: 92.97%] [G loss: 1.657127]\n",
      "epoch:29 step:28041 [D loss: 0.904995, acc.: 35.94%] [G loss: 0.814461]\n",
      "epoch:29 step:28042 [D loss: 0.403347, acc.: 87.50%] [G loss: 1.343281]\n",
      "epoch:29 step:28043 [D loss: 0.693962, acc.: 53.91%] [G loss: 0.899457]\n",
      "epoch:29 step:28044 [D loss: 0.459197, acc.: 82.81%] [G loss: 0.935511]\n",
      "epoch:29 step:28045 [D loss: 0.398601, acc.: 87.50%] [G loss: 1.451280]\n",
      "epoch:29 step:28046 [D loss: 0.638065, acc.: 67.19%] [G loss: 0.721492]\n",
      "epoch:29 step:28047 [D loss: 0.562967, acc.: 72.66%] [G loss: 1.790981]\n",
      "epoch:29 step:28048 [D loss: 0.463268, acc.: 79.69%] [G loss: 1.108120]\n",
      "epoch:29 step:28049 [D loss: 0.802442, acc.: 48.44%] [G loss: 0.776760]\n",
      "epoch:29 step:28050 [D loss: 0.984650, acc.: 31.25%] [G loss: 1.009611]\n",
      "epoch:29 step:28051 [D loss: 1.101333, acc.: 24.22%] [G loss: 1.053020]\n",
      "epoch:29 step:28052 [D loss: 0.816439, acc.: 53.91%] [G loss: 1.204878]\n",
      "epoch:29 step:28053 [D loss: 0.462267, acc.: 85.16%] [G loss: 1.359625]\n",
      "epoch:29 step:28054 [D loss: 0.795152, acc.: 44.53%] [G loss: 1.132898]\n",
      "epoch:29 step:28055 [D loss: 0.939883, acc.: 40.62%] [G loss: 0.961474]\n",
      "epoch:29 step:28056 [D loss: 0.607821, acc.: 68.75%] [G loss: 1.003049]\n",
      "epoch:29 step:28057 [D loss: 0.447257, acc.: 82.03%] [G loss: 1.496732]\n",
      "epoch:29 step:28058 [D loss: 0.444283, acc.: 78.12%] [G loss: 1.411751]\n",
      "epoch:29 step:28059 [D loss: 0.525939, acc.: 72.66%] [G loss: 1.246767]\n",
      "epoch:29 step:28060 [D loss: 0.598902, acc.: 67.97%] [G loss: 1.416253]\n",
      "epoch:29 step:28061 [D loss: 1.003156, acc.: 28.91%] [G loss: 0.720504]\n",
      "epoch:29 step:28062 [D loss: 0.402208, acc.: 82.03%] [G loss: 1.801920]\n",
      "epoch:29 step:28063 [D loss: 0.552577, acc.: 76.56%] [G loss: 1.158405]\n",
      "epoch:29 step:28064 [D loss: 1.127536, acc.: 25.00%] [G loss: 0.908590]\n",
      "epoch:29 step:28065 [D loss: 0.735219, acc.: 57.81%] [G loss: 1.096651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28066 [D loss: 0.334018, acc.: 90.62%] [G loss: 1.946773]\n",
      "epoch:29 step:28067 [D loss: 0.320383, acc.: 89.84%] [G loss: 1.562225]\n",
      "epoch:29 step:28068 [D loss: 0.572255, acc.: 70.31%] [G loss: 1.477905]\n",
      "epoch:29 step:28069 [D loss: 0.195385, acc.: 98.44%] [G loss: 1.899957]\n",
      "epoch:29 step:28070 [D loss: 0.202001, acc.: 98.44%] [G loss: 1.842049]\n",
      "epoch:29 step:28071 [D loss: 0.154938, acc.: 98.44%] [G loss: 2.035897]\n",
      "epoch:29 step:28072 [D loss: 0.109962, acc.: 100.00%] [G loss: 2.762444]\n",
      "epoch:29 step:28073 [D loss: 0.125748, acc.: 100.00%] [G loss: 2.688625]\n",
      "epoch:29 step:28074 [D loss: 0.221241, acc.: 98.44%] [G loss: 1.803971]\n",
      "epoch:29 step:28075 [D loss: 0.373411, acc.: 84.38%] [G loss: 2.093618]\n",
      "epoch:29 step:28076 [D loss: 0.360259, acc.: 85.94%] [G loss: 1.911591]\n",
      "epoch:29 step:28077 [D loss: 0.665246, acc.: 60.16%] [G loss: 1.291614]\n",
      "epoch:29 step:28078 [D loss: 0.432973, acc.: 82.81%] [G loss: 1.602618]\n",
      "epoch:29 step:28079 [D loss: 0.547176, acc.: 70.31%] [G loss: 0.974543]\n",
      "epoch:29 step:28080 [D loss: 0.379457, acc.: 83.59%] [G loss: 1.096369]\n",
      "epoch:29 step:28081 [D loss: 0.195340, acc.: 100.00%] [G loss: 2.279059]\n",
      "epoch:29 step:28082 [D loss: 0.130688, acc.: 100.00%] [G loss: 1.977925]\n",
      "epoch:29 step:28083 [D loss: 0.491612, acc.: 76.56%] [G loss: 1.470888]\n",
      "epoch:29 step:28084 [D loss: 0.123700, acc.: 100.00%] [G loss: 1.896579]\n",
      "epoch:29 step:28085 [D loss: 0.069853, acc.: 100.00%] [G loss: 2.459064]\n",
      "epoch:29 step:28086 [D loss: 0.493167, acc.: 75.00%] [G loss: 1.596749]\n",
      "epoch:29 step:28087 [D loss: 0.360629, acc.: 88.28%] [G loss: 1.226167]\n",
      "epoch:29 step:28088 [D loss: 0.266899, acc.: 94.53%] [G loss: 1.196913]\n",
      "epoch:29 step:28089 [D loss: 0.374072, acc.: 91.41%] [G loss: 1.645205]\n",
      "epoch:29 step:28090 [D loss: 0.501582, acc.: 75.00%] [G loss: 1.208691]\n",
      "epoch:29 step:28091 [D loss: 0.422601, acc.: 82.03%] [G loss: 1.102976]\n",
      "epoch:29 step:28092 [D loss: 0.200129, acc.: 96.88%] [G loss: 2.069751]\n",
      "epoch:29 step:28093 [D loss: 1.210349, acc.: 50.78%] [G loss: 1.760213]\n",
      "epoch:29 step:28094 [D loss: 0.949281, acc.: 34.38%] [G loss: 0.840316]\n",
      "epoch:29 step:28095 [D loss: 0.601161, acc.: 64.84%] [G loss: 0.684158]\n",
      "epoch:29 step:28096 [D loss: 0.297751, acc.: 95.31%] [G loss: 1.535974]\n",
      "epoch:29 step:28097 [D loss: 0.278388, acc.: 93.75%] [G loss: 1.591296]\n",
      "epoch:29 step:28098 [D loss: 0.368557, acc.: 89.84%] [G loss: 1.571770]\n",
      "epoch:29 step:28099 [D loss: 0.295575, acc.: 92.97%] [G loss: 2.003740]\n",
      "epoch:29 step:28100 [D loss: 0.176057, acc.: 99.22%] [G loss: 2.280816]\n",
      "epoch:29 step:28101 [D loss: 1.226182, acc.: 46.88%] [G loss: 1.345607]\n",
      "epoch:29 step:28102 [D loss: 0.985433, acc.: 50.78%] [G loss: 1.534531]\n",
      "epoch:29 step:28103 [D loss: 0.832959, acc.: 41.41%] [G loss: 1.195757]\n",
      "epoch:29 step:28104 [D loss: 0.666004, acc.: 61.72%] [G loss: 1.049481]\n",
      "epoch:29 step:28105 [D loss: 0.989179, acc.: 49.22%] [G loss: 0.787716]\n",
      "epoch:29 step:28106 [D loss: 0.426362, acc.: 83.59%] [G loss: 1.358248]\n",
      "epoch:29 step:28107 [D loss: 0.228789, acc.: 95.31%] [G loss: 1.831067]\n",
      "epoch:29 step:28108 [D loss: 0.470849, acc.: 84.38%] [G loss: 1.381761]\n",
      "epoch:29 step:28109 [D loss: 0.356037, acc.: 91.41%] [G loss: 1.260808]\n",
      "epoch:29 step:28110 [D loss: 0.369226, acc.: 78.91%] [G loss: 1.044033]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # labels = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # Sample noise and generate a batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Train the generator (wants discriminator to mistake images as real)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % save_interval == 0:\n",
    "                    self.save_imgs(epoch,global_step)\n",
    "\n",
    "\n",
    "\n",
    "    def save_imgs(self, epoch,global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_dcgan'):\n",
    "            os.mkdir('images_dcgan')\n",
    "        fig.savefig(\"images_dcgan/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    dcgan.train(epochs=30, batch_size=64, save_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
