{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import torch\n",
    "from keras.utils.np_utils import *\n",
    "from keras.datasets import mnist\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH ='/home/imi432_006/huangdengrong/GAN-Research/metrics_gan/metrics/classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def calculate_labels(images,epoch,global_step):\n",
    "    label_dict={}\n",
    "    for i in range(10):\n",
    "        label_dict[i]=0\n",
    "    eval_images = tf.convert_to_tensor(images)\n",
    "    y_logit = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    labels=tf.argmax(y_logit, 1)\n",
    "    labels=tf.Session().run(labels)\n",
    "    for data in labels:\n",
    "        label_dict[data]+=1\n",
    "    for i in range(10):\n",
    "        label_dict[i]=label_dict[i]/len(images)\n",
    "    max_value=max(label_dict.values())\n",
    "    min_value=min(label_dict.values())\n",
    "    print('epoch:%d   global_step:%d'%(epoch,global_step))\n",
    "    print(label_dict)\n",
    "    print('chazhi:%.8f'%(max_value-min_value))\n",
    "    return label_dict,max_value-min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "(60000, 28, 28, 1)\n",
      "epoch:0   global_step:200\n",
      "{0: 0.0085, 1: 0.0, 2: 0.0026, 3: 0.0003, 4: 0.058, 5: 0.0, 6: 0.0, 7: 0.0448, 8: 0.8796, 9: 0.0062}\n",
      "chazhi:0.87960000\n",
      "epoch:0   global_step:400\n",
      "{0: 0.3012, 1: 0.0031, 2: 0.0005, 3: 0.0362, 4: 0.1319, 5: 0.0, 6: 0.0, 7: 0.0789, 8: 0.4481, 9: 0.0001}\n",
      "chazhi:0.44810000\n",
      "epoch:0   global_step:600\n",
      "{0: 0.0573, 1: 0.0206, 2: 0.0545, 3: 0.1265, 4: 0.121, 5: 0.0285, 6: 0.0002, 7: 0.2459, 8: 0.3286, 9: 0.0169}\n",
      "chazhi:0.32840000\n",
      "epoch:0   global_step:800\n",
      "{0: 0.1453, 1: 0.0414, 2: 0.0197, 3: 0.1991, 4: 0.1337, 5: 0.0083, 6: 0.0245, 7: 0.1138, 8: 0.2498, 9: 0.0644}\n",
      "chazhi:0.24150000\n",
      "epoch:1   global_step:1000\n",
      "{0: 0.1209, 1: 0.0419, 2: 0.0157, 3: 0.1485, 4: 0.2288, 5: 0.0186, 6: 0.1263, 7: 0.1257, 8: 0.1535, 9: 0.0201}\n",
      "chazhi:0.21310000\n",
      "epoch:1   global_step:1200\n",
      "{0: 0.0633, 1: 0.0292, 2: 0.1131, 3: 0.168, 4: 0.1181, 5: 0.0105, 6: 0.0009, 7: 0.1984, 8: 0.262, 9: 0.0365}\n",
      "chazhi:0.26110000\n",
      "epoch:1   global_step:1400\n",
      "{0: 0.1344, 1: 0.0476, 2: 0.0121, 3: 0.1295, 4: 0.1783, 5: 0.0246, 6: 0.0754, 7: 0.1282, 8: 0.248, 9: 0.0219}\n",
      "chazhi:0.23590000\n",
      "epoch:1   global_step:1600\n",
      "{0: 0.0943, 1: 0.0646, 2: 0.0606, 3: 0.1254, 4: 0.1795, 5: 0.0298, 6: 0.0498, 7: 0.1616, 8: 0.1878, 9: 0.0466}\n",
      "chazhi:0.15800000\n",
      "epoch:1   global_step:1800\n",
      "{0: 0.1303, 1: 0.0489, 2: 0.1246, 3: 0.1534, 4: 0.1455, 5: 0.0234, 6: 0.0403, 7: 0.1645, 8: 0.1272, 9: 0.0419}\n",
      "chazhi:0.14110000\n",
      "epoch:2   global_step:2000\n",
      "{0: 0.1299, 1: 0.0619, 2: 0.0758, 3: 0.0858, 4: 0.1401, 5: 0.0491, 6: 0.0755, 7: 0.1578, 8: 0.1762, 9: 0.0479}\n",
      "chazhi:0.12830000\n",
      "epoch:2   global_step:2200\n",
      "{0: 0.1348, 1: 0.0626, 2: 0.0739, 3: 0.1567, 4: 0.1036, 5: 0.0193, 6: 0.0658, 7: 0.1651, 8: 0.1805, 9: 0.0377}\n",
      "chazhi:0.16120000\n",
      "epoch:2   global_step:2400\n",
      "{0: 0.143, 1: 0.0563, 2: 0.0437, 3: 0.1417, 4: 0.1343, 5: 0.0389, 6: 0.0517, 7: 0.1227, 8: 0.2138, 9: 0.0539}\n",
      "chazhi:0.17490000\n",
      "epoch:2   global_step:2600\n",
      "{0: 0.0864, 1: 0.0548, 2: 0.0593, 3: 0.1387, 4: 0.1273, 5: 0.0377, 6: 0.0248, 7: 0.1695, 8: 0.2227, 9: 0.0788}\n",
      "chazhi:0.19790000\n",
      "epoch:2   global_step:2800\n",
      "{0: 0.0904, 1: 0.0515, 2: 0.0704, 3: 0.1596, 4: 0.1398, 5: 0.0323, 6: 0.0551, 7: 0.1729, 8: 0.1669, 9: 0.0611}\n",
      "chazhi:0.14060000\n",
      "epoch:3   global_step:3000\n",
      "{0: 0.1163, 1: 0.0924, 2: 0.0669, 3: 0.1181, 4: 0.1278, 5: 0.0367, 6: 0.0887, 7: 0.1779, 8: 0.1144, 9: 0.0608}\n",
      "chazhi:0.14120000\n",
      "epoch:3   global_step:3200\n",
      "{0: 0.1088, 1: 0.0969, 2: 0.0745, 3: 0.124, 4: 0.1351, 5: 0.0364, 6: 0.0873, 7: 0.1638, 8: 0.1399, 9: 0.0333}\n",
      "chazhi:0.13050000\n",
      "epoch:3   global_step:3400\n",
      "{0: 0.0869, 1: 0.1049, 2: 0.0911, 3: 0.1019, 4: 0.1135, 5: 0.0415, 6: 0.0651, 7: 0.1612, 8: 0.1366, 9: 0.0973}\n",
      "chazhi:0.11970000\n",
      "epoch:3   global_step:3600\n",
      "{0: 0.1104, 1: 0.0781, 2: 0.0511, 3: 0.1474, 4: 0.0796, 5: 0.0293, 6: 0.0864, 7: 0.1654, 8: 0.1505, 9: 0.1018}\n",
      "chazhi:0.13610000\n",
      "epoch:4   global_step:3800\n",
      "{0: 0.0985, 1: 0.0853, 2: 0.07, 3: 0.128, 4: 0.1151, 5: 0.0294, 6: 0.0966, 7: 0.1334, 8: 0.1739, 9: 0.0698}\n",
      "chazhi:0.14450000\n",
      "epoch:4   global_step:4000\n",
      "{0: 0.1125, 1: 0.0764, 2: 0.0775, 3: 0.1156, 4: 0.1523, 5: 0.0502, 6: 0.1095, 7: 0.1092, 8: 0.139, 9: 0.0578}\n",
      "chazhi:0.10210000\n",
      "epoch:4   global_step:4200\n",
      "{0: 0.109, 1: 0.0867, 2: 0.0806, 3: 0.1184, 4: 0.1284, 5: 0.043, 6: 0.0926, 7: 0.1485, 8: 0.1318, 9: 0.061}\n",
      "chazhi:0.10550000\n",
      "epoch:4   global_step:4400\n",
      "{0: 0.1098, 1: 0.0901, 2: 0.0658, 3: 0.1238, 4: 0.1372, 5: 0.0335, 6: 0.1111, 7: 0.1339, 8: 0.1252, 9: 0.0696}\n",
      "chazhi:0.10370000\n",
      "epoch:4   global_step:4600\n",
      "{0: 0.1377, 1: 0.0694, 2: 0.0882, 3: 0.1373, 4: 0.0919, 5: 0.0421, 6: 0.0878, 7: 0.148, 8: 0.1323, 9: 0.0653}\n",
      "chazhi:0.10590000\n",
      "epoch:5   global_step:4800\n",
      "{0: 0.0887, 1: 0.091, 2: 0.0701, 3: 0.1094, 4: 0.1542, 5: 0.0405, 6: 0.1161, 7: 0.13, 8: 0.1403, 9: 0.0597}\n",
      "chazhi:0.11370000\n",
      "epoch:5   global_step:5000\n",
      "{0: 0.099, 1: 0.1193, 2: 0.0808, 3: 0.1039, 4: 0.0845, 5: 0.0598, 6: 0.0822, 7: 0.1443, 8: 0.1395, 9: 0.0867}\n",
      "chazhi:0.08450000\n",
      "epoch:5   global_step:5200\n",
      "{0: 0.1046, 1: 0.0952, 2: 0.0743, 3: 0.1009, 4: 0.1332, 5: 0.0505, 6: 0.0789, 7: 0.137, 8: 0.1256, 9: 0.0998}\n",
      "chazhi:0.08650000\n",
      "epoch:5   global_step:5400\n",
      "{0: 0.0927, 1: 0.094, 2: 0.0877, 3: 0.1213, 4: 0.1166, 5: 0.0502, 6: 0.0808, 7: 0.1253, 8: 0.1512, 9: 0.0802}\n",
      "chazhi:0.10100000\n",
      "epoch:5   global_step:5600\n",
      "{0: 0.1016, 1: 0.081, 2: 0.0973, 3: 0.1377, 4: 0.1156, 5: 0.048, 6: 0.1015, 7: 0.1186, 8: 0.1234, 9: 0.0753}\n",
      "chazhi:0.08970000\n",
      "epoch:6   global_step:5800\n",
      "{0: 0.0859, 1: 0.0966, 2: 0.0661, 3: 0.1365, 4: 0.1329, 5: 0.0405, 6: 0.1145, 7: 0.1173, 8: 0.1282, 9: 0.0815}\n",
      "chazhi:0.09600000\n",
      "epoch:6   global_step:6000\n",
      "{0: 0.1056, 1: 0.0878, 2: 0.0719, 3: 0.1202, 4: 0.0943, 5: 0.0494, 6: 0.1127, 7: 0.1451, 8: 0.1343, 9: 0.0787}\n",
      "chazhi:0.09570000\n",
      "epoch:6   global_step:6200\n",
      "{0: 0.1112, 1: 0.0901, 2: 0.0837, 3: 0.0976, 4: 0.1223, 5: 0.0538, 6: 0.0977, 7: 0.1329, 8: 0.1322, 9: 0.0785}\n",
      "chazhi:0.07910000\n",
      "epoch:6   global_step:6400\n",
      "{0: 0.0953, 1: 0.0883, 2: 0.0496, 3: 0.1176, 4: 0.1423, 5: 0.0469, 6: 0.1174, 7: 0.1282, 8: 0.143, 9: 0.0714}\n",
      "chazhi:0.09610000\n",
      "epoch:7   global_step:6600\n",
      "{0: 0.1065, 1: 0.1004, 2: 0.0564, 3: 0.1049, 4: 0.1154, 5: 0.0605, 6: 0.1126, 7: 0.1286, 8: 0.1353, 9: 0.0794}\n",
      "chazhi:0.07890000\n",
      "epoch:7   global_step:6800\n",
      "{0: 0.105, 1: 0.0996, 2: 0.062, 3: 0.0994, 4: 0.1284, 5: 0.0479, 6: 0.1075, 7: 0.1236, 8: 0.1327, 9: 0.0939}\n",
      "chazhi:0.08480000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7   global_step:7000\n",
      "{0: 0.0987, 1: 0.1029, 2: 0.0955, 3: 0.1212, 4: 0.0986, 5: 0.0461, 6: 0.0984, 7: 0.132, 8: 0.1124, 9: 0.0942}\n",
      "chazhi:0.08590000\n",
      "epoch:7   global_step:7200\n",
      "{0: 0.1177, 1: 0.1066, 2: 0.0635, 3: 0.1142, 4: 0.1328, 5: 0.0496, 6: 0.0906, 7: 0.1208, 8: 0.1119, 9: 0.0923}\n",
      "chazhi:0.08320000\n",
      "epoch:7   global_step:7400\n",
      "{0: 0.0895, 1: 0.1206, 2: 0.0829, 3: 0.1015, 4: 0.1203, 5: 0.0533, 6: 0.1009, 7: 0.1305, 8: 0.1215, 9: 0.079}\n",
      "chazhi:0.07720000\n",
      "epoch:8   global_step:7600\n",
      "{0: 0.078, 1: 0.111, 2: 0.0762, 3: 0.1178, 4: 0.1565, 5: 0.0599, 6: 0.0928, 7: 0.108, 8: 0.1097, 9: 0.0901}\n",
      "chazhi:0.09660000\n",
      "epoch:8   global_step:7800\n",
      "{0: 0.1089, 1: 0.111, 2: 0.0657, 3: 0.1036, 4: 0.1378, 5: 0.0471, 6: 0.0912, 7: 0.1433, 8: 0.1071, 9: 0.0843}\n",
      "chazhi:0.09620000\n",
      "epoch:8   global_step:8000\n",
      "{0: 0.0904, 1: 0.0913, 2: 0.0628, 3: 0.1095, 4: 0.1332, 5: 0.0514, 6: 0.0969, 7: 0.1301, 8: 0.1369, 9: 0.0975}\n",
      "chazhi:0.08550000\n",
      "epoch:8   global_step:8200\n",
      "{0: 0.0849, 1: 0.1125, 2: 0.093, 3: 0.1063, 4: 0.1187, 5: 0.065, 6: 0.0786, 7: 0.1222, 8: 0.1271, 9: 0.0917}\n",
      "chazhi:0.06210000\n",
      "epoch:8   global_step:8400\n",
      "{0: 0.0976, 1: 0.108, 2: 0.0732, 3: 0.11, 4: 0.1581, 5: 0.0575, 6: 0.0911, 7: 0.1232, 8: 0.1126, 9: 0.0687}\n",
      "chazhi:0.10060000\n",
      "epoch:9   global_step:8600\n",
      "{0: 0.1034, 1: 0.1009, 2: 0.0775, 3: 0.1141, 4: 0.1192, 5: 0.0374, 6: 0.0972, 7: 0.127, 8: 0.1222, 9: 0.1011}\n",
      "chazhi:0.08960000\n",
      "epoch:9   global_step:8800\n",
      "{0: 0.1219, 1: 0.1147, 2: 0.067, 3: 0.0847, 4: 0.1235, 5: 0.0566, 6: 0.0932, 7: 0.114, 8: 0.1354, 9: 0.089}\n",
      "chazhi:0.07880000\n",
      "epoch:9   global_step:9000\n",
      "{0: 0.1003, 1: 0.0894, 2: 0.0767, 3: 0.1178, 4: 0.1158, 5: 0.0548, 6: 0.092, 7: 0.1269, 8: 0.1428, 9: 0.0835}\n",
      "chazhi:0.08800000\n",
      "epoch:9   global_step:9200\n",
      "{0: 0.113, 1: 0.1115, 2: 0.0742, 3: 0.1038, 4: 0.1215, 5: 0.0486, 6: 0.0898, 7: 0.1425, 8: 0.1241, 9: 0.071}\n",
      "chazhi:0.09390000\n",
      "epoch:10   global_step:9400\n",
      "{0: 0.1237, 1: 0.0982, 2: 0.0667, 3: 0.1183, 4: 0.1099, 5: 0.0518, 6: 0.1065, 7: 0.1153, 8: 0.1186, 9: 0.091}\n",
      "chazhi:0.07190000\n",
      "epoch:10   global_step:9600\n",
      "{0: 0.0995, 1: 0.1009, 2: 0.059, 3: 0.129, 4: 0.1146, 5: 0.052, 6: 0.1117, 7: 0.1253, 8: 0.1218, 9: 0.0862}\n",
      "chazhi:0.07700000\n",
      "epoch:10   global_step:9800\n",
      "{0: 0.1039, 1: 0.1068, 2: 0.0703, 3: 0.096, 4: 0.108, 5: 0.0501, 6: 0.0927, 7: 0.1268, 8: 0.1459, 9: 0.0995}\n",
      "chazhi:0.09580000\n",
      "epoch:10   global_step:10000\n",
      "{0: 0.1266, 1: 0.0964, 2: 0.0835, 3: 0.1015, 4: 0.1155, 5: 0.0529, 6: 0.0989, 7: 0.1218, 8: 0.1267, 9: 0.0762}\n",
      "chazhi:0.07380000\n",
      "epoch:10   global_step:10200\n",
      "{0: 0.1039, 1: 0.0931, 2: 0.084, 3: 0.0897, 4: 0.1319, 5: 0.0531, 6: 0.093, 7: 0.1321, 8: 0.1317, 9: 0.0875}\n",
      "chazhi:0.07900000\n",
      "epoch:11   global_step:10400\n",
      "{0: 0.1178, 1: 0.1155, 2: 0.0711, 3: 0.0941, 4: 0.1294, 5: 0.0479, 6: 0.0989, 7: 0.1247, 8: 0.1137, 9: 0.0869}\n",
      "chazhi:0.08150000\n",
      "epoch:11   global_step:10600\n",
      "{0: 0.1157, 1: 0.1116, 2: 0.0795, 3: 0.1, 4: 0.1071, 5: 0.0568, 6: 0.0979, 7: 0.1318, 8: 0.1259, 9: 0.0737}\n",
      "chazhi:0.07500000\n",
      "epoch:11   global_step:10800\n",
      "{0: 0.1095, 1: 0.1126, 2: 0.0688, 3: 0.0967, 4: 0.1001, 5: 0.0596, 6: 0.1153, 7: 0.131, 8: 0.1301, 9: 0.0763}\n",
      "chazhi:0.07140000\n",
      "epoch:11   global_step:11000\n",
      "{0: 0.0994, 1: 0.1151, 2: 0.0709, 3: 0.094, 4: 0.1088, 5: 0.0491, 6: 0.1155, 7: 0.1493, 8: 0.1268, 9: 0.0711}\n",
      "chazhi:0.10020000\n",
      "epoch:11   global_step:11200\n",
      "{0: 0.1171, 1: 0.1004, 2: 0.0784, 3: 0.1011, 4: 0.1053, 5: 0.067, 6: 0.1064, 7: 0.1341, 8: 0.1157, 9: 0.0745}\n",
      "chazhi:0.06710000\n",
      "epoch:12   global_step:11400\n",
      "{0: 0.1083, 1: 0.1154, 2: 0.0635, 3: 0.1088, 4: 0.0924, 5: 0.0508, 6: 0.1072, 7: 0.1543, 8: 0.1199, 9: 0.0794}\n",
      "chazhi:0.10350000\n",
      "epoch:12   global_step:11600\n",
      "{0: 0.0993, 1: 0.1049, 2: 0.0602, 3: 0.1038, 4: 0.1193, 5: 0.0607, 6: 0.1095, 7: 0.1364, 8: 0.1297, 9: 0.0762}\n",
      "chazhi:0.07620000\n",
      "epoch:12   global_step:11800\n",
      "{0: 0.116, 1: 0.1023, 2: 0.0798, 3: 0.1179, 4: 0.1089, 5: 0.0449, 6: 0.1048, 7: 0.1238, 8: 0.1161, 9: 0.0855}\n",
      "chazhi:0.07890000\n",
      "epoch:12   global_step:12000\n",
      "{0: 0.1012, 1: 0.1188, 2: 0.0844, 3: 0.1156, 4: 0.1224, 5: 0.0557, 6: 0.1081, 7: 0.1266, 8: 0.1004, 9: 0.0668}\n",
      "chazhi:0.07090000\n",
      "epoch:13   global_step:12200\n",
      "{0: 0.1084, 1: 0.0967, 2: 0.0738, 3: 0.1071, 4: 0.1224, 5: 0.0624, 6: 0.1082, 7: 0.1231, 8: 0.1206, 9: 0.0773}\n",
      "chazhi:0.06070000\n",
      "epoch:13   global_step:12400\n",
      "{0: 0.1121, 1: 0.1103, 2: 0.0767, 3: 0.1067, 4: 0.1171, 5: 0.0568, 6: 0.0961, 7: 0.1241, 8: 0.115, 9: 0.0851}\n",
      "chazhi:0.06730000\n",
      "epoch:13   global_step:12600\n",
      "{0: 0.0955, 1: 0.1133, 2: 0.0741, 3: 0.1034, 4: 0.1256, 5: 0.0566, 6: 0.1034, 7: 0.127, 8: 0.1265, 9: 0.0746}\n",
      "chazhi:0.07040000\n",
      "epoch:13   global_step:12800\n",
      "{0: 0.1064, 1: 0.1036, 2: 0.0837, 3: 0.113, 4: 0.1169, 5: 0.045, 6: 0.0995, 7: 0.1411, 8: 0.1147, 9: 0.0761}\n",
      "chazhi:0.09610000\n",
      "epoch:13   global_step:13000\n",
      "{0: 0.0968, 1: 0.1115, 2: 0.0689, 3: 0.1055, 4: 0.1122, 5: 0.0585, 6: 0.1003, 7: 0.1264, 8: 0.126, 9: 0.0939}\n",
      "chazhi:0.06790000\n",
      "epoch:14   global_step:13200\n",
      "{0: 0.1162, 1: 0.0861, 2: 0.0797, 3: 0.1146, 4: 0.1111, 5: 0.0589, 6: 0.1099, 7: 0.1265, 8: 0.1086, 9: 0.0884}\n",
      "chazhi:0.06760000\n",
      "epoch:14   global_step:13400\n",
      "{0: 0.1033, 1: 0.1007, 2: 0.0578, 3: 0.1112, 4: 0.1093, 5: 0.0601, 6: 0.1005, 7: 0.1286, 8: 0.1327, 9: 0.0958}\n",
      "chazhi:0.07490000\n",
      "epoch:14   global_step:13600\n",
      "{0: 0.1, 1: 0.0994, 2: 0.0772, 3: 0.1066, 4: 0.1127, 5: 0.0484, 6: 0.0901, 7: 0.1401, 8: 0.1327, 9: 0.0928}\n",
      "chazhi:0.09170000\n",
      "epoch:14   global_step:13800\n",
      "{0: 0.1037, 1: 0.1017, 2: 0.065, 3: 0.0949, 4: 0.1257, 5: 0.0619, 6: 0.1018, 7: 0.1377, 8: 0.1185, 9: 0.0891}\n",
      "chazhi:0.07580000\n",
      "epoch:14   global_step:14000\n",
      "{0: 0.1149, 1: 0.1119, 2: 0.0766, 3: 0.1022, 4: 0.1162, 5: 0.0592, 6: 0.1038, 7: 0.1331, 8: 0.1054, 9: 0.0767}\n",
      "chazhi:0.07390000\n",
      "epoch:15   global_step:14200\n",
      "{0: 0.1197, 1: 0.1105, 2: 0.0712, 3: 0.1011, 4: 0.13, 5: 0.0559, 6: 0.0993, 7: 0.1068, 8: 0.1148, 9: 0.0907}\n",
      "chazhi:0.07410000\n",
      "epoch:15   global_step:14400\n",
      "{0: 0.1027, 1: 0.1197, 2: 0.0669, 3: 0.0917, 4: 0.1261, 5: 0.0602, 6: 0.0981, 7: 0.1329, 8: 0.1157, 9: 0.086}\n",
      "chazhi:0.07270000\n",
      "epoch:15   global_step:14600\n",
      "{0: 0.1205, 1: 0.0956, 2: 0.0782, 3: 0.1165, 4: 0.1066, 5: 0.0713, 6: 0.1032, 7: 0.0951, 8: 0.1193, 9: 0.0937}\n",
      "chazhi:0.04920000\n",
      "epoch:15   global_step:14800\n",
      "{0: 0.1153, 1: 0.103, 2: 0.0735, 3: 0.1063, 4: 0.1328, 5: 0.0576, 6: 0.0878, 7: 0.1202, 8: 0.1149, 9: 0.0886}\n",
      "chazhi:0.07520000\n",
      "epoch:16   global_step:15000\n",
      "{0: 0.1137, 1: 0.1016, 2: 0.0763, 3: 0.1092, 4: 0.1251, 5: 0.0585, 6: 0.1163, 7: 0.1213, 8: 0.1053, 9: 0.0727}\n",
      "chazhi:0.06660000\n",
      "epoch:16   global_step:15200\n",
      "{0: 0.0901, 1: 0.1192, 2: 0.0864, 3: 0.0984, 4: 0.1189, 5: 0.0551, 6: 0.095, 7: 0.1296, 8: 0.1303, 9: 0.077}\n",
      "chazhi:0.07520000\n",
      "epoch:16   global_step:15400\n",
      "{0: 0.1243, 1: 0.1271, 2: 0.0729, 3: 0.1046, 4: 0.1124, 5: 0.0555, 6: 0.0943, 7: 0.1279, 8: 0.1132, 9: 0.0678}\n",
      "chazhi:0.07240000\n",
      "epoch:16   global_step:15600\n",
      "{0: 0.1214, 1: 0.115, 2: 0.0832, 3: 0.0845, 4: 0.1129, 5: 0.0568, 6: 0.1017, 7: 0.1176, 8: 0.1219, 9: 0.085}\n",
      "chazhi:0.06510000\n",
      "epoch:16   global_step:15800\n",
      "{0: 0.1227, 1: 0.099, 2: 0.0732, 3: 0.0902, 4: 0.1261, 5: 0.0581, 6: 0.0845, 7: 0.1204, 8: 0.1272, 9: 0.0986}\n",
      "chazhi:0.06910000\n",
      "epoch:17   global_step:16000\n",
      "{0: 0.1138, 1: 0.0891, 2: 0.0797, 3: 0.1199, 4: 0.1184, 5: 0.0566, 6: 0.0982, 7: 0.1387, 8: 0.1068, 9: 0.0788}\n",
      "chazhi:0.08210000\n",
      "epoch:17   global_step:16200\n",
      "{0: 0.1068, 1: 0.1131, 2: 0.0698, 3: 0.1025, 4: 0.1105, 5: 0.0462, 6: 0.0957, 7: 0.1235, 8: 0.1367, 9: 0.0952}\n",
      "chazhi:0.09050000\n",
      "epoch:17   global_step:16400\n",
      "{0: 0.0931, 1: 0.1178, 2: 0.0732, 3: 0.0826, 4: 0.1337, 5: 0.0548, 6: 0.1019, 7: 0.1268, 8: 0.1231, 9: 0.093}\n",
      "chazhi:0.07890000\n",
      "epoch:17   global_step:16600\n",
      "{0: 0.1065, 1: 0.1001, 2: 0.0761, 3: 0.081, 4: 0.1136, 5: 0.0527, 6: 0.1162, 7: 0.1133, 8: 0.1311, 9: 0.1094}\n",
      "chazhi:0.07840000\n",
      "epoch:17   global_step:16800\n",
      "{0: 0.1137, 1: 0.1122, 2: 0.0822, 3: 0.0928, 4: 0.1226, 5: 0.0502, 6: 0.1154, 7: 0.119, 8: 0.1046, 9: 0.0873}\n",
      "chazhi:0.07240000\n",
      "epoch:18   global_step:17000\n",
      "{0: 0.0984, 1: 0.1216, 2: 0.0746, 3: 0.1178, 4: 0.1156, 5: 0.0464, 6: 0.0791, 7: 0.1454, 8: 0.1124, 9: 0.0887}\n",
      "chazhi:0.09900000\n",
      "epoch:18   global_step:17200\n",
      "{0: 0.1058, 1: 0.1081, 2: 0.0715, 3: 0.106, 4: 0.121, 5: 0.0532, 6: 0.0998, 7: 0.1136, 8: 0.1228, 9: 0.0982}\n",
      "chazhi:0.06960000\n",
      "epoch:18   global_step:17400\n",
      "{0: 0.093, 1: 0.1278, 2: 0.0792, 3: 0.107, 4: 0.118, 5: 0.0476, 6: 0.1022, 7: 0.1274, 8: 0.107, 9: 0.0908}\n",
      "chazhi:0.08020000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18   global_step:17600\n",
      "{0: 0.1027, 1: 0.1277, 2: 0.0818, 3: 0.0906, 4: 0.1237, 5: 0.0525, 6: 0.0995, 7: 0.1194, 8: 0.113, 9: 0.0891}\n",
      "chazhi:0.07520000\n",
      "epoch:18   global_step:17800\n",
      "{0: 0.1296, 1: 0.126, 2: 0.0823, 3: 0.0883, 4: 0.0954, 5: 0.0652, 6: 0.1025, 7: 0.1152, 8: 0.1189, 9: 0.0766}\n",
      "chazhi:0.06440000\n",
      "epoch:19   global_step:18000\n",
      "{0: 0.1388, 1: 0.1176, 2: 0.0708, 3: 0.0946, 4: 0.1092, 5: 0.0444, 6: 0.109, 7: 0.1317, 8: 0.1044, 9: 0.0795}\n",
      "chazhi:0.09440000\n",
      "epoch:19   global_step:18200\n",
      "{0: 0.1005, 1: 0.128, 2: 0.0808, 3: 0.1059, 4: 0.1315, 5: 0.0589, 6: 0.1019, 7: 0.1202, 8: 0.1007, 9: 0.0716}\n",
      "chazhi:0.07260000\n",
      "epoch:19   global_step:18400\n",
      "{0: 0.1169, 1: 0.0958, 2: 0.069, 3: 0.116, 4: 0.1076, 5: 0.0701, 6: 0.0939, 7: 0.1205, 8: 0.1154, 9: 0.0948}\n",
      "chazhi:0.05150000\n",
      "epoch:19   global_step:18600\n",
      "{0: 0.1063, 1: 0.1101, 2: 0.0723, 3: 0.1002, 4: 0.0984, 5: 0.0622, 6: 0.0979, 7: 0.1262, 8: 0.1175, 9: 0.1089}\n",
      "chazhi:0.06400000\n",
      "epoch:20   global_step:18800\n",
      "{0: 0.1143, 1: 0.1103, 2: 0.0707, 3: 0.1195, 4: 0.1027, 5: 0.0648, 6: 0.1056, 7: 0.1112, 8: 0.1138, 9: 0.0871}\n",
      "chazhi:0.05470000\n",
      "epoch:20   global_step:19000\n",
      "{0: 0.0893, 1: 0.1071, 2: 0.0784, 3: 0.107, 4: 0.1294, 5: 0.0575, 6: 0.0936, 7: 0.1325, 8: 0.1131, 9: 0.0921}\n",
      "chazhi:0.07500000\n",
      "epoch:20   global_step:19200\n",
      "{0: 0.092, 1: 0.1121, 2: 0.0805, 3: 0.0925, 4: 0.1215, 5: 0.0702, 6: 0.1177, 7: 0.113, 8: 0.1149, 9: 0.0856}\n",
      "chazhi:0.05130000\n",
      "epoch:20   global_step:19400\n",
      "{0: 0.0878, 1: 0.1309, 2: 0.0698, 3: 0.0897, 4: 0.1028, 5: 0.0604, 6: 0.0929, 7: 0.1355, 8: 0.1345, 9: 0.0957}\n",
      "chazhi:0.07510000\n",
      "epoch:20   global_step:19600\n",
      "{0: 0.1048, 1: 0.101, 2: 0.0694, 3: 0.0849, 4: 0.131, 5: 0.0674, 6: 0.1204, 7: 0.1158, 8: 0.1149, 9: 0.0904}\n",
      "chazhi:0.06360000\n",
      "epoch:21   global_step:19800\n",
      "{0: 0.1091, 1: 0.1025, 2: 0.0698, 3: 0.1045, 4: 0.1109, 5: 0.0599, 6: 0.088, 7: 0.1334, 8: 0.1297, 9: 0.0922}\n",
      "chazhi:0.07350000\n",
      "epoch:21   global_step:20000\n",
      "{0: 0.1073, 1: 0.1131, 2: 0.0723, 3: 0.0903, 4: 0.1144, 5: 0.0589, 6: 0.0906, 7: 0.1247, 8: 0.1193, 9: 0.1091}\n",
      "chazhi:0.06580000\n",
      "epoch:21   global_step:20200\n",
      "{0: 0.0953, 1: 0.1066, 2: 0.0862, 3: 0.1031, 4: 0.1125, 5: 0.0551, 6: 0.1004, 7: 0.1335, 8: 0.1121, 9: 0.0952}\n",
      "chazhi:0.07840000\n",
      "epoch:21   global_step:20400\n",
      "{0: 0.1121, 1: 0.0939, 2: 0.0788, 3: 0.1024, 4: 0.1317, 5: 0.0626, 6: 0.0985, 7: 0.1154, 8: 0.1182, 9: 0.0864}\n",
      "chazhi:0.06910000\n",
      "epoch:21   global_step:20600\n",
      "{0: 0.1015, 1: 0.1169, 2: 0.0779, 3: 0.1162, 4: 0.1133, 5: 0.0655, 6: 0.1, 7: 0.1207, 8: 0.1149, 9: 0.0731}\n",
      "chazhi:0.05520000\n",
      "epoch:22   global_step:20800\n",
      "{0: 0.1109, 1: 0.1156, 2: 0.0808, 3: 0.1019, 4: 0.1157, 5: 0.0621, 6: 0.102, 7: 0.1219, 8: 0.1142, 9: 0.0749}\n",
      "chazhi:0.05980000\n",
      "epoch:22   global_step:21000\n",
      "{0: 0.0961, 1: 0.1118, 2: 0.0838, 3: 0.1086, 4: 0.116, 5: 0.0682, 6: 0.1016, 7: 0.1216, 8: 0.1112, 9: 0.0811}\n",
      "chazhi:0.05340000\n",
      "epoch:22   global_step:21200\n",
      "{0: 0.094, 1: 0.1288, 2: 0.0616, 3: 0.0996, 4: 0.1085, 5: 0.0702, 6: 0.1099, 7: 0.1203, 8: 0.1225, 9: 0.0846}\n",
      "chazhi:0.06720000\n",
      "epoch:22   global_step:21400\n",
      "{0: 0.1075, 1: 0.1168, 2: 0.0794, 3: 0.0916, 4: 0.1321, 5: 0.0599, 6: 0.0961, 7: 0.102, 8: 0.1204, 9: 0.0942}\n",
      "chazhi:0.07220000\n",
      "epoch:23   global_step:21600\n",
      "{0: 0.082, 1: 0.1123, 2: 0.082, 3: 0.0938, 4: 0.1365, 5: 0.0553, 6: 0.1042, 7: 0.1208, 8: 0.1217, 9: 0.0914}\n",
      "chazhi:0.08120000\n",
      "epoch:23   global_step:21800\n",
      "{0: 0.099, 1: 0.106, 2: 0.062, 3: 0.1058, 4: 0.123, 5: 0.0561, 6: 0.0893, 7: 0.1319, 8: 0.1222, 9: 0.1047}\n",
      "chazhi:0.07580000\n",
      "epoch:23   global_step:22000\n",
      "{0: 0.106, 1: 0.1071, 2: 0.0661, 3: 0.1121, 4: 0.1099, 5: 0.0747, 6: 0.1124, 7: 0.1386, 8: 0.1012, 9: 0.0719}\n",
      "chazhi:0.07250000\n",
      "epoch:23   global_step:22200\n",
      "{0: 0.1323, 1: 0.1091, 2: 0.071, 3: 0.1106, 4: 0.1088, 5: 0.0569, 6: 0.0997, 7: 0.1139, 8: 0.1042, 9: 0.0935}\n",
      "chazhi:0.07540000\n",
      "epoch:23   global_step:22400\n",
      "{0: 0.095, 1: 0.0981, 2: 0.078, 3: 0.0878, 4: 0.1231, 5: 0.0663, 6: 0.0955, 7: 0.143, 8: 0.1234, 9: 0.0898}\n",
      "chazhi:0.07670000\n",
      "epoch:24   global_step:22600\n",
      "{0: 0.1334, 1: 0.1088, 2: 0.0613, 3: 0.108, 4: 0.1122, 5: 0.0577, 6: 0.1139, 7: 0.1138, 8: 0.1185, 9: 0.0724}\n",
      "chazhi:0.07570000\n",
      "epoch:24   global_step:22800\n",
      "{0: 0.118, 1: 0.1155, 2: 0.0719, 3: 0.109, 4: 0.1159, 5: 0.0587, 6: 0.0883, 7: 0.1299, 8: 0.1, 9: 0.0928}\n",
      "chazhi:0.07120000\n",
      "epoch:24   global_step:23000\n",
      "{0: 0.1037, 1: 0.1067, 2: 0.0725, 3: 0.1038, 4: 0.118, 5: 0.0601, 6: 0.1008, 7: 0.1154, 8: 0.1226, 9: 0.0964}\n",
      "chazhi:0.06250000\n",
      "epoch:24   global_step:23200\n",
      "{0: 0.1021, 1: 0.122, 2: 0.067, 3: 0.0882, 4: 0.0974, 5: 0.0699, 6: 0.0985, 7: 0.1365, 8: 0.1175, 9: 0.1009}\n",
      "chazhi:0.06950000\n",
      "epoch:24   global_step:23400\n",
      "{0: 0.0987, 1: 0.1211, 2: 0.0808, 3: 0.0981, 4: 0.1327, 5: 0.0581, 6: 0.0964, 7: 0.1233, 8: 0.113, 9: 0.0778}\n",
      "chazhi:0.07460000\n",
      "epoch:25   global_step:23600\n",
      "{0: 0.1216, 1: 0.1108, 2: 0.0897, 3: 0.1024, 4: 0.1181, 5: 0.049, 6: 0.095, 7: 0.1168, 8: 0.1076, 9: 0.089}\n",
      "chazhi:0.07260000\n",
      "epoch:25   global_step:23800\n",
      "{0: 0.1349, 1: 0.1129, 2: 0.069, 3: 0.0962, 4: 0.1036, 5: 0.0617, 6: 0.0892, 7: 0.1158, 8: 0.1269, 9: 0.0898}\n",
      "chazhi:0.07320000\n",
      "epoch:25   global_step:24000\n",
      "{0: 0.1048, 1: 0.1145, 2: 0.0693, 3: 0.1012, 4: 0.1146, 5: 0.0664, 6: 0.1004, 7: 0.1279, 8: 0.1077, 9: 0.0932}\n",
      "chazhi:0.06150000\n",
      "epoch:25   global_step:24200\n",
      "{0: 0.0964, 1: 0.1039, 2: 0.0674, 3: 0.0892, 4: 0.1197, 5: 0.0664, 6: 0.1011, 7: 0.1315, 8: 0.1152, 9: 0.1092}\n",
      "chazhi:0.06510000\n",
      "epoch:26   global_step:24400\n",
      "{0: 0.1101, 1: 0.1062, 2: 0.0755, 3: 0.1016, 4: 0.1105, 5: 0.061, 6: 0.1001, 7: 0.1334, 8: 0.0978, 9: 0.1038}\n",
      "chazhi:0.07240000\n",
      "epoch:26   global_step:24600\n",
      "{0: 0.106, 1: 0.1072, 2: 0.0738, 3: 0.0991, 4: 0.1335, 5: 0.0622, 6: 0.0968, 7: 0.1249, 8: 0.1064, 9: 0.0901}\n",
      "chazhi:0.07130000\n",
      "epoch:26   global_step:24800\n",
      "{0: 0.0897, 1: 0.1161, 2: 0.0845, 3: 0.1087, 4: 0.0949, 5: 0.0597, 6: 0.0972, 7: 0.1197, 8: 0.1319, 9: 0.0976}\n",
      "chazhi:0.07220000\n",
      "epoch:26   global_step:25000\n",
      "{0: 0.1187, 1: 0.1291, 2: 0.0581, 3: 0.1017, 4: 0.1097, 5: 0.0556, 6: 0.1102, 7: 0.1157, 8: 0.1049, 9: 0.0963}\n",
      "chazhi:0.07350000\n",
      "epoch:26   global_step:25200\n",
      "{0: 0.1212, 1: 0.1115, 2: 0.0626, 3: 0.1001, 4: 0.1126, 5: 0.0585, 6: 0.1003, 7: 0.1212, 8: 0.1176, 9: 0.0944}\n",
      "chazhi:0.06270000\n",
      "epoch:27   global_step:25400\n",
      "{0: 0.1036, 1: 0.1113, 2: 0.0766, 3: 0.0825, 4: 0.1121, 5: 0.0622, 6: 0.1072, 7: 0.1438, 8: 0.105, 9: 0.0957}\n",
      "chazhi:0.08160000\n",
      "epoch:27   global_step:25600\n",
      "{0: 0.0955, 1: 0.1189, 2: 0.0714, 3: 0.0993, 4: 0.102, 5: 0.0624, 6: 0.1008, 7: 0.1254, 8: 0.1212, 9: 0.1031}\n",
      "chazhi:0.06300000\n",
      "epoch:27   global_step:25800\n",
      "{0: 0.1046, 1: 0.1146, 2: 0.0726, 3: 0.0917, 4: 0.0901, 5: 0.0673, 6: 0.106, 7: 0.1222, 8: 0.1294, 9: 0.1015}\n",
      "chazhi:0.06210000\n",
      "epoch:27   global_step:26000\n",
      "{0: 0.1075, 1: 0.1108, 2: 0.0764, 3: 0.0971, 4: 0.1002, 5: 0.0511, 6: 0.0943, 7: 0.1166, 8: 0.1378, 9: 0.1082}\n",
      "chazhi:0.08670000\n",
      "epoch:27   global_step:26200\n",
      "{0: 0.1033, 1: 0.1233, 2: 0.0783, 3: 0.0851, 4: 0.115, 5: 0.0579, 6: 0.0943, 7: 0.1376, 8: 0.1134, 9: 0.0918}\n",
      "chazhi:0.07970000\n",
      "epoch:28   global_step:26400\n",
      "{0: 0.0952, 1: 0.1365, 2: 0.0581, 3: 0.1064, 4: 0.1112, 5: 0.0629, 6: 0.111, 7: 0.1119, 8: 0.1031, 9: 0.1037}\n",
      "chazhi:0.07840000\n",
      "epoch:28   global_step:26600\n",
      "{0: 0.1358, 1: 0.1124, 2: 0.0626, 3: 0.0945, 4: 0.115, 5: 0.0678, 6: 0.1008, 7: 0.1072, 8: 0.1115, 9: 0.0924}\n",
      "chazhi:0.07320000\n",
      "epoch:28   global_step:26800\n",
      "{0: 0.0992, 1: 0.1165, 2: 0.0697, 3: 0.0971, 4: 0.1144, 5: 0.0573, 6: 0.1013, 7: 0.1267, 8: 0.1308, 9: 0.087}\n",
      "chazhi:0.07350000\n",
      "epoch:28   global_step:27000\n",
      "{0: 0.117, 1: 0.113, 2: 0.0664, 3: 0.0956, 4: 0.1101, 5: 0.0551, 6: 0.1095, 7: 0.1488, 8: 0.0987, 9: 0.0858}\n",
      "chazhi:0.09370000\n",
      "epoch:29   global_step:27200\n",
      "{0: 0.0946, 1: 0.1066, 2: 0.0656, 3: 0.1043, 4: 0.133, 5: 0.0604, 6: 0.1008, 7: 0.1417, 8: 0.1062, 9: 0.0868}\n",
      "chazhi:0.08130000\n",
      "epoch:29   global_step:27400\n",
      "{0: 0.1054, 1: 0.1048, 2: 0.066, 3: 0.1006, 4: 0.1303, 5: 0.0563, 6: 0.1033, 7: 0.1107, 8: 0.1288, 9: 0.0938}\n",
      "chazhi:0.07400000\n",
      "epoch:29   global_step:27600\n",
      "{0: 0.1193, 1: 0.1025, 2: 0.0858, 3: 0.1095, 4: 0.1107, 5: 0.0575, 6: 0.0863, 7: 0.1388, 8: 0.101, 9: 0.0886}\n",
      "chazhi:0.08130000\n",
      "epoch:29   global_step:27800\n",
      "{0: 0.1135, 1: 0.1024, 2: 0.0789, 3: 0.104, 4: 0.1229, 5: 0.0613, 6: 0.0976, 7: 0.1123, 8: 0.1193, 9: 0.0878}\n",
      "chazhi:0.06160000\n",
      "epoch:29   global_step:28000\n",
      "{0: 0.1145, 1: 0.1067, 2: 0.0759, 3: 0.0885, 4: 0.1096, 5: 0.0634, 6: 0.0989, 7: 0.1234, 8: 0.1311, 9: 0.088}\n",
      "chazhi:0.06770000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam #optimizer of keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels) #shape of image\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5) #optimizer of gan\n",
    "\n",
    "        # Build and compile the discriminator,only to keras\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))  #Input():用来实例化一个keras张量\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "\n",
    "        X_train = np.expand_dims(X_train, axis=3)  #expand_dims用于扩充数组形状\n",
    "        print(np.shape(X_train))\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        steps=[]\n",
    "        values=[]\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "               \n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "    \n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                # Train the generator (to have the discriminator label samples as valid)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    label_dict,value=self.mode_drop(epoch,global_step)\n",
    "                    steps.append(global_step)\n",
    "                    values.append(value)\n",
    "#             plt.subplots(1, 1)\n",
    "        plt.plot(steps,values)\n",
    "        plt.xlim([0,40000])\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.xlabel('steps')\n",
    "        plt.ylabel('epochs')\n",
    "        plt.tick_params(axis='both',which='major',labelsize=13)\n",
    "        plt.legend(loc='lower right')\n",
    "        if not os.path.isdir('images_gan'):\n",
    "            os.mkdir('images_gan')\n",
    "        plt.savefig(\"images_gan/mode_drop.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "\n",
    "        if not os.path.isdir('images_gan'):\n",
    "            os.mkdir('images_gan')\n",
    "        fig.savefig(\"images_gan/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "    def mode_drop(self,epoch,global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        label_dict,value=calculate_labels(gen_imgs,epoch,global_step)\n",
    "        return label_dict,value\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=30, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
