{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import torch\n",
    "from keras.utils.np_utils import *\n",
    "from keras.datasets import mnist\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH ='/home/imi432_006/huangdengrong/GAN-Research/metrics_gan/metrics/classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def calculate_labels(images,epoch,global_step):\n",
    "    images=[cv2.resize(i,(28,28)) for i in images]\n",
    "    images=np.expand_dims(images,axis=3)\n",
    "    label_dict={}\n",
    "    for i in range(10):\n",
    "        label_dict[i]=0\n",
    "    eval_images = tf.convert_to_tensor(images)\n",
    "    y_logit = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    labels=tf.argmax(y_logit, 1)\n",
    "    labels=tf.Session().run(labels)\n",
    "    for data in labels:\n",
    "        label_dict[data]+=1\n",
    "    for i in range(10):\n",
    "        label_dict[i]=label_dict[i]/len(images)\n",
    "    max_value=max(label_dict.values())\n",
    "    min_value=min(label_dict.values())\n",
    "    print('epoch:%d   global_step:%d'%(epoch,global_step))\n",
    "    print(label_dict)\n",
    "    print('chazhi:%.8f'%(max_value-min_value))\n",
    "    return label_dict,max_value-min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_5 (Conv2DTr (None, 4, 4, 512)         147968    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 8, 8, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 16, 16, 128)       295040    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 1)         577       \n",
      "=================================================================\n",
      "Total params: 1,697,281\n",
      "Trainable params: 1,697,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sn_conv2d_6 (SNConv2D)       (None, 16, 16, 64)        704       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "sn_conv2d_7 (SNConv2D)       (None, 8, 8, 128)         73984     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "sn_conv2d_8 (SNConv2D)       (None, 4, 4, 256)         295424    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "sn_conv2d_9 (SNConv2D)       (None, 2, 2, 512)         1180672   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "sn_conv2d_10 (SNConv2D)      (None, 2, 2, 1)           4610      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,555,394\n",
      "Trainable params: 1,554,433\n",
      "Non-trainable params: 961\n",
      "_________________________________________________________________\n",
      "epoch:0   global_step:200\n",
      "{0: 0.0, 1: 0.9991, 2: 0.0, 3: 0.0, 4: 0.0008, 5: 0.0, 6: 0.0, 7: 0.0001, 8: 0.0, 9: 0.0}\n",
      "chazhi:0.99910000\n",
      "epoch:0   global_step:400\n",
      "{0: 0.0219, 1: 0.1219, 2: 0.0484, 3: 0.0042, 4: 0.2765, 5: 0.0056, 6: 0.0335, 7: 0.4845, 8: 0.0028, 9: 0.0007}\n",
      "chazhi:0.48380000\n",
      "epoch:0   global_step:600\n",
      "{0: 0.0037, 1: 0.3023, 2: 0.0478, 3: 0.021, 4: 0.2759, 5: 0.0013, 6: 0.0548, 7: 0.2744, 8: 0.017, 9: 0.0018}\n",
      "chazhi:0.30100000\n",
      "epoch:0   global_step:800\n",
      "{0: 0.0062, 1: 0.1538, 2: 0.1447, 3: 0.1315, 4: 0.1504, 5: 0.0579, 6: 0.0205, 7: 0.2238, 8: 0.1091, 9: 0.0021}\n",
      "chazhi:0.22170000\n",
      "epoch:1   global_step:1000\n",
      "{0: 0.028, 1: 0.2403, 2: 0.0313, 3: 0.0452, 4: 0.2759, 5: 0.0121, 6: 0.0567, 7: 0.2665, 8: 0.0328, 9: 0.0112}\n",
      "chazhi:0.26470000\n",
      "epoch:1   global_step:1200\n",
      "{0: 0.0242, 1: 0.1922, 2: 0.0561, 3: 0.0836, 4: 0.2214, 5: 0.0107, 6: 0.0273, 7: 0.2431, 8: 0.0944, 9: 0.047}\n",
      "chazhi:0.23240000\n",
      "epoch:1   global_step:1400\n",
      "{0: 0.0064, 1: 0.2963, 2: 0.0598, 3: 0.0673, 4: 0.1957, 5: 0.0114, 6: 0.0527, 7: 0.2076, 8: 0.0544, 9: 0.0484}\n",
      "chazhi:0.28990000\n",
      "epoch:1   global_step:1600\n",
      "{0: 0.0112, 1: 0.1755, 2: 0.0544, 3: 0.0637, 4: 0.268, 5: 0.025, 6: 0.0357, 7: 0.2567, 8: 0.0423, 9: 0.0675}\n",
      "chazhi:0.25680000\n",
      "epoch:1   global_step:1800\n",
      "{0: 0.0175, 1: 0.2171, 2: 0.0488, 3: 0.0229, 4: 0.3045, 5: 0.0032, 6: 0.0531, 7: 0.2056, 8: 0.05, 9: 0.0773}\n",
      "chazhi:0.30130000\n",
      "epoch:2   global_step:2000\n",
      "{0: 0.0214, 1: 0.2147, 2: 0.0486, 3: 0.0382, 4: 0.2786, 5: 0.0093, 6: 0.0539, 7: 0.19, 8: 0.049, 9: 0.0963}\n",
      "chazhi:0.26930000\n",
      "epoch:2   global_step:2200\n",
      "{0: 0.0178, 1: 0.2326, 2: 0.0571, 3: 0.0517, 4: 0.2332, 5: 0.0099, 6: 0.0584, 7: 0.1936, 8: 0.0541, 9: 0.0916}\n",
      "chazhi:0.22330000\n",
      "epoch:2   global_step:2400\n",
      "{0: 0.0225, 1: 0.2143, 2: 0.0698, 3: 0.05, 4: 0.2139, 5: 0.0167, 6: 0.0626, 7: 0.1997, 8: 0.0487, 9: 0.1018}\n",
      "chazhi:0.19760000\n",
      "epoch:2   global_step:2600\n",
      "{0: 0.031, 1: 0.2173, 2: 0.065, 3: 0.0515, 4: 0.1999, 5: 0.0133, 6: 0.0724, 7: 0.2001, 8: 0.0533, 9: 0.0962}\n",
      "chazhi:0.20400000\n",
      "epoch:2   global_step:2800\n",
      "{0: 0.0437, 1: 0.1585, 2: 0.0624, 3: 0.048, 4: 0.2116, 5: 0.0143, 6: 0.0779, 7: 0.1915, 8: 0.0715, 9: 0.1206}\n",
      "chazhi:0.19730000\n",
      "epoch:3   global_step:3000\n",
      "{0: 0.0406, 1: 0.2076, 2: 0.0706, 3: 0.0616, 4: 0.1999, 5: 0.0191, 6: 0.0761, 7: 0.1886, 8: 0.0514, 9: 0.0845}\n",
      "chazhi:0.18850000\n",
      "epoch:3   global_step:3200\n",
      "{0: 0.0438, 1: 0.1908, 2: 0.0673, 3: 0.0604, 4: 0.1861, 5: 0.0187, 6: 0.0653, 7: 0.1807, 8: 0.0693, 9: 0.1176}\n",
      "chazhi:0.17210000\n",
      "epoch:3   global_step:3400\n",
      "{0: 0.0393, 1: 0.1614, 2: 0.0811, 3: 0.0565, 4: 0.1853, 5: 0.0275, 6: 0.0681, 7: 0.1822, 8: 0.0778, 9: 0.1208}\n",
      "chazhi:0.15780000\n",
      "epoch:3   global_step:3600\n",
      "{0: 0.0575, 1: 0.1534, 2: 0.0849, 3: 0.0553, 4: 0.1817, 5: 0.0296, 6: 0.0589, 7: 0.1623, 8: 0.0898, 9: 0.1266}\n",
      "chazhi:0.15210000\n",
      "epoch:4   global_step:3800\n",
      "{0: 0.045, 1: 0.1607, 2: 0.0781, 3: 0.067, 4: 0.1757, 5: 0.0267, 6: 0.0705, 7: 0.1812, 8: 0.0973, 9: 0.0978}\n",
      "chazhi:0.15450000\n",
      "epoch:4   global_step:4000\n",
      "{0: 0.0555, 1: 0.1578, 2: 0.0648, 3: 0.0668, 4: 0.1694, 5: 0.0365, 6: 0.0551, 7: 0.1644, 8: 0.0949, 9: 0.1348}\n",
      "chazhi:0.13290000\n",
      "epoch:4   global_step:4200\n",
      "{0: 0.0726, 1: 0.1708, 2: 0.0651, 3: 0.051, 4: 0.1637, 5: 0.0248, 6: 0.0547, 7: 0.1639, 8: 0.1074, 9: 0.126}\n",
      "chazhi:0.14600000\n",
      "epoch:4   global_step:4400\n",
      "{0: 0.0506, 1: 0.1891, 2: 0.0685, 3: 0.0735, 4: 0.1519, 5: 0.0402, 6: 0.0579, 7: 0.1894, 8: 0.0799, 9: 0.099}\n",
      "chazhi:0.14920000\n",
      "epoch:4   global_step:4600\n",
      "{0: 0.0661, 1: 0.1691, 2: 0.0762, 3: 0.0662, 4: 0.155, 5: 0.0329, 6: 0.0581, 7: 0.1562, 8: 0.0931, 9: 0.1271}\n",
      "chazhi:0.13620000\n",
      "epoch:5   global_step:4800\n",
      "{0: 0.0397, 1: 0.165, 2: 0.0675, 3: 0.0902, 4: 0.1507, 5: 0.0497, 6: 0.0662, 7: 0.1959, 8: 0.0697, 9: 0.1054}\n",
      "chazhi:0.15620000\n",
      "epoch:5   global_step:5000\n",
      "{0: 0.0504, 1: 0.1723, 2: 0.0598, 3: 0.0857, 4: 0.1329, 5: 0.0472, 6: 0.0482, 7: 0.1926, 8: 0.0829, 9: 0.128}\n",
      "chazhi:0.14540000\n",
      "epoch:5   global_step:5200\n",
      "{0: 0.0626, 1: 0.1873, 2: 0.0652, 3: 0.0638, 4: 0.1377, 5: 0.0313, 6: 0.0569, 7: 0.1642, 8: 0.0978, 9: 0.1332}\n",
      "chazhi:0.15600000\n",
      "epoch:5   global_step:5400\n",
      "{0: 0.0678, 1: 0.1775, 2: 0.0691, 3: 0.0787, 4: 0.1207, 5: 0.0469, 6: 0.0436, 7: 0.1856, 8: 0.0856, 9: 0.1245}\n",
      "chazhi:0.14200000\n",
      "epoch:5   global_step:5600\n",
      "{0: 0.0539, 1: 0.1657, 2: 0.0693, 3: 0.0717, 4: 0.1475, 5: 0.0435, 6: 0.0498, 7: 0.1847, 8: 0.092, 9: 0.1219}\n",
      "chazhi:0.14120000\n",
      "epoch:6   global_step:5800\n",
      "{0: 0.0591, 1: 0.1785, 2: 0.0585, 3: 0.0779, 4: 0.1462, 5: 0.0472, 6: 0.0538, 7: 0.1911, 8: 0.0749, 9: 0.1128}\n",
      "chazhi:0.14390000\n",
      "epoch:6   global_step:6000\n",
      "{0: 0.0641, 1: 0.1747, 2: 0.0597, 3: 0.0763, 4: 0.1449, 5: 0.0415, 6: 0.0498, 7: 0.1735, 8: 0.0809, 9: 0.1346}\n",
      "chazhi:0.13320000\n",
      "epoch:6   global_step:6200\n",
      "{0: 0.0714, 1: 0.1912, 2: 0.0513, 3: 0.0618, 4: 0.1351, 5: 0.0397, 6: 0.0566, 7: 0.1857, 8: 0.0893, 9: 0.1179}\n",
      "chazhi:0.15150000\n",
      "epoch:6   global_step:6400\n",
      "{0: 0.0586, 1: 0.181, 2: 0.0583, 3: 0.0677, 4: 0.1321, 5: 0.0407, 6: 0.0576, 7: 0.2026, 8: 0.0859, 9: 0.1155}\n",
      "chazhi:0.16190000\n",
      "epoch:7   global_step:6600\n",
      "{0: 0.0654, 1: 0.1938, 2: 0.0542, 3: 0.0681, 4: 0.16, 5: 0.0348, 6: 0.0502, 7: 0.1841, 8: 0.0773, 9: 0.1121}\n",
      "chazhi:0.15900000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7   global_step:6800\n",
      "{0: 0.0627, 1: 0.1896, 2: 0.0482, 3: 0.0811, 4: 0.147, 5: 0.0409, 6: 0.053, 7: 0.1781, 8: 0.0664, 9: 0.133}\n",
      "chazhi:0.14870000\n",
      "epoch:7   global_step:7000\n",
      "{0: 0.0765, 1: 0.1992, 2: 0.0452, 3: 0.0626, 4: 0.1404, 5: 0.0392, 6: 0.0565, 7: 0.1747, 8: 0.0699, 9: 0.1358}\n",
      "chazhi:0.16000000\n",
      "epoch:7   global_step:7200\n",
      "{0: 0.0775, 1: 0.1949, 2: 0.0519, 3: 0.0749, 4: 0.1449, 5: 0.0373, 6: 0.0532, 7: 0.1722, 8: 0.0652, 9: 0.128}\n",
      "chazhi:0.15760000\n",
      "epoch:7   global_step:7400\n",
      "{0: 0.0567, 1: 0.2201, 2: 0.0462, 3: 0.0907, 4: 0.126, 5: 0.0434, 6: 0.0442, 7: 0.1823, 8: 0.0662, 9: 0.1242}\n",
      "chazhi:0.17670000\n",
      "epoch:8   global_step:7600\n",
      "{0: 0.0632, 1: 0.2154, 2: 0.0425, 3: 0.0688, 4: 0.1618, 5: 0.0406, 6: 0.0457, 7: 0.1829, 8: 0.0622, 9: 0.1169}\n",
      "chazhi:0.17480000\n",
      "epoch:8   global_step:7800\n",
      "{0: 0.0672, 1: 0.2196, 2: 0.0372, 3: 0.0817, 4: 0.1193, 5: 0.0361, 6: 0.0489, 7: 0.1827, 8: 0.0711, 9: 0.1362}\n",
      "chazhi:0.18350000\n",
      "epoch:8   global_step:8000\n",
      "{0: 0.0667, 1: 0.2048, 2: 0.043, 3: 0.066, 4: 0.1326, 5: 0.0433, 6: 0.0522, 7: 0.1787, 8: 0.0693, 9: 0.1434}\n",
      "chazhi:0.16180000\n",
      "epoch:8   global_step:8200\n",
      "{0: 0.0698, 1: 0.2119, 2: 0.0443, 3: 0.0765, 4: 0.1172, 5: 0.0493, 6: 0.0452, 7: 0.1737, 8: 0.0722, 9: 0.1399}\n",
      "chazhi:0.16760000\n",
      "epoch:8   global_step:8400\n",
      "{0: 0.0515, 1: 0.2012, 2: 0.0426, 3: 0.0871, 4: 0.1244, 5: 0.0559, 6: 0.0385, 7: 0.2016, 8: 0.0638, 9: 0.1334}\n",
      "chazhi:0.16310000\n",
      "epoch:9   global_step:8600\n",
      "{0: 0.0683, 1: 0.2214, 2: 0.0396, 3: 0.078, 4: 0.1238, 5: 0.0388, 6: 0.052, 7: 0.1721, 8: 0.0677, 9: 0.1383}\n",
      "chazhi:0.18260000\n",
      "epoch:9   global_step:8800\n",
      "{0: 0.0709, 1: 0.2255, 2: 0.043, 3: 0.0652, 4: 0.1314, 5: 0.0363, 6: 0.0484, 7: 0.1711, 8: 0.0755, 9: 0.1327}\n",
      "chazhi:0.18920000\n",
      "epoch:9   global_step:9000\n",
      "{0: 0.0591, 1: 0.2191, 2: 0.0418, 3: 0.078, 4: 0.1182, 5: 0.0413, 6: 0.0422, 7: 0.1796, 8: 0.0795, 9: 0.1412}\n",
      "chazhi:0.17780000\n",
      "epoch:9   global_step:9200\n",
      "{0: 0.0683, 1: 0.2321, 2: 0.0392, 3: 0.0689, 4: 0.1239, 5: 0.0487, 6: 0.0396, 7: 0.1756, 8: 0.0664, 9: 0.1373}\n",
      "chazhi:0.19290000\n",
      "epoch:10   global_step:9400\n",
      "{0: 0.0692, 1: 0.2414, 2: 0.0373, 3: 0.062, 4: 0.1174, 5: 0.0398, 6: 0.0382, 7: 0.1734, 8: 0.0812, 9: 0.1401}\n",
      "chazhi:0.20410000\n",
      "epoch:10   global_step:9600\n",
      "{0: 0.0613, 1: 0.2406, 2: 0.031, 3: 0.086, 4: 0.1165, 5: 0.043, 6: 0.0414, 7: 0.1849, 8: 0.0634, 9: 0.1319}\n",
      "chazhi:0.20960000\n",
      "epoch:10   global_step:9800\n",
      "{0: 0.0565, 1: 0.2443, 2: 0.0324, 3: 0.0808, 4: 0.1157, 5: 0.0483, 6: 0.0407, 7: 0.1856, 8: 0.0549, 9: 0.1408}\n",
      "chazhi:0.21190000\n",
      "epoch:10   global_step:10000\n",
      "{0: 0.0628, 1: 0.2517, 2: 0.0323, 3: 0.0687, 4: 0.1051, 5: 0.0433, 6: 0.0387, 7: 0.1767, 8: 0.0617, 9: 0.159}\n",
      "chazhi:0.21940000\n",
      "epoch:10   global_step:10200\n",
      "{0: 0.0665, 1: 0.2384, 2: 0.0388, 3: 0.0659, 4: 0.1234, 5: 0.0427, 6: 0.0393, 7: 0.1769, 8: 0.0683, 9: 0.1398}\n",
      "chazhi:0.19960000\n",
      "epoch:11   global_step:10400\n",
      "{0: 0.0626, 1: 0.2462, 2: 0.0325, 3: 0.0719, 4: 0.1282, 5: 0.0552, 6: 0.0364, 7: 0.1691, 8: 0.0535, 9: 0.1444}\n",
      "chazhi:0.21370000\n",
      "epoch:11   global_step:10600\n",
      "{0: 0.0519, 1: 0.2554, 2: 0.032, 3: 0.0767, 4: 0.1127, 5: 0.0558, 6: 0.0374, 7: 0.1887, 8: 0.0526, 9: 0.1368}\n",
      "chazhi:0.22340000\n",
      "epoch:11   global_step:10800\n",
      "{0: 0.0616, 1: 0.2647, 2: 0.0247, 3: 0.0777, 4: 0.1008, 5: 0.0554, 6: 0.043, 7: 0.1819, 8: 0.0473, 9: 0.1429}\n",
      "chazhi:0.24000000\n",
      "epoch:11   global_step:11000\n",
      "{0: 0.0657, 1: 0.269, 2: 0.0259, 3: 0.0713, 4: 0.1118, 5: 0.0429, 6: 0.0412, 7: 0.1633, 8: 0.061, 9: 0.1479}\n",
      "chazhi:0.24310000\n",
      "epoch:11   global_step:11200\n",
      "{0: 0.0478, 1: 0.2648, 2: 0.0239, 3: 0.0782, 4: 0.1131, 5: 0.0555, 6: 0.0355, 7: 0.1792, 8: 0.0555, 9: 0.1465}\n",
      "chazhi:0.24090000\n",
      "epoch:12   global_step:11400\n",
      "{0: 0.0605, 1: 0.2687, 2: 0.0272, 3: 0.0719, 4: 0.1053, 5: 0.0426, 6: 0.0422, 7: 0.1837, 8: 0.0536, 9: 0.1443}\n",
      "chazhi:0.24150000\n",
      "epoch:12   global_step:11600\n",
      "{0: 0.0551, 1: 0.2646, 2: 0.0268, 3: 0.0746, 4: 0.1082, 5: 0.0501, 6: 0.034, 7: 0.1863, 8: 0.0517, 9: 0.1486}\n",
      "chazhi:0.23780000\n",
      "epoch:12   global_step:11800\n",
      "{0: 0.0503, 1: 0.2713, 2: 0.0295, 3: 0.0691, 4: 0.1081, 5: 0.0515, 6: 0.0332, 7: 0.1718, 8: 0.0593, 9: 0.1559}\n",
      "chazhi:0.24180000\n",
      "epoch:12   global_step:12000\n",
      "{0: 0.0538, 1: 0.2742, 2: 0.0283, 3: 0.0658, 4: 0.1101, 5: 0.0434, 6: 0.036, 7: 0.1739, 8: 0.058, 9: 0.1565}\n",
      "chazhi:0.24590000\n",
      "epoch:13   global_step:12200\n",
      "{0: 0.0447, 1: 0.2813, 2: 0.0257, 3: 0.074, 4: 0.1128, 5: 0.0467, 6: 0.0355, 7: 0.181, 8: 0.0447, 9: 0.1536}\n",
      "chazhi:0.25560000\n",
      "epoch:13   global_step:12400\n",
      "{0: 0.0495, 1: 0.2804, 2: 0.0196, 3: 0.071, 4: 0.1119, 5: 0.0484, 6: 0.0347, 7: 0.1831, 8: 0.0533, 9: 0.1481}\n",
      "chazhi:0.26080000\n",
      "epoch:13   global_step:12600\n",
      "{0: 0.0446, 1: 0.2842, 2: 0.0257, 3: 0.0711, 4: 0.1018, 5: 0.0555, 6: 0.0354, 7: 0.169, 8: 0.0499, 9: 0.1628}\n",
      "chazhi:0.25850000\n",
      "epoch:13   global_step:12800\n",
      "{0: 0.0461, 1: 0.3019, 2: 0.023, 3: 0.0626, 4: 0.0943, 5: 0.0557, 6: 0.0351, 7: 0.1807, 8: 0.0469, 9: 0.1537}\n",
      "chazhi:0.27890000\n",
      "epoch:13   global_step:13000\n",
      "{0: 0.0446, 1: 0.3122, 2: 0.0204, 3: 0.0674, 4: 0.1013, 5: 0.0575, 6: 0.0315, 7: 0.1797, 8: 0.0465, 9: 0.1389}\n",
      "chazhi:0.29180000\n",
      "epoch:14   global_step:13200\n",
      "{0: 0.0395, 1: 0.2973, 2: 0.0252, 3: 0.0731, 4: 0.1011, 5: 0.0548, 6: 0.0311, 7: 0.1719, 8: 0.05, 9: 0.156}\n",
      "chazhi:0.27210000\n",
      "epoch:14   global_step:13400\n",
      "{0: 0.0491, 1: 0.3177, 2: 0.0188, 3: 0.0702, 4: 0.0898, 5: 0.0484, 6: 0.0338, 7: 0.1826, 8: 0.0513, 9: 0.1383}\n",
      "chazhi:0.29890000\n",
      "epoch:14   global_step:13600\n",
      "{0: 0.0411, 1: 0.3345, 2: 0.0237, 3: 0.0651, 4: 0.1039, 5: 0.0546, 6: 0.0301, 7: 0.1664, 8: 0.0471, 9: 0.1335}\n",
      "chazhi:0.31080000\n",
      "epoch:14   global_step:13800\n",
      "{0: 0.0398, 1: 0.3236, 2: 0.0199, 3: 0.0662, 4: 0.0933, 5: 0.0633, 6: 0.025, 7: 0.1673, 8: 0.0471, 9: 0.1545}\n",
      "chazhi:0.30370000\n",
      "epoch:14   global_step:14000\n",
      "{0: 0.0321, 1: 0.3092, 2: 0.0235, 3: 0.0578, 4: 0.1044, 5: 0.0608, 6: 0.0349, 7: 0.1697, 8: 0.053, 9: 0.1546}\n",
      "chazhi:0.28570000\n",
      "epoch:15   global_step:14200\n",
      "{0: 0.0392, 1: 0.3344, 2: 0.019, 3: 0.0585, 4: 0.1148, 5: 0.0433, 6: 0.0274, 7: 0.1686, 8: 0.0511, 9: 0.1437}\n",
      "chazhi:0.31540000\n",
      "epoch:15   global_step:14400\n",
      "{0: 0.0369, 1: 0.3429, 2: 0.0196, 3: 0.066, 4: 0.1021, 5: 0.0449, 6: 0.0217, 7: 0.1684, 8: 0.0415, 9: 0.156}\n",
      "chazhi:0.32330000\n",
      "epoch:15   global_step:14600\n",
      "{0: 0.0275, 1: 0.3444, 2: 0.019, 3: 0.0675, 4: 0.1081, 5: 0.0517, 6: 0.0244, 7: 0.1679, 8: 0.0457, 9: 0.1438}\n",
      "chazhi:0.32540000\n",
      "epoch:15   global_step:14800\n",
      "{0: 0.0272, 1: 0.3353, 2: 0.0207, 3: 0.063, 4: 0.0981, 5: 0.0533, 6: 0.0252, 7: 0.1704, 8: 0.0482, 9: 0.1586}\n",
      "chazhi:0.31460000\n",
      "epoch:16   global_step:15000\n",
      "{0: 0.0285, 1: 0.3458, 2: 0.0192, 3: 0.062, 4: 0.1017, 5: 0.046, 6: 0.023, 7: 0.1693, 8: 0.0533, 9: 0.1512}\n",
      "chazhi:0.32660000\n",
      "epoch:16   global_step:15200\n",
      "{0: 0.0278, 1: 0.3432, 2: 0.0211, 3: 0.0545, 4: 0.1054, 5: 0.0567, 6: 0.0279, 7: 0.1669, 8: 0.0435, 9: 0.153}\n",
      "chazhi:0.32210000\n",
      "epoch:16   global_step:15400\n",
      "{0: 0.0297, 1: 0.3599, 2: 0.0179, 3: 0.0604, 4: 0.1005, 5: 0.0478, 6: 0.022, 7: 0.164, 8: 0.0424, 9: 0.1554}\n",
      "chazhi:0.34200000\n",
      "epoch:16   global_step:15600\n",
      "{0: 0.0311, 1: 0.3532, 2: 0.0218, 3: 0.0678, 4: 0.0881, 5: 0.0483, 6: 0.0232, 7: 0.1672, 8: 0.0461, 9: 0.1532}\n",
      "chazhi:0.33140000\n",
      "epoch:16   global_step:15800\n",
      "{0: 0.0251, 1: 0.3687, 2: 0.0204, 3: 0.0588, 4: 0.0964, 5: 0.0478, 6: 0.0209, 7: 0.1637, 8: 0.0424, 9: 0.1558}\n",
      "chazhi:0.34830000\n",
      "epoch:17   global_step:16000\n",
      "{0: 0.0215, 1: 0.3736, 2: 0.0139, 3: 0.0644, 4: 0.1075, 5: 0.0576, 6: 0.0175, 7: 0.1588, 8: 0.0384, 9: 0.1468}\n",
      "chazhi:0.35970000\n",
      "epoch:17   global_step:16200\n",
      "{0: 0.0262, 1: 0.3771, 2: 0.0164, 3: 0.0602, 4: 0.1018, 5: 0.0518, 6: 0.0216, 7: 0.1663, 8: 0.0394, 9: 0.1392}\n",
      "chazhi:0.36070000\n",
      "epoch:17   global_step:16400\n",
      "{0: 0.0317, 1: 0.3666, 2: 0.0155, 3: 0.0565, 4: 0.0958, 5: 0.0522, 6: 0.0232, 7: 0.161, 8: 0.0431, 9: 0.1544}\n",
      "chazhi:0.35110000\n",
      "epoch:17   global_step:16600\n",
      "{0: 0.0283, 1: 0.3789, 2: 0.0183, 3: 0.0608, 4: 0.0886, 5: 0.0551, 6: 0.018, 7: 0.1576, 8: 0.0422, 9: 0.1522}\n",
      "chazhi:0.36090000\n",
      "epoch:17   global_step:16800\n",
      "{0: 0.0219, 1: 0.3726, 2: 0.0153, 3: 0.0614, 4: 0.0858, 5: 0.0605, 6: 0.0194, 7: 0.1607, 8: 0.0451, 9: 0.1573}\n",
      "chazhi:0.35730000\n",
      "epoch:18   global_step:17000\n",
      "{0: 0.0263, 1: 0.3811, 2: 0.0137, 3: 0.0525, 4: 0.0935, 5: 0.053, 6: 0.0283, 7: 0.1507, 8: 0.0506, 9: 0.1503}\n",
      "chazhi:0.36740000\n",
      "epoch:18   global_step:17200\n",
      "{0: 0.0215, 1: 0.4016, 2: 0.0195, 3: 0.0537, 4: 0.0768, 5: 0.064, 6: 0.015, 7: 0.1597, 8: 0.0451, 9: 0.1431}\n",
      "chazhi:0.38660000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18   global_step:17400\n",
      "{0: 0.0182, 1: 0.4038, 2: 0.0168, 3: 0.053, 4: 0.0833, 5: 0.0592, 6: 0.0237, 7: 0.1608, 8: 0.0416, 9: 0.1396}\n",
      "chazhi:0.38700000\n",
      "epoch:18   global_step:17600\n",
      "{0: 0.0208, 1: 0.4066, 2: 0.0164, 3: 0.0561, 4: 0.0752, 5: 0.0637, 6: 0.0218, 7: 0.1563, 8: 0.0373, 9: 0.1458}\n",
      "chazhi:0.39020000\n",
      "epoch:18   global_step:17800\n",
      "{0: 0.0185, 1: 0.4115, 2: 0.0149, 3: 0.058, 4: 0.0796, 5: 0.0595, 6: 0.0161, 7: 0.1528, 8: 0.0388, 9: 0.1503}\n",
      "chazhi:0.39660000\n",
      "epoch:19   global_step:18000\n",
      "{0: 0.0216, 1: 0.4166, 2: 0.0143, 3: 0.055, 4: 0.0761, 5: 0.0551, 6: 0.02, 7: 0.1793, 8: 0.0371, 9: 0.1249}\n",
      "chazhi:0.40230000\n",
      "epoch:19   global_step:18200\n",
      "{0: 0.0206, 1: 0.4222, 2: 0.0131, 3: 0.0554, 4: 0.0824, 5: 0.055, 6: 0.0183, 7: 0.1656, 8: 0.033, 9: 0.1344}\n",
      "chazhi:0.40910000\n",
      "epoch:19   global_step:18400\n",
      "{0: 0.0209, 1: 0.4401, 2: 0.0151, 3: 0.0518, 4: 0.0768, 5: 0.0459, 6: 0.0173, 7: 0.1609, 8: 0.0356, 9: 0.1356}\n",
      "chazhi:0.42500000\n",
      "epoch:19   global_step:18600\n",
      "{0: 0.0157, 1: 0.4298, 2: 0.0124, 3: 0.0665, 4: 0.0672, 5: 0.0577, 6: 0.0177, 7: 0.155, 8: 0.0359, 9: 0.1421}\n",
      "chazhi:0.41740000\n",
      "epoch:20   global_step:18800\n",
      "{0: 0.0184, 1: 0.4307, 2: 0.0126, 3: 0.0554, 4: 0.0724, 5: 0.055, 6: 0.0171, 7: 0.1682, 8: 0.0342, 9: 0.136}\n",
      "chazhi:0.41810000\n",
      "epoch:20   global_step:19000\n",
      "{0: 0.0178, 1: 0.4483, 2: 0.0128, 3: 0.0649, 4: 0.0732, 5: 0.0491, 6: 0.0106, 7: 0.1664, 8: 0.0361, 9: 0.1208}\n",
      "chazhi:0.43770000\n",
      "epoch:20   global_step:19200\n",
      "{0: 0.016, 1: 0.4674, 2: 0.0147, 3: 0.0562, 4: 0.0626, 5: 0.0542, 6: 0.0119, 7: 0.1568, 8: 0.0339, 9: 0.1263}\n",
      "chazhi:0.45550000\n",
      "epoch:20   global_step:19400\n",
      "{0: 0.0181, 1: 0.4583, 2: 0.0164, 3: 0.0453, 4: 0.0727, 5: 0.0537, 6: 0.0105, 7: 0.1548, 8: 0.0403, 9: 0.1299}\n",
      "chazhi:0.44780000\n",
      "epoch:20   global_step:19600\n",
      "{0: 0.0162, 1: 0.4526, 2: 0.0176, 3: 0.0501, 4: 0.0701, 5: 0.0546, 6: 0.0112, 7: 0.1634, 8: 0.0388, 9: 0.1254}\n",
      "chazhi:0.44140000\n",
      "epoch:21   global_step:19800\n",
      "{0: 0.0149, 1: 0.4545, 2: 0.0142, 3: 0.0598, 4: 0.0745, 5: 0.0613, 6: 0.0123, 7: 0.1513, 8: 0.0322, 9: 0.125}\n",
      "chazhi:0.44220000\n",
      "epoch:21   global_step:20000\n",
      "{0: 0.0139, 1: 0.4709, 2: 0.0108, 3: 0.0597, 4: 0.0721, 5: 0.06, 6: 0.0106, 7: 0.1592, 8: 0.0277, 9: 0.1151}\n",
      "chazhi:0.46030000\n",
      "epoch:21   global_step:20200\n",
      "{0: 0.0146, 1: 0.4587, 2: 0.0124, 3: 0.0552, 4: 0.0659, 5: 0.0533, 6: 0.0121, 7: 0.16, 8: 0.0314, 9: 0.1364}\n",
      "chazhi:0.44660000\n",
      "epoch:21   global_step:20400\n",
      "{0: 0.0122, 1: 0.4716, 2: 0.0133, 3: 0.0514, 4: 0.0727, 5: 0.0597, 6: 0.0124, 7: 0.1468, 8: 0.0338, 9: 0.1261}\n",
      "chazhi:0.45940000\n",
      "epoch:21   global_step:20600\n",
      "{0: 0.0102, 1: 0.4763, 2: 0.0109, 3: 0.0536, 4: 0.0671, 5: 0.0581, 6: 0.0102, 7: 0.1615, 8: 0.0249, 9: 0.1272}\n",
      "chazhi:0.46610000\n",
      "epoch:22   global_step:20800\n",
      "{0: 0.0133, 1: 0.4899, 2: 0.0114, 3: 0.0426, 4: 0.073, 5: 0.0539, 6: 0.0115, 7: 0.1517, 8: 0.0269, 9: 0.1258}\n",
      "chazhi:0.47850000\n",
      "epoch:22   global_step:21000\n",
      "{0: 0.0115, 1: 0.4901, 2: 0.0138, 3: 0.0436, 4: 0.0651, 5: 0.0593, 6: 0.0128, 7: 0.1469, 8: 0.03, 9: 0.1269}\n",
      "chazhi:0.47860000\n",
      "epoch:22   global_step:21200\n",
      "{0: 0.0093, 1: 0.4841, 2: 0.0142, 3: 0.0513, 4: 0.0594, 5: 0.066, 6: 0.0109, 7: 0.1509, 8: 0.0245, 9: 0.1294}\n",
      "chazhi:0.47480000\n",
      "epoch:22   global_step:21400\n",
      "{0: 0.011, 1: 0.5062, 2: 0.011, 3: 0.0505, 4: 0.0615, 5: 0.0623, 6: 0.0114, 7: 0.1474, 8: 0.0237, 9: 0.115}\n",
      "chazhi:0.49520000\n",
      "epoch:23   global_step:21600\n",
      "{0: 0.0117, 1: 0.4916, 2: 0.0112, 3: 0.0495, 4: 0.0628, 5: 0.0569, 6: 0.0109, 7: 0.1558, 8: 0.0223, 9: 0.1273}\n",
      "chazhi:0.48070000\n",
      "epoch:23   global_step:21800\n",
      "{0: 0.0104, 1: 0.5039, 2: 0.0096, 3: 0.0475, 4: 0.0577, 5: 0.056, 6: 0.0118, 7: 0.1564, 8: 0.0233, 9: 0.1234}\n",
      "chazhi:0.49430000\n",
      "epoch:23   global_step:22000\n",
      "{0: 0.0151, 1: 0.5121, 2: 0.0127, 3: 0.0414, 4: 0.0598, 5: 0.0506, 6: 0.0119, 7: 0.1547, 8: 0.0237, 9: 0.118}\n",
      "chazhi:0.50020000\n",
      "epoch:23   global_step:22200\n",
      "{0: 0.0119, 1: 0.5166, 2: 0.0101, 3: 0.0434, 4: 0.0445, 5: 0.0627, 6: 0.0124, 7: 0.1507, 8: 0.0246, 9: 0.1231}\n",
      "chazhi:0.50650000\n",
      "epoch:23   global_step:22400\n",
      "{0: 0.0117, 1: 0.5223, 2: 0.0101, 3: 0.0536, 4: 0.053, 5: 0.0551, 6: 0.0089, 7: 0.1569, 8: 0.0225, 9: 0.1059}\n",
      "chazhi:0.51340000\n",
      "epoch:24   global_step:22600\n",
      "{0: 0.0096, 1: 0.5141, 2: 0.0086, 3: 0.0467, 4: 0.0461, 5: 0.0563, 6: 0.0085, 7: 0.1591, 8: 0.0229, 9: 0.1281}\n",
      "chazhi:0.50560000\n",
      "epoch:24   global_step:22800\n",
      "{0: 0.0105, 1: 0.5289, 2: 0.0088, 3: 0.0441, 4: 0.0539, 5: 0.0499, 6: 0.0111, 7: 0.1531, 8: 0.0234, 9: 0.1163}\n",
      "chazhi:0.52010000\n",
      "epoch:24   global_step:23000\n",
      "{0: 0.0126, 1: 0.5357, 2: 0.0115, 3: 0.0423, 4: 0.0499, 5: 0.051, 6: 0.0082, 7: 0.1518, 8: 0.0255, 9: 0.1115}\n",
      "chazhi:0.52750000\n",
      "epoch:24   global_step:23200\n",
      "{0: 0.0079, 1: 0.5387, 2: 0.0114, 3: 0.0367, 4: 0.0463, 5: 0.0537, 6: 0.009, 7: 0.1517, 8: 0.027, 9: 0.1176}\n",
      "chazhi:0.53080000\n",
      "epoch:24   global_step:23400\n",
      "{0: 0.0057, 1: 0.5405, 2: 0.0091, 3: 0.0391, 4: 0.0541, 5: 0.0537, 6: 0.0071, 7: 0.1638, 8: 0.0155, 9: 0.1114}\n",
      "chazhi:0.53480000\n",
      "epoch:25   global_step:23600\n",
      "{0: 0.006, 1: 0.5546, 2: 0.0085, 3: 0.0393, 4: 0.05, 5: 0.0481, 6: 0.0076, 7: 0.1666, 8: 0.0208, 9: 0.0985}\n",
      "chazhi:0.54860000\n",
      "epoch:25   global_step:23800\n",
      "{0: 0.0073, 1: 0.5377, 2: 0.0094, 3: 0.0448, 4: 0.0523, 5: 0.0533, 6: 0.0074, 7: 0.1624, 8: 0.0196, 9: 0.1058}\n",
      "chazhi:0.53040000\n",
      "epoch:25   global_step:24000\n",
      "{0: 0.005, 1: 0.5596, 2: 0.0063, 3: 0.0417, 4: 0.0459, 5: 0.0485, 6: 0.0073, 7: 0.1614, 8: 0.0173, 9: 0.107}\n",
      "chazhi:0.55460000\n",
      "epoch:25   global_step:24200\n",
      "{0: 0.008, 1: 0.5703, 2: 0.0079, 3: 0.0335, 4: 0.0481, 5: 0.0485, 6: 0.0068, 7: 0.1665, 8: 0.018, 9: 0.0924}\n",
      "chazhi:0.56350000\n",
      "epoch:26   global_step:24400\n",
      "{0: 0.0045, 1: 0.5701, 2: 0.0085, 3: 0.0342, 4: 0.0422, 5: 0.0424, 6: 0.0061, 7: 0.1603, 8: 0.0253, 9: 0.1064}\n",
      "chazhi:0.56560000\n",
      "epoch:26   global_step:24600\n",
      "{0: 0.0047, 1: 0.576, 2: 0.0078, 3: 0.0392, 4: 0.0404, 5: 0.0496, 6: 0.0053, 7: 0.1664, 8: 0.0187, 9: 0.0919}\n",
      "chazhi:0.57130000\n",
      "epoch:26   global_step:24800\n",
      "{0: 0.0042, 1: 0.5703, 2: 0.0053, 3: 0.0376, 4: 0.0406, 5: 0.046, 6: 0.0073, 7: 0.1681, 8: 0.0167, 9: 0.1039}\n",
      "chazhi:0.56610000\n",
      "epoch:26   global_step:25000\n",
      "{0: 0.0046, 1: 0.5879, 2: 0.0095, 3: 0.0269, 4: 0.039, 5: 0.0416, 6: 0.007, 7: 0.1637, 8: 0.0184, 9: 0.1014}\n",
      "chazhi:0.58330000\n",
      "epoch:26   global_step:25200\n",
      "{0: 0.0063, 1: 0.5987, 2: 0.0057, 3: 0.0325, 4: 0.0322, 5: 0.0446, 6: 0.0053, 7: 0.1666, 8: 0.0127, 9: 0.0954}\n",
      "chazhi:0.59340000\n",
      "epoch:27   global_step:25400\n",
      "{0: 0.0055, 1: 0.5972, 2: 0.0057, 3: 0.0333, 4: 0.0348, 5: 0.0389, 6: 0.0041, 7: 0.1638, 8: 0.0135, 9: 0.1032}\n",
      "chazhi:0.59310000\n",
      "epoch:27   global_step:25600\n",
      "{0: 0.0056, 1: 0.6106, 2: 0.0076, 3: 0.0344, 4: 0.0349, 5: 0.0413, 6: 0.0062, 7: 0.1621, 8: 0.015, 9: 0.0823}\n",
      "chazhi:0.60500000\n",
      "epoch:27   global_step:25800\n",
      "{0: 0.002, 1: 0.6121, 2: 0.0058, 3: 0.0309, 4: 0.0395, 5: 0.044, 6: 0.0039, 7: 0.1548, 8: 0.0117, 9: 0.0953}\n",
      "chazhi:0.61010000\n",
      "epoch:27   global_step:26000\n",
      "{0: 0.0028, 1: 0.6183, 2: 0.0051, 3: 0.0292, 4: 0.0398, 5: 0.0423, 6: 0.0038, 7: 0.1498, 8: 0.0124, 9: 0.0965}\n",
      "chazhi:0.61550000\n",
      "epoch:27   global_step:26200\n",
      "{0: 0.0019, 1: 0.6255, 2: 0.0063, 3: 0.0297, 4: 0.0335, 5: 0.0419, 6: 0.0048, 7: 0.156, 8: 0.0103, 9: 0.0901}\n",
      "chazhi:0.62360000\n",
      "epoch:28   global_step:26400\n",
      "{0: 0.0021, 1: 0.6293, 2: 0.004, 3: 0.0267, 4: 0.0349, 5: 0.0445, 6: 0.0039, 7: 0.1512, 8: 0.0118, 9: 0.0916}\n",
      "chazhi:0.62720000\n",
      "epoch:28   global_step:26600\n",
      "{0: 0.0031, 1: 0.6335, 2: 0.0047, 3: 0.0315, 4: 0.0334, 5: 0.0449, 6: 0.0048, 7: 0.1366, 8: 0.0111, 9: 0.0964}\n",
      "chazhi:0.63040000\n",
      "epoch:28   global_step:26800\n",
      "{0: 0.0029, 1: 0.6283, 2: 0.0033, 3: 0.0329, 4: 0.0348, 5: 0.0437, 6: 0.0031, 7: 0.1556, 8: 0.0099, 9: 0.0855}\n",
      "chazhi:0.62540000\n",
      "epoch:28   global_step:27000\n",
      "{0: 0.0022, 1: 0.6378, 2: 0.0051, 3: 0.0329, 4: 0.0321, 5: 0.0406, 6: 0.0028, 7: 0.1441, 8: 0.0084, 9: 0.094}\n",
      "chazhi:0.63560000\n",
      "epoch:29   global_step:27200\n",
      "{0: 0.0025, 1: 0.6546, 2: 0.005, 3: 0.0265, 4: 0.0298, 5: 0.0404, 6: 0.0023, 7: 0.1375, 8: 0.0104, 9: 0.091}\n",
      "chazhi:0.65230000\n",
      "epoch:29   global_step:27400\n",
      "{0: 0.0036, 1: 0.6471, 2: 0.0039, 3: 0.03, 4: 0.0362, 5: 0.0414, 6: 0.003, 7: 0.1402, 8: 0.0133, 9: 0.0813}\n",
      "chazhi:0.64410000\n",
      "epoch:29   global_step:27600\n",
      "{0: 0.0023, 1: 0.652, 2: 0.0018, 3: 0.0278, 4: 0.0313, 5: 0.042, 6: 0.0018, 7: 0.1402, 8: 0.0107, 9: 0.0901}\n",
      "chazhi:0.65020000\n",
      "epoch:29   global_step:27800\n",
      "{0: 0.0013, 1: 0.6598, 2: 0.0029, 3: 0.0286, 4: 0.0281, 5: 0.0345, 6: 0.0026, 7: 0.1466, 8: 0.0101, 9: 0.0855}\n",
      "chazhi:0.65850000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29   global_step:28000\n",
      "{0: 0.002, 1: 0.672, 2: 0.0029, 3: 0.0301, 4: 0.0222, 5: 0.0347, 6: 0.0026, 7: 0.1496, 8: 0.0088, 9: 0.0751}\n",
      "chazhi:0.67000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import cifar10,fashion_mnist,mnist\n",
    "import os\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D,LeakyReLU,Conv2DTranspose, Conv2D\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from keras.layers.convolutional import _Conv\n",
    "from keras.legacy import interfaces\n",
    "from keras.engine import InputSpec\n",
    "import cv2\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "from scipy import misc\n",
    "def set_gpu_config(device = \"0\",fraction=0.25):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    KTF.set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "def predict_images(file_name, generator, noise_size, n = 10, size = 32):\n",
    "\n",
    "    image = generator.predict(np.random.normal(size=(n*n, ) + noise_size))\n",
    "\n",
    "    image = np.reshape(image, (n, n, size, size, 3))\n",
    "    image = np.transpose(image, (0, 2, 1, 3, 4))\n",
    "    image = np.reshape(image, (n*size, n*size, 3))\n",
    "\n",
    "    image = 255 * (image + 1) / 2\n",
    "    image = image.astype(\"uint8\")\n",
    "    misc.imsave(file_name, image)\n",
    "def build_generator(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2DTranspose(512,(3,3),strides=(2,2),padding=\"same\",input_shape=input_shape))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(256,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(128,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(64,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2D(1,(3,3),padding=\"same\",activation=\"tanh\"))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(SNConv2D(64,(3,3),strides=(2,2),padding=\"same\",input_shape=input_shape))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(SNConv2D(128,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(SNConv2D(256,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(SNConv2D(512,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(SNConv2D(1,(3,3),padding=\"same\"))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_functions(batch_size, noise_size, image_size, generator, discriminator):\n",
    "\n",
    "    noise = K.random_normal((batch_size,) + noise_size,0.0,1.0,\"float32\")\n",
    "    real_image = K.placeholder((batch_size,) + image_size)\n",
    "    fake_image = generator(noise)\n",
    "\n",
    "    d_input = K.concatenate([real_image, fake_image], axis=0)\n",
    "    pred_real, pred_fake = tf.split(discriminator(d_input), num_or_size_splits = 2, axis = 0)\n",
    "\n",
    "    d_loss = K.mean(K.maximum(0., 1 - pred_real)) + K.mean(K.maximum(0., 1 + pred_fake))\n",
    "    g_loss = -K.mean(pred_fake)\n",
    "\n",
    "    d_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(d_loss, discriminator.trainable_weights)\n",
    "    d_train = K.function([real_image, K.learning_phase()], [d_loss], d_training_updates)\n",
    "\n",
    "    g_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(g_loss, generator.trainable_weights)\n",
    "    g_train = K.function([real_image, K.learning_phase()], [g_loss], g_training_updates)\n",
    "\n",
    "    return d_train,g_train\n",
    "\n",
    "class SNConv2D(_Conv):\n",
    "    @interfaces.legacy_conv2d_support\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "\n",
    "        super(SNConv2D, self).__init__(\n",
    "            rank=2,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        self.Ip = 1\n",
    "        self.u = self.add_weight(\n",
    "            name='W_u',\n",
    "            shape=(1,filters),\n",
    "            initializer='random_uniform',\n",
    "            trainable=False\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = K.conv2d(\n",
    "            inputs,\n",
    "            self.W_bar(),\n",
    "            strides=self.strides,\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format,\n",
    "            dilation_rate=self.dilation_rate)\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SNConv2D, self).get_config()\n",
    "        config.pop('rank')\n",
    "        return config\n",
    "\n",
    "    def W_bar(self):\n",
    "        # Spectrally Normalized Weight\n",
    "        W_mat = K.permute_dimensions(self.kernel, (3, 2, 0, 1)) # (h, w, i, o) => (o, i, h, w)\n",
    "        W_mat = K.reshape(W_mat,[K.shape(W_mat)[0], -1]) # (o, i * h * w)\n",
    "\n",
    "        if not self.Ip >= 1:\n",
    "            raise ValueError(\"The number of power iterations should be positive integer\")\n",
    "\n",
    "        _u = self.u\n",
    "        _v = None\n",
    "\n",
    "        for _ in range(self.Ip):\n",
    "            _v = _l2normalize(K.dot(_u, W_mat))\n",
    "            _u = _l2normalize(K.dot(_v, K.transpose(W_mat)))\n",
    "\n",
    "        sigma = K.sum(K.dot(_u,W_mat)*_v)\n",
    "\n",
    "        K.update(self.u,K.in_train_phase(_u, self.u))\n",
    "        return self.kernel / sigma\n",
    "\n",
    "def _l2normalize(x):\n",
    "    return x / K.sqrt(K.sum(K.square(x)) + K.epsilon())\n",
    "set_gpu_config(\"0\",0.5)\n",
    "\n",
    "epochs = 30\n",
    "image_size = (32,32,1)\n",
    "noise_size = (2,2,32)\n",
    "batch_size = 64\n",
    "sample_size=10\n",
    "size=32\n",
    "sample_interval=200\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train=[cv2.resize(i,(32,32)) for i in x_train]\n",
    "x_test=[cv2.resize(i,(32,32)) for i in x_test]\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "x_train=np.expand_dims(x_train,axis=3)\n",
    "x_test=np.expand_dims(x_test,axis=3)\n",
    "num_of_data = x_train.shape[0]\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train = (x_train/255)*2-1\n",
    "x_test = (x_test/255)*2-1\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)\n",
    "x = []\n",
    "y = np.zeros((31, 1), dtype=np.int)\n",
    "y = list(y)\n",
    "for i in range(31):\n",
    "    y[i] = []\n",
    "generator = build_generator(noise_size)\n",
    "discriminator = build_discriminator(image_size)\n",
    "d_train, g_train = build_functions(batch_size, noise_size, image_size, generator, discriminator)\n",
    "\n",
    "nb_batches = int(x_train.shape[0] / batch_size)\n",
    "global_step = 0\n",
    "steps=[]\n",
    "values=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for index in range(nb_batches):\n",
    "        global_step += 1\n",
    "        real_images = x_train[index * batch_size:(index + 1) * batch_size]\n",
    "        d_loss, = d_train([real_images, 1])\n",
    "        g_loss, = g_train([real_images, 1])\n",
    "#         print(\"[{0}/{1}] [{2}_{3}] d_loss: {4:.4}, g_loss: {5:.4}\".format(epoch, epochs, epoch, global_step, d_loss,\n",
    "#                                                                               g_loss))\n",
    "        if global_step % sample_interval == 0:\n",
    "            image = generator.predict(np.random.normal(size=(10000,) + noise_size))\n",
    "            image = 255 * (image + 1) / 2\n",
    "            label_dict,value=calculate_labels(image,epoch,global_step)\n",
    "            steps.append(global_step)\n",
    "            values.append(value)\n",
    "#             plt.subplots(1, 1)\n",
    "plt.plot(steps,values)\n",
    "plt.xlim([0,40000])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('epochs')\n",
    "plt.tick_params(axis='both',which='major',labelsize=13)\n",
    "plt.legend(loc='lower right')\n",
    "if not os.path.isdir('images_sngan'):\n",
    "    os.mkdir('images_sngan')\n",
    "plt.savefig(\"images_sngan/mode_drop.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
