{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import torch\n",
    "from keras.utils.np_utils import *\n",
    "from keras.datasets import mnist\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH ='/home/imi432_006/huangdengrong/GAN-Research/metrics_gan/metrics/classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def calculate_labels(images,epoch,global_step):\n",
    "    label_dict={}\n",
    "    for i in range(10):\n",
    "        label_dict[i]=0\n",
    "    eval_images = tf.convert_to_tensor(images)\n",
    "    y_logit = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    labels=tf.argmax(y_logit, 1)\n",
    "    labels=tf.Session().run(labels)\n",
    "    for data in labels:\n",
    "        label_dict[data]+=1\n",
    "    for i in range(10):\n",
    "        label_dict[i]=label_dict[i]/len(images)\n",
    "    max_value=max(label_dict.values())\n",
    "    min_value=min(label_dict.values())\n",
    "    print('epoch:%d   global_step:%d'%(epoch,global_step))\n",
    "    print(label_dict)\n",
    "    print('chazhi:%.8f'%(max_value-min_value))\n",
    "    return label_dict,max_value-min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "epoch:0   global_step:200\n",
      "{0: 0.0808, 1: 0.047, 2: 0.0856, 3: 0.1758, 4: 0.1805, 5: 0.0281, 6: 0.033, 7: 0.1717, 8: 0.1683, 9: 0.0292}\n",
      "chazhi:0.15240000\n",
      "epoch:0   global_step:400\n",
      "{0: 0.0909, 1: 0.035, 2: 0.068, 3: 0.1885, 4: 0.143, 5: 0.0314, 6: 0.0367, 7: 0.1896, 8: 0.17, 9: 0.0469}\n",
      "chazhi:0.15820000\n",
      "epoch:0   global_step:600\n",
      "{0: 0.1125, 1: 0.0512, 2: 0.064, 3: 0.1358, 4: 0.1635, 5: 0.0245, 6: 0.0528, 7: 0.1775, 8: 0.1627, 9: 0.0555}\n",
      "chazhi:0.15300000\n",
      "epoch:0   global_step:800\n",
      "{0: 0.1377, 1: 0.0753, 2: 0.0758, 3: 0.0978, 4: 0.1508, 5: 0.0249, 6: 0.0568, 7: 0.1695, 8: 0.1347, 9: 0.0767}\n",
      "chazhi:0.14460000\n",
      "epoch:1   global_step:1000\n",
      "{0: 0.1236, 1: 0.0963, 2: 0.073, 3: 0.0856, 4: 0.1471, 5: 0.0263, 6: 0.0796, 7: 0.1849, 8: 0.1182, 9: 0.0654}\n",
      "chazhi:0.15860000\n",
      "epoch:1   global_step:1200\n",
      "{0: 0.1242, 1: 0.0982, 2: 0.0594, 3: 0.0821, 4: 0.1485, 5: 0.032, 6: 0.0873, 7: 0.1791, 8: 0.1088, 9: 0.0804}\n",
      "chazhi:0.14710000\n",
      "epoch:1   global_step:1400\n",
      "{0: 0.1137, 1: 0.1096, 2: 0.0707, 3: 0.1012, 4: 0.1221, 5: 0.0409, 6: 0.0742, 7: 0.1842, 8: 0.1157, 9: 0.0677}\n",
      "chazhi:0.14330000\n",
      "epoch:1   global_step:1600\n",
      "{0: 0.1283, 1: 0.0964, 2: 0.0875, 3: 0.0711, 4: 0.1577, 5: 0.0276, 6: 0.0953, 7: 0.1555, 8: 0.1073, 9: 0.0733}\n",
      "chazhi:0.13010000\n",
      "epoch:1   global_step:1800\n",
      "{0: 0.1165, 1: 0.0916, 2: 0.0787, 3: 0.096, 4: 0.1349, 5: 0.0431, 6: 0.0894, 7: 0.138, 8: 0.1212, 9: 0.0906}\n",
      "chazhi:0.09490000\n",
      "epoch:2   global_step:2000\n",
      "{0: 0.1392, 1: 0.1111, 2: 0.069, 3: 0.0709, 4: 0.1423, 5: 0.0255, 6: 0.0997, 7: 0.1507, 8: 0.1136, 9: 0.078}\n",
      "chazhi:0.12520000\n",
      "epoch:2   global_step:2200\n",
      "{0: 0.1029, 1: 0.1042, 2: 0.07, 3: 0.0909, 4: 0.111, 5: 0.0488, 6: 0.0865, 7: 0.1477, 8: 0.1363, 9: 0.1017}\n",
      "chazhi:0.09890000\n",
      "epoch:2   global_step:2400\n",
      "{0: 0.1181, 1: 0.1212, 2: 0.0767, 3: 0.0957, 4: 0.1248, 5: 0.0362, 6: 0.09, 7: 0.1359, 8: 0.1212, 9: 0.0802}\n",
      "chazhi:0.09970000\n",
      "epoch:2   global_step:2600\n",
      "{0: 0.1061, 1: 0.0995, 2: 0.0788, 3: 0.084, 4: 0.1206, 5: 0.0436, 6: 0.1046, 7: 0.1437, 8: 0.1253, 9: 0.0938}\n",
      "chazhi:0.10010000\n",
      "epoch:2   global_step:2800\n",
      "{0: 0.1243, 1: 0.1045, 2: 0.0834, 3: 0.0742, 4: 0.136, 5: 0.0432, 6: 0.0961, 7: 0.1656, 8: 0.1086, 9: 0.0641}\n",
      "chazhi:0.12240000\n",
      "epoch:3   global_step:3000\n",
      "{0: 0.1108, 1: 0.1246, 2: 0.0772, 3: 0.0859, 4: 0.1508, 5: 0.0356, 6: 0.1047, 7: 0.1425, 8: 0.1065, 9: 0.0614}\n",
      "chazhi:0.11520000\n",
      "epoch:3   global_step:3200\n",
      "{0: 0.1291, 1: 0.1135, 2: 0.0621, 3: 0.0774, 4: 0.133, 5: 0.0349, 6: 0.1083, 7: 0.1501, 8: 0.1133, 9: 0.0783}\n",
      "chazhi:0.11520000\n",
      "epoch:3   global_step:3400\n",
      "{0: 0.1065, 1: 0.1062, 2: 0.0836, 3: 0.1042, 4: 0.1234, 5: 0.0432, 6: 0.103, 7: 0.1299, 8: 0.1097, 9: 0.0903}\n",
      "chazhi:0.08670000\n",
      "epoch:3   global_step:3600\n",
      "{0: 0.1232, 1: 0.104, 2: 0.0729, 3: 0.0814, 4: 0.1369, 5: 0.0477, 6: 0.1083, 7: 0.1436, 8: 0.1148, 9: 0.0672}\n",
      "chazhi:0.09590000\n",
      "epoch:4   global_step:3800\n",
      "{0: 0.1062, 1: 0.0835, 2: 0.0841, 3: 0.1061, 4: 0.1189, 5: 0.0562, 6: 0.1139, 7: 0.1401, 8: 0.1122, 9: 0.0788}\n",
      "chazhi:0.08390000\n",
      "epoch:4   global_step:4000\n",
      "{0: 0.1103, 1: 0.0917, 2: 0.0823, 3: 0.1016, 4: 0.1202, 5: 0.0472, 6: 0.1127, 7: 0.1408, 8: 0.1161, 9: 0.0771}\n",
      "chazhi:0.09360000\n",
      "epoch:4   global_step:4200\n",
      "{0: 0.1075, 1: 0.0978, 2: 0.0731, 3: 0.0993, 4: 0.1075, 5: 0.0546, 6: 0.1071, 7: 0.1221, 8: 0.1258, 9: 0.1052}\n",
      "chazhi:0.07120000\n",
      "epoch:4   global_step:4400\n",
      "{0: 0.1146, 1: 0.1079, 2: 0.0853, 3: 0.1014, 4: 0.1088, 5: 0.0529, 6: 0.12, 7: 0.1332, 8: 0.1104, 9: 0.0655}\n",
      "chazhi:0.08030000\n",
      "epoch:4   global_step:4600\n",
      "{0: 0.1125, 1: 0.0969, 2: 0.0941, 3: 0.0835, 4: 0.12, 5: 0.0445, 6: 0.1114, 7: 0.1349, 8: 0.1139, 9: 0.0883}\n",
      "chazhi:0.09040000\n",
      "epoch:5   global_step:4800\n",
      "{0: 0.1058, 1: 0.1207, 2: 0.0712, 3: 0.0946, 4: 0.1123, 5: 0.0378, 6: 0.1248, 7: 0.1456, 8: 0.1141, 9: 0.0731}\n",
      "chazhi:0.10780000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5   global_step:5000\n",
      "{0: 0.1075, 1: 0.1136, 2: 0.0737, 3: 0.0905, 4: 0.1172, 5: 0.0523, 6: 0.1019, 7: 0.12, 8: 0.1298, 9: 0.0935}\n",
      "chazhi:0.07750000\n",
      "epoch:5   global_step:5200\n",
      "{0: 0.1043, 1: 0.1127, 2: 0.0852, 3: 0.0826, 4: 0.1273, 5: 0.0557, 6: 0.1066, 7: 0.1424, 8: 0.0998, 9: 0.0834}\n",
      "chazhi:0.08670000\n",
      "epoch:5   global_step:5400\n",
      "{0: 0.1049, 1: 0.1039, 2: 0.0935, 3: 0.092, 4: 0.1355, 5: 0.0467, 6: 0.0967, 7: 0.1408, 8: 0.107, 9: 0.079}\n",
      "chazhi:0.09410000\n",
      "epoch:5   global_step:5600\n",
      "{0: 0.1127, 1: 0.1026, 2: 0.0902, 3: 0.098, 4: 0.1213, 5: 0.0553, 6: 0.089, 7: 0.1478, 8: 0.1063, 9: 0.0768}\n",
      "chazhi:0.09250000\n",
      "epoch:6   global_step:5800\n",
      "{0: 0.1029, 1: 0.1097, 2: 0.0905, 3: 0.0926, 4: 0.1159, 5: 0.0565, 6: 0.1141, 7: 0.1334, 8: 0.1063, 9: 0.0781}\n",
      "chazhi:0.07690000\n",
      "epoch:6   global_step:6000\n",
      "{0: 0.1087, 1: 0.1074, 2: 0.0892, 3: 0.0832, 4: 0.1276, 5: 0.0439, 6: 0.1095, 7: 0.1316, 8: 0.1236, 9: 0.0753}\n",
      "chazhi:0.08770000\n",
      "epoch:6   global_step:6200\n",
      "{0: 0.1292, 1: 0.0958, 2: 0.0866, 3: 0.0878, 4: 0.1207, 5: 0.0435, 6: 0.1102, 7: 0.1118, 8: 0.1307, 9: 0.0837}\n",
      "chazhi:0.08720000\n",
      "epoch:6   global_step:6400\n",
      "{0: 0.0999, 1: 0.1052, 2: 0.0848, 3: 0.0953, 4: 0.1166, 5: 0.0778, 6: 0.1133, 7: 0.1269, 8: 0.1043, 9: 0.0759}\n",
      "chazhi:0.05100000\n",
      "epoch:7   global_step:6600\n",
      "{0: 0.1175, 1: 0.097, 2: 0.0882, 3: 0.089, 4: 0.1351, 5: 0.0477, 6: 0.1045, 7: 0.131, 8: 0.1099, 9: 0.0801}\n",
      "chazhi:0.08740000\n",
      "epoch:7   global_step:6800\n",
      "{0: 0.1061, 1: 0.1131, 2: 0.0832, 3: 0.1036, 4: 0.1303, 5: 0.0558, 6: 0.098, 7: 0.1191, 8: 0.1101, 9: 0.0807}\n",
      "chazhi:0.07450000\n",
      "epoch:7   global_step:7000\n",
      "{0: 0.1146, 1: 0.1039, 2: 0.0757, 3: 0.0966, 4: 0.1269, 5: 0.0639, 6: 0.1012, 7: 0.1222, 8: 0.1054, 9: 0.0896}\n",
      "chazhi:0.06300000\n",
      "epoch:7   global_step:7200\n",
      "{0: 0.1121, 1: 0.119, 2: 0.0855, 3: 0.0817, 4: 0.1136, 5: 0.0451, 6: 0.1189, 7: 0.1188, 8: 0.1194, 9: 0.0859}\n",
      "chazhi:0.07430000\n",
      "epoch:7   global_step:7400\n",
      "{0: 0.1174, 1: 0.1236, 2: 0.0842, 3: 0.0844, 4: 0.1263, 5: 0.0441, 6: 0.1073, 7: 0.1427, 8: 0.0926, 9: 0.0774}\n",
      "chazhi:0.09860000\n",
      "epoch:8   global_step:7600\n",
      "{0: 0.1142, 1: 0.112, 2: 0.0743, 3: 0.1003, 4: 0.1243, 5: 0.0453, 6: 0.1001, 7: 0.1212, 8: 0.1207, 9: 0.0876}\n",
      "chazhi:0.07900000\n",
      "epoch:8   global_step:7800\n",
      "{0: 0.1071, 1: 0.1237, 2: 0.0718, 3: 0.098, 4: 0.1116, 5: 0.0617, 6: 0.1061, 7: 0.1289, 8: 0.1106, 9: 0.0805}\n",
      "chazhi:0.06720000\n",
      "epoch:8   global_step:8000\n",
      "{0: 0.103, 1: 0.1101, 2: 0.0852, 3: 0.0922, 4: 0.132, 5: 0.0496, 6: 0.1204, 7: 0.1309, 8: 0.1068, 9: 0.0698}\n",
      "chazhi:0.08240000\n",
      "epoch:8   global_step:8200\n",
      "{0: 0.1155, 1: 0.1012, 2: 0.0939, 3: 0.0897, 4: 0.1202, 5: 0.0551, 6: 0.1, 7: 0.1284, 8: 0.1103, 9: 0.0857}\n",
      "chazhi:0.07330000\n",
      "epoch:8   global_step:8400\n",
      "{0: 0.1124, 1: 0.1065, 2: 0.0847, 3: 0.0886, 4: 0.1185, 5: 0.0637, 6: 0.1006, 7: 0.137, 8: 0.1153, 9: 0.0727}\n",
      "chazhi:0.07330000\n",
      "epoch:9   global_step:8600\n",
      "{0: 0.1143, 1: 0.1232, 2: 0.0745, 3: 0.0838, 4: 0.1137, 5: 0.0566, 6: 0.1113, 7: 0.1216, 8: 0.1216, 9: 0.0794}\n",
      "chazhi:0.06660000\n",
      "epoch:9   global_step:8800\n",
      "{0: 0.1169, 1: 0.1151, 2: 0.0863, 3: 0.0798, 4: 0.1182, 5: 0.0494, 6: 0.1109, 7: 0.1164, 8: 0.1224, 9: 0.0846}\n",
      "chazhi:0.07300000\n",
      "epoch:9   global_step:9000\n",
      "{0: 0.1096, 1: 0.1227, 2: 0.0859, 3: 0.0916, 4: 0.1196, 5: 0.0618, 6: 0.1096, 7: 0.1198, 8: 0.0976, 9: 0.0818}\n",
      "chazhi:0.06090000\n",
      "epoch:9   global_step:9200\n",
      "{0: 0.0985, 1: 0.0971, 2: 0.0911, 3: 0.1, 4: 0.1105, 5: 0.0541, 6: 0.104, 7: 0.1262, 8: 0.1298, 9: 0.0887}\n",
      "chazhi:0.07570000\n",
      "epoch:10   global_step:9400\n",
      "{0: 0.1184, 1: 0.1174, 2: 0.088, 3: 0.0961, 4: 0.1388, 5: 0.0379, 6: 0.1048, 7: 0.1246, 8: 0.1031, 9: 0.0709}\n",
      "chazhi:0.10090000\n",
      "epoch:10   global_step:9600\n",
      "{0: 0.0973, 1: 0.1007, 2: 0.0923, 3: 0.113, 4: 0.1073, 5: 0.0611, 6: 0.1066, 7: 0.1263, 8: 0.1075, 9: 0.0879}\n",
      "chazhi:0.06520000\n",
      "epoch:10   global_step:9800\n",
      "{0: 0.1137, 1: 0.1236, 2: 0.0812, 3: 0.0933, 4: 0.1064, 5: 0.0605, 6: 0.1009, 7: 0.123, 8: 0.1139, 9: 0.0835}\n",
      "chazhi:0.06310000\n",
      "epoch:10   global_step:10000\n",
      "{0: 0.1094, 1: 0.1116, 2: 0.0847, 3: 0.0933, 4: 0.117, 5: 0.0502, 6: 0.1078, 7: 0.1157, 8: 0.1218, 9: 0.0885}\n",
      "chazhi:0.07160000\n",
      "epoch:10   global_step:10200\n",
      "{0: 0.1162, 1: 0.1088, 2: 0.0866, 3: 0.0865, 4: 0.1288, 5: 0.0589, 6: 0.109, 7: 0.1305, 8: 0.1023, 9: 0.0724}\n",
      "chazhi:0.07160000\n",
      "epoch:11   global_step:10400\n",
      "{0: 0.1154, 1: 0.1184, 2: 0.0855, 3: 0.1, 4: 0.1136, 5: 0.0642, 6: 0.0975, 7: 0.1148, 8: 0.104, 9: 0.0866}\n",
      "chazhi:0.05420000\n",
      "epoch:11   global_step:10600\n",
      "{0: 0.1134, 1: 0.1181, 2: 0.0734, 3: 0.0896, 4: 0.1184, 5: 0.0558, 6: 0.1018, 7: 0.1277, 8: 0.1157, 9: 0.0861}\n",
      "chazhi:0.07190000\n",
      "epoch:11   global_step:10800\n",
      "{0: 0.1158, 1: 0.1204, 2: 0.0796, 3: 0.0847, 4: 0.1234, 5: 0.0439, 6: 0.1183, 7: 0.1394, 8: 0.0996, 9: 0.0749}\n",
      "chazhi:0.09550000\n",
      "epoch:11   global_step:11000\n",
      "{0: 0.1137, 1: 0.1287, 2: 0.0814, 3: 0.0865, 4: 0.112, 5: 0.0578, 6: 0.1048, 7: 0.1268, 8: 0.1041, 9: 0.0842}\n",
      "chazhi:0.07090000\n",
      "epoch:11   global_step:11200\n",
      "{0: 0.105, 1: 0.1053, 2: 0.0876, 3: 0.091, 4: 0.1224, 5: 0.0742, 6: 0.1034, 7: 0.1239, 8: 0.1003, 9: 0.0869}\n",
      "chazhi:0.04970000\n",
      "epoch:12   global_step:11400\n",
      "{0: 0.1058, 1: 0.1099, 2: 0.0874, 3: 0.097, 4: 0.1112, 5: 0.0728, 6: 0.1083, 7: 0.1192, 8: 0.1067, 9: 0.0817}\n",
      "chazhi:0.04640000\n",
      "epoch:12   global_step:11600\n",
      "{0: 0.1078, 1: 0.1093, 2: 0.0807, 3: 0.0982, 4: 0.1181, 5: 0.0598, 6: 0.1082, 7: 0.1277, 8: 0.1065, 9: 0.0837}\n",
      "chazhi:0.06790000\n",
      "epoch:12   global_step:11800\n",
      "{0: 0.1217, 1: 0.1095, 2: 0.0901, 3: 0.0854, 4: 0.1261, 5: 0.06, 6: 0.0981, 7: 0.1215, 8: 0.1083, 9: 0.0793}\n",
      "chazhi:0.06610000\n",
      "epoch:12   global_step:12000\n",
      "{0: 0.1163, 1: 0.1087, 2: 0.086, 3: 0.0973, 4: 0.1031, 5: 0.0554, 6: 0.1109, 7: 0.1099, 8: 0.1274, 9: 0.085}\n",
      "chazhi:0.07200000\n",
      "epoch:13   global_step:12200\n",
      "{0: 0.117, 1: 0.1088, 2: 0.0891, 3: 0.1045, 4: 0.1285, 5: 0.05, 6: 0.1081, 7: 0.1328, 8: 0.0921, 9: 0.0691}\n",
      "chazhi:0.08280000\n",
      "epoch:13   global_step:12400\n",
      "{0: 0.1068, 1: 0.1178, 2: 0.0848, 3: 0.1006, 4: 0.1239, 5: 0.0564, 6: 0.0993, 7: 0.1325, 8: 0.1003, 9: 0.0776}\n",
      "chazhi:0.07610000\n",
      "epoch:13   global_step:12600\n",
      "{0: 0.1105, 1: 0.1191, 2: 0.078, 3: 0.0913, 4: 0.1243, 5: 0.0585, 6: 0.1014, 7: 0.1111, 8: 0.1254, 9: 0.0804}\n",
      "chazhi:0.06690000\n",
      "epoch:13   global_step:12800\n",
      "{0: 0.1169, 1: 0.1172, 2: 0.086, 3: 0.0845, 4: 0.1177, 5: 0.0467, 6: 0.1047, 7: 0.1202, 8: 0.1229, 9: 0.0832}\n",
      "chazhi:0.07620000\n",
      "epoch:13   global_step:13000\n",
      "{0: 0.106, 1: 0.1164, 2: 0.0951, 3: 0.0818, 4: 0.1117, 5: 0.0705, 6: 0.1142, 7: 0.1165, 8: 0.11, 9: 0.0778}\n",
      "chazhi:0.04600000\n",
      "epoch:14   global_step:13200\n",
      "{0: 0.1247, 1: 0.1045, 2: 0.088, 3: 0.0849, 4: 0.1167, 5: 0.0628, 6: 0.1003, 7: 0.1174, 8: 0.1134, 9: 0.0873}\n",
      "chazhi:0.06190000\n",
      "epoch:14   global_step:13400\n",
      "{0: 0.1105, 1: 0.1113, 2: 0.0847, 3: 0.097, 4: 0.1142, 5: 0.0593, 6: 0.1026, 7: 0.1302, 8: 0.1071, 9: 0.0831}\n",
      "chazhi:0.07090000\n",
      "epoch:14   global_step:13600\n",
      "{0: 0.1077, 1: 0.0896, 2: 0.0968, 3: 0.1047, 4: 0.1243, 5: 0.0377, 6: 0.1277, 7: 0.1423, 8: 0.1023, 9: 0.0669}\n",
      "chazhi:0.10460000\n",
      "epoch:14   global_step:13800\n",
      "{0: 0.1036, 1: 0.1099, 2: 0.0856, 3: 0.104, 4: 0.113, 5: 0.0804, 6: 0.1021, 7: 0.1137, 8: 0.1023, 9: 0.0854}\n",
      "chazhi:0.03330000\n",
      "epoch:14   global_step:14000\n",
      "{0: 0.114, 1: 0.1117, 2: 0.0885, 3: 0.0883, 4: 0.1027, 5: 0.0695, 6: 0.1035, 7: 0.1137, 8: 0.1073, 9: 0.1008}\n",
      "chazhi:0.04450000\n",
      "epoch:15   global_step:14200\n",
      "{0: 0.1105, 1: 0.1219, 2: 0.0861, 3: 0.0813, 4: 0.117, 5: 0.0532, 6: 0.1109, 7: 0.1147, 8: 0.1172, 9: 0.0872}\n",
      "chazhi:0.06870000\n",
      "epoch:15   global_step:14400\n",
      "{0: 0.1011, 1: 0.0974, 2: 0.0859, 3: 0.1095, 4: 0.1092, 5: 0.0581, 6: 0.1101, 7: 0.1228, 8: 0.117, 9: 0.0889}\n",
      "chazhi:0.06470000\n",
      "epoch:15   global_step:14600\n",
      "{0: 0.1157, 1: 0.1249, 2: 0.0758, 3: 0.0967, 4: 0.1063, 5: 0.0595, 6: 0.1014, 7: 0.129, 8: 0.1011, 9: 0.0896}\n",
      "chazhi:0.06950000\n",
      "epoch:15   global_step:14800\n",
      "{0: 0.0996, 1: 0.102, 2: 0.0952, 3: 0.0938, 4: 0.1204, 5: 0.0684, 6: 0.1055, 7: 0.1126, 8: 0.1083, 9: 0.0942}\n",
      "chazhi:0.05200000\n",
      "epoch:16   global_step:15000\n",
      "{0: 0.1174, 1: 0.1096, 2: 0.0915, 3: 0.0911, 4: 0.1203, 5: 0.0532, 6: 0.1123, 7: 0.1223, 8: 0.0992, 9: 0.0831}\n",
      "chazhi:0.06910000\n",
      "epoch:16   global_step:15200\n",
      "{0: 0.1096, 1: 0.1181, 2: 0.0822, 3: 0.0899, 4: 0.1306, 5: 0.0557, 6: 0.106, 7: 0.1194, 8: 0.1109, 9: 0.0776}\n",
      "chazhi:0.07490000\n",
      "epoch:16   global_step:15400\n",
      "{0: 0.1074, 1: 0.1141, 2: 0.083, 3: 0.0919, 4: 0.1142, 5: 0.0703, 6: 0.0942, 7: 0.1252, 8: 0.1136, 9: 0.0861}\n",
      "chazhi:0.05490000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16   global_step:15600\n",
      "{0: 0.1045, 1: 0.1246, 2: 0.0806, 3: 0.0964, 4: 0.1035, 5: 0.0706, 6: 0.1062, 7: 0.1081, 8: 0.1065, 9: 0.099}\n",
      "chazhi:0.05400000\n",
      "epoch:16   global_step:15800\n",
      "{0: 0.1037, 1: 0.1188, 2: 0.0899, 3: 0.094, 4: 0.1184, 5: 0.0682, 6: 0.1064, 7: 0.1234, 8: 0.1029, 9: 0.0743}\n",
      "chazhi:0.05520000\n",
      "epoch:17   global_step:16000\n",
      "{0: 0.1128, 1: 0.1055, 2: 0.0851, 3: 0.1054, 4: 0.1145, 5: 0.0671, 6: 0.0984, 7: 0.1261, 8: 0.1013, 9: 0.0838}\n",
      "chazhi:0.05900000\n",
      "epoch:17   global_step:16200\n",
      "{0: 0.1087, 1: 0.119, 2: 0.0727, 3: 0.1025, 4: 0.1324, 5: 0.0604, 6: 0.0981, 7: 0.1217, 8: 0.1028, 9: 0.0817}\n",
      "chazhi:0.07200000\n",
      "epoch:17   global_step:16400\n",
      "{0: 0.1044, 1: 0.0783, 2: 0.0974, 3: 0.1003, 4: 0.1175, 5: 0.056, 6: 0.1253, 7: 0.1247, 8: 0.1113, 9: 0.0848}\n",
      "chazhi:0.06930000\n",
      "epoch:17   global_step:16600\n",
      "{0: 0.1144, 1: 0.1048, 2: 0.092, 3: 0.0848, 4: 0.1271, 5: 0.0608, 6: 0.1056, 7: 0.1083, 8: 0.1126, 9: 0.0896}\n",
      "chazhi:0.06630000\n",
      "epoch:17   global_step:16800\n",
      "{0: 0.1021, 1: 0.1173, 2: 0.0864, 3: 0.0952, 4: 0.1193, 5: 0.06, 6: 0.1127, 7: 0.1143, 8: 0.1075, 9: 0.0852}\n",
      "chazhi:0.05930000\n",
      "epoch:18   global_step:17000\n",
      "{0: 0.1055, 1: 0.1267, 2: 0.0798, 3: 0.0868, 4: 0.1154, 5: 0.0601, 6: 0.104, 7: 0.1308, 8: 0.1109, 9: 0.08}\n",
      "chazhi:0.07070000\n",
      "epoch:18   global_step:17200\n",
      "{0: 0.1101, 1: 0.1162, 2: 0.0734, 3: 0.0981, 4: 0.1185, 5: 0.058, 6: 0.1032, 7: 0.1157, 8: 0.1169, 9: 0.0899}\n",
      "chazhi:0.06050000\n",
      "epoch:18   global_step:17400\n",
      "{0: 0.1038, 1: 0.1232, 2: 0.0739, 3: 0.0963, 4: 0.1163, 5: 0.0656, 6: 0.1019, 7: 0.1381, 8: 0.0996, 9: 0.0813}\n",
      "chazhi:0.07250000\n",
      "epoch:18   global_step:17600\n",
      "{0: 0.1108, 1: 0.1076, 2: 0.0929, 3: 0.0959, 4: 0.1177, 5: 0.0559, 6: 0.1, 7: 0.1264, 8: 0.104, 9: 0.0888}\n",
      "chazhi:0.07050000\n",
      "epoch:18   global_step:17800\n",
      "{0: 0.1105, 1: 0.1057, 2: 0.1039, 3: 0.0859, 4: 0.1262, 5: 0.0542, 6: 0.11, 7: 0.1186, 8: 0.0993, 9: 0.0857}\n",
      "chazhi:0.07200000\n",
      "epoch:19   global_step:18000\n",
      "{0: 0.1191, 1: 0.111, 2: 0.0881, 3: 0.095, 4: 0.1146, 5: 0.0504, 6: 0.1061, 7: 0.1227, 8: 0.1019, 9: 0.0911}\n",
      "chazhi:0.07230000\n",
      "epoch:19   global_step:18200\n",
      "{0: 0.1074, 1: 0.1091, 2: 0.0816, 3: 0.0975, 4: 0.1201, 5: 0.071, 6: 0.109, 7: 0.1169, 8: 0.1093, 9: 0.0781}\n",
      "chazhi:0.04910000\n",
      "epoch:19   global_step:18400\n",
      "{0: 0.1074, 1: 0.1008, 2: 0.0912, 3: 0.0915, 4: 0.1034, 5: 0.0785, 6: 0.1027, 7: 0.1061, 8: 0.1222, 9: 0.0962}\n",
      "chazhi:0.04370000\n",
      "epoch:19   global_step:18600\n",
      "{0: 0.1088, 1: 0.1054, 2: 0.0929, 3: 0.0957, 4: 0.1149, 5: 0.0648, 6: 0.1034, 7: 0.115, 8: 0.107, 9: 0.0921}\n",
      "chazhi:0.05020000\n",
      "epoch:20   global_step:18800\n",
      "{0: 0.1123, 1: 0.1056, 2: 0.0934, 3: 0.0966, 4: 0.119, 5: 0.0672, 6: 0.1054, 7: 0.1175, 8: 0.1052, 9: 0.0778}\n",
      "chazhi:0.05180000\n",
      "epoch:20   global_step:19000\n",
      "{0: 0.1029, 1: 0.1156, 2: 0.0822, 3: 0.0915, 4: 0.1196, 5: 0.059, 6: 0.1107, 7: 0.1217, 8: 0.1112, 9: 0.0856}\n",
      "chazhi:0.06270000\n",
      "epoch:20   global_step:19200\n",
      "{0: 0.0916, 1: 0.0906, 2: 0.1046, 3: 0.0988, 4: 0.1162, 5: 0.057, 6: 0.1135, 7: 0.1182, 8: 0.1167, 9: 0.0928}\n",
      "chazhi:0.06120000\n",
      "epoch:20   global_step:19400\n",
      "{0: 0.1162, 1: 0.1071, 2: 0.0877, 3: 0.1014, 4: 0.1238, 5: 0.0551, 6: 0.1031, 7: 0.13, 8: 0.0978, 9: 0.0778}\n",
      "chazhi:0.07490000\n",
      "epoch:20   global_step:19600\n",
      "{0: 0.104, 1: 0.1028, 2: 0.0962, 3: 0.0971, 4: 0.1101, 5: 0.072, 6: 0.0999, 7: 0.1234, 8: 0.1063, 9: 0.0882}\n",
      "chazhi:0.05140000\n",
      "epoch:21   global_step:19800\n",
      "{0: 0.1107, 1: 0.1142, 2: 0.0959, 3: 0.1019, 4: 0.1226, 5: 0.0609, 6: 0.0998, 7: 0.1288, 8: 0.0908, 9: 0.0744}\n",
      "chazhi:0.06790000\n",
      "epoch:21   global_step:20000\n",
      "{0: 0.1007, 1: 0.1177, 2: 0.0737, 3: 0.0963, 4: 0.1085, 5: 0.0699, 6: 0.1097, 7: 0.1102, 8: 0.1115, 9: 0.1018}\n",
      "chazhi:0.04780000\n",
      "epoch:21   global_step:20200\n",
      "{0: 0.1084, 1: 0.118, 2: 0.0906, 3: 0.096, 4: 0.1184, 5: 0.0514, 6: 0.1153, 7: 0.1287, 8: 0.0934, 9: 0.0798}\n",
      "chazhi:0.07730000\n",
      "epoch:21   global_step:20400\n",
      "{0: 0.1049, 1: 0.1125, 2: 0.0907, 3: 0.0866, 4: 0.1109, 5: 0.0664, 6: 0.1005, 7: 0.1163, 8: 0.1194, 9: 0.0918}\n",
      "chazhi:0.05300000\n",
      "epoch:21   global_step:20600\n",
      "{0: 0.1103, 1: 0.0975, 2: 0.0957, 3: 0.0934, 4: 0.1215, 5: 0.0558, 6: 0.1101, 7: 0.1223, 8: 0.1106, 9: 0.0828}\n",
      "chazhi:0.06650000\n",
      "epoch:22   global_step:20800\n",
      "{0: 0.1075, 1: 0.1066, 2: 0.0924, 3: 0.0865, 4: 0.1165, 5: 0.0559, 6: 0.113, 7: 0.1266, 8: 0.1103, 9: 0.0847}\n",
      "chazhi:0.07070000\n",
      "epoch:22   global_step:21000\n",
      "{0: 0.1049, 1: 0.1114, 2: 0.0735, 3: 0.0907, 4: 0.1277, 5: 0.0628, 6: 0.1074, 7: 0.1247, 8: 0.1082, 9: 0.0887}\n",
      "chazhi:0.06490000\n",
      "epoch:22   global_step:21200\n",
      "{0: 0.1169, 1: 0.1182, 2: 0.0828, 3: 0.0865, 4: 0.1121, 5: 0.0553, 6: 0.0993, 7: 0.1229, 8: 0.1165, 9: 0.0895}\n",
      "chazhi:0.06760000\n",
      "epoch:22   global_step:21400\n",
      "{0: 0.1071, 1: 0.1018, 2: 0.1008, 3: 0.0889, 4: 0.1249, 5: 0.0581, 6: 0.1063, 7: 0.1079, 8: 0.1129, 9: 0.0913}\n",
      "chazhi:0.06680000\n",
      "epoch:23   global_step:21600\n",
      "{0: 0.1173, 1: 0.1163, 2: 0.0828, 3: 0.0794, 4: 0.1306, 5: 0.0602, 6: 0.1036, 7: 0.1242, 8: 0.1024, 9: 0.0832}\n",
      "chazhi:0.07040000\n",
      "epoch:23   global_step:21800\n",
      "{0: 0.0896, 1: 0.1069, 2: 0.0865, 3: 0.1065, 4: 0.1033, 5: 0.0788, 6: 0.0967, 7: 0.118, 8: 0.1151, 9: 0.0986}\n",
      "chazhi:0.03920000\n",
      "epoch:23   global_step:22000\n",
      "{0: 0.1049, 1: 0.1037, 2: 0.0931, 3: 0.0976, 4: 0.1093, 5: 0.0601, 6: 0.1089, 7: 0.1197, 8: 0.111, 9: 0.0917}\n",
      "chazhi:0.05960000\n",
      "epoch:23   global_step:22200\n",
      "{0: 0.1138, 1: 0.0959, 2: 0.0889, 3: 0.0926, 4: 0.1222, 5: 0.0546, 6: 0.1109, 7: 0.1321, 8: 0.1133, 9: 0.0757}\n",
      "chazhi:0.07750000\n",
      "epoch:23   global_step:22400\n",
      "{0: 0.1138, 1: 0.1065, 2: 0.0982, 3: 0.0895, 4: 0.1302, 5: 0.0572, 6: 0.1086, 7: 0.127, 8: 0.0923, 9: 0.0767}\n",
      "chazhi:0.07300000\n",
      "epoch:24   global_step:22600\n",
      "{0: 0.1051, 1: 0.1145, 2: 0.091, 3: 0.0899, 4: 0.1156, 5: 0.0731, 6: 0.1042, 7: 0.1124, 8: 0.1047, 9: 0.0895}\n",
      "chazhi:0.04250000\n",
      "epoch:24   global_step:22800\n",
      "{0: 0.1091, 1: 0.1033, 2: 0.0876, 3: 0.0897, 4: 0.116, 5: 0.0585, 6: 0.1095, 7: 0.1189, 8: 0.1143, 9: 0.0931}\n",
      "chazhi:0.06040000\n",
      "epoch:24   global_step:23000\n",
      "{0: 0.1144, 1: 0.1168, 2: 0.0879, 3: 0.0868, 4: 0.1268, 5: 0.0607, 6: 0.1039, 7: 0.1273, 8: 0.0942, 9: 0.0812}\n",
      "chazhi:0.06660000\n",
      "epoch:24   global_step:23200\n",
      "{0: 0.11, 1: 0.1129, 2: 0.0821, 3: 0.0892, 4: 0.1173, 5: 0.0686, 6: 0.1002, 7: 0.1099, 8: 0.1162, 9: 0.0936}\n",
      "chazhi:0.04870000\n",
      "epoch:24   global_step:23400\n",
      "{0: 0.106, 1: 0.1024, 2: 0.0947, 3: 0.0984, 4: 0.1026, 5: 0.0654, 6: 0.1012, 7: 0.1265, 8: 0.109, 9: 0.0938}\n",
      "chazhi:0.06110000\n",
      "epoch:25   global_step:23600\n",
      "{0: 0.118, 1: 0.1186, 2: 0.0827, 3: 0.0831, 4: 0.1118, 5: 0.0588, 6: 0.1122, 7: 0.1126, 8: 0.1076, 9: 0.0946}\n",
      "chazhi:0.05980000\n",
      "epoch:25   global_step:23800\n",
      "{0: 0.1036, 1: 0.1091, 2: 0.0903, 3: 0.1014, 4: 0.1077, 5: 0.0639, 6: 0.1021, 7: 0.112, 8: 0.1178, 9: 0.0921}\n",
      "chazhi:0.05390000\n",
      "epoch:25   global_step:24000\n",
      "{0: 0.111, 1: 0.1136, 2: 0.0884, 3: 0.1012, 4: 0.1185, 5: 0.0672, 6: 0.1082, 7: 0.1225, 8: 0.0887, 9: 0.0807}\n",
      "chazhi:0.05530000\n",
      "epoch:25   global_step:24200\n",
      "{0: 0.1055, 1: 0.0922, 2: 0.1062, 3: 0.1022, 4: 0.1111, 5: 0.0596, 6: 0.1004, 7: 0.1224, 8: 0.1105, 9: 0.0899}\n",
      "chazhi:0.06280000\n",
      "epoch:26   global_step:24400\n",
      "{0: 0.1116, 1: 0.1006, 2: 0.0853, 3: 0.1029, 4: 0.1227, 5: 0.0574, 6: 0.1096, 7: 0.13, 8: 0.0966, 9: 0.0833}\n",
      "chazhi:0.07260000\n",
      "epoch:26   global_step:24600\n",
      "{0: 0.1043, 1: 0.1098, 2: 0.0881, 3: 0.1066, 4: 0.1137, 5: 0.0691, 6: 0.1032, 7: 0.1113, 8: 0.1095, 9: 0.0844}\n",
      "chazhi:0.04460000\n",
      "epoch:26   global_step:24800\n",
      "{0: 0.1105, 1: 0.1054, 2: 0.0872, 3: 0.0964, 4: 0.1016, 5: 0.0739, 6: 0.1014, 7: 0.107, 8: 0.1239, 9: 0.0927}\n",
      "chazhi:0.05000000\n",
      "epoch:26   global_step:25000\n",
      "{0: 0.1102, 1: 0.109, 2: 0.0845, 3: 0.0795, 4: 0.1165, 5: 0.054, 6: 0.1205, 7: 0.1156, 8: 0.1183, 9: 0.0919}\n",
      "chazhi:0.06650000\n",
      "epoch:26   global_step:25200\n",
      "{0: 0.1137, 1: 0.1084, 2: 0.0981, 3: 0.0826, 4: 0.1188, 5: 0.054, 6: 0.1152, 7: 0.1218, 8: 0.1154, 9: 0.072}\n",
      "chazhi:0.06780000\n",
      "epoch:27   global_step:25400\n",
      "{0: 0.1297, 1: 0.1197, 2: 0.087, 3: 0.0815, 4: 0.1178, 5: 0.0596, 6: 0.1047, 7: 0.1104, 8: 0.1049, 9: 0.0847}\n",
      "chazhi:0.07010000\n",
      "epoch:27   global_step:25600\n",
      "{0: 0.1067, 1: 0.1151, 2: 0.0788, 3: 0.1002, 4: 0.1107, 5: 0.0733, 6: 0.1025, 7: 0.1084, 8: 0.1171, 9: 0.0872}\n",
      "chazhi:0.04380000\n",
      "epoch:27   global_step:25800\n",
      "{0: 0.1028, 1: 0.1061, 2: 0.0984, 3: 0.0937, 4: 0.1114, 5: 0.0558, 6: 0.1175, 7: 0.1196, 8: 0.0989, 9: 0.0958}\n",
      "chazhi:0.06380000\n",
      "epoch:27   global_step:26000\n",
      "{0: 0.0995, 1: 0.1208, 2: 0.0862, 3: 0.0958, 4: 0.1087, 5: 0.0731, 6: 0.1011, 7: 0.1252, 8: 0.1058, 9: 0.0838}\n",
      "chazhi:0.05210000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27   global_step:26200\n",
      "{0: 0.101, 1: 0.1125, 2: 0.0883, 3: 0.0933, 4: 0.11, 5: 0.0806, 6: 0.1071, 7: 0.1229, 8: 0.104, 9: 0.0803}\n",
      "chazhi:0.04260000\n",
      "epoch:28   global_step:26400\n",
      "{0: 0.1017, 1: 0.1109, 2: 0.0926, 3: 0.0989, 4: 0.1156, 5: 0.0668, 6: 0.0995, 7: 0.1272, 8: 0.1058, 9: 0.081}\n",
      "chazhi:0.06040000\n",
      "epoch:28   global_step:26600\n",
      "{0: 0.1156, 1: 0.1086, 2: 0.071, 3: 0.0967, 4: 0.1197, 5: 0.0646, 6: 0.1079, 7: 0.1081, 8: 0.1127, 9: 0.0951}\n",
      "chazhi:0.05510000\n",
      "epoch:28   global_step:26800\n",
      "{0: 0.1117, 1: 0.1077, 2: 0.0835, 3: 0.1002, 4: 0.1084, 5: 0.0638, 6: 0.1085, 7: 0.1276, 8: 0.1017, 9: 0.0869}\n",
      "chazhi:0.06380000\n",
      "epoch:28   global_step:27000\n",
      "{0: 0.1048, 1: 0.1158, 2: 0.0888, 3: 0.0917, 4: 0.1119, 5: 0.0669, 6: 0.1074, 7: 0.0965, 8: 0.1164, 9: 0.0998}\n",
      "chazhi:0.04950000\n",
      "epoch:29   global_step:27200\n",
      "{0: 0.1202, 1: 0.1042, 2: 0.0907, 3: 0.0869, 4: 0.1236, 5: 0.0526, 6: 0.1004, 7: 0.1252, 8: 0.1004, 9: 0.0958}\n",
      "chazhi:0.07260000\n",
      "epoch:29   global_step:27400\n",
      "{0: 0.1186, 1: 0.1118, 2: 0.0895, 3: 0.0944, 4: 0.1283, 5: 0.0619, 6: 0.0914, 7: 0.1221, 8: 0.0996, 9: 0.0824}\n",
      "chazhi:0.06640000\n",
      "epoch:29   global_step:27600\n",
      "{0: 0.1016, 1: 0.1206, 2: 0.0836, 3: 0.099, 4: 0.1091, 5: 0.073, 6: 0.0926, 7: 0.1287, 8: 0.1095, 9: 0.0823}\n",
      "chazhi:0.05570000\n",
      "epoch:29   global_step:27800\n",
      "{0: 0.1137, 1: 0.1079, 2: 0.0894, 3: 0.0816, 4: 0.1136, 5: 0.0574, 6: 0.1119, 7: 0.1207, 8: 0.1241, 9: 0.0797}\n",
      "chazhi:0.06670000\n",
      "epoch:29   global_step:28000\n",
      "{0: 0.1158, 1: 0.109, 2: 0.0923, 3: 0.0844, 4: 0.1126, 5: 0.0669, 6: 0.1032, 7: 0.1167, 8: 0.1144, 9: 0.0847}\n",
      "chazhi:0.04980000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps=[]\n",
    "        values=[]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # labels = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # Sample noise and generate a batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Train the generator (wants discriminator to mistake images as real)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "#                 print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if  global_step % save_interval == 0:\n",
    "                    label_dict,value=self.mode_drop(epoch,global_step)\n",
    "                    steps.append(global_step)\n",
    "                    values.append(value)\n",
    "#             plt.subplots(1, 1)\n",
    "        plt.plot(steps,values)\n",
    "        plt.xlim([0,40000])\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.xlabel('steps')\n",
    "        plt.ylabel('epochs')\n",
    "        plt.tick_params(axis='both',which='major',labelsize=13)\n",
    "        plt.legend(loc='lower right')\n",
    "        if not os.path.isdir('images_dcgan'):\n",
    "            os.mkdir('images_dcgan')\n",
    "        plt.savefig(\"images_dcgan/mode_drop.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def save_imgs(self, epoch,global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_dcgan'):\n",
    "            os.mkdir('images_dcgan')\n",
    "        fig.savefig(\"images_dcgan/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "        plt.close()\n",
    "    def mode_drop(self,epoch,global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        label_dict,value=calculate_labels(gen_imgs,epoch,global_step)\n",
    "        return label_dict,value\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    dcgan.train(epochs=30, batch_size=64, save_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
