{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import torch\n",
    "from keras.utils.np_utils import *\n",
    "from keras.datasets import mnist\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH ='/home/imi432_006/huangdengrong/GAN-Research/metrics_gan/metrics/classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def calculate_labels(images,epoch,global_step):\n",
    "    label_dict={}\n",
    "    for i in range(10):\n",
    "        label_dict[i]=0\n",
    "    eval_images = tf.convert_to_tensor(images)\n",
    "    y_logit = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    labels=tf.argmax(y_logit, 1)\n",
    "    labels=tf.Session().run(labels)\n",
    "    for data in labels:\n",
    "        label_dict[data]+=1\n",
    "    for i in range(10):\n",
    "        label_dict[i]=label_dict[i]/len(images)\n",
    "    max_value=max(label_dict.values())\n",
    "    min_value=min(label_dict.values())\n",
    "    print('epoch:%d   global_step:%d'%(epoch,global_step))\n",
    "    print(label_dict)\n",
    "    print('chazhi:%.8f'%(max_value-min_value))\n",
    "    return label_dict,max_value-min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 784)               402192    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 720,656\n",
      "Trainable params: 718,608\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 719,972\n",
      "Trainable params: 717,924\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "epoch:0   global_step:200\n",
      "{0: 0.0053, 1: 0.0, 2: 0.0, 3: 0.0009, 4: 0.0293, 5: 0.0, 6: 0.0, 7: 0.002, 8: 0.9625, 9: 0.0}\n",
      "chazhi:0.96250000\n",
      "epoch:0   global_step:400\n",
      "{0: 0.1014, 1: 0.0006, 2: 0.0004, 3: 0.0173, 4: 0.1766, 5: 0.0, 6: 0.0001, 7: 0.0711, 8: 0.6325, 9: 0.0}\n",
      "chazhi:0.63250000\n",
      "epoch:0   global_step:600\n",
      "{0: 0.1985, 1: 0.0163, 2: 0.0473, 3: 0.1139, 4: 0.097, 5: 0.0144, 6: 0.0147, 7: 0.1448, 8: 0.327, 9: 0.0261}\n",
      "chazhi:0.31260000\n",
      "epoch:0   global_step:800\n",
      "{0: 0.1402, 1: 0.0204, 2: 0.0879, 3: 0.1182, 4: 0.1473, 5: 0.022, 6: 0.0297, 7: 0.1777, 8: 0.2285, 9: 0.0281}\n",
      "chazhi:0.20810000\n",
      "epoch:1   global_step:1000\n",
      "{0: 0.1207, 1: 0.0154, 2: 0.0947, 3: 0.1494, 4: 0.1676, 5: 0.0133, 6: 0.031, 7: 0.2097, 8: 0.1536, 9: 0.0446}\n",
      "chazhi:0.19640000\n",
      "epoch:1   global_step:1200\n",
      "{0: 0.1103, 1: 0.0128, 2: 0.0725, 3: 0.1455, 4: 0.1719, 5: 0.0236, 6: 0.0389, 7: 0.1735, 8: 0.2056, 9: 0.0454}\n",
      "chazhi:0.19280000\n",
      "epoch:1   global_step:1400\n",
      "{0: 0.0997, 1: 0.0183, 2: 0.0908, 3: 0.1527, 4: 0.1569, 5: 0.027, 6: 0.0309, 7: 0.1798, 8: 0.1955, 9: 0.0484}\n",
      "chazhi:0.17720000\n",
      "epoch:1   global_step:1600\n",
      "{0: 0.1062, 1: 0.0166, 2: 0.0891, 3: 0.1503, 4: 0.1549, 5: 0.0249, 6: 0.0345, 7: 0.171, 8: 0.2001, 9: 0.0524}\n",
      "chazhi:0.18350000\n",
      "epoch:1   global_step:1800\n",
      "{0: 0.0801, 1: 0.0133, 2: 0.0883, 3: 0.178, 4: 0.146, 5: 0.0263, 6: 0.0396, 7: 0.1717, 8: 0.2061, 9: 0.0506}\n",
      "chazhi:0.19280000\n",
      "epoch:2   global_step:2000\n",
      "{0: 0.0984, 1: 0.0076, 2: 0.0789, 3: 0.1625, 4: 0.1566, 5: 0.0326, 6: 0.0538, 7: 0.1683, 8: 0.1909, 9: 0.0504}\n",
      "chazhi:0.18330000\n",
      "epoch:2   global_step:2200\n",
      "{0: 0.091, 1: 0.0126, 2: 0.0773, 3: 0.2098, 4: 0.1365, 5: 0.0319, 6: 0.0346, 7: 0.1604, 8: 0.1843, 9: 0.0616}\n",
      "chazhi:0.19720000\n",
      "epoch:2   global_step:2400\n",
      "{0: 0.105, 1: 0.0086, 2: 0.0853, 3: 0.1728, 4: 0.1465, 5: 0.0309, 6: 0.0448, 7: 0.1491, 8: 0.1963, 9: 0.0607}\n",
      "chazhi:0.18770000\n",
      "epoch:2   global_step:2600\n",
      "{0: 0.0892, 1: 0.0108, 2: 0.0992, 3: 0.1761, 4: 0.1432, 5: 0.0304, 6: 0.0447, 7: 0.179, 8: 0.1651, 9: 0.0623}\n",
      "chazhi:0.16820000\n",
      "epoch:2   global_step:2800\n",
      "{0: 0.0954, 1: 0.0143, 2: 0.0925, 3: 0.1648, 4: 0.1454, 5: 0.0276, 6: 0.0466, 7: 0.168, 8: 0.1923, 9: 0.0531}\n",
      "chazhi:0.17800000\n",
      "epoch:3   global_step:3000\n",
      "{0: 0.0906, 1: 0.0211, 2: 0.0766, 3: 0.1801, 4: 0.1556, 5: 0.029, 6: 0.0436, 7: 0.1437, 8: 0.2028, 9: 0.0569}\n",
      "chazhi:0.18170000\n",
      "epoch:3   global_step:3200\n",
      "{0: 0.0915, 1: 0.0201, 2: 0.0769, 3: 0.1767, 4: 0.1308, 5: 0.0307, 6: 0.0397, 7: 0.1588, 8: 0.219, 9: 0.0558}\n",
      "chazhi:0.19890000\n",
      "epoch:3   global_step:3400\n",
      "{0: 0.1141, 1: 0.0144, 2: 0.0792, 3: 0.1554, 4: 0.1193, 5: 0.0341, 6: 0.0423, 7: 0.1596, 8: 0.2221, 9: 0.0595}\n",
      "chazhi:0.20770000\n",
      "epoch:3   global_step:3600\n",
      "{0: 0.1038, 1: 0.0207, 2: 0.0946, 3: 0.1581, 4: 0.1283, 5: 0.029, 6: 0.0493, 7: 0.1597, 8: 0.1974, 9: 0.0591}\n",
      "chazhi:0.17670000\n",
      "epoch:4   global_step:3800\n",
      "{0: 0.0931, 1: 0.0216, 2: 0.0894, 3: 0.1707, 4: 0.1314, 5: 0.0297, 6: 0.0468, 7: 0.1627, 8: 0.1973, 9: 0.0573}\n",
      "chazhi:0.17570000\n",
      "epoch:4   global_step:4000\n",
      "{0: 0.1109, 1: 0.0369, 2: 0.0833, 3: 0.1605, 4: 0.138, 5: 0.0316, 6: 0.0571, 7: 0.1388, 8: 0.1848, 9: 0.0581}\n",
      "chazhi:0.15320000\n",
      "epoch:4   global_step:4200\n",
      "{0: 0.1158, 1: 0.0529, 2: 0.0714, 3: 0.145, 4: 0.1286, 5: 0.0274, 6: 0.0463, 7: 0.1658, 8: 0.2001, 9: 0.0467}\n",
      "chazhi:0.17270000\n",
      "epoch:4   global_step:4400\n",
      "{0: 0.1188, 1: 0.0366, 2: 0.0655, 3: 0.1634, 4: 0.1309, 5: 0.0407, 6: 0.0467, 7: 0.1547, 8: 0.1862, 9: 0.0565}\n",
      "chazhi:0.14960000\n",
      "epoch:4   global_step:4600\n",
      "{0: 0.1183, 1: 0.0369, 2: 0.0788, 3: 0.1494, 4: 0.1163, 5: 0.0461, 6: 0.0547, 7: 0.1645, 8: 0.1817, 9: 0.0533}\n",
      "chazhi:0.14480000\n",
      "epoch:5   global_step:4800\n",
      "{0: 0.0965, 1: 0.0436, 2: 0.067, 3: 0.1713, 4: 0.1256, 5: 0.0278, 6: 0.0541, 7: 0.1737, 8: 0.1814, 9: 0.059}\n",
      "chazhi:0.15360000\n",
      "epoch:5   global_step:5000\n",
      "{0: 0.0952, 1: 0.0453, 2: 0.0786, 3: 0.1747, 4: 0.1169, 5: 0.0386, 6: 0.0478, 7: 0.1912, 8: 0.1531, 9: 0.0586}\n",
      "chazhi:0.15260000\n",
      "epoch:5   global_step:5200\n",
      "{0: 0.1068, 1: 0.0436, 2: 0.072, 3: 0.1274, 4: 0.1081, 5: 0.0404, 6: 0.0502, 7: 0.1742, 8: 0.1919, 9: 0.0854}\n",
      "chazhi:0.15150000\n",
      "epoch:5   global_step:5400\n",
      "{0: 0.1173, 1: 0.0494, 2: 0.0634, 3: 0.1287, 4: 0.1297, 5: 0.0365, 6: 0.0588, 7: 0.1793, 8: 0.1699, 9: 0.067}\n",
      "chazhi:0.14280000\n",
      "epoch:5   global_step:5600\n",
      "{0: 0.0914, 1: 0.0642, 2: 0.0714, 3: 0.1314, 4: 0.133, 5: 0.0363, 6: 0.0594, 7: 0.155, 8: 0.1815, 9: 0.0764}\n",
      "chazhi:0.14520000\n",
      "epoch:6   global_step:5800\n",
      "{0: 0.13, 1: 0.0683, 2: 0.0637, 3: 0.12, 4: 0.1344, 5: 0.0267, 6: 0.0523, 7: 0.1696, 8: 0.1603, 9: 0.0747}\n",
      "chazhi:0.14290000\n",
      "epoch:6   global_step:6000\n",
      "{0: 0.1037, 1: 0.0567, 2: 0.0805, 3: 0.1384, 4: 0.1487, 5: 0.0302, 6: 0.0442, 7: 0.1778, 8: 0.1589, 9: 0.0609}\n",
      "chazhi:0.14760000\n",
      "epoch:6   global_step:6200\n",
      "{0: 0.1069, 1: 0.049, 2: 0.0674, 3: 0.1409, 4: 0.1176, 5: 0.0322, 6: 0.0507, 7: 0.2035, 8: 0.1617, 9: 0.0701}\n",
      "chazhi:0.17130000\n",
      "epoch:6   global_step:6400\n",
      "{0: 0.1294, 1: 0.071, 2: 0.08, 3: 0.1133, 4: 0.1471, 5: 0.0303, 6: 0.0651, 7: 0.1613, 8: 0.1517, 9: 0.0508}\n",
      "chazhi:0.13100000\n",
      "epoch:7   global_step:6600\n",
      "{0: 0.0945, 1: 0.0501, 2: 0.091, 3: 0.1331, 4: 0.1341, 5: 0.0309, 6: 0.0537, 7: 0.2005, 8: 0.1487, 9: 0.0634}\n",
      "chazhi:0.16960000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7   global_step:6800\n",
      "{0: 0.1057, 1: 0.0674, 2: 0.058, 3: 0.1334, 4: 0.1506, 5: 0.0356, 6: 0.0495, 7: 0.1797, 8: 0.1523, 9: 0.0678}\n",
      "chazhi:0.14410000\n",
      "epoch:7   global_step:7000\n",
      "{0: 0.1046, 1: 0.067, 2: 0.0793, 3: 0.1295, 4: 0.1189, 5: 0.0435, 6: 0.0516, 7: 0.163, 8: 0.1791, 9: 0.0635}\n",
      "chazhi:0.13560000\n",
      "epoch:7   global_step:7200\n",
      "{0: 0.1092, 1: 0.0718, 2: 0.0629, 3: 0.1262, 4: 0.1402, 5: 0.0462, 6: 0.0619, 7: 0.146, 8: 0.1584, 9: 0.0772}\n",
      "chazhi:0.11220000\n",
      "epoch:7   global_step:7400\n",
      "{0: 0.0935, 1: 0.0665, 2: 0.0694, 3: 0.1348, 4: 0.1165, 5: 0.0438, 6: 0.0639, 7: 0.1763, 8: 0.1659, 9: 0.0694}\n",
      "chazhi:0.13250000\n",
      "epoch:8   global_step:7600\n",
      "{0: 0.099, 1: 0.0825, 2: 0.0758, 3: 0.1385, 4: 0.1378, 5: 0.0305, 6: 0.0636, 7: 0.1527, 8: 0.1452, 9: 0.0744}\n",
      "chazhi:0.12220000\n",
      "epoch:8   global_step:7800\n",
      "{0: 0.0962, 1: 0.0663, 2: 0.0771, 3: 0.1266, 4: 0.1278, 5: 0.0508, 6: 0.0734, 7: 0.1485, 8: 0.1692, 9: 0.0641}\n",
      "chazhi:0.11840000\n",
      "epoch:8   global_step:8000\n",
      "{0: 0.1005, 1: 0.0813, 2: 0.084, 3: 0.1142, 4: 0.1233, 5: 0.0391, 6: 0.0605, 7: 0.15, 8: 0.1756, 9: 0.0715}\n",
      "chazhi:0.13650000\n",
      "epoch:8   global_step:8200\n",
      "{0: 0.1055, 1: 0.0802, 2: 0.0844, 3: 0.1145, 4: 0.142, 5: 0.0384, 6: 0.0663, 7: 0.1406, 8: 0.1621, 9: 0.066}\n",
      "chazhi:0.12370000\n",
      "epoch:8   global_step:8400\n",
      "{0: 0.1057, 1: 0.0665, 2: 0.0869, 3: 0.1222, 4: 0.118, 5: 0.0419, 6: 0.077, 7: 0.1634, 8: 0.1464, 9: 0.072}\n",
      "chazhi:0.12150000\n",
      "epoch:9   global_step:8600\n",
      "{0: 0.117, 1: 0.0866, 2: 0.0742, 3: 0.1037, 4: 0.1316, 5: 0.0368, 6: 0.0647, 7: 0.1757, 8: 0.1468, 9: 0.0629}\n",
      "chazhi:0.13890000\n",
      "epoch:9   global_step:8800\n",
      "{0: 0.1003, 1: 0.0751, 2: 0.0713, 3: 0.1439, 4: 0.1312, 5: 0.0272, 6: 0.0656, 7: 0.1704, 8: 0.16, 9: 0.055}\n",
      "chazhi:0.14320000\n",
      "epoch:9   global_step:9000\n",
      "{0: 0.107, 1: 0.0861, 2: 0.0726, 3: 0.1246, 4: 0.1385, 5: 0.027, 6: 0.0757, 7: 0.1633, 8: 0.1421, 9: 0.0631}\n",
      "chazhi:0.13630000\n",
      "epoch:9   global_step:9200\n",
      "{0: 0.1051, 1: 0.0868, 2: 0.0761, 3: 0.118, 4: 0.1281, 5: 0.0321, 6: 0.0667, 7: 0.1505, 8: 0.1576, 9: 0.079}\n",
      "chazhi:0.12550000\n",
      "epoch:10   global_step:9400\n",
      "{0: 0.111, 1: 0.0701, 2: 0.0686, 3: 0.137, 4: 0.1239, 5: 0.0339, 6: 0.066, 7: 0.1509, 8: 0.1626, 9: 0.076}\n",
      "chazhi:0.12870000\n",
      "epoch:10   global_step:9600\n",
      "{0: 0.1018, 1: 0.0797, 2: 0.0826, 3: 0.1188, 4: 0.129, 5: 0.0389, 6: 0.0784, 7: 0.1441, 8: 0.1546, 9: 0.0721}\n",
      "chazhi:0.11570000\n",
      "epoch:10   global_step:9800\n",
      "{0: 0.1371, 1: 0.067, 2: 0.0756, 3: 0.1098, 4: 0.1215, 5: 0.0458, 6: 0.0681, 7: 0.1507, 8: 0.1586, 9: 0.0658}\n",
      "chazhi:0.11280000\n",
      "epoch:10   global_step:10000\n",
      "{0: 0.0913, 1: 0.0844, 2: 0.0805, 3: 0.1219, 4: 0.126, 5: 0.0416, 6: 0.081, 7: 0.1464, 8: 0.1659, 9: 0.061}\n",
      "chazhi:0.12430000\n",
      "epoch:10   global_step:10200\n",
      "{0: 0.1, 1: 0.0937, 2: 0.0807, 3: 0.1055, 4: 0.1245, 5: 0.0303, 6: 0.0711, 7: 0.168, 8: 0.153, 9: 0.0732}\n",
      "chazhi:0.13770000\n",
      "epoch:11   global_step:10400\n",
      "{0: 0.1199, 1: 0.0668, 2: 0.0665, 3: 0.1163, 4: 0.1358, 5: 0.0437, 6: 0.0838, 7: 0.14, 8: 0.1495, 9: 0.0777}\n",
      "chazhi:0.10580000\n",
      "epoch:11   global_step:10600\n",
      "{0: 0.1024, 1: 0.0757, 2: 0.0658, 3: 0.1265, 4: 0.1224, 5: 0.0529, 6: 0.071, 7: 0.1552, 8: 0.1565, 9: 0.0716}\n",
      "chazhi:0.10360000\n",
      "epoch:11   global_step:10800\n",
      "{0: 0.1181, 1: 0.0891, 2: 0.0836, 3: 0.1148, 4: 0.1322, 5: 0.047, 6: 0.0717, 7: 0.1405, 8: 0.1359, 9: 0.0671}\n",
      "chazhi:0.09350000\n",
      "epoch:11   global_step:11000\n",
      "{0: 0.1203, 1: 0.0776, 2: 0.0769, 3: 0.1003, 4: 0.1169, 5: 0.0531, 6: 0.0855, 7: 0.1443, 8: 0.1566, 9: 0.0685}\n",
      "chazhi:0.10350000\n",
      "epoch:11   global_step:11200\n",
      "{0: 0.1118, 1: 0.0877, 2: 0.0705, 3: 0.128, 4: 0.1325, 5: 0.0432, 6: 0.0797, 7: 0.1251, 8: 0.1553, 9: 0.0662}\n",
      "chazhi:0.11210000\n",
      "epoch:12   global_step:11400\n",
      "{0: 0.1027, 1: 0.0851, 2: 0.073, 3: 0.1097, 4: 0.1184, 5: 0.0462, 6: 0.0719, 7: 0.1756, 8: 0.1478, 9: 0.0696}\n",
      "chazhi:0.12940000\n",
      "epoch:12   global_step:11600\n",
      "{0: 0.0995, 1: 0.1112, 2: 0.0748, 3: 0.1129, 4: 0.1264, 5: 0.0372, 6: 0.0734, 7: 0.1425, 8: 0.1558, 9: 0.0663}\n",
      "chazhi:0.11860000\n",
      "epoch:12   global_step:11800\n",
      "{0: 0.0926, 1: 0.0881, 2: 0.0743, 3: 0.1257, 4: 0.1353, 5: 0.0397, 6: 0.0712, 7: 0.1404, 8: 0.1626, 9: 0.0701}\n",
      "chazhi:0.12290000\n",
      "epoch:12   global_step:12000\n",
      "{0: 0.1034, 1: 0.091, 2: 0.0736, 3: 0.1278, 4: 0.1295, 5: 0.039, 6: 0.07, 7: 0.1287, 8: 0.1634, 9: 0.0736}\n",
      "chazhi:0.12440000\n",
      "epoch:13   global_step:12200\n",
      "{0: 0.0959, 1: 0.0861, 2: 0.0817, 3: 0.1014, 4: 0.128, 5: 0.0396, 6: 0.0821, 7: 0.1513, 8: 0.1588, 9: 0.0751}\n",
      "chazhi:0.11920000\n",
      "epoch:13   global_step:12400\n",
      "{0: 0.1112, 1: 0.0956, 2: 0.0822, 3: 0.0968, 4: 0.1248, 5: 0.035, 6: 0.0646, 7: 0.1738, 8: 0.1428, 9: 0.0732}\n",
      "chazhi:0.13880000\n",
      "epoch:13   global_step:12600\n",
      "{0: 0.1084, 1: 0.0915, 2: 0.0888, 3: 0.1212, 4: 0.1105, 5: 0.0447, 6: 0.0657, 7: 0.1599, 8: 0.1311, 9: 0.0782}\n",
      "chazhi:0.11520000\n",
      "epoch:13   global_step:12800\n",
      "{0: 0.1326, 1: 0.0855, 2: 0.0698, 3: 0.1208, 4: 0.1147, 5: 0.0388, 6: 0.0663, 7: 0.1326, 8: 0.1671, 9: 0.0718}\n",
      "chazhi:0.12830000\n",
      "epoch:13   global_step:13000\n",
      "{0: 0.1373, 1: 0.0894, 2: 0.0758, 3: 0.1181, 4: 0.1072, 5: 0.0417, 6: 0.0765, 7: 0.1524, 8: 0.1367, 9: 0.0649}\n",
      "chazhi:0.11070000\n",
      "epoch:14   global_step:13200\n",
      "{0: 0.0947, 1: 0.0914, 2: 0.0732, 3: 0.1064, 4: 0.1299, 5: 0.0358, 6: 0.0763, 7: 0.1563, 8: 0.1505, 9: 0.0855}\n",
      "chazhi:0.12050000\n",
      "epoch:14   global_step:13400\n",
      "{0: 0.1059, 1: 0.0982, 2: 0.0727, 3: 0.1151, 4: 0.1261, 5: 0.0413, 6: 0.0851, 7: 0.1583, 8: 0.1272, 9: 0.0701}\n",
      "chazhi:0.11700000\n",
      "epoch:14   global_step:13600\n",
      "{0: 0.1122, 1: 0.096, 2: 0.0879, 3: 0.1072, 4: 0.1218, 5: 0.0427, 6: 0.0733, 7: 0.1472, 8: 0.14, 9: 0.0717}\n",
      "chazhi:0.10450000\n",
      "epoch:14   global_step:13800\n",
      "{0: 0.1134, 1: 0.0982, 2: 0.0792, 3: 0.1177, 4: 0.1134, 5: 0.0458, 6: 0.0932, 7: 0.1366, 8: 0.1282, 9: 0.0743}\n",
      "chazhi:0.09080000\n",
      "epoch:14   global_step:14000\n",
      "{0: 0.106, 1: 0.082, 2: 0.0754, 3: 0.1209, 4: 0.146, 5: 0.0362, 6: 0.0752, 7: 0.161, 8: 0.1273, 9: 0.07}\n",
      "chazhi:0.12480000\n",
      "epoch:15   global_step:14200\n",
      "{0: 0.1063, 1: 0.0913, 2: 0.0753, 3: 0.1174, 4: 0.1054, 5: 0.0452, 6: 0.0722, 7: 0.1535, 8: 0.1557, 9: 0.0777}\n",
      "chazhi:0.11050000\n",
      "epoch:15   global_step:14400\n",
      "{0: 0.1084, 1: 0.0985, 2: 0.0769, 3: 0.1195, 4: 0.1203, 5: 0.049, 6: 0.0699, 7: 0.1529, 8: 0.1354, 9: 0.0692}\n",
      "chazhi:0.10390000\n",
      "epoch:15   global_step:14600\n",
      "{0: 0.0979, 1: 0.0876, 2: 0.088, 3: 0.1202, 4: 0.1166, 5: 0.0435, 6: 0.0759, 7: 0.1453, 8: 0.1536, 9: 0.0714}\n",
      "chazhi:0.11010000\n",
      "epoch:15   global_step:14800\n",
      "{0: 0.1129, 1: 0.0994, 2: 0.0753, 3: 0.1069, 4: 0.1263, 5: 0.0421, 6: 0.0681, 7: 0.1442, 8: 0.1481, 9: 0.0767}\n",
      "chazhi:0.10600000\n",
      "epoch:16   global_step:15000\n",
      "{0: 0.1088, 1: 0.0915, 2: 0.0762, 3: 0.1261, 4: 0.1386, 5: 0.0362, 6: 0.0711, 7: 0.1549, 8: 0.1336, 9: 0.063}\n",
      "chazhi:0.11870000\n",
      "epoch:16   global_step:15200\n",
      "{0: 0.1054, 1: 0.1026, 2: 0.0713, 3: 0.1074, 4: 0.1189, 5: 0.0451, 6: 0.0779, 7: 0.1554, 8: 0.1371, 9: 0.0789}\n",
      "chazhi:0.11030000\n",
      "epoch:16   global_step:15400\n",
      "{0: 0.0947, 1: 0.0895, 2: 0.0736, 3: 0.1286, 4: 0.1061, 5: 0.0401, 6: 0.076, 7: 0.1719, 8: 0.1426, 9: 0.0769}\n",
      "chazhi:0.13180000\n",
      "epoch:16   global_step:15600\n",
      "{0: 0.1011, 1: 0.0878, 2: 0.0788, 3: 0.1162, 4: 0.1349, 5: 0.0504, 6: 0.082, 7: 0.1329, 8: 0.1396, 9: 0.0763}\n",
      "chazhi:0.08920000\n",
      "epoch:16   global_step:15800\n",
      "{0: 0.1045, 1: 0.095, 2: 0.0975, 3: 0.1165, 4: 0.1313, 5: 0.0493, 6: 0.0671, 7: 0.1322, 8: 0.1304, 9: 0.0762}\n",
      "chazhi:0.08290000\n",
      "epoch:17   global_step:16000\n",
      "{0: 0.1163, 1: 0.0825, 2: 0.0853, 3: 0.1146, 4: 0.1199, 5: 0.0392, 6: 0.0781, 7: 0.1405, 8: 0.1445, 9: 0.0791}\n",
      "chazhi:0.10530000\n",
      "epoch:17   global_step:16200\n",
      "{0: 0.1085, 1: 0.1052, 2: 0.0751, 3: 0.108, 4: 0.1345, 5: 0.044, 6: 0.0939, 7: 0.1156, 8: 0.134, 9: 0.0812}\n",
      "chazhi:0.09050000\n",
      "epoch:17   global_step:16400\n",
      "{0: 0.1242, 1: 0.0829, 2: 0.0662, 3: 0.0965, 4: 0.1281, 5: 0.0421, 6: 0.0882, 7: 0.1462, 8: 0.1329, 9: 0.0927}\n",
      "chazhi:0.10410000\n",
      "epoch:17   global_step:16600\n",
      "{0: 0.1094, 1: 0.0829, 2: 0.0911, 3: 0.1112, 4: 0.125, 5: 0.0346, 6: 0.0756, 7: 0.1439, 8: 0.1534, 9: 0.0729}\n",
      "chazhi:0.11880000\n",
      "epoch:17   global_step:16800\n",
      "{0: 0.0905, 1: 0.0928, 2: 0.082, 3: 0.1067, 4: 0.1095, 5: 0.0602, 6: 0.0884, 7: 0.1473, 8: 0.1437, 9: 0.0789}\n",
      "chazhi:0.08710000\n",
      "epoch:18   global_step:17000\n",
      "{0: 0.1417, 1: 0.0932, 2: 0.0739, 3: 0.1222, 4: 0.1248, 5: 0.0426, 6: 0.0755, 7: 0.139, 8: 0.1223, 9: 0.0648}\n",
      "chazhi:0.09910000\n",
      "epoch:18   global_step:17200\n",
      "{0: 0.1149, 1: 0.1045, 2: 0.0599, 3: 0.1006, 4: 0.1226, 5: 0.0463, 6: 0.0802, 7: 0.1506, 8: 0.1423, 9: 0.0781}\n",
      "chazhi:0.10430000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18   global_step:17400\n",
      "{0: 0.1199, 1: 0.0962, 2: 0.0695, 3: 0.1179, 4: 0.1362, 5: 0.0418, 6: 0.0689, 7: 0.1243, 8: 0.137, 9: 0.0883}\n",
      "chazhi:0.09520000\n",
      "epoch:18   global_step:17600\n",
      "{0: 0.1069, 1: 0.1009, 2: 0.0802, 3: 0.1176, 4: 0.1216, 5: 0.0447, 6: 0.0763, 7: 0.1262, 8: 0.1422, 9: 0.0834}\n",
      "chazhi:0.09750000\n",
      "epoch:18   global_step:17800\n",
      "{0: 0.1179, 1: 0.0805, 2: 0.0802, 3: 0.1134, 4: 0.1326, 5: 0.0401, 6: 0.0768, 7: 0.1474, 8: 0.1336, 9: 0.0775}\n",
      "chazhi:0.10730000\n",
      "epoch:19   global_step:18000\n",
      "{0: 0.0888, 1: 0.1095, 2: 0.0682, 3: 0.1169, 4: 0.1271, 5: 0.0457, 6: 0.0755, 7: 0.1571, 8: 0.1232, 9: 0.088}\n",
      "chazhi:0.11140000\n",
      "epoch:19   global_step:18200\n",
      "{0: 0.1334, 1: 0.0926, 2: 0.0758, 3: 0.0977, 4: 0.105, 5: 0.0496, 6: 0.0936, 7: 0.1413, 8: 0.1426, 9: 0.0684}\n",
      "chazhi:0.09300000\n",
      "epoch:19   global_step:18400\n",
      "{0: 0.1076, 1: 0.0924, 2: 0.0882, 3: 0.1258, 4: 0.1228, 5: 0.0389, 6: 0.0939, 7: 0.1207, 8: 0.1404, 9: 0.0693}\n",
      "chazhi:0.10150000\n",
      "epoch:19   global_step:18600\n",
      "{0: 0.121, 1: 0.0968, 2: 0.0779, 3: 0.1014, 4: 0.1181, 5: 0.0377, 6: 0.0888, 7: 0.1553, 8: 0.1408, 9: 0.0622}\n",
      "chazhi:0.11760000\n",
      "epoch:20   global_step:18800\n",
      "{0: 0.1231, 1: 0.0987, 2: 0.0724, 3: 0.1155, 4: 0.1283, 5: 0.043, 6: 0.0815, 7: 0.1368, 8: 0.1283, 9: 0.0724}\n",
      "chazhi:0.09380000\n",
      "epoch:20   global_step:19000\n",
      "{0: 0.0975, 1: 0.0978, 2: 0.074, 3: 0.131, 4: 0.1083, 5: 0.0432, 6: 0.0852, 7: 0.1583, 8: 0.1299, 9: 0.0748}\n",
      "chazhi:0.11510000\n",
      "epoch:20   global_step:19200\n",
      "{0: 0.1187, 1: 0.092, 2: 0.0805, 3: 0.1156, 4: 0.1199, 5: 0.0423, 6: 0.0817, 7: 0.1381, 8: 0.1384, 9: 0.0728}\n",
      "chazhi:0.09610000\n",
      "epoch:20   global_step:19400\n",
      "{0: 0.0936, 1: 0.105, 2: 0.0806, 3: 0.1219, 4: 0.1223, 5: 0.0413, 6: 0.0754, 7: 0.1404, 8: 0.1449, 9: 0.0746}\n",
      "chazhi:0.10360000\n",
      "epoch:20   global_step:19600\n",
      "{0: 0.0938, 1: 0.1022, 2: 0.0757, 3: 0.1091, 4: 0.1011, 5: 0.0543, 6: 0.0922, 7: 0.1466, 8: 0.1367, 9: 0.0883}\n",
      "chazhi:0.09230000\n",
      "epoch:21   global_step:19800\n",
      "{0: 0.0928, 1: 0.0867, 2: 0.084, 3: 0.1199, 4: 0.1076, 5: 0.0561, 6: 0.0789, 7: 0.1551, 8: 0.1426, 9: 0.0763}\n",
      "chazhi:0.09900000\n",
      "epoch:21   global_step:20000\n",
      "{0: 0.108, 1: 0.108, 2: 0.0661, 3: 0.1185, 4: 0.1302, 5: 0.0451, 6: 0.0762, 7: 0.1215, 8: 0.141, 9: 0.0854}\n",
      "chazhi:0.09590000\n",
      "epoch:21   global_step:20200\n",
      "{0: 0.1125, 1: 0.0979, 2: 0.0775, 3: 0.1112, 4: 0.1208, 5: 0.0359, 6: 0.0933, 7: 0.1447, 8: 0.1356, 9: 0.0706}\n",
      "chazhi:0.10880000\n",
      "epoch:21   global_step:20400\n",
      "{0: 0.116, 1: 0.0998, 2: 0.0828, 3: 0.0888, 4: 0.1222, 5: 0.0405, 6: 0.0762, 7: 0.1356, 8: 0.1472, 9: 0.0909}\n",
      "chazhi:0.10670000\n",
      "epoch:21   global_step:20600\n",
      "{0: 0.1004, 1: 0.0944, 2: 0.0781, 3: 0.1102, 4: 0.1316, 5: 0.0447, 6: 0.0881, 7: 0.1485, 8: 0.1354, 9: 0.0686}\n",
      "chazhi:0.10380000\n",
      "epoch:22   global_step:20800\n",
      "{0: 0.1096, 1: 0.1097, 2: 0.0704, 3: 0.1059, 4: 0.1307, 5: 0.0423, 6: 0.0703, 7: 0.1468, 8: 0.1313, 9: 0.083}\n",
      "chazhi:0.10450000\n",
      "epoch:22   global_step:21000\n",
      "{0: 0.1159, 1: 0.1134, 2: 0.073, 3: 0.0964, 4: 0.114, 5: 0.0455, 6: 0.0872, 7: 0.1468, 8: 0.13, 9: 0.0778}\n",
      "chazhi:0.10130000\n",
      "epoch:22   global_step:21200\n",
      "{0: 0.0983, 1: 0.1071, 2: 0.0836, 3: 0.1153, 4: 0.1231, 5: 0.0459, 6: 0.0853, 7: 0.1243, 8: 0.1389, 9: 0.0782}\n",
      "chazhi:0.09300000\n",
      "epoch:22   global_step:21400\n",
      "{0: 0.1105, 1: 0.1002, 2: 0.0756, 3: 0.1031, 4: 0.1278, 5: 0.0503, 6: 0.0894, 7: 0.1396, 8: 0.1387, 9: 0.0648}\n",
      "chazhi:0.08930000\n",
      "epoch:23   global_step:21600\n",
      "{0: 0.1177, 1: 0.1057, 2: 0.074, 3: 0.1023, 4: 0.1302, 5: 0.0378, 6: 0.0836, 7: 0.1338, 8: 0.1345, 9: 0.0804}\n",
      "chazhi:0.09670000\n",
      "epoch:23   global_step:21800\n",
      "{0: 0.115, 1: 0.0958, 2: 0.0741, 3: 0.1148, 4: 0.1358, 5: 0.0477, 6: 0.0898, 7: 0.1174, 8: 0.1359, 9: 0.0737}\n",
      "chazhi:0.08820000\n",
      "epoch:23   global_step:22000\n",
      "{0: 0.1038, 1: 0.1149, 2: 0.0711, 3: 0.1128, 4: 0.1117, 5: 0.0582, 6: 0.0871, 7: 0.1319, 8: 0.1307, 9: 0.0778}\n",
      "chazhi:0.07370000\n",
      "epoch:23   global_step:22200\n",
      "{0: 0.1221, 1: 0.111, 2: 0.0657, 3: 0.1004, 4: 0.1247, 5: 0.0439, 6: 0.086, 7: 0.137, 8: 0.1327, 9: 0.0765}\n",
      "chazhi:0.09310000\n",
      "epoch:23   global_step:22400\n",
      "{0: 0.1218, 1: 0.0999, 2: 0.0759, 3: 0.0988, 4: 0.1179, 5: 0.0494, 6: 0.1011, 7: 0.1327, 8: 0.127, 9: 0.0755}\n",
      "chazhi:0.08330000\n",
      "epoch:24   global_step:22600\n",
      "{0: 0.1217, 1: 0.0964, 2: 0.0933, 3: 0.1275, 4: 0.1145, 5: 0.0427, 6: 0.0755, 7: 0.1308, 8: 0.1318, 9: 0.0658}\n",
      "chazhi:0.08910000\n",
      "epoch:24   global_step:22800\n",
      "{0: 0.0987, 1: 0.1239, 2: 0.0842, 3: 0.1208, 4: 0.105, 5: 0.0523, 6: 0.0842, 7: 0.122, 8: 0.1329, 9: 0.076}\n",
      "chazhi:0.08060000\n",
      "epoch:24   global_step:23000\n",
      "{0: 0.116, 1: 0.1017, 2: 0.0816, 3: 0.0884, 4: 0.1194, 5: 0.0466, 6: 0.0817, 7: 0.1399, 8: 0.1373, 9: 0.0874}\n",
      "chazhi:0.09330000\n",
      "epoch:24   global_step:23200\n",
      "{0: 0.112, 1: 0.0969, 2: 0.08, 3: 0.1048, 4: 0.1023, 5: 0.0467, 6: 0.0859, 7: 0.1482, 8: 0.135, 9: 0.0882}\n",
      "chazhi:0.10150000\n",
      "epoch:24   global_step:23400\n",
      "{0: 0.1051, 1: 0.1023, 2: 0.0845, 3: 0.1223, 4: 0.0941, 5: 0.0389, 6: 0.0888, 7: 0.1408, 8: 0.144, 9: 0.0792}\n",
      "chazhi:0.10510000\n",
      "epoch:25   global_step:23600\n",
      "{0: 0.1172, 1: 0.1002, 2: 0.0797, 3: 0.1113, 4: 0.131, 5: 0.0384, 6: 0.0886, 7: 0.1348, 8: 0.1137, 9: 0.0851}\n",
      "chazhi:0.09640000\n",
      "epoch:25   global_step:23800\n",
      "{0: 0.1082, 1: 0.099, 2: 0.0803, 3: 0.0966, 4: 0.1224, 5: 0.0483, 6: 0.0968, 7: 0.1353, 8: 0.1362, 9: 0.0769}\n",
      "chazhi:0.08790000\n",
      "epoch:25   global_step:24000\n",
      "{0: 0.1172, 1: 0.0913, 2: 0.0791, 3: 0.1095, 4: 0.1153, 5: 0.0373, 6: 0.0875, 7: 0.1309, 8: 0.1298, 9: 0.1021}\n",
      "chazhi:0.09360000\n",
      "epoch:25   global_step:24200\n",
      "{0: 0.1056, 1: 0.0977, 2: 0.0728, 3: 0.1061, 4: 0.1334, 5: 0.0467, 6: 0.0864, 7: 0.1292, 8: 0.1482, 9: 0.0739}\n",
      "chazhi:0.10150000\n",
      "epoch:26   global_step:24400\n",
      "{0: 0.1122, 1: 0.087, 2: 0.0769, 3: 0.1021, 4: 0.135, 5: 0.0359, 6: 0.093, 7: 0.1354, 8: 0.1406, 9: 0.0819}\n",
      "chazhi:0.10470000\n",
      "epoch:26   global_step:24600\n",
      "{0: 0.1033, 1: 0.1073, 2: 0.0752, 3: 0.1108, 4: 0.1231, 5: 0.038, 6: 0.0886, 7: 0.1402, 8: 0.13, 9: 0.0835}\n",
      "chazhi:0.10220000\n",
      "epoch:26   global_step:24800\n",
      "{0: 0.103, 1: 0.1008, 2: 0.0829, 3: 0.1095, 4: 0.1003, 5: 0.0515, 6: 0.0818, 7: 0.152, 8: 0.1413, 9: 0.0769}\n",
      "chazhi:0.10050000\n",
      "epoch:26   global_step:25000\n",
      "{0: 0.1156, 1: 0.0972, 2: 0.0771, 3: 0.1116, 4: 0.1283, 5: 0.0492, 6: 0.0848, 7: 0.1323, 8: 0.1298, 9: 0.0741}\n",
      "chazhi:0.08310000\n",
      "epoch:26   global_step:25200\n",
      "{0: 0.1277, 1: 0.082, 2: 0.0792, 3: 0.1126, 4: 0.099, 5: 0.0554, 6: 0.0977, 7: 0.136, 8: 0.1394, 9: 0.071}\n",
      "chazhi:0.08400000\n",
      "epoch:27   global_step:25400\n",
      "{0: 0.1115, 1: 0.0992, 2: 0.0813, 3: 0.1084, 4: 0.1353, 5: 0.0413, 6: 0.0885, 7: 0.1412, 8: 0.1191, 9: 0.0742}\n",
      "chazhi:0.09990000\n",
      "epoch:27   global_step:25600\n",
      "{0: 0.1191, 1: 0.1041, 2: 0.0804, 3: 0.1247, 4: 0.1008, 5: 0.0639, 6: 0.0721, 7: 0.1344, 8: 0.1271, 9: 0.0734}\n",
      "chazhi:0.07050000\n",
      "epoch:27   global_step:25800\n",
      "{0: 0.1066, 1: 0.0948, 2: 0.0767, 3: 0.1114, 4: 0.1329, 5: 0.0541, 6: 0.0894, 7: 0.1265, 8: 0.1261, 9: 0.0815}\n",
      "chazhi:0.07880000\n",
      "epoch:27   global_step:26000\n",
      "{0: 0.1156, 1: 0.0853, 2: 0.0808, 3: 0.0981, 4: 0.1307, 5: 0.0548, 6: 0.0931, 7: 0.1239, 8: 0.141, 9: 0.0767}\n",
      "chazhi:0.08620000\n",
      "epoch:27   global_step:26200\n",
      "{0: 0.1095, 1: 0.0981, 2: 0.0877, 3: 0.1032, 4: 0.1183, 5: 0.0538, 6: 0.0824, 7: 0.127, 8: 0.1445, 9: 0.0755}\n",
      "chazhi:0.09070000\n",
      "epoch:28   global_step:26400\n",
      "{0: 0.1184, 1: 0.0788, 2: 0.0721, 3: 0.1174, 4: 0.1381, 5: 0.0426, 6: 0.0873, 7: 0.127, 8: 0.1466, 9: 0.0717}\n",
      "chazhi:0.10400000\n",
      "epoch:28   global_step:26600\n",
      "{0: 0.1188, 1: 0.1, 2: 0.0758, 3: 0.1226, 4: 0.1142, 5: 0.0515, 6: 0.0894, 7: 0.1351, 8: 0.1255, 9: 0.0671}\n",
      "chazhi:0.08360000\n",
      "epoch:28   global_step:26800\n",
      "{0: 0.1036, 1: 0.1102, 2: 0.0718, 3: 0.1092, 4: 0.1046, 5: 0.0512, 6: 0.0897, 7: 0.1328, 8: 0.1345, 9: 0.0924}\n",
      "chazhi:0.08330000\n",
      "epoch:28   global_step:27000\n",
      "{0: 0.1039, 1: 0.0972, 2: 0.0773, 3: 0.1002, 4: 0.1269, 5: 0.0587, 6: 0.0903, 7: 0.1258, 8: 0.1388, 9: 0.0809}\n",
      "chazhi:0.08010000\n",
      "epoch:29   global_step:27200\n",
      "{0: 0.1182, 1: 0.0985, 2: 0.0759, 3: 0.1093, 4: 0.1357, 5: 0.0388, 6: 0.0854, 7: 0.1465, 8: 0.1326, 9: 0.0591}\n",
      "chazhi:0.10770000\n",
      "epoch:29   global_step:27400\n",
      "{0: 0.1114, 1: 0.0922, 2: 0.0723, 3: 0.1158, 4: 0.1345, 5: 0.0453, 6: 0.0944, 7: 0.125, 8: 0.1263, 9: 0.0828}\n",
      "chazhi:0.08920000\n",
      "epoch:29   global_step:27600\n",
      "{0: 0.1106, 1: 0.0977, 2: 0.0807, 3: 0.1064, 4: 0.1204, 5: 0.0628, 6: 0.0869, 7: 0.1283, 8: 0.1335, 9: 0.0727}\n",
      "chazhi:0.07070000\n",
      "epoch:29   global_step:27800\n",
      "{0: 0.1282, 1: 0.0963, 2: 0.0648, 3: 0.091, 4: 0.1334, 5: 0.0456, 6: 0.1112, 7: 0.1138, 8: 0.1402, 9: 0.0755}\n",
      "chazhi:0.09460000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29   global_step:28000\n",
      "{0: 0.0976, 1: 0.121, 2: 0.0707, 3: 0.1084, 4: 0.0974, 5: 0.0423, 6: 0.092, 7: 0.1191, 8: 0.1637, 9: 0.0878}\n",
      "chazhi:0.12140000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist,fashion_mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class BIGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # Build the encoder\n",
    "        self.encoder = self.build_encoder()\n",
    "\n",
    "        # The part of the bigan that trains the discriminator and encoder\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Generate image from sampled noise\n",
    "        z = Input(shape=(self.latent_dim, ))\n",
    "        img_ = self.generator(z)\n",
    "\n",
    "        # Encode image\n",
    "        img = Input(shape=self.img_shape)\n",
    "        z_ = self.encoder(img)\n",
    "\n",
    "        # Latent -> img is fake, and img -> latent is valid\n",
    "        fake = self.discriminator([z, img_])\n",
    "        valid = self.discriminator([z_, img])\n",
    "\n",
    "        # Set up and compile the combined model\n",
    "        # Trains generator to fool the discriminator\n",
    "        self.bigan_generator = Model([z, img], [fake, valid])\n",
    "        self.bigan_generator.compile(loss=['binary_crossentropy', 'binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_encoder(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(self.latent_dim))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        z = model(img)\n",
    "\n",
    "        return Model(img, z)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        gen_img = model(z)\n",
    "\n",
    "        return Model(z, gen_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        z = Input(shape=(self.latent_dim, ))\n",
    "        img = Input(shape=self.img_shape)\n",
    "        d_in = concatenate([z, Flatten()(img)])\n",
    "\n",
    "        model = Dense(1024)(d_in)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.5)(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.5)(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.5)(model)\n",
    "        validity = Dense(1, activation=\"sigmoid\")(model)\n",
    "\n",
    "        return Model([z, img], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps=[]\n",
    "        values=[]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                z = np.random.normal(size=(batch_size, self.latent_dim))\n",
    "                imgs_ = self.generator.predict(z)\n",
    "\n",
    "                # Select a random batch of images and encode\n",
    "                # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                # imgs = X_train[idx]\n",
    "                z_ = self.encoder.predict(image_batch)\n",
    "\n",
    "                # Train the discriminator (img -> z is valid, z -> img is fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([z_, image_batch], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([z, imgs_], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Train the generator (z -> img is valid and img -> z is is invalid)\n",
    "                g_loss = self.bigan_generator.train_on_batch([z, image_batch], [valid, fake])\n",
    "\n",
    "                # Plot the progress\n",
    "#                 print(\"epoch:%d step:%d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0],\n",
    "#                                                                                    100 * d_loss[1], g_loss[0]))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    label_dict,value=self.mode_drop(epoch,global_step)\n",
    "                    steps.append(global_step)\n",
    "                    values.append(value)\n",
    "#             plt.subplots(1, 1)\n",
    "        plt.plot(steps,values)\n",
    "        plt.xlim([0,40000])\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.xlabel('steps')\n",
    "        plt.ylabel('epochs')\n",
    "        plt.tick_params(axis='both',which='major',labelsize=13)\n",
    "        plt.legend(loc='lower right')\n",
    "        if not os.path.isdir('images_bigan'):\n",
    "            os.mkdir('images_bigan')\n",
    "        plt.savefig(\"images_bigan/mode_drop.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def sample_interval(self, epoch,global_step):\n",
    "        r, c = 10, 10\n",
    "        z = np.random.normal(size=(r*c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(z)\n",
    "\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_bigan'):\n",
    "            os.mkdir('images_bigan')\n",
    "        fig.savefig(\"images_bigan/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "        plt.close()\n",
    "    def sample_interval_mult(self, epoch):\n",
    "        r, c = 20, 20\n",
    "        z = np.random.normal(size=(r*c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(z)\n",
    "\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig1, axs1 = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r//2):\n",
    "            for j in range(c//2):\n",
    "                axs1[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs1[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig2, axs2 = plt.subplots(r, c)\n",
    "        for i in range(r//2):\n",
    "            for j in range(c//2):\n",
    "                axs2[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs2[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_bigan'):\n",
    "            os.mkdir('images_bigan')\n",
    "        fig1.savefig(\"images_bigan/%d_1.png\" % epoch)\n",
    "        fig2.savefig(\"images_bigan/%d_2.png\" % epoch)\n",
    "        plt.close()\n",
    "    def mode_drop(self,epoch,global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        label_dict,value=calculate_labels(gen_imgs,epoch,global_step)\n",
    "        return label_dict,value\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bigan = BIGAN()\n",
    "    bigan.train(epochs=30, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
