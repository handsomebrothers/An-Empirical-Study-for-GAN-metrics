{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import torch\n",
    "from keras.utils.np_utils import *\n",
    "from keras.datasets import mnist\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH ='/home/imi432_006/huangdengrong/GAN-Research/metrics_gan/metrics/classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def calculate_labels(images,epoch,global_step):\n",
    "    label_dict={}\n",
    "    for i in range(10):\n",
    "        label_dict[i]=0\n",
    "    eval_images = tf.convert_to_tensor(images)\n",
    "    y_logit = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    labels=tf.argmax(y_logit, 1)\n",
    "    labels=tf.Session().run(labels)\n",
    "    for data in labels:\n",
    "        label_dict[data]+=1\n",
    "    for i in range(10):\n",
    "        label_dict[i]=label_dict[i]/len(images)\n",
    "    max_value=max(label_dict.values())\n",
    "    min_value=min(label_dict.values())\n",
    "    print('epoch:%d   global_step:%d'%(epoch,global_step))\n",
    "    print(label_dict)\n",
    "    print('chazhi:%.8f'%(max_value-min_value))\n",
    "    return label_dict,max_value-min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,097\n",
      "Trainable params: 99,649\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 1)         1025      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,028,673\n",
      "Trainable params: 1,028,289\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "epoch:0   global_step:200\n",
      "{0: 0.0217, 1: 0.0087, 2: 0.0144, 3: 0.0559, 4: 0.123, 5: 0.0178, 6: 0.0246, 7: 0.0696, 8: 0.6581, 9: 0.0062}\n",
      "chazhi:0.65190000\n",
      "epoch:0   global_step:400\n",
      "{0: 0.0116, 1: 0.0209, 2: 0.0093, 3: 0.1227, 4: 0.1987, 5: 0.0022, 6: 0.0143, 7: 0.1254, 8: 0.4942, 9: 0.0007}\n",
      "chazhi:0.49350000\n",
      "epoch:0   global_step:600\n",
      "{0: 0.038, 1: 0.0222, 2: 0.0615, 3: 0.0476, 4: 0.1402, 5: 0.0076, 6: 0.0114, 7: 0.1156, 8: 0.5558, 9: 0.0001}\n",
      "chazhi:0.55570000\n",
      "epoch:0   global_step:800\n",
      "{0: 0.1395, 1: 0.0146, 2: 0.1183, 3: 0.025, 4: 0.1898, 5: 0.0109, 6: 0.025, 7: 0.1429, 8: 0.3338, 9: 0.0002}\n",
      "chazhi:0.33360000\n",
      "epoch:0   global_step:1000\n",
      "{0: 0.0766, 1: 0.0225, 2: 0.1329, 3: 0.0665, 4: 0.1744, 5: 0.0341, 6: 0.0523, 7: 0.2213, 8: 0.217, 9: 0.0024}\n",
      "chazhi:0.21890000\n",
      "epoch:0   global_step:1200\n",
      "{0: 0.0537, 1: 0.0267, 2: 0.0975, 3: 0.0651, 4: 0.1734, 5: 0.0479, 6: 0.0808, 7: 0.1978, 8: 0.2536, 9: 0.0035}\n",
      "chazhi:0.25010000\n",
      "epoch:0   global_step:1400\n",
      "{0: 0.0387, 1: 0.0255, 2: 0.1096, 3: 0.1165, 4: 0.1233, 5: 0.0692, 6: 0.0463, 7: 0.1946, 8: 0.2706, 9: 0.0057}\n",
      "chazhi:0.26490000\n",
      "epoch:0   global_step:1600\n",
      "{0: 0.0402, 1: 0.0419, 2: 0.1296, 3: 0.1037, 4: 0.1176, 5: 0.0461, 6: 0.0375, 7: 0.1714, 8: 0.3065, 9: 0.0055}\n",
      "chazhi:0.30100000\n",
      "epoch:0   global_step:1800\n",
      "{0: 0.0587, 1: 0.0534, 2: 0.0908, 3: 0.085, 4: 0.1586, 5: 0.0299, 6: 0.0196, 7: 0.1955, 8: 0.3037, 9: 0.0048}\n",
      "chazhi:0.29890000\n",
      "epoch:0   global_step:2000\n",
      "{0: 0.0436, 1: 0.0867, 2: 0.0812, 3: 0.0871, 4: 0.1975, 5: 0.0166, 6: 0.0171, 7: 0.2606, 8: 0.2056, 9: 0.004}\n",
      "chazhi:0.25660000\n",
      "epoch:0   global_step:2200\n",
      "{0: 0.051, 1: 0.0953, 2: 0.0649, 3: 0.0675, 4: 0.2358, 5: 0.0137, 6: 0.0251, 7: 0.2823, 8: 0.1583, 9: 0.0061}\n",
      "chazhi:0.27620000\n",
      "epoch:0   global_step:2400\n",
      "{0: 0.0468, 1: 0.1126, 2: 0.0887, 3: 0.1007, 4: 0.2273, 5: 0.0134, 6: 0.0201, 7: 0.2496, 8: 0.1369, 9: 0.0039}\n",
      "chazhi:0.24570000\n",
      "epoch:0   global_step:2600\n",
      "{0: 0.0803, 1: 0.1566, 2: 0.0802, 3: 0.0623, 4: 0.251, 5: 0.0083, 6: 0.0273, 7: 0.1973, 8: 0.1327, 9: 0.004}\n",
      "chazhi:0.24700000\n",
      "epoch:0   global_step:2800\n",
      "{0: 0.0691, 1: 0.1357, 2: 0.0664, 3: 0.0551, 4: 0.2932, 5: 0.0133, 6: 0.035, 7: 0.2124, 8: 0.1174, 9: 0.0024}\n",
      "chazhi:0.29080000\n",
      "epoch:0   global_step:3000\n",
      "{0: 0.0679, 1: 0.1066, 2: 0.0662, 3: 0.0665, 4: 0.2913, 5: 0.0141, 6: 0.0338, 7: 0.2197, 8: 0.1311, 9: 0.0028}\n",
      "chazhi:0.28850000\n",
      "epoch:0   global_step:3200\n",
      "{0: 0.064, 1: 0.1033, 2: 0.0769, 3: 0.0824, 4: 0.2568, 5: 0.0212, 6: 0.0327, 7: 0.2082, 8: 0.1488, 9: 0.0057}\n",
      "chazhi:0.25110000\n",
      "epoch:0   global_step:3400\n",
      "{0: 0.0642, 1: 0.0857, 2: 0.1003, 3: 0.1032, 4: 0.2337, 5: 0.0195, 6: 0.0221, 7: 0.227, 8: 0.1392, 9: 0.0051}\n",
      "chazhi:0.22860000\n",
      "epoch:0   global_step:3600\n",
      "{0: 0.0294, 1: 0.0371, 2: 0.0915, 3: 0.1445, 4: 0.215, 5: 0.0177, 6: 0.0155, 7: 0.2971, 8: 0.1457, 9: 0.0065}\n",
      "chazhi:0.29060000\n",
      "epoch:0   global_step:3800\n",
      "{0: 0.0311, 1: 0.03, 2: 0.1046, 3: 0.1241, 4: 0.2317, 5: 0.0159, 6: 0.0288, 7: 0.2431, 8: 0.1808, 9: 0.0099}\n",
      "chazhi:0.23320000\n",
      "epoch:0   global_step:4000\n",
      "{0: 0.0373, 1: 0.0295, 2: 0.1036, 3: 0.126, 4: 0.2315, 5: 0.0143, 6: 0.0231, 7: 0.2357, 8: 0.1826, 9: 0.0164}\n",
      "chazhi:0.22140000\n",
      "epoch:0   global_step:4200\n",
      "{0: 0.0438, 1: 0.038, 2: 0.1326, 3: 0.1395, 4: 0.2068, 5: 0.0175, 6: 0.0305, 7: 0.2032, 8: 0.1776, 9: 0.0105}\n",
      "chazhi:0.19630000\n",
      "epoch:0   global_step:4400\n",
      "{0: 0.0416, 1: 0.0363, 2: 0.0881, 3: 0.1491, 4: 0.2272, 5: 0.0226, 6: 0.0414, 7: 0.2015, 8: 0.1745, 9: 0.0177}\n",
      "chazhi:0.20950000\n",
      "epoch:0   global_step:4600\n",
      "{0: 0.0477, 1: 0.0361, 2: 0.0743, 3: 0.1435, 4: 0.2373, 5: 0.0213, 6: 0.0388, 7: 0.1971, 8: 0.1829, 9: 0.021}\n",
      "chazhi:0.21630000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1   global_step:4800\n",
      "{0: 0.0933, 1: 0.042, 2: 0.0915, 3: 0.0884, 4: 0.2838, 5: 0.0119, 6: 0.0355, 7: 0.1419, 8: 0.1995, 9: 0.0122}\n",
      "chazhi:0.27190000\n",
      "epoch:1   global_step:5000\n",
      "{0: 0.0499, 1: 0.0357, 2: 0.0898, 3: 0.1477, 4: 0.2238, 5: 0.0297, 6: 0.0399, 7: 0.205, 8: 0.157, 9: 0.0215}\n",
      "chazhi:0.20230000\n",
      "epoch:1   global_step:5200\n",
      "{0: 0.0323, 1: 0.0415, 2: 0.0906, 3: 0.1508, 4: 0.217, 5: 0.0291, 6: 0.0447, 7: 0.1821, 8: 0.1872, 9: 0.0247}\n",
      "chazhi:0.19230000\n",
      "epoch:1   global_step:5400\n",
      "{0: 0.0522, 1: 0.0509, 2: 0.1023, 3: 0.1478, 4: 0.2172, 5: 0.0199, 6: 0.0395, 7: 0.1704, 8: 0.1838, 9: 0.016}\n",
      "chazhi:0.20120000\n",
      "epoch:1   global_step:5600\n",
      "{0: 0.0557, 1: 0.0442, 2: 0.0871, 3: 0.1271, 4: 0.1977, 5: 0.0319, 6: 0.0577, 7: 0.1806, 8: 0.1953, 9: 0.0227}\n",
      "chazhi:0.17500000\n",
      "epoch:1   global_step:5800\n",
      "{0: 0.0951, 1: 0.029, 2: 0.096, 3: 0.0888, 4: 0.2253, 5: 0.0208, 6: 0.048, 7: 0.1392, 8: 0.242, 9: 0.0158}\n",
      "chazhi:0.22620000\n",
      "epoch:1   global_step:6000\n",
      "{0: 0.0495, 1: 0.0345, 2: 0.081, 3: 0.1716, 4: 0.1763, 5: 0.0347, 6: 0.0498, 7: 0.187, 8: 0.1904, 9: 0.0252}\n",
      "chazhi:0.16520000\n",
      "epoch:1   global_step:6200\n",
      "{0: 0.063, 1: 0.0305, 2: 0.078, 3: 0.12, 4: 0.2049, 5: 0.0247, 6: 0.0411, 7: 0.1869, 8: 0.229, 9: 0.0219}\n",
      "chazhi:0.20710000\n",
      "epoch:1   global_step:6400\n",
      "{0: 0.0657, 1: 0.0321, 2: 0.0846, 3: 0.1246, 4: 0.1908, 5: 0.023, 6: 0.0402, 7: 0.1648, 8: 0.244, 9: 0.0302}\n",
      "chazhi:0.22100000\n",
      "epoch:1   global_step:6600\n",
      "{0: 0.0821, 1: 0.0337, 2: 0.099, 3: 0.1279, 4: 0.1743, 5: 0.0301, 6: 0.0441, 7: 0.1848, 8: 0.1976, 9: 0.0264}\n",
      "chazhi:0.17120000\n",
      "epoch:1   global_step:6800\n",
      "{0: 0.0457, 1: 0.0303, 2: 0.086, 3: 0.1644, 4: 0.1659, 5: 0.0365, 6: 0.0457, 7: 0.2055, 8: 0.186, 9: 0.034}\n",
      "chazhi:0.17520000\n",
      "epoch:1   global_step:7000\n",
      "{0: 0.0524, 1: 0.0317, 2: 0.1177, 3: 0.1426, 4: 0.1662, 5: 0.0269, 6: 0.0507, 7: 0.1777, 8: 0.2017, 9: 0.0324}\n",
      "chazhi:0.17480000\n",
      "epoch:1   global_step:7200\n",
      "{0: 0.0795, 1: 0.0441, 2: 0.0932, 3: 0.1406, 4: 0.1774, 5: 0.0203, 6: 0.0301, 7: 0.2018, 8: 0.1853, 9: 0.0277}\n",
      "chazhi:0.18150000\n",
      "epoch:1   global_step:7400\n",
      "{0: 0.0491, 1: 0.0398, 2: 0.0941, 3: 0.1633, 4: 0.1688, 5: 0.0287, 6: 0.0378, 7: 0.2095, 8: 0.1725, 9: 0.0364}\n",
      "chazhi:0.18080000\n",
      "epoch:1   global_step:7600\n",
      "{0: 0.0632, 1: 0.0417, 2: 0.0831, 3: 0.1328, 4: 0.1831, 5: 0.0276, 6: 0.0415, 7: 0.1803, 8: 0.2119, 9: 0.0348}\n",
      "chazhi:0.18430000\n",
      "epoch:1   global_step:7800\n",
      "{0: 0.0388, 1: 0.0516, 2: 0.0959, 3: 0.1533, 4: 0.1496, 5: 0.0312, 6: 0.0454, 7: 0.1987, 8: 0.203, 9: 0.0325}\n",
      "chazhi:0.17180000\n",
      "epoch:1   global_step:8000\n",
      "{0: 0.0689, 1: 0.0393, 2: 0.1057, 3: 0.1199, 4: 0.1774, 5: 0.0308, 6: 0.0541, 7: 0.2091, 8: 0.1683, 9: 0.0265}\n",
      "chazhi:0.18260000\n",
      "epoch:1   global_step:8200\n",
      "{0: 0.0561, 1: 0.0249, 2: 0.0984, 3: 0.1573, 4: 0.1878, 5: 0.0275, 6: 0.0333, 7: 0.2185, 8: 0.1658, 9: 0.0304}\n",
      "chazhi:0.19360000\n",
      "epoch:1   global_step:8400\n",
      "{0: 0.0668, 1: 0.0316, 2: 0.0969, 3: 0.1684, 4: 0.1515, 5: 0.0309, 6: 0.0435, 7: 0.2066, 8: 0.1677, 9: 0.0361}\n",
      "chazhi:0.17570000\n",
      "epoch:1   global_step:8600\n",
      "{0: 0.072, 1: 0.0242, 2: 0.1074, 3: 0.1256, 4: 0.1771, 5: 0.0229, 6: 0.0389, 7: 0.2293, 8: 0.1751, 9: 0.0275}\n",
      "chazhi:0.20640000\n",
      "epoch:1   global_step:8800\n",
      "{0: 0.0592, 1: 0.0269, 2: 0.1074, 3: 0.126, 4: 0.1645, 5: 0.0238, 6: 0.0479, 7: 0.201, 8: 0.2071, 9: 0.0362}\n",
      "chazhi:0.18330000\n",
      "epoch:1   global_step:9000\n",
      "{0: 0.0666, 1: 0.0342, 2: 0.0835, 3: 0.1538, 4: 0.1422, 5: 0.0255, 6: 0.0404, 7: 0.2135, 8: 0.1982, 9: 0.0421}\n",
      "chazhi:0.18800000\n",
      "epoch:1   global_step:9200\n",
      "{0: 0.0578, 1: 0.0282, 2: 0.0888, 3: 0.1574, 4: 0.1534, 5: 0.0367, 6: 0.042, 7: 0.2206, 8: 0.1724, 9: 0.0427}\n",
      "chazhi:0.19240000\n",
      "epoch:2   global_step:9400\n",
      "{0: 0.0742, 1: 0.0385, 2: 0.1074, 3: 0.1263, 4: 0.1817, 5: 0.0196, 6: 0.0317, 7: 0.2012, 8: 0.1859, 9: 0.0335}\n",
      "chazhi:0.18160000\n",
      "epoch:2   global_step:9600\n",
      "{0: 0.0847, 1: 0.0383, 2: 0.0975, 3: 0.1687, 4: 0.1554, 5: 0.0287, 6: 0.0346, 7: 0.209, 8: 0.1526, 9: 0.0305}\n",
      "chazhi:0.18030000\n",
      "epoch:2   global_step:9800\n",
      "{0: 0.0738, 1: 0.0459, 2: 0.0966, 3: 0.1316, 4: 0.1618, 5: 0.0191, 6: 0.0356, 7: 0.2083, 8: 0.1862, 9: 0.0411}\n",
      "chazhi:0.18920000\n",
      "epoch:2   global_step:10000\n",
      "{0: 0.0853, 1: 0.0481, 2: 0.0872, 3: 0.1207, 4: 0.1933, 5: 0.0134, 6: 0.0278, 7: 0.2121, 8: 0.1802, 9: 0.0319}\n",
      "chazhi:0.19870000\n",
      "epoch:2   global_step:10200\n",
      "{0: 0.0922, 1: 0.0411, 2: 0.0845, 3: 0.1265, 4: 0.1632, 5: 0.0213, 6: 0.0372, 7: 0.2261, 8: 0.1677, 9: 0.0402}\n",
      "chazhi:0.20480000\n",
      "epoch:2   global_step:10400\n",
      "{0: 0.1063, 1: 0.0422, 2: 0.0846, 3: 0.105, 4: 0.1864, 5: 0.0103, 6: 0.0313, 7: 0.2082, 8: 0.19, 9: 0.0357}\n",
      "chazhi:0.19790000\n",
      "epoch:2   global_step:10600\n",
      "{0: 0.0793, 1: 0.0442, 2: 0.0889, 3: 0.1558, 4: 0.1331, 5: 0.021, 6: 0.0323, 7: 0.1965, 8: 0.2028, 9: 0.0461}\n",
      "chazhi:0.18180000\n",
      "epoch:2   global_step:10800\n",
      "{0: 0.0832, 1: 0.0624, 2: 0.0696, 3: 0.15, 4: 0.1498, 5: 0.0174, 6: 0.0306, 7: 0.2189, 8: 0.1755, 9: 0.0426}\n",
      "chazhi:0.20150000\n",
      "epoch:2   global_step:11000\n",
      "{0: 0.0888, 1: 0.0472, 2: 0.0767, 3: 0.1337, 4: 0.1527, 5: 0.024, 6: 0.0357, 7: 0.2264, 8: 0.172, 9: 0.0428}\n",
      "chazhi:0.20240000\n",
      "epoch:2   global_step:11200\n",
      "{0: 0.0829, 1: 0.0554, 2: 0.0961, 3: 0.1372, 4: 0.1395, 5: 0.0234, 6: 0.0431, 7: 0.1867, 8: 0.1926, 9: 0.0431}\n",
      "chazhi:0.16920000\n",
      "epoch:2   global_step:11400\n",
      "{0: 0.0713, 1: 0.0628, 2: 0.0675, 3: 0.1847, 4: 0.1543, 5: 0.0219, 6: 0.0211, 7: 0.2907, 8: 0.0993, 9: 0.0264}\n",
      "chazhi:0.26960000\n",
      "epoch:2   global_step:11600\n",
      "{0: 0.0931, 1: 0.0525, 2: 0.0703, 3: 0.1439, 4: 0.1398, 5: 0.0227, 6: 0.04, 7: 0.2039, 8: 0.185, 9: 0.0488}\n",
      "chazhi:0.18120000\n",
      "epoch:2   global_step:11800\n",
      "{0: 0.0991, 1: 0.0605, 2: 0.088, 3: 0.1234, 4: 0.1653, 5: 0.0143, 6: 0.0356, 7: 0.197, 8: 0.1834, 9: 0.0334}\n",
      "chazhi:0.18270000\n",
      "epoch:2   global_step:12000\n",
      "{0: 0.0891, 1: 0.0589, 2: 0.0806, 3: 0.1581, 4: 0.1588, 5: 0.0292, 6: 0.0325, 7: 0.223, 8: 0.1394, 9: 0.0304}\n",
      "chazhi:0.19380000\n",
      "epoch:2   global_step:12200\n",
      "{0: 0.0822, 1: 0.0467, 2: 0.0814, 3: 0.1284, 4: 0.1831, 5: 0.0296, 6: 0.0362, 7: 0.2167, 8: 0.1655, 9: 0.0302}\n",
      "chazhi:0.18710000\n",
      "epoch:2   global_step:12400\n",
      "{0: 0.113, 1: 0.0749, 2: 0.072, 3: 0.1176, 4: 0.1585, 5: 0.0323, 6: 0.0407, 7: 0.1707, 8: 0.1861, 9: 0.0342}\n",
      "chazhi:0.15380000\n",
      "epoch:2   global_step:12600\n",
      "{0: 0.104, 1: 0.0695, 2: 0.0763, 3: 0.1156, 4: 0.1776, 5: 0.0283, 6: 0.0398, 7: 0.2302, 8: 0.1315, 9: 0.0272}\n",
      "chazhi:0.20300000\n",
      "epoch:2   global_step:12800\n",
      "{0: 0.0855, 1: 0.0851, 2: 0.0693, 3: 0.129, 4: 0.174, 5: 0.0339, 6: 0.0411, 7: 0.2283, 8: 0.1287, 9: 0.0251}\n",
      "chazhi:0.20320000\n",
      "epoch:2   global_step:13000\n",
      "{0: 0.1007, 1: 0.0778, 2: 0.0681, 3: 0.1152, 4: 0.1633, 5: 0.0337, 6: 0.0481, 7: 0.2092, 8: 0.1482, 9: 0.0357}\n",
      "chazhi:0.17550000\n",
      "epoch:2   global_step:13200\n",
      "{0: 0.0864, 1: 0.0859, 2: 0.0828, 3: 0.119, 4: 0.1699, 5: 0.0289, 6: 0.0461, 7: 0.2208, 8: 0.1311, 9: 0.0291}\n",
      "chazhi:0.19190000\n",
      "epoch:2   global_step:13400\n",
      "{0: 0.0933, 1: 0.0808, 2: 0.0735, 3: 0.1189, 4: 0.1638, 5: 0.0235, 6: 0.0423, 7: 0.2257, 8: 0.1337, 9: 0.0445}\n",
      "chazhi:0.20220000\n",
      "epoch:2   global_step:13600\n",
      "{0: 0.1153, 1: 0.0785, 2: 0.0832, 3: 0.123, 4: 0.1631, 5: 0.0238, 6: 0.0332, 7: 0.2125, 8: 0.1251, 9: 0.0423}\n",
      "chazhi:0.18870000\n",
      "epoch:2   global_step:13800\n",
      "{0: 0.0865, 1: 0.0724, 2: 0.0837, 3: 0.1465, 4: 0.1616, 5: 0.0346, 6: 0.0334, 7: 0.2456, 8: 0.0959, 9: 0.0398}\n",
      "chazhi:0.21220000\n",
      "epoch:2   global_step:14000\n",
      "{0: 0.0984, 1: 0.0703, 2: 0.0842, 3: 0.0964, 4: 0.1827, 5: 0.0288, 6: 0.0341, 7: 0.2077, 8: 0.1558, 9: 0.0416}\n",
      "chazhi:0.17890000\n",
      "epoch:3   global_step:14200\n",
      "{0: 0.092, 1: 0.0751, 2: 0.085, 3: 0.1274, 4: 0.2079, 5: 0.0294, 6: 0.0337, 7: 0.2216, 8: 0.1023, 9: 0.0256}\n",
      "chazhi:0.19600000\n",
      "epoch:3   global_step:14400\n",
      "{0: 0.0842, 1: 0.0713, 2: 0.0947, 3: 0.1151, 4: 0.1781, 5: 0.0326, 6: 0.0474, 7: 0.1927, 8: 0.1386, 9: 0.0453}\n",
      "chazhi:0.16010000\n",
      "epoch:3   global_step:14600\n",
      "{0: 0.0888, 1: 0.1021, 2: 0.087, 3: 0.1176, 4: 0.1566, 5: 0.0345, 6: 0.0573, 7: 0.191, 8: 0.1264, 9: 0.0387}\n",
      "chazhi:0.15650000\n",
      "epoch:3   global_step:14800\n",
      "{0: 0.1201, 1: 0.103, 2: 0.0608, 3: 0.1058, 4: 0.1868, 5: 0.0208, 6: 0.0428, 7: 0.206, 8: 0.1093, 9: 0.0446}\n",
      "chazhi:0.18520000\n",
      "epoch:3   global_step:15000\n",
      "{0: 0.1021, 1: 0.1028, 2: 0.0756, 3: 0.1301, 4: 0.1622, 5: 0.0203, 6: 0.0411, 7: 0.2075, 8: 0.1133, 9: 0.045}\n",
      "chazhi:0.18720000\n",
      "epoch:3   global_step:15200\n",
      "{0: 0.1043, 1: 0.084, 2: 0.0854, 3: 0.1428, 4: 0.1849, 5: 0.0233, 6: 0.0303, 7: 0.2215, 8: 0.0945, 9: 0.029}\n",
      "chazhi:0.19820000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3   global_step:15400\n",
      "{0: 0.0958, 1: 0.0797, 2: 0.0724, 3: 0.1277, 4: 0.168, 5: 0.0313, 6: 0.0478, 7: 0.1923, 8: 0.137, 9: 0.048}\n",
      "chazhi:0.16100000\n",
      "epoch:3   global_step:15600\n",
      "{0: 0.13, 1: 0.0983, 2: 0.0675, 3: 0.0874, 4: 0.1977, 5: 0.0183, 6: 0.0464, 7: 0.1939, 8: 0.12, 9: 0.0405}\n",
      "chazhi:0.17940000\n",
      "epoch:3   global_step:15800\n",
      "{0: 0.0987, 1: 0.0875, 2: 0.0638, 3: 0.1551, 4: 0.1594, 5: 0.0281, 6: 0.027, 7: 0.2096, 8: 0.1113, 9: 0.0595}\n",
      "chazhi:0.18260000\n",
      "epoch:3   global_step:16000\n",
      "{0: 0.1155, 1: 0.0883, 2: 0.0748, 3: 0.1101, 4: 0.1708, 5: 0.0272, 6: 0.0482, 7: 0.2013, 8: 0.1164, 9: 0.0474}\n",
      "chazhi:0.17410000\n",
      "epoch:3   global_step:16200\n",
      "{0: 0.1014, 1: 0.0796, 2: 0.0652, 3: 0.108, 4: 0.1685, 5: 0.0332, 6: 0.0445, 7: 0.2177, 8: 0.1244, 9: 0.0575}\n",
      "chazhi:0.18450000\n",
      "epoch:3   global_step:16400\n",
      "{0: 0.0898, 1: 0.085, 2: 0.1, 3: 0.1322, 4: 0.1581, 5: 0.0288, 6: 0.0448, 7: 0.1847, 8: 0.1363, 9: 0.0403}\n",
      "chazhi:0.15590000\n",
      "epoch:3   global_step:16600\n",
      "{0: 0.1249, 1: 0.1009, 2: 0.0684, 3: 0.1086, 4: 0.1603, 5: 0.0254, 6: 0.0448, 7: 0.1831, 8: 0.131, 9: 0.0526}\n",
      "chazhi:0.15770000\n",
      "epoch:3   global_step:16800\n",
      "{0: 0.1003, 1: 0.0894, 2: 0.0673, 3: 0.0981, 4: 0.1746, 5: 0.0256, 6: 0.0456, 7: 0.1878, 8: 0.1473, 9: 0.064}\n",
      "chazhi:0.16220000\n",
      "epoch:3   global_step:17000\n",
      "{0: 0.118, 1: 0.0973, 2: 0.075, 3: 0.1043, 4: 0.1853, 5: 0.0271, 6: 0.0402, 7: 0.1776, 8: 0.1266, 9: 0.0486}\n",
      "chazhi:0.15820000\n",
      "epoch:3   global_step:17200\n",
      "{0: 0.1048, 1: 0.0994, 2: 0.0655, 3: 0.0971, 4: 0.1759, 5: 0.0272, 6: 0.0523, 7: 0.184, 8: 0.1425, 9: 0.0513}\n",
      "chazhi:0.15680000\n",
      "epoch:3   global_step:17400\n",
      "{0: 0.1293, 1: 0.1062, 2: 0.0719, 3: 0.0804, 4: 0.1823, 5: 0.025, 6: 0.0466, 7: 0.2043, 8: 0.1154, 9: 0.0386}\n",
      "chazhi:0.17930000\n",
      "epoch:3   global_step:17600\n",
      "{0: 0.0954, 1: 0.0785, 2: 0.0641, 3: 0.1113, 4: 0.1948, 5: 0.025, 6: 0.0298, 7: 0.2261, 8: 0.1287, 9: 0.0463}\n",
      "chazhi:0.20110000\n",
      "epoch:3   global_step:17800\n",
      "{0: 0.115, 1: 0.0846, 2: 0.0791, 3: 0.0833, 4: 0.181, 5: 0.0297, 6: 0.0496, 7: 0.1761, 8: 0.154, 9: 0.0476}\n",
      "chazhi:0.15130000\n",
      "epoch:3   global_step:18000\n",
      "{0: 0.1189, 1: 0.083, 2: 0.0671, 3: 0.1162, 4: 0.1786, 5: 0.0307, 6: 0.0331, 7: 0.2046, 8: 0.1162, 9: 0.0516}\n",
      "chazhi:0.17390000\n",
      "epoch:3   global_step:18200\n",
      "{0: 0.1087, 1: 0.0915, 2: 0.0772, 3: 0.0971, 4: 0.1714, 5: 0.0202, 6: 0.0433, 7: 0.183, 8: 0.1486, 9: 0.059}\n",
      "chazhi:0.16280000\n",
      "epoch:3   global_step:18400\n",
      "{0: 0.1149, 1: 0.0858, 2: 0.0711, 3: 0.1063, 4: 0.1392, 5: 0.0311, 6: 0.055, 7: 0.178, 8: 0.1571, 9: 0.0615}\n",
      "chazhi:0.14690000\n",
      "epoch:3   global_step:18600\n",
      "{0: 0.0923, 1: 0.0764, 2: 0.07, 3: 0.121, 4: 0.16, 5: 0.0333, 6: 0.0403, 7: 0.2271, 8: 0.1203, 9: 0.0593}\n",
      "chazhi:0.19380000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "                            optimizer=optimizer,\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "                              optimizer=optimizer,\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake = np.ones((batch_size, 1))\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps=[]\n",
    "        values=[]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                for _ in range(self.n_critic):\n",
    "                    global_step += 1\n",
    "                    imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                    # ---------------------\n",
    "                    #  Train Discriminator\n",
    "                    # ---------------------\n",
    "\n",
    "                    # Select a random batch of images\n",
    "                    # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                    # imgs = X_train[idx]\n",
    "\n",
    "                    # Sample noise as generator input\n",
    "                    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                    # Generate a batch of new images\n",
    "                    gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                    # Train the critic\n",
    "                    d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                    d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                    d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                    # Clip critic weights\n",
    "                    for l in self.critic.layers:\n",
    "                        weights = l.get_weights()\n",
    "                        weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                        l.set_weights(weights)\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Generator\n",
    "                    # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "#                 print(\"epoch:%d step:%d[D loss: %f] [G loss: %f]\" % (epoch,global_step, 1 - d_loss[0], 1 - g_loss[0]))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    label_dict,value=self.mode_drop(epoch,global_step)\n",
    "                    steps.append(global_step)\n",
    "                    values.append(value)\n",
    "#             plt.subplots(1, 1)\n",
    "        plt.plot(steps,values)\n",
    "        plt.xlim([0,40000])\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.xlabel('steps')\n",
    "        plt.ylabel('epochs')\n",
    "        plt.tick_params(axis='both',which='major',labelsize=13)\n",
    "        plt.legend(loc='lower right')\n",
    "        if not os.path.isdir('images_wgan'):\n",
    "            os.mkdir('images_wgan')\n",
    "        plt.savefig(\"images_wgan/mode_drop.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch,global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_wgan'):\n",
    "            os.mkdir('images_wgan')\n",
    "        fig.savefig(\"images_wgan/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "        plt.close()\n",
    "    def mode_drop(self,epoch,global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        label_dict,value=calculate_labels(gen_imgs,epoch,global_step)\n",
    "        return label_dict,value\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGAN()\n",
    "    wgan.train(epochs=4, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
