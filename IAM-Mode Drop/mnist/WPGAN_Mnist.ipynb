{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import util\n",
    "import torch\n",
    "from keras.utils.np_utils import *\n",
    "from keras.datasets import mnist\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH ='/home/imi432_006/huangdengrong/GAN-Research/metrics_gan/metrics/classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def calculate_labels(images,epoch,global_step):\n",
    "    label_dict={}\n",
    "    for i in range(10):\n",
    "        label_dict[i]=0\n",
    "    eval_images = tf.convert_to_tensor(images)\n",
    "    y_logit = util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    labels=tf.argmax(y_logit, 1)\n",
    "    labels=tf.Session().run(labels)\n",
    "    for data in labels:\n",
    "        label_dict[data]+=1\n",
    "    for i in range(10):\n",
    "        label_dict[i]=label_dict[i]/len(images)\n",
    "    max_value=max(label_dict.values())\n",
    "    min_value=min(label_dict.values())\n",
    "    print('epoch:%d   global_step:%d'%(epoch,global_step))\n",
    "    print(label_dict)\n",
    "    print('chazhi:%.8f'%(max_value-min_value))\n",
    "    return label_dict,max_value-min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 28, 28, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 28, 28, 1)         1025      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,028,673\n",
      "Trainable params: 1,028,289\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,097\n",
      "Trainable params: 99,649\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "epoch:0   global_step:200\n",
      "{0: 0.0332, 1: 0.0023, 2: 0.0265, 3: 0.0162, 4: 0.248, 5: 0.0047, 6: 0.0073, 7: 0.0714, 8: 0.588, 9: 0.0024}\n",
      "chazhi:0.58570000\n",
      "epoch:0   global_step:400\n",
      "{0: 0.0257, 1: 0.01, 2: 0.0339, 3: 0.0542, 4: 0.1864, 5: 0.0072, 6: 0.0163, 7: 0.1589, 8: 0.5055, 9: 0.0019}\n",
      "chazhi:0.50360000\n",
      "epoch:0   global_step:600\n",
      "{0: 0.0401, 1: 0.0122, 2: 0.0425, 3: 0.0587, 4: 0.1569, 5: 0.0184, 6: 0.0183, 7: 0.1882, 8: 0.4626, 9: 0.0021}\n",
      "chazhi:0.46050000\n",
      "epoch:0   global_step:800\n",
      "{0: 0.0386, 1: 0.0092, 2: 0.0565, 3: 0.1025, 4: 0.1412, 5: 0.0276, 6: 0.0109, 7: 0.2744, 8: 0.3289, 9: 0.0102}\n",
      "chazhi:0.31970000\n",
      "epoch:0   global_step:1000\n",
      "{0: 0.0522, 1: 0.0386, 2: 0.0707, 3: 0.0681, 4: 0.1614, 5: 0.0267, 6: 0.0275, 7: 0.2185, 8: 0.3292, 9: 0.0071}\n",
      "chazhi:0.32210000\n",
      "epoch:0   global_step:1200\n",
      "{0: 0.0518, 1: 0.055, 2: 0.0652, 3: 0.1299, 4: 0.1228, 5: 0.0553, 6: 0.0215, 7: 0.2415, 8: 0.2499, 9: 0.0071}\n",
      "chazhi:0.24280000\n",
      "epoch:0   global_step:1400\n",
      "{0: 0.0736, 1: 0.0675, 2: 0.0784, 3: 0.0937, 4: 0.1534, 5: 0.0231, 6: 0.0251, 7: 0.254, 8: 0.2217, 9: 0.0095}\n",
      "chazhi:0.24450000\n",
      "epoch:0   global_step:1600\n",
      "{0: 0.0721, 1: 0.0616, 2: 0.0778, 3: 0.1216, 4: 0.1503, 5: 0.0272, 6: 0.0272, 7: 0.2785, 8: 0.1737, 9: 0.01}\n",
      "chazhi:0.26850000\n",
      "epoch:0   global_step:1800\n",
      "{0: 0.0918, 1: 0.0801, 2: 0.0787, 3: 0.1237, 4: 0.1809, 5: 0.0251, 6: 0.023, 7: 0.1975, 8: 0.1847, 9: 0.0145}\n",
      "chazhi:0.18300000\n",
      "epoch:0   global_step:2000\n",
      "{0: 0.0807, 1: 0.0422, 2: 0.1103, 3: 0.1399, 4: 0.1901, 5: 0.0365, 6: 0.0201, 7: 0.1957, 8: 0.17, 9: 0.0145}\n",
      "chazhi:0.18120000\n",
      "epoch:0   global_step:2200\n",
      "{0: 0.0467, 1: 0.0133, 2: 0.1319, 3: 0.2212, 4: 0.145, 5: 0.0379, 6: 0.0068, 7: 0.1957, 8: 0.1887, 9: 0.0128}\n",
      "chazhi:0.21440000\n",
      "epoch:0   global_step:2400\n",
      "{0: 0.0409, 1: 0.0187, 2: 0.0899, 3: 0.2635, 4: 0.1295, 5: 0.0368, 6: 0.0143, 7: 0.2153, 8: 0.1603, 9: 0.0308}\n",
      "chazhi:0.24920000\n",
      "epoch:0   global_step:2600\n",
      "{0: 0.0624, 1: 0.0247, 2: 0.0945, 3: 0.2361, 4: 0.1479, 5: 0.0295, 6: 0.0171, 7: 0.2173, 8: 0.1497, 9: 0.0208}\n",
      "chazhi:0.21900000\n",
      "epoch:0   global_step:2800\n",
      "{0: 0.0752, 1: 0.0166, 2: 0.1073, 3: 0.1967, 4: 0.176, 5: 0.0286, 6: 0.0184, 7: 0.2003, 8: 0.1567, 9: 0.0242}\n",
      "chazhi:0.18370000\n",
      "epoch:0   global_step:3000\n",
      "{0: 0.0647, 1: 0.0201, 2: 0.0766, 3: 0.2071, 4: 0.16, 5: 0.028, 6: 0.0198, 7: 0.2381, 8: 0.1538, 9: 0.0318}\n",
      "chazhi:0.21830000\n",
      "epoch:0   global_step:3200\n",
      "{0: 0.0851, 1: 0.0146, 2: 0.0839, 3: 0.2252, 4: 0.1557, 5: 0.0324, 6: 0.0131, 7: 0.1954, 8: 0.1671, 9: 0.0275}\n",
      "chazhi:0.21210000\n",
      "epoch:0   global_step:3400\n",
      "{0: 0.056, 1: 0.0213, 2: 0.0955, 3: 0.268, 4: 0.1202, 5: 0.036, 6: 0.0165, 7: 0.1569, 8: 0.1987, 9: 0.0309}\n",
      "chazhi:0.25150000\n",
      "epoch:0   global_step:3600\n",
      "{0: 0.1289, 1: 0.021, 2: 0.0678, 3: 0.1384, 4: 0.2046, 5: 0.0232, 6: 0.022, 7: 0.1424, 8: 0.2051, 9: 0.0466}\n",
      "chazhi:0.18410000\n",
      "epoch:0   global_step:3800\n",
      "{0: 0.1003, 1: 0.0156, 2: 0.079, 3: 0.1546, 4: 0.1592, 5: 0.0301, 6: 0.0224, 7: 0.2257, 8: 0.1756, 9: 0.0375}\n",
      "chazhi:0.21010000\n",
      "epoch:0   global_step:4000\n",
      "{0: 0.0797, 1: 0.0212, 2: 0.0687, 3: 0.2177, 4: 0.1161, 5: 0.0294, 6: 0.0171, 7: 0.2157, 8: 0.1932, 9: 0.0412}\n",
      "chazhi:0.20060000\n",
      "epoch:0   global_step:4200\n",
      "{0: 0.0693, 1: 0.0262, 2: 0.0673, 3: 0.1685, 4: 0.1395, 5: 0.0338, 6: 0.0347, 7: 0.2053, 8: 0.2148, 9: 0.0406}\n",
      "chazhi:0.18860000\n",
      "epoch:0   global_step:4400\n",
      "{0: 0.0996, 1: 0.0245, 2: 0.0671, 3: 0.1687, 4: 0.1335, 5: 0.0271, 6: 0.032, 7: 0.1728, 8: 0.2266, 9: 0.0481}\n",
      "chazhi:0.20210000\n",
      "epoch:0   global_step:4600\n",
      "{0: 0.0846, 1: 0.0267, 2: 0.0755, 3: 0.16, 4: 0.1791, 5: 0.0191, 6: 0.0256, 7: 0.2065, 8: 0.1928, 9: 0.0301}\n",
      "chazhi:0.18740000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0   global_step:4800\n",
      "{0: 0.1436, 1: 0.0274, 2: 0.0777, 3: 0.1286, 4: 0.1467, 5: 0.0266, 6: 0.0235, 7: 0.17, 8: 0.2262, 9: 0.0297}\n",
      "chazhi:0.20270000\n",
      "epoch:0   global_step:5000\n",
      "{0: 0.0863, 1: 0.021, 2: 0.072, 3: 0.1629, 4: 0.1492, 5: 0.0312, 6: 0.0228, 7: 0.1733, 8: 0.2408, 9: 0.0405}\n",
      "chazhi:0.21980000\n",
      "epoch:0   global_step:5200\n",
      "{0: 0.0795, 1: 0.0284, 2: 0.0857, 3: 0.1555, 4: 0.1637, 5: 0.0303, 6: 0.032, 7: 0.16, 8: 0.2301, 9: 0.0348}\n",
      "chazhi:0.20170000\n",
      "epoch:0   global_step:5400\n",
      "{0: 0.0943, 1: 0.0268, 2: 0.0781, 3: 0.1458, 4: 0.1756, 5: 0.0217, 6: 0.0295, 7: 0.1839, 8: 0.2114, 9: 0.0329}\n",
      "chazhi:0.18970000\n",
      "epoch:0   global_step:5600\n",
      "{0: 0.1, 1: 0.0216, 2: 0.0878, 3: 0.1254, 4: 0.1862, 5: 0.0218, 6: 0.0263, 7: 0.1844, 8: 0.2166, 9: 0.0299}\n",
      "chazhi:0.19500000\n",
      "epoch:0   global_step:5800\n",
      "{0: 0.1296, 1: 0.0124, 2: 0.0878, 3: 0.1346, 4: 0.1333, 5: 0.0231, 6: 0.0361, 7: 0.1351, 8: 0.2571, 9: 0.0509}\n",
      "chazhi:0.24470000\n",
      "epoch:0   global_step:6000\n",
      "{0: 0.1003, 1: 0.0169, 2: 0.0776, 3: 0.169, 4: 0.1346, 5: 0.0162, 6: 0.0305, 7: 0.1661, 8: 0.2329, 9: 0.0559}\n",
      "chazhi:0.21670000\n",
      "epoch:0   global_step:6200\n",
      "{0: 0.1165, 1: 0.0289, 2: 0.0873, 3: 0.1355, 4: 0.133, 5: 0.0268, 6: 0.0465, 7: 0.1678, 8: 0.2094, 9: 0.0483}\n",
      "chazhi:0.18260000\n",
      "epoch:0   global_step:6400\n",
      "{0: 0.1321, 1: 0.0362, 2: 0.0784, 3: 0.1206, 4: 0.1757, 5: 0.0302, 6: 0.0387, 7: 0.1797, 8: 0.1742, 9: 0.0342}\n",
      "chazhi:0.14950000\n",
      "epoch:0   global_step:6600\n",
      "{0: 0.1376, 1: 0.0334, 2: 0.0767, 3: 0.1004, 4: 0.1915, 5: 0.0238, 6: 0.0521, 7: 0.1318, 8: 0.2076, 9: 0.0451}\n",
      "chazhi:0.18380000\n",
      "epoch:0   global_step:6800\n",
      "{0: 0.0865, 1: 0.0277, 2: 0.0876, 3: 0.1649, 4: 0.136, 5: 0.0286, 6: 0.0449, 7: 0.1643, 8: 0.2092, 9: 0.0503}\n",
      "chazhi:0.18150000\n",
      "epoch:0   global_step:7000\n",
      "{0: 0.0848, 1: 0.0266, 2: 0.0817, 3: 0.1623, 4: 0.1654, 5: 0.0291, 6: 0.035, 7: 0.2046, 8: 0.1753, 9: 0.0352}\n",
      "chazhi:0.17800000\n",
      "epoch:0   global_step:7200\n",
      "{0: 0.0932, 1: 0.0201, 2: 0.0788, 3: 0.1472, 4: 0.1547, 5: 0.0314, 6: 0.0476, 7: 0.1868, 8: 0.1905, 9: 0.0497}\n",
      "chazhi:0.17040000\n",
      "epoch:0   global_step:7400\n",
      "{0: 0.095, 1: 0.0311, 2: 0.0797, 3: 0.1563, 4: 0.166, 5: 0.0241, 6: 0.0436, 7: 0.1933, 8: 0.1675, 9: 0.0434}\n",
      "chazhi:0.16920000\n",
      "epoch:0   global_step:7600\n",
      "{0: 0.1123, 1: 0.0455, 2: 0.0841, 3: 0.1252, 4: 0.1823, 5: 0.0189, 6: 0.0531, 7: 0.173, 8: 0.1619, 9: 0.0437}\n",
      "chazhi:0.16340000\n",
      "epoch:0   global_step:7800\n",
      "{0: 0.1248, 1: 0.0308, 2: 0.0866, 3: 0.1358, 4: 0.1844, 5: 0.023, 6: 0.0499, 7: 0.1707, 8: 0.1548, 9: 0.0392}\n",
      "chazhi:0.16140000\n",
      "epoch:0   global_step:8000\n",
      "{0: 0.0957, 1: 0.0355, 2: 0.0791, 3: 0.1953, 4: 0.1391, 5: 0.0309, 6: 0.037, 7: 0.1805, 8: 0.1557, 9: 0.0512}\n",
      "chazhi:0.16440000\n",
      "epoch:0   global_step:8200\n",
      "{0: 0.1107, 1: 0.0478, 2: 0.0905, 3: 0.1546, 4: 0.1639, 5: 0.0242, 6: 0.045, 7: 0.1586, 8: 0.1652, 9: 0.0395}\n",
      "chazhi:0.14100000\n",
      "epoch:0   global_step:8400\n",
      "{0: 0.0962, 1: 0.0493, 2: 0.0971, 3: 0.1496, 4: 0.1646, 5: 0.0334, 6: 0.0429, 7: 0.1729, 8: 0.1576, 9: 0.0364}\n",
      "chazhi:0.13950000\n",
      "epoch:0   global_step:8600\n",
      "{0: 0.0903, 1: 0.0252, 2: 0.084, 3: 0.1542, 4: 0.1523, 5: 0.0306, 6: 0.0541, 7: 0.1591, 8: 0.1855, 9: 0.0647}\n",
      "chazhi:0.16030000\n",
      "epoch:0   global_step:8800\n",
      "{0: 0.0876, 1: 0.0316, 2: 0.1109, 3: 0.1715, 4: 0.1547, 5: 0.0306, 6: 0.0471, 7: 0.1712, 8: 0.147, 9: 0.0478}\n",
      "chazhi:0.14090000\n",
      "epoch:0   global_step:9000\n",
      "{0: 0.0872, 1: 0.029, 2: 0.1076, 3: 0.1702, 4: 0.1399, 5: 0.0303, 6: 0.0468, 7: 0.1822, 8: 0.1435, 9: 0.0633}\n",
      "chazhi:0.15320000\n",
      "epoch:0   global_step:9200\n",
      "{0: 0.1169, 1: 0.0493, 2: 0.0992, 3: 0.1215, 4: 0.1741, 5: 0.0201, 6: 0.039, 7: 0.1635, 8: 0.1645, 9: 0.0519}\n",
      "chazhi:0.15400000\n",
      "epoch:1   global_step:9400\n",
      "{0: 0.1322, 1: 0.0751, 2: 0.0855, 3: 0.0929, 4: 0.2002, 5: 0.0208, 6: 0.0518, 7: 0.1511, 8: 0.1474, 9: 0.043}\n",
      "chazhi:0.17940000\n",
      "epoch:1   global_step:9600\n",
      "{0: 0.1253, 1: 0.0554, 2: 0.0958, 3: 0.0907, 4: 0.1974, 5: 0.0206, 6: 0.0585, 7: 0.134, 8: 0.1702, 9: 0.0521}\n",
      "chazhi:0.17680000\n",
      "epoch:1   global_step:9800\n",
      "{0: 0.1011, 1: 0.0434, 2: 0.0941, 3: 0.1152, 4: 0.1795, 5: 0.0238, 6: 0.065, 7: 0.169, 8: 0.1611, 9: 0.0478}\n",
      "chazhi:0.15570000\n",
      "epoch:1   global_step:10000\n",
      "{0: 0.0993, 1: 0.0531, 2: 0.0927, 3: 0.1236, 4: 0.1602, 5: 0.0241, 6: 0.0608, 7: 0.1695, 8: 0.1631, 9: 0.0536}\n",
      "chazhi:0.14540000\n",
      "epoch:1   global_step:10200\n",
      "{0: 0.1139, 1: 0.0499, 2: 0.0913, 3: 0.0977, 4: 0.1876, 5: 0.0118, 6: 0.0524, 7: 0.1839, 8: 0.1548, 9: 0.0567}\n",
      "chazhi:0.17580000\n",
      "epoch:1   global_step:10400\n",
      "{0: 0.121, 1: 0.0748, 2: 0.0801, 3: 0.0949, 4: 0.1913, 5: 0.0147, 6: 0.0595, 7: 0.1805, 8: 0.1247, 9: 0.0585}\n",
      "chazhi:0.17660000\n",
      "epoch:1   global_step:10600\n",
      "{0: 0.1366, 1: 0.0732, 2: 0.0587, 3: 0.0913, 4: 0.1535, 5: 0.0201, 6: 0.0551, 7: 0.1457, 8: 0.2033, 9: 0.0625}\n",
      "chazhi:0.18320000\n",
      "epoch:1   global_step:10800\n",
      "{0: 0.1319, 1: 0.0835, 2: 0.0779, 3: 0.0805, 4: 0.1915, 5: 0.0126, 6: 0.0546, 7: 0.1606, 8: 0.1565, 9: 0.0504}\n",
      "chazhi:0.17890000\n",
      "epoch:1   global_step:11000\n",
      "{0: 0.1387, 1: 0.0597, 2: 0.0851, 3: 0.1044, 4: 0.1484, 5: 0.0152, 6: 0.0563, 7: 0.187, 8: 0.1507, 9: 0.0545}\n",
      "chazhi:0.17180000\n",
      "epoch:1   global_step:11200\n",
      "{0: 0.1187, 1: 0.0652, 2: 0.0645, 3: 0.1193, 4: 0.1415, 5: 0.0262, 6: 0.0543, 7: 0.1821, 8: 0.1623, 9: 0.0659}\n",
      "chazhi:0.15590000\n",
      "epoch:1   global_step:11400\n",
      "{0: 0.1299, 1: 0.0841, 2: 0.0696, 3: 0.096, 4: 0.1756, 5: 0.0237, 6: 0.0585, 7: 0.163, 8: 0.1513, 9: 0.0483}\n",
      "chazhi:0.15190000\n",
      "epoch:1   global_step:11600\n",
      "{0: 0.1147, 1: 0.0588, 2: 0.0799, 3: 0.1137, 4: 0.1564, 5: 0.0226, 6: 0.0501, 7: 0.1572, 8: 0.1889, 9: 0.0577}\n",
      "chazhi:0.16630000\n",
      "epoch:1   global_step:11800\n",
      "{0: 0.1042, 1: 0.0688, 2: 0.0718, 3: 0.1205, 4: 0.1565, 5: 0.0228, 6: 0.0616, 7: 0.1755, 8: 0.1518, 9: 0.0665}\n",
      "chazhi:0.15270000\n",
      "epoch:1   global_step:12000\n",
      "{0: 0.1236, 1: 0.0939, 2: 0.06, 3: 0.1286, 4: 0.1331, 5: 0.024, 6: 0.0523, 7: 0.1873, 8: 0.129, 9: 0.0682}\n",
      "chazhi:0.16330000\n",
      "epoch:1   global_step:12200\n",
      "{0: 0.1236, 1: 0.0782, 2: 0.0737, 3: 0.1303, 4: 0.1426, 5: 0.0182, 6: 0.0488, 7: 0.1854, 8: 0.1369, 9: 0.0623}\n",
      "chazhi:0.16720000\n",
      "epoch:1   global_step:12400\n",
      "{0: 0.1157, 1: 0.0861, 2: 0.0743, 3: 0.1095, 4: 0.1477, 5: 0.0208, 6: 0.0544, 7: 0.1863, 8: 0.1424, 9: 0.0628}\n",
      "chazhi:0.16550000\n",
      "epoch:1   global_step:12600\n",
      "{0: 0.1185, 1: 0.0608, 2: 0.0757, 3: 0.1124, 4: 0.1423, 5: 0.0299, 6: 0.0547, 7: 0.1516, 8: 0.1738, 9: 0.0803}\n",
      "chazhi:0.14390000\n",
      "epoch:1   global_step:12800\n",
      "{0: 0.1312, 1: 0.0937, 2: 0.0901, 3: 0.1163, 4: 0.1435, 5: 0.0261, 6: 0.0439, 7: 0.1654, 8: 0.1236, 9: 0.0662}\n",
      "chazhi:0.13930000\n",
      "epoch:1   global_step:13000\n",
      "{0: 0.1428, 1: 0.0848, 2: 0.0784, 3: 0.0779, 4: 0.1822, 5: 0.015, 6: 0.0711, 7: 0.1261, 8: 0.1453, 9: 0.0764}\n",
      "chazhi:0.16720000\n",
      "epoch:1   global_step:13200\n",
      "{0: 0.1242, 1: 0.0769, 2: 0.0585, 3: 0.0886, 4: 0.1598, 5: 0.0246, 6: 0.0598, 7: 0.1701, 8: 0.1648, 9: 0.0727}\n",
      "chazhi:0.14550000\n",
      "epoch:1   global_step:13400\n",
      "{0: 0.1284, 1: 0.0801, 2: 0.0654, 3: 0.1033, 4: 0.1311, 5: 0.0231, 6: 0.0543, 7: 0.1799, 8: 0.163, 9: 0.0714}\n",
      "chazhi:0.15680000\n",
      "epoch:1   global_step:13600\n",
      "{0: 0.1208, 1: 0.068, 2: 0.0666, 3: 0.0811, 4: 0.1475, 5: 0.0245, 6: 0.0731, 7: 0.1637, 8: 0.1635, 9: 0.0912}\n",
      "chazhi:0.13920000\n",
      "epoch:1   global_step:13800\n",
      "{0: 0.1183, 1: 0.0677, 2: 0.072, 3: 0.0771, 4: 0.1571, 5: 0.0193, 6: 0.0676, 7: 0.1529, 8: 0.1769, 9: 0.0911}\n",
      "chazhi:0.15760000\n",
      "epoch:1   global_step:14000\n",
      "{0: 0.1343, 1: 0.0811, 2: 0.0755, 3: 0.0747, 4: 0.1826, 5: 0.0242, 6: 0.0613, 7: 0.1671, 8: 0.1325, 9: 0.0667}\n",
      "chazhi:0.15840000\n",
      "epoch:1   global_step:14200\n",
      "{0: 0.1216, 1: 0.1029, 2: 0.0737, 3: 0.0822, 4: 0.1791, 5: 0.0275, 6: 0.0593, 7: 0.1647, 8: 0.1308, 9: 0.0582}\n",
      "chazhi:0.15160000\n",
      "epoch:1   global_step:14400\n",
      "{0: 0.1055, 1: 0.104, 2: 0.07, 3: 0.0843, 4: 0.1522, 5: 0.0341, 6: 0.0708, 7: 0.1597, 8: 0.1488, 9: 0.0706}\n",
      "chazhi:0.12560000\n",
      "epoch:1   global_step:14600\n",
      "{0: 0.1063, 1: 0.0912, 2: 0.089, 3: 0.0823, 4: 0.1582, 5: 0.0315, 6: 0.0752, 7: 0.1479, 8: 0.1582, 9: 0.0602}\n",
      "chazhi:0.12670000\n",
      "epoch:1   global_step:14800\n",
      "{0: 0.11, 1: 0.0747, 2: 0.075, 3: 0.1033, 4: 0.1566, 5: 0.0226, 6: 0.0543, 7: 0.1658, 8: 0.1591, 9: 0.0786}\n",
      "chazhi:0.14320000\n",
      "epoch:1   global_step:15000\n",
      "{0: 0.1183, 1: 0.075, 2: 0.0772, 3: 0.0983, 4: 0.1713, 5: 0.0288, 6: 0.0551, 7: 0.1622, 8: 0.1424, 9: 0.0714}\n",
      "chazhi:0.14250000\n",
      "epoch:1   global_step:15200\n",
      "{0: 0.1399, 1: 0.0696, 2: 0.0658, 3: 0.0837, 4: 0.1615, 5: 0.0202, 6: 0.0724, 7: 0.1159, 8: 0.1674, 9: 0.1036}\n",
      "chazhi:0.14720000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1   global_step:15400\n",
      "{0: 0.1302, 1: 0.0758, 2: 0.0764, 3: 0.101, 4: 0.1597, 5: 0.0276, 6: 0.0661, 7: 0.1288, 8: 0.1403, 9: 0.0941}\n",
      "chazhi:0.13210000\n",
      "epoch:1   global_step:15600\n",
      "{0: 0.1222, 1: 0.1076, 2: 0.0676, 3: 0.0892, 4: 0.1879, 5: 0.0195, 6: 0.0694, 7: 0.1433, 8: 0.1221, 9: 0.0712}\n",
      "chazhi:0.16840000\n",
      "epoch:1   global_step:15800\n",
      "{0: 0.1376, 1: 0.083, 2: 0.0707, 3: 0.1009, 4: 0.1739, 5: 0.0321, 6: 0.0633, 7: 0.152, 8: 0.121, 9: 0.0655}\n",
      "chazhi:0.14180000\n",
      "epoch:1   global_step:16000\n",
      "{0: 0.1316, 1: 0.0785, 2: 0.0762, 3: 0.0801, 4: 0.1884, 5: 0.0255, 6: 0.0831, 7: 0.1261, 8: 0.138, 9: 0.0725}\n",
      "chazhi:0.16290000\n",
      "epoch:1   global_step:16200\n",
      "{0: 0.1091, 1: 0.091, 2: 0.0729, 3: 0.0928, 4: 0.1372, 5: 0.0268, 6: 0.0812, 7: 0.1611, 8: 0.1558, 9: 0.0721}\n",
      "chazhi:0.13430000\n",
      "epoch:1   global_step:16400\n",
      "{0: 0.0978, 1: 0.0796, 2: 0.0757, 3: 0.0981, 4: 0.1529, 5: 0.0311, 6: 0.067, 7: 0.1801, 8: 0.1441, 9: 0.0736}\n",
      "chazhi:0.14900000\n",
      "epoch:1   global_step:16600\n",
      "{0: 0.1017, 1: 0.0596, 2: 0.0723, 3: 0.0955, 4: 0.1436, 5: 0.0363, 6: 0.0914, 7: 0.1661, 8: 0.1426, 9: 0.0909}\n",
      "chazhi:0.12980000\n",
      "epoch:1   global_step:16800\n",
      "{0: 0.11, 1: 0.0932, 2: 0.0649, 3: 0.0803, 4: 0.1597, 5: 0.0252, 6: 0.0888, 7: 0.1482, 8: 0.1425, 9: 0.0872}\n",
      "chazhi:0.13450000\n",
      "epoch:1   global_step:17000\n",
      "{0: 0.146, 1: 0.1013, 2: 0.0651, 3: 0.0644, 4: 0.1687, 5: 0.016, 6: 0.081, 7: 0.1437, 8: 0.1314, 9: 0.0824}\n",
      "chazhi:0.15270000\n",
      "epoch:1   global_step:17200\n",
      "{0: 0.1412, 1: 0.0832, 2: 0.0647, 3: 0.0931, 4: 0.1503, 5: 0.0293, 6: 0.066, 7: 0.161, 8: 0.1266, 9: 0.0846}\n",
      "chazhi:0.13170000\n",
      "epoch:1   global_step:17400\n",
      "{0: 0.1244, 1: 0.0802, 2: 0.0771, 3: 0.0868, 4: 0.1335, 5: 0.028, 6: 0.0704, 7: 0.1475, 8: 0.1509, 9: 0.1012}\n",
      "chazhi:0.12290000\n",
      "epoch:1   global_step:17600\n",
      "{0: 0.1192, 1: 0.0924, 2: 0.0952, 3: 0.0828, 4: 0.1604, 5: 0.0281, 6: 0.0627, 7: 0.1352, 8: 0.1441, 9: 0.0799}\n",
      "chazhi:0.13230000\n",
      "epoch:1   global_step:17800\n",
      "{0: 0.1086, 1: 0.1088, 2: 0.0723, 3: 0.1017, 4: 0.1463, 5: 0.0371, 6: 0.0627, 7: 0.1743, 8: 0.1202, 9: 0.068}\n",
      "chazhi:0.13720000\n",
      "epoch:1   global_step:18000\n",
      "{0: 0.1079, 1: 0.0567, 2: 0.0764, 3: 0.1064, 4: 0.1402, 5: 0.0361, 6: 0.0742, 7: 0.1424, 8: 0.1551, 9: 0.1046}\n",
      "chazhi:0.11900000\n",
      "epoch:1   global_step:18200\n",
      "{0: 0.1109, 1: 0.0759, 2: 0.0737, 3: 0.0957, 4: 0.1433, 5: 0.03, 6: 0.0829, 7: 0.1661, 8: 0.1367, 9: 0.0848}\n",
      "chazhi:0.13610000\n",
      "epoch:1   global_step:18400\n",
      "{0: 0.1134, 1: 0.0779, 2: 0.0827, 3: 0.0978, 4: 0.1564, 5: 0.0249, 6: 0.0676, 7: 0.1653, 8: 0.1201, 9: 0.0939}\n",
      "chazhi:0.14040000\n",
      "epoch:1   global_step:18600\n",
      "{0: 0.1231, 1: 0.1074, 2: 0.0838, 3: 0.0852, 4: 0.1763, 5: 0.0178, 6: 0.0708, 7: 0.1494, 8: 0.1097, 9: 0.0765}\n",
      "chazhi:0.15850000\n",
      "epoch:2   global_step:18800\n",
      "{0: 0.1283, 1: 0.0991, 2: 0.0841, 3: 0.0928, 4: 0.1686, 5: 0.0232, 6: 0.073, 7: 0.1497, 8: 0.1107, 9: 0.0705}\n",
      "chazhi:0.14540000\n",
      "epoch:2   global_step:19000\n",
      "{0: 0.1224, 1: 0.0798, 2: 0.0896, 3: 0.084, 4: 0.1765, 5: 0.0168, 6: 0.0837, 7: 0.1243, 8: 0.1475, 9: 0.0754}\n",
      "chazhi:0.15970000\n",
      "epoch:2   global_step:19200\n",
      "{0: 0.1047, 1: 0.0751, 2: 0.0916, 3: 0.1007, 4: 0.1606, 5: 0.0257, 6: 0.0804, 7: 0.1521, 8: 0.1298, 9: 0.0793}\n",
      "chazhi:0.13490000\n",
      "epoch:2   global_step:19400\n",
      "{0: 0.096, 1: 0.0723, 2: 0.0981, 3: 0.117, 4: 0.1342, 5: 0.0256, 6: 0.0797, 7: 0.1562, 8: 0.1367, 9: 0.0842}\n",
      "chazhi:0.13060000\n",
      "epoch:2   global_step:19600\n",
      "{0: 0.1295, 1: 0.0837, 2: 0.083, 3: 0.0815, 4: 0.1792, 5: 0.0112, 6: 0.0745, 7: 0.1585, 8: 0.1238, 9: 0.0751}\n",
      "chazhi:0.16800000\n",
      "epoch:2   global_step:19800\n",
      "{0: 0.1489, 1: 0.1078, 2: 0.0642, 3: 0.0677, 4: 0.1734, 5: 0.0125, 6: 0.086, 7: 0.1413, 8: 0.1191, 9: 0.0791}\n",
      "chazhi:0.16090000\n",
      "epoch:2   global_step:20000\n",
      "{0: 0.1271, 1: 0.1053, 2: 0.0597, 3: 0.0851, 4: 0.1522, 5: 0.0179, 6: 0.084, 7: 0.1455, 8: 0.1361, 9: 0.0871}\n",
      "chazhi:0.13430000\n",
      "epoch:2   global_step:20200\n",
      "{0: 0.105, 1: 0.1068, 2: 0.0781, 3: 0.0908, 4: 0.1605, 5: 0.0197, 6: 0.077, 7: 0.1629, 8: 0.1277, 9: 0.0715}\n",
      "chazhi:0.14320000\n",
      "epoch:2   global_step:20400\n",
      "{0: 0.1216, 1: 0.0749, 2: 0.0783, 3: 0.0988, 4: 0.1237, 5: 0.0238, 6: 0.0864, 7: 0.1616, 8: 0.1428, 9: 0.0881}\n",
      "chazhi:0.13780000\n",
      "epoch:2   global_step:20600\n",
      "{0: 0.106, 1: 0.1025, 2: 0.0755, 3: 0.1013, 4: 0.147, 5: 0.0302, 6: 0.0908, 7: 0.1626, 8: 0.1038, 9: 0.0803}\n",
      "chazhi:0.13240000\n",
      "epoch:2   global_step:20800\n",
      "{0: 0.1194, 1: 0.0948, 2: 0.0827, 3: 0.0817, 4: 0.1667, 5: 0.0301, 6: 0.0896, 7: 0.1408, 8: 0.1281, 9: 0.0661}\n",
      "chazhi:0.13660000\n",
      "epoch:2   global_step:21000\n",
      "{0: 0.1148, 1: 0.077, 2: 0.0797, 3: 0.0926, 4: 0.1525, 5: 0.0288, 6: 0.084, 7: 0.1397, 8: 0.1494, 9: 0.0815}\n",
      "chazhi:0.12370000\n",
      "epoch:2   global_step:21200\n",
      "{0: 0.0843, 1: 0.0867, 2: 0.071, 3: 0.121, 4: 0.13, 5: 0.0304, 6: 0.0864, 7: 0.1567, 8: 0.1305, 9: 0.103}\n",
      "chazhi:0.12630000\n",
      "epoch:2   global_step:21400\n",
      "{0: 0.0992, 1: 0.0983, 2: 0.0752, 3: 0.1116, 4: 0.1327, 5: 0.0297, 6: 0.0818, 7: 0.1793, 8: 0.1184, 9: 0.0738}\n",
      "chazhi:0.14960000\n",
      "epoch:2   global_step:21600\n",
      "{0: 0.1157, 1: 0.0863, 2: 0.0679, 3: 0.0978, 4: 0.1546, 5: 0.0211, 6: 0.0773, 7: 0.1623, 8: 0.1417, 9: 0.0753}\n",
      "chazhi:0.14120000\n",
      "epoch:2   global_step:21800\n",
      "{0: 0.1178, 1: 0.0924, 2: 0.0722, 3: 0.0847, 4: 0.1483, 5: 0.0288, 6: 0.1008, 7: 0.1495, 8: 0.1238, 9: 0.0817}\n",
      "chazhi:0.12070000\n",
      "epoch:2   global_step:22000\n",
      "{0: 0.1071, 1: 0.0789, 2: 0.0804, 3: 0.1051, 4: 0.1386, 5: 0.0321, 6: 0.0913, 7: 0.1414, 8: 0.1322, 9: 0.0929}\n",
      "chazhi:0.10930000\n",
      "epoch:2   global_step:22200\n",
      "{0: 0.1187, 1: 0.101, 2: 0.0809, 3: 0.1103, 4: 0.1326, 5: 0.0277, 6: 0.0784, 7: 0.1503, 8: 0.1104, 9: 0.0897}\n",
      "chazhi:0.12260000\n",
      "epoch:2   global_step:22400\n",
      "{0: 0.1339, 1: 0.0924, 2: 0.0835, 3: 0.0705, 4: 0.1672, 5: 0.0177, 6: 0.0869, 7: 0.1373, 8: 0.132, 9: 0.0786}\n",
      "chazhi:0.14950000\n",
      "epoch:2   global_step:22600\n",
      "{0: 0.1167, 1: 0.0822, 2: 0.067, 3: 0.093, 4: 0.1537, 5: 0.0288, 6: 0.0894, 7: 0.158, 8: 0.1276, 9: 0.0836}\n",
      "chazhi:0.12920000\n",
      "epoch:2   global_step:22800\n",
      "{0: 0.1012, 1: 0.0832, 2: 0.0679, 3: 0.1185, 4: 0.1283, 5: 0.0382, 6: 0.0746, 7: 0.1662, 8: 0.1427, 9: 0.0792}\n",
      "chazhi:0.12800000\n",
      "epoch:2   global_step:23000\n",
      "{0: 0.1034, 1: 0.0919, 2: 0.0742, 3: 0.0912, 4: 0.1324, 5: 0.0315, 6: 0.0959, 7: 0.1589, 8: 0.1374, 9: 0.0832}\n",
      "chazhi:0.12740000\n",
      "epoch:2   global_step:23200\n",
      "{0: 0.1127, 1: 0.0827, 2: 0.0808, 3: 0.0797, 4: 0.129, 5: 0.02, 6: 0.0932, 7: 0.149, 8: 0.1551, 9: 0.0978}\n",
      "chazhi:0.13510000\n",
      "epoch:2   global_step:23400\n",
      "{0: 0.1355, 1: 0.1202, 2: 0.0768, 3: 0.0627, 4: 0.1642, 5: 0.0173, 6: 0.0832, 7: 0.1711, 8: 0.1034, 9: 0.0656}\n",
      "chazhi:0.15380000\n",
      "epoch:2   global_step:23600\n",
      "{0: 0.1174, 1: 0.1127, 2: 0.0781, 3: 0.0772, 4: 0.1574, 5: 0.0262, 6: 0.0909, 7: 0.1475, 8: 0.1234, 9: 0.0692}\n",
      "chazhi:0.13120000\n",
      "epoch:2   global_step:23800\n",
      "{0: 0.1031, 1: 0.0817, 2: 0.0686, 3: 0.0894, 4: 0.1503, 5: 0.043, 6: 0.0965, 7: 0.1411, 8: 0.1295, 9: 0.0968}\n",
      "chazhi:0.10730000\n",
      "epoch:2   global_step:24000\n",
      "{0: 0.1031, 1: 0.1015, 2: 0.0886, 3: 0.096, 4: 0.1536, 5: 0.034, 6: 0.0863, 7: 0.1541, 8: 0.1185, 9: 0.0643}\n",
      "chazhi:0.12010000\n",
      "epoch:2   global_step:24200\n",
      "{0: 0.1008, 1: 0.0863, 2: 0.081, 3: 0.0831, 4: 0.164, 5: 0.0258, 6: 0.0881, 7: 0.1599, 8: 0.1327, 9: 0.0783}\n",
      "chazhi:0.13820000\n",
      "epoch:2   global_step:24400\n",
      "{0: 0.1132, 1: 0.0785, 2: 0.0882, 3: 0.095, 4: 0.1467, 5: 0.038, 6: 0.0811, 7: 0.1538, 8: 0.143, 9: 0.0625}\n",
      "chazhi:0.11580000\n",
      "epoch:2   global_step:24600\n",
      "{0: 0.1187, 1: 0.0805, 2: 0.0678, 3: 0.0764, 4: 0.1642, 5: 0.0169, 6: 0.0965, 7: 0.1175, 8: 0.1592, 9: 0.1023}\n",
      "chazhi:0.14730000\n",
      "epoch:2   global_step:24800\n",
      "{0: 0.1249, 1: 0.0915, 2: 0.0872, 3: 0.0903, 4: 0.1471, 5: 0.0236, 6: 0.0892, 7: 0.131, 8: 0.1326, 9: 0.0826}\n",
      "chazhi:0.12350000\n",
      "epoch:2   global_step:25000\n",
      "{0: 0.105, 1: 0.1104, 2: 0.0871, 3: 0.0873, 4: 0.172, 5: 0.0208, 6: 0.0815, 7: 0.1644, 8: 0.1051, 9: 0.0664}\n",
      "chazhi:0.15120000\n",
      "epoch:2   global_step:25200\n",
      "{0: 0.1239, 1: 0.0952, 2: 0.0916, 3: 0.0826, 4: 0.1705, 5: 0.0331, 6: 0.0902, 7: 0.1436, 8: 0.1069, 9: 0.0624}\n",
      "chazhi:0.13740000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-38e66fd90204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mwgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGANGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-38e66fd90204>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# If at save interval => save generated image samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                     \u001b[0mlabel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                     \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-38e66fd90204>\u001b[0m in \u001b[0;36mmode_drop\u001b[0;34m(self, epoch, global_step)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# Rescale images 0 - 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgen_imgs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mlabel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fad461489524>\u001b[0m in \u001b[0;36mcalculate_labels\u001b[0;34m(images, epoch, global_step)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0my_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMNIST_CLASSIFIER_FROZEN_GRAPH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINPUT_TENSOR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_TENSOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_logit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlabel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Large amount of credit goes to:\n",
    "# https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
    "# which I've used as a reference for this implementation\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from functools import partial\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((32, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "class WGANGP():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build the generator and critic\n",
    "        self.generator = self.build_generator()\n",
    "        self.critic = self.build_critic()\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        # Generate image based of noise (fake sample)\n",
    "        fake_img = self.generator(z_disc)\n",
    "\n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.critic(fake_img)\n",
    "        valid = self.critic(real_img)\n",
    "\n",
    "        # Construct weighted average between real and fake images\n",
    "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(interpolated_img)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, z_disc],\n",
    "                            outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                              self.wasserstein_loss,\n",
    "                                              partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(100,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator(z_gen)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(z_gen, valid)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake =  np.ones((batch_size, 1))\n",
    "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps=[]\n",
    "        values=[]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                for _ in range(self.n_critic):\n",
    "                    global_step += 1\n",
    "                    imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                    # Sample generator input\n",
    "                    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                    # Train the critic\n",
    "                    d_loss = self.critic_model.train_on_batch([imgs, noise],\n",
    "                                                              [valid, fake, dummy])\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Generator\n",
    "                    # ---------------------\n",
    "\n",
    "                g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "#                 print(\"epoch%d step%d [D loss: %f] [G loss: %f]\" % (epoch,global_step, d_loss[0], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    label_dict,value=self.mode_drop(epoch,global_step)\n",
    "                    steps.append(global_step)\n",
    "                    values.append(value)\n",
    "#             plt.subplots(1, 1)\n",
    "        plt.plot(steps,values)\n",
    "        plt.xlim([0,40000])\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.xlabel('steps')\n",
    "        plt.ylabel('epochs')\n",
    "        plt.tick_params(axis='both',which='major',labelsize=13)\n",
    "        plt.legend(loc='lower right')\n",
    "        if not os.path.isdir('images_wgan'):\n",
    "            os.mkdir('images_wgan')\n",
    "        plt.savefig(\"images_wgan/mode_drop.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch,global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_wgan'):\n",
    "            os.mkdir('images_wgan')\n",
    "        fig.savefig(\"images_wgan/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "        plt.close()\n",
    "    def mode_drop(self,epoch,global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        label_dict,value=calculate_labels(gen_imgs,epoch,global_step)\n",
    "        return label_dict,value\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGANGP()\n",
    "    wgan.train(epochs=20, batch_size=32, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
