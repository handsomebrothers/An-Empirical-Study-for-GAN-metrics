{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f7e243c6278>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# #指定使用那块GUP训练\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.ConfigProto()\n",
    "# 设置最大占有GPU不超过显存的70%\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 \n",
    "# # 重点：设置动态分配GPU\n",
    "config.gpu_options.allow_growth = True\n",
    "# 创建session时\n",
    "tf.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (16): ReLU()\n",
      "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (19): ReLU()\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (23): ReLU()\n",
      "  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "=================================================================\n",
      "Total params: 389,184\n",
      "Trainable params: 388,800\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 3)         1731      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,051,779\n",
      "Trainable params: 1,051,139\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1[D loss: 0.677287, acc: 32.03%, op_acc: 6.25%] [G loss: 0.657322]\n",
      "epoch:0 step:2[D loss: 0.604413, acc: 46.88%, op_acc: 8.59%] [G loss: 0.685917]\n",
      "epoch:0 step:3[D loss: 0.582296, acc: 56.25%, op_acc: 5.47%] [G loss: 0.801060]\n",
      "epoch:0 step:4[D loss: 0.566151, acc: 55.47%, op_acc: 11.72%] [G loss: 0.823084]\n",
      "epoch:0 step:5[D loss: 0.545274, acc: 63.28%, op_acc: 13.28%] [G loss: 0.849048]\n",
      "epoch:0 step:6[D loss: 0.578087, acc: 51.56%, op_acc: 10.94%] [G loss: 0.795171]\n",
      "epoch:0 step:7[D loss: 0.546784, acc: 56.25%, op_acc: 12.50%] [G loss: 0.825469]\n",
      "epoch:0 step:8[D loss: 0.548622, acc: 65.62%, op_acc: 7.03%] [G loss: 0.844846]\n",
      "epoch:0 step:9[D loss: 0.537477, acc: 58.59%, op_acc: 10.94%] [G loss: 1.012536]\n",
      "epoch:0 step:10[D loss: 0.502473, acc: 67.97%, op_acc: 14.06%] [G loss: 0.974035]\n",
      "epoch:0 step:11[D loss: 0.522098, acc: 66.41%, op_acc: 14.84%] [G loss: 0.908690]\n",
      "epoch:0 step:12[D loss: 0.515360, acc: 65.62%, op_acc: 12.50%] [G loss: 0.949969]\n",
      "epoch:0 step:13[D loss: 0.507906, acc: 71.09%, op_acc: 17.97%] [G loss: 0.949501]\n",
      "epoch:0 step:14[D loss: 0.553812, acc: 59.38%, op_acc: 9.38%] [G loss: 1.021488]\n",
      "epoch:0 step:15[D loss: 0.514399, acc: 70.31%, op_acc: 14.06%] [G loss: 0.968276]\n",
      "epoch:0 step:16[D loss: 0.515969, acc: 61.72%, op_acc: 7.81%] [G loss: 1.040516]\n",
      "epoch:0 step:17[D loss: 0.521180, acc: 61.72%, op_acc: 19.53%] [G loss: 1.001255]\n",
      "epoch:0 step:18[D loss: 0.489801, acc: 68.75%, op_acc: 12.50%] [G loss: 1.003772]\n",
      "epoch:0 step:19[D loss: 0.512554, acc: 68.75%, op_acc: 13.28%] [G loss: 1.135742]\n",
      "epoch:0 step:20[D loss: 0.462925, acc: 75.78%, op_acc: 22.66%] [G loss: 1.230594]\n",
      "epoch:0 step:21[D loss: 0.458186, acc: 77.34%, op_acc: 21.88%] [G loss: 1.123827]\n",
      "epoch:0 step:22[D loss: 0.462901, acc: 70.31%, op_acc: 14.84%] [G loss: 1.229816]\n",
      "epoch:0 step:23[D loss: 0.468443, acc: 70.31%, op_acc: 17.19%] [G loss: 1.314930]\n",
      "epoch:0 step:24[D loss: 0.439870, acc: 73.44%, op_acc: 18.75%] [G loss: 1.281559]\n",
      "epoch:0 step:25[D loss: 0.465870, acc: 71.09%, op_acc: 23.44%] [G loss: 1.314534]\n",
      "epoch:0 step:26[D loss: 0.424606, acc: 82.81%, op_acc: 16.41%] [G loss: 1.260552]\n",
      "epoch:0 step:27[D loss: 0.423788, acc: 81.25%, op_acc: 20.31%] [G loss: 1.416773]\n",
      "epoch:0 step:28[D loss: 0.424554, acc: 84.38%, op_acc: 17.97%] [G loss: 1.438712]\n",
      "epoch:0 step:29[D loss: 0.431065, acc: 76.56%, op_acc: 21.09%] [G loss: 1.323003]\n",
      "epoch:0 step:30[D loss: 0.489202, acc: 71.88%, op_acc: 19.53%] [G loss: 1.255084]\n",
      "epoch:0 step:31[D loss: 0.420583, acc: 77.34%, op_acc: 15.62%] [G loss: 1.290542]\n",
      "epoch:0 step:32[D loss: 0.436267, acc: 76.56%, op_acc: 18.75%] [G loss: 1.419664]\n",
      "epoch:0 step:33[D loss: 0.470460, acc: 72.66%, op_acc: 20.31%] [G loss: 1.204687]\n",
      "epoch:0 step:34[D loss: 0.420687, acc: 74.22%, op_acc: 25.78%] [G loss: 1.358015]\n",
      "epoch:0 step:35[D loss: 0.413808, acc: 82.03%, op_acc: 21.09%] [G loss: 1.290243]\n",
      "epoch:0 step:36[D loss: 0.493629, acc: 66.41%, op_acc: 14.84%] [G loss: 1.236862]\n",
      "epoch:0 step:37[D loss: 0.447929, acc: 77.34%, op_acc: 20.31%] [G loss: 1.469567]\n",
      "epoch:0 step:38[D loss: 0.429191, acc: 73.44%, op_acc: 22.66%] [G loss: 1.336527]\n",
      "epoch:0 step:39[D loss: 0.466024, acc: 75.00%, op_acc: 17.97%] [G loss: 1.340182]\n",
      "epoch:0 step:40[D loss: 0.509282, acc: 66.41%, op_acc: 17.19%] [G loss: 1.222372]\n",
      "epoch:0 step:41[D loss: 0.486191, acc: 70.31%, op_acc: 17.19%] [G loss: 1.228102]\n",
      "epoch:0 step:42[D loss: 0.473260, acc: 75.78%, op_acc: 16.41%] [G loss: 1.340868]\n",
      "epoch:0 step:43[D loss: 0.459808, acc: 73.44%, op_acc: 12.50%] [G loss: 1.141940]\n",
      "epoch:0 step:44[D loss: 0.464200, acc: 70.31%, op_acc: 17.97%] [G loss: 1.176104]\n",
      "epoch:0 step:45[D loss: 0.519118, acc: 65.62%, op_acc: 17.97%] [G loss: 1.159438]\n",
      "epoch:0 step:46[D loss: 0.462926, acc: 73.44%, op_acc: 15.62%] [G loss: 1.366556]\n",
      "epoch:0 step:47[D loss: 0.461757, acc: 71.09%, op_acc: 15.62%] [G loss: 1.584092]\n",
      "epoch:0 step:48[D loss: 0.469262, acc: 68.75%, op_acc: 20.31%] [G loss: 1.348508]\n",
      "epoch:0 step:49[D loss: 0.510773, acc: 64.84%, op_acc: 21.09%] [G loss: 1.217646]\n",
      "epoch:0 step:50[D loss: 0.474865, acc: 73.44%, op_acc: 14.84%] [G loss: 1.248134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:57: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:86: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.84825758 0.90148818 0.82787853 0.86352314 0.81594814 0.82457266\n",
      " 0.83273167 0.84021078 0.82932369 0.82418251]\n",
      "##########\n",
      "epoch:0 step:51[D loss: 0.445969, acc: 71.88%, op_acc: 14.84%] [G loss: 1.454506]\n",
      "epoch:0 step:52[D loss: 0.532576, acc: 60.94%, op_acc: 19.53%] [G loss: 1.365644]\n",
      "epoch:0 step:53[D loss: 0.479777, acc: 68.75%, op_acc: 19.53%] [G loss: 1.265031]\n",
      "epoch:0 step:54[D loss: 0.492475, acc: 71.09%, op_acc: 16.41%] [G loss: 1.048065]\n",
      "epoch:0 step:55[D loss: 0.494374, acc: 67.19%, op_acc: 17.97%] [G loss: 1.254624]\n",
      "epoch:0 step:56[D loss: 0.415771, acc: 78.91%, op_acc: 21.88%] [G loss: 1.398268]\n",
      "epoch:0 step:57[D loss: 0.480202, acc: 67.97%, op_acc: 22.66%] [G loss: 1.491378]\n",
      "epoch:0 step:58[D loss: 0.523743, acc: 54.69%, op_acc: 23.44%] [G loss: 1.427967]\n",
      "epoch:0 step:59[D loss: 0.467603, acc: 67.19%, op_acc: 20.31%] [G loss: 1.495003]\n",
      "epoch:0 step:60[D loss: 0.426216, acc: 76.56%, op_acc: 20.31%] [G loss: 1.531954]\n",
      "epoch:0 step:61[D loss: 0.469731, acc: 76.56%, op_acc: 22.66%] [G loss: 1.426720]\n",
      "epoch:0 step:62[D loss: 0.425236, acc: 80.47%, op_acc: 18.75%] [G loss: 1.565577]\n",
      "epoch:0 step:63[D loss: 0.449368, acc: 75.00%, op_acc: 21.09%] [G loss: 1.464330]\n",
      "epoch:0 step:64[D loss: 0.487750, acc: 68.75%, op_acc: 28.91%] [G loss: 1.297194]\n",
      "epoch:0 step:65[D loss: 0.427489, acc: 75.00%, op_acc: 27.34%] [G loss: 1.196394]\n",
      "epoch:0 step:66[D loss: 0.401755, acc: 81.25%, op_acc: 30.47%] [G loss: 1.215085]\n",
      "epoch:0 step:67[D loss: 0.430073, acc: 74.22%, op_acc: 25.78%] [G loss: 1.279392]\n",
      "epoch:0 step:68[D loss: 0.426639, acc: 77.34%, op_acc: 21.88%] [G loss: 1.183524]\n",
      "epoch:0 step:69[D loss: 0.467196, acc: 71.09%, op_acc: 28.91%] [G loss: 1.215296]\n",
      "epoch:0 step:70[D loss: 0.422633, acc: 80.47%, op_acc: 26.56%] [G loss: 1.255558]\n",
      "epoch:0 step:71[D loss: 0.543529, acc: 57.81%, op_acc: 20.31%] [G loss: 1.082558]\n",
      "epoch:0 step:72[D loss: 0.446922, acc: 71.09%, op_acc: 20.31%] [G loss: 1.237250]\n",
      "epoch:0 step:73[D loss: 0.482293, acc: 65.62%, op_acc: 20.31%] [G loss: 1.215571]\n",
      "epoch:0 step:74[D loss: 0.441283, acc: 73.44%, op_acc: 26.56%] [G loss: 1.430378]\n",
      "epoch:0 step:75[D loss: 0.441592, acc: 68.75%, op_acc: 22.66%] [G loss: 1.311329]\n",
      "epoch:0 step:76[D loss: 0.506668, acc: 67.19%, op_acc: 24.22%] [G loss: 1.308091]\n",
      "epoch:0 step:77[D loss: 0.464865, acc: 68.75%, op_acc: 26.56%] [G loss: 1.384779]\n",
      "epoch:0 step:78[D loss: 0.467907, acc: 71.09%, op_acc: 20.31%] [G loss: 1.318068]\n",
      "epoch:0 step:79[D loss: 0.449857, acc: 68.75%, op_acc: 23.44%] [G loss: 1.427911]\n",
      "epoch:0 step:80[D loss: 0.455718, acc: 75.78%, op_acc: 15.62%] [G loss: 1.417438]\n",
      "epoch:0 step:81[D loss: 0.490308, acc: 66.41%, op_acc: 17.19%] [G loss: 1.241483]\n",
      "epoch:0 step:82[D loss: 0.457721, acc: 75.00%, op_acc: 20.31%] [G loss: 1.325506]\n",
      "epoch:0 step:83[D loss: 0.499909, acc: 63.28%, op_acc: 25.78%] [G loss: 1.425366]\n",
      "epoch:0 step:84[D loss: 0.470406, acc: 71.88%, op_acc: 18.75%] [G loss: 1.445560]\n",
      "epoch:0 step:85[D loss: 0.537561, acc: 60.16%, op_acc: 21.09%] [G loss: 1.446769]\n",
      "epoch:0 step:86[D loss: 0.449530, acc: 75.78%, op_acc: 21.09%] [G loss: 1.301774]\n",
      "epoch:0 step:87[D loss: 0.438416, acc: 75.78%, op_acc: 19.53%] [G loss: 1.612470]\n",
      "epoch:0 step:88[D loss: 0.427861, acc: 75.00%, op_acc: 28.12%] [G loss: 1.519529]\n",
      "epoch:0 step:89[D loss: 0.398134, acc: 85.94%, op_acc: 22.66%] [G loss: 1.450542]\n",
      "epoch:0 step:90[D loss: 0.449870, acc: 70.31%, op_acc: 15.62%] [G loss: 1.332184]\n",
      "epoch:0 step:91[D loss: 0.493974, acc: 67.97%, op_acc: 21.88%] [G loss: 1.323943]\n",
      "epoch:0 step:92[D loss: 0.418176, acc: 83.59%, op_acc: 24.22%] [G loss: 1.571795]\n",
      "epoch:0 step:93[D loss: 0.423541, acc: 77.34%, op_acc: 24.22%] [G loss: 1.657063]\n",
      "epoch:0 step:94[D loss: 0.432064, acc: 74.22%, op_acc: 21.09%] [G loss: 1.316334]\n",
      "epoch:0 step:95[D loss: 0.408130, acc: 82.03%, op_acc: 23.44%] [G loss: 1.412556]\n",
      "epoch:0 step:96[D loss: 0.445660, acc: 76.56%, op_acc: 24.22%] [G loss: 1.603836]\n",
      "epoch:0 step:97[D loss: 0.399853, acc: 77.34%, op_acc: 26.56%] [G loss: 1.471996]\n",
      "epoch:0 step:98[D loss: 0.435062, acc: 75.78%, op_acc: 22.66%] [G loss: 1.433580]\n",
      "epoch:0 step:99[D loss: 0.464238, acc: 67.97%, op_acc: 20.31%] [G loss: 1.279270]\n",
      "epoch:0 step:100[D loss: 0.426051, acc: 75.00%, op_acc: 21.88%] [G loss: 1.318960]\n",
      "##############\n",
      "[0.86433888 0.89872914 0.82630487 0.84744537 0.81253147 0.83609135\n",
      " 0.86420216 0.84992184 0.82735268 0.83412277]\n",
      "##########\n",
      "epoch:0 step:101[D loss: 0.395271, acc: 82.81%, op_acc: 26.56%] [G loss: 1.524921]\n",
      "epoch:0 step:102[D loss: 0.476794, acc: 63.28%, op_acc: 28.12%] [G loss: 1.444422]\n",
      "epoch:0 step:103[D loss: 0.466702, acc: 70.31%, op_acc: 20.31%] [G loss: 1.346810]\n",
      "epoch:0 step:104[D loss: 0.498847, acc: 64.84%, op_acc: 22.66%] [G loss: 1.204847]\n",
      "epoch:0 step:105[D loss: 0.502430, acc: 65.62%, op_acc: 19.53%] [G loss: 1.358490]\n",
      "epoch:0 step:106[D loss: 0.438961, acc: 71.88%, op_acc: 19.53%] [G loss: 1.521821]\n",
      "epoch:0 step:107[D loss: 0.440827, acc: 71.09%, op_acc: 24.22%] [G loss: 1.504368]\n",
      "epoch:0 step:108[D loss: 0.477668, acc: 71.88%, op_acc: 25.00%] [G loss: 1.391293]\n",
      "epoch:0 step:109[D loss: 0.451442, acc: 75.00%, op_acc: 17.97%] [G loss: 1.247945]\n",
      "epoch:0 step:110[D loss: 0.450126, acc: 73.44%, op_acc: 22.66%] [G loss: 1.437465]\n",
      "epoch:0 step:111[D loss: 0.396769, acc: 80.47%, op_acc: 27.34%] [G loss: 1.458869]\n",
      "epoch:0 step:112[D loss: 0.446436, acc: 68.75%, op_acc: 28.12%] [G loss: 1.368698]\n",
      "epoch:0 step:113[D loss: 0.432842, acc: 78.12%, op_acc: 20.31%] [G loss: 1.441738]\n",
      "epoch:0 step:114[D loss: 0.407220, acc: 75.00%, op_acc: 28.12%] [G loss: 1.385219]\n",
      "epoch:0 step:115[D loss: 0.418659, acc: 75.00%, op_acc: 25.78%] [G loss: 1.517085]\n",
      "epoch:0 step:116[D loss: 0.464788, acc: 70.31%, op_acc: 25.78%] [G loss: 1.290236]\n",
      "epoch:0 step:117[D loss: 0.476617, acc: 69.53%, op_acc: 21.88%] [G loss: 1.274162]\n",
      "epoch:0 step:118[D loss: 0.373398, acc: 84.38%, op_acc: 28.91%] [G loss: 1.550746]\n",
      "epoch:0 step:119[D loss: 0.434628, acc: 73.44%, op_acc: 25.00%] [G loss: 1.463556]\n",
      "epoch:0 step:120[D loss: 0.432239, acc: 75.00%, op_acc: 23.44%] [G loss: 1.423268]\n",
      "epoch:0 step:121[D loss: 0.416086, acc: 82.03%, op_acc: 22.66%] [G loss: 1.206452]\n",
      "epoch:0 step:122[D loss: 0.462875, acc: 75.00%, op_acc: 28.91%] [G loss: 1.359481]\n",
      "epoch:0 step:123[D loss: 0.442915, acc: 71.09%, op_acc: 18.75%] [G loss: 1.597382]\n",
      "epoch:0 step:124[D loss: 0.446594, acc: 73.44%, op_acc: 23.44%] [G loss: 1.565878]\n",
      "epoch:0 step:125[D loss: 0.411324, acc: 82.81%, op_acc: 23.44%] [G loss: 1.672204]\n",
      "epoch:0 step:126[D loss: 0.433890, acc: 74.22%, op_acc: 16.41%] [G loss: 1.538730]\n",
      "epoch:0 step:127[D loss: 0.365995, acc: 82.81%, op_acc: 28.91%] [G loss: 1.508160]\n",
      "epoch:0 step:128[D loss: 0.476066, acc: 68.75%, op_acc: 24.22%] [G loss: 1.686189]\n",
      "epoch:0 step:129[D loss: 0.403686, acc: 81.25%, op_acc: 23.44%] [G loss: 1.748776]\n",
      "epoch:0 step:130[D loss: 0.415983, acc: 78.12%, op_acc: 28.91%] [G loss: 1.697390]\n",
      "epoch:0 step:131[D loss: 0.445753, acc: 74.22%, op_acc: 17.19%] [G loss: 1.597299]\n",
      "epoch:0 step:132[D loss: 0.438766, acc: 75.00%, op_acc: 20.31%] [G loss: 1.449618]\n",
      "epoch:0 step:133[D loss: 0.429759, acc: 78.91%, op_acc: 20.31%] [G loss: 1.355891]\n",
      "epoch:0 step:134[D loss: 0.439530, acc: 73.44%, op_acc: 26.56%] [G loss: 1.481398]\n",
      "epoch:0 step:135[D loss: 0.373010, acc: 82.81%, op_acc: 25.00%] [G loss: 1.712706]\n",
      "epoch:0 step:136[D loss: 0.387837, acc: 78.91%, op_acc: 30.47%] [G loss: 1.659389]\n",
      "epoch:0 step:137[D loss: 0.384780, acc: 81.25%, op_acc: 26.56%] [G loss: 1.715120]\n",
      "epoch:0 step:138[D loss: 0.376676, acc: 83.59%, op_acc: 21.88%] [G loss: 1.734889]\n",
      "epoch:0 step:139[D loss: 0.415851, acc: 82.03%, op_acc: 24.22%] [G loss: 1.564357]\n",
      "epoch:0 step:140[D loss: 0.413637, acc: 76.56%, op_acc: 25.00%] [G loss: 1.435386]\n",
      "epoch:0 step:141[D loss: 0.453395, acc: 75.78%, op_acc: 16.41%] [G loss: 1.622125]\n",
      "epoch:0 step:142[D loss: 0.395447, acc: 82.81%, op_acc: 31.25%] [G loss: 1.605422]\n",
      "epoch:0 step:143[D loss: 0.421123, acc: 75.00%, op_acc: 30.47%] [G loss: 1.652025]\n",
      "epoch:0 step:144[D loss: 0.366671, acc: 83.59%, op_acc: 25.78%] [G loss: 1.542586]\n",
      "epoch:0 step:145[D loss: 0.376259, acc: 81.25%, op_acc: 31.25%] [G loss: 1.746046]\n",
      "epoch:0 step:146[D loss: 0.387105, acc: 82.81%, op_acc: 24.22%] [G loss: 1.832717]\n",
      "epoch:0 step:147[D loss: 0.373445, acc: 80.47%, op_acc: 28.91%] [G loss: 1.701924]\n",
      "epoch:0 step:148[D loss: 0.415704, acc: 79.69%, op_acc: 33.59%] [G loss: 1.949244]\n",
      "epoch:0 step:149[D loss: 0.347393, acc: 83.59%, op_acc: 35.94%] [G loss: 1.731637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:150[D loss: 0.369032, acc: 84.38%, op_acc: 29.69%] [G loss: 1.842093]\n",
      "##############\n",
      "[0.86953477 0.89205823 0.85718869 0.84218613 0.82261989 0.84512266\n",
      " 0.86648466 0.85781509 0.8062859  0.85612474]\n",
      "##########\n",
      "epoch:0 step:151[D loss: 0.314590, acc: 89.84%, op_acc: 29.69%] [G loss: 2.156389]\n",
      "epoch:0 step:152[D loss: 0.377705, acc: 85.94%, op_acc: 28.91%] [G loss: 2.040085]\n",
      "epoch:0 step:153[D loss: 0.354214, acc: 86.72%, op_acc: 29.69%] [G loss: 2.103373]\n",
      "epoch:0 step:154[D loss: 0.344974, acc: 82.81%, op_acc: 37.50%] [G loss: 1.958428]\n",
      "epoch:0 step:155[D loss: 0.422123, acc: 75.78%, op_acc: 35.16%] [G loss: 1.739258]\n",
      "epoch:0 step:156[D loss: 0.350748, acc: 86.72%, op_acc: 35.16%] [G loss: 2.092850]\n",
      "epoch:0 step:157[D loss: 0.359284, acc: 85.16%, op_acc: 26.56%] [G loss: 2.024248]\n",
      "epoch:0 step:158[D loss: 0.326000, acc: 88.28%, op_acc: 38.28%] [G loss: 2.069980]\n",
      "epoch:0 step:159[D loss: 0.314863, acc: 89.84%, op_acc: 44.53%] [G loss: 2.028647]\n",
      "epoch:0 step:160[D loss: 0.315826, acc: 92.97%, op_acc: 32.03%] [G loss: 2.019866]\n",
      "epoch:0 step:161[D loss: 0.342495, acc: 85.94%, op_acc: 35.94%] [G loss: 2.031058]\n",
      "epoch:0 step:162[D loss: 0.317051, acc: 92.19%, op_acc: 41.41%] [G loss: 2.099417]\n",
      "epoch:0 step:163[D loss: 0.320667, acc: 89.06%, op_acc: 35.16%] [G loss: 2.101448]\n",
      "epoch:0 step:164[D loss: 0.350271, acc: 85.94%, op_acc: 33.59%] [G loss: 2.214620]\n",
      "epoch:0 step:165[D loss: 0.299047, acc: 92.19%, op_acc: 38.28%] [G loss: 2.175303]\n",
      "epoch:0 step:166[D loss: 0.301089, acc: 93.75%, op_acc: 40.62%] [G loss: 2.592469]\n",
      "epoch:0 step:167[D loss: 0.347934, acc: 88.28%, op_acc: 31.25%] [G loss: 2.506307]\n",
      "epoch:0 step:168[D loss: 0.267145, acc: 94.53%, op_acc: 42.19%] [G loss: 2.263319]\n",
      "epoch:0 step:169[D loss: 0.278751, acc: 91.41%, op_acc: 46.09%] [G loss: 2.427293]\n",
      "epoch:0 step:170[D loss: 0.290796, acc: 92.19%, op_acc: 35.16%] [G loss: 2.359187]\n",
      "epoch:0 step:171[D loss: 0.289968, acc: 93.75%, op_acc: 38.28%] [G loss: 2.159284]\n",
      "epoch:0 step:172[D loss: 0.279048, acc: 92.19%, op_acc: 39.06%] [G loss: 2.119570]\n",
      "epoch:0 step:173[D loss: 0.289244, acc: 89.84%, op_acc: 46.88%] [G loss: 2.409993]\n",
      "epoch:0 step:174[D loss: 0.309218, acc: 92.19%, op_acc: 45.31%] [G loss: 2.375042]\n",
      "epoch:0 step:175[D loss: 0.313715, acc: 89.06%, op_acc: 41.41%] [G loss: 2.282562]\n",
      "epoch:0 step:176[D loss: 0.282196, acc: 93.75%, op_acc: 39.84%] [G loss: 2.308893]\n",
      "epoch:0 step:177[D loss: 0.281047, acc: 90.62%, op_acc: 46.09%] [G loss: 2.594894]\n",
      "epoch:0 step:178[D loss: 0.327957, acc: 89.06%, op_acc: 38.28%] [G loss: 2.055042]\n",
      "epoch:0 step:179[D loss: 0.324219, acc: 89.84%, op_acc: 44.53%] [G loss: 2.153528]\n",
      "epoch:0 step:180[D loss: 0.337955, acc: 89.84%, op_acc: 35.16%] [G loss: 2.145730]\n",
      "epoch:0 step:181[D loss: 0.311130, acc: 89.06%, op_acc: 45.31%] [G loss: 2.096440]\n",
      "epoch:0 step:182[D loss: 0.370968, acc: 81.25%, op_acc: 39.84%] [G loss: 2.165530]\n",
      "epoch:0 step:183[D loss: 0.350011, acc: 86.72%, op_acc: 36.72%] [G loss: 2.455851]\n",
      "epoch:0 step:184[D loss: 0.304197, acc: 90.62%, op_acc: 49.22%] [G loss: 2.404859]\n",
      "epoch:0 step:185[D loss: 0.325018, acc: 86.72%, op_acc: 38.28%] [G loss: 2.216891]\n",
      "epoch:0 step:186[D loss: 0.318344, acc: 87.50%, op_acc: 39.84%] [G loss: 2.391229]\n",
      "epoch:0 step:187[D loss: 0.346791, acc: 87.50%, op_acc: 40.62%] [G loss: 2.532035]\n",
      "epoch:0 step:188[D loss: 0.299323, acc: 88.28%, op_acc: 46.09%] [G loss: 2.510548]\n",
      "epoch:0 step:189[D loss: 0.298700, acc: 90.62%, op_acc: 48.44%] [G loss: 2.326732]\n",
      "epoch:0 step:190[D loss: 0.305536, acc: 91.41%, op_acc: 37.50%] [G loss: 2.139904]\n",
      "epoch:0 step:191[D loss: 0.282581, acc: 89.06%, op_acc: 51.56%] [G loss: 2.166648]\n",
      "epoch:0 step:192[D loss: 0.394347, acc: 82.03%, op_acc: 30.47%] [G loss: 1.751683]\n",
      "epoch:0 step:193[D loss: 0.312262, acc: 91.41%, op_acc: 37.50%] [G loss: 1.938063]\n",
      "epoch:0 step:194[D loss: 0.351066, acc: 85.94%, op_acc: 45.31%] [G loss: 2.060090]\n",
      "epoch:0 step:195[D loss: 0.345596, acc: 84.38%, op_acc: 43.75%] [G loss: 2.322372]\n",
      "epoch:0 step:196[D loss: 0.328676, acc: 86.72%, op_acc: 39.84%] [G loss: 2.258180]\n",
      "epoch:0 step:197[D loss: 0.313846, acc: 87.50%, op_acc: 38.28%] [G loss: 2.290330]\n",
      "epoch:0 step:198[D loss: 0.386679, acc: 78.91%, op_acc: 31.25%] [G loss: 2.316464]\n",
      "epoch:0 step:199[D loss: 0.409460, acc: 78.12%, op_acc: 28.12%] [G loss: 1.435335]\n",
      "epoch:0 step:200[D loss: 0.414853, acc: 77.34%, op_acc: 35.16%] [G loss: 1.593017]\n",
      "##############\n",
      "[0.86517958 0.90086341 0.81012851 0.82876009 0.79489499 0.8378734\n",
      " 0.87731194 0.80578403 0.82863172 0.83594135]\n",
      "##########\n",
      "epoch:0 step:201[D loss: 0.465085, acc: 67.97%, op_acc: 28.12%] [G loss: 1.687252]\n",
      "epoch:0 step:202[D loss: 0.408342, acc: 76.56%, op_acc: 35.94%] [G loss: 1.803274]\n",
      "epoch:0 step:203[D loss: 0.515786, acc: 68.75%, op_acc: 25.78%] [G loss: 1.597332]\n",
      "epoch:0 step:204[D loss: 0.366837, acc: 81.25%, op_acc: 35.16%] [G loss: 2.056086]\n",
      "epoch:0 step:205[D loss: 0.401080, acc: 78.91%, op_acc: 36.72%] [G loss: 2.542495]\n",
      "epoch:0 step:206[D loss: 0.523268, acc: 64.06%, op_acc: 33.59%] [G loss: 1.649036]\n",
      "epoch:0 step:207[D loss: 0.407160, acc: 78.12%, op_acc: 37.50%] [G loss: 1.562055]\n",
      "epoch:0 step:208[D loss: 0.462955, acc: 69.53%, op_acc: 34.38%] [G loss: 1.724265]\n",
      "epoch:0 step:209[D loss: 0.450578, acc: 69.53%, op_acc: 24.22%] [G loss: 1.603817]\n",
      "epoch:0 step:210[D loss: 0.442369, acc: 76.56%, op_acc: 30.47%] [G loss: 1.574406]\n",
      "epoch:0 step:211[D loss: 0.534682, acc: 67.97%, op_acc: 28.91%] [G loss: 1.410328]\n",
      "epoch:0 step:212[D loss: 0.447121, acc: 71.88%, op_acc: 28.12%] [G loss: 1.811922]\n",
      "epoch:0 step:213[D loss: 0.445005, acc: 74.22%, op_acc: 27.34%] [G loss: 1.583097]\n",
      "epoch:0 step:214[D loss: 0.475016, acc: 67.19%, op_acc: 21.09%] [G loss: 1.766838]\n",
      "epoch:0 step:215[D loss: 0.678216, acc: 52.34%, op_acc: 21.88%] [G loss: 1.520034]\n",
      "epoch:0 step:216[D loss: 0.543575, acc: 61.72%, op_acc: 22.66%] [G loss: 1.583190]\n",
      "epoch:0 step:217[D loss: 0.573488, acc: 60.94%, op_acc: 35.16%] [G loss: 1.888981]\n",
      "epoch:0 step:218[D loss: 0.596895, acc: 53.91%, op_acc: 24.22%] [G loss: 1.458289]\n",
      "epoch:0 step:219[D loss: 0.594817, acc: 54.69%, op_acc: 20.31%] [G loss: 1.335609]\n",
      "epoch:0 step:220[D loss: 0.547082, acc: 60.16%, op_acc: 21.09%] [G loss: 1.638883]\n",
      "epoch:0 step:221[D loss: 0.514141, acc: 63.28%, op_acc: 22.66%] [G loss: 1.387173]\n",
      "epoch:0 step:222[D loss: 0.570215, acc: 60.94%, op_acc: 14.84%] [G loss: 1.252615]\n",
      "epoch:0 step:223[D loss: 0.595464, acc: 49.22%, op_acc: 19.53%] [G loss: 1.312705]\n",
      "epoch:0 step:224[D loss: 0.589125, acc: 58.59%, op_acc: 20.31%] [G loss: 1.414321]\n",
      "epoch:0 step:225[D loss: 0.594369, acc: 52.34%, op_acc: 13.28%] [G loss: 1.202184]\n",
      "epoch:0 step:226[D loss: 0.527686, acc: 67.19%, op_acc: 21.88%] [G loss: 1.256431]\n",
      "epoch:0 step:227[D loss: 0.608881, acc: 52.34%, op_acc: 17.19%] [G loss: 1.326283]\n",
      "epoch:0 step:228[D loss: 0.553564, acc: 59.38%, op_acc: 21.09%] [G loss: 1.282855]\n",
      "epoch:0 step:229[D loss: 0.577743, acc: 56.25%, op_acc: 18.75%] [G loss: 1.085608]\n",
      "epoch:0 step:230[D loss: 0.566971, acc: 64.84%, op_acc: 12.50%] [G loss: 1.273313]\n",
      "epoch:0 step:231[D loss: 0.562091, acc: 60.16%, op_acc: 20.31%] [G loss: 1.469288]\n",
      "epoch:0 step:232[D loss: 0.602959, acc: 50.78%, op_acc: 17.19%] [G loss: 1.514322]\n",
      "epoch:0 step:233[D loss: 0.495737, acc: 67.97%, op_acc: 30.47%] [G loss: 1.272053]\n",
      "epoch:0 step:234[D loss: 0.486614, acc: 66.41%, op_acc: 25.00%] [G loss: 1.183676]\n",
      "epoch:0 step:235[D loss: 0.620770, acc: 51.56%, op_acc: 14.84%] [G loss: 0.881487]\n",
      "epoch:0 step:236[D loss: 0.612751, acc: 51.56%, op_acc: 16.41%] [G loss: 1.171194]\n",
      "epoch:0 step:237[D loss: 0.606906, acc: 57.03%, op_acc: 13.28%] [G loss: 1.086776]\n",
      "epoch:0 step:238[D loss: 0.572589, acc: 60.16%, op_acc: 17.97%] [G loss: 1.492121]\n",
      "epoch:0 step:239[D loss: 0.525975, acc: 61.72%, op_acc: 23.44%] [G loss: 1.258843]\n",
      "epoch:0 step:240[D loss: 0.548912, acc: 60.94%, op_acc: 27.34%] [G loss: 1.181165]\n",
      "epoch:0 step:241[D loss: 0.610735, acc: 53.12%, op_acc: 18.75%] [G loss: 1.166674]\n",
      "epoch:0 step:242[D loss: 0.498414, acc: 62.50%, op_acc: 23.44%] [G loss: 1.432623]\n",
      "epoch:0 step:243[D loss: 0.539537, acc: 50.78%, op_acc: 18.75%] [G loss: 1.278132]\n",
      "epoch:0 step:244[D loss: 0.571861, acc: 57.81%, op_acc: 23.44%] [G loss: 1.561822]\n",
      "epoch:0 step:245[D loss: 0.540102, acc: 63.28%, op_acc: 19.53%] [G loss: 1.346722]\n",
      "epoch:0 step:246[D loss: 0.540178, acc: 57.03%, op_acc: 17.19%] [G loss: 1.079578]\n",
      "epoch:0 step:247[D loss: 0.570625, acc: 54.69%, op_acc: 18.75%] [G loss: 1.310652]\n",
      "epoch:0 step:248[D loss: 0.595370, acc: 58.59%, op_acc: 14.84%] [G loss: 1.218460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:249[D loss: 0.536973, acc: 60.16%, op_acc: 23.44%] [G loss: 1.383077]\n",
      "epoch:0 step:250[D loss: 0.591284, acc: 55.47%, op_acc: 12.50%] [G loss: 1.253669]\n",
      "##############\n",
      "[0.83409626 0.84475389 0.80311534 0.78790306 0.78476192 0.83489584\n",
      " 0.88498887 0.8177186  0.79976077 0.8293734 ]\n",
      "##########\n",
      "epoch:0 step:251[D loss: 0.517169, acc: 56.25%, op_acc: 20.31%] [G loss: 1.158603]\n",
      "epoch:0 step:252[D loss: 0.495529, acc: 63.28%, op_acc: 25.00%] [G loss: 1.480991]\n",
      "epoch:0 step:253[D loss: 0.487631, acc: 67.97%, op_acc: 28.12%] [G loss: 1.455939]\n",
      "epoch:0 step:254[D loss: 0.539611, acc: 58.59%, op_acc: 23.44%] [G loss: 1.230453]\n",
      "epoch:0 step:255[D loss: 0.601715, acc: 50.00%, op_acc: 20.31%] [G loss: 1.331211]\n",
      "epoch:0 step:256[D loss: 0.530540, acc: 59.38%, op_acc: 25.00%] [G loss: 1.379495]\n",
      "epoch:0 step:257[D loss: 0.582688, acc: 48.44%, op_acc: 21.09%] [G loss: 1.116324]\n",
      "epoch:0 step:258[D loss: 0.521576, acc: 57.81%, op_acc: 21.88%] [G loss: 1.125091]\n",
      "epoch:0 step:259[D loss: 0.501572, acc: 67.19%, op_acc: 18.75%] [G loss: 1.501853]\n",
      "epoch:0 step:260[D loss: 0.509662, acc: 65.62%, op_acc: 21.09%] [G loss: 1.533839]\n",
      "epoch:0 step:261[D loss: 0.564224, acc: 57.81%, op_acc: 22.66%] [G loss: 1.228967]\n",
      "epoch:0 step:262[D loss: 0.525400, acc: 55.47%, op_acc: 18.75%] [G loss: 1.447178]\n",
      "epoch:0 step:263[D loss: 0.514307, acc: 60.16%, op_acc: 20.31%] [G loss: 1.191938]\n",
      "epoch:0 step:264[D loss: 0.554646, acc: 62.50%, op_acc: 17.97%] [G loss: 1.254104]\n",
      "epoch:0 step:265[D loss: 0.567448, acc: 54.69%, op_acc: 21.09%] [G loss: 1.042361]\n",
      "epoch:0 step:266[D loss: 0.521330, acc: 61.72%, op_acc: 28.91%] [G loss: 1.146718]\n",
      "epoch:0 step:267[D loss: 0.526810, acc: 60.16%, op_acc: 21.09%] [G loss: 1.388183]\n",
      "epoch:0 step:268[D loss: 0.504675, acc: 61.72%, op_acc: 17.19%] [G loss: 1.218261]\n",
      "epoch:0 step:269[D loss: 0.465446, acc: 66.41%, op_acc: 29.69%] [G loss: 1.203589]\n",
      "epoch:0 step:270[D loss: 0.517915, acc: 61.72%, op_acc: 19.53%] [G loss: 1.444195]\n",
      "epoch:0 step:271[D loss: 0.596555, acc: 49.22%, op_acc: 19.53%] [G loss: 1.231931]\n",
      "epoch:0 step:272[D loss: 0.539315, acc: 53.91%, op_acc: 18.75%] [G loss: 1.382876]\n",
      "epoch:0 step:273[D loss: 0.538392, acc: 60.94%, op_acc: 21.09%] [G loss: 1.314279]\n",
      "epoch:0 step:274[D loss: 0.544469, acc: 52.34%, op_acc: 20.31%] [G loss: 1.504738]\n",
      "epoch:0 step:275[D loss: 0.521234, acc: 59.38%, op_acc: 25.78%] [G loss: 1.423766]\n",
      "epoch:0 step:276[D loss: 0.505324, acc: 65.62%, op_acc: 25.78%] [G loss: 1.324992]\n",
      "epoch:0 step:277[D loss: 0.540163, acc: 62.50%, op_acc: 17.97%] [G loss: 1.267206]\n",
      "epoch:0 step:278[D loss: 0.510795, acc: 57.03%, op_acc: 26.56%] [G loss: 1.268127]\n",
      "epoch:0 step:279[D loss: 0.508260, acc: 62.50%, op_acc: 21.88%] [G loss: 1.167869]\n",
      "epoch:0 step:280[D loss: 0.585219, acc: 58.59%, op_acc: 31.25%] [G loss: 1.219629]\n",
      "epoch:0 step:281[D loss: 0.495948, acc: 64.84%, op_acc: 27.34%] [G loss: 1.300164]\n",
      "epoch:0 step:282[D loss: 0.495577, acc: 67.19%, op_acc: 25.00%] [G loss: 1.354241]\n",
      "epoch:0 step:283[D loss: 0.469788, acc: 66.41%, op_acc: 28.91%] [G loss: 1.657367]\n",
      "epoch:0 step:284[D loss: 0.505826, acc: 68.75%, op_acc: 21.88%] [G loss: 1.387725]\n",
      "epoch:0 step:285[D loss: 0.498795, acc: 58.59%, op_acc: 17.97%] [G loss: 1.019115]\n",
      "epoch:0 step:286[D loss: 0.564085, acc: 52.34%, op_acc: 17.97%] [G loss: 1.146363]\n",
      "epoch:0 step:287[D loss: 0.546277, acc: 53.12%, op_acc: 21.88%] [G loss: 1.106727]\n",
      "epoch:0 step:288[D loss: 0.542241, acc: 53.12%, op_acc: 19.53%] [G loss: 1.186079]\n",
      "epoch:0 step:289[D loss: 0.513538, acc: 60.16%, op_acc: 13.28%] [G loss: 1.329138]\n",
      "epoch:0 step:290[D loss: 0.453960, acc: 73.44%, op_acc: 19.53%] [G loss: 1.719121]\n",
      "epoch:0 step:291[D loss: 0.588216, acc: 53.12%, op_acc: 21.09%] [G loss: 1.293365]\n",
      "epoch:0 step:292[D loss: 0.551083, acc: 54.69%, op_acc: 24.22%] [G loss: 1.279925]\n",
      "epoch:0 step:293[D loss: 0.496870, acc: 60.94%, op_acc: 26.56%] [G loss: 1.373999]\n",
      "epoch:0 step:294[D loss: 0.514929, acc: 62.50%, op_acc: 22.66%] [G loss: 1.063143]\n",
      "epoch:0 step:295[D loss: 0.513418, acc: 54.69%, op_acc: 28.12%] [G loss: 1.364861]\n",
      "epoch:0 step:296[D loss: 0.539103, acc: 57.81%, op_acc: 25.00%] [G loss: 1.375185]\n",
      "epoch:0 step:297[D loss: 0.501356, acc: 66.41%, op_acc: 24.22%] [G loss: 1.315766]\n",
      "epoch:0 step:298[D loss: 0.451039, acc: 74.22%, op_acc: 22.66%] [G loss: 1.065439]\n",
      "epoch:0 step:299[D loss: 0.594930, acc: 45.31%, op_acc: 23.44%] [G loss: 0.847888]\n",
      "epoch:0 step:300[D loss: 0.530331, acc: 53.12%, op_acc: 21.09%] [G loss: 1.004112]\n",
      "##############\n",
      "[0.83316244 0.87317871 0.83535319 0.81503056 0.76618503 0.83516938\n",
      " 0.87673875 0.81828554 0.8303384  0.81742243]\n",
      "##########\n",
      "epoch:0 step:301[D loss: 0.564868, acc: 52.34%, op_acc: 18.75%] [G loss: 1.319983]\n",
      "epoch:0 step:302[D loss: 0.511370, acc: 61.72%, op_acc: 21.09%] [G loss: 1.327284]\n",
      "epoch:0 step:303[D loss: 0.496096, acc: 62.50%, op_acc: 21.09%] [G loss: 1.317408]\n",
      "epoch:0 step:304[D loss: 0.485468, acc: 62.50%, op_acc: 25.00%] [G loss: 1.359213]\n",
      "epoch:0 step:305[D loss: 0.494472, acc: 64.06%, op_acc: 23.44%] [G loss: 1.518585]\n",
      "epoch:0 step:306[D loss: 0.515587, acc: 63.28%, op_acc: 19.53%] [G loss: 1.330744]\n",
      "epoch:0 step:307[D loss: 0.483127, acc: 66.41%, op_acc: 26.56%] [G loss: 1.326761]\n",
      "epoch:0 step:308[D loss: 0.512055, acc: 53.91%, op_acc: 24.22%] [G loss: 1.274924]\n",
      "epoch:0 step:309[D loss: 0.490672, acc: 65.62%, op_acc: 21.88%] [G loss: 1.336181]\n",
      "epoch:0 step:310[D loss: 0.442379, acc: 65.62%, op_acc: 28.12%] [G loss: 1.276723]\n",
      "epoch:0 step:311[D loss: 0.468257, acc: 69.53%, op_acc: 19.53%] [G loss: 1.355589]\n",
      "epoch:0 step:312[D loss: 0.510893, acc: 62.50%, op_acc: 22.66%] [G loss: 1.447058]\n",
      "epoch:0 step:313[D loss: 0.486629, acc: 67.97%, op_acc: 25.78%] [G loss: 1.474302]\n",
      "epoch:0 step:314[D loss: 0.477551, acc: 67.19%, op_acc: 24.22%] [G loss: 1.373697]\n",
      "epoch:0 step:315[D loss: 0.534914, acc: 57.03%, op_acc: 18.75%] [G loss: 1.245655]\n",
      "epoch:0 step:316[D loss: 0.527826, acc: 58.59%, op_acc: 22.66%] [G loss: 1.093662]\n",
      "epoch:0 step:317[D loss: 0.543246, acc: 56.25%, op_acc: 19.53%] [G loss: 1.221065]\n",
      "epoch:0 step:318[D loss: 0.491821, acc: 64.84%, op_acc: 20.31%] [G loss: 1.295100]\n",
      "epoch:0 step:319[D loss: 0.526737, acc: 57.81%, op_acc: 25.00%] [G loss: 1.105692]\n",
      "epoch:0 step:320[D loss: 0.507368, acc: 65.62%, op_acc: 25.78%] [G loss: 0.978737]\n",
      "epoch:0 step:321[D loss: 0.529326, acc: 57.81%, op_acc: 20.31%] [G loss: 1.025080]\n",
      "epoch:0 step:322[D loss: 0.510810, acc: 63.28%, op_acc: 28.12%] [G loss: 1.148715]\n",
      "epoch:0 step:323[D loss: 0.556915, acc: 50.00%, op_acc: 21.88%] [G loss: 1.037484]\n",
      "epoch:0 step:324[D loss: 0.558488, acc: 55.47%, op_acc: 14.06%] [G loss: 1.051144]\n",
      "epoch:0 step:325[D loss: 0.514532, acc: 58.59%, op_acc: 25.78%] [G loss: 0.958195]\n",
      "epoch:0 step:326[D loss: 0.539930, acc: 55.47%, op_acc: 23.44%] [G loss: 1.137589]\n",
      "epoch:0 step:327[D loss: 0.525608, acc: 56.25%, op_acc: 24.22%] [G loss: 1.140713]\n",
      "epoch:0 step:328[D loss: 0.444718, acc: 66.41%, op_acc: 23.44%] [G loss: 1.267554]\n",
      "epoch:0 step:329[D loss: 0.514754, acc: 59.38%, op_acc: 19.53%] [G loss: 1.300913]\n",
      "epoch:0 step:330[D loss: 0.596143, acc: 47.66%, op_acc: 19.53%] [G loss: 1.018081]\n",
      "epoch:0 step:331[D loss: 0.462877, acc: 68.75%, op_acc: 26.56%] [G loss: 1.206488]\n",
      "epoch:0 step:332[D loss: 0.534607, acc: 57.81%, op_acc: 30.47%] [G loss: 1.149674]\n",
      "epoch:0 step:333[D loss: 0.563903, acc: 53.12%, op_acc: 25.00%] [G loss: 1.020127]\n",
      "epoch:0 step:334[D loss: 0.511242, acc: 60.16%, op_acc: 26.56%] [G loss: 1.195479]\n",
      "epoch:0 step:335[D loss: 0.440851, acc: 74.22%, op_acc: 30.47%] [G loss: 1.305990]\n",
      "epoch:0 step:336[D loss: 0.441586, acc: 69.53%, op_acc: 30.47%] [G loss: 1.402964]\n",
      "epoch:0 step:337[D loss: 0.464001, acc: 62.50%, op_acc: 28.91%] [G loss: 1.198092]\n",
      "epoch:0 step:338[D loss: 0.435638, acc: 68.75%, op_acc: 31.25%] [G loss: 1.141466]\n",
      "epoch:0 step:339[D loss: 0.447427, acc: 72.66%, op_acc: 23.44%] [G loss: 0.969202]\n",
      "epoch:0 step:340[D loss: 0.547495, acc: 53.91%, op_acc: 21.09%] [G loss: 0.938110]\n",
      "epoch:0 step:341[D loss: 0.529491, acc: 58.59%, op_acc: 23.44%] [G loss: 1.122828]\n",
      "epoch:0 step:342[D loss: 0.494357, acc: 60.94%, op_acc: 21.09%] [G loss: 1.405624]\n",
      "epoch:0 step:343[D loss: 0.522964, acc: 59.38%, op_acc: 19.53%] [G loss: 1.192378]\n",
      "epoch:0 step:344[D loss: 0.485214, acc: 65.62%, op_acc: 26.56%] [G loss: 1.195428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:345[D loss: 0.536471, acc: 53.91%, op_acc: 21.88%] [G loss: 1.121680]\n",
      "epoch:0 step:346[D loss: 0.519627, acc: 57.81%, op_acc: 25.00%] [G loss: 1.105680]\n",
      "epoch:0 step:347[D loss: 0.564697, acc: 51.56%, op_acc: 20.31%] [G loss: 1.108726]\n",
      "epoch:0 step:348[D loss: 0.548384, acc: 53.91%, op_acc: 23.44%] [G loss: 1.163785]\n",
      "epoch:0 step:349[D loss: 0.481287, acc: 67.97%, op_acc: 20.31%] [G loss: 1.174278]\n",
      "epoch:0 step:350[D loss: 0.441127, acc: 71.09%, op_acc: 30.47%] [G loss: 1.211482]\n",
      "##############\n",
      "[0.86093627 0.85836323 0.84504774 0.81625824 0.7989295  0.81389764\n",
      " 0.84799323 0.81063528 0.79493782 0.80921081]\n",
      "##########\n",
      "epoch:0 step:351[D loss: 0.494703, acc: 65.62%, op_acc: 21.09%] [G loss: 1.254355]\n",
      "epoch:0 step:352[D loss: 0.517630, acc: 57.81%, op_acc: 23.44%] [G loss: 1.320848]\n",
      "epoch:0 step:353[D loss: 0.485082, acc: 63.28%, op_acc: 21.09%] [G loss: 1.215646]\n",
      "epoch:0 step:354[D loss: 0.526837, acc: 60.94%, op_acc: 20.31%] [G loss: 0.970150]\n",
      "epoch:0 step:355[D loss: 0.485326, acc: 64.84%, op_acc: 23.44%] [G loss: 1.322161]\n",
      "epoch:0 step:356[D loss: 0.549262, acc: 58.59%, op_acc: 21.09%] [G loss: 1.221893]\n",
      "epoch:0 step:357[D loss: 0.481967, acc: 66.41%, op_acc: 22.66%] [G loss: 1.394713]\n",
      "epoch:0 step:358[D loss: 0.493199, acc: 61.72%, op_acc: 27.34%] [G loss: 1.308036]\n",
      "epoch:0 step:359[D loss: 0.503374, acc: 53.91%, op_acc: 27.34%] [G loss: 1.270242]\n",
      "epoch:0 step:360[D loss: 0.509058, acc: 60.16%, op_acc: 22.66%] [G loss: 1.298473]\n",
      "epoch:0 step:361[D loss: 0.525431, acc: 58.59%, op_acc: 19.53%] [G loss: 1.152444]\n",
      "epoch:0 step:362[D loss: 0.424653, acc: 70.31%, op_acc: 25.00%] [G loss: 1.218724]\n",
      "epoch:0 step:363[D loss: 0.555083, acc: 56.25%, op_acc: 22.66%] [G loss: 1.246215]\n",
      "epoch:0 step:364[D loss: 0.468035, acc: 65.62%, op_acc: 25.00%] [G loss: 1.282514]\n",
      "epoch:0 step:365[D loss: 0.452774, acc: 68.75%, op_acc: 32.81%] [G loss: 1.150466]\n",
      "epoch:0 step:366[D loss: 0.509848, acc: 57.03%, op_acc: 34.38%] [G loss: 1.232260]\n",
      "epoch:0 step:367[D loss: 0.444259, acc: 72.66%, op_acc: 21.88%] [G loss: 1.334752]\n",
      "epoch:0 step:368[D loss: 0.444587, acc: 74.22%, op_acc: 32.81%] [G loss: 1.311019]\n",
      "epoch:0 step:369[D loss: 0.413490, acc: 70.31%, op_acc: 29.69%] [G loss: 1.301405]\n",
      "epoch:0 step:370[D loss: 0.495126, acc: 60.94%, op_acc: 25.00%] [G loss: 1.073499]\n",
      "epoch:0 step:371[D loss: 0.496182, acc: 60.16%, op_acc: 22.66%] [G loss: 1.037734]\n",
      "epoch:0 step:372[D loss: 0.522132, acc: 58.59%, op_acc: 24.22%] [G loss: 1.221021]\n",
      "epoch:0 step:373[D loss: 0.461893, acc: 74.22%, op_acc: 30.47%] [G loss: 1.280420]\n",
      "epoch:0 step:374[D loss: 0.459834, acc: 61.72%, op_acc: 28.12%] [G loss: 1.624742]\n",
      "epoch:0 step:375[D loss: 0.470196, acc: 68.75%, op_acc: 19.53%] [G loss: 1.455047]\n",
      "epoch:0 step:376[D loss: 0.457691, acc: 64.84%, op_acc: 27.34%] [G loss: 1.308396]\n",
      "epoch:0 step:377[D loss: 0.504018, acc: 57.81%, op_acc: 21.88%] [G loss: 1.158689]\n",
      "epoch:0 step:378[D loss: 0.513850, acc: 56.25%, op_acc: 26.56%] [G loss: 1.175851]\n",
      "epoch:0 step:379[D loss: 0.449821, acc: 71.88%, op_acc: 17.97%] [G loss: 1.171286]\n",
      "epoch:0 step:380[D loss: 0.455751, acc: 65.62%, op_acc: 25.78%] [G loss: 1.093176]\n",
      "epoch:0 step:381[D loss: 0.463125, acc: 67.19%, op_acc: 30.47%] [G loss: 1.077977]\n",
      "epoch:0 step:382[D loss: 0.429091, acc: 73.44%, op_acc: 32.81%] [G loss: 1.312893]\n",
      "epoch:0 step:383[D loss: 0.504618, acc: 52.34%, op_acc: 25.00%] [G loss: 1.086897]\n",
      "epoch:0 step:384[D loss: 0.429313, acc: 71.09%, op_acc: 37.50%] [G loss: 1.093094]\n",
      "epoch:0 step:385[D loss: 0.459005, acc: 61.72%, op_acc: 27.34%] [G loss: 1.140939]\n",
      "epoch:0 step:386[D loss: 0.477200, acc: 63.28%, op_acc: 21.09%] [G loss: 1.100975]\n",
      "epoch:0 step:387[D loss: 0.550160, acc: 57.03%, op_acc: 24.22%] [G loss: 0.993578]\n",
      "epoch:0 step:388[D loss: 0.594692, acc: 46.88%, op_acc: 17.19%] [G loss: 1.077237]\n",
      "epoch:0 step:389[D loss: 0.459161, acc: 65.62%, op_acc: 28.12%] [G loss: 1.246478]\n",
      "epoch:0 step:390[D loss: 0.400499, acc: 78.91%, op_acc: 33.59%] [G loss: 1.400321]\n",
      "epoch:0 step:391[D loss: 0.498577, acc: 59.38%, op_acc: 28.12%] [G loss: 1.156645]\n",
      "epoch:0 step:392[D loss: 0.467088, acc: 67.19%, op_acc: 20.31%] [G loss: 1.360583]\n",
      "epoch:0 step:393[D loss: 0.450250, acc: 70.31%, op_acc: 27.34%] [G loss: 0.995525]\n",
      "epoch:0 step:394[D loss: 0.507140, acc: 62.50%, op_acc: 24.22%] [G loss: 1.201394]\n",
      "epoch:0 step:395[D loss: 0.496985, acc: 62.50%, op_acc: 19.53%] [G loss: 1.216366]\n",
      "epoch:0 step:396[D loss: 0.475554, acc: 64.06%, op_acc: 23.44%] [G loss: 1.259989]\n",
      "epoch:0 step:397[D loss: 0.512713, acc: 56.25%, op_acc: 20.31%] [G loss: 1.162328]\n",
      "epoch:0 step:398[D loss: 0.530528, acc: 55.47%, op_acc: 23.44%] [G loss: 1.182885]\n",
      "epoch:0 step:399[D loss: 0.458631, acc: 64.84%, op_acc: 30.47%] [G loss: 1.131394]\n",
      "epoch:0 step:400[D loss: 0.433207, acc: 70.31%, op_acc: 33.59%] [G loss: 1.289357]\n",
      "##############\n",
      "[0.84656757 0.87023349 0.82901454 0.82275465 0.79795631 0.863586\n",
      " 0.85291081 0.84058814 0.80779642 0.82771848]\n",
      "##########\n",
      "epoch:0 step:401[D loss: 0.501753, acc: 60.94%, op_acc: 25.78%] [G loss: 1.217057]\n",
      "epoch:0 step:402[D loss: 0.505297, acc: 60.94%, op_acc: 25.78%] [G loss: 1.139441]\n",
      "epoch:0 step:403[D loss: 0.486840, acc: 64.84%, op_acc: 27.34%] [G loss: 1.086652]\n",
      "epoch:0 step:404[D loss: 0.524892, acc: 55.47%, op_acc: 23.44%] [G loss: 1.015686]\n",
      "epoch:0 step:405[D loss: 0.567640, acc: 50.00%, op_acc: 27.34%] [G loss: 1.040657]\n",
      "epoch:0 step:406[D loss: 0.476313, acc: 61.72%, op_acc: 25.78%] [G loss: 1.017292]\n",
      "epoch:0 step:407[D loss: 0.462421, acc: 70.31%, op_acc: 33.59%] [G loss: 1.352163]\n",
      "epoch:0 step:408[D loss: 0.463309, acc: 61.72%, op_acc: 34.38%] [G loss: 1.191353]\n",
      "epoch:0 step:409[D loss: 0.478113, acc: 63.28%, op_acc: 31.25%] [G loss: 1.311184]\n",
      "epoch:0 step:410[D loss: 0.445902, acc: 67.97%, op_acc: 29.69%] [G loss: 1.160320]\n",
      "epoch:0 step:411[D loss: 0.506725, acc: 60.16%, op_acc: 19.53%] [G loss: 1.236249]\n",
      "epoch:0 step:412[D loss: 0.464515, acc: 66.41%, op_acc: 26.56%] [G loss: 1.186629]\n",
      "epoch:0 step:413[D loss: 0.485469, acc: 67.19%, op_acc: 17.97%] [G loss: 1.081814]\n",
      "epoch:0 step:414[D loss: 0.544816, acc: 50.00%, op_acc: 15.62%] [G loss: 0.999393]\n",
      "epoch:0 step:415[D loss: 0.457062, acc: 70.31%, op_acc: 24.22%] [G loss: 1.267685]\n",
      "epoch:0 step:416[D loss: 0.503909, acc: 60.94%, op_acc: 17.97%] [G loss: 1.143775]\n",
      "epoch:0 step:417[D loss: 0.501547, acc: 61.72%, op_acc: 25.00%] [G loss: 1.174854]\n",
      "epoch:0 step:418[D loss: 0.450008, acc: 66.41%, op_acc: 25.00%] [G loss: 1.122839]\n",
      "epoch:0 step:419[D loss: 0.490626, acc: 65.62%, op_acc: 25.78%] [G loss: 1.035669]\n",
      "epoch:0 step:420[D loss: 0.499943, acc: 63.28%, op_acc: 26.56%] [G loss: 1.028448]\n",
      "epoch:0 step:421[D loss: 0.490306, acc: 62.50%, op_acc: 25.78%] [G loss: 1.130366]\n",
      "epoch:0 step:422[D loss: 0.477025, acc: 64.06%, op_acc: 18.75%] [G loss: 1.401090]\n",
      "epoch:0 step:423[D loss: 0.418684, acc: 71.09%, op_acc: 22.66%] [G loss: 1.350194]\n",
      "epoch:0 step:424[D loss: 0.493943, acc: 64.84%, op_acc: 28.12%] [G loss: 1.265335]\n",
      "epoch:0 step:425[D loss: 0.455524, acc: 70.31%, op_acc: 28.91%] [G loss: 1.121201]\n",
      "epoch:0 step:426[D loss: 0.474582, acc: 65.62%, op_acc: 28.12%] [G loss: 1.196647]\n",
      "epoch:0 step:427[D loss: 0.508282, acc: 60.94%, op_acc: 28.12%] [G loss: 1.144315]\n",
      "epoch:0 step:428[D loss: 0.453379, acc: 66.41%, op_acc: 28.91%] [G loss: 1.125961]\n",
      "epoch:0 step:429[D loss: 0.476728, acc: 62.50%, op_acc: 26.56%] [G loss: 1.331736]\n",
      "epoch:0 step:430[D loss: 0.495698, acc: 59.38%, op_acc: 26.56%] [G loss: 1.262261]\n",
      "epoch:0 step:431[D loss: 0.476008, acc: 67.19%, op_acc: 23.44%] [G loss: 1.262821]\n",
      "epoch:0 step:432[D loss: 0.434012, acc: 67.19%, op_acc: 30.47%] [G loss: 1.289225]\n",
      "epoch:0 step:433[D loss: 0.476452, acc: 71.09%, op_acc: 27.34%] [G loss: 1.104384]\n",
      "epoch:0 step:434[D loss: 0.440677, acc: 71.09%, op_acc: 27.34%] [G loss: 1.237194]\n",
      "epoch:0 step:435[D loss: 0.515880, acc: 56.25%, op_acc: 23.44%] [G loss: 1.054191]\n",
      "epoch:0 step:436[D loss: 0.522877, acc: 55.47%, op_acc: 20.31%] [G loss: 1.201911]\n",
      "epoch:0 step:437[D loss: 0.470208, acc: 64.06%, op_acc: 25.00%] [G loss: 1.332942]\n",
      "epoch:0 step:438[D loss: 0.496492, acc: 59.38%, op_acc: 26.56%] [G loss: 1.369998]\n",
      "epoch:0 step:439[D loss: 0.508003, acc: 63.28%, op_acc: 21.88%] [G loss: 1.070868]\n",
      "epoch:0 step:440[D loss: 0.519112, acc: 60.94%, op_acc: 27.34%] [G loss: 1.222017]\n",
      "epoch:0 step:441[D loss: 0.510544, acc: 65.62%, op_acc: 25.00%] [G loss: 1.063628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:442[D loss: 0.466060, acc: 68.75%, op_acc: 27.34%] [G loss: 1.149857]\n",
      "epoch:0 step:443[D loss: 0.473999, acc: 61.72%, op_acc: 22.66%] [G loss: 1.293262]\n",
      "epoch:0 step:444[D loss: 0.506273, acc: 54.69%, op_acc: 22.66%] [G loss: 1.054676]\n",
      "epoch:0 step:445[D loss: 0.532575, acc: 57.81%, op_acc: 17.97%] [G loss: 1.122628]\n",
      "epoch:0 step:446[D loss: 0.523014, acc: 60.94%, op_acc: 23.44%] [G loss: 1.300270]\n",
      "epoch:0 step:447[D loss: 0.566850, acc: 43.75%, op_acc: 16.41%] [G loss: 1.162554]\n",
      "epoch:0 step:448[D loss: 0.483655, acc: 60.94%, op_acc: 25.78%] [G loss: 1.360311]\n",
      "epoch:0 step:449[D loss: 0.510189, acc: 57.81%, op_acc: 25.78%] [G loss: 1.043982]\n",
      "epoch:0 step:450[D loss: 0.457016, acc: 65.62%, op_acc: 24.22%] [G loss: 1.094463]\n",
      "##############\n",
      "[0.86346416 0.8639216  0.80735957 0.81968233 0.81258542 0.83528913\n",
      " 0.88048953 0.83337817 0.79510418 0.83759971]\n",
      "##########\n",
      "epoch:0 step:451[D loss: 0.474441, acc: 70.31%, op_acc: 28.91%] [G loss: 1.329124]\n",
      "epoch:0 step:452[D loss: 0.498358, acc: 55.47%, op_acc: 28.12%] [G loss: 1.076110]\n",
      "epoch:0 step:453[D loss: 0.441708, acc: 68.75%, op_acc: 32.03%] [G loss: 1.197197]\n",
      "epoch:0 step:454[D loss: 0.508310, acc: 55.47%, op_acc: 22.66%] [G loss: 1.037112]\n",
      "epoch:0 step:455[D loss: 0.521716, acc: 55.47%, op_acc: 23.44%] [G loss: 1.091330]\n",
      "epoch:0 step:456[D loss: 0.468078, acc: 59.38%, op_acc: 27.34%] [G loss: 1.065887]\n",
      "epoch:0 step:457[D loss: 0.488541, acc: 60.94%, op_acc: 23.44%] [G loss: 1.134096]\n",
      "epoch:0 step:458[D loss: 0.414453, acc: 69.53%, op_acc: 30.47%] [G loss: 1.270435]\n",
      "epoch:0 step:459[D loss: 0.502218, acc: 63.28%, op_acc: 17.97%] [G loss: 1.187850]\n",
      "epoch:0 step:460[D loss: 0.429869, acc: 68.75%, op_acc: 26.56%] [G loss: 1.345648]\n",
      "epoch:0 step:461[D loss: 0.430822, acc: 71.09%, op_acc: 31.25%] [G loss: 1.353671]\n",
      "epoch:0 step:462[D loss: 0.434874, acc: 75.78%, op_acc: 27.34%] [G loss: 1.300138]\n",
      "epoch:0 step:463[D loss: 0.405169, acc: 71.88%, op_acc: 37.50%] [G loss: 1.462452]\n",
      "epoch:0 step:464[D loss: 0.486389, acc: 63.28%, op_acc: 30.47%] [G loss: 1.340330]\n",
      "epoch:0 step:465[D loss: 0.394470, acc: 78.91%, op_acc: 32.03%] [G loss: 1.293776]\n",
      "epoch:0 step:466[D loss: 0.455188, acc: 72.66%, op_acc: 24.22%] [G loss: 1.038560]\n",
      "epoch:0 step:467[D loss: 0.512896, acc: 59.38%, op_acc: 25.78%] [G loss: 1.204229]\n",
      "epoch:0 step:468[D loss: 0.417390, acc: 72.66%, op_acc: 30.47%] [G loss: 1.123220]\n",
      "epoch:0 step:469[D loss: 0.471833, acc: 64.06%, op_acc: 33.59%] [G loss: 1.238747]\n",
      "epoch:0 step:470[D loss: 0.463885, acc: 66.41%, op_acc: 28.12%] [G loss: 1.325826]\n",
      "epoch:0 step:471[D loss: 0.471280, acc: 66.41%, op_acc: 30.47%] [G loss: 1.419749]\n",
      "epoch:0 step:472[D loss: 0.433763, acc: 71.88%, op_acc: 27.34%] [G loss: 1.599323]\n",
      "epoch:0 step:473[D loss: 0.499141, acc: 56.25%, op_acc: 26.56%] [G loss: 1.293902]\n",
      "epoch:0 step:474[D loss: 0.479878, acc: 68.75%, op_acc: 21.09%] [G loss: 1.282041]\n",
      "epoch:0 step:475[D loss: 0.470234, acc: 64.06%, op_acc: 18.75%] [G loss: 1.336931]\n",
      "epoch:0 step:476[D loss: 0.520973, acc: 56.25%, op_acc: 21.88%] [G loss: 1.144719]\n",
      "epoch:0 step:477[D loss: 0.490278, acc: 66.41%, op_acc: 24.22%] [G loss: 1.293264]\n",
      "epoch:0 step:478[D loss: 0.526182, acc: 56.25%, op_acc: 26.56%] [G loss: 1.025645]\n",
      "epoch:0 step:479[D loss: 0.501003, acc: 62.50%, op_acc: 24.22%] [G loss: 1.008648]\n",
      "epoch:0 step:480[D loss: 0.542261, acc: 55.47%, op_acc: 22.66%] [G loss: 1.077365]\n",
      "epoch:0 step:481[D loss: 0.466136, acc: 67.97%, op_acc: 27.34%] [G loss: 1.123606]\n",
      "epoch:0 step:482[D loss: 0.462408, acc: 67.19%, op_acc: 32.03%] [G loss: 1.217974]\n",
      "epoch:0 step:483[D loss: 0.555555, acc: 51.56%, op_acc: 22.66%] [G loss: 1.244477]\n",
      "epoch:0 step:484[D loss: 0.440320, acc: 68.75%, op_acc: 30.47%] [G loss: 1.155223]\n",
      "epoch:0 step:485[D loss: 0.469559, acc: 67.19%, op_acc: 28.91%] [G loss: 1.254623]\n",
      "epoch:0 step:486[D loss: 0.455473, acc: 68.75%, op_acc: 28.12%] [G loss: 1.108450]\n",
      "epoch:0 step:487[D loss: 0.483682, acc: 64.06%, op_acc: 27.34%] [G loss: 1.092551]\n",
      "epoch:0 step:488[D loss: 0.475905, acc: 63.28%, op_acc: 24.22%] [G loss: 1.098640]\n",
      "epoch:0 step:489[D loss: 0.475038, acc: 64.84%, op_acc: 25.78%] [G loss: 1.145016]\n",
      "epoch:0 step:490[D loss: 0.476599, acc: 61.72%, op_acc: 30.47%] [G loss: 1.045644]\n",
      "epoch:0 step:491[D loss: 0.537103, acc: 54.69%, op_acc: 25.00%] [G loss: 1.059033]\n",
      "epoch:0 step:492[D loss: 0.524946, acc: 47.66%, op_acc: 25.00%] [G loss: 1.319577]\n",
      "epoch:0 step:493[D loss: 0.454880, acc: 67.97%, op_acc: 26.56%] [G loss: 1.187294]\n",
      "epoch:0 step:494[D loss: 0.425807, acc: 75.00%, op_acc: 25.78%] [G loss: 1.328029]\n",
      "epoch:0 step:495[D loss: 0.453869, acc: 71.88%, op_acc: 21.88%] [G loss: 1.218280]\n",
      "epoch:0 step:496[D loss: 0.420602, acc: 71.88%, op_acc: 29.69%] [G loss: 1.156903]\n",
      "epoch:0 step:497[D loss: 0.444632, acc: 72.66%, op_acc: 30.47%] [G loss: 1.459649]\n",
      "epoch:0 step:498[D loss: 0.492506, acc: 62.50%, op_acc: 22.66%] [G loss: 0.993985]\n",
      "epoch:0 step:499[D loss: 0.521245, acc: 57.03%, op_acc: 21.09%] [G loss: 1.260209]\n",
      "epoch:0 step:500[D loss: 0.458620, acc: 67.97%, op_acc: 28.91%] [G loss: 1.252063]\n",
      "##############\n",
      "[0.85146835 0.8640734  0.8251907  0.80975113 0.77873468 0.83764877\n",
      " 0.8786887  0.84936411 0.82966632 0.83568101]\n",
      "##########\n",
      "epoch:0 step:501[D loss: 0.451067, acc: 71.09%, op_acc: 26.56%] [G loss: 1.025994]\n",
      "epoch:0 step:502[D loss: 0.494649, acc: 56.25%, op_acc: 23.44%] [G loss: 1.150668]\n",
      "epoch:0 step:503[D loss: 0.448370, acc: 64.84%, op_acc: 29.69%] [G loss: 1.245214]\n",
      "epoch:0 step:504[D loss: 0.480905, acc: 61.72%, op_acc: 24.22%] [G loss: 1.344683]\n",
      "epoch:0 step:505[D loss: 0.497702, acc: 60.16%, op_acc: 29.69%] [G loss: 0.923182]\n",
      "epoch:0 step:506[D loss: 0.514629, acc: 55.47%, op_acc: 30.47%] [G loss: 1.249141]\n",
      "epoch:0 step:507[D loss: 0.466301, acc: 64.84%, op_acc: 29.69%] [G loss: 1.295476]\n",
      "epoch:0 step:508[D loss: 0.454678, acc: 67.19%, op_acc: 28.12%] [G loss: 1.072058]\n",
      "epoch:0 step:509[D loss: 0.471388, acc: 65.62%, op_acc: 21.09%] [G loss: 1.104838]\n",
      "epoch:0 step:510[D loss: 0.497049, acc: 60.16%, op_acc: 27.34%] [G loss: 1.106415]\n",
      "epoch:0 step:511[D loss: 0.516121, acc: 53.91%, op_acc: 19.53%] [G loss: 1.044193]\n",
      "epoch:0 step:512[D loss: 0.469331, acc: 60.16%, op_acc: 21.88%] [G loss: 1.299511]\n",
      "epoch:0 step:513[D loss: 0.527920, acc: 58.59%, op_acc: 22.66%] [G loss: 1.284764]\n",
      "epoch:0 step:514[D loss: 0.512717, acc: 52.34%, op_acc: 26.56%] [G loss: 1.341945]\n",
      "epoch:0 step:515[D loss: 0.504093, acc: 64.06%, op_acc: 25.00%] [G loss: 1.050695]\n",
      "epoch:0 step:516[D loss: 0.493688, acc: 61.72%, op_acc: 21.09%] [G loss: 1.085444]\n",
      "epoch:0 step:517[D loss: 0.517957, acc: 59.38%, op_acc: 26.56%] [G loss: 1.190374]\n",
      "epoch:0 step:518[D loss: 0.478492, acc: 64.84%, op_acc: 21.09%] [G loss: 1.081111]\n",
      "epoch:0 step:519[D loss: 0.471747, acc: 68.75%, op_acc: 25.78%] [G loss: 1.077914]\n",
      "epoch:0 step:520[D loss: 0.457757, acc: 64.84%, op_acc: 33.59%] [G loss: 1.272525]\n",
      "epoch:0 step:521[D loss: 0.488254, acc: 59.38%, op_acc: 29.69%] [G loss: 1.146528]\n",
      "epoch:0 step:522[D loss: 0.500201, acc: 65.62%, op_acc: 17.97%] [G loss: 1.330841]\n",
      "epoch:0 step:523[D loss: 0.482527, acc: 60.94%, op_acc: 25.78%] [G loss: 1.140972]\n",
      "epoch:0 step:524[D loss: 0.512414, acc: 59.38%, op_acc: 25.00%] [G loss: 1.123787]\n",
      "epoch:0 step:525[D loss: 0.505215, acc: 59.38%, op_acc: 21.09%] [G loss: 1.146303]\n",
      "epoch:0 step:526[D loss: 0.538066, acc: 60.16%, op_acc: 20.31%] [G loss: 1.185506]\n",
      "epoch:0 step:527[D loss: 0.476618, acc: 62.50%, op_acc: 25.00%] [G loss: 1.248921]\n",
      "epoch:0 step:528[D loss: 0.481468, acc: 61.72%, op_acc: 27.34%] [G loss: 1.067637]\n",
      "epoch:0 step:529[D loss: 0.516004, acc: 61.72%, op_acc: 26.56%] [G loss: 0.990978]\n",
      "epoch:0 step:530[D loss: 0.547655, acc: 57.03%, op_acc: 24.22%] [G loss: 1.065386]\n",
      "epoch:0 step:531[D loss: 0.494325, acc: 57.03%, op_acc: 26.56%] [G loss: 1.095364]\n",
      "epoch:0 step:532[D loss: 0.489808, acc: 64.84%, op_acc: 30.47%] [G loss: 1.121319]\n",
      "epoch:0 step:533[D loss: 0.505170, acc: 57.03%, op_acc: 23.44%] [G loss: 1.026355]\n",
      "epoch:0 step:534[D loss: 0.460178, acc: 63.28%, op_acc: 32.03%] [G loss: 1.011077]\n",
      "epoch:0 step:535[D loss: 0.486282, acc: 57.81%, op_acc: 29.69%] [G loss: 1.144510]\n",
      "epoch:0 step:536[D loss: 0.472065, acc: 55.47%, op_acc: 32.03%] [G loss: 1.006095]\n",
      "epoch:0 step:537[D loss: 0.477357, acc: 58.59%, op_acc: 21.88%] [G loss: 1.217461]\n",
      "epoch:0 step:538[D loss: 0.488123, acc: 60.16%, op_acc: 25.78%] [G loss: 1.109159]\n",
      "epoch:0 step:539[D loss: 0.470929, acc: 74.22%, op_acc: 28.12%] [G loss: 1.162327]\n",
      "epoch:0 step:540[D loss: 0.474581, acc: 61.72%, op_acc: 29.69%] [G loss: 1.185369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:541[D loss: 0.453508, acc: 62.50%, op_acc: 24.22%] [G loss: 1.191176]\n",
      "epoch:0 step:542[D loss: 0.441066, acc: 68.75%, op_acc: 29.69%] [G loss: 1.420693]\n",
      "epoch:0 step:543[D loss: 0.490670, acc: 64.06%, op_acc: 27.34%] [G loss: 1.205024]\n",
      "epoch:0 step:544[D loss: 0.449782, acc: 64.84%, op_acc: 35.16%] [G loss: 1.076159]\n",
      "epoch:0 step:545[D loss: 0.507614, acc: 57.03%, op_acc: 29.69%] [G loss: 1.273758]\n",
      "epoch:0 step:546[D loss: 0.499539, acc: 60.16%, op_acc: 25.78%] [G loss: 1.045084]\n",
      "epoch:0 step:547[D loss: 0.495949, acc: 60.16%, op_acc: 21.09%] [G loss: 1.183868]\n",
      "epoch:0 step:548[D loss: 0.493067, acc: 61.72%, op_acc: 30.47%] [G loss: 1.171963]\n",
      "epoch:0 step:549[D loss: 0.453646, acc: 69.53%, op_acc: 32.03%] [G loss: 1.086806]\n",
      "epoch:0 step:550[D loss: 0.505881, acc: 57.03%, op_acc: 24.22%] [G loss: 1.114415]\n",
      "##############\n",
      "[0.85668991 0.86953837 0.80646849 0.82385026 0.79832959 0.83531605\n",
      " 0.88361668 0.82626586 0.81737257 0.80194257]\n",
      "##########\n",
      "epoch:0 step:551[D loss: 0.458719, acc: 63.28%, op_acc: 21.88%] [G loss: 1.187406]\n",
      "epoch:0 step:552[D loss: 0.525559, acc: 57.03%, op_acc: 21.09%] [G loss: 1.067969]\n",
      "epoch:0 step:553[D loss: 0.469278, acc: 64.06%, op_acc: 27.34%] [G loss: 1.084487]\n",
      "epoch:0 step:554[D loss: 0.467429, acc: 63.28%, op_acc: 25.00%] [G loss: 1.192088]\n",
      "epoch:0 step:555[D loss: 0.512235, acc: 58.59%, op_acc: 28.91%] [G loss: 1.130590]\n",
      "epoch:0 step:556[D loss: 0.462953, acc: 65.62%, op_acc: 28.91%] [G loss: 1.197460]\n",
      "epoch:0 step:557[D loss: 0.473074, acc: 61.72%, op_acc: 21.88%] [G loss: 1.083106]\n",
      "epoch:0 step:558[D loss: 0.433273, acc: 67.19%, op_acc: 30.47%] [G loss: 1.230520]\n",
      "epoch:0 step:559[D loss: 0.482236, acc: 63.28%, op_acc: 18.75%] [G loss: 0.918690]\n",
      "epoch:0 step:560[D loss: 0.459759, acc: 70.31%, op_acc: 27.34%] [G loss: 1.080791]\n",
      "epoch:0 step:561[D loss: 0.467054, acc: 59.38%, op_acc: 25.78%] [G loss: 1.195093]\n",
      "epoch:0 step:562[D loss: 0.484592, acc: 60.16%, op_acc: 23.44%] [G loss: 1.163748]\n",
      "epoch:0 step:563[D loss: 0.462438, acc: 70.31%, op_acc: 24.22%] [G loss: 1.278211]\n",
      "epoch:0 step:564[D loss: 0.492398, acc: 59.38%, op_acc: 17.97%] [G loss: 1.157275]\n",
      "epoch:0 step:565[D loss: 0.449580, acc: 71.09%, op_acc: 22.66%] [G loss: 1.243419]\n",
      "epoch:0 step:566[D loss: 0.483195, acc: 66.41%, op_acc: 20.31%] [G loss: 1.186902]\n",
      "epoch:0 step:567[D loss: 0.497362, acc: 62.50%, op_acc: 28.12%] [G loss: 1.200720]\n",
      "epoch:0 step:568[D loss: 0.496259, acc: 59.38%, op_acc: 19.53%] [G loss: 1.183205]\n",
      "epoch:0 step:569[D loss: 0.481323, acc: 60.94%, op_acc: 31.25%] [G loss: 1.291426]\n",
      "epoch:0 step:570[D loss: 0.490765, acc: 59.38%, op_acc: 32.03%] [G loss: 1.065563]\n",
      "epoch:0 step:571[D loss: 0.482699, acc: 63.28%, op_acc: 25.78%] [G loss: 1.093726]\n",
      "epoch:0 step:572[D loss: 0.501708, acc: 53.12%, op_acc: 28.91%] [G loss: 1.112794]\n",
      "epoch:0 step:573[D loss: 0.471611, acc: 58.59%, op_acc: 23.44%] [G loss: 1.085642]\n",
      "epoch:0 step:574[D loss: 0.505621, acc: 58.59%, op_acc: 19.53%] [G loss: 1.054608]\n",
      "epoch:0 step:575[D loss: 0.447598, acc: 67.19%, op_acc: 30.47%] [G loss: 1.226204]\n",
      "epoch:0 step:576[D loss: 0.515537, acc: 58.59%, op_acc: 25.00%] [G loss: 1.062850]\n",
      "epoch:0 step:577[D loss: 0.498753, acc: 64.06%, op_acc: 29.69%] [G loss: 1.062272]\n",
      "epoch:0 step:578[D loss: 0.507800, acc: 64.06%, op_acc: 22.66%] [G loss: 1.279813]\n",
      "epoch:0 step:579[D loss: 0.468595, acc: 66.41%, op_acc: 28.12%] [G loss: 0.993124]\n",
      "epoch:0 step:580[D loss: 0.526578, acc: 52.34%, op_acc: 32.81%] [G loss: 1.101584]\n",
      "epoch:0 step:581[D loss: 0.446450, acc: 67.19%, op_acc: 30.47%] [G loss: 1.123334]\n",
      "epoch:0 step:582[D loss: 0.455458, acc: 64.84%, op_acc: 26.56%] [G loss: 1.171980]\n",
      "epoch:0 step:583[D loss: 0.437411, acc: 71.09%, op_acc: 26.56%] [G loss: 1.179238]\n",
      "epoch:0 step:584[D loss: 0.478341, acc: 62.50%, op_acc: 23.44%] [G loss: 1.083625]\n",
      "epoch:0 step:585[D loss: 0.454491, acc: 67.19%, op_acc: 32.03%] [G loss: 1.084354]\n",
      "epoch:0 step:586[D loss: 0.418030, acc: 66.41%, op_acc: 25.78%] [G loss: 1.113617]\n",
      "epoch:0 step:587[D loss: 0.512069, acc: 57.81%, op_acc: 23.44%] [G loss: 1.021556]\n",
      "epoch:0 step:588[D loss: 0.448491, acc: 71.88%, op_acc: 29.69%] [G loss: 1.072096]\n",
      "epoch:0 step:589[D loss: 0.448341, acc: 65.62%, op_acc: 25.78%] [G loss: 0.973557]\n",
      "epoch:0 step:590[D loss: 0.468873, acc: 63.28%, op_acc: 28.91%] [G loss: 1.128067]\n",
      "epoch:0 step:591[D loss: 0.488537, acc: 56.25%, op_acc: 30.47%] [G loss: 1.305237]\n",
      "epoch:0 step:592[D loss: 0.459389, acc: 61.72%, op_acc: 30.47%] [G loss: 1.294443]\n",
      "epoch:0 step:593[D loss: 0.468439, acc: 65.62%, op_acc: 21.09%] [G loss: 1.148986]\n",
      "epoch:0 step:594[D loss: 0.524195, acc: 56.25%, op_acc: 23.44%] [G loss: 1.204595]\n",
      "epoch:0 step:595[D loss: 0.497550, acc: 57.81%, op_acc: 25.78%] [G loss: 1.113318]\n",
      "epoch:0 step:596[D loss: 0.464867, acc: 65.62%, op_acc: 24.22%] [G loss: 1.063182]\n",
      "epoch:0 step:597[D loss: 0.441239, acc: 74.22%, op_acc: 27.34%] [G loss: 1.115312]\n",
      "epoch:0 step:598[D loss: 0.500458, acc: 59.38%, op_acc: 27.34%] [G loss: 1.095580]\n",
      "epoch:0 step:599[D loss: 0.420802, acc: 73.44%, op_acc: 28.12%] [G loss: 1.156013]\n",
      "epoch:0 step:600[D loss: 0.525237, acc: 62.50%, op_acc: 23.44%] [G loss: 1.190834]\n",
      "##############\n",
      "[0.85813503 0.87251813 0.81411797 0.83400458 0.80678443 0.81144753\n",
      " 0.87699805 0.83475665 0.84190943 0.8225443 ]\n",
      "##########\n",
      "epoch:0 step:601[D loss: 0.455868, acc: 62.50%, op_acc: 24.22%] [G loss: 1.181329]\n",
      "epoch:0 step:602[D loss: 0.444616, acc: 67.19%, op_acc: 28.12%] [G loss: 1.166717]\n",
      "epoch:0 step:603[D loss: 0.470424, acc: 60.16%, op_acc: 32.81%] [G loss: 1.094854]\n",
      "epoch:0 step:604[D loss: 0.473976, acc: 60.94%, op_acc: 28.12%] [G loss: 1.133906]\n",
      "epoch:0 step:605[D loss: 0.481026, acc: 65.62%, op_acc: 31.25%] [G loss: 1.042098]\n",
      "epoch:0 step:606[D loss: 0.485685, acc: 65.62%, op_acc: 28.12%] [G loss: 1.077211]\n",
      "epoch:0 step:607[D loss: 0.426057, acc: 65.62%, op_acc: 28.91%] [G loss: 1.185353]\n",
      "epoch:0 step:608[D loss: 0.461278, acc: 72.66%, op_acc: 26.56%] [G loss: 1.129027]\n",
      "epoch:0 step:609[D loss: 0.430783, acc: 65.62%, op_acc: 31.25%] [G loss: 1.303063]\n",
      "epoch:0 step:610[D loss: 0.475623, acc: 67.97%, op_acc: 28.91%] [G loss: 1.086451]\n",
      "epoch:0 step:611[D loss: 0.493778, acc: 59.38%, op_acc: 22.66%] [G loss: 1.156189]\n",
      "epoch:0 step:612[D loss: 0.492573, acc: 67.19%, op_acc: 28.12%] [G loss: 1.090637]\n",
      "epoch:0 step:613[D loss: 0.534067, acc: 59.38%, op_acc: 20.31%] [G loss: 1.022088]\n",
      "epoch:0 step:614[D loss: 0.463033, acc: 64.06%, op_acc: 24.22%] [G loss: 1.065239]\n",
      "epoch:0 step:615[D loss: 0.427127, acc: 69.53%, op_acc: 25.78%] [G loss: 1.265309]\n",
      "epoch:0 step:616[D loss: 0.494785, acc: 58.59%, op_acc: 25.78%] [G loss: 1.159186]\n",
      "epoch:0 step:617[D loss: 0.520938, acc: 58.59%, op_acc: 16.41%] [G loss: 1.291095]\n",
      "epoch:0 step:618[D loss: 0.488956, acc: 58.59%, op_acc: 30.47%] [G loss: 1.137174]\n",
      "epoch:0 step:619[D loss: 0.489460, acc: 60.16%, op_acc: 25.00%] [G loss: 1.279426]\n",
      "epoch:0 step:620[D loss: 0.480228, acc: 65.62%, op_acc: 22.66%] [G loss: 1.083010]\n",
      "epoch:0 step:621[D loss: 0.455027, acc: 67.97%, op_acc: 23.44%] [G loss: 1.101967]\n",
      "epoch:0 step:622[D loss: 0.514349, acc: 58.59%, op_acc: 22.66%] [G loss: 0.987837]\n",
      "epoch:0 step:623[D loss: 0.466235, acc: 64.06%, op_acc: 26.56%] [G loss: 1.050298]\n",
      "epoch:0 step:624[D loss: 0.418491, acc: 72.66%, op_acc: 28.12%] [G loss: 1.123255]\n",
      "epoch:0 step:625[D loss: 0.498305, acc: 62.50%, op_acc: 26.56%] [G loss: 1.074561]\n",
      "epoch:0 step:626[D loss: 0.474330, acc: 60.94%, op_acc: 32.81%] [G loss: 1.151346]\n",
      "epoch:0 step:627[D loss: 0.458199, acc: 60.94%, op_acc: 26.56%] [G loss: 1.175671]\n",
      "epoch:0 step:628[D loss: 0.435115, acc: 71.09%, op_acc: 26.56%] [G loss: 1.175089]\n",
      "epoch:0 step:629[D loss: 0.479178, acc: 61.72%, op_acc: 28.12%] [G loss: 1.254173]\n",
      "epoch:0 step:630[D loss: 0.429640, acc: 71.88%, op_acc: 27.34%] [G loss: 1.211546]\n",
      "epoch:0 step:631[D loss: 0.506994, acc: 60.94%, op_acc: 25.78%] [G loss: 1.095506]\n",
      "epoch:0 step:632[D loss: 0.465489, acc: 68.75%, op_acc: 26.56%] [G loss: 1.157048]\n",
      "epoch:0 step:633[D loss: 0.470698, acc: 66.41%, op_acc: 25.78%] [G loss: 1.298352]\n",
      "epoch:0 step:634[D loss: 0.424895, acc: 68.75%, op_acc: 38.28%] [G loss: 1.122451]\n",
      "epoch:0 step:635[D loss: 0.467637, acc: 65.62%, op_acc: 31.25%] [G loss: 1.010421]\n",
      "epoch:0 step:636[D loss: 0.468024, acc: 59.38%, op_acc: 29.69%] [G loss: 1.018394]\n",
      "epoch:0 step:637[D loss: 0.489039, acc: 64.84%, op_acc: 18.75%] [G loss: 1.115636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:638[D loss: 0.453539, acc: 61.72%, op_acc: 31.25%] [G loss: 1.046628]\n",
      "epoch:0 step:639[D loss: 0.433934, acc: 68.75%, op_acc: 26.56%] [G loss: 1.036994]\n",
      "epoch:0 step:640[D loss: 0.476466, acc: 66.41%, op_acc: 31.25%] [G loss: 1.090990]\n",
      "epoch:0 step:641[D loss: 0.484822, acc: 65.62%, op_acc: 18.75%] [G loss: 1.010966]\n",
      "epoch:0 step:642[D loss: 0.491094, acc: 61.72%, op_acc: 23.44%] [G loss: 1.252264]\n",
      "epoch:0 step:643[D loss: 0.502697, acc: 57.03%, op_acc: 19.53%] [G loss: 1.066526]\n",
      "epoch:0 step:644[D loss: 0.464558, acc: 60.16%, op_acc: 32.03%] [G loss: 1.069195]\n",
      "epoch:0 step:645[D loss: 0.479999, acc: 65.62%, op_acc: 30.47%] [G loss: 1.132169]\n",
      "epoch:0 step:646[D loss: 0.528938, acc: 59.38%, op_acc: 22.66%] [G loss: 1.257967]\n",
      "epoch:0 step:647[D loss: 0.497311, acc: 58.59%, op_acc: 27.34%] [G loss: 1.094654]\n",
      "epoch:0 step:648[D loss: 0.479905, acc: 64.84%, op_acc: 25.78%] [G loss: 1.208598]\n",
      "epoch:0 step:649[D loss: 0.462427, acc: 63.28%, op_acc: 34.38%] [G loss: 1.090404]\n",
      "epoch:0 step:650[D loss: 0.498794, acc: 60.16%, op_acc: 25.78%] [G loss: 1.082300]\n",
      "##############\n",
      "[0.86587518 0.87569346 0.80684977 0.82290794 0.78766609 0.83912888\n",
      " 0.87493879 0.81141665 0.8258984  0.82906221]\n",
      "##########\n",
      "epoch:0 step:651[D loss: 0.450466, acc: 65.62%, op_acc: 31.25%] [G loss: 1.109328]\n",
      "epoch:0 step:652[D loss: 0.447860, acc: 65.62%, op_acc: 31.25%] [G loss: 1.102453]\n",
      "epoch:0 step:653[D loss: 0.458531, acc: 63.28%, op_acc: 35.94%] [G loss: 1.053784]\n",
      "epoch:0 step:654[D loss: 0.469263, acc: 63.28%, op_acc: 28.12%] [G loss: 1.057961]\n",
      "epoch:0 step:655[D loss: 0.436916, acc: 70.31%, op_acc: 35.16%] [G loss: 0.962286]\n",
      "epoch:0 step:656[D loss: 0.505356, acc: 57.03%, op_acc: 21.09%] [G loss: 1.116781]\n",
      "epoch:0 step:657[D loss: 0.516153, acc: 61.72%, op_acc: 19.53%] [G loss: 1.119454]\n",
      "epoch:0 step:658[D loss: 0.419537, acc: 69.53%, op_acc: 35.16%] [G loss: 1.281838]\n",
      "epoch:0 step:659[D loss: 0.489153, acc: 57.81%, op_acc: 22.66%] [G loss: 0.944102]\n",
      "epoch:0 step:660[D loss: 0.445042, acc: 67.19%, op_acc: 30.47%] [G loss: 1.201720]\n",
      "epoch:0 step:661[D loss: 0.454406, acc: 64.84%, op_acc: 29.69%] [G loss: 1.230833]\n",
      "epoch:0 step:662[D loss: 0.466860, acc: 60.94%, op_acc: 32.81%] [G loss: 1.156756]\n",
      "epoch:0 step:663[D loss: 0.429365, acc: 65.62%, op_acc: 29.69%] [G loss: 1.128502]\n",
      "epoch:0 step:664[D loss: 0.432299, acc: 70.31%, op_acc: 28.12%] [G loss: 1.096720]\n",
      "epoch:0 step:665[D loss: 0.454606, acc: 72.66%, op_acc: 27.34%] [G loss: 1.053406]\n",
      "epoch:0 step:666[D loss: 0.465531, acc: 68.75%, op_acc: 23.44%] [G loss: 1.243305]\n",
      "epoch:0 step:667[D loss: 0.407868, acc: 75.00%, op_acc: 28.91%] [G loss: 1.134305]\n",
      "epoch:0 step:668[D loss: 0.491691, acc: 57.03%, op_acc: 20.31%] [G loss: 1.036756]\n",
      "epoch:0 step:669[D loss: 0.462839, acc: 73.44%, op_acc: 20.31%] [G loss: 1.303229]\n",
      "epoch:0 step:670[D loss: 0.454734, acc: 70.31%, op_acc: 27.34%] [G loss: 1.302444]\n",
      "epoch:0 step:671[D loss: 0.516574, acc: 59.38%, op_acc: 31.25%] [G loss: 1.293866]\n",
      "epoch:0 step:672[D loss: 0.415482, acc: 72.66%, op_acc: 32.81%] [G loss: 1.197810]\n",
      "epoch:0 step:673[D loss: 0.419784, acc: 70.31%, op_acc: 30.47%] [G loss: 1.189617]\n",
      "epoch:0 step:674[D loss: 0.445000, acc: 67.19%, op_acc: 28.12%] [G loss: 1.226631]\n",
      "epoch:0 step:675[D loss: 0.453057, acc: 71.09%, op_acc: 26.56%] [G loss: 1.175296]\n",
      "epoch:0 step:676[D loss: 0.484074, acc: 64.06%, op_acc: 28.12%] [G loss: 1.115852]\n",
      "epoch:0 step:677[D loss: 0.476653, acc: 63.28%, op_acc: 26.56%] [G loss: 1.232066]\n",
      "epoch:0 step:678[D loss: 0.465157, acc: 61.72%, op_acc: 32.81%] [G loss: 1.161732]\n",
      "epoch:0 step:679[D loss: 0.437478, acc: 70.31%, op_acc: 26.56%] [G loss: 1.228485]\n",
      "epoch:0 step:680[D loss: 0.496992, acc: 54.69%, op_acc: 28.91%] [G loss: 1.165205]\n",
      "epoch:0 step:681[D loss: 0.463452, acc: 65.62%, op_acc: 27.34%] [G loss: 1.147915]\n",
      "epoch:0 step:682[D loss: 0.463100, acc: 62.50%, op_acc: 31.25%] [G loss: 1.237163]\n",
      "epoch:0 step:683[D loss: 0.482584, acc: 66.41%, op_acc: 28.12%] [G loss: 1.082143]\n",
      "epoch:0 step:684[D loss: 0.465119, acc: 62.50%, op_acc: 25.78%] [G loss: 1.235466]\n",
      "epoch:0 step:685[D loss: 0.454568, acc: 67.19%, op_acc: 22.66%] [G loss: 1.046206]\n",
      "epoch:0 step:686[D loss: 0.526919, acc: 63.28%, op_acc: 21.88%] [G loss: 1.274558]\n",
      "epoch:0 step:687[D loss: 0.462326, acc: 62.50%, op_acc: 28.12%] [G loss: 1.103016]\n",
      "epoch:0 step:688[D loss: 0.479356, acc: 61.72%, op_acc: 23.44%] [G loss: 0.968842]\n",
      "epoch:0 step:689[D loss: 0.475537, acc: 62.50%, op_acc: 28.91%] [G loss: 1.057943]\n",
      "epoch:0 step:690[D loss: 0.469300, acc: 63.28%, op_acc: 28.12%] [G loss: 1.232431]\n",
      "epoch:0 step:691[D loss: 0.500159, acc: 59.38%, op_acc: 22.66%] [G loss: 1.028587]\n",
      "epoch:0 step:692[D loss: 0.574824, acc: 50.00%, op_acc: 20.31%] [G loss: 0.998390]\n",
      "epoch:0 step:693[D loss: 0.473167, acc: 66.41%, op_acc: 27.34%] [G loss: 1.071528]\n",
      "epoch:0 step:694[D loss: 0.520457, acc: 53.91%, op_acc: 22.66%] [G loss: 0.990359]\n",
      "epoch:0 step:695[D loss: 0.464901, acc: 67.97%, op_acc: 28.12%] [G loss: 1.237218]\n",
      "epoch:0 step:696[D loss: 0.503152, acc: 56.25%, op_acc: 28.12%] [G loss: 1.245594]\n",
      "epoch:0 step:697[D loss: 0.492154, acc: 63.28%, op_acc: 25.00%] [G loss: 1.057816]\n",
      "epoch:0 step:698[D loss: 0.489668, acc: 58.59%, op_acc: 20.31%] [G loss: 1.238100]\n",
      "epoch:0 step:699[D loss: 0.421708, acc: 75.00%, op_acc: 28.91%] [G loss: 1.268957]\n",
      "epoch:0 step:700[D loss: 0.469718, acc: 67.19%, op_acc: 23.44%] [G loss: 1.159826]\n",
      "##############\n",
      "[0.85885834 0.86939273 0.81024441 0.82060793 0.80010005 0.83580068\n",
      " 0.88716343 0.82393921 0.80828233 0.82002508]\n",
      "##########\n",
      "epoch:0 step:701[D loss: 0.454124, acc: 68.75%, op_acc: 25.78%] [G loss: 1.048349]\n",
      "epoch:0 step:702[D loss: 0.473098, acc: 62.50%, op_acc: 27.34%] [G loss: 1.027398]\n",
      "epoch:0 step:703[D loss: 0.415876, acc: 72.66%, op_acc: 26.56%] [G loss: 1.197540]\n",
      "epoch:0 step:704[D loss: 0.417478, acc: 70.31%, op_acc: 35.94%] [G loss: 1.258136]\n",
      "epoch:0 step:705[D loss: 0.437934, acc: 73.44%, op_acc: 21.09%] [G loss: 1.007167]\n",
      "epoch:0 step:706[D loss: 0.450840, acc: 71.09%, op_acc: 27.34%] [G loss: 1.044035]\n",
      "epoch:0 step:707[D loss: 0.488288, acc: 63.28%, op_acc: 27.34%] [G loss: 1.068278]\n",
      "epoch:0 step:708[D loss: 0.497482, acc: 64.06%, op_acc: 22.66%] [G loss: 1.195762]\n",
      "epoch:0 step:709[D loss: 0.554007, acc: 56.25%, op_acc: 23.44%] [G loss: 1.131658]\n",
      "epoch:0 step:710[D loss: 0.437079, acc: 63.28%, op_acc: 31.25%] [G loss: 1.148432]\n",
      "epoch:0 step:711[D loss: 0.460381, acc: 67.19%, op_acc: 29.69%] [G loss: 0.945250]\n",
      "epoch:0 step:712[D loss: 0.437268, acc: 68.75%, op_acc: 24.22%] [G loss: 1.237950]\n",
      "epoch:0 step:713[D loss: 0.452568, acc: 69.53%, op_acc: 28.12%] [G loss: 1.244713]\n",
      "epoch:0 step:714[D loss: 0.449645, acc: 66.41%, op_acc: 25.78%] [G loss: 1.091832]\n",
      "epoch:0 step:715[D loss: 0.494160, acc: 56.25%, op_acc: 29.69%] [G loss: 1.005446]\n",
      "epoch:0 step:716[D loss: 0.485620, acc: 60.94%, op_acc: 21.09%] [G loss: 1.102418]\n",
      "epoch:0 step:717[D loss: 0.453089, acc: 68.75%, op_acc: 28.91%] [G loss: 1.088607]\n",
      "epoch:0 step:718[D loss: 0.491134, acc: 63.28%, op_acc: 31.25%] [G loss: 1.110693]\n",
      "epoch:0 step:719[D loss: 0.457645, acc: 67.97%, op_acc: 19.53%] [G loss: 1.056535]\n",
      "epoch:0 step:720[D loss: 0.436538, acc: 70.31%, op_acc: 26.56%] [G loss: 1.015034]\n",
      "epoch:0 step:721[D loss: 0.482664, acc: 56.25%, op_acc: 29.69%] [G loss: 1.274446]\n",
      "epoch:0 step:722[D loss: 0.447423, acc: 65.62%, op_acc: 30.47%] [G loss: 1.079239]\n",
      "epoch:0 step:723[D loss: 0.488027, acc: 60.16%, op_acc: 31.25%] [G loss: 1.040829]\n",
      "epoch:0 step:724[D loss: 0.483426, acc: 60.94%, op_acc: 23.44%] [G loss: 1.047832]\n",
      "epoch:0 step:725[D loss: 0.428252, acc: 67.97%, op_acc: 26.56%] [G loss: 1.120003]\n",
      "epoch:0 step:726[D loss: 0.404796, acc: 73.44%, op_acc: 29.69%] [G loss: 1.127666]\n",
      "epoch:0 step:727[D loss: 0.523290, acc: 65.62%, op_acc: 21.88%] [G loss: 1.146604]\n",
      "epoch:0 step:728[D loss: 0.473744, acc: 69.53%, op_acc: 22.66%] [G loss: 1.159462]\n",
      "epoch:0 step:729[D loss: 0.501454, acc: 54.69%, op_acc: 29.69%] [G loss: 1.018989]\n",
      "epoch:0 step:730[D loss: 0.483413, acc: 62.50%, op_acc: 28.12%] [G loss: 1.355532]\n",
      "epoch:0 step:731[D loss: 0.433886, acc: 68.75%, op_acc: 35.16%] [G loss: 1.094186]\n",
      "epoch:0 step:732[D loss: 0.435858, acc: 68.75%, op_acc: 24.22%] [G loss: 1.191142]\n",
      "epoch:0 step:733[D loss: 0.452170, acc: 64.06%, op_acc: 24.22%] [G loss: 1.162077]\n",
      "epoch:0 step:734[D loss: 0.502180, acc: 60.16%, op_acc: 26.56%] [G loss: 1.023933]\n",
      "epoch:0 step:735[D loss: 0.474817, acc: 60.94%, op_acc: 22.66%] [G loss: 1.078065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:736[D loss: 0.497539, acc: 63.28%, op_acc: 20.31%] [G loss: 1.146980]\n",
      "epoch:0 step:737[D loss: 0.450964, acc: 60.16%, op_acc: 29.69%] [G loss: 1.058690]\n",
      "epoch:0 step:738[D loss: 0.480591, acc: 59.38%, op_acc: 31.25%] [G loss: 1.133902]\n",
      "epoch:0 step:739[D loss: 0.422793, acc: 67.19%, op_acc: 29.69%] [G loss: 1.183251]\n",
      "epoch:0 step:740[D loss: 0.456371, acc: 67.97%, op_acc: 32.03%] [G loss: 1.061530]\n",
      "epoch:0 step:741[D loss: 0.510905, acc: 58.59%, op_acc: 24.22%] [G loss: 1.174920]\n",
      "epoch:0 step:742[D loss: 0.466730, acc: 67.97%, op_acc: 28.91%] [G loss: 1.120197]\n",
      "epoch:0 step:743[D loss: 0.504615, acc: 65.62%, op_acc: 26.56%] [G loss: 1.160865]\n",
      "epoch:0 step:744[D loss: 0.433348, acc: 68.75%, op_acc: 36.72%] [G loss: 1.241609]\n",
      "epoch:0 step:745[D loss: 0.479048, acc: 60.16%, op_acc: 29.69%] [G loss: 0.987308]\n",
      "epoch:0 step:746[D loss: 0.494788, acc: 65.62%, op_acc: 25.78%] [G loss: 1.129670]\n",
      "epoch:0 step:747[D loss: 0.414320, acc: 70.31%, op_acc: 30.47%] [G loss: 1.336589]\n",
      "epoch:0 step:748[D loss: 0.462598, acc: 67.19%, op_acc: 20.31%] [G loss: 1.096619]\n",
      "epoch:0 step:749[D loss: 0.495578, acc: 64.06%, op_acc: 22.66%] [G loss: 1.035256]\n",
      "epoch:0 step:750[D loss: 0.523423, acc: 52.34%, op_acc: 23.44%] [G loss: 1.124949]\n",
      "##############\n",
      "[0.86699697 0.85257713 0.79958996 0.81665622 0.77867562 0.829949\n",
      " 0.91549755 0.81165678 0.82000539 0.84776386]\n",
      "##########\n",
      "epoch:0 step:751[D loss: 0.484339, acc: 66.41%, op_acc: 24.22%] [G loss: 1.234690]\n",
      "epoch:0 step:752[D loss: 0.492244, acc: 64.06%, op_acc: 29.69%] [G loss: 1.098765]\n",
      "epoch:0 step:753[D loss: 0.481088, acc: 67.19%, op_acc: 25.00%] [G loss: 1.058766]\n",
      "epoch:0 step:754[D loss: 0.510656, acc: 58.59%, op_acc: 29.69%] [G loss: 1.159897]\n",
      "epoch:0 step:755[D loss: 0.461677, acc: 61.72%, op_acc: 29.69%] [G loss: 0.998828]\n",
      "epoch:0 step:756[D loss: 0.514279, acc: 55.47%, op_acc: 31.25%] [G loss: 0.979667]\n",
      "epoch:0 step:757[D loss: 0.481224, acc: 63.28%, op_acc: 25.00%] [G loss: 1.083418]\n",
      "epoch:0 step:758[D loss: 0.437032, acc: 67.97%, op_acc: 32.03%] [G loss: 1.232399]\n",
      "epoch:0 step:759[D loss: 0.473346, acc: 65.62%, op_acc: 21.09%] [G loss: 1.073241]\n",
      "epoch:0 step:760[D loss: 0.487185, acc: 60.94%, op_acc: 28.12%] [G loss: 1.183550]\n",
      "epoch:0 step:761[D loss: 0.468715, acc: 61.72%, op_acc: 31.25%] [G loss: 1.150965]\n",
      "epoch:0 step:762[D loss: 0.480341, acc: 64.06%, op_acc: 25.78%] [G loss: 1.175861]\n",
      "epoch:0 step:763[D loss: 0.472365, acc: 66.41%, op_acc: 25.78%] [G loss: 1.019448]\n",
      "epoch:0 step:764[D loss: 0.444056, acc: 67.97%, op_acc: 25.78%] [G loss: 1.253187]\n",
      "epoch:0 step:765[D loss: 0.509225, acc: 57.03%, op_acc: 25.00%] [G loss: 1.102978]\n",
      "epoch:0 step:766[D loss: 0.496000, acc: 56.25%, op_acc: 23.44%] [G loss: 1.122947]\n",
      "epoch:0 step:767[D loss: 0.482141, acc: 60.94%, op_acc: 28.12%] [G loss: 1.233082]\n",
      "epoch:0 step:768[D loss: 0.485036, acc: 58.59%, op_acc: 25.00%] [G loss: 1.097935]\n",
      "epoch:0 step:769[D loss: 0.480289, acc: 60.16%, op_acc: 31.25%] [G loss: 1.080081]\n",
      "epoch:0 step:770[D loss: 0.461681, acc: 60.16%, op_acc: 25.78%] [G loss: 1.099748]\n",
      "epoch:0 step:771[D loss: 0.483578, acc: 60.16%, op_acc: 25.00%] [G loss: 1.181287]\n",
      "epoch:0 step:772[D loss: 0.423898, acc: 70.31%, op_acc: 31.25%] [G loss: 1.124267]\n",
      "epoch:0 step:773[D loss: 0.495456, acc: 58.59%, op_acc: 26.56%] [G loss: 1.082777]\n",
      "epoch:0 step:774[D loss: 0.463606, acc: 71.88%, op_acc: 26.56%] [G loss: 1.160950]\n",
      "epoch:0 step:775[D loss: 0.465880, acc: 69.53%, op_acc: 28.12%] [G loss: 1.202321]\n",
      "epoch:0 step:776[D loss: 0.456697, acc: 64.06%, op_acc: 25.78%] [G loss: 0.941944]\n",
      "epoch:0 step:777[D loss: 0.482042, acc: 64.06%, op_acc: 24.22%] [G loss: 1.028843]\n",
      "epoch:0 step:778[D loss: 0.461178, acc: 64.84%, op_acc: 27.34%] [G loss: 1.049322]\n",
      "epoch:0 step:779[D loss: 0.502615, acc: 56.25%, op_acc: 29.69%] [G loss: 0.873544]\n",
      "epoch:0 step:780[D loss: 0.467725, acc: 57.81%, op_acc: 27.34%] [G loss: 0.911890]\n",
      "epoch:0 step:781[D loss: 0.450781, acc: 66.41%, op_acc: 25.00%] [G loss: 1.097900]\n",
      "epoch:1 step:782[D loss: 0.469104, acc: 71.09%, op_acc: 27.34%] [G loss: 1.132022]\n",
      "epoch:1 step:783[D loss: 0.476665, acc: 59.38%, op_acc: 28.91%] [G loss: 1.005315]\n",
      "epoch:1 step:784[D loss: 0.501735, acc: 56.25%, op_acc: 20.31%] [G loss: 0.907859]\n",
      "epoch:1 step:785[D loss: 0.425993, acc: 64.84%, op_acc: 30.47%] [G loss: 1.190507]\n",
      "epoch:1 step:786[D loss: 0.495338, acc: 60.16%, op_acc: 25.00%] [G loss: 1.022957]\n",
      "epoch:1 step:787[D loss: 0.459339, acc: 61.72%, op_acc: 32.81%] [G loss: 1.072405]\n",
      "epoch:1 step:788[D loss: 0.491169, acc: 60.16%, op_acc: 27.34%] [G loss: 1.089749]\n",
      "epoch:1 step:789[D loss: 0.502669, acc: 54.69%, op_acc: 26.56%] [G loss: 1.272933]\n",
      "epoch:1 step:790[D loss: 0.422277, acc: 71.88%, op_acc: 29.69%] [G loss: 1.108520]\n",
      "epoch:1 step:791[D loss: 0.486688, acc: 64.06%, op_acc: 29.69%] [G loss: 1.225915]\n",
      "epoch:1 step:792[D loss: 0.532685, acc: 49.22%, op_acc: 28.91%] [G loss: 1.168308]\n",
      "epoch:1 step:793[D loss: 0.442273, acc: 65.62%, op_acc: 33.59%] [G loss: 1.318329]\n",
      "epoch:1 step:794[D loss: 0.456603, acc: 66.41%, op_acc: 31.25%] [G loss: 1.179785]\n",
      "epoch:1 step:795[D loss: 0.458929, acc: 64.84%, op_acc: 27.34%] [G loss: 1.252775]\n",
      "epoch:1 step:796[D loss: 0.505459, acc: 57.81%, op_acc: 24.22%] [G loss: 1.204764]\n",
      "epoch:1 step:797[D loss: 0.476985, acc: 60.16%, op_acc: 21.09%] [G loss: 1.010629]\n",
      "epoch:1 step:798[D loss: 0.491123, acc: 57.81%, op_acc: 28.91%] [G loss: 1.001279]\n",
      "epoch:1 step:799[D loss: 0.467663, acc: 64.06%, op_acc: 28.91%] [G loss: 1.082483]\n",
      "epoch:1 step:800[D loss: 0.499019, acc: 50.00%, op_acc: 26.56%] [G loss: 1.067976]\n",
      "##############\n",
      "[0.85388823 0.8736672  0.82965826 0.85192278 0.79807411 0.83096509\n",
      " 0.88612604 0.82385901 0.81918709 0.81897584]\n",
      "##########\n",
      "epoch:1 step:801[D loss: 0.485445, acc: 59.38%, op_acc: 23.44%] [G loss: 1.204576]\n",
      "epoch:1 step:802[D loss: 0.463993, acc: 68.75%, op_acc: 24.22%] [G loss: 1.121242]\n",
      "epoch:1 step:803[D loss: 0.505832, acc: 53.91%, op_acc: 32.03%] [G loss: 1.054303]\n",
      "epoch:1 step:804[D loss: 0.472872, acc: 61.72%, op_acc: 29.69%] [G loss: 0.916753]\n",
      "epoch:1 step:805[D loss: 0.477919, acc: 67.19%, op_acc: 32.81%] [G loss: 1.041481]\n",
      "epoch:1 step:806[D loss: 0.466104, acc: 64.06%, op_acc: 32.03%] [G loss: 1.152618]\n",
      "epoch:1 step:807[D loss: 0.421220, acc: 65.62%, op_acc: 35.94%] [G loss: 1.043739]\n",
      "epoch:1 step:808[D loss: 0.488508, acc: 61.72%, op_acc: 23.44%] [G loss: 1.163482]\n",
      "epoch:1 step:809[D loss: 0.474935, acc: 58.59%, op_acc: 26.56%] [G loss: 1.164206]\n",
      "epoch:1 step:810[D loss: 0.497280, acc: 57.81%, op_acc: 31.25%] [G loss: 1.067803]\n",
      "epoch:1 step:811[D loss: 0.471838, acc: 56.25%, op_acc: 32.03%] [G loss: 1.064683]\n",
      "epoch:1 step:812[D loss: 0.492569, acc: 60.94%, op_acc: 27.34%] [G loss: 1.134298]\n",
      "epoch:1 step:813[D loss: 0.459048, acc: 65.62%, op_acc: 27.34%] [G loss: 1.115972]\n",
      "epoch:1 step:814[D loss: 0.505328, acc: 54.69%, op_acc: 23.44%] [G loss: 1.038582]\n",
      "epoch:1 step:815[D loss: 0.442377, acc: 63.28%, op_acc: 32.81%] [G loss: 1.113929]\n",
      "epoch:1 step:816[D loss: 0.459265, acc: 61.72%, op_acc: 33.59%] [G loss: 1.113606]\n",
      "epoch:1 step:817[D loss: 0.485009, acc: 59.38%, op_acc: 25.78%] [G loss: 1.067421]\n",
      "epoch:1 step:818[D loss: 0.471990, acc: 60.16%, op_acc: 26.56%] [G loss: 1.039290]\n",
      "epoch:1 step:819[D loss: 0.441435, acc: 61.72%, op_acc: 34.38%] [G loss: 1.226570]\n",
      "epoch:1 step:820[D loss: 0.419046, acc: 73.44%, op_acc: 24.22%] [G loss: 1.106796]\n",
      "epoch:1 step:821[D loss: 0.461864, acc: 68.75%, op_acc: 23.44%] [G loss: 1.016262]\n",
      "epoch:1 step:822[D loss: 0.489166, acc: 55.47%, op_acc: 21.88%] [G loss: 1.088693]\n",
      "epoch:1 step:823[D loss: 0.476401, acc: 63.28%, op_acc: 27.34%] [G loss: 0.946066]\n",
      "epoch:1 step:824[D loss: 0.523890, acc: 54.69%, op_acc: 25.00%] [G loss: 1.046174]\n",
      "epoch:1 step:825[D loss: 0.471802, acc: 63.28%, op_acc: 21.88%] [G loss: 1.064484]\n",
      "epoch:1 step:826[D loss: 0.519398, acc: 46.88%, op_acc: 25.00%] [G loss: 1.190457]\n",
      "epoch:1 step:827[D loss: 0.489526, acc: 59.38%, op_acc: 31.25%] [G loss: 1.038363]\n",
      "epoch:1 step:828[D loss: 0.476687, acc: 66.41%, op_acc: 25.00%] [G loss: 1.138370]\n",
      "epoch:1 step:829[D loss: 0.464823, acc: 64.84%, op_acc: 28.91%] [G loss: 0.952280]\n",
      "epoch:1 step:830[D loss: 0.439546, acc: 67.19%, op_acc: 32.81%] [G loss: 0.955338]\n",
      "epoch:1 step:831[D loss: 0.539321, acc: 52.34%, op_acc: 26.56%] [G loss: 1.064921]\n",
      "epoch:1 step:832[D loss: 0.454058, acc: 67.97%, op_acc: 30.47%] [G loss: 1.002177]\n",
      "epoch:1 step:833[D loss: 0.483787, acc: 58.59%, op_acc: 27.34%] [G loss: 1.010359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:834[D loss: 0.489022, acc: 60.94%, op_acc: 22.66%] [G loss: 1.056854]\n",
      "epoch:1 step:835[D loss: 0.500575, acc: 64.84%, op_acc: 23.44%] [G loss: 1.077386]\n",
      "epoch:1 step:836[D loss: 0.468761, acc: 56.25%, op_acc: 23.44%] [G loss: 1.037625]\n",
      "epoch:1 step:837[D loss: 0.494223, acc: 57.03%, op_acc: 23.44%] [G loss: 1.033855]\n",
      "epoch:1 step:838[D loss: 0.496263, acc: 59.38%, op_acc: 22.66%] [G loss: 1.064415]\n",
      "epoch:1 step:839[D loss: 0.472345, acc: 60.94%, op_acc: 27.34%] [G loss: 1.008294]\n",
      "epoch:1 step:840[D loss: 0.503724, acc: 48.44%, op_acc: 33.59%] [G loss: 1.020071]\n",
      "epoch:1 step:841[D loss: 0.477253, acc: 59.38%, op_acc: 25.00%] [G loss: 1.006286]\n",
      "epoch:1 step:842[D loss: 0.503768, acc: 57.03%, op_acc: 24.22%] [G loss: 1.107682]\n",
      "epoch:1 step:843[D loss: 0.475983, acc: 61.72%, op_acc: 25.00%] [G loss: 1.226708]\n",
      "epoch:1 step:844[D loss: 0.501276, acc: 57.03%, op_acc: 24.22%] [G loss: 1.217286]\n",
      "epoch:1 step:845[D loss: 0.476748, acc: 64.06%, op_acc: 28.91%] [G loss: 1.121450]\n",
      "epoch:1 step:846[D loss: 0.490752, acc: 60.94%, op_acc: 24.22%] [G loss: 1.164085]\n",
      "epoch:1 step:847[D loss: 0.435693, acc: 70.31%, op_acc: 26.56%] [G loss: 1.030893]\n",
      "epoch:1 step:848[D loss: 0.470537, acc: 56.25%, op_acc: 28.91%] [G loss: 1.126718]\n",
      "epoch:1 step:849[D loss: 0.461514, acc: 64.84%, op_acc: 28.12%] [G loss: 1.065520]\n",
      "epoch:1 step:850[D loss: 0.484006, acc: 55.47%, op_acc: 28.12%] [G loss: 0.886743]\n",
      "##############\n",
      "[0.85035711 0.86627996 0.80959382 0.83087955 0.80322311 0.82544468\n",
      " 0.90279731 0.8313261  0.79811885 0.8301513 ]\n",
      "##########\n",
      "epoch:1 step:851[D loss: 0.466856, acc: 59.38%, op_acc: 32.03%] [G loss: 1.243216]\n",
      "epoch:1 step:852[D loss: 0.484036, acc: 62.50%, op_acc: 21.88%] [G loss: 1.078558]\n",
      "epoch:1 step:853[D loss: 0.427328, acc: 67.97%, op_acc: 28.12%] [G loss: 0.977673]\n",
      "epoch:1 step:854[D loss: 0.437029, acc: 64.84%, op_acc: 31.25%] [G loss: 1.104518]\n",
      "epoch:1 step:855[D loss: 0.428840, acc: 65.62%, op_acc: 30.47%] [G loss: 1.262638]\n",
      "epoch:1 step:856[D loss: 0.497341, acc: 56.25%, op_acc: 23.44%] [G loss: 1.119884]\n",
      "epoch:1 step:857[D loss: 0.472167, acc: 64.06%, op_acc: 29.69%] [G loss: 0.992597]\n",
      "epoch:1 step:858[D loss: 0.476767, acc: 62.50%, op_acc: 30.47%] [G loss: 1.120107]\n",
      "epoch:1 step:859[D loss: 0.490421, acc: 62.50%, op_acc: 22.66%] [G loss: 1.089157]\n",
      "epoch:1 step:860[D loss: 0.499227, acc: 57.81%, op_acc: 24.22%] [G loss: 0.959522]\n",
      "epoch:1 step:861[D loss: 0.518543, acc: 56.25%, op_acc: 17.97%] [G loss: 0.893862]\n",
      "epoch:1 step:862[D loss: 0.500902, acc: 57.81%, op_acc: 22.66%] [G loss: 1.041951]\n",
      "epoch:1 step:863[D loss: 0.470203, acc: 60.16%, op_acc: 27.34%] [G loss: 1.031008]\n",
      "epoch:1 step:864[D loss: 0.512861, acc: 57.03%, op_acc: 28.12%] [G loss: 1.070619]\n",
      "epoch:1 step:865[D loss: 0.495947, acc: 60.16%, op_acc: 28.12%] [G loss: 1.115999]\n",
      "epoch:1 step:866[D loss: 0.471453, acc: 64.06%, op_acc: 21.09%] [G loss: 1.118637]\n",
      "epoch:1 step:867[D loss: 0.512439, acc: 53.91%, op_acc: 25.78%] [G loss: 1.079618]\n",
      "epoch:1 step:868[D loss: 0.503670, acc: 56.25%, op_acc: 28.12%] [G loss: 1.003915]\n",
      "epoch:1 step:869[D loss: 0.426134, acc: 64.84%, op_acc: 33.59%] [G loss: 1.069889]\n",
      "epoch:1 step:870[D loss: 0.471640, acc: 65.62%, op_acc: 29.69%] [G loss: 1.132548]\n",
      "epoch:1 step:871[D loss: 0.443398, acc: 68.75%, op_acc: 28.12%] [G loss: 1.036492]\n",
      "epoch:1 step:872[D loss: 0.510804, acc: 57.03%, op_acc: 21.09%] [G loss: 1.117922]\n",
      "epoch:1 step:873[D loss: 0.480930, acc: 60.16%, op_acc: 25.00%] [G loss: 1.103033]\n",
      "epoch:1 step:874[D loss: 0.468522, acc: 60.16%, op_acc: 27.34%] [G loss: 1.075956]\n",
      "epoch:1 step:875[D loss: 0.436694, acc: 70.31%, op_acc: 28.12%] [G loss: 1.134650]\n",
      "epoch:1 step:876[D loss: 0.488011, acc: 64.06%, op_acc: 21.88%] [G loss: 1.145316]\n",
      "epoch:1 step:877[D loss: 0.470416, acc: 64.06%, op_acc: 23.44%] [G loss: 1.137439]\n",
      "epoch:1 step:878[D loss: 0.479891, acc: 59.38%, op_acc: 31.25%] [G loss: 1.056366]\n",
      "epoch:1 step:879[D loss: 0.465773, acc: 66.41%, op_acc: 24.22%] [G loss: 1.139596]\n",
      "epoch:1 step:880[D loss: 0.461099, acc: 64.06%, op_acc: 34.38%] [G loss: 1.176301]\n",
      "epoch:1 step:881[D loss: 0.447900, acc: 67.97%, op_acc: 22.66%] [G loss: 1.211563]\n",
      "epoch:1 step:882[D loss: 0.495586, acc: 57.03%, op_acc: 28.12%] [G loss: 0.995253]\n",
      "epoch:1 step:883[D loss: 0.447767, acc: 66.41%, op_acc: 30.47%] [G loss: 1.181449]\n",
      "epoch:1 step:884[D loss: 0.489485, acc: 60.94%, op_acc: 25.00%] [G loss: 1.043002]\n",
      "epoch:1 step:885[D loss: 0.474141, acc: 61.72%, op_acc: 21.88%] [G loss: 1.219231]\n",
      "epoch:1 step:886[D loss: 0.463850, acc: 64.06%, op_acc: 29.69%] [G loss: 1.129023]\n",
      "epoch:1 step:887[D loss: 0.478010, acc: 66.41%, op_acc: 28.12%] [G loss: 1.066947]\n",
      "epoch:1 step:888[D loss: 0.497005, acc: 55.47%, op_acc: 28.91%] [G loss: 1.181382]\n",
      "epoch:1 step:889[D loss: 0.557036, acc: 50.78%, op_acc: 16.41%] [G loss: 1.038681]\n",
      "epoch:1 step:890[D loss: 0.468896, acc: 63.28%, op_acc: 23.44%] [G loss: 1.152781]\n",
      "epoch:1 step:891[D loss: 0.445537, acc: 61.72%, op_acc: 29.69%] [G loss: 1.109474]\n",
      "epoch:1 step:892[D loss: 0.484789, acc: 59.38%, op_acc: 32.03%] [G loss: 0.924607]\n",
      "epoch:1 step:893[D loss: 0.461275, acc: 60.94%, op_acc: 24.22%] [G loss: 1.052976]\n",
      "epoch:1 step:894[D loss: 0.468683, acc: 65.62%, op_acc: 23.44%] [G loss: 1.051285]\n",
      "epoch:1 step:895[D loss: 0.446488, acc: 64.84%, op_acc: 31.25%] [G loss: 1.079420]\n",
      "epoch:1 step:896[D loss: 0.482832, acc: 56.25%, op_acc: 25.00%] [G loss: 1.095218]\n",
      "epoch:1 step:897[D loss: 0.530295, acc: 52.34%, op_acc: 25.00%] [G loss: 1.146434]\n",
      "epoch:1 step:898[D loss: 0.547142, acc: 54.69%, op_acc: 24.22%] [G loss: 1.052701]\n",
      "epoch:1 step:899[D loss: 0.433754, acc: 67.19%, op_acc: 23.44%] [G loss: 0.965305]\n",
      "epoch:1 step:900[D loss: 0.518648, acc: 53.12%, op_acc: 20.31%] [G loss: 0.941862]\n",
      "##############\n",
      "[0.8792395  0.8665217  0.81039584 0.83276359 0.82471888 0.8325126\n",
      " 0.89893218 0.81657158 0.7984275  0.82416964]\n",
      "##########\n",
      "epoch:1 step:901[D loss: 0.511110, acc: 55.47%, op_acc: 28.91%] [G loss: 0.967159]\n",
      "epoch:1 step:902[D loss: 0.507710, acc: 55.47%, op_acc: 24.22%] [G loss: 0.928265]\n",
      "epoch:1 step:903[D loss: 0.486113, acc: 58.59%, op_acc: 23.44%] [G loss: 0.892876]\n",
      "epoch:1 step:904[D loss: 0.479838, acc: 62.50%, op_acc: 25.00%] [G loss: 1.089072]\n",
      "epoch:1 step:905[D loss: 0.477418, acc: 55.47%, op_acc: 30.47%] [G loss: 1.059831]\n",
      "epoch:1 step:906[D loss: 0.526015, acc: 57.81%, op_acc: 26.56%] [G loss: 0.941432]\n",
      "epoch:1 step:907[D loss: 0.461714, acc: 60.94%, op_acc: 31.25%] [G loss: 1.098648]\n",
      "epoch:1 step:908[D loss: 0.454462, acc: 64.84%, op_acc: 25.00%] [G loss: 1.086287]\n",
      "epoch:1 step:909[D loss: 0.491006, acc: 61.72%, op_acc: 26.56%] [G loss: 0.983609]\n",
      "epoch:1 step:910[D loss: 0.463333, acc: 61.72%, op_acc: 22.66%] [G loss: 0.974619]\n",
      "epoch:1 step:911[D loss: 0.471278, acc: 62.50%, op_acc: 29.69%] [G loss: 1.003295]\n",
      "epoch:1 step:912[D loss: 0.495107, acc: 53.91%, op_acc: 20.31%] [G loss: 1.016448]\n",
      "epoch:1 step:913[D loss: 0.462624, acc: 60.16%, op_acc: 24.22%] [G loss: 1.051581]\n",
      "epoch:1 step:914[D loss: 0.497454, acc: 60.16%, op_acc: 21.09%] [G loss: 1.234358]\n",
      "epoch:1 step:915[D loss: 0.437508, acc: 60.16%, op_acc: 32.81%] [G loss: 1.097008]\n",
      "epoch:1 step:916[D loss: 0.501796, acc: 56.25%, op_acc: 28.91%] [G loss: 1.015371]\n",
      "epoch:1 step:917[D loss: 0.423251, acc: 67.97%, op_acc: 27.34%] [G loss: 1.111138]\n",
      "epoch:1 step:918[D loss: 0.478563, acc: 57.81%, op_acc: 29.69%] [G loss: 0.954236]\n",
      "epoch:1 step:919[D loss: 0.541650, acc: 51.56%, op_acc: 18.75%] [G loss: 1.001005]\n",
      "epoch:1 step:920[D loss: 0.448988, acc: 64.84%, op_acc: 33.59%] [G loss: 1.025290]\n",
      "epoch:1 step:921[D loss: 0.500850, acc: 59.38%, op_acc: 23.44%] [G loss: 1.014659]\n",
      "epoch:1 step:922[D loss: 0.510695, acc: 61.72%, op_acc: 24.22%] [G loss: 1.014399]\n",
      "epoch:1 step:923[D loss: 0.492795, acc: 60.16%, op_acc: 25.00%] [G loss: 1.061967]\n",
      "epoch:1 step:924[D loss: 0.465152, acc: 64.84%, op_acc: 30.47%] [G loss: 1.023497]\n",
      "epoch:1 step:925[D loss: 0.508323, acc: 61.72%, op_acc: 28.12%] [G loss: 1.019503]\n",
      "epoch:1 step:926[D loss: 0.436147, acc: 67.97%, op_acc: 31.25%] [G loss: 1.094551]\n",
      "epoch:1 step:927[D loss: 0.490946, acc: 57.81%, op_acc: 25.00%] [G loss: 1.003238]\n",
      "epoch:1 step:928[D loss: 0.475540, acc: 55.47%, op_acc: 28.12%] [G loss: 1.095806]\n",
      "epoch:1 step:929[D loss: 0.448464, acc: 66.41%, op_acc: 30.47%] [G loss: 0.951184]\n",
      "epoch:1 step:930[D loss: 0.485443, acc: 60.16%, op_acc: 24.22%] [G loss: 0.986147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:931[D loss: 0.437413, acc: 64.06%, op_acc: 32.81%] [G loss: 1.048688]\n",
      "epoch:1 step:932[D loss: 0.483522, acc: 64.06%, op_acc: 29.69%] [G loss: 0.975818]\n",
      "epoch:1 step:933[D loss: 0.480303, acc: 58.59%, op_acc: 20.31%] [G loss: 1.146479]\n",
      "epoch:1 step:934[D loss: 0.476953, acc: 65.62%, op_acc: 27.34%] [G loss: 0.963405]\n",
      "epoch:1 step:935[D loss: 0.485315, acc: 59.38%, op_acc: 23.44%] [G loss: 1.012628]\n",
      "epoch:1 step:936[D loss: 0.463721, acc: 65.62%, op_acc: 21.88%] [G loss: 0.958972]\n",
      "epoch:1 step:937[D loss: 0.461689, acc: 63.28%, op_acc: 28.12%] [G loss: 1.056233]\n",
      "epoch:1 step:938[D loss: 0.483793, acc: 60.94%, op_acc: 26.56%] [G loss: 1.042608]\n",
      "epoch:1 step:939[D loss: 0.489127, acc: 60.16%, op_acc: 24.22%] [G loss: 1.071413]\n",
      "epoch:1 step:940[D loss: 0.474067, acc: 63.28%, op_acc: 29.69%] [G loss: 1.096369]\n",
      "epoch:1 step:941[D loss: 0.521302, acc: 62.50%, op_acc: 19.53%] [G loss: 1.006379]\n",
      "epoch:1 step:942[D loss: 0.490668, acc: 59.38%, op_acc: 23.44%] [G loss: 1.017055]\n",
      "epoch:1 step:943[D loss: 0.445211, acc: 63.28%, op_acc: 25.78%] [G loss: 1.115600]\n",
      "epoch:1 step:944[D loss: 0.477118, acc: 61.72%, op_acc: 29.69%] [G loss: 1.053739]\n",
      "epoch:1 step:945[D loss: 0.516912, acc: 61.72%, op_acc: 23.44%] [G loss: 1.035628]\n",
      "epoch:1 step:946[D loss: 0.448059, acc: 64.84%, op_acc: 28.91%] [G loss: 1.069666]\n",
      "epoch:1 step:947[D loss: 0.497434, acc: 59.38%, op_acc: 29.69%] [G loss: 1.057211]\n",
      "epoch:1 step:948[D loss: 0.462031, acc: 64.06%, op_acc: 27.34%] [G loss: 1.165599]\n",
      "epoch:1 step:949[D loss: 0.452108, acc: 64.84%, op_acc: 27.34%] [G loss: 1.038179]\n",
      "epoch:1 step:950[D loss: 0.488106, acc: 58.59%, op_acc: 29.69%] [G loss: 0.877028]\n",
      "##############\n",
      "[0.854116   0.85483961 0.80405251 0.80849217 0.78738968 0.83062693\n",
      " 0.89963722 0.82982397 0.80867876 0.84390966]\n",
      "##########\n",
      "epoch:1 step:951[D loss: 0.454327, acc: 64.84%, op_acc: 35.16%] [G loss: 1.082436]\n",
      "epoch:1 step:952[D loss: 0.469007, acc: 64.06%, op_acc: 24.22%] [G loss: 1.117818]\n",
      "epoch:1 step:953[D loss: 0.439433, acc: 62.50%, op_acc: 29.69%] [G loss: 0.972430]\n",
      "epoch:1 step:954[D loss: 0.497738, acc: 60.16%, op_acc: 22.66%] [G loss: 1.056649]\n",
      "epoch:1 step:955[D loss: 0.511314, acc: 58.59%, op_acc: 25.00%] [G loss: 1.039384]\n",
      "epoch:1 step:956[D loss: 0.437496, acc: 75.00%, op_acc: 26.56%] [G loss: 0.995717]\n",
      "epoch:1 step:957[D loss: 0.513990, acc: 51.56%, op_acc: 27.34%] [G loss: 1.109138]\n",
      "epoch:1 step:958[D loss: 0.448902, acc: 61.72%, op_acc: 27.34%] [G loss: 1.199087]\n",
      "epoch:1 step:959[D loss: 0.497992, acc: 60.16%, op_acc: 26.56%] [G loss: 1.153878]\n",
      "epoch:1 step:960[D loss: 0.498520, acc: 60.16%, op_acc: 22.66%] [G loss: 1.050896]\n",
      "epoch:1 step:961[D loss: 0.450433, acc: 64.06%, op_acc: 25.00%] [G loss: 0.932902]\n",
      "epoch:1 step:962[D loss: 0.455985, acc: 60.16%, op_acc: 23.44%] [G loss: 1.049787]\n",
      "epoch:1 step:963[D loss: 0.477026, acc: 58.59%, op_acc: 28.91%] [G loss: 1.002880]\n",
      "epoch:1 step:964[D loss: 0.504846, acc: 57.03%, op_acc: 26.56%] [G loss: 0.906216]\n",
      "epoch:1 step:965[D loss: 0.495747, acc: 54.69%, op_acc: 27.34%] [G loss: 1.209834]\n",
      "epoch:1 step:966[D loss: 0.446668, acc: 68.75%, op_acc: 29.69%] [G loss: 1.173122]\n",
      "epoch:1 step:967[D loss: 0.421122, acc: 71.09%, op_acc: 36.72%] [G loss: 1.190541]\n",
      "epoch:1 step:968[D loss: 0.493143, acc: 51.56%, op_acc: 34.38%] [G loss: 0.988551]\n",
      "epoch:1 step:969[D loss: 0.546605, acc: 49.22%, op_acc: 27.34%] [G loss: 0.937458]\n",
      "epoch:1 step:970[D loss: 0.455153, acc: 70.31%, op_acc: 28.12%] [G loss: 0.993438]\n",
      "epoch:1 step:971[D loss: 0.509302, acc: 57.03%, op_acc: 22.66%] [G loss: 0.877418]\n",
      "epoch:1 step:972[D loss: 0.459189, acc: 60.16%, op_acc: 30.47%] [G loss: 1.024931]\n",
      "epoch:1 step:973[D loss: 0.472118, acc: 57.81%, op_acc: 27.34%] [G loss: 1.085092]\n",
      "epoch:1 step:974[D loss: 0.499025, acc: 60.94%, op_acc: 28.12%] [G loss: 0.948657]\n",
      "epoch:1 step:975[D loss: 0.468078, acc: 60.94%, op_acc: 29.69%] [G loss: 0.996707]\n",
      "epoch:1 step:976[D loss: 0.468729, acc: 57.81%, op_acc: 27.34%] [G loss: 0.969545]\n",
      "epoch:1 step:977[D loss: 0.451637, acc: 64.06%, op_acc: 27.34%] [G loss: 0.954337]\n",
      "epoch:1 step:978[D loss: 0.528334, acc: 53.91%, op_acc: 24.22%] [G loss: 0.907496]\n",
      "epoch:1 step:979[D loss: 0.508010, acc: 55.47%, op_acc: 24.22%] [G loss: 1.001171]\n",
      "epoch:1 step:980[D loss: 0.543020, acc: 55.47%, op_acc: 22.66%] [G loss: 1.044428]\n",
      "epoch:1 step:981[D loss: 0.489034, acc: 59.38%, op_acc: 26.56%] [G loss: 0.991151]\n",
      "epoch:1 step:982[D loss: 0.459817, acc: 56.25%, op_acc: 25.00%] [G loss: 0.970205]\n",
      "epoch:1 step:983[D loss: 0.502190, acc: 60.16%, op_acc: 25.00%] [G loss: 0.982747]\n",
      "epoch:1 step:984[D loss: 0.473786, acc: 63.28%, op_acc: 28.12%] [G loss: 0.941553]\n",
      "epoch:1 step:985[D loss: 0.493247, acc: 62.50%, op_acc: 26.56%] [G loss: 1.024043]\n",
      "epoch:1 step:986[D loss: 0.442478, acc: 68.75%, op_acc: 25.78%] [G loss: 1.094938]\n",
      "epoch:1 step:987[D loss: 0.486717, acc: 64.06%, op_acc: 24.22%] [G loss: 0.972017]\n",
      "epoch:1 step:988[D loss: 0.469389, acc: 68.75%, op_acc: 29.69%] [G loss: 1.014580]\n",
      "epoch:1 step:989[D loss: 0.509913, acc: 56.25%, op_acc: 25.00%] [G loss: 1.035717]\n",
      "epoch:1 step:990[D loss: 0.475241, acc: 59.38%, op_acc: 28.91%] [G loss: 1.071083]\n",
      "epoch:1 step:991[D loss: 0.524102, acc: 56.25%, op_acc: 19.53%] [G loss: 1.007101]\n",
      "epoch:1 step:992[D loss: 0.401821, acc: 75.00%, op_acc: 32.81%] [G loss: 1.095732]\n",
      "epoch:1 step:993[D loss: 0.460601, acc: 64.84%, op_acc: 27.34%] [G loss: 0.977102]\n",
      "epoch:1 step:994[D loss: 0.467644, acc: 59.38%, op_acc: 35.16%] [G loss: 1.042464]\n",
      "epoch:1 step:995[D loss: 0.485904, acc: 54.69%, op_acc: 29.69%] [G loss: 1.052587]\n",
      "epoch:1 step:996[D loss: 0.529107, acc: 54.69%, op_acc: 26.56%] [G loss: 1.105180]\n",
      "epoch:1 step:997[D loss: 0.493943, acc: 56.25%, op_acc: 24.22%] [G loss: 1.014596]\n",
      "epoch:1 step:998[D loss: 0.453952, acc: 64.06%, op_acc: 28.91%] [G loss: 1.161763]\n",
      "epoch:1 step:999[D loss: 0.457672, acc: 60.16%, op_acc: 28.12%] [G loss: 1.042695]\n",
      "epoch:1 step:1000[D loss: 0.488970, acc: 58.59%, op_acc: 28.12%] [G loss: 1.109060]\n",
      "##############\n",
      "[0.87402478 0.87098729 0.81800554 0.80281308 0.81937626 0.81998362\n",
      " 0.89059102 0.79707833 0.79096621 0.83707495]\n",
      "##########\n",
      "epoch:1 step:1001[D loss: 0.452871, acc: 65.62%, op_acc: 27.34%] [G loss: 1.019051]\n",
      "epoch:1 step:1002[D loss: 0.470549, acc: 64.06%, op_acc: 22.66%] [G loss: 1.075481]\n",
      "epoch:1 step:1003[D loss: 0.516670, acc: 56.25%, op_acc: 22.66%] [G loss: 1.064079]\n",
      "epoch:1 step:1004[D loss: 0.451355, acc: 61.72%, op_acc: 26.56%] [G loss: 1.084699]\n",
      "epoch:1 step:1005[D loss: 0.495491, acc: 55.47%, op_acc: 17.97%] [G loss: 1.121711]\n",
      "epoch:1 step:1006[D loss: 0.480488, acc: 62.50%, op_acc: 23.44%] [G loss: 0.957950]\n",
      "epoch:1 step:1007[D loss: 0.480586, acc: 58.59%, op_acc: 24.22%] [G loss: 1.093509]\n",
      "epoch:1 step:1008[D loss: 0.490822, acc: 60.16%, op_acc: 23.44%] [G loss: 0.994252]\n",
      "epoch:1 step:1009[D loss: 0.446279, acc: 67.97%, op_acc: 31.25%] [G loss: 0.984261]\n",
      "epoch:1 step:1010[D loss: 0.483203, acc: 62.50%, op_acc: 25.78%] [G loss: 1.090500]\n",
      "epoch:1 step:1011[D loss: 0.514827, acc: 52.34%, op_acc: 27.34%] [G loss: 1.064380]\n",
      "epoch:1 step:1012[D loss: 0.463963, acc: 67.19%, op_acc: 32.81%] [G loss: 1.026103]\n",
      "epoch:1 step:1013[D loss: 0.503056, acc: 62.50%, op_acc: 28.91%] [G loss: 0.909397]\n",
      "epoch:1 step:1014[D loss: 0.454687, acc: 60.94%, op_acc: 22.66%] [G loss: 1.060728]\n",
      "epoch:1 step:1015[D loss: 0.468979, acc: 64.06%, op_acc: 25.00%] [G loss: 1.090133]\n",
      "epoch:1 step:1016[D loss: 0.434541, acc: 65.62%, op_acc: 35.16%] [G loss: 1.040405]\n",
      "epoch:1 step:1017[D loss: 0.522060, acc: 56.25%, op_acc: 21.88%] [G loss: 1.086498]\n",
      "epoch:1 step:1018[D loss: 0.511484, acc: 54.69%, op_acc: 23.44%] [G loss: 1.099761]\n",
      "epoch:1 step:1019[D loss: 0.475204, acc: 63.28%, op_acc: 28.91%] [G loss: 0.971597]\n",
      "epoch:1 step:1020[D loss: 0.501899, acc: 52.34%, op_acc: 30.47%] [G loss: 0.905021]\n",
      "epoch:1 step:1021[D loss: 0.497442, acc: 57.03%, op_acc: 28.91%] [G loss: 1.009860]\n",
      "epoch:1 step:1022[D loss: 0.463751, acc: 64.06%, op_acc: 24.22%] [G loss: 0.918867]\n",
      "epoch:1 step:1023[D loss: 0.509158, acc: 57.03%, op_acc: 28.12%] [G loss: 0.950649]\n",
      "epoch:1 step:1024[D loss: 0.521748, acc: 52.34%, op_acc: 28.91%] [G loss: 0.960176]\n",
      "epoch:1 step:1025[D loss: 0.538645, acc: 59.38%, op_acc: 25.00%] [G loss: 0.928520]\n",
      "epoch:1 step:1026[D loss: 0.481408, acc: 58.59%, op_acc: 32.81%] [G loss: 1.108028]\n",
      "epoch:1 step:1027[D loss: 0.470480, acc: 64.06%, op_acc: 27.34%] [G loss: 1.031623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1028[D loss: 0.476599, acc: 57.03%, op_acc: 29.69%] [G loss: 0.986570]\n",
      "epoch:1 step:1029[D loss: 0.509784, acc: 58.59%, op_acc: 25.00%] [G loss: 1.007819]\n",
      "epoch:1 step:1030[D loss: 0.496588, acc: 65.62%, op_acc: 28.12%] [G loss: 0.984244]\n",
      "epoch:1 step:1031[D loss: 0.477913, acc: 60.16%, op_acc: 27.34%] [G loss: 0.958510]\n",
      "epoch:1 step:1032[D loss: 0.449649, acc: 64.84%, op_acc: 28.12%] [G loss: 1.049594]\n",
      "epoch:1 step:1033[D loss: 0.483581, acc: 60.16%, op_acc: 24.22%] [G loss: 0.989331]\n",
      "epoch:1 step:1034[D loss: 0.474242, acc: 62.50%, op_acc: 28.91%] [G loss: 0.957526]\n",
      "epoch:1 step:1035[D loss: 0.505120, acc: 58.59%, op_acc: 19.53%] [G loss: 1.115993]\n",
      "epoch:1 step:1036[D loss: 0.480885, acc: 60.16%, op_acc: 23.44%] [G loss: 1.073947]\n",
      "epoch:1 step:1037[D loss: 0.481924, acc: 53.91%, op_acc: 28.91%] [G loss: 1.032582]\n",
      "epoch:1 step:1038[D loss: 0.530423, acc: 60.16%, op_acc: 21.09%] [G loss: 0.949118]\n",
      "epoch:1 step:1039[D loss: 0.469062, acc: 63.28%, op_acc: 24.22%] [G loss: 0.927223]\n",
      "epoch:1 step:1040[D loss: 0.467250, acc: 59.38%, op_acc: 25.78%] [G loss: 1.068923]\n",
      "epoch:1 step:1041[D loss: 0.504085, acc: 54.69%, op_acc: 29.69%] [G loss: 0.961886]\n",
      "epoch:1 step:1042[D loss: 0.505007, acc: 46.88%, op_acc: 27.34%] [G loss: 1.027776]\n",
      "epoch:1 step:1043[D loss: 0.467501, acc: 62.50%, op_acc: 25.00%] [G loss: 0.976053]\n",
      "epoch:1 step:1044[D loss: 0.463677, acc: 60.16%, op_acc: 31.25%] [G loss: 1.099657]\n",
      "epoch:1 step:1045[D loss: 0.448961, acc: 62.50%, op_acc: 28.12%] [G loss: 1.167349]\n",
      "epoch:1 step:1046[D loss: 0.442697, acc: 60.16%, op_acc: 36.72%] [G loss: 1.297822]\n",
      "epoch:1 step:1047[D loss: 0.471356, acc: 61.72%, op_acc: 26.56%] [G loss: 1.079669]\n",
      "epoch:1 step:1048[D loss: 0.501602, acc: 63.28%, op_acc: 30.47%] [G loss: 1.020674]\n",
      "epoch:1 step:1049[D loss: 0.473725, acc: 61.72%, op_acc: 25.00%] [G loss: 1.063701]\n",
      "epoch:1 step:1050[D loss: 0.494521, acc: 57.81%, op_acc: 32.81%] [G loss: 0.958245]\n",
      "##############\n",
      "[0.85904346 0.85792403 0.79571865 0.8002168  0.78724408 0.8363027\n",
      " 0.90969558 0.82452733 0.81096593 0.81432163]\n",
      "##########\n",
      "epoch:1 step:1051[D loss: 0.460770, acc: 66.41%, op_acc: 21.88%] [G loss: 1.011285]\n",
      "epoch:1 step:1052[D loss: 0.472845, acc: 67.19%, op_acc: 21.88%] [G loss: 1.037860]\n",
      "epoch:1 step:1053[D loss: 0.525931, acc: 58.59%, op_acc: 22.66%] [G loss: 1.039534]\n",
      "epoch:1 step:1054[D loss: 0.419617, acc: 69.53%, op_acc: 27.34%] [G loss: 1.151471]\n",
      "epoch:1 step:1055[D loss: 0.468644, acc: 64.06%, op_acc: 25.00%] [G loss: 1.035018]\n",
      "epoch:1 step:1056[D loss: 0.487222, acc: 62.50%, op_acc: 28.12%] [G loss: 1.127477]\n",
      "epoch:1 step:1057[D loss: 0.444763, acc: 62.50%, op_acc: 34.38%] [G loss: 1.228634]\n",
      "epoch:1 step:1058[D loss: 0.538317, acc: 59.38%, op_acc: 22.66%] [G loss: 1.045457]\n",
      "epoch:1 step:1059[D loss: 0.479099, acc: 60.94%, op_acc: 30.47%] [G loss: 0.977510]\n",
      "epoch:1 step:1060[D loss: 0.474564, acc: 56.25%, op_acc: 32.03%] [G loss: 1.022125]\n",
      "epoch:1 step:1061[D loss: 0.449433, acc: 67.97%, op_acc: 27.34%] [G loss: 1.057322]\n",
      "epoch:1 step:1062[D loss: 0.522142, acc: 53.91%, op_acc: 23.44%] [G loss: 1.099471]\n",
      "epoch:1 step:1063[D loss: 0.474324, acc: 60.94%, op_acc: 28.91%] [G loss: 0.946962]\n",
      "epoch:1 step:1064[D loss: 0.465226, acc: 68.75%, op_acc: 24.22%] [G loss: 1.042561]\n",
      "epoch:1 step:1065[D loss: 0.485126, acc: 58.59%, op_acc: 27.34%] [G loss: 1.068764]\n",
      "epoch:1 step:1066[D loss: 0.478293, acc: 60.94%, op_acc: 30.47%] [G loss: 1.057351]\n",
      "epoch:1 step:1067[D loss: 0.506659, acc: 53.12%, op_acc: 34.38%] [G loss: 0.912386]\n",
      "epoch:1 step:1068[D loss: 0.479665, acc: 58.59%, op_acc: 30.47%] [G loss: 1.100909]\n",
      "epoch:1 step:1069[D loss: 0.472583, acc: 68.75%, op_acc: 25.00%] [G loss: 1.159333]\n",
      "epoch:1 step:1070[D loss: 0.489342, acc: 57.81%, op_acc: 21.88%] [G loss: 1.052397]\n",
      "epoch:1 step:1071[D loss: 0.478430, acc: 58.59%, op_acc: 28.91%] [G loss: 1.032073]\n",
      "epoch:1 step:1072[D loss: 0.495332, acc: 57.81%, op_acc: 21.09%] [G loss: 1.119562]\n",
      "epoch:1 step:1073[D loss: 0.447309, acc: 67.19%, op_acc: 30.47%] [G loss: 1.111899]\n",
      "epoch:1 step:1074[D loss: 0.486820, acc: 57.81%, op_acc: 32.81%] [G loss: 0.992716]\n",
      "epoch:1 step:1075[D loss: 0.513727, acc: 57.03%, op_acc: 27.34%] [G loss: 1.123196]\n",
      "epoch:1 step:1076[D loss: 0.483480, acc: 60.94%, op_acc: 25.78%] [G loss: 1.087020]\n",
      "epoch:1 step:1077[D loss: 0.491131, acc: 56.25%, op_acc: 28.12%] [G loss: 1.085796]\n",
      "epoch:1 step:1078[D loss: 0.515159, acc: 59.38%, op_acc: 25.78%] [G loss: 1.049527]\n",
      "epoch:1 step:1079[D loss: 0.519676, acc: 54.69%, op_acc: 28.12%] [G loss: 0.914582]\n",
      "epoch:1 step:1080[D loss: 0.455460, acc: 66.41%, op_acc: 26.56%] [G loss: 0.961206]\n",
      "epoch:1 step:1081[D loss: 0.493734, acc: 55.47%, op_acc: 25.00%] [G loss: 0.970158]\n",
      "epoch:1 step:1082[D loss: 0.506323, acc: 57.03%, op_acc: 21.09%] [G loss: 1.039380]\n",
      "epoch:1 step:1083[D loss: 0.470701, acc: 55.47%, op_acc: 27.34%] [G loss: 0.975141]\n",
      "epoch:1 step:1084[D loss: 0.504276, acc: 53.91%, op_acc: 23.44%] [G loss: 1.115558]\n",
      "epoch:1 step:1085[D loss: 0.441802, acc: 62.50%, op_acc: 31.25%] [G loss: 1.046812]\n",
      "epoch:1 step:1086[D loss: 0.513647, acc: 57.81%, op_acc: 28.12%] [G loss: 1.065661]\n",
      "epoch:1 step:1087[D loss: 0.512457, acc: 57.03%, op_acc: 15.62%] [G loss: 1.045457]\n",
      "epoch:1 step:1088[D loss: 0.491850, acc: 53.12%, op_acc: 31.25%] [G loss: 1.065437]\n",
      "epoch:1 step:1089[D loss: 0.470257, acc: 68.75%, op_acc: 27.34%] [G loss: 1.030828]\n",
      "epoch:1 step:1090[D loss: 0.501732, acc: 57.81%, op_acc: 22.66%] [G loss: 0.902795]\n",
      "epoch:1 step:1091[D loss: 0.468017, acc: 60.94%, op_acc: 28.12%] [G loss: 1.061978]\n",
      "epoch:1 step:1092[D loss: 0.499070, acc: 57.03%, op_acc: 27.34%] [G loss: 1.064245]\n",
      "epoch:1 step:1093[D loss: 0.474065, acc: 60.16%, op_acc: 27.34%] [G loss: 0.940675]\n",
      "epoch:1 step:1094[D loss: 0.455653, acc: 68.75%, op_acc: 30.47%] [G loss: 1.029632]\n",
      "epoch:1 step:1095[D loss: 0.444718, acc: 63.28%, op_acc: 26.56%] [G loss: 0.918323]\n",
      "epoch:1 step:1096[D loss: 0.481603, acc: 60.94%, op_acc: 26.56%] [G loss: 0.950872]\n",
      "epoch:1 step:1097[D loss: 0.463955, acc: 64.84%, op_acc: 29.69%] [G loss: 0.968093]\n",
      "epoch:1 step:1098[D loss: 0.474859, acc: 57.03%, op_acc: 28.12%] [G loss: 1.040974]\n",
      "epoch:1 step:1099[D loss: 0.437633, acc: 70.31%, op_acc: 25.00%] [G loss: 1.047492]\n",
      "epoch:1 step:1100[D loss: 0.469449, acc: 64.06%, op_acc: 28.12%] [G loss: 1.014742]\n",
      "##############\n",
      "[0.87476148 0.87456646 0.80405525 0.80507915 0.77517148 0.83196089\n",
      " 0.89007337 0.84039489 0.83420235 0.82529086]\n",
      "##########\n",
      "epoch:1 step:1101[D loss: 0.496452, acc: 52.34%, op_acc: 26.56%] [G loss: 1.061774]\n",
      "epoch:1 step:1102[D loss: 0.500825, acc: 57.81%, op_acc: 24.22%] [G loss: 0.940157]\n",
      "epoch:1 step:1103[D loss: 0.492008, acc: 55.47%, op_acc: 25.78%] [G loss: 0.954054]\n",
      "epoch:1 step:1104[D loss: 0.523910, acc: 53.12%, op_acc: 28.12%] [G loss: 1.035908]\n",
      "epoch:1 step:1105[D loss: 0.481395, acc: 57.81%, op_acc: 23.44%] [G loss: 1.048163]\n",
      "epoch:1 step:1106[D loss: 0.488503, acc: 52.34%, op_acc: 28.12%] [G loss: 1.057789]\n",
      "epoch:1 step:1107[D loss: 0.453370, acc: 60.16%, op_acc: 28.91%] [G loss: 1.196094]\n",
      "epoch:1 step:1108[D loss: 0.443282, acc: 63.28%, op_acc: 28.91%] [G loss: 0.969203]\n",
      "epoch:1 step:1109[D loss: 0.500506, acc: 56.25%, op_acc: 25.00%] [G loss: 0.994547]\n",
      "epoch:1 step:1110[D loss: 0.474344, acc: 59.38%, op_acc: 25.00%] [G loss: 1.104332]\n",
      "epoch:1 step:1111[D loss: 0.444003, acc: 71.09%, op_acc: 31.25%] [G loss: 1.082287]\n",
      "epoch:1 step:1112[D loss: 0.474536, acc: 54.69%, op_acc: 33.59%] [G loss: 1.075979]\n",
      "epoch:1 step:1113[D loss: 0.491785, acc: 53.12%, op_acc: 29.69%] [G loss: 0.954092]\n",
      "epoch:1 step:1114[D loss: 0.488487, acc: 57.03%, op_acc: 32.81%] [G loss: 0.945259]\n",
      "epoch:1 step:1115[D loss: 0.469206, acc: 60.94%, op_acc: 32.03%] [G loss: 1.104788]\n",
      "epoch:1 step:1116[D loss: 0.497508, acc: 60.16%, op_acc: 27.34%] [G loss: 0.938090]\n",
      "epoch:1 step:1117[D loss: 0.455708, acc: 65.62%, op_acc: 28.12%] [G loss: 0.978708]\n",
      "epoch:1 step:1118[D loss: 0.504040, acc: 60.94%, op_acc: 23.44%] [G loss: 1.016388]\n",
      "epoch:1 step:1119[D loss: 0.447193, acc: 62.50%, op_acc: 32.03%] [G loss: 1.035579]\n",
      "epoch:1 step:1120[D loss: 0.445859, acc: 65.62%, op_acc: 31.25%] [G loss: 1.013026]\n",
      "epoch:1 step:1121[D loss: 0.444526, acc: 64.84%, op_acc: 28.12%] [G loss: 1.049519]\n",
      "epoch:1 step:1122[D loss: 0.466445, acc: 64.84%, op_acc: 27.34%] [G loss: 0.968246]\n",
      "epoch:1 step:1123[D loss: 0.431691, acc: 70.31%, op_acc: 25.78%] [G loss: 1.034737]\n",
      "epoch:1 step:1124[D loss: 0.467921, acc: 61.72%, op_acc: 30.47%] [G loss: 1.013880]\n",
      "epoch:1 step:1125[D loss: 0.484790, acc: 59.38%, op_acc: 26.56%] [G loss: 1.020731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1126[D loss: 0.448983, acc: 64.84%, op_acc: 35.16%] [G loss: 1.037956]\n",
      "epoch:1 step:1127[D loss: 0.491966, acc: 53.91%, op_acc: 28.12%] [G loss: 1.015231]\n",
      "epoch:1 step:1128[D loss: 0.464016, acc: 64.84%, op_acc: 32.81%] [G loss: 0.973608]\n",
      "epoch:1 step:1129[D loss: 0.482847, acc: 54.69%, op_acc: 30.47%] [G loss: 1.075089]\n",
      "epoch:1 step:1130[D loss: 0.475195, acc: 58.59%, op_acc: 24.22%] [G loss: 1.011100]\n",
      "epoch:1 step:1131[D loss: 0.476214, acc: 60.94%, op_acc: 23.44%] [G loss: 1.092286]\n",
      "epoch:1 step:1132[D loss: 0.498310, acc: 58.59%, op_acc: 24.22%] [G loss: 1.005346]\n",
      "epoch:1 step:1133[D loss: 0.549560, acc: 50.78%, op_acc: 27.34%] [G loss: 0.975380]\n",
      "epoch:1 step:1134[D loss: 0.463245, acc: 63.28%, op_acc: 32.81%] [G loss: 1.125797]\n",
      "epoch:1 step:1135[D loss: 0.477793, acc: 62.50%, op_acc: 26.56%] [G loss: 1.049466]\n",
      "epoch:1 step:1136[D loss: 0.453768, acc: 64.84%, op_acc: 28.91%] [G loss: 0.947207]\n",
      "epoch:1 step:1137[D loss: 0.535336, acc: 53.91%, op_acc: 17.97%] [G loss: 0.999916]\n",
      "epoch:1 step:1138[D loss: 0.436989, acc: 69.53%, op_acc: 30.47%] [G loss: 0.978446]\n",
      "epoch:1 step:1139[D loss: 0.513026, acc: 53.12%, op_acc: 25.78%] [G loss: 1.004979]\n",
      "epoch:1 step:1140[D loss: 0.469349, acc: 57.81%, op_acc: 33.59%] [G loss: 0.951571]\n",
      "epoch:1 step:1141[D loss: 0.489231, acc: 58.59%, op_acc: 25.78%] [G loss: 1.098639]\n",
      "epoch:1 step:1142[D loss: 0.473196, acc: 58.59%, op_acc: 27.34%] [G loss: 1.071596]\n",
      "epoch:1 step:1143[D loss: 0.453722, acc: 60.16%, op_acc: 27.34%] [G loss: 1.112119]\n",
      "epoch:1 step:1144[D loss: 0.531664, acc: 46.09%, op_acc: 21.88%] [G loss: 0.877131]\n",
      "epoch:1 step:1145[D loss: 0.448035, acc: 65.62%, op_acc: 25.78%] [G loss: 1.000583]\n",
      "epoch:1 step:1146[D loss: 0.477111, acc: 49.22%, op_acc: 32.03%] [G loss: 0.909317]\n",
      "epoch:1 step:1147[D loss: 0.493396, acc: 58.59%, op_acc: 31.25%] [G loss: 0.950338]\n",
      "epoch:1 step:1148[D loss: 0.505823, acc: 59.38%, op_acc: 23.44%] [G loss: 0.940103]\n",
      "epoch:1 step:1149[D loss: 0.531555, acc: 49.22%, op_acc: 29.69%] [G loss: 0.961562]\n",
      "epoch:1 step:1150[D loss: 0.484089, acc: 57.81%, op_acc: 31.25%] [G loss: 0.963071]\n",
      "##############\n",
      "[0.84605542 0.86566978 0.81118382 0.80314348 0.77586468 0.81221761\n",
      " 0.88771204 0.8587701  0.81574951 0.82830826]\n",
      "##########\n",
      "epoch:1 step:1151[D loss: 0.494962, acc: 61.72%, op_acc: 25.00%] [G loss: 0.978720]\n",
      "epoch:1 step:1152[D loss: 0.474593, acc: 57.03%, op_acc: 32.81%] [G loss: 0.990040]\n",
      "epoch:1 step:1153[D loss: 0.485782, acc: 63.28%, op_acc: 29.69%] [G loss: 1.046078]\n",
      "epoch:1 step:1154[D loss: 0.453617, acc: 58.59%, op_acc: 28.91%] [G loss: 1.134316]\n",
      "epoch:1 step:1155[D loss: 0.540090, acc: 50.78%, op_acc: 28.91%] [G loss: 0.903032]\n",
      "epoch:1 step:1156[D loss: 0.463056, acc: 65.62%, op_acc: 31.25%] [G loss: 1.003911]\n",
      "epoch:1 step:1157[D loss: 0.473940, acc: 56.25%, op_acc: 25.00%] [G loss: 1.041823]\n",
      "epoch:1 step:1158[D loss: 0.475965, acc: 62.50%, op_acc: 21.88%] [G loss: 1.137417]\n",
      "epoch:1 step:1159[D loss: 0.430650, acc: 66.41%, op_acc: 32.03%] [G loss: 1.121718]\n",
      "epoch:1 step:1160[D loss: 0.472274, acc: 62.50%, op_acc: 24.22%] [G loss: 0.926514]\n",
      "epoch:1 step:1161[D loss: 0.481515, acc: 60.16%, op_acc: 27.34%] [G loss: 0.930761]\n",
      "epoch:1 step:1162[D loss: 0.496609, acc: 53.91%, op_acc: 28.12%] [G loss: 0.878030]\n",
      "epoch:1 step:1163[D loss: 0.484066, acc: 60.16%, op_acc: 28.12%] [G loss: 0.888549]\n",
      "epoch:1 step:1164[D loss: 0.499608, acc: 55.47%, op_acc: 25.00%] [G loss: 0.912296]\n",
      "epoch:1 step:1165[D loss: 0.465715, acc: 63.28%, op_acc: 25.78%] [G loss: 0.931972]\n",
      "epoch:1 step:1166[D loss: 0.458541, acc: 58.59%, op_acc: 28.12%] [G loss: 1.014388]\n",
      "epoch:1 step:1167[D loss: 0.458489, acc: 60.94%, op_acc: 29.69%] [G loss: 1.067624]\n",
      "epoch:1 step:1168[D loss: 0.499300, acc: 54.69%, op_acc: 24.22%] [G loss: 0.899075]\n",
      "epoch:1 step:1169[D loss: 0.474683, acc: 59.38%, op_acc: 22.66%] [G loss: 1.107760]\n",
      "epoch:1 step:1170[D loss: 0.465293, acc: 60.94%, op_acc: 31.25%] [G loss: 0.891734]\n",
      "epoch:1 step:1171[D loss: 0.436800, acc: 70.31%, op_acc: 30.47%] [G loss: 0.962747]\n",
      "epoch:1 step:1172[D loss: 0.500946, acc: 57.03%, op_acc: 24.22%] [G loss: 0.953315]\n",
      "epoch:1 step:1173[D loss: 0.458064, acc: 59.38%, op_acc: 26.56%] [G loss: 1.027700]\n",
      "epoch:1 step:1174[D loss: 0.494833, acc: 56.25%, op_acc: 28.91%] [G loss: 1.090448]\n",
      "epoch:1 step:1175[D loss: 0.468710, acc: 61.72%, op_acc: 29.69%] [G loss: 1.001560]\n",
      "epoch:1 step:1176[D loss: 0.473770, acc: 63.28%, op_acc: 19.53%] [G loss: 1.005542]\n",
      "epoch:1 step:1177[D loss: 0.460805, acc: 59.38%, op_acc: 30.47%] [G loss: 1.023964]\n",
      "epoch:1 step:1178[D loss: 0.454854, acc: 60.94%, op_acc: 29.69%] [G loss: 1.001031]\n",
      "epoch:1 step:1179[D loss: 0.502951, acc: 60.94%, op_acc: 22.66%] [G loss: 1.039113]\n",
      "epoch:1 step:1180[D loss: 0.454113, acc: 60.94%, op_acc: 28.12%] [G loss: 1.010579]\n",
      "epoch:1 step:1181[D loss: 0.474853, acc: 58.59%, op_acc: 33.59%] [G loss: 0.955398]\n",
      "epoch:1 step:1182[D loss: 0.494135, acc: 52.34%, op_acc: 26.56%] [G loss: 1.028658]\n",
      "epoch:1 step:1183[D loss: 0.505913, acc: 53.12%, op_acc: 26.56%] [G loss: 1.070617]\n",
      "epoch:1 step:1184[D loss: 0.508901, acc: 50.78%, op_acc: 24.22%] [G loss: 1.009585]\n",
      "epoch:1 step:1185[D loss: 0.445201, acc: 64.84%, op_acc: 34.38%] [G loss: 1.048314]\n",
      "epoch:1 step:1186[D loss: 0.483532, acc: 60.94%, op_acc: 23.44%] [G loss: 0.909038]\n",
      "epoch:1 step:1187[D loss: 0.470793, acc: 57.81%, op_acc: 25.78%] [G loss: 0.937661]\n",
      "epoch:1 step:1188[D loss: 0.464923, acc: 60.16%, op_acc: 28.12%] [G loss: 1.101050]\n",
      "epoch:1 step:1189[D loss: 0.444016, acc: 61.72%, op_acc: 34.38%] [G loss: 0.987002]\n",
      "epoch:1 step:1190[D loss: 0.456497, acc: 67.19%, op_acc: 28.12%] [G loss: 0.967479]\n",
      "epoch:1 step:1191[D loss: 0.489784, acc: 50.00%, op_acc: 27.34%] [G loss: 0.878728]\n",
      "epoch:1 step:1192[D loss: 0.492504, acc: 57.03%, op_acc: 27.34%] [G loss: 0.949270]\n",
      "epoch:1 step:1193[D loss: 0.476248, acc: 64.06%, op_acc: 25.00%] [G loss: 0.962051]\n",
      "epoch:1 step:1194[D loss: 0.461285, acc: 65.62%, op_acc: 28.12%] [G loss: 1.031355]\n",
      "epoch:1 step:1195[D loss: 0.487785, acc: 61.72%, op_acc: 23.44%] [G loss: 1.071481]\n",
      "epoch:1 step:1196[D loss: 0.470581, acc: 58.59%, op_acc: 28.12%] [G loss: 0.941166]\n",
      "epoch:1 step:1197[D loss: 0.487636, acc: 57.81%, op_acc: 25.78%] [G loss: 0.990009]\n",
      "epoch:1 step:1198[D loss: 0.472751, acc: 68.75%, op_acc: 23.44%] [G loss: 1.042266]\n",
      "epoch:1 step:1199[D loss: 0.471712, acc: 57.81%, op_acc: 30.47%] [G loss: 0.920133]\n",
      "epoch:1 step:1200[D loss: 0.478158, acc: 60.94%, op_acc: 27.34%] [G loss: 0.912813]\n",
      "##############\n",
      "[0.86787097 0.85453753 0.82803435 0.80843255 0.79949693 0.82242871\n",
      " 0.88540466 0.85309843 0.79651137 0.82888011]\n",
      "##########\n",
      "epoch:1 step:1201[D loss: 0.540759, acc: 45.31%, op_acc: 23.44%] [G loss: 0.897238]\n",
      "epoch:1 step:1202[D loss: 0.468884, acc: 64.06%, op_acc: 27.34%] [G loss: 0.980884]\n",
      "epoch:1 step:1203[D loss: 0.468812, acc: 63.28%, op_acc: 29.69%] [G loss: 0.929099]\n",
      "epoch:1 step:1204[D loss: 0.468471, acc: 66.41%, op_acc: 26.56%] [G loss: 0.965659]\n",
      "epoch:1 step:1205[D loss: 0.497378, acc: 60.16%, op_acc: 26.56%] [G loss: 0.925199]\n",
      "epoch:1 step:1206[D loss: 0.453345, acc: 66.41%, op_acc: 25.00%] [G loss: 0.900064]\n",
      "epoch:1 step:1207[D loss: 0.536972, acc: 48.44%, op_acc: 24.22%] [G loss: 0.871241]\n",
      "epoch:1 step:1208[D loss: 0.482717, acc: 64.06%, op_acc: 24.22%] [G loss: 1.012691]\n",
      "epoch:1 step:1209[D loss: 0.481533, acc: 62.50%, op_acc: 25.78%] [G loss: 1.054422]\n",
      "epoch:1 step:1210[D loss: 0.464517, acc: 64.06%, op_acc: 26.56%] [G loss: 0.993467]\n",
      "epoch:1 step:1211[D loss: 0.481213, acc: 64.84%, op_acc: 30.47%] [G loss: 1.011143]\n",
      "epoch:1 step:1212[D loss: 0.521288, acc: 54.69%, op_acc: 23.44%] [G loss: 0.967047]\n",
      "epoch:1 step:1213[D loss: 0.460502, acc: 62.50%, op_acc: 31.25%] [G loss: 1.001763]\n",
      "epoch:1 step:1214[D loss: 0.467802, acc: 60.16%, op_acc: 31.25%] [G loss: 0.974544]\n",
      "epoch:1 step:1215[D loss: 0.467824, acc: 57.81%, op_acc: 30.47%] [G loss: 1.060662]\n",
      "epoch:1 step:1216[D loss: 0.462181, acc: 64.84%, op_acc: 33.59%] [G loss: 1.089004]\n",
      "epoch:1 step:1217[D loss: 0.535325, acc: 48.44%, op_acc: 28.91%] [G loss: 0.987017]\n",
      "epoch:1 step:1218[D loss: 0.511514, acc: 55.47%, op_acc: 22.66%] [G loss: 0.936357]\n",
      "epoch:1 step:1219[D loss: 0.514348, acc: 60.16%, op_acc: 28.12%] [G loss: 0.875393]\n",
      "epoch:1 step:1220[D loss: 0.468061, acc: 59.38%, op_acc: 26.56%] [G loss: 0.912112]\n",
      "epoch:1 step:1221[D loss: 0.482898, acc: 60.94%, op_acc: 25.78%] [G loss: 0.967462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1222[D loss: 0.546027, acc: 50.78%, op_acc: 17.97%] [G loss: 0.884551]\n",
      "epoch:1 step:1223[D loss: 0.485098, acc: 57.81%, op_acc: 25.00%] [G loss: 0.794589]\n",
      "epoch:1 step:1224[D loss: 0.512696, acc: 57.81%, op_acc: 25.00%] [G loss: 0.907216]\n",
      "epoch:1 step:1225[D loss: 0.492685, acc: 57.03%, op_acc: 27.34%] [G loss: 0.961373]\n",
      "epoch:1 step:1226[D loss: 0.487215, acc: 60.16%, op_acc: 21.88%] [G loss: 1.065941]\n",
      "epoch:1 step:1227[D loss: 0.479259, acc: 58.59%, op_acc: 26.56%] [G loss: 0.978309]\n",
      "epoch:1 step:1228[D loss: 0.515587, acc: 57.03%, op_acc: 28.91%] [G loss: 0.916816]\n",
      "epoch:1 step:1229[D loss: 0.468088, acc: 54.69%, op_acc: 32.81%] [G loss: 1.009561]\n",
      "epoch:1 step:1230[D loss: 0.460418, acc: 62.50%, op_acc: 31.25%] [G loss: 0.995812]\n",
      "epoch:1 step:1231[D loss: 0.473335, acc: 60.94%, op_acc: 25.78%] [G loss: 1.149873]\n",
      "epoch:1 step:1232[D loss: 0.484991, acc: 53.12%, op_acc: 29.69%] [G loss: 0.928330]\n",
      "epoch:1 step:1233[D loss: 0.420196, acc: 67.19%, op_acc: 35.16%] [G loss: 1.112425]\n",
      "epoch:1 step:1234[D loss: 0.468940, acc: 57.81%, op_acc: 32.81%] [G loss: 1.019172]\n",
      "epoch:1 step:1235[D loss: 0.479128, acc: 58.59%, op_acc: 22.66%] [G loss: 1.121159]\n",
      "epoch:1 step:1236[D loss: 0.515563, acc: 52.34%, op_acc: 24.22%] [G loss: 0.995814]\n",
      "epoch:1 step:1237[D loss: 0.486742, acc: 59.38%, op_acc: 23.44%] [G loss: 0.940621]\n",
      "epoch:1 step:1238[D loss: 0.481505, acc: 60.94%, op_acc: 25.00%] [G loss: 1.018066]\n",
      "epoch:1 step:1239[D loss: 0.462761, acc: 60.94%, op_acc: 26.56%] [G loss: 1.095486]\n",
      "epoch:1 step:1240[D loss: 0.487802, acc: 54.69%, op_acc: 28.91%] [G loss: 0.972102]\n",
      "epoch:1 step:1241[D loss: 0.435249, acc: 64.84%, op_acc: 33.59%] [G loss: 1.032546]\n",
      "epoch:1 step:1242[D loss: 0.479510, acc: 59.38%, op_acc: 21.09%] [G loss: 0.874923]\n",
      "epoch:1 step:1243[D loss: 0.485877, acc: 59.38%, op_acc: 25.78%] [G loss: 1.064896]\n",
      "epoch:1 step:1244[D loss: 0.477712, acc: 55.47%, op_acc: 28.91%] [G loss: 0.948626]\n",
      "epoch:1 step:1245[D loss: 0.480572, acc: 60.16%, op_acc: 30.47%] [G loss: 1.073625]\n",
      "epoch:1 step:1246[D loss: 0.473553, acc: 59.38%, op_acc: 25.00%] [G loss: 0.956004]\n",
      "epoch:1 step:1247[D loss: 0.465012, acc: 61.72%, op_acc: 37.50%] [G loss: 0.968474]\n",
      "epoch:1 step:1248[D loss: 0.477431, acc: 62.50%, op_acc: 27.34%] [G loss: 0.963309]\n",
      "epoch:1 step:1249[D loss: 0.493919, acc: 54.69%, op_acc: 27.34%] [G loss: 0.969606]\n",
      "epoch:1 step:1250[D loss: 0.447439, acc: 61.72%, op_acc: 30.47%] [G loss: 0.936011]\n",
      "##############\n",
      "[0.84765562 0.84985117 0.81325171 0.80873601 0.78301854 0.83351086\n",
      " 0.89826419 0.83017274 0.82520311 0.8329823 ]\n",
      "##########\n",
      "epoch:1 step:1251[D loss: 0.459259, acc: 63.28%, op_acc: 30.47%] [G loss: 1.081078]\n",
      "epoch:1 step:1252[D loss: 0.500055, acc: 55.47%, op_acc: 29.69%] [G loss: 0.867937]\n",
      "epoch:1 step:1253[D loss: 0.528524, acc: 44.53%, op_acc: 22.66%] [G loss: 0.915666]\n",
      "epoch:1 step:1254[D loss: 0.490563, acc: 50.78%, op_acc: 29.69%] [G loss: 1.000521]\n",
      "epoch:1 step:1255[D loss: 0.503510, acc: 55.47%, op_acc: 27.34%] [G loss: 0.984352]\n",
      "epoch:1 step:1256[D loss: 0.470934, acc: 56.25%, op_acc: 28.91%] [G loss: 0.940030]\n",
      "epoch:1 step:1257[D loss: 0.491221, acc: 57.03%, op_acc: 25.78%] [G loss: 1.061598]\n",
      "epoch:1 step:1258[D loss: 0.454044, acc: 63.28%, op_acc: 34.38%] [G loss: 0.885844]\n",
      "epoch:1 step:1259[D loss: 0.502550, acc: 49.22%, op_acc: 34.38%] [G loss: 0.856544]\n",
      "epoch:1 step:1260[D loss: 0.487773, acc: 59.38%, op_acc: 28.91%] [G loss: 0.958129]\n",
      "epoch:1 step:1261[D loss: 0.481549, acc: 62.50%, op_acc: 25.78%] [G loss: 1.003469]\n",
      "epoch:1 step:1262[D loss: 0.517150, acc: 54.69%, op_acc: 24.22%] [G loss: 1.002069]\n",
      "epoch:1 step:1263[D loss: 0.527874, acc: 53.91%, op_acc: 25.78%] [G loss: 1.002291]\n",
      "epoch:1 step:1264[D loss: 0.497473, acc: 57.81%, op_acc: 25.78%] [G loss: 0.870218]\n",
      "epoch:1 step:1265[D loss: 0.489019, acc: 55.47%, op_acc: 33.59%] [G loss: 0.935930]\n",
      "epoch:1 step:1266[D loss: 0.503787, acc: 50.78%, op_acc: 21.88%] [G loss: 0.906209]\n",
      "epoch:1 step:1267[D loss: 0.453374, acc: 64.06%, op_acc: 28.12%] [G loss: 1.080176]\n",
      "epoch:1 step:1268[D loss: 0.482758, acc: 57.03%, op_acc: 28.12%] [G loss: 1.070417]\n",
      "epoch:1 step:1269[D loss: 0.460600, acc: 65.62%, op_acc: 28.91%] [G loss: 1.102541]\n",
      "epoch:1 step:1270[D loss: 0.464128, acc: 63.28%, op_acc: 29.69%] [G loss: 0.890754]\n",
      "epoch:1 step:1271[D loss: 0.480205, acc: 57.03%, op_acc: 35.94%] [G loss: 1.132849]\n",
      "epoch:1 step:1272[D loss: 0.473639, acc: 65.62%, op_acc: 26.56%] [G loss: 0.953302]\n",
      "epoch:1 step:1273[D loss: 0.486475, acc: 59.38%, op_acc: 26.56%] [G loss: 1.008347]\n",
      "epoch:1 step:1274[D loss: 0.464739, acc: 62.50%, op_acc: 26.56%] [G loss: 1.046023]\n",
      "epoch:1 step:1275[D loss: 0.452661, acc: 60.94%, op_acc: 32.81%] [G loss: 1.001744]\n",
      "epoch:1 step:1276[D loss: 0.487484, acc: 58.59%, op_acc: 31.25%] [G loss: 1.006346]\n",
      "epoch:1 step:1277[D loss: 0.456252, acc: 69.53%, op_acc: 29.69%] [G loss: 1.019061]\n",
      "epoch:1 step:1278[D loss: 0.458837, acc: 60.16%, op_acc: 31.25%] [G loss: 0.989537]\n",
      "epoch:1 step:1279[D loss: 0.476291, acc: 58.59%, op_acc: 26.56%] [G loss: 1.060578]\n",
      "epoch:1 step:1280[D loss: 0.513313, acc: 53.91%, op_acc: 30.47%] [G loss: 1.004957]\n",
      "epoch:1 step:1281[D loss: 0.460525, acc: 61.72%, op_acc: 33.59%] [G loss: 1.003960]\n",
      "epoch:1 step:1282[D loss: 0.482409, acc: 58.59%, op_acc: 32.81%] [G loss: 1.050889]\n",
      "epoch:1 step:1283[D loss: 0.472874, acc: 64.06%, op_acc: 35.16%] [G loss: 1.010516]\n",
      "epoch:1 step:1284[D loss: 0.443405, acc: 62.50%, op_acc: 30.47%] [G loss: 1.033152]\n",
      "epoch:1 step:1285[D loss: 0.475728, acc: 60.94%, op_acc: 26.56%] [G loss: 0.914043]\n",
      "epoch:1 step:1286[D loss: 0.484067, acc: 62.50%, op_acc: 25.00%] [G loss: 0.846512]\n",
      "epoch:1 step:1287[D loss: 0.506052, acc: 58.59%, op_acc: 27.34%] [G loss: 1.026184]\n",
      "epoch:1 step:1288[D loss: 0.443259, acc: 64.06%, op_acc: 28.12%] [G loss: 1.029782]\n",
      "epoch:1 step:1289[D loss: 0.482881, acc: 56.25%, op_acc: 26.56%] [G loss: 0.966618]\n",
      "epoch:1 step:1290[D loss: 0.496120, acc: 55.47%, op_acc: 30.47%] [G loss: 0.891455]\n",
      "epoch:1 step:1291[D loss: 0.493381, acc: 59.38%, op_acc: 28.91%] [G loss: 0.984015]\n",
      "epoch:1 step:1292[D loss: 0.499294, acc: 61.72%, op_acc: 28.91%] [G loss: 0.993225]\n",
      "epoch:1 step:1293[D loss: 0.474011, acc: 68.75%, op_acc: 25.00%] [G loss: 1.004341]\n",
      "epoch:1 step:1294[D loss: 0.472086, acc: 66.41%, op_acc: 26.56%] [G loss: 0.977564]\n",
      "epoch:1 step:1295[D loss: 0.525428, acc: 56.25%, op_acc: 24.22%] [G loss: 0.994776]\n",
      "epoch:1 step:1296[D loss: 0.507262, acc: 57.03%, op_acc: 25.00%] [G loss: 0.909056]\n",
      "epoch:1 step:1297[D loss: 0.448102, acc: 67.97%, op_acc: 21.88%] [G loss: 1.011967]\n",
      "epoch:1 step:1298[D loss: 0.475051, acc: 61.72%, op_acc: 25.00%] [G loss: 1.012918]\n",
      "epoch:1 step:1299[D loss: 0.467470, acc: 58.59%, op_acc: 25.00%] [G loss: 1.093449]\n",
      "epoch:1 step:1300[D loss: 0.476705, acc: 60.16%, op_acc: 23.44%] [G loss: 1.017663]\n",
      "##############\n",
      "[0.87305714 0.85586243 0.80561576 0.8106506  0.80392927 0.81949769\n",
      " 0.87293901 0.80867    0.80960823 0.82462692]\n",
      "##########\n",
      "epoch:1 step:1301[D loss: 0.492740, acc: 51.56%, op_acc: 28.12%] [G loss: 1.045548]\n",
      "epoch:1 step:1302[D loss: 0.480487, acc: 59.38%, op_acc: 25.00%] [G loss: 0.893674]\n",
      "epoch:1 step:1303[D loss: 0.496736, acc: 58.59%, op_acc: 21.88%] [G loss: 0.883373]\n",
      "epoch:1 step:1304[D loss: 0.494271, acc: 61.72%, op_acc: 30.47%] [G loss: 0.968859]\n",
      "epoch:1 step:1305[D loss: 0.468896, acc: 67.19%, op_acc: 23.44%] [G loss: 1.106097]\n",
      "epoch:1 step:1306[D loss: 0.494392, acc: 61.72%, op_acc: 28.12%] [G loss: 1.054556]\n",
      "epoch:1 step:1307[D loss: 0.504433, acc: 55.47%, op_acc: 21.88%] [G loss: 1.000238]\n",
      "epoch:1 step:1308[D loss: 0.480527, acc: 58.59%, op_acc: 25.00%] [G loss: 1.009249]\n",
      "epoch:1 step:1309[D loss: 0.489052, acc: 54.69%, op_acc: 29.69%] [G loss: 1.047231]\n",
      "epoch:1 step:1310[D loss: 0.483199, acc: 54.69%, op_acc: 28.12%] [G loss: 1.011938]\n",
      "epoch:1 step:1311[D loss: 0.464655, acc: 61.72%, op_acc: 26.56%] [G loss: 0.883321]\n",
      "epoch:1 step:1312[D loss: 0.456118, acc: 67.97%, op_acc: 23.44%] [G loss: 1.088948]\n",
      "epoch:1 step:1313[D loss: 0.495276, acc: 57.03%, op_acc: 29.69%] [G loss: 0.889456]\n",
      "epoch:1 step:1314[D loss: 0.481889, acc: 52.34%, op_acc: 28.91%] [G loss: 0.929165]\n",
      "epoch:1 step:1315[D loss: 0.444691, acc: 60.94%, op_acc: 32.03%] [G loss: 0.969352]\n",
      "epoch:1 step:1316[D loss: 0.467285, acc: 57.81%, op_acc: 29.69%] [G loss: 1.007807]\n",
      "epoch:1 step:1317[D loss: 0.465632, acc: 57.81%, op_acc: 32.81%] [G loss: 0.983219]\n",
      "epoch:1 step:1318[D loss: 0.499941, acc: 60.16%, op_acc: 23.44%] [G loss: 1.008013]\n",
      "epoch:1 step:1319[D loss: 0.437689, acc: 67.97%, op_acc: 29.69%] [G loss: 1.150777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1320[D loss: 0.519877, acc: 55.47%, op_acc: 29.69%] [G loss: 0.858487]\n",
      "epoch:1 step:1321[D loss: 0.489739, acc: 59.38%, op_acc: 26.56%] [G loss: 0.881022]\n",
      "epoch:1 step:1322[D loss: 0.458321, acc: 63.28%, op_acc: 29.69%] [G loss: 0.874286]\n",
      "epoch:1 step:1323[D loss: 0.507277, acc: 50.78%, op_acc: 30.47%] [G loss: 1.027074]\n",
      "epoch:1 step:1324[D loss: 0.469558, acc: 61.72%, op_acc: 25.00%] [G loss: 0.995712]\n",
      "epoch:1 step:1325[D loss: 0.485523, acc: 54.69%, op_acc: 30.47%] [G loss: 0.962893]\n",
      "epoch:1 step:1326[D loss: 0.463082, acc: 60.94%, op_acc: 34.38%] [G loss: 0.977799]\n",
      "epoch:1 step:1327[D loss: 0.480218, acc: 50.78%, op_acc: 30.47%] [G loss: 0.993472]\n",
      "epoch:1 step:1328[D loss: 0.521409, acc: 53.12%, op_acc: 24.22%] [G loss: 0.906954]\n",
      "epoch:1 step:1329[D loss: 0.506910, acc: 55.47%, op_acc: 22.66%] [G loss: 1.010324]\n",
      "epoch:1 step:1330[D loss: 0.487502, acc: 60.16%, op_acc: 24.22%] [G loss: 0.888915]\n",
      "epoch:1 step:1331[D loss: 0.501296, acc: 52.34%, op_acc: 25.00%] [G loss: 0.894336]\n",
      "epoch:1 step:1332[D loss: 0.447244, acc: 64.84%, op_acc: 26.56%] [G loss: 1.033699]\n",
      "epoch:1 step:1333[D loss: 0.503213, acc: 57.81%, op_acc: 19.53%] [G loss: 0.951459]\n",
      "epoch:1 step:1334[D loss: 0.458664, acc: 64.06%, op_acc: 30.47%] [G loss: 0.892514]\n",
      "epoch:1 step:1335[D loss: 0.453489, acc: 60.16%, op_acc: 26.56%] [G loss: 0.925624]\n",
      "epoch:1 step:1336[D loss: 0.480044, acc: 60.16%, op_acc: 33.59%] [G loss: 1.002331]\n",
      "epoch:1 step:1337[D loss: 0.477331, acc: 61.72%, op_acc: 29.69%] [G loss: 0.943444]\n",
      "epoch:1 step:1338[D loss: 0.480913, acc: 60.16%, op_acc: 25.00%] [G loss: 1.011863]\n",
      "epoch:1 step:1339[D loss: 0.460458, acc: 62.50%, op_acc: 25.00%] [G loss: 0.972734]\n",
      "epoch:1 step:1340[D loss: 0.444185, acc: 64.06%, op_acc: 27.34%] [G loss: 0.972206]\n",
      "epoch:1 step:1341[D loss: 0.506531, acc: 50.78%, op_acc: 26.56%] [G loss: 1.016523]\n",
      "epoch:1 step:1342[D loss: 0.496342, acc: 57.03%, op_acc: 29.69%] [G loss: 0.937734]\n",
      "epoch:1 step:1343[D loss: 0.444063, acc: 71.09%, op_acc: 25.00%] [G loss: 0.841697]\n",
      "epoch:1 step:1344[D loss: 0.482554, acc: 56.25%, op_acc: 31.25%] [G loss: 0.932538]\n",
      "epoch:1 step:1345[D loss: 0.511482, acc: 58.59%, op_acc: 24.22%] [G loss: 0.984177]\n",
      "epoch:1 step:1346[D loss: 0.442497, acc: 67.97%, op_acc: 31.25%] [G loss: 1.009948]\n",
      "epoch:1 step:1347[D loss: 0.507201, acc: 51.56%, op_acc: 27.34%] [G loss: 0.895840]\n",
      "epoch:1 step:1348[D loss: 0.532273, acc: 46.09%, op_acc: 26.56%] [G loss: 0.875175]\n",
      "epoch:1 step:1349[D loss: 0.457420, acc: 64.84%, op_acc: 25.00%] [G loss: 0.959247]\n",
      "epoch:1 step:1350[D loss: 0.468619, acc: 60.94%, op_acc: 30.47%] [G loss: 1.005332]\n",
      "##############\n",
      "[0.87648877 0.86935307 0.82146621 0.8203071  0.78104263 0.83754486\n",
      " 0.88765554 0.834809   0.8486673  0.80648483]\n",
      "##########\n",
      "epoch:1 step:1351[D loss: 0.456412, acc: 64.06%, op_acc: 34.38%] [G loss: 1.028248]\n",
      "epoch:1 step:1352[D loss: 0.464348, acc: 62.50%, op_acc: 27.34%] [G loss: 0.920664]\n",
      "epoch:1 step:1353[D loss: 0.437451, acc: 65.62%, op_acc: 28.12%] [G loss: 0.885098]\n",
      "epoch:1 step:1354[D loss: 0.462577, acc: 64.06%, op_acc: 39.06%] [G loss: 1.027876]\n",
      "epoch:1 step:1355[D loss: 0.484763, acc: 60.94%, op_acc: 26.56%] [G loss: 0.942918]\n",
      "epoch:1 step:1356[D loss: 0.456112, acc: 60.94%, op_acc: 28.91%] [G loss: 0.961871]\n",
      "epoch:1 step:1357[D loss: 0.501832, acc: 54.69%, op_acc: 28.12%] [G loss: 0.893818]\n",
      "epoch:1 step:1358[D loss: 0.476829, acc: 61.72%, op_acc: 28.91%] [G loss: 1.042960]\n",
      "epoch:1 step:1359[D loss: 0.450507, acc: 71.09%, op_acc: 26.56%] [G loss: 0.994936]\n",
      "epoch:1 step:1360[D loss: 0.464302, acc: 58.59%, op_acc: 25.78%] [G loss: 0.927285]\n",
      "epoch:1 step:1361[D loss: 0.548126, acc: 50.00%, op_acc: 20.31%] [G loss: 0.976854]\n",
      "epoch:1 step:1362[D loss: 0.532484, acc: 48.44%, op_acc: 27.34%] [G loss: 0.911926]\n",
      "epoch:1 step:1363[D loss: 0.477582, acc: 57.03%, op_acc: 26.56%] [G loss: 1.032846]\n",
      "epoch:1 step:1364[D loss: 0.444463, acc: 63.28%, op_acc: 28.91%] [G loss: 1.015778]\n",
      "epoch:1 step:1365[D loss: 0.489016, acc: 59.38%, op_acc: 24.22%] [G loss: 0.984087]\n",
      "epoch:1 step:1366[D loss: 0.484046, acc: 58.59%, op_acc: 32.03%] [G loss: 1.021757]\n",
      "epoch:1 step:1367[D loss: 0.468831, acc: 66.41%, op_acc: 21.88%] [G loss: 0.964851]\n",
      "epoch:1 step:1368[D loss: 0.513040, acc: 52.34%, op_acc: 25.00%] [G loss: 0.917619]\n",
      "epoch:1 step:1369[D loss: 0.474168, acc: 60.94%, op_acc: 32.81%] [G loss: 0.988985]\n",
      "epoch:1 step:1370[D loss: 0.461877, acc: 63.28%, op_acc: 28.91%] [G loss: 1.045618]\n",
      "epoch:1 step:1371[D loss: 0.439228, acc: 66.41%, op_acc: 28.91%] [G loss: 0.952452]\n",
      "epoch:1 step:1372[D loss: 0.468186, acc: 60.16%, op_acc: 22.66%] [G loss: 1.098573]\n",
      "epoch:1 step:1373[D loss: 0.460500, acc: 61.72%, op_acc: 35.94%] [G loss: 1.003487]\n",
      "epoch:1 step:1374[D loss: 0.470636, acc: 62.50%, op_acc: 23.44%] [G loss: 1.017141]\n",
      "epoch:1 step:1375[D loss: 0.536555, acc: 46.88%, op_acc: 18.75%] [G loss: 0.860168]\n",
      "epoch:1 step:1376[D loss: 0.482572, acc: 64.06%, op_acc: 22.66%] [G loss: 0.849733]\n",
      "epoch:1 step:1377[D loss: 0.492150, acc: 52.34%, op_acc: 28.91%] [G loss: 0.884350]\n",
      "epoch:1 step:1378[D loss: 0.472209, acc: 62.50%, op_acc: 31.25%] [G loss: 0.888203]\n",
      "epoch:1 step:1379[D loss: 0.513537, acc: 50.00%, op_acc: 27.34%] [G loss: 0.831402]\n",
      "epoch:1 step:1380[D loss: 0.510816, acc: 53.12%, op_acc: 25.78%] [G loss: 0.788030]\n",
      "epoch:1 step:1381[D loss: 0.480187, acc: 59.38%, op_acc: 25.78%] [G loss: 0.948589]\n",
      "epoch:1 step:1382[D loss: 0.483092, acc: 51.56%, op_acc: 28.91%] [G loss: 0.902676]\n",
      "epoch:1 step:1383[D loss: 0.447686, acc: 60.16%, op_acc: 30.47%] [G loss: 0.930680]\n",
      "epoch:1 step:1384[D loss: 0.467357, acc: 60.16%, op_acc: 30.47%] [G loss: 0.905045]\n",
      "epoch:1 step:1385[D loss: 0.519223, acc: 50.00%, op_acc: 21.09%] [G loss: 0.854790]\n",
      "epoch:1 step:1386[D loss: 0.468883, acc: 61.72%, op_acc: 26.56%] [G loss: 1.048718]\n",
      "epoch:1 step:1387[D loss: 0.478966, acc: 63.28%, op_acc: 28.12%] [G loss: 0.992445]\n",
      "epoch:1 step:1388[D loss: 0.489377, acc: 50.78%, op_acc: 32.03%] [G loss: 0.957019]\n",
      "epoch:1 step:1389[D loss: 0.457512, acc: 63.28%, op_acc: 30.47%] [G loss: 0.963332]\n",
      "epoch:1 step:1390[D loss: 0.489917, acc: 53.12%, op_acc: 32.81%] [G loss: 0.931830]\n",
      "epoch:1 step:1391[D loss: 0.464754, acc: 67.97%, op_acc: 22.66%] [G loss: 0.925143]\n",
      "epoch:1 step:1392[D loss: 0.471379, acc: 57.81%, op_acc: 32.03%] [G loss: 0.987959]\n",
      "epoch:1 step:1393[D loss: 0.506568, acc: 62.50%, op_acc: 21.09%] [G loss: 0.948571]\n",
      "epoch:1 step:1394[D loss: 0.448582, acc: 63.28%, op_acc: 30.47%] [G loss: 1.054300]\n",
      "epoch:1 step:1395[D loss: 0.463087, acc: 62.50%, op_acc: 29.69%] [G loss: 1.005194]\n",
      "epoch:1 step:1396[D loss: 0.470259, acc: 61.72%, op_acc: 27.34%] [G loss: 0.940614]\n",
      "epoch:1 step:1397[D loss: 0.441060, acc: 58.59%, op_acc: 33.59%] [G loss: 0.894841]\n",
      "epoch:1 step:1398[D loss: 0.507006, acc: 57.81%, op_acc: 22.66%] [G loss: 1.020001]\n",
      "epoch:1 step:1399[D loss: 0.459334, acc: 59.38%, op_acc: 32.03%] [G loss: 0.918530]\n",
      "epoch:1 step:1400[D loss: 0.485699, acc: 57.03%, op_acc: 28.91%] [G loss: 1.012508]\n",
      "##############\n",
      "[0.8711478  0.85979412 0.79951317 0.81259716 0.80060331 0.82635153\n",
      " 0.89583959 0.82692781 0.81676864 0.82986435]\n",
      "##########\n",
      "epoch:1 step:1401[D loss: 0.485884, acc: 57.81%, op_acc: 24.22%] [G loss: 1.063992]\n",
      "epoch:1 step:1402[D loss: 0.498185, acc: 57.03%, op_acc: 29.69%] [G loss: 0.901436]\n",
      "epoch:1 step:1403[D loss: 0.491167, acc: 54.69%, op_acc: 31.25%] [G loss: 1.058017]\n",
      "epoch:1 step:1404[D loss: 0.502533, acc: 53.91%, op_acc: 26.56%] [G loss: 0.991029]\n",
      "epoch:1 step:1405[D loss: 0.463877, acc: 59.38%, op_acc: 23.44%] [G loss: 0.976348]\n",
      "epoch:1 step:1406[D loss: 0.473578, acc: 60.94%, op_acc: 26.56%] [G loss: 1.021757]\n",
      "epoch:1 step:1407[D loss: 0.487775, acc: 56.25%, op_acc: 35.16%] [G loss: 1.051910]\n",
      "epoch:1 step:1408[D loss: 0.451085, acc: 67.19%, op_acc: 28.91%] [G loss: 0.942513]\n",
      "epoch:1 step:1409[D loss: 0.504595, acc: 56.25%, op_acc: 24.22%] [G loss: 0.905659]\n",
      "epoch:1 step:1410[D loss: 0.459642, acc: 63.28%, op_acc: 26.56%] [G loss: 0.907739]\n",
      "epoch:1 step:1411[D loss: 0.475382, acc: 59.38%, op_acc: 28.12%] [G loss: 1.031212]\n",
      "epoch:1 step:1412[D loss: 0.461560, acc: 64.84%, op_acc: 29.69%] [G loss: 1.018690]\n",
      "epoch:1 step:1413[D loss: 0.492833, acc: 59.38%, op_acc: 21.09%] [G loss: 0.938970]\n",
      "epoch:1 step:1414[D loss: 0.467358, acc: 60.16%, op_acc: 25.78%] [G loss: 0.933890]\n",
      "epoch:1 step:1415[D loss: 0.479857, acc: 57.81%, op_acc: 35.16%] [G loss: 1.015433]\n",
      "epoch:1 step:1416[D loss: 0.482173, acc: 55.47%, op_acc: 31.25%] [G loss: 0.930561]\n",
      "epoch:1 step:1417[D loss: 0.455469, acc: 62.50%, op_acc: 33.59%] [G loss: 0.969397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1418[D loss: 0.480210, acc: 56.25%, op_acc: 26.56%] [G loss: 0.991662]\n",
      "epoch:1 step:1419[D loss: 0.493955, acc: 58.59%, op_acc: 28.12%] [G loss: 1.029089]\n",
      "epoch:1 step:1420[D loss: 0.464809, acc: 60.94%, op_acc: 27.34%] [G loss: 0.907271]\n",
      "epoch:1 step:1421[D loss: 0.465393, acc: 60.94%, op_acc: 29.69%] [G loss: 0.993529]\n",
      "epoch:1 step:1422[D loss: 0.505976, acc: 53.91%, op_acc: 25.78%] [G loss: 1.011283]\n",
      "epoch:1 step:1423[D loss: 0.496098, acc: 57.03%, op_acc: 24.22%] [G loss: 0.895663]\n",
      "epoch:1 step:1424[D loss: 0.482752, acc: 57.03%, op_acc: 22.66%] [G loss: 1.021298]\n",
      "epoch:1 step:1425[D loss: 0.448571, acc: 68.75%, op_acc: 34.38%] [G loss: 1.044600]\n",
      "epoch:1 step:1426[D loss: 0.487843, acc: 54.69%, op_acc: 25.00%] [G loss: 0.857816]\n",
      "epoch:1 step:1427[D loss: 0.537081, acc: 50.00%, op_acc: 25.78%] [G loss: 0.829409]\n",
      "epoch:1 step:1428[D loss: 0.455999, acc: 55.47%, op_acc: 33.59%] [G loss: 0.915599]\n",
      "epoch:1 step:1429[D loss: 0.479197, acc: 55.47%, op_acc: 29.69%] [G loss: 0.923742]\n",
      "epoch:1 step:1430[D loss: 0.495538, acc: 57.81%, op_acc: 29.69%] [G loss: 0.852165]\n",
      "epoch:1 step:1431[D loss: 0.500449, acc: 58.59%, op_acc: 21.88%] [G loss: 0.826042]\n",
      "epoch:1 step:1432[D loss: 0.494884, acc: 60.16%, op_acc: 28.12%] [G loss: 0.873961]\n",
      "epoch:1 step:1433[D loss: 0.424177, acc: 71.09%, op_acc: 32.03%] [G loss: 0.957371]\n",
      "epoch:1 step:1434[D loss: 0.433008, acc: 63.28%, op_acc: 32.03%] [G loss: 0.935016]\n",
      "epoch:1 step:1435[D loss: 0.463831, acc: 60.94%, op_acc: 31.25%] [G loss: 0.971796]\n",
      "epoch:1 step:1436[D loss: 0.438460, acc: 63.28%, op_acc: 29.69%] [G loss: 0.978328]\n",
      "epoch:1 step:1437[D loss: 0.446095, acc: 67.19%, op_acc: 28.12%] [G loss: 0.969054]\n",
      "epoch:1 step:1438[D loss: 0.473470, acc: 64.06%, op_acc: 31.25%] [G loss: 0.959562]\n",
      "epoch:1 step:1439[D loss: 0.482865, acc: 57.03%, op_acc: 29.69%] [G loss: 0.918783]\n",
      "epoch:1 step:1440[D loss: 0.487281, acc: 62.50%, op_acc: 26.56%] [G loss: 1.026606]\n",
      "epoch:1 step:1441[D loss: 0.506059, acc: 59.38%, op_acc: 23.44%] [G loss: 0.812914]\n",
      "epoch:1 step:1442[D loss: 0.458568, acc: 58.59%, op_acc: 30.47%] [G loss: 1.038796]\n",
      "epoch:1 step:1443[D loss: 0.469310, acc: 57.03%, op_acc: 34.38%] [G loss: 0.882439]\n",
      "epoch:1 step:1444[D loss: 0.463373, acc: 58.59%, op_acc: 30.47%] [G loss: 0.985198]\n",
      "epoch:1 step:1445[D loss: 0.490374, acc: 53.12%, op_acc: 25.78%] [G loss: 0.899605]\n",
      "epoch:1 step:1446[D loss: 0.498236, acc: 60.94%, op_acc: 17.97%] [G loss: 1.011277]\n",
      "epoch:1 step:1447[D loss: 0.529713, acc: 56.25%, op_acc: 20.31%] [G loss: 0.972501]\n",
      "epoch:1 step:1448[D loss: 0.470961, acc: 62.50%, op_acc: 30.47%] [G loss: 0.824119]\n",
      "epoch:1 step:1449[D loss: 0.486573, acc: 54.69%, op_acc: 28.91%] [G loss: 1.024842]\n",
      "epoch:1 step:1450[D loss: 0.473087, acc: 60.16%, op_acc: 22.66%] [G loss: 1.113222]\n",
      "##############\n",
      "[0.86438728 0.84871126 0.83609374 0.8002921  0.79393352 0.81491386\n",
      " 0.87385044 0.83463094 0.81508955 0.81907917]\n",
      "##########\n",
      "epoch:1 step:1451[D loss: 0.486670, acc: 61.72%, op_acc: 25.78%] [G loss: 1.021152]\n",
      "epoch:1 step:1452[D loss: 0.492078, acc: 66.41%, op_acc: 21.88%] [G loss: 0.950487]\n",
      "epoch:1 step:1453[D loss: 0.482277, acc: 50.78%, op_acc: 26.56%] [G loss: 0.897455]\n",
      "epoch:1 step:1454[D loss: 0.451919, acc: 69.53%, op_acc: 31.25%] [G loss: 1.029976]\n",
      "epoch:1 step:1455[D loss: 0.498931, acc: 53.91%, op_acc: 22.66%] [G loss: 0.917104]\n",
      "epoch:1 step:1456[D loss: 0.471912, acc: 58.59%, op_acc: 28.12%] [G loss: 1.046808]\n",
      "epoch:1 step:1457[D loss: 0.482162, acc: 60.94%, op_acc: 23.44%] [G loss: 0.957086]\n",
      "epoch:1 step:1458[D loss: 0.471738, acc: 64.84%, op_acc: 22.66%] [G loss: 1.000934]\n",
      "epoch:1 step:1459[D loss: 0.490752, acc: 55.47%, op_acc: 28.91%] [G loss: 1.022883]\n",
      "epoch:1 step:1460[D loss: 0.446974, acc: 59.38%, op_acc: 28.12%] [G loss: 0.986136]\n",
      "epoch:1 step:1461[D loss: 0.509136, acc: 56.25%, op_acc: 28.12%] [G loss: 0.955234]\n",
      "epoch:1 step:1462[D loss: 0.477264, acc: 64.84%, op_acc: 26.56%] [G loss: 0.938375]\n",
      "epoch:1 step:1463[D loss: 0.480167, acc: 54.69%, op_acc: 36.72%] [G loss: 0.985324]\n",
      "epoch:1 step:1464[D loss: 0.475568, acc: 55.47%, op_acc: 32.81%] [G loss: 0.881944]\n",
      "epoch:1 step:1465[D loss: 0.492317, acc: 57.03%, op_acc: 25.78%] [G loss: 0.988435]\n",
      "epoch:1 step:1466[D loss: 0.488800, acc: 55.47%, op_acc: 25.00%] [G loss: 1.014697]\n",
      "epoch:1 step:1467[D loss: 0.495345, acc: 57.81%, op_acc: 24.22%] [G loss: 0.922270]\n",
      "epoch:1 step:1468[D loss: 0.485682, acc: 62.50%, op_acc: 23.44%] [G loss: 0.955712]\n",
      "epoch:1 step:1469[D loss: 0.489450, acc: 56.25%, op_acc: 28.91%] [G loss: 0.932722]\n",
      "epoch:1 step:1470[D loss: 0.474074, acc: 57.03%, op_acc: 25.78%] [G loss: 0.857022]\n",
      "epoch:1 step:1471[D loss: 0.448839, acc: 64.84%, op_acc: 28.91%] [G loss: 0.890635]\n",
      "epoch:1 step:1472[D loss: 0.498984, acc: 57.03%, op_acc: 24.22%] [G loss: 1.043387]\n",
      "epoch:1 step:1473[D loss: 0.481357, acc: 61.72%, op_acc: 25.00%] [G loss: 1.005485]\n",
      "epoch:1 step:1474[D loss: 0.499088, acc: 57.81%, op_acc: 25.00%] [G loss: 0.969554]\n",
      "epoch:1 step:1475[D loss: 0.468596, acc: 64.06%, op_acc: 32.81%] [G loss: 0.952578]\n",
      "epoch:1 step:1476[D loss: 0.467184, acc: 61.72%, op_acc: 32.03%] [G loss: 0.911489]\n",
      "epoch:1 step:1477[D loss: 0.481824, acc: 57.81%, op_acc: 34.38%] [G loss: 0.835564]\n",
      "epoch:1 step:1478[D loss: 0.480285, acc: 60.16%, op_acc: 24.22%] [G loss: 0.981399]\n",
      "epoch:1 step:1479[D loss: 0.470317, acc: 60.16%, op_acc: 25.78%] [G loss: 0.765284]\n",
      "epoch:1 step:1480[D loss: 0.463778, acc: 58.59%, op_acc: 29.69%] [G loss: 0.966524]\n",
      "epoch:1 step:1481[D loss: 0.486194, acc: 63.28%, op_acc: 22.66%] [G loss: 0.962835]\n",
      "epoch:1 step:1482[D loss: 0.441856, acc: 67.19%, op_acc: 25.78%] [G loss: 0.981332]\n",
      "epoch:1 step:1483[D loss: 0.483092, acc: 56.25%, op_acc: 26.56%] [G loss: 0.848634]\n",
      "epoch:1 step:1484[D loss: 0.496476, acc: 53.12%, op_acc: 25.00%] [G loss: 0.877089]\n",
      "epoch:1 step:1485[D loss: 0.440265, acc: 67.97%, op_acc: 32.81%] [G loss: 1.081055]\n",
      "epoch:1 step:1486[D loss: 0.459855, acc: 63.28%, op_acc: 27.34%] [G loss: 1.019070]\n",
      "epoch:1 step:1487[D loss: 0.495046, acc: 55.47%, op_acc: 24.22%] [G loss: 0.966040]\n",
      "epoch:1 step:1488[D loss: 0.487398, acc: 56.25%, op_acc: 24.22%] [G loss: 0.944344]\n",
      "epoch:1 step:1489[D loss: 0.500699, acc: 55.47%, op_acc: 25.78%] [G loss: 0.964436]\n",
      "epoch:1 step:1490[D loss: 0.506088, acc: 53.91%, op_acc: 20.31%] [G loss: 0.920344]\n",
      "epoch:1 step:1491[D loss: 0.463849, acc: 59.38%, op_acc: 32.81%] [G loss: 0.945430]\n",
      "epoch:1 step:1492[D loss: 0.459286, acc: 64.06%, op_acc: 25.78%] [G loss: 1.042174]\n",
      "epoch:1 step:1493[D loss: 0.474369, acc: 50.78%, op_acc: 34.38%] [G loss: 0.932455]\n",
      "epoch:1 step:1494[D loss: 0.472244, acc: 56.25%, op_acc: 28.91%] [G loss: 1.046673]\n",
      "epoch:1 step:1495[D loss: 0.437824, acc: 63.28%, op_acc: 28.12%] [G loss: 1.092245]\n",
      "epoch:1 step:1496[D loss: 0.486846, acc: 55.47%, op_acc: 28.12%] [G loss: 0.935185]\n",
      "epoch:1 step:1497[D loss: 0.509438, acc: 53.12%, op_acc: 25.00%] [G loss: 0.896998]\n",
      "epoch:1 step:1498[D loss: 0.468698, acc: 64.06%, op_acc: 30.47%] [G loss: 0.994886]\n",
      "epoch:1 step:1499[D loss: 0.469170, acc: 60.16%, op_acc: 26.56%] [G loss: 0.970009]\n",
      "epoch:1 step:1500[D loss: 0.446613, acc: 60.16%, op_acc: 28.12%] [G loss: 0.971426]\n",
      "##############\n",
      "[0.85739384 0.87917228 0.81474474 0.8146934  0.76071528 0.84168342\n",
      " 0.86901923 0.83541393 0.83354623 0.81191739]\n",
      "##########\n",
      "epoch:1 step:1501[D loss: 0.478764, acc: 53.91%, op_acc: 25.78%] [G loss: 0.910403]\n",
      "epoch:1 step:1502[D loss: 0.449926, acc: 66.41%, op_acc: 27.34%] [G loss: 0.936806]\n",
      "epoch:1 step:1503[D loss: 0.477901, acc: 55.47%, op_acc: 32.03%] [G loss: 0.873380]\n",
      "epoch:1 step:1504[D loss: 0.490551, acc: 52.34%, op_acc: 26.56%] [G loss: 0.833287]\n",
      "epoch:1 step:1505[D loss: 0.521918, acc: 54.69%, op_acc: 22.66%] [G loss: 0.978240]\n",
      "epoch:1 step:1506[D loss: 0.480814, acc: 59.38%, op_acc: 22.66%] [G loss: 0.965144]\n",
      "epoch:1 step:1507[D loss: 0.467498, acc: 57.03%, op_acc: 25.78%] [G loss: 0.970371]\n",
      "epoch:1 step:1508[D loss: 0.522544, acc: 53.12%, op_acc: 25.78%] [G loss: 0.896571]\n",
      "epoch:1 step:1509[D loss: 0.469113, acc: 63.28%, op_acc: 21.88%] [G loss: 0.930375]\n",
      "epoch:1 step:1510[D loss: 0.453539, acc: 64.84%, op_acc: 21.09%] [G loss: 0.988323]\n",
      "epoch:1 step:1511[D loss: 0.483844, acc: 55.47%, op_acc: 23.44%] [G loss: 0.933414]\n",
      "epoch:1 step:1512[D loss: 0.470642, acc: 53.12%, op_acc: 28.91%] [G loss: 0.943049]\n",
      "epoch:1 step:1513[D loss: 0.497831, acc: 59.38%, op_acc: 25.00%] [G loss: 1.055495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1514[D loss: 0.477526, acc: 57.81%, op_acc: 24.22%] [G loss: 1.004204]\n",
      "epoch:1 step:1515[D loss: 0.479412, acc: 54.69%, op_acc: 33.59%] [G loss: 0.935570]\n",
      "epoch:1 step:1516[D loss: 0.490148, acc: 60.94%, op_acc: 31.25%] [G loss: 1.025841]\n",
      "epoch:1 step:1517[D loss: 0.457650, acc: 60.94%, op_acc: 28.12%] [G loss: 1.098251]\n",
      "epoch:1 step:1518[D loss: 0.468641, acc: 57.81%, op_acc: 25.78%] [G loss: 0.943669]\n",
      "epoch:1 step:1519[D loss: 0.476718, acc: 62.50%, op_acc: 34.38%] [G loss: 1.037411]\n",
      "epoch:1 step:1520[D loss: 0.476638, acc: 64.06%, op_acc: 24.22%] [G loss: 1.044789]\n",
      "epoch:1 step:1521[D loss: 0.479536, acc: 60.94%, op_acc: 28.91%] [G loss: 0.907657]\n",
      "epoch:1 step:1522[D loss: 0.472966, acc: 55.47%, op_acc: 26.56%] [G loss: 0.951954]\n",
      "epoch:1 step:1523[D loss: 0.451508, acc: 62.50%, op_acc: 30.47%] [G loss: 0.926648]\n",
      "epoch:1 step:1524[D loss: 0.492424, acc: 60.16%, op_acc: 22.66%] [G loss: 0.904785]\n",
      "epoch:1 step:1525[D loss: 0.440482, acc: 64.06%, op_acc: 33.59%] [G loss: 0.951411]\n",
      "epoch:1 step:1526[D loss: 0.470077, acc: 60.94%, op_acc: 28.91%] [G loss: 0.960559]\n",
      "epoch:1 step:1527[D loss: 0.490567, acc: 55.47%, op_acc: 27.34%] [G loss: 0.964157]\n",
      "epoch:1 step:1528[D loss: 0.481663, acc: 53.91%, op_acc: 31.25%] [G loss: 0.921464]\n",
      "epoch:1 step:1529[D loss: 0.504672, acc: 54.69%, op_acc: 22.66%] [G loss: 0.945504]\n",
      "epoch:1 step:1530[D loss: 0.487986, acc: 54.69%, op_acc: 28.91%] [G loss: 0.873819]\n",
      "epoch:1 step:1531[D loss: 0.439802, acc: 64.84%, op_acc: 33.59%] [G loss: 0.976382]\n",
      "epoch:1 step:1532[D loss: 0.501263, acc: 59.38%, op_acc: 21.09%] [G loss: 0.955299]\n",
      "epoch:1 step:1533[D loss: 0.463954, acc: 58.59%, op_acc: 20.31%] [G loss: 0.945186]\n",
      "epoch:1 step:1534[D loss: 0.466241, acc: 60.16%, op_acc: 30.47%] [G loss: 1.051809]\n",
      "epoch:1 step:1535[D loss: 0.473719, acc: 56.25%, op_acc: 25.78%] [G loss: 0.904388]\n",
      "epoch:1 step:1536[D loss: 0.436012, acc: 67.19%, op_acc: 28.91%] [G loss: 0.967688]\n",
      "epoch:1 step:1537[D loss: 0.495064, acc: 56.25%, op_acc: 33.59%] [G loss: 0.893218]\n",
      "epoch:1 step:1538[D loss: 0.503535, acc: 57.81%, op_acc: 17.97%] [G loss: 0.897135]\n",
      "epoch:1 step:1539[D loss: 0.434809, acc: 71.88%, op_acc: 21.88%] [G loss: 0.945046]\n",
      "epoch:1 step:1540[D loss: 0.477160, acc: 60.16%, op_acc: 25.00%] [G loss: 0.897495]\n",
      "epoch:1 step:1541[D loss: 0.487077, acc: 53.12%, op_acc: 31.25%] [G loss: 0.862382]\n",
      "epoch:1 step:1542[D loss: 0.449094, acc: 61.72%, op_acc: 32.03%] [G loss: 0.929595]\n",
      "epoch:1 step:1543[D loss: 0.502990, acc: 58.59%, op_acc: 26.56%] [G loss: 1.012748]\n",
      "epoch:1 step:1544[D loss: 0.480301, acc: 64.06%, op_acc: 26.56%] [G loss: 1.006511]\n",
      "epoch:1 step:1545[D loss: 0.462411, acc: 61.72%, op_acc: 32.03%] [G loss: 1.069395]\n",
      "epoch:1 step:1546[D loss: 0.445736, acc: 66.41%, op_acc: 35.94%] [G loss: 1.044623]\n",
      "epoch:1 step:1547[D loss: 0.483590, acc: 58.59%, op_acc: 28.12%] [G loss: 0.976786]\n",
      "epoch:1 step:1548[D loss: 0.478176, acc: 52.34%, op_acc: 27.34%] [G loss: 0.894650]\n",
      "epoch:1 step:1549[D loss: 0.469554, acc: 61.72%, op_acc: 24.22%] [G loss: 1.012821]\n",
      "epoch:1 step:1550[D loss: 0.421192, acc: 64.84%, op_acc: 39.84%] [G loss: 1.037526]\n",
      "##############\n",
      "[0.86802426 0.88346266 0.82265081 0.8134084  0.7921421  0.81543735\n",
      " 0.90426731 0.83081534 0.81473102 0.82130463]\n",
      "##########\n",
      "epoch:1 step:1551[D loss: 0.449276, acc: 60.16%, op_acc: 29.69%] [G loss: 0.996376]\n",
      "epoch:1 step:1552[D loss: 0.488661, acc: 51.56%, op_acc: 28.12%] [G loss: 1.012763]\n",
      "epoch:1 step:1553[D loss: 0.468766, acc: 58.59%, op_acc: 26.56%] [G loss: 1.059874]\n",
      "epoch:1 step:1554[D loss: 0.450842, acc: 60.16%, op_acc: 29.69%] [G loss: 1.079960]\n",
      "epoch:1 step:1555[D loss: 0.491938, acc: 53.91%, op_acc: 32.81%] [G loss: 0.837783]\n",
      "epoch:1 step:1556[D loss: 0.494813, acc: 57.81%, op_acc: 22.66%] [G loss: 0.956919]\n",
      "epoch:1 step:1557[D loss: 0.447107, acc: 60.94%, op_acc: 27.34%] [G loss: 0.950643]\n",
      "epoch:1 step:1558[D loss: 0.509505, acc: 53.91%, op_acc: 20.31%] [G loss: 0.929455]\n",
      "epoch:1 step:1559[D loss: 0.443218, acc: 58.59%, op_acc: 30.47%] [G loss: 0.987793]\n",
      "epoch:1 step:1560[D loss: 0.457905, acc: 60.94%, op_acc: 33.59%] [G loss: 0.939391]\n",
      "epoch:1 step:1561[D loss: 0.462000, acc: 57.03%, op_acc: 28.12%] [G loss: 0.899955]\n",
      "epoch:1 step:1562[D loss: 0.484935, acc: 60.94%, op_acc: 28.12%] [G loss: 0.889198]\n",
      "epoch:2 step:1563[D loss: 0.489527, acc: 56.25%, op_acc: 26.56%] [G loss: 1.046594]\n",
      "epoch:2 step:1564[D loss: 0.435908, acc: 62.50%, op_acc: 27.34%] [G loss: 0.947875]\n",
      "epoch:2 step:1565[D loss: 0.469640, acc: 57.81%, op_acc: 30.47%] [G loss: 0.995042]\n",
      "epoch:2 step:1566[D loss: 0.408122, acc: 68.75%, op_acc: 30.47%] [G loss: 1.013751]\n",
      "epoch:2 step:1567[D loss: 0.468419, acc: 57.81%, op_acc: 33.59%] [G loss: 0.933862]\n",
      "epoch:2 step:1568[D loss: 0.486978, acc: 57.81%, op_acc: 21.88%] [G loss: 0.988660]\n",
      "epoch:2 step:1569[D loss: 0.446167, acc: 65.62%, op_acc: 31.25%] [G loss: 0.928881]\n",
      "epoch:2 step:1570[D loss: 0.499372, acc: 53.12%, op_acc: 20.31%] [G loss: 0.909445]\n",
      "epoch:2 step:1571[D loss: 0.430785, acc: 60.16%, op_acc: 34.38%] [G loss: 0.944134]\n",
      "epoch:2 step:1572[D loss: 0.479082, acc: 58.59%, op_acc: 27.34%] [G loss: 1.061834]\n",
      "epoch:2 step:1573[D loss: 0.494454, acc: 60.16%, op_acc: 25.78%] [G loss: 0.906514]\n",
      "epoch:2 step:1574[D loss: 0.452565, acc: 60.94%, op_acc: 21.88%] [G loss: 0.825506]\n",
      "epoch:2 step:1575[D loss: 0.491687, acc: 57.03%, op_acc: 26.56%] [G loss: 0.950787]\n",
      "epoch:2 step:1576[D loss: 0.437686, acc: 67.97%, op_acc: 26.56%] [G loss: 1.068307]\n",
      "epoch:2 step:1577[D loss: 0.474031, acc: 59.38%, op_acc: 29.69%] [G loss: 0.948450]\n",
      "epoch:2 step:1578[D loss: 0.486589, acc: 50.78%, op_acc: 30.47%] [G loss: 1.032295]\n",
      "epoch:2 step:1579[D loss: 0.472720, acc: 60.94%, op_acc: 26.56%] [G loss: 0.932782]\n",
      "epoch:2 step:1580[D loss: 0.473655, acc: 62.50%, op_acc: 25.00%] [G loss: 1.049707]\n",
      "epoch:2 step:1581[D loss: 0.463428, acc: 59.38%, op_acc: 30.47%] [G loss: 0.936127]\n",
      "epoch:2 step:1582[D loss: 0.473316, acc: 59.38%, op_acc: 22.66%] [G loss: 0.851344]\n",
      "epoch:2 step:1583[D loss: 0.456279, acc: 67.97%, op_acc: 21.09%] [G loss: 0.904795]\n",
      "epoch:2 step:1584[D loss: 0.459704, acc: 60.16%, op_acc: 33.59%] [G loss: 0.936967]\n",
      "epoch:2 step:1585[D loss: 0.471490, acc: 57.03%, op_acc: 27.34%] [G loss: 0.989431]\n",
      "epoch:2 step:1586[D loss: 0.496896, acc: 56.25%, op_acc: 25.78%] [G loss: 0.850302]\n",
      "epoch:2 step:1587[D loss: 0.498245, acc: 53.12%, op_acc: 28.91%] [G loss: 1.076823]\n",
      "epoch:2 step:1588[D loss: 0.456711, acc: 61.72%, op_acc: 30.47%] [G loss: 0.894710]\n",
      "epoch:2 step:1589[D loss: 0.446993, acc: 68.75%, op_acc: 26.56%] [G loss: 0.972995]\n",
      "epoch:2 step:1590[D loss: 0.461277, acc: 57.81%, op_acc: 34.38%] [G loss: 0.909919]\n",
      "epoch:2 step:1591[D loss: 0.463817, acc: 60.94%, op_acc: 25.00%] [G loss: 1.089880]\n",
      "epoch:2 step:1592[D loss: 0.487856, acc: 47.66%, op_acc: 29.69%] [G loss: 0.894439]\n",
      "epoch:2 step:1593[D loss: 0.486130, acc: 57.03%, op_acc: 24.22%] [G loss: 0.899687]\n",
      "epoch:2 step:1594[D loss: 0.504893, acc: 57.81%, op_acc: 29.69%] [G loss: 0.968449]\n",
      "epoch:2 step:1595[D loss: 0.441589, acc: 60.94%, op_acc: 29.69%] [G loss: 1.078575]\n",
      "epoch:2 step:1596[D loss: 0.471477, acc: 60.94%, op_acc: 31.25%] [G loss: 1.092299]\n",
      "epoch:2 step:1597[D loss: 0.447061, acc: 60.16%, op_acc: 34.38%] [G loss: 0.977742]\n",
      "epoch:2 step:1598[D loss: 0.522500, acc: 48.44%, op_acc: 28.12%] [G loss: 0.865548]\n",
      "epoch:2 step:1599[D loss: 0.520929, acc: 49.22%, op_acc: 26.56%] [G loss: 0.907389]\n",
      "epoch:2 step:1600[D loss: 0.430328, acc: 60.94%, op_acc: 36.72%] [G loss: 1.089014]\n",
      "##############\n",
      "[0.82970732 0.86313564 0.81084481 0.79642208 0.76488592 0.81410761\n",
      " 0.89715407 0.83351423 0.80516113 0.82714968]\n",
      "##########\n",
      "epoch:2 step:1601[D loss: 0.452341, acc: 62.50%, op_acc: 25.00%] [G loss: 0.954396]\n",
      "epoch:2 step:1602[D loss: 0.434521, acc: 68.75%, op_acc: 26.56%] [G loss: 1.012376]\n",
      "epoch:2 step:1603[D loss: 0.429873, acc: 70.31%, op_acc: 29.69%] [G loss: 1.059485]\n",
      "epoch:2 step:1604[D loss: 0.454556, acc: 59.38%, op_acc: 29.69%] [G loss: 0.942182]\n",
      "epoch:2 step:1605[D loss: 0.455633, acc: 62.50%, op_acc: 26.56%] [G loss: 0.961597]\n",
      "epoch:2 step:1606[D loss: 0.493687, acc: 58.59%, op_acc: 21.88%] [G loss: 0.910279]\n",
      "epoch:2 step:1607[D loss: 0.482605, acc: 58.59%, op_acc: 32.03%] [G loss: 0.898343]\n",
      "epoch:2 step:1608[D loss: 0.472723, acc: 56.25%, op_acc: 29.69%] [G loss: 1.017172]\n",
      "epoch:2 step:1609[D loss: 0.497799, acc: 57.03%, op_acc: 28.12%] [G loss: 0.866926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1610[D loss: 0.460228, acc: 66.41%, op_acc: 23.44%] [G loss: 0.893714]\n",
      "epoch:2 step:1611[D loss: 0.491202, acc: 51.56%, op_acc: 27.34%] [G loss: 0.969463]\n",
      "epoch:2 step:1612[D loss: 0.516554, acc: 57.81%, op_acc: 21.88%] [G loss: 0.934000]\n",
      "epoch:2 step:1613[D loss: 0.480514, acc: 59.38%, op_acc: 26.56%] [G loss: 0.885518]\n",
      "epoch:2 step:1614[D loss: 0.479493, acc: 57.03%, op_acc: 28.91%] [G loss: 0.917162]\n",
      "epoch:2 step:1615[D loss: 0.479290, acc: 61.72%, op_acc: 31.25%] [G loss: 0.973523]\n",
      "epoch:2 step:1616[D loss: 0.474875, acc: 60.94%, op_acc: 28.12%] [G loss: 0.968731]\n",
      "epoch:2 step:1617[D loss: 0.431000, acc: 69.53%, op_acc: 29.69%] [G loss: 1.009941]\n",
      "epoch:2 step:1618[D loss: 0.455913, acc: 65.62%, op_acc: 25.00%] [G loss: 1.123097]\n",
      "epoch:2 step:1619[D loss: 0.483115, acc: 56.25%, op_acc: 27.34%] [G loss: 1.022481]\n",
      "epoch:2 step:1620[D loss: 0.437874, acc: 68.75%, op_acc: 35.16%] [G loss: 0.925635]\n",
      "epoch:2 step:1621[D loss: 0.430840, acc: 64.84%, op_acc: 31.25%] [G loss: 0.995876]\n",
      "epoch:2 step:1622[D loss: 0.452764, acc: 60.16%, op_acc: 26.56%] [G loss: 1.031782]\n",
      "epoch:2 step:1623[D loss: 0.471751, acc: 55.47%, op_acc: 26.56%] [G loss: 0.970237]\n",
      "epoch:2 step:1624[D loss: 0.533288, acc: 47.66%, op_acc: 20.31%] [G loss: 0.910762]\n",
      "epoch:2 step:1625[D loss: 0.475613, acc: 57.03%, op_acc: 29.69%] [G loss: 0.983226]\n",
      "epoch:2 step:1626[D loss: 0.510442, acc: 47.66%, op_acc: 27.34%] [G loss: 1.000973]\n",
      "epoch:2 step:1627[D loss: 0.471192, acc: 58.59%, op_acc: 29.69%] [G loss: 1.037226]\n",
      "epoch:2 step:1628[D loss: 0.464706, acc: 61.72%, op_acc: 29.69%] [G loss: 0.895524]\n",
      "epoch:2 step:1629[D loss: 0.442094, acc: 67.97%, op_acc: 35.16%] [G loss: 1.040984]\n",
      "epoch:2 step:1630[D loss: 0.494425, acc: 55.47%, op_acc: 28.91%] [G loss: 0.919403]\n",
      "epoch:2 step:1631[D loss: 0.442346, acc: 67.97%, op_acc: 33.59%] [G loss: 0.978716]\n",
      "epoch:2 step:1632[D loss: 0.466086, acc: 60.94%, op_acc: 27.34%] [G loss: 0.882387]\n",
      "epoch:2 step:1633[D loss: 0.520553, acc: 55.47%, op_acc: 17.97%] [G loss: 0.923095]\n",
      "epoch:2 step:1634[D loss: 0.459009, acc: 57.03%, op_acc: 30.47%] [G loss: 1.106531]\n",
      "epoch:2 step:1635[D loss: 0.459580, acc: 57.81%, op_acc: 25.78%] [G loss: 0.963230]\n",
      "epoch:2 step:1636[D loss: 0.457349, acc: 57.81%, op_acc: 30.47%] [G loss: 0.844831]\n",
      "epoch:2 step:1637[D loss: 0.479521, acc: 55.47%, op_acc: 21.88%] [G loss: 1.021315]\n",
      "epoch:2 step:1638[D loss: 0.475166, acc: 58.59%, op_acc: 28.91%] [G loss: 0.906480]\n",
      "epoch:2 step:1639[D loss: 0.477550, acc: 56.25%, op_acc: 25.78%] [G loss: 0.888674]\n",
      "epoch:2 step:1640[D loss: 0.469819, acc: 66.41%, op_acc: 25.78%] [G loss: 0.914495]\n",
      "epoch:2 step:1641[D loss: 0.475842, acc: 66.41%, op_acc: 27.34%] [G loss: 0.976526]\n",
      "epoch:2 step:1642[D loss: 0.496050, acc: 63.28%, op_acc: 17.97%] [G loss: 0.958250]\n",
      "epoch:2 step:1643[D loss: 0.492954, acc: 63.28%, op_acc: 23.44%] [G loss: 1.014607]\n",
      "epoch:2 step:1644[D loss: 0.486961, acc: 53.91%, op_acc: 27.34%] [G loss: 1.008157]\n",
      "epoch:2 step:1645[D loss: 0.470176, acc: 61.72%, op_acc: 35.16%] [G loss: 0.986989]\n",
      "epoch:2 step:1646[D loss: 0.457550, acc: 60.94%, op_acc: 28.91%] [G loss: 1.020273]\n",
      "epoch:2 step:1647[D loss: 0.473749, acc: 59.38%, op_acc: 23.44%] [G loss: 0.970697]\n",
      "epoch:2 step:1648[D loss: 0.469409, acc: 58.59%, op_acc: 25.78%] [G loss: 0.919572]\n",
      "epoch:2 step:1649[D loss: 0.461176, acc: 62.50%, op_acc: 26.56%] [G loss: 1.009700]\n",
      "epoch:2 step:1650[D loss: 0.439139, acc: 61.72%, op_acc: 33.59%] [G loss: 1.009967]\n",
      "##############\n",
      "[0.8658183  0.87573366 0.83341802 0.81239382 0.80333997 0.82412332\n",
      " 0.86289478 0.81187235 0.8161828  0.83872016]\n",
      "##########\n",
      "epoch:2 step:1651[D loss: 0.502556, acc: 50.78%, op_acc: 23.44%] [G loss: 0.844212]\n",
      "epoch:2 step:1652[D loss: 0.458330, acc: 61.72%, op_acc: 33.59%] [G loss: 0.981331]\n",
      "epoch:2 step:1653[D loss: 0.467730, acc: 64.84%, op_acc: 24.22%] [G loss: 0.935530]\n",
      "epoch:2 step:1654[D loss: 0.462888, acc: 58.59%, op_acc: 26.56%] [G loss: 0.992090]\n",
      "epoch:2 step:1655[D loss: 0.469200, acc: 54.69%, op_acc: 32.03%] [G loss: 0.950967]\n",
      "epoch:2 step:1656[D loss: 0.474131, acc: 58.59%, op_acc: 35.16%] [G loss: 0.881958]\n",
      "epoch:2 step:1657[D loss: 0.481886, acc: 53.91%, op_acc: 26.56%] [G loss: 0.882516]\n",
      "epoch:2 step:1658[D loss: 0.482360, acc: 57.81%, op_acc: 23.44%] [G loss: 0.987654]\n",
      "epoch:2 step:1659[D loss: 0.485030, acc: 50.00%, op_acc: 28.91%] [G loss: 0.994591]\n",
      "epoch:2 step:1660[D loss: 0.490174, acc: 60.94%, op_acc: 22.66%] [G loss: 0.980536]\n",
      "epoch:2 step:1661[D loss: 0.469020, acc: 57.81%, op_acc: 31.25%] [G loss: 0.899559]\n",
      "epoch:2 step:1662[D loss: 0.462304, acc: 53.91%, op_acc: 27.34%] [G loss: 0.986112]\n",
      "epoch:2 step:1663[D loss: 0.460275, acc: 57.81%, op_acc: 28.12%] [G loss: 0.903818]\n",
      "epoch:2 step:1664[D loss: 0.481003, acc: 49.22%, op_acc: 32.03%] [G loss: 0.909750]\n",
      "epoch:2 step:1665[D loss: 0.482482, acc: 57.81%, op_acc: 25.00%] [G loss: 0.898924]\n",
      "epoch:2 step:1666[D loss: 0.473983, acc: 53.91%, op_acc: 19.53%] [G loss: 0.989830]\n",
      "epoch:2 step:1667[D loss: 0.478602, acc: 57.81%, op_acc: 32.81%] [G loss: 1.002482]\n",
      "epoch:2 step:1668[D loss: 0.488940, acc: 53.12%, op_acc: 29.69%] [G loss: 0.901526]\n",
      "epoch:2 step:1669[D loss: 0.450998, acc: 62.50%, op_acc: 30.47%] [G loss: 0.984090]\n",
      "epoch:2 step:1670[D loss: 0.486662, acc: 57.81%, op_acc: 26.56%] [G loss: 0.885303]\n",
      "epoch:2 step:1671[D loss: 0.513785, acc: 48.44%, op_acc: 29.69%] [G loss: 0.933074]\n",
      "epoch:2 step:1672[D loss: 0.458756, acc: 61.72%, op_acc: 30.47%] [G loss: 1.073973]\n",
      "epoch:2 step:1673[D loss: 0.461315, acc: 61.72%, op_acc: 28.12%] [G loss: 0.891961]\n",
      "epoch:2 step:1674[D loss: 0.458468, acc: 54.69%, op_acc: 32.03%] [G loss: 0.953598]\n",
      "epoch:2 step:1675[D loss: 0.458240, acc: 64.84%, op_acc: 24.22%] [G loss: 0.910692]\n",
      "epoch:2 step:1676[D loss: 0.456073, acc: 60.16%, op_acc: 30.47%] [G loss: 1.022009]\n",
      "epoch:2 step:1677[D loss: 0.444131, acc: 59.38%, op_acc: 30.47%] [G loss: 0.962097]\n",
      "epoch:2 step:1678[D loss: 0.475085, acc: 61.72%, op_acc: 30.47%] [G loss: 0.890324]\n",
      "epoch:2 step:1679[D loss: 0.488276, acc: 60.16%, op_acc: 22.66%] [G loss: 0.830665]\n",
      "epoch:2 step:1680[D loss: 0.477140, acc: 64.06%, op_acc: 29.69%] [G loss: 0.875981]\n",
      "epoch:2 step:1681[D loss: 0.439090, acc: 64.06%, op_acc: 28.12%] [G loss: 0.940965]\n",
      "epoch:2 step:1682[D loss: 0.483263, acc: 51.56%, op_acc: 28.91%] [G loss: 0.912511]\n",
      "epoch:2 step:1683[D loss: 0.476100, acc: 63.28%, op_acc: 29.69%] [G loss: 0.967292]\n",
      "epoch:2 step:1684[D loss: 0.446029, acc: 64.06%, op_acc: 26.56%] [G loss: 1.067369]\n",
      "epoch:2 step:1685[D loss: 0.487585, acc: 53.91%, op_acc: 32.03%] [G loss: 0.889081]\n",
      "epoch:2 step:1686[D loss: 0.477257, acc: 59.38%, op_acc: 30.47%] [G loss: 1.036926]\n",
      "epoch:2 step:1687[D loss: 0.512560, acc: 60.16%, op_acc: 25.78%] [G loss: 0.953998]\n",
      "epoch:2 step:1688[D loss: 0.477354, acc: 57.03%, op_acc: 29.69%] [G loss: 0.883698]\n",
      "epoch:2 step:1689[D loss: 0.446922, acc: 61.72%, op_acc: 29.69%] [G loss: 0.968983]\n",
      "epoch:2 step:1690[D loss: 0.441446, acc: 70.31%, op_acc: 30.47%] [G loss: 0.980070]\n",
      "epoch:2 step:1691[D loss: 0.449000, acc: 70.31%, op_acc: 36.72%] [G loss: 1.025623]\n",
      "epoch:2 step:1692[D loss: 0.483781, acc: 51.56%, op_acc: 34.38%] [G loss: 1.034743]\n",
      "epoch:2 step:1693[D loss: 0.438475, acc: 60.94%, op_acc: 26.56%] [G loss: 1.026248]\n",
      "epoch:2 step:1694[D loss: 0.405033, acc: 72.66%, op_acc: 33.59%] [G loss: 0.922272]\n",
      "epoch:2 step:1695[D loss: 0.485622, acc: 59.38%, op_acc: 25.00%] [G loss: 0.992909]\n",
      "epoch:2 step:1696[D loss: 0.452034, acc: 65.62%, op_acc: 28.12%] [G loss: 0.895223]\n",
      "epoch:2 step:1697[D loss: 0.476302, acc: 63.28%, op_acc: 26.56%] [G loss: 0.909817]\n",
      "epoch:2 step:1698[D loss: 0.456500, acc: 62.50%, op_acc: 33.59%] [G loss: 0.950723]\n",
      "epoch:2 step:1699[D loss: 0.511072, acc: 51.56%, op_acc: 29.69%] [G loss: 0.978146]\n",
      "epoch:2 step:1700[D loss: 0.487262, acc: 54.69%, op_acc: 26.56%] [G loss: 0.963416]\n",
      "##############\n",
      "[0.8650755  0.86323227 0.81978106 0.82317968 0.78609422 0.82169446\n",
      " 0.86969991 0.82380209 0.84395812 0.84058361]\n",
      "##########\n",
      "epoch:2 step:1701[D loss: 0.472913, acc: 57.03%, op_acc: 25.78%] [G loss: 0.841893]\n",
      "epoch:2 step:1702[D loss: 0.513328, acc: 55.47%, op_acc: 21.88%] [G loss: 0.852342]\n",
      "epoch:2 step:1703[D loss: 0.498618, acc: 56.25%, op_acc: 20.31%] [G loss: 0.868848]\n",
      "epoch:2 step:1704[D loss: 0.463049, acc: 60.94%, op_acc: 21.88%] [G loss: 0.883771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1705[D loss: 0.464935, acc: 57.03%, op_acc: 32.81%] [G loss: 0.877925]\n",
      "epoch:2 step:1706[D loss: 0.445746, acc: 64.84%, op_acc: 32.03%] [G loss: 0.879687]\n",
      "epoch:2 step:1707[D loss: 0.467520, acc: 58.59%, op_acc: 28.12%] [G loss: 0.915092]\n",
      "epoch:2 step:1708[D loss: 0.435454, acc: 71.88%, op_acc: 24.22%] [G loss: 0.959916]\n",
      "epoch:2 step:1709[D loss: 0.464407, acc: 60.16%, op_acc: 35.16%] [G loss: 1.026596]\n",
      "epoch:2 step:1710[D loss: 0.516801, acc: 52.34%, op_acc: 24.22%] [G loss: 0.993090]\n",
      "epoch:2 step:1711[D loss: 0.467291, acc: 61.72%, op_acc: 31.25%] [G loss: 0.954904]\n",
      "epoch:2 step:1712[D loss: 0.466146, acc: 59.38%, op_acc: 32.03%] [G loss: 0.972438]\n",
      "epoch:2 step:1713[D loss: 0.475706, acc: 55.47%, op_acc: 29.69%] [G loss: 0.981684]\n",
      "epoch:2 step:1714[D loss: 0.430247, acc: 67.19%, op_acc: 25.78%] [G loss: 0.988612]\n",
      "epoch:2 step:1715[D loss: 0.494153, acc: 65.62%, op_acc: 24.22%] [G loss: 0.936994]\n",
      "epoch:2 step:1716[D loss: 0.437065, acc: 60.16%, op_acc: 33.59%] [G loss: 0.992562]\n",
      "epoch:2 step:1717[D loss: 0.460332, acc: 64.06%, op_acc: 28.91%] [G loss: 0.931349]\n",
      "epoch:2 step:1718[D loss: 0.464790, acc: 57.03%, op_acc: 28.12%] [G loss: 0.911700]\n",
      "epoch:2 step:1719[D loss: 0.464390, acc: 62.50%, op_acc: 27.34%] [G loss: 0.979089]\n",
      "epoch:2 step:1720[D loss: 0.472766, acc: 56.25%, op_acc: 31.25%] [G loss: 0.925232]\n",
      "epoch:2 step:1721[D loss: 0.473074, acc: 61.72%, op_acc: 31.25%] [G loss: 1.045382]\n",
      "epoch:2 step:1722[D loss: 0.492494, acc: 58.59%, op_acc: 21.88%] [G loss: 0.956008]\n",
      "epoch:2 step:1723[D loss: 0.464669, acc: 61.72%, op_acc: 28.12%] [G loss: 0.959645]\n",
      "epoch:2 step:1724[D loss: 0.432479, acc: 63.28%, op_acc: 34.38%] [G loss: 0.966675]\n",
      "epoch:2 step:1725[D loss: 0.458429, acc: 61.72%, op_acc: 23.44%] [G loss: 0.917206]\n",
      "epoch:2 step:1726[D loss: 0.487792, acc: 58.59%, op_acc: 17.97%] [G loss: 0.954308]\n",
      "epoch:2 step:1727[D loss: 0.464327, acc: 54.69%, op_acc: 31.25%] [G loss: 1.004824]\n",
      "epoch:2 step:1728[D loss: 0.464069, acc: 61.72%, op_acc: 25.78%] [G loss: 1.040177]\n",
      "epoch:2 step:1729[D loss: 0.453460, acc: 61.72%, op_acc: 32.81%] [G loss: 0.927390]\n",
      "epoch:2 step:1730[D loss: 0.460244, acc: 58.59%, op_acc: 28.12%] [G loss: 0.870849]\n",
      "epoch:2 step:1731[D loss: 0.499410, acc: 47.66%, op_acc: 35.94%] [G loss: 0.962806]\n",
      "epoch:2 step:1732[D loss: 0.454647, acc: 62.50%, op_acc: 32.81%] [G loss: 1.076170]\n",
      "epoch:2 step:1733[D loss: 0.487108, acc: 53.12%, op_acc: 25.78%] [G loss: 1.011639]\n",
      "epoch:2 step:1734[D loss: 0.451205, acc: 64.06%, op_acc: 32.81%] [G loss: 1.064791]\n",
      "epoch:2 step:1735[D loss: 0.462095, acc: 59.38%, op_acc: 27.34%] [G loss: 0.873204]\n",
      "epoch:2 step:1736[D loss: 0.486186, acc: 56.25%, op_acc: 25.00%] [G loss: 0.881980]\n",
      "epoch:2 step:1737[D loss: 0.474703, acc: 51.56%, op_acc: 29.69%] [G loss: 1.000584]\n",
      "epoch:2 step:1738[D loss: 0.452983, acc: 61.72%, op_acc: 28.91%] [G loss: 0.969200]\n",
      "epoch:2 step:1739[D loss: 0.422174, acc: 64.84%, op_acc: 31.25%] [G loss: 1.103945]\n",
      "epoch:2 step:1740[D loss: 0.496006, acc: 57.03%, op_acc: 28.12%] [G loss: 1.058549]\n",
      "epoch:2 step:1741[D loss: 0.468862, acc: 53.91%, op_acc: 29.69%] [G loss: 0.943728]\n",
      "epoch:2 step:1742[D loss: 0.477536, acc: 57.81%, op_acc: 28.91%] [G loss: 0.908355]\n",
      "epoch:2 step:1743[D loss: 0.454825, acc: 63.28%, op_acc: 27.34%] [G loss: 1.091154]\n",
      "epoch:2 step:1744[D loss: 0.466660, acc: 58.59%, op_acc: 28.91%] [G loss: 0.991043]\n",
      "epoch:2 step:1745[D loss: 0.439489, acc: 62.50%, op_acc: 32.03%] [G loss: 1.028124]\n",
      "epoch:2 step:1746[D loss: 0.413216, acc: 65.62%, op_acc: 33.59%] [G loss: 1.024559]\n",
      "epoch:2 step:1747[D loss: 0.454729, acc: 64.84%, op_acc: 28.12%] [G loss: 1.085542]\n",
      "epoch:2 step:1748[D loss: 0.491575, acc: 57.81%, op_acc: 30.47%] [G loss: 0.919522]\n",
      "epoch:2 step:1749[D loss: 0.497294, acc: 56.25%, op_acc: 23.44%] [G loss: 1.026126]\n",
      "epoch:2 step:1750[D loss: 0.486205, acc: 58.59%, op_acc: 28.12%] [G loss: 1.003943]\n",
      "##############\n",
      "[0.86332739 0.84628709 0.81788404 0.81282811 0.79695816 0.84133536\n",
      " 0.88139752 0.87385204 0.8288187  0.81301914]\n",
      "##########\n",
      "epoch:2 step:1751[D loss: 0.476529, acc: 58.59%, op_acc: 32.03%] [G loss: 1.026478]\n",
      "epoch:2 step:1752[D loss: 0.485501, acc: 58.59%, op_acc: 30.47%] [G loss: 0.987730]\n",
      "epoch:2 step:1753[D loss: 0.436681, acc: 64.84%, op_acc: 31.25%] [G loss: 1.043571]\n",
      "epoch:2 step:1754[D loss: 0.485126, acc: 54.69%, op_acc: 30.47%] [G loss: 0.937871]\n",
      "epoch:2 step:1755[D loss: 0.463272, acc: 62.50%, op_acc: 26.56%] [G loss: 1.004365]\n",
      "epoch:2 step:1756[D loss: 0.489036, acc: 50.78%, op_acc: 35.94%] [G loss: 0.828891]\n",
      "epoch:2 step:1757[D loss: 0.498912, acc: 53.91%, op_acc: 24.22%] [G loss: 1.030823]\n",
      "epoch:2 step:1758[D loss: 0.493817, acc: 55.47%, op_acc: 28.12%] [G loss: 0.896787]\n",
      "epoch:2 step:1759[D loss: 0.498404, acc: 49.22%, op_acc: 24.22%] [G loss: 0.888563]\n",
      "epoch:2 step:1760[D loss: 0.473581, acc: 60.16%, op_acc: 28.91%] [G loss: 0.970666]\n",
      "epoch:2 step:1761[D loss: 0.480231, acc: 59.38%, op_acc: 28.91%] [G loss: 0.986168]\n",
      "epoch:2 step:1762[D loss: 0.487257, acc: 59.38%, op_acc: 27.34%] [G loss: 1.009599]\n",
      "epoch:2 step:1763[D loss: 0.432358, acc: 64.84%, op_acc: 32.81%] [G loss: 0.950953]\n",
      "epoch:2 step:1764[D loss: 0.508903, acc: 54.69%, op_acc: 25.78%] [G loss: 0.910140]\n",
      "epoch:2 step:1765[D loss: 0.468695, acc: 59.38%, op_acc: 28.91%] [G loss: 0.984654]\n",
      "epoch:2 step:1766[D loss: 0.434380, acc: 68.75%, op_acc: 30.47%] [G loss: 1.087800]\n",
      "epoch:2 step:1767[D loss: 0.487454, acc: 56.25%, op_acc: 22.66%] [G loss: 0.944008]\n",
      "epoch:2 step:1768[D loss: 0.461881, acc: 60.94%, op_acc: 25.00%] [G loss: 0.960124]\n",
      "epoch:2 step:1769[D loss: 0.489785, acc: 52.34%, op_acc: 28.12%] [G loss: 1.016069]\n",
      "epoch:2 step:1770[D loss: 0.513756, acc: 50.78%, op_acc: 25.00%] [G loss: 0.973646]\n",
      "epoch:2 step:1771[D loss: 0.447952, acc: 64.06%, op_acc: 34.38%] [G loss: 1.032920]\n",
      "epoch:2 step:1772[D loss: 0.467753, acc: 60.94%, op_acc: 27.34%] [G loss: 1.051254]\n",
      "epoch:2 step:1773[D loss: 0.456729, acc: 60.16%, op_acc: 31.25%] [G loss: 0.989715]\n",
      "epoch:2 step:1774[D loss: 0.462023, acc: 59.38%, op_acc: 30.47%] [G loss: 0.957498]\n",
      "epoch:2 step:1775[D loss: 0.439926, acc: 61.72%, op_acc: 28.12%] [G loss: 0.942729]\n",
      "epoch:2 step:1776[D loss: 0.484123, acc: 60.94%, op_acc: 24.22%] [G loss: 1.010659]\n",
      "epoch:2 step:1777[D loss: 0.489858, acc: 60.16%, op_acc: 25.78%] [G loss: 1.035654]\n",
      "epoch:2 step:1778[D loss: 0.468300, acc: 62.50%, op_acc: 19.53%] [G loss: 1.016998]\n",
      "epoch:2 step:1779[D loss: 0.428233, acc: 67.19%, op_acc: 29.69%] [G loss: 0.979418]\n",
      "epoch:2 step:1780[D loss: 0.492542, acc: 58.59%, op_acc: 28.12%] [G loss: 0.941981]\n",
      "epoch:2 step:1781[D loss: 0.449923, acc: 57.81%, op_acc: 30.47%] [G loss: 1.001758]\n",
      "epoch:2 step:1782[D loss: 0.475153, acc: 58.59%, op_acc: 28.12%] [G loss: 0.850523]\n",
      "epoch:2 step:1783[D loss: 0.460165, acc: 60.94%, op_acc: 26.56%] [G loss: 0.979467]\n",
      "epoch:2 step:1784[D loss: 0.454802, acc: 65.62%, op_acc: 30.47%] [G loss: 0.931225]\n",
      "epoch:2 step:1785[D loss: 0.515016, acc: 46.09%, op_acc: 26.56%] [G loss: 0.987946]\n",
      "epoch:2 step:1786[D loss: 0.468707, acc: 58.59%, op_acc: 21.88%] [G loss: 1.026282]\n",
      "epoch:2 step:1787[D loss: 0.468695, acc: 60.94%, op_acc: 21.09%] [G loss: 0.993212]\n",
      "epoch:2 step:1788[D loss: 0.457833, acc: 60.94%, op_acc: 24.22%] [G loss: 0.964036]\n",
      "epoch:2 step:1789[D loss: 0.437571, acc: 68.75%, op_acc: 27.34%] [G loss: 0.934109]\n",
      "epoch:2 step:1790[D loss: 0.418796, acc: 66.41%, op_acc: 26.56%] [G loss: 1.016590]\n",
      "epoch:2 step:1791[D loss: 0.502970, acc: 59.38%, op_acc: 27.34%] [G loss: 0.949719]\n",
      "epoch:2 step:1792[D loss: 0.479968, acc: 61.72%, op_acc: 27.34%] [G loss: 0.868885]\n",
      "epoch:2 step:1793[D loss: 0.468899, acc: 59.38%, op_acc: 32.03%] [G loss: 0.857301]\n",
      "epoch:2 step:1794[D loss: 0.491810, acc: 60.94%, op_acc: 26.56%] [G loss: 0.875536]\n",
      "epoch:2 step:1795[D loss: 0.439670, acc: 66.41%, op_acc: 32.81%] [G loss: 0.790436]\n",
      "epoch:2 step:1796[D loss: 0.499541, acc: 61.72%, op_acc: 25.78%] [G loss: 1.006838]\n",
      "epoch:2 step:1797[D loss: 0.488900, acc: 56.25%, op_acc: 30.47%] [G loss: 0.946250]\n",
      "epoch:2 step:1798[D loss: 0.495362, acc: 57.03%, op_acc: 24.22%] [G loss: 1.020099]\n",
      "epoch:2 step:1799[D loss: 0.447824, acc: 67.97%, op_acc: 25.78%] [G loss: 1.059775]\n",
      "epoch:2 step:1800[D loss: 0.528442, acc: 51.56%, op_acc: 25.78%] [G loss: 1.053174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.88585688 0.85811521 0.80578064 0.81694539 0.78693409 0.81898075\n",
      " 0.87760726 0.84213884 0.83167867 0.81056143]\n",
      "##########\n",
      "epoch:2 step:1801[D loss: 0.444268, acc: 66.41%, op_acc: 26.56%] [G loss: 0.990197]\n",
      "epoch:2 step:1802[D loss: 0.468684, acc: 62.50%, op_acc: 28.12%] [G loss: 0.925904]\n",
      "epoch:2 step:1803[D loss: 0.464414, acc: 53.91%, op_acc: 31.25%] [G loss: 0.950810]\n",
      "epoch:2 step:1804[D loss: 0.462590, acc: 61.72%, op_acc: 30.47%] [G loss: 0.995882]\n",
      "epoch:2 step:1805[D loss: 0.490712, acc: 61.72%, op_acc: 28.91%] [G loss: 0.904238]\n",
      "epoch:2 step:1806[D loss: 0.521503, acc: 51.56%, op_acc: 26.56%] [G loss: 0.918867]\n",
      "epoch:2 step:1807[D loss: 0.466073, acc: 54.69%, op_acc: 35.16%] [G loss: 0.927192]\n",
      "epoch:2 step:1808[D loss: 0.487558, acc: 53.91%, op_acc: 25.78%] [G loss: 0.943038]\n",
      "epoch:2 step:1809[D loss: 0.458241, acc: 60.16%, op_acc: 33.59%] [G loss: 0.958117]\n",
      "epoch:2 step:1810[D loss: 0.477110, acc: 64.06%, op_acc: 27.34%] [G loss: 0.996205]\n",
      "epoch:2 step:1811[D loss: 0.478172, acc: 60.94%, op_acc: 26.56%] [G loss: 0.970802]\n",
      "epoch:2 step:1812[D loss: 0.489336, acc: 56.25%, op_acc: 24.22%] [G loss: 0.871216]\n",
      "epoch:2 step:1813[D loss: 0.482520, acc: 59.38%, op_acc: 32.03%] [G loss: 0.888935]\n",
      "epoch:2 step:1814[D loss: 0.445377, acc: 66.41%, op_acc: 32.81%] [G loss: 0.935735]\n",
      "epoch:2 step:1815[D loss: 0.475863, acc: 57.81%, op_acc: 29.69%] [G loss: 0.931165]\n",
      "epoch:2 step:1816[D loss: 0.456306, acc: 68.75%, op_acc: 28.12%] [G loss: 0.904494]\n",
      "epoch:2 step:1817[D loss: 0.446312, acc: 64.06%, op_acc: 28.12%] [G loss: 0.894085]\n",
      "epoch:2 step:1818[D loss: 0.471296, acc: 60.16%, op_acc: 32.03%] [G loss: 0.818563]\n",
      "epoch:2 step:1819[D loss: 0.442665, acc: 60.94%, op_acc: 28.12%] [G loss: 0.931322]\n",
      "epoch:2 step:1820[D loss: 0.456024, acc: 64.84%, op_acc: 31.25%] [G loss: 0.996994]\n",
      "epoch:2 step:1821[D loss: 0.454710, acc: 64.84%, op_acc: 28.12%] [G loss: 0.923069]\n",
      "epoch:2 step:1822[D loss: 0.464372, acc: 63.28%, op_acc: 27.34%] [G loss: 1.032237]\n",
      "epoch:2 step:1823[D loss: 0.418158, acc: 67.97%, op_acc: 36.72%] [G loss: 0.978586]\n",
      "epoch:2 step:1824[D loss: 0.448266, acc: 67.97%, op_acc: 26.56%] [G loss: 0.980955]\n",
      "epoch:2 step:1825[D loss: 0.480675, acc: 60.94%, op_acc: 28.12%] [G loss: 0.874218]\n",
      "epoch:2 step:1826[D loss: 0.495475, acc: 54.69%, op_acc: 25.78%] [G loss: 1.114872]\n",
      "epoch:2 step:1827[D loss: 0.472180, acc: 61.72%, op_acc: 32.81%] [G loss: 0.896663]\n",
      "epoch:2 step:1828[D loss: 0.460667, acc: 64.06%, op_acc: 28.91%] [G loss: 1.053809]\n",
      "epoch:2 step:1829[D loss: 0.489704, acc: 63.28%, op_acc: 24.22%] [G loss: 0.937753]\n",
      "epoch:2 step:1830[D loss: 0.443087, acc: 65.62%, op_acc: 25.00%] [G loss: 1.054456]\n",
      "epoch:2 step:1831[D loss: 0.441297, acc: 61.72%, op_acc: 31.25%] [G loss: 0.948619]\n",
      "epoch:2 step:1832[D loss: 0.448154, acc: 67.97%, op_acc: 28.12%] [G loss: 0.876322]\n",
      "epoch:2 step:1833[D loss: 0.454381, acc: 67.97%, op_acc: 25.78%] [G loss: 1.029114]\n",
      "epoch:2 step:1834[D loss: 0.480478, acc: 58.59%, op_acc: 28.12%] [G loss: 1.042166]\n",
      "epoch:2 step:1835[D loss: 0.457193, acc: 58.59%, op_acc: 28.91%] [G loss: 1.081107]\n",
      "epoch:2 step:1836[D loss: 0.485033, acc: 59.38%, op_acc: 28.91%] [G loss: 0.995462]\n",
      "epoch:2 step:1837[D loss: 0.448813, acc: 60.94%, op_acc: 26.56%] [G loss: 0.915645]\n",
      "epoch:2 step:1838[D loss: 0.444246, acc: 61.72%, op_acc: 31.25%] [G loss: 1.021265]\n",
      "epoch:2 step:1839[D loss: 0.494550, acc: 60.94%, op_acc: 23.44%] [G loss: 0.986088]\n",
      "epoch:2 step:1840[D loss: 0.482133, acc: 55.47%, op_acc: 34.38%] [G loss: 0.994965]\n",
      "epoch:2 step:1841[D loss: 0.444824, acc: 64.06%, op_acc: 32.81%] [G loss: 0.919212]\n",
      "epoch:2 step:1842[D loss: 0.465670, acc: 58.59%, op_acc: 29.69%] [G loss: 0.947291]\n",
      "epoch:2 step:1843[D loss: 0.484642, acc: 61.72%, op_acc: 23.44%] [G loss: 0.874215]\n",
      "epoch:2 step:1844[D loss: 0.518628, acc: 46.88%, op_acc: 21.88%] [G loss: 0.921913]\n",
      "epoch:2 step:1845[D loss: 0.457504, acc: 58.59%, op_acc: 28.12%] [G loss: 0.990838]\n",
      "epoch:2 step:1846[D loss: 0.475533, acc: 61.72%, op_acc: 30.47%] [G loss: 0.970890]\n",
      "epoch:2 step:1847[D loss: 0.461298, acc: 62.50%, op_acc: 29.69%] [G loss: 0.866331]\n",
      "epoch:2 step:1848[D loss: 0.515852, acc: 48.44%, op_acc: 27.34%] [G loss: 0.883563]\n",
      "epoch:2 step:1849[D loss: 0.493110, acc: 55.47%, op_acc: 29.69%] [G loss: 1.029005]\n",
      "epoch:2 step:1850[D loss: 0.473342, acc: 60.16%, op_acc: 32.81%] [G loss: 0.982557]\n",
      "##############\n",
      "[0.88305418 0.86489738 0.82377014 0.81814912 0.79211664 0.82501499\n",
      " 0.87239105 0.81519297 0.8207352  0.80873424]\n",
      "##########\n",
      "epoch:2 step:1851[D loss: 0.508157, acc: 51.56%, op_acc: 27.34%] [G loss: 0.948591]\n",
      "epoch:2 step:1852[D loss: 0.458823, acc: 60.94%, op_acc: 26.56%] [G loss: 0.902762]\n",
      "epoch:2 step:1853[D loss: 0.440053, acc: 66.41%, op_acc: 29.69%] [G loss: 1.025725]\n",
      "epoch:2 step:1854[D loss: 0.455920, acc: 64.06%, op_acc: 30.47%] [G loss: 0.954613]\n",
      "epoch:2 step:1855[D loss: 0.451527, acc: 58.59%, op_acc: 34.38%] [G loss: 0.898115]\n",
      "epoch:2 step:1856[D loss: 0.462196, acc: 55.47%, op_acc: 33.59%] [G loss: 0.918923]\n",
      "epoch:2 step:1857[D loss: 0.503774, acc: 54.69%, op_acc: 25.00%] [G loss: 0.936506]\n",
      "epoch:2 step:1858[D loss: 0.481875, acc: 51.56%, op_acc: 34.38%] [G loss: 0.938221]\n",
      "epoch:2 step:1859[D loss: 0.490866, acc: 51.56%, op_acc: 28.91%] [G loss: 0.914707]\n",
      "epoch:2 step:1860[D loss: 0.447423, acc: 70.31%, op_acc: 32.03%] [G loss: 1.007214]\n",
      "epoch:2 step:1861[D loss: 0.428153, acc: 71.09%, op_acc: 30.47%] [G loss: 0.879764]\n",
      "epoch:2 step:1862[D loss: 0.489172, acc: 49.22%, op_acc: 31.25%] [G loss: 0.982499]\n",
      "epoch:2 step:1863[D loss: 0.460681, acc: 61.72%, op_acc: 27.34%] [G loss: 0.985312]\n",
      "epoch:2 step:1864[D loss: 0.461734, acc: 58.59%, op_acc: 32.81%] [G loss: 0.950474]\n",
      "epoch:2 step:1865[D loss: 0.452786, acc: 57.03%, op_acc: 29.69%] [G loss: 0.977645]\n",
      "epoch:2 step:1866[D loss: 0.467089, acc: 57.81%, op_acc: 35.94%] [G loss: 0.947216]\n",
      "epoch:2 step:1867[D loss: 0.502675, acc: 47.66%, op_acc: 26.56%] [G loss: 0.920737]\n",
      "epoch:2 step:1868[D loss: 0.480275, acc: 65.62%, op_acc: 26.56%] [G loss: 1.060500]\n",
      "epoch:2 step:1869[D loss: 0.415207, acc: 71.09%, op_acc: 25.00%] [G loss: 0.972434]\n",
      "epoch:2 step:1870[D loss: 0.457953, acc: 58.59%, op_acc: 29.69%] [G loss: 0.991559]\n",
      "epoch:2 step:1871[D loss: 0.478138, acc: 61.72%, op_acc: 18.75%] [G loss: 0.910675]\n",
      "epoch:2 step:1872[D loss: 0.483103, acc: 52.34%, op_acc: 28.12%] [G loss: 0.914678]\n",
      "epoch:2 step:1873[D loss: 0.442400, acc: 64.84%, op_acc: 30.47%] [G loss: 0.937167]\n",
      "epoch:2 step:1874[D loss: 0.469454, acc: 63.28%, op_acc: 21.09%] [G loss: 0.903830]\n",
      "epoch:2 step:1875[D loss: 0.476653, acc: 61.72%, op_acc: 31.25%] [G loss: 1.035533]\n",
      "epoch:2 step:1876[D loss: 0.484410, acc: 54.69%, op_acc: 32.03%] [G loss: 0.963318]\n",
      "epoch:2 step:1877[D loss: 0.490652, acc: 57.81%, op_acc: 23.44%] [G loss: 0.842284]\n",
      "epoch:2 step:1878[D loss: 0.465326, acc: 59.38%, op_acc: 29.69%] [G loss: 0.948398]\n",
      "epoch:2 step:1879[D loss: 0.457860, acc: 61.72%, op_acc: 28.12%] [G loss: 0.822820]\n",
      "epoch:2 step:1880[D loss: 0.471928, acc: 61.72%, op_acc: 25.78%] [G loss: 0.933166]\n",
      "epoch:2 step:1881[D loss: 0.440593, acc: 62.50%, op_acc: 33.59%] [G loss: 1.039477]\n",
      "epoch:2 step:1882[D loss: 0.499862, acc: 53.12%, op_acc: 25.78%] [G loss: 0.968101]\n",
      "epoch:2 step:1883[D loss: 0.484148, acc: 58.59%, op_acc: 30.47%] [G loss: 0.929595]\n",
      "epoch:2 step:1884[D loss: 0.517006, acc: 48.44%, op_acc: 30.47%] [G loss: 0.951019]\n",
      "epoch:2 step:1885[D loss: 0.441736, acc: 68.75%, op_acc: 26.56%] [G loss: 0.993413]\n",
      "epoch:2 step:1886[D loss: 0.439174, acc: 67.19%, op_acc: 32.81%] [G loss: 0.939401]\n",
      "epoch:2 step:1887[D loss: 0.449425, acc: 57.03%, op_acc: 31.25%] [G loss: 0.858090]\n",
      "epoch:2 step:1888[D loss: 0.461027, acc: 64.84%, op_acc: 29.69%] [G loss: 0.862807]\n",
      "epoch:2 step:1889[D loss: 0.435775, acc: 62.50%, op_acc: 29.69%] [G loss: 1.006051]\n",
      "epoch:2 step:1890[D loss: 0.464484, acc: 60.94%, op_acc: 25.78%] [G loss: 0.936620]\n",
      "epoch:2 step:1891[D loss: 0.443737, acc: 64.06%, op_acc: 32.03%] [G loss: 0.994670]\n",
      "epoch:2 step:1892[D loss: 0.484158, acc: 53.12%, op_acc: 33.59%] [G loss: 0.919444]\n",
      "epoch:2 step:1893[D loss: 0.460844, acc: 60.94%, op_acc: 34.38%] [G loss: 0.955211]\n",
      "epoch:2 step:1894[D loss: 0.452841, acc: 61.72%, op_acc: 34.38%] [G loss: 1.004921]\n",
      "epoch:2 step:1895[D loss: 0.437433, acc: 67.97%, op_acc: 33.59%] [G loss: 1.027469]\n",
      "epoch:2 step:1896[D loss: 0.462351, acc: 61.72%, op_acc: 32.81%] [G loss: 1.091149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1897[D loss: 0.510229, acc: 55.47%, op_acc: 27.34%] [G loss: 0.846731]\n",
      "epoch:2 step:1898[D loss: 0.483496, acc: 60.16%, op_acc: 25.78%] [G loss: 0.910620]\n",
      "epoch:2 step:1899[D loss: 0.457566, acc: 64.84%, op_acc: 28.91%] [G loss: 0.975482]\n",
      "epoch:2 step:1900[D loss: 0.444828, acc: 58.59%, op_acc: 34.38%] [G loss: 1.015566]\n",
      "##############\n",
      "[0.87084129 0.85112843 0.81072326 0.81907069 0.81335853 0.7961339\n",
      " 0.87835632 0.82182866 0.79925136 0.83159116]\n",
      "##########\n",
      "epoch:2 step:1901[D loss: 0.479521, acc: 53.91%, op_acc: 29.69%] [G loss: 0.976056]\n",
      "epoch:2 step:1902[D loss: 0.439884, acc: 61.72%, op_acc: 27.34%] [G loss: 0.978119]\n",
      "epoch:2 step:1903[D loss: 0.490462, acc: 54.69%, op_acc: 32.03%] [G loss: 1.001329]\n",
      "epoch:2 step:1904[D loss: 0.470154, acc: 60.94%, op_acc: 25.78%] [G loss: 1.009243]\n",
      "epoch:2 step:1905[D loss: 0.485194, acc: 56.25%, op_acc: 23.44%] [G loss: 0.947030]\n",
      "epoch:2 step:1906[D loss: 0.454798, acc: 60.16%, op_acc: 27.34%] [G loss: 0.920861]\n",
      "epoch:2 step:1907[D loss: 0.480626, acc: 58.59%, op_acc: 24.22%] [G loss: 0.887279]\n",
      "epoch:2 step:1908[D loss: 0.448329, acc: 57.81%, op_acc: 32.03%] [G loss: 0.942898]\n",
      "epoch:2 step:1909[D loss: 0.488439, acc: 53.12%, op_acc: 28.12%] [G loss: 0.855006]\n",
      "epoch:2 step:1910[D loss: 0.469647, acc: 59.38%, op_acc: 26.56%] [G loss: 0.971369]\n",
      "epoch:2 step:1911[D loss: 0.473307, acc: 54.69%, op_acc: 28.12%] [G loss: 1.079436]\n",
      "epoch:2 step:1912[D loss: 0.474307, acc: 59.38%, op_acc: 27.34%] [G loss: 0.951327]\n",
      "epoch:2 step:1913[D loss: 0.501533, acc: 50.00%, op_acc: 28.91%] [G loss: 1.018462]\n",
      "epoch:2 step:1914[D loss: 0.479557, acc: 56.25%, op_acc: 30.47%] [G loss: 0.940442]\n",
      "epoch:2 step:1915[D loss: 0.445326, acc: 68.75%, op_acc: 29.69%] [G loss: 1.100567]\n",
      "epoch:2 step:1916[D loss: 0.486435, acc: 57.03%, op_acc: 26.56%] [G loss: 0.943047]\n",
      "epoch:2 step:1917[D loss: 0.498732, acc: 47.66%, op_acc: 30.47%] [G loss: 0.910803]\n",
      "epoch:2 step:1918[D loss: 0.494529, acc: 51.56%, op_acc: 27.34%] [G loss: 0.816779]\n",
      "epoch:2 step:1919[D loss: 0.472179, acc: 60.16%, op_acc: 21.88%] [G loss: 0.929378]\n",
      "epoch:2 step:1920[D loss: 0.490194, acc: 59.38%, op_acc: 26.56%] [G loss: 0.963763]\n",
      "epoch:2 step:1921[D loss: 0.463038, acc: 57.03%, op_acc: 33.59%] [G loss: 0.953717]\n",
      "epoch:2 step:1922[D loss: 0.478116, acc: 57.81%, op_acc: 25.78%] [G loss: 0.994184]\n",
      "epoch:2 step:1923[D loss: 0.471490, acc: 57.03%, op_acc: 29.69%] [G loss: 0.932252]\n",
      "epoch:2 step:1924[D loss: 0.433335, acc: 64.84%, op_acc: 32.81%] [G loss: 0.947125]\n",
      "epoch:2 step:1925[D loss: 0.476312, acc: 61.72%, op_acc: 26.56%] [G loss: 0.990867]\n",
      "epoch:2 step:1926[D loss: 0.482122, acc: 56.25%, op_acc: 26.56%] [G loss: 0.992365]\n",
      "epoch:2 step:1927[D loss: 0.463814, acc: 53.12%, op_acc: 37.50%] [G loss: 1.005501]\n",
      "epoch:2 step:1928[D loss: 0.443739, acc: 62.50%, op_acc: 30.47%] [G loss: 1.027461]\n",
      "epoch:2 step:1929[D loss: 0.450439, acc: 65.62%, op_acc: 25.00%] [G loss: 0.924866]\n",
      "epoch:2 step:1930[D loss: 0.456588, acc: 65.62%, op_acc: 30.47%] [G loss: 1.095696]\n",
      "epoch:2 step:1931[D loss: 0.426578, acc: 64.84%, op_acc: 32.03%] [G loss: 0.984029]\n",
      "epoch:2 step:1932[D loss: 0.514149, acc: 50.00%, op_acc: 25.78%] [G loss: 0.883983]\n",
      "epoch:2 step:1933[D loss: 0.431406, acc: 63.28%, op_acc: 41.41%] [G loss: 0.999794]\n",
      "epoch:2 step:1934[D loss: 0.501331, acc: 52.34%, op_acc: 28.12%] [G loss: 0.918706]\n",
      "epoch:2 step:1935[D loss: 0.480630, acc: 52.34%, op_acc: 25.78%] [G loss: 0.850159]\n",
      "epoch:2 step:1936[D loss: 0.478145, acc: 60.94%, op_acc: 31.25%] [G loss: 0.898260]\n",
      "epoch:2 step:1937[D loss: 0.462040, acc: 53.91%, op_acc: 28.91%] [G loss: 0.905129]\n",
      "epoch:2 step:1938[D loss: 0.463899, acc: 59.38%, op_acc: 32.03%] [G loss: 0.944291]\n",
      "epoch:2 step:1939[D loss: 0.498788, acc: 53.12%, op_acc: 27.34%] [G loss: 0.902332]\n",
      "epoch:2 step:1940[D loss: 0.468557, acc: 57.03%, op_acc: 28.91%] [G loss: 0.984413]\n",
      "epoch:2 step:1941[D loss: 0.473600, acc: 55.47%, op_acc: 27.34%] [G loss: 0.938239]\n",
      "epoch:2 step:1942[D loss: 0.488068, acc: 58.59%, op_acc: 32.81%] [G loss: 0.990035]\n",
      "epoch:2 step:1943[D loss: 0.465150, acc: 57.81%, op_acc: 33.59%] [G loss: 0.951830]\n",
      "epoch:2 step:1944[D loss: 0.450701, acc: 61.72%, op_acc: 33.59%] [G loss: 0.890976]\n",
      "epoch:2 step:1945[D loss: 0.462522, acc: 60.94%, op_acc: 28.12%] [G loss: 0.944495]\n",
      "epoch:2 step:1946[D loss: 0.448378, acc: 65.62%, op_acc: 34.38%] [G loss: 0.924906]\n",
      "epoch:2 step:1947[D loss: 0.429962, acc: 64.84%, op_acc: 32.03%] [G loss: 0.895724]\n",
      "epoch:2 step:1948[D loss: 0.433122, acc: 60.94%, op_acc: 29.69%] [G loss: 0.970116]\n",
      "epoch:2 step:1949[D loss: 0.470953, acc: 64.84%, op_acc: 28.12%] [G loss: 0.933329]\n",
      "epoch:2 step:1950[D loss: 0.463113, acc: 63.28%, op_acc: 28.12%] [G loss: 0.972952]\n",
      "##############\n",
      "[0.86875628 0.86703851 0.82651809 0.82483806 0.76883885 0.80820615\n",
      " 0.87651896 0.83287079 0.78544122 0.82429638]\n",
      "##########\n",
      "epoch:2 step:1951[D loss: 0.488897, acc: 54.69%, op_acc: 30.47%] [G loss: 0.928577]\n",
      "epoch:2 step:1952[D loss: 0.455282, acc: 57.81%, op_acc: 37.50%] [G loss: 1.002450]\n",
      "epoch:2 step:1953[D loss: 0.457924, acc: 60.16%, op_acc: 28.91%] [G loss: 0.928075]\n",
      "epoch:2 step:1954[D loss: 0.405211, acc: 66.41%, op_acc: 32.03%] [G loss: 0.935743]\n",
      "epoch:2 step:1955[D loss: 0.424881, acc: 69.53%, op_acc: 36.72%] [G loss: 0.962024]\n",
      "epoch:2 step:1956[D loss: 0.469104, acc: 54.69%, op_acc: 23.44%] [G loss: 0.980428]\n",
      "epoch:2 step:1957[D loss: 0.493993, acc: 56.25%, op_acc: 28.91%] [G loss: 0.956752]\n",
      "epoch:2 step:1958[D loss: 0.439036, acc: 64.84%, op_acc: 34.38%] [G loss: 0.983304]\n",
      "epoch:2 step:1959[D loss: 0.471574, acc: 53.91%, op_acc: 28.12%] [G loss: 0.961297]\n",
      "epoch:2 step:1960[D loss: 0.507618, acc: 57.81%, op_acc: 22.66%] [G loss: 0.953052]\n",
      "epoch:2 step:1961[D loss: 0.481260, acc: 56.25%, op_acc: 31.25%] [G loss: 0.873203]\n",
      "epoch:2 step:1962[D loss: 0.468915, acc: 57.03%, op_acc: 28.12%] [G loss: 0.998918]\n",
      "epoch:2 step:1963[D loss: 0.456123, acc: 58.59%, op_acc: 28.91%] [G loss: 1.007677]\n",
      "epoch:2 step:1964[D loss: 0.499142, acc: 52.34%, op_acc: 28.91%] [G loss: 0.873155]\n",
      "epoch:2 step:1965[D loss: 0.471281, acc: 53.12%, op_acc: 33.59%] [G loss: 0.973567]\n",
      "epoch:2 step:1966[D loss: 0.431589, acc: 62.50%, op_acc: 28.91%] [G loss: 1.010809]\n",
      "epoch:2 step:1967[D loss: 0.483004, acc: 55.47%, op_acc: 27.34%] [G loss: 0.979576]\n",
      "epoch:2 step:1968[D loss: 0.470645, acc: 54.69%, op_acc: 37.50%] [G loss: 0.896446]\n",
      "epoch:2 step:1969[D loss: 0.440620, acc: 63.28%, op_acc: 31.25%] [G loss: 1.007255]\n",
      "epoch:2 step:1970[D loss: 0.455676, acc: 60.94%, op_acc: 30.47%] [G loss: 0.869700]\n",
      "epoch:2 step:1971[D loss: 0.482826, acc: 56.25%, op_acc: 30.47%] [G loss: 0.935502]\n",
      "epoch:2 step:1972[D loss: 0.468717, acc: 55.47%, op_acc: 30.47%] [G loss: 0.872271]\n",
      "epoch:2 step:1973[D loss: 0.491768, acc: 56.25%, op_acc: 25.78%] [G loss: 0.968536]\n",
      "epoch:2 step:1974[D loss: 0.481464, acc: 51.56%, op_acc: 28.12%] [G loss: 0.949010]\n",
      "epoch:2 step:1975[D loss: 0.430302, acc: 67.97%, op_acc: 30.47%] [G loss: 0.971025]\n",
      "epoch:2 step:1976[D loss: 0.452885, acc: 57.81%, op_acc: 32.03%] [G loss: 0.857434]\n",
      "epoch:2 step:1977[D loss: 0.468612, acc: 60.16%, op_acc: 32.81%] [G loss: 0.891894]\n",
      "epoch:2 step:1978[D loss: 0.475265, acc: 60.16%, op_acc: 29.69%] [G loss: 0.984327]\n",
      "epoch:2 step:1979[D loss: 0.489233, acc: 56.25%, op_acc: 28.12%] [G loss: 0.873121]\n",
      "epoch:2 step:1980[D loss: 0.456871, acc: 60.94%, op_acc: 30.47%] [G loss: 0.895068]\n",
      "epoch:2 step:1981[D loss: 0.460592, acc: 64.06%, op_acc: 29.69%] [G loss: 1.004853]\n",
      "epoch:2 step:1982[D loss: 0.454286, acc: 64.06%, op_acc: 30.47%] [G loss: 0.952137]\n",
      "epoch:2 step:1983[D loss: 0.447899, acc: 62.50%, op_acc: 29.69%] [G loss: 0.961456]\n",
      "epoch:2 step:1984[D loss: 0.484611, acc: 57.03%, op_acc: 31.25%] [G loss: 0.940504]\n",
      "epoch:2 step:1985[D loss: 0.465436, acc: 64.06%, op_acc: 35.16%] [G loss: 0.945825]\n",
      "epoch:2 step:1986[D loss: 0.463024, acc: 63.28%, op_acc: 29.69%] [G loss: 1.147754]\n",
      "epoch:2 step:1987[D loss: 0.440406, acc: 69.53%, op_acc: 26.56%] [G loss: 0.982581]\n",
      "epoch:2 step:1988[D loss: 0.486823, acc: 55.47%, op_acc: 25.00%] [G loss: 0.882918]\n",
      "epoch:2 step:1989[D loss: 0.445579, acc: 66.41%, op_acc: 28.12%] [G loss: 0.961663]\n",
      "epoch:2 step:1990[D loss: 0.469761, acc: 58.59%, op_acc: 32.81%] [G loss: 0.942885]\n",
      "epoch:2 step:1991[D loss: 0.439944, acc: 66.41%, op_acc: 25.78%] [G loss: 1.016935]\n",
      "epoch:2 step:1992[D loss: 0.446678, acc: 63.28%, op_acc: 32.03%] [G loss: 0.909390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1993[D loss: 0.450873, acc: 59.38%, op_acc: 31.25%] [G loss: 0.886475]\n",
      "epoch:2 step:1994[D loss: 0.428134, acc: 67.97%, op_acc: 32.81%] [G loss: 0.921702]\n",
      "epoch:2 step:1995[D loss: 0.453077, acc: 70.31%, op_acc: 22.66%] [G loss: 0.924274]\n",
      "epoch:2 step:1996[D loss: 0.434796, acc: 64.84%, op_acc: 35.16%] [G loss: 0.988535]\n",
      "epoch:2 step:1997[D loss: 0.479375, acc: 55.47%, op_acc: 33.59%] [G loss: 0.868674]\n",
      "epoch:2 step:1998[D loss: 0.495051, acc: 55.47%, op_acc: 29.69%] [G loss: 0.937816]\n",
      "epoch:2 step:1999[D loss: 0.474906, acc: 58.59%, op_acc: 24.22%] [G loss: 0.941519]\n",
      "epoch:2 step:2000[D loss: 0.459080, acc: 67.19%, op_acc: 30.47%] [G loss: 1.033195]\n",
      "##############\n",
      "[0.86272689 0.85742958 0.81901948 0.81094497 0.7972713  0.82029766\n",
      " 0.88956864 0.84922959 0.79228794 0.8324552 ]\n",
      "##########\n",
      "epoch:2 step:2001[D loss: 0.469680, acc: 59.38%, op_acc: 27.34%] [G loss: 0.984812]\n",
      "epoch:2 step:2002[D loss: 0.475475, acc: 53.12%, op_acc: 29.69%] [G loss: 1.023899]\n",
      "epoch:2 step:2003[D loss: 0.476581, acc: 56.25%, op_acc: 24.22%] [G loss: 1.071852]\n",
      "epoch:2 step:2004[D loss: 0.444452, acc: 65.62%, op_acc: 29.69%] [G loss: 1.029448]\n",
      "epoch:2 step:2005[D loss: 0.501091, acc: 54.69%, op_acc: 22.66%] [G loss: 1.030302]\n",
      "epoch:2 step:2006[D loss: 0.461588, acc: 60.16%, op_acc: 25.00%] [G loss: 1.030407]\n",
      "epoch:2 step:2007[D loss: 0.463643, acc: 60.94%, op_acc: 28.91%] [G loss: 0.885581]\n",
      "epoch:2 step:2008[D loss: 0.485725, acc: 59.38%, op_acc: 27.34%] [G loss: 0.950993]\n",
      "epoch:2 step:2009[D loss: 0.440099, acc: 68.75%, op_acc: 25.00%] [G loss: 0.924174]\n",
      "epoch:2 step:2010[D loss: 0.467247, acc: 58.59%, op_acc: 28.12%] [G loss: 0.943442]\n",
      "epoch:2 step:2011[D loss: 0.438011, acc: 61.72%, op_acc: 34.38%] [G loss: 1.067175]\n",
      "epoch:2 step:2012[D loss: 0.470033, acc: 64.84%, op_acc: 21.88%] [G loss: 1.006395]\n",
      "epoch:2 step:2013[D loss: 0.409322, acc: 62.50%, op_acc: 35.94%] [G loss: 1.047743]\n",
      "epoch:2 step:2014[D loss: 0.436477, acc: 66.41%, op_acc: 31.25%] [G loss: 1.035078]\n",
      "epoch:2 step:2015[D loss: 0.441480, acc: 64.06%, op_acc: 35.16%] [G loss: 0.959531]\n",
      "epoch:2 step:2016[D loss: 0.445991, acc: 65.62%, op_acc: 27.34%] [G loss: 0.960337]\n",
      "epoch:2 step:2017[D loss: 0.444839, acc: 61.72%, op_acc: 32.81%] [G loss: 0.938987]\n",
      "epoch:2 step:2018[D loss: 0.483141, acc: 56.25%, op_acc: 28.91%] [G loss: 0.931177]\n",
      "epoch:2 step:2019[D loss: 0.473041, acc: 58.59%, op_acc: 27.34%] [G loss: 0.951921]\n",
      "epoch:2 step:2020[D loss: 0.449021, acc: 64.06%, op_acc: 35.94%] [G loss: 0.995023]\n",
      "epoch:2 step:2021[D loss: 0.428588, acc: 62.50%, op_acc: 31.25%] [G loss: 0.958558]\n",
      "epoch:2 step:2022[D loss: 0.445263, acc: 60.94%, op_acc: 27.34%] [G loss: 0.966543]\n",
      "epoch:2 step:2023[D loss: 0.456830, acc: 60.16%, op_acc: 25.78%] [G loss: 0.933960]\n",
      "epoch:2 step:2024[D loss: 0.476680, acc: 61.72%, op_acc: 24.22%] [G loss: 0.919971]\n",
      "epoch:2 step:2025[D loss: 0.440124, acc: 63.28%, op_acc: 20.31%] [G loss: 0.898555]\n",
      "epoch:2 step:2026[D loss: 0.481545, acc: 58.59%, op_acc: 27.34%] [G loss: 0.896795]\n",
      "epoch:2 step:2027[D loss: 0.509491, acc: 49.22%, op_acc: 35.94%] [G loss: 1.010521]\n",
      "epoch:2 step:2028[D loss: 0.471048, acc: 60.16%, op_acc: 32.81%] [G loss: 0.998657]\n",
      "epoch:2 step:2029[D loss: 0.469438, acc: 58.59%, op_acc: 28.12%] [G loss: 0.925418]\n",
      "epoch:2 step:2030[D loss: 0.445414, acc: 60.94%, op_acc: 30.47%] [G loss: 0.941446]\n",
      "epoch:2 step:2031[D loss: 0.440045, acc: 59.38%, op_acc: 32.03%] [G loss: 0.989526]\n",
      "epoch:2 step:2032[D loss: 0.457182, acc: 56.25%, op_acc: 35.16%] [G loss: 0.888853]\n",
      "epoch:2 step:2033[D loss: 0.469951, acc: 57.81%, op_acc: 30.47%] [G loss: 0.874061]\n",
      "epoch:2 step:2034[D loss: 0.469748, acc: 56.25%, op_acc: 24.22%] [G loss: 1.044523]\n",
      "epoch:2 step:2035[D loss: 0.461000, acc: 50.00%, op_acc: 35.16%] [G loss: 0.872532]\n",
      "epoch:2 step:2036[D loss: 0.435603, acc: 71.09%, op_acc: 25.78%] [G loss: 1.066198]\n",
      "epoch:2 step:2037[D loss: 0.413224, acc: 65.62%, op_acc: 31.25%] [G loss: 1.025082]\n",
      "epoch:2 step:2038[D loss: 0.506170, acc: 53.91%, op_acc: 22.66%] [G loss: 0.987185]\n",
      "epoch:2 step:2039[D loss: 0.440183, acc: 63.28%, op_acc: 30.47%] [G loss: 1.074250]\n",
      "epoch:2 step:2040[D loss: 0.464646, acc: 66.41%, op_acc: 30.47%] [G loss: 1.097537]\n",
      "epoch:2 step:2041[D loss: 0.478340, acc: 58.59%, op_acc: 27.34%] [G loss: 0.905316]\n",
      "epoch:2 step:2042[D loss: 0.479858, acc: 56.25%, op_acc: 26.56%] [G loss: 0.970362]\n",
      "epoch:2 step:2043[D loss: 0.452864, acc: 67.19%, op_acc: 25.00%] [G loss: 0.979105]\n",
      "epoch:2 step:2044[D loss: 0.460879, acc: 65.62%, op_acc: 32.81%] [G loss: 0.908333]\n",
      "epoch:2 step:2045[D loss: 0.472187, acc: 57.81%, op_acc: 27.34%] [G loss: 1.037177]\n",
      "epoch:2 step:2046[D loss: 0.441091, acc: 61.72%, op_acc: 35.94%] [G loss: 0.966015]\n",
      "epoch:2 step:2047[D loss: 0.432897, acc: 67.97%, op_acc: 29.69%] [G loss: 1.009389]\n",
      "epoch:2 step:2048[D loss: 0.433329, acc: 58.59%, op_acc: 32.03%] [G loss: 0.929804]\n",
      "epoch:2 step:2049[D loss: 0.453718, acc: 67.19%, op_acc: 30.47%] [G loss: 0.973600]\n",
      "epoch:2 step:2050[D loss: 0.456914, acc: 64.06%, op_acc: 31.25%] [G loss: 0.944222]\n",
      "##############\n",
      "[0.85524774 0.85675836 0.80909067 0.80877677 0.80012247 0.81829127\n",
      " 0.8993061  0.84486051 0.80969245 0.8470485 ]\n",
      "##########\n",
      "epoch:2 step:2051[D loss: 0.470870, acc: 53.91%, op_acc: 31.25%] [G loss: 0.876482]\n",
      "epoch:2 step:2052[D loss: 0.466849, acc: 59.38%, op_acc: 32.81%] [G loss: 0.913234]\n",
      "epoch:2 step:2053[D loss: 0.495155, acc: 58.59%, op_acc: 29.69%] [G loss: 0.926308]\n",
      "epoch:2 step:2054[D loss: 0.467276, acc: 60.94%, op_acc: 27.34%] [G loss: 0.971702]\n",
      "epoch:2 step:2055[D loss: 0.457670, acc: 60.94%, op_acc: 27.34%] [G loss: 0.867387]\n",
      "epoch:2 step:2056[D loss: 0.485570, acc: 55.47%, op_acc: 33.59%] [G loss: 1.043912]\n",
      "epoch:2 step:2057[D loss: 0.459292, acc: 57.03%, op_acc: 32.03%] [G loss: 1.093627]\n",
      "epoch:2 step:2058[D loss: 0.501577, acc: 54.69%, op_acc: 28.91%] [G loss: 0.992242]\n",
      "epoch:2 step:2059[D loss: 0.461076, acc: 63.28%, op_acc: 29.69%] [G loss: 0.964964]\n",
      "epoch:2 step:2060[D loss: 0.507351, acc: 53.91%, op_acc: 24.22%] [G loss: 0.917020]\n",
      "epoch:2 step:2061[D loss: 0.486860, acc: 57.81%, op_acc: 30.47%] [G loss: 1.026602]\n",
      "epoch:2 step:2062[D loss: 0.460979, acc: 57.03%, op_acc: 32.03%] [G loss: 0.981179]\n",
      "epoch:2 step:2063[D loss: 0.463799, acc: 58.59%, op_acc: 29.69%] [G loss: 1.153792]\n",
      "epoch:2 step:2064[D loss: 0.496307, acc: 57.81%, op_acc: 26.56%] [G loss: 0.883675]\n",
      "epoch:2 step:2065[D loss: 0.456663, acc: 58.59%, op_acc: 29.69%] [G loss: 0.988709]\n",
      "epoch:2 step:2066[D loss: 0.491273, acc: 49.22%, op_acc: 28.91%] [G loss: 0.919549]\n",
      "epoch:2 step:2067[D loss: 0.490524, acc: 54.69%, op_acc: 27.34%] [G loss: 0.973997]\n",
      "epoch:2 step:2068[D loss: 0.484392, acc: 60.16%, op_acc: 32.81%] [G loss: 0.885728]\n",
      "epoch:2 step:2069[D loss: 0.439050, acc: 61.72%, op_acc: 33.59%] [G loss: 0.915875]\n",
      "epoch:2 step:2070[D loss: 0.455447, acc: 57.81%, op_acc: 27.34%] [G loss: 0.987743]\n",
      "epoch:2 step:2071[D loss: 0.486182, acc: 60.16%, op_acc: 25.00%] [G loss: 1.024727]\n",
      "epoch:2 step:2072[D loss: 0.429499, acc: 67.19%, op_acc: 30.47%] [G loss: 0.998507]\n",
      "epoch:2 step:2073[D loss: 0.417190, acc: 74.22%, op_acc: 31.25%] [G loss: 1.118771]\n",
      "epoch:2 step:2074[D loss: 0.438076, acc: 61.72%, op_acc: 30.47%] [G loss: 1.005516]\n",
      "epoch:2 step:2075[D loss: 0.488526, acc: 60.16%, op_acc: 25.00%] [G loss: 0.982887]\n",
      "epoch:2 step:2076[D loss: 0.470723, acc: 60.94%, op_acc: 31.25%] [G loss: 0.996139]\n",
      "epoch:2 step:2077[D loss: 0.453968, acc: 66.41%, op_acc: 24.22%] [G loss: 0.966379]\n",
      "epoch:2 step:2078[D loss: 0.432070, acc: 68.75%, op_acc: 28.91%] [G loss: 1.037048]\n",
      "epoch:2 step:2079[D loss: 0.484145, acc: 62.50%, op_acc: 22.66%] [G loss: 0.940788]\n",
      "epoch:2 step:2080[D loss: 0.451449, acc: 62.50%, op_acc: 24.22%] [G loss: 0.871196]\n",
      "epoch:2 step:2081[D loss: 0.477989, acc: 59.38%, op_acc: 25.78%] [G loss: 0.934758]\n",
      "epoch:2 step:2082[D loss: 0.481111, acc: 57.81%, op_acc: 28.12%] [G loss: 0.894846]\n",
      "epoch:2 step:2083[D loss: 0.497815, acc: 57.03%, op_acc: 25.78%] [G loss: 1.018461]\n",
      "epoch:2 step:2084[D loss: 0.461255, acc: 59.38%, op_acc: 25.78%] [G loss: 0.927153]\n",
      "epoch:2 step:2085[D loss: 0.450393, acc: 62.50%, op_acc: 35.94%] [G loss: 0.967499]\n",
      "epoch:2 step:2086[D loss: 0.458061, acc: 66.41%, op_acc: 23.44%] [G loss: 1.011869]\n",
      "epoch:2 step:2087[D loss: 0.494016, acc: 57.03%, op_acc: 29.69%] [G loss: 0.882576]\n",
      "epoch:2 step:2088[D loss: 0.517397, acc: 49.22%, op_acc: 23.44%] [G loss: 1.002945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2089[D loss: 0.482171, acc: 58.59%, op_acc: 31.25%] [G loss: 1.065177]\n",
      "epoch:2 step:2090[D loss: 0.470079, acc: 58.59%, op_acc: 31.25%] [G loss: 0.972851]\n",
      "epoch:2 step:2091[D loss: 0.457177, acc: 64.06%, op_acc: 27.34%] [G loss: 0.941746]\n",
      "epoch:2 step:2092[D loss: 0.452115, acc: 64.06%, op_acc: 24.22%] [G loss: 0.953878]\n",
      "epoch:2 step:2093[D loss: 0.468327, acc: 61.72%, op_acc: 32.03%] [G loss: 0.983729]\n",
      "epoch:2 step:2094[D loss: 0.454744, acc: 65.62%, op_acc: 28.12%] [G loss: 0.996655]\n",
      "epoch:2 step:2095[D loss: 0.468563, acc: 63.28%, op_acc: 26.56%] [G loss: 0.914665]\n",
      "epoch:2 step:2096[D loss: 0.448867, acc: 59.38%, op_acc: 31.25%] [G loss: 0.981368]\n",
      "epoch:2 step:2097[D loss: 0.495241, acc: 54.69%, op_acc: 25.00%] [G loss: 0.966053]\n",
      "epoch:2 step:2098[D loss: 0.461334, acc: 55.47%, op_acc: 31.25%] [G loss: 0.927270]\n",
      "epoch:2 step:2099[D loss: 0.476609, acc: 64.06%, op_acc: 26.56%] [G loss: 0.919391]\n",
      "epoch:2 step:2100[D loss: 0.490875, acc: 53.12%, op_acc: 33.59%] [G loss: 0.951667]\n",
      "##############\n",
      "[0.85010674 0.87001696 0.79399816 0.7939275  0.776846   0.8183016\n",
      " 0.88500118 0.82686666 0.83160709 0.82529904]\n",
      "##########\n",
      "epoch:2 step:2101[D loss: 0.483246, acc: 60.94%, op_acc: 25.78%] [G loss: 1.042387]\n",
      "epoch:2 step:2102[D loss: 0.479266, acc: 60.94%, op_acc: 29.69%] [G loss: 0.968822]\n",
      "epoch:2 step:2103[D loss: 0.422683, acc: 65.62%, op_acc: 35.16%] [G loss: 0.944902]\n",
      "epoch:2 step:2104[D loss: 0.469098, acc: 57.03%, op_acc: 28.12%] [G loss: 0.898016]\n",
      "epoch:2 step:2105[D loss: 0.427622, acc: 67.97%, op_acc: 32.03%] [G loss: 0.969609]\n",
      "epoch:2 step:2106[D loss: 0.490045, acc: 54.69%, op_acc: 26.56%] [G loss: 0.958280]\n",
      "epoch:2 step:2107[D loss: 0.441941, acc: 64.06%, op_acc: 37.50%] [G loss: 1.008666]\n",
      "epoch:2 step:2108[D loss: 0.449955, acc: 53.91%, op_acc: 27.34%] [G loss: 0.938884]\n",
      "epoch:2 step:2109[D loss: 0.507066, acc: 56.25%, op_acc: 23.44%] [G loss: 0.869682]\n",
      "epoch:2 step:2110[D loss: 0.496690, acc: 55.47%, op_acc: 27.34%] [G loss: 0.928550]\n",
      "epoch:2 step:2111[D loss: 0.458071, acc: 59.38%, op_acc: 28.91%] [G loss: 0.971622]\n",
      "epoch:2 step:2112[D loss: 0.463505, acc: 60.16%, op_acc: 31.25%] [G loss: 0.950681]\n",
      "epoch:2 step:2113[D loss: 0.471097, acc: 62.50%, op_acc: 24.22%] [G loss: 0.990220]\n",
      "epoch:2 step:2114[D loss: 0.492860, acc: 51.56%, op_acc: 26.56%] [G loss: 0.966770]\n",
      "epoch:2 step:2115[D loss: 0.429624, acc: 62.50%, op_acc: 34.38%] [G loss: 0.977642]\n",
      "epoch:2 step:2116[D loss: 0.450744, acc: 64.84%, op_acc: 28.91%] [G loss: 0.893198]\n",
      "epoch:2 step:2117[D loss: 0.471806, acc: 57.03%, op_acc: 28.91%] [G loss: 0.927009]\n",
      "epoch:2 step:2118[D loss: 0.459420, acc: 61.72%, op_acc: 30.47%] [G loss: 0.935932]\n",
      "epoch:2 step:2119[D loss: 0.458263, acc: 61.72%, op_acc: 26.56%] [G loss: 0.983732]\n",
      "epoch:2 step:2120[D loss: 0.464289, acc: 58.59%, op_acc: 28.91%] [G loss: 1.022037]\n",
      "epoch:2 step:2121[D loss: 0.428650, acc: 67.19%, op_acc: 35.16%] [G loss: 1.014003]\n",
      "epoch:2 step:2122[D loss: 0.486925, acc: 58.59%, op_acc: 25.00%] [G loss: 0.869602]\n",
      "epoch:2 step:2123[D loss: 0.492108, acc: 59.38%, op_acc: 29.69%] [G loss: 0.876738]\n",
      "epoch:2 step:2124[D loss: 0.448525, acc: 60.94%, op_acc: 32.81%] [G loss: 0.888983]\n",
      "epoch:2 step:2125[D loss: 0.454616, acc: 62.50%, op_acc: 28.91%] [G loss: 0.971717]\n",
      "epoch:2 step:2126[D loss: 0.482094, acc: 52.34%, op_acc: 27.34%] [G loss: 0.920824]\n",
      "epoch:2 step:2127[D loss: 0.471059, acc: 59.38%, op_acc: 35.16%] [G loss: 0.968953]\n",
      "epoch:2 step:2128[D loss: 0.474354, acc: 60.16%, op_acc: 28.12%] [G loss: 1.000506]\n",
      "epoch:2 step:2129[D loss: 0.456326, acc: 62.50%, op_acc: 30.47%] [G loss: 1.011547]\n",
      "epoch:2 step:2130[D loss: 0.464127, acc: 60.94%, op_acc: 29.69%] [G loss: 0.974150]\n",
      "epoch:2 step:2131[D loss: 0.447121, acc: 63.28%, op_acc: 27.34%] [G loss: 0.984234]\n",
      "epoch:2 step:2132[D loss: 0.429955, acc: 66.41%, op_acc: 32.03%] [G loss: 1.000157]\n",
      "epoch:2 step:2133[D loss: 0.476120, acc: 54.69%, op_acc: 30.47%] [G loss: 1.070337]\n",
      "epoch:2 step:2134[D loss: 0.432039, acc: 63.28%, op_acc: 37.50%] [G loss: 0.972922]\n",
      "epoch:2 step:2135[D loss: 0.453601, acc: 59.38%, op_acc: 34.38%] [G loss: 1.017227]\n",
      "epoch:2 step:2136[D loss: 0.464129, acc: 60.94%, op_acc: 25.00%] [G loss: 0.919846]\n",
      "epoch:2 step:2137[D loss: 0.495034, acc: 53.91%, op_acc: 26.56%] [G loss: 0.962069]\n",
      "epoch:2 step:2138[D loss: 0.441146, acc: 66.41%, op_acc: 32.03%] [G loss: 0.991507]\n",
      "epoch:2 step:2139[D loss: 0.450299, acc: 68.75%, op_acc: 29.69%] [G loss: 1.075109]\n",
      "epoch:2 step:2140[D loss: 0.475382, acc: 63.28%, op_acc: 21.09%] [G loss: 0.969196]\n",
      "epoch:2 step:2141[D loss: 0.458981, acc: 56.25%, op_acc: 30.47%] [G loss: 0.994974]\n",
      "epoch:2 step:2142[D loss: 0.460058, acc: 63.28%, op_acc: 25.00%] [G loss: 0.950220]\n",
      "epoch:2 step:2143[D loss: 0.456153, acc: 57.03%, op_acc: 33.59%] [G loss: 1.083269]\n",
      "epoch:2 step:2144[D loss: 0.492134, acc: 53.12%, op_acc: 25.78%] [G loss: 0.918794]\n",
      "epoch:2 step:2145[D loss: 0.462545, acc: 57.81%, op_acc: 32.81%] [G loss: 1.014311]\n",
      "epoch:2 step:2146[D loss: 0.507475, acc: 55.47%, op_acc: 22.66%] [G loss: 1.030140]\n",
      "epoch:2 step:2147[D loss: 0.457393, acc: 62.50%, op_acc: 31.25%] [G loss: 0.874093]\n",
      "epoch:2 step:2148[D loss: 0.446124, acc: 67.19%, op_acc: 25.78%] [G loss: 0.942132]\n",
      "epoch:2 step:2149[D loss: 0.467800, acc: 63.28%, op_acc: 25.78%] [G loss: 0.953902]\n",
      "epoch:2 step:2150[D loss: 0.437888, acc: 65.62%, op_acc: 34.38%] [G loss: 0.914227]\n",
      "##############\n",
      "[0.87862185 0.87788565 0.80082126 0.81582157 0.78845807 0.82680422\n",
      " 0.88123479 0.83325527 0.79968105 0.82874172]\n",
      "##########\n",
      "epoch:2 step:2151[D loss: 0.462568, acc: 64.84%, op_acc: 32.03%] [G loss: 0.917125]\n",
      "epoch:2 step:2152[D loss: 0.429674, acc: 67.19%, op_acc: 29.69%] [G loss: 0.955652]\n",
      "epoch:2 step:2153[D loss: 0.503032, acc: 51.56%, op_acc: 25.78%] [G loss: 0.925873]\n",
      "epoch:2 step:2154[D loss: 0.468618, acc: 57.81%, op_acc: 39.84%] [G loss: 0.840711]\n",
      "epoch:2 step:2155[D loss: 0.425431, acc: 63.28%, op_acc: 39.84%] [G loss: 0.961798]\n",
      "epoch:2 step:2156[D loss: 0.488294, acc: 54.69%, op_acc: 25.78%] [G loss: 0.918559]\n",
      "epoch:2 step:2157[D loss: 0.493469, acc: 57.03%, op_acc: 26.56%] [G loss: 0.905934]\n",
      "epoch:2 step:2158[D loss: 0.454358, acc: 64.06%, op_acc: 24.22%] [G loss: 0.999866]\n",
      "epoch:2 step:2159[D loss: 0.474901, acc: 61.72%, op_acc: 23.44%] [G loss: 0.875409]\n",
      "epoch:2 step:2160[D loss: 0.485670, acc: 55.47%, op_acc: 31.25%] [G loss: 1.009654]\n",
      "epoch:2 step:2161[D loss: 0.452672, acc: 67.19%, op_acc: 28.91%] [G loss: 1.007296]\n",
      "epoch:2 step:2162[D loss: 0.495806, acc: 50.78%, op_acc: 27.34%] [G loss: 0.930865]\n",
      "epoch:2 step:2163[D loss: 0.468028, acc: 63.28%, op_acc: 28.12%] [G loss: 0.993955]\n",
      "epoch:2 step:2164[D loss: 0.437448, acc: 60.94%, op_acc: 33.59%] [G loss: 1.019675]\n",
      "epoch:2 step:2165[D loss: 0.413435, acc: 63.28%, op_acc: 33.59%] [G loss: 1.044123]\n",
      "epoch:2 step:2166[D loss: 0.476438, acc: 61.72%, op_acc: 28.12%] [G loss: 0.998984]\n",
      "epoch:2 step:2167[D loss: 0.485139, acc: 59.38%, op_acc: 27.34%] [G loss: 0.960385]\n",
      "epoch:2 step:2168[D loss: 0.488029, acc: 53.91%, op_acc: 30.47%] [G loss: 0.974935]\n",
      "epoch:2 step:2169[D loss: 0.486281, acc: 53.12%, op_acc: 32.81%] [G loss: 0.931195]\n",
      "epoch:2 step:2170[D loss: 0.459048, acc: 57.81%, op_acc: 29.69%] [G loss: 1.063378]\n",
      "epoch:2 step:2171[D loss: 0.467138, acc: 60.94%, op_acc: 28.91%] [G loss: 0.921582]\n",
      "epoch:2 step:2172[D loss: 0.456533, acc: 64.84%, op_acc: 25.00%] [G loss: 1.135679]\n",
      "epoch:2 step:2173[D loss: 0.499015, acc: 52.34%, op_acc: 28.12%] [G loss: 0.983302]\n",
      "epoch:2 step:2174[D loss: 0.476354, acc: 55.47%, op_acc: 24.22%] [G loss: 0.930546]\n",
      "epoch:2 step:2175[D loss: 0.487090, acc: 50.00%, op_acc: 33.59%] [G loss: 1.026711]\n",
      "epoch:2 step:2176[D loss: 0.487336, acc: 55.47%, op_acc: 30.47%] [G loss: 0.886056]\n",
      "epoch:2 step:2177[D loss: 0.463628, acc: 63.28%, op_acc: 32.81%] [G loss: 1.083030]\n",
      "epoch:2 step:2178[D loss: 0.488838, acc: 56.25%, op_acc: 28.91%] [G loss: 1.029836]\n",
      "epoch:2 step:2179[D loss: 0.474780, acc: 57.03%, op_acc: 24.22%] [G loss: 1.051562]\n",
      "epoch:2 step:2180[D loss: 0.446093, acc: 62.50%, op_acc: 28.91%] [G loss: 0.964649]\n",
      "epoch:2 step:2181[D loss: 0.477113, acc: 60.16%, op_acc: 26.56%] [G loss: 1.001027]\n",
      "epoch:2 step:2182[D loss: 0.453508, acc: 62.50%, op_acc: 28.12%] [G loss: 0.967295]\n",
      "epoch:2 step:2183[D loss: 0.479958, acc: 60.16%, op_acc: 30.47%] [G loss: 1.002581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2184[D loss: 0.503038, acc: 51.56%, op_acc: 25.78%] [G loss: 1.015968]\n",
      "epoch:2 step:2185[D loss: 0.499833, acc: 55.47%, op_acc: 31.25%] [G loss: 0.957202]\n",
      "epoch:2 step:2186[D loss: 0.418381, acc: 66.41%, op_acc: 36.72%] [G loss: 0.966533]\n",
      "epoch:2 step:2187[D loss: 0.453281, acc: 61.72%, op_acc: 32.81%] [G loss: 0.939012]\n",
      "epoch:2 step:2188[D loss: 0.452295, acc: 57.81%, op_acc: 35.16%] [G loss: 0.934921]\n",
      "epoch:2 step:2189[D loss: 0.466225, acc: 60.16%, op_acc: 24.22%] [G loss: 0.958066]\n",
      "epoch:2 step:2190[D loss: 0.457900, acc: 65.62%, op_acc: 26.56%] [G loss: 0.952884]\n",
      "epoch:2 step:2191[D loss: 0.520115, acc: 51.56%, op_acc: 23.44%] [G loss: 0.939961]\n",
      "epoch:2 step:2192[D loss: 0.471067, acc: 61.72%, op_acc: 25.78%] [G loss: 0.849504]\n",
      "epoch:2 step:2193[D loss: 0.481143, acc: 57.03%, op_acc: 29.69%] [G loss: 0.968880]\n",
      "epoch:2 step:2194[D loss: 0.482348, acc: 64.84%, op_acc: 20.31%] [G loss: 0.980423]\n",
      "epoch:2 step:2195[D loss: 0.498029, acc: 54.69%, op_acc: 29.69%] [G loss: 1.022233]\n",
      "epoch:2 step:2196[D loss: 0.445126, acc: 57.03%, op_acc: 35.94%] [G loss: 1.080797]\n",
      "epoch:2 step:2197[D loss: 0.494842, acc: 53.91%, op_acc: 32.03%] [G loss: 1.011220]\n",
      "epoch:2 step:2198[D loss: 0.437595, acc: 62.50%, op_acc: 38.28%] [G loss: 1.014727]\n",
      "epoch:2 step:2199[D loss: 0.459034, acc: 56.25%, op_acc: 32.03%] [G loss: 1.101582]\n",
      "epoch:2 step:2200[D loss: 0.468559, acc: 57.81%, op_acc: 25.00%] [G loss: 0.983509]\n",
      "##############\n",
      "[0.86082192 0.8354131  0.82611649 0.8193649  0.77290509 0.80046028\n",
      " 0.88762271 0.8437076  0.84559034 0.84526938]\n",
      "##########\n",
      "epoch:2 step:2201[D loss: 0.462199, acc: 66.41%, op_acc: 28.91%] [G loss: 0.982400]\n",
      "epoch:2 step:2202[D loss: 0.477220, acc: 58.59%, op_acc: 30.47%] [G loss: 0.953199]\n",
      "epoch:2 step:2203[D loss: 0.502131, acc: 54.69%, op_acc: 28.91%] [G loss: 1.031949]\n",
      "epoch:2 step:2204[D loss: 0.451365, acc: 65.62%, op_acc: 27.34%] [G loss: 0.973791]\n",
      "epoch:2 step:2205[D loss: 0.491494, acc: 52.34%, op_acc: 32.03%] [G loss: 0.886051]\n",
      "epoch:2 step:2206[D loss: 0.505186, acc: 53.12%, op_acc: 26.56%] [G loss: 0.795739]\n",
      "epoch:2 step:2207[D loss: 0.527613, acc: 46.88%, op_acc: 28.91%] [G loss: 0.841912]\n",
      "epoch:2 step:2208[D loss: 0.484090, acc: 66.41%, op_acc: 29.69%] [G loss: 0.988212]\n",
      "epoch:2 step:2209[D loss: 0.457479, acc: 57.03%, op_acc: 31.25%] [G loss: 0.948159]\n",
      "epoch:2 step:2210[D loss: 0.478915, acc: 57.81%, op_acc: 25.00%] [G loss: 0.929989]\n",
      "epoch:2 step:2211[D loss: 0.503966, acc: 52.34%, op_acc: 31.25%] [G loss: 0.918505]\n",
      "epoch:2 step:2212[D loss: 0.526759, acc: 53.12%, op_acc: 21.09%] [G loss: 1.085000]\n",
      "epoch:2 step:2213[D loss: 0.437411, acc: 64.06%, op_acc: 32.81%] [G loss: 0.977558]\n",
      "epoch:2 step:2214[D loss: 0.442456, acc: 65.62%, op_acc: 31.25%] [G loss: 0.940073]\n",
      "epoch:2 step:2215[D loss: 0.443977, acc: 61.72%, op_acc: 30.47%] [G loss: 0.950102]\n",
      "epoch:2 step:2216[D loss: 0.452896, acc: 60.16%, op_acc: 32.81%] [G loss: 0.976893]\n",
      "epoch:2 step:2217[D loss: 0.459751, acc: 58.59%, op_acc: 25.00%] [G loss: 0.883075]\n",
      "epoch:2 step:2218[D loss: 0.444526, acc: 61.72%, op_acc: 30.47%] [G loss: 0.889429]\n",
      "epoch:2 step:2219[D loss: 0.496088, acc: 57.03%, op_acc: 23.44%] [G loss: 0.929810]\n",
      "epoch:2 step:2220[D loss: 0.469165, acc: 60.16%, op_acc: 32.03%] [G loss: 0.874586]\n",
      "epoch:2 step:2221[D loss: 0.440323, acc: 65.62%, op_acc: 32.81%] [G loss: 0.958268]\n",
      "epoch:2 step:2222[D loss: 0.455549, acc: 53.12%, op_acc: 32.03%] [G loss: 0.991090]\n",
      "epoch:2 step:2223[D loss: 0.455675, acc: 57.81%, op_acc: 28.91%] [G loss: 0.904971]\n",
      "epoch:2 step:2224[D loss: 0.493466, acc: 44.53%, op_acc: 35.16%] [G loss: 1.019338]\n",
      "epoch:2 step:2225[D loss: 0.444002, acc: 59.38%, op_acc: 32.81%] [G loss: 1.039614]\n",
      "epoch:2 step:2226[D loss: 0.449737, acc: 60.94%, op_acc: 29.69%] [G loss: 0.914752]\n",
      "epoch:2 step:2227[D loss: 0.504426, acc: 62.50%, op_acc: 21.09%] [G loss: 0.895166]\n",
      "epoch:2 step:2228[D loss: 0.486999, acc: 60.16%, op_acc: 22.66%] [G loss: 0.905410]\n",
      "epoch:2 step:2229[D loss: 0.449036, acc: 57.81%, op_acc: 25.00%] [G loss: 0.954861]\n",
      "epoch:2 step:2230[D loss: 0.449144, acc: 57.81%, op_acc: 28.12%] [G loss: 0.832572]\n",
      "epoch:2 step:2231[D loss: 0.506569, acc: 54.69%, op_acc: 25.00%] [G loss: 0.995160]\n",
      "epoch:2 step:2232[D loss: 0.463453, acc: 62.50%, op_acc: 29.69%] [G loss: 0.893314]\n",
      "epoch:2 step:2233[D loss: 0.479273, acc: 56.25%, op_acc: 26.56%] [G loss: 0.921832]\n",
      "epoch:2 step:2234[D loss: 0.493057, acc: 58.59%, op_acc: 27.34%] [G loss: 1.005239]\n",
      "epoch:2 step:2235[D loss: 0.471872, acc: 58.59%, op_acc: 32.03%] [G loss: 0.919756]\n",
      "epoch:2 step:2236[D loss: 0.479482, acc: 53.91%, op_acc: 31.25%] [G loss: 0.979790]\n",
      "epoch:2 step:2237[D loss: 0.468043, acc: 57.03%, op_acc: 25.00%] [G loss: 0.911599]\n",
      "epoch:2 step:2238[D loss: 0.476834, acc: 59.38%, op_acc: 25.78%] [G loss: 0.908364]\n",
      "epoch:2 step:2239[D loss: 0.504806, acc: 46.88%, op_acc: 25.78%] [G loss: 0.945113]\n",
      "epoch:2 step:2240[D loss: 0.455230, acc: 60.16%, op_acc: 29.69%] [G loss: 0.849550]\n",
      "epoch:2 step:2241[D loss: 0.467877, acc: 57.81%, op_acc: 28.91%] [G loss: 0.910689]\n",
      "epoch:2 step:2242[D loss: 0.449127, acc: 62.50%, op_acc: 30.47%] [G loss: 0.927295]\n",
      "epoch:2 step:2243[D loss: 0.497772, acc: 50.78%, op_acc: 25.00%] [G loss: 0.961595]\n",
      "epoch:2 step:2244[D loss: 0.485213, acc: 53.91%, op_acc: 28.12%] [G loss: 0.973661]\n",
      "epoch:2 step:2245[D loss: 0.453052, acc: 58.59%, op_acc: 37.50%] [G loss: 0.910332]\n",
      "epoch:2 step:2246[D loss: 0.469721, acc: 57.81%, op_acc: 19.53%] [G loss: 0.894181]\n",
      "epoch:2 step:2247[D loss: 0.488046, acc: 60.94%, op_acc: 27.34%] [G loss: 0.965800]\n",
      "epoch:2 step:2248[D loss: 0.485913, acc: 55.47%, op_acc: 22.66%] [G loss: 0.990766]\n",
      "epoch:2 step:2249[D loss: 0.482788, acc: 53.91%, op_acc: 24.22%] [G loss: 0.978035]\n",
      "epoch:2 step:2250[D loss: 0.458000, acc: 64.06%, op_acc: 31.25%] [G loss: 0.935718]\n",
      "##############\n",
      "[0.85730747 0.88017582 0.80787951 0.81210367 0.79649518 0.80468421\n",
      " 0.89347317 0.82095149 0.80880766 0.8391387 ]\n",
      "##########\n",
      "epoch:2 step:2251[D loss: 0.465996, acc: 61.72%, op_acc: 26.56%] [G loss: 1.013007]\n",
      "epoch:2 step:2252[D loss: 0.448625, acc: 64.84%, op_acc: 25.78%] [G loss: 0.975254]\n",
      "epoch:2 step:2253[D loss: 0.480932, acc: 57.81%, op_acc: 30.47%] [G loss: 0.930141]\n",
      "epoch:2 step:2254[D loss: 0.471118, acc: 60.16%, op_acc: 22.66%] [G loss: 1.039513]\n",
      "epoch:2 step:2255[D loss: 0.468312, acc: 67.97%, op_acc: 19.53%] [G loss: 0.982552]\n",
      "epoch:2 step:2256[D loss: 0.480722, acc: 62.50%, op_acc: 20.31%] [G loss: 0.913867]\n",
      "epoch:2 step:2257[D loss: 0.497998, acc: 50.78%, op_acc: 23.44%] [G loss: 1.011651]\n",
      "epoch:2 step:2258[D loss: 0.463924, acc: 64.84%, op_acc: 27.34%] [G loss: 1.098414]\n",
      "epoch:2 step:2259[D loss: 0.479629, acc: 64.06%, op_acc: 23.44%] [G loss: 0.925136]\n",
      "epoch:2 step:2260[D loss: 0.449798, acc: 64.84%, op_acc: 29.69%] [G loss: 1.024829]\n",
      "epoch:2 step:2261[D loss: 0.458460, acc: 60.94%, op_acc: 32.03%] [G loss: 0.971159]\n",
      "epoch:2 step:2262[D loss: 0.478196, acc: 60.16%, op_acc: 33.59%] [G loss: 0.881820]\n",
      "epoch:2 step:2263[D loss: 0.486876, acc: 60.16%, op_acc: 22.66%] [G loss: 0.824844]\n",
      "epoch:2 step:2264[D loss: 0.471913, acc: 60.16%, op_acc: 26.56%] [G loss: 0.969328]\n",
      "epoch:2 step:2265[D loss: 0.425714, acc: 67.97%, op_acc: 28.12%] [G loss: 0.944627]\n",
      "epoch:2 step:2266[D loss: 0.443586, acc: 64.06%, op_acc: 34.38%] [G loss: 0.861907]\n",
      "epoch:2 step:2267[D loss: 0.463058, acc: 60.16%, op_acc: 32.81%] [G loss: 0.941008]\n",
      "epoch:2 step:2268[D loss: 0.469057, acc: 55.47%, op_acc: 28.91%] [G loss: 0.945238]\n",
      "epoch:2 step:2269[D loss: 0.476148, acc: 57.03%, op_acc: 28.12%] [G loss: 0.969637]\n",
      "epoch:2 step:2270[D loss: 0.474604, acc: 59.38%, op_acc: 27.34%] [G loss: 0.897870]\n",
      "epoch:2 step:2271[D loss: 0.485306, acc: 51.56%, op_acc: 30.47%] [G loss: 0.889737]\n",
      "epoch:2 step:2272[D loss: 0.411082, acc: 60.16%, op_acc: 40.62%] [G loss: 0.905718]\n",
      "epoch:2 step:2273[D loss: 0.445963, acc: 64.06%, op_acc: 31.25%] [G loss: 1.043707]\n",
      "epoch:2 step:2274[D loss: 0.418014, acc: 66.41%, op_acc: 34.38%] [G loss: 1.096873]\n",
      "epoch:2 step:2275[D loss: 0.440191, acc: 66.41%, op_acc: 34.38%] [G loss: 0.994271]\n",
      "epoch:2 step:2276[D loss: 0.466396, acc: 58.59%, op_acc: 25.78%] [G loss: 0.928434]\n",
      "epoch:2 step:2277[D loss: 0.441146, acc: 64.06%, op_acc: 28.91%] [G loss: 1.008257]\n",
      "epoch:2 step:2278[D loss: 0.475163, acc: 65.62%, op_acc: 24.22%] [G loss: 0.910856]\n",
      "epoch:2 step:2279[D loss: 0.451557, acc: 60.94%, op_acc: 34.38%] [G loss: 0.961438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2280[D loss: 0.496276, acc: 53.91%, op_acc: 22.66%] [G loss: 0.860105]\n",
      "epoch:2 step:2281[D loss: 0.441285, acc: 62.50%, op_acc: 25.78%] [G loss: 0.940996]\n",
      "epoch:2 step:2282[D loss: 0.449165, acc: 66.41%, op_acc: 28.12%] [G loss: 0.903580]\n",
      "epoch:2 step:2283[D loss: 0.468228, acc: 54.69%, op_acc: 31.25%] [G loss: 0.914025]\n",
      "epoch:2 step:2284[D loss: 0.473387, acc: 62.50%, op_acc: 29.69%] [G loss: 0.890582]\n",
      "epoch:2 step:2285[D loss: 0.428428, acc: 67.19%, op_acc: 28.91%] [G loss: 0.979186]\n",
      "epoch:2 step:2286[D loss: 0.481814, acc: 60.16%, op_acc: 29.69%] [G loss: 1.004841]\n",
      "epoch:2 step:2287[D loss: 0.454664, acc: 61.72%, op_acc: 31.25%] [G loss: 1.025093]\n",
      "epoch:2 step:2288[D loss: 0.435361, acc: 64.06%, op_acc: 35.94%] [G loss: 0.919786]\n",
      "epoch:2 step:2289[D loss: 0.478568, acc: 54.69%, op_acc: 33.59%] [G loss: 1.100951]\n",
      "epoch:2 step:2290[D loss: 0.495581, acc: 57.81%, op_acc: 21.09%] [G loss: 0.961622]\n",
      "epoch:2 step:2291[D loss: 0.440220, acc: 67.19%, op_acc: 31.25%] [G loss: 0.966758]\n",
      "epoch:2 step:2292[D loss: 0.448191, acc: 60.94%, op_acc: 28.91%] [G loss: 1.010604]\n",
      "epoch:2 step:2293[D loss: 0.466128, acc: 57.03%, op_acc: 32.03%] [G loss: 0.989548]\n",
      "epoch:2 step:2294[D loss: 0.473749, acc: 60.94%, op_acc: 34.38%] [G loss: 0.928445]\n",
      "epoch:2 step:2295[D loss: 0.495698, acc: 48.44%, op_acc: 30.47%] [G loss: 0.946385]\n",
      "epoch:2 step:2296[D loss: 0.473803, acc: 60.16%, op_acc: 32.81%] [G loss: 0.934599]\n",
      "epoch:2 step:2297[D loss: 0.513020, acc: 53.12%, op_acc: 27.34%] [G loss: 0.895490]\n",
      "epoch:2 step:2298[D loss: 0.479660, acc: 52.34%, op_acc: 28.12%] [G loss: 0.925094]\n",
      "epoch:2 step:2299[D loss: 0.445984, acc: 57.03%, op_acc: 31.25%] [G loss: 0.843821]\n",
      "epoch:2 step:2300[D loss: 0.446347, acc: 62.50%, op_acc: 30.47%] [G loss: 0.914867]\n",
      "##############\n",
      "[0.84853409 0.85446877 0.82289461 0.80203417 0.81899348 0.83329015\n",
      " 0.88465156 0.8502608  0.82065341 0.82515406]\n",
      "##########\n",
      "epoch:2 step:2301[D loss: 0.456778, acc: 58.59%, op_acc: 28.91%] [G loss: 0.948138]\n",
      "epoch:2 step:2302[D loss: 0.428155, acc: 68.75%, op_acc: 32.81%] [G loss: 0.998499]\n",
      "epoch:2 step:2303[D loss: 0.473065, acc: 62.50%, op_acc: 29.69%] [G loss: 0.975846]\n",
      "epoch:2 step:2304[D loss: 0.491468, acc: 57.03%, op_acc: 32.03%] [G loss: 0.941902]\n",
      "epoch:2 step:2305[D loss: 0.463402, acc: 65.62%, op_acc: 21.88%] [G loss: 1.015118]\n",
      "epoch:2 step:2306[D loss: 0.481407, acc: 53.12%, op_acc: 28.91%] [G loss: 0.941004]\n",
      "epoch:2 step:2307[D loss: 0.429644, acc: 62.50%, op_acc: 33.59%] [G loss: 1.010839]\n",
      "epoch:2 step:2308[D loss: 0.462561, acc: 57.03%, op_acc: 29.69%] [G loss: 0.923034]\n",
      "epoch:2 step:2309[D loss: 0.459037, acc: 56.25%, op_acc: 33.59%] [G loss: 1.056120]\n",
      "epoch:2 step:2310[D loss: 0.477082, acc: 61.72%, op_acc: 22.66%] [G loss: 0.892171]\n",
      "epoch:2 step:2311[D loss: 0.477502, acc: 55.47%, op_acc: 28.12%] [G loss: 0.920674]\n",
      "epoch:2 step:2312[D loss: 0.448467, acc: 60.94%, op_acc: 33.59%] [G loss: 0.972239]\n",
      "epoch:2 step:2313[D loss: 0.481310, acc: 65.62%, op_acc: 28.12%] [G loss: 1.029751]\n",
      "epoch:2 step:2314[D loss: 0.479728, acc: 57.03%, op_acc: 30.47%] [G loss: 0.983291]\n",
      "epoch:2 step:2315[D loss: 0.475823, acc: 58.59%, op_acc: 36.72%] [G loss: 0.867104]\n",
      "epoch:2 step:2316[D loss: 0.430328, acc: 68.75%, op_acc: 36.72%] [G loss: 0.885989]\n",
      "epoch:2 step:2317[D loss: 0.444824, acc: 59.38%, op_acc: 32.81%] [G loss: 0.945783]\n",
      "epoch:2 step:2318[D loss: 0.437818, acc: 64.06%, op_acc: 27.34%] [G loss: 0.913283]\n",
      "epoch:2 step:2319[D loss: 0.455171, acc: 58.59%, op_acc: 31.25%] [G loss: 0.942224]\n",
      "epoch:2 step:2320[D loss: 0.469438, acc: 57.81%, op_acc: 31.25%] [G loss: 0.972402]\n",
      "epoch:2 step:2321[D loss: 0.455981, acc: 60.94%, op_acc: 27.34%] [G loss: 0.935964]\n",
      "epoch:2 step:2322[D loss: 0.469117, acc: 63.28%, op_acc: 28.91%] [G loss: 1.020512]\n",
      "epoch:2 step:2323[D loss: 0.455967, acc: 61.72%, op_acc: 34.38%] [G loss: 1.020835]\n",
      "epoch:2 step:2324[D loss: 0.454643, acc: 61.72%, op_acc: 29.69%] [G loss: 0.933141]\n",
      "epoch:2 step:2325[D loss: 0.463841, acc: 63.28%, op_acc: 26.56%] [G loss: 0.988553]\n",
      "epoch:2 step:2326[D loss: 0.480370, acc: 50.78%, op_acc: 31.25%] [G loss: 0.981532]\n",
      "epoch:2 step:2327[D loss: 0.472298, acc: 64.06%, op_acc: 30.47%] [G loss: 1.113447]\n",
      "epoch:2 step:2328[D loss: 0.456107, acc: 61.72%, op_acc: 32.81%] [G loss: 0.978402]\n",
      "epoch:2 step:2329[D loss: 0.486763, acc: 55.47%, op_acc: 28.91%] [G loss: 0.892504]\n",
      "epoch:2 step:2330[D loss: 0.488410, acc: 57.03%, op_acc: 26.56%] [G loss: 0.972655]\n",
      "epoch:2 step:2331[D loss: 0.432482, acc: 65.62%, op_acc: 34.38%] [G loss: 0.866037]\n",
      "epoch:2 step:2332[D loss: 0.446176, acc: 69.53%, op_acc: 23.44%] [G loss: 0.935022]\n",
      "epoch:2 step:2333[D loss: 0.492258, acc: 48.44%, op_acc: 28.12%] [G loss: 1.010308]\n",
      "epoch:2 step:2334[D loss: 0.493286, acc: 55.47%, op_acc: 26.56%] [G loss: 1.016389]\n",
      "epoch:2 step:2335[D loss: 0.485738, acc: 57.03%, op_acc: 25.78%] [G loss: 0.974336]\n",
      "epoch:2 step:2336[D loss: 0.437786, acc: 57.03%, op_acc: 31.25%] [G loss: 0.975012]\n",
      "epoch:2 step:2337[D loss: 0.451364, acc: 64.06%, op_acc: 28.91%] [G loss: 1.025695]\n",
      "epoch:2 step:2338[D loss: 0.450077, acc: 60.94%, op_acc: 28.91%] [G loss: 0.959728]\n",
      "epoch:2 step:2339[D loss: 0.492192, acc: 58.59%, op_acc: 17.19%] [G loss: 0.939600]\n",
      "epoch:2 step:2340[D loss: 0.468862, acc: 55.47%, op_acc: 35.16%] [G loss: 0.870641]\n",
      "epoch:2 step:2341[D loss: 0.462296, acc: 57.03%, op_acc: 25.78%] [G loss: 1.021918]\n",
      "epoch:2 step:2342[D loss: 0.458394, acc: 60.94%, op_acc: 30.47%] [G loss: 0.990627]\n",
      "epoch:2 step:2343[D loss: 0.445251, acc: 61.72%, op_acc: 32.03%] [G loss: 0.978640]\n",
      "epoch:3 step:2344[D loss: 0.468942, acc: 56.25%, op_acc: 28.12%] [G loss: 1.045174]\n",
      "epoch:3 step:2345[D loss: 0.398387, acc: 68.75%, op_acc: 35.16%] [G loss: 1.033941]\n",
      "epoch:3 step:2346[D loss: 0.445263, acc: 65.62%, op_acc: 29.69%] [G loss: 1.012208]\n",
      "epoch:3 step:2347[D loss: 0.450133, acc: 61.72%, op_acc: 30.47%] [G loss: 0.922049]\n",
      "epoch:3 step:2348[D loss: 0.423854, acc: 63.28%, op_acc: 35.16%] [G loss: 1.032228]\n",
      "epoch:3 step:2349[D loss: 0.428204, acc: 69.53%, op_acc: 29.69%] [G loss: 0.969717]\n",
      "epoch:3 step:2350[D loss: 0.465974, acc: 60.94%, op_acc: 24.22%] [G loss: 1.072789]\n",
      "##############\n",
      "[0.86246929 0.85523409 0.81615172 0.80946197 0.81533762 0.81816234\n",
      " 0.91170631 0.82923731 0.8242384  0.81892782]\n",
      "##########\n",
      "epoch:3 step:2351[D loss: 0.457115, acc: 58.59%, op_acc: 33.59%] [G loss: 1.046696]\n",
      "epoch:3 step:2352[D loss: 0.433587, acc: 62.50%, op_acc: 33.59%] [G loss: 0.937187]\n",
      "epoch:3 step:2353[D loss: 0.467786, acc: 60.16%, op_acc: 27.34%] [G loss: 0.982652]\n",
      "epoch:3 step:2354[D loss: 0.456663, acc: 65.62%, op_acc: 29.69%] [G loss: 0.975494]\n",
      "epoch:3 step:2355[D loss: 0.455515, acc: 64.06%, op_acc: 28.12%] [G loss: 1.092713]\n",
      "epoch:3 step:2356[D loss: 0.407628, acc: 79.69%, op_acc: 35.16%] [G loss: 1.060282]\n",
      "epoch:3 step:2357[D loss: 0.479964, acc: 61.72%, op_acc: 28.12%] [G loss: 1.000936]\n",
      "epoch:3 step:2358[D loss: 0.481106, acc: 56.25%, op_acc: 37.50%] [G loss: 1.052313]\n",
      "epoch:3 step:2359[D loss: 0.468781, acc: 56.25%, op_acc: 33.59%] [G loss: 0.976025]\n",
      "epoch:3 step:2360[D loss: 0.479029, acc: 55.47%, op_acc: 32.03%] [G loss: 0.887765]\n",
      "epoch:3 step:2361[D loss: 0.452641, acc: 57.81%, op_acc: 32.81%] [G loss: 0.880530]\n",
      "epoch:3 step:2362[D loss: 0.452659, acc: 60.94%, op_acc: 32.03%] [G loss: 0.963575]\n",
      "epoch:3 step:2363[D loss: 0.455140, acc: 57.03%, op_acc: 35.94%] [G loss: 0.986285]\n",
      "epoch:3 step:2364[D loss: 0.471166, acc: 55.47%, op_acc: 28.12%] [G loss: 1.038375]\n",
      "epoch:3 step:2365[D loss: 0.455459, acc: 62.50%, op_acc: 32.03%] [G loss: 1.019638]\n",
      "epoch:3 step:2366[D loss: 0.499190, acc: 51.56%, op_acc: 28.12%] [G loss: 0.907309]\n",
      "epoch:3 step:2367[D loss: 0.499217, acc: 51.56%, op_acc: 30.47%] [G loss: 0.986027]\n",
      "epoch:3 step:2368[D loss: 0.467876, acc: 60.16%, op_acc: 30.47%] [G loss: 0.998797]\n",
      "epoch:3 step:2369[D loss: 0.446116, acc: 64.84%, op_acc: 28.91%] [G loss: 0.976432]\n",
      "epoch:3 step:2370[D loss: 0.462687, acc: 57.81%, op_acc: 25.00%] [G loss: 0.982892]\n",
      "epoch:3 step:2371[D loss: 0.459071, acc: 58.59%, op_acc: 27.34%] [G loss: 0.929453]\n",
      "epoch:3 step:2372[D loss: 0.433755, acc: 65.62%, op_acc: 32.03%] [G loss: 1.028881]\n",
      "epoch:3 step:2373[D loss: 0.448066, acc: 60.16%, op_acc: 32.81%] [G loss: 1.022070]\n",
      "epoch:3 step:2374[D loss: 0.478696, acc: 61.72%, op_acc: 27.34%] [G loss: 1.076497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2375[D loss: 0.506147, acc: 51.56%, op_acc: 29.69%] [G loss: 0.927411]\n",
      "epoch:3 step:2376[D loss: 0.437099, acc: 60.16%, op_acc: 35.16%] [G loss: 1.019478]\n",
      "epoch:3 step:2377[D loss: 0.467888, acc: 60.16%, op_acc: 32.03%] [G loss: 0.990844]\n",
      "epoch:3 step:2378[D loss: 0.476116, acc: 55.47%, op_acc: 29.69%] [G loss: 0.900765]\n",
      "epoch:3 step:2379[D loss: 0.467724, acc: 55.47%, op_acc: 31.25%] [G loss: 0.909418]\n",
      "epoch:3 step:2380[D loss: 0.478754, acc: 51.56%, op_acc: 27.34%] [G loss: 0.912290]\n",
      "epoch:3 step:2381[D loss: 0.452908, acc: 61.72%, op_acc: 29.69%] [G loss: 0.936699]\n",
      "epoch:3 step:2382[D loss: 0.454648, acc: 64.06%, op_acc: 28.12%] [G loss: 0.920292]\n",
      "epoch:3 step:2383[D loss: 0.485524, acc: 57.03%, op_acc: 25.00%] [G loss: 0.934540]\n",
      "epoch:3 step:2384[D loss: 0.442994, acc: 60.94%, op_acc: 34.38%] [G loss: 1.135974]\n",
      "epoch:3 step:2385[D loss: 0.461722, acc: 54.69%, op_acc: 33.59%] [G loss: 0.929727]\n",
      "epoch:3 step:2386[D loss: 0.461122, acc: 61.72%, op_acc: 25.78%] [G loss: 0.968436]\n",
      "epoch:3 step:2387[D loss: 0.469340, acc: 57.81%, op_acc: 29.69%] [G loss: 0.890446]\n",
      "epoch:3 step:2388[D loss: 0.460901, acc: 64.84%, op_acc: 32.81%] [G loss: 0.932848]\n",
      "epoch:3 step:2389[D loss: 0.491337, acc: 51.56%, op_acc: 26.56%] [G loss: 0.951854]\n",
      "epoch:3 step:2390[D loss: 0.472629, acc: 56.25%, op_acc: 26.56%] [G loss: 0.892301]\n",
      "epoch:3 step:2391[D loss: 0.478579, acc: 55.47%, op_acc: 27.34%] [G loss: 0.962003]\n",
      "epoch:3 step:2392[D loss: 0.483381, acc: 59.38%, op_acc: 32.03%] [G loss: 0.871886]\n",
      "epoch:3 step:2393[D loss: 0.474607, acc: 62.50%, op_acc: 27.34%] [G loss: 0.918312]\n",
      "epoch:3 step:2394[D loss: 0.472594, acc: 60.16%, op_acc: 31.25%] [G loss: 0.949856]\n",
      "epoch:3 step:2395[D loss: 0.476466, acc: 54.69%, op_acc: 27.34%] [G loss: 0.924494]\n",
      "epoch:3 step:2396[D loss: 0.451557, acc: 71.09%, op_acc: 25.00%] [G loss: 1.104169]\n",
      "epoch:3 step:2397[D loss: 0.483605, acc: 60.16%, op_acc: 31.25%] [G loss: 0.910116]\n",
      "epoch:3 step:2398[D loss: 0.469042, acc: 50.00%, op_acc: 32.81%] [G loss: 0.975733]\n",
      "epoch:3 step:2399[D loss: 0.450949, acc: 57.81%, op_acc: 33.59%] [G loss: 0.960572]\n",
      "epoch:3 step:2400[D loss: 0.483804, acc: 53.91%, op_acc: 28.91%] [G loss: 0.899819]\n",
      "##############\n",
      "[0.84676404 0.83551853 0.82092925 0.80206032 0.80713731 0.80594899\n",
      " 0.88471002 0.83666806 0.81014464 0.81584585]\n",
      "##########\n",
      "epoch:3 step:2401[D loss: 0.466546, acc: 61.72%, op_acc: 32.81%] [G loss: 0.916417]\n",
      "epoch:3 step:2402[D loss: 0.427252, acc: 64.06%, op_acc: 35.16%] [G loss: 0.892027]\n",
      "epoch:3 step:2403[D loss: 0.484889, acc: 55.47%, op_acc: 24.22%] [G loss: 0.945913]\n",
      "epoch:3 step:2404[D loss: 0.481039, acc: 56.25%, op_acc: 27.34%] [G loss: 0.979778]\n",
      "epoch:3 step:2405[D loss: 0.497511, acc: 56.25%, op_acc: 25.00%] [G loss: 0.992023]\n",
      "epoch:3 step:2406[D loss: 0.471550, acc: 63.28%, op_acc: 27.34%] [G loss: 0.933236]\n",
      "epoch:3 step:2407[D loss: 0.437242, acc: 63.28%, op_acc: 28.12%] [G loss: 1.071406]\n",
      "epoch:3 step:2408[D loss: 0.474059, acc: 62.50%, op_acc: 25.00%] [G loss: 0.910081]\n",
      "epoch:3 step:2409[D loss: 0.459821, acc: 57.03%, op_acc: 27.34%] [G loss: 0.891258]\n",
      "epoch:3 step:2410[D loss: 0.454296, acc: 58.59%, op_acc: 27.34%] [G loss: 0.925911]\n",
      "epoch:3 step:2411[D loss: 0.449533, acc: 62.50%, op_acc: 31.25%] [G loss: 1.017661]\n",
      "epoch:3 step:2412[D loss: 0.456501, acc: 58.59%, op_acc: 32.03%] [G loss: 0.849922]\n",
      "epoch:3 step:2413[D loss: 0.462150, acc: 56.25%, op_acc: 26.56%] [G loss: 1.012916]\n",
      "epoch:3 step:2414[D loss: 0.498630, acc: 57.81%, op_acc: 21.88%] [G loss: 1.005552]\n",
      "epoch:3 step:2415[D loss: 0.458932, acc: 59.38%, op_acc: 28.12%] [G loss: 0.979040]\n",
      "epoch:3 step:2416[D loss: 0.445971, acc: 56.25%, op_acc: 29.69%] [G loss: 0.884083]\n",
      "epoch:3 step:2417[D loss: 0.436848, acc: 67.97%, op_acc: 32.81%] [G loss: 0.895156]\n",
      "epoch:3 step:2418[D loss: 0.464709, acc: 56.25%, op_acc: 25.78%] [G loss: 0.924338]\n",
      "epoch:3 step:2419[D loss: 0.465556, acc: 60.16%, op_acc: 31.25%] [G loss: 0.802041]\n",
      "epoch:3 step:2420[D loss: 0.468593, acc: 50.78%, op_acc: 28.91%] [G loss: 0.995023]\n",
      "epoch:3 step:2421[D loss: 0.493074, acc: 60.16%, op_acc: 23.44%] [G loss: 0.844161]\n",
      "epoch:3 step:2422[D loss: 0.456598, acc: 63.28%, op_acc: 29.69%] [G loss: 0.976610]\n",
      "epoch:3 step:2423[D loss: 0.480019, acc: 63.28%, op_acc: 25.78%] [G loss: 0.894982]\n",
      "epoch:3 step:2424[D loss: 0.463093, acc: 64.84%, op_acc: 29.69%] [G loss: 0.954776]\n",
      "epoch:3 step:2425[D loss: 0.481931, acc: 57.03%, op_acc: 31.25%] [G loss: 0.844979]\n",
      "epoch:3 step:2426[D loss: 0.479039, acc: 56.25%, op_acc: 24.22%] [G loss: 0.904696]\n",
      "epoch:3 step:2427[D loss: 0.477031, acc: 60.94%, op_acc: 28.91%] [G loss: 0.884657]\n",
      "epoch:3 step:2428[D loss: 0.469014, acc: 60.94%, op_acc: 25.78%] [G loss: 0.867171]\n",
      "epoch:3 step:2429[D loss: 0.497365, acc: 50.00%, op_acc: 26.56%] [G loss: 0.939613]\n",
      "epoch:3 step:2430[D loss: 0.453539, acc: 62.50%, op_acc: 25.78%] [G loss: 0.982608]\n",
      "epoch:3 step:2431[D loss: 0.438298, acc: 62.50%, op_acc: 34.38%] [G loss: 0.922267]\n",
      "epoch:3 step:2432[D loss: 0.503802, acc: 54.69%, op_acc: 23.44%] [G loss: 0.859717]\n",
      "epoch:3 step:2433[D loss: 0.472764, acc: 57.81%, op_acc: 34.38%] [G loss: 0.877922]\n",
      "epoch:3 step:2434[D loss: 0.464882, acc: 59.38%, op_acc: 28.91%] [G loss: 0.911769]\n",
      "epoch:3 step:2435[D loss: 0.468147, acc: 59.38%, op_acc: 28.12%] [G loss: 0.947732]\n",
      "epoch:3 step:2436[D loss: 0.469573, acc: 53.12%, op_acc: 29.69%] [G loss: 0.944834]\n",
      "epoch:3 step:2437[D loss: 0.413677, acc: 71.88%, op_acc: 24.22%] [G loss: 0.946597]\n",
      "epoch:3 step:2438[D loss: 0.466392, acc: 53.91%, op_acc: 30.47%] [G loss: 0.909673]\n",
      "epoch:3 step:2439[D loss: 0.481606, acc: 56.25%, op_acc: 27.34%] [G loss: 0.955138]\n",
      "epoch:3 step:2440[D loss: 0.474401, acc: 55.47%, op_acc: 29.69%] [G loss: 0.890081]\n",
      "epoch:3 step:2441[D loss: 0.507098, acc: 56.25%, op_acc: 19.53%] [G loss: 0.964042]\n",
      "epoch:3 step:2442[D loss: 0.479630, acc: 54.69%, op_acc: 25.78%] [G loss: 0.852044]\n",
      "epoch:3 step:2443[D loss: 0.462224, acc: 53.12%, op_acc: 28.12%] [G loss: 0.929421]\n",
      "epoch:3 step:2444[D loss: 0.434383, acc: 64.84%, op_acc: 37.50%] [G loss: 0.984596]\n",
      "epoch:3 step:2445[D loss: 0.457144, acc: 60.16%, op_acc: 28.91%] [G loss: 0.901353]\n",
      "epoch:3 step:2446[D loss: 0.475147, acc: 59.38%, op_acc: 31.25%] [G loss: 1.044401]\n",
      "epoch:3 step:2447[D loss: 0.463996, acc: 60.16%, op_acc: 26.56%] [G loss: 0.861357]\n",
      "epoch:3 step:2448[D loss: 0.420445, acc: 68.75%, op_acc: 33.59%] [G loss: 0.980276]\n",
      "epoch:3 step:2449[D loss: 0.450706, acc: 54.69%, op_acc: 34.38%] [G loss: 1.028104]\n",
      "epoch:3 step:2450[D loss: 0.441439, acc: 64.06%, op_acc: 33.59%] [G loss: 0.796453]\n",
      "##############\n",
      "[0.87636274 0.86670098 0.81425465 0.81343877 0.80128295 0.82938758\n",
      " 0.88887439 0.82702373 0.79283408 0.83339089]\n",
      "##########\n",
      "epoch:3 step:2451[D loss: 0.504165, acc: 51.56%, op_acc: 32.03%] [G loss: 0.930232]\n",
      "epoch:3 step:2452[D loss: 0.436284, acc: 63.28%, op_acc: 28.12%] [G loss: 0.927129]\n",
      "epoch:3 step:2453[D loss: 0.460110, acc: 58.59%, op_acc: 33.59%] [G loss: 0.928083]\n",
      "epoch:3 step:2454[D loss: 0.473885, acc: 62.50%, op_acc: 33.59%] [G loss: 0.980220]\n",
      "epoch:3 step:2455[D loss: 0.459079, acc: 60.94%, op_acc: 34.38%] [G loss: 0.876826]\n",
      "epoch:3 step:2456[D loss: 0.452000, acc: 64.84%, op_acc: 25.78%] [G loss: 1.018408]\n",
      "epoch:3 step:2457[D loss: 0.452167, acc: 55.47%, op_acc: 35.94%] [G loss: 0.870035]\n",
      "epoch:3 step:2458[D loss: 0.453320, acc: 57.03%, op_acc: 36.72%] [G loss: 0.931099]\n",
      "epoch:3 step:2459[D loss: 0.480807, acc: 58.59%, op_acc: 29.69%] [G loss: 0.912665]\n",
      "epoch:3 step:2460[D loss: 0.446238, acc: 60.16%, op_acc: 27.34%] [G loss: 0.986266]\n",
      "epoch:3 step:2461[D loss: 0.469502, acc: 60.16%, op_acc: 32.03%] [G loss: 0.906331]\n",
      "epoch:3 step:2462[D loss: 0.481091, acc: 53.12%, op_acc: 27.34%] [G loss: 0.921875]\n",
      "epoch:3 step:2463[D loss: 0.468716, acc: 59.38%, op_acc: 23.44%] [G loss: 0.952654]\n",
      "epoch:3 step:2464[D loss: 0.503521, acc: 53.91%, op_acc: 23.44%] [G loss: 1.000975]\n",
      "epoch:3 step:2465[D loss: 0.472502, acc: 60.16%, op_acc: 30.47%] [G loss: 0.982681]\n",
      "epoch:3 step:2466[D loss: 0.474256, acc: 55.47%, op_acc: 24.22%] [G loss: 0.855826]\n",
      "epoch:3 step:2467[D loss: 0.484947, acc: 56.25%, op_acc: 28.12%] [G loss: 0.903443]\n",
      "epoch:3 step:2468[D loss: 0.487444, acc: 57.81%, op_acc: 26.56%] [G loss: 0.910083]\n",
      "epoch:3 step:2469[D loss: 0.465059, acc: 66.41%, op_acc: 27.34%] [G loss: 0.862027]\n",
      "epoch:3 step:2470[D loss: 0.470950, acc: 59.38%, op_acc: 25.00%] [G loss: 0.974002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2471[D loss: 0.467678, acc: 60.94%, op_acc: 26.56%] [G loss: 0.974027]\n",
      "epoch:3 step:2472[D loss: 0.483225, acc: 57.81%, op_acc: 27.34%] [G loss: 0.788276]\n",
      "epoch:3 step:2473[D loss: 0.482003, acc: 60.94%, op_acc: 23.44%] [G loss: 0.911564]\n",
      "epoch:3 step:2474[D loss: 0.449928, acc: 60.94%, op_acc: 30.47%] [G loss: 0.946040]\n",
      "epoch:3 step:2475[D loss: 0.437201, acc: 64.06%, op_acc: 29.69%] [G loss: 1.068647]\n",
      "epoch:3 step:2476[D loss: 0.490315, acc: 56.25%, op_acc: 28.12%] [G loss: 0.959740]\n",
      "epoch:3 step:2477[D loss: 0.449560, acc: 61.72%, op_acc: 31.25%] [G loss: 0.994939]\n",
      "epoch:3 step:2478[D loss: 0.452966, acc: 58.59%, op_acc: 36.72%] [G loss: 0.809177]\n",
      "epoch:3 step:2479[D loss: 0.432477, acc: 60.94%, op_acc: 32.81%] [G loss: 0.945157]\n",
      "epoch:3 step:2480[D loss: 0.460524, acc: 60.94%, op_acc: 28.91%] [G loss: 0.911670]\n",
      "epoch:3 step:2481[D loss: 0.475766, acc: 55.47%, op_acc: 27.34%] [G loss: 0.922624]\n",
      "epoch:3 step:2482[D loss: 0.449845, acc: 62.50%, op_acc: 33.59%] [G loss: 0.880949]\n",
      "epoch:3 step:2483[D loss: 0.505853, acc: 54.69%, op_acc: 24.22%] [G loss: 0.889686]\n",
      "epoch:3 step:2484[D loss: 0.445299, acc: 67.19%, op_acc: 25.78%] [G loss: 0.924660]\n",
      "epoch:3 step:2485[D loss: 0.438278, acc: 61.72%, op_acc: 32.81%] [G loss: 0.930533]\n",
      "epoch:3 step:2486[D loss: 0.460681, acc: 58.59%, op_acc: 28.91%] [G loss: 0.883928]\n",
      "epoch:3 step:2487[D loss: 0.450687, acc: 61.72%, op_acc: 26.56%] [G loss: 0.892331]\n",
      "epoch:3 step:2488[D loss: 0.467821, acc: 60.16%, op_acc: 28.91%] [G loss: 0.941449]\n",
      "epoch:3 step:2489[D loss: 0.437711, acc: 61.72%, op_acc: 31.25%] [G loss: 0.866529]\n",
      "epoch:3 step:2490[D loss: 0.479589, acc: 54.69%, op_acc: 28.91%] [G loss: 0.916077]\n",
      "epoch:3 step:2491[D loss: 0.456512, acc: 65.62%, op_acc: 28.91%] [G loss: 0.909243]\n",
      "epoch:3 step:2492[D loss: 0.454594, acc: 60.94%, op_acc: 30.47%] [G loss: 0.979691]\n",
      "epoch:3 step:2493[D loss: 0.440968, acc: 60.94%, op_acc: 34.38%] [G loss: 0.918302]\n",
      "epoch:3 step:2494[D loss: 0.453386, acc: 64.06%, op_acc: 28.91%] [G loss: 0.958933]\n",
      "epoch:3 step:2495[D loss: 0.468510, acc: 60.16%, op_acc: 26.56%] [G loss: 0.958805]\n",
      "epoch:3 step:2496[D loss: 0.491279, acc: 56.25%, op_acc: 26.56%] [G loss: 0.934061]\n",
      "epoch:3 step:2497[D loss: 0.450796, acc: 61.72%, op_acc: 34.38%] [G loss: 0.891326]\n",
      "epoch:3 step:2498[D loss: 0.473628, acc: 57.81%, op_acc: 26.56%] [G loss: 0.984711]\n",
      "epoch:3 step:2499[D loss: 0.454106, acc: 61.72%, op_acc: 31.25%] [G loss: 0.927437]\n",
      "epoch:3 step:2500[D loss: 0.447741, acc: 57.03%, op_acc: 29.69%] [G loss: 0.941990]\n",
      "##############\n",
      "[0.85172879 0.86996627 0.80869134 0.8030823  0.823526   0.83217405\n",
      " 0.88806137 0.82118858 0.78285916 0.84528059]\n",
      "##########\n",
      "epoch:3 step:2501[D loss: 0.445849, acc: 60.16%, op_acc: 31.25%] [G loss: 1.024502]\n",
      "epoch:3 step:2502[D loss: 0.470553, acc: 63.28%, op_acc: 28.12%] [G loss: 0.952009]\n",
      "epoch:3 step:2503[D loss: 0.482525, acc: 60.94%, op_acc: 24.22%] [G loss: 0.904418]\n",
      "epoch:3 step:2504[D loss: 0.499854, acc: 51.56%, op_acc: 28.91%] [G loss: 0.889491]\n",
      "epoch:3 step:2505[D loss: 0.446030, acc: 59.38%, op_acc: 33.59%] [G loss: 0.927952]\n",
      "epoch:3 step:2506[D loss: 0.487081, acc: 55.47%, op_acc: 25.00%] [G loss: 0.855466]\n",
      "epoch:3 step:2507[D loss: 0.463197, acc: 62.50%, op_acc: 27.34%] [G loss: 0.952028]\n",
      "epoch:3 step:2508[D loss: 0.472158, acc: 57.81%, op_acc: 31.25%] [G loss: 0.853764]\n",
      "epoch:3 step:2509[D loss: 0.455895, acc: 58.59%, op_acc: 30.47%] [G loss: 0.957680]\n",
      "epoch:3 step:2510[D loss: 0.476195, acc: 53.91%, op_acc: 32.03%] [G loss: 0.966674]\n",
      "epoch:3 step:2511[D loss: 0.466444, acc: 57.03%, op_acc: 35.16%] [G loss: 0.953170]\n",
      "epoch:3 step:2512[D loss: 0.466097, acc: 57.81%, op_acc: 31.25%] [G loss: 0.978268]\n",
      "epoch:3 step:2513[D loss: 0.437759, acc: 65.62%, op_acc: 35.94%] [G loss: 0.951530]\n",
      "epoch:3 step:2514[D loss: 0.441452, acc: 62.50%, op_acc: 32.03%] [G loss: 0.956145]\n",
      "epoch:3 step:2515[D loss: 0.476443, acc: 53.91%, op_acc: 31.25%] [G loss: 0.964271]\n",
      "epoch:3 step:2516[D loss: 0.470392, acc: 57.03%, op_acc: 28.12%] [G loss: 0.984317]\n",
      "epoch:3 step:2517[D loss: 0.459990, acc: 61.72%, op_acc: 28.91%] [G loss: 0.898383]\n",
      "epoch:3 step:2518[D loss: 0.452919, acc: 62.50%, op_acc: 26.56%] [G loss: 0.955496]\n",
      "epoch:3 step:2519[D loss: 0.464794, acc: 59.38%, op_acc: 35.16%] [G loss: 0.965853]\n",
      "epoch:3 step:2520[D loss: 0.436789, acc: 66.41%, op_acc: 28.12%] [G loss: 0.933275]\n",
      "epoch:3 step:2521[D loss: 0.456121, acc: 64.06%, op_acc: 31.25%] [G loss: 0.947120]\n",
      "epoch:3 step:2522[D loss: 0.447732, acc: 59.38%, op_acc: 37.50%] [G loss: 0.948065]\n",
      "epoch:3 step:2523[D loss: 0.463127, acc: 60.16%, op_acc: 29.69%] [G loss: 0.991230]\n",
      "epoch:3 step:2524[D loss: 0.423337, acc: 67.19%, op_acc: 29.69%] [G loss: 1.006354]\n",
      "epoch:3 step:2525[D loss: 0.471392, acc: 58.59%, op_acc: 30.47%] [G loss: 0.969680]\n",
      "epoch:3 step:2526[D loss: 0.446023, acc: 67.97%, op_acc: 32.03%] [G loss: 0.904159]\n",
      "epoch:3 step:2527[D loss: 0.491667, acc: 48.44%, op_acc: 28.91%] [G loss: 0.933696]\n",
      "epoch:3 step:2528[D loss: 0.480897, acc: 60.16%, op_acc: 27.34%] [G loss: 0.912844]\n",
      "epoch:3 step:2529[D loss: 0.476663, acc: 53.12%, op_acc: 29.69%] [G loss: 0.910352]\n",
      "epoch:3 step:2530[D loss: 0.462691, acc: 60.16%, op_acc: 29.69%] [G loss: 1.054494]\n",
      "epoch:3 step:2531[D loss: 0.471646, acc: 55.47%, op_acc: 33.59%] [G loss: 1.051599]\n",
      "epoch:3 step:2532[D loss: 0.465231, acc: 60.94%, op_acc: 29.69%] [G loss: 0.979377]\n",
      "epoch:3 step:2533[D loss: 0.464073, acc: 60.16%, op_acc: 32.03%] [G loss: 0.918204]\n",
      "epoch:3 step:2534[D loss: 0.415950, acc: 65.62%, op_acc: 34.38%] [G loss: 0.922666]\n",
      "epoch:3 step:2535[D loss: 0.471499, acc: 57.03%, op_acc: 30.47%] [G loss: 0.884610]\n",
      "epoch:3 step:2536[D loss: 0.465853, acc: 58.59%, op_acc: 28.91%] [G loss: 0.940013]\n",
      "epoch:3 step:2537[D loss: 0.506807, acc: 48.44%, op_acc: 34.38%] [G loss: 0.907617]\n",
      "epoch:3 step:2538[D loss: 0.485744, acc: 53.91%, op_acc: 28.91%] [G loss: 0.890166]\n",
      "epoch:3 step:2539[D loss: 0.506837, acc: 52.34%, op_acc: 25.00%] [G loss: 0.813976]\n",
      "epoch:3 step:2540[D loss: 0.474620, acc: 55.47%, op_acc: 29.69%] [G loss: 0.938173]\n",
      "epoch:3 step:2541[D loss: 0.468145, acc: 58.59%, op_acc: 32.81%] [G loss: 0.998453]\n",
      "epoch:3 step:2542[D loss: 0.455171, acc: 64.84%, op_acc: 28.12%] [G loss: 0.931805]\n",
      "epoch:3 step:2543[D loss: 0.494979, acc: 56.25%, op_acc: 22.66%] [G loss: 0.948402]\n",
      "epoch:3 step:2544[D loss: 0.469815, acc: 53.91%, op_acc: 35.16%] [G loss: 0.980247]\n",
      "epoch:3 step:2545[D loss: 0.495755, acc: 60.16%, op_acc: 26.56%] [G loss: 0.970777]\n",
      "epoch:3 step:2546[D loss: 0.467319, acc: 63.28%, op_acc: 28.12%] [G loss: 0.996420]\n",
      "epoch:3 step:2547[D loss: 0.459711, acc: 64.06%, op_acc: 31.25%] [G loss: 1.010138]\n",
      "epoch:3 step:2548[D loss: 0.463474, acc: 62.50%, op_acc: 24.22%] [G loss: 1.022431]\n",
      "epoch:3 step:2549[D loss: 0.474858, acc: 57.81%, op_acc: 29.69%] [G loss: 1.054638]\n",
      "epoch:3 step:2550[D loss: 0.452452, acc: 64.06%, op_acc: 28.91%] [G loss: 1.046192]\n",
      "##############\n",
      "[0.84750784 0.87641591 0.80605403 0.81946127 0.77218055 0.83078089\n",
      " 0.85091042 0.82682317 0.83430739 0.82372215]\n",
      "##########\n",
      "epoch:3 step:2551[D loss: 0.462335, acc: 63.28%, op_acc: 31.25%] [G loss: 0.910779]\n",
      "epoch:3 step:2552[D loss: 0.487612, acc: 50.00%, op_acc: 29.69%] [G loss: 0.899170]\n",
      "epoch:3 step:2553[D loss: 0.459051, acc: 64.84%, op_acc: 27.34%] [G loss: 0.996873]\n",
      "epoch:3 step:2554[D loss: 0.444375, acc: 62.50%, op_acc: 33.59%] [G loss: 0.982254]\n",
      "epoch:3 step:2555[D loss: 0.471783, acc: 60.94%, op_acc: 25.00%] [G loss: 0.871353]\n",
      "epoch:3 step:2556[D loss: 0.465347, acc: 54.69%, op_acc: 36.72%] [G loss: 0.955504]\n",
      "epoch:3 step:2557[D loss: 0.466336, acc: 59.38%, op_acc: 32.03%] [G loss: 0.977046]\n",
      "epoch:3 step:2558[D loss: 0.494531, acc: 50.00%, op_acc: 30.47%] [G loss: 0.945602]\n",
      "epoch:3 step:2559[D loss: 0.478055, acc: 57.03%, op_acc: 28.91%] [G loss: 1.003594]\n",
      "epoch:3 step:2560[D loss: 0.469336, acc: 58.59%, op_acc: 30.47%] [G loss: 0.926756]\n",
      "epoch:3 step:2561[D loss: 0.436349, acc: 69.53%, op_acc: 30.47%] [G loss: 1.076418]\n",
      "epoch:3 step:2562[D loss: 0.477957, acc: 61.72%, op_acc: 28.12%] [G loss: 0.927876]\n",
      "epoch:3 step:2563[D loss: 0.456320, acc: 62.50%, op_acc: 28.12%] [G loss: 0.992395]\n",
      "epoch:3 step:2564[D loss: 0.473435, acc: 60.16%, op_acc: 26.56%] [G loss: 0.956884]\n",
      "epoch:3 step:2565[D loss: 0.464778, acc: 64.84%, op_acc: 25.78%] [G loss: 0.986051]\n",
      "epoch:3 step:2566[D loss: 0.470590, acc: 57.81%, op_acc: 26.56%] [G loss: 1.026514]\n",
      "epoch:3 step:2567[D loss: 0.467327, acc: 56.25%, op_acc: 29.69%] [G loss: 1.055048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2568[D loss: 0.456568, acc: 61.72%, op_acc: 26.56%] [G loss: 0.953366]\n",
      "epoch:3 step:2569[D loss: 0.441612, acc: 64.84%, op_acc: 39.06%] [G loss: 0.973717]\n",
      "epoch:3 step:2570[D loss: 0.448753, acc: 64.84%, op_acc: 28.91%] [G loss: 0.959054]\n",
      "epoch:3 step:2571[D loss: 0.452111, acc: 60.16%, op_acc: 31.25%] [G loss: 0.897925]\n",
      "epoch:3 step:2572[D loss: 0.440987, acc: 67.97%, op_acc: 31.25%] [G loss: 0.931953]\n",
      "epoch:3 step:2573[D loss: 0.479318, acc: 58.59%, op_acc: 25.78%] [G loss: 0.844723]\n",
      "epoch:3 step:2574[D loss: 0.432768, acc: 64.06%, op_acc: 33.59%] [G loss: 0.927495]\n",
      "epoch:3 step:2575[D loss: 0.476604, acc: 55.47%, op_acc: 24.22%] [G loss: 0.942562]\n",
      "epoch:3 step:2576[D loss: 0.463962, acc: 59.38%, op_acc: 29.69%] [G loss: 0.977502]\n",
      "epoch:3 step:2577[D loss: 0.461738, acc: 60.94%, op_acc: 29.69%] [G loss: 1.082897]\n",
      "epoch:3 step:2578[D loss: 0.480759, acc: 55.47%, op_acc: 33.59%] [G loss: 0.908004]\n",
      "epoch:3 step:2579[D loss: 0.451299, acc: 68.75%, op_acc: 28.12%] [G loss: 1.101143]\n",
      "epoch:3 step:2580[D loss: 0.482943, acc: 55.47%, op_acc: 30.47%] [G loss: 0.938012]\n",
      "epoch:3 step:2581[D loss: 0.489318, acc: 51.56%, op_acc: 34.38%] [G loss: 0.942877]\n",
      "epoch:3 step:2582[D loss: 0.468718, acc: 60.94%, op_acc: 30.47%] [G loss: 0.979457]\n",
      "epoch:3 step:2583[D loss: 0.439868, acc: 60.16%, op_acc: 29.69%] [G loss: 0.992030]\n",
      "epoch:3 step:2584[D loss: 0.432841, acc: 64.84%, op_acc: 32.81%] [G loss: 0.918663]\n",
      "epoch:3 step:2585[D loss: 0.459662, acc: 58.59%, op_acc: 30.47%] [G loss: 0.982773]\n",
      "epoch:3 step:2586[D loss: 0.497433, acc: 53.91%, op_acc: 33.59%] [G loss: 0.892445]\n",
      "epoch:3 step:2587[D loss: 0.470641, acc: 61.72%, op_acc: 27.34%] [G loss: 0.879086]\n",
      "epoch:3 step:2588[D loss: 0.499108, acc: 54.69%, op_acc: 30.47%] [G loss: 0.835216]\n",
      "epoch:3 step:2589[D loss: 0.458701, acc: 65.62%, op_acc: 32.03%] [G loss: 0.945523]\n",
      "epoch:3 step:2590[D loss: 0.458952, acc: 59.38%, op_acc: 35.16%] [G loss: 0.989421]\n",
      "epoch:3 step:2591[D loss: 0.462919, acc: 57.03%, op_acc: 26.56%] [G loss: 0.940629]\n",
      "epoch:3 step:2592[D loss: 0.486289, acc: 59.38%, op_acc: 28.12%] [G loss: 1.014691]\n",
      "epoch:3 step:2593[D loss: 0.468440, acc: 58.59%, op_acc: 27.34%] [G loss: 1.035810]\n",
      "epoch:3 step:2594[D loss: 0.440319, acc: 60.94%, op_acc: 32.03%] [G loss: 0.971881]\n",
      "epoch:3 step:2595[D loss: 0.449010, acc: 61.72%, op_acc: 30.47%] [G loss: 0.985538]\n",
      "epoch:3 step:2596[D loss: 0.436595, acc: 68.75%, op_acc: 32.81%] [G loss: 0.933591]\n",
      "epoch:3 step:2597[D loss: 0.468248, acc: 59.38%, op_acc: 31.25%] [G loss: 0.925452]\n",
      "epoch:3 step:2598[D loss: 0.471667, acc: 54.69%, op_acc: 32.03%] [G loss: 0.859291]\n",
      "epoch:3 step:2599[D loss: 0.490890, acc: 54.69%, op_acc: 28.12%] [G loss: 0.852843]\n",
      "epoch:3 step:2600[D loss: 0.513062, acc: 50.00%, op_acc: 29.69%] [G loss: 0.903160]\n",
      "##############\n",
      "[0.85804377 0.87371984 0.79293807 0.80416242 0.78577903 0.81892062\n",
      " 0.87004756 0.81170709 0.81787402 0.82915473]\n",
      "##########\n",
      "epoch:3 step:2601[D loss: 0.413753, acc: 67.97%, op_acc: 35.16%] [G loss: 0.925627]\n",
      "epoch:3 step:2602[D loss: 0.477192, acc: 57.03%, op_acc: 27.34%] [G loss: 0.909973]\n",
      "epoch:3 step:2603[D loss: 0.467963, acc: 57.81%, op_acc: 32.81%] [G loss: 0.961858]\n",
      "epoch:3 step:2604[D loss: 0.446715, acc: 59.38%, op_acc: 30.47%] [G loss: 0.964706]\n",
      "epoch:3 step:2605[D loss: 0.417906, acc: 65.62%, op_acc: 31.25%] [G loss: 0.908970]\n",
      "epoch:3 step:2606[D loss: 0.460600, acc: 58.59%, op_acc: 30.47%] [G loss: 0.944526]\n",
      "epoch:3 step:2607[D loss: 0.449717, acc: 64.06%, op_acc: 28.91%] [G loss: 0.966699]\n",
      "epoch:3 step:2608[D loss: 0.443210, acc: 57.81%, op_acc: 39.06%] [G loss: 0.961311]\n",
      "epoch:3 step:2609[D loss: 0.445717, acc: 59.38%, op_acc: 34.38%] [G loss: 0.943084]\n",
      "epoch:3 step:2610[D loss: 0.463910, acc: 56.25%, op_acc: 35.16%] [G loss: 0.846636]\n",
      "epoch:3 step:2611[D loss: 0.445708, acc: 56.25%, op_acc: 34.38%] [G loss: 0.920846]\n",
      "epoch:3 step:2612[D loss: 0.446576, acc: 57.81%, op_acc: 39.84%] [G loss: 0.931587]\n",
      "epoch:3 step:2613[D loss: 0.481898, acc: 54.69%, op_acc: 29.69%] [G loss: 0.912765]\n",
      "epoch:3 step:2614[D loss: 0.457554, acc: 62.50%, op_acc: 29.69%] [G loss: 0.980022]\n",
      "epoch:3 step:2615[D loss: 0.461532, acc: 60.94%, op_acc: 32.03%] [G loss: 0.899285]\n",
      "epoch:3 step:2616[D loss: 0.433596, acc: 61.72%, op_acc: 34.38%] [G loss: 0.943955]\n",
      "epoch:3 step:2617[D loss: 0.424178, acc: 67.19%, op_acc: 34.38%] [G loss: 0.944120]\n",
      "epoch:3 step:2618[D loss: 0.439215, acc: 67.97%, op_acc: 32.81%] [G loss: 0.973802]\n",
      "epoch:3 step:2619[D loss: 0.453016, acc: 64.84%, op_acc: 29.69%] [G loss: 0.924019]\n",
      "epoch:3 step:2620[D loss: 0.476667, acc: 61.72%, op_acc: 25.00%] [G loss: 0.961319]\n",
      "epoch:3 step:2621[D loss: 0.477363, acc: 54.69%, op_acc: 37.50%] [G loss: 0.899331]\n",
      "epoch:3 step:2622[D loss: 0.432825, acc: 63.28%, op_acc: 38.28%] [G loss: 1.030383]\n",
      "epoch:3 step:2623[D loss: 0.461670, acc: 55.47%, op_acc: 35.94%] [G loss: 0.990553]\n",
      "epoch:3 step:2624[D loss: 0.481546, acc: 56.25%, op_acc: 35.16%] [G loss: 0.882132]\n",
      "epoch:3 step:2625[D loss: 0.476039, acc: 57.03%, op_acc: 28.12%] [G loss: 0.863650]\n",
      "epoch:3 step:2626[D loss: 0.471011, acc: 47.66%, op_acc: 32.81%] [G loss: 0.840498]\n",
      "epoch:3 step:2627[D loss: 0.462728, acc: 62.50%, op_acc: 25.00%] [G loss: 0.947987]\n",
      "epoch:3 step:2628[D loss: 0.478467, acc: 52.34%, op_acc: 29.69%] [G loss: 0.911903]\n",
      "epoch:3 step:2629[D loss: 0.444983, acc: 64.06%, op_acc: 25.78%] [G loss: 0.994805]\n",
      "epoch:3 step:2630[D loss: 0.484034, acc: 53.12%, op_acc: 26.56%] [G loss: 0.948346]\n",
      "epoch:3 step:2631[D loss: 0.474865, acc: 57.81%, op_acc: 31.25%] [G loss: 0.984242]\n",
      "epoch:3 step:2632[D loss: 0.478786, acc: 63.28%, op_acc: 28.12%] [G loss: 0.834398]\n",
      "epoch:3 step:2633[D loss: 0.473187, acc: 59.38%, op_acc: 32.03%] [G loss: 1.026795]\n",
      "epoch:3 step:2634[D loss: 0.461130, acc: 55.47%, op_acc: 35.16%] [G loss: 0.979893]\n",
      "epoch:3 step:2635[D loss: 0.484087, acc: 50.00%, op_acc: 32.03%] [G loss: 0.969078]\n",
      "epoch:3 step:2636[D loss: 0.460907, acc: 57.03%, op_acc: 32.81%] [G loss: 0.963308]\n",
      "epoch:3 step:2637[D loss: 0.422923, acc: 74.22%, op_acc: 34.38%] [G loss: 1.033994]\n",
      "epoch:3 step:2638[D loss: 0.465823, acc: 62.50%, op_acc: 29.69%] [G loss: 0.921828]\n",
      "epoch:3 step:2639[D loss: 0.439308, acc: 63.28%, op_acc: 33.59%] [G loss: 1.004405]\n",
      "epoch:3 step:2640[D loss: 0.498278, acc: 54.69%, op_acc: 24.22%] [G loss: 0.886970]\n",
      "epoch:3 step:2641[D loss: 0.441645, acc: 64.06%, op_acc: 31.25%] [G loss: 0.962936]\n",
      "epoch:3 step:2642[D loss: 0.459438, acc: 57.81%, op_acc: 28.91%] [G loss: 0.957141]\n",
      "epoch:3 step:2643[D loss: 0.459984, acc: 57.81%, op_acc: 28.91%] [G loss: 0.939246]\n",
      "epoch:3 step:2644[D loss: 0.498319, acc: 50.78%, op_acc: 23.44%] [G loss: 0.863483]\n",
      "epoch:3 step:2645[D loss: 0.475825, acc: 57.81%, op_acc: 29.69%] [G loss: 0.962156]\n",
      "epoch:3 step:2646[D loss: 0.464873, acc: 59.38%, op_acc: 35.94%] [G loss: 0.915587]\n",
      "epoch:3 step:2647[D loss: 0.452253, acc: 60.94%, op_acc: 31.25%] [G loss: 0.920671]\n",
      "epoch:3 step:2648[D loss: 0.452343, acc: 66.41%, op_acc: 30.47%] [G loss: 1.003471]\n",
      "epoch:3 step:2649[D loss: 0.485631, acc: 56.25%, op_acc: 25.00%] [G loss: 0.913042]\n",
      "epoch:3 step:2650[D loss: 0.455248, acc: 60.16%, op_acc: 31.25%] [G loss: 0.890735]\n",
      "##############\n",
      "[0.8652218  0.87034661 0.80459565 0.82181761 0.79631723 0.83847752\n",
      " 0.87216268 0.81854397 0.81429866 0.83304716]\n",
      "##########\n",
      "epoch:3 step:2651[D loss: 0.472002, acc: 59.38%, op_acc: 26.56%] [G loss: 0.982329]\n",
      "epoch:3 step:2652[D loss: 0.454274, acc: 65.62%, op_acc: 21.09%] [G loss: 0.962152]\n",
      "epoch:3 step:2653[D loss: 0.463728, acc: 57.03%, op_acc: 27.34%] [G loss: 0.855165]\n",
      "epoch:3 step:2654[D loss: 0.473021, acc: 52.34%, op_acc: 32.03%] [G loss: 0.938819]\n",
      "epoch:3 step:2655[D loss: 0.448115, acc: 57.03%, op_acc: 30.47%] [G loss: 0.914607]\n",
      "epoch:3 step:2656[D loss: 0.464755, acc: 61.72%, op_acc: 32.81%] [G loss: 0.874367]\n",
      "epoch:3 step:2657[D loss: 0.446180, acc: 64.06%, op_acc: 25.78%] [G loss: 0.967142]\n",
      "epoch:3 step:2658[D loss: 0.483487, acc: 53.91%, op_acc: 28.12%] [G loss: 0.887264]\n",
      "epoch:3 step:2659[D loss: 0.480309, acc: 57.03%, op_acc: 25.00%] [G loss: 0.868113]\n",
      "epoch:3 step:2660[D loss: 0.458141, acc: 55.47%, op_acc: 33.59%] [G loss: 0.932536]\n",
      "epoch:3 step:2661[D loss: 0.459142, acc: 55.47%, op_acc: 26.56%] [G loss: 0.896418]\n",
      "epoch:3 step:2662[D loss: 0.459167, acc: 60.16%, op_acc: 30.47%] [G loss: 0.986837]\n",
      "epoch:3 step:2663[D loss: 0.445349, acc: 57.03%, op_acc: 28.91%] [G loss: 0.876958]\n",
      "epoch:3 step:2664[D loss: 0.479004, acc: 58.59%, op_acc: 28.12%] [G loss: 0.991717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2665[D loss: 0.472962, acc: 60.94%, op_acc: 27.34%] [G loss: 0.981061]\n",
      "epoch:3 step:2666[D loss: 0.464769, acc: 53.12%, op_acc: 32.03%] [G loss: 0.888893]\n",
      "epoch:3 step:2667[D loss: 0.447303, acc: 61.72%, op_acc: 27.34%] [G loss: 0.890960]\n",
      "epoch:3 step:2668[D loss: 0.433054, acc: 62.50%, op_acc: 32.03%] [G loss: 1.020715]\n",
      "epoch:3 step:2669[D loss: 0.440854, acc: 62.50%, op_acc: 29.69%] [G loss: 1.019279]\n",
      "epoch:3 step:2670[D loss: 0.448162, acc: 60.94%, op_acc: 32.03%] [G loss: 0.891861]\n",
      "epoch:3 step:2671[D loss: 0.444207, acc: 64.84%, op_acc: 32.03%] [G loss: 0.919552]\n",
      "epoch:3 step:2672[D loss: 0.443961, acc: 59.38%, op_acc: 28.91%] [G loss: 0.905284]\n",
      "epoch:3 step:2673[D loss: 0.455376, acc: 58.59%, op_acc: 32.81%] [G loss: 0.852123]\n",
      "epoch:3 step:2674[D loss: 0.465662, acc: 60.94%, op_acc: 30.47%] [G loss: 0.937136]\n",
      "epoch:3 step:2675[D loss: 0.433086, acc: 70.31%, op_acc: 29.69%] [G loss: 0.986871]\n",
      "epoch:3 step:2676[D loss: 0.463724, acc: 58.59%, op_acc: 30.47%] [G loss: 0.969049]\n",
      "epoch:3 step:2677[D loss: 0.462789, acc: 60.16%, op_acc: 26.56%] [G loss: 0.954860]\n",
      "epoch:3 step:2678[D loss: 0.493919, acc: 53.91%, op_acc: 31.25%] [G loss: 0.946779]\n",
      "epoch:3 step:2679[D loss: 0.518646, acc: 49.22%, op_acc: 25.00%] [G loss: 0.888695]\n",
      "epoch:3 step:2680[D loss: 0.494867, acc: 54.69%, op_acc: 32.81%] [G loss: 0.963142]\n",
      "epoch:3 step:2681[D loss: 0.473953, acc: 51.56%, op_acc: 36.72%] [G loss: 0.937689]\n",
      "epoch:3 step:2682[D loss: 0.472699, acc: 53.12%, op_acc: 35.94%] [G loss: 0.850466]\n",
      "epoch:3 step:2683[D loss: 0.463627, acc: 56.25%, op_acc: 31.25%] [G loss: 0.858100]\n",
      "epoch:3 step:2684[D loss: 0.491542, acc: 54.69%, op_acc: 28.91%] [G loss: 0.913504]\n",
      "epoch:3 step:2685[D loss: 0.481486, acc: 53.12%, op_acc: 28.91%] [G loss: 0.811205]\n",
      "epoch:3 step:2686[D loss: 0.455373, acc: 60.16%, op_acc: 28.12%] [G loss: 0.925591]\n",
      "epoch:3 step:2687[D loss: 0.440049, acc: 64.84%, op_acc: 28.12%] [G loss: 0.903023]\n",
      "epoch:3 step:2688[D loss: 0.497576, acc: 60.16%, op_acc: 31.25%] [G loss: 0.941247]\n",
      "epoch:3 step:2689[D loss: 0.417238, acc: 67.97%, op_acc: 31.25%] [G loss: 0.921418]\n",
      "epoch:3 step:2690[D loss: 0.478759, acc: 58.59%, op_acc: 32.03%] [G loss: 0.925693]\n",
      "epoch:3 step:2691[D loss: 0.429145, acc: 64.84%, op_acc: 32.81%] [G loss: 0.940655]\n",
      "epoch:3 step:2692[D loss: 0.444899, acc: 62.50%, op_acc: 34.38%] [G loss: 1.019090]\n",
      "epoch:3 step:2693[D loss: 0.470355, acc: 57.81%, op_acc: 35.16%] [G loss: 1.055952]\n",
      "epoch:3 step:2694[D loss: 0.435295, acc: 57.03%, op_acc: 32.81%] [G loss: 0.946710]\n",
      "epoch:3 step:2695[D loss: 0.503050, acc: 53.12%, op_acc: 28.12%] [G loss: 0.929435]\n",
      "epoch:3 step:2696[D loss: 0.447501, acc: 57.03%, op_acc: 37.50%] [G loss: 0.913419]\n",
      "epoch:3 step:2697[D loss: 0.488967, acc: 55.47%, op_acc: 31.25%] [G loss: 0.949803]\n",
      "epoch:3 step:2698[D loss: 0.442386, acc: 61.72%, op_acc: 32.03%] [G loss: 0.898387]\n",
      "epoch:3 step:2699[D loss: 0.432348, acc: 68.75%, op_acc: 34.38%] [G loss: 0.961301]\n",
      "epoch:3 step:2700[D loss: 0.463583, acc: 64.06%, op_acc: 31.25%] [G loss: 0.905834]\n",
      "##############\n",
      "[0.87130771 0.85248159 0.79951489 0.78862578 0.76946699 0.83297834\n",
      " 0.86481484 0.83294594 0.80549443 0.81887601]\n",
      "##########\n",
      "epoch:3 step:2701[D loss: 0.477172, acc: 56.25%, op_acc: 28.12%] [G loss: 1.009267]\n",
      "epoch:3 step:2702[D loss: 0.474681, acc: 56.25%, op_acc: 35.16%] [G loss: 0.904955]\n",
      "epoch:3 step:2703[D loss: 0.430873, acc: 71.88%, op_acc: 26.56%] [G loss: 0.953570]\n",
      "epoch:3 step:2704[D loss: 0.445851, acc: 64.06%, op_acc: 34.38%] [G loss: 0.901616]\n",
      "epoch:3 step:2705[D loss: 0.442286, acc: 52.34%, op_acc: 33.59%] [G loss: 0.928415]\n",
      "epoch:3 step:2706[D loss: 0.456045, acc: 64.84%, op_acc: 28.12%] [G loss: 0.929255]\n",
      "epoch:3 step:2707[D loss: 0.455508, acc: 64.06%, op_acc: 37.50%] [G loss: 1.021487]\n",
      "epoch:3 step:2708[D loss: 0.423343, acc: 59.38%, op_acc: 34.38%] [G loss: 0.962647]\n",
      "epoch:3 step:2709[D loss: 0.427821, acc: 60.94%, op_acc: 38.28%] [G loss: 0.941855]\n",
      "epoch:3 step:2710[D loss: 0.461861, acc: 64.06%, op_acc: 23.44%] [G loss: 1.048464]\n",
      "epoch:3 step:2711[D loss: 0.451357, acc: 64.84%, op_acc: 31.25%] [G loss: 0.988381]\n",
      "epoch:3 step:2712[D loss: 0.462960, acc: 62.50%, op_acc: 30.47%] [G loss: 0.991739]\n",
      "epoch:3 step:2713[D loss: 0.446180, acc: 61.72%, op_acc: 29.69%] [G loss: 0.939736]\n",
      "epoch:3 step:2714[D loss: 0.408961, acc: 66.41%, op_acc: 41.41%] [G loss: 0.965815]\n",
      "epoch:3 step:2715[D loss: 0.463263, acc: 58.59%, op_acc: 27.34%] [G loss: 0.975884]\n",
      "epoch:3 step:2716[D loss: 0.475075, acc: 56.25%, op_acc: 32.81%] [G loss: 0.906677]\n",
      "epoch:3 step:2717[D loss: 0.440392, acc: 64.84%, op_acc: 32.81%] [G loss: 0.902145]\n",
      "epoch:3 step:2718[D loss: 0.465490, acc: 60.16%, op_acc: 25.00%] [G loss: 1.015199]\n",
      "epoch:3 step:2719[D loss: 0.467632, acc: 61.72%, op_acc: 31.25%] [G loss: 0.848084]\n",
      "epoch:3 step:2720[D loss: 0.465033, acc: 60.94%, op_acc: 25.78%] [G loss: 0.964830]\n",
      "epoch:3 step:2721[D loss: 0.434358, acc: 63.28%, op_acc: 35.94%] [G loss: 0.962747]\n",
      "epoch:3 step:2722[D loss: 0.434317, acc: 62.50%, op_acc: 36.72%] [G loss: 0.935432]\n",
      "epoch:3 step:2723[D loss: 0.470152, acc: 60.16%, op_acc: 30.47%] [G loss: 0.909335]\n",
      "epoch:3 step:2724[D loss: 0.486141, acc: 57.81%, op_acc: 27.34%] [G loss: 0.842977]\n",
      "epoch:3 step:2725[D loss: 0.471252, acc: 58.59%, op_acc: 25.78%] [G loss: 0.862161]\n",
      "epoch:3 step:2726[D loss: 0.456814, acc: 59.38%, op_acc: 32.81%] [G loss: 1.042111]\n",
      "epoch:3 step:2727[D loss: 0.457933, acc: 59.38%, op_acc: 34.38%] [G loss: 1.033055]\n",
      "epoch:3 step:2728[D loss: 0.463451, acc: 53.12%, op_acc: 28.12%] [G loss: 0.965761]\n",
      "epoch:3 step:2729[D loss: 0.462552, acc: 58.59%, op_acc: 31.25%] [G loss: 0.964898]\n",
      "epoch:3 step:2730[D loss: 0.462079, acc: 58.59%, op_acc: 30.47%] [G loss: 1.065985]\n",
      "epoch:3 step:2731[D loss: 0.492270, acc: 48.44%, op_acc: 28.91%] [G loss: 0.949606]\n",
      "epoch:3 step:2732[D loss: 0.453904, acc: 66.41%, op_acc: 32.03%] [G loss: 0.950479]\n",
      "epoch:3 step:2733[D loss: 0.435185, acc: 65.62%, op_acc: 35.94%] [G loss: 0.869894]\n",
      "epoch:3 step:2734[D loss: 0.448886, acc: 58.59%, op_acc: 28.91%] [G loss: 0.881392]\n",
      "epoch:3 step:2735[D loss: 0.420946, acc: 59.38%, op_acc: 35.16%] [G loss: 0.910308]\n",
      "epoch:3 step:2736[D loss: 0.441049, acc: 62.50%, op_acc: 32.03%] [G loss: 0.917663]\n",
      "epoch:3 step:2737[D loss: 0.449467, acc: 64.06%, op_acc: 30.47%] [G loss: 0.968664]\n",
      "epoch:3 step:2738[D loss: 0.479456, acc: 60.16%, op_acc: 27.34%] [G loss: 1.003927]\n",
      "epoch:3 step:2739[D loss: 0.445318, acc: 58.59%, op_acc: 32.03%] [G loss: 0.909013]\n",
      "epoch:3 step:2740[D loss: 0.436161, acc: 63.28%, op_acc: 32.03%] [G loss: 1.013606]\n",
      "epoch:3 step:2741[D loss: 0.485392, acc: 58.59%, op_acc: 28.91%] [G loss: 0.923938]\n",
      "epoch:3 step:2742[D loss: 0.455599, acc: 54.69%, op_acc: 36.72%] [G loss: 0.866548]\n",
      "epoch:3 step:2743[D loss: 0.432956, acc: 65.62%, op_acc: 28.91%] [G loss: 0.942027]\n",
      "epoch:3 step:2744[D loss: 0.436251, acc: 64.84%, op_acc: 32.81%] [G loss: 0.920101]\n",
      "epoch:3 step:2745[D loss: 0.472593, acc: 53.91%, op_acc: 28.91%] [G loss: 0.937032]\n",
      "epoch:3 step:2746[D loss: 0.470187, acc: 58.59%, op_acc: 27.34%] [G loss: 0.914809]\n",
      "epoch:3 step:2747[D loss: 0.430565, acc: 67.19%, op_acc: 35.16%] [G loss: 0.932612]\n",
      "epoch:3 step:2748[D loss: 0.484327, acc: 56.25%, op_acc: 28.12%] [G loss: 0.893030]\n",
      "epoch:3 step:2749[D loss: 0.467748, acc: 57.03%, op_acc: 32.81%] [G loss: 0.921300]\n",
      "epoch:3 step:2750[D loss: 0.461572, acc: 63.28%, op_acc: 28.12%] [G loss: 0.988873]\n",
      "##############\n",
      "[0.86464993 0.85377798 0.8213675  0.79578421 0.80608091 0.82353222\n",
      " 0.8849896  0.83081371 0.80661675 0.83492336]\n",
      "##########\n",
      "epoch:3 step:2751[D loss: 0.466065, acc: 52.34%, op_acc: 39.06%] [G loss: 0.929443]\n",
      "epoch:3 step:2752[D loss: 0.447777, acc: 66.41%, op_acc: 31.25%] [G loss: 0.964584]\n",
      "epoch:3 step:2753[D loss: 0.442522, acc: 64.06%, op_acc: 28.12%] [G loss: 0.896180]\n",
      "epoch:3 step:2754[D loss: 0.474253, acc: 64.06%, op_acc: 31.25%] [G loss: 0.958757]\n",
      "epoch:3 step:2755[D loss: 0.436485, acc: 64.06%, op_acc: 33.59%] [G loss: 1.025491]\n",
      "epoch:3 step:2756[D loss: 0.479753, acc: 55.47%, op_acc: 30.47%] [G loss: 0.981471]\n",
      "epoch:3 step:2757[D loss: 0.467235, acc: 56.25%, op_acc: 28.91%] [G loss: 1.098157]\n",
      "epoch:3 step:2758[D loss: 0.450280, acc: 64.06%, op_acc: 27.34%] [G loss: 0.908168]\n",
      "epoch:3 step:2759[D loss: 0.483929, acc: 53.91%, op_acc: 25.78%] [G loss: 0.972009]\n",
      "epoch:3 step:2760[D loss: 0.448096, acc: 63.28%, op_acc: 31.25%] [G loss: 0.928119]\n",
      "epoch:3 step:2761[D loss: 0.428685, acc: 67.19%, op_acc: 29.69%] [G loss: 1.052198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2762[D loss: 0.486317, acc: 58.59%, op_acc: 28.91%] [G loss: 0.998106]\n",
      "epoch:3 step:2763[D loss: 0.453078, acc: 64.06%, op_acc: 32.03%] [G loss: 0.939740]\n",
      "epoch:3 step:2764[D loss: 0.448819, acc: 67.19%, op_acc: 28.12%] [G loss: 0.961483]\n",
      "epoch:3 step:2765[D loss: 0.445825, acc: 61.72%, op_acc: 35.16%] [G loss: 0.903735]\n",
      "epoch:3 step:2766[D loss: 0.465761, acc: 64.84%, op_acc: 32.03%] [G loss: 1.023899]\n",
      "epoch:3 step:2767[D loss: 0.456981, acc: 61.72%, op_acc: 29.69%] [G loss: 0.906725]\n",
      "epoch:3 step:2768[D loss: 0.470643, acc: 64.84%, op_acc: 26.56%] [G loss: 0.941916]\n",
      "epoch:3 step:2769[D loss: 0.496612, acc: 51.56%, op_acc: 28.91%] [G loss: 0.950038]\n",
      "epoch:3 step:2770[D loss: 0.458009, acc: 64.06%, op_acc: 26.56%] [G loss: 1.061491]\n",
      "epoch:3 step:2771[D loss: 0.486434, acc: 57.81%, op_acc: 33.59%] [G loss: 0.995371]\n",
      "epoch:3 step:2772[D loss: 0.457403, acc: 60.16%, op_acc: 32.81%] [G loss: 0.884659]\n",
      "epoch:3 step:2773[D loss: 0.436610, acc: 61.72%, op_acc: 31.25%] [G loss: 0.969895]\n",
      "epoch:3 step:2774[D loss: 0.454811, acc: 62.50%, op_acc: 30.47%] [G loss: 0.932957]\n",
      "epoch:3 step:2775[D loss: 0.421889, acc: 71.09%, op_acc: 28.12%] [G loss: 0.915561]\n",
      "epoch:3 step:2776[D loss: 0.450162, acc: 64.84%, op_acc: 33.59%] [G loss: 1.014760]\n",
      "epoch:3 step:2777[D loss: 0.495626, acc: 50.78%, op_acc: 29.69%] [G loss: 0.908102]\n",
      "epoch:3 step:2778[D loss: 0.483911, acc: 53.12%, op_acc: 35.16%] [G loss: 0.830648]\n",
      "epoch:3 step:2779[D loss: 0.487857, acc: 53.91%, op_acc: 30.47%] [G loss: 0.865849]\n",
      "epoch:3 step:2780[D loss: 0.468716, acc: 58.59%, op_acc: 29.69%] [G loss: 0.834550]\n",
      "epoch:3 step:2781[D loss: 0.436920, acc: 59.38%, op_acc: 29.69%] [G loss: 0.970323]\n",
      "epoch:3 step:2782[D loss: 0.440988, acc: 60.94%, op_acc: 30.47%] [G loss: 0.938867]\n",
      "epoch:3 step:2783[D loss: 0.431727, acc: 67.19%, op_acc: 35.94%] [G loss: 0.967940]\n",
      "epoch:3 step:2784[D loss: 0.483423, acc: 54.69%, op_acc: 27.34%] [G loss: 0.883719]\n",
      "epoch:3 step:2785[D loss: 0.446715, acc: 61.72%, op_acc: 39.06%] [G loss: 0.926674]\n",
      "epoch:3 step:2786[D loss: 0.453514, acc: 64.06%, op_acc: 31.25%] [G loss: 0.894705]\n",
      "epoch:3 step:2787[D loss: 0.450938, acc: 62.50%, op_acc: 34.38%] [G loss: 0.863629]\n",
      "epoch:3 step:2788[D loss: 0.458375, acc: 64.84%, op_acc: 25.78%] [G loss: 0.934370]\n",
      "epoch:3 step:2789[D loss: 0.447397, acc: 60.94%, op_acc: 30.47%] [G loss: 0.892637]\n",
      "epoch:3 step:2790[D loss: 0.468517, acc: 58.59%, op_acc: 26.56%] [G loss: 0.894566]\n",
      "epoch:3 step:2791[D loss: 0.456119, acc: 54.69%, op_acc: 28.12%] [G loss: 0.909736]\n",
      "epoch:3 step:2792[D loss: 0.471840, acc: 54.69%, op_acc: 28.91%] [G loss: 0.869991]\n",
      "epoch:3 step:2793[D loss: 0.442232, acc: 58.59%, op_acc: 26.56%] [G loss: 0.958404]\n",
      "epoch:3 step:2794[D loss: 0.454322, acc: 55.47%, op_acc: 38.28%] [G loss: 0.880330]\n",
      "epoch:3 step:2795[D loss: 0.439854, acc: 61.72%, op_acc: 33.59%] [G loss: 0.943283]\n",
      "epoch:3 step:2796[D loss: 0.482028, acc: 43.75%, op_acc: 36.72%] [G loss: 0.918328]\n",
      "epoch:3 step:2797[D loss: 0.471949, acc: 60.94%, op_acc: 28.12%] [G loss: 1.045091]\n",
      "epoch:3 step:2798[D loss: 0.481525, acc: 61.72%, op_acc: 25.00%] [G loss: 0.884874]\n",
      "epoch:3 step:2799[D loss: 0.449377, acc: 62.50%, op_acc: 26.56%] [G loss: 0.995017]\n",
      "epoch:3 step:2800[D loss: 0.465112, acc: 57.03%, op_acc: 25.00%] [G loss: 0.926931]\n",
      "##############\n",
      "[0.86087241 0.85935261 0.83552002 0.80956525 0.78453562 0.82663006\n",
      " 0.87318835 0.84865944 0.80888721 0.81523247]\n",
      "##########\n",
      "epoch:3 step:2801[D loss: 0.454183, acc: 57.81%, op_acc: 31.25%] [G loss: 0.982499]\n",
      "epoch:3 step:2802[D loss: 0.449814, acc: 57.03%, op_acc: 30.47%] [G loss: 0.992244]\n",
      "epoch:3 step:2803[D loss: 0.480084, acc: 51.56%, op_acc: 28.91%] [G loss: 0.982911]\n",
      "epoch:3 step:2804[D loss: 0.456925, acc: 63.28%, op_acc: 25.78%] [G loss: 1.012694]\n",
      "epoch:3 step:2805[D loss: 0.479001, acc: 56.25%, op_acc: 32.81%] [G loss: 1.028084]\n",
      "epoch:3 step:2806[D loss: 0.463290, acc: 54.69%, op_acc: 31.25%] [G loss: 1.026232]\n",
      "epoch:3 step:2807[D loss: 0.456059, acc: 64.06%, op_acc: 29.69%] [G loss: 0.939707]\n",
      "epoch:3 step:2808[D loss: 0.453629, acc: 63.28%, op_acc: 31.25%] [G loss: 0.932174]\n",
      "epoch:3 step:2809[D loss: 0.469135, acc: 50.78%, op_acc: 31.25%] [G loss: 0.910566]\n",
      "epoch:3 step:2810[D loss: 0.486202, acc: 54.69%, op_acc: 32.81%] [G loss: 0.922645]\n",
      "epoch:3 step:2811[D loss: 0.443736, acc: 65.62%, op_acc: 25.78%] [G loss: 0.945312]\n",
      "epoch:3 step:2812[D loss: 0.437535, acc: 59.38%, op_acc: 31.25%] [G loss: 1.020296]\n",
      "epoch:3 step:2813[D loss: 0.456204, acc: 60.16%, op_acc: 34.38%] [G loss: 0.924031]\n",
      "epoch:3 step:2814[D loss: 0.424967, acc: 66.41%, op_acc: 33.59%] [G loss: 1.034138]\n",
      "epoch:3 step:2815[D loss: 0.445820, acc: 67.97%, op_acc: 31.25%] [G loss: 0.981146]\n",
      "epoch:3 step:2816[D loss: 0.450954, acc: 54.69%, op_acc: 33.59%] [G loss: 0.915652]\n",
      "epoch:3 step:2817[D loss: 0.455899, acc: 64.06%, op_acc: 26.56%] [G loss: 0.971025]\n",
      "epoch:3 step:2818[D loss: 0.417959, acc: 62.50%, op_acc: 39.06%] [G loss: 0.946489]\n",
      "epoch:3 step:2819[D loss: 0.452142, acc: 63.28%, op_acc: 32.03%] [G loss: 0.912466]\n",
      "epoch:3 step:2820[D loss: 0.441194, acc: 66.41%, op_acc: 32.03%] [G loss: 0.948381]\n",
      "epoch:3 step:2821[D loss: 0.446839, acc: 61.72%, op_acc: 36.72%] [G loss: 1.004971]\n",
      "epoch:3 step:2822[D loss: 0.466230, acc: 62.50%, op_acc: 30.47%] [G loss: 0.938132]\n",
      "epoch:3 step:2823[D loss: 0.488486, acc: 54.69%, op_acc: 28.12%] [G loss: 0.940007]\n",
      "epoch:3 step:2824[D loss: 0.473392, acc: 60.16%, op_acc: 27.34%] [G loss: 0.908321]\n",
      "epoch:3 step:2825[D loss: 0.490712, acc: 56.25%, op_acc: 32.03%] [G loss: 0.902530]\n",
      "epoch:3 step:2826[D loss: 0.497386, acc: 49.22%, op_acc: 25.00%] [G loss: 0.931683]\n",
      "epoch:3 step:2827[D loss: 0.458249, acc: 53.91%, op_acc: 32.81%] [G loss: 0.898363]\n",
      "epoch:3 step:2828[D loss: 0.444885, acc: 60.94%, op_acc: 32.03%] [G loss: 0.966877]\n",
      "epoch:3 step:2829[D loss: 0.450348, acc: 58.59%, op_acc: 36.72%] [G loss: 1.026874]\n",
      "epoch:3 step:2830[D loss: 0.458284, acc: 61.72%, op_acc: 31.25%] [G loss: 0.983579]\n",
      "epoch:3 step:2831[D loss: 0.450782, acc: 61.72%, op_acc: 30.47%] [G loss: 0.977293]\n",
      "epoch:3 step:2832[D loss: 0.475610, acc: 48.44%, op_acc: 34.38%] [G loss: 0.884534]\n",
      "epoch:3 step:2833[D loss: 0.435884, acc: 66.41%, op_acc: 34.38%] [G loss: 0.983876]\n",
      "epoch:3 step:2834[D loss: 0.500923, acc: 50.78%, op_acc: 27.34%] [G loss: 0.936703]\n",
      "epoch:3 step:2835[D loss: 0.471278, acc: 54.69%, op_acc: 28.12%] [G loss: 0.892634]\n",
      "epoch:3 step:2836[D loss: 0.481630, acc: 61.72%, op_acc: 28.12%] [G loss: 1.003031]\n",
      "epoch:3 step:2837[D loss: 0.468566, acc: 55.47%, op_acc: 31.25%] [G loss: 0.912013]\n",
      "epoch:3 step:2838[D loss: 0.480821, acc: 61.72%, op_acc: 31.25%] [G loss: 0.936899]\n",
      "epoch:3 step:2839[D loss: 0.478910, acc: 59.38%, op_acc: 26.56%] [G loss: 0.883222]\n",
      "epoch:3 step:2840[D loss: 0.425822, acc: 65.62%, op_acc: 35.94%] [G loss: 0.872441]\n",
      "epoch:3 step:2841[D loss: 0.469398, acc: 64.06%, op_acc: 28.12%] [G loss: 0.872295]\n",
      "epoch:3 step:2842[D loss: 0.440361, acc: 67.97%, op_acc: 30.47%] [G loss: 0.861785]\n",
      "epoch:3 step:2843[D loss: 0.447558, acc: 56.25%, op_acc: 33.59%] [G loss: 0.923326]\n",
      "epoch:3 step:2844[D loss: 0.486722, acc: 56.25%, op_acc: 28.12%] [G loss: 0.939360]\n",
      "epoch:3 step:2845[D loss: 0.469205, acc: 55.47%, op_acc: 34.38%] [G loss: 0.891699]\n",
      "epoch:3 step:2846[D loss: 0.450141, acc: 57.03%, op_acc: 35.94%] [G loss: 1.027790]\n",
      "epoch:3 step:2847[D loss: 0.479828, acc: 54.69%, op_acc: 32.81%] [G loss: 0.894301]\n",
      "epoch:3 step:2848[D loss: 0.433232, acc: 67.19%, op_acc: 32.81%] [G loss: 0.844777]\n",
      "epoch:3 step:2849[D loss: 0.423948, acc: 71.88%, op_acc: 34.38%] [G loss: 0.984534]\n",
      "epoch:3 step:2850[D loss: 0.458732, acc: 60.94%, op_acc: 37.50%] [G loss: 0.870711]\n",
      "##############\n",
      "[0.86960002 0.85028849 0.810393   0.80471242 0.81845185 0.81768151\n",
      " 0.87307697 0.82430227 0.82068114 0.82797014]\n",
      "##########\n",
      "epoch:3 step:2851[D loss: 0.434029, acc: 63.28%, op_acc: 33.59%] [G loss: 0.944242]\n",
      "epoch:3 step:2852[D loss: 0.464954, acc: 60.16%, op_acc: 34.38%] [G loss: 0.912799]\n",
      "epoch:3 step:2853[D loss: 0.418842, acc: 65.62%, op_acc: 30.47%] [G loss: 0.943506]\n",
      "epoch:3 step:2854[D loss: 0.445282, acc: 59.38%, op_acc: 33.59%] [G loss: 1.068985]\n",
      "epoch:3 step:2855[D loss: 0.467762, acc: 56.25%, op_acc: 26.56%] [G loss: 0.946119]\n",
      "epoch:3 step:2856[D loss: 0.468993, acc: 64.06%, op_acc: 27.34%] [G loss: 0.958619]\n",
      "epoch:3 step:2857[D loss: 0.475896, acc: 55.47%, op_acc: 29.69%] [G loss: 0.879603]\n",
      "epoch:3 step:2858[D loss: 0.486027, acc: 58.59%, op_acc: 27.34%] [G loss: 0.970765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2859[D loss: 0.471571, acc: 57.03%, op_acc: 22.66%] [G loss: 0.873956]\n",
      "epoch:3 step:2860[D loss: 0.491664, acc: 63.28%, op_acc: 25.78%] [G loss: 0.912345]\n",
      "epoch:3 step:2861[D loss: 0.444263, acc: 62.50%, op_acc: 32.03%] [G loss: 1.007230]\n",
      "epoch:3 step:2862[D loss: 0.419963, acc: 65.62%, op_acc: 34.38%] [G loss: 0.998560]\n",
      "epoch:3 step:2863[D loss: 0.480668, acc: 53.12%, op_acc: 27.34%] [G loss: 0.839789]\n",
      "epoch:3 step:2864[D loss: 0.444746, acc: 65.62%, op_acc: 32.03%] [G loss: 0.954119]\n",
      "epoch:3 step:2865[D loss: 0.486295, acc: 59.38%, op_acc: 25.78%] [G loss: 1.043866]\n",
      "epoch:3 step:2866[D loss: 0.446719, acc: 56.25%, op_acc: 32.81%] [G loss: 1.013129]\n",
      "epoch:3 step:2867[D loss: 0.444669, acc: 65.62%, op_acc: 27.34%] [G loss: 0.917639]\n",
      "epoch:3 step:2868[D loss: 0.461120, acc: 63.28%, op_acc: 21.09%] [G loss: 0.953411]\n",
      "epoch:3 step:2869[D loss: 0.537793, acc: 53.12%, op_acc: 18.75%] [G loss: 0.900599]\n",
      "epoch:3 step:2870[D loss: 0.490708, acc: 54.69%, op_acc: 28.12%] [G loss: 0.868449]\n",
      "epoch:3 step:2871[D loss: 0.443900, acc: 57.81%, op_acc: 40.62%] [G loss: 0.942782]\n",
      "epoch:3 step:2872[D loss: 0.426631, acc: 63.28%, op_acc: 31.25%] [G loss: 0.962518]\n",
      "epoch:3 step:2873[D loss: 0.484576, acc: 56.25%, op_acc: 27.34%] [G loss: 0.877283]\n",
      "epoch:3 step:2874[D loss: 0.487832, acc: 54.69%, op_acc: 24.22%] [G loss: 0.953848]\n",
      "epoch:3 step:2875[D loss: 0.468502, acc: 58.59%, op_acc: 32.81%] [G loss: 0.981989]\n",
      "epoch:3 step:2876[D loss: 0.450725, acc: 65.62%, op_acc: 35.16%] [G loss: 0.979099]\n",
      "epoch:3 step:2877[D loss: 0.460796, acc: 53.12%, op_acc: 31.25%] [G loss: 0.887469]\n",
      "epoch:3 step:2878[D loss: 0.484647, acc: 54.69%, op_acc: 32.03%] [G loss: 0.904134]\n",
      "epoch:3 step:2879[D loss: 0.438753, acc: 55.47%, op_acc: 42.19%] [G loss: 0.949630]\n",
      "epoch:3 step:2880[D loss: 0.471302, acc: 57.81%, op_acc: 28.91%] [G loss: 0.900143]\n",
      "epoch:3 step:2881[D loss: 0.456988, acc: 60.16%, op_acc: 35.16%] [G loss: 0.991082]\n",
      "epoch:3 step:2882[D loss: 0.481843, acc: 57.03%, op_acc: 26.56%] [G loss: 0.994707]\n",
      "epoch:3 step:2883[D loss: 0.450186, acc: 60.94%, op_acc: 34.38%] [G loss: 0.898611]\n",
      "epoch:3 step:2884[D loss: 0.430228, acc: 67.19%, op_acc: 35.16%] [G loss: 1.014704]\n",
      "epoch:3 step:2885[D loss: 0.424539, acc: 67.19%, op_acc: 39.84%] [G loss: 0.955947]\n",
      "epoch:3 step:2886[D loss: 0.438001, acc: 64.06%, op_acc: 34.38%] [G loss: 0.972476]\n",
      "epoch:3 step:2887[D loss: 0.460838, acc: 57.81%, op_acc: 36.72%] [G loss: 1.024997]\n",
      "epoch:3 step:2888[D loss: 0.439601, acc: 64.06%, op_acc: 31.25%] [G loss: 0.938420]\n",
      "epoch:3 step:2889[D loss: 0.484318, acc: 53.91%, op_acc: 29.69%] [G loss: 0.978257]\n",
      "epoch:3 step:2890[D loss: 0.475081, acc: 57.03%, op_acc: 28.12%] [G loss: 1.038632]\n",
      "epoch:3 step:2891[D loss: 0.453385, acc: 64.84%, op_acc: 33.59%] [G loss: 0.959311]\n",
      "epoch:3 step:2892[D loss: 0.467764, acc: 57.03%, op_acc: 30.47%] [G loss: 0.918514]\n",
      "epoch:3 step:2893[D loss: 0.453589, acc: 62.50%, op_acc: 32.03%] [G loss: 0.892866]\n",
      "epoch:3 step:2894[D loss: 0.459287, acc: 59.38%, op_acc: 29.69%] [G loss: 0.907852]\n",
      "epoch:3 step:2895[D loss: 0.503737, acc: 57.03%, op_acc: 17.19%] [G loss: 0.920279]\n",
      "epoch:3 step:2896[D loss: 0.478252, acc: 50.00%, op_acc: 33.59%] [G loss: 0.796101]\n",
      "epoch:3 step:2897[D loss: 0.497238, acc: 55.47%, op_acc: 27.34%] [G loss: 0.909352]\n",
      "epoch:3 step:2898[D loss: 0.456070, acc: 59.38%, op_acc: 32.03%] [G loss: 0.905801]\n",
      "epoch:3 step:2899[D loss: 0.476270, acc: 57.03%, op_acc: 30.47%] [G loss: 0.873657]\n",
      "epoch:3 step:2900[D loss: 0.471815, acc: 56.25%, op_acc: 27.34%] [G loss: 0.917530]\n",
      "##############\n",
      "[0.8625192  0.86883908 0.81931447 0.79260372 0.77874488 0.82070321\n",
      " 0.87036084 0.8224599  0.81953616 0.85320269]\n",
      "##########\n",
      "epoch:3 step:2901[D loss: 0.484187, acc: 59.38%, op_acc: 31.25%] [G loss: 0.887609]\n",
      "epoch:3 step:2902[D loss: 0.436973, acc: 63.28%, op_acc: 25.00%] [G loss: 1.029709]\n",
      "epoch:3 step:2903[D loss: 0.429141, acc: 71.88%, op_acc: 31.25%] [G loss: 1.032678]\n",
      "epoch:3 step:2904[D loss: 0.454373, acc: 59.38%, op_acc: 28.91%] [G loss: 0.998519]\n",
      "epoch:3 step:2905[D loss: 0.476441, acc: 53.91%, op_acc: 24.22%] [G loss: 0.918078]\n",
      "epoch:3 step:2906[D loss: 0.501607, acc: 50.78%, op_acc: 27.34%] [G loss: 0.946564]\n",
      "epoch:3 step:2907[D loss: 0.434965, acc: 68.75%, op_acc: 37.50%] [G loss: 1.015088]\n",
      "epoch:3 step:2908[D loss: 0.484845, acc: 52.34%, op_acc: 31.25%] [G loss: 0.915154]\n",
      "epoch:3 step:2909[D loss: 0.457336, acc: 64.84%, op_acc: 28.91%] [G loss: 0.916020]\n",
      "epoch:3 step:2910[D loss: 0.474164, acc: 54.69%, op_acc: 28.91%] [G loss: 0.837775]\n",
      "epoch:3 step:2911[D loss: 0.449940, acc: 62.50%, op_acc: 28.12%] [G loss: 0.972543]\n",
      "epoch:3 step:2912[D loss: 0.473707, acc: 58.59%, op_acc: 30.47%] [G loss: 0.915282]\n",
      "epoch:3 step:2913[D loss: 0.475556, acc: 53.91%, op_acc: 33.59%] [G loss: 0.930386]\n",
      "epoch:3 step:2914[D loss: 0.464120, acc: 57.03%, op_acc: 33.59%] [G loss: 0.875097]\n",
      "epoch:3 step:2915[D loss: 0.424409, acc: 71.88%, op_acc: 32.81%] [G loss: 0.958982]\n",
      "epoch:3 step:2916[D loss: 0.483325, acc: 50.00%, op_acc: 34.38%] [G loss: 0.852352]\n",
      "epoch:3 step:2917[D loss: 0.475575, acc: 57.03%, op_acc: 25.78%] [G loss: 1.021995]\n",
      "epoch:3 step:2918[D loss: 0.460853, acc: 59.38%, op_acc: 27.34%] [G loss: 0.951901]\n",
      "epoch:3 step:2919[D loss: 0.447079, acc: 57.81%, op_acc: 36.72%] [G loss: 1.020120]\n",
      "epoch:3 step:2920[D loss: 0.460085, acc: 61.72%, op_acc: 28.91%] [G loss: 0.926028]\n",
      "epoch:3 step:2921[D loss: 0.479915, acc: 60.94%, op_acc: 23.44%] [G loss: 0.995968]\n",
      "epoch:3 step:2922[D loss: 0.420940, acc: 64.84%, op_acc: 34.38%] [G loss: 0.930833]\n",
      "epoch:3 step:2923[D loss: 0.468137, acc: 60.94%, op_acc: 28.91%] [G loss: 1.014204]\n",
      "epoch:3 step:2924[D loss: 0.473588, acc: 53.91%, op_acc: 32.03%] [G loss: 0.859957]\n",
      "epoch:3 step:2925[D loss: 0.486860, acc: 57.03%, op_acc: 25.00%] [G loss: 0.904559]\n",
      "epoch:3 step:2926[D loss: 0.443753, acc: 59.38%, op_acc: 28.12%] [G loss: 0.986991]\n",
      "epoch:3 step:2927[D loss: 0.483946, acc: 59.38%, op_acc: 25.78%] [G loss: 0.883406]\n",
      "epoch:3 step:2928[D loss: 0.452001, acc: 61.72%, op_acc: 35.94%] [G loss: 0.955183]\n",
      "epoch:3 step:2929[D loss: 0.475098, acc: 60.16%, op_acc: 21.88%] [G loss: 0.880881]\n",
      "epoch:3 step:2930[D loss: 0.464863, acc: 57.81%, op_acc: 24.22%] [G loss: 0.952105]\n",
      "epoch:3 step:2931[D loss: 0.446213, acc: 57.81%, op_acc: 32.81%] [G loss: 0.911358]\n",
      "epoch:3 step:2932[D loss: 0.436755, acc: 67.19%, op_acc: 31.25%] [G loss: 1.038987]\n",
      "epoch:3 step:2933[D loss: 0.451210, acc: 64.84%, op_acc: 31.25%] [G loss: 0.947300]\n",
      "epoch:3 step:2934[D loss: 0.482576, acc: 53.91%, op_acc: 28.91%] [G loss: 0.914172]\n",
      "epoch:3 step:2935[D loss: 0.430904, acc: 67.19%, op_acc: 31.25%] [G loss: 0.960542]\n",
      "epoch:3 step:2936[D loss: 0.453396, acc: 63.28%, op_acc: 31.25%] [G loss: 0.985184]\n",
      "epoch:3 step:2937[D loss: 0.465681, acc: 55.47%, op_acc: 26.56%] [G loss: 0.807815]\n",
      "epoch:3 step:2938[D loss: 0.458896, acc: 60.94%, op_acc: 24.22%] [G loss: 0.910166]\n",
      "epoch:3 step:2939[D loss: 0.502734, acc: 48.44%, op_acc: 26.56%] [G loss: 0.921627]\n",
      "epoch:3 step:2940[D loss: 0.456670, acc: 63.28%, op_acc: 30.47%] [G loss: 0.992286]\n",
      "epoch:3 step:2941[D loss: 0.460332, acc: 60.94%, op_acc: 33.59%] [G loss: 0.859702]\n",
      "epoch:3 step:2942[D loss: 0.465522, acc: 66.41%, op_acc: 27.34%] [G loss: 0.946084]\n",
      "epoch:3 step:2943[D loss: 0.458852, acc: 60.16%, op_acc: 29.69%] [G loss: 0.860976]\n",
      "epoch:3 step:2944[D loss: 0.462879, acc: 51.56%, op_acc: 34.38%] [G loss: 0.872239]\n",
      "epoch:3 step:2945[D loss: 0.434823, acc: 60.94%, op_acc: 36.72%] [G loss: 0.904967]\n",
      "epoch:3 step:2946[D loss: 0.456109, acc: 57.03%, op_acc: 32.03%] [G loss: 0.860954]\n",
      "epoch:3 step:2947[D loss: 0.499959, acc: 54.69%, op_acc: 28.91%] [G loss: 0.927648]\n",
      "epoch:3 step:2948[D loss: 0.445463, acc: 61.72%, op_acc: 28.12%] [G loss: 0.913973]\n",
      "epoch:3 step:2949[D loss: 0.485632, acc: 53.12%, op_acc: 35.16%] [G loss: 0.868234]\n",
      "epoch:3 step:2950[D loss: 0.442089, acc: 57.03%, op_acc: 39.06%] [G loss: 0.922475]\n",
      "##############\n",
      "[0.87197373 0.87966189 0.82013166 0.8095009  0.78561303 0.81111341\n",
      " 0.86910555 0.83510543 0.79036907 0.81790815]\n",
      "##########\n",
      "epoch:3 step:2951[D loss: 0.460553, acc: 58.59%, op_acc: 32.03%] [G loss: 0.927769]\n",
      "epoch:3 step:2952[D loss: 0.455004, acc: 60.16%, op_acc: 32.81%] [G loss: 0.907994]\n",
      "epoch:3 step:2953[D loss: 0.466197, acc: 57.81%, op_acc: 29.69%] [G loss: 0.899452]\n",
      "epoch:3 step:2954[D loss: 0.484131, acc: 56.25%, op_acc: 29.69%] [G loss: 0.894882]\n",
      "epoch:3 step:2955[D loss: 0.436716, acc: 64.84%, op_acc: 33.59%] [G loss: 1.064955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2956[D loss: 0.481418, acc: 54.69%, op_acc: 28.91%] [G loss: 0.880305]\n",
      "epoch:3 step:2957[D loss: 0.460800, acc: 56.25%, op_acc: 32.81%] [G loss: 1.000728]\n",
      "epoch:3 step:2958[D loss: 0.477384, acc: 56.25%, op_acc: 28.12%] [G loss: 0.982319]\n",
      "epoch:3 step:2959[D loss: 0.458227, acc: 58.59%, op_acc: 34.38%] [G loss: 0.972710]\n",
      "epoch:3 step:2960[D loss: 0.501358, acc: 55.47%, op_acc: 27.34%] [G loss: 0.889780]\n",
      "epoch:3 step:2961[D loss: 0.449595, acc: 59.38%, op_acc: 33.59%] [G loss: 0.924739]\n",
      "epoch:3 step:2962[D loss: 0.457070, acc: 63.28%, op_acc: 26.56%] [G loss: 0.969249]\n",
      "epoch:3 step:2963[D loss: 0.423285, acc: 68.75%, op_acc: 23.44%] [G loss: 1.019873]\n",
      "epoch:3 step:2964[D loss: 0.437871, acc: 68.75%, op_acc: 28.91%] [G loss: 1.004363]\n",
      "epoch:3 step:2965[D loss: 0.460543, acc: 68.75%, op_acc: 28.12%] [G loss: 1.010600]\n",
      "epoch:3 step:2966[D loss: 0.465230, acc: 60.16%, op_acc: 32.81%] [G loss: 0.954731]\n",
      "epoch:3 step:2967[D loss: 0.445708, acc: 62.50%, op_acc: 27.34%] [G loss: 0.944786]\n",
      "epoch:3 step:2968[D loss: 0.435926, acc: 67.97%, op_acc: 32.03%] [G loss: 0.894930]\n",
      "epoch:3 step:2969[D loss: 0.424418, acc: 62.50%, op_acc: 34.38%] [G loss: 0.939261]\n",
      "epoch:3 step:2970[D loss: 0.475593, acc: 52.34%, op_acc: 35.94%] [G loss: 0.835108]\n",
      "epoch:3 step:2971[D loss: 0.486583, acc: 54.69%, op_acc: 30.47%] [G loss: 0.837266]\n",
      "epoch:3 step:2972[D loss: 0.451764, acc: 63.28%, op_acc: 24.22%] [G loss: 0.959412]\n",
      "epoch:3 step:2973[D loss: 0.454134, acc: 54.69%, op_acc: 36.72%] [G loss: 0.865385]\n",
      "epoch:3 step:2974[D loss: 0.450731, acc: 66.41%, op_acc: 27.34%] [G loss: 0.922453]\n",
      "epoch:3 step:2975[D loss: 0.466880, acc: 66.41%, op_acc: 25.78%] [G loss: 0.954409]\n",
      "epoch:3 step:2976[D loss: 0.454421, acc: 59.38%, op_acc: 30.47%] [G loss: 0.975031]\n",
      "epoch:3 step:2977[D loss: 0.439541, acc: 54.69%, op_acc: 38.28%] [G loss: 1.044000]\n",
      "epoch:3 step:2978[D loss: 0.469269, acc: 58.59%, op_acc: 25.00%] [G loss: 0.875330]\n",
      "epoch:3 step:2979[D loss: 0.430931, acc: 59.38%, op_acc: 38.28%] [G loss: 0.932981]\n",
      "epoch:3 step:2980[D loss: 0.496552, acc: 50.78%, op_acc: 30.47%] [G loss: 1.024094]\n",
      "epoch:3 step:2981[D loss: 0.464619, acc: 64.06%, op_acc: 33.59%] [G loss: 0.974239]\n",
      "epoch:3 step:2982[D loss: 0.479051, acc: 55.47%, op_acc: 28.91%] [G loss: 0.963919]\n",
      "epoch:3 step:2983[D loss: 0.462648, acc: 61.72%, op_acc: 34.38%] [G loss: 1.023545]\n",
      "epoch:3 step:2984[D loss: 0.479858, acc: 59.38%, op_acc: 28.91%] [G loss: 0.949358]\n",
      "epoch:3 step:2985[D loss: 0.471882, acc: 67.19%, op_acc: 27.34%] [G loss: 0.946841]\n",
      "epoch:3 step:2986[D loss: 0.475184, acc: 57.03%, op_acc: 28.91%] [G loss: 0.981771]\n",
      "epoch:3 step:2987[D loss: 0.440951, acc: 64.06%, op_acc: 32.81%] [G loss: 1.008495]\n",
      "epoch:3 step:2988[D loss: 0.424596, acc: 67.97%, op_acc: 31.25%] [G loss: 0.919927]\n",
      "epoch:3 step:2989[D loss: 0.509446, acc: 55.47%, op_acc: 26.56%] [G loss: 0.903695]\n",
      "epoch:3 step:2990[D loss: 0.479354, acc: 49.22%, op_acc: 33.59%] [G loss: 0.802194]\n",
      "epoch:3 step:2991[D loss: 0.473789, acc: 58.59%, op_acc: 26.56%] [G loss: 0.950982]\n",
      "epoch:3 step:2992[D loss: 0.449661, acc: 66.41%, op_acc: 32.81%] [G loss: 1.027694]\n",
      "epoch:3 step:2993[D loss: 0.495554, acc: 60.16%, op_acc: 25.00%] [G loss: 1.003550]\n",
      "epoch:3 step:2994[D loss: 0.490125, acc: 48.44%, op_acc: 29.69%] [G loss: 0.869315]\n",
      "epoch:3 step:2995[D loss: 0.426522, acc: 65.62%, op_acc: 33.59%] [G loss: 0.978235]\n",
      "epoch:3 step:2996[D loss: 0.439602, acc: 64.06%, op_acc: 38.28%] [G loss: 0.866031]\n",
      "epoch:3 step:2997[D loss: 0.462020, acc: 55.47%, op_acc: 33.59%] [G loss: 0.870619]\n",
      "epoch:3 step:2998[D loss: 0.430313, acc: 67.19%, op_acc: 29.69%] [G loss: 0.907724]\n",
      "epoch:3 step:2999[D loss: 0.458888, acc: 61.72%, op_acc: 31.25%] [G loss: 0.910318]\n",
      "epoch:3 step:3000[D loss: 0.470796, acc: 55.47%, op_acc: 34.38%] [G loss: 0.955504]\n",
      "##############\n",
      "[0.85644804 0.85606461 0.79229741 0.80820988 0.76638951 0.80328767\n",
      " 0.85963187 0.83889253 0.82248938 0.83827413]\n",
      "##########\n",
      "epoch:3 step:3001[D loss: 0.431733, acc: 70.31%, op_acc: 32.03%] [G loss: 1.023903]\n",
      "epoch:3 step:3002[D loss: 0.464393, acc: 62.50%, op_acc: 32.81%] [G loss: 0.933258]\n",
      "epoch:3 step:3003[D loss: 0.441035, acc: 62.50%, op_acc: 32.81%] [G loss: 0.906285]\n",
      "epoch:3 step:3004[D loss: 0.471436, acc: 57.81%, op_acc: 32.81%] [G loss: 1.047103]\n",
      "epoch:3 step:3005[D loss: 0.438099, acc: 63.28%, op_acc: 36.72%] [G loss: 1.027169]\n",
      "epoch:3 step:3006[D loss: 0.415760, acc: 69.53%, op_acc: 28.12%] [G loss: 1.051734]\n",
      "epoch:3 step:3007[D loss: 0.401725, acc: 72.66%, op_acc: 36.72%] [G loss: 1.091334]\n",
      "epoch:3 step:3008[D loss: 0.472867, acc: 61.72%, op_acc: 22.66%] [G loss: 0.904991]\n",
      "epoch:3 step:3009[D loss: 0.437043, acc: 68.75%, op_acc: 30.47%] [G loss: 1.053293]\n",
      "epoch:3 step:3010[D loss: 0.433897, acc: 63.28%, op_acc: 39.84%] [G loss: 0.962694]\n",
      "epoch:3 step:3011[D loss: 0.439305, acc: 64.84%, op_acc: 29.69%] [G loss: 0.956420]\n",
      "epoch:3 step:3012[D loss: 0.483108, acc: 57.81%, op_acc: 24.22%] [G loss: 1.013114]\n",
      "epoch:3 step:3013[D loss: 0.456588, acc: 59.38%, op_acc: 28.91%] [G loss: 1.008867]\n",
      "epoch:3 step:3014[D loss: 0.480896, acc: 50.78%, op_acc: 26.56%] [G loss: 1.013138]\n",
      "epoch:3 step:3015[D loss: 0.492033, acc: 53.91%, op_acc: 26.56%] [G loss: 0.953229]\n",
      "epoch:3 step:3016[D loss: 0.489253, acc: 52.34%, op_acc: 27.34%] [G loss: 1.031314]\n",
      "epoch:3 step:3017[D loss: 0.458026, acc: 58.59%, op_acc: 32.03%] [G loss: 0.970716]\n",
      "epoch:3 step:3018[D loss: 0.473959, acc: 55.47%, op_acc: 35.16%] [G loss: 0.915221]\n",
      "epoch:3 step:3019[D loss: 0.463319, acc: 58.59%, op_acc: 27.34%] [G loss: 0.940883]\n",
      "epoch:3 step:3020[D loss: 0.446272, acc: 62.50%, op_acc: 32.03%] [G loss: 0.910828]\n",
      "epoch:3 step:3021[D loss: 0.427915, acc: 62.50%, op_acc: 31.25%] [G loss: 0.973516]\n",
      "epoch:3 step:3022[D loss: 0.451737, acc: 62.50%, op_acc: 35.16%] [G loss: 0.953512]\n",
      "epoch:3 step:3023[D loss: 0.447209, acc: 65.62%, op_acc: 29.69%] [G loss: 1.003574]\n",
      "epoch:3 step:3024[D loss: 0.465526, acc: 65.62%, op_acc: 21.88%] [G loss: 0.980162]\n",
      "epoch:3 step:3025[D loss: 0.451515, acc: 57.81%, op_acc: 35.16%] [G loss: 0.887876]\n",
      "epoch:3 step:3026[D loss: 0.402389, acc: 67.19%, op_acc: 38.28%] [G loss: 0.908100]\n",
      "epoch:3 step:3027[D loss: 0.436942, acc: 67.97%, op_acc: 29.69%] [G loss: 0.872673]\n",
      "epoch:3 step:3028[D loss: 0.468273, acc: 57.03%, op_acc: 28.91%] [G loss: 0.863449]\n",
      "epoch:3 step:3029[D loss: 0.442427, acc: 64.84%, op_acc: 25.78%] [G loss: 0.863898]\n",
      "epoch:3 step:3030[D loss: 0.446787, acc: 58.59%, op_acc: 28.91%] [G loss: 0.917498]\n",
      "epoch:3 step:3031[D loss: 0.463150, acc: 55.47%, op_acc: 30.47%] [G loss: 0.939864]\n",
      "epoch:3 step:3032[D loss: 0.482536, acc: 53.91%, op_acc: 34.38%] [G loss: 0.909625]\n",
      "epoch:3 step:3033[D loss: 0.469996, acc: 64.06%, op_acc: 31.25%] [G loss: 0.946256]\n",
      "epoch:3 step:3034[D loss: 0.461985, acc: 59.38%, op_acc: 29.69%] [G loss: 0.894842]\n",
      "epoch:3 step:3035[D loss: 0.493499, acc: 60.16%, op_acc: 25.78%] [G loss: 0.880986]\n",
      "epoch:3 step:3036[D loss: 0.479028, acc: 63.28%, op_acc: 22.66%] [G loss: 0.981320]\n",
      "epoch:3 step:3037[D loss: 0.443572, acc: 64.84%, op_acc: 35.16%] [G loss: 1.004197]\n",
      "epoch:3 step:3038[D loss: 0.455940, acc: 61.72%, op_acc: 32.81%] [G loss: 0.968194]\n",
      "epoch:3 step:3039[D loss: 0.452244, acc: 62.50%, op_acc: 32.81%] [G loss: 0.899354]\n",
      "epoch:3 step:3040[D loss: 0.457642, acc: 60.94%, op_acc: 34.38%] [G loss: 0.889961]\n",
      "epoch:3 step:3041[D loss: 0.467579, acc: 58.59%, op_acc: 25.78%] [G loss: 0.881337]\n",
      "epoch:3 step:3042[D loss: 0.439910, acc: 60.16%, op_acc: 35.16%] [G loss: 0.844283]\n",
      "epoch:3 step:3043[D loss: 0.478743, acc: 57.81%, op_acc: 28.12%] [G loss: 0.930003]\n",
      "epoch:3 step:3044[D loss: 0.488173, acc: 55.47%, op_acc: 25.78%] [G loss: 0.934099]\n",
      "epoch:3 step:3045[D loss: 0.446668, acc: 64.06%, op_acc: 32.03%] [G loss: 0.996123]\n",
      "epoch:3 step:3046[D loss: 0.453581, acc: 57.03%, op_acc: 29.69%] [G loss: 0.924781]\n",
      "epoch:3 step:3047[D loss: 0.437989, acc: 60.16%, op_acc: 33.59%] [G loss: 0.954141]\n",
      "epoch:3 step:3048[D loss: 0.449669, acc: 63.28%, op_acc: 28.12%] [G loss: 0.937652]\n",
      "epoch:3 step:3049[D loss: 0.473289, acc: 60.94%, op_acc: 27.34%] [G loss: 0.944505]\n",
      "epoch:3 step:3050[D loss: 0.487643, acc: 57.03%, op_acc: 24.22%] [G loss: 0.901717]\n",
      "##############\n",
      "[0.85244922 0.88355609 0.81997686 0.80022121 0.78407305 0.82879645\n",
      " 0.91190279 0.83028202 0.80360478 0.83815322]\n",
      "##########\n",
      "epoch:3 step:3051[D loss: 0.486576, acc: 55.47%, op_acc: 25.78%] [G loss: 0.907822]\n",
      "epoch:3 step:3052[D loss: 0.463967, acc: 59.38%, op_acc: 25.78%] [G loss: 0.891240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3053[D loss: 0.427652, acc: 60.94%, op_acc: 36.72%] [G loss: 0.960065]\n",
      "epoch:3 step:3054[D loss: 0.462139, acc: 57.81%, op_acc: 28.91%] [G loss: 0.940760]\n",
      "epoch:3 step:3055[D loss: 0.421482, acc: 64.06%, op_acc: 35.16%] [G loss: 1.005593]\n",
      "epoch:3 step:3056[D loss: 0.453422, acc: 56.25%, op_acc: 35.16%] [G loss: 0.951020]\n",
      "epoch:3 step:3057[D loss: 0.470664, acc: 55.47%, op_acc: 27.34%] [G loss: 0.943765]\n",
      "epoch:3 step:3058[D loss: 0.470867, acc: 55.47%, op_acc: 29.69%] [G loss: 0.981978]\n",
      "epoch:3 step:3059[D loss: 0.498618, acc: 52.34%, op_acc: 26.56%] [G loss: 0.920022]\n",
      "epoch:3 step:3060[D loss: 0.458851, acc: 55.47%, op_acc: 28.91%] [G loss: 1.020553]\n",
      "epoch:3 step:3061[D loss: 0.440409, acc: 63.28%, op_acc: 28.91%] [G loss: 1.037250]\n",
      "epoch:3 step:3062[D loss: 0.467571, acc: 53.91%, op_acc: 32.03%] [G loss: 0.937683]\n",
      "epoch:3 step:3063[D loss: 0.468690, acc: 52.34%, op_acc: 31.25%] [G loss: 0.915428]\n",
      "epoch:3 step:3064[D loss: 0.458794, acc: 55.47%, op_acc: 31.25%] [G loss: 0.992563]\n",
      "epoch:3 step:3065[D loss: 0.434943, acc: 63.28%, op_acc: 33.59%] [G loss: 1.049671]\n",
      "epoch:3 step:3066[D loss: 0.427239, acc: 67.19%, op_acc: 32.03%] [G loss: 0.941896]\n",
      "epoch:3 step:3067[D loss: 0.476082, acc: 60.16%, op_acc: 23.44%] [G loss: 0.982764]\n",
      "epoch:3 step:3068[D loss: 0.428850, acc: 67.19%, op_acc: 32.03%] [G loss: 0.884849]\n",
      "epoch:3 step:3069[D loss: 0.460482, acc: 53.12%, op_acc: 32.03%] [G loss: 0.884148]\n",
      "epoch:3 step:3070[D loss: 0.477639, acc: 62.50%, op_acc: 25.00%] [G loss: 0.889268]\n",
      "epoch:3 step:3071[D loss: 0.468119, acc: 59.38%, op_acc: 25.00%] [G loss: 0.929962]\n",
      "epoch:3 step:3072[D loss: 0.434317, acc: 65.62%, op_acc: 29.69%] [G loss: 0.849595]\n",
      "epoch:3 step:3073[D loss: 0.446691, acc: 62.50%, op_acc: 34.38%] [G loss: 1.003168]\n",
      "epoch:3 step:3074[D loss: 0.461882, acc: 53.12%, op_acc: 32.81%] [G loss: 0.894593]\n",
      "epoch:3 step:3075[D loss: 0.472259, acc: 58.59%, op_acc: 34.38%] [G loss: 0.869505]\n",
      "epoch:3 step:3076[D loss: 0.451270, acc: 64.84%, op_acc: 35.94%] [G loss: 0.947201]\n",
      "epoch:3 step:3077[D loss: 0.478306, acc: 60.16%, op_acc: 23.44%] [G loss: 0.933934]\n",
      "epoch:3 step:3078[D loss: 0.481846, acc: 54.69%, op_acc: 23.44%] [G loss: 0.837523]\n",
      "epoch:3 step:3079[D loss: 0.443820, acc: 64.84%, op_acc: 29.69%] [G loss: 0.847083]\n",
      "epoch:3 step:3080[D loss: 0.448828, acc: 55.47%, op_acc: 35.16%] [G loss: 0.852362]\n",
      "epoch:3 step:3081[D loss: 0.462724, acc: 56.25%, op_acc: 28.12%] [G loss: 0.917921]\n",
      "epoch:3 step:3082[D loss: 0.466951, acc: 60.16%, op_acc: 28.91%] [G loss: 0.951733]\n",
      "epoch:3 step:3083[D loss: 0.441725, acc: 63.28%, op_acc: 38.28%] [G loss: 0.965145]\n",
      "epoch:3 step:3084[D loss: 0.443935, acc: 60.94%, op_acc: 31.25%] [G loss: 1.015558]\n",
      "epoch:3 step:3085[D loss: 0.427705, acc: 61.72%, op_acc: 32.81%] [G loss: 0.999857]\n",
      "epoch:3 step:3086[D loss: 0.474218, acc: 60.16%, op_acc: 27.34%] [G loss: 1.017423]\n",
      "epoch:3 step:3087[D loss: 0.439129, acc: 64.06%, op_acc: 33.59%] [G loss: 1.027716]\n",
      "epoch:3 step:3088[D loss: 0.462196, acc: 60.16%, op_acc: 26.56%] [G loss: 0.879327]\n",
      "epoch:3 step:3089[D loss: 0.463507, acc: 57.03%, op_acc: 31.25%] [G loss: 0.990193]\n",
      "epoch:3 step:3090[D loss: 0.442311, acc: 61.72%, op_acc: 33.59%] [G loss: 0.965454]\n",
      "epoch:3 step:3091[D loss: 0.468327, acc: 59.38%, op_acc: 25.78%] [G loss: 1.023521]\n",
      "epoch:3 step:3092[D loss: 0.450479, acc: 67.97%, op_acc: 29.69%] [G loss: 0.897125]\n",
      "epoch:3 step:3093[D loss: 0.447462, acc: 64.84%, op_acc: 29.69%] [G loss: 1.004700]\n",
      "epoch:3 step:3094[D loss: 0.509406, acc: 53.12%, op_acc: 22.66%] [G loss: 0.923135]\n",
      "epoch:3 step:3095[D loss: 0.460895, acc: 63.28%, op_acc: 26.56%] [G loss: 0.876824]\n",
      "epoch:3 step:3096[D loss: 0.418629, acc: 72.66%, op_acc: 35.94%] [G loss: 0.903711]\n",
      "epoch:3 step:3097[D loss: 0.440222, acc: 67.19%, op_acc: 35.16%] [G loss: 0.883146]\n",
      "epoch:3 step:3098[D loss: 0.436989, acc: 64.06%, op_acc: 37.50%] [G loss: 0.939097]\n",
      "epoch:3 step:3099[D loss: 0.464709, acc: 56.25%, op_acc: 37.50%] [G loss: 0.968239]\n",
      "epoch:3 step:3100[D loss: 0.457742, acc: 61.72%, op_acc: 30.47%] [G loss: 1.014299]\n",
      "##############\n",
      "[0.85727057 0.8881135  0.79711257 0.798912   0.79325543 0.80287561\n",
      " 0.87472824 0.818592   0.81199037 0.83396452]\n",
      "##########\n",
      "epoch:3 step:3101[D loss: 0.474229, acc: 52.34%, op_acc: 31.25%] [G loss: 0.960229]\n",
      "epoch:3 step:3102[D loss: 0.447589, acc: 66.41%, op_acc: 28.91%] [G loss: 0.994938]\n",
      "epoch:3 step:3103[D loss: 0.479365, acc: 60.94%, op_acc: 32.81%] [G loss: 0.917215]\n",
      "epoch:3 step:3104[D loss: 0.423837, acc: 66.41%, op_acc: 32.03%] [G loss: 0.974640]\n",
      "epoch:3 step:3105[D loss: 0.473819, acc: 64.06%, op_acc: 27.34%] [G loss: 0.937725]\n",
      "epoch:3 step:3106[D loss: 0.474280, acc: 55.47%, op_acc: 28.91%] [G loss: 0.974843]\n",
      "epoch:3 step:3107[D loss: 0.476258, acc: 56.25%, op_acc: 33.59%] [G loss: 0.922225]\n",
      "epoch:3 step:3108[D loss: 0.459332, acc: 62.50%, op_acc: 33.59%] [G loss: 0.867641]\n",
      "epoch:3 step:3109[D loss: 0.466839, acc: 59.38%, op_acc: 25.78%] [G loss: 0.944261]\n",
      "epoch:3 step:3110[D loss: 0.457318, acc: 57.03%, op_acc: 26.56%] [G loss: 0.973811]\n",
      "epoch:3 step:3111[D loss: 0.477179, acc: 58.59%, op_acc: 27.34%] [G loss: 0.995991]\n",
      "epoch:3 step:3112[D loss: 0.469203, acc: 51.56%, op_acc: 36.72%] [G loss: 0.945065]\n",
      "epoch:3 step:3113[D loss: 0.450567, acc: 62.50%, op_acc: 33.59%] [G loss: 1.009584]\n",
      "epoch:3 step:3114[D loss: 0.468227, acc: 57.81%, op_acc: 35.16%] [G loss: 1.026022]\n",
      "epoch:3 step:3115[D loss: 0.448280, acc: 65.62%, op_acc: 28.91%] [G loss: 0.970074]\n",
      "epoch:3 step:3116[D loss: 0.429417, acc: 64.84%, op_acc: 39.06%] [G loss: 0.956055]\n",
      "epoch:3 step:3117[D loss: 0.435153, acc: 64.84%, op_acc: 35.16%] [G loss: 0.945102]\n",
      "epoch:3 step:3118[D loss: 0.466356, acc: 60.16%, op_acc: 28.91%] [G loss: 0.962690]\n",
      "epoch:3 step:3119[D loss: 0.453881, acc: 60.94%, op_acc: 32.81%] [G loss: 0.906568]\n",
      "epoch:3 step:3120[D loss: 0.470477, acc: 66.41%, op_acc: 25.00%] [G loss: 0.901963]\n",
      "epoch:3 step:3121[D loss: 0.458371, acc: 57.81%, op_acc: 32.81%] [G loss: 0.845382]\n",
      "epoch:3 step:3122[D loss: 0.432395, acc: 62.50%, op_acc: 31.25%] [G loss: 0.998770]\n",
      "epoch:3 step:3123[D loss: 0.479343, acc: 50.00%, op_acc: 33.59%] [G loss: 0.957611]\n",
      "epoch:3 step:3124[D loss: 0.456257, acc: 60.94%, op_acc: 32.81%] [G loss: 0.938034]\n",
      "epoch:4 step:3125[D loss: 0.491680, acc: 51.56%, op_acc: 30.47%] [G loss: 0.955880]\n",
      "epoch:4 step:3126[D loss: 0.423881, acc: 70.31%, op_acc: 32.81%] [G loss: 0.980425]\n",
      "epoch:4 step:3127[D loss: 0.490463, acc: 54.69%, op_acc: 28.91%] [G loss: 0.968621]\n",
      "epoch:4 step:3128[D loss: 0.424273, acc: 64.06%, op_acc: 35.16%] [G loss: 0.975942]\n",
      "epoch:4 step:3129[D loss: 0.454437, acc: 55.47%, op_acc: 37.50%] [G loss: 0.973237]\n",
      "epoch:4 step:3130[D loss: 0.429964, acc: 64.84%, op_acc: 35.94%] [G loss: 0.954672]\n",
      "epoch:4 step:3131[D loss: 0.463163, acc: 55.47%, op_acc: 32.03%] [G loss: 0.912642]\n",
      "epoch:4 step:3132[D loss: 0.464560, acc: 59.38%, op_acc: 31.25%] [G loss: 0.987415]\n",
      "epoch:4 step:3133[D loss: 0.406781, acc: 64.84%, op_acc: 35.94%] [G loss: 0.980650]\n",
      "epoch:4 step:3134[D loss: 0.449900, acc: 57.81%, op_acc: 33.59%] [G loss: 0.893002]\n",
      "epoch:4 step:3135[D loss: 0.469435, acc: 60.94%, op_acc: 26.56%] [G loss: 1.026401]\n",
      "epoch:4 step:3136[D loss: 0.456933, acc: 61.72%, op_acc: 29.69%] [G loss: 0.919343]\n",
      "epoch:4 step:3137[D loss: 0.451046, acc: 67.19%, op_acc: 27.34%] [G loss: 0.920556]\n",
      "epoch:4 step:3138[D loss: 0.463823, acc: 56.25%, op_acc: 25.78%] [G loss: 0.966029]\n",
      "epoch:4 step:3139[D loss: 0.462246, acc: 60.94%, op_acc: 28.91%] [G loss: 0.969757]\n",
      "epoch:4 step:3140[D loss: 0.452246, acc: 57.81%, op_acc: 33.59%] [G loss: 0.951919]\n",
      "epoch:4 step:3141[D loss: 0.478496, acc: 50.78%, op_acc: 28.91%] [G loss: 0.996615]\n",
      "epoch:4 step:3142[D loss: 0.451856, acc: 57.03%, op_acc: 34.38%] [G loss: 0.919881]\n",
      "epoch:4 step:3143[D loss: 0.454065, acc: 64.06%, op_acc: 29.69%] [G loss: 0.925097]\n",
      "epoch:4 step:3144[D loss: 0.440968, acc: 60.16%, op_acc: 33.59%] [G loss: 1.104515]\n",
      "epoch:4 step:3145[D loss: 0.456044, acc: 57.03%, op_acc: 30.47%] [G loss: 0.889912]\n",
      "epoch:4 step:3146[D loss: 0.438011, acc: 60.94%, op_acc: 37.50%] [G loss: 0.978555]\n",
      "epoch:4 step:3147[D loss: 0.468519, acc: 54.69%, op_acc: 35.16%] [G loss: 1.001476]\n",
      "epoch:4 step:3148[D loss: 0.458993, acc: 63.28%, op_acc: 32.03%] [G loss: 0.844981]\n",
      "epoch:4 step:3149[D loss: 0.498457, acc: 56.25%, op_acc: 29.69%] [G loss: 0.956155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3150[D loss: 0.471646, acc: 54.69%, op_acc: 34.38%] [G loss: 0.875738]\n",
      "##############\n",
      "[0.87327615 0.8579081  0.79933556 0.80725615 0.78091241 0.84164887\n",
      " 0.88471377 0.81040961 0.80241436 0.84990975]\n",
      "##########\n",
      "epoch:4 step:3151[D loss: 0.456955, acc: 59.38%, op_acc: 28.91%] [G loss: 0.861015]\n",
      "epoch:4 step:3152[D loss: 0.458918, acc: 58.59%, op_acc: 32.81%] [G loss: 0.918216]\n",
      "epoch:4 step:3153[D loss: 0.473051, acc: 55.47%, op_acc: 32.03%] [G loss: 0.936483]\n",
      "epoch:4 step:3154[D loss: 0.433959, acc: 60.94%, op_acc: 33.59%] [G loss: 1.045414]\n",
      "epoch:4 step:3155[D loss: 0.502842, acc: 51.56%, op_acc: 24.22%] [G loss: 0.979127]\n",
      "epoch:4 step:3156[D loss: 0.454482, acc: 64.84%, op_acc: 27.34%] [G loss: 1.054395]\n",
      "epoch:4 step:3157[D loss: 0.477179, acc: 53.91%, op_acc: 36.72%] [G loss: 0.817510]\n",
      "epoch:4 step:3158[D loss: 0.423437, acc: 67.19%, op_acc: 28.12%] [G loss: 0.959235]\n",
      "epoch:4 step:3159[D loss: 0.455843, acc: 57.81%, op_acc: 32.03%] [G loss: 0.897842]\n",
      "epoch:4 step:3160[D loss: 0.422235, acc: 58.59%, op_acc: 35.16%] [G loss: 0.873587]\n",
      "epoch:4 step:3161[D loss: 0.438394, acc: 64.06%, op_acc: 26.56%] [G loss: 0.924129]\n",
      "epoch:4 step:3162[D loss: 0.434706, acc: 60.94%, op_acc: 34.38%] [G loss: 0.908745]\n",
      "epoch:4 step:3163[D loss: 0.466356, acc: 54.69%, op_acc: 28.12%] [G loss: 0.906581]\n",
      "epoch:4 step:3164[D loss: 0.465974, acc: 54.69%, op_acc: 30.47%] [G loss: 0.896618]\n",
      "epoch:4 step:3165[D loss: 0.454801, acc: 59.38%, op_acc: 31.25%] [G loss: 1.002479]\n",
      "epoch:4 step:3166[D loss: 0.430387, acc: 57.81%, op_acc: 35.94%] [G loss: 0.891954]\n",
      "epoch:4 step:3167[D loss: 0.443380, acc: 67.97%, op_acc: 30.47%] [G loss: 0.927585]\n",
      "epoch:4 step:3168[D loss: 0.423903, acc: 68.75%, op_acc: 39.06%] [G loss: 0.924223]\n",
      "epoch:4 step:3169[D loss: 0.443160, acc: 64.84%, op_acc: 30.47%] [G loss: 0.975252]\n",
      "epoch:4 step:3170[D loss: 0.416449, acc: 67.19%, op_acc: 31.25%] [G loss: 0.953671]\n",
      "epoch:4 step:3171[D loss: 0.476871, acc: 61.72%, op_acc: 25.78%] [G loss: 0.981720]\n",
      "epoch:4 step:3172[D loss: 0.445971, acc: 60.94%, op_acc: 25.78%] [G loss: 0.938692]\n",
      "epoch:4 step:3173[D loss: 0.473089, acc: 57.03%, op_acc: 21.88%] [G loss: 0.965146]\n",
      "epoch:4 step:3174[D loss: 0.484393, acc: 51.56%, op_acc: 28.12%] [G loss: 0.953990]\n",
      "epoch:4 step:3175[D loss: 0.445632, acc: 64.06%, op_acc: 32.03%] [G loss: 1.020311]\n",
      "epoch:4 step:3176[D loss: 0.460561, acc: 59.38%, op_acc: 27.34%] [G loss: 1.072849]\n",
      "epoch:4 step:3177[D loss: 0.482742, acc: 55.47%, op_acc: 28.12%] [G loss: 0.897474]\n",
      "epoch:4 step:3178[D loss: 0.480457, acc: 57.81%, op_acc: 34.38%] [G loss: 1.005889]\n",
      "epoch:4 step:3179[D loss: 0.442219, acc: 64.84%, op_acc: 32.81%] [G loss: 0.891875]\n",
      "epoch:4 step:3180[D loss: 0.472070, acc: 49.22%, op_acc: 28.91%] [G loss: 0.950481]\n",
      "epoch:4 step:3181[D loss: 0.508282, acc: 46.88%, op_acc: 32.03%] [G loss: 1.019735]\n",
      "epoch:4 step:3182[D loss: 0.436772, acc: 63.28%, op_acc: 35.16%] [G loss: 1.093668]\n",
      "epoch:4 step:3183[D loss: 0.449453, acc: 61.72%, op_acc: 32.03%] [G loss: 0.885849]\n",
      "epoch:4 step:3184[D loss: 0.471560, acc: 54.69%, op_acc: 30.47%] [G loss: 0.808930]\n",
      "epoch:4 step:3185[D loss: 0.456513, acc: 60.16%, op_acc: 32.03%] [G loss: 0.968174]\n",
      "epoch:4 step:3186[D loss: 0.482707, acc: 50.78%, op_acc: 28.12%] [G loss: 0.797039]\n",
      "epoch:4 step:3187[D loss: 0.471493, acc: 61.72%, op_acc: 29.69%] [G loss: 0.957389]\n",
      "epoch:4 step:3188[D loss: 0.452886, acc: 60.94%, op_acc: 32.81%] [G loss: 0.905933]\n",
      "epoch:4 step:3189[D loss: 0.441200, acc: 64.06%, op_acc: 33.59%] [G loss: 0.899112]\n",
      "epoch:4 step:3190[D loss: 0.441130, acc: 58.59%, op_acc: 32.81%] [G loss: 0.919041]\n",
      "epoch:4 step:3191[D loss: 0.446345, acc: 65.62%, op_acc: 30.47%] [G loss: 0.903470]\n",
      "epoch:4 step:3192[D loss: 0.471825, acc: 56.25%, op_acc: 27.34%] [G loss: 0.845928]\n",
      "epoch:4 step:3193[D loss: 0.433783, acc: 61.72%, op_acc: 36.72%] [G loss: 0.904100]\n",
      "epoch:4 step:3194[D loss: 0.466123, acc: 58.59%, op_acc: 33.59%] [G loss: 0.840682]\n",
      "epoch:4 step:3195[D loss: 0.493368, acc: 56.25%, op_acc: 24.22%] [G loss: 0.930094]\n",
      "epoch:4 step:3196[D loss: 0.438333, acc: 60.16%, op_acc: 32.81%] [G loss: 0.945527]\n",
      "epoch:4 step:3197[D loss: 0.426211, acc: 61.72%, op_acc: 35.16%] [G loss: 0.949790]\n",
      "epoch:4 step:3198[D loss: 0.402605, acc: 71.88%, op_acc: 35.94%] [G loss: 1.042752]\n",
      "epoch:4 step:3199[D loss: 0.464599, acc: 60.94%, op_acc: 29.69%] [G loss: 0.976301]\n",
      "epoch:4 step:3200[D loss: 0.479106, acc: 54.69%, op_acc: 33.59%] [G loss: 0.815683]\n",
      "##############\n",
      "[0.84188949 0.87739202 0.80106785 0.78596348 0.77252626 0.82550486\n",
      " 0.90135681 0.84918929 0.82728521 0.83026194]\n",
      "##########\n",
      "epoch:4 step:3201[D loss: 0.475571, acc: 57.03%, op_acc: 28.91%] [G loss: 0.955463]\n",
      "epoch:4 step:3202[D loss: 0.461218, acc: 66.41%, op_acc: 25.78%] [G loss: 0.910543]\n",
      "epoch:4 step:3203[D loss: 0.478124, acc: 53.91%, op_acc: 30.47%] [G loss: 1.037153]\n",
      "epoch:4 step:3204[D loss: 0.476503, acc: 63.28%, op_acc: 22.66%] [G loss: 0.942248]\n",
      "epoch:4 step:3205[D loss: 0.473275, acc: 61.72%, op_acc: 34.38%] [G loss: 0.913982]\n",
      "epoch:4 step:3206[D loss: 0.412849, acc: 67.19%, op_acc: 31.25%] [G loss: 0.949205]\n",
      "epoch:4 step:3207[D loss: 0.439410, acc: 64.84%, op_acc: 33.59%] [G loss: 0.963029]\n",
      "epoch:4 step:3208[D loss: 0.473755, acc: 55.47%, op_acc: 32.81%] [G loss: 0.889954]\n",
      "epoch:4 step:3209[D loss: 0.441079, acc: 61.72%, op_acc: 29.69%] [G loss: 0.958016]\n",
      "epoch:4 step:3210[D loss: 0.474196, acc: 57.03%, op_acc: 25.78%] [G loss: 0.901458]\n",
      "epoch:4 step:3211[D loss: 0.460739, acc: 55.47%, op_acc: 26.56%] [G loss: 0.920605]\n",
      "epoch:4 step:3212[D loss: 0.438657, acc: 58.59%, op_acc: 37.50%] [G loss: 0.980808]\n",
      "epoch:4 step:3213[D loss: 0.500855, acc: 52.34%, op_acc: 29.69%] [G loss: 0.981156]\n",
      "epoch:4 step:3214[D loss: 0.445074, acc: 58.59%, op_acc: 32.03%] [G loss: 0.886943]\n",
      "epoch:4 step:3215[D loss: 0.465587, acc: 58.59%, op_acc: 28.12%] [G loss: 0.906294]\n",
      "epoch:4 step:3216[D loss: 0.456988, acc: 61.72%, op_acc: 28.12%] [G loss: 0.957088]\n",
      "epoch:4 step:3217[D loss: 0.442357, acc: 60.16%, op_acc: 30.47%] [G loss: 0.994656]\n",
      "epoch:4 step:3218[D loss: 0.438699, acc: 61.72%, op_acc: 26.56%] [G loss: 0.905425]\n",
      "epoch:4 step:3219[D loss: 0.451846, acc: 58.59%, op_acc: 32.81%] [G loss: 0.980124]\n",
      "epoch:4 step:3220[D loss: 0.484465, acc: 54.69%, op_acc: 28.91%] [G loss: 0.915114]\n",
      "epoch:4 step:3221[D loss: 0.446831, acc: 59.38%, op_acc: 28.91%] [G loss: 0.956760]\n",
      "epoch:4 step:3222[D loss: 0.450812, acc: 65.62%, op_acc: 26.56%] [G loss: 0.996421]\n",
      "epoch:4 step:3223[D loss: 0.454058, acc: 58.59%, op_acc: 32.03%] [G loss: 0.954379]\n",
      "epoch:4 step:3224[D loss: 0.484881, acc: 56.25%, op_acc: 28.91%] [G loss: 0.870723]\n",
      "epoch:4 step:3225[D loss: 0.470559, acc: 59.38%, op_acc: 28.91%] [G loss: 0.863016]\n",
      "epoch:4 step:3226[D loss: 0.449959, acc: 63.28%, op_acc: 32.03%] [G loss: 0.908626]\n",
      "epoch:4 step:3227[D loss: 0.455869, acc: 65.62%, op_acc: 24.22%] [G loss: 0.937405]\n",
      "epoch:4 step:3228[D loss: 0.470285, acc: 58.59%, op_acc: 27.34%] [G loss: 0.927455]\n",
      "epoch:4 step:3229[D loss: 0.505342, acc: 47.66%, op_acc: 26.56%] [G loss: 0.894332]\n",
      "epoch:4 step:3230[D loss: 0.456477, acc: 54.69%, op_acc: 30.47%] [G loss: 0.907083]\n",
      "epoch:4 step:3231[D loss: 0.476063, acc: 50.00%, op_acc: 29.69%] [G loss: 0.933707]\n",
      "epoch:4 step:3232[D loss: 0.480408, acc: 50.00%, op_acc: 35.16%] [G loss: 0.899638]\n",
      "epoch:4 step:3233[D loss: 0.466294, acc: 60.94%, op_acc: 28.12%] [G loss: 0.914000]\n",
      "epoch:4 step:3234[D loss: 0.471771, acc: 54.69%, op_acc: 29.69%] [G loss: 0.903000]\n",
      "epoch:4 step:3235[D loss: 0.440990, acc: 67.97%, op_acc: 35.16%] [G loss: 0.881172]\n",
      "epoch:4 step:3236[D loss: 0.436353, acc: 62.50%, op_acc: 35.94%] [G loss: 0.984020]\n",
      "epoch:4 step:3237[D loss: 0.457802, acc: 65.62%, op_acc: 18.75%] [G loss: 0.889220]\n",
      "epoch:4 step:3238[D loss: 0.446513, acc: 54.69%, op_acc: 37.50%] [G loss: 0.897954]\n",
      "epoch:4 step:3239[D loss: 0.442569, acc: 64.06%, op_acc: 27.34%] [G loss: 0.935250]\n",
      "epoch:4 step:3240[D loss: 0.514449, acc: 57.81%, op_acc: 27.34%] [G loss: 0.871924]\n",
      "epoch:4 step:3241[D loss: 0.459663, acc: 63.28%, op_acc: 29.69%] [G loss: 0.928286]\n",
      "epoch:4 step:3242[D loss: 0.466315, acc: 60.94%, op_acc: 33.59%] [G loss: 0.797547]\n",
      "epoch:4 step:3243[D loss: 0.466798, acc: 57.81%, op_acc: 25.00%] [G loss: 0.937831]\n",
      "epoch:4 step:3244[D loss: 0.466230, acc: 59.38%, op_acc: 31.25%] [G loss: 0.905653]\n",
      "epoch:4 step:3245[D loss: 0.461296, acc: 61.72%, op_acc: 28.12%] [G loss: 0.978743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3246[D loss: 0.454266, acc: 56.25%, op_acc: 31.25%] [G loss: 0.980529]\n",
      "epoch:4 step:3247[D loss: 0.458674, acc: 60.16%, op_acc: 33.59%] [G loss: 0.909760]\n",
      "epoch:4 step:3248[D loss: 0.492002, acc: 52.34%, op_acc: 32.81%] [G loss: 0.913252]\n",
      "epoch:4 step:3249[D loss: 0.480027, acc: 54.69%, op_acc: 25.78%] [G loss: 0.897769]\n",
      "epoch:4 step:3250[D loss: 0.429243, acc: 66.41%, op_acc: 36.72%] [G loss: 1.024971]\n",
      "##############\n",
      "[0.84064087 0.85557426 0.80870293 0.81803462 0.79841674 0.83024238\n",
      " 0.88458018 0.81237275 0.79701644 0.8426818 ]\n",
      "##########\n",
      "epoch:4 step:3251[D loss: 0.483906, acc: 53.12%, op_acc: 28.12%] [G loss: 0.841475]\n",
      "epoch:4 step:3252[D loss: 0.486058, acc: 53.12%, op_acc: 27.34%] [G loss: 0.892915]\n",
      "epoch:4 step:3253[D loss: 0.457354, acc: 60.16%, op_acc: 28.12%] [G loss: 0.968438]\n",
      "epoch:4 step:3254[D loss: 0.469204, acc: 55.47%, op_acc: 34.38%] [G loss: 0.924242]\n",
      "epoch:4 step:3255[D loss: 0.460681, acc: 57.81%, op_acc: 24.22%] [G loss: 0.935290]\n",
      "epoch:4 step:3256[D loss: 0.454520, acc: 53.91%, op_acc: 39.84%] [G loss: 0.882442]\n",
      "epoch:4 step:3257[D loss: 0.507752, acc: 54.69%, op_acc: 25.78%] [G loss: 0.969901]\n",
      "epoch:4 step:3258[D loss: 0.434891, acc: 64.06%, op_acc: 27.34%] [G loss: 0.972035]\n",
      "epoch:4 step:3259[D loss: 0.470819, acc: 57.81%, op_acc: 25.78%] [G loss: 0.866341]\n",
      "epoch:4 step:3260[D loss: 0.467463, acc: 52.34%, op_acc: 31.25%] [G loss: 0.929463]\n",
      "epoch:4 step:3261[D loss: 0.430315, acc: 67.97%, op_acc: 32.03%] [G loss: 0.834585]\n",
      "epoch:4 step:3262[D loss: 0.487923, acc: 54.69%, op_acc: 22.66%] [G loss: 0.896858]\n",
      "epoch:4 step:3263[D loss: 0.458513, acc: 58.59%, op_acc: 32.03%] [G loss: 0.946568]\n",
      "epoch:4 step:3264[D loss: 0.494929, acc: 57.03%, op_acc: 33.59%] [G loss: 0.930376]\n",
      "epoch:4 step:3265[D loss: 0.471251, acc: 61.72%, op_acc: 29.69%] [G loss: 0.892950]\n",
      "epoch:4 step:3266[D loss: 0.497636, acc: 51.56%, op_acc: 26.56%] [G loss: 0.925129]\n",
      "epoch:4 step:3267[D loss: 0.441531, acc: 64.06%, op_acc: 31.25%] [G loss: 0.913666]\n",
      "epoch:4 step:3268[D loss: 0.450582, acc: 57.81%, op_acc: 28.91%] [G loss: 0.887343]\n",
      "epoch:4 step:3269[D loss: 0.457624, acc: 59.38%, op_acc: 32.81%] [G loss: 0.834160]\n",
      "epoch:4 step:3270[D loss: 0.434482, acc: 62.50%, op_acc: 35.16%] [G loss: 0.948439]\n",
      "epoch:4 step:3271[D loss: 0.472659, acc: 54.69%, op_acc: 32.81%] [G loss: 0.895907]\n",
      "epoch:4 step:3272[D loss: 0.457122, acc: 55.47%, op_acc: 32.81%] [G loss: 0.892030]\n",
      "epoch:4 step:3273[D loss: 0.433071, acc: 60.16%, op_acc: 32.81%] [G loss: 0.972159]\n",
      "epoch:4 step:3274[D loss: 0.468126, acc: 57.03%, op_acc: 32.03%] [G loss: 0.950649]\n",
      "epoch:4 step:3275[D loss: 0.503373, acc: 50.78%, op_acc: 32.03%] [G loss: 0.853647]\n",
      "epoch:4 step:3276[D loss: 0.472803, acc: 50.00%, op_acc: 29.69%] [G loss: 0.876510]\n",
      "epoch:4 step:3277[D loss: 0.468204, acc: 54.69%, op_acc: 35.94%] [G loss: 0.851587]\n",
      "epoch:4 step:3278[D loss: 0.471793, acc: 56.25%, op_acc: 32.81%] [G loss: 0.976362]\n",
      "epoch:4 step:3279[D loss: 0.465473, acc: 59.38%, op_acc: 28.12%] [G loss: 0.931300]\n",
      "epoch:4 step:3280[D loss: 0.453078, acc: 58.59%, op_acc: 32.81%] [G loss: 0.859978]\n",
      "epoch:4 step:3281[D loss: 0.427235, acc: 66.41%, op_acc: 28.12%] [G loss: 0.959052]\n",
      "epoch:4 step:3282[D loss: 0.483799, acc: 52.34%, op_acc: 28.12%] [G loss: 0.936801]\n",
      "epoch:4 step:3283[D loss: 0.457472, acc: 57.81%, op_acc: 31.25%] [G loss: 0.921407]\n",
      "epoch:4 step:3284[D loss: 0.481698, acc: 60.94%, op_acc: 27.34%] [G loss: 0.892783]\n",
      "epoch:4 step:3285[D loss: 0.483006, acc: 51.56%, op_acc: 30.47%] [G loss: 0.932283]\n",
      "epoch:4 step:3286[D loss: 0.405787, acc: 67.97%, op_acc: 40.62%] [G loss: 1.034558]\n",
      "epoch:4 step:3287[D loss: 0.470878, acc: 59.38%, op_acc: 29.69%] [G loss: 0.944784]\n",
      "epoch:4 step:3288[D loss: 0.477041, acc: 54.69%, op_acc: 26.56%] [G loss: 1.008053]\n",
      "epoch:4 step:3289[D loss: 0.446993, acc: 58.59%, op_acc: 32.81%] [G loss: 0.960492]\n",
      "epoch:4 step:3290[D loss: 0.444175, acc: 63.28%, op_acc: 36.72%] [G loss: 0.951205]\n",
      "epoch:4 step:3291[D loss: 0.416333, acc: 64.06%, op_acc: 36.72%] [G loss: 0.953268]\n",
      "epoch:4 step:3292[D loss: 0.460705, acc: 53.91%, op_acc: 35.94%] [G loss: 0.875354]\n",
      "epoch:4 step:3293[D loss: 0.443352, acc: 64.06%, op_acc: 35.16%] [G loss: 0.787795]\n",
      "epoch:4 step:3294[D loss: 0.471226, acc: 59.38%, op_acc: 30.47%] [G loss: 0.881550]\n",
      "epoch:4 step:3295[D loss: 0.462079, acc: 65.62%, op_acc: 26.56%] [G loss: 0.868710]\n",
      "epoch:4 step:3296[D loss: 0.435004, acc: 60.94%, op_acc: 35.16%] [G loss: 0.921287]\n",
      "epoch:4 step:3297[D loss: 0.446311, acc: 63.28%, op_acc: 27.34%] [G loss: 0.971711]\n",
      "epoch:4 step:3298[D loss: 0.457724, acc: 65.62%, op_acc: 25.78%] [G loss: 0.928969]\n",
      "epoch:4 step:3299[D loss: 0.458662, acc: 62.50%, op_acc: 30.47%] [G loss: 0.915186]\n",
      "epoch:4 step:3300[D loss: 0.446142, acc: 63.28%, op_acc: 32.03%] [G loss: 0.959341]\n",
      "##############\n",
      "[0.84252276 0.84430703 0.80404518 0.80077744 0.7994198  0.81764371\n",
      " 0.88903748 0.82803833 0.79992153 0.83619629]\n",
      "##########\n",
      "epoch:4 step:3301[D loss: 0.425319, acc: 62.50%, op_acc: 32.03%] [G loss: 0.850324]\n",
      "epoch:4 step:3302[D loss: 0.447499, acc: 60.94%, op_acc: 28.12%] [G loss: 0.985425]\n",
      "epoch:4 step:3303[D loss: 0.434003, acc: 61.72%, op_acc: 33.59%] [G loss: 1.014913]\n",
      "epoch:4 step:3304[D loss: 0.431394, acc: 71.88%, op_acc: 28.91%] [G loss: 0.972909]\n",
      "epoch:4 step:3305[D loss: 0.431845, acc: 61.72%, op_acc: 32.03%] [G loss: 0.972162]\n",
      "epoch:4 step:3306[D loss: 0.437402, acc: 64.84%, op_acc: 33.59%] [G loss: 0.870921]\n",
      "epoch:4 step:3307[D loss: 0.463583, acc: 62.50%, op_acc: 31.25%] [G loss: 0.856272]\n",
      "epoch:4 step:3308[D loss: 0.412845, acc: 67.19%, op_acc: 30.47%] [G loss: 0.963386]\n",
      "epoch:4 step:3309[D loss: 0.478929, acc: 59.38%, op_acc: 25.78%] [G loss: 0.932816]\n",
      "epoch:4 step:3310[D loss: 0.473234, acc: 55.47%, op_acc: 32.81%] [G loss: 0.931272]\n",
      "epoch:4 step:3311[D loss: 0.461009, acc: 58.59%, op_acc: 32.81%] [G loss: 1.015675]\n",
      "epoch:4 step:3312[D loss: 0.455080, acc: 53.12%, op_acc: 39.84%] [G loss: 1.049920]\n",
      "epoch:4 step:3313[D loss: 0.472019, acc: 57.81%, op_acc: 34.38%] [G loss: 0.895912]\n",
      "epoch:4 step:3314[D loss: 0.469784, acc: 59.38%, op_acc: 28.91%] [G loss: 0.965756]\n",
      "epoch:4 step:3315[D loss: 0.438468, acc: 55.47%, op_acc: 36.72%] [G loss: 0.949337]\n",
      "epoch:4 step:3316[D loss: 0.437804, acc: 66.41%, op_acc: 32.03%] [G loss: 0.890925]\n",
      "epoch:4 step:3317[D loss: 0.452824, acc: 64.84%, op_acc: 28.12%] [G loss: 0.863892]\n",
      "epoch:4 step:3318[D loss: 0.439292, acc: 60.94%, op_acc: 31.25%] [G loss: 0.941392]\n",
      "epoch:4 step:3319[D loss: 0.488125, acc: 53.91%, op_acc: 29.69%] [G loss: 0.916837]\n",
      "epoch:4 step:3320[D loss: 0.474675, acc: 59.38%, op_acc: 28.91%] [G loss: 0.878701]\n",
      "epoch:4 step:3321[D loss: 0.459563, acc: 60.16%, op_acc: 31.25%] [G loss: 0.974157]\n",
      "epoch:4 step:3322[D loss: 0.438120, acc: 64.84%, op_acc: 30.47%] [G loss: 0.869414]\n",
      "epoch:4 step:3323[D loss: 0.451531, acc: 58.59%, op_acc: 31.25%] [G loss: 1.004219]\n",
      "epoch:4 step:3324[D loss: 0.456499, acc: 60.94%, op_acc: 27.34%] [G loss: 0.934401]\n",
      "epoch:4 step:3325[D loss: 0.425929, acc: 60.16%, op_acc: 39.84%] [G loss: 0.956575]\n",
      "epoch:4 step:3326[D loss: 0.465125, acc: 61.72%, op_acc: 25.78%] [G loss: 0.976628]\n",
      "epoch:4 step:3327[D loss: 0.453239, acc: 65.62%, op_acc: 28.12%] [G loss: 0.981235]\n",
      "epoch:4 step:3328[D loss: 0.477466, acc: 57.81%, op_acc: 30.47%] [G loss: 0.928838]\n",
      "epoch:4 step:3329[D loss: 0.434139, acc: 69.53%, op_acc: 30.47%] [G loss: 0.912744]\n",
      "epoch:4 step:3330[D loss: 0.472343, acc: 53.12%, op_acc: 31.25%] [G loss: 0.871100]\n",
      "epoch:4 step:3331[D loss: 0.426934, acc: 71.09%, op_acc: 35.16%] [G loss: 0.953927]\n",
      "epoch:4 step:3332[D loss: 0.457712, acc: 58.59%, op_acc: 34.38%] [G loss: 0.958323]\n",
      "epoch:4 step:3333[D loss: 0.457322, acc: 58.59%, op_acc: 35.94%] [G loss: 0.953299]\n",
      "epoch:4 step:3334[D loss: 0.482314, acc: 57.03%, op_acc: 32.81%] [G loss: 0.878105]\n",
      "epoch:4 step:3335[D loss: 0.441358, acc: 59.38%, op_acc: 32.81%] [G loss: 0.962602]\n",
      "epoch:4 step:3336[D loss: 0.483476, acc: 55.47%, op_acc: 25.78%] [G loss: 0.908375]\n",
      "epoch:4 step:3337[D loss: 0.477536, acc: 55.47%, op_acc: 36.72%] [G loss: 0.889573]\n",
      "epoch:4 step:3338[D loss: 0.454999, acc: 64.84%, op_acc: 29.69%] [G loss: 0.964134]\n",
      "epoch:4 step:3339[D loss: 0.471144, acc: 60.16%, op_acc: 28.12%] [G loss: 0.958524]\n",
      "epoch:4 step:3340[D loss: 0.474471, acc: 60.94%, op_acc: 28.91%] [G loss: 0.892150]\n",
      "epoch:4 step:3341[D loss: 0.448638, acc: 59.38%, op_acc: 34.38%] [G loss: 0.978265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3342[D loss: 0.448177, acc: 62.50%, op_acc: 31.25%] [G loss: 0.923605]\n",
      "epoch:4 step:3343[D loss: 0.449976, acc: 57.03%, op_acc: 30.47%] [G loss: 0.980101]\n",
      "epoch:4 step:3344[D loss: 0.453298, acc: 55.47%, op_acc: 35.16%] [G loss: 0.929528]\n",
      "epoch:4 step:3345[D loss: 0.469770, acc: 55.47%, op_acc: 25.78%] [G loss: 0.930661]\n",
      "epoch:4 step:3346[D loss: 0.423879, acc: 71.09%, op_acc: 31.25%] [G loss: 0.987270]\n",
      "epoch:4 step:3347[D loss: 0.463953, acc: 55.47%, op_acc: 30.47%] [G loss: 0.984698]\n",
      "epoch:4 step:3348[D loss: 0.434500, acc: 67.97%, op_acc: 24.22%] [G loss: 0.920673]\n",
      "epoch:4 step:3349[D loss: 0.449982, acc: 62.50%, op_acc: 29.69%] [G loss: 0.969411]\n",
      "epoch:4 step:3350[D loss: 0.452020, acc: 58.59%, op_acc: 37.50%] [G loss: 0.929336]\n",
      "##############\n",
      "[0.840705   0.88921736 0.81521437 0.78427273 0.79275197 0.84061331\n",
      " 0.8828739  0.82593891 0.80534608 0.81656547]\n",
      "##########\n",
      "epoch:4 step:3351[D loss: 0.467819, acc: 55.47%, op_acc: 25.78%] [G loss: 1.008615]\n",
      "epoch:4 step:3352[D loss: 0.475605, acc: 58.59%, op_acc: 28.91%] [G loss: 0.827262]\n",
      "epoch:4 step:3353[D loss: 0.442605, acc: 62.50%, op_acc: 31.25%] [G loss: 0.830990]\n",
      "epoch:4 step:3354[D loss: 0.437746, acc: 64.84%, op_acc: 22.66%] [G loss: 0.949116]\n",
      "epoch:4 step:3355[D loss: 0.439821, acc: 60.94%, op_acc: 32.81%] [G loss: 0.985310]\n",
      "epoch:4 step:3356[D loss: 0.467962, acc: 58.59%, op_acc: 30.47%] [G loss: 0.940188]\n",
      "epoch:4 step:3357[D loss: 0.470977, acc: 53.91%, op_acc: 27.34%] [G loss: 0.929845]\n",
      "epoch:4 step:3358[D loss: 0.487719, acc: 56.25%, op_acc: 28.91%] [G loss: 0.862140]\n",
      "epoch:4 step:3359[D loss: 0.456305, acc: 57.03%, op_acc: 34.38%] [G loss: 1.032696]\n",
      "epoch:4 step:3360[D loss: 0.454120, acc: 62.50%, op_acc: 33.59%] [G loss: 1.055781]\n",
      "epoch:4 step:3361[D loss: 0.450612, acc: 58.59%, op_acc: 31.25%] [G loss: 0.964745]\n",
      "epoch:4 step:3362[D loss: 0.450942, acc: 65.62%, op_acc: 30.47%] [G loss: 0.858964]\n",
      "epoch:4 step:3363[D loss: 0.430964, acc: 64.06%, op_acc: 31.25%] [G loss: 0.863910]\n",
      "epoch:4 step:3364[D loss: 0.434983, acc: 64.06%, op_acc: 28.91%] [G loss: 0.955041]\n",
      "epoch:4 step:3365[D loss: 0.474379, acc: 57.81%, op_acc: 28.12%] [G loss: 0.889316]\n",
      "epoch:4 step:3366[D loss: 0.433300, acc: 64.06%, op_acc: 31.25%] [G loss: 0.938978]\n",
      "epoch:4 step:3367[D loss: 0.421575, acc: 65.62%, op_acc: 33.59%] [G loss: 1.002594]\n",
      "epoch:4 step:3368[D loss: 0.439518, acc: 64.84%, op_acc: 30.47%] [G loss: 0.897140]\n",
      "epoch:4 step:3369[D loss: 0.438779, acc: 62.50%, op_acc: 32.03%] [G loss: 1.013144]\n",
      "epoch:4 step:3370[D loss: 0.429665, acc: 68.75%, op_acc: 33.59%] [G loss: 0.983321]\n",
      "epoch:4 step:3371[D loss: 0.435850, acc: 63.28%, op_acc: 34.38%] [G loss: 0.893587]\n",
      "epoch:4 step:3372[D loss: 0.474858, acc: 53.91%, op_acc: 23.44%] [G loss: 0.915575]\n",
      "epoch:4 step:3373[D loss: 0.466220, acc: 55.47%, op_acc: 29.69%] [G loss: 0.941262]\n",
      "epoch:4 step:3374[D loss: 0.488201, acc: 54.69%, op_acc: 28.12%] [G loss: 0.811676]\n",
      "epoch:4 step:3375[D loss: 0.484403, acc: 50.78%, op_acc: 29.69%] [G loss: 0.864751]\n",
      "epoch:4 step:3376[D loss: 0.473651, acc: 57.03%, op_acc: 32.03%] [G loss: 0.921394]\n",
      "epoch:4 step:3377[D loss: 0.458138, acc: 57.03%, op_acc: 32.03%] [G loss: 0.883728]\n",
      "epoch:4 step:3378[D loss: 0.487579, acc: 60.16%, op_acc: 32.81%] [G loss: 0.920176]\n",
      "epoch:4 step:3379[D loss: 0.467345, acc: 54.69%, op_acc: 30.47%] [G loss: 0.968446]\n",
      "epoch:4 step:3380[D loss: 0.461851, acc: 54.69%, op_acc: 32.03%] [G loss: 0.962886]\n",
      "epoch:4 step:3381[D loss: 0.457161, acc: 62.50%, op_acc: 28.12%] [G loss: 0.951049]\n",
      "epoch:4 step:3382[D loss: 0.430182, acc: 63.28%, op_acc: 38.28%] [G loss: 0.943932]\n",
      "epoch:4 step:3383[D loss: 0.444872, acc: 58.59%, op_acc: 32.03%] [G loss: 0.968886]\n",
      "epoch:4 step:3384[D loss: 0.464982, acc: 62.50%, op_acc: 32.03%] [G loss: 0.850530]\n",
      "epoch:4 step:3385[D loss: 0.476923, acc: 54.69%, op_acc: 39.06%] [G loss: 0.957155]\n",
      "epoch:4 step:3386[D loss: 0.409158, acc: 69.53%, op_acc: 33.59%] [G loss: 0.938027]\n",
      "epoch:4 step:3387[D loss: 0.437908, acc: 63.28%, op_acc: 35.94%] [G loss: 0.924426]\n",
      "epoch:4 step:3388[D loss: 0.467289, acc: 64.06%, op_acc: 26.56%] [G loss: 0.884994]\n",
      "epoch:4 step:3389[D loss: 0.413311, acc: 65.62%, op_acc: 35.94%] [G loss: 0.908074]\n",
      "epoch:4 step:3390[D loss: 0.441657, acc: 62.50%, op_acc: 34.38%] [G loss: 0.934257]\n",
      "epoch:4 step:3391[D loss: 0.465754, acc: 56.25%, op_acc: 30.47%] [G loss: 0.892650]\n",
      "epoch:4 step:3392[D loss: 0.415325, acc: 71.88%, op_acc: 39.84%] [G loss: 0.912197]\n",
      "epoch:4 step:3393[D loss: 0.407337, acc: 70.31%, op_acc: 35.94%] [G loss: 0.950467]\n",
      "epoch:4 step:3394[D loss: 0.463919, acc: 60.94%, op_acc: 29.69%] [G loss: 0.805238]\n",
      "epoch:4 step:3395[D loss: 0.467017, acc: 61.72%, op_acc: 31.25%] [G loss: 0.850435]\n",
      "epoch:4 step:3396[D loss: 0.474339, acc: 56.25%, op_acc: 28.12%] [G loss: 0.918950]\n",
      "epoch:4 step:3397[D loss: 0.435856, acc: 62.50%, op_acc: 32.81%] [G loss: 0.866229]\n",
      "epoch:4 step:3398[D loss: 0.467134, acc: 64.06%, op_acc: 31.25%] [G loss: 0.896673]\n",
      "epoch:4 step:3399[D loss: 0.460225, acc: 55.47%, op_acc: 31.25%] [G loss: 0.917225]\n",
      "epoch:4 step:3400[D loss: 0.436481, acc: 66.41%, op_acc: 36.72%] [G loss: 0.870938]\n",
      "##############\n",
      "[0.86922117 0.85801747 0.81333381 0.79351603 0.81109553 0.81489828\n",
      " 0.89572507 0.8021716  0.81042229 0.8570653 ]\n",
      "##########\n",
      "epoch:4 step:3401[D loss: 0.480288, acc: 58.59%, op_acc: 27.34%] [G loss: 0.849365]\n",
      "epoch:4 step:3402[D loss: 0.455726, acc: 59.38%, op_acc: 33.59%] [G loss: 0.846779]\n",
      "epoch:4 step:3403[D loss: 0.427042, acc: 70.31%, op_acc: 30.47%] [G loss: 0.996984]\n",
      "epoch:4 step:3404[D loss: 0.412372, acc: 64.84%, op_acc: 38.28%] [G loss: 0.967252]\n",
      "epoch:4 step:3405[D loss: 0.472271, acc: 57.03%, op_acc: 28.91%] [G loss: 0.883335]\n",
      "epoch:4 step:3406[D loss: 0.445846, acc: 59.38%, op_acc: 32.03%] [G loss: 0.950586]\n",
      "epoch:4 step:3407[D loss: 0.417022, acc: 71.09%, op_acc: 32.81%] [G loss: 0.939310]\n",
      "epoch:4 step:3408[D loss: 0.459876, acc: 56.25%, op_acc: 32.81%] [G loss: 0.987946]\n",
      "epoch:4 step:3409[D loss: 0.422284, acc: 67.19%, op_acc: 31.25%] [G loss: 0.906387]\n",
      "epoch:4 step:3410[D loss: 0.427487, acc: 61.72%, op_acc: 33.59%] [G loss: 0.877838]\n",
      "epoch:4 step:3411[D loss: 0.459158, acc: 59.38%, op_acc: 35.94%] [G loss: 0.939841]\n",
      "epoch:4 step:3412[D loss: 0.453466, acc: 54.69%, op_acc: 32.81%] [G loss: 0.836149]\n",
      "epoch:4 step:3413[D loss: 0.451617, acc: 64.06%, op_acc: 32.03%] [G loss: 0.936505]\n",
      "epoch:4 step:3414[D loss: 0.462189, acc: 57.03%, op_acc: 32.03%] [G loss: 0.891779]\n",
      "epoch:4 step:3415[D loss: 0.437848, acc: 64.06%, op_acc: 31.25%] [G loss: 0.992891]\n",
      "epoch:4 step:3416[D loss: 0.477519, acc: 57.03%, op_acc: 31.25%] [G loss: 0.962552]\n",
      "epoch:4 step:3417[D loss: 0.449085, acc: 60.94%, op_acc: 30.47%] [G loss: 0.962586]\n",
      "epoch:4 step:3418[D loss: 0.458114, acc: 53.91%, op_acc: 33.59%] [G loss: 0.913497]\n",
      "epoch:4 step:3419[D loss: 0.446197, acc: 60.16%, op_acc: 35.16%] [G loss: 0.987025]\n",
      "epoch:4 step:3420[D loss: 0.449880, acc: 59.38%, op_acc: 35.16%] [G loss: 0.897660]\n",
      "epoch:4 step:3421[D loss: 0.471129, acc: 57.03%, op_acc: 27.34%] [G loss: 0.969832]\n",
      "epoch:4 step:3422[D loss: 0.439402, acc: 63.28%, op_acc: 32.03%] [G loss: 0.804633]\n",
      "epoch:4 step:3423[D loss: 0.436038, acc: 62.50%, op_acc: 33.59%] [G loss: 0.948598]\n",
      "epoch:4 step:3424[D loss: 0.469233, acc: 57.03%, op_acc: 31.25%] [G loss: 0.913985]\n",
      "epoch:4 step:3425[D loss: 0.466530, acc: 53.12%, op_acc: 32.81%] [G loss: 0.941368]\n",
      "epoch:4 step:3426[D loss: 0.463518, acc: 53.12%, op_acc: 30.47%] [G loss: 0.946234]\n",
      "epoch:4 step:3427[D loss: 0.434232, acc: 65.62%, op_acc: 29.69%] [G loss: 1.062768]\n",
      "epoch:4 step:3428[D loss: 0.469326, acc: 54.69%, op_acc: 25.78%] [G loss: 0.889695]\n",
      "epoch:4 step:3429[D loss: 0.461931, acc: 56.25%, op_acc: 28.12%] [G loss: 0.926497]\n",
      "epoch:4 step:3430[D loss: 0.478019, acc: 58.59%, op_acc: 30.47%] [G loss: 0.892408]\n",
      "epoch:4 step:3431[D loss: 0.432559, acc: 67.19%, op_acc: 35.94%] [G loss: 0.943766]\n",
      "epoch:4 step:3432[D loss: 0.429717, acc: 65.62%, op_acc: 25.78%] [G loss: 1.004495]\n",
      "epoch:4 step:3433[D loss: 0.469496, acc: 60.16%, op_acc: 25.00%] [G loss: 0.888383]\n",
      "epoch:4 step:3434[D loss: 0.466248, acc: 58.59%, op_acc: 31.25%] [G loss: 0.945330]\n",
      "epoch:4 step:3435[D loss: 0.497546, acc: 50.00%, op_acc: 30.47%] [G loss: 0.904601]\n",
      "epoch:4 step:3436[D loss: 0.455384, acc: 52.34%, op_acc: 34.38%] [G loss: 0.934591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3437[D loss: 0.501093, acc: 55.47%, op_acc: 27.34%] [G loss: 0.923846]\n",
      "epoch:4 step:3438[D loss: 0.471398, acc: 53.91%, op_acc: 28.12%] [G loss: 1.035234]\n",
      "epoch:4 step:3439[D loss: 0.460669, acc: 65.62%, op_acc: 28.12%] [G loss: 0.910910]\n",
      "epoch:4 step:3440[D loss: 0.471429, acc: 60.16%, op_acc: 26.56%] [G loss: 0.815434]\n",
      "epoch:4 step:3441[D loss: 0.480315, acc: 54.69%, op_acc: 30.47%] [G loss: 0.841827]\n",
      "epoch:4 step:3442[D loss: 0.464279, acc: 60.16%, op_acc: 25.78%] [G loss: 0.822142]\n",
      "epoch:4 step:3443[D loss: 0.462545, acc: 55.47%, op_acc: 35.94%] [G loss: 0.950897]\n",
      "epoch:4 step:3444[D loss: 0.456122, acc: 63.28%, op_acc: 24.22%] [G loss: 0.971075]\n",
      "epoch:4 step:3445[D loss: 0.499276, acc: 54.69%, op_acc: 30.47%] [G loss: 0.808877]\n",
      "epoch:4 step:3446[D loss: 0.437949, acc: 60.16%, op_acc: 31.25%] [G loss: 1.015481]\n",
      "epoch:4 step:3447[D loss: 0.467088, acc: 54.69%, op_acc: 32.03%] [G loss: 0.908266]\n",
      "epoch:4 step:3448[D loss: 0.450474, acc: 63.28%, op_acc: 29.69%] [G loss: 0.902496]\n",
      "epoch:4 step:3449[D loss: 0.468932, acc: 57.81%, op_acc: 29.69%] [G loss: 0.895114]\n",
      "epoch:4 step:3450[D loss: 0.443166, acc: 60.94%, op_acc: 32.81%] [G loss: 0.918676]\n",
      "##############\n",
      "[0.86658887 0.87261443 0.81837424 0.79121597 0.7755705  0.82452105\n",
      " 0.89186161 0.83236527 0.79833368 0.82152213]\n",
      "##########\n",
      "epoch:4 step:3451[D loss: 0.444910, acc: 58.59%, op_acc: 28.91%] [G loss: 0.826394]\n",
      "epoch:4 step:3452[D loss: 0.446973, acc: 57.03%, op_acc: 34.38%] [G loss: 0.937200]\n",
      "epoch:4 step:3453[D loss: 0.438769, acc: 60.16%, op_acc: 35.16%] [G loss: 0.868157]\n",
      "epoch:4 step:3454[D loss: 0.449937, acc: 61.72%, op_acc: 35.16%] [G loss: 1.003304]\n",
      "epoch:4 step:3455[D loss: 0.420018, acc: 65.62%, op_acc: 27.34%] [G loss: 0.910826]\n",
      "epoch:4 step:3456[D loss: 0.407441, acc: 66.41%, op_acc: 38.28%] [G loss: 0.943575]\n",
      "epoch:4 step:3457[D loss: 0.445691, acc: 61.72%, op_acc: 33.59%] [G loss: 0.888951]\n",
      "epoch:4 step:3458[D loss: 0.465309, acc: 53.91%, op_acc: 26.56%] [G loss: 0.983068]\n",
      "epoch:4 step:3459[D loss: 0.499783, acc: 53.12%, op_acc: 24.22%] [G loss: 0.908492]\n",
      "epoch:4 step:3460[D loss: 0.452671, acc: 60.94%, op_acc: 32.81%] [G loss: 1.020759]\n",
      "epoch:4 step:3461[D loss: 0.451771, acc: 62.50%, op_acc: 32.03%] [G loss: 0.853124]\n",
      "epoch:4 step:3462[D loss: 0.417449, acc: 60.16%, op_acc: 39.06%] [G loss: 0.941057]\n",
      "epoch:4 step:3463[D loss: 0.427647, acc: 65.62%, op_acc: 28.12%] [G loss: 0.888085]\n",
      "epoch:4 step:3464[D loss: 0.461108, acc: 57.81%, op_acc: 32.03%] [G loss: 0.886627]\n",
      "epoch:4 step:3465[D loss: 0.500286, acc: 48.44%, op_acc: 30.47%] [G loss: 0.967863]\n",
      "epoch:4 step:3466[D loss: 0.458397, acc: 55.47%, op_acc: 31.25%] [G loss: 0.960250]\n",
      "epoch:4 step:3467[D loss: 0.464475, acc: 57.81%, op_acc: 28.12%] [G loss: 0.907274]\n",
      "epoch:4 step:3468[D loss: 0.480708, acc: 53.91%, op_acc: 31.25%] [G loss: 0.858232]\n",
      "epoch:4 step:3469[D loss: 0.468644, acc: 59.38%, op_acc: 32.81%] [G loss: 0.937785]\n",
      "epoch:4 step:3470[D loss: 0.412958, acc: 69.53%, op_acc: 28.91%] [G loss: 0.939676]\n",
      "epoch:4 step:3471[D loss: 0.484791, acc: 52.34%, op_acc: 28.91%] [G loss: 0.841090]\n",
      "epoch:4 step:3472[D loss: 0.445665, acc: 64.84%, op_acc: 30.47%] [G loss: 0.911543]\n",
      "epoch:4 step:3473[D loss: 0.441028, acc: 60.16%, op_acc: 35.94%] [G loss: 0.965876]\n",
      "epoch:4 step:3474[D loss: 0.487932, acc: 48.44%, op_acc: 28.12%] [G loss: 0.884163]\n",
      "epoch:4 step:3475[D loss: 0.450537, acc: 57.81%, op_acc: 31.25%] [G loss: 0.873074]\n",
      "epoch:4 step:3476[D loss: 0.460258, acc: 61.72%, op_acc: 27.34%] [G loss: 0.871596]\n",
      "epoch:4 step:3477[D loss: 0.458996, acc: 50.78%, op_acc: 39.06%] [G loss: 0.879589]\n",
      "epoch:4 step:3478[D loss: 0.425571, acc: 70.31%, op_acc: 33.59%] [G loss: 0.969055]\n",
      "epoch:4 step:3479[D loss: 0.484590, acc: 48.44%, op_acc: 31.25%] [G loss: 0.885429]\n",
      "epoch:4 step:3480[D loss: 0.479112, acc: 50.00%, op_acc: 32.81%] [G loss: 0.968626]\n",
      "epoch:4 step:3481[D loss: 0.454818, acc: 63.28%, op_acc: 36.72%] [G loss: 0.824571]\n",
      "epoch:4 step:3482[D loss: 0.460437, acc: 62.50%, op_acc: 32.03%] [G loss: 0.876183]\n",
      "epoch:4 step:3483[D loss: 0.451737, acc: 55.47%, op_acc: 33.59%] [G loss: 0.824624]\n",
      "epoch:4 step:3484[D loss: 0.450332, acc: 59.38%, op_acc: 34.38%] [G loss: 0.994864]\n",
      "epoch:4 step:3485[D loss: 0.452936, acc: 63.28%, op_acc: 32.03%] [G loss: 0.954820]\n",
      "epoch:4 step:3486[D loss: 0.426992, acc: 61.72%, op_acc: 33.59%] [G loss: 0.977447]\n",
      "epoch:4 step:3487[D loss: 0.474138, acc: 63.28%, op_acc: 28.12%] [G loss: 0.885688]\n",
      "epoch:4 step:3488[D loss: 0.507372, acc: 50.00%, op_acc: 26.56%] [G loss: 0.858127]\n",
      "epoch:4 step:3489[D loss: 0.448077, acc: 58.59%, op_acc: 34.38%] [G loss: 0.938835]\n",
      "epoch:4 step:3490[D loss: 0.439946, acc: 60.16%, op_acc: 32.81%] [G loss: 0.947945]\n",
      "epoch:4 step:3491[D loss: 0.433988, acc: 65.62%, op_acc: 35.94%] [G loss: 0.935600]\n",
      "epoch:4 step:3492[D loss: 0.436857, acc: 70.31%, op_acc: 35.94%] [G loss: 1.012924]\n",
      "epoch:4 step:3493[D loss: 0.444756, acc: 62.50%, op_acc: 32.81%] [G loss: 0.971609]\n",
      "epoch:4 step:3494[D loss: 0.444652, acc: 65.62%, op_acc: 33.59%] [G loss: 0.934609]\n",
      "epoch:4 step:3495[D loss: 0.409211, acc: 61.72%, op_acc: 36.72%] [G loss: 0.941417]\n",
      "epoch:4 step:3496[D loss: 0.427382, acc: 65.62%, op_acc: 32.81%] [G loss: 0.855562]\n",
      "epoch:4 step:3497[D loss: 0.457534, acc: 62.50%, op_acc: 28.91%] [G loss: 0.921030]\n",
      "epoch:4 step:3498[D loss: 0.459679, acc: 54.69%, op_acc: 39.06%] [G loss: 0.881739]\n",
      "epoch:4 step:3499[D loss: 0.446214, acc: 61.72%, op_acc: 31.25%] [G loss: 0.957941]\n",
      "epoch:4 step:3500[D loss: 0.440621, acc: 60.16%, op_acc: 35.16%] [G loss: 0.996766]\n",
      "##############\n",
      "[0.85653387 0.86011079 0.80988508 0.81466685 0.79001044 0.82969378\n",
      " 0.87368444 0.80374853 0.80074631 0.860167  ]\n",
      "##########\n",
      "epoch:4 step:3501[D loss: 0.455332, acc: 58.59%, op_acc: 32.03%] [G loss: 0.848812]\n",
      "epoch:4 step:3502[D loss: 0.443218, acc: 59.38%, op_acc: 31.25%] [G loss: 0.918742]\n",
      "epoch:4 step:3503[D loss: 0.440747, acc: 62.50%, op_acc: 37.50%] [G loss: 0.995875]\n",
      "epoch:4 step:3504[D loss: 0.469953, acc: 52.34%, op_acc: 33.59%] [G loss: 0.988490]\n",
      "epoch:4 step:3505[D loss: 0.449593, acc: 64.84%, op_acc: 32.03%] [G loss: 0.899342]\n",
      "epoch:4 step:3506[D loss: 0.435484, acc: 64.84%, op_acc: 37.50%] [G loss: 0.985027]\n",
      "epoch:4 step:3507[D loss: 0.458714, acc: 52.34%, op_acc: 30.47%] [G loss: 0.967825]\n",
      "epoch:4 step:3508[D loss: 0.431521, acc: 60.16%, op_acc: 31.25%] [G loss: 1.017409]\n",
      "epoch:4 step:3509[D loss: 0.430299, acc: 68.75%, op_acc: 33.59%] [G loss: 0.939340]\n",
      "epoch:4 step:3510[D loss: 0.477465, acc: 53.91%, op_acc: 32.81%] [G loss: 0.845282]\n",
      "epoch:4 step:3511[D loss: 0.467661, acc: 57.03%, op_acc: 31.25%] [G loss: 0.934671]\n",
      "epoch:4 step:3512[D loss: 0.479979, acc: 57.03%, op_acc: 32.03%] [G loss: 0.947339]\n",
      "epoch:4 step:3513[D loss: 0.475761, acc: 59.38%, op_acc: 28.12%] [G loss: 0.948385]\n",
      "epoch:4 step:3514[D loss: 0.446902, acc: 60.16%, op_acc: 30.47%] [G loss: 0.898346]\n",
      "epoch:4 step:3515[D loss: 0.426169, acc: 61.72%, op_acc: 37.50%] [G loss: 0.941536]\n",
      "epoch:4 step:3516[D loss: 0.417275, acc: 67.97%, op_acc: 33.59%] [G loss: 1.027400]\n",
      "epoch:4 step:3517[D loss: 0.475029, acc: 52.34%, op_acc: 30.47%] [G loss: 0.990691]\n",
      "epoch:4 step:3518[D loss: 0.407359, acc: 75.00%, op_acc: 31.25%] [G loss: 0.958064]\n",
      "epoch:4 step:3519[D loss: 0.481278, acc: 54.69%, op_acc: 27.34%] [G loss: 0.866802]\n",
      "epoch:4 step:3520[D loss: 0.455225, acc: 53.12%, op_acc: 36.72%] [G loss: 0.982606]\n",
      "epoch:4 step:3521[D loss: 0.459310, acc: 53.91%, op_acc: 35.16%] [G loss: 0.937601]\n",
      "epoch:4 step:3522[D loss: 0.492148, acc: 56.25%, op_acc: 26.56%] [G loss: 0.980838]\n",
      "epoch:4 step:3523[D loss: 0.443531, acc: 59.38%, op_acc: 32.03%] [G loss: 0.915283]\n",
      "epoch:4 step:3524[D loss: 0.473374, acc: 53.12%, op_acc: 37.50%] [G loss: 1.036936]\n",
      "epoch:4 step:3525[D loss: 0.436192, acc: 66.41%, op_acc: 35.94%] [G loss: 0.901479]\n",
      "epoch:4 step:3526[D loss: 0.458180, acc: 60.94%, op_acc: 31.25%] [G loss: 0.893973]\n",
      "epoch:4 step:3527[D loss: 0.447572, acc: 62.50%, op_acc: 30.47%] [G loss: 0.916773]\n",
      "epoch:4 step:3528[D loss: 0.450529, acc: 56.25%, op_acc: 33.59%] [G loss: 0.853708]\n",
      "epoch:4 step:3529[D loss: 0.461031, acc: 58.59%, op_acc: 28.91%] [G loss: 0.951243]\n",
      "epoch:4 step:3530[D loss: 0.457964, acc: 56.25%, op_acc: 27.34%] [G loss: 0.959431]\n",
      "epoch:4 step:3531[D loss: 0.457561, acc: 61.72%, op_acc: 28.91%] [G loss: 0.923337]\n",
      "epoch:4 step:3532[D loss: 0.463276, acc: 57.81%, op_acc: 30.47%] [G loss: 0.915804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3533[D loss: 0.440047, acc: 56.25%, op_acc: 36.72%] [G loss: 0.958091]\n",
      "epoch:4 step:3534[D loss: 0.410693, acc: 64.84%, op_acc: 36.72%] [G loss: 1.046108]\n",
      "epoch:4 step:3535[D loss: 0.482645, acc: 57.03%, op_acc: 28.12%] [G loss: 0.947757]\n",
      "epoch:4 step:3536[D loss: 0.425478, acc: 66.41%, op_acc: 32.81%] [G loss: 1.012149]\n",
      "epoch:4 step:3537[D loss: 0.444777, acc: 64.84%, op_acc: 29.69%] [G loss: 0.971943]\n",
      "epoch:4 step:3538[D loss: 0.473327, acc: 56.25%, op_acc: 29.69%] [G loss: 0.862696]\n",
      "epoch:4 step:3539[D loss: 0.446318, acc: 62.50%, op_acc: 33.59%] [G loss: 0.939806]\n",
      "epoch:4 step:3540[D loss: 0.432479, acc: 59.38%, op_acc: 31.25%] [G loss: 0.983903]\n",
      "epoch:4 step:3541[D loss: 0.464539, acc: 60.16%, op_acc: 27.34%] [G loss: 0.932868]\n",
      "epoch:4 step:3542[D loss: 0.399787, acc: 71.88%, op_acc: 32.81%] [G loss: 0.945704]\n",
      "epoch:4 step:3543[D loss: 0.437128, acc: 63.28%, op_acc: 32.81%] [G loss: 0.952962]\n",
      "epoch:4 step:3544[D loss: 0.444148, acc: 58.59%, op_acc: 30.47%] [G loss: 1.055760]\n",
      "epoch:4 step:3545[D loss: 0.459923, acc: 57.81%, op_acc: 36.72%] [G loss: 0.987302]\n",
      "epoch:4 step:3546[D loss: 0.422527, acc: 64.84%, op_acc: 39.84%] [G loss: 0.948371]\n",
      "epoch:4 step:3547[D loss: 0.456275, acc: 60.94%, op_acc: 35.16%] [G loss: 0.971827]\n",
      "epoch:4 step:3548[D loss: 0.459215, acc: 57.81%, op_acc: 28.12%] [G loss: 0.966271]\n",
      "epoch:4 step:3549[D loss: 0.466970, acc: 59.38%, op_acc: 25.78%] [G loss: 0.907789]\n",
      "epoch:4 step:3550[D loss: 0.486788, acc: 53.91%, op_acc: 29.69%] [G loss: 0.956634]\n",
      "##############\n",
      "[0.87270305 0.84729867 0.8196161  0.81019179 0.76994639 0.84655186\n",
      " 0.87310659 0.81480159 0.81792559 0.85329699]\n",
      "##########\n",
      "epoch:4 step:3551[D loss: 0.463074, acc: 58.59%, op_acc: 28.12%] [G loss: 0.998702]\n",
      "epoch:4 step:3552[D loss: 0.452553, acc: 58.59%, op_acc: 35.94%] [G loss: 1.026614]\n",
      "epoch:4 step:3553[D loss: 0.457423, acc: 53.12%, op_acc: 28.12%] [G loss: 0.784083]\n",
      "epoch:4 step:3554[D loss: 0.457220, acc: 55.47%, op_acc: 31.25%] [G loss: 0.885084]\n",
      "epoch:4 step:3555[D loss: 0.471388, acc: 57.81%, op_acc: 29.69%] [G loss: 0.898991]\n",
      "epoch:4 step:3556[D loss: 0.402591, acc: 68.75%, op_acc: 35.16%] [G loss: 0.955267]\n",
      "epoch:4 step:3557[D loss: 0.468512, acc: 54.69%, op_acc: 31.25%] [G loss: 0.977702]\n",
      "epoch:4 step:3558[D loss: 0.447331, acc: 60.94%, op_acc: 36.72%] [G loss: 0.914575]\n",
      "epoch:4 step:3559[D loss: 0.444067, acc: 60.94%, op_acc: 35.94%] [G loss: 0.931705]\n",
      "epoch:4 step:3560[D loss: 0.485475, acc: 54.69%, op_acc: 32.03%] [G loss: 0.910192]\n",
      "epoch:4 step:3561[D loss: 0.416871, acc: 71.09%, op_acc: 31.25%] [G loss: 0.935261]\n",
      "epoch:4 step:3562[D loss: 0.446647, acc: 60.94%, op_acc: 27.34%] [G loss: 0.893576]\n",
      "epoch:4 step:3563[D loss: 0.418539, acc: 67.19%, op_acc: 37.50%] [G loss: 0.881346]\n",
      "epoch:4 step:3564[D loss: 0.453382, acc: 56.25%, op_acc: 30.47%] [G loss: 0.905054]\n",
      "epoch:4 step:3565[D loss: 0.450483, acc: 64.84%, op_acc: 27.34%] [G loss: 0.975462]\n",
      "epoch:4 step:3566[D loss: 0.464779, acc: 58.59%, op_acc: 28.12%] [G loss: 0.916696]\n",
      "epoch:4 step:3567[D loss: 0.441875, acc: 67.97%, op_acc: 31.25%] [G loss: 0.940688]\n",
      "epoch:4 step:3568[D loss: 0.469952, acc: 53.12%, op_acc: 33.59%] [G loss: 1.002910]\n",
      "epoch:4 step:3569[D loss: 0.446387, acc: 67.19%, op_acc: 32.03%] [G loss: 0.870390]\n",
      "epoch:4 step:3570[D loss: 0.457076, acc: 59.38%, op_acc: 34.38%] [G loss: 0.965703]\n",
      "epoch:4 step:3571[D loss: 0.434162, acc: 62.50%, op_acc: 32.03%] [G loss: 0.921298]\n",
      "epoch:4 step:3572[D loss: 0.462273, acc: 60.94%, op_acc: 33.59%] [G loss: 0.971751]\n",
      "epoch:4 step:3573[D loss: 0.454363, acc: 60.16%, op_acc: 28.12%] [G loss: 0.901774]\n",
      "epoch:4 step:3574[D loss: 0.449341, acc: 64.06%, op_acc: 25.78%] [G loss: 0.969465]\n",
      "epoch:4 step:3575[D loss: 0.461580, acc: 57.03%, op_acc: 36.72%] [G loss: 0.983971]\n",
      "epoch:4 step:3576[D loss: 0.426611, acc: 59.38%, op_acc: 35.16%] [G loss: 1.038975]\n",
      "epoch:4 step:3577[D loss: 0.429226, acc: 64.06%, op_acc: 35.94%] [G loss: 1.021038]\n",
      "epoch:4 step:3578[D loss: 0.470840, acc: 57.03%, op_acc: 27.34%] [G loss: 0.972717]\n",
      "epoch:4 step:3579[D loss: 0.489003, acc: 55.47%, op_acc: 25.78%] [G loss: 0.981591]\n",
      "epoch:4 step:3580[D loss: 0.427894, acc: 70.31%, op_acc: 28.91%] [G loss: 0.966011]\n",
      "epoch:4 step:3581[D loss: 0.465096, acc: 58.59%, op_acc: 28.91%] [G loss: 0.959419]\n",
      "epoch:4 step:3582[D loss: 0.467208, acc: 55.47%, op_acc: 35.16%] [G loss: 1.033526]\n",
      "epoch:4 step:3583[D loss: 0.445150, acc: 60.94%, op_acc: 37.50%] [G loss: 1.015353]\n",
      "epoch:4 step:3584[D loss: 0.452708, acc: 57.81%, op_acc: 32.81%] [G loss: 0.955237]\n",
      "epoch:4 step:3585[D loss: 0.470617, acc: 61.72%, op_acc: 25.00%] [G loss: 0.912984]\n",
      "epoch:4 step:3586[D loss: 0.445335, acc: 62.50%, op_acc: 28.12%] [G loss: 0.948178]\n",
      "epoch:4 step:3587[D loss: 0.449131, acc: 61.72%, op_acc: 34.38%] [G loss: 0.964931]\n",
      "epoch:4 step:3588[D loss: 0.464573, acc: 53.12%, op_acc: 29.69%] [G loss: 0.935670]\n",
      "epoch:4 step:3589[D loss: 0.456238, acc: 59.38%, op_acc: 30.47%] [G loss: 0.973024]\n",
      "epoch:4 step:3590[D loss: 0.470398, acc: 54.69%, op_acc: 31.25%] [G loss: 0.890182]\n",
      "epoch:4 step:3591[D loss: 0.455092, acc: 61.72%, op_acc: 35.16%] [G loss: 0.936825]\n",
      "epoch:4 step:3592[D loss: 0.440264, acc: 61.72%, op_acc: 36.72%] [G loss: 0.974861]\n",
      "epoch:4 step:3593[D loss: 0.423932, acc: 64.06%, op_acc: 35.94%] [G loss: 0.907800]\n",
      "epoch:4 step:3594[D loss: 0.450780, acc: 56.25%, op_acc: 33.59%] [G loss: 0.993019]\n",
      "epoch:4 step:3595[D loss: 0.469243, acc: 59.38%, op_acc: 30.47%] [G loss: 0.922042]\n",
      "epoch:4 step:3596[D loss: 0.451891, acc: 61.72%, op_acc: 26.56%] [G loss: 0.922409]\n",
      "epoch:4 step:3597[D loss: 0.443420, acc: 60.16%, op_acc: 38.28%] [G loss: 0.960980]\n",
      "epoch:4 step:3598[D loss: 0.442769, acc: 64.06%, op_acc: 27.34%] [G loss: 0.920182]\n",
      "epoch:4 step:3599[D loss: 0.439964, acc: 60.94%, op_acc: 32.03%] [G loss: 0.892168]\n",
      "epoch:4 step:3600[D loss: 0.474390, acc: 60.16%, op_acc: 30.47%] [G loss: 1.033361]\n",
      "##############\n",
      "[0.85388579 0.8613691  0.79705821 0.80891016 0.80052746 0.83504532\n",
      " 0.88330599 0.827753   0.80196838 0.86169694]\n",
      "##########\n",
      "epoch:4 step:3601[D loss: 0.461393, acc: 52.34%, op_acc: 32.81%] [G loss: 1.000629]\n",
      "epoch:4 step:3602[D loss: 0.458866, acc: 55.47%, op_acc: 29.69%] [G loss: 0.946828]\n",
      "epoch:4 step:3603[D loss: 0.473576, acc: 57.81%, op_acc: 28.91%] [G loss: 0.900641]\n",
      "epoch:4 step:3604[D loss: 0.486784, acc: 57.03%, op_acc: 30.47%] [G loss: 0.911549]\n",
      "epoch:4 step:3605[D loss: 0.484951, acc: 57.03%, op_acc: 27.34%] [G loss: 0.971945]\n",
      "epoch:4 step:3606[D loss: 0.461013, acc: 61.72%, op_acc: 30.47%] [G loss: 0.939885]\n",
      "epoch:4 step:3607[D loss: 0.430257, acc: 64.84%, op_acc: 33.59%] [G loss: 1.037333]\n",
      "epoch:4 step:3608[D loss: 0.439034, acc: 60.16%, op_acc: 36.72%] [G loss: 0.920410]\n",
      "epoch:4 step:3609[D loss: 0.461779, acc: 57.03%, op_acc: 32.81%] [G loss: 0.969349]\n",
      "epoch:4 step:3610[D loss: 0.417586, acc: 66.41%, op_acc: 28.91%] [G loss: 0.998393]\n",
      "epoch:4 step:3611[D loss: 0.439404, acc: 61.72%, op_acc: 32.03%] [G loss: 0.828108]\n",
      "epoch:4 step:3612[D loss: 0.457660, acc: 53.12%, op_acc: 32.03%] [G loss: 1.039303]\n",
      "epoch:4 step:3613[D loss: 0.507595, acc: 49.22%, op_acc: 31.25%] [G loss: 0.791123]\n",
      "epoch:4 step:3614[D loss: 0.466888, acc: 56.25%, op_acc: 33.59%] [G loss: 0.856357]\n",
      "epoch:4 step:3615[D loss: 0.481256, acc: 61.72%, op_acc: 27.34%] [G loss: 0.917405]\n",
      "epoch:4 step:3616[D loss: 0.429680, acc: 64.06%, op_acc: 30.47%] [G loss: 0.977418]\n",
      "epoch:4 step:3617[D loss: 0.472608, acc: 57.03%, op_acc: 33.59%] [G loss: 0.891513]\n",
      "epoch:4 step:3618[D loss: 0.419245, acc: 66.41%, op_acc: 36.72%] [G loss: 0.917109]\n",
      "epoch:4 step:3619[D loss: 0.453835, acc: 59.38%, op_acc: 33.59%] [G loss: 0.920685]\n",
      "epoch:4 step:3620[D loss: 0.466053, acc: 59.38%, op_acc: 28.12%] [G loss: 0.958601]\n",
      "epoch:4 step:3621[D loss: 0.460665, acc: 53.12%, op_acc: 34.38%] [G loss: 0.859356]\n",
      "epoch:4 step:3622[D loss: 0.445209, acc: 60.16%, op_acc: 31.25%] [G loss: 0.879836]\n",
      "epoch:4 step:3623[D loss: 0.465583, acc: 60.94%, op_acc: 28.12%] [G loss: 1.016948]\n",
      "epoch:4 step:3624[D loss: 0.451848, acc: 57.03%, op_acc: 37.50%] [G loss: 0.959202]\n",
      "epoch:4 step:3625[D loss: 0.469489, acc: 56.25%, op_acc: 31.25%] [G loss: 0.898483]\n",
      "epoch:4 step:3626[D loss: 0.462674, acc: 57.03%, op_acc: 28.91%] [G loss: 0.891339]\n",
      "epoch:4 step:3627[D loss: 0.450941, acc: 55.47%, op_acc: 30.47%] [G loss: 0.883023]\n",
      "epoch:4 step:3628[D loss: 0.500833, acc: 43.75%, op_acc: 27.34%] [G loss: 0.860449]\n",
      "epoch:4 step:3629[D loss: 0.464774, acc: 60.16%, op_acc: 29.69%] [G loss: 0.954879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3630[D loss: 0.440146, acc: 63.28%, op_acc: 34.38%] [G loss: 0.960065]\n",
      "epoch:4 step:3631[D loss: 0.413883, acc: 64.84%, op_acc: 32.03%] [G loss: 0.948931]\n",
      "epoch:4 step:3632[D loss: 0.439216, acc: 63.28%, op_acc: 32.03%] [G loss: 0.879277]\n",
      "epoch:4 step:3633[D loss: 0.466235, acc: 62.50%, op_acc: 29.69%] [G loss: 0.947920]\n",
      "epoch:4 step:3634[D loss: 0.445121, acc: 62.50%, op_acc: 28.91%] [G loss: 0.952097]\n",
      "epoch:4 step:3635[D loss: 0.484192, acc: 49.22%, op_acc: 28.91%] [G loss: 0.915609]\n",
      "epoch:4 step:3636[D loss: 0.493368, acc: 50.78%, op_acc: 28.91%] [G loss: 0.925624]\n",
      "epoch:4 step:3637[D loss: 0.495030, acc: 49.22%, op_acc: 21.88%] [G loss: 0.914566]\n",
      "epoch:4 step:3638[D loss: 0.504243, acc: 51.56%, op_acc: 29.69%] [G loss: 0.900827]\n",
      "epoch:4 step:3639[D loss: 0.476160, acc: 64.84%, op_acc: 28.12%] [G loss: 0.878302]\n",
      "epoch:4 step:3640[D loss: 0.430687, acc: 63.28%, op_acc: 28.91%] [G loss: 0.843952]\n",
      "epoch:4 step:3641[D loss: 0.481223, acc: 63.28%, op_acc: 24.22%] [G loss: 0.983221]\n",
      "epoch:4 step:3642[D loss: 0.472764, acc: 52.34%, op_acc: 32.03%] [G loss: 0.883124]\n",
      "epoch:4 step:3643[D loss: 0.470925, acc: 50.78%, op_acc: 32.03%] [G loss: 0.913013]\n",
      "epoch:4 step:3644[D loss: 0.457748, acc: 64.06%, op_acc: 36.72%] [G loss: 0.897230]\n",
      "epoch:4 step:3645[D loss: 0.490951, acc: 53.12%, op_acc: 32.03%] [G loss: 0.910664]\n",
      "epoch:4 step:3646[D loss: 0.469550, acc: 60.16%, op_acc: 24.22%] [G loss: 0.952464]\n",
      "epoch:4 step:3647[D loss: 0.445150, acc: 62.50%, op_acc: 28.12%] [G loss: 0.980915]\n",
      "epoch:4 step:3648[D loss: 0.446042, acc: 67.97%, op_acc: 30.47%] [G loss: 0.965855]\n",
      "epoch:4 step:3649[D loss: 0.457651, acc: 57.03%, op_acc: 23.44%] [G loss: 0.940256]\n",
      "epoch:4 step:3650[D loss: 0.470541, acc: 60.16%, op_acc: 27.34%] [G loss: 0.967275]\n",
      "##############\n",
      "[0.86909159 0.87568742 0.81220192 0.82483612 0.81049158 0.83208001\n",
      " 0.88034327 0.81546909 0.80261162 0.82995691]\n",
      "##########\n",
      "epoch:4 step:3651[D loss: 0.453136, acc: 60.16%, op_acc: 29.69%] [G loss: 0.943354]\n",
      "epoch:4 step:3652[D loss: 0.454575, acc: 60.94%, op_acc: 30.47%] [G loss: 0.922379]\n",
      "epoch:4 step:3653[D loss: 0.434632, acc: 62.50%, op_acc: 32.81%] [G loss: 0.827591]\n",
      "epoch:4 step:3654[D loss: 0.461159, acc: 62.50%, op_acc: 24.22%] [G loss: 0.833152]\n",
      "epoch:4 step:3655[D loss: 0.451620, acc: 61.72%, op_acc: 32.81%] [G loss: 0.923163]\n",
      "epoch:4 step:3656[D loss: 0.482237, acc: 53.12%, op_acc: 24.22%] [G loss: 0.825249]\n",
      "epoch:4 step:3657[D loss: 0.468100, acc: 50.78%, op_acc: 35.16%] [G loss: 0.906313]\n",
      "epoch:4 step:3658[D loss: 0.459425, acc: 59.38%, op_acc: 37.50%] [G loss: 0.919579]\n",
      "epoch:4 step:3659[D loss: 0.418784, acc: 63.28%, op_acc: 39.06%] [G loss: 0.853835]\n",
      "epoch:4 step:3660[D loss: 0.417645, acc: 66.41%, op_acc: 31.25%] [G loss: 0.870905]\n",
      "epoch:4 step:3661[D loss: 0.465951, acc: 57.03%, op_acc: 32.03%] [G loss: 0.870928]\n",
      "epoch:4 step:3662[D loss: 0.460070, acc: 58.59%, op_acc: 37.50%] [G loss: 0.878882]\n",
      "epoch:4 step:3663[D loss: 0.443866, acc: 62.50%, op_acc: 30.47%] [G loss: 0.927365]\n",
      "epoch:4 step:3664[D loss: 0.451010, acc: 59.38%, op_acc: 31.25%] [G loss: 0.888974]\n",
      "epoch:4 step:3665[D loss: 0.424368, acc: 64.06%, op_acc: 35.94%] [G loss: 0.991388]\n",
      "epoch:4 step:3666[D loss: 0.458779, acc: 53.12%, op_acc: 32.03%] [G loss: 1.046824]\n",
      "epoch:4 step:3667[D loss: 0.422332, acc: 68.75%, op_acc: 39.06%] [G loss: 0.975814]\n",
      "epoch:4 step:3668[D loss: 0.451050, acc: 57.03%, op_acc: 35.16%] [G loss: 0.954746]\n",
      "epoch:4 step:3669[D loss: 0.410408, acc: 71.09%, op_acc: 30.47%] [G loss: 0.971620]\n",
      "epoch:4 step:3670[D loss: 0.467919, acc: 55.47%, op_acc: 28.91%] [G loss: 0.967834]\n",
      "epoch:4 step:3671[D loss: 0.477631, acc: 57.81%, op_acc: 26.56%] [G loss: 0.981657]\n",
      "epoch:4 step:3672[D loss: 0.479502, acc: 55.47%, op_acc: 34.38%] [G loss: 0.995543]\n",
      "epoch:4 step:3673[D loss: 0.432654, acc: 64.06%, op_acc: 39.06%] [G loss: 1.053750]\n",
      "epoch:4 step:3674[D loss: 0.465304, acc: 60.94%, op_acc: 28.91%] [G loss: 0.876947]\n",
      "epoch:4 step:3675[D loss: 0.453352, acc: 60.94%, op_acc: 27.34%] [G loss: 1.043171]\n",
      "epoch:4 step:3676[D loss: 0.480871, acc: 60.16%, op_acc: 25.78%] [G loss: 0.910806]\n",
      "epoch:4 step:3677[D loss: 0.449340, acc: 62.50%, op_acc: 28.91%] [G loss: 0.865443]\n",
      "epoch:4 step:3678[D loss: 0.481925, acc: 55.47%, op_acc: 28.91%] [G loss: 0.902286]\n",
      "epoch:4 step:3679[D loss: 0.425840, acc: 61.72%, op_acc: 31.25%] [G loss: 0.924219]\n",
      "epoch:4 step:3680[D loss: 0.473283, acc: 51.56%, op_acc: 32.03%] [G loss: 0.815858]\n",
      "epoch:4 step:3681[D loss: 0.467397, acc: 66.41%, op_acc: 25.78%] [G loss: 0.929874]\n",
      "epoch:4 step:3682[D loss: 0.449289, acc: 57.81%, op_acc: 34.38%] [G loss: 0.943858]\n",
      "epoch:4 step:3683[D loss: 0.412385, acc: 67.19%, op_acc: 32.81%] [G loss: 0.925165]\n",
      "epoch:4 step:3684[D loss: 0.452038, acc: 59.38%, op_acc: 28.12%] [G loss: 0.870827]\n",
      "epoch:4 step:3685[D loss: 0.471881, acc: 58.59%, op_acc: 29.69%] [G loss: 0.903466]\n",
      "epoch:4 step:3686[D loss: 0.441656, acc: 61.72%, op_acc: 28.12%] [G loss: 0.975193]\n",
      "epoch:4 step:3687[D loss: 0.438877, acc: 67.19%, op_acc: 31.25%] [G loss: 0.876590]\n",
      "epoch:4 step:3688[D loss: 0.471943, acc: 53.91%, op_acc: 38.28%] [G loss: 0.941113]\n",
      "epoch:4 step:3689[D loss: 0.450910, acc: 63.28%, op_acc: 33.59%] [G loss: 0.972029]\n",
      "epoch:4 step:3690[D loss: 0.482096, acc: 50.78%, op_acc: 28.12%] [G loss: 0.978727]\n",
      "epoch:4 step:3691[D loss: 0.462028, acc: 53.12%, op_acc: 32.81%] [G loss: 0.949134]\n",
      "epoch:4 step:3692[D loss: 0.458973, acc: 57.81%, op_acc: 33.59%] [G loss: 0.958049]\n",
      "epoch:4 step:3693[D loss: 0.437657, acc: 69.53%, op_acc: 31.25%] [G loss: 0.918372]\n",
      "epoch:4 step:3694[D loss: 0.429004, acc: 64.06%, op_acc: 33.59%] [G loss: 0.908387]\n",
      "epoch:4 step:3695[D loss: 0.459255, acc: 52.34%, op_acc: 31.25%] [G loss: 0.841151]\n",
      "epoch:4 step:3696[D loss: 0.426999, acc: 60.94%, op_acc: 31.25%] [G loss: 0.887187]\n",
      "epoch:4 step:3697[D loss: 0.477091, acc: 53.12%, op_acc: 30.47%] [G loss: 0.880781]\n",
      "epoch:4 step:3698[D loss: 0.458272, acc: 63.28%, op_acc: 30.47%] [G loss: 0.927430]\n",
      "epoch:4 step:3699[D loss: 0.454732, acc: 58.59%, op_acc: 30.47%] [G loss: 0.993043]\n",
      "epoch:4 step:3700[D loss: 0.448861, acc: 61.72%, op_acc: 35.94%] [G loss: 0.866627]\n",
      "##############\n",
      "[0.87217297 0.86911855 0.79895436 0.80309303 0.80248836 0.83352499\n",
      " 0.88534272 0.81665594 0.79881919 0.84090107]\n",
      "##########\n",
      "epoch:4 step:3701[D loss: 0.499131, acc: 46.88%, op_acc: 26.56%] [G loss: 0.888616]\n",
      "epoch:4 step:3702[D loss: 0.490623, acc: 50.00%, op_acc: 31.25%] [G loss: 0.836409]\n",
      "epoch:4 step:3703[D loss: 0.439261, acc: 55.47%, op_acc: 40.62%] [G loss: 0.971923]\n",
      "epoch:4 step:3704[D loss: 0.461997, acc: 57.81%, op_acc: 27.34%] [G loss: 0.943687]\n",
      "epoch:4 step:3705[D loss: 0.486446, acc: 52.34%, op_acc: 28.12%] [G loss: 0.954792]\n",
      "epoch:4 step:3706[D loss: 0.495727, acc: 49.22%, op_acc: 26.56%] [G loss: 0.893460]\n",
      "epoch:4 step:3707[D loss: 0.463288, acc: 57.81%, op_acc: 32.81%] [G loss: 0.979688]\n",
      "epoch:4 step:3708[D loss: 0.482299, acc: 64.06%, op_acc: 26.56%] [G loss: 0.916249]\n",
      "epoch:4 step:3709[D loss: 0.440777, acc: 64.06%, op_acc: 29.69%] [G loss: 1.008511]\n",
      "epoch:4 step:3710[D loss: 0.438016, acc: 64.84%, op_acc: 32.03%] [G loss: 1.020149]\n",
      "epoch:4 step:3711[D loss: 0.421255, acc: 67.19%, op_acc: 31.25%] [G loss: 1.141789]\n",
      "epoch:4 step:3712[D loss: 0.414974, acc: 64.84%, op_acc: 39.06%] [G loss: 0.979341]\n",
      "epoch:4 step:3713[D loss: 0.412036, acc: 67.97%, op_acc: 35.16%] [G loss: 1.079314]\n",
      "epoch:4 step:3714[D loss: 0.420237, acc: 69.53%, op_acc: 35.16%] [G loss: 1.058595]\n",
      "epoch:4 step:3715[D loss: 0.481680, acc: 54.69%, op_acc: 29.69%] [G loss: 0.985598]\n",
      "epoch:4 step:3716[D loss: 0.429443, acc: 62.50%, op_acc: 31.25%] [G loss: 0.918550]\n",
      "epoch:4 step:3717[D loss: 0.469076, acc: 60.94%, op_acc: 32.81%] [G loss: 1.006167]\n",
      "epoch:4 step:3718[D loss: 0.466844, acc: 57.03%, op_acc: 28.12%] [G loss: 0.964341]\n",
      "epoch:4 step:3719[D loss: 0.448415, acc: 67.19%, op_acc: 25.78%] [G loss: 0.968081]\n",
      "epoch:4 step:3720[D loss: 0.464154, acc: 57.81%, op_acc: 28.91%] [G loss: 0.941379]\n",
      "epoch:4 step:3721[D loss: 0.447947, acc: 61.72%, op_acc: 32.03%] [G loss: 0.976016]\n",
      "epoch:4 step:3722[D loss: 0.396250, acc: 74.22%, op_acc: 41.41%] [G loss: 1.057491]\n",
      "epoch:4 step:3723[D loss: 0.425247, acc: 75.00%, op_acc: 32.81%] [G loss: 0.975377]\n",
      "epoch:4 step:3724[D loss: 0.432197, acc: 65.62%, op_acc: 30.47%] [G loss: 0.971244]\n",
      "epoch:4 step:3725[D loss: 0.423042, acc: 66.41%, op_acc: 30.47%] [G loss: 0.987511]\n",
      "epoch:4 step:3726[D loss: 0.433842, acc: 62.50%, op_acc: 37.50%] [G loss: 0.972170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3727[D loss: 0.409703, acc: 61.72%, op_acc: 36.72%] [G loss: 1.005357]\n",
      "epoch:4 step:3728[D loss: 0.477354, acc: 55.47%, op_acc: 29.69%] [G loss: 0.960384]\n",
      "epoch:4 step:3729[D loss: 0.438132, acc: 66.41%, op_acc: 32.81%] [G loss: 0.972256]\n",
      "epoch:4 step:3730[D loss: 0.427433, acc: 61.72%, op_acc: 38.28%] [G loss: 0.926273]\n",
      "epoch:4 step:3731[D loss: 0.445715, acc: 58.59%, op_acc: 39.84%] [G loss: 0.888201]\n",
      "epoch:4 step:3732[D loss: 0.463588, acc: 49.22%, op_acc: 35.16%] [G loss: 0.921284]\n",
      "epoch:4 step:3733[D loss: 0.470139, acc: 53.12%, op_acc: 35.16%] [G loss: 0.908291]\n",
      "epoch:4 step:3734[D loss: 0.468091, acc: 60.16%, op_acc: 32.03%] [G loss: 0.937512]\n",
      "epoch:4 step:3735[D loss: 0.501597, acc: 52.34%, op_acc: 30.47%] [G loss: 0.925391]\n",
      "epoch:4 step:3736[D loss: 0.466739, acc: 60.16%, op_acc: 37.50%] [G loss: 0.885881]\n",
      "epoch:4 step:3737[D loss: 0.475526, acc: 55.47%, op_acc: 31.25%] [G loss: 0.916450]\n",
      "epoch:4 step:3738[D loss: 0.464885, acc: 57.81%, op_acc: 30.47%] [G loss: 0.899714]\n",
      "epoch:4 step:3739[D loss: 0.479666, acc: 57.03%, op_acc: 28.12%] [G loss: 0.942350]\n",
      "epoch:4 step:3740[D loss: 0.447137, acc: 63.28%, op_acc: 33.59%] [G loss: 0.993047]\n",
      "epoch:4 step:3741[D loss: 0.497144, acc: 53.91%, op_acc: 24.22%] [G loss: 0.941542]\n",
      "epoch:4 step:3742[D loss: 0.476582, acc: 57.81%, op_acc: 31.25%] [G loss: 0.823442]\n",
      "epoch:4 step:3743[D loss: 0.470645, acc: 60.16%, op_acc: 28.91%] [G loss: 0.906887]\n",
      "epoch:4 step:3744[D loss: 0.449190, acc: 58.59%, op_acc: 25.00%] [G loss: 0.983745]\n",
      "epoch:4 step:3745[D loss: 0.462179, acc: 62.50%, op_acc: 30.47%] [G loss: 0.957181]\n",
      "epoch:4 step:3746[D loss: 0.496653, acc: 52.34%, op_acc: 28.12%] [G loss: 0.994199]\n",
      "epoch:4 step:3747[D loss: 0.428091, acc: 66.41%, op_acc: 36.72%] [G loss: 0.969519]\n",
      "epoch:4 step:3748[D loss: 0.460284, acc: 54.69%, op_acc: 35.94%] [G loss: 1.002253]\n",
      "epoch:4 step:3749[D loss: 0.498187, acc: 51.56%, op_acc: 28.12%] [G loss: 0.906351]\n",
      "epoch:4 step:3750[D loss: 0.437774, acc: 57.03%, op_acc: 34.38%] [G loss: 0.895972]\n",
      "##############\n",
      "[0.8442647  0.86080687 0.82730009 0.81319412 0.80465863 0.84969732\n",
      " 0.86705961 0.82391127 0.79683316 0.81967795]\n",
      "##########\n",
      "epoch:4 step:3751[D loss: 0.470439, acc: 56.25%, op_acc: 37.50%] [G loss: 0.961347]\n",
      "epoch:4 step:3752[D loss: 0.443914, acc: 70.31%, op_acc: 33.59%] [G loss: 1.002515]\n",
      "epoch:4 step:3753[D loss: 0.459979, acc: 62.50%, op_acc: 27.34%] [G loss: 0.908018]\n",
      "epoch:4 step:3754[D loss: 0.422295, acc: 69.53%, op_acc: 30.47%] [G loss: 0.967200]\n",
      "epoch:4 step:3755[D loss: 0.438096, acc: 59.38%, op_acc: 36.72%] [G loss: 0.898013]\n",
      "epoch:4 step:3756[D loss: 0.468432, acc: 62.50%, op_acc: 25.00%] [G loss: 0.907327]\n",
      "epoch:4 step:3757[D loss: 0.456684, acc: 60.16%, op_acc: 31.25%] [G loss: 0.959748]\n",
      "epoch:4 step:3758[D loss: 0.463897, acc: 58.59%, op_acc: 35.94%] [G loss: 0.881626]\n",
      "epoch:4 step:3759[D loss: 0.438573, acc: 61.72%, op_acc: 35.94%] [G loss: 0.818217]\n",
      "epoch:4 step:3760[D loss: 0.402081, acc: 63.28%, op_acc: 37.50%] [G loss: 0.845029]\n",
      "epoch:4 step:3761[D loss: 0.434009, acc: 62.50%, op_acc: 31.25%] [G loss: 0.957961]\n",
      "epoch:4 step:3762[D loss: 0.466267, acc: 60.16%, op_acc: 34.38%] [G loss: 0.949906]\n",
      "epoch:4 step:3763[D loss: 0.486634, acc: 50.00%, op_acc: 30.47%] [G loss: 0.820768]\n",
      "epoch:4 step:3764[D loss: 0.474781, acc: 60.16%, op_acc: 30.47%] [G loss: 0.898161]\n",
      "epoch:4 step:3765[D loss: 0.479909, acc: 53.91%, op_acc: 27.34%] [G loss: 0.918869]\n",
      "epoch:4 step:3766[D loss: 0.444066, acc: 63.28%, op_acc: 28.12%] [G loss: 0.901099]\n",
      "epoch:4 step:3767[D loss: 0.479533, acc: 57.03%, op_acc: 26.56%] [G loss: 0.876640]\n",
      "epoch:4 step:3768[D loss: 0.452023, acc: 58.59%, op_acc: 38.28%] [G loss: 0.929751]\n",
      "epoch:4 step:3769[D loss: 0.468065, acc: 54.69%, op_acc: 28.12%] [G loss: 0.985985]\n",
      "epoch:4 step:3770[D loss: 0.474700, acc: 55.47%, op_acc: 32.03%] [G loss: 0.882147]\n",
      "epoch:4 step:3771[D loss: 0.463448, acc: 56.25%, op_acc: 29.69%] [G loss: 1.006121]\n",
      "epoch:4 step:3772[D loss: 0.465770, acc: 53.91%, op_acc: 29.69%] [G loss: 0.899785]\n",
      "epoch:4 step:3773[D loss: 0.478464, acc: 52.34%, op_acc: 33.59%] [G loss: 0.948821]\n",
      "epoch:4 step:3774[D loss: 0.515298, acc: 50.00%, op_acc: 24.22%] [G loss: 0.848938]\n",
      "epoch:4 step:3775[D loss: 0.466799, acc: 53.12%, op_acc: 30.47%] [G loss: 0.883725]\n",
      "epoch:4 step:3776[D loss: 0.448620, acc: 57.03%, op_acc: 31.25%] [G loss: 0.927633]\n",
      "epoch:4 step:3777[D loss: 0.440119, acc: 57.81%, op_acc: 32.81%] [G loss: 0.868911]\n",
      "epoch:4 step:3778[D loss: 0.460033, acc: 58.59%, op_acc: 33.59%] [G loss: 0.913964]\n",
      "epoch:4 step:3779[D loss: 0.433575, acc: 61.72%, op_acc: 36.72%] [G loss: 0.954019]\n",
      "epoch:4 step:3780[D loss: 0.488582, acc: 51.56%, op_acc: 25.00%] [G loss: 0.922318]\n",
      "epoch:4 step:3781[D loss: 0.451910, acc: 63.28%, op_acc: 31.25%] [G loss: 1.029481]\n",
      "epoch:4 step:3782[D loss: 0.448078, acc: 62.50%, op_acc: 31.25%] [G loss: 0.852226]\n",
      "epoch:4 step:3783[D loss: 0.450658, acc: 64.06%, op_acc: 30.47%] [G loss: 0.934238]\n",
      "epoch:4 step:3784[D loss: 0.442610, acc: 60.94%, op_acc: 31.25%] [G loss: 0.906574]\n",
      "epoch:4 step:3785[D loss: 0.445715, acc: 60.94%, op_acc: 34.38%] [G loss: 0.914762]\n",
      "epoch:4 step:3786[D loss: 0.450847, acc: 59.38%, op_acc: 36.72%] [G loss: 0.880987]\n",
      "epoch:4 step:3787[D loss: 0.460692, acc: 44.53%, op_acc: 32.03%] [G loss: 0.864365]\n",
      "epoch:4 step:3788[D loss: 0.427945, acc: 64.84%, op_acc: 28.12%] [G loss: 0.985521]\n",
      "epoch:4 step:3789[D loss: 0.468487, acc: 60.16%, op_acc: 30.47%] [G loss: 0.904127]\n",
      "epoch:4 step:3790[D loss: 0.457166, acc: 67.19%, op_acc: 26.56%] [G loss: 0.928574]\n",
      "epoch:4 step:3791[D loss: 0.460319, acc: 53.91%, op_acc: 36.72%] [G loss: 0.906067]\n",
      "epoch:4 step:3792[D loss: 0.461935, acc: 54.69%, op_acc: 28.91%] [G loss: 0.933602]\n",
      "epoch:4 step:3793[D loss: 0.478954, acc: 56.25%, op_acc: 32.03%] [G loss: 0.910782]\n",
      "epoch:4 step:3794[D loss: 0.465462, acc: 56.25%, op_acc: 30.47%] [G loss: 0.861767]\n",
      "epoch:4 step:3795[D loss: 0.472734, acc: 52.34%, op_acc: 28.12%] [G loss: 0.963681]\n",
      "epoch:4 step:3796[D loss: 0.426560, acc: 64.84%, op_acc: 27.34%] [G loss: 1.027827]\n",
      "epoch:4 step:3797[D loss: 0.450126, acc: 61.72%, op_acc: 28.12%] [G loss: 0.958457]\n",
      "epoch:4 step:3798[D loss: 0.433376, acc: 60.94%, op_acc: 36.72%] [G loss: 0.992955]\n",
      "epoch:4 step:3799[D loss: 0.457530, acc: 58.59%, op_acc: 30.47%] [G loss: 0.874297]\n",
      "epoch:4 step:3800[D loss: 0.478070, acc: 59.38%, op_acc: 25.78%] [G loss: 0.922266]\n",
      "##############\n",
      "[0.85417659 0.88720541 0.81185825 0.79127538 0.78768531 0.84195176\n",
      " 0.88026411 0.80855743 0.79278736 0.8374222 ]\n",
      "##########\n",
      "epoch:4 step:3801[D loss: 0.454300, acc: 68.75%, op_acc: 35.16%] [G loss: 0.974764]\n",
      "epoch:4 step:3802[D loss: 0.476663, acc: 49.22%, op_acc: 30.47%] [G loss: 0.956513]\n",
      "epoch:4 step:3803[D loss: 0.458522, acc: 57.03%, op_acc: 27.34%] [G loss: 0.957701]\n",
      "epoch:4 step:3804[D loss: 0.438852, acc: 68.75%, op_acc: 28.91%] [G loss: 0.908891]\n",
      "epoch:4 step:3805[D loss: 0.463456, acc: 60.16%, op_acc: 32.03%] [G loss: 0.945894]\n",
      "epoch:4 step:3806[D loss: 0.431186, acc: 62.50%, op_acc: 33.59%] [G loss: 0.961369]\n",
      "epoch:4 step:3807[D loss: 0.419876, acc: 66.41%, op_acc: 37.50%] [G loss: 1.046045]\n",
      "epoch:4 step:3808[D loss: 0.439574, acc: 62.50%, op_acc: 29.69%] [G loss: 0.980281]\n",
      "epoch:4 step:3809[D loss: 0.457903, acc: 64.06%, op_acc: 31.25%] [G loss: 1.013254]\n",
      "epoch:4 step:3810[D loss: 0.460346, acc: 57.03%, op_acc: 28.12%] [G loss: 1.010273]\n",
      "epoch:4 step:3811[D loss: 0.449567, acc: 65.62%, op_acc: 27.34%] [G loss: 0.909384]\n",
      "epoch:4 step:3812[D loss: 0.459026, acc: 56.25%, op_acc: 31.25%] [G loss: 0.996580]\n",
      "epoch:4 step:3813[D loss: 0.437361, acc: 63.28%, op_acc: 33.59%] [G loss: 0.928002]\n",
      "epoch:4 step:3814[D loss: 0.442033, acc: 62.50%, op_acc: 28.12%] [G loss: 0.899842]\n",
      "epoch:4 step:3815[D loss: 0.456703, acc: 64.84%, op_acc: 35.94%] [G loss: 0.980075]\n",
      "epoch:4 step:3816[D loss: 0.449007, acc: 62.50%, op_acc: 28.91%] [G loss: 0.957879]\n",
      "epoch:4 step:3817[D loss: 0.437679, acc: 62.50%, op_acc: 30.47%] [G loss: 1.007226]\n",
      "epoch:4 step:3818[D loss: 0.445353, acc: 67.97%, op_acc: 28.91%] [G loss: 0.930198]\n",
      "epoch:4 step:3819[D loss: 0.456188, acc: 53.12%, op_acc: 32.03%] [G loss: 0.897619]\n",
      "epoch:4 step:3820[D loss: 0.444992, acc: 64.84%, op_acc: 29.69%] [G loss: 0.939760]\n",
      "epoch:4 step:3821[D loss: 0.462401, acc: 59.38%, op_acc: 30.47%] [G loss: 0.843341]\n",
      "epoch:4 step:3822[D loss: 0.459091, acc: 58.59%, op_acc: 28.12%] [G loss: 0.847003]\n",
      "epoch:4 step:3823[D loss: 0.445719, acc: 65.62%, op_acc: 32.03%] [G loss: 0.853109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3824[D loss: 0.482140, acc: 52.34%, op_acc: 32.81%] [G loss: 0.962150]\n",
      "epoch:4 step:3825[D loss: 0.439262, acc: 66.41%, op_acc: 29.69%] [G loss: 1.014927]\n",
      "epoch:4 step:3826[D loss: 0.460529, acc: 54.69%, op_acc: 26.56%] [G loss: 1.032887]\n",
      "epoch:4 step:3827[D loss: 0.449452, acc: 57.81%, op_acc: 32.03%] [G loss: 0.961723]\n",
      "epoch:4 step:3828[D loss: 0.423546, acc: 57.03%, op_acc: 38.28%] [G loss: 0.929780]\n",
      "epoch:4 step:3829[D loss: 0.444291, acc: 62.50%, op_acc: 32.81%] [G loss: 0.930830]\n",
      "epoch:4 step:3830[D loss: 0.453840, acc: 59.38%, op_acc: 34.38%] [G loss: 0.994367]\n",
      "epoch:4 step:3831[D loss: 0.449251, acc: 58.59%, op_acc: 29.69%] [G loss: 0.885012]\n",
      "epoch:4 step:3832[D loss: 0.468353, acc: 61.72%, op_acc: 26.56%] [G loss: 0.892430]\n",
      "epoch:4 step:3833[D loss: 0.413406, acc: 71.09%, op_acc: 33.59%] [G loss: 0.901380]\n",
      "epoch:4 step:3834[D loss: 0.450438, acc: 55.47%, op_acc: 35.94%] [G loss: 0.877236]\n",
      "epoch:4 step:3835[D loss: 0.446298, acc: 55.47%, op_acc: 32.03%] [G loss: 0.936687]\n",
      "epoch:4 step:3836[D loss: 0.442306, acc: 57.81%, op_acc: 33.59%] [G loss: 0.884804]\n",
      "epoch:4 step:3837[D loss: 0.448082, acc: 54.69%, op_acc: 32.03%] [G loss: 0.914040]\n",
      "epoch:4 step:3838[D loss: 0.449882, acc: 61.72%, op_acc: 29.69%] [G loss: 0.941170]\n",
      "epoch:4 step:3839[D loss: 0.427388, acc: 60.16%, op_acc: 33.59%] [G loss: 0.959584]\n",
      "epoch:4 step:3840[D loss: 0.469740, acc: 57.03%, op_acc: 31.25%] [G loss: 0.904339]\n",
      "epoch:4 step:3841[D loss: 0.409990, acc: 67.19%, op_acc: 35.94%] [G loss: 1.047301]\n",
      "epoch:4 step:3842[D loss: 0.461827, acc: 59.38%, op_acc: 32.81%] [G loss: 0.930525]\n",
      "epoch:4 step:3843[D loss: 0.426425, acc: 67.19%, op_acc: 36.72%] [G loss: 0.911334]\n",
      "epoch:4 step:3844[D loss: 0.424806, acc: 65.62%, op_acc: 34.38%] [G loss: 0.965367]\n",
      "epoch:4 step:3845[D loss: 0.471259, acc: 52.34%, op_acc: 32.03%] [G loss: 0.809526]\n",
      "epoch:4 step:3846[D loss: 0.469355, acc: 53.91%, op_acc: 35.94%] [G loss: 0.902613]\n",
      "epoch:4 step:3847[D loss: 0.476529, acc: 50.00%, op_acc: 27.34%] [G loss: 0.858652]\n",
      "epoch:4 step:3848[D loss: 0.513311, acc: 57.03%, op_acc: 25.00%] [G loss: 0.926573]\n",
      "epoch:4 step:3849[D loss: 0.464650, acc: 57.03%, op_acc: 31.25%] [G loss: 0.954763]\n",
      "epoch:4 step:3850[D loss: 0.423710, acc: 67.19%, op_acc: 35.94%] [G loss: 0.947061]\n",
      "##############\n",
      "[0.85732581 0.87195907 0.79704594 0.812702   0.78694777 0.8053582\n",
      " 0.86781096 0.81252309 0.80970792 0.82670356]\n",
      "##########\n",
      "epoch:4 step:3851[D loss: 0.484282, acc: 52.34%, op_acc: 24.22%] [G loss: 0.943532]\n",
      "epoch:4 step:3852[D loss: 0.443679, acc: 60.16%, op_acc: 30.47%] [G loss: 0.969178]\n",
      "epoch:4 step:3853[D loss: 0.430897, acc: 64.84%, op_acc: 36.72%] [G loss: 0.925338]\n",
      "epoch:4 step:3854[D loss: 0.452925, acc: 59.38%, op_acc: 30.47%] [G loss: 0.903108]\n",
      "epoch:4 step:3855[D loss: 0.442254, acc: 58.59%, op_acc: 35.16%] [G loss: 0.860292]\n",
      "epoch:4 step:3856[D loss: 0.438291, acc: 64.06%, op_acc: 35.16%] [G loss: 0.906176]\n",
      "epoch:4 step:3857[D loss: 0.451559, acc: 59.38%, op_acc: 30.47%] [G loss: 0.852804]\n",
      "epoch:4 step:3858[D loss: 0.456872, acc: 55.47%, op_acc: 34.38%] [G loss: 0.897987]\n",
      "epoch:4 step:3859[D loss: 0.440662, acc: 61.72%, op_acc: 30.47%] [G loss: 1.055185]\n",
      "epoch:4 step:3860[D loss: 0.464353, acc: 59.38%, op_acc: 28.12%] [G loss: 0.976506]\n",
      "epoch:4 step:3861[D loss: 0.447784, acc: 56.25%, op_acc: 31.25%] [G loss: 1.020369]\n",
      "epoch:4 step:3862[D loss: 0.450191, acc: 55.47%, op_acc: 32.81%] [G loss: 0.980503]\n",
      "epoch:4 step:3863[D loss: 0.433174, acc: 57.03%, op_acc: 33.59%] [G loss: 0.904752]\n",
      "epoch:4 step:3864[D loss: 0.464728, acc: 57.81%, op_acc: 34.38%] [G loss: 0.868923]\n",
      "epoch:4 step:3865[D loss: 0.458714, acc: 61.72%, op_acc: 31.25%] [G loss: 0.953002]\n",
      "epoch:4 step:3866[D loss: 0.432938, acc: 66.41%, op_acc: 31.25%] [G loss: 0.961908]\n",
      "epoch:4 step:3867[D loss: 0.486307, acc: 53.12%, op_acc: 26.56%] [G loss: 0.892878]\n",
      "epoch:4 step:3868[D loss: 0.432139, acc: 66.41%, op_acc: 32.03%] [G loss: 0.953734]\n",
      "epoch:4 step:3869[D loss: 0.455778, acc: 57.03%, op_acc: 33.59%] [G loss: 0.877541]\n",
      "epoch:4 step:3870[D loss: 0.489578, acc: 49.22%, op_acc: 31.25%] [G loss: 0.902581]\n",
      "epoch:4 step:3871[D loss: 0.420487, acc: 67.97%, op_acc: 30.47%] [G loss: 0.962197]\n",
      "epoch:4 step:3872[D loss: 0.430111, acc: 68.75%, op_acc: 36.72%] [G loss: 0.974310]\n",
      "epoch:4 step:3873[D loss: 0.472246, acc: 60.94%, op_acc: 23.44%] [G loss: 0.952215]\n",
      "epoch:4 step:3874[D loss: 0.442349, acc: 61.72%, op_acc: 32.81%] [G loss: 0.941642]\n",
      "epoch:4 step:3875[D loss: 0.489358, acc: 54.69%, op_acc: 26.56%] [G loss: 0.965416]\n",
      "epoch:4 step:3876[D loss: 0.450489, acc: 63.28%, op_acc: 29.69%] [G loss: 0.974981]\n",
      "epoch:4 step:3877[D loss: 0.424186, acc: 66.41%, op_acc: 33.59%] [G loss: 0.913799]\n",
      "epoch:4 step:3878[D loss: 0.482270, acc: 54.69%, op_acc: 30.47%] [G loss: 0.914644]\n",
      "epoch:4 step:3879[D loss: 0.429834, acc: 64.06%, op_acc: 34.38%] [G loss: 1.006672]\n",
      "epoch:4 step:3880[D loss: 0.428457, acc: 60.16%, op_acc: 37.50%] [G loss: 0.975097]\n",
      "epoch:4 step:3881[D loss: 0.464608, acc: 60.16%, op_acc: 35.16%] [G loss: 0.986277]\n",
      "epoch:4 step:3882[D loss: 0.487676, acc: 52.34%, op_acc: 32.81%] [G loss: 0.871615]\n",
      "epoch:4 step:3883[D loss: 0.432738, acc: 71.88%, op_acc: 32.81%] [G loss: 0.910401]\n",
      "epoch:4 step:3884[D loss: 0.453695, acc: 58.59%, op_acc: 35.94%] [G loss: 0.859481]\n",
      "epoch:4 step:3885[D loss: 0.442021, acc: 60.94%, op_acc: 40.62%] [G loss: 0.901285]\n",
      "epoch:4 step:3886[D loss: 0.469902, acc: 57.03%, op_acc: 30.47%] [G loss: 0.997492]\n",
      "epoch:4 step:3887[D loss: 0.437592, acc: 60.94%, op_acc: 32.03%] [G loss: 0.873283]\n",
      "epoch:4 step:3888[D loss: 0.438308, acc: 61.72%, op_acc: 35.16%] [G loss: 0.928865]\n",
      "epoch:4 step:3889[D loss: 0.454564, acc: 63.28%, op_acc: 32.03%] [G loss: 0.946135]\n",
      "epoch:4 step:3890[D loss: 0.464734, acc: 62.50%, op_acc: 32.81%] [G loss: 0.969937]\n",
      "epoch:4 step:3891[D loss: 0.424172, acc: 64.06%, op_acc: 38.28%] [G loss: 0.966196]\n",
      "epoch:4 step:3892[D loss: 0.470543, acc: 60.94%, op_acc: 25.78%] [G loss: 0.929932]\n",
      "epoch:4 step:3893[D loss: 0.453477, acc: 58.59%, op_acc: 35.94%] [G loss: 1.032281]\n",
      "epoch:4 step:3894[D loss: 0.440364, acc: 67.19%, op_acc: 28.91%] [G loss: 1.003913]\n",
      "epoch:4 step:3895[D loss: 0.489293, acc: 56.25%, op_acc: 28.91%] [G loss: 0.924173]\n",
      "epoch:4 step:3896[D loss: 0.460224, acc: 60.16%, op_acc: 31.25%] [G loss: 0.996841]\n",
      "epoch:4 step:3897[D loss: 0.437531, acc: 64.84%, op_acc: 30.47%] [G loss: 0.939051]\n",
      "epoch:4 step:3898[D loss: 0.412002, acc: 67.19%, op_acc: 35.16%] [G loss: 1.061254]\n",
      "epoch:4 step:3899[D loss: 0.430178, acc: 65.62%, op_acc: 37.50%] [G loss: 0.967639]\n",
      "epoch:4 step:3900[D loss: 0.458797, acc: 53.91%, op_acc: 31.25%] [G loss: 0.984369]\n",
      "##############\n",
      "[0.84743433 0.87206624 0.81905374 0.81237213 0.8062809  0.81647038\n",
      " 0.87581773 0.81287727 0.81768369 0.84066021]\n",
      "##########\n",
      "epoch:4 step:3901[D loss: 0.499710, acc: 52.34%, op_acc: 21.88%] [G loss: 0.874617]\n",
      "epoch:4 step:3902[D loss: 0.434771, acc: 67.97%, op_acc: 36.72%] [G loss: 1.013685]\n",
      "epoch:4 step:3903[D loss: 0.447350, acc: 62.50%, op_acc: 36.72%] [G loss: 0.986113]\n",
      "epoch:4 step:3904[D loss: 0.441241, acc: 60.94%, op_acc: 36.72%] [G loss: 0.974845]\n",
      "epoch:4 step:3905[D loss: 0.441802, acc: 63.28%, op_acc: 32.03%] [G loss: 0.952622]\n",
      "epoch:5 step:3906[D loss: 0.455329, acc: 62.50%, op_acc: 32.81%] [G loss: 0.971255]\n",
      "epoch:5 step:3907[D loss: 0.394938, acc: 68.75%, op_acc: 34.38%] [G loss: 0.922272]\n",
      "epoch:5 step:3908[D loss: 0.468124, acc: 57.03%, op_acc: 27.34%] [G loss: 0.905151]\n",
      "epoch:5 step:3909[D loss: 0.442779, acc: 55.47%, op_acc: 37.50%] [G loss: 0.861727]\n",
      "epoch:5 step:3910[D loss: 0.447703, acc: 60.16%, op_acc: 34.38%] [G loss: 0.926643]\n",
      "epoch:5 step:3911[D loss: 0.458004, acc: 53.91%, op_acc: 32.81%] [G loss: 0.917026]\n",
      "epoch:5 step:3912[D loss: 0.436299, acc: 62.50%, op_acc: 34.38%] [G loss: 0.976094]\n",
      "epoch:5 step:3913[D loss: 0.464166, acc: 60.94%, op_acc: 30.47%] [G loss: 0.982888]\n",
      "epoch:5 step:3914[D loss: 0.403208, acc: 69.53%, op_acc: 41.41%] [G loss: 0.992948]\n",
      "epoch:5 step:3915[D loss: 0.457321, acc: 60.94%, op_acc: 31.25%] [G loss: 0.939725]\n",
      "epoch:5 step:3916[D loss: 0.469403, acc: 54.69%, op_acc: 32.81%] [G loss: 0.992034]\n",
      "epoch:5 step:3917[D loss: 0.448977, acc: 59.38%, op_acc: 30.47%] [G loss: 0.951423]\n",
      "epoch:5 step:3918[D loss: 0.414791, acc: 68.75%, op_acc: 33.59%] [G loss: 0.966142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:3919[D loss: 0.465207, acc: 55.47%, op_acc: 29.69%] [G loss: 0.880983]\n",
      "epoch:5 step:3920[D loss: 0.455385, acc: 63.28%, op_acc: 31.25%] [G loss: 0.882519]\n",
      "epoch:5 step:3921[D loss: 0.433158, acc: 60.94%, op_acc: 37.50%] [G loss: 0.986882]\n",
      "epoch:5 step:3922[D loss: 0.460572, acc: 58.59%, op_acc: 28.91%] [G loss: 0.929415]\n",
      "epoch:5 step:3923[D loss: 0.419875, acc: 62.50%, op_acc: 37.50%] [G loss: 0.952043]\n",
      "epoch:5 step:3924[D loss: 0.426440, acc: 67.19%, op_acc: 30.47%] [G loss: 0.889079]\n",
      "epoch:5 step:3925[D loss: 0.441233, acc: 53.12%, op_acc: 33.59%] [G loss: 0.872922]\n",
      "epoch:5 step:3926[D loss: 0.446836, acc: 64.06%, op_acc: 28.91%] [G loss: 0.892869]\n",
      "epoch:5 step:3927[D loss: 0.437499, acc: 64.84%, op_acc: 31.25%] [G loss: 0.894652]\n",
      "epoch:5 step:3928[D loss: 0.480960, acc: 51.56%, op_acc: 32.81%] [G loss: 0.915369]\n",
      "epoch:5 step:3929[D loss: 0.464568, acc: 56.25%, op_acc: 32.03%] [G loss: 0.821998]\n",
      "epoch:5 step:3930[D loss: 0.450157, acc: 65.62%, op_acc: 30.47%] [G loss: 0.947981]\n",
      "epoch:5 step:3931[D loss: 0.426010, acc: 62.50%, op_acc: 33.59%] [G loss: 0.861456]\n",
      "epoch:5 step:3932[D loss: 0.449325, acc: 58.59%, op_acc: 32.81%] [G loss: 1.087477]\n",
      "epoch:5 step:3933[D loss: 0.461281, acc: 56.25%, op_acc: 33.59%] [G loss: 0.975022]\n",
      "epoch:5 step:3934[D loss: 0.463456, acc: 52.34%, op_acc: 38.28%] [G loss: 0.866246]\n",
      "epoch:5 step:3935[D loss: 0.421036, acc: 58.59%, op_acc: 31.25%] [G loss: 0.862916]\n",
      "epoch:5 step:3936[D loss: 0.486567, acc: 56.25%, op_acc: 27.34%] [G loss: 1.006763]\n",
      "epoch:5 step:3937[D loss: 0.452628, acc: 60.94%, op_acc: 28.91%] [G loss: 0.952136]\n",
      "epoch:5 step:3938[D loss: 0.448911, acc: 53.12%, op_acc: 36.72%] [G loss: 0.915247]\n",
      "epoch:5 step:3939[D loss: 0.433539, acc: 60.94%, op_acc: 40.62%] [G loss: 0.973164]\n",
      "epoch:5 step:3940[D loss: 0.447599, acc: 70.31%, op_acc: 27.34%] [G loss: 0.928582]\n",
      "epoch:5 step:3941[D loss: 0.427743, acc: 60.94%, op_acc: 32.03%] [G loss: 0.957826]\n",
      "epoch:5 step:3942[D loss: 0.436900, acc: 62.50%, op_acc: 32.81%] [G loss: 0.903113]\n",
      "epoch:5 step:3943[D loss: 0.447103, acc: 58.59%, op_acc: 33.59%] [G loss: 0.915200]\n",
      "epoch:5 step:3944[D loss: 0.476020, acc: 60.16%, op_acc: 26.56%] [G loss: 0.871116]\n",
      "epoch:5 step:3945[D loss: 0.454130, acc: 57.03%, op_acc: 32.03%] [G loss: 0.938777]\n",
      "epoch:5 step:3946[D loss: 0.456443, acc: 60.16%, op_acc: 32.81%] [G loss: 0.963437]\n",
      "epoch:5 step:3947[D loss: 0.421815, acc: 60.16%, op_acc: 34.38%] [G loss: 0.926438]\n",
      "epoch:5 step:3948[D loss: 0.481884, acc: 50.00%, op_acc: 31.25%] [G loss: 0.854934]\n",
      "epoch:5 step:3949[D loss: 0.480867, acc: 51.56%, op_acc: 33.59%] [G loss: 0.980177]\n",
      "epoch:5 step:3950[D loss: 0.437791, acc: 57.81%, op_acc: 35.94%] [G loss: 0.903415]\n",
      "##############\n",
      "[0.86123641 0.85677942 0.8147313  0.79919764 0.7962383  0.8187604\n",
      " 0.91016372 0.80791031 0.79001524 0.84354352]\n",
      "##########\n",
      "epoch:5 step:3951[D loss: 0.458874, acc: 59.38%, op_acc: 30.47%] [G loss: 0.935126]\n",
      "epoch:5 step:3952[D loss: 0.491234, acc: 60.16%, op_acc: 24.22%] [G loss: 0.877362]\n",
      "epoch:5 step:3953[D loss: 0.471467, acc: 61.72%, op_acc: 28.91%] [G loss: 0.969665]\n",
      "epoch:5 step:3954[D loss: 0.461133, acc: 60.16%, op_acc: 36.72%] [G loss: 0.921240]\n",
      "epoch:5 step:3955[D loss: 0.458301, acc: 60.16%, op_acc: 29.69%] [G loss: 0.931094]\n",
      "epoch:5 step:3956[D loss: 0.398829, acc: 74.22%, op_acc: 39.06%] [G loss: 0.919316]\n",
      "epoch:5 step:3957[D loss: 0.457042, acc: 64.06%, op_acc: 32.03%] [G loss: 0.877220]\n",
      "epoch:5 step:3958[D loss: 0.477583, acc: 60.16%, op_acc: 26.56%] [G loss: 0.928997]\n",
      "epoch:5 step:3959[D loss: 0.470745, acc: 57.81%, op_acc: 35.16%] [G loss: 0.999773]\n",
      "epoch:5 step:3960[D loss: 0.435474, acc: 61.72%, op_acc: 38.28%] [G loss: 0.895926]\n",
      "epoch:5 step:3961[D loss: 0.431395, acc: 63.28%, op_acc: 32.03%] [G loss: 0.955399]\n",
      "epoch:5 step:3962[D loss: 0.456813, acc: 53.12%, op_acc: 37.50%] [G loss: 0.844901]\n",
      "epoch:5 step:3963[D loss: 0.440787, acc: 60.94%, op_acc: 36.72%] [G loss: 0.949256]\n",
      "epoch:5 step:3964[D loss: 0.446445, acc: 58.59%, op_acc: 30.47%] [G loss: 0.950053]\n",
      "epoch:5 step:3965[D loss: 0.457783, acc: 58.59%, op_acc: 32.03%] [G loss: 0.934449]\n",
      "epoch:5 step:3966[D loss: 0.445430, acc: 64.06%, op_acc: 32.03%] [G loss: 0.979505]\n",
      "epoch:5 step:3967[D loss: 0.452509, acc: 60.94%, op_acc: 27.34%] [G loss: 0.893836]\n",
      "epoch:5 step:3968[D loss: 0.456400, acc: 64.84%, op_acc: 32.03%] [G loss: 0.931392]\n",
      "epoch:5 step:3969[D loss: 0.438649, acc: 67.97%, op_acc: 29.69%] [G loss: 0.924244]\n",
      "epoch:5 step:3970[D loss: 0.476287, acc: 53.12%, op_acc: 30.47%] [G loss: 0.961431]\n",
      "epoch:5 step:3971[D loss: 0.435318, acc: 61.72%, op_acc: 35.94%] [G loss: 1.001780]\n",
      "epoch:5 step:3972[D loss: 0.448750, acc: 60.94%, op_acc: 29.69%] [G loss: 0.849138]\n",
      "epoch:5 step:3973[D loss: 0.461771, acc: 64.84%, op_acc: 28.91%] [G loss: 0.960006]\n",
      "epoch:5 step:3974[D loss: 0.436235, acc: 54.69%, op_acc: 38.28%] [G loss: 0.919562]\n",
      "epoch:5 step:3975[D loss: 0.449281, acc: 64.06%, op_acc: 29.69%] [G loss: 0.877807]\n",
      "epoch:5 step:3976[D loss: 0.483993, acc: 60.16%, op_acc: 25.78%] [G loss: 0.982989]\n",
      "epoch:5 step:3977[D loss: 0.464475, acc: 55.47%, op_acc: 35.94%] [G loss: 0.904369]\n",
      "epoch:5 step:3978[D loss: 0.430730, acc: 61.72%, op_acc: 35.16%] [G loss: 0.921812]\n",
      "epoch:5 step:3979[D loss: 0.427297, acc: 60.94%, op_acc: 32.03%] [G loss: 0.875057]\n",
      "epoch:5 step:3980[D loss: 0.485688, acc: 46.88%, op_acc: 32.81%] [G loss: 0.873561]\n",
      "epoch:5 step:3981[D loss: 0.480766, acc: 57.81%, op_acc: 31.25%] [G loss: 0.869508]\n",
      "epoch:5 step:3982[D loss: 0.447232, acc: 60.16%, op_acc: 32.03%] [G loss: 0.878604]\n",
      "epoch:5 step:3983[D loss: 0.494638, acc: 61.72%, op_acc: 25.78%] [G loss: 0.930974]\n",
      "epoch:5 step:3984[D loss: 0.472563, acc: 57.03%, op_acc: 33.59%] [G loss: 0.889234]\n",
      "epoch:5 step:3985[D loss: 0.455428, acc: 61.72%, op_acc: 29.69%] [G loss: 0.936334]\n",
      "epoch:5 step:3986[D loss: 0.484094, acc: 58.59%, op_acc: 28.91%] [G loss: 0.866390]\n",
      "epoch:5 step:3987[D loss: 0.451172, acc: 58.59%, op_acc: 31.25%] [G loss: 0.907181]\n",
      "epoch:5 step:3988[D loss: 0.448378, acc: 60.94%, op_acc: 28.91%] [G loss: 0.964557]\n",
      "epoch:5 step:3989[D loss: 0.483413, acc: 50.78%, op_acc: 31.25%] [G loss: 0.933044]\n",
      "epoch:5 step:3990[D loss: 0.431601, acc: 63.28%, op_acc: 32.03%] [G loss: 0.964225]\n",
      "epoch:5 step:3991[D loss: 0.456365, acc: 62.50%, op_acc: 31.25%] [G loss: 0.979779]\n",
      "epoch:5 step:3992[D loss: 0.445079, acc: 65.62%, op_acc: 28.12%] [G loss: 0.893808]\n",
      "epoch:5 step:3993[D loss: 0.436453, acc: 56.25%, op_acc: 35.94%] [G loss: 0.933325]\n",
      "epoch:5 step:3994[D loss: 0.464989, acc: 60.16%, op_acc: 26.56%] [G loss: 0.929307]\n",
      "epoch:5 step:3995[D loss: 0.448346, acc: 61.72%, op_acc: 35.94%] [G loss: 0.991306]\n",
      "epoch:5 step:3996[D loss: 0.443238, acc: 67.97%, op_acc: 24.22%] [G loss: 1.029351]\n",
      "epoch:5 step:3997[D loss: 0.439115, acc: 64.84%, op_acc: 28.12%] [G loss: 0.997521]\n",
      "epoch:5 step:3998[D loss: 0.435256, acc: 63.28%, op_acc: 35.94%] [G loss: 0.906085]\n",
      "epoch:5 step:3999[D loss: 0.409441, acc: 72.66%, op_acc: 33.59%] [G loss: 0.981673]\n",
      "epoch:5 step:4000[D loss: 0.433148, acc: 56.25%, op_acc: 32.03%] [G loss: 0.875101]\n",
      "##############\n",
      "[0.84133477 0.87501882 0.80909928 0.80028276 0.80048331 0.84057033\n",
      " 0.89791611 0.83179206 0.80830196 0.82449131]\n",
      "##########\n",
      "epoch:5 step:4001[D loss: 0.448032, acc: 67.19%, op_acc: 28.91%] [G loss: 0.983967]\n",
      "epoch:5 step:4002[D loss: 0.431141, acc: 62.50%, op_acc: 32.03%] [G loss: 1.003670]\n",
      "epoch:5 step:4003[D loss: 0.469509, acc: 58.59%, op_acc: 30.47%] [G loss: 0.942617]\n",
      "epoch:5 step:4004[D loss: 0.445400, acc: 60.16%, op_acc: 32.81%] [G loss: 0.956554]\n",
      "epoch:5 step:4005[D loss: 0.458042, acc: 60.16%, op_acc: 35.94%] [G loss: 0.877996]\n",
      "epoch:5 step:4006[D loss: 0.483184, acc: 57.03%, op_acc: 28.91%] [G loss: 0.860473]\n",
      "epoch:5 step:4007[D loss: 0.468302, acc: 49.22%, op_acc: 33.59%] [G loss: 0.940004]\n",
      "epoch:5 step:4008[D loss: 0.440823, acc: 64.84%, op_acc: 28.12%] [G loss: 0.959967]\n",
      "epoch:5 step:4009[D loss: 0.470378, acc: 60.16%, op_acc: 33.59%] [G loss: 0.926973]\n",
      "epoch:5 step:4010[D loss: 0.480618, acc: 50.00%, op_acc: 35.16%] [G loss: 0.849388]\n",
      "epoch:5 step:4011[D loss: 0.442819, acc: 55.47%, op_acc: 32.03%] [G loss: 0.869510]\n",
      "epoch:5 step:4012[D loss: 0.449593, acc: 57.81%, op_acc: 35.16%] [G loss: 1.005989]\n",
      "epoch:5 step:4013[D loss: 0.475762, acc: 50.78%, op_acc: 29.69%] [G loss: 0.958487]\n",
      "epoch:5 step:4014[D loss: 0.426333, acc: 64.06%, op_acc: 32.81%] [G loss: 1.028414]\n",
      "epoch:5 step:4015[D loss: 0.439253, acc: 57.81%, op_acc: 30.47%] [G loss: 0.947486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4016[D loss: 0.444736, acc: 63.28%, op_acc: 25.78%] [G loss: 0.982951]\n",
      "epoch:5 step:4017[D loss: 0.412126, acc: 68.75%, op_acc: 40.62%] [G loss: 0.902631]\n",
      "epoch:5 step:4018[D loss: 0.493734, acc: 51.56%, op_acc: 27.34%] [G loss: 0.979604]\n",
      "epoch:5 step:4019[D loss: 0.436185, acc: 63.28%, op_acc: 32.81%] [G loss: 0.985557]\n",
      "epoch:5 step:4020[D loss: 0.408206, acc: 65.62%, op_acc: 39.06%] [G loss: 0.970835]\n",
      "epoch:5 step:4021[D loss: 0.495129, acc: 55.47%, op_acc: 26.56%] [G loss: 0.958476]\n",
      "epoch:5 step:4022[D loss: 0.448239, acc: 59.38%, op_acc: 38.28%] [G loss: 0.857799]\n",
      "epoch:5 step:4023[D loss: 0.419010, acc: 64.84%, op_acc: 35.16%] [G loss: 0.924569]\n",
      "epoch:5 step:4024[D loss: 0.474094, acc: 58.59%, op_acc: 28.91%] [G loss: 0.973605]\n",
      "epoch:5 step:4025[D loss: 0.444378, acc: 65.62%, op_acc: 35.94%] [G loss: 1.007429]\n",
      "epoch:5 step:4026[D loss: 0.460600, acc: 63.28%, op_acc: 36.72%] [G loss: 0.923934]\n",
      "epoch:5 step:4027[D loss: 0.440821, acc: 64.06%, op_acc: 37.50%] [G loss: 0.950728]\n",
      "epoch:5 step:4028[D loss: 0.456701, acc: 57.81%, op_acc: 29.69%] [G loss: 0.920707]\n",
      "epoch:5 step:4029[D loss: 0.454129, acc: 58.59%, op_acc: 34.38%] [G loss: 0.939595]\n",
      "epoch:5 step:4030[D loss: 0.453609, acc: 60.16%, op_acc: 34.38%] [G loss: 0.904878]\n",
      "epoch:5 step:4031[D loss: 0.432071, acc: 64.06%, op_acc: 34.38%] [G loss: 0.864056]\n",
      "epoch:5 step:4032[D loss: 0.453537, acc: 64.06%, op_acc: 27.34%] [G loss: 0.913605]\n",
      "epoch:5 step:4033[D loss: 0.446361, acc: 60.94%, op_acc: 31.25%] [G loss: 0.953293]\n",
      "epoch:5 step:4034[D loss: 0.477584, acc: 59.38%, op_acc: 26.56%] [G loss: 0.889307]\n",
      "epoch:5 step:4035[D loss: 0.430578, acc: 63.28%, op_acc: 32.81%] [G loss: 0.911503]\n",
      "epoch:5 step:4036[D loss: 0.456898, acc: 60.16%, op_acc: 30.47%] [G loss: 0.886412]\n",
      "epoch:5 step:4037[D loss: 0.430359, acc: 54.69%, op_acc: 40.62%] [G loss: 0.924667]\n",
      "epoch:5 step:4038[D loss: 0.487955, acc: 52.34%, op_acc: 27.34%] [G loss: 0.978278]\n",
      "epoch:5 step:4039[D loss: 0.463506, acc: 59.38%, op_acc: 32.03%] [G loss: 0.952254]\n",
      "epoch:5 step:4040[D loss: 0.454594, acc: 55.47%, op_acc: 34.38%] [G loss: 1.015955]\n",
      "epoch:5 step:4041[D loss: 0.445514, acc: 62.50%, op_acc: 30.47%] [G loss: 0.896744]\n",
      "epoch:5 step:4042[D loss: 0.459460, acc: 62.50%, op_acc: 27.34%] [G loss: 0.963666]\n",
      "epoch:5 step:4043[D loss: 0.466612, acc: 60.16%, op_acc: 29.69%] [G loss: 0.989077]\n",
      "epoch:5 step:4044[D loss: 0.472556, acc: 54.69%, op_acc: 34.38%] [G loss: 0.901516]\n",
      "epoch:5 step:4045[D loss: 0.491356, acc: 56.25%, op_acc: 28.91%] [G loss: 0.938504]\n",
      "epoch:5 step:4046[D loss: 0.471220, acc: 61.72%, op_acc: 28.12%] [G loss: 0.895149]\n",
      "epoch:5 step:4047[D loss: 0.434544, acc: 67.97%, op_acc: 30.47%] [G loss: 0.953175]\n",
      "epoch:5 step:4048[D loss: 0.440705, acc: 57.81%, op_acc: 33.59%] [G loss: 0.951881]\n",
      "epoch:5 step:4049[D loss: 0.438965, acc: 58.59%, op_acc: 38.28%] [G loss: 0.939274]\n",
      "epoch:5 step:4050[D loss: 0.444061, acc: 63.28%, op_acc: 27.34%] [G loss: 0.876814]\n",
      "##############\n",
      "[0.8413412  0.84137298 0.80556055 0.80815143 0.77468272 0.81841235\n",
      " 0.87914982 0.8254409  0.83637637 0.83514184]\n",
      "##########\n",
      "epoch:5 step:4051[D loss: 0.434172, acc: 63.28%, op_acc: 28.12%] [G loss: 0.946691]\n",
      "epoch:5 step:4052[D loss: 0.431630, acc: 62.50%, op_acc: 34.38%] [G loss: 0.917484]\n",
      "epoch:5 step:4053[D loss: 0.467279, acc: 60.16%, op_acc: 29.69%] [G loss: 0.949825]\n",
      "epoch:5 step:4054[D loss: 0.423413, acc: 64.06%, op_acc: 39.84%] [G loss: 0.927205]\n",
      "epoch:5 step:4055[D loss: 0.436346, acc: 63.28%, op_acc: 39.84%] [G loss: 0.990395]\n",
      "epoch:5 step:4056[D loss: 0.452702, acc: 58.59%, op_acc: 32.03%] [G loss: 0.961991]\n",
      "epoch:5 step:4057[D loss: 0.476458, acc: 53.91%, op_acc: 29.69%] [G loss: 0.943150]\n",
      "epoch:5 step:4058[D loss: 0.477370, acc: 50.78%, op_acc: 28.12%] [G loss: 0.922523]\n",
      "epoch:5 step:4059[D loss: 0.469866, acc: 60.94%, op_acc: 35.94%] [G loss: 0.930930]\n",
      "epoch:5 step:4060[D loss: 0.443287, acc: 60.94%, op_acc: 29.69%] [G loss: 0.864159]\n",
      "epoch:5 step:4061[D loss: 0.477129, acc: 50.00%, op_acc: 32.81%] [G loss: 0.844867]\n",
      "epoch:5 step:4062[D loss: 0.431992, acc: 66.41%, op_acc: 27.34%] [G loss: 0.904227]\n",
      "epoch:5 step:4063[D loss: 0.432676, acc: 62.50%, op_acc: 34.38%] [G loss: 1.063200]\n",
      "epoch:5 step:4064[D loss: 0.468772, acc: 57.81%, op_acc: 34.38%] [G loss: 0.857226]\n",
      "epoch:5 step:4065[D loss: 0.494767, acc: 54.69%, op_acc: 28.91%] [G loss: 0.945271]\n",
      "epoch:5 step:4066[D loss: 0.491224, acc: 49.22%, op_acc: 33.59%] [G loss: 0.975390]\n",
      "epoch:5 step:4067[D loss: 0.439720, acc: 61.72%, op_acc: 37.50%] [G loss: 0.951437]\n",
      "epoch:5 step:4068[D loss: 0.452168, acc: 63.28%, op_acc: 28.12%] [G loss: 0.887719]\n",
      "epoch:5 step:4069[D loss: 0.462455, acc: 64.06%, op_acc: 27.34%] [G loss: 0.936080]\n",
      "epoch:5 step:4070[D loss: 0.436093, acc: 60.16%, op_acc: 35.16%] [G loss: 0.917440]\n",
      "epoch:5 step:4071[D loss: 0.448840, acc: 61.72%, op_acc: 33.59%] [G loss: 0.970253]\n",
      "epoch:5 step:4072[D loss: 0.444028, acc: 56.25%, op_acc: 39.84%] [G loss: 0.941115]\n",
      "epoch:5 step:4073[D loss: 0.429630, acc: 60.16%, op_acc: 30.47%] [G loss: 0.945492]\n",
      "epoch:5 step:4074[D loss: 0.443379, acc: 60.16%, op_acc: 40.62%] [G loss: 0.918775]\n",
      "epoch:5 step:4075[D loss: 0.471856, acc: 53.91%, op_acc: 34.38%] [G loss: 0.896830]\n",
      "epoch:5 step:4076[D loss: 0.447292, acc: 59.38%, op_acc: 28.91%] [G loss: 0.980607]\n",
      "epoch:5 step:4077[D loss: 0.447765, acc: 61.72%, op_acc: 27.34%] [G loss: 1.015091]\n",
      "epoch:5 step:4078[D loss: 0.431261, acc: 66.41%, op_acc: 28.12%] [G loss: 1.025926]\n",
      "epoch:5 step:4079[D loss: 0.482683, acc: 55.47%, op_acc: 26.56%] [G loss: 0.946762]\n",
      "epoch:5 step:4080[D loss: 0.410197, acc: 68.75%, op_acc: 32.81%] [G loss: 1.007992]\n",
      "epoch:5 step:4081[D loss: 0.486081, acc: 50.78%, op_acc: 29.69%] [G loss: 1.046625]\n",
      "epoch:5 step:4082[D loss: 0.429943, acc: 66.41%, op_acc: 30.47%] [G loss: 0.950198]\n",
      "epoch:5 step:4083[D loss: 0.458098, acc: 60.16%, op_acc: 28.91%] [G loss: 0.965618]\n",
      "epoch:5 step:4084[D loss: 0.434784, acc: 61.72%, op_acc: 36.72%] [G loss: 0.980008]\n",
      "epoch:5 step:4085[D loss: 0.456764, acc: 63.28%, op_acc: 33.59%] [G loss: 0.946133]\n",
      "epoch:5 step:4086[D loss: 0.411471, acc: 70.31%, op_acc: 34.38%] [G loss: 1.007444]\n",
      "epoch:5 step:4087[D loss: 0.456988, acc: 51.56%, op_acc: 34.38%] [G loss: 0.895894]\n",
      "epoch:5 step:4088[D loss: 0.447047, acc: 62.50%, op_acc: 32.03%] [G loss: 0.997316]\n",
      "epoch:5 step:4089[D loss: 0.436082, acc: 63.28%, op_acc: 38.28%] [G loss: 0.901922]\n",
      "epoch:5 step:4090[D loss: 0.447332, acc: 59.38%, op_acc: 28.91%] [G loss: 0.962186]\n",
      "epoch:5 step:4091[D loss: 0.458277, acc: 51.56%, op_acc: 32.03%] [G loss: 0.986385]\n",
      "epoch:5 step:4092[D loss: 0.464998, acc: 56.25%, op_acc: 34.38%] [G loss: 1.011418]\n",
      "epoch:5 step:4093[D loss: 0.433521, acc: 66.41%, op_acc: 35.16%] [G loss: 0.966290]\n",
      "epoch:5 step:4094[D loss: 0.433702, acc: 64.06%, op_acc: 33.59%] [G loss: 0.916791]\n",
      "epoch:5 step:4095[D loss: 0.499966, acc: 51.56%, op_acc: 32.03%] [G loss: 0.908740]\n",
      "epoch:5 step:4096[D loss: 0.440986, acc: 57.81%, op_acc: 34.38%] [G loss: 0.881333]\n",
      "epoch:5 step:4097[D loss: 0.449781, acc: 64.06%, op_acc: 31.25%] [G loss: 0.921924]\n",
      "epoch:5 step:4098[D loss: 0.455841, acc: 63.28%, op_acc: 30.47%] [G loss: 0.895861]\n",
      "epoch:5 step:4099[D loss: 0.434329, acc: 66.41%, op_acc: 31.25%] [G loss: 0.946848]\n",
      "epoch:5 step:4100[D loss: 0.450741, acc: 61.72%, op_acc: 30.47%] [G loss: 0.884381]\n",
      "##############\n",
      "[0.86246512 0.87600686 0.80585513 0.81287006 0.79734973 0.84113591\n",
      " 0.86313696 0.82441339 0.80629072 0.83127538]\n",
      "##########\n",
      "epoch:5 step:4101[D loss: 0.438288, acc: 62.50%, op_acc: 32.81%] [G loss: 0.866563]\n",
      "epoch:5 step:4102[D loss: 0.463875, acc: 57.03%, op_acc: 30.47%] [G loss: 0.906301]\n",
      "epoch:5 step:4103[D loss: 0.475225, acc: 53.91%, op_acc: 28.12%] [G loss: 0.967105]\n",
      "epoch:5 step:4104[D loss: 0.449743, acc: 60.16%, op_acc: 33.59%] [G loss: 0.872076]\n",
      "epoch:5 step:4105[D loss: 0.460947, acc: 57.81%, op_acc: 27.34%] [G loss: 0.915575]\n",
      "epoch:5 step:4106[D loss: 0.421558, acc: 64.06%, op_acc: 37.50%] [G loss: 1.008212]\n",
      "epoch:5 step:4107[D loss: 0.503881, acc: 50.00%, op_acc: 25.00%] [G loss: 0.928083]\n",
      "epoch:5 step:4108[D loss: 0.433205, acc: 68.75%, op_acc: 25.78%] [G loss: 0.973956]\n",
      "epoch:5 step:4109[D loss: 0.448134, acc: 61.72%, op_acc: 30.47%] [G loss: 0.941012]\n",
      "epoch:5 step:4110[D loss: 0.451689, acc: 58.59%, op_acc: 32.03%] [G loss: 0.926559]\n",
      "epoch:5 step:4111[D loss: 0.456574, acc: 58.59%, op_acc: 32.03%] [G loss: 0.936404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4112[D loss: 0.449929, acc: 64.06%, op_acc: 34.38%] [G loss: 1.017481]\n",
      "epoch:5 step:4113[D loss: 0.467849, acc: 61.72%, op_acc: 28.12%] [G loss: 0.968721]\n",
      "epoch:5 step:4114[D loss: 0.453320, acc: 55.47%, op_acc: 36.72%] [G loss: 0.921847]\n",
      "epoch:5 step:4115[D loss: 0.447133, acc: 64.84%, op_acc: 28.91%] [G loss: 0.984607]\n",
      "epoch:5 step:4116[D loss: 0.450664, acc: 57.81%, op_acc: 32.81%] [G loss: 0.858742]\n",
      "epoch:5 step:4117[D loss: 0.459097, acc: 55.47%, op_acc: 31.25%] [G loss: 0.881818]\n",
      "epoch:5 step:4118[D loss: 0.461243, acc: 57.03%, op_acc: 32.81%] [G loss: 0.859675]\n",
      "epoch:5 step:4119[D loss: 0.448008, acc: 64.06%, op_acc: 31.25%] [G loss: 0.899088]\n",
      "epoch:5 step:4120[D loss: 0.459007, acc: 60.94%, op_acc: 29.69%] [G loss: 0.938517]\n",
      "epoch:5 step:4121[D loss: 0.461195, acc: 62.50%, op_acc: 26.56%] [G loss: 0.889226]\n",
      "epoch:5 step:4122[D loss: 0.428338, acc: 67.19%, op_acc: 30.47%] [G loss: 0.947805]\n",
      "epoch:5 step:4123[D loss: 0.463248, acc: 52.34%, op_acc: 34.38%] [G loss: 0.838977]\n",
      "epoch:5 step:4124[D loss: 0.460722, acc: 55.47%, op_acc: 30.47%] [G loss: 0.878491]\n",
      "epoch:5 step:4125[D loss: 0.433000, acc: 66.41%, op_acc: 29.69%] [G loss: 0.943889]\n",
      "epoch:5 step:4126[D loss: 0.435453, acc: 63.28%, op_acc: 28.12%] [G loss: 0.893473]\n",
      "epoch:5 step:4127[D loss: 0.469920, acc: 59.38%, op_acc: 29.69%] [G loss: 0.853941]\n",
      "epoch:5 step:4128[D loss: 0.441155, acc: 61.72%, op_acc: 33.59%] [G loss: 0.904368]\n",
      "epoch:5 step:4129[D loss: 0.433314, acc: 64.84%, op_acc: 33.59%] [G loss: 0.920199]\n",
      "epoch:5 step:4130[D loss: 0.447412, acc: 64.06%, op_acc: 29.69%] [G loss: 0.918115]\n",
      "epoch:5 step:4131[D loss: 0.464662, acc: 61.72%, op_acc: 32.03%] [G loss: 0.988006]\n",
      "epoch:5 step:4132[D loss: 0.430846, acc: 67.97%, op_acc: 36.72%] [G loss: 0.909996]\n",
      "epoch:5 step:4133[D loss: 0.461673, acc: 60.16%, op_acc: 31.25%] [G loss: 0.844551]\n",
      "epoch:5 step:4134[D loss: 0.423924, acc: 71.09%, op_acc: 32.81%] [G loss: 0.881184]\n",
      "epoch:5 step:4135[D loss: 0.437223, acc: 67.19%, op_acc: 30.47%] [G loss: 0.990430]\n",
      "epoch:5 step:4136[D loss: 0.446193, acc: 53.91%, op_acc: 35.94%] [G loss: 0.914695]\n",
      "epoch:5 step:4137[D loss: 0.464269, acc: 57.81%, op_acc: 31.25%] [G loss: 0.943278]\n",
      "epoch:5 step:4138[D loss: 0.431318, acc: 61.72%, op_acc: 28.12%] [G loss: 1.048730]\n",
      "epoch:5 step:4139[D loss: 0.468628, acc: 56.25%, op_acc: 30.47%] [G loss: 1.079968]\n",
      "epoch:5 step:4140[D loss: 0.432507, acc: 64.84%, op_acc: 35.16%] [G loss: 0.984622]\n",
      "epoch:5 step:4141[D loss: 0.455136, acc: 63.28%, op_acc: 32.81%] [G loss: 0.919826]\n",
      "epoch:5 step:4142[D loss: 0.452442, acc: 57.03%, op_acc: 32.03%] [G loss: 1.027521]\n",
      "epoch:5 step:4143[D loss: 0.448204, acc: 62.50%, op_acc: 30.47%] [G loss: 0.965952]\n",
      "epoch:5 step:4144[D loss: 0.448562, acc: 56.25%, op_acc: 33.59%] [G loss: 0.853163]\n",
      "epoch:5 step:4145[D loss: 0.454673, acc: 53.91%, op_acc: 35.94%] [G loss: 0.933122]\n",
      "epoch:5 step:4146[D loss: 0.442371, acc: 60.16%, op_acc: 32.81%] [G loss: 0.925926]\n",
      "epoch:5 step:4147[D loss: 0.466065, acc: 57.81%, op_acc: 34.38%] [G loss: 0.824117]\n",
      "epoch:5 step:4148[D loss: 0.479112, acc: 50.00%, op_acc: 30.47%] [G loss: 0.930341]\n",
      "epoch:5 step:4149[D loss: 0.485752, acc: 60.16%, op_acc: 25.00%] [G loss: 0.855932]\n",
      "epoch:5 step:4150[D loss: 0.429156, acc: 65.62%, op_acc: 37.50%] [G loss: 0.833364]\n",
      "##############\n",
      "[0.84626803 0.87058233 0.81699658 0.79298995 0.77474963 0.82649037\n",
      " 0.87139981 0.82257812 0.83186876 0.86479808]\n",
      "##########\n",
      "epoch:5 step:4151[D loss: 0.443586, acc: 61.72%, op_acc: 32.03%] [G loss: 1.038790]\n",
      "epoch:5 step:4152[D loss: 0.437567, acc: 58.59%, op_acc: 34.38%] [G loss: 0.907097]\n",
      "epoch:5 step:4153[D loss: 0.463268, acc: 63.28%, op_acc: 24.22%] [G loss: 0.881236]\n",
      "epoch:5 step:4154[D loss: 0.472161, acc: 56.25%, op_acc: 34.38%] [G loss: 0.859470]\n",
      "epoch:5 step:4155[D loss: 0.474237, acc: 59.38%, op_acc: 28.12%] [G loss: 0.970946]\n",
      "epoch:5 step:4156[D loss: 0.418586, acc: 66.41%, op_acc: 39.06%] [G loss: 1.036945]\n",
      "epoch:5 step:4157[D loss: 0.437208, acc: 59.38%, op_acc: 35.94%] [G loss: 0.972223]\n",
      "epoch:5 step:4158[D loss: 0.463882, acc: 57.81%, op_acc: 28.12%] [G loss: 0.984752]\n",
      "epoch:5 step:4159[D loss: 0.470779, acc: 60.94%, op_acc: 27.34%] [G loss: 0.967803]\n",
      "epoch:5 step:4160[D loss: 0.453740, acc: 60.94%, op_acc: 32.03%] [G loss: 0.841954]\n",
      "epoch:5 step:4161[D loss: 0.466394, acc: 53.91%, op_acc: 31.25%] [G loss: 0.918092]\n",
      "epoch:5 step:4162[D loss: 0.477826, acc: 53.12%, op_acc: 29.69%] [G loss: 0.950736]\n",
      "epoch:5 step:4163[D loss: 0.434335, acc: 64.84%, op_acc: 35.94%] [G loss: 0.951831]\n",
      "epoch:5 step:4164[D loss: 0.455870, acc: 58.59%, op_acc: 29.69%] [G loss: 0.942336]\n",
      "epoch:5 step:4165[D loss: 0.455296, acc: 59.38%, op_acc: 37.50%] [G loss: 0.900006]\n",
      "epoch:5 step:4166[D loss: 0.466390, acc: 50.00%, op_acc: 30.47%] [G loss: 0.886343]\n",
      "epoch:5 step:4167[D loss: 0.421306, acc: 68.75%, op_acc: 35.16%] [G loss: 0.895073]\n",
      "epoch:5 step:4168[D loss: 0.454593, acc: 60.94%, op_acc: 28.12%] [G loss: 0.919821]\n",
      "epoch:5 step:4169[D loss: 0.451026, acc: 64.84%, op_acc: 28.12%] [G loss: 0.987679]\n",
      "epoch:5 step:4170[D loss: 0.416166, acc: 64.84%, op_acc: 37.50%] [G loss: 0.921421]\n",
      "epoch:5 step:4171[D loss: 0.465001, acc: 60.16%, op_acc: 33.59%] [G loss: 0.853151]\n",
      "epoch:5 step:4172[D loss: 0.502440, acc: 50.00%, op_acc: 32.03%] [G loss: 0.870290]\n",
      "epoch:5 step:4173[D loss: 0.445260, acc: 60.94%, op_acc: 35.94%] [G loss: 0.874685]\n",
      "epoch:5 step:4174[D loss: 0.463418, acc: 57.03%, op_acc: 32.81%] [G loss: 0.999548]\n",
      "epoch:5 step:4175[D loss: 0.444997, acc: 64.06%, op_acc: 33.59%] [G loss: 1.015722]\n",
      "epoch:5 step:4176[D loss: 0.456532, acc: 64.84%, op_acc: 32.03%] [G loss: 0.955148]\n",
      "epoch:5 step:4177[D loss: 0.469854, acc: 58.59%, op_acc: 26.56%] [G loss: 0.978786]\n",
      "epoch:5 step:4178[D loss: 0.428568, acc: 67.97%, op_acc: 29.69%] [G loss: 0.913176]\n",
      "epoch:5 step:4179[D loss: 0.469666, acc: 55.47%, op_acc: 31.25%] [G loss: 1.019726]\n",
      "epoch:5 step:4180[D loss: 0.438381, acc: 63.28%, op_acc: 30.47%] [G loss: 0.929203]\n",
      "epoch:5 step:4181[D loss: 0.471419, acc: 54.69%, op_acc: 31.25%] [G loss: 0.921970]\n",
      "epoch:5 step:4182[D loss: 0.486044, acc: 56.25%, op_acc: 26.56%] [G loss: 0.970784]\n",
      "epoch:5 step:4183[D loss: 0.445251, acc: 61.72%, op_acc: 34.38%] [G loss: 0.970686]\n",
      "epoch:5 step:4184[D loss: 0.414443, acc: 67.97%, op_acc: 39.84%] [G loss: 0.982309]\n",
      "epoch:5 step:4185[D loss: 0.422373, acc: 60.94%, op_acc: 37.50%] [G loss: 0.957475]\n",
      "epoch:5 step:4186[D loss: 0.458459, acc: 60.94%, op_acc: 28.91%] [G loss: 0.907349]\n",
      "epoch:5 step:4187[D loss: 0.456097, acc: 60.94%, op_acc: 28.91%] [G loss: 0.863097]\n",
      "epoch:5 step:4188[D loss: 0.461132, acc: 53.91%, op_acc: 36.72%] [G loss: 0.967855]\n",
      "epoch:5 step:4189[D loss: 0.464756, acc: 60.16%, op_acc: 29.69%] [G loss: 0.896655]\n",
      "epoch:5 step:4190[D loss: 0.432697, acc: 60.16%, op_acc: 31.25%] [G loss: 0.860986]\n",
      "epoch:5 step:4191[D loss: 0.420231, acc: 72.66%, op_acc: 31.25%] [G loss: 0.878472]\n",
      "epoch:5 step:4192[D loss: 0.460815, acc: 57.81%, op_acc: 36.72%] [G loss: 0.944132]\n",
      "epoch:5 step:4193[D loss: 0.441351, acc: 60.94%, op_acc: 31.25%] [G loss: 0.965620]\n",
      "epoch:5 step:4194[D loss: 0.473556, acc: 55.47%, op_acc: 28.12%] [G loss: 0.902360]\n",
      "epoch:5 step:4195[D loss: 0.452354, acc: 62.50%, op_acc: 35.94%] [G loss: 0.976361]\n",
      "epoch:5 step:4196[D loss: 0.440457, acc: 66.41%, op_acc: 32.03%] [G loss: 0.858353]\n",
      "epoch:5 step:4197[D loss: 0.479131, acc: 53.12%, op_acc: 29.69%] [G loss: 0.856571]\n",
      "epoch:5 step:4198[D loss: 0.418957, acc: 67.97%, op_acc: 33.59%] [G loss: 0.808945]\n",
      "epoch:5 step:4199[D loss: 0.449333, acc: 60.16%, op_acc: 32.81%] [G loss: 0.870462]\n",
      "epoch:5 step:4200[D loss: 0.443380, acc: 58.59%, op_acc: 29.69%] [G loss: 0.923268]\n",
      "##############\n",
      "[0.85636354 0.86403932 0.8045384  0.80308724 0.77852659 0.83769156\n",
      " 0.85916459 0.83173596 0.81413887 0.85429921]\n",
      "##########\n",
      "epoch:5 step:4201[D loss: 0.460188, acc: 53.91%, op_acc: 38.28%] [G loss: 0.868808]\n",
      "epoch:5 step:4202[D loss: 0.458605, acc: 63.28%, op_acc: 26.56%] [G loss: 0.915250]\n",
      "epoch:5 step:4203[D loss: 0.457316, acc: 58.59%, op_acc: 30.47%] [G loss: 1.055087]\n",
      "epoch:5 step:4204[D loss: 0.443207, acc: 60.94%, op_acc: 35.94%] [G loss: 0.919912]\n",
      "epoch:5 step:4205[D loss: 0.498352, acc: 53.12%, op_acc: 28.91%] [G loss: 0.883525]\n",
      "epoch:5 step:4206[D loss: 0.465883, acc: 52.34%, op_acc: 32.03%] [G loss: 1.024834]\n",
      "epoch:5 step:4207[D loss: 0.439626, acc: 55.47%, op_acc: 37.50%] [G loss: 0.864459]\n",
      "epoch:5 step:4208[D loss: 0.437300, acc: 63.28%, op_acc: 28.91%] [G loss: 0.890866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4209[D loss: 0.474314, acc: 50.78%, op_acc: 33.59%] [G loss: 0.875888]\n",
      "epoch:5 step:4210[D loss: 0.485942, acc: 52.34%, op_acc: 28.91%] [G loss: 0.877582]\n",
      "epoch:5 step:4211[D loss: 0.526070, acc: 54.69%, op_acc: 24.22%] [G loss: 0.894296]\n",
      "epoch:5 step:4212[D loss: 0.449501, acc: 60.94%, op_acc: 29.69%] [G loss: 0.892412]\n",
      "epoch:5 step:4213[D loss: 0.433723, acc: 64.84%, op_acc: 30.47%] [G loss: 0.919420]\n",
      "epoch:5 step:4214[D loss: 0.451038, acc: 65.62%, op_acc: 31.25%] [G loss: 0.836051]\n",
      "epoch:5 step:4215[D loss: 0.455849, acc: 58.59%, op_acc: 29.69%] [G loss: 0.903826]\n",
      "epoch:5 step:4216[D loss: 0.437820, acc: 65.62%, op_acc: 31.25%] [G loss: 0.875829]\n",
      "epoch:5 step:4217[D loss: 0.431096, acc: 66.41%, op_acc: 30.47%] [G loss: 0.956324]\n",
      "epoch:5 step:4218[D loss: 0.434478, acc: 61.72%, op_acc: 28.91%] [G loss: 0.939458]\n",
      "epoch:5 step:4219[D loss: 0.479028, acc: 55.47%, op_acc: 29.69%] [G loss: 0.981513]\n",
      "epoch:5 step:4220[D loss: 0.455336, acc: 57.03%, op_acc: 31.25%] [G loss: 1.007611]\n",
      "epoch:5 step:4221[D loss: 0.438511, acc: 61.72%, op_acc: 29.69%] [G loss: 0.971439]\n",
      "epoch:5 step:4222[D loss: 0.429735, acc: 64.84%, op_acc: 28.91%] [G loss: 1.020059]\n",
      "epoch:5 step:4223[D loss: 0.432344, acc: 66.41%, op_acc: 31.25%] [G loss: 0.983563]\n",
      "epoch:5 step:4224[D loss: 0.450620, acc: 61.72%, op_acc: 32.03%] [G loss: 0.941014]\n",
      "epoch:5 step:4225[D loss: 0.448846, acc: 64.06%, op_acc: 32.81%] [G loss: 0.936775]\n",
      "epoch:5 step:4226[D loss: 0.489045, acc: 52.34%, op_acc: 27.34%] [G loss: 0.816309]\n",
      "epoch:5 step:4227[D loss: 0.466064, acc: 63.28%, op_acc: 27.34%] [G loss: 0.932902]\n",
      "epoch:5 step:4228[D loss: 0.456917, acc: 58.59%, op_acc: 35.94%] [G loss: 0.866993]\n",
      "epoch:5 step:4229[D loss: 0.426398, acc: 68.75%, op_acc: 26.56%] [G loss: 0.904540]\n",
      "epoch:5 step:4230[D loss: 0.417945, acc: 67.97%, op_acc: 34.38%] [G loss: 0.916254]\n",
      "epoch:5 step:4231[D loss: 0.423009, acc: 65.62%, op_acc: 32.03%] [G loss: 0.895678]\n",
      "epoch:5 step:4232[D loss: 0.465288, acc: 58.59%, op_acc: 30.47%] [G loss: 0.936432]\n",
      "epoch:5 step:4233[D loss: 0.468909, acc: 57.81%, op_acc: 33.59%] [G loss: 0.830765]\n",
      "epoch:5 step:4234[D loss: 0.456274, acc: 55.47%, op_acc: 29.69%] [G loss: 0.794948]\n",
      "epoch:5 step:4235[D loss: 0.479771, acc: 56.25%, op_acc: 34.38%] [G loss: 0.931548]\n",
      "epoch:5 step:4236[D loss: 0.464849, acc: 53.12%, op_acc: 25.00%] [G loss: 0.862494]\n",
      "epoch:5 step:4237[D loss: 0.411392, acc: 70.31%, op_acc: 34.38%] [G loss: 0.976701]\n",
      "epoch:5 step:4238[D loss: 0.414846, acc: 71.09%, op_acc: 35.94%] [G loss: 0.913516]\n",
      "epoch:5 step:4239[D loss: 0.471842, acc: 54.69%, op_acc: 32.81%] [G loss: 0.871984]\n",
      "epoch:5 step:4240[D loss: 0.463247, acc: 61.72%, op_acc: 26.56%] [G loss: 0.943522]\n",
      "epoch:5 step:4241[D loss: 0.507232, acc: 51.56%, op_acc: 25.78%] [G loss: 0.911377]\n",
      "epoch:5 step:4242[D loss: 0.456862, acc: 56.25%, op_acc: 35.94%] [G loss: 0.888999]\n",
      "epoch:5 step:4243[D loss: 0.444541, acc: 56.25%, op_acc: 34.38%] [G loss: 1.012641]\n",
      "epoch:5 step:4244[D loss: 0.470718, acc: 55.47%, op_acc: 27.34%] [G loss: 0.937732]\n",
      "epoch:5 step:4245[D loss: 0.435349, acc: 60.16%, op_acc: 29.69%] [G loss: 0.893471]\n",
      "epoch:5 step:4246[D loss: 0.451708, acc: 67.19%, op_acc: 28.91%] [G loss: 0.985033]\n",
      "epoch:5 step:4247[D loss: 0.460773, acc: 58.59%, op_acc: 24.22%] [G loss: 0.896227]\n",
      "epoch:5 step:4248[D loss: 0.476383, acc: 56.25%, op_acc: 25.78%] [G loss: 0.858945]\n",
      "epoch:5 step:4249[D loss: 0.432342, acc: 67.97%, op_acc: 32.03%] [G loss: 0.898588]\n",
      "epoch:5 step:4250[D loss: 0.457796, acc: 61.72%, op_acc: 31.25%] [G loss: 0.884975]\n",
      "##############\n",
      "[0.85702775 0.86467187 0.80220277 0.80051283 0.7918904  0.80974747\n",
      " 0.89986001 0.82108234 0.81862569 0.82745613]\n",
      "##########\n",
      "epoch:5 step:4251[D loss: 0.420156, acc: 63.28%, op_acc: 32.81%] [G loss: 0.933914]\n",
      "epoch:5 step:4252[D loss: 0.464985, acc: 49.22%, op_acc: 33.59%] [G loss: 0.908178]\n",
      "epoch:5 step:4253[D loss: 0.443963, acc: 63.28%, op_acc: 28.12%] [G loss: 0.916206]\n",
      "epoch:5 step:4254[D loss: 0.454664, acc: 56.25%, op_acc: 30.47%] [G loss: 0.957600]\n",
      "epoch:5 step:4255[D loss: 0.455301, acc: 57.03%, op_acc: 32.81%] [G loss: 0.871869]\n",
      "epoch:5 step:4256[D loss: 0.507916, acc: 49.22%, op_acc: 26.56%] [G loss: 0.919378]\n",
      "epoch:5 step:4257[D loss: 0.461676, acc: 55.47%, op_acc: 27.34%] [G loss: 1.016018]\n",
      "epoch:5 step:4258[D loss: 0.432315, acc: 58.59%, op_acc: 37.50%] [G loss: 0.988234]\n",
      "epoch:5 step:4259[D loss: 0.455883, acc: 51.56%, op_acc: 36.72%] [G loss: 0.911729]\n",
      "epoch:5 step:4260[D loss: 0.462773, acc: 51.56%, op_acc: 32.03%] [G loss: 0.955405]\n",
      "epoch:5 step:4261[D loss: 0.483126, acc: 56.25%, op_acc: 28.12%] [G loss: 0.912839]\n",
      "epoch:5 step:4262[D loss: 0.445440, acc: 63.28%, op_acc: 32.03%] [G loss: 0.978074]\n",
      "epoch:5 step:4263[D loss: 0.477199, acc: 56.25%, op_acc: 32.81%] [G loss: 0.889533]\n",
      "epoch:5 step:4264[D loss: 0.477279, acc: 57.81%, op_acc: 28.12%] [G loss: 0.913736]\n",
      "epoch:5 step:4265[D loss: 0.449951, acc: 61.72%, op_acc: 33.59%] [G loss: 0.888379]\n",
      "epoch:5 step:4266[D loss: 0.444797, acc: 59.38%, op_acc: 32.81%] [G loss: 0.932181]\n",
      "epoch:5 step:4267[D loss: 0.393408, acc: 63.28%, op_acc: 40.62%] [G loss: 0.925377]\n",
      "epoch:5 step:4268[D loss: 0.469308, acc: 55.47%, op_acc: 27.34%] [G loss: 0.933749]\n",
      "epoch:5 step:4269[D loss: 0.482052, acc: 50.00%, op_acc: 29.69%] [G loss: 0.986735]\n",
      "epoch:5 step:4270[D loss: 0.447298, acc: 53.12%, op_acc: 37.50%] [G loss: 0.895937]\n",
      "epoch:5 step:4271[D loss: 0.441077, acc: 57.81%, op_acc: 31.25%] [G loss: 0.863880]\n",
      "epoch:5 step:4272[D loss: 0.449505, acc: 62.50%, op_acc: 31.25%] [G loss: 0.815912]\n",
      "epoch:5 step:4273[D loss: 0.432744, acc: 66.41%, op_acc: 28.12%] [G loss: 0.889636]\n",
      "epoch:5 step:4274[D loss: 0.447548, acc: 62.50%, op_acc: 31.25%] [G loss: 0.970524]\n",
      "epoch:5 step:4275[D loss: 0.444960, acc: 65.62%, op_acc: 30.47%] [G loss: 0.897482]\n",
      "epoch:5 step:4276[D loss: 0.425791, acc: 63.28%, op_acc: 38.28%] [G loss: 0.899125]\n",
      "epoch:5 step:4277[D loss: 0.454630, acc: 55.47%, op_acc: 35.16%] [G loss: 0.926965]\n",
      "epoch:5 step:4278[D loss: 0.468045, acc: 57.81%, op_acc: 34.38%] [G loss: 0.919072]\n",
      "epoch:5 step:4279[D loss: 0.439930, acc: 60.16%, op_acc: 39.06%] [G loss: 0.945479]\n",
      "epoch:5 step:4280[D loss: 0.424959, acc: 67.19%, op_acc: 30.47%] [G loss: 0.948840]\n",
      "epoch:5 step:4281[D loss: 0.418446, acc: 68.75%, op_acc: 33.59%] [G loss: 0.903418]\n",
      "epoch:5 step:4282[D loss: 0.449647, acc: 60.16%, op_acc: 32.03%] [G loss: 0.912698]\n",
      "epoch:5 step:4283[D loss: 0.435731, acc: 64.84%, op_acc: 37.50%] [G loss: 0.988800]\n",
      "epoch:5 step:4284[D loss: 0.407092, acc: 67.19%, op_acc: 39.06%] [G loss: 0.990398]\n",
      "epoch:5 step:4285[D loss: 0.465002, acc: 59.38%, op_acc: 35.16%] [G loss: 0.847232]\n",
      "epoch:5 step:4286[D loss: 0.445093, acc: 60.94%, op_acc: 34.38%] [G loss: 0.926424]\n",
      "epoch:5 step:4287[D loss: 0.423679, acc: 65.62%, op_acc: 32.81%] [G loss: 0.979314]\n",
      "epoch:5 step:4288[D loss: 0.461465, acc: 56.25%, op_acc: 35.16%] [G loss: 0.853122]\n",
      "epoch:5 step:4289[D loss: 0.435488, acc: 58.59%, op_acc: 32.03%] [G loss: 0.926467]\n",
      "epoch:5 step:4290[D loss: 0.451188, acc: 55.47%, op_acc: 34.38%] [G loss: 0.870256]\n",
      "epoch:5 step:4291[D loss: 0.451043, acc: 60.16%, op_acc: 32.03%] [G loss: 0.990365]\n",
      "epoch:5 step:4292[D loss: 0.483735, acc: 53.91%, op_acc: 28.91%] [G loss: 0.958980]\n",
      "epoch:5 step:4293[D loss: 0.496138, acc: 52.34%, op_acc: 25.00%] [G loss: 0.868073]\n",
      "epoch:5 step:4294[D loss: 0.464682, acc: 57.03%, op_acc: 32.81%] [G loss: 0.869691]\n",
      "epoch:5 step:4295[D loss: 0.429149, acc: 61.72%, op_acc: 37.50%] [G loss: 0.986205]\n",
      "epoch:5 step:4296[D loss: 0.426511, acc: 62.50%, op_acc: 31.25%] [G loss: 0.929228]\n",
      "epoch:5 step:4297[D loss: 0.433006, acc: 57.81%, op_acc: 39.06%] [G loss: 0.960032]\n",
      "epoch:5 step:4298[D loss: 0.440893, acc: 60.94%, op_acc: 35.16%] [G loss: 0.898724]\n",
      "epoch:5 step:4299[D loss: 0.457154, acc: 60.16%, op_acc: 32.03%] [G loss: 0.978687]\n",
      "epoch:5 step:4300[D loss: 0.474730, acc: 60.94%, op_acc: 23.44%] [G loss: 0.902537]\n",
      "##############\n",
      "[0.86493205 0.85759788 0.81273591 0.81242562 0.79941266 0.83612864\n",
      " 0.88837655 0.81483756 0.80378876 0.833916  ]\n",
      "##########\n",
      "epoch:5 step:4301[D loss: 0.431033, acc: 65.62%, op_acc: 36.72%] [G loss: 0.948515]\n",
      "epoch:5 step:4302[D loss: 0.451035, acc: 60.94%, op_acc: 35.16%] [G loss: 1.044103]\n",
      "epoch:5 step:4303[D loss: 0.487005, acc: 50.78%, op_acc: 27.34%] [G loss: 0.864749]\n",
      "epoch:5 step:4304[D loss: 0.443527, acc: 60.16%, op_acc: 39.06%] [G loss: 0.950087]\n",
      "epoch:5 step:4305[D loss: 0.439745, acc: 60.94%, op_acc: 36.72%] [G loss: 0.914726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4306[D loss: 0.448692, acc: 59.38%, op_acc: 34.38%] [G loss: 0.894781]\n",
      "epoch:5 step:4307[D loss: 0.439292, acc: 63.28%, op_acc: 32.03%] [G loss: 1.028021]\n",
      "epoch:5 step:4308[D loss: 0.473261, acc: 55.47%, op_acc: 26.56%] [G loss: 0.862657]\n",
      "epoch:5 step:4309[D loss: 0.409344, acc: 67.19%, op_acc: 35.16%] [G loss: 1.055436]\n",
      "epoch:5 step:4310[D loss: 0.481833, acc: 57.81%, op_acc: 32.03%] [G loss: 0.937158]\n",
      "epoch:5 step:4311[D loss: 0.441438, acc: 57.81%, op_acc: 35.16%] [G loss: 0.896507]\n",
      "epoch:5 step:4312[D loss: 0.471668, acc: 57.03%, op_acc: 26.56%] [G loss: 0.919219]\n",
      "epoch:5 step:4313[D loss: 0.427894, acc: 58.59%, op_acc: 40.62%] [G loss: 0.960494]\n",
      "epoch:5 step:4314[D loss: 0.439374, acc: 59.38%, op_acc: 33.59%] [G loss: 0.940066]\n",
      "epoch:5 step:4315[D loss: 0.410894, acc: 66.41%, op_acc: 35.16%] [G loss: 0.974520]\n",
      "epoch:5 step:4316[D loss: 0.438953, acc: 61.72%, op_acc: 35.94%] [G loss: 0.979615]\n",
      "epoch:5 step:4317[D loss: 0.459144, acc: 60.16%, op_acc: 34.38%] [G loss: 0.922419]\n",
      "epoch:5 step:4318[D loss: 0.438072, acc: 63.28%, op_acc: 33.59%] [G loss: 0.940897]\n",
      "epoch:5 step:4319[D loss: 0.451184, acc: 59.38%, op_acc: 32.81%] [G loss: 0.922499]\n",
      "epoch:5 step:4320[D loss: 0.440947, acc: 62.50%, op_acc: 30.47%] [G loss: 0.937694]\n",
      "epoch:5 step:4321[D loss: 0.449910, acc: 64.06%, op_acc: 28.91%] [G loss: 0.936617]\n",
      "epoch:5 step:4322[D loss: 0.433673, acc: 67.19%, op_acc: 32.81%] [G loss: 0.903938]\n",
      "epoch:5 step:4323[D loss: 0.407324, acc: 67.19%, op_acc: 34.38%] [G loss: 0.941713]\n",
      "epoch:5 step:4324[D loss: 0.445933, acc: 66.41%, op_acc: 28.91%] [G loss: 0.966123]\n",
      "epoch:5 step:4325[D loss: 0.452676, acc: 62.50%, op_acc: 30.47%] [G loss: 0.880863]\n",
      "epoch:5 step:4326[D loss: 0.414194, acc: 67.19%, op_acc: 36.72%] [G loss: 0.900765]\n",
      "epoch:5 step:4327[D loss: 0.426035, acc: 61.72%, op_acc: 35.94%] [G loss: 0.924447]\n",
      "epoch:5 step:4328[D loss: 0.468188, acc: 53.91%, op_acc: 32.03%] [G loss: 0.993400]\n",
      "epoch:5 step:4329[D loss: 0.447785, acc: 58.59%, op_acc: 28.12%] [G loss: 0.987441]\n",
      "epoch:5 step:4330[D loss: 0.456030, acc: 56.25%, op_acc: 32.81%] [G loss: 0.971474]\n",
      "epoch:5 step:4331[D loss: 0.447499, acc: 63.28%, op_acc: 32.03%] [G loss: 0.887075]\n",
      "epoch:5 step:4332[D loss: 0.452678, acc: 55.47%, op_acc: 28.91%] [G loss: 0.985185]\n",
      "epoch:5 step:4333[D loss: 0.441902, acc: 59.38%, op_acc: 31.25%] [G loss: 1.038718]\n",
      "epoch:5 step:4334[D loss: 0.469074, acc: 59.38%, op_acc: 32.03%] [G loss: 0.882048]\n",
      "epoch:5 step:4335[D loss: 0.466730, acc: 59.38%, op_acc: 28.91%] [G loss: 0.987794]\n",
      "epoch:5 step:4336[D loss: 0.459526, acc: 57.03%, op_acc: 34.38%] [G loss: 0.959954]\n",
      "epoch:5 step:4337[D loss: 0.440451, acc: 61.72%, op_acc: 35.94%] [G loss: 0.929978]\n",
      "epoch:5 step:4338[D loss: 0.462021, acc: 56.25%, op_acc: 29.69%] [G loss: 0.996432]\n",
      "epoch:5 step:4339[D loss: 0.443633, acc: 61.72%, op_acc: 37.50%] [G loss: 1.020445]\n",
      "epoch:5 step:4340[D loss: 0.422621, acc: 64.06%, op_acc: 39.06%] [G loss: 0.874543]\n",
      "epoch:5 step:4341[D loss: 0.502666, acc: 52.34%, op_acc: 29.69%] [G loss: 0.841917]\n",
      "epoch:5 step:4342[D loss: 0.466170, acc: 56.25%, op_acc: 34.38%] [G loss: 0.945793]\n",
      "epoch:5 step:4343[D loss: 0.446429, acc: 62.50%, op_acc: 33.59%] [G loss: 0.929948]\n",
      "epoch:5 step:4344[D loss: 0.462053, acc: 56.25%, op_acc: 29.69%] [G loss: 0.909922]\n",
      "epoch:5 step:4345[D loss: 0.442869, acc: 62.50%, op_acc: 35.94%] [G loss: 0.937236]\n",
      "epoch:5 step:4346[D loss: 0.475704, acc: 53.91%, op_acc: 32.03%] [G loss: 0.895017]\n",
      "epoch:5 step:4347[D loss: 0.442461, acc: 60.16%, op_acc: 32.03%] [G loss: 0.956620]\n",
      "epoch:5 step:4348[D loss: 0.474476, acc: 58.59%, op_acc: 27.34%] [G loss: 0.911012]\n",
      "epoch:5 step:4349[D loss: 0.408121, acc: 68.75%, op_acc: 41.41%] [G loss: 1.001372]\n",
      "epoch:5 step:4350[D loss: 0.451730, acc: 59.38%, op_acc: 30.47%] [G loss: 0.977134]\n",
      "##############\n",
      "[0.86703259 0.86152142 0.81534941 0.80328517 0.77503985 0.82418184\n",
      " 0.86962228 0.82318613 0.80098437 0.83878169]\n",
      "##########\n",
      "epoch:5 step:4351[D loss: 0.447627, acc: 61.72%, op_acc: 29.69%] [G loss: 0.928648]\n",
      "epoch:5 step:4352[D loss: 0.454886, acc: 66.41%, op_acc: 27.34%] [G loss: 0.971771]\n",
      "epoch:5 step:4353[D loss: 0.440097, acc: 63.28%, op_acc: 33.59%] [G loss: 0.917873]\n",
      "epoch:5 step:4354[D loss: 0.447594, acc: 61.72%, op_acc: 33.59%] [G loss: 0.968121]\n",
      "epoch:5 step:4355[D loss: 0.454661, acc: 66.41%, op_acc: 26.56%] [G loss: 0.976894]\n",
      "epoch:5 step:4356[D loss: 0.450777, acc: 55.47%, op_acc: 38.28%] [G loss: 0.892042]\n",
      "epoch:5 step:4357[D loss: 0.406481, acc: 66.41%, op_acc: 34.38%] [G loss: 0.937874]\n",
      "epoch:5 step:4358[D loss: 0.442838, acc: 60.16%, op_acc: 33.59%] [G loss: 0.884753]\n",
      "epoch:5 step:4359[D loss: 0.434139, acc: 62.50%, op_acc: 28.91%] [G loss: 1.012945]\n",
      "epoch:5 step:4360[D loss: 0.444827, acc: 60.16%, op_acc: 28.12%] [G loss: 0.979098]\n",
      "epoch:5 step:4361[D loss: 0.416495, acc: 71.09%, op_acc: 34.38%] [G loss: 0.962925]\n",
      "epoch:5 step:4362[D loss: 0.434412, acc: 64.06%, op_acc: 30.47%] [G loss: 0.878549]\n",
      "epoch:5 step:4363[D loss: 0.446552, acc: 56.25%, op_acc: 35.16%] [G loss: 0.918247]\n",
      "epoch:5 step:4364[D loss: 0.427135, acc: 60.94%, op_acc: 35.94%] [G loss: 0.886344]\n",
      "epoch:5 step:4365[D loss: 0.451020, acc: 64.06%, op_acc: 27.34%] [G loss: 0.948298]\n",
      "epoch:5 step:4366[D loss: 0.457610, acc: 60.94%, op_acc: 28.12%] [G loss: 0.948042]\n",
      "epoch:5 step:4367[D loss: 0.442179, acc: 66.41%, op_acc: 35.94%] [G loss: 0.919340]\n",
      "epoch:5 step:4368[D loss: 0.446926, acc: 66.41%, op_acc: 30.47%] [G loss: 0.879587]\n",
      "epoch:5 step:4369[D loss: 0.458589, acc: 59.38%, op_acc: 30.47%] [G loss: 0.871962]\n",
      "epoch:5 step:4370[D loss: 0.462953, acc: 57.03%, op_acc: 29.69%] [G loss: 0.904819]\n",
      "epoch:5 step:4371[D loss: 0.464330, acc: 59.38%, op_acc: 32.03%] [G loss: 0.901971]\n",
      "epoch:5 step:4372[D loss: 0.460146, acc: 54.69%, op_acc: 32.81%] [G loss: 0.939943]\n",
      "epoch:5 step:4373[D loss: 0.445029, acc: 53.12%, op_acc: 37.50%] [G loss: 0.889319]\n",
      "epoch:5 step:4374[D loss: 0.427659, acc: 57.03%, op_acc: 33.59%] [G loss: 0.847223]\n",
      "epoch:5 step:4375[D loss: 0.437554, acc: 57.81%, op_acc: 33.59%] [G loss: 0.893234]\n",
      "epoch:5 step:4376[D loss: 0.458056, acc: 57.81%, op_acc: 28.91%] [G loss: 0.979675]\n",
      "epoch:5 step:4377[D loss: 0.457415, acc: 62.50%, op_acc: 28.91%] [G loss: 0.961553]\n",
      "epoch:5 step:4378[D loss: 0.421356, acc: 64.06%, op_acc: 39.84%] [G loss: 0.919488]\n",
      "epoch:5 step:4379[D loss: 0.464099, acc: 57.03%, op_acc: 32.81%] [G loss: 0.952268]\n",
      "epoch:5 step:4380[D loss: 0.463887, acc: 56.25%, op_acc: 34.38%] [G loss: 0.919018]\n",
      "epoch:5 step:4381[D loss: 0.445666, acc: 66.41%, op_acc: 28.12%] [G loss: 0.885909]\n",
      "epoch:5 step:4382[D loss: 0.468230, acc: 57.81%, op_acc: 30.47%] [G loss: 0.931531]\n",
      "epoch:5 step:4383[D loss: 0.435158, acc: 64.06%, op_acc: 32.03%] [G loss: 1.025616]\n",
      "epoch:5 step:4384[D loss: 0.461373, acc: 57.81%, op_acc: 32.03%] [G loss: 0.944485]\n",
      "epoch:5 step:4385[D loss: 0.469276, acc: 60.16%, op_acc: 24.22%] [G loss: 0.962262]\n",
      "epoch:5 step:4386[D loss: 0.459798, acc: 64.84%, op_acc: 28.12%] [G loss: 0.879131]\n",
      "epoch:5 step:4387[D loss: 0.452181, acc: 60.94%, op_acc: 35.16%] [G loss: 0.904085]\n",
      "epoch:5 step:4388[D loss: 0.448243, acc: 67.19%, op_acc: 31.25%] [G loss: 0.907208]\n",
      "epoch:5 step:4389[D loss: 0.408684, acc: 60.16%, op_acc: 39.06%] [G loss: 1.056604]\n",
      "epoch:5 step:4390[D loss: 0.435316, acc: 67.97%, op_acc: 32.81%] [G loss: 0.975459]\n",
      "epoch:5 step:4391[D loss: 0.436713, acc: 66.41%, op_acc: 35.94%] [G loss: 0.949277]\n",
      "epoch:5 step:4392[D loss: 0.433693, acc: 58.59%, op_acc: 35.16%] [G loss: 0.972707]\n",
      "epoch:5 step:4393[D loss: 0.414017, acc: 64.06%, op_acc: 34.38%] [G loss: 0.994901]\n",
      "epoch:5 step:4394[D loss: 0.441228, acc: 59.38%, op_acc: 34.38%] [G loss: 0.931786]\n",
      "epoch:5 step:4395[D loss: 0.429928, acc: 64.84%, op_acc: 37.50%] [G loss: 0.936012]\n",
      "epoch:5 step:4396[D loss: 0.457106, acc: 58.59%, op_acc: 32.81%] [G loss: 0.874925]\n",
      "epoch:5 step:4397[D loss: 0.438027, acc: 67.97%, op_acc: 32.03%] [G loss: 0.873614]\n",
      "epoch:5 step:4398[D loss: 0.430006, acc: 65.62%, op_acc: 36.72%] [G loss: 0.888538]\n",
      "epoch:5 step:4399[D loss: 0.419331, acc: 59.38%, op_acc: 42.19%] [G loss: 0.884825]\n",
      "epoch:5 step:4400[D loss: 0.423201, acc: 65.62%, op_acc: 37.50%] [G loss: 1.007119]\n",
      "##############\n",
      "[0.88190132 0.87542247 0.81068662 0.80747367 0.79268602 0.82002903\n",
      " 0.87672117 0.81276086 0.81505147 0.82881299]\n",
      "##########\n",
      "epoch:5 step:4401[D loss: 0.460867, acc: 57.81%, op_acc: 31.25%] [G loss: 0.897874]\n",
      "epoch:5 step:4402[D loss: 0.447425, acc: 60.16%, op_acc: 30.47%] [G loss: 0.892501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4403[D loss: 0.463638, acc: 51.56%, op_acc: 35.94%] [G loss: 0.893557]\n",
      "epoch:5 step:4404[D loss: 0.503029, acc: 54.69%, op_acc: 30.47%] [G loss: 0.819196]\n",
      "epoch:5 step:4405[D loss: 0.449157, acc: 59.38%, op_acc: 35.16%] [G loss: 0.947318]\n",
      "epoch:5 step:4406[D loss: 0.429020, acc: 69.53%, op_acc: 31.25%] [G loss: 0.953989]\n",
      "epoch:5 step:4407[D loss: 0.471856, acc: 50.78%, op_acc: 32.81%] [G loss: 0.933604]\n",
      "epoch:5 step:4408[D loss: 0.434642, acc: 65.62%, op_acc: 31.25%] [G loss: 0.871692]\n",
      "epoch:5 step:4409[D loss: 0.495639, acc: 50.00%, op_acc: 29.69%] [G loss: 0.825420]\n",
      "epoch:5 step:4410[D loss: 0.458205, acc: 57.03%, op_acc: 33.59%] [G loss: 0.871538]\n",
      "epoch:5 step:4411[D loss: 0.452820, acc: 55.47%, op_acc: 36.72%] [G loss: 0.900725]\n",
      "epoch:5 step:4412[D loss: 0.442567, acc: 60.16%, op_acc: 32.81%] [G loss: 0.911108]\n",
      "epoch:5 step:4413[D loss: 0.424807, acc: 60.94%, op_acc: 33.59%] [G loss: 0.861397]\n",
      "epoch:5 step:4414[D loss: 0.461713, acc: 55.47%, op_acc: 32.81%] [G loss: 0.968873]\n",
      "epoch:5 step:4415[D loss: 0.442443, acc: 65.62%, op_acc: 32.81%] [G loss: 1.023258]\n",
      "epoch:5 step:4416[D loss: 0.470657, acc: 54.69%, op_acc: 31.25%] [G loss: 0.879709]\n",
      "epoch:5 step:4417[D loss: 0.462318, acc: 54.69%, op_acc: 28.91%] [G loss: 0.966148]\n",
      "epoch:5 step:4418[D loss: 0.471499, acc: 54.69%, op_acc: 31.25%] [G loss: 0.899699]\n",
      "epoch:5 step:4419[D loss: 0.488055, acc: 54.69%, op_acc: 33.59%] [G loss: 0.942344]\n",
      "epoch:5 step:4420[D loss: 0.452904, acc: 62.50%, op_acc: 28.12%] [G loss: 0.902832]\n",
      "epoch:5 step:4421[D loss: 0.415246, acc: 64.06%, op_acc: 32.81%] [G loss: 0.973466]\n",
      "epoch:5 step:4422[D loss: 0.454364, acc: 62.50%, op_acc: 32.03%] [G loss: 0.892558]\n",
      "epoch:5 step:4423[D loss: 0.410390, acc: 65.62%, op_acc: 35.94%] [G loss: 0.953323]\n",
      "epoch:5 step:4424[D loss: 0.416040, acc: 66.41%, op_acc: 35.16%] [G loss: 0.872926]\n",
      "epoch:5 step:4425[D loss: 0.464417, acc: 56.25%, op_acc: 31.25%] [G loss: 0.929982]\n",
      "epoch:5 step:4426[D loss: 0.434859, acc: 64.84%, op_acc: 32.03%] [G loss: 0.902879]\n",
      "epoch:5 step:4427[D loss: 0.451286, acc: 62.50%, op_acc: 32.03%] [G loss: 1.000549]\n",
      "epoch:5 step:4428[D loss: 0.455485, acc: 56.25%, op_acc: 31.25%] [G loss: 0.951834]\n",
      "epoch:5 step:4429[D loss: 0.447379, acc: 63.28%, op_acc: 32.81%] [G loss: 1.022925]\n",
      "epoch:5 step:4430[D loss: 0.432612, acc: 65.62%, op_acc: 28.12%] [G loss: 1.013254]\n",
      "epoch:5 step:4431[D loss: 0.482140, acc: 59.38%, op_acc: 25.00%] [G loss: 0.959034]\n",
      "epoch:5 step:4432[D loss: 0.482441, acc: 56.25%, op_acc: 26.56%] [G loss: 0.913167]\n",
      "epoch:5 step:4433[D loss: 0.449673, acc: 60.16%, op_acc: 35.94%] [G loss: 0.838558]\n",
      "epoch:5 step:4434[D loss: 0.434103, acc: 60.16%, op_acc: 30.47%] [G loss: 0.976315]\n",
      "epoch:5 step:4435[D loss: 0.470642, acc: 59.38%, op_acc: 29.69%] [G loss: 0.927837]\n",
      "epoch:5 step:4436[D loss: 0.448063, acc: 66.41%, op_acc: 28.12%] [G loss: 0.907533]\n",
      "epoch:5 step:4437[D loss: 0.455028, acc: 57.03%, op_acc: 28.12%] [G loss: 0.884667]\n",
      "epoch:5 step:4438[D loss: 0.435149, acc: 63.28%, op_acc: 33.59%] [G loss: 0.909267]\n",
      "epoch:5 step:4439[D loss: 0.441296, acc: 64.84%, op_acc: 36.72%] [G loss: 0.847003]\n",
      "epoch:5 step:4440[D loss: 0.484857, acc: 50.78%, op_acc: 30.47%] [G loss: 0.992304]\n",
      "epoch:5 step:4441[D loss: 0.424245, acc: 56.25%, op_acc: 41.41%] [G loss: 1.016611]\n",
      "epoch:5 step:4442[D loss: 0.448697, acc: 67.19%, op_acc: 32.03%] [G loss: 0.984386]\n",
      "epoch:5 step:4443[D loss: 0.447369, acc: 59.38%, op_acc: 32.03%] [G loss: 0.999074]\n",
      "epoch:5 step:4444[D loss: 0.482792, acc: 53.91%, op_acc: 32.03%] [G loss: 0.894116]\n",
      "epoch:5 step:4445[D loss: 0.435287, acc: 60.94%, op_acc: 37.50%] [G loss: 0.928790]\n",
      "epoch:5 step:4446[D loss: 0.439561, acc: 64.06%, op_acc: 33.59%] [G loss: 0.887747]\n",
      "epoch:5 step:4447[D loss: 0.470212, acc: 54.69%, op_acc: 33.59%] [G loss: 0.890929]\n",
      "epoch:5 step:4448[D loss: 0.447407, acc: 60.16%, op_acc: 34.38%] [G loss: 1.005872]\n",
      "epoch:5 step:4449[D loss: 0.457250, acc: 60.16%, op_acc: 35.94%] [G loss: 0.882380]\n",
      "epoch:5 step:4450[D loss: 0.452146, acc: 64.84%, op_acc: 28.12%] [G loss: 0.990180]\n",
      "##############\n",
      "[0.8457099  0.86013578 0.80748113 0.80794307 0.76577032 0.82518508\n",
      " 0.89303803 0.82455728 0.81277099 0.83433595]\n",
      "##########\n",
      "epoch:5 step:4451[D loss: 0.474320, acc: 53.91%, op_acc: 34.38%] [G loss: 1.051762]\n",
      "epoch:5 step:4452[D loss: 0.491356, acc: 57.81%, op_acc: 33.59%] [G loss: 0.985822]\n",
      "epoch:5 step:4453[D loss: 0.467178, acc: 60.94%, op_acc: 32.81%] [G loss: 0.983001]\n",
      "epoch:5 step:4454[D loss: 0.446927, acc: 57.81%, op_acc: 39.84%] [G loss: 0.884058]\n",
      "epoch:5 step:4455[D loss: 0.480333, acc: 53.91%, op_acc: 37.50%] [G loss: 0.914628]\n",
      "epoch:5 step:4456[D loss: 0.447892, acc: 60.94%, op_acc: 33.59%] [G loss: 1.034422]\n",
      "epoch:5 step:4457[D loss: 0.473048, acc: 54.69%, op_acc: 27.34%] [G loss: 0.922857]\n",
      "epoch:5 step:4458[D loss: 0.442693, acc: 57.81%, op_acc: 32.03%] [G loss: 0.875991]\n",
      "epoch:5 step:4459[D loss: 0.450852, acc: 59.38%, op_acc: 32.03%] [G loss: 0.865250]\n",
      "epoch:5 step:4460[D loss: 0.429612, acc: 63.28%, op_acc: 33.59%] [G loss: 0.981934]\n",
      "epoch:5 step:4461[D loss: 0.440488, acc: 60.94%, op_acc: 35.94%] [G loss: 0.910760]\n",
      "epoch:5 step:4462[D loss: 0.445755, acc: 60.16%, op_acc: 27.34%] [G loss: 0.935569]\n",
      "epoch:5 step:4463[D loss: 0.423506, acc: 65.62%, op_acc: 37.50%] [G loss: 0.911030]\n",
      "epoch:5 step:4464[D loss: 0.423939, acc: 67.97%, op_acc: 29.69%] [G loss: 0.949914]\n",
      "epoch:5 step:4465[D loss: 0.463333, acc: 60.16%, op_acc: 32.81%] [G loss: 0.936112]\n",
      "epoch:5 step:4466[D loss: 0.467181, acc: 59.38%, op_acc: 32.03%] [G loss: 0.892852]\n",
      "epoch:5 step:4467[D loss: 0.438758, acc: 57.81%, op_acc: 33.59%] [G loss: 1.043617]\n",
      "epoch:5 step:4468[D loss: 0.467174, acc: 57.03%, op_acc: 32.03%] [G loss: 0.916290]\n",
      "epoch:5 step:4469[D loss: 0.445516, acc: 64.84%, op_acc: 37.50%] [G loss: 0.890563]\n",
      "epoch:5 step:4470[D loss: 0.456893, acc: 55.47%, op_acc: 33.59%] [G loss: 0.975044]\n",
      "epoch:5 step:4471[D loss: 0.466575, acc: 60.94%, op_acc: 30.47%] [G loss: 0.872016]\n",
      "epoch:5 step:4472[D loss: 0.428306, acc: 71.09%, op_acc: 35.94%] [G loss: 0.938954]\n",
      "epoch:5 step:4473[D loss: 0.468219, acc: 60.16%, op_acc: 34.38%] [G loss: 0.856285]\n",
      "epoch:5 step:4474[D loss: 0.421987, acc: 65.62%, op_acc: 33.59%] [G loss: 0.880992]\n",
      "epoch:5 step:4475[D loss: 0.436821, acc: 57.81%, op_acc: 35.94%] [G loss: 0.880374]\n",
      "epoch:5 step:4476[D loss: 0.458487, acc: 60.94%, op_acc: 30.47%] [G loss: 0.895044]\n",
      "epoch:5 step:4477[D loss: 0.439260, acc: 64.06%, op_acc: 29.69%] [G loss: 0.831521]\n",
      "epoch:5 step:4478[D loss: 0.434332, acc: 64.84%, op_acc: 34.38%] [G loss: 0.892923]\n",
      "epoch:5 step:4479[D loss: 0.477111, acc: 53.12%, op_acc: 27.34%] [G loss: 0.896654]\n",
      "epoch:5 step:4480[D loss: 0.458078, acc: 57.03%, op_acc: 25.78%] [G loss: 0.867707]\n",
      "epoch:5 step:4481[D loss: 0.455282, acc: 59.38%, op_acc: 35.94%] [G loss: 0.847760]\n",
      "epoch:5 step:4482[D loss: 0.466389, acc: 60.16%, op_acc: 28.91%] [G loss: 0.871218]\n",
      "epoch:5 step:4483[D loss: 0.495617, acc: 58.59%, op_acc: 24.22%] [G loss: 1.024396]\n",
      "epoch:5 step:4484[D loss: 0.443618, acc: 60.16%, op_acc: 37.50%] [G loss: 1.012817]\n",
      "epoch:5 step:4485[D loss: 0.461055, acc: 60.94%, op_acc: 26.56%] [G loss: 0.971126]\n",
      "epoch:5 step:4486[D loss: 0.433324, acc: 67.97%, op_acc: 30.47%] [G loss: 1.077088]\n",
      "epoch:5 step:4487[D loss: 0.474983, acc: 57.81%, op_acc: 27.34%] [G loss: 0.941783]\n",
      "epoch:5 step:4488[D loss: 0.438374, acc: 56.25%, op_acc: 35.16%] [G loss: 0.957582]\n",
      "epoch:5 step:4489[D loss: 0.460532, acc: 62.50%, op_acc: 28.91%] [G loss: 0.973598]\n",
      "epoch:5 step:4490[D loss: 0.431056, acc: 64.06%, op_acc: 28.91%] [G loss: 0.985629]\n",
      "epoch:5 step:4491[D loss: 0.445373, acc: 71.09%, op_acc: 25.00%] [G loss: 0.935158]\n",
      "epoch:5 step:4492[D loss: 0.421059, acc: 65.62%, op_acc: 33.59%] [G loss: 1.056674]\n",
      "epoch:5 step:4493[D loss: 0.458831, acc: 56.25%, op_acc: 36.72%] [G loss: 1.004156]\n",
      "epoch:5 step:4494[D loss: 0.458022, acc: 60.16%, op_acc: 30.47%] [G loss: 0.933016]\n",
      "epoch:5 step:4495[D loss: 0.438579, acc: 64.84%, op_acc: 33.59%] [G loss: 0.960893]\n",
      "epoch:5 step:4496[D loss: 0.437762, acc: 61.72%, op_acc: 37.50%] [G loss: 1.046930]\n",
      "epoch:5 step:4497[D loss: 0.457585, acc: 59.38%, op_acc: 36.72%] [G loss: 0.883047]\n",
      "epoch:5 step:4498[D loss: 0.470066, acc: 62.50%, op_acc: 30.47%] [G loss: 0.929744]\n",
      "epoch:5 step:4499[D loss: 0.501417, acc: 46.88%, op_acc: 28.91%] [G loss: 0.922258]\n",
      "epoch:5 step:4500[D loss: 0.434972, acc: 70.31%, op_acc: 28.12%] [G loss: 0.982046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.8499893  0.85586035 0.81056911 0.78620225 0.79406683 0.83747045\n",
      " 0.89263825 0.8300022  0.80182789 0.8469008 ]\n",
      "##########\n",
      "epoch:5 step:4501[D loss: 0.416431, acc: 67.97%, op_acc: 38.28%] [G loss: 1.084846]\n",
      "epoch:5 step:4502[D loss: 0.464920, acc: 57.81%, op_acc: 30.47%] [G loss: 0.868975]\n",
      "epoch:5 step:4503[D loss: 0.429433, acc: 62.50%, op_acc: 39.06%] [G loss: 0.951427]\n",
      "epoch:5 step:4504[D loss: 0.464520, acc: 60.16%, op_acc: 27.34%] [G loss: 0.980257]\n",
      "epoch:5 step:4505[D loss: 0.417058, acc: 65.62%, op_acc: 35.94%] [G loss: 0.911634]\n",
      "epoch:5 step:4506[D loss: 0.448537, acc: 62.50%, op_acc: 27.34%] [G loss: 0.940804]\n",
      "epoch:5 step:4507[D loss: 0.384213, acc: 70.31%, op_acc: 37.50%] [G loss: 1.056160]\n",
      "epoch:5 step:4508[D loss: 0.427257, acc: 66.41%, op_acc: 34.38%] [G loss: 0.934839]\n",
      "epoch:5 step:4509[D loss: 0.493699, acc: 57.81%, op_acc: 26.56%] [G loss: 0.842904]\n",
      "epoch:5 step:4510[D loss: 0.424485, acc: 62.50%, op_acc: 34.38%] [G loss: 0.927613]\n",
      "epoch:5 step:4511[D loss: 0.463498, acc: 53.12%, op_acc: 35.94%] [G loss: 0.873914]\n",
      "epoch:5 step:4512[D loss: 0.397838, acc: 68.75%, op_acc: 46.09%] [G loss: 0.967229]\n",
      "epoch:5 step:4513[D loss: 0.417775, acc: 68.75%, op_acc: 32.81%] [G loss: 0.855286]\n",
      "epoch:5 step:4514[D loss: 0.467690, acc: 60.94%, op_acc: 35.94%] [G loss: 0.905820]\n",
      "epoch:5 step:4515[D loss: 0.403054, acc: 71.09%, op_acc: 34.38%] [G loss: 0.939336]\n",
      "epoch:5 step:4516[D loss: 0.448090, acc: 55.47%, op_acc: 33.59%] [G loss: 0.942944]\n",
      "epoch:5 step:4517[D loss: 0.420138, acc: 67.97%, op_acc: 35.16%] [G loss: 1.003555]\n",
      "epoch:5 step:4518[D loss: 0.446011, acc: 57.03%, op_acc: 38.28%] [G loss: 0.964323]\n",
      "epoch:5 step:4519[D loss: 0.428860, acc: 60.16%, op_acc: 31.25%] [G loss: 0.917198]\n",
      "epoch:5 step:4520[D loss: 0.452671, acc: 56.25%, op_acc: 33.59%] [G loss: 0.943799]\n",
      "epoch:5 step:4521[D loss: 0.425556, acc: 64.06%, op_acc: 35.16%] [G loss: 1.035080]\n",
      "epoch:5 step:4522[D loss: 0.485551, acc: 50.78%, op_acc: 30.47%] [G loss: 0.922097]\n",
      "epoch:5 step:4523[D loss: 0.431989, acc: 63.28%, op_acc: 39.06%] [G loss: 1.026745]\n",
      "epoch:5 step:4524[D loss: 0.487525, acc: 56.25%, op_acc: 28.91%] [G loss: 0.854720]\n",
      "epoch:5 step:4525[D loss: 0.431398, acc: 64.84%, op_acc: 28.91%] [G loss: 0.908144]\n",
      "epoch:5 step:4526[D loss: 0.459013, acc: 59.38%, op_acc: 30.47%] [G loss: 0.919030]\n",
      "epoch:5 step:4527[D loss: 0.475449, acc: 59.38%, op_acc: 28.12%] [G loss: 0.909046]\n",
      "epoch:5 step:4528[D loss: 0.443548, acc: 58.59%, op_acc: 35.94%] [G loss: 0.957378]\n",
      "epoch:5 step:4529[D loss: 0.419361, acc: 63.28%, op_acc: 32.81%] [G loss: 0.965150]\n",
      "epoch:5 step:4530[D loss: 0.456052, acc: 64.06%, op_acc: 35.94%] [G loss: 0.972467]\n",
      "epoch:5 step:4531[D loss: 0.421719, acc: 61.72%, op_acc: 39.06%] [G loss: 0.942563]\n",
      "epoch:5 step:4532[D loss: 0.453540, acc: 55.47%, op_acc: 32.03%] [G loss: 0.887229]\n",
      "epoch:5 step:4533[D loss: 0.434370, acc: 64.06%, op_acc: 29.69%] [G loss: 0.900617]\n",
      "epoch:5 step:4534[D loss: 0.467245, acc: 59.38%, op_acc: 28.12%] [G loss: 0.912193]\n",
      "epoch:5 step:4535[D loss: 0.414977, acc: 65.62%, op_acc: 35.94%] [G loss: 0.930448]\n",
      "epoch:5 step:4536[D loss: 0.470929, acc: 55.47%, op_acc: 27.34%] [G loss: 0.849659]\n",
      "epoch:5 step:4537[D loss: 0.457045, acc: 67.19%, op_acc: 25.78%] [G loss: 0.867737]\n",
      "epoch:5 step:4538[D loss: 0.458181, acc: 59.38%, op_acc: 28.12%] [G loss: 0.953773]\n",
      "epoch:5 step:4539[D loss: 0.433285, acc: 65.62%, op_acc: 38.28%] [G loss: 0.903379]\n",
      "epoch:5 step:4540[D loss: 0.414796, acc: 71.09%, op_acc: 33.59%] [G loss: 0.965972]\n",
      "epoch:5 step:4541[D loss: 0.430498, acc: 55.47%, op_acc: 39.06%] [G loss: 0.908598]\n",
      "epoch:5 step:4542[D loss: 0.408158, acc: 71.88%, op_acc: 31.25%] [G loss: 0.976838]\n",
      "epoch:5 step:4543[D loss: 0.472245, acc: 55.47%, op_acc: 28.91%] [G loss: 0.963530]\n",
      "epoch:5 step:4544[D loss: 0.485324, acc: 50.78%, op_acc: 34.38%] [G loss: 0.894031]\n",
      "epoch:5 step:4545[D loss: 0.461222, acc: 61.72%, op_acc: 28.91%] [G loss: 0.943579]\n",
      "epoch:5 step:4546[D loss: 0.455219, acc: 61.72%, op_acc: 22.66%] [G loss: 0.968662]\n",
      "epoch:5 step:4547[D loss: 0.425958, acc: 62.50%, op_acc: 31.25%] [G loss: 1.019822]\n",
      "epoch:5 step:4548[D loss: 0.483072, acc: 51.56%, op_acc: 28.12%] [G loss: 0.823533]\n",
      "epoch:5 step:4549[D loss: 0.434212, acc: 62.50%, op_acc: 29.69%] [G loss: 0.873734]\n",
      "epoch:5 step:4550[D loss: 0.441957, acc: 60.16%, op_acc: 34.38%] [G loss: 0.958575]\n",
      "##############\n",
      "[0.854076   0.85108462 0.82080838 0.79905668 0.80161251 0.81241832\n",
      " 0.87084747 0.81909373 0.8245811  0.84079536]\n",
      "##########\n",
      "epoch:5 step:4551[D loss: 0.462829, acc: 55.47%, op_acc: 30.47%] [G loss: 0.882207]\n",
      "epoch:5 step:4552[D loss: 0.448713, acc: 56.25%, op_acc: 33.59%] [G loss: 0.892110]\n",
      "epoch:5 step:4553[D loss: 0.480857, acc: 50.00%, op_acc: 32.81%] [G loss: 0.892531]\n",
      "epoch:5 step:4554[D loss: 0.495113, acc: 54.69%, op_acc: 29.69%] [G loss: 0.919996]\n",
      "epoch:5 step:4555[D loss: 0.492996, acc: 54.69%, op_acc: 30.47%] [G loss: 0.915398]\n",
      "epoch:5 step:4556[D loss: 0.438272, acc: 64.84%, op_acc: 34.38%] [G loss: 0.938157]\n",
      "epoch:5 step:4557[D loss: 0.428539, acc: 65.62%, op_acc: 38.28%] [G loss: 0.985237]\n",
      "epoch:5 step:4558[D loss: 0.453859, acc: 54.69%, op_acc: 36.72%] [G loss: 0.952304]\n",
      "epoch:5 step:4559[D loss: 0.461782, acc: 57.81%, op_acc: 26.56%] [G loss: 0.919880]\n",
      "epoch:5 step:4560[D loss: 0.447489, acc: 58.59%, op_acc: 33.59%] [G loss: 0.950048]\n",
      "epoch:5 step:4561[D loss: 0.456685, acc: 57.81%, op_acc: 32.81%] [G loss: 0.942120]\n",
      "epoch:5 step:4562[D loss: 0.470137, acc: 52.34%, op_acc: 34.38%] [G loss: 0.972126]\n",
      "epoch:5 step:4563[D loss: 0.426920, acc: 60.94%, op_acc: 35.16%] [G loss: 0.966359]\n",
      "epoch:5 step:4564[D loss: 0.454978, acc: 56.25%, op_acc: 29.69%] [G loss: 0.952440]\n",
      "epoch:5 step:4565[D loss: 0.440535, acc: 58.59%, op_acc: 37.50%] [G loss: 1.043032]\n",
      "epoch:5 step:4566[D loss: 0.433519, acc: 60.16%, op_acc: 35.16%] [G loss: 0.964526]\n",
      "epoch:5 step:4567[D loss: 0.421514, acc: 60.94%, op_acc: 35.16%] [G loss: 0.940689]\n",
      "epoch:5 step:4568[D loss: 0.424663, acc: 64.06%, op_acc: 35.16%] [G loss: 0.875924]\n",
      "epoch:5 step:4569[D loss: 0.462489, acc: 55.47%, op_acc: 35.16%] [G loss: 0.926252]\n",
      "epoch:5 step:4570[D loss: 0.463995, acc: 60.94%, op_acc: 28.91%] [G loss: 0.943928]\n",
      "epoch:5 step:4571[D loss: 0.444158, acc: 60.94%, op_acc: 32.81%] [G loss: 0.902413]\n",
      "epoch:5 step:4572[D loss: 0.440428, acc: 62.50%, op_acc: 25.00%] [G loss: 0.932232]\n",
      "epoch:5 step:4573[D loss: 0.467799, acc: 57.81%, op_acc: 28.12%] [G loss: 0.883759]\n",
      "epoch:5 step:4574[D loss: 0.446514, acc: 61.72%, op_acc: 29.69%] [G loss: 0.979069]\n",
      "epoch:5 step:4575[D loss: 0.452703, acc: 58.59%, op_acc: 32.81%] [G loss: 0.930578]\n",
      "epoch:5 step:4576[D loss: 0.475762, acc: 53.91%, op_acc: 27.34%] [G loss: 0.893853]\n",
      "epoch:5 step:4577[D loss: 0.434975, acc: 64.84%, op_acc: 31.25%] [G loss: 0.922828]\n",
      "epoch:5 step:4578[D loss: 0.439775, acc: 61.72%, op_acc: 34.38%] [G loss: 0.934386]\n",
      "epoch:5 step:4579[D loss: 0.426732, acc: 64.06%, op_acc: 33.59%] [G loss: 0.873003]\n",
      "epoch:5 step:4580[D loss: 0.456867, acc: 59.38%, op_acc: 27.34%] [G loss: 0.938478]\n",
      "epoch:5 step:4581[D loss: 0.456936, acc: 64.06%, op_acc: 30.47%] [G loss: 0.881125]\n",
      "epoch:5 step:4582[D loss: 0.489369, acc: 53.12%, op_acc: 28.91%] [G loss: 0.873698]\n",
      "epoch:5 step:4583[D loss: 0.437535, acc: 62.50%, op_acc: 30.47%] [G loss: 0.910983]\n",
      "epoch:5 step:4584[D loss: 0.445871, acc: 57.81%, op_acc: 35.94%] [G loss: 0.931205]\n",
      "epoch:5 step:4585[D loss: 0.439993, acc: 64.84%, op_acc: 28.91%] [G loss: 0.894838]\n",
      "epoch:5 step:4586[D loss: 0.432623, acc: 71.09%, op_acc: 28.91%] [G loss: 0.919248]\n",
      "epoch:5 step:4587[D loss: 0.435940, acc: 54.69%, op_acc: 33.59%] [G loss: 0.937044]\n",
      "epoch:5 step:4588[D loss: 0.435144, acc: 57.81%, op_acc: 37.50%] [G loss: 0.901081]\n",
      "epoch:5 step:4589[D loss: 0.433495, acc: 64.84%, op_acc: 36.72%] [G loss: 0.942135]\n",
      "epoch:5 step:4590[D loss: 0.482745, acc: 50.78%, op_acc: 30.47%] [G loss: 0.925637]\n",
      "epoch:5 step:4591[D loss: 0.440941, acc: 63.28%, op_acc: 32.03%] [G loss: 0.928819]\n",
      "epoch:5 step:4592[D loss: 0.430073, acc: 68.75%, op_acc: 28.91%] [G loss: 0.892736]\n",
      "epoch:5 step:4593[D loss: 0.456201, acc: 55.47%, op_acc: 34.38%] [G loss: 0.876388]\n",
      "epoch:5 step:4594[D loss: 0.430282, acc: 64.06%, op_acc: 35.94%] [G loss: 0.943638]\n",
      "epoch:5 step:4595[D loss: 0.441962, acc: 63.28%, op_acc: 31.25%] [G loss: 0.878962]\n",
      "epoch:5 step:4596[D loss: 0.473753, acc: 66.41%, op_acc: 31.25%] [G loss: 0.925905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4597[D loss: 0.453929, acc: 63.28%, op_acc: 30.47%] [G loss: 0.873882]\n",
      "epoch:5 step:4598[D loss: 0.462044, acc: 59.38%, op_acc: 21.88%] [G loss: 0.879055]\n",
      "epoch:5 step:4599[D loss: 0.421294, acc: 67.97%, op_acc: 32.03%] [G loss: 0.891286]\n",
      "epoch:5 step:4600[D loss: 0.438905, acc: 65.62%, op_acc: 37.50%] [G loss: 0.900910]\n",
      "##############\n",
      "[0.86363357 0.82635722 0.80414011 0.80623011 0.78983206 0.82533641\n",
      " 0.88791555 0.83232129 0.82712559 0.81611861]\n",
      "##########\n",
      "epoch:5 step:4601[D loss: 0.451349, acc: 62.50%, op_acc: 30.47%] [G loss: 0.902318]\n",
      "epoch:5 step:4602[D loss: 0.466594, acc: 57.03%, op_acc: 28.91%] [G loss: 0.893543]\n",
      "epoch:5 step:4603[D loss: 0.452656, acc: 64.06%, op_acc: 32.81%] [G loss: 0.900096]\n",
      "epoch:5 step:4604[D loss: 0.456413, acc: 51.56%, op_acc: 35.94%] [G loss: 0.863660]\n",
      "epoch:5 step:4605[D loss: 0.441777, acc: 63.28%, op_acc: 35.16%] [G loss: 0.840844]\n",
      "epoch:5 step:4606[D loss: 0.467886, acc: 60.94%, op_acc: 22.66%] [G loss: 0.882697]\n",
      "epoch:5 step:4607[D loss: 0.444008, acc: 62.50%, op_acc: 31.25%] [G loss: 0.921581]\n",
      "epoch:5 step:4608[D loss: 0.450422, acc: 58.59%, op_acc: 32.81%] [G loss: 0.885160]\n",
      "epoch:5 step:4609[D loss: 0.422752, acc: 65.62%, op_acc: 37.50%] [G loss: 0.978793]\n",
      "epoch:5 step:4610[D loss: 0.434934, acc: 64.06%, op_acc: 33.59%] [G loss: 1.051170]\n",
      "epoch:5 step:4611[D loss: 0.443018, acc: 61.72%, op_acc: 36.72%] [G loss: 0.896135]\n",
      "epoch:5 step:4612[D loss: 0.478847, acc: 54.69%, op_acc: 32.03%] [G loss: 0.906428]\n",
      "epoch:5 step:4613[D loss: 0.441538, acc: 58.59%, op_acc: 32.81%] [G loss: 0.935164]\n",
      "epoch:5 step:4614[D loss: 0.464270, acc: 58.59%, op_acc: 25.78%] [G loss: 0.851983]\n",
      "epoch:5 step:4615[D loss: 0.441949, acc: 52.34%, op_acc: 35.94%] [G loss: 0.985822]\n",
      "epoch:5 step:4616[D loss: 0.488401, acc: 54.69%, op_acc: 28.12%] [G loss: 0.927321]\n",
      "epoch:5 step:4617[D loss: 0.432501, acc: 57.81%, op_acc: 35.16%] [G loss: 0.914070]\n",
      "epoch:5 step:4618[D loss: 0.433557, acc: 58.59%, op_acc: 27.34%] [G loss: 0.934939]\n",
      "epoch:5 step:4619[D loss: 0.456885, acc: 59.38%, op_acc: 29.69%] [G loss: 1.005270]\n",
      "epoch:5 step:4620[D loss: 0.460770, acc: 55.47%, op_acc: 32.81%] [G loss: 0.837617]\n",
      "epoch:5 step:4621[D loss: 0.471167, acc: 57.81%, op_acc: 32.03%] [G loss: 0.898703]\n",
      "epoch:5 step:4622[D loss: 0.462097, acc: 50.78%, op_acc: 32.81%] [G loss: 0.925813]\n",
      "epoch:5 step:4623[D loss: 0.445098, acc: 59.38%, op_acc: 32.81%] [G loss: 1.004022]\n",
      "epoch:5 step:4624[D loss: 0.437262, acc: 62.50%, op_acc: 35.16%] [G loss: 0.894328]\n",
      "epoch:5 step:4625[D loss: 0.469014, acc: 58.59%, op_acc: 30.47%] [G loss: 0.969384]\n",
      "epoch:5 step:4626[D loss: 0.449870, acc: 54.69%, op_acc: 35.94%] [G loss: 0.892012]\n",
      "epoch:5 step:4627[D loss: 0.434799, acc: 62.50%, op_acc: 31.25%] [G loss: 0.973314]\n",
      "epoch:5 step:4628[D loss: 0.423472, acc: 60.16%, op_acc: 34.38%] [G loss: 1.017468]\n",
      "epoch:5 step:4629[D loss: 0.455126, acc: 62.50%, op_acc: 25.78%] [G loss: 0.976870]\n",
      "epoch:5 step:4630[D loss: 0.448478, acc: 60.94%, op_acc: 30.47%] [G loss: 0.901996]\n",
      "epoch:5 step:4631[D loss: 0.419028, acc: 60.16%, op_acc: 35.94%] [G loss: 0.925747]\n",
      "epoch:5 step:4632[D loss: 0.456141, acc: 59.38%, op_acc: 29.69%] [G loss: 0.949502]\n",
      "epoch:5 step:4633[D loss: 0.448374, acc: 58.59%, op_acc: 32.03%] [G loss: 0.919127]\n",
      "epoch:5 step:4634[D loss: 0.423825, acc: 67.19%, op_acc: 32.81%] [G loss: 0.917672]\n",
      "epoch:5 step:4635[D loss: 0.450934, acc: 63.28%, op_acc: 25.00%] [G loss: 0.869293]\n",
      "epoch:5 step:4636[D loss: 0.425132, acc: 58.59%, op_acc: 36.72%] [G loss: 0.907117]\n",
      "epoch:5 step:4637[D loss: 0.441782, acc: 60.16%, op_acc: 35.16%] [G loss: 0.880747]\n",
      "epoch:5 step:4638[D loss: 0.446863, acc: 61.72%, op_acc: 35.16%] [G loss: 0.918432]\n",
      "epoch:5 step:4639[D loss: 0.456897, acc: 60.16%, op_acc: 31.25%] [G loss: 0.962373]\n",
      "epoch:5 step:4640[D loss: 0.470304, acc: 58.59%, op_acc: 34.38%] [G loss: 0.894137]\n",
      "epoch:5 step:4641[D loss: 0.447792, acc: 59.38%, op_acc: 29.69%] [G loss: 0.986472]\n",
      "epoch:5 step:4642[D loss: 0.445212, acc: 61.72%, op_acc: 35.94%] [G loss: 0.968471]\n",
      "epoch:5 step:4643[D loss: 0.445703, acc: 58.59%, op_acc: 33.59%] [G loss: 0.986133]\n",
      "epoch:5 step:4644[D loss: 0.443279, acc: 60.94%, op_acc: 32.81%] [G loss: 0.990122]\n",
      "epoch:5 step:4645[D loss: 0.435429, acc: 58.59%, op_acc: 39.06%] [G loss: 0.953356]\n",
      "epoch:5 step:4646[D loss: 0.431616, acc: 61.72%, op_acc: 32.81%] [G loss: 0.939755]\n",
      "epoch:5 step:4647[D loss: 0.471772, acc: 52.34%, op_acc: 29.69%] [G loss: 0.875406]\n",
      "epoch:5 step:4648[D loss: 0.459360, acc: 57.81%, op_acc: 32.81%] [G loss: 0.898553]\n",
      "epoch:5 step:4649[D loss: 0.436436, acc: 57.03%, op_acc: 41.41%] [G loss: 1.011672]\n",
      "epoch:5 step:4650[D loss: 0.437473, acc: 67.19%, op_acc: 31.25%] [G loss: 0.941084]\n",
      "##############\n",
      "[0.85766895 0.87487602 0.79917346 0.81515723 0.79972374 0.81085518\n",
      " 0.89576315 0.82912047 0.80094758 0.83590766]\n",
      "##########\n",
      "epoch:5 step:4651[D loss: 0.429054, acc: 61.72%, op_acc: 33.59%] [G loss: 0.964466]\n",
      "epoch:5 step:4652[D loss: 0.423303, acc: 70.31%, op_acc: 32.81%] [G loss: 0.844164]\n",
      "epoch:5 step:4653[D loss: 0.467658, acc: 57.81%, op_acc: 27.34%] [G loss: 0.897809]\n",
      "epoch:5 step:4654[D loss: 0.479553, acc: 58.59%, op_acc: 24.22%] [G loss: 0.983855]\n",
      "epoch:5 step:4655[D loss: 0.435872, acc: 61.72%, op_acc: 28.12%] [G loss: 0.982204]\n",
      "epoch:5 step:4656[D loss: 0.477049, acc: 56.25%, op_acc: 37.50%] [G loss: 0.973306]\n",
      "epoch:5 step:4657[D loss: 0.489857, acc: 53.91%, op_acc: 26.56%] [G loss: 0.880998]\n",
      "epoch:5 step:4658[D loss: 0.417014, acc: 64.84%, op_acc: 35.94%] [G loss: 0.936186]\n",
      "epoch:5 step:4659[D loss: 0.426610, acc: 64.84%, op_acc: 30.47%] [G loss: 0.930852]\n",
      "epoch:5 step:4660[D loss: 0.438575, acc: 64.84%, op_acc: 31.25%] [G loss: 0.951806]\n",
      "epoch:5 step:4661[D loss: 0.411283, acc: 69.53%, op_acc: 32.03%] [G loss: 1.005829]\n",
      "epoch:5 step:4662[D loss: 0.422908, acc: 61.72%, op_acc: 35.16%] [G loss: 0.922935]\n",
      "epoch:5 step:4663[D loss: 0.417299, acc: 68.75%, op_acc: 33.59%] [G loss: 0.841699]\n",
      "epoch:5 step:4664[D loss: 0.452055, acc: 60.16%, op_acc: 32.81%] [G loss: 0.919242]\n",
      "epoch:5 step:4665[D loss: 0.427717, acc: 64.06%, op_acc: 35.16%] [G loss: 0.933218]\n",
      "epoch:5 step:4666[D loss: 0.444627, acc: 56.25%, op_acc: 36.72%] [G loss: 0.887271]\n",
      "epoch:5 step:4667[D loss: 0.458262, acc: 54.69%, op_acc: 32.81%] [G loss: 0.960418]\n",
      "epoch:5 step:4668[D loss: 0.448587, acc: 60.94%, op_acc: 35.94%] [G loss: 0.854192]\n",
      "epoch:5 step:4669[D loss: 0.430558, acc: 65.62%, op_acc: 31.25%] [G loss: 0.897026]\n",
      "epoch:5 step:4670[D loss: 0.475788, acc: 45.31%, op_acc: 33.59%] [G loss: 0.954101]\n",
      "epoch:5 step:4671[D loss: 0.448058, acc: 63.28%, op_acc: 34.38%] [G loss: 1.033288]\n",
      "epoch:5 step:4672[D loss: 0.432503, acc: 57.03%, op_acc: 35.16%] [G loss: 0.863144]\n",
      "epoch:5 step:4673[D loss: 0.482700, acc: 55.47%, op_acc: 29.69%] [G loss: 0.884221]\n",
      "epoch:5 step:4674[D loss: 0.415030, acc: 65.62%, op_acc: 38.28%] [G loss: 1.014733]\n",
      "epoch:5 step:4675[D loss: 0.419034, acc: 70.31%, op_acc: 37.50%] [G loss: 0.954885]\n",
      "epoch:5 step:4676[D loss: 0.454059, acc: 59.38%, op_acc: 29.69%] [G loss: 0.879696]\n",
      "epoch:5 step:4677[D loss: 0.470285, acc: 56.25%, op_acc: 26.56%] [G loss: 0.914870]\n",
      "epoch:5 step:4678[D loss: 0.493625, acc: 50.00%, op_acc: 30.47%] [G loss: 0.912380]\n",
      "epoch:5 step:4679[D loss: 0.435193, acc: 60.94%, op_acc: 31.25%] [G loss: 0.854594]\n",
      "epoch:5 step:4680[D loss: 0.451888, acc: 57.03%, op_acc: 34.38%] [G loss: 0.891604]\n",
      "epoch:5 step:4681[D loss: 0.435241, acc: 64.06%, op_acc: 31.25%] [G loss: 0.974321]\n",
      "epoch:5 step:4682[D loss: 0.492610, acc: 51.56%, op_acc: 21.09%] [G loss: 0.931821]\n",
      "epoch:5 step:4683[D loss: 0.434925, acc: 57.81%, op_acc: 42.97%] [G loss: 0.955018]\n",
      "epoch:5 step:4684[D loss: 0.452330, acc: 57.03%, op_acc: 31.25%] [G loss: 1.011120]\n",
      "epoch:5 step:4685[D loss: 0.422731, acc: 64.06%, op_acc: 31.25%] [G loss: 0.896758]\n",
      "epoch:5 step:4686[D loss: 0.458085, acc: 61.72%, op_acc: 28.91%] [G loss: 0.857799]\n",
      "epoch:6 step:4687[D loss: 0.446466, acc: 60.94%, op_acc: 32.03%] [G loss: 0.970054]\n",
      "epoch:6 step:4688[D loss: 0.427060, acc: 60.94%, op_acc: 35.16%] [G loss: 0.939789]\n",
      "epoch:6 step:4689[D loss: 0.466706, acc: 56.25%, op_acc: 29.69%] [G loss: 0.908041]\n",
      "epoch:6 step:4690[D loss: 0.413814, acc: 62.50%, op_acc: 37.50%] [G loss: 0.979206]\n",
      "epoch:6 step:4691[D loss: 0.438299, acc: 65.62%, op_acc: 29.69%] [G loss: 0.981850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4692[D loss: 0.420756, acc: 63.28%, op_acc: 31.25%] [G loss: 0.989430]\n",
      "epoch:6 step:4693[D loss: 0.441590, acc: 54.69%, op_acc: 33.59%] [G loss: 0.963326]\n",
      "epoch:6 step:4694[D loss: 0.451614, acc: 63.28%, op_acc: 25.00%] [G loss: 0.874744]\n",
      "epoch:6 step:4695[D loss: 0.436146, acc: 57.81%, op_acc: 36.72%] [G loss: 0.874281]\n",
      "epoch:6 step:4696[D loss: 0.457191, acc: 55.47%, op_acc: 28.91%] [G loss: 0.839747]\n",
      "epoch:6 step:4697[D loss: 0.459341, acc: 53.91%, op_acc: 34.38%] [G loss: 0.928283]\n",
      "epoch:6 step:4698[D loss: 0.498426, acc: 56.25%, op_acc: 27.34%] [G loss: 0.796443]\n",
      "epoch:6 step:4699[D loss: 0.444691, acc: 60.94%, op_acc: 26.56%] [G loss: 0.850873]\n",
      "epoch:6 step:4700[D loss: 0.453249, acc: 59.38%, op_acc: 29.69%] [G loss: 0.939966]\n",
      "##############\n",
      "[0.84897368 0.83841254 0.81012476 0.80817088 0.79016774 0.81164273\n",
      " 0.8824781  0.8368953  0.80113911 0.83777605]\n",
      "##########\n",
      "epoch:6 step:4701[D loss: 0.469718, acc: 52.34%, op_acc: 34.38%] [G loss: 0.948384]\n",
      "epoch:6 step:4702[D loss: 0.445784, acc: 60.16%, op_acc: 33.59%] [G loss: 0.915024]\n",
      "epoch:6 step:4703[D loss: 0.452465, acc: 59.38%, op_acc: 32.81%] [G loss: 0.885898]\n",
      "epoch:6 step:4704[D loss: 0.431167, acc: 57.03%, op_acc: 34.38%] [G loss: 0.992074]\n",
      "epoch:6 step:4705[D loss: 0.425717, acc: 66.41%, op_acc: 35.94%] [G loss: 0.967490]\n",
      "epoch:6 step:4706[D loss: 0.441767, acc: 60.16%, op_acc: 33.59%] [G loss: 0.983532]\n",
      "epoch:6 step:4707[D loss: 0.458002, acc: 65.62%, op_acc: 31.25%] [G loss: 0.976974]\n",
      "epoch:6 step:4708[D loss: 0.412498, acc: 64.06%, op_acc: 42.19%] [G loss: 0.972973]\n",
      "epoch:6 step:4709[D loss: 0.481827, acc: 59.38%, op_acc: 30.47%] [G loss: 0.932215]\n",
      "epoch:6 step:4710[D loss: 0.455722, acc: 57.03%, op_acc: 35.16%] [G loss: 0.913186]\n",
      "epoch:6 step:4711[D loss: 0.463937, acc: 53.12%, op_acc: 28.91%] [G loss: 1.010830]\n",
      "epoch:6 step:4712[D loss: 0.443028, acc: 55.47%, op_acc: 33.59%] [G loss: 0.955110]\n",
      "epoch:6 step:4713[D loss: 0.436429, acc: 64.84%, op_acc: 33.59%] [G loss: 0.971537]\n",
      "epoch:6 step:4714[D loss: 0.419975, acc: 64.06%, op_acc: 36.72%] [G loss: 0.973347]\n",
      "epoch:6 step:4715[D loss: 0.461935, acc: 58.59%, op_acc: 33.59%] [G loss: 1.003140]\n",
      "epoch:6 step:4716[D loss: 0.405252, acc: 63.28%, op_acc: 37.50%] [G loss: 0.939474]\n",
      "epoch:6 step:4717[D loss: 0.473870, acc: 53.12%, op_acc: 32.03%] [G loss: 0.934575]\n",
      "epoch:6 step:4718[D loss: 0.464017, acc: 62.50%, op_acc: 31.25%] [G loss: 0.887799]\n",
      "epoch:6 step:4719[D loss: 0.452974, acc: 54.69%, op_acc: 40.62%] [G loss: 0.908322]\n",
      "epoch:6 step:4720[D loss: 0.432172, acc: 64.06%, op_acc: 36.72%] [G loss: 0.925897]\n",
      "epoch:6 step:4721[D loss: 0.443030, acc: 59.38%, op_acc: 33.59%] [G loss: 0.992532]\n",
      "epoch:6 step:4722[D loss: 0.478058, acc: 48.44%, op_acc: 32.81%] [G loss: 0.889879]\n",
      "epoch:6 step:4723[D loss: 0.469222, acc: 54.69%, op_acc: 28.91%] [G loss: 0.951532]\n",
      "epoch:6 step:4724[D loss: 0.451005, acc: 58.59%, op_acc: 35.94%] [G loss: 1.005963]\n",
      "epoch:6 step:4725[D loss: 0.437972, acc: 65.62%, op_acc: 34.38%] [G loss: 0.949303]\n",
      "epoch:6 step:4726[D loss: 0.449240, acc: 58.59%, op_acc: 31.25%] [G loss: 0.933469]\n",
      "epoch:6 step:4727[D loss: 0.400888, acc: 71.09%, op_acc: 36.72%] [G loss: 0.941178]\n",
      "epoch:6 step:4728[D loss: 0.433701, acc: 60.94%, op_acc: 32.81%] [G loss: 0.896079]\n",
      "epoch:6 step:4729[D loss: 0.453543, acc: 59.38%, op_acc: 32.03%] [G loss: 0.943626]\n",
      "epoch:6 step:4730[D loss: 0.444485, acc: 68.75%, op_acc: 35.94%] [G loss: 0.945371]\n",
      "epoch:6 step:4731[D loss: 0.456588, acc: 58.59%, op_acc: 31.25%] [G loss: 0.970899]\n",
      "epoch:6 step:4732[D loss: 0.454579, acc: 57.81%, op_acc: 33.59%] [G loss: 0.981989]\n",
      "epoch:6 step:4733[D loss: 0.477240, acc: 60.16%, op_acc: 26.56%] [G loss: 0.879692]\n",
      "epoch:6 step:4734[D loss: 0.461903, acc: 62.50%, op_acc: 28.12%] [G loss: 0.940159]\n",
      "epoch:6 step:4735[D loss: 0.411020, acc: 71.09%, op_acc: 29.69%] [G loss: 0.982794]\n",
      "epoch:6 step:4736[D loss: 0.465708, acc: 59.38%, op_acc: 31.25%] [G loss: 0.947590]\n",
      "epoch:6 step:4737[D loss: 0.464109, acc: 57.03%, op_acc: 30.47%] [G loss: 0.898853]\n",
      "epoch:6 step:4738[D loss: 0.457736, acc: 59.38%, op_acc: 32.03%] [G loss: 0.947318]\n",
      "epoch:6 step:4739[D loss: 0.442280, acc: 67.19%, op_acc: 30.47%] [G loss: 0.950370]\n",
      "epoch:6 step:4740[D loss: 0.474879, acc: 55.47%, op_acc: 32.03%] [G loss: 0.881486]\n",
      "epoch:6 step:4741[D loss: 0.425517, acc: 61.72%, op_acc: 32.81%] [G loss: 0.829760]\n",
      "epoch:6 step:4742[D loss: 0.420399, acc: 64.06%, op_acc: 31.25%] [G loss: 0.864987]\n",
      "epoch:6 step:4743[D loss: 0.469030, acc: 53.12%, op_acc: 34.38%] [G loss: 0.881742]\n",
      "epoch:6 step:4744[D loss: 0.438044, acc: 56.25%, op_acc: 38.28%] [G loss: 0.945411]\n",
      "epoch:6 step:4745[D loss: 0.441672, acc: 57.81%, op_acc: 35.94%] [G loss: 0.957397]\n",
      "epoch:6 step:4746[D loss: 0.436146, acc: 57.81%, op_acc: 28.91%] [G loss: 0.998625]\n",
      "epoch:6 step:4747[D loss: 0.457004, acc: 59.38%, op_acc: 31.25%] [G loss: 0.895102]\n",
      "epoch:6 step:4748[D loss: 0.475628, acc: 53.91%, op_acc: 32.03%] [G loss: 0.861876]\n",
      "epoch:6 step:4749[D loss: 0.439583, acc: 62.50%, op_acc: 34.38%] [G loss: 0.938164]\n",
      "epoch:6 step:4750[D loss: 0.460059, acc: 54.69%, op_acc: 32.81%] [G loss: 0.975306]\n",
      "##############\n",
      "[0.84956242 0.85989186 0.8311181  0.8008606  0.78804658 0.81722761\n",
      " 0.89931369 0.84647131 0.8096415  0.83859491]\n",
      "##########\n",
      "epoch:6 step:4751[D loss: 0.470279, acc: 53.91%, op_acc: 32.03%] [G loss: 0.987149]\n",
      "epoch:6 step:4752[D loss: 0.462531, acc: 54.69%, op_acc: 34.38%] [G loss: 0.988675]\n",
      "epoch:6 step:4753[D loss: 0.436398, acc: 62.50%, op_acc: 33.59%] [G loss: 0.926923]\n",
      "epoch:6 step:4754[D loss: 0.453937, acc: 56.25%, op_acc: 28.12%] [G loss: 0.929082]\n",
      "epoch:6 step:4755[D loss: 0.434195, acc: 60.16%, op_acc: 38.28%] [G loss: 0.964357]\n",
      "epoch:6 step:4756[D loss: 0.452244, acc: 63.28%, op_acc: 33.59%] [G loss: 0.870424]\n",
      "epoch:6 step:4757[D loss: 0.480439, acc: 58.59%, op_acc: 24.22%] [G loss: 0.866218]\n",
      "epoch:6 step:4758[D loss: 0.461523, acc: 53.12%, op_acc: 34.38%] [G loss: 0.845468]\n",
      "epoch:6 step:4759[D loss: 0.460266, acc: 53.12%, op_acc: 31.25%] [G loss: 0.894980]\n",
      "epoch:6 step:4760[D loss: 0.424406, acc: 67.19%, op_acc: 41.41%] [G loss: 0.839279]\n",
      "epoch:6 step:4761[D loss: 0.450717, acc: 65.62%, op_acc: 29.69%] [G loss: 0.855294]\n",
      "epoch:6 step:4762[D loss: 0.463978, acc: 57.81%, op_acc: 33.59%] [G loss: 0.905056]\n",
      "epoch:6 step:4763[D loss: 0.459724, acc: 56.25%, op_acc: 28.91%] [G loss: 0.885252]\n",
      "epoch:6 step:4764[D loss: 0.444357, acc: 71.88%, op_acc: 25.78%] [G loss: 0.972729]\n",
      "epoch:6 step:4765[D loss: 0.460763, acc: 52.34%, op_acc: 32.03%] [G loss: 0.927218]\n",
      "epoch:6 step:4766[D loss: 0.483931, acc: 57.03%, op_acc: 28.91%] [G loss: 0.912145]\n",
      "epoch:6 step:4767[D loss: 0.484897, acc: 57.03%, op_acc: 25.00%] [G loss: 0.907715]\n",
      "epoch:6 step:4768[D loss: 0.439506, acc: 57.81%, op_acc: 34.38%] [G loss: 1.007639]\n",
      "epoch:6 step:4769[D loss: 0.430168, acc: 67.97%, op_acc: 31.25%] [G loss: 0.967361]\n",
      "epoch:6 step:4770[D loss: 0.436684, acc: 63.28%, op_acc: 35.94%] [G loss: 0.924681]\n",
      "epoch:6 step:4771[D loss: 0.454179, acc: 64.06%, op_acc: 32.03%] [G loss: 0.947567]\n",
      "epoch:6 step:4772[D loss: 0.433248, acc: 64.06%, op_acc: 33.59%] [G loss: 0.953161]\n",
      "epoch:6 step:4773[D loss: 0.426334, acc: 68.75%, op_acc: 37.50%] [G loss: 1.088946]\n",
      "epoch:6 step:4774[D loss: 0.438743, acc: 64.06%, op_acc: 31.25%] [G loss: 0.886592]\n",
      "epoch:6 step:4775[D loss: 0.472769, acc: 58.59%, op_acc: 29.69%] [G loss: 0.923502]\n",
      "epoch:6 step:4776[D loss: 0.459184, acc: 60.16%, op_acc: 33.59%] [G loss: 0.874118]\n",
      "epoch:6 step:4777[D loss: 0.468988, acc: 59.38%, op_acc: 29.69%] [G loss: 0.872949]\n",
      "epoch:6 step:4778[D loss: 0.488715, acc: 54.69%, op_acc: 23.44%] [G loss: 0.913724]\n",
      "epoch:6 step:4779[D loss: 0.454117, acc: 53.91%, op_acc: 34.38%] [G loss: 0.788043]\n",
      "epoch:6 step:4780[D loss: 0.446177, acc: 54.69%, op_acc: 36.72%] [G loss: 0.837597]\n",
      "epoch:6 step:4781[D loss: 0.419947, acc: 66.41%, op_acc: 34.38%] [G loss: 0.931605]\n",
      "epoch:6 step:4782[D loss: 0.470662, acc: 54.69%, op_acc: 28.91%] [G loss: 0.870683]\n",
      "epoch:6 step:4783[D loss: 0.424697, acc: 61.72%, op_acc: 32.81%] [G loss: 0.914495]\n",
      "epoch:6 step:4784[D loss: 0.480555, acc: 57.81%, op_acc: 22.66%] [G loss: 0.914493]\n",
      "epoch:6 step:4785[D loss: 0.449852, acc: 57.81%, op_acc: 35.16%] [G loss: 0.917326]\n",
      "epoch:6 step:4786[D loss: 0.422823, acc: 67.97%, op_acc: 39.06%] [G loss: 0.919869]\n",
      "epoch:6 step:4787[D loss: 0.453238, acc: 59.38%, op_acc: 27.34%] [G loss: 0.972288]\n",
      "epoch:6 step:4788[D loss: 0.447342, acc: 56.25%, op_acc: 33.59%] [G loss: 0.907148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4789[D loss: 0.472945, acc: 50.78%, op_acc: 33.59%] [G loss: 0.905069]\n",
      "epoch:6 step:4790[D loss: 0.452466, acc: 65.62%, op_acc: 28.12%] [G loss: 0.923532]\n",
      "epoch:6 step:4791[D loss: 0.465543, acc: 57.03%, op_acc: 33.59%] [G loss: 0.873926]\n",
      "epoch:6 step:4792[D loss: 0.429747, acc: 61.72%, op_acc: 35.94%] [G loss: 0.914088]\n",
      "epoch:6 step:4793[D loss: 0.421548, acc: 64.06%, op_acc: 40.62%] [G loss: 0.921963]\n",
      "epoch:6 step:4794[D loss: 0.452305, acc: 54.69%, op_acc: 38.28%] [G loss: 0.930933]\n",
      "epoch:6 step:4795[D loss: 0.431875, acc: 57.03%, op_acc: 35.16%] [G loss: 0.846310]\n",
      "epoch:6 step:4796[D loss: 0.419369, acc: 63.28%, op_acc: 34.38%] [G loss: 0.909399]\n",
      "epoch:6 step:4797[D loss: 0.482350, acc: 58.59%, op_acc: 24.22%] [G loss: 0.945850]\n",
      "epoch:6 step:4798[D loss: 0.422586, acc: 62.50%, op_acc: 38.28%] [G loss: 0.975765]\n",
      "epoch:6 step:4799[D loss: 0.453914, acc: 60.94%, op_acc: 28.91%] [G loss: 0.894113]\n",
      "epoch:6 step:4800[D loss: 0.445746, acc: 59.38%, op_acc: 42.19%] [G loss: 0.897322]\n",
      "##############\n",
      "[0.86289636 0.87876959 0.80350297 0.80454273 0.78385162 0.81544614\n",
      " 0.86329761 0.83597839 0.80754074 0.83175899]\n",
      "##########\n",
      "epoch:6 step:4801[D loss: 0.431209, acc: 67.19%, op_acc: 36.72%] [G loss: 0.948198]\n",
      "epoch:6 step:4802[D loss: 0.482534, acc: 57.03%, op_acc: 27.34%] [G loss: 0.913540]\n",
      "epoch:6 step:4803[D loss: 0.445146, acc: 60.16%, op_acc: 27.34%] [G loss: 0.912982]\n",
      "epoch:6 step:4804[D loss: 0.442574, acc: 63.28%, op_acc: 32.03%] [G loss: 0.831936]\n",
      "epoch:6 step:4805[D loss: 0.454305, acc: 58.59%, op_acc: 32.81%] [G loss: 0.856969]\n",
      "epoch:6 step:4806[D loss: 0.463454, acc: 59.38%, op_acc: 35.94%] [G loss: 0.863739]\n",
      "epoch:6 step:4807[D loss: 0.473492, acc: 57.03%, op_acc: 32.03%] [G loss: 1.008960]\n",
      "epoch:6 step:4808[D loss: 0.430206, acc: 65.62%, op_acc: 29.69%] [G loss: 1.030113]\n",
      "epoch:6 step:4809[D loss: 0.415234, acc: 64.84%, op_acc: 30.47%] [G loss: 0.939275]\n",
      "epoch:6 step:4810[D loss: 0.437586, acc: 66.41%, op_acc: 32.81%] [G loss: 0.964080]\n",
      "epoch:6 step:4811[D loss: 0.472088, acc: 57.03%, op_acc: 29.69%] [G loss: 0.954504]\n",
      "epoch:6 step:4812[D loss: 0.418099, acc: 67.19%, op_acc: 40.62%] [G loss: 0.884879]\n",
      "epoch:6 step:4813[D loss: 0.439041, acc: 64.06%, op_acc: 28.12%] [G loss: 0.930669]\n",
      "epoch:6 step:4814[D loss: 0.448773, acc: 60.16%, op_acc: 34.38%] [G loss: 0.863447]\n",
      "epoch:6 step:4815[D loss: 0.462629, acc: 57.03%, op_acc: 28.91%] [G loss: 0.918145]\n",
      "epoch:6 step:4816[D loss: 0.420461, acc: 67.19%, op_acc: 39.84%] [G loss: 0.956261]\n",
      "epoch:6 step:4817[D loss: 0.435357, acc: 60.16%, op_acc: 28.12%] [G loss: 0.925386]\n",
      "epoch:6 step:4818[D loss: 0.454835, acc: 57.81%, op_acc: 37.50%] [G loss: 0.930319]\n",
      "epoch:6 step:4819[D loss: 0.468181, acc: 60.94%, op_acc: 32.03%] [G loss: 0.878501]\n",
      "epoch:6 step:4820[D loss: 0.441235, acc: 66.41%, op_acc: 35.16%] [G loss: 0.955020]\n",
      "epoch:6 step:4821[D loss: 0.450408, acc: 64.84%, op_acc: 31.25%] [G loss: 0.936796]\n",
      "epoch:6 step:4822[D loss: 0.428334, acc: 64.06%, op_acc: 32.81%] [G loss: 0.871065]\n",
      "epoch:6 step:4823[D loss: 0.448269, acc: 61.72%, op_acc: 35.94%] [G loss: 0.869866]\n",
      "epoch:6 step:4824[D loss: 0.429007, acc: 63.28%, op_acc: 32.81%] [G loss: 0.960329]\n",
      "epoch:6 step:4825[D loss: 0.420963, acc: 64.84%, op_acc: 39.06%] [G loss: 0.905053]\n",
      "epoch:6 step:4826[D loss: 0.474593, acc: 60.94%, op_acc: 28.12%] [G loss: 0.918272]\n",
      "epoch:6 step:4827[D loss: 0.452807, acc: 60.94%, op_acc: 29.69%] [G loss: 0.946139]\n",
      "epoch:6 step:4828[D loss: 0.442373, acc: 59.38%, op_acc: 31.25%] [G loss: 0.953916]\n",
      "epoch:6 step:4829[D loss: 0.438068, acc: 63.28%, op_acc: 37.50%] [G loss: 0.994976]\n",
      "epoch:6 step:4830[D loss: 0.459667, acc: 54.69%, op_acc: 35.16%] [G loss: 0.985604]\n",
      "epoch:6 step:4831[D loss: 0.462820, acc: 58.59%, op_acc: 30.47%] [G loss: 0.971390]\n",
      "epoch:6 step:4832[D loss: 0.438059, acc: 65.62%, op_acc: 32.81%] [G loss: 1.004992]\n",
      "epoch:6 step:4833[D loss: 0.444214, acc: 56.25%, op_acc: 36.72%] [G loss: 0.920656]\n",
      "epoch:6 step:4834[D loss: 0.444703, acc: 64.06%, op_acc: 34.38%] [G loss: 0.927178]\n",
      "epoch:6 step:4835[D loss: 0.431441, acc: 62.50%, op_acc: 35.94%] [G loss: 0.982939]\n",
      "epoch:6 step:4836[D loss: 0.432885, acc: 60.16%, op_acc: 30.47%] [G loss: 0.899192]\n",
      "epoch:6 step:4837[D loss: 0.422113, acc: 65.62%, op_acc: 36.72%] [G loss: 0.914794]\n",
      "epoch:6 step:4838[D loss: 0.463399, acc: 51.56%, op_acc: 32.81%] [G loss: 0.964235]\n",
      "epoch:6 step:4839[D loss: 0.471478, acc: 56.25%, op_acc: 31.25%] [G loss: 0.898455]\n",
      "epoch:6 step:4840[D loss: 0.463518, acc: 59.38%, op_acc: 35.16%] [G loss: 0.867281]\n",
      "epoch:6 step:4841[D loss: 0.419279, acc: 70.31%, op_acc: 28.12%] [G loss: 0.915025]\n",
      "epoch:6 step:4842[D loss: 0.442587, acc: 57.03%, op_acc: 34.38%] [G loss: 0.860991]\n",
      "epoch:6 step:4843[D loss: 0.421350, acc: 64.84%, op_acc: 33.59%] [G loss: 0.876409]\n",
      "epoch:6 step:4844[D loss: 0.427322, acc: 64.06%, op_acc: 32.03%] [G loss: 0.853329]\n",
      "epoch:6 step:4845[D loss: 0.475351, acc: 56.25%, op_acc: 35.94%] [G loss: 0.885122]\n",
      "epoch:6 step:4846[D loss: 0.481210, acc: 61.72%, op_acc: 25.78%] [G loss: 0.880014]\n",
      "epoch:6 step:4847[D loss: 0.477724, acc: 56.25%, op_acc: 33.59%] [G loss: 0.878331]\n",
      "epoch:6 step:4848[D loss: 0.432906, acc: 60.94%, op_acc: 35.16%] [G loss: 0.960292]\n",
      "epoch:6 step:4849[D loss: 0.444810, acc: 64.84%, op_acc: 33.59%] [G loss: 0.998435]\n",
      "epoch:6 step:4850[D loss: 0.467263, acc: 61.72%, op_acc: 31.25%] [G loss: 0.910596]\n",
      "##############\n",
      "[0.8550698  0.84574455 0.81836181 0.80890966 0.78361948 0.82721895\n",
      " 0.88070075 0.83459069 0.79520293 0.85705322]\n",
      "##########\n",
      "epoch:6 step:4851[D loss: 0.467463, acc: 56.25%, op_acc: 33.59%] [G loss: 0.968094]\n",
      "epoch:6 step:4852[D loss: 0.469877, acc: 54.69%, op_acc: 34.38%] [G loss: 0.894590]\n",
      "epoch:6 step:4853[D loss: 0.432999, acc: 63.28%, op_acc: 40.62%] [G loss: 0.937189]\n",
      "epoch:6 step:4854[D loss: 0.437707, acc: 58.59%, op_acc: 35.94%] [G loss: 0.825687]\n",
      "epoch:6 step:4855[D loss: 0.410765, acc: 67.19%, op_acc: 37.50%] [G loss: 0.919674]\n",
      "epoch:6 step:4856[D loss: 0.444547, acc: 61.72%, op_acc: 33.59%] [G loss: 0.873731]\n",
      "epoch:6 step:4857[D loss: 0.449369, acc: 60.94%, op_acc: 28.12%] [G loss: 0.830879]\n",
      "epoch:6 step:4858[D loss: 0.443737, acc: 65.62%, op_acc: 32.81%] [G loss: 0.841591]\n",
      "epoch:6 step:4859[D loss: 0.424104, acc: 68.75%, op_acc: 32.81%] [G loss: 0.905744]\n",
      "epoch:6 step:4860[D loss: 0.507939, acc: 48.44%, op_acc: 27.34%] [G loss: 0.904495]\n",
      "epoch:6 step:4861[D loss: 0.455353, acc: 53.12%, op_acc: 33.59%] [G loss: 0.935664]\n",
      "epoch:6 step:4862[D loss: 0.469023, acc: 53.12%, op_acc: 35.16%] [G loss: 0.917091]\n",
      "epoch:6 step:4863[D loss: 0.434151, acc: 60.94%, op_acc: 35.16%] [G loss: 0.955736]\n",
      "epoch:6 step:4864[D loss: 0.437432, acc: 64.06%, op_acc: 35.16%] [G loss: 0.960196]\n",
      "epoch:6 step:4865[D loss: 0.441511, acc: 59.38%, op_acc: 39.84%] [G loss: 0.930323]\n",
      "epoch:6 step:4866[D loss: 0.468440, acc: 58.59%, op_acc: 28.91%] [G loss: 0.912207]\n",
      "epoch:6 step:4867[D loss: 0.418895, acc: 62.50%, op_acc: 34.38%] [G loss: 0.927346]\n",
      "epoch:6 step:4868[D loss: 0.433123, acc: 61.72%, op_acc: 35.16%] [G loss: 1.038097]\n",
      "epoch:6 step:4869[D loss: 0.419309, acc: 71.09%, op_acc: 33.59%] [G loss: 1.058050]\n",
      "epoch:6 step:4870[D loss: 0.462353, acc: 54.69%, op_acc: 28.91%] [G loss: 0.947564]\n",
      "epoch:6 step:4871[D loss: 0.432165, acc: 62.50%, op_acc: 29.69%] [G loss: 1.014478]\n",
      "epoch:6 step:4872[D loss: 0.436471, acc: 60.16%, op_acc: 34.38%] [G loss: 1.004879]\n",
      "epoch:6 step:4873[D loss: 0.478890, acc: 48.44%, op_acc: 27.34%] [G loss: 0.954020]\n",
      "epoch:6 step:4874[D loss: 0.451484, acc: 58.59%, op_acc: 35.16%] [G loss: 1.061023]\n",
      "epoch:6 step:4875[D loss: 0.437242, acc: 69.53%, op_acc: 29.69%] [G loss: 1.027316]\n",
      "epoch:6 step:4876[D loss: 0.439061, acc: 64.06%, op_acc: 35.16%] [G loss: 1.000638]\n",
      "epoch:6 step:4877[D loss: 0.453734, acc: 60.16%, op_acc: 32.03%] [G loss: 0.926130]\n",
      "epoch:6 step:4878[D loss: 0.456197, acc: 60.94%, op_acc: 30.47%] [G loss: 0.926436]\n",
      "epoch:6 step:4879[D loss: 0.455448, acc: 64.84%, op_acc: 33.59%] [G loss: 1.008636]\n",
      "epoch:6 step:4880[D loss: 0.454231, acc: 57.81%, op_acc: 30.47%] [G loss: 0.972708]\n",
      "epoch:6 step:4881[D loss: 0.450431, acc: 57.03%, op_acc: 35.94%] [G loss: 1.013818]\n",
      "epoch:6 step:4882[D loss: 0.437431, acc: 65.62%, op_acc: 34.38%] [G loss: 0.904379]\n",
      "epoch:6 step:4883[D loss: 0.471847, acc: 53.91%, op_acc: 34.38%] [G loss: 0.945381]\n",
      "epoch:6 step:4884[D loss: 0.431566, acc: 64.06%, op_acc: 35.94%] [G loss: 0.915766]\n",
      "epoch:6 step:4885[D loss: 0.448800, acc: 62.50%, op_acc: 31.25%] [G loss: 0.960443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4886[D loss: 0.468307, acc: 58.59%, op_acc: 33.59%] [G loss: 1.036617]\n",
      "epoch:6 step:4887[D loss: 0.422723, acc: 60.94%, op_acc: 31.25%] [G loss: 0.907779]\n",
      "epoch:6 step:4888[D loss: 0.480762, acc: 54.69%, op_acc: 33.59%] [G loss: 0.970854]\n",
      "epoch:6 step:4889[D loss: 0.460468, acc: 60.94%, op_acc: 30.47%] [G loss: 0.964515]\n",
      "epoch:6 step:4890[D loss: 0.458962, acc: 58.59%, op_acc: 33.59%] [G loss: 0.879697]\n",
      "epoch:6 step:4891[D loss: 0.450822, acc: 58.59%, op_acc: 28.12%] [G loss: 0.921253]\n",
      "epoch:6 step:4892[D loss: 0.501707, acc: 53.12%, op_acc: 30.47%] [G loss: 0.872726]\n",
      "epoch:6 step:4893[D loss: 0.477247, acc: 50.78%, op_acc: 30.47%] [G loss: 0.900523]\n",
      "epoch:6 step:4894[D loss: 0.450697, acc: 64.06%, op_acc: 23.44%] [G loss: 0.891165]\n",
      "epoch:6 step:4895[D loss: 0.450961, acc: 57.03%, op_acc: 32.03%] [G loss: 0.928654]\n",
      "epoch:6 step:4896[D loss: 0.504144, acc: 51.56%, op_acc: 24.22%] [G loss: 0.833184]\n",
      "epoch:6 step:4897[D loss: 0.396658, acc: 64.84%, op_acc: 41.41%] [G loss: 0.891266]\n",
      "epoch:6 step:4898[D loss: 0.441250, acc: 59.38%, op_acc: 33.59%] [G loss: 0.998417]\n",
      "epoch:6 step:4899[D loss: 0.436963, acc: 60.94%, op_acc: 33.59%] [G loss: 0.973474]\n",
      "epoch:6 step:4900[D loss: 0.464644, acc: 61.72%, op_acc: 28.12%] [G loss: 0.944839]\n",
      "##############\n",
      "[0.8463062  0.86327598 0.80542222 0.80449539 0.79321819 0.82750093\n",
      " 0.87224982 0.82507027 0.81637917 0.82370409]\n",
      "##########\n",
      "epoch:6 step:4901[D loss: 0.486040, acc: 53.12%, op_acc: 32.03%] [G loss: 0.811090]\n",
      "epoch:6 step:4902[D loss: 0.462021, acc: 54.69%, op_acc: 32.03%] [G loss: 0.864264]\n",
      "epoch:6 step:4903[D loss: 0.424004, acc: 61.72%, op_acc: 39.06%] [G loss: 0.919329]\n",
      "epoch:6 step:4904[D loss: 0.484958, acc: 52.34%, op_acc: 33.59%] [G loss: 0.855330]\n",
      "epoch:6 step:4905[D loss: 0.417389, acc: 64.06%, op_acc: 35.94%] [G loss: 0.907036]\n",
      "epoch:6 step:4906[D loss: 0.434854, acc: 66.41%, op_acc: 33.59%] [G loss: 0.956762]\n",
      "epoch:6 step:4907[D loss: 0.457515, acc: 59.38%, op_acc: 30.47%] [G loss: 0.883030]\n",
      "epoch:6 step:4908[D loss: 0.423430, acc: 71.09%, op_acc: 33.59%] [G loss: 0.981783]\n",
      "epoch:6 step:4909[D loss: 0.466264, acc: 56.25%, op_acc: 37.50%] [G loss: 0.928976]\n",
      "epoch:6 step:4910[D loss: 0.437738, acc: 59.38%, op_acc: 32.81%] [G loss: 0.892132]\n",
      "epoch:6 step:4911[D loss: 0.428513, acc: 62.50%, op_acc: 34.38%] [G loss: 0.969934]\n",
      "epoch:6 step:4912[D loss: 0.440307, acc: 61.72%, op_acc: 35.94%] [G loss: 0.956537]\n",
      "epoch:6 step:4913[D loss: 0.431564, acc: 64.84%, op_acc: 28.12%] [G loss: 0.984007]\n",
      "epoch:6 step:4914[D loss: 0.433099, acc: 68.75%, op_acc: 29.69%] [G loss: 0.890739]\n",
      "epoch:6 step:4915[D loss: 0.413648, acc: 63.28%, op_acc: 33.59%] [G loss: 0.961270]\n",
      "epoch:6 step:4916[D loss: 0.426447, acc: 68.75%, op_acc: 32.03%] [G loss: 0.949318]\n",
      "epoch:6 step:4917[D loss: 0.415523, acc: 65.62%, op_acc: 37.50%] [G loss: 0.883409]\n",
      "epoch:6 step:4918[D loss: 0.459986, acc: 60.94%, op_acc: 35.16%] [G loss: 0.944305]\n",
      "epoch:6 step:4919[D loss: 0.419781, acc: 69.53%, op_acc: 36.72%] [G loss: 0.932680]\n",
      "epoch:6 step:4920[D loss: 0.454792, acc: 64.06%, op_acc: 32.03%] [G loss: 0.964670]\n",
      "epoch:6 step:4921[D loss: 0.423440, acc: 69.53%, op_acc: 37.50%] [G loss: 0.927478]\n",
      "epoch:6 step:4922[D loss: 0.450417, acc: 65.62%, op_acc: 33.59%] [G loss: 0.904025]\n",
      "epoch:6 step:4923[D loss: 0.435982, acc: 61.72%, op_acc: 35.16%] [G loss: 0.946034]\n",
      "epoch:6 step:4924[D loss: 0.445088, acc: 65.62%, op_acc: 30.47%] [G loss: 0.924152]\n",
      "epoch:6 step:4925[D loss: 0.441663, acc: 57.03%, op_acc: 28.12%] [G loss: 0.911430]\n",
      "epoch:6 step:4926[D loss: 0.448679, acc: 59.38%, op_acc: 28.91%] [G loss: 0.958399]\n",
      "epoch:6 step:4927[D loss: 0.439981, acc: 60.94%, op_acc: 37.50%] [G loss: 0.970742]\n",
      "epoch:6 step:4928[D loss: 0.443729, acc: 59.38%, op_acc: 39.06%] [G loss: 0.933305]\n",
      "epoch:6 step:4929[D loss: 0.442443, acc: 57.81%, op_acc: 31.25%] [G loss: 0.907046]\n",
      "epoch:6 step:4930[D loss: 0.463553, acc: 57.03%, op_acc: 30.47%] [G loss: 0.915000]\n",
      "epoch:6 step:4931[D loss: 0.437884, acc: 64.06%, op_acc: 35.94%] [G loss: 0.851728]\n",
      "epoch:6 step:4932[D loss: 0.472589, acc: 52.34%, op_acc: 29.69%] [G loss: 0.938839]\n",
      "epoch:6 step:4933[D loss: 0.445687, acc: 57.81%, op_acc: 31.25%] [G loss: 0.807419]\n",
      "epoch:6 step:4934[D loss: 0.418012, acc: 67.19%, op_acc: 32.81%] [G loss: 0.876004]\n",
      "epoch:6 step:4935[D loss: 0.462793, acc: 53.91%, op_acc: 37.50%] [G loss: 0.923526]\n",
      "epoch:6 step:4936[D loss: 0.454080, acc: 62.50%, op_acc: 28.12%] [G loss: 0.949671]\n",
      "epoch:6 step:4937[D loss: 0.447404, acc: 63.28%, op_acc: 35.94%] [G loss: 0.878279]\n",
      "epoch:6 step:4938[D loss: 0.462087, acc: 53.91%, op_acc: 34.38%] [G loss: 0.856841]\n",
      "epoch:6 step:4939[D loss: 0.446898, acc: 60.94%, op_acc: 28.12%] [G loss: 0.880094]\n",
      "epoch:6 step:4940[D loss: 0.436395, acc: 64.84%, op_acc: 29.69%] [G loss: 0.936848]\n",
      "epoch:6 step:4941[D loss: 0.448703, acc: 64.06%, op_acc: 28.12%] [G loss: 0.940652]\n",
      "epoch:6 step:4942[D loss: 0.466090, acc: 49.22%, op_acc: 32.03%] [G loss: 0.904648]\n",
      "epoch:6 step:4943[D loss: 0.443929, acc: 57.03%, op_acc: 33.59%] [G loss: 0.953063]\n",
      "epoch:6 step:4944[D loss: 0.458053, acc: 56.25%, op_acc: 31.25%] [G loss: 0.838527]\n",
      "epoch:6 step:4945[D loss: 0.458727, acc: 57.03%, op_acc: 29.69%] [G loss: 0.885645]\n",
      "epoch:6 step:4946[D loss: 0.497581, acc: 49.22%, op_acc: 25.78%] [G loss: 0.869255]\n",
      "epoch:6 step:4947[D loss: 0.432264, acc: 59.38%, op_acc: 33.59%] [G loss: 0.904298]\n",
      "epoch:6 step:4948[D loss: 0.432434, acc: 60.16%, op_acc: 32.03%] [G loss: 1.085722]\n",
      "epoch:6 step:4949[D loss: 0.462442, acc: 53.12%, op_acc: 32.81%] [G loss: 0.904813]\n",
      "epoch:6 step:4950[D loss: 0.490359, acc: 57.81%, op_acc: 34.38%] [G loss: 0.974630]\n",
      "##############\n",
      "[0.87430378 0.87100816 0.81279826 0.80404735 0.7990934  0.81057531\n",
      " 0.88256496 0.8279923  0.81098621 0.81587768]\n",
      "##########\n",
      "epoch:6 step:4951[D loss: 0.415237, acc: 62.50%, op_acc: 35.94%] [G loss: 0.963666]\n",
      "epoch:6 step:4952[D loss: 0.484732, acc: 52.34%, op_acc: 28.12%] [G loss: 0.846078]\n",
      "epoch:6 step:4953[D loss: 0.467051, acc: 53.91%, op_acc: 33.59%] [G loss: 0.873737]\n",
      "epoch:6 step:4954[D loss: 0.426635, acc: 64.84%, op_acc: 38.28%] [G loss: 0.935373]\n",
      "epoch:6 step:4955[D loss: 0.424570, acc: 65.62%, op_acc: 36.72%] [G loss: 0.954585]\n",
      "epoch:6 step:4956[D loss: 0.464323, acc: 56.25%, op_acc: 28.12%] [G loss: 0.915324]\n",
      "epoch:6 step:4957[D loss: 0.463310, acc: 58.59%, op_acc: 29.69%] [G loss: 0.959462]\n",
      "epoch:6 step:4958[D loss: 0.456306, acc: 61.72%, op_acc: 32.03%] [G loss: 0.903344]\n",
      "epoch:6 step:4959[D loss: 0.425851, acc: 61.72%, op_acc: 41.41%] [G loss: 0.966473]\n",
      "epoch:6 step:4960[D loss: 0.466686, acc: 56.25%, op_acc: 32.03%] [G loss: 0.890576]\n",
      "epoch:6 step:4961[D loss: 0.443693, acc: 61.72%, op_acc: 39.06%] [G loss: 0.794400]\n",
      "epoch:6 step:4962[D loss: 0.460826, acc: 59.38%, op_acc: 35.16%] [G loss: 0.939476]\n",
      "epoch:6 step:4963[D loss: 0.458180, acc: 57.81%, op_acc: 29.69%] [G loss: 0.856877]\n",
      "epoch:6 step:4964[D loss: 0.466885, acc: 52.34%, op_acc: 31.25%] [G loss: 0.923745]\n",
      "epoch:6 step:4965[D loss: 0.446260, acc: 57.03%, op_acc: 29.69%] [G loss: 0.945347]\n",
      "epoch:6 step:4966[D loss: 0.428193, acc: 60.94%, op_acc: 35.16%] [G loss: 0.913782]\n",
      "epoch:6 step:4967[D loss: 0.455737, acc: 65.62%, op_acc: 24.22%] [G loss: 0.928437]\n",
      "epoch:6 step:4968[D loss: 0.453725, acc: 60.94%, op_acc: 30.47%] [G loss: 0.981713]\n",
      "epoch:6 step:4969[D loss: 0.464591, acc: 54.69%, op_acc: 36.72%] [G loss: 0.834157]\n",
      "epoch:6 step:4970[D loss: 0.450639, acc: 58.59%, op_acc: 31.25%] [G loss: 0.915477]\n",
      "epoch:6 step:4971[D loss: 0.438413, acc: 58.59%, op_acc: 32.81%] [G loss: 0.973684]\n",
      "epoch:6 step:4972[D loss: 0.414449, acc: 69.53%, op_acc: 30.47%] [G loss: 0.928578]\n",
      "epoch:6 step:4973[D loss: 0.441913, acc: 62.50%, op_acc: 42.97%] [G loss: 0.972729]\n",
      "epoch:6 step:4974[D loss: 0.418184, acc: 61.72%, op_acc: 34.38%] [G loss: 0.930171]\n",
      "epoch:6 step:4975[D loss: 0.439586, acc: 67.19%, op_acc: 26.56%] [G loss: 1.033169]\n",
      "epoch:6 step:4976[D loss: 0.438016, acc: 60.94%, op_acc: 36.72%] [G loss: 0.906045]\n",
      "epoch:6 step:4977[D loss: 0.418368, acc: 68.75%, op_acc: 39.84%] [G loss: 0.990528]\n",
      "epoch:6 step:4978[D loss: 0.478541, acc: 51.56%, op_acc: 29.69%] [G loss: 0.913915]\n",
      "epoch:6 step:4979[D loss: 0.417523, acc: 64.06%, op_acc: 33.59%] [G loss: 0.948099]\n",
      "epoch:6 step:4980[D loss: 0.479961, acc: 58.59%, op_acc: 32.03%] [G loss: 0.894185]\n",
      "epoch:6 step:4981[D loss: 0.454084, acc: 60.16%, op_acc: 32.03%] [G loss: 0.998737]\n",
      "epoch:6 step:4982[D loss: 0.463597, acc: 55.47%, op_acc: 35.94%] [G loss: 0.914130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4983[D loss: 0.498357, acc: 53.12%, op_acc: 25.78%] [G loss: 0.899493]\n",
      "epoch:6 step:4984[D loss: 0.441222, acc: 66.41%, op_acc: 36.72%] [G loss: 0.996587]\n",
      "epoch:6 step:4985[D loss: 0.444685, acc: 53.12%, op_acc: 35.94%] [G loss: 0.887014]\n",
      "epoch:6 step:4986[D loss: 0.477343, acc: 57.03%, op_acc: 28.91%] [G loss: 0.964777]\n",
      "epoch:6 step:4987[D loss: 0.468481, acc: 50.78%, op_acc: 35.16%] [G loss: 0.879870]\n",
      "epoch:6 step:4988[D loss: 0.426585, acc: 64.84%, op_acc: 34.38%] [G loss: 0.830708]\n",
      "epoch:6 step:4989[D loss: 0.464929, acc: 56.25%, op_acc: 33.59%] [G loss: 0.920193]\n",
      "epoch:6 step:4990[D loss: 0.456759, acc: 61.72%, op_acc: 39.84%] [G loss: 0.935102]\n",
      "epoch:6 step:4991[D loss: 0.427757, acc: 67.19%, op_acc: 32.81%] [G loss: 0.914961]\n",
      "epoch:6 step:4992[D loss: 0.449047, acc: 62.50%, op_acc: 32.03%] [G loss: 0.919115]\n",
      "epoch:6 step:4993[D loss: 0.437819, acc: 63.28%, op_acc: 32.03%] [G loss: 0.901871]\n",
      "epoch:6 step:4994[D loss: 0.463812, acc: 62.50%, op_acc: 26.56%] [G loss: 0.850634]\n",
      "epoch:6 step:4995[D loss: 0.481112, acc: 60.94%, op_acc: 28.91%] [G loss: 0.929404]\n",
      "epoch:6 step:4996[D loss: 0.424249, acc: 66.41%, op_acc: 30.47%] [G loss: 0.982715]\n",
      "epoch:6 step:4997[D loss: 0.455544, acc: 56.25%, op_acc: 28.91%] [G loss: 0.967246]\n",
      "epoch:6 step:4998[D loss: 0.465715, acc: 53.91%, op_acc: 31.25%] [G loss: 0.839299]\n",
      "epoch:6 step:4999[D loss: 0.485909, acc: 54.69%, op_acc: 27.34%] [G loss: 0.827942]\n",
      "epoch:6 step:5000[D loss: 0.470167, acc: 53.12%, op_acc: 35.16%] [G loss: 0.921008]\n",
      "##############\n",
      "[0.86554546 0.86880376 0.80106856 0.816715   0.76359908 0.82252445\n",
      " 0.87720459 0.82858794 0.80604507 0.82208716]\n",
      "##########\n",
      "epoch:6 step:5001[D loss: 0.511978, acc: 42.97%, op_acc: 32.03%] [G loss: 0.895645]\n",
      "epoch:6 step:5002[D loss: 0.446567, acc: 55.47%, op_acc: 33.59%] [G loss: 0.906793]\n",
      "epoch:6 step:5003[D loss: 0.493000, acc: 45.31%, op_acc: 29.69%] [G loss: 0.845652]\n",
      "epoch:6 step:5004[D loss: 0.484243, acc: 55.47%, op_acc: 31.25%] [G loss: 0.927013]\n",
      "epoch:6 step:5005[D loss: 0.457562, acc: 50.78%, op_acc: 36.72%] [G loss: 0.958304]\n",
      "epoch:6 step:5006[D loss: 0.463747, acc: 54.69%, op_acc: 29.69%] [G loss: 0.912934]\n",
      "epoch:6 step:5007[D loss: 0.435203, acc: 64.06%, op_acc: 29.69%] [G loss: 0.992264]\n",
      "epoch:6 step:5008[D loss: 0.435541, acc: 66.41%, op_acc: 32.03%] [G loss: 1.011358]\n",
      "epoch:6 step:5009[D loss: 0.479384, acc: 53.91%, op_acc: 30.47%] [G loss: 0.898014]\n",
      "epoch:6 step:5010[D loss: 0.475924, acc: 53.12%, op_acc: 28.91%] [G loss: 0.899828]\n",
      "epoch:6 step:5011[D loss: 0.465931, acc: 56.25%, op_acc: 34.38%] [G loss: 0.915598]\n",
      "epoch:6 step:5012[D loss: 0.418064, acc: 66.41%, op_acc: 34.38%] [G loss: 1.015738]\n",
      "epoch:6 step:5013[D loss: 0.443420, acc: 57.81%, op_acc: 34.38%] [G loss: 0.880880]\n",
      "epoch:6 step:5014[D loss: 0.427242, acc: 68.75%, op_acc: 32.81%] [G loss: 0.915273]\n",
      "epoch:6 step:5015[D loss: 0.437969, acc: 64.06%, op_acc: 36.72%] [G loss: 0.837237]\n",
      "epoch:6 step:5016[D loss: 0.446948, acc: 56.25%, op_acc: 37.50%] [G loss: 0.849982]\n",
      "epoch:6 step:5017[D loss: 0.457079, acc: 52.34%, op_acc: 35.16%] [G loss: 0.944620]\n",
      "epoch:6 step:5018[D loss: 0.407493, acc: 71.09%, op_acc: 35.16%] [G loss: 0.969609]\n",
      "epoch:6 step:5019[D loss: 0.424868, acc: 65.62%, op_acc: 37.50%] [G loss: 1.036313]\n",
      "epoch:6 step:5020[D loss: 0.491176, acc: 47.66%, op_acc: 31.25%] [G loss: 0.946399]\n",
      "epoch:6 step:5021[D loss: 0.455833, acc: 60.16%, op_acc: 32.03%] [G loss: 0.866318]\n",
      "epoch:6 step:5022[D loss: 0.445864, acc: 64.06%, op_acc: 31.25%] [G loss: 0.876559]\n",
      "epoch:6 step:5023[D loss: 0.440726, acc: 64.84%, op_acc: 35.16%] [G loss: 0.969426]\n",
      "epoch:6 step:5024[D loss: 0.442604, acc: 60.94%, op_acc: 39.06%] [G loss: 0.960679]\n",
      "epoch:6 step:5025[D loss: 0.461189, acc: 60.16%, op_acc: 30.47%] [G loss: 0.908589]\n",
      "epoch:6 step:5026[D loss: 0.438928, acc: 57.81%, op_acc: 38.28%] [G loss: 0.882786]\n",
      "epoch:6 step:5027[D loss: 0.467223, acc: 54.69%, op_acc: 34.38%] [G loss: 0.845515]\n",
      "epoch:6 step:5028[D loss: 0.494887, acc: 49.22%, op_acc: 26.56%] [G loss: 0.892058]\n",
      "epoch:6 step:5029[D loss: 0.472824, acc: 57.81%, op_acc: 32.81%] [G loss: 0.903371]\n",
      "epoch:6 step:5030[D loss: 0.436775, acc: 64.06%, op_acc: 32.81%] [G loss: 0.959995]\n",
      "epoch:6 step:5031[D loss: 0.475422, acc: 57.81%, op_acc: 26.56%] [G loss: 0.891450]\n",
      "epoch:6 step:5032[D loss: 0.433746, acc: 66.41%, op_acc: 31.25%] [G loss: 0.966370]\n",
      "epoch:6 step:5033[D loss: 0.437671, acc: 61.72%, op_acc: 37.50%] [G loss: 0.953937]\n",
      "epoch:6 step:5034[D loss: 0.450512, acc: 63.28%, op_acc: 32.03%] [G loss: 0.838843]\n",
      "epoch:6 step:5035[D loss: 0.420494, acc: 70.31%, op_acc: 28.91%] [G loss: 0.975309]\n",
      "epoch:6 step:5036[D loss: 0.459400, acc: 58.59%, op_acc: 33.59%] [G loss: 0.804335]\n",
      "epoch:6 step:5037[D loss: 0.447705, acc: 60.94%, op_acc: 32.03%] [G loss: 0.924912]\n",
      "epoch:6 step:5038[D loss: 0.448481, acc: 61.72%, op_acc: 30.47%] [G loss: 1.043031]\n",
      "epoch:6 step:5039[D loss: 0.405783, acc: 67.19%, op_acc: 35.94%] [G loss: 0.995186]\n",
      "epoch:6 step:5040[D loss: 0.462969, acc: 56.25%, op_acc: 30.47%] [G loss: 0.943968]\n",
      "epoch:6 step:5041[D loss: 0.434269, acc: 59.38%, op_acc: 34.38%] [G loss: 0.890732]\n",
      "epoch:6 step:5042[D loss: 0.460364, acc: 57.81%, op_acc: 35.16%] [G loss: 0.873247]\n",
      "epoch:6 step:5043[D loss: 0.456881, acc: 59.38%, op_acc: 29.69%] [G loss: 0.913997]\n",
      "epoch:6 step:5044[D loss: 0.453019, acc: 60.94%, op_acc: 28.91%] [G loss: 0.852647]\n",
      "epoch:6 step:5045[D loss: 0.445745, acc: 57.03%, op_acc: 32.03%] [G loss: 0.901600]\n",
      "epoch:6 step:5046[D loss: 0.463684, acc: 52.34%, op_acc: 32.81%] [G loss: 0.973754]\n",
      "epoch:6 step:5047[D loss: 0.467346, acc: 57.03%, op_acc: 32.81%] [G loss: 0.892755]\n",
      "epoch:6 step:5048[D loss: 0.422413, acc: 57.03%, op_acc: 39.06%] [G loss: 0.943866]\n",
      "epoch:6 step:5049[D loss: 0.463855, acc: 57.81%, op_acc: 32.81%] [G loss: 0.915148]\n",
      "epoch:6 step:5050[D loss: 0.449436, acc: 60.94%, op_acc: 30.47%] [G loss: 0.943528]\n",
      "##############\n",
      "[0.87579793 0.87540254 0.8129573  0.80346112 0.78175793 0.82241296\n",
      " 0.86092117 0.83505375 0.8086079  0.83520942]\n",
      "##########\n",
      "epoch:6 step:5051[D loss: 0.434603, acc: 60.16%, op_acc: 34.38%] [G loss: 0.846576]\n",
      "epoch:6 step:5052[D loss: 0.422853, acc: 63.28%, op_acc: 35.94%] [G loss: 0.960943]\n",
      "epoch:6 step:5053[D loss: 0.437223, acc: 67.97%, op_acc: 32.81%] [G loss: 0.990799]\n",
      "epoch:6 step:5054[D loss: 0.445843, acc: 67.97%, op_acc: 33.59%] [G loss: 0.841338]\n",
      "epoch:6 step:5055[D loss: 0.422221, acc: 67.19%, op_acc: 32.81%] [G loss: 0.920311]\n",
      "epoch:6 step:5056[D loss: 0.447322, acc: 58.59%, op_acc: 34.38%] [G loss: 0.858604]\n",
      "epoch:6 step:5057[D loss: 0.413288, acc: 57.03%, op_acc: 39.84%] [G loss: 0.985191]\n",
      "epoch:6 step:5058[D loss: 0.443491, acc: 61.72%, op_acc: 28.12%] [G loss: 0.860596]\n",
      "epoch:6 step:5059[D loss: 0.459543, acc: 56.25%, op_acc: 30.47%] [G loss: 0.901776]\n",
      "epoch:6 step:5060[D loss: 0.434404, acc: 67.19%, op_acc: 35.16%] [G loss: 0.911132]\n",
      "epoch:6 step:5061[D loss: 0.442845, acc: 59.38%, op_acc: 29.69%] [G loss: 0.839475]\n",
      "epoch:6 step:5062[D loss: 0.437159, acc: 64.84%, op_acc: 30.47%] [G loss: 0.922155]\n",
      "epoch:6 step:5063[D loss: 0.457350, acc: 54.69%, op_acc: 33.59%] [G loss: 0.848299]\n",
      "epoch:6 step:5064[D loss: 0.414715, acc: 75.78%, op_acc: 29.69%] [G loss: 0.864650]\n",
      "epoch:6 step:5065[D loss: 0.412230, acc: 69.53%, op_acc: 35.16%] [G loss: 0.947891]\n",
      "epoch:6 step:5066[D loss: 0.467242, acc: 55.47%, op_acc: 29.69%] [G loss: 0.948937]\n",
      "epoch:6 step:5067[D loss: 0.416763, acc: 67.19%, op_acc: 37.50%] [G loss: 0.857081]\n",
      "epoch:6 step:5068[D loss: 0.448629, acc: 61.72%, op_acc: 34.38%] [G loss: 0.867848]\n",
      "epoch:6 step:5069[D loss: 0.423988, acc: 64.06%, op_acc: 35.16%] [G loss: 0.948942]\n",
      "epoch:6 step:5070[D loss: 0.436257, acc: 63.28%, op_acc: 34.38%] [G loss: 0.927337]\n",
      "epoch:6 step:5071[D loss: 0.458568, acc: 56.25%, op_acc: 36.72%] [G loss: 0.906369]\n",
      "epoch:6 step:5072[D loss: 0.439598, acc: 56.25%, op_acc: 32.81%] [G loss: 0.956722]\n",
      "epoch:6 step:5073[D loss: 0.467041, acc: 57.03%, op_acc: 26.56%] [G loss: 0.889743]\n",
      "epoch:6 step:5074[D loss: 0.478436, acc: 53.91%, op_acc: 30.47%] [G loss: 0.842025]\n",
      "epoch:6 step:5075[D loss: 0.479007, acc: 57.81%, op_acc: 29.69%] [G loss: 0.880303]\n",
      "epoch:6 step:5076[D loss: 0.447978, acc: 56.25%, op_acc: 34.38%] [G loss: 0.873599]\n",
      "epoch:6 step:5077[D loss: 0.442229, acc: 58.59%, op_acc: 38.28%] [G loss: 0.861223]\n",
      "epoch:6 step:5078[D loss: 0.427665, acc: 57.81%, op_acc: 40.62%] [G loss: 0.888217]\n",
      "epoch:6 step:5079[D loss: 0.452102, acc: 57.03%, op_acc: 35.94%] [G loss: 0.879022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5080[D loss: 0.436247, acc: 64.84%, op_acc: 35.94%] [G loss: 0.986644]\n",
      "epoch:6 step:5081[D loss: 0.477040, acc: 53.91%, op_acc: 28.12%] [G loss: 0.908384]\n",
      "epoch:6 step:5082[D loss: 0.438114, acc: 56.25%, op_acc: 41.41%] [G loss: 0.881938]\n",
      "epoch:6 step:5083[D loss: 0.443466, acc: 64.06%, op_acc: 33.59%] [G loss: 0.932536]\n",
      "epoch:6 step:5084[D loss: 0.452935, acc: 59.38%, op_acc: 32.03%] [G loss: 0.858356]\n",
      "epoch:6 step:5085[D loss: 0.444403, acc: 58.59%, op_acc: 34.38%] [G loss: 0.957445]\n",
      "epoch:6 step:5086[D loss: 0.434479, acc: 61.72%, op_acc: 35.16%] [G loss: 0.920673]\n",
      "epoch:6 step:5087[D loss: 0.417036, acc: 64.84%, op_acc: 32.81%] [G loss: 0.920505]\n",
      "epoch:6 step:5088[D loss: 0.458568, acc: 59.38%, op_acc: 25.78%] [G loss: 0.979616]\n",
      "epoch:6 step:5089[D loss: 0.448151, acc: 64.84%, op_acc: 32.81%] [G loss: 0.940868]\n",
      "epoch:6 step:5090[D loss: 0.444869, acc: 53.91%, op_acc: 36.72%] [G loss: 0.857889]\n",
      "epoch:6 step:5091[D loss: 0.465983, acc: 57.81%, op_acc: 30.47%] [G loss: 0.926128]\n",
      "epoch:6 step:5092[D loss: 0.442331, acc: 59.38%, op_acc: 32.03%] [G loss: 0.893536]\n",
      "epoch:6 step:5093[D loss: 0.454775, acc: 61.72%, op_acc: 25.78%] [G loss: 0.924426]\n",
      "epoch:6 step:5094[D loss: 0.446549, acc: 50.78%, op_acc: 35.16%] [G loss: 0.868921]\n",
      "epoch:6 step:5095[D loss: 0.452552, acc: 60.94%, op_acc: 30.47%] [G loss: 0.886976]\n",
      "epoch:6 step:5096[D loss: 0.423693, acc: 59.38%, op_acc: 38.28%] [G loss: 0.943761]\n",
      "epoch:6 step:5097[D loss: 0.447031, acc: 60.16%, op_acc: 35.16%] [G loss: 0.930868]\n",
      "epoch:6 step:5098[D loss: 0.458983, acc: 56.25%, op_acc: 35.16%] [G loss: 0.848554]\n",
      "epoch:6 step:5099[D loss: 0.445324, acc: 60.16%, op_acc: 32.03%] [G loss: 0.924070]\n",
      "epoch:6 step:5100[D loss: 0.441007, acc: 59.38%, op_acc: 35.94%] [G loss: 0.877699]\n",
      "##############\n",
      "[0.86850155 0.87462052 0.80529964 0.80665781 0.79649522 0.84484535\n",
      " 0.84329827 0.82004886 0.81455651 0.82187538]\n",
      "##########\n",
      "epoch:6 step:5101[D loss: 0.427706, acc: 60.16%, op_acc: 37.50%] [G loss: 0.895705]\n",
      "epoch:6 step:5102[D loss: 0.479442, acc: 50.78%, op_acc: 32.03%] [G loss: 0.835030]\n",
      "epoch:6 step:5103[D loss: 0.430385, acc: 68.75%, op_acc: 28.91%] [G loss: 1.017751]\n",
      "epoch:6 step:5104[D loss: 0.431987, acc: 60.16%, op_acc: 35.94%] [G loss: 0.945067]\n",
      "epoch:6 step:5105[D loss: 0.435404, acc: 60.94%, op_acc: 32.81%] [G loss: 0.875036]\n",
      "epoch:6 step:5106[D loss: 0.435939, acc: 66.41%, op_acc: 34.38%] [G loss: 0.932802]\n",
      "epoch:6 step:5107[D loss: 0.443471, acc: 57.03%, op_acc: 32.03%] [G loss: 0.918097]\n",
      "epoch:6 step:5108[D loss: 0.454063, acc: 60.16%, op_acc: 35.94%] [G loss: 0.984603]\n",
      "epoch:6 step:5109[D loss: 0.458464, acc: 57.81%, op_acc: 37.50%] [G loss: 0.955698]\n",
      "epoch:6 step:5110[D loss: 0.494844, acc: 54.69%, op_acc: 33.59%] [G loss: 0.887730]\n",
      "epoch:6 step:5111[D loss: 0.465591, acc: 60.94%, op_acc: 27.34%] [G loss: 0.938507]\n",
      "epoch:6 step:5112[D loss: 0.451963, acc: 61.72%, op_acc: 32.03%] [G loss: 1.004285]\n",
      "epoch:6 step:5113[D loss: 0.466861, acc: 60.94%, op_acc: 31.25%] [G loss: 0.942562]\n",
      "epoch:6 step:5114[D loss: 0.444497, acc: 63.28%, op_acc: 32.03%] [G loss: 1.014118]\n",
      "epoch:6 step:5115[D loss: 0.446279, acc: 58.59%, op_acc: 34.38%] [G loss: 0.835366]\n",
      "epoch:6 step:5116[D loss: 0.458233, acc: 58.59%, op_acc: 34.38%] [G loss: 0.874753]\n",
      "epoch:6 step:5117[D loss: 0.501400, acc: 56.25%, op_acc: 26.56%] [G loss: 0.794052]\n",
      "epoch:6 step:5118[D loss: 0.436932, acc: 59.38%, op_acc: 35.94%] [G loss: 0.984299]\n",
      "epoch:6 step:5119[D loss: 0.457683, acc: 59.38%, op_acc: 28.12%] [G loss: 0.913643]\n",
      "epoch:6 step:5120[D loss: 0.447921, acc: 57.81%, op_acc: 35.16%] [G loss: 0.866783]\n",
      "epoch:6 step:5121[D loss: 0.440757, acc: 54.69%, op_acc: 39.84%] [G loss: 0.823558]\n",
      "epoch:6 step:5122[D loss: 0.470631, acc: 55.47%, op_acc: 35.16%] [G loss: 0.921629]\n",
      "epoch:6 step:5123[D loss: 0.491732, acc: 48.44%, op_acc: 32.03%] [G loss: 0.820073]\n",
      "epoch:6 step:5124[D loss: 0.433796, acc: 65.62%, op_acc: 32.03%] [G loss: 0.949705]\n",
      "epoch:6 step:5125[D loss: 0.414485, acc: 68.75%, op_acc: 34.38%] [G loss: 0.925244]\n",
      "epoch:6 step:5126[D loss: 0.462438, acc: 51.56%, op_acc: 35.16%] [G loss: 0.821166]\n",
      "epoch:6 step:5127[D loss: 0.458038, acc: 57.81%, op_acc: 28.12%] [G loss: 0.873426]\n",
      "epoch:6 step:5128[D loss: 0.393567, acc: 70.31%, op_acc: 35.94%] [G loss: 0.967460]\n",
      "epoch:6 step:5129[D loss: 0.498806, acc: 53.12%, op_acc: 25.78%] [G loss: 0.936966]\n",
      "epoch:6 step:5130[D loss: 0.479431, acc: 54.69%, op_acc: 29.69%] [G loss: 0.910859]\n",
      "epoch:6 step:5131[D loss: 0.467364, acc: 60.94%, op_acc: 30.47%] [G loss: 0.921061]\n",
      "epoch:6 step:5132[D loss: 0.447522, acc: 61.72%, op_acc: 31.25%] [G loss: 0.932354]\n",
      "epoch:6 step:5133[D loss: 0.461066, acc: 59.38%, op_acc: 28.12%] [G loss: 0.879090]\n",
      "epoch:6 step:5134[D loss: 0.433568, acc: 60.16%, op_acc: 37.50%] [G loss: 0.899402]\n",
      "epoch:6 step:5135[D loss: 0.429062, acc: 67.97%, op_acc: 35.94%] [G loss: 0.933161]\n",
      "epoch:6 step:5136[D loss: 0.433389, acc: 62.50%, op_acc: 25.78%] [G loss: 0.920157]\n",
      "epoch:6 step:5137[D loss: 0.419595, acc: 65.62%, op_acc: 35.94%] [G loss: 0.927104]\n",
      "epoch:6 step:5138[D loss: 0.421978, acc: 64.84%, op_acc: 32.81%] [G loss: 0.883881]\n",
      "epoch:6 step:5139[D loss: 0.435668, acc: 54.69%, op_acc: 37.50%] [G loss: 1.031925]\n",
      "epoch:6 step:5140[D loss: 0.469612, acc: 53.91%, op_acc: 29.69%] [G loss: 0.969723]\n",
      "epoch:6 step:5141[D loss: 0.447403, acc: 60.94%, op_acc: 32.03%] [G loss: 0.854897]\n",
      "epoch:6 step:5142[D loss: 0.425826, acc: 62.50%, op_acc: 35.16%] [G loss: 0.861723]\n",
      "epoch:6 step:5143[D loss: 0.415928, acc: 70.31%, op_acc: 31.25%] [G loss: 0.902385]\n",
      "epoch:6 step:5144[D loss: 0.438086, acc: 57.81%, op_acc: 40.62%] [G loss: 0.899656]\n",
      "epoch:6 step:5145[D loss: 0.438336, acc: 58.59%, op_acc: 35.94%] [G loss: 0.906988]\n",
      "epoch:6 step:5146[D loss: 0.445359, acc: 52.34%, op_acc: 32.03%] [G loss: 0.891489]\n",
      "epoch:6 step:5147[D loss: 0.471557, acc: 57.81%, op_acc: 29.69%] [G loss: 0.941774]\n",
      "epoch:6 step:5148[D loss: 0.441239, acc: 58.59%, op_acc: 35.16%] [G loss: 0.848222]\n",
      "epoch:6 step:5149[D loss: 0.439396, acc: 61.72%, op_acc: 28.91%] [G loss: 0.903193]\n",
      "epoch:6 step:5150[D loss: 0.447937, acc: 62.50%, op_acc: 34.38%] [G loss: 0.965484]\n",
      "##############\n",
      "[0.86288414 0.83548713 0.80845935 0.81179595 0.76528398 0.84335863\n",
      " 0.89356165 0.83158189 0.81675656 0.83046553]\n",
      "##########\n",
      "epoch:6 step:5151[D loss: 0.453420, acc: 57.81%, op_acc: 31.25%] [G loss: 0.952911]\n",
      "epoch:6 step:5152[D loss: 0.425888, acc: 65.62%, op_acc: 33.59%] [G loss: 1.013680]\n",
      "epoch:6 step:5153[D loss: 0.473918, acc: 56.25%, op_acc: 26.56%] [G loss: 0.921246]\n",
      "epoch:6 step:5154[D loss: 0.448255, acc: 63.28%, op_acc: 36.72%] [G loss: 0.898974]\n",
      "epoch:6 step:5155[D loss: 0.430511, acc: 60.16%, op_acc: 36.72%] [G loss: 1.026562]\n",
      "epoch:6 step:5156[D loss: 0.432112, acc: 67.19%, op_acc: 30.47%] [G loss: 0.932298]\n",
      "epoch:6 step:5157[D loss: 0.447508, acc: 60.94%, op_acc: 28.12%] [G loss: 0.961776]\n",
      "epoch:6 step:5158[D loss: 0.441862, acc: 58.59%, op_acc: 31.25%] [G loss: 0.943784]\n",
      "epoch:6 step:5159[D loss: 0.429014, acc: 57.03%, op_acc: 39.06%] [G loss: 0.860333]\n",
      "epoch:6 step:5160[D loss: 0.449788, acc: 56.25%, op_acc: 32.81%] [G loss: 0.960274]\n",
      "epoch:6 step:5161[D loss: 0.442496, acc: 58.59%, op_acc: 37.50%] [G loss: 0.900463]\n",
      "epoch:6 step:5162[D loss: 0.461742, acc: 64.84%, op_acc: 28.91%] [G loss: 0.945822]\n",
      "epoch:6 step:5163[D loss: 0.429721, acc: 62.50%, op_acc: 36.72%] [G loss: 0.901715]\n",
      "epoch:6 step:5164[D loss: 0.462252, acc: 56.25%, op_acc: 29.69%] [G loss: 0.871667]\n",
      "epoch:6 step:5165[D loss: 0.437778, acc: 63.28%, op_acc: 32.81%] [G loss: 0.884270]\n",
      "epoch:6 step:5166[D loss: 0.509111, acc: 46.88%, op_acc: 26.56%] [G loss: 0.899675]\n",
      "epoch:6 step:5167[D loss: 0.465946, acc: 62.50%, op_acc: 30.47%] [G loss: 0.956713]\n",
      "epoch:6 step:5168[D loss: 0.470253, acc: 62.50%, op_acc: 30.47%] [G loss: 0.945414]\n",
      "epoch:6 step:5169[D loss: 0.430064, acc: 59.38%, op_acc: 33.59%] [G loss: 0.954876]\n",
      "epoch:6 step:5170[D loss: 0.407798, acc: 66.41%, op_acc: 41.41%] [G loss: 0.863983]\n",
      "epoch:6 step:5171[D loss: 0.423339, acc: 68.75%, op_acc: 32.81%] [G loss: 0.934150]\n",
      "epoch:6 step:5172[D loss: 0.463465, acc: 53.12%, op_acc: 34.38%] [G loss: 0.894602]\n",
      "epoch:6 step:5173[D loss: 0.431616, acc: 63.28%, op_acc: 36.72%] [G loss: 0.901902]\n",
      "epoch:6 step:5174[D loss: 0.458220, acc: 60.94%, op_acc: 27.34%] [G loss: 0.936988]\n",
      "epoch:6 step:5175[D loss: 0.455927, acc: 55.47%, op_acc: 41.41%] [G loss: 0.845099]\n",
      "epoch:6 step:5176[D loss: 0.428185, acc: 58.59%, op_acc: 33.59%] [G loss: 0.907463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5177[D loss: 0.478764, acc: 54.69%, op_acc: 31.25%] [G loss: 0.926939]\n",
      "epoch:6 step:5178[D loss: 0.419578, acc: 67.97%, op_acc: 35.16%] [G loss: 0.970345]\n",
      "epoch:6 step:5179[D loss: 0.452819, acc: 58.59%, op_acc: 33.59%] [G loss: 0.860280]\n",
      "epoch:6 step:5180[D loss: 0.407785, acc: 70.31%, op_acc: 36.72%] [G loss: 0.898758]\n",
      "epoch:6 step:5181[D loss: 0.428921, acc: 63.28%, op_acc: 35.16%] [G loss: 0.840779]\n",
      "epoch:6 step:5182[D loss: 0.461116, acc: 57.81%, op_acc: 36.72%] [G loss: 0.903981]\n",
      "epoch:6 step:5183[D loss: 0.488489, acc: 43.75%, op_acc: 33.59%] [G loss: 1.008608]\n",
      "epoch:6 step:5184[D loss: 0.442303, acc: 64.84%, op_acc: 30.47%] [G loss: 0.982398]\n",
      "epoch:6 step:5185[D loss: 0.465759, acc: 66.41%, op_acc: 25.78%] [G loss: 0.947239]\n",
      "epoch:6 step:5186[D loss: 0.445328, acc: 62.50%, op_acc: 38.28%] [G loss: 0.933337]\n",
      "epoch:6 step:5187[D loss: 0.449514, acc: 65.62%, op_acc: 30.47%] [G loss: 0.948871]\n",
      "epoch:6 step:5188[D loss: 0.417703, acc: 62.50%, op_acc: 36.72%] [G loss: 0.909092]\n",
      "epoch:6 step:5189[D loss: 0.419264, acc: 67.97%, op_acc: 28.12%] [G loss: 0.925175]\n",
      "epoch:6 step:5190[D loss: 0.473559, acc: 48.44%, op_acc: 33.59%] [G loss: 0.955753]\n",
      "epoch:6 step:5191[D loss: 0.471822, acc: 58.59%, op_acc: 28.91%] [G loss: 0.866105]\n",
      "epoch:6 step:5192[D loss: 0.428945, acc: 66.41%, op_acc: 37.50%] [G loss: 0.904409]\n",
      "epoch:6 step:5193[D loss: 0.435618, acc: 53.91%, op_acc: 34.38%] [G loss: 0.906594]\n",
      "epoch:6 step:5194[D loss: 0.466802, acc: 56.25%, op_acc: 31.25%] [G loss: 0.882360]\n",
      "epoch:6 step:5195[D loss: 0.494765, acc: 48.44%, op_acc: 29.69%] [G loss: 0.864779]\n",
      "epoch:6 step:5196[D loss: 0.423628, acc: 67.97%, op_acc: 34.38%] [G loss: 0.937973]\n",
      "epoch:6 step:5197[D loss: 0.476429, acc: 46.09%, op_acc: 36.72%] [G loss: 0.845882]\n",
      "epoch:6 step:5198[D loss: 0.474893, acc: 53.12%, op_acc: 32.03%] [G loss: 0.877652]\n",
      "epoch:6 step:5199[D loss: 0.458233, acc: 61.72%, op_acc: 32.03%] [G loss: 0.884972]\n",
      "epoch:6 step:5200[D loss: 0.468772, acc: 64.06%, op_acc: 28.12%] [G loss: 0.907297]\n",
      "##############\n",
      "[0.86198318 0.86308503 0.80311906 0.78342426 0.79176776 0.84871456\n",
      " 0.89478636 0.84459164 0.80170196 0.8543233 ]\n",
      "##########\n",
      "epoch:6 step:5201[D loss: 0.448982, acc: 54.69%, op_acc: 35.94%] [G loss: 0.917756]\n",
      "epoch:6 step:5202[D loss: 0.424056, acc: 64.06%, op_acc: 39.06%] [G loss: 0.930883]\n",
      "epoch:6 step:5203[D loss: 0.457996, acc: 60.16%, op_acc: 31.25%] [G loss: 0.943219]\n",
      "epoch:6 step:5204[D loss: 0.423515, acc: 67.19%, op_acc: 34.38%] [G loss: 0.982824]\n",
      "epoch:6 step:5205[D loss: 0.425365, acc: 60.94%, op_acc: 35.16%] [G loss: 0.829092]\n",
      "epoch:6 step:5206[D loss: 0.443696, acc: 60.94%, op_acc: 36.72%] [G loss: 0.993400]\n",
      "epoch:6 step:5207[D loss: 0.471150, acc: 59.38%, op_acc: 31.25%] [G loss: 0.989832]\n",
      "epoch:6 step:5208[D loss: 0.475613, acc: 58.59%, op_acc: 27.34%] [G loss: 0.856676]\n",
      "epoch:6 step:5209[D loss: 0.455139, acc: 60.94%, op_acc: 32.03%] [G loss: 0.810193]\n",
      "epoch:6 step:5210[D loss: 0.436774, acc: 66.41%, op_acc: 31.25%] [G loss: 0.969837]\n",
      "epoch:6 step:5211[D loss: 0.488509, acc: 58.59%, op_acc: 25.00%] [G loss: 0.912295]\n",
      "epoch:6 step:5212[D loss: 0.514321, acc: 49.22%, op_acc: 32.03%] [G loss: 0.906864]\n",
      "epoch:6 step:5213[D loss: 0.431758, acc: 60.94%, op_acc: 29.69%] [G loss: 0.948951]\n",
      "epoch:6 step:5214[D loss: 0.465747, acc: 51.56%, op_acc: 33.59%] [G loss: 0.854899]\n",
      "epoch:6 step:5215[D loss: 0.450626, acc: 55.47%, op_acc: 32.81%] [G loss: 0.870224]\n",
      "epoch:6 step:5216[D loss: 0.453805, acc: 60.16%, op_acc: 30.47%] [G loss: 0.919766]\n",
      "epoch:6 step:5217[D loss: 0.459310, acc: 59.38%, op_acc: 28.91%] [G loss: 0.922810]\n",
      "epoch:6 step:5218[D loss: 0.462731, acc: 55.47%, op_acc: 27.34%] [G loss: 1.027612]\n",
      "epoch:6 step:5219[D loss: 0.451988, acc: 58.59%, op_acc: 35.16%] [G loss: 0.991380]\n",
      "epoch:6 step:5220[D loss: 0.428619, acc: 65.62%, op_acc: 37.50%] [G loss: 0.933415]\n",
      "epoch:6 step:5221[D loss: 0.423741, acc: 65.62%, op_acc: 40.62%] [G loss: 0.907903]\n",
      "epoch:6 step:5222[D loss: 0.420231, acc: 66.41%, op_acc: 36.72%] [G loss: 1.004942]\n",
      "epoch:6 step:5223[D loss: 0.467993, acc: 60.16%, op_acc: 28.91%] [G loss: 0.996988]\n",
      "epoch:6 step:5224[D loss: 0.430326, acc: 61.72%, op_acc: 32.81%] [G loss: 0.967682]\n",
      "epoch:6 step:5225[D loss: 0.475537, acc: 61.72%, op_acc: 28.12%] [G loss: 0.923619]\n",
      "epoch:6 step:5226[D loss: 0.428502, acc: 64.06%, op_acc: 32.81%] [G loss: 1.008680]\n",
      "epoch:6 step:5227[D loss: 0.407077, acc: 66.41%, op_acc: 41.41%] [G loss: 0.941170]\n",
      "epoch:6 step:5228[D loss: 0.477758, acc: 51.56%, op_acc: 32.03%] [G loss: 0.942988]\n",
      "epoch:6 step:5229[D loss: 0.442504, acc: 65.62%, op_acc: 27.34%] [G loss: 0.975082]\n",
      "epoch:6 step:5230[D loss: 0.469368, acc: 52.34%, op_acc: 35.94%] [G loss: 0.899345]\n",
      "epoch:6 step:5231[D loss: 0.430135, acc: 60.94%, op_acc: 34.38%] [G loss: 0.948528]\n",
      "epoch:6 step:5232[D loss: 0.453097, acc: 54.69%, op_acc: 30.47%] [G loss: 0.862079]\n",
      "epoch:6 step:5233[D loss: 0.441505, acc: 69.53%, op_acc: 32.81%] [G loss: 0.927392]\n",
      "epoch:6 step:5234[D loss: 0.471236, acc: 57.81%, op_acc: 35.16%] [G loss: 0.888698]\n",
      "epoch:6 step:5235[D loss: 0.471457, acc: 46.09%, op_acc: 33.59%] [G loss: 0.780884]\n",
      "epoch:6 step:5236[D loss: 0.482591, acc: 56.25%, op_acc: 28.12%] [G loss: 0.893023]\n",
      "epoch:6 step:5237[D loss: 0.443259, acc: 60.16%, op_acc: 31.25%] [G loss: 0.843958]\n",
      "epoch:6 step:5238[D loss: 0.458395, acc: 66.41%, op_acc: 26.56%] [G loss: 0.865735]\n",
      "epoch:6 step:5239[D loss: 0.433509, acc: 58.59%, op_acc: 36.72%] [G loss: 0.900453]\n",
      "epoch:6 step:5240[D loss: 0.453006, acc: 55.47%, op_acc: 32.03%] [G loss: 0.880725]\n",
      "epoch:6 step:5241[D loss: 0.451384, acc: 60.94%, op_acc: 35.94%] [G loss: 0.949578]\n",
      "epoch:6 step:5242[D loss: 0.428057, acc: 66.41%, op_acc: 37.50%] [G loss: 0.894603]\n",
      "epoch:6 step:5243[D loss: 0.466749, acc: 53.12%, op_acc: 27.34%] [G loss: 0.890176]\n",
      "epoch:6 step:5244[D loss: 0.452065, acc: 62.50%, op_acc: 34.38%] [G loss: 0.939877]\n",
      "epoch:6 step:5245[D loss: 0.440314, acc: 60.16%, op_acc: 32.81%] [G loss: 0.903198]\n",
      "epoch:6 step:5246[D loss: 0.459437, acc: 56.25%, op_acc: 29.69%] [G loss: 0.835002]\n",
      "epoch:6 step:5247[D loss: 0.466957, acc: 58.59%, op_acc: 32.03%] [G loss: 0.946049]\n",
      "epoch:6 step:5248[D loss: 0.463317, acc: 52.34%, op_acc: 30.47%] [G loss: 0.888808]\n",
      "epoch:6 step:5249[D loss: 0.449905, acc: 60.16%, op_acc: 30.47%] [G loss: 0.957821]\n",
      "epoch:6 step:5250[D loss: 0.455863, acc: 54.69%, op_acc: 38.28%] [G loss: 0.954908]\n",
      "##############\n",
      "[0.86277964 0.87206308 0.81420975 0.79909034 0.79554892 0.79713015\n",
      " 0.87382658 0.806836   0.79574381 0.84812408]\n",
      "##########\n",
      "epoch:6 step:5251[D loss: 0.428768, acc: 64.06%, op_acc: 35.16%] [G loss: 0.821543]\n",
      "epoch:6 step:5252[D loss: 0.438305, acc: 67.97%, op_acc: 26.56%] [G loss: 0.864344]\n",
      "epoch:6 step:5253[D loss: 0.437581, acc: 61.72%, op_acc: 31.25%] [G loss: 0.914240]\n",
      "epoch:6 step:5254[D loss: 0.454516, acc: 58.59%, op_acc: 29.69%] [G loss: 0.968075]\n",
      "epoch:6 step:5255[D loss: 0.447011, acc: 58.59%, op_acc: 34.38%] [G loss: 0.887291]\n",
      "epoch:6 step:5256[D loss: 0.439751, acc: 58.59%, op_acc: 36.72%] [G loss: 0.918923]\n",
      "epoch:6 step:5257[D loss: 0.429759, acc: 60.94%, op_acc: 39.84%] [G loss: 0.889886]\n",
      "epoch:6 step:5258[D loss: 0.440766, acc: 61.72%, op_acc: 32.81%] [G loss: 0.882528]\n",
      "epoch:6 step:5259[D loss: 0.461430, acc: 56.25%, op_acc: 33.59%] [G loss: 0.844940]\n",
      "epoch:6 step:5260[D loss: 0.462170, acc: 54.69%, op_acc: 29.69%] [G loss: 0.944952]\n",
      "epoch:6 step:5261[D loss: 0.447711, acc: 62.50%, op_acc: 33.59%] [G loss: 0.908894]\n",
      "epoch:6 step:5262[D loss: 0.444376, acc: 57.81%, op_acc: 33.59%] [G loss: 0.890333]\n",
      "epoch:6 step:5263[D loss: 0.445369, acc: 60.94%, op_acc: 28.12%] [G loss: 0.882835]\n",
      "epoch:6 step:5264[D loss: 0.429854, acc: 64.06%, op_acc: 37.50%] [G loss: 0.860110]\n",
      "epoch:6 step:5265[D loss: 0.417767, acc: 61.72%, op_acc: 36.72%] [G loss: 0.927574]\n",
      "epoch:6 step:5266[D loss: 0.462502, acc: 56.25%, op_acc: 29.69%] [G loss: 0.928320]\n",
      "epoch:6 step:5267[D loss: 0.467513, acc: 50.78%, op_acc: 31.25%] [G loss: 0.903200]\n",
      "epoch:6 step:5268[D loss: 0.453723, acc: 57.03%, op_acc: 30.47%] [G loss: 0.848452]\n",
      "epoch:6 step:5269[D loss: 0.436699, acc: 57.81%, op_acc: 31.25%] [G loss: 0.941421]\n",
      "epoch:6 step:5270[D loss: 0.439450, acc: 66.41%, op_acc: 25.00%] [G loss: 0.920054]\n",
      "epoch:6 step:5271[D loss: 0.428322, acc: 61.72%, op_acc: 36.72%] [G loss: 0.925624]\n",
      "epoch:6 step:5272[D loss: 0.450525, acc: 60.16%, op_acc: 32.03%] [G loss: 0.928931]\n",
      "epoch:6 step:5273[D loss: 0.428054, acc: 66.41%, op_acc: 32.81%] [G loss: 0.940127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5274[D loss: 0.429015, acc: 60.16%, op_acc: 35.94%] [G loss: 0.936354]\n",
      "epoch:6 step:5275[D loss: 0.442895, acc: 60.94%, op_acc: 32.03%] [G loss: 0.948409]\n",
      "epoch:6 step:5276[D loss: 0.445502, acc: 64.06%, op_acc: 31.25%] [G loss: 0.876649]\n",
      "epoch:6 step:5277[D loss: 0.445437, acc: 56.25%, op_acc: 33.59%] [G loss: 0.929807]\n",
      "epoch:6 step:5278[D loss: 0.447816, acc: 60.16%, op_acc: 35.16%] [G loss: 0.915347]\n",
      "epoch:6 step:5279[D loss: 0.437746, acc: 68.75%, op_acc: 31.25%] [G loss: 0.988024]\n",
      "epoch:6 step:5280[D loss: 0.456771, acc: 56.25%, op_acc: 35.94%] [G loss: 0.891807]\n",
      "epoch:6 step:5281[D loss: 0.423758, acc: 68.75%, op_acc: 30.47%] [G loss: 1.020048]\n",
      "epoch:6 step:5282[D loss: 0.435942, acc: 61.72%, op_acc: 36.72%] [G loss: 0.917318]\n",
      "epoch:6 step:5283[D loss: 0.459287, acc: 58.59%, op_acc: 31.25%] [G loss: 0.973343]\n",
      "epoch:6 step:5284[D loss: 0.441963, acc: 57.03%, op_acc: 37.50%] [G loss: 0.924021]\n",
      "epoch:6 step:5285[D loss: 0.446258, acc: 69.53%, op_acc: 25.78%] [G loss: 1.000062]\n",
      "epoch:6 step:5286[D loss: 0.461465, acc: 60.16%, op_acc: 29.69%] [G loss: 0.907787]\n",
      "epoch:6 step:5287[D loss: 0.451473, acc: 60.16%, op_acc: 29.69%] [G loss: 0.888924]\n",
      "epoch:6 step:5288[D loss: 0.431270, acc: 57.03%, op_acc: 35.16%] [G loss: 0.898761]\n",
      "epoch:6 step:5289[D loss: 0.409271, acc: 59.38%, op_acc: 40.62%] [G loss: 0.980640]\n",
      "epoch:6 step:5290[D loss: 0.449487, acc: 61.72%, op_acc: 33.59%] [G loss: 0.942298]\n",
      "epoch:6 step:5291[D loss: 0.412315, acc: 69.53%, op_acc: 35.94%] [G loss: 1.005767]\n",
      "epoch:6 step:5292[D loss: 0.425466, acc: 63.28%, op_acc: 33.59%] [G loss: 0.959973]\n",
      "epoch:6 step:5293[D loss: 0.415114, acc: 69.53%, op_acc: 40.62%] [G loss: 0.833797]\n",
      "epoch:6 step:5294[D loss: 0.450008, acc: 57.03%, op_acc: 32.81%] [G loss: 0.869647]\n",
      "epoch:6 step:5295[D loss: 0.460023, acc: 55.47%, op_acc: 29.69%] [G loss: 0.907779]\n",
      "epoch:6 step:5296[D loss: 0.396234, acc: 76.56%, op_acc: 34.38%] [G loss: 0.994718]\n",
      "epoch:6 step:5297[D loss: 0.450860, acc: 60.94%, op_acc: 30.47%] [G loss: 0.981431]\n",
      "epoch:6 step:5298[D loss: 0.453623, acc: 61.72%, op_acc: 35.94%] [G loss: 0.897092]\n",
      "epoch:6 step:5299[D loss: 0.466717, acc: 52.34%, op_acc: 32.81%] [G loss: 0.877860]\n",
      "epoch:6 step:5300[D loss: 0.434706, acc: 58.59%, op_acc: 40.62%] [G loss: 0.930980]\n",
      "##############\n",
      "[0.85182116 0.85700962 0.83978099 0.79036376 0.78862467 0.81415275\n",
      " 0.88446723 0.83423558 0.79695868 0.82857412]\n",
      "##########\n",
      "epoch:6 step:5301[D loss: 0.469240, acc: 56.25%, op_acc: 30.47%] [G loss: 0.818038]\n",
      "epoch:6 step:5302[D loss: 0.455076, acc: 57.03%, op_acc: 35.16%] [G loss: 0.934594]\n",
      "epoch:6 step:5303[D loss: 0.470371, acc: 60.94%, op_acc: 28.12%] [G loss: 0.976288]\n",
      "epoch:6 step:5304[D loss: 0.424547, acc: 66.41%, op_acc: 39.06%] [G loss: 0.936625]\n",
      "epoch:6 step:5305[D loss: 0.469398, acc: 57.81%, op_acc: 32.03%] [G loss: 0.903244]\n",
      "epoch:6 step:5306[D loss: 0.461702, acc: 57.03%, op_acc: 24.22%] [G loss: 0.908076]\n",
      "epoch:6 step:5307[D loss: 0.422196, acc: 67.19%, op_acc: 33.59%] [G loss: 0.983238]\n",
      "epoch:6 step:5308[D loss: 0.445813, acc: 62.50%, op_acc: 31.25%] [G loss: 0.916576]\n",
      "epoch:6 step:5309[D loss: 0.434275, acc: 58.59%, op_acc: 35.94%] [G loss: 1.022227]\n",
      "epoch:6 step:5310[D loss: 0.454748, acc: 57.03%, op_acc: 29.69%] [G loss: 0.880440]\n",
      "epoch:6 step:5311[D loss: 0.436989, acc: 62.50%, op_acc: 33.59%] [G loss: 0.819950]\n",
      "epoch:6 step:5312[D loss: 0.429071, acc: 57.81%, op_acc: 39.84%] [G loss: 0.963275]\n",
      "epoch:6 step:5313[D loss: 0.433569, acc: 60.94%, op_acc: 35.16%] [G loss: 0.979421]\n",
      "epoch:6 step:5314[D loss: 0.457104, acc: 60.16%, op_acc: 29.69%] [G loss: 1.028853]\n",
      "epoch:6 step:5315[D loss: 0.496168, acc: 49.22%, op_acc: 28.12%] [G loss: 0.808536]\n",
      "epoch:6 step:5316[D loss: 0.464368, acc: 55.47%, op_acc: 22.66%] [G loss: 0.975435]\n",
      "epoch:6 step:5317[D loss: 0.433517, acc: 65.62%, op_acc: 35.16%] [G loss: 0.908550]\n",
      "epoch:6 step:5318[D loss: 0.467804, acc: 56.25%, op_acc: 28.12%] [G loss: 0.876302]\n",
      "epoch:6 step:5319[D loss: 0.459031, acc: 62.50%, op_acc: 25.78%] [G loss: 0.833465]\n",
      "epoch:6 step:5320[D loss: 0.455105, acc: 55.47%, op_acc: 35.16%] [G loss: 0.915473]\n",
      "epoch:6 step:5321[D loss: 0.476961, acc: 53.91%, op_acc: 32.03%] [G loss: 0.911175]\n",
      "epoch:6 step:5322[D loss: 0.439804, acc: 57.03%, op_acc: 31.25%] [G loss: 0.884754]\n",
      "epoch:6 step:5323[D loss: 0.464288, acc: 57.03%, op_acc: 35.16%] [G loss: 0.927805]\n",
      "epoch:6 step:5324[D loss: 0.450161, acc: 60.94%, op_acc: 39.84%] [G loss: 1.026456]\n",
      "epoch:6 step:5325[D loss: 0.437326, acc: 62.50%, op_acc: 32.03%] [G loss: 0.927941]\n",
      "epoch:6 step:5326[D loss: 0.488989, acc: 55.47%, op_acc: 28.91%] [G loss: 0.925089]\n",
      "epoch:6 step:5327[D loss: 0.432310, acc: 64.06%, op_acc: 28.91%] [G loss: 0.952351]\n",
      "epoch:6 step:5328[D loss: 0.456141, acc: 59.38%, op_acc: 33.59%] [G loss: 0.993160]\n",
      "epoch:6 step:5329[D loss: 0.464405, acc: 60.94%, op_acc: 30.47%] [G loss: 1.004106]\n",
      "epoch:6 step:5330[D loss: 0.454291, acc: 61.72%, op_acc: 35.16%] [G loss: 0.884016]\n",
      "epoch:6 step:5331[D loss: 0.462366, acc: 56.25%, op_acc: 32.03%] [G loss: 0.843311]\n",
      "epoch:6 step:5332[D loss: 0.452370, acc: 62.50%, op_acc: 31.25%] [G loss: 0.894429]\n",
      "epoch:6 step:5333[D loss: 0.452775, acc: 51.56%, op_acc: 32.81%] [G loss: 0.889790]\n",
      "epoch:6 step:5334[D loss: 0.468943, acc: 54.69%, op_acc: 27.34%] [G loss: 0.827418]\n",
      "epoch:6 step:5335[D loss: 0.442704, acc: 58.59%, op_acc: 34.38%] [G loss: 0.944605]\n",
      "epoch:6 step:5336[D loss: 0.461393, acc: 62.50%, op_acc: 29.69%] [G loss: 0.943111]\n",
      "epoch:6 step:5337[D loss: 0.477532, acc: 53.12%, op_acc: 27.34%] [G loss: 0.848179]\n",
      "epoch:6 step:5338[D loss: 0.441186, acc: 60.94%, op_acc: 32.81%] [G loss: 0.860645]\n",
      "epoch:6 step:5339[D loss: 0.447180, acc: 53.12%, op_acc: 32.81%] [G loss: 0.863415]\n",
      "epoch:6 step:5340[D loss: 0.427385, acc: 63.28%, op_acc: 32.03%] [G loss: 0.899295]\n",
      "epoch:6 step:5341[D loss: 0.433461, acc: 60.94%, op_acc: 29.69%] [G loss: 0.895752]\n",
      "epoch:6 step:5342[D loss: 0.448132, acc: 63.28%, op_acc: 32.81%] [G loss: 0.915455]\n",
      "epoch:6 step:5343[D loss: 0.458867, acc: 53.12%, op_acc: 32.03%] [G loss: 0.886464]\n",
      "epoch:6 step:5344[D loss: 0.428725, acc: 65.62%, op_acc: 32.81%] [G loss: 0.862119]\n",
      "epoch:6 step:5345[D loss: 0.441858, acc: 63.28%, op_acc: 28.12%] [G loss: 0.946228]\n",
      "epoch:6 step:5346[D loss: 0.428302, acc: 65.62%, op_acc: 33.59%] [G loss: 0.919432]\n",
      "epoch:6 step:5347[D loss: 0.455497, acc: 60.94%, op_acc: 34.38%] [G loss: 0.899283]\n",
      "epoch:6 step:5348[D loss: 0.441073, acc: 57.81%, op_acc: 36.72%] [G loss: 0.955124]\n",
      "epoch:6 step:5349[D loss: 0.410631, acc: 60.94%, op_acc: 37.50%] [G loss: 0.974246]\n",
      "epoch:6 step:5350[D loss: 0.440851, acc: 54.69%, op_acc: 34.38%] [G loss: 0.890211]\n",
      "##############\n",
      "[0.84721466 0.85364217 0.80016034 0.78275795 0.76555036 0.82885212\n",
      " 0.89853876 0.81097746 0.80234554 0.86068223]\n",
      "##########\n",
      "epoch:6 step:5351[D loss: 0.460786, acc: 64.84%, op_acc: 28.12%] [G loss: 0.909038]\n",
      "epoch:6 step:5352[D loss: 0.460481, acc: 61.72%, op_acc: 24.22%] [G loss: 0.898908]\n",
      "epoch:6 step:5353[D loss: 0.424951, acc: 68.75%, op_acc: 32.81%] [G loss: 0.862839]\n",
      "epoch:6 step:5354[D loss: 0.473180, acc: 55.47%, op_acc: 30.47%] [G loss: 0.915744]\n",
      "epoch:6 step:5355[D loss: 0.464702, acc: 51.56%, op_acc: 28.91%] [G loss: 0.816514]\n",
      "epoch:6 step:5356[D loss: 0.402288, acc: 71.09%, op_acc: 38.28%] [G loss: 0.914233]\n",
      "epoch:6 step:5357[D loss: 0.476869, acc: 56.25%, op_acc: 25.00%] [G loss: 0.862516]\n",
      "epoch:6 step:5358[D loss: 0.467875, acc: 60.94%, op_acc: 28.12%] [G loss: 0.900330]\n",
      "epoch:6 step:5359[D loss: 0.472421, acc: 55.47%, op_acc: 31.25%] [G loss: 0.848621]\n",
      "epoch:6 step:5360[D loss: 0.455747, acc: 50.78%, op_acc: 39.06%] [G loss: 0.929001]\n",
      "epoch:6 step:5361[D loss: 0.456977, acc: 55.47%, op_acc: 33.59%] [G loss: 0.765720]\n",
      "epoch:6 step:5362[D loss: 0.462106, acc: 61.72%, op_acc: 29.69%] [G loss: 0.951412]\n",
      "epoch:6 step:5363[D loss: 0.461897, acc: 61.72%, op_acc: 31.25%] [G loss: 0.825308]\n",
      "epoch:6 step:5364[D loss: 0.417667, acc: 64.06%, op_acc: 37.50%] [G loss: 0.895339]\n",
      "epoch:6 step:5365[D loss: 0.439712, acc: 63.28%, op_acc: 40.62%] [G loss: 0.921312]\n",
      "epoch:6 step:5366[D loss: 0.456221, acc: 61.72%, op_acc: 29.69%] [G loss: 0.894911]\n",
      "epoch:6 step:5367[D loss: 0.459951, acc: 64.84%, op_acc: 26.56%] [G loss: 0.887760]\n",
      "epoch:6 step:5368[D loss: 0.430689, acc: 59.38%, op_acc: 42.97%] [G loss: 0.934060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5369[D loss: 0.488244, acc: 53.91%, op_acc: 32.03%] [G loss: 0.871499]\n",
      "epoch:6 step:5370[D loss: 0.425453, acc: 67.97%, op_acc: 34.38%] [G loss: 0.942439]\n",
      "epoch:6 step:5371[D loss: 0.469304, acc: 50.00%, op_acc: 33.59%] [G loss: 0.898457]\n",
      "epoch:6 step:5372[D loss: 0.465664, acc: 61.72%, op_acc: 24.22%] [G loss: 0.961035]\n",
      "epoch:6 step:5373[D loss: 0.481526, acc: 53.12%, op_acc: 32.03%] [G loss: 0.879497]\n",
      "epoch:6 step:5374[D loss: 0.423297, acc: 67.19%, op_acc: 37.50%] [G loss: 0.876337]\n",
      "epoch:6 step:5375[D loss: 0.474303, acc: 46.88%, op_acc: 30.47%] [G loss: 0.892047]\n",
      "epoch:6 step:5376[D loss: 0.422438, acc: 67.19%, op_acc: 37.50%] [G loss: 0.914128]\n",
      "epoch:6 step:5377[D loss: 0.449894, acc: 59.38%, op_acc: 32.03%] [G loss: 0.926738]\n",
      "epoch:6 step:5378[D loss: 0.466613, acc: 66.41%, op_acc: 32.03%] [G loss: 0.997790]\n",
      "epoch:6 step:5379[D loss: 0.421535, acc: 64.06%, op_acc: 35.16%] [G loss: 1.052026]\n",
      "epoch:6 step:5380[D loss: 0.450760, acc: 64.06%, op_acc: 33.59%] [G loss: 0.900674]\n",
      "epoch:6 step:5381[D loss: 0.424237, acc: 61.72%, op_acc: 29.69%] [G loss: 1.019340]\n",
      "epoch:6 step:5382[D loss: 0.467723, acc: 54.69%, op_acc: 33.59%] [G loss: 0.876834]\n",
      "epoch:6 step:5383[D loss: 0.449503, acc: 60.94%, op_acc: 28.91%] [G loss: 0.905946]\n",
      "epoch:6 step:5384[D loss: 0.442952, acc: 59.38%, op_acc: 32.03%] [G loss: 0.942659]\n",
      "epoch:6 step:5385[D loss: 0.418559, acc: 63.28%, op_acc: 35.94%] [G loss: 0.856679]\n",
      "epoch:6 step:5386[D loss: 0.466459, acc: 61.72%, op_acc: 32.03%] [G loss: 0.794068]\n",
      "epoch:6 step:5387[D loss: 0.457705, acc: 60.16%, op_acc: 32.03%] [G loss: 0.786522]\n",
      "epoch:6 step:5388[D loss: 0.465271, acc: 53.91%, op_acc: 32.03%] [G loss: 0.846646]\n",
      "epoch:6 step:5389[D loss: 0.449649, acc: 57.03%, op_acc: 35.16%] [G loss: 0.911715]\n",
      "epoch:6 step:5390[D loss: 0.445137, acc: 57.03%, op_acc: 41.41%] [G loss: 0.843055]\n",
      "epoch:6 step:5391[D loss: 0.469350, acc: 61.72%, op_acc: 31.25%] [G loss: 0.974240]\n",
      "epoch:6 step:5392[D loss: 0.445454, acc: 63.28%, op_acc: 34.38%] [G loss: 0.936665]\n",
      "epoch:6 step:5393[D loss: 0.470306, acc: 60.94%, op_acc: 22.66%] [G loss: 0.961004]\n",
      "epoch:6 step:5394[D loss: 0.463800, acc: 57.81%, op_acc: 32.03%] [G loss: 0.906627]\n",
      "epoch:6 step:5395[D loss: 0.459245, acc: 57.81%, op_acc: 31.25%] [G loss: 0.892256]\n",
      "epoch:6 step:5396[D loss: 0.415876, acc: 60.94%, op_acc: 42.19%] [G loss: 0.859940]\n",
      "epoch:6 step:5397[D loss: 0.429729, acc: 68.75%, op_acc: 30.47%] [G loss: 0.915509]\n",
      "epoch:6 step:5398[D loss: 0.439191, acc: 60.16%, op_acc: 35.94%] [G loss: 0.950915]\n",
      "epoch:6 step:5399[D loss: 0.464156, acc: 53.91%, op_acc: 30.47%] [G loss: 0.910682]\n",
      "epoch:6 step:5400[D loss: 0.456724, acc: 59.38%, op_acc: 30.47%] [G loss: 0.896327]\n",
      "##############\n",
      "[0.86495136 0.89219794 0.81681948 0.80601812 0.79003507 0.81073765\n",
      " 0.87775874 0.84465919 0.80577122 0.83520838]\n",
      "##########\n",
      "epoch:6 step:5401[D loss: 0.425399, acc: 65.62%, op_acc: 35.94%] [G loss: 0.911338]\n",
      "epoch:6 step:5402[D loss: 0.493397, acc: 52.34%, op_acc: 31.25%] [G loss: 0.880784]\n",
      "epoch:6 step:5403[D loss: 0.459900, acc: 59.38%, op_acc: 35.16%] [G loss: 0.937239]\n",
      "epoch:6 step:5404[D loss: 0.502438, acc: 46.09%, op_acc: 32.03%] [G loss: 1.002758]\n",
      "epoch:6 step:5405[D loss: 0.444197, acc: 60.16%, op_acc: 34.38%] [G loss: 0.899990]\n",
      "epoch:6 step:5406[D loss: 0.439111, acc: 67.19%, op_acc: 33.59%] [G loss: 0.939791]\n",
      "epoch:6 step:5407[D loss: 0.452713, acc: 58.59%, op_acc: 32.81%] [G loss: 0.895459]\n",
      "epoch:6 step:5408[D loss: 0.434465, acc: 60.94%, op_acc: 32.03%] [G loss: 0.897528]\n",
      "epoch:6 step:5409[D loss: 0.437901, acc: 63.28%, op_acc: 26.56%] [G loss: 0.897950]\n",
      "epoch:6 step:5410[D loss: 0.478396, acc: 60.94%, op_acc: 25.00%] [G loss: 0.869840]\n",
      "epoch:6 step:5411[D loss: 0.415242, acc: 66.41%, op_acc: 35.94%] [G loss: 0.880661]\n",
      "epoch:6 step:5412[D loss: 0.456464, acc: 57.81%, op_acc: 31.25%] [G loss: 0.955978]\n",
      "epoch:6 step:5413[D loss: 0.453065, acc: 62.50%, op_acc: 30.47%] [G loss: 0.883163]\n",
      "epoch:6 step:5414[D loss: 0.455517, acc: 60.94%, op_acc: 33.59%] [G loss: 0.908882]\n",
      "epoch:6 step:5415[D loss: 0.448870, acc: 61.72%, op_acc: 29.69%] [G loss: 0.854371]\n",
      "epoch:6 step:5416[D loss: 0.437687, acc: 55.47%, op_acc: 30.47%] [G loss: 0.873328]\n",
      "epoch:6 step:5417[D loss: 0.432785, acc: 57.03%, op_acc: 35.16%] [G loss: 0.914708]\n",
      "epoch:6 step:5418[D loss: 0.477516, acc: 49.22%, op_acc: 29.69%] [G loss: 0.917433]\n",
      "epoch:6 step:5419[D loss: 0.433294, acc: 67.97%, op_acc: 32.03%] [G loss: 0.935688]\n",
      "epoch:6 step:5420[D loss: 0.479548, acc: 50.78%, op_acc: 31.25%] [G loss: 0.897077]\n",
      "epoch:6 step:5421[D loss: 0.444630, acc: 62.50%, op_acc: 27.34%] [G loss: 0.909218]\n",
      "epoch:6 step:5422[D loss: 0.479553, acc: 55.47%, op_acc: 30.47%] [G loss: 0.856118]\n",
      "epoch:6 step:5423[D loss: 0.432398, acc: 59.38%, op_acc: 38.28%] [G loss: 0.936980]\n",
      "epoch:6 step:5424[D loss: 0.459229, acc: 60.16%, op_acc: 32.03%] [G loss: 0.882879]\n",
      "epoch:6 step:5425[D loss: 0.437551, acc: 60.16%, op_acc: 35.16%] [G loss: 0.910544]\n",
      "epoch:6 step:5426[D loss: 0.436259, acc: 64.84%, op_acc: 35.94%] [G loss: 0.906181]\n",
      "epoch:6 step:5427[D loss: 0.413695, acc: 66.41%, op_acc: 37.50%] [G loss: 0.939209]\n",
      "epoch:6 step:5428[D loss: 0.449292, acc: 58.59%, op_acc: 29.69%] [G loss: 0.805800]\n",
      "epoch:6 step:5429[D loss: 0.446003, acc: 60.16%, op_acc: 33.59%] [G loss: 0.973983]\n",
      "epoch:6 step:5430[D loss: 0.448069, acc: 53.12%, op_acc: 33.59%] [G loss: 0.899149]\n",
      "epoch:6 step:5431[D loss: 0.420861, acc: 64.84%, op_acc: 30.47%] [G loss: 0.863474]\n",
      "epoch:6 step:5432[D loss: 0.444495, acc: 65.62%, op_acc: 28.91%] [G loss: 1.008157]\n",
      "epoch:6 step:5433[D loss: 0.458452, acc: 54.69%, op_acc: 32.03%] [G loss: 0.888541]\n",
      "epoch:6 step:5434[D loss: 0.443337, acc: 61.72%, op_acc: 31.25%] [G loss: 0.892863]\n",
      "epoch:6 step:5435[D loss: 0.456678, acc: 61.72%, op_acc: 28.91%] [G loss: 0.874871]\n",
      "epoch:6 step:5436[D loss: 0.455621, acc: 55.47%, op_acc: 37.50%] [G loss: 1.006180]\n",
      "epoch:6 step:5437[D loss: 0.469445, acc: 62.50%, op_acc: 29.69%] [G loss: 0.924008]\n",
      "epoch:6 step:5438[D loss: 0.449865, acc: 61.72%, op_acc: 32.03%] [G loss: 0.860826]\n",
      "epoch:6 step:5439[D loss: 0.444023, acc: 56.25%, op_acc: 36.72%] [G loss: 0.958486]\n",
      "epoch:6 step:5440[D loss: 0.424832, acc: 64.06%, op_acc: 35.94%] [G loss: 0.877645]\n",
      "epoch:6 step:5441[D loss: 0.429163, acc: 61.72%, op_acc: 38.28%] [G loss: 0.925640]\n",
      "epoch:6 step:5442[D loss: 0.438486, acc: 60.16%, op_acc: 38.28%] [G loss: 0.926497]\n",
      "epoch:6 step:5443[D loss: 0.414845, acc: 68.75%, op_acc: 38.28%] [G loss: 0.905735]\n",
      "epoch:6 step:5444[D loss: 0.438485, acc: 63.28%, op_acc: 34.38%] [G loss: 0.837161]\n",
      "epoch:6 step:5445[D loss: 0.461163, acc: 57.03%, op_acc: 33.59%] [G loss: 0.851348]\n",
      "epoch:6 step:5446[D loss: 0.441184, acc: 56.25%, op_acc: 35.16%] [G loss: 0.924487]\n",
      "epoch:6 step:5447[D loss: 0.434341, acc: 62.50%, op_acc: 34.38%] [G loss: 0.911568]\n",
      "epoch:6 step:5448[D loss: 0.484713, acc: 44.53%, op_acc: 32.03%] [G loss: 0.924709]\n",
      "epoch:6 step:5449[D loss: 0.473200, acc: 53.12%, op_acc: 32.03%] [G loss: 0.795954]\n",
      "epoch:6 step:5450[D loss: 0.429595, acc: 57.03%, op_acc: 38.28%] [G loss: 0.950087]\n",
      "##############\n",
      "[0.85834789 0.86134235 0.80166367 0.80492976 0.79134551 0.81731572\n",
      " 0.86234052 0.83027497 0.81965706 0.83360786]\n",
      "##########\n",
      "epoch:6 step:5451[D loss: 0.452213, acc: 53.12%, op_acc: 34.38%] [G loss: 0.849750]\n",
      "epoch:6 step:5452[D loss: 0.493418, acc: 53.91%, op_acc: 29.69%] [G loss: 0.775446]\n",
      "epoch:6 step:5453[D loss: 0.432362, acc: 57.81%, op_acc: 36.72%] [G loss: 0.919602]\n",
      "epoch:6 step:5454[D loss: 0.468707, acc: 57.03%, op_acc: 30.47%] [G loss: 0.825505]\n",
      "epoch:6 step:5455[D loss: 0.426985, acc: 64.84%, op_acc: 34.38%] [G loss: 0.814694]\n",
      "epoch:6 step:5456[D loss: 0.437050, acc: 60.16%, op_acc: 39.06%] [G loss: 0.958824]\n",
      "epoch:6 step:5457[D loss: 0.463671, acc: 63.28%, op_acc: 30.47%] [G loss: 0.987268]\n",
      "epoch:6 step:5458[D loss: 0.443127, acc: 70.31%, op_acc: 28.91%] [G loss: 0.986941]\n",
      "epoch:6 step:5459[D loss: 0.471904, acc: 53.91%, op_acc: 32.03%] [G loss: 0.925350]\n",
      "epoch:6 step:5460[D loss: 0.414239, acc: 61.72%, op_acc: 39.06%] [G loss: 0.873534]\n",
      "epoch:6 step:5461[D loss: 0.448289, acc: 60.16%, op_acc: 35.16%] [G loss: 0.929104]\n",
      "epoch:6 step:5462[D loss: 0.435029, acc: 68.75%, op_acc: 34.38%] [G loss: 0.838225]\n",
      "epoch:6 step:5463[D loss: 0.479298, acc: 59.38%, op_acc: 26.56%] [G loss: 0.885553]\n",
      "epoch:6 step:5464[D loss: 0.439582, acc: 60.94%, op_acc: 42.19%] [G loss: 0.882480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5465[D loss: 0.437230, acc: 57.81%, op_acc: 36.72%] [G loss: 0.878482]\n",
      "epoch:6 step:5466[D loss: 0.431290, acc: 59.38%, op_acc: 35.94%] [G loss: 0.833902]\n",
      "epoch:6 step:5467[D loss: 0.444930, acc: 64.06%, op_acc: 32.81%] [G loss: 0.869800]\n",
      "epoch:7 step:5468[D loss: 0.469082, acc: 49.22%, op_acc: 36.72%] [G loss: 1.029347]\n",
      "epoch:7 step:5469[D loss: 0.435339, acc: 64.06%, op_acc: 35.16%] [G loss: 0.941170]\n",
      "epoch:7 step:5470[D loss: 0.493194, acc: 53.91%, op_acc: 32.03%] [G loss: 0.959886]\n",
      "epoch:7 step:5471[D loss: 0.435355, acc: 64.06%, op_acc: 40.62%] [G loss: 0.917389]\n",
      "epoch:7 step:5472[D loss: 0.444960, acc: 62.50%, op_acc: 32.03%] [G loss: 0.861198]\n",
      "epoch:7 step:5473[D loss: 0.451253, acc: 55.47%, op_acc: 28.12%] [G loss: 0.834258]\n",
      "epoch:7 step:5474[D loss: 0.441601, acc: 63.28%, op_acc: 36.72%] [G loss: 0.909091]\n",
      "epoch:7 step:5475[D loss: 0.474991, acc: 47.66%, op_acc: 31.25%] [G loss: 0.856870]\n",
      "epoch:7 step:5476[D loss: 0.406811, acc: 67.97%, op_acc: 36.72%] [G loss: 0.854818]\n",
      "epoch:7 step:5477[D loss: 0.481465, acc: 50.00%, op_acc: 33.59%] [G loss: 0.891979]\n",
      "epoch:7 step:5478[D loss: 0.469634, acc: 57.81%, op_acc: 28.12%] [G loss: 0.886640]\n",
      "epoch:7 step:5479[D loss: 0.460739, acc: 57.81%, op_acc: 32.03%] [G loss: 0.962850]\n",
      "epoch:7 step:5480[D loss: 0.437259, acc: 62.50%, op_acc: 34.38%] [G loss: 0.904735]\n",
      "epoch:7 step:5481[D loss: 0.481819, acc: 58.59%, op_acc: 26.56%] [G loss: 0.842156]\n",
      "epoch:7 step:5482[D loss: 0.426713, acc: 59.38%, op_acc: 35.16%] [G loss: 0.888416]\n",
      "epoch:7 step:5483[D loss: 0.449155, acc: 60.16%, op_acc: 38.28%] [G loss: 0.926836]\n",
      "epoch:7 step:5484[D loss: 0.417960, acc: 62.50%, op_acc: 33.59%] [G loss: 0.937596]\n",
      "epoch:7 step:5485[D loss: 0.434014, acc: 62.50%, op_acc: 33.59%] [G loss: 0.855443]\n",
      "epoch:7 step:5486[D loss: 0.425627, acc: 62.50%, op_acc: 44.53%] [G loss: 0.977649]\n",
      "epoch:7 step:5487[D loss: 0.432182, acc: 60.16%, op_acc: 32.03%] [G loss: 0.844791]\n",
      "epoch:7 step:5488[D loss: 0.459329, acc: 57.03%, op_acc: 30.47%] [G loss: 0.910553]\n",
      "epoch:7 step:5489[D loss: 0.431571, acc: 61.72%, op_acc: 40.62%] [G loss: 0.896102]\n",
      "epoch:7 step:5490[D loss: 0.450163, acc: 59.38%, op_acc: 34.38%] [G loss: 0.842475]\n",
      "epoch:7 step:5491[D loss: 0.444542, acc: 60.94%, op_acc: 34.38%] [G loss: 0.925872]\n",
      "epoch:7 step:5492[D loss: 0.481311, acc: 51.56%, op_acc: 31.25%] [G loss: 0.842288]\n",
      "epoch:7 step:5493[D loss: 0.425770, acc: 60.94%, op_acc: 35.94%] [G loss: 0.839965]\n",
      "epoch:7 step:5494[D loss: 0.461430, acc: 57.81%, op_acc: 32.81%] [G loss: 0.893663]\n",
      "epoch:7 step:5495[D loss: 0.438935, acc: 59.38%, op_acc: 32.81%] [G loss: 0.922248]\n",
      "epoch:7 step:5496[D loss: 0.430106, acc: 62.50%, op_acc: 34.38%] [G loss: 0.865662]\n",
      "epoch:7 step:5497[D loss: 0.409031, acc: 63.28%, op_acc: 35.94%] [G loss: 0.888909]\n",
      "epoch:7 step:5498[D loss: 0.452182, acc: 57.81%, op_acc: 32.03%] [G loss: 0.931456]\n",
      "epoch:7 step:5499[D loss: 0.448348, acc: 65.62%, op_acc: 32.03%] [G loss: 0.914746]\n",
      "epoch:7 step:5500[D loss: 0.408902, acc: 66.41%, op_acc: 39.84%] [G loss: 0.915153]\n",
      "##############\n",
      "[0.86979785 0.84999411 0.80914944 0.8170611  0.81807997 0.81248761\n",
      " 0.87538007 0.82710734 0.8103007  0.83703261]\n",
      "##########\n",
      "epoch:7 step:5501[D loss: 0.434848, acc: 60.16%, op_acc: 39.06%] [G loss: 0.899853]\n",
      "epoch:7 step:5502[D loss: 0.418574, acc: 67.19%, op_acc: 35.16%] [G loss: 0.884377]\n",
      "epoch:7 step:5503[D loss: 0.449144, acc: 57.81%, op_acc: 34.38%] [G loss: 0.891027]\n",
      "epoch:7 step:5504[D loss: 0.429897, acc: 65.62%, op_acc: 36.72%] [G loss: 0.981957]\n",
      "epoch:7 step:5505[D loss: 0.483173, acc: 46.09%, op_acc: 32.03%] [G loss: 0.858767]\n",
      "epoch:7 step:5506[D loss: 0.417616, acc: 64.84%, op_acc: 33.59%] [G loss: 0.907624]\n",
      "epoch:7 step:5507[D loss: 0.511647, acc: 43.75%, op_acc: 34.38%] [G loss: 0.864317]\n",
      "epoch:7 step:5508[D loss: 0.446195, acc: 61.72%, op_acc: 33.59%] [G loss: 0.895196]\n",
      "epoch:7 step:5509[D loss: 0.430670, acc: 58.59%, op_acc: 34.38%] [G loss: 0.938880]\n",
      "epoch:7 step:5510[D loss: 0.471988, acc: 53.12%, op_acc: 28.12%] [G loss: 0.839667]\n",
      "epoch:7 step:5511[D loss: 0.463434, acc: 58.59%, op_acc: 35.16%] [G loss: 0.916214]\n",
      "epoch:7 step:5512[D loss: 0.409295, acc: 67.19%, op_acc: 34.38%] [G loss: 0.983445]\n",
      "epoch:7 step:5513[D loss: 0.441871, acc: 60.94%, op_acc: 38.28%] [G loss: 0.960163]\n",
      "epoch:7 step:5514[D loss: 0.457112, acc: 59.38%, op_acc: 27.34%] [G loss: 0.890456]\n",
      "epoch:7 step:5515[D loss: 0.453832, acc: 64.84%, op_acc: 31.25%] [G loss: 0.926534]\n",
      "epoch:7 step:5516[D loss: 0.423590, acc: 68.75%, op_acc: 32.03%] [G loss: 0.958139]\n",
      "epoch:7 step:5517[D loss: 0.441363, acc: 60.94%, op_acc: 32.03%] [G loss: 0.911722]\n",
      "epoch:7 step:5518[D loss: 0.436082, acc: 61.72%, op_acc: 35.94%] [G loss: 0.866662]\n",
      "epoch:7 step:5519[D loss: 0.473228, acc: 57.03%, op_acc: 25.00%] [G loss: 0.937868]\n",
      "epoch:7 step:5520[D loss: 0.482564, acc: 50.78%, op_acc: 30.47%] [G loss: 0.922252]\n",
      "epoch:7 step:5521[D loss: 0.462799, acc: 56.25%, op_acc: 40.62%] [G loss: 0.908901]\n",
      "epoch:7 step:5522[D loss: 0.436002, acc: 58.59%, op_acc: 33.59%] [G loss: 0.949548]\n",
      "epoch:7 step:5523[D loss: 0.433244, acc: 58.59%, op_acc: 35.16%] [G loss: 0.914014]\n",
      "epoch:7 step:5524[D loss: 0.469338, acc: 53.91%, op_acc: 30.47%] [G loss: 0.978539]\n",
      "epoch:7 step:5525[D loss: 0.420039, acc: 58.59%, op_acc: 35.16%] [G loss: 0.905234]\n",
      "epoch:7 step:5526[D loss: 0.416459, acc: 60.16%, op_acc: 36.72%] [G loss: 0.915701]\n",
      "epoch:7 step:5527[D loss: 0.461126, acc: 46.88%, op_acc: 35.16%] [G loss: 0.913826]\n",
      "epoch:7 step:5528[D loss: 0.455008, acc: 61.72%, op_acc: 29.69%] [G loss: 0.895906]\n",
      "epoch:7 step:5529[D loss: 0.480871, acc: 53.12%, op_acc: 33.59%] [G loss: 0.919489]\n",
      "epoch:7 step:5530[D loss: 0.434236, acc: 66.41%, op_acc: 28.91%] [G loss: 0.932983]\n",
      "epoch:7 step:5531[D loss: 0.441515, acc: 57.03%, op_acc: 34.38%] [G loss: 0.958044]\n",
      "epoch:7 step:5532[D loss: 0.434193, acc: 64.06%, op_acc: 35.16%] [G loss: 0.903260]\n",
      "epoch:7 step:5533[D loss: 0.425740, acc: 64.84%, op_acc: 32.81%] [G loss: 0.938637]\n",
      "epoch:7 step:5534[D loss: 0.434853, acc: 62.50%, op_acc: 30.47%] [G loss: 0.944044]\n",
      "epoch:7 step:5535[D loss: 0.450477, acc: 60.94%, op_acc: 34.38%] [G loss: 0.914612]\n",
      "epoch:7 step:5536[D loss: 0.395780, acc: 64.06%, op_acc: 40.62%] [G loss: 0.921638]\n",
      "epoch:7 step:5537[D loss: 0.432592, acc: 66.41%, op_acc: 30.47%] [G loss: 0.881175]\n",
      "epoch:7 step:5538[D loss: 0.479433, acc: 57.81%, op_acc: 28.91%] [G loss: 0.881842]\n",
      "epoch:7 step:5539[D loss: 0.430552, acc: 60.94%, op_acc: 32.81%] [G loss: 0.906208]\n",
      "epoch:7 step:5540[D loss: 0.406148, acc: 67.97%, op_acc: 39.06%] [G loss: 0.815613]\n",
      "epoch:7 step:5541[D loss: 0.413569, acc: 60.94%, op_acc: 39.06%] [G loss: 0.903951]\n",
      "epoch:7 step:5542[D loss: 0.435114, acc: 58.59%, op_acc: 37.50%] [G loss: 0.891802]\n",
      "epoch:7 step:5543[D loss: 0.481633, acc: 49.22%, op_acc: 32.81%] [G loss: 0.867299]\n",
      "epoch:7 step:5544[D loss: 0.443009, acc: 57.81%, op_acc: 32.03%] [G loss: 0.884753]\n",
      "epoch:7 step:5545[D loss: 0.473504, acc: 56.25%, op_acc: 28.91%] [G loss: 0.838540]\n",
      "epoch:7 step:5546[D loss: 0.454446, acc: 63.28%, op_acc: 31.25%] [G loss: 0.857793]\n",
      "epoch:7 step:5547[D loss: 0.456102, acc: 60.16%, op_acc: 28.12%] [G loss: 0.835788]\n",
      "epoch:7 step:5548[D loss: 0.452294, acc: 57.03%, op_acc: 32.81%] [G loss: 0.945906]\n",
      "epoch:7 step:5549[D loss: 0.440076, acc: 60.16%, op_acc: 37.50%] [G loss: 0.868273]\n",
      "epoch:7 step:5550[D loss: 0.467729, acc: 56.25%, op_acc: 29.69%] [G loss: 0.907234]\n",
      "##############\n",
      "[0.85310515 0.8572895  0.80754448 0.79993372 0.78263463 0.8280682\n",
      " 0.88775294 0.81759925 0.82112678 0.83948304]\n",
      "##########\n",
      "epoch:7 step:5551[D loss: 0.447058, acc: 58.59%, op_acc: 35.94%] [G loss: 0.937255]\n",
      "epoch:7 step:5552[D loss: 0.474303, acc: 57.81%, op_acc: 25.00%] [G loss: 0.874399]\n",
      "epoch:7 step:5553[D loss: 0.449578, acc: 57.81%, op_acc: 32.81%] [G loss: 0.899530]\n",
      "epoch:7 step:5554[D loss: 0.439997, acc: 58.59%, op_acc: 38.28%] [G loss: 0.911934]\n",
      "epoch:7 step:5555[D loss: 0.441112, acc: 58.59%, op_acc: 29.69%] [G loss: 0.853662]\n",
      "epoch:7 step:5556[D loss: 0.478137, acc: 57.03%, op_acc: 25.78%] [G loss: 0.799761]\n",
      "epoch:7 step:5557[D loss: 0.418133, acc: 66.41%, op_acc: 36.72%] [G loss: 0.957612]\n",
      "epoch:7 step:5558[D loss: 0.439188, acc: 62.50%, op_acc: 39.06%] [G loss: 0.921889]\n",
      "epoch:7 step:5559[D loss: 0.494051, acc: 52.34%, op_acc: 28.91%] [G loss: 0.894060]\n",
      "epoch:7 step:5560[D loss: 0.466669, acc: 50.00%, op_acc: 35.94%] [G loss: 0.899784]\n",
      "epoch:7 step:5561[D loss: 0.446375, acc: 52.34%, op_acc: 35.16%] [G loss: 0.953425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5562[D loss: 0.399724, acc: 67.97%, op_acc: 39.06%] [G loss: 0.987622]\n",
      "epoch:7 step:5563[D loss: 0.447757, acc: 60.16%, op_acc: 32.03%] [G loss: 0.923879]\n",
      "epoch:7 step:5564[D loss: 0.426622, acc: 58.59%, op_acc: 38.28%] [G loss: 0.883906]\n",
      "epoch:7 step:5565[D loss: 0.454392, acc: 63.28%, op_acc: 28.91%] [G loss: 0.921980]\n",
      "epoch:7 step:5566[D loss: 0.429770, acc: 64.84%, op_acc: 38.28%] [G loss: 0.969644]\n",
      "epoch:7 step:5567[D loss: 0.420766, acc: 64.06%, op_acc: 34.38%] [G loss: 0.900272]\n",
      "epoch:7 step:5568[D loss: 0.464881, acc: 53.12%, op_acc: 33.59%] [G loss: 0.891205]\n",
      "epoch:7 step:5569[D loss: 0.435726, acc: 62.50%, op_acc: 31.25%] [G loss: 0.894339]\n",
      "epoch:7 step:5570[D loss: 0.441981, acc: 55.47%, op_acc: 31.25%] [G loss: 0.937751]\n",
      "epoch:7 step:5571[D loss: 0.492435, acc: 52.34%, op_acc: 26.56%] [G loss: 0.874889]\n",
      "epoch:7 step:5572[D loss: 0.437858, acc: 59.38%, op_acc: 37.50%] [G loss: 0.838921]\n",
      "epoch:7 step:5573[D loss: 0.453974, acc: 52.34%, op_acc: 33.59%] [G loss: 0.805804]\n",
      "epoch:7 step:5574[D loss: 0.449650, acc: 55.47%, op_acc: 38.28%] [G loss: 0.934231]\n",
      "epoch:7 step:5575[D loss: 0.463774, acc: 59.38%, op_acc: 31.25%] [G loss: 0.917767]\n",
      "epoch:7 step:5576[D loss: 0.455064, acc: 56.25%, op_acc: 33.59%] [G loss: 0.888548]\n",
      "epoch:7 step:5577[D loss: 0.450730, acc: 57.03%, op_acc: 35.16%] [G loss: 0.836207]\n",
      "epoch:7 step:5578[D loss: 0.483740, acc: 60.16%, op_acc: 28.91%] [G loss: 0.861994]\n",
      "epoch:7 step:5579[D loss: 0.435976, acc: 62.50%, op_acc: 37.50%] [G loss: 0.881957]\n",
      "epoch:7 step:5580[D loss: 0.469279, acc: 51.56%, op_acc: 25.78%] [G loss: 0.862141]\n",
      "epoch:7 step:5581[D loss: 0.429465, acc: 60.16%, op_acc: 34.38%] [G loss: 0.913458]\n",
      "epoch:7 step:5582[D loss: 0.410215, acc: 61.72%, op_acc: 40.62%] [G loss: 0.948990]\n",
      "epoch:7 step:5583[D loss: 0.456786, acc: 59.38%, op_acc: 33.59%] [G loss: 0.894550]\n",
      "epoch:7 step:5584[D loss: 0.464724, acc: 50.78%, op_acc: 34.38%] [G loss: 0.783444]\n",
      "epoch:7 step:5585[D loss: 0.443942, acc: 60.16%, op_acc: 33.59%] [G loss: 0.865051]\n",
      "epoch:7 step:5586[D loss: 0.431158, acc: 63.28%, op_acc: 31.25%] [G loss: 0.877378]\n",
      "epoch:7 step:5587[D loss: 0.457043, acc: 58.59%, op_acc: 30.47%] [G loss: 0.948634]\n",
      "epoch:7 step:5588[D loss: 0.467875, acc: 57.03%, op_acc: 36.72%] [G loss: 0.865748]\n",
      "epoch:7 step:5589[D loss: 0.458450, acc: 56.25%, op_acc: 27.34%] [G loss: 0.849817]\n",
      "epoch:7 step:5590[D loss: 0.447694, acc: 54.69%, op_acc: 28.91%] [G loss: 0.906340]\n",
      "epoch:7 step:5591[D loss: 0.454926, acc: 53.91%, op_acc: 35.94%] [G loss: 0.824549]\n",
      "epoch:7 step:5592[D loss: 0.496537, acc: 53.91%, op_acc: 25.00%] [G loss: 0.914804]\n",
      "epoch:7 step:5593[D loss: 0.437747, acc: 56.25%, op_acc: 34.38%] [G loss: 0.897380]\n",
      "epoch:7 step:5594[D loss: 0.418496, acc: 69.53%, op_acc: 31.25%] [G loss: 0.912744]\n",
      "epoch:7 step:5595[D loss: 0.442254, acc: 60.16%, op_acc: 35.16%] [G loss: 0.857457]\n",
      "epoch:7 step:5596[D loss: 0.493192, acc: 57.81%, op_acc: 32.03%] [G loss: 0.869375]\n",
      "epoch:7 step:5597[D loss: 0.449074, acc: 57.03%, op_acc: 37.50%] [G loss: 0.877289]\n",
      "epoch:7 step:5598[D loss: 0.441812, acc: 66.41%, op_acc: 28.91%] [G loss: 0.942393]\n",
      "epoch:7 step:5599[D loss: 0.441383, acc: 50.78%, op_acc: 40.62%] [G loss: 0.875157]\n",
      "epoch:7 step:5600[D loss: 0.460778, acc: 60.94%, op_acc: 29.69%] [G loss: 0.952150]\n",
      "##############\n",
      "[0.85491199 0.86173154 0.81003572 0.81410832 0.80123128 0.82122042\n",
      " 0.89404758 0.83436576 0.81305864 0.8279041 ]\n",
      "##########\n",
      "epoch:7 step:5601[D loss: 0.465413, acc: 54.69%, op_acc: 33.59%] [G loss: 0.913476]\n",
      "epoch:7 step:5602[D loss: 0.469649, acc: 53.12%, op_acc: 34.38%] [G loss: 0.868133]\n",
      "epoch:7 step:5603[D loss: 0.447487, acc: 58.59%, op_acc: 35.16%] [G loss: 0.952106]\n",
      "epoch:7 step:5604[D loss: 0.432486, acc: 64.06%, op_acc: 35.94%] [G loss: 0.935276]\n",
      "epoch:7 step:5605[D loss: 0.451797, acc: 63.28%, op_acc: 25.78%] [G loss: 0.952766]\n",
      "epoch:7 step:5606[D loss: 0.413091, acc: 67.97%, op_acc: 34.38%] [G loss: 0.912928]\n",
      "epoch:7 step:5607[D loss: 0.473454, acc: 57.03%, op_acc: 33.59%] [G loss: 0.841425]\n",
      "epoch:7 step:5608[D loss: 0.471341, acc: 56.25%, op_acc: 29.69%] [G loss: 0.838991]\n",
      "epoch:7 step:5609[D loss: 0.462249, acc: 54.69%, op_acc: 29.69%] [G loss: 0.850423]\n",
      "epoch:7 step:5610[D loss: 0.480747, acc: 50.00%, op_acc: 32.03%] [G loss: 0.865419]\n",
      "epoch:7 step:5611[D loss: 0.443635, acc: 57.81%, op_acc: 33.59%] [G loss: 0.887157]\n",
      "epoch:7 step:5612[D loss: 0.463014, acc: 58.59%, op_acc: 28.12%] [G loss: 0.812102]\n",
      "epoch:7 step:5613[D loss: 0.430646, acc: 55.47%, op_acc: 32.03%] [G loss: 0.893833]\n",
      "epoch:7 step:5614[D loss: 0.440480, acc: 59.38%, op_acc: 32.03%] [G loss: 0.900472]\n",
      "epoch:7 step:5615[D loss: 0.459639, acc: 62.50%, op_acc: 30.47%] [G loss: 0.935498]\n",
      "epoch:7 step:5616[D loss: 0.446865, acc: 51.56%, op_acc: 33.59%] [G loss: 0.904013]\n",
      "epoch:7 step:5617[D loss: 0.421011, acc: 57.81%, op_acc: 35.16%] [G loss: 0.955895]\n",
      "epoch:7 step:5618[D loss: 0.458814, acc: 55.47%, op_acc: 35.16%] [G loss: 0.894679]\n",
      "epoch:7 step:5619[D loss: 0.452429, acc: 61.72%, op_acc: 33.59%] [G loss: 0.888513]\n",
      "epoch:7 step:5620[D loss: 0.443585, acc: 52.34%, op_acc: 35.16%] [G loss: 0.889735]\n",
      "epoch:7 step:5621[D loss: 0.444239, acc: 61.72%, op_acc: 31.25%] [G loss: 0.864182]\n",
      "epoch:7 step:5622[D loss: 0.437658, acc: 64.06%, op_acc: 32.03%] [G loss: 0.974472]\n",
      "epoch:7 step:5623[D loss: 0.437697, acc: 56.25%, op_acc: 33.59%] [G loss: 0.862129]\n",
      "epoch:7 step:5624[D loss: 0.430646, acc: 57.81%, op_acc: 30.47%] [G loss: 0.897755]\n",
      "epoch:7 step:5625[D loss: 0.429168, acc: 56.25%, op_acc: 39.06%] [G loss: 0.883620]\n",
      "epoch:7 step:5626[D loss: 0.445629, acc: 62.50%, op_acc: 35.94%] [G loss: 0.921261]\n",
      "epoch:7 step:5627[D loss: 0.485193, acc: 57.81%, op_acc: 25.78%] [G loss: 0.954663]\n",
      "epoch:7 step:5628[D loss: 0.464229, acc: 56.25%, op_acc: 36.72%] [G loss: 0.978838]\n",
      "epoch:7 step:5629[D loss: 0.447038, acc: 57.81%, op_acc: 39.06%] [G loss: 0.892733]\n",
      "epoch:7 step:5630[D loss: 0.485956, acc: 52.34%, op_acc: 27.34%] [G loss: 0.886739]\n",
      "epoch:7 step:5631[D loss: 0.470251, acc: 59.38%, op_acc: 29.69%] [G loss: 0.913453]\n",
      "epoch:7 step:5632[D loss: 0.425807, acc: 60.16%, op_acc: 32.81%] [G loss: 0.885124]\n",
      "epoch:7 step:5633[D loss: 0.477223, acc: 56.25%, op_acc: 35.16%] [G loss: 0.988707]\n",
      "epoch:7 step:5634[D loss: 0.409075, acc: 72.66%, op_acc: 37.50%] [G loss: 0.858163]\n",
      "epoch:7 step:5635[D loss: 0.439377, acc: 58.59%, op_acc: 37.50%] [G loss: 0.878672]\n",
      "epoch:7 step:5636[D loss: 0.449539, acc: 60.94%, op_acc: 32.81%] [G loss: 0.909671]\n",
      "epoch:7 step:5637[D loss: 0.460069, acc: 57.81%, op_acc: 32.81%] [G loss: 0.877110]\n",
      "epoch:7 step:5638[D loss: 0.470251, acc: 57.81%, op_acc: 31.25%] [G loss: 0.876883]\n",
      "epoch:7 step:5639[D loss: 0.429497, acc: 62.50%, op_acc: 33.59%] [G loss: 0.853310]\n",
      "epoch:7 step:5640[D loss: 0.457894, acc: 59.38%, op_acc: 29.69%] [G loss: 0.883883]\n",
      "epoch:7 step:5641[D loss: 0.488537, acc: 49.22%, op_acc: 29.69%] [G loss: 0.866590]\n",
      "epoch:7 step:5642[D loss: 0.421257, acc: 61.72%, op_acc: 37.50%] [G loss: 0.860137]\n",
      "epoch:7 step:5643[D loss: 0.460413, acc: 60.16%, op_acc: 34.38%] [G loss: 0.835377]\n",
      "epoch:7 step:5644[D loss: 0.454007, acc: 50.00%, op_acc: 32.81%] [G loss: 0.878264]\n",
      "epoch:7 step:5645[D loss: 0.460637, acc: 54.69%, op_acc: 29.69%] [G loss: 0.872305]\n",
      "epoch:7 step:5646[D loss: 0.437802, acc: 60.16%, op_acc: 36.72%] [G loss: 0.945395]\n",
      "epoch:7 step:5647[D loss: 0.429388, acc: 66.41%, op_acc: 32.81%] [G loss: 0.963273]\n",
      "epoch:7 step:5648[D loss: 0.405569, acc: 67.97%, op_acc: 35.94%] [G loss: 0.945420]\n",
      "epoch:7 step:5649[D loss: 0.446929, acc: 59.38%, op_acc: 31.25%] [G loss: 0.941977]\n",
      "epoch:7 step:5650[D loss: 0.422825, acc: 64.06%, op_acc: 39.84%] [G loss: 1.060210]\n",
      "##############\n",
      "[0.86444428 0.85839998 0.80605049 0.8181469  0.79493267 0.82350879\n",
      " 0.88172911 0.82795031 0.80945875 0.8534632 ]\n",
      "##########\n",
      "epoch:7 step:5651[D loss: 0.429986, acc: 62.50%, op_acc: 37.50%] [G loss: 1.020378]\n",
      "epoch:7 step:5652[D loss: 0.433018, acc: 63.28%, op_acc: 32.81%] [G loss: 0.922876]\n",
      "epoch:7 step:5653[D loss: 0.443409, acc: 55.47%, op_acc: 30.47%] [G loss: 0.879576]\n",
      "epoch:7 step:5654[D loss: 0.454918, acc: 58.59%, op_acc: 32.03%] [G loss: 0.914054]\n",
      "epoch:7 step:5655[D loss: 0.462736, acc: 53.91%, op_acc: 32.81%] [G loss: 0.916995]\n",
      "epoch:7 step:5656[D loss: 0.458633, acc: 60.16%, op_acc: 26.56%] [G loss: 0.930613]\n",
      "epoch:7 step:5657[D loss: 0.469702, acc: 62.50%, op_acc: 29.69%] [G loss: 0.961625]\n",
      "epoch:7 step:5658[D loss: 0.435335, acc: 60.94%, op_acc: 33.59%] [G loss: 0.950527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5659[D loss: 0.419072, acc: 70.31%, op_acc: 35.16%] [G loss: 0.869700]\n",
      "epoch:7 step:5660[D loss: 0.459453, acc: 53.91%, op_acc: 33.59%] [G loss: 0.887532]\n",
      "epoch:7 step:5661[D loss: 0.448875, acc: 58.59%, op_acc: 34.38%] [G loss: 0.910778]\n",
      "epoch:7 step:5662[D loss: 0.445075, acc: 57.03%, op_acc: 32.81%] [G loss: 0.829076]\n",
      "epoch:7 step:5663[D loss: 0.436261, acc: 64.06%, op_acc: 34.38%] [G loss: 0.862594]\n",
      "epoch:7 step:5664[D loss: 0.477678, acc: 57.03%, op_acc: 30.47%] [G loss: 0.838543]\n",
      "epoch:7 step:5665[D loss: 0.471243, acc: 56.25%, op_acc: 34.38%] [G loss: 0.886834]\n",
      "epoch:7 step:5666[D loss: 0.426691, acc: 60.16%, op_acc: 34.38%] [G loss: 0.945467]\n",
      "epoch:7 step:5667[D loss: 0.434578, acc: 60.16%, op_acc: 32.81%] [G loss: 0.942903]\n",
      "epoch:7 step:5668[D loss: 0.409042, acc: 65.62%, op_acc: 39.06%] [G loss: 0.930550]\n",
      "epoch:7 step:5669[D loss: 0.459779, acc: 55.47%, op_acc: 28.12%] [G loss: 0.912602]\n",
      "epoch:7 step:5670[D loss: 0.443825, acc: 63.28%, op_acc: 29.69%] [G loss: 0.987046]\n",
      "epoch:7 step:5671[D loss: 0.440788, acc: 66.41%, op_acc: 35.16%] [G loss: 0.935985]\n",
      "epoch:7 step:5672[D loss: 0.479841, acc: 53.91%, op_acc: 29.69%] [G loss: 0.861130]\n",
      "epoch:7 step:5673[D loss: 0.475680, acc: 51.56%, op_acc: 28.91%] [G loss: 0.861531]\n",
      "epoch:7 step:5674[D loss: 0.421327, acc: 59.38%, op_acc: 39.84%] [G loss: 0.815207]\n",
      "epoch:7 step:5675[D loss: 0.449529, acc: 63.28%, op_acc: 28.12%] [G loss: 0.947083]\n",
      "epoch:7 step:5676[D loss: 0.434452, acc: 63.28%, op_acc: 38.28%] [G loss: 0.966846]\n",
      "epoch:7 step:5677[D loss: 0.456793, acc: 60.94%, op_acc: 27.34%] [G loss: 0.916518]\n",
      "epoch:7 step:5678[D loss: 0.406395, acc: 62.50%, op_acc: 37.50%] [G loss: 0.872955]\n",
      "epoch:7 step:5679[D loss: 0.458187, acc: 57.81%, op_acc: 32.81%] [G loss: 0.789070]\n",
      "epoch:7 step:5680[D loss: 0.468202, acc: 47.66%, op_acc: 34.38%] [G loss: 0.795994]\n",
      "epoch:7 step:5681[D loss: 0.449743, acc: 63.28%, op_acc: 32.81%] [G loss: 0.966447]\n",
      "epoch:7 step:5682[D loss: 0.444270, acc: 67.19%, op_acc: 35.16%] [G loss: 0.889526]\n",
      "epoch:7 step:5683[D loss: 0.458214, acc: 51.56%, op_acc: 34.38%] [G loss: 0.963745]\n",
      "epoch:7 step:5684[D loss: 0.441840, acc: 57.81%, op_acc: 36.72%] [G loss: 0.838414]\n",
      "epoch:7 step:5685[D loss: 0.445364, acc: 56.25%, op_acc: 32.81%] [G loss: 0.952082]\n",
      "epoch:7 step:5686[D loss: 0.445825, acc: 60.16%, op_acc: 32.03%] [G loss: 0.953410]\n",
      "epoch:7 step:5687[D loss: 0.459799, acc: 60.94%, op_acc: 31.25%] [G loss: 0.817427]\n",
      "epoch:7 step:5688[D loss: 0.470660, acc: 54.69%, op_acc: 32.81%] [G loss: 0.880261]\n",
      "epoch:7 step:5689[D loss: 0.454104, acc: 59.38%, op_acc: 34.38%] [G loss: 0.925645]\n",
      "epoch:7 step:5690[D loss: 0.472238, acc: 50.00%, op_acc: 33.59%] [G loss: 0.885556]\n",
      "epoch:7 step:5691[D loss: 0.421562, acc: 67.19%, op_acc: 30.47%] [G loss: 0.865216]\n",
      "epoch:7 step:5692[D loss: 0.455723, acc: 60.16%, op_acc: 35.94%] [G loss: 0.916259]\n",
      "epoch:7 step:5693[D loss: 0.462070, acc: 59.38%, op_acc: 31.25%] [G loss: 0.865454]\n",
      "epoch:7 step:5694[D loss: 0.425667, acc: 65.62%, op_acc: 35.94%] [G loss: 0.906958]\n",
      "epoch:7 step:5695[D loss: 0.431633, acc: 67.19%, op_acc: 35.94%] [G loss: 0.859481]\n",
      "epoch:7 step:5696[D loss: 0.440684, acc: 62.50%, op_acc: 33.59%] [G loss: 0.918068]\n",
      "epoch:7 step:5697[D loss: 0.448180, acc: 67.97%, op_acc: 28.12%] [G loss: 0.879113]\n",
      "epoch:7 step:5698[D loss: 0.422502, acc: 63.28%, op_acc: 34.38%] [G loss: 0.894130]\n",
      "epoch:7 step:5699[D loss: 0.466390, acc: 51.56%, op_acc: 35.94%] [G loss: 0.858508]\n",
      "epoch:7 step:5700[D loss: 0.422669, acc: 71.88%, op_acc: 33.59%] [G loss: 0.898155]\n",
      "##############\n",
      "[0.85580227 0.8770645  0.80490161 0.81250048 0.80704597 0.84423558\n",
      " 0.87485223 0.83043085 0.8071755  0.83036755]\n",
      "##########\n",
      "epoch:7 step:5701[D loss: 0.480842, acc: 57.81%, op_acc: 24.22%] [G loss: 0.898693]\n",
      "epoch:7 step:5702[D loss: 0.435802, acc: 64.84%, op_acc: 35.94%] [G loss: 0.984322]\n",
      "epoch:7 step:5703[D loss: 0.490518, acc: 53.12%, op_acc: 32.81%] [G loss: 0.959727]\n",
      "epoch:7 step:5704[D loss: 0.435603, acc: 58.59%, op_acc: 36.72%] [G loss: 1.004283]\n",
      "epoch:7 step:5705[D loss: 0.476145, acc: 53.91%, op_acc: 32.03%] [G loss: 0.871230]\n",
      "epoch:7 step:5706[D loss: 0.424740, acc: 66.41%, op_acc: 33.59%] [G loss: 0.892601]\n",
      "epoch:7 step:5707[D loss: 0.437752, acc: 64.84%, op_acc: 33.59%] [G loss: 0.899309]\n",
      "epoch:7 step:5708[D loss: 0.443796, acc: 57.81%, op_acc: 39.84%] [G loss: 0.884470]\n",
      "epoch:7 step:5709[D loss: 0.418242, acc: 63.28%, op_acc: 42.19%] [G loss: 0.854623]\n",
      "epoch:7 step:5710[D loss: 0.480843, acc: 46.09%, op_acc: 33.59%] [G loss: 0.850950]\n",
      "epoch:7 step:5711[D loss: 0.461412, acc: 63.28%, op_acc: 33.59%] [G loss: 0.907850]\n",
      "epoch:7 step:5712[D loss: 0.445228, acc: 62.50%, op_acc: 36.72%] [G loss: 0.841998]\n",
      "epoch:7 step:5713[D loss: 0.470797, acc: 55.47%, op_acc: 34.38%] [G loss: 0.835989]\n",
      "epoch:7 step:5714[D loss: 0.434883, acc: 62.50%, op_acc: 35.16%] [G loss: 0.873833]\n",
      "epoch:7 step:5715[D loss: 0.453078, acc: 60.16%, op_acc: 34.38%] [G loss: 0.846430]\n",
      "epoch:7 step:5716[D loss: 0.444622, acc: 67.97%, op_acc: 29.69%] [G loss: 0.874341]\n",
      "epoch:7 step:5717[D loss: 0.451843, acc: 62.50%, op_acc: 34.38%] [G loss: 0.839528]\n",
      "epoch:7 step:5718[D loss: 0.435381, acc: 60.16%, op_acc: 34.38%] [G loss: 0.862467]\n",
      "epoch:7 step:5719[D loss: 0.407537, acc: 69.53%, op_acc: 39.84%] [G loss: 0.795368]\n",
      "epoch:7 step:5720[D loss: 0.454100, acc: 57.03%, op_acc: 29.69%] [G loss: 0.887155]\n",
      "epoch:7 step:5721[D loss: 0.446983, acc: 61.72%, op_acc: 31.25%] [G loss: 0.884726]\n",
      "epoch:7 step:5722[D loss: 0.449980, acc: 58.59%, op_acc: 32.03%] [G loss: 0.879113]\n",
      "epoch:7 step:5723[D loss: 0.455723, acc: 56.25%, op_acc: 31.25%] [G loss: 0.859339]\n",
      "epoch:7 step:5724[D loss: 0.447922, acc: 65.62%, op_acc: 27.34%] [G loss: 0.922080]\n",
      "epoch:7 step:5725[D loss: 0.436271, acc: 55.47%, op_acc: 37.50%] [G loss: 0.819841]\n",
      "epoch:7 step:5726[D loss: 0.474002, acc: 56.25%, op_acc: 28.91%] [G loss: 0.871225]\n",
      "epoch:7 step:5727[D loss: 0.445637, acc: 60.16%, op_acc: 35.16%] [G loss: 0.900529]\n",
      "epoch:7 step:5728[D loss: 0.458537, acc: 53.12%, op_acc: 38.28%] [G loss: 0.855323]\n",
      "epoch:7 step:5729[D loss: 0.417890, acc: 68.75%, op_acc: 35.94%] [G loss: 0.907930]\n",
      "epoch:7 step:5730[D loss: 0.449076, acc: 60.94%, op_acc: 34.38%] [G loss: 0.884078]\n",
      "epoch:7 step:5731[D loss: 0.438088, acc: 60.94%, op_acc: 35.94%] [G loss: 0.865952]\n",
      "epoch:7 step:5732[D loss: 0.442905, acc: 59.38%, op_acc: 35.16%] [G loss: 0.946608]\n",
      "epoch:7 step:5733[D loss: 0.429936, acc: 67.97%, op_acc: 32.81%] [G loss: 0.917027]\n",
      "epoch:7 step:5734[D loss: 0.503137, acc: 48.44%, op_acc: 33.59%] [G loss: 0.924964]\n",
      "epoch:7 step:5735[D loss: 0.438011, acc: 63.28%, op_acc: 33.59%] [G loss: 0.931572]\n",
      "epoch:7 step:5736[D loss: 0.430063, acc: 57.03%, op_acc: 40.62%] [G loss: 0.927426]\n",
      "epoch:7 step:5737[D loss: 0.445227, acc: 58.59%, op_acc: 33.59%] [G loss: 0.966380]\n",
      "epoch:7 step:5738[D loss: 0.452592, acc: 57.81%, op_acc: 34.38%] [G loss: 1.008064]\n",
      "epoch:7 step:5739[D loss: 0.452061, acc: 62.50%, op_acc: 31.25%] [G loss: 0.934985]\n",
      "epoch:7 step:5740[D loss: 0.426435, acc: 64.84%, op_acc: 37.50%] [G loss: 0.967924]\n",
      "epoch:7 step:5741[D loss: 0.450797, acc: 59.38%, op_acc: 31.25%] [G loss: 0.884293]\n",
      "epoch:7 step:5742[D loss: 0.437036, acc: 56.25%, op_acc: 32.03%] [G loss: 0.961120]\n",
      "epoch:7 step:5743[D loss: 0.459798, acc: 56.25%, op_acc: 35.16%] [G loss: 0.915664]\n",
      "epoch:7 step:5744[D loss: 0.492005, acc: 58.59%, op_acc: 29.69%] [G loss: 0.868964]\n",
      "epoch:7 step:5745[D loss: 0.438387, acc: 62.50%, op_acc: 34.38%] [G loss: 0.935189]\n",
      "epoch:7 step:5746[D loss: 0.447606, acc: 61.72%, op_acc: 38.28%] [G loss: 0.872091]\n",
      "epoch:7 step:5747[D loss: 0.434480, acc: 60.94%, op_acc: 33.59%] [G loss: 0.907153]\n",
      "epoch:7 step:5748[D loss: 0.462465, acc: 59.38%, op_acc: 31.25%] [G loss: 0.889811]\n",
      "epoch:7 step:5749[D loss: 0.449189, acc: 61.72%, op_acc: 31.25%] [G loss: 0.849000]\n",
      "epoch:7 step:5750[D loss: 0.441622, acc: 59.38%, op_acc: 34.38%] [G loss: 0.802414]\n",
      "##############\n",
      "[0.83943915 0.86068184 0.80279741 0.80964752 0.77984285 0.84068695\n",
      " 0.8889013  0.82347862 0.80057711 0.81549276]\n",
      "##########\n",
      "epoch:7 step:5751[D loss: 0.456688, acc: 59.38%, op_acc: 33.59%] [G loss: 0.791612]\n",
      "epoch:7 step:5752[D loss: 0.438351, acc: 57.03%, op_acc: 36.72%] [G loss: 0.924821]\n",
      "epoch:7 step:5753[D loss: 0.441022, acc: 65.62%, op_acc: 33.59%] [G loss: 0.900559]\n",
      "epoch:7 step:5754[D loss: 0.481298, acc: 50.78%, op_acc: 31.25%] [G loss: 0.902152]\n",
      "epoch:7 step:5755[D loss: 0.447165, acc: 56.25%, op_acc: 32.81%] [G loss: 0.904939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5756[D loss: 0.453809, acc: 60.16%, op_acc: 32.81%] [G loss: 0.854097]\n",
      "epoch:7 step:5757[D loss: 0.441572, acc: 57.03%, op_acc: 35.94%] [G loss: 0.909228]\n",
      "epoch:7 step:5758[D loss: 0.430960, acc: 58.59%, op_acc: 37.50%] [G loss: 0.894420]\n",
      "epoch:7 step:5759[D loss: 0.477196, acc: 56.25%, op_acc: 29.69%] [G loss: 0.889727]\n",
      "epoch:7 step:5760[D loss: 0.436447, acc: 63.28%, op_acc: 33.59%] [G loss: 0.843779]\n",
      "epoch:7 step:5761[D loss: 0.446311, acc: 59.38%, op_acc: 33.59%] [G loss: 0.896636]\n",
      "epoch:7 step:5762[D loss: 0.443957, acc: 60.94%, op_acc: 35.94%] [G loss: 0.886482]\n",
      "epoch:7 step:5763[D loss: 0.451414, acc: 58.59%, op_acc: 38.28%] [G loss: 0.845812]\n",
      "epoch:7 step:5764[D loss: 0.470895, acc: 54.69%, op_acc: 31.25%] [G loss: 0.904194]\n",
      "epoch:7 step:5765[D loss: 0.429890, acc: 65.62%, op_acc: 31.25%] [G loss: 0.952439]\n",
      "epoch:7 step:5766[D loss: 0.440933, acc: 63.28%, op_acc: 31.25%] [G loss: 0.859490]\n",
      "epoch:7 step:5767[D loss: 0.469999, acc: 57.03%, op_acc: 31.25%] [G loss: 0.881775]\n",
      "epoch:7 step:5768[D loss: 0.474489, acc: 51.56%, op_acc: 32.03%] [G loss: 0.807820]\n",
      "epoch:7 step:5769[D loss: 0.408198, acc: 67.19%, op_acc: 37.50%] [G loss: 0.891594]\n",
      "epoch:7 step:5770[D loss: 0.446556, acc: 61.72%, op_acc: 25.78%] [G loss: 0.887796]\n",
      "epoch:7 step:5771[D loss: 0.440000, acc: 60.94%, op_acc: 33.59%] [G loss: 0.923469]\n",
      "epoch:7 step:5772[D loss: 0.435188, acc: 58.59%, op_acc: 32.81%] [G loss: 0.894461]\n",
      "epoch:7 step:5773[D loss: 0.458405, acc: 62.50%, op_acc: 28.91%] [G loss: 0.975395]\n",
      "epoch:7 step:5774[D loss: 0.422173, acc: 63.28%, op_acc: 35.16%] [G loss: 0.901079]\n",
      "epoch:7 step:5775[D loss: 0.445655, acc: 62.50%, op_acc: 32.81%] [G loss: 0.981853]\n",
      "epoch:7 step:5776[D loss: 0.440894, acc: 63.28%, op_acc: 35.16%] [G loss: 0.975611]\n",
      "epoch:7 step:5777[D loss: 0.432713, acc: 67.19%, op_acc: 30.47%] [G loss: 0.896041]\n",
      "epoch:7 step:5778[D loss: 0.434986, acc: 64.84%, op_acc: 34.38%] [G loss: 0.910298]\n",
      "epoch:7 step:5779[D loss: 0.452720, acc: 55.47%, op_acc: 36.72%] [G loss: 0.880853]\n",
      "epoch:7 step:5780[D loss: 0.484026, acc: 51.56%, op_acc: 33.59%] [G loss: 0.882841]\n",
      "epoch:7 step:5781[D loss: 0.466062, acc: 56.25%, op_acc: 29.69%] [G loss: 0.905854]\n",
      "epoch:7 step:5782[D loss: 0.485170, acc: 54.69%, op_acc: 28.91%] [G loss: 0.826126]\n",
      "epoch:7 step:5783[D loss: 0.472031, acc: 53.91%, op_acc: 28.91%] [G loss: 0.884523]\n",
      "epoch:7 step:5784[D loss: 0.447543, acc: 59.38%, op_acc: 35.16%] [G loss: 0.830805]\n",
      "epoch:7 step:5785[D loss: 0.438799, acc: 62.50%, op_acc: 30.47%] [G loss: 0.932531]\n",
      "epoch:7 step:5786[D loss: 0.443653, acc: 61.72%, op_acc: 32.81%] [G loss: 0.864536]\n",
      "epoch:7 step:5787[D loss: 0.451974, acc: 55.47%, op_acc: 37.50%] [G loss: 0.900829]\n",
      "epoch:7 step:5788[D loss: 0.450475, acc: 57.81%, op_acc: 35.16%] [G loss: 0.910990]\n",
      "epoch:7 step:5789[D loss: 0.452892, acc: 60.16%, op_acc: 34.38%] [G loss: 0.911802]\n",
      "epoch:7 step:5790[D loss: 0.426252, acc: 60.16%, op_acc: 35.94%] [G loss: 0.849271]\n",
      "epoch:7 step:5791[D loss: 0.475064, acc: 51.56%, op_acc: 31.25%] [G loss: 0.848702]\n",
      "epoch:7 step:5792[D loss: 0.474213, acc: 49.22%, op_acc: 32.81%] [G loss: 0.858784]\n",
      "epoch:7 step:5793[D loss: 0.444120, acc: 63.28%, op_acc: 35.94%] [G loss: 0.883380]\n",
      "epoch:7 step:5794[D loss: 0.446011, acc: 55.47%, op_acc: 30.47%] [G loss: 0.928486]\n",
      "epoch:7 step:5795[D loss: 0.458386, acc: 55.47%, op_acc: 32.03%] [G loss: 0.872966]\n",
      "epoch:7 step:5796[D loss: 0.439237, acc: 63.28%, op_acc: 32.03%] [G loss: 0.827248]\n",
      "epoch:7 step:5797[D loss: 0.433794, acc: 55.47%, op_acc: 40.62%] [G loss: 0.889443]\n",
      "epoch:7 step:5798[D loss: 0.424143, acc: 58.59%, op_acc: 34.38%] [G loss: 0.937364]\n",
      "epoch:7 step:5799[D loss: 0.399097, acc: 69.53%, op_acc: 34.38%] [G loss: 0.969811]\n",
      "epoch:7 step:5800[D loss: 0.425699, acc: 65.62%, op_acc: 37.50%] [G loss: 0.916822]\n",
      "##############\n",
      "[0.86665284 0.85249933 0.79789285 0.82227565 0.81100426 0.82443112\n",
      " 0.88701783 0.8159576  0.82523611 0.81633141]\n",
      "##########\n",
      "epoch:7 step:5801[D loss: 0.470939, acc: 50.78%, op_acc: 32.81%] [G loss: 0.853648]\n",
      "epoch:7 step:5802[D loss: 0.463281, acc: 55.47%, op_acc: 32.03%] [G loss: 0.871685]\n",
      "epoch:7 step:5803[D loss: 0.484651, acc: 54.69%, op_acc: 30.47%] [G loss: 0.846645]\n",
      "epoch:7 step:5804[D loss: 0.454055, acc: 59.38%, op_acc: 32.81%] [G loss: 0.823455]\n",
      "epoch:7 step:5805[D loss: 0.441767, acc: 59.38%, op_acc: 34.38%] [G loss: 0.923726]\n",
      "epoch:7 step:5806[D loss: 0.433320, acc: 62.50%, op_acc: 35.94%] [G loss: 0.935291]\n",
      "epoch:7 step:5807[D loss: 0.440899, acc: 60.94%, op_acc: 32.81%] [G loss: 1.003381]\n",
      "epoch:7 step:5808[D loss: 0.444462, acc: 63.28%, op_acc: 38.28%] [G loss: 0.921042]\n",
      "epoch:7 step:5809[D loss: 0.469794, acc: 50.78%, op_acc: 32.03%] [G loss: 0.906847]\n",
      "epoch:7 step:5810[D loss: 0.467908, acc: 53.12%, op_acc: 32.03%] [G loss: 0.908361]\n",
      "epoch:7 step:5811[D loss: 0.436446, acc: 58.59%, op_acc: 32.81%] [G loss: 0.915141]\n",
      "epoch:7 step:5812[D loss: 0.448774, acc: 60.94%, op_acc: 29.69%] [G loss: 0.994002]\n",
      "epoch:7 step:5813[D loss: 0.438022, acc: 71.88%, op_acc: 32.81%] [G loss: 0.915267]\n",
      "epoch:7 step:5814[D loss: 0.455977, acc: 58.59%, op_acc: 38.28%] [G loss: 0.886635]\n",
      "epoch:7 step:5815[D loss: 0.421486, acc: 64.06%, op_acc: 32.81%] [G loss: 0.934078]\n",
      "epoch:7 step:5816[D loss: 0.436429, acc: 62.50%, op_acc: 39.84%] [G loss: 0.930130]\n",
      "epoch:7 step:5817[D loss: 0.438142, acc: 63.28%, op_acc: 32.81%] [G loss: 0.926176]\n",
      "epoch:7 step:5818[D loss: 0.433129, acc: 66.41%, op_acc: 32.03%] [G loss: 0.977898]\n",
      "epoch:7 step:5819[D loss: 0.440518, acc: 64.06%, op_acc: 32.81%] [G loss: 0.911822]\n",
      "epoch:7 step:5820[D loss: 0.432504, acc: 55.47%, op_acc: 33.59%] [G loss: 0.881350]\n",
      "epoch:7 step:5821[D loss: 0.456391, acc: 54.69%, op_acc: 29.69%] [G loss: 0.828617]\n",
      "epoch:7 step:5822[D loss: 0.458803, acc: 53.91%, op_acc: 35.16%] [G loss: 0.888289]\n",
      "epoch:7 step:5823[D loss: 0.447555, acc: 60.16%, op_acc: 31.25%] [G loss: 0.883670]\n",
      "epoch:7 step:5824[D loss: 0.443576, acc: 60.94%, op_acc: 30.47%] [G loss: 0.875667]\n",
      "epoch:7 step:5825[D loss: 0.433460, acc: 60.16%, op_acc: 35.16%] [G loss: 0.887887]\n",
      "epoch:7 step:5826[D loss: 0.440574, acc: 62.50%, op_acc: 35.16%] [G loss: 1.015703]\n",
      "epoch:7 step:5827[D loss: 0.481156, acc: 47.66%, op_acc: 32.81%] [G loss: 0.854661]\n",
      "epoch:7 step:5828[D loss: 0.425013, acc: 62.50%, op_acc: 38.28%] [G loss: 0.883670]\n",
      "epoch:7 step:5829[D loss: 0.423213, acc: 57.03%, op_acc: 35.16%] [G loss: 0.844177]\n",
      "epoch:7 step:5830[D loss: 0.467021, acc: 60.16%, op_acc: 29.69%] [G loss: 0.867261]\n",
      "epoch:7 step:5831[D loss: 0.477572, acc: 56.25%, op_acc: 33.59%] [G loss: 0.816672]\n",
      "epoch:7 step:5832[D loss: 0.426932, acc: 55.47%, op_acc: 35.94%] [G loss: 0.874876]\n",
      "epoch:7 step:5833[D loss: 0.428006, acc: 64.06%, op_acc: 35.16%] [G loss: 0.858767]\n",
      "epoch:7 step:5834[D loss: 0.450946, acc: 60.94%, op_acc: 31.25%] [G loss: 0.976881]\n",
      "epoch:7 step:5835[D loss: 0.457387, acc: 61.72%, op_acc: 29.69%] [G loss: 0.890239]\n",
      "epoch:7 step:5836[D loss: 0.428518, acc: 60.94%, op_acc: 33.59%] [G loss: 0.888362]\n",
      "epoch:7 step:5837[D loss: 0.446197, acc: 60.16%, op_acc: 40.62%] [G loss: 0.868815]\n",
      "epoch:7 step:5838[D loss: 0.415059, acc: 53.91%, op_acc: 39.06%] [G loss: 0.919723]\n",
      "epoch:7 step:5839[D loss: 0.433617, acc: 63.28%, op_acc: 38.28%] [G loss: 0.954690]\n",
      "epoch:7 step:5840[D loss: 0.456167, acc: 57.81%, op_acc: 32.81%] [G loss: 0.864688]\n",
      "epoch:7 step:5841[D loss: 0.447865, acc: 60.94%, op_acc: 34.38%] [G loss: 0.922676]\n",
      "epoch:7 step:5842[D loss: 0.427959, acc: 64.06%, op_acc: 29.69%] [G loss: 0.996902]\n",
      "epoch:7 step:5843[D loss: 0.428811, acc: 63.28%, op_acc: 32.81%] [G loss: 0.889026]\n",
      "epoch:7 step:5844[D loss: 0.427685, acc: 61.72%, op_acc: 35.94%] [G loss: 0.919961]\n",
      "epoch:7 step:5845[D loss: 0.437663, acc: 62.50%, op_acc: 35.94%] [G loss: 0.827013]\n",
      "epoch:7 step:5846[D loss: 0.438748, acc: 60.94%, op_acc: 36.72%] [G loss: 0.901018]\n",
      "epoch:7 step:5847[D loss: 0.437295, acc: 68.75%, op_acc: 34.38%] [G loss: 0.915948]\n",
      "epoch:7 step:5848[D loss: 0.466446, acc: 57.03%, op_acc: 34.38%] [G loss: 0.841638]\n",
      "epoch:7 step:5849[D loss: 0.434732, acc: 60.94%, op_acc: 35.16%] [G loss: 0.902430]\n",
      "epoch:7 step:5850[D loss: 0.444981, acc: 54.69%, op_acc: 32.81%] [G loss: 0.936442]\n",
      "##############\n",
      "[0.86494315 0.84093229 0.80991599 0.79389851 0.78225119 0.82026916\n",
      " 0.87832673 0.83032216 0.80814766 0.83157162]\n",
      "##########\n",
      "epoch:7 step:5851[D loss: 0.425281, acc: 63.28%, op_acc: 36.72%] [G loss: 0.868373]\n",
      "epoch:7 step:5852[D loss: 0.457117, acc: 53.12%, op_acc: 35.16%] [G loss: 0.971078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5853[D loss: 0.441498, acc: 55.47%, op_acc: 31.25%] [G loss: 0.958364]\n",
      "epoch:7 step:5854[D loss: 0.502701, acc: 42.97%, op_acc: 33.59%] [G loss: 0.895655]\n",
      "epoch:7 step:5855[D loss: 0.450413, acc: 63.28%, op_acc: 33.59%] [G loss: 0.979498]\n",
      "epoch:7 step:5856[D loss: 0.483879, acc: 50.78%, op_acc: 28.91%] [G loss: 0.771344]\n",
      "epoch:7 step:5857[D loss: 0.431236, acc: 60.94%, op_acc: 36.72%] [G loss: 0.915378]\n",
      "epoch:7 step:5858[D loss: 0.460377, acc: 53.91%, op_acc: 39.06%] [G loss: 0.909627]\n",
      "epoch:7 step:5859[D loss: 0.433503, acc: 57.03%, op_acc: 37.50%] [G loss: 0.923172]\n",
      "epoch:7 step:5860[D loss: 0.448534, acc: 60.94%, op_acc: 35.16%] [G loss: 0.980739]\n",
      "epoch:7 step:5861[D loss: 0.437223, acc: 61.72%, op_acc: 34.38%] [G loss: 0.905588]\n",
      "epoch:7 step:5862[D loss: 0.449648, acc: 56.25%, op_acc: 30.47%] [G loss: 0.930555]\n",
      "epoch:7 step:5863[D loss: 0.437180, acc: 60.94%, op_acc: 33.59%] [G loss: 0.868562]\n",
      "epoch:7 step:5864[D loss: 0.449650, acc: 64.06%, op_acc: 32.03%] [G loss: 0.952083]\n",
      "epoch:7 step:5865[D loss: 0.462465, acc: 60.16%, op_acc: 29.69%] [G loss: 0.860749]\n",
      "epoch:7 step:5866[D loss: 0.439179, acc: 53.91%, op_acc: 33.59%] [G loss: 0.842199]\n",
      "epoch:7 step:5867[D loss: 0.420925, acc: 64.06%, op_acc: 39.06%] [G loss: 0.842826]\n",
      "epoch:7 step:5868[D loss: 0.469542, acc: 56.25%, op_acc: 32.81%] [G loss: 0.925592]\n",
      "epoch:7 step:5869[D loss: 0.442958, acc: 58.59%, op_acc: 33.59%] [G loss: 0.919087]\n",
      "epoch:7 step:5870[D loss: 0.448025, acc: 57.81%, op_acc: 36.72%] [G loss: 0.869836]\n",
      "epoch:7 step:5871[D loss: 0.422308, acc: 60.16%, op_acc: 39.84%] [G loss: 0.974863]\n",
      "epoch:7 step:5872[D loss: 0.469198, acc: 53.91%, op_acc: 36.72%] [G loss: 0.880185]\n",
      "epoch:7 step:5873[D loss: 0.441510, acc: 60.16%, op_acc: 29.69%] [G loss: 0.839194]\n",
      "epoch:7 step:5874[D loss: 0.455494, acc: 62.50%, op_acc: 28.91%] [G loss: 0.863587]\n",
      "epoch:7 step:5875[D loss: 0.427835, acc: 60.16%, op_acc: 39.06%] [G loss: 0.894112]\n",
      "epoch:7 step:5876[D loss: 0.448511, acc: 56.25%, op_acc: 32.03%] [G loss: 0.793350]\n",
      "epoch:7 step:5877[D loss: 0.437537, acc: 54.69%, op_acc: 36.72%] [G loss: 0.810097]\n",
      "epoch:7 step:5878[D loss: 0.444106, acc: 57.81%, op_acc: 35.94%] [G loss: 0.872340]\n",
      "epoch:7 step:5879[D loss: 0.441909, acc: 56.25%, op_acc: 32.03%] [G loss: 0.834520]\n",
      "epoch:7 step:5880[D loss: 0.446257, acc: 54.69%, op_acc: 35.16%] [G loss: 0.799059]\n",
      "epoch:7 step:5881[D loss: 0.440994, acc: 59.38%, op_acc: 40.62%] [G loss: 0.917332]\n",
      "epoch:7 step:5882[D loss: 0.445348, acc: 58.59%, op_acc: 35.16%] [G loss: 0.844612]\n",
      "epoch:7 step:5883[D loss: 0.418688, acc: 66.41%, op_acc: 36.72%] [G loss: 0.860500]\n",
      "epoch:7 step:5884[D loss: 0.424351, acc: 64.06%, op_acc: 33.59%] [G loss: 0.916477]\n",
      "epoch:7 step:5885[D loss: 0.435208, acc: 63.28%, op_acc: 33.59%] [G loss: 0.823214]\n",
      "epoch:7 step:5886[D loss: 0.430987, acc: 62.50%, op_acc: 31.25%] [G loss: 0.884947]\n",
      "epoch:7 step:5887[D loss: 0.440841, acc: 64.06%, op_acc: 35.16%] [G loss: 0.865129]\n",
      "epoch:7 step:5888[D loss: 0.468805, acc: 57.81%, op_acc: 27.34%] [G loss: 0.854750]\n",
      "epoch:7 step:5889[D loss: 0.427036, acc: 63.28%, op_acc: 34.38%] [G loss: 0.881928]\n",
      "epoch:7 step:5890[D loss: 0.499172, acc: 50.78%, op_acc: 29.69%] [G loss: 0.884892]\n",
      "epoch:7 step:5891[D loss: 0.459522, acc: 59.38%, op_acc: 35.16%] [G loss: 0.857712]\n",
      "epoch:7 step:5892[D loss: 0.468257, acc: 52.34%, op_acc: 31.25%] [G loss: 0.919434]\n",
      "epoch:7 step:5893[D loss: 0.463511, acc: 60.94%, op_acc: 27.34%] [G loss: 0.934119]\n",
      "epoch:7 step:5894[D loss: 0.432799, acc: 62.50%, op_acc: 32.81%] [G loss: 0.944836]\n",
      "epoch:7 step:5895[D loss: 0.467772, acc: 53.12%, op_acc: 32.81%] [G loss: 0.941640]\n",
      "epoch:7 step:5896[D loss: 0.421136, acc: 71.09%, op_acc: 28.91%] [G loss: 0.866256]\n",
      "epoch:7 step:5897[D loss: 0.435913, acc: 57.81%, op_acc: 32.03%] [G loss: 0.967015]\n",
      "epoch:7 step:5898[D loss: 0.449277, acc: 61.72%, op_acc: 33.59%] [G loss: 0.913218]\n",
      "epoch:7 step:5899[D loss: 0.426952, acc: 64.84%, op_acc: 37.50%] [G loss: 0.926894]\n",
      "epoch:7 step:5900[D loss: 0.433449, acc: 64.84%, op_acc: 31.25%] [G loss: 0.911142]\n",
      "##############\n",
      "[0.8529848  0.83876131 0.80017551 0.81401442 0.78745759 0.83408096\n",
      " 0.90468705 0.83240931 0.79059347 0.8405129 ]\n",
      "##########\n",
      "epoch:7 step:5901[D loss: 0.465405, acc: 56.25%, op_acc: 32.03%] [G loss: 0.909641]\n",
      "epoch:7 step:5902[D loss: 0.424275, acc: 60.94%, op_acc: 39.06%] [G loss: 0.827748]\n",
      "epoch:7 step:5903[D loss: 0.446688, acc: 60.94%, op_acc: 27.34%] [G loss: 0.924129]\n",
      "epoch:7 step:5904[D loss: 0.429439, acc: 64.84%, op_acc: 35.94%] [G loss: 0.871725]\n",
      "epoch:7 step:5905[D loss: 0.451986, acc: 59.38%, op_acc: 32.81%] [G loss: 0.855331]\n",
      "epoch:7 step:5906[D loss: 0.460741, acc: 57.03%, op_acc: 32.03%] [G loss: 0.843375]\n",
      "epoch:7 step:5907[D loss: 0.431383, acc: 60.94%, op_acc: 39.06%] [G loss: 0.901599]\n",
      "epoch:7 step:5908[D loss: 0.445655, acc: 58.59%, op_acc: 31.25%] [G loss: 0.867586]\n",
      "epoch:7 step:5909[D loss: 0.464498, acc: 54.69%, op_acc: 33.59%] [G loss: 0.883517]\n",
      "epoch:7 step:5910[D loss: 0.450381, acc: 60.16%, op_acc: 29.69%] [G loss: 0.973526]\n",
      "epoch:7 step:5911[D loss: 0.446454, acc: 58.59%, op_acc: 31.25%] [G loss: 0.872509]\n",
      "epoch:7 step:5912[D loss: 0.443761, acc: 54.69%, op_acc: 36.72%] [G loss: 0.855947]\n",
      "epoch:7 step:5913[D loss: 0.443383, acc: 57.03%, op_acc: 28.12%] [G loss: 0.858104]\n",
      "epoch:7 step:5914[D loss: 0.451496, acc: 62.50%, op_acc: 29.69%] [G loss: 0.880913]\n",
      "epoch:7 step:5915[D loss: 0.431882, acc: 64.06%, op_acc: 39.06%] [G loss: 0.836483]\n",
      "epoch:7 step:5916[D loss: 0.480020, acc: 53.12%, op_acc: 32.81%] [G loss: 0.974492]\n",
      "epoch:7 step:5917[D loss: 0.431784, acc: 60.94%, op_acc: 32.03%] [G loss: 0.904588]\n",
      "epoch:7 step:5918[D loss: 0.448919, acc: 50.78%, op_acc: 37.50%] [G loss: 0.909301]\n",
      "epoch:7 step:5919[D loss: 0.421829, acc: 64.06%, op_acc: 37.50%] [G loss: 0.960234]\n",
      "epoch:7 step:5920[D loss: 0.453111, acc: 53.91%, op_acc: 32.81%] [G loss: 0.878747]\n",
      "epoch:7 step:5921[D loss: 0.451571, acc: 57.81%, op_acc: 32.81%] [G loss: 0.939746]\n",
      "epoch:7 step:5922[D loss: 0.472597, acc: 51.56%, op_acc: 32.03%] [G loss: 0.924560]\n",
      "epoch:7 step:5923[D loss: 0.473589, acc: 57.03%, op_acc: 31.25%] [G loss: 0.881535]\n",
      "epoch:7 step:5924[D loss: 0.422071, acc: 63.28%, op_acc: 31.25%] [G loss: 1.057036]\n",
      "epoch:7 step:5925[D loss: 0.432106, acc: 58.59%, op_acc: 34.38%] [G loss: 0.903751]\n",
      "epoch:7 step:5926[D loss: 0.460992, acc: 48.44%, op_acc: 29.69%] [G loss: 0.878209]\n",
      "epoch:7 step:5927[D loss: 0.418806, acc: 64.06%, op_acc: 37.50%] [G loss: 0.949215]\n",
      "epoch:7 step:5928[D loss: 0.460826, acc: 58.59%, op_acc: 30.47%] [G loss: 0.865939]\n",
      "epoch:7 step:5929[D loss: 0.412261, acc: 69.53%, op_acc: 28.91%] [G loss: 0.918022]\n",
      "epoch:7 step:5930[D loss: 0.451824, acc: 60.16%, op_acc: 36.72%] [G loss: 0.863046]\n",
      "epoch:7 step:5931[D loss: 0.451449, acc: 64.06%, op_acc: 25.00%] [G loss: 0.988888]\n",
      "epoch:7 step:5932[D loss: 0.459818, acc: 64.84%, op_acc: 25.78%] [G loss: 0.933615]\n",
      "epoch:7 step:5933[D loss: 0.433094, acc: 62.50%, op_acc: 35.94%] [G loss: 0.928676]\n",
      "epoch:7 step:5934[D loss: 0.439575, acc: 58.59%, op_acc: 32.81%] [G loss: 0.920725]\n",
      "epoch:7 step:5935[D loss: 0.438785, acc: 54.69%, op_acc: 37.50%] [G loss: 0.848138]\n",
      "epoch:7 step:5936[D loss: 0.395261, acc: 66.41%, op_acc: 35.94%] [G loss: 0.966253]\n",
      "epoch:7 step:5937[D loss: 0.445100, acc: 64.84%, op_acc: 35.94%] [G loss: 1.015366]\n",
      "epoch:7 step:5938[D loss: 0.469830, acc: 59.38%, op_acc: 32.81%] [G loss: 0.852099]\n",
      "epoch:7 step:5939[D loss: 0.459790, acc: 60.16%, op_acc: 27.34%] [G loss: 0.886883]\n",
      "epoch:7 step:5940[D loss: 0.428492, acc: 64.06%, op_acc: 39.84%] [G loss: 0.805561]\n",
      "epoch:7 step:5941[D loss: 0.442093, acc: 62.50%, op_acc: 35.16%] [G loss: 0.907841]\n",
      "epoch:7 step:5942[D loss: 0.465720, acc: 50.78%, op_acc: 35.94%] [G loss: 0.887247]\n",
      "epoch:7 step:5943[D loss: 0.468754, acc: 55.47%, op_acc: 28.91%] [G loss: 0.890642]\n",
      "epoch:7 step:5944[D loss: 0.436970, acc: 60.16%, op_acc: 39.84%] [G loss: 0.915174]\n",
      "epoch:7 step:5945[D loss: 0.439545, acc: 57.03%, op_acc: 35.16%] [G loss: 0.889465]\n",
      "epoch:7 step:5946[D loss: 0.436915, acc: 56.25%, op_acc: 32.03%] [G loss: 0.941687]\n",
      "epoch:7 step:5947[D loss: 0.519362, acc: 47.66%, op_acc: 25.78%] [G loss: 0.905962]\n",
      "epoch:7 step:5948[D loss: 0.452274, acc: 61.72%, op_acc: 29.69%] [G loss: 0.960204]\n",
      "epoch:7 step:5949[D loss: 0.476322, acc: 56.25%, op_acc: 28.91%] [G loss: 0.875515]\n",
      "epoch:7 step:5950[D loss: 0.483226, acc: 53.12%, op_acc: 35.94%] [G loss: 0.875574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.85897132 0.86133564 0.82480103 0.80007568 0.80041412 0.81843008\n",
      " 0.88442852 0.83295728 0.80696433 0.83232037]\n",
      "##########\n",
      "epoch:7 step:5951[D loss: 0.428780, acc: 62.50%, op_acc: 37.50%] [G loss: 0.903399]\n",
      "epoch:7 step:5952[D loss: 0.425342, acc: 64.06%, op_acc: 35.16%] [G loss: 0.964992]\n",
      "epoch:7 step:5953[D loss: 0.439621, acc: 59.38%, op_acc: 35.94%] [G loss: 0.914601]\n",
      "epoch:7 step:5954[D loss: 0.435945, acc: 63.28%, op_acc: 35.94%] [G loss: 0.890120]\n",
      "epoch:7 step:5955[D loss: 0.479481, acc: 55.47%, op_acc: 34.38%] [G loss: 0.860763]\n",
      "epoch:7 step:5956[D loss: 0.436668, acc: 56.25%, op_acc: 38.28%] [G loss: 0.874787]\n",
      "epoch:7 step:5957[D loss: 0.435043, acc: 60.94%, op_acc: 37.50%] [G loss: 0.888093]\n",
      "epoch:7 step:5958[D loss: 0.435847, acc: 65.62%, op_acc: 30.47%] [G loss: 1.012601]\n",
      "epoch:7 step:5959[D loss: 0.411433, acc: 67.97%, op_acc: 39.84%] [G loss: 0.942517]\n",
      "epoch:7 step:5960[D loss: 0.420138, acc: 66.41%, op_acc: 31.25%] [G loss: 0.943105]\n",
      "epoch:7 step:5961[D loss: 0.408849, acc: 60.94%, op_acc: 35.94%] [G loss: 0.908828]\n",
      "epoch:7 step:5962[D loss: 0.451473, acc: 53.12%, op_acc: 29.69%] [G loss: 0.831499]\n",
      "epoch:7 step:5963[D loss: 0.429441, acc: 63.28%, op_acc: 30.47%] [G loss: 0.932284]\n",
      "epoch:7 step:5964[D loss: 0.433022, acc: 58.59%, op_acc: 38.28%] [G loss: 0.900160]\n",
      "epoch:7 step:5965[D loss: 0.449980, acc: 57.81%, op_acc: 25.78%] [G loss: 0.909439]\n",
      "epoch:7 step:5966[D loss: 0.478441, acc: 57.03%, op_acc: 34.38%] [G loss: 0.977036]\n",
      "epoch:7 step:5967[D loss: 0.428281, acc: 60.16%, op_acc: 35.94%] [G loss: 0.979491]\n",
      "epoch:7 step:5968[D loss: 0.454639, acc: 54.69%, op_acc: 28.91%] [G loss: 0.888452]\n",
      "epoch:7 step:5969[D loss: 0.432979, acc: 58.59%, op_acc: 33.59%] [G loss: 0.939905]\n",
      "epoch:7 step:5970[D loss: 0.448711, acc: 60.16%, op_acc: 27.34%] [G loss: 0.882278]\n",
      "epoch:7 step:5971[D loss: 0.469567, acc: 53.91%, op_acc: 35.16%] [G loss: 0.811392]\n",
      "epoch:7 step:5972[D loss: 0.457700, acc: 60.94%, op_acc: 32.81%] [G loss: 0.824262]\n",
      "epoch:7 step:5973[D loss: 0.430443, acc: 60.16%, op_acc: 33.59%] [G loss: 0.896432]\n",
      "epoch:7 step:5974[D loss: 0.421926, acc: 61.72%, op_acc: 38.28%] [G loss: 0.907128]\n",
      "epoch:7 step:5975[D loss: 0.459121, acc: 48.44%, op_acc: 37.50%] [G loss: 0.870088]\n",
      "epoch:7 step:5976[D loss: 0.473811, acc: 53.91%, op_acc: 29.69%] [G loss: 0.886668]\n",
      "epoch:7 step:5977[D loss: 0.450226, acc: 52.34%, op_acc: 31.25%] [G loss: 0.929061]\n",
      "epoch:7 step:5978[D loss: 0.466909, acc: 50.00%, op_acc: 36.72%] [G loss: 0.832218]\n",
      "epoch:7 step:5979[D loss: 0.449874, acc: 58.59%, op_acc: 30.47%] [G loss: 0.889785]\n",
      "epoch:7 step:5980[D loss: 0.462194, acc: 61.72%, op_acc: 32.03%] [G loss: 0.864993]\n",
      "epoch:7 step:5981[D loss: 0.451859, acc: 60.16%, op_acc: 30.47%] [G loss: 0.951201]\n",
      "epoch:7 step:5982[D loss: 0.462693, acc: 60.94%, op_acc: 27.34%] [G loss: 0.809237]\n",
      "epoch:7 step:5983[D loss: 0.484809, acc: 50.78%, op_acc: 31.25%] [G loss: 0.869737]\n",
      "epoch:7 step:5984[D loss: 0.439650, acc: 65.62%, op_acc: 26.56%] [G loss: 0.850830]\n",
      "epoch:7 step:5985[D loss: 0.422682, acc: 59.38%, op_acc: 34.38%] [G loss: 0.916454]\n",
      "epoch:7 step:5986[D loss: 0.441678, acc: 64.06%, op_acc: 40.62%] [G loss: 0.904627]\n",
      "epoch:7 step:5987[D loss: 0.431338, acc: 61.72%, op_acc: 35.16%] [G loss: 0.800042]\n",
      "epoch:7 step:5988[D loss: 0.430246, acc: 62.50%, op_acc: 32.03%] [G loss: 0.839916]\n",
      "epoch:7 step:5989[D loss: 0.458199, acc: 57.03%, op_acc: 29.69%] [G loss: 0.844878]\n",
      "epoch:7 step:5990[D loss: 0.445555, acc: 60.94%, op_acc: 37.50%] [G loss: 0.888701]\n",
      "epoch:7 step:5991[D loss: 0.424428, acc: 67.97%, op_acc: 28.91%] [G loss: 0.905840]\n",
      "epoch:7 step:5992[D loss: 0.432434, acc: 64.06%, op_acc: 27.34%] [G loss: 0.886865]\n",
      "epoch:7 step:5993[D loss: 0.493532, acc: 53.12%, op_acc: 26.56%] [G loss: 0.927961]\n",
      "epoch:7 step:5994[D loss: 0.432335, acc: 63.28%, op_acc: 31.25%] [G loss: 0.892004]\n",
      "epoch:7 step:5995[D loss: 0.447147, acc: 57.81%, op_acc: 31.25%] [G loss: 0.892200]\n",
      "epoch:7 step:5996[D loss: 0.437461, acc: 59.38%, op_acc: 35.16%] [G loss: 0.854377]\n",
      "epoch:7 step:5997[D loss: 0.444921, acc: 60.16%, op_acc: 31.25%] [G loss: 0.936750]\n",
      "epoch:7 step:5998[D loss: 0.481191, acc: 54.69%, op_acc: 28.91%] [G loss: 0.777616]\n",
      "epoch:7 step:5999[D loss: 0.435856, acc: 55.47%, op_acc: 34.38%] [G loss: 0.861054]\n",
      "epoch:7 step:6000[D loss: 0.442444, acc: 58.59%, op_acc: 30.47%] [G loss: 0.817099]\n",
      "##############\n",
      "[0.85336872 0.86353036 0.7995044  0.80626095 0.77866326 0.84690093\n",
      " 0.88586719 0.81334011 0.8196757  0.8403463 ]\n",
      "##########\n",
      "epoch:7 step:6001[D loss: 0.423227, acc: 62.50%, op_acc: 41.41%] [G loss: 0.868578]\n",
      "epoch:7 step:6002[D loss: 0.465013, acc: 50.78%, op_acc: 35.94%] [G loss: 0.884611]\n",
      "epoch:7 step:6003[D loss: 0.418154, acc: 60.94%, op_acc: 39.06%] [G loss: 0.853379]\n",
      "epoch:7 step:6004[D loss: 0.477725, acc: 51.56%, op_acc: 28.12%] [G loss: 0.857708]\n",
      "epoch:7 step:6005[D loss: 0.450948, acc: 57.81%, op_acc: 38.28%] [G loss: 0.840625]\n",
      "epoch:7 step:6006[D loss: 0.487918, acc: 56.25%, op_acc: 27.34%] [G loss: 0.913253]\n",
      "epoch:7 step:6007[D loss: 0.439395, acc: 56.25%, op_acc: 32.81%] [G loss: 0.827803]\n",
      "epoch:7 step:6008[D loss: 0.445046, acc: 60.94%, op_acc: 36.72%] [G loss: 0.923204]\n",
      "epoch:7 step:6009[D loss: 0.436081, acc: 62.50%, op_acc: 30.47%] [G loss: 0.803585]\n",
      "epoch:7 step:6010[D loss: 0.459585, acc: 63.28%, op_acc: 32.03%] [G loss: 0.787418]\n",
      "epoch:7 step:6011[D loss: 0.432928, acc: 60.16%, op_acc: 36.72%] [G loss: 0.890275]\n",
      "epoch:7 step:6012[D loss: 0.456012, acc: 54.69%, op_acc: 34.38%] [G loss: 0.827617]\n",
      "epoch:7 step:6013[D loss: 0.464437, acc: 55.47%, op_acc: 28.91%] [G loss: 0.906040]\n",
      "epoch:7 step:6014[D loss: 0.459539, acc: 57.03%, op_acc: 32.03%] [G loss: 0.888815]\n",
      "epoch:7 step:6015[D loss: 0.460474, acc: 59.38%, op_acc: 32.81%] [G loss: 0.871750]\n",
      "epoch:7 step:6016[D loss: 0.446198, acc: 61.72%, op_acc: 31.25%] [G loss: 0.891453]\n",
      "epoch:7 step:6017[D loss: 0.466972, acc: 53.12%, op_acc: 29.69%] [G loss: 0.811541]\n",
      "epoch:7 step:6018[D loss: 0.461159, acc: 56.25%, op_acc: 32.81%] [G loss: 0.883194]\n",
      "epoch:7 step:6019[D loss: 0.485289, acc: 53.91%, op_acc: 23.44%] [G loss: 0.951425]\n",
      "epoch:7 step:6020[D loss: 0.444847, acc: 59.38%, op_acc: 32.03%] [G loss: 0.918805]\n",
      "epoch:7 step:6021[D loss: 0.416494, acc: 66.41%, op_acc: 38.28%] [G loss: 0.895045]\n",
      "epoch:7 step:6022[D loss: 0.448616, acc: 53.91%, op_acc: 32.03%] [G loss: 0.838127]\n",
      "epoch:7 step:6023[D loss: 0.423926, acc: 62.50%, op_acc: 36.72%] [G loss: 0.879142]\n",
      "epoch:7 step:6024[D loss: 0.449638, acc: 63.28%, op_acc: 31.25%] [G loss: 0.859977]\n",
      "epoch:7 step:6025[D loss: 0.425719, acc: 64.06%, op_acc: 40.62%] [G loss: 0.924626]\n",
      "epoch:7 step:6026[D loss: 0.424808, acc: 63.28%, op_acc: 36.72%] [G loss: 0.898492]\n",
      "epoch:7 step:6027[D loss: 0.446058, acc: 64.06%, op_acc: 32.03%] [G loss: 0.962891]\n",
      "epoch:7 step:6028[D loss: 0.461495, acc: 57.81%, op_acc: 32.81%] [G loss: 0.890438]\n",
      "epoch:7 step:6029[D loss: 0.427697, acc: 62.50%, op_acc: 35.94%] [G loss: 0.857110]\n",
      "epoch:7 step:6030[D loss: 0.434355, acc: 62.50%, op_acc: 34.38%] [G loss: 0.872521]\n",
      "epoch:7 step:6031[D loss: 0.438214, acc: 60.94%, op_acc: 35.94%] [G loss: 0.930491]\n",
      "epoch:7 step:6032[D loss: 0.456538, acc: 57.81%, op_acc: 37.50%] [G loss: 0.901154]\n",
      "epoch:7 step:6033[D loss: 0.443185, acc: 67.19%, op_acc: 35.16%] [G loss: 0.930232]\n",
      "epoch:7 step:6034[D loss: 0.441598, acc: 54.69%, op_acc: 32.81%] [G loss: 0.953588]\n",
      "epoch:7 step:6035[D loss: 0.423706, acc: 63.28%, op_acc: 39.06%] [G loss: 0.939062]\n",
      "epoch:7 step:6036[D loss: 0.446171, acc: 60.16%, op_acc: 32.81%] [G loss: 0.881586]\n",
      "epoch:7 step:6037[D loss: 0.423796, acc: 61.72%, op_acc: 35.94%] [G loss: 0.885615]\n",
      "epoch:7 step:6038[D loss: 0.458279, acc: 55.47%, op_acc: 32.81%] [G loss: 0.900933]\n",
      "epoch:7 step:6039[D loss: 0.459504, acc: 55.47%, op_acc: 32.81%] [G loss: 0.843557]\n",
      "epoch:7 step:6040[D loss: 0.444592, acc: 61.72%, op_acc: 32.03%] [G loss: 0.876941]\n",
      "epoch:7 step:6041[D loss: 0.453456, acc: 59.38%, op_acc: 25.78%] [G loss: 0.853448]\n",
      "epoch:7 step:6042[D loss: 0.450143, acc: 56.25%, op_acc: 33.59%] [G loss: 0.920316]\n",
      "epoch:7 step:6043[D loss: 0.435068, acc: 58.59%, op_acc: 35.16%] [G loss: 0.846968]\n",
      "epoch:7 step:6044[D loss: 0.484644, acc: 50.78%, op_acc: 28.91%] [G loss: 0.903111]\n",
      "epoch:7 step:6045[D loss: 0.437357, acc: 64.06%, op_acc: 33.59%] [G loss: 0.879009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6046[D loss: 0.431660, acc: 57.81%, op_acc: 39.84%] [G loss: 0.997029]\n",
      "epoch:7 step:6047[D loss: 0.460103, acc: 57.03%, op_acc: 29.69%] [G loss: 0.913704]\n",
      "epoch:7 step:6048[D loss: 0.458560, acc: 53.91%, op_acc: 32.81%] [G loss: 0.904261]\n",
      "epoch:7 step:6049[D loss: 0.431653, acc: 66.41%, op_acc: 27.34%] [G loss: 0.872127]\n",
      "epoch:7 step:6050[D loss: 0.450703, acc: 58.59%, op_acc: 32.03%] [G loss: 0.943470]\n",
      "##############\n",
      "[0.8562267  0.85329769 0.81250191 0.81824802 0.77355442 0.81054717\n",
      " 0.8688697  0.83250331 0.82479431 0.83610998]\n",
      "##########\n",
      "epoch:7 step:6051[D loss: 0.455365, acc: 59.38%, op_acc: 34.38%] [G loss: 0.858593]\n",
      "epoch:7 step:6052[D loss: 0.442798, acc: 60.16%, op_acc: 29.69%] [G loss: 0.856929]\n",
      "epoch:7 step:6053[D loss: 0.455003, acc: 53.12%, op_acc: 31.25%] [G loss: 0.958587]\n",
      "epoch:7 step:6054[D loss: 0.429081, acc: 62.50%, op_acc: 32.03%] [G loss: 0.860736]\n",
      "epoch:7 step:6055[D loss: 0.424659, acc: 64.06%, op_acc: 38.28%] [G loss: 0.877589]\n",
      "epoch:7 step:6056[D loss: 0.431338, acc: 59.38%, op_acc: 31.25%] [G loss: 0.911687]\n",
      "epoch:7 step:6057[D loss: 0.478898, acc: 54.69%, op_acc: 37.50%] [G loss: 0.873937]\n",
      "epoch:7 step:6058[D loss: 0.455074, acc: 60.94%, op_acc: 32.03%] [G loss: 0.929497]\n",
      "epoch:7 step:6059[D loss: 0.460900, acc: 53.91%, op_acc: 32.81%] [G loss: 0.854137]\n",
      "epoch:7 step:6060[D loss: 0.458542, acc: 56.25%, op_acc: 34.38%] [G loss: 0.892206]\n",
      "epoch:7 step:6061[D loss: 0.480999, acc: 50.78%, op_acc: 35.94%] [G loss: 0.874250]\n",
      "epoch:7 step:6062[D loss: 0.447702, acc: 65.62%, op_acc: 32.03%] [G loss: 0.929397]\n",
      "epoch:7 step:6063[D loss: 0.457959, acc: 58.59%, op_acc: 32.03%] [G loss: 0.911256]\n",
      "epoch:7 step:6064[D loss: 0.472114, acc: 53.91%, op_acc: 32.03%] [G loss: 0.957926]\n",
      "epoch:7 step:6065[D loss: 0.444278, acc: 60.16%, op_acc: 32.81%] [G loss: 0.916476]\n",
      "epoch:7 step:6066[D loss: 0.460028, acc: 56.25%, op_acc: 35.16%] [G loss: 0.959499]\n",
      "epoch:7 step:6067[D loss: 0.423283, acc: 65.62%, op_acc: 35.94%] [G loss: 0.953694]\n",
      "epoch:7 step:6068[D loss: 0.455484, acc: 57.03%, op_acc: 35.94%] [G loss: 0.847531]\n",
      "epoch:7 step:6069[D loss: 0.421272, acc: 59.38%, op_acc: 39.06%] [G loss: 0.831450]\n",
      "epoch:7 step:6070[D loss: 0.407844, acc: 62.50%, op_acc: 39.06%] [G loss: 0.893244]\n",
      "epoch:7 step:6071[D loss: 0.479816, acc: 59.38%, op_acc: 26.56%] [G loss: 0.946077]\n",
      "epoch:7 step:6072[D loss: 0.446561, acc: 56.25%, op_acc: 34.38%] [G loss: 0.837628]\n",
      "epoch:7 step:6073[D loss: 0.456887, acc: 50.00%, op_acc: 35.16%] [G loss: 0.893482]\n",
      "epoch:7 step:6074[D loss: 0.443120, acc: 56.25%, op_acc: 40.62%] [G loss: 0.889616]\n",
      "epoch:7 step:6075[D loss: 0.412459, acc: 68.75%, op_acc: 33.59%] [G loss: 0.895003]\n",
      "epoch:7 step:6076[D loss: 0.446170, acc: 63.28%, op_acc: 31.25%] [G loss: 0.912433]\n",
      "epoch:7 step:6077[D loss: 0.446498, acc: 64.06%, op_acc: 27.34%] [G loss: 0.884360]\n",
      "epoch:7 step:6078[D loss: 0.435314, acc: 60.16%, op_acc: 35.94%] [G loss: 0.875146]\n",
      "epoch:7 step:6079[D loss: 0.438395, acc: 57.81%, op_acc: 30.47%] [G loss: 0.882235]\n",
      "epoch:7 step:6080[D loss: 0.453324, acc: 50.78%, op_acc: 38.28%] [G loss: 0.940947]\n",
      "epoch:7 step:6081[D loss: 0.423256, acc: 60.16%, op_acc: 42.19%] [G loss: 0.913393]\n",
      "epoch:7 step:6082[D loss: 0.462945, acc: 55.47%, op_acc: 32.03%] [G loss: 0.871883]\n",
      "epoch:7 step:6083[D loss: 0.486866, acc: 47.66%, op_acc: 28.91%] [G loss: 0.801020]\n",
      "epoch:7 step:6084[D loss: 0.481423, acc: 50.00%, op_acc: 29.69%] [G loss: 0.838912]\n",
      "epoch:7 step:6085[D loss: 0.432656, acc: 63.28%, op_acc: 39.06%] [G loss: 0.900458]\n",
      "epoch:7 step:6086[D loss: 0.488409, acc: 57.03%, op_acc: 23.44%] [G loss: 0.885498]\n",
      "epoch:7 step:6087[D loss: 0.443237, acc: 64.84%, op_acc: 28.12%] [G loss: 0.842221]\n",
      "epoch:7 step:6088[D loss: 0.458741, acc: 60.16%, op_acc: 30.47%] [G loss: 0.844698]\n",
      "epoch:7 step:6089[D loss: 0.457598, acc: 65.62%, op_acc: 31.25%] [G loss: 0.931059]\n",
      "epoch:7 step:6090[D loss: 0.440404, acc: 56.25%, op_acc: 35.94%] [G loss: 0.917776]\n",
      "epoch:7 step:6091[D loss: 0.428399, acc: 57.81%, op_acc: 39.06%] [G loss: 0.877294]\n",
      "epoch:7 step:6092[D loss: 0.460057, acc: 57.03%, op_acc: 33.59%] [G loss: 1.004052]\n",
      "epoch:7 step:6093[D loss: 0.414867, acc: 65.62%, op_acc: 39.06%] [G loss: 0.974753]\n",
      "epoch:7 step:6094[D loss: 0.455122, acc: 55.47%, op_acc: 34.38%] [G loss: 0.886056]\n",
      "epoch:7 step:6095[D loss: 0.462403, acc: 62.50%, op_acc: 25.00%] [G loss: 0.919433]\n",
      "epoch:7 step:6096[D loss: 0.447914, acc: 64.84%, op_acc: 32.03%] [G loss: 0.802729]\n",
      "epoch:7 step:6097[D loss: 0.441271, acc: 57.03%, op_acc: 35.94%] [G loss: 0.817481]\n",
      "epoch:7 step:6098[D loss: 0.465889, acc: 56.25%, op_acc: 32.81%] [G loss: 0.887011]\n",
      "epoch:7 step:6099[D loss: 0.464453, acc: 59.38%, op_acc: 28.91%] [G loss: 0.816033]\n",
      "epoch:7 step:6100[D loss: 0.430766, acc: 61.72%, op_acc: 32.03%] [G loss: 0.860245]\n",
      "##############\n",
      "[0.85975981 0.84895823 0.80496281 0.80862817 0.78838834 0.82088178\n",
      " 0.88252804 0.81725921 0.81754926 0.84193713]\n",
      "##########\n",
      "epoch:7 step:6101[D loss: 0.452009, acc: 51.56%, op_acc: 35.94%] [G loss: 0.864723]\n",
      "epoch:7 step:6102[D loss: 0.488398, acc: 56.25%, op_acc: 34.38%] [G loss: 0.905861]\n",
      "epoch:7 step:6103[D loss: 0.439658, acc: 55.47%, op_acc: 36.72%] [G loss: 0.867101]\n",
      "epoch:7 step:6104[D loss: 0.439385, acc: 61.72%, op_acc: 30.47%] [G loss: 0.833583]\n",
      "epoch:7 step:6105[D loss: 0.434753, acc: 59.38%, op_acc: 35.16%] [G loss: 0.796461]\n",
      "epoch:7 step:6106[D loss: 0.451937, acc: 59.38%, op_acc: 30.47%] [G loss: 0.860523]\n",
      "epoch:7 step:6107[D loss: 0.485029, acc: 50.00%, op_acc: 32.81%] [G loss: 0.821005]\n",
      "epoch:7 step:6108[D loss: 0.457029, acc: 61.72%, op_acc: 31.25%] [G loss: 0.912870]\n",
      "epoch:7 step:6109[D loss: 0.438107, acc: 65.62%, op_acc: 31.25%] [G loss: 0.918149]\n",
      "epoch:7 step:6110[D loss: 0.471252, acc: 51.56%, op_acc: 28.12%] [G loss: 0.918680]\n",
      "epoch:7 step:6111[D loss: 0.416303, acc: 66.41%, op_acc: 40.62%] [G loss: 0.942497]\n",
      "epoch:7 step:6112[D loss: 0.449523, acc: 57.03%, op_acc: 33.59%] [G loss: 0.942319]\n",
      "epoch:7 step:6113[D loss: 0.439046, acc: 65.62%, op_acc: 28.91%] [G loss: 0.940186]\n",
      "epoch:7 step:6114[D loss: 0.432954, acc: 58.59%, op_acc: 37.50%] [G loss: 0.865183]\n",
      "epoch:7 step:6115[D loss: 0.457458, acc: 56.25%, op_acc: 32.81%] [G loss: 0.882411]\n",
      "epoch:7 step:6116[D loss: 0.460990, acc: 57.03%, op_acc: 31.25%] [G loss: 0.895726]\n",
      "epoch:7 step:6117[D loss: 0.506206, acc: 47.66%, op_acc: 27.34%] [G loss: 0.792702]\n",
      "epoch:7 step:6118[D loss: 0.460107, acc: 56.25%, op_acc: 32.81%] [G loss: 0.929117]\n",
      "epoch:7 step:6119[D loss: 0.447723, acc: 54.69%, op_acc: 36.72%] [G loss: 0.814969]\n",
      "epoch:7 step:6120[D loss: 0.444637, acc: 54.69%, op_acc: 41.41%] [G loss: 0.832668]\n",
      "epoch:7 step:6121[D loss: 0.415618, acc: 67.19%, op_acc: 35.16%] [G loss: 0.843538]\n",
      "epoch:7 step:6122[D loss: 0.428913, acc: 62.50%, op_acc: 32.81%] [G loss: 0.986781]\n",
      "epoch:7 step:6123[D loss: 0.481201, acc: 52.34%, op_acc: 29.69%] [G loss: 0.875705]\n",
      "epoch:7 step:6124[D loss: 0.446564, acc: 60.16%, op_acc: 32.81%] [G loss: 0.877559]\n",
      "epoch:7 step:6125[D loss: 0.416986, acc: 68.75%, op_acc: 37.50%] [G loss: 0.860289]\n",
      "epoch:7 step:6126[D loss: 0.442615, acc: 70.31%, op_acc: 29.69%] [G loss: 0.967475]\n",
      "epoch:7 step:6127[D loss: 0.448547, acc: 58.59%, op_acc: 32.03%] [G loss: 0.886758]\n",
      "epoch:7 step:6128[D loss: 0.449154, acc: 54.69%, op_acc: 35.16%] [G loss: 0.842164]\n",
      "epoch:7 step:6129[D loss: 0.437550, acc: 57.03%, op_acc: 36.72%] [G loss: 0.898444]\n",
      "epoch:7 step:6130[D loss: 0.431343, acc: 58.59%, op_acc: 32.03%] [G loss: 0.938452]\n",
      "epoch:7 step:6131[D loss: 0.440992, acc: 60.16%, op_acc: 35.16%] [G loss: 0.960456]\n",
      "epoch:7 step:6132[D loss: 0.447393, acc: 64.06%, op_acc: 28.91%] [G loss: 0.854300]\n",
      "epoch:7 step:6133[D loss: 0.440999, acc: 64.06%, op_acc: 32.81%] [G loss: 0.918180]\n",
      "epoch:7 step:6134[D loss: 0.403261, acc: 67.19%, op_acc: 35.94%] [G loss: 0.965786]\n",
      "epoch:7 step:6135[D loss: 0.442222, acc: 60.16%, op_acc: 31.25%] [G loss: 0.829620]\n",
      "epoch:7 step:6136[D loss: 0.452820, acc: 54.69%, op_acc: 30.47%] [G loss: 0.882232]\n",
      "epoch:7 step:6137[D loss: 0.432717, acc: 60.16%, op_acc: 35.16%] [G loss: 0.936535]\n",
      "epoch:7 step:6138[D loss: 0.449125, acc: 63.28%, op_acc: 29.69%] [G loss: 0.838125]\n",
      "epoch:7 step:6139[D loss: 0.446525, acc: 62.50%, op_acc: 31.25%] [G loss: 0.858700]\n",
      "epoch:7 step:6140[D loss: 0.451235, acc: 54.69%, op_acc: 32.81%] [G loss: 0.879999]\n",
      "epoch:7 step:6141[D loss: 0.426914, acc: 66.41%, op_acc: 34.38%] [G loss: 0.854460]\n",
      "epoch:7 step:6142[D loss: 0.429169, acc: 64.84%, op_acc: 35.16%] [G loss: 0.880223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6143[D loss: 0.495524, acc: 55.47%, op_acc: 26.56%] [G loss: 0.794282]\n",
      "epoch:7 step:6144[D loss: 0.454517, acc: 58.59%, op_acc: 28.12%] [G loss: 0.804787]\n",
      "epoch:7 step:6145[D loss: 0.427352, acc: 64.06%, op_acc: 31.25%] [G loss: 0.896468]\n",
      "epoch:7 step:6146[D loss: 0.437133, acc: 60.94%, op_acc: 38.28%] [G loss: 0.926138]\n",
      "epoch:7 step:6147[D loss: 0.461594, acc: 60.16%, op_acc: 32.03%] [G loss: 0.916823]\n",
      "epoch:7 step:6148[D loss: 0.457195, acc: 57.03%, op_acc: 26.56%] [G loss: 0.963662]\n",
      "epoch:7 step:6149[D loss: 0.436346, acc: 57.81%, op_acc: 30.47%] [G loss: 0.864063]\n",
      "epoch:7 step:6150[D loss: 0.462779, acc: 48.44%, op_acc: 35.94%] [G loss: 0.786472]\n",
      "##############\n",
      "[0.86820494 0.85188175 0.80508164 0.80629176 0.79483382 0.81603456\n",
      " 0.87280305 0.83041565 0.7955778  0.8461235 ]\n",
      "##########\n",
      "epoch:7 step:6151[D loss: 0.467922, acc: 56.25%, op_acc: 29.69%] [G loss: 0.974436]\n",
      "epoch:7 step:6152[D loss: 0.443722, acc: 66.41%, op_acc: 34.38%] [G loss: 0.870033]\n",
      "epoch:7 step:6153[D loss: 0.462306, acc: 60.16%, op_acc: 27.34%] [G loss: 0.931375]\n",
      "epoch:7 step:6154[D loss: 0.429037, acc: 64.06%, op_acc: 32.03%] [G loss: 0.915755]\n",
      "epoch:7 step:6155[D loss: 0.459965, acc: 58.59%, op_acc: 35.94%] [G loss: 0.824762]\n",
      "epoch:7 step:6156[D loss: 0.445537, acc: 65.62%, op_acc: 33.59%] [G loss: 0.849678]\n",
      "epoch:7 step:6157[D loss: 0.434390, acc: 62.50%, op_acc: 33.59%] [G loss: 0.851757]\n",
      "epoch:7 step:6158[D loss: 0.453804, acc: 59.38%, op_acc: 32.81%] [G loss: 0.922118]\n",
      "epoch:7 step:6159[D loss: 0.448807, acc: 66.41%, op_acc: 34.38%] [G loss: 0.869706]\n",
      "epoch:7 step:6160[D loss: 0.460462, acc: 58.59%, op_acc: 28.91%] [G loss: 0.965169]\n",
      "epoch:7 step:6161[D loss: 0.455528, acc: 62.50%, op_acc: 33.59%] [G loss: 0.889243]\n",
      "epoch:7 step:6162[D loss: 0.458856, acc: 55.47%, op_acc: 32.81%] [G loss: 0.864307]\n",
      "epoch:7 step:6163[D loss: 0.476003, acc: 55.47%, op_acc: 29.69%] [G loss: 0.943764]\n",
      "epoch:7 step:6164[D loss: 0.467893, acc: 50.78%, op_acc: 32.03%] [G loss: 0.858551]\n",
      "epoch:7 step:6165[D loss: 0.446338, acc: 61.72%, op_acc: 32.03%] [G loss: 0.895268]\n",
      "epoch:7 step:6166[D loss: 0.471057, acc: 51.56%, op_acc: 36.72%] [G loss: 0.887541]\n",
      "epoch:7 step:6167[D loss: 0.468743, acc: 56.25%, op_acc: 28.91%] [G loss: 0.876304]\n",
      "epoch:7 step:6168[D loss: 0.446272, acc: 57.81%, op_acc: 32.81%] [G loss: 0.924093]\n",
      "epoch:7 step:6169[D loss: 0.445139, acc: 61.72%, op_acc: 30.47%] [G loss: 0.883739]\n",
      "epoch:7 step:6170[D loss: 0.437710, acc: 57.03%, op_acc: 31.25%] [G loss: 0.813044]\n",
      "epoch:7 step:6171[D loss: 0.408595, acc: 63.28%, op_acc: 39.84%] [G loss: 0.871343]\n",
      "epoch:7 step:6172[D loss: 0.430603, acc: 66.41%, op_acc: 34.38%] [G loss: 0.844732]\n",
      "epoch:7 step:6173[D loss: 0.445171, acc: 62.50%, op_acc: 35.94%] [G loss: 0.836016]\n",
      "epoch:7 step:6174[D loss: 0.461372, acc: 53.91%, op_acc: 30.47%] [G loss: 0.908367]\n",
      "epoch:7 step:6175[D loss: 0.451133, acc: 57.81%, op_acc: 36.72%] [G loss: 0.873684]\n",
      "epoch:7 step:6176[D loss: 0.448548, acc: 58.59%, op_acc: 33.59%] [G loss: 0.935320]\n",
      "epoch:7 step:6177[D loss: 0.437193, acc: 50.78%, op_acc: 37.50%] [G loss: 0.916631]\n",
      "epoch:7 step:6178[D loss: 0.422665, acc: 65.62%, op_acc: 33.59%] [G loss: 0.839186]\n",
      "epoch:7 step:6179[D loss: 0.427690, acc: 58.59%, op_acc: 31.25%] [G loss: 0.921540]\n",
      "epoch:7 step:6180[D loss: 0.433408, acc: 60.94%, op_acc: 35.16%] [G loss: 0.877862]\n",
      "epoch:7 step:6181[D loss: 0.438132, acc: 64.84%, op_acc: 33.59%] [G loss: 0.860035]\n",
      "epoch:7 step:6182[D loss: 0.434963, acc: 59.38%, op_acc: 34.38%] [G loss: 0.892509]\n",
      "epoch:7 step:6183[D loss: 0.454586, acc: 59.38%, op_acc: 27.34%] [G loss: 0.813218]\n",
      "epoch:7 step:6184[D loss: 0.453989, acc: 55.47%, op_acc: 39.06%] [G loss: 0.863695]\n",
      "epoch:7 step:6185[D loss: 0.455274, acc: 57.03%, op_acc: 34.38%] [G loss: 0.916242]\n",
      "epoch:7 step:6186[D loss: 0.460394, acc: 56.25%, op_acc: 35.16%] [G loss: 0.865772]\n",
      "epoch:7 step:6187[D loss: 0.453677, acc: 57.03%, op_acc: 31.25%] [G loss: 0.939117]\n",
      "epoch:7 step:6188[D loss: 0.429480, acc: 58.59%, op_acc: 34.38%] [G loss: 0.869014]\n",
      "epoch:7 step:6189[D loss: 0.410694, acc: 67.19%, op_acc: 32.81%] [G loss: 0.912199]\n",
      "epoch:7 step:6190[D loss: 0.434642, acc: 61.72%, op_acc: 32.81%] [G loss: 0.844440]\n",
      "epoch:7 step:6191[D loss: 0.443191, acc: 64.84%, op_acc: 25.00%] [G loss: 0.851529]\n",
      "epoch:7 step:6192[D loss: 0.430576, acc: 64.06%, op_acc: 33.59%] [G loss: 0.935475]\n",
      "epoch:7 step:6193[D loss: 0.440537, acc: 58.59%, op_acc: 31.25%] [G loss: 0.816600]\n",
      "epoch:7 step:6194[D loss: 0.448287, acc: 64.84%, op_acc: 28.91%] [G loss: 0.859769]\n",
      "epoch:7 step:6195[D loss: 0.459717, acc: 57.81%, op_acc: 31.25%] [G loss: 0.867986]\n",
      "epoch:7 step:6196[D loss: 0.419319, acc: 63.28%, op_acc: 34.38%] [G loss: 0.856646]\n",
      "epoch:7 step:6197[D loss: 0.452381, acc: 60.94%, op_acc: 33.59%] [G loss: 0.838191]\n",
      "epoch:7 step:6198[D loss: 0.457783, acc: 54.69%, op_acc: 37.50%] [G loss: 0.860823]\n",
      "epoch:7 step:6199[D loss: 0.423726, acc: 61.72%, op_acc: 32.81%] [G loss: 0.918819]\n",
      "epoch:7 step:6200[D loss: 0.433515, acc: 58.59%, op_acc: 37.50%] [G loss: 0.814426]\n",
      "##############\n",
      "[0.86298731 0.85908046 0.84512934 0.78815179 0.80172015 0.83906018\n",
      " 0.88842015 0.81885347 0.78744321 0.83917258]\n",
      "##########\n",
      "epoch:7 step:6201[D loss: 0.454636, acc: 49.22%, op_acc: 35.94%] [G loss: 0.869287]\n",
      "epoch:7 step:6202[D loss: 0.449940, acc: 57.81%, op_acc: 33.59%] [G loss: 0.884292]\n",
      "epoch:7 step:6203[D loss: 0.449422, acc: 63.28%, op_acc: 30.47%] [G loss: 0.840255]\n",
      "epoch:7 step:6204[D loss: 0.430826, acc: 60.94%, op_acc: 33.59%] [G loss: 0.879929]\n",
      "epoch:7 step:6205[D loss: 0.452166, acc: 51.56%, op_acc: 31.25%] [G loss: 0.908319]\n",
      "epoch:7 step:6206[D loss: 0.458033, acc: 51.56%, op_acc: 32.03%] [G loss: 0.853735]\n",
      "epoch:7 step:6207[D loss: 0.435871, acc: 63.28%, op_acc: 36.72%] [G loss: 0.848969]\n",
      "epoch:7 step:6208[D loss: 0.445318, acc: 60.16%, op_acc: 34.38%] [G loss: 0.874189]\n",
      "epoch:7 step:6209[D loss: 0.433215, acc: 62.50%, op_acc: 38.28%] [G loss: 0.844705]\n",
      "epoch:7 step:6210[D loss: 0.462491, acc: 52.34%, op_acc: 32.81%] [G loss: 0.943520]\n",
      "epoch:7 step:6211[D loss: 0.419197, acc: 58.59%, op_acc: 35.16%] [G loss: 0.848103]\n",
      "epoch:7 step:6212[D loss: 0.431936, acc: 55.47%, op_acc: 35.94%] [G loss: 0.879942]\n",
      "epoch:7 step:6213[D loss: 0.466642, acc: 57.03%, op_acc: 28.91%] [G loss: 0.875491]\n",
      "epoch:7 step:6214[D loss: 0.459483, acc: 56.25%, op_acc: 32.81%] [G loss: 0.862371]\n",
      "epoch:7 step:6215[D loss: 0.454267, acc: 56.25%, op_acc: 28.91%] [G loss: 0.933667]\n",
      "epoch:7 step:6216[D loss: 0.471169, acc: 58.59%, op_acc: 32.81%] [G loss: 0.873803]\n",
      "epoch:7 step:6217[D loss: 0.436890, acc: 59.38%, op_acc: 35.16%] [G loss: 0.869403]\n",
      "epoch:7 step:6218[D loss: 0.447939, acc: 67.19%, op_acc: 27.34%] [G loss: 0.921233]\n",
      "epoch:7 step:6219[D loss: 0.405807, acc: 71.88%, op_acc: 32.81%] [G loss: 0.816894]\n",
      "epoch:7 step:6220[D loss: 0.447634, acc: 58.59%, op_acc: 32.03%] [G loss: 0.874830]\n",
      "epoch:7 step:6221[D loss: 0.429874, acc: 60.16%, op_acc: 34.38%] [G loss: 0.858279]\n",
      "epoch:7 step:6222[D loss: 0.437905, acc: 59.38%, op_acc: 39.06%] [G loss: 0.899325]\n",
      "epoch:7 step:6223[D loss: 0.428515, acc: 59.38%, op_acc: 37.50%] [G loss: 0.899637]\n",
      "epoch:7 step:6224[D loss: 0.454364, acc: 60.16%, op_acc: 33.59%] [G loss: 0.935761]\n",
      "epoch:7 step:6225[D loss: 0.442754, acc: 55.47%, op_acc: 39.06%] [G loss: 0.860204]\n",
      "epoch:7 step:6226[D loss: 0.460775, acc: 59.38%, op_acc: 32.03%] [G loss: 0.870581]\n",
      "epoch:7 step:6227[D loss: 0.435791, acc: 59.38%, op_acc: 35.94%] [G loss: 0.937176]\n",
      "epoch:7 step:6228[D loss: 0.422584, acc: 62.50%, op_acc: 44.53%] [G loss: 0.870880]\n",
      "epoch:7 step:6229[D loss: 0.451203, acc: 57.03%, op_acc: 32.81%] [G loss: 0.874688]\n",
      "epoch:7 step:6230[D loss: 0.496094, acc: 51.56%, op_acc: 33.59%] [G loss: 0.838499]\n",
      "epoch:7 step:6231[D loss: 0.422484, acc: 61.72%, op_acc: 40.62%] [G loss: 0.941159]\n",
      "epoch:7 step:6232[D loss: 0.445370, acc: 53.12%, op_acc: 35.16%] [G loss: 0.848075]\n",
      "epoch:7 step:6233[D loss: 0.472015, acc: 54.69%, op_acc: 32.03%] [G loss: 0.879516]\n",
      "epoch:7 step:6234[D loss: 0.448952, acc: 57.81%, op_acc: 37.50%] [G loss: 0.802885]\n",
      "epoch:7 step:6235[D loss: 0.430582, acc: 64.84%, op_acc: 35.94%] [G loss: 0.847830]\n",
      "epoch:7 step:6236[D loss: 0.424815, acc: 64.06%, op_acc: 36.72%] [G loss: 0.803262]\n",
      "epoch:7 step:6237[D loss: 0.440531, acc: 53.91%, op_acc: 37.50%] [G loss: 0.891094]\n",
      "epoch:7 step:6238[D loss: 0.482972, acc: 53.12%, op_acc: 30.47%] [G loss: 0.875205]\n",
      "epoch:7 step:6239[D loss: 0.470692, acc: 56.25%, op_acc: 32.03%] [G loss: 0.839165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6240[D loss: 0.464068, acc: 47.66%, op_acc: 32.03%] [G loss: 0.848862]\n",
      "epoch:7 step:6241[D loss: 0.413447, acc: 63.28%, op_acc: 37.50%] [G loss: 0.918601]\n",
      "epoch:7 step:6242[D loss: 0.428837, acc: 58.59%, op_acc: 34.38%] [G loss: 0.956403]\n",
      "epoch:7 step:6243[D loss: 0.426517, acc: 65.62%, op_acc: 30.47%] [G loss: 0.903444]\n",
      "epoch:7 step:6244[D loss: 0.462922, acc: 62.50%, op_acc: 32.81%] [G loss: 0.928861]\n",
      "epoch:7 step:6245[D loss: 0.416443, acc: 65.62%, op_acc: 33.59%] [G loss: 0.916885]\n",
      "epoch:7 step:6246[D loss: 0.428681, acc: 63.28%, op_acc: 33.59%] [G loss: 0.925070]\n",
      "epoch:7 step:6247[D loss: 0.437218, acc: 56.25%, op_acc: 35.16%] [G loss: 0.927245]\n",
      "epoch:7 step:6248[D loss: 0.472514, acc: 54.69%, op_acc: 32.81%] [G loss: 0.922178]\n",
      "epoch:8 step:6249[D loss: 0.441325, acc: 54.69%, op_acc: 37.50%] [G loss: 0.897079]\n",
      "epoch:8 step:6250[D loss: 0.430876, acc: 57.03%, op_acc: 42.97%] [G loss: 0.927035]\n",
      "##############\n",
      "[0.85490427 0.86252532 0.82974405 0.80832192 0.78684372 0.81420813\n",
      " 0.8604387  0.8430001  0.80254914 0.82335226]\n",
      "##########\n",
      "epoch:8 step:6251[D loss: 0.476318, acc: 51.56%, op_acc: 33.59%] [G loss: 0.854743]\n",
      "epoch:8 step:6252[D loss: 0.416645, acc: 66.41%, op_acc: 39.06%] [G loss: 0.865502]\n",
      "epoch:8 step:6253[D loss: 0.453349, acc: 54.69%, op_acc: 34.38%] [G loss: 0.846069]\n",
      "epoch:8 step:6254[D loss: 0.451636, acc: 54.69%, op_acc: 33.59%] [G loss: 0.863123]\n",
      "epoch:8 step:6255[D loss: 0.444645, acc: 57.03%, op_acc: 32.03%] [G loss: 0.884446]\n",
      "epoch:8 step:6256[D loss: 0.448156, acc: 60.94%, op_acc: 35.16%] [G loss: 0.909197]\n",
      "epoch:8 step:6257[D loss: 0.441225, acc: 57.03%, op_acc: 36.72%] [G loss: 0.906865]\n",
      "epoch:8 step:6258[D loss: 0.447624, acc: 58.59%, op_acc: 32.03%] [G loss: 0.944046]\n",
      "epoch:8 step:6259[D loss: 0.474408, acc: 49.22%, op_acc: 39.06%] [G loss: 0.873878]\n",
      "epoch:8 step:6260[D loss: 0.408191, acc: 72.66%, op_acc: 34.38%] [G loss: 0.884527]\n",
      "epoch:8 step:6261[D loss: 0.451567, acc: 59.38%, op_acc: 32.03%] [G loss: 0.872448]\n",
      "epoch:8 step:6262[D loss: 0.443697, acc: 61.72%, op_acc: 32.81%] [G loss: 0.912317]\n",
      "epoch:8 step:6263[D loss: 0.447368, acc: 59.38%, op_acc: 30.47%] [G loss: 0.820891]\n",
      "epoch:8 step:6264[D loss: 0.416067, acc: 62.50%, op_acc: 35.94%] [G loss: 0.852265]\n",
      "epoch:8 step:6265[D loss: 0.430517, acc: 64.84%, op_acc: 38.28%] [G loss: 0.896467]\n",
      "epoch:8 step:6266[D loss: 0.420733, acc: 69.53%, op_acc: 36.72%] [G loss: 0.876985]\n",
      "epoch:8 step:6267[D loss: 0.452803, acc: 54.69%, op_acc: 32.03%] [G loss: 0.885344]\n",
      "epoch:8 step:6268[D loss: 0.443767, acc: 54.69%, op_acc: 28.12%] [G loss: 0.839098]\n",
      "epoch:8 step:6269[D loss: 0.478377, acc: 55.47%, op_acc: 28.91%] [G loss: 0.849391]\n",
      "epoch:8 step:6270[D loss: 0.426701, acc: 64.84%, op_acc: 36.72%] [G loss: 0.859619]\n",
      "epoch:8 step:6271[D loss: 0.431804, acc: 60.94%, op_acc: 35.94%] [G loss: 0.913386]\n",
      "epoch:8 step:6272[D loss: 0.422348, acc: 65.62%, op_acc: 32.03%] [G loss: 0.837008]\n",
      "epoch:8 step:6273[D loss: 0.462955, acc: 60.16%, op_acc: 35.16%] [G loss: 0.904975]\n",
      "epoch:8 step:6274[D loss: 0.420205, acc: 60.16%, op_acc: 39.06%] [G loss: 0.821997]\n",
      "epoch:8 step:6275[D loss: 0.446946, acc: 59.38%, op_acc: 32.81%] [G loss: 0.911452]\n",
      "epoch:8 step:6276[D loss: 0.423396, acc: 57.81%, op_acc: 37.50%] [G loss: 0.895688]\n",
      "epoch:8 step:6277[D loss: 0.443455, acc: 58.59%, op_acc: 36.72%] [G loss: 0.916337]\n",
      "epoch:8 step:6278[D loss: 0.414497, acc: 66.41%, op_acc: 36.72%] [G loss: 0.932538]\n",
      "epoch:8 step:6279[D loss: 0.445918, acc: 55.47%, op_acc: 36.72%] [G loss: 0.934527]\n",
      "epoch:8 step:6280[D loss: 0.443210, acc: 60.16%, op_acc: 34.38%] [G loss: 0.888845]\n",
      "epoch:8 step:6281[D loss: 0.415418, acc: 60.94%, op_acc: 45.31%] [G loss: 0.915839]\n",
      "epoch:8 step:6282[D loss: 0.440433, acc: 55.47%, op_acc: 34.38%] [G loss: 0.851192]\n",
      "epoch:8 step:6283[D loss: 0.451680, acc: 60.94%, op_acc: 32.81%] [G loss: 0.889708]\n",
      "epoch:8 step:6284[D loss: 0.442180, acc: 61.72%, op_acc: 36.72%] [G loss: 0.901770]\n",
      "epoch:8 step:6285[D loss: 0.439128, acc: 59.38%, op_acc: 28.91%] [G loss: 0.871563]\n",
      "epoch:8 step:6286[D loss: 0.456845, acc: 60.16%, op_acc: 30.47%] [G loss: 0.851555]\n",
      "epoch:8 step:6287[D loss: 0.443880, acc: 57.03%, op_acc: 39.84%] [G loss: 0.901648]\n",
      "epoch:8 step:6288[D loss: 0.411222, acc: 66.41%, op_acc: 42.97%] [G loss: 0.935583]\n",
      "epoch:8 step:6289[D loss: 0.419679, acc: 60.94%, op_acc: 32.81%] [G loss: 0.971796]\n",
      "epoch:8 step:6290[D loss: 0.423856, acc: 60.16%, op_acc: 38.28%] [G loss: 0.909865]\n",
      "epoch:8 step:6291[D loss: 0.443845, acc: 61.72%, op_acc: 32.03%] [G loss: 0.871706]\n",
      "epoch:8 step:6292[D loss: 0.454376, acc: 52.34%, op_acc: 34.38%] [G loss: 0.899630]\n",
      "epoch:8 step:6293[D loss: 0.448330, acc: 62.50%, op_acc: 33.59%] [G loss: 0.800378]\n",
      "epoch:8 step:6294[D loss: 0.442630, acc: 60.16%, op_acc: 37.50%] [G loss: 0.881321]\n",
      "epoch:8 step:6295[D loss: 0.467242, acc: 60.16%, op_acc: 27.34%] [G loss: 0.822449]\n",
      "epoch:8 step:6296[D loss: 0.525441, acc: 51.56%, op_acc: 26.56%] [G loss: 0.909516]\n",
      "epoch:8 step:6297[D loss: 0.419285, acc: 60.94%, op_acc: 36.72%] [G loss: 0.843038]\n",
      "epoch:8 step:6298[D loss: 0.452727, acc: 57.81%, op_acc: 35.16%] [G loss: 0.867853]\n",
      "epoch:8 step:6299[D loss: 0.419213, acc: 63.28%, op_acc: 40.62%] [G loss: 0.822111]\n",
      "epoch:8 step:6300[D loss: 0.460445, acc: 52.34%, op_acc: 36.72%] [G loss: 0.849531]\n",
      "##############\n",
      "[0.86277364 0.87094138 0.81129589 0.80408503 0.78372391 0.82831345\n",
      " 0.86344295 0.84527325 0.82919561 0.82582666]\n",
      "##########\n",
      "epoch:8 step:6301[D loss: 0.486540, acc: 55.47%, op_acc: 28.91%] [G loss: 0.837919]\n",
      "epoch:8 step:6302[D loss: 0.485714, acc: 50.78%, op_acc: 32.03%] [G loss: 0.812664]\n",
      "epoch:8 step:6303[D loss: 0.458612, acc: 44.53%, op_acc: 39.06%] [G loss: 0.807164]\n",
      "epoch:8 step:6304[D loss: 0.440991, acc: 55.47%, op_acc: 28.91%] [G loss: 0.881254]\n",
      "epoch:8 step:6305[D loss: 0.437803, acc: 57.81%, op_acc: 39.84%] [G loss: 0.904460]\n",
      "epoch:8 step:6306[D loss: 0.424317, acc: 64.06%, op_acc: 36.72%] [G loss: 0.850875]\n",
      "epoch:8 step:6307[D loss: 0.441254, acc: 57.81%, op_acc: 30.47%] [G loss: 0.895269]\n",
      "epoch:8 step:6308[D loss: 0.416806, acc: 64.84%, op_acc: 36.72%] [G loss: 0.927662]\n",
      "epoch:8 step:6309[D loss: 0.444497, acc: 60.16%, op_acc: 36.72%] [G loss: 0.963590]\n",
      "epoch:8 step:6310[D loss: 0.439243, acc: 64.06%, op_acc: 38.28%] [G loss: 0.867602]\n",
      "epoch:8 step:6311[D loss: 0.430460, acc: 65.62%, op_acc: 33.59%] [G loss: 0.924741]\n",
      "epoch:8 step:6312[D loss: 0.422735, acc: 64.84%, op_acc: 36.72%] [G loss: 0.932675]\n",
      "epoch:8 step:6313[D loss: 0.474634, acc: 54.69%, op_acc: 34.38%] [G loss: 0.947719]\n",
      "epoch:8 step:6314[D loss: 0.435666, acc: 59.38%, op_acc: 30.47%] [G loss: 0.866442]\n",
      "epoch:8 step:6315[D loss: 0.433817, acc: 67.19%, op_acc: 35.94%] [G loss: 0.886200]\n",
      "epoch:8 step:6316[D loss: 0.460735, acc: 54.69%, op_acc: 35.94%] [G loss: 0.844850]\n",
      "epoch:8 step:6317[D loss: 0.421313, acc: 62.50%, op_acc: 39.06%] [G loss: 0.974990]\n",
      "epoch:8 step:6318[D loss: 0.421135, acc: 64.84%, op_acc: 33.59%] [G loss: 0.946100]\n",
      "epoch:8 step:6319[D loss: 0.476462, acc: 53.12%, op_acc: 27.34%] [G loss: 0.900046]\n",
      "epoch:8 step:6320[D loss: 0.436465, acc: 54.69%, op_acc: 39.06%] [G loss: 0.807869]\n",
      "epoch:8 step:6321[D loss: 0.434938, acc: 57.81%, op_acc: 36.72%] [G loss: 0.887026]\n",
      "epoch:8 step:6322[D loss: 0.417751, acc: 62.50%, op_acc: 38.28%] [G loss: 0.882764]\n",
      "epoch:8 step:6323[D loss: 0.437319, acc: 65.62%, op_acc: 32.03%] [G loss: 0.884192]\n",
      "epoch:8 step:6324[D loss: 0.487872, acc: 54.69%, op_acc: 28.91%] [G loss: 0.916031]\n",
      "epoch:8 step:6325[D loss: 0.431813, acc: 61.72%, op_acc: 31.25%] [G loss: 0.914873]\n",
      "epoch:8 step:6326[D loss: 0.461475, acc: 62.50%, op_acc: 28.91%] [G loss: 0.867792]\n",
      "epoch:8 step:6327[D loss: 0.461537, acc: 53.12%, op_acc: 29.69%] [G loss: 0.894320]\n",
      "epoch:8 step:6328[D loss: 0.477896, acc: 57.03%, op_acc: 29.69%] [G loss: 0.885328]\n",
      "epoch:8 step:6329[D loss: 0.471315, acc: 57.03%, op_acc: 34.38%] [G loss: 0.859166]\n",
      "epoch:8 step:6330[D loss: 0.442288, acc: 58.59%, op_acc: 31.25%] [G loss: 0.880249]\n",
      "epoch:8 step:6331[D loss: 0.471680, acc: 61.72%, op_acc: 29.69%] [G loss: 0.848669]\n",
      "epoch:8 step:6332[D loss: 0.462734, acc: 52.34%, op_acc: 40.62%] [G loss: 0.897050]\n",
      "epoch:8 step:6333[D loss: 0.491921, acc: 46.88%, op_acc: 32.03%] [G loss: 0.886764]\n",
      "epoch:8 step:6334[D loss: 0.443613, acc: 60.16%, op_acc: 39.84%] [G loss: 0.874942]\n",
      "epoch:8 step:6335[D loss: 0.435080, acc: 59.38%, op_acc: 33.59%] [G loss: 0.868059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6336[D loss: 0.464626, acc: 57.81%, op_acc: 29.69%] [G loss: 0.887001]\n",
      "epoch:8 step:6337[D loss: 0.475228, acc: 51.56%, op_acc: 29.69%] [G loss: 0.818875]\n",
      "epoch:8 step:6338[D loss: 0.420192, acc: 60.16%, op_acc: 37.50%] [G loss: 0.867501]\n",
      "epoch:8 step:6339[D loss: 0.463492, acc: 53.12%, op_acc: 34.38%] [G loss: 0.796814]\n",
      "epoch:8 step:6340[D loss: 0.460015, acc: 55.47%, op_acc: 28.12%] [G loss: 0.796202]\n",
      "epoch:8 step:6341[D loss: 0.435564, acc: 54.69%, op_acc: 36.72%] [G loss: 0.888321]\n",
      "epoch:8 step:6342[D loss: 0.444313, acc: 61.72%, op_acc: 35.16%] [G loss: 0.853908]\n",
      "epoch:8 step:6343[D loss: 0.430091, acc: 58.59%, op_acc: 32.81%] [G loss: 0.780341]\n",
      "epoch:8 step:6344[D loss: 0.450333, acc: 59.38%, op_acc: 31.25%] [G loss: 0.904998]\n",
      "epoch:8 step:6345[D loss: 0.432894, acc: 59.38%, op_acc: 34.38%] [G loss: 0.934948]\n",
      "epoch:8 step:6346[D loss: 0.449658, acc: 57.81%, op_acc: 30.47%] [G loss: 0.877904]\n",
      "epoch:8 step:6347[D loss: 0.458486, acc: 53.91%, op_acc: 31.25%] [G loss: 0.840927]\n",
      "epoch:8 step:6348[D loss: 0.419999, acc: 59.38%, op_acc: 40.62%] [G loss: 0.934825]\n",
      "epoch:8 step:6349[D loss: 0.429006, acc: 62.50%, op_acc: 37.50%] [G loss: 0.823083]\n",
      "epoch:8 step:6350[D loss: 0.426960, acc: 62.50%, op_acc: 39.84%] [G loss: 0.904073]\n",
      "##############\n",
      "[0.87565702 0.86959    0.81772941 0.8010798  0.8263895  0.80730284\n",
      " 0.87337098 0.82630266 0.81638874 0.83976634]\n",
      "##########\n",
      "epoch:8 step:6351[D loss: 0.431728, acc: 67.97%, op_acc: 39.06%] [G loss: 0.895684]\n",
      "epoch:8 step:6352[D loss: 0.454763, acc: 59.38%, op_acc: 32.81%] [G loss: 0.890821]\n",
      "epoch:8 step:6353[D loss: 0.441064, acc: 61.72%, op_acc: 30.47%] [G loss: 0.884016]\n",
      "epoch:8 step:6354[D loss: 0.442681, acc: 53.12%, op_acc: 32.03%] [G loss: 0.884830]\n",
      "epoch:8 step:6355[D loss: 0.473517, acc: 56.25%, op_acc: 29.69%] [G loss: 0.840785]\n",
      "epoch:8 step:6356[D loss: 0.472196, acc: 52.34%, op_acc: 32.03%] [G loss: 0.833242]\n",
      "epoch:8 step:6357[D loss: 0.429721, acc: 64.84%, op_acc: 35.94%] [G loss: 0.877517]\n",
      "epoch:8 step:6358[D loss: 0.422903, acc: 62.50%, op_acc: 38.28%] [G loss: 0.845666]\n",
      "epoch:8 step:6359[D loss: 0.445789, acc: 61.72%, op_acc: 30.47%] [G loss: 0.924077]\n",
      "epoch:8 step:6360[D loss: 0.440317, acc: 60.94%, op_acc: 34.38%] [G loss: 0.903834]\n",
      "epoch:8 step:6361[D loss: 0.414646, acc: 67.97%, op_acc: 34.38%] [G loss: 0.929247]\n",
      "epoch:8 step:6362[D loss: 0.428955, acc: 54.69%, op_acc: 40.62%] [G loss: 0.983325]\n",
      "epoch:8 step:6363[D loss: 0.441285, acc: 57.03%, op_acc: 35.16%] [G loss: 0.876948]\n",
      "epoch:8 step:6364[D loss: 0.461337, acc: 64.84%, op_acc: 27.34%] [G loss: 0.865635]\n",
      "epoch:8 step:6365[D loss: 0.438958, acc: 53.12%, op_acc: 36.72%] [G loss: 0.810431]\n",
      "epoch:8 step:6366[D loss: 0.429312, acc: 64.84%, op_acc: 34.38%] [G loss: 0.890019]\n",
      "epoch:8 step:6367[D loss: 0.420511, acc: 63.28%, op_acc: 34.38%] [G loss: 0.886023]\n",
      "epoch:8 step:6368[D loss: 0.451494, acc: 53.91%, op_acc: 35.16%] [G loss: 0.831508]\n",
      "epoch:8 step:6369[D loss: 0.437310, acc: 65.62%, op_acc: 34.38%] [G loss: 0.933946]\n",
      "epoch:8 step:6370[D loss: 0.468678, acc: 53.91%, op_acc: 31.25%] [G loss: 0.917679]\n",
      "epoch:8 step:6371[D loss: 0.436529, acc: 65.62%, op_acc: 27.34%] [G loss: 0.906898]\n",
      "epoch:8 step:6372[D loss: 0.423017, acc: 55.47%, op_acc: 35.94%] [G loss: 0.921557]\n",
      "epoch:8 step:6373[D loss: 0.456315, acc: 60.16%, op_acc: 29.69%] [G loss: 0.906651]\n",
      "epoch:8 step:6374[D loss: 0.451703, acc: 60.16%, op_acc: 31.25%] [G loss: 0.911151]\n",
      "epoch:8 step:6375[D loss: 0.443327, acc: 64.06%, op_acc: 34.38%] [G loss: 0.879156]\n",
      "epoch:8 step:6376[D loss: 0.435885, acc: 60.16%, op_acc: 37.50%] [G loss: 0.921266]\n",
      "epoch:8 step:6377[D loss: 0.472243, acc: 57.03%, op_acc: 38.28%] [G loss: 0.904737]\n",
      "epoch:8 step:6378[D loss: 0.425683, acc: 62.50%, op_acc: 35.16%] [G loss: 0.841460]\n",
      "epoch:8 step:6379[D loss: 0.441627, acc: 60.94%, op_acc: 32.03%] [G loss: 0.932206]\n",
      "epoch:8 step:6380[D loss: 0.397927, acc: 67.19%, op_acc: 38.28%] [G loss: 0.943249]\n",
      "epoch:8 step:6381[D loss: 0.468156, acc: 61.72%, op_acc: 31.25%] [G loss: 0.914760]\n",
      "epoch:8 step:6382[D loss: 0.425726, acc: 61.72%, op_acc: 35.16%] [G loss: 0.871233]\n",
      "epoch:8 step:6383[D loss: 0.482110, acc: 44.53%, op_acc: 35.94%] [G loss: 0.794279]\n",
      "epoch:8 step:6384[D loss: 0.419654, acc: 62.50%, op_acc: 38.28%] [G loss: 0.927235]\n",
      "epoch:8 step:6385[D loss: 0.441354, acc: 59.38%, op_acc: 40.62%] [G loss: 0.813883]\n",
      "epoch:8 step:6386[D loss: 0.432071, acc: 64.06%, op_acc: 32.03%] [G loss: 0.840905]\n",
      "epoch:8 step:6387[D loss: 0.416623, acc: 65.62%, op_acc: 37.50%] [G loss: 0.931733]\n",
      "epoch:8 step:6388[D loss: 0.466882, acc: 61.72%, op_acc: 28.91%] [G loss: 0.924374]\n",
      "epoch:8 step:6389[D loss: 0.467432, acc: 58.59%, op_acc: 28.91%] [G loss: 0.979597]\n",
      "epoch:8 step:6390[D loss: 0.407594, acc: 67.97%, op_acc: 38.28%] [G loss: 0.982816]\n",
      "epoch:8 step:6391[D loss: 0.461270, acc: 54.69%, op_acc: 32.81%] [G loss: 0.907169]\n",
      "epoch:8 step:6392[D loss: 0.439496, acc: 60.16%, op_acc: 35.16%] [G loss: 0.875896]\n",
      "epoch:8 step:6393[D loss: 0.431452, acc: 65.62%, op_acc: 34.38%] [G loss: 0.885749]\n",
      "epoch:8 step:6394[D loss: 0.409540, acc: 68.75%, op_acc: 34.38%] [G loss: 0.871547]\n",
      "epoch:8 step:6395[D loss: 0.417563, acc: 57.03%, op_acc: 35.16%] [G loss: 0.984020]\n",
      "epoch:8 step:6396[D loss: 0.438815, acc: 58.59%, op_acc: 37.50%] [G loss: 0.857459]\n",
      "epoch:8 step:6397[D loss: 0.424898, acc: 62.50%, op_acc: 37.50%] [G loss: 0.958524]\n",
      "epoch:8 step:6398[D loss: 0.445989, acc: 61.72%, op_acc: 33.59%] [G loss: 0.788541]\n",
      "epoch:8 step:6399[D loss: 0.485555, acc: 47.66%, op_acc: 35.16%] [G loss: 0.847212]\n",
      "epoch:8 step:6400[D loss: 0.447041, acc: 55.47%, op_acc: 32.81%] [G loss: 0.894422]\n",
      "##############\n",
      "[0.86331602 0.86154547 0.81630917 0.80362902 0.809639   0.81815607\n",
      " 0.87175572 0.82580603 0.80117249 0.82587788]\n",
      "##########\n",
      "epoch:8 step:6401[D loss: 0.459844, acc: 57.81%, op_acc: 33.59%] [G loss: 0.892694]\n",
      "epoch:8 step:6402[D loss: 0.455412, acc: 54.69%, op_acc: 35.16%] [G loss: 0.842413]\n",
      "epoch:8 step:6403[D loss: 0.447401, acc: 64.06%, op_acc: 33.59%] [G loss: 0.870911]\n",
      "epoch:8 step:6404[D loss: 0.489463, acc: 41.41%, op_acc: 29.69%] [G loss: 0.787602]\n",
      "epoch:8 step:6405[D loss: 0.464310, acc: 49.22%, op_acc: 33.59%] [G loss: 0.886781]\n",
      "epoch:8 step:6406[D loss: 0.441321, acc: 56.25%, op_acc: 38.28%] [G loss: 0.897395]\n",
      "epoch:8 step:6407[D loss: 0.453888, acc: 62.50%, op_acc: 32.03%] [G loss: 0.869804]\n",
      "epoch:8 step:6408[D loss: 0.471651, acc: 58.59%, op_acc: 25.78%] [G loss: 0.881476]\n",
      "epoch:8 step:6409[D loss: 0.458477, acc: 52.34%, op_acc: 39.06%] [G loss: 0.955897]\n",
      "epoch:8 step:6410[D loss: 0.422747, acc: 61.72%, op_acc: 37.50%] [G loss: 0.948313]\n",
      "epoch:8 step:6411[D loss: 0.469733, acc: 53.12%, op_acc: 35.16%] [G loss: 0.896656]\n",
      "epoch:8 step:6412[D loss: 0.472854, acc: 54.69%, op_acc: 30.47%] [G loss: 0.835145]\n",
      "epoch:8 step:6413[D loss: 0.437894, acc: 52.34%, op_acc: 37.50%] [G loss: 0.899788]\n",
      "epoch:8 step:6414[D loss: 0.470292, acc: 57.81%, op_acc: 32.03%] [G loss: 0.853219]\n",
      "epoch:8 step:6415[D loss: 0.436292, acc: 53.91%, op_acc: 40.62%] [G loss: 0.828746]\n",
      "epoch:8 step:6416[D loss: 0.419487, acc: 62.50%, op_acc: 35.16%] [G loss: 1.003515]\n",
      "epoch:8 step:6417[D loss: 0.453394, acc: 55.47%, op_acc: 35.94%] [G loss: 0.792304]\n",
      "epoch:8 step:6418[D loss: 0.439423, acc: 59.38%, op_acc: 37.50%] [G loss: 0.880588]\n",
      "epoch:8 step:6419[D loss: 0.447342, acc: 65.62%, op_acc: 26.56%] [G loss: 0.827981]\n",
      "epoch:8 step:6420[D loss: 0.439320, acc: 59.38%, op_acc: 32.81%] [G loss: 0.837344]\n",
      "epoch:8 step:6421[D loss: 0.443811, acc: 63.28%, op_acc: 34.38%] [G loss: 0.862672]\n",
      "epoch:8 step:6422[D loss: 0.470960, acc: 52.34%, op_acc: 32.03%] [G loss: 0.854175]\n",
      "epoch:8 step:6423[D loss: 0.433266, acc: 56.25%, op_acc: 32.03%] [G loss: 0.932383]\n",
      "epoch:8 step:6424[D loss: 0.427656, acc: 57.81%, op_acc: 32.81%] [G loss: 0.909641]\n",
      "epoch:8 step:6425[D loss: 0.425568, acc: 59.38%, op_acc: 32.03%] [G loss: 0.821466]\n",
      "epoch:8 step:6426[D loss: 0.423106, acc: 67.97%, op_acc: 34.38%] [G loss: 0.909126]\n",
      "epoch:8 step:6427[D loss: 0.425385, acc: 64.06%, op_acc: 35.16%] [G loss: 0.878894]\n",
      "epoch:8 step:6428[D loss: 0.467353, acc: 58.59%, op_acc: 32.81%] [G loss: 0.835349]\n",
      "epoch:8 step:6429[D loss: 0.408926, acc: 66.41%, op_acc: 35.94%] [G loss: 0.922233]\n",
      "epoch:8 step:6430[D loss: 0.434199, acc: 65.62%, op_acc: 35.16%] [G loss: 0.898344]\n",
      "epoch:8 step:6431[D loss: 0.429562, acc: 66.41%, op_acc: 35.16%] [G loss: 0.891844]\n",
      "epoch:8 step:6432[D loss: 0.455263, acc: 58.59%, op_acc: 34.38%] [G loss: 0.921665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6433[D loss: 0.455453, acc: 58.59%, op_acc: 31.25%] [G loss: 0.888734]\n",
      "epoch:8 step:6434[D loss: 0.459662, acc: 56.25%, op_acc: 29.69%] [G loss: 0.851281]\n",
      "epoch:8 step:6435[D loss: 0.440392, acc: 60.94%, op_acc: 32.03%] [G loss: 0.888074]\n",
      "epoch:8 step:6436[D loss: 0.412243, acc: 60.16%, op_acc: 40.62%] [G loss: 0.893931]\n",
      "epoch:8 step:6437[D loss: 0.447862, acc: 57.03%, op_acc: 34.38%] [G loss: 0.841084]\n",
      "epoch:8 step:6438[D loss: 0.443615, acc: 59.38%, op_acc: 33.59%] [G loss: 0.852893]\n",
      "epoch:8 step:6439[D loss: 0.416483, acc: 67.19%, op_acc: 38.28%] [G loss: 0.912372]\n",
      "epoch:8 step:6440[D loss: 0.421136, acc: 62.50%, op_acc: 32.81%] [G loss: 0.843905]\n",
      "epoch:8 step:6441[D loss: 0.466602, acc: 58.59%, op_acc: 33.59%] [G loss: 0.886425]\n",
      "epoch:8 step:6442[D loss: 0.468256, acc: 60.16%, op_acc: 34.38%] [G loss: 0.901781]\n",
      "epoch:8 step:6443[D loss: 0.454929, acc: 60.94%, op_acc: 33.59%] [G loss: 0.897938]\n",
      "epoch:8 step:6444[D loss: 0.445664, acc: 60.16%, op_acc: 31.25%] [G loss: 0.910883]\n",
      "epoch:8 step:6445[D loss: 0.478507, acc: 48.44%, op_acc: 32.81%] [G loss: 0.849069]\n",
      "epoch:8 step:6446[D loss: 0.462122, acc: 54.69%, op_acc: 34.38%] [G loss: 0.848422]\n",
      "epoch:8 step:6447[D loss: 0.457951, acc: 53.12%, op_acc: 32.81%] [G loss: 0.885182]\n",
      "epoch:8 step:6448[D loss: 0.443143, acc: 62.50%, op_acc: 32.03%] [G loss: 0.893589]\n",
      "epoch:8 step:6449[D loss: 0.445693, acc: 55.47%, op_acc: 34.38%] [G loss: 0.914985]\n",
      "epoch:8 step:6450[D loss: 0.456093, acc: 53.91%, op_acc: 28.91%] [G loss: 0.826968]\n",
      "##############\n",
      "[0.84678779 0.86218099 0.82104652 0.79008403 0.77044814 0.82809651\n",
      " 0.90191137 0.80916596 0.82725197 0.8253003 ]\n",
      "##########\n",
      "epoch:8 step:6451[D loss: 0.457185, acc: 61.72%, op_acc: 32.03%] [G loss: 0.857895]\n",
      "epoch:8 step:6452[D loss: 0.482291, acc: 58.59%, op_acc: 34.38%] [G loss: 0.826719]\n",
      "epoch:8 step:6453[D loss: 0.465709, acc: 55.47%, op_acc: 32.81%] [G loss: 0.815348]\n",
      "epoch:8 step:6454[D loss: 0.466018, acc: 57.81%, op_acc: 34.38%] [G loss: 0.911295]\n",
      "epoch:8 step:6455[D loss: 0.466026, acc: 53.12%, op_acc: 34.38%] [G loss: 0.843728]\n",
      "epoch:8 step:6456[D loss: 0.443515, acc: 60.94%, op_acc: 28.91%] [G loss: 0.872280]\n",
      "epoch:8 step:6457[D loss: 0.435396, acc: 57.81%, op_acc: 40.62%] [G loss: 0.806356]\n",
      "epoch:8 step:6458[D loss: 0.458629, acc: 58.59%, op_acc: 32.03%] [G loss: 0.919164]\n",
      "epoch:8 step:6459[D loss: 0.408383, acc: 66.41%, op_acc: 45.31%] [G loss: 0.903141]\n",
      "epoch:8 step:6460[D loss: 0.452889, acc: 57.81%, op_acc: 34.38%] [G loss: 0.805138]\n",
      "epoch:8 step:6461[D loss: 0.448299, acc: 59.38%, op_acc: 40.62%] [G loss: 0.870660]\n",
      "epoch:8 step:6462[D loss: 0.433648, acc: 67.97%, op_acc: 36.72%] [G loss: 0.946698]\n",
      "epoch:8 step:6463[D loss: 0.450624, acc: 64.06%, op_acc: 28.91%] [G loss: 0.930887]\n",
      "epoch:8 step:6464[D loss: 0.460878, acc: 54.69%, op_acc: 29.69%] [G loss: 0.882092]\n",
      "epoch:8 step:6465[D loss: 0.431836, acc: 59.38%, op_acc: 36.72%] [G loss: 0.866068]\n",
      "epoch:8 step:6466[D loss: 0.448003, acc: 60.16%, op_acc: 36.72%] [G loss: 0.816805]\n",
      "epoch:8 step:6467[D loss: 0.427074, acc: 56.25%, op_acc: 38.28%] [G loss: 0.861579]\n",
      "epoch:8 step:6468[D loss: 0.430853, acc: 63.28%, op_acc: 32.81%] [G loss: 0.906362]\n",
      "epoch:8 step:6469[D loss: 0.437747, acc: 66.41%, op_acc: 34.38%] [G loss: 0.879038]\n",
      "epoch:8 step:6470[D loss: 0.478517, acc: 58.59%, op_acc: 25.78%] [G loss: 0.894033]\n",
      "epoch:8 step:6471[D loss: 0.444305, acc: 60.94%, op_acc: 34.38%] [G loss: 0.824187]\n",
      "epoch:8 step:6472[D loss: 0.457426, acc: 59.38%, op_acc: 28.12%] [G loss: 0.856223]\n",
      "epoch:8 step:6473[D loss: 0.447370, acc: 55.47%, op_acc: 36.72%] [G loss: 0.815591]\n",
      "epoch:8 step:6474[D loss: 0.434799, acc: 60.94%, op_acc: 35.16%] [G loss: 0.858835]\n",
      "epoch:8 step:6475[D loss: 0.432901, acc: 63.28%, op_acc: 30.47%] [G loss: 0.896078]\n",
      "epoch:8 step:6476[D loss: 0.410855, acc: 62.50%, op_acc: 37.50%] [G loss: 0.970324]\n",
      "epoch:8 step:6477[D loss: 0.447881, acc: 54.69%, op_acc: 32.81%] [G loss: 0.856009]\n",
      "epoch:8 step:6478[D loss: 0.475386, acc: 55.47%, op_acc: 31.25%] [G loss: 0.893352]\n",
      "epoch:8 step:6479[D loss: 0.399865, acc: 67.97%, op_acc: 37.50%] [G loss: 0.832828]\n",
      "epoch:8 step:6480[D loss: 0.451486, acc: 58.59%, op_acc: 33.59%] [G loss: 0.917023]\n",
      "epoch:8 step:6481[D loss: 0.428185, acc: 64.84%, op_acc: 32.03%] [G loss: 0.920953]\n",
      "epoch:8 step:6482[D loss: 0.464897, acc: 53.91%, op_acc: 30.47%] [G loss: 0.901983]\n",
      "epoch:8 step:6483[D loss: 0.433539, acc: 61.72%, op_acc: 39.06%] [G loss: 0.834055]\n",
      "epoch:8 step:6484[D loss: 0.485035, acc: 53.12%, op_acc: 28.12%] [G loss: 0.868155]\n",
      "epoch:8 step:6485[D loss: 0.454759, acc: 53.91%, op_acc: 33.59%] [G loss: 0.818665]\n",
      "epoch:8 step:6486[D loss: 0.452631, acc: 54.69%, op_acc: 31.25%] [G loss: 0.946880]\n",
      "epoch:8 step:6487[D loss: 0.435896, acc: 59.38%, op_acc: 33.59%] [G loss: 0.898364]\n",
      "epoch:8 step:6488[D loss: 0.464932, acc: 52.34%, op_acc: 28.12%] [G loss: 0.876349]\n",
      "epoch:8 step:6489[D loss: 0.460707, acc: 57.81%, op_acc: 33.59%] [G loss: 0.875949]\n",
      "epoch:8 step:6490[D loss: 0.436313, acc: 60.94%, op_acc: 33.59%] [G loss: 0.909464]\n",
      "epoch:8 step:6491[D loss: 0.431136, acc: 60.94%, op_acc: 39.84%] [G loss: 0.857306]\n",
      "epoch:8 step:6492[D loss: 0.484547, acc: 53.91%, op_acc: 28.12%] [G loss: 0.797231]\n",
      "epoch:8 step:6493[D loss: 0.448357, acc: 62.50%, op_acc: 33.59%] [G loss: 0.907428]\n",
      "epoch:8 step:6494[D loss: 0.459730, acc: 63.28%, op_acc: 31.25%] [G loss: 0.896331]\n",
      "epoch:8 step:6495[D loss: 0.435429, acc: 57.81%, op_acc: 38.28%] [G loss: 0.925396]\n",
      "epoch:8 step:6496[D loss: 0.453207, acc: 60.94%, op_acc: 35.16%] [G loss: 0.868780]\n",
      "epoch:8 step:6497[D loss: 0.481525, acc: 53.91%, op_acc: 28.91%] [G loss: 0.832652]\n",
      "epoch:8 step:6498[D loss: 0.482977, acc: 49.22%, op_acc: 30.47%] [G loss: 0.859367]\n",
      "epoch:8 step:6499[D loss: 0.459177, acc: 48.44%, op_acc: 35.94%] [G loss: 0.839735]\n",
      "epoch:8 step:6500[D loss: 0.430737, acc: 60.94%, op_acc: 39.84%] [G loss: 0.894689]\n",
      "##############\n",
      "[0.85700152 0.84651534 0.82729941 0.80784709 0.79311649 0.82371878\n",
      " 0.86359778 0.82761067 0.8091072  0.81970377]\n",
      "##########\n",
      "epoch:8 step:6501[D loss: 0.471827, acc: 58.59%, op_acc: 26.56%] [G loss: 0.847790]\n",
      "epoch:8 step:6502[D loss: 0.471552, acc: 56.25%, op_acc: 28.91%] [G loss: 0.877657]\n",
      "epoch:8 step:6503[D loss: 0.422762, acc: 63.28%, op_acc: 38.28%] [G loss: 0.848136]\n",
      "epoch:8 step:6504[D loss: 0.432212, acc: 66.41%, op_acc: 32.03%] [G loss: 0.849842]\n",
      "epoch:8 step:6505[D loss: 0.438111, acc: 68.75%, op_acc: 25.78%] [G loss: 0.876117]\n",
      "epoch:8 step:6506[D loss: 0.421227, acc: 61.72%, op_acc: 42.97%] [G loss: 0.880352]\n",
      "epoch:8 step:6507[D loss: 0.456584, acc: 59.38%, op_acc: 30.47%] [G loss: 0.935293]\n",
      "epoch:8 step:6508[D loss: 0.451379, acc: 64.06%, op_acc: 32.03%] [G loss: 0.951830]\n",
      "epoch:8 step:6509[D loss: 0.424712, acc: 57.03%, op_acc: 37.50%] [G loss: 0.985258]\n",
      "epoch:8 step:6510[D loss: 0.440058, acc: 61.72%, op_acc: 32.03%] [G loss: 0.986891]\n",
      "epoch:8 step:6511[D loss: 0.455715, acc: 57.81%, op_acc: 32.03%] [G loss: 0.955051]\n",
      "epoch:8 step:6512[D loss: 0.453879, acc: 52.34%, op_acc: 35.16%] [G loss: 0.888459]\n",
      "epoch:8 step:6513[D loss: 0.436655, acc: 57.81%, op_acc: 33.59%] [G loss: 0.925460]\n",
      "epoch:8 step:6514[D loss: 0.402558, acc: 67.97%, op_acc: 41.41%] [G loss: 0.873905]\n",
      "epoch:8 step:6515[D loss: 0.446954, acc: 57.81%, op_acc: 35.94%] [G loss: 0.923183]\n",
      "epoch:8 step:6516[D loss: 0.417647, acc: 66.41%, op_acc: 41.41%] [G loss: 0.907861]\n",
      "epoch:8 step:6517[D loss: 0.417358, acc: 62.50%, op_acc: 40.62%] [G loss: 0.879407]\n",
      "epoch:8 step:6518[D loss: 0.427017, acc: 64.06%, op_acc: 33.59%] [G loss: 0.788640]\n",
      "epoch:8 step:6519[D loss: 0.448064, acc: 57.03%, op_acc: 39.06%] [G loss: 0.929224]\n",
      "epoch:8 step:6520[D loss: 0.462537, acc: 59.38%, op_acc: 31.25%] [G loss: 0.876820]\n",
      "epoch:8 step:6521[D loss: 0.428767, acc: 54.69%, op_acc: 34.38%] [G loss: 0.924412]\n",
      "epoch:8 step:6522[D loss: 0.454808, acc: 58.59%, op_acc: 34.38%] [G loss: 0.870063]\n",
      "epoch:8 step:6523[D loss: 0.422829, acc: 63.28%, op_acc: 39.84%] [G loss: 0.900298]\n",
      "epoch:8 step:6524[D loss: 0.458878, acc: 55.47%, op_acc: 34.38%] [G loss: 0.889249]\n",
      "epoch:8 step:6525[D loss: 0.441656, acc: 67.97%, op_acc: 27.34%] [G loss: 0.846353]\n",
      "epoch:8 step:6526[D loss: 0.467142, acc: 52.34%, op_acc: 32.81%] [G loss: 0.795798]\n",
      "epoch:8 step:6527[D loss: 0.432946, acc: 64.06%, op_acc: 35.94%] [G loss: 0.881276]\n",
      "epoch:8 step:6528[D loss: 0.438522, acc: 57.03%, op_acc: 41.41%] [G loss: 0.829521]\n",
      "epoch:8 step:6529[D loss: 0.452736, acc: 57.81%, op_acc: 33.59%] [G loss: 0.926827]\n",
      "epoch:8 step:6530[D loss: 0.420541, acc: 67.19%, op_acc: 32.81%] [G loss: 0.818130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6531[D loss: 0.431086, acc: 61.72%, op_acc: 35.94%] [G loss: 0.793528]\n",
      "epoch:8 step:6532[D loss: 0.447601, acc: 63.28%, op_acc: 28.12%] [G loss: 0.852138]\n",
      "epoch:8 step:6533[D loss: 0.421731, acc: 62.50%, op_acc: 31.25%] [G loss: 0.903362]\n",
      "epoch:8 step:6534[D loss: 0.433518, acc: 64.84%, op_acc: 34.38%] [G loss: 0.909364]\n",
      "epoch:8 step:6535[D loss: 0.470255, acc: 52.34%, op_acc: 36.72%] [G loss: 0.959165]\n",
      "epoch:8 step:6536[D loss: 0.430198, acc: 59.38%, op_acc: 35.94%] [G loss: 0.919207]\n",
      "epoch:8 step:6537[D loss: 0.449257, acc: 60.94%, op_acc: 32.03%] [G loss: 0.865272]\n",
      "epoch:8 step:6538[D loss: 0.439651, acc: 58.59%, op_acc: 35.94%] [G loss: 0.885044]\n",
      "epoch:8 step:6539[D loss: 0.440758, acc: 56.25%, op_acc: 36.72%] [G loss: 0.841372]\n",
      "epoch:8 step:6540[D loss: 0.469552, acc: 53.12%, op_acc: 32.81%] [G loss: 0.896091]\n",
      "epoch:8 step:6541[D loss: 0.454933, acc: 50.78%, op_acc: 35.16%] [G loss: 0.801874]\n",
      "epoch:8 step:6542[D loss: 0.458621, acc: 55.47%, op_acc: 36.72%] [G loss: 0.841891]\n",
      "epoch:8 step:6543[D loss: 0.444215, acc: 61.72%, op_acc: 32.81%] [G loss: 0.900324]\n",
      "epoch:8 step:6544[D loss: 0.447598, acc: 50.00%, op_acc: 35.94%] [G loss: 0.864027]\n",
      "epoch:8 step:6545[D loss: 0.475553, acc: 56.25%, op_acc: 27.34%] [G loss: 0.876671]\n",
      "epoch:8 step:6546[D loss: 0.439981, acc: 57.81%, op_acc: 37.50%] [G loss: 0.893957]\n",
      "epoch:8 step:6547[D loss: 0.446274, acc: 58.59%, op_acc: 37.50%] [G loss: 0.848999]\n",
      "epoch:8 step:6548[D loss: 0.512701, acc: 46.88%, op_acc: 28.12%] [G loss: 0.887695]\n",
      "epoch:8 step:6549[D loss: 0.446133, acc: 56.25%, op_acc: 40.62%] [G loss: 0.868955]\n",
      "epoch:8 step:6550[D loss: 0.407353, acc: 67.97%, op_acc: 35.94%] [G loss: 1.002723]\n",
      "##############\n",
      "[0.87065072 0.85824987 0.82126278 0.81143779 0.77595599 0.81176282\n",
      " 0.86711453 0.81368196 0.80658674 0.81586005]\n",
      "##########\n",
      "epoch:8 step:6551[D loss: 0.479418, acc: 47.66%, op_acc: 28.12%] [G loss: 0.825832]\n",
      "epoch:8 step:6552[D loss: 0.435598, acc: 60.16%, op_acc: 32.03%] [G loss: 0.895840]\n",
      "epoch:8 step:6553[D loss: 0.445273, acc: 61.72%, op_acc: 33.59%] [G loss: 0.906151]\n",
      "epoch:8 step:6554[D loss: 0.475224, acc: 57.03%, op_acc: 26.56%] [G loss: 0.906256]\n",
      "epoch:8 step:6555[D loss: 0.429802, acc: 60.94%, op_acc: 32.03%] [G loss: 0.980438]\n",
      "epoch:8 step:6556[D loss: 0.446026, acc: 66.41%, op_acc: 30.47%] [G loss: 0.873033]\n",
      "epoch:8 step:6557[D loss: 0.463915, acc: 56.25%, op_acc: 28.12%] [G loss: 0.949312]\n",
      "epoch:8 step:6558[D loss: 0.437430, acc: 59.38%, op_acc: 32.03%] [G loss: 0.915592]\n",
      "epoch:8 step:6559[D loss: 0.469184, acc: 50.78%, op_acc: 28.12%] [G loss: 0.942716]\n",
      "epoch:8 step:6560[D loss: 0.434146, acc: 63.28%, op_acc: 32.81%] [G loss: 0.900699]\n",
      "epoch:8 step:6561[D loss: 0.479824, acc: 46.88%, op_acc: 32.81%] [G loss: 0.820695]\n",
      "epoch:8 step:6562[D loss: 0.450168, acc: 54.69%, op_acc: 35.94%] [G loss: 0.859884]\n",
      "epoch:8 step:6563[D loss: 0.467681, acc: 54.69%, op_acc: 32.81%] [G loss: 0.865767]\n",
      "epoch:8 step:6564[D loss: 0.434651, acc: 61.72%, op_acc: 32.81%] [G loss: 0.852241]\n",
      "epoch:8 step:6565[D loss: 0.457932, acc: 56.25%, op_acc: 32.03%] [G loss: 0.885100]\n",
      "epoch:8 step:6566[D loss: 0.469138, acc: 57.03%, op_acc: 26.56%] [G loss: 0.940899]\n",
      "epoch:8 step:6567[D loss: 0.439414, acc: 53.12%, op_acc: 39.06%] [G loss: 0.946736]\n",
      "epoch:8 step:6568[D loss: 0.464889, acc: 59.38%, op_acc: 32.81%] [G loss: 0.834659]\n",
      "epoch:8 step:6569[D loss: 0.448381, acc: 64.06%, op_acc: 36.72%] [G loss: 0.936854]\n",
      "epoch:8 step:6570[D loss: 0.459424, acc: 53.91%, op_acc: 29.69%] [G loss: 0.977287]\n",
      "epoch:8 step:6571[D loss: 0.463656, acc: 57.03%, op_acc: 35.16%] [G loss: 0.883728]\n",
      "epoch:8 step:6572[D loss: 0.471512, acc: 52.34%, op_acc: 33.59%] [G loss: 0.863737]\n",
      "epoch:8 step:6573[D loss: 0.477162, acc: 51.56%, op_acc: 32.81%] [G loss: 0.794852]\n",
      "epoch:8 step:6574[D loss: 0.426432, acc: 62.50%, op_acc: 33.59%] [G loss: 0.921306]\n",
      "epoch:8 step:6575[D loss: 0.440936, acc: 59.38%, op_acc: 41.41%] [G loss: 0.957934]\n",
      "epoch:8 step:6576[D loss: 0.450337, acc: 58.59%, op_acc: 31.25%] [G loss: 0.948739]\n",
      "epoch:8 step:6577[D loss: 0.428127, acc: 62.50%, op_acc: 37.50%] [G loss: 0.840163]\n",
      "epoch:8 step:6578[D loss: 0.450404, acc: 51.56%, op_acc: 35.16%] [G loss: 0.901865]\n",
      "epoch:8 step:6579[D loss: 0.445662, acc: 58.59%, op_acc: 35.16%] [G loss: 0.904274]\n",
      "epoch:8 step:6580[D loss: 0.402713, acc: 65.62%, op_acc: 36.72%] [G loss: 0.892228]\n",
      "epoch:8 step:6581[D loss: 0.457544, acc: 59.38%, op_acc: 32.03%] [G loss: 0.854696]\n",
      "epoch:8 step:6582[D loss: 0.464360, acc: 54.69%, op_acc: 33.59%] [G loss: 0.840528]\n",
      "epoch:8 step:6583[D loss: 0.482620, acc: 57.81%, op_acc: 28.12%] [G loss: 0.885310]\n",
      "epoch:8 step:6584[D loss: 0.471025, acc: 46.88%, op_acc: 34.38%] [G loss: 0.817322]\n",
      "epoch:8 step:6585[D loss: 0.428257, acc: 61.72%, op_acc: 38.28%] [G loss: 0.920965]\n",
      "epoch:8 step:6586[D loss: 0.406025, acc: 64.06%, op_acc: 39.06%] [G loss: 0.906641]\n",
      "epoch:8 step:6587[D loss: 0.437287, acc: 60.94%, op_acc: 32.03%] [G loss: 0.895352]\n",
      "epoch:8 step:6588[D loss: 0.421257, acc: 64.06%, op_acc: 33.59%] [G loss: 0.874736]\n",
      "epoch:8 step:6589[D loss: 0.449854, acc: 60.94%, op_acc: 33.59%] [G loss: 0.875772]\n",
      "epoch:8 step:6590[D loss: 0.465632, acc: 53.91%, op_acc: 28.91%] [G loss: 0.880904]\n",
      "epoch:8 step:6591[D loss: 0.461041, acc: 55.47%, op_acc: 34.38%] [G loss: 0.857731]\n",
      "epoch:8 step:6592[D loss: 0.439110, acc: 54.69%, op_acc: 43.75%] [G loss: 0.817910]\n",
      "epoch:8 step:6593[D loss: 0.454629, acc: 56.25%, op_acc: 34.38%] [G loss: 0.815156]\n",
      "epoch:8 step:6594[D loss: 0.481181, acc: 53.12%, op_acc: 32.03%] [G loss: 0.860658]\n",
      "epoch:8 step:6595[D loss: 0.430704, acc: 56.25%, op_acc: 38.28%] [G loss: 0.929444]\n",
      "epoch:8 step:6596[D loss: 0.434395, acc: 64.84%, op_acc: 35.16%] [G loss: 0.864356]\n",
      "epoch:8 step:6597[D loss: 0.415822, acc: 60.16%, op_acc: 36.72%] [G loss: 0.917254]\n",
      "epoch:8 step:6598[D loss: 0.452473, acc: 59.38%, op_acc: 30.47%] [G loss: 0.893895]\n",
      "epoch:8 step:6599[D loss: 0.468577, acc: 50.78%, op_acc: 32.81%] [G loss: 0.841234]\n",
      "epoch:8 step:6600[D loss: 0.446365, acc: 60.94%, op_acc: 32.81%] [G loss: 0.822866]\n",
      "##############\n",
      "[0.85637543 0.86266978 0.82114773 0.80720791 0.79378648 0.84435233\n",
      " 0.86717756 0.8371359  0.78913488 0.84726606]\n",
      "##########\n",
      "epoch:8 step:6601[D loss: 0.440411, acc: 54.69%, op_acc: 38.28%] [G loss: 0.870753]\n",
      "epoch:8 step:6602[D loss: 0.458859, acc: 58.59%, op_acc: 29.69%] [G loss: 0.885537]\n",
      "epoch:8 step:6603[D loss: 0.461115, acc: 56.25%, op_acc: 28.12%] [G loss: 0.909717]\n",
      "epoch:8 step:6604[D loss: 0.460085, acc: 53.91%, op_acc: 32.81%] [G loss: 0.917240]\n",
      "epoch:8 step:6605[D loss: 0.479724, acc: 48.44%, op_acc: 28.12%] [G loss: 0.869004]\n",
      "epoch:8 step:6606[D loss: 0.425759, acc: 68.75%, op_acc: 31.25%] [G loss: 0.929389]\n",
      "epoch:8 step:6607[D loss: 0.435409, acc: 60.16%, op_acc: 33.59%] [G loss: 0.821417]\n",
      "epoch:8 step:6608[D loss: 0.472981, acc: 52.34%, op_acc: 37.50%] [G loss: 0.795452]\n",
      "epoch:8 step:6609[D loss: 0.465089, acc: 46.88%, op_acc: 39.84%] [G loss: 0.865618]\n",
      "epoch:8 step:6610[D loss: 0.413916, acc: 60.16%, op_acc: 40.62%] [G loss: 0.855037]\n",
      "epoch:8 step:6611[D loss: 0.475803, acc: 50.00%, op_acc: 32.03%] [G loss: 0.845387]\n",
      "epoch:8 step:6612[D loss: 0.472759, acc: 59.38%, op_acc: 27.34%] [G loss: 0.843690]\n",
      "epoch:8 step:6613[D loss: 0.405783, acc: 64.06%, op_acc: 39.06%] [G loss: 0.900935]\n",
      "epoch:8 step:6614[D loss: 0.429824, acc: 54.69%, op_acc: 39.06%] [G loss: 0.865660]\n",
      "epoch:8 step:6615[D loss: 0.480981, acc: 53.91%, op_acc: 29.69%] [G loss: 0.848999]\n",
      "epoch:8 step:6616[D loss: 0.440249, acc: 69.53%, op_acc: 31.25%] [G loss: 0.851931]\n",
      "epoch:8 step:6617[D loss: 0.438672, acc: 60.16%, op_acc: 33.59%] [G loss: 0.843636]\n",
      "epoch:8 step:6618[D loss: 0.458530, acc: 55.47%, op_acc: 33.59%] [G loss: 0.829750]\n",
      "epoch:8 step:6619[D loss: 0.403169, acc: 64.84%, op_acc: 39.06%] [G loss: 0.918872]\n",
      "epoch:8 step:6620[D loss: 0.444385, acc: 57.81%, op_acc: 34.38%] [G loss: 0.743893]\n",
      "epoch:8 step:6621[D loss: 0.446698, acc: 51.56%, op_acc: 36.72%] [G loss: 0.829104]\n",
      "epoch:8 step:6622[D loss: 0.451193, acc: 58.59%, op_acc: 37.50%] [G loss: 0.877715]\n",
      "epoch:8 step:6623[D loss: 0.444986, acc: 59.38%, op_acc: 34.38%] [G loss: 0.899493]\n",
      "epoch:8 step:6624[D loss: 0.435557, acc: 60.16%, op_acc: 32.81%] [G loss: 0.871863]\n",
      "epoch:8 step:6625[D loss: 0.452234, acc: 59.38%, op_acc: 32.81%] [G loss: 0.894312]\n",
      "epoch:8 step:6626[D loss: 0.426815, acc: 64.06%, op_acc: 34.38%] [G loss: 0.850416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6627[D loss: 0.428683, acc: 60.94%, op_acc: 33.59%] [G loss: 0.898700]\n",
      "epoch:8 step:6628[D loss: 0.427292, acc: 68.75%, op_acc: 33.59%] [G loss: 0.880154]\n",
      "epoch:8 step:6629[D loss: 0.444523, acc: 60.94%, op_acc: 31.25%] [G loss: 0.874452]\n",
      "epoch:8 step:6630[D loss: 0.440082, acc: 61.72%, op_acc: 40.62%] [G loss: 0.880978]\n",
      "epoch:8 step:6631[D loss: 0.403820, acc: 67.19%, op_acc: 35.94%] [G loss: 0.876503]\n",
      "epoch:8 step:6632[D loss: 0.408028, acc: 67.19%, op_acc: 36.72%] [G loss: 0.888215]\n",
      "epoch:8 step:6633[D loss: 0.443919, acc: 53.12%, op_acc: 35.94%] [G loss: 0.846990]\n",
      "epoch:8 step:6634[D loss: 0.414047, acc: 63.28%, op_acc: 35.16%] [G loss: 0.820395]\n",
      "epoch:8 step:6635[D loss: 0.463607, acc: 57.03%, op_acc: 34.38%] [G loss: 0.901290]\n",
      "epoch:8 step:6636[D loss: 0.462288, acc: 59.38%, op_acc: 29.69%] [G loss: 0.923496]\n",
      "epoch:8 step:6637[D loss: 0.450117, acc: 60.16%, op_acc: 32.03%] [G loss: 0.944780]\n",
      "epoch:8 step:6638[D loss: 0.459812, acc: 53.91%, op_acc: 33.59%] [G loss: 0.887914]\n",
      "epoch:8 step:6639[D loss: 0.413487, acc: 61.72%, op_acc: 42.19%] [G loss: 0.972875]\n",
      "epoch:8 step:6640[D loss: 0.419000, acc: 61.72%, op_acc: 39.84%] [G loss: 0.863865]\n",
      "epoch:8 step:6641[D loss: 0.468442, acc: 55.47%, op_acc: 35.16%] [G loss: 0.940821]\n",
      "epoch:8 step:6642[D loss: 0.476114, acc: 51.56%, op_acc: 28.12%] [G loss: 0.936527]\n",
      "epoch:8 step:6643[D loss: 0.445971, acc: 53.91%, op_acc: 33.59%] [G loss: 0.939885]\n",
      "epoch:8 step:6644[D loss: 0.453038, acc: 53.12%, op_acc: 35.94%] [G loss: 0.900649]\n",
      "epoch:8 step:6645[D loss: 0.460405, acc: 55.47%, op_acc: 31.25%] [G loss: 0.908980]\n",
      "epoch:8 step:6646[D loss: 0.491223, acc: 52.34%, op_acc: 29.69%] [G loss: 0.846711]\n",
      "epoch:8 step:6647[D loss: 0.461556, acc: 53.12%, op_acc: 38.28%] [G loss: 0.906885]\n",
      "epoch:8 step:6648[D loss: 0.436328, acc: 57.03%, op_acc: 35.16%] [G loss: 0.884763]\n",
      "epoch:8 step:6649[D loss: 0.434789, acc: 63.28%, op_acc: 33.59%] [G loss: 0.876357]\n",
      "epoch:8 step:6650[D loss: 0.466269, acc: 55.47%, op_acc: 31.25%] [G loss: 0.852465]\n",
      "##############\n",
      "[0.84544472 0.84543398 0.81117558 0.7983257  0.77801551 0.79854981\n",
      " 0.90118188 0.84151743 0.81797619 0.84197636]\n",
      "##########\n",
      "epoch:8 step:6651[D loss: 0.418166, acc: 64.06%, op_acc: 36.72%] [G loss: 0.879339]\n",
      "epoch:8 step:6652[D loss: 0.447422, acc: 60.94%, op_acc: 35.94%] [G loss: 0.932360]\n",
      "epoch:8 step:6653[D loss: 0.473327, acc: 53.91%, op_acc: 30.47%] [G loss: 0.853858]\n",
      "epoch:8 step:6654[D loss: 0.424696, acc: 62.50%, op_acc: 37.50%] [G loss: 0.864378]\n",
      "epoch:8 step:6655[D loss: 0.440286, acc: 64.84%, op_acc: 27.34%] [G loss: 0.913396]\n",
      "epoch:8 step:6656[D loss: 0.420490, acc: 60.16%, op_acc: 38.28%] [G loss: 0.884497]\n",
      "epoch:8 step:6657[D loss: 0.450689, acc: 57.03%, op_acc: 31.25%] [G loss: 0.866704]\n",
      "epoch:8 step:6658[D loss: 0.431553, acc: 60.94%, op_acc: 39.06%] [G loss: 0.871996]\n",
      "epoch:8 step:6659[D loss: 0.464738, acc: 56.25%, op_acc: 32.03%] [G loss: 0.887406]\n",
      "epoch:8 step:6660[D loss: 0.436021, acc: 59.38%, op_acc: 35.16%] [G loss: 0.875636]\n",
      "epoch:8 step:6661[D loss: 0.440075, acc: 57.03%, op_acc: 34.38%] [G loss: 0.809667]\n",
      "epoch:8 step:6662[D loss: 0.438908, acc: 52.34%, op_acc: 35.16%] [G loss: 0.883159]\n",
      "epoch:8 step:6663[D loss: 0.429513, acc: 63.28%, op_acc: 35.16%] [G loss: 0.795620]\n",
      "epoch:8 step:6664[D loss: 0.453032, acc: 52.34%, op_acc: 36.72%] [G loss: 0.905244]\n",
      "epoch:8 step:6665[D loss: 0.457914, acc: 58.59%, op_acc: 30.47%] [G loss: 0.851142]\n",
      "epoch:8 step:6666[D loss: 0.442931, acc: 57.03%, op_acc: 35.94%] [G loss: 0.954929]\n",
      "epoch:8 step:6667[D loss: 0.441432, acc: 60.94%, op_acc: 32.03%] [G loss: 0.917948]\n",
      "epoch:8 step:6668[D loss: 0.436985, acc: 61.72%, op_acc: 36.72%] [G loss: 0.900902]\n",
      "epoch:8 step:6669[D loss: 0.432226, acc: 63.28%, op_acc: 33.59%] [G loss: 0.927673]\n",
      "epoch:8 step:6670[D loss: 0.420223, acc: 62.50%, op_acc: 38.28%] [G loss: 0.883215]\n",
      "epoch:8 step:6671[D loss: 0.481117, acc: 51.56%, op_acc: 28.91%] [G loss: 0.836216]\n",
      "epoch:8 step:6672[D loss: 0.425301, acc: 59.38%, op_acc: 36.72%] [G loss: 0.891018]\n",
      "epoch:8 step:6673[D loss: 0.475912, acc: 53.12%, op_acc: 28.91%] [G loss: 0.903451]\n",
      "epoch:8 step:6674[D loss: 0.434355, acc: 64.06%, op_acc: 36.72%] [G loss: 0.864054]\n",
      "epoch:8 step:6675[D loss: 0.458643, acc: 60.94%, op_acc: 26.56%] [G loss: 0.855120]\n",
      "epoch:8 step:6676[D loss: 0.436026, acc: 60.94%, op_acc: 38.28%] [G loss: 0.870941]\n",
      "epoch:8 step:6677[D loss: 0.440675, acc: 60.94%, op_acc: 28.91%] [G loss: 0.817033]\n",
      "epoch:8 step:6678[D loss: 0.447299, acc: 54.69%, op_acc: 36.72%] [G loss: 0.835936]\n",
      "epoch:8 step:6679[D loss: 0.470739, acc: 53.91%, op_acc: 30.47%] [G loss: 0.856472]\n",
      "epoch:8 step:6680[D loss: 0.419597, acc: 63.28%, op_acc: 41.41%] [G loss: 0.915518]\n",
      "epoch:8 step:6681[D loss: 0.438505, acc: 65.62%, op_acc: 32.81%] [G loss: 0.946279]\n",
      "epoch:8 step:6682[D loss: 0.444007, acc: 59.38%, op_acc: 42.19%] [G loss: 0.920972]\n",
      "epoch:8 step:6683[D loss: 0.434512, acc: 56.25%, op_acc: 39.06%] [G loss: 0.905893]\n",
      "epoch:8 step:6684[D loss: 0.453745, acc: 61.72%, op_acc: 35.16%] [G loss: 0.919844]\n",
      "epoch:8 step:6685[D loss: 0.442209, acc: 57.03%, op_acc: 35.16%] [G loss: 0.912037]\n",
      "epoch:8 step:6686[D loss: 0.482121, acc: 55.47%, op_acc: 34.38%] [G loss: 0.829114]\n",
      "epoch:8 step:6687[D loss: 0.434854, acc: 64.06%, op_acc: 33.59%] [G loss: 0.894705]\n",
      "epoch:8 step:6688[D loss: 0.426554, acc: 64.06%, op_acc: 35.16%] [G loss: 0.984382]\n",
      "epoch:8 step:6689[D loss: 0.434246, acc: 66.41%, op_acc: 32.81%] [G loss: 0.870971]\n",
      "epoch:8 step:6690[D loss: 0.420032, acc: 65.62%, op_acc: 33.59%] [G loss: 0.837066]\n",
      "epoch:8 step:6691[D loss: 0.434654, acc: 70.31%, op_acc: 32.81%] [G loss: 0.901313]\n",
      "epoch:8 step:6692[D loss: 0.426751, acc: 59.38%, op_acc: 35.16%] [G loss: 0.951137]\n",
      "epoch:8 step:6693[D loss: 0.446459, acc: 60.16%, op_acc: 34.38%] [G loss: 0.864574]\n",
      "epoch:8 step:6694[D loss: 0.441271, acc: 66.41%, op_acc: 35.16%] [G loss: 0.932582]\n",
      "epoch:8 step:6695[D loss: 0.446038, acc: 64.84%, op_acc: 33.59%] [G loss: 0.940886]\n",
      "epoch:8 step:6696[D loss: 0.429461, acc: 63.28%, op_acc: 35.94%] [G loss: 0.869730]\n",
      "epoch:8 step:6697[D loss: 0.442010, acc: 60.94%, op_acc: 25.00%] [G loss: 0.898005]\n",
      "epoch:8 step:6698[D loss: 0.435648, acc: 58.59%, op_acc: 29.69%] [G loss: 0.953129]\n",
      "epoch:8 step:6699[D loss: 0.432298, acc: 61.72%, op_acc: 38.28%] [G loss: 0.875342]\n",
      "epoch:8 step:6700[D loss: 0.400502, acc: 60.94%, op_acc: 40.62%] [G loss: 0.958363]\n",
      "##############\n",
      "[0.84890466 0.84400518 0.83473888 0.81005077 0.78006628 0.82942047\n",
      " 0.8783732  0.83176875 0.83125955 0.83911689]\n",
      "##########\n",
      "epoch:8 step:6701[D loss: 0.436246, acc: 53.91%, op_acc: 35.16%] [G loss: 0.863399]\n",
      "epoch:8 step:6702[D loss: 0.431123, acc: 60.16%, op_acc: 35.16%] [G loss: 0.902536]\n",
      "epoch:8 step:6703[D loss: 0.468662, acc: 53.91%, op_acc: 35.94%] [G loss: 0.782320]\n",
      "epoch:8 step:6704[D loss: 0.441716, acc: 60.94%, op_acc: 32.81%] [G loss: 0.816635]\n",
      "epoch:8 step:6705[D loss: 0.437214, acc: 64.84%, op_acc: 29.69%] [G loss: 0.856854]\n",
      "epoch:8 step:6706[D loss: 0.449844, acc: 56.25%, op_acc: 38.28%] [G loss: 0.904967]\n",
      "epoch:8 step:6707[D loss: 0.431063, acc: 54.69%, op_acc: 36.72%] [G loss: 0.946993]\n",
      "epoch:8 step:6708[D loss: 0.431352, acc: 60.94%, op_acc: 33.59%] [G loss: 0.966204]\n",
      "epoch:8 step:6709[D loss: 0.427507, acc: 67.19%, op_acc: 31.25%] [G loss: 0.927381]\n",
      "epoch:8 step:6710[D loss: 0.422488, acc: 64.06%, op_acc: 33.59%] [G loss: 0.928499]\n",
      "epoch:8 step:6711[D loss: 0.426838, acc: 68.75%, op_acc: 37.50%] [G loss: 0.883465]\n",
      "epoch:8 step:6712[D loss: 0.451776, acc: 60.94%, op_acc: 31.25%] [G loss: 0.847370]\n",
      "epoch:8 step:6713[D loss: 0.441635, acc: 61.72%, op_acc: 31.25%] [G loss: 0.875682]\n",
      "epoch:8 step:6714[D loss: 0.430955, acc: 56.25%, op_acc: 36.72%] [G loss: 0.876660]\n",
      "epoch:8 step:6715[D loss: 0.425317, acc: 63.28%, op_acc: 35.16%] [G loss: 0.886541]\n",
      "epoch:8 step:6716[D loss: 0.450842, acc: 54.69%, op_acc: 35.94%] [G loss: 0.858438]\n",
      "epoch:8 step:6717[D loss: 0.432841, acc: 58.59%, op_acc: 34.38%] [G loss: 0.892826]\n",
      "epoch:8 step:6718[D loss: 0.450098, acc: 60.16%, op_acc: 35.16%] [G loss: 0.888809]\n",
      "epoch:8 step:6719[D loss: 0.446194, acc: 57.81%, op_acc: 32.81%] [G loss: 0.934829]\n",
      "epoch:8 step:6720[D loss: 0.474939, acc: 47.66%, op_acc: 33.59%] [G loss: 0.815998]\n",
      "epoch:8 step:6721[D loss: 0.428748, acc: 59.38%, op_acc: 37.50%] [G loss: 0.926238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6722[D loss: 0.431922, acc: 67.97%, op_acc: 33.59%] [G loss: 0.936021]\n",
      "epoch:8 step:6723[D loss: 0.422201, acc: 57.03%, op_acc: 40.62%] [G loss: 0.860019]\n",
      "epoch:8 step:6724[D loss: 0.469764, acc: 57.81%, op_acc: 29.69%] [G loss: 0.824189]\n",
      "epoch:8 step:6725[D loss: 0.449505, acc: 59.38%, op_acc: 32.81%] [G loss: 0.881928]\n",
      "epoch:8 step:6726[D loss: 0.406171, acc: 67.97%, op_acc: 39.84%] [G loss: 0.935110]\n",
      "epoch:8 step:6727[D loss: 0.439494, acc: 64.84%, op_acc: 32.03%] [G loss: 0.971863]\n",
      "epoch:8 step:6728[D loss: 0.463060, acc: 57.81%, op_acc: 28.12%] [G loss: 0.948781]\n",
      "epoch:8 step:6729[D loss: 0.471258, acc: 59.38%, op_acc: 30.47%] [G loss: 0.855992]\n",
      "epoch:8 step:6730[D loss: 0.471700, acc: 54.69%, op_acc: 31.25%] [G loss: 0.866904]\n",
      "epoch:8 step:6731[D loss: 0.443081, acc: 64.06%, op_acc: 33.59%] [G loss: 0.925845]\n",
      "epoch:8 step:6732[D loss: 0.440722, acc: 59.38%, op_acc: 37.50%] [G loss: 0.842445]\n",
      "epoch:8 step:6733[D loss: 0.428896, acc: 58.59%, op_acc: 34.38%] [G loss: 0.876413]\n",
      "epoch:8 step:6734[D loss: 0.409361, acc: 67.97%, op_acc: 35.94%] [G loss: 0.889277]\n",
      "epoch:8 step:6735[D loss: 0.439008, acc: 64.06%, op_acc: 38.28%] [G loss: 0.905177]\n",
      "epoch:8 step:6736[D loss: 0.470304, acc: 50.78%, op_acc: 26.56%] [G loss: 0.924063]\n",
      "epoch:8 step:6737[D loss: 0.430754, acc: 58.59%, op_acc: 36.72%] [G loss: 0.915081]\n",
      "epoch:8 step:6738[D loss: 0.471496, acc: 52.34%, op_acc: 39.06%] [G loss: 0.845852]\n",
      "epoch:8 step:6739[D loss: 0.488800, acc: 50.00%, op_acc: 26.56%] [G loss: 0.883911]\n",
      "epoch:8 step:6740[D loss: 0.427195, acc: 60.94%, op_acc: 38.28%] [G loss: 0.947195]\n",
      "epoch:8 step:6741[D loss: 0.471917, acc: 56.25%, op_acc: 28.91%] [G loss: 0.813806]\n",
      "epoch:8 step:6742[D loss: 0.410784, acc: 67.19%, op_acc: 38.28%] [G loss: 0.948633]\n",
      "epoch:8 step:6743[D loss: 0.454207, acc: 55.47%, op_acc: 33.59%] [G loss: 0.821772]\n",
      "epoch:8 step:6744[D loss: 0.440793, acc: 67.19%, op_acc: 29.69%] [G loss: 0.863087]\n",
      "epoch:8 step:6745[D loss: 0.408001, acc: 64.06%, op_acc: 42.19%] [G loss: 0.889324]\n",
      "epoch:8 step:6746[D loss: 0.445443, acc: 58.59%, op_acc: 34.38%] [G loss: 0.812444]\n",
      "epoch:8 step:6747[D loss: 0.457843, acc: 64.84%, op_acc: 32.03%] [G loss: 0.928611]\n",
      "epoch:8 step:6748[D loss: 0.439271, acc: 60.16%, op_acc: 40.62%] [G loss: 0.864552]\n",
      "epoch:8 step:6749[D loss: 0.430521, acc: 64.06%, op_acc: 34.38%] [G loss: 0.879365]\n",
      "epoch:8 step:6750[D loss: 0.449433, acc: 55.47%, op_acc: 32.81%] [G loss: 0.858411]\n",
      "##############\n",
      "[0.85104053 0.8494205  0.79331697 0.82023121 0.80433074 0.81343667\n",
      " 0.88103773 0.84357614 0.82798608 0.81006734]\n",
      "##########\n",
      "epoch:8 step:6751[D loss: 0.411995, acc: 64.84%, op_acc: 42.19%] [G loss: 0.903421]\n",
      "epoch:8 step:6752[D loss: 0.470550, acc: 49.22%, op_acc: 35.16%] [G loss: 0.848337]\n",
      "epoch:8 step:6753[D loss: 0.433478, acc: 67.97%, op_acc: 34.38%] [G loss: 0.892213]\n",
      "epoch:8 step:6754[D loss: 0.449141, acc: 58.59%, op_acc: 32.81%] [G loss: 0.917533]\n",
      "epoch:8 step:6755[D loss: 0.447010, acc: 53.91%, op_acc: 32.81%] [G loss: 0.885505]\n",
      "epoch:8 step:6756[D loss: 0.444532, acc: 56.25%, op_acc: 33.59%] [G loss: 0.927213]\n",
      "epoch:8 step:6757[D loss: 0.502434, acc: 45.31%, op_acc: 35.16%] [G loss: 0.907659]\n",
      "epoch:8 step:6758[D loss: 0.450966, acc: 62.50%, op_acc: 35.16%] [G loss: 0.916742]\n",
      "epoch:8 step:6759[D loss: 0.452356, acc: 51.56%, op_acc: 36.72%] [G loss: 0.849558]\n",
      "epoch:8 step:6760[D loss: 0.482465, acc: 50.78%, op_acc: 27.34%] [G loss: 0.884541]\n",
      "epoch:8 step:6761[D loss: 0.476664, acc: 56.25%, op_acc: 29.69%] [G loss: 0.852178]\n",
      "epoch:8 step:6762[D loss: 0.450678, acc: 51.56%, op_acc: 34.38%] [G loss: 0.962172]\n",
      "epoch:8 step:6763[D loss: 0.454436, acc: 57.81%, op_acc: 28.12%] [G loss: 0.816285]\n",
      "epoch:8 step:6764[D loss: 0.432567, acc: 58.59%, op_acc: 35.94%] [G loss: 0.851245]\n",
      "epoch:8 step:6765[D loss: 0.454690, acc: 56.25%, op_acc: 28.12%] [G loss: 0.898056]\n",
      "epoch:8 step:6766[D loss: 0.420977, acc: 60.94%, op_acc: 37.50%] [G loss: 0.930805]\n",
      "epoch:8 step:6767[D loss: 0.409512, acc: 63.28%, op_acc: 38.28%] [G loss: 0.910228]\n",
      "epoch:8 step:6768[D loss: 0.438664, acc: 57.81%, op_acc: 36.72%] [G loss: 0.950525]\n",
      "epoch:8 step:6769[D loss: 0.427133, acc: 63.28%, op_acc: 32.03%] [G loss: 0.905189]\n",
      "epoch:8 step:6770[D loss: 0.467930, acc: 49.22%, op_acc: 28.12%] [G loss: 0.844402]\n",
      "epoch:8 step:6771[D loss: 0.451852, acc: 59.38%, op_acc: 35.94%] [G loss: 0.847033]\n",
      "epoch:8 step:6772[D loss: 0.433812, acc: 63.28%, op_acc: 42.97%] [G loss: 0.909973]\n",
      "epoch:8 step:6773[D loss: 0.414037, acc: 67.19%, op_acc: 32.81%] [G loss: 0.855110]\n",
      "epoch:8 step:6774[D loss: 0.486974, acc: 56.25%, op_acc: 29.69%] [G loss: 0.895710]\n",
      "epoch:8 step:6775[D loss: 0.464594, acc: 50.78%, op_acc: 31.25%] [G loss: 0.819212]\n",
      "epoch:8 step:6776[D loss: 0.466597, acc: 53.91%, op_acc: 33.59%] [G loss: 0.889110]\n",
      "epoch:8 step:6777[D loss: 0.430324, acc: 64.84%, op_acc: 38.28%] [G loss: 0.937033]\n",
      "epoch:8 step:6778[D loss: 0.465015, acc: 61.72%, op_acc: 30.47%] [G loss: 0.871515]\n",
      "epoch:8 step:6779[D loss: 0.459826, acc: 61.72%, op_acc: 30.47%] [G loss: 0.883513]\n",
      "epoch:8 step:6780[D loss: 0.461722, acc: 54.69%, op_acc: 37.50%] [G loss: 0.886161]\n",
      "epoch:8 step:6781[D loss: 0.411499, acc: 64.06%, op_acc: 36.72%] [G loss: 0.886157]\n",
      "epoch:8 step:6782[D loss: 0.441079, acc: 57.81%, op_acc: 34.38%] [G loss: 0.863206]\n",
      "epoch:8 step:6783[D loss: 0.435894, acc: 58.59%, op_acc: 35.94%] [G loss: 0.832258]\n",
      "epoch:8 step:6784[D loss: 0.399285, acc: 64.06%, op_acc: 40.62%] [G loss: 0.900684]\n",
      "epoch:8 step:6785[D loss: 0.477793, acc: 49.22%, op_acc: 31.25%] [G loss: 0.801722]\n",
      "epoch:8 step:6786[D loss: 0.457989, acc: 56.25%, op_acc: 32.81%] [G loss: 0.888420]\n",
      "epoch:8 step:6787[D loss: 0.464190, acc: 63.28%, op_acc: 27.34%] [G loss: 0.892707]\n",
      "epoch:8 step:6788[D loss: 0.424698, acc: 59.38%, op_acc: 34.38%] [G loss: 0.875517]\n",
      "epoch:8 step:6789[D loss: 0.423266, acc: 57.81%, op_acc: 34.38%] [G loss: 0.916022]\n",
      "epoch:8 step:6790[D loss: 0.484815, acc: 54.69%, op_acc: 28.91%] [G loss: 0.870748]\n",
      "epoch:8 step:6791[D loss: 0.440952, acc: 61.72%, op_acc: 30.47%] [G loss: 0.931430]\n",
      "epoch:8 step:6792[D loss: 0.446485, acc: 60.16%, op_acc: 35.16%] [G loss: 0.873295]\n",
      "epoch:8 step:6793[D loss: 0.411414, acc: 67.97%, op_acc: 39.06%] [G loss: 0.841670]\n",
      "epoch:8 step:6794[D loss: 0.453166, acc: 56.25%, op_acc: 37.50%] [G loss: 0.930646]\n",
      "epoch:8 step:6795[D loss: 0.452572, acc: 52.34%, op_acc: 34.38%] [G loss: 0.900460]\n",
      "epoch:8 step:6796[D loss: 0.504547, acc: 48.44%, op_acc: 29.69%] [G loss: 0.930073]\n",
      "epoch:8 step:6797[D loss: 0.446645, acc: 61.72%, op_acc: 34.38%] [G loss: 0.891550]\n",
      "epoch:8 step:6798[D loss: 0.466466, acc: 55.47%, op_acc: 29.69%] [G loss: 0.835056]\n",
      "epoch:8 step:6799[D loss: 0.452582, acc: 54.69%, op_acc: 36.72%] [G loss: 0.867703]\n",
      "epoch:8 step:6800[D loss: 0.455197, acc: 60.16%, op_acc: 25.00%] [G loss: 0.835949]\n",
      "##############\n",
      "[0.86044799 0.87234125 0.80779884 0.79778712 0.76061129 0.83804521\n",
      " 0.8710918  0.82876594 0.81323779 0.83408664]\n",
      "##########\n",
      "epoch:8 step:6801[D loss: 0.428156, acc: 61.72%, op_acc: 36.72%] [G loss: 0.911071]\n",
      "epoch:8 step:6802[D loss: 0.447188, acc: 60.94%, op_acc: 32.81%] [G loss: 0.867374]\n",
      "epoch:8 step:6803[D loss: 0.442727, acc: 59.38%, op_acc: 32.81%] [G loss: 0.914647]\n",
      "epoch:8 step:6804[D loss: 0.441774, acc: 50.00%, op_acc: 33.59%] [G loss: 0.775797]\n",
      "epoch:8 step:6805[D loss: 0.451716, acc: 56.25%, op_acc: 26.56%] [G loss: 0.941745]\n",
      "epoch:8 step:6806[D loss: 0.421669, acc: 62.50%, op_acc: 38.28%] [G loss: 0.880212]\n",
      "epoch:8 step:6807[D loss: 0.444513, acc: 60.16%, op_acc: 31.25%] [G loss: 0.867919]\n",
      "epoch:8 step:6808[D loss: 0.472911, acc: 52.34%, op_acc: 28.91%] [G loss: 0.826598]\n",
      "epoch:8 step:6809[D loss: 0.450187, acc: 54.69%, op_acc: 37.50%] [G loss: 0.794559]\n",
      "epoch:8 step:6810[D loss: 0.442521, acc: 57.81%, op_acc: 32.81%] [G loss: 0.858621]\n",
      "epoch:8 step:6811[D loss: 0.447136, acc: 60.16%, op_acc: 33.59%] [G loss: 0.925561]\n",
      "epoch:8 step:6812[D loss: 0.435662, acc: 58.59%, op_acc: 42.19%] [G loss: 0.939391]\n",
      "epoch:8 step:6813[D loss: 0.423980, acc: 64.06%, op_acc: 40.62%] [G loss: 0.947592]\n",
      "epoch:8 step:6814[D loss: 0.448342, acc: 57.81%, op_acc: 33.59%] [G loss: 0.924664]\n",
      "epoch:8 step:6815[D loss: 0.440315, acc: 61.72%, op_acc: 35.16%] [G loss: 0.828932]\n",
      "epoch:8 step:6816[D loss: 0.416601, acc: 65.62%, op_acc: 35.94%] [G loss: 0.896674]\n",
      "epoch:8 step:6817[D loss: 0.439111, acc: 57.03%, op_acc: 39.84%] [G loss: 0.965454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6818[D loss: 0.425541, acc: 61.72%, op_acc: 35.16%] [G loss: 0.905258]\n",
      "epoch:8 step:6819[D loss: 0.427381, acc: 61.72%, op_acc: 37.50%] [G loss: 0.983709]\n",
      "epoch:8 step:6820[D loss: 0.440080, acc: 60.16%, op_acc: 33.59%] [G loss: 0.872502]\n",
      "epoch:8 step:6821[D loss: 0.465625, acc: 51.56%, op_acc: 35.94%] [G loss: 0.870091]\n",
      "epoch:8 step:6822[D loss: 0.455121, acc: 60.94%, op_acc: 28.91%] [G loss: 0.839696]\n",
      "epoch:8 step:6823[D loss: 0.472243, acc: 51.56%, op_acc: 32.81%] [G loss: 0.869730]\n",
      "epoch:8 step:6824[D loss: 0.444444, acc: 57.03%, op_acc: 35.16%] [G loss: 0.909355]\n",
      "epoch:8 step:6825[D loss: 0.452597, acc: 57.03%, op_acc: 30.47%] [G loss: 0.875170]\n",
      "epoch:8 step:6826[D loss: 0.504939, acc: 51.56%, op_acc: 25.78%] [G loss: 0.925337]\n",
      "epoch:8 step:6827[D loss: 0.444885, acc: 59.38%, op_acc: 36.72%] [G loss: 0.901999]\n",
      "epoch:8 step:6828[D loss: 0.456350, acc: 59.38%, op_acc: 30.47%] [G loss: 0.869524]\n",
      "epoch:8 step:6829[D loss: 0.442289, acc: 58.59%, op_acc: 34.38%] [G loss: 0.833809]\n",
      "epoch:8 step:6830[D loss: 0.466011, acc: 57.81%, op_acc: 27.34%] [G loss: 0.836654]\n",
      "epoch:8 step:6831[D loss: 0.426061, acc: 59.38%, op_acc: 33.59%] [G loss: 0.946431]\n",
      "epoch:8 step:6832[D loss: 0.475786, acc: 59.38%, op_acc: 30.47%] [G loss: 0.855287]\n",
      "epoch:8 step:6833[D loss: 0.445340, acc: 59.38%, op_acc: 40.62%] [G loss: 0.890664]\n",
      "epoch:8 step:6834[D loss: 0.462535, acc: 57.03%, op_acc: 32.03%] [G loss: 0.879662]\n",
      "epoch:8 step:6835[D loss: 0.447329, acc: 64.06%, op_acc: 32.81%] [G loss: 0.926966]\n",
      "epoch:8 step:6836[D loss: 0.438858, acc: 59.38%, op_acc: 33.59%] [G loss: 0.879118]\n",
      "epoch:8 step:6837[D loss: 0.428266, acc: 67.19%, op_acc: 30.47%] [G loss: 0.937078]\n",
      "epoch:8 step:6838[D loss: 0.436800, acc: 56.25%, op_acc: 36.72%] [G loss: 0.924523]\n",
      "epoch:8 step:6839[D loss: 0.446939, acc: 58.59%, op_acc: 32.03%] [G loss: 0.903166]\n",
      "epoch:8 step:6840[D loss: 0.446520, acc: 54.69%, op_acc: 37.50%] [G loss: 0.844965]\n",
      "epoch:8 step:6841[D loss: 0.465469, acc: 58.59%, op_acc: 33.59%] [G loss: 0.860703]\n",
      "epoch:8 step:6842[D loss: 0.424005, acc: 60.94%, op_acc: 36.72%] [G loss: 0.913442]\n",
      "epoch:8 step:6843[D loss: 0.435127, acc: 65.62%, op_acc: 28.12%] [G loss: 0.914045]\n",
      "epoch:8 step:6844[D loss: 0.416743, acc: 67.19%, op_acc: 36.72%] [G loss: 0.903338]\n",
      "epoch:8 step:6845[D loss: 0.482842, acc: 50.00%, op_acc: 32.81%] [G loss: 0.902563]\n",
      "epoch:8 step:6846[D loss: 0.438678, acc: 60.94%, op_acc: 33.59%] [G loss: 0.866696]\n",
      "epoch:8 step:6847[D loss: 0.454083, acc: 64.06%, op_acc: 32.81%] [G loss: 0.963597]\n",
      "epoch:8 step:6848[D loss: 0.428035, acc: 63.28%, op_acc: 36.72%] [G loss: 0.903637]\n",
      "epoch:8 step:6849[D loss: 0.433780, acc: 60.16%, op_acc: 34.38%] [G loss: 0.892893]\n",
      "epoch:8 step:6850[D loss: 0.420971, acc: 57.81%, op_acc: 40.62%] [G loss: 0.885273]\n",
      "##############\n",
      "[0.85858119 0.86143092 0.82464901 0.79763219 0.83325779 0.80381052\n",
      " 0.88491018 0.83365275 0.82516008 0.85663419]\n",
      "##########\n",
      "epoch:8 step:6851[D loss: 0.410293, acc: 66.41%, op_acc: 40.62%] [G loss: 0.914880]\n",
      "epoch:8 step:6852[D loss: 0.479694, acc: 57.03%, op_acc: 30.47%] [G loss: 0.781455]\n",
      "epoch:8 step:6853[D loss: 0.449389, acc: 60.16%, op_acc: 28.91%] [G loss: 0.860048]\n",
      "epoch:8 step:6854[D loss: 0.442607, acc: 58.59%, op_acc: 35.94%] [G loss: 0.891383]\n",
      "epoch:8 step:6855[D loss: 0.442238, acc: 56.25%, op_acc: 39.06%] [G loss: 0.854665]\n",
      "epoch:8 step:6856[D loss: 0.433714, acc: 59.38%, op_acc: 36.72%] [G loss: 0.915443]\n",
      "epoch:8 step:6857[D loss: 0.460996, acc: 50.00%, op_acc: 33.59%] [G loss: 0.869359]\n",
      "epoch:8 step:6858[D loss: 0.423623, acc: 60.16%, op_acc: 35.16%] [G loss: 0.861818]\n",
      "epoch:8 step:6859[D loss: 0.451076, acc: 53.91%, op_acc: 35.94%] [G loss: 0.875068]\n",
      "epoch:8 step:6860[D loss: 0.437349, acc: 63.28%, op_acc: 33.59%] [G loss: 0.785150]\n",
      "epoch:8 step:6861[D loss: 0.474306, acc: 50.00%, op_acc: 37.50%] [G loss: 0.857412]\n",
      "epoch:8 step:6862[D loss: 0.423641, acc: 64.06%, op_acc: 35.16%] [G loss: 0.831743]\n",
      "epoch:8 step:6863[D loss: 0.431950, acc: 64.84%, op_acc: 34.38%] [G loss: 0.886420]\n",
      "epoch:8 step:6864[D loss: 0.473372, acc: 53.12%, op_acc: 35.94%] [G loss: 0.885716]\n",
      "epoch:8 step:6865[D loss: 0.467692, acc: 55.47%, op_acc: 31.25%] [G loss: 0.907497]\n",
      "epoch:8 step:6866[D loss: 0.424369, acc: 63.28%, op_acc: 34.38%] [G loss: 0.925911]\n",
      "epoch:8 step:6867[D loss: 0.452492, acc: 63.28%, op_acc: 32.81%] [G loss: 0.920439]\n",
      "epoch:8 step:6868[D loss: 0.398164, acc: 74.22%, op_acc: 38.28%] [G loss: 0.912506]\n",
      "epoch:8 step:6869[D loss: 0.423441, acc: 66.41%, op_acc: 32.03%] [G loss: 0.951640]\n",
      "epoch:8 step:6870[D loss: 0.455244, acc: 61.72%, op_acc: 32.81%] [G loss: 0.844574]\n",
      "epoch:8 step:6871[D loss: 0.432902, acc: 55.47%, op_acc: 35.16%] [G loss: 0.841879]\n",
      "epoch:8 step:6872[D loss: 0.455017, acc: 57.81%, op_acc: 33.59%] [G loss: 0.872974]\n",
      "epoch:8 step:6873[D loss: 0.469204, acc: 48.44%, op_acc: 39.06%] [G loss: 0.811132]\n",
      "epoch:8 step:6874[D loss: 0.427773, acc: 59.38%, op_acc: 39.84%] [G loss: 0.894658]\n",
      "epoch:8 step:6875[D loss: 0.447358, acc: 56.25%, op_acc: 35.94%] [G loss: 0.826693]\n",
      "epoch:8 step:6876[D loss: 0.463433, acc: 54.69%, op_acc: 32.03%] [G loss: 0.874338]\n",
      "epoch:8 step:6877[D loss: 0.464657, acc: 63.28%, op_acc: 32.03%] [G loss: 0.843334]\n",
      "epoch:8 step:6878[D loss: 0.457587, acc: 53.91%, op_acc: 30.47%] [G loss: 0.845694]\n",
      "epoch:8 step:6879[D loss: 0.472381, acc: 48.44%, op_acc: 34.38%] [G loss: 0.874865]\n",
      "epoch:8 step:6880[D loss: 0.453660, acc: 64.06%, op_acc: 30.47%] [G loss: 0.878684]\n",
      "epoch:8 step:6881[D loss: 0.434880, acc: 63.28%, op_acc: 33.59%] [G loss: 0.898607]\n",
      "epoch:8 step:6882[D loss: 0.439848, acc: 55.47%, op_acc: 38.28%] [G loss: 0.832603]\n",
      "epoch:8 step:6883[D loss: 0.462582, acc: 54.69%, op_acc: 31.25%] [G loss: 0.907066]\n",
      "epoch:8 step:6884[D loss: 0.427645, acc: 59.38%, op_acc: 40.62%] [G loss: 0.876045]\n",
      "epoch:8 step:6885[D loss: 0.435785, acc: 62.50%, op_acc: 34.38%] [G loss: 0.882263]\n",
      "epoch:8 step:6886[D loss: 0.480438, acc: 52.34%, op_acc: 33.59%] [G loss: 0.920391]\n",
      "epoch:8 step:6887[D loss: 0.442117, acc: 63.28%, op_acc: 37.50%] [G loss: 0.921247]\n",
      "epoch:8 step:6888[D loss: 0.487636, acc: 46.88%, op_acc: 35.16%] [G loss: 0.911778]\n",
      "epoch:8 step:6889[D loss: 0.459750, acc: 54.69%, op_acc: 34.38%] [G loss: 0.972035]\n",
      "epoch:8 step:6890[D loss: 0.437910, acc: 61.72%, op_acc: 29.69%] [G loss: 0.906840]\n",
      "epoch:8 step:6891[D loss: 0.474218, acc: 51.56%, op_acc: 32.03%] [G loss: 0.857093]\n",
      "epoch:8 step:6892[D loss: 0.433978, acc: 60.94%, op_acc: 39.06%] [G loss: 0.965816]\n",
      "epoch:8 step:6893[D loss: 0.461812, acc: 58.59%, op_acc: 30.47%] [G loss: 0.892524]\n",
      "epoch:8 step:6894[D loss: 0.450441, acc: 58.59%, op_acc: 29.69%] [G loss: 0.916836]\n",
      "epoch:8 step:6895[D loss: 0.437224, acc: 57.81%, op_acc: 41.41%] [G loss: 0.863875]\n",
      "epoch:8 step:6896[D loss: 0.448663, acc: 57.81%, op_acc: 31.25%] [G loss: 0.864898]\n",
      "epoch:8 step:6897[D loss: 0.459951, acc: 50.78%, op_acc: 29.69%] [G loss: 0.895491]\n",
      "epoch:8 step:6898[D loss: 0.470960, acc: 59.38%, op_acc: 30.47%] [G loss: 0.913732]\n",
      "epoch:8 step:6899[D loss: 0.426525, acc: 61.72%, op_acc: 35.94%] [G loss: 0.957587]\n",
      "epoch:8 step:6900[D loss: 0.447228, acc: 56.25%, op_acc: 33.59%] [G loss: 0.862373]\n",
      "##############\n",
      "[0.85808901 0.86972523 0.8213031  0.82020717 0.75924161 0.84476161\n",
      " 0.87424326 0.8360171  0.81804699 0.83648846]\n",
      "##########\n",
      "epoch:8 step:6901[D loss: 0.432322, acc: 59.38%, op_acc: 39.06%] [G loss: 0.915542]\n",
      "epoch:8 step:6902[D loss: 0.415322, acc: 66.41%, op_acc: 39.84%] [G loss: 0.876535]\n",
      "epoch:8 step:6903[D loss: 0.453423, acc: 58.59%, op_acc: 28.91%] [G loss: 0.904192]\n",
      "epoch:8 step:6904[D loss: 0.446357, acc: 59.38%, op_acc: 33.59%] [G loss: 0.885176]\n",
      "epoch:8 step:6905[D loss: 0.466744, acc: 55.47%, op_acc: 32.81%] [G loss: 0.820017]\n",
      "epoch:8 step:6906[D loss: 0.415909, acc: 70.31%, op_acc: 30.47%] [G loss: 0.878570]\n",
      "epoch:8 step:6907[D loss: 0.436629, acc: 66.41%, op_acc: 29.69%] [G loss: 0.949662]\n",
      "epoch:8 step:6908[D loss: 0.420739, acc: 63.28%, op_acc: 41.41%] [G loss: 0.889416]\n",
      "epoch:8 step:6909[D loss: 0.449271, acc: 53.12%, op_acc: 36.72%] [G loss: 0.914028]\n",
      "epoch:8 step:6910[D loss: 0.444649, acc: 53.91%, op_acc: 39.84%] [G loss: 0.863724]\n",
      "epoch:8 step:6911[D loss: 0.410310, acc: 58.59%, op_acc: 43.75%] [G loss: 0.898801]\n",
      "epoch:8 step:6912[D loss: 0.419155, acc: 64.06%, op_acc: 37.50%] [G loss: 0.880343]\n",
      "epoch:8 step:6913[D loss: 0.449420, acc: 59.38%, op_acc: 28.91%] [G loss: 0.869196]\n",
      "epoch:8 step:6914[D loss: 0.438248, acc: 60.16%, op_acc: 35.16%] [G loss: 0.980696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6915[D loss: 0.421234, acc: 65.62%, op_acc: 34.38%] [G loss: 0.900705]\n",
      "epoch:8 step:6916[D loss: 0.449709, acc: 58.59%, op_acc: 35.94%] [G loss: 0.856535]\n",
      "epoch:8 step:6917[D loss: 0.453665, acc: 64.06%, op_acc: 32.03%] [G loss: 0.857013]\n",
      "epoch:8 step:6918[D loss: 0.432917, acc: 57.81%, op_acc: 38.28%] [G loss: 0.894932]\n",
      "epoch:8 step:6919[D loss: 0.441034, acc: 62.50%, op_acc: 31.25%] [G loss: 0.950579]\n",
      "epoch:8 step:6920[D loss: 0.452225, acc: 57.81%, op_acc: 32.03%] [G loss: 0.865017]\n",
      "epoch:8 step:6921[D loss: 0.451998, acc: 59.38%, op_acc: 32.03%] [G loss: 0.922659]\n",
      "epoch:8 step:6922[D loss: 0.455195, acc: 55.47%, op_acc: 35.94%] [G loss: 0.856863]\n",
      "epoch:8 step:6923[D loss: 0.458316, acc: 54.69%, op_acc: 35.94%] [G loss: 0.837631]\n",
      "epoch:8 step:6924[D loss: 0.471837, acc: 57.03%, op_acc: 29.69%] [G loss: 0.909527]\n",
      "epoch:8 step:6925[D loss: 0.461650, acc: 54.69%, op_acc: 30.47%] [G loss: 0.845633]\n",
      "epoch:8 step:6926[D loss: 0.445889, acc: 64.06%, op_acc: 32.81%] [G loss: 0.892834]\n",
      "epoch:8 step:6927[D loss: 0.454158, acc: 57.03%, op_acc: 32.81%] [G loss: 0.872066]\n",
      "epoch:8 step:6928[D loss: 0.458711, acc: 56.25%, op_acc: 32.03%] [G loss: 0.928656]\n",
      "epoch:8 step:6929[D loss: 0.470307, acc: 59.38%, op_acc: 25.78%] [G loss: 0.852302]\n",
      "epoch:8 step:6930[D loss: 0.424191, acc: 53.12%, op_acc: 37.50%] [G loss: 0.952684]\n",
      "epoch:8 step:6931[D loss: 0.460932, acc: 59.38%, op_acc: 39.84%] [G loss: 0.884951]\n",
      "epoch:8 step:6932[D loss: 0.431476, acc: 62.50%, op_acc: 32.81%] [G loss: 0.929236]\n",
      "epoch:8 step:6933[D loss: 0.459535, acc: 57.81%, op_acc: 32.03%] [G loss: 0.898244]\n",
      "epoch:8 step:6934[D loss: 0.457225, acc: 56.25%, op_acc: 31.25%] [G loss: 0.845590]\n",
      "epoch:8 step:6935[D loss: 0.449754, acc: 51.56%, op_acc: 33.59%] [G loss: 0.838450]\n",
      "epoch:8 step:6936[D loss: 0.459756, acc: 52.34%, op_acc: 32.03%] [G loss: 0.908864]\n",
      "epoch:8 step:6937[D loss: 0.443781, acc: 55.47%, op_acc: 34.38%] [G loss: 0.838522]\n",
      "epoch:8 step:6938[D loss: 0.446920, acc: 64.84%, op_acc: 34.38%] [G loss: 0.827087]\n",
      "epoch:8 step:6939[D loss: 0.468379, acc: 55.47%, op_acc: 32.81%] [G loss: 0.882915]\n",
      "epoch:8 step:6940[D loss: 0.440029, acc: 63.28%, op_acc: 31.25%] [G loss: 0.914606]\n",
      "epoch:8 step:6941[D loss: 0.456130, acc: 57.03%, op_acc: 29.69%] [G loss: 0.841890]\n",
      "epoch:8 step:6942[D loss: 0.454122, acc: 55.47%, op_acc: 32.81%] [G loss: 0.903503]\n",
      "epoch:8 step:6943[D loss: 0.443769, acc: 66.41%, op_acc: 33.59%] [G loss: 0.868938]\n",
      "epoch:8 step:6944[D loss: 0.471214, acc: 52.34%, op_acc: 32.81%] [G loss: 0.839973]\n",
      "epoch:8 step:6945[D loss: 0.441111, acc: 57.03%, op_acc: 31.25%] [G loss: 0.815425]\n",
      "epoch:8 step:6946[D loss: 0.448673, acc: 58.59%, op_acc: 38.28%] [G loss: 0.958141]\n",
      "epoch:8 step:6947[D loss: 0.440498, acc: 52.34%, op_acc: 36.72%] [G loss: 0.879015]\n",
      "epoch:8 step:6948[D loss: 0.440425, acc: 58.59%, op_acc: 34.38%] [G loss: 0.873541]\n",
      "epoch:8 step:6949[D loss: 0.411798, acc: 68.75%, op_acc: 32.81%] [G loss: 0.962018]\n",
      "epoch:8 step:6950[D loss: 0.441444, acc: 59.38%, op_acc: 35.16%] [G loss: 0.844339]\n",
      "##############\n",
      "[0.87615639 0.85619086 0.81128059 0.81033932 0.77595529 0.83035747\n",
      " 0.89258262 0.84776743 0.82351178 0.80376428]\n",
      "##########\n",
      "epoch:8 step:6951[D loss: 0.458865, acc: 57.81%, op_acc: 30.47%] [G loss: 0.839583]\n",
      "epoch:8 step:6952[D loss: 0.388775, acc: 65.62%, op_acc: 44.53%] [G loss: 0.885778]\n",
      "epoch:8 step:6953[D loss: 0.462886, acc: 53.12%, op_acc: 34.38%] [G loss: 0.933985]\n",
      "epoch:8 step:6954[D loss: 0.452156, acc: 58.59%, op_acc: 32.03%] [G loss: 0.846015]\n",
      "epoch:8 step:6955[D loss: 0.468031, acc: 54.69%, op_acc: 30.47%] [G loss: 0.835107]\n",
      "epoch:8 step:6956[D loss: 0.433984, acc: 64.06%, op_acc: 32.81%] [G loss: 0.870623]\n",
      "epoch:8 step:6957[D loss: 0.438168, acc: 64.84%, op_acc: 29.69%] [G loss: 0.846123]\n",
      "epoch:8 step:6958[D loss: 0.425520, acc: 57.81%, op_acc: 36.72%] [G loss: 0.848077]\n",
      "epoch:8 step:6959[D loss: 0.427522, acc: 67.19%, op_acc: 35.94%] [G loss: 0.882724]\n",
      "epoch:8 step:6960[D loss: 0.429472, acc: 58.59%, op_acc: 34.38%] [G loss: 0.862000]\n",
      "epoch:8 step:6961[D loss: 0.422051, acc: 64.06%, op_acc: 38.28%] [G loss: 0.907094]\n",
      "epoch:8 step:6962[D loss: 0.444431, acc: 59.38%, op_acc: 32.03%] [G loss: 0.787794]\n",
      "epoch:8 step:6963[D loss: 0.439164, acc: 54.69%, op_acc: 33.59%] [G loss: 0.891765]\n",
      "epoch:8 step:6964[D loss: 0.456920, acc: 53.91%, op_acc: 39.84%] [G loss: 0.918788]\n",
      "epoch:8 step:6965[D loss: 0.428741, acc: 60.94%, op_acc: 35.16%] [G loss: 0.828560]\n",
      "epoch:8 step:6966[D loss: 0.450131, acc: 58.59%, op_acc: 32.81%] [G loss: 0.855172]\n",
      "epoch:8 step:6967[D loss: 0.447464, acc: 51.56%, op_acc: 32.03%] [G loss: 0.893798]\n",
      "epoch:8 step:6968[D loss: 0.454761, acc: 59.38%, op_acc: 34.38%] [G loss: 0.895516]\n",
      "epoch:8 step:6969[D loss: 0.439915, acc: 56.25%, op_acc: 40.62%] [G loss: 0.905295]\n",
      "epoch:8 step:6970[D loss: 0.441230, acc: 55.47%, op_acc: 34.38%] [G loss: 0.942885]\n",
      "epoch:8 step:6971[D loss: 0.407418, acc: 67.97%, op_acc: 36.72%] [G loss: 0.827641]\n",
      "epoch:8 step:6972[D loss: 0.465242, acc: 63.28%, op_acc: 31.25%] [G loss: 1.009997]\n",
      "epoch:8 step:6973[D loss: 0.428235, acc: 60.94%, op_acc: 38.28%] [G loss: 0.923241]\n",
      "epoch:8 step:6974[D loss: 0.416101, acc: 66.41%, op_acc: 35.94%] [G loss: 0.900055]\n",
      "epoch:8 step:6975[D loss: 0.430476, acc: 64.06%, op_acc: 34.38%] [G loss: 0.845698]\n",
      "epoch:8 step:6976[D loss: 0.464607, acc: 53.91%, op_acc: 30.47%] [G loss: 0.838026]\n",
      "epoch:8 step:6977[D loss: 0.439344, acc: 58.59%, op_acc: 35.94%] [G loss: 0.926934]\n",
      "epoch:8 step:6978[D loss: 0.421901, acc: 64.84%, op_acc: 32.81%] [G loss: 0.875201]\n",
      "epoch:8 step:6979[D loss: 0.416201, acc: 65.62%, op_acc: 40.62%] [G loss: 0.853134]\n",
      "epoch:8 step:6980[D loss: 0.428481, acc: 60.16%, op_acc: 30.47%] [G loss: 0.886498]\n",
      "epoch:8 step:6981[D loss: 0.452371, acc: 57.81%, op_acc: 34.38%] [G loss: 0.854775]\n",
      "epoch:8 step:6982[D loss: 0.446330, acc: 58.59%, op_acc: 35.16%] [G loss: 0.797316]\n",
      "epoch:8 step:6983[D loss: 0.451406, acc: 55.47%, op_acc: 34.38%] [G loss: 0.783090]\n",
      "epoch:8 step:6984[D loss: 0.465506, acc: 53.91%, op_acc: 33.59%] [G loss: 0.887874]\n",
      "epoch:8 step:6985[D loss: 0.436176, acc: 56.25%, op_acc: 35.94%] [G loss: 0.848191]\n",
      "epoch:8 step:6986[D loss: 0.443504, acc: 58.59%, op_acc: 35.16%] [G loss: 0.887052]\n",
      "epoch:8 step:6987[D loss: 0.417692, acc: 64.84%, op_acc: 42.19%] [G loss: 0.945432]\n",
      "epoch:8 step:6988[D loss: 0.438756, acc: 56.25%, op_acc: 34.38%] [G loss: 0.868896]\n",
      "epoch:8 step:6989[D loss: 0.421899, acc: 66.41%, op_acc: 35.94%] [G loss: 0.935468]\n",
      "epoch:8 step:6990[D loss: 0.431406, acc: 64.06%, op_acc: 37.50%] [G loss: 0.943841]\n",
      "epoch:8 step:6991[D loss: 0.450101, acc: 60.16%, op_acc: 33.59%] [G loss: 0.895727]\n",
      "epoch:8 step:6992[D loss: 0.432134, acc: 53.12%, op_acc: 42.19%] [G loss: 0.868531]\n",
      "epoch:8 step:6993[D loss: 0.423423, acc: 57.03%, op_acc: 35.16%] [G loss: 0.975696]\n",
      "epoch:8 step:6994[D loss: 0.482511, acc: 52.34%, op_acc: 35.16%] [G loss: 0.977837]\n",
      "epoch:8 step:6995[D loss: 0.436285, acc: 61.72%, op_acc: 35.16%] [G loss: 0.862563]\n",
      "epoch:8 step:6996[D loss: 0.462203, acc: 57.03%, op_acc: 32.81%] [G loss: 0.891580]\n",
      "epoch:8 step:6997[D loss: 0.488872, acc: 46.88%, op_acc: 35.94%] [G loss: 0.856261]\n",
      "epoch:8 step:6998[D loss: 0.440265, acc: 59.38%, op_acc: 33.59%] [G loss: 0.835746]\n",
      "epoch:8 step:6999[D loss: 0.455171, acc: 62.50%, op_acc: 28.12%] [G loss: 0.871357]\n",
      "epoch:8 step:7000[D loss: 0.454900, acc: 58.59%, op_acc: 36.72%] [G loss: 0.879505]\n",
      "##############\n",
      "[0.86145117 0.85837553 0.80297795 0.81906156 0.77139978 0.81559992\n",
      " 0.91230401 0.81642144 0.81742719 0.83252497]\n",
      "##########\n",
      "epoch:8 step:7001[D loss: 0.432283, acc: 63.28%, op_acc: 34.38%] [G loss: 0.912341]\n",
      "epoch:8 step:7002[D loss: 0.451725, acc: 58.59%, op_acc: 34.38%] [G loss: 0.869422]\n",
      "epoch:8 step:7003[D loss: 0.419518, acc: 67.97%, op_acc: 38.28%] [G loss: 0.881319]\n",
      "epoch:8 step:7004[D loss: 0.426390, acc: 57.81%, op_acc: 42.97%] [G loss: 0.858281]\n",
      "epoch:8 step:7005[D loss: 0.432643, acc: 63.28%, op_acc: 34.38%] [G loss: 0.879277]\n",
      "epoch:8 step:7006[D loss: 0.413499, acc: 67.19%, op_acc: 38.28%] [G loss: 0.932427]\n",
      "epoch:8 step:7007[D loss: 0.452398, acc: 60.16%, op_acc: 34.38%] [G loss: 0.856507]\n",
      "epoch:8 step:7008[D loss: 0.455066, acc: 52.34%, op_acc: 34.38%] [G loss: 0.842629]\n",
      "epoch:8 step:7009[D loss: 0.438140, acc: 59.38%, op_acc: 35.16%] [G loss: 0.884325]\n",
      "epoch:8 step:7010[D loss: 0.480052, acc: 53.12%, op_acc: 25.78%] [G loss: 0.866788]\n",
      "epoch:8 step:7011[D loss: 0.432579, acc: 60.94%, op_acc: 35.16%] [G loss: 0.826459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7012[D loss: 0.466491, acc: 49.22%, op_acc: 33.59%] [G loss: 0.843917]\n",
      "epoch:8 step:7013[D loss: 0.461477, acc: 53.12%, op_acc: 33.59%] [G loss: 0.885357]\n",
      "epoch:8 step:7014[D loss: 0.474152, acc: 54.69%, op_acc: 28.91%] [G loss: 0.796185]\n",
      "epoch:8 step:7015[D loss: 0.446629, acc: 54.69%, op_acc: 32.03%] [G loss: 0.853964]\n",
      "epoch:8 step:7016[D loss: 0.448949, acc: 58.59%, op_acc: 29.69%] [G loss: 0.923451]\n",
      "epoch:8 step:7017[D loss: 0.421485, acc: 57.81%, op_acc: 39.84%] [G loss: 0.843849]\n",
      "epoch:8 step:7018[D loss: 0.409388, acc: 67.19%, op_acc: 34.38%] [G loss: 0.834779]\n",
      "epoch:8 step:7019[D loss: 0.465080, acc: 60.16%, op_acc: 31.25%] [G loss: 0.890994]\n",
      "epoch:8 step:7020[D loss: 0.452595, acc: 60.16%, op_acc: 33.59%] [G loss: 0.839917]\n",
      "epoch:8 step:7021[D loss: 0.453974, acc: 60.16%, op_acc: 33.59%] [G loss: 0.870468]\n",
      "epoch:8 step:7022[D loss: 0.395118, acc: 60.16%, op_acc: 41.41%] [G loss: 0.820873]\n",
      "epoch:8 step:7023[D loss: 0.435262, acc: 59.38%, op_acc: 37.50%] [G loss: 0.943155]\n",
      "epoch:8 step:7024[D loss: 0.426076, acc: 58.59%, op_acc: 35.94%] [G loss: 0.838256]\n",
      "epoch:8 step:7025[D loss: 0.492076, acc: 55.47%, op_acc: 25.00%] [G loss: 0.921916]\n",
      "epoch:8 step:7026[D loss: 0.447550, acc: 56.25%, op_acc: 39.84%] [G loss: 0.870133]\n",
      "epoch:8 step:7027[D loss: 0.426805, acc: 64.06%, op_acc: 36.72%] [G loss: 0.888988]\n",
      "epoch:8 step:7028[D loss: 0.428325, acc: 59.38%, op_acc: 40.62%] [G loss: 0.852259]\n",
      "epoch:8 step:7029[D loss: 0.453894, acc: 56.25%, op_acc: 35.94%] [G loss: 0.838983]\n",
      "epoch:9 step:7030[D loss: 0.432305, acc: 63.28%, op_acc: 37.50%] [G loss: 0.871129]\n",
      "epoch:9 step:7031[D loss: 0.428367, acc: 63.28%, op_acc: 33.59%] [G loss: 0.889852]\n",
      "epoch:9 step:7032[D loss: 0.433875, acc: 60.16%, op_acc: 38.28%] [G loss: 0.835099]\n",
      "epoch:9 step:7033[D loss: 0.427192, acc: 59.38%, op_acc: 42.19%] [G loss: 0.866130]\n",
      "epoch:9 step:7034[D loss: 0.439027, acc: 56.25%, op_acc: 38.28%] [G loss: 0.871854]\n",
      "epoch:9 step:7035[D loss: 0.458537, acc: 56.25%, op_acc: 35.16%] [G loss: 0.884891]\n",
      "epoch:9 step:7036[D loss: 0.440478, acc: 53.91%, op_acc: 36.72%] [G loss: 0.859549]\n",
      "epoch:9 step:7037[D loss: 0.438184, acc: 63.28%, op_acc: 27.34%] [G loss: 0.898282]\n",
      "epoch:9 step:7038[D loss: 0.414528, acc: 59.38%, op_acc: 41.41%] [G loss: 0.904858]\n",
      "epoch:9 step:7039[D loss: 0.459498, acc: 56.25%, op_acc: 35.16%] [G loss: 0.830871]\n",
      "epoch:9 step:7040[D loss: 0.455249, acc: 62.50%, op_acc: 33.59%] [G loss: 0.930469]\n",
      "epoch:9 step:7041[D loss: 0.420784, acc: 64.84%, op_acc: 33.59%] [G loss: 0.934661]\n",
      "epoch:9 step:7042[D loss: 0.429861, acc: 67.19%, op_acc: 32.03%] [G loss: 0.884236]\n",
      "epoch:9 step:7043[D loss: 0.459296, acc: 60.94%, op_acc: 31.25%] [G loss: 0.923757]\n",
      "epoch:9 step:7044[D loss: 0.462237, acc: 54.69%, op_acc: 32.81%] [G loss: 0.860396]\n",
      "epoch:9 step:7045[D loss: 0.426526, acc: 59.38%, op_acc: 37.50%] [G loss: 0.897166]\n",
      "epoch:9 step:7046[D loss: 0.441610, acc: 62.50%, op_acc: 35.16%] [G loss: 0.867695]\n",
      "epoch:9 step:7047[D loss: 0.419913, acc: 57.03%, op_acc: 38.28%] [G loss: 0.900671]\n",
      "epoch:9 step:7048[D loss: 0.434915, acc: 60.16%, op_acc: 35.94%] [G loss: 0.877368]\n",
      "epoch:9 step:7049[D loss: 0.428263, acc: 59.38%, op_acc: 35.16%] [G loss: 0.958639]\n",
      "epoch:9 step:7050[D loss: 0.459828, acc: 50.78%, op_acc: 37.50%] [G loss: 0.901650]\n",
      "##############\n",
      "[0.85491331 0.85170059 0.82777844 0.81743678 0.82684631 0.8436965\n",
      " 0.8913952  0.82931891 0.80607062 0.82954141]\n",
      "##########\n",
      "epoch:9 step:7051[D loss: 0.429292, acc: 56.25%, op_acc: 36.72%] [G loss: 0.875531]\n",
      "epoch:9 step:7052[D loss: 0.434609, acc: 59.38%, op_acc: 43.75%] [G loss: 0.885896]\n",
      "epoch:9 step:7053[D loss: 0.446474, acc: 67.19%, op_acc: 32.81%] [G loss: 0.928325]\n",
      "epoch:9 step:7054[D loss: 0.431580, acc: 67.97%, op_acc: 32.81%] [G loss: 0.885177]\n",
      "epoch:9 step:7055[D loss: 0.424621, acc: 56.25%, op_acc: 35.94%] [G loss: 0.845610]\n",
      "epoch:9 step:7056[D loss: 0.429858, acc: 64.06%, op_acc: 38.28%] [G loss: 0.927256]\n",
      "epoch:9 step:7057[D loss: 0.427678, acc: 58.59%, op_acc: 35.94%] [G loss: 0.920520]\n",
      "epoch:9 step:7058[D loss: 0.436600, acc: 54.69%, op_acc: 39.06%] [G loss: 0.928564]\n",
      "epoch:9 step:7059[D loss: 0.411932, acc: 61.72%, op_acc: 41.41%] [G loss: 0.866350]\n",
      "epoch:9 step:7060[D loss: 0.449404, acc: 58.59%, op_acc: 35.16%] [G loss: 0.900709]\n",
      "epoch:9 step:7061[D loss: 0.466771, acc: 52.34%, op_acc: 35.94%] [G loss: 0.854717]\n",
      "epoch:9 step:7062[D loss: 0.426598, acc: 57.03%, op_acc: 42.19%] [G loss: 0.914316]\n",
      "epoch:9 step:7063[D loss: 0.453667, acc: 48.44%, op_acc: 39.84%] [G loss: 0.837016]\n",
      "epoch:9 step:7064[D loss: 0.451762, acc: 56.25%, op_acc: 33.59%] [G loss: 0.882877]\n",
      "epoch:9 step:7065[D loss: 0.410480, acc: 69.53%, op_acc: 39.84%] [G loss: 0.845347]\n",
      "epoch:9 step:7066[D loss: 0.420953, acc: 57.03%, op_acc: 37.50%] [G loss: 0.968288]\n",
      "epoch:9 step:7067[D loss: 0.452822, acc: 48.44%, op_acc: 35.94%] [G loss: 0.850281]\n",
      "epoch:9 step:7068[D loss: 0.424465, acc: 61.72%, op_acc: 35.16%] [G loss: 0.864774]\n",
      "epoch:9 step:7069[D loss: 0.471907, acc: 44.53%, op_acc: 32.03%] [G loss: 0.854370]\n",
      "epoch:9 step:7070[D loss: 0.416805, acc: 62.50%, op_acc: 37.50%] [G loss: 0.981659]\n",
      "epoch:9 step:7071[D loss: 0.410864, acc: 59.38%, op_acc: 45.31%] [G loss: 0.917540]\n",
      "epoch:9 step:7072[D loss: 0.448005, acc: 60.16%, op_acc: 32.81%] [G loss: 0.868986]\n",
      "epoch:9 step:7073[D loss: 0.451816, acc: 56.25%, op_acc: 31.25%] [G loss: 0.856249]\n",
      "epoch:9 step:7074[D loss: 0.426737, acc: 60.94%, op_acc: 39.06%] [G loss: 0.907929]\n",
      "epoch:9 step:7075[D loss: 0.439082, acc: 60.16%, op_acc: 32.03%] [G loss: 0.886464]\n",
      "epoch:9 step:7076[D loss: 0.472563, acc: 57.81%, op_acc: 28.12%] [G loss: 0.918219]\n",
      "epoch:9 step:7077[D loss: 0.476600, acc: 51.56%, op_acc: 32.81%] [G loss: 0.885627]\n",
      "epoch:9 step:7078[D loss: 0.445691, acc: 60.94%, op_acc: 33.59%] [G loss: 0.852093]\n",
      "epoch:9 step:7079[D loss: 0.469704, acc: 52.34%, op_acc: 34.38%] [G loss: 0.884075]\n",
      "epoch:9 step:7080[D loss: 0.435616, acc: 56.25%, op_acc: 37.50%] [G loss: 0.908669]\n",
      "epoch:9 step:7081[D loss: 0.460205, acc: 55.47%, op_acc: 32.03%] [G loss: 0.924840]\n",
      "epoch:9 step:7082[D loss: 0.447755, acc: 55.47%, op_acc: 34.38%] [G loss: 0.901199]\n",
      "epoch:9 step:7083[D loss: 0.471084, acc: 57.81%, op_acc: 34.38%] [G loss: 0.871326]\n",
      "epoch:9 step:7084[D loss: 0.445186, acc: 51.56%, op_acc: 35.94%] [G loss: 0.872317]\n",
      "epoch:9 step:7085[D loss: 0.430217, acc: 57.81%, op_acc: 35.16%] [G loss: 0.867211]\n",
      "epoch:9 step:7086[D loss: 0.458494, acc: 57.81%, op_acc: 30.47%] [G loss: 0.862419]\n",
      "epoch:9 step:7087[D loss: 0.428141, acc: 63.28%, op_acc: 36.72%] [G loss: 0.916040]\n",
      "epoch:9 step:7088[D loss: 0.426536, acc: 60.94%, op_acc: 37.50%] [G loss: 0.890467]\n",
      "epoch:9 step:7089[D loss: 0.435174, acc: 59.38%, op_acc: 35.94%] [G loss: 0.962070]\n",
      "epoch:9 step:7090[D loss: 0.448869, acc: 63.28%, op_acc: 28.91%] [G loss: 0.911926]\n",
      "epoch:9 step:7091[D loss: 0.458434, acc: 53.12%, op_acc: 29.69%] [G loss: 0.861188]\n",
      "epoch:9 step:7092[D loss: 0.438173, acc: 54.69%, op_acc: 36.72%] [G loss: 0.935826]\n",
      "epoch:9 step:7093[D loss: 0.439942, acc: 59.38%, op_acc: 31.25%] [G loss: 0.872849]\n",
      "epoch:9 step:7094[D loss: 0.449245, acc: 56.25%, op_acc: 35.16%] [G loss: 0.833995]\n",
      "epoch:9 step:7095[D loss: 0.477384, acc: 49.22%, op_acc: 36.72%] [G loss: 0.831656]\n",
      "epoch:9 step:7096[D loss: 0.413597, acc: 66.41%, op_acc: 43.75%] [G loss: 0.886454]\n",
      "epoch:9 step:7097[D loss: 0.430723, acc: 62.50%, op_acc: 35.94%] [G loss: 0.860379]\n",
      "epoch:9 step:7098[D loss: 0.422140, acc: 61.72%, op_acc: 38.28%] [G loss: 0.911911]\n",
      "epoch:9 step:7099[D loss: 0.457184, acc: 55.47%, op_acc: 34.38%] [G loss: 0.867828]\n",
      "epoch:9 step:7100[D loss: 0.462906, acc: 61.72%, op_acc: 25.78%] [G loss: 0.921467]\n",
      "##############\n",
      "[0.85892057 0.85398319 0.82403402 0.81150055 0.78889784 0.80123275\n",
      " 0.88451619 0.83686688 0.80579365 0.85676186]\n",
      "##########\n",
      "epoch:9 step:7101[D loss: 0.444822, acc: 53.91%, op_acc: 36.72%] [G loss: 0.781274]\n",
      "epoch:9 step:7102[D loss: 0.418953, acc: 60.16%, op_acc: 39.06%] [G loss: 0.936673]\n",
      "epoch:9 step:7103[D loss: 0.453537, acc: 50.78%, op_acc: 38.28%] [G loss: 0.849815]\n",
      "epoch:9 step:7104[D loss: 0.433738, acc: 65.62%, op_acc: 34.38%] [G loss: 0.890425]\n",
      "epoch:9 step:7105[D loss: 0.465872, acc: 57.03%, op_acc: 36.72%] [G loss: 0.915483]\n",
      "epoch:9 step:7106[D loss: 0.423680, acc: 61.72%, op_acc: 40.62%] [G loss: 0.915879]\n",
      "epoch:9 step:7107[D loss: 0.451521, acc: 67.97%, op_acc: 29.69%] [G loss: 1.042789]\n",
      "epoch:9 step:7108[D loss: 0.453281, acc: 55.47%, op_acc: 36.72%] [G loss: 0.883485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7109[D loss: 0.456446, acc: 65.62%, op_acc: 31.25%] [G loss: 0.896853]\n",
      "epoch:9 step:7110[D loss: 0.462059, acc: 60.94%, op_acc: 28.91%] [G loss: 0.903897]\n",
      "epoch:9 step:7111[D loss: 0.412652, acc: 64.06%, op_acc: 36.72%] [G loss: 0.991572]\n",
      "epoch:9 step:7112[D loss: 0.444492, acc: 60.16%, op_acc: 32.81%] [G loss: 0.833313]\n",
      "epoch:9 step:7113[D loss: 0.441278, acc: 57.81%, op_acc: 36.72%] [G loss: 0.823058]\n",
      "epoch:9 step:7114[D loss: 0.439444, acc: 60.16%, op_acc: 32.81%] [G loss: 0.822677]\n",
      "epoch:9 step:7115[D loss: 0.435353, acc: 59.38%, op_acc: 33.59%] [G loss: 0.942722]\n",
      "epoch:9 step:7116[D loss: 0.427016, acc: 65.62%, op_acc: 34.38%] [G loss: 0.849881]\n",
      "epoch:9 step:7117[D loss: 0.428125, acc: 60.94%, op_acc: 32.81%] [G loss: 0.865420]\n",
      "epoch:9 step:7118[D loss: 0.456785, acc: 57.03%, op_acc: 31.25%] [G loss: 0.900381]\n",
      "epoch:9 step:7119[D loss: 0.443644, acc: 57.81%, op_acc: 35.94%] [G loss: 0.828118]\n",
      "epoch:9 step:7120[D loss: 0.436241, acc: 60.94%, op_acc: 35.94%] [G loss: 0.845697]\n",
      "epoch:9 step:7121[D loss: 0.458306, acc: 50.78%, op_acc: 32.03%] [G loss: 0.844508]\n",
      "epoch:9 step:7122[D loss: 0.418571, acc: 59.38%, op_acc: 37.50%] [G loss: 0.851174]\n",
      "epoch:9 step:7123[D loss: 0.456730, acc: 54.69%, op_acc: 31.25%] [G loss: 0.819599]\n",
      "epoch:9 step:7124[D loss: 0.425325, acc: 64.06%, op_acc: 28.91%] [G loss: 0.886033]\n",
      "epoch:9 step:7125[D loss: 0.452784, acc: 55.47%, op_acc: 31.25%] [G loss: 0.886051]\n",
      "epoch:9 step:7126[D loss: 0.425789, acc: 64.84%, op_acc: 35.16%] [G loss: 0.819802]\n",
      "epoch:9 step:7127[D loss: 0.466034, acc: 50.00%, op_acc: 33.59%] [G loss: 0.845137]\n",
      "epoch:9 step:7128[D loss: 0.439824, acc: 56.25%, op_acc: 40.62%] [G loss: 0.848815]\n",
      "epoch:9 step:7129[D loss: 0.445311, acc: 52.34%, op_acc: 35.16%] [G loss: 0.792311]\n",
      "epoch:9 step:7130[D loss: 0.454742, acc: 54.69%, op_acc: 35.94%] [G loss: 0.903835]\n",
      "epoch:9 step:7131[D loss: 0.427132, acc: 62.50%, op_acc: 33.59%] [G loss: 0.877546]\n",
      "epoch:9 step:7132[D loss: 0.456887, acc: 53.12%, op_acc: 33.59%] [G loss: 0.818422]\n",
      "epoch:9 step:7133[D loss: 0.451839, acc: 55.47%, op_acc: 36.72%] [G loss: 0.875066]\n",
      "epoch:9 step:7134[D loss: 0.457982, acc: 50.00%, op_acc: 39.06%] [G loss: 0.875677]\n",
      "epoch:9 step:7135[D loss: 0.431249, acc: 61.72%, op_acc: 35.16%] [G loss: 0.874616]\n",
      "epoch:9 step:7136[D loss: 0.433825, acc: 64.06%, op_acc: 29.69%] [G loss: 0.778945]\n",
      "epoch:9 step:7137[D loss: 0.471496, acc: 57.03%, op_acc: 28.12%] [G loss: 0.829486]\n",
      "epoch:9 step:7138[D loss: 0.445541, acc: 60.94%, op_acc: 32.03%] [G loss: 0.916916]\n",
      "epoch:9 step:7139[D loss: 0.456949, acc: 57.81%, op_acc: 37.50%] [G loss: 0.814464]\n",
      "epoch:9 step:7140[D loss: 0.488150, acc: 56.25%, op_acc: 26.56%] [G loss: 0.852126]\n",
      "epoch:9 step:7141[D loss: 0.411178, acc: 65.62%, op_acc: 39.84%] [G loss: 0.849797]\n",
      "epoch:9 step:7142[D loss: 0.448361, acc: 54.69%, op_acc: 33.59%] [G loss: 0.902355]\n",
      "epoch:9 step:7143[D loss: 0.440912, acc: 55.47%, op_acc: 40.62%] [G loss: 0.808842]\n",
      "epoch:9 step:7144[D loss: 0.461109, acc: 53.91%, op_acc: 38.28%] [G loss: 0.823601]\n",
      "epoch:9 step:7145[D loss: 0.482230, acc: 50.78%, op_acc: 32.03%] [G loss: 0.865818]\n",
      "epoch:9 step:7146[D loss: 0.464360, acc: 52.34%, op_acc: 31.25%] [G loss: 0.879803]\n",
      "epoch:9 step:7147[D loss: 0.451608, acc: 57.03%, op_acc: 34.38%] [G loss: 0.807155]\n",
      "epoch:9 step:7148[D loss: 0.416397, acc: 64.84%, op_acc: 39.06%] [G loss: 0.911670]\n",
      "epoch:9 step:7149[D loss: 0.468208, acc: 53.12%, op_acc: 28.12%] [G loss: 0.867657]\n",
      "epoch:9 step:7150[D loss: 0.424357, acc: 61.72%, op_acc: 36.72%] [G loss: 0.842214]\n",
      "##############\n",
      "[0.85312693 0.84962775 0.81250297 0.80436998 0.78252471 0.82277015\n",
      " 0.88464774 0.83317683 0.81562426 0.81222676]\n",
      "##########\n",
      "epoch:9 step:7151[D loss: 0.451787, acc: 58.59%, op_acc: 32.81%] [G loss: 0.815856]\n",
      "epoch:9 step:7152[D loss: 0.470667, acc: 57.03%, op_acc: 32.81%] [G loss: 0.819198]\n",
      "epoch:9 step:7153[D loss: 0.459410, acc: 54.69%, op_acc: 34.38%] [G loss: 0.841828]\n",
      "epoch:9 step:7154[D loss: 0.494656, acc: 56.25%, op_acc: 26.56%] [G loss: 0.869492]\n",
      "epoch:9 step:7155[D loss: 0.427164, acc: 60.94%, op_acc: 36.72%] [G loss: 0.843440]\n",
      "epoch:9 step:7156[D loss: 0.458479, acc: 56.25%, op_acc: 31.25%] [G loss: 0.881615]\n",
      "epoch:9 step:7157[D loss: 0.440926, acc: 60.94%, op_acc: 33.59%] [G loss: 0.850854]\n",
      "epoch:9 step:7158[D loss: 0.463625, acc: 56.25%, op_acc: 30.47%] [G loss: 0.825971]\n",
      "epoch:9 step:7159[D loss: 0.467113, acc: 48.44%, op_acc: 35.16%] [G loss: 0.837431]\n",
      "epoch:9 step:7160[D loss: 0.421550, acc: 63.28%, op_acc: 32.81%] [G loss: 0.875225]\n",
      "epoch:9 step:7161[D loss: 0.425135, acc: 53.12%, op_acc: 37.50%] [G loss: 0.839802]\n",
      "epoch:9 step:7162[D loss: 0.473447, acc: 61.72%, op_acc: 27.34%] [G loss: 0.857247]\n",
      "epoch:9 step:7163[D loss: 0.428262, acc: 64.84%, op_acc: 33.59%] [G loss: 0.852049]\n",
      "epoch:9 step:7164[D loss: 0.477535, acc: 46.09%, op_acc: 31.25%] [G loss: 0.866992]\n",
      "epoch:9 step:7165[D loss: 0.425303, acc: 60.16%, op_acc: 35.16%] [G loss: 0.823714]\n",
      "epoch:9 step:7166[D loss: 0.428707, acc: 67.19%, op_acc: 32.81%] [G loss: 0.855449]\n",
      "epoch:9 step:7167[D loss: 0.448916, acc: 56.25%, op_acc: 36.72%] [G loss: 0.858008]\n",
      "epoch:9 step:7168[D loss: 0.424300, acc: 64.84%, op_acc: 35.16%] [G loss: 0.919829]\n",
      "epoch:9 step:7169[D loss: 0.482663, acc: 57.81%, op_acc: 28.12%] [G loss: 0.939134]\n",
      "epoch:9 step:7170[D loss: 0.463684, acc: 63.28%, op_acc: 32.03%] [G loss: 0.912142]\n",
      "epoch:9 step:7171[D loss: 0.414041, acc: 66.41%, op_acc: 37.50%] [G loss: 0.880021]\n",
      "epoch:9 step:7172[D loss: 0.421088, acc: 60.16%, op_acc: 38.28%] [G loss: 0.944024]\n",
      "epoch:9 step:7173[D loss: 0.421188, acc: 61.72%, op_acc: 37.50%] [G loss: 0.859506]\n",
      "epoch:9 step:7174[D loss: 0.441311, acc: 59.38%, op_acc: 39.06%] [G loss: 0.894065]\n",
      "epoch:9 step:7175[D loss: 0.437088, acc: 64.84%, op_acc: 33.59%] [G loss: 0.903719]\n",
      "epoch:9 step:7176[D loss: 0.438208, acc: 58.59%, op_acc: 40.62%] [G loss: 0.838914]\n",
      "epoch:9 step:7177[D loss: 0.439906, acc: 54.69%, op_acc: 34.38%] [G loss: 0.871708]\n",
      "epoch:9 step:7178[D loss: 0.408784, acc: 66.41%, op_acc: 37.50%] [G loss: 0.865492]\n",
      "epoch:9 step:7179[D loss: 0.430417, acc: 57.81%, op_acc: 35.94%] [G loss: 0.875134]\n",
      "epoch:9 step:7180[D loss: 0.448267, acc: 56.25%, op_acc: 32.81%] [G loss: 0.914332]\n",
      "epoch:9 step:7181[D loss: 0.461309, acc: 51.56%, op_acc: 39.06%] [G loss: 0.882717]\n",
      "epoch:9 step:7182[D loss: 0.440596, acc: 60.16%, op_acc: 36.72%] [G loss: 0.832272]\n",
      "epoch:9 step:7183[D loss: 0.476753, acc: 47.66%, op_acc: 36.72%] [G loss: 0.899666]\n",
      "epoch:9 step:7184[D loss: 0.426697, acc: 65.62%, op_acc: 30.47%] [G loss: 0.894894]\n",
      "epoch:9 step:7185[D loss: 0.413657, acc: 68.75%, op_acc: 32.81%] [G loss: 0.848647]\n",
      "epoch:9 step:7186[D loss: 0.417853, acc: 61.72%, op_acc: 35.16%] [G loss: 0.918606]\n",
      "epoch:9 step:7187[D loss: 0.387142, acc: 67.19%, op_acc: 38.28%] [G loss: 0.816461]\n",
      "epoch:9 step:7188[D loss: 0.441458, acc: 58.59%, op_acc: 35.94%] [G loss: 0.918039]\n",
      "epoch:9 step:7189[D loss: 0.468532, acc: 57.81%, op_acc: 31.25%] [G loss: 0.853753]\n",
      "epoch:9 step:7190[D loss: 0.449090, acc: 55.47%, op_acc: 32.03%] [G loss: 0.902316]\n",
      "epoch:9 step:7191[D loss: 0.429226, acc: 60.94%, op_acc: 39.84%] [G loss: 0.905187]\n",
      "epoch:9 step:7192[D loss: 0.456386, acc: 58.59%, op_acc: 32.03%] [G loss: 0.865674]\n",
      "epoch:9 step:7193[D loss: 0.471372, acc: 54.69%, op_acc: 32.81%] [G loss: 0.877773]\n",
      "epoch:9 step:7194[D loss: 0.416714, acc: 60.94%, op_acc: 42.97%] [G loss: 0.925803]\n",
      "epoch:9 step:7195[D loss: 0.428990, acc: 66.41%, op_acc: 31.25%] [G loss: 0.846382]\n",
      "epoch:9 step:7196[D loss: 0.421040, acc: 63.28%, op_acc: 39.84%] [G loss: 0.891669]\n",
      "epoch:9 step:7197[D loss: 0.430078, acc: 60.16%, op_acc: 35.94%] [G loss: 0.888540]\n",
      "epoch:9 step:7198[D loss: 0.433438, acc: 57.03%, op_acc: 41.41%] [G loss: 0.878600]\n",
      "epoch:9 step:7199[D loss: 0.439351, acc: 58.59%, op_acc: 35.16%] [G loss: 0.900388]\n",
      "epoch:9 step:7200[D loss: 0.444581, acc: 60.16%, op_acc: 30.47%] [G loss: 0.887836]\n",
      "##############\n",
      "[0.84984536 0.84414219 0.81934759 0.82511949 0.78956794 0.82881715\n",
      " 0.89403249 0.82854248 0.82964278 0.82247318]\n",
      "##########\n",
      "epoch:9 step:7201[D loss: 0.421193, acc: 65.62%, op_acc: 36.72%] [G loss: 0.959930]\n",
      "epoch:9 step:7202[D loss: 0.480000, acc: 52.34%, op_acc: 26.56%] [G loss: 0.765454]\n",
      "epoch:9 step:7203[D loss: 0.496745, acc: 51.56%, op_acc: 32.03%] [G loss: 0.853785]\n",
      "epoch:9 step:7204[D loss: 0.416529, acc: 63.28%, op_acc: 32.03%] [G loss: 0.864241]\n",
      "epoch:9 step:7205[D loss: 0.433124, acc: 63.28%, op_acc: 35.16%] [G loss: 0.856204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7206[D loss: 0.417231, acc: 63.28%, op_acc: 37.50%] [G loss: 0.889388]\n",
      "epoch:9 step:7207[D loss: 0.485459, acc: 48.44%, op_acc: 33.59%] [G loss: 0.834751]\n",
      "epoch:9 step:7208[D loss: 0.420935, acc: 63.28%, op_acc: 37.50%] [G loss: 0.938252]\n",
      "epoch:9 step:7209[D loss: 0.445300, acc: 56.25%, op_acc: 35.16%] [G loss: 0.874349]\n",
      "epoch:9 step:7210[D loss: 0.437901, acc: 54.69%, op_acc: 33.59%] [G loss: 0.896616]\n",
      "epoch:9 step:7211[D loss: 0.423210, acc: 63.28%, op_acc: 34.38%] [G loss: 0.895556]\n",
      "epoch:9 step:7212[D loss: 0.439402, acc: 59.38%, op_acc: 29.69%] [G loss: 0.885945]\n",
      "epoch:9 step:7213[D loss: 0.449697, acc: 59.38%, op_acc: 32.81%] [G loss: 0.835601]\n",
      "epoch:9 step:7214[D loss: 0.441529, acc: 64.06%, op_acc: 34.38%] [G loss: 0.871953]\n",
      "epoch:9 step:7215[D loss: 0.448465, acc: 59.38%, op_acc: 35.94%] [G loss: 0.896757]\n",
      "epoch:9 step:7216[D loss: 0.428842, acc: 56.25%, op_acc: 34.38%] [G loss: 0.872639]\n",
      "epoch:9 step:7217[D loss: 0.445956, acc: 53.91%, op_acc: 33.59%] [G loss: 0.907185]\n",
      "epoch:9 step:7218[D loss: 0.438670, acc: 60.16%, op_acc: 36.72%] [G loss: 0.886797]\n",
      "epoch:9 step:7219[D loss: 0.446775, acc: 60.16%, op_acc: 32.03%] [G loss: 0.911560]\n",
      "epoch:9 step:7220[D loss: 0.437521, acc: 58.59%, op_acc: 35.94%] [G loss: 0.904562]\n",
      "epoch:9 step:7221[D loss: 0.434040, acc: 61.72%, op_acc: 35.94%] [G loss: 0.839412]\n",
      "epoch:9 step:7222[D loss: 0.464803, acc: 59.38%, op_acc: 31.25%] [G loss: 0.836764]\n",
      "epoch:9 step:7223[D loss: 0.441593, acc: 58.59%, op_acc: 29.69%] [G loss: 0.929193]\n",
      "epoch:9 step:7224[D loss: 0.451736, acc: 58.59%, op_acc: 37.50%] [G loss: 0.872597]\n",
      "epoch:9 step:7225[D loss: 0.437729, acc: 57.81%, op_acc: 32.03%] [G loss: 0.816580]\n",
      "epoch:9 step:7226[D loss: 0.457676, acc: 54.69%, op_acc: 34.38%] [G loss: 0.942290]\n",
      "epoch:9 step:7227[D loss: 0.472846, acc: 52.34%, op_acc: 28.12%] [G loss: 0.883007]\n",
      "epoch:9 step:7228[D loss: 0.418941, acc: 69.53%, op_acc: 35.94%] [G loss: 0.893448]\n",
      "epoch:9 step:7229[D loss: 0.465044, acc: 54.69%, op_acc: 35.16%] [G loss: 0.847156]\n",
      "epoch:9 step:7230[D loss: 0.448290, acc: 51.56%, op_acc: 36.72%] [G loss: 0.897530]\n",
      "epoch:9 step:7231[D loss: 0.444017, acc: 57.81%, op_acc: 32.81%] [G loss: 0.909191]\n",
      "epoch:9 step:7232[D loss: 0.467756, acc: 57.81%, op_acc: 32.81%] [G loss: 0.858961]\n",
      "epoch:9 step:7233[D loss: 0.460663, acc: 57.81%, op_acc: 34.38%] [G loss: 0.922965]\n",
      "epoch:9 step:7234[D loss: 0.443729, acc: 62.50%, op_acc: 34.38%] [G loss: 0.886740]\n",
      "epoch:9 step:7235[D loss: 0.453874, acc: 54.69%, op_acc: 35.94%] [G loss: 0.783290]\n",
      "epoch:9 step:7236[D loss: 0.419557, acc: 59.38%, op_acc: 35.94%] [G loss: 0.866286]\n",
      "epoch:9 step:7237[D loss: 0.451976, acc: 62.50%, op_acc: 31.25%] [G loss: 0.865111]\n",
      "epoch:9 step:7238[D loss: 0.444352, acc: 55.47%, op_acc: 34.38%] [G loss: 0.948899]\n",
      "epoch:9 step:7239[D loss: 0.489880, acc: 51.56%, op_acc: 28.12%] [G loss: 0.800717]\n",
      "epoch:9 step:7240[D loss: 0.417269, acc: 64.06%, op_acc: 37.50%] [G loss: 0.860864]\n",
      "epoch:9 step:7241[D loss: 0.417635, acc: 71.88%, op_acc: 37.50%] [G loss: 0.845991]\n",
      "epoch:9 step:7242[D loss: 0.443530, acc: 59.38%, op_acc: 36.72%] [G loss: 0.843936]\n",
      "epoch:9 step:7243[D loss: 0.430976, acc: 64.06%, op_acc: 33.59%] [G loss: 0.958071]\n",
      "epoch:9 step:7244[D loss: 0.462993, acc: 59.38%, op_acc: 35.94%] [G loss: 0.856159]\n",
      "epoch:9 step:7245[D loss: 0.427147, acc: 60.94%, op_acc: 32.81%] [G loss: 0.874899]\n",
      "epoch:9 step:7246[D loss: 0.416528, acc: 66.41%, op_acc: 38.28%] [G loss: 0.815820]\n",
      "epoch:9 step:7247[D loss: 0.433492, acc: 60.94%, op_acc: 38.28%] [G loss: 0.879543]\n",
      "epoch:9 step:7248[D loss: 0.438791, acc: 57.03%, op_acc: 33.59%] [G loss: 0.886500]\n",
      "epoch:9 step:7249[D loss: 0.452629, acc: 54.69%, op_acc: 40.62%] [G loss: 0.890376]\n",
      "epoch:9 step:7250[D loss: 0.460506, acc: 54.69%, op_acc: 32.81%] [G loss: 0.865327]\n",
      "##############\n",
      "[0.86136681 0.86219118 0.83018257 0.8003991  0.79758004 0.82627136\n",
      " 0.86886148 0.80736144 0.83111386 0.83514646]\n",
      "##########\n",
      "epoch:9 step:7251[D loss: 0.443124, acc: 62.50%, op_acc: 32.03%] [G loss: 0.932643]\n",
      "epoch:9 step:7252[D loss: 0.447577, acc: 57.81%, op_acc: 36.72%] [G loss: 0.886289]\n",
      "epoch:9 step:7253[D loss: 0.436312, acc: 62.50%, op_acc: 29.69%] [G loss: 0.881345]\n",
      "epoch:9 step:7254[D loss: 0.464398, acc: 55.47%, op_acc: 32.03%] [G loss: 0.855698]\n",
      "epoch:9 step:7255[D loss: 0.434030, acc: 62.50%, op_acc: 32.81%] [G loss: 0.868016]\n",
      "epoch:9 step:7256[D loss: 0.419568, acc: 63.28%, op_acc: 34.38%] [G loss: 0.966004]\n",
      "epoch:9 step:7257[D loss: 0.422357, acc: 66.41%, op_acc: 38.28%] [G loss: 0.912426]\n",
      "epoch:9 step:7258[D loss: 0.444671, acc: 63.28%, op_acc: 32.03%] [G loss: 0.887179]\n",
      "epoch:9 step:7259[D loss: 0.468397, acc: 54.69%, op_acc: 32.81%] [G loss: 0.918014]\n",
      "epoch:9 step:7260[D loss: 0.433948, acc: 59.38%, op_acc: 39.84%] [G loss: 0.871586]\n",
      "epoch:9 step:7261[D loss: 0.451308, acc: 63.28%, op_acc: 35.16%] [G loss: 0.889428]\n",
      "epoch:9 step:7262[D loss: 0.414452, acc: 64.06%, op_acc: 36.72%] [G loss: 0.858953]\n",
      "epoch:9 step:7263[D loss: 0.460022, acc: 60.94%, op_acc: 28.91%] [G loss: 0.944255]\n",
      "epoch:9 step:7264[D loss: 0.427567, acc: 62.50%, op_acc: 39.06%] [G loss: 0.873115]\n",
      "epoch:9 step:7265[D loss: 0.445742, acc: 57.81%, op_acc: 41.41%] [G loss: 0.859779]\n",
      "epoch:9 step:7266[D loss: 0.447660, acc: 57.81%, op_acc: 31.25%] [G loss: 0.935593]\n",
      "epoch:9 step:7267[D loss: 0.453403, acc: 54.69%, op_acc: 35.16%] [G loss: 0.881539]\n",
      "epoch:9 step:7268[D loss: 0.442787, acc: 58.59%, op_acc: 35.94%] [G loss: 0.858490]\n",
      "epoch:9 step:7269[D loss: 0.444232, acc: 57.03%, op_acc: 37.50%] [G loss: 0.944205]\n",
      "epoch:9 step:7270[D loss: 0.428914, acc: 60.94%, op_acc: 35.16%] [G loss: 0.886705]\n",
      "epoch:9 step:7271[D loss: 0.456080, acc: 47.66%, op_acc: 35.94%] [G loss: 0.821706]\n",
      "epoch:9 step:7272[D loss: 0.435461, acc: 56.25%, op_acc: 35.94%] [G loss: 0.844371]\n",
      "epoch:9 step:7273[D loss: 0.457199, acc: 57.81%, op_acc: 33.59%] [G loss: 0.946970]\n",
      "epoch:9 step:7274[D loss: 0.460500, acc: 54.69%, op_acc: 35.16%] [G loss: 0.879324]\n",
      "epoch:9 step:7275[D loss: 0.448794, acc: 56.25%, op_acc: 33.59%] [G loss: 0.843101]\n",
      "epoch:9 step:7276[D loss: 0.432230, acc: 58.59%, op_acc: 32.81%] [G loss: 0.818816]\n",
      "epoch:9 step:7277[D loss: 0.479939, acc: 54.69%, op_acc: 32.03%] [G loss: 0.761919]\n",
      "epoch:9 step:7278[D loss: 0.475047, acc: 52.34%, op_acc: 32.03%] [G loss: 0.793786]\n",
      "epoch:9 step:7279[D loss: 0.447588, acc: 64.84%, op_acc: 25.00%] [G loss: 0.929557]\n",
      "epoch:9 step:7280[D loss: 0.442655, acc: 60.16%, op_acc: 35.16%] [G loss: 0.843817]\n",
      "epoch:9 step:7281[D loss: 0.407672, acc: 64.84%, op_acc: 39.06%] [G loss: 0.909476]\n",
      "epoch:9 step:7282[D loss: 0.459674, acc: 53.12%, op_acc: 32.81%] [G loss: 0.832862]\n",
      "epoch:9 step:7283[D loss: 0.466822, acc: 60.94%, op_acc: 27.34%] [G loss: 0.913518]\n",
      "epoch:9 step:7284[D loss: 0.435992, acc: 61.72%, op_acc: 35.16%] [G loss: 0.848121]\n",
      "epoch:9 step:7285[D loss: 0.434340, acc: 62.50%, op_acc: 35.94%] [G loss: 0.859461]\n",
      "epoch:9 step:7286[D loss: 0.450880, acc: 64.06%, op_acc: 31.25%] [G loss: 0.864944]\n",
      "epoch:9 step:7287[D loss: 0.427748, acc: 58.59%, op_acc: 36.72%] [G loss: 0.910616]\n",
      "epoch:9 step:7288[D loss: 0.449204, acc: 57.03%, op_acc: 35.16%] [G loss: 0.864505]\n",
      "epoch:9 step:7289[D loss: 0.466175, acc: 55.47%, op_acc: 29.69%] [G loss: 0.892646]\n",
      "epoch:9 step:7290[D loss: 0.432059, acc: 60.16%, op_acc: 39.84%] [G loss: 0.846926]\n",
      "epoch:9 step:7291[D loss: 0.414088, acc: 60.16%, op_acc: 35.94%] [G loss: 0.868103]\n",
      "epoch:9 step:7292[D loss: 0.452150, acc: 58.59%, op_acc: 33.59%] [G loss: 0.954864]\n",
      "epoch:9 step:7293[D loss: 0.438112, acc: 61.72%, op_acc: 32.81%] [G loss: 0.926535]\n",
      "epoch:9 step:7294[D loss: 0.412211, acc: 61.72%, op_acc: 39.06%] [G loss: 0.886794]\n",
      "epoch:9 step:7295[D loss: 0.429033, acc: 58.59%, op_acc: 45.31%] [G loss: 0.952852]\n",
      "epoch:9 step:7296[D loss: 0.447853, acc: 60.94%, op_acc: 34.38%] [G loss: 0.958180]\n",
      "epoch:9 step:7297[D loss: 0.431462, acc: 60.94%, op_acc: 35.94%] [G loss: 0.949534]\n",
      "epoch:9 step:7298[D loss: 0.429346, acc: 55.47%, op_acc: 36.72%] [G loss: 0.935891]\n",
      "epoch:9 step:7299[D loss: 0.444332, acc: 56.25%, op_acc: 35.94%] [G loss: 0.950352]\n",
      "epoch:9 step:7300[D loss: 0.443437, acc: 56.25%, op_acc: 39.06%] [G loss: 0.859770]\n",
      "##############\n",
      "[0.84421737 0.84695735 0.81399962 0.81204232 0.8057866  0.8325969\n",
      " 0.88718176 0.84197201 0.80649686 0.84582472]\n",
      "##########\n",
      "epoch:9 step:7301[D loss: 0.432997, acc: 64.84%, op_acc: 31.25%] [G loss: 0.849227]\n",
      "epoch:9 step:7302[D loss: 0.417413, acc: 61.72%, op_acc: 41.41%] [G loss: 0.808747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7303[D loss: 0.452623, acc: 57.03%, op_acc: 29.69%] [G loss: 0.930693]\n",
      "epoch:9 step:7304[D loss: 0.413335, acc: 62.50%, op_acc: 40.62%] [G loss: 0.904494]\n",
      "epoch:9 step:7305[D loss: 0.438859, acc: 57.81%, op_acc: 32.03%] [G loss: 0.884884]\n",
      "epoch:9 step:7306[D loss: 0.455670, acc: 60.16%, op_acc: 35.16%] [G loss: 0.903616]\n",
      "epoch:9 step:7307[D loss: 0.469632, acc: 53.91%, op_acc: 35.16%] [G loss: 0.762936]\n",
      "epoch:9 step:7308[D loss: 0.457969, acc: 52.34%, op_acc: 33.59%] [G loss: 0.914467]\n",
      "epoch:9 step:7309[D loss: 0.418427, acc: 57.03%, op_acc: 42.97%] [G loss: 0.855306]\n",
      "epoch:9 step:7310[D loss: 0.439449, acc: 64.84%, op_acc: 30.47%] [G loss: 0.812465]\n",
      "epoch:9 step:7311[D loss: 0.466830, acc: 50.78%, op_acc: 34.38%] [G loss: 0.862771]\n",
      "epoch:9 step:7312[D loss: 0.445288, acc: 54.69%, op_acc: 36.72%] [G loss: 0.885178]\n",
      "epoch:9 step:7313[D loss: 0.459958, acc: 52.34%, op_acc: 32.03%] [G loss: 0.847697]\n",
      "epoch:9 step:7314[D loss: 0.450574, acc: 54.69%, op_acc: 30.47%] [G loss: 0.833350]\n",
      "epoch:9 step:7315[D loss: 0.443390, acc: 64.06%, op_acc: 38.28%] [G loss: 0.821556]\n",
      "epoch:9 step:7316[D loss: 0.472595, acc: 48.44%, op_acc: 36.72%] [G loss: 0.835940]\n",
      "epoch:9 step:7317[D loss: 0.438204, acc: 58.59%, op_acc: 32.03%] [G loss: 0.891234]\n",
      "epoch:9 step:7318[D loss: 0.440764, acc: 64.84%, op_acc: 27.34%] [G loss: 0.914892]\n",
      "epoch:9 step:7319[D loss: 0.408909, acc: 73.44%, op_acc: 35.94%] [G loss: 0.929291]\n",
      "epoch:9 step:7320[D loss: 0.425603, acc: 59.38%, op_acc: 41.41%] [G loss: 0.855492]\n",
      "epoch:9 step:7321[D loss: 0.453366, acc: 56.25%, op_acc: 36.72%] [G loss: 0.887406]\n",
      "epoch:9 step:7322[D loss: 0.430806, acc: 57.81%, op_acc: 36.72%] [G loss: 0.866802]\n",
      "epoch:9 step:7323[D loss: 0.448133, acc: 59.38%, op_acc: 32.03%] [G loss: 0.837218]\n",
      "epoch:9 step:7324[D loss: 0.422236, acc: 60.16%, op_acc: 38.28%] [G loss: 0.864816]\n",
      "epoch:9 step:7325[D loss: 0.433272, acc: 57.81%, op_acc: 40.62%] [G loss: 0.881018]\n",
      "epoch:9 step:7326[D loss: 0.481905, acc: 49.22%, op_acc: 25.00%] [G loss: 0.828097]\n",
      "epoch:9 step:7327[D loss: 0.438336, acc: 65.62%, op_acc: 32.03%] [G loss: 0.877528]\n",
      "epoch:9 step:7328[D loss: 0.438712, acc: 60.94%, op_acc: 35.94%] [G loss: 0.854846]\n",
      "epoch:9 step:7329[D loss: 0.499176, acc: 47.66%, op_acc: 27.34%] [G loss: 0.762583]\n",
      "epoch:9 step:7330[D loss: 0.436817, acc: 54.69%, op_acc: 35.94%] [G loss: 0.798186]\n",
      "epoch:9 step:7331[D loss: 0.418614, acc: 64.06%, op_acc: 34.38%] [G loss: 0.844497]\n",
      "epoch:9 step:7332[D loss: 0.439745, acc: 63.28%, op_acc: 32.03%] [G loss: 0.854173]\n",
      "epoch:9 step:7333[D loss: 0.421543, acc: 64.06%, op_acc: 35.16%] [G loss: 0.853361]\n",
      "epoch:9 step:7334[D loss: 0.425051, acc: 57.03%, op_acc: 37.50%] [G loss: 0.881717]\n",
      "epoch:9 step:7335[D loss: 0.475640, acc: 60.94%, op_acc: 29.69%] [G loss: 0.885293]\n",
      "epoch:9 step:7336[D loss: 0.431184, acc: 53.91%, op_acc: 37.50%] [G loss: 0.903422]\n",
      "epoch:9 step:7337[D loss: 0.448388, acc: 60.94%, op_acc: 31.25%] [G loss: 0.873364]\n",
      "epoch:9 step:7338[D loss: 0.497381, acc: 50.78%, op_acc: 29.69%] [G loss: 0.843506]\n",
      "epoch:9 step:7339[D loss: 0.437510, acc: 58.59%, op_acc: 30.47%] [G loss: 0.842618]\n",
      "epoch:9 step:7340[D loss: 0.422880, acc: 67.19%, op_acc: 34.38%] [G loss: 0.861288]\n",
      "epoch:9 step:7341[D loss: 0.447884, acc: 57.03%, op_acc: 38.28%] [G loss: 0.806895]\n",
      "epoch:9 step:7342[D loss: 0.439925, acc: 63.28%, op_acc: 37.50%] [G loss: 0.862385]\n",
      "epoch:9 step:7343[D loss: 0.447048, acc: 57.81%, op_acc: 35.94%] [G loss: 0.939085]\n",
      "epoch:9 step:7344[D loss: 0.471442, acc: 47.66%, op_acc: 33.59%] [G loss: 0.857876]\n",
      "epoch:9 step:7345[D loss: 0.447038, acc: 58.59%, op_acc: 32.81%] [G loss: 0.818150]\n",
      "epoch:9 step:7346[D loss: 0.421299, acc: 70.31%, op_acc: 36.72%] [G loss: 0.843031]\n",
      "epoch:9 step:7347[D loss: 0.448985, acc: 60.16%, op_acc: 28.91%] [G loss: 0.919108]\n",
      "epoch:9 step:7348[D loss: 0.452372, acc: 53.12%, op_acc: 39.06%] [G loss: 0.855578]\n",
      "epoch:9 step:7349[D loss: 0.452996, acc: 60.94%, op_acc: 33.59%] [G loss: 0.863943]\n",
      "epoch:9 step:7350[D loss: 0.437590, acc: 60.16%, op_acc: 33.59%] [G loss: 0.887337]\n",
      "##############\n",
      "[0.86100449 0.84917506 0.8309763  0.79647046 0.78388427 0.83086653\n",
      " 0.88437513 0.83017988 0.8275227  0.82542571]\n",
      "##########\n",
      "epoch:9 step:7351[D loss: 0.459787, acc: 57.03%, op_acc: 32.03%] [G loss: 0.924389]\n",
      "epoch:9 step:7352[D loss: 0.434323, acc: 59.38%, op_acc: 36.72%] [G loss: 0.839849]\n",
      "epoch:9 step:7353[D loss: 0.453935, acc: 53.91%, op_acc: 32.81%] [G loss: 0.893119]\n",
      "epoch:9 step:7354[D loss: 0.418484, acc: 65.62%, op_acc: 39.84%] [G loss: 0.883006]\n",
      "epoch:9 step:7355[D loss: 0.423168, acc: 64.84%, op_acc: 35.16%] [G loss: 0.910065]\n",
      "epoch:9 step:7356[D loss: 0.437570, acc: 60.16%, op_acc: 32.03%] [G loss: 0.909124]\n",
      "epoch:9 step:7357[D loss: 0.426877, acc: 61.72%, op_acc: 35.16%] [G loss: 0.880575]\n",
      "epoch:9 step:7358[D loss: 0.450820, acc: 59.38%, op_acc: 35.16%] [G loss: 0.822923]\n",
      "epoch:9 step:7359[D loss: 0.446353, acc: 55.47%, op_acc: 36.72%] [G loss: 0.902406]\n",
      "epoch:9 step:7360[D loss: 0.441044, acc: 58.59%, op_acc: 36.72%] [G loss: 0.918349]\n",
      "epoch:9 step:7361[D loss: 0.463415, acc: 53.12%, op_acc: 33.59%] [G loss: 0.820853]\n",
      "epoch:9 step:7362[D loss: 0.442687, acc: 58.59%, op_acc: 35.16%] [G loss: 0.842154]\n",
      "epoch:9 step:7363[D loss: 0.449300, acc: 57.03%, op_acc: 36.72%] [G loss: 0.882438]\n",
      "epoch:9 step:7364[D loss: 0.463624, acc: 59.38%, op_acc: 33.59%] [G loss: 0.894508]\n",
      "epoch:9 step:7365[D loss: 0.448349, acc: 57.81%, op_acc: 36.72%] [G loss: 0.891635]\n",
      "epoch:9 step:7366[D loss: 0.462485, acc: 57.03%, op_acc: 32.81%] [G loss: 0.898637]\n",
      "epoch:9 step:7367[D loss: 0.424426, acc: 57.03%, op_acc: 37.50%] [G loss: 0.829349]\n",
      "epoch:9 step:7368[D loss: 0.454856, acc: 56.25%, op_acc: 35.16%] [G loss: 0.809307]\n",
      "epoch:9 step:7369[D loss: 0.447070, acc: 53.12%, op_acc: 34.38%] [G loss: 0.835464]\n",
      "epoch:9 step:7370[D loss: 0.482345, acc: 52.34%, op_acc: 32.81%] [G loss: 0.835550]\n",
      "epoch:9 step:7371[D loss: 0.468276, acc: 49.22%, op_acc: 30.47%] [G loss: 0.899029]\n",
      "epoch:9 step:7372[D loss: 0.462307, acc: 52.34%, op_acc: 38.28%] [G loss: 0.812061]\n",
      "epoch:9 step:7373[D loss: 0.473334, acc: 50.78%, op_acc: 33.59%] [G loss: 0.881295]\n",
      "epoch:9 step:7374[D loss: 0.470576, acc: 53.91%, op_acc: 31.25%] [G loss: 0.855054]\n",
      "epoch:9 step:7375[D loss: 0.452433, acc: 57.03%, op_acc: 30.47%] [G loss: 0.882640]\n",
      "epoch:9 step:7376[D loss: 0.447775, acc: 53.91%, op_acc: 31.25%] [G loss: 0.962629]\n",
      "epoch:9 step:7377[D loss: 0.425649, acc: 63.28%, op_acc: 32.03%] [G loss: 0.941693]\n",
      "epoch:9 step:7378[D loss: 0.425337, acc: 64.06%, op_acc: 35.94%] [G loss: 0.876092]\n",
      "epoch:9 step:7379[D loss: 0.446055, acc: 58.59%, op_acc: 31.25%] [G loss: 0.947088]\n",
      "epoch:9 step:7380[D loss: 0.420032, acc: 69.53%, op_acc: 31.25%] [G loss: 0.899336]\n",
      "epoch:9 step:7381[D loss: 0.422905, acc: 67.19%, op_acc: 36.72%] [G loss: 0.921715]\n",
      "epoch:9 step:7382[D loss: 0.409553, acc: 63.28%, op_acc: 46.09%] [G loss: 0.874560]\n",
      "epoch:9 step:7383[D loss: 0.452160, acc: 57.03%, op_acc: 31.25%] [G loss: 0.914452]\n",
      "epoch:9 step:7384[D loss: 0.471544, acc: 50.00%, op_acc: 34.38%] [G loss: 0.810930]\n",
      "epoch:9 step:7385[D loss: 0.430689, acc: 55.47%, op_acc: 34.38%] [G loss: 0.866887]\n",
      "epoch:9 step:7386[D loss: 0.449881, acc: 60.94%, op_acc: 36.72%] [G loss: 0.863199]\n",
      "epoch:9 step:7387[D loss: 0.452700, acc: 55.47%, op_acc: 38.28%] [G loss: 0.882538]\n",
      "epoch:9 step:7388[D loss: 0.429370, acc: 61.72%, op_acc: 34.38%] [G loss: 0.805220]\n",
      "epoch:9 step:7389[D loss: 0.430960, acc: 67.97%, op_acc: 33.59%] [G loss: 0.845167]\n",
      "epoch:9 step:7390[D loss: 0.427110, acc: 61.72%, op_acc: 35.16%] [G loss: 0.807979]\n",
      "epoch:9 step:7391[D loss: 0.417060, acc: 57.03%, op_acc: 40.62%] [G loss: 0.833782]\n",
      "epoch:9 step:7392[D loss: 0.461472, acc: 57.03%, op_acc: 33.59%] [G loss: 0.874201]\n",
      "epoch:9 step:7393[D loss: 0.470755, acc: 53.12%, op_acc: 30.47%] [G loss: 0.861903]\n",
      "epoch:9 step:7394[D loss: 0.419514, acc: 60.16%, op_acc: 37.50%] [G loss: 0.838971]\n",
      "epoch:9 step:7395[D loss: 0.457408, acc: 43.75%, op_acc: 36.72%] [G loss: 0.813194]\n",
      "epoch:9 step:7396[D loss: 0.483451, acc: 50.78%, op_acc: 31.25%] [G loss: 0.884891]\n",
      "epoch:9 step:7397[D loss: 0.445704, acc: 63.28%, op_acc: 28.12%] [G loss: 0.973835]\n",
      "epoch:9 step:7398[D loss: 0.426186, acc: 64.06%, op_acc: 31.25%] [G loss: 0.920299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7399[D loss: 0.462123, acc: 56.25%, op_acc: 32.81%] [G loss: 0.889847]\n",
      "epoch:9 step:7400[D loss: 0.388502, acc: 64.06%, op_acc: 41.41%] [G loss: 0.920324]\n",
      "##############\n",
      "[0.84739917 0.86102889 0.82669646 0.81486908 0.78870019 0.80981803\n",
      " 0.89448831 0.84719633 0.79907608 0.84404683]\n",
      "##########\n",
      "epoch:9 step:7401[D loss: 0.448674, acc: 53.12%, op_acc: 36.72%] [G loss: 0.845785]\n",
      "epoch:9 step:7402[D loss: 0.407270, acc: 71.88%, op_acc: 38.28%] [G loss: 1.012274]\n",
      "epoch:9 step:7403[D loss: 0.449949, acc: 57.81%, op_acc: 35.16%] [G loss: 0.842166]\n",
      "epoch:9 step:7404[D loss: 0.445936, acc: 54.69%, op_acc: 35.94%] [G loss: 0.879276]\n",
      "epoch:9 step:7405[D loss: 0.423513, acc: 64.06%, op_acc: 36.72%] [G loss: 0.853375]\n",
      "epoch:9 step:7406[D loss: 0.462877, acc: 60.94%, op_acc: 31.25%] [G loss: 0.906605]\n",
      "epoch:9 step:7407[D loss: 0.445919, acc: 58.59%, op_acc: 34.38%] [G loss: 0.877300]\n",
      "epoch:9 step:7408[D loss: 0.409884, acc: 61.72%, op_acc: 39.84%] [G loss: 0.925873]\n",
      "epoch:9 step:7409[D loss: 0.430058, acc: 61.72%, op_acc: 41.41%] [G loss: 0.878413]\n",
      "epoch:9 step:7410[D loss: 0.422083, acc: 66.41%, op_acc: 35.16%] [G loss: 0.932590]\n",
      "epoch:9 step:7411[D loss: 0.421880, acc: 61.72%, op_acc: 38.28%] [G loss: 0.877117]\n",
      "epoch:9 step:7412[D loss: 0.431754, acc: 57.03%, op_acc: 39.84%] [G loss: 0.858173]\n",
      "epoch:9 step:7413[D loss: 0.434022, acc: 62.50%, op_acc: 39.06%] [G loss: 0.910197]\n",
      "epoch:9 step:7414[D loss: 0.436876, acc: 58.59%, op_acc: 37.50%] [G loss: 0.880847]\n",
      "epoch:9 step:7415[D loss: 0.436689, acc: 59.38%, op_acc: 35.94%] [G loss: 0.829895]\n",
      "epoch:9 step:7416[D loss: 0.446924, acc: 59.38%, op_acc: 37.50%] [G loss: 0.832855]\n",
      "epoch:9 step:7417[D loss: 0.457724, acc: 55.47%, op_acc: 31.25%] [G loss: 0.864444]\n",
      "epoch:9 step:7418[D loss: 0.462940, acc: 60.16%, op_acc: 32.81%] [G loss: 0.891867]\n",
      "epoch:9 step:7419[D loss: 0.429558, acc: 60.16%, op_acc: 39.06%] [G loss: 0.803992]\n",
      "epoch:9 step:7420[D loss: 0.416150, acc: 62.50%, op_acc: 39.06%] [G loss: 0.846978]\n",
      "epoch:9 step:7421[D loss: 0.412465, acc: 57.81%, op_acc: 37.50%] [G loss: 0.948885]\n",
      "epoch:9 step:7422[D loss: 0.463263, acc: 59.38%, op_acc: 32.03%] [G loss: 0.907191]\n",
      "epoch:9 step:7423[D loss: 0.472403, acc: 56.25%, op_acc: 31.25%] [G loss: 0.824297]\n",
      "epoch:9 step:7424[D loss: 0.452469, acc: 59.38%, op_acc: 25.00%] [G loss: 0.886462]\n",
      "epoch:9 step:7425[D loss: 0.422607, acc: 54.69%, op_acc: 39.84%] [G loss: 0.877195]\n",
      "epoch:9 step:7426[D loss: 0.424266, acc: 61.72%, op_acc: 35.16%] [G loss: 0.914822]\n",
      "epoch:9 step:7427[D loss: 0.462505, acc: 52.34%, op_acc: 30.47%] [G loss: 0.807368]\n",
      "epoch:9 step:7428[D loss: 0.444219, acc: 57.81%, op_acc: 32.03%] [G loss: 0.810661]\n",
      "epoch:9 step:7429[D loss: 0.451251, acc: 55.47%, op_acc: 36.72%] [G loss: 0.851803]\n",
      "epoch:9 step:7430[D loss: 0.425498, acc: 65.62%, op_acc: 32.81%] [G loss: 0.927789]\n",
      "epoch:9 step:7431[D loss: 0.444301, acc: 64.06%, op_acc: 31.25%] [G loss: 0.878227]\n",
      "epoch:9 step:7432[D loss: 0.437018, acc: 60.94%, op_acc: 35.16%] [G loss: 0.905371]\n",
      "epoch:9 step:7433[D loss: 0.393224, acc: 72.66%, op_acc: 42.19%] [G loss: 0.891827]\n",
      "epoch:9 step:7434[D loss: 0.495409, acc: 53.12%, op_acc: 27.34%] [G loss: 0.861400]\n",
      "epoch:9 step:7435[D loss: 0.442167, acc: 55.47%, op_acc: 35.94%] [G loss: 0.958536]\n",
      "epoch:9 step:7436[D loss: 0.463954, acc: 55.47%, op_acc: 35.16%] [G loss: 0.892659]\n",
      "epoch:9 step:7437[D loss: 0.428079, acc: 55.47%, op_acc: 41.41%] [G loss: 0.843666]\n",
      "epoch:9 step:7438[D loss: 0.445751, acc: 54.69%, op_acc: 35.94%] [G loss: 0.985876]\n",
      "epoch:9 step:7439[D loss: 0.429081, acc: 59.38%, op_acc: 34.38%] [G loss: 0.860663]\n",
      "epoch:9 step:7440[D loss: 0.468068, acc: 55.47%, op_acc: 31.25%] [G loss: 0.979725]\n",
      "epoch:9 step:7441[D loss: 0.427872, acc: 60.16%, op_acc: 37.50%] [G loss: 0.827506]\n",
      "epoch:9 step:7442[D loss: 0.439028, acc: 56.25%, op_acc: 38.28%] [G loss: 1.000271]\n",
      "epoch:9 step:7443[D loss: 0.429484, acc: 57.81%, op_acc: 35.16%] [G loss: 0.930511]\n",
      "epoch:9 step:7444[D loss: 0.451001, acc: 57.81%, op_acc: 35.94%] [G loss: 0.855746]\n",
      "epoch:9 step:7445[D loss: 0.423578, acc: 66.41%, op_acc: 36.72%] [G loss: 0.875576]\n",
      "epoch:9 step:7446[D loss: 0.455424, acc: 60.16%, op_acc: 32.03%] [G loss: 0.918002]\n",
      "epoch:9 step:7447[D loss: 0.437246, acc: 60.94%, op_acc: 34.38%] [G loss: 0.765489]\n",
      "epoch:9 step:7448[D loss: 0.432101, acc: 60.94%, op_acc: 36.72%] [G loss: 0.884481]\n",
      "epoch:9 step:7449[D loss: 0.471038, acc: 57.81%, op_acc: 31.25%] [G loss: 0.918587]\n",
      "epoch:9 step:7450[D loss: 0.437958, acc: 60.16%, op_acc: 35.94%] [G loss: 0.894069]\n",
      "##############\n",
      "[0.86610231 0.84206288 0.81501307 0.81854146 0.80029066 0.83803714\n",
      " 0.87070398 0.83840968 0.82506114 0.83063995]\n",
      "##########\n",
      "epoch:9 step:7451[D loss: 0.428810, acc: 59.38%, op_acc: 39.84%] [G loss: 0.996433]\n",
      "epoch:9 step:7452[D loss: 0.450914, acc: 62.50%, op_acc: 33.59%] [G loss: 0.951834]\n",
      "epoch:9 step:7453[D loss: 0.414364, acc: 70.31%, op_acc: 38.28%] [G loss: 0.879558]\n",
      "epoch:9 step:7454[D loss: 0.438654, acc: 58.59%, op_acc: 33.59%] [G loss: 0.847339]\n",
      "epoch:9 step:7455[D loss: 0.462015, acc: 57.03%, op_acc: 35.94%] [G loss: 0.849816]\n",
      "epoch:9 step:7456[D loss: 0.461939, acc: 55.47%, op_acc: 34.38%] [G loss: 0.837617]\n",
      "epoch:9 step:7457[D loss: 0.431411, acc: 59.38%, op_acc: 38.28%] [G loss: 0.780227]\n",
      "epoch:9 step:7458[D loss: 0.455091, acc: 53.12%, op_acc: 32.81%] [G loss: 0.824202]\n",
      "epoch:9 step:7459[D loss: 0.445663, acc: 58.59%, op_acc: 34.38%] [G loss: 0.904907]\n",
      "epoch:9 step:7460[D loss: 0.446814, acc: 56.25%, op_acc: 35.16%] [G loss: 0.941121]\n",
      "epoch:9 step:7461[D loss: 0.411996, acc: 65.62%, op_acc: 41.41%] [G loss: 0.863782]\n",
      "epoch:9 step:7462[D loss: 0.421466, acc: 67.19%, op_acc: 35.16%] [G loss: 0.823310]\n",
      "epoch:9 step:7463[D loss: 0.428967, acc: 60.94%, op_acc: 34.38%] [G loss: 0.855604]\n",
      "epoch:9 step:7464[D loss: 0.422347, acc: 57.81%, op_acc: 42.19%] [G loss: 0.949497]\n",
      "epoch:9 step:7465[D loss: 0.458461, acc: 53.91%, op_acc: 38.28%] [G loss: 0.836641]\n",
      "epoch:9 step:7466[D loss: 0.470742, acc: 49.22%, op_acc: 36.72%] [G loss: 0.835387]\n",
      "epoch:9 step:7467[D loss: 0.448217, acc: 59.38%, op_acc: 34.38%] [G loss: 0.897643]\n",
      "epoch:9 step:7468[D loss: 0.438771, acc: 61.72%, op_acc: 34.38%] [G loss: 0.874323]\n",
      "epoch:9 step:7469[D loss: 0.430536, acc: 54.69%, op_acc: 35.16%] [G loss: 0.912588]\n",
      "epoch:9 step:7470[D loss: 0.451692, acc: 60.94%, op_acc: 31.25%] [G loss: 0.821318]\n",
      "epoch:9 step:7471[D loss: 0.417343, acc: 67.97%, op_acc: 35.94%] [G loss: 0.882267]\n",
      "epoch:9 step:7472[D loss: 0.466323, acc: 60.94%, op_acc: 33.59%] [G loss: 0.891925]\n",
      "epoch:9 step:7473[D loss: 0.449213, acc: 51.56%, op_acc: 39.06%] [G loss: 0.883574]\n",
      "epoch:9 step:7474[D loss: 0.474765, acc: 54.69%, op_acc: 33.59%] [G loss: 0.803740]\n",
      "epoch:9 step:7475[D loss: 0.447822, acc: 55.47%, op_acc: 37.50%] [G loss: 0.881180]\n",
      "epoch:9 step:7476[D loss: 0.423099, acc: 67.97%, op_acc: 28.91%] [G loss: 0.893977]\n",
      "epoch:9 step:7477[D loss: 0.467048, acc: 53.91%, op_acc: 32.81%] [G loss: 0.824748]\n",
      "epoch:9 step:7478[D loss: 0.455595, acc: 51.56%, op_acc: 32.03%] [G loss: 0.840008]\n",
      "epoch:9 step:7479[D loss: 0.444342, acc: 59.38%, op_acc: 30.47%] [G loss: 0.851068]\n",
      "epoch:9 step:7480[D loss: 0.446029, acc: 60.94%, op_acc: 41.41%] [G loss: 0.836797]\n",
      "epoch:9 step:7481[D loss: 0.426954, acc: 56.25%, op_acc: 37.50%] [G loss: 0.916931]\n",
      "epoch:9 step:7482[D loss: 0.410957, acc: 56.25%, op_acc: 41.41%] [G loss: 0.867211]\n",
      "epoch:9 step:7483[D loss: 0.417475, acc: 58.59%, op_acc: 36.72%] [G loss: 0.862124]\n",
      "epoch:9 step:7484[D loss: 0.449169, acc: 53.12%, op_acc: 35.16%] [G loss: 0.857800]\n",
      "epoch:9 step:7485[D loss: 0.429041, acc: 60.94%, op_acc: 38.28%] [G loss: 0.865790]\n",
      "epoch:9 step:7486[D loss: 0.430052, acc: 60.94%, op_acc: 33.59%] [G loss: 0.859097]\n",
      "epoch:9 step:7487[D loss: 0.435418, acc: 59.38%, op_acc: 36.72%] [G loss: 0.909914]\n",
      "epoch:9 step:7488[D loss: 0.427802, acc: 58.59%, op_acc: 42.97%] [G loss: 0.910586]\n",
      "epoch:9 step:7489[D loss: 0.457075, acc: 50.78%, op_acc: 32.81%] [G loss: 0.875782]\n",
      "epoch:9 step:7490[D loss: 0.457349, acc: 60.16%, op_acc: 32.81%] [G loss: 0.908488]\n",
      "epoch:9 step:7491[D loss: 0.437927, acc: 58.59%, op_acc: 32.81%] [G loss: 0.861893]\n",
      "epoch:9 step:7492[D loss: 0.443962, acc: 49.22%, op_acc: 35.94%] [G loss: 0.924355]\n",
      "epoch:9 step:7493[D loss: 0.437289, acc: 61.72%, op_acc: 30.47%] [G loss: 0.879984]\n",
      "epoch:9 step:7494[D loss: 0.432305, acc: 60.94%, op_acc: 35.16%] [G loss: 0.878773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7495[D loss: 0.454981, acc: 57.81%, op_acc: 37.50%] [G loss: 0.898987]\n",
      "epoch:9 step:7496[D loss: 0.442167, acc: 57.81%, op_acc: 32.03%] [G loss: 0.911287]\n",
      "epoch:9 step:7497[D loss: 0.434999, acc: 59.38%, op_acc: 35.94%] [G loss: 0.838266]\n",
      "epoch:9 step:7498[D loss: 0.409079, acc: 64.06%, op_acc: 38.28%] [G loss: 0.929163]\n",
      "epoch:9 step:7499[D loss: 0.418211, acc: 67.97%, op_acc: 31.25%] [G loss: 0.925154]\n",
      "epoch:9 step:7500[D loss: 0.465662, acc: 55.47%, op_acc: 35.16%] [G loss: 0.956525]\n",
      "##############\n",
      "[0.85198981 0.85777553 0.78888099 0.79955647 0.79688772 0.82060526\n",
      " 0.88265023 0.82978156 0.80156728 0.86519963]\n",
      "##########\n",
      "epoch:9 step:7501[D loss: 0.451790, acc: 58.59%, op_acc: 35.16%] [G loss: 0.822267]\n",
      "epoch:9 step:7502[D loss: 0.430843, acc: 55.47%, op_acc: 37.50%] [G loss: 0.938841]\n",
      "epoch:9 step:7503[D loss: 0.424523, acc: 62.50%, op_acc: 37.50%] [G loss: 0.849726]\n",
      "epoch:9 step:7504[D loss: 0.414674, acc: 58.59%, op_acc: 42.19%] [G loss: 0.848096]\n",
      "epoch:9 step:7505[D loss: 0.448797, acc: 61.72%, op_acc: 32.03%] [G loss: 0.884297]\n",
      "epoch:9 step:7506[D loss: 0.411192, acc: 66.41%, op_acc: 33.59%] [G loss: 0.886592]\n",
      "epoch:9 step:7507[D loss: 0.429068, acc: 61.72%, op_acc: 35.94%] [G loss: 0.836983]\n",
      "epoch:9 step:7508[D loss: 0.452586, acc: 57.03%, op_acc: 32.81%] [G loss: 0.872092]\n",
      "epoch:9 step:7509[D loss: 0.481247, acc: 54.69%, op_acc: 29.69%] [G loss: 0.922265]\n",
      "epoch:9 step:7510[D loss: 0.442566, acc: 66.41%, op_acc: 32.81%] [G loss: 0.858644]\n",
      "epoch:9 step:7511[D loss: 0.447359, acc: 61.72%, op_acc: 34.38%] [G loss: 0.887426]\n",
      "epoch:9 step:7512[D loss: 0.450784, acc: 57.03%, op_acc: 35.94%] [G loss: 0.877656]\n",
      "epoch:9 step:7513[D loss: 0.421518, acc: 68.75%, op_acc: 43.75%] [G loss: 0.882335]\n",
      "epoch:9 step:7514[D loss: 0.464324, acc: 53.91%, op_acc: 28.91%] [G loss: 0.851268]\n",
      "epoch:9 step:7515[D loss: 0.420687, acc: 61.72%, op_acc: 40.62%] [G loss: 0.897356]\n",
      "epoch:9 step:7516[D loss: 0.419027, acc: 64.06%, op_acc: 38.28%] [G loss: 0.931015]\n",
      "epoch:9 step:7517[D loss: 0.459411, acc: 53.91%, op_acc: 29.69%] [G loss: 0.965082]\n",
      "epoch:9 step:7518[D loss: 0.442771, acc: 53.91%, op_acc: 34.38%] [G loss: 0.830172]\n",
      "epoch:9 step:7519[D loss: 0.423296, acc: 66.41%, op_acc: 37.50%] [G loss: 0.865107]\n",
      "epoch:9 step:7520[D loss: 0.460944, acc: 53.91%, op_acc: 32.81%] [G loss: 0.846174]\n",
      "epoch:9 step:7521[D loss: 0.449180, acc: 62.50%, op_acc: 31.25%] [G loss: 0.836851]\n",
      "epoch:9 step:7522[D loss: 0.442061, acc: 61.72%, op_acc: 34.38%] [G loss: 0.811466]\n",
      "epoch:9 step:7523[D loss: 0.430580, acc: 63.28%, op_acc: 32.81%] [G loss: 0.902568]\n",
      "epoch:9 step:7524[D loss: 0.433639, acc: 64.06%, op_acc: 33.59%] [G loss: 0.954895]\n",
      "epoch:9 step:7525[D loss: 0.442203, acc: 60.16%, op_acc: 28.91%] [G loss: 0.772778]\n",
      "epoch:9 step:7526[D loss: 0.413705, acc: 58.59%, op_acc: 38.28%] [G loss: 0.898062]\n",
      "epoch:9 step:7527[D loss: 0.461612, acc: 53.91%, op_acc: 30.47%] [G loss: 0.868642]\n",
      "epoch:9 step:7528[D loss: 0.440014, acc: 67.19%, op_acc: 30.47%] [G loss: 0.891847]\n",
      "epoch:9 step:7529[D loss: 0.438354, acc: 60.16%, op_acc: 38.28%] [G loss: 0.875858]\n",
      "epoch:9 step:7530[D loss: 0.467230, acc: 58.59%, op_acc: 26.56%] [G loss: 0.860578]\n",
      "epoch:9 step:7531[D loss: 0.444802, acc: 59.38%, op_acc: 41.41%] [G loss: 0.925042]\n",
      "epoch:9 step:7532[D loss: 0.450316, acc: 56.25%, op_acc: 32.03%] [G loss: 0.865973]\n",
      "epoch:9 step:7533[D loss: 0.444238, acc: 61.72%, op_acc: 42.19%] [G loss: 0.908580]\n",
      "epoch:9 step:7534[D loss: 0.459669, acc: 54.69%, op_acc: 34.38%] [G loss: 0.871435]\n",
      "epoch:9 step:7535[D loss: 0.421928, acc: 65.62%, op_acc: 34.38%] [G loss: 0.927369]\n",
      "epoch:9 step:7536[D loss: 0.409588, acc: 63.28%, op_acc: 35.16%] [G loss: 0.838030]\n",
      "epoch:9 step:7537[D loss: 0.421291, acc: 66.41%, op_acc: 39.84%] [G loss: 0.896111]\n",
      "epoch:9 step:7538[D loss: 0.491425, acc: 49.22%, op_acc: 30.47%] [G loss: 0.833925]\n",
      "epoch:9 step:7539[D loss: 0.416543, acc: 69.53%, op_acc: 36.72%] [G loss: 0.917128]\n",
      "epoch:9 step:7540[D loss: 0.454055, acc: 57.03%, op_acc: 35.16%] [G loss: 0.896057]\n",
      "epoch:9 step:7541[D loss: 0.486507, acc: 48.44%, op_acc: 28.91%] [G loss: 0.873276]\n",
      "epoch:9 step:7542[D loss: 0.458287, acc: 51.56%, op_acc: 31.25%] [G loss: 0.889905]\n",
      "epoch:9 step:7543[D loss: 0.451705, acc: 57.03%, op_acc: 37.50%] [G loss: 0.896522]\n",
      "epoch:9 step:7544[D loss: 0.459627, acc: 59.38%, op_acc: 29.69%] [G loss: 0.893733]\n",
      "epoch:9 step:7545[D loss: 0.431901, acc: 68.75%, op_acc: 36.72%] [G loss: 0.914326]\n",
      "epoch:9 step:7546[D loss: 0.451087, acc: 50.78%, op_acc: 35.16%] [G loss: 0.842708]\n",
      "epoch:9 step:7547[D loss: 0.449261, acc: 57.81%, op_acc: 32.03%] [G loss: 0.843260]\n",
      "epoch:9 step:7548[D loss: 0.430081, acc: 53.91%, op_acc: 39.06%] [G loss: 0.895230]\n",
      "epoch:9 step:7549[D loss: 0.438388, acc: 60.16%, op_acc: 35.94%] [G loss: 0.885563]\n",
      "epoch:9 step:7550[D loss: 0.457149, acc: 58.59%, op_acc: 32.03%] [G loss: 0.913116]\n",
      "##############\n",
      "[0.86302666 0.86385523 0.80941331 0.79969389 0.76673557 0.82774545\n",
      " 0.88010492 0.85869468 0.83678882 0.82763895]\n",
      "##########\n",
      "epoch:9 step:7551[D loss: 0.479496, acc: 49.22%, op_acc: 36.72%] [G loss: 0.793106]\n",
      "epoch:9 step:7552[D loss: 0.460463, acc: 55.47%, op_acc: 34.38%] [G loss: 0.884595]\n",
      "epoch:9 step:7553[D loss: 0.479864, acc: 47.66%, op_acc: 28.12%] [G loss: 0.904057]\n",
      "epoch:9 step:7554[D loss: 0.419874, acc: 67.97%, op_acc: 28.12%] [G loss: 0.950158]\n",
      "epoch:9 step:7555[D loss: 0.484581, acc: 54.69%, op_acc: 25.78%] [G loss: 0.879849]\n",
      "epoch:9 step:7556[D loss: 0.469449, acc: 48.44%, op_acc: 36.72%] [G loss: 0.814678]\n",
      "epoch:9 step:7557[D loss: 0.433156, acc: 62.50%, op_acc: 39.06%] [G loss: 0.870934]\n",
      "epoch:9 step:7558[D loss: 0.440181, acc: 54.69%, op_acc: 34.38%] [G loss: 0.890957]\n",
      "epoch:9 step:7559[D loss: 0.471764, acc: 51.56%, op_acc: 30.47%] [G loss: 0.817163]\n",
      "epoch:9 step:7560[D loss: 0.464050, acc: 54.69%, op_acc: 28.12%] [G loss: 0.857098]\n",
      "epoch:9 step:7561[D loss: 0.480286, acc: 48.44%, op_acc: 28.12%] [G loss: 0.851252]\n",
      "epoch:9 step:7562[D loss: 0.410497, acc: 64.84%, op_acc: 39.84%] [G loss: 0.837152]\n",
      "epoch:9 step:7563[D loss: 0.433216, acc: 64.84%, op_acc: 33.59%] [G loss: 0.882768]\n",
      "epoch:9 step:7564[D loss: 0.447346, acc: 52.34%, op_acc: 35.16%] [G loss: 0.860041]\n",
      "epoch:9 step:7565[D loss: 0.422171, acc: 62.50%, op_acc: 35.94%] [G loss: 0.933727]\n",
      "epoch:9 step:7566[D loss: 0.455537, acc: 60.16%, op_acc: 30.47%] [G loss: 0.926276]\n",
      "epoch:9 step:7567[D loss: 0.444143, acc: 54.69%, op_acc: 35.16%] [G loss: 0.801137]\n",
      "epoch:9 step:7568[D loss: 0.470218, acc: 51.56%, op_acc: 31.25%] [G loss: 0.841560]\n",
      "epoch:9 step:7569[D loss: 0.423083, acc: 63.28%, op_acc: 38.28%] [G loss: 0.835408]\n",
      "epoch:9 step:7570[D loss: 0.413737, acc: 59.38%, op_acc: 39.06%] [G loss: 0.867437]\n",
      "epoch:9 step:7571[D loss: 0.439173, acc: 56.25%, op_acc: 38.28%] [G loss: 0.858526]\n",
      "epoch:9 step:7572[D loss: 0.432432, acc: 67.19%, op_acc: 34.38%] [G loss: 0.916308]\n",
      "epoch:9 step:7573[D loss: 0.457600, acc: 55.47%, op_acc: 36.72%] [G loss: 0.935240]\n",
      "epoch:9 step:7574[D loss: 0.428527, acc: 62.50%, op_acc: 32.81%] [G loss: 0.915298]\n",
      "epoch:9 step:7575[D loss: 0.477973, acc: 51.56%, op_acc: 36.72%] [G loss: 0.878123]\n",
      "epoch:9 step:7576[D loss: 0.463387, acc: 59.38%, op_acc: 28.91%] [G loss: 0.944115]\n",
      "epoch:9 step:7577[D loss: 0.459730, acc: 55.47%, op_acc: 34.38%] [G loss: 0.916692]\n",
      "epoch:9 step:7578[D loss: 0.438304, acc: 63.28%, op_acc: 35.16%] [G loss: 0.895807]\n",
      "epoch:9 step:7579[D loss: 0.445578, acc: 59.38%, op_acc: 38.28%] [G loss: 0.866689]\n",
      "epoch:9 step:7580[D loss: 0.429641, acc: 64.84%, op_acc: 33.59%] [G loss: 0.871638]\n",
      "epoch:9 step:7581[D loss: 0.490330, acc: 45.31%, op_acc: 27.34%] [G loss: 0.871186]\n",
      "epoch:9 step:7582[D loss: 0.419605, acc: 69.53%, op_acc: 36.72%] [G loss: 0.848520]\n",
      "epoch:9 step:7583[D loss: 0.451269, acc: 59.38%, op_acc: 33.59%] [G loss: 0.922975]\n",
      "epoch:9 step:7584[D loss: 0.394456, acc: 67.97%, op_acc: 39.84%] [G loss: 0.924829]\n",
      "epoch:9 step:7585[D loss: 0.445381, acc: 54.69%, op_acc: 39.06%] [G loss: 0.807859]\n",
      "epoch:9 step:7586[D loss: 0.450303, acc: 63.28%, op_acc: 29.69%] [G loss: 0.850096]\n",
      "epoch:9 step:7587[D loss: 0.421570, acc: 63.28%, op_acc: 37.50%] [G loss: 0.942114]\n",
      "epoch:9 step:7588[D loss: 0.423680, acc: 59.38%, op_acc: 34.38%] [G loss: 0.877993]\n",
      "epoch:9 step:7589[D loss: 0.471238, acc: 52.34%, op_acc: 33.59%] [G loss: 0.831613]\n",
      "epoch:9 step:7590[D loss: 0.429624, acc: 56.25%, op_acc: 34.38%] [G loss: 0.870175]\n",
      "epoch:9 step:7591[D loss: 0.435590, acc: 62.50%, op_acc: 33.59%] [G loss: 0.894003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7592[D loss: 0.428163, acc: 58.59%, op_acc: 33.59%] [G loss: 0.890708]\n",
      "epoch:9 step:7593[D loss: 0.417045, acc: 57.81%, op_acc: 40.62%] [G loss: 0.973029]\n",
      "epoch:9 step:7594[D loss: 0.441540, acc: 60.94%, op_acc: 39.06%] [G loss: 0.904238]\n",
      "epoch:9 step:7595[D loss: 0.451062, acc: 63.28%, op_acc: 31.25%] [G loss: 0.960447]\n",
      "epoch:9 step:7596[D loss: 0.432488, acc: 68.75%, op_acc: 39.84%] [G loss: 0.891534]\n",
      "epoch:9 step:7597[D loss: 0.442662, acc: 59.38%, op_acc: 35.16%] [G loss: 0.838361]\n",
      "epoch:9 step:7598[D loss: 0.437764, acc: 58.59%, op_acc: 35.94%] [G loss: 0.873874]\n",
      "epoch:9 step:7599[D loss: 0.419552, acc: 67.19%, op_acc: 35.94%] [G loss: 0.928725]\n",
      "epoch:9 step:7600[D loss: 0.438447, acc: 60.94%, op_acc: 35.16%] [G loss: 0.895237]\n",
      "##############\n",
      "[0.8625913  0.84608333 0.81376966 0.80645877 0.76466931 0.82753843\n",
      " 0.86930295 0.81388713 0.80294454 0.83451562]\n",
      "##########\n",
      "epoch:9 step:7601[D loss: 0.423396, acc: 60.94%, op_acc: 34.38%] [G loss: 0.954756]\n",
      "epoch:9 step:7602[D loss: 0.475453, acc: 51.56%, op_acc: 34.38%] [G loss: 0.877571]\n",
      "epoch:9 step:7603[D loss: 0.420954, acc: 67.19%, op_acc: 38.28%] [G loss: 0.897356]\n",
      "epoch:9 step:7604[D loss: 0.451156, acc: 56.25%, op_acc: 35.16%] [G loss: 0.889031]\n",
      "epoch:9 step:7605[D loss: 0.413574, acc: 67.97%, op_acc: 41.41%] [G loss: 0.948905]\n",
      "epoch:9 step:7606[D loss: 0.476437, acc: 53.91%, op_acc: 32.81%] [G loss: 0.865954]\n",
      "epoch:9 step:7607[D loss: 0.475347, acc: 58.59%, op_acc: 34.38%] [G loss: 0.832996]\n",
      "epoch:9 step:7608[D loss: 0.430467, acc: 56.25%, op_acc: 36.72%] [G loss: 0.821102]\n",
      "epoch:9 step:7609[D loss: 0.464336, acc: 58.59%, op_acc: 29.69%] [G loss: 0.909253]\n",
      "epoch:9 step:7610[D loss: 0.419955, acc: 68.75%, op_acc: 32.81%] [G loss: 0.903747]\n",
      "epoch:9 step:7611[D loss: 0.459354, acc: 55.47%, op_acc: 31.25%] [G loss: 0.803613]\n",
      "epoch:9 step:7612[D loss: 0.419060, acc: 57.81%, op_acc: 36.72%] [G loss: 0.904540]\n",
      "epoch:9 step:7613[D loss: 0.452475, acc: 60.94%, op_acc: 33.59%] [G loss: 0.891838]\n",
      "epoch:9 step:7614[D loss: 0.410599, acc: 64.06%, op_acc: 42.19%] [G loss: 0.833435]\n",
      "epoch:9 step:7615[D loss: 0.463397, acc: 59.38%, op_acc: 32.03%] [G loss: 0.863211]\n",
      "epoch:9 step:7616[D loss: 0.428949, acc: 64.84%, op_acc: 28.12%] [G loss: 0.901411]\n",
      "epoch:9 step:7617[D loss: 0.436989, acc: 61.72%, op_acc: 40.62%] [G loss: 0.833483]\n",
      "epoch:9 step:7618[D loss: 0.412792, acc: 70.31%, op_acc: 30.47%] [G loss: 0.899332]\n",
      "epoch:9 step:7619[D loss: 0.445780, acc: 53.91%, op_acc: 34.38%] [G loss: 0.888417]\n",
      "epoch:9 step:7620[D loss: 0.463643, acc: 57.81%, op_acc: 31.25%] [G loss: 0.865851]\n",
      "epoch:9 step:7621[D loss: 0.456683, acc: 48.44%, op_acc: 35.94%] [G loss: 0.838412]\n",
      "epoch:9 step:7622[D loss: 0.462179, acc: 48.44%, op_acc: 32.03%] [G loss: 0.852323]\n",
      "epoch:9 step:7623[D loss: 0.436437, acc: 58.59%, op_acc: 35.16%] [G loss: 0.901714]\n",
      "epoch:9 step:7624[D loss: 0.464310, acc: 58.59%, op_acc: 32.81%] [G loss: 0.882564]\n",
      "epoch:9 step:7625[D loss: 0.434225, acc: 63.28%, op_acc: 32.81%] [G loss: 0.915283]\n",
      "epoch:9 step:7626[D loss: 0.462869, acc: 59.38%, op_acc: 28.91%] [G loss: 0.941019]\n",
      "epoch:9 step:7627[D loss: 0.433158, acc: 57.03%, op_acc: 36.72%] [G loss: 0.882452]\n",
      "epoch:9 step:7628[D loss: 0.473727, acc: 57.81%, op_acc: 31.25%] [G loss: 0.873289]\n",
      "epoch:9 step:7629[D loss: 0.445807, acc: 60.94%, op_acc: 37.50%] [G loss: 0.825550]\n",
      "epoch:9 step:7630[D loss: 0.434468, acc: 59.38%, op_acc: 35.94%] [G loss: 0.855135]\n",
      "epoch:9 step:7631[D loss: 0.419640, acc: 61.72%, op_acc: 39.84%] [G loss: 0.920108]\n",
      "epoch:9 step:7632[D loss: 0.392711, acc: 67.97%, op_acc: 40.62%] [G loss: 0.897556]\n",
      "epoch:9 step:7633[D loss: 0.484271, acc: 53.12%, op_acc: 31.25%] [G loss: 0.825178]\n",
      "epoch:9 step:7634[D loss: 0.427107, acc: 67.19%, op_acc: 35.16%] [G loss: 0.843486]\n",
      "epoch:9 step:7635[D loss: 0.464929, acc: 51.56%, op_acc: 32.81%] [G loss: 0.826173]\n",
      "epoch:9 step:7636[D loss: 0.427346, acc: 58.59%, op_acc: 34.38%] [G loss: 0.838872]\n",
      "epoch:9 step:7637[D loss: 0.431741, acc: 63.28%, op_acc: 35.94%] [G loss: 0.869447]\n",
      "epoch:9 step:7638[D loss: 0.448117, acc: 59.38%, op_acc: 34.38%] [G loss: 0.900184]\n",
      "epoch:9 step:7639[D loss: 0.432288, acc: 64.06%, op_acc: 31.25%] [G loss: 0.915443]\n",
      "epoch:9 step:7640[D loss: 0.456135, acc: 57.81%, op_acc: 35.94%] [G loss: 0.875725]\n",
      "epoch:9 step:7641[D loss: 0.462194, acc: 53.12%, op_acc: 35.94%] [G loss: 0.842746]\n",
      "epoch:9 step:7642[D loss: 0.432904, acc: 56.25%, op_acc: 40.62%] [G loss: 0.817847]\n",
      "epoch:9 step:7643[D loss: 0.411474, acc: 67.19%, op_acc: 39.06%] [G loss: 0.849629]\n",
      "epoch:9 step:7644[D loss: 0.424524, acc: 63.28%, op_acc: 40.62%] [G loss: 0.920937]\n",
      "epoch:9 step:7645[D loss: 0.430177, acc: 57.81%, op_acc: 42.19%] [G loss: 0.911285]\n",
      "epoch:9 step:7646[D loss: 0.493866, acc: 46.09%, op_acc: 32.03%] [G loss: 0.902475]\n",
      "epoch:9 step:7647[D loss: 0.446914, acc: 63.28%, op_acc: 35.16%] [G loss: 0.893797]\n",
      "epoch:9 step:7648[D loss: 0.502077, acc: 50.00%, op_acc: 30.47%] [G loss: 0.904323]\n",
      "epoch:9 step:7649[D loss: 0.471715, acc: 56.25%, op_acc: 28.12%] [G loss: 0.893313]\n",
      "epoch:9 step:7650[D loss: 0.449019, acc: 59.38%, op_acc: 33.59%] [G loss: 0.984525]\n",
      "##############\n",
      "[0.86388144 0.86187865 0.81080597 0.79149447 0.78680278 0.85609157\n",
      " 0.88067728 0.82873993 0.84237126 0.82190751]\n",
      "##########\n",
      "epoch:9 step:7651[D loss: 0.482481, acc: 57.03%, op_acc: 29.69%] [G loss: 0.917839]\n",
      "epoch:9 step:7652[D loss: 0.427405, acc: 58.59%, op_acc: 35.94%] [G loss: 0.912236]\n",
      "epoch:9 step:7653[D loss: 0.440562, acc: 53.12%, op_acc: 35.16%] [G loss: 0.912278]\n",
      "epoch:9 step:7654[D loss: 0.444303, acc: 61.72%, op_acc: 40.62%] [G loss: 0.929140]\n",
      "epoch:9 step:7655[D loss: 0.437405, acc: 52.34%, op_acc: 39.06%] [G loss: 0.891067]\n",
      "epoch:9 step:7656[D loss: 0.420803, acc: 56.25%, op_acc: 41.41%] [G loss: 0.840003]\n",
      "epoch:9 step:7657[D loss: 0.433595, acc: 63.28%, op_acc: 30.47%] [G loss: 0.934915]\n",
      "epoch:9 step:7658[D loss: 0.442928, acc: 63.28%, op_acc: 32.81%] [G loss: 0.844191]\n",
      "epoch:9 step:7659[D loss: 0.456408, acc: 54.69%, op_acc: 39.84%] [G loss: 0.835888]\n",
      "epoch:9 step:7660[D loss: 0.451299, acc: 60.16%, op_acc: 31.25%] [G loss: 0.910839]\n",
      "epoch:9 step:7661[D loss: 0.467890, acc: 56.25%, op_acc: 28.91%] [G loss: 0.862880]\n",
      "epoch:9 step:7662[D loss: 0.438407, acc: 60.16%, op_acc: 32.81%] [G loss: 0.893481]\n",
      "epoch:9 step:7663[D loss: 0.431703, acc: 58.59%, op_acc: 38.28%] [G loss: 0.837595]\n",
      "epoch:9 step:7664[D loss: 0.462582, acc: 51.56%, op_acc: 29.69%] [G loss: 0.810069]\n",
      "epoch:9 step:7665[D loss: 0.435679, acc: 56.25%, op_acc: 36.72%] [G loss: 0.858423]\n",
      "epoch:9 step:7666[D loss: 0.440685, acc: 60.16%, op_acc: 34.38%] [G loss: 0.853672]\n",
      "epoch:9 step:7667[D loss: 0.462409, acc: 55.47%, op_acc: 32.81%] [G loss: 0.893427]\n",
      "epoch:9 step:7668[D loss: 0.449637, acc: 51.56%, op_acc: 37.50%] [G loss: 0.860444]\n",
      "epoch:9 step:7669[D loss: 0.469296, acc: 61.72%, op_acc: 30.47%] [G loss: 0.892006]\n",
      "epoch:9 step:7670[D loss: 0.458296, acc: 61.72%, op_acc: 28.91%] [G loss: 0.808026]\n",
      "epoch:9 step:7671[D loss: 0.441694, acc: 60.94%, op_acc: 36.72%] [G loss: 0.854162]\n",
      "epoch:9 step:7672[D loss: 0.445151, acc: 64.06%, op_acc: 28.12%] [G loss: 0.889570]\n",
      "epoch:9 step:7673[D loss: 0.412135, acc: 63.28%, op_acc: 39.84%] [G loss: 0.781294]\n",
      "epoch:9 step:7674[D loss: 0.439513, acc: 61.72%, op_acc: 33.59%] [G loss: 0.846172]\n",
      "epoch:9 step:7675[D loss: 0.462416, acc: 58.59%, op_acc: 30.47%] [G loss: 0.938514]\n",
      "epoch:9 step:7676[D loss: 0.418883, acc: 60.94%, op_acc: 39.84%] [G loss: 0.881766]\n",
      "epoch:9 step:7677[D loss: 0.447411, acc: 59.38%, op_acc: 35.16%] [G loss: 0.964209]\n",
      "epoch:9 step:7678[D loss: 0.436973, acc: 60.94%, op_acc: 36.72%] [G loss: 0.906769]\n",
      "epoch:9 step:7679[D loss: 0.442382, acc: 64.84%, op_acc: 34.38%] [G loss: 0.894012]\n",
      "epoch:9 step:7680[D loss: 0.424213, acc: 63.28%, op_acc: 42.19%] [G loss: 0.910927]\n",
      "epoch:9 step:7681[D loss: 0.433304, acc: 59.38%, op_acc: 37.50%] [G loss: 0.934990]\n",
      "epoch:9 step:7682[D loss: 0.408293, acc: 65.62%, op_acc: 37.50%] [G loss: 0.855237]\n",
      "epoch:9 step:7683[D loss: 0.456563, acc: 50.78%, op_acc: 36.72%] [G loss: 0.845922]\n",
      "epoch:9 step:7684[D loss: 0.454799, acc: 56.25%, op_acc: 32.81%] [G loss: 0.894375]\n",
      "epoch:9 step:7685[D loss: 0.444476, acc: 62.50%, op_acc: 34.38%] [G loss: 0.919745]\n",
      "epoch:9 step:7686[D loss: 0.446342, acc: 53.12%, op_acc: 35.94%] [G loss: 0.913523]\n",
      "epoch:9 step:7687[D loss: 0.442758, acc: 57.03%, op_acc: 42.97%] [G loss: 0.857836]\n",
      "epoch:9 step:7688[D loss: 0.446709, acc: 70.31%, op_acc: 30.47%] [G loss: 0.802780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7689[D loss: 0.441786, acc: 57.03%, op_acc: 39.84%] [G loss: 0.835023]\n",
      "epoch:9 step:7690[D loss: 0.430034, acc: 61.72%, op_acc: 37.50%] [G loss: 0.956417]\n",
      "epoch:9 step:7691[D loss: 0.439683, acc: 60.94%, op_acc: 37.50%] [G loss: 0.865138]\n",
      "epoch:9 step:7692[D loss: 0.416653, acc: 60.16%, op_acc: 39.84%] [G loss: 0.942171]\n",
      "epoch:9 step:7693[D loss: 0.445531, acc: 59.38%, op_acc: 33.59%] [G loss: 0.848263]\n",
      "epoch:9 step:7694[D loss: 0.456493, acc: 52.34%, op_acc: 30.47%] [G loss: 0.853280]\n",
      "epoch:9 step:7695[D loss: 0.471022, acc: 59.38%, op_acc: 30.47%] [G loss: 0.819107]\n",
      "epoch:9 step:7696[D loss: 0.424231, acc: 62.50%, op_acc: 35.16%] [G loss: 0.932219]\n",
      "epoch:9 step:7697[D loss: 0.465007, acc: 57.03%, op_acc: 32.81%] [G loss: 0.902901]\n",
      "epoch:9 step:7698[D loss: 0.458007, acc: 50.78%, op_acc: 33.59%] [G loss: 0.893000]\n",
      "epoch:9 step:7699[D loss: 0.450399, acc: 56.25%, op_acc: 34.38%] [G loss: 0.890635]\n",
      "epoch:9 step:7700[D loss: 0.438632, acc: 59.38%, op_acc: 33.59%] [G loss: 0.954704]\n",
      "##############\n",
      "[0.86792772 0.85225075 0.8163681  0.80677219 0.81396222 0.7969383\n",
      " 0.88091233 0.80766939 0.81539062 0.83404498]\n",
      "##########\n",
      "epoch:9 step:7701[D loss: 0.470051, acc: 53.12%, op_acc: 34.38%] [G loss: 0.897537]\n",
      "epoch:9 step:7702[D loss: 0.456946, acc: 59.38%, op_acc: 30.47%] [G loss: 0.871221]\n",
      "epoch:9 step:7703[D loss: 0.429511, acc: 60.94%, op_acc: 35.94%] [G loss: 0.895658]\n",
      "epoch:9 step:7704[D loss: 0.437217, acc: 58.59%, op_acc: 39.06%] [G loss: 0.854637]\n",
      "epoch:9 step:7705[D loss: 0.461260, acc: 61.72%, op_acc: 29.69%] [G loss: 0.927242]\n",
      "epoch:9 step:7706[D loss: 0.460221, acc: 56.25%, op_acc: 28.91%] [G loss: 0.890306]\n",
      "epoch:9 step:7707[D loss: 0.419687, acc: 60.16%, op_acc: 39.84%] [G loss: 0.895973]\n",
      "epoch:9 step:7708[D loss: 0.446538, acc: 60.16%, op_acc: 38.28%] [G loss: 0.886012]\n",
      "epoch:9 step:7709[D loss: 0.453502, acc: 61.72%, op_acc: 35.16%] [G loss: 0.866914]\n",
      "epoch:9 step:7710[D loss: 0.485028, acc: 54.69%, op_acc: 29.69%] [G loss: 0.900855]\n",
      "epoch:9 step:7711[D loss: 0.443856, acc: 53.12%, op_acc: 39.84%] [G loss: 0.869921]\n",
      "epoch:9 step:7712[D loss: 0.445954, acc: 62.50%, op_acc: 35.16%] [G loss: 0.840846]\n",
      "epoch:9 step:7713[D loss: 0.474535, acc: 52.34%, op_acc: 25.78%] [G loss: 0.872902]\n",
      "epoch:9 step:7714[D loss: 0.467351, acc: 53.12%, op_acc: 33.59%] [G loss: 0.876995]\n",
      "epoch:9 step:7715[D loss: 0.450131, acc: 55.47%, op_acc: 35.16%] [G loss: 0.856462]\n",
      "epoch:9 step:7716[D loss: 0.425710, acc: 67.19%, op_acc: 33.59%] [G loss: 0.877841]\n",
      "epoch:9 step:7717[D loss: 0.446275, acc: 53.91%, op_acc: 35.16%] [G loss: 0.916715]\n",
      "epoch:9 step:7718[D loss: 0.458879, acc: 56.25%, op_acc: 32.03%] [G loss: 0.899983]\n",
      "epoch:9 step:7719[D loss: 0.429760, acc: 70.31%, op_acc: 35.16%] [G loss: 0.905488]\n",
      "epoch:9 step:7720[D loss: 0.462142, acc: 53.91%, op_acc: 33.59%] [G loss: 0.871826]\n",
      "epoch:9 step:7721[D loss: 0.456028, acc: 57.81%, op_acc: 28.91%] [G loss: 0.854853]\n",
      "epoch:9 step:7722[D loss: 0.464730, acc: 59.38%, op_acc: 28.12%] [G loss: 0.928388]\n",
      "epoch:9 step:7723[D loss: 0.438470, acc: 59.38%, op_acc: 36.72%] [G loss: 0.907997]\n",
      "epoch:9 step:7724[D loss: 0.449581, acc: 59.38%, op_acc: 34.38%] [G loss: 0.850874]\n",
      "epoch:9 step:7725[D loss: 0.432825, acc: 62.50%, op_acc: 33.59%] [G loss: 0.910207]\n",
      "epoch:9 step:7726[D loss: 0.452821, acc: 57.03%, op_acc: 32.81%] [G loss: 0.901103]\n",
      "epoch:9 step:7727[D loss: 0.460574, acc: 52.34%, op_acc: 36.72%] [G loss: 0.818062]\n",
      "epoch:9 step:7728[D loss: 0.460064, acc: 51.56%, op_acc: 36.72%] [G loss: 0.884238]\n",
      "epoch:9 step:7729[D loss: 0.485349, acc: 59.38%, op_acc: 32.03%] [G loss: 0.856883]\n",
      "epoch:9 step:7730[D loss: 0.438023, acc: 62.50%, op_acc: 27.34%] [G loss: 0.910443]\n",
      "epoch:9 step:7731[D loss: 0.465143, acc: 49.22%, op_acc: 33.59%] [G loss: 0.815930]\n",
      "epoch:9 step:7732[D loss: 0.469315, acc: 50.78%, op_acc: 31.25%] [G loss: 0.848304]\n",
      "epoch:9 step:7733[D loss: 0.397186, acc: 65.62%, op_acc: 46.09%] [G loss: 0.895707]\n",
      "epoch:9 step:7734[D loss: 0.440075, acc: 61.72%, op_acc: 32.03%] [G loss: 0.829513]\n",
      "epoch:9 step:7735[D loss: 0.439307, acc: 59.38%, op_acc: 35.94%] [G loss: 0.850191]\n",
      "epoch:9 step:7736[D loss: 0.457832, acc: 56.25%, op_acc: 35.94%] [G loss: 0.800032]\n",
      "epoch:9 step:7737[D loss: 0.430125, acc: 63.28%, op_acc: 37.50%] [G loss: 0.820357]\n",
      "epoch:9 step:7738[D loss: 0.457611, acc: 54.69%, op_acc: 32.81%] [G loss: 0.904506]\n",
      "epoch:9 step:7739[D loss: 0.414529, acc: 57.03%, op_acc: 41.41%] [G loss: 0.865028]\n",
      "epoch:9 step:7740[D loss: 0.429613, acc: 59.38%, op_acc: 32.81%] [G loss: 0.856781]\n",
      "epoch:9 step:7741[D loss: 0.411389, acc: 64.06%, op_acc: 36.72%] [G loss: 0.924431]\n",
      "epoch:9 step:7742[D loss: 0.418593, acc: 60.16%, op_acc: 38.28%] [G loss: 0.823662]\n",
      "epoch:9 step:7743[D loss: 0.443108, acc: 65.62%, op_acc: 31.25%] [G loss: 0.888213]\n",
      "epoch:9 step:7744[D loss: 0.441257, acc: 57.81%, op_acc: 35.94%] [G loss: 0.894384]\n",
      "epoch:9 step:7745[D loss: 0.477019, acc: 47.66%, op_acc: 34.38%] [G loss: 0.826086]\n",
      "epoch:9 step:7746[D loss: 0.414859, acc: 63.28%, op_acc: 39.06%] [G loss: 0.884866]\n",
      "epoch:9 step:7747[D loss: 0.427404, acc: 60.16%, op_acc: 33.59%] [G loss: 0.881615]\n",
      "epoch:9 step:7748[D loss: 0.444438, acc: 62.50%, op_acc: 35.16%] [G loss: 0.842698]\n",
      "epoch:9 step:7749[D loss: 0.465467, acc: 52.34%, op_acc: 34.38%] [G loss: 0.838540]\n",
      "epoch:9 step:7750[D loss: 0.446936, acc: 51.56%, op_acc: 35.94%] [G loss: 0.863366]\n",
      "##############\n",
      "[0.88258949 0.84334033 0.80709326 0.80484713 0.78645297 0.84475947\n",
      " 0.89212956 0.83021174 0.79154806 0.83286144]\n",
      "##########\n",
      "epoch:9 step:7751[D loss: 0.450761, acc: 56.25%, op_acc: 38.28%] [G loss: 0.895424]\n",
      "epoch:9 step:7752[D loss: 0.433179, acc: 53.91%, op_acc: 40.62%] [G loss: 0.902496]\n",
      "epoch:9 step:7753[D loss: 0.468891, acc: 58.59%, op_acc: 28.91%] [G loss: 0.891600]\n",
      "epoch:9 step:7754[D loss: 0.444129, acc: 59.38%, op_acc: 32.03%] [G loss: 0.878032]\n",
      "epoch:9 step:7755[D loss: 0.453553, acc: 56.25%, op_acc: 34.38%] [G loss: 0.890786]\n",
      "epoch:9 step:7756[D loss: 0.463114, acc: 62.50%, op_acc: 28.91%] [G loss: 0.861934]\n",
      "epoch:9 step:7757[D loss: 0.450581, acc: 55.47%, op_acc: 35.16%] [G loss: 0.891118]\n",
      "epoch:9 step:7758[D loss: 0.460088, acc: 51.56%, op_acc: 34.38%] [G loss: 0.795150]\n",
      "epoch:9 step:7759[D loss: 0.439405, acc: 62.50%, op_acc: 34.38%] [G loss: 0.865196]\n",
      "epoch:9 step:7760[D loss: 0.442190, acc: 54.69%, op_acc: 39.06%] [G loss: 0.891028]\n",
      "epoch:9 step:7761[D loss: 0.455319, acc: 51.56%, op_acc: 37.50%] [G loss: 0.887550]\n",
      "epoch:9 step:7762[D loss: 0.431667, acc: 57.81%, op_acc: 35.16%] [G loss: 0.843040]\n",
      "epoch:9 step:7763[D loss: 0.451227, acc: 59.38%, op_acc: 35.94%] [G loss: 0.854042]\n",
      "epoch:9 step:7764[D loss: 0.451164, acc: 60.94%, op_acc: 30.47%] [G loss: 0.827644]\n",
      "epoch:9 step:7765[D loss: 0.449391, acc: 61.72%, op_acc: 34.38%] [G loss: 0.917130]\n",
      "epoch:9 step:7766[D loss: 0.460975, acc: 52.34%, op_acc: 34.38%] [G loss: 0.851852]\n",
      "epoch:9 step:7767[D loss: 0.432416, acc: 58.59%, op_acc: 33.59%] [G loss: 0.914804]\n",
      "epoch:9 step:7768[D loss: 0.431920, acc: 61.72%, op_acc: 35.94%] [G loss: 0.958790]\n",
      "epoch:9 step:7769[D loss: 0.420500, acc: 63.28%, op_acc: 39.06%] [G loss: 0.823274]\n",
      "epoch:9 step:7770[D loss: 0.441865, acc: 58.59%, op_acc: 33.59%] [G loss: 0.877202]\n",
      "epoch:9 step:7771[D loss: 0.435798, acc: 58.59%, op_acc: 37.50%] [G loss: 0.852875]\n",
      "epoch:9 step:7772[D loss: 0.455758, acc: 55.47%, op_acc: 33.59%] [G loss: 0.811857]\n",
      "epoch:9 step:7773[D loss: 0.428211, acc: 60.94%, op_acc: 36.72%] [G loss: 0.860726]\n",
      "epoch:9 step:7774[D loss: 0.431368, acc: 65.62%, op_acc: 33.59%] [G loss: 0.884711]\n",
      "epoch:9 step:7775[D loss: 0.447420, acc: 56.25%, op_acc: 30.47%] [G loss: 0.910373]\n",
      "epoch:9 step:7776[D loss: 0.462090, acc: 52.34%, op_acc: 35.16%] [G loss: 0.865064]\n",
      "epoch:9 step:7777[D loss: 0.432302, acc: 67.97%, op_acc: 38.28%] [G loss: 0.834116]\n",
      "epoch:9 step:7778[D loss: 0.459676, acc: 55.47%, op_acc: 33.59%] [G loss: 0.804759]\n",
      "epoch:9 step:7779[D loss: 0.447554, acc: 58.59%, op_acc: 33.59%] [G loss: 0.910240]\n",
      "epoch:9 step:7780[D loss: 0.461091, acc: 59.38%, op_acc: 30.47%] [G loss: 0.872410]\n",
      "epoch:9 step:7781[D loss: 0.445518, acc: 57.81%, op_acc: 32.81%] [G loss: 0.849517]\n",
      "epoch:9 step:7782[D loss: 0.432275, acc: 64.84%, op_acc: 35.94%] [G loss: 0.809691]\n",
      "epoch:9 step:7783[D loss: 0.421366, acc: 64.84%, op_acc: 36.72%] [G loss: 0.918524]\n",
      "epoch:9 step:7784[D loss: 0.444524, acc: 54.69%, op_acc: 34.38%] [G loss: 0.869999]\n",
      "epoch:9 step:7785[D loss: 0.398561, acc: 75.00%, op_acc: 36.72%] [G loss: 0.933667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7786[D loss: 0.436262, acc: 62.50%, op_acc: 36.72%] [G loss: 0.851898]\n",
      "epoch:9 step:7787[D loss: 0.422195, acc: 65.62%, op_acc: 39.84%] [G loss: 0.882753]\n",
      "epoch:9 step:7788[D loss: 0.428598, acc: 66.41%, op_acc: 33.59%] [G loss: 0.904165]\n",
      "epoch:9 step:7789[D loss: 0.433947, acc: 57.81%, op_acc: 39.06%] [G loss: 0.873428]\n",
      "epoch:9 step:7790[D loss: 0.407920, acc: 59.38%, op_acc: 40.62%] [G loss: 0.864169]\n",
      "epoch:9 step:7791[D loss: 0.445393, acc: 59.38%, op_acc: 30.47%] [G loss: 0.882303]\n",
      "epoch:9 step:7792[D loss: 0.479290, acc: 48.44%, op_acc: 33.59%] [G loss: 0.810077]\n",
      "epoch:9 step:7793[D loss: 0.434622, acc: 55.47%, op_acc: 36.72%] [G loss: 0.932151]\n",
      "epoch:9 step:7794[D loss: 0.443804, acc: 57.03%, op_acc: 35.16%] [G loss: 0.835709]\n",
      "epoch:9 step:7795[D loss: 0.460345, acc: 55.47%, op_acc: 34.38%] [G loss: 0.869632]\n",
      "epoch:9 step:7796[D loss: 0.442490, acc: 59.38%, op_acc: 35.16%] [G loss: 0.853272]\n",
      "epoch:9 step:7797[D loss: 0.448053, acc: 66.41%, op_acc: 37.50%] [G loss: 0.875992]\n",
      "epoch:9 step:7798[D loss: 0.445481, acc: 51.56%, op_acc: 40.62%] [G loss: 0.835225]\n",
      "epoch:9 step:7799[D loss: 0.407224, acc: 60.94%, op_acc: 35.16%] [G loss: 0.855460]\n",
      "epoch:9 step:7800[D loss: 0.446844, acc: 63.28%, op_acc: 31.25%] [G loss: 0.879652]\n",
      "##############\n",
      "[0.85410555 0.85985952 0.81300838 0.806544   0.80060017 0.83031613\n",
      " 0.88499671 0.80352932 0.82850903 0.83804858]\n",
      "##########\n",
      "epoch:9 step:7801[D loss: 0.474894, acc: 52.34%, op_acc: 35.16%] [G loss: 0.835909]\n",
      "epoch:9 step:7802[D loss: 0.430855, acc: 62.50%, op_acc: 37.50%] [G loss: 0.875355]\n",
      "epoch:9 step:7803[D loss: 0.401964, acc: 64.06%, op_acc: 40.62%] [G loss: 0.977261]\n",
      "epoch:9 step:7804[D loss: 0.450065, acc: 62.50%, op_acc: 33.59%] [G loss: 0.851917]\n",
      "epoch:9 step:7805[D loss: 0.423233, acc: 67.19%, op_acc: 34.38%] [G loss: 0.870194]\n",
      "epoch:9 step:7806[D loss: 0.463106, acc: 54.69%, op_acc: 30.47%] [G loss: 0.873549]\n",
      "epoch:9 step:7807[D loss: 0.407380, acc: 67.19%, op_acc: 42.19%] [G loss: 0.884286]\n",
      "epoch:9 step:7808[D loss: 0.446505, acc: 53.12%, op_acc: 39.06%] [G loss: 0.855318]\n",
      "epoch:9 step:7809[D loss: 0.421021, acc: 64.06%, op_acc: 35.94%] [G loss: 0.863801]\n",
      "epoch:9 step:7810[D loss: 0.460088, acc: 53.12%, op_acc: 32.03%] [G loss: 0.878351]\n",
      "epoch:10 step:7811[D loss: 0.451962, acc: 56.25%, op_acc: 36.72%] [G loss: 0.902106]\n",
      "epoch:10 step:7812[D loss: 0.413478, acc: 58.59%, op_acc: 38.28%] [G loss: 0.890410]\n",
      "epoch:10 step:7813[D loss: 0.447772, acc: 55.47%, op_acc: 35.94%] [G loss: 0.912363]\n",
      "epoch:10 step:7814[D loss: 0.423243, acc: 59.38%, op_acc: 33.59%] [G loss: 0.909917]\n",
      "epoch:10 step:7815[D loss: 0.413378, acc: 67.19%, op_acc: 35.16%] [G loss: 0.897273]\n",
      "epoch:10 step:7816[D loss: 0.404928, acc: 63.28%, op_acc: 39.84%] [G loss: 0.878218]\n",
      "epoch:10 step:7817[D loss: 0.416232, acc: 65.62%, op_acc: 35.94%] [G loss: 0.869590]\n",
      "epoch:10 step:7818[D loss: 0.435641, acc: 63.28%, op_acc: 33.59%] [G loss: 0.867264]\n",
      "epoch:10 step:7819[D loss: 0.408720, acc: 67.97%, op_acc: 40.62%] [G loss: 0.906945]\n",
      "epoch:10 step:7820[D loss: 0.425699, acc: 66.41%, op_acc: 36.72%] [G loss: 0.886591]\n",
      "epoch:10 step:7821[D loss: 0.482667, acc: 52.34%, op_acc: 30.47%] [G loss: 0.847268]\n",
      "epoch:10 step:7822[D loss: 0.470452, acc: 46.88%, op_acc: 33.59%] [G loss: 0.734534]\n",
      "epoch:10 step:7823[D loss: 0.431217, acc: 63.28%, op_acc: 37.50%] [G loss: 0.909306]\n",
      "epoch:10 step:7824[D loss: 0.443170, acc: 63.28%, op_acc: 31.25%] [G loss: 0.887339]\n",
      "epoch:10 step:7825[D loss: 0.439799, acc: 61.72%, op_acc: 32.81%] [G loss: 0.947424]\n",
      "epoch:10 step:7826[D loss: 0.420197, acc: 57.81%, op_acc: 35.16%] [G loss: 0.863279]\n",
      "epoch:10 step:7827[D loss: 0.462247, acc: 59.38%, op_acc: 39.84%] [G loss: 0.851329]\n",
      "epoch:10 step:7828[D loss: 0.453383, acc: 59.38%, op_acc: 35.16%] [G loss: 0.843049]\n",
      "epoch:10 step:7829[D loss: 0.434212, acc: 57.81%, op_acc: 37.50%] [G loss: 0.868953]\n",
      "epoch:10 step:7830[D loss: 0.418455, acc: 64.06%, op_acc: 37.50%] [G loss: 0.895442]\n",
      "epoch:10 step:7831[D loss: 0.456452, acc: 57.03%, op_acc: 38.28%] [G loss: 0.847123]\n",
      "epoch:10 step:7832[D loss: 0.449679, acc: 50.00%, op_acc: 35.94%] [G loss: 0.872186]\n",
      "epoch:10 step:7833[D loss: 0.472931, acc: 45.31%, op_acc: 30.47%] [G loss: 0.837190]\n",
      "epoch:10 step:7834[D loss: 0.445264, acc: 61.72%, op_acc: 32.03%] [G loss: 0.871937]\n",
      "epoch:10 step:7835[D loss: 0.479320, acc: 56.25%, op_acc: 32.81%] [G loss: 0.894881]\n",
      "epoch:10 step:7836[D loss: 0.453469, acc: 50.78%, op_acc: 39.84%] [G loss: 0.870874]\n",
      "epoch:10 step:7837[D loss: 0.448342, acc: 61.72%, op_acc: 32.03%] [G loss: 0.873287]\n",
      "epoch:10 step:7838[D loss: 0.421986, acc: 61.72%, op_acc: 39.06%] [G loss: 0.839454]\n",
      "epoch:10 step:7839[D loss: 0.438379, acc: 52.34%, op_acc: 39.06%] [G loss: 0.848256]\n",
      "epoch:10 step:7840[D loss: 0.427210, acc: 60.16%, op_acc: 36.72%] [G loss: 0.898170]\n",
      "epoch:10 step:7841[D loss: 0.444851, acc: 60.94%, op_acc: 35.94%] [G loss: 0.865594]\n",
      "epoch:10 step:7842[D loss: 0.448242, acc: 60.16%, op_acc: 35.16%] [G loss: 0.877727]\n",
      "epoch:10 step:7843[D loss: 0.436016, acc: 56.25%, op_acc: 39.84%] [G loss: 0.875251]\n",
      "epoch:10 step:7844[D loss: 0.419476, acc: 60.16%, op_acc: 35.16%] [G loss: 0.838487]\n",
      "epoch:10 step:7845[D loss: 0.413386, acc: 71.09%, op_acc: 32.81%] [G loss: 0.931197]\n",
      "epoch:10 step:7846[D loss: 0.438148, acc: 49.22%, op_acc: 39.06%] [G loss: 0.834821]\n",
      "epoch:10 step:7847[D loss: 0.437490, acc: 57.03%, op_acc: 35.16%] [G loss: 0.880182]\n",
      "epoch:10 step:7848[D loss: 0.453587, acc: 52.34%, op_acc: 35.16%] [G loss: 0.909082]\n",
      "epoch:10 step:7849[D loss: 0.437195, acc: 56.25%, op_acc: 36.72%] [G loss: 0.835636]\n",
      "epoch:10 step:7850[D loss: 0.472437, acc: 57.03%, op_acc: 32.03%] [G loss: 0.877317]\n",
      "##############\n",
      "[0.85564257 0.87335176 0.82188149 0.79988955 0.81126559 0.80999326\n",
      " 0.8874825  0.81406144 0.82265072 0.82549458]\n",
      "##########\n",
      "epoch:10 step:7851[D loss: 0.434877, acc: 53.91%, op_acc: 31.25%] [G loss: 0.889665]\n",
      "epoch:10 step:7852[D loss: 0.421771, acc: 60.94%, op_acc: 33.59%] [G loss: 0.846721]\n",
      "epoch:10 step:7853[D loss: 0.444717, acc: 60.16%, op_acc: 29.69%] [G loss: 0.914181]\n",
      "epoch:10 step:7854[D loss: 0.460171, acc: 54.69%, op_acc: 36.72%] [G loss: 0.899976]\n",
      "epoch:10 step:7855[D loss: 0.451593, acc: 56.25%, op_acc: 35.16%] [G loss: 0.894370]\n",
      "epoch:10 step:7856[D loss: 0.453142, acc: 59.38%, op_acc: 32.81%] [G loss: 0.856248]\n",
      "epoch:10 step:7857[D loss: 0.408889, acc: 69.53%, op_acc: 36.72%] [G loss: 0.879201]\n",
      "epoch:10 step:7858[D loss: 0.472059, acc: 50.78%, op_acc: 32.03%] [G loss: 0.867845]\n",
      "epoch:10 step:7859[D loss: 0.473191, acc: 51.56%, op_acc: 28.12%] [G loss: 0.848971]\n",
      "epoch:10 step:7860[D loss: 0.447303, acc: 55.47%, op_acc: 33.59%] [G loss: 0.868372]\n",
      "epoch:10 step:7861[D loss: 0.442271, acc: 60.16%, op_acc: 39.06%] [G loss: 0.926341]\n",
      "epoch:10 step:7862[D loss: 0.436132, acc: 60.94%, op_acc: 30.47%] [G loss: 0.881053]\n",
      "epoch:10 step:7863[D loss: 0.474863, acc: 51.56%, op_acc: 28.91%] [G loss: 0.939183]\n",
      "epoch:10 step:7864[D loss: 0.451815, acc: 53.91%, op_acc: 32.03%] [G loss: 0.933823]\n",
      "epoch:10 step:7865[D loss: 0.431283, acc: 60.94%, op_acc: 34.38%] [G loss: 0.939153]\n",
      "epoch:10 step:7866[D loss: 0.425608, acc: 62.50%, op_acc: 39.06%] [G loss: 0.905022]\n",
      "epoch:10 step:7867[D loss: 0.451631, acc: 63.28%, op_acc: 29.69%] [G loss: 0.909951]\n",
      "epoch:10 step:7868[D loss: 0.425529, acc: 63.28%, op_acc: 39.84%] [G loss: 0.944142]\n",
      "epoch:10 step:7869[D loss: 0.434828, acc: 57.03%, op_acc: 32.03%] [G loss: 0.904025]\n",
      "epoch:10 step:7870[D loss: 0.420100, acc: 64.84%, op_acc: 32.81%] [G loss: 0.872430]\n",
      "epoch:10 step:7871[D loss: 0.439927, acc: 57.03%, op_acc: 29.69%] [G loss: 0.876085]\n",
      "epoch:10 step:7872[D loss: 0.444588, acc: 60.16%, op_acc: 32.03%] [G loss: 0.887071]\n",
      "epoch:10 step:7873[D loss: 0.447679, acc: 63.28%, op_acc: 35.94%] [G loss: 0.888550]\n",
      "epoch:10 step:7874[D loss: 0.436654, acc: 53.91%, op_acc: 32.03%] [G loss: 0.963191]\n",
      "epoch:10 step:7875[D loss: 0.442066, acc: 67.19%, op_acc: 33.59%] [G loss: 0.954409]\n",
      "epoch:10 step:7876[D loss: 0.475563, acc: 44.53%, op_acc: 36.72%] [G loss: 0.826075]\n",
      "epoch:10 step:7877[D loss: 0.449585, acc: 47.66%, op_acc: 38.28%] [G loss: 0.868085]\n",
      "epoch:10 step:7878[D loss: 0.434672, acc: 57.81%, op_acc: 35.94%] [G loss: 1.026085]\n",
      "epoch:10 step:7879[D loss: 0.432427, acc: 57.03%, op_acc: 39.84%] [G loss: 0.848603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7880[D loss: 0.452033, acc: 53.12%, op_acc: 35.94%] [G loss: 0.903547]\n",
      "epoch:10 step:7881[D loss: 0.467916, acc: 54.69%, op_acc: 34.38%] [G loss: 0.855666]\n",
      "epoch:10 step:7882[D loss: 0.420395, acc: 56.25%, op_acc: 36.72%] [G loss: 0.913447]\n",
      "epoch:10 step:7883[D loss: 0.436588, acc: 55.47%, op_acc: 38.28%] [G loss: 0.871736]\n",
      "epoch:10 step:7884[D loss: 0.400845, acc: 68.75%, op_acc: 39.06%] [G loss: 0.906248]\n",
      "epoch:10 step:7885[D loss: 0.409754, acc: 67.97%, op_acc: 39.06%] [G loss: 0.882337]\n",
      "epoch:10 step:7886[D loss: 0.493065, acc: 45.31%, op_acc: 34.38%] [G loss: 0.851165]\n",
      "epoch:10 step:7887[D loss: 0.430557, acc: 55.47%, op_acc: 34.38%] [G loss: 0.832999]\n",
      "epoch:10 step:7888[D loss: 0.451737, acc: 62.50%, op_acc: 30.47%] [G loss: 0.892252]\n",
      "epoch:10 step:7889[D loss: 0.455124, acc: 53.91%, op_acc: 32.81%] [G loss: 0.796376]\n",
      "epoch:10 step:7890[D loss: 0.479305, acc: 60.94%, op_acc: 26.56%] [G loss: 0.864978]\n",
      "epoch:10 step:7891[D loss: 0.478354, acc: 57.81%, op_acc: 29.69%] [G loss: 0.818032]\n",
      "epoch:10 step:7892[D loss: 0.443952, acc: 62.50%, op_acc: 35.16%] [G loss: 0.884058]\n",
      "epoch:10 step:7893[D loss: 0.441877, acc: 58.59%, op_acc: 33.59%] [G loss: 0.855890]\n",
      "epoch:10 step:7894[D loss: 0.422832, acc: 64.84%, op_acc: 34.38%] [G loss: 0.843754]\n",
      "epoch:10 step:7895[D loss: 0.465057, acc: 53.91%, op_acc: 28.12%] [G loss: 0.839313]\n",
      "epoch:10 step:7896[D loss: 0.430550, acc: 64.06%, op_acc: 35.16%] [G loss: 0.897876]\n",
      "epoch:10 step:7897[D loss: 0.437016, acc: 61.72%, op_acc: 41.41%] [G loss: 0.837184]\n",
      "epoch:10 step:7898[D loss: 0.444213, acc: 53.91%, op_acc: 33.59%] [G loss: 0.865220]\n",
      "epoch:10 step:7899[D loss: 0.439773, acc: 60.16%, op_acc: 34.38%] [G loss: 0.920991]\n",
      "epoch:10 step:7900[D loss: 0.415595, acc: 64.06%, op_acc: 36.72%] [G loss: 0.867353]\n",
      "##############\n",
      "[0.86413152 0.87831372 0.81266401 0.805215   0.79979323 0.8518591\n",
      " 0.91158377 0.81762998 0.80996348 0.8355425 ]\n",
      "##########\n",
      "epoch:10 step:7901[D loss: 0.452084, acc: 49.22%, op_acc: 35.94%] [G loss: 0.863384]\n",
      "epoch:10 step:7902[D loss: 0.464377, acc: 59.38%, op_acc: 35.94%] [G loss: 0.797077]\n",
      "epoch:10 step:7903[D loss: 0.437056, acc: 57.03%, op_acc: 39.06%] [G loss: 0.884813]\n",
      "epoch:10 step:7904[D loss: 0.431466, acc: 56.25%, op_acc: 32.81%] [G loss: 0.901532]\n",
      "epoch:10 step:7905[D loss: 0.413953, acc: 63.28%, op_acc: 41.41%] [G loss: 0.931317]\n",
      "epoch:10 step:7906[D loss: 0.447287, acc: 59.38%, op_acc: 32.81%] [G loss: 0.804352]\n",
      "epoch:10 step:7907[D loss: 0.425953, acc: 57.81%, op_acc: 31.25%] [G loss: 0.837083]\n",
      "epoch:10 step:7908[D loss: 0.437661, acc: 62.50%, op_acc: 29.69%] [G loss: 0.868764]\n",
      "epoch:10 step:7909[D loss: 0.439455, acc: 57.81%, op_acc: 37.50%] [G loss: 0.847601]\n",
      "epoch:10 step:7910[D loss: 0.423754, acc: 60.16%, op_acc: 37.50%] [G loss: 0.818343]\n",
      "epoch:10 step:7911[D loss: 0.447866, acc: 57.03%, op_acc: 35.16%] [G loss: 0.806654]\n",
      "epoch:10 step:7912[D loss: 0.439762, acc: 56.25%, op_acc: 35.94%] [G loss: 0.877592]\n",
      "epoch:10 step:7913[D loss: 0.462964, acc: 53.91%, op_acc: 32.81%] [G loss: 0.869217]\n",
      "epoch:10 step:7914[D loss: 0.434924, acc: 65.62%, op_acc: 31.25%] [G loss: 0.914538]\n",
      "epoch:10 step:7915[D loss: 0.449402, acc: 56.25%, op_acc: 35.94%] [G loss: 0.819964]\n",
      "epoch:10 step:7916[D loss: 0.422111, acc: 64.84%, op_acc: 35.94%] [G loss: 0.837504]\n",
      "epoch:10 step:7917[D loss: 0.434793, acc: 59.38%, op_acc: 34.38%] [G loss: 0.898244]\n",
      "epoch:10 step:7918[D loss: 0.469054, acc: 51.56%, op_acc: 35.94%] [G loss: 0.852511]\n",
      "epoch:10 step:7919[D loss: 0.433108, acc: 60.94%, op_acc: 34.38%] [G loss: 0.864463]\n",
      "epoch:10 step:7920[D loss: 0.424709, acc: 60.16%, op_acc: 37.50%] [G loss: 0.829286]\n",
      "epoch:10 step:7921[D loss: 0.459802, acc: 63.28%, op_acc: 33.59%] [G loss: 0.870411]\n",
      "epoch:10 step:7922[D loss: 0.423325, acc: 56.25%, op_acc: 40.62%] [G loss: 0.839331]\n",
      "epoch:10 step:7923[D loss: 0.461441, acc: 57.03%, op_acc: 31.25%] [G loss: 0.874684]\n",
      "epoch:10 step:7924[D loss: 0.440257, acc: 56.25%, op_acc: 43.75%] [G loss: 0.870924]\n",
      "epoch:10 step:7925[D loss: 0.435539, acc: 58.59%, op_acc: 38.28%] [G loss: 0.854758]\n",
      "epoch:10 step:7926[D loss: 0.468677, acc: 54.69%, op_acc: 33.59%] [G loss: 0.834372]\n",
      "epoch:10 step:7927[D loss: 0.469837, acc: 56.25%, op_acc: 30.47%] [G loss: 0.926765]\n",
      "epoch:10 step:7928[D loss: 0.466740, acc: 56.25%, op_acc: 32.03%] [G loss: 0.864775]\n",
      "epoch:10 step:7929[D loss: 0.441274, acc: 66.41%, op_acc: 32.03%] [G loss: 0.888334]\n",
      "epoch:10 step:7930[D loss: 0.448022, acc: 57.81%, op_acc: 32.81%] [G loss: 0.856315]\n",
      "epoch:10 step:7931[D loss: 0.429786, acc: 64.84%, op_acc: 33.59%] [G loss: 0.878906]\n",
      "epoch:10 step:7932[D loss: 0.439066, acc: 60.16%, op_acc: 38.28%] [G loss: 0.892628]\n",
      "epoch:10 step:7933[D loss: 0.442773, acc: 56.25%, op_acc: 31.25%] [G loss: 0.821790]\n",
      "epoch:10 step:7934[D loss: 0.442437, acc: 53.91%, op_acc: 41.41%] [G loss: 0.834521]\n",
      "epoch:10 step:7935[D loss: 0.473586, acc: 50.00%, op_acc: 30.47%] [G loss: 0.914192]\n",
      "epoch:10 step:7936[D loss: 0.397980, acc: 65.62%, op_acc: 35.16%] [G loss: 0.869245]\n",
      "epoch:10 step:7937[D loss: 0.467266, acc: 57.03%, op_acc: 31.25%] [G loss: 0.847127]\n",
      "epoch:10 step:7938[D loss: 0.431439, acc: 64.06%, op_acc: 34.38%] [G loss: 0.840159]\n",
      "epoch:10 step:7939[D loss: 0.468900, acc: 55.47%, op_acc: 34.38%] [G loss: 0.902647]\n",
      "epoch:10 step:7940[D loss: 0.437004, acc: 55.47%, op_acc: 35.16%] [G loss: 0.877530]\n",
      "epoch:10 step:7941[D loss: 0.449462, acc: 57.81%, op_acc: 30.47%] [G loss: 0.780813]\n",
      "epoch:10 step:7942[D loss: 0.414681, acc: 58.59%, op_acc: 39.84%] [G loss: 0.878001]\n",
      "epoch:10 step:7943[D loss: 0.445931, acc: 62.50%, op_acc: 29.69%] [G loss: 0.817431]\n",
      "epoch:10 step:7944[D loss: 0.458268, acc: 57.81%, op_acc: 29.69%] [G loss: 0.818352]\n",
      "epoch:10 step:7945[D loss: 0.470365, acc: 47.66%, op_acc: 35.16%] [G loss: 0.793358]\n",
      "epoch:10 step:7946[D loss: 0.418935, acc: 62.50%, op_acc: 40.62%] [G loss: 0.917487]\n",
      "epoch:10 step:7947[D loss: 0.471458, acc: 53.91%, op_acc: 33.59%] [G loss: 0.955774]\n",
      "epoch:10 step:7948[D loss: 0.430638, acc: 59.38%, op_acc: 36.72%] [G loss: 0.959850]\n",
      "epoch:10 step:7949[D loss: 0.419644, acc: 67.19%, op_acc: 36.72%] [G loss: 0.902270]\n",
      "epoch:10 step:7950[D loss: 0.435715, acc: 70.31%, op_acc: 36.72%] [G loss: 0.874956]\n",
      "##############\n",
      "[0.85486655 0.87009587 0.80402846 0.83334922 0.7977949  0.83954619\n",
      " 0.87574074 0.82335539 0.81942359 0.8341201 ]\n",
      "##########\n",
      "epoch:10 step:7951[D loss: 0.448822, acc: 60.16%, op_acc: 31.25%] [G loss: 0.917278]\n",
      "epoch:10 step:7952[D loss: 0.433449, acc: 58.59%, op_acc: 27.34%] [G loss: 0.927403]\n",
      "epoch:10 step:7953[D loss: 0.446341, acc: 58.59%, op_acc: 35.16%] [G loss: 0.870083]\n",
      "epoch:10 step:7954[D loss: 0.442600, acc: 53.91%, op_acc: 35.94%] [G loss: 0.912627]\n",
      "epoch:10 step:7955[D loss: 0.427729, acc: 63.28%, op_acc: 32.81%] [G loss: 0.892321]\n",
      "epoch:10 step:7956[D loss: 0.429456, acc: 64.06%, op_acc: 32.03%] [G loss: 0.860393]\n",
      "epoch:10 step:7957[D loss: 0.434223, acc: 54.69%, op_acc: 34.38%] [G loss: 0.912334]\n",
      "epoch:10 step:7958[D loss: 0.433344, acc: 62.50%, op_acc: 30.47%] [G loss: 0.915740]\n",
      "epoch:10 step:7959[D loss: 0.422452, acc: 61.72%, op_acc: 38.28%] [G loss: 0.861584]\n",
      "epoch:10 step:7960[D loss: 0.440364, acc: 58.59%, op_acc: 34.38%] [G loss: 0.888770]\n",
      "epoch:10 step:7961[D loss: 0.457273, acc: 60.16%, op_acc: 36.72%] [G loss: 0.846247]\n",
      "epoch:10 step:7962[D loss: 0.414748, acc: 62.50%, op_acc: 41.41%] [G loss: 0.924333]\n",
      "epoch:10 step:7963[D loss: 0.467466, acc: 52.34%, op_acc: 28.12%] [G loss: 0.841683]\n",
      "epoch:10 step:7964[D loss: 0.444422, acc: 56.25%, op_acc: 36.72%] [G loss: 0.806437]\n",
      "epoch:10 step:7965[D loss: 0.461294, acc: 50.00%, op_acc: 33.59%] [G loss: 0.821315]\n",
      "epoch:10 step:7966[D loss: 0.446980, acc: 56.25%, op_acc: 32.03%] [G loss: 0.835201]\n",
      "epoch:10 step:7967[D loss: 0.433614, acc: 60.94%, op_acc: 35.16%] [G loss: 0.866080]\n",
      "epoch:10 step:7968[D loss: 0.423906, acc: 57.81%, op_acc: 39.84%] [G loss: 0.942022]\n",
      "epoch:10 step:7969[D loss: 0.442650, acc: 55.47%, op_acc: 35.16%] [G loss: 0.880522]\n",
      "epoch:10 step:7970[D loss: 0.441166, acc: 66.41%, op_acc: 33.59%] [G loss: 0.869439]\n",
      "epoch:10 step:7971[D loss: 0.445992, acc: 63.28%, op_acc: 38.28%] [G loss: 0.847986]\n",
      "epoch:10 step:7972[D loss: 0.444862, acc: 56.25%, op_acc: 40.62%] [G loss: 0.837727]\n",
      "epoch:10 step:7973[D loss: 0.447300, acc: 57.03%, op_acc: 36.72%] [G loss: 0.854052]\n",
      "epoch:10 step:7974[D loss: 0.452133, acc: 63.28%, op_acc: 31.25%] [G loss: 0.878309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7975[D loss: 0.435277, acc: 58.59%, op_acc: 35.16%] [G loss: 0.902026]\n",
      "epoch:10 step:7976[D loss: 0.454399, acc: 61.72%, op_acc: 35.94%] [G loss: 0.884056]\n",
      "epoch:10 step:7977[D loss: 0.437465, acc: 57.81%, op_acc: 34.38%] [G loss: 0.917650]\n",
      "epoch:10 step:7978[D loss: 0.438357, acc: 53.91%, op_acc: 34.38%] [G loss: 0.829625]\n",
      "epoch:10 step:7979[D loss: 0.395649, acc: 64.06%, op_acc: 45.31%] [G loss: 0.841694]\n",
      "epoch:10 step:7980[D loss: 0.452940, acc: 51.56%, op_acc: 34.38%] [G loss: 0.830392]\n",
      "epoch:10 step:7981[D loss: 0.442383, acc: 67.19%, op_acc: 38.28%] [G loss: 0.869810]\n",
      "epoch:10 step:7982[D loss: 0.439646, acc: 60.16%, op_acc: 35.94%] [G loss: 0.859967]\n",
      "epoch:10 step:7983[D loss: 0.439235, acc: 57.03%, op_acc: 35.16%] [G loss: 0.879665]\n",
      "epoch:10 step:7984[D loss: 0.493750, acc: 46.09%, op_acc: 32.03%] [G loss: 0.865801]\n",
      "epoch:10 step:7985[D loss: 0.437809, acc: 69.53%, op_acc: 30.47%] [G loss: 0.873218]\n",
      "epoch:10 step:7986[D loss: 0.458125, acc: 60.16%, op_acc: 33.59%] [G loss: 0.899943]\n",
      "epoch:10 step:7987[D loss: 0.457501, acc: 44.53%, op_acc: 31.25%] [G loss: 0.783762]\n",
      "epoch:10 step:7988[D loss: 0.480633, acc: 47.66%, op_acc: 31.25%] [G loss: 0.884837]\n",
      "epoch:10 step:7989[D loss: 0.441969, acc: 54.69%, op_acc: 42.19%] [G loss: 0.778989]\n",
      "epoch:10 step:7990[D loss: 0.432488, acc: 59.38%, op_acc: 36.72%] [G loss: 0.895251]\n",
      "epoch:10 step:7991[D loss: 0.424635, acc: 57.81%, op_acc: 43.75%] [G loss: 0.851392]\n",
      "epoch:10 step:7992[D loss: 0.448875, acc: 56.25%, op_acc: 35.16%] [G loss: 0.904923]\n",
      "epoch:10 step:7993[D loss: 0.431686, acc: 63.28%, op_acc: 32.03%] [G loss: 0.936691]\n",
      "epoch:10 step:7994[D loss: 0.436813, acc: 58.59%, op_acc: 37.50%] [G loss: 0.811282]\n",
      "epoch:10 step:7995[D loss: 0.435325, acc: 64.84%, op_acc: 33.59%] [G loss: 1.007470]\n",
      "epoch:10 step:7996[D loss: 0.462940, acc: 51.56%, op_acc: 32.81%] [G loss: 0.872893]\n",
      "epoch:10 step:7997[D loss: 0.440403, acc: 57.03%, op_acc: 35.16%] [G loss: 0.853436]\n",
      "epoch:10 step:7998[D loss: 0.403364, acc: 65.62%, op_acc: 39.84%] [G loss: 0.881953]\n",
      "epoch:10 step:7999[D loss: 0.418587, acc: 67.97%, op_acc: 38.28%] [G loss: 0.890855]\n",
      "epoch:10 step:8000[D loss: 0.454861, acc: 57.81%, op_acc: 32.81%] [G loss: 0.931434]\n",
      "##############\n",
      "[0.86340264 0.84943855 0.82253417 0.80476864 0.78088363 0.81430746\n",
      " 0.88147398 0.83368426 0.82648812 0.82797182]\n",
      "##########\n",
      "epoch:10 step:8001[D loss: 0.426549, acc: 61.72%, op_acc: 40.62%] [G loss: 0.859190]\n",
      "epoch:10 step:8002[D loss: 0.444670, acc: 64.84%, op_acc: 29.69%] [G loss: 0.851312]\n",
      "epoch:10 step:8003[D loss: 0.459614, acc: 63.28%, op_acc: 30.47%] [G loss: 0.906777]\n",
      "epoch:10 step:8004[D loss: 0.427243, acc: 63.28%, op_acc: 37.50%] [G loss: 0.942753]\n",
      "epoch:10 step:8005[D loss: 0.440740, acc: 60.16%, op_acc: 38.28%] [G loss: 0.906462]\n",
      "epoch:10 step:8006[D loss: 0.437769, acc: 66.41%, op_acc: 32.81%] [G loss: 0.893734]\n",
      "epoch:10 step:8007[D loss: 0.465283, acc: 55.47%, op_acc: 35.94%] [G loss: 0.864691]\n",
      "epoch:10 step:8008[D loss: 0.458574, acc: 56.25%, op_acc: 35.16%] [G loss: 0.884032]\n",
      "epoch:10 step:8009[D loss: 0.464158, acc: 52.34%, op_acc: 32.81%] [G loss: 0.905092]\n",
      "epoch:10 step:8010[D loss: 0.425186, acc: 65.62%, op_acc: 32.81%] [G loss: 0.873552]\n",
      "epoch:10 step:8011[D loss: 0.445594, acc: 58.59%, op_acc: 35.94%] [G loss: 0.892406]\n",
      "epoch:10 step:8012[D loss: 0.429451, acc: 61.72%, op_acc: 33.59%] [G loss: 0.825948]\n",
      "epoch:10 step:8013[D loss: 0.444482, acc: 53.91%, op_acc: 33.59%] [G loss: 0.800824]\n",
      "epoch:10 step:8014[D loss: 0.461667, acc: 57.03%, op_acc: 35.94%] [G loss: 0.759742]\n",
      "epoch:10 step:8015[D loss: 0.452176, acc: 62.50%, op_acc: 31.25%] [G loss: 0.844603]\n",
      "epoch:10 step:8016[D loss: 0.453277, acc: 55.47%, op_acc: 32.81%] [G loss: 0.878272]\n",
      "epoch:10 step:8017[D loss: 0.448456, acc: 56.25%, op_acc: 33.59%] [G loss: 0.833155]\n",
      "epoch:10 step:8018[D loss: 0.483304, acc: 58.59%, op_acc: 35.94%] [G loss: 0.770832]\n",
      "epoch:10 step:8019[D loss: 0.417765, acc: 57.03%, op_acc: 39.06%] [G loss: 0.856054]\n",
      "epoch:10 step:8020[D loss: 0.459349, acc: 60.94%, op_acc: 34.38%] [G loss: 0.829042]\n",
      "epoch:10 step:8021[D loss: 0.431083, acc: 61.72%, op_acc: 41.41%] [G loss: 0.923499]\n",
      "epoch:10 step:8022[D loss: 0.429853, acc: 60.94%, op_acc: 32.03%] [G loss: 0.908085]\n",
      "epoch:10 step:8023[D loss: 0.451758, acc: 58.59%, op_acc: 37.50%] [G loss: 0.856710]\n",
      "epoch:10 step:8024[D loss: 0.472820, acc: 50.78%, op_acc: 34.38%] [G loss: 0.865806]\n",
      "epoch:10 step:8025[D loss: 0.442984, acc: 61.72%, op_acc: 35.94%] [G loss: 0.819360]\n",
      "epoch:10 step:8026[D loss: 0.451502, acc: 56.25%, op_acc: 30.47%] [G loss: 0.878209]\n",
      "epoch:10 step:8027[D loss: 0.435663, acc: 53.91%, op_acc: 32.81%] [G loss: 0.880058]\n",
      "epoch:10 step:8028[D loss: 0.425504, acc: 64.84%, op_acc: 40.62%] [G loss: 0.880469]\n",
      "epoch:10 step:8029[D loss: 0.437258, acc: 57.03%, op_acc: 35.16%] [G loss: 0.903686]\n",
      "epoch:10 step:8030[D loss: 0.436111, acc: 63.28%, op_acc: 33.59%] [G loss: 0.871672]\n",
      "epoch:10 step:8031[D loss: 0.435900, acc: 62.50%, op_acc: 34.38%] [G loss: 0.879905]\n",
      "epoch:10 step:8032[D loss: 0.452576, acc: 57.03%, op_acc: 31.25%] [G loss: 0.862770]\n",
      "epoch:10 step:8033[D loss: 0.425510, acc: 60.94%, op_acc: 36.72%] [G loss: 0.847093]\n",
      "epoch:10 step:8034[D loss: 0.462466, acc: 56.25%, op_acc: 34.38%] [G loss: 0.847510]\n",
      "epoch:10 step:8035[D loss: 0.435039, acc: 60.94%, op_acc: 38.28%] [G loss: 0.841775]\n",
      "epoch:10 step:8036[D loss: 0.443710, acc: 58.59%, op_acc: 37.50%] [G loss: 0.862107]\n",
      "epoch:10 step:8037[D loss: 0.450311, acc: 57.03%, op_acc: 32.03%] [G loss: 0.890243]\n",
      "epoch:10 step:8038[D loss: 0.402355, acc: 62.50%, op_acc: 39.06%] [G loss: 0.910829]\n",
      "epoch:10 step:8039[D loss: 0.431147, acc: 56.25%, op_acc: 35.94%] [G loss: 0.805264]\n",
      "epoch:10 step:8040[D loss: 0.471933, acc: 54.69%, op_acc: 31.25%] [G loss: 0.890751]\n",
      "epoch:10 step:8041[D loss: 0.424144, acc: 60.16%, op_acc: 34.38%] [G loss: 0.913764]\n",
      "epoch:10 step:8042[D loss: 0.428218, acc: 62.50%, op_acc: 39.06%] [G loss: 0.855126]\n",
      "epoch:10 step:8043[D loss: 0.408527, acc: 71.09%, op_acc: 34.38%] [G loss: 0.952577]\n",
      "epoch:10 step:8044[D loss: 0.485640, acc: 49.22%, op_acc: 29.69%] [G loss: 0.897040]\n",
      "epoch:10 step:8045[D loss: 0.450292, acc: 56.25%, op_acc: 29.69%] [G loss: 0.863530]\n",
      "epoch:10 step:8046[D loss: 0.452814, acc: 60.16%, op_acc: 33.59%] [G loss: 0.869812]\n",
      "epoch:10 step:8047[D loss: 0.415523, acc: 62.50%, op_acc: 37.50%] [G loss: 0.988934]\n",
      "epoch:10 step:8048[D loss: 0.455470, acc: 56.25%, op_acc: 32.03%] [G loss: 0.903675]\n",
      "epoch:10 step:8049[D loss: 0.456973, acc: 57.03%, op_acc: 32.03%] [G loss: 0.864773]\n",
      "epoch:10 step:8050[D loss: 0.467527, acc: 52.34%, op_acc: 34.38%] [G loss: 0.912153]\n",
      "##############\n",
      "[0.85120595 0.84065691 0.82462    0.81226947 0.78631089 0.80509183\n",
      " 0.89309382 0.82604106 0.82862303 0.83847439]\n",
      "##########\n",
      "epoch:10 step:8051[D loss: 0.467541, acc: 49.22%, op_acc: 34.38%] [G loss: 0.859516]\n",
      "epoch:10 step:8052[D loss: 0.437221, acc: 57.81%, op_acc: 40.62%] [G loss: 0.885826]\n",
      "epoch:10 step:8053[D loss: 0.433547, acc: 67.97%, op_acc: 32.03%] [G loss: 0.925698]\n",
      "epoch:10 step:8054[D loss: 0.484361, acc: 52.34%, op_acc: 31.25%] [G loss: 0.835068]\n",
      "epoch:10 step:8055[D loss: 0.463571, acc: 53.91%, op_acc: 33.59%] [G loss: 0.831429]\n",
      "epoch:10 step:8056[D loss: 0.447647, acc: 58.59%, op_acc: 36.72%] [G loss: 0.847019]\n",
      "epoch:10 step:8057[D loss: 0.437869, acc: 57.03%, op_acc: 39.06%] [G loss: 0.861814]\n",
      "epoch:10 step:8058[D loss: 0.469636, acc: 52.34%, op_acc: 35.16%] [G loss: 0.809507]\n",
      "epoch:10 step:8059[D loss: 0.469810, acc: 57.81%, op_acc: 32.03%] [G loss: 0.905975]\n",
      "epoch:10 step:8060[D loss: 0.443224, acc: 58.59%, op_acc: 35.16%] [G loss: 0.959503]\n",
      "epoch:10 step:8061[D loss: 0.411207, acc: 64.06%, op_acc: 38.28%] [G loss: 0.892098]\n",
      "epoch:10 step:8062[D loss: 0.437443, acc: 57.81%, op_acc: 38.28%] [G loss: 0.833077]\n",
      "epoch:10 step:8063[D loss: 0.442195, acc: 62.50%, op_acc: 32.03%] [G loss: 0.820406]\n",
      "epoch:10 step:8064[D loss: 0.475912, acc: 51.56%, op_acc: 31.25%] [G loss: 0.834046]\n",
      "epoch:10 step:8065[D loss: 0.448321, acc: 56.25%, op_acc: 32.03%] [G loss: 0.905573]\n",
      "epoch:10 step:8066[D loss: 0.411787, acc: 60.16%, op_acc: 35.16%] [G loss: 0.845989]\n",
      "epoch:10 step:8067[D loss: 0.455944, acc: 57.03%, op_acc: 33.59%] [G loss: 0.879634]\n",
      "epoch:10 step:8068[D loss: 0.428064, acc: 60.16%, op_acc: 37.50%] [G loss: 0.939636]\n",
      "epoch:10 step:8069[D loss: 0.462803, acc: 53.91%, op_acc: 34.38%] [G loss: 0.851336]\n",
      "epoch:10 step:8070[D loss: 0.448505, acc: 64.06%, op_acc: 29.69%] [G loss: 0.922221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8071[D loss: 0.428685, acc: 61.72%, op_acc: 31.25%] [G loss: 0.880481]\n",
      "epoch:10 step:8072[D loss: 0.423041, acc: 63.28%, op_acc: 32.81%] [G loss: 0.894665]\n",
      "epoch:10 step:8073[D loss: 0.439673, acc: 53.91%, op_acc: 37.50%] [G loss: 0.875884]\n",
      "epoch:10 step:8074[D loss: 0.430482, acc: 64.06%, op_acc: 32.03%] [G loss: 0.932992]\n",
      "epoch:10 step:8075[D loss: 0.428068, acc: 60.94%, op_acc: 39.84%] [G loss: 0.823904]\n",
      "epoch:10 step:8076[D loss: 0.401251, acc: 66.41%, op_acc: 37.50%] [G loss: 0.922081]\n",
      "epoch:10 step:8077[D loss: 0.459356, acc: 52.34%, op_acc: 35.94%] [G loss: 0.870257]\n",
      "epoch:10 step:8078[D loss: 0.406775, acc: 67.97%, op_acc: 39.06%] [G loss: 0.962113]\n",
      "epoch:10 step:8079[D loss: 0.430921, acc: 54.69%, op_acc: 35.16%] [G loss: 0.834226]\n",
      "epoch:10 step:8080[D loss: 0.440845, acc: 56.25%, op_acc: 39.06%] [G loss: 0.861974]\n",
      "epoch:10 step:8081[D loss: 0.439130, acc: 59.38%, op_acc: 30.47%] [G loss: 0.816345]\n",
      "epoch:10 step:8082[D loss: 0.427746, acc: 57.81%, op_acc: 35.94%] [G loss: 0.866723]\n",
      "epoch:10 step:8083[D loss: 0.436211, acc: 55.47%, op_acc: 40.62%] [G loss: 0.844582]\n",
      "epoch:10 step:8084[D loss: 0.449475, acc: 54.69%, op_acc: 30.47%] [G loss: 0.800837]\n",
      "epoch:10 step:8085[D loss: 0.441500, acc: 60.16%, op_acc: 30.47%] [G loss: 0.775701]\n",
      "epoch:10 step:8086[D loss: 0.453309, acc: 55.47%, op_acc: 35.94%] [G loss: 0.827588]\n",
      "epoch:10 step:8087[D loss: 0.428430, acc: 60.94%, op_acc: 31.25%] [G loss: 0.888009]\n",
      "epoch:10 step:8088[D loss: 0.458820, acc: 53.12%, op_acc: 35.16%] [G loss: 0.886522]\n",
      "epoch:10 step:8089[D loss: 0.426729, acc: 67.97%, op_acc: 35.16%] [G loss: 0.868058]\n",
      "epoch:10 step:8090[D loss: 0.429248, acc: 60.16%, op_acc: 35.94%] [G loss: 0.889656]\n",
      "epoch:10 step:8091[D loss: 0.451446, acc: 55.47%, op_acc: 36.72%] [G loss: 0.911401]\n",
      "epoch:10 step:8092[D loss: 0.459090, acc: 57.03%, op_acc: 36.72%] [G loss: 0.862586]\n",
      "epoch:10 step:8093[D loss: 0.441607, acc: 58.59%, op_acc: 39.06%] [G loss: 0.839682]\n",
      "epoch:10 step:8094[D loss: 0.449828, acc: 57.81%, op_acc: 34.38%] [G loss: 0.883640]\n",
      "epoch:10 step:8095[D loss: 0.411397, acc: 63.28%, op_acc: 36.72%] [G loss: 0.902476]\n",
      "epoch:10 step:8096[D loss: 0.426740, acc: 57.03%, op_acc: 36.72%] [G loss: 0.860293]\n",
      "epoch:10 step:8097[D loss: 0.470624, acc: 53.91%, op_acc: 35.16%] [G loss: 0.924068]\n",
      "epoch:10 step:8098[D loss: 0.435353, acc: 60.16%, op_acc: 33.59%] [G loss: 0.814448]\n",
      "epoch:10 step:8099[D loss: 0.452703, acc: 61.72%, op_acc: 31.25%] [G loss: 0.825860]\n",
      "epoch:10 step:8100[D loss: 0.430916, acc: 60.16%, op_acc: 38.28%] [G loss: 0.905143]\n",
      "##############\n",
      "[0.84361743 0.85231104 0.81369181 0.79728084 0.79870028 0.83388125\n",
      " 0.87890953 0.83290411 0.78958079 0.84166666]\n",
      "##########\n",
      "epoch:10 step:8101[D loss: 0.427795, acc: 60.94%, op_acc: 36.72%] [G loss: 0.779795]\n",
      "epoch:10 step:8102[D loss: 0.483443, acc: 50.78%, op_acc: 28.91%] [G loss: 0.791549]\n",
      "epoch:10 step:8103[D loss: 0.447272, acc: 58.59%, op_acc: 35.16%] [G loss: 0.858393]\n",
      "epoch:10 step:8104[D loss: 0.439200, acc: 64.06%, op_acc: 32.03%] [G loss: 0.891461]\n",
      "epoch:10 step:8105[D loss: 0.437865, acc: 55.47%, op_acc: 37.50%] [G loss: 0.790181]\n",
      "epoch:10 step:8106[D loss: 0.419947, acc: 59.38%, op_acc: 36.72%] [G loss: 0.906957]\n",
      "epoch:10 step:8107[D loss: 0.466053, acc: 55.47%, op_acc: 31.25%] [G loss: 0.873784]\n",
      "epoch:10 step:8108[D loss: 0.423250, acc: 66.41%, op_acc: 33.59%] [G loss: 0.914997]\n",
      "epoch:10 step:8109[D loss: 0.440594, acc: 61.72%, op_acc: 32.81%] [G loss: 0.880696]\n",
      "epoch:10 step:8110[D loss: 0.485719, acc: 46.09%, op_acc: 32.81%] [G loss: 0.836530]\n",
      "epoch:10 step:8111[D loss: 0.460689, acc: 55.47%, op_acc: 33.59%] [G loss: 0.909024]\n",
      "epoch:10 step:8112[D loss: 0.424761, acc: 64.06%, op_acc: 35.16%] [G loss: 0.852202]\n",
      "epoch:10 step:8113[D loss: 0.467180, acc: 52.34%, op_acc: 29.69%] [G loss: 0.788040]\n",
      "epoch:10 step:8114[D loss: 0.442358, acc: 53.12%, op_acc: 34.38%] [G loss: 0.844768]\n",
      "epoch:10 step:8115[D loss: 0.431669, acc: 62.50%, op_acc: 39.06%] [G loss: 0.906412]\n",
      "epoch:10 step:8116[D loss: 0.482375, acc: 54.69%, op_acc: 28.91%] [G loss: 0.880780]\n",
      "epoch:10 step:8117[D loss: 0.413941, acc: 63.28%, op_acc: 34.38%] [G loss: 0.901659]\n",
      "epoch:10 step:8118[D loss: 0.467456, acc: 55.47%, op_acc: 32.03%] [G loss: 0.865921]\n",
      "epoch:10 step:8119[D loss: 0.471776, acc: 53.91%, op_acc: 29.69%] [G loss: 0.876242]\n",
      "epoch:10 step:8120[D loss: 0.420172, acc: 64.06%, op_acc: 33.59%] [G loss: 0.901166]\n",
      "epoch:10 step:8121[D loss: 0.474370, acc: 47.66%, op_acc: 32.81%] [G loss: 0.917932]\n",
      "epoch:10 step:8122[D loss: 0.443133, acc: 53.91%, op_acc: 35.16%] [G loss: 0.832052]\n",
      "epoch:10 step:8123[D loss: 0.446527, acc: 60.94%, op_acc: 35.94%] [G loss: 0.907890]\n",
      "epoch:10 step:8124[D loss: 0.474245, acc: 51.56%, op_acc: 32.03%] [G loss: 0.861946]\n",
      "epoch:10 step:8125[D loss: 0.462571, acc: 52.34%, op_acc: 35.94%] [G loss: 0.840182]\n",
      "epoch:10 step:8126[D loss: 0.440794, acc: 60.16%, op_acc: 32.03%] [G loss: 0.787730]\n",
      "epoch:10 step:8127[D loss: 0.447580, acc: 59.38%, op_acc: 34.38%] [G loss: 0.811263]\n",
      "epoch:10 step:8128[D loss: 0.454912, acc: 57.81%, op_acc: 28.12%] [G loss: 0.825785]\n",
      "epoch:10 step:8129[D loss: 0.441883, acc: 53.12%, op_acc: 36.72%] [G loss: 0.802287]\n",
      "epoch:10 step:8130[D loss: 0.469680, acc: 56.25%, op_acc: 32.81%] [G loss: 0.864735]\n",
      "epoch:10 step:8131[D loss: 0.429244, acc: 64.84%, op_acc: 37.50%] [G loss: 0.917642]\n",
      "epoch:10 step:8132[D loss: 0.425694, acc: 59.38%, op_acc: 38.28%] [G loss: 0.857085]\n",
      "epoch:10 step:8133[D loss: 0.468080, acc: 57.03%, op_acc: 29.69%] [G loss: 0.786767]\n",
      "epoch:10 step:8134[D loss: 0.440954, acc: 66.41%, op_acc: 34.38%] [G loss: 0.850903]\n",
      "epoch:10 step:8135[D loss: 0.423120, acc: 62.50%, op_acc: 35.94%] [G loss: 0.846052]\n",
      "epoch:10 step:8136[D loss: 0.441442, acc: 55.47%, op_acc: 32.81%] [G loss: 0.859259]\n",
      "epoch:10 step:8137[D loss: 0.422143, acc: 62.50%, op_acc: 30.47%] [G loss: 0.880369]\n",
      "epoch:10 step:8138[D loss: 0.460642, acc: 51.56%, op_acc: 30.47%] [G loss: 0.879298]\n",
      "epoch:10 step:8139[D loss: 0.429054, acc: 57.81%, op_acc: 36.72%] [G loss: 0.869962]\n",
      "epoch:10 step:8140[D loss: 0.427640, acc: 64.06%, op_acc: 32.81%] [G loss: 0.907662]\n",
      "epoch:10 step:8141[D loss: 0.467998, acc: 54.69%, op_acc: 36.72%] [G loss: 0.827345]\n",
      "epoch:10 step:8142[D loss: 0.415280, acc: 63.28%, op_acc: 38.28%] [G loss: 0.872004]\n",
      "epoch:10 step:8143[D loss: 0.427925, acc: 63.28%, op_acc: 35.94%] [G loss: 0.916728]\n",
      "epoch:10 step:8144[D loss: 0.434632, acc: 54.69%, op_acc: 41.41%] [G loss: 0.916248]\n",
      "epoch:10 step:8145[D loss: 0.449643, acc: 58.59%, op_acc: 34.38%] [G loss: 0.844079]\n",
      "epoch:10 step:8146[D loss: 0.457823, acc: 56.25%, op_acc: 30.47%] [G loss: 0.873481]\n",
      "epoch:10 step:8147[D loss: 0.472394, acc: 53.12%, op_acc: 34.38%] [G loss: 0.757178]\n",
      "epoch:10 step:8148[D loss: 0.400618, acc: 66.41%, op_acc: 39.06%] [G loss: 0.801269]\n",
      "epoch:10 step:8149[D loss: 0.453797, acc: 53.91%, op_acc: 33.59%] [G loss: 0.838045]\n",
      "epoch:10 step:8150[D loss: 0.443443, acc: 58.59%, op_acc: 34.38%] [G loss: 0.850034]\n",
      "##############\n",
      "[0.86201322 0.86955979 0.8124369  0.81358009 0.81255928 0.84017671\n",
      " 0.86931187 0.84740745 0.83102033 0.83634683]\n",
      "##########\n",
      "epoch:10 step:8151[D loss: 0.449476, acc: 60.16%, op_acc: 33.59%] [G loss: 0.855072]\n",
      "epoch:10 step:8152[D loss: 0.477192, acc: 48.44%, op_acc: 33.59%] [G loss: 0.812404]\n",
      "epoch:10 step:8153[D loss: 0.471995, acc: 53.91%, op_acc: 33.59%] [G loss: 0.893849]\n",
      "epoch:10 step:8154[D loss: 0.426320, acc: 58.59%, op_acc: 37.50%] [G loss: 0.875587]\n",
      "epoch:10 step:8155[D loss: 0.411346, acc: 67.97%, op_acc: 35.94%] [G loss: 0.926656]\n",
      "epoch:10 step:8156[D loss: 0.445543, acc: 59.38%, op_acc: 33.59%] [G loss: 0.834473]\n",
      "epoch:10 step:8157[D loss: 0.427041, acc: 60.94%, op_acc: 33.59%] [G loss: 0.883260]\n",
      "epoch:10 step:8158[D loss: 0.442182, acc: 63.28%, op_acc: 33.59%] [G loss: 0.884949]\n",
      "epoch:10 step:8159[D loss: 0.457042, acc: 57.03%, op_acc: 32.81%] [G loss: 0.918119]\n",
      "epoch:10 step:8160[D loss: 0.442745, acc: 62.50%, op_acc: 32.81%] [G loss: 0.873841]\n",
      "epoch:10 step:8161[D loss: 0.470041, acc: 53.12%, op_acc: 35.16%] [G loss: 0.847418]\n",
      "epoch:10 step:8162[D loss: 0.423962, acc: 69.53%, op_acc: 31.25%] [G loss: 0.839298]\n",
      "epoch:10 step:8163[D loss: 0.409211, acc: 62.50%, op_acc: 40.62%] [G loss: 0.844529]\n",
      "epoch:10 step:8164[D loss: 0.448829, acc: 57.03%, op_acc: 32.03%] [G loss: 0.870008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8165[D loss: 0.435515, acc: 57.81%, op_acc: 32.81%] [G loss: 0.882361]\n",
      "epoch:10 step:8166[D loss: 0.439000, acc: 58.59%, op_acc: 36.72%] [G loss: 0.863339]\n",
      "epoch:10 step:8167[D loss: 0.455691, acc: 60.94%, op_acc: 34.38%] [G loss: 0.867516]\n",
      "epoch:10 step:8168[D loss: 0.459817, acc: 60.94%, op_acc: 32.03%] [G loss: 0.870149]\n",
      "epoch:10 step:8169[D loss: 0.455811, acc: 57.03%, op_acc: 32.81%] [G loss: 0.833283]\n",
      "epoch:10 step:8170[D loss: 0.441153, acc: 60.94%, op_acc: 38.28%] [G loss: 0.832323]\n",
      "epoch:10 step:8171[D loss: 0.432704, acc: 60.16%, op_acc: 33.59%] [G loss: 0.896062]\n",
      "epoch:10 step:8172[D loss: 0.406442, acc: 60.94%, op_acc: 41.41%] [G loss: 0.837452]\n",
      "epoch:10 step:8173[D loss: 0.451304, acc: 64.06%, op_acc: 32.81%] [G loss: 0.882911]\n",
      "epoch:10 step:8174[D loss: 0.467287, acc: 49.22%, op_acc: 39.84%] [G loss: 0.856156]\n",
      "epoch:10 step:8175[D loss: 0.431776, acc: 50.78%, op_acc: 39.06%] [G loss: 0.802584]\n",
      "epoch:10 step:8176[D loss: 0.454844, acc: 55.47%, op_acc: 35.16%] [G loss: 0.846730]\n",
      "epoch:10 step:8177[D loss: 0.456433, acc: 57.03%, op_acc: 33.59%] [G loss: 0.866957]\n",
      "epoch:10 step:8178[D loss: 0.482900, acc: 60.16%, op_acc: 33.59%] [G loss: 0.908361]\n",
      "epoch:10 step:8179[D loss: 0.443821, acc: 60.94%, op_acc: 37.50%] [G loss: 0.935764]\n",
      "epoch:10 step:8180[D loss: 0.459102, acc: 55.47%, op_acc: 32.81%] [G loss: 0.820695]\n",
      "epoch:10 step:8181[D loss: 0.402330, acc: 58.59%, op_acc: 46.09%] [G loss: 0.869138]\n",
      "epoch:10 step:8182[D loss: 0.442652, acc: 54.69%, op_acc: 34.38%] [G loss: 0.860513]\n",
      "epoch:10 step:8183[D loss: 0.440839, acc: 57.81%, op_acc: 32.81%] [G loss: 0.853673]\n",
      "epoch:10 step:8184[D loss: 0.445729, acc: 58.59%, op_acc: 35.16%] [G loss: 0.832932]\n",
      "epoch:10 step:8185[D loss: 0.447788, acc: 57.81%, op_acc: 30.47%] [G loss: 0.905358]\n",
      "epoch:10 step:8186[D loss: 0.434504, acc: 55.47%, op_acc: 36.72%] [G loss: 0.828564]\n",
      "epoch:10 step:8187[D loss: 0.432394, acc: 64.06%, op_acc: 35.94%] [G loss: 0.871504]\n",
      "epoch:10 step:8188[D loss: 0.448940, acc: 58.59%, op_acc: 35.16%] [G loss: 0.932560]\n",
      "epoch:10 step:8189[D loss: 0.425239, acc: 61.72%, op_acc: 38.28%] [G loss: 0.830318]\n",
      "epoch:10 step:8190[D loss: 0.478158, acc: 52.34%, op_acc: 35.94%] [G loss: 0.810240]\n",
      "epoch:10 step:8191[D loss: 0.425519, acc: 62.50%, op_acc: 35.94%] [G loss: 0.900358]\n",
      "epoch:10 step:8192[D loss: 0.430051, acc: 60.16%, op_acc: 36.72%] [G loss: 0.959156]\n",
      "epoch:10 step:8193[D loss: 0.414778, acc: 64.84%, op_acc: 37.50%] [G loss: 0.857026]\n",
      "epoch:10 step:8194[D loss: 0.442828, acc: 58.59%, op_acc: 33.59%] [G loss: 0.874878]\n",
      "epoch:10 step:8195[D loss: 0.424628, acc: 62.50%, op_acc: 34.38%] [G loss: 0.784433]\n",
      "epoch:10 step:8196[D loss: 0.426358, acc: 64.06%, op_acc: 38.28%] [G loss: 0.913637]\n",
      "epoch:10 step:8197[D loss: 0.471570, acc: 49.22%, op_acc: 32.03%] [G loss: 0.770498]\n",
      "epoch:10 step:8198[D loss: 0.459252, acc: 53.91%, op_acc: 33.59%] [G loss: 0.843762]\n",
      "epoch:10 step:8199[D loss: 0.448550, acc: 53.12%, op_acc: 37.50%] [G loss: 0.892626]\n",
      "epoch:10 step:8200[D loss: 0.418635, acc: 60.16%, op_acc: 36.72%] [G loss: 0.847267]\n",
      "##############\n",
      "[0.85660722 0.86515803 0.79892203 0.80965731 0.78534038 0.82292232\n",
      " 0.909539   0.83546991 0.83376732 0.83404493]\n",
      "##########\n",
      "epoch:10 step:8201[D loss: 0.423793, acc: 57.81%, op_acc: 37.50%] [G loss: 0.774903]\n",
      "epoch:10 step:8202[D loss: 0.403355, acc: 66.41%, op_acc: 42.97%] [G loss: 0.789104]\n",
      "epoch:10 step:8203[D loss: 0.465788, acc: 54.69%, op_acc: 33.59%] [G loss: 0.791068]\n",
      "epoch:10 step:8204[D loss: 0.423677, acc: 59.38%, op_acc: 32.81%] [G loss: 0.854444]\n",
      "epoch:10 step:8205[D loss: 0.454190, acc: 52.34%, op_acc: 29.69%] [G loss: 0.832304]\n",
      "epoch:10 step:8206[D loss: 0.435627, acc: 60.94%, op_acc: 35.94%] [G loss: 0.864000]\n",
      "epoch:10 step:8207[D loss: 0.434103, acc: 59.38%, op_acc: 39.84%] [G loss: 0.803081]\n",
      "epoch:10 step:8208[D loss: 0.464395, acc: 54.69%, op_acc: 30.47%] [G loss: 0.829113]\n",
      "epoch:10 step:8209[D loss: 0.439626, acc: 57.03%, op_acc: 42.97%] [G loss: 0.821302]\n",
      "epoch:10 step:8210[D loss: 0.439631, acc: 64.84%, op_acc: 34.38%] [G loss: 0.842671]\n",
      "epoch:10 step:8211[D loss: 0.443114, acc: 55.47%, op_acc: 33.59%] [G loss: 0.886801]\n",
      "epoch:10 step:8212[D loss: 0.441949, acc: 64.06%, op_acc: 32.81%] [G loss: 0.899961]\n",
      "epoch:10 step:8213[D loss: 0.443331, acc: 61.72%, op_acc: 35.16%] [G loss: 0.959477]\n",
      "epoch:10 step:8214[D loss: 0.423816, acc: 60.94%, op_acc: 38.28%] [G loss: 0.885415]\n",
      "epoch:10 step:8215[D loss: 0.447966, acc: 60.94%, op_acc: 36.72%] [G loss: 0.944285]\n",
      "epoch:10 step:8216[D loss: 0.454544, acc: 55.47%, op_acc: 34.38%] [G loss: 0.780633]\n",
      "epoch:10 step:8217[D loss: 0.442715, acc: 60.16%, op_acc: 36.72%] [G loss: 0.837412]\n",
      "epoch:10 step:8218[D loss: 0.418596, acc: 58.59%, op_acc: 38.28%] [G loss: 0.907585]\n",
      "epoch:10 step:8219[D loss: 0.432588, acc: 62.50%, op_acc: 35.16%] [G loss: 0.901491]\n",
      "epoch:10 step:8220[D loss: 0.424401, acc: 60.16%, op_acc: 39.06%] [G loss: 0.898447]\n",
      "epoch:10 step:8221[D loss: 0.453654, acc: 57.03%, op_acc: 37.50%] [G loss: 0.875698]\n",
      "epoch:10 step:8222[D loss: 0.423504, acc: 57.03%, op_acc: 39.84%] [G loss: 0.846759]\n",
      "epoch:10 step:8223[D loss: 0.442303, acc: 60.94%, op_acc: 35.94%] [G loss: 0.892480]\n",
      "epoch:10 step:8224[D loss: 0.436013, acc: 63.28%, op_acc: 33.59%] [G loss: 0.929392]\n",
      "epoch:10 step:8225[D loss: 0.429292, acc: 60.94%, op_acc: 36.72%] [G loss: 0.876752]\n",
      "epoch:10 step:8226[D loss: 0.428883, acc: 64.84%, op_acc: 34.38%] [G loss: 0.915987]\n",
      "epoch:10 step:8227[D loss: 0.448786, acc: 57.03%, op_acc: 32.03%] [G loss: 0.899889]\n",
      "epoch:10 step:8228[D loss: 0.420112, acc: 63.28%, op_acc: 36.72%] [G loss: 0.996852]\n",
      "epoch:10 step:8229[D loss: 0.445912, acc: 57.81%, op_acc: 35.94%] [G loss: 0.875161]\n",
      "epoch:10 step:8230[D loss: 0.441252, acc: 60.16%, op_acc: 35.16%] [G loss: 0.915424]\n",
      "epoch:10 step:8231[D loss: 0.441105, acc: 60.16%, op_acc: 34.38%] [G loss: 0.881293]\n",
      "epoch:10 step:8232[D loss: 0.435963, acc: 53.12%, op_acc: 36.72%] [G loss: 0.901119]\n",
      "epoch:10 step:8233[D loss: 0.429125, acc: 63.28%, op_acc: 34.38%] [G loss: 0.900910]\n",
      "epoch:10 step:8234[D loss: 0.433312, acc: 64.84%, op_acc: 35.16%] [G loss: 0.932753]\n",
      "epoch:10 step:8235[D loss: 0.441175, acc: 62.50%, op_acc: 34.38%] [G loss: 0.875912]\n",
      "epoch:10 step:8236[D loss: 0.482341, acc: 52.34%, op_acc: 32.03%] [G loss: 0.938275]\n",
      "epoch:10 step:8237[D loss: 0.423648, acc: 66.41%, op_acc: 38.28%] [G loss: 0.955207]\n",
      "epoch:10 step:8238[D loss: 0.461954, acc: 49.22%, op_acc: 37.50%] [G loss: 0.906647]\n",
      "epoch:10 step:8239[D loss: 0.438301, acc: 64.06%, op_acc: 35.16%] [G loss: 0.881761]\n",
      "epoch:10 step:8240[D loss: 0.435531, acc: 60.94%, op_acc: 35.16%] [G loss: 0.864804]\n",
      "epoch:10 step:8241[D loss: 0.479200, acc: 51.56%, op_acc: 28.91%] [G loss: 0.882716]\n",
      "epoch:10 step:8242[D loss: 0.412212, acc: 62.50%, op_acc: 39.84%] [G loss: 0.892333]\n",
      "epoch:10 step:8243[D loss: 0.440299, acc: 60.16%, op_acc: 34.38%] [G loss: 0.861470]\n",
      "epoch:10 step:8244[D loss: 0.441198, acc: 61.72%, op_acc: 35.94%] [G loss: 0.843701]\n",
      "epoch:10 step:8245[D loss: 0.452084, acc: 49.22%, op_acc: 40.62%] [G loss: 0.858344]\n",
      "epoch:10 step:8246[D loss: 0.478855, acc: 52.34%, op_acc: 39.06%] [G loss: 0.863254]\n",
      "epoch:10 step:8247[D loss: 0.433410, acc: 55.47%, op_acc: 35.94%] [G loss: 0.906714]\n",
      "epoch:10 step:8248[D loss: 0.434059, acc: 57.81%, op_acc: 35.94%] [G loss: 0.861010]\n",
      "epoch:10 step:8249[D loss: 0.427561, acc: 56.25%, op_acc: 39.06%] [G loss: 0.826013]\n",
      "epoch:10 step:8250[D loss: 0.455912, acc: 58.59%, op_acc: 35.16%] [G loss: 0.881601]\n",
      "##############\n",
      "[0.83593257 0.85474085 0.79593118 0.79919676 0.79301499 0.81130848\n",
      " 0.87775927 0.83308766 0.80986288 0.81648303]\n",
      "##########\n",
      "epoch:10 step:8251[D loss: 0.447918, acc: 63.28%, op_acc: 32.03%] [G loss: 0.903862]\n",
      "epoch:10 step:8252[D loss: 0.411182, acc: 71.09%, op_acc: 35.16%] [G loss: 0.915855]\n",
      "epoch:10 step:8253[D loss: 0.459199, acc: 57.81%, op_acc: 32.03%] [G loss: 0.884505]\n",
      "epoch:10 step:8254[D loss: 0.424691, acc: 67.97%, op_acc: 34.38%] [G loss: 0.874825]\n",
      "epoch:10 step:8255[D loss: 0.447706, acc: 60.16%, op_acc: 32.81%] [G loss: 0.849379]\n",
      "epoch:10 step:8256[D loss: 0.445333, acc: 60.16%, op_acc: 32.03%] [G loss: 0.880953]\n",
      "epoch:10 step:8257[D loss: 0.437879, acc: 64.84%, op_acc: 28.12%] [G loss: 0.860125]\n",
      "epoch:10 step:8258[D loss: 0.455681, acc: 57.81%, op_acc: 33.59%] [G loss: 0.872587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8259[D loss: 0.414364, acc: 70.31%, op_acc: 32.81%] [G loss: 0.917870]\n",
      "epoch:10 step:8260[D loss: 0.430009, acc: 67.19%, op_acc: 35.16%] [G loss: 0.916986]\n",
      "epoch:10 step:8261[D loss: 0.457760, acc: 52.34%, op_acc: 39.84%] [G loss: 0.892377]\n",
      "epoch:10 step:8262[D loss: 0.425202, acc: 59.38%, op_acc: 37.50%] [G loss: 0.870966]\n",
      "epoch:10 step:8263[D loss: 0.437359, acc: 57.03%, op_acc: 37.50%] [G loss: 0.852812]\n",
      "epoch:10 step:8264[D loss: 0.427102, acc: 59.38%, op_acc: 40.62%] [G loss: 0.788520]\n",
      "epoch:10 step:8265[D loss: 0.454105, acc: 59.38%, op_acc: 39.06%] [G loss: 0.923373]\n",
      "epoch:10 step:8266[D loss: 0.442060, acc: 60.16%, op_acc: 36.72%] [G loss: 0.891308]\n",
      "epoch:10 step:8267[D loss: 0.444802, acc: 56.25%, op_acc: 31.25%] [G loss: 0.880355]\n",
      "epoch:10 step:8268[D loss: 0.416462, acc: 63.28%, op_acc: 40.62%] [G loss: 0.907851]\n",
      "epoch:10 step:8269[D loss: 0.435121, acc: 53.91%, op_acc: 35.94%] [G loss: 0.857034]\n",
      "epoch:10 step:8270[D loss: 0.465513, acc: 52.34%, op_acc: 36.72%] [G loss: 0.842125]\n",
      "epoch:10 step:8271[D loss: 0.447400, acc: 55.47%, op_acc: 30.47%] [G loss: 0.888569]\n",
      "epoch:10 step:8272[D loss: 0.444931, acc: 56.25%, op_acc: 33.59%] [G loss: 0.926699]\n",
      "epoch:10 step:8273[D loss: 0.467552, acc: 52.34%, op_acc: 35.16%] [G loss: 0.793927]\n",
      "epoch:10 step:8274[D loss: 0.437696, acc: 65.62%, op_acc: 31.25%] [G loss: 0.854445]\n",
      "epoch:10 step:8275[D loss: 0.430895, acc: 60.16%, op_acc: 42.19%] [G loss: 0.997767]\n",
      "epoch:10 step:8276[D loss: 0.413419, acc: 63.28%, op_acc: 39.84%] [G loss: 0.926991]\n",
      "epoch:10 step:8277[D loss: 0.432784, acc: 62.50%, op_acc: 34.38%] [G loss: 0.847369]\n",
      "epoch:10 step:8278[D loss: 0.417585, acc: 64.84%, op_acc: 41.41%] [G loss: 0.869623]\n",
      "epoch:10 step:8279[D loss: 0.387029, acc: 66.41%, op_acc: 38.28%] [G loss: 0.908413]\n",
      "epoch:10 step:8280[D loss: 0.430026, acc: 59.38%, op_acc: 35.94%] [G loss: 0.870607]\n",
      "epoch:10 step:8281[D loss: 0.455048, acc: 53.12%, op_acc: 29.69%] [G loss: 0.887834]\n",
      "epoch:10 step:8282[D loss: 0.470652, acc: 53.12%, op_acc: 28.91%] [G loss: 0.879507]\n",
      "epoch:10 step:8283[D loss: 0.429349, acc: 52.34%, op_acc: 38.28%] [G loss: 0.882696]\n",
      "epoch:10 step:8284[D loss: 0.451296, acc: 59.38%, op_acc: 33.59%] [G loss: 0.902581]\n",
      "epoch:10 step:8285[D loss: 0.446757, acc: 50.00%, op_acc: 33.59%] [G loss: 0.978945]\n",
      "epoch:10 step:8286[D loss: 0.458173, acc: 55.47%, op_acc: 31.25%] [G loss: 0.871999]\n",
      "epoch:10 step:8287[D loss: 0.422174, acc: 60.16%, op_acc: 33.59%] [G loss: 0.875905]\n",
      "epoch:10 step:8288[D loss: 0.436571, acc: 55.47%, op_acc: 36.72%] [G loss: 0.933078]\n",
      "epoch:10 step:8289[D loss: 0.450964, acc: 53.91%, op_acc: 32.81%] [G loss: 0.902193]\n",
      "epoch:10 step:8290[D loss: 0.466635, acc: 54.69%, op_acc: 31.25%] [G loss: 0.881986]\n",
      "epoch:10 step:8291[D loss: 0.499972, acc: 52.34%, op_acc: 29.69%] [G loss: 0.890542]\n",
      "epoch:10 step:8292[D loss: 0.439652, acc: 62.50%, op_acc: 35.16%] [G loss: 0.882784]\n",
      "epoch:10 step:8293[D loss: 0.458376, acc: 57.81%, op_acc: 28.91%] [G loss: 0.789330]\n",
      "epoch:10 step:8294[D loss: 0.457178, acc: 48.44%, op_acc: 38.28%] [G loss: 0.851267]\n",
      "epoch:10 step:8295[D loss: 0.460924, acc: 52.34%, op_acc: 30.47%] [G loss: 0.834719]\n",
      "epoch:10 step:8296[D loss: 0.429108, acc: 62.50%, op_acc: 38.28%] [G loss: 0.843814]\n",
      "epoch:10 step:8297[D loss: 0.425430, acc: 64.84%, op_acc: 33.59%] [G loss: 0.925046]\n",
      "epoch:10 step:8298[D loss: 0.470199, acc: 51.56%, op_acc: 28.12%] [G loss: 0.874575]\n",
      "epoch:10 step:8299[D loss: 0.414264, acc: 64.84%, op_acc: 42.97%] [G loss: 0.854814]\n",
      "epoch:10 step:8300[D loss: 0.420146, acc: 63.28%, op_acc: 35.94%] [G loss: 0.892288]\n",
      "##############\n",
      "[0.86704865 0.85378121 0.80849722 0.80660257 0.80243593 0.84286709\n",
      " 0.86808196 0.84684929 0.81585743 0.83215557]\n",
      "##########\n",
      "epoch:10 step:8301[D loss: 0.459788, acc: 53.91%, op_acc: 32.81%] [G loss: 0.831706]\n",
      "epoch:10 step:8302[D loss: 0.420046, acc: 62.50%, op_acc: 36.72%] [G loss: 0.891711]\n",
      "epoch:10 step:8303[D loss: 0.457060, acc: 60.16%, op_acc: 29.69%] [G loss: 0.874167]\n",
      "epoch:10 step:8304[D loss: 0.447234, acc: 56.25%, op_acc: 37.50%] [G loss: 0.879299]\n",
      "epoch:10 step:8305[D loss: 0.430676, acc: 64.06%, op_acc: 42.19%] [G loss: 0.859287]\n",
      "epoch:10 step:8306[D loss: 0.445797, acc: 56.25%, op_acc: 32.81%] [G loss: 0.833898]\n",
      "epoch:10 step:8307[D loss: 0.450039, acc: 60.16%, op_acc: 32.03%] [G loss: 0.855823]\n",
      "epoch:10 step:8308[D loss: 0.464866, acc: 67.19%, op_acc: 31.25%] [G loss: 0.877038]\n",
      "epoch:10 step:8309[D loss: 0.454204, acc: 58.59%, op_acc: 33.59%] [G loss: 0.922756]\n",
      "epoch:10 step:8310[D loss: 0.423923, acc: 64.06%, op_acc: 39.84%] [G loss: 0.886491]\n",
      "epoch:10 step:8311[D loss: 0.444683, acc: 62.50%, op_acc: 30.47%] [G loss: 0.896022]\n",
      "epoch:10 step:8312[D loss: 0.434135, acc: 57.03%, op_acc: 37.50%] [G loss: 0.880610]\n",
      "epoch:10 step:8313[D loss: 0.453501, acc: 55.47%, op_acc: 31.25%] [G loss: 0.774465]\n",
      "epoch:10 step:8314[D loss: 0.433229, acc: 57.81%, op_acc: 38.28%] [G loss: 0.885129]\n",
      "epoch:10 step:8315[D loss: 0.455883, acc: 56.25%, op_acc: 30.47%] [G loss: 0.823979]\n",
      "epoch:10 step:8316[D loss: 0.477637, acc: 51.56%, op_acc: 30.47%] [G loss: 0.890763]\n",
      "epoch:10 step:8317[D loss: 0.427881, acc: 62.50%, op_acc: 39.84%] [G loss: 0.865373]\n",
      "epoch:10 step:8318[D loss: 0.434288, acc: 57.81%, op_acc: 32.03%] [G loss: 0.905937]\n",
      "epoch:10 step:8319[D loss: 0.483634, acc: 50.00%, op_acc: 31.25%] [G loss: 0.793896]\n",
      "epoch:10 step:8320[D loss: 0.462163, acc: 53.12%, op_acc: 35.16%] [G loss: 0.803960]\n",
      "epoch:10 step:8321[D loss: 0.460020, acc: 51.56%, op_acc: 32.03%] [G loss: 0.867727]\n",
      "epoch:10 step:8322[D loss: 0.435254, acc: 56.25%, op_acc: 39.84%] [G loss: 0.875311]\n",
      "epoch:10 step:8323[D loss: 0.456966, acc: 56.25%, op_acc: 29.69%] [G loss: 0.886184]\n",
      "epoch:10 step:8324[D loss: 0.443233, acc: 55.47%, op_acc: 35.16%] [G loss: 0.894898]\n",
      "epoch:10 step:8325[D loss: 0.455845, acc: 58.59%, op_acc: 32.81%] [G loss: 0.845562]\n",
      "epoch:10 step:8326[D loss: 0.437723, acc: 60.94%, op_acc: 39.06%] [G loss: 0.914609]\n",
      "epoch:10 step:8327[D loss: 0.452128, acc: 57.03%, op_acc: 30.47%] [G loss: 0.869234]\n",
      "epoch:10 step:8328[D loss: 0.408481, acc: 64.84%, op_acc: 35.94%] [G loss: 0.914957]\n",
      "epoch:10 step:8329[D loss: 0.448798, acc: 57.03%, op_acc: 34.38%] [G loss: 0.962607]\n",
      "epoch:10 step:8330[D loss: 0.444919, acc: 57.81%, op_acc: 38.28%] [G loss: 0.933595]\n",
      "epoch:10 step:8331[D loss: 0.449850, acc: 58.59%, op_acc: 36.72%] [G loss: 0.897950]\n",
      "epoch:10 step:8332[D loss: 0.454849, acc: 57.81%, op_acc: 28.91%] [G loss: 0.825228]\n",
      "epoch:10 step:8333[D loss: 0.443675, acc: 57.03%, op_acc: 30.47%] [G loss: 0.936430]\n",
      "epoch:10 step:8334[D loss: 0.452896, acc: 62.50%, op_acc: 30.47%] [G loss: 0.875845]\n",
      "epoch:10 step:8335[D loss: 0.407092, acc: 74.22%, op_acc: 36.72%] [G loss: 0.808045]\n",
      "epoch:10 step:8336[D loss: 0.454102, acc: 57.03%, op_acc: 26.56%] [G loss: 0.905587]\n",
      "epoch:10 step:8337[D loss: 0.441934, acc: 64.06%, op_acc: 31.25%] [G loss: 0.881576]\n",
      "epoch:10 step:8338[D loss: 0.428828, acc: 64.84%, op_acc: 35.16%] [G loss: 0.885312]\n",
      "epoch:10 step:8339[D loss: 0.450736, acc: 56.25%, op_acc: 32.81%] [G loss: 0.860401]\n",
      "epoch:10 step:8340[D loss: 0.452944, acc: 61.72%, op_acc: 29.69%] [G loss: 0.809127]\n",
      "epoch:10 step:8341[D loss: 0.442509, acc: 65.62%, op_acc: 36.72%] [G loss: 0.882837]\n",
      "epoch:10 step:8342[D loss: 0.431045, acc: 60.94%, op_acc: 36.72%] [G loss: 0.937093]\n",
      "epoch:10 step:8343[D loss: 0.433942, acc: 62.50%, op_acc: 35.94%] [G loss: 0.871844]\n",
      "epoch:10 step:8344[D loss: 0.429488, acc: 64.06%, op_acc: 35.94%] [G loss: 0.789542]\n",
      "epoch:10 step:8345[D loss: 0.448766, acc: 54.69%, op_acc: 33.59%] [G loss: 0.810630]\n",
      "epoch:10 step:8346[D loss: 0.394396, acc: 60.94%, op_acc: 39.84%] [G loss: 0.864735]\n",
      "epoch:10 step:8347[D loss: 0.477648, acc: 53.91%, op_acc: 23.44%] [G loss: 0.904655]\n",
      "epoch:10 step:8348[D loss: 0.415533, acc: 59.38%, op_acc: 40.62%] [G loss: 0.899295]\n",
      "epoch:10 step:8349[D loss: 0.473026, acc: 60.94%, op_acc: 29.69%] [G loss: 0.850371]\n",
      "epoch:10 step:8350[D loss: 0.427472, acc: 56.25%, op_acc: 37.50%] [G loss: 0.880077]\n",
      "##############\n",
      "[0.84845818 0.86103002 0.8031167  0.8312461  0.78712471 0.82678197\n",
      " 0.87805389 0.82152795 0.79033401 0.83119574]\n",
      "##########\n",
      "epoch:10 step:8351[D loss: 0.421051, acc: 60.16%, op_acc: 40.62%] [G loss: 0.840049]\n",
      "epoch:10 step:8352[D loss: 0.446554, acc: 54.69%, op_acc: 34.38%] [G loss: 0.849611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8353[D loss: 0.440735, acc: 58.59%, op_acc: 32.03%] [G loss: 0.841842]\n",
      "epoch:10 step:8354[D loss: 0.458454, acc: 52.34%, op_acc: 37.50%] [G loss: 0.766286]\n",
      "epoch:10 step:8355[D loss: 0.433640, acc: 60.16%, op_acc: 35.16%] [G loss: 0.885040]\n",
      "epoch:10 step:8356[D loss: 0.441801, acc: 55.47%, op_acc: 39.84%] [G loss: 0.907558]\n",
      "epoch:10 step:8357[D loss: 0.443502, acc: 62.50%, op_acc: 32.81%] [G loss: 0.929071]\n",
      "epoch:10 step:8358[D loss: 0.456778, acc: 57.81%, op_acc: 30.47%] [G loss: 0.891395]\n",
      "epoch:10 step:8359[D loss: 0.437502, acc: 62.50%, op_acc: 34.38%] [G loss: 0.882676]\n",
      "epoch:10 step:8360[D loss: 0.447715, acc: 51.56%, op_acc: 35.16%] [G loss: 0.866377]\n",
      "epoch:10 step:8361[D loss: 0.417469, acc: 64.06%, op_acc: 35.16%] [G loss: 0.879476]\n",
      "epoch:10 step:8362[D loss: 0.450184, acc: 63.28%, op_acc: 32.03%] [G loss: 0.881686]\n",
      "epoch:10 step:8363[D loss: 0.410447, acc: 60.16%, op_acc: 35.94%] [G loss: 0.852263]\n",
      "epoch:10 step:8364[D loss: 0.433847, acc: 59.38%, op_acc: 36.72%] [G loss: 0.835348]\n",
      "epoch:10 step:8365[D loss: 0.415314, acc: 67.19%, op_acc: 36.72%] [G loss: 0.854674]\n",
      "epoch:10 step:8366[D loss: 0.415672, acc: 59.38%, op_acc: 39.06%] [G loss: 0.881831]\n",
      "epoch:10 step:8367[D loss: 0.429810, acc: 65.62%, op_acc: 36.72%] [G loss: 0.819271]\n",
      "epoch:10 step:8368[D loss: 0.423267, acc: 60.94%, op_acc: 36.72%] [G loss: 0.885992]\n",
      "epoch:10 step:8369[D loss: 0.427031, acc: 58.59%, op_acc: 35.94%] [G loss: 0.825924]\n",
      "epoch:10 step:8370[D loss: 0.460236, acc: 53.12%, op_acc: 32.81%] [G loss: 0.877207]\n",
      "epoch:10 step:8371[D loss: 0.433179, acc: 59.38%, op_acc: 40.62%] [G loss: 0.894180]\n",
      "epoch:10 step:8372[D loss: 0.470913, acc: 57.03%, op_acc: 33.59%] [G loss: 0.828528]\n",
      "epoch:10 step:8373[D loss: 0.441712, acc: 56.25%, op_acc: 32.03%] [G loss: 0.913677]\n",
      "epoch:10 step:8374[D loss: 0.461420, acc: 49.22%, op_acc: 36.72%] [G loss: 0.880695]\n",
      "epoch:10 step:8375[D loss: 0.458396, acc: 46.09%, op_acc: 37.50%] [G loss: 0.873624]\n",
      "epoch:10 step:8376[D loss: 0.449248, acc: 60.94%, op_acc: 29.69%] [G loss: 0.781511]\n",
      "epoch:10 step:8377[D loss: 0.439718, acc: 64.84%, op_acc: 36.72%] [G loss: 0.936811]\n",
      "epoch:10 step:8378[D loss: 0.433620, acc: 60.94%, op_acc: 37.50%] [G loss: 0.901802]\n",
      "epoch:10 step:8379[D loss: 0.435314, acc: 61.72%, op_acc: 35.94%] [G loss: 0.852906]\n",
      "epoch:10 step:8380[D loss: 0.418971, acc: 65.62%, op_acc: 35.16%] [G loss: 0.883701]\n",
      "epoch:10 step:8381[D loss: 0.439185, acc: 57.81%, op_acc: 35.16%] [G loss: 0.766611]\n",
      "epoch:10 step:8382[D loss: 0.417658, acc: 63.28%, op_acc: 37.50%] [G loss: 0.871132]\n",
      "epoch:10 step:8383[D loss: 0.458333, acc: 53.91%, op_acc: 38.28%] [G loss: 0.829168]\n",
      "epoch:10 step:8384[D loss: 0.426763, acc: 61.72%, op_acc: 34.38%] [G loss: 0.896321]\n",
      "epoch:10 step:8385[D loss: 0.457252, acc: 53.91%, op_acc: 33.59%] [G loss: 0.840775]\n",
      "epoch:10 step:8386[D loss: 0.431861, acc: 63.28%, op_acc: 35.16%] [G loss: 0.849520]\n",
      "epoch:10 step:8387[D loss: 0.460026, acc: 57.03%, op_acc: 34.38%] [G loss: 0.858308]\n",
      "epoch:10 step:8388[D loss: 0.444951, acc: 60.94%, op_acc: 33.59%] [G loss: 0.966132]\n",
      "epoch:10 step:8389[D loss: 0.434933, acc: 55.47%, op_acc: 38.28%] [G loss: 0.846286]\n",
      "epoch:10 step:8390[D loss: 0.448257, acc: 57.81%, op_acc: 32.81%] [G loss: 0.856214]\n",
      "epoch:10 step:8391[D loss: 0.435305, acc: 63.28%, op_acc: 34.38%] [G loss: 0.847856]\n",
      "epoch:10 step:8392[D loss: 0.458052, acc: 53.12%, op_acc: 28.91%] [G loss: 0.936143]\n",
      "epoch:10 step:8393[D loss: 0.420288, acc: 61.72%, op_acc: 32.81%] [G loss: 0.941595]\n",
      "epoch:10 step:8394[D loss: 0.468338, acc: 56.25%, op_acc: 28.91%] [G loss: 0.897646]\n",
      "epoch:10 step:8395[D loss: 0.415223, acc: 62.50%, op_acc: 35.94%] [G loss: 0.909105]\n",
      "epoch:10 step:8396[D loss: 0.447161, acc: 58.59%, op_acc: 35.16%] [G loss: 0.893787]\n",
      "epoch:10 step:8397[D loss: 0.429829, acc: 64.84%, op_acc: 30.47%] [G loss: 0.921328]\n",
      "epoch:10 step:8398[D loss: 0.447462, acc: 57.03%, op_acc: 35.16%] [G loss: 0.894604]\n",
      "epoch:10 step:8399[D loss: 0.441638, acc: 61.72%, op_acc: 36.72%] [G loss: 0.950345]\n",
      "epoch:10 step:8400[D loss: 0.435719, acc: 60.16%, op_acc: 37.50%] [G loss: 0.889739]\n",
      "##############\n",
      "[0.86534675 0.84594237 0.82541052 0.81753963 0.79868113 0.82212752\n",
      " 0.88323171 0.82017318 0.82482933 0.82794697]\n",
      "##########\n",
      "epoch:10 step:8401[D loss: 0.437380, acc: 53.12%, op_acc: 36.72%] [G loss: 0.915655]\n",
      "epoch:10 step:8402[D loss: 0.458766, acc: 56.25%, op_acc: 39.06%] [G loss: 0.951532]\n",
      "epoch:10 step:8403[D loss: 0.483183, acc: 47.66%, op_acc: 32.81%] [G loss: 0.850347]\n",
      "epoch:10 step:8404[D loss: 0.425511, acc: 63.28%, op_acc: 35.16%] [G loss: 0.927862]\n",
      "epoch:10 step:8405[D loss: 0.474029, acc: 47.66%, op_acc: 32.81%] [G loss: 0.913905]\n",
      "epoch:10 step:8406[D loss: 0.403063, acc: 68.75%, op_acc: 36.72%] [G loss: 0.944214]\n",
      "epoch:10 step:8407[D loss: 0.429020, acc: 63.28%, op_acc: 35.16%] [G loss: 0.885516]\n",
      "epoch:10 step:8408[D loss: 0.467636, acc: 50.78%, op_acc: 37.50%] [G loss: 0.916174]\n",
      "epoch:10 step:8409[D loss: 0.450935, acc: 57.81%, op_acc: 33.59%] [G loss: 0.929231]\n",
      "epoch:10 step:8410[D loss: 0.454127, acc: 56.25%, op_acc: 36.72%] [G loss: 0.828325]\n",
      "epoch:10 step:8411[D loss: 0.447319, acc: 53.91%, op_acc: 32.03%] [G loss: 0.894835]\n",
      "epoch:10 step:8412[D loss: 0.427485, acc: 59.38%, op_acc: 40.62%] [G loss: 0.827161]\n",
      "epoch:10 step:8413[D loss: 0.393874, acc: 64.06%, op_acc: 42.19%] [G loss: 0.840505]\n",
      "epoch:10 step:8414[D loss: 0.453297, acc: 58.59%, op_acc: 35.94%] [G loss: 0.793276]\n",
      "epoch:10 step:8415[D loss: 0.435131, acc: 60.16%, op_acc: 34.38%] [G loss: 0.815500]\n",
      "epoch:10 step:8416[D loss: 0.422700, acc: 57.81%, op_acc: 42.19%] [G loss: 0.817529]\n",
      "epoch:10 step:8417[D loss: 0.410420, acc: 60.16%, op_acc: 42.19%] [G loss: 0.865056]\n",
      "epoch:10 step:8418[D loss: 0.444940, acc: 54.69%, op_acc: 34.38%] [G loss: 0.821585]\n",
      "epoch:10 step:8419[D loss: 0.450122, acc: 53.91%, op_acc: 38.28%] [G loss: 0.884879]\n",
      "epoch:10 step:8420[D loss: 0.439042, acc: 57.81%, op_acc: 31.25%] [G loss: 0.863248]\n",
      "epoch:10 step:8421[D loss: 0.453294, acc: 57.03%, op_acc: 32.03%] [G loss: 0.867109]\n",
      "epoch:10 step:8422[D loss: 0.427071, acc: 57.81%, op_acc: 35.16%] [G loss: 0.875759]\n",
      "epoch:10 step:8423[D loss: 0.450671, acc: 60.16%, op_acc: 35.16%] [G loss: 0.840948]\n",
      "epoch:10 step:8424[D loss: 0.443809, acc: 50.78%, op_acc: 41.41%] [G loss: 0.824958]\n",
      "epoch:10 step:8425[D loss: 0.405928, acc: 64.06%, op_acc: 41.41%] [G loss: 0.902326]\n",
      "epoch:10 step:8426[D loss: 0.437271, acc: 61.72%, op_acc: 33.59%] [G loss: 0.903018]\n",
      "epoch:10 step:8427[D loss: 0.458523, acc: 56.25%, op_acc: 35.94%] [G loss: 0.899228]\n",
      "epoch:10 step:8428[D loss: 0.426165, acc: 60.16%, op_acc: 38.28%] [G loss: 0.886475]\n",
      "epoch:10 step:8429[D loss: 0.465963, acc: 65.62%, op_acc: 28.91%] [G loss: 0.853441]\n",
      "epoch:10 step:8430[D loss: 0.457202, acc: 57.81%, op_acc: 34.38%] [G loss: 0.914448]\n",
      "epoch:10 step:8431[D loss: 0.440821, acc: 60.94%, op_acc: 35.94%] [G loss: 0.860000]\n",
      "epoch:10 step:8432[D loss: 0.469534, acc: 57.81%, op_acc: 30.47%] [G loss: 0.851603]\n",
      "epoch:10 step:8433[D loss: 0.416325, acc: 65.62%, op_acc: 37.50%] [G loss: 0.858204]\n",
      "epoch:10 step:8434[D loss: 0.391000, acc: 67.97%, op_acc: 41.41%] [G loss: 0.911783]\n",
      "epoch:10 step:8435[D loss: 0.460678, acc: 57.81%, op_acc: 35.16%] [G loss: 0.871213]\n",
      "epoch:10 step:8436[D loss: 0.393303, acc: 67.19%, op_acc: 46.88%] [G loss: 0.934061]\n",
      "epoch:10 step:8437[D loss: 0.416182, acc: 60.16%, op_acc: 39.06%] [G loss: 0.924370]\n",
      "epoch:10 step:8438[D loss: 0.452992, acc: 58.59%, op_acc: 34.38%] [G loss: 0.931377]\n",
      "epoch:10 step:8439[D loss: 0.445515, acc: 60.16%, op_acc: 35.16%] [G loss: 0.865718]\n",
      "epoch:10 step:8440[D loss: 0.442541, acc: 52.34%, op_acc: 35.94%] [G loss: 0.939224]\n",
      "epoch:10 step:8441[D loss: 0.429090, acc: 62.50%, op_acc: 35.16%] [G loss: 0.938914]\n",
      "epoch:10 step:8442[D loss: 0.464121, acc: 60.16%, op_acc: 28.12%] [G loss: 0.887651]\n",
      "epoch:10 step:8443[D loss: 0.456398, acc: 56.25%, op_acc: 35.94%] [G loss: 0.798068]\n",
      "epoch:10 step:8444[D loss: 0.428236, acc: 64.06%, op_acc: 39.84%] [G loss: 0.915122]\n",
      "epoch:10 step:8445[D loss: 0.435948, acc: 60.16%, op_acc: 35.16%] [G loss: 0.932912]\n",
      "epoch:10 step:8446[D loss: 0.422904, acc: 58.59%, op_acc: 38.28%] [G loss: 0.877936]\n",
      "epoch:10 step:8447[D loss: 0.461060, acc: 53.12%, op_acc: 37.50%] [G loss: 0.840355]\n",
      "epoch:10 step:8448[D loss: 0.452036, acc: 62.50%, op_acc: 32.03%] [G loss: 0.906610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8449[D loss: 0.460694, acc: 53.91%, op_acc: 37.50%] [G loss: 0.900272]\n",
      "epoch:10 step:8450[D loss: 0.458937, acc: 57.81%, op_acc: 32.03%] [G loss: 0.895990]\n",
      "##############\n",
      "[0.85792154 0.86245381 0.81802262 0.80862585 0.80297936 0.83268126\n",
      " 0.88533229 0.82296795 0.79756899 0.834863  ]\n",
      "##########\n",
      "epoch:10 step:8451[D loss: 0.446550, acc: 63.28%, op_acc: 28.12%] [G loss: 0.832344]\n",
      "epoch:10 step:8452[D loss: 0.438076, acc: 69.53%, op_acc: 28.91%] [G loss: 0.968841]\n",
      "epoch:10 step:8453[D loss: 0.472183, acc: 55.47%, op_acc: 35.16%] [G loss: 0.875065]\n",
      "epoch:10 step:8454[D loss: 0.420059, acc: 64.06%, op_acc: 36.72%] [G loss: 0.838239]\n",
      "epoch:10 step:8455[D loss: 0.436163, acc: 57.81%, op_acc: 41.41%] [G loss: 0.808432]\n",
      "epoch:10 step:8456[D loss: 0.442382, acc: 67.19%, op_acc: 33.59%] [G loss: 0.843705]\n",
      "epoch:10 step:8457[D loss: 0.455703, acc: 49.22%, op_acc: 37.50%] [G loss: 0.868832]\n",
      "epoch:10 step:8458[D loss: 0.465096, acc: 53.12%, op_acc: 31.25%] [G loss: 0.895670]\n",
      "epoch:10 step:8459[D loss: 0.436880, acc: 58.59%, op_acc: 32.03%] [G loss: 0.929069]\n",
      "epoch:10 step:8460[D loss: 0.463282, acc: 62.50%, op_acc: 32.81%] [G loss: 0.961349]\n",
      "epoch:10 step:8461[D loss: 0.447369, acc: 58.59%, op_acc: 36.72%] [G loss: 0.866005]\n",
      "epoch:10 step:8462[D loss: 0.437200, acc: 58.59%, op_acc: 35.16%] [G loss: 0.922160]\n",
      "epoch:10 step:8463[D loss: 0.402408, acc: 64.84%, op_acc: 41.41%] [G loss: 0.922645]\n",
      "epoch:10 step:8464[D loss: 0.434659, acc: 60.16%, op_acc: 33.59%] [G loss: 0.896237]\n",
      "epoch:10 step:8465[D loss: 0.442806, acc: 57.03%, op_acc: 39.06%] [G loss: 0.854894]\n",
      "epoch:10 step:8466[D loss: 0.444231, acc: 61.72%, op_acc: 32.81%] [G loss: 0.893991]\n",
      "epoch:10 step:8467[D loss: 0.467329, acc: 53.12%, op_acc: 35.16%] [G loss: 0.900441]\n",
      "epoch:10 step:8468[D loss: 0.425361, acc: 65.62%, op_acc: 34.38%] [G loss: 0.861529]\n",
      "epoch:10 step:8469[D loss: 0.459055, acc: 60.94%, op_acc: 34.38%] [G loss: 0.915035]\n",
      "epoch:10 step:8470[D loss: 0.408881, acc: 67.97%, op_acc: 39.06%] [G loss: 0.868880]\n",
      "epoch:10 step:8471[D loss: 0.434155, acc: 53.12%, op_acc: 38.28%] [G loss: 0.820673]\n",
      "epoch:10 step:8472[D loss: 0.445093, acc: 58.59%, op_acc: 35.16%] [G loss: 0.815557]\n",
      "epoch:10 step:8473[D loss: 0.427999, acc: 57.03%, op_acc: 35.94%] [G loss: 0.855608]\n",
      "epoch:10 step:8474[D loss: 0.421320, acc: 60.16%, op_acc: 37.50%] [G loss: 0.849006]\n",
      "epoch:10 step:8475[D loss: 0.475501, acc: 62.50%, op_acc: 28.91%] [G loss: 0.818271]\n",
      "epoch:10 step:8476[D loss: 0.472536, acc: 54.69%, op_acc: 35.94%] [G loss: 0.797516]\n",
      "epoch:10 step:8477[D loss: 0.441216, acc: 57.03%, op_acc: 37.50%] [G loss: 0.911207]\n",
      "epoch:10 step:8478[D loss: 0.428874, acc: 63.28%, op_acc: 35.94%] [G loss: 0.966977]\n",
      "epoch:10 step:8479[D loss: 0.460596, acc: 59.38%, op_acc: 31.25%] [G loss: 0.846324]\n",
      "epoch:10 step:8480[D loss: 0.424450, acc: 56.25%, op_acc: 39.84%] [G loss: 0.867030]\n",
      "epoch:10 step:8481[D loss: 0.455085, acc: 60.94%, op_acc: 31.25%] [G loss: 0.900236]\n",
      "epoch:10 step:8482[D loss: 0.447872, acc: 57.03%, op_acc: 35.94%] [G loss: 0.920807]\n",
      "epoch:10 step:8483[D loss: 0.448307, acc: 53.91%, op_acc: 33.59%] [G loss: 0.868992]\n",
      "epoch:10 step:8484[D loss: 0.456446, acc: 50.78%, op_acc: 35.94%] [G loss: 0.814457]\n",
      "epoch:10 step:8485[D loss: 0.449341, acc: 53.12%, op_acc: 34.38%] [G loss: 0.902272]\n",
      "epoch:10 step:8486[D loss: 0.491448, acc: 46.09%, op_acc: 28.12%] [G loss: 0.904877]\n",
      "epoch:10 step:8487[D loss: 0.465426, acc: 60.94%, op_acc: 30.47%] [G loss: 0.808595]\n",
      "epoch:10 step:8488[D loss: 0.422666, acc: 62.50%, op_acc: 39.84%] [G loss: 0.816851]\n",
      "epoch:10 step:8489[D loss: 0.453191, acc: 55.47%, op_acc: 35.16%] [G loss: 0.801905]\n",
      "epoch:10 step:8490[D loss: 0.472178, acc: 52.34%, op_acc: 34.38%] [G loss: 0.894855]\n",
      "epoch:10 step:8491[D loss: 0.444383, acc: 59.38%, op_acc: 36.72%] [G loss: 0.785036]\n",
      "epoch:10 step:8492[D loss: 0.401891, acc: 60.16%, op_acc: 45.31%] [G loss: 0.889069]\n",
      "epoch:10 step:8493[D loss: 0.438732, acc: 56.25%, op_acc: 41.41%] [G loss: 0.889798]\n",
      "epoch:10 step:8494[D loss: 0.436935, acc: 61.72%, op_acc: 31.25%] [G loss: 0.860930]\n",
      "epoch:10 step:8495[D loss: 0.446118, acc: 55.47%, op_acc: 36.72%] [G loss: 0.800635]\n",
      "epoch:10 step:8496[D loss: 0.452735, acc: 57.03%, op_acc: 30.47%] [G loss: 0.826717]\n",
      "epoch:10 step:8497[D loss: 0.402625, acc: 71.09%, op_acc: 39.06%] [G loss: 0.903906]\n",
      "epoch:10 step:8498[D loss: 0.434434, acc: 54.69%, op_acc: 41.41%] [G loss: 0.931719]\n",
      "epoch:10 step:8499[D loss: 0.452010, acc: 53.91%, op_acc: 29.69%] [G loss: 0.852433]\n",
      "epoch:10 step:8500[D loss: 0.428415, acc: 65.62%, op_acc: 37.50%] [G loss: 0.947813]\n",
      "##############\n",
      "[0.86009777 0.83595707 0.82417306 0.80279684 0.81737843 0.83116886\n",
      " 0.88863217 0.83106081 0.83832168 0.84756843]\n",
      "##########\n",
      "epoch:10 step:8501[D loss: 0.435085, acc: 61.72%, op_acc: 33.59%] [G loss: 0.913173]\n",
      "epoch:10 step:8502[D loss: 0.420791, acc: 64.06%, op_acc: 35.94%] [G loss: 0.893672]\n",
      "epoch:10 step:8503[D loss: 0.446916, acc: 60.16%, op_acc: 34.38%] [G loss: 0.895340]\n",
      "epoch:10 step:8504[D loss: 0.461525, acc: 58.59%, op_acc: 38.28%] [G loss: 0.914367]\n",
      "epoch:10 step:8505[D loss: 0.449701, acc: 56.25%, op_acc: 32.81%] [G loss: 0.887382]\n",
      "epoch:10 step:8506[D loss: 0.426156, acc: 60.94%, op_acc: 35.16%] [G loss: 0.871395]\n",
      "epoch:10 step:8507[D loss: 0.450143, acc: 60.16%, op_acc: 38.28%] [G loss: 0.871017]\n",
      "epoch:10 step:8508[D loss: 0.441347, acc: 54.69%, op_acc: 39.06%] [G loss: 0.929772]\n",
      "epoch:10 step:8509[D loss: 0.405545, acc: 64.84%, op_acc: 39.84%] [G loss: 0.951963]\n",
      "epoch:10 step:8510[D loss: 0.466154, acc: 57.03%, op_acc: 30.47%] [G loss: 0.820344]\n",
      "epoch:10 step:8511[D loss: 0.461394, acc: 51.56%, op_acc: 35.16%] [G loss: 0.818716]\n",
      "epoch:10 step:8512[D loss: 0.425505, acc: 61.72%, op_acc: 32.81%] [G loss: 0.899738]\n",
      "epoch:10 step:8513[D loss: 0.460485, acc: 53.91%, op_acc: 33.59%] [G loss: 0.818122]\n",
      "epoch:10 step:8514[D loss: 0.389413, acc: 64.84%, op_acc: 36.72%] [G loss: 0.885644]\n",
      "epoch:10 step:8515[D loss: 0.449515, acc: 54.69%, op_acc: 35.16%] [G loss: 0.786826]\n",
      "epoch:10 step:8516[D loss: 0.439849, acc: 58.59%, op_acc: 37.50%] [G loss: 0.792257]\n",
      "epoch:10 step:8517[D loss: 0.456647, acc: 62.50%, op_acc: 35.16%] [G loss: 0.876907]\n",
      "epoch:10 step:8518[D loss: 0.444475, acc: 57.03%, op_acc: 31.25%] [G loss: 0.844772]\n",
      "epoch:10 step:8519[D loss: 0.437782, acc: 63.28%, op_acc: 34.38%] [G loss: 0.884099]\n",
      "epoch:10 step:8520[D loss: 0.408851, acc: 53.91%, op_acc: 39.06%] [G loss: 0.887220]\n",
      "epoch:10 step:8521[D loss: 0.436771, acc: 60.16%, op_acc: 34.38%] [G loss: 0.823779]\n",
      "epoch:10 step:8522[D loss: 0.400099, acc: 60.16%, op_acc: 40.62%] [G loss: 0.872195]\n",
      "epoch:10 step:8523[D loss: 0.419877, acc: 60.94%, op_acc: 33.59%] [G loss: 0.914968]\n",
      "epoch:10 step:8524[D loss: 0.478338, acc: 50.00%, op_acc: 33.59%] [G loss: 0.856057]\n",
      "epoch:10 step:8525[D loss: 0.417336, acc: 61.72%, op_acc: 42.19%] [G loss: 0.879077]\n",
      "epoch:10 step:8526[D loss: 0.442801, acc: 57.03%, op_acc: 32.81%] [G loss: 0.862665]\n",
      "epoch:10 step:8527[D loss: 0.426703, acc: 60.94%, op_acc: 38.28%] [G loss: 0.919591]\n",
      "epoch:10 step:8528[D loss: 0.429641, acc: 57.81%, op_acc: 35.94%] [G loss: 0.873620]\n",
      "epoch:10 step:8529[D loss: 0.432970, acc: 58.59%, op_acc: 38.28%] [G loss: 0.822387]\n",
      "epoch:10 step:8530[D loss: 0.444584, acc: 64.84%, op_acc: 34.38%] [G loss: 0.880916]\n",
      "epoch:10 step:8531[D loss: 0.434987, acc: 60.94%, op_acc: 33.59%] [G loss: 0.885594]\n",
      "epoch:10 step:8532[D loss: 0.440472, acc: 54.69%, op_acc: 39.06%] [G loss: 0.834702]\n",
      "epoch:10 step:8533[D loss: 0.421128, acc: 62.50%, op_acc: 38.28%] [G loss: 0.870058]\n",
      "epoch:10 step:8534[D loss: 0.491475, acc: 53.12%, op_acc: 28.12%] [G loss: 0.887263]\n",
      "epoch:10 step:8535[D loss: 0.428701, acc: 60.16%, op_acc: 37.50%] [G loss: 0.833767]\n",
      "epoch:10 step:8536[D loss: 0.433579, acc: 53.91%, op_acc: 41.41%] [G loss: 0.887650]\n",
      "epoch:10 step:8537[D loss: 0.481251, acc: 51.56%, op_acc: 28.91%] [G loss: 0.815244]\n",
      "epoch:10 step:8538[D loss: 0.453807, acc: 58.59%, op_acc: 30.47%] [G loss: 0.867398]\n",
      "epoch:10 step:8539[D loss: 0.426990, acc: 63.28%, op_acc: 33.59%] [G loss: 0.889561]\n",
      "epoch:10 step:8540[D loss: 0.423653, acc: 63.28%, op_acc: 34.38%] [G loss: 0.893382]\n",
      "epoch:10 step:8541[D loss: 0.432901, acc: 53.12%, op_acc: 35.16%] [G loss: 0.895929]\n",
      "epoch:10 step:8542[D loss: 0.452620, acc: 56.25%, op_acc: 34.38%] [G loss: 0.892819]\n",
      "epoch:10 step:8543[D loss: 0.427281, acc: 58.59%, op_acc: 39.06%] [G loss: 0.844565]\n",
      "epoch:10 step:8544[D loss: 0.448718, acc: 64.06%, op_acc: 32.03%] [G loss: 0.836971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8545[D loss: 0.461519, acc: 53.12%, op_acc: 32.81%] [G loss: 0.873558]\n",
      "epoch:10 step:8546[D loss: 0.434677, acc: 62.50%, op_acc: 30.47%] [G loss: 0.883983]\n",
      "epoch:10 step:8547[D loss: 0.406043, acc: 67.19%, op_acc: 41.41%] [G loss: 0.867455]\n",
      "epoch:10 step:8548[D loss: 0.455069, acc: 54.69%, op_acc: 33.59%] [G loss: 0.860415]\n",
      "epoch:10 step:8549[D loss: 0.450852, acc: 52.34%, op_acc: 34.38%] [G loss: 0.831127]\n",
      "epoch:10 step:8550[D loss: 0.454786, acc: 45.31%, op_acc: 35.94%] [G loss: 0.819042]\n",
      "##############\n",
      "[0.86585341 0.84587106 0.81161241 0.79541534 0.79062764 0.8362113\n",
      " 0.88856311 0.81719583 0.82016267 0.84914481]\n",
      "##########\n",
      "epoch:10 step:8551[D loss: 0.432125, acc: 60.16%, op_acc: 32.81%] [G loss: 0.887141]\n",
      "epoch:10 step:8552[D loss: 0.425640, acc: 67.19%, op_acc: 34.38%] [G loss: 0.852059]\n",
      "epoch:10 step:8553[D loss: 0.437252, acc: 66.41%, op_acc: 32.03%] [G loss: 0.893552]\n",
      "epoch:10 step:8554[D loss: 0.412762, acc: 64.06%, op_acc: 38.28%] [G loss: 0.883080]\n",
      "epoch:10 step:8555[D loss: 0.451465, acc: 55.47%, op_acc: 38.28%] [G loss: 0.873382]\n",
      "epoch:10 step:8556[D loss: 0.440700, acc: 60.16%, op_acc: 33.59%] [G loss: 0.886812]\n",
      "epoch:10 step:8557[D loss: 0.425347, acc: 57.81%, op_acc: 37.50%] [G loss: 0.884346]\n",
      "epoch:10 step:8558[D loss: 0.471671, acc: 55.47%, op_acc: 32.03%] [G loss: 0.874792]\n",
      "epoch:10 step:8559[D loss: 0.472424, acc: 51.56%, op_acc: 32.81%] [G loss: 0.815355]\n",
      "epoch:10 step:8560[D loss: 0.431154, acc: 60.94%, op_acc: 42.97%] [G loss: 0.887355]\n",
      "epoch:10 step:8561[D loss: 0.471062, acc: 51.56%, op_acc: 36.72%] [G loss: 0.867345]\n",
      "epoch:10 step:8562[D loss: 0.419831, acc: 67.97%, op_acc: 36.72%] [G loss: 0.837977]\n",
      "epoch:10 step:8563[D loss: 0.456764, acc: 49.22%, op_acc: 33.59%] [G loss: 0.857553]\n",
      "epoch:10 step:8564[D loss: 0.453301, acc: 50.00%, op_acc: 32.03%] [G loss: 0.863563]\n",
      "epoch:10 step:8565[D loss: 0.450723, acc: 59.38%, op_acc: 37.50%] [G loss: 0.842412]\n",
      "epoch:10 step:8566[D loss: 0.416867, acc: 60.94%, op_acc: 40.62%] [G loss: 0.861860]\n",
      "epoch:10 step:8567[D loss: 0.441138, acc: 53.91%, op_acc: 32.81%] [G loss: 0.881012]\n",
      "epoch:10 step:8568[D loss: 0.458844, acc: 51.56%, op_acc: 35.16%] [G loss: 0.869818]\n",
      "epoch:10 step:8569[D loss: 0.440688, acc: 57.03%, op_acc: 37.50%] [G loss: 0.835431]\n",
      "epoch:10 step:8570[D loss: 0.424757, acc: 60.94%, op_acc: 39.84%] [G loss: 0.859608]\n",
      "epoch:10 step:8571[D loss: 0.413066, acc: 62.50%, op_acc: 38.28%] [G loss: 0.899822]\n",
      "epoch:10 step:8572[D loss: 0.466901, acc: 59.38%, op_acc: 33.59%] [G loss: 0.880257]\n",
      "epoch:10 step:8573[D loss: 0.469323, acc: 57.03%, op_acc: 33.59%] [G loss: 0.888640]\n",
      "epoch:10 step:8574[D loss: 0.441838, acc: 55.47%, op_acc: 39.06%] [G loss: 0.894793]\n",
      "epoch:10 step:8575[D loss: 0.450311, acc: 53.12%, op_acc: 34.38%] [G loss: 0.866186]\n",
      "epoch:10 step:8576[D loss: 0.460962, acc: 49.22%, op_acc: 36.72%] [G loss: 0.822756]\n",
      "epoch:10 step:8577[D loss: 0.442203, acc: 60.94%, op_acc: 34.38%] [G loss: 0.889161]\n",
      "epoch:10 step:8578[D loss: 0.449799, acc: 59.38%, op_acc: 27.34%] [G loss: 0.852567]\n",
      "epoch:10 step:8579[D loss: 0.423419, acc: 60.94%, op_acc: 40.62%] [G loss: 0.884673]\n",
      "epoch:10 step:8580[D loss: 0.421446, acc: 57.81%, op_acc: 41.41%] [G loss: 0.860415]\n",
      "epoch:10 step:8581[D loss: 0.486042, acc: 50.78%, op_acc: 28.91%] [G loss: 0.912071]\n",
      "epoch:10 step:8582[D loss: 0.451692, acc: 59.38%, op_acc: 25.78%] [G loss: 0.935698]\n",
      "epoch:10 step:8583[D loss: 0.435036, acc: 60.94%, op_acc: 34.38%] [G loss: 0.875081]\n",
      "epoch:10 step:8584[D loss: 0.394566, acc: 67.19%, op_acc: 37.50%] [G loss: 0.866179]\n",
      "epoch:10 step:8585[D loss: 0.404205, acc: 65.62%, op_acc: 39.06%] [G loss: 0.879225]\n",
      "epoch:10 step:8586[D loss: 0.423966, acc: 57.03%, op_acc: 38.28%] [G loss: 0.874706]\n",
      "epoch:10 step:8587[D loss: 0.474186, acc: 49.22%, op_acc: 35.94%] [G loss: 0.881258]\n",
      "epoch:10 step:8588[D loss: 0.421695, acc: 59.38%, op_acc: 39.84%] [G loss: 0.885426]\n",
      "epoch:10 step:8589[D loss: 0.438041, acc: 60.16%, op_acc: 35.94%] [G loss: 0.881570]\n",
      "epoch:10 step:8590[D loss: 0.416371, acc: 59.38%, op_acc: 35.16%] [G loss: 0.888633]\n",
      "epoch:10 step:8591[D loss: 0.433890, acc: 60.16%, op_acc: 32.03%] [G loss: 0.935541]\n",
      "epoch:11 step:8592[D loss: 0.441546, acc: 57.03%, op_acc: 42.19%] [G loss: 0.837829]\n",
      "epoch:11 step:8593[D loss: 0.423921, acc: 61.72%, op_acc: 35.94%] [G loss: 0.798738]\n",
      "epoch:11 step:8594[D loss: 0.475038, acc: 51.56%, op_acc: 35.16%] [G loss: 0.828218]\n",
      "epoch:11 step:8595[D loss: 0.426563, acc: 61.72%, op_acc: 38.28%] [G loss: 0.902313]\n",
      "epoch:11 step:8596[D loss: 0.426611, acc: 63.28%, op_acc: 38.28%] [G loss: 0.872930]\n",
      "epoch:11 step:8597[D loss: 0.426619, acc: 58.59%, op_acc: 36.72%] [G loss: 0.814247]\n",
      "epoch:11 step:8598[D loss: 0.426433, acc: 60.94%, op_acc: 35.16%] [G loss: 0.845432]\n",
      "epoch:11 step:8599[D loss: 0.444651, acc: 57.03%, op_acc: 33.59%] [G loss: 0.869550]\n",
      "epoch:11 step:8600[D loss: 0.408926, acc: 58.59%, op_acc: 43.75%] [G loss: 0.869992]\n",
      "##############\n",
      "[0.8747159  0.85127584 0.81761008 0.80839014 0.80179879 0.83075452\n",
      " 0.88194453 0.83170255 0.7874748  0.83132305]\n",
      "##########\n",
      "epoch:11 step:8601[D loss: 0.451326, acc: 59.38%, op_acc: 33.59%] [G loss: 0.905672]\n",
      "epoch:11 step:8602[D loss: 0.458652, acc: 53.12%, op_acc: 35.94%] [G loss: 0.799697]\n",
      "epoch:11 step:8603[D loss: 0.415258, acc: 65.62%, op_acc: 28.91%] [G loss: 0.925345]\n",
      "epoch:11 step:8604[D loss: 0.463746, acc: 54.69%, op_acc: 30.47%] [G loss: 0.855124]\n",
      "epoch:11 step:8605[D loss: 0.449457, acc: 61.72%, op_acc: 31.25%] [G loss: 0.838878]\n",
      "epoch:11 step:8606[D loss: 0.427656, acc: 57.81%, op_acc: 43.75%] [G loss: 0.869608]\n",
      "epoch:11 step:8607[D loss: 0.408637, acc: 64.06%, op_acc: 39.84%] [G loss: 0.965354]\n",
      "epoch:11 step:8608[D loss: 0.423363, acc: 63.28%, op_acc: 35.16%] [G loss: 0.867606]\n",
      "epoch:11 step:8609[D loss: 0.415294, acc: 57.81%, op_acc: 38.28%] [G loss: 0.819754]\n",
      "epoch:11 step:8610[D loss: 0.449307, acc: 55.47%, op_acc: 34.38%] [G loss: 0.815799]\n",
      "epoch:11 step:8611[D loss: 0.404081, acc: 70.31%, op_acc: 40.62%] [G loss: 0.871214]\n",
      "epoch:11 step:8612[D loss: 0.461382, acc: 57.03%, op_acc: 29.69%] [G loss: 0.853276]\n",
      "epoch:11 step:8613[D loss: 0.441579, acc: 55.47%, op_acc: 34.38%] [G loss: 0.856341]\n",
      "epoch:11 step:8614[D loss: 0.460235, acc: 48.44%, op_acc: 36.72%] [G loss: 0.835779]\n",
      "epoch:11 step:8615[D loss: 0.438487, acc: 61.72%, op_acc: 36.72%] [G loss: 0.900280]\n",
      "epoch:11 step:8616[D loss: 0.467423, acc: 54.69%, op_acc: 34.38%] [G loss: 0.821536]\n",
      "epoch:11 step:8617[D loss: 0.458257, acc: 51.56%, op_acc: 32.81%] [G loss: 0.854236]\n",
      "epoch:11 step:8618[D loss: 0.443287, acc: 61.72%, op_acc: 31.25%] [G loss: 0.895545]\n",
      "epoch:11 step:8619[D loss: 0.439073, acc: 55.47%, op_acc: 35.94%] [G loss: 0.936683]\n",
      "epoch:11 step:8620[D loss: 0.442647, acc: 49.22%, op_acc: 45.31%] [G loss: 0.886433]\n",
      "epoch:11 step:8621[D loss: 0.403953, acc: 63.28%, op_acc: 41.41%] [G loss: 0.902877]\n",
      "epoch:11 step:8622[D loss: 0.459738, acc: 56.25%, op_acc: 35.16%] [G loss: 0.921910]\n",
      "epoch:11 step:8623[D loss: 0.445076, acc: 58.59%, op_acc: 32.03%] [G loss: 0.917509]\n",
      "epoch:11 step:8624[D loss: 0.481814, acc: 45.31%, op_acc: 35.94%] [G loss: 0.844143]\n",
      "epoch:11 step:8625[D loss: 0.424327, acc: 57.81%, op_acc: 39.84%] [G loss: 0.847805]\n",
      "epoch:11 step:8626[D loss: 0.439747, acc: 56.25%, op_acc: 33.59%] [G loss: 0.851601]\n",
      "epoch:11 step:8627[D loss: 0.432144, acc: 60.94%, op_acc: 38.28%] [G loss: 0.863220]\n",
      "epoch:11 step:8628[D loss: 0.430956, acc: 60.94%, op_acc: 32.81%] [G loss: 0.924438]\n",
      "epoch:11 step:8629[D loss: 0.434792, acc: 60.94%, op_acc: 31.25%] [G loss: 0.806718]\n",
      "epoch:11 step:8630[D loss: 0.460182, acc: 51.56%, op_acc: 32.81%] [G loss: 0.893463]\n",
      "epoch:11 step:8631[D loss: 0.444973, acc: 57.81%, op_acc: 34.38%] [G loss: 0.857875]\n",
      "epoch:11 step:8632[D loss: 0.439470, acc: 53.91%, op_acc: 34.38%] [G loss: 0.826187]\n",
      "epoch:11 step:8633[D loss: 0.415356, acc: 57.81%, op_acc: 41.41%] [G loss: 0.860079]\n",
      "epoch:11 step:8634[D loss: 0.443469, acc: 56.25%, op_acc: 30.47%] [G loss: 0.852417]\n",
      "epoch:11 step:8635[D loss: 0.435640, acc: 60.16%, op_acc: 33.59%] [G loss: 0.831512]\n",
      "epoch:11 step:8636[D loss: 0.438266, acc: 63.28%, op_acc: 36.72%] [G loss: 0.848359]\n",
      "epoch:11 step:8637[D loss: 0.439193, acc: 64.06%, op_acc: 30.47%] [G loss: 0.846025]\n",
      "epoch:11 step:8638[D loss: 0.467397, acc: 59.38%, op_acc: 28.91%] [G loss: 0.943556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8639[D loss: 0.460987, acc: 58.59%, op_acc: 34.38%] [G loss: 0.843522]\n",
      "epoch:11 step:8640[D loss: 0.445476, acc: 56.25%, op_acc: 39.06%] [G loss: 0.816080]\n",
      "epoch:11 step:8641[D loss: 0.441918, acc: 56.25%, op_acc: 40.62%] [G loss: 0.847282]\n",
      "epoch:11 step:8642[D loss: 0.429232, acc: 64.06%, op_acc: 35.94%] [G loss: 0.847258]\n",
      "epoch:11 step:8643[D loss: 0.455480, acc: 59.38%, op_acc: 28.91%] [G loss: 0.890175]\n",
      "epoch:11 step:8644[D loss: 0.487068, acc: 52.34%, op_acc: 31.25%] [G loss: 0.803069]\n",
      "epoch:11 step:8645[D loss: 0.465681, acc: 57.03%, op_acc: 32.81%] [G loss: 0.850419]\n",
      "epoch:11 step:8646[D loss: 0.447964, acc: 54.69%, op_acc: 36.72%] [G loss: 0.880888]\n",
      "epoch:11 step:8647[D loss: 0.432370, acc: 60.16%, op_acc: 39.06%] [G loss: 0.952350]\n",
      "epoch:11 step:8648[D loss: 0.423522, acc: 67.97%, op_acc: 33.59%] [G loss: 0.934583]\n",
      "epoch:11 step:8649[D loss: 0.434376, acc: 56.25%, op_acc: 41.41%] [G loss: 0.933612]\n",
      "epoch:11 step:8650[D loss: 0.425298, acc: 57.81%, op_acc: 35.16%] [G loss: 0.895739]\n",
      "##############\n",
      "[0.88315583 0.84745194 0.82701636 0.81940259 0.81470619 0.8317763\n",
      " 0.88060035 0.83520882 0.79527442 0.82055294]\n",
      "##########\n",
      "epoch:11 step:8651[D loss: 0.442292, acc: 54.69%, op_acc: 38.28%] [G loss: 0.839263]\n",
      "epoch:11 step:8652[D loss: 0.443160, acc: 62.50%, op_acc: 32.81%] [G loss: 0.932971]\n",
      "epoch:11 step:8653[D loss: 0.443718, acc: 59.38%, op_acc: 37.50%] [G loss: 0.853035]\n",
      "epoch:11 step:8654[D loss: 0.461334, acc: 53.12%, op_acc: 31.25%] [G loss: 0.850320]\n",
      "epoch:11 step:8655[D loss: 0.426856, acc: 56.25%, op_acc: 32.81%] [G loss: 0.856310]\n",
      "epoch:11 step:8656[D loss: 0.457928, acc: 57.03%, op_acc: 36.72%] [G loss: 0.913049]\n",
      "epoch:11 step:8657[D loss: 0.470085, acc: 50.78%, op_acc: 35.94%] [G loss: 0.829039]\n",
      "epoch:11 step:8658[D loss: 0.425293, acc: 59.38%, op_acc: 39.84%] [G loss: 0.945142]\n",
      "epoch:11 step:8659[D loss: 0.420374, acc: 60.16%, op_acc: 42.97%] [G loss: 0.878719]\n",
      "epoch:11 step:8660[D loss: 0.426384, acc: 59.38%, op_acc: 37.50%] [G loss: 0.806652]\n",
      "epoch:11 step:8661[D loss: 0.454942, acc: 51.56%, op_acc: 37.50%] [G loss: 0.823569]\n",
      "epoch:11 step:8662[D loss: 0.464509, acc: 54.69%, op_acc: 28.91%] [G loss: 0.863635]\n",
      "epoch:11 step:8663[D loss: 0.412859, acc: 55.47%, op_acc: 42.19%] [G loss: 0.861526]\n",
      "epoch:11 step:8664[D loss: 0.402612, acc: 65.62%, op_acc: 38.28%] [G loss: 0.916282]\n",
      "epoch:11 step:8665[D loss: 0.427504, acc: 62.50%, op_acc: 39.84%] [G loss: 0.867760]\n",
      "epoch:11 step:8666[D loss: 0.437520, acc: 50.78%, op_acc: 35.16%] [G loss: 0.827793]\n",
      "epoch:11 step:8667[D loss: 0.453103, acc: 59.38%, op_acc: 32.81%] [G loss: 0.906716]\n",
      "epoch:11 step:8668[D loss: 0.421429, acc: 60.94%, op_acc: 39.06%] [G loss: 0.864269]\n",
      "epoch:11 step:8669[D loss: 0.487650, acc: 48.44%, op_acc: 25.78%] [G loss: 0.856027]\n",
      "epoch:11 step:8670[D loss: 0.431352, acc: 57.03%, op_acc: 39.84%] [G loss: 0.955844]\n",
      "epoch:11 step:8671[D loss: 0.432465, acc: 62.50%, op_acc: 28.91%] [G loss: 0.841725]\n",
      "epoch:11 step:8672[D loss: 0.442561, acc: 63.28%, op_acc: 35.16%] [G loss: 0.874705]\n",
      "epoch:11 step:8673[D loss: 0.423082, acc: 64.84%, op_acc: 34.38%] [G loss: 0.861035]\n",
      "epoch:11 step:8674[D loss: 0.461892, acc: 56.25%, op_acc: 32.81%] [G loss: 0.838108]\n",
      "epoch:11 step:8675[D loss: 0.432286, acc: 53.12%, op_acc: 37.50%] [G loss: 0.812523]\n",
      "epoch:11 step:8676[D loss: 0.439789, acc: 59.38%, op_acc: 29.69%] [G loss: 0.920808]\n",
      "epoch:11 step:8677[D loss: 0.418856, acc: 63.28%, op_acc: 39.84%] [G loss: 0.822515]\n",
      "epoch:11 step:8678[D loss: 0.429292, acc: 60.16%, op_acc: 37.50%] [G loss: 0.882537]\n",
      "epoch:11 step:8679[D loss: 0.473917, acc: 54.69%, op_acc: 36.72%] [G loss: 0.844802]\n",
      "epoch:11 step:8680[D loss: 0.458352, acc: 51.56%, op_acc: 33.59%] [G loss: 0.875888]\n",
      "epoch:11 step:8681[D loss: 0.451195, acc: 50.00%, op_acc: 37.50%] [G loss: 0.877624]\n",
      "epoch:11 step:8682[D loss: 0.445108, acc: 54.69%, op_acc: 34.38%] [G loss: 0.912337]\n",
      "epoch:11 step:8683[D loss: 0.440058, acc: 55.47%, op_acc: 36.72%] [G loss: 0.828894]\n",
      "epoch:11 step:8684[D loss: 0.409423, acc: 56.25%, op_acc: 41.41%] [G loss: 0.874678]\n",
      "epoch:11 step:8685[D loss: 0.421841, acc: 64.06%, op_acc: 35.94%] [G loss: 0.817338]\n",
      "epoch:11 step:8686[D loss: 0.439653, acc: 60.16%, op_acc: 31.25%] [G loss: 0.826083]\n",
      "epoch:11 step:8687[D loss: 0.458354, acc: 55.47%, op_acc: 33.59%] [G loss: 0.827395]\n",
      "epoch:11 step:8688[D loss: 0.420987, acc: 64.06%, op_acc: 34.38%] [G loss: 0.858573]\n",
      "epoch:11 step:8689[D loss: 0.440229, acc: 63.28%, op_acc: 32.03%] [G loss: 0.857504]\n",
      "epoch:11 step:8690[D loss: 0.421328, acc: 60.94%, op_acc: 35.16%] [G loss: 0.834594]\n",
      "epoch:11 step:8691[D loss: 0.432379, acc: 59.38%, op_acc: 40.62%] [G loss: 0.831237]\n",
      "epoch:11 step:8692[D loss: 0.395602, acc: 67.97%, op_acc: 37.50%] [G loss: 0.912996]\n",
      "epoch:11 step:8693[D loss: 0.462449, acc: 54.69%, op_acc: 35.94%] [G loss: 0.883835]\n",
      "epoch:11 step:8694[D loss: 0.440130, acc: 56.25%, op_acc: 36.72%] [G loss: 0.910523]\n",
      "epoch:11 step:8695[D loss: 0.447316, acc: 55.47%, op_acc: 29.69%] [G loss: 0.837797]\n",
      "epoch:11 step:8696[D loss: 0.439959, acc: 55.47%, op_acc: 38.28%] [G loss: 0.923759]\n",
      "epoch:11 step:8697[D loss: 0.444502, acc: 52.34%, op_acc: 32.81%] [G loss: 0.840542]\n",
      "epoch:11 step:8698[D loss: 0.418751, acc: 67.19%, op_acc: 39.06%] [G loss: 0.930625]\n",
      "epoch:11 step:8699[D loss: 0.494113, acc: 51.56%, op_acc: 30.47%] [G loss: 0.890726]\n",
      "epoch:11 step:8700[D loss: 0.435035, acc: 63.28%, op_acc: 28.12%] [G loss: 0.897104]\n",
      "##############\n",
      "[0.86909157 0.85641081 0.83674532 0.81691937 0.79266218 0.82203527\n",
      " 0.88150754 0.84164194 0.80833227 0.81932813]\n",
      "##########\n",
      "epoch:11 step:8701[D loss: 0.445948, acc: 60.94%, op_acc: 37.50%] [G loss: 0.868460]\n",
      "epoch:11 step:8702[D loss: 0.421451, acc: 71.09%, op_acc: 32.81%] [G loss: 0.972922]\n",
      "epoch:11 step:8703[D loss: 0.408711, acc: 67.19%, op_acc: 40.62%] [G loss: 0.931752]\n",
      "epoch:11 step:8704[D loss: 0.445891, acc: 60.94%, op_acc: 39.84%] [G loss: 0.853447]\n",
      "epoch:11 step:8705[D loss: 0.398340, acc: 67.97%, op_acc: 41.41%] [G loss: 0.933549]\n",
      "epoch:11 step:8706[D loss: 0.438821, acc: 52.34%, op_acc: 35.16%] [G loss: 1.010976]\n",
      "epoch:11 step:8707[D loss: 0.465351, acc: 56.25%, op_acc: 32.03%] [G loss: 0.844729]\n",
      "epoch:11 step:8708[D loss: 0.435739, acc: 57.03%, op_acc: 37.50%] [G loss: 0.853575]\n",
      "epoch:11 step:8709[D loss: 0.441505, acc: 60.94%, op_acc: 32.81%] [G loss: 0.852943]\n",
      "epoch:11 step:8710[D loss: 0.456895, acc: 57.03%, op_acc: 34.38%] [G loss: 0.938532]\n",
      "epoch:11 step:8711[D loss: 0.436907, acc: 59.38%, op_acc: 38.28%] [G loss: 0.895091]\n",
      "epoch:11 step:8712[D loss: 0.465473, acc: 55.47%, op_acc: 33.59%] [G loss: 0.854013]\n",
      "epoch:11 step:8713[D loss: 0.433325, acc: 55.47%, op_acc: 40.62%] [G loss: 0.884484]\n",
      "epoch:11 step:8714[D loss: 0.439539, acc: 57.81%, op_acc: 33.59%] [G loss: 0.811186]\n",
      "epoch:11 step:8715[D loss: 0.435249, acc: 55.47%, op_acc: 34.38%] [G loss: 0.857026]\n",
      "epoch:11 step:8716[D loss: 0.479715, acc: 49.22%, op_acc: 29.69%] [G loss: 0.870246]\n",
      "epoch:11 step:8717[D loss: 0.401998, acc: 66.41%, op_acc: 40.62%] [G loss: 0.868563]\n",
      "epoch:11 step:8718[D loss: 0.436375, acc: 55.47%, op_acc: 35.94%] [G loss: 0.877967]\n",
      "epoch:11 step:8719[D loss: 0.462100, acc: 56.25%, op_acc: 35.16%] [G loss: 0.839334]\n",
      "epoch:11 step:8720[D loss: 0.454984, acc: 58.59%, op_acc: 35.16%] [G loss: 0.854910]\n",
      "epoch:11 step:8721[D loss: 0.423456, acc: 64.06%, op_acc: 37.50%] [G loss: 0.878277]\n",
      "epoch:11 step:8722[D loss: 0.428643, acc: 60.16%, op_acc: 37.50%] [G loss: 0.897187]\n",
      "epoch:11 step:8723[D loss: 0.411876, acc: 61.72%, op_acc: 41.41%] [G loss: 0.870661]\n",
      "epoch:11 step:8724[D loss: 0.440357, acc: 64.84%, op_acc: 32.03%] [G loss: 0.788939]\n",
      "epoch:11 step:8725[D loss: 0.436632, acc: 57.03%, op_acc: 39.06%] [G loss: 0.879593]\n",
      "epoch:11 step:8726[D loss: 0.431400, acc: 60.94%, op_acc: 38.28%] [G loss: 0.794189]\n",
      "epoch:11 step:8727[D loss: 0.439534, acc: 53.91%, op_acc: 35.94%] [G loss: 0.860869]\n",
      "epoch:11 step:8728[D loss: 0.433789, acc: 60.94%, op_acc: 36.72%] [G loss: 0.831026]\n",
      "epoch:11 step:8729[D loss: 0.458815, acc: 50.78%, op_acc: 30.47%] [G loss: 0.933891]\n",
      "epoch:11 step:8730[D loss: 0.447344, acc: 55.47%, op_acc: 35.94%] [G loss: 0.962902]\n",
      "epoch:11 step:8731[D loss: 0.485963, acc: 51.56%, op_acc: 29.69%] [G loss: 0.884239]\n",
      "epoch:11 step:8732[D loss: 0.438480, acc: 62.50%, op_acc: 32.03%] [G loss: 0.957914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8733[D loss: 0.414940, acc: 67.19%, op_acc: 33.59%] [G loss: 0.888584]\n",
      "epoch:11 step:8734[D loss: 0.456014, acc: 50.78%, op_acc: 31.25%] [G loss: 0.759906]\n",
      "epoch:11 step:8735[D loss: 0.471720, acc: 48.44%, op_acc: 32.81%] [G loss: 0.789426]\n",
      "epoch:11 step:8736[D loss: 0.445614, acc: 57.03%, op_acc: 35.16%] [G loss: 0.801163]\n",
      "epoch:11 step:8737[D loss: 0.421338, acc: 64.84%, op_acc: 35.16%] [G loss: 0.801473]\n",
      "epoch:11 step:8738[D loss: 0.442238, acc: 57.03%, op_acc: 35.16%] [G loss: 0.810976]\n",
      "epoch:11 step:8739[D loss: 0.436316, acc: 66.41%, op_acc: 37.50%] [G loss: 0.852360]\n",
      "epoch:11 step:8740[D loss: 0.412007, acc: 65.62%, op_acc: 41.41%] [G loss: 0.872866]\n",
      "epoch:11 step:8741[D loss: 0.460163, acc: 57.81%, op_acc: 32.03%] [G loss: 0.841628]\n",
      "epoch:11 step:8742[D loss: 0.440548, acc: 53.12%, op_acc: 38.28%] [G loss: 0.937420]\n",
      "epoch:11 step:8743[D loss: 0.461647, acc: 57.81%, op_acc: 28.91%] [G loss: 0.856862]\n",
      "epoch:11 step:8744[D loss: 0.463188, acc: 50.00%, op_acc: 32.03%] [G loss: 0.868582]\n",
      "epoch:11 step:8745[D loss: 0.431074, acc: 57.81%, op_acc: 37.50%] [G loss: 0.865300]\n",
      "epoch:11 step:8746[D loss: 0.421719, acc: 63.28%, op_acc: 38.28%] [G loss: 0.958064]\n",
      "epoch:11 step:8747[D loss: 0.452750, acc: 54.69%, op_acc: 36.72%] [G loss: 0.831447]\n",
      "epoch:11 step:8748[D loss: 0.424600, acc: 62.50%, op_acc: 32.03%] [G loss: 0.944812]\n",
      "epoch:11 step:8749[D loss: 0.425143, acc: 56.25%, op_acc: 40.62%] [G loss: 0.938472]\n",
      "epoch:11 step:8750[D loss: 0.430568, acc: 64.84%, op_acc: 41.41%] [G loss: 0.837058]\n",
      "##############\n",
      "[0.85910665 0.85598327 0.83190715 0.80670733 0.77711626 0.8404856\n",
      " 0.89755059 0.83221619 0.8189708  0.82003297]\n",
      "##########\n",
      "epoch:11 step:8751[D loss: 0.478439, acc: 57.03%, op_acc: 28.91%] [G loss: 0.867081]\n",
      "epoch:11 step:8752[D loss: 0.429135, acc: 61.72%, op_acc: 39.06%] [G loss: 0.889497]\n",
      "epoch:11 step:8753[D loss: 0.443967, acc: 57.81%, op_acc: 29.69%] [G loss: 0.863652]\n",
      "epoch:11 step:8754[D loss: 0.449229, acc: 56.25%, op_acc: 34.38%] [G loss: 0.846153]\n",
      "epoch:11 step:8755[D loss: 0.472349, acc: 51.56%, op_acc: 28.12%] [G loss: 0.929125]\n",
      "epoch:11 step:8756[D loss: 0.426259, acc: 57.81%, op_acc: 39.06%] [G loss: 0.842586]\n",
      "epoch:11 step:8757[D loss: 0.466504, acc: 54.69%, op_acc: 33.59%] [G loss: 0.799895]\n",
      "epoch:11 step:8758[D loss: 0.459518, acc: 55.47%, op_acc: 31.25%] [G loss: 0.813224]\n",
      "epoch:11 step:8759[D loss: 0.442292, acc: 49.22%, op_acc: 39.06%] [G loss: 0.901263]\n",
      "epoch:11 step:8760[D loss: 0.450080, acc: 56.25%, op_acc: 33.59%] [G loss: 0.965905]\n",
      "epoch:11 step:8761[D loss: 0.436243, acc: 60.16%, op_acc: 35.94%] [G loss: 0.923726]\n",
      "epoch:11 step:8762[D loss: 0.461273, acc: 50.78%, op_acc: 33.59%] [G loss: 0.914504]\n",
      "epoch:11 step:8763[D loss: 0.423252, acc: 62.50%, op_acc: 35.16%] [G loss: 0.852939]\n",
      "epoch:11 step:8764[D loss: 0.437608, acc: 56.25%, op_acc: 32.81%] [G loss: 0.900913]\n",
      "epoch:11 step:8765[D loss: 0.440125, acc: 57.03%, op_acc: 34.38%] [G loss: 0.959099]\n",
      "epoch:11 step:8766[D loss: 0.402438, acc: 65.62%, op_acc: 37.50%] [G loss: 0.873945]\n",
      "epoch:11 step:8767[D loss: 0.465419, acc: 55.47%, op_acc: 35.16%] [G loss: 0.915488]\n",
      "epoch:11 step:8768[D loss: 0.401596, acc: 65.62%, op_acc: 37.50%] [G loss: 0.953048]\n",
      "epoch:11 step:8769[D loss: 0.436013, acc: 61.72%, op_acc: 35.16%] [G loss: 0.838763]\n",
      "epoch:11 step:8770[D loss: 0.418408, acc: 64.84%, op_acc: 38.28%] [G loss: 0.898335]\n",
      "epoch:11 step:8771[D loss: 0.406004, acc: 67.19%, op_acc: 36.72%] [G loss: 0.882117]\n",
      "epoch:11 step:8772[D loss: 0.433031, acc: 54.69%, op_acc: 36.72%] [G loss: 0.810255]\n",
      "epoch:11 step:8773[D loss: 0.412558, acc: 65.62%, op_acc: 35.16%] [G loss: 0.873951]\n",
      "epoch:11 step:8774[D loss: 0.446175, acc: 59.38%, op_acc: 32.81%] [G loss: 0.903919]\n",
      "epoch:11 step:8775[D loss: 0.463624, acc: 56.25%, op_acc: 30.47%] [G loss: 0.932623]\n",
      "epoch:11 step:8776[D loss: 0.448926, acc: 62.50%, op_acc: 32.81%] [G loss: 0.825320]\n",
      "epoch:11 step:8777[D loss: 0.464938, acc: 47.66%, op_acc: 32.81%] [G loss: 0.874064]\n",
      "epoch:11 step:8778[D loss: 0.456499, acc: 43.75%, op_acc: 29.69%] [G loss: 0.860314]\n",
      "epoch:11 step:8779[D loss: 0.456911, acc: 50.78%, op_acc: 35.94%] [G loss: 0.909686]\n",
      "epoch:11 step:8780[D loss: 0.432031, acc: 58.59%, op_acc: 37.50%] [G loss: 0.863280]\n",
      "epoch:11 step:8781[D loss: 0.448692, acc: 61.72%, op_acc: 31.25%] [G loss: 0.885756]\n",
      "epoch:11 step:8782[D loss: 0.441650, acc: 57.81%, op_acc: 35.16%] [G loss: 0.864307]\n",
      "epoch:11 step:8783[D loss: 0.434794, acc: 62.50%, op_acc: 34.38%] [G loss: 0.866545]\n",
      "epoch:11 step:8784[D loss: 0.458290, acc: 62.50%, op_acc: 34.38%] [G loss: 0.861637]\n",
      "epoch:11 step:8785[D loss: 0.442030, acc: 56.25%, op_acc: 35.94%] [G loss: 0.886748]\n",
      "epoch:11 step:8786[D loss: 0.428468, acc: 62.50%, op_acc: 41.41%] [G loss: 0.834986]\n",
      "epoch:11 step:8787[D loss: 0.447033, acc: 61.72%, op_acc: 34.38%] [G loss: 0.862170]\n",
      "epoch:11 step:8788[D loss: 0.480552, acc: 49.22%, op_acc: 33.59%] [G loss: 0.854143]\n",
      "epoch:11 step:8789[D loss: 0.431507, acc: 60.16%, op_acc: 32.81%] [G loss: 0.856571]\n",
      "epoch:11 step:8790[D loss: 0.443854, acc: 54.69%, op_acc: 35.16%] [G loss: 0.933234]\n",
      "epoch:11 step:8791[D loss: 0.453564, acc: 59.38%, op_acc: 34.38%] [G loss: 0.827056]\n",
      "epoch:11 step:8792[D loss: 0.411270, acc: 58.59%, op_acc: 36.72%] [G loss: 0.974947]\n",
      "epoch:11 step:8793[D loss: 0.459869, acc: 59.38%, op_acc: 35.94%] [G loss: 0.893400]\n",
      "epoch:11 step:8794[D loss: 0.481488, acc: 50.78%, op_acc: 31.25%] [G loss: 0.822515]\n",
      "epoch:11 step:8795[D loss: 0.453409, acc: 51.56%, op_acc: 32.81%] [G loss: 0.896098]\n",
      "epoch:11 step:8796[D loss: 0.440010, acc: 60.16%, op_acc: 32.81%] [G loss: 0.821737]\n",
      "epoch:11 step:8797[D loss: 0.462660, acc: 54.69%, op_acc: 32.03%] [G loss: 0.868451]\n",
      "epoch:11 step:8798[D loss: 0.422549, acc: 64.84%, op_acc: 39.84%] [G loss: 0.962474]\n",
      "epoch:11 step:8799[D loss: 0.458185, acc: 53.91%, op_acc: 35.16%] [G loss: 0.846831]\n",
      "epoch:11 step:8800[D loss: 0.449394, acc: 56.25%, op_acc: 35.94%] [G loss: 0.919761]\n",
      "##############\n",
      "[0.8673741  0.8598912  0.79948143 0.81731205 0.79458816 0.83637664\n",
      " 0.87376676 0.86242022 0.83155196 0.83964863]\n",
      "##########\n",
      "epoch:11 step:8801[D loss: 0.449387, acc: 53.91%, op_acc: 39.06%] [G loss: 0.815396]\n",
      "epoch:11 step:8802[D loss: 0.404669, acc: 67.97%, op_acc: 39.84%] [G loss: 0.857153]\n",
      "epoch:11 step:8803[D loss: 0.422163, acc: 62.50%, op_acc: 33.59%] [G loss: 0.851325]\n",
      "epoch:11 step:8804[D loss: 0.440653, acc: 56.25%, op_acc: 36.72%] [G loss: 0.879709]\n",
      "epoch:11 step:8805[D loss: 0.464900, acc: 60.94%, op_acc: 34.38%] [G loss: 0.891456]\n",
      "epoch:11 step:8806[D loss: 0.424822, acc: 70.31%, op_acc: 31.25%] [G loss: 0.888670]\n",
      "epoch:11 step:8807[D loss: 0.458029, acc: 56.25%, op_acc: 35.16%] [G loss: 0.881117]\n",
      "epoch:11 step:8808[D loss: 0.437629, acc: 53.12%, op_acc: 42.19%] [G loss: 0.890251]\n",
      "epoch:11 step:8809[D loss: 0.452804, acc: 54.69%, op_acc: 37.50%] [G loss: 0.905837]\n",
      "epoch:11 step:8810[D loss: 0.423257, acc: 63.28%, op_acc: 39.06%] [G loss: 0.895536]\n",
      "epoch:11 step:8811[D loss: 0.433273, acc: 57.81%, op_acc: 34.38%] [G loss: 0.795774]\n",
      "epoch:11 step:8812[D loss: 0.433414, acc: 61.72%, op_acc: 30.47%] [G loss: 0.849875]\n",
      "epoch:11 step:8813[D loss: 0.457999, acc: 53.12%, op_acc: 34.38%] [G loss: 0.803508]\n",
      "epoch:11 step:8814[D loss: 0.466631, acc: 51.56%, op_acc: 33.59%] [G loss: 0.807931]\n",
      "epoch:11 step:8815[D loss: 0.436271, acc: 59.38%, op_acc: 33.59%] [G loss: 0.875445]\n",
      "epoch:11 step:8816[D loss: 0.449097, acc: 56.25%, op_acc: 38.28%] [G loss: 0.858556]\n",
      "epoch:11 step:8817[D loss: 0.437529, acc: 62.50%, op_acc: 34.38%] [G loss: 0.870131]\n",
      "epoch:11 step:8818[D loss: 0.427606, acc: 63.28%, op_acc: 34.38%] [G loss: 0.847378]\n",
      "epoch:11 step:8819[D loss: 0.454584, acc: 47.66%, op_acc: 36.72%] [G loss: 0.809396]\n",
      "epoch:11 step:8820[D loss: 0.431305, acc: 60.94%, op_acc: 36.72%] [G loss: 0.943956]\n",
      "epoch:11 step:8821[D loss: 0.465114, acc: 50.00%, op_acc: 34.38%] [G loss: 0.843919]\n",
      "epoch:11 step:8822[D loss: 0.415999, acc: 63.28%, op_acc: 40.62%] [G loss: 0.924717]\n",
      "epoch:11 step:8823[D loss: 0.443404, acc: 53.91%, op_acc: 36.72%] [G loss: 0.907528]\n",
      "epoch:11 step:8824[D loss: 0.433999, acc: 60.94%, op_acc: 34.38%] [G loss: 0.860209]\n",
      "epoch:11 step:8825[D loss: 0.463422, acc: 56.25%, op_acc: 35.94%] [G loss: 0.932818]\n",
      "epoch:11 step:8826[D loss: 0.437449, acc: 54.69%, op_acc: 39.06%] [G loss: 0.889053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8827[D loss: 0.445824, acc: 54.69%, op_acc: 33.59%] [G loss: 0.866320]\n",
      "epoch:11 step:8828[D loss: 0.422434, acc: 68.75%, op_acc: 36.72%] [G loss: 0.956583]\n",
      "epoch:11 step:8829[D loss: 0.441503, acc: 60.94%, op_acc: 36.72%] [G loss: 0.881153]\n",
      "epoch:11 step:8830[D loss: 0.426740, acc: 59.38%, op_acc: 39.84%] [G loss: 0.903244]\n",
      "epoch:11 step:8831[D loss: 0.429614, acc: 57.81%, op_acc: 34.38%] [G loss: 0.867656]\n",
      "epoch:11 step:8832[D loss: 0.473167, acc: 51.56%, op_acc: 32.81%] [G loss: 0.837737]\n",
      "epoch:11 step:8833[D loss: 0.430583, acc: 60.94%, op_acc: 34.38%] [G loss: 0.874254]\n",
      "epoch:11 step:8834[D loss: 0.446064, acc: 51.56%, op_acc: 34.38%] [G loss: 0.926142]\n",
      "epoch:11 step:8835[D loss: 0.446347, acc: 58.59%, op_acc: 32.03%] [G loss: 0.849712]\n",
      "epoch:11 step:8836[D loss: 0.430729, acc: 59.38%, op_acc: 38.28%] [G loss: 0.908108]\n",
      "epoch:11 step:8837[D loss: 0.448837, acc: 55.47%, op_acc: 32.81%] [G loss: 0.871096]\n",
      "epoch:11 step:8838[D loss: 0.434847, acc: 54.69%, op_acc: 37.50%] [G loss: 0.939424]\n",
      "epoch:11 step:8839[D loss: 0.462509, acc: 50.78%, op_acc: 32.81%] [G loss: 0.892345]\n",
      "epoch:11 step:8840[D loss: 0.470973, acc: 53.91%, op_acc: 32.81%] [G loss: 0.918435]\n",
      "epoch:11 step:8841[D loss: 0.433369, acc: 60.16%, op_acc: 30.47%] [G loss: 0.890973]\n",
      "epoch:11 step:8842[D loss: 0.424323, acc: 58.59%, op_acc: 40.62%] [G loss: 0.852435]\n",
      "epoch:11 step:8843[D loss: 0.439510, acc: 60.94%, op_acc: 39.84%] [G loss: 0.860067]\n",
      "epoch:11 step:8844[D loss: 0.444864, acc: 56.25%, op_acc: 29.69%] [G loss: 0.833082]\n",
      "epoch:11 step:8845[D loss: 0.452133, acc: 59.38%, op_acc: 34.38%] [G loss: 0.900231]\n",
      "epoch:11 step:8846[D loss: 0.446915, acc: 54.69%, op_acc: 35.16%] [G loss: 0.908944]\n",
      "epoch:11 step:8847[D loss: 0.443046, acc: 56.25%, op_acc: 34.38%] [G loss: 0.873123]\n",
      "epoch:11 step:8848[D loss: 0.432511, acc: 61.72%, op_acc: 34.38%] [G loss: 0.873863]\n",
      "epoch:11 step:8849[D loss: 0.399691, acc: 73.44%, op_acc: 40.62%] [G loss: 0.893468]\n",
      "epoch:11 step:8850[D loss: 0.448936, acc: 54.69%, op_acc: 29.69%] [G loss: 0.855299]\n",
      "##############\n",
      "[0.84420035 0.85700762 0.80658933 0.79370267 0.77605368 0.83947234\n",
      " 0.91223365 0.82085098 0.81577898 0.83077535]\n",
      "##########\n",
      "epoch:11 step:8851[D loss: 0.424919, acc: 63.28%, op_acc: 34.38%] [G loss: 0.885968]\n",
      "epoch:11 step:8852[D loss: 0.442397, acc: 55.47%, op_acc: 35.16%] [G loss: 0.899993]\n",
      "epoch:11 step:8853[D loss: 0.420008, acc: 59.38%, op_acc: 36.72%] [G loss: 0.857547]\n",
      "epoch:11 step:8854[D loss: 0.438875, acc: 53.91%, op_acc: 35.16%] [G loss: 0.922537]\n",
      "epoch:11 step:8855[D loss: 0.451831, acc: 54.69%, op_acc: 37.50%] [G loss: 0.836754]\n",
      "epoch:11 step:8856[D loss: 0.404935, acc: 60.16%, op_acc: 38.28%] [G loss: 0.963988]\n",
      "epoch:11 step:8857[D loss: 0.433166, acc: 57.81%, op_acc: 35.94%] [G loss: 0.841966]\n",
      "epoch:11 step:8858[D loss: 0.454769, acc: 56.25%, op_acc: 34.38%] [G loss: 0.898755]\n",
      "epoch:11 step:8859[D loss: 0.418202, acc: 60.16%, op_acc: 39.06%] [G loss: 0.893726]\n",
      "epoch:11 step:8860[D loss: 0.441594, acc: 49.22%, op_acc: 39.84%] [G loss: 0.852298]\n",
      "epoch:11 step:8861[D loss: 0.440019, acc: 57.03%, op_acc: 36.72%] [G loss: 0.832567]\n",
      "epoch:11 step:8862[D loss: 0.441532, acc: 60.94%, op_acc: 33.59%] [G loss: 0.903972]\n",
      "epoch:11 step:8863[D loss: 0.438357, acc: 61.72%, op_acc: 37.50%] [G loss: 0.828670]\n",
      "epoch:11 step:8864[D loss: 0.421294, acc: 60.94%, op_acc: 40.62%] [G loss: 0.875072]\n",
      "epoch:11 step:8865[D loss: 0.445025, acc: 50.78%, op_acc: 31.25%] [G loss: 0.799400]\n",
      "epoch:11 step:8866[D loss: 0.446318, acc: 53.12%, op_acc: 29.69%] [G loss: 0.772719]\n",
      "epoch:11 step:8867[D loss: 0.453093, acc: 52.34%, op_acc: 35.94%] [G loss: 0.836744]\n",
      "epoch:11 step:8868[D loss: 0.471513, acc: 50.78%, op_acc: 34.38%] [G loss: 0.846579]\n",
      "epoch:11 step:8869[D loss: 0.462772, acc: 52.34%, op_acc: 32.81%] [G loss: 0.814246]\n",
      "epoch:11 step:8870[D loss: 0.458795, acc: 61.72%, op_acc: 33.59%] [G loss: 0.879731]\n",
      "epoch:11 step:8871[D loss: 0.448846, acc: 52.34%, op_acc: 32.03%] [G loss: 0.783710]\n",
      "epoch:11 step:8872[D loss: 0.485222, acc: 52.34%, op_acc: 31.25%] [G loss: 0.839550]\n",
      "epoch:11 step:8873[D loss: 0.457662, acc: 54.69%, op_acc: 35.16%] [G loss: 0.838807]\n",
      "epoch:11 step:8874[D loss: 0.422107, acc: 63.28%, op_acc: 39.06%] [G loss: 0.871628]\n",
      "epoch:11 step:8875[D loss: 0.442376, acc: 57.03%, op_acc: 32.81%] [G loss: 0.851402]\n",
      "epoch:11 step:8876[D loss: 0.454374, acc: 53.12%, op_acc: 29.69%] [G loss: 0.854932]\n",
      "epoch:11 step:8877[D loss: 0.426604, acc: 65.62%, op_acc: 35.16%] [G loss: 0.882134]\n",
      "epoch:11 step:8878[D loss: 0.462475, acc: 53.12%, op_acc: 35.16%] [G loss: 0.901846]\n",
      "epoch:11 step:8879[D loss: 0.430232, acc: 59.38%, op_acc: 41.41%] [G loss: 0.839507]\n",
      "epoch:11 step:8880[D loss: 0.463036, acc: 60.94%, op_acc: 32.81%] [G loss: 0.786018]\n",
      "epoch:11 step:8881[D loss: 0.447403, acc: 55.47%, op_acc: 38.28%] [G loss: 0.917289]\n",
      "epoch:11 step:8882[D loss: 0.439513, acc: 57.81%, op_acc: 36.72%] [G loss: 0.918352]\n",
      "epoch:11 step:8883[D loss: 0.454066, acc: 54.69%, op_acc: 33.59%] [G loss: 0.843095]\n",
      "epoch:11 step:8884[D loss: 0.468002, acc: 52.34%, op_acc: 39.06%] [G loss: 0.818033]\n",
      "epoch:11 step:8885[D loss: 0.432185, acc: 66.41%, op_acc: 32.03%] [G loss: 0.884897]\n",
      "epoch:11 step:8886[D loss: 0.437547, acc: 56.25%, op_acc: 33.59%] [G loss: 0.898048]\n",
      "epoch:11 step:8887[D loss: 0.431278, acc: 58.59%, op_acc: 40.62%] [G loss: 0.869423]\n",
      "epoch:11 step:8888[D loss: 0.466516, acc: 56.25%, op_acc: 29.69%] [G loss: 0.866071]\n",
      "epoch:11 step:8889[D loss: 0.416780, acc: 70.31%, op_acc: 36.72%] [G loss: 0.875306]\n",
      "epoch:11 step:8890[D loss: 0.437366, acc: 58.59%, op_acc: 28.91%] [G loss: 0.878118]\n",
      "epoch:11 step:8891[D loss: 0.447111, acc: 60.16%, op_acc: 30.47%] [G loss: 0.836082]\n",
      "epoch:11 step:8892[D loss: 0.465524, acc: 52.34%, op_acc: 37.50%] [G loss: 0.853912]\n",
      "epoch:11 step:8893[D loss: 0.426826, acc: 60.16%, op_acc: 39.06%] [G loss: 0.871615]\n",
      "epoch:11 step:8894[D loss: 0.431687, acc: 65.62%, op_acc: 34.38%] [G loss: 0.916297]\n",
      "epoch:11 step:8895[D loss: 0.406861, acc: 64.84%, op_acc: 39.84%] [G loss: 0.864879]\n",
      "epoch:11 step:8896[D loss: 0.424553, acc: 60.16%, op_acc: 35.94%] [G loss: 0.914387]\n",
      "epoch:11 step:8897[D loss: 0.471908, acc: 57.03%, op_acc: 33.59%] [G loss: 0.898292]\n",
      "epoch:11 step:8898[D loss: 0.435939, acc: 53.12%, op_acc: 35.16%] [G loss: 0.885585]\n",
      "epoch:11 step:8899[D loss: 0.456396, acc: 53.91%, op_acc: 37.50%] [G loss: 0.865795]\n",
      "epoch:11 step:8900[D loss: 0.455446, acc: 62.50%, op_acc: 32.81%] [G loss: 0.892636]\n",
      "##############\n",
      "[0.8632037  0.85917514 0.80370398 0.81786553 0.76387286 0.81111643\n",
      " 0.91222094 0.82225639 0.8136173  0.84863684]\n",
      "##########\n",
      "epoch:11 step:8901[D loss: 0.430668, acc: 57.03%, op_acc: 35.94%] [G loss: 0.835652]\n",
      "epoch:11 step:8902[D loss: 0.426036, acc: 64.06%, op_acc: 34.38%] [G loss: 0.760066]\n",
      "epoch:11 step:8903[D loss: 0.457296, acc: 57.81%, op_acc: 34.38%] [G loss: 0.864708]\n",
      "epoch:11 step:8904[D loss: 0.457071, acc: 53.12%, op_acc: 35.16%] [G loss: 0.840755]\n",
      "epoch:11 step:8905[D loss: 0.458950, acc: 56.25%, op_acc: 30.47%] [G loss: 0.840944]\n",
      "epoch:11 step:8906[D loss: 0.462549, acc: 47.66%, op_acc: 34.38%] [G loss: 0.862146]\n",
      "epoch:11 step:8907[D loss: 0.439127, acc: 55.47%, op_acc: 34.38%] [G loss: 0.861461]\n",
      "epoch:11 step:8908[D loss: 0.434705, acc: 63.28%, op_acc: 38.28%] [G loss: 0.839485]\n",
      "epoch:11 step:8909[D loss: 0.442720, acc: 60.94%, op_acc: 28.91%] [G loss: 0.858437]\n",
      "epoch:11 step:8910[D loss: 0.441081, acc: 57.81%, op_acc: 36.72%] [G loss: 0.859556]\n",
      "epoch:11 step:8911[D loss: 0.439992, acc: 62.50%, op_acc: 32.81%] [G loss: 0.894390]\n",
      "epoch:11 step:8912[D loss: 0.481768, acc: 48.44%, op_acc: 32.81%] [G loss: 0.820867]\n",
      "epoch:11 step:8913[D loss: 0.466501, acc: 55.47%, op_acc: 35.94%] [G loss: 0.797995]\n",
      "epoch:11 step:8914[D loss: 0.449427, acc: 56.25%, op_acc: 39.06%] [G loss: 0.861767]\n",
      "epoch:11 step:8915[D loss: 0.444458, acc: 57.81%, op_acc: 35.94%] [G loss: 0.813276]\n",
      "epoch:11 step:8916[D loss: 0.421838, acc: 63.28%, op_acc: 35.94%] [G loss: 0.893950]\n",
      "epoch:11 step:8917[D loss: 0.436315, acc: 62.50%, op_acc: 39.06%] [G loss: 0.871727]\n",
      "epoch:11 step:8918[D loss: 0.414352, acc: 66.41%, op_acc: 41.41%] [G loss: 0.828307]\n",
      "epoch:11 step:8919[D loss: 0.444213, acc: 53.91%, op_acc: 32.03%] [G loss: 0.899005]\n",
      "epoch:11 step:8920[D loss: 0.431542, acc: 64.06%, op_acc: 34.38%] [G loss: 0.911284]\n",
      "epoch:11 step:8921[D loss: 0.427815, acc: 59.38%, op_acc: 39.06%] [G loss: 0.833788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8922[D loss: 0.430177, acc: 60.16%, op_acc: 37.50%] [G loss: 0.881226]\n",
      "epoch:11 step:8923[D loss: 0.404174, acc: 66.41%, op_acc: 39.06%] [G loss: 0.907664]\n",
      "epoch:11 step:8924[D loss: 0.420974, acc: 67.19%, op_acc: 40.62%] [G loss: 0.882472]\n",
      "epoch:11 step:8925[D loss: 0.453062, acc: 55.47%, op_acc: 35.16%] [G loss: 0.821839]\n",
      "epoch:11 step:8926[D loss: 0.442182, acc: 61.72%, op_acc: 32.81%] [G loss: 0.856085]\n",
      "epoch:11 step:8927[D loss: 0.429717, acc: 60.94%, op_acc: 35.16%] [G loss: 0.917773]\n",
      "epoch:11 step:8928[D loss: 0.468657, acc: 51.56%, op_acc: 32.81%] [G loss: 0.887178]\n",
      "epoch:11 step:8929[D loss: 0.402874, acc: 60.94%, op_acc: 39.84%] [G loss: 0.886004]\n",
      "epoch:11 step:8930[D loss: 0.444844, acc: 62.50%, op_acc: 34.38%] [G loss: 0.961203]\n",
      "epoch:11 step:8931[D loss: 0.438954, acc: 59.38%, op_acc: 34.38%] [G loss: 0.877390]\n",
      "epoch:11 step:8932[D loss: 0.455697, acc: 58.59%, op_acc: 38.28%] [G loss: 0.822632]\n",
      "epoch:11 step:8933[D loss: 0.483674, acc: 51.56%, op_acc: 32.03%] [G loss: 0.801539]\n",
      "epoch:11 step:8934[D loss: 0.461086, acc: 55.47%, op_acc: 31.25%] [G loss: 0.887998]\n",
      "epoch:11 step:8935[D loss: 0.454304, acc: 54.69%, op_acc: 38.28%] [G loss: 0.831290]\n",
      "epoch:11 step:8936[D loss: 0.444510, acc: 59.38%, op_acc: 32.03%] [G loss: 0.829790]\n",
      "epoch:11 step:8937[D loss: 0.437661, acc: 60.16%, op_acc: 29.69%] [G loss: 0.909634]\n",
      "epoch:11 step:8938[D loss: 0.453365, acc: 50.00%, op_acc: 39.84%] [G loss: 0.923303]\n",
      "epoch:11 step:8939[D loss: 0.413968, acc: 67.19%, op_acc: 36.72%] [G loss: 0.915377]\n",
      "epoch:11 step:8940[D loss: 0.443261, acc: 60.16%, op_acc: 35.94%] [G loss: 0.874341]\n",
      "epoch:11 step:8941[D loss: 0.454214, acc: 55.47%, op_acc: 32.81%] [G loss: 0.892028]\n",
      "epoch:11 step:8942[D loss: 0.445585, acc: 59.38%, op_acc: 35.16%] [G loss: 0.874820]\n",
      "epoch:11 step:8943[D loss: 0.424054, acc: 64.84%, op_acc: 33.59%] [G loss: 0.838929]\n",
      "epoch:11 step:8944[D loss: 0.412756, acc: 59.38%, op_acc: 42.19%] [G loss: 0.873296]\n",
      "epoch:11 step:8945[D loss: 0.437869, acc: 56.25%, op_acc: 38.28%] [G loss: 0.851847]\n",
      "epoch:11 step:8946[D loss: 0.428613, acc: 58.59%, op_acc: 32.81%] [G loss: 0.902689]\n",
      "epoch:11 step:8947[D loss: 0.410029, acc: 63.28%, op_acc: 45.31%] [G loss: 0.892244]\n",
      "epoch:11 step:8948[D loss: 0.446322, acc: 57.03%, op_acc: 34.38%] [G loss: 0.857682]\n",
      "epoch:11 step:8949[D loss: 0.442538, acc: 57.03%, op_acc: 42.19%] [G loss: 0.796929]\n",
      "epoch:11 step:8950[D loss: 0.448049, acc: 57.81%, op_acc: 31.25%] [G loss: 0.821068]\n",
      "##############\n",
      "[0.85112974 0.86522816 0.80837949 0.81075327 0.78850863 0.82130423\n",
      " 0.87782281 0.82396266 0.8111962  0.84550001]\n",
      "##########\n",
      "epoch:11 step:8951[D loss: 0.432080, acc: 61.72%, op_acc: 34.38%] [G loss: 0.858387]\n",
      "epoch:11 step:8952[D loss: 0.433024, acc: 55.47%, op_acc: 35.16%] [G loss: 0.824694]\n",
      "epoch:11 step:8953[D loss: 0.413462, acc: 56.25%, op_acc: 40.62%] [G loss: 0.798393]\n",
      "epoch:11 step:8954[D loss: 0.430250, acc: 61.72%, op_acc: 34.38%] [G loss: 0.817389]\n",
      "epoch:11 step:8955[D loss: 0.443630, acc: 58.59%, op_acc: 36.72%] [G loss: 0.873073]\n",
      "epoch:11 step:8956[D loss: 0.396069, acc: 65.62%, op_acc: 39.84%] [G loss: 0.898846]\n",
      "epoch:11 step:8957[D loss: 0.402931, acc: 65.62%, op_acc: 39.84%] [G loss: 0.836424]\n",
      "epoch:11 step:8958[D loss: 0.457999, acc: 57.81%, op_acc: 29.69%] [G loss: 0.859696]\n",
      "epoch:11 step:8959[D loss: 0.424594, acc: 67.97%, op_acc: 34.38%] [G loss: 0.825984]\n",
      "epoch:11 step:8960[D loss: 0.443650, acc: 56.25%, op_acc: 35.94%] [G loss: 0.860222]\n",
      "epoch:11 step:8961[D loss: 0.461947, acc: 53.91%, op_acc: 36.72%] [G loss: 0.840641]\n",
      "epoch:11 step:8962[D loss: 0.392547, acc: 68.75%, op_acc: 37.50%] [G loss: 0.849275]\n",
      "epoch:11 step:8963[D loss: 0.458822, acc: 50.78%, op_acc: 35.16%] [G loss: 0.851070]\n",
      "epoch:11 step:8964[D loss: 0.443676, acc: 57.81%, op_acc: 32.81%] [G loss: 0.950268]\n",
      "epoch:11 step:8965[D loss: 0.426752, acc: 60.94%, op_acc: 36.72%] [G loss: 0.925078]\n",
      "epoch:11 step:8966[D loss: 0.428432, acc: 57.81%, op_acc: 34.38%] [G loss: 0.860919]\n",
      "epoch:11 step:8967[D loss: 0.430643, acc: 57.81%, op_acc: 32.81%] [G loss: 0.841801]\n",
      "epoch:11 step:8968[D loss: 0.457460, acc: 51.56%, op_acc: 33.59%] [G loss: 0.900740]\n",
      "epoch:11 step:8969[D loss: 0.433616, acc: 62.50%, op_acc: 35.94%] [G loss: 0.899931]\n",
      "epoch:11 step:8970[D loss: 0.414150, acc: 61.72%, op_acc: 39.06%] [G loss: 0.832075]\n",
      "epoch:11 step:8971[D loss: 0.424073, acc: 67.97%, op_acc: 37.50%] [G loss: 0.859789]\n",
      "epoch:11 step:8972[D loss: 0.434415, acc: 57.81%, op_acc: 37.50%] [G loss: 0.868652]\n",
      "epoch:11 step:8973[D loss: 0.433011, acc: 61.72%, op_acc: 34.38%] [G loss: 0.877930]\n",
      "epoch:11 step:8974[D loss: 0.399765, acc: 67.19%, op_acc: 43.75%] [G loss: 0.923944]\n",
      "epoch:11 step:8975[D loss: 0.432755, acc: 57.03%, op_acc: 32.81%] [G loss: 0.840818]\n",
      "epoch:11 step:8976[D loss: 0.418187, acc: 62.50%, op_acc: 41.41%] [G loss: 0.903240]\n",
      "epoch:11 step:8977[D loss: 0.414183, acc: 57.81%, op_acc: 37.50%] [G loss: 0.867651]\n",
      "epoch:11 step:8978[D loss: 0.433944, acc: 60.94%, op_acc: 35.94%] [G loss: 0.873144]\n",
      "epoch:11 step:8979[D loss: 0.428870, acc: 65.62%, op_acc: 32.81%] [G loss: 0.840021]\n",
      "epoch:11 step:8980[D loss: 0.448506, acc: 55.47%, op_acc: 33.59%] [G loss: 0.911450]\n",
      "epoch:11 step:8981[D loss: 0.433817, acc: 59.38%, op_acc: 35.16%] [G loss: 0.893469]\n",
      "epoch:11 step:8982[D loss: 0.443862, acc: 59.38%, op_acc: 35.94%] [G loss: 0.849366]\n",
      "epoch:11 step:8983[D loss: 0.447088, acc: 50.78%, op_acc: 39.84%] [G loss: 0.857991]\n",
      "epoch:11 step:8984[D loss: 0.443997, acc: 53.12%, op_acc: 35.94%] [G loss: 0.829064]\n",
      "epoch:11 step:8985[D loss: 0.430783, acc: 61.72%, op_acc: 36.72%] [G loss: 0.927530]\n",
      "epoch:11 step:8986[D loss: 0.485639, acc: 53.12%, op_acc: 33.59%] [G loss: 0.822899]\n",
      "epoch:11 step:8987[D loss: 0.410871, acc: 67.19%, op_acc: 37.50%] [G loss: 0.834226]\n",
      "epoch:11 step:8988[D loss: 0.441218, acc: 56.25%, op_acc: 33.59%] [G loss: 0.920753]\n",
      "epoch:11 step:8989[D loss: 0.475691, acc: 57.03%, op_acc: 32.81%] [G loss: 0.884896]\n",
      "epoch:11 step:8990[D loss: 0.449719, acc: 55.47%, op_acc: 34.38%] [G loss: 0.909247]\n",
      "epoch:11 step:8991[D loss: 0.427183, acc: 57.81%, op_acc: 35.94%] [G loss: 0.855095]\n",
      "epoch:11 step:8992[D loss: 0.445593, acc: 50.78%, op_acc: 35.94%] [G loss: 0.839790]\n",
      "epoch:11 step:8993[D loss: 0.442396, acc: 59.38%, op_acc: 35.16%] [G loss: 0.857558]\n",
      "epoch:11 step:8994[D loss: 0.401348, acc: 64.06%, op_acc: 40.62%] [G loss: 0.921105]\n",
      "epoch:11 step:8995[D loss: 0.403155, acc: 64.84%, op_acc: 43.75%] [G loss: 0.888055]\n",
      "epoch:11 step:8996[D loss: 0.454263, acc: 59.38%, op_acc: 35.94%] [G loss: 0.949497]\n",
      "epoch:11 step:8997[D loss: 0.421757, acc: 60.94%, op_acc: 39.06%] [G loss: 0.939039]\n",
      "epoch:11 step:8998[D loss: 0.437346, acc: 58.59%, op_acc: 32.81%] [G loss: 0.834977]\n",
      "epoch:11 step:8999[D loss: 0.430405, acc: 60.16%, op_acc: 39.84%] [G loss: 0.879717]\n",
      "epoch:11 step:9000[D loss: 0.447859, acc: 61.72%, op_acc: 35.16%] [G loss: 0.828231]\n",
      "##############\n",
      "[0.85401559 0.86762041 0.82771593 0.79647409 0.82986299 0.80274863\n",
      " 0.90560215 0.82010533 0.81003436 0.82120129]\n",
      "##########\n",
      "epoch:11 step:9001[D loss: 0.417457, acc: 58.59%, op_acc: 41.41%] [G loss: 0.860899]\n",
      "epoch:11 step:9002[D loss: 0.443572, acc: 60.16%, op_acc: 38.28%] [G loss: 0.807370]\n",
      "epoch:11 step:9003[D loss: 0.421738, acc: 57.03%, op_acc: 37.50%] [G loss: 0.904686]\n",
      "epoch:11 step:9004[D loss: 0.453032, acc: 53.12%, op_acc: 39.06%] [G loss: 0.871928]\n",
      "epoch:11 step:9005[D loss: 0.454578, acc: 53.91%, op_acc: 35.16%] [G loss: 0.843490]\n",
      "epoch:11 step:9006[D loss: 0.473411, acc: 52.34%, op_acc: 32.03%] [G loss: 0.870692]\n",
      "epoch:11 step:9007[D loss: 0.432380, acc: 60.16%, op_acc: 37.50%] [G loss: 0.893848]\n",
      "epoch:11 step:9008[D loss: 0.455414, acc: 53.12%, op_acc: 37.50%] [G loss: 0.886262]\n",
      "epoch:11 step:9009[D loss: 0.444866, acc: 60.94%, op_acc: 31.25%] [G loss: 0.871762]\n",
      "epoch:11 step:9010[D loss: 0.445176, acc: 56.25%, op_acc: 35.16%] [G loss: 0.879385]\n",
      "epoch:11 step:9011[D loss: 0.452877, acc: 55.47%, op_acc: 34.38%] [G loss: 0.847819]\n",
      "epoch:11 step:9012[D loss: 0.449316, acc: 60.94%, op_acc: 37.50%] [G loss: 0.885363]\n",
      "epoch:11 step:9013[D loss: 0.422800, acc: 63.28%, op_acc: 35.16%] [G loss: 0.941235]\n",
      "epoch:11 step:9014[D loss: 0.443886, acc: 60.94%, op_acc: 38.28%] [G loss: 0.825783]\n",
      "epoch:11 step:9015[D loss: 0.436670, acc: 64.06%, op_acc: 33.59%] [G loss: 0.915016]\n",
      "epoch:11 step:9016[D loss: 0.482112, acc: 51.56%, op_acc: 35.94%] [G loss: 0.827428]\n",
      "epoch:11 step:9017[D loss: 0.473238, acc: 52.34%, op_acc: 31.25%] [G loss: 0.813210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9018[D loss: 0.447165, acc: 57.03%, op_acc: 33.59%] [G loss: 0.881092]\n",
      "epoch:11 step:9019[D loss: 0.436567, acc: 60.16%, op_acc: 33.59%] [G loss: 0.852023]\n",
      "epoch:11 step:9020[D loss: 0.439407, acc: 58.59%, op_acc: 36.72%] [G loss: 0.852862]\n",
      "epoch:11 step:9021[D loss: 0.418121, acc: 64.06%, op_acc: 36.72%] [G loss: 0.909814]\n",
      "epoch:11 step:9022[D loss: 0.446853, acc: 57.03%, op_acc: 33.59%] [G loss: 0.868077]\n",
      "epoch:11 step:9023[D loss: 0.417067, acc: 58.59%, op_acc: 38.28%] [G loss: 0.871725]\n",
      "epoch:11 step:9024[D loss: 0.426520, acc: 64.84%, op_acc: 36.72%] [G loss: 0.932838]\n",
      "epoch:11 step:9025[D loss: 0.441422, acc: 54.69%, op_acc: 36.72%] [G loss: 0.844824]\n",
      "epoch:11 step:9026[D loss: 0.425161, acc: 60.16%, op_acc: 37.50%] [G loss: 0.867435]\n",
      "epoch:11 step:9027[D loss: 0.450043, acc: 55.47%, op_acc: 36.72%] [G loss: 0.850473]\n",
      "epoch:11 step:9028[D loss: 0.457997, acc: 50.78%, op_acc: 36.72%] [G loss: 0.863732]\n",
      "epoch:11 step:9029[D loss: 0.455127, acc: 50.00%, op_acc: 32.81%] [G loss: 0.837799]\n",
      "epoch:11 step:9030[D loss: 0.404078, acc: 69.53%, op_acc: 38.28%] [G loss: 0.930675]\n",
      "epoch:11 step:9031[D loss: 0.431323, acc: 61.72%, op_acc: 35.94%] [G loss: 0.874271]\n",
      "epoch:11 step:9032[D loss: 0.422793, acc: 67.97%, op_acc: 35.16%] [G loss: 0.863764]\n",
      "epoch:11 step:9033[D loss: 0.428998, acc: 60.16%, op_acc: 39.84%] [G loss: 0.834832]\n",
      "epoch:11 step:9034[D loss: 0.434057, acc: 57.03%, op_acc: 37.50%] [G loss: 0.828278]\n",
      "epoch:11 step:9035[D loss: 0.432826, acc: 53.91%, op_acc: 35.16%] [G loss: 0.864972]\n",
      "epoch:11 step:9036[D loss: 0.465302, acc: 50.78%, op_acc: 32.81%] [G loss: 0.859089]\n",
      "epoch:11 step:9037[D loss: 0.456516, acc: 55.47%, op_acc: 33.59%] [G loss: 0.848894]\n",
      "epoch:11 step:9038[D loss: 0.480450, acc: 56.25%, op_acc: 29.69%] [G loss: 0.832111]\n",
      "epoch:11 step:9039[D loss: 0.404048, acc: 64.06%, op_acc: 42.19%] [G loss: 0.867644]\n",
      "epoch:11 step:9040[D loss: 0.444921, acc: 53.12%, op_acc: 34.38%] [G loss: 0.827108]\n",
      "epoch:11 step:9041[D loss: 0.436398, acc: 59.38%, op_acc: 36.72%] [G loss: 0.858150]\n",
      "epoch:11 step:9042[D loss: 0.464885, acc: 42.19%, op_acc: 39.84%] [G loss: 0.851416]\n",
      "epoch:11 step:9043[D loss: 0.429454, acc: 55.47%, op_acc: 33.59%] [G loss: 0.890375]\n",
      "epoch:11 step:9044[D loss: 0.411037, acc: 63.28%, op_acc: 42.97%] [G loss: 0.833698]\n",
      "epoch:11 step:9045[D loss: 0.442471, acc: 59.38%, op_acc: 36.72%] [G loss: 0.838900]\n",
      "epoch:11 step:9046[D loss: 0.435778, acc: 58.59%, op_acc: 36.72%] [G loss: 0.897459]\n",
      "epoch:11 step:9047[D loss: 0.449519, acc: 57.81%, op_acc: 34.38%] [G loss: 0.897027]\n",
      "epoch:11 step:9048[D loss: 0.418576, acc: 63.28%, op_acc: 35.16%] [G loss: 0.878447]\n",
      "epoch:11 step:9049[D loss: 0.449503, acc: 53.12%, op_acc: 35.94%] [G loss: 0.833470]\n",
      "epoch:11 step:9050[D loss: 0.438372, acc: 56.25%, op_acc: 39.84%] [G loss: 0.855889]\n",
      "##############\n",
      "[0.86462307 0.8754363  0.81064163 0.81342688 0.78437671 0.82828071\n",
      " 0.8832498  0.84617772 0.81881818 0.82225726]\n",
      "##########\n",
      "epoch:11 step:9051[D loss: 0.427360, acc: 60.16%, op_acc: 39.84%] [G loss: 0.863551]\n",
      "epoch:11 step:9052[D loss: 0.463895, acc: 53.12%, op_acc: 32.03%] [G loss: 0.857372]\n",
      "epoch:11 step:9053[D loss: 0.415898, acc: 63.28%, op_acc: 34.38%] [G loss: 0.868730]\n",
      "epoch:11 step:9054[D loss: 0.450776, acc: 50.78%, op_acc: 34.38%] [G loss: 0.888255]\n",
      "epoch:11 step:9055[D loss: 0.461088, acc: 52.34%, op_acc: 30.47%] [G loss: 0.901112]\n",
      "epoch:11 step:9056[D loss: 0.434957, acc: 59.38%, op_acc: 35.94%] [G loss: 0.903604]\n",
      "epoch:11 step:9057[D loss: 0.440208, acc: 60.94%, op_acc: 36.72%] [G loss: 0.842445]\n",
      "epoch:11 step:9058[D loss: 0.450589, acc: 59.38%, op_acc: 30.47%] [G loss: 0.836582]\n",
      "epoch:11 step:9059[D loss: 0.437446, acc: 57.81%, op_acc: 35.94%] [G loss: 0.875980]\n",
      "epoch:11 step:9060[D loss: 0.402485, acc: 66.41%, op_acc: 40.62%] [G loss: 0.849694]\n",
      "epoch:11 step:9061[D loss: 0.415923, acc: 63.28%, op_acc: 37.50%] [G loss: 0.878881]\n",
      "epoch:11 step:9062[D loss: 0.434790, acc: 64.84%, op_acc: 30.47%] [G loss: 0.782691]\n",
      "epoch:11 step:9063[D loss: 0.432100, acc: 58.59%, op_acc: 32.81%] [G loss: 0.965914]\n",
      "epoch:11 step:9064[D loss: 0.404598, acc: 64.06%, op_acc: 42.19%] [G loss: 0.895561]\n",
      "epoch:11 step:9065[D loss: 0.445086, acc: 62.50%, op_acc: 33.59%] [G loss: 0.922284]\n",
      "epoch:11 step:9066[D loss: 0.424550, acc: 57.81%, op_acc: 39.06%] [G loss: 0.879608]\n",
      "epoch:11 step:9067[D loss: 0.437820, acc: 64.84%, op_acc: 29.69%] [G loss: 0.934924]\n",
      "epoch:11 step:9068[D loss: 0.456761, acc: 53.91%, op_acc: 34.38%] [G loss: 0.856503]\n",
      "epoch:11 step:9069[D loss: 0.434696, acc: 66.41%, op_acc: 37.50%] [G loss: 0.816297]\n",
      "epoch:11 step:9070[D loss: 0.428655, acc: 60.16%, op_acc: 34.38%] [G loss: 0.855898]\n",
      "epoch:11 step:9071[D loss: 0.452191, acc: 64.84%, op_acc: 32.03%] [G loss: 0.830305]\n",
      "epoch:11 step:9072[D loss: 0.446518, acc: 66.41%, op_acc: 32.03%] [G loss: 0.927468]\n",
      "epoch:11 step:9073[D loss: 0.429037, acc: 64.06%, op_acc: 32.81%] [G loss: 0.857488]\n",
      "epoch:11 step:9074[D loss: 0.436058, acc: 60.94%, op_acc: 35.94%] [G loss: 0.879021]\n",
      "epoch:11 step:9075[D loss: 0.414908, acc: 61.72%, op_acc: 42.97%] [G loss: 0.886749]\n",
      "epoch:11 step:9076[D loss: 0.425614, acc: 63.28%, op_acc: 39.84%] [G loss: 0.856601]\n",
      "epoch:11 step:9077[D loss: 0.440533, acc: 53.12%, op_acc: 34.38%] [G loss: 0.890419]\n",
      "epoch:11 step:9078[D loss: 0.437788, acc: 61.72%, op_acc: 36.72%] [G loss: 0.888464]\n",
      "epoch:11 step:9079[D loss: 0.434711, acc: 57.03%, op_acc: 35.16%] [G loss: 0.844868]\n",
      "epoch:11 step:9080[D loss: 0.448361, acc: 54.69%, op_acc: 37.50%] [G loss: 0.877039]\n",
      "epoch:11 step:9081[D loss: 0.408966, acc: 62.50%, op_acc: 42.19%] [G loss: 0.842261]\n",
      "epoch:11 step:9082[D loss: 0.470303, acc: 52.34%, op_acc: 25.78%] [G loss: 0.873945]\n",
      "epoch:11 step:9083[D loss: 0.430362, acc: 59.38%, op_acc: 36.72%] [G loss: 0.821122]\n",
      "epoch:11 step:9084[D loss: 0.443246, acc: 60.16%, op_acc: 32.03%] [G loss: 0.856601]\n",
      "epoch:11 step:9085[D loss: 0.401246, acc: 66.41%, op_acc: 39.84%] [G loss: 0.916708]\n",
      "epoch:11 step:9086[D loss: 0.442398, acc: 57.81%, op_acc: 32.81%] [G loss: 0.912600]\n",
      "epoch:11 step:9087[D loss: 0.427345, acc: 62.50%, op_acc: 32.03%] [G loss: 0.940357]\n",
      "epoch:11 step:9088[D loss: 0.412627, acc: 57.81%, op_acc: 39.84%] [G loss: 0.866225]\n",
      "epoch:11 step:9089[D loss: 0.444397, acc: 61.72%, op_acc: 38.28%] [G loss: 0.876451]\n",
      "epoch:11 step:9090[D loss: 0.458287, acc: 59.38%, op_acc: 31.25%] [G loss: 0.908876]\n",
      "epoch:11 step:9091[D loss: 0.446018, acc: 56.25%, op_acc: 35.16%] [G loss: 0.845870]\n",
      "epoch:11 step:9092[D loss: 0.458213, acc: 55.47%, op_acc: 32.81%] [G loss: 0.847054]\n",
      "epoch:11 step:9093[D loss: 0.450855, acc: 55.47%, op_acc: 38.28%] [G loss: 0.866758]\n",
      "epoch:11 step:9094[D loss: 0.426196, acc: 62.50%, op_acc: 37.50%] [G loss: 0.867064]\n",
      "epoch:11 step:9095[D loss: 0.431401, acc: 59.38%, op_acc: 40.62%] [G loss: 0.810972]\n",
      "epoch:11 step:9096[D loss: 0.446744, acc: 56.25%, op_acc: 35.16%] [G loss: 0.788081]\n",
      "epoch:11 step:9097[D loss: 0.458566, acc: 52.34%, op_acc: 35.16%] [G loss: 0.864611]\n",
      "epoch:11 step:9098[D loss: 0.435299, acc: 56.25%, op_acc: 35.16%] [G loss: 0.846774]\n",
      "epoch:11 step:9099[D loss: 0.421064, acc: 62.50%, op_acc: 33.59%] [G loss: 0.959559]\n",
      "epoch:11 step:9100[D loss: 0.459950, acc: 53.12%, op_acc: 39.06%] [G loss: 0.884399]\n",
      "##############\n",
      "[0.85074522 0.8609151  0.82680887 0.79807399 0.81255221 0.82447498\n",
      " 0.8932473  0.81393574 0.80717221 0.81774244]\n",
      "##########\n",
      "epoch:11 step:9101[D loss: 0.418211, acc: 66.41%, op_acc: 40.62%] [G loss: 0.928052]\n",
      "epoch:11 step:9102[D loss: 0.435271, acc: 57.03%, op_acc: 38.28%] [G loss: 0.916348]\n",
      "epoch:11 step:9103[D loss: 0.448242, acc: 54.69%, op_acc: 36.72%] [G loss: 0.889850]\n",
      "epoch:11 step:9104[D loss: 0.440634, acc: 64.06%, op_acc: 33.59%] [G loss: 0.839851]\n",
      "epoch:11 step:9105[D loss: 0.460688, acc: 54.69%, op_acc: 35.16%] [G loss: 0.832356]\n",
      "epoch:11 step:9106[D loss: 0.454037, acc: 54.69%, op_acc: 34.38%] [G loss: 0.923532]\n",
      "epoch:11 step:9107[D loss: 0.423484, acc: 62.50%, op_acc: 34.38%] [G loss: 0.859239]\n",
      "epoch:11 step:9108[D loss: 0.443738, acc: 62.50%, op_acc: 32.03%] [G loss: 0.924234]\n",
      "epoch:11 step:9109[D loss: 0.411370, acc: 63.28%, op_acc: 39.84%] [G loss: 0.892132]\n",
      "epoch:11 step:9110[D loss: 0.444476, acc: 57.81%, op_acc: 35.16%] [G loss: 0.902740]\n",
      "epoch:11 step:9111[D loss: 0.431080, acc: 57.81%, op_acc: 38.28%] [G loss: 0.917126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9112[D loss: 0.430336, acc: 60.16%, op_acc: 35.16%] [G loss: 0.867831]\n",
      "epoch:11 step:9113[D loss: 0.467743, acc: 55.47%, op_acc: 35.16%] [G loss: 0.793078]\n",
      "epoch:11 step:9114[D loss: 0.438074, acc: 57.03%, op_acc: 34.38%] [G loss: 0.846842]\n",
      "epoch:11 step:9115[D loss: 0.431555, acc: 61.72%, op_acc: 34.38%] [G loss: 0.869777]\n",
      "epoch:11 step:9116[D loss: 0.445407, acc: 61.72%, op_acc: 34.38%] [G loss: 0.852588]\n",
      "epoch:11 step:9117[D loss: 0.476374, acc: 57.03%, op_acc: 28.12%] [G loss: 0.798411]\n",
      "epoch:11 step:9118[D loss: 0.462662, acc: 57.81%, op_acc: 26.56%] [G loss: 0.911030]\n",
      "epoch:11 step:9119[D loss: 0.450816, acc: 48.44%, op_acc: 40.62%] [G loss: 0.908219]\n",
      "epoch:11 step:9120[D loss: 0.454796, acc: 53.91%, op_acc: 34.38%] [G loss: 0.873246]\n",
      "epoch:11 step:9121[D loss: 0.432358, acc: 65.62%, op_acc: 30.47%] [G loss: 0.913516]\n",
      "epoch:11 step:9122[D loss: 0.455747, acc: 55.47%, op_acc: 30.47%] [G loss: 0.834408]\n",
      "epoch:11 step:9123[D loss: 0.461734, acc: 56.25%, op_acc: 35.94%] [G loss: 0.880578]\n",
      "epoch:11 step:9124[D loss: 0.424734, acc: 60.16%, op_acc: 33.59%] [G loss: 0.813762]\n",
      "epoch:11 step:9125[D loss: 0.437081, acc: 57.81%, op_acc: 35.94%] [G loss: 0.911543]\n",
      "epoch:11 step:9126[D loss: 0.416225, acc: 65.62%, op_acc: 35.16%] [G loss: 0.853056]\n",
      "epoch:11 step:9127[D loss: 0.410374, acc: 66.41%, op_acc: 39.06%] [G loss: 0.969411]\n",
      "epoch:11 step:9128[D loss: 0.491562, acc: 47.66%, op_acc: 30.47%] [G loss: 0.892764]\n",
      "epoch:11 step:9129[D loss: 0.463091, acc: 45.31%, op_acc: 34.38%] [G loss: 0.746900]\n",
      "epoch:11 step:9130[D loss: 0.468703, acc: 55.47%, op_acc: 31.25%] [G loss: 0.880445]\n",
      "epoch:11 step:9131[D loss: 0.434358, acc: 60.16%, op_acc: 42.19%] [G loss: 0.855836]\n",
      "epoch:11 step:9132[D loss: 0.437866, acc: 56.25%, op_acc: 33.59%] [G loss: 0.808549]\n",
      "epoch:11 step:9133[D loss: 0.446483, acc: 54.69%, op_acc: 38.28%] [G loss: 0.867953]\n",
      "epoch:11 step:9134[D loss: 0.442332, acc: 61.72%, op_acc: 35.16%] [G loss: 0.887235]\n",
      "epoch:11 step:9135[D loss: 0.416540, acc: 63.28%, op_acc: 46.09%] [G loss: 0.883781]\n",
      "epoch:11 step:9136[D loss: 0.416828, acc: 64.84%, op_acc: 32.81%] [G loss: 0.914518]\n",
      "epoch:11 step:9137[D loss: 0.448125, acc: 51.56%, op_acc: 32.81%] [G loss: 0.858217]\n",
      "epoch:11 step:9138[D loss: 0.450490, acc: 56.25%, op_acc: 35.94%] [G loss: 0.903582]\n",
      "epoch:11 step:9139[D loss: 0.436107, acc: 55.47%, op_acc: 38.28%] [G loss: 0.884508]\n",
      "epoch:11 step:9140[D loss: 0.440111, acc: 57.81%, op_acc: 40.62%] [G loss: 0.822542]\n",
      "epoch:11 step:9141[D loss: 0.452501, acc: 56.25%, op_acc: 32.81%] [G loss: 0.863275]\n",
      "epoch:11 step:9142[D loss: 0.411110, acc: 68.75%, op_acc: 37.50%] [G loss: 0.826621]\n",
      "epoch:11 step:9143[D loss: 0.454585, acc: 59.38%, op_acc: 30.47%] [G loss: 0.904634]\n",
      "epoch:11 step:9144[D loss: 0.436864, acc: 61.72%, op_acc: 33.59%] [G loss: 0.830687]\n",
      "epoch:11 step:9145[D loss: 0.426017, acc: 60.16%, op_acc: 35.94%] [G loss: 0.875973]\n",
      "epoch:11 step:9146[D loss: 0.421358, acc: 60.94%, op_acc: 39.84%] [G loss: 0.856339]\n",
      "epoch:11 step:9147[D loss: 0.429584, acc: 57.81%, op_acc: 39.06%] [G loss: 0.770862]\n",
      "epoch:11 step:9148[D loss: 0.439970, acc: 64.06%, op_acc: 28.91%] [G loss: 0.883501]\n",
      "epoch:11 step:9149[D loss: 0.426354, acc: 64.84%, op_acc: 42.97%] [G loss: 0.830392]\n",
      "epoch:11 step:9150[D loss: 0.422878, acc: 62.50%, op_acc: 32.03%] [G loss: 0.853806]\n",
      "##############\n",
      "[0.84957063 0.8641655  0.81982635 0.80407289 0.77612094 0.81956159\n",
      " 0.88735102 0.81499705 0.81442632 0.83889843]\n",
      "##########\n",
      "epoch:11 step:9151[D loss: 0.433463, acc: 53.91%, op_acc: 32.03%] [G loss: 0.777042]\n",
      "epoch:11 step:9152[D loss: 0.449967, acc: 53.12%, op_acc: 36.72%] [G loss: 0.873712]\n",
      "epoch:11 step:9153[D loss: 0.424207, acc: 57.81%, op_acc: 34.38%] [G loss: 0.863783]\n",
      "epoch:11 step:9154[D loss: 0.432089, acc: 64.84%, op_acc: 33.59%] [G loss: 0.898224]\n",
      "epoch:11 step:9155[D loss: 0.441176, acc: 63.28%, op_acc: 35.16%] [G loss: 0.887349]\n",
      "epoch:11 step:9156[D loss: 0.430307, acc: 58.59%, op_acc: 39.84%] [G loss: 0.917162]\n",
      "epoch:11 step:9157[D loss: 0.436717, acc: 61.72%, op_acc: 35.16%] [G loss: 0.894331]\n",
      "epoch:11 step:9158[D loss: 0.440346, acc: 58.59%, op_acc: 39.84%] [G loss: 0.914594]\n",
      "epoch:11 step:9159[D loss: 0.418492, acc: 65.62%, op_acc: 39.06%] [G loss: 0.889208]\n",
      "epoch:11 step:9160[D loss: 0.434676, acc: 59.38%, op_acc: 35.94%] [G loss: 0.869642]\n",
      "epoch:11 step:9161[D loss: 0.427461, acc: 60.16%, op_acc: 35.94%] [G loss: 0.856862]\n",
      "epoch:11 step:9162[D loss: 0.433857, acc: 57.81%, op_acc: 40.62%] [G loss: 1.004426]\n",
      "epoch:11 step:9163[D loss: 0.438984, acc: 60.16%, op_acc: 27.34%] [G loss: 0.879615]\n",
      "epoch:11 step:9164[D loss: 0.447057, acc: 60.16%, op_acc: 37.50%] [G loss: 0.911578]\n",
      "epoch:11 step:9165[D loss: 0.441862, acc: 58.59%, op_acc: 32.03%] [G loss: 0.852078]\n",
      "epoch:11 step:9166[D loss: 0.432641, acc: 60.94%, op_acc: 35.94%] [G loss: 0.796476]\n",
      "epoch:11 step:9167[D loss: 0.433381, acc: 56.25%, op_acc: 34.38%] [G loss: 0.835855]\n",
      "epoch:11 step:9168[D loss: 0.462498, acc: 57.81%, op_acc: 30.47%] [G loss: 0.876503]\n",
      "epoch:11 step:9169[D loss: 0.466486, acc: 57.03%, op_acc: 31.25%] [G loss: 0.822142]\n",
      "epoch:11 step:9170[D loss: 0.410627, acc: 63.28%, op_acc: 42.97%] [G loss: 0.972999]\n",
      "epoch:11 step:9171[D loss: 0.459978, acc: 54.69%, op_acc: 39.06%] [G loss: 0.934094]\n",
      "epoch:11 step:9172[D loss: 0.429256, acc: 63.28%, op_acc: 35.16%] [G loss: 0.913451]\n",
      "epoch:11 step:9173[D loss: 0.432788, acc: 63.28%, op_acc: 32.81%] [G loss: 0.853902]\n",
      "epoch:11 step:9174[D loss: 0.427417, acc: 56.25%, op_acc: 35.94%] [G loss: 0.911842]\n",
      "epoch:11 step:9175[D loss: 0.481828, acc: 53.12%, op_acc: 31.25%] [G loss: 0.870680]\n",
      "epoch:11 step:9176[D loss: 0.449409, acc: 57.03%, op_acc: 35.16%] [G loss: 0.901482]\n",
      "epoch:11 step:9177[D loss: 0.454370, acc: 59.38%, op_acc: 34.38%] [G loss: 0.831010]\n",
      "epoch:11 step:9178[D loss: 0.431585, acc: 57.81%, op_acc: 32.03%] [G loss: 0.924969]\n",
      "epoch:11 step:9179[D loss: 0.418138, acc: 64.84%, op_acc: 39.84%] [G loss: 1.052017]\n",
      "epoch:11 step:9180[D loss: 0.436228, acc: 63.28%, op_acc: 35.94%] [G loss: 0.921058]\n",
      "epoch:11 step:9181[D loss: 0.422230, acc: 61.72%, op_acc: 39.84%] [G loss: 0.955362]\n",
      "epoch:11 step:9182[D loss: 0.465894, acc: 53.91%, op_acc: 35.16%] [G loss: 0.942316]\n",
      "epoch:11 step:9183[D loss: 0.444195, acc: 55.47%, op_acc: 30.47%] [G loss: 0.946196]\n",
      "epoch:11 step:9184[D loss: 0.431053, acc: 68.75%, op_acc: 33.59%] [G loss: 0.925879]\n",
      "epoch:11 step:9185[D loss: 0.426362, acc: 59.38%, op_acc: 42.19%] [G loss: 0.893727]\n",
      "epoch:11 step:9186[D loss: 0.441360, acc: 61.72%, op_acc: 32.03%] [G loss: 0.889254]\n",
      "epoch:11 step:9187[D loss: 0.457583, acc: 61.72%, op_acc: 29.69%] [G loss: 0.850078]\n",
      "epoch:11 step:9188[D loss: 0.430655, acc: 59.38%, op_acc: 38.28%] [G loss: 0.893311]\n",
      "epoch:11 step:9189[D loss: 0.415022, acc: 66.41%, op_acc: 35.16%] [G loss: 0.813479]\n",
      "epoch:11 step:9190[D loss: 0.454032, acc: 57.81%, op_acc: 32.03%] [G loss: 0.857198]\n",
      "epoch:11 step:9191[D loss: 0.415908, acc: 70.31%, op_acc: 34.38%] [G loss: 0.931149]\n",
      "epoch:11 step:9192[D loss: 0.428829, acc: 64.06%, op_acc: 34.38%] [G loss: 0.865487]\n",
      "epoch:11 step:9193[D loss: 0.418526, acc: 60.16%, op_acc: 37.50%] [G loss: 0.854196]\n",
      "epoch:11 step:9194[D loss: 0.407903, acc: 62.50%, op_acc: 39.84%] [G loss: 0.882932]\n",
      "epoch:11 step:9195[D loss: 0.465574, acc: 48.44%, op_acc: 36.72%] [G loss: 0.884561]\n",
      "epoch:11 step:9196[D loss: 0.460031, acc: 53.12%, op_acc: 29.69%] [G loss: 0.849722]\n",
      "epoch:11 step:9197[D loss: 0.440049, acc: 54.69%, op_acc: 39.06%] [G loss: 0.879667]\n",
      "epoch:11 step:9198[D loss: 0.412443, acc: 55.47%, op_acc: 42.19%] [G loss: 0.868427]\n",
      "epoch:11 step:9199[D loss: 0.420179, acc: 61.72%, op_acc: 39.84%] [G loss: 0.862744]\n",
      "epoch:11 step:9200[D loss: 0.421273, acc: 62.50%, op_acc: 37.50%] [G loss: 0.928441]\n",
      "##############\n",
      "[0.8429443  0.85513066 0.83590506 0.82180688 0.7631881  0.82152013\n",
      " 0.87638275 0.83395923 0.82607418 0.82372215]\n",
      "##########\n",
      "epoch:11 step:9201[D loss: 0.429464, acc: 65.62%, op_acc: 29.69%] [G loss: 0.901022]\n",
      "epoch:11 step:9202[D loss: 0.443050, acc: 57.03%, op_acc: 34.38%] [G loss: 0.879687]\n",
      "epoch:11 step:9203[D loss: 0.459409, acc: 53.12%, op_acc: 33.59%] [G loss: 0.894029]\n",
      "epoch:11 step:9204[D loss: 0.437528, acc: 53.12%, op_acc: 37.50%] [G loss: 0.950882]\n",
      "epoch:11 step:9205[D loss: 0.410135, acc: 64.06%, op_acc: 38.28%] [G loss: 0.950361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9206[D loss: 0.449295, acc: 55.47%, op_acc: 31.25%] [G loss: 0.895339]\n",
      "epoch:11 step:9207[D loss: 0.441743, acc: 58.59%, op_acc: 33.59%] [G loss: 0.896584]\n",
      "epoch:11 step:9208[D loss: 0.449278, acc: 57.81%, op_acc: 35.16%] [G loss: 0.873224]\n",
      "epoch:11 step:9209[D loss: 0.453328, acc: 56.25%, op_acc: 33.59%] [G loss: 0.816719]\n",
      "epoch:11 step:9210[D loss: 0.463988, acc: 58.59%, op_acc: 30.47%] [G loss: 0.899540]\n",
      "epoch:11 step:9211[D loss: 0.416016, acc: 63.28%, op_acc: 38.28%] [G loss: 0.923525]\n",
      "epoch:11 step:9212[D loss: 0.419102, acc: 67.97%, op_acc: 36.72%] [G loss: 0.891739]\n",
      "epoch:11 step:9213[D loss: 0.465947, acc: 60.94%, op_acc: 30.47%] [G loss: 0.892732]\n",
      "epoch:11 step:9214[D loss: 0.407052, acc: 66.41%, op_acc: 41.41%] [G loss: 0.923216]\n",
      "epoch:11 step:9215[D loss: 0.450292, acc: 50.00%, op_acc: 40.62%] [G loss: 0.828218]\n",
      "epoch:11 step:9216[D loss: 0.442579, acc: 55.47%, op_acc: 40.62%] [G loss: 0.851450]\n",
      "epoch:11 step:9217[D loss: 0.425145, acc: 62.50%, op_acc: 35.94%] [G loss: 0.819716]\n",
      "epoch:11 step:9218[D loss: 0.418261, acc: 56.25%, op_acc: 42.97%] [G loss: 0.888578]\n",
      "epoch:11 step:9219[D loss: 0.438957, acc: 64.06%, op_acc: 32.03%] [G loss: 0.856790]\n",
      "epoch:11 step:9220[D loss: 0.463116, acc: 61.72%, op_acc: 24.22%] [G loss: 0.793865]\n",
      "epoch:11 step:9221[D loss: 0.425557, acc: 57.03%, op_acc: 41.41%] [G loss: 0.872851]\n",
      "epoch:11 step:9222[D loss: 0.460012, acc: 50.00%, op_acc: 35.16%] [G loss: 0.807554]\n",
      "epoch:11 step:9223[D loss: 0.439615, acc: 64.84%, op_acc: 32.81%] [G loss: 0.883318]\n",
      "epoch:11 step:9224[D loss: 0.431847, acc: 64.84%, op_acc: 32.81%] [G loss: 0.840913]\n",
      "epoch:11 step:9225[D loss: 0.428457, acc: 60.16%, op_acc: 43.75%] [G loss: 0.846186]\n",
      "epoch:11 step:9226[D loss: 0.483444, acc: 44.53%, op_acc: 38.28%] [G loss: 0.765627]\n",
      "epoch:11 step:9227[D loss: 0.445266, acc: 57.81%, op_acc: 35.16%] [G loss: 0.900132]\n",
      "epoch:11 step:9228[D loss: 0.436712, acc: 59.38%, op_acc: 34.38%] [G loss: 0.875884]\n",
      "epoch:11 step:9229[D loss: 0.435991, acc: 60.16%, op_acc: 33.59%] [G loss: 0.880776]\n",
      "epoch:11 step:9230[D loss: 0.451494, acc: 53.91%, op_acc: 33.59%] [G loss: 0.940457]\n",
      "epoch:11 step:9231[D loss: 0.474255, acc: 49.22%, op_acc: 32.81%] [G loss: 0.877689]\n",
      "epoch:11 step:9232[D loss: 0.426990, acc: 64.06%, op_acc: 34.38%] [G loss: 0.901633]\n",
      "epoch:11 step:9233[D loss: 0.442939, acc: 57.81%, op_acc: 35.16%] [G loss: 0.864324]\n",
      "epoch:11 step:9234[D loss: 0.483263, acc: 53.91%, op_acc: 36.72%] [G loss: 0.852578]\n",
      "epoch:11 step:9235[D loss: 0.396577, acc: 66.41%, op_acc: 42.97%] [G loss: 0.917768]\n",
      "epoch:11 step:9236[D loss: 0.420184, acc: 67.97%, op_acc: 32.03%] [G loss: 0.902728]\n",
      "epoch:11 step:9237[D loss: 0.447936, acc: 60.94%, op_acc: 35.16%] [G loss: 0.875972]\n",
      "epoch:11 step:9238[D loss: 0.430916, acc: 60.16%, op_acc: 35.94%] [G loss: 0.797631]\n",
      "epoch:11 step:9239[D loss: 0.427179, acc: 60.16%, op_acc: 32.81%] [G loss: 0.927734]\n",
      "epoch:11 step:9240[D loss: 0.436014, acc: 58.59%, op_acc: 35.94%] [G loss: 0.878429]\n",
      "epoch:11 step:9241[D loss: 0.461212, acc: 60.16%, op_acc: 32.81%] [G loss: 0.969044]\n",
      "epoch:11 step:9242[D loss: 0.451993, acc: 50.00%, op_acc: 39.84%] [G loss: 0.797911]\n",
      "epoch:11 step:9243[D loss: 0.449680, acc: 53.91%, op_acc: 36.72%] [G loss: 0.852116]\n",
      "epoch:11 step:9244[D loss: 0.433788, acc: 53.12%, op_acc: 43.75%] [G loss: 0.874472]\n",
      "epoch:11 step:9245[D loss: 0.444784, acc: 48.44%, op_acc: 39.06%] [G loss: 0.892014]\n",
      "epoch:11 step:9246[D loss: 0.425436, acc: 58.59%, op_acc: 35.16%] [G loss: 0.885682]\n",
      "epoch:11 step:9247[D loss: 0.440437, acc: 62.50%, op_acc: 39.84%] [G loss: 0.889197]\n",
      "epoch:11 step:9248[D loss: 0.451062, acc: 60.16%, op_acc: 35.16%] [G loss: 0.925001]\n",
      "epoch:11 step:9249[D loss: 0.472611, acc: 53.91%, op_acc: 33.59%] [G loss: 0.877990]\n",
      "epoch:11 step:9250[D loss: 0.454111, acc: 64.06%, op_acc: 30.47%] [G loss: 0.901385]\n",
      "##############\n",
      "[0.85579308 0.85529442 0.81140507 0.79980296 0.77052908 0.8132198\n",
      " 0.88897323 0.80997615 0.81401842 0.83237145]\n",
      "##########\n",
      "epoch:11 step:9251[D loss: 0.439935, acc: 50.78%, op_acc: 38.28%] [G loss: 0.859665]\n",
      "epoch:11 step:9252[D loss: 0.418613, acc: 58.59%, op_acc: 36.72%] [G loss: 0.909183]\n",
      "epoch:11 step:9253[D loss: 0.433239, acc: 62.50%, op_acc: 38.28%] [G loss: 0.936802]\n",
      "epoch:11 step:9254[D loss: 0.439429, acc: 53.91%, op_acc: 39.06%] [G loss: 0.805771]\n",
      "epoch:11 step:9255[D loss: 0.398740, acc: 71.09%, op_acc: 33.59%] [G loss: 0.914937]\n",
      "epoch:11 step:9256[D loss: 0.466620, acc: 60.16%, op_acc: 34.38%] [G loss: 0.809532]\n",
      "epoch:11 step:9257[D loss: 0.450811, acc: 64.06%, op_acc: 31.25%] [G loss: 0.843411]\n",
      "epoch:11 step:9258[D loss: 0.393969, acc: 69.53%, op_acc: 35.94%] [G loss: 0.851870]\n",
      "epoch:11 step:9259[D loss: 0.433627, acc: 58.59%, op_acc: 40.62%] [G loss: 0.919692]\n",
      "epoch:11 step:9260[D loss: 0.457778, acc: 55.47%, op_acc: 39.06%] [G loss: 0.877399]\n",
      "epoch:11 step:9261[D loss: 0.444087, acc: 50.78%, op_acc: 35.16%] [G loss: 0.841312]\n",
      "epoch:11 step:9262[D loss: 0.476024, acc: 60.16%, op_acc: 32.03%] [G loss: 0.837572]\n",
      "epoch:11 step:9263[D loss: 0.434606, acc: 63.28%, op_acc: 35.94%] [G loss: 0.845790]\n",
      "epoch:11 step:9264[D loss: 0.436233, acc: 59.38%, op_acc: 36.72%] [G loss: 0.817780]\n",
      "epoch:11 step:9265[D loss: 0.458994, acc: 57.81%, op_acc: 34.38%] [G loss: 0.832540]\n",
      "epoch:11 step:9266[D loss: 0.424111, acc: 62.50%, op_acc: 39.84%] [G loss: 0.890788]\n",
      "epoch:11 step:9267[D loss: 0.442075, acc: 63.28%, op_acc: 35.94%] [G loss: 0.889881]\n",
      "epoch:11 step:9268[D loss: 0.457708, acc: 61.72%, op_acc: 32.03%] [G loss: 0.901720]\n",
      "epoch:11 step:9269[D loss: 0.427539, acc: 57.81%, op_acc: 39.06%] [G loss: 0.851158]\n",
      "epoch:11 step:9270[D loss: 0.419800, acc: 59.38%, op_acc: 38.28%] [G loss: 0.895561]\n",
      "epoch:11 step:9271[D loss: 0.454149, acc: 57.03%, op_acc: 34.38%] [G loss: 0.865226]\n",
      "epoch:11 step:9272[D loss: 0.457585, acc: 57.81%, op_acc: 27.34%] [G loss: 0.830660]\n",
      "epoch:11 step:9273[D loss: 0.439526, acc: 54.69%, op_acc: 43.75%] [G loss: 0.901113]\n",
      "epoch:11 step:9274[D loss: 0.429209, acc: 57.81%, op_acc: 37.50%] [G loss: 0.858181]\n",
      "epoch:11 step:9275[D loss: 0.422504, acc: 63.28%, op_acc: 34.38%] [G loss: 0.916966]\n",
      "epoch:11 step:9276[D loss: 0.463135, acc: 56.25%, op_acc: 32.03%] [G loss: 0.907043]\n",
      "epoch:11 step:9277[D loss: 0.438122, acc: 58.59%, op_acc: 37.50%] [G loss: 0.819023]\n",
      "epoch:11 step:9278[D loss: 0.419515, acc: 62.50%, op_acc: 28.91%] [G loss: 0.833389]\n",
      "epoch:11 step:9279[D loss: 0.446206, acc: 53.91%, op_acc: 39.84%] [G loss: 0.827934]\n",
      "epoch:11 step:9280[D loss: 0.421477, acc: 61.72%, op_acc: 39.84%] [G loss: 0.821868]\n",
      "epoch:11 step:9281[D loss: 0.423271, acc: 62.50%, op_acc: 35.16%] [G loss: 0.849126]\n",
      "epoch:11 step:9282[D loss: 0.465936, acc: 56.25%, op_acc: 38.28%] [G loss: 0.915562]\n",
      "epoch:11 step:9283[D loss: 0.455461, acc: 58.59%, op_acc: 35.16%] [G loss: 0.825441]\n",
      "epoch:11 step:9284[D loss: 0.441832, acc: 64.84%, op_acc: 33.59%] [G loss: 0.822713]\n",
      "epoch:11 step:9285[D loss: 0.446968, acc: 62.50%, op_acc: 31.25%] [G loss: 0.860321]\n",
      "epoch:11 step:9286[D loss: 0.447256, acc: 56.25%, op_acc: 37.50%] [G loss: 0.847739]\n",
      "epoch:11 step:9287[D loss: 0.452128, acc: 53.91%, op_acc: 36.72%] [G loss: 0.867981]\n",
      "epoch:11 step:9288[D loss: 0.421687, acc: 62.50%, op_acc: 33.59%] [G loss: 0.882250]\n",
      "epoch:11 step:9289[D loss: 0.426401, acc: 64.84%, op_acc: 33.59%] [G loss: 0.822436]\n",
      "epoch:11 step:9290[D loss: 0.441104, acc: 49.22%, op_acc: 37.50%] [G loss: 0.863177]\n",
      "epoch:11 step:9291[D loss: 0.452864, acc: 57.81%, op_acc: 35.94%] [G loss: 0.850979]\n",
      "epoch:11 step:9292[D loss: 0.465144, acc: 54.69%, op_acc: 25.78%] [G loss: 0.808556]\n",
      "epoch:11 step:9293[D loss: 0.442894, acc: 60.94%, op_acc: 34.38%] [G loss: 0.861475]\n",
      "epoch:11 step:9294[D loss: 0.434714, acc: 55.47%, op_acc: 35.16%] [G loss: 0.904708]\n",
      "epoch:11 step:9295[D loss: 0.407049, acc: 61.72%, op_acc: 43.75%] [G loss: 0.878485]\n",
      "epoch:11 step:9296[D loss: 0.437358, acc: 51.56%, op_acc: 33.59%] [G loss: 0.858572]\n",
      "epoch:11 step:9297[D loss: 0.461655, acc: 52.34%, op_acc: 33.59%] [G loss: 0.871913]\n",
      "epoch:11 step:9298[D loss: 0.488762, acc: 50.78%, op_acc: 32.03%] [G loss: 0.778550]\n",
      "epoch:11 step:9299[D loss: 0.439898, acc: 64.06%, op_acc: 32.03%] [G loss: 0.932254]\n",
      "epoch:11 step:9300[D loss: 0.407045, acc: 70.31%, op_acc: 35.16%] [G loss: 0.855374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.85563492 0.83486686 0.79846055 0.81337827 0.79578458 0.81198592\n",
      " 0.89836926 0.84366053 0.83646566 0.81847189]\n",
      "##########\n",
      "epoch:11 step:9301[D loss: 0.413252, acc: 57.81%, op_acc: 38.28%] [G loss: 0.933162]\n",
      "epoch:11 step:9302[D loss: 0.444188, acc: 58.59%, op_acc: 36.72%] [G loss: 0.886450]\n",
      "epoch:11 step:9303[D loss: 0.414134, acc: 59.38%, op_acc: 36.72%] [G loss: 0.910618]\n",
      "epoch:11 step:9304[D loss: 0.432278, acc: 58.59%, op_acc: 37.50%] [G loss: 0.862269]\n",
      "epoch:11 step:9305[D loss: 0.414825, acc: 69.53%, op_acc: 37.50%] [G loss: 0.920579]\n",
      "epoch:11 step:9306[D loss: 0.439208, acc: 52.34%, op_acc: 34.38%] [G loss: 0.942686]\n",
      "epoch:11 step:9307[D loss: 0.468654, acc: 50.00%, op_acc: 33.59%] [G loss: 0.904882]\n",
      "epoch:11 step:9308[D loss: 0.427664, acc: 55.47%, op_acc: 36.72%] [G loss: 0.839464]\n",
      "epoch:11 step:9309[D loss: 0.449383, acc: 55.47%, op_acc: 37.50%] [G loss: 0.939047]\n",
      "epoch:11 step:9310[D loss: 0.427328, acc: 58.59%, op_acc: 40.62%] [G loss: 0.923330]\n",
      "epoch:11 step:9311[D loss: 0.460498, acc: 55.47%, op_acc: 30.47%] [G loss: 0.857412]\n",
      "epoch:11 step:9312[D loss: 0.434829, acc: 58.59%, op_acc: 42.97%] [G loss: 0.828214]\n",
      "epoch:11 step:9313[D loss: 0.417918, acc: 59.38%, op_acc: 39.06%] [G loss: 0.827809]\n",
      "epoch:11 step:9314[D loss: 0.425049, acc: 60.94%, op_acc: 37.50%] [G loss: 0.902321]\n",
      "epoch:11 step:9315[D loss: 0.498881, acc: 44.53%, op_acc: 29.69%] [G loss: 0.789821]\n",
      "epoch:11 step:9316[D loss: 0.437793, acc: 55.47%, op_acc: 32.03%] [G loss: 0.842333]\n",
      "epoch:11 step:9317[D loss: 0.427716, acc: 60.16%, op_acc: 35.94%] [G loss: 0.930248]\n",
      "epoch:11 step:9318[D loss: 0.459202, acc: 61.72%, op_acc: 32.03%] [G loss: 0.852648]\n",
      "epoch:11 step:9319[D loss: 0.448105, acc: 60.16%, op_acc: 37.50%] [G loss: 0.899324]\n",
      "epoch:11 step:9320[D loss: 0.412658, acc: 60.16%, op_acc: 36.72%] [G loss: 0.864236]\n",
      "epoch:11 step:9321[D loss: 0.429400, acc: 58.59%, op_acc: 33.59%] [G loss: 0.934654]\n",
      "epoch:11 step:9322[D loss: 0.443307, acc: 57.03%, op_acc: 39.06%] [G loss: 0.913521]\n",
      "epoch:11 step:9323[D loss: 0.455066, acc: 50.00%, op_acc: 35.16%] [G loss: 0.856635]\n",
      "epoch:11 step:9324[D loss: 0.420582, acc: 61.72%, op_acc: 38.28%] [G loss: 0.885477]\n",
      "epoch:11 step:9325[D loss: 0.432744, acc: 58.59%, op_acc: 33.59%] [G loss: 0.898625]\n",
      "epoch:11 step:9326[D loss: 0.435896, acc: 59.38%, op_acc: 34.38%] [G loss: 0.910183]\n",
      "epoch:11 step:9327[D loss: 0.438588, acc: 60.94%, op_acc: 39.84%] [G loss: 0.928183]\n",
      "epoch:11 step:9328[D loss: 0.426434, acc: 57.81%, op_acc: 42.19%] [G loss: 0.894308]\n",
      "epoch:11 step:9329[D loss: 0.448542, acc: 54.69%, op_acc: 33.59%] [G loss: 0.956001]\n",
      "epoch:11 step:9330[D loss: 0.452054, acc: 48.44%, op_acc: 35.16%] [G loss: 0.809424]\n",
      "epoch:11 step:9331[D loss: 0.419536, acc: 59.38%, op_acc: 40.62%] [G loss: 0.853908]\n",
      "epoch:11 step:9332[D loss: 0.443341, acc: 60.16%, op_acc: 32.81%] [G loss: 0.897606]\n",
      "epoch:11 step:9333[D loss: 0.451358, acc: 57.81%, op_acc: 35.16%] [G loss: 0.865723]\n",
      "epoch:11 step:9334[D loss: 0.438262, acc: 53.12%, op_acc: 36.72%] [G loss: 0.901173]\n",
      "epoch:11 step:9335[D loss: 0.415515, acc: 57.81%, op_acc: 42.19%] [G loss: 0.840530]\n",
      "epoch:11 step:9336[D loss: 0.417183, acc: 64.84%, op_acc: 36.72%] [G loss: 0.874693]\n",
      "epoch:11 step:9337[D loss: 0.458473, acc: 53.12%, op_acc: 32.81%] [G loss: 0.927769]\n",
      "epoch:11 step:9338[D loss: 0.461724, acc: 56.25%, op_acc: 38.28%] [G loss: 0.865194]\n",
      "epoch:11 step:9339[D loss: 0.460579, acc: 57.81%, op_acc: 29.69%] [G loss: 0.803657]\n",
      "epoch:11 step:9340[D loss: 0.457840, acc: 55.47%, op_acc: 38.28%] [G loss: 0.892267]\n",
      "epoch:11 step:9341[D loss: 0.463305, acc: 50.00%, op_acc: 32.81%] [G loss: 0.841791]\n",
      "epoch:11 step:9342[D loss: 0.467224, acc: 62.50%, op_acc: 28.91%] [G loss: 0.882349]\n",
      "epoch:11 step:9343[D loss: 0.431124, acc: 58.59%, op_acc: 33.59%] [G loss: 0.841367]\n",
      "epoch:11 step:9344[D loss: 0.442783, acc: 55.47%, op_acc: 39.06%] [G loss: 0.879028]\n",
      "epoch:11 step:9345[D loss: 0.431046, acc: 57.81%, op_acc: 41.41%] [G loss: 0.846169]\n",
      "epoch:11 step:9346[D loss: 0.424502, acc: 65.62%, op_acc: 35.94%] [G loss: 0.955947]\n",
      "epoch:11 step:9347[D loss: 0.425719, acc: 63.28%, op_acc: 40.62%] [G loss: 0.836199]\n",
      "epoch:11 step:9348[D loss: 0.446520, acc: 56.25%, op_acc: 38.28%] [G loss: 0.846398]\n",
      "epoch:11 step:9349[D loss: 0.433891, acc: 54.69%, op_acc: 34.38%] [G loss: 0.874668]\n",
      "epoch:11 step:9350[D loss: 0.435059, acc: 60.16%, op_acc: 35.16%] [G loss: 0.883668]\n",
      "##############\n",
      "[0.83920658 0.8569528  0.82999097 0.80250689 0.77599325 0.83313955\n",
      " 0.88089858 0.81558424 0.83351968 0.83407251]\n",
      "##########\n",
      "epoch:11 step:9351[D loss: 0.425455, acc: 61.72%, op_acc: 37.50%] [G loss: 0.863249]\n",
      "epoch:11 step:9352[D loss: 0.416210, acc: 60.16%, op_acc: 41.41%] [G loss: 0.860954]\n",
      "epoch:11 step:9353[D loss: 0.471174, acc: 47.66%, op_acc: 35.16%] [G loss: 0.816427]\n",
      "epoch:11 step:9354[D loss: 0.446038, acc: 58.59%, op_acc: 36.72%] [G loss: 0.857448]\n",
      "epoch:11 step:9355[D loss: 0.417733, acc: 62.50%, op_acc: 41.41%] [G loss: 0.931360]\n",
      "epoch:11 step:9356[D loss: 0.427711, acc: 60.16%, op_acc: 33.59%] [G loss: 0.832669]\n",
      "epoch:11 step:9357[D loss: 0.448573, acc: 51.56%, op_acc: 32.81%] [G loss: 0.825844]\n",
      "epoch:11 step:9358[D loss: 0.401348, acc: 67.19%, op_acc: 36.72%] [G loss: 0.848213]\n",
      "epoch:11 step:9359[D loss: 0.431305, acc: 61.72%, op_acc: 28.12%] [G loss: 0.894739]\n",
      "epoch:11 step:9360[D loss: 0.436961, acc: 56.25%, op_acc: 40.62%] [G loss: 0.847043]\n",
      "epoch:11 step:9361[D loss: 0.437441, acc: 57.81%, op_acc: 36.72%] [G loss: 0.828901]\n",
      "epoch:11 step:9362[D loss: 0.478071, acc: 53.12%, op_acc: 33.59%] [G loss: 0.888135]\n",
      "epoch:11 step:9363[D loss: 0.453787, acc: 52.34%, op_acc: 34.38%] [G loss: 0.885054]\n",
      "epoch:11 step:9364[D loss: 0.451711, acc: 57.03%, op_acc: 32.81%] [G loss: 0.817906]\n",
      "epoch:11 step:9365[D loss: 0.423061, acc: 53.91%, op_acc: 40.62%] [G loss: 0.793824]\n",
      "epoch:11 step:9366[D loss: 0.406672, acc: 69.53%, op_acc: 39.06%] [G loss: 0.842772]\n",
      "epoch:11 step:9367[D loss: 0.407216, acc: 62.50%, op_acc: 38.28%] [G loss: 0.862828]\n",
      "epoch:11 step:9368[D loss: 0.481205, acc: 50.00%, op_acc: 28.12%] [G loss: 0.813425]\n",
      "epoch:11 step:9369[D loss: 0.418365, acc: 66.41%, op_acc: 38.28%] [G loss: 0.839250]\n",
      "epoch:11 step:9370[D loss: 0.443256, acc: 57.81%, op_acc: 35.16%] [G loss: 0.892869]\n",
      "epoch:11 step:9371[D loss: 0.420544, acc: 54.69%, op_acc: 37.50%] [G loss: 0.844400]\n",
      "epoch:11 step:9372[D loss: 0.431598, acc: 64.06%, op_acc: 34.38%] [G loss: 0.852307]\n",
      "epoch:12 step:9373[D loss: 0.463565, acc: 53.91%, op_acc: 37.50%] [G loss: 0.859334]\n",
      "epoch:12 step:9374[D loss: 0.429465, acc: 57.03%, op_acc: 40.62%] [G loss: 0.938178]\n",
      "epoch:12 step:9375[D loss: 0.443229, acc: 57.81%, op_acc: 37.50%] [G loss: 0.905861]\n",
      "epoch:12 step:9376[D loss: 0.400567, acc: 61.72%, op_acc: 40.62%] [G loss: 0.911886]\n",
      "epoch:12 step:9377[D loss: 0.447565, acc: 57.81%, op_acc: 39.84%] [G loss: 0.853648]\n",
      "epoch:12 step:9378[D loss: 0.440141, acc: 58.59%, op_acc: 36.72%] [G loss: 0.838707]\n",
      "epoch:12 step:9379[D loss: 0.439165, acc: 59.38%, op_acc: 33.59%] [G loss: 0.858850]\n",
      "epoch:12 step:9380[D loss: 0.430957, acc: 60.16%, op_acc: 35.94%] [G loss: 0.880234]\n",
      "epoch:12 step:9381[D loss: 0.431194, acc: 51.56%, op_acc: 42.19%] [G loss: 0.848889]\n",
      "epoch:12 step:9382[D loss: 0.429266, acc: 61.72%, op_acc: 38.28%] [G loss: 0.862363]\n",
      "epoch:12 step:9383[D loss: 0.467638, acc: 50.78%, op_acc: 32.03%] [G loss: 0.833182]\n",
      "epoch:12 step:9384[D loss: 0.435857, acc: 60.16%, op_acc: 35.94%] [G loss: 0.847947]\n",
      "epoch:12 step:9385[D loss: 0.423828, acc: 61.72%, op_acc: 39.84%] [G loss: 0.908752]\n",
      "epoch:12 step:9386[D loss: 0.449178, acc: 64.84%, op_acc: 31.25%] [G loss: 0.816400]\n",
      "epoch:12 step:9387[D loss: 0.444403, acc: 58.59%, op_acc: 30.47%] [G loss: 0.803357]\n",
      "epoch:12 step:9388[D loss: 0.420378, acc: 56.25%, op_acc: 39.06%] [G loss: 0.902480]\n",
      "epoch:12 step:9389[D loss: 0.424811, acc: 58.59%, op_acc: 37.50%] [G loss: 0.904669]\n",
      "epoch:12 step:9390[D loss: 0.428810, acc: 59.38%, op_acc: 35.94%] [G loss: 0.886238]\n",
      "epoch:12 step:9391[D loss: 0.409633, acc: 69.53%, op_acc: 39.84%] [G loss: 0.850229]\n",
      "epoch:12 step:9392[D loss: 0.412985, acc: 64.84%, op_acc: 39.84%] [G loss: 0.874458]\n",
      "epoch:12 step:9393[D loss: 0.424555, acc: 64.06%, op_acc: 35.94%] [G loss: 0.879954]\n",
      "epoch:12 step:9394[D loss: 0.465703, acc: 53.12%, op_acc: 35.16%] [G loss: 0.739331]\n",
      "epoch:12 step:9395[D loss: 0.408610, acc: 65.62%, op_acc: 42.97%] [G loss: 0.822738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9396[D loss: 0.453172, acc: 57.03%, op_acc: 29.69%] [G loss: 0.834738]\n",
      "epoch:12 step:9397[D loss: 0.443037, acc: 58.59%, op_acc: 34.38%] [G loss: 0.884816]\n",
      "epoch:12 step:9398[D loss: 0.415273, acc: 61.72%, op_acc: 37.50%] [G loss: 0.897414]\n",
      "epoch:12 step:9399[D loss: 0.439295, acc: 59.38%, op_acc: 34.38%] [G loss: 0.940933]\n",
      "epoch:12 step:9400[D loss: 0.433965, acc: 57.81%, op_acc: 37.50%] [G loss: 0.843496]\n",
      "##############\n",
      "[0.84948068 0.87420316 0.82434609 0.79889705 0.80244158 0.82144784\n",
      " 0.88969997 0.82901823 0.79022595 0.82130558]\n",
      "##########\n",
      "epoch:12 step:9401[D loss: 0.424753, acc: 57.81%, op_acc: 40.62%] [G loss: 0.882339]\n",
      "epoch:12 step:9402[D loss: 0.425945, acc: 60.16%, op_acc: 42.19%] [G loss: 0.924812]\n",
      "epoch:12 step:9403[D loss: 0.462623, acc: 49.22%, op_acc: 36.72%] [G loss: 0.865909]\n",
      "epoch:12 step:9404[D loss: 0.468484, acc: 62.50%, op_acc: 32.03%] [G loss: 0.933608]\n",
      "epoch:12 step:9405[D loss: 0.410660, acc: 62.50%, op_acc: 39.06%] [G loss: 1.014552]\n",
      "epoch:12 step:9406[D loss: 0.421290, acc: 60.16%, op_acc: 39.06%] [G loss: 0.871856]\n",
      "epoch:12 step:9407[D loss: 0.434006, acc: 60.94%, op_acc: 37.50%] [G loss: 0.856162]\n",
      "epoch:12 step:9408[D loss: 0.446588, acc: 50.00%, op_acc: 36.72%] [G loss: 0.927537]\n",
      "epoch:12 step:9409[D loss: 0.409436, acc: 61.72%, op_acc: 36.72%] [G loss: 0.817589]\n",
      "epoch:12 step:9410[D loss: 0.457189, acc: 50.78%, op_acc: 35.94%] [G loss: 0.842972]\n",
      "epoch:12 step:9411[D loss: 0.432055, acc: 54.69%, op_acc: 34.38%] [G loss: 0.857269]\n",
      "epoch:12 step:9412[D loss: 0.466493, acc: 54.69%, op_acc: 32.03%] [G loss: 0.883186]\n",
      "epoch:12 step:9413[D loss: 0.421623, acc: 62.50%, op_acc: 37.50%] [G loss: 0.856801]\n",
      "epoch:12 step:9414[D loss: 0.426176, acc: 55.47%, op_acc: 40.62%] [G loss: 0.816343]\n",
      "epoch:12 step:9415[D loss: 0.451787, acc: 50.00%, op_acc: 29.69%] [G loss: 0.776668]\n",
      "epoch:12 step:9416[D loss: 0.463395, acc: 46.88%, op_acc: 33.59%] [G loss: 0.784721]\n",
      "epoch:12 step:9417[D loss: 0.439784, acc: 62.50%, op_acc: 34.38%] [G loss: 0.886618]\n",
      "epoch:12 step:9418[D loss: 0.440547, acc: 59.38%, op_acc: 32.03%] [G loss: 0.868856]\n",
      "epoch:12 step:9419[D loss: 0.434774, acc: 67.19%, op_acc: 28.91%] [G loss: 0.849178]\n",
      "epoch:12 step:9420[D loss: 0.440756, acc: 62.50%, op_acc: 37.50%] [G loss: 0.839738]\n",
      "epoch:12 step:9421[D loss: 0.417454, acc: 60.16%, op_acc: 39.06%] [G loss: 0.895971]\n",
      "epoch:12 step:9422[D loss: 0.459973, acc: 52.34%, op_acc: 33.59%] [G loss: 0.805505]\n",
      "epoch:12 step:9423[D loss: 0.427536, acc: 61.72%, op_acc: 34.38%] [G loss: 0.814451]\n",
      "epoch:12 step:9424[D loss: 0.443490, acc: 55.47%, op_acc: 34.38%] [G loss: 0.834719]\n",
      "epoch:12 step:9425[D loss: 0.464892, acc: 49.22%, op_acc: 32.03%] [G loss: 0.860759]\n",
      "epoch:12 step:9426[D loss: 0.451578, acc: 59.38%, op_acc: 35.94%] [G loss: 0.821458]\n",
      "epoch:12 step:9427[D loss: 0.416390, acc: 60.94%, op_acc: 36.72%] [G loss: 0.843277]\n",
      "epoch:12 step:9428[D loss: 0.431817, acc: 63.28%, op_acc: 35.16%] [G loss: 0.839021]\n",
      "epoch:12 step:9429[D loss: 0.440263, acc: 62.50%, op_acc: 35.16%] [G loss: 0.809629]\n",
      "epoch:12 step:9430[D loss: 0.437666, acc: 55.47%, op_acc: 38.28%] [G loss: 0.915772]\n",
      "epoch:12 step:9431[D loss: 0.422490, acc: 54.69%, op_acc: 41.41%] [G loss: 0.842747]\n",
      "epoch:12 step:9432[D loss: 0.418862, acc: 65.62%, op_acc: 32.81%] [G loss: 0.872467]\n",
      "epoch:12 step:9433[D loss: 0.426935, acc: 65.62%, op_acc: 35.16%] [G loss: 0.878469]\n",
      "epoch:12 step:9434[D loss: 0.438311, acc: 58.59%, op_acc: 32.03%] [G loss: 0.832522]\n",
      "epoch:12 step:9435[D loss: 0.427377, acc: 65.62%, op_acc: 34.38%] [G loss: 0.872651]\n",
      "epoch:12 step:9436[D loss: 0.417691, acc: 64.84%, op_acc: 37.50%] [G loss: 0.966304]\n",
      "epoch:12 step:9437[D loss: 0.474664, acc: 49.22%, op_acc: 32.81%] [G loss: 0.903801]\n",
      "epoch:12 step:9438[D loss: 0.458429, acc: 53.12%, op_acc: 40.62%] [G loss: 0.897923]\n",
      "epoch:12 step:9439[D loss: 0.421530, acc: 62.50%, op_acc: 34.38%] [G loss: 0.946655]\n",
      "epoch:12 step:9440[D loss: 0.447006, acc: 57.81%, op_acc: 34.38%] [G loss: 0.850858]\n",
      "epoch:12 step:9441[D loss: 0.414289, acc: 66.41%, op_acc: 46.88%] [G loss: 0.891373]\n",
      "epoch:12 step:9442[D loss: 0.447487, acc: 58.59%, op_acc: 38.28%] [G loss: 0.930583]\n",
      "epoch:12 step:9443[D loss: 0.465867, acc: 60.16%, op_acc: 28.91%] [G loss: 0.895016]\n",
      "epoch:12 step:9444[D loss: 0.400560, acc: 67.19%, op_acc: 38.28%] [G loss: 0.881429]\n",
      "epoch:12 step:9445[D loss: 0.422414, acc: 67.97%, op_acc: 45.31%] [G loss: 0.881416]\n",
      "epoch:12 step:9446[D loss: 0.421105, acc: 58.59%, op_acc: 35.94%] [G loss: 0.935894]\n",
      "epoch:12 step:9447[D loss: 0.416301, acc: 62.50%, op_acc: 35.16%] [G loss: 0.838453]\n",
      "epoch:12 step:9448[D loss: 0.471125, acc: 52.34%, op_acc: 33.59%] [G loss: 0.874631]\n",
      "epoch:12 step:9449[D loss: 0.421892, acc: 64.84%, op_acc: 38.28%] [G loss: 0.846744]\n",
      "epoch:12 step:9450[D loss: 0.462887, acc: 64.84%, op_acc: 35.16%] [G loss: 0.857861]\n",
      "##############\n",
      "[0.84969354 0.85610889 0.79940677 0.81256593 0.79506116 0.82815425\n",
      " 0.89009611 0.82383613 0.80816342 0.83076387]\n",
      "##########\n",
      "epoch:12 step:9451[D loss: 0.441366, acc: 60.94%, op_acc: 28.91%] [G loss: 0.915407]\n",
      "epoch:12 step:9452[D loss: 0.445292, acc: 62.50%, op_acc: 30.47%] [G loss: 0.947896]\n",
      "epoch:12 step:9453[D loss: 0.447796, acc: 64.06%, op_acc: 31.25%] [G loss: 0.934811]\n",
      "epoch:12 step:9454[D loss: 0.439572, acc: 62.50%, op_acc: 32.81%] [G loss: 0.892215]\n",
      "epoch:12 step:9455[D loss: 0.467249, acc: 56.25%, op_acc: 33.59%] [G loss: 0.852130]\n",
      "epoch:12 step:9456[D loss: 0.453106, acc: 55.47%, op_acc: 39.06%] [G loss: 0.875213]\n",
      "epoch:12 step:9457[D loss: 0.461789, acc: 58.59%, op_acc: 30.47%] [G loss: 0.827056]\n",
      "epoch:12 step:9458[D loss: 0.407931, acc: 66.41%, op_acc: 33.59%] [G loss: 0.945219]\n",
      "epoch:12 step:9459[D loss: 0.435768, acc: 58.59%, op_acc: 33.59%] [G loss: 0.856474]\n",
      "epoch:12 step:9460[D loss: 0.453720, acc: 49.22%, op_acc: 37.50%] [G loss: 0.858527]\n",
      "epoch:12 step:9461[D loss: 0.458902, acc: 57.81%, op_acc: 32.81%] [G loss: 0.828241]\n",
      "epoch:12 step:9462[D loss: 0.433762, acc: 62.50%, op_acc: 36.72%] [G loss: 0.871474]\n",
      "epoch:12 step:9463[D loss: 0.435549, acc: 58.59%, op_acc: 34.38%] [G loss: 0.855164]\n",
      "epoch:12 step:9464[D loss: 0.439795, acc: 56.25%, op_acc: 32.03%] [G loss: 0.889068]\n",
      "epoch:12 step:9465[D loss: 0.412709, acc: 61.72%, op_acc: 39.84%] [G loss: 0.897404]\n",
      "epoch:12 step:9466[D loss: 0.449449, acc: 54.69%, op_acc: 32.03%] [G loss: 0.851979]\n",
      "epoch:12 step:9467[D loss: 0.422044, acc: 60.94%, op_acc: 36.72%] [G loss: 0.900787]\n",
      "epoch:12 step:9468[D loss: 0.441409, acc: 61.72%, op_acc: 35.16%] [G loss: 0.889675]\n",
      "epoch:12 step:9469[D loss: 0.433861, acc: 53.91%, op_acc: 36.72%] [G loss: 0.823858]\n",
      "epoch:12 step:9470[D loss: 0.426960, acc: 61.72%, op_acc: 36.72%] [G loss: 0.810980]\n",
      "epoch:12 step:9471[D loss: 0.426656, acc: 61.72%, op_acc: 34.38%] [G loss: 0.876175]\n",
      "epoch:12 step:9472[D loss: 0.437003, acc: 60.16%, op_acc: 39.06%] [G loss: 0.836159]\n",
      "epoch:12 step:9473[D loss: 0.470735, acc: 52.34%, op_acc: 32.03%] [G loss: 0.784386]\n",
      "epoch:12 step:9474[D loss: 0.418234, acc: 59.38%, op_acc: 40.62%] [G loss: 0.895059]\n",
      "epoch:12 step:9475[D loss: 0.451054, acc: 51.56%, op_acc: 34.38%] [G loss: 0.948193]\n",
      "epoch:12 step:9476[D loss: 0.419286, acc: 65.62%, op_acc: 32.81%] [G loss: 0.909719]\n",
      "epoch:12 step:9477[D loss: 0.431775, acc: 60.16%, op_acc: 39.84%] [G loss: 0.835546]\n",
      "epoch:12 step:9478[D loss: 0.416852, acc: 68.75%, op_acc: 33.59%] [G loss: 0.862546]\n",
      "epoch:12 step:9479[D loss: 0.431329, acc: 62.50%, op_acc: 35.94%] [G loss: 0.871992]\n",
      "epoch:12 step:9480[D loss: 0.469342, acc: 53.12%, op_acc: 33.59%] [G loss: 0.852205]\n",
      "epoch:12 step:9481[D loss: 0.447380, acc: 52.34%, op_acc: 32.81%] [G loss: 0.870647]\n",
      "epoch:12 step:9482[D loss: 0.451560, acc: 51.56%, op_acc: 39.84%] [G loss: 0.873050]\n",
      "epoch:12 step:9483[D loss: 0.438752, acc: 60.16%, op_acc: 32.03%] [G loss: 0.914437]\n",
      "epoch:12 step:9484[D loss: 0.431919, acc: 58.59%, op_acc: 36.72%] [G loss: 0.813720]\n",
      "epoch:12 step:9485[D loss: 0.430192, acc: 66.41%, op_acc: 35.94%] [G loss: 0.866304]\n",
      "epoch:12 step:9486[D loss: 0.405902, acc: 64.06%, op_acc: 42.19%] [G loss: 0.908992]\n",
      "epoch:12 step:9487[D loss: 0.418979, acc: 59.38%, op_acc: 35.16%] [G loss: 0.819857]\n",
      "epoch:12 step:9488[D loss: 0.460828, acc: 57.03%, op_acc: 30.47%] [G loss: 0.885604]\n",
      "epoch:12 step:9489[D loss: 0.439062, acc: 57.81%, op_acc: 34.38%] [G loss: 0.863460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9490[D loss: 0.440604, acc: 58.59%, op_acc: 36.72%] [G loss: 0.839265]\n",
      "epoch:12 step:9491[D loss: 0.432787, acc: 60.94%, op_acc: 28.91%] [G loss: 0.905924]\n",
      "epoch:12 step:9492[D loss: 0.440082, acc: 64.84%, op_acc: 34.38%] [G loss: 0.899094]\n",
      "epoch:12 step:9493[D loss: 0.440649, acc: 64.84%, op_acc: 40.62%] [G loss: 0.905503]\n",
      "epoch:12 step:9494[D loss: 0.428073, acc: 58.59%, op_acc: 35.16%] [G loss: 0.912666]\n",
      "epoch:12 step:9495[D loss: 0.422020, acc: 64.84%, op_acc: 37.50%] [G loss: 0.891666]\n",
      "epoch:12 step:9496[D loss: 0.420708, acc: 63.28%, op_acc: 36.72%] [G loss: 0.889101]\n",
      "epoch:12 step:9497[D loss: 0.467786, acc: 51.56%, op_acc: 32.03%] [G loss: 0.845681]\n",
      "epoch:12 step:9498[D loss: 0.426872, acc: 59.38%, op_acc: 33.59%] [G loss: 0.871745]\n",
      "epoch:12 step:9499[D loss: 0.418717, acc: 67.97%, op_acc: 35.16%] [G loss: 0.902747]\n",
      "epoch:12 step:9500[D loss: 0.429031, acc: 59.38%, op_acc: 36.72%] [G loss: 0.953098]\n",
      "##############\n",
      "[0.87639113 0.86636876 0.81714243 0.80192508 0.78747587 0.82502398\n",
      " 0.87897507 0.83623899 0.82448548 0.83537691]\n",
      "##########\n",
      "epoch:12 step:9501[D loss: 0.469230, acc: 53.12%, op_acc: 30.47%] [G loss: 0.866783]\n",
      "epoch:12 step:9502[D loss: 0.427368, acc: 64.06%, op_acc: 39.06%] [G loss: 0.924508]\n",
      "epoch:12 step:9503[D loss: 0.414911, acc: 67.19%, op_acc: 33.59%] [G loss: 0.912612]\n",
      "epoch:12 step:9504[D loss: 0.412674, acc: 57.81%, op_acc: 43.75%] [G loss: 0.862685]\n",
      "epoch:12 step:9505[D loss: 0.466199, acc: 57.03%, op_acc: 26.56%] [G loss: 0.884870]\n",
      "epoch:12 step:9506[D loss: 0.420477, acc: 67.97%, op_acc: 35.16%] [G loss: 0.876148]\n",
      "epoch:12 step:9507[D loss: 0.455576, acc: 57.81%, op_acc: 32.81%] [G loss: 0.924384]\n",
      "epoch:12 step:9508[D loss: 0.410885, acc: 59.38%, op_acc: 37.50%] [G loss: 0.894191]\n",
      "epoch:12 step:9509[D loss: 0.464493, acc: 55.47%, op_acc: 32.81%] [G loss: 0.880895]\n",
      "epoch:12 step:9510[D loss: 0.440024, acc: 57.03%, op_acc: 34.38%] [G loss: 0.830246]\n",
      "epoch:12 step:9511[D loss: 0.421530, acc: 61.72%, op_acc: 38.28%] [G loss: 0.810275]\n",
      "epoch:12 step:9512[D loss: 0.473879, acc: 57.03%, op_acc: 27.34%] [G loss: 0.890524]\n",
      "epoch:12 step:9513[D loss: 0.433682, acc: 63.28%, op_acc: 35.94%] [G loss: 0.967769]\n",
      "epoch:12 step:9514[D loss: 0.416235, acc: 62.50%, op_acc: 42.97%] [G loss: 0.916851]\n",
      "epoch:12 step:9515[D loss: 0.460011, acc: 55.47%, op_acc: 37.50%] [G loss: 0.923902]\n",
      "epoch:12 step:9516[D loss: 0.457117, acc: 50.00%, op_acc: 38.28%] [G loss: 0.836648]\n",
      "epoch:12 step:9517[D loss: 0.457161, acc: 52.34%, op_acc: 37.50%] [G loss: 0.800465]\n",
      "epoch:12 step:9518[D loss: 0.401018, acc: 75.00%, op_acc: 37.50%] [G loss: 0.931668]\n",
      "epoch:12 step:9519[D loss: 0.403290, acc: 64.06%, op_acc: 35.94%] [G loss: 0.968244]\n",
      "epoch:12 step:9520[D loss: 0.433540, acc: 60.94%, op_acc: 35.16%] [G loss: 0.867395]\n",
      "epoch:12 step:9521[D loss: 0.423984, acc: 57.03%, op_acc: 39.06%] [G loss: 0.841594]\n",
      "epoch:12 step:9522[D loss: 0.440072, acc: 51.56%, op_acc: 40.62%] [G loss: 0.784226]\n",
      "epoch:12 step:9523[D loss: 0.433157, acc: 57.81%, op_acc: 39.06%] [G loss: 0.895551]\n",
      "epoch:12 step:9524[D loss: 0.434579, acc: 57.03%, op_acc: 37.50%] [G loss: 0.895219]\n",
      "epoch:12 step:9525[D loss: 0.460400, acc: 57.81%, op_acc: 33.59%] [G loss: 0.810993]\n",
      "epoch:12 step:9526[D loss: 0.430514, acc: 64.84%, op_acc: 39.06%] [G loss: 0.851473]\n",
      "epoch:12 step:9527[D loss: 0.471863, acc: 55.47%, op_acc: 31.25%] [G loss: 0.829627]\n",
      "epoch:12 step:9528[D loss: 0.454114, acc: 57.81%, op_acc: 35.94%] [G loss: 0.881245]\n",
      "epoch:12 step:9529[D loss: 0.424329, acc: 59.38%, op_acc: 38.28%] [G loss: 0.864383]\n",
      "epoch:12 step:9530[D loss: 0.421922, acc: 58.59%, op_acc: 40.62%] [G loss: 0.897177]\n",
      "epoch:12 step:9531[D loss: 0.447448, acc: 56.25%, op_acc: 34.38%] [G loss: 0.836670]\n",
      "epoch:12 step:9532[D loss: 0.468247, acc: 52.34%, op_acc: 28.91%] [G loss: 0.835722]\n",
      "epoch:12 step:9533[D loss: 0.441038, acc: 54.69%, op_acc: 40.62%] [G loss: 0.894222]\n",
      "epoch:12 step:9534[D loss: 0.428971, acc: 57.03%, op_acc: 40.62%] [G loss: 0.904977]\n",
      "epoch:12 step:9535[D loss: 0.439928, acc: 56.25%, op_acc: 35.16%] [G loss: 0.837512]\n",
      "epoch:12 step:9536[D loss: 0.450675, acc: 54.69%, op_acc: 36.72%] [G loss: 0.892316]\n",
      "epoch:12 step:9537[D loss: 0.436421, acc: 57.03%, op_acc: 35.94%] [G loss: 0.842493]\n",
      "epoch:12 step:9538[D loss: 0.444401, acc: 57.81%, op_acc: 36.72%] [G loss: 0.902921]\n",
      "epoch:12 step:9539[D loss: 0.421717, acc: 61.72%, op_acc: 39.06%] [G loss: 0.957683]\n",
      "epoch:12 step:9540[D loss: 0.423896, acc: 66.41%, op_acc: 40.62%] [G loss: 0.873429]\n",
      "epoch:12 step:9541[D loss: 0.425506, acc: 60.94%, op_acc: 40.62%] [G loss: 0.927586]\n",
      "epoch:12 step:9542[D loss: 0.426017, acc: 60.94%, op_acc: 36.72%] [G loss: 0.861162]\n",
      "epoch:12 step:9543[D loss: 0.454580, acc: 58.59%, op_acc: 37.50%] [G loss: 0.948113]\n",
      "epoch:12 step:9544[D loss: 0.424157, acc: 61.72%, op_acc: 34.38%] [G loss: 0.933373]\n",
      "epoch:12 step:9545[D loss: 0.446717, acc: 58.59%, op_acc: 33.59%] [G loss: 0.866438]\n",
      "epoch:12 step:9546[D loss: 0.484027, acc: 46.88%, op_acc: 31.25%] [G loss: 0.830525]\n",
      "epoch:12 step:9547[D loss: 0.405325, acc: 64.06%, op_acc: 41.41%] [G loss: 0.932912]\n",
      "epoch:12 step:9548[D loss: 0.417949, acc: 60.94%, op_acc: 39.84%] [G loss: 0.886142]\n",
      "epoch:12 step:9549[D loss: 0.417820, acc: 64.06%, op_acc: 35.94%] [G loss: 0.885504]\n",
      "epoch:12 step:9550[D loss: 0.456142, acc: 52.34%, op_acc: 27.34%] [G loss: 0.877058]\n",
      "##############\n",
      "[0.85279939 0.85732233 0.81217095 0.78663705 0.78437413 0.83297167\n",
      " 0.88177547 0.8229055  0.80233265 0.83220901]\n",
      "##########\n",
      "epoch:12 step:9551[D loss: 0.415541, acc: 60.94%, op_acc: 39.06%] [G loss: 0.929640]\n",
      "epoch:12 step:9552[D loss: 0.430201, acc: 67.19%, op_acc: 32.81%] [G loss: 0.895957]\n",
      "epoch:12 step:9553[D loss: 0.433341, acc: 53.12%, op_acc: 39.06%] [G loss: 0.872181]\n",
      "epoch:12 step:9554[D loss: 0.402769, acc: 69.53%, op_acc: 35.16%] [G loss: 0.941319]\n",
      "epoch:12 step:9555[D loss: 0.410911, acc: 66.41%, op_acc: 38.28%] [G loss: 0.895700]\n",
      "epoch:12 step:9556[D loss: 0.444399, acc: 55.47%, op_acc: 39.06%] [G loss: 0.887563]\n",
      "epoch:12 step:9557[D loss: 0.419745, acc: 68.75%, op_acc: 40.62%] [G loss: 0.977358]\n",
      "epoch:12 step:9558[D loss: 0.448340, acc: 53.91%, op_acc: 35.94%] [G loss: 0.867825]\n",
      "epoch:12 step:9559[D loss: 0.408353, acc: 63.28%, op_acc: 35.94%] [G loss: 0.878258]\n",
      "epoch:12 step:9560[D loss: 0.424326, acc: 56.25%, op_acc: 41.41%] [G loss: 0.892948]\n",
      "epoch:12 step:9561[D loss: 0.447176, acc: 56.25%, op_acc: 34.38%] [G loss: 0.831347]\n",
      "epoch:12 step:9562[D loss: 0.432252, acc: 57.81%, op_acc: 35.16%] [G loss: 0.907977]\n",
      "epoch:12 step:9563[D loss: 0.421653, acc: 60.94%, op_acc: 42.19%] [G loss: 0.863073]\n",
      "epoch:12 step:9564[D loss: 0.428469, acc: 60.94%, op_acc: 37.50%] [G loss: 0.890582]\n",
      "epoch:12 step:9565[D loss: 0.458851, acc: 61.72%, op_acc: 31.25%] [G loss: 0.915852]\n",
      "epoch:12 step:9566[D loss: 0.429959, acc: 58.59%, op_acc: 33.59%] [G loss: 0.829488]\n",
      "epoch:12 step:9567[D loss: 0.424708, acc: 57.81%, op_acc: 37.50%] [G loss: 0.880370]\n",
      "epoch:12 step:9568[D loss: 0.423474, acc: 69.53%, op_acc: 35.16%] [G loss: 0.859538]\n",
      "epoch:12 step:9569[D loss: 0.460467, acc: 50.78%, op_acc: 35.16%] [G loss: 0.900403]\n",
      "epoch:12 step:9570[D loss: 0.439411, acc: 57.81%, op_acc: 39.84%] [G loss: 0.785168]\n",
      "epoch:12 step:9571[D loss: 0.478367, acc: 52.34%, op_acc: 33.59%] [G loss: 0.788394]\n",
      "epoch:12 step:9572[D loss: 0.450445, acc: 58.59%, op_acc: 32.03%] [G loss: 0.887354]\n",
      "epoch:12 step:9573[D loss: 0.417309, acc: 59.38%, op_acc: 35.94%] [G loss: 0.926858]\n",
      "epoch:12 step:9574[D loss: 0.435697, acc: 57.81%, op_acc: 32.81%] [G loss: 0.879048]\n",
      "epoch:12 step:9575[D loss: 0.438069, acc: 59.38%, op_acc: 32.03%] [G loss: 0.902215]\n",
      "epoch:12 step:9576[D loss: 0.460084, acc: 54.69%, op_acc: 34.38%] [G loss: 0.797617]\n",
      "epoch:12 step:9577[D loss: 0.432377, acc: 57.81%, op_acc: 38.28%] [G loss: 0.897875]\n",
      "epoch:12 step:9578[D loss: 0.467130, acc: 53.91%, op_acc: 35.16%] [G loss: 0.870710]\n",
      "epoch:12 step:9579[D loss: 0.396542, acc: 65.62%, op_acc: 39.06%] [G loss: 0.925296]\n",
      "epoch:12 step:9580[D loss: 0.429916, acc: 63.28%, op_acc: 28.12%] [G loss: 0.884446]\n",
      "epoch:12 step:9581[D loss: 0.432844, acc: 56.25%, op_acc: 39.06%] [G loss: 0.902798]\n",
      "epoch:12 step:9582[D loss: 0.476063, acc: 50.00%, op_acc: 35.94%] [G loss: 0.895917]\n",
      "epoch:12 step:9583[D loss: 0.392511, acc: 67.19%, op_acc: 41.41%] [G loss: 0.915984]\n",
      "epoch:12 step:9584[D loss: 0.416617, acc: 63.28%, op_acc: 37.50%] [G loss: 0.912745]\n",
      "epoch:12 step:9585[D loss: 0.438981, acc: 53.91%, op_acc: 41.41%] [G loss: 0.903666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9586[D loss: 0.461091, acc: 57.03%, op_acc: 37.50%] [G loss: 0.855388]\n",
      "epoch:12 step:9587[D loss: 0.441097, acc: 61.72%, op_acc: 35.16%] [G loss: 0.922440]\n",
      "epoch:12 step:9588[D loss: 0.429445, acc: 66.41%, op_acc: 35.94%] [G loss: 0.907880]\n",
      "epoch:12 step:9589[D loss: 0.424973, acc: 56.25%, op_acc: 40.62%] [G loss: 0.838746]\n",
      "epoch:12 step:9590[D loss: 0.433274, acc: 57.03%, op_acc: 38.28%] [G loss: 0.897156]\n",
      "epoch:12 step:9591[D loss: 0.408069, acc: 63.28%, op_acc: 37.50%] [G loss: 0.897402]\n",
      "epoch:12 step:9592[D loss: 0.445654, acc: 60.94%, op_acc: 33.59%] [G loss: 0.862995]\n",
      "epoch:12 step:9593[D loss: 0.437337, acc: 61.72%, op_acc: 31.25%] [G loss: 0.885990]\n",
      "epoch:12 step:9594[D loss: 0.450738, acc: 59.38%, op_acc: 33.59%] [G loss: 0.889710]\n",
      "epoch:12 step:9595[D loss: 0.440992, acc: 57.81%, op_acc: 35.94%] [G loss: 0.880941]\n",
      "epoch:12 step:9596[D loss: 0.453758, acc: 55.47%, op_acc: 40.62%] [G loss: 0.851603]\n",
      "epoch:12 step:9597[D loss: 0.455809, acc: 50.78%, op_acc: 36.72%] [G loss: 0.822689]\n",
      "epoch:12 step:9598[D loss: 0.433146, acc: 56.25%, op_acc: 39.06%] [G loss: 0.825432]\n",
      "epoch:12 step:9599[D loss: 0.425853, acc: 62.50%, op_acc: 36.72%] [G loss: 0.892287]\n",
      "epoch:12 step:9600[D loss: 0.449396, acc: 54.69%, op_acc: 37.50%] [G loss: 0.898110]\n",
      "##############\n",
      "[0.86339283 0.8413288  0.81745836 0.81216849 0.82043146 0.81756689\n",
      " 0.86815896 0.84165282 0.81215338 0.84611289]\n",
      "##########\n",
      "epoch:12 step:9601[D loss: 0.434223, acc: 60.94%, op_acc: 37.50%] [G loss: 0.809989]\n",
      "epoch:12 step:9602[D loss: 0.451403, acc: 57.03%, op_acc: 33.59%] [G loss: 0.920695]\n",
      "epoch:12 step:9603[D loss: 0.406614, acc: 67.19%, op_acc: 38.28%] [G loss: 0.935511]\n",
      "epoch:12 step:9604[D loss: 0.440966, acc: 56.25%, op_acc: 35.94%] [G loss: 0.842352]\n",
      "epoch:12 step:9605[D loss: 0.411574, acc: 64.84%, op_acc: 37.50%] [G loss: 0.932538]\n",
      "epoch:12 step:9606[D loss: 0.458598, acc: 57.81%, op_acc: 33.59%] [G loss: 0.896950]\n",
      "epoch:12 step:9607[D loss: 0.429519, acc: 58.59%, op_acc: 38.28%] [G loss: 0.889821]\n",
      "epoch:12 step:9608[D loss: 0.432851, acc: 59.38%, op_acc: 34.38%] [G loss: 0.826995]\n",
      "epoch:12 step:9609[D loss: 0.420677, acc: 64.84%, op_acc: 35.16%] [G loss: 0.886122]\n",
      "epoch:12 step:9610[D loss: 0.455653, acc: 52.34%, op_acc: 34.38%] [G loss: 0.947527]\n",
      "epoch:12 step:9611[D loss: 0.448641, acc: 50.00%, op_acc: 35.94%] [G loss: 0.784452]\n",
      "epoch:12 step:9612[D loss: 0.432469, acc: 61.72%, op_acc: 32.03%] [G loss: 0.913399]\n",
      "epoch:12 step:9613[D loss: 0.462494, acc: 50.78%, op_acc: 35.94%] [G loss: 0.864777]\n",
      "epoch:12 step:9614[D loss: 0.419395, acc: 65.62%, op_acc: 33.59%] [G loss: 0.893938]\n",
      "epoch:12 step:9615[D loss: 0.449142, acc: 57.81%, op_acc: 33.59%] [G loss: 0.892723]\n",
      "epoch:12 step:9616[D loss: 0.442548, acc: 57.03%, op_acc: 29.69%] [G loss: 0.852639]\n",
      "epoch:12 step:9617[D loss: 0.452519, acc: 55.47%, op_acc: 36.72%] [G loss: 0.902939]\n",
      "epoch:12 step:9618[D loss: 0.443262, acc: 63.28%, op_acc: 34.38%] [G loss: 0.934083]\n",
      "epoch:12 step:9619[D loss: 0.424985, acc: 55.47%, op_acc: 40.62%] [G loss: 0.902364]\n",
      "epoch:12 step:9620[D loss: 0.429165, acc: 65.62%, op_acc: 34.38%] [G loss: 0.950735]\n",
      "epoch:12 step:9621[D loss: 0.420261, acc: 64.84%, op_acc: 39.84%] [G loss: 0.906595]\n",
      "epoch:12 step:9622[D loss: 0.444685, acc: 63.28%, op_acc: 33.59%] [G loss: 0.872635]\n",
      "epoch:12 step:9623[D loss: 0.426665, acc: 64.06%, op_acc: 39.84%] [G loss: 0.827267]\n",
      "epoch:12 step:9624[D loss: 0.425016, acc: 61.72%, op_acc: 42.19%] [G loss: 0.911030]\n",
      "epoch:12 step:9625[D loss: 0.440054, acc: 56.25%, op_acc: 36.72%] [G loss: 0.888131]\n",
      "epoch:12 step:9626[D loss: 0.474545, acc: 48.44%, op_acc: 31.25%] [G loss: 0.840477]\n",
      "epoch:12 step:9627[D loss: 0.421950, acc: 59.38%, op_acc: 35.16%] [G loss: 0.812408]\n",
      "epoch:12 step:9628[D loss: 0.431080, acc: 56.25%, op_acc: 35.94%] [G loss: 0.848974]\n",
      "epoch:12 step:9629[D loss: 0.449618, acc: 57.81%, op_acc: 35.94%] [G loss: 0.853329]\n",
      "epoch:12 step:9630[D loss: 0.395142, acc: 72.66%, op_acc: 40.62%] [G loss: 0.817402]\n",
      "epoch:12 step:9631[D loss: 0.447933, acc: 61.72%, op_acc: 29.69%] [G loss: 0.851872]\n",
      "epoch:12 step:9632[D loss: 0.435462, acc: 57.03%, op_acc: 32.81%] [G loss: 0.929598]\n",
      "epoch:12 step:9633[D loss: 0.420896, acc: 60.94%, op_acc: 35.16%] [G loss: 0.828783]\n",
      "epoch:12 step:9634[D loss: 0.410958, acc: 63.28%, op_acc: 39.06%] [G loss: 0.874679]\n",
      "epoch:12 step:9635[D loss: 0.444057, acc: 61.72%, op_acc: 32.81%] [G loss: 0.884449]\n",
      "epoch:12 step:9636[D loss: 0.427543, acc: 61.72%, op_acc: 34.38%] [G loss: 0.973571]\n",
      "epoch:12 step:9637[D loss: 0.415266, acc: 61.72%, op_acc: 37.50%] [G loss: 0.910715]\n",
      "epoch:12 step:9638[D loss: 0.409569, acc: 65.62%, op_acc: 39.84%] [G loss: 0.887209]\n",
      "epoch:12 step:9639[D loss: 0.457486, acc: 57.81%, op_acc: 32.03%] [G loss: 0.832665]\n",
      "epoch:12 step:9640[D loss: 0.415630, acc: 60.16%, op_acc: 39.84%] [G loss: 0.961056]\n",
      "epoch:12 step:9641[D loss: 0.418399, acc: 63.28%, op_acc: 43.75%] [G loss: 0.872388]\n",
      "epoch:12 step:9642[D loss: 0.428223, acc: 61.72%, op_acc: 35.16%] [G loss: 0.841452]\n",
      "epoch:12 step:9643[D loss: 0.447973, acc: 59.38%, op_acc: 33.59%] [G loss: 0.900359]\n",
      "epoch:12 step:9644[D loss: 0.439142, acc: 58.59%, op_acc: 37.50%] [G loss: 0.840868]\n",
      "epoch:12 step:9645[D loss: 0.423137, acc: 62.50%, op_acc: 42.19%] [G loss: 0.888537]\n",
      "epoch:12 step:9646[D loss: 0.437138, acc: 62.50%, op_acc: 32.81%] [G loss: 0.890618]\n",
      "epoch:12 step:9647[D loss: 0.438247, acc: 57.81%, op_acc: 35.94%] [G loss: 0.902918]\n",
      "epoch:12 step:9648[D loss: 0.471215, acc: 46.88%, op_acc: 35.16%] [G loss: 0.869240]\n",
      "epoch:12 step:9649[D loss: 0.453541, acc: 60.16%, op_acc: 32.81%] [G loss: 0.880165]\n",
      "epoch:12 step:9650[D loss: 0.437153, acc: 64.06%, op_acc: 34.38%] [G loss: 0.848251]\n",
      "##############\n",
      "[0.86422696 0.87397356 0.81069398 0.80902762 0.79575249 0.82607108\n",
      " 0.89060552 0.84204826 0.82279559 0.85280176]\n",
      "##########\n",
      "epoch:12 step:9651[D loss: 0.455633, acc: 56.25%, op_acc: 37.50%] [G loss: 0.859680]\n",
      "epoch:12 step:9652[D loss: 0.423235, acc: 64.06%, op_acc: 37.50%] [G loss: 0.835374]\n",
      "epoch:12 step:9653[D loss: 0.427713, acc: 60.94%, op_acc: 35.16%] [G loss: 0.826534]\n",
      "epoch:12 step:9654[D loss: 0.473296, acc: 58.59%, op_acc: 32.81%] [G loss: 0.935079]\n",
      "epoch:12 step:9655[D loss: 0.425187, acc: 60.16%, op_acc: 36.72%] [G loss: 0.894544]\n",
      "epoch:12 step:9656[D loss: 0.436041, acc: 57.03%, op_acc: 41.41%] [G loss: 0.898055]\n",
      "epoch:12 step:9657[D loss: 0.419955, acc: 61.72%, op_acc: 33.59%] [G loss: 0.848738]\n",
      "epoch:12 step:9658[D loss: 0.449177, acc: 52.34%, op_acc: 32.81%] [G loss: 0.791837]\n",
      "epoch:12 step:9659[D loss: 0.443015, acc: 59.38%, op_acc: 34.38%] [G loss: 0.896637]\n",
      "epoch:12 step:9660[D loss: 0.423341, acc: 62.50%, op_acc: 40.62%] [G loss: 0.867731]\n",
      "epoch:12 step:9661[D loss: 0.458824, acc: 53.91%, op_acc: 26.56%] [G loss: 0.828772]\n",
      "epoch:12 step:9662[D loss: 0.443014, acc: 57.81%, op_acc: 35.94%] [G loss: 0.778990]\n",
      "epoch:12 step:9663[D loss: 0.437206, acc: 58.59%, op_acc: 39.06%] [G loss: 0.828537]\n",
      "epoch:12 step:9664[D loss: 0.451360, acc: 57.03%, op_acc: 32.81%] [G loss: 0.862809]\n",
      "epoch:12 step:9665[D loss: 0.434506, acc: 59.38%, op_acc: 40.62%] [G loss: 0.880897]\n",
      "epoch:12 step:9666[D loss: 0.430941, acc: 60.16%, op_acc: 37.50%] [G loss: 0.883676]\n",
      "epoch:12 step:9667[D loss: 0.439438, acc: 55.47%, op_acc: 33.59%] [G loss: 0.849639]\n",
      "epoch:12 step:9668[D loss: 0.418545, acc: 65.62%, op_acc: 38.28%] [G loss: 0.843374]\n",
      "epoch:12 step:9669[D loss: 0.451628, acc: 57.03%, op_acc: 32.81%] [G loss: 0.899813]\n",
      "epoch:12 step:9670[D loss: 0.442938, acc: 56.25%, op_acc: 37.50%] [G loss: 0.902608]\n",
      "epoch:12 step:9671[D loss: 0.438500, acc: 58.59%, op_acc: 36.72%] [G loss: 0.885359]\n",
      "epoch:12 step:9672[D loss: 0.462739, acc: 58.59%, op_acc: 36.72%] [G loss: 0.953289]\n",
      "epoch:12 step:9673[D loss: 0.412781, acc: 63.28%, op_acc: 37.50%] [G loss: 0.912633]\n",
      "epoch:12 step:9674[D loss: 0.398255, acc: 70.31%, op_acc: 32.81%] [G loss: 0.885902]\n",
      "epoch:12 step:9675[D loss: 0.463540, acc: 53.12%, op_acc: 34.38%] [G loss: 0.894059]\n",
      "epoch:12 step:9676[D loss: 0.419311, acc: 57.03%, op_acc: 38.28%] [G loss: 0.928970]\n",
      "epoch:12 step:9677[D loss: 0.443880, acc: 52.34%, op_acc: 33.59%] [G loss: 0.944031]\n",
      "epoch:12 step:9678[D loss: 0.490356, acc: 55.47%, op_acc: 28.12%] [G loss: 0.887327]\n",
      "epoch:12 step:9679[D loss: 0.410400, acc: 65.62%, op_acc: 38.28%] [G loss: 0.941577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9680[D loss: 0.429058, acc: 62.50%, op_acc: 34.38%] [G loss: 0.891355]\n",
      "epoch:12 step:9681[D loss: 0.448168, acc: 61.72%, op_acc: 34.38%] [G loss: 0.907514]\n",
      "epoch:12 step:9682[D loss: 0.445760, acc: 59.38%, op_acc: 33.59%] [G loss: 0.892623]\n",
      "epoch:12 step:9683[D loss: 0.451023, acc: 51.56%, op_acc: 35.94%] [G loss: 0.951300]\n",
      "epoch:12 step:9684[D loss: 0.455082, acc: 53.12%, op_acc: 37.50%] [G loss: 0.904376]\n",
      "epoch:12 step:9685[D loss: 0.442541, acc: 57.81%, op_acc: 39.06%] [G loss: 0.801817]\n",
      "epoch:12 step:9686[D loss: 0.426408, acc: 69.53%, op_acc: 31.25%] [G loss: 0.901893]\n",
      "epoch:12 step:9687[D loss: 0.450016, acc: 55.47%, op_acc: 36.72%] [G loss: 0.888076]\n",
      "epoch:12 step:9688[D loss: 0.460189, acc: 50.00%, op_acc: 33.59%] [G loss: 0.843338]\n",
      "epoch:12 step:9689[D loss: 0.419254, acc: 68.75%, op_acc: 35.16%] [G loss: 0.909991]\n",
      "epoch:12 step:9690[D loss: 0.447502, acc: 57.81%, op_acc: 29.69%] [G loss: 0.867931]\n",
      "epoch:12 step:9691[D loss: 0.439642, acc: 53.12%, op_acc: 39.84%] [G loss: 0.816117]\n",
      "epoch:12 step:9692[D loss: 0.433447, acc: 66.41%, op_acc: 33.59%] [G loss: 0.843339]\n",
      "epoch:12 step:9693[D loss: 0.462705, acc: 48.44%, op_acc: 32.03%] [G loss: 0.797600]\n",
      "epoch:12 step:9694[D loss: 0.439025, acc: 58.59%, op_acc: 35.94%] [G loss: 0.848883]\n",
      "epoch:12 step:9695[D loss: 0.441037, acc: 59.38%, op_acc: 39.84%] [G loss: 0.813275]\n",
      "epoch:12 step:9696[D loss: 0.436505, acc: 60.16%, op_acc: 32.81%] [G loss: 0.758526]\n",
      "epoch:12 step:9697[D loss: 0.445387, acc: 52.34%, op_acc: 33.59%] [G loss: 0.887490]\n",
      "epoch:12 step:9698[D loss: 0.434027, acc: 58.59%, op_acc: 34.38%] [G loss: 0.909230]\n",
      "epoch:12 step:9699[D loss: 0.414319, acc: 60.94%, op_acc: 38.28%] [G loss: 0.907030]\n",
      "epoch:12 step:9700[D loss: 0.443933, acc: 57.03%, op_acc: 35.16%] [G loss: 0.856033]\n",
      "##############\n",
      "[0.83802317 0.86830994 0.82189242 0.80020553 0.78951738 0.82148969\n",
      " 0.87447453 0.82952076 0.84467847 0.83570922]\n",
      "##########\n",
      "epoch:12 step:9701[D loss: 0.433136, acc: 60.16%, op_acc: 33.59%] [G loss: 0.847833]\n",
      "epoch:12 step:9702[D loss: 0.424915, acc: 62.50%, op_acc: 39.06%] [G loss: 0.902237]\n",
      "epoch:12 step:9703[D loss: 0.440470, acc: 59.38%, op_acc: 35.94%] [G loss: 0.893935]\n",
      "epoch:12 step:9704[D loss: 0.444784, acc: 57.03%, op_acc: 37.50%] [G loss: 0.842848]\n",
      "epoch:12 step:9705[D loss: 0.446373, acc: 60.94%, op_acc: 32.03%] [G loss: 0.819942]\n",
      "epoch:12 step:9706[D loss: 0.429646, acc: 54.69%, op_acc: 40.62%] [G loss: 0.864773]\n",
      "epoch:12 step:9707[D loss: 0.450150, acc: 53.12%, op_acc: 31.25%] [G loss: 0.877673]\n",
      "epoch:12 step:9708[D loss: 0.452427, acc: 56.25%, op_acc: 35.16%] [G loss: 0.788124]\n",
      "epoch:12 step:9709[D loss: 0.466096, acc: 51.56%, op_acc: 35.94%] [G loss: 0.887904]\n",
      "epoch:12 step:9710[D loss: 0.409976, acc: 61.72%, op_acc: 43.75%] [G loss: 0.812654]\n",
      "epoch:12 step:9711[D loss: 0.455666, acc: 56.25%, op_acc: 36.72%] [G loss: 0.781834]\n",
      "epoch:12 step:9712[D loss: 0.433773, acc: 60.16%, op_acc: 35.94%] [G loss: 0.821801]\n",
      "epoch:12 step:9713[D loss: 0.421903, acc: 67.19%, op_acc: 37.50%] [G loss: 0.831234]\n",
      "epoch:12 step:9714[D loss: 0.452312, acc: 50.78%, op_acc: 37.50%] [G loss: 0.890556]\n",
      "epoch:12 step:9715[D loss: 0.475245, acc: 51.56%, op_acc: 31.25%] [G loss: 0.863465]\n",
      "epoch:12 step:9716[D loss: 0.431107, acc: 64.06%, op_acc: 34.38%] [G loss: 0.905361]\n",
      "epoch:12 step:9717[D loss: 0.452288, acc: 58.59%, op_acc: 31.25%] [G loss: 0.860345]\n",
      "epoch:12 step:9718[D loss: 0.442793, acc: 57.81%, op_acc: 34.38%] [G loss: 0.910052]\n",
      "epoch:12 step:9719[D loss: 0.463902, acc: 52.34%, op_acc: 37.50%] [G loss: 0.878699]\n",
      "epoch:12 step:9720[D loss: 0.430730, acc: 59.38%, op_acc: 37.50%] [G loss: 0.877597]\n",
      "epoch:12 step:9721[D loss: 0.455817, acc: 54.69%, op_acc: 37.50%] [G loss: 0.871242]\n",
      "epoch:12 step:9722[D loss: 0.441791, acc: 56.25%, op_acc: 35.16%] [G loss: 0.810543]\n",
      "epoch:12 step:9723[D loss: 0.461486, acc: 52.34%, op_acc: 31.25%] [G loss: 0.863711]\n",
      "epoch:12 step:9724[D loss: 0.430980, acc: 60.16%, op_acc: 33.59%] [G loss: 0.888627]\n",
      "epoch:12 step:9725[D loss: 0.418821, acc: 54.69%, op_acc: 41.41%] [G loss: 0.788581]\n",
      "epoch:12 step:9726[D loss: 0.450935, acc: 57.03%, op_acc: 35.16%] [G loss: 0.885605]\n",
      "epoch:12 step:9727[D loss: 0.436416, acc: 62.50%, op_acc: 32.03%] [G loss: 0.763659]\n",
      "epoch:12 step:9728[D loss: 0.451306, acc: 57.81%, op_acc: 35.94%] [G loss: 0.900093]\n",
      "epoch:12 step:9729[D loss: 0.478152, acc: 56.25%, op_acc: 35.16%] [G loss: 0.816657]\n",
      "epoch:12 step:9730[D loss: 0.417884, acc: 61.72%, op_acc: 39.84%] [G loss: 0.853617]\n",
      "epoch:12 step:9731[D loss: 0.453967, acc: 54.69%, op_acc: 32.81%] [G loss: 0.865636]\n",
      "epoch:12 step:9732[D loss: 0.432579, acc: 62.50%, op_acc: 38.28%] [G loss: 0.920668]\n",
      "epoch:12 step:9733[D loss: 0.405237, acc: 68.75%, op_acc: 37.50%] [G loss: 0.913374]\n",
      "epoch:12 step:9734[D loss: 0.419903, acc: 60.94%, op_acc: 39.06%] [G loss: 0.902978]\n",
      "epoch:12 step:9735[D loss: 0.450769, acc: 55.47%, op_acc: 35.94%] [G loss: 0.856746]\n",
      "epoch:12 step:9736[D loss: 0.448470, acc: 53.91%, op_acc: 35.94%] [G loss: 0.923802]\n",
      "epoch:12 step:9737[D loss: 0.429414, acc: 59.38%, op_acc: 43.75%] [G loss: 0.850176]\n",
      "epoch:12 step:9738[D loss: 0.427851, acc: 60.16%, op_acc: 39.84%] [G loss: 0.865656]\n",
      "epoch:12 step:9739[D loss: 0.442648, acc: 62.50%, op_acc: 34.38%] [G loss: 0.903050]\n",
      "epoch:12 step:9740[D loss: 0.457602, acc: 57.81%, op_acc: 33.59%] [G loss: 0.901456]\n",
      "epoch:12 step:9741[D loss: 0.419296, acc: 57.81%, op_acc: 39.84%] [G loss: 0.824023]\n",
      "epoch:12 step:9742[D loss: 0.427250, acc: 59.38%, op_acc: 35.16%] [G loss: 0.879742]\n",
      "epoch:12 step:9743[D loss: 0.414736, acc: 57.03%, op_acc: 38.28%] [G loss: 0.831284]\n",
      "epoch:12 step:9744[D loss: 0.438222, acc: 59.38%, op_acc: 33.59%] [G loss: 0.854197]\n",
      "epoch:12 step:9745[D loss: 0.417289, acc: 62.50%, op_acc: 42.97%] [G loss: 0.931334]\n",
      "epoch:12 step:9746[D loss: 0.424763, acc: 57.81%, op_acc: 39.84%] [G loss: 0.885169]\n",
      "epoch:12 step:9747[D loss: 0.448079, acc: 53.91%, op_acc: 31.25%] [G loss: 0.814565]\n",
      "epoch:12 step:9748[D loss: 0.420328, acc: 64.06%, op_acc: 35.94%] [G loss: 0.894073]\n",
      "epoch:12 step:9749[D loss: 0.434992, acc: 60.16%, op_acc: 36.72%] [G loss: 0.893645]\n",
      "epoch:12 step:9750[D loss: 0.438341, acc: 58.59%, op_acc: 29.69%] [G loss: 0.936507]\n",
      "##############\n",
      "[0.85507423 0.84684848 0.83185475 0.81596324 0.78381601 0.82188314\n",
      " 0.88431544 0.84033261 0.80228758 0.84676566]\n",
      "##########\n",
      "epoch:12 step:9751[D loss: 0.397101, acc: 66.41%, op_acc: 42.19%] [G loss: 0.893885]\n",
      "epoch:12 step:9752[D loss: 0.435060, acc: 66.41%, op_acc: 35.94%] [G loss: 0.885863]\n",
      "epoch:12 step:9753[D loss: 0.407571, acc: 68.75%, op_acc: 39.06%] [G loss: 0.895749]\n",
      "epoch:12 step:9754[D loss: 0.425312, acc: 57.81%, op_acc: 33.59%] [G loss: 0.931211]\n",
      "epoch:12 step:9755[D loss: 0.427079, acc: 60.94%, op_acc: 34.38%] [G loss: 0.960165]\n",
      "epoch:12 step:9756[D loss: 0.435352, acc: 56.25%, op_acc: 35.94%] [G loss: 0.947634]\n",
      "epoch:12 step:9757[D loss: 0.424270, acc: 64.06%, op_acc: 40.62%] [G loss: 0.921916]\n",
      "epoch:12 step:9758[D loss: 0.425478, acc: 60.94%, op_acc: 38.28%] [G loss: 0.887123]\n",
      "epoch:12 step:9759[D loss: 0.440268, acc: 59.38%, op_acc: 35.16%] [G loss: 0.957831]\n",
      "epoch:12 step:9760[D loss: 0.460195, acc: 48.44%, op_acc: 35.16%] [G loss: 0.845929]\n",
      "epoch:12 step:9761[D loss: 0.444054, acc: 54.69%, op_acc: 35.94%] [G loss: 0.942327]\n",
      "epoch:12 step:9762[D loss: 0.437584, acc: 57.03%, op_acc: 35.94%] [G loss: 0.899647]\n",
      "epoch:12 step:9763[D loss: 0.438994, acc: 56.25%, op_acc: 37.50%] [G loss: 0.885599]\n",
      "epoch:12 step:9764[D loss: 0.417763, acc: 58.59%, op_acc: 42.19%] [G loss: 0.871370]\n",
      "epoch:12 step:9765[D loss: 0.455739, acc: 59.38%, op_acc: 35.16%] [G loss: 0.829139]\n",
      "epoch:12 step:9766[D loss: 0.436822, acc: 59.38%, op_acc: 35.16%] [G loss: 0.819457]\n",
      "epoch:12 step:9767[D loss: 0.466333, acc: 57.03%, op_acc: 32.03%] [G loss: 0.849950]\n",
      "epoch:12 step:9768[D loss: 0.458445, acc: 52.34%, op_acc: 37.50%] [G loss: 0.817462]\n",
      "epoch:12 step:9769[D loss: 0.429235, acc: 60.16%, op_acc: 40.62%] [G loss: 0.874224]\n",
      "epoch:12 step:9770[D loss: 0.476795, acc: 49.22%, op_acc: 28.12%] [G loss: 0.854441]\n",
      "epoch:12 step:9771[D loss: 0.454636, acc: 50.78%, op_acc: 33.59%] [G loss: 0.816931]\n",
      "epoch:12 step:9772[D loss: 0.423149, acc: 64.84%, op_acc: 43.75%] [G loss: 0.905983]\n",
      "epoch:12 step:9773[D loss: 0.407822, acc: 71.09%, op_acc: 31.25%] [G loss: 0.818441]\n",
      "epoch:12 step:9774[D loss: 0.439372, acc: 57.03%, op_acc: 31.25%] [G loss: 0.870853]\n",
      "epoch:12 step:9775[D loss: 0.406930, acc: 67.97%, op_acc: 42.19%] [G loss: 0.831069]\n",
      "epoch:12 step:9776[D loss: 0.389700, acc: 71.09%, op_acc: 44.53%] [G loss: 0.872735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9777[D loss: 0.471792, acc: 48.44%, op_acc: 34.38%] [G loss: 0.937008]\n",
      "epoch:12 step:9778[D loss: 0.420543, acc: 61.72%, op_acc: 37.50%] [G loss: 0.854965]\n",
      "epoch:12 step:9779[D loss: 0.462355, acc: 56.25%, op_acc: 33.59%] [G loss: 0.823167]\n",
      "epoch:12 step:9780[D loss: 0.438557, acc: 52.34%, op_acc: 39.06%] [G loss: 0.875303]\n",
      "epoch:12 step:9781[D loss: 0.459156, acc: 52.34%, op_acc: 39.06%] [G loss: 0.870028]\n",
      "epoch:12 step:9782[D loss: 0.431584, acc: 59.38%, op_acc: 37.50%] [G loss: 0.899285]\n",
      "epoch:12 step:9783[D loss: 0.467953, acc: 47.66%, op_acc: 34.38%] [G loss: 0.826616]\n",
      "epoch:12 step:9784[D loss: 0.441351, acc: 60.16%, op_acc: 35.16%] [G loss: 0.845431]\n",
      "epoch:12 step:9785[D loss: 0.459828, acc: 56.25%, op_acc: 34.38%] [G loss: 0.835390]\n",
      "epoch:12 step:9786[D loss: 0.434429, acc: 58.59%, op_acc: 37.50%] [G loss: 0.868195]\n",
      "epoch:12 step:9787[D loss: 0.433272, acc: 60.16%, op_acc: 35.16%] [G loss: 0.919313]\n",
      "epoch:12 step:9788[D loss: 0.419619, acc: 60.16%, op_acc: 38.28%] [G loss: 0.888610]\n",
      "epoch:12 step:9789[D loss: 0.437460, acc: 57.03%, op_acc: 39.06%] [G loss: 0.871679]\n",
      "epoch:12 step:9790[D loss: 0.424068, acc: 58.59%, op_acc: 42.97%] [G loss: 0.889069]\n",
      "epoch:12 step:9791[D loss: 0.445665, acc: 52.34%, op_acc: 34.38%] [G loss: 0.865781]\n",
      "epoch:12 step:9792[D loss: 0.453497, acc: 57.81%, op_acc: 36.72%] [G loss: 0.747208]\n",
      "epoch:12 step:9793[D loss: 0.435964, acc: 65.62%, op_acc: 33.59%] [G loss: 0.922524]\n",
      "epoch:12 step:9794[D loss: 0.423871, acc: 60.94%, op_acc: 37.50%] [G loss: 0.860950]\n",
      "epoch:12 step:9795[D loss: 0.427500, acc: 61.72%, op_acc: 35.94%] [G loss: 0.870077]\n",
      "epoch:12 step:9796[D loss: 0.481367, acc: 51.56%, op_acc: 29.69%] [G loss: 0.838729]\n",
      "epoch:12 step:9797[D loss: 0.447473, acc: 51.56%, op_acc: 36.72%] [G loss: 0.830652]\n",
      "epoch:12 step:9798[D loss: 0.469025, acc: 50.00%, op_acc: 34.38%] [G loss: 0.903466]\n",
      "epoch:12 step:9799[D loss: 0.467537, acc: 58.59%, op_acc: 32.03%] [G loss: 0.864332]\n",
      "epoch:12 step:9800[D loss: 0.424844, acc: 55.47%, op_acc: 40.62%] [G loss: 0.860392]\n",
      "##############\n",
      "[0.84991625 0.86036115 0.80911023 0.81253664 0.78028676 0.83515089\n",
      " 0.87314285 0.84593472 0.80934556 0.82360076]\n",
      "##########\n",
      "epoch:12 step:9801[D loss: 0.439429, acc: 62.50%, op_acc: 33.59%] [G loss: 0.900213]\n",
      "epoch:12 step:9802[D loss: 0.423117, acc: 59.38%, op_acc: 38.28%] [G loss: 0.829972]\n",
      "epoch:12 step:9803[D loss: 0.460702, acc: 57.03%, op_acc: 33.59%] [G loss: 0.842035]\n",
      "epoch:12 step:9804[D loss: 0.427857, acc: 52.34%, op_acc: 38.28%] [G loss: 0.815831]\n",
      "epoch:12 step:9805[D loss: 0.458466, acc: 49.22%, op_acc: 37.50%] [G loss: 0.784111]\n",
      "epoch:12 step:9806[D loss: 0.447398, acc: 55.47%, op_acc: 40.62%] [G loss: 0.855828]\n",
      "epoch:12 step:9807[D loss: 0.437518, acc: 55.47%, op_acc: 39.84%] [G loss: 0.815917]\n",
      "epoch:12 step:9808[D loss: 0.476195, acc: 51.56%, op_acc: 34.38%] [G loss: 0.870893]\n",
      "epoch:12 step:9809[D loss: 0.435404, acc: 59.38%, op_acc: 36.72%] [G loss: 0.875875]\n",
      "epoch:12 step:9810[D loss: 0.427533, acc: 59.38%, op_acc: 35.16%] [G loss: 0.888352]\n",
      "epoch:12 step:9811[D loss: 0.435062, acc: 56.25%, op_acc: 36.72%] [G loss: 0.830328]\n",
      "epoch:12 step:9812[D loss: 0.453577, acc: 55.47%, op_acc: 35.16%] [G loss: 0.903076]\n",
      "epoch:12 step:9813[D loss: 0.444326, acc: 54.69%, op_acc: 39.84%] [G loss: 0.867571]\n",
      "epoch:12 step:9814[D loss: 0.448231, acc: 46.09%, op_acc: 38.28%] [G loss: 0.893170]\n",
      "epoch:12 step:9815[D loss: 0.432862, acc: 61.72%, op_acc: 37.50%] [G loss: 0.899037]\n",
      "epoch:12 step:9816[D loss: 0.449825, acc: 57.03%, op_acc: 39.06%] [G loss: 0.876249]\n",
      "epoch:12 step:9817[D loss: 0.447241, acc: 61.72%, op_acc: 28.91%] [G loss: 0.812351]\n",
      "epoch:12 step:9818[D loss: 0.448660, acc: 50.00%, op_acc: 36.72%] [G loss: 0.863781]\n",
      "epoch:12 step:9819[D loss: 0.451502, acc: 57.81%, op_acc: 35.94%] [G loss: 0.902594]\n",
      "epoch:12 step:9820[D loss: 0.437223, acc: 61.72%, op_acc: 42.19%] [G loss: 0.835564]\n",
      "epoch:12 step:9821[D loss: 0.434821, acc: 62.50%, op_acc: 34.38%] [G loss: 0.949715]\n",
      "epoch:12 step:9822[D loss: 0.436735, acc: 59.38%, op_acc: 33.59%] [G loss: 0.883822]\n",
      "epoch:12 step:9823[D loss: 0.412953, acc: 60.94%, op_acc: 42.97%] [G loss: 0.919009]\n",
      "epoch:12 step:9824[D loss: 0.425720, acc: 64.84%, op_acc: 34.38%] [G loss: 0.954832]\n",
      "epoch:12 step:9825[D loss: 0.412398, acc: 51.56%, op_acc: 42.19%] [G loss: 0.893187]\n",
      "epoch:12 step:9826[D loss: 0.436996, acc: 64.06%, op_acc: 31.25%] [G loss: 0.811132]\n",
      "epoch:12 step:9827[D loss: 0.460358, acc: 52.34%, op_acc: 37.50%] [G loss: 0.865612]\n",
      "epoch:12 step:9828[D loss: 0.426663, acc: 60.94%, op_acc: 38.28%] [G loss: 0.874332]\n",
      "epoch:12 step:9829[D loss: 0.415532, acc: 67.19%, op_acc: 39.84%] [G loss: 0.910153]\n",
      "epoch:12 step:9830[D loss: 0.410247, acc: 60.94%, op_acc: 39.06%] [G loss: 0.862464]\n",
      "epoch:12 step:9831[D loss: 0.423956, acc: 58.59%, op_acc: 42.19%] [G loss: 0.791365]\n",
      "epoch:12 step:9832[D loss: 0.414165, acc: 59.38%, op_acc: 40.62%] [G loss: 0.860693]\n",
      "epoch:12 step:9833[D loss: 0.475274, acc: 43.75%, op_acc: 28.91%] [G loss: 0.787003]\n",
      "epoch:12 step:9834[D loss: 0.426972, acc: 53.12%, op_acc: 35.16%] [G loss: 0.842124]\n",
      "epoch:12 step:9835[D loss: 0.424197, acc: 60.94%, op_acc: 35.94%] [G loss: 0.916657]\n",
      "epoch:12 step:9836[D loss: 0.436258, acc: 62.50%, op_acc: 33.59%] [G loss: 0.919571]\n",
      "epoch:12 step:9837[D loss: 0.419722, acc: 67.19%, op_acc: 37.50%] [G loss: 0.878948]\n",
      "epoch:12 step:9838[D loss: 0.401999, acc: 63.28%, op_acc: 40.62%] [G loss: 0.919549]\n",
      "epoch:12 step:9839[D loss: 0.440629, acc: 60.94%, op_acc: 35.94%] [G loss: 0.945260]\n",
      "epoch:12 step:9840[D loss: 0.441878, acc: 56.25%, op_acc: 39.06%] [G loss: 0.848017]\n",
      "epoch:12 step:9841[D loss: 0.408638, acc: 64.84%, op_acc: 43.75%] [G loss: 0.904212]\n",
      "epoch:12 step:9842[D loss: 0.426571, acc: 59.38%, op_acc: 36.72%] [G loss: 0.922959]\n",
      "epoch:12 step:9843[D loss: 0.431353, acc: 64.06%, op_acc: 38.28%] [G loss: 0.843735]\n",
      "epoch:12 step:9844[D loss: 0.428071, acc: 65.62%, op_acc: 34.38%] [G loss: 0.894175]\n",
      "epoch:12 step:9845[D loss: 0.449259, acc: 57.03%, op_acc: 39.06%] [G loss: 0.876081]\n",
      "epoch:12 step:9846[D loss: 0.472936, acc: 50.78%, op_acc: 32.03%] [G loss: 0.873444]\n",
      "epoch:12 step:9847[D loss: 0.428766, acc: 50.78%, op_acc: 39.84%] [G loss: 0.893287]\n",
      "epoch:12 step:9848[D loss: 0.435548, acc: 64.06%, op_acc: 33.59%] [G loss: 0.849438]\n",
      "epoch:12 step:9849[D loss: 0.439606, acc: 60.16%, op_acc: 41.41%] [G loss: 0.860330]\n",
      "epoch:12 step:9850[D loss: 0.416824, acc: 64.06%, op_acc: 39.84%] [G loss: 0.863229]\n",
      "##############\n",
      "[0.85962533 0.8423567  0.82117288 0.81503807 0.81812832 0.80586396\n",
      " 0.89505743 0.83361006 0.82971332 0.82884927]\n",
      "##########\n",
      "epoch:12 step:9851[D loss: 0.423097, acc: 63.28%, op_acc: 39.06%] [G loss: 0.899984]\n",
      "epoch:12 step:9852[D loss: 0.452979, acc: 62.50%, op_acc: 32.03%] [G loss: 0.950451]\n",
      "epoch:12 step:9853[D loss: 0.483341, acc: 52.34%, op_acc: 32.03%] [G loss: 0.874881]\n",
      "epoch:12 step:9854[D loss: 0.471200, acc: 54.69%, op_acc: 32.81%] [G loss: 0.858053]\n",
      "epoch:12 step:9855[D loss: 0.430935, acc: 63.28%, op_acc: 32.81%] [G loss: 0.819141]\n",
      "epoch:12 step:9856[D loss: 0.405539, acc: 63.28%, op_acc: 44.53%] [G loss: 0.820080]\n",
      "epoch:12 step:9857[D loss: 0.416987, acc: 63.28%, op_acc: 38.28%] [G loss: 0.827843]\n",
      "epoch:12 step:9858[D loss: 0.440138, acc: 55.47%, op_acc: 39.06%] [G loss: 0.820346]\n",
      "epoch:12 step:9859[D loss: 0.431335, acc: 62.50%, op_acc: 39.84%] [G loss: 0.887003]\n",
      "epoch:12 step:9860[D loss: 0.459376, acc: 48.44%, op_acc: 37.50%] [G loss: 0.882720]\n",
      "epoch:12 step:9861[D loss: 0.442179, acc: 51.56%, op_acc: 36.72%] [G loss: 0.824922]\n",
      "epoch:12 step:9862[D loss: 0.444456, acc: 56.25%, op_acc: 37.50%] [G loss: 0.829285]\n",
      "epoch:12 step:9863[D loss: 0.454471, acc: 60.16%, op_acc: 35.94%] [G loss: 0.823968]\n",
      "epoch:12 step:9864[D loss: 0.415406, acc: 58.59%, op_acc: 36.72%] [G loss: 0.872431]\n",
      "epoch:12 step:9865[D loss: 0.450445, acc: 58.59%, op_acc: 35.94%] [G loss: 0.817029]\n",
      "epoch:12 step:9866[D loss: 0.400067, acc: 67.19%, op_acc: 40.62%] [G loss: 0.946369]\n",
      "epoch:12 step:9867[D loss: 0.453548, acc: 61.72%, op_acc: 35.94%] [G loss: 0.887640]\n",
      "epoch:12 step:9868[D loss: 0.400637, acc: 61.72%, op_acc: 39.84%] [G loss: 0.948068]\n",
      "epoch:12 step:9869[D loss: 0.412303, acc: 65.62%, op_acc: 41.41%] [G loss: 0.846622]\n",
      "epoch:12 step:9870[D loss: 0.475171, acc: 51.56%, op_acc: 35.16%] [G loss: 0.824348]\n",
      "epoch:12 step:9871[D loss: 0.439722, acc: 61.72%, op_acc: 33.59%] [G loss: 0.803331]\n",
      "epoch:12 step:9872[D loss: 0.431831, acc: 57.81%, op_acc: 40.62%] [G loss: 0.831216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9873[D loss: 0.421138, acc: 65.62%, op_acc: 37.50%] [G loss: 0.911417]\n",
      "epoch:12 step:9874[D loss: 0.428910, acc: 59.38%, op_acc: 36.72%] [G loss: 0.953184]\n",
      "epoch:12 step:9875[D loss: 0.440196, acc: 61.72%, op_acc: 31.25%] [G loss: 0.839389]\n",
      "epoch:12 step:9876[D loss: 0.448707, acc: 60.94%, op_acc: 39.84%] [G loss: 0.922345]\n",
      "epoch:12 step:9877[D loss: 0.429290, acc: 65.62%, op_acc: 34.38%] [G loss: 0.858529]\n",
      "epoch:12 step:9878[D loss: 0.444825, acc: 53.91%, op_acc: 37.50%] [G loss: 0.847861]\n",
      "epoch:12 step:9879[D loss: 0.413683, acc: 53.12%, op_acc: 42.19%] [G loss: 0.869478]\n",
      "epoch:12 step:9880[D loss: 0.441413, acc: 59.38%, op_acc: 34.38%] [G loss: 0.927127]\n",
      "epoch:12 step:9881[D loss: 0.500801, acc: 50.78%, op_acc: 32.03%] [G loss: 0.852125]\n",
      "epoch:12 step:9882[D loss: 0.433670, acc: 62.50%, op_acc: 37.50%] [G loss: 0.846349]\n",
      "epoch:12 step:9883[D loss: 0.440605, acc: 55.47%, op_acc: 34.38%] [G loss: 0.957790]\n",
      "epoch:12 step:9884[D loss: 0.472764, acc: 45.31%, op_acc: 36.72%] [G loss: 0.820851]\n",
      "epoch:12 step:9885[D loss: 0.481736, acc: 50.78%, op_acc: 32.81%] [G loss: 0.786364]\n",
      "epoch:12 step:9886[D loss: 0.444834, acc: 59.38%, op_acc: 33.59%] [G loss: 0.849225]\n",
      "epoch:12 step:9887[D loss: 0.467865, acc: 55.47%, op_acc: 27.34%] [G loss: 0.852760]\n",
      "epoch:12 step:9888[D loss: 0.447205, acc: 57.03%, op_acc: 39.84%] [G loss: 0.811853]\n",
      "epoch:12 step:9889[D loss: 0.470340, acc: 46.88%, op_acc: 32.81%] [G loss: 0.904262]\n",
      "epoch:12 step:9890[D loss: 0.408859, acc: 62.50%, op_acc: 41.41%] [G loss: 0.894087]\n",
      "epoch:12 step:9891[D loss: 0.419730, acc: 65.62%, op_acc: 36.72%] [G loss: 0.923532]\n",
      "epoch:12 step:9892[D loss: 0.446200, acc: 55.47%, op_acc: 35.94%] [G loss: 0.824760]\n",
      "epoch:12 step:9893[D loss: 0.461917, acc: 58.59%, op_acc: 34.38%] [G loss: 0.918963]\n",
      "epoch:12 step:9894[D loss: 0.453997, acc: 59.38%, op_acc: 33.59%] [G loss: 0.878130]\n",
      "epoch:12 step:9895[D loss: 0.432252, acc: 66.41%, op_acc: 33.59%] [G loss: 0.938667]\n",
      "epoch:12 step:9896[D loss: 0.442369, acc: 66.41%, op_acc: 33.59%] [G loss: 0.875384]\n",
      "epoch:12 step:9897[D loss: 0.424035, acc: 65.62%, op_acc: 33.59%] [G loss: 0.883346]\n",
      "epoch:12 step:9898[D loss: 0.460595, acc: 64.84%, op_acc: 29.69%] [G loss: 0.922472]\n",
      "epoch:12 step:9899[D loss: 0.449305, acc: 52.34%, op_acc: 39.84%] [G loss: 0.801236]\n",
      "epoch:12 step:9900[D loss: 0.434285, acc: 57.03%, op_acc: 36.72%] [G loss: 0.904757]\n",
      "##############\n",
      "[0.86219849 0.86727642 0.82994327 0.80352702 0.80074433 0.81946564\n",
      " 0.89784161 0.82743107 0.82980636 0.83770489]\n",
      "##########\n",
      "epoch:12 step:9901[D loss: 0.439328, acc: 58.59%, op_acc: 34.38%] [G loss: 0.849504]\n",
      "epoch:12 step:9902[D loss: 0.430150, acc: 63.28%, op_acc: 31.25%] [G loss: 0.835291]\n",
      "epoch:12 step:9903[D loss: 0.440610, acc: 61.72%, op_acc: 33.59%] [G loss: 0.842735]\n",
      "epoch:12 step:9904[D loss: 0.442885, acc: 59.38%, op_acc: 32.81%] [G loss: 0.888986]\n",
      "epoch:12 step:9905[D loss: 0.421415, acc: 58.59%, op_acc: 38.28%] [G loss: 0.898316]\n",
      "epoch:12 step:9906[D loss: 0.441186, acc: 53.91%, op_acc: 36.72%] [G loss: 0.822925]\n",
      "epoch:12 step:9907[D loss: 0.464665, acc: 51.56%, op_acc: 35.94%] [G loss: 0.915051]\n",
      "epoch:12 step:9908[D loss: 0.406381, acc: 61.72%, op_acc: 38.28%] [G loss: 0.910826]\n",
      "epoch:12 step:9909[D loss: 0.467172, acc: 50.78%, op_acc: 37.50%] [G loss: 0.810755]\n",
      "epoch:12 step:9910[D loss: 0.436106, acc: 56.25%, op_acc: 35.94%] [G loss: 0.817451]\n",
      "epoch:12 step:9911[D loss: 0.435441, acc: 61.72%, op_acc: 35.94%] [G loss: 0.835490]\n",
      "epoch:12 step:9912[D loss: 0.410520, acc: 64.84%, op_acc: 38.28%] [G loss: 0.846719]\n",
      "epoch:12 step:9913[D loss: 0.410535, acc: 64.84%, op_acc: 39.06%] [G loss: 0.842843]\n",
      "epoch:12 step:9914[D loss: 0.426257, acc: 59.38%, op_acc: 39.06%] [G loss: 0.835860]\n",
      "epoch:12 step:9915[D loss: 0.434849, acc: 58.59%, op_acc: 39.06%] [G loss: 0.946550]\n",
      "epoch:12 step:9916[D loss: 0.435705, acc: 61.72%, op_acc: 39.84%] [G loss: 0.875605]\n",
      "epoch:12 step:9917[D loss: 0.420031, acc: 67.97%, op_acc: 34.38%] [G loss: 0.948575]\n",
      "epoch:12 step:9918[D loss: 0.427981, acc: 66.41%, op_acc: 39.84%] [G loss: 0.919661]\n",
      "epoch:12 step:9919[D loss: 0.458611, acc: 59.38%, op_acc: 35.94%] [G loss: 0.908448]\n",
      "epoch:12 step:9920[D loss: 0.437886, acc: 58.59%, op_acc: 37.50%] [G loss: 0.927930]\n",
      "epoch:12 step:9921[D loss: 0.443436, acc: 58.59%, op_acc: 39.06%] [G loss: 0.937067]\n",
      "epoch:12 step:9922[D loss: 0.437386, acc: 61.72%, op_acc: 39.06%] [G loss: 0.879919]\n",
      "epoch:12 step:9923[D loss: 0.435612, acc: 56.25%, op_acc: 37.50%] [G loss: 0.774781]\n",
      "epoch:12 step:9924[D loss: 0.455628, acc: 56.25%, op_acc: 28.12%] [G loss: 0.854137]\n",
      "epoch:12 step:9925[D loss: 0.413974, acc: 67.19%, op_acc: 35.94%] [G loss: 0.850949]\n",
      "epoch:12 step:9926[D loss: 0.423112, acc: 62.50%, op_acc: 35.16%] [G loss: 0.863278]\n",
      "epoch:12 step:9927[D loss: 0.435765, acc: 56.25%, op_acc: 39.06%] [G loss: 0.887142]\n",
      "epoch:12 step:9928[D loss: 0.431981, acc: 55.47%, op_acc: 38.28%] [G loss: 0.882978]\n",
      "epoch:12 step:9929[D loss: 0.442335, acc: 57.81%, op_acc: 34.38%] [G loss: 0.881499]\n",
      "epoch:12 step:9930[D loss: 0.401108, acc: 63.28%, op_acc: 45.31%] [G loss: 0.903428]\n",
      "epoch:12 step:9931[D loss: 0.437060, acc: 54.69%, op_acc: 38.28%] [G loss: 0.924211]\n",
      "epoch:12 step:9932[D loss: 0.463017, acc: 50.78%, op_acc: 33.59%] [G loss: 0.819959]\n",
      "epoch:12 step:9933[D loss: 0.418473, acc: 60.94%, op_acc: 38.28%] [G loss: 0.905456]\n",
      "epoch:12 step:9934[D loss: 0.449511, acc: 62.50%, op_acc: 33.59%] [G loss: 0.954706]\n",
      "epoch:12 step:9935[D loss: 0.426338, acc: 68.75%, op_acc: 35.94%] [G loss: 0.942510]\n",
      "epoch:12 step:9936[D loss: 0.409082, acc: 65.62%, op_acc: 40.62%] [G loss: 0.884735]\n",
      "epoch:12 step:9937[D loss: 0.440611, acc: 57.03%, op_acc: 34.38%] [G loss: 0.925198]\n",
      "epoch:12 step:9938[D loss: 0.424775, acc: 61.72%, op_acc: 34.38%] [G loss: 0.881492]\n",
      "epoch:12 step:9939[D loss: 0.434779, acc: 52.34%, op_acc: 42.19%] [G loss: 0.905889]\n",
      "epoch:12 step:9940[D loss: 0.427952, acc: 60.94%, op_acc: 37.50%] [G loss: 0.906361]\n",
      "epoch:12 step:9941[D loss: 0.443027, acc: 53.91%, op_acc: 37.50%] [G loss: 0.837815]\n",
      "epoch:12 step:9942[D loss: 0.404763, acc: 69.53%, op_acc: 35.16%] [G loss: 0.901396]\n",
      "epoch:12 step:9943[D loss: 0.435184, acc: 53.12%, op_acc: 44.53%] [G loss: 0.881394]\n",
      "epoch:12 step:9944[D loss: 0.413577, acc: 63.28%, op_acc: 36.72%] [G loss: 0.877551]\n",
      "epoch:12 step:9945[D loss: 0.428978, acc: 60.16%, op_acc: 35.94%] [G loss: 0.832484]\n",
      "epoch:12 step:9946[D loss: 0.447842, acc: 52.34%, op_acc: 40.62%] [G loss: 0.843558]\n",
      "epoch:12 step:9947[D loss: 0.450283, acc: 54.69%, op_acc: 34.38%] [G loss: 0.851119]\n",
      "epoch:12 step:9948[D loss: 0.438764, acc: 50.78%, op_acc: 36.72%] [G loss: 0.891259]\n",
      "epoch:12 step:9949[D loss: 0.458293, acc: 54.69%, op_acc: 33.59%] [G loss: 0.823098]\n",
      "epoch:12 step:9950[D loss: 0.440929, acc: 63.28%, op_acc: 34.38%] [G loss: 0.868518]\n",
      "##############\n",
      "[0.8464523  0.85267551 0.80861581 0.82278159 0.80533652 0.80744147\n",
      " 0.87348212 0.83463342 0.78874757 0.83245658]\n",
      "##########\n",
      "epoch:12 step:9951[D loss: 0.419527, acc: 56.25%, op_acc: 46.09%] [G loss: 0.942974]\n",
      "epoch:12 step:9952[D loss: 0.443977, acc: 59.38%, op_acc: 33.59%] [G loss: 0.871508]\n",
      "epoch:12 step:9953[D loss: 0.446475, acc: 53.91%, op_acc: 36.72%] [G loss: 0.844990]\n",
      "epoch:12 step:9954[D loss: 0.446361, acc: 58.59%, op_acc: 28.91%] [G loss: 0.897812]\n",
      "epoch:12 step:9955[D loss: 0.429521, acc: 64.06%, op_acc: 36.72%] [G loss: 0.887967]\n",
      "epoch:12 step:9956[D loss: 0.473151, acc: 54.69%, op_acc: 27.34%] [G loss: 0.899623]\n",
      "epoch:12 step:9957[D loss: 0.449766, acc: 56.25%, op_acc: 36.72%] [G loss: 0.853469]\n",
      "epoch:12 step:9958[D loss: 0.429642, acc: 64.84%, op_acc: 28.12%] [G loss: 0.873878]\n",
      "epoch:12 step:9959[D loss: 0.422830, acc: 62.50%, op_acc: 32.03%] [G loss: 0.859207]\n",
      "epoch:12 step:9960[D loss: 0.410565, acc: 63.28%, op_acc: 42.97%] [G loss: 0.917607]\n",
      "epoch:12 step:9961[D loss: 0.426693, acc: 64.84%, op_acc: 31.25%] [G loss: 0.981267]\n",
      "epoch:12 step:9962[D loss: 0.437413, acc: 53.91%, op_acc: 36.72%] [G loss: 0.836444]\n",
      "epoch:12 step:9963[D loss: 0.432326, acc: 57.81%, op_acc: 35.16%] [G loss: 0.916416]\n",
      "epoch:12 step:9964[D loss: 0.457416, acc: 47.66%, op_acc: 32.03%] [G loss: 0.906981]\n",
      "epoch:12 step:9965[D loss: 0.442003, acc: 61.72%, op_acc: 31.25%] [G loss: 0.912324]\n",
      "epoch:12 step:9966[D loss: 0.452004, acc: 53.91%, op_acc: 31.25%] [G loss: 0.874884]\n",
      "epoch:12 step:9967[D loss: 0.420791, acc: 67.97%, op_acc: 36.72%] [G loss: 0.853450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9968[D loss: 0.447620, acc: 57.81%, op_acc: 35.16%] [G loss: 0.910532]\n",
      "epoch:12 step:9969[D loss: 0.438936, acc: 65.62%, op_acc: 35.16%] [G loss: 0.895338]\n",
      "epoch:12 step:9970[D loss: 0.434064, acc: 57.03%, op_acc: 35.94%] [G loss: 0.896659]\n",
      "epoch:12 step:9971[D loss: 0.434829, acc: 61.72%, op_acc: 38.28%] [G loss: 0.817382]\n",
      "epoch:12 step:9972[D loss: 0.453739, acc: 54.69%, op_acc: 36.72%] [G loss: 0.858003]\n",
      "epoch:12 step:9973[D loss: 0.417177, acc: 65.62%, op_acc: 35.94%] [G loss: 0.898405]\n",
      "epoch:12 step:9974[D loss: 0.403980, acc: 64.06%, op_acc: 40.62%] [G loss: 0.853495]\n",
      "epoch:12 step:9975[D loss: 0.402219, acc: 64.06%, op_acc: 33.59%] [G loss: 0.867255]\n",
      "epoch:12 step:9976[D loss: 0.443509, acc: 60.94%, op_acc: 29.69%] [G loss: 0.892632]\n",
      "epoch:12 step:9977[D loss: 0.449423, acc: 59.38%, op_acc: 32.81%] [G loss: 0.767110]\n",
      "epoch:12 step:9978[D loss: 0.424169, acc: 60.94%, op_acc: 35.94%] [G loss: 0.853451]\n",
      "epoch:12 step:9979[D loss: 0.406394, acc: 64.06%, op_acc: 40.62%] [G loss: 0.865569]\n",
      "epoch:12 step:9980[D loss: 0.422989, acc: 50.00%, op_acc: 37.50%] [G loss: 0.842330]\n",
      "epoch:12 step:9981[D loss: 0.450658, acc: 55.47%, op_acc: 39.84%] [G loss: 0.892232]\n",
      "epoch:12 step:9982[D loss: 0.407609, acc: 69.53%, op_acc: 32.81%] [G loss: 0.937666]\n",
      "epoch:12 step:9983[D loss: 0.430435, acc: 57.81%, op_acc: 35.16%] [G loss: 0.832900]\n",
      "epoch:12 step:9984[D loss: 0.415194, acc: 64.84%, op_acc: 35.94%] [G loss: 0.861580]\n",
      "epoch:12 step:9985[D loss: 0.460648, acc: 49.22%, op_acc: 37.50%] [G loss: 0.852294]\n",
      "epoch:12 step:9986[D loss: 0.380992, acc: 70.31%, op_acc: 35.94%] [G loss: 0.887278]\n",
      "epoch:12 step:9987[D loss: 0.442395, acc: 61.72%, op_acc: 37.50%] [G loss: 0.850698]\n",
      "epoch:12 step:9988[D loss: 0.436928, acc: 58.59%, op_acc: 39.06%] [G loss: 0.805735]\n",
      "epoch:12 step:9989[D loss: 0.434468, acc: 57.81%, op_acc: 38.28%] [G loss: 0.892684]\n",
      "epoch:12 step:9990[D loss: 0.434439, acc: 59.38%, op_acc: 35.94%] [G loss: 0.849116]\n",
      "epoch:12 step:9991[D loss: 0.469513, acc: 59.38%, op_acc: 36.72%] [G loss: 0.866909]\n",
      "epoch:12 step:9992[D loss: 0.454970, acc: 57.03%, op_acc: 32.03%] [G loss: 0.855652]\n",
      "epoch:12 step:9993[D loss: 0.441707, acc: 56.25%, op_acc: 35.16%] [G loss: 0.845173]\n",
      "epoch:12 step:9994[D loss: 0.457619, acc: 60.16%, op_acc: 34.38%] [G loss: 0.859638]\n",
      "epoch:12 step:9995[D loss: 0.416428, acc: 64.84%, op_acc: 39.06%] [G loss: 0.988292]\n",
      "epoch:12 step:9996[D loss: 0.426831, acc: 61.72%, op_acc: 39.84%] [G loss: 0.897780]\n",
      "epoch:12 step:9997[D loss: 0.431133, acc: 58.59%, op_acc: 35.94%] [G loss: 0.920245]\n",
      "epoch:12 step:9998[D loss: 0.413424, acc: 62.50%, op_acc: 39.84%] [G loss: 0.879575]\n",
      "epoch:12 step:9999[D loss: 0.427724, acc: 54.69%, op_acc: 40.62%] [G loss: 0.893709]\n",
      "epoch:12 step:10000[D loss: 0.452503, acc: 54.69%, op_acc: 35.94%] [G loss: 0.894448]\n",
      "##############\n",
      "[0.85135412 0.86785575 0.81771987 0.79362141 0.77591416 0.8313514\n",
      " 0.89844976 0.81076667 0.81797156 0.8297551 ]\n",
      "##########\n",
      "epoch:12 step:10001[D loss: 0.445020, acc: 64.06%, op_acc: 31.25%] [G loss: 0.970934]\n",
      "epoch:12 step:10002[D loss: 0.428025, acc: 60.16%, op_acc: 34.38%] [G loss: 0.872152]\n",
      "epoch:12 step:10003[D loss: 0.450898, acc: 57.03%, op_acc: 36.72%] [G loss: 0.913368]\n",
      "epoch:12 step:10004[D loss: 0.437839, acc: 64.84%, op_acc: 29.69%] [G loss: 0.896899]\n",
      "epoch:12 step:10005[D loss: 0.446356, acc: 59.38%, op_acc: 33.59%] [G loss: 0.819187]\n",
      "epoch:12 step:10006[D loss: 0.442041, acc: 57.03%, op_acc: 37.50%] [G loss: 0.877512]\n",
      "epoch:12 step:10007[D loss: 0.440317, acc: 58.59%, op_acc: 34.38%] [G loss: 0.925716]\n",
      "epoch:12 step:10008[D loss: 0.420726, acc: 57.81%, op_acc: 40.62%] [G loss: 0.852807]\n",
      "epoch:12 step:10009[D loss: 0.420789, acc: 62.50%, op_acc: 31.25%] [G loss: 0.854879]\n",
      "epoch:12 step:10010[D loss: 0.454755, acc: 53.12%, op_acc: 32.03%] [G loss: 0.816463]\n",
      "epoch:12 step:10011[D loss: 0.449544, acc: 53.91%, op_acc: 38.28%] [G loss: 0.820359]\n",
      "epoch:12 step:10012[D loss: 0.451850, acc: 52.34%, op_acc: 34.38%] [G loss: 0.882290]\n",
      "epoch:12 step:10013[D loss: 0.444674, acc: 56.25%, op_acc: 33.59%] [G loss: 0.913990]\n",
      "epoch:12 step:10014[D loss: 0.427731, acc: 60.94%, op_acc: 32.81%] [G loss: 0.854504]\n",
      "epoch:12 step:10015[D loss: 0.489791, acc: 45.31%, op_acc: 26.56%] [G loss: 0.887142]\n",
      "epoch:12 step:10016[D loss: 0.408581, acc: 64.06%, op_acc: 42.19%] [G loss: 0.884491]\n",
      "epoch:12 step:10017[D loss: 0.432559, acc: 56.25%, op_acc: 39.84%] [G loss: 0.788484]\n",
      "epoch:12 step:10018[D loss: 0.457775, acc: 56.25%, op_acc: 38.28%] [G loss: 0.871978]\n",
      "epoch:12 step:10019[D loss: 0.432218, acc: 54.69%, op_acc: 39.06%] [G loss: 0.889236]\n",
      "epoch:12 step:10020[D loss: 0.439749, acc: 56.25%, op_acc: 32.81%] [G loss: 0.923849]\n",
      "epoch:12 step:10021[D loss: 0.432886, acc: 56.25%, op_acc: 35.94%] [G loss: 0.850873]\n",
      "epoch:12 step:10022[D loss: 0.466298, acc: 55.47%, op_acc: 34.38%] [G loss: 0.845038]\n",
      "epoch:12 step:10023[D loss: 0.409450, acc: 66.41%, op_acc: 35.16%] [G loss: 0.844333]\n",
      "epoch:12 step:10024[D loss: 0.422819, acc: 57.03%, op_acc: 41.41%] [G loss: 0.900567]\n",
      "epoch:12 step:10025[D loss: 0.414984, acc: 61.72%, op_acc: 39.84%] [G loss: 0.920284]\n",
      "epoch:12 step:10026[D loss: 0.432219, acc: 60.94%, op_acc: 32.03%] [G loss: 0.803635]\n",
      "epoch:12 step:10027[D loss: 0.407306, acc: 64.06%, op_acc: 36.72%] [G loss: 0.877892]\n",
      "epoch:12 step:10028[D loss: 0.434372, acc: 63.28%, op_acc: 38.28%] [G loss: 0.864698]\n",
      "epoch:12 step:10029[D loss: 0.466030, acc: 50.78%, op_acc: 37.50%] [G loss: 0.853133]\n",
      "epoch:12 step:10030[D loss: 0.413743, acc: 70.31%, op_acc: 33.59%] [G loss: 0.881519]\n",
      "epoch:12 step:10031[D loss: 0.434805, acc: 62.50%, op_acc: 33.59%] [G loss: 0.915856]\n",
      "epoch:12 step:10032[D loss: 0.411163, acc: 60.16%, op_acc: 36.72%] [G loss: 0.885630]\n",
      "epoch:12 step:10033[D loss: 0.417999, acc: 61.72%, op_acc: 42.19%] [G loss: 0.900826]\n",
      "epoch:12 step:10034[D loss: 0.401709, acc: 62.50%, op_acc: 41.41%] [G loss: 0.809173]\n",
      "epoch:12 step:10035[D loss: 0.425288, acc: 64.06%, op_acc: 35.16%] [G loss: 0.875707]\n",
      "epoch:12 step:10036[D loss: 0.444895, acc: 50.00%, op_acc: 35.16%] [G loss: 0.901280]\n",
      "epoch:12 step:10037[D loss: 0.466738, acc: 50.78%, op_acc: 30.47%] [G loss: 0.860067]\n",
      "epoch:12 step:10038[D loss: 0.434960, acc: 64.84%, op_acc: 35.16%] [G loss: 0.918679]\n",
      "epoch:12 step:10039[D loss: 0.432037, acc: 60.16%, op_acc: 35.16%] [G loss: 0.868394]\n",
      "epoch:12 step:10040[D loss: 0.461955, acc: 52.34%, op_acc: 37.50%] [G loss: 0.863200]\n",
      "epoch:12 step:10041[D loss: 0.457929, acc: 54.69%, op_acc: 35.94%] [G loss: 0.838562]\n",
      "epoch:12 step:10042[D loss: 0.422979, acc: 63.28%, op_acc: 36.72%] [G loss: 0.912113]\n",
      "epoch:12 step:10043[D loss: 0.470644, acc: 53.91%, op_acc: 32.81%] [G loss: 0.838019]\n",
      "epoch:12 step:10044[D loss: 0.446651, acc: 53.91%, op_acc: 38.28%] [G loss: 0.891852]\n",
      "epoch:12 step:10045[D loss: 0.453253, acc: 60.94%, op_acc: 32.03%] [G loss: 0.952207]\n",
      "epoch:12 step:10046[D loss: 0.434760, acc: 56.25%, op_acc: 35.94%] [G loss: 0.959177]\n",
      "epoch:12 step:10047[D loss: 0.442021, acc: 53.12%, op_acc: 40.62%] [G loss: 0.796762]\n",
      "epoch:12 step:10048[D loss: 0.456745, acc: 60.16%, op_acc: 28.91%] [G loss: 0.855700]\n",
      "epoch:12 step:10049[D loss: 0.449561, acc: 56.25%, op_acc: 32.81%] [G loss: 0.843944]\n",
      "epoch:12 step:10050[D loss: 0.443540, acc: 56.25%, op_acc: 32.03%] [G loss: 0.825863]\n",
      "##############\n",
      "[0.86428425 0.84280639 0.8109272  0.80849506 0.78543266 0.81620397\n",
      " 0.89072949 0.8086527  0.79423128 0.82853755]\n",
      "##########\n",
      "epoch:12 step:10051[D loss: 0.435108, acc: 53.91%, op_acc: 39.06%] [G loss: 0.908950]\n",
      "epoch:12 step:10052[D loss: 0.441491, acc: 58.59%, op_acc: 39.06%] [G loss: 0.883321]\n",
      "epoch:12 step:10053[D loss: 0.440854, acc: 62.50%, op_acc: 34.38%] [G loss: 0.970837]\n",
      "epoch:12 step:10054[D loss: 0.418986, acc: 64.84%, op_acc: 39.84%] [G loss: 0.882614]\n",
      "epoch:12 step:10055[D loss: 0.428578, acc: 58.59%, op_acc: 39.06%] [G loss: 0.927422]\n",
      "epoch:12 step:10056[D loss: 0.459258, acc: 53.91%, op_acc: 35.94%] [G loss: 0.897741]\n",
      "epoch:12 step:10057[D loss: 0.463924, acc: 56.25%, op_acc: 29.69%] [G loss: 0.843786]\n",
      "epoch:12 step:10058[D loss: 0.418263, acc: 63.28%, op_acc: 38.28%] [G loss: 0.892906]\n",
      "epoch:12 step:10059[D loss: 0.427523, acc: 60.16%, op_acc: 39.84%] [G loss: 0.849932]\n",
      "epoch:12 step:10060[D loss: 0.429546, acc: 57.03%, op_acc: 39.84%] [G loss: 0.916605]\n",
      "epoch:12 step:10061[D loss: 0.429668, acc: 53.91%, op_acc: 39.84%] [G loss: 0.812489]\n",
      "epoch:12 step:10062[D loss: 0.461461, acc: 55.47%, op_acc: 39.06%] [G loss: 0.892494]\n",
      "epoch:12 step:10063[D loss: 0.425087, acc: 61.72%, op_acc: 37.50%] [G loss: 0.918653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:10064[D loss: 0.449851, acc: 56.25%, op_acc: 37.50%] [G loss: 0.875825]\n",
      "epoch:12 step:10065[D loss: 0.469869, acc: 50.78%, op_acc: 34.38%] [G loss: 0.813079]\n",
      "epoch:12 step:10066[D loss: 0.444007, acc: 58.59%, op_acc: 38.28%] [G loss: 0.886028]\n",
      "epoch:12 step:10067[D loss: 0.402974, acc: 60.94%, op_acc: 40.62%] [G loss: 0.940945]\n",
      "epoch:12 step:10068[D loss: 0.452614, acc: 52.34%, op_acc: 33.59%] [G loss: 0.840965]\n",
      "epoch:12 step:10069[D loss: 0.417431, acc: 57.81%, op_acc: 42.19%] [G loss: 0.886119]\n",
      "epoch:12 step:10070[D loss: 0.428849, acc: 61.72%, op_acc: 36.72%] [G loss: 0.859061]\n",
      "epoch:12 step:10071[D loss: 0.409890, acc: 59.38%, op_acc: 41.41%] [G loss: 0.891526]\n",
      "epoch:12 step:10072[D loss: 0.454988, acc: 51.56%, op_acc: 32.03%] [G loss: 0.839711]\n",
      "epoch:12 step:10073[D loss: 0.443225, acc: 57.03%, op_acc: 32.81%] [G loss: 0.845922]\n",
      "epoch:12 step:10074[D loss: 0.443632, acc: 55.47%, op_acc: 32.81%] [G loss: 0.828257]\n",
      "epoch:12 step:10075[D loss: 0.443001, acc: 55.47%, op_acc: 35.94%] [G loss: 0.827730]\n",
      "epoch:12 step:10076[D loss: 0.426139, acc: 58.59%, op_acc: 38.28%] [G loss: 0.924116]\n",
      "epoch:12 step:10077[D loss: 0.426685, acc: 66.41%, op_acc: 36.72%] [G loss: 0.847123]\n",
      "epoch:12 step:10078[D loss: 0.430652, acc: 57.03%, op_acc: 42.19%] [G loss: 0.860441]\n",
      "epoch:12 step:10079[D loss: 0.455802, acc: 54.69%, op_acc: 34.38%] [G loss: 0.822302]\n",
      "epoch:12 step:10080[D loss: 0.438370, acc: 64.84%, op_acc: 33.59%] [G loss: 0.840925]\n",
      "epoch:12 step:10081[D loss: 0.443801, acc: 60.94%, op_acc: 38.28%] [G loss: 0.822644]\n",
      "epoch:12 step:10082[D loss: 0.421779, acc: 54.69%, op_acc: 43.75%] [G loss: 0.809721]\n",
      "epoch:12 step:10083[D loss: 0.419161, acc: 62.50%, op_acc: 34.38%] [G loss: 0.872610]\n",
      "epoch:12 step:10084[D loss: 0.392851, acc: 67.97%, op_acc: 39.84%] [G loss: 0.947143]\n",
      "epoch:12 step:10085[D loss: 0.446761, acc: 53.12%, op_acc: 36.72%] [G loss: 0.899377]\n",
      "epoch:12 step:10086[D loss: 0.422625, acc: 61.72%, op_acc: 34.38%] [G loss: 0.922394]\n",
      "epoch:12 step:10087[D loss: 0.405648, acc: 60.16%, op_acc: 39.06%] [G loss: 0.919295]\n",
      "epoch:12 step:10088[D loss: 0.430024, acc: 57.81%, op_acc: 40.62%] [G loss: 0.833310]\n",
      "epoch:12 step:10089[D loss: 0.435152, acc: 53.91%, op_acc: 41.41%] [G loss: 0.865900]\n",
      "epoch:12 step:10090[D loss: 0.427775, acc: 66.41%, op_acc: 37.50%] [G loss: 0.841286]\n",
      "epoch:12 step:10091[D loss: 0.437500, acc: 57.03%, op_acc: 33.59%] [G loss: 0.892779]\n",
      "epoch:12 step:10092[D loss: 0.459739, acc: 54.69%, op_acc: 36.72%] [G loss: 0.904650]\n",
      "epoch:12 step:10093[D loss: 0.438459, acc: 56.25%, op_acc: 39.84%] [G loss: 0.846025]\n",
      "epoch:12 step:10094[D loss: 0.441012, acc: 55.47%, op_acc: 37.50%] [G loss: 0.773472]\n",
      "epoch:12 step:10095[D loss: 0.427340, acc: 64.06%, op_acc: 36.72%] [G loss: 0.832746]\n",
      "epoch:12 step:10096[D loss: 0.474153, acc: 57.03%, op_acc: 32.81%] [G loss: 0.867243]\n",
      "epoch:12 step:10097[D loss: 0.432259, acc: 56.25%, op_acc: 38.28%] [G loss: 0.911047]\n",
      "epoch:12 step:10098[D loss: 0.425878, acc: 61.72%, op_acc: 32.81%] [G loss: 0.805453]\n",
      "epoch:12 step:10099[D loss: 0.461528, acc: 56.25%, op_acc: 28.12%] [G loss: 0.822592]\n",
      "epoch:12 step:10100[D loss: 0.442752, acc: 59.38%, op_acc: 32.03%] [G loss: 0.838823]\n",
      "##############\n",
      "[0.84590183 0.86590847 0.81945873 0.798948   0.78202303 0.82063893\n",
      " 0.89614166 0.81947631 0.81231652 0.83626376]\n",
      "##########\n",
      "epoch:12 step:10101[D loss: 0.419479, acc: 64.06%, op_acc: 40.62%] [G loss: 0.854442]\n",
      "epoch:12 step:10102[D loss: 0.475899, acc: 49.22%, op_acc: 34.38%] [G loss: 0.812881]\n",
      "epoch:12 step:10103[D loss: 0.418973, acc: 64.06%, op_acc: 33.59%] [G loss: 0.769922]\n",
      "epoch:12 step:10104[D loss: 0.448389, acc: 53.91%, op_acc: 36.72%] [G loss: 0.806581]\n",
      "epoch:12 step:10105[D loss: 0.431285, acc: 60.94%, op_acc: 34.38%] [G loss: 0.886266]\n",
      "epoch:12 step:10106[D loss: 0.463559, acc: 49.22%, op_acc: 35.16%] [G loss: 0.783531]\n",
      "epoch:12 step:10107[D loss: 0.447255, acc: 61.72%, op_acc: 35.94%] [G loss: 0.944165]\n",
      "epoch:12 step:10108[D loss: 0.432065, acc: 61.72%, op_acc: 32.81%] [G loss: 0.834948]\n",
      "epoch:12 step:10109[D loss: 0.422759, acc: 55.47%, op_acc: 38.28%] [G loss: 0.875428]\n",
      "epoch:12 step:10110[D loss: 0.439239, acc: 59.38%, op_acc: 39.84%] [G loss: 0.854458]\n",
      "epoch:12 step:10111[D loss: 0.413095, acc: 57.81%, op_acc: 35.94%] [G loss: 0.883805]\n",
      "epoch:12 step:10112[D loss: 0.420098, acc: 60.16%, op_acc: 38.28%] [G loss: 0.915943]\n",
      "epoch:12 step:10113[D loss: 0.448728, acc: 60.94%, op_acc: 34.38%] [G loss: 0.874347]\n",
      "epoch:12 step:10114[D loss: 0.421585, acc: 61.72%, op_acc: 40.62%] [G loss: 0.923744]\n",
      "epoch:12 step:10115[D loss: 0.441062, acc: 58.59%, op_acc: 40.62%] [G loss: 0.779597]\n",
      "epoch:12 step:10116[D loss: 0.400545, acc: 64.06%, op_acc: 42.19%] [G loss: 0.877553]\n",
      "epoch:12 step:10117[D loss: 0.428420, acc: 51.56%, op_acc: 39.84%] [G loss: 0.897105]\n",
      "epoch:12 step:10118[D loss: 0.443110, acc: 55.47%, op_acc: 38.28%] [G loss: 0.809729]\n",
      "epoch:12 step:10119[D loss: 0.441106, acc: 53.91%, op_acc: 38.28%] [G loss: 0.937907]\n",
      "epoch:12 step:10120[D loss: 0.427350, acc: 64.84%, op_acc: 40.62%] [G loss: 0.915650]\n",
      "epoch:12 step:10121[D loss: 0.461916, acc: 59.38%, op_acc: 39.84%] [G loss: 0.872662]\n",
      "epoch:12 step:10122[D loss: 0.433939, acc: 57.81%, op_acc: 39.06%] [G loss: 0.892322]\n",
      "epoch:12 step:10123[D loss: 0.458427, acc: 54.69%, op_acc: 35.16%] [G loss: 0.954191]\n",
      "epoch:12 step:10124[D loss: 0.441592, acc: 60.94%, op_acc: 31.25%] [G loss: 0.876142]\n",
      "epoch:12 step:10125[D loss: 0.453924, acc: 51.56%, op_acc: 37.50%] [G loss: 0.800913]\n",
      "epoch:12 step:10126[D loss: 0.438118, acc: 57.03%, op_acc: 34.38%] [G loss: 0.911171]\n",
      "epoch:12 step:10127[D loss: 0.431084, acc: 57.81%, op_acc: 39.06%] [G loss: 0.832686]\n",
      "epoch:12 step:10128[D loss: 0.422923, acc: 55.47%, op_acc: 41.41%] [G loss: 0.821995]\n",
      "epoch:12 step:10129[D loss: 0.448911, acc: 57.81%, op_acc: 28.91%] [G loss: 0.881240]\n",
      "epoch:12 step:10130[D loss: 0.447358, acc: 54.69%, op_acc: 42.97%] [G loss: 0.878978]\n",
      "epoch:12 step:10131[D loss: 0.434653, acc: 61.72%, op_acc: 36.72%] [G loss: 0.857443]\n",
      "epoch:12 step:10132[D loss: 0.434876, acc: 53.12%, op_acc: 39.06%] [G loss: 0.807221]\n",
      "epoch:12 step:10133[D loss: 0.386458, acc: 67.97%, op_acc: 41.41%] [G loss: 0.886571]\n",
      "epoch:12 step:10134[D loss: 0.458513, acc: 50.78%, op_acc: 33.59%] [G loss: 0.836022]\n",
      "epoch:12 step:10135[D loss: 0.436626, acc: 60.16%, op_acc: 35.94%] [G loss: 0.855395]\n",
      "epoch:12 step:10136[D loss: 0.440309, acc: 53.12%, op_acc: 42.19%] [G loss: 0.856244]\n",
      "epoch:12 step:10137[D loss: 0.413561, acc: 60.94%, op_acc: 34.38%] [G loss: 0.863587]\n",
      "epoch:12 step:10138[D loss: 0.462853, acc: 46.88%, op_acc: 33.59%] [G loss: 0.777738]\n",
      "epoch:12 step:10139[D loss: 0.417520, acc: 62.50%, op_acc: 36.72%] [G loss: 0.853974]\n",
      "epoch:12 step:10140[D loss: 0.456888, acc: 53.91%, op_acc: 32.03%] [G loss: 0.837084]\n",
      "epoch:12 step:10141[D loss: 0.403654, acc: 63.28%, op_acc: 39.06%] [G loss: 0.926431]\n",
      "epoch:12 step:10142[D loss: 0.433810, acc: 57.03%, op_acc: 38.28%] [G loss: 0.891110]\n",
      "epoch:12 step:10143[D loss: 0.459221, acc: 58.59%, op_acc: 32.03%] [G loss: 0.880495]\n",
      "epoch:12 step:10144[D loss: 0.461354, acc: 53.12%, op_acc: 33.59%] [G loss: 0.846105]\n",
      "epoch:12 step:10145[D loss: 0.433481, acc: 63.28%, op_acc: 32.81%] [G loss: 0.835440]\n",
      "epoch:12 step:10146[D loss: 0.380092, acc: 66.41%, op_acc: 42.97%] [G loss: 0.875405]\n",
      "epoch:12 step:10147[D loss: 0.420443, acc: 61.72%, op_acc: 33.59%] [G loss: 0.852469]\n",
      "epoch:12 step:10148[D loss: 0.390557, acc: 69.53%, op_acc: 37.50%] [G loss: 0.898088]\n",
      "epoch:12 step:10149[D loss: 0.466329, acc: 58.59%, op_acc: 32.03%] [G loss: 0.943063]\n",
      "epoch:12 step:10150[D loss: 0.451587, acc: 50.78%, op_acc: 40.62%] [G loss: 0.834277]\n",
      "##############\n",
      "[0.86291321 0.86060432 0.82558043 0.81705847 0.77457804 0.83440125\n",
      " 0.87387531 0.83692138 0.82633423 0.85487552]\n",
      "##########\n",
      "epoch:12 step:10151[D loss: 0.451269, acc: 52.34%, op_acc: 38.28%] [G loss: 0.780841]\n",
      "epoch:12 step:10152[D loss: 0.433414, acc: 57.03%, op_acc: 38.28%] [G loss: 0.874387]\n",
      "epoch:12 step:10153[D loss: 0.434504, acc: 59.38%, op_acc: 34.38%] [G loss: 0.911000]\n",
      "epoch:13 step:10154[D loss: 0.414919, acc: 64.84%, op_acc: 39.84%] [G loss: 0.818896]\n",
      "epoch:13 step:10155[D loss: 0.408851, acc: 63.28%, op_acc: 43.75%] [G loss: 0.969837]\n",
      "epoch:13 step:10156[D loss: 0.432351, acc: 58.59%, op_acc: 36.72%] [G loss: 0.813837]\n",
      "epoch:13 step:10157[D loss: 0.437452, acc: 55.47%, op_acc: 37.50%] [G loss: 0.855837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10158[D loss: 0.413953, acc: 66.41%, op_acc: 35.94%] [G loss: 0.872319]\n",
      "epoch:13 step:10159[D loss: 0.427638, acc: 63.28%, op_acc: 38.28%] [G loss: 0.827002]\n",
      "epoch:13 step:10160[D loss: 0.423591, acc: 60.16%, op_acc: 41.41%] [G loss: 0.842219]\n",
      "epoch:13 step:10161[D loss: 0.428364, acc: 57.81%, op_acc: 35.94%] [G loss: 0.929112]\n",
      "epoch:13 step:10162[D loss: 0.402533, acc: 58.59%, op_acc: 46.09%] [G loss: 0.899830]\n",
      "epoch:13 step:10163[D loss: 0.445853, acc: 62.50%, op_acc: 33.59%] [G loss: 0.867728]\n",
      "epoch:13 step:10164[D loss: 0.451639, acc: 52.34%, op_acc: 41.41%] [G loss: 0.844867]\n",
      "epoch:13 step:10165[D loss: 0.430863, acc: 58.59%, op_acc: 32.81%] [G loss: 0.839876]\n",
      "epoch:13 step:10166[D loss: 0.451166, acc: 59.38%, op_acc: 32.81%] [G loss: 0.866392]\n",
      "epoch:13 step:10167[D loss: 0.421232, acc: 63.28%, op_acc: 31.25%] [G loss: 0.915823]\n",
      "epoch:13 step:10168[D loss: 0.460849, acc: 52.34%, op_acc: 34.38%] [G loss: 0.873345]\n",
      "epoch:13 step:10169[D loss: 0.449657, acc: 50.00%, op_acc: 35.94%] [G loss: 0.811043]\n",
      "epoch:13 step:10170[D loss: 0.462811, acc: 45.31%, op_acc: 32.81%] [G loss: 0.843691]\n",
      "epoch:13 step:10171[D loss: 0.427574, acc: 57.81%, op_acc: 32.03%] [G loss: 0.810672]\n",
      "epoch:13 step:10172[D loss: 0.411850, acc: 67.97%, op_acc: 41.41%] [G loss: 0.911211]\n",
      "epoch:13 step:10173[D loss: 0.421600, acc: 61.72%, op_acc: 39.84%] [G loss: 0.886937]\n",
      "epoch:13 step:10174[D loss: 0.448773, acc: 60.16%, op_acc: 33.59%] [G loss: 0.865735]\n",
      "epoch:13 step:10175[D loss: 0.461549, acc: 51.56%, op_acc: 31.25%] [G loss: 0.847597]\n",
      "epoch:13 step:10176[D loss: 0.445881, acc: 52.34%, op_acc: 35.16%] [G loss: 0.834817]\n",
      "epoch:13 step:10177[D loss: 0.445776, acc: 60.16%, op_acc: 35.94%] [G loss: 0.874800]\n",
      "epoch:13 step:10178[D loss: 0.452436, acc: 56.25%, op_acc: 35.94%] [G loss: 0.857784]\n",
      "epoch:13 step:10179[D loss: 0.446353, acc: 52.34%, op_acc: 35.94%] [G loss: 0.852813]\n",
      "epoch:13 step:10180[D loss: 0.405230, acc: 71.09%, op_acc: 42.97%] [G loss: 0.908573]\n",
      "epoch:13 step:10181[D loss: 0.427716, acc: 58.59%, op_acc: 39.84%] [G loss: 0.846809]\n",
      "epoch:13 step:10182[D loss: 0.405131, acc: 67.19%, op_acc: 43.75%] [G loss: 0.931202]\n",
      "epoch:13 step:10183[D loss: 0.410309, acc: 61.72%, op_acc: 39.06%] [G loss: 0.937134]\n",
      "epoch:13 step:10184[D loss: 0.449013, acc: 61.72%, op_acc: 33.59%] [G loss: 0.862291]\n",
      "epoch:13 step:10185[D loss: 0.449209, acc: 54.69%, op_acc: 35.94%] [G loss: 0.894599]\n",
      "epoch:13 step:10186[D loss: 0.408693, acc: 64.84%, op_acc: 39.06%] [G loss: 0.913945]\n",
      "epoch:13 step:10187[D loss: 0.414284, acc: 60.16%, op_acc: 42.19%] [G loss: 0.882401]\n",
      "epoch:13 step:10188[D loss: 0.433792, acc: 60.94%, op_acc: 31.25%] [G loss: 0.807531]\n",
      "epoch:13 step:10189[D loss: 0.425511, acc: 58.59%, op_acc: 38.28%] [G loss: 0.910368]\n",
      "epoch:13 step:10190[D loss: 0.416749, acc: 64.84%, op_acc: 35.16%] [G loss: 0.938499]\n",
      "epoch:13 step:10191[D loss: 0.441757, acc: 56.25%, op_acc: 37.50%] [G loss: 0.861966]\n",
      "epoch:13 step:10192[D loss: 0.441754, acc: 53.91%, op_acc: 36.72%] [G loss: 0.885842]\n",
      "epoch:13 step:10193[D loss: 0.465327, acc: 48.44%, op_acc: 32.81%] [G loss: 0.863467]\n",
      "epoch:13 step:10194[D loss: 0.457636, acc: 48.44%, op_acc: 39.06%] [G loss: 0.869874]\n",
      "epoch:13 step:10195[D loss: 0.412298, acc: 60.16%, op_acc: 39.06%] [G loss: 0.939466]\n",
      "epoch:13 step:10196[D loss: 0.445577, acc: 56.25%, op_acc: 35.16%] [G loss: 0.916069]\n",
      "epoch:13 step:10197[D loss: 0.431785, acc: 65.62%, op_acc: 36.72%] [G loss: 0.880329]\n",
      "epoch:13 step:10198[D loss: 0.428404, acc: 63.28%, op_acc: 35.16%] [G loss: 0.862635]\n",
      "epoch:13 step:10199[D loss: 0.413411, acc: 67.19%, op_acc: 39.06%] [G loss: 0.896107]\n",
      "epoch:13 step:10200[D loss: 0.453608, acc: 60.16%, op_acc: 32.03%] [G loss: 0.824122]\n",
      "##############\n",
      "[0.86666588 0.86514105 0.82551354 0.81888564 0.78608765 0.8311339\n",
      " 0.87843533 0.81555847 0.82307835 0.84455639]\n",
      "##########\n",
      "epoch:13 step:10201[D loss: 0.473474, acc: 53.91%, op_acc: 34.38%] [G loss: 0.896206]\n",
      "epoch:13 step:10202[D loss: 0.449414, acc: 50.78%, op_acc: 35.16%] [G loss: 0.779120]\n",
      "epoch:13 step:10203[D loss: 0.436094, acc: 61.72%, op_acc: 33.59%] [G loss: 0.887222]\n",
      "epoch:13 step:10204[D loss: 0.447890, acc: 57.81%, op_acc: 28.91%] [G loss: 0.843529]\n",
      "epoch:13 step:10205[D loss: 0.439800, acc: 55.47%, op_acc: 36.72%] [G loss: 0.882718]\n",
      "epoch:13 step:10206[D loss: 0.452628, acc: 63.28%, op_acc: 34.38%] [G loss: 0.844509]\n",
      "epoch:13 step:10207[D loss: 0.489624, acc: 53.12%, op_acc: 35.94%] [G loss: 0.795284]\n",
      "epoch:13 step:10208[D loss: 0.433238, acc: 56.25%, op_acc: 38.28%] [G loss: 0.806699]\n",
      "epoch:13 step:10209[D loss: 0.453725, acc: 54.69%, op_acc: 29.69%] [G loss: 0.826195]\n",
      "epoch:13 step:10210[D loss: 0.447644, acc: 58.59%, op_acc: 31.25%] [G loss: 0.908745]\n",
      "epoch:13 step:10211[D loss: 0.413161, acc: 60.94%, op_acc: 41.41%] [G loss: 0.903835]\n",
      "epoch:13 step:10212[D loss: 0.401612, acc: 62.50%, op_acc: 41.41%] [G loss: 0.892924]\n",
      "epoch:13 step:10213[D loss: 0.448333, acc: 55.47%, op_acc: 35.94%] [G loss: 0.903419]\n",
      "epoch:13 step:10214[D loss: 0.463156, acc: 51.56%, op_acc: 35.94%] [G loss: 0.906375]\n",
      "epoch:13 step:10215[D loss: 0.444307, acc: 56.25%, op_acc: 34.38%] [G loss: 0.842618]\n",
      "epoch:13 step:10216[D loss: 0.448225, acc: 58.59%, op_acc: 33.59%] [G loss: 0.833501]\n",
      "epoch:13 step:10217[D loss: 0.437093, acc: 55.47%, op_acc: 32.81%] [G loss: 0.903012]\n",
      "epoch:13 step:10218[D loss: 0.467217, acc: 54.69%, op_acc: 36.72%] [G loss: 0.824012]\n",
      "epoch:13 step:10219[D loss: 0.430992, acc: 61.72%, op_acc: 34.38%] [G loss: 0.794547]\n",
      "epoch:13 step:10220[D loss: 0.421390, acc: 63.28%, op_acc: 36.72%] [G loss: 0.873653]\n",
      "epoch:13 step:10221[D loss: 0.451472, acc: 55.47%, op_acc: 34.38%] [G loss: 0.829834]\n",
      "epoch:13 step:10222[D loss: 0.420339, acc: 55.47%, op_acc: 42.19%] [G loss: 0.855563]\n",
      "epoch:13 step:10223[D loss: 0.433947, acc: 60.94%, op_acc: 35.94%] [G loss: 0.896130]\n",
      "epoch:13 step:10224[D loss: 0.488556, acc: 57.81%, op_acc: 29.69%] [G loss: 0.848024]\n",
      "epoch:13 step:10225[D loss: 0.425636, acc: 56.25%, op_acc: 41.41%] [G loss: 0.873020]\n",
      "epoch:13 step:10226[D loss: 0.427537, acc: 55.47%, op_acc: 42.97%] [G loss: 0.853696]\n",
      "epoch:13 step:10227[D loss: 0.416881, acc: 61.72%, op_acc: 39.84%] [G loss: 0.885577]\n",
      "epoch:13 step:10228[D loss: 0.426951, acc: 63.28%, op_acc: 35.16%] [G loss: 0.878177]\n",
      "epoch:13 step:10229[D loss: 0.451193, acc: 57.03%, op_acc: 35.94%] [G loss: 0.853720]\n",
      "epoch:13 step:10230[D loss: 0.418629, acc: 57.81%, op_acc: 37.50%] [G loss: 0.802398]\n",
      "epoch:13 step:10231[D loss: 0.456591, acc: 59.38%, op_acc: 25.78%] [G loss: 0.816106]\n",
      "epoch:13 step:10232[D loss: 0.423836, acc: 59.38%, op_acc: 38.28%] [G loss: 0.789798]\n",
      "epoch:13 step:10233[D loss: 0.441337, acc: 61.72%, op_acc: 31.25%] [G loss: 0.874521]\n",
      "epoch:13 step:10234[D loss: 0.460866, acc: 60.94%, op_acc: 31.25%] [G loss: 0.841733]\n",
      "epoch:13 step:10235[D loss: 0.431768, acc: 58.59%, op_acc: 36.72%] [G loss: 0.899958]\n",
      "epoch:13 step:10236[D loss: 0.436017, acc: 61.72%, op_acc: 36.72%] [G loss: 0.900388]\n",
      "epoch:13 step:10237[D loss: 0.431051, acc: 54.69%, op_acc: 38.28%] [G loss: 0.871014]\n",
      "epoch:13 step:10238[D loss: 0.442576, acc: 59.38%, op_acc: 28.91%] [G loss: 0.892945]\n",
      "epoch:13 step:10239[D loss: 0.415024, acc: 63.28%, op_acc: 43.75%] [G loss: 0.925183]\n",
      "epoch:13 step:10240[D loss: 0.434669, acc: 60.16%, op_acc: 35.94%] [G loss: 0.919230]\n",
      "epoch:13 step:10241[D loss: 0.414871, acc: 60.94%, op_acc: 42.19%] [G loss: 0.861665]\n",
      "epoch:13 step:10242[D loss: 0.453812, acc: 53.12%, op_acc: 40.62%] [G loss: 0.826309]\n",
      "epoch:13 step:10243[D loss: 0.449275, acc: 57.81%, op_acc: 38.28%] [G loss: 0.772899]\n",
      "epoch:13 step:10244[D loss: 0.436717, acc: 55.47%, op_acc: 39.84%] [G loss: 0.827655]\n",
      "epoch:13 step:10245[D loss: 0.416374, acc: 64.06%, op_acc: 39.84%] [G loss: 0.884363]\n",
      "epoch:13 step:10246[D loss: 0.413359, acc: 66.41%, op_acc: 37.50%] [G loss: 0.845909]\n",
      "epoch:13 step:10247[D loss: 0.431494, acc: 61.72%, op_acc: 36.72%] [G loss: 0.931034]\n",
      "epoch:13 step:10248[D loss: 0.437486, acc: 58.59%, op_acc: 39.84%] [G loss: 0.881750]\n",
      "epoch:13 step:10249[D loss: 0.468608, acc: 53.91%, op_acc: 32.81%] [G loss: 0.845509]\n",
      "epoch:13 step:10250[D loss: 0.446406, acc: 53.12%, op_acc: 38.28%] [G loss: 0.869600]\n",
      "##############\n",
      "[0.85780328 0.86545205 0.80428538 0.8058598  0.78271367 0.83817898\n",
      " 0.89486673 0.83592409 0.8234681  0.8131733 ]\n",
      "##########\n",
      "epoch:13 step:10251[D loss: 0.443580, acc: 57.03%, op_acc: 32.81%] [G loss: 0.964206]\n",
      "epoch:13 step:10252[D loss: 0.431796, acc: 62.50%, op_acc: 38.28%] [G loss: 0.885590]\n",
      "epoch:13 step:10253[D loss: 0.416893, acc: 60.94%, op_acc: 39.06%] [G loss: 0.890182]\n",
      "epoch:13 step:10254[D loss: 0.429017, acc: 57.81%, op_acc: 32.81%] [G loss: 0.798088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10255[D loss: 0.438861, acc: 57.03%, op_acc: 32.81%] [G loss: 0.928012]\n",
      "epoch:13 step:10256[D loss: 0.428839, acc: 61.72%, op_acc: 36.72%] [G loss: 0.906962]\n",
      "epoch:13 step:10257[D loss: 0.434914, acc: 55.47%, op_acc: 33.59%] [G loss: 0.915127]\n",
      "epoch:13 step:10258[D loss: 0.482810, acc: 46.09%, op_acc: 30.47%] [G loss: 0.810045]\n",
      "epoch:13 step:10259[D loss: 0.416179, acc: 60.94%, op_acc: 36.72%] [G loss: 0.914662]\n",
      "epoch:13 step:10260[D loss: 0.404481, acc: 65.62%, op_acc: 39.84%] [G loss: 0.829473]\n",
      "epoch:13 step:10261[D loss: 0.447617, acc: 62.50%, op_acc: 33.59%] [G loss: 0.943738]\n",
      "epoch:13 step:10262[D loss: 0.428222, acc: 59.38%, op_acc: 33.59%] [G loss: 0.784456]\n",
      "epoch:13 step:10263[D loss: 0.430868, acc: 56.25%, op_acc: 39.84%] [G loss: 0.832128]\n",
      "epoch:13 step:10264[D loss: 0.477313, acc: 51.56%, op_acc: 27.34%] [G loss: 0.743317]\n",
      "epoch:13 step:10265[D loss: 0.385443, acc: 68.75%, op_acc: 35.16%] [G loss: 0.836737]\n",
      "epoch:13 step:10266[D loss: 0.459556, acc: 56.25%, op_acc: 27.34%] [G loss: 0.786570]\n",
      "epoch:13 step:10267[D loss: 0.424838, acc: 60.16%, op_acc: 44.53%] [G loss: 0.845239]\n",
      "epoch:13 step:10268[D loss: 0.431564, acc: 51.56%, op_acc: 38.28%] [G loss: 0.793182]\n",
      "epoch:13 step:10269[D loss: 0.477872, acc: 50.00%, op_acc: 38.28%] [G loss: 0.832707]\n",
      "epoch:13 step:10270[D loss: 0.458754, acc: 50.00%, op_acc: 35.16%] [G loss: 0.847788]\n",
      "epoch:13 step:10271[D loss: 0.452032, acc: 50.00%, op_acc: 39.84%] [G loss: 0.870567]\n",
      "epoch:13 step:10272[D loss: 0.441500, acc: 63.28%, op_acc: 28.91%] [G loss: 0.789230]\n",
      "epoch:13 step:10273[D loss: 0.446001, acc: 67.19%, op_acc: 34.38%] [G loss: 0.836404]\n",
      "epoch:13 step:10274[D loss: 0.442902, acc: 57.81%, op_acc: 34.38%] [G loss: 0.939039]\n",
      "epoch:13 step:10275[D loss: 0.455977, acc: 50.78%, op_acc: 37.50%] [G loss: 0.869389]\n",
      "epoch:13 step:10276[D loss: 0.437725, acc: 53.91%, op_acc: 40.62%] [G loss: 0.860424]\n",
      "epoch:13 step:10277[D loss: 0.444857, acc: 54.69%, op_acc: 35.16%] [G loss: 0.886163]\n",
      "epoch:13 step:10278[D loss: 0.462720, acc: 59.38%, op_acc: 28.91%] [G loss: 0.861647]\n",
      "epoch:13 step:10279[D loss: 0.436745, acc: 59.38%, op_acc: 39.84%] [G loss: 0.930601]\n",
      "epoch:13 step:10280[D loss: 0.457228, acc: 53.12%, op_acc: 33.59%] [G loss: 0.939432]\n",
      "epoch:13 step:10281[D loss: 0.417783, acc: 67.19%, op_acc: 35.94%] [G loss: 0.849459]\n",
      "epoch:13 step:10282[D loss: 0.471060, acc: 53.91%, op_acc: 35.16%] [G loss: 0.875306]\n",
      "epoch:13 step:10283[D loss: 0.405723, acc: 67.97%, op_acc: 39.06%] [G loss: 0.881745]\n",
      "epoch:13 step:10284[D loss: 0.411238, acc: 59.38%, op_acc: 35.94%] [G loss: 0.862894]\n",
      "epoch:13 step:10285[D loss: 0.403202, acc: 58.59%, op_acc: 38.28%] [G loss: 0.863215]\n",
      "epoch:13 step:10286[D loss: 0.444732, acc: 66.41%, op_acc: 32.03%] [G loss: 0.848359]\n",
      "epoch:13 step:10287[D loss: 0.431226, acc: 62.50%, op_acc: 38.28%] [G loss: 0.864778]\n",
      "epoch:13 step:10288[D loss: 0.444785, acc: 60.94%, op_acc: 33.59%] [G loss: 0.892904]\n",
      "epoch:13 step:10289[D loss: 0.429542, acc: 56.25%, op_acc: 39.84%] [G loss: 0.884576]\n",
      "epoch:13 step:10290[D loss: 0.432515, acc: 59.38%, op_acc: 35.94%] [G loss: 0.909345]\n",
      "epoch:13 step:10291[D loss: 0.452593, acc: 56.25%, op_acc: 33.59%] [G loss: 0.831897]\n",
      "epoch:13 step:10292[D loss: 0.435231, acc: 55.47%, op_acc: 35.16%] [G loss: 0.860102]\n",
      "epoch:13 step:10293[D loss: 0.451999, acc: 62.50%, op_acc: 32.03%] [G loss: 0.878957]\n",
      "epoch:13 step:10294[D loss: 0.447153, acc: 58.59%, op_acc: 29.69%] [G loss: 0.899694]\n",
      "epoch:13 step:10295[D loss: 0.401271, acc: 64.06%, op_acc: 40.62%] [G loss: 0.820524]\n",
      "epoch:13 step:10296[D loss: 0.436805, acc: 60.94%, op_acc: 35.94%] [G loss: 0.907392]\n",
      "epoch:13 step:10297[D loss: 0.438479, acc: 59.38%, op_acc: 32.03%] [G loss: 0.883546]\n",
      "epoch:13 step:10298[D loss: 0.460062, acc: 56.25%, op_acc: 31.25%] [G loss: 0.914786]\n",
      "epoch:13 step:10299[D loss: 0.447754, acc: 57.03%, op_acc: 31.25%] [G loss: 0.848660]\n",
      "epoch:13 step:10300[D loss: 0.422980, acc: 60.16%, op_acc: 36.72%] [G loss: 0.835894]\n",
      "##############\n",
      "[0.89134025 0.8556181  0.80968314 0.7994955  0.79041196 0.82377937\n",
      " 0.87599131 0.82202852 0.79378896 0.83554563]\n",
      "##########\n",
      "epoch:13 step:10301[D loss: 0.455155, acc: 59.38%, op_acc: 31.25%] [G loss: 0.913284]\n",
      "epoch:13 step:10302[D loss: 0.442215, acc: 57.81%, op_acc: 32.81%] [G loss: 0.831266]\n",
      "epoch:13 step:10303[D loss: 0.415130, acc: 60.94%, op_acc: 39.84%] [G loss: 0.893658]\n",
      "epoch:13 step:10304[D loss: 0.446217, acc: 53.91%, op_acc: 39.06%] [G loss: 0.965555]\n",
      "epoch:13 step:10305[D loss: 0.422069, acc: 57.81%, op_acc: 39.06%] [G loss: 0.868183]\n",
      "epoch:13 step:10306[D loss: 0.444319, acc: 60.16%, op_acc: 32.81%] [G loss: 0.984693]\n",
      "epoch:13 step:10307[D loss: 0.418718, acc: 57.81%, op_acc: 38.28%] [G loss: 0.871001]\n",
      "epoch:13 step:10308[D loss: 0.408843, acc: 61.72%, op_acc: 40.62%] [G loss: 0.830252]\n",
      "epoch:13 step:10309[D loss: 0.455599, acc: 51.56%, op_acc: 37.50%] [G loss: 0.898828]\n",
      "epoch:13 step:10310[D loss: 0.433958, acc: 55.47%, op_acc: 40.62%] [G loss: 0.806146]\n",
      "epoch:13 step:10311[D loss: 0.415419, acc: 57.81%, op_acc: 35.94%] [G loss: 0.850359]\n",
      "epoch:13 step:10312[D loss: 0.445596, acc: 58.59%, op_acc: 35.16%] [G loss: 0.900497]\n",
      "epoch:13 step:10313[D loss: 0.447290, acc: 57.03%, op_acc: 32.81%] [G loss: 0.881005]\n",
      "epoch:13 step:10314[D loss: 0.448705, acc: 55.47%, op_acc: 32.81%] [G loss: 0.937949]\n",
      "epoch:13 step:10315[D loss: 0.413849, acc: 57.03%, op_acc: 42.97%] [G loss: 0.951771]\n",
      "epoch:13 step:10316[D loss: 0.443023, acc: 57.81%, op_acc: 37.50%] [G loss: 0.792243]\n",
      "epoch:13 step:10317[D loss: 0.437518, acc: 60.16%, op_acc: 36.72%] [G loss: 0.837987]\n",
      "epoch:13 step:10318[D loss: 0.414949, acc: 57.03%, op_acc: 43.75%] [G loss: 0.885721]\n",
      "epoch:13 step:10319[D loss: 0.465600, acc: 54.69%, op_acc: 30.47%] [G loss: 0.862089]\n",
      "epoch:13 step:10320[D loss: 0.434209, acc: 60.94%, op_acc: 35.16%] [G loss: 0.920882]\n",
      "epoch:13 step:10321[D loss: 0.423493, acc: 51.56%, op_acc: 48.44%] [G loss: 0.947389]\n",
      "epoch:13 step:10322[D loss: 0.432123, acc: 57.03%, op_acc: 35.16%] [G loss: 0.898492]\n",
      "epoch:13 step:10323[D loss: 0.450286, acc: 56.25%, op_acc: 36.72%] [G loss: 0.898530]\n",
      "epoch:13 step:10324[D loss: 0.446733, acc: 59.38%, op_acc: 30.47%] [G loss: 0.912468]\n",
      "epoch:13 step:10325[D loss: 0.439380, acc: 57.81%, op_acc: 33.59%] [G loss: 0.855609]\n",
      "epoch:13 step:10326[D loss: 0.442505, acc: 57.03%, op_acc: 32.81%] [G loss: 0.844602]\n",
      "epoch:13 step:10327[D loss: 0.461441, acc: 59.38%, op_acc: 32.81%] [G loss: 0.884642]\n",
      "epoch:13 step:10328[D loss: 0.404257, acc: 64.84%, op_acc: 40.62%] [G loss: 0.845657]\n",
      "epoch:13 step:10329[D loss: 0.453505, acc: 58.59%, op_acc: 33.59%] [G loss: 0.860164]\n",
      "epoch:13 step:10330[D loss: 0.431140, acc: 58.59%, op_acc: 35.94%] [G loss: 0.849265]\n",
      "epoch:13 step:10331[D loss: 0.439482, acc: 60.16%, op_acc: 32.81%] [G loss: 0.907491]\n",
      "epoch:13 step:10332[D loss: 0.396433, acc: 67.19%, op_acc: 38.28%] [G loss: 0.860561]\n",
      "epoch:13 step:10333[D loss: 0.425932, acc: 66.41%, op_acc: 35.94%] [G loss: 0.880090]\n",
      "epoch:13 step:10334[D loss: 0.414573, acc: 64.06%, op_acc: 41.41%] [G loss: 0.855386]\n",
      "epoch:13 step:10335[D loss: 0.404102, acc: 64.84%, op_acc: 39.84%] [G loss: 0.857982]\n",
      "epoch:13 step:10336[D loss: 0.415181, acc: 66.41%, op_acc: 37.50%] [G loss: 0.853493]\n",
      "epoch:13 step:10337[D loss: 0.436462, acc: 54.69%, op_acc: 39.06%] [G loss: 0.872857]\n",
      "epoch:13 step:10338[D loss: 0.443759, acc: 59.38%, op_acc: 34.38%] [G loss: 0.957021]\n",
      "epoch:13 step:10339[D loss: 0.425142, acc: 62.50%, op_acc: 36.72%] [G loss: 0.918700]\n",
      "epoch:13 step:10340[D loss: 0.428938, acc: 55.47%, op_acc: 40.62%] [G loss: 0.928377]\n",
      "epoch:13 step:10341[D loss: 0.435203, acc: 54.69%, op_acc: 39.84%] [G loss: 0.887845]\n",
      "epoch:13 step:10342[D loss: 0.438918, acc: 63.28%, op_acc: 33.59%] [G loss: 0.932303]\n",
      "epoch:13 step:10343[D loss: 0.436086, acc: 58.59%, op_acc: 37.50%] [G loss: 0.919235]\n",
      "epoch:13 step:10344[D loss: 0.433093, acc: 53.12%, op_acc: 36.72%] [G loss: 0.836591]\n",
      "epoch:13 step:10345[D loss: 0.439065, acc: 57.03%, op_acc: 35.94%] [G loss: 0.920698]\n",
      "epoch:13 step:10346[D loss: 0.460686, acc: 57.81%, op_acc: 30.47%] [G loss: 0.884786]\n",
      "epoch:13 step:10347[D loss: 0.433278, acc: 58.59%, op_acc: 35.94%] [G loss: 0.852382]\n",
      "epoch:13 step:10348[D loss: 0.421991, acc: 65.62%, op_acc: 42.19%] [G loss: 0.963051]\n",
      "epoch:13 step:10349[D loss: 0.440496, acc: 64.06%, op_acc: 32.81%] [G loss: 0.802412]\n",
      "epoch:13 step:10350[D loss: 0.464283, acc: 48.44%, op_acc: 38.28%] [G loss: 0.850675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.86335415 0.86032709 0.82819844 0.80300453 0.80273249 0.80672363\n",
      " 0.88459972 0.82340263 0.8229023  0.8330756 ]\n",
      "##########\n",
      "epoch:13 step:10351[D loss: 0.415894, acc: 67.97%, op_acc: 38.28%] [G loss: 0.956350]\n",
      "epoch:13 step:10352[D loss: 0.434116, acc: 57.81%, op_acc: 38.28%] [G loss: 0.801435]\n",
      "epoch:13 step:10353[D loss: 0.441099, acc: 58.59%, op_acc: 32.03%] [G loss: 0.812679]\n",
      "epoch:13 step:10354[D loss: 0.434363, acc: 54.69%, op_acc: 39.06%] [G loss: 0.857400]\n",
      "epoch:13 step:10355[D loss: 0.433813, acc: 61.72%, op_acc: 32.81%] [G loss: 0.930363]\n",
      "epoch:13 step:10356[D loss: 0.457767, acc: 49.22%, op_acc: 37.50%] [G loss: 0.838724]\n",
      "epoch:13 step:10357[D loss: 0.435879, acc: 60.16%, op_acc: 33.59%] [G loss: 0.877059]\n",
      "epoch:13 step:10358[D loss: 0.447166, acc: 53.91%, op_acc: 30.47%] [G loss: 0.879669]\n",
      "epoch:13 step:10359[D loss: 0.454338, acc: 56.25%, op_acc: 32.03%] [G loss: 0.855936]\n",
      "epoch:13 step:10360[D loss: 0.406020, acc: 60.16%, op_acc: 42.19%] [G loss: 0.943263]\n",
      "epoch:13 step:10361[D loss: 0.445393, acc: 59.38%, op_acc: 31.25%] [G loss: 0.863887]\n",
      "epoch:13 step:10362[D loss: 0.426724, acc: 59.38%, op_acc: 39.06%] [G loss: 0.869021]\n",
      "epoch:13 step:10363[D loss: 0.474790, acc: 56.25%, op_acc: 32.81%] [G loss: 0.898529]\n",
      "epoch:13 step:10364[D loss: 0.414511, acc: 58.59%, op_acc: 39.84%] [G loss: 0.867673]\n",
      "epoch:13 step:10365[D loss: 0.426279, acc: 55.47%, op_acc: 34.38%] [G loss: 0.923077]\n",
      "epoch:13 step:10366[D loss: 0.456660, acc: 46.88%, op_acc: 35.94%] [G loss: 0.927384]\n",
      "epoch:13 step:10367[D loss: 0.467396, acc: 53.91%, op_acc: 33.59%] [G loss: 0.913628]\n",
      "epoch:13 step:10368[D loss: 0.446235, acc: 64.06%, op_acc: 32.03%] [G loss: 0.842598]\n",
      "epoch:13 step:10369[D loss: 0.456800, acc: 57.81%, op_acc: 28.91%] [G loss: 0.902934]\n",
      "epoch:13 step:10370[D loss: 0.414849, acc: 59.38%, op_acc: 36.72%] [G loss: 0.903863]\n",
      "epoch:13 step:10371[D loss: 0.461448, acc: 50.78%, op_acc: 36.72%] [G loss: 0.899061]\n",
      "epoch:13 step:10372[D loss: 0.435006, acc: 59.38%, op_acc: 42.19%] [G loss: 0.841865]\n",
      "epoch:13 step:10373[D loss: 0.451815, acc: 51.56%, op_acc: 36.72%] [G loss: 0.845483]\n",
      "epoch:13 step:10374[D loss: 0.437826, acc: 58.59%, op_acc: 36.72%] [G loss: 0.832978]\n",
      "epoch:13 step:10375[D loss: 0.460492, acc: 50.78%, op_acc: 35.16%] [G loss: 0.818014]\n",
      "epoch:13 step:10376[D loss: 0.417956, acc: 60.16%, op_acc: 41.41%] [G loss: 0.906629]\n",
      "epoch:13 step:10377[D loss: 0.427002, acc: 59.38%, op_acc: 34.38%] [G loss: 0.870836]\n",
      "epoch:13 step:10378[D loss: 0.433980, acc: 61.72%, op_acc: 37.50%] [G loss: 0.854754]\n",
      "epoch:13 step:10379[D loss: 0.446043, acc: 57.81%, op_acc: 38.28%] [G loss: 0.849628]\n",
      "epoch:13 step:10380[D loss: 0.434668, acc: 64.84%, op_acc: 32.81%] [G loss: 0.902378]\n",
      "epoch:13 step:10381[D loss: 0.411662, acc: 60.94%, op_acc: 39.06%] [G loss: 0.885912]\n",
      "epoch:13 step:10382[D loss: 0.458723, acc: 50.78%, op_acc: 31.25%] [G loss: 0.743122]\n",
      "epoch:13 step:10383[D loss: 0.437833, acc: 58.59%, op_acc: 35.94%] [G loss: 0.826846]\n",
      "epoch:13 step:10384[D loss: 0.410178, acc: 65.62%, op_acc: 39.06%] [G loss: 0.900414]\n",
      "epoch:13 step:10385[D loss: 0.415946, acc: 63.28%, op_acc: 34.38%] [G loss: 0.849776]\n",
      "epoch:13 step:10386[D loss: 0.430683, acc: 60.16%, op_acc: 35.94%] [G loss: 0.840619]\n",
      "epoch:13 step:10387[D loss: 0.472383, acc: 51.56%, op_acc: 30.47%] [G loss: 0.900676]\n",
      "epoch:13 step:10388[D loss: 0.414925, acc: 60.16%, op_acc: 36.72%] [G loss: 0.829288]\n",
      "epoch:13 step:10389[D loss: 0.442290, acc: 57.81%, op_acc: 34.38%] [G loss: 0.918430]\n",
      "epoch:13 step:10390[D loss: 0.430599, acc: 58.59%, op_acc: 39.06%] [G loss: 0.870791]\n",
      "epoch:13 step:10391[D loss: 0.442032, acc: 61.72%, op_acc: 35.94%] [G loss: 0.920712]\n",
      "epoch:13 step:10392[D loss: 0.395098, acc: 60.94%, op_acc: 42.97%] [G loss: 0.894560]\n",
      "epoch:13 step:10393[D loss: 0.443463, acc: 54.69%, op_acc: 33.59%] [G loss: 0.840529]\n",
      "epoch:13 step:10394[D loss: 0.424537, acc: 59.38%, op_acc: 40.62%] [G loss: 0.926001]\n",
      "epoch:13 step:10395[D loss: 0.414088, acc: 61.72%, op_acc: 39.06%] [G loss: 0.846724]\n",
      "epoch:13 step:10396[D loss: 0.422211, acc: 56.25%, op_acc: 40.62%] [G loss: 0.894814]\n",
      "epoch:13 step:10397[D loss: 0.425134, acc: 60.16%, op_acc: 39.06%] [G loss: 0.810755]\n",
      "epoch:13 step:10398[D loss: 0.450687, acc: 55.47%, op_acc: 39.06%] [G loss: 0.864697]\n",
      "epoch:13 step:10399[D loss: 0.455854, acc: 56.25%, op_acc: 33.59%] [G loss: 0.833487]\n",
      "epoch:13 step:10400[D loss: 0.415585, acc: 55.47%, op_acc: 39.84%] [G loss: 0.872927]\n",
      "##############\n",
      "[0.85213669 0.85531157 0.81011429 0.82372849 0.78862821 0.82020513\n",
      " 0.87483437 0.83410751 0.80686083 0.84368019]\n",
      "##########\n",
      "epoch:13 step:10401[D loss: 0.461842, acc: 57.81%, op_acc: 32.81%] [G loss: 0.884804]\n",
      "epoch:13 step:10402[D loss: 0.471790, acc: 53.12%, op_acc: 35.16%] [G loss: 0.925803]\n",
      "epoch:13 step:10403[D loss: 0.460527, acc: 57.03%, op_acc: 27.34%] [G loss: 0.836874]\n",
      "epoch:13 step:10404[D loss: 0.418095, acc: 60.94%, op_acc: 42.19%] [G loss: 0.835276]\n",
      "epoch:13 step:10405[D loss: 0.414574, acc: 65.62%, op_acc: 38.28%] [G loss: 0.818896]\n",
      "epoch:13 step:10406[D loss: 0.427099, acc: 61.72%, op_acc: 34.38%] [G loss: 0.798237]\n",
      "epoch:13 step:10407[D loss: 0.440286, acc: 62.50%, op_acc: 35.94%] [G loss: 0.906958]\n",
      "epoch:13 step:10408[D loss: 0.440462, acc: 54.69%, op_acc: 35.94%] [G loss: 0.843337]\n",
      "epoch:13 step:10409[D loss: 0.419520, acc: 62.50%, op_acc: 39.84%] [G loss: 0.843606]\n",
      "epoch:13 step:10410[D loss: 0.436972, acc: 61.72%, op_acc: 35.16%] [G loss: 0.863762]\n",
      "epoch:13 step:10411[D loss: 0.415703, acc: 60.94%, op_acc: 35.16%] [G loss: 0.854451]\n",
      "epoch:13 step:10412[D loss: 0.432738, acc: 70.31%, op_acc: 31.25%] [G loss: 0.880395]\n",
      "epoch:13 step:10413[D loss: 0.460642, acc: 55.47%, op_acc: 32.03%] [G loss: 0.847235]\n",
      "epoch:13 step:10414[D loss: 0.407544, acc: 62.50%, op_acc: 38.28%] [G loss: 0.872816]\n",
      "epoch:13 step:10415[D loss: 0.449973, acc: 57.81%, op_acc: 35.16%] [G loss: 0.814920]\n",
      "epoch:13 step:10416[D loss: 0.443121, acc: 60.94%, op_acc: 35.94%] [G loss: 0.863042]\n",
      "epoch:13 step:10417[D loss: 0.462021, acc: 56.25%, op_acc: 30.47%] [G loss: 0.831529]\n",
      "epoch:13 step:10418[D loss: 0.408343, acc: 64.06%, op_acc: 41.41%] [G loss: 0.866969]\n",
      "epoch:13 step:10419[D loss: 0.430114, acc: 54.69%, op_acc: 39.84%] [G loss: 0.924464]\n",
      "epoch:13 step:10420[D loss: 0.454246, acc: 54.69%, op_acc: 36.72%] [G loss: 0.916043]\n",
      "epoch:13 step:10421[D loss: 0.432933, acc: 54.69%, op_acc: 46.09%] [G loss: 0.896610]\n",
      "epoch:13 step:10422[D loss: 0.408324, acc: 60.16%, op_acc: 39.84%] [G loss: 0.886701]\n",
      "epoch:13 step:10423[D loss: 0.445812, acc: 58.59%, op_acc: 35.94%] [G loss: 1.013656]\n",
      "epoch:13 step:10424[D loss: 0.423881, acc: 60.16%, op_acc: 37.50%] [G loss: 0.904322]\n",
      "epoch:13 step:10425[D loss: 0.425532, acc: 59.38%, op_acc: 37.50%] [G loss: 0.840892]\n",
      "epoch:13 step:10426[D loss: 0.401104, acc: 61.72%, op_acc: 41.41%] [G loss: 0.905368]\n",
      "epoch:13 step:10427[D loss: 0.444549, acc: 60.16%, op_acc: 36.72%] [G loss: 0.882602]\n",
      "epoch:13 step:10428[D loss: 0.426681, acc: 55.47%, op_acc: 37.50%] [G loss: 0.886316]\n",
      "epoch:13 step:10429[D loss: 0.448929, acc: 53.12%, op_acc: 36.72%] [G loss: 0.770494]\n",
      "epoch:13 step:10430[D loss: 0.446577, acc: 59.38%, op_acc: 28.12%] [G loss: 0.855620]\n",
      "epoch:13 step:10431[D loss: 0.443997, acc: 60.94%, op_acc: 32.81%] [G loss: 0.848161]\n",
      "epoch:13 step:10432[D loss: 0.472041, acc: 50.00%, op_acc: 35.16%] [G loss: 0.826153]\n",
      "epoch:13 step:10433[D loss: 0.452669, acc: 48.44%, op_acc: 40.62%] [G loss: 0.891404]\n",
      "epoch:13 step:10434[D loss: 0.440027, acc: 63.28%, op_acc: 32.81%] [G loss: 0.814548]\n",
      "epoch:13 step:10435[D loss: 0.438735, acc: 63.28%, op_acc: 32.81%] [G loss: 0.833660]\n",
      "epoch:13 step:10436[D loss: 0.412743, acc: 60.94%, op_acc: 43.75%] [G loss: 0.875800]\n",
      "epoch:13 step:10437[D loss: 0.435097, acc: 62.50%, op_acc: 32.81%] [G loss: 0.887734]\n",
      "epoch:13 step:10438[D loss: 0.443298, acc: 59.38%, op_acc: 39.06%] [G loss: 0.861018]\n",
      "epoch:13 step:10439[D loss: 0.451697, acc: 51.56%, op_acc: 36.72%] [G loss: 0.874837]\n",
      "epoch:13 step:10440[D loss: 0.433659, acc: 61.72%, op_acc: 38.28%] [G loss: 0.891598]\n",
      "epoch:13 step:10441[D loss: 0.444948, acc: 53.91%, op_acc: 41.41%] [G loss: 0.831301]\n",
      "epoch:13 step:10442[D loss: 0.449693, acc: 54.69%, op_acc: 32.03%] [G loss: 0.825434]\n",
      "epoch:13 step:10443[D loss: 0.413412, acc: 65.62%, op_acc: 35.94%] [G loss: 0.880306]\n",
      "epoch:13 step:10444[D loss: 0.416770, acc: 60.94%, op_acc: 43.75%] [G loss: 0.801627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10445[D loss: 0.461985, acc: 53.91%, op_acc: 36.72%] [G loss: 0.824587]\n",
      "epoch:13 step:10446[D loss: 0.447020, acc: 55.47%, op_acc: 32.81%] [G loss: 0.820776]\n",
      "epoch:13 step:10447[D loss: 0.441338, acc: 59.38%, op_acc: 36.72%] [G loss: 0.879274]\n",
      "epoch:13 step:10448[D loss: 0.440518, acc: 53.12%, op_acc: 36.72%] [G loss: 0.839477]\n",
      "epoch:13 step:10449[D loss: 0.442703, acc: 57.81%, op_acc: 41.41%] [G loss: 0.843411]\n",
      "epoch:13 step:10450[D loss: 0.449056, acc: 59.38%, op_acc: 32.03%] [G loss: 0.879645]\n",
      "##############\n",
      "[0.87120202 0.87007974 0.83640852 0.81217889 0.78007569 0.82600481\n",
      " 0.89098266 0.84903695 0.79127247 0.82899976]\n",
      "##########\n",
      "epoch:13 step:10451[D loss: 0.435546, acc: 55.47%, op_acc: 35.16%] [G loss: 0.859478]\n",
      "epoch:13 step:10452[D loss: 0.433092, acc: 53.91%, op_acc: 44.53%] [G loss: 0.859409]\n",
      "epoch:13 step:10453[D loss: 0.445041, acc: 57.81%, op_acc: 34.38%] [G loss: 0.881953]\n",
      "epoch:13 step:10454[D loss: 0.440784, acc: 53.91%, op_acc: 39.06%] [G loss: 0.846843]\n",
      "epoch:13 step:10455[D loss: 0.396783, acc: 67.19%, op_acc: 40.62%] [G loss: 0.882746]\n",
      "epoch:13 step:10456[D loss: 0.442442, acc: 60.16%, op_acc: 32.81%] [G loss: 0.826824]\n",
      "epoch:13 step:10457[D loss: 0.424202, acc: 63.28%, op_acc: 39.84%] [G loss: 0.845807]\n",
      "epoch:13 step:10458[D loss: 0.458054, acc: 50.78%, op_acc: 29.69%] [G loss: 0.888094]\n",
      "epoch:13 step:10459[D loss: 0.445003, acc: 59.38%, op_acc: 34.38%] [G loss: 0.847133]\n",
      "epoch:13 step:10460[D loss: 0.413089, acc: 61.72%, op_acc: 35.94%] [G loss: 0.921877]\n",
      "epoch:13 step:10461[D loss: 0.440560, acc: 59.38%, op_acc: 35.16%] [G loss: 0.932325]\n",
      "epoch:13 step:10462[D loss: 0.431375, acc: 64.06%, op_acc: 32.03%] [G loss: 0.859691]\n",
      "epoch:13 step:10463[D loss: 0.415728, acc: 63.28%, op_acc: 32.81%] [G loss: 0.895409]\n",
      "epoch:13 step:10464[D loss: 0.431123, acc: 63.28%, op_acc: 36.72%] [G loss: 0.904337]\n",
      "epoch:13 step:10465[D loss: 0.436248, acc: 58.59%, op_acc: 32.81%] [G loss: 0.855925]\n",
      "epoch:13 step:10466[D loss: 0.488329, acc: 41.41%, op_acc: 36.72%] [G loss: 0.824483]\n",
      "epoch:13 step:10467[D loss: 0.450171, acc: 55.47%, op_acc: 31.25%] [G loss: 0.846676]\n",
      "epoch:13 step:10468[D loss: 0.451830, acc: 55.47%, op_acc: 33.59%] [G loss: 0.908827]\n",
      "epoch:13 step:10469[D loss: 0.448013, acc: 52.34%, op_acc: 33.59%] [G loss: 0.869692]\n",
      "epoch:13 step:10470[D loss: 0.449918, acc: 53.12%, op_acc: 32.81%] [G loss: 0.884445]\n",
      "epoch:13 step:10471[D loss: 0.433933, acc: 64.84%, op_acc: 26.56%] [G loss: 0.937576]\n",
      "epoch:13 step:10472[D loss: 0.451247, acc: 42.97%, op_acc: 44.53%] [G loss: 0.894072]\n",
      "epoch:13 step:10473[D loss: 0.443344, acc: 53.91%, op_acc: 38.28%] [G loss: 0.925867]\n",
      "epoch:13 step:10474[D loss: 0.432233, acc: 60.94%, op_acc: 34.38%] [G loss: 0.902161]\n",
      "epoch:13 step:10475[D loss: 0.452418, acc: 57.81%, op_acc: 41.41%] [G loss: 0.913112]\n",
      "epoch:13 step:10476[D loss: 0.422970, acc: 58.59%, op_acc: 38.28%] [G loss: 0.866525]\n",
      "epoch:13 step:10477[D loss: 0.440470, acc: 56.25%, op_acc: 32.03%] [G loss: 0.839067]\n",
      "epoch:13 step:10478[D loss: 0.454990, acc: 53.12%, op_acc: 35.16%] [G loss: 0.892696]\n",
      "epoch:13 step:10479[D loss: 0.421327, acc: 63.28%, op_acc: 36.72%] [G loss: 0.767587]\n",
      "epoch:13 step:10480[D loss: 0.420775, acc: 57.81%, op_acc: 39.84%] [G loss: 0.923302]\n",
      "epoch:13 step:10481[D loss: 0.427321, acc: 65.62%, op_acc: 36.72%] [G loss: 0.877413]\n",
      "epoch:13 step:10482[D loss: 0.421421, acc: 58.59%, op_acc: 39.84%] [G loss: 0.945913]\n",
      "epoch:13 step:10483[D loss: 0.423849, acc: 61.72%, op_acc: 37.50%] [G loss: 0.915675]\n",
      "epoch:13 step:10484[D loss: 0.452382, acc: 53.91%, op_acc: 39.84%] [G loss: 0.891357]\n",
      "epoch:13 step:10485[D loss: 0.424551, acc: 60.16%, op_acc: 35.94%] [G loss: 0.857379]\n",
      "epoch:13 step:10486[D loss: 0.425453, acc: 60.94%, op_acc: 35.16%] [G loss: 0.855227]\n",
      "epoch:13 step:10487[D loss: 0.472132, acc: 46.09%, op_acc: 34.38%] [G loss: 0.827728]\n",
      "epoch:13 step:10488[D loss: 0.416553, acc: 64.84%, op_acc: 35.94%] [G loss: 0.870141]\n",
      "epoch:13 step:10489[D loss: 0.440057, acc: 57.81%, op_acc: 38.28%] [G loss: 0.888783]\n",
      "epoch:13 step:10490[D loss: 0.449921, acc: 56.25%, op_acc: 35.16%] [G loss: 0.811331]\n",
      "epoch:13 step:10491[D loss: 0.407486, acc: 63.28%, op_acc: 38.28%] [G loss: 0.904086]\n",
      "epoch:13 step:10492[D loss: 0.448086, acc: 61.72%, op_acc: 34.38%] [G loss: 0.870244]\n",
      "epoch:13 step:10493[D loss: 0.424554, acc: 65.62%, op_acc: 35.94%] [G loss: 0.868551]\n",
      "epoch:13 step:10494[D loss: 0.439030, acc: 57.81%, op_acc: 31.25%] [G loss: 0.839644]\n",
      "epoch:13 step:10495[D loss: 0.489281, acc: 46.88%, op_acc: 30.47%] [G loss: 0.871666]\n",
      "epoch:13 step:10496[D loss: 0.453126, acc: 53.91%, op_acc: 35.16%] [G loss: 0.857054]\n",
      "epoch:13 step:10497[D loss: 0.415001, acc: 58.59%, op_acc: 37.50%] [G loss: 0.885339]\n",
      "epoch:13 step:10498[D loss: 0.446566, acc: 57.81%, op_acc: 37.50%] [G loss: 0.900543]\n",
      "epoch:13 step:10499[D loss: 0.451185, acc: 64.06%, op_acc: 32.81%] [G loss: 0.846901]\n",
      "epoch:13 step:10500[D loss: 0.450037, acc: 51.56%, op_acc: 39.06%] [G loss: 0.824894]\n",
      "##############\n",
      "[0.84565375 0.85801751 0.83280739 0.8271902  0.78289126 0.85182123\n",
      " 0.87022945 0.81279128 0.79456179 0.8274869 ]\n",
      "##########\n",
      "epoch:13 step:10501[D loss: 0.439093, acc: 54.69%, op_acc: 33.59%] [G loss: 0.844171]\n",
      "epoch:13 step:10502[D loss: 0.431970, acc: 60.94%, op_acc: 35.16%] [G loss: 0.859764]\n",
      "epoch:13 step:10503[D loss: 0.450713, acc: 59.38%, op_acc: 37.50%] [G loss: 0.836156]\n",
      "epoch:13 step:10504[D loss: 0.452459, acc: 56.25%, op_acc: 35.94%] [G loss: 0.869681]\n",
      "epoch:13 step:10505[D loss: 0.424021, acc: 60.16%, op_acc: 39.06%] [G loss: 0.872176]\n",
      "epoch:13 step:10506[D loss: 0.437355, acc: 57.03%, op_acc: 39.84%] [G loss: 0.843446]\n",
      "epoch:13 step:10507[D loss: 0.428431, acc: 62.50%, op_acc: 42.97%] [G loss: 0.867851]\n",
      "epoch:13 step:10508[D loss: 0.447424, acc: 53.12%, op_acc: 38.28%] [G loss: 0.857914]\n",
      "epoch:13 step:10509[D loss: 0.423197, acc: 62.50%, op_acc: 35.94%] [G loss: 0.840931]\n",
      "epoch:13 step:10510[D loss: 0.432724, acc: 60.94%, op_acc: 34.38%] [G loss: 0.895110]\n",
      "epoch:13 step:10511[D loss: 0.436969, acc: 63.28%, op_acc: 38.28%] [G loss: 0.874122]\n",
      "epoch:13 step:10512[D loss: 0.428731, acc: 53.91%, op_acc: 40.62%] [G loss: 0.891752]\n",
      "epoch:13 step:10513[D loss: 0.457046, acc: 53.12%, op_acc: 34.38%] [G loss: 0.852999]\n",
      "epoch:13 step:10514[D loss: 0.420065, acc: 64.84%, op_acc: 37.50%] [G loss: 0.952197]\n",
      "epoch:13 step:10515[D loss: 0.409057, acc: 65.62%, op_acc: 35.16%] [G loss: 0.938763]\n",
      "epoch:13 step:10516[D loss: 0.426953, acc: 61.72%, op_acc: 35.16%] [G loss: 0.921703]\n",
      "epoch:13 step:10517[D loss: 0.445832, acc: 53.91%, op_acc: 35.94%] [G loss: 0.916162]\n",
      "epoch:13 step:10518[D loss: 0.406042, acc: 57.81%, op_acc: 41.41%] [G loss: 0.976045]\n",
      "epoch:13 step:10519[D loss: 0.427493, acc: 59.38%, op_acc: 35.16%] [G loss: 0.929862]\n",
      "epoch:13 step:10520[D loss: 0.472481, acc: 56.25%, op_acc: 28.91%] [G loss: 0.917086]\n",
      "epoch:13 step:10521[D loss: 0.439423, acc: 60.16%, op_acc: 33.59%] [G loss: 0.830478]\n",
      "epoch:13 step:10522[D loss: 0.439728, acc: 62.50%, op_acc: 31.25%] [G loss: 0.859056]\n",
      "epoch:13 step:10523[D loss: 0.438796, acc: 57.81%, op_acc: 36.72%] [G loss: 0.895714]\n",
      "epoch:13 step:10524[D loss: 0.399953, acc: 65.62%, op_acc: 41.41%] [G loss: 0.926822]\n",
      "epoch:13 step:10525[D loss: 0.446996, acc: 50.00%, op_acc: 35.16%] [G loss: 0.849696]\n",
      "epoch:13 step:10526[D loss: 0.436942, acc: 57.81%, op_acc: 34.38%] [G loss: 0.892393]\n",
      "epoch:13 step:10527[D loss: 0.430113, acc: 56.25%, op_acc: 35.94%] [G loss: 0.904410]\n",
      "epoch:13 step:10528[D loss: 0.425270, acc: 61.72%, op_acc: 35.16%] [G loss: 0.888411]\n",
      "epoch:13 step:10529[D loss: 0.432848, acc: 57.81%, op_acc: 35.94%] [G loss: 0.849007]\n",
      "epoch:13 step:10530[D loss: 0.445010, acc: 58.59%, op_acc: 30.47%] [G loss: 0.893212]\n",
      "epoch:13 step:10531[D loss: 0.437677, acc: 53.12%, op_acc: 36.72%] [G loss: 0.862810]\n",
      "epoch:13 step:10532[D loss: 0.397221, acc: 64.06%, op_acc: 37.50%] [G loss: 0.853388]\n",
      "epoch:13 step:10533[D loss: 0.436237, acc: 54.69%, op_acc: 46.09%] [G loss: 0.996088]\n",
      "epoch:13 step:10534[D loss: 0.400970, acc: 72.66%, op_acc: 39.06%] [G loss: 0.891776]\n",
      "epoch:13 step:10535[D loss: 0.439319, acc: 58.59%, op_acc: 35.94%] [G loss: 0.955733]\n",
      "epoch:13 step:10536[D loss: 0.398884, acc: 61.72%, op_acc: 38.28%] [G loss: 0.878178]\n",
      "epoch:13 step:10537[D loss: 0.430541, acc: 62.50%, op_acc: 36.72%] [G loss: 0.981073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10538[D loss: 0.411295, acc: 65.62%, op_acc: 36.72%] [G loss: 0.900641]\n",
      "epoch:13 step:10539[D loss: 0.437142, acc: 57.03%, op_acc: 36.72%] [G loss: 0.854417]\n",
      "epoch:13 step:10540[D loss: 0.422700, acc: 67.97%, op_acc: 39.84%] [G loss: 0.895306]\n",
      "epoch:13 step:10541[D loss: 0.432882, acc: 65.62%, op_acc: 35.94%] [G loss: 0.947160]\n",
      "epoch:13 step:10542[D loss: 0.417415, acc: 65.62%, op_acc: 32.03%] [G loss: 0.969794]\n",
      "epoch:13 step:10543[D loss: 0.417795, acc: 61.72%, op_acc: 39.84%] [G loss: 0.930463]\n",
      "epoch:13 step:10544[D loss: 0.418333, acc: 57.03%, op_acc: 39.06%] [G loss: 0.731214]\n",
      "epoch:13 step:10545[D loss: 0.416657, acc: 60.94%, op_acc: 39.84%] [G loss: 0.907646]\n",
      "epoch:13 step:10546[D loss: 0.450903, acc: 62.50%, op_acc: 40.62%] [G loss: 0.877534]\n",
      "epoch:13 step:10547[D loss: 0.418808, acc: 61.72%, op_acc: 37.50%] [G loss: 0.829254]\n",
      "epoch:13 step:10548[D loss: 0.468794, acc: 53.12%, op_acc: 32.03%] [G loss: 0.822432]\n",
      "epoch:13 step:10549[D loss: 0.423149, acc: 63.28%, op_acc: 35.94%] [G loss: 0.905416]\n",
      "epoch:13 step:10550[D loss: 0.413244, acc: 60.16%, op_acc: 42.97%] [G loss: 0.875542]\n",
      "##############\n",
      "[0.85664425 0.84823416 0.8349914  0.80079634 0.78271381 0.82634805\n",
      " 0.87182118 0.84210908 0.82935153 0.84891096]\n",
      "##########\n",
      "epoch:13 step:10551[D loss: 0.445829, acc: 60.16%, op_acc: 30.47%] [G loss: 0.964932]\n",
      "epoch:13 step:10552[D loss: 0.440576, acc: 59.38%, op_acc: 36.72%] [G loss: 0.848953]\n",
      "epoch:13 step:10553[D loss: 0.425879, acc: 61.72%, op_acc: 39.84%] [G loss: 0.896737]\n",
      "epoch:13 step:10554[D loss: 0.421988, acc: 61.72%, op_acc: 36.72%] [G loss: 0.845903]\n",
      "epoch:13 step:10555[D loss: 0.464920, acc: 49.22%, op_acc: 34.38%] [G loss: 0.791917]\n",
      "epoch:13 step:10556[D loss: 0.447760, acc: 57.03%, op_acc: 37.50%] [G loss: 0.784894]\n",
      "epoch:13 step:10557[D loss: 0.420253, acc: 61.72%, op_acc: 38.28%] [G loss: 0.797962]\n",
      "epoch:13 step:10558[D loss: 0.465593, acc: 57.03%, op_acc: 30.47%] [G loss: 0.878774]\n",
      "epoch:13 step:10559[D loss: 0.394036, acc: 71.09%, op_acc: 38.28%] [G loss: 0.969412]\n",
      "epoch:13 step:10560[D loss: 0.418262, acc: 66.41%, op_acc: 37.50%] [G loss: 0.920853]\n",
      "epoch:13 step:10561[D loss: 0.427721, acc: 50.78%, op_acc: 42.19%] [G loss: 0.909100]\n",
      "epoch:13 step:10562[D loss: 0.453249, acc: 53.12%, op_acc: 35.16%] [G loss: 0.935524]\n",
      "epoch:13 step:10563[D loss: 0.407042, acc: 63.28%, op_acc: 40.62%] [G loss: 0.857489]\n",
      "epoch:13 step:10564[D loss: 0.448830, acc: 52.34%, op_acc: 38.28%] [G loss: 0.900989]\n",
      "epoch:13 step:10565[D loss: 0.430456, acc: 59.38%, op_acc: 38.28%] [G loss: 0.886773]\n",
      "epoch:13 step:10566[D loss: 0.425320, acc: 62.50%, op_acc: 38.28%] [G loss: 0.837696]\n",
      "epoch:13 step:10567[D loss: 0.445264, acc: 54.69%, op_acc: 34.38%] [G loss: 0.914495]\n",
      "epoch:13 step:10568[D loss: 0.411455, acc: 60.16%, op_acc: 40.62%] [G loss: 0.832744]\n",
      "epoch:13 step:10569[D loss: 0.415115, acc: 62.50%, op_acc: 39.06%] [G loss: 0.936667]\n",
      "epoch:13 step:10570[D loss: 0.430125, acc: 60.94%, op_acc: 36.72%] [G loss: 0.932904]\n",
      "epoch:13 step:10571[D loss: 0.414053, acc: 60.16%, op_acc: 35.94%] [G loss: 0.893298]\n",
      "epoch:13 step:10572[D loss: 0.447224, acc: 58.59%, op_acc: 35.16%] [G loss: 0.849339]\n",
      "epoch:13 step:10573[D loss: 0.451679, acc: 59.38%, op_acc: 33.59%] [G loss: 0.780540]\n",
      "epoch:13 step:10574[D loss: 0.435837, acc: 63.28%, op_acc: 35.16%] [G loss: 0.866247]\n",
      "epoch:13 step:10575[D loss: 0.465127, acc: 52.34%, op_acc: 32.03%] [G loss: 0.810090]\n",
      "epoch:13 step:10576[D loss: 0.432012, acc: 62.50%, op_acc: 35.94%] [G loss: 0.865411]\n",
      "epoch:13 step:10577[D loss: 0.449891, acc: 60.94%, op_acc: 39.06%] [G loss: 0.945101]\n",
      "epoch:13 step:10578[D loss: 0.445415, acc: 54.69%, op_acc: 35.94%] [G loss: 0.883726]\n",
      "epoch:13 step:10579[D loss: 0.451117, acc: 54.69%, op_acc: 40.62%] [G loss: 0.883103]\n",
      "epoch:13 step:10580[D loss: 0.445334, acc: 56.25%, op_acc: 32.81%] [G loss: 0.832895]\n",
      "epoch:13 step:10581[D loss: 0.425880, acc: 60.16%, op_acc: 38.28%] [G loss: 0.898692]\n",
      "epoch:13 step:10582[D loss: 0.460187, acc: 49.22%, op_acc: 35.94%] [G loss: 0.892539]\n",
      "epoch:13 step:10583[D loss: 0.411534, acc: 65.62%, op_acc: 40.62%] [G loss: 0.887780]\n",
      "epoch:13 step:10584[D loss: 0.456533, acc: 58.59%, op_acc: 33.59%] [G loss: 0.855651]\n",
      "epoch:13 step:10585[D loss: 0.417714, acc: 61.72%, op_acc: 42.19%] [G loss: 0.950273]\n",
      "epoch:13 step:10586[D loss: 0.449464, acc: 58.59%, op_acc: 38.28%] [G loss: 0.870162]\n",
      "epoch:13 step:10587[D loss: 0.436912, acc: 60.16%, op_acc: 38.28%] [G loss: 0.873123]\n",
      "epoch:13 step:10588[D loss: 0.428925, acc: 61.72%, op_acc: 37.50%] [G loss: 0.898655]\n",
      "epoch:13 step:10589[D loss: 0.416649, acc: 69.53%, op_acc: 40.62%] [G loss: 0.992408]\n",
      "epoch:13 step:10590[D loss: 0.425728, acc: 59.38%, op_acc: 36.72%] [G loss: 0.854867]\n",
      "epoch:13 step:10591[D loss: 0.419431, acc: 60.94%, op_acc: 37.50%] [G loss: 0.886382]\n",
      "epoch:13 step:10592[D loss: 0.436618, acc: 60.94%, op_acc: 32.03%] [G loss: 0.883889]\n",
      "epoch:13 step:10593[D loss: 0.424254, acc: 58.59%, op_acc: 38.28%] [G loss: 0.883857]\n",
      "epoch:13 step:10594[D loss: 0.439915, acc: 53.91%, op_acc: 34.38%] [G loss: 0.845526]\n",
      "epoch:13 step:10595[D loss: 0.414433, acc: 57.81%, op_acc: 42.19%] [G loss: 0.851808]\n",
      "epoch:13 step:10596[D loss: 0.455880, acc: 56.25%, op_acc: 32.03%] [G loss: 0.881398]\n",
      "epoch:13 step:10597[D loss: 0.418682, acc: 60.94%, op_acc: 39.84%] [G loss: 0.873814]\n",
      "epoch:13 step:10598[D loss: 0.454782, acc: 49.22%, op_acc: 38.28%] [G loss: 0.890488]\n",
      "epoch:13 step:10599[D loss: 0.418866, acc: 63.28%, op_acc: 36.72%] [G loss: 0.915442]\n",
      "epoch:13 step:10600[D loss: 0.449481, acc: 60.16%, op_acc: 32.81%] [G loss: 0.941854]\n",
      "##############\n",
      "[0.87739014 0.86423072 0.8380931  0.80053391 0.77364106 0.8314527\n",
      " 0.88721449 0.81916548 0.82062036 0.82909525]\n",
      "##########\n",
      "epoch:13 step:10601[D loss: 0.414603, acc: 66.41%, op_acc: 39.06%] [G loss: 0.967786]\n",
      "epoch:13 step:10602[D loss: 0.437547, acc: 60.16%, op_acc: 35.16%] [G loss: 0.876821]\n",
      "epoch:13 step:10603[D loss: 0.421975, acc: 67.19%, op_acc: 30.47%] [G loss: 0.859044]\n",
      "epoch:13 step:10604[D loss: 0.445152, acc: 52.34%, op_acc: 39.06%] [G loss: 0.919253]\n",
      "epoch:13 step:10605[D loss: 0.416881, acc: 64.06%, op_acc: 39.84%] [G loss: 0.826603]\n",
      "epoch:13 step:10606[D loss: 0.415246, acc: 58.59%, op_acc: 42.19%] [G loss: 0.916188]\n",
      "epoch:13 step:10607[D loss: 0.425722, acc: 57.03%, op_acc: 36.72%] [G loss: 0.819165]\n",
      "epoch:13 step:10608[D loss: 0.477285, acc: 47.66%, op_acc: 32.81%] [G loss: 0.861489]\n",
      "epoch:13 step:10609[D loss: 0.444097, acc: 57.81%, op_acc: 42.19%] [G loss: 0.857435]\n",
      "epoch:13 step:10610[D loss: 0.428958, acc: 60.16%, op_acc: 34.38%] [G loss: 0.939483]\n",
      "epoch:13 step:10611[D loss: 0.402382, acc: 64.06%, op_acc: 43.75%] [G loss: 0.904194]\n",
      "epoch:13 step:10612[D loss: 0.416647, acc: 62.50%, op_acc: 42.19%] [G loss: 0.920830]\n",
      "epoch:13 step:10613[D loss: 0.443165, acc: 57.81%, op_acc: 37.50%] [G loss: 0.868958]\n",
      "epoch:13 step:10614[D loss: 0.428151, acc: 56.25%, op_acc: 37.50%] [G loss: 0.871305]\n",
      "epoch:13 step:10615[D loss: 0.453672, acc: 53.12%, op_acc: 31.25%] [G loss: 0.900590]\n",
      "epoch:13 step:10616[D loss: 0.426714, acc: 63.28%, op_acc: 37.50%] [G loss: 0.863859]\n",
      "epoch:13 step:10617[D loss: 0.420461, acc: 62.50%, op_acc: 35.16%] [G loss: 0.869575]\n",
      "epoch:13 step:10618[D loss: 0.446900, acc: 50.78%, op_acc: 37.50%] [G loss: 0.821737]\n",
      "epoch:13 step:10619[D loss: 0.435032, acc: 57.03%, op_acc: 37.50%] [G loss: 0.850720]\n",
      "epoch:13 step:10620[D loss: 0.453220, acc: 55.47%, op_acc: 35.94%] [G loss: 0.849794]\n",
      "epoch:13 step:10621[D loss: 0.428712, acc: 64.84%, op_acc: 33.59%] [G loss: 0.822565]\n",
      "epoch:13 step:10622[D loss: 0.440091, acc: 54.69%, op_acc: 39.06%] [G loss: 0.835736]\n",
      "epoch:13 step:10623[D loss: 0.413260, acc: 64.06%, op_acc: 43.75%] [G loss: 0.896687]\n",
      "epoch:13 step:10624[D loss: 0.451848, acc: 57.03%, op_acc: 32.81%] [G loss: 0.854748]\n",
      "epoch:13 step:10625[D loss: 0.438705, acc: 61.72%, op_acc: 34.38%] [G loss: 0.892594]\n",
      "epoch:13 step:10626[D loss: 0.440473, acc: 48.44%, op_acc: 40.62%] [G loss: 0.850815]\n",
      "epoch:13 step:10627[D loss: 0.421982, acc: 62.50%, op_acc: 35.94%] [G loss: 0.880324]\n",
      "epoch:13 step:10628[D loss: 0.457319, acc: 50.78%, op_acc: 39.84%] [G loss: 0.862526]\n",
      "epoch:13 step:10629[D loss: 0.439419, acc: 60.16%, op_acc: 39.06%] [G loss: 0.909368]\n",
      "epoch:13 step:10630[D loss: 0.440086, acc: 64.06%, op_acc: 36.72%] [G loss: 0.863120]\n",
      "epoch:13 step:10631[D loss: 0.433470, acc: 57.03%, op_acc: 37.50%] [G loss: 0.885099]\n",
      "epoch:13 step:10632[D loss: 0.432729, acc: 62.50%, op_acc: 35.94%] [G loss: 0.964520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10633[D loss: 0.455147, acc: 59.38%, op_acc: 32.03%] [G loss: 0.845589]\n",
      "epoch:13 step:10634[D loss: 0.434684, acc: 67.97%, op_acc: 31.25%] [G loss: 0.864929]\n",
      "epoch:13 step:10635[D loss: 0.463001, acc: 51.56%, op_acc: 31.25%] [G loss: 0.849520]\n",
      "epoch:13 step:10636[D loss: 0.429848, acc: 62.50%, op_acc: 38.28%] [G loss: 0.904136]\n",
      "epoch:13 step:10637[D loss: 0.424747, acc: 57.81%, op_acc: 39.84%] [G loss: 0.829241]\n",
      "epoch:13 step:10638[D loss: 0.433796, acc: 64.06%, op_acc: 33.59%] [G loss: 0.918800]\n",
      "epoch:13 step:10639[D loss: 0.411554, acc: 61.72%, op_acc: 44.53%] [G loss: 0.868802]\n",
      "epoch:13 step:10640[D loss: 0.445685, acc: 57.81%, op_acc: 35.94%] [G loss: 0.904564]\n",
      "epoch:13 step:10641[D loss: 0.445910, acc: 56.25%, op_acc: 36.72%] [G loss: 0.890276]\n",
      "epoch:13 step:10642[D loss: 0.420831, acc: 60.16%, op_acc: 40.62%] [G loss: 0.902292]\n",
      "epoch:13 step:10643[D loss: 0.440338, acc: 62.50%, op_acc: 38.28%] [G loss: 0.864382]\n",
      "epoch:13 step:10644[D loss: 0.436599, acc: 62.50%, op_acc: 34.38%] [G loss: 0.852099]\n",
      "epoch:13 step:10645[D loss: 0.424506, acc: 58.59%, op_acc: 35.94%] [G loss: 0.923520]\n",
      "epoch:13 step:10646[D loss: 0.421998, acc: 60.94%, op_acc: 41.41%] [G loss: 0.918126]\n",
      "epoch:13 step:10647[D loss: 0.424217, acc: 63.28%, op_acc: 32.03%] [G loss: 0.946995]\n",
      "epoch:13 step:10648[D loss: 0.438921, acc: 57.03%, op_acc: 36.72%] [G loss: 0.837241]\n",
      "epoch:13 step:10649[D loss: 0.411932, acc: 68.75%, op_acc: 36.72%] [G loss: 0.883966]\n",
      "epoch:13 step:10650[D loss: 0.434232, acc: 53.91%, op_acc: 35.16%] [G loss: 0.959481]\n",
      "##############\n",
      "[0.84416298 0.85751914 0.8200882  0.81438388 0.82322508 0.83181462\n",
      " 0.86380159 0.83067122 0.80776227 0.80844532]\n",
      "##########\n",
      "epoch:13 step:10651[D loss: 0.435729, acc: 62.50%, op_acc: 32.03%] [G loss: 0.896456]\n",
      "epoch:13 step:10652[D loss: 0.452371, acc: 61.72%, op_acc: 32.81%] [G loss: 0.880931]\n",
      "epoch:13 step:10653[D loss: 0.435733, acc: 63.28%, op_acc: 35.16%] [G loss: 0.883414]\n",
      "epoch:13 step:10654[D loss: 0.445147, acc: 65.62%, op_acc: 34.38%] [G loss: 0.848187]\n",
      "epoch:13 step:10655[D loss: 0.406323, acc: 62.50%, op_acc: 44.53%] [G loss: 0.894690]\n",
      "epoch:13 step:10656[D loss: 0.426983, acc: 59.38%, op_acc: 39.06%] [G loss: 0.854248]\n",
      "epoch:13 step:10657[D loss: 0.445509, acc: 53.12%, op_acc: 35.16%] [G loss: 0.828554]\n",
      "epoch:13 step:10658[D loss: 0.455687, acc: 53.12%, op_acc: 32.81%] [G loss: 0.866329]\n",
      "epoch:13 step:10659[D loss: 0.421099, acc: 65.62%, op_acc: 36.72%] [G loss: 0.867936]\n",
      "epoch:13 step:10660[D loss: 0.444687, acc: 51.56%, op_acc: 42.97%] [G loss: 0.865485]\n",
      "epoch:13 step:10661[D loss: 0.421464, acc: 57.81%, op_acc: 37.50%] [G loss: 0.796016]\n",
      "epoch:13 step:10662[D loss: 0.454898, acc: 58.59%, op_acc: 32.81%] [G loss: 0.850149]\n",
      "epoch:13 step:10663[D loss: 0.424300, acc: 63.28%, op_acc: 35.16%] [G loss: 0.876297]\n",
      "epoch:13 step:10664[D loss: 0.420763, acc: 60.16%, op_acc: 38.28%] [G loss: 0.859100]\n",
      "epoch:13 step:10665[D loss: 0.444850, acc: 62.50%, op_acc: 32.81%] [G loss: 0.933957]\n",
      "epoch:13 step:10666[D loss: 0.453872, acc: 57.03%, op_acc: 33.59%] [G loss: 0.884932]\n",
      "epoch:13 step:10667[D loss: 0.451805, acc: 52.34%, op_acc: 30.47%] [G loss: 0.883604]\n",
      "epoch:13 step:10668[D loss: 0.447156, acc: 59.38%, op_acc: 31.25%] [G loss: 0.884893]\n",
      "epoch:13 step:10669[D loss: 0.424575, acc: 64.06%, op_acc: 37.50%] [G loss: 0.869206]\n",
      "epoch:13 step:10670[D loss: 0.452893, acc: 57.81%, op_acc: 28.12%] [G loss: 0.872984]\n",
      "epoch:13 step:10671[D loss: 0.393214, acc: 68.75%, op_acc: 41.41%] [G loss: 0.858778]\n",
      "epoch:13 step:10672[D loss: 0.400267, acc: 64.06%, op_acc: 38.28%] [G loss: 0.903552]\n",
      "epoch:13 step:10673[D loss: 0.438330, acc: 57.81%, op_acc: 40.62%] [G loss: 0.884357]\n",
      "epoch:13 step:10674[D loss: 0.431263, acc: 61.72%, op_acc: 38.28%] [G loss: 0.924454]\n",
      "epoch:13 step:10675[D loss: 0.460947, acc: 55.47%, op_acc: 32.81%] [G loss: 0.893943]\n",
      "epoch:13 step:10676[D loss: 0.425653, acc: 59.38%, op_acc: 38.28%] [G loss: 0.859518]\n",
      "epoch:13 step:10677[D loss: 0.416574, acc: 64.06%, op_acc: 39.06%] [G loss: 0.902710]\n",
      "epoch:13 step:10678[D loss: 0.457674, acc: 58.59%, op_acc: 29.69%] [G loss: 0.884972]\n",
      "epoch:13 step:10679[D loss: 0.470945, acc: 57.81%, op_acc: 29.69%] [G loss: 0.883308]\n",
      "epoch:13 step:10680[D loss: 0.476389, acc: 50.00%, op_acc: 32.81%] [G loss: 0.882078]\n",
      "epoch:13 step:10681[D loss: 0.409185, acc: 61.72%, op_acc: 35.16%] [G loss: 0.950305]\n",
      "epoch:13 step:10682[D loss: 0.433044, acc: 58.59%, op_acc: 38.28%] [G loss: 0.879068]\n",
      "epoch:13 step:10683[D loss: 0.443203, acc: 59.38%, op_acc: 29.69%] [G loss: 0.874077]\n",
      "epoch:13 step:10684[D loss: 0.416387, acc: 69.53%, op_acc: 35.16%] [G loss: 0.940835]\n",
      "epoch:13 step:10685[D loss: 0.435516, acc: 59.38%, op_acc: 36.72%] [G loss: 0.865866]\n",
      "epoch:13 step:10686[D loss: 0.442251, acc: 56.25%, op_acc: 38.28%] [G loss: 0.856474]\n",
      "epoch:13 step:10687[D loss: 0.428464, acc: 58.59%, op_acc: 36.72%] [G loss: 0.879283]\n",
      "epoch:13 step:10688[D loss: 0.442518, acc: 56.25%, op_acc: 39.06%] [G loss: 0.872812]\n",
      "epoch:13 step:10689[D loss: 0.414242, acc: 55.47%, op_acc: 39.06%] [G loss: 0.910042]\n",
      "epoch:13 step:10690[D loss: 0.448506, acc: 63.28%, op_acc: 35.16%] [G loss: 0.925804]\n",
      "epoch:13 step:10691[D loss: 0.447559, acc: 54.69%, op_acc: 34.38%] [G loss: 0.810117]\n",
      "epoch:13 step:10692[D loss: 0.454924, acc: 50.78%, op_acc: 34.38%] [G loss: 0.902556]\n",
      "epoch:13 step:10693[D loss: 0.409568, acc: 61.72%, op_acc: 41.41%] [G loss: 0.860564]\n",
      "epoch:13 step:10694[D loss: 0.420039, acc: 58.59%, op_acc: 37.50%] [G loss: 0.855600]\n",
      "epoch:13 step:10695[D loss: 0.448266, acc: 58.59%, op_acc: 37.50%] [G loss: 0.835880]\n",
      "epoch:13 step:10696[D loss: 0.444543, acc: 63.28%, op_acc: 33.59%] [G loss: 0.841382]\n",
      "epoch:13 step:10697[D loss: 0.415330, acc: 62.50%, op_acc: 42.19%] [G loss: 0.884753]\n",
      "epoch:13 step:10698[D loss: 0.394772, acc: 66.41%, op_acc: 35.16%] [G loss: 0.943286]\n",
      "epoch:13 step:10699[D loss: 0.441959, acc: 52.34%, op_acc: 31.25%] [G loss: 0.824944]\n",
      "epoch:13 step:10700[D loss: 0.449376, acc: 60.16%, op_acc: 33.59%] [G loss: 0.865020]\n",
      "##############\n",
      "[0.86026314 0.88168634 0.80147447 0.7996823  0.79499517 0.8247512\n",
      " 0.90318086 0.82741403 0.8287781  0.81486064]\n",
      "##########\n",
      "epoch:13 step:10701[D loss: 0.444870, acc: 55.47%, op_acc: 39.06%] [G loss: 0.869716]\n",
      "epoch:13 step:10702[D loss: 0.435219, acc: 57.03%, op_acc: 43.75%] [G loss: 0.858722]\n",
      "epoch:13 step:10703[D loss: 0.442778, acc: 54.69%, op_acc: 36.72%] [G loss: 0.889930]\n",
      "epoch:13 step:10704[D loss: 0.426949, acc: 60.94%, op_acc: 40.62%] [G loss: 0.944488]\n",
      "epoch:13 step:10705[D loss: 0.454601, acc: 51.56%, op_acc: 34.38%] [G loss: 0.852081]\n",
      "epoch:13 step:10706[D loss: 0.436856, acc: 55.47%, op_acc: 36.72%] [G loss: 0.848771]\n",
      "epoch:13 step:10707[D loss: 0.433902, acc: 61.72%, op_acc: 38.28%] [G loss: 0.846536]\n",
      "epoch:13 step:10708[D loss: 0.442201, acc: 54.69%, op_acc: 35.94%] [G loss: 0.924127]\n",
      "epoch:13 step:10709[D loss: 0.416100, acc: 60.94%, op_acc: 42.97%] [G loss: 0.841053]\n",
      "epoch:13 step:10710[D loss: 0.447829, acc: 56.25%, op_acc: 32.03%] [G loss: 0.804119]\n",
      "epoch:13 step:10711[D loss: 0.446650, acc: 55.47%, op_acc: 42.19%] [G loss: 0.897072]\n",
      "epoch:13 step:10712[D loss: 0.419567, acc: 57.81%, op_acc: 36.72%] [G loss: 0.873194]\n",
      "epoch:13 step:10713[D loss: 0.432951, acc: 57.03%, op_acc: 38.28%] [G loss: 0.922290]\n",
      "epoch:13 step:10714[D loss: 0.411580, acc: 64.84%, op_acc: 43.75%] [G loss: 0.912271]\n",
      "epoch:13 step:10715[D loss: 0.468610, acc: 49.22%, op_acc: 35.16%] [G loss: 0.825668]\n",
      "epoch:13 step:10716[D loss: 0.444793, acc: 64.06%, op_acc: 34.38%] [G loss: 0.854350]\n",
      "epoch:13 step:10717[D loss: 0.425195, acc: 61.72%, op_acc: 39.06%] [G loss: 0.924868]\n",
      "epoch:13 step:10718[D loss: 0.415742, acc: 60.94%, op_acc: 40.62%] [G loss: 0.898746]\n",
      "epoch:13 step:10719[D loss: 0.436113, acc: 61.72%, op_acc: 37.50%] [G loss: 0.939294]\n",
      "epoch:13 step:10720[D loss: 0.421957, acc: 60.94%, op_acc: 36.72%] [G loss: 0.847004]\n",
      "epoch:13 step:10721[D loss: 0.426243, acc: 60.94%, op_acc: 43.75%] [G loss: 0.924925]\n",
      "epoch:13 step:10722[D loss: 0.420034, acc: 60.16%, op_acc: 37.50%] [G loss: 0.922102]\n",
      "epoch:13 step:10723[D loss: 0.416296, acc: 61.72%, op_acc: 40.62%] [G loss: 0.889138]\n",
      "epoch:13 step:10724[D loss: 0.411204, acc: 64.06%, op_acc: 39.06%] [G loss: 0.943078]\n",
      "epoch:13 step:10725[D loss: 0.431496, acc: 60.94%, op_acc: 35.94%] [G loss: 0.857733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10726[D loss: 0.436322, acc: 53.91%, op_acc: 35.94%] [G loss: 0.852130]\n",
      "epoch:13 step:10727[D loss: 0.441571, acc: 56.25%, op_acc: 33.59%] [G loss: 0.951020]\n",
      "epoch:13 step:10728[D loss: 0.422206, acc: 63.28%, op_acc: 36.72%] [G loss: 0.930818]\n",
      "epoch:13 step:10729[D loss: 0.439504, acc: 57.03%, op_acc: 36.72%] [G loss: 0.825913]\n",
      "epoch:13 step:10730[D loss: 0.466493, acc: 53.91%, op_acc: 34.38%] [G loss: 0.895772]\n",
      "epoch:13 step:10731[D loss: 0.448848, acc: 62.50%, op_acc: 33.59%] [G loss: 0.940842]\n",
      "epoch:13 step:10732[D loss: 0.412626, acc: 64.06%, op_acc: 40.62%] [G loss: 0.976316]\n",
      "epoch:13 step:10733[D loss: 0.433572, acc: 60.94%, op_acc: 41.41%] [G loss: 0.968272]\n",
      "epoch:13 step:10734[D loss: 0.449589, acc: 54.69%, op_acc: 32.03%] [G loss: 0.896525]\n",
      "epoch:13 step:10735[D loss: 0.428486, acc: 66.41%, op_acc: 34.38%] [G loss: 0.816620]\n",
      "epoch:13 step:10736[D loss: 0.428133, acc: 63.28%, op_acc: 31.25%] [G loss: 0.920395]\n",
      "epoch:13 step:10737[D loss: 0.452617, acc: 62.50%, op_acc: 30.47%] [G loss: 0.913257]\n",
      "epoch:13 step:10738[D loss: 0.420454, acc: 59.38%, op_acc: 39.06%] [G loss: 0.858006]\n",
      "epoch:13 step:10739[D loss: 0.425984, acc: 66.41%, op_acc: 35.94%] [G loss: 0.887119]\n",
      "epoch:13 step:10740[D loss: 0.414944, acc: 62.50%, op_acc: 36.72%] [G loss: 0.888799]\n",
      "epoch:13 step:10741[D loss: 0.429106, acc: 57.81%, op_acc: 37.50%] [G loss: 0.965645]\n",
      "epoch:13 step:10742[D loss: 0.442740, acc: 56.25%, op_acc: 35.94%] [G loss: 0.877225]\n",
      "epoch:13 step:10743[D loss: 0.437336, acc: 61.72%, op_acc: 34.38%] [G loss: 0.927972]\n",
      "epoch:13 step:10744[D loss: 0.446220, acc: 56.25%, op_acc: 28.91%] [G loss: 0.798242]\n",
      "epoch:13 step:10745[D loss: 0.427757, acc: 59.38%, op_acc: 37.50%] [G loss: 0.880871]\n",
      "epoch:13 step:10746[D loss: 0.423401, acc: 68.75%, op_acc: 37.50%] [G loss: 0.811867]\n",
      "epoch:13 step:10747[D loss: 0.427224, acc: 62.50%, op_acc: 42.19%] [G loss: 0.874894]\n",
      "epoch:13 step:10748[D loss: 0.442407, acc: 53.12%, op_acc: 35.94%] [G loss: 0.860872]\n",
      "epoch:13 step:10749[D loss: 0.438937, acc: 58.59%, op_acc: 35.94%] [G loss: 0.804834]\n",
      "epoch:13 step:10750[D loss: 0.456925, acc: 55.47%, op_acc: 37.50%] [G loss: 0.895021]\n",
      "##############\n",
      "[0.86981349 0.86279596 0.82557034 0.80837942 0.79722248 0.82813704\n",
      " 0.88345876 0.81009003 0.81574701 0.8391236 ]\n",
      "##########\n",
      "epoch:13 step:10751[D loss: 0.436377, acc: 52.34%, op_acc: 39.84%] [G loss: 0.827044]\n",
      "epoch:13 step:10752[D loss: 0.443482, acc: 59.38%, op_acc: 36.72%] [G loss: 0.853639]\n",
      "epoch:13 step:10753[D loss: 0.419657, acc: 59.38%, op_acc: 38.28%] [G loss: 0.930671]\n",
      "epoch:13 step:10754[D loss: 0.435535, acc: 56.25%, op_acc: 36.72%] [G loss: 0.903073]\n",
      "epoch:13 step:10755[D loss: 0.410498, acc: 63.28%, op_acc: 40.62%] [G loss: 0.835190]\n",
      "epoch:13 step:10756[D loss: 0.397408, acc: 61.72%, op_acc: 39.84%] [G loss: 0.853524]\n",
      "epoch:13 step:10757[D loss: 0.480137, acc: 57.03%, op_acc: 31.25%] [G loss: 0.905539]\n",
      "epoch:13 step:10758[D loss: 0.423245, acc: 63.28%, op_acc: 32.81%] [G loss: 0.872459]\n",
      "epoch:13 step:10759[D loss: 0.442657, acc: 57.81%, op_acc: 34.38%] [G loss: 0.853571]\n",
      "epoch:13 step:10760[D loss: 0.425579, acc: 52.34%, op_acc: 39.06%] [G loss: 0.801818]\n",
      "epoch:13 step:10761[D loss: 0.414649, acc: 63.28%, op_acc: 43.75%] [G loss: 0.826512]\n",
      "epoch:13 step:10762[D loss: 0.440771, acc: 54.69%, op_acc: 37.50%] [G loss: 0.979773]\n",
      "epoch:13 step:10763[D loss: 0.445209, acc: 57.03%, op_acc: 38.28%] [G loss: 0.812247]\n",
      "epoch:13 step:10764[D loss: 0.437743, acc: 57.81%, op_acc: 37.50%] [G loss: 0.880741]\n",
      "epoch:13 step:10765[D loss: 0.430482, acc: 64.06%, op_acc: 37.50%] [G loss: 0.882888]\n",
      "epoch:13 step:10766[D loss: 0.451964, acc: 51.56%, op_acc: 39.84%] [G loss: 0.837654]\n",
      "epoch:13 step:10767[D loss: 0.417944, acc: 57.03%, op_acc: 37.50%] [G loss: 0.911988]\n",
      "epoch:13 step:10768[D loss: 0.417800, acc: 60.94%, op_acc: 37.50%] [G loss: 0.969492]\n",
      "epoch:13 step:10769[D loss: 0.461105, acc: 57.81%, op_acc: 37.50%] [G loss: 0.917148]\n",
      "epoch:13 step:10770[D loss: 0.428137, acc: 61.72%, op_acc: 32.81%] [G loss: 0.881663]\n",
      "epoch:13 step:10771[D loss: 0.420187, acc: 60.16%, op_acc: 38.28%] [G loss: 0.824258]\n",
      "epoch:13 step:10772[D loss: 0.444914, acc: 68.75%, op_acc: 28.91%] [G loss: 0.901697]\n",
      "epoch:13 step:10773[D loss: 0.441198, acc: 56.25%, op_acc: 32.81%] [G loss: 0.900939]\n",
      "epoch:13 step:10774[D loss: 0.415540, acc: 62.50%, op_acc: 40.62%] [G loss: 0.972888]\n",
      "epoch:13 step:10775[D loss: 0.452706, acc: 60.94%, op_acc: 33.59%] [G loss: 0.915495]\n",
      "epoch:13 step:10776[D loss: 0.445493, acc: 56.25%, op_acc: 36.72%] [G loss: 0.915744]\n",
      "epoch:13 step:10777[D loss: 0.435792, acc: 53.91%, op_acc: 37.50%] [G loss: 0.868242]\n",
      "epoch:13 step:10778[D loss: 0.434003, acc: 62.50%, op_acc: 39.06%] [G loss: 0.854724]\n",
      "epoch:13 step:10779[D loss: 0.400834, acc: 71.88%, op_acc: 40.62%] [G loss: 0.903605]\n",
      "epoch:13 step:10780[D loss: 0.442662, acc: 52.34%, op_acc: 39.06%] [G loss: 0.872347]\n",
      "epoch:13 step:10781[D loss: 0.421150, acc: 63.28%, op_acc: 37.50%] [G loss: 0.996194]\n",
      "epoch:13 step:10782[D loss: 0.448870, acc: 61.72%, op_acc: 30.47%] [G loss: 0.923407]\n",
      "epoch:13 step:10783[D loss: 0.418212, acc: 63.28%, op_acc: 36.72%] [G loss: 0.803620]\n",
      "epoch:13 step:10784[D loss: 0.446638, acc: 55.47%, op_acc: 39.84%] [G loss: 0.955734]\n",
      "epoch:13 step:10785[D loss: 0.446852, acc: 64.06%, op_acc: 31.25%] [G loss: 0.906604]\n",
      "epoch:13 step:10786[D loss: 0.428455, acc: 60.16%, op_acc: 36.72%] [G loss: 0.859783]\n",
      "epoch:13 step:10787[D loss: 0.460896, acc: 50.78%, op_acc: 35.16%] [G loss: 0.841717]\n",
      "epoch:13 step:10788[D loss: 0.451518, acc: 51.56%, op_acc: 37.50%] [G loss: 0.806323]\n",
      "epoch:13 step:10789[D loss: 0.426562, acc: 61.72%, op_acc: 39.06%] [G loss: 0.809413]\n",
      "epoch:13 step:10790[D loss: 0.432366, acc: 60.16%, op_acc: 33.59%] [G loss: 0.919475]\n",
      "epoch:13 step:10791[D loss: 0.444491, acc: 56.25%, op_acc: 35.16%] [G loss: 0.846321]\n",
      "epoch:13 step:10792[D loss: 0.463108, acc: 46.88%, op_acc: 41.41%] [G loss: 0.891587]\n",
      "epoch:13 step:10793[D loss: 0.456246, acc: 54.69%, op_acc: 31.25%] [G loss: 0.906889]\n",
      "epoch:13 step:10794[D loss: 0.416708, acc: 64.06%, op_acc: 35.94%] [G loss: 0.882523]\n",
      "epoch:13 step:10795[D loss: 0.426442, acc: 63.28%, op_acc: 35.94%] [G loss: 0.903645]\n",
      "epoch:13 step:10796[D loss: 0.470948, acc: 53.12%, op_acc: 34.38%] [G loss: 0.825511]\n",
      "epoch:13 step:10797[D loss: 0.404445, acc: 61.72%, op_acc: 39.84%] [G loss: 0.903724]\n",
      "epoch:13 step:10798[D loss: 0.424170, acc: 60.16%, op_acc: 36.72%] [G loss: 0.847256]\n",
      "epoch:13 step:10799[D loss: 0.456198, acc: 60.16%, op_acc: 34.38%] [G loss: 0.890787]\n",
      "epoch:13 step:10800[D loss: 0.432011, acc: 57.03%, op_acc: 38.28%] [G loss: 0.836360]\n",
      "##############\n",
      "[0.8700337  0.8412126  0.81001292 0.80326403 0.78107466 0.82509295\n",
      " 0.88570208 0.82820005 0.82250058 0.83110876]\n",
      "##########\n",
      "epoch:13 step:10801[D loss: 0.477608, acc: 46.88%, op_acc: 32.81%] [G loss: 0.895699]\n",
      "epoch:13 step:10802[D loss: 0.433369, acc: 54.69%, op_acc: 37.50%] [G loss: 0.988569]\n",
      "epoch:13 step:10803[D loss: 0.499690, acc: 50.78%, op_acc: 35.16%] [G loss: 0.854481]\n",
      "epoch:13 step:10804[D loss: 0.418784, acc: 60.94%, op_acc: 37.50%] [G loss: 0.868397]\n",
      "epoch:13 step:10805[D loss: 0.451001, acc: 47.66%, op_acc: 43.75%] [G loss: 0.868411]\n",
      "epoch:13 step:10806[D loss: 0.412713, acc: 61.72%, op_acc: 45.31%] [G loss: 0.840428]\n",
      "epoch:13 step:10807[D loss: 0.437479, acc: 58.59%, op_acc: 37.50%] [G loss: 0.927103]\n",
      "epoch:13 step:10808[D loss: 0.433211, acc: 58.59%, op_acc: 34.38%] [G loss: 0.822717]\n",
      "epoch:13 step:10809[D loss: 0.437564, acc: 53.91%, op_acc: 42.97%] [G loss: 0.897485]\n",
      "epoch:13 step:10810[D loss: 0.434470, acc: 63.28%, op_acc: 34.38%] [G loss: 0.831258]\n",
      "epoch:13 step:10811[D loss: 0.444954, acc: 56.25%, op_acc: 33.59%] [G loss: 0.800097]\n",
      "epoch:13 step:10812[D loss: 0.459169, acc: 58.59%, op_acc: 32.81%] [G loss: 0.908190]\n",
      "epoch:13 step:10813[D loss: 0.427382, acc: 58.59%, op_acc: 40.62%] [G loss: 0.868354]\n",
      "epoch:13 step:10814[D loss: 0.429975, acc: 51.56%, op_acc: 35.94%] [G loss: 0.761982]\n",
      "epoch:13 step:10815[D loss: 0.421235, acc: 53.91%, op_acc: 37.50%] [G loss: 0.837131]\n",
      "epoch:13 step:10816[D loss: 0.419540, acc: 61.72%, op_acc: 37.50%] [G loss: 0.832188]\n",
      "epoch:13 step:10817[D loss: 0.416486, acc: 61.72%, op_acc: 38.28%] [G loss: 0.896082]\n",
      "epoch:13 step:10818[D loss: 0.437197, acc: 60.94%, op_acc: 33.59%] [G loss: 0.843899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10819[D loss: 0.417555, acc: 66.41%, op_acc: 34.38%] [G loss: 0.924408]\n",
      "epoch:13 step:10820[D loss: 0.431312, acc: 57.03%, op_acc: 38.28%] [G loss: 0.882151]\n",
      "epoch:13 step:10821[D loss: 0.459156, acc: 53.91%, op_acc: 33.59%] [G loss: 0.893475]\n",
      "epoch:13 step:10822[D loss: 0.436285, acc: 59.38%, op_acc: 38.28%] [G loss: 0.891840]\n",
      "epoch:13 step:10823[D loss: 0.430481, acc: 60.16%, op_acc: 39.84%] [G loss: 0.883880]\n",
      "epoch:13 step:10824[D loss: 0.428190, acc: 62.50%, op_acc: 33.59%] [G loss: 0.910925]\n",
      "epoch:13 step:10825[D loss: 0.421626, acc: 63.28%, op_acc: 42.19%] [G loss: 0.935523]\n",
      "epoch:13 step:10826[D loss: 0.445849, acc: 62.50%, op_acc: 35.16%] [G loss: 0.833090]\n",
      "epoch:13 step:10827[D loss: 0.413102, acc: 63.28%, op_acc: 34.38%] [G loss: 0.880546]\n",
      "epoch:13 step:10828[D loss: 0.419864, acc: 53.91%, op_acc: 45.31%] [G loss: 0.881950]\n",
      "epoch:13 step:10829[D loss: 0.459712, acc: 54.69%, op_acc: 32.03%] [G loss: 0.854302]\n",
      "epoch:13 step:10830[D loss: 0.451493, acc: 55.47%, op_acc: 31.25%] [G loss: 0.865094]\n",
      "epoch:13 step:10831[D loss: 0.408054, acc: 62.50%, op_acc: 39.06%] [G loss: 0.837117]\n",
      "epoch:13 step:10832[D loss: 0.412433, acc: 59.38%, op_acc: 39.84%] [G loss: 0.895851]\n",
      "epoch:13 step:10833[D loss: 0.436803, acc: 61.72%, op_acc: 35.16%] [G loss: 0.879570]\n",
      "epoch:13 step:10834[D loss: 0.435038, acc: 61.72%, op_acc: 35.94%] [G loss: 0.928748]\n",
      "epoch:13 step:10835[D loss: 0.418134, acc: 56.25%, op_acc: 45.31%] [G loss: 0.878370]\n",
      "epoch:13 step:10836[D loss: 0.417874, acc: 64.84%, op_acc: 42.97%] [G loss: 0.933100]\n",
      "epoch:13 step:10837[D loss: 0.479095, acc: 53.91%, op_acc: 34.38%] [G loss: 0.842867]\n",
      "epoch:13 step:10838[D loss: 0.463322, acc: 50.00%, op_acc: 36.72%] [G loss: 0.859518]\n",
      "epoch:13 step:10839[D loss: 0.431213, acc: 61.72%, op_acc: 39.84%] [G loss: 0.885954]\n",
      "epoch:13 step:10840[D loss: 0.446405, acc: 60.94%, op_acc: 31.25%] [G loss: 0.907132]\n",
      "epoch:13 step:10841[D loss: 0.413697, acc: 61.72%, op_acc: 41.41%] [G loss: 0.816394]\n",
      "epoch:13 step:10842[D loss: 0.427437, acc: 53.91%, op_acc: 36.72%] [G loss: 0.788466]\n",
      "epoch:13 step:10843[D loss: 0.436041, acc: 60.94%, op_acc: 39.84%] [G loss: 0.947642]\n",
      "epoch:13 step:10844[D loss: 0.434708, acc: 61.72%, op_acc: 34.38%] [G loss: 0.890636]\n",
      "epoch:13 step:10845[D loss: 0.433210, acc: 60.94%, op_acc: 33.59%] [G loss: 0.889351]\n",
      "epoch:13 step:10846[D loss: 0.445140, acc: 54.69%, op_acc: 35.94%] [G loss: 0.887481]\n",
      "epoch:13 step:10847[D loss: 0.422790, acc: 65.62%, op_acc: 33.59%] [G loss: 0.879642]\n",
      "epoch:13 step:10848[D loss: 0.449605, acc: 57.81%, op_acc: 34.38%] [G loss: 0.833476]\n",
      "epoch:13 step:10849[D loss: 0.444366, acc: 61.72%, op_acc: 35.94%] [G loss: 0.777773]\n",
      "epoch:13 step:10850[D loss: 0.429142, acc: 57.03%, op_acc: 39.84%] [G loss: 0.916396]\n",
      "##############\n",
      "[0.86620239 0.84922387 0.80412514 0.78642817 0.79165231 0.81633945\n",
      " 0.90323231 0.79884077 0.81706903 0.80888848]\n",
      "##########\n",
      "epoch:13 step:10851[D loss: 0.446632, acc: 53.12%, op_acc: 38.28%] [G loss: 0.825377]\n",
      "epoch:13 step:10852[D loss: 0.414326, acc: 57.81%, op_acc: 38.28%] [G loss: 0.897735]\n",
      "epoch:13 step:10853[D loss: 0.432219, acc: 62.50%, op_acc: 37.50%] [G loss: 0.883750]\n",
      "epoch:13 step:10854[D loss: 0.448047, acc: 59.38%, op_acc: 35.94%] [G loss: 0.911636]\n",
      "epoch:13 step:10855[D loss: 0.442670, acc: 52.34%, op_acc: 38.28%] [G loss: 0.862865]\n",
      "epoch:13 step:10856[D loss: 0.421383, acc: 60.16%, op_acc: 35.94%] [G loss: 0.882522]\n",
      "epoch:13 step:10857[D loss: 0.384706, acc: 65.62%, op_acc: 42.19%] [G loss: 0.881421]\n",
      "epoch:13 step:10858[D loss: 0.433730, acc: 63.28%, op_acc: 35.16%] [G loss: 0.847214]\n",
      "epoch:13 step:10859[D loss: 0.455766, acc: 51.56%, op_acc: 37.50%] [G loss: 0.852524]\n",
      "epoch:13 step:10860[D loss: 0.468101, acc: 53.12%, op_acc: 39.06%] [G loss: 0.844962]\n",
      "epoch:13 step:10861[D loss: 0.436934, acc: 60.16%, op_acc: 29.69%] [G loss: 0.864365]\n",
      "epoch:13 step:10862[D loss: 0.441594, acc: 61.72%, op_acc: 36.72%] [G loss: 0.835908]\n",
      "epoch:13 step:10863[D loss: 0.423547, acc: 57.03%, op_acc: 35.94%] [G loss: 0.892651]\n",
      "epoch:13 step:10864[D loss: 0.409616, acc: 64.84%, op_acc: 32.03%] [G loss: 0.959981]\n",
      "epoch:13 step:10865[D loss: 0.421357, acc: 59.38%, op_acc: 39.84%] [G loss: 0.947104]\n",
      "epoch:13 step:10866[D loss: 0.412979, acc: 59.38%, op_acc: 40.62%] [G loss: 0.965804]\n",
      "epoch:13 step:10867[D loss: 0.434799, acc: 57.81%, op_acc: 33.59%] [G loss: 0.899929]\n",
      "epoch:13 step:10868[D loss: 0.424038, acc: 58.59%, op_acc: 41.41%] [G loss: 0.937307]\n",
      "epoch:13 step:10869[D loss: 0.429606, acc: 64.84%, op_acc: 34.38%] [G loss: 0.874248]\n",
      "epoch:13 step:10870[D loss: 0.423837, acc: 56.25%, op_acc: 37.50%] [G loss: 1.016068]\n",
      "epoch:13 step:10871[D loss: 0.417040, acc: 60.94%, op_acc: 37.50%] [G loss: 0.904984]\n",
      "epoch:13 step:10872[D loss: 0.434168, acc: 63.28%, op_acc: 38.28%] [G loss: 0.917587]\n",
      "epoch:13 step:10873[D loss: 0.449324, acc: 54.69%, op_acc: 35.94%] [G loss: 0.908031]\n",
      "epoch:13 step:10874[D loss: 0.456356, acc: 51.56%, op_acc: 32.03%] [G loss: 0.797891]\n",
      "epoch:13 step:10875[D loss: 0.428528, acc: 59.38%, op_acc: 34.38%] [G loss: 0.807528]\n",
      "epoch:13 step:10876[D loss: 0.427327, acc: 56.25%, op_acc: 35.94%] [G loss: 0.828036]\n",
      "epoch:13 step:10877[D loss: 0.496220, acc: 50.78%, op_acc: 31.25%] [G loss: 0.870459]\n",
      "epoch:13 step:10878[D loss: 0.424302, acc: 58.59%, op_acc: 41.41%] [G loss: 0.869455]\n",
      "epoch:13 step:10879[D loss: 0.427555, acc: 56.25%, op_acc: 40.62%] [G loss: 0.918940]\n",
      "epoch:13 step:10880[D loss: 0.460434, acc: 56.25%, op_acc: 32.81%] [G loss: 0.866661]\n",
      "epoch:13 step:10881[D loss: 0.472400, acc: 50.78%, op_acc: 32.81%] [G loss: 0.866188]\n",
      "epoch:13 step:10882[D loss: 0.439609, acc: 57.03%, op_acc: 34.38%] [G loss: 0.887806]\n",
      "epoch:13 step:10883[D loss: 0.440708, acc: 56.25%, op_acc: 36.72%] [G loss: 0.937522]\n",
      "epoch:13 step:10884[D loss: 0.455184, acc: 51.56%, op_acc: 37.50%] [G loss: 0.849727]\n",
      "epoch:13 step:10885[D loss: 0.446068, acc: 58.59%, op_acc: 35.16%] [G loss: 0.863291]\n",
      "epoch:13 step:10886[D loss: 0.418762, acc: 61.72%, op_acc: 38.28%] [G loss: 0.885538]\n",
      "epoch:13 step:10887[D loss: 0.440245, acc: 56.25%, op_acc: 39.06%] [G loss: 0.888628]\n",
      "epoch:13 step:10888[D loss: 0.462944, acc: 53.91%, op_acc: 32.03%] [G loss: 0.866908]\n",
      "epoch:13 step:10889[D loss: 0.413544, acc: 70.31%, op_acc: 32.81%] [G loss: 0.879876]\n",
      "epoch:13 step:10890[D loss: 0.408589, acc: 68.75%, op_acc: 39.84%] [G loss: 0.935768]\n",
      "epoch:13 step:10891[D loss: 0.465239, acc: 51.56%, op_acc: 33.59%] [G loss: 0.967772]\n",
      "epoch:13 step:10892[D loss: 0.420035, acc: 59.38%, op_acc: 33.59%] [G loss: 0.846113]\n",
      "epoch:13 step:10893[D loss: 0.387232, acc: 67.97%, op_acc: 42.19%] [G loss: 0.900731]\n",
      "epoch:13 step:10894[D loss: 0.429428, acc: 58.59%, op_acc: 35.94%] [G loss: 0.801076]\n",
      "epoch:13 step:10895[D loss: 0.442168, acc: 57.03%, op_acc: 34.38%] [G loss: 0.847218]\n",
      "epoch:13 step:10896[D loss: 0.451836, acc: 57.81%, op_acc: 35.16%] [G loss: 0.904542]\n",
      "epoch:13 step:10897[D loss: 0.413256, acc: 57.81%, op_acc: 46.88%] [G loss: 0.880574]\n",
      "epoch:13 step:10898[D loss: 0.447268, acc: 54.69%, op_acc: 37.50%] [G loss: 0.831644]\n",
      "epoch:13 step:10899[D loss: 0.444583, acc: 58.59%, op_acc: 35.16%] [G loss: 0.897597]\n",
      "epoch:13 step:10900[D loss: 0.459648, acc: 56.25%, op_acc: 32.81%] [G loss: 0.890686]\n",
      "##############\n",
      "[0.86214608 0.84670904 0.80651726 0.81564354 0.77692423 0.82999149\n",
      " 0.87239115 0.8454019  0.83061428 0.83291796]\n",
      "##########\n",
      "epoch:13 step:10901[D loss: 0.417877, acc: 64.06%, op_acc: 37.50%] [G loss: 0.861481]\n",
      "epoch:13 step:10902[D loss: 0.453282, acc: 57.03%, op_acc: 36.72%] [G loss: 0.877413]\n",
      "epoch:13 step:10903[D loss: 0.445192, acc: 53.91%, op_acc: 37.50%] [G loss: 0.886680]\n",
      "epoch:13 step:10904[D loss: 0.492337, acc: 43.75%, op_acc: 33.59%] [G loss: 0.856969]\n",
      "epoch:13 step:10905[D loss: 0.429127, acc: 58.59%, op_acc: 34.38%] [G loss: 0.885460]\n",
      "epoch:13 step:10906[D loss: 0.433792, acc: 60.16%, op_acc: 32.03%] [G loss: 0.906643]\n",
      "epoch:13 step:10907[D loss: 0.442471, acc: 59.38%, op_acc: 36.72%] [G loss: 0.916008]\n",
      "epoch:13 step:10908[D loss: 0.419003, acc: 61.72%, op_acc: 35.94%] [G loss: 0.903197]\n",
      "epoch:13 step:10909[D loss: 0.392953, acc: 73.44%, op_acc: 40.62%] [G loss: 0.904506]\n",
      "epoch:13 step:10910[D loss: 0.431753, acc: 58.59%, op_acc: 39.84%] [G loss: 0.892619]\n",
      "epoch:13 step:10911[D loss: 0.435099, acc: 53.12%, op_acc: 39.84%] [G loss: 0.858445]\n",
      "epoch:13 step:10912[D loss: 0.446687, acc: 53.12%, op_acc: 41.41%] [G loss: 0.808433]\n",
      "epoch:13 step:10913[D loss: 0.415153, acc: 60.16%, op_acc: 39.06%] [G loss: 0.929876]\n",
      "epoch:13 step:10914[D loss: 0.405481, acc: 58.59%, op_acc: 42.19%] [G loss: 0.929640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10915[D loss: 0.432075, acc: 66.41%, op_acc: 35.94%] [G loss: 0.890501]\n",
      "epoch:13 step:10916[D loss: 0.449670, acc: 54.69%, op_acc: 32.03%] [G loss: 0.899452]\n",
      "epoch:13 step:10917[D loss: 0.438582, acc: 51.56%, op_acc: 39.06%] [G loss: 0.813457]\n",
      "epoch:13 step:10918[D loss: 0.420182, acc: 62.50%, op_acc: 42.19%] [G loss: 0.859574]\n",
      "epoch:13 step:10919[D loss: 0.454484, acc: 54.69%, op_acc: 32.81%] [G loss: 0.862832]\n",
      "epoch:13 step:10920[D loss: 0.437895, acc: 57.03%, op_acc: 39.84%] [G loss: 0.877762]\n",
      "epoch:13 step:10921[D loss: 0.435773, acc: 53.91%, op_acc: 35.16%] [G loss: 0.879594]\n",
      "epoch:13 step:10922[D loss: 0.407619, acc: 58.59%, op_acc: 40.62%] [G loss: 0.876283]\n",
      "epoch:13 step:10923[D loss: 0.415719, acc: 64.84%, op_acc: 37.50%] [G loss: 0.925581]\n",
      "epoch:13 step:10924[D loss: 0.476294, acc: 53.91%, op_acc: 29.69%] [G loss: 0.911161]\n",
      "epoch:13 step:10925[D loss: 0.454888, acc: 57.81%, op_acc: 33.59%] [G loss: 0.802928]\n",
      "epoch:13 step:10926[D loss: 0.454794, acc: 53.91%, op_acc: 35.16%] [G loss: 0.922274]\n",
      "epoch:13 step:10927[D loss: 0.412415, acc: 57.81%, op_acc: 37.50%] [G loss: 0.857646]\n",
      "epoch:13 step:10928[D loss: 0.426384, acc: 57.03%, op_acc: 38.28%] [G loss: 0.853114]\n",
      "epoch:13 step:10929[D loss: 0.410280, acc: 62.50%, op_acc: 39.84%] [G loss: 0.876830]\n",
      "epoch:13 step:10930[D loss: 0.443833, acc: 57.03%, op_acc: 32.03%] [G loss: 0.903112]\n",
      "epoch:13 step:10931[D loss: 0.435757, acc: 56.25%, op_acc: 44.53%] [G loss: 0.987818]\n",
      "epoch:13 step:10932[D loss: 0.427621, acc: 64.06%, op_acc: 39.06%] [G loss: 0.860282]\n",
      "epoch:13 step:10933[D loss: 0.430571, acc: 58.59%, op_acc: 35.94%] [G loss: 0.846889]\n",
      "epoch:13 step:10934[D loss: 0.435216, acc: 57.03%, op_acc: 34.38%] [G loss: 0.908085]\n",
      "epoch:14 step:10935[D loss: 0.428689, acc: 57.81%, op_acc: 41.41%] [G loss: 0.928133]\n",
      "epoch:14 step:10936[D loss: 0.395989, acc: 71.09%, op_acc: 42.19%] [G loss: 0.927988]\n",
      "epoch:14 step:10937[D loss: 0.409320, acc: 67.97%, op_acc: 37.50%] [G loss: 0.894588]\n",
      "epoch:14 step:10938[D loss: 0.423534, acc: 55.47%, op_acc: 41.41%] [G loss: 0.822272]\n",
      "epoch:14 step:10939[D loss: 0.428309, acc: 60.94%, op_acc: 35.16%] [G loss: 0.847507]\n",
      "epoch:14 step:10940[D loss: 0.428579, acc: 57.81%, op_acc: 37.50%] [G loss: 0.885898]\n",
      "epoch:14 step:10941[D loss: 0.411298, acc: 57.03%, op_acc: 42.97%] [G loss: 0.923796]\n",
      "epoch:14 step:10942[D loss: 0.439834, acc: 52.34%, op_acc: 37.50%] [G loss: 0.905736]\n",
      "epoch:14 step:10943[D loss: 0.403755, acc: 66.41%, op_acc: 40.62%] [G loss: 0.880959]\n",
      "epoch:14 step:10944[D loss: 0.458985, acc: 60.94%, op_acc: 32.81%] [G loss: 0.841036]\n",
      "epoch:14 step:10945[D loss: 0.467724, acc: 51.56%, op_acc: 31.25%] [G loss: 0.898429]\n",
      "epoch:14 step:10946[D loss: 0.443918, acc: 61.72%, op_acc: 29.69%] [G loss: 0.824698]\n",
      "epoch:14 step:10947[D loss: 0.442573, acc: 57.81%, op_acc: 36.72%] [G loss: 0.822118]\n",
      "epoch:14 step:10948[D loss: 0.420348, acc: 67.97%, op_acc: 28.12%] [G loss: 0.881254]\n",
      "epoch:14 step:10949[D loss: 0.409715, acc: 62.50%, op_acc: 38.28%] [G loss: 0.900743]\n",
      "epoch:14 step:10950[D loss: 0.395510, acc: 63.28%, op_acc: 42.97%] [G loss: 0.886795]\n",
      "##############\n",
      "[0.8427788  0.86951852 0.83184755 0.81539705 0.80229493 0.8296575\n",
      " 0.8743636  0.82790913 0.81297227 0.83515972]\n",
      "##########\n",
      "epoch:14 step:10951[D loss: 0.411803, acc: 57.81%, op_acc: 37.50%] [G loss: 0.924069]\n",
      "epoch:14 step:10952[D loss: 0.443207, acc: 60.94%, op_acc: 34.38%] [G loss: 0.968318]\n",
      "epoch:14 step:10953[D loss: 0.412651, acc: 55.47%, op_acc: 39.84%] [G loss: 0.787698]\n",
      "epoch:14 step:10954[D loss: 0.429546, acc: 60.16%, op_acc: 33.59%] [G loss: 0.860907]\n",
      "epoch:14 step:10955[D loss: 0.466215, acc: 50.00%, op_acc: 37.50%] [G loss: 0.821697]\n",
      "epoch:14 step:10956[D loss: 0.418679, acc: 64.84%, op_acc: 42.19%] [G loss: 0.830958]\n",
      "epoch:14 step:10957[D loss: 0.435963, acc: 60.16%, op_acc: 38.28%] [G loss: 0.840619]\n",
      "epoch:14 step:10958[D loss: 0.500104, acc: 50.78%, op_acc: 30.47%] [G loss: 0.818915]\n",
      "epoch:14 step:10959[D loss: 0.450317, acc: 50.78%, op_acc: 40.62%] [G loss: 0.852406]\n",
      "epoch:14 step:10960[D loss: 0.401244, acc: 65.62%, op_acc: 40.62%] [G loss: 0.926050]\n",
      "epoch:14 step:10961[D loss: 0.438707, acc: 59.38%, op_acc: 38.28%] [G loss: 0.892325]\n",
      "epoch:14 step:10962[D loss: 0.458734, acc: 49.22%, op_acc: 37.50%] [G loss: 0.840835]\n",
      "epoch:14 step:10963[D loss: 0.425718, acc: 58.59%, op_acc: 36.72%] [G loss: 0.831984]\n",
      "epoch:14 step:10964[D loss: 0.390309, acc: 63.28%, op_acc: 36.72%] [G loss: 0.801624]\n",
      "epoch:14 step:10965[D loss: 0.444444, acc: 55.47%, op_acc: 33.59%] [G loss: 0.864749]\n",
      "epoch:14 step:10966[D loss: 0.461535, acc: 56.25%, op_acc: 35.94%] [G loss: 0.861748]\n",
      "epoch:14 step:10967[D loss: 0.414005, acc: 61.72%, op_acc: 39.84%] [G loss: 0.913582]\n",
      "epoch:14 step:10968[D loss: 0.417606, acc: 60.16%, op_acc: 42.19%] [G loss: 0.838967]\n",
      "epoch:14 step:10969[D loss: 0.423170, acc: 60.16%, op_acc: 34.38%] [G loss: 0.837107]\n",
      "epoch:14 step:10970[D loss: 0.429978, acc: 53.12%, op_acc: 39.06%] [G loss: 0.985862]\n",
      "epoch:14 step:10971[D loss: 0.423178, acc: 53.12%, op_acc: 42.19%] [G loss: 0.881519]\n",
      "epoch:14 step:10972[D loss: 0.430760, acc: 58.59%, op_acc: 39.84%] [G loss: 0.912237]\n",
      "epoch:14 step:10973[D loss: 0.397723, acc: 67.97%, op_acc: 41.41%] [G loss: 0.908134]\n",
      "epoch:14 step:10974[D loss: 0.462020, acc: 51.56%, op_acc: 32.81%] [G loss: 0.847357]\n",
      "epoch:14 step:10975[D loss: 0.418366, acc: 57.81%, op_acc: 35.94%] [G loss: 0.838817]\n",
      "epoch:14 step:10976[D loss: 0.416491, acc: 59.38%, op_acc: 39.84%] [G loss: 0.850243]\n",
      "epoch:14 step:10977[D loss: 0.439689, acc: 62.50%, op_acc: 33.59%] [G loss: 0.926550]\n",
      "epoch:14 step:10978[D loss: 0.447461, acc: 53.12%, op_acc: 36.72%] [G loss: 0.914601]\n",
      "epoch:14 step:10979[D loss: 0.398862, acc: 73.44%, op_acc: 41.41%] [G loss: 0.805362]\n",
      "epoch:14 step:10980[D loss: 0.432332, acc: 60.16%, op_acc: 35.16%] [G loss: 0.905951]\n",
      "epoch:14 step:10981[D loss: 0.478338, acc: 51.56%, op_acc: 30.47%] [G loss: 0.831767]\n",
      "epoch:14 step:10982[D loss: 0.462980, acc: 56.25%, op_acc: 33.59%] [G loss: 0.868060]\n",
      "epoch:14 step:10983[D loss: 0.425698, acc: 61.72%, op_acc: 34.38%] [G loss: 0.887650]\n",
      "epoch:14 step:10984[D loss: 0.454821, acc: 56.25%, op_acc: 32.03%] [G loss: 0.789796]\n",
      "epoch:14 step:10985[D loss: 0.429793, acc: 65.62%, op_acc: 32.03%] [G loss: 0.817330]\n",
      "epoch:14 step:10986[D loss: 0.438237, acc: 56.25%, op_acc: 36.72%] [G loss: 0.915958]\n",
      "epoch:14 step:10987[D loss: 0.448129, acc: 59.38%, op_acc: 33.59%] [G loss: 0.894362]\n",
      "epoch:14 step:10988[D loss: 0.449242, acc: 64.06%, op_acc: 35.94%] [G loss: 0.865038]\n",
      "epoch:14 step:10989[D loss: 0.429369, acc: 56.25%, op_acc: 35.16%] [G loss: 0.856243]\n",
      "epoch:14 step:10990[D loss: 0.439298, acc: 57.81%, op_acc: 32.81%] [G loss: 0.825136]\n",
      "epoch:14 step:10991[D loss: 0.424227, acc: 67.19%, op_acc: 30.47%] [G loss: 0.940536]\n",
      "epoch:14 step:10992[D loss: 0.407145, acc: 56.25%, op_acc: 40.62%] [G loss: 0.851979]\n",
      "epoch:14 step:10993[D loss: 0.419664, acc: 58.59%, op_acc: 36.72%] [G loss: 0.874442]\n",
      "epoch:14 step:10994[D loss: 0.450775, acc: 53.91%, op_acc: 36.72%] [G loss: 0.840213]\n",
      "epoch:14 step:10995[D loss: 0.424747, acc: 63.28%, op_acc: 37.50%] [G loss: 0.852665]\n",
      "epoch:14 step:10996[D loss: 0.413968, acc: 61.72%, op_acc: 35.94%] [G loss: 0.921259]\n",
      "epoch:14 step:10997[D loss: 0.453363, acc: 52.34%, op_acc: 34.38%] [G loss: 0.883784]\n",
      "epoch:14 step:10998[D loss: 0.431304, acc: 60.16%, op_acc: 34.38%] [G loss: 0.850271]\n",
      "epoch:14 step:10999[D loss: 0.440498, acc: 59.38%, op_acc: 35.16%] [G loss: 0.917413]\n",
      "epoch:14 step:11000[D loss: 0.439283, acc: 57.81%, op_acc: 39.84%] [G loss: 0.869040]\n",
      "##############\n",
      "[0.87184945 0.85512117 0.80509483 0.80131605 0.7820666  0.84556461\n",
      " 0.87736428 0.82247251 0.80838267 0.84976848]\n",
      "##########\n",
      "epoch:14 step:11001[D loss: 0.420113, acc: 63.28%, op_acc: 32.81%] [G loss: 0.894775]\n",
      "epoch:14 step:11002[D loss: 0.431786, acc: 63.28%, op_acc: 34.38%] [G loss: 0.863702]\n",
      "epoch:14 step:11003[D loss: 0.380199, acc: 66.41%, op_acc: 42.97%] [G loss: 0.861126]\n",
      "epoch:14 step:11004[D loss: 0.428430, acc: 58.59%, op_acc: 39.06%] [G loss: 0.819786]\n",
      "epoch:14 step:11005[D loss: 0.453297, acc: 59.38%, op_acc: 33.59%] [G loss: 0.824250]\n",
      "epoch:14 step:11006[D loss: 0.406770, acc: 63.28%, op_acc: 39.06%] [G loss: 0.875778]\n",
      "epoch:14 step:11007[D loss: 0.435797, acc: 59.38%, op_acc: 35.16%] [G loss: 0.893020]\n",
      "epoch:14 step:11008[D loss: 0.419508, acc: 62.50%, op_acc: 44.53%] [G loss: 0.750599]\n",
      "epoch:14 step:11009[D loss: 0.440744, acc: 57.81%, op_acc: 36.72%] [G loss: 0.813940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11010[D loss: 0.418873, acc: 66.41%, op_acc: 39.06%] [G loss: 0.867389]\n",
      "epoch:14 step:11011[D loss: 0.449406, acc: 55.47%, op_acc: 33.59%] [G loss: 0.843048]\n",
      "epoch:14 step:11012[D loss: 0.431933, acc: 64.06%, op_acc: 33.59%] [G loss: 0.897715]\n",
      "epoch:14 step:11013[D loss: 0.431465, acc: 64.06%, op_acc: 35.16%] [G loss: 0.829716]\n",
      "epoch:14 step:11014[D loss: 0.456883, acc: 60.94%, op_acc: 32.81%] [G loss: 0.844659]\n",
      "epoch:14 step:11015[D loss: 0.441821, acc: 60.94%, op_acc: 32.81%] [G loss: 0.850823]\n",
      "epoch:14 step:11016[D loss: 0.424011, acc: 60.16%, op_acc: 36.72%] [G loss: 0.843918]\n",
      "epoch:14 step:11017[D loss: 0.469060, acc: 52.34%, op_acc: 32.03%] [G loss: 0.838841]\n",
      "epoch:14 step:11018[D loss: 0.417929, acc: 60.94%, op_acc: 38.28%] [G loss: 0.886576]\n",
      "epoch:14 step:11019[D loss: 0.450684, acc: 57.81%, op_acc: 32.03%] [G loss: 0.871431]\n",
      "epoch:14 step:11020[D loss: 0.412382, acc: 64.06%, op_acc: 39.84%] [G loss: 0.878545]\n",
      "epoch:14 step:11021[D loss: 0.420740, acc: 61.72%, op_acc: 34.38%] [G loss: 0.969738]\n",
      "epoch:14 step:11022[D loss: 0.422879, acc: 60.94%, op_acc: 35.94%] [G loss: 0.903720]\n",
      "epoch:14 step:11023[D loss: 0.485836, acc: 49.22%, op_acc: 39.06%] [G loss: 0.855991]\n",
      "epoch:14 step:11024[D loss: 0.425649, acc: 57.03%, op_acc: 36.72%] [G loss: 0.813666]\n",
      "epoch:14 step:11025[D loss: 0.460863, acc: 49.22%, op_acc: 32.81%] [G loss: 0.834832]\n",
      "epoch:14 step:11026[D loss: 0.451281, acc: 57.03%, op_acc: 33.59%] [G loss: 0.822717]\n",
      "epoch:14 step:11027[D loss: 0.398249, acc: 64.06%, op_acc: 40.62%] [G loss: 0.877115]\n",
      "epoch:14 step:11028[D loss: 0.429588, acc: 58.59%, op_acc: 35.94%] [G loss: 0.878879]\n",
      "epoch:14 step:11029[D loss: 0.424885, acc: 60.94%, op_acc: 41.41%] [G loss: 0.895532]\n",
      "epoch:14 step:11030[D loss: 0.437321, acc: 60.94%, op_acc: 34.38%] [G loss: 0.880183]\n",
      "epoch:14 step:11031[D loss: 0.452457, acc: 59.38%, op_acc: 31.25%] [G loss: 0.887655]\n",
      "epoch:14 step:11032[D loss: 0.457655, acc: 61.72%, op_acc: 32.81%] [G loss: 0.856022]\n",
      "epoch:14 step:11033[D loss: 0.427617, acc: 58.59%, op_acc: 41.41%] [G loss: 0.967674]\n",
      "epoch:14 step:11034[D loss: 0.436334, acc: 60.16%, op_acc: 37.50%] [G loss: 0.894803]\n",
      "epoch:14 step:11035[D loss: 0.419966, acc: 60.16%, op_acc: 38.28%] [G loss: 0.908397]\n",
      "epoch:14 step:11036[D loss: 0.414002, acc: 64.06%, op_acc: 39.84%] [G loss: 0.970476]\n",
      "epoch:14 step:11037[D loss: 0.426855, acc: 61.72%, op_acc: 34.38%] [G loss: 0.920577]\n",
      "epoch:14 step:11038[D loss: 0.447740, acc: 51.56%, op_acc: 39.06%] [G loss: 0.870494]\n",
      "epoch:14 step:11039[D loss: 0.437614, acc: 60.16%, op_acc: 38.28%] [G loss: 0.837226]\n",
      "epoch:14 step:11040[D loss: 0.431364, acc: 65.62%, op_acc: 35.94%] [G loss: 0.879694]\n",
      "epoch:14 step:11041[D loss: 0.429351, acc: 67.19%, op_acc: 35.94%] [G loss: 0.907167]\n",
      "epoch:14 step:11042[D loss: 0.474871, acc: 59.38%, op_acc: 32.03%] [G loss: 0.878367]\n",
      "epoch:14 step:11043[D loss: 0.423527, acc: 61.72%, op_acc: 39.06%] [G loss: 0.906862]\n",
      "epoch:14 step:11044[D loss: 0.382203, acc: 68.75%, op_acc: 44.53%] [G loss: 0.906366]\n",
      "epoch:14 step:11045[D loss: 0.440415, acc: 63.28%, op_acc: 32.03%] [G loss: 0.903451]\n",
      "epoch:14 step:11046[D loss: 0.433471, acc: 53.12%, op_acc: 42.19%] [G loss: 0.890493]\n",
      "epoch:14 step:11047[D loss: 0.443539, acc: 58.59%, op_acc: 29.69%] [G loss: 0.885520]\n",
      "epoch:14 step:11048[D loss: 0.415124, acc: 58.59%, op_acc: 37.50%] [G loss: 0.877673]\n",
      "epoch:14 step:11049[D loss: 0.418908, acc: 59.38%, op_acc: 36.72%] [G loss: 0.810100]\n",
      "epoch:14 step:11050[D loss: 0.460381, acc: 60.94%, op_acc: 29.69%] [G loss: 0.918984]\n",
      "##############\n",
      "[0.84386723 0.84144083 0.78938695 0.8081775  0.79457113 0.8095305\n",
      " 0.88063205 0.8112416  0.81984616 0.8514032 ]\n",
      "##########\n",
      "epoch:14 step:11051[D loss: 0.443971, acc: 59.38%, op_acc: 35.94%] [G loss: 0.897419]\n",
      "epoch:14 step:11052[D loss: 0.443380, acc: 59.38%, op_acc: 33.59%] [G loss: 0.808318]\n",
      "epoch:14 step:11053[D loss: 0.420490, acc: 61.72%, op_acc: 37.50%] [G loss: 0.800070]\n",
      "epoch:14 step:11054[D loss: 0.439960, acc: 64.84%, op_acc: 33.59%] [G loss: 0.906811]\n",
      "epoch:14 step:11055[D loss: 0.451762, acc: 55.47%, op_acc: 37.50%] [G loss: 0.891155]\n",
      "epoch:14 step:11056[D loss: 0.435530, acc: 59.38%, op_acc: 37.50%] [G loss: 0.904414]\n",
      "epoch:14 step:11057[D loss: 0.425422, acc: 64.84%, op_acc: 33.59%] [G loss: 0.867086]\n",
      "epoch:14 step:11058[D loss: 0.439818, acc: 57.03%, op_acc: 34.38%] [G loss: 0.817221]\n",
      "epoch:14 step:11059[D loss: 0.447692, acc: 62.50%, op_acc: 33.59%] [G loss: 0.902732]\n",
      "epoch:14 step:11060[D loss: 0.424342, acc: 58.59%, op_acc: 37.50%] [G loss: 0.860384]\n",
      "epoch:14 step:11061[D loss: 0.424313, acc: 63.28%, op_acc: 34.38%] [G loss: 0.893518]\n",
      "epoch:14 step:11062[D loss: 0.412607, acc: 64.84%, op_acc: 38.28%] [G loss: 0.930216]\n",
      "epoch:14 step:11063[D loss: 0.456646, acc: 52.34%, op_acc: 34.38%] [G loss: 0.894454]\n",
      "epoch:14 step:11064[D loss: 0.426597, acc: 57.81%, op_acc: 37.50%] [G loss: 0.916987]\n",
      "epoch:14 step:11065[D loss: 0.423948, acc: 65.62%, op_acc: 35.16%] [G loss: 0.854913]\n",
      "epoch:14 step:11066[D loss: 0.411014, acc: 61.72%, op_acc: 38.28%] [G loss: 0.850239]\n",
      "epoch:14 step:11067[D loss: 0.440729, acc: 64.06%, op_acc: 36.72%] [G loss: 0.841812]\n",
      "epoch:14 step:11068[D loss: 0.422010, acc: 61.72%, op_acc: 39.84%] [G loss: 0.867959]\n",
      "epoch:14 step:11069[D loss: 0.420897, acc: 67.97%, op_acc: 42.97%] [G loss: 0.886745]\n",
      "epoch:14 step:11070[D loss: 0.412542, acc: 66.41%, op_acc: 40.62%] [G loss: 0.832281]\n",
      "epoch:14 step:11071[D loss: 0.448602, acc: 51.56%, op_acc: 35.94%] [G loss: 0.817969]\n",
      "epoch:14 step:11072[D loss: 0.438087, acc: 53.91%, op_acc: 35.94%] [G loss: 0.871002]\n",
      "epoch:14 step:11073[D loss: 0.410048, acc: 62.50%, op_acc: 36.72%] [G loss: 0.843579]\n",
      "epoch:14 step:11074[D loss: 0.459758, acc: 53.91%, op_acc: 33.59%] [G loss: 0.877744]\n",
      "epoch:14 step:11075[D loss: 0.451891, acc: 49.22%, op_acc: 31.25%] [G loss: 0.911553]\n",
      "epoch:14 step:11076[D loss: 0.428960, acc: 58.59%, op_acc: 39.84%] [G loss: 0.903955]\n",
      "epoch:14 step:11077[D loss: 0.450566, acc: 53.91%, op_acc: 31.25%] [G loss: 0.869844]\n",
      "epoch:14 step:11078[D loss: 0.446826, acc: 57.81%, op_acc: 33.59%] [G loss: 0.872011]\n",
      "epoch:14 step:11079[D loss: 0.453378, acc: 58.59%, op_acc: 35.16%] [G loss: 0.904157]\n",
      "epoch:14 step:11080[D loss: 0.458726, acc: 53.12%, op_acc: 34.38%] [G loss: 0.859446]\n",
      "epoch:14 step:11081[D loss: 0.419188, acc: 62.50%, op_acc: 35.94%] [G loss: 0.843644]\n",
      "epoch:14 step:11082[D loss: 0.421575, acc: 60.94%, op_acc: 40.62%] [G loss: 0.883825]\n",
      "epoch:14 step:11083[D loss: 0.428116, acc: 48.44%, op_acc: 35.16%] [G loss: 0.821834]\n",
      "epoch:14 step:11084[D loss: 0.414735, acc: 62.50%, op_acc: 42.19%] [G loss: 0.919755]\n",
      "epoch:14 step:11085[D loss: 0.431239, acc: 53.91%, op_acc: 35.16%] [G loss: 0.817834]\n",
      "epoch:14 step:11086[D loss: 0.435653, acc: 54.69%, op_acc: 36.72%] [G loss: 0.876664]\n",
      "epoch:14 step:11087[D loss: 0.459532, acc: 51.56%, op_acc: 35.16%] [G loss: 0.837539]\n",
      "epoch:14 step:11088[D loss: 0.457183, acc: 58.59%, op_acc: 32.03%] [G loss: 0.847262]\n",
      "epoch:14 step:11089[D loss: 0.446871, acc: 52.34%, op_acc: 34.38%] [G loss: 0.878311]\n",
      "epoch:14 step:11090[D loss: 0.437899, acc: 57.03%, op_acc: 34.38%] [G loss: 0.939500]\n",
      "epoch:14 step:11091[D loss: 0.416016, acc: 68.75%, op_acc: 39.06%] [G loss: 0.893924]\n",
      "epoch:14 step:11092[D loss: 0.408453, acc: 60.16%, op_acc: 42.97%] [G loss: 0.913911]\n",
      "epoch:14 step:11093[D loss: 0.439269, acc: 54.69%, op_acc: 33.59%] [G loss: 0.866076]\n",
      "epoch:14 step:11094[D loss: 0.439421, acc: 60.16%, op_acc: 27.34%] [G loss: 0.875086]\n",
      "epoch:14 step:11095[D loss: 0.435621, acc: 60.94%, op_acc: 41.41%] [G loss: 0.816649]\n",
      "epoch:14 step:11096[D loss: 0.449426, acc: 55.47%, op_acc: 35.16%] [G loss: 0.865775]\n",
      "epoch:14 step:11097[D loss: 0.453249, acc: 51.56%, op_acc: 32.81%] [G loss: 0.931306]\n",
      "epoch:14 step:11098[D loss: 0.450105, acc: 59.38%, op_acc: 32.81%] [G loss: 0.903305]\n",
      "epoch:14 step:11099[D loss: 0.427494, acc: 60.16%, op_acc: 39.84%] [G loss: 0.912995]\n",
      "epoch:14 step:11100[D loss: 0.458141, acc: 57.81%, op_acc: 31.25%] [G loss: 0.896930]\n",
      "##############\n",
      "[0.85553705 0.84301164 0.8313773  0.81123523 0.78704851 0.82796192\n",
      " 0.89509975 0.81673474 0.80964684 0.82699786]\n",
      "##########\n",
      "epoch:14 step:11101[D loss: 0.413410, acc: 65.62%, op_acc: 39.06%] [G loss: 0.892148]\n",
      "epoch:14 step:11102[D loss: 0.452643, acc: 52.34%, op_acc: 33.59%] [G loss: 0.876763]\n",
      "epoch:14 step:11103[D loss: 0.427509, acc: 57.81%, op_acc: 35.94%] [G loss: 0.876073]\n",
      "epoch:14 step:11104[D loss: 0.424314, acc: 57.81%, op_acc: 35.94%] [G loss: 0.906350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11105[D loss: 0.466414, acc: 54.69%, op_acc: 34.38%] [G loss: 0.832146]\n",
      "epoch:14 step:11106[D loss: 0.418193, acc: 64.84%, op_acc: 41.41%] [G loss: 0.901930]\n",
      "epoch:14 step:11107[D loss: 0.448873, acc: 55.47%, op_acc: 35.16%] [G loss: 0.788115]\n",
      "epoch:14 step:11108[D loss: 0.453869, acc: 58.59%, op_acc: 35.94%] [G loss: 0.802567]\n",
      "epoch:14 step:11109[D loss: 0.432331, acc: 55.47%, op_acc: 38.28%] [G loss: 0.807969]\n",
      "epoch:14 step:11110[D loss: 0.455545, acc: 52.34%, op_acc: 32.81%] [G loss: 0.843380]\n",
      "epoch:14 step:11111[D loss: 0.409079, acc: 63.28%, op_acc: 36.72%] [G loss: 0.872970]\n",
      "epoch:14 step:11112[D loss: 0.432585, acc: 62.50%, op_acc: 36.72%] [G loss: 0.838311]\n",
      "epoch:14 step:11113[D loss: 0.428496, acc: 60.16%, op_acc: 39.06%] [G loss: 0.902192]\n",
      "epoch:14 step:11114[D loss: 0.435728, acc: 58.59%, op_acc: 36.72%] [G loss: 0.914137]\n",
      "epoch:14 step:11115[D loss: 0.408785, acc: 62.50%, op_acc: 37.50%] [G loss: 0.872424]\n",
      "epoch:14 step:11116[D loss: 0.418833, acc: 65.62%, op_acc: 39.06%] [G loss: 0.895171]\n",
      "epoch:14 step:11117[D loss: 0.400577, acc: 66.41%, op_acc: 40.62%] [G loss: 0.857679]\n",
      "epoch:14 step:11118[D loss: 0.420599, acc: 65.62%, op_acc: 40.62%] [G loss: 0.962583]\n",
      "epoch:14 step:11119[D loss: 0.424199, acc: 64.06%, op_acc: 35.94%] [G loss: 0.962315]\n",
      "epoch:14 step:11120[D loss: 0.429006, acc: 61.72%, op_acc: 36.72%] [G loss: 0.808609]\n",
      "epoch:14 step:11121[D loss: 0.438047, acc: 54.69%, op_acc: 39.84%] [G loss: 0.932212]\n",
      "epoch:14 step:11122[D loss: 0.407719, acc: 58.59%, op_acc: 39.06%] [G loss: 0.919190]\n",
      "epoch:14 step:11123[D loss: 0.430133, acc: 65.62%, op_acc: 32.81%] [G loss: 0.909950]\n",
      "epoch:14 step:11124[D loss: 0.428857, acc: 63.28%, op_acc: 38.28%] [G loss: 0.857193]\n",
      "epoch:14 step:11125[D loss: 0.419861, acc: 62.50%, op_acc: 40.62%] [G loss: 0.917511]\n",
      "epoch:14 step:11126[D loss: 0.470843, acc: 50.78%, op_acc: 33.59%] [G loss: 0.849879]\n",
      "epoch:14 step:11127[D loss: 0.430178, acc: 68.75%, op_acc: 31.25%] [G loss: 0.914010]\n",
      "epoch:14 step:11128[D loss: 0.476343, acc: 42.97%, op_acc: 39.06%] [G loss: 0.791454]\n",
      "epoch:14 step:11129[D loss: 0.432199, acc: 53.12%, op_acc: 39.84%] [G loss: 0.819436]\n",
      "epoch:14 step:11130[D loss: 0.470848, acc: 56.25%, op_acc: 31.25%] [G loss: 0.868977]\n",
      "epoch:14 step:11131[D loss: 0.464595, acc: 57.03%, op_acc: 37.50%] [G loss: 0.839835]\n",
      "epoch:14 step:11132[D loss: 0.431875, acc: 56.25%, op_acc: 42.19%] [G loss: 0.882018]\n",
      "epoch:14 step:11133[D loss: 0.463987, acc: 54.69%, op_acc: 32.81%] [G loss: 0.885644]\n",
      "epoch:14 step:11134[D loss: 0.436295, acc: 57.03%, op_acc: 35.94%] [G loss: 0.908546]\n",
      "epoch:14 step:11135[D loss: 0.444848, acc: 53.91%, op_acc: 38.28%] [G loss: 0.832856]\n",
      "epoch:14 step:11136[D loss: 0.433610, acc: 60.94%, op_acc: 35.16%] [G loss: 0.881651]\n",
      "epoch:14 step:11137[D loss: 0.434193, acc: 65.62%, op_acc: 32.03%] [G loss: 0.875996]\n",
      "epoch:14 step:11138[D loss: 0.436397, acc: 59.38%, op_acc: 32.03%] [G loss: 0.920974]\n",
      "epoch:14 step:11139[D loss: 0.442286, acc: 60.16%, op_acc: 37.50%] [G loss: 0.884256]\n",
      "epoch:14 step:11140[D loss: 0.425143, acc: 60.16%, op_acc: 37.50%] [G loss: 0.860139]\n",
      "epoch:14 step:11141[D loss: 0.403936, acc: 60.16%, op_acc: 43.75%] [G loss: 0.896646]\n",
      "epoch:14 step:11142[D loss: 0.434346, acc: 59.38%, op_acc: 35.16%] [G loss: 0.897740]\n",
      "epoch:14 step:11143[D loss: 0.436248, acc: 57.81%, op_acc: 32.03%] [G loss: 0.881847]\n",
      "epoch:14 step:11144[D loss: 0.466191, acc: 53.91%, op_acc: 32.03%] [G loss: 0.851645]\n",
      "epoch:14 step:11145[D loss: 0.410491, acc: 64.06%, op_acc: 43.75%] [G loss: 0.914217]\n",
      "epoch:14 step:11146[D loss: 0.446692, acc: 57.81%, op_acc: 33.59%] [G loss: 0.847239]\n",
      "epoch:14 step:11147[D loss: 0.443621, acc: 46.88%, op_acc: 41.41%] [G loss: 0.934943]\n",
      "epoch:14 step:11148[D loss: 0.451023, acc: 56.25%, op_acc: 35.94%] [G loss: 0.906774]\n",
      "epoch:14 step:11149[D loss: 0.467003, acc: 52.34%, op_acc: 29.69%] [G loss: 0.893858]\n",
      "epoch:14 step:11150[D loss: 0.445911, acc: 59.38%, op_acc: 35.16%] [G loss: 0.855137]\n",
      "##############\n",
      "[0.87744726 0.86044781 0.81969277 0.78498247 0.79258783 0.84335856\n",
      " 0.89037407 0.83452356 0.81034019 0.81631923]\n",
      "##########\n",
      "epoch:14 step:11151[D loss: 0.427586, acc: 58.59%, op_acc: 37.50%] [G loss: 0.860881]\n",
      "epoch:14 step:11152[D loss: 0.410275, acc: 59.38%, op_acc: 41.41%] [G loss: 0.843105]\n",
      "epoch:14 step:11153[D loss: 0.427569, acc: 57.03%, op_acc: 42.19%] [G loss: 0.874665]\n",
      "epoch:14 step:11154[D loss: 0.438772, acc: 63.28%, op_acc: 33.59%] [G loss: 0.913437]\n",
      "epoch:14 step:11155[D loss: 0.417814, acc: 61.72%, op_acc: 37.50%] [G loss: 0.889269]\n",
      "epoch:14 step:11156[D loss: 0.435627, acc: 62.50%, op_acc: 39.06%] [G loss: 0.818349]\n",
      "epoch:14 step:11157[D loss: 0.407070, acc: 67.19%, op_acc: 35.94%] [G loss: 0.860149]\n",
      "epoch:14 step:11158[D loss: 0.434853, acc: 55.47%, op_acc: 35.94%] [G loss: 0.904723]\n",
      "epoch:14 step:11159[D loss: 0.438082, acc: 62.50%, op_acc: 35.94%] [G loss: 0.865833]\n",
      "epoch:14 step:11160[D loss: 0.429893, acc: 60.94%, op_acc: 39.84%] [G loss: 0.902785]\n",
      "epoch:14 step:11161[D loss: 0.425725, acc: 63.28%, op_acc: 33.59%] [G loss: 0.897269]\n",
      "epoch:14 step:11162[D loss: 0.416060, acc: 67.19%, op_acc: 37.50%] [G loss: 0.793173]\n",
      "epoch:14 step:11163[D loss: 0.459504, acc: 48.44%, op_acc: 39.84%] [G loss: 0.899585]\n",
      "epoch:14 step:11164[D loss: 0.433146, acc: 61.72%, op_acc: 35.94%] [G loss: 0.950464]\n",
      "epoch:14 step:11165[D loss: 0.419077, acc: 67.19%, op_acc: 35.94%] [G loss: 0.930764]\n",
      "epoch:14 step:11166[D loss: 0.433752, acc: 57.81%, op_acc: 38.28%] [G loss: 0.876154]\n",
      "epoch:14 step:11167[D loss: 0.442037, acc: 53.91%, op_acc: 33.59%] [G loss: 0.882329]\n",
      "epoch:14 step:11168[D loss: 0.452873, acc: 53.12%, op_acc: 38.28%] [G loss: 0.908753]\n",
      "epoch:14 step:11169[D loss: 0.424028, acc: 60.16%, op_acc: 36.72%] [G loss: 0.947417]\n",
      "epoch:14 step:11170[D loss: 0.436013, acc: 57.03%, op_acc: 39.06%] [G loss: 0.888492]\n",
      "epoch:14 step:11171[D loss: 0.413318, acc: 66.41%, op_acc: 33.59%] [G loss: 1.008930]\n",
      "epoch:14 step:11172[D loss: 0.420115, acc: 70.31%, op_acc: 35.16%] [G loss: 0.893200]\n",
      "epoch:14 step:11173[D loss: 0.397625, acc: 62.50%, op_acc: 39.84%] [G loss: 0.829568]\n",
      "epoch:14 step:11174[D loss: 0.447408, acc: 50.78%, op_acc: 39.06%] [G loss: 0.804396]\n",
      "epoch:14 step:11175[D loss: 0.452798, acc: 49.22%, op_acc: 36.72%] [G loss: 0.917643]\n",
      "epoch:14 step:11176[D loss: 0.427852, acc: 54.69%, op_acc: 34.38%] [G loss: 0.874116]\n",
      "epoch:14 step:11177[D loss: 0.391326, acc: 67.19%, op_acc: 42.19%] [G loss: 0.917543]\n",
      "epoch:14 step:11178[D loss: 0.431892, acc: 57.81%, op_acc: 34.38%] [G loss: 0.889696]\n",
      "epoch:14 step:11179[D loss: 0.441384, acc: 54.69%, op_acc: 40.62%] [G loss: 0.845361]\n",
      "epoch:14 step:11180[D loss: 0.433575, acc: 64.06%, op_acc: 37.50%] [G loss: 0.885535]\n",
      "epoch:14 step:11181[D loss: 0.401068, acc: 65.62%, op_acc: 39.06%] [G loss: 0.914098]\n",
      "epoch:14 step:11182[D loss: 0.468570, acc: 57.81%, op_acc: 32.81%] [G loss: 0.822218]\n",
      "epoch:14 step:11183[D loss: 0.434843, acc: 64.06%, op_acc: 35.94%] [G loss: 0.863610]\n",
      "epoch:14 step:11184[D loss: 0.459399, acc: 57.03%, op_acc: 32.81%] [G loss: 0.916820]\n",
      "epoch:14 step:11185[D loss: 0.410951, acc: 61.72%, op_acc: 38.28%] [G loss: 0.920134]\n",
      "epoch:14 step:11186[D loss: 0.435766, acc: 53.12%, op_acc: 34.38%] [G loss: 0.904746]\n",
      "epoch:14 step:11187[D loss: 0.443422, acc: 59.38%, op_acc: 35.16%] [G loss: 0.909269]\n",
      "epoch:14 step:11188[D loss: 0.436292, acc: 61.72%, op_acc: 32.81%] [G loss: 0.835510]\n",
      "epoch:14 step:11189[D loss: 0.426799, acc: 57.81%, op_acc: 39.06%] [G loss: 0.873975]\n",
      "epoch:14 step:11190[D loss: 0.418793, acc: 58.59%, op_acc: 41.41%] [G loss: 0.952051]\n",
      "epoch:14 step:11191[D loss: 0.426167, acc: 60.94%, op_acc: 32.81%] [G loss: 0.864024]\n",
      "epoch:14 step:11192[D loss: 0.425891, acc: 60.94%, op_acc: 43.75%] [G loss: 0.833452]\n",
      "epoch:14 step:11193[D loss: 0.427298, acc: 68.75%, op_acc: 35.16%] [G loss: 0.825137]\n",
      "epoch:14 step:11194[D loss: 0.456967, acc: 59.38%, op_acc: 36.72%] [G loss: 0.854967]\n",
      "epoch:14 step:11195[D loss: 0.412710, acc: 65.62%, op_acc: 40.62%] [G loss: 0.962681]\n",
      "epoch:14 step:11196[D loss: 0.426663, acc: 59.38%, op_acc: 33.59%] [G loss: 0.940891]\n",
      "epoch:14 step:11197[D loss: 0.415061, acc: 62.50%, op_acc: 37.50%] [G loss: 0.933383]\n",
      "epoch:14 step:11198[D loss: 0.448915, acc: 57.03%, op_acc: 33.59%] [G loss: 0.854722]\n",
      "epoch:14 step:11199[D loss: 0.404217, acc: 66.41%, op_acc: 34.38%] [G loss: 0.969384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11200[D loss: 0.421385, acc: 61.72%, op_acc: 39.84%] [G loss: 0.875087]\n",
      "##############\n",
      "[0.85645103 0.86193243 0.79864603 0.79288265 0.78791026 0.80945438\n",
      " 0.89893401 0.82024328 0.79797667 0.82505216]\n",
      "##########\n",
      "epoch:14 step:11201[D loss: 0.458801, acc: 54.69%, op_acc: 39.06%] [G loss: 0.834890]\n",
      "epoch:14 step:11202[D loss: 0.430775, acc: 62.50%, op_acc: 36.72%] [G loss: 0.883324]\n",
      "epoch:14 step:11203[D loss: 0.416214, acc: 60.16%, op_acc: 41.41%] [G loss: 0.917883]\n",
      "epoch:14 step:11204[D loss: 0.435351, acc: 60.94%, op_acc: 31.25%] [G loss: 0.917639]\n",
      "epoch:14 step:11205[D loss: 0.448023, acc: 57.81%, op_acc: 37.50%] [G loss: 0.869589]\n",
      "epoch:14 step:11206[D loss: 0.422288, acc: 67.97%, op_acc: 34.38%] [G loss: 0.838139]\n",
      "epoch:14 step:11207[D loss: 0.436545, acc: 57.81%, op_acc: 38.28%] [G loss: 0.865794]\n",
      "epoch:14 step:11208[D loss: 0.454995, acc: 51.56%, op_acc: 35.16%] [G loss: 0.885965]\n",
      "epoch:14 step:11209[D loss: 0.428359, acc: 58.59%, op_acc: 42.19%] [G loss: 0.879411]\n",
      "epoch:14 step:11210[D loss: 0.440815, acc: 58.59%, op_acc: 36.72%] [G loss: 0.897206]\n",
      "epoch:14 step:11211[D loss: 0.465898, acc: 52.34%, op_acc: 31.25%] [G loss: 0.856844]\n",
      "epoch:14 step:11212[D loss: 0.453988, acc: 57.81%, op_acc: 36.72%] [G loss: 0.841388]\n",
      "epoch:14 step:11213[D loss: 0.416595, acc: 64.06%, op_acc: 35.16%] [G loss: 0.846522]\n",
      "epoch:14 step:11214[D loss: 0.447416, acc: 50.00%, op_acc: 43.75%] [G loss: 0.888832]\n",
      "epoch:14 step:11215[D loss: 0.470645, acc: 52.34%, op_acc: 30.47%] [G loss: 0.843132]\n",
      "epoch:14 step:11216[D loss: 0.422187, acc: 67.97%, op_acc: 39.84%] [G loss: 0.953772]\n",
      "epoch:14 step:11217[D loss: 0.398668, acc: 65.62%, op_acc: 41.41%] [G loss: 0.864963]\n",
      "epoch:14 step:11218[D loss: 0.415421, acc: 60.16%, op_acc: 37.50%] [G loss: 0.902403]\n",
      "epoch:14 step:11219[D loss: 0.437143, acc: 60.94%, op_acc: 33.59%] [G loss: 0.969682]\n",
      "epoch:14 step:11220[D loss: 0.444971, acc: 58.59%, op_acc: 32.81%] [G loss: 0.866126]\n",
      "epoch:14 step:11221[D loss: 0.430904, acc: 57.81%, op_acc: 42.19%] [G loss: 0.910567]\n",
      "epoch:14 step:11222[D loss: 0.425633, acc: 60.94%, op_acc: 40.62%] [G loss: 0.913918]\n",
      "epoch:14 step:11223[D loss: 0.443284, acc: 59.38%, op_acc: 27.34%] [G loss: 0.866785]\n",
      "epoch:14 step:11224[D loss: 0.408174, acc: 64.84%, op_acc: 39.84%] [G loss: 0.860231]\n",
      "epoch:14 step:11225[D loss: 0.456262, acc: 47.66%, op_acc: 36.72%] [G loss: 0.869202]\n",
      "epoch:14 step:11226[D loss: 0.432374, acc: 63.28%, op_acc: 35.94%] [G loss: 0.885742]\n",
      "epoch:14 step:11227[D loss: 0.445751, acc: 55.47%, op_acc: 41.41%] [G loss: 0.822062]\n",
      "epoch:14 step:11228[D loss: 0.446073, acc: 54.69%, op_acc: 32.03%] [G loss: 0.875382]\n",
      "epoch:14 step:11229[D loss: 0.416319, acc: 60.94%, op_acc: 38.28%] [G loss: 0.895652]\n",
      "epoch:14 step:11230[D loss: 0.418203, acc: 61.72%, op_acc: 37.50%] [G loss: 0.875672]\n",
      "epoch:14 step:11231[D loss: 0.450829, acc: 54.69%, op_acc: 32.81%] [G loss: 0.835283]\n",
      "epoch:14 step:11232[D loss: 0.426206, acc: 60.16%, op_acc: 39.06%] [G loss: 0.949513]\n",
      "epoch:14 step:11233[D loss: 0.463706, acc: 50.00%, op_acc: 36.72%] [G loss: 0.933470]\n",
      "epoch:14 step:11234[D loss: 0.441534, acc: 60.16%, op_acc: 39.06%] [G loss: 0.874295]\n",
      "epoch:14 step:11235[D loss: 0.434355, acc: 60.16%, op_acc: 35.16%] [G loss: 0.874858]\n",
      "epoch:14 step:11236[D loss: 0.398926, acc: 65.62%, op_acc: 39.06%] [G loss: 0.827677]\n",
      "epoch:14 step:11237[D loss: 0.449193, acc: 54.69%, op_acc: 36.72%] [G loss: 0.871881]\n",
      "epoch:14 step:11238[D loss: 0.411972, acc: 66.41%, op_acc: 39.06%] [G loss: 0.887097]\n",
      "epoch:14 step:11239[D loss: 0.419955, acc: 64.84%, op_acc: 35.94%] [G loss: 0.839604]\n",
      "epoch:14 step:11240[D loss: 0.489349, acc: 53.12%, op_acc: 35.16%] [G loss: 0.913570]\n",
      "epoch:14 step:11241[D loss: 0.424045, acc: 57.03%, op_acc: 37.50%] [G loss: 0.862369]\n",
      "epoch:14 step:11242[D loss: 0.410528, acc: 66.41%, op_acc: 37.50%] [G loss: 0.821091]\n",
      "epoch:14 step:11243[D loss: 0.442471, acc: 57.03%, op_acc: 35.94%] [G loss: 0.888376]\n",
      "epoch:14 step:11244[D loss: 0.423621, acc: 60.16%, op_acc: 35.94%] [G loss: 0.913772]\n",
      "epoch:14 step:11245[D loss: 0.467450, acc: 55.47%, op_acc: 32.03%] [G loss: 0.879230]\n",
      "epoch:14 step:11246[D loss: 0.420271, acc: 64.06%, op_acc: 35.16%] [G loss: 0.915979]\n",
      "epoch:14 step:11247[D loss: 0.443860, acc: 63.28%, op_acc: 29.69%] [G loss: 0.839332]\n",
      "epoch:14 step:11248[D loss: 0.453697, acc: 55.47%, op_acc: 32.81%] [G loss: 0.817882]\n",
      "epoch:14 step:11249[D loss: 0.429666, acc: 60.16%, op_acc: 39.06%] [G loss: 0.850504]\n",
      "epoch:14 step:11250[D loss: 0.433453, acc: 52.34%, op_acc: 37.50%] [G loss: 0.879926]\n",
      "##############\n",
      "[0.86523427 0.85403642 0.81743784 0.81025656 0.77845106 0.82134757\n",
      " 0.88816564 0.82432037 0.79362016 0.83231625]\n",
      "##########\n",
      "epoch:14 step:11251[D loss: 0.425842, acc: 58.59%, op_acc: 32.81%] [G loss: 0.829504]\n",
      "epoch:14 step:11252[D loss: 0.456743, acc: 54.69%, op_acc: 32.03%] [G loss: 0.826545]\n",
      "epoch:14 step:11253[D loss: 0.438610, acc: 57.03%, op_acc: 36.72%] [G loss: 0.867299]\n",
      "epoch:14 step:11254[D loss: 0.454540, acc: 53.91%, op_acc: 34.38%] [G loss: 0.908394]\n",
      "epoch:14 step:11255[D loss: 0.435357, acc: 60.94%, op_acc: 37.50%] [G loss: 0.852884]\n",
      "epoch:14 step:11256[D loss: 0.406454, acc: 65.62%, op_acc: 41.41%] [G loss: 0.924880]\n",
      "epoch:14 step:11257[D loss: 0.455157, acc: 48.44%, op_acc: 38.28%] [G loss: 0.925396]\n",
      "epoch:14 step:11258[D loss: 0.431879, acc: 64.06%, op_acc: 32.81%] [G loss: 0.876403]\n",
      "epoch:14 step:11259[D loss: 0.438857, acc: 51.56%, op_acc: 36.72%] [G loss: 0.863210]\n",
      "epoch:14 step:11260[D loss: 0.433892, acc: 53.91%, op_acc: 32.81%] [G loss: 0.855867]\n",
      "epoch:14 step:11261[D loss: 0.417625, acc: 64.84%, op_acc: 42.19%] [G loss: 0.818140]\n",
      "epoch:14 step:11262[D loss: 0.447030, acc: 59.38%, op_acc: 32.81%] [G loss: 0.849106]\n",
      "epoch:14 step:11263[D loss: 0.429653, acc: 62.50%, op_acc: 33.59%] [G loss: 0.907339]\n",
      "epoch:14 step:11264[D loss: 0.415671, acc: 57.81%, op_acc: 39.06%] [G loss: 0.916287]\n",
      "epoch:14 step:11265[D loss: 0.451845, acc: 57.03%, op_acc: 34.38%] [G loss: 0.922648]\n",
      "epoch:14 step:11266[D loss: 0.404317, acc: 66.41%, op_acc: 39.06%] [G loss: 0.880930]\n",
      "epoch:14 step:11267[D loss: 0.414975, acc: 64.84%, op_acc: 37.50%] [G loss: 0.839616]\n",
      "epoch:14 step:11268[D loss: 0.433275, acc: 53.12%, op_acc: 35.94%] [G loss: 0.858797]\n",
      "epoch:14 step:11269[D loss: 0.446012, acc: 55.47%, op_acc: 32.81%] [G loss: 0.880962]\n",
      "epoch:14 step:11270[D loss: 0.440601, acc: 57.03%, op_acc: 32.03%] [G loss: 0.884487]\n",
      "epoch:14 step:11271[D loss: 0.430035, acc: 64.06%, op_acc: 32.81%] [G loss: 0.886268]\n",
      "epoch:14 step:11272[D loss: 0.410480, acc: 61.72%, op_acc: 42.19%] [G loss: 0.845087]\n",
      "epoch:14 step:11273[D loss: 0.439016, acc: 55.47%, op_acc: 35.94%] [G loss: 0.870161]\n",
      "epoch:14 step:11274[D loss: 0.424261, acc: 62.50%, op_acc: 38.28%] [G loss: 0.873440]\n",
      "epoch:14 step:11275[D loss: 0.434724, acc: 60.94%, op_acc: 31.25%] [G loss: 0.903400]\n",
      "epoch:14 step:11276[D loss: 0.438947, acc: 56.25%, op_acc: 36.72%] [G loss: 0.883483]\n",
      "epoch:14 step:11277[D loss: 0.444273, acc: 59.38%, op_acc: 35.94%] [G loss: 0.864495]\n",
      "epoch:14 step:11278[D loss: 0.424495, acc: 60.16%, op_acc: 42.19%] [G loss: 0.871970]\n",
      "epoch:14 step:11279[D loss: 0.431288, acc: 60.16%, op_acc: 39.06%] [G loss: 0.883422]\n",
      "epoch:14 step:11280[D loss: 0.438250, acc: 60.16%, op_acc: 36.72%] [G loss: 0.925678]\n",
      "epoch:14 step:11281[D loss: 0.415420, acc: 63.28%, op_acc: 39.84%] [G loss: 0.859168]\n",
      "epoch:14 step:11282[D loss: 0.424287, acc: 60.94%, op_acc: 32.03%] [G loss: 0.955181]\n",
      "epoch:14 step:11283[D loss: 0.432782, acc: 60.16%, op_acc: 32.03%] [G loss: 0.881395]\n",
      "epoch:14 step:11284[D loss: 0.440746, acc: 57.81%, op_acc: 37.50%] [G loss: 0.893636]\n",
      "epoch:14 step:11285[D loss: 0.448570, acc: 54.69%, op_acc: 32.03%] [G loss: 0.893751]\n",
      "epoch:14 step:11286[D loss: 0.434432, acc: 60.16%, op_acc: 32.03%] [G loss: 0.885071]\n",
      "epoch:14 step:11287[D loss: 0.413331, acc: 59.38%, op_acc: 44.53%] [G loss: 0.863809]\n",
      "epoch:14 step:11288[D loss: 0.451032, acc: 56.25%, op_acc: 35.94%] [G loss: 0.852711]\n",
      "epoch:14 step:11289[D loss: 0.413754, acc: 64.84%, op_acc: 39.84%] [G loss: 0.912975]\n",
      "epoch:14 step:11290[D loss: 0.421338, acc: 60.94%, op_acc: 40.62%] [G loss: 0.917179]\n",
      "epoch:14 step:11291[D loss: 0.447816, acc: 58.59%, op_acc: 32.81%] [G loss: 0.885448]\n",
      "epoch:14 step:11292[D loss: 0.449647, acc: 65.62%, op_acc: 32.03%] [G loss: 0.936505]\n",
      "epoch:14 step:11293[D loss: 0.416298, acc: 62.50%, op_acc: 39.84%] [G loss: 0.896420]\n",
      "epoch:14 step:11294[D loss: 0.447287, acc: 53.12%, op_acc: 39.06%] [G loss: 0.853534]\n",
      "epoch:14 step:11295[D loss: 0.430122, acc: 57.81%, op_acc: 37.50%] [G loss: 0.865355]\n",
      "epoch:14 step:11296[D loss: 0.387885, acc: 69.53%, op_acc: 41.41%] [G loss: 0.979604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11297[D loss: 0.420183, acc: 72.66%, op_acc: 37.50%] [G loss: 0.972363]\n",
      "epoch:14 step:11298[D loss: 0.439265, acc: 57.81%, op_acc: 33.59%] [G loss: 0.924717]\n",
      "epoch:14 step:11299[D loss: 0.413252, acc: 53.91%, op_acc: 38.28%] [G loss: 0.946606]\n",
      "epoch:14 step:11300[D loss: 0.413123, acc: 58.59%, op_acc: 40.62%] [G loss: 0.877865]\n",
      "##############\n",
      "[0.86963837 0.87094399 0.79679509 0.80852693 0.78487659 0.84630026\n",
      " 0.88025057 0.83556499 0.80676466 0.8185102 ]\n",
      "##########\n",
      "epoch:14 step:11301[D loss: 0.466999, acc: 47.66%, op_acc: 30.47%] [G loss: 0.827208]\n",
      "epoch:14 step:11302[D loss: 0.431590, acc: 56.25%, op_acc: 33.59%] [G loss: 0.869441]\n",
      "epoch:14 step:11303[D loss: 0.434692, acc: 57.03%, op_acc: 40.62%] [G loss: 0.839734]\n",
      "epoch:14 step:11304[D loss: 0.449445, acc: 51.56%, op_acc: 39.06%] [G loss: 0.854045]\n",
      "epoch:14 step:11305[D loss: 0.394705, acc: 64.84%, op_acc: 46.09%] [G loss: 0.870923]\n",
      "epoch:14 step:11306[D loss: 0.419490, acc: 59.38%, op_acc: 40.62%] [G loss: 0.861148]\n",
      "epoch:14 step:11307[D loss: 0.425787, acc: 62.50%, op_acc: 39.06%] [G loss: 0.872480]\n",
      "epoch:14 step:11308[D loss: 0.438673, acc: 54.69%, op_acc: 42.19%] [G loss: 0.787623]\n",
      "epoch:14 step:11309[D loss: 0.409999, acc: 62.50%, op_acc: 38.28%] [G loss: 0.863374]\n",
      "epoch:14 step:11310[D loss: 0.439442, acc: 60.16%, op_acc: 34.38%] [G loss: 0.836576]\n",
      "epoch:14 step:11311[D loss: 0.436928, acc: 57.81%, op_acc: 38.28%] [G loss: 0.854023]\n",
      "epoch:14 step:11312[D loss: 0.436423, acc: 56.25%, op_acc: 40.62%] [G loss: 0.894554]\n",
      "epoch:14 step:11313[D loss: 0.417262, acc: 61.72%, op_acc: 41.41%] [G loss: 0.912817]\n",
      "epoch:14 step:11314[D loss: 0.440632, acc: 57.81%, op_acc: 36.72%] [G loss: 0.904519]\n",
      "epoch:14 step:11315[D loss: 0.438172, acc: 57.81%, op_acc: 35.94%] [G loss: 0.865088]\n",
      "epoch:14 step:11316[D loss: 0.435200, acc: 60.16%, op_acc: 35.94%] [G loss: 0.942575]\n",
      "epoch:14 step:11317[D loss: 0.426897, acc: 63.28%, op_acc: 39.84%] [G loss: 0.876358]\n",
      "epoch:14 step:11318[D loss: 0.423027, acc: 60.16%, op_acc: 38.28%] [G loss: 0.931432]\n",
      "epoch:14 step:11319[D loss: 0.415617, acc: 59.38%, op_acc: 41.41%] [G loss: 0.939893]\n",
      "epoch:14 step:11320[D loss: 0.414990, acc: 60.16%, op_acc: 40.62%] [G loss: 0.799263]\n",
      "epoch:14 step:11321[D loss: 0.444454, acc: 66.41%, op_acc: 35.94%] [G loss: 0.862128]\n",
      "epoch:14 step:11322[D loss: 0.426266, acc: 66.41%, op_acc: 41.41%] [G loss: 0.946483]\n",
      "epoch:14 step:11323[D loss: 0.430906, acc: 55.47%, op_acc: 40.62%] [G loss: 0.913810]\n",
      "epoch:14 step:11324[D loss: 0.426526, acc: 59.38%, op_acc: 36.72%] [G loss: 0.888923]\n",
      "epoch:14 step:11325[D loss: 0.411855, acc: 60.16%, op_acc: 38.28%] [G loss: 0.924058]\n",
      "epoch:14 step:11326[D loss: 0.390934, acc: 68.75%, op_acc: 44.53%] [G loss: 0.865271]\n",
      "epoch:14 step:11327[D loss: 0.416900, acc: 65.62%, op_acc: 39.06%] [G loss: 0.939231]\n",
      "epoch:14 step:11328[D loss: 0.423861, acc: 64.84%, op_acc: 38.28%] [G loss: 0.884967]\n",
      "epoch:14 step:11329[D loss: 0.438757, acc: 59.38%, op_acc: 32.03%] [G loss: 0.902966]\n",
      "epoch:14 step:11330[D loss: 0.483924, acc: 42.19%, op_acc: 34.38%] [G loss: 0.869667]\n",
      "epoch:14 step:11331[D loss: 0.420292, acc: 59.38%, op_acc: 39.84%] [G loss: 0.887778]\n",
      "epoch:14 step:11332[D loss: 0.475583, acc: 53.12%, op_acc: 30.47%] [G loss: 0.820213]\n",
      "epoch:14 step:11333[D loss: 0.439285, acc: 54.69%, op_acc: 35.94%] [G loss: 0.886248]\n",
      "epoch:14 step:11334[D loss: 0.424465, acc: 58.59%, op_acc: 35.94%] [G loss: 0.834214]\n",
      "epoch:14 step:11335[D loss: 0.423639, acc: 56.25%, op_acc: 36.72%] [G loss: 0.917738]\n",
      "epoch:14 step:11336[D loss: 0.449630, acc: 53.91%, op_acc: 33.59%] [G loss: 0.961830]\n",
      "epoch:14 step:11337[D loss: 0.443574, acc: 62.50%, op_acc: 34.38%] [G loss: 0.850075]\n",
      "epoch:14 step:11338[D loss: 0.427397, acc: 57.03%, op_acc: 39.06%] [G loss: 0.910435]\n",
      "epoch:14 step:11339[D loss: 0.457768, acc: 60.16%, op_acc: 34.38%] [G loss: 0.908775]\n",
      "epoch:14 step:11340[D loss: 0.443715, acc: 53.91%, op_acc: 36.72%] [G loss: 0.881762]\n",
      "epoch:14 step:11341[D loss: 0.424409, acc: 57.81%, op_acc: 31.25%] [G loss: 0.927117]\n",
      "epoch:14 step:11342[D loss: 0.425403, acc: 59.38%, op_acc: 39.84%] [G loss: 0.857276]\n",
      "epoch:14 step:11343[D loss: 0.444807, acc: 59.38%, op_acc: 42.19%] [G loss: 0.844522]\n",
      "epoch:14 step:11344[D loss: 0.404136, acc: 61.72%, op_acc: 39.84%] [G loss: 0.864671]\n",
      "epoch:14 step:11345[D loss: 0.451883, acc: 54.69%, op_acc: 39.06%] [G loss: 0.864858]\n",
      "epoch:14 step:11346[D loss: 0.423549, acc: 57.81%, op_acc: 42.19%] [G loss: 0.883280]\n",
      "epoch:14 step:11347[D loss: 0.423309, acc: 54.69%, op_acc: 36.72%] [G loss: 0.877144]\n",
      "epoch:14 step:11348[D loss: 0.428986, acc: 62.50%, op_acc: 36.72%] [G loss: 0.953832]\n",
      "epoch:14 step:11349[D loss: 0.406033, acc: 67.97%, op_acc: 39.06%] [G loss: 0.924153]\n",
      "epoch:14 step:11350[D loss: 0.416672, acc: 60.16%, op_acc: 41.41%] [G loss: 0.947290]\n",
      "##############\n",
      "[0.86642198 0.87261966 0.83504834 0.82734429 0.79910729 0.8352666\n",
      " 0.86621814 0.80524504 0.80423776 0.81825182]\n",
      "##########\n",
      "epoch:14 step:11351[D loss: 0.446505, acc: 58.59%, op_acc: 38.28%] [G loss: 0.962825]\n",
      "epoch:14 step:11352[D loss: 0.426118, acc: 55.47%, op_acc: 36.72%] [G loss: 0.978301]\n",
      "epoch:14 step:11353[D loss: 0.436770, acc: 62.50%, op_acc: 31.25%] [G loss: 0.917471]\n",
      "epoch:14 step:11354[D loss: 0.450163, acc: 57.81%, op_acc: 33.59%] [G loss: 0.915629]\n",
      "epoch:14 step:11355[D loss: 0.440262, acc: 58.59%, op_acc: 34.38%] [G loss: 0.789748]\n",
      "epoch:14 step:11356[D loss: 0.454836, acc: 54.69%, op_acc: 39.84%] [G loss: 0.910353]\n",
      "epoch:14 step:11357[D loss: 0.425230, acc: 63.28%, op_acc: 39.84%] [G loss: 0.876813]\n",
      "epoch:14 step:11358[D loss: 0.419049, acc: 66.41%, op_acc: 39.06%] [G loss: 0.919880]\n",
      "epoch:14 step:11359[D loss: 0.428279, acc: 61.72%, op_acc: 36.72%] [G loss: 0.846187]\n",
      "epoch:14 step:11360[D loss: 0.479409, acc: 47.66%, op_acc: 32.81%] [G loss: 0.746524]\n",
      "epoch:14 step:11361[D loss: 0.438403, acc: 60.94%, op_acc: 32.81%] [G loss: 0.827367]\n",
      "epoch:14 step:11362[D loss: 0.434739, acc: 54.69%, op_acc: 34.38%] [G loss: 0.854152]\n",
      "epoch:14 step:11363[D loss: 0.423785, acc: 59.38%, op_acc: 38.28%] [G loss: 0.879072]\n",
      "epoch:14 step:11364[D loss: 0.444638, acc: 51.56%, op_acc: 40.62%] [G loss: 0.878710]\n",
      "epoch:14 step:11365[D loss: 0.445763, acc: 62.50%, op_acc: 39.84%] [G loss: 0.867729]\n",
      "epoch:14 step:11366[D loss: 0.428702, acc: 59.38%, op_acc: 43.75%] [G loss: 0.945527]\n",
      "epoch:14 step:11367[D loss: 0.468973, acc: 51.56%, op_acc: 34.38%] [G loss: 0.755791]\n",
      "epoch:14 step:11368[D loss: 0.420778, acc: 53.91%, op_acc: 40.62%] [G loss: 0.829608]\n",
      "epoch:14 step:11369[D loss: 0.413182, acc: 60.94%, op_acc: 38.28%] [G loss: 0.842425]\n",
      "epoch:14 step:11370[D loss: 0.434268, acc: 59.38%, op_acc: 36.72%] [G loss: 0.856468]\n",
      "epoch:14 step:11371[D loss: 0.418515, acc: 60.16%, op_acc: 39.84%] [G loss: 0.911540]\n",
      "epoch:14 step:11372[D loss: 0.402294, acc: 58.59%, op_acc: 42.19%] [G loss: 0.846637]\n",
      "epoch:14 step:11373[D loss: 0.406759, acc: 67.97%, op_acc: 39.06%] [G loss: 0.883212]\n",
      "epoch:14 step:11374[D loss: 0.438818, acc: 61.72%, op_acc: 42.19%] [G loss: 0.936060]\n",
      "epoch:14 step:11375[D loss: 0.457378, acc: 54.69%, op_acc: 31.25%] [G loss: 0.882972]\n",
      "epoch:14 step:11376[D loss: 0.417258, acc: 60.94%, op_acc: 41.41%] [G loss: 0.835524]\n",
      "epoch:14 step:11377[D loss: 0.427898, acc: 57.03%, op_acc: 33.59%] [G loss: 0.804760]\n",
      "epoch:14 step:11378[D loss: 0.404643, acc: 66.41%, op_acc: 41.41%] [G loss: 0.880807]\n",
      "epoch:14 step:11379[D loss: 0.431500, acc: 61.72%, op_acc: 37.50%] [G loss: 0.912494]\n",
      "epoch:14 step:11380[D loss: 0.416233, acc: 62.50%, op_acc: 39.06%] [G loss: 0.891389]\n",
      "epoch:14 step:11381[D loss: 0.460079, acc: 53.12%, op_acc: 35.16%] [G loss: 0.818317]\n",
      "epoch:14 step:11382[D loss: 0.421075, acc: 65.62%, op_acc: 35.16%] [G loss: 0.880842]\n",
      "epoch:14 step:11383[D loss: 0.439478, acc: 53.12%, op_acc: 38.28%] [G loss: 0.875192]\n",
      "epoch:14 step:11384[D loss: 0.419128, acc: 68.75%, op_acc: 29.69%] [G loss: 0.847397]\n",
      "epoch:14 step:11385[D loss: 0.416039, acc: 59.38%, op_acc: 40.62%] [G loss: 0.953861]\n",
      "epoch:14 step:11386[D loss: 0.418217, acc: 63.28%, op_acc: 37.50%] [G loss: 0.886626]\n",
      "epoch:14 step:11387[D loss: 0.429322, acc: 53.12%, op_acc: 39.06%] [G loss: 0.882978]\n",
      "epoch:14 step:11388[D loss: 0.437502, acc: 60.94%, op_acc: 40.62%] [G loss: 0.962220]\n",
      "epoch:14 step:11389[D loss: 0.436763, acc: 58.59%, op_acc: 39.84%] [G loss: 0.903814]\n",
      "epoch:14 step:11390[D loss: 0.434228, acc: 57.03%, op_acc: 39.84%] [G loss: 0.933946]\n",
      "epoch:14 step:11391[D loss: 0.447755, acc: 52.34%, op_acc: 39.06%] [G loss: 0.858523]\n",
      "epoch:14 step:11392[D loss: 0.422662, acc: 61.72%, op_acc: 36.72%] [G loss: 0.875241]\n",
      "epoch:14 step:11393[D loss: 0.457397, acc: 50.00%, op_acc: 43.75%] [G loss: 0.898168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11394[D loss: 0.402476, acc: 60.94%, op_acc: 42.19%] [G loss: 0.875396]\n",
      "epoch:14 step:11395[D loss: 0.444830, acc: 56.25%, op_acc: 39.84%] [G loss: 0.875588]\n",
      "epoch:14 step:11396[D loss: 0.424169, acc: 59.38%, op_acc: 38.28%] [G loss: 0.884646]\n",
      "epoch:14 step:11397[D loss: 0.444046, acc: 49.22%, op_acc: 33.59%] [G loss: 0.935639]\n",
      "epoch:14 step:11398[D loss: 0.460006, acc: 54.69%, op_acc: 32.81%] [G loss: 0.843130]\n",
      "epoch:14 step:11399[D loss: 0.438420, acc: 60.94%, op_acc: 35.16%] [G loss: 0.881916]\n",
      "epoch:14 step:11400[D loss: 0.438808, acc: 57.03%, op_acc: 37.50%] [G loss: 0.835521]\n",
      "##############\n",
      "[0.873075   0.83360678 0.79095841 0.81667644 0.8052215  0.83681716\n",
      " 0.85829273 0.83894251 0.82218025 0.82537232]\n",
      "##########\n",
      "epoch:14 step:11401[D loss: 0.424612, acc: 57.81%, op_acc: 36.72%] [G loss: 0.909115]\n",
      "epoch:14 step:11402[D loss: 0.400519, acc: 58.59%, op_acc: 39.06%] [G loss: 0.950689]\n",
      "epoch:14 step:11403[D loss: 0.409036, acc: 60.16%, op_acc: 39.06%] [G loss: 0.907727]\n",
      "epoch:14 step:11404[D loss: 0.427974, acc: 63.28%, op_acc: 34.38%] [G loss: 0.918004]\n",
      "epoch:14 step:11405[D loss: 0.406781, acc: 67.19%, op_acc: 33.59%] [G loss: 0.922551]\n",
      "epoch:14 step:11406[D loss: 0.432752, acc: 58.59%, op_acc: 32.03%] [G loss: 0.925551]\n",
      "epoch:14 step:11407[D loss: 0.403187, acc: 67.97%, op_acc: 41.41%] [G loss: 0.881595]\n",
      "epoch:14 step:11408[D loss: 0.429789, acc: 57.81%, op_acc: 32.81%] [G loss: 0.878522]\n",
      "epoch:14 step:11409[D loss: 0.451899, acc: 47.66%, op_acc: 32.81%] [G loss: 0.862088]\n",
      "epoch:14 step:11410[D loss: 0.410800, acc: 70.31%, op_acc: 37.50%] [G loss: 0.963273]\n",
      "epoch:14 step:11411[D loss: 0.429011, acc: 60.16%, op_acc: 39.84%] [G loss: 0.911891]\n",
      "epoch:14 step:11412[D loss: 0.426654, acc: 55.47%, op_acc: 43.75%] [G loss: 0.853819]\n",
      "epoch:14 step:11413[D loss: 0.424046, acc: 64.06%, op_acc: 35.94%] [G loss: 0.826027]\n",
      "epoch:14 step:11414[D loss: 0.452670, acc: 60.16%, op_acc: 35.16%] [G loss: 0.870939]\n",
      "epoch:14 step:11415[D loss: 0.462487, acc: 55.47%, op_acc: 32.03%] [G loss: 0.897714]\n",
      "epoch:14 step:11416[D loss: 0.445034, acc: 58.59%, op_acc: 37.50%] [G loss: 0.901864]\n",
      "epoch:14 step:11417[D loss: 0.445690, acc: 52.34%, op_acc: 35.94%] [G loss: 0.937602]\n",
      "epoch:14 step:11418[D loss: 0.430487, acc: 58.59%, op_acc: 36.72%] [G loss: 0.905529]\n",
      "epoch:14 step:11419[D loss: 0.430363, acc: 58.59%, op_acc: 36.72%] [G loss: 0.827235]\n",
      "epoch:14 step:11420[D loss: 0.419168, acc: 58.59%, op_acc: 41.41%] [G loss: 0.887378]\n",
      "epoch:14 step:11421[D loss: 0.409354, acc: 64.06%, op_acc: 37.50%] [G loss: 0.902230]\n",
      "epoch:14 step:11422[D loss: 0.452673, acc: 55.47%, op_acc: 38.28%] [G loss: 0.978771]\n",
      "epoch:14 step:11423[D loss: 0.429572, acc: 60.94%, op_acc: 35.94%] [G loss: 0.927877]\n",
      "epoch:14 step:11424[D loss: 0.413333, acc: 64.06%, op_acc: 41.41%] [G loss: 0.914998]\n",
      "epoch:14 step:11425[D loss: 0.471338, acc: 52.34%, op_acc: 35.94%] [G loss: 0.855347]\n",
      "epoch:14 step:11426[D loss: 0.438733, acc: 55.47%, op_acc: 36.72%] [G loss: 0.829080]\n",
      "epoch:14 step:11427[D loss: 0.461998, acc: 57.81%, op_acc: 32.81%] [G loss: 0.924380]\n",
      "epoch:14 step:11428[D loss: 0.430857, acc: 55.47%, op_acc: 41.41%] [G loss: 0.874499]\n",
      "epoch:14 step:11429[D loss: 0.413769, acc: 61.72%, op_acc: 39.06%] [G loss: 0.930223]\n",
      "epoch:14 step:11430[D loss: 0.428411, acc: 56.25%, op_acc: 36.72%] [G loss: 0.887860]\n",
      "epoch:14 step:11431[D loss: 0.426617, acc: 54.69%, op_acc: 32.81%] [G loss: 0.929849]\n",
      "epoch:14 step:11432[D loss: 0.430951, acc: 64.84%, op_acc: 32.03%] [G loss: 0.972687]\n",
      "epoch:14 step:11433[D loss: 0.417274, acc: 71.09%, op_acc: 37.50%] [G loss: 0.928837]\n",
      "epoch:14 step:11434[D loss: 0.449729, acc: 54.69%, op_acc: 35.94%] [G loss: 0.850957]\n",
      "epoch:14 step:11435[D loss: 0.440203, acc: 57.03%, op_acc: 34.38%] [G loss: 0.873531]\n",
      "epoch:14 step:11436[D loss: 0.418170, acc: 54.69%, op_acc: 42.97%] [G loss: 0.869388]\n",
      "epoch:14 step:11437[D loss: 0.419303, acc: 64.06%, op_acc: 33.59%] [G loss: 0.906734]\n",
      "epoch:14 step:11438[D loss: 0.428269, acc: 57.81%, op_acc: 38.28%] [G loss: 0.898125]\n",
      "epoch:14 step:11439[D loss: 0.443583, acc: 59.38%, op_acc: 33.59%] [G loss: 0.881663]\n",
      "epoch:14 step:11440[D loss: 0.454460, acc: 52.34%, op_acc: 35.94%] [G loss: 0.866417]\n",
      "epoch:14 step:11441[D loss: 0.402073, acc: 61.72%, op_acc: 41.41%] [G loss: 0.904980]\n",
      "epoch:14 step:11442[D loss: 0.423060, acc: 60.16%, op_acc: 39.06%] [G loss: 0.899529]\n",
      "epoch:14 step:11443[D loss: 0.452595, acc: 52.34%, op_acc: 39.06%] [G loss: 0.880481]\n",
      "epoch:14 step:11444[D loss: 0.421568, acc: 63.28%, op_acc: 37.50%] [G loss: 0.901567]\n",
      "epoch:14 step:11445[D loss: 0.432283, acc: 61.72%, op_acc: 39.84%] [G loss: 0.808929]\n",
      "epoch:14 step:11446[D loss: 0.457276, acc: 56.25%, op_acc: 36.72%] [G loss: 0.821516]\n",
      "epoch:14 step:11447[D loss: 0.425187, acc: 61.72%, op_acc: 34.38%] [G loss: 0.861372]\n",
      "epoch:14 step:11448[D loss: 0.426247, acc: 62.50%, op_acc: 36.72%] [G loss: 0.829099]\n",
      "epoch:14 step:11449[D loss: 0.446831, acc: 49.22%, op_acc: 37.50%] [G loss: 0.903933]\n",
      "epoch:14 step:11450[D loss: 0.445770, acc: 54.69%, op_acc: 36.72%] [G loss: 0.871287]\n",
      "##############\n",
      "[0.85024352 0.8629281  0.80675298 0.80171631 0.76644598 0.82221166\n",
      " 0.88231608 0.82636218 0.81785259 0.8298951 ]\n",
      "##########\n",
      "epoch:14 step:11451[D loss: 0.445665, acc: 61.72%, op_acc: 32.81%] [G loss: 0.933959]\n",
      "epoch:14 step:11452[D loss: 0.422441, acc: 57.03%, op_acc: 40.62%] [G loss: 0.846528]\n",
      "epoch:14 step:11453[D loss: 0.435952, acc: 57.81%, op_acc: 38.28%] [G loss: 0.896403]\n",
      "epoch:14 step:11454[D loss: 0.391000, acc: 78.12%, op_acc: 39.06%] [G loss: 0.993714]\n",
      "epoch:14 step:11455[D loss: 0.437322, acc: 55.47%, op_acc: 35.16%] [G loss: 0.865524]\n",
      "epoch:14 step:11456[D loss: 0.471493, acc: 48.44%, op_acc: 35.16%] [G loss: 0.898694]\n",
      "epoch:14 step:11457[D loss: 0.438130, acc: 57.03%, op_acc: 36.72%] [G loss: 0.840797]\n",
      "epoch:14 step:11458[D loss: 0.430238, acc: 57.81%, op_acc: 39.06%] [G loss: 0.927841]\n",
      "epoch:14 step:11459[D loss: 0.448887, acc: 61.72%, op_acc: 33.59%] [G loss: 0.882109]\n",
      "epoch:14 step:11460[D loss: 0.477694, acc: 49.22%, op_acc: 29.69%] [G loss: 0.880169]\n",
      "epoch:14 step:11461[D loss: 0.448416, acc: 50.78%, op_acc: 37.50%] [G loss: 0.912047]\n",
      "epoch:14 step:11462[D loss: 0.443243, acc: 56.25%, op_acc: 35.94%] [G loss: 0.843032]\n",
      "epoch:14 step:11463[D loss: 0.439862, acc: 54.69%, op_acc: 37.50%] [G loss: 0.901252]\n",
      "epoch:14 step:11464[D loss: 0.429395, acc: 62.50%, op_acc: 35.94%] [G loss: 0.948285]\n",
      "epoch:14 step:11465[D loss: 0.430512, acc: 62.50%, op_acc: 37.50%] [G loss: 1.023160]\n",
      "epoch:14 step:11466[D loss: 0.407540, acc: 69.53%, op_acc: 39.06%] [G loss: 0.941058]\n",
      "epoch:14 step:11467[D loss: 0.403525, acc: 65.62%, op_acc: 39.84%] [G loss: 0.963332]\n",
      "epoch:14 step:11468[D loss: 0.421175, acc: 60.94%, op_acc: 40.62%] [G loss: 0.825542]\n",
      "epoch:14 step:11469[D loss: 0.425933, acc: 56.25%, op_acc: 39.84%] [G loss: 0.917490]\n",
      "epoch:14 step:11470[D loss: 0.414970, acc: 53.91%, op_acc: 40.62%] [G loss: 0.901303]\n",
      "epoch:14 step:11471[D loss: 0.486606, acc: 48.44%, op_acc: 29.69%] [G loss: 0.832841]\n",
      "epoch:14 step:11472[D loss: 0.438247, acc: 56.25%, op_acc: 35.94%] [G loss: 0.870667]\n",
      "epoch:14 step:11473[D loss: 0.454796, acc: 57.03%, op_acc: 37.50%] [G loss: 0.916637]\n",
      "epoch:14 step:11474[D loss: 0.417879, acc: 60.16%, op_acc: 38.28%] [G loss: 0.809381]\n",
      "epoch:14 step:11475[D loss: 0.405509, acc: 64.06%, op_acc: 39.84%] [G loss: 0.838311]\n",
      "epoch:14 step:11476[D loss: 0.457313, acc: 50.00%, op_acc: 36.72%] [G loss: 0.924502]\n",
      "epoch:14 step:11477[D loss: 0.457893, acc: 48.44%, op_acc: 37.50%] [G loss: 0.971268]\n",
      "epoch:14 step:11478[D loss: 0.437563, acc: 52.34%, op_acc: 39.84%] [G loss: 0.920202]\n",
      "epoch:14 step:11479[D loss: 0.426737, acc: 59.38%, op_acc: 32.81%] [G loss: 0.946261]\n",
      "epoch:14 step:11480[D loss: 0.453709, acc: 53.91%, op_acc: 36.72%] [G loss: 0.888456]\n",
      "epoch:14 step:11481[D loss: 0.480670, acc: 46.88%, op_acc: 39.06%] [G loss: 0.851565]\n",
      "epoch:14 step:11482[D loss: 0.444522, acc: 65.62%, op_acc: 34.38%] [G loss: 0.975365]\n",
      "epoch:14 step:11483[D loss: 0.422664, acc: 66.41%, op_acc: 41.41%] [G loss: 0.930193]\n",
      "epoch:14 step:11484[D loss: 0.417297, acc: 59.38%, op_acc: 39.06%] [G loss: 0.898404]\n",
      "epoch:14 step:11485[D loss: 0.455881, acc: 55.47%, op_acc: 32.03%] [G loss: 0.901782]\n",
      "epoch:14 step:11486[D loss: 0.453328, acc: 61.72%, op_acc: 27.34%] [G loss: 0.916240]\n",
      "epoch:14 step:11487[D loss: 0.414731, acc: 65.62%, op_acc: 35.16%] [G loss: 0.856235]\n",
      "epoch:14 step:11488[D loss: 0.429146, acc: 61.72%, op_acc: 38.28%] [G loss: 0.855642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11489[D loss: 0.410823, acc: 64.06%, op_acc: 35.94%] [G loss: 0.864657]\n",
      "epoch:14 step:11490[D loss: 0.438885, acc: 57.03%, op_acc: 38.28%] [G loss: 0.871759]\n",
      "epoch:14 step:11491[D loss: 0.426630, acc: 64.84%, op_acc: 34.38%] [G loss: 0.903853]\n",
      "epoch:14 step:11492[D loss: 0.445539, acc: 53.91%, op_acc: 41.41%] [G loss: 0.866697]\n",
      "epoch:14 step:11493[D loss: 0.400574, acc: 65.62%, op_acc: 33.59%] [G loss: 0.883459]\n",
      "epoch:14 step:11494[D loss: 0.460669, acc: 54.69%, op_acc: 31.25%] [G loss: 0.868255]\n",
      "epoch:14 step:11495[D loss: 0.429952, acc: 58.59%, op_acc: 38.28%] [G loss: 0.848433]\n",
      "epoch:14 step:11496[D loss: 0.439414, acc: 52.34%, op_acc: 38.28%] [G loss: 0.926112]\n",
      "epoch:14 step:11497[D loss: 0.400596, acc: 68.75%, op_acc: 36.72%] [G loss: 0.974795]\n",
      "epoch:14 step:11498[D loss: 0.430374, acc: 59.38%, op_acc: 38.28%] [G loss: 0.852694]\n",
      "epoch:14 step:11499[D loss: 0.434230, acc: 54.69%, op_acc: 35.16%] [G loss: 0.969618]\n",
      "epoch:14 step:11500[D loss: 0.438456, acc: 55.47%, op_acc: 37.50%] [G loss: 0.895559]\n",
      "##############\n",
      "[0.85249749 0.85119734 0.81394163 0.79125042 0.81895185 0.82908598\n",
      " 0.88276082 0.82056678 0.81120813 0.83728751]\n",
      "##########\n",
      "epoch:14 step:11501[D loss: 0.405210, acc: 64.84%, op_acc: 38.28%] [G loss: 0.950931]\n",
      "epoch:14 step:11502[D loss: 0.451456, acc: 55.47%, op_acc: 41.41%] [G loss: 0.846257]\n",
      "epoch:14 step:11503[D loss: 0.431447, acc: 60.16%, op_acc: 35.94%] [G loss: 0.947249]\n",
      "epoch:14 step:11504[D loss: 0.433853, acc: 54.69%, op_acc: 38.28%] [G loss: 0.802565]\n",
      "epoch:14 step:11505[D loss: 0.441144, acc: 52.34%, op_acc: 37.50%] [G loss: 0.868452]\n",
      "epoch:14 step:11506[D loss: 0.418692, acc: 64.84%, op_acc: 38.28%] [G loss: 0.940397]\n",
      "epoch:14 step:11507[D loss: 0.450689, acc: 59.38%, op_acc: 42.97%] [G loss: 0.906271]\n",
      "epoch:14 step:11508[D loss: 0.469272, acc: 58.59%, op_acc: 26.56%] [G loss: 0.913911]\n",
      "epoch:14 step:11509[D loss: 0.452333, acc: 56.25%, op_acc: 35.94%] [G loss: 0.808528]\n",
      "epoch:14 step:11510[D loss: 0.402049, acc: 60.94%, op_acc: 41.41%] [G loss: 0.886522]\n",
      "epoch:14 step:11511[D loss: 0.440154, acc: 64.06%, op_acc: 29.69%] [G loss: 0.941662]\n",
      "epoch:14 step:11512[D loss: 0.463912, acc: 57.03%, op_acc: 33.59%] [G loss: 0.937328]\n",
      "epoch:14 step:11513[D loss: 0.425115, acc: 53.12%, op_acc: 42.19%] [G loss: 0.924725]\n",
      "epoch:14 step:11514[D loss: 0.422425, acc: 59.38%, op_acc: 39.84%] [G loss: 0.956104]\n",
      "epoch:14 step:11515[D loss: 0.465560, acc: 57.03%, op_acc: 30.47%] [G loss: 0.962653]\n",
      "epoch:14 step:11516[D loss: 0.468764, acc: 53.91%, op_acc: 27.34%] [G loss: 0.896914]\n",
      "epoch:14 step:11517[D loss: 0.438595, acc: 57.03%, op_acc: 35.94%] [G loss: 0.876846]\n",
      "epoch:14 step:11518[D loss: 0.451388, acc: 58.59%, op_acc: 31.25%] [G loss: 0.916369]\n",
      "epoch:14 step:11519[D loss: 0.425272, acc: 61.72%, op_acc: 41.41%] [G loss: 0.915775]\n",
      "epoch:14 step:11520[D loss: 0.409497, acc: 60.94%, op_acc: 37.50%] [G loss: 0.812380]\n",
      "epoch:14 step:11521[D loss: 0.426892, acc: 67.19%, op_acc: 37.50%] [G loss: 0.875919]\n",
      "epoch:14 step:11522[D loss: 0.409700, acc: 61.72%, op_acc: 43.75%] [G loss: 0.871688]\n",
      "epoch:14 step:11523[D loss: 0.418206, acc: 61.72%, op_acc: 36.72%] [G loss: 0.846293]\n",
      "epoch:14 step:11524[D loss: 0.425064, acc: 57.03%, op_acc: 38.28%] [G loss: 0.905145]\n",
      "epoch:14 step:11525[D loss: 0.441234, acc: 58.59%, op_acc: 36.72%] [G loss: 0.819363]\n",
      "epoch:14 step:11526[D loss: 0.429828, acc: 64.06%, op_acc: 35.16%] [G loss: 0.899140]\n",
      "epoch:14 step:11527[D loss: 0.423887, acc: 60.94%, op_acc: 37.50%] [G loss: 0.874847]\n",
      "epoch:14 step:11528[D loss: 0.438574, acc: 54.69%, op_acc: 36.72%] [G loss: 0.883255]\n",
      "epoch:14 step:11529[D loss: 0.445304, acc: 60.94%, op_acc: 33.59%] [G loss: 0.921720]\n",
      "epoch:14 step:11530[D loss: 0.444685, acc: 59.38%, op_acc: 35.16%] [G loss: 0.833500]\n",
      "epoch:14 step:11531[D loss: 0.481165, acc: 53.12%, op_acc: 30.47%] [G loss: 0.806167]\n",
      "epoch:14 step:11532[D loss: 0.422206, acc: 61.72%, op_acc: 34.38%] [G loss: 0.861877]\n",
      "epoch:14 step:11533[D loss: 0.433863, acc: 61.72%, op_acc: 35.16%] [G loss: 0.842836]\n",
      "epoch:14 step:11534[D loss: 0.439590, acc: 60.94%, op_acc: 39.06%] [G loss: 0.878267]\n",
      "epoch:14 step:11535[D loss: 0.443661, acc: 60.16%, op_acc: 35.16%] [G loss: 0.866131]\n",
      "epoch:14 step:11536[D loss: 0.397638, acc: 67.19%, op_acc: 42.19%] [G loss: 0.921160]\n",
      "epoch:14 step:11537[D loss: 0.394753, acc: 62.50%, op_acc: 40.62%] [G loss: 0.907357]\n",
      "epoch:14 step:11538[D loss: 0.494534, acc: 56.25%, op_acc: 30.47%] [G loss: 0.834242]\n",
      "epoch:14 step:11539[D loss: 0.413609, acc: 58.59%, op_acc: 39.06%] [G loss: 0.955471]\n",
      "epoch:14 step:11540[D loss: 0.433481, acc: 57.03%, op_acc: 40.62%] [G loss: 0.840828]\n",
      "epoch:14 step:11541[D loss: 0.430613, acc: 57.81%, op_acc: 41.41%] [G loss: 0.841248]\n",
      "epoch:14 step:11542[D loss: 0.399543, acc: 63.28%, op_acc: 40.62%] [G loss: 0.862907]\n",
      "epoch:14 step:11543[D loss: 0.437673, acc: 54.69%, op_acc: 39.06%] [G loss: 0.957543]\n",
      "epoch:14 step:11544[D loss: 0.422686, acc: 64.06%, op_acc: 38.28%] [G loss: 0.872545]\n",
      "epoch:14 step:11545[D loss: 0.426925, acc: 54.69%, op_acc: 39.06%] [G loss: 0.861677]\n",
      "epoch:14 step:11546[D loss: 0.418321, acc: 63.28%, op_acc: 37.50%] [G loss: 0.956907]\n",
      "epoch:14 step:11547[D loss: 0.442081, acc: 57.03%, op_acc: 42.97%] [G loss: 0.973483]\n",
      "epoch:14 step:11548[D loss: 0.431231, acc: 53.12%, op_acc: 41.41%] [G loss: 0.835759]\n",
      "epoch:14 step:11549[D loss: 0.438043, acc: 55.47%, op_acc: 39.06%] [G loss: 0.887212]\n",
      "epoch:14 step:11550[D loss: 0.435957, acc: 61.72%, op_acc: 38.28%] [G loss: 0.914014]\n",
      "##############\n",
      "[0.86529738 0.87193122 0.79775615 0.8077873  0.79469811 0.81229241\n",
      " 0.8767317  0.83120063 0.79709763 0.82733805]\n",
      "##########\n",
      "epoch:14 step:11551[D loss: 0.476430, acc: 50.78%, op_acc: 38.28%] [G loss: 0.939168]\n",
      "epoch:14 step:11552[D loss: 0.445129, acc: 53.91%, op_acc: 38.28%] [G loss: 0.869143]\n",
      "epoch:14 step:11553[D loss: 0.472186, acc: 59.38%, op_acc: 31.25%] [G loss: 0.855892]\n",
      "epoch:14 step:11554[D loss: 0.441388, acc: 60.94%, op_acc: 32.81%] [G loss: 0.946315]\n",
      "epoch:14 step:11555[D loss: 0.413057, acc: 67.97%, op_acc: 36.72%] [G loss: 0.909325]\n",
      "epoch:14 step:11556[D loss: 0.462578, acc: 56.25%, op_acc: 34.38%] [G loss: 0.925973]\n",
      "epoch:14 step:11557[D loss: 0.407021, acc: 64.06%, op_acc: 36.72%] [G loss: 0.927883]\n",
      "epoch:14 step:11558[D loss: 0.430898, acc: 53.91%, op_acc: 40.62%] [G loss: 0.910114]\n",
      "epoch:14 step:11559[D loss: 0.440378, acc: 58.59%, op_acc: 36.72%] [G loss: 0.888421]\n",
      "epoch:14 step:11560[D loss: 0.414456, acc: 60.16%, op_acc: 43.75%] [G loss: 0.913154]\n",
      "epoch:14 step:11561[D loss: 0.436053, acc: 51.56%, op_acc: 37.50%] [G loss: 0.883795]\n",
      "epoch:14 step:11562[D loss: 0.424909, acc: 59.38%, op_acc: 38.28%] [G loss: 0.833138]\n",
      "epoch:14 step:11563[D loss: 0.441209, acc: 53.12%, op_acc: 35.16%] [G loss: 0.890600]\n",
      "epoch:14 step:11564[D loss: 0.426574, acc: 59.38%, op_acc: 35.16%] [G loss: 0.856008]\n",
      "epoch:14 step:11565[D loss: 0.419332, acc: 64.84%, op_acc: 35.94%] [G loss: 0.836422]\n",
      "epoch:14 step:11566[D loss: 0.452231, acc: 57.81%, op_acc: 34.38%] [G loss: 0.802513]\n",
      "epoch:14 step:11567[D loss: 0.413777, acc: 67.97%, op_acc: 35.16%] [G loss: 0.802933]\n",
      "epoch:14 step:11568[D loss: 0.433708, acc: 56.25%, op_acc: 42.19%] [G loss: 0.867900]\n",
      "epoch:14 step:11569[D loss: 0.451424, acc: 57.81%, op_acc: 38.28%] [G loss: 0.812824]\n",
      "epoch:14 step:11570[D loss: 0.435302, acc: 56.25%, op_acc: 35.94%] [G loss: 0.788967]\n",
      "epoch:14 step:11571[D loss: 0.401104, acc: 63.28%, op_acc: 38.28%] [G loss: 0.874260]\n",
      "epoch:14 step:11572[D loss: 0.430556, acc: 62.50%, op_acc: 37.50%] [G loss: 0.959654]\n",
      "epoch:14 step:11573[D loss: 0.427979, acc: 57.03%, op_acc: 39.84%] [G loss: 0.913094]\n",
      "epoch:14 step:11574[D loss: 0.442217, acc: 59.38%, op_acc: 38.28%] [G loss: 0.948983]\n",
      "epoch:14 step:11575[D loss: 0.453622, acc: 61.72%, op_acc: 35.16%] [G loss: 0.827368]\n",
      "epoch:14 step:11576[D loss: 0.424986, acc: 60.94%, op_acc: 40.62%] [G loss: 0.865414]\n",
      "epoch:14 step:11577[D loss: 0.479295, acc: 47.66%, op_acc: 36.72%] [G loss: 0.873078]\n",
      "epoch:14 step:11578[D loss: 0.434946, acc: 64.06%, op_acc: 39.84%] [G loss: 0.891337]\n",
      "epoch:14 step:11579[D loss: 0.426001, acc: 65.62%, op_acc: 35.94%] [G loss: 0.856571]\n",
      "epoch:14 step:11580[D loss: 0.474500, acc: 54.69%, op_acc: 31.25%] [G loss: 0.884424]\n",
      "epoch:14 step:11581[D loss: 0.426211, acc: 59.38%, op_acc: 34.38%] [G loss: 0.867720]\n",
      "epoch:14 step:11582[D loss: 0.437906, acc: 59.38%, op_acc: 35.16%] [G loss: 0.903781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11583[D loss: 0.448644, acc: 53.91%, op_acc: 33.59%] [G loss: 0.841764]\n",
      "epoch:14 step:11584[D loss: 0.445039, acc: 64.06%, op_acc: 35.16%] [G loss: 0.901589]\n",
      "epoch:14 step:11585[D loss: 0.444653, acc: 54.69%, op_acc: 41.41%] [G loss: 0.824317]\n",
      "epoch:14 step:11586[D loss: 0.449098, acc: 54.69%, op_acc: 34.38%] [G loss: 0.855594]\n",
      "epoch:14 step:11587[D loss: 0.424618, acc: 53.91%, op_acc: 40.62%] [G loss: 0.916068]\n",
      "epoch:14 step:11588[D loss: 0.444133, acc: 56.25%, op_acc: 42.19%] [G loss: 0.857986]\n",
      "epoch:14 step:11589[D loss: 0.437378, acc: 53.91%, op_acc: 37.50%] [G loss: 0.908184]\n",
      "epoch:14 step:11590[D loss: 0.433424, acc: 61.72%, op_acc: 35.94%] [G loss: 0.932090]\n",
      "epoch:14 step:11591[D loss: 0.456372, acc: 52.34%, op_acc: 35.94%] [G loss: 0.899717]\n",
      "epoch:14 step:11592[D loss: 0.454852, acc: 56.25%, op_acc: 32.81%] [G loss: 0.867964]\n",
      "epoch:14 step:11593[D loss: 0.422258, acc: 66.41%, op_acc: 35.16%] [G loss: 0.905602]\n",
      "epoch:14 step:11594[D loss: 0.441923, acc: 53.91%, op_acc: 39.06%] [G loss: 0.855798]\n",
      "epoch:14 step:11595[D loss: 0.395697, acc: 69.53%, op_acc: 39.84%] [G loss: 0.925453]\n",
      "epoch:14 step:11596[D loss: 0.426481, acc: 60.16%, op_acc: 40.62%] [G loss: 0.844917]\n",
      "epoch:14 step:11597[D loss: 0.425496, acc: 60.16%, op_acc: 38.28%] [G loss: 0.802005]\n",
      "epoch:14 step:11598[D loss: 0.416447, acc: 59.38%, op_acc: 36.72%] [G loss: 0.842719]\n",
      "epoch:14 step:11599[D loss: 0.448581, acc: 62.50%, op_acc: 28.91%] [G loss: 0.847885]\n",
      "epoch:14 step:11600[D loss: 0.406095, acc: 71.09%, op_acc: 34.38%] [G loss: 0.853361]\n",
      "##############\n",
      "[0.85531646 0.85073538 0.81747184 0.81746569 0.79850769 0.82671253\n",
      " 0.90617815 0.82802419 0.80197649 0.80618866]\n",
      "##########\n",
      "epoch:14 step:11601[D loss: 0.386705, acc: 71.88%, op_acc: 37.50%] [G loss: 0.946439]\n",
      "epoch:14 step:11602[D loss: 0.414530, acc: 58.59%, op_acc: 40.62%] [G loss: 0.899904]\n",
      "epoch:14 step:11603[D loss: 0.447974, acc: 53.12%, op_acc: 37.50%] [G loss: 0.911366]\n",
      "epoch:14 step:11604[D loss: 0.383606, acc: 69.53%, op_acc: 42.19%] [G loss: 0.943648]\n",
      "epoch:14 step:11605[D loss: 0.403646, acc: 67.97%, op_acc: 40.62%] [G loss: 0.909613]\n",
      "epoch:14 step:11606[D loss: 0.435513, acc: 64.06%, op_acc: 38.28%] [G loss: 0.918521]\n",
      "epoch:14 step:11607[D loss: 0.454699, acc: 52.34%, op_acc: 37.50%] [G loss: 0.868607]\n",
      "epoch:14 step:11608[D loss: 0.439387, acc: 56.25%, op_acc: 37.50%] [G loss: 0.874428]\n",
      "epoch:14 step:11609[D loss: 0.430747, acc: 58.59%, op_acc: 39.84%] [G loss: 0.928962]\n",
      "epoch:14 step:11610[D loss: 0.492290, acc: 44.53%, op_acc: 30.47%] [G loss: 0.919531]\n",
      "epoch:14 step:11611[D loss: 0.420589, acc: 67.97%, op_acc: 35.16%] [G loss: 1.013582]\n",
      "epoch:14 step:11612[D loss: 0.436192, acc: 56.25%, op_acc: 42.19%] [G loss: 0.834007]\n",
      "epoch:14 step:11613[D loss: 0.442637, acc: 53.91%, op_acc: 34.38%] [G loss: 0.888440]\n",
      "epoch:14 step:11614[D loss: 0.442471, acc: 60.16%, op_acc: 32.81%] [G loss: 0.833872]\n",
      "epoch:14 step:11615[D loss: 0.433061, acc: 65.62%, op_acc: 33.59%] [G loss: 0.959932]\n",
      "epoch:14 step:11616[D loss: 0.429348, acc: 53.12%, op_acc: 40.62%] [G loss: 0.879624]\n",
      "epoch:14 step:11617[D loss: 0.440378, acc: 53.91%, op_acc: 34.38%] [G loss: 0.927361]\n",
      "epoch:14 step:11618[D loss: 0.417256, acc: 64.06%, op_acc: 34.38%] [G loss: 0.951792]\n",
      "epoch:14 step:11619[D loss: 0.472902, acc: 57.81%, op_acc: 34.38%] [G loss: 0.919063]\n",
      "epoch:14 step:11620[D loss: 0.441320, acc: 54.69%, op_acc: 39.84%] [G loss: 0.927661]\n",
      "epoch:14 step:11621[D loss: 0.436534, acc: 62.50%, op_acc: 36.72%] [G loss: 0.884565]\n",
      "epoch:14 step:11622[D loss: 0.419364, acc: 57.03%, op_acc: 37.50%] [G loss: 0.856508]\n",
      "epoch:14 step:11623[D loss: 0.432699, acc: 55.47%, op_acc: 43.75%] [G loss: 0.972156]\n",
      "epoch:14 step:11624[D loss: 0.440405, acc: 58.59%, op_acc: 39.84%] [G loss: 0.883614]\n",
      "epoch:14 step:11625[D loss: 0.426900, acc: 57.81%, op_acc: 36.72%] [G loss: 0.907554]\n",
      "epoch:14 step:11626[D loss: 0.433335, acc: 62.50%, op_acc: 37.50%] [G loss: 0.860995]\n",
      "epoch:14 step:11627[D loss: 0.435952, acc: 60.16%, op_acc: 34.38%] [G loss: 0.903388]\n",
      "epoch:14 step:11628[D loss: 0.446151, acc: 62.50%, op_acc: 35.16%] [G loss: 0.840552]\n",
      "epoch:14 step:11629[D loss: 0.450501, acc: 54.69%, op_acc: 33.59%] [G loss: 0.800004]\n",
      "epoch:14 step:11630[D loss: 0.453034, acc: 53.91%, op_acc: 34.38%] [G loss: 0.932090]\n",
      "epoch:14 step:11631[D loss: 0.444558, acc: 57.81%, op_acc: 37.50%] [G loss: 0.803765]\n",
      "epoch:14 step:11632[D loss: 0.456155, acc: 54.69%, op_acc: 32.81%] [G loss: 0.904997]\n",
      "epoch:14 step:11633[D loss: 0.436873, acc: 55.47%, op_acc: 36.72%] [G loss: 0.812618]\n",
      "epoch:14 step:11634[D loss: 0.444601, acc: 55.47%, op_acc: 35.16%] [G loss: 0.894490]\n",
      "epoch:14 step:11635[D loss: 0.432761, acc: 61.72%, op_acc: 35.94%] [G loss: 0.901093]\n",
      "epoch:14 step:11636[D loss: 0.410321, acc: 61.72%, op_acc: 36.72%] [G loss: 0.911575]\n",
      "epoch:14 step:11637[D loss: 0.441097, acc: 60.94%, op_acc: 35.16%] [G loss: 0.902671]\n",
      "epoch:14 step:11638[D loss: 0.413451, acc: 53.12%, op_acc: 47.66%] [G loss: 0.857794]\n",
      "epoch:14 step:11639[D loss: 0.433398, acc: 63.28%, op_acc: 40.62%] [G loss: 0.891963]\n",
      "epoch:14 step:11640[D loss: 0.441967, acc: 61.72%, op_acc: 35.16%] [G loss: 0.878324]\n",
      "epoch:14 step:11641[D loss: 0.462003, acc: 56.25%, op_acc: 35.16%] [G loss: 0.764921]\n",
      "epoch:14 step:11642[D loss: 0.436059, acc: 57.03%, op_acc: 33.59%] [G loss: 0.820391]\n",
      "epoch:14 step:11643[D loss: 0.432690, acc: 62.50%, op_acc: 35.16%] [G loss: 0.865216]\n",
      "epoch:14 step:11644[D loss: 0.388959, acc: 69.53%, op_acc: 39.06%] [G loss: 0.856357]\n",
      "epoch:14 step:11645[D loss: 0.437297, acc: 57.81%, op_acc: 36.72%] [G loss: 0.805838]\n",
      "epoch:14 step:11646[D loss: 0.422463, acc: 64.06%, op_acc: 38.28%] [G loss: 0.934028]\n",
      "epoch:14 step:11647[D loss: 0.424018, acc: 60.94%, op_acc: 40.62%] [G loss: 0.878165]\n",
      "epoch:14 step:11648[D loss: 0.449332, acc: 57.03%, op_acc: 32.03%] [G loss: 0.816059]\n",
      "epoch:14 step:11649[D loss: 0.429339, acc: 56.25%, op_acc: 35.94%] [G loss: 0.924415]\n",
      "epoch:14 step:11650[D loss: 0.431546, acc: 53.91%, op_acc: 36.72%] [G loss: 0.838800]\n",
      "##############\n",
      "[0.85098398 0.85016932 0.81509523 0.80867816 0.80179064 0.81286776\n",
      " 0.88757011 0.83376497 0.8142857  0.85312513]\n",
      "##########\n",
      "epoch:14 step:11651[D loss: 0.404329, acc: 60.94%, op_acc: 41.41%] [G loss: 0.896163]\n",
      "epoch:14 step:11652[D loss: 0.411097, acc: 67.97%, op_acc: 42.19%] [G loss: 0.902738]\n",
      "epoch:14 step:11653[D loss: 0.423617, acc: 63.28%, op_acc: 35.94%] [G loss: 0.916446]\n",
      "epoch:14 step:11654[D loss: 0.439932, acc: 64.06%, op_acc: 32.81%] [G loss: 0.919288]\n",
      "epoch:14 step:11655[D loss: 0.412127, acc: 57.81%, op_acc: 39.84%] [G loss: 0.868497]\n",
      "epoch:14 step:11656[D loss: 0.419823, acc: 60.94%, op_acc: 40.62%] [G loss: 0.903308]\n",
      "epoch:14 step:11657[D loss: 0.427900, acc: 61.72%, op_acc: 35.94%] [G loss: 0.857920]\n",
      "epoch:14 step:11658[D loss: 0.477335, acc: 59.38%, op_acc: 28.12%] [G loss: 0.840813]\n",
      "epoch:14 step:11659[D loss: 0.441627, acc: 60.94%, op_acc: 38.28%] [G loss: 0.873700]\n",
      "epoch:14 step:11660[D loss: 0.443410, acc: 54.69%, op_acc: 39.84%] [G loss: 0.811750]\n",
      "epoch:14 step:11661[D loss: 0.435732, acc: 67.97%, op_acc: 30.47%] [G loss: 0.834267]\n",
      "epoch:14 step:11662[D loss: 0.457888, acc: 59.38%, op_acc: 32.03%] [G loss: 0.871933]\n",
      "epoch:14 step:11663[D loss: 0.411531, acc: 61.72%, op_acc: 39.84%] [G loss: 0.898118]\n",
      "epoch:14 step:11664[D loss: 0.440029, acc: 56.25%, op_acc: 35.16%] [G loss: 0.823476]\n",
      "epoch:14 step:11665[D loss: 0.415213, acc: 59.38%, op_acc: 45.31%] [G loss: 0.896783]\n",
      "epoch:14 step:11666[D loss: 0.404908, acc: 63.28%, op_acc: 38.28%] [G loss: 0.910794]\n",
      "epoch:14 step:11667[D loss: 0.440573, acc: 53.91%, op_acc: 34.38%] [G loss: 0.881229]\n",
      "epoch:14 step:11668[D loss: 0.454372, acc: 54.69%, op_acc: 37.50%] [G loss: 0.849572]\n",
      "epoch:14 step:11669[D loss: 0.451746, acc: 57.81%, op_acc: 30.47%] [G loss: 0.825941]\n",
      "epoch:14 step:11670[D loss: 0.426393, acc: 58.59%, op_acc: 35.94%] [G loss: 0.906755]\n",
      "epoch:14 step:11671[D loss: 0.426063, acc: 54.69%, op_acc: 44.53%] [G loss: 0.924720]\n",
      "epoch:14 step:11672[D loss: 0.445902, acc: 60.94%, op_acc: 32.03%] [G loss: 0.910442]\n",
      "epoch:14 step:11673[D loss: 0.431246, acc: 50.78%, op_acc: 42.19%] [G loss: 0.868483]\n",
      "epoch:14 step:11674[D loss: 0.415681, acc: 63.28%, op_acc: 40.62%] [G loss: 0.989684]\n",
      "epoch:14 step:11675[D loss: 0.420592, acc: 63.28%, op_acc: 35.16%] [G loss: 0.916958]\n",
      "epoch:14 step:11676[D loss: 0.421593, acc: 59.38%, op_acc: 40.62%] [G loss: 0.915954]\n",
      "epoch:14 step:11677[D loss: 0.426958, acc: 59.38%, op_acc: 35.16%] [G loss: 0.798419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11678[D loss: 0.389158, acc: 64.84%, op_acc: 37.50%] [G loss: 0.836449]\n",
      "epoch:14 step:11679[D loss: 0.426490, acc: 62.50%, op_acc: 40.62%] [G loss: 0.897958]\n",
      "epoch:14 step:11680[D loss: 0.422645, acc: 60.94%, op_acc: 36.72%] [G loss: 0.907282]\n",
      "epoch:14 step:11681[D loss: 0.416170, acc: 64.84%, op_acc: 36.72%] [G loss: 0.989972]\n",
      "epoch:14 step:11682[D loss: 0.436269, acc: 59.38%, op_acc: 35.94%] [G loss: 0.906558]\n",
      "epoch:14 step:11683[D loss: 0.493277, acc: 45.31%, op_acc: 35.94%] [G loss: 0.851569]\n",
      "epoch:14 step:11684[D loss: 0.455915, acc: 56.25%, op_acc: 35.16%] [G loss: 0.846802]\n",
      "epoch:14 step:11685[D loss: 0.441376, acc: 58.59%, op_acc: 42.97%] [G loss: 0.871624]\n",
      "epoch:14 step:11686[D loss: 0.433029, acc: 60.16%, op_acc: 38.28%] [G loss: 0.822325]\n",
      "epoch:14 step:11687[D loss: 0.441469, acc: 49.22%, op_acc: 37.50%] [G loss: 0.887566]\n",
      "epoch:14 step:11688[D loss: 0.421379, acc: 59.38%, op_acc: 42.19%] [G loss: 0.932418]\n",
      "epoch:14 step:11689[D loss: 0.442874, acc: 56.25%, op_acc: 39.06%] [G loss: 0.862700]\n",
      "epoch:14 step:11690[D loss: 0.426129, acc: 54.69%, op_acc: 39.84%] [G loss: 0.897231]\n",
      "epoch:14 step:11691[D loss: 0.444133, acc: 52.34%, op_acc: 35.94%] [G loss: 0.836726]\n",
      "epoch:14 step:11692[D loss: 0.413202, acc: 55.47%, op_acc: 43.75%] [G loss: 0.921491]\n",
      "epoch:14 step:11693[D loss: 0.454052, acc: 47.66%, op_acc: 33.59%] [G loss: 0.759565]\n",
      "epoch:14 step:11694[D loss: 0.440152, acc: 50.78%, op_acc: 37.50%] [G loss: 0.861168]\n",
      "epoch:14 step:11695[D loss: 0.422291, acc: 54.69%, op_acc: 42.97%] [G loss: 0.859731]\n",
      "epoch:14 step:11696[D loss: 0.444148, acc: 58.59%, op_acc: 35.94%] [G loss: 0.869225]\n",
      "epoch:14 step:11697[D loss: 0.470185, acc: 55.47%, op_acc: 31.25%] [G loss: 0.785727]\n",
      "epoch:14 step:11698[D loss: 0.415812, acc: 61.72%, op_acc: 35.94%] [G loss: 0.841962]\n",
      "epoch:14 step:11699[D loss: 0.434701, acc: 56.25%, op_acc: 39.06%] [G loss: 0.873568]\n",
      "epoch:14 step:11700[D loss: 0.442393, acc: 54.69%, op_acc: 33.59%] [G loss: 0.864881]\n",
      "##############\n",
      "[0.84448544 0.86350909 0.80932513 0.81007921 0.78326693 0.81831123\n",
      " 0.88601709 0.84068643 0.84620221 0.83399101]\n",
      "##########\n",
      "epoch:14 step:11701[D loss: 0.416892, acc: 65.62%, op_acc: 35.16%] [G loss: 0.861082]\n",
      "epoch:14 step:11702[D loss: 0.431064, acc: 57.03%, op_acc: 39.84%] [G loss: 0.851093]\n",
      "epoch:14 step:11703[D loss: 0.423822, acc: 60.94%, op_acc: 40.62%] [G loss: 0.744696]\n",
      "epoch:14 step:11704[D loss: 0.434343, acc: 54.69%, op_acc: 38.28%] [G loss: 0.832500]\n",
      "epoch:14 step:11705[D loss: 0.449376, acc: 57.03%, op_acc: 32.81%] [G loss: 0.936231]\n",
      "epoch:14 step:11706[D loss: 0.462128, acc: 53.12%, op_acc: 35.94%] [G loss: 0.846935]\n",
      "epoch:14 step:11707[D loss: 0.439613, acc: 58.59%, op_acc: 38.28%] [G loss: 0.945151]\n",
      "epoch:14 step:11708[D loss: 0.422743, acc: 61.72%, op_acc: 35.16%] [G loss: 0.859048]\n",
      "epoch:14 step:11709[D loss: 0.428723, acc: 60.16%, op_acc: 35.94%] [G loss: 0.894821]\n",
      "epoch:14 step:11710[D loss: 0.423777, acc: 57.81%, op_acc: 37.50%] [G loss: 0.802686]\n",
      "epoch:14 step:11711[D loss: 0.449592, acc: 62.50%, op_acc: 30.47%] [G loss: 0.832128]\n",
      "epoch:14 step:11712[D loss: 0.420506, acc: 59.38%, op_acc: 42.97%] [G loss: 0.861024]\n",
      "epoch:14 step:11713[D loss: 0.424552, acc: 63.28%, op_acc: 39.06%] [G loss: 0.825949]\n",
      "epoch:14 step:11714[D loss: 0.436205, acc: 57.81%, op_acc: 34.38%] [G loss: 0.854404]\n",
      "epoch:14 step:11715[D loss: 0.425020, acc: 64.84%, op_acc: 33.59%] [G loss: 0.831298]\n",
      "epoch:15 step:11716[D loss: 0.406433, acc: 64.06%, op_acc: 43.75%] [G loss: 0.847481]\n",
      "epoch:15 step:11717[D loss: 0.425922, acc: 60.94%, op_acc: 37.50%] [G loss: 0.806330]\n",
      "epoch:15 step:11718[D loss: 0.431211, acc: 62.50%, op_acc: 35.94%] [G loss: 0.827989]\n",
      "epoch:15 step:11719[D loss: 0.442197, acc: 53.12%, op_acc: 39.06%] [G loss: 0.875903]\n",
      "epoch:15 step:11720[D loss: 0.421244, acc: 60.94%, op_acc: 42.97%] [G loss: 0.885094]\n",
      "epoch:15 step:11721[D loss: 0.425281, acc: 55.47%, op_acc: 38.28%] [G loss: 0.971573]\n",
      "epoch:15 step:11722[D loss: 0.434834, acc: 58.59%, op_acc: 39.06%] [G loss: 0.879315]\n",
      "epoch:15 step:11723[D loss: 0.426722, acc: 66.41%, op_acc: 41.41%] [G loss: 0.865602]\n",
      "epoch:15 step:11724[D loss: 0.422137, acc: 60.94%, op_acc: 42.19%] [G loss: 0.900043]\n",
      "epoch:15 step:11725[D loss: 0.434810, acc: 60.16%, op_acc: 35.16%] [G loss: 0.849557]\n",
      "epoch:15 step:11726[D loss: 0.444900, acc: 57.81%, op_acc: 42.97%] [G loss: 0.818521]\n",
      "epoch:15 step:11727[D loss: 0.423124, acc: 57.81%, op_acc: 35.94%] [G loss: 0.941984]\n",
      "epoch:15 step:11728[D loss: 0.428339, acc: 61.72%, op_acc: 35.16%] [G loss: 0.848915]\n",
      "epoch:15 step:11729[D loss: 0.443040, acc: 59.38%, op_acc: 37.50%] [G loss: 0.947473]\n",
      "epoch:15 step:11730[D loss: 0.453979, acc: 53.91%, op_acc: 35.94%] [G loss: 0.891668]\n",
      "epoch:15 step:11731[D loss: 0.409503, acc: 58.59%, op_acc: 39.84%] [G loss: 0.898844]\n",
      "epoch:15 step:11732[D loss: 0.423525, acc: 62.50%, op_acc: 41.41%] [G loss: 1.012027]\n",
      "epoch:15 step:11733[D loss: 0.408195, acc: 64.84%, op_acc: 41.41%] [G loss: 0.898796]\n",
      "epoch:15 step:11734[D loss: 0.416400, acc: 59.38%, op_acc: 36.72%] [G loss: 0.912510]\n",
      "epoch:15 step:11735[D loss: 0.402967, acc: 61.72%, op_acc: 42.97%] [G loss: 0.889285]\n",
      "epoch:15 step:11736[D loss: 0.485257, acc: 55.47%, op_acc: 35.16%] [G loss: 0.894223]\n",
      "epoch:15 step:11737[D loss: 0.429958, acc: 58.59%, op_acc: 36.72%] [G loss: 0.835817]\n",
      "epoch:15 step:11738[D loss: 0.444140, acc: 58.59%, op_acc: 34.38%] [G loss: 0.890765]\n",
      "epoch:15 step:11739[D loss: 0.447873, acc: 60.16%, op_acc: 31.25%] [G loss: 0.863895]\n",
      "epoch:15 step:11740[D loss: 0.430482, acc: 62.50%, op_acc: 35.94%] [G loss: 0.837054]\n",
      "epoch:15 step:11741[D loss: 0.391683, acc: 66.41%, op_acc: 45.31%] [G loss: 0.891456]\n",
      "epoch:15 step:11742[D loss: 0.430098, acc: 56.25%, op_acc: 38.28%] [G loss: 0.853408]\n",
      "epoch:15 step:11743[D loss: 0.417147, acc: 58.59%, op_acc: 36.72%] [G loss: 0.917467]\n",
      "epoch:15 step:11744[D loss: 0.418371, acc: 63.28%, op_acc: 39.06%] [G loss: 0.949314]\n",
      "epoch:15 step:11745[D loss: 0.409277, acc: 63.28%, op_acc: 40.62%] [G loss: 0.941847]\n",
      "epoch:15 step:11746[D loss: 0.436434, acc: 64.84%, op_acc: 32.03%] [G loss: 0.895645]\n",
      "epoch:15 step:11747[D loss: 0.435364, acc: 64.84%, op_acc: 34.38%] [G loss: 0.866852]\n",
      "epoch:15 step:11748[D loss: 0.443745, acc: 54.69%, op_acc: 39.84%] [G loss: 0.806327]\n",
      "epoch:15 step:11749[D loss: 0.441722, acc: 45.31%, op_acc: 36.72%] [G loss: 0.900553]\n",
      "epoch:15 step:11750[D loss: 0.417176, acc: 63.28%, op_acc: 35.94%] [G loss: 0.888689]\n",
      "##############\n",
      "[0.85726635 0.85746994 0.82268211 0.80089065 0.77686445 0.8330981\n",
      " 0.90269525 0.82993257 0.80388373 0.83310608]\n",
      "##########\n",
      "epoch:15 step:11751[D loss: 0.439412, acc: 53.12%, op_acc: 36.72%] [G loss: 0.867491]\n",
      "epoch:15 step:11752[D loss: 0.403821, acc: 64.06%, op_acc: 42.19%] [G loss: 0.904567]\n",
      "epoch:15 step:11753[D loss: 0.415872, acc: 64.84%, op_acc: 37.50%] [G loss: 0.940158]\n",
      "epoch:15 step:11754[D loss: 0.407987, acc: 61.72%, op_acc: 38.28%] [G loss: 0.835106]\n",
      "epoch:15 step:11755[D loss: 0.461813, acc: 58.59%, op_acc: 28.91%] [G loss: 0.837124]\n",
      "epoch:15 step:11756[D loss: 0.412105, acc: 59.38%, op_acc: 41.41%] [G loss: 0.893671]\n",
      "epoch:15 step:11757[D loss: 0.413151, acc: 53.91%, op_acc: 42.19%] [G loss: 0.920853]\n",
      "epoch:15 step:11758[D loss: 0.430436, acc: 61.72%, op_acc: 36.72%] [G loss: 0.861406]\n",
      "epoch:15 step:11759[D loss: 0.467076, acc: 51.56%, op_acc: 33.59%] [G loss: 0.747437]\n",
      "epoch:15 step:11760[D loss: 0.407950, acc: 67.97%, op_acc: 41.41%] [G loss: 0.872838]\n",
      "epoch:15 step:11761[D loss: 0.452325, acc: 53.12%, op_acc: 33.59%] [G loss: 0.791527]\n",
      "epoch:15 step:11762[D loss: 0.422875, acc: 69.53%, op_acc: 35.16%] [G loss: 0.900251]\n",
      "epoch:15 step:11763[D loss: 0.444163, acc: 61.72%, op_acc: 34.38%] [G loss: 0.902950]\n",
      "epoch:15 step:11764[D loss: 0.430757, acc: 59.38%, op_acc: 36.72%] [G loss: 0.860346]\n",
      "epoch:15 step:11765[D loss: 0.443650, acc: 57.81%, op_acc: 39.06%] [G loss: 0.886968]\n",
      "epoch:15 step:11766[D loss: 0.394339, acc: 76.56%, op_acc: 34.38%] [G loss: 0.896273]\n",
      "epoch:15 step:11767[D loss: 0.447014, acc: 55.47%, op_acc: 32.81%] [G loss: 0.854361]\n",
      "epoch:15 step:11768[D loss: 0.458497, acc: 61.72%, op_acc: 32.81%] [G loss: 0.799202]\n",
      "epoch:15 step:11769[D loss: 0.446216, acc: 58.59%, op_acc: 37.50%] [G loss: 0.871094]\n",
      "epoch:15 step:11770[D loss: 0.421752, acc: 60.94%, op_acc: 39.06%] [G loss: 0.824184]\n",
      "epoch:15 step:11771[D loss: 0.414396, acc: 62.50%, op_acc: 40.62%] [G loss: 0.898924]\n",
      "epoch:15 step:11772[D loss: 0.415305, acc: 62.50%, op_acc: 37.50%] [G loss: 0.935347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11773[D loss: 0.397617, acc: 65.62%, op_acc: 42.19%] [G loss: 0.886990]\n",
      "epoch:15 step:11774[D loss: 0.428680, acc: 57.81%, op_acc: 35.16%] [G loss: 0.884077]\n",
      "epoch:15 step:11775[D loss: 0.420434, acc: 61.72%, op_acc: 35.94%] [G loss: 0.846079]\n",
      "epoch:15 step:11776[D loss: 0.453526, acc: 59.38%, op_acc: 36.72%] [G loss: 0.908558]\n",
      "epoch:15 step:11777[D loss: 0.421482, acc: 68.75%, op_acc: 37.50%] [G loss: 0.878262]\n",
      "epoch:15 step:11778[D loss: 0.443674, acc: 54.69%, op_acc: 38.28%] [G loss: 0.864910]\n",
      "epoch:15 step:11779[D loss: 0.410476, acc: 57.81%, op_acc: 39.84%] [G loss: 0.903690]\n",
      "epoch:15 step:11780[D loss: 0.427815, acc: 56.25%, op_acc: 32.03%] [G loss: 0.951470]\n",
      "epoch:15 step:11781[D loss: 0.468965, acc: 46.88%, op_acc: 31.25%] [G loss: 0.924925]\n",
      "epoch:15 step:11782[D loss: 0.426393, acc: 65.62%, op_acc: 39.84%] [G loss: 0.890115]\n",
      "epoch:15 step:11783[D loss: 0.419788, acc: 64.06%, op_acc: 43.75%] [G loss: 0.888207]\n",
      "epoch:15 step:11784[D loss: 0.386728, acc: 67.19%, op_acc: 41.41%] [G loss: 0.939970]\n",
      "epoch:15 step:11785[D loss: 0.440779, acc: 65.62%, op_acc: 34.38%] [G loss: 0.876499]\n",
      "epoch:15 step:11786[D loss: 0.470446, acc: 56.25%, op_acc: 35.16%] [G loss: 0.885738]\n",
      "epoch:15 step:11787[D loss: 0.423346, acc: 54.69%, op_acc: 42.97%] [G loss: 0.911563]\n",
      "epoch:15 step:11788[D loss: 0.412046, acc: 69.53%, op_acc: 39.84%] [G loss: 0.904624]\n",
      "epoch:15 step:11789[D loss: 0.420257, acc: 52.34%, op_acc: 39.84%] [G loss: 0.885516]\n",
      "epoch:15 step:11790[D loss: 0.427341, acc: 59.38%, op_acc: 35.94%] [G loss: 0.960354]\n",
      "epoch:15 step:11791[D loss: 0.481639, acc: 46.09%, op_acc: 35.16%] [G loss: 0.879470]\n",
      "epoch:15 step:11792[D loss: 0.441405, acc: 56.25%, op_acc: 31.25%] [G loss: 0.793508]\n",
      "epoch:15 step:11793[D loss: 0.471142, acc: 53.12%, op_acc: 34.38%] [G loss: 0.888162]\n",
      "epoch:15 step:11794[D loss: 0.431738, acc: 55.47%, op_acc: 39.06%] [G loss: 0.882914]\n",
      "epoch:15 step:11795[D loss: 0.473928, acc: 56.25%, op_acc: 32.03%] [G loss: 0.851871]\n",
      "epoch:15 step:11796[D loss: 0.435579, acc: 64.06%, op_acc: 30.47%] [G loss: 0.929168]\n",
      "epoch:15 step:11797[D loss: 0.395466, acc: 64.06%, op_acc: 39.84%] [G loss: 0.830497]\n",
      "epoch:15 step:11798[D loss: 0.437292, acc: 53.91%, op_acc: 36.72%] [G loss: 0.856420]\n",
      "epoch:15 step:11799[D loss: 0.420915, acc: 67.19%, op_acc: 42.97%] [G loss: 0.952115]\n",
      "epoch:15 step:11800[D loss: 0.457727, acc: 54.69%, op_acc: 31.25%] [G loss: 0.881989]\n",
      "##############\n",
      "[0.82459803 0.85573882 0.81759507 0.79477891 0.79592615 0.83396301\n",
      " 0.91372705 0.82543792 0.81810817 0.82735732]\n",
      "##########\n",
      "epoch:15 step:11801[D loss: 0.442471, acc: 61.72%, op_acc: 35.94%] [G loss: 0.997888]\n",
      "epoch:15 step:11802[D loss: 0.454255, acc: 58.59%, op_acc: 34.38%] [G loss: 0.820310]\n",
      "epoch:15 step:11803[D loss: 0.445506, acc: 54.69%, op_acc: 32.81%] [G loss: 0.844460]\n",
      "epoch:15 step:11804[D loss: 0.461653, acc: 48.44%, op_acc: 37.50%] [G loss: 0.882079]\n",
      "epoch:15 step:11805[D loss: 0.432759, acc: 62.50%, op_acc: 39.06%] [G loss: 0.869367]\n",
      "epoch:15 step:11806[D loss: 0.430954, acc: 59.38%, op_acc: 32.81%] [G loss: 0.857775]\n",
      "epoch:15 step:11807[D loss: 0.415775, acc: 63.28%, op_acc: 30.47%] [G loss: 0.899001]\n",
      "epoch:15 step:11808[D loss: 0.415517, acc: 64.84%, op_acc: 41.41%] [G loss: 0.851901]\n",
      "epoch:15 step:11809[D loss: 0.410784, acc: 65.62%, op_acc: 40.62%] [G loss: 0.890031]\n",
      "epoch:15 step:11810[D loss: 0.444929, acc: 48.44%, op_acc: 40.62%] [G loss: 0.839762]\n",
      "epoch:15 step:11811[D loss: 0.457151, acc: 55.47%, op_acc: 35.16%] [G loss: 0.900377]\n",
      "epoch:15 step:11812[D loss: 0.441461, acc: 55.47%, op_acc: 38.28%] [G loss: 0.825426]\n",
      "epoch:15 step:11813[D loss: 0.417948, acc: 60.16%, op_acc: 37.50%] [G loss: 0.873755]\n",
      "epoch:15 step:11814[D loss: 0.432876, acc: 56.25%, op_acc: 40.62%] [G loss: 0.805766]\n",
      "epoch:15 step:11815[D loss: 0.433839, acc: 57.81%, op_acc: 37.50%] [G loss: 0.830429]\n",
      "epoch:15 step:11816[D loss: 0.435380, acc: 60.16%, op_acc: 38.28%] [G loss: 0.868350]\n",
      "epoch:15 step:11817[D loss: 0.433715, acc: 56.25%, op_acc: 36.72%] [G loss: 0.898478]\n",
      "epoch:15 step:11818[D loss: 0.427256, acc: 65.62%, op_acc: 37.50%] [G loss: 0.964189]\n",
      "epoch:15 step:11819[D loss: 0.431324, acc: 56.25%, op_acc: 39.06%] [G loss: 0.840276]\n",
      "epoch:15 step:11820[D loss: 0.428135, acc: 57.03%, op_acc: 39.84%] [G loss: 0.909491]\n",
      "epoch:15 step:11821[D loss: 0.414406, acc: 64.84%, op_acc: 42.97%] [G loss: 0.835073]\n",
      "epoch:15 step:11822[D loss: 0.424228, acc: 60.94%, op_acc: 37.50%] [G loss: 0.882120]\n",
      "epoch:15 step:11823[D loss: 0.464886, acc: 50.78%, op_acc: 34.38%] [G loss: 0.858843]\n",
      "epoch:15 step:11824[D loss: 0.431584, acc: 54.69%, op_acc: 37.50%] [G loss: 0.901668]\n",
      "epoch:15 step:11825[D loss: 0.439393, acc: 53.91%, op_acc: 35.94%] [G loss: 0.878411]\n",
      "epoch:15 step:11826[D loss: 0.440118, acc: 69.53%, op_acc: 26.56%] [G loss: 0.881288]\n",
      "epoch:15 step:11827[D loss: 0.390452, acc: 64.06%, op_acc: 42.97%] [G loss: 0.906976]\n",
      "epoch:15 step:11828[D loss: 0.419491, acc: 68.75%, op_acc: 39.06%] [G loss: 0.878892]\n",
      "epoch:15 step:11829[D loss: 0.404694, acc: 59.38%, op_acc: 42.19%] [G loss: 0.889822]\n",
      "epoch:15 step:11830[D loss: 0.421983, acc: 58.59%, op_acc: 37.50%] [G loss: 0.859815]\n",
      "epoch:15 step:11831[D loss: 0.456669, acc: 60.16%, op_acc: 34.38%] [G loss: 0.885759]\n",
      "epoch:15 step:11832[D loss: 0.443157, acc: 59.38%, op_acc: 35.16%] [G loss: 0.867731]\n",
      "epoch:15 step:11833[D loss: 0.438227, acc: 57.03%, op_acc: 36.72%] [G loss: 0.826983]\n",
      "epoch:15 step:11834[D loss: 0.416440, acc: 64.84%, op_acc: 35.94%] [G loss: 0.888078]\n",
      "epoch:15 step:11835[D loss: 0.433476, acc: 56.25%, op_acc: 37.50%] [G loss: 0.866654]\n",
      "epoch:15 step:11836[D loss: 0.419930, acc: 64.06%, op_acc: 36.72%] [G loss: 0.873130]\n",
      "epoch:15 step:11837[D loss: 0.452296, acc: 48.44%, op_acc: 32.81%] [G loss: 0.812687]\n",
      "epoch:15 step:11838[D loss: 0.459880, acc: 53.91%, op_acc: 35.94%] [G loss: 0.830010]\n",
      "epoch:15 step:11839[D loss: 0.437534, acc: 55.47%, op_acc: 39.84%] [G loss: 0.855468]\n",
      "epoch:15 step:11840[D loss: 0.450430, acc: 51.56%, op_acc: 36.72%] [G loss: 0.846108]\n",
      "epoch:15 step:11841[D loss: 0.456250, acc: 52.34%, op_acc: 38.28%] [G loss: 0.859416]\n",
      "epoch:15 step:11842[D loss: 0.464810, acc: 56.25%, op_acc: 35.16%] [G loss: 0.905154]\n",
      "epoch:15 step:11843[D loss: 0.423609, acc: 62.50%, op_acc: 35.16%] [G loss: 0.875382]\n",
      "epoch:15 step:11844[D loss: 0.472708, acc: 50.00%, op_acc: 35.94%] [G loss: 0.877365]\n",
      "epoch:15 step:11845[D loss: 0.392222, acc: 62.50%, op_acc: 44.53%] [G loss: 0.969597]\n",
      "epoch:15 step:11846[D loss: 0.405089, acc: 65.62%, op_acc: 38.28%] [G loss: 0.845325]\n",
      "epoch:15 step:11847[D loss: 0.415438, acc: 60.16%, op_acc: 41.41%] [G loss: 0.843844]\n",
      "epoch:15 step:11848[D loss: 0.471980, acc: 50.00%, op_acc: 31.25%] [G loss: 0.913342]\n",
      "epoch:15 step:11849[D loss: 0.437474, acc: 58.59%, op_acc: 36.72%] [G loss: 0.900196]\n",
      "epoch:15 step:11850[D loss: 0.447305, acc: 54.69%, op_acc: 38.28%] [G loss: 0.915068]\n",
      "##############\n",
      "[0.87199222 0.86669555 0.78987168 0.80665224 0.79273276 0.82748016\n",
      " 0.87613021 0.81276738 0.82774552 0.82573262]\n",
      "##########\n",
      "epoch:15 step:11851[D loss: 0.443420, acc: 56.25%, op_acc: 36.72%] [G loss: 0.843234]\n",
      "epoch:15 step:11852[D loss: 0.436884, acc: 57.03%, op_acc: 35.16%] [G loss: 0.860813]\n",
      "epoch:15 step:11853[D loss: 0.404771, acc: 58.59%, op_acc: 39.84%] [G loss: 0.865128]\n",
      "epoch:15 step:11854[D loss: 0.395567, acc: 66.41%, op_acc: 42.19%] [G loss: 0.962475]\n",
      "epoch:15 step:11855[D loss: 0.432494, acc: 61.72%, op_acc: 37.50%] [G loss: 0.885827]\n",
      "epoch:15 step:11856[D loss: 0.432858, acc: 64.84%, op_acc: 34.38%] [G loss: 0.830651]\n",
      "epoch:15 step:11857[D loss: 0.417806, acc: 61.72%, op_acc: 39.06%] [G loss: 0.898599]\n",
      "epoch:15 step:11858[D loss: 0.440012, acc: 61.72%, op_acc: 37.50%] [G loss: 0.859303]\n",
      "epoch:15 step:11859[D loss: 0.429323, acc: 60.94%, op_acc: 35.94%] [G loss: 0.908040]\n",
      "epoch:15 step:11860[D loss: 0.421881, acc: 64.84%, op_acc: 42.19%] [G loss: 0.913050]\n",
      "epoch:15 step:11861[D loss: 0.461038, acc: 53.12%, op_acc: 35.94%] [G loss: 0.802294]\n",
      "epoch:15 step:11862[D loss: 0.412843, acc: 63.28%, op_acc: 42.97%] [G loss: 0.928735]\n",
      "epoch:15 step:11863[D loss: 0.418509, acc: 67.97%, op_acc: 36.72%] [G loss: 0.907868]\n",
      "epoch:15 step:11864[D loss: 0.432757, acc: 55.47%, op_acc: 36.72%] [G loss: 0.807659]\n",
      "epoch:15 step:11865[D loss: 0.431585, acc: 62.50%, op_acc: 38.28%] [G loss: 0.827942]\n",
      "epoch:15 step:11866[D loss: 0.436347, acc: 57.81%, op_acc: 37.50%] [G loss: 0.805523]\n",
      "epoch:15 step:11867[D loss: 0.431967, acc: 57.03%, op_acc: 35.94%] [G loss: 0.799497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11868[D loss: 0.438602, acc: 59.38%, op_acc: 39.06%] [G loss: 0.865062]\n",
      "epoch:15 step:11869[D loss: 0.445981, acc: 55.47%, op_acc: 32.03%] [G loss: 0.828443]\n",
      "epoch:15 step:11870[D loss: 0.429600, acc: 56.25%, op_acc: 42.97%] [G loss: 0.889659]\n",
      "epoch:15 step:11871[D loss: 0.436632, acc: 54.69%, op_acc: 33.59%] [G loss: 0.831879]\n",
      "epoch:15 step:11872[D loss: 0.425762, acc: 57.03%, op_acc: 37.50%] [G loss: 0.843148]\n",
      "epoch:15 step:11873[D loss: 0.391860, acc: 65.62%, op_acc: 39.06%] [G loss: 0.896112]\n",
      "epoch:15 step:11874[D loss: 0.392815, acc: 66.41%, op_acc: 38.28%] [G loss: 0.969606]\n",
      "epoch:15 step:11875[D loss: 0.451286, acc: 59.38%, op_acc: 34.38%] [G loss: 0.881058]\n",
      "epoch:15 step:11876[D loss: 0.428806, acc: 58.59%, op_acc: 39.06%] [G loss: 0.885064]\n",
      "epoch:15 step:11877[D loss: 0.417443, acc: 60.16%, op_acc: 42.97%] [G loss: 0.962274]\n",
      "epoch:15 step:11878[D loss: 0.470132, acc: 58.59%, op_acc: 31.25%] [G loss: 0.843456]\n",
      "epoch:15 step:11879[D loss: 0.437097, acc: 62.50%, op_acc: 34.38%] [G loss: 0.952331]\n",
      "epoch:15 step:11880[D loss: 0.411575, acc: 60.16%, op_acc: 40.62%] [G loss: 0.872641]\n",
      "epoch:15 step:11881[D loss: 0.441432, acc: 59.38%, op_acc: 32.81%] [G loss: 0.884328]\n",
      "epoch:15 step:11882[D loss: 0.420594, acc: 58.59%, op_acc: 42.19%] [G loss: 0.919868]\n",
      "epoch:15 step:11883[D loss: 0.461290, acc: 53.12%, op_acc: 38.28%] [G loss: 0.873076]\n",
      "epoch:15 step:11884[D loss: 0.451584, acc: 51.56%, op_acc: 34.38%] [G loss: 0.879817]\n",
      "epoch:15 step:11885[D loss: 0.447263, acc: 56.25%, op_acc: 38.28%] [G loss: 0.879949]\n",
      "epoch:15 step:11886[D loss: 0.466938, acc: 53.12%, op_acc: 36.72%] [G loss: 0.884261]\n",
      "epoch:15 step:11887[D loss: 0.425331, acc: 57.03%, op_acc: 35.94%] [G loss: 0.912428]\n",
      "epoch:15 step:11888[D loss: 0.445937, acc: 59.38%, op_acc: 39.06%] [G loss: 0.911859]\n",
      "epoch:15 step:11889[D loss: 0.484719, acc: 46.09%, op_acc: 29.69%] [G loss: 0.839860]\n",
      "epoch:15 step:11890[D loss: 0.412939, acc: 60.94%, op_acc: 39.84%] [G loss: 0.900593]\n",
      "epoch:15 step:11891[D loss: 0.432412, acc: 61.72%, op_acc: 35.16%] [G loss: 0.853446]\n",
      "epoch:15 step:11892[D loss: 0.412531, acc: 61.72%, op_acc: 39.84%] [G loss: 0.898949]\n",
      "epoch:15 step:11893[D loss: 0.443289, acc: 53.91%, op_acc: 37.50%] [G loss: 0.875224]\n",
      "epoch:15 step:11894[D loss: 0.396997, acc: 65.62%, op_acc: 45.31%] [G loss: 0.883033]\n",
      "epoch:15 step:11895[D loss: 0.437509, acc: 62.50%, op_acc: 33.59%] [G loss: 0.817924]\n",
      "epoch:15 step:11896[D loss: 0.418030, acc: 64.84%, op_acc: 32.81%] [G loss: 0.936291]\n",
      "epoch:15 step:11897[D loss: 0.396501, acc: 66.41%, op_acc: 36.72%] [G loss: 0.923546]\n",
      "epoch:15 step:11898[D loss: 0.411005, acc: 63.28%, op_acc: 37.50%] [G loss: 0.912639]\n",
      "epoch:15 step:11899[D loss: 0.411840, acc: 57.03%, op_acc: 42.19%] [G loss: 0.911533]\n",
      "epoch:15 step:11900[D loss: 0.438311, acc: 65.62%, op_acc: 30.47%] [G loss: 0.923367]\n",
      "##############\n",
      "[0.85898346 0.86104732 0.81716379 0.80748125 0.78419277 0.83998799\n",
      " 0.87569645 0.83382472 0.80095578 0.82716337]\n",
      "##########\n",
      "epoch:15 step:11901[D loss: 0.468314, acc: 48.44%, op_acc: 34.38%] [G loss: 0.754310]\n",
      "epoch:15 step:11902[D loss: 0.460484, acc: 52.34%, op_acc: 35.16%] [G loss: 0.867714]\n",
      "epoch:15 step:11903[D loss: 0.426274, acc: 57.03%, op_acc: 38.28%] [G loss: 0.917065]\n",
      "epoch:15 step:11904[D loss: 0.443394, acc: 56.25%, op_acc: 36.72%] [G loss: 0.888670]\n",
      "epoch:15 step:11905[D loss: 0.461848, acc: 50.78%, op_acc: 35.94%] [G loss: 0.868410]\n",
      "epoch:15 step:11906[D loss: 0.397047, acc: 64.06%, op_acc: 40.62%] [G loss: 0.907587]\n",
      "epoch:15 step:11907[D loss: 0.400394, acc: 67.19%, op_acc: 35.94%] [G loss: 0.804094]\n",
      "epoch:15 step:11908[D loss: 0.465799, acc: 57.81%, op_acc: 32.03%] [G loss: 0.843128]\n",
      "epoch:15 step:11909[D loss: 0.428046, acc: 60.94%, op_acc: 35.94%] [G loss: 0.897396]\n",
      "epoch:15 step:11910[D loss: 0.454802, acc: 55.47%, op_acc: 34.38%] [G loss: 0.867485]\n",
      "epoch:15 step:11911[D loss: 0.423318, acc: 64.06%, op_acc: 32.03%] [G loss: 0.879152]\n",
      "epoch:15 step:11912[D loss: 0.443204, acc: 60.16%, op_acc: 35.94%] [G loss: 0.845439]\n",
      "epoch:15 step:11913[D loss: 0.428943, acc: 60.94%, op_acc: 39.06%] [G loss: 0.882158]\n",
      "epoch:15 step:11914[D loss: 0.451926, acc: 53.12%, op_acc: 38.28%] [G loss: 0.793400]\n",
      "epoch:15 step:11915[D loss: 0.412066, acc: 66.41%, op_acc: 38.28%] [G loss: 0.923848]\n",
      "epoch:15 step:11916[D loss: 0.442846, acc: 55.47%, op_acc: 35.16%] [G loss: 0.880049]\n",
      "epoch:15 step:11917[D loss: 0.442887, acc: 53.91%, op_acc: 37.50%] [G loss: 0.810515]\n",
      "epoch:15 step:11918[D loss: 0.433894, acc: 59.38%, op_acc: 38.28%] [G loss: 0.870757]\n",
      "epoch:15 step:11919[D loss: 0.438435, acc: 62.50%, op_acc: 34.38%] [G loss: 0.917267]\n",
      "epoch:15 step:11920[D loss: 0.458777, acc: 52.34%, op_acc: 35.16%] [G loss: 0.828658]\n",
      "epoch:15 step:11921[D loss: 0.444463, acc: 58.59%, op_acc: 36.72%] [G loss: 0.908981]\n",
      "epoch:15 step:11922[D loss: 0.418147, acc: 64.06%, op_acc: 36.72%] [G loss: 0.888024]\n",
      "epoch:15 step:11923[D loss: 0.438483, acc: 57.81%, op_acc: 34.38%] [G loss: 0.859442]\n",
      "epoch:15 step:11924[D loss: 0.412549, acc: 62.50%, op_acc: 42.97%] [G loss: 0.854845]\n",
      "epoch:15 step:11925[D loss: 0.483095, acc: 56.25%, op_acc: 34.38%] [G loss: 0.939152]\n",
      "epoch:15 step:11926[D loss: 0.423729, acc: 60.16%, op_acc: 37.50%] [G loss: 0.890172]\n",
      "epoch:15 step:11927[D loss: 0.424217, acc: 60.16%, op_acc: 41.41%] [G loss: 0.854584]\n",
      "epoch:15 step:11928[D loss: 0.436063, acc: 53.91%, op_acc: 36.72%] [G loss: 0.882858]\n",
      "epoch:15 step:11929[D loss: 0.449525, acc: 57.03%, op_acc: 38.28%] [G loss: 0.855114]\n",
      "epoch:15 step:11930[D loss: 0.472850, acc: 54.69%, op_acc: 29.69%] [G loss: 0.965849]\n",
      "epoch:15 step:11931[D loss: 0.434292, acc: 64.84%, op_acc: 34.38%] [G loss: 0.826839]\n",
      "epoch:15 step:11932[D loss: 0.399734, acc: 69.53%, op_acc: 36.72%] [G loss: 0.841921]\n",
      "epoch:15 step:11933[D loss: 0.423990, acc: 60.16%, op_acc: 39.06%] [G loss: 0.903659]\n",
      "epoch:15 step:11934[D loss: 0.399351, acc: 70.31%, op_acc: 45.31%] [G loss: 0.874488]\n",
      "epoch:15 step:11935[D loss: 0.442172, acc: 55.47%, op_acc: 39.06%] [G loss: 0.867265]\n",
      "epoch:15 step:11936[D loss: 0.425571, acc: 61.72%, op_acc: 34.38%] [G loss: 0.869889]\n",
      "epoch:15 step:11937[D loss: 0.442399, acc: 62.50%, op_acc: 37.50%] [G loss: 0.886836]\n",
      "epoch:15 step:11938[D loss: 0.411099, acc: 64.84%, op_acc: 42.97%] [G loss: 0.926401]\n",
      "epoch:15 step:11939[D loss: 0.443685, acc: 55.47%, op_acc: 33.59%] [G loss: 0.861677]\n",
      "epoch:15 step:11940[D loss: 0.430265, acc: 60.16%, op_acc: 41.41%] [G loss: 0.800151]\n",
      "epoch:15 step:11941[D loss: 0.440506, acc: 57.81%, op_acc: 39.06%] [G loss: 0.874061]\n",
      "epoch:15 step:11942[D loss: 0.457820, acc: 55.47%, op_acc: 36.72%] [G loss: 0.846511]\n",
      "epoch:15 step:11943[D loss: 0.422253, acc: 57.81%, op_acc: 40.62%] [G loss: 0.845897]\n",
      "epoch:15 step:11944[D loss: 0.434590, acc: 58.59%, op_acc: 37.50%] [G loss: 0.783463]\n",
      "epoch:15 step:11945[D loss: 0.443822, acc: 58.59%, op_acc: 33.59%] [G loss: 0.950538]\n",
      "epoch:15 step:11946[D loss: 0.410594, acc: 60.94%, op_acc: 41.41%] [G loss: 0.871430]\n",
      "epoch:15 step:11947[D loss: 0.427431, acc: 63.28%, op_acc: 35.94%] [G loss: 0.913111]\n",
      "epoch:15 step:11948[D loss: 0.441570, acc: 54.69%, op_acc: 38.28%] [G loss: 0.917350]\n",
      "epoch:15 step:11949[D loss: 0.466354, acc: 58.59%, op_acc: 35.16%] [G loss: 0.881348]\n",
      "epoch:15 step:11950[D loss: 0.446196, acc: 53.12%, op_acc: 39.06%] [G loss: 0.969571]\n",
      "##############\n",
      "[0.83495834 0.87354711 0.81359976 0.78396092 0.81089973 0.82613602\n",
      " 0.86905019 0.84057388 0.81982807 0.84066599]\n",
      "##########\n",
      "epoch:15 step:11951[D loss: 0.455966, acc: 54.69%, op_acc: 36.72%] [G loss: 0.913910]\n",
      "epoch:15 step:11952[D loss: 0.397541, acc: 69.53%, op_acc: 40.62%] [G loss: 0.875096]\n",
      "epoch:15 step:11953[D loss: 0.415972, acc: 63.28%, op_acc: 35.94%] [G loss: 0.940118]\n",
      "epoch:15 step:11954[D loss: 0.415375, acc: 60.94%, op_acc: 39.06%] [G loss: 0.884395]\n",
      "epoch:15 step:11955[D loss: 0.447093, acc: 53.12%, op_acc: 37.50%] [G loss: 0.885423]\n",
      "epoch:15 step:11956[D loss: 0.433298, acc: 59.38%, op_acc: 35.94%] [G loss: 0.873883]\n",
      "epoch:15 step:11957[D loss: 0.402797, acc: 60.16%, op_acc: 42.19%] [G loss: 0.916496]\n",
      "epoch:15 step:11958[D loss: 0.433365, acc: 51.56%, op_acc: 37.50%] [G loss: 0.898080]\n",
      "epoch:15 step:11959[D loss: 0.432513, acc: 59.38%, op_acc: 37.50%] [G loss: 0.856933]\n",
      "epoch:15 step:11960[D loss: 0.431678, acc: 61.72%, op_acc: 39.84%] [G loss: 0.794952]\n",
      "epoch:15 step:11961[D loss: 0.430017, acc: 62.50%, op_acc: 33.59%] [G loss: 0.900416]\n",
      "epoch:15 step:11962[D loss: 0.423347, acc: 54.69%, op_acc: 40.62%] [G loss: 0.852922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11963[D loss: 0.425888, acc: 60.94%, op_acc: 41.41%] [G loss: 0.887924]\n",
      "epoch:15 step:11964[D loss: 0.449675, acc: 55.47%, op_acc: 39.06%] [G loss: 0.844825]\n",
      "epoch:15 step:11965[D loss: 0.434847, acc: 63.28%, op_acc: 36.72%] [G loss: 0.913562]\n",
      "epoch:15 step:11966[D loss: 0.441123, acc: 52.34%, op_acc: 40.62%] [G loss: 0.791267]\n",
      "epoch:15 step:11967[D loss: 0.425212, acc: 57.03%, op_acc: 32.81%] [G loss: 0.874744]\n",
      "epoch:15 step:11968[D loss: 0.455262, acc: 53.91%, op_acc: 35.16%] [G loss: 0.892944]\n",
      "epoch:15 step:11969[D loss: 0.433779, acc: 67.19%, op_acc: 32.03%] [G loss: 0.794827]\n",
      "epoch:15 step:11970[D loss: 0.439118, acc: 61.72%, op_acc: 34.38%] [G loss: 0.857398]\n",
      "epoch:15 step:11971[D loss: 0.407077, acc: 61.72%, op_acc: 39.84%] [G loss: 0.837564]\n",
      "epoch:15 step:11972[D loss: 0.439913, acc: 55.47%, op_acc: 39.06%] [G loss: 0.854143]\n",
      "epoch:15 step:11973[D loss: 0.433638, acc: 53.91%, op_acc: 35.16%] [G loss: 0.822019]\n",
      "epoch:15 step:11974[D loss: 0.446068, acc: 59.38%, op_acc: 32.03%] [G loss: 0.836748]\n",
      "epoch:15 step:11975[D loss: 0.425730, acc: 58.59%, op_acc: 33.59%] [G loss: 0.850961]\n",
      "epoch:15 step:11976[D loss: 0.413468, acc: 60.16%, op_acc: 38.28%] [G loss: 0.893713]\n",
      "epoch:15 step:11977[D loss: 0.429877, acc: 60.94%, op_acc: 32.81%] [G loss: 0.866045]\n",
      "epoch:15 step:11978[D loss: 0.431165, acc: 64.06%, op_acc: 36.72%] [G loss: 0.926221]\n",
      "epoch:15 step:11979[D loss: 0.460719, acc: 52.34%, op_acc: 29.69%] [G loss: 0.894014]\n",
      "epoch:15 step:11980[D loss: 0.411606, acc: 64.84%, op_acc: 33.59%] [G loss: 0.899362]\n",
      "epoch:15 step:11981[D loss: 0.459092, acc: 50.00%, op_acc: 38.28%] [G loss: 0.822236]\n",
      "epoch:15 step:11982[D loss: 0.435724, acc: 62.50%, op_acc: 35.16%] [G loss: 0.833853]\n",
      "epoch:15 step:11983[D loss: 0.418099, acc: 60.16%, op_acc: 39.84%] [G loss: 0.872215]\n",
      "epoch:15 step:11984[D loss: 0.401539, acc: 62.50%, op_acc: 40.62%] [G loss: 0.967307]\n",
      "epoch:15 step:11985[D loss: 0.441311, acc: 55.47%, op_acc: 36.72%] [G loss: 0.824840]\n",
      "epoch:15 step:11986[D loss: 0.419200, acc: 67.19%, op_acc: 30.47%] [G loss: 0.911437]\n",
      "epoch:15 step:11987[D loss: 0.402666, acc: 65.62%, op_acc: 34.38%] [G loss: 0.949877]\n",
      "epoch:15 step:11988[D loss: 0.411332, acc: 57.03%, op_acc: 39.84%] [G loss: 0.910544]\n",
      "epoch:15 step:11989[D loss: 0.434725, acc: 60.16%, op_acc: 39.06%] [G loss: 0.887518]\n",
      "epoch:15 step:11990[D loss: 0.418372, acc: 64.06%, op_acc: 42.19%] [G loss: 0.861124]\n",
      "epoch:15 step:11991[D loss: 0.458566, acc: 52.34%, op_acc: 36.72%] [G loss: 0.855762]\n",
      "epoch:15 step:11992[D loss: 0.434313, acc: 58.59%, op_acc: 32.81%] [G loss: 0.875882]\n",
      "epoch:15 step:11993[D loss: 0.450788, acc: 59.38%, op_acc: 35.94%] [G loss: 0.841794]\n",
      "epoch:15 step:11994[D loss: 0.436218, acc: 60.94%, op_acc: 39.84%] [G loss: 0.811886]\n",
      "epoch:15 step:11995[D loss: 0.440340, acc: 50.78%, op_acc: 36.72%] [G loss: 0.787964]\n",
      "epoch:15 step:11996[D loss: 0.415150, acc: 61.72%, op_acc: 33.59%] [G loss: 0.924341]\n",
      "epoch:15 step:11997[D loss: 0.448201, acc: 59.38%, op_acc: 32.03%] [G loss: 0.865383]\n",
      "epoch:15 step:11998[D loss: 0.403219, acc: 58.59%, op_acc: 44.53%] [G loss: 0.889530]\n",
      "epoch:15 step:11999[D loss: 0.441560, acc: 61.72%, op_acc: 29.69%] [G loss: 0.877504]\n",
      "epoch:15 step:12000[D loss: 0.428261, acc: 57.03%, op_acc: 35.16%] [G loss: 0.869710]\n",
      "##############\n",
      "[0.83529127 0.86183721 0.81157463 0.80934345 0.78845882 0.81762335\n",
      " 0.89755776 0.83011487 0.81019466 0.82113416]\n",
      "##########\n",
      "epoch:15 step:12001[D loss: 0.427150, acc: 67.97%, op_acc: 35.16%] [G loss: 0.796257]\n",
      "epoch:15 step:12002[D loss: 0.455579, acc: 53.91%, op_acc: 37.50%] [G loss: 0.897578]\n",
      "epoch:15 step:12003[D loss: 0.437126, acc: 57.81%, op_acc: 39.06%] [G loss: 0.822094]\n",
      "epoch:15 step:12004[D loss: 0.440176, acc: 60.94%, op_acc: 33.59%] [G loss: 0.888713]\n",
      "epoch:15 step:12005[D loss: 0.397983, acc: 65.62%, op_acc: 36.72%] [G loss: 0.845342]\n",
      "epoch:15 step:12006[D loss: 0.423925, acc: 63.28%, op_acc: 42.97%] [G loss: 0.896570]\n",
      "epoch:15 step:12007[D loss: 0.467622, acc: 53.12%, op_acc: 28.12%] [G loss: 0.884186]\n",
      "epoch:15 step:12008[D loss: 0.420465, acc: 63.28%, op_acc: 35.94%] [G loss: 0.856224]\n",
      "epoch:15 step:12009[D loss: 0.430661, acc: 60.16%, op_acc: 29.69%] [G loss: 0.901976]\n",
      "epoch:15 step:12010[D loss: 0.439429, acc: 53.12%, op_acc: 36.72%] [G loss: 0.918134]\n",
      "epoch:15 step:12011[D loss: 0.417696, acc: 60.16%, op_acc: 42.97%] [G loss: 0.895462]\n",
      "epoch:15 step:12012[D loss: 0.453009, acc: 53.91%, op_acc: 35.16%] [G loss: 0.824074]\n",
      "epoch:15 step:12013[D loss: 0.447472, acc: 55.47%, op_acc: 38.28%] [G loss: 0.846049]\n",
      "epoch:15 step:12014[D loss: 0.438289, acc: 59.38%, op_acc: 37.50%] [G loss: 0.871066]\n",
      "epoch:15 step:12015[D loss: 0.479664, acc: 46.09%, op_acc: 37.50%] [G loss: 0.854965]\n",
      "epoch:15 step:12016[D loss: 0.424421, acc: 61.72%, op_acc: 38.28%] [G loss: 0.909511]\n",
      "epoch:15 step:12017[D loss: 0.443439, acc: 59.38%, op_acc: 39.06%] [G loss: 0.855009]\n",
      "epoch:15 step:12018[D loss: 0.452773, acc: 53.12%, op_acc: 33.59%] [G loss: 0.879747]\n",
      "epoch:15 step:12019[D loss: 0.420521, acc: 64.06%, op_acc: 39.06%] [G loss: 0.808102]\n",
      "epoch:15 step:12020[D loss: 0.444905, acc: 49.22%, op_acc: 35.94%] [G loss: 0.892675]\n",
      "epoch:15 step:12021[D loss: 0.471717, acc: 60.16%, op_acc: 29.69%] [G loss: 0.836232]\n",
      "epoch:15 step:12022[D loss: 0.429747, acc: 66.41%, op_acc: 35.94%] [G loss: 0.903288]\n",
      "epoch:15 step:12023[D loss: 0.434635, acc: 60.94%, op_acc: 35.16%] [G loss: 0.878215]\n",
      "epoch:15 step:12024[D loss: 0.445822, acc: 57.81%, op_acc: 29.69%] [G loss: 0.848402]\n",
      "epoch:15 step:12025[D loss: 0.423656, acc: 58.59%, op_acc: 39.84%] [G loss: 0.863859]\n",
      "epoch:15 step:12026[D loss: 0.439175, acc: 57.81%, op_acc: 35.94%] [G loss: 0.925151]\n",
      "epoch:15 step:12027[D loss: 0.430720, acc: 49.22%, op_acc: 44.53%] [G loss: 0.869312]\n",
      "epoch:15 step:12028[D loss: 0.463426, acc: 55.47%, op_acc: 32.03%] [G loss: 0.873830]\n",
      "epoch:15 step:12029[D loss: 0.436574, acc: 59.38%, op_acc: 36.72%] [G loss: 0.877149]\n",
      "epoch:15 step:12030[D loss: 0.462866, acc: 44.53%, op_acc: 37.50%] [G loss: 0.862037]\n",
      "epoch:15 step:12031[D loss: 0.446597, acc: 55.47%, op_acc: 39.06%] [G loss: 0.858509]\n",
      "epoch:15 step:12032[D loss: 0.441450, acc: 57.03%, op_acc: 35.94%] [G loss: 0.860651]\n",
      "epoch:15 step:12033[D loss: 0.433537, acc: 57.03%, op_acc: 35.16%] [G loss: 0.813058]\n",
      "epoch:15 step:12034[D loss: 0.442996, acc: 52.34%, op_acc: 34.38%] [G loss: 0.881853]\n",
      "epoch:15 step:12035[D loss: 0.453982, acc: 57.03%, op_acc: 34.38%] [G loss: 0.891930]\n",
      "epoch:15 step:12036[D loss: 0.426653, acc: 69.53%, op_acc: 39.06%] [G loss: 0.893769]\n",
      "epoch:15 step:12037[D loss: 0.444200, acc: 54.69%, op_acc: 35.94%] [G loss: 0.859701]\n",
      "epoch:15 step:12038[D loss: 0.440709, acc: 54.69%, op_acc: 35.94%] [G loss: 0.916085]\n",
      "epoch:15 step:12039[D loss: 0.441071, acc: 63.28%, op_acc: 35.94%] [G loss: 0.921654]\n",
      "epoch:15 step:12040[D loss: 0.435652, acc: 55.47%, op_acc: 42.19%] [G loss: 0.833397]\n",
      "epoch:15 step:12041[D loss: 0.416358, acc: 56.25%, op_acc: 42.19%] [G loss: 0.900147]\n",
      "epoch:15 step:12042[D loss: 0.412493, acc: 60.94%, op_acc: 39.06%] [G loss: 0.887238]\n",
      "epoch:15 step:12043[D loss: 0.432837, acc: 57.03%, op_acc: 38.28%] [G loss: 0.792547]\n",
      "epoch:15 step:12044[D loss: 0.438745, acc: 55.47%, op_acc: 38.28%] [G loss: 0.892074]\n",
      "epoch:15 step:12045[D loss: 0.420692, acc: 60.94%, op_acc: 39.06%] [G loss: 0.899791]\n",
      "epoch:15 step:12046[D loss: 0.453802, acc: 49.22%, op_acc: 38.28%] [G loss: 0.893575]\n",
      "epoch:15 step:12047[D loss: 0.413910, acc: 65.62%, op_acc: 39.84%] [G loss: 0.840204]\n",
      "epoch:15 step:12048[D loss: 0.444598, acc: 60.16%, op_acc: 37.50%] [G loss: 0.911556]\n",
      "epoch:15 step:12049[D loss: 0.445974, acc: 53.12%, op_acc: 37.50%] [G loss: 0.914002]\n",
      "epoch:15 step:12050[D loss: 0.433335, acc: 64.84%, op_acc: 32.03%] [G loss: 0.865713]\n",
      "##############\n",
      "[0.86443293 0.83738691 0.80945147 0.80523164 0.80720605 0.83173754\n",
      " 0.90139965 0.82651139 0.80531274 0.83844019]\n",
      "##########\n",
      "epoch:15 step:12051[D loss: 0.436851, acc: 62.50%, op_acc: 37.50%] [G loss: 0.858856]\n",
      "epoch:15 step:12052[D loss: 0.456861, acc: 57.03%, op_acc: 31.25%] [G loss: 0.834238]\n",
      "epoch:15 step:12053[D loss: 0.411266, acc: 60.16%, op_acc: 43.75%] [G loss: 0.842785]\n",
      "epoch:15 step:12054[D loss: 0.402592, acc: 67.97%, op_acc: 35.16%] [G loss: 0.905376]\n",
      "epoch:15 step:12055[D loss: 0.440369, acc: 61.72%, op_acc: 38.28%] [G loss: 0.891955]\n",
      "epoch:15 step:12056[D loss: 0.449178, acc: 58.59%, op_acc: 33.59%] [G loss: 0.865779]\n",
      "epoch:15 step:12057[D loss: 0.471770, acc: 50.78%, op_acc: 32.81%] [G loss: 0.869919]\n",
      "epoch:15 step:12058[D loss: 0.438301, acc: 59.38%, op_acc: 29.69%] [G loss: 0.829976]\n",
      "epoch:15 step:12059[D loss: 0.411784, acc: 60.16%, op_acc: 39.06%] [G loss: 0.804965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12060[D loss: 0.422735, acc: 63.28%, op_acc: 32.03%] [G loss: 0.937340]\n",
      "epoch:15 step:12061[D loss: 0.429255, acc: 61.72%, op_acc: 34.38%] [G loss: 0.901605]\n",
      "epoch:15 step:12062[D loss: 0.441867, acc: 57.03%, op_acc: 37.50%] [G loss: 0.829454]\n",
      "epoch:15 step:12063[D loss: 0.425767, acc: 61.72%, op_acc: 35.16%] [G loss: 0.853285]\n",
      "epoch:15 step:12064[D loss: 0.428093, acc: 60.16%, op_acc: 36.72%] [G loss: 0.807758]\n",
      "epoch:15 step:12065[D loss: 0.448540, acc: 58.59%, op_acc: 32.03%] [G loss: 0.818446]\n",
      "epoch:15 step:12066[D loss: 0.443278, acc: 62.50%, op_acc: 36.72%] [G loss: 0.940844]\n",
      "epoch:15 step:12067[D loss: 0.452995, acc: 53.91%, op_acc: 35.16%] [G loss: 0.839393]\n",
      "epoch:15 step:12068[D loss: 0.410668, acc: 60.16%, op_acc: 42.19%] [G loss: 0.843357]\n",
      "epoch:15 step:12069[D loss: 0.432199, acc: 61.72%, op_acc: 32.03%] [G loss: 0.858981]\n",
      "epoch:15 step:12070[D loss: 0.419904, acc: 58.59%, op_acc: 42.19%] [G loss: 0.821468]\n",
      "epoch:15 step:12071[D loss: 0.423293, acc: 61.72%, op_acc: 37.50%] [G loss: 0.859020]\n",
      "epoch:15 step:12072[D loss: 0.438385, acc: 57.03%, op_acc: 35.16%] [G loss: 0.948072]\n",
      "epoch:15 step:12073[D loss: 0.444959, acc: 58.59%, op_acc: 38.28%] [G loss: 0.899277]\n",
      "epoch:15 step:12074[D loss: 0.410319, acc: 64.06%, op_acc: 39.84%] [G loss: 0.949340]\n",
      "epoch:15 step:12075[D loss: 0.441603, acc: 56.25%, op_acc: 41.41%] [G loss: 0.905675]\n",
      "epoch:15 step:12076[D loss: 0.444280, acc: 56.25%, op_acc: 38.28%] [G loss: 0.936108]\n",
      "epoch:15 step:12077[D loss: 0.383095, acc: 67.97%, op_acc: 36.72%] [G loss: 0.852039]\n",
      "epoch:15 step:12078[D loss: 0.438686, acc: 58.59%, op_acc: 37.50%] [G loss: 0.916719]\n",
      "epoch:15 step:12079[D loss: 0.447506, acc: 53.12%, op_acc: 34.38%] [G loss: 0.926555]\n",
      "epoch:15 step:12080[D loss: 0.405873, acc: 64.84%, op_acc: 42.19%] [G loss: 0.944503]\n",
      "epoch:15 step:12081[D loss: 0.412438, acc: 66.41%, op_acc: 39.06%] [G loss: 0.879940]\n",
      "epoch:15 step:12082[D loss: 0.440697, acc: 60.94%, op_acc: 31.25%] [G loss: 0.893988]\n",
      "epoch:15 step:12083[D loss: 0.449682, acc: 61.72%, op_acc: 32.81%] [G loss: 0.916217]\n",
      "epoch:15 step:12084[D loss: 0.433364, acc: 57.03%, op_acc: 41.41%] [G loss: 0.845585]\n",
      "epoch:15 step:12085[D loss: 0.434175, acc: 58.59%, op_acc: 39.84%] [G loss: 0.896879]\n",
      "epoch:15 step:12086[D loss: 0.430259, acc: 59.38%, op_acc: 37.50%] [G loss: 0.882298]\n",
      "epoch:15 step:12087[D loss: 0.456682, acc: 50.00%, op_acc: 36.72%] [G loss: 0.850684]\n",
      "epoch:15 step:12088[D loss: 0.409969, acc: 67.19%, op_acc: 35.94%] [G loss: 0.914313]\n",
      "epoch:15 step:12089[D loss: 0.418129, acc: 60.16%, op_acc: 39.06%] [G loss: 0.902377]\n",
      "epoch:15 step:12090[D loss: 0.421448, acc: 63.28%, op_acc: 35.16%] [G loss: 0.890404]\n",
      "epoch:15 step:12091[D loss: 0.424322, acc: 64.84%, op_acc: 32.81%] [G loss: 0.879704]\n",
      "epoch:15 step:12092[D loss: 0.461656, acc: 51.56%, op_acc: 32.03%] [G loss: 0.901812]\n",
      "epoch:15 step:12093[D loss: 0.412855, acc: 60.94%, op_acc: 39.06%] [G loss: 0.930862]\n",
      "epoch:15 step:12094[D loss: 0.439679, acc: 53.91%, op_acc: 39.84%] [G loss: 0.944863]\n",
      "epoch:15 step:12095[D loss: 0.396764, acc: 68.75%, op_acc: 39.84%] [G loss: 0.948512]\n",
      "epoch:15 step:12096[D loss: 0.397549, acc: 72.66%, op_acc: 35.94%] [G loss: 0.925632]\n",
      "epoch:15 step:12097[D loss: 0.437724, acc: 52.34%, op_acc: 35.94%] [G loss: 0.832902]\n",
      "epoch:15 step:12098[D loss: 0.401720, acc: 64.06%, op_acc: 40.62%] [G loss: 0.926831]\n",
      "epoch:15 step:12099[D loss: 0.421284, acc: 58.59%, op_acc: 35.94%] [G loss: 0.852846]\n",
      "epoch:15 step:12100[D loss: 0.466702, acc: 42.97%, op_acc: 39.84%] [G loss: 0.876662]\n",
      "##############\n",
      "[0.85270137 0.87260019 0.81646016 0.80204362 0.81009109 0.82318548\n",
      " 0.87470616 0.80591535 0.80274517 0.83588463]\n",
      "##########\n",
      "epoch:15 step:12101[D loss: 0.415379, acc: 60.16%, op_acc: 38.28%] [G loss: 0.852613]\n",
      "epoch:15 step:12102[D loss: 0.456205, acc: 49.22%, op_acc: 35.16%] [G loss: 0.806124]\n",
      "epoch:15 step:12103[D loss: 0.469595, acc: 54.69%, op_acc: 33.59%] [G loss: 0.936325]\n",
      "epoch:15 step:12104[D loss: 0.426050, acc: 58.59%, op_acc: 35.16%] [G loss: 0.924708]\n",
      "epoch:15 step:12105[D loss: 0.420263, acc: 62.50%, op_acc: 35.94%] [G loss: 0.939329]\n",
      "epoch:15 step:12106[D loss: 0.433394, acc: 45.31%, op_acc: 39.84%] [G loss: 0.887441]\n",
      "epoch:15 step:12107[D loss: 0.417129, acc: 57.03%, op_acc: 41.41%] [G loss: 0.889767]\n",
      "epoch:15 step:12108[D loss: 0.413075, acc: 64.06%, op_acc: 40.62%] [G loss: 0.882478]\n",
      "epoch:15 step:12109[D loss: 0.412749, acc: 65.62%, op_acc: 43.75%] [G loss: 0.883816]\n",
      "epoch:15 step:12110[D loss: 0.462471, acc: 52.34%, op_acc: 32.81%] [G loss: 0.876157]\n",
      "epoch:15 step:12111[D loss: 0.420140, acc: 57.81%, op_acc: 42.19%] [G loss: 0.857452]\n",
      "epoch:15 step:12112[D loss: 0.411657, acc: 61.72%, op_acc: 35.94%] [G loss: 0.905511]\n",
      "epoch:15 step:12113[D loss: 0.469110, acc: 54.69%, op_acc: 32.81%] [G loss: 0.889773]\n",
      "epoch:15 step:12114[D loss: 0.418825, acc: 61.72%, op_acc: 46.88%] [G loss: 0.911237]\n",
      "epoch:15 step:12115[D loss: 0.438567, acc: 55.47%, op_acc: 38.28%] [G loss: 0.851537]\n",
      "epoch:15 step:12116[D loss: 0.446983, acc: 59.38%, op_acc: 35.16%] [G loss: 0.883377]\n",
      "epoch:15 step:12117[D loss: 0.426128, acc: 58.59%, op_acc: 39.06%] [G loss: 0.936055]\n",
      "epoch:15 step:12118[D loss: 0.451934, acc: 54.69%, op_acc: 35.16%] [G loss: 0.849333]\n",
      "epoch:15 step:12119[D loss: 0.415511, acc: 60.94%, op_acc: 41.41%] [G loss: 0.924940]\n",
      "epoch:15 step:12120[D loss: 0.433795, acc: 60.94%, op_acc: 35.16%] [G loss: 0.915452]\n",
      "epoch:15 step:12121[D loss: 0.416523, acc: 62.50%, op_acc: 39.84%] [G loss: 0.886961]\n",
      "epoch:15 step:12122[D loss: 0.422536, acc: 62.50%, op_acc: 37.50%] [G loss: 0.887890]\n",
      "epoch:15 step:12123[D loss: 0.417586, acc: 58.59%, op_acc: 42.19%] [G loss: 0.767112]\n",
      "epoch:15 step:12124[D loss: 0.426987, acc: 58.59%, op_acc: 35.94%] [G loss: 0.838758]\n",
      "epoch:15 step:12125[D loss: 0.400436, acc: 66.41%, op_acc: 39.06%] [G loss: 0.893679]\n",
      "epoch:15 step:12126[D loss: 0.440452, acc: 55.47%, op_acc: 36.72%] [G loss: 0.865130]\n",
      "epoch:15 step:12127[D loss: 0.439959, acc: 49.22%, op_acc: 38.28%] [G loss: 0.891760]\n",
      "epoch:15 step:12128[D loss: 0.411202, acc: 70.31%, op_acc: 42.97%] [G loss: 0.900168]\n",
      "epoch:15 step:12129[D loss: 0.415486, acc: 67.19%, op_acc: 39.06%] [G loss: 0.794828]\n",
      "epoch:15 step:12130[D loss: 0.412474, acc: 71.88%, op_acc: 36.72%] [G loss: 0.940260]\n",
      "epoch:15 step:12131[D loss: 0.410372, acc: 55.47%, op_acc: 43.75%] [G loss: 0.891493]\n",
      "epoch:15 step:12132[D loss: 0.442885, acc: 55.47%, op_acc: 35.16%] [G loss: 0.828547]\n",
      "epoch:15 step:12133[D loss: 0.436267, acc: 56.25%, op_acc: 34.38%] [G loss: 0.822618]\n",
      "epoch:15 step:12134[D loss: 0.415986, acc: 63.28%, op_acc: 40.62%] [G loss: 0.891046]\n",
      "epoch:15 step:12135[D loss: 0.441533, acc: 60.94%, op_acc: 34.38%] [G loss: 0.911410]\n",
      "epoch:15 step:12136[D loss: 0.440545, acc: 59.38%, op_acc: 39.06%] [G loss: 0.869842]\n",
      "epoch:15 step:12137[D loss: 0.428886, acc: 57.03%, op_acc: 36.72%] [G loss: 0.890792]\n",
      "epoch:15 step:12138[D loss: 0.429650, acc: 60.94%, op_acc: 35.94%] [G loss: 0.905463]\n",
      "epoch:15 step:12139[D loss: 0.435770, acc: 55.47%, op_acc: 42.97%] [G loss: 0.861396]\n",
      "epoch:15 step:12140[D loss: 0.436682, acc: 59.38%, op_acc: 33.59%] [G loss: 0.866431]\n",
      "epoch:15 step:12141[D loss: 0.485169, acc: 50.78%, op_acc: 30.47%] [G loss: 0.900141]\n",
      "epoch:15 step:12142[D loss: 0.407141, acc: 71.09%, op_acc: 35.94%] [G loss: 0.917796]\n",
      "epoch:15 step:12143[D loss: 0.440903, acc: 58.59%, op_acc: 35.94%] [G loss: 0.844593]\n",
      "epoch:15 step:12144[D loss: 0.457517, acc: 51.56%, op_acc: 35.16%] [G loss: 0.941404]\n",
      "epoch:15 step:12145[D loss: 0.414947, acc: 62.50%, op_acc: 40.62%] [G loss: 0.964288]\n",
      "epoch:15 step:12146[D loss: 0.472326, acc: 50.78%, op_acc: 35.16%] [G loss: 0.880765]\n",
      "epoch:15 step:12147[D loss: 0.419554, acc: 56.25%, op_acc: 38.28%] [G loss: 0.894250]\n",
      "epoch:15 step:12148[D loss: 0.431423, acc: 60.94%, op_acc: 35.16%] [G loss: 0.876071]\n",
      "epoch:15 step:12149[D loss: 0.433659, acc: 54.69%, op_acc: 39.06%] [G loss: 0.926280]\n",
      "epoch:15 step:12150[D loss: 0.433766, acc: 56.25%, op_acc: 40.62%] [G loss: 0.910518]\n",
      "##############\n",
      "[0.83149307 0.84455234 0.81461161 0.80103986 0.78481303 0.83670003\n",
      " 0.86370144 0.82540084 0.81562685 0.8219765 ]\n",
      "##########\n",
      "epoch:15 step:12151[D loss: 0.470807, acc: 52.34%, op_acc: 34.38%] [G loss: 0.866808]\n",
      "epoch:15 step:12152[D loss: 0.443477, acc: 53.12%, op_acc: 35.16%] [G loss: 0.853854]\n",
      "epoch:15 step:12153[D loss: 0.433019, acc: 57.81%, op_acc: 37.50%] [G loss: 0.836054]\n",
      "epoch:15 step:12154[D loss: 0.415144, acc: 61.72%, op_acc: 34.38%] [G loss: 0.933944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12155[D loss: 0.439552, acc: 57.03%, op_acc: 36.72%] [G loss: 0.852073]\n",
      "epoch:15 step:12156[D loss: 0.450424, acc: 57.03%, op_acc: 34.38%] [G loss: 0.869071]\n",
      "epoch:15 step:12157[D loss: 0.440150, acc: 58.59%, op_acc: 42.97%] [G loss: 0.868609]\n",
      "epoch:15 step:12158[D loss: 0.411143, acc: 68.75%, op_acc: 36.72%] [G loss: 0.953704]\n",
      "epoch:15 step:12159[D loss: 0.439701, acc: 57.03%, op_acc: 40.62%] [G loss: 0.892259]\n",
      "epoch:15 step:12160[D loss: 0.449433, acc: 56.25%, op_acc: 32.81%] [G loss: 0.901858]\n",
      "epoch:15 step:12161[D loss: 0.455777, acc: 57.81%, op_acc: 33.59%] [G loss: 0.844212]\n",
      "epoch:15 step:12162[D loss: 0.436490, acc: 62.50%, op_acc: 35.94%] [G loss: 0.860494]\n",
      "epoch:15 step:12163[D loss: 0.401469, acc: 69.53%, op_acc: 38.28%] [G loss: 0.902697]\n",
      "epoch:15 step:12164[D loss: 0.403395, acc: 65.62%, op_acc: 36.72%] [G loss: 0.798515]\n",
      "epoch:15 step:12165[D loss: 0.448585, acc: 58.59%, op_acc: 32.03%] [G loss: 0.910452]\n",
      "epoch:15 step:12166[D loss: 0.469147, acc: 47.66%, op_acc: 35.16%] [G loss: 0.864834]\n",
      "epoch:15 step:12167[D loss: 0.406899, acc: 63.28%, op_acc: 42.19%] [G loss: 0.915396]\n",
      "epoch:15 step:12168[D loss: 0.435966, acc: 55.47%, op_acc: 42.97%] [G loss: 0.836280]\n",
      "epoch:15 step:12169[D loss: 0.406813, acc: 65.62%, op_acc: 41.41%] [G loss: 0.990145]\n",
      "epoch:15 step:12170[D loss: 0.457885, acc: 51.56%, op_acc: 42.19%] [G loss: 0.829490]\n",
      "epoch:15 step:12171[D loss: 0.436225, acc: 62.50%, op_acc: 33.59%] [G loss: 0.837458]\n",
      "epoch:15 step:12172[D loss: 0.437781, acc: 57.03%, op_acc: 33.59%] [G loss: 0.873583]\n",
      "epoch:15 step:12173[D loss: 0.418418, acc: 57.81%, op_acc: 41.41%] [G loss: 0.846103]\n",
      "epoch:15 step:12174[D loss: 0.426665, acc: 53.91%, op_acc: 39.06%] [G loss: 0.911585]\n",
      "epoch:15 step:12175[D loss: 0.455316, acc: 51.56%, op_acc: 38.28%] [G loss: 0.854126]\n",
      "epoch:15 step:12176[D loss: 0.459394, acc: 57.03%, op_acc: 35.94%] [G loss: 0.909042]\n",
      "epoch:15 step:12177[D loss: 0.437987, acc: 54.69%, op_acc: 39.06%] [G loss: 0.859141]\n",
      "epoch:15 step:12178[D loss: 0.435623, acc: 54.69%, op_acc: 40.62%] [G loss: 0.925425]\n",
      "epoch:15 step:12179[D loss: 0.445840, acc: 55.47%, op_acc: 35.16%] [G loss: 0.916043]\n",
      "epoch:15 step:12180[D loss: 0.421674, acc: 61.72%, op_acc: 36.72%] [G loss: 0.876433]\n",
      "epoch:15 step:12181[D loss: 0.428148, acc: 58.59%, op_acc: 37.50%] [G loss: 0.911659]\n",
      "epoch:15 step:12182[D loss: 0.444404, acc: 54.69%, op_acc: 35.94%] [G loss: 0.804393]\n",
      "epoch:15 step:12183[D loss: 0.426914, acc: 60.16%, op_acc: 46.09%] [G loss: 0.902757]\n",
      "epoch:15 step:12184[D loss: 0.386908, acc: 66.41%, op_acc: 40.62%] [G loss: 0.971817]\n",
      "epoch:15 step:12185[D loss: 0.410630, acc: 61.72%, op_acc: 39.06%] [G loss: 0.920724]\n",
      "epoch:15 step:12186[D loss: 0.428783, acc: 60.94%, op_acc: 32.81%] [G loss: 0.893411]\n",
      "epoch:15 step:12187[D loss: 0.420687, acc: 62.50%, op_acc: 35.94%] [G loss: 0.864045]\n",
      "epoch:15 step:12188[D loss: 0.388248, acc: 64.06%, op_acc: 43.75%] [G loss: 0.892219]\n",
      "epoch:15 step:12189[D loss: 0.432645, acc: 56.25%, op_acc: 41.41%] [G loss: 0.921019]\n",
      "epoch:15 step:12190[D loss: 0.432889, acc: 54.69%, op_acc: 38.28%] [G loss: 0.951576]\n",
      "epoch:15 step:12191[D loss: 0.465589, acc: 56.25%, op_acc: 33.59%] [G loss: 0.878334]\n",
      "epoch:15 step:12192[D loss: 0.462075, acc: 56.25%, op_acc: 34.38%] [G loss: 0.961244]\n",
      "epoch:15 step:12193[D loss: 0.406095, acc: 67.19%, op_acc: 34.38%] [G loss: 0.948968]\n",
      "epoch:15 step:12194[D loss: 0.436867, acc: 61.72%, op_acc: 35.94%] [G loss: 1.010485]\n",
      "epoch:15 step:12195[D loss: 0.471418, acc: 55.47%, op_acc: 32.03%] [G loss: 0.877888]\n",
      "epoch:15 step:12196[D loss: 0.439554, acc: 61.72%, op_acc: 34.38%] [G loss: 0.936987]\n",
      "epoch:15 step:12197[D loss: 0.423647, acc: 59.38%, op_acc: 37.50%] [G loss: 0.871387]\n",
      "epoch:15 step:12198[D loss: 0.419854, acc: 63.28%, op_acc: 42.97%] [G loss: 0.919338]\n",
      "epoch:15 step:12199[D loss: 0.429848, acc: 56.25%, op_acc: 42.19%] [G loss: 0.809914]\n",
      "epoch:15 step:12200[D loss: 0.441546, acc: 62.50%, op_acc: 28.91%] [G loss: 0.909690]\n",
      "##############\n",
      "[0.84356354 0.86589879 0.82641756 0.80347029 0.79011916 0.82656308\n",
      " 0.89313671 0.82704406 0.80112834 0.81598834]\n",
      "##########\n",
      "epoch:15 step:12201[D loss: 0.416678, acc: 64.84%, op_acc: 42.19%] [G loss: 0.823948]\n",
      "epoch:15 step:12202[D loss: 0.399443, acc: 64.84%, op_acc: 35.16%] [G loss: 0.837379]\n",
      "epoch:15 step:12203[D loss: 0.432411, acc: 59.38%, op_acc: 37.50%] [G loss: 0.855349]\n",
      "epoch:15 step:12204[D loss: 0.452823, acc: 51.56%, op_acc: 38.28%] [G loss: 0.854188]\n",
      "epoch:15 step:12205[D loss: 0.426562, acc: 62.50%, op_acc: 38.28%] [G loss: 0.876419]\n",
      "epoch:15 step:12206[D loss: 0.453366, acc: 58.59%, op_acc: 30.47%] [G loss: 0.871862]\n",
      "epoch:15 step:12207[D loss: 0.406667, acc: 64.84%, op_acc: 41.41%] [G loss: 0.914792]\n",
      "epoch:15 step:12208[D loss: 0.430207, acc: 63.28%, op_acc: 35.16%] [G loss: 0.869112]\n",
      "epoch:15 step:12209[D loss: 0.410344, acc: 64.84%, op_acc: 37.50%] [G loss: 0.821469]\n",
      "epoch:15 step:12210[D loss: 0.428714, acc: 60.16%, op_acc: 40.62%] [G loss: 0.858730]\n",
      "epoch:15 step:12211[D loss: 0.409172, acc: 62.50%, op_acc: 40.62%] [G loss: 0.901202]\n",
      "epoch:15 step:12212[D loss: 0.431286, acc: 60.16%, op_acc: 38.28%] [G loss: 0.858242]\n",
      "epoch:15 step:12213[D loss: 0.436964, acc: 54.69%, op_acc: 35.94%] [G loss: 0.831924]\n",
      "epoch:15 step:12214[D loss: 0.444474, acc: 54.69%, op_acc: 33.59%] [G loss: 0.928080]\n",
      "epoch:15 step:12215[D loss: 0.419967, acc: 63.28%, op_acc: 37.50%] [G loss: 0.872401]\n",
      "epoch:15 step:12216[D loss: 0.450928, acc: 53.91%, op_acc: 35.16%] [G loss: 0.817143]\n",
      "epoch:15 step:12217[D loss: 0.406786, acc: 57.81%, op_acc: 40.62%] [G loss: 0.922651]\n",
      "epoch:15 step:12218[D loss: 0.461836, acc: 46.88%, op_acc: 33.59%] [G loss: 0.909944]\n",
      "epoch:15 step:12219[D loss: 0.438303, acc: 58.59%, op_acc: 35.16%] [G loss: 0.857396]\n",
      "epoch:15 step:12220[D loss: 0.448235, acc: 54.69%, op_acc: 36.72%] [G loss: 0.910980]\n",
      "epoch:15 step:12221[D loss: 0.432251, acc: 60.16%, op_acc: 37.50%] [G loss: 0.882328]\n",
      "epoch:15 step:12222[D loss: 0.410471, acc: 61.72%, op_acc: 42.97%] [G loss: 0.887373]\n",
      "epoch:15 step:12223[D loss: 0.428456, acc: 59.38%, op_acc: 34.38%] [G loss: 0.941595]\n",
      "epoch:15 step:12224[D loss: 0.454754, acc: 53.12%, op_acc: 36.72%] [G loss: 0.808398]\n",
      "epoch:15 step:12225[D loss: 0.430395, acc: 64.84%, op_acc: 39.06%] [G loss: 0.796923]\n",
      "epoch:15 step:12226[D loss: 0.440598, acc: 53.91%, op_acc: 33.59%] [G loss: 0.898156]\n",
      "epoch:15 step:12227[D loss: 0.447905, acc: 53.12%, op_acc: 40.62%] [G loss: 0.798918]\n",
      "epoch:15 step:12228[D loss: 0.466174, acc: 50.78%, op_acc: 30.47%] [G loss: 0.782912]\n",
      "epoch:15 step:12229[D loss: 0.440256, acc: 60.16%, op_acc: 34.38%] [G loss: 0.804506]\n",
      "epoch:15 step:12230[D loss: 0.446537, acc: 55.47%, op_acc: 34.38%] [G loss: 0.884800]\n",
      "epoch:15 step:12231[D loss: 0.445071, acc: 59.38%, op_acc: 35.94%] [G loss: 0.846681]\n",
      "epoch:15 step:12232[D loss: 0.456353, acc: 46.09%, op_acc: 39.06%] [G loss: 0.844966]\n",
      "epoch:15 step:12233[D loss: 0.416040, acc: 54.69%, op_acc: 37.50%] [G loss: 0.907797]\n",
      "epoch:15 step:12234[D loss: 0.404737, acc: 66.41%, op_acc: 39.84%] [G loss: 0.830598]\n",
      "epoch:15 step:12235[D loss: 0.454411, acc: 53.12%, op_acc: 37.50%] [G loss: 0.902919]\n",
      "epoch:15 step:12236[D loss: 0.439925, acc: 57.81%, op_acc: 36.72%] [G loss: 0.859103]\n",
      "epoch:15 step:12237[D loss: 0.448266, acc: 59.38%, op_acc: 34.38%] [G loss: 0.855847]\n",
      "epoch:15 step:12238[D loss: 0.418992, acc: 53.91%, op_acc: 38.28%] [G loss: 0.926577]\n",
      "epoch:15 step:12239[D loss: 0.434821, acc: 61.72%, op_acc: 36.72%] [G loss: 0.975175]\n",
      "epoch:15 step:12240[D loss: 0.439153, acc: 63.28%, op_acc: 27.34%] [G loss: 0.949475]\n",
      "epoch:15 step:12241[D loss: 0.496943, acc: 45.31%, op_acc: 25.78%] [G loss: 0.921455]\n",
      "epoch:15 step:12242[D loss: 0.446062, acc: 57.03%, op_acc: 39.84%] [G loss: 0.863459]\n",
      "epoch:15 step:12243[D loss: 0.443186, acc: 57.03%, op_acc: 33.59%] [G loss: 0.851924]\n",
      "epoch:15 step:12244[D loss: 0.428527, acc: 59.38%, op_acc: 40.62%] [G loss: 0.922067]\n",
      "epoch:15 step:12245[D loss: 0.445007, acc: 60.94%, op_acc: 35.94%] [G loss: 0.947255]\n",
      "epoch:15 step:12246[D loss: 0.417152, acc: 64.06%, op_acc: 34.38%] [G loss: 0.901300]\n",
      "epoch:15 step:12247[D loss: 0.419169, acc: 67.97%, op_acc: 36.72%] [G loss: 0.896970]\n",
      "epoch:15 step:12248[D loss: 0.413289, acc: 63.28%, op_acc: 39.06%] [G loss: 0.891804]\n",
      "epoch:15 step:12249[D loss: 0.415803, acc: 60.16%, op_acc: 41.41%] [G loss: 0.868919]\n",
      "epoch:15 step:12250[D loss: 0.419256, acc: 63.28%, op_acc: 39.84%] [G loss: 0.849657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.8544874  0.88181834 0.81150206 0.8099707  0.79821291 0.81206024\n",
      " 0.86267149 0.82316338 0.81090187 0.81294254]\n",
      "##########\n",
      "epoch:15 step:12251[D loss: 0.416839, acc: 63.28%, op_acc: 40.62%] [G loss: 0.896903]\n",
      "epoch:15 step:12252[D loss: 0.471834, acc: 58.59%, op_acc: 30.47%] [G loss: 0.902755]\n",
      "epoch:15 step:12253[D loss: 0.412001, acc: 58.59%, op_acc: 40.62%] [G loss: 0.899431]\n",
      "epoch:15 step:12254[D loss: 0.440466, acc: 60.94%, op_acc: 35.94%] [G loss: 0.888933]\n",
      "epoch:15 step:12255[D loss: 0.431032, acc: 57.81%, op_acc: 36.72%] [G loss: 0.876762]\n",
      "epoch:15 step:12256[D loss: 0.416362, acc: 63.28%, op_acc: 39.06%] [G loss: 0.866996]\n",
      "epoch:15 step:12257[D loss: 0.435752, acc: 60.94%, op_acc: 35.94%] [G loss: 0.871050]\n",
      "epoch:15 step:12258[D loss: 0.438813, acc: 57.81%, op_acc: 38.28%] [G loss: 0.858398]\n",
      "epoch:15 step:12259[D loss: 0.432514, acc: 53.91%, op_acc: 41.41%] [G loss: 0.881428]\n",
      "epoch:15 step:12260[D loss: 0.440308, acc: 54.69%, op_acc: 39.84%] [G loss: 0.898188]\n",
      "epoch:15 step:12261[D loss: 0.434429, acc: 55.47%, op_acc: 39.06%] [G loss: 0.880009]\n",
      "epoch:15 step:12262[D loss: 0.427583, acc: 58.59%, op_acc: 35.94%] [G loss: 0.852617]\n",
      "epoch:15 step:12263[D loss: 0.430091, acc: 64.84%, op_acc: 35.16%] [G loss: 0.926547]\n",
      "epoch:15 step:12264[D loss: 0.423610, acc: 55.47%, op_acc: 38.28%] [G loss: 0.900187]\n",
      "epoch:15 step:12265[D loss: 0.420110, acc: 67.19%, op_acc: 40.62%] [G loss: 0.989986]\n",
      "epoch:15 step:12266[D loss: 0.412468, acc: 64.06%, op_acc: 41.41%] [G loss: 0.862054]\n",
      "epoch:15 step:12267[D loss: 0.452239, acc: 54.69%, op_acc: 35.94%] [G loss: 0.787395]\n",
      "epoch:15 step:12268[D loss: 0.433274, acc: 60.16%, op_acc: 35.16%] [G loss: 0.915794]\n",
      "epoch:15 step:12269[D loss: 0.437666, acc: 57.81%, op_acc: 35.94%] [G loss: 0.822201]\n",
      "epoch:15 step:12270[D loss: 0.411491, acc: 60.16%, op_acc: 39.84%] [G loss: 0.900133]\n",
      "epoch:15 step:12271[D loss: 0.407255, acc: 64.06%, op_acc: 42.19%] [G loss: 0.918182]\n",
      "epoch:15 step:12272[D loss: 0.435603, acc: 60.94%, op_acc: 36.72%] [G loss: 0.909539]\n",
      "epoch:15 step:12273[D loss: 0.390809, acc: 66.41%, op_acc: 40.62%] [G loss: 0.917261]\n",
      "epoch:15 step:12274[D loss: 0.403895, acc: 63.28%, op_acc: 35.16%] [G loss: 0.858105]\n",
      "epoch:15 step:12275[D loss: 0.441211, acc: 58.59%, op_acc: 38.28%] [G loss: 0.936790]\n",
      "epoch:15 step:12276[D loss: 0.420213, acc: 57.81%, op_acc: 42.19%] [G loss: 0.876910]\n",
      "epoch:15 step:12277[D loss: 0.442702, acc: 53.91%, op_acc: 33.59%] [G loss: 0.862652]\n",
      "epoch:15 step:12278[D loss: 0.407192, acc: 63.28%, op_acc: 35.94%] [G loss: 0.932021]\n",
      "epoch:15 step:12279[D loss: 0.435215, acc: 59.38%, op_acc: 42.19%] [G loss: 0.833443]\n",
      "epoch:15 step:12280[D loss: 0.428589, acc: 61.72%, op_acc: 37.50%] [G loss: 0.841928]\n",
      "epoch:15 step:12281[D loss: 0.437165, acc: 62.50%, op_acc: 37.50%] [G loss: 0.840847]\n",
      "epoch:15 step:12282[D loss: 0.423440, acc: 58.59%, op_acc: 39.84%] [G loss: 0.914310]\n",
      "epoch:15 step:12283[D loss: 0.452632, acc: 53.12%, op_acc: 37.50%] [G loss: 0.811183]\n",
      "epoch:15 step:12284[D loss: 0.439210, acc: 59.38%, op_acc: 35.16%] [G loss: 0.828021]\n",
      "epoch:15 step:12285[D loss: 0.430460, acc: 58.59%, op_acc: 32.81%] [G loss: 0.862917]\n",
      "epoch:15 step:12286[D loss: 0.434818, acc: 57.03%, op_acc: 37.50%] [G loss: 0.847453]\n",
      "epoch:15 step:12287[D loss: 0.418538, acc: 60.16%, op_acc: 36.72%] [G loss: 0.843469]\n",
      "epoch:15 step:12288[D loss: 0.440329, acc: 59.38%, op_acc: 37.50%] [G loss: 0.867019]\n",
      "epoch:15 step:12289[D loss: 0.444905, acc: 60.16%, op_acc: 33.59%] [G loss: 0.901216]\n",
      "epoch:15 step:12290[D loss: 0.437101, acc: 55.47%, op_acc: 41.41%] [G loss: 0.762088]\n",
      "epoch:15 step:12291[D loss: 0.403054, acc: 61.72%, op_acc: 43.75%] [G loss: 0.768965]\n",
      "epoch:15 step:12292[D loss: 0.438593, acc: 58.59%, op_acc: 35.94%] [G loss: 0.942955]\n",
      "epoch:15 step:12293[D loss: 0.455560, acc: 59.38%, op_acc: 35.16%] [G loss: 0.881073]\n",
      "epoch:15 step:12294[D loss: 0.397374, acc: 64.06%, op_acc: 38.28%] [G loss: 0.958836]\n",
      "epoch:15 step:12295[D loss: 0.416759, acc: 62.50%, op_acc: 37.50%] [G loss: 0.867463]\n",
      "epoch:15 step:12296[D loss: 0.436629, acc: 57.81%, op_acc: 35.94%] [G loss: 0.842344]\n",
      "epoch:15 step:12297[D loss: 0.447226, acc: 58.59%, op_acc: 32.81%] [G loss: 0.936949]\n",
      "epoch:15 step:12298[D loss: 0.441135, acc: 57.03%, op_acc: 41.41%] [G loss: 0.967404]\n",
      "epoch:15 step:12299[D loss: 0.456510, acc: 57.03%, op_acc: 35.94%] [G loss: 0.929009]\n",
      "epoch:15 step:12300[D loss: 0.420592, acc: 58.59%, op_acc: 39.06%] [G loss: 0.881621]\n",
      "##############\n",
      "[0.85507767 0.87270132 0.81468951 0.80407483 0.8103405  0.84729692\n",
      " 0.8804918  0.8043172  0.81039846 0.82844791]\n",
      "##########\n",
      "epoch:15 step:12301[D loss: 0.403094, acc: 63.28%, op_acc: 38.28%] [G loss: 0.929269]\n",
      "epoch:15 step:12302[D loss: 0.421310, acc: 60.94%, op_acc: 37.50%] [G loss: 0.886060]\n",
      "epoch:15 step:12303[D loss: 0.430439, acc: 57.81%, op_acc: 38.28%] [G loss: 1.009056]\n",
      "epoch:15 step:12304[D loss: 0.439327, acc: 54.69%, op_acc: 39.06%] [G loss: 0.824822]\n",
      "epoch:15 step:12305[D loss: 0.451821, acc: 51.56%, op_acc: 42.97%] [G loss: 0.939293]\n",
      "epoch:15 step:12306[D loss: 0.446541, acc: 57.03%, op_acc: 32.81%] [G loss: 0.906005]\n",
      "epoch:15 step:12307[D loss: 0.429564, acc: 57.03%, op_acc: 39.84%] [G loss: 0.887551]\n",
      "epoch:15 step:12308[D loss: 0.474000, acc: 57.03%, op_acc: 30.47%] [G loss: 0.879569]\n",
      "epoch:15 step:12309[D loss: 0.422659, acc: 64.84%, op_acc: 38.28%] [G loss: 0.900907]\n",
      "epoch:15 step:12310[D loss: 0.423681, acc: 61.72%, op_acc: 35.16%] [G loss: 0.890017]\n",
      "epoch:15 step:12311[D loss: 0.450431, acc: 58.59%, op_acc: 33.59%] [G loss: 0.945099]\n",
      "epoch:15 step:12312[D loss: 0.436602, acc: 61.72%, op_acc: 35.16%] [G loss: 0.886508]\n",
      "epoch:15 step:12313[D loss: 0.412282, acc: 60.94%, op_acc: 42.97%] [G loss: 0.939920]\n",
      "epoch:15 step:12314[D loss: 0.445494, acc: 60.94%, op_acc: 36.72%] [G loss: 0.957879]\n",
      "epoch:15 step:12315[D loss: 0.440747, acc: 53.12%, op_acc: 36.72%] [G loss: 0.805724]\n",
      "epoch:15 step:12316[D loss: 0.425924, acc: 64.06%, op_acc: 34.38%] [G loss: 0.917684]\n",
      "epoch:15 step:12317[D loss: 0.421313, acc: 57.81%, op_acc: 40.62%] [G loss: 0.850055]\n",
      "epoch:15 step:12318[D loss: 0.393102, acc: 62.50%, op_acc: 40.62%] [G loss: 0.959325]\n",
      "epoch:15 step:12319[D loss: 0.448549, acc: 61.72%, op_acc: 34.38%] [G loss: 0.882108]\n",
      "epoch:15 step:12320[D loss: 0.439066, acc: 57.03%, op_acc: 32.03%] [G loss: 0.845945]\n",
      "epoch:15 step:12321[D loss: 0.431491, acc: 58.59%, op_acc: 41.41%] [G loss: 0.885001]\n",
      "epoch:15 step:12322[D loss: 0.379151, acc: 65.62%, op_acc: 40.62%] [G loss: 0.838833]\n",
      "epoch:15 step:12323[D loss: 0.382097, acc: 69.53%, op_acc: 41.41%] [G loss: 0.880347]\n",
      "epoch:15 step:12324[D loss: 0.429616, acc: 58.59%, op_acc: 37.50%] [G loss: 0.854606]\n",
      "epoch:15 step:12325[D loss: 0.418000, acc: 61.72%, op_acc: 41.41%] [G loss: 0.948505]\n",
      "epoch:15 step:12326[D loss: 0.437798, acc: 54.69%, op_acc: 38.28%] [G loss: 0.884387]\n",
      "epoch:15 step:12327[D loss: 0.381164, acc: 75.00%, op_acc: 41.41%] [G loss: 0.938086]\n",
      "epoch:15 step:12328[D loss: 0.428225, acc: 58.59%, op_acc: 39.84%] [G loss: 0.903422]\n",
      "epoch:15 step:12329[D loss: 0.414341, acc: 61.72%, op_acc: 42.97%] [G loss: 0.928638]\n",
      "epoch:15 step:12330[D loss: 0.434756, acc: 57.81%, op_acc: 36.72%] [G loss: 0.893820]\n",
      "epoch:15 step:12331[D loss: 0.439287, acc: 58.59%, op_acc: 37.50%] [G loss: 0.869457]\n",
      "epoch:15 step:12332[D loss: 0.426523, acc: 63.28%, op_acc: 34.38%] [G loss: 0.852219]\n",
      "epoch:15 step:12333[D loss: 0.438901, acc: 47.66%, op_acc: 37.50%] [G loss: 0.836720]\n",
      "epoch:15 step:12334[D loss: 0.466651, acc: 54.69%, op_acc: 35.94%] [G loss: 0.793865]\n",
      "epoch:15 step:12335[D loss: 0.444375, acc: 57.81%, op_acc: 36.72%] [G loss: 0.851031]\n",
      "epoch:15 step:12336[D loss: 0.422843, acc: 59.38%, op_acc: 40.62%] [G loss: 0.916091]\n",
      "epoch:15 step:12337[D loss: 0.456362, acc: 60.94%, op_acc: 35.94%] [G loss: 0.957833]\n",
      "epoch:15 step:12338[D loss: 0.410510, acc: 60.94%, op_acc: 41.41%] [G loss: 0.991587]\n",
      "epoch:15 step:12339[D loss: 0.443921, acc: 53.12%, op_acc: 36.72%] [G loss: 0.971893]\n",
      "epoch:15 step:12340[D loss: 0.414638, acc: 64.84%, op_acc: 37.50%] [G loss: 0.924894]\n",
      "epoch:15 step:12341[D loss: 0.404329, acc: 63.28%, op_acc: 41.41%] [G loss: 0.937074]\n",
      "epoch:15 step:12342[D loss: 0.410191, acc: 63.28%, op_acc: 43.75%] [G loss: 1.017744]\n",
      "epoch:15 step:12343[D loss: 0.433561, acc: 60.16%, op_acc: 36.72%] [G loss: 0.899698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12344[D loss: 0.438740, acc: 62.50%, op_acc: 32.03%] [G loss: 0.934090]\n",
      "epoch:15 step:12345[D loss: 0.389779, acc: 68.75%, op_acc: 43.75%] [G loss: 0.954967]\n",
      "epoch:15 step:12346[D loss: 0.430468, acc: 67.19%, op_acc: 39.84%] [G loss: 0.945725]\n",
      "epoch:15 step:12347[D loss: 0.440745, acc: 60.94%, op_acc: 32.03%] [G loss: 0.861727]\n",
      "epoch:15 step:12348[D loss: 0.426364, acc: 64.06%, op_acc: 32.81%] [G loss: 0.820019]\n",
      "epoch:15 step:12349[D loss: 0.424141, acc: 60.16%, op_acc: 42.19%] [G loss: 0.885563]\n",
      "epoch:15 step:12350[D loss: 0.432493, acc: 57.03%, op_acc: 35.94%] [G loss: 0.829637]\n",
      "##############\n",
      "[0.86139975 0.8520614  0.81989557 0.80827996 0.80680394 0.83642522\n",
      " 0.88336448 0.82397109 0.82097494 0.83646365]\n",
      "##########\n",
      "epoch:15 step:12351[D loss: 0.405055, acc: 63.28%, op_acc: 45.31%] [G loss: 0.876359]\n",
      "epoch:15 step:12352[D loss: 0.444310, acc: 56.25%, op_acc: 40.62%] [G loss: 0.852076]\n",
      "epoch:15 step:12353[D loss: 0.457723, acc: 53.12%, op_acc: 36.72%] [G loss: 0.945224]\n",
      "epoch:15 step:12354[D loss: 0.472345, acc: 53.12%, op_acc: 35.94%] [G loss: 0.807718]\n",
      "epoch:15 step:12355[D loss: 0.469789, acc: 53.91%, op_acc: 39.84%] [G loss: 0.871237]\n",
      "epoch:15 step:12356[D loss: 0.441514, acc: 65.62%, op_acc: 28.91%] [G loss: 0.899185]\n",
      "epoch:15 step:12357[D loss: 0.453253, acc: 51.56%, op_acc: 33.59%] [G loss: 0.869864]\n",
      "epoch:15 step:12358[D loss: 0.443579, acc: 58.59%, op_acc: 33.59%] [G loss: 0.900881]\n",
      "epoch:15 step:12359[D loss: 0.420728, acc: 57.81%, op_acc: 43.75%] [G loss: 0.893738]\n",
      "epoch:15 step:12360[D loss: 0.410096, acc: 66.41%, op_acc: 41.41%] [G loss: 0.939215]\n",
      "epoch:15 step:12361[D loss: 0.426219, acc: 65.62%, op_acc: 38.28%] [G loss: 1.009416]\n",
      "epoch:15 step:12362[D loss: 0.418145, acc: 67.19%, op_acc: 37.50%] [G loss: 0.876494]\n",
      "epoch:15 step:12363[D loss: 0.404990, acc: 66.41%, op_acc: 35.94%] [G loss: 0.972766]\n",
      "epoch:15 step:12364[D loss: 0.405250, acc: 65.62%, op_acc: 42.97%] [G loss: 0.858474]\n",
      "epoch:15 step:12365[D loss: 0.431382, acc: 72.66%, op_acc: 32.81%] [G loss: 0.841135]\n",
      "epoch:15 step:12366[D loss: 0.421604, acc: 61.72%, op_acc: 35.94%] [G loss: 0.923962]\n",
      "epoch:15 step:12367[D loss: 0.416055, acc: 60.16%, op_acc: 41.41%] [G loss: 0.889500]\n",
      "epoch:15 step:12368[D loss: 0.395408, acc: 62.50%, op_acc: 39.06%] [G loss: 0.884778]\n",
      "epoch:15 step:12369[D loss: 0.423861, acc: 57.03%, op_acc: 44.53%] [G loss: 0.874816]\n",
      "epoch:15 step:12370[D loss: 0.421751, acc: 62.50%, op_acc: 37.50%] [G loss: 0.912642]\n",
      "epoch:15 step:12371[D loss: 0.427471, acc: 63.28%, op_acc: 36.72%] [G loss: 0.895593]\n",
      "epoch:15 step:12372[D loss: 0.447761, acc: 54.69%, op_acc: 39.06%] [G loss: 0.858192]\n",
      "epoch:15 step:12373[D loss: 0.426545, acc: 64.06%, op_acc: 39.06%] [G loss: 0.835428]\n",
      "epoch:15 step:12374[D loss: 0.449173, acc: 53.91%, op_acc: 34.38%] [G loss: 0.928864]\n",
      "epoch:15 step:12375[D loss: 0.440503, acc: 52.34%, op_acc: 42.19%] [G loss: 0.841660]\n",
      "epoch:15 step:12376[D loss: 0.438706, acc: 51.56%, op_acc: 40.62%] [G loss: 0.900317]\n",
      "epoch:15 step:12377[D loss: 0.408303, acc: 61.72%, op_acc: 45.31%] [G loss: 0.879978]\n",
      "epoch:15 step:12378[D loss: 0.411405, acc: 65.62%, op_acc: 37.50%] [G loss: 0.894782]\n",
      "epoch:15 step:12379[D loss: 0.400091, acc: 65.62%, op_acc: 40.62%] [G loss: 0.931661]\n",
      "epoch:15 step:12380[D loss: 0.447103, acc: 64.06%, op_acc: 31.25%] [G loss: 0.935990]\n",
      "epoch:15 step:12381[D loss: 0.415439, acc: 67.97%, op_acc: 40.62%] [G loss: 0.949628]\n",
      "epoch:15 step:12382[D loss: 0.414231, acc: 58.59%, op_acc: 36.72%] [G loss: 0.988137]\n",
      "epoch:15 step:12383[D loss: 0.425595, acc: 60.16%, op_acc: 41.41%] [G loss: 0.923669]\n",
      "epoch:15 step:12384[D loss: 0.426793, acc: 66.41%, op_acc: 36.72%] [G loss: 0.916215]\n",
      "epoch:15 step:12385[D loss: 0.436410, acc: 59.38%, op_acc: 36.72%] [G loss: 0.872827]\n",
      "epoch:15 step:12386[D loss: 0.438391, acc: 58.59%, op_acc: 40.62%] [G loss: 0.966046]\n",
      "epoch:15 step:12387[D loss: 0.428007, acc: 66.41%, op_acc: 35.16%] [G loss: 0.956904]\n",
      "epoch:15 step:12388[D loss: 0.439030, acc: 58.59%, op_acc: 38.28%] [G loss: 0.995581]\n",
      "epoch:15 step:12389[D loss: 0.416916, acc: 62.50%, op_acc: 41.41%] [G loss: 0.866895]\n",
      "epoch:15 step:12390[D loss: 0.458534, acc: 47.66%, op_acc: 35.16%] [G loss: 0.938211]\n",
      "epoch:15 step:12391[D loss: 0.459047, acc: 52.34%, op_acc: 34.38%] [G loss: 0.860100]\n",
      "epoch:15 step:12392[D loss: 0.439715, acc: 53.12%, op_acc: 36.72%] [G loss: 0.867794]\n",
      "epoch:15 step:12393[D loss: 0.413099, acc: 60.94%, op_acc: 38.28%] [G loss: 0.946671]\n",
      "epoch:15 step:12394[D loss: 0.421930, acc: 54.69%, op_acc: 42.97%] [G loss: 0.919023]\n",
      "epoch:15 step:12395[D loss: 0.445226, acc: 57.03%, op_acc: 32.03%] [G loss: 0.844505]\n",
      "epoch:15 step:12396[D loss: 0.462894, acc: 49.22%, op_acc: 36.72%] [G loss: 0.872239]\n",
      "epoch:15 step:12397[D loss: 0.418605, acc: 59.38%, op_acc: 42.97%] [G loss: 0.937689]\n",
      "epoch:15 step:12398[D loss: 0.456677, acc: 53.91%, op_acc: 38.28%] [G loss: 0.923270]\n",
      "epoch:15 step:12399[D loss: 0.447359, acc: 58.59%, op_acc: 34.38%] [G loss: 0.896882]\n",
      "epoch:15 step:12400[D loss: 0.440199, acc: 61.72%, op_acc: 38.28%] [G loss: 0.921529]\n",
      "##############\n",
      "[0.8481667  0.84909348 0.82726549 0.8051573  0.78813169 0.83126055\n",
      " 0.89183803 0.82827839 0.79668926 0.83805864]\n",
      "##########\n",
      "epoch:15 step:12401[D loss: 0.442201, acc: 54.69%, op_acc: 35.16%] [G loss: 0.920569]\n",
      "epoch:15 step:12402[D loss: 0.405674, acc: 58.59%, op_acc: 40.62%] [G loss: 0.901973]\n",
      "epoch:15 step:12403[D loss: 0.417416, acc: 56.25%, op_acc: 43.75%] [G loss: 0.847895]\n",
      "epoch:15 step:12404[D loss: 0.461419, acc: 53.12%, op_acc: 35.16%] [G loss: 0.855235]\n",
      "epoch:15 step:12405[D loss: 0.436763, acc: 60.94%, op_acc: 36.72%] [G loss: 0.837242]\n",
      "epoch:15 step:12406[D loss: 0.424314, acc: 63.28%, op_acc: 36.72%] [G loss: 0.888256]\n",
      "epoch:15 step:12407[D loss: 0.446619, acc: 55.47%, op_acc: 33.59%] [G loss: 0.879577]\n",
      "epoch:15 step:12408[D loss: 0.409052, acc: 64.06%, op_acc: 35.94%] [G loss: 0.905250]\n",
      "epoch:15 step:12409[D loss: 0.422565, acc: 55.47%, op_acc: 40.62%] [G loss: 0.888053]\n",
      "epoch:15 step:12410[D loss: 0.411483, acc: 58.59%, op_acc: 32.81%] [G loss: 0.903112]\n",
      "epoch:15 step:12411[D loss: 0.445571, acc: 57.03%, op_acc: 32.03%] [G loss: 0.885542]\n",
      "epoch:15 step:12412[D loss: 0.394061, acc: 71.88%, op_acc: 41.41%] [G loss: 0.959575]\n",
      "epoch:15 step:12413[D loss: 0.425638, acc: 67.19%, op_acc: 36.72%] [G loss: 0.895020]\n",
      "epoch:15 step:12414[D loss: 0.415691, acc: 63.28%, op_acc: 37.50%] [G loss: 0.876050]\n",
      "epoch:15 step:12415[D loss: 0.458078, acc: 56.25%, op_acc: 33.59%] [G loss: 0.834180]\n",
      "epoch:15 step:12416[D loss: 0.431869, acc: 64.84%, op_acc: 31.25%] [G loss: 0.872717]\n",
      "epoch:15 step:12417[D loss: 0.452095, acc: 50.00%, op_acc: 33.59%] [G loss: 0.859873]\n",
      "epoch:15 step:12418[D loss: 0.436934, acc: 55.47%, op_acc: 36.72%] [G loss: 0.804083]\n",
      "epoch:15 step:12419[D loss: 0.398718, acc: 64.84%, op_acc: 45.31%] [G loss: 0.903272]\n",
      "epoch:15 step:12420[D loss: 0.442086, acc: 60.16%, op_acc: 39.06%] [G loss: 0.837785]\n",
      "epoch:15 step:12421[D loss: 0.414500, acc: 67.19%, op_acc: 38.28%] [G loss: 0.831501]\n",
      "epoch:15 step:12422[D loss: 0.445700, acc: 61.72%, op_acc: 34.38%] [G loss: 0.875772]\n",
      "epoch:15 step:12423[D loss: 0.440678, acc: 57.81%, op_acc: 34.38%] [G loss: 0.843017]\n",
      "epoch:15 step:12424[D loss: 0.438320, acc: 54.69%, op_acc: 39.84%] [G loss: 0.933252]\n",
      "epoch:15 step:12425[D loss: 0.405620, acc: 63.28%, op_acc: 41.41%] [G loss: 0.896803]\n",
      "epoch:15 step:12426[D loss: 0.440980, acc: 60.94%, op_acc: 36.72%] [G loss: 0.919596]\n",
      "epoch:15 step:12427[D loss: 0.406489, acc: 61.72%, op_acc: 42.19%] [G loss: 0.825899]\n",
      "epoch:15 step:12428[D loss: 0.425312, acc: 59.38%, op_acc: 39.06%] [G loss: 0.897451]\n",
      "epoch:15 step:12429[D loss: 0.471282, acc: 57.81%, op_acc: 34.38%] [G loss: 0.844022]\n",
      "epoch:15 step:12430[D loss: 0.439971, acc: 53.12%, op_acc: 35.94%] [G loss: 0.929580]\n",
      "epoch:15 step:12431[D loss: 0.443422, acc: 53.91%, op_acc: 35.16%] [G loss: 0.888105]\n",
      "epoch:15 step:12432[D loss: 0.436284, acc: 57.03%, op_acc: 36.72%] [G loss: 0.883175]\n",
      "epoch:15 step:12433[D loss: 0.426181, acc: 55.47%, op_acc: 43.75%] [G loss: 0.971054]\n",
      "epoch:15 step:12434[D loss: 0.410096, acc: 63.28%, op_acc: 45.31%] [G loss: 0.912800]\n",
      "epoch:15 step:12435[D loss: 0.432943, acc: 56.25%, op_acc: 38.28%] [G loss: 0.868067]\n",
      "epoch:15 step:12436[D loss: 0.423547, acc: 56.25%, op_acc: 38.28%] [G loss: 0.875361]\n",
      "epoch:15 step:12437[D loss: 0.444622, acc: 55.47%, op_acc: 35.94%] [G loss: 0.803670]\n",
      "epoch:15 step:12438[D loss: 0.420358, acc: 62.50%, op_acc: 38.28%] [G loss: 0.904725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12439[D loss: 0.498337, acc: 50.00%, op_acc: 32.03%] [G loss: 0.878108]\n",
      "epoch:15 step:12440[D loss: 0.427687, acc: 64.06%, op_acc: 35.94%] [G loss: 0.893851]\n",
      "epoch:15 step:12441[D loss: 0.438624, acc: 55.47%, op_acc: 38.28%] [G loss: 0.883989]\n",
      "epoch:15 step:12442[D loss: 0.435051, acc: 61.72%, op_acc: 35.94%] [G loss: 0.829057]\n",
      "epoch:15 step:12443[D loss: 0.461134, acc: 51.56%, op_acc: 38.28%] [G loss: 0.878735]\n",
      "epoch:15 step:12444[D loss: 0.422227, acc: 59.38%, op_acc: 42.19%] [G loss: 0.917694]\n",
      "epoch:15 step:12445[D loss: 0.405960, acc: 63.28%, op_acc: 47.66%] [G loss: 0.861616]\n",
      "epoch:15 step:12446[D loss: 0.424261, acc: 60.94%, op_acc: 42.19%] [G loss: 0.860589]\n",
      "epoch:15 step:12447[D loss: 0.457425, acc: 48.44%, op_acc: 33.59%] [G loss: 0.895527]\n",
      "epoch:15 step:12448[D loss: 0.424513, acc: 58.59%, op_acc: 39.06%] [G loss: 0.822206]\n",
      "epoch:15 step:12449[D loss: 0.452125, acc: 53.12%, op_acc: 39.84%] [G loss: 0.840187]\n",
      "epoch:15 step:12450[D loss: 0.438450, acc: 60.94%, op_acc: 34.38%] [G loss: 0.862027]\n",
      "##############\n",
      "[0.87262092 0.87283439 0.81726817 0.80663214 0.78092474 0.83444965\n",
      " 0.89232188 0.83517241 0.82639745 0.84431129]\n",
      "##########\n",
      "epoch:15 step:12451[D loss: 0.399076, acc: 73.44%, op_acc: 34.38%] [G loss: 0.943355]\n",
      "epoch:15 step:12452[D loss: 0.427176, acc: 53.91%, op_acc: 40.62%] [G loss: 0.878747]\n",
      "epoch:15 step:12453[D loss: 0.439206, acc: 58.59%, op_acc: 38.28%] [G loss: 0.917751]\n",
      "epoch:15 step:12454[D loss: 0.465033, acc: 46.88%, op_acc: 39.84%] [G loss: 0.845482]\n",
      "epoch:15 step:12455[D loss: 0.396366, acc: 63.28%, op_acc: 44.53%] [G loss: 0.900677]\n",
      "epoch:15 step:12456[D loss: 0.452472, acc: 54.69%, op_acc: 39.06%] [G loss: 0.868897]\n",
      "epoch:15 step:12457[D loss: 0.429159, acc: 60.94%, op_acc: 34.38%] [G loss: 0.911435]\n",
      "epoch:15 step:12458[D loss: 0.459622, acc: 51.56%, op_acc: 37.50%] [G loss: 0.863001]\n",
      "epoch:15 step:12459[D loss: 0.406187, acc: 64.06%, op_acc: 40.62%] [G loss: 0.854039]\n",
      "epoch:15 step:12460[D loss: 0.430240, acc: 54.69%, op_acc: 40.62%] [G loss: 0.829758]\n",
      "epoch:15 step:12461[D loss: 0.423363, acc: 59.38%, op_acc: 38.28%] [G loss: 0.933596]\n",
      "epoch:15 step:12462[D loss: 0.427920, acc: 60.16%, op_acc: 39.84%] [G loss: 0.866782]\n",
      "epoch:15 step:12463[D loss: 0.419323, acc: 62.50%, op_acc: 42.97%] [G loss: 0.853059]\n",
      "epoch:15 step:12464[D loss: 0.440954, acc: 57.81%, op_acc: 35.94%] [G loss: 0.887668]\n",
      "epoch:15 step:12465[D loss: 0.429620, acc: 60.16%, op_acc: 37.50%] [G loss: 0.799930]\n",
      "epoch:15 step:12466[D loss: 0.438630, acc: 59.38%, op_acc: 34.38%] [G loss: 0.878030]\n",
      "epoch:15 step:12467[D loss: 0.450944, acc: 57.81%, op_acc: 38.28%] [G loss: 0.772773]\n",
      "epoch:15 step:12468[D loss: 0.410056, acc: 62.50%, op_acc: 42.19%] [G loss: 0.924593]\n",
      "epoch:15 step:12469[D loss: 0.419080, acc: 62.50%, op_acc: 41.41%] [G loss: 0.851618]\n",
      "epoch:15 step:12470[D loss: 0.409882, acc: 62.50%, op_acc: 41.41%] [G loss: 0.927744]\n",
      "epoch:15 step:12471[D loss: 0.432980, acc: 57.81%, op_acc: 42.19%] [G loss: 0.816899]\n",
      "epoch:15 step:12472[D loss: 0.444616, acc: 50.00%, op_acc: 37.50%] [G loss: 0.826106]\n",
      "epoch:15 step:12473[D loss: 0.402478, acc: 65.62%, op_acc: 41.41%] [G loss: 0.918600]\n",
      "epoch:15 step:12474[D loss: 0.462916, acc: 51.56%, op_acc: 33.59%] [G loss: 0.853474]\n",
      "epoch:15 step:12475[D loss: 0.433522, acc: 47.66%, op_acc: 41.41%] [G loss: 0.870864]\n",
      "epoch:15 step:12476[D loss: 0.440311, acc: 50.00%, op_acc: 38.28%] [G loss: 0.865651]\n",
      "epoch:15 step:12477[D loss: 0.448093, acc: 52.34%, op_acc: 38.28%] [G loss: 0.852987]\n",
      "epoch:15 step:12478[D loss: 0.433162, acc: 58.59%, op_acc: 33.59%] [G loss: 0.874256]\n",
      "epoch:15 step:12479[D loss: 0.417403, acc: 58.59%, op_acc: 39.84%] [G loss: 0.877246]\n",
      "epoch:15 step:12480[D loss: 0.410320, acc: 57.81%, op_acc: 49.22%] [G loss: 0.906688]\n",
      "epoch:15 step:12481[D loss: 0.425032, acc: 60.94%, op_acc: 35.94%] [G loss: 0.957547]\n",
      "epoch:15 step:12482[D loss: 0.434883, acc: 57.81%, op_acc: 36.72%] [G loss: 0.888573]\n",
      "epoch:15 step:12483[D loss: 0.402773, acc: 64.84%, op_acc: 38.28%] [G loss: 0.833396]\n",
      "epoch:15 step:12484[D loss: 0.417174, acc: 65.62%, op_acc: 42.97%] [G loss: 0.806990]\n",
      "epoch:15 step:12485[D loss: 0.446106, acc: 49.22%, op_acc: 38.28%] [G loss: 0.854983]\n",
      "epoch:15 step:12486[D loss: 0.493127, acc: 50.78%, op_acc: 32.03%] [G loss: 0.819410]\n",
      "epoch:15 step:12487[D loss: 0.443022, acc: 53.12%, op_acc: 39.84%] [G loss: 0.854492]\n",
      "epoch:15 step:12488[D loss: 0.414239, acc: 62.50%, op_acc: 39.06%] [G loss: 0.895948]\n",
      "epoch:15 step:12489[D loss: 0.410867, acc: 60.94%, op_acc: 43.75%] [G loss: 0.842071]\n",
      "epoch:15 step:12490[D loss: 0.417611, acc: 59.38%, op_acc: 39.06%] [G loss: 0.950086]\n",
      "epoch:15 step:12491[D loss: 0.417361, acc: 62.50%, op_acc: 36.72%] [G loss: 0.874240]\n",
      "epoch:15 step:12492[D loss: 0.471246, acc: 55.47%, op_acc: 29.69%] [G loss: 0.854243]\n",
      "epoch:15 step:12493[D loss: 0.404442, acc: 60.16%, op_acc: 40.62%] [G loss: 0.931780]\n",
      "epoch:15 step:12494[D loss: 0.422656, acc: 65.62%, op_acc: 36.72%] [G loss: 0.867011]\n",
      "epoch:15 step:12495[D loss: 0.427156, acc: 60.16%, op_acc: 38.28%] [G loss: 0.946547]\n",
      "epoch:15 step:12496[D loss: 0.421754, acc: 66.41%, op_acc: 35.94%] [G loss: 0.911321]\n",
      "epoch:16 step:12497[D loss: 0.437955, acc: 55.47%, op_acc: 38.28%] [G loss: 0.885730]\n",
      "epoch:16 step:12498[D loss: 0.393620, acc: 66.41%, op_acc: 40.62%] [G loss: 0.854378]\n",
      "epoch:16 step:12499[D loss: 0.433481, acc: 50.78%, op_acc: 40.62%] [G loss: 0.884818]\n",
      "epoch:16 step:12500[D loss: 0.432628, acc: 52.34%, op_acc: 41.41%] [G loss: 0.884476]\n",
      "##############\n",
      "[0.87055925 0.8618347  0.79652665 0.79510198 0.77376312 0.8241872\n",
      " 0.88382022 0.84522855 0.81694007 0.82997932]\n",
      "##########\n",
      "epoch:16 step:12501[D loss: 0.413506, acc: 63.28%, op_acc: 43.75%] [G loss: 0.911790]\n",
      "epoch:16 step:12502[D loss: 0.458343, acc: 55.47%, op_acc: 35.94%] [G loss: 0.845218]\n",
      "epoch:16 step:12503[D loss: 0.409341, acc: 59.38%, op_acc: 40.62%] [G loss: 0.916526]\n",
      "epoch:16 step:12504[D loss: 0.445468, acc: 61.72%, op_acc: 41.41%] [G loss: 0.852720]\n",
      "epoch:16 step:12505[D loss: 0.393582, acc: 62.50%, op_acc: 40.62%] [G loss: 0.912918]\n",
      "epoch:16 step:12506[D loss: 0.439243, acc: 59.38%, op_acc: 35.94%] [G loss: 0.942833]\n",
      "epoch:16 step:12507[D loss: 0.434524, acc: 60.94%, op_acc: 35.94%] [G loss: 0.880246]\n",
      "epoch:16 step:12508[D loss: 0.417799, acc: 60.94%, op_acc: 45.31%] [G loss: 0.920912]\n",
      "epoch:16 step:12509[D loss: 0.434646, acc: 53.91%, op_acc: 39.84%] [G loss: 0.831842]\n",
      "epoch:16 step:12510[D loss: 0.427473, acc: 61.72%, op_acc: 36.72%] [G loss: 0.927108]\n",
      "epoch:16 step:12511[D loss: 0.427229, acc: 60.16%, op_acc: 39.06%] [G loss: 0.928624]\n",
      "epoch:16 step:12512[D loss: 0.398592, acc: 55.47%, op_acc: 46.09%] [G loss: 0.847904]\n",
      "epoch:16 step:12513[D loss: 0.435976, acc: 58.59%, op_acc: 42.97%] [G loss: 0.929463]\n",
      "epoch:16 step:12514[D loss: 0.444131, acc: 57.81%, op_acc: 35.16%] [G loss: 0.819097]\n",
      "epoch:16 step:12515[D loss: 0.419648, acc: 57.81%, op_acc: 36.72%] [G loss: 0.787986]\n",
      "epoch:16 step:12516[D loss: 0.420204, acc: 62.50%, op_acc: 37.50%] [G loss: 0.893351]\n",
      "epoch:16 step:12517[D loss: 0.448212, acc: 59.38%, op_acc: 31.25%] [G loss: 0.894319]\n",
      "epoch:16 step:12518[D loss: 0.424500, acc: 60.16%, op_acc: 39.84%] [G loss: 0.881301]\n",
      "epoch:16 step:12519[D loss: 0.459449, acc: 49.22%, op_acc: 35.94%] [G loss: 0.854696]\n",
      "epoch:16 step:12520[D loss: 0.476492, acc: 59.38%, op_acc: 35.94%] [G loss: 0.826428]\n",
      "epoch:16 step:12521[D loss: 0.465301, acc: 48.44%, op_acc: 34.38%] [G loss: 0.818482]\n",
      "epoch:16 step:12522[D loss: 0.416751, acc: 59.38%, op_acc: 43.75%] [G loss: 0.890299]\n",
      "epoch:16 step:12523[D loss: 0.420256, acc: 58.59%, op_acc: 37.50%] [G loss: 0.900976]\n",
      "epoch:16 step:12524[D loss: 0.426627, acc: 58.59%, op_acc: 39.84%] [G loss: 0.917144]\n",
      "epoch:16 step:12525[D loss: 0.402991, acc: 61.72%, op_acc: 42.97%] [G loss: 0.872469]\n",
      "epoch:16 step:12526[D loss: 0.398358, acc: 67.19%, op_acc: 42.19%] [G loss: 0.848430]\n",
      "epoch:16 step:12527[D loss: 0.458204, acc: 59.38%, op_acc: 32.03%] [G loss: 0.895066]\n",
      "epoch:16 step:12528[D loss: 0.438096, acc: 61.72%, op_acc: 31.25%] [G loss: 0.890836]\n",
      "epoch:16 step:12529[D loss: 0.417430, acc: 67.19%, op_acc: 36.72%] [G loss: 0.992591]\n",
      "epoch:16 step:12530[D loss: 0.418320, acc: 62.50%, op_acc: 33.59%] [G loss: 0.875525]\n",
      "epoch:16 step:12531[D loss: 0.438059, acc: 57.03%, op_acc: 35.16%] [G loss: 0.861052]\n",
      "epoch:16 step:12532[D loss: 0.430135, acc: 64.84%, op_acc: 42.19%] [G loss: 0.961111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12533[D loss: 0.442436, acc: 53.12%, op_acc: 35.94%] [G loss: 0.843042]\n",
      "epoch:16 step:12534[D loss: 0.409138, acc: 62.50%, op_acc: 40.62%] [G loss: 0.930471]\n",
      "epoch:16 step:12535[D loss: 0.424455, acc: 57.81%, op_acc: 40.62%] [G loss: 0.814006]\n",
      "epoch:16 step:12536[D loss: 0.430909, acc: 59.38%, op_acc: 32.81%] [G loss: 0.847397]\n",
      "epoch:16 step:12537[D loss: 0.396812, acc: 59.38%, op_acc: 42.97%] [G loss: 0.922336]\n",
      "epoch:16 step:12538[D loss: 0.399635, acc: 67.19%, op_acc: 43.75%] [G loss: 0.923709]\n",
      "epoch:16 step:12539[D loss: 0.424791, acc: 64.84%, op_acc: 39.06%] [G loss: 0.833297]\n",
      "epoch:16 step:12540[D loss: 0.427440, acc: 57.81%, op_acc: 35.94%] [G loss: 0.813089]\n",
      "epoch:16 step:12541[D loss: 0.436480, acc: 59.38%, op_acc: 33.59%] [G loss: 0.824012]\n",
      "epoch:16 step:12542[D loss: 0.415273, acc: 62.50%, op_acc: 38.28%] [G loss: 0.893364]\n",
      "epoch:16 step:12543[D loss: 0.438812, acc: 61.72%, op_acc: 32.03%] [G loss: 0.913980]\n",
      "epoch:16 step:12544[D loss: 0.439181, acc: 64.84%, op_acc: 33.59%] [G loss: 0.814615]\n",
      "epoch:16 step:12545[D loss: 0.436174, acc: 58.59%, op_acc: 35.94%] [G loss: 0.866924]\n",
      "epoch:16 step:12546[D loss: 0.447404, acc: 50.00%, op_acc: 33.59%] [G loss: 0.887670]\n",
      "epoch:16 step:12547[D loss: 0.402483, acc: 64.84%, op_acc: 35.94%] [G loss: 0.868011]\n",
      "epoch:16 step:12548[D loss: 0.435536, acc: 61.72%, op_acc: 34.38%] [G loss: 0.937660]\n",
      "epoch:16 step:12549[D loss: 0.450234, acc: 57.81%, op_acc: 36.72%] [G loss: 0.872047]\n",
      "epoch:16 step:12550[D loss: 0.474517, acc: 50.78%, op_acc: 39.06%] [G loss: 0.915763]\n",
      "##############\n",
      "[0.85353519 0.8548948  0.83871391 0.83023896 0.80349942 0.83774691\n",
      " 0.87864882 0.82088761 0.82714252 0.81446633]\n",
      "##########\n",
      "epoch:16 step:12551[D loss: 0.452983, acc: 51.56%, op_acc: 40.62%] [G loss: 0.873861]\n",
      "epoch:16 step:12552[D loss: 0.444744, acc: 57.03%, op_acc: 35.16%] [G loss: 0.803573]\n",
      "epoch:16 step:12553[D loss: 0.447045, acc: 57.03%, op_acc: 36.72%] [G loss: 0.874891]\n",
      "epoch:16 step:12554[D loss: 0.395925, acc: 64.84%, op_acc: 42.97%] [G loss: 0.990088]\n",
      "epoch:16 step:12555[D loss: 0.418594, acc: 60.94%, op_acc: 41.41%] [G loss: 0.908236]\n",
      "epoch:16 step:12556[D loss: 0.433842, acc: 63.28%, op_acc: 36.72%] [G loss: 0.913464]\n",
      "epoch:16 step:12557[D loss: 0.426946, acc: 60.16%, op_acc: 35.94%] [G loss: 0.886573]\n",
      "epoch:16 step:12558[D loss: 0.448575, acc: 58.59%, op_acc: 34.38%] [G loss: 0.946822]\n",
      "epoch:16 step:12559[D loss: 0.444829, acc: 60.94%, op_acc: 32.03%] [G loss: 0.863397]\n",
      "epoch:16 step:12560[D loss: 0.429397, acc: 63.28%, op_acc: 36.72%] [G loss: 0.841874]\n",
      "epoch:16 step:12561[D loss: 0.471096, acc: 53.91%, op_acc: 36.72%] [G loss: 0.842459]\n",
      "epoch:16 step:12562[D loss: 0.409090, acc: 64.06%, op_acc: 43.75%] [G loss: 0.858056]\n",
      "epoch:16 step:12563[D loss: 0.431039, acc: 56.25%, op_acc: 39.84%] [G loss: 0.795737]\n",
      "epoch:16 step:12564[D loss: 0.431393, acc: 56.25%, op_acc: 36.72%] [G loss: 0.870556]\n",
      "epoch:16 step:12565[D loss: 0.416774, acc: 57.03%, op_acc: 42.97%] [G loss: 0.853196]\n",
      "epoch:16 step:12566[D loss: 0.443980, acc: 54.69%, op_acc: 36.72%] [G loss: 0.852965]\n",
      "epoch:16 step:12567[D loss: 0.458318, acc: 63.28%, op_acc: 32.03%] [G loss: 0.863212]\n",
      "epoch:16 step:12568[D loss: 0.417990, acc: 59.38%, op_acc: 42.19%] [G loss: 0.887139]\n",
      "epoch:16 step:12569[D loss: 0.427230, acc: 60.16%, op_acc: 39.06%] [G loss: 0.897945]\n",
      "epoch:16 step:12570[D loss: 0.410219, acc: 55.47%, op_acc: 49.22%] [G loss: 0.897463]\n",
      "epoch:16 step:12571[D loss: 0.418845, acc: 59.38%, op_acc: 34.38%] [G loss: 0.963110]\n",
      "epoch:16 step:12572[D loss: 0.449833, acc: 53.12%, op_acc: 42.97%] [G loss: 0.878639]\n",
      "epoch:16 step:12573[D loss: 0.427130, acc: 56.25%, op_acc: 39.06%] [G loss: 0.785517]\n",
      "epoch:16 step:12574[D loss: 0.470275, acc: 52.34%, op_acc: 32.03%] [G loss: 0.839893]\n",
      "epoch:16 step:12575[D loss: 0.438560, acc: 60.94%, op_acc: 33.59%] [G loss: 0.872726]\n",
      "epoch:16 step:12576[D loss: 0.484212, acc: 45.31%, op_acc: 33.59%] [G loss: 0.891381]\n",
      "epoch:16 step:12577[D loss: 0.453695, acc: 46.88%, op_acc: 38.28%] [G loss: 0.888840]\n",
      "epoch:16 step:12578[D loss: 0.406617, acc: 63.28%, op_acc: 36.72%] [G loss: 0.896869]\n",
      "epoch:16 step:12579[D loss: 0.438501, acc: 60.16%, op_acc: 39.06%] [G loss: 0.874712]\n",
      "epoch:16 step:12580[D loss: 0.439904, acc: 62.50%, op_acc: 39.06%] [G loss: 0.837454]\n",
      "epoch:16 step:12581[D loss: 0.460363, acc: 48.44%, op_acc: 33.59%] [G loss: 0.891186]\n",
      "epoch:16 step:12582[D loss: 0.426398, acc: 56.25%, op_acc: 35.16%] [G loss: 0.923885]\n",
      "epoch:16 step:12583[D loss: 0.449379, acc: 57.81%, op_acc: 35.16%] [G loss: 0.929410]\n",
      "epoch:16 step:12584[D loss: 0.413546, acc: 66.41%, op_acc: 36.72%] [G loss: 0.879592]\n",
      "epoch:16 step:12585[D loss: 0.423807, acc: 62.50%, op_acc: 39.06%] [G loss: 0.870665]\n",
      "epoch:16 step:12586[D loss: 0.417964, acc: 60.94%, op_acc: 40.62%] [G loss: 0.898609]\n",
      "epoch:16 step:12587[D loss: 0.426479, acc: 57.03%, op_acc: 37.50%] [G loss: 0.826049]\n",
      "epoch:16 step:12588[D loss: 0.426714, acc: 59.38%, op_acc: 36.72%] [G loss: 0.913276]\n",
      "epoch:16 step:12589[D loss: 0.403251, acc: 67.19%, op_acc: 43.75%] [G loss: 0.893223]\n",
      "epoch:16 step:12590[D loss: 0.434107, acc: 57.81%, op_acc: 39.84%] [G loss: 0.911422]\n",
      "epoch:16 step:12591[D loss: 0.402734, acc: 61.72%, op_acc: 39.84%] [G loss: 0.918335]\n",
      "epoch:16 step:12592[D loss: 0.474373, acc: 54.69%, op_acc: 35.94%] [G loss: 0.890162]\n",
      "epoch:16 step:12593[D loss: 0.428181, acc: 58.59%, op_acc: 35.94%] [G loss: 0.865501]\n",
      "epoch:16 step:12594[D loss: 0.435808, acc: 57.81%, op_acc: 35.16%] [G loss: 0.967017]\n",
      "epoch:16 step:12595[D loss: 0.397249, acc: 63.28%, op_acc: 42.97%] [G loss: 0.948777]\n",
      "epoch:16 step:12596[D loss: 0.392310, acc: 66.41%, op_acc: 43.75%] [G loss: 0.912862]\n",
      "epoch:16 step:12597[D loss: 0.421343, acc: 60.94%, op_acc: 39.06%] [G loss: 0.967635]\n",
      "epoch:16 step:12598[D loss: 0.448791, acc: 56.25%, op_acc: 38.28%] [G loss: 0.950571]\n",
      "epoch:16 step:12599[D loss: 0.423865, acc: 61.72%, op_acc: 38.28%] [G loss: 0.920431]\n",
      "epoch:16 step:12600[D loss: 0.461495, acc: 59.38%, op_acc: 35.94%] [G loss: 0.884882]\n",
      "##############\n",
      "[0.85762284 0.87593445 0.79010798 0.82074125 0.79523755 0.82960279\n",
      " 0.87912303 0.83813394 0.82473794 0.82986383]\n",
      "##########\n",
      "epoch:16 step:12601[D loss: 0.439746, acc: 49.22%, op_acc: 43.75%] [G loss: 0.919017]\n",
      "epoch:16 step:12602[D loss: 0.426939, acc: 57.81%, op_acc: 39.84%] [G loss: 0.852261]\n",
      "epoch:16 step:12603[D loss: 0.428594, acc: 53.91%, op_acc: 36.72%] [G loss: 0.845337]\n",
      "epoch:16 step:12604[D loss: 0.450972, acc: 57.03%, op_acc: 31.25%] [G loss: 0.890234]\n",
      "epoch:16 step:12605[D loss: 0.435903, acc: 60.16%, op_acc: 35.16%] [G loss: 0.960269]\n",
      "epoch:16 step:12606[D loss: 0.438914, acc: 60.94%, op_acc: 37.50%] [G loss: 0.898391]\n",
      "epoch:16 step:12607[D loss: 0.461777, acc: 56.25%, op_acc: 30.47%] [G loss: 0.889268]\n",
      "epoch:16 step:12608[D loss: 0.407561, acc: 60.16%, op_acc: 35.94%] [G loss: 0.951797]\n",
      "epoch:16 step:12609[D loss: 0.428936, acc: 59.38%, op_acc: 33.59%] [G loss: 0.957549]\n",
      "epoch:16 step:12610[D loss: 0.425767, acc: 52.34%, op_acc: 43.75%] [G loss: 0.873700]\n",
      "epoch:16 step:12611[D loss: 0.432004, acc: 55.47%, op_acc: 43.75%] [G loss: 0.859031]\n",
      "epoch:16 step:12612[D loss: 0.474886, acc: 48.44%, op_acc: 30.47%] [G loss: 0.867759]\n",
      "epoch:16 step:12613[D loss: 0.414821, acc: 60.16%, op_acc: 36.72%] [G loss: 0.883235]\n",
      "epoch:16 step:12614[D loss: 0.457156, acc: 53.12%, op_acc: 41.41%] [G loss: 0.817537]\n",
      "epoch:16 step:12615[D loss: 0.396898, acc: 67.97%, op_acc: 32.81%] [G loss: 0.817188]\n",
      "epoch:16 step:12616[D loss: 0.429929, acc: 53.12%, op_acc: 32.03%] [G loss: 0.853198]\n",
      "epoch:16 step:12617[D loss: 0.451929, acc: 57.03%, op_acc: 39.84%] [G loss: 0.882315]\n",
      "epoch:16 step:12618[D loss: 0.437057, acc: 61.72%, op_acc: 38.28%] [G loss: 0.851490]\n",
      "epoch:16 step:12619[D loss: 0.432234, acc: 59.38%, op_acc: 37.50%] [G loss: 0.857375]\n",
      "epoch:16 step:12620[D loss: 0.430957, acc: 55.47%, op_acc: 39.06%] [G loss: 0.810069]\n",
      "epoch:16 step:12621[D loss: 0.469083, acc: 56.25%, op_acc: 28.91%] [G loss: 0.889691]\n",
      "epoch:16 step:12622[D loss: 0.427810, acc: 60.94%, op_acc: 36.72%] [G loss: 0.926041]\n",
      "epoch:16 step:12623[D loss: 0.432205, acc: 59.38%, op_acc: 35.16%] [G loss: 0.912745]\n",
      "epoch:16 step:12624[D loss: 0.428551, acc: 64.06%, op_acc: 40.62%] [G loss: 0.895212]\n",
      "epoch:16 step:12625[D loss: 0.437178, acc: 59.38%, op_acc: 35.94%] [G loss: 0.841012]\n",
      "epoch:16 step:12626[D loss: 0.444439, acc: 50.78%, op_acc: 34.38%] [G loss: 0.930256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12627[D loss: 0.410977, acc: 60.16%, op_acc: 37.50%] [G loss: 0.866557]\n",
      "epoch:16 step:12628[D loss: 0.405507, acc: 57.81%, op_acc: 41.41%] [G loss: 0.838803]\n",
      "epoch:16 step:12629[D loss: 0.465686, acc: 57.03%, op_acc: 27.34%] [G loss: 0.903420]\n",
      "epoch:16 step:12630[D loss: 0.448332, acc: 57.81%, op_acc: 37.50%] [G loss: 0.897778]\n",
      "epoch:16 step:12631[D loss: 0.449034, acc: 57.03%, op_acc: 39.06%] [G loss: 0.896558]\n",
      "epoch:16 step:12632[D loss: 0.402304, acc: 64.06%, op_acc: 39.06%] [G loss: 0.862206]\n",
      "epoch:16 step:12633[D loss: 0.426849, acc: 64.06%, op_acc: 36.72%] [G loss: 0.835042]\n",
      "epoch:16 step:12634[D loss: 0.438230, acc: 57.81%, op_acc: 32.03%] [G loss: 0.861089]\n",
      "epoch:16 step:12635[D loss: 0.435203, acc: 58.59%, op_acc: 36.72%] [G loss: 0.869828]\n",
      "epoch:16 step:12636[D loss: 0.479449, acc: 49.22%, op_acc: 37.50%] [G loss: 0.835813]\n",
      "epoch:16 step:12637[D loss: 0.430771, acc: 61.72%, op_acc: 36.72%] [G loss: 0.907444]\n",
      "epoch:16 step:12638[D loss: 0.421015, acc: 63.28%, op_acc: 40.62%] [G loss: 0.907845]\n",
      "epoch:16 step:12639[D loss: 0.437663, acc: 56.25%, op_acc: 37.50%] [G loss: 0.787971]\n",
      "epoch:16 step:12640[D loss: 0.437241, acc: 57.81%, op_acc: 37.50%] [G loss: 0.846866]\n",
      "epoch:16 step:12641[D loss: 0.436957, acc: 60.16%, op_acc: 35.94%] [G loss: 0.961848]\n",
      "epoch:16 step:12642[D loss: 0.441856, acc: 51.56%, op_acc: 36.72%] [G loss: 0.943973]\n",
      "epoch:16 step:12643[D loss: 0.436208, acc: 54.69%, op_acc: 39.06%] [G loss: 0.888140]\n",
      "epoch:16 step:12644[D loss: 0.438827, acc: 53.91%, op_acc: 42.97%] [G loss: 0.813222]\n",
      "epoch:16 step:12645[D loss: 0.412671, acc: 60.94%, op_acc: 39.84%] [G loss: 0.925441]\n",
      "epoch:16 step:12646[D loss: 0.406965, acc: 64.06%, op_acc: 40.62%] [G loss: 0.940269]\n",
      "epoch:16 step:12647[D loss: 0.422774, acc: 63.28%, op_acc: 36.72%] [G loss: 0.913897]\n",
      "epoch:16 step:12648[D loss: 0.420492, acc: 54.69%, op_acc: 41.41%] [G loss: 0.775977]\n",
      "epoch:16 step:12649[D loss: 0.422687, acc: 67.97%, op_acc: 37.50%] [G loss: 1.006879]\n",
      "epoch:16 step:12650[D loss: 0.392388, acc: 64.06%, op_acc: 39.84%] [G loss: 0.898863]\n",
      "##############\n",
      "[0.84966735 0.85307544 0.798775   0.78602284 0.77159648 0.82097496\n",
      " 0.86786783 0.80690645 0.79469579 0.83934212]\n",
      "##########\n",
      "epoch:16 step:12651[D loss: 0.457485, acc: 51.56%, op_acc: 35.16%] [G loss: 0.866513]\n",
      "epoch:16 step:12652[D loss: 0.439347, acc: 55.47%, op_acc: 35.94%] [G loss: 0.849808]\n",
      "epoch:16 step:12653[D loss: 0.432390, acc: 61.72%, op_acc: 41.41%] [G loss: 0.833308]\n",
      "epoch:16 step:12654[D loss: 0.409604, acc: 61.72%, op_acc: 42.97%] [G loss: 0.882520]\n",
      "epoch:16 step:12655[D loss: 0.437824, acc: 62.50%, op_acc: 39.06%] [G loss: 0.824178]\n",
      "epoch:16 step:12656[D loss: 0.464090, acc: 52.34%, op_acc: 34.38%] [G loss: 0.873233]\n",
      "epoch:16 step:12657[D loss: 0.442034, acc: 56.25%, op_acc: 39.06%] [G loss: 0.845936]\n",
      "epoch:16 step:12658[D loss: 0.388946, acc: 72.66%, op_acc: 42.19%] [G loss: 0.893579]\n",
      "epoch:16 step:12659[D loss: 0.418359, acc: 61.72%, op_acc: 35.94%] [G loss: 0.905312]\n",
      "epoch:16 step:12660[D loss: 0.452070, acc: 60.94%, op_acc: 32.03%] [G loss: 0.863056]\n",
      "epoch:16 step:12661[D loss: 0.421205, acc: 60.94%, op_acc: 40.62%] [G loss: 0.848482]\n",
      "epoch:16 step:12662[D loss: 0.448367, acc: 54.69%, op_acc: 35.16%] [G loss: 0.871265]\n",
      "epoch:16 step:12663[D loss: 0.419994, acc: 59.38%, op_acc: 42.97%] [G loss: 0.912851]\n",
      "epoch:16 step:12664[D loss: 0.426927, acc: 55.47%, op_acc: 40.62%] [G loss: 0.849322]\n",
      "epoch:16 step:12665[D loss: 0.432490, acc: 60.94%, op_acc: 28.12%] [G loss: 0.881158]\n",
      "epoch:16 step:12666[D loss: 0.464514, acc: 57.81%, op_acc: 35.16%] [G loss: 0.896980]\n",
      "epoch:16 step:12667[D loss: 0.484411, acc: 50.00%, op_acc: 30.47%] [G loss: 0.895925]\n",
      "epoch:16 step:12668[D loss: 0.416092, acc: 61.72%, op_acc: 40.62%] [G loss: 0.870404]\n",
      "epoch:16 step:12669[D loss: 0.441347, acc: 56.25%, op_acc: 34.38%] [G loss: 0.879273]\n",
      "epoch:16 step:12670[D loss: 0.457640, acc: 61.72%, op_acc: 30.47%] [G loss: 0.839862]\n",
      "epoch:16 step:12671[D loss: 0.399270, acc: 68.75%, op_acc: 39.06%] [G loss: 0.989638]\n",
      "epoch:16 step:12672[D loss: 0.424241, acc: 60.94%, op_acc: 40.62%] [G loss: 0.954623]\n",
      "epoch:16 step:12673[D loss: 0.420818, acc: 63.28%, op_acc: 34.38%] [G loss: 0.915527]\n",
      "epoch:16 step:12674[D loss: 0.413776, acc: 64.84%, op_acc: 38.28%] [G loss: 0.893661]\n",
      "epoch:16 step:12675[D loss: 0.401459, acc: 62.50%, op_acc: 41.41%] [G loss: 0.902232]\n",
      "epoch:16 step:12676[D loss: 0.436572, acc: 57.03%, op_acc: 32.03%] [G loss: 0.901974]\n",
      "epoch:16 step:12677[D loss: 0.416718, acc: 61.72%, op_acc: 36.72%] [G loss: 0.913236]\n",
      "epoch:16 step:12678[D loss: 0.417401, acc: 57.81%, op_acc: 39.84%] [G loss: 0.891617]\n",
      "epoch:16 step:12679[D loss: 0.397299, acc: 65.62%, op_acc: 37.50%] [G loss: 0.935595]\n",
      "epoch:16 step:12680[D loss: 0.411475, acc: 58.59%, op_acc: 38.28%] [G loss: 0.941663]\n",
      "epoch:16 step:12681[D loss: 0.443083, acc: 62.50%, op_acc: 35.94%] [G loss: 0.851665]\n",
      "epoch:16 step:12682[D loss: 0.425595, acc: 57.03%, op_acc: 36.72%] [G loss: 0.899545]\n",
      "epoch:16 step:12683[D loss: 0.453342, acc: 52.34%, op_acc: 34.38%] [G loss: 0.869566]\n",
      "epoch:16 step:12684[D loss: 0.410772, acc: 61.72%, op_acc: 41.41%] [G loss: 0.925503]\n",
      "epoch:16 step:12685[D loss: 0.418970, acc: 62.50%, op_acc: 36.72%] [G loss: 0.959751]\n",
      "epoch:16 step:12686[D loss: 0.456327, acc: 49.22%, op_acc: 35.94%] [G loss: 0.845801]\n",
      "epoch:16 step:12687[D loss: 0.395208, acc: 66.41%, op_acc: 40.62%] [G loss: 0.865952]\n",
      "epoch:16 step:12688[D loss: 0.417007, acc: 62.50%, op_acc: 32.81%] [G loss: 0.946281]\n",
      "epoch:16 step:12689[D loss: 0.417760, acc: 63.28%, op_acc: 41.41%] [G loss: 0.926392]\n",
      "epoch:16 step:12690[D loss: 0.416500, acc: 64.06%, op_acc: 34.38%] [G loss: 0.916110]\n",
      "epoch:16 step:12691[D loss: 0.459114, acc: 52.34%, op_acc: 37.50%] [G loss: 0.857679]\n",
      "epoch:16 step:12692[D loss: 0.438374, acc: 61.72%, op_acc: 32.81%] [G loss: 0.884304]\n",
      "epoch:16 step:12693[D loss: 0.432389, acc: 58.59%, op_acc: 41.41%] [G loss: 1.006624]\n",
      "epoch:16 step:12694[D loss: 0.416510, acc: 62.50%, op_acc: 36.72%] [G loss: 0.846718]\n",
      "epoch:16 step:12695[D loss: 0.416419, acc: 59.38%, op_acc: 37.50%] [G loss: 0.949730]\n",
      "epoch:16 step:12696[D loss: 0.442035, acc: 60.94%, op_acc: 34.38%] [G loss: 0.872098]\n",
      "epoch:16 step:12697[D loss: 0.428793, acc: 60.16%, op_acc: 36.72%] [G loss: 0.991469]\n",
      "epoch:16 step:12698[D loss: 0.453053, acc: 54.69%, op_acc: 35.16%] [G loss: 0.901762]\n",
      "epoch:16 step:12699[D loss: 0.464287, acc: 54.69%, op_acc: 35.16%] [G loss: 0.847214]\n",
      "epoch:16 step:12700[D loss: 0.403833, acc: 67.19%, op_acc: 37.50%] [G loss: 0.901583]\n",
      "##############\n",
      "[0.84181371 0.87325118 0.80597525 0.7913061  0.78402605 0.84300651\n",
      " 0.88324604 0.82380397 0.78818321 0.83227412]\n",
      "##########\n",
      "epoch:16 step:12701[D loss: 0.435457, acc: 58.59%, op_acc: 36.72%] [G loss: 0.846307]\n",
      "epoch:16 step:12702[D loss: 0.422572, acc: 57.03%, op_acc: 38.28%] [G loss: 0.902152]\n",
      "epoch:16 step:12703[D loss: 0.393460, acc: 67.19%, op_acc: 37.50%] [G loss: 0.926765]\n",
      "epoch:16 step:12704[D loss: 0.443005, acc: 60.94%, op_acc: 31.25%] [G loss: 0.879542]\n",
      "epoch:16 step:12705[D loss: 0.460888, acc: 52.34%, op_acc: 41.41%] [G loss: 0.805458]\n",
      "epoch:16 step:12706[D loss: 0.424554, acc: 62.50%, op_acc: 34.38%] [G loss: 0.843185]\n",
      "epoch:16 step:12707[D loss: 0.417443, acc: 60.16%, op_acc: 41.41%] [G loss: 0.891603]\n",
      "epoch:16 step:12708[D loss: 0.428478, acc: 56.25%, op_acc: 36.72%] [G loss: 0.910628]\n",
      "epoch:16 step:12709[D loss: 0.433767, acc: 54.69%, op_acc: 39.06%] [G loss: 0.945857]\n",
      "epoch:16 step:12710[D loss: 0.445252, acc: 57.03%, op_acc: 32.81%] [G loss: 0.938304]\n",
      "epoch:16 step:12711[D loss: 0.433214, acc: 60.94%, op_acc: 29.69%] [G loss: 0.898439]\n",
      "epoch:16 step:12712[D loss: 0.440573, acc: 58.59%, op_acc: 37.50%] [G loss: 0.862475]\n",
      "epoch:16 step:12713[D loss: 0.411363, acc: 64.06%, op_acc: 42.19%] [G loss: 0.918200]\n",
      "epoch:16 step:12714[D loss: 0.413673, acc: 65.62%, op_acc: 41.41%] [G loss: 0.899948]\n",
      "epoch:16 step:12715[D loss: 0.399843, acc: 69.53%, op_acc: 39.06%] [G loss: 0.881716]\n",
      "epoch:16 step:12716[D loss: 0.427291, acc: 57.81%, op_acc: 32.81%] [G loss: 0.934082]\n",
      "epoch:16 step:12717[D loss: 0.428144, acc: 58.59%, op_acc: 36.72%] [G loss: 0.909673]\n",
      "epoch:16 step:12718[D loss: 0.431037, acc: 57.03%, op_acc: 40.62%] [G loss: 0.843852]\n",
      "epoch:16 step:12719[D loss: 0.427492, acc: 59.38%, op_acc: 36.72%] [G loss: 0.803728]\n",
      "epoch:16 step:12720[D loss: 0.427143, acc: 60.16%, op_acc: 32.03%] [G loss: 0.823560]\n",
      "epoch:16 step:12721[D loss: 0.439752, acc: 61.72%, op_acc: 32.03%] [G loss: 0.786397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12722[D loss: 0.432379, acc: 61.72%, op_acc: 39.06%] [G loss: 0.888507]\n",
      "epoch:16 step:12723[D loss: 0.423594, acc: 62.50%, op_acc: 38.28%] [G loss: 0.899161]\n",
      "epoch:16 step:12724[D loss: 0.424413, acc: 58.59%, op_acc: 40.62%] [G loss: 0.884289]\n",
      "epoch:16 step:12725[D loss: 0.445483, acc: 53.91%, op_acc: 38.28%] [G loss: 0.930968]\n",
      "epoch:16 step:12726[D loss: 0.470646, acc: 53.12%, op_acc: 32.03%] [G loss: 0.856639]\n",
      "epoch:16 step:12727[D loss: 0.404351, acc: 62.50%, op_acc: 41.41%] [G loss: 0.955899]\n",
      "epoch:16 step:12728[D loss: 0.442713, acc: 59.38%, op_acc: 36.72%] [G loss: 0.928668]\n",
      "epoch:16 step:12729[D loss: 0.410008, acc: 60.94%, op_acc: 41.41%] [G loss: 0.902031]\n",
      "epoch:16 step:12730[D loss: 0.443484, acc: 56.25%, op_acc: 35.94%] [G loss: 0.864177]\n",
      "epoch:16 step:12731[D loss: 0.421551, acc: 57.03%, op_acc: 43.75%] [G loss: 0.959546]\n",
      "epoch:16 step:12732[D loss: 0.436274, acc: 65.62%, op_acc: 34.38%] [G loss: 0.871654]\n",
      "epoch:16 step:12733[D loss: 0.410583, acc: 62.50%, op_acc: 37.50%] [G loss: 0.923509]\n",
      "epoch:16 step:12734[D loss: 0.474699, acc: 57.81%, op_acc: 31.25%] [G loss: 0.946527]\n",
      "epoch:16 step:12735[D loss: 0.424725, acc: 60.16%, op_acc: 38.28%] [G loss: 0.971466]\n",
      "epoch:16 step:12736[D loss: 0.427142, acc: 60.94%, op_acc: 37.50%] [G loss: 0.918527]\n",
      "epoch:16 step:12737[D loss: 0.444079, acc: 54.69%, op_acc: 35.94%] [G loss: 0.909517]\n",
      "epoch:16 step:12738[D loss: 0.423157, acc: 54.69%, op_acc: 44.53%] [G loss: 0.878109]\n",
      "epoch:16 step:12739[D loss: 0.422942, acc: 57.81%, op_acc: 39.06%] [G loss: 0.872230]\n",
      "epoch:16 step:12740[D loss: 0.437485, acc: 57.81%, op_acc: 39.06%] [G loss: 0.890373]\n",
      "epoch:16 step:12741[D loss: 0.426058, acc: 53.12%, op_acc: 37.50%] [G loss: 0.827158]\n",
      "epoch:16 step:12742[D loss: 0.458556, acc: 54.69%, op_acc: 36.72%] [G loss: 0.805640]\n",
      "epoch:16 step:12743[D loss: 0.454354, acc: 48.44%, op_acc: 33.59%] [G loss: 0.865055]\n",
      "epoch:16 step:12744[D loss: 0.463858, acc: 51.56%, op_acc: 33.59%] [G loss: 0.831235]\n",
      "epoch:16 step:12745[D loss: 0.423753, acc: 59.38%, op_acc: 42.19%] [G loss: 0.817020]\n",
      "epoch:16 step:12746[D loss: 0.430604, acc: 60.16%, op_acc: 36.72%] [G loss: 0.886289]\n",
      "epoch:16 step:12747[D loss: 0.408583, acc: 61.72%, op_acc: 44.53%] [G loss: 0.836357]\n",
      "epoch:16 step:12748[D loss: 0.408515, acc: 67.19%, op_acc: 36.72%] [G loss: 0.897711]\n",
      "epoch:16 step:12749[D loss: 0.429456, acc: 60.16%, op_acc: 35.16%] [G loss: 0.831702]\n",
      "epoch:16 step:12750[D loss: 0.433132, acc: 57.81%, op_acc: 36.72%] [G loss: 0.795269]\n",
      "##############\n",
      "[0.85139422 0.8770936  0.80318055 0.79875068 0.7856075  0.83512038\n",
      " 0.88483706 0.81874271 0.81573085 0.85881104]\n",
      "##########\n",
      "epoch:16 step:12751[D loss: 0.413512, acc: 67.97%, op_acc: 39.84%] [G loss: 0.857726]\n",
      "epoch:16 step:12752[D loss: 0.430201, acc: 57.81%, op_acc: 35.94%] [G loss: 0.890187]\n",
      "epoch:16 step:12753[D loss: 0.452038, acc: 57.81%, op_acc: 35.16%] [G loss: 0.903150]\n",
      "epoch:16 step:12754[D loss: 0.402064, acc: 64.06%, op_acc: 40.62%] [G loss: 0.889097]\n",
      "epoch:16 step:12755[D loss: 0.442467, acc: 60.94%, op_acc: 35.16%] [G loss: 0.826984]\n",
      "epoch:16 step:12756[D loss: 0.438625, acc: 62.50%, op_acc: 36.72%] [G loss: 0.903661]\n",
      "epoch:16 step:12757[D loss: 0.417149, acc: 62.50%, op_acc: 42.19%] [G loss: 0.870398]\n",
      "epoch:16 step:12758[D loss: 0.396113, acc: 69.53%, op_acc: 36.72%] [G loss: 0.919890]\n",
      "epoch:16 step:12759[D loss: 0.427222, acc: 58.59%, op_acc: 37.50%] [G loss: 0.832172]\n",
      "epoch:16 step:12760[D loss: 0.442599, acc: 58.59%, op_acc: 36.72%] [G loss: 0.900651]\n",
      "epoch:16 step:12761[D loss: 0.424289, acc: 60.94%, op_acc: 36.72%] [G loss: 0.862355]\n",
      "epoch:16 step:12762[D loss: 0.423113, acc: 60.16%, op_acc: 42.19%] [G loss: 0.826234]\n",
      "epoch:16 step:12763[D loss: 0.467051, acc: 56.25%, op_acc: 33.59%] [G loss: 0.838952]\n",
      "epoch:16 step:12764[D loss: 0.416358, acc: 60.16%, op_acc: 40.62%] [G loss: 0.895274]\n",
      "epoch:16 step:12765[D loss: 0.434104, acc: 60.16%, op_acc: 40.62%] [G loss: 0.910226]\n",
      "epoch:16 step:12766[D loss: 0.437106, acc: 59.38%, op_acc: 33.59%] [G loss: 0.864008]\n",
      "epoch:16 step:12767[D loss: 0.434687, acc: 64.84%, op_acc: 31.25%] [G loss: 0.937087]\n",
      "epoch:16 step:12768[D loss: 0.419558, acc: 61.72%, op_acc: 38.28%] [G loss: 0.855931]\n",
      "epoch:16 step:12769[D loss: 0.426839, acc: 59.38%, op_acc: 40.62%] [G loss: 0.888020]\n",
      "epoch:16 step:12770[D loss: 0.419970, acc: 66.41%, op_acc: 35.94%] [G loss: 0.881905]\n",
      "epoch:16 step:12771[D loss: 0.410776, acc: 60.94%, op_acc: 38.28%] [G loss: 0.890432]\n",
      "epoch:16 step:12772[D loss: 0.453482, acc: 52.34%, op_acc: 35.94%] [G loss: 0.847267]\n",
      "epoch:16 step:12773[D loss: 0.418257, acc: 64.84%, op_acc: 34.38%] [G loss: 0.895396]\n",
      "epoch:16 step:12774[D loss: 0.431565, acc: 60.16%, op_acc: 43.75%] [G loss: 0.931755]\n",
      "epoch:16 step:12775[D loss: 0.426830, acc: 58.59%, op_acc: 39.84%] [G loss: 0.895671]\n",
      "epoch:16 step:12776[D loss: 0.434263, acc: 53.91%, op_acc: 38.28%] [G loss: 0.857507]\n",
      "epoch:16 step:12777[D loss: 0.433840, acc: 53.91%, op_acc: 37.50%] [G loss: 0.873281]\n",
      "epoch:16 step:12778[D loss: 0.464417, acc: 54.69%, op_acc: 35.16%] [G loss: 0.830072]\n",
      "epoch:16 step:12779[D loss: 0.403200, acc: 62.50%, op_acc: 40.62%] [G loss: 0.819196]\n",
      "epoch:16 step:12780[D loss: 0.430096, acc: 57.03%, op_acc: 35.94%] [G loss: 0.870365]\n",
      "epoch:16 step:12781[D loss: 0.447054, acc: 59.38%, op_acc: 35.16%] [G loss: 0.945059]\n",
      "epoch:16 step:12782[D loss: 0.436450, acc: 61.72%, op_acc: 33.59%] [G loss: 0.875574]\n",
      "epoch:16 step:12783[D loss: 0.442599, acc: 53.12%, op_acc: 37.50%] [G loss: 0.916961]\n",
      "epoch:16 step:12784[D loss: 0.444002, acc: 53.91%, op_acc: 39.84%] [G loss: 0.895462]\n",
      "epoch:16 step:12785[D loss: 0.458367, acc: 50.78%, op_acc: 31.25%] [G loss: 0.879091]\n",
      "epoch:16 step:12786[D loss: 0.421525, acc: 61.72%, op_acc: 39.84%] [G loss: 0.868652]\n",
      "epoch:16 step:12787[D loss: 0.432405, acc: 55.47%, op_acc: 41.41%] [G loss: 0.909831]\n",
      "epoch:16 step:12788[D loss: 0.445445, acc: 57.03%, op_acc: 37.50%] [G loss: 0.925275]\n",
      "epoch:16 step:12789[D loss: 0.421216, acc: 57.81%, op_acc: 35.94%] [G loss: 0.876710]\n",
      "epoch:16 step:12790[D loss: 0.427374, acc: 64.06%, op_acc: 38.28%] [G loss: 0.875983]\n",
      "epoch:16 step:12791[D loss: 0.425387, acc: 62.50%, op_acc: 37.50%] [G loss: 0.923512]\n",
      "epoch:16 step:12792[D loss: 0.454987, acc: 48.44%, op_acc: 41.41%] [G loss: 0.929903]\n",
      "epoch:16 step:12793[D loss: 0.426722, acc: 62.50%, op_acc: 38.28%] [G loss: 0.934588]\n",
      "epoch:16 step:12794[D loss: 0.419293, acc: 64.84%, op_acc: 37.50%] [G loss: 0.888775]\n",
      "epoch:16 step:12795[D loss: 0.436415, acc: 57.03%, op_acc: 38.28%] [G loss: 0.883680]\n",
      "epoch:16 step:12796[D loss: 0.439499, acc: 56.25%, op_acc: 36.72%] [G loss: 0.942213]\n",
      "epoch:16 step:12797[D loss: 0.436988, acc: 60.16%, op_acc: 39.06%] [G loss: 0.863907]\n",
      "epoch:16 step:12798[D loss: 0.417092, acc: 63.28%, op_acc: 42.19%] [G loss: 0.886121]\n",
      "epoch:16 step:12799[D loss: 0.445755, acc: 57.81%, op_acc: 39.06%] [G loss: 0.834697]\n",
      "epoch:16 step:12800[D loss: 0.393713, acc: 63.28%, op_acc: 40.62%] [G loss: 0.981980]\n",
      "##############\n",
      "[0.85437812 0.8389687  0.79834478 0.77243304 0.81907228 0.83058894\n",
      " 0.89969399 0.81928986 0.80691241 0.83346871]\n",
      "##########\n",
      "epoch:16 step:12801[D loss: 0.433063, acc: 57.81%, op_acc: 34.38%] [G loss: 0.870115]\n",
      "epoch:16 step:12802[D loss: 0.418513, acc: 69.53%, op_acc: 34.38%] [G loss: 0.828070]\n",
      "epoch:16 step:12803[D loss: 0.425131, acc: 59.38%, op_acc: 36.72%] [G loss: 0.978605]\n",
      "epoch:16 step:12804[D loss: 0.408641, acc: 64.84%, op_acc: 43.75%] [G loss: 0.892831]\n",
      "epoch:16 step:12805[D loss: 0.460003, acc: 50.00%, op_acc: 35.94%] [G loss: 0.878507]\n",
      "epoch:16 step:12806[D loss: 0.415566, acc: 63.28%, op_acc: 39.06%] [G loss: 0.838218]\n",
      "epoch:16 step:12807[D loss: 0.435500, acc: 58.59%, op_acc: 37.50%] [G loss: 0.882544]\n",
      "epoch:16 step:12808[D loss: 0.417193, acc: 64.06%, op_acc: 46.09%] [G loss: 0.852073]\n",
      "epoch:16 step:12809[D loss: 0.418996, acc: 63.28%, op_acc: 41.41%] [G loss: 0.952023]\n",
      "epoch:16 step:12810[D loss: 0.453781, acc: 56.25%, op_acc: 34.38%] [G loss: 0.828790]\n",
      "epoch:16 step:12811[D loss: 0.457775, acc: 53.91%, op_acc: 35.94%] [G loss: 0.805782]\n",
      "epoch:16 step:12812[D loss: 0.425328, acc: 56.25%, op_acc: 43.75%] [G loss: 0.856253]\n",
      "epoch:16 step:12813[D loss: 0.451380, acc: 57.03%, op_acc: 34.38%] [G loss: 0.852328]\n",
      "epoch:16 step:12814[D loss: 0.415117, acc: 64.06%, op_acc: 36.72%] [G loss: 0.927088]\n",
      "epoch:16 step:12815[D loss: 0.436307, acc: 55.47%, op_acc: 40.62%] [G loss: 0.844990]\n",
      "epoch:16 step:12816[D loss: 0.431189, acc: 60.16%, op_acc: 35.16%] [G loss: 0.893226]\n",
      "epoch:16 step:12817[D loss: 0.430028, acc: 64.06%, op_acc: 38.28%] [G loss: 0.864206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12818[D loss: 0.441599, acc: 60.94%, op_acc: 32.81%] [G loss: 0.897261]\n",
      "epoch:16 step:12819[D loss: 0.445027, acc: 53.12%, op_acc: 35.94%] [G loss: 0.903593]\n",
      "epoch:16 step:12820[D loss: 0.430300, acc: 59.38%, op_acc: 38.28%] [G loss: 0.885712]\n",
      "epoch:16 step:12821[D loss: 0.399593, acc: 68.75%, op_acc: 41.41%] [G loss: 0.906577]\n",
      "epoch:16 step:12822[D loss: 0.417508, acc: 57.81%, op_acc: 43.75%] [G loss: 0.905397]\n",
      "epoch:16 step:12823[D loss: 0.433783, acc: 55.47%, op_acc: 32.81%] [G loss: 0.862954]\n",
      "epoch:16 step:12824[D loss: 0.457670, acc: 55.47%, op_acc: 31.25%] [G loss: 0.775581]\n",
      "epoch:16 step:12825[D loss: 0.435162, acc: 59.38%, op_acc: 37.50%] [G loss: 0.859697]\n",
      "epoch:16 step:12826[D loss: 0.437439, acc: 49.22%, op_acc: 35.94%] [G loss: 0.891693]\n",
      "epoch:16 step:12827[D loss: 0.434459, acc: 58.59%, op_acc: 35.94%] [G loss: 0.853352]\n",
      "epoch:16 step:12828[D loss: 0.394981, acc: 64.06%, op_acc: 40.62%] [G loss: 0.886788]\n",
      "epoch:16 step:12829[D loss: 0.423861, acc: 62.50%, op_acc: 37.50%] [G loss: 0.790898]\n",
      "epoch:16 step:12830[D loss: 0.434649, acc: 58.59%, op_acc: 41.41%] [G loss: 0.889994]\n",
      "epoch:16 step:12831[D loss: 0.436369, acc: 62.50%, op_acc: 33.59%] [G loss: 0.793913]\n",
      "epoch:16 step:12832[D loss: 0.441508, acc: 51.56%, op_acc: 39.06%] [G loss: 0.885448]\n",
      "epoch:16 step:12833[D loss: 0.439450, acc: 63.28%, op_acc: 33.59%] [G loss: 0.841472]\n",
      "epoch:16 step:12834[D loss: 0.409906, acc: 57.81%, op_acc: 39.06%] [G loss: 0.954506]\n",
      "epoch:16 step:12835[D loss: 0.420867, acc: 60.16%, op_acc: 40.62%] [G loss: 0.892431]\n",
      "epoch:16 step:12836[D loss: 0.443108, acc: 64.06%, op_acc: 35.94%] [G loss: 0.854135]\n",
      "epoch:16 step:12837[D loss: 0.448750, acc: 58.59%, op_acc: 41.41%] [G loss: 0.821829]\n",
      "epoch:16 step:12838[D loss: 0.447390, acc: 61.72%, op_acc: 34.38%] [G loss: 0.888342]\n",
      "epoch:16 step:12839[D loss: 0.431627, acc: 64.84%, op_acc: 32.81%] [G loss: 0.891490]\n",
      "epoch:16 step:12840[D loss: 0.420439, acc: 58.59%, op_acc: 43.75%] [G loss: 0.798082]\n",
      "epoch:16 step:12841[D loss: 0.420006, acc: 64.06%, op_acc: 35.94%] [G loss: 0.875661]\n",
      "epoch:16 step:12842[D loss: 0.426057, acc: 67.97%, op_acc: 32.81%] [G loss: 0.894411]\n",
      "epoch:16 step:12843[D loss: 0.424804, acc: 59.38%, op_acc: 39.06%] [G loss: 0.842348]\n",
      "epoch:16 step:12844[D loss: 0.433863, acc: 56.25%, op_acc: 35.94%] [G loss: 0.895131]\n",
      "epoch:16 step:12845[D loss: 0.437673, acc: 54.69%, op_acc: 42.19%] [G loss: 0.863556]\n",
      "epoch:16 step:12846[D loss: 0.462846, acc: 57.81%, op_acc: 35.94%] [G loss: 0.845800]\n",
      "epoch:16 step:12847[D loss: 0.471611, acc: 52.34%, op_acc: 35.16%] [G loss: 0.879394]\n",
      "epoch:16 step:12848[D loss: 0.413434, acc: 61.72%, op_acc: 41.41%] [G loss: 0.908177]\n",
      "epoch:16 step:12849[D loss: 0.406863, acc: 56.25%, op_acc: 41.41%] [G loss: 0.864631]\n",
      "epoch:16 step:12850[D loss: 0.460726, acc: 57.03%, op_acc: 32.81%] [G loss: 0.869574]\n",
      "##############\n",
      "[0.85584267 0.86762725 0.81512227 0.80330741 0.79710102 0.83156562\n",
      " 0.8743329  0.83614251 0.80233869 0.8444584 ]\n",
      "##########\n",
      "epoch:16 step:12851[D loss: 0.445250, acc: 49.22%, op_acc: 38.28%] [G loss: 0.862296]\n",
      "epoch:16 step:12852[D loss: 0.452398, acc: 54.69%, op_acc: 33.59%] [G loss: 0.804364]\n",
      "epoch:16 step:12853[D loss: 0.442057, acc: 57.03%, op_acc: 40.62%] [G loss: 0.944676]\n",
      "epoch:16 step:12854[D loss: 0.453640, acc: 55.47%, op_acc: 37.50%] [G loss: 0.937611]\n",
      "epoch:16 step:12855[D loss: 0.442776, acc: 57.03%, op_acc: 34.38%] [G loss: 0.895446]\n",
      "epoch:16 step:12856[D loss: 0.451254, acc: 57.81%, op_acc: 35.16%] [G loss: 0.912440]\n",
      "epoch:16 step:12857[D loss: 0.397187, acc: 64.84%, op_acc: 41.41%] [G loss: 0.892584]\n",
      "epoch:16 step:12858[D loss: 0.407752, acc: 60.94%, op_acc: 38.28%] [G loss: 0.899091]\n",
      "epoch:16 step:12859[D loss: 0.431685, acc: 59.38%, op_acc: 36.72%] [G loss: 0.827546]\n",
      "epoch:16 step:12860[D loss: 0.449672, acc: 55.47%, op_acc: 35.94%] [G loss: 0.881239]\n",
      "epoch:16 step:12861[D loss: 0.420424, acc: 57.81%, op_acc: 38.28%] [G loss: 0.922690]\n",
      "epoch:16 step:12862[D loss: 0.413791, acc: 56.25%, op_acc: 39.84%] [G loss: 0.932492]\n",
      "epoch:16 step:12863[D loss: 0.440298, acc: 62.50%, op_acc: 29.69%] [G loss: 0.884331]\n",
      "epoch:16 step:12864[D loss: 0.445753, acc: 60.16%, op_acc: 34.38%] [G loss: 0.856613]\n",
      "epoch:16 step:12865[D loss: 0.436656, acc: 57.81%, op_acc: 43.75%] [G loss: 0.829927]\n",
      "epoch:16 step:12866[D loss: 0.440576, acc: 63.28%, op_acc: 36.72%] [G loss: 0.905430]\n",
      "epoch:16 step:12867[D loss: 0.426181, acc: 57.81%, op_acc: 35.94%] [G loss: 0.871411]\n",
      "epoch:16 step:12868[D loss: 0.406993, acc: 64.06%, op_acc: 39.06%] [G loss: 0.868563]\n",
      "epoch:16 step:12869[D loss: 0.422486, acc: 60.16%, op_acc: 41.41%] [G loss: 0.871698]\n",
      "epoch:16 step:12870[D loss: 0.433833, acc: 58.59%, op_acc: 37.50%] [G loss: 0.909746]\n",
      "epoch:16 step:12871[D loss: 0.438420, acc: 52.34%, op_acc: 35.16%] [G loss: 0.774171]\n",
      "epoch:16 step:12872[D loss: 0.419084, acc: 60.94%, op_acc: 37.50%] [G loss: 0.863814]\n",
      "epoch:16 step:12873[D loss: 0.432872, acc: 54.69%, op_acc: 39.06%] [G loss: 0.880288]\n",
      "epoch:16 step:12874[D loss: 0.400603, acc: 60.94%, op_acc: 38.28%] [G loss: 0.841089]\n",
      "epoch:16 step:12875[D loss: 0.427198, acc: 57.81%, op_acc: 37.50%] [G loss: 0.837327]\n",
      "epoch:16 step:12876[D loss: 0.451130, acc: 54.69%, op_acc: 39.06%] [G loss: 0.926374]\n",
      "epoch:16 step:12877[D loss: 0.428710, acc: 63.28%, op_acc: 31.25%] [G loss: 0.902696]\n",
      "epoch:16 step:12878[D loss: 0.430516, acc: 63.28%, op_acc: 36.72%] [G loss: 0.911068]\n",
      "epoch:16 step:12879[D loss: 0.405611, acc: 60.16%, op_acc: 40.62%] [G loss: 0.891754]\n",
      "epoch:16 step:12880[D loss: 0.412655, acc: 61.72%, op_acc: 32.81%] [G loss: 0.884676]\n",
      "epoch:16 step:12881[D loss: 0.424418, acc: 63.28%, op_acc: 37.50%] [G loss: 0.872309]\n",
      "epoch:16 step:12882[D loss: 0.404962, acc: 63.28%, op_acc: 39.84%] [G loss: 0.896187]\n",
      "epoch:16 step:12883[D loss: 0.428781, acc: 58.59%, op_acc: 39.84%] [G loss: 0.952899]\n",
      "epoch:16 step:12884[D loss: 0.435356, acc: 60.94%, op_acc: 35.16%] [G loss: 0.902905]\n",
      "epoch:16 step:12885[D loss: 0.433290, acc: 62.50%, op_acc: 34.38%] [G loss: 0.908945]\n",
      "epoch:16 step:12886[D loss: 0.414849, acc: 63.28%, op_acc: 39.06%] [G loss: 0.909571]\n",
      "epoch:16 step:12887[D loss: 0.422916, acc: 55.47%, op_acc: 40.62%] [G loss: 0.924451]\n",
      "epoch:16 step:12888[D loss: 0.417812, acc: 59.38%, op_acc: 40.62%] [G loss: 0.932646]\n",
      "epoch:16 step:12889[D loss: 0.451151, acc: 58.59%, op_acc: 31.25%] [G loss: 0.831925]\n",
      "epoch:16 step:12890[D loss: 0.424132, acc: 64.06%, op_acc: 35.94%] [G loss: 0.878682]\n",
      "epoch:16 step:12891[D loss: 0.459609, acc: 54.69%, op_acc: 30.47%] [G loss: 0.849938]\n",
      "epoch:16 step:12892[D loss: 0.408165, acc: 60.94%, op_acc: 39.06%] [G loss: 0.895039]\n",
      "epoch:16 step:12893[D loss: 0.448940, acc: 56.25%, op_acc: 32.81%] [G loss: 0.846640]\n",
      "epoch:16 step:12894[D loss: 0.437557, acc: 56.25%, op_acc: 31.25%] [G loss: 0.880220]\n",
      "epoch:16 step:12895[D loss: 0.440175, acc: 62.50%, op_acc: 37.50%] [G loss: 0.854947]\n",
      "epoch:16 step:12896[D loss: 0.392114, acc: 68.75%, op_acc: 39.84%] [G loss: 0.911667]\n",
      "epoch:16 step:12897[D loss: 0.405281, acc: 64.06%, op_acc: 39.06%] [G loss: 0.876213]\n",
      "epoch:16 step:12898[D loss: 0.423834, acc: 64.06%, op_acc: 31.25%] [G loss: 0.937365]\n",
      "epoch:16 step:12899[D loss: 0.438163, acc: 53.91%, op_acc: 35.16%] [G loss: 0.902420]\n",
      "epoch:16 step:12900[D loss: 0.400271, acc: 66.41%, op_acc: 45.31%] [G loss: 0.891015]\n",
      "##############\n",
      "[0.84540862 0.8387612  0.79902054 0.80836121 0.80668849 0.82583146\n",
      " 0.89095969 0.82289068 0.79590444 0.82018975]\n",
      "##########\n",
      "epoch:16 step:12901[D loss: 0.422925, acc: 60.94%, op_acc: 36.72%] [G loss: 0.917588]\n",
      "epoch:16 step:12902[D loss: 0.430732, acc: 52.34%, op_acc: 41.41%] [G loss: 0.922825]\n",
      "epoch:16 step:12903[D loss: 0.420700, acc: 60.94%, op_acc: 40.62%] [G loss: 0.903988]\n",
      "epoch:16 step:12904[D loss: 0.401295, acc: 64.06%, op_acc: 45.31%] [G loss: 0.917444]\n",
      "epoch:16 step:12905[D loss: 0.456683, acc: 54.69%, op_acc: 42.19%] [G loss: 0.859008]\n",
      "epoch:16 step:12906[D loss: 0.421114, acc: 55.47%, op_acc: 41.41%] [G loss: 0.896381]\n",
      "epoch:16 step:12907[D loss: 0.429157, acc: 57.81%, op_acc: 35.94%] [G loss: 0.821316]\n",
      "epoch:16 step:12908[D loss: 0.417814, acc: 58.59%, op_acc: 38.28%] [G loss: 0.971009]\n",
      "epoch:16 step:12909[D loss: 0.412630, acc: 57.03%, op_acc: 40.62%] [G loss: 0.893495]\n",
      "epoch:16 step:12910[D loss: 0.449110, acc: 47.66%, op_acc: 35.94%] [G loss: 0.847041]\n",
      "epoch:16 step:12911[D loss: 0.441955, acc: 56.25%, op_acc: 31.25%] [G loss: 0.858332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12912[D loss: 0.406901, acc: 63.28%, op_acc: 35.94%] [G loss: 0.821145]\n",
      "epoch:16 step:12913[D loss: 0.412592, acc: 64.84%, op_acc: 40.62%] [G loss: 0.878797]\n",
      "epoch:16 step:12914[D loss: 0.428858, acc: 57.81%, op_acc: 36.72%] [G loss: 0.864964]\n",
      "epoch:16 step:12915[D loss: 0.429694, acc: 63.28%, op_acc: 39.84%] [G loss: 0.952683]\n",
      "epoch:16 step:12916[D loss: 0.419949, acc: 61.72%, op_acc: 32.81%] [G loss: 0.907994]\n",
      "epoch:16 step:12917[D loss: 0.440009, acc: 63.28%, op_acc: 42.19%] [G loss: 0.935433]\n",
      "epoch:16 step:12918[D loss: 0.426892, acc: 60.94%, op_acc: 38.28%] [G loss: 0.951593]\n",
      "epoch:16 step:12919[D loss: 0.446708, acc: 53.91%, op_acc: 33.59%] [G loss: 0.877784]\n",
      "epoch:16 step:12920[D loss: 0.424890, acc: 60.94%, op_acc: 36.72%] [G loss: 0.919873]\n",
      "epoch:16 step:12921[D loss: 0.445722, acc: 54.69%, op_acc: 37.50%] [G loss: 0.888470]\n",
      "epoch:16 step:12922[D loss: 0.434808, acc: 63.28%, op_acc: 36.72%] [G loss: 0.928156]\n",
      "epoch:16 step:12923[D loss: 0.421593, acc: 61.72%, op_acc: 38.28%] [G loss: 0.881454]\n",
      "epoch:16 step:12924[D loss: 0.411165, acc: 53.91%, op_acc: 49.22%] [G loss: 0.885036]\n",
      "epoch:16 step:12925[D loss: 0.409125, acc: 62.50%, op_acc: 39.06%] [G loss: 0.861774]\n",
      "epoch:16 step:12926[D loss: 0.420361, acc: 60.16%, op_acc: 41.41%] [G loss: 0.862445]\n",
      "epoch:16 step:12927[D loss: 0.449684, acc: 50.78%, op_acc: 39.06%] [G loss: 0.892054]\n",
      "epoch:16 step:12928[D loss: 0.408704, acc: 60.16%, op_acc: 42.97%] [G loss: 0.841998]\n",
      "epoch:16 step:12929[D loss: 0.428051, acc: 57.03%, op_acc: 39.84%] [G loss: 0.888508]\n",
      "epoch:16 step:12930[D loss: 0.411194, acc: 59.38%, op_acc: 42.19%] [G loss: 0.859890]\n",
      "epoch:16 step:12931[D loss: 0.433628, acc: 54.69%, op_acc: 39.06%] [G loss: 0.850111]\n",
      "epoch:16 step:12932[D loss: 0.470854, acc: 53.91%, op_acc: 35.94%] [G loss: 0.872338]\n",
      "epoch:16 step:12933[D loss: 0.434171, acc: 57.03%, op_acc: 34.38%] [G loss: 0.910625]\n",
      "epoch:16 step:12934[D loss: 0.406506, acc: 57.81%, op_acc: 45.31%] [G loss: 0.906266]\n",
      "epoch:16 step:12935[D loss: 0.419297, acc: 61.72%, op_acc: 37.50%] [G loss: 0.847037]\n",
      "epoch:16 step:12936[D loss: 0.455410, acc: 53.91%, op_acc: 36.72%] [G loss: 0.883339]\n",
      "epoch:16 step:12937[D loss: 0.471285, acc: 45.31%, op_acc: 35.16%] [G loss: 0.848655]\n",
      "epoch:16 step:12938[D loss: 0.450545, acc: 46.09%, op_acc: 37.50%] [G loss: 0.806853]\n",
      "epoch:16 step:12939[D loss: 0.463682, acc: 53.12%, op_acc: 33.59%] [G loss: 0.831793]\n",
      "epoch:16 step:12940[D loss: 0.445651, acc: 54.69%, op_acc: 33.59%] [G loss: 0.818709]\n",
      "epoch:16 step:12941[D loss: 0.463398, acc: 51.56%, op_acc: 35.16%] [G loss: 0.878208]\n",
      "epoch:16 step:12942[D loss: 0.428191, acc: 66.41%, op_acc: 32.03%] [G loss: 0.870512]\n",
      "epoch:16 step:12943[D loss: 0.438886, acc: 60.94%, op_acc: 35.94%] [G loss: 0.903675]\n",
      "epoch:16 step:12944[D loss: 0.414474, acc: 58.59%, op_acc: 39.84%] [G loss: 0.875788]\n",
      "epoch:16 step:12945[D loss: 0.440775, acc: 60.94%, op_acc: 32.81%] [G loss: 0.896503]\n",
      "epoch:16 step:12946[D loss: 0.453479, acc: 57.81%, op_acc: 34.38%] [G loss: 0.825112]\n",
      "epoch:16 step:12947[D loss: 0.409850, acc: 60.94%, op_acc: 40.62%] [G loss: 0.871261]\n",
      "epoch:16 step:12948[D loss: 0.405610, acc: 68.75%, op_acc: 32.81%] [G loss: 0.902400]\n",
      "epoch:16 step:12949[D loss: 0.451696, acc: 52.34%, op_acc: 35.16%] [G loss: 0.795117]\n",
      "epoch:16 step:12950[D loss: 0.422607, acc: 53.91%, op_acc: 38.28%] [G loss: 0.891491]\n",
      "##############\n",
      "[0.85698201 0.87899837 0.80820993 0.81452321 0.80128671 0.83659505\n",
      " 0.88644077 0.8180487  0.8066034  0.8326398 ]\n",
      "##########\n",
      "epoch:16 step:12951[D loss: 0.455755, acc: 50.78%, op_acc: 40.62%] [G loss: 0.868547]\n",
      "epoch:16 step:12952[D loss: 0.433897, acc: 62.50%, op_acc: 35.94%] [G loss: 0.954765]\n",
      "epoch:16 step:12953[D loss: 0.413240, acc: 64.06%, op_acc: 38.28%] [G loss: 0.965731]\n",
      "epoch:16 step:12954[D loss: 0.410402, acc: 63.28%, op_acc: 38.28%] [G loss: 0.963811]\n",
      "epoch:16 step:12955[D loss: 0.423098, acc: 56.25%, op_acc: 35.94%] [G loss: 0.963422]\n",
      "epoch:16 step:12956[D loss: 0.416393, acc: 60.16%, op_acc: 48.44%] [G loss: 0.976666]\n",
      "epoch:16 step:12957[D loss: 0.455892, acc: 52.34%, op_acc: 35.94%] [G loss: 0.887906]\n",
      "epoch:16 step:12958[D loss: 0.431907, acc: 54.69%, op_acc: 39.06%] [G loss: 0.804748]\n",
      "epoch:16 step:12959[D loss: 0.421996, acc: 61.72%, op_acc: 44.53%] [G loss: 0.858236]\n",
      "epoch:16 step:12960[D loss: 0.433127, acc: 60.16%, op_acc: 36.72%] [G loss: 0.875458]\n",
      "epoch:16 step:12961[D loss: 0.429808, acc: 52.34%, op_acc: 39.84%] [G loss: 0.935774]\n",
      "epoch:16 step:12962[D loss: 0.388634, acc: 72.66%, op_acc: 45.31%] [G loss: 0.921582]\n",
      "epoch:16 step:12963[D loss: 0.430216, acc: 57.81%, op_acc: 39.84%] [G loss: 0.899584]\n",
      "epoch:16 step:12964[D loss: 0.407501, acc: 63.28%, op_acc: 43.75%] [G loss: 0.875236]\n",
      "epoch:16 step:12965[D loss: 0.428752, acc: 56.25%, op_acc: 37.50%] [G loss: 0.858573]\n",
      "epoch:16 step:12966[D loss: 0.441093, acc: 58.59%, op_acc: 42.19%] [G loss: 0.855363]\n",
      "epoch:16 step:12967[D loss: 0.447415, acc: 59.38%, op_acc: 36.72%] [G loss: 0.845096]\n",
      "epoch:16 step:12968[D loss: 0.461907, acc: 53.91%, op_acc: 33.59%] [G loss: 0.849512]\n",
      "epoch:16 step:12969[D loss: 0.393042, acc: 66.41%, op_acc: 41.41%] [G loss: 0.866503]\n",
      "epoch:16 step:12970[D loss: 0.455612, acc: 57.03%, op_acc: 35.94%] [G loss: 0.822867]\n",
      "epoch:16 step:12971[D loss: 0.427452, acc: 52.34%, op_acc: 35.94%] [G loss: 0.893963]\n",
      "epoch:16 step:12972[D loss: 0.425083, acc: 62.50%, op_acc: 40.62%] [G loss: 0.846767]\n",
      "epoch:16 step:12973[D loss: 0.445796, acc: 52.34%, op_acc: 37.50%] [G loss: 0.884986]\n",
      "epoch:16 step:12974[D loss: 0.431065, acc: 53.91%, op_acc: 38.28%] [G loss: 0.821842]\n",
      "epoch:16 step:12975[D loss: 0.434967, acc: 56.25%, op_acc: 36.72%] [G loss: 0.862618]\n",
      "epoch:16 step:12976[D loss: 0.437270, acc: 59.38%, op_acc: 32.03%] [G loss: 0.908617]\n",
      "epoch:16 step:12977[D loss: 0.452180, acc: 63.28%, op_acc: 34.38%] [G loss: 0.870999]\n",
      "epoch:16 step:12978[D loss: 0.438641, acc: 56.25%, op_acc: 36.72%] [G loss: 0.890449]\n",
      "epoch:16 step:12979[D loss: 0.453556, acc: 58.59%, op_acc: 32.81%] [G loss: 0.896266]\n",
      "epoch:16 step:12980[D loss: 0.409046, acc: 61.72%, op_acc: 47.66%] [G loss: 0.946034]\n",
      "epoch:16 step:12981[D loss: 0.413509, acc: 63.28%, op_acc: 34.38%] [G loss: 0.889514]\n",
      "epoch:16 step:12982[D loss: 0.424716, acc: 58.59%, op_acc: 44.53%] [G loss: 0.882781]\n",
      "epoch:16 step:12983[D loss: 0.418411, acc: 58.59%, op_acc: 41.41%] [G loss: 0.793817]\n",
      "epoch:16 step:12984[D loss: 0.425250, acc: 60.16%, op_acc: 35.94%] [G loss: 0.900827]\n",
      "epoch:16 step:12985[D loss: 0.430734, acc: 59.38%, op_acc: 39.84%] [G loss: 0.877769]\n",
      "epoch:16 step:12986[D loss: 0.406326, acc: 61.72%, op_acc: 40.62%] [G loss: 0.810721]\n",
      "epoch:16 step:12987[D loss: 0.464306, acc: 50.00%, op_acc: 33.59%] [G loss: 0.779503]\n",
      "epoch:16 step:12988[D loss: 0.426877, acc: 51.56%, op_acc: 41.41%] [G loss: 0.804284]\n",
      "epoch:16 step:12989[D loss: 0.424452, acc: 62.50%, op_acc: 36.72%] [G loss: 0.895942]\n",
      "epoch:16 step:12990[D loss: 0.410083, acc: 63.28%, op_acc: 40.62%] [G loss: 0.927962]\n",
      "epoch:16 step:12991[D loss: 0.425531, acc: 65.62%, op_acc: 37.50%] [G loss: 0.850313]\n",
      "epoch:16 step:12992[D loss: 0.417216, acc: 64.84%, op_acc: 39.84%] [G loss: 0.890153]\n",
      "epoch:16 step:12993[D loss: 0.406181, acc: 56.25%, op_acc: 42.19%] [G loss: 0.845501]\n",
      "epoch:16 step:12994[D loss: 0.452903, acc: 60.94%, op_acc: 32.81%] [G loss: 0.821224]\n",
      "epoch:16 step:12995[D loss: 0.445366, acc: 54.69%, op_acc: 36.72%] [G loss: 0.939801]\n",
      "epoch:16 step:12996[D loss: 0.420795, acc: 59.38%, op_acc: 37.50%] [G loss: 0.859364]\n",
      "epoch:16 step:12997[D loss: 0.413795, acc: 63.28%, op_acc: 39.84%] [G loss: 0.863529]\n",
      "epoch:16 step:12998[D loss: 0.449335, acc: 54.69%, op_acc: 39.06%] [G loss: 0.896747]\n",
      "epoch:16 step:12999[D loss: 0.440197, acc: 54.69%, op_acc: 35.16%] [G loss: 0.914239]\n",
      "epoch:16 step:13000[D loss: 0.412934, acc: 67.19%, op_acc: 32.03%] [G loss: 0.971448]\n",
      "##############\n",
      "[0.85085861 0.86497814 0.82365742 0.80591944 0.82375334 0.82664979\n",
      " 0.86111688 0.82741635 0.8288065  0.8396918 ]\n",
      "##########\n",
      "epoch:16 step:13001[D loss: 0.436315, acc: 60.94%, op_acc: 35.94%] [G loss: 0.975151]\n",
      "epoch:16 step:13002[D loss: 0.400378, acc: 67.97%, op_acc: 40.62%] [G loss: 0.925248]\n",
      "epoch:16 step:13003[D loss: 0.403545, acc: 60.94%, op_acc: 45.31%] [G loss: 0.855051]\n",
      "epoch:16 step:13004[D loss: 0.413724, acc: 60.16%, op_acc: 40.62%] [G loss: 0.949925]\n",
      "epoch:16 step:13005[D loss: 0.462012, acc: 57.03%, op_acc: 40.62%] [G loss: 0.887271]\n",
      "epoch:16 step:13006[D loss: 0.413246, acc: 60.94%, op_acc: 41.41%] [G loss: 0.988142]\n",
      "epoch:16 step:13007[D loss: 0.438644, acc: 54.69%, op_acc: 40.62%] [G loss: 0.957522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13008[D loss: 0.460728, acc: 54.69%, op_acc: 38.28%] [G loss: 0.909104]\n",
      "epoch:16 step:13009[D loss: 0.463921, acc: 50.00%, op_acc: 37.50%] [G loss: 0.896718]\n",
      "epoch:16 step:13010[D loss: 0.405310, acc: 63.28%, op_acc: 39.06%] [G loss: 0.907223]\n",
      "epoch:16 step:13011[D loss: 0.466225, acc: 51.56%, op_acc: 35.94%] [G loss: 0.876031]\n",
      "epoch:16 step:13012[D loss: 0.437441, acc: 56.25%, op_acc: 41.41%] [G loss: 0.849704]\n",
      "epoch:16 step:13013[D loss: 0.449899, acc: 58.59%, op_acc: 40.62%] [G loss: 0.802962]\n",
      "epoch:16 step:13014[D loss: 0.382490, acc: 69.53%, op_acc: 37.50%] [G loss: 0.865740]\n",
      "epoch:16 step:13015[D loss: 0.427165, acc: 52.34%, op_acc: 36.72%] [G loss: 0.934772]\n",
      "epoch:16 step:13016[D loss: 0.455645, acc: 51.56%, op_acc: 38.28%] [G loss: 0.893094]\n",
      "epoch:16 step:13017[D loss: 0.402583, acc: 75.00%, op_acc: 37.50%] [G loss: 0.897322]\n",
      "epoch:16 step:13018[D loss: 0.454668, acc: 53.91%, op_acc: 39.06%] [G loss: 0.911277]\n",
      "epoch:16 step:13019[D loss: 0.445136, acc: 57.81%, op_acc: 34.38%] [G loss: 0.872049]\n",
      "epoch:16 step:13020[D loss: 0.413479, acc: 64.06%, op_acc: 39.06%] [G loss: 0.891449]\n",
      "epoch:16 step:13021[D loss: 0.443842, acc: 59.38%, op_acc: 36.72%] [G loss: 0.885041]\n",
      "epoch:16 step:13022[D loss: 0.498782, acc: 47.66%, op_acc: 30.47%] [G loss: 0.813475]\n",
      "epoch:16 step:13023[D loss: 0.438380, acc: 57.81%, op_acc: 39.06%] [G loss: 0.889197]\n",
      "epoch:16 step:13024[D loss: 0.430734, acc: 55.47%, op_acc: 43.75%] [G loss: 0.899079]\n",
      "epoch:16 step:13025[D loss: 0.415733, acc: 60.94%, op_acc: 40.62%] [G loss: 0.919942]\n",
      "epoch:16 step:13026[D loss: 0.444433, acc: 56.25%, op_acc: 37.50%] [G loss: 0.843378]\n",
      "epoch:16 step:13027[D loss: 0.443944, acc: 62.50%, op_acc: 33.59%] [G loss: 0.932257]\n",
      "epoch:16 step:13028[D loss: 0.475480, acc: 48.44%, op_acc: 32.03%] [G loss: 0.863979]\n",
      "epoch:16 step:13029[D loss: 0.405410, acc: 68.75%, op_acc: 40.62%] [G loss: 0.922808]\n",
      "epoch:16 step:13030[D loss: 0.432088, acc: 54.69%, op_acc: 34.38%] [G loss: 0.914112]\n",
      "epoch:16 step:13031[D loss: 0.428562, acc: 60.94%, op_acc: 35.94%] [G loss: 0.962409]\n",
      "epoch:16 step:13032[D loss: 0.400636, acc: 60.16%, op_acc: 40.62%] [G loss: 0.930888]\n",
      "epoch:16 step:13033[D loss: 0.456538, acc: 57.03%, op_acc: 35.94%] [G loss: 0.908477]\n",
      "epoch:16 step:13034[D loss: 0.447818, acc: 50.00%, op_acc: 39.06%] [G loss: 0.947324]\n",
      "epoch:16 step:13035[D loss: 0.428524, acc: 58.59%, op_acc: 39.84%] [G loss: 0.884085]\n",
      "epoch:16 step:13036[D loss: 0.426056, acc: 54.69%, op_acc: 47.66%] [G loss: 0.885899]\n",
      "epoch:16 step:13037[D loss: 0.413597, acc: 63.28%, op_acc: 38.28%] [G loss: 0.916301]\n",
      "epoch:16 step:13038[D loss: 0.459293, acc: 50.78%, op_acc: 40.62%] [G loss: 0.824708]\n",
      "epoch:16 step:13039[D loss: 0.460109, acc: 50.78%, op_acc: 31.25%] [G loss: 0.843594]\n",
      "epoch:16 step:13040[D loss: 0.432578, acc: 50.78%, op_acc: 35.16%] [G loss: 0.898436]\n",
      "epoch:16 step:13041[D loss: 0.406534, acc: 65.62%, op_acc: 42.19%] [G loss: 0.989352]\n",
      "epoch:16 step:13042[D loss: 0.431998, acc: 56.25%, op_acc: 39.06%] [G loss: 0.961620]\n",
      "epoch:16 step:13043[D loss: 0.426785, acc: 61.72%, op_acc: 38.28%] [G loss: 0.883075]\n",
      "epoch:16 step:13044[D loss: 0.434382, acc: 56.25%, op_acc: 34.38%] [G loss: 0.989140]\n",
      "epoch:16 step:13045[D loss: 0.445811, acc: 52.34%, op_acc: 39.84%] [G loss: 0.929674]\n",
      "epoch:16 step:13046[D loss: 0.417587, acc: 64.06%, op_acc: 34.38%] [G loss: 0.922246]\n",
      "epoch:16 step:13047[D loss: 0.403882, acc: 63.28%, op_acc: 41.41%] [G loss: 0.956162]\n",
      "epoch:16 step:13048[D loss: 0.466137, acc: 57.03%, op_acc: 28.91%] [G loss: 0.844124]\n",
      "epoch:16 step:13049[D loss: 0.418393, acc: 64.06%, op_acc: 31.25%] [G loss: 0.823174]\n",
      "epoch:16 step:13050[D loss: 0.413374, acc: 65.62%, op_acc: 39.06%] [G loss: 0.916250]\n",
      "##############\n",
      "[0.85701656 0.86371943 0.81621119 0.79278618 0.79646579 0.82043813\n",
      " 0.8832507  0.82114549 0.79837263 0.81730608]\n",
      "##########\n",
      "epoch:16 step:13051[D loss: 0.413979, acc: 60.16%, op_acc: 38.28%] [G loss: 0.821964]\n",
      "epoch:16 step:13052[D loss: 0.433712, acc: 57.81%, op_acc: 35.16%] [G loss: 0.862283]\n",
      "epoch:16 step:13053[D loss: 0.437579, acc: 62.50%, op_acc: 35.94%] [G loss: 0.877702]\n",
      "epoch:16 step:13054[D loss: 0.442965, acc: 58.59%, op_acc: 41.41%] [G loss: 0.925658]\n",
      "epoch:16 step:13055[D loss: 0.400839, acc: 65.62%, op_acc: 32.81%] [G loss: 0.876561]\n",
      "epoch:16 step:13056[D loss: 0.428562, acc: 60.16%, op_acc: 36.72%] [G loss: 0.872778]\n",
      "epoch:16 step:13057[D loss: 0.435487, acc: 53.12%, op_acc: 40.62%] [G loss: 0.941615]\n",
      "epoch:16 step:13058[D loss: 0.440008, acc: 56.25%, op_acc: 39.06%] [G loss: 0.894837]\n",
      "epoch:16 step:13059[D loss: 0.417811, acc: 64.84%, op_acc: 34.38%] [G loss: 0.980108]\n",
      "epoch:16 step:13060[D loss: 0.442078, acc: 53.91%, op_acc: 42.19%] [G loss: 0.892511]\n",
      "epoch:16 step:13061[D loss: 0.414955, acc: 60.16%, op_acc: 42.97%] [G loss: 0.909693]\n",
      "epoch:16 step:13062[D loss: 0.410325, acc: 62.50%, op_acc: 34.38%] [G loss: 0.956167]\n",
      "epoch:16 step:13063[D loss: 0.395587, acc: 68.75%, op_acc: 42.97%] [G loss: 0.934254]\n",
      "epoch:16 step:13064[D loss: 0.452421, acc: 49.22%, op_acc: 38.28%] [G loss: 0.852030]\n",
      "epoch:16 step:13065[D loss: 0.442631, acc: 56.25%, op_acc: 37.50%] [G loss: 0.917327]\n",
      "epoch:16 step:13066[D loss: 0.414982, acc: 61.72%, op_acc: 40.62%] [G loss: 0.840725]\n",
      "epoch:16 step:13067[D loss: 0.441383, acc: 53.91%, op_acc: 43.75%] [G loss: 0.797890]\n",
      "epoch:16 step:13068[D loss: 0.416762, acc: 62.50%, op_acc: 39.06%] [G loss: 0.903151]\n",
      "epoch:16 step:13069[D loss: 0.469180, acc: 47.66%, op_acc: 42.19%] [G loss: 0.890798]\n",
      "epoch:16 step:13070[D loss: 0.426158, acc: 60.94%, op_acc: 39.84%] [G loss: 0.871599]\n",
      "epoch:16 step:13071[D loss: 0.439038, acc: 60.94%, op_acc: 32.81%] [G loss: 0.919692]\n",
      "epoch:16 step:13072[D loss: 0.400064, acc: 65.62%, op_acc: 42.97%] [G loss: 0.883495]\n",
      "epoch:16 step:13073[D loss: 0.446927, acc: 62.50%, op_acc: 32.81%] [G loss: 0.869594]\n",
      "epoch:16 step:13074[D loss: 0.452774, acc: 57.81%, op_acc: 40.62%] [G loss: 0.870388]\n",
      "epoch:16 step:13075[D loss: 0.385919, acc: 64.06%, op_acc: 45.31%] [G loss: 0.818524]\n",
      "epoch:16 step:13076[D loss: 0.427211, acc: 57.81%, op_acc: 39.06%] [G loss: 0.907632]\n",
      "epoch:16 step:13077[D loss: 0.411614, acc: 61.72%, op_acc: 36.72%] [G loss: 0.832509]\n",
      "epoch:16 step:13078[D loss: 0.424331, acc: 64.06%, op_acc: 34.38%] [G loss: 0.874998]\n",
      "epoch:16 step:13079[D loss: 0.446997, acc: 60.16%, op_acc: 34.38%] [G loss: 0.860830]\n",
      "epoch:16 step:13080[D loss: 0.455580, acc: 62.50%, op_acc: 32.81%] [G loss: 0.867139]\n",
      "epoch:16 step:13081[D loss: 0.413107, acc: 60.94%, op_acc: 41.41%] [G loss: 0.796899]\n",
      "epoch:16 step:13082[D loss: 0.435785, acc: 61.72%, op_acc: 32.81%] [G loss: 0.801077]\n",
      "epoch:16 step:13083[D loss: 0.410029, acc: 65.62%, op_acc: 38.28%] [G loss: 0.908017]\n",
      "epoch:16 step:13084[D loss: 0.411049, acc: 64.06%, op_acc: 40.62%] [G loss: 0.961569]\n",
      "epoch:16 step:13085[D loss: 0.437096, acc: 59.38%, op_acc: 32.81%] [G loss: 0.895776]\n",
      "epoch:16 step:13086[D loss: 0.424896, acc: 63.28%, op_acc: 40.62%] [G loss: 0.889691]\n",
      "epoch:16 step:13087[D loss: 0.452132, acc: 53.91%, op_acc: 32.81%] [G loss: 0.821696]\n",
      "epoch:16 step:13088[D loss: 0.446765, acc: 59.38%, op_acc: 38.28%] [G loss: 0.851243]\n",
      "epoch:16 step:13089[D loss: 0.444845, acc: 56.25%, op_acc: 32.03%] [G loss: 0.898381]\n",
      "epoch:16 step:13090[D loss: 0.443553, acc: 57.03%, op_acc: 39.84%] [G loss: 0.872161]\n",
      "epoch:16 step:13091[D loss: 0.423421, acc: 64.06%, op_acc: 35.94%] [G loss: 0.881241]\n",
      "epoch:16 step:13092[D loss: 0.435600, acc: 60.16%, op_acc: 35.16%] [G loss: 0.913771]\n",
      "epoch:16 step:13093[D loss: 0.435912, acc: 61.72%, op_acc: 35.16%] [G loss: 0.842822]\n",
      "epoch:16 step:13094[D loss: 0.430435, acc: 59.38%, op_acc: 39.06%] [G loss: 0.925464]\n",
      "epoch:16 step:13095[D loss: 0.449144, acc: 61.72%, op_acc: 35.16%] [G loss: 0.853789]\n",
      "epoch:16 step:13096[D loss: 0.409632, acc: 70.31%, op_acc: 36.72%] [G loss: 0.939474]\n",
      "epoch:16 step:13097[D loss: 0.443011, acc: 55.47%, op_acc: 39.06%] [G loss: 0.917042]\n",
      "epoch:16 step:13098[D loss: 0.430458, acc: 57.03%, op_acc: 39.06%] [G loss: 0.850746]\n",
      "epoch:16 step:13099[D loss: 0.397194, acc: 57.81%, op_acc: 45.31%] [G loss: 0.876450]\n",
      "epoch:16 step:13100[D loss: 0.468231, acc: 60.94%, op_acc: 29.69%] [G loss: 0.872918]\n",
      "##############\n",
      "[0.8489964  0.86338795 0.80544427 0.79323452 0.78416112 0.82245281\n",
      " 0.87777251 0.80164362 0.81169084 0.82736091]\n",
      "##########\n",
      "epoch:16 step:13101[D loss: 0.414801, acc: 67.19%, op_acc: 35.16%] [G loss: 0.858284]\n",
      "epoch:16 step:13102[D loss: 0.426356, acc: 58.59%, op_acc: 39.84%] [G loss: 0.889421]\n",
      "epoch:16 step:13103[D loss: 0.439040, acc: 53.12%, op_acc: 40.62%] [G loss: 0.899598]\n",
      "epoch:16 step:13104[D loss: 0.417327, acc: 64.84%, op_acc: 39.84%] [G loss: 0.836334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13105[D loss: 0.426614, acc: 57.03%, op_acc: 36.72%] [G loss: 0.914398]\n",
      "epoch:16 step:13106[D loss: 0.440190, acc: 59.38%, op_acc: 32.03%] [G loss: 0.848946]\n",
      "epoch:16 step:13107[D loss: 0.431604, acc: 59.38%, op_acc: 39.84%] [G loss: 0.964404]\n",
      "epoch:16 step:13108[D loss: 0.432667, acc: 59.38%, op_acc: 38.28%] [G loss: 0.925938]\n",
      "epoch:16 step:13109[D loss: 0.455201, acc: 49.22%, op_acc: 40.62%] [G loss: 0.896000]\n",
      "epoch:16 step:13110[D loss: 0.401075, acc: 65.62%, op_acc: 37.50%] [G loss: 0.897224]\n",
      "epoch:16 step:13111[D loss: 0.393014, acc: 64.84%, op_acc: 37.50%] [G loss: 0.829514]\n",
      "epoch:16 step:13112[D loss: 0.421830, acc: 60.94%, op_acc: 37.50%] [G loss: 0.944624]\n",
      "epoch:16 step:13113[D loss: 0.445873, acc: 57.03%, op_acc: 37.50%] [G loss: 0.859588]\n",
      "epoch:16 step:13114[D loss: 0.414925, acc: 60.94%, op_acc: 43.75%] [G loss: 0.928476]\n",
      "epoch:16 step:13115[D loss: 0.447126, acc: 59.38%, op_acc: 33.59%] [G loss: 0.918004]\n",
      "epoch:16 step:13116[D loss: 0.437196, acc: 64.06%, op_acc: 34.38%] [G loss: 0.916298]\n",
      "epoch:16 step:13117[D loss: 0.407859, acc: 65.62%, op_acc: 39.84%] [G loss: 0.909779]\n",
      "epoch:16 step:13118[D loss: 0.449151, acc: 55.47%, op_acc: 34.38%] [G loss: 0.914909]\n",
      "epoch:16 step:13119[D loss: 0.432742, acc: 62.50%, op_acc: 35.94%] [G loss: 0.944910]\n",
      "epoch:16 step:13120[D loss: 0.452635, acc: 45.31%, op_acc: 36.72%] [G loss: 0.882690]\n",
      "epoch:16 step:13121[D loss: 0.461151, acc: 53.12%, op_acc: 36.72%] [G loss: 0.860530]\n",
      "epoch:16 step:13122[D loss: 0.398092, acc: 63.28%, op_acc: 46.88%] [G loss: 0.916647]\n",
      "epoch:16 step:13123[D loss: 0.431569, acc: 58.59%, op_acc: 42.97%] [G loss: 0.979760]\n",
      "epoch:16 step:13124[D loss: 0.418621, acc: 58.59%, op_acc: 37.50%] [G loss: 0.889405]\n",
      "epoch:16 step:13125[D loss: 0.463045, acc: 54.69%, op_acc: 34.38%] [G loss: 0.889134]\n",
      "epoch:16 step:13126[D loss: 0.437339, acc: 55.47%, op_acc: 42.97%] [G loss: 0.783970]\n",
      "epoch:16 step:13127[D loss: 0.429555, acc: 57.03%, op_acc: 37.50%] [G loss: 0.929591]\n",
      "epoch:16 step:13128[D loss: 0.442635, acc: 59.38%, op_acc: 38.28%] [G loss: 0.872357]\n",
      "epoch:16 step:13129[D loss: 0.426244, acc: 55.47%, op_acc: 40.62%] [G loss: 0.927330]\n",
      "epoch:16 step:13130[D loss: 0.447604, acc: 51.56%, op_acc: 41.41%] [G loss: 0.899416]\n",
      "epoch:16 step:13131[D loss: 0.448710, acc: 52.34%, op_acc: 37.50%] [G loss: 0.884170]\n",
      "epoch:16 step:13132[D loss: 0.436792, acc: 54.69%, op_acc: 37.50%] [G loss: 0.936516]\n",
      "epoch:16 step:13133[D loss: 0.446050, acc: 55.47%, op_acc: 38.28%] [G loss: 0.840043]\n",
      "epoch:16 step:13134[D loss: 0.447949, acc: 55.47%, op_acc: 35.94%] [G loss: 0.901673]\n",
      "epoch:16 step:13135[D loss: 0.439021, acc: 52.34%, op_acc: 34.38%] [G loss: 0.871040]\n",
      "epoch:16 step:13136[D loss: 0.446893, acc: 58.59%, op_acc: 35.16%] [G loss: 0.918704]\n",
      "epoch:16 step:13137[D loss: 0.444780, acc: 60.16%, op_acc: 30.47%] [G loss: 0.916457]\n",
      "epoch:16 step:13138[D loss: 0.425684, acc: 57.03%, op_acc: 41.41%] [G loss: 0.892218]\n",
      "epoch:16 step:13139[D loss: 0.454810, acc: 56.25%, op_acc: 35.94%] [G loss: 0.914568]\n",
      "epoch:16 step:13140[D loss: 0.406621, acc: 60.16%, op_acc: 43.75%] [G loss: 0.883387]\n",
      "epoch:16 step:13141[D loss: 0.399774, acc: 67.19%, op_acc: 41.41%] [G loss: 0.890472]\n",
      "epoch:16 step:13142[D loss: 0.460058, acc: 50.78%, op_acc: 35.94%] [G loss: 0.851522]\n",
      "epoch:16 step:13143[D loss: 0.410163, acc: 66.41%, op_acc: 35.94%] [G loss: 0.924593]\n",
      "epoch:16 step:13144[D loss: 0.439431, acc: 54.69%, op_acc: 35.94%] [G loss: 0.874892]\n",
      "epoch:16 step:13145[D loss: 0.446873, acc: 54.69%, op_acc: 39.84%] [G loss: 0.890888]\n",
      "epoch:16 step:13146[D loss: 0.447631, acc: 60.16%, op_acc: 33.59%] [G loss: 0.869318]\n",
      "epoch:16 step:13147[D loss: 0.438287, acc: 55.47%, op_acc: 39.84%] [G loss: 0.886209]\n",
      "epoch:16 step:13148[D loss: 0.412206, acc: 60.94%, op_acc: 39.06%] [G loss: 0.891893]\n",
      "epoch:16 step:13149[D loss: 0.394172, acc: 71.09%, op_acc: 38.28%] [G loss: 0.947713]\n",
      "epoch:16 step:13150[D loss: 0.421981, acc: 58.59%, op_acc: 37.50%] [G loss: 0.838068]\n",
      "##############\n",
      "[0.86520663 0.85268585 0.81890446 0.80410141 0.78007261 0.83381311\n",
      " 0.89714035 0.83897471 0.81442218 0.8259307 ]\n",
      "##########\n",
      "epoch:16 step:13151[D loss: 0.422775, acc: 60.16%, op_acc: 35.94%] [G loss: 0.855690]\n",
      "epoch:16 step:13152[D loss: 0.465218, acc: 50.78%, op_acc: 34.38%] [G loss: 0.884570]\n",
      "epoch:16 step:13153[D loss: 0.416097, acc: 59.38%, op_acc: 36.72%] [G loss: 0.866199]\n",
      "epoch:16 step:13154[D loss: 0.446750, acc: 56.25%, op_acc: 38.28%] [G loss: 0.833290]\n",
      "epoch:16 step:13155[D loss: 0.450646, acc: 50.00%, op_acc: 33.59%] [G loss: 0.843813]\n",
      "epoch:16 step:13156[D loss: 0.432261, acc: 56.25%, op_acc: 38.28%] [G loss: 0.863468]\n",
      "epoch:16 step:13157[D loss: 0.411226, acc: 58.59%, op_acc: 37.50%] [G loss: 0.854455]\n",
      "epoch:16 step:13158[D loss: 0.421186, acc: 64.06%, op_acc: 39.06%] [G loss: 0.818667]\n",
      "epoch:16 step:13159[D loss: 0.408698, acc: 61.72%, op_acc: 38.28%] [G loss: 0.882160]\n",
      "epoch:16 step:13160[D loss: 0.406087, acc: 64.84%, op_acc: 39.84%] [G loss: 0.865036]\n",
      "epoch:16 step:13161[D loss: 0.439842, acc: 57.81%, op_acc: 38.28%] [G loss: 0.907878]\n",
      "epoch:16 step:13162[D loss: 0.420819, acc: 61.72%, op_acc: 36.72%] [G loss: 0.928218]\n",
      "epoch:16 step:13163[D loss: 0.416224, acc: 63.28%, op_acc: 40.62%] [G loss: 0.778014]\n",
      "epoch:16 step:13164[D loss: 0.439204, acc: 57.03%, op_acc: 32.81%] [G loss: 0.836324]\n",
      "epoch:16 step:13165[D loss: 0.443529, acc: 57.81%, op_acc: 37.50%] [G loss: 0.895144]\n",
      "epoch:16 step:13166[D loss: 0.419390, acc: 47.66%, op_acc: 40.62%] [G loss: 0.854352]\n",
      "epoch:16 step:13167[D loss: 0.452976, acc: 57.03%, op_acc: 33.59%] [G loss: 0.865059]\n",
      "epoch:16 step:13168[D loss: 0.450417, acc: 60.94%, op_acc: 34.38%] [G loss: 0.914377]\n",
      "epoch:16 step:13169[D loss: 0.419188, acc: 64.84%, op_acc: 36.72%] [G loss: 0.910064]\n",
      "epoch:16 step:13170[D loss: 0.410940, acc: 63.28%, op_acc: 37.50%] [G loss: 0.973746]\n",
      "epoch:16 step:13171[D loss: 0.443346, acc: 61.72%, op_acc: 33.59%] [G loss: 0.849173]\n",
      "epoch:16 step:13172[D loss: 0.465758, acc: 54.69%, op_acc: 35.16%] [G loss: 0.908826]\n",
      "epoch:16 step:13173[D loss: 0.454913, acc: 57.81%, op_acc: 35.94%] [G loss: 0.892689]\n",
      "epoch:16 step:13174[D loss: 0.396958, acc: 66.41%, op_acc: 40.62%] [G loss: 0.983422]\n",
      "epoch:16 step:13175[D loss: 0.433209, acc: 54.69%, op_acc: 40.62%] [G loss: 0.914027]\n",
      "epoch:16 step:13176[D loss: 0.449652, acc: 52.34%, op_acc: 37.50%] [G loss: 0.953961]\n",
      "epoch:16 step:13177[D loss: 0.454719, acc: 53.91%, op_acc: 37.50%] [G loss: 0.922913]\n",
      "epoch:16 step:13178[D loss: 0.402978, acc: 68.75%, op_acc: 39.06%] [G loss: 0.898180]\n",
      "epoch:16 step:13179[D loss: 0.426557, acc: 60.94%, op_acc: 40.62%] [G loss: 0.847084]\n",
      "epoch:16 step:13180[D loss: 0.432692, acc: 66.41%, op_acc: 32.81%] [G loss: 0.847575]\n",
      "epoch:16 step:13181[D loss: 0.464808, acc: 56.25%, op_acc: 35.94%] [G loss: 0.892526]\n",
      "epoch:16 step:13182[D loss: 0.405382, acc: 67.97%, op_acc: 42.19%] [G loss: 0.877318]\n",
      "epoch:16 step:13183[D loss: 0.416394, acc: 61.72%, op_acc: 41.41%] [G loss: 0.911598]\n",
      "epoch:16 step:13184[D loss: 0.435731, acc: 55.47%, op_acc: 39.06%] [G loss: 0.849001]\n",
      "epoch:16 step:13185[D loss: 0.447693, acc: 51.56%, op_acc: 39.06%] [G loss: 0.961192]\n",
      "epoch:16 step:13186[D loss: 0.436477, acc: 57.03%, op_acc: 39.84%] [G loss: 0.896925]\n",
      "epoch:16 step:13187[D loss: 0.426541, acc: 58.59%, op_acc: 35.16%] [G loss: 0.908531]\n",
      "epoch:16 step:13188[D loss: 0.445140, acc: 58.59%, op_acc: 39.06%] [G loss: 0.871506]\n",
      "epoch:16 step:13189[D loss: 0.432776, acc: 60.94%, op_acc: 41.41%] [G loss: 0.835545]\n",
      "epoch:16 step:13190[D loss: 0.416640, acc: 58.59%, op_acc: 37.50%] [G loss: 0.861622]\n",
      "epoch:16 step:13191[D loss: 0.411355, acc: 59.38%, op_acc: 37.50%] [G loss: 0.864990]\n",
      "epoch:16 step:13192[D loss: 0.465861, acc: 51.56%, op_acc: 32.03%] [G loss: 0.846975]\n",
      "epoch:16 step:13193[D loss: 0.400837, acc: 64.84%, op_acc: 40.62%] [G loss: 0.853761]\n",
      "epoch:16 step:13194[D loss: 0.441254, acc: 60.94%, op_acc: 33.59%] [G loss: 0.935598]\n",
      "epoch:16 step:13195[D loss: 0.434473, acc: 57.81%, op_acc: 36.72%] [G loss: 0.844246]\n",
      "epoch:16 step:13196[D loss: 0.435303, acc: 64.06%, op_acc: 34.38%] [G loss: 0.892722]\n",
      "epoch:16 step:13197[D loss: 0.436268, acc: 61.72%, op_acc: 41.41%] [G loss: 0.889100]\n",
      "epoch:16 step:13198[D loss: 0.445717, acc: 50.00%, op_acc: 39.84%] [G loss: 0.859477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13199[D loss: 0.421632, acc: 60.94%, op_acc: 42.97%] [G loss: 0.827851]\n",
      "epoch:16 step:13200[D loss: 0.394760, acc: 61.72%, op_acc: 46.88%] [G loss: 0.890749]\n",
      "##############\n",
      "[0.84050097 0.85128492 0.81042203 0.77862191 0.79829566 0.83622164\n",
      " 0.86494599 0.83076437 0.82111372 0.82088297]\n",
      "##########\n",
      "epoch:16 step:13201[D loss: 0.437719, acc: 64.06%, op_acc: 32.03%] [G loss: 0.847662]\n",
      "epoch:16 step:13202[D loss: 0.423381, acc: 60.16%, op_acc: 38.28%] [G loss: 0.861633]\n",
      "epoch:16 step:13203[D loss: 0.469728, acc: 53.91%, op_acc: 36.72%] [G loss: 0.764799]\n",
      "epoch:16 step:13204[D loss: 0.433323, acc: 60.94%, op_acc: 39.84%] [G loss: 0.979773]\n",
      "epoch:16 step:13205[D loss: 0.412753, acc: 60.16%, op_acc: 39.84%] [G loss: 0.880922]\n",
      "epoch:16 step:13206[D loss: 0.423707, acc: 50.78%, op_acc: 42.19%] [G loss: 0.803494]\n",
      "epoch:16 step:13207[D loss: 0.417571, acc: 66.41%, op_acc: 35.94%] [G loss: 0.912654]\n",
      "epoch:16 step:13208[D loss: 0.427949, acc: 56.25%, op_acc: 39.06%] [G loss: 0.940964]\n",
      "epoch:16 step:13209[D loss: 0.437405, acc: 56.25%, op_acc: 39.06%] [G loss: 0.902917]\n",
      "epoch:16 step:13210[D loss: 0.413800, acc: 67.97%, op_acc: 39.84%] [G loss: 0.918996]\n",
      "epoch:16 step:13211[D loss: 0.416269, acc: 60.16%, op_acc: 41.41%] [G loss: 0.866937]\n",
      "epoch:16 step:13212[D loss: 0.438657, acc: 55.47%, op_acc: 39.84%] [G loss: 0.885499]\n",
      "epoch:16 step:13213[D loss: 0.413791, acc: 57.81%, op_acc: 39.06%] [G loss: 0.860139]\n",
      "epoch:16 step:13214[D loss: 0.416862, acc: 62.50%, op_acc: 40.62%] [G loss: 0.939511]\n",
      "epoch:16 step:13215[D loss: 0.423747, acc: 57.03%, op_acc: 41.41%] [G loss: 0.966321]\n",
      "epoch:16 step:13216[D loss: 0.437453, acc: 58.59%, op_acc: 39.06%] [G loss: 0.817143]\n",
      "epoch:16 step:13217[D loss: 0.441259, acc: 52.34%, op_acc: 34.38%] [G loss: 0.852186]\n",
      "epoch:16 step:13218[D loss: 0.453836, acc: 47.66%, op_acc: 41.41%] [G loss: 0.890844]\n",
      "epoch:16 step:13219[D loss: 0.457193, acc: 53.12%, op_acc: 35.16%] [G loss: 0.851232]\n",
      "epoch:16 step:13220[D loss: 0.463896, acc: 61.72%, op_acc: 32.03%] [G loss: 0.844597]\n",
      "epoch:16 step:13221[D loss: 0.426481, acc: 57.03%, op_acc: 38.28%] [G loss: 0.839478]\n",
      "epoch:16 step:13222[D loss: 0.393411, acc: 69.53%, op_acc: 39.84%] [G loss: 0.965300]\n",
      "epoch:16 step:13223[D loss: 0.443938, acc: 61.72%, op_acc: 35.94%] [G loss: 0.812635]\n",
      "epoch:16 step:13224[D loss: 0.447944, acc: 61.72%, op_acc: 32.81%] [G loss: 0.854257]\n",
      "epoch:16 step:13225[D loss: 0.417968, acc: 67.97%, op_acc: 36.72%] [G loss: 0.945103]\n",
      "epoch:16 step:13226[D loss: 0.422448, acc: 60.94%, op_acc: 37.50%] [G loss: 0.932998]\n",
      "epoch:16 step:13227[D loss: 0.414171, acc: 62.50%, op_acc: 39.84%] [G loss: 0.915618]\n",
      "epoch:16 step:13228[D loss: 0.419677, acc: 60.94%, op_acc: 40.62%] [G loss: 0.812307]\n",
      "epoch:16 step:13229[D loss: 0.439201, acc: 58.59%, op_acc: 42.97%] [G loss: 0.884863]\n",
      "epoch:16 step:13230[D loss: 0.459071, acc: 55.47%, op_acc: 38.28%] [G loss: 0.909262]\n",
      "epoch:16 step:13231[D loss: 0.463416, acc: 50.78%, op_acc: 36.72%] [G loss: 0.817591]\n",
      "epoch:16 step:13232[D loss: 0.412548, acc: 67.19%, op_acc: 38.28%] [G loss: 1.009382]\n",
      "epoch:16 step:13233[D loss: 0.417376, acc: 58.59%, op_acc: 39.06%] [G loss: 0.836134]\n",
      "epoch:16 step:13234[D loss: 0.436403, acc: 57.03%, op_acc: 37.50%] [G loss: 0.948022]\n",
      "epoch:16 step:13235[D loss: 0.428279, acc: 56.25%, op_acc: 38.28%] [G loss: 0.952906]\n",
      "epoch:16 step:13236[D loss: 0.390033, acc: 67.97%, op_acc: 39.84%] [G loss: 0.875585]\n",
      "epoch:16 step:13237[D loss: 0.414798, acc: 67.19%, op_acc: 36.72%] [G loss: 0.871344]\n",
      "epoch:16 step:13238[D loss: 0.460196, acc: 50.78%, op_acc: 39.06%] [G loss: 0.885215]\n",
      "epoch:16 step:13239[D loss: 0.444407, acc: 52.34%, op_acc: 35.94%] [G loss: 0.837584]\n",
      "epoch:16 step:13240[D loss: 0.431465, acc: 53.91%, op_acc: 39.06%] [G loss: 0.916315]\n",
      "epoch:16 step:13241[D loss: 0.434706, acc: 51.56%, op_acc: 42.19%] [G loss: 0.911130]\n",
      "epoch:16 step:13242[D loss: 0.419359, acc: 61.72%, op_acc: 37.50%] [G loss: 0.831219]\n",
      "epoch:16 step:13243[D loss: 0.444071, acc: 54.69%, op_acc: 35.94%] [G loss: 0.833558]\n",
      "epoch:16 step:13244[D loss: 0.438904, acc: 57.03%, op_acc: 36.72%] [G loss: 0.865847]\n",
      "epoch:16 step:13245[D loss: 0.446473, acc: 59.38%, op_acc: 35.16%] [G loss: 0.898963]\n",
      "epoch:16 step:13246[D loss: 0.424073, acc: 63.28%, op_acc: 36.72%] [G loss: 0.893899]\n",
      "epoch:16 step:13247[D loss: 0.463082, acc: 64.06%, op_acc: 31.25%] [G loss: 0.943862]\n",
      "epoch:16 step:13248[D loss: 0.432437, acc: 58.59%, op_acc: 39.06%] [G loss: 0.844594]\n",
      "epoch:16 step:13249[D loss: 0.413256, acc: 61.72%, op_acc: 40.62%] [G loss: 0.904285]\n",
      "epoch:16 step:13250[D loss: 0.427573, acc: 57.81%, op_acc: 39.06%] [G loss: 0.898986]\n",
      "##############\n",
      "[0.88212921 0.86287932 0.80061868 0.79840873 0.80118036 0.83574327\n",
      " 0.88358625 0.84329827 0.80105811 0.81852421]\n",
      "##########\n",
      "epoch:16 step:13251[D loss: 0.410675, acc: 69.53%, op_acc: 37.50%] [G loss: 0.895493]\n",
      "epoch:16 step:13252[D loss: 0.430590, acc: 56.25%, op_acc: 39.84%] [G loss: 0.870572]\n",
      "epoch:16 step:13253[D loss: 0.440602, acc: 53.91%, op_acc: 39.84%] [G loss: 0.850155]\n",
      "epoch:16 step:13254[D loss: 0.440161, acc: 52.34%, op_acc: 42.19%] [G loss: 0.849375]\n",
      "epoch:16 step:13255[D loss: 0.428923, acc: 58.59%, op_acc: 42.97%] [G loss: 1.001136]\n",
      "epoch:16 step:13256[D loss: 0.395619, acc: 68.75%, op_acc: 39.84%] [G loss: 0.950137]\n",
      "epoch:16 step:13257[D loss: 0.417446, acc: 62.50%, op_acc: 40.62%] [G loss: 0.974255]\n",
      "epoch:16 step:13258[D loss: 0.440753, acc: 57.81%, op_acc: 38.28%] [G loss: 0.804003]\n",
      "epoch:16 step:13259[D loss: 0.437450, acc: 61.72%, op_acc: 33.59%] [G loss: 0.914689]\n",
      "epoch:16 step:13260[D loss: 0.429003, acc: 57.03%, op_acc: 38.28%] [G loss: 0.800419]\n",
      "epoch:16 step:13261[D loss: 0.393892, acc: 64.06%, op_acc: 42.97%] [G loss: 0.842461]\n",
      "epoch:16 step:13262[D loss: 0.445291, acc: 53.12%, op_acc: 40.62%] [G loss: 0.821387]\n",
      "epoch:16 step:13263[D loss: 0.418916, acc: 64.84%, op_acc: 39.06%] [G loss: 0.872209]\n",
      "epoch:16 step:13264[D loss: 0.419140, acc: 58.59%, op_acc: 38.28%] [G loss: 0.836711]\n",
      "epoch:16 step:13265[D loss: 0.395662, acc: 65.62%, op_acc: 40.62%] [G loss: 0.871355]\n",
      "epoch:16 step:13266[D loss: 0.427514, acc: 60.94%, op_acc: 38.28%] [G loss: 0.867034]\n",
      "epoch:16 step:13267[D loss: 0.480259, acc: 53.12%, op_acc: 28.12%] [G loss: 0.827234]\n",
      "epoch:16 step:13268[D loss: 0.445995, acc: 59.38%, op_acc: 35.16%] [G loss: 0.841497]\n",
      "epoch:16 step:13269[D loss: 0.463711, acc: 51.56%, op_acc: 37.50%] [G loss: 0.858951]\n",
      "epoch:16 step:13270[D loss: 0.383126, acc: 65.62%, op_acc: 43.75%] [G loss: 0.912115]\n",
      "epoch:16 step:13271[D loss: 0.422219, acc: 61.72%, op_acc: 33.59%] [G loss: 0.887735]\n",
      "epoch:16 step:13272[D loss: 0.436464, acc: 54.69%, op_acc: 37.50%] [G loss: 0.834642]\n",
      "epoch:16 step:13273[D loss: 0.490510, acc: 48.44%, op_acc: 29.69%] [G loss: 0.861641]\n",
      "epoch:16 step:13274[D loss: 0.422333, acc: 59.38%, op_acc: 46.09%] [G loss: 0.895702]\n",
      "epoch:16 step:13275[D loss: 0.444824, acc: 53.91%, op_acc: 33.59%] [G loss: 0.857280]\n",
      "epoch:16 step:13276[D loss: 0.421085, acc: 59.38%, op_acc: 37.50%] [G loss: 0.860915]\n",
      "epoch:16 step:13277[D loss: 0.399387, acc: 68.75%, op_acc: 39.06%] [G loss: 0.877267]\n",
      "epoch:17 step:13278[D loss: 0.441873, acc: 57.81%, op_acc: 39.06%] [G loss: 0.903998]\n",
      "epoch:17 step:13279[D loss: 0.418793, acc: 53.91%, op_acc: 41.41%] [G loss: 0.929116]\n",
      "epoch:17 step:13280[D loss: 0.437396, acc: 55.47%, op_acc: 37.50%] [G loss: 0.875126]\n",
      "epoch:17 step:13281[D loss: 0.424337, acc: 62.50%, op_acc: 37.50%] [G loss: 0.917512]\n",
      "epoch:17 step:13282[D loss: 0.412131, acc: 67.19%, op_acc: 40.62%] [G loss: 0.896365]\n",
      "epoch:17 step:13283[D loss: 0.438841, acc: 53.91%, op_acc: 36.72%] [G loss: 0.932028]\n",
      "epoch:17 step:13284[D loss: 0.388295, acc: 64.84%, op_acc: 42.97%] [G loss: 0.931417]\n",
      "epoch:17 step:13285[D loss: 0.413411, acc: 59.38%, op_acc: 39.06%] [G loss: 0.890421]\n",
      "epoch:17 step:13286[D loss: 0.384060, acc: 63.28%, op_acc: 39.06%] [G loss: 0.820978]\n",
      "epoch:17 step:13287[D loss: 0.428252, acc: 62.50%, op_acc: 39.06%] [G loss: 0.895984]\n",
      "epoch:17 step:13288[D loss: 0.444248, acc: 54.69%, op_acc: 35.94%] [G loss: 0.823867]\n",
      "epoch:17 step:13289[D loss: 0.409096, acc: 63.28%, op_acc: 36.72%] [G loss: 0.924552]\n",
      "epoch:17 step:13290[D loss: 0.424793, acc: 61.72%, op_acc: 40.62%] [G loss: 0.820657]\n",
      "epoch:17 step:13291[D loss: 0.454991, acc: 57.81%, op_acc: 35.16%] [G loss: 0.918731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13292[D loss: 0.429010, acc: 56.25%, op_acc: 42.97%] [G loss: 0.856290]\n",
      "epoch:17 step:13293[D loss: 0.400679, acc: 61.72%, op_acc: 41.41%] [G loss: 0.900142]\n",
      "epoch:17 step:13294[D loss: 0.443916, acc: 56.25%, op_acc: 38.28%] [G loss: 0.880251]\n",
      "epoch:17 step:13295[D loss: 0.421378, acc: 51.56%, op_acc: 38.28%] [G loss: 0.871814]\n",
      "epoch:17 step:13296[D loss: 0.449826, acc: 49.22%, op_acc: 35.16%] [G loss: 0.784608]\n",
      "epoch:17 step:13297[D loss: 0.414935, acc: 62.50%, op_acc: 35.94%] [G loss: 0.891030]\n",
      "epoch:17 step:13298[D loss: 0.449945, acc: 59.38%, op_acc: 32.81%] [G loss: 0.786143]\n",
      "epoch:17 step:13299[D loss: 0.428326, acc: 60.94%, op_acc: 40.62%] [G loss: 0.937067]\n",
      "epoch:17 step:13300[D loss: 0.389214, acc: 67.97%, op_acc: 40.62%] [G loss: 0.970004]\n",
      "##############\n",
      "[0.85880074 0.84801495 0.80800683 0.80963518 0.82210817 0.83659043\n",
      " 0.88586345 0.81845427 0.80376435 0.8212566 ]\n",
      "##########\n",
      "epoch:17 step:13301[D loss: 0.442236, acc: 62.50%, op_acc: 37.50%] [G loss: 0.956550]\n",
      "epoch:17 step:13302[D loss: 0.432424, acc: 63.28%, op_acc: 42.19%] [G loss: 0.878966]\n",
      "epoch:17 step:13303[D loss: 0.430078, acc: 52.34%, op_acc: 40.62%] [G loss: 0.956834]\n",
      "epoch:17 step:13304[D loss: 0.404332, acc: 67.19%, op_acc: 40.62%] [G loss: 0.875558]\n",
      "epoch:17 step:13305[D loss: 0.409071, acc: 59.38%, op_acc: 42.97%] [G loss: 0.951897]\n",
      "epoch:17 step:13306[D loss: 0.393692, acc: 70.31%, op_acc: 47.66%] [G loss: 0.880139]\n",
      "epoch:17 step:13307[D loss: 0.388224, acc: 67.97%, op_acc: 39.06%] [G loss: 0.952217]\n",
      "epoch:17 step:13308[D loss: 0.421515, acc: 60.94%, op_acc: 39.84%] [G loss: 0.904394]\n",
      "epoch:17 step:13309[D loss: 0.441777, acc: 52.34%, op_acc: 39.84%] [G loss: 0.922587]\n",
      "epoch:17 step:13310[D loss: 0.410904, acc: 61.72%, op_acc: 45.31%] [G loss: 0.886135]\n",
      "epoch:17 step:13311[D loss: 0.398319, acc: 67.97%, op_acc: 45.31%] [G loss: 0.922425]\n",
      "epoch:17 step:13312[D loss: 0.441253, acc: 57.03%, op_acc: 40.62%] [G loss: 0.897838]\n",
      "epoch:17 step:13313[D loss: 0.444630, acc: 57.81%, op_acc: 34.38%] [G loss: 0.916125]\n",
      "epoch:17 step:13314[D loss: 0.415993, acc: 59.38%, op_acc: 39.84%] [G loss: 0.852287]\n",
      "epoch:17 step:13315[D loss: 0.432500, acc: 55.47%, op_acc: 42.97%] [G loss: 0.897672]\n",
      "epoch:17 step:13316[D loss: 0.405425, acc: 63.28%, op_acc: 40.62%] [G loss: 0.824769]\n",
      "epoch:17 step:13317[D loss: 0.449631, acc: 55.47%, op_acc: 34.38%] [G loss: 0.868792]\n",
      "epoch:17 step:13318[D loss: 0.391162, acc: 62.50%, op_acc: 41.41%] [G loss: 0.893305]\n",
      "epoch:17 step:13319[D loss: 0.392154, acc: 64.06%, op_acc: 43.75%] [G loss: 0.942547]\n",
      "epoch:17 step:13320[D loss: 0.430167, acc: 58.59%, op_acc: 37.50%] [G loss: 0.926238]\n",
      "epoch:17 step:13321[D loss: 0.426953, acc: 59.38%, op_acc: 40.62%] [G loss: 0.875395]\n",
      "epoch:17 step:13322[D loss: 0.442166, acc: 58.59%, op_acc: 34.38%] [G loss: 0.864107]\n",
      "epoch:17 step:13323[D loss: 0.430231, acc: 57.03%, op_acc: 34.38%] [G loss: 0.840784]\n",
      "epoch:17 step:13324[D loss: 0.440989, acc: 60.16%, op_acc: 35.94%] [G loss: 0.874206]\n",
      "epoch:17 step:13325[D loss: 0.439277, acc: 57.81%, op_acc: 34.38%] [G loss: 0.818550]\n",
      "epoch:17 step:13326[D loss: 0.452821, acc: 55.47%, op_acc: 33.59%] [G loss: 0.767412]\n",
      "epoch:17 step:13327[D loss: 0.446564, acc: 58.59%, op_acc: 37.50%] [G loss: 0.859015]\n",
      "epoch:17 step:13328[D loss: 0.409343, acc: 64.06%, op_acc: 38.28%] [G loss: 0.906754]\n",
      "epoch:17 step:13329[D loss: 0.391098, acc: 75.78%, op_acc: 30.47%] [G loss: 0.888751]\n",
      "epoch:17 step:13330[D loss: 0.458197, acc: 56.25%, op_acc: 34.38%] [G loss: 0.854708]\n",
      "epoch:17 step:13331[D loss: 0.445203, acc: 59.38%, op_acc: 39.84%] [G loss: 0.820005]\n",
      "epoch:17 step:13332[D loss: 0.428396, acc: 58.59%, op_acc: 38.28%] [G loss: 0.907748]\n",
      "epoch:17 step:13333[D loss: 0.428426, acc: 58.59%, op_acc: 39.06%] [G loss: 0.858153]\n",
      "epoch:17 step:13334[D loss: 0.437808, acc: 56.25%, op_acc: 36.72%] [G loss: 0.833778]\n",
      "epoch:17 step:13335[D loss: 0.425887, acc: 57.81%, op_acc: 42.19%] [G loss: 0.884261]\n",
      "epoch:17 step:13336[D loss: 0.394306, acc: 63.28%, op_acc: 41.41%] [G loss: 0.947799]\n",
      "epoch:17 step:13337[D loss: 0.415820, acc: 58.59%, op_acc: 38.28%] [G loss: 0.901082]\n",
      "epoch:17 step:13338[D loss: 0.442008, acc: 56.25%, op_acc: 34.38%] [G loss: 0.852612]\n",
      "epoch:17 step:13339[D loss: 0.431694, acc: 63.28%, op_acc: 36.72%] [G loss: 0.895998]\n",
      "epoch:17 step:13340[D loss: 0.427672, acc: 66.41%, op_acc: 33.59%] [G loss: 0.882433]\n",
      "epoch:17 step:13341[D loss: 0.395921, acc: 68.75%, op_acc: 35.94%] [G loss: 0.979736]\n",
      "epoch:17 step:13342[D loss: 0.442256, acc: 55.47%, op_acc: 40.62%] [G loss: 0.839903]\n",
      "epoch:17 step:13343[D loss: 0.413821, acc: 63.28%, op_acc: 36.72%] [G loss: 0.900308]\n",
      "epoch:17 step:13344[D loss: 0.429258, acc: 56.25%, op_acc: 38.28%] [G loss: 0.872748]\n",
      "epoch:17 step:13345[D loss: 0.410917, acc: 68.75%, op_acc: 30.47%] [G loss: 0.953657]\n",
      "epoch:17 step:13346[D loss: 0.401868, acc: 61.72%, op_acc: 46.88%] [G loss: 0.898648]\n",
      "epoch:17 step:13347[D loss: 0.448827, acc: 54.69%, op_acc: 37.50%] [G loss: 0.901129]\n",
      "epoch:17 step:13348[D loss: 0.465552, acc: 55.47%, op_acc: 35.16%] [G loss: 0.864616]\n",
      "epoch:17 step:13349[D loss: 0.415673, acc: 60.94%, op_acc: 39.84%] [G loss: 0.855731]\n",
      "epoch:17 step:13350[D loss: 0.418263, acc: 67.97%, op_acc: 34.38%] [G loss: 0.860791]\n",
      "##############\n",
      "[0.8598496  0.84479397 0.82067597 0.81065219 0.80249635 0.82944204\n",
      " 0.87543937 0.78434537 0.81386564 0.83054908]\n",
      "##########\n",
      "epoch:17 step:13351[D loss: 0.402953, acc: 58.59%, op_acc: 42.19%] [G loss: 0.881110]\n",
      "epoch:17 step:13352[D loss: 0.428506, acc: 55.47%, op_acc: 41.41%] [G loss: 0.878863]\n",
      "epoch:17 step:13353[D loss: 0.447788, acc: 63.28%, op_acc: 34.38%] [G loss: 0.820473]\n",
      "epoch:17 step:13354[D loss: 0.448034, acc: 55.47%, op_acc: 32.03%] [G loss: 0.801828]\n",
      "epoch:17 step:13355[D loss: 0.466437, acc: 60.16%, op_acc: 28.12%] [G loss: 0.927759]\n",
      "epoch:17 step:13356[D loss: 0.446474, acc: 55.47%, op_acc: 30.47%] [G loss: 0.868162]\n",
      "epoch:17 step:13357[D loss: 0.438136, acc: 58.59%, op_acc: 30.47%] [G loss: 0.876821]\n",
      "epoch:17 step:13358[D loss: 0.442419, acc: 54.69%, op_acc: 31.25%] [G loss: 0.913358]\n",
      "epoch:17 step:13359[D loss: 0.403179, acc: 66.41%, op_acc: 42.19%] [G loss: 0.965769]\n",
      "epoch:17 step:13360[D loss: 0.453160, acc: 54.69%, op_acc: 32.03%] [G loss: 0.893705]\n",
      "epoch:17 step:13361[D loss: 0.432402, acc: 53.91%, op_acc: 46.09%] [G loss: 0.822606]\n",
      "epoch:17 step:13362[D loss: 0.435528, acc: 58.59%, op_acc: 30.47%] [G loss: 0.786003]\n",
      "epoch:17 step:13363[D loss: 0.440705, acc: 48.44%, op_acc: 35.16%] [G loss: 0.830438]\n",
      "epoch:17 step:13364[D loss: 0.414755, acc: 61.72%, op_acc: 35.16%] [G loss: 0.978414]\n",
      "epoch:17 step:13365[D loss: 0.421479, acc: 64.84%, op_acc: 33.59%] [G loss: 0.966348]\n",
      "epoch:17 step:13366[D loss: 0.452650, acc: 55.47%, op_acc: 34.38%] [G loss: 0.886982]\n",
      "epoch:17 step:13367[D loss: 0.467289, acc: 46.88%, op_acc: 34.38%] [G loss: 0.860365]\n",
      "epoch:17 step:13368[D loss: 0.434468, acc: 55.47%, op_acc: 36.72%] [G loss: 0.838699]\n",
      "epoch:17 step:13369[D loss: 0.435064, acc: 60.94%, op_acc: 29.69%] [G loss: 0.856621]\n",
      "epoch:17 step:13370[D loss: 0.406977, acc: 67.19%, op_acc: 39.84%] [G loss: 0.879144]\n",
      "epoch:17 step:13371[D loss: 0.410747, acc: 62.50%, op_acc: 39.06%] [G loss: 0.824540]\n",
      "epoch:17 step:13372[D loss: 0.435239, acc: 53.12%, op_acc: 34.38%] [G loss: 0.915936]\n",
      "epoch:17 step:13373[D loss: 0.473135, acc: 52.34%, op_acc: 35.16%] [G loss: 0.834980]\n",
      "epoch:17 step:13374[D loss: 0.452258, acc: 53.91%, op_acc: 35.16%] [G loss: 0.920866]\n",
      "epoch:17 step:13375[D loss: 0.430441, acc: 65.62%, op_acc: 33.59%] [G loss: 0.909441]\n",
      "epoch:17 step:13376[D loss: 0.406619, acc: 69.53%, op_acc: 39.06%] [G loss: 0.879172]\n",
      "epoch:17 step:13377[D loss: 0.427872, acc: 57.81%, op_acc: 39.06%] [G loss: 0.994315]\n",
      "epoch:17 step:13378[D loss: 0.440816, acc: 60.16%, op_acc: 37.50%] [G loss: 0.926221]\n",
      "epoch:17 step:13379[D loss: 0.439041, acc: 58.59%, op_acc: 39.06%] [G loss: 0.854651]\n",
      "epoch:17 step:13380[D loss: 0.457932, acc: 55.47%, op_acc: 28.12%] [G loss: 0.959424]\n",
      "epoch:17 step:13381[D loss: 0.427695, acc: 56.25%, op_acc: 38.28%] [G loss: 0.927646]\n",
      "epoch:17 step:13382[D loss: 0.437769, acc: 62.50%, op_acc: 42.19%] [G loss: 0.880278]\n",
      "epoch:17 step:13383[D loss: 0.404457, acc: 64.84%, op_acc: 38.28%] [G loss: 0.854428]\n",
      "epoch:17 step:13384[D loss: 0.414520, acc: 60.94%, op_acc: 42.19%] [G loss: 0.930284]\n",
      "epoch:17 step:13385[D loss: 0.457795, acc: 53.12%, op_acc: 28.91%] [G loss: 0.925056]\n",
      "epoch:17 step:13386[D loss: 0.393982, acc: 67.19%, op_acc: 41.41%] [G loss: 0.907509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13387[D loss: 0.435193, acc: 58.59%, op_acc: 35.94%] [G loss: 0.827268]\n",
      "epoch:17 step:13388[D loss: 0.475257, acc: 57.03%, op_acc: 29.69%] [G loss: 0.815270]\n",
      "epoch:17 step:13389[D loss: 0.401209, acc: 60.16%, op_acc: 42.97%] [G loss: 0.944831]\n",
      "epoch:17 step:13390[D loss: 0.437782, acc: 62.50%, op_acc: 32.03%] [G loss: 0.885583]\n",
      "epoch:17 step:13391[D loss: 0.429167, acc: 57.81%, op_acc: 42.19%] [G loss: 0.833315]\n",
      "epoch:17 step:13392[D loss: 0.423656, acc: 61.72%, op_acc: 39.84%] [G loss: 0.790294]\n",
      "epoch:17 step:13393[D loss: 0.434127, acc: 60.94%, op_acc: 39.06%] [G loss: 0.889465]\n",
      "epoch:17 step:13394[D loss: 0.411968, acc: 60.94%, op_acc: 39.06%] [G loss: 0.926703]\n",
      "epoch:17 step:13395[D loss: 0.445877, acc: 53.91%, op_acc: 36.72%] [G loss: 0.862479]\n",
      "epoch:17 step:13396[D loss: 0.415606, acc: 60.94%, op_acc: 44.53%] [G loss: 0.880418]\n",
      "epoch:17 step:13397[D loss: 0.432809, acc: 54.69%, op_acc: 33.59%] [G loss: 0.809394]\n",
      "epoch:17 step:13398[D loss: 0.414642, acc: 59.38%, op_acc: 41.41%] [G loss: 0.979588]\n",
      "epoch:17 step:13399[D loss: 0.446844, acc: 55.47%, op_acc: 35.94%] [G loss: 0.835971]\n",
      "epoch:17 step:13400[D loss: 0.453170, acc: 56.25%, op_acc: 33.59%] [G loss: 0.881906]\n",
      "##############\n",
      "[0.85290243 0.85526167 0.83559172 0.82143407 0.78984998 0.81015945\n",
      " 0.86440485 0.80462136 0.82741739 0.83309923]\n",
      "##########\n",
      "epoch:17 step:13401[D loss: 0.414464, acc: 66.41%, op_acc: 32.81%] [G loss: 0.941168]\n",
      "epoch:17 step:13402[D loss: 0.435133, acc: 58.59%, op_acc: 30.47%] [G loss: 0.923119]\n",
      "epoch:17 step:13403[D loss: 0.429644, acc: 61.72%, op_acc: 39.06%] [G loss: 0.884302]\n",
      "epoch:17 step:13404[D loss: 0.447248, acc: 50.00%, op_acc: 39.84%] [G loss: 0.894060]\n",
      "epoch:17 step:13405[D loss: 0.419934, acc: 67.19%, op_acc: 32.81%] [G loss: 0.904666]\n",
      "epoch:17 step:13406[D loss: 0.445124, acc: 57.03%, op_acc: 35.16%] [G loss: 0.874280]\n",
      "epoch:17 step:13407[D loss: 0.445094, acc: 59.38%, op_acc: 35.94%] [G loss: 0.865983]\n",
      "epoch:17 step:13408[D loss: 0.408257, acc: 59.38%, op_acc: 38.28%] [G loss: 0.816369]\n",
      "epoch:17 step:13409[D loss: 0.401094, acc: 65.62%, op_acc: 39.84%] [G loss: 0.862589]\n",
      "epoch:17 step:13410[D loss: 0.468127, acc: 53.91%, op_acc: 32.03%] [G loss: 0.892721]\n",
      "epoch:17 step:13411[D loss: 0.420851, acc: 64.84%, op_acc: 37.50%] [G loss: 0.931204]\n",
      "epoch:17 step:13412[D loss: 0.448935, acc: 54.69%, op_acc: 32.81%] [G loss: 0.889541]\n",
      "epoch:17 step:13413[D loss: 0.386507, acc: 69.53%, op_acc: 42.19%] [G loss: 0.914818]\n",
      "epoch:17 step:13414[D loss: 0.419653, acc: 66.41%, op_acc: 32.81%] [G loss: 0.829033]\n",
      "epoch:17 step:13415[D loss: 0.436332, acc: 57.81%, op_acc: 35.16%] [G loss: 0.926122]\n",
      "epoch:17 step:13416[D loss: 0.439685, acc: 49.22%, op_acc: 39.06%] [G loss: 0.899472]\n",
      "epoch:17 step:13417[D loss: 0.436908, acc: 57.03%, op_acc: 40.62%] [G loss: 0.846084]\n",
      "epoch:17 step:13418[D loss: 0.469264, acc: 56.25%, op_acc: 30.47%] [G loss: 0.829517]\n",
      "epoch:17 step:13419[D loss: 0.416912, acc: 64.84%, op_acc: 35.16%] [G loss: 0.837228]\n",
      "epoch:17 step:13420[D loss: 0.415437, acc: 57.03%, op_acc: 39.06%] [G loss: 0.868686]\n",
      "epoch:17 step:13421[D loss: 0.434649, acc: 59.38%, op_acc: 38.28%] [G loss: 0.872092]\n",
      "epoch:17 step:13422[D loss: 0.434062, acc: 57.81%, op_acc: 39.84%] [G loss: 0.857088]\n",
      "epoch:17 step:13423[D loss: 0.419445, acc: 60.16%, op_acc: 41.41%] [G loss: 0.945074]\n",
      "epoch:17 step:13424[D loss: 0.418982, acc: 61.72%, op_acc: 41.41%] [G loss: 0.901246]\n",
      "epoch:17 step:13425[D loss: 0.437912, acc: 56.25%, op_acc: 37.50%] [G loss: 0.841021]\n",
      "epoch:17 step:13426[D loss: 0.424749, acc: 58.59%, op_acc: 39.84%] [G loss: 0.904236]\n",
      "epoch:17 step:13427[D loss: 0.423660, acc: 57.03%, op_acc: 40.62%] [G loss: 0.909681]\n",
      "epoch:17 step:13428[D loss: 0.417523, acc: 55.47%, op_acc: 44.53%] [G loss: 0.885802]\n",
      "epoch:17 step:13429[D loss: 0.404759, acc: 64.06%, op_acc: 42.19%] [G loss: 0.815857]\n",
      "epoch:17 step:13430[D loss: 0.442557, acc: 53.12%, op_acc: 32.81%] [G loss: 0.865942]\n",
      "epoch:17 step:13431[D loss: 0.426358, acc: 59.38%, op_acc: 37.50%] [G loss: 0.878245]\n",
      "epoch:17 step:13432[D loss: 0.420534, acc: 61.72%, op_acc: 34.38%] [G loss: 0.853297]\n",
      "epoch:17 step:13433[D loss: 0.434724, acc: 62.50%, op_acc: 32.81%] [G loss: 0.833423]\n",
      "epoch:17 step:13434[D loss: 0.426753, acc: 61.72%, op_acc: 37.50%] [G loss: 0.877984]\n",
      "epoch:17 step:13435[D loss: 0.409877, acc: 57.81%, op_acc: 44.53%] [G loss: 0.886631]\n",
      "epoch:17 step:13436[D loss: 0.451786, acc: 52.34%, op_acc: 36.72%] [G loss: 0.882976]\n",
      "epoch:17 step:13437[D loss: 0.460735, acc: 46.88%, op_acc: 34.38%] [G loss: 0.893740]\n",
      "epoch:17 step:13438[D loss: 0.437932, acc: 57.81%, op_acc: 42.19%] [G loss: 0.930774]\n",
      "epoch:17 step:13439[D loss: 0.425007, acc: 57.03%, op_acc: 40.62%] [G loss: 0.919910]\n",
      "epoch:17 step:13440[D loss: 0.428352, acc: 64.06%, op_acc: 35.16%] [G loss: 0.967350]\n",
      "epoch:17 step:13441[D loss: 0.460244, acc: 45.31%, op_acc: 29.69%] [G loss: 0.855226]\n",
      "epoch:17 step:13442[D loss: 0.403729, acc: 61.72%, op_acc: 40.62%] [G loss: 0.906477]\n",
      "epoch:17 step:13443[D loss: 0.452514, acc: 59.38%, op_acc: 39.84%] [G loss: 0.887789]\n",
      "epoch:17 step:13444[D loss: 0.438808, acc: 57.81%, op_acc: 35.94%] [G loss: 0.806671]\n",
      "epoch:17 step:13445[D loss: 0.441807, acc: 53.91%, op_acc: 40.62%] [G loss: 0.879922]\n",
      "epoch:17 step:13446[D loss: 0.404482, acc: 70.31%, op_acc: 40.62%] [G loss: 0.945124]\n",
      "epoch:17 step:13447[D loss: 0.413842, acc: 63.28%, op_acc: 42.97%] [G loss: 0.955966]\n",
      "epoch:17 step:13448[D loss: 0.441998, acc: 52.34%, op_acc: 33.59%] [G loss: 0.926248]\n",
      "epoch:17 step:13449[D loss: 0.411157, acc: 63.28%, op_acc: 39.06%] [G loss: 0.935005]\n",
      "epoch:17 step:13450[D loss: 0.440313, acc: 59.38%, op_acc: 36.72%] [G loss: 0.828698]\n",
      "##############\n",
      "[0.85677773 0.85232891 0.80602957 0.79026987 0.76913977 0.84434811\n",
      " 0.87333866 0.83297905 0.82603053 0.80570132]\n",
      "##########\n",
      "epoch:17 step:13451[D loss: 0.468233, acc: 53.91%, op_acc: 34.38%] [G loss: 0.899156]\n",
      "epoch:17 step:13452[D loss: 0.397910, acc: 63.28%, op_acc: 42.97%] [G loss: 0.917380]\n",
      "epoch:17 step:13453[D loss: 0.431336, acc: 60.16%, op_acc: 38.28%] [G loss: 0.889757]\n",
      "epoch:17 step:13454[D loss: 0.406653, acc: 64.06%, op_acc: 39.84%] [G loss: 0.779514]\n",
      "epoch:17 step:13455[D loss: 0.452454, acc: 60.94%, op_acc: 29.69%] [G loss: 0.867435]\n",
      "epoch:17 step:13456[D loss: 0.378620, acc: 73.44%, op_acc: 37.50%] [G loss: 0.936698]\n",
      "epoch:17 step:13457[D loss: 0.444859, acc: 62.50%, op_acc: 32.03%] [G loss: 0.923655]\n",
      "epoch:17 step:13458[D loss: 0.406055, acc: 63.28%, op_acc: 42.19%] [G loss: 0.935751]\n",
      "epoch:17 step:13459[D loss: 0.383886, acc: 70.31%, op_acc: 48.44%] [G loss: 0.965797]\n",
      "epoch:17 step:13460[D loss: 0.422209, acc: 60.94%, op_acc: 44.53%] [G loss: 0.860575]\n",
      "epoch:17 step:13461[D loss: 0.411563, acc: 61.72%, op_acc: 39.84%] [G loss: 0.934745]\n",
      "epoch:17 step:13462[D loss: 0.428241, acc: 61.72%, op_acc: 34.38%] [G loss: 0.929415]\n",
      "epoch:17 step:13463[D loss: 0.428485, acc: 67.97%, op_acc: 46.09%] [G loss: 0.955234]\n",
      "epoch:17 step:13464[D loss: 0.432838, acc: 54.69%, op_acc: 42.97%] [G loss: 0.837095]\n",
      "epoch:17 step:13465[D loss: 0.431202, acc: 56.25%, op_acc: 42.19%] [G loss: 0.984834]\n",
      "epoch:17 step:13466[D loss: 0.405237, acc: 67.19%, op_acc: 38.28%] [G loss: 0.947157]\n",
      "epoch:17 step:13467[D loss: 0.451252, acc: 57.03%, op_acc: 35.16%] [G loss: 0.960685]\n",
      "epoch:17 step:13468[D loss: 0.419530, acc: 63.28%, op_acc: 40.62%] [G loss: 0.917806]\n",
      "epoch:17 step:13469[D loss: 0.440101, acc: 50.00%, op_acc: 36.72%] [G loss: 0.860729]\n",
      "epoch:17 step:13470[D loss: 0.451125, acc: 57.81%, op_acc: 28.91%] [G loss: 0.930579]\n",
      "epoch:17 step:13471[D loss: 0.405712, acc: 61.72%, op_acc: 42.19%] [G loss: 0.919763]\n",
      "epoch:17 step:13472[D loss: 0.440797, acc: 65.62%, op_acc: 39.06%] [G loss: 0.901790]\n",
      "epoch:17 step:13473[D loss: 0.415074, acc: 65.62%, op_acc: 39.84%] [G loss: 0.837855]\n",
      "epoch:17 step:13474[D loss: 0.445221, acc: 56.25%, op_acc: 34.38%] [G loss: 0.946661]\n",
      "epoch:17 step:13475[D loss: 0.471482, acc: 53.91%, op_acc: 34.38%] [G loss: 0.817078]\n",
      "epoch:17 step:13476[D loss: 0.445438, acc: 53.12%, op_acc: 34.38%] [G loss: 0.940506]\n",
      "epoch:17 step:13477[D loss: 0.420119, acc: 66.41%, op_acc: 37.50%] [G loss: 0.933847]\n",
      "epoch:17 step:13478[D loss: 0.399872, acc: 65.62%, op_acc: 37.50%] [G loss: 1.000971]\n",
      "epoch:17 step:13479[D loss: 0.442305, acc: 58.59%, op_acc: 33.59%] [G loss: 0.876242]\n",
      "epoch:17 step:13480[D loss: 0.440754, acc: 57.81%, op_acc: 35.16%] [G loss: 0.879206]\n",
      "epoch:17 step:13481[D loss: 0.445218, acc: 54.69%, op_acc: 32.81%] [G loss: 0.988637]\n",
      "epoch:17 step:13482[D loss: 0.430939, acc: 58.59%, op_acc: 39.84%] [G loss: 0.845516]\n",
      "epoch:17 step:13483[D loss: 0.451388, acc: 51.56%, op_acc: 36.72%] [G loss: 0.792507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13484[D loss: 0.436266, acc: 55.47%, op_acc: 44.53%] [G loss: 0.853594]\n",
      "epoch:17 step:13485[D loss: 0.479302, acc: 59.38%, op_acc: 32.03%] [G loss: 0.860418]\n",
      "epoch:17 step:13486[D loss: 0.432963, acc: 56.25%, op_acc: 43.75%] [G loss: 0.912958]\n",
      "epoch:17 step:13487[D loss: 0.470086, acc: 50.00%, op_acc: 37.50%] [G loss: 0.942817]\n",
      "epoch:17 step:13488[D loss: 0.369589, acc: 67.97%, op_acc: 43.75%] [G loss: 0.964445]\n",
      "epoch:17 step:13489[D loss: 0.427395, acc: 57.03%, op_acc: 41.41%] [G loss: 0.938588]\n",
      "epoch:17 step:13490[D loss: 0.439074, acc: 54.69%, op_acc: 40.62%] [G loss: 0.817385]\n",
      "epoch:17 step:13491[D loss: 0.456340, acc: 61.72%, op_acc: 33.59%] [G loss: 0.930384]\n",
      "epoch:17 step:13492[D loss: 0.452153, acc: 63.28%, op_acc: 35.94%] [G loss: 0.980232]\n",
      "epoch:17 step:13493[D loss: 0.449481, acc: 60.94%, op_acc: 34.38%] [G loss: 0.873138]\n",
      "epoch:17 step:13494[D loss: 0.426909, acc: 53.12%, op_acc: 46.09%] [G loss: 0.894101]\n",
      "epoch:17 step:13495[D loss: 0.428759, acc: 58.59%, op_acc: 41.41%] [G loss: 0.878413]\n",
      "epoch:17 step:13496[D loss: 0.408709, acc: 60.94%, op_acc: 42.97%] [G loss: 0.879712]\n",
      "epoch:17 step:13497[D loss: 0.440665, acc: 53.12%, op_acc: 34.38%] [G loss: 0.860261]\n",
      "epoch:17 step:13498[D loss: 0.432034, acc: 56.25%, op_acc: 41.41%] [G loss: 0.912268]\n",
      "epoch:17 step:13499[D loss: 0.429473, acc: 59.38%, op_acc: 36.72%] [G loss: 0.940298]\n",
      "epoch:17 step:13500[D loss: 0.451814, acc: 50.78%, op_acc: 39.06%] [G loss: 0.844042]\n",
      "##############\n",
      "[0.85408574 0.83308228 0.8180067  0.8201841  0.81712914 0.83559643\n",
      " 0.88255673 0.81601597 0.82220014 0.81859879]\n",
      "##########\n",
      "epoch:17 step:13501[D loss: 0.399865, acc: 67.97%, op_acc: 42.19%] [G loss: 0.876350]\n",
      "epoch:17 step:13502[D loss: 0.445136, acc: 55.47%, op_acc: 35.16%] [G loss: 0.886738]\n",
      "epoch:17 step:13503[D loss: 0.426688, acc: 60.16%, op_acc: 39.84%] [G loss: 0.932634]\n",
      "epoch:17 step:13504[D loss: 0.427530, acc: 57.03%, op_acc: 41.41%] [G loss: 0.951146]\n",
      "epoch:17 step:13505[D loss: 0.419655, acc: 54.69%, op_acc: 36.72%] [G loss: 0.824922]\n",
      "epoch:17 step:13506[D loss: 0.411105, acc: 58.59%, op_acc: 45.31%] [G loss: 0.894048]\n",
      "epoch:17 step:13507[D loss: 0.417992, acc: 66.41%, op_acc: 35.94%] [G loss: 0.857021]\n",
      "epoch:17 step:13508[D loss: 0.422105, acc: 56.25%, op_acc: 36.72%] [G loss: 0.911283]\n",
      "epoch:17 step:13509[D loss: 0.438434, acc: 53.91%, op_acc: 38.28%] [G loss: 0.957445]\n",
      "epoch:17 step:13510[D loss: 0.396981, acc: 68.75%, op_acc: 42.19%] [G loss: 0.870803]\n",
      "epoch:17 step:13511[D loss: 0.437845, acc: 65.62%, op_acc: 36.72%] [G loss: 0.889408]\n",
      "epoch:17 step:13512[D loss: 0.395713, acc: 66.41%, op_acc: 45.31%] [G loss: 0.947507]\n",
      "epoch:17 step:13513[D loss: 0.424713, acc: 61.72%, op_acc: 34.38%] [G loss: 0.920941]\n",
      "epoch:17 step:13514[D loss: 0.377366, acc: 70.31%, op_acc: 42.19%] [G loss: 0.970869]\n",
      "epoch:17 step:13515[D loss: 0.430380, acc: 59.38%, op_acc: 38.28%] [G loss: 0.929523]\n",
      "epoch:17 step:13516[D loss: 0.414120, acc: 57.81%, op_acc: 42.97%] [G loss: 0.828196]\n",
      "epoch:17 step:13517[D loss: 0.453224, acc: 53.12%, op_acc: 39.06%] [G loss: 0.943827]\n",
      "epoch:17 step:13518[D loss: 0.425104, acc: 59.38%, op_acc: 35.16%] [G loss: 0.908960]\n",
      "epoch:17 step:13519[D loss: 0.408157, acc: 60.16%, op_acc: 38.28%] [G loss: 0.827815]\n",
      "epoch:17 step:13520[D loss: 0.419433, acc: 57.03%, op_acc: 45.31%] [G loss: 0.829415]\n",
      "epoch:17 step:13521[D loss: 0.433187, acc: 63.28%, op_acc: 36.72%] [G loss: 0.867039]\n",
      "epoch:17 step:13522[D loss: 0.420769, acc: 63.28%, op_acc: 42.97%] [G loss: 0.790923]\n",
      "epoch:17 step:13523[D loss: 0.457936, acc: 54.69%, op_acc: 35.16%] [G loss: 0.908494]\n",
      "epoch:17 step:13524[D loss: 0.401750, acc: 62.50%, op_acc: 43.75%] [G loss: 0.857010]\n",
      "epoch:17 step:13525[D loss: 0.482858, acc: 56.25%, op_acc: 29.69%] [G loss: 0.829485]\n",
      "epoch:17 step:13526[D loss: 0.435868, acc: 64.06%, op_acc: 39.84%] [G loss: 0.915231]\n",
      "epoch:17 step:13527[D loss: 0.434007, acc: 58.59%, op_acc: 35.94%] [G loss: 0.877087]\n",
      "epoch:17 step:13528[D loss: 0.413490, acc: 62.50%, op_acc: 42.97%] [G loss: 0.870736]\n",
      "epoch:17 step:13529[D loss: 0.415728, acc: 60.94%, op_acc: 35.94%] [G loss: 0.878030]\n",
      "epoch:17 step:13530[D loss: 0.422309, acc: 66.41%, op_acc: 39.06%] [G loss: 0.935720]\n",
      "epoch:17 step:13531[D loss: 0.422169, acc: 67.97%, op_acc: 36.72%] [G loss: 0.864424]\n",
      "epoch:17 step:13532[D loss: 0.427483, acc: 59.38%, op_acc: 40.62%] [G loss: 0.879964]\n",
      "epoch:17 step:13533[D loss: 0.423616, acc: 64.84%, op_acc: 41.41%] [G loss: 0.868372]\n",
      "epoch:17 step:13534[D loss: 0.431249, acc: 64.84%, op_acc: 38.28%] [G loss: 0.839881]\n",
      "epoch:17 step:13535[D loss: 0.431349, acc: 57.81%, op_acc: 40.62%] [G loss: 0.798794]\n",
      "epoch:17 step:13536[D loss: 0.422761, acc: 60.16%, op_acc: 36.72%] [G loss: 0.899955]\n",
      "epoch:17 step:13537[D loss: 0.439825, acc: 59.38%, op_acc: 33.59%] [G loss: 0.924223]\n",
      "epoch:17 step:13538[D loss: 0.403913, acc: 62.50%, op_acc: 39.84%] [G loss: 0.916985]\n",
      "epoch:17 step:13539[D loss: 0.424222, acc: 57.81%, op_acc: 38.28%] [G loss: 0.924895]\n",
      "epoch:17 step:13540[D loss: 0.456728, acc: 50.00%, op_acc: 37.50%] [G loss: 0.866702]\n",
      "epoch:17 step:13541[D loss: 0.452632, acc: 59.38%, op_acc: 35.94%] [G loss: 0.928394]\n",
      "epoch:17 step:13542[D loss: 0.379205, acc: 68.75%, op_acc: 42.97%] [G loss: 0.932405]\n",
      "epoch:17 step:13543[D loss: 0.441712, acc: 52.34%, op_acc: 35.94%] [G loss: 0.890978]\n",
      "epoch:17 step:13544[D loss: 0.450366, acc: 57.81%, op_acc: 34.38%] [G loss: 0.897943]\n",
      "epoch:17 step:13545[D loss: 0.414963, acc: 61.72%, op_acc: 43.75%] [G loss: 0.951588]\n",
      "epoch:17 step:13546[D loss: 0.439986, acc: 57.03%, op_acc: 39.06%] [G loss: 0.863968]\n",
      "epoch:17 step:13547[D loss: 0.411902, acc: 62.50%, op_acc: 38.28%] [G loss: 1.030913]\n",
      "epoch:17 step:13548[D loss: 0.429762, acc: 61.72%, op_acc: 35.16%] [G loss: 0.946539]\n",
      "epoch:17 step:13549[D loss: 0.433885, acc: 59.38%, op_acc: 38.28%] [G loss: 0.885392]\n",
      "epoch:17 step:13550[D loss: 0.419904, acc: 57.81%, op_acc: 39.06%] [G loss: 0.916488]\n",
      "##############\n",
      "[0.84311269 0.858177   0.81012459 0.82519134 0.78905405 0.83624848\n",
      " 0.89052215 0.82362477 0.84293224 0.82202767]\n",
      "##########\n",
      "epoch:17 step:13551[D loss: 0.447637, acc: 53.12%, op_acc: 38.28%] [G loss: 0.867931]\n",
      "epoch:17 step:13552[D loss: 0.419886, acc: 60.94%, op_acc: 36.72%] [G loss: 0.924715]\n",
      "epoch:17 step:13553[D loss: 0.433446, acc: 63.28%, op_acc: 38.28%] [G loss: 0.934106]\n",
      "epoch:17 step:13554[D loss: 0.437940, acc: 61.72%, op_acc: 32.03%] [G loss: 0.890769]\n",
      "epoch:17 step:13555[D loss: 0.446108, acc: 60.16%, op_acc: 33.59%] [G loss: 0.922264]\n",
      "epoch:17 step:13556[D loss: 0.454587, acc: 56.25%, op_acc: 35.94%] [G loss: 0.834870]\n",
      "epoch:17 step:13557[D loss: 0.418810, acc: 56.25%, op_acc: 37.50%] [G loss: 0.795531]\n",
      "epoch:17 step:13558[D loss: 0.423502, acc: 64.84%, op_acc: 38.28%] [G loss: 0.876558]\n",
      "epoch:17 step:13559[D loss: 0.427634, acc: 61.72%, op_acc: 36.72%] [G loss: 0.850130]\n",
      "epoch:17 step:13560[D loss: 0.420909, acc: 56.25%, op_acc: 44.53%] [G loss: 0.874895]\n",
      "epoch:17 step:13561[D loss: 0.420542, acc: 60.94%, op_acc: 38.28%] [G loss: 0.938876]\n",
      "epoch:17 step:13562[D loss: 0.425075, acc: 61.72%, op_acc: 39.06%] [G loss: 0.903416]\n",
      "epoch:17 step:13563[D loss: 0.428656, acc: 62.50%, op_acc: 36.72%] [G loss: 0.901113]\n",
      "epoch:17 step:13564[D loss: 0.464633, acc: 53.91%, op_acc: 42.19%] [G loss: 0.953724]\n",
      "epoch:17 step:13565[D loss: 0.430908, acc: 55.47%, op_acc: 46.88%] [G loss: 0.850776]\n",
      "epoch:17 step:13566[D loss: 0.451111, acc: 56.25%, op_acc: 35.16%] [G loss: 0.875776]\n",
      "epoch:17 step:13567[D loss: 0.413349, acc: 57.03%, op_acc: 42.97%] [G loss: 0.896487]\n",
      "epoch:17 step:13568[D loss: 0.440369, acc: 55.47%, op_acc: 36.72%] [G loss: 0.845755]\n",
      "epoch:17 step:13569[D loss: 0.425390, acc: 58.59%, op_acc: 37.50%] [G loss: 0.844720]\n",
      "epoch:17 step:13570[D loss: 0.434992, acc: 58.59%, op_acc: 37.50%] [G loss: 0.827808]\n",
      "epoch:17 step:13571[D loss: 0.397831, acc: 66.41%, op_acc: 38.28%] [G loss: 0.805209]\n",
      "epoch:17 step:13572[D loss: 0.440075, acc: 50.00%, op_acc: 39.06%] [G loss: 0.855622]\n",
      "epoch:17 step:13573[D loss: 0.425366, acc: 56.25%, op_acc: 42.19%] [G loss: 0.789042]\n",
      "epoch:17 step:13574[D loss: 0.455580, acc: 57.03%, op_acc: 27.34%] [G loss: 0.952559]\n",
      "epoch:17 step:13575[D loss: 0.432355, acc: 57.03%, op_acc: 34.38%] [G loss: 0.894499]\n",
      "epoch:17 step:13576[D loss: 0.444785, acc: 59.38%, op_acc: 36.72%] [G loss: 0.919643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13577[D loss: 0.440151, acc: 58.59%, op_acc: 36.72%] [G loss: 0.929316]\n",
      "epoch:17 step:13578[D loss: 0.412595, acc: 57.81%, op_acc: 41.41%] [G loss: 0.858448]\n",
      "epoch:17 step:13579[D loss: 0.436432, acc: 59.38%, op_acc: 33.59%] [G loss: 0.986724]\n",
      "epoch:17 step:13580[D loss: 0.450152, acc: 53.91%, op_acc: 35.16%] [G loss: 0.865276]\n",
      "epoch:17 step:13581[D loss: 0.433031, acc: 57.81%, op_acc: 35.94%] [G loss: 0.933225]\n",
      "epoch:17 step:13582[D loss: 0.408760, acc: 61.72%, op_acc: 42.19%] [G loss: 0.877240]\n",
      "epoch:17 step:13583[D loss: 0.441181, acc: 67.19%, op_acc: 37.50%] [G loss: 0.902001]\n",
      "epoch:17 step:13584[D loss: 0.415537, acc: 63.28%, op_acc: 38.28%] [G loss: 0.953043]\n",
      "epoch:17 step:13585[D loss: 0.405572, acc: 67.97%, op_acc: 42.97%] [G loss: 0.852394]\n",
      "epoch:17 step:13586[D loss: 0.440851, acc: 59.38%, op_acc: 36.72%] [G loss: 0.957359]\n",
      "epoch:17 step:13587[D loss: 0.416702, acc: 63.28%, op_acc: 36.72%] [G loss: 0.922292]\n",
      "epoch:17 step:13588[D loss: 0.448589, acc: 50.00%, op_acc: 33.59%] [G loss: 0.840491]\n",
      "epoch:17 step:13589[D loss: 0.470531, acc: 49.22%, op_acc: 32.81%] [G loss: 0.882166]\n",
      "epoch:17 step:13590[D loss: 0.448095, acc: 53.91%, op_acc: 41.41%] [G loss: 0.832068]\n",
      "epoch:17 step:13591[D loss: 0.450749, acc: 54.69%, op_acc: 35.16%] [G loss: 0.860879]\n",
      "epoch:17 step:13592[D loss: 0.431169, acc: 58.59%, op_acc: 39.06%] [G loss: 0.869220]\n",
      "epoch:17 step:13593[D loss: 0.422271, acc: 56.25%, op_acc: 42.19%] [G loss: 0.882136]\n",
      "epoch:17 step:13594[D loss: 0.429824, acc: 63.28%, op_acc: 38.28%] [G loss: 0.819845]\n",
      "epoch:17 step:13595[D loss: 0.466054, acc: 55.47%, op_acc: 30.47%] [G loss: 0.856784]\n",
      "epoch:17 step:13596[D loss: 0.458346, acc: 49.22%, op_acc: 36.72%] [G loss: 0.840481]\n",
      "epoch:17 step:13597[D loss: 0.416625, acc: 64.84%, op_acc: 36.72%] [G loss: 0.737351]\n",
      "epoch:17 step:13598[D loss: 0.442316, acc: 58.59%, op_acc: 32.81%] [G loss: 0.917992]\n",
      "epoch:17 step:13599[D loss: 0.442426, acc: 57.03%, op_acc: 36.72%] [G loss: 0.862269]\n",
      "epoch:17 step:13600[D loss: 0.425381, acc: 61.72%, op_acc: 37.50%] [G loss: 0.844193]\n",
      "##############\n",
      "[0.86608537 0.86788393 0.79984983 0.82551079 0.78656555 0.82223091\n",
      " 0.87306744 0.80074141 0.79468374 0.80751399]\n",
      "##########\n",
      "epoch:17 step:13601[D loss: 0.424464, acc: 58.59%, op_acc: 34.38%] [G loss: 0.947576]\n",
      "epoch:17 step:13602[D loss: 0.422955, acc: 60.16%, op_acc: 37.50%] [G loss: 0.888028]\n",
      "epoch:17 step:13603[D loss: 0.428120, acc: 57.81%, op_acc: 39.06%] [G loss: 0.781585]\n",
      "epoch:17 step:13604[D loss: 0.412852, acc: 64.84%, op_acc: 41.41%] [G loss: 0.836121]\n",
      "epoch:17 step:13605[D loss: 0.471588, acc: 58.59%, op_acc: 39.06%] [G loss: 0.859869]\n",
      "epoch:17 step:13606[D loss: 0.444761, acc: 53.91%, op_acc: 36.72%] [G loss: 0.776736]\n",
      "epoch:17 step:13607[D loss: 0.409215, acc: 61.72%, op_acc: 40.62%] [G loss: 0.916052]\n",
      "epoch:17 step:13608[D loss: 0.440034, acc: 54.69%, op_acc: 39.84%] [G loss: 0.865624]\n",
      "epoch:17 step:13609[D loss: 0.455928, acc: 53.12%, op_acc: 38.28%] [G loss: 0.876368]\n",
      "epoch:17 step:13610[D loss: 0.448648, acc: 57.03%, op_acc: 38.28%] [G loss: 0.837633]\n",
      "epoch:17 step:13611[D loss: 0.426955, acc: 58.59%, op_acc: 38.28%] [G loss: 0.911413]\n",
      "epoch:17 step:13612[D loss: 0.429368, acc: 65.62%, op_acc: 35.16%] [G loss: 0.838829]\n",
      "epoch:17 step:13613[D loss: 0.441956, acc: 62.50%, op_acc: 39.06%] [G loss: 0.889783]\n",
      "epoch:17 step:13614[D loss: 0.442585, acc: 63.28%, op_acc: 32.03%] [G loss: 0.915849]\n",
      "epoch:17 step:13615[D loss: 0.403670, acc: 60.16%, op_acc: 42.19%] [G loss: 0.894421]\n",
      "epoch:17 step:13616[D loss: 0.427798, acc: 57.03%, op_acc: 37.50%] [G loss: 0.866364]\n",
      "epoch:17 step:13617[D loss: 0.404045, acc: 65.62%, op_acc: 38.28%] [G loss: 0.937794]\n",
      "epoch:17 step:13618[D loss: 0.442326, acc: 63.28%, op_acc: 38.28%] [G loss: 0.879095]\n",
      "epoch:17 step:13619[D loss: 0.447232, acc: 57.03%, op_acc: 34.38%] [G loss: 0.863590]\n",
      "epoch:17 step:13620[D loss: 0.447174, acc: 61.72%, op_acc: 35.94%] [G loss: 0.874107]\n",
      "epoch:17 step:13621[D loss: 0.456507, acc: 50.00%, op_acc: 30.47%] [G loss: 0.936769]\n",
      "epoch:17 step:13622[D loss: 0.439459, acc: 60.16%, op_acc: 35.16%] [G loss: 0.968901]\n",
      "epoch:17 step:13623[D loss: 0.425606, acc: 60.16%, op_acc: 35.16%] [G loss: 0.902076]\n",
      "epoch:17 step:13624[D loss: 0.418518, acc: 60.94%, op_acc: 41.41%] [G loss: 0.881633]\n",
      "epoch:17 step:13625[D loss: 0.431623, acc: 50.00%, op_acc: 31.25%] [G loss: 0.822788]\n",
      "epoch:17 step:13626[D loss: 0.428039, acc: 64.06%, op_acc: 35.16%] [G loss: 0.839555]\n",
      "epoch:17 step:13627[D loss: 0.431394, acc: 62.50%, op_acc: 35.94%] [G loss: 0.884475]\n",
      "epoch:17 step:13628[D loss: 0.442137, acc: 65.62%, op_acc: 35.16%] [G loss: 0.941878]\n",
      "epoch:17 step:13629[D loss: 0.429051, acc: 65.62%, op_acc: 32.81%] [G loss: 0.820444]\n",
      "epoch:17 step:13630[D loss: 0.418969, acc: 54.69%, op_acc: 39.84%] [G loss: 0.843321]\n",
      "epoch:17 step:13631[D loss: 0.453497, acc: 57.81%, op_acc: 36.72%] [G loss: 0.909072]\n",
      "epoch:17 step:13632[D loss: 0.419769, acc: 58.59%, op_acc: 38.28%] [G loss: 0.841688]\n",
      "epoch:17 step:13633[D loss: 0.403913, acc: 60.94%, op_acc: 37.50%] [G loss: 0.905581]\n",
      "epoch:17 step:13634[D loss: 0.460425, acc: 54.69%, op_acc: 37.50%] [G loss: 0.874966]\n",
      "epoch:17 step:13635[D loss: 0.437086, acc: 63.28%, op_acc: 39.06%] [G loss: 0.838420]\n",
      "epoch:17 step:13636[D loss: 0.429572, acc: 61.72%, op_acc: 36.72%] [G loss: 0.830015]\n",
      "epoch:17 step:13637[D loss: 0.425012, acc: 60.16%, op_acc: 39.06%] [G loss: 0.937080]\n",
      "epoch:17 step:13638[D loss: 0.413088, acc: 63.28%, op_acc: 39.06%] [G loss: 0.880008]\n",
      "epoch:17 step:13639[D loss: 0.403774, acc: 64.84%, op_acc: 38.28%] [G loss: 0.820574]\n",
      "epoch:17 step:13640[D loss: 0.442433, acc: 53.12%, op_acc: 39.06%] [G loss: 0.869058]\n",
      "epoch:17 step:13641[D loss: 0.425320, acc: 59.38%, op_acc: 39.84%] [G loss: 0.880193]\n",
      "epoch:17 step:13642[D loss: 0.397545, acc: 61.72%, op_acc: 41.41%] [G loss: 0.898763]\n",
      "epoch:17 step:13643[D loss: 0.411401, acc: 62.50%, op_acc: 38.28%] [G loss: 0.947893]\n",
      "epoch:17 step:13644[D loss: 0.437625, acc: 64.06%, op_acc: 35.94%] [G loss: 0.834079]\n",
      "epoch:17 step:13645[D loss: 0.413953, acc: 67.97%, op_acc: 39.84%] [G loss: 0.911988]\n",
      "epoch:17 step:13646[D loss: 0.415174, acc: 62.50%, op_acc: 41.41%] [G loss: 0.895539]\n",
      "epoch:17 step:13647[D loss: 0.415992, acc: 57.81%, op_acc: 34.38%] [G loss: 0.876887]\n",
      "epoch:17 step:13648[D loss: 0.411868, acc: 58.59%, op_acc: 44.53%] [G loss: 0.973438]\n",
      "epoch:17 step:13649[D loss: 0.411896, acc: 65.62%, op_acc: 38.28%] [G loss: 0.876474]\n",
      "epoch:17 step:13650[D loss: 0.399967, acc: 67.19%, op_acc: 39.84%] [G loss: 0.956158]\n",
      "##############\n",
      "[0.86414376 0.84786633 0.8230479  0.81069555 0.75924144 0.81940777\n",
      " 0.88637933 0.82810114 0.8199932  0.84229239]\n",
      "##########\n",
      "epoch:17 step:13651[D loss: 0.442887, acc: 57.81%, op_acc: 39.06%] [G loss: 0.916273]\n",
      "epoch:17 step:13652[D loss: 0.427754, acc: 59.38%, op_acc: 41.41%] [G loss: 0.963054]\n",
      "epoch:17 step:13653[D loss: 0.452379, acc: 54.69%, op_acc: 36.72%] [G loss: 0.863587]\n",
      "epoch:17 step:13654[D loss: 0.456083, acc: 54.69%, op_acc: 34.38%] [G loss: 0.827055]\n",
      "epoch:17 step:13655[D loss: 0.413599, acc: 61.72%, op_acc: 43.75%] [G loss: 0.879980]\n",
      "epoch:17 step:13656[D loss: 0.424706, acc: 57.03%, op_acc: 42.19%] [G loss: 0.796705]\n",
      "epoch:17 step:13657[D loss: 0.396931, acc: 69.53%, op_acc: 36.72%] [G loss: 0.952717]\n",
      "epoch:17 step:13658[D loss: 0.426822, acc: 56.25%, op_acc: 37.50%] [G loss: 0.940025]\n",
      "epoch:17 step:13659[D loss: 0.418068, acc: 64.84%, op_acc: 39.06%] [G loss: 0.878024]\n",
      "epoch:17 step:13660[D loss: 0.387579, acc: 64.84%, op_acc: 46.09%] [G loss: 0.885881]\n",
      "epoch:17 step:13661[D loss: 0.427358, acc: 58.59%, op_acc: 37.50%] [G loss: 0.818325]\n",
      "epoch:17 step:13662[D loss: 0.419247, acc: 62.50%, op_acc: 39.06%] [G loss: 0.929493]\n",
      "epoch:17 step:13663[D loss: 0.426152, acc: 62.50%, op_acc: 39.84%] [G loss: 0.881077]\n",
      "epoch:17 step:13664[D loss: 0.429678, acc: 63.28%, op_acc: 35.94%] [G loss: 0.924113]\n",
      "epoch:17 step:13665[D loss: 0.449913, acc: 61.72%, op_acc: 34.38%] [G loss: 0.908263]\n",
      "epoch:17 step:13666[D loss: 0.461744, acc: 49.22%, op_acc: 40.62%] [G loss: 0.853938]\n",
      "epoch:17 step:13667[D loss: 0.426911, acc: 53.91%, op_acc: 39.06%] [G loss: 0.846056]\n",
      "epoch:17 step:13668[D loss: 0.423722, acc: 61.72%, op_acc: 37.50%] [G loss: 0.914960]\n",
      "epoch:17 step:13669[D loss: 0.402473, acc: 65.62%, op_acc: 39.06%] [G loss: 0.899406]\n",
      "epoch:17 step:13670[D loss: 0.445929, acc: 55.47%, op_acc: 42.19%] [G loss: 0.894540]\n",
      "epoch:17 step:13671[D loss: 0.404181, acc: 68.75%, op_acc: 35.94%] [G loss: 0.956760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13672[D loss: 0.417591, acc: 64.06%, op_acc: 37.50%] [G loss: 0.962229]\n",
      "epoch:17 step:13673[D loss: 0.441927, acc: 52.34%, op_acc: 39.06%] [G loss: 0.858855]\n",
      "epoch:17 step:13674[D loss: 0.418035, acc: 63.28%, op_acc: 37.50%] [G loss: 0.886174]\n",
      "epoch:17 step:13675[D loss: 0.446994, acc: 62.50%, op_acc: 38.28%] [G loss: 0.857884]\n",
      "epoch:17 step:13676[D loss: 0.429991, acc: 55.47%, op_acc: 37.50%] [G loss: 0.927233]\n",
      "epoch:17 step:13677[D loss: 0.417827, acc: 62.50%, op_acc: 40.62%] [G loss: 0.878317]\n",
      "epoch:17 step:13678[D loss: 0.409898, acc: 64.06%, op_acc: 47.66%] [G loss: 0.895517]\n",
      "epoch:17 step:13679[D loss: 0.448332, acc: 54.69%, op_acc: 35.94%] [G loss: 0.967495]\n",
      "epoch:17 step:13680[D loss: 0.408521, acc: 64.06%, op_acc: 35.16%] [G loss: 0.923096]\n",
      "epoch:17 step:13681[D loss: 0.385079, acc: 65.62%, op_acc: 44.53%] [G loss: 0.915504]\n",
      "epoch:17 step:13682[D loss: 0.461684, acc: 51.56%, op_acc: 31.25%] [G loss: 0.809463]\n",
      "epoch:17 step:13683[D loss: 0.437416, acc: 52.34%, op_acc: 40.62%] [G loss: 0.834939]\n",
      "epoch:17 step:13684[D loss: 0.423950, acc: 57.81%, op_acc: 37.50%] [G loss: 0.909097]\n",
      "epoch:17 step:13685[D loss: 0.428972, acc: 51.56%, op_acc: 39.06%] [G loss: 0.865836]\n",
      "epoch:17 step:13686[D loss: 0.406935, acc: 66.41%, op_acc: 44.53%] [G loss: 0.926937]\n",
      "epoch:17 step:13687[D loss: 0.424934, acc: 53.91%, op_acc: 39.06%] [G loss: 0.842688]\n",
      "epoch:17 step:13688[D loss: 0.456653, acc: 53.91%, op_acc: 36.72%] [G loss: 0.823421]\n",
      "epoch:17 step:13689[D loss: 0.453384, acc: 49.22%, op_acc: 41.41%] [G loss: 0.857787]\n",
      "epoch:17 step:13690[D loss: 0.427647, acc: 56.25%, op_acc: 41.41%] [G loss: 0.892922]\n",
      "epoch:17 step:13691[D loss: 0.415027, acc: 57.81%, op_acc: 44.53%] [G loss: 0.920659]\n",
      "epoch:17 step:13692[D loss: 0.417069, acc: 60.94%, op_acc: 36.72%] [G loss: 0.931170]\n",
      "epoch:17 step:13693[D loss: 0.432174, acc: 63.28%, op_acc: 32.03%] [G loss: 0.871971]\n",
      "epoch:17 step:13694[D loss: 0.404785, acc: 68.75%, op_acc: 42.19%] [G loss: 0.859725]\n",
      "epoch:17 step:13695[D loss: 0.420803, acc: 60.94%, op_acc: 36.72%] [G loss: 0.919321]\n",
      "epoch:17 step:13696[D loss: 0.454449, acc: 57.81%, op_acc: 38.28%] [G loss: 0.893901]\n",
      "epoch:17 step:13697[D loss: 0.427584, acc: 60.16%, op_acc: 36.72%] [G loss: 0.929198]\n",
      "epoch:17 step:13698[D loss: 0.444736, acc: 53.91%, op_acc: 40.62%] [G loss: 0.880394]\n",
      "epoch:17 step:13699[D loss: 0.418308, acc: 61.72%, op_acc: 43.75%] [G loss: 0.959165]\n",
      "epoch:17 step:13700[D loss: 0.432011, acc: 65.62%, op_acc: 32.03%] [G loss: 0.887147]\n",
      "##############\n",
      "[0.87327382 0.82082021 0.82213551 0.7957161  0.79694282 0.81371063\n",
      " 0.88079615 0.85361172 0.80108553 0.8108686 ]\n",
      "##########\n",
      "epoch:17 step:13701[D loss: 0.436665, acc: 58.59%, op_acc: 35.94%] [G loss: 0.863147]\n",
      "epoch:17 step:13702[D loss: 0.432395, acc: 57.81%, op_acc: 39.84%] [G loss: 0.921634]\n",
      "epoch:17 step:13703[D loss: 0.447385, acc: 54.69%, op_acc: 35.16%] [G loss: 0.915180]\n",
      "epoch:17 step:13704[D loss: 0.420618, acc: 58.59%, op_acc: 35.16%] [G loss: 0.916327]\n",
      "epoch:17 step:13705[D loss: 0.432583, acc: 55.47%, op_acc: 40.62%] [G loss: 0.930163]\n",
      "epoch:17 step:13706[D loss: 0.460689, acc: 52.34%, op_acc: 39.84%] [G loss: 0.891522]\n",
      "epoch:17 step:13707[D loss: 0.436406, acc: 56.25%, op_acc: 34.38%] [G loss: 0.913023]\n",
      "epoch:17 step:13708[D loss: 0.420651, acc: 61.72%, op_acc: 35.94%] [G loss: 0.871325]\n",
      "epoch:17 step:13709[D loss: 0.410908, acc: 58.59%, op_acc: 40.62%] [G loss: 0.834774]\n",
      "epoch:17 step:13710[D loss: 0.428182, acc: 60.16%, op_acc: 40.62%] [G loss: 0.847210]\n",
      "epoch:17 step:13711[D loss: 0.419104, acc: 58.59%, op_acc: 49.22%] [G loss: 0.832742]\n",
      "epoch:17 step:13712[D loss: 0.473103, acc: 46.09%, op_acc: 37.50%] [G loss: 0.827455]\n",
      "epoch:17 step:13713[D loss: 0.475241, acc: 50.78%, op_acc: 35.16%] [G loss: 0.905528]\n",
      "epoch:17 step:13714[D loss: 0.451743, acc: 51.56%, op_acc: 39.06%] [G loss: 0.916438]\n",
      "epoch:17 step:13715[D loss: 0.420180, acc: 61.72%, op_acc: 39.84%] [G loss: 0.901112]\n",
      "epoch:17 step:13716[D loss: 0.429098, acc: 58.59%, op_acc: 39.84%] [G loss: 0.852633]\n",
      "epoch:17 step:13717[D loss: 0.419590, acc: 64.84%, op_acc: 38.28%] [G loss: 0.974229]\n",
      "epoch:17 step:13718[D loss: 0.431411, acc: 54.69%, op_acc: 39.84%] [G loss: 0.844825]\n",
      "epoch:17 step:13719[D loss: 0.416703, acc: 60.94%, op_acc: 40.62%] [G loss: 0.864101]\n",
      "epoch:17 step:13720[D loss: 0.417855, acc: 64.84%, op_acc: 34.38%] [G loss: 0.789304]\n",
      "epoch:17 step:13721[D loss: 0.378623, acc: 68.75%, op_acc: 38.28%] [G loss: 0.919713]\n",
      "epoch:17 step:13722[D loss: 0.427394, acc: 57.03%, op_acc: 33.59%] [G loss: 0.903988]\n",
      "epoch:17 step:13723[D loss: 0.416676, acc: 67.19%, op_acc: 37.50%] [G loss: 0.857454]\n",
      "epoch:17 step:13724[D loss: 0.450099, acc: 56.25%, op_acc: 36.72%] [G loss: 0.861512]\n",
      "epoch:17 step:13725[D loss: 0.410754, acc: 60.16%, op_acc: 36.72%] [G loss: 0.869009]\n",
      "epoch:17 step:13726[D loss: 0.425836, acc: 61.72%, op_acc: 39.84%] [G loss: 0.883097]\n",
      "epoch:17 step:13727[D loss: 0.429297, acc: 64.06%, op_acc: 34.38%] [G loss: 0.880994]\n",
      "epoch:17 step:13728[D loss: 0.450530, acc: 53.12%, op_acc: 35.94%] [G loss: 0.922931]\n",
      "epoch:17 step:13729[D loss: 0.381384, acc: 66.41%, op_acc: 42.97%] [G loss: 0.941261]\n",
      "epoch:17 step:13730[D loss: 0.429227, acc: 49.22%, op_acc: 47.66%] [G loss: 0.870401]\n",
      "epoch:17 step:13731[D loss: 0.421302, acc: 62.50%, op_acc: 34.38%] [G loss: 0.905339]\n",
      "epoch:17 step:13732[D loss: 0.460356, acc: 52.34%, op_acc: 41.41%] [G loss: 0.881793]\n",
      "epoch:17 step:13733[D loss: 0.435482, acc: 55.47%, op_acc: 38.28%] [G loss: 0.904058]\n",
      "epoch:17 step:13734[D loss: 0.439022, acc: 58.59%, op_acc: 37.50%] [G loss: 0.869732]\n",
      "epoch:17 step:13735[D loss: 0.402457, acc: 61.72%, op_acc: 45.31%] [G loss: 0.846022]\n",
      "epoch:17 step:13736[D loss: 0.433814, acc: 59.38%, op_acc: 36.72%] [G loss: 0.830925]\n",
      "epoch:17 step:13737[D loss: 0.434592, acc: 57.03%, op_acc: 39.06%] [G loss: 0.919250]\n",
      "epoch:17 step:13738[D loss: 0.413827, acc: 71.09%, op_acc: 32.03%] [G loss: 0.881300]\n",
      "epoch:17 step:13739[D loss: 0.428303, acc: 62.50%, op_acc: 36.72%] [G loss: 0.916414]\n",
      "epoch:17 step:13740[D loss: 0.445459, acc: 50.00%, op_acc: 35.16%] [G loss: 0.849594]\n",
      "epoch:17 step:13741[D loss: 0.431944, acc: 58.59%, op_acc: 37.50%] [G loss: 0.846427]\n",
      "epoch:17 step:13742[D loss: 0.419371, acc: 60.94%, op_acc: 36.72%] [G loss: 0.934825]\n",
      "epoch:17 step:13743[D loss: 0.404642, acc: 62.50%, op_acc: 39.84%] [G loss: 0.899491]\n",
      "epoch:17 step:13744[D loss: 0.425591, acc: 62.50%, op_acc: 40.62%] [G loss: 0.896603]\n",
      "epoch:17 step:13745[D loss: 0.431595, acc: 57.81%, op_acc: 35.94%] [G loss: 0.838350]\n",
      "epoch:17 step:13746[D loss: 0.395676, acc: 66.41%, op_acc: 39.84%] [G loss: 0.908617]\n",
      "epoch:17 step:13747[D loss: 0.437515, acc: 59.38%, op_acc: 39.06%] [G loss: 0.859832]\n",
      "epoch:17 step:13748[D loss: 0.445922, acc: 57.81%, op_acc: 35.16%] [G loss: 0.880891]\n",
      "epoch:17 step:13749[D loss: 0.435651, acc: 58.59%, op_acc: 33.59%] [G loss: 0.858898]\n",
      "epoch:17 step:13750[D loss: 0.409430, acc: 67.19%, op_acc: 39.84%] [G loss: 0.865784]\n",
      "##############\n",
      "[0.86063175 0.85721706 0.80242367 0.79005242 0.78905319 0.84006459\n",
      " 0.90241676 0.8324146  0.79321397 0.84536764]\n",
      "##########\n",
      "epoch:17 step:13751[D loss: 0.409563, acc: 64.06%, op_acc: 39.06%] [G loss: 0.934415]\n",
      "epoch:17 step:13752[D loss: 0.447979, acc: 52.34%, op_acc: 36.72%] [G loss: 0.870149]\n",
      "epoch:17 step:13753[D loss: 0.455177, acc: 61.72%, op_acc: 34.38%] [G loss: 0.880881]\n",
      "epoch:17 step:13754[D loss: 0.440503, acc: 57.81%, op_acc: 41.41%] [G loss: 0.886762]\n",
      "epoch:17 step:13755[D loss: 0.419702, acc: 53.91%, op_acc: 40.62%] [G loss: 0.891634]\n",
      "epoch:17 step:13756[D loss: 0.429850, acc: 60.16%, op_acc: 39.84%] [G loss: 0.950693]\n",
      "epoch:17 step:13757[D loss: 0.451004, acc: 55.47%, op_acc: 33.59%] [G loss: 0.852385]\n",
      "epoch:17 step:13758[D loss: 0.467250, acc: 53.91%, op_acc: 32.81%] [G loss: 0.934426]\n",
      "epoch:17 step:13759[D loss: 0.474837, acc: 58.59%, op_acc: 32.81%] [G loss: 0.807977]\n",
      "epoch:17 step:13760[D loss: 0.420829, acc: 60.16%, op_acc: 36.72%] [G loss: 0.928399]\n",
      "epoch:17 step:13761[D loss: 0.406791, acc: 66.41%, op_acc: 38.28%] [G loss: 0.925016]\n",
      "epoch:17 step:13762[D loss: 0.434015, acc: 59.38%, op_acc: 39.06%] [G loss: 0.822380]\n",
      "epoch:17 step:13763[D loss: 0.415605, acc: 55.47%, op_acc: 43.75%] [G loss: 0.890990]\n",
      "epoch:17 step:13764[D loss: 0.416836, acc: 61.72%, op_acc: 34.38%] [G loss: 0.852010]\n",
      "epoch:17 step:13765[D loss: 0.429630, acc: 61.72%, op_acc: 34.38%] [G loss: 0.779655]\n",
      "epoch:17 step:13766[D loss: 0.423241, acc: 57.81%, op_acc: 42.97%] [G loss: 0.956948]\n",
      "epoch:17 step:13767[D loss: 0.406087, acc: 57.03%, op_acc: 41.41%] [G loss: 0.908192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13768[D loss: 0.464829, acc: 57.81%, op_acc: 33.59%] [G loss: 0.849135]\n",
      "epoch:17 step:13769[D loss: 0.449236, acc: 48.44%, op_acc: 39.84%] [G loss: 0.966092]\n",
      "epoch:17 step:13770[D loss: 0.427656, acc: 61.72%, op_acc: 33.59%] [G loss: 0.877751]\n",
      "epoch:17 step:13771[D loss: 0.410881, acc: 58.59%, op_acc: 40.62%] [G loss: 0.805079]\n",
      "epoch:17 step:13772[D loss: 0.436424, acc: 55.47%, op_acc: 36.72%] [G loss: 0.879924]\n",
      "epoch:17 step:13773[D loss: 0.416700, acc: 69.53%, op_acc: 33.59%] [G loss: 0.909202]\n",
      "epoch:17 step:13774[D loss: 0.396227, acc: 68.75%, op_acc: 39.06%] [G loss: 0.827601]\n",
      "epoch:17 step:13775[D loss: 0.415162, acc: 65.62%, op_acc: 35.94%] [G loss: 0.895364]\n",
      "epoch:17 step:13776[D loss: 0.413373, acc: 71.09%, op_acc: 35.16%] [G loss: 0.887790]\n",
      "epoch:17 step:13777[D loss: 0.412489, acc: 60.94%, op_acc: 37.50%] [G loss: 0.956826]\n",
      "epoch:17 step:13778[D loss: 0.452414, acc: 56.25%, op_acc: 37.50%] [G loss: 0.845614]\n",
      "epoch:17 step:13779[D loss: 0.440673, acc: 50.00%, op_acc: 39.06%] [G loss: 0.927651]\n",
      "epoch:17 step:13780[D loss: 0.414034, acc: 64.84%, op_acc: 38.28%] [G loss: 0.881690]\n",
      "epoch:17 step:13781[D loss: 0.448407, acc: 57.03%, op_acc: 32.81%] [G loss: 0.890405]\n",
      "epoch:17 step:13782[D loss: 0.443935, acc: 57.81%, op_acc: 37.50%] [G loss: 0.867244]\n",
      "epoch:17 step:13783[D loss: 0.431934, acc: 60.94%, op_acc: 36.72%] [G loss: 0.919939]\n",
      "epoch:17 step:13784[D loss: 0.417077, acc: 53.12%, op_acc: 40.62%] [G loss: 0.908475]\n",
      "epoch:17 step:13785[D loss: 0.430697, acc: 56.25%, op_acc: 43.75%] [G loss: 0.939473]\n",
      "epoch:17 step:13786[D loss: 0.438370, acc: 56.25%, op_acc: 35.16%] [G loss: 0.941286]\n",
      "epoch:17 step:13787[D loss: 0.410043, acc: 66.41%, op_acc: 40.62%] [G loss: 0.948034]\n",
      "epoch:17 step:13788[D loss: 0.401188, acc: 64.84%, op_acc: 42.19%] [G loss: 1.027706]\n",
      "epoch:17 step:13789[D loss: 0.445123, acc: 59.38%, op_acc: 36.72%] [G loss: 0.892072]\n",
      "epoch:17 step:13790[D loss: 0.434306, acc: 64.84%, op_acc: 37.50%] [G loss: 0.913033]\n",
      "epoch:17 step:13791[D loss: 0.451814, acc: 54.69%, op_acc: 31.25%] [G loss: 0.802614]\n",
      "epoch:17 step:13792[D loss: 0.438097, acc: 58.59%, op_acc: 37.50%] [G loss: 0.859146]\n",
      "epoch:17 step:13793[D loss: 0.448923, acc: 55.47%, op_acc: 37.50%] [G loss: 0.787628]\n",
      "epoch:17 step:13794[D loss: 0.441539, acc: 57.03%, op_acc: 36.72%] [G loss: 0.876670]\n",
      "epoch:17 step:13795[D loss: 0.386775, acc: 64.06%, op_acc: 39.06%] [G loss: 0.864864]\n",
      "epoch:17 step:13796[D loss: 0.401213, acc: 67.19%, op_acc: 40.62%] [G loss: 0.941369]\n",
      "epoch:17 step:13797[D loss: 0.410890, acc: 58.59%, op_acc: 41.41%] [G loss: 0.845893]\n",
      "epoch:17 step:13798[D loss: 0.431570, acc: 59.38%, op_acc: 35.16%] [G loss: 0.890433]\n",
      "epoch:17 step:13799[D loss: 0.442639, acc: 56.25%, op_acc: 37.50%] [G loss: 0.819800]\n",
      "epoch:17 step:13800[D loss: 0.414722, acc: 63.28%, op_acc: 36.72%] [G loss: 0.901177]\n",
      "##############\n",
      "[0.84651433 0.86751361 0.80894372 0.80665989 0.79411715 0.82912751\n",
      " 0.8621574  0.82482055 0.82967395 0.84827588]\n",
      "##########\n",
      "epoch:17 step:13801[D loss: 0.403837, acc: 69.53%, op_acc: 39.06%] [G loss: 0.885756]\n",
      "epoch:17 step:13802[D loss: 0.409687, acc: 68.75%, op_acc: 34.38%] [G loss: 0.849459]\n",
      "epoch:17 step:13803[D loss: 0.461566, acc: 53.12%, op_acc: 33.59%] [G loss: 0.849819]\n",
      "epoch:17 step:13804[D loss: 0.455249, acc: 50.00%, op_acc: 38.28%] [G loss: 0.785511]\n",
      "epoch:17 step:13805[D loss: 0.445024, acc: 60.94%, op_acc: 33.59%] [G loss: 0.935557]\n",
      "epoch:17 step:13806[D loss: 0.404667, acc: 64.06%, op_acc: 37.50%] [G loss: 0.902088]\n",
      "epoch:17 step:13807[D loss: 0.442476, acc: 55.47%, op_acc: 34.38%] [G loss: 0.846575]\n",
      "epoch:17 step:13808[D loss: 0.474184, acc: 50.78%, op_acc: 29.69%] [G loss: 0.908675]\n",
      "epoch:17 step:13809[D loss: 0.443257, acc: 57.81%, op_acc: 39.06%] [G loss: 0.880970]\n",
      "epoch:17 step:13810[D loss: 0.448583, acc: 54.69%, op_acc: 37.50%] [G loss: 0.864760]\n",
      "epoch:17 step:13811[D loss: 0.406096, acc: 62.50%, op_acc: 46.09%] [G loss: 0.890451]\n",
      "epoch:17 step:13812[D loss: 0.423182, acc: 57.81%, op_acc: 39.06%] [G loss: 0.940056]\n",
      "epoch:17 step:13813[D loss: 0.412245, acc: 59.38%, op_acc: 46.09%] [G loss: 0.943413]\n",
      "epoch:17 step:13814[D loss: 0.457712, acc: 60.94%, op_acc: 32.81%] [G loss: 1.033050]\n",
      "epoch:17 step:13815[D loss: 0.418046, acc: 57.03%, op_acc: 40.62%] [G loss: 0.850127]\n",
      "epoch:17 step:13816[D loss: 0.426688, acc: 63.28%, op_acc: 36.72%] [G loss: 0.992386]\n",
      "epoch:17 step:13817[D loss: 0.392247, acc: 64.84%, op_acc: 40.62%] [G loss: 0.918545]\n",
      "epoch:17 step:13818[D loss: 0.398585, acc: 61.72%, op_acc: 43.75%] [G loss: 0.897805]\n",
      "epoch:17 step:13819[D loss: 0.446353, acc: 57.81%, op_acc: 34.38%] [G loss: 0.821785]\n",
      "epoch:17 step:13820[D loss: 0.448117, acc: 51.56%, op_acc: 34.38%] [G loss: 0.819033]\n",
      "epoch:17 step:13821[D loss: 0.417231, acc: 62.50%, op_acc: 39.06%] [G loss: 0.898355]\n",
      "epoch:17 step:13822[D loss: 0.429607, acc: 60.16%, op_acc: 35.16%] [G loss: 0.872767]\n",
      "epoch:17 step:13823[D loss: 0.431599, acc: 58.59%, op_acc: 39.06%] [G loss: 0.877939]\n",
      "epoch:17 step:13824[D loss: 0.440962, acc: 59.38%, op_acc: 35.16%] [G loss: 0.897884]\n",
      "epoch:17 step:13825[D loss: 0.433342, acc: 63.28%, op_acc: 39.06%] [G loss: 0.929394]\n",
      "epoch:17 step:13826[D loss: 0.443612, acc: 54.69%, op_acc: 39.84%] [G loss: 0.878382]\n",
      "epoch:17 step:13827[D loss: 0.426070, acc: 63.28%, op_acc: 37.50%] [G loss: 0.923145]\n",
      "epoch:17 step:13828[D loss: 0.438377, acc: 57.81%, op_acc: 41.41%] [G loss: 0.930182]\n",
      "epoch:17 step:13829[D loss: 0.462653, acc: 51.56%, op_acc: 37.50%] [G loss: 0.801697]\n",
      "epoch:17 step:13830[D loss: 0.431417, acc: 59.38%, op_acc: 33.59%] [G loss: 0.909469]\n",
      "epoch:17 step:13831[D loss: 0.430168, acc: 59.38%, op_acc: 37.50%] [G loss: 0.891725]\n",
      "epoch:17 step:13832[D loss: 0.428124, acc: 56.25%, op_acc: 44.53%] [G loss: 0.880728]\n",
      "epoch:17 step:13833[D loss: 0.419349, acc: 60.94%, op_acc: 40.62%] [G loss: 0.798668]\n",
      "epoch:17 step:13834[D loss: 0.454777, acc: 52.34%, op_acc: 36.72%] [G loss: 0.907491]\n",
      "epoch:17 step:13835[D loss: 0.401868, acc: 61.72%, op_acc: 39.06%] [G loss: 0.885552]\n",
      "epoch:17 step:13836[D loss: 0.408573, acc: 60.94%, op_acc: 38.28%] [G loss: 0.781861]\n",
      "epoch:17 step:13837[D loss: 0.424087, acc: 59.38%, op_acc: 35.16%] [G loss: 0.824991]\n",
      "epoch:17 step:13838[D loss: 0.415208, acc: 60.94%, op_acc: 40.62%] [G loss: 0.863771]\n",
      "epoch:17 step:13839[D loss: 0.430843, acc: 60.16%, op_acc: 37.50%] [G loss: 0.847938]\n",
      "epoch:17 step:13840[D loss: 0.433328, acc: 61.72%, op_acc: 36.72%] [G loss: 0.947694]\n",
      "epoch:17 step:13841[D loss: 0.436982, acc: 57.81%, op_acc: 31.25%] [G loss: 0.870342]\n",
      "epoch:17 step:13842[D loss: 0.424306, acc: 63.28%, op_acc: 35.94%] [G loss: 0.910009]\n",
      "epoch:17 step:13843[D loss: 0.422292, acc: 62.50%, op_acc: 39.06%] [G loss: 0.912632]\n",
      "epoch:17 step:13844[D loss: 0.423227, acc: 61.72%, op_acc: 40.62%] [G loss: 0.890886]\n",
      "epoch:17 step:13845[D loss: 0.420293, acc: 60.94%, op_acc: 39.06%] [G loss: 0.920354]\n",
      "epoch:17 step:13846[D loss: 0.426600, acc: 60.94%, op_acc: 35.94%] [G loss: 0.848534]\n",
      "epoch:17 step:13847[D loss: 0.410638, acc: 64.06%, op_acc: 38.28%] [G loss: 0.866458]\n",
      "epoch:17 step:13848[D loss: 0.409727, acc: 60.16%, op_acc: 40.62%] [G loss: 0.847377]\n",
      "epoch:17 step:13849[D loss: 0.449904, acc: 53.12%, op_acc: 39.06%] [G loss: 0.855050]\n",
      "epoch:17 step:13850[D loss: 0.431232, acc: 57.81%, op_acc: 40.62%] [G loss: 0.893655]\n",
      "##############\n",
      "[0.85373111 0.8517946  0.8137075  0.8075017  0.79367243 0.83282382\n",
      " 0.86746803 0.82347469 0.81526744 0.8284562 ]\n",
      "##########\n",
      "epoch:17 step:13851[D loss: 0.430089, acc: 58.59%, op_acc: 34.38%] [G loss: 0.811250]\n",
      "epoch:17 step:13852[D loss: 0.455998, acc: 57.03%, op_acc: 33.59%] [G loss: 0.826174]\n",
      "epoch:17 step:13853[D loss: 0.444180, acc: 58.59%, op_acc: 37.50%] [G loss: 0.940792]\n",
      "epoch:17 step:13854[D loss: 0.416973, acc: 63.28%, op_acc: 34.38%] [G loss: 0.886876]\n",
      "epoch:17 step:13855[D loss: 0.441862, acc: 56.25%, op_acc: 38.28%] [G loss: 0.929884]\n",
      "epoch:17 step:13856[D loss: 0.409407, acc: 56.25%, op_acc: 43.75%] [G loss: 0.884412]\n",
      "epoch:17 step:13857[D loss: 0.452969, acc: 50.78%, op_acc: 39.84%] [G loss: 0.849347]\n",
      "epoch:17 step:13858[D loss: 0.452719, acc: 60.16%, op_acc: 32.03%] [G loss: 0.811340]\n",
      "epoch:17 step:13859[D loss: 0.422087, acc: 64.84%, op_acc: 37.50%] [G loss: 0.940554]\n",
      "epoch:17 step:13860[D loss: 0.435186, acc: 57.03%, op_acc: 37.50%] [G loss: 0.879389]\n",
      "epoch:17 step:13861[D loss: 0.426801, acc: 67.97%, op_acc: 34.38%] [G loss: 0.896736]\n",
      "epoch:17 step:13862[D loss: 0.398059, acc: 63.28%, op_acc: 39.84%] [G loss: 0.910387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13863[D loss: 0.424305, acc: 64.84%, op_acc: 37.50%] [G loss: 0.975456]\n",
      "epoch:17 step:13864[D loss: 0.410613, acc: 64.06%, op_acc: 35.94%] [G loss: 0.868961]\n",
      "epoch:17 step:13865[D loss: 0.428078, acc: 58.59%, op_acc: 39.84%] [G loss: 0.933020]\n",
      "epoch:17 step:13866[D loss: 0.432379, acc: 60.16%, op_acc: 37.50%] [G loss: 0.954235]\n",
      "epoch:17 step:13867[D loss: 0.433881, acc: 55.47%, op_acc: 39.06%] [G loss: 0.969272]\n",
      "epoch:17 step:13868[D loss: 0.429502, acc: 56.25%, op_acc: 39.06%] [G loss: 0.904646]\n",
      "epoch:17 step:13869[D loss: 0.430548, acc: 57.03%, op_acc: 36.72%] [G loss: 0.903338]\n",
      "epoch:17 step:13870[D loss: 0.440089, acc: 61.72%, op_acc: 33.59%] [G loss: 0.924956]\n",
      "epoch:17 step:13871[D loss: 0.468485, acc: 51.56%, op_acc: 35.94%] [G loss: 0.810856]\n",
      "epoch:17 step:13872[D loss: 0.401949, acc: 67.97%, op_acc: 39.06%] [G loss: 0.947284]\n",
      "epoch:17 step:13873[D loss: 0.449746, acc: 47.66%, op_acc: 34.38%] [G loss: 0.897909]\n",
      "epoch:17 step:13874[D loss: 0.434010, acc: 60.94%, op_acc: 39.06%] [G loss: 0.868970]\n",
      "epoch:17 step:13875[D loss: 0.416806, acc: 67.97%, op_acc: 38.28%] [G loss: 0.926999]\n",
      "epoch:17 step:13876[D loss: 0.445423, acc: 55.47%, op_acc: 35.94%] [G loss: 0.912913]\n",
      "epoch:17 step:13877[D loss: 0.438044, acc: 55.47%, op_acc: 42.97%] [G loss: 0.860514]\n",
      "epoch:17 step:13878[D loss: 0.469070, acc: 50.00%, op_acc: 38.28%] [G loss: 0.879306]\n",
      "epoch:17 step:13879[D loss: 0.414697, acc: 58.59%, op_acc: 39.06%] [G loss: 0.838650]\n",
      "epoch:17 step:13880[D loss: 0.388545, acc: 64.84%, op_acc: 41.41%] [G loss: 0.821680]\n",
      "epoch:17 step:13881[D loss: 0.456239, acc: 57.03%, op_acc: 32.03%] [G loss: 0.889291]\n",
      "epoch:17 step:13882[D loss: 0.428342, acc: 59.38%, op_acc: 35.94%] [G loss: 0.886215]\n",
      "epoch:17 step:13883[D loss: 0.420717, acc: 58.59%, op_acc: 39.84%] [G loss: 0.868054]\n",
      "epoch:17 step:13884[D loss: 0.388159, acc: 62.50%, op_acc: 44.53%] [G loss: 0.935575]\n",
      "epoch:17 step:13885[D loss: 0.381114, acc: 69.53%, op_acc: 36.72%] [G loss: 0.996227]\n",
      "epoch:17 step:13886[D loss: 0.461554, acc: 53.91%, op_acc: 35.16%] [G loss: 0.843222]\n",
      "epoch:17 step:13887[D loss: 0.414936, acc: 64.84%, op_acc: 34.38%] [G loss: 0.905034]\n",
      "epoch:17 step:13888[D loss: 0.475665, acc: 51.56%, op_acc: 37.50%] [G loss: 0.879356]\n",
      "epoch:17 step:13889[D loss: 0.421517, acc: 58.59%, op_acc: 38.28%] [G loss: 0.918867]\n",
      "epoch:17 step:13890[D loss: 0.440620, acc: 55.47%, op_acc: 41.41%] [G loss: 0.883081]\n",
      "epoch:17 step:13891[D loss: 0.423153, acc: 60.94%, op_acc: 39.06%] [G loss: 0.896936]\n",
      "epoch:17 step:13892[D loss: 0.401786, acc: 64.06%, op_acc: 39.84%] [G loss: 0.913586]\n",
      "epoch:17 step:13893[D loss: 0.452913, acc: 50.78%, op_acc: 42.19%] [G loss: 0.902838]\n",
      "epoch:17 step:13894[D loss: 0.445795, acc: 58.59%, op_acc: 38.28%] [G loss: 0.879005]\n",
      "epoch:17 step:13895[D loss: 0.407067, acc: 61.72%, op_acc: 41.41%] [G loss: 0.876138]\n",
      "epoch:17 step:13896[D loss: 0.433866, acc: 57.03%, op_acc: 33.59%] [G loss: 0.968003]\n",
      "epoch:17 step:13897[D loss: 0.440481, acc: 59.38%, op_acc: 33.59%] [G loss: 0.959289]\n",
      "epoch:17 step:13898[D loss: 0.451512, acc: 55.47%, op_acc: 37.50%] [G loss: 0.871898]\n",
      "epoch:17 step:13899[D loss: 0.470971, acc: 57.81%, op_acc: 32.81%] [G loss: 0.886229]\n",
      "epoch:17 step:13900[D loss: 0.428993, acc: 57.03%, op_acc: 41.41%] [G loss: 0.910832]\n",
      "##############\n",
      "[0.85028615 0.83214224 0.80852675 0.80787867 0.78446534 0.82227659\n",
      " 0.8666098  0.83142126 0.82076047 0.83411333]\n",
      "##########\n",
      "epoch:17 step:13901[D loss: 0.469653, acc: 49.22%, op_acc: 37.50%] [G loss: 0.915730]\n",
      "epoch:17 step:13902[D loss: 0.451076, acc: 50.00%, op_acc: 37.50%] [G loss: 0.804450]\n",
      "epoch:17 step:13903[D loss: 0.410015, acc: 57.81%, op_acc: 44.53%] [G loss: 0.952176]\n",
      "epoch:17 step:13904[D loss: 0.445297, acc: 57.03%, op_acc: 35.94%] [G loss: 0.938884]\n",
      "epoch:17 step:13905[D loss: 0.429691, acc: 66.41%, op_acc: 34.38%] [G loss: 0.869930]\n",
      "epoch:17 step:13906[D loss: 0.457960, acc: 63.28%, op_acc: 28.91%] [G loss: 0.884857]\n",
      "epoch:17 step:13907[D loss: 0.428130, acc: 63.28%, op_acc: 38.28%] [G loss: 0.848812]\n",
      "epoch:17 step:13908[D loss: 0.458317, acc: 57.81%, op_acc: 33.59%] [G loss: 0.854876]\n",
      "epoch:17 step:13909[D loss: 0.450044, acc: 52.34%, op_acc: 35.16%] [G loss: 0.828943]\n",
      "epoch:17 step:13910[D loss: 0.447412, acc: 57.03%, op_acc: 39.84%] [G loss: 0.844445]\n",
      "epoch:17 step:13911[D loss: 0.431084, acc: 57.03%, op_acc: 35.94%] [G loss: 0.869457]\n",
      "epoch:17 step:13912[D loss: 0.464367, acc: 58.59%, op_acc: 33.59%] [G loss: 0.900391]\n",
      "epoch:17 step:13913[D loss: 0.414538, acc: 58.59%, op_acc: 42.19%] [G loss: 0.862532]\n",
      "epoch:17 step:13914[D loss: 0.441085, acc: 52.34%, op_acc: 44.53%] [G loss: 0.864439]\n",
      "epoch:17 step:13915[D loss: 0.451343, acc: 57.03%, op_acc: 32.81%] [G loss: 0.906948]\n",
      "epoch:17 step:13916[D loss: 0.443257, acc: 49.22%, op_acc: 41.41%] [G loss: 0.888759]\n",
      "epoch:17 step:13917[D loss: 0.442301, acc: 57.81%, op_acc: 39.84%] [G loss: 0.882981]\n",
      "epoch:17 step:13918[D loss: 0.449369, acc: 56.25%, op_acc: 36.72%] [G loss: 0.993546]\n",
      "epoch:17 step:13919[D loss: 0.427823, acc: 62.50%, op_acc: 39.84%] [G loss: 0.908471]\n",
      "epoch:17 step:13920[D loss: 0.464160, acc: 46.09%, op_acc: 35.16%] [G loss: 0.936600]\n",
      "epoch:17 step:13921[D loss: 0.427981, acc: 57.03%, op_acc: 42.19%] [G loss: 0.912487]\n",
      "epoch:17 step:13922[D loss: 0.402859, acc: 66.41%, op_acc: 39.84%] [G loss: 0.946339]\n",
      "epoch:17 step:13923[D loss: 0.407088, acc: 67.19%, op_acc: 35.94%] [G loss: 0.948222]\n",
      "epoch:17 step:13924[D loss: 0.424072, acc: 57.81%, op_acc: 42.19%] [G loss: 0.868936]\n",
      "epoch:17 step:13925[D loss: 0.419059, acc: 64.06%, op_acc: 31.25%] [G loss: 0.992322]\n",
      "epoch:17 step:13926[D loss: 0.431693, acc: 61.72%, op_acc: 37.50%] [G loss: 0.819385]\n",
      "epoch:17 step:13927[D loss: 0.450263, acc: 57.81%, op_acc: 34.38%] [G loss: 0.957049]\n",
      "epoch:17 step:13928[D loss: 0.443291, acc: 53.12%, op_acc: 41.41%] [G loss: 0.856516]\n",
      "epoch:17 step:13929[D loss: 0.409025, acc: 61.72%, op_acc: 39.84%] [G loss: 0.939205]\n",
      "epoch:17 step:13930[D loss: 0.390232, acc: 63.28%, op_acc: 43.75%] [G loss: 0.843183]\n",
      "epoch:17 step:13931[D loss: 0.416264, acc: 59.38%, op_acc: 39.84%] [G loss: 0.856065]\n",
      "epoch:17 step:13932[D loss: 0.414370, acc: 64.06%, op_acc: 37.50%] [G loss: 0.881181]\n",
      "epoch:17 step:13933[D loss: 0.446966, acc: 57.03%, op_acc: 34.38%] [G loss: 1.029098]\n",
      "epoch:17 step:13934[D loss: 0.448183, acc: 60.16%, op_acc: 36.72%] [G loss: 0.907750]\n",
      "epoch:17 step:13935[D loss: 0.423600, acc: 60.94%, op_acc: 34.38%] [G loss: 0.954497]\n",
      "epoch:17 step:13936[D loss: 0.438227, acc: 67.19%, op_acc: 38.28%] [G loss: 0.893536]\n",
      "epoch:17 step:13937[D loss: 0.416975, acc: 62.50%, op_acc: 36.72%] [G loss: 0.935637]\n",
      "epoch:17 step:13938[D loss: 0.408469, acc: 55.47%, op_acc: 43.75%] [G loss: 0.868033]\n",
      "epoch:17 step:13939[D loss: 0.408717, acc: 61.72%, op_acc: 43.75%] [G loss: 0.973390]\n",
      "epoch:17 step:13940[D loss: 0.413043, acc: 61.72%, op_acc: 37.50%] [G loss: 0.950444]\n",
      "epoch:17 step:13941[D loss: 0.422483, acc: 60.16%, op_acc: 38.28%] [G loss: 0.894450]\n",
      "epoch:17 step:13942[D loss: 0.444623, acc: 62.50%, op_acc: 34.38%] [G loss: 0.882604]\n",
      "epoch:17 step:13943[D loss: 0.427113, acc: 58.59%, op_acc: 36.72%] [G loss: 0.899622]\n",
      "epoch:17 step:13944[D loss: 0.394313, acc: 64.84%, op_acc: 38.28%] [G loss: 0.962311]\n",
      "epoch:17 step:13945[D loss: 0.445596, acc: 55.47%, op_acc: 39.06%] [G loss: 0.855172]\n",
      "epoch:17 step:13946[D loss: 0.441411, acc: 58.59%, op_acc: 38.28%] [G loss: 0.850448]\n",
      "epoch:17 step:13947[D loss: 0.399933, acc: 69.53%, op_acc: 42.19%] [G loss: 0.886581]\n",
      "epoch:17 step:13948[D loss: 0.441155, acc: 56.25%, op_acc: 38.28%] [G loss: 0.914844]\n",
      "epoch:17 step:13949[D loss: 0.448550, acc: 58.59%, op_acc: 38.28%] [G loss: 0.780739]\n",
      "epoch:17 step:13950[D loss: 0.442127, acc: 60.94%, op_acc: 35.16%] [G loss: 0.875843]\n",
      "##############\n",
      "[0.83941615 0.85052248 0.81109647 0.82027647 0.82082211 0.82470785\n",
      " 0.89032607 0.81099096 0.8007576  0.80677085]\n",
      "##########\n",
      "epoch:17 step:13951[D loss: 0.458393, acc: 49.22%, op_acc: 35.16%] [G loss: 0.933002]\n",
      "epoch:17 step:13952[D loss: 0.449002, acc: 50.00%, op_acc: 38.28%] [G loss: 0.811852]\n",
      "epoch:17 step:13953[D loss: 0.478593, acc: 55.47%, op_acc: 28.12%] [G loss: 0.864192]\n",
      "epoch:17 step:13954[D loss: 0.461045, acc: 52.34%, op_acc: 35.94%] [G loss: 0.843232]\n",
      "epoch:17 step:13955[D loss: 0.426526, acc: 59.38%, op_acc: 35.94%] [G loss: 0.916741]\n",
      "epoch:17 step:13956[D loss: 0.388045, acc: 65.62%, op_acc: 47.66%] [G loss: 0.836497]\n",
      "epoch:17 step:13957[D loss: 0.442378, acc: 64.06%, op_acc: 38.28%] [G loss: 0.896880]\n",
      "epoch:17 step:13958[D loss: 0.421545, acc: 62.50%, op_acc: 32.03%] [G loss: 0.825181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13959[D loss: 0.401302, acc: 60.16%, op_acc: 41.41%] [G loss: 0.885789]\n",
      "epoch:17 step:13960[D loss: 0.451537, acc: 51.56%, op_acc: 37.50%] [G loss: 0.861448]\n",
      "epoch:17 step:13961[D loss: 0.440823, acc: 61.72%, op_acc: 33.59%] [G loss: 0.872807]\n",
      "epoch:17 step:13962[D loss: 0.449940, acc: 56.25%, op_acc: 36.72%] [G loss: 0.977006]\n",
      "epoch:17 step:13963[D loss: 0.427854, acc: 64.06%, op_acc: 39.84%] [G loss: 0.829937]\n",
      "epoch:17 step:13964[D loss: 0.415540, acc: 61.72%, op_acc: 35.94%] [G loss: 0.895388]\n",
      "epoch:17 step:13965[D loss: 0.428481, acc: 53.91%, op_acc: 43.75%] [G loss: 0.819848]\n",
      "epoch:17 step:13966[D loss: 0.428922, acc: 50.78%, op_acc: 39.84%] [G loss: 0.896643]\n",
      "epoch:17 step:13967[D loss: 0.398887, acc: 69.53%, op_acc: 41.41%] [G loss: 0.902567]\n",
      "epoch:17 step:13968[D loss: 0.419898, acc: 64.84%, op_acc: 38.28%] [G loss: 0.960113]\n",
      "epoch:17 step:13969[D loss: 0.447257, acc: 52.34%, op_acc: 39.06%] [G loss: 0.841591]\n",
      "epoch:17 step:13970[D loss: 0.482614, acc: 48.44%, op_acc: 33.59%] [G loss: 0.824696]\n",
      "epoch:17 step:13971[D loss: 0.435878, acc: 60.94%, op_acc: 33.59%] [G loss: 0.879051]\n",
      "epoch:17 step:13972[D loss: 0.421509, acc: 63.28%, op_acc: 40.62%] [G loss: 0.876419]\n",
      "epoch:17 step:13973[D loss: 0.443255, acc: 58.59%, op_acc: 37.50%] [G loss: 0.821339]\n",
      "epoch:17 step:13974[D loss: 0.402867, acc: 66.41%, op_acc: 39.06%] [G loss: 0.920145]\n",
      "epoch:17 step:13975[D loss: 0.417256, acc: 63.28%, op_acc: 41.41%] [G loss: 0.860293]\n",
      "epoch:17 step:13976[D loss: 0.403015, acc: 60.16%, op_acc: 42.19%] [G loss: 0.861400]\n",
      "epoch:17 step:13977[D loss: 0.449371, acc: 58.59%, op_acc: 34.38%] [G loss: 0.843235]\n",
      "epoch:17 step:13978[D loss: 0.452447, acc: 60.16%, op_acc: 33.59%] [G loss: 0.882213]\n",
      "epoch:17 step:13979[D loss: 0.427322, acc: 63.28%, op_acc: 35.94%] [G loss: 0.872548]\n",
      "epoch:17 step:13980[D loss: 0.439988, acc: 58.59%, op_acc: 38.28%] [G loss: 0.870347]\n",
      "epoch:17 step:13981[D loss: 0.392711, acc: 61.72%, op_acc: 46.88%] [G loss: 0.828433]\n",
      "epoch:17 step:13982[D loss: 0.432321, acc: 58.59%, op_acc: 38.28%] [G loss: 0.929200]\n",
      "epoch:17 step:13983[D loss: 0.451838, acc: 53.12%, op_acc: 36.72%] [G loss: 0.898210]\n",
      "epoch:17 step:13984[D loss: 0.446481, acc: 52.34%, op_acc: 37.50%] [G loss: 0.835391]\n",
      "epoch:17 step:13985[D loss: 0.446630, acc: 54.69%, op_acc: 42.97%] [G loss: 0.827988]\n",
      "epoch:17 step:13986[D loss: 0.432708, acc: 58.59%, op_acc: 38.28%] [G loss: 0.890180]\n",
      "epoch:17 step:13987[D loss: 0.420753, acc: 53.12%, op_acc: 43.75%] [G loss: 0.962310]\n",
      "epoch:17 step:13988[D loss: 0.427529, acc: 57.81%, op_acc: 36.72%] [G loss: 0.885354]\n",
      "epoch:17 step:13989[D loss: 0.416339, acc: 57.81%, op_acc: 39.84%] [G loss: 0.890500]\n",
      "epoch:17 step:13990[D loss: 0.418854, acc: 65.62%, op_acc: 41.41%] [G loss: 0.974296]\n",
      "epoch:17 step:13991[D loss: 0.432048, acc: 64.06%, op_acc: 35.16%] [G loss: 0.924047]\n",
      "epoch:17 step:13992[D loss: 0.437577, acc: 56.25%, op_acc: 39.06%] [G loss: 0.904071]\n",
      "epoch:17 step:13993[D loss: 0.435419, acc: 57.03%, op_acc: 35.94%] [G loss: 0.901495]\n",
      "epoch:17 step:13994[D loss: 0.418548, acc: 57.03%, op_acc: 45.31%] [G loss: 0.837932]\n",
      "epoch:17 step:13995[D loss: 0.424334, acc: 59.38%, op_acc: 40.62%] [G loss: 0.894771]\n",
      "epoch:17 step:13996[D loss: 0.436645, acc: 61.72%, op_acc: 39.84%] [G loss: 0.918687]\n",
      "epoch:17 step:13997[D loss: 0.423438, acc: 62.50%, op_acc: 41.41%] [G loss: 0.914215]\n",
      "epoch:17 step:13998[D loss: 0.439357, acc: 50.78%, op_acc: 40.62%] [G loss: 0.842865]\n",
      "epoch:17 step:13999[D loss: 0.416334, acc: 56.25%, op_acc: 40.62%] [G loss: 0.821609]\n",
      "epoch:17 step:14000[D loss: 0.429014, acc: 57.03%, op_acc: 35.94%] [G loss: 0.896818]\n",
      "##############\n",
      "[0.87217225 0.86559702 0.82768227 0.80968178 0.78636275 0.84068126\n",
      " 0.90215419 0.83429339 0.82437034 0.81608515]\n",
      "##########\n",
      "epoch:17 step:14001[D loss: 0.493353, acc: 42.97%, op_acc: 32.03%] [G loss: 0.858596]\n",
      "epoch:17 step:14002[D loss: 0.410249, acc: 68.75%, op_acc: 36.72%] [G loss: 0.966039]\n",
      "epoch:17 step:14003[D loss: 0.427690, acc: 64.84%, op_acc: 39.84%] [G loss: 0.947486]\n",
      "epoch:17 step:14004[D loss: 0.436845, acc: 63.28%, op_acc: 35.16%] [G loss: 0.934430]\n",
      "epoch:17 step:14005[D loss: 0.444861, acc: 57.03%, op_acc: 37.50%] [G loss: 0.893818]\n",
      "epoch:17 step:14006[D loss: 0.434237, acc: 62.50%, op_acc: 33.59%] [G loss: 0.964726]\n",
      "epoch:17 step:14007[D loss: 0.398837, acc: 71.09%, op_acc: 33.59%] [G loss: 0.917244]\n",
      "epoch:17 step:14008[D loss: 0.426075, acc: 57.81%, op_acc: 42.19%] [G loss: 0.863092]\n",
      "epoch:17 step:14009[D loss: 0.438913, acc: 53.91%, op_acc: 33.59%] [G loss: 0.871617]\n",
      "epoch:17 step:14010[D loss: 0.411633, acc: 60.16%, op_acc: 35.94%] [G loss: 0.897598]\n",
      "epoch:17 step:14011[D loss: 0.441933, acc: 56.25%, op_acc: 35.16%] [G loss: 0.927804]\n",
      "epoch:17 step:14012[D loss: 0.449819, acc: 55.47%, op_acc: 39.06%] [G loss: 0.823795]\n",
      "epoch:17 step:14013[D loss: 0.423298, acc: 63.28%, op_acc: 33.59%] [G loss: 0.907772]\n",
      "epoch:17 step:14014[D loss: 0.402223, acc: 60.94%, op_acc: 45.31%] [G loss: 0.888648]\n",
      "epoch:17 step:14015[D loss: 0.426980, acc: 60.16%, op_acc: 38.28%] [G loss: 0.910280]\n",
      "epoch:17 step:14016[D loss: 0.426087, acc: 55.47%, op_acc: 35.94%] [G loss: 0.845379]\n",
      "epoch:17 step:14017[D loss: 0.420234, acc: 57.03%, op_acc: 42.19%] [G loss: 0.908738]\n",
      "epoch:17 step:14018[D loss: 0.435278, acc: 57.81%, op_acc: 34.38%] [G loss: 0.826100]\n",
      "epoch:17 step:14019[D loss: 0.397271, acc: 63.28%, op_acc: 42.97%] [G loss: 0.880653]\n",
      "epoch:17 step:14020[D loss: 0.448345, acc: 56.25%, op_acc: 34.38%] [G loss: 0.840643]\n",
      "epoch:17 step:14021[D loss: 0.406264, acc: 62.50%, op_acc: 40.62%] [G loss: 0.890832]\n",
      "epoch:17 step:14022[D loss: 0.424718, acc: 57.03%, op_acc: 41.41%] [G loss: 0.968721]\n",
      "epoch:17 step:14023[D loss: 0.410966, acc: 60.16%, op_acc: 42.19%] [G loss: 0.963768]\n",
      "epoch:17 step:14024[D loss: 0.460431, acc: 49.22%, op_acc: 39.84%] [G loss: 0.860451]\n",
      "epoch:17 step:14025[D loss: 0.436418, acc: 61.72%, op_acc: 36.72%] [G loss: 0.926041]\n",
      "epoch:17 step:14026[D loss: 0.472228, acc: 54.69%, op_acc: 32.81%] [G loss: 0.822393]\n",
      "epoch:17 step:14027[D loss: 0.434919, acc: 53.91%, op_acc: 39.84%] [G loss: 0.849056]\n",
      "epoch:17 step:14028[D loss: 0.437588, acc: 61.72%, op_acc: 37.50%] [G loss: 0.812008]\n",
      "epoch:17 step:14029[D loss: 0.460044, acc: 58.59%, op_acc: 35.94%] [G loss: 0.866272]\n",
      "epoch:17 step:14030[D loss: 0.413570, acc: 60.16%, op_acc: 43.75%] [G loss: 0.921448]\n",
      "epoch:17 step:14031[D loss: 0.443577, acc: 59.38%, op_acc: 37.50%] [G loss: 0.839201]\n",
      "epoch:17 step:14032[D loss: 0.405794, acc: 67.19%, op_acc: 42.97%] [G loss: 0.889214]\n",
      "epoch:17 step:14033[D loss: 0.403507, acc: 60.94%, op_acc: 47.66%] [G loss: 0.922848]\n",
      "epoch:17 step:14034[D loss: 0.424775, acc: 54.69%, op_acc: 40.62%] [G loss: 0.794091]\n",
      "epoch:17 step:14035[D loss: 0.399993, acc: 57.81%, op_acc: 48.44%] [G loss: 0.851289]\n",
      "epoch:17 step:14036[D loss: 0.466203, acc: 51.56%, op_acc: 40.62%] [G loss: 0.868145]\n",
      "epoch:17 step:14037[D loss: 0.449274, acc: 55.47%, op_acc: 40.62%] [G loss: 0.926417]\n",
      "epoch:17 step:14038[D loss: 0.389241, acc: 65.62%, op_acc: 44.53%] [G loss: 0.973752]\n",
      "epoch:17 step:14039[D loss: 0.451163, acc: 56.25%, op_acc: 41.41%] [G loss: 0.873677]\n",
      "epoch:17 step:14040[D loss: 0.452724, acc: 56.25%, op_acc: 35.94%] [G loss: 0.874705]\n",
      "epoch:17 step:14041[D loss: 0.437027, acc: 53.91%, op_acc: 35.16%] [G loss: 0.840831]\n",
      "epoch:17 step:14042[D loss: 0.400259, acc: 66.41%, op_acc: 39.84%] [G loss: 0.918824]\n",
      "epoch:17 step:14043[D loss: 0.417249, acc: 61.72%, op_acc: 39.06%] [G loss: 0.833769]\n",
      "epoch:17 step:14044[D loss: 0.424335, acc: 61.72%, op_acc: 32.03%] [G loss: 0.884141]\n",
      "epoch:17 step:14045[D loss: 0.478242, acc: 50.00%, op_acc: 35.94%] [G loss: 0.923867]\n",
      "epoch:17 step:14046[D loss: 0.411229, acc: 67.19%, op_acc: 33.59%] [G loss: 0.911806]\n",
      "epoch:17 step:14047[D loss: 0.418161, acc: 57.03%, op_acc: 42.97%] [G loss: 0.879980]\n",
      "epoch:17 step:14048[D loss: 0.485318, acc: 46.09%, op_acc: 34.38%] [G loss: 0.980007]\n",
      "epoch:17 step:14049[D loss: 0.448597, acc: 59.38%, op_acc: 33.59%] [G loss: 0.846210]\n",
      "epoch:17 step:14050[D loss: 0.405881, acc: 67.97%, op_acc: 35.16%] [G loss: 0.962113]\n",
      "##############\n",
      "[0.85502186 0.87140536 0.81190426 0.79840658 0.7936712  0.83379388\n",
      " 0.87605967 0.8255599  0.84190165 0.83572799]\n",
      "##########\n",
      "epoch:17 step:14051[D loss: 0.416968, acc: 55.47%, op_acc: 42.97%] [G loss: 0.865697]\n",
      "epoch:17 step:14052[D loss: 0.431212, acc: 59.38%, op_acc: 39.06%] [G loss: 0.875059]\n",
      "epoch:17 step:14053[D loss: 0.406522, acc: 60.94%, op_acc: 39.06%] [G loss: 0.949794]\n",
      "epoch:17 step:14054[D loss: 0.459595, acc: 54.69%, op_acc: 37.50%] [G loss: 0.847322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:14055[D loss: 0.416599, acc: 64.06%, op_acc: 39.84%] [G loss: 0.897628]\n",
      "epoch:17 step:14056[D loss: 0.409453, acc: 59.38%, op_acc: 38.28%] [G loss: 0.992072]\n",
      "epoch:17 step:14057[D loss: 0.431362, acc: 57.03%, op_acc: 35.16%] [G loss: 0.870992]\n",
      "epoch:17 step:14058[D loss: 0.429840, acc: 56.25%, op_acc: 41.41%] [G loss: 0.958557]\n",
      "epoch:18 step:14059[D loss: 0.415150, acc: 61.72%, op_acc: 42.19%] [G loss: 0.940186]\n",
      "epoch:18 step:14060[D loss: 0.395895, acc: 64.84%, op_acc: 39.06%] [G loss: 0.893658]\n",
      "epoch:18 step:14061[D loss: 0.460233, acc: 47.66%, op_acc: 39.06%] [G loss: 0.831779]\n",
      "epoch:18 step:14062[D loss: 0.430244, acc: 60.16%, op_acc: 38.28%] [G loss: 0.873712]\n",
      "epoch:18 step:14063[D loss: 0.425050, acc: 61.72%, op_acc: 35.94%] [G loss: 0.898549]\n",
      "epoch:18 step:14064[D loss: 0.426196, acc: 64.06%, op_acc: 35.16%] [G loss: 0.876813]\n",
      "epoch:18 step:14065[D loss: 0.423123, acc: 56.25%, op_acc: 36.72%] [G loss: 0.870258]\n",
      "epoch:18 step:14066[D loss: 0.453261, acc: 55.47%, op_acc: 39.84%] [G loss: 0.863855]\n",
      "epoch:18 step:14067[D loss: 0.407449, acc: 57.03%, op_acc: 42.97%] [G loss: 0.870347]\n",
      "epoch:18 step:14068[D loss: 0.419433, acc: 59.38%, op_acc: 38.28%] [G loss: 0.910711]\n",
      "epoch:18 step:14069[D loss: 0.462351, acc: 53.91%, op_acc: 36.72%] [G loss: 0.871167]\n",
      "epoch:18 step:14070[D loss: 0.413113, acc: 61.72%, op_acc: 36.72%] [G loss: 0.841909]\n",
      "epoch:18 step:14071[D loss: 0.429262, acc: 62.50%, op_acc: 34.38%] [G loss: 0.837155]\n",
      "epoch:18 step:14072[D loss: 0.455444, acc: 55.47%, op_acc: 34.38%] [G loss: 0.887347]\n",
      "epoch:18 step:14073[D loss: 0.427475, acc: 57.81%, op_acc: 36.72%] [G loss: 0.940050]\n",
      "epoch:18 step:14074[D loss: 0.390700, acc: 62.50%, op_acc: 43.75%] [G loss: 0.788375]\n",
      "epoch:18 step:14075[D loss: 0.425333, acc: 55.47%, op_acc: 39.06%] [G loss: 0.853486]\n",
      "epoch:18 step:14076[D loss: 0.420507, acc: 57.03%, op_acc: 37.50%] [G loss: 0.836177]\n",
      "epoch:18 step:14077[D loss: 0.425282, acc: 58.59%, op_acc: 39.84%] [G loss: 0.836147]\n",
      "epoch:18 step:14078[D loss: 0.427050, acc: 59.38%, op_acc: 39.84%] [G loss: 0.894890]\n",
      "epoch:18 step:14079[D loss: 0.432978, acc: 68.75%, op_acc: 32.81%] [G loss: 0.918727]\n",
      "epoch:18 step:14080[D loss: 0.404697, acc: 70.31%, op_acc: 42.97%] [G loss: 0.942799]\n",
      "epoch:18 step:14081[D loss: 0.430247, acc: 60.94%, op_acc: 34.38%] [G loss: 0.853531]\n",
      "epoch:18 step:14082[D loss: 0.443124, acc: 59.38%, op_acc: 32.81%] [G loss: 0.874599]\n",
      "epoch:18 step:14083[D loss: 0.442908, acc: 55.47%, op_acc: 37.50%] [G loss: 0.843642]\n",
      "epoch:18 step:14084[D loss: 0.422695, acc: 59.38%, op_acc: 35.16%] [G loss: 0.877418]\n",
      "epoch:18 step:14085[D loss: 0.410215, acc: 64.84%, op_acc: 37.50%] [G loss: 0.945796]\n",
      "epoch:18 step:14086[D loss: 0.435379, acc: 58.59%, op_acc: 39.06%] [G loss: 0.887955]\n",
      "epoch:18 step:14087[D loss: 0.410831, acc: 65.62%, op_acc: 42.19%] [G loss: 0.897818]\n",
      "epoch:18 step:14088[D loss: 0.405256, acc: 60.94%, op_acc: 39.06%] [G loss: 0.891418]\n",
      "epoch:18 step:14089[D loss: 0.431007, acc: 64.84%, op_acc: 38.28%] [G loss: 0.927442]\n",
      "epoch:18 step:14090[D loss: 0.458724, acc: 53.12%, op_acc: 36.72%] [G loss: 0.816589]\n",
      "epoch:18 step:14091[D loss: 0.414032, acc: 61.72%, op_acc: 41.41%] [G loss: 0.845954]\n",
      "epoch:18 step:14092[D loss: 0.412571, acc: 61.72%, op_acc: 41.41%] [G loss: 0.894351]\n",
      "epoch:18 step:14093[D loss: 0.449871, acc: 59.38%, op_acc: 33.59%] [G loss: 0.939802]\n",
      "epoch:18 step:14094[D loss: 0.435431, acc: 55.47%, op_acc: 41.41%] [G loss: 0.772880]\n",
      "epoch:18 step:14095[D loss: 0.411880, acc: 60.16%, op_acc: 36.72%] [G loss: 0.903642]\n",
      "epoch:18 step:14096[D loss: 0.396891, acc: 65.62%, op_acc: 39.06%] [G loss: 0.920416]\n",
      "epoch:18 step:14097[D loss: 0.425209, acc: 55.47%, op_acc: 41.41%] [G loss: 0.870751]\n",
      "epoch:18 step:14098[D loss: 0.464387, acc: 56.25%, op_acc: 35.94%] [G loss: 0.864880]\n",
      "epoch:18 step:14099[D loss: 0.402109, acc: 58.59%, op_acc: 41.41%] [G loss: 0.886767]\n",
      "epoch:18 step:14100[D loss: 0.406843, acc: 63.28%, op_acc: 43.75%] [G loss: 0.911403]\n",
      "##############\n",
      "[0.85296796 0.85580826 0.81688346 0.79237972 0.77767022 0.83307479\n",
      " 0.86796285 0.84437497 0.81250126 0.81686719]\n",
      "##########\n",
      "epoch:18 step:14101[D loss: 0.432461, acc: 62.50%, op_acc: 42.19%] [G loss: 0.926753]\n",
      "epoch:18 step:14102[D loss: 0.445721, acc: 46.88%, op_acc: 38.28%] [G loss: 0.921519]\n",
      "epoch:18 step:14103[D loss: 0.394644, acc: 64.84%, op_acc: 40.62%] [G loss: 0.973887]\n",
      "epoch:18 step:14104[D loss: 0.419204, acc: 60.16%, op_acc: 38.28%] [G loss: 0.876411]\n",
      "epoch:18 step:14105[D loss: 0.446668, acc: 56.25%, op_acc: 37.50%] [G loss: 0.903205]\n",
      "epoch:18 step:14106[D loss: 0.454756, acc: 55.47%, op_acc: 38.28%] [G loss: 0.839508]\n",
      "epoch:18 step:14107[D loss: 0.419941, acc: 61.72%, op_acc: 35.16%] [G loss: 0.901134]\n",
      "epoch:18 step:14108[D loss: 0.415518, acc: 60.94%, op_acc: 39.06%] [G loss: 0.926996]\n",
      "epoch:18 step:14109[D loss: 0.414230, acc: 63.28%, op_acc: 38.28%] [G loss: 0.899667]\n",
      "epoch:18 step:14110[D loss: 0.430965, acc: 62.50%, op_acc: 39.84%] [G loss: 0.889063]\n",
      "epoch:18 step:14111[D loss: 0.459450, acc: 56.25%, op_acc: 31.25%] [G loss: 0.945273]\n",
      "epoch:18 step:14112[D loss: 0.462685, acc: 54.69%, op_acc: 35.94%] [G loss: 0.896509]\n",
      "epoch:18 step:14113[D loss: 0.399571, acc: 61.72%, op_acc: 40.62%] [G loss: 0.919729]\n",
      "epoch:18 step:14114[D loss: 0.414361, acc: 57.81%, op_acc: 36.72%] [G loss: 0.834569]\n",
      "epoch:18 step:14115[D loss: 0.429721, acc: 54.69%, op_acc: 42.19%] [G loss: 0.846366]\n",
      "epoch:18 step:14116[D loss: 0.421481, acc: 50.00%, op_acc: 42.19%] [G loss: 0.878838]\n",
      "epoch:18 step:14117[D loss: 0.417290, acc: 58.59%, op_acc: 39.06%] [G loss: 0.862186]\n",
      "epoch:18 step:14118[D loss: 0.418956, acc: 57.03%, op_acc: 35.94%] [G loss: 0.917329]\n",
      "epoch:18 step:14119[D loss: 0.430810, acc: 56.25%, op_acc: 39.06%] [G loss: 0.861997]\n",
      "epoch:18 step:14120[D loss: 0.441970, acc: 55.47%, op_acc: 37.50%] [G loss: 0.862470]\n",
      "epoch:18 step:14121[D loss: 0.411856, acc: 61.72%, op_acc: 39.84%] [G loss: 0.865956]\n",
      "epoch:18 step:14122[D loss: 0.407494, acc: 67.97%, op_acc: 39.06%] [G loss: 0.924179]\n",
      "epoch:18 step:14123[D loss: 0.458127, acc: 53.91%, op_acc: 38.28%] [G loss: 0.872415]\n",
      "epoch:18 step:14124[D loss: 0.435989, acc: 57.81%, op_acc: 41.41%] [G loss: 0.851083]\n",
      "epoch:18 step:14125[D loss: 0.406564, acc: 64.06%, op_acc: 39.84%] [G loss: 0.839289]\n",
      "epoch:18 step:14126[D loss: 0.425302, acc: 53.12%, op_acc: 39.84%] [G loss: 0.962387]\n",
      "epoch:18 step:14127[D loss: 0.448356, acc: 48.44%, op_acc: 39.84%] [G loss: 0.831585]\n",
      "epoch:18 step:14128[D loss: 0.420902, acc: 61.72%, op_acc: 42.97%] [G loss: 0.928866]\n",
      "epoch:18 step:14129[D loss: 0.460943, acc: 57.81%, op_acc: 36.72%] [G loss: 0.849186]\n",
      "epoch:18 step:14130[D loss: 0.407986, acc: 59.38%, op_acc: 39.06%] [G loss: 0.834287]\n",
      "epoch:18 step:14131[D loss: 0.451465, acc: 50.78%, op_acc: 36.72%] [G loss: 0.865245]\n",
      "epoch:18 step:14132[D loss: 0.397282, acc: 58.59%, op_acc: 42.19%] [G loss: 0.908679]\n",
      "epoch:18 step:14133[D loss: 0.414776, acc: 59.38%, op_acc: 37.50%] [G loss: 0.825476]\n",
      "epoch:18 step:14134[D loss: 0.455591, acc: 57.81%, op_acc: 33.59%] [G loss: 0.879842]\n",
      "epoch:18 step:14135[D loss: 0.418812, acc: 63.28%, op_acc: 42.19%] [G loss: 0.905448]\n",
      "epoch:18 step:14136[D loss: 0.451689, acc: 58.59%, op_acc: 34.38%] [G loss: 0.857929]\n",
      "epoch:18 step:14137[D loss: 0.429479, acc: 57.81%, op_acc: 39.84%] [G loss: 0.891853]\n",
      "epoch:18 step:14138[D loss: 0.442728, acc: 59.38%, op_acc: 30.47%] [G loss: 0.961449]\n",
      "epoch:18 step:14139[D loss: 0.441307, acc: 60.94%, op_acc: 35.16%] [G loss: 0.967766]\n",
      "epoch:18 step:14140[D loss: 0.401811, acc: 67.97%, op_acc: 35.94%] [G loss: 0.896717]\n",
      "epoch:18 step:14141[D loss: 0.437256, acc: 63.28%, op_acc: 35.94%] [G loss: 0.887293]\n",
      "epoch:18 step:14142[D loss: 0.416866, acc: 62.50%, op_acc: 39.84%] [G loss: 0.858235]\n",
      "epoch:18 step:14143[D loss: 0.443817, acc: 58.59%, op_acc: 33.59%] [G loss: 0.833854]\n",
      "epoch:18 step:14144[D loss: 0.431768, acc: 60.94%, op_acc: 41.41%] [G loss: 0.909568]\n",
      "epoch:18 step:14145[D loss: 0.400740, acc: 67.19%, op_acc: 34.38%] [G loss: 0.969898]\n",
      "epoch:18 step:14146[D loss: 0.435146, acc: 56.25%, op_acc: 35.94%] [G loss: 0.804525]\n",
      "epoch:18 step:14147[D loss: 0.475892, acc: 51.56%, op_acc: 35.94%] [G loss: 0.866268]\n",
      "epoch:18 step:14148[D loss: 0.432860, acc: 59.38%, op_acc: 32.81%] [G loss: 0.881417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14149[D loss: 0.411584, acc: 59.38%, op_acc: 39.06%] [G loss: 0.916106]\n",
      "epoch:18 step:14150[D loss: 0.448494, acc: 62.50%, op_acc: 33.59%] [G loss: 0.853272]\n",
      "##############\n",
      "[0.86409029 0.86009023 0.82801874 0.80960887 0.80378981 0.82107609\n",
      " 0.88959484 0.82688081 0.80017592 0.82112053]\n",
      "##########\n",
      "epoch:18 step:14151[D loss: 0.410659, acc: 62.50%, op_acc: 41.41%] [G loss: 0.928789]\n",
      "epoch:18 step:14152[D loss: 0.414358, acc: 60.16%, op_acc: 34.38%] [G loss: 0.861654]\n",
      "epoch:18 step:14153[D loss: 0.425194, acc: 58.59%, op_acc: 39.06%] [G loss: 0.964556]\n",
      "epoch:18 step:14154[D loss: 0.460307, acc: 57.81%, op_acc: 29.69%] [G loss: 0.854288]\n",
      "epoch:18 step:14155[D loss: 0.420695, acc: 60.94%, op_acc: 38.28%] [G loss: 0.862650]\n",
      "epoch:18 step:14156[D loss: 0.439485, acc: 56.25%, op_acc: 31.25%] [G loss: 0.899749]\n",
      "epoch:18 step:14157[D loss: 0.430215, acc: 60.94%, op_acc: 40.62%] [G loss: 0.872722]\n",
      "epoch:18 step:14158[D loss: 0.417039, acc: 55.47%, op_acc: 45.31%] [G loss: 0.854676]\n",
      "epoch:18 step:14159[D loss: 0.404952, acc: 67.97%, op_acc: 39.84%] [G loss: 0.901894]\n",
      "epoch:18 step:14160[D loss: 0.449594, acc: 55.47%, op_acc: 34.38%] [G loss: 0.906911]\n",
      "epoch:18 step:14161[D loss: 0.438416, acc: 56.25%, op_acc: 35.16%] [G loss: 0.896370]\n",
      "epoch:18 step:14162[D loss: 0.421680, acc: 59.38%, op_acc: 35.16%] [G loss: 0.866952]\n",
      "epoch:18 step:14163[D loss: 0.425489, acc: 59.38%, op_acc: 39.84%] [G loss: 0.879462]\n",
      "epoch:18 step:14164[D loss: 0.410619, acc: 63.28%, op_acc: 39.06%] [G loss: 0.832829]\n",
      "epoch:18 step:14165[D loss: 0.396128, acc: 67.97%, op_acc: 37.50%] [G loss: 0.923635]\n",
      "epoch:18 step:14166[D loss: 0.449898, acc: 54.69%, op_acc: 32.03%] [G loss: 0.873171]\n",
      "epoch:18 step:14167[D loss: 0.451057, acc: 50.78%, op_acc: 40.62%] [G loss: 0.778803]\n",
      "epoch:18 step:14168[D loss: 0.434201, acc: 56.25%, op_acc: 40.62%] [G loss: 0.892728]\n",
      "epoch:18 step:14169[D loss: 0.465614, acc: 57.03%, op_acc: 35.94%] [G loss: 0.923691]\n",
      "epoch:18 step:14170[D loss: 0.411862, acc: 62.50%, op_acc: 41.41%] [G loss: 0.858078]\n",
      "epoch:18 step:14171[D loss: 0.422643, acc: 64.06%, op_acc: 35.16%] [G loss: 0.962847]\n",
      "epoch:18 step:14172[D loss: 0.410138, acc: 66.41%, op_acc: 45.31%] [G loss: 0.865091]\n",
      "epoch:18 step:14173[D loss: 0.443500, acc: 49.22%, op_acc: 34.38%] [G loss: 0.887307]\n",
      "epoch:18 step:14174[D loss: 0.453043, acc: 50.78%, op_acc: 37.50%] [G loss: 0.891092]\n",
      "epoch:18 step:14175[D loss: 0.419426, acc: 55.47%, op_acc: 42.19%] [G loss: 0.888907]\n",
      "epoch:18 step:14176[D loss: 0.453086, acc: 57.03%, op_acc: 33.59%] [G loss: 0.733633]\n",
      "epoch:18 step:14177[D loss: 0.412239, acc: 62.50%, op_acc: 41.41%] [G loss: 0.853091]\n",
      "epoch:18 step:14178[D loss: 0.442467, acc: 51.56%, op_acc: 35.94%] [G loss: 0.854014]\n",
      "epoch:18 step:14179[D loss: 0.419612, acc: 65.62%, op_acc: 40.62%] [G loss: 0.860636]\n",
      "epoch:18 step:14180[D loss: 0.420981, acc: 58.59%, op_acc: 32.81%] [G loss: 0.884964]\n",
      "epoch:18 step:14181[D loss: 0.413852, acc: 64.06%, op_acc: 35.16%] [G loss: 0.867897]\n",
      "epoch:18 step:14182[D loss: 0.397020, acc: 66.41%, op_acc: 42.19%] [G loss: 0.955184]\n",
      "epoch:18 step:14183[D loss: 0.443728, acc: 52.34%, op_acc: 37.50%] [G loss: 0.879783]\n",
      "epoch:18 step:14184[D loss: 0.440219, acc: 55.47%, op_acc: 36.72%] [G loss: 0.870729]\n",
      "epoch:18 step:14185[D loss: 0.441742, acc: 58.59%, op_acc: 39.06%] [G loss: 0.874799]\n",
      "epoch:18 step:14186[D loss: 0.455150, acc: 51.56%, op_acc: 37.50%] [G loss: 0.864995]\n",
      "epoch:18 step:14187[D loss: 0.440160, acc: 60.94%, op_acc: 39.06%] [G loss: 0.902016]\n",
      "epoch:18 step:14188[D loss: 0.421892, acc: 60.16%, op_acc: 39.84%] [G loss: 0.911771]\n",
      "epoch:18 step:14189[D loss: 0.430135, acc: 56.25%, op_acc: 37.50%] [G loss: 0.791872]\n",
      "epoch:18 step:14190[D loss: 0.385046, acc: 64.06%, op_acc: 43.75%] [G loss: 0.881392]\n",
      "epoch:18 step:14191[D loss: 0.469316, acc: 60.16%, op_acc: 31.25%] [G loss: 0.856065]\n",
      "epoch:18 step:14192[D loss: 0.418997, acc: 63.28%, op_acc: 33.59%] [G loss: 0.828736]\n",
      "epoch:18 step:14193[D loss: 0.432054, acc: 58.59%, op_acc: 41.41%] [G loss: 0.863624]\n",
      "epoch:18 step:14194[D loss: 0.383654, acc: 67.19%, op_acc: 42.19%] [G loss: 0.910061]\n",
      "epoch:18 step:14195[D loss: 0.452332, acc: 53.12%, op_acc: 33.59%] [G loss: 0.854955]\n",
      "epoch:18 step:14196[D loss: 0.430779, acc: 58.59%, op_acc: 33.59%] [G loss: 0.915671]\n",
      "epoch:18 step:14197[D loss: 0.418898, acc: 62.50%, op_acc: 35.94%] [G loss: 0.849629]\n",
      "epoch:18 step:14198[D loss: 0.472343, acc: 47.66%, op_acc: 34.38%] [G loss: 0.811686]\n",
      "epoch:18 step:14199[D loss: 0.409875, acc: 66.41%, op_acc: 38.28%] [G loss: 0.836951]\n",
      "epoch:18 step:14200[D loss: 0.429360, acc: 62.50%, op_acc: 35.94%] [G loss: 0.872019]\n",
      "##############\n",
      "[0.85325274 0.86569645 0.81120399 0.80568822 0.79337803 0.82753317\n",
      " 0.89036548 0.82970004 0.80849958 0.82683462]\n",
      "##########\n",
      "epoch:18 step:14201[D loss: 0.424640, acc: 57.81%, op_acc: 43.75%] [G loss: 0.934456]\n",
      "epoch:18 step:14202[D loss: 0.431743, acc: 59.38%, op_acc: 37.50%] [G loss: 0.847098]\n",
      "epoch:18 step:14203[D loss: 0.440913, acc: 57.03%, op_acc: 39.84%] [G loss: 0.895321]\n",
      "epoch:18 step:14204[D loss: 0.431547, acc: 56.25%, op_acc: 35.16%] [G loss: 0.851550]\n",
      "epoch:18 step:14205[D loss: 0.420875, acc: 57.81%, op_acc: 39.06%] [G loss: 0.929514]\n",
      "epoch:18 step:14206[D loss: 0.418993, acc: 64.84%, op_acc: 41.41%] [G loss: 0.797792]\n",
      "epoch:18 step:14207[D loss: 0.405201, acc: 65.62%, op_acc: 37.50%] [G loss: 0.900258]\n",
      "epoch:18 step:14208[D loss: 0.444929, acc: 55.47%, op_acc: 38.28%] [G loss: 0.927004]\n",
      "epoch:18 step:14209[D loss: 0.420447, acc: 62.50%, op_acc: 39.84%] [G loss: 0.889299]\n",
      "epoch:18 step:14210[D loss: 0.425498, acc: 60.16%, op_acc: 37.50%] [G loss: 0.885294]\n",
      "epoch:18 step:14211[D loss: 0.428727, acc: 58.59%, op_acc: 39.06%] [G loss: 0.968969]\n",
      "epoch:18 step:14212[D loss: 0.437421, acc: 54.69%, op_acc: 34.38%] [G loss: 0.897907]\n",
      "epoch:18 step:14213[D loss: 0.421843, acc: 57.81%, op_acc: 40.62%] [G loss: 0.895143]\n",
      "epoch:18 step:14214[D loss: 0.438094, acc: 56.25%, op_acc: 36.72%] [G loss: 0.858300]\n",
      "epoch:18 step:14215[D loss: 0.431567, acc: 63.28%, op_acc: 39.84%] [G loss: 0.850778]\n",
      "epoch:18 step:14216[D loss: 0.407206, acc: 59.38%, op_acc: 38.28%] [G loss: 0.894470]\n",
      "epoch:18 step:14217[D loss: 0.446236, acc: 53.91%, op_acc: 39.06%] [G loss: 0.881948]\n",
      "epoch:18 step:14218[D loss: 0.452513, acc: 54.69%, op_acc: 30.47%] [G loss: 0.900042]\n",
      "epoch:18 step:14219[D loss: 0.439377, acc: 56.25%, op_acc: 37.50%] [G loss: 0.876306]\n",
      "epoch:18 step:14220[D loss: 0.418577, acc: 52.34%, op_acc: 44.53%] [G loss: 0.924623]\n",
      "epoch:18 step:14221[D loss: 0.422260, acc: 61.72%, op_acc: 37.50%] [G loss: 0.935936]\n",
      "epoch:18 step:14222[D loss: 0.430603, acc: 62.50%, op_acc: 40.62%] [G loss: 0.904223]\n",
      "epoch:18 step:14223[D loss: 0.407451, acc: 61.72%, op_acc: 39.84%] [G loss: 0.839181]\n",
      "epoch:18 step:14224[D loss: 0.447466, acc: 53.12%, op_acc: 39.84%] [G loss: 0.871074]\n",
      "epoch:18 step:14225[D loss: 0.405777, acc: 60.16%, op_acc: 42.19%] [G loss: 0.940912]\n",
      "epoch:18 step:14226[D loss: 0.407388, acc: 60.16%, op_acc: 44.53%] [G loss: 0.857201]\n",
      "epoch:18 step:14227[D loss: 0.465640, acc: 48.44%, op_acc: 39.06%] [G loss: 0.877231]\n",
      "epoch:18 step:14228[D loss: 0.449391, acc: 53.91%, op_acc: 42.19%] [G loss: 0.877012]\n",
      "epoch:18 step:14229[D loss: 0.432708, acc: 60.94%, op_acc: 38.28%] [G loss: 0.917748]\n",
      "epoch:18 step:14230[D loss: 0.415103, acc: 60.16%, op_acc: 40.62%] [G loss: 0.888474]\n",
      "epoch:18 step:14231[D loss: 0.453882, acc: 54.69%, op_acc: 35.16%] [G loss: 0.848984]\n",
      "epoch:18 step:14232[D loss: 0.492407, acc: 42.19%, op_acc: 33.59%] [G loss: 0.869170]\n",
      "epoch:18 step:14233[D loss: 0.406076, acc: 66.41%, op_acc: 37.50%] [G loss: 0.931813]\n",
      "epoch:18 step:14234[D loss: 0.448961, acc: 53.12%, op_acc: 44.53%] [G loss: 0.879370]\n",
      "epoch:18 step:14235[D loss: 0.384261, acc: 70.31%, op_acc: 35.16%] [G loss: 0.914961]\n",
      "epoch:18 step:14236[D loss: 0.447908, acc: 50.00%, op_acc: 39.84%] [G loss: 0.904788]\n",
      "epoch:18 step:14237[D loss: 0.422922, acc: 58.59%, op_acc: 40.62%] [G loss: 0.856337]\n",
      "epoch:18 step:14238[D loss: 0.443497, acc: 53.12%, op_acc: 38.28%] [G loss: 0.908965]\n",
      "epoch:18 step:14239[D loss: 0.430701, acc: 57.81%, op_acc: 42.97%] [G loss: 0.853413]\n",
      "epoch:18 step:14240[D loss: 0.414750, acc: 60.94%, op_acc: 39.84%] [G loss: 0.883907]\n",
      "epoch:18 step:14241[D loss: 0.408852, acc: 64.06%, op_acc: 38.28%] [G loss: 0.894719]\n",
      "epoch:18 step:14242[D loss: 0.427115, acc: 60.16%, op_acc: 36.72%] [G loss: 0.974778]\n",
      "epoch:18 step:14243[D loss: 0.435208, acc: 63.28%, op_acc: 32.03%] [G loss: 0.974215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14244[D loss: 0.404530, acc: 64.06%, op_acc: 38.28%] [G loss: 0.978760]\n",
      "epoch:18 step:14245[D loss: 0.427293, acc: 55.47%, op_acc: 42.97%] [G loss: 0.923132]\n",
      "epoch:18 step:14246[D loss: 0.428480, acc: 54.69%, op_acc: 36.72%] [G loss: 0.908270]\n",
      "epoch:18 step:14247[D loss: 0.434895, acc: 53.91%, op_acc: 39.84%] [G loss: 0.836426]\n",
      "epoch:18 step:14248[D loss: 0.431143, acc: 60.16%, op_acc: 36.72%] [G loss: 0.932106]\n",
      "epoch:18 step:14249[D loss: 0.393279, acc: 65.62%, op_acc: 42.19%] [G loss: 0.814508]\n",
      "epoch:18 step:14250[D loss: 0.426719, acc: 58.59%, op_acc: 40.62%] [G loss: 0.861617]\n",
      "##############\n",
      "[0.83336217 0.83276497 0.80621698 0.81564325 0.76244718 0.8006675\n",
      " 0.88246289 0.82567283 0.81859815 0.8077373 ]\n",
      "##########\n",
      "epoch:18 step:14251[D loss: 0.434900, acc: 62.50%, op_acc: 35.94%] [G loss: 0.947688]\n",
      "epoch:18 step:14252[D loss: 0.397952, acc: 64.06%, op_acc: 44.53%] [G loss: 0.898041]\n",
      "epoch:18 step:14253[D loss: 0.455916, acc: 50.78%, op_acc: 38.28%] [G loss: 0.763311]\n",
      "epoch:18 step:14254[D loss: 0.404186, acc: 65.62%, op_acc: 35.94%] [G loss: 0.979354]\n",
      "epoch:18 step:14255[D loss: 0.477874, acc: 52.34%, op_acc: 32.03%] [G loss: 0.848131]\n",
      "epoch:18 step:14256[D loss: 0.466271, acc: 50.78%, op_acc: 39.06%] [G loss: 0.810512]\n",
      "epoch:18 step:14257[D loss: 0.430504, acc: 59.38%, op_acc: 36.72%] [G loss: 0.877859]\n",
      "epoch:18 step:14258[D loss: 0.451228, acc: 57.81%, op_acc: 39.06%] [G loss: 0.916318]\n",
      "epoch:18 step:14259[D loss: 0.456697, acc: 49.22%, op_acc: 35.16%] [G loss: 0.916062]\n",
      "epoch:18 step:14260[D loss: 0.448346, acc: 60.94%, op_acc: 32.03%] [G loss: 0.835409]\n",
      "epoch:18 step:14261[D loss: 0.453749, acc: 58.59%, op_acc: 39.06%] [G loss: 0.953951]\n",
      "epoch:18 step:14262[D loss: 0.418658, acc: 66.41%, op_acc: 40.62%] [G loss: 0.937454]\n",
      "epoch:18 step:14263[D loss: 0.442514, acc: 57.81%, op_acc: 39.06%] [G loss: 0.875373]\n",
      "epoch:18 step:14264[D loss: 0.436080, acc: 60.16%, op_acc: 31.25%] [G loss: 0.966656]\n",
      "epoch:18 step:14265[D loss: 0.399737, acc: 67.19%, op_acc: 38.28%] [G loss: 0.897801]\n",
      "epoch:18 step:14266[D loss: 0.430903, acc: 60.16%, op_acc: 32.81%] [G loss: 0.883596]\n",
      "epoch:18 step:14267[D loss: 0.433738, acc: 56.25%, op_acc: 39.06%] [G loss: 0.842552]\n",
      "epoch:18 step:14268[D loss: 0.427189, acc: 58.59%, op_acc: 39.06%] [G loss: 0.881100]\n",
      "epoch:18 step:14269[D loss: 0.416648, acc: 57.81%, op_acc: 42.97%] [G loss: 0.886262]\n",
      "epoch:18 step:14270[D loss: 0.453670, acc: 52.34%, op_acc: 38.28%] [G loss: 0.888868]\n",
      "epoch:18 step:14271[D loss: 0.405225, acc: 64.06%, op_acc: 38.28%] [G loss: 0.926699]\n",
      "epoch:18 step:14272[D loss: 0.435542, acc: 57.81%, op_acc: 35.16%] [G loss: 0.850182]\n",
      "epoch:18 step:14273[D loss: 0.452431, acc: 61.72%, op_acc: 34.38%] [G loss: 0.913504]\n",
      "epoch:18 step:14274[D loss: 0.408919, acc: 64.06%, op_acc: 35.94%] [G loss: 0.884917]\n",
      "epoch:18 step:14275[D loss: 0.393287, acc: 75.00%, op_acc: 40.62%] [G loss: 0.957746]\n",
      "epoch:18 step:14276[D loss: 0.433062, acc: 57.81%, op_acc: 40.62%] [G loss: 0.823563]\n",
      "epoch:18 step:14277[D loss: 0.392292, acc: 67.19%, op_acc: 40.62%] [G loss: 0.925279]\n",
      "epoch:18 step:14278[D loss: 0.446539, acc: 56.25%, op_acc: 34.38%] [G loss: 0.867665]\n",
      "epoch:18 step:14279[D loss: 0.429774, acc: 58.59%, op_acc: 42.97%] [G loss: 0.899565]\n",
      "epoch:18 step:14280[D loss: 0.444926, acc: 59.38%, op_acc: 37.50%] [G loss: 0.829530]\n",
      "epoch:18 step:14281[D loss: 0.430810, acc: 64.84%, op_acc: 38.28%] [G loss: 0.918116]\n",
      "epoch:18 step:14282[D loss: 0.440023, acc: 56.25%, op_acc: 40.62%] [G loss: 0.824281]\n",
      "epoch:18 step:14283[D loss: 0.420808, acc: 64.06%, op_acc: 34.38%] [G loss: 0.827080]\n",
      "epoch:18 step:14284[D loss: 0.440496, acc: 57.81%, op_acc: 43.75%] [G loss: 0.778096]\n",
      "epoch:18 step:14285[D loss: 0.433583, acc: 56.25%, op_acc: 36.72%] [G loss: 0.876952]\n",
      "epoch:18 step:14286[D loss: 0.434062, acc: 56.25%, op_acc: 35.94%] [G loss: 0.872732]\n",
      "epoch:18 step:14287[D loss: 0.419319, acc: 59.38%, op_acc: 33.59%] [G loss: 0.868678]\n",
      "epoch:18 step:14288[D loss: 0.445253, acc: 59.38%, op_acc: 38.28%] [G loss: 0.962205]\n",
      "epoch:18 step:14289[D loss: 0.431295, acc: 57.03%, op_acc: 40.62%] [G loss: 0.836372]\n",
      "epoch:18 step:14290[D loss: 0.432205, acc: 52.34%, op_acc: 40.62%] [G loss: 0.843540]\n",
      "epoch:18 step:14291[D loss: 0.421536, acc: 64.84%, op_acc: 39.84%] [G loss: 0.924382]\n",
      "epoch:18 step:14292[D loss: 0.425291, acc: 60.94%, op_acc: 34.38%] [G loss: 0.884088]\n",
      "epoch:18 step:14293[D loss: 0.433178, acc: 57.03%, op_acc: 38.28%] [G loss: 0.920862]\n",
      "epoch:18 step:14294[D loss: 0.420891, acc: 62.50%, op_acc: 39.06%] [G loss: 0.866540]\n",
      "epoch:18 step:14295[D loss: 0.433792, acc: 60.16%, op_acc: 36.72%] [G loss: 0.862038]\n",
      "epoch:18 step:14296[D loss: 0.440009, acc: 57.81%, op_acc: 35.16%] [G loss: 0.902492]\n",
      "epoch:18 step:14297[D loss: 0.404923, acc: 61.72%, op_acc: 39.06%] [G loss: 0.841939]\n",
      "epoch:18 step:14298[D loss: 0.438463, acc: 54.69%, op_acc: 38.28%] [G loss: 0.897107]\n",
      "epoch:18 step:14299[D loss: 0.420055, acc: 61.72%, op_acc: 45.31%] [G loss: 0.777201]\n",
      "epoch:18 step:14300[D loss: 0.403702, acc: 67.19%, op_acc: 37.50%] [G loss: 0.826289]\n",
      "##############\n",
      "[0.84332954 0.89117751 0.81401336 0.81288835 0.80953277 0.83699621\n",
      " 0.89520852 0.8241114  0.82550089 0.82109625]\n",
      "##########\n",
      "epoch:18 step:14301[D loss: 0.415615, acc: 57.81%, op_acc: 41.41%] [G loss: 0.940764]\n",
      "epoch:18 step:14302[D loss: 0.448978, acc: 60.94%, op_acc: 34.38%] [G loss: 0.883432]\n",
      "epoch:18 step:14303[D loss: 0.422498, acc: 57.81%, op_acc: 43.75%] [G loss: 0.838881]\n",
      "epoch:18 step:14304[D loss: 0.453011, acc: 55.47%, op_acc: 37.50%] [G loss: 0.785696]\n",
      "epoch:18 step:14305[D loss: 0.416778, acc: 56.25%, op_acc: 38.28%] [G loss: 0.851130]\n",
      "epoch:18 step:14306[D loss: 0.438308, acc: 58.59%, op_acc: 39.84%] [G loss: 0.842914]\n",
      "epoch:18 step:14307[D loss: 0.438764, acc: 58.59%, op_acc: 41.41%] [G loss: 0.882284]\n",
      "epoch:18 step:14308[D loss: 0.449823, acc: 57.03%, op_acc: 34.38%] [G loss: 0.809484]\n",
      "epoch:18 step:14309[D loss: 0.420822, acc: 62.50%, op_acc: 40.62%] [G loss: 0.870258]\n",
      "epoch:18 step:14310[D loss: 0.424304, acc: 59.38%, op_acc: 40.62%] [G loss: 0.860373]\n",
      "epoch:18 step:14311[D loss: 0.432703, acc: 59.38%, op_acc: 40.62%] [G loss: 0.921149]\n",
      "epoch:18 step:14312[D loss: 0.436470, acc: 59.38%, op_acc: 35.16%] [G loss: 0.824989]\n",
      "epoch:18 step:14313[D loss: 0.430898, acc: 58.59%, op_acc: 38.28%] [G loss: 0.863196]\n",
      "epoch:18 step:14314[D loss: 0.434751, acc: 50.78%, op_acc: 39.06%] [G loss: 0.921319]\n",
      "epoch:18 step:14315[D loss: 0.442219, acc: 52.34%, op_acc: 33.59%] [G loss: 0.790471]\n",
      "epoch:18 step:14316[D loss: 0.405715, acc: 60.16%, op_acc: 40.62%] [G loss: 0.821629]\n",
      "epoch:18 step:14317[D loss: 0.452171, acc: 64.06%, op_acc: 32.03%] [G loss: 0.905462]\n",
      "epoch:18 step:14318[D loss: 0.429611, acc: 67.97%, op_acc: 37.50%] [G loss: 0.864175]\n",
      "epoch:18 step:14319[D loss: 0.435010, acc: 57.03%, op_acc: 42.97%] [G loss: 0.964598]\n",
      "epoch:18 step:14320[D loss: 0.416747, acc: 59.38%, op_acc: 33.59%] [G loss: 0.966653]\n",
      "epoch:18 step:14321[D loss: 0.422522, acc: 57.81%, op_acc: 35.94%] [G loss: 0.937486]\n",
      "epoch:18 step:14322[D loss: 0.449349, acc: 46.88%, op_acc: 35.94%] [G loss: 0.880495]\n",
      "epoch:18 step:14323[D loss: 0.400344, acc: 68.75%, op_acc: 38.28%] [G loss: 0.888087]\n",
      "epoch:18 step:14324[D loss: 0.434343, acc: 51.56%, op_acc: 36.72%] [G loss: 0.830267]\n",
      "epoch:18 step:14325[D loss: 0.476609, acc: 41.41%, op_acc: 36.72%] [G loss: 0.881237]\n",
      "epoch:18 step:14326[D loss: 0.418620, acc: 61.72%, op_acc: 37.50%] [G loss: 0.843751]\n",
      "epoch:18 step:14327[D loss: 0.412232, acc: 60.16%, op_acc: 39.84%] [G loss: 0.883084]\n",
      "epoch:18 step:14328[D loss: 0.420837, acc: 63.28%, op_acc: 41.41%] [G loss: 0.960564]\n",
      "epoch:18 step:14329[D loss: 0.413140, acc: 67.97%, op_acc: 39.06%] [G loss: 0.888795]\n",
      "epoch:18 step:14330[D loss: 0.416180, acc: 60.16%, op_acc: 35.94%] [G loss: 0.891331]\n",
      "epoch:18 step:14331[D loss: 0.431013, acc: 58.59%, op_acc: 35.94%] [G loss: 0.875601]\n",
      "epoch:18 step:14332[D loss: 0.439120, acc: 50.78%, op_acc: 36.72%] [G loss: 0.861237]\n",
      "epoch:18 step:14333[D loss: 0.473074, acc: 45.31%, op_acc: 39.84%] [G loss: 0.833454]\n",
      "epoch:18 step:14334[D loss: 0.454952, acc: 50.00%, op_acc: 38.28%] [G loss: 0.849829]\n",
      "epoch:18 step:14335[D loss: 0.439852, acc: 57.81%, op_acc: 39.06%] [G loss: 0.836855]\n",
      "epoch:18 step:14336[D loss: 0.440997, acc: 65.62%, op_acc: 35.16%] [G loss: 0.872442]\n",
      "epoch:18 step:14337[D loss: 0.454176, acc: 57.81%, op_acc: 35.94%] [G loss: 0.894485]\n",
      "epoch:18 step:14338[D loss: 0.411446, acc: 66.41%, op_acc: 39.06%] [G loss: 0.891101]\n",
      "epoch:18 step:14339[D loss: 0.439430, acc: 53.91%, op_acc: 40.62%] [G loss: 0.792167]\n",
      "epoch:18 step:14340[D loss: 0.422788, acc: 60.16%, op_acc: 38.28%] [G loss: 0.933112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14341[D loss: 0.395986, acc: 61.72%, op_acc: 42.19%] [G loss: 0.896495]\n",
      "epoch:18 step:14342[D loss: 0.398906, acc: 62.50%, op_acc: 46.88%] [G loss: 0.843631]\n",
      "epoch:18 step:14343[D loss: 0.402279, acc: 70.31%, op_acc: 36.72%] [G loss: 0.880322]\n",
      "epoch:18 step:14344[D loss: 0.429845, acc: 60.94%, op_acc: 38.28%] [G loss: 0.862578]\n",
      "epoch:18 step:14345[D loss: 0.446711, acc: 47.66%, op_acc: 39.84%] [G loss: 0.891991]\n",
      "epoch:18 step:14346[D loss: 0.439338, acc: 57.81%, op_acc: 37.50%] [G loss: 0.854754]\n",
      "epoch:18 step:14347[D loss: 0.457598, acc: 56.25%, op_acc: 31.25%] [G loss: 0.846253]\n",
      "epoch:18 step:14348[D loss: 0.449804, acc: 55.47%, op_acc: 32.81%] [G loss: 0.854078]\n",
      "epoch:18 step:14349[D loss: 0.451520, acc: 53.91%, op_acc: 37.50%] [G loss: 0.877681]\n",
      "epoch:18 step:14350[D loss: 0.451040, acc: 57.81%, op_acc: 32.81%] [G loss: 0.908405]\n",
      "##############\n",
      "[0.84480598 0.86999163 0.8017942  0.79757618 0.81229187 0.8350142\n",
      " 0.86005969 0.80976624 0.79885704 0.84518774]\n",
      "##########\n",
      "epoch:18 step:14351[D loss: 0.451960, acc: 47.66%, op_acc: 36.72%] [G loss: 0.898293]\n",
      "epoch:18 step:14352[D loss: 0.423179, acc: 58.59%, op_acc: 36.72%] [G loss: 0.892593]\n",
      "epoch:18 step:14353[D loss: 0.421920, acc: 56.25%, op_acc: 40.62%] [G loss: 0.851560]\n",
      "epoch:18 step:14354[D loss: 0.434352, acc: 52.34%, op_acc: 45.31%] [G loss: 0.905778]\n",
      "epoch:18 step:14355[D loss: 0.426322, acc: 60.16%, op_acc: 43.75%] [G loss: 0.946804]\n",
      "epoch:18 step:14356[D loss: 0.445502, acc: 60.94%, op_acc: 46.09%] [G loss: 0.890579]\n",
      "epoch:18 step:14357[D loss: 0.449026, acc: 55.47%, op_acc: 31.25%] [G loss: 0.921785]\n",
      "epoch:18 step:14358[D loss: 0.438398, acc: 57.81%, op_acc: 37.50%] [G loss: 0.927382]\n",
      "epoch:18 step:14359[D loss: 0.444599, acc: 53.91%, op_acc: 36.72%] [G loss: 0.899585]\n",
      "epoch:18 step:14360[D loss: 0.427619, acc: 57.81%, op_acc: 41.41%] [G loss: 0.832314]\n",
      "epoch:18 step:14361[D loss: 0.420518, acc: 57.03%, op_acc: 37.50%] [G loss: 0.867168]\n",
      "epoch:18 step:14362[D loss: 0.444731, acc: 58.59%, op_acc: 37.50%] [G loss: 0.898604]\n",
      "epoch:18 step:14363[D loss: 0.429319, acc: 60.94%, op_acc: 35.16%] [G loss: 0.898046]\n",
      "epoch:18 step:14364[D loss: 0.437137, acc: 60.94%, op_acc: 34.38%] [G loss: 0.876165]\n",
      "epoch:18 step:14365[D loss: 0.429179, acc: 60.94%, op_acc: 38.28%] [G loss: 0.959769]\n",
      "epoch:18 step:14366[D loss: 0.434364, acc: 60.94%, op_acc: 34.38%] [G loss: 0.885069]\n",
      "epoch:18 step:14367[D loss: 0.461378, acc: 53.91%, op_acc: 37.50%] [G loss: 0.848894]\n",
      "epoch:18 step:14368[D loss: 0.433556, acc: 60.16%, op_acc: 34.38%] [G loss: 0.862356]\n",
      "epoch:18 step:14369[D loss: 0.448563, acc: 55.47%, op_acc: 35.94%] [G loss: 0.871949]\n",
      "epoch:18 step:14370[D loss: 0.416608, acc: 68.75%, op_acc: 34.38%] [G loss: 0.865161]\n",
      "epoch:18 step:14371[D loss: 0.432324, acc: 61.72%, op_acc: 36.72%] [G loss: 0.927786]\n",
      "epoch:18 step:14372[D loss: 0.427837, acc: 62.50%, op_acc: 35.94%] [G loss: 0.911138]\n",
      "epoch:18 step:14373[D loss: 0.460312, acc: 53.91%, op_acc: 29.69%] [G loss: 0.825797]\n",
      "epoch:18 step:14374[D loss: 0.431913, acc: 54.69%, op_acc: 37.50%] [G loss: 0.796125]\n",
      "epoch:18 step:14375[D loss: 0.435649, acc: 56.25%, op_acc: 41.41%] [G loss: 0.859049]\n",
      "epoch:18 step:14376[D loss: 0.441699, acc: 58.59%, op_acc: 37.50%] [G loss: 0.836123]\n",
      "epoch:18 step:14377[D loss: 0.415238, acc: 61.72%, op_acc: 38.28%] [G loss: 0.928411]\n",
      "epoch:18 step:14378[D loss: 0.438577, acc: 64.06%, op_acc: 29.69%] [G loss: 0.901966]\n",
      "epoch:18 step:14379[D loss: 0.441085, acc: 59.38%, op_acc: 34.38%] [G loss: 0.980028]\n",
      "epoch:18 step:14380[D loss: 0.445711, acc: 53.12%, op_acc: 36.72%] [G loss: 0.907071]\n",
      "epoch:18 step:14381[D loss: 0.428594, acc: 55.47%, op_acc: 42.19%] [G loss: 0.854246]\n",
      "epoch:18 step:14382[D loss: 0.442039, acc: 60.94%, op_acc: 35.94%] [G loss: 0.871124]\n",
      "epoch:18 step:14383[D loss: 0.407557, acc: 60.94%, op_acc: 39.06%] [G loss: 0.830674]\n",
      "epoch:18 step:14384[D loss: 0.430971, acc: 53.91%, op_acc: 37.50%] [G loss: 0.899449]\n",
      "epoch:18 step:14385[D loss: 0.419985, acc: 61.72%, op_acc: 33.59%] [G loss: 0.807179]\n",
      "epoch:18 step:14386[D loss: 0.440072, acc: 54.69%, op_acc: 38.28%] [G loss: 0.868337]\n",
      "epoch:18 step:14387[D loss: 0.448990, acc: 50.00%, op_acc: 36.72%] [G loss: 0.918669]\n",
      "epoch:18 step:14388[D loss: 0.409782, acc: 63.28%, op_acc: 41.41%] [G loss: 0.900306]\n",
      "epoch:18 step:14389[D loss: 0.454352, acc: 55.47%, op_acc: 36.72%] [G loss: 0.868094]\n",
      "epoch:18 step:14390[D loss: 0.408818, acc: 63.28%, op_acc: 41.41%] [G loss: 0.877620]\n",
      "epoch:18 step:14391[D loss: 0.401527, acc: 64.06%, op_acc: 39.06%] [G loss: 0.844561]\n",
      "epoch:18 step:14392[D loss: 0.418826, acc: 57.03%, op_acc: 39.06%] [G loss: 0.988163]\n",
      "epoch:18 step:14393[D loss: 0.450711, acc: 55.47%, op_acc: 39.84%] [G loss: 0.919606]\n",
      "epoch:18 step:14394[D loss: 0.419818, acc: 61.72%, op_acc: 39.06%] [G loss: 0.915130]\n",
      "epoch:18 step:14395[D loss: 0.453831, acc: 61.72%, op_acc: 28.12%] [G loss: 0.862129]\n",
      "epoch:18 step:14396[D loss: 0.382936, acc: 67.97%, op_acc: 38.28%] [G loss: 0.919038]\n",
      "epoch:18 step:14397[D loss: 0.404790, acc: 67.19%, op_acc: 37.50%] [G loss: 0.842919]\n",
      "epoch:18 step:14398[D loss: 0.434594, acc: 60.94%, op_acc: 35.16%] [G loss: 0.857891]\n",
      "epoch:18 step:14399[D loss: 0.433492, acc: 60.94%, op_acc: 34.38%] [G loss: 0.897153]\n",
      "epoch:18 step:14400[D loss: 0.455595, acc: 59.38%, op_acc: 31.25%] [G loss: 0.898426]\n",
      "##############\n",
      "[0.85826799 0.88064726 0.8073705  0.79213681 0.80410057 0.8355789\n",
      " 0.88587296 0.82602103 0.81602537 0.83558827]\n",
      "##########\n",
      "epoch:18 step:14401[D loss: 0.440289, acc: 57.81%, op_acc: 35.16%] [G loss: 0.801038]\n",
      "epoch:18 step:14402[D loss: 0.411188, acc: 62.50%, op_acc: 35.16%] [G loss: 0.859957]\n",
      "epoch:18 step:14403[D loss: 0.436477, acc: 60.94%, op_acc: 37.50%] [G loss: 0.860448]\n",
      "epoch:18 step:14404[D loss: 0.439885, acc: 52.34%, op_acc: 36.72%] [G loss: 0.873457]\n",
      "epoch:18 step:14405[D loss: 0.410845, acc: 64.06%, op_acc: 42.19%] [G loss: 0.968267]\n",
      "epoch:18 step:14406[D loss: 0.434765, acc: 64.06%, op_acc: 35.16%] [G loss: 0.826439]\n",
      "epoch:18 step:14407[D loss: 0.408877, acc: 66.41%, op_acc: 35.94%] [G loss: 0.873857]\n",
      "epoch:18 step:14408[D loss: 0.438507, acc: 62.50%, op_acc: 32.81%] [G loss: 0.894400]\n",
      "epoch:18 step:14409[D loss: 0.425148, acc: 59.38%, op_acc: 36.72%] [G loss: 0.876534]\n",
      "epoch:18 step:14410[D loss: 0.440502, acc: 58.59%, op_acc: 37.50%] [G loss: 0.869852]\n",
      "epoch:18 step:14411[D loss: 0.411676, acc: 56.25%, op_acc: 42.19%] [G loss: 0.866198]\n",
      "epoch:18 step:14412[D loss: 0.444348, acc: 52.34%, op_acc: 39.84%] [G loss: 0.861705]\n",
      "epoch:18 step:14413[D loss: 0.436530, acc: 56.25%, op_acc: 42.97%] [G loss: 0.854037]\n",
      "epoch:18 step:14414[D loss: 0.427580, acc: 58.59%, op_acc: 38.28%] [G loss: 0.900527]\n",
      "epoch:18 step:14415[D loss: 0.417038, acc: 65.62%, op_acc: 39.06%] [G loss: 0.909683]\n",
      "epoch:18 step:14416[D loss: 0.451463, acc: 51.56%, op_acc: 40.62%] [G loss: 0.955920]\n",
      "epoch:18 step:14417[D loss: 0.418428, acc: 61.72%, op_acc: 37.50%] [G loss: 0.845466]\n",
      "epoch:18 step:14418[D loss: 0.424434, acc: 60.16%, op_acc: 40.62%] [G loss: 0.878288]\n",
      "epoch:18 step:14419[D loss: 0.395886, acc: 69.53%, op_acc: 45.31%] [G loss: 0.960823]\n",
      "epoch:18 step:14420[D loss: 0.376829, acc: 68.75%, op_acc: 44.53%] [G loss: 0.963758]\n",
      "epoch:18 step:14421[D loss: 0.424627, acc: 64.84%, op_acc: 34.38%] [G loss: 0.876659]\n",
      "epoch:18 step:14422[D loss: 0.428799, acc: 60.16%, op_acc: 36.72%] [G loss: 0.885599]\n",
      "epoch:18 step:14423[D loss: 0.393112, acc: 60.16%, op_acc: 41.41%] [G loss: 0.869676]\n",
      "epoch:18 step:14424[D loss: 0.430169, acc: 57.03%, op_acc: 41.41%] [G loss: 0.871089]\n",
      "epoch:18 step:14425[D loss: 0.435374, acc: 59.38%, op_acc: 36.72%] [G loss: 0.945327]\n",
      "epoch:18 step:14426[D loss: 0.411957, acc: 65.62%, op_acc: 39.06%] [G loss: 0.911410]\n",
      "epoch:18 step:14427[D loss: 0.414152, acc: 69.53%, op_acc: 36.72%] [G loss: 0.958110]\n",
      "epoch:18 step:14428[D loss: 0.450954, acc: 51.56%, op_acc: 35.16%] [G loss: 0.843534]\n",
      "epoch:18 step:14429[D loss: 0.397989, acc: 60.16%, op_acc: 40.62%] [G loss: 0.850327]\n",
      "epoch:18 step:14430[D loss: 0.422224, acc: 60.94%, op_acc: 39.84%] [G loss: 0.799714]\n",
      "epoch:18 step:14431[D loss: 0.434293, acc: 55.47%, op_acc: 39.06%] [G loss: 0.883317]\n",
      "epoch:18 step:14432[D loss: 0.424594, acc: 62.50%, op_acc: 34.38%] [G loss: 0.902935]\n",
      "epoch:18 step:14433[D loss: 0.453726, acc: 57.03%, op_acc: 35.16%] [G loss: 0.915631]\n",
      "epoch:18 step:14434[D loss: 0.409647, acc: 61.72%, op_acc: 41.41%] [G loss: 0.869311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14435[D loss: 0.436248, acc: 57.03%, op_acc: 39.06%] [G loss: 0.832224]\n",
      "epoch:18 step:14436[D loss: 0.447288, acc: 53.91%, op_acc: 42.19%] [G loss: 0.899765]\n",
      "epoch:18 step:14437[D loss: 0.407874, acc: 64.06%, op_acc: 42.97%] [G loss: 0.941084]\n",
      "epoch:18 step:14438[D loss: 0.421963, acc: 64.84%, op_acc: 41.41%] [G loss: 0.859566]\n",
      "epoch:18 step:14439[D loss: 0.411752, acc: 67.97%, op_acc: 42.19%] [G loss: 0.930935]\n",
      "epoch:18 step:14440[D loss: 0.397640, acc: 67.97%, op_acc: 39.84%] [G loss: 0.862270]\n",
      "epoch:18 step:14441[D loss: 0.439406, acc: 51.56%, op_acc: 42.19%] [G loss: 0.899882]\n",
      "epoch:18 step:14442[D loss: 0.416638, acc: 60.94%, op_acc: 36.72%] [G loss: 0.875458]\n",
      "epoch:18 step:14443[D loss: 0.414574, acc: 56.25%, op_acc: 42.19%] [G loss: 0.937457]\n",
      "epoch:18 step:14444[D loss: 0.411046, acc: 62.50%, op_acc: 41.41%] [G loss: 0.945344]\n",
      "epoch:18 step:14445[D loss: 0.444307, acc: 57.81%, op_acc: 39.06%] [G loss: 0.920289]\n",
      "epoch:18 step:14446[D loss: 0.428981, acc: 63.28%, op_acc: 39.84%] [G loss: 0.908709]\n",
      "epoch:18 step:14447[D loss: 0.460226, acc: 57.81%, op_acc: 33.59%] [G loss: 0.923349]\n",
      "epoch:18 step:14448[D loss: 0.390825, acc: 61.72%, op_acc: 40.62%] [G loss: 0.976202]\n",
      "epoch:18 step:14449[D loss: 0.419282, acc: 60.16%, op_acc: 37.50%] [G loss: 0.845060]\n",
      "epoch:18 step:14450[D loss: 0.434578, acc: 55.47%, op_acc: 37.50%] [G loss: 0.862777]\n",
      "##############\n",
      "[0.83481007 0.85299057 0.82263426 0.81062908 0.78520271 0.81179604\n",
      " 0.87871006 0.82510518 0.80299274 0.84307175]\n",
      "##########\n",
      "epoch:18 step:14451[D loss: 0.442995, acc: 55.47%, op_acc: 37.50%] [G loss: 0.926778]\n",
      "epoch:18 step:14452[D loss: 0.430300, acc: 54.69%, op_acc: 40.62%] [G loss: 0.928342]\n",
      "epoch:18 step:14453[D loss: 0.433411, acc: 61.72%, op_acc: 39.84%] [G loss: 0.865820]\n",
      "epoch:18 step:14454[D loss: 0.444877, acc: 54.69%, op_acc: 42.19%] [G loss: 0.856170]\n",
      "epoch:18 step:14455[D loss: 0.456776, acc: 46.09%, op_acc: 37.50%] [G loss: 0.881759]\n",
      "epoch:18 step:14456[D loss: 0.439504, acc: 58.59%, op_acc: 36.72%] [G loss: 0.845377]\n",
      "epoch:18 step:14457[D loss: 0.411784, acc: 59.38%, op_acc: 43.75%] [G loss: 0.867247]\n",
      "epoch:18 step:14458[D loss: 0.418668, acc: 66.41%, op_acc: 35.94%] [G loss: 0.839591]\n",
      "epoch:18 step:14459[D loss: 0.401743, acc: 67.97%, op_acc: 36.72%] [G loss: 0.877917]\n",
      "epoch:18 step:14460[D loss: 0.453999, acc: 53.91%, op_acc: 35.16%] [G loss: 0.865738]\n",
      "epoch:18 step:14461[D loss: 0.426701, acc: 59.38%, op_acc: 35.94%] [G loss: 0.926969]\n",
      "epoch:18 step:14462[D loss: 0.404644, acc: 64.06%, op_acc: 39.84%] [G loss: 0.893607]\n",
      "epoch:18 step:14463[D loss: 0.452372, acc: 54.69%, op_acc: 40.62%] [G loss: 0.850420]\n",
      "epoch:18 step:14464[D loss: 0.450089, acc: 49.22%, op_acc: 39.84%] [G loss: 0.899916]\n",
      "epoch:18 step:14465[D loss: 0.419893, acc: 62.50%, op_acc: 43.75%] [G loss: 0.821697]\n",
      "epoch:18 step:14466[D loss: 0.398241, acc: 67.97%, op_acc: 41.41%] [G loss: 0.859779]\n",
      "epoch:18 step:14467[D loss: 0.441182, acc: 57.81%, op_acc: 39.84%] [G loss: 0.861073]\n",
      "epoch:18 step:14468[D loss: 0.430995, acc: 53.91%, op_acc: 40.62%] [G loss: 0.957187]\n",
      "epoch:18 step:14469[D loss: 0.413687, acc: 60.16%, op_acc: 39.84%] [G loss: 0.996359]\n",
      "epoch:18 step:14470[D loss: 0.433574, acc: 49.22%, op_acc: 36.72%] [G loss: 0.854292]\n",
      "epoch:18 step:14471[D loss: 0.430477, acc: 56.25%, op_acc: 39.06%] [G loss: 0.945191]\n",
      "epoch:18 step:14472[D loss: 0.418380, acc: 60.94%, op_acc: 39.84%] [G loss: 0.890977]\n",
      "epoch:18 step:14473[D loss: 0.439160, acc: 55.47%, op_acc: 36.72%] [G loss: 0.848220]\n",
      "epoch:18 step:14474[D loss: 0.406600, acc: 69.53%, op_acc: 37.50%] [G loss: 0.868099]\n",
      "epoch:18 step:14475[D loss: 0.429915, acc: 59.38%, op_acc: 37.50%] [G loss: 0.906670]\n",
      "epoch:18 step:14476[D loss: 0.433106, acc: 59.38%, op_acc: 39.06%] [G loss: 0.830563]\n",
      "epoch:18 step:14477[D loss: 0.414934, acc: 65.62%, op_acc: 37.50%] [G loss: 0.889235]\n",
      "epoch:18 step:14478[D loss: 0.438019, acc: 55.47%, op_acc: 38.28%] [G loss: 0.963878]\n",
      "epoch:18 step:14479[D loss: 0.451585, acc: 52.34%, op_acc: 36.72%] [G loss: 0.938539]\n",
      "epoch:18 step:14480[D loss: 0.449606, acc: 47.66%, op_acc: 39.06%] [G loss: 0.795219]\n",
      "epoch:18 step:14481[D loss: 0.466081, acc: 50.78%, op_acc: 34.38%] [G loss: 0.899164]\n",
      "epoch:18 step:14482[D loss: 0.465734, acc: 56.25%, op_acc: 35.16%] [G loss: 0.868948]\n",
      "epoch:18 step:14483[D loss: 0.453288, acc: 57.03%, op_acc: 31.25%] [G loss: 0.881568]\n",
      "epoch:18 step:14484[D loss: 0.449029, acc: 55.47%, op_acc: 38.28%] [G loss: 0.908688]\n",
      "epoch:18 step:14485[D loss: 0.428654, acc: 66.41%, op_acc: 33.59%] [G loss: 0.820325]\n",
      "epoch:18 step:14486[D loss: 0.411977, acc: 63.28%, op_acc: 44.53%] [G loss: 0.885262]\n",
      "epoch:18 step:14487[D loss: 0.440191, acc: 58.59%, op_acc: 33.59%] [G loss: 0.833171]\n",
      "epoch:18 step:14488[D loss: 0.397621, acc: 68.75%, op_acc: 40.62%] [G loss: 0.826769]\n",
      "epoch:18 step:14489[D loss: 0.443826, acc: 58.59%, op_acc: 31.25%] [G loss: 0.869267]\n",
      "epoch:18 step:14490[D loss: 0.413682, acc: 57.81%, op_acc: 39.84%] [G loss: 0.852306]\n",
      "epoch:18 step:14491[D loss: 0.406225, acc: 59.38%, op_acc: 35.94%] [G loss: 0.869555]\n",
      "epoch:18 step:14492[D loss: 0.411842, acc: 62.50%, op_acc: 37.50%] [G loss: 0.901062]\n",
      "epoch:18 step:14493[D loss: 0.432579, acc: 54.69%, op_acc: 38.28%] [G loss: 0.891065]\n",
      "epoch:18 step:14494[D loss: 0.460263, acc: 55.47%, op_acc: 38.28%] [G loss: 0.841510]\n",
      "epoch:18 step:14495[D loss: 0.449666, acc: 57.03%, op_acc: 42.19%] [G loss: 0.847257]\n",
      "epoch:18 step:14496[D loss: 0.420892, acc: 61.72%, op_acc: 42.19%] [G loss: 0.854273]\n",
      "epoch:18 step:14497[D loss: 0.423289, acc: 60.16%, op_acc: 38.28%] [G loss: 0.878915]\n",
      "epoch:18 step:14498[D loss: 0.414612, acc: 62.50%, op_acc: 40.62%] [G loss: 0.895557]\n",
      "epoch:18 step:14499[D loss: 0.430706, acc: 56.25%, op_acc: 39.84%] [G loss: 0.895603]\n",
      "epoch:18 step:14500[D loss: 0.398191, acc: 65.62%, op_acc: 39.84%] [G loss: 0.911108]\n",
      "##############\n",
      "[0.84281984 0.86820141 0.8130119  0.79891261 0.77699039 0.83514143\n",
      " 0.87498583 0.83095615 0.81390006 0.83303636]\n",
      "##########\n",
      "epoch:18 step:14501[D loss: 0.448784, acc: 59.38%, op_acc: 34.38%] [G loss: 0.882822]\n",
      "epoch:18 step:14502[D loss: 0.418998, acc: 59.38%, op_acc: 40.62%] [G loss: 0.928454]\n",
      "epoch:18 step:14503[D loss: 0.457216, acc: 56.25%, op_acc: 35.16%] [G loss: 0.986025]\n",
      "epoch:18 step:14504[D loss: 0.423276, acc: 60.16%, op_acc: 38.28%] [G loss: 0.826928]\n",
      "epoch:18 step:14505[D loss: 0.464734, acc: 57.81%, op_acc: 30.47%] [G loss: 0.937807]\n",
      "epoch:18 step:14506[D loss: 0.396534, acc: 68.75%, op_acc: 41.41%] [G loss: 0.847648]\n",
      "epoch:18 step:14507[D loss: 0.433978, acc: 61.72%, op_acc: 36.72%] [G loss: 0.894270]\n",
      "epoch:18 step:14508[D loss: 0.400757, acc: 67.97%, op_acc: 35.16%] [G loss: 0.889159]\n",
      "epoch:18 step:14509[D loss: 0.439092, acc: 51.56%, op_acc: 42.19%] [G loss: 0.855848]\n",
      "epoch:18 step:14510[D loss: 0.419584, acc: 60.16%, op_acc: 36.72%] [G loss: 0.895466]\n",
      "epoch:18 step:14511[D loss: 0.411575, acc: 57.81%, op_acc: 41.41%] [G loss: 0.873790]\n",
      "epoch:18 step:14512[D loss: 0.453293, acc: 53.91%, op_acc: 38.28%] [G loss: 0.774480]\n",
      "epoch:18 step:14513[D loss: 0.441748, acc: 60.94%, op_acc: 35.16%] [G loss: 0.938971]\n",
      "epoch:18 step:14514[D loss: 0.443285, acc: 53.91%, op_acc: 35.16%] [G loss: 0.875935]\n",
      "epoch:18 step:14515[D loss: 0.417501, acc: 62.50%, op_acc: 40.62%] [G loss: 0.874376]\n",
      "epoch:18 step:14516[D loss: 0.426467, acc: 58.59%, op_acc: 40.62%] [G loss: 0.828235]\n",
      "epoch:18 step:14517[D loss: 0.416184, acc: 61.72%, op_acc: 38.28%] [G loss: 0.808207]\n",
      "epoch:18 step:14518[D loss: 0.434729, acc: 54.69%, op_acc: 39.06%] [G loss: 0.879697]\n",
      "epoch:18 step:14519[D loss: 0.442552, acc: 55.47%, op_acc: 35.94%] [G loss: 0.933980]\n",
      "epoch:18 step:14520[D loss: 0.459568, acc: 48.44%, op_acc: 39.84%] [G loss: 0.884110]\n",
      "epoch:18 step:14521[D loss: 0.408207, acc: 60.16%, op_acc: 36.72%] [G loss: 0.891256]\n",
      "epoch:18 step:14522[D loss: 0.417960, acc: 55.47%, op_acc: 38.28%] [G loss: 0.887199]\n",
      "epoch:18 step:14523[D loss: 0.428201, acc: 60.94%, op_acc: 39.06%] [G loss: 0.967997]\n",
      "epoch:18 step:14524[D loss: 0.417403, acc: 53.91%, op_acc: 46.88%] [G loss: 0.882760]\n",
      "epoch:18 step:14525[D loss: 0.436347, acc: 58.59%, op_acc: 39.06%] [G loss: 0.937625]\n",
      "epoch:18 step:14526[D loss: 0.415920, acc: 59.38%, op_acc: 42.19%] [G loss: 0.891290]\n",
      "epoch:18 step:14527[D loss: 0.404638, acc: 62.50%, op_acc: 35.16%] [G loss: 0.854337]\n",
      "epoch:18 step:14528[D loss: 0.410031, acc: 57.81%, op_acc: 39.06%] [G loss: 0.914797]\n",
      "epoch:18 step:14529[D loss: 0.426242, acc: 60.94%, op_acc: 39.84%] [G loss: 0.871144]\n",
      "epoch:18 step:14530[D loss: 0.430861, acc: 59.38%, op_acc: 34.38%] [G loss: 0.902389]\n",
      "epoch:18 step:14531[D loss: 0.374798, acc: 67.97%, op_acc: 46.09%] [G loss: 0.808015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14532[D loss: 0.426069, acc: 58.59%, op_acc: 42.19%] [G loss: 0.867353]\n",
      "epoch:18 step:14533[D loss: 0.422874, acc: 54.69%, op_acc: 39.06%] [G loss: 0.874847]\n",
      "epoch:18 step:14534[D loss: 0.432680, acc: 57.81%, op_acc: 41.41%] [G loss: 0.890918]\n",
      "epoch:18 step:14535[D loss: 0.431941, acc: 57.03%, op_acc: 42.19%] [G loss: 0.859268]\n",
      "epoch:18 step:14536[D loss: 0.406943, acc: 61.72%, op_acc: 43.75%] [G loss: 0.909839]\n",
      "epoch:18 step:14537[D loss: 0.444302, acc: 51.56%, op_acc: 39.84%] [G loss: 0.877489]\n",
      "epoch:18 step:14538[D loss: 0.437250, acc: 64.84%, op_acc: 33.59%] [G loss: 0.867829]\n",
      "epoch:18 step:14539[D loss: 0.467705, acc: 53.12%, op_acc: 37.50%] [G loss: 0.866883]\n",
      "epoch:18 step:14540[D loss: 0.426568, acc: 61.72%, op_acc: 38.28%] [G loss: 0.839805]\n",
      "epoch:18 step:14541[D loss: 0.406391, acc: 66.41%, op_acc: 37.50%] [G loss: 0.840125]\n",
      "epoch:18 step:14542[D loss: 0.409340, acc: 60.94%, op_acc: 43.75%] [G loss: 0.860014]\n",
      "epoch:18 step:14543[D loss: 0.431857, acc: 56.25%, op_acc: 39.06%] [G loss: 0.834575]\n",
      "epoch:18 step:14544[D loss: 0.426267, acc: 58.59%, op_acc: 36.72%] [G loss: 0.912177]\n",
      "epoch:18 step:14545[D loss: 0.447480, acc: 57.03%, op_acc: 35.16%] [G loss: 0.847408]\n",
      "epoch:18 step:14546[D loss: 0.428447, acc: 64.06%, op_acc: 35.16%] [G loss: 0.874872]\n",
      "epoch:18 step:14547[D loss: 0.417706, acc: 60.94%, op_acc: 43.75%] [G loss: 0.963681]\n",
      "epoch:18 step:14548[D loss: 0.403773, acc: 65.62%, op_acc: 44.53%] [G loss: 0.895571]\n",
      "epoch:18 step:14549[D loss: 0.461631, acc: 57.03%, op_acc: 33.59%] [G loss: 0.966227]\n",
      "epoch:18 step:14550[D loss: 0.407483, acc: 60.16%, op_acc: 39.84%] [G loss: 0.843272]\n",
      "##############\n",
      "[0.87864532 0.86432229 0.82764716 0.81320339 0.77743227 0.81737895\n",
      " 0.8821775  0.82644408 0.79480977 0.82521478]\n",
      "##########\n",
      "epoch:18 step:14551[D loss: 0.412436, acc: 65.62%, op_acc: 35.94%] [G loss: 0.913753]\n",
      "epoch:18 step:14552[D loss: 0.382550, acc: 67.97%, op_acc: 39.06%] [G loss: 0.947018]\n",
      "epoch:18 step:14553[D loss: 0.429701, acc: 59.38%, op_acc: 35.94%] [G loss: 0.841798]\n",
      "epoch:18 step:14554[D loss: 0.412951, acc: 63.28%, op_acc: 35.94%] [G loss: 0.883901]\n",
      "epoch:18 step:14555[D loss: 0.437932, acc: 53.91%, op_acc: 42.97%] [G loss: 0.847814]\n",
      "epoch:18 step:14556[D loss: 0.473108, acc: 50.78%, op_acc: 35.94%] [G loss: 0.883600]\n",
      "epoch:18 step:14557[D loss: 0.434620, acc: 64.84%, op_acc: 36.72%] [G loss: 0.938683]\n",
      "epoch:18 step:14558[D loss: 0.416631, acc: 63.28%, op_acc: 42.97%] [G loss: 0.942337]\n",
      "epoch:18 step:14559[D loss: 0.427712, acc: 57.03%, op_acc: 38.28%] [G loss: 1.038096]\n",
      "epoch:18 step:14560[D loss: 0.438919, acc: 56.25%, op_acc: 39.84%] [G loss: 0.911994]\n",
      "epoch:18 step:14561[D loss: 0.436948, acc: 60.16%, op_acc: 35.16%] [G loss: 0.878446]\n",
      "epoch:18 step:14562[D loss: 0.447949, acc: 53.91%, op_acc: 38.28%] [G loss: 0.821758]\n",
      "epoch:18 step:14563[D loss: 0.441975, acc: 59.38%, op_acc: 35.94%] [G loss: 0.917651]\n",
      "epoch:18 step:14564[D loss: 0.418599, acc: 55.47%, op_acc: 42.19%] [G loss: 0.892959]\n",
      "epoch:18 step:14565[D loss: 0.381449, acc: 67.19%, op_acc: 39.84%] [G loss: 0.914825]\n",
      "epoch:18 step:14566[D loss: 0.431898, acc: 58.59%, op_acc: 39.84%] [G loss: 0.880650]\n",
      "epoch:18 step:14567[D loss: 0.447720, acc: 50.78%, op_acc: 39.84%] [G loss: 0.893423]\n",
      "epoch:18 step:14568[D loss: 0.428009, acc: 60.94%, op_acc: 43.75%] [G loss: 0.869162]\n",
      "epoch:18 step:14569[D loss: 0.409662, acc: 60.94%, op_acc: 42.97%] [G loss: 0.861918]\n",
      "epoch:18 step:14570[D loss: 0.453010, acc: 49.22%, op_acc: 38.28%] [G loss: 0.825571]\n",
      "epoch:18 step:14571[D loss: 0.461442, acc: 54.69%, op_acc: 31.25%] [G loss: 0.896220]\n",
      "epoch:18 step:14572[D loss: 0.418921, acc: 60.16%, op_acc: 40.62%] [G loss: 0.848811]\n",
      "epoch:18 step:14573[D loss: 0.419357, acc: 64.06%, op_acc: 34.38%] [G loss: 0.956947]\n",
      "epoch:18 step:14574[D loss: 0.434133, acc: 60.16%, op_acc: 39.06%] [G loss: 0.888782]\n",
      "epoch:18 step:14575[D loss: 0.449451, acc: 51.56%, op_acc: 36.72%] [G loss: 0.875481]\n",
      "epoch:18 step:14576[D loss: 0.412188, acc: 58.59%, op_acc: 33.59%] [G loss: 0.868477]\n",
      "epoch:18 step:14577[D loss: 0.407195, acc: 64.84%, op_acc: 34.38%] [G loss: 0.914345]\n",
      "epoch:18 step:14578[D loss: 0.430610, acc: 60.94%, op_acc: 41.41%] [G loss: 0.911901]\n",
      "epoch:18 step:14579[D loss: 0.425085, acc: 59.38%, op_acc: 39.06%] [G loss: 0.963550]\n",
      "epoch:18 step:14580[D loss: 0.458517, acc: 51.56%, op_acc: 36.72%] [G loss: 0.851438]\n",
      "epoch:18 step:14581[D loss: 0.414975, acc: 62.50%, op_acc: 35.94%] [G loss: 0.907073]\n",
      "epoch:18 step:14582[D loss: 0.438707, acc: 58.59%, op_acc: 35.94%] [G loss: 0.803827]\n",
      "epoch:18 step:14583[D loss: 0.406497, acc: 63.28%, op_acc: 38.28%] [G loss: 0.910041]\n",
      "epoch:18 step:14584[D loss: 0.470414, acc: 56.25%, op_acc: 33.59%] [G loss: 0.853232]\n",
      "epoch:18 step:14585[D loss: 0.447205, acc: 53.91%, op_acc: 40.62%] [G loss: 0.957299]\n",
      "epoch:18 step:14586[D loss: 0.419971, acc: 54.69%, op_acc: 42.97%] [G loss: 0.878086]\n",
      "epoch:18 step:14587[D loss: 0.439383, acc: 51.56%, op_acc: 37.50%] [G loss: 0.888973]\n",
      "epoch:18 step:14588[D loss: 0.431730, acc: 59.38%, op_acc: 37.50%] [G loss: 0.891762]\n",
      "epoch:18 step:14589[D loss: 0.444948, acc: 57.81%, op_acc: 32.03%] [G loss: 0.934867]\n",
      "epoch:18 step:14590[D loss: 0.432223, acc: 56.25%, op_acc: 36.72%] [G loss: 0.948713]\n",
      "epoch:18 step:14591[D loss: 0.415875, acc: 60.94%, op_acc: 42.97%] [G loss: 0.872303]\n",
      "epoch:18 step:14592[D loss: 0.430566, acc: 59.38%, op_acc: 42.97%] [G loss: 0.902376]\n",
      "epoch:18 step:14593[D loss: 0.422005, acc: 60.16%, op_acc: 35.94%] [G loss: 0.940381]\n",
      "epoch:18 step:14594[D loss: 0.426281, acc: 55.47%, op_acc: 39.84%] [G loss: 0.982916]\n",
      "epoch:18 step:14595[D loss: 0.466541, acc: 49.22%, op_acc: 31.25%] [G loss: 0.881681]\n",
      "epoch:18 step:14596[D loss: 0.426293, acc: 59.38%, op_acc: 39.06%] [G loss: 0.999757]\n",
      "epoch:18 step:14597[D loss: 0.425367, acc: 63.28%, op_acc: 39.06%] [G loss: 0.928104]\n",
      "epoch:18 step:14598[D loss: 0.417546, acc: 59.38%, op_acc: 38.28%] [G loss: 0.843119]\n",
      "epoch:18 step:14599[D loss: 0.411763, acc: 60.94%, op_acc: 44.53%] [G loss: 0.880796]\n",
      "epoch:18 step:14600[D loss: 0.442426, acc: 57.81%, op_acc: 34.38%] [G loss: 0.911316]\n",
      "##############\n",
      "[0.859979   0.85778933 0.81534711 0.81564987 0.79282318 0.82304016\n",
      " 0.89255688 0.82200351 0.78973529 0.82295154]\n",
      "##########\n",
      "epoch:18 step:14601[D loss: 0.434532, acc: 63.28%, op_acc: 35.94%] [G loss: 0.866340]\n",
      "epoch:18 step:14602[D loss: 0.437189, acc: 57.81%, op_acc: 41.41%] [G loss: 0.855435]\n",
      "epoch:18 step:14603[D loss: 0.411039, acc: 62.50%, op_acc: 37.50%] [G loss: 0.891246]\n",
      "epoch:18 step:14604[D loss: 0.454781, acc: 49.22%, op_acc: 36.72%] [G loss: 0.841233]\n",
      "epoch:18 step:14605[D loss: 0.445049, acc: 55.47%, op_acc: 34.38%] [G loss: 0.945071]\n",
      "epoch:18 step:14606[D loss: 0.429832, acc: 62.50%, op_acc: 34.38%] [G loss: 0.899372]\n",
      "epoch:18 step:14607[D loss: 0.441651, acc: 56.25%, op_acc: 42.19%] [G loss: 1.002192]\n",
      "epoch:18 step:14608[D loss: 0.419866, acc: 64.84%, op_acc: 37.50%] [G loss: 0.885025]\n",
      "epoch:18 step:14609[D loss: 0.420882, acc: 60.16%, op_acc: 40.62%] [G loss: 0.961364]\n",
      "epoch:18 step:14610[D loss: 0.461239, acc: 52.34%, op_acc: 33.59%] [G loss: 0.829690]\n",
      "epoch:18 step:14611[D loss: 0.410537, acc: 63.28%, op_acc: 39.06%] [G loss: 0.802210]\n",
      "epoch:18 step:14612[D loss: 0.411447, acc: 61.72%, op_acc: 39.06%] [G loss: 0.878185]\n",
      "epoch:18 step:14613[D loss: 0.413994, acc: 60.16%, op_acc: 39.06%] [G loss: 0.826093]\n",
      "epoch:18 step:14614[D loss: 0.406745, acc: 67.97%, op_acc: 38.28%] [G loss: 0.802024]\n",
      "epoch:18 step:14615[D loss: 0.447841, acc: 49.22%, op_acc: 33.59%] [G loss: 0.880130]\n",
      "epoch:18 step:14616[D loss: 0.420482, acc: 58.59%, op_acc: 42.97%] [G loss: 0.840522]\n",
      "epoch:18 step:14617[D loss: 0.400346, acc: 66.41%, op_acc: 39.06%] [G loss: 0.894742]\n",
      "epoch:18 step:14618[D loss: 0.435960, acc: 64.06%, op_acc: 36.72%] [G loss: 0.872746]\n",
      "epoch:18 step:14619[D loss: 0.438624, acc: 50.78%, op_acc: 39.84%] [G loss: 0.887905]\n",
      "epoch:18 step:14620[D loss: 0.446322, acc: 55.47%, op_acc: 36.72%] [G loss: 0.837959]\n",
      "epoch:18 step:14621[D loss: 0.437448, acc: 66.41%, op_acc: 34.38%] [G loss: 0.857149]\n",
      "epoch:18 step:14622[D loss: 0.424804, acc: 64.06%, op_acc: 40.62%] [G loss: 0.877071]\n",
      "epoch:18 step:14623[D loss: 0.451985, acc: 53.12%, op_acc: 39.84%] [G loss: 0.822706]\n",
      "epoch:18 step:14624[D loss: 0.419518, acc: 60.16%, op_acc: 40.62%] [G loss: 0.935977]\n",
      "epoch:18 step:14625[D loss: 0.421099, acc: 60.16%, op_acc: 42.97%] [G loss: 0.906453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14626[D loss: 0.431865, acc: 56.25%, op_acc: 44.53%] [G loss: 0.984570]\n",
      "epoch:18 step:14627[D loss: 0.428237, acc: 60.94%, op_acc: 36.72%] [G loss: 0.945272]\n",
      "epoch:18 step:14628[D loss: 0.423147, acc: 57.03%, op_acc: 41.41%] [G loss: 0.857436]\n",
      "epoch:18 step:14629[D loss: 0.432303, acc: 51.56%, op_acc: 44.53%] [G loss: 0.872374]\n",
      "epoch:18 step:14630[D loss: 0.424439, acc: 63.28%, op_acc: 35.16%] [G loss: 0.912244]\n",
      "epoch:18 step:14631[D loss: 0.440876, acc: 57.03%, op_acc: 39.84%] [G loss: 0.844665]\n",
      "epoch:18 step:14632[D loss: 0.430204, acc: 58.59%, op_acc: 36.72%] [G loss: 0.880699]\n",
      "epoch:18 step:14633[D loss: 0.422821, acc: 63.28%, op_acc: 39.06%] [G loss: 0.810496]\n",
      "epoch:18 step:14634[D loss: 0.395768, acc: 67.19%, op_acc: 41.41%] [G loss: 0.892297]\n",
      "epoch:18 step:14635[D loss: 0.441869, acc: 62.50%, op_acc: 34.38%] [G loss: 0.904956]\n",
      "epoch:18 step:14636[D loss: 0.471664, acc: 53.12%, op_acc: 36.72%] [G loss: 0.888574]\n",
      "epoch:18 step:14637[D loss: 0.401406, acc: 59.38%, op_acc: 40.62%] [G loss: 0.910327]\n",
      "epoch:18 step:14638[D loss: 0.442909, acc: 58.59%, op_acc: 36.72%] [G loss: 0.928949]\n",
      "epoch:18 step:14639[D loss: 0.425527, acc: 57.81%, op_acc: 32.03%] [G loss: 0.923691]\n",
      "epoch:18 step:14640[D loss: 0.434224, acc: 68.75%, op_acc: 36.72%] [G loss: 0.898345]\n",
      "epoch:18 step:14641[D loss: 0.436425, acc: 60.94%, op_acc: 39.84%] [G loss: 0.921380]\n",
      "epoch:18 step:14642[D loss: 0.475039, acc: 56.25%, op_acc: 34.38%] [G loss: 1.007576]\n",
      "epoch:18 step:14643[D loss: 0.435781, acc: 56.25%, op_acc: 39.84%] [G loss: 0.940927]\n",
      "epoch:18 step:14644[D loss: 0.428271, acc: 56.25%, op_acc: 35.94%] [G loss: 0.939971]\n",
      "epoch:18 step:14645[D loss: 0.431249, acc: 60.94%, op_acc: 38.28%] [G loss: 0.892044]\n",
      "epoch:18 step:14646[D loss: 0.426299, acc: 57.81%, op_acc: 39.84%] [G loss: 0.826185]\n",
      "epoch:18 step:14647[D loss: 0.447475, acc: 53.91%, op_acc: 35.94%] [G loss: 0.976004]\n",
      "epoch:18 step:14648[D loss: 0.423489, acc: 53.91%, op_acc: 39.84%] [G loss: 0.906759]\n",
      "epoch:18 step:14649[D loss: 0.446833, acc: 53.12%, op_acc: 38.28%] [G loss: 0.948252]\n",
      "epoch:18 step:14650[D loss: 0.432969, acc: 62.50%, op_acc: 32.81%] [G loss: 0.940935]\n",
      "##############\n",
      "[0.85228915 0.85469087 0.82195768 0.81246825 0.8021473  0.81144863\n",
      " 0.86564817 0.85359102 0.80907716 0.82868738]\n",
      "##########\n",
      "epoch:18 step:14651[D loss: 0.416116, acc: 63.28%, op_acc: 37.50%] [G loss: 0.906837]\n",
      "epoch:18 step:14652[D loss: 0.453436, acc: 53.12%, op_acc: 36.72%] [G loss: 0.854984]\n",
      "epoch:18 step:14653[D loss: 0.443020, acc: 62.50%, op_acc: 36.72%] [G loss: 0.849633]\n",
      "epoch:18 step:14654[D loss: 0.437156, acc: 57.03%, op_acc: 35.94%] [G loss: 0.867747]\n",
      "epoch:18 step:14655[D loss: 0.432453, acc: 58.59%, op_acc: 38.28%] [G loss: 0.889530]\n",
      "epoch:18 step:14656[D loss: 0.416981, acc: 65.62%, op_acc: 37.50%] [G loss: 0.940323]\n",
      "epoch:18 step:14657[D loss: 0.433864, acc: 57.03%, op_acc: 44.53%] [G loss: 0.958934]\n",
      "epoch:18 step:14658[D loss: 0.416351, acc: 64.84%, op_acc: 42.19%] [G loss: 0.946514]\n",
      "epoch:18 step:14659[D loss: 0.433339, acc: 59.38%, op_acc: 37.50%] [G loss: 0.863564]\n",
      "epoch:18 step:14660[D loss: 0.427932, acc: 55.47%, op_acc: 40.62%] [G loss: 0.873865]\n",
      "epoch:18 step:14661[D loss: 0.390652, acc: 64.84%, op_acc: 42.19%] [G loss: 0.932187]\n",
      "epoch:18 step:14662[D loss: 0.468587, acc: 53.91%, op_acc: 34.38%] [G loss: 0.916424]\n",
      "epoch:18 step:14663[D loss: 0.397462, acc: 71.88%, op_acc: 39.84%] [G loss: 0.847629]\n",
      "epoch:18 step:14664[D loss: 0.446648, acc: 61.72%, op_acc: 35.16%] [G loss: 0.830946]\n",
      "epoch:18 step:14665[D loss: 0.405908, acc: 62.50%, op_acc: 40.62%] [G loss: 0.895405]\n",
      "epoch:18 step:14666[D loss: 0.403149, acc: 58.59%, op_acc: 43.75%] [G loss: 0.848087]\n",
      "epoch:18 step:14667[D loss: 0.441907, acc: 56.25%, op_acc: 38.28%] [G loss: 0.882168]\n",
      "epoch:18 step:14668[D loss: 0.420273, acc: 60.16%, op_acc: 42.19%] [G loss: 0.909456]\n",
      "epoch:18 step:14669[D loss: 0.428576, acc: 54.69%, op_acc: 42.97%] [G loss: 0.905462]\n",
      "epoch:18 step:14670[D loss: 0.431063, acc: 58.59%, op_acc: 42.19%] [G loss: 0.800061]\n",
      "epoch:18 step:14671[D loss: 0.438435, acc: 55.47%, op_acc: 40.62%] [G loss: 0.873180]\n",
      "epoch:18 step:14672[D loss: 0.395288, acc: 64.84%, op_acc: 35.16%] [G loss: 0.883254]\n",
      "epoch:18 step:14673[D loss: 0.415806, acc: 64.84%, op_acc: 41.41%] [G loss: 0.835460]\n",
      "epoch:18 step:14674[D loss: 0.423620, acc: 60.16%, op_acc: 39.84%] [G loss: 0.902375]\n",
      "epoch:18 step:14675[D loss: 0.435620, acc: 58.59%, op_acc: 34.38%] [G loss: 0.890219]\n",
      "epoch:18 step:14676[D loss: 0.407408, acc: 61.72%, op_acc: 42.97%] [G loss: 0.822715]\n",
      "epoch:18 step:14677[D loss: 0.440180, acc: 54.69%, op_acc: 36.72%] [G loss: 0.889082]\n",
      "epoch:18 step:14678[D loss: 0.423730, acc: 65.62%, op_acc: 35.16%] [G loss: 1.002084]\n",
      "epoch:18 step:14679[D loss: 0.428323, acc: 54.69%, op_acc: 38.28%] [G loss: 0.921233]\n",
      "epoch:18 step:14680[D loss: 0.453490, acc: 57.81%, op_acc: 35.94%] [G loss: 0.829049]\n",
      "epoch:18 step:14681[D loss: 0.459752, acc: 44.53%, op_acc: 35.94%] [G loss: 0.860258]\n",
      "epoch:18 step:14682[D loss: 0.420676, acc: 60.16%, op_acc: 39.06%] [G loss: 0.917893]\n",
      "epoch:18 step:14683[D loss: 0.434799, acc: 64.84%, op_acc: 39.06%] [G loss: 0.843408]\n",
      "epoch:18 step:14684[D loss: 0.409236, acc: 62.50%, op_acc: 44.53%] [G loss: 0.982464]\n",
      "epoch:18 step:14685[D loss: 0.431933, acc: 61.72%, op_acc: 36.72%] [G loss: 0.878358]\n",
      "epoch:18 step:14686[D loss: 0.415917, acc: 71.88%, op_acc: 37.50%] [G loss: 0.920504]\n",
      "epoch:18 step:14687[D loss: 0.465747, acc: 52.34%, op_acc: 32.81%] [G loss: 0.929147]\n",
      "epoch:18 step:14688[D loss: 0.414054, acc: 59.38%, op_acc: 42.19%] [G loss: 0.917105]\n",
      "epoch:18 step:14689[D loss: 0.429828, acc: 60.16%, op_acc: 31.25%] [G loss: 0.929209]\n",
      "epoch:18 step:14690[D loss: 0.418463, acc: 64.84%, op_acc: 33.59%] [G loss: 0.933984]\n",
      "epoch:18 step:14691[D loss: 0.410703, acc: 65.62%, op_acc: 35.94%] [G loss: 0.856937]\n",
      "epoch:18 step:14692[D loss: 0.403999, acc: 64.84%, op_acc: 42.97%] [G loss: 0.874659]\n",
      "epoch:18 step:14693[D loss: 0.445939, acc: 55.47%, op_acc: 32.03%] [G loss: 0.920255]\n",
      "epoch:18 step:14694[D loss: 0.407225, acc: 60.94%, op_acc: 40.62%] [G loss: 0.866169]\n",
      "epoch:18 step:14695[D loss: 0.418243, acc: 56.25%, op_acc: 39.84%] [G loss: 0.871990]\n",
      "epoch:18 step:14696[D loss: 0.442098, acc: 53.91%, op_acc: 39.84%] [G loss: 0.859070]\n",
      "epoch:18 step:14697[D loss: 0.435260, acc: 64.06%, op_acc: 36.72%] [G loss: 0.880149]\n",
      "epoch:18 step:14698[D loss: 0.449902, acc: 57.81%, op_acc: 35.94%] [G loss: 0.866273]\n",
      "epoch:18 step:14699[D loss: 0.437066, acc: 53.12%, op_acc: 38.28%] [G loss: 0.810397]\n",
      "epoch:18 step:14700[D loss: 0.419264, acc: 69.53%, op_acc: 32.03%] [G loss: 0.913864]\n",
      "##############\n",
      "[0.85839106 0.87351121 0.81445945 0.80539745 0.79232765 0.82992066\n",
      " 0.86273479 0.82771024 0.80326219 0.82161629]\n",
      "##########\n",
      "epoch:18 step:14701[D loss: 0.469648, acc: 52.34%, op_acc: 35.94%] [G loss: 0.859753]\n",
      "epoch:18 step:14702[D loss: 0.383789, acc: 69.53%, op_acc: 37.50%] [G loss: 0.951131]\n",
      "epoch:18 step:14703[D loss: 0.409681, acc: 58.59%, op_acc: 43.75%] [G loss: 0.863700]\n",
      "epoch:18 step:14704[D loss: 0.436399, acc: 59.38%, op_acc: 40.62%] [G loss: 0.871180]\n",
      "epoch:18 step:14705[D loss: 0.403317, acc: 59.38%, op_acc: 39.06%] [G loss: 0.903499]\n",
      "epoch:18 step:14706[D loss: 0.438010, acc: 54.69%, op_acc: 35.16%] [G loss: 0.897434]\n",
      "epoch:18 step:14707[D loss: 0.413177, acc: 67.97%, op_acc: 39.06%] [G loss: 0.935136]\n",
      "epoch:18 step:14708[D loss: 0.421763, acc: 61.72%, op_acc: 41.41%] [G loss: 0.928353]\n",
      "epoch:18 step:14709[D loss: 0.424954, acc: 59.38%, op_acc: 42.19%] [G loss: 0.969024]\n",
      "epoch:18 step:14710[D loss: 0.437523, acc: 50.78%, op_acc: 35.16%] [G loss: 0.831382]\n",
      "epoch:18 step:14711[D loss: 0.418111, acc: 59.38%, op_acc: 35.94%] [G loss: 0.874941]\n",
      "epoch:18 step:14712[D loss: 0.438596, acc: 53.12%, op_acc: 40.62%] [G loss: 0.892274]\n",
      "epoch:18 step:14713[D loss: 0.434628, acc: 62.50%, op_acc: 35.94%] [G loss: 0.984203]\n",
      "epoch:18 step:14714[D loss: 0.396537, acc: 67.97%, op_acc: 37.50%] [G loss: 0.839443]\n",
      "epoch:18 step:14715[D loss: 0.424654, acc: 60.16%, op_acc: 33.59%] [G loss: 0.913602]\n",
      "epoch:18 step:14716[D loss: 0.392415, acc: 66.41%, op_acc: 44.53%] [G loss: 0.981189]\n",
      "epoch:18 step:14717[D loss: 0.428293, acc: 60.94%, op_acc: 41.41%] [G loss: 0.847125]\n",
      "epoch:18 step:14718[D loss: 0.429325, acc: 58.59%, op_acc: 41.41%] [G loss: 0.921496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14719[D loss: 0.420375, acc: 62.50%, op_acc: 42.19%] [G loss: 0.829304]\n",
      "epoch:18 step:14720[D loss: 0.399937, acc: 61.72%, op_acc: 40.62%] [G loss: 0.896620]\n",
      "epoch:18 step:14721[D loss: 0.417485, acc: 58.59%, op_acc: 39.84%] [G loss: 0.904004]\n",
      "epoch:18 step:14722[D loss: 0.399838, acc: 66.41%, op_acc: 41.41%] [G loss: 0.880030]\n",
      "epoch:18 step:14723[D loss: 0.453129, acc: 57.81%, op_acc: 33.59%] [G loss: 0.992010]\n",
      "epoch:18 step:14724[D loss: 0.428660, acc: 58.59%, op_acc: 35.94%] [G loss: 0.888311]\n",
      "epoch:18 step:14725[D loss: 0.442637, acc: 53.12%, op_acc: 36.72%] [G loss: 0.908968]\n",
      "epoch:18 step:14726[D loss: 0.425823, acc: 61.72%, op_acc: 35.94%] [G loss: 0.873912]\n",
      "epoch:18 step:14727[D loss: 0.459514, acc: 50.00%, op_acc: 35.16%] [G loss: 0.923931]\n",
      "epoch:18 step:14728[D loss: 0.420784, acc: 60.16%, op_acc: 42.19%] [G loss: 0.874720]\n",
      "epoch:18 step:14729[D loss: 0.428053, acc: 59.38%, op_acc: 38.28%] [G loss: 0.805332]\n",
      "epoch:18 step:14730[D loss: 0.444411, acc: 54.69%, op_acc: 34.38%] [G loss: 0.793960]\n",
      "epoch:18 step:14731[D loss: 0.441511, acc: 50.78%, op_acc: 35.16%] [G loss: 0.979352]\n",
      "epoch:18 step:14732[D loss: 0.425156, acc: 57.81%, op_acc: 37.50%] [G loss: 0.882321]\n",
      "epoch:18 step:14733[D loss: 0.466637, acc: 53.91%, op_acc: 32.03%] [G loss: 0.899958]\n",
      "epoch:18 step:14734[D loss: 0.462603, acc: 56.25%, op_acc: 30.47%] [G loss: 0.924083]\n",
      "epoch:18 step:14735[D loss: 0.459957, acc: 55.47%, op_acc: 35.16%] [G loss: 0.869738]\n",
      "epoch:18 step:14736[D loss: 0.456396, acc: 53.12%, op_acc: 34.38%] [G loss: 0.882916]\n",
      "epoch:18 step:14737[D loss: 0.401825, acc: 59.38%, op_acc: 40.62%] [G loss: 0.883439]\n",
      "epoch:18 step:14738[D loss: 0.429551, acc: 63.28%, op_acc: 35.94%] [G loss: 0.941175]\n",
      "epoch:18 step:14739[D loss: 0.456245, acc: 57.03%, op_acc: 32.81%] [G loss: 0.903995]\n",
      "epoch:18 step:14740[D loss: 0.402674, acc: 65.62%, op_acc: 42.97%] [G loss: 0.892528]\n",
      "epoch:18 step:14741[D loss: 0.416909, acc: 60.16%, op_acc: 42.19%] [G loss: 0.906530]\n",
      "epoch:18 step:14742[D loss: 0.445833, acc: 53.91%, op_acc: 37.50%] [G loss: 0.853378]\n",
      "epoch:18 step:14743[D loss: 0.426046, acc: 56.25%, op_acc: 38.28%] [G loss: 0.911467]\n",
      "epoch:18 step:14744[D loss: 0.432472, acc: 57.81%, op_acc: 35.94%] [G loss: 0.877144]\n",
      "epoch:18 step:14745[D loss: 0.427617, acc: 59.38%, op_acc: 37.50%] [G loss: 0.865708]\n",
      "epoch:18 step:14746[D loss: 0.406365, acc: 64.06%, op_acc: 42.19%] [G loss: 0.861236]\n",
      "epoch:18 step:14747[D loss: 0.434460, acc: 52.34%, op_acc: 39.84%] [G loss: 0.914509]\n",
      "epoch:18 step:14748[D loss: 0.443389, acc: 61.72%, op_acc: 29.69%] [G loss: 0.869801]\n",
      "epoch:18 step:14749[D loss: 0.414978, acc: 64.06%, op_acc: 44.53%] [G loss: 0.846329]\n",
      "epoch:18 step:14750[D loss: 0.442705, acc: 57.03%, op_acc: 37.50%] [G loss: 0.883803]\n",
      "##############\n",
      "[0.860075   0.86462896 0.79866916 0.81308089 0.80273438 0.81885636\n",
      " 0.87632657 0.82119838 0.78031556 0.85252954]\n",
      "##########\n",
      "epoch:18 step:14751[D loss: 0.426886, acc: 63.28%, op_acc: 33.59%] [G loss: 0.931226]\n",
      "epoch:18 step:14752[D loss: 0.443242, acc: 59.38%, op_acc: 34.38%] [G loss: 0.858199]\n",
      "epoch:18 step:14753[D loss: 0.425573, acc: 63.28%, op_acc: 37.50%] [G loss: 0.905466]\n",
      "epoch:18 step:14754[D loss: 0.430054, acc: 54.69%, op_acc: 36.72%] [G loss: 0.852962]\n",
      "epoch:18 step:14755[D loss: 0.422742, acc: 55.47%, op_acc: 39.84%] [G loss: 0.879411]\n",
      "epoch:18 step:14756[D loss: 0.412850, acc: 61.72%, op_acc: 45.31%] [G loss: 0.850994]\n",
      "epoch:18 step:14757[D loss: 0.412562, acc: 59.38%, op_acc: 39.06%] [G loss: 0.935806]\n",
      "epoch:18 step:14758[D loss: 0.435193, acc: 66.41%, op_acc: 36.72%] [G loss: 0.850855]\n",
      "epoch:18 step:14759[D loss: 0.450568, acc: 59.38%, op_acc: 35.94%] [G loss: 0.867762]\n",
      "epoch:18 step:14760[D loss: 0.445454, acc: 57.81%, op_acc: 37.50%] [G loss: 0.913942]\n",
      "epoch:18 step:14761[D loss: 0.426743, acc: 60.16%, op_acc: 41.41%] [G loss: 0.805721]\n",
      "epoch:18 step:14762[D loss: 0.394257, acc: 65.62%, op_acc: 43.75%] [G loss: 0.816939]\n",
      "epoch:18 step:14763[D loss: 0.452347, acc: 58.59%, op_acc: 39.84%] [G loss: 0.784636]\n",
      "epoch:18 step:14764[D loss: 0.434980, acc: 59.38%, op_acc: 41.41%] [G loss: 0.825469]\n",
      "epoch:18 step:14765[D loss: 0.472476, acc: 47.66%, op_acc: 38.28%] [G loss: 0.865134]\n",
      "epoch:18 step:14766[D loss: 0.478892, acc: 48.44%, op_acc: 39.84%] [G loss: 0.773659]\n",
      "epoch:18 step:14767[D loss: 0.386748, acc: 67.97%, op_acc: 39.84%] [G loss: 0.844965]\n",
      "epoch:18 step:14768[D loss: 0.412441, acc: 59.38%, op_acc: 46.09%] [G loss: 0.890162]\n",
      "epoch:18 step:14769[D loss: 0.426352, acc: 59.38%, op_acc: 35.16%] [G loss: 0.854041]\n",
      "epoch:18 step:14770[D loss: 0.390981, acc: 73.44%, op_acc: 37.50%] [G loss: 0.795197]\n",
      "epoch:18 step:14771[D loss: 0.415621, acc: 61.72%, op_acc: 43.75%] [G loss: 0.907020]\n",
      "epoch:18 step:14772[D loss: 0.450696, acc: 57.03%, op_acc: 39.06%] [G loss: 0.859003]\n",
      "epoch:18 step:14773[D loss: 0.415254, acc: 60.94%, op_acc: 38.28%] [G loss: 0.941099]\n",
      "epoch:18 step:14774[D loss: 0.409677, acc: 65.62%, op_acc: 42.97%] [G loss: 0.901027]\n",
      "epoch:18 step:14775[D loss: 0.431592, acc: 48.44%, op_acc: 43.75%] [G loss: 0.879193]\n",
      "epoch:18 step:14776[D loss: 0.443140, acc: 60.16%, op_acc: 32.81%] [G loss: 0.839120]\n",
      "epoch:18 step:14777[D loss: 0.415971, acc: 65.62%, op_acc: 42.97%] [G loss: 0.919060]\n",
      "epoch:18 step:14778[D loss: 0.452912, acc: 53.91%, op_acc: 38.28%] [G loss: 0.886129]\n",
      "epoch:18 step:14779[D loss: 0.450347, acc: 52.34%, op_acc: 32.81%] [G loss: 0.827708]\n",
      "epoch:18 step:14780[D loss: 0.443534, acc: 60.16%, op_acc: 39.06%] [G loss: 0.815672]\n",
      "epoch:18 step:14781[D loss: 0.435769, acc: 50.78%, op_acc: 39.84%] [G loss: 0.864524]\n",
      "epoch:18 step:14782[D loss: 0.489516, acc: 53.91%, op_acc: 32.81%] [G loss: 0.866664]\n",
      "epoch:18 step:14783[D loss: 0.444429, acc: 59.38%, op_acc: 38.28%] [G loss: 0.993470]\n",
      "epoch:18 step:14784[D loss: 0.418541, acc: 57.81%, op_acc: 39.06%] [G loss: 0.851138]\n",
      "epoch:18 step:14785[D loss: 0.469757, acc: 47.66%, op_acc: 32.81%] [G loss: 0.827257]\n",
      "epoch:18 step:14786[D loss: 0.445900, acc: 57.81%, op_acc: 35.16%] [G loss: 0.900322]\n",
      "epoch:18 step:14787[D loss: 0.425068, acc: 54.69%, op_acc: 42.97%] [G loss: 0.851351]\n",
      "epoch:18 step:14788[D loss: 0.425055, acc: 63.28%, op_acc: 41.41%] [G loss: 0.872039]\n",
      "epoch:18 step:14789[D loss: 0.430990, acc: 57.03%, op_acc: 39.84%] [G loss: 0.845532]\n",
      "epoch:18 step:14790[D loss: 0.425196, acc: 57.03%, op_acc: 38.28%] [G loss: 0.836774]\n",
      "epoch:18 step:14791[D loss: 0.442290, acc: 50.00%, op_acc: 36.72%] [G loss: 0.856282]\n",
      "epoch:18 step:14792[D loss: 0.457215, acc: 48.44%, op_acc: 32.03%] [G loss: 0.821653]\n",
      "epoch:18 step:14793[D loss: 0.447938, acc: 51.56%, op_acc: 38.28%] [G loss: 0.863538]\n",
      "epoch:18 step:14794[D loss: 0.434055, acc: 60.16%, op_acc: 37.50%] [G loss: 0.905798]\n",
      "epoch:18 step:14795[D loss: 0.407836, acc: 64.84%, op_acc: 38.28%] [G loss: 0.971355]\n",
      "epoch:18 step:14796[D loss: 0.444212, acc: 59.38%, op_acc: 39.06%] [G loss: 0.971094]\n",
      "epoch:18 step:14797[D loss: 0.427669, acc: 54.69%, op_acc: 38.28%] [G loss: 0.836378]\n",
      "epoch:18 step:14798[D loss: 0.410527, acc: 63.28%, op_acc: 44.53%] [G loss: 0.918958]\n",
      "epoch:18 step:14799[D loss: 0.408496, acc: 70.31%, op_acc: 39.06%] [G loss: 0.919803]\n",
      "epoch:18 step:14800[D loss: 0.420719, acc: 60.16%, op_acc: 42.19%] [G loss: 0.943968]\n",
      "##############\n",
      "[0.86692328 0.85538512 0.81409921 0.8126814  0.78576488 0.82305737\n",
      " 0.88114034 0.8328464  0.81409714 0.80594957]\n",
      "##########\n",
      "epoch:18 step:14801[D loss: 0.424516, acc: 59.38%, op_acc: 39.84%] [G loss: 0.887240]\n",
      "epoch:18 step:14802[D loss: 0.394628, acc: 60.16%, op_acc: 46.09%] [G loss: 0.917865]\n",
      "epoch:18 step:14803[D loss: 0.409160, acc: 58.59%, op_acc: 44.53%] [G loss: 0.871311]\n",
      "epoch:18 step:14804[D loss: 0.435677, acc: 62.50%, op_acc: 38.28%] [G loss: 0.851591]\n",
      "epoch:18 step:14805[D loss: 0.426666, acc: 55.47%, op_acc: 36.72%] [G loss: 0.922804]\n",
      "epoch:18 step:14806[D loss: 0.428998, acc: 60.16%, op_acc: 35.16%] [G loss: 0.930237]\n",
      "epoch:18 step:14807[D loss: 0.429373, acc: 64.84%, op_acc: 42.19%] [G loss: 0.897393]\n",
      "epoch:18 step:14808[D loss: 0.459065, acc: 54.69%, op_acc: 38.28%] [G loss: 0.821319]\n",
      "epoch:18 step:14809[D loss: 0.460200, acc: 53.91%, op_acc: 33.59%] [G loss: 0.885201]\n",
      "epoch:18 step:14810[D loss: 0.425356, acc: 62.50%, op_acc: 39.06%] [G loss: 0.924625]\n",
      "epoch:18 step:14811[D loss: 0.396932, acc: 66.41%, op_acc: 39.06%] [G loss: 0.946216]\n",
      "epoch:18 step:14812[D loss: 0.401306, acc: 65.62%, op_acc: 41.41%] [G loss: 0.934872]\n",
      "epoch:18 step:14813[D loss: 0.409043, acc: 64.06%, op_acc: 37.50%] [G loss: 0.889544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14814[D loss: 0.475321, acc: 46.88%, op_acc: 35.16%] [G loss: 0.868952]\n",
      "epoch:18 step:14815[D loss: 0.456772, acc: 53.91%, op_acc: 35.16%] [G loss: 0.932637]\n",
      "epoch:18 step:14816[D loss: 0.423521, acc: 60.16%, op_acc: 43.75%] [G loss: 0.998843]\n",
      "epoch:18 step:14817[D loss: 0.446692, acc: 60.94%, op_acc: 36.72%] [G loss: 0.951681]\n",
      "epoch:18 step:14818[D loss: 0.410252, acc: 63.28%, op_acc: 39.06%] [G loss: 0.965241]\n",
      "epoch:18 step:14819[D loss: 0.394004, acc: 67.19%, op_acc: 40.62%] [G loss: 0.886106]\n",
      "epoch:18 step:14820[D loss: 0.458931, acc: 50.00%, op_acc: 35.94%] [G loss: 0.839948]\n",
      "epoch:18 step:14821[D loss: 0.435406, acc: 57.81%, op_acc: 39.06%] [G loss: 0.879673]\n",
      "epoch:18 step:14822[D loss: 0.433006, acc: 54.69%, op_acc: 39.06%] [G loss: 0.897140]\n",
      "epoch:18 step:14823[D loss: 0.398645, acc: 60.16%, op_acc: 46.88%] [G loss: 0.846112]\n",
      "epoch:18 step:14824[D loss: 0.399808, acc: 68.75%, op_acc: 42.97%] [G loss: 0.937816]\n",
      "epoch:18 step:14825[D loss: 0.438915, acc: 60.94%, op_acc: 35.16%] [G loss: 0.867136]\n",
      "epoch:18 step:14826[D loss: 0.428899, acc: 63.28%, op_acc: 34.38%] [G loss: 0.905181]\n",
      "epoch:18 step:14827[D loss: 0.412387, acc: 60.94%, op_acc: 42.19%] [G loss: 0.910740]\n",
      "epoch:18 step:14828[D loss: 0.433284, acc: 57.03%, op_acc: 41.41%] [G loss: 0.913743]\n",
      "epoch:18 step:14829[D loss: 0.461666, acc: 47.66%, op_acc: 36.72%] [G loss: 0.824596]\n",
      "epoch:18 step:14830[D loss: 0.462872, acc: 55.47%, op_acc: 35.16%] [G loss: 0.843417]\n",
      "epoch:18 step:14831[D loss: 0.446733, acc: 55.47%, op_acc: 40.62%] [G loss: 0.815846]\n",
      "epoch:18 step:14832[D loss: 0.414445, acc: 63.28%, op_acc: 38.28%] [G loss: 0.846763]\n",
      "epoch:18 step:14833[D loss: 0.444993, acc: 57.81%, op_acc: 38.28%] [G loss: 0.859124]\n",
      "epoch:18 step:14834[D loss: 0.421903, acc: 52.34%, op_acc: 40.62%] [G loss: 0.846121]\n",
      "epoch:18 step:14835[D loss: 0.453231, acc: 54.69%, op_acc: 34.38%] [G loss: 0.946625]\n",
      "epoch:18 step:14836[D loss: 0.404073, acc: 66.41%, op_acc: 42.19%] [G loss: 0.951787]\n",
      "epoch:18 step:14837[D loss: 0.410070, acc: 63.28%, op_acc: 41.41%] [G loss: 0.915938]\n",
      "epoch:18 step:14838[D loss: 0.415323, acc: 63.28%, op_acc: 42.19%] [G loss: 0.929643]\n",
      "epoch:18 step:14839[D loss: 0.395329, acc: 65.62%, op_acc: 38.28%] [G loss: 0.873052]\n",
      "epoch:19 step:14840[D loss: 0.445182, acc: 47.66%, op_acc: 41.41%] [G loss: 0.848365]\n",
      "epoch:19 step:14841[D loss: 0.403556, acc: 63.28%, op_acc: 39.06%] [G loss: 0.892879]\n",
      "epoch:19 step:14842[D loss: 0.429680, acc: 58.59%, op_acc: 37.50%] [G loss: 0.862377]\n",
      "epoch:19 step:14843[D loss: 0.414119, acc: 59.38%, op_acc: 38.28%] [G loss: 0.937328]\n",
      "epoch:19 step:14844[D loss: 0.420159, acc: 60.16%, op_acc: 41.41%] [G loss: 0.909797]\n",
      "epoch:19 step:14845[D loss: 0.432877, acc: 60.16%, op_acc: 38.28%] [G loss: 0.898464]\n",
      "epoch:19 step:14846[D loss: 0.425861, acc: 58.59%, op_acc: 39.84%] [G loss: 0.866134]\n",
      "epoch:19 step:14847[D loss: 0.425863, acc: 58.59%, op_acc: 38.28%] [G loss: 0.972309]\n",
      "epoch:19 step:14848[D loss: 0.430798, acc: 53.91%, op_acc: 42.19%] [G loss: 0.862284]\n",
      "epoch:19 step:14849[D loss: 0.427587, acc: 60.94%, op_acc: 35.16%] [G loss: 0.918575]\n",
      "epoch:19 step:14850[D loss: 0.433544, acc: 61.72%, op_acc: 38.28%] [G loss: 0.885991]\n",
      "##############\n",
      "[0.84194355 0.86220874 0.82594501 0.79273719 0.79388199 0.84611536\n",
      " 0.8772794  0.8110201  0.80826663 0.81563346]\n",
      "##########\n",
      "epoch:19 step:14851[D loss: 0.411733, acc: 62.50%, op_acc: 37.50%] [G loss: 0.890919]\n",
      "epoch:19 step:14852[D loss: 0.412533, acc: 60.94%, op_acc: 37.50%] [G loss: 0.941682]\n",
      "epoch:19 step:14853[D loss: 0.437130, acc: 61.72%, op_acc: 32.03%] [G loss: 0.906277]\n",
      "epoch:19 step:14854[D loss: 0.425015, acc: 63.28%, op_acc: 43.75%] [G loss: 0.877456]\n",
      "epoch:19 step:14855[D loss: 0.421049, acc: 57.03%, op_acc: 38.28%] [G loss: 0.857007]\n",
      "epoch:19 step:14856[D loss: 0.421446, acc: 63.28%, op_acc: 41.41%] [G loss: 0.856423]\n",
      "epoch:19 step:14857[D loss: 0.409535, acc: 60.16%, op_acc: 39.84%] [G loss: 0.895856]\n",
      "epoch:19 step:14858[D loss: 0.404043, acc: 63.28%, op_acc: 42.97%] [G loss: 0.892982]\n",
      "epoch:19 step:14859[D loss: 0.418255, acc: 63.28%, op_acc: 42.19%] [G loss: 0.867747]\n",
      "epoch:19 step:14860[D loss: 0.470973, acc: 50.00%, op_acc: 33.59%] [G loss: 0.859817]\n",
      "epoch:19 step:14861[D loss: 0.432042, acc: 63.28%, op_acc: 36.72%] [G loss: 0.877506]\n",
      "epoch:19 step:14862[D loss: 0.430696, acc: 55.47%, op_acc: 39.06%] [G loss: 0.825618]\n",
      "epoch:19 step:14863[D loss: 0.451932, acc: 53.91%, op_acc: 35.94%] [G loss: 0.879057]\n",
      "epoch:19 step:14864[D loss: 0.461012, acc: 55.47%, op_acc: 34.38%] [G loss: 0.914719]\n",
      "epoch:19 step:14865[D loss: 0.431536, acc: 58.59%, op_acc: 36.72%] [G loss: 0.866394]\n",
      "epoch:19 step:14866[D loss: 0.439178, acc: 61.72%, op_acc: 39.06%] [G loss: 0.892680]\n",
      "epoch:19 step:14867[D loss: 0.415681, acc: 60.16%, op_acc: 42.19%] [G loss: 0.881038]\n",
      "epoch:19 step:14868[D loss: 0.418562, acc: 61.72%, op_acc: 38.28%] [G loss: 0.870581]\n",
      "epoch:19 step:14869[D loss: 0.435188, acc: 57.81%, op_acc: 39.06%] [G loss: 0.881039]\n",
      "epoch:19 step:14870[D loss: 0.435279, acc: 58.59%, op_acc: 38.28%] [G loss: 0.912974]\n",
      "epoch:19 step:14871[D loss: 0.427061, acc: 59.38%, op_acc: 36.72%] [G loss: 0.904300]\n",
      "epoch:19 step:14872[D loss: 0.417509, acc: 58.59%, op_acc: 42.97%] [G loss: 0.865861]\n",
      "epoch:19 step:14873[D loss: 0.424496, acc: 64.84%, op_acc: 38.28%] [G loss: 0.864459]\n",
      "epoch:19 step:14874[D loss: 0.468725, acc: 50.00%, op_acc: 39.06%] [G loss: 0.744471]\n",
      "epoch:19 step:14875[D loss: 0.408793, acc: 62.50%, op_acc: 36.72%] [G loss: 0.828352]\n",
      "epoch:19 step:14876[D loss: 0.420906, acc: 61.72%, op_acc: 41.41%] [G loss: 0.924584]\n",
      "epoch:19 step:14877[D loss: 0.400804, acc: 60.16%, op_acc: 41.41%] [G loss: 0.877543]\n",
      "epoch:19 step:14878[D loss: 0.441010, acc: 46.88%, op_acc: 39.06%] [G loss: 0.810847]\n",
      "epoch:19 step:14879[D loss: 0.439819, acc: 59.38%, op_acc: 37.50%] [G loss: 0.845875]\n",
      "epoch:19 step:14880[D loss: 0.422224, acc: 62.50%, op_acc: 39.84%] [G loss: 0.912568]\n",
      "epoch:19 step:14881[D loss: 0.404372, acc: 62.50%, op_acc: 41.41%] [G loss: 0.886580]\n",
      "epoch:19 step:14882[D loss: 0.408071, acc: 64.84%, op_acc: 35.16%] [G loss: 0.877657]\n",
      "epoch:19 step:14883[D loss: 0.420321, acc: 60.16%, op_acc: 39.06%] [G loss: 0.858042]\n",
      "epoch:19 step:14884[D loss: 0.385172, acc: 68.75%, op_acc: 43.75%] [G loss: 0.948555]\n",
      "epoch:19 step:14885[D loss: 0.435185, acc: 62.50%, op_acc: 32.81%] [G loss: 0.880895]\n",
      "epoch:19 step:14886[D loss: 0.453821, acc: 53.12%, op_acc: 34.38%] [G loss: 0.878125]\n",
      "epoch:19 step:14887[D loss: 0.428365, acc: 63.28%, op_acc: 35.16%] [G loss: 0.875890]\n",
      "epoch:19 step:14888[D loss: 0.431863, acc: 67.19%, op_acc: 32.03%] [G loss: 0.839256]\n",
      "epoch:19 step:14889[D loss: 0.409617, acc: 59.38%, op_acc: 41.41%] [G loss: 0.837920]\n",
      "epoch:19 step:14890[D loss: 0.422772, acc: 68.75%, op_acc: 35.94%] [G loss: 0.909379]\n",
      "epoch:19 step:14891[D loss: 0.438408, acc: 57.03%, op_acc: 37.50%] [G loss: 0.831854]\n",
      "epoch:19 step:14892[D loss: 0.460303, acc: 58.59%, op_acc: 33.59%] [G loss: 0.844129]\n",
      "epoch:19 step:14893[D loss: 0.461019, acc: 53.91%, op_acc: 40.62%] [G loss: 0.821371]\n",
      "epoch:19 step:14894[D loss: 0.422054, acc: 59.38%, op_acc: 39.84%] [G loss: 0.908920]\n",
      "epoch:19 step:14895[D loss: 0.429912, acc: 59.38%, op_acc: 37.50%] [G loss: 0.986000]\n",
      "epoch:19 step:14896[D loss: 0.454125, acc: 54.69%, op_acc: 36.72%] [G loss: 0.975834]\n",
      "epoch:19 step:14897[D loss: 0.423575, acc: 54.69%, op_acc: 42.97%] [G loss: 0.815295]\n",
      "epoch:19 step:14898[D loss: 0.410160, acc: 62.50%, op_acc: 42.19%] [G loss: 0.849351]\n",
      "epoch:19 step:14899[D loss: 0.405333, acc: 66.41%, op_acc: 42.19%] [G loss: 0.885015]\n",
      "epoch:19 step:14900[D loss: 0.436956, acc: 58.59%, op_acc: 37.50%] [G loss: 0.832499]\n",
      "##############\n",
      "[0.86578994 0.8581521  0.81169345 0.80360719 0.80550222 0.82706975\n",
      " 0.90050609 0.82998712 0.80241807 0.82605699]\n",
      "##########\n",
      "epoch:19 step:14901[D loss: 0.421218, acc: 58.59%, op_acc: 38.28%] [G loss: 0.935319]\n",
      "epoch:19 step:14902[D loss: 0.439873, acc: 55.47%, op_acc: 37.50%] [G loss: 0.852758]\n",
      "epoch:19 step:14903[D loss: 0.411871, acc: 62.50%, op_acc: 39.06%] [G loss: 0.818435]\n",
      "epoch:19 step:14904[D loss: 0.422242, acc: 60.16%, op_acc: 42.97%] [G loss: 0.886870]\n",
      "epoch:19 step:14905[D loss: 0.432772, acc: 58.59%, op_acc: 38.28%] [G loss: 0.917197]\n",
      "epoch:19 step:14906[D loss: 0.411838, acc: 60.16%, op_acc: 39.06%] [G loss: 0.915879]\n",
      "epoch:19 step:14907[D loss: 0.443819, acc: 52.34%, op_acc: 36.72%] [G loss: 0.819828]\n",
      "epoch:19 step:14908[D loss: 0.406193, acc: 57.81%, op_acc: 41.41%] [G loss: 0.805637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:14909[D loss: 0.420850, acc: 64.06%, op_acc: 40.62%] [G loss: 0.871514]\n",
      "epoch:19 step:14910[D loss: 0.471123, acc: 59.38%, op_acc: 30.47%] [G loss: 0.889106]\n",
      "epoch:19 step:14911[D loss: 0.396724, acc: 64.06%, op_acc: 36.72%] [G loss: 0.839926]\n",
      "epoch:19 step:14912[D loss: 0.396818, acc: 65.62%, op_acc: 41.41%] [G loss: 0.887406]\n",
      "epoch:19 step:14913[D loss: 0.393823, acc: 64.84%, op_acc: 36.72%] [G loss: 0.882639]\n",
      "epoch:19 step:14914[D loss: 0.439072, acc: 56.25%, op_acc: 37.50%] [G loss: 0.846981]\n",
      "epoch:19 step:14915[D loss: 0.458898, acc: 60.94%, op_acc: 34.38%] [G loss: 0.886744]\n",
      "epoch:19 step:14916[D loss: 0.417828, acc: 62.50%, op_acc: 35.16%] [G loss: 0.914493]\n",
      "epoch:19 step:14917[D loss: 0.435683, acc: 68.75%, op_acc: 31.25%] [G loss: 0.915687]\n",
      "epoch:19 step:14918[D loss: 0.487120, acc: 49.22%, op_acc: 37.50%] [G loss: 0.887650]\n",
      "epoch:19 step:14919[D loss: 0.459568, acc: 53.12%, op_acc: 31.25%] [G loss: 0.932381]\n",
      "epoch:19 step:14920[D loss: 0.429232, acc: 57.81%, op_acc: 33.59%] [G loss: 0.831223]\n",
      "epoch:19 step:14921[D loss: 0.428072, acc: 59.38%, op_acc: 39.06%] [G loss: 0.902781]\n",
      "epoch:19 step:14922[D loss: 0.446967, acc: 55.47%, op_acc: 35.94%] [G loss: 0.844969]\n",
      "epoch:19 step:14923[D loss: 0.390265, acc: 71.09%, op_acc: 39.06%] [G loss: 0.914162]\n",
      "epoch:19 step:14924[D loss: 0.445456, acc: 58.59%, op_acc: 35.94%] [G loss: 0.886745]\n",
      "epoch:19 step:14925[D loss: 0.402628, acc: 66.41%, op_acc: 36.72%] [G loss: 0.932833]\n",
      "epoch:19 step:14926[D loss: 0.410648, acc: 65.62%, op_acc: 37.50%] [G loss: 0.951725]\n",
      "epoch:19 step:14927[D loss: 0.439977, acc: 56.25%, op_acc: 39.84%] [G loss: 0.925391]\n",
      "epoch:19 step:14928[D loss: 0.433509, acc: 56.25%, op_acc: 35.94%] [G loss: 0.886923]\n",
      "epoch:19 step:14929[D loss: 0.417381, acc: 60.94%, op_acc: 41.41%] [G loss: 0.876263]\n",
      "epoch:19 step:14930[D loss: 0.391348, acc: 69.53%, op_acc: 42.19%] [G loss: 0.878569]\n",
      "epoch:19 step:14931[D loss: 0.463861, acc: 59.38%, op_acc: 32.81%] [G loss: 0.907025]\n",
      "epoch:19 step:14932[D loss: 0.398117, acc: 64.84%, op_acc: 39.06%] [G loss: 0.918408]\n",
      "epoch:19 step:14933[D loss: 0.395768, acc: 63.28%, op_acc: 35.16%] [G loss: 0.967871]\n",
      "epoch:19 step:14934[D loss: 0.433051, acc: 53.91%, op_acc: 41.41%] [G loss: 0.907664]\n",
      "epoch:19 step:14935[D loss: 0.441341, acc: 62.50%, op_acc: 33.59%] [G loss: 0.929317]\n",
      "epoch:19 step:14936[D loss: 0.411137, acc: 59.38%, op_acc: 40.62%] [G loss: 0.941514]\n",
      "epoch:19 step:14937[D loss: 0.418024, acc: 65.62%, op_acc: 36.72%] [G loss: 0.819182]\n",
      "epoch:19 step:14938[D loss: 0.405842, acc: 60.16%, op_acc: 41.41%] [G loss: 0.879910]\n",
      "epoch:19 step:14939[D loss: 0.428195, acc: 55.47%, op_acc: 40.62%] [G loss: 0.911866]\n",
      "epoch:19 step:14940[D loss: 0.436800, acc: 53.91%, op_acc: 41.41%] [G loss: 0.876402]\n",
      "epoch:19 step:14941[D loss: 0.404196, acc: 64.84%, op_acc: 40.62%] [G loss: 0.956115]\n",
      "epoch:19 step:14942[D loss: 0.391687, acc: 67.19%, op_acc: 39.84%] [G loss: 0.933500]\n",
      "epoch:19 step:14943[D loss: 0.426271, acc: 65.62%, op_acc: 40.62%] [G loss: 0.819235]\n",
      "epoch:19 step:14944[D loss: 0.461430, acc: 57.81%, op_acc: 37.50%] [G loss: 0.795738]\n",
      "epoch:19 step:14945[D loss: 0.429989, acc: 51.56%, op_acc: 35.94%] [G loss: 0.807401]\n",
      "epoch:19 step:14946[D loss: 0.419989, acc: 63.28%, op_acc: 38.28%] [G loss: 0.858388]\n",
      "epoch:19 step:14947[D loss: 0.459471, acc: 50.78%, op_acc: 32.03%] [G loss: 0.951225]\n",
      "epoch:19 step:14948[D loss: 0.424211, acc: 59.38%, op_acc: 39.84%] [G loss: 0.863595]\n",
      "epoch:19 step:14949[D loss: 0.423250, acc: 60.94%, op_acc: 43.75%] [G loss: 0.975559]\n",
      "epoch:19 step:14950[D loss: 0.455477, acc: 52.34%, op_acc: 31.25%] [G loss: 0.815913]\n",
      "##############\n",
      "[0.85585194 0.85708756 0.81466531 0.80347035 0.79977096 0.83401195\n",
      " 0.89301165 0.78581742 0.80723056 0.83327445]\n",
      "##########\n",
      "epoch:19 step:14951[D loss: 0.415560, acc: 57.81%, op_acc: 44.53%] [G loss: 0.834582]\n",
      "epoch:19 step:14952[D loss: 0.457595, acc: 55.47%, op_acc: 28.91%] [G loss: 0.915014]\n",
      "epoch:19 step:14953[D loss: 0.407504, acc: 57.03%, op_acc: 42.97%] [G loss: 0.942431]\n",
      "epoch:19 step:14954[D loss: 0.415297, acc: 54.69%, op_acc: 44.53%] [G loss: 0.912744]\n",
      "epoch:19 step:14955[D loss: 0.460479, acc: 55.47%, op_acc: 33.59%] [G loss: 0.912145]\n",
      "epoch:19 step:14956[D loss: 0.409744, acc: 63.28%, op_acc: 39.06%] [G loss: 0.925290]\n",
      "epoch:19 step:14957[D loss: 0.439606, acc: 53.91%, op_acc: 39.06%] [G loss: 0.816523]\n",
      "epoch:19 step:14958[D loss: 0.412416, acc: 61.72%, op_acc: 40.62%] [G loss: 0.903562]\n",
      "epoch:19 step:14959[D loss: 0.440785, acc: 53.12%, op_acc: 32.03%] [G loss: 0.837764]\n",
      "epoch:19 step:14960[D loss: 0.417466, acc: 60.94%, op_acc: 39.84%] [G loss: 0.847237]\n",
      "epoch:19 step:14961[D loss: 0.412246, acc: 68.75%, op_acc: 40.62%] [G loss: 0.886713]\n",
      "epoch:19 step:14962[D loss: 0.442794, acc: 59.38%, op_acc: 39.84%] [G loss: 0.900116]\n",
      "epoch:19 step:14963[D loss: 0.442549, acc: 57.81%, op_acc: 36.72%] [G loss: 0.910744]\n",
      "epoch:19 step:14964[D loss: 0.452524, acc: 52.34%, op_acc: 38.28%] [G loss: 0.844263]\n",
      "epoch:19 step:14965[D loss: 0.430385, acc: 53.91%, op_acc: 40.62%] [G loss: 0.904739]\n",
      "epoch:19 step:14966[D loss: 0.434981, acc: 60.94%, op_acc: 35.16%] [G loss: 0.891527]\n",
      "epoch:19 step:14967[D loss: 0.438961, acc: 54.69%, op_acc: 38.28%] [G loss: 0.938909]\n",
      "epoch:19 step:14968[D loss: 0.457621, acc: 59.38%, op_acc: 32.81%] [G loss: 0.806074]\n",
      "epoch:19 step:14969[D loss: 0.437397, acc: 53.12%, op_acc: 45.31%] [G loss: 0.916226]\n",
      "epoch:19 step:14970[D loss: 0.426544, acc: 59.38%, op_acc: 35.94%] [G loss: 0.831018]\n",
      "epoch:19 step:14971[D loss: 0.414561, acc: 58.59%, op_acc: 39.84%] [G loss: 0.949083]\n",
      "epoch:19 step:14972[D loss: 0.462458, acc: 60.94%, op_acc: 32.03%] [G loss: 0.926581]\n",
      "epoch:19 step:14973[D loss: 0.421496, acc: 54.69%, op_acc: 38.28%] [G loss: 0.947419]\n",
      "epoch:19 step:14974[D loss: 0.444420, acc: 60.94%, op_acc: 35.16%] [G loss: 0.912012]\n",
      "epoch:19 step:14975[D loss: 0.400777, acc: 61.72%, op_acc: 46.09%] [G loss: 0.908406]\n",
      "epoch:19 step:14976[D loss: 0.424161, acc: 62.50%, op_acc: 37.50%] [G loss: 0.925077]\n",
      "epoch:19 step:14977[D loss: 0.461911, acc: 50.78%, op_acc: 34.38%] [G loss: 0.789549]\n",
      "epoch:19 step:14978[D loss: 0.424233, acc: 57.81%, op_acc: 41.41%] [G loss: 0.829143]\n",
      "epoch:19 step:14979[D loss: 0.451450, acc: 57.03%, op_acc: 35.94%] [G loss: 0.877394]\n",
      "epoch:19 step:14980[D loss: 0.444949, acc: 64.06%, op_acc: 35.16%] [G loss: 0.877539]\n",
      "epoch:19 step:14981[D loss: 0.399359, acc: 68.75%, op_acc: 36.72%] [G loss: 0.861112]\n",
      "epoch:19 step:14982[D loss: 0.413827, acc: 62.50%, op_acc: 38.28%] [G loss: 0.899560]\n",
      "epoch:19 step:14983[D loss: 0.453998, acc: 56.25%, op_acc: 38.28%] [G loss: 0.904800]\n",
      "epoch:19 step:14984[D loss: 0.425893, acc: 60.16%, op_acc: 35.94%] [G loss: 0.943396]\n",
      "epoch:19 step:14985[D loss: 0.420222, acc: 61.72%, op_acc: 35.94%] [G loss: 0.859046]\n",
      "epoch:19 step:14986[D loss: 0.474435, acc: 51.56%, op_acc: 36.72%] [G loss: 0.842257]\n",
      "epoch:19 step:14987[D loss: 0.449648, acc: 54.69%, op_acc: 37.50%] [G loss: 0.839987]\n",
      "epoch:19 step:14988[D loss: 0.422000, acc: 55.47%, op_acc: 38.28%] [G loss: 0.881786]\n",
      "epoch:19 step:14989[D loss: 0.428071, acc: 56.25%, op_acc: 41.41%] [G loss: 0.957410]\n",
      "epoch:19 step:14990[D loss: 0.394423, acc: 64.06%, op_acc: 45.31%] [G loss: 0.901457]\n",
      "epoch:19 step:14991[D loss: 0.421357, acc: 64.06%, op_acc: 39.06%] [G loss: 0.973127]\n",
      "epoch:19 step:14992[D loss: 0.443000, acc: 52.34%, op_acc: 34.38%] [G loss: 0.904919]\n",
      "epoch:19 step:14993[D loss: 0.432544, acc: 61.72%, op_acc: 35.16%] [G loss: 0.894080]\n",
      "epoch:19 step:14994[D loss: 0.430558, acc: 50.78%, op_acc: 44.53%] [G loss: 0.870852]\n",
      "epoch:19 step:14995[D loss: 0.440641, acc: 56.25%, op_acc: 36.72%] [G loss: 0.847577]\n",
      "epoch:19 step:14996[D loss: 0.447063, acc: 55.47%, op_acc: 37.50%] [G loss: 0.869418]\n",
      "epoch:19 step:14997[D loss: 0.413182, acc: 57.81%, op_acc: 38.28%] [G loss: 0.843289]\n",
      "epoch:19 step:14998[D loss: 0.401527, acc: 64.84%, op_acc: 42.97%] [G loss: 0.929852]\n",
      "epoch:19 step:14999[D loss: 0.473356, acc: 48.44%, op_acc: 32.81%] [G loss: 0.862033]\n",
      "epoch:19 step:15000[D loss: 0.405519, acc: 67.97%, op_acc: 41.41%] [G loss: 0.896822]\n",
      "##############\n",
      "[0.87857891 0.85628838 0.82885154 0.78879986 0.80428804 0.81205141\n",
      " 0.91167825 0.82662807 0.79845174 0.8259981 ]\n",
      "##########\n",
      "epoch:19 step:15001[D loss: 0.431417, acc: 59.38%, op_acc: 40.62%] [G loss: 0.886102]\n",
      "epoch:19 step:15002[D loss: 0.437795, acc: 63.28%, op_acc: 37.50%] [G loss: 0.891213]\n",
      "epoch:19 step:15003[D loss: 0.443969, acc: 61.72%, op_acc: 31.25%] [G loss: 0.933324]\n",
      "epoch:19 step:15004[D loss: 0.414676, acc: 61.72%, op_acc: 36.72%] [G loss: 0.899477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15005[D loss: 0.459981, acc: 53.91%, op_acc: 30.47%] [G loss: 0.872726]\n",
      "epoch:19 step:15006[D loss: 0.413793, acc: 59.38%, op_acc: 37.50%] [G loss: 0.907282]\n",
      "epoch:19 step:15007[D loss: 0.393518, acc: 64.84%, op_acc: 46.09%] [G loss: 0.952243]\n",
      "epoch:19 step:15008[D loss: 0.437825, acc: 60.94%, op_acc: 40.62%] [G loss: 0.885752]\n",
      "epoch:19 step:15009[D loss: 0.423569, acc: 60.94%, op_acc: 40.62%] [G loss: 0.909096]\n",
      "epoch:19 step:15010[D loss: 0.440963, acc: 53.91%, op_acc: 35.16%] [G loss: 0.905933]\n",
      "epoch:19 step:15011[D loss: 0.444219, acc: 57.03%, op_acc: 39.84%] [G loss: 0.832260]\n",
      "epoch:19 step:15012[D loss: 0.416082, acc: 66.41%, op_acc: 37.50%] [G loss: 0.862409]\n",
      "epoch:19 step:15013[D loss: 0.480809, acc: 53.91%, op_acc: 39.06%] [G loss: 0.878734]\n",
      "epoch:19 step:15014[D loss: 0.403994, acc: 61.72%, op_acc: 42.19%] [G loss: 0.841294]\n",
      "epoch:19 step:15015[D loss: 0.408745, acc: 63.28%, op_acc: 41.41%] [G loss: 0.886118]\n",
      "epoch:19 step:15016[D loss: 0.391736, acc: 68.75%, op_acc: 43.75%] [G loss: 0.858143]\n",
      "epoch:19 step:15017[D loss: 0.416309, acc: 62.50%, op_acc: 39.84%] [G loss: 0.861823]\n",
      "epoch:19 step:15018[D loss: 0.408718, acc: 60.16%, op_acc: 39.84%] [G loss: 0.838812]\n",
      "epoch:19 step:15019[D loss: 0.450832, acc: 53.12%, op_acc: 33.59%] [G loss: 0.749797]\n",
      "epoch:19 step:15020[D loss: 0.418374, acc: 64.06%, op_acc: 36.72%] [G loss: 0.941413]\n",
      "epoch:19 step:15021[D loss: 0.404177, acc: 63.28%, op_acc: 41.41%] [G loss: 0.863246]\n",
      "epoch:19 step:15022[D loss: 0.432600, acc: 54.69%, op_acc: 42.19%] [G loss: 0.927874]\n",
      "epoch:19 step:15023[D loss: 0.413579, acc: 64.06%, op_acc: 36.72%] [G loss: 0.940654]\n",
      "epoch:19 step:15024[D loss: 0.448810, acc: 60.16%, op_acc: 36.72%] [G loss: 0.894775]\n",
      "epoch:19 step:15025[D loss: 0.438762, acc: 55.47%, op_acc: 42.19%] [G loss: 0.885967]\n",
      "epoch:19 step:15026[D loss: 0.396895, acc: 60.94%, op_acc: 45.31%] [G loss: 0.945069]\n",
      "epoch:19 step:15027[D loss: 0.424590, acc: 56.25%, op_acc: 40.62%] [G loss: 0.948372]\n",
      "epoch:19 step:15028[D loss: 0.421067, acc: 63.28%, op_acc: 36.72%] [G loss: 0.914815]\n",
      "epoch:19 step:15029[D loss: 0.437649, acc: 55.47%, op_acc: 35.94%] [G loss: 0.894899]\n",
      "epoch:19 step:15030[D loss: 0.401366, acc: 65.62%, op_acc: 42.97%] [G loss: 0.873743]\n",
      "epoch:19 step:15031[D loss: 0.403989, acc: 71.88%, op_acc: 38.28%] [G loss: 0.861995]\n",
      "epoch:19 step:15032[D loss: 0.478206, acc: 53.91%, op_acc: 32.03%] [G loss: 0.815369]\n",
      "epoch:19 step:15033[D loss: 0.434997, acc: 60.16%, op_acc: 39.06%] [G loss: 0.934446]\n",
      "epoch:19 step:15034[D loss: 0.449732, acc: 58.59%, op_acc: 35.16%] [G loss: 0.802673]\n",
      "epoch:19 step:15035[D loss: 0.431834, acc: 61.72%, op_acc: 35.94%] [G loss: 0.920975]\n",
      "epoch:19 step:15036[D loss: 0.453137, acc: 52.34%, op_acc: 39.06%] [G loss: 0.820605]\n",
      "epoch:19 step:15037[D loss: 0.467818, acc: 51.56%, op_acc: 36.72%] [G loss: 0.803574]\n",
      "epoch:19 step:15038[D loss: 0.437375, acc: 53.12%, op_acc: 40.62%] [G loss: 0.960596]\n",
      "epoch:19 step:15039[D loss: 0.422827, acc: 53.91%, op_acc: 38.28%] [G loss: 0.868424]\n",
      "epoch:19 step:15040[D loss: 0.416701, acc: 59.38%, op_acc: 37.50%] [G loss: 0.867972]\n",
      "epoch:19 step:15041[D loss: 0.450403, acc: 57.03%, op_acc: 34.38%] [G loss: 0.870013]\n",
      "epoch:19 step:15042[D loss: 0.449199, acc: 53.12%, op_acc: 33.59%] [G loss: 0.839464]\n",
      "epoch:19 step:15043[D loss: 0.427566, acc: 63.28%, op_acc: 36.72%] [G loss: 0.901461]\n",
      "epoch:19 step:15044[D loss: 0.412795, acc: 67.19%, op_acc: 33.59%] [G loss: 0.872171]\n",
      "epoch:19 step:15045[D loss: 0.450020, acc: 52.34%, op_acc: 39.84%] [G loss: 1.007076]\n",
      "epoch:19 step:15046[D loss: 0.399465, acc: 64.06%, op_acc: 41.41%] [G loss: 0.910988]\n",
      "epoch:19 step:15047[D loss: 0.425103, acc: 63.28%, op_acc: 35.94%] [G loss: 0.860926]\n",
      "epoch:19 step:15048[D loss: 0.430746, acc: 53.12%, op_acc: 38.28%] [G loss: 0.861362]\n",
      "epoch:19 step:15049[D loss: 0.454081, acc: 53.91%, op_acc: 35.94%] [G loss: 0.849350]\n",
      "epoch:19 step:15050[D loss: 0.416576, acc: 56.25%, op_acc: 40.62%] [G loss: 0.862841]\n",
      "##############\n",
      "[0.85446536 0.84803363 0.8178624  0.80881729 0.81285454 0.85181897\n",
      " 0.86942196 0.82182719 0.80691702 0.81833507]\n",
      "##########\n",
      "epoch:19 step:15051[D loss: 0.434012, acc: 54.69%, op_acc: 35.16%] [G loss: 0.820228]\n",
      "epoch:19 step:15052[D loss: 0.441132, acc: 50.78%, op_acc: 37.50%] [G loss: 0.868629]\n",
      "epoch:19 step:15053[D loss: 0.457895, acc: 58.59%, op_acc: 32.03%] [G loss: 0.878468]\n",
      "epoch:19 step:15054[D loss: 0.443225, acc: 60.16%, op_acc: 34.38%] [G loss: 0.880687]\n",
      "epoch:19 step:15055[D loss: 0.442102, acc: 55.47%, op_acc: 32.03%] [G loss: 0.898177]\n",
      "epoch:19 step:15056[D loss: 0.417406, acc: 65.62%, op_acc: 41.41%] [G loss: 0.893038]\n",
      "epoch:19 step:15057[D loss: 0.425575, acc: 57.03%, op_acc: 38.28%] [G loss: 0.924459]\n",
      "epoch:19 step:15058[D loss: 0.420227, acc: 54.69%, op_acc: 39.84%] [G loss: 0.914023]\n",
      "epoch:19 step:15059[D loss: 0.452301, acc: 57.03%, op_acc: 33.59%] [G loss: 0.906139]\n",
      "epoch:19 step:15060[D loss: 0.437950, acc: 58.59%, op_acc: 32.03%] [G loss: 0.932441]\n",
      "epoch:19 step:15061[D loss: 0.429971, acc: 58.59%, op_acc: 41.41%] [G loss: 0.854443]\n",
      "epoch:19 step:15062[D loss: 0.459808, acc: 48.44%, op_acc: 40.62%] [G loss: 0.832617]\n",
      "epoch:19 step:15063[D loss: 0.427500, acc: 52.34%, op_acc: 37.50%] [G loss: 0.871908]\n",
      "epoch:19 step:15064[D loss: 0.411153, acc: 67.19%, op_acc: 40.62%] [G loss: 0.857845]\n",
      "epoch:19 step:15065[D loss: 0.429093, acc: 60.94%, op_acc: 41.41%] [G loss: 0.935527]\n",
      "epoch:19 step:15066[D loss: 0.433165, acc: 54.69%, op_acc: 37.50%] [G loss: 0.822016]\n",
      "epoch:19 step:15067[D loss: 0.433479, acc: 48.44%, op_acc: 38.28%] [G loss: 0.835403]\n",
      "epoch:19 step:15068[D loss: 0.424978, acc: 59.38%, op_acc: 37.50%] [G loss: 0.909021]\n",
      "epoch:19 step:15069[D loss: 0.439539, acc: 57.81%, op_acc: 33.59%] [G loss: 0.883574]\n",
      "epoch:19 step:15070[D loss: 0.397510, acc: 66.41%, op_acc: 42.97%] [G loss: 0.912667]\n",
      "epoch:19 step:15071[D loss: 0.425788, acc: 58.59%, op_acc: 35.94%] [G loss: 0.913816]\n",
      "epoch:19 step:15072[D loss: 0.416438, acc: 65.62%, op_acc: 35.94%] [G loss: 0.793617]\n",
      "epoch:19 step:15073[D loss: 0.462904, acc: 61.72%, op_acc: 28.12%] [G loss: 0.852182]\n",
      "epoch:19 step:15074[D loss: 0.421168, acc: 57.81%, op_acc: 42.19%] [G loss: 0.899623]\n",
      "epoch:19 step:15075[D loss: 0.428631, acc: 60.16%, op_acc: 34.38%] [G loss: 0.961342]\n",
      "epoch:19 step:15076[D loss: 0.424726, acc: 53.12%, op_acc: 36.72%] [G loss: 0.953675]\n",
      "epoch:19 step:15077[D loss: 0.434010, acc: 51.56%, op_acc: 36.72%] [G loss: 0.821478]\n",
      "epoch:19 step:15078[D loss: 0.396613, acc: 65.62%, op_acc: 39.06%] [G loss: 1.034868]\n",
      "epoch:19 step:15079[D loss: 0.429459, acc: 61.72%, op_acc: 37.50%] [G loss: 0.885104]\n",
      "epoch:19 step:15080[D loss: 0.416007, acc: 58.59%, op_acc: 38.28%] [G loss: 0.864383]\n",
      "epoch:19 step:15081[D loss: 0.409937, acc: 59.38%, op_acc: 40.62%] [G loss: 0.873572]\n",
      "epoch:19 step:15082[D loss: 0.415404, acc: 60.16%, op_acc: 39.06%] [G loss: 0.858551]\n",
      "epoch:19 step:15083[D loss: 0.455721, acc: 57.81%, op_acc: 35.94%] [G loss: 0.837312]\n",
      "epoch:19 step:15084[D loss: 0.428620, acc: 56.25%, op_acc: 41.41%] [G loss: 0.820832]\n",
      "epoch:19 step:15085[D loss: 0.467972, acc: 56.25%, op_acc: 38.28%] [G loss: 0.839799]\n",
      "epoch:19 step:15086[D loss: 0.401263, acc: 57.03%, op_acc: 42.97%] [G loss: 0.891794]\n",
      "epoch:19 step:15087[D loss: 0.452233, acc: 56.25%, op_acc: 32.81%] [G loss: 0.890521]\n",
      "epoch:19 step:15088[D loss: 0.442796, acc: 57.81%, op_acc: 35.16%] [G loss: 0.897791]\n",
      "epoch:19 step:15089[D loss: 0.481136, acc: 46.09%, op_acc: 34.38%] [G loss: 0.770921]\n",
      "epoch:19 step:15090[D loss: 0.414732, acc: 64.84%, op_acc: 37.50%] [G loss: 0.827672]\n",
      "epoch:19 step:15091[D loss: 0.448137, acc: 50.00%, op_acc: 39.84%] [G loss: 0.813133]\n",
      "epoch:19 step:15092[D loss: 0.440173, acc: 60.16%, op_acc: 34.38%] [G loss: 0.838916]\n",
      "epoch:19 step:15093[D loss: 0.439882, acc: 61.72%, op_acc: 32.81%] [G loss: 0.852303]\n",
      "epoch:19 step:15094[D loss: 0.439593, acc: 53.12%, op_acc: 35.94%] [G loss: 0.823908]\n",
      "epoch:19 step:15095[D loss: 0.458790, acc: 53.91%, op_acc: 36.72%] [G loss: 0.858048]\n",
      "epoch:19 step:15096[D loss: 0.437857, acc: 62.50%, op_acc: 39.06%] [G loss: 0.810244]\n",
      "epoch:19 step:15097[D loss: 0.395142, acc: 67.97%, op_acc: 40.62%] [G loss: 0.936358]\n",
      "epoch:19 step:15098[D loss: 0.433406, acc: 57.81%, op_acc: 33.59%] [G loss: 0.807455]\n",
      "epoch:19 step:15099[D loss: 0.432332, acc: 69.53%, op_acc: 39.06%] [G loss: 0.885501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15100[D loss: 0.434329, acc: 63.28%, op_acc: 34.38%] [G loss: 0.925965]\n",
      "##############\n",
      "[0.84161149 0.85659488 0.81571591 0.81470092 0.80976785 0.82766502\n",
      " 0.8631252  0.82497845 0.79755083 0.80818345]\n",
      "##########\n",
      "epoch:19 step:15101[D loss: 0.429229, acc: 62.50%, op_acc: 36.72%] [G loss: 0.878186]\n",
      "epoch:19 step:15102[D loss: 0.431559, acc: 58.59%, op_acc: 40.62%] [G loss: 0.885599]\n",
      "epoch:19 step:15103[D loss: 0.451809, acc: 50.78%, op_acc: 36.72%] [G loss: 0.856024]\n",
      "epoch:19 step:15104[D loss: 0.431172, acc: 57.03%, op_acc: 39.06%] [G loss: 0.920066]\n",
      "epoch:19 step:15105[D loss: 0.420600, acc: 60.94%, op_acc: 39.06%] [G loss: 0.915944]\n",
      "epoch:19 step:15106[D loss: 0.451825, acc: 59.38%, op_acc: 38.28%] [G loss: 0.851461]\n",
      "epoch:19 step:15107[D loss: 0.415381, acc: 58.59%, op_acc: 40.62%] [G loss: 0.921857]\n",
      "epoch:19 step:15108[D loss: 0.443496, acc: 48.44%, op_acc: 42.97%] [G loss: 0.896755]\n",
      "epoch:19 step:15109[D loss: 0.447559, acc: 49.22%, op_acc: 39.06%] [G loss: 0.948108]\n",
      "epoch:19 step:15110[D loss: 0.423721, acc: 56.25%, op_acc: 39.84%] [G loss: 0.897453]\n",
      "epoch:19 step:15111[D loss: 0.408233, acc: 61.72%, op_acc: 35.16%] [G loss: 0.928760]\n",
      "epoch:19 step:15112[D loss: 0.415210, acc: 62.50%, op_acc: 39.84%] [G loss: 0.959348]\n",
      "epoch:19 step:15113[D loss: 0.433371, acc: 59.38%, op_acc: 42.97%] [G loss: 0.917235]\n",
      "epoch:19 step:15114[D loss: 0.423397, acc: 59.38%, op_acc: 41.41%] [G loss: 0.875268]\n",
      "epoch:19 step:15115[D loss: 0.441815, acc: 63.28%, op_acc: 38.28%] [G loss: 0.841480]\n",
      "epoch:19 step:15116[D loss: 0.428896, acc: 61.72%, op_acc: 31.25%] [G loss: 0.886774]\n",
      "epoch:19 step:15117[D loss: 0.460181, acc: 53.91%, op_acc: 38.28%] [G loss: 0.812384]\n",
      "epoch:19 step:15118[D loss: 0.420637, acc: 63.28%, op_acc: 40.62%] [G loss: 0.878314]\n",
      "epoch:19 step:15119[D loss: 0.402499, acc: 56.25%, op_acc: 42.19%] [G loss: 0.864219]\n",
      "epoch:19 step:15120[D loss: 0.442196, acc: 54.69%, op_acc: 33.59%] [G loss: 0.835093]\n",
      "epoch:19 step:15121[D loss: 0.438123, acc: 55.47%, op_acc: 35.94%] [G loss: 0.886245]\n",
      "epoch:19 step:15122[D loss: 0.410999, acc: 57.03%, op_acc: 43.75%] [G loss: 0.873945]\n",
      "epoch:19 step:15123[D loss: 0.421431, acc: 54.69%, op_acc: 42.97%] [G loss: 0.903089]\n",
      "epoch:19 step:15124[D loss: 0.440975, acc: 57.81%, op_acc: 39.84%] [G loss: 0.823916]\n",
      "epoch:19 step:15125[D loss: 0.458278, acc: 54.69%, op_acc: 38.28%] [G loss: 0.863936]\n",
      "epoch:19 step:15126[D loss: 0.445094, acc: 50.00%, op_acc: 42.19%] [G loss: 0.783311]\n",
      "epoch:19 step:15127[D loss: 0.401880, acc: 66.41%, op_acc: 36.72%] [G loss: 0.841896]\n",
      "epoch:19 step:15128[D loss: 0.424079, acc: 64.06%, op_acc: 34.38%] [G loss: 0.807131]\n",
      "epoch:19 step:15129[D loss: 0.422296, acc: 60.94%, op_acc: 35.16%] [G loss: 0.894016]\n",
      "epoch:19 step:15130[D loss: 0.444990, acc: 53.91%, op_acc: 39.84%] [G loss: 0.956007]\n",
      "epoch:19 step:15131[D loss: 0.441978, acc: 53.91%, op_acc: 39.06%] [G loss: 0.855017]\n",
      "epoch:19 step:15132[D loss: 0.441225, acc: 57.81%, op_acc: 37.50%] [G loss: 0.898596]\n",
      "epoch:19 step:15133[D loss: 0.439956, acc: 62.50%, op_acc: 32.81%] [G loss: 0.832113]\n",
      "epoch:19 step:15134[D loss: 0.438708, acc: 55.47%, op_acc: 38.28%] [G loss: 0.853516]\n",
      "epoch:19 step:15135[D loss: 0.433398, acc: 60.16%, op_acc: 40.62%] [G loss: 0.877039]\n",
      "epoch:19 step:15136[D loss: 0.471533, acc: 53.12%, op_acc: 32.03%] [G loss: 0.864504]\n",
      "epoch:19 step:15137[D loss: 0.415798, acc: 65.62%, op_acc: 35.94%] [G loss: 0.884688]\n",
      "epoch:19 step:15138[D loss: 0.414433, acc: 66.41%, op_acc: 38.28%] [G loss: 0.916050]\n",
      "epoch:19 step:15139[D loss: 0.465618, acc: 49.22%, op_acc: 33.59%] [G loss: 0.869513]\n",
      "epoch:19 step:15140[D loss: 0.431653, acc: 65.62%, op_acc: 34.38%] [G loss: 0.906134]\n",
      "epoch:19 step:15141[D loss: 0.430585, acc: 55.47%, op_acc: 39.84%] [G loss: 0.925779]\n",
      "epoch:19 step:15142[D loss: 0.464416, acc: 57.03%, op_acc: 35.16%] [G loss: 0.844290]\n",
      "epoch:19 step:15143[D loss: 0.419236, acc: 58.59%, op_acc: 35.94%] [G loss: 0.857320]\n",
      "epoch:19 step:15144[D loss: 0.427009, acc: 58.59%, op_acc: 37.50%] [G loss: 0.966470]\n",
      "epoch:19 step:15145[D loss: 0.462678, acc: 55.47%, op_acc: 34.38%] [G loss: 0.946536]\n",
      "epoch:19 step:15146[D loss: 0.437467, acc: 60.94%, op_acc: 39.06%] [G loss: 0.842105]\n",
      "epoch:19 step:15147[D loss: 0.428299, acc: 57.81%, op_acc: 41.41%] [G loss: 0.902840]\n",
      "epoch:19 step:15148[D loss: 0.464243, acc: 55.47%, op_acc: 32.81%] [G loss: 0.921353]\n",
      "epoch:19 step:15149[D loss: 0.433643, acc: 60.16%, op_acc: 36.72%] [G loss: 0.921820]\n",
      "epoch:19 step:15150[D loss: 0.437308, acc: 58.59%, op_acc: 35.94%] [G loss: 0.866874]\n",
      "##############\n",
      "[0.85066279 0.85905641 0.80707694 0.81520475 0.79565815 0.82357908\n",
      " 0.89889199 0.82690044 0.80563907 0.82211191]\n",
      "##########\n",
      "epoch:19 step:15151[D loss: 0.440502, acc: 50.00%, op_acc: 36.72%] [G loss: 0.883352]\n",
      "epoch:19 step:15152[D loss: 0.432635, acc: 62.50%, op_acc: 33.59%] [G loss: 0.850276]\n",
      "epoch:19 step:15153[D loss: 0.449451, acc: 54.69%, op_acc: 35.94%] [G loss: 0.865136]\n",
      "epoch:19 step:15154[D loss: 0.435268, acc: 54.69%, op_acc: 35.94%] [G loss: 0.909179]\n",
      "epoch:19 step:15155[D loss: 0.432050, acc: 63.28%, op_acc: 37.50%] [G loss: 0.817588]\n",
      "epoch:19 step:15156[D loss: 0.433120, acc: 57.03%, op_acc: 39.06%] [G loss: 0.882194]\n",
      "epoch:19 step:15157[D loss: 0.429276, acc: 57.81%, op_acc: 34.38%] [G loss: 0.894757]\n",
      "epoch:19 step:15158[D loss: 0.421942, acc: 64.06%, op_acc: 41.41%] [G loss: 0.895270]\n",
      "epoch:19 step:15159[D loss: 0.435060, acc: 56.25%, op_acc: 41.41%] [G loss: 0.858816]\n",
      "epoch:19 step:15160[D loss: 0.467897, acc: 50.00%, op_acc: 32.81%] [G loss: 0.840941]\n",
      "epoch:19 step:15161[D loss: 0.406999, acc: 64.06%, op_acc: 40.62%] [G loss: 0.859277]\n",
      "epoch:19 step:15162[D loss: 0.435841, acc: 57.81%, op_acc: 39.06%] [G loss: 0.801275]\n",
      "epoch:19 step:15163[D loss: 0.432201, acc: 65.62%, op_acc: 39.06%] [G loss: 0.877146]\n",
      "epoch:19 step:15164[D loss: 0.425890, acc: 61.72%, op_acc: 37.50%] [G loss: 0.855114]\n",
      "epoch:19 step:15165[D loss: 0.424591, acc: 58.59%, op_acc: 39.06%] [G loss: 0.865448]\n",
      "epoch:19 step:15166[D loss: 0.401187, acc: 60.94%, op_acc: 43.75%] [G loss: 0.870303]\n",
      "epoch:19 step:15167[D loss: 0.424502, acc: 61.72%, op_acc: 39.06%] [G loss: 0.925445]\n",
      "epoch:19 step:15168[D loss: 0.441302, acc: 52.34%, op_acc: 39.06%] [G loss: 0.923251]\n",
      "epoch:19 step:15169[D loss: 0.423914, acc: 60.94%, op_acc: 39.06%] [G loss: 0.834139]\n",
      "epoch:19 step:15170[D loss: 0.445224, acc: 61.72%, op_acc: 38.28%] [G loss: 0.864872]\n",
      "epoch:19 step:15171[D loss: 0.431242, acc: 59.38%, op_acc: 39.84%] [G loss: 0.858334]\n",
      "epoch:19 step:15172[D loss: 0.424552, acc: 57.81%, op_acc: 40.62%] [G loss: 0.867948]\n",
      "epoch:19 step:15173[D loss: 0.410818, acc: 61.72%, op_acc: 42.19%] [G loss: 0.883802]\n",
      "epoch:19 step:15174[D loss: 0.430254, acc: 59.38%, op_acc: 35.94%] [G loss: 0.951111]\n",
      "epoch:19 step:15175[D loss: 0.414709, acc: 65.62%, op_acc: 38.28%] [G loss: 0.886599]\n",
      "epoch:19 step:15176[D loss: 0.432978, acc: 62.50%, op_acc: 31.25%] [G loss: 0.877124]\n",
      "epoch:19 step:15177[D loss: 0.419074, acc: 56.25%, op_acc: 39.06%] [G loss: 0.902233]\n",
      "epoch:19 step:15178[D loss: 0.449109, acc: 50.78%, op_acc: 35.94%] [G loss: 0.831377]\n",
      "epoch:19 step:15179[D loss: 0.450240, acc: 61.72%, op_acc: 28.91%] [G loss: 0.841978]\n",
      "epoch:19 step:15180[D loss: 0.437995, acc: 60.16%, op_acc: 36.72%] [G loss: 0.840060]\n",
      "epoch:19 step:15181[D loss: 0.452906, acc: 52.34%, op_acc: 31.25%] [G loss: 0.831984]\n",
      "epoch:19 step:15182[D loss: 0.452133, acc: 50.78%, op_acc: 31.25%] [G loss: 0.973249]\n",
      "epoch:19 step:15183[D loss: 0.431010, acc: 58.59%, op_acc: 35.94%] [G loss: 0.870906]\n",
      "epoch:19 step:15184[D loss: 0.429883, acc: 58.59%, op_acc: 34.38%] [G loss: 0.861120]\n",
      "epoch:19 step:15185[D loss: 0.424563, acc: 62.50%, op_acc: 37.50%] [G loss: 0.882186]\n",
      "epoch:19 step:15186[D loss: 0.421257, acc: 61.72%, op_acc: 39.84%] [G loss: 0.803481]\n",
      "epoch:19 step:15187[D loss: 0.409728, acc: 59.38%, op_acc: 39.06%] [G loss: 0.925451]\n",
      "epoch:19 step:15188[D loss: 0.425988, acc: 60.16%, op_acc: 37.50%] [G loss: 0.862505]\n",
      "epoch:19 step:15189[D loss: 0.447349, acc: 57.03%, op_acc: 31.25%] [G loss: 0.863467]\n",
      "epoch:19 step:15190[D loss: 0.427892, acc: 64.84%, op_acc: 38.28%] [G loss: 1.002807]\n",
      "epoch:19 step:15191[D loss: 0.439856, acc: 56.25%, op_acc: 34.38%] [G loss: 0.874209]\n",
      "epoch:19 step:15192[D loss: 0.421264, acc: 57.81%, op_acc: 42.19%] [G loss: 0.866840]\n",
      "epoch:19 step:15193[D loss: 0.449239, acc: 55.47%, op_acc: 32.81%] [G loss: 0.962968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15194[D loss: 0.422637, acc: 64.06%, op_acc: 41.41%] [G loss: 0.911347]\n",
      "epoch:19 step:15195[D loss: 0.411279, acc: 57.03%, op_acc: 40.62%] [G loss: 0.878980]\n",
      "epoch:19 step:15196[D loss: 0.421442, acc: 64.84%, op_acc: 40.62%] [G loss: 0.836646]\n",
      "epoch:19 step:15197[D loss: 0.439443, acc: 57.03%, op_acc: 38.28%] [G loss: 0.882518]\n",
      "epoch:19 step:15198[D loss: 0.428926, acc: 63.28%, op_acc: 38.28%] [G loss: 0.923670]\n",
      "epoch:19 step:15199[D loss: 0.415687, acc: 66.41%, op_acc: 38.28%] [G loss: 0.917704]\n",
      "epoch:19 step:15200[D loss: 0.411383, acc: 65.62%, op_acc: 39.84%] [G loss: 0.862616]\n",
      "##############\n",
      "[0.83563015 0.84946321 0.80549018 0.82140266 0.79198285 0.83164504\n",
      " 0.87891262 0.84020438 0.79264282 0.81699101]\n",
      "##########\n",
      "epoch:19 step:15201[D loss: 0.415109, acc: 55.47%, op_acc: 42.19%] [G loss: 0.812524]\n",
      "epoch:19 step:15202[D loss: 0.428734, acc: 50.78%, op_acc: 38.28%] [G loss: 0.839417]\n",
      "epoch:19 step:15203[D loss: 0.436925, acc: 57.81%, op_acc: 32.81%] [G loss: 0.889991]\n",
      "epoch:19 step:15204[D loss: 0.383056, acc: 64.84%, op_acc: 40.62%] [G loss: 0.893105]\n",
      "epoch:19 step:15205[D loss: 0.437913, acc: 51.56%, op_acc: 42.97%] [G loss: 0.842126]\n",
      "epoch:19 step:15206[D loss: 0.423726, acc: 60.16%, op_acc: 35.94%] [G loss: 0.922087]\n",
      "epoch:19 step:15207[D loss: 0.414846, acc: 67.19%, op_acc: 32.03%] [G loss: 0.892778]\n",
      "epoch:19 step:15208[D loss: 0.411877, acc: 58.59%, op_acc: 35.94%] [G loss: 0.796004]\n",
      "epoch:19 step:15209[D loss: 0.466849, acc: 49.22%, op_acc: 33.59%] [G loss: 0.767763]\n",
      "epoch:19 step:15210[D loss: 0.413629, acc: 58.59%, op_acc: 42.97%] [G loss: 0.849341]\n",
      "epoch:19 step:15211[D loss: 0.443748, acc: 50.78%, op_acc: 36.72%] [G loss: 0.910842]\n",
      "epoch:19 step:15212[D loss: 0.421286, acc: 65.62%, op_acc: 44.53%] [G loss: 0.951492]\n",
      "epoch:19 step:15213[D loss: 0.422971, acc: 63.28%, op_acc: 42.19%] [G loss: 0.893981]\n",
      "epoch:19 step:15214[D loss: 0.423235, acc: 62.50%, op_acc: 33.59%] [G loss: 0.914100]\n",
      "epoch:19 step:15215[D loss: 0.407969, acc: 64.06%, op_acc: 33.59%] [G loss: 0.881163]\n",
      "epoch:19 step:15216[D loss: 0.449719, acc: 49.22%, op_acc: 36.72%] [G loss: 0.818511]\n",
      "epoch:19 step:15217[D loss: 0.405415, acc: 62.50%, op_acc: 42.97%] [G loss: 0.867381]\n",
      "epoch:19 step:15218[D loss: 0.409005, acc: 60.94%, op_acc: 37.50%] [G loss: 0.884355]\n",
      "epoch:19 step:15219[D loss: 0.414020, acc: 63.28%, op_acc: 41.41%] [G loss: 0.954654]\n",
      "epoch:19 step:15220[D loss: 0.408538, acc: 64.84%, op_acc: 42.97%] [G loss: 0.962598]\n",
      "epoch:19 step:15221[D loss: 0.430823, acc: 62.50%, op_acc: 39.06%] [G loss: 0.915062]\n",
      "epoch:19 step:15222[D loss: 0.422018, acc: 63.28%, op_acc: 42.19%] [G loss: 0.872595]\n",
      "epoch:19 step:15223[D loss: 0.434896, acc: 60.94%, op_acc: 35.16%] [G loss: 0.854409]\n",
      "epoch:19 step:15224[D loss: 0.427073, acc: 60.16%, op_acc: 38.28%] [G loss: 0.867327]\n",
      "epoch:19 step:15225[D loss: 0.405701, acc: 60.16%, op_acc: 42.19%] [G loss: 0.959599]\n",
      "epoch:19 step:15226[D loss: 0.469176, acc: 50.00%, op_acc: 36.72%] [G loss: 0.880225]\n",
      "epoch:19 step:15227[D loss: 0.435718, acc: 58.59%, op_acc: 36.72%] [G loss: 0.890377]\n",
      "epoch:19 step:15228[D loss: 0.480068, acc: 55.47%, op_acc: 34.38%] [G loss: 0.943065]\n",
      "epoch:19 step:15229[D loss: 0.439912, acc: 48.44%, op_acc: 42.19%] [G loss: 0.885328]\n",
      "epoch:19 step:15230[D loss: 0.439706, acc: 53.91%, op_acc: 40.62%] [G loss: 0.882845]\n",
      "epoch:19 step:15231[D loss: 0.419516, acc: 57.81%, op_acc: 41.41%] [G loss: 0.898918]\n",
      "epoch:19 step:15232[D loss: 0.453868, acc: 51.56%, op_acc: 38.28%] [G loss: 0.935783]\n",
      "epoch:19 step:15233[D loss: 0.472242, acc: 52.34%, op_acc: 30.47%] [G loss: 0.848762]\n",
      "epoch:19 step:15234[D loss: 0.462306, acc: 50.00%, op_acc: 34.38%] [G loss: 0.839761]\n",
      "epoch:19 step:15235[D loss: 0.410273, acc: 59.38%, op_acc: 42.97%] [G loss: 0.898521]\n",
      "epoch:19 step:15236[D loss: 0.421611, acc: 59.38%, op_acc: 41.41%] [G loss: 0.887506]\n",
      "epoch:19 step:15237[D loss: 0.458543, acc: 52.34%, op_acc: 32.81%] [G loss: 0.850018]\n",
      "epoch:19 step:15238[D loss: 0.431195, acc: 54.69%, op_acc: 37.50%] [G loss: 0.855574]\n",
      "epoch:19 step:15239[D loss: 0.430610, acc: 60.94%, op_acc: 35.16%] [G loss: 0.814459]\n",
      "epoch:19 step:15240[D loss: 0.422527, acc: 58.59%, op_acc: 39.84%] [G loss: 0.868221]\n",
      "epoch:19 step:15241[D loss: 0.444260, acc: 56.25%, op_acc: 39.06%] [G loss: 0.900905]\n",
      "epoch:19 step:15242[D loss: 0.430820, acc: 60.94%, op_acc: 36.72%] [G loss: 0.884317]\n",
      "epoch:19 step:15243[D loss: 0.418330, acc: 57.03%, op_acc: 41.41%] [G loss: 0.948793]\n",
      "epoch:19 step:15244[D loss: 0.447769, acc: 53.91%, op_acc: 39.06%] [G loss: 0.914596]\n",
      "epoch:19 step:15245[D loss: 0.464583, acc: 44.53%, op_acc: 38.28%] [G loss: 0.884116]\n",
      "epoch:19 step:15246[D loss: 0.414614, acc: 60.94%, op_acc: 35.94%] [G loss: 0.907927]\n",
      "epoch:19 step:15247[D loss: 0.394577, acc: 67.97%, op_acc: 39.84%] [G loss: 0.964730]\n",
      "epoch:19 step:15248[D loss: 0.434317, acc: 58.59%, op_acc: 39.06%] [G loss: 0.860587]\n",
      "epoch:19 step:15249[D loss: 0.405897, acc: 60.94%, op_acc: 39.06%] [G loss: 0.911058]\n",
      "epoch:19 step:15250[D loss: 0.431672, acc: 61.72%, op_acc: 39.84%] [G loss: 0.867807]\n",
      "##############\n",
      "[0.85036952 0.84922904 0.81565004 0.7966629  0.80988149 0.83080457\n",
      " 0.89213736 0.8045433  0.81256745 0.81017609]\n",
      "##########\n",
      "epoch:19 step:15251[D loss: 0.424368, acc: 64.06%, op_acc: 39.84%] [G loss: 0.880088]\n",
      "epoch:19 step:15252[D loss: 0.436698, acc: 56.25%, op_acc: 42.19%] [G loss: 0.872233]\n",
      "epoch:19 step:15253[D loss: 0.425222, acc: 55.47%, op_acc: 37.50%] [G loss: 0.855452]\n",
      "epoch:19 step:15254[D loss: 0.402647, acc: 67.19%, op_acc: 40.62%] [G loss: 0.876338]\n",
      "epoch:19 step:15255[D loss: 0.403898, acc: 68.75%, op_acc: 40.62%] [G loss: 0.841306]\n",
      "epoch:19 step:15256[D loss: 0.415881, acc: 67.97%, op_acc: 40.62%] [G loss: 0.879260]\n",
      "epoch:19 step:15257[D loss: 0.415674, acc: 62.50%, op_acc: 40.62%] [G loss: 0.896547]\n",
      "epoch:19 step:15258[D loss: 0.423363, acc: 54.69%, op_acc: 36.72%] [G loss: 0.859422]\n",
      "epoch:19 step:15259[D loss: 0.450852, acc: 60.94%, op_acc: 32.03%] [G loss: 0.873657]\n",
      "epoch:19 step:15260[D loss: 0.436795, acc: 60.16%, op_acc: 37.50%] [G loss: 0.866379]\n",
      "epoch:19 step:15261[D loss: 0.410161, acc: 61.72%, op_acc: 39.84%] [G loss: 0.946450]\n",
      "epoch:19 step:15262[D loss: 0.449518, acc: 63.28%, op_acc: 32.81%] [G loss: 0.913162]\n",
      "epoch:19 step:15263[D loss: 0.423393, acc: 58.59%, op_acc: 39.84%] [G loss: 0.844438]\n",
      "epoch:19 step:15264[D loss: 0.437946, acc: 59.38%, op_acc: 30.47%] [G loss: 0.855775]\n",
      "epoch:19 step:15265[D loss: 0.477278, acc: 42.97%, op_acc: 35.94%] [G loss: 0.841406]\n",
      "epoch:19 step:15266[D loss: 0.429577, acc: 58.59%, op_acc: 42.19%] [G loss: 0.905782]\n",
      "epoch:19 step:15267[D loss: 0.432051, acc: 53.12%, op_acc: 39.06%] [G loss: 0.955595]\n",
      "epoch:19 step:15268[D loss: 0.423561, acc: 55.47%, op_acc: 40.62%] [G loss: 0.876447]\n",
      "epoch:19 step:15269[D loss: 0.426959, acc: 60.16%, op_acc: 40.62%] [G loss: 0.917123]\n",
      "epoch:19 step:15270[D loss: 0.449380, acc: 55.47%, op_acc: 35.94%] [G loss: 0.833709]\n",
      "epoch:19 step:15271[D loss: 0.405332, acc: 62.50%, op_acc: 42.97%] [G loss: 0.880034]\n",
      "epoch:19 step:15272[D loss: 0.448010, acc: 56.25%, op_acc: 33.59%] [G loss: 0.809147]\n",
      "epoch:19 step:15273[D loss: 0.394734, acc: 64.84%, op_acc: 40.62%] [G loss: 0.909990]\n",
      "epoch:19 step:15274[D loss: 0.404339, acc: 63.28%, op_acc: 42.97%] [G loss: 0.955290]\n",
      "epoch:19 step:15275[D loss: 0.462640, acc: 54.69%, op_acc: 41.41%] [G loss: 0.858609]\n",
      "epoch:19 step:15276[D loss: 0.424241, acc: 61.72%, op_acc: 36.72%] [G loss: 0.935940]\n",
      "epoch:19 step:15277[D loss: 0.426295, acc: 61.72%, op_acc: 37.50%] [G loss: 0.902865]\n",
      "epoch:19 step:15278[D loss: 0.422503, acc: 49.22%, op_acc: 40.62%] [G loss: 0.805498]\n",
      "epoch:19 step:15279[D loss: 0.442322, acc: 53.12%, op_acc: 35.94%] [G loss: 0.918057]\n",
      "epoch:19 step:15280[D loss: 0.419045, acc: 60.94%, op_acc: 42.19%] [G loss: 0.851047]\n",
      "epoch:19 step:15281[D loss: 0.426829, acc: 59.38%, op_acc: 43.75%] [G loss: 0.880650]\n",
      "epoch:19 step:15282[D loss: 0.415251, acc: 67.97%, op_acc: 36.72%] [G loss: 0.851575]\n",
      "epoch:19 step:15283[D loss: 0.417756, acc: 56.25%, op_acc: 41.41%] [G loss: 0.876730]\n",
      "epoch:19 step:15284[D loss: 0.456512, acc: 51.56%, op_acc: 35.16%] [G loss: 0.876953]\n",
      "epoch:19 step:15285[D loss: 0.433474, acc: 58.59%, op_acc: 39.84%] [G loss: 0.856982]\n",
      "epoch:19 step:15286[D loss: 0.461112, acc: 53.91%, op_acc: 37.50%] [G loss: 0.924842]\n",
      "epoch:19 step:15287[D loss: 0.412935, acc: 60.94%, op_acc: 41.41%] [G loss: 0.890935]\n",
      "epoch:19 step:15288[D loss: 0.414524, acc: 64.84%, op_acc: 37.50%] [G loss: 0.876813]\n",
      "epoch:19 step:15289[D loss: 0.425833, acc: 57.81%, op_acc: 40.62%] [G loss: 0.889864]\n",
      "epoch:19 step:15290[D loss: 0.416709, acc: 60.16%, op_acc: 39.84%] [G loss: 0.946103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15291[D loss: 0.442551, acc: 58.59%, op_acc: 39.06%] [G loss: 0.889845]\n",
      "epoch:19 step:15292[D loss: 0.405691, acc: 61.72%, op_acc: 40.62%] [G loss: 0.847780]\n",
      "epoch:19 step:15293[D loss: 0.435508, acc: 55.47%, op_acc: 37.50%] [G loss: 0.942948]\n",
      "epoch:19 step:15294[D loss: 0.404318, acc: 64.06%, op_acc: 39.84%] [G loss: 0.911192]\n",
      "epoch:19 step:15295[D loss: 0.424316, acc: 62.50%, op_acc: 38.28%] [G loss: 0.919542]\n",
      "epoch:19 step:15296[D loss: 0.426867, acc: 57.81%, op_acc: 42.19%] [G loss: 0.859394]\n",
      "epoch:19 step:15297[D loss: 0.420405, acc: 54.69%, op_acc: 39.84%] [G loss: 0.920898]\n",
      "epoch:19 step:15298[D loss: 0.447094, acc: 52.34%, op_acc: 42.97%] [G loss: 0.826444]\n",
      "epoch:19 step:15299[D loss: 0.399304, acc: 61.72%, op_acc: 42.97%] [G loss: 0.964579]\n",
      "epoch:19 step:15300[D loss: 0.461592, acc: 56.25%, op_acc: 28.12%] [G loss: 0.916124]\n",
      "##############\n",
      "[0.84584454 0.88321009 0.83601814 0.82267484 0.77865297 0.82328497\n",
      " 0.88493238 0.84753505 0.81818137 0.82577795]\n",
      "##########\n",
      "epoch:19 step:15301[D loss: 0.447650, acc: 53.91%, op_acc: 36.72%] [G loss: 0.797806]\n",
      "epoch:19 step:15302[D loss: 0.407964, acc: 65.62%, op_acc: 44.53%] [G loss: 0.856365]\n",
      "epoch:19 step:15303[D loss: 0.432826, acc: 57.81%, op_acc: 39.06%] [G loss: 0.889596]\n",
      "epoch:19 step:15304[D loss: 0.447851, acc: 59.38%, op_acc: 42.19%] [G loss: 0.897638]\n",
      "epoch:19 step:15305[D loss: 0.408405, acc: 67.19%, op_acc: 40.62%] [G loss: 0.822836]\n",
      "epoch:19 step:15306[D loss: 0.437902, acc: 53.91%, op_acc: 39.84%] [G loss: 0.860481]\n",
      "epoch:19 step:15307[D loss: 0.400712, acc: 66.41%, op_acc: 39.06%] [G loss: 0.851319]\n",
      "epoch:19 step:15308[D loss: 0.390976, acc: 60.94%, op_acc: 46.88%] [G loss: 0.864545]\n",
      "epoch:19 step:15309[D loss: 0.414511, acc: 59.38%, op_acc: 40.62%] [G loss: 0.893776]\n",
      "epoch:19 step:15310[D loss: 0.442363, acc: 53.12%, op_acc: 39.84%] [G loss: 0.893622]\n",
      "epoch:19 step:15311[D loss: 0.434852, acc: 66.41%, op_acc: 32.03%] [G loss: 0.871214]\n",
      "epoch:19 step:15312[D loss: 0.396601, acc: 64.06%, op_acc: 41.41%] [G loss: 0.876928]\n",
      "epoch:19 step:15313[D loss: 0.414260, acc: 58.59%, op_acc: 44.53%] [G loss: 0.906124]\n",
      "epoch:19 step:15314[D loss: 0.427198, acc: 54.69%, op_acc: 40.62%] [G loss: 0.892898]\n",
      "epoch:19 step:15315[D loss: 0.455232, acc: 56.25%, op_acc: 36.72%] [G loss: 0.903021]\n",
      "epoch:19 step:15316[D loss: 0.414471, acc: 67.19%, op_acc: 42.97%] [G loss: 0.902555]\n",
      "epoch:19 step:15317[D loss: 0.397857, acc: 66.41%, op_acc: 39.84%] [G loss: 0.874838]\n",
      "epoch:19 step:15318[D loss: 0.424773, acc: 59.38%, op_acc: 39.06%] [G loss: 0.893019]\n",
      "epoch:19 step:15319[D loss: 0.424654, acc: 67.97%, op_acc: 31.25%] [G loss: 0.890421]\n",
      "epoch:19 step:15320[D loss: 0.474171, acc: 53.91%, op_acc: 33.59%] [G loss: 0.865784]\n",
      "epoch:19 step:15321[D loss: 0.465975, acc: 50.78%, op_acc: 32.03%] [G loss: 0.848737]\n",
      "epoch:19 step:15322[D loss: 0.404229, acc: 63.28%, op_acc: 41.41%] [G loss: 0.840385]\n",
      "epoch:19 step:15323[D loss: 0.413735, acc: 62.50%, op_acc: 45.31%] [G loss: 0.862956]\n",
      "epoch:19 step:15324[D loss: 0.432664, acc: 59.38%, op_acc: 37.50%] [G loss: 0.841824]\n",
      "epoch:19 step:15325[D loss: 0.400451, acc: 64.84%, op_acc: 39.84%] [G loss: 0.897673]\n",
      "epoch:19 step:15326[D loss: 0.417111, acc: 60.16%, op_acc: 38.28%] [G loss: 0.901787]\n",
      "epoch:19 step:15327[D loss: 0.442292, acc: 57.81%, op_acc: 33.59%] [G loss: 0.841360]\n",
      "epoch:19 step:15328[D loss: 0.437506, acc: 53.91%, op_acc: 44.53%] [G loss: 0.890637]\n",
      "epoch:19 step:15329[D loss: 0.414016, acc: 61.72%, op_acc: 36.72%] [G loss: 0.814676]\n",
      "epoch:19 step:15330[D loss: 0.455661, acc: 62.50%, op_acc: 32.81%] [G loss: 0.822912]\n",
      "epoch:19 step:15331[D loss: 0.432648, acc: 56.25%, op_acc: 35.16%] [G loss: 0.872039]\n",
      "epoch:19 step:15332[D loss: 0.433588, acc: 61.72%, op_acc: 34.38%] [G loss: 0.849153]\n",
      "epoch:19 step:15333[D loss: 0.404598, acc: 64.06%, op_acc: 39.84%] [G loss: 0.853636]\n",
      "epoch:19 step:15334[D loss: 0.437840, acc: 58.59%, op_acc: 35.94%] [G loss: 0.827054]\n",
      "epoch:19 step:15335[D loss: 0.423521, acc: 59.38%, op_acc: 39.84%] [G loss: 0.828121]\n",
      "epoch:19 step:15336[D loss: 0.433570, acc: 55.47%, op_acc: 42.97%] [G loss: 0.838505]\n",
      "epoch:19 step:15337[D loss: 0.438849, acc: 57.81%, op_acc: 39.06%] [G loss: 0.946604]\n",
      "epoch:19 step:15338[D loss: 0.435217, acc: 66.41%, op_acc: 33.59%] [G loss: 0.796863]\n",
      "epoch:19 step:15339[D loss: 0.404337, acc: 62.50%, op_acc: 44.53%] [G loss: 0.923475]\n",
      "epoch:19 step:15340[D loss: 0.431621, acc: 66.41%, op_acc: 34.38%] [G loss: 0.921450]\n",
      "epoch:19 step:15341[D loss: 0.432277, acc: 57.03%, op_acc: 41.41%] [G loss: 0.939044]\n",
      "epoch:19 step:15342[D loss: 0.439454, acc: 60.94%, op_acc: 36.72%] [G loss: 0.871224]\n",
      "epoch:19 step:15343[D loss: 0.445564, acc: 50.78%, op_acc: 36.72%] [G loss: 0.909778]\n",
      "epoch:19 step:15344[D loss: 0.424024, acc: 64.84%, op_acc: 35.16%] [G loss: 0.972833]\n",
      "epoch:19 step:15345[D loss: 0.439366, acc: 57.03%, op_acc: 42.19%] [G loss: 0.897183]\n",
      "epoch:19 step:15346[D loss: 0.413298, acc: 64.06%, op_acc: 42.19%] [G loss: 0.945336]\n",
      "epoch:19 step:15347[D loss: 0.416520, acc: 62.50%, op_acc: 37.50%] [G loss: 0.915732]\n",
      "epoch:19 step:15348[D loss: 0.460746, acc: 51.56%, op_acc: 33.59%] [G loss: 0.907347]\n",
      "epoch:19 step:15349[D loss: 0.423182, acc: 65.62%, op_acc: 35.94%] [G loss: 0.874020]\n",
      "epoch:19 step:15350[D loss: 0.443476, acc: 57.81%, op_acc: 35.94%] [G loss: 0.865624]\n",
      "##############\n",
      "[0.85807885 0.84849305 0.80486641 0.81462933 0.7819021  0.81874248\n",
      " 0.87332905 0.82721073 0.81334755 0.81791122]\n",
      "##########\n",
      "epoch:19 step:15351[D loss: 0.451629, acc: 56.25%, op_acc: 35.16%] [G loss: 0.839574]\n",
      "epoch:19 step:15352[D loss: 0.429514, acc: 58.59%, op_acc: 35.94%] [G loss: 0.799973]\n",
      "epoch:19 step:15353[D loss: 0.440762, acc: 53.91%, op_acc: 37.50%] [G loss: 0.868149]\n",
      "epoch:19 step:15354[D loss: 0.434898, acc: 61.72%, op_acc: 39.84%] [G loss: 0.773300]\n",
      "epoch:19 step:15355[D loss: 0.436693, acc: 60.94%, op_acc: 35.16%] [G loss: 0.809440]\n",
      "epoch:19 step:15356[D loss: 0.422385, acc: 67.97%, op_acc: 39.84%] [G loss: 0.869449]\n",
      "epoch:19 step:15357[D loss: 0.399510, acc: 63.28%, op_acc: 43.75%] [G loss: 0.868328]\n",
      "epoch:19 step:15358[D loss: 0.439019, acc: 59.38%, op_acc: 33.59%] [G loss: 0.903915]\n",
      "epoch:19 step:15359[D loss: 0.436060, acc: 60.16%, op_acc: 38.28%] [G loss: 0.834739]\n",
      "epoch:19 step:15360[D loss: 0.425446, acc: 61.72%, op_acc: 30.47%] [G loss: 0.906503]\n",
      "epoch:19 step:15361[D loss: 0.473187, acc: 50.78%, op_acc: 29.69%] [G loss: 0.879667]\n",
      "epoch:19 step:15362[D loss: 0.420791, acc: 62.50%, op_acc: 42.97%] [G loss: 0.947879]\n",
      "epoch:19 step:15363[D loss: 0.413378, acc: 69.53%, op_acc: 35.16%] [G loss: 0.910703]\n",
      "epoch:19 step:15364[D loss: 0.435777, acc: 62.50%, op_acc: 35.16%] [G loss: 0.853339]\n",
      "epoch:19 step:15365[D loss: 0.469809, acc: 59.38%, op_acc: 29.69%] [G loss: 0.860104]\n",
      "epoch:19 step:15366[D loss: 0.454379, acc: 52.34%, op_acc: 35.94%] [G loss: 0.921626]\n",
      "epoch:19 step:15367[D loss: 0.410281, acc: 60.16%, op_acc: 36.72%] [G loss: 0.855505]\n",
      "epoch:19 step:15368[D loss: 0.422344, acc: 66.41%, op_acc: 39.06%] [G loss: 0.928140]\n",
      "epoch:19 step:15369[D loss: 0.430879, acc: 59.38%, op_acc: 34.38%] [G loss: 0.936522]\n",
      "epoch:19 step:15370[D loss: 0.414922, acc: 59.38%, op_acc: 39.84%] [G loss: 0.955392]\n",
      "epoch:19 step:15371[D loss: 0.432035, acc: 53.12%, op_acc: 41.41%] [G loss: 0.946176]\n",
      "epoch:19 step:15372[D loss: 0.433027, acc: 58.59%, op_acc: 38.28%] [G loss: 0.804448]\n",
      "epoch:19 step:15373[D loss: 0.437001, acc: 51.56%, op_acc: 41.41%] [G loss: 0.838869]\n",
      "epoch:19 step:15374[D loss: 0.442349, acc: 58.59%, op_acc: 35.94%] [G loss: 0.842187]\n",
      "epoch:19 step:15375[D loss: 0.425456, acc: 51.56%, op_acc: 40.62%] [G loss: 0.883110]\n",
      "epoch:19 step:15376[D loss: 0.444763, acc: 63.28%, op_acc: 33.59%] [G loss: 0.877928]\n",
      "epoch:19 step:15377[D loss: 0.426053, acc: 58.59%, op_acc: 33.59%] [G loss: 0.886348]\n",
      "epoch:19 step:15378[D loss: 0.431202, acc: 66.41%, op_acc: 35.94%] [G loss: 0.877068]\n",
      "epoch:19 step:15379[D loss: 0.423621, acc: 53.91%, op_acc: 42.97%] [G loss: 0.965831]\n",
      "epoch:19 step:15380[D loss: 0.387452, acc: 64.06%, op_acc: 46.09%] [G loss: 0.908473]\n",
      "epoch:19 step:15381[D loss: 0.447605, acc: 61.72%, op_acc: 35.94%] [G loss: 0.918459]\n",
      "epoch:19 step:15382[D loss: 0.402411, acc: 65.62%, op_acc: 40.62%] [G loss: 0.913032]\n",
      "epoch:19 step:15383[D loss: 0.418525, acc: 64.06%, op_acc: 39.06%] [G loss: 0.909595]\n",
      "epoch:19 step:15384[D loss: 0.413204, acc: 60.16%, op_acc: 38.28%] [G loss: 0.938361]\n",
      "epoch:19 step:15385[D loss: 0.439401, acc: 56.25%, op_acc: 42.19%] [G loss: 0.884815]\n",
      "epoch:19 step:15386[D loss: 0.426337, acc: 61.72%, op_acc: 33.59%] [G loss: 0.898756]\n",
      "epoch:19 step:15387[D loss: 0.416658, acc: 57.81%, op_acc: 42.19%] [G loss: 0.892936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15388[D loss: 0.434262, acc: 57.81%, op_acc: 41.41%] [G loss: 0.876462]\n",
      "epoch:19 step:15389[D loss: 0.417602, acc: 60.94%, op_acc: 39.84%] [G loss: 0.943333]\n",
      "epoch:19 step:15390[D loss: 0.431660, acc: 61.72%, op_acc: 39.06%] [G loss: 0.837928]\n",
      "epoch:19 step:15391[D loss: 0.458452, acc: 60.16%, op_acc: 39.84%] [G loss: 0.856515]\n",
      "epoch:19 step:15392[D loss: 0.412303, acc: 64.06%, op_acc: 38.28%] [G loss: 0.884978]\n",
      "epoch:19 step:15393[D loss: 0.413908, acc: 62.50%, op_acc: 37.50%] [G loss: 0.867070]\n",
      "epoch:19 step:15394[D loss: 0.415195, acc: 62.50%, op_acc: 39.84%] [G loss: 0.845025]\n",
      "epoch:19 step:15395[D loss: 0.395323, acc: 64.84%, op_acc: 41.41%] [G loss: 0.936297]\n",
      "epoch:19 step:15396[D loss: 0.441345, acc: 59.38%, op_acc: 35.94%] [G loss: 0.903743]\n",
      "epoch:19 step:15397[D loss: 0.418739, acc: 64.06%, op_acc: 42.19%] [G loss: 0.885398]\n",
      "epoch:19 step:15398[D loss: 0.412981, acc: 60.94%, op_acc: 42.97%] [G loss: 0.798973]\n",
      "epoch:19 step:15399[D loss: 0.446779, acc: 57.03%, op_acc: 32.03%] [G loss: 0.885598]\n",
      "epoch:19 step:15400[D loss: 0.418115, acc: 61.72%, op_acc: 38.28%] [G loss: 0.943099]\n",
      "##############\n",
      "[0.85967025 0.86191264 0.78989579 0.82303288 0.80857346 0.83035222\n",
      " 0.88983228 0.82228747 0.80524633 0.81517001]\n",
      "##########\n",
      "epoch:19 step:15401[D loss: 0.446363, acc: 47.66%, op_acc: 38.28%] [G loss: 0.872002]\n",
      "epoch:19 step:15402[D loss: 0.407222, acc: 67.97%, op_acc: 35.16%] [G loss: 0.993848]\n",
      "epoch:19 step:15403[D loss: 0.431159, acc: 56.25%, op_acc: 32.81%] [G loss: 0.890717]\n",
      "epoch:19 step:15404[D loss: 0.422253, acc: 57.81%, op_acc: 43.75%] [G loss: 0.925836]\n",
      "epoch:19 step:15405[D loss: 0.448093, acc: 53.12%, op_acc: 34.38%] [G loss: 0.911615]\n",
      "epoch:19 step:15406[D loss: 0.406377, acc: 60.94%, op_acc: 41.41%] [G loss: 0.859668]\n",
      "epoch:19 step:15407[D loss: 0.399017, acc: 64.84%, op_acc: 42.19%] [G loss: 0.929933]\n",
      "epoch:19 step:15408[D loss: 0.410800, acc: 60.94%, op_acc: 42.97%] [G loss: 0.822867]\n",
      "epoch:19 step:15409[D loss: 0.433245, acc: 55.47%, op_acc: 39.84%] [G loss: 0.856057]\n",
      "epoch:19 step:15410[D loss: 0.418415, acc: 60.94%, op_acc: 35.94%] [G loss: 0.898613]\n",
      "epoch:19 step:15411[D loss: 0.419396, acc: 61.72%, op_acc: 34.38%] [G loss: 0.829369]\n",
      "epoch:19 step:15412[D loss: 0.408649, acc: 68.75%, op_acc: 38.28%] [G loss: 0.863171]\n",
      "epoch:19 step:15413[D loss: 0.433492, acc: 57.03%, op_acc: 41.41%] [G loss: 0.894938]\n",
      "epoch:19 step:15414[D loss: 0.412981, acc: 63.28%, op_acc: 40.62%] [G loss: 0.844811]\n",
      "epoch:19 step:15415[D loss: 0.398582, acc: 60.94%, op_acc: 42.97%] [G loss: 0.843103]\n",
      "epoch:19 step:15416[D loss: 0.451653, acc: 57.03%, op_acc: 30.47%] [G loss: 0.888049]\n",
      "epoch:19 step:15417[D loss: 0.473827, acc: 49.22%, op_acc: 35.16%] [G loss: 0.820407]\n",
      "epoch:19 step:15418[D loss: 0.407689, acc: 57.03%, op_acc: 43.75%] [G loss: 0.845060]\n",
      "epoch:19 step:15419[D loss: 0.439004, acc: 61.72%, op_acc: 37.50%] [G loss: 0.903396]\n",
      "epoch:19 step:15420[D loss: 0.444343, acc: 58.59%, op_acc: 32.81%] [G loss: 0.813656]\n",
      "epoch:19 step:15421[D loss: 0.413942, acc: 65.62%, op_acc: 39.06%] [G loss: 0.969197]\n",
      "epoch:19 step:15422[D loss: 0.411655, acc: 56.25%, op_acc: 41.41%] [G loss: 0.870319]\n",
      "epoch:19 step:15423[D loss: 0.441730, acc: 61.72%, op_acc: 35.94%] [G loss: 0.976853]\n",
      "epoch:19 step:15424[D loss: 0.412174, acc: 66.41%, op_acc: 38.28%] [G loss: 0.908522]\n",
      "epoch:19 step:15425[D loss: 0.440584, acc: 65.62%, op_acc: 35.94%] [G loss: 0.861595]\n",
      "epoch:19 step:15426[D loss: 0.415702, acc: 59.38%, op_acc: 37.50%] [G loss: 0.826968]\n",
      "epoch:19 step:15427[D loss: 0.399492, acc: 63.28%, op_acc: 43.75%] [G loss: 0.889072]\n",
      "epoch:19 step:15428[D loss: 0.413945, acc: 65.62%, op_acc: 39.06%] [G loss: 0.895546]\n",
      "epoch:19 step:15429[D loss: 0.402275, acc: 61.72%, op_acc: 42.97%] [G loss: 0.890750]\n",
      "epoch:19 step:15430[D loss: 0.427342, acc: 58.59%, op_acc: 36.72%] [G loss: 0.882556]\n",
      "epoch:19 step:15431[D loss: 0.433801, acc: 53.12%, op_acc: 37.50%] [G loss: 0.897751]\n",
      "epoch:19 step:15432[D loss: 0.462665, acc: 60.94%, op_acc: 28.12%] [G loss: 0.958731]\n",
      "epoch:19 step:15433[D loss: 0.423203, acc: 61.72%, op_acc: 35.16%] [G loss: 0.848432]\n",
      "epoch:19 step:15434[D loss: 0.432517, acc: 62.50%, op_acc: 35.16%] [G loss: 0.850069]\n",
      "epoch:19 step:15435[D loss: 0.450603, acc: 59.38%, op_acc: 35.16%] [G loss: 0.886960]\n",
      "epoch:19 step:15436[D loss: 0.427734, acc: 64.84%, op_acc: 37.50%] [G loss: 0.874337]\n",
      "epoch:19 step:15437[D loss: 0.436407, acc: 51.56%, op_acc: 38.28%] [G loss: 0.880386]\n",
      "epoch:19 step:15438[D loss: 0.446627, acc: 57.81%, op_acc: 42.19%] [G loss: 0.854308]\n",
      "epoch:19 step:15439[D loss: 0.414839, acc: 73.44%, op_acc: 35.16%] [G loss: 0.951475]\n",
      "epoch:19 step:15440[D loss: 0.430747, acc: 60.94%, op_acc: 36.72%] [G loss: 0.954377]\n",
      "epoch:19 step:15441[D loss: 0.423192, acc: 57.81%, op_acc: 42.97%] [G loss: 0.835806]\n",
      "epoch:19 step:15442[D loss: 0.415576, acc: 59.38%, op_acc: 42.19%] [G loss: 0.939671]\n",
      "epoch:19 step:15443[D loss: 0.455186, acc: 60.94%, op_acc: 35.16%] [G loss: 0.852816]\n",
      "epoch:19 step:15444[D loss: 0.402970, acc: 65.62%, op_acc: 32.81%] [G loss: 0.763456]\n",
      "epoch:19 step:15445[D loss: 0.433441, acc: 52.34%, op_acc: 40.62%] [G loss: 0.839769]\n",
      "epoch:19 step:15446[D loss: 0.428781, acc: 54.69%, op_acc: 43.75%] [G loss: 0.854231]\n",
      "epoch:19 step:15447[D loss: 0.380326, acc: 60.94%, op_acc: 41.41%] [G loss: 0.856762]\n",
      "epoch:19 step:15448[D loss: 0.416452, acc: 61.72%, op_acc: 38.28%] [G loss: 0.967925]\n",
      "epoch:19 step:15449[D loss: 0.409683, acc: 63.28%, op_acc: 35.94%] [G loss: 0.906708]\n",
      "epoch:19 step:15450[D loss: 0.419665, acc: 57.81%, op_acc: 46.88%] [G loss: 0.921161]\n",
      "##############\n",
      "[0.84962344 0.88499257 0.80189395 0.80409934 0.78884903 0.8512081\n",
      " 0.88574932 0.82481413 0.81505676 0.82337603]\n",
      "##########\n",
      "epoch:19 step:15451[D loss: 0.396031, acc: 66.41%, op_acc: 42.19%] [G loss: 0.954700]\n",
      "epoch:19 step:15452[D loss: 0.390801, acc: 61.72%, op_acc: 47.66%] [G loss: 0.994350]\n",
      "epoch:19 step:15453[D loss: 0.393521, acc: 66.41%, op_acc: 49.22%] [G loss: 0.911475]\n",
      "epoch:19 step:15454[D loss: 0.409044, acc: 63.28%, op_acc: 39.84%] [G loss: 0.870269]\n",
      "epoch:19 step:15455[D loss: 0.430296, acc: 61.72%, op_acc: 41.41%] [G loss: 0.882889]\n",
      "epoch:19 step:15456[D loss: 0.453688, acc: 49.22%, op_acc: 37.50%] [G loss: 0.777319]\n",
      "epoch:19 step:15457[D loss: 0.421245, acc: 58.59%, op_acc: 39.84%] [G loss: 0.830525]\n",
      "epoch:19 step:15458[D loss: 0.456037, acc: 55.47%, op_acc: 38.28%] [G loss: 0.885099]\n",
      "epoch:19 step:15459[D loss: 0.468908, acc: 48.44%, op_acc: 39.84%] [G loss: 0.825103]\n",
      "epoch:19 step:15460[D loss: 0.434656, acc: 55.47%, op_acc: 39.84%] [G loss: 0.914371]\n",
      "epoch:19 step:15461[D loss: 0.455353, acc: 58.59%, op_acc: 32.81%] [G loss: 0.861113]\n",
      "epoch:19 step:15462[D loss: 0.420834, acc: 57.81%, op_acc: 38.28%] [G loss: 1.005470]\n",
      "epoch:19 step:15463[D loss: 0.407652, acc: 67.97%, op_acc: 42.19%] [G loss: 0.879719]\n",
      "epoch:19 step:15464[D loss: 0.432145, acc: 63.28%, op_acc: 40.62%] [G loss: 0.963617]\n",
      "epoch:19 step:15465[D loss: 0.418997, acc: 57.03%, op_acc: 42.19%] [G loss: 0.924738]\n",
      "epoch:19 step:15466[D loss: 0.414650, acc: 62.50%, op_acc: 38.28%] [G loss: 0.960587]\n",
      "epoch:19 step:15467[D loss: 0.410116, acc: 61.72%, op_acc: 42.19%] [G loss: 0.946415]\n",
      "epoch:19 step:15468[D loss: 0.438487, acc: 58.59%, op_acc: 35.16%] [G loss: 0.919597]\n",
      "epoch:19 step:15469[D loss: 0.390237, acc: 62.50%, op_acc: 37.50%] [G loss: 0.887132]\n",
      "epoch:19 step:15470[D loss: 0.441606, acc: 61.72%, op_acc: 35.94%] [G loss: 0.912079]\n",
      "epoch:19 step:15471[D loss: 0.452249, acc: 53.91%, op_acc: 41.41%] [G loss: 0.850290]\n",
      "epoch:19 step:15472[D loss: 0.408162, acc: 70.31%, op_acc: 33.59%] [G loss: 0.910322]\n",
      "epoch:19 step:15473[D loss: 0.423839, acc: 50.78%, op_acc: 39.06%] [G loss: 0.896009]\n",
      "epoch:19 step:15474[D loss: 0.435513, acc: 57.03%, op_acc: 37.50%] [G loss: 0.855388]\n",
      "epoch:19 step:15475[D loss: 0.414794, acc: 58.59%, op_acc: 39.84%] [G loss: 0.911981]\n",
      "epoch:19 step:15476[D loss: 0.428881, acc: 60.16%, op_acc: 37.50%] [G loss: 0.882587]\n",
      "epoch:19 step:15477[D loss: 0.447454, acc: 57.03%, op_acc: 33.59%] [G loss: 0.962152]\n",
      "epoch:19 step:15478[D loss: 0.419577, acc: 57.03%, op_acc: 37.50%] [G loss: 0.845576]\n",
      "epoch:19 step:15479[D loss: 0.451496, acc: 61.72%, op_acc: 35.16%] [G loss: 0.871933]\n",
      "epoch:19 step:15480[D loss: 0.426662, acc: 57.81%, op_acc: 37.50%] [G loss: 0.833399]\n",
      "epoch:19 step:15481[D loss: 0.438521, acc: 60.16%, op_acc: 33.59%] [G loss: 0.906700]\n",
      "epoch:19 step:15482[D loss: 0.436983, acc: 60.16%, op_acc: 36.72%] [G loss: 0.836271]\n",
      "epoch:19 step:15483[D loss: 0.409634, acc: 55.47%, op_acc: 39.84%] [G loss: 0.891930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15484[D loss: 0.420205, acc: 60.94%, op_acc: 42.97%] [G loss: 0.920571]\n",
      "epoch:19 step:15485[D loss: 0.415742, acc: 64.84%, op_acc: 39.06%] [G loss: 0.924418]\n",
      "epoch:19 step:15486[D loss: 0.425212, acc: 54.69%, op_acc: 35.16%] [G loss: 0.897864]\n",
      "epoch:19 step:15487[D loss: 0.432732, acc: 53.91%, op_acc: 35.16%] [G loss: 0.923524]\n",
      "epoch:19 step:15488[D loss: 0.418114, acc: 61.72%, op_acc: 35.94%] [G loss: 0.887525]\n",
      "epoch:19 step:15489[D loss: 0.460123, acc: 47.66%, op_acc: 32.03%] [G loss: 0.909919]\n",
      "epoch:19 step:15490[D loss: 0.437351, acc: 61.72%, op_acc: 36.72%] [G loss: 0.811695]\n",
      "epoch:19 step:15491[D loss: 0.417919, acc: 59.38%, op_acc: 41.41%] [G loss: 0.903537]\n",
      "epoch:19 step:15492[D loss: 0.416437, acc: 60.94%, op_acc: 49.22%] [G loss: 0.839722]\n",
      "epoch:19 step:15493[D loss: 0.434473, acc: 50.78%, op_acc: 41.41%] [G loss: 0.827004]\n",
      "epoch:19 step:15494[D loss: 0.440085, acc: 57.81%, op_acc: 39.84%] [G loss: 0.826615]\n",
      "epoch:19 step:15495[D loss: 0.438868, acc: 63.28%, op_acc: 39.06%] [G loss: 0.892846]\n",
      "epoch:19 step:15496[D loss: 0.445994, acc: 51.56%, op_acc: 36.72%] [G loss: 0.867028]\n",
      "epoch:19 step:15497[D loss: 0.430285, acc: 60.16%, op_acc: 32.81%] [G loss: 0.869727]\n",
      "epoch:19 step:15498[D loss: 0.463669, acc: 57.03%, op_acc: 34.38%] [G loss: 0.835987]\n",
      "epoch:19 step:15499[D loss: 0.389024, acc: 66.41%, op_acc: 39.84%] [G loss: 0.909903]\n",
      "epoch:19 step:15500[D loss: 0.397804, acc: 60.16%, op_acc: 42.97%] [G loss: 0.824548]\n",
      "##############\n",
      "[0.85055552 0.87361845 0.81494431 0.79926241 0.78583497 0.84306757\n",
      " 0.88684206 0.82683337 0.81518235 0.83713375]\n",
      "##########\n",
      "epoch:19 step:15501[D loss: 0.409185, acc: 58.59%, op_acc: 39.84%] [G loss: 0.888428]\n",
      "epoch:19 step:15502[D loss: 0.437301, acc: 57.03%, op_acc: 42.19%] [G loss: 0.798742]\n",
      "epoch:19 step:15503[D loss: 0.414316, acc: 60.94%, op_acc: 42.19%] [G loss: 0.882543]\n",
      "epoch:19 step:15504[D loss: 0.461856, acc: 59.38%, op_acc: 32.81%] [G loss: 0.875230]\n",
      "epoch:19 step:15505[D loss: 0.420284, acc: 63.28%, op_acc: 35.16%] [G loss: 0.953476]\n",
      "epoch:19 step:15506[D loss: 0.439506, acc: 57.03%, op_acc: 30.47%] [G loss: 0.898118]\n",
      "epoch:19 step:15507[D loss: 0.425379, acc: 61.72%, op_acc: 35.16%] [G loss: 0.918560]\n",
      "epoch:19 step:15508[D loss: 0.434913, acc: 59.38%, op_acc: 36.72%] [G loss: 0.872148]\n",
      "epoch:19 step:15509[D loss: 0.401917, acc: 62.50%, op_acc: 38.28%] [G loss: 0.957048]\n",
      "epoch:19 step:15510[D loss: 0.445104, acc: 57.81%, op_acc: 36.72%] [G loss: 0.903844]\n",
      "epoch:19 step:15511[D loss: 0.420569, acc: 61.72%, op_acc: 39.84%] [G loss: 0.856869]\n",
      "epoch:19 step:15512[D loss: 0.426831, acc: 61.72%, op_acc: 32.81%] [G loss: 0.886820]\n",
      "epoch:19 step:15513[D loss: 0.446872, acc: 53.91%, op_acc: 36.72%] [G loss: 0.909716]\n",
      "epoch:19 step:15514[D loss: 0.446150, acc: 52.34%, op_acc: 33.59%] [G loss: 0.858456]\n",
      "epoch:19 step:15515[D loss: 0.468946, acc: 50.78%, op_acc: 30.47%] [G loss: 0.880130]\n",
      "epoch:19 step:15516[D loss: 0.475864, acc: 50.00%, op_acc: 36.72%] [G loss: 0.798021]\n",
      "epoch:19 step:15517[D loss: 0.428530, acc: 57.03%, op_acc: 37.50%] [G loss: 0.912836]\n",
      "epoch:19 step:15518[D loss: 0.418365, acc: 58.59%, op_acc: 37.50%] [G loss: 0.798281]\n",
      "epoch:19 step:15519[D loss: 0.430858, acc: 59.38%, op_acc: 35.16%] [G loss: 0.901068]\n",
      "epoch:19 step:15520[D loss: 0.462482, acc: 51.56%, op_acc: 35.94%] [G loss: 0.839301]\n",
      "epoch:19 step:15521[D loss: 0.387597, acc: 62.50%, op_acc: 39.06%] [G loss: 0.911856]\n",
      "epoch:19 step:15522[D loss: 0.427910, acc: 53.12%, op_acc: 36.72%] [G loss: 0.868926]\n",
      "epoch:19 step:15523[D loss: 0.450988, acc: 53.91%, op_acc: 37.50%] [G loss: 0.887242]\n",
      "epoch:19 step:15524[D loss: 0.436744, acc: 59.38%, op_acc: 38.28%] [G loss: 0.893046]\n",
      "epoch:19 step:15525[D loss: 0.432577, acc: 60.16%, op_acc: 37.50%] [G loss: 0.925461]\n",
      "epoch:19 step:15526[D loss: 0.402042, acc: 60.94%, op_acc: 39.84%] [G loss: 0.890532]\n",
      "epoch:19 step:15527[D loss: 0.410454, acc: 62.50%, op_acc: 43.75%] [G loss: 0.928845]\n",
      "epoch:19 step:15528[D loss: 0.431862, acc: 57.03%, op_acc: 39.06%] [G loss: 1.008308]\n",
      "epoch:19 step:15529[D loss: 0.433423, acc: 57.03%, op_acc: 28.12%] [G loss: 0.862695]\n",
      "epoch:19 step:15530[D loss: 0.435394, acc: 53.12%, op_acc: 39.06%] [G loss: 0.915730]\n",
      "epoch:19 step:15531[D loss: 0.463458, acc: 52.34%, op_acc: 36.72%] [G loss: 0.875502]\n",
      "epoch:19 step:15532[D loss: 0.410693, acc: 73.44%, op_acc: 38.28%] [G loss: 0.888273]\n",
      "epoch:19 step:15533[D loss: 0.433916, acc: 59.38%, op_acc: 35.16%] [G loss: 0.899769]\n",
      "epoch:19 step:15534[D loss: 0.429303, acc: 54.69%, op_acc: 34.38%] [G loss: 0.860317]\n",
      "epoch:19 step:15535[D loss: 0.440875, acc: 62.50%, op_acc: 41.41%] [G loss: 0.866490]\n",
      "epoch:19 step:15536[D loss: 0.410087, acc: 64.84%, op_acc: 41.41%] [G loss: 0.925882]\n",
      "epoch:19 step:15537[D loss: 0.434065, acc: 54.69%, op_acc: 35.94%] [G loss: 0.874706]\n",
      "epoch:19 step:15538[D loss: 0.424078, acc: 51.56%, op_acc: 42.97%] [G loss: 0.779077]\n",
      "epoch:19 step:15539[D loss: 0.438157, acc: 63.28%, op_acc: 32.03%] [G loss: 0.877570]\n",
      "epoch:19 step:15540[D loss: 0.419794, acc: 60.94%, op_acc: 36.72%] [G loss: 0.947125]\n",
      "epoch:19 step:15541[D loss: 0.425596, acc: 66.41%, op_acc: 38.28%] [G loss: 0.832172]\n",
      "epoch:19 step:15542[D loss: 0.466227, acc: 52.34%, op_acc: 40.62%] [G loss: 0.895370]\n",
      "epoch:19 step:15543[D loss: 0.403464, acc: 57.81%, op_acc: 43.75%] [G loss: 0.825871]\n",
      "epoch:19 step:15544[D loss: 0.417724, acc: 67.97%, op_acc: 36.72%] [G loss: 0.865251]\n",
      "epoch:19 step:15545[D loss: 0.437721, acc: 58.59%, op_acc: 38.28%] [G loss: 0.861563]\n",
      "epoch:19 step:15546[D loss: 0.459672, acc: 50.78%, op_acc: 34.38%] [G loss: 0.882942]\n",
      "epoch:19 step:15547[D loss: 0.446457, acc: 57.03%, op_acc: 32.81%] [G loss: 0.885724]\n",
      "epoch:19 step:15548[D loss: 0.409257, acc: 69.53%, op_acc: 37.50%] [G loss: 0.917498]\n",
      "epoch:19 step:15549[D loss: 0.412592, acc: 52.34%, op_acc: 46.09%] [G loss: 0.954661]\n",
      "epoch:19 step:15550[D loss: 0.406813, acc: 66.41%, op_acc: 35.94%] [G loss: 0.945384]\n",
      "##############\n",
      "[0.87841917 0.85213948 0.80602432 0.81002554 0.78182441 0.8237864\n",
      " 0.87471079 0.82763779 0.80649367 0.81826792]\n",
      "##########\n",
      "epoch:19 step:15551[D loss: 0.411461, acc: 58.59%, op_acc: 40.62%] [G loss: 0.950933]\n",
      "epoch:19 step:15552[D loss: 0.435818, acc: 57.03%, op_acc: 35.16%] [G loss: 0.831502]\n",
      "epoch:19 step:15553[D loss: 0.419082, acc: 59.38%, op_acc: 36.72%] [G loss: 0.859253]\n",
      "epoch:19 step:15554[D loss: 0.422778, acc: 54.69%, op_acc: 41.41%] [G loss: 0.858558]\n",
      "epoch:19 step:15555[D loss: 0.437877, acc: 53.12%, op_acc: 41.41%] [G loss: 0.827347]\n",
      "epoch:19 step:15556[D loss: 0.411100, acc: 55.47%, op_acc: 43.75%] [G loss: 0.910430]\n",
      "epoch:19 step:15557[D loss: 0.405681, acc: 60.16%, op_acc: 34.38%] [G loss: 0.950016]\n",
      "epoch:19 step:15558[D loss: 0.458047, acc: 50.78%, op_acc: 38.28%] [G loss: 0.868596]\n",
      "epoch:19 step:15559[D loss: 0.448174, acc: 50.00%, op_acc: 35.16%] [G loss: 0.826647]\n",
      "epoch:19 step:15560[D loss: 0.413385, acc: 53.91%, op_acc: 38.28%] [G loss: 0.874235]\n",
      "epoch:19 step:15561[D loss: 0.436402, acc: 53.91%, op_acc: 39.06%] [G loss: 0.860728]\n",
      "epoch:19 step:15562[D loss: 0.422687, acc: 50.78%, op_acc: 38.28%] [G loss: 0.851326]\n",
      "epoch:19 step:15563[D loss: 0.456770, acc: 58.59%, op_acc: 30.47%] [G loss: 0.829956]\n",
      "epoch:19 step:15564[D loss: 0.437503, acc: 60.16%, op_acc: 37.50%] [G loss: 0.869526]\n",
      "epoch:19 step:15565[D loss: 0.430946, acc: 57.03%, op_acc: 36.72%] [G loss: 0.824675]\n",
      "epoch:19 step:15566[D loss: 0.491787, acc: 49.22%, op_acc: 31.25%] [G loss: 0.826235]\n",
      "epoch:19 step:15567[D loss: 0.446558, acc: 58.59%, op_acc: 36.72%] [G loss: 0.838636]\n",
      "epoch:19 step:15568[D loss: 0.405864, acc: 64.06%, op_acc: 38.28%] [G loss: 0.875616]\n",
      "epoch:19 step:15569[D loss: 0.422922, acc: 59.38%, op_acc: 47.66%] [G loss: 0.834721]\n",
      "epoch:19 step:15570[D loss: 0.428307, acc: 57.81%, op_acc: 42.97%] [G loss: 0.836230]\n",
      "epoch:19 step:15571[D loss: 0.424524, acc: 58.59%, op_acc: 40.62%] [G loss: 0.898163]\n",
      "epoch:19 step:15572[D loss: 0.422470, acc: 56.25%, op_acc: 41.41%] [G loss: 0.847373]\n",
      "epoch:19 step:15573[D loss: 0.425538, acc: 64.84%, op_acc: 41.41%] [G loss: 0.934834]\n",
      "epoch:19 step:15574[D loss: 0.431501, acc: 56.25%, op_acc: 35.94%] [G loss: 0.881263]\n",
      "epoch:19 step:15575[D loss: 0.440717, acc: 57.81%, op_acc: 35.16%] [G loss: 0.864665]\n",
      "epoch:19 step:15576[D loss: 0.403382, acc: 61.72%, op_acc: 39.84%] [G loss: 0.880318]\n",
      "epoch:19 step:15577[D loss: 0.428323, acc: 55.47%, op_acc: 39.06%] [G loss: 0.906786]\n",
      "epoch:19 step:15578[D loss: 0.414682, acc: 62.50%, op_acc: 39.06%] [G loss: 0.904458]\n",
      "epoch:19 step:15579[D loss: 0.421855, acc: 60.16%, op_acc: 41.41%] [G loss: 0.877756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15580[D loss: 0.403980, acc: 64.84%, op_acc: 39.06%] [G loss: 0.886783]\n",
      "epoch:19 step:15581[D loss: 0.451885, acc: 55.47%, op_acc: 35.94%] [G loss: 0.857396]\n",
      "epoch:19 step:15582[D loss: 0.440454, acc: 59.38%, op_acc: 38.28%] [G loss: 0.851113]\n",
      "epoch:19 step:15583[D loss: 0.420920, acc: 56.25%, op_acc: 42.19%] [G loss: 0.850518]\n",
      "epoch:19 step:15584[D loss: 0.391742, acc: 65.62%, op_acc: 41.41%] [G loss: 0.914905]\n",
      "epoch:19 step:15585[D loss: 0.438985, acc: 60.94%, op_acc: 34.38%] [G loss: 0.908534]\n",
      "epoch:19 step:15586[D loss: 0.427234, acc: 60.16%, op_acc: 37.50%] [G loss: 0.896653]\n",
      "epoch:19 step:15587[D loss: 0.449564, acc: 48.44%, op_acc: 34.38%] [G loss: 0.805307]\n",
      "epoch:19 step:15588[D loss: 0.461684, acc: 50.00%, op_acc: 39.06%] [G loss: 0.804993]\n",
      "epoch:19 step:15589[D loss: 0.431124, acc: 57.03%, op_acc: 39.06%] [G loss: 0.845220]\n",
      "epoch:19 step:15590[D loss: 0.448277, acc: 56.25%, op_acc: 34.38%] [G loss: 0.880719]\n",
      "epoch:19 step:15591[D loss: 0.419497, acc: 53.91%, op_acc: 41.41%] [G loss: 0.912028]\n",
      "epoch:19 step:15592[D loss: 0.416836, acc: 55.47%, op_acc: 42.19%] [G loss: 0.865141]\n",
      "epoch:19 step:15593[D loss: 0.409688, acc: 57.81%, op_acc: 42.19%] [G loss: 0.897492]\n",
      "epoch:19 step:15594[D loss: 0.402871, acc: 63.28%, op_acc: 37.50%] [G loss: 0.953111]\n",
      "epoch:19 step:15595[D loss: 0.410589, acc: 67.19%, op_acc: 42.19%] [G loss: 0.878970]\n",
      "epoch:19 step:15596[D loss: 0.424531, acc: 58.59%, op_acc: 42.97%] [G loss: 0.915243]\n",
      "epoch:19 step:15597[D loss: 0.441388, acc: 52.34%, op_acc: 39.84%] [G loss: 0.879510]\n",
      "epoch:19 step:15598[D loss: 0.424907, acc: 60.16%, op_acc: 42.19%] [G loss: 0.895216]\n",
      "epoch:19 step:15599[D loss: 0.429085, acc: 53.12%, op_acc: 42.97%] [G loss: 0.901224]\n",
      "epoch:19 step:15600[D loss: 0.413420, acc: 61.72%, op_acc: 44.53%] [G loss: 0.882491]\n",
      "##############\n",
      "[0.84966264 0.85577743 0.8190887  0.80293382 0.82003751 0.81310228\n",
      " 0.88450504 0.83056131 0.77937223 0.8318717 ]\n",
      "##########\n",
      "epoch:19 step:15601[D loss: 0.446485, acc: 55.47%, op_acc: 37.50%] [G loss: 0.894868]\n",
      "epoch:19 step:15602[D loss: 0.440219, acc: 55.47%, op_acc: 37.50%] [G loss: 0.892920]\n",
      "epoch:19 step:15603[D loss: 0.416270, acc: 60.16%, op_acc: 40.62%] [G loss: 0.807385]\n",
      "epoch:19 step:15604[D loss: 0.401404, acc: 63.28%, op_acc: 46.88%] [G loss: 0.885568]\n",
      "epoch:19 step:15605[D loss: 0.430351, acc: 57.81%, op_acc: 38.28%] [G loss: 0.901638]\n",
      "epoch:19 step:15606[D loss: 0.427842, acc: 57.03%, op_acc: 36.72%] [G loss: 0.765392]\n",
      "epoch:19 step:15607[D loss: 0.449345, acc: 50.78%, op_acc: 33.59%] [G loss: 0.865344]\n",
      "epoch:19 step:15608[D loss: 0.395599, acc: 63.28%, op_acc: 42.19%] [G loss: 0.929893]\n",
      "epoch:19 step:15609[D loss: 0.405468, acc: 62.50%, op_acc: 38.28%] [G loss: 0.891685]\n",
      "epoch:19 step:15610[D loss: 0.453177, acc: 55.47%, op_acc: 31.25%] [G loss: 0.930373]\n",
      "epoch:19 step:15611[D loss: 0.455336, acc: 47.66%, op_acc: 36.72%] [G loss: 0.917994]\n",
      "epoch:19 step:15612[D loss: 0.438190, acc: 58.59%, op_acc: 38.28%] [G loss: 0.850309]\n",
      "epoch:19 step:15613[D loss: 0.392613, acc: 72.66%, op_acc: 42.19%] [G loss: 0.952650]\n",
      "epoch:19 step:15614[D loss: 0.442813, acc: 56.25%, op_acc: 32.03%] [G loss: 0.859024]\n",
      "epoch:19 step:15615[D loss: 0.446715, acc: 50.78%, op_acc: 35.94%] [G loss: 0.902456]\n",
      "epoch:19 step:15616[D loss: 0.450245, acc: 47.66%, op_acc: 36.72%] [G loss: 0.862773]\n",
      "epoch:19 step:15617[D loss: 0.412874, acc: 53.12%, op_acc: 43.75%] [G loss: 0.826811]\n",
      "epoch:19 step:15618[D loss: 0.413738, acc: 64.84%, op_acc: 33.59%] [G loss: 0.937297]\n",
      "epoch:19 step:15619[D loss: 0.394644, acc: 60.94%, op_acc: 42.19%] [G loss: 0.880726]\n",
      "epoch:19 step:15620[D loss: 0.418917, acc: 64.84%, op_acc: 37.50%] [G loss: 0.957215]\n",
      "epoch:20 step:15621[D loss: 0.436972, acc: 50.00%, op_acc: 37.50%] [G loss: 0.856546]\n",
      "epoch:20 step:15622[D loss: 0.435016, acc: 56.25%, op_acc: 42.19%] [G loss: 0.869090]\n",
      "epoch:20 step:15623[D loss: 0.459403, acc: 50.78%, op_acc: 37.50%] [G loss: 0.915767]\n",
      "epoch:20 step:15624[D loss: 0.403063, acc: 64.06%, op_acc: 43.75%] [G loss: 0.955298]\n",
      "epoch:20 step:15625[D loss: 0.424167, acc: 58.59%, op_acc: 36.72%] [G loss: 0.861788]\n",
      "epoch:20 step:15626[D loss: 0.453013, acc: 52.34%, op_acc: 32.81%] [G loss: 0.876957]\n",
      "epoch:20 step:15627[D loss: 0.407994, acc: 63.28%, op_acc: 37.50%] [G loss: 0.946256]\n",
      "epoch:20 step:15628[D loss: 0.431777, acc: 59.38%, op_acc: 35.16%] [G loss: 0.816812]\n",
      "epoch:20 step:15629[D loss: 0.424357, acc: 54.69%, op_acc: 39.84%] [G loss: 0.968283]\n",
      "epoch:20 step:15630[D loss: 0.403549, acc: 70.31%, op_acc: 32.81%] [G loss: 0.869230]\n",
      "epoch:20 step:15631[D loss: 0.438354, acc: 54.69%, op_acc: 39.84%] [G loss: 0.883198]\n",
      "epoch:20 step:15632[D loss: 0.432862, acc: 60.16%, op_acc: 40.62%] [G loss: 0.820810]\n",
      "epoch:20 step:15633[D loss: 0.419595, acc: 60.16%, op_acc: 38.28%] [G loss: 0.822572]\n",
      "epoch:20 step:15634[D loss: 0.453372, acc: 54.69%, op_acc: 33.59%] [G loss: 0.808417]\n",
      "epoch:20 step:15635[D loss: 0.438150, acc: 60.16%, op_acc: 39.06%] [G loss: 0.850652]\n",
      "epoch:20 step:15636[D loss: 0.402683, acc: 59.38%, op_acc: 43.75%] [G loss: 0.878090]\n",
      "epoch:20 step:15637[D loss: 0.467606, acc: 45.31%, op_acc: 42.19%] [G loss: 0.960777]\n",
      "epoch:20 step:15638[D loss: 0.401478, acc: 64.84%, op_acc: 40.62%] [G loss: 0.865127]\n",
      "epoch:20 step:15639[D loss: 0.407632, acc: 64.84%, op_acc: 42.97%] [G loss: 0.886859]\n",
      "epoch:20 step:15640[D loss: 0.423322, acc: 53.91%, op_acc: 39.06%] [G loss: 0.872701]\n",
      "epoch:20 step:15641[D loss: 0.474849, acc: 56.25%, op_acc: 32.81%] [G loss: 0.838829]\n",
      "epoch:20 step:15642[D loss: 0.428151, acc: 56.25%, op_acc: 39.84%] [G loss: 0.909837]\n",
      "epoch:20 step:15643[D loss: 0.429228, acc: 57.03%, op_acc: 39.06%] [G loss: 0.896764]\n",
      "epoch:20 step:15644[D loss: 0.435452, acc: 64.84%, op_acc: 34.38%] [G loss: 0.903927]\n",
      "epoch:20 step:15645[D loss: 0.431530, acc: 60.94%, op_acc: 36.72%] [G loss: 0.873397]\n",
      "epoch:20 step:15646[D loss: 0.434359, acc: 57.03%, op_acc: 41.41%] [G loss: 0.846382]\n",
      "epoch:20 step:15647[D loss: 0.432201, acc: 58.59%, op_acc: 33.59%] [G loss: 0.983648]\n",
      "epoch:20 step:15648[D loss: 0.428494, acc: 60.16%, op_acc: 40.62%] [G loss: 0.880613]\n",
      "epoch:20 step:15649[D loss: 0.426585, acc: 56.25%, op_acc: 42.97%] [G loss: 0.903081]\n",
      "epoch:20 step:15650[D loss: 0.393298, acc: 69.53%, op_acc: 43.75%] [G loss: 0.889025]\n",
      "##############\n",
      "[0.85829855 0.87719461 0.82782912 0.80647384 0.79382286 0.84184223\n",
      " 0.90307746 0.83208445 0.83711416 0.83039782]\n",
      "##########\n",
      "epoch:20 step:15651[D loss: 0.432749, acc: 62.50%, op_acc: 35.16%] [G loss: 0.942113]\n",
      "epoch:20 step:15652[D loss: 0.442067, acc: 58.59%, op_acc: 35.16%] [G loss: 0.952418]\n",
      "epoch:20 step:15653[D loss: 0.386832, acc: 69.53%, op_acc: 44.53%] [G loss: 0.871130]\n",
      "epoch:20 step:15654[D loss: 0.407128, acc: 60.16%, op_acc: 43.75%] [G loss: 0.922666]\n",
      "epoch:20 step:15655[D loss: 0.429542, acc: 64.06%, op_acc: 38.28%] [G loss: 0.951400]\n",
      "epoch:20 step:15656[D loss: 0.400135, acc: 61.72%, op_acc: 43.75%] [G loss: 0.939152]\n",
      "epoch:20 step:15657[D loss: 0.380148, acc: 69.53%, op_acc: 39.84%] [G loss: 1.040597]\n",
      "epoch:20 step:15658[D loss: 0.418460, acc: 63.28%, op_acc: 39.84%] [G loss: 0.880771]\n",
      "epoch:20 step:15659[D loss: 0.417034, acc: 57.03%, op_acc: 39.84%] [G loss: 0.969222]\n",
      "epoch:20 step:15660[D loss: 0.441526, acc: 60.16%, op_acc: 35.94%] [G loss: 0.878517]\n",
      "epoch:20 step:15661[D loss: 0.434351, acc: 57.03%, op_acc: 39.06%] [G loss: 0.823852]\n",
      "epoch:20 step:15662[D loss: 0.409591, acc: 60.94%, op_acc: 46.09%] [G loss: 0.843139]\n",
      "epoch:20 step:15663[D loss: 0.422102, acc: 58.59%, op_acc: 42.97%] [G loss: 0.827816]\n",
      "epoch:20 step:15664[D loss: 0.448958, acc: 52.34%, op_acc: 39.06%] [G loss: 0.890588]\n",
      "epoch:20 step:15665[D loss: 0.406910, acc: 63.28%, op_acc: 40.62%] [G loss: 0.921161]\n",
      "epoch:20 step:15666[D loss: 0.405558, acc: 64.84%, op_acc: 41.41%] [G loss: 0.819432]\n",
      "epoch:20 step:15667[D loss: 0.453075, acc: 53.91%, op_acc: 38.28%] [G loss: 0.874154]\n",
      "epoch:20 step:15668[D loss: 0.452949, acc: 56.25%, op_acc: 31.25%] [G loss: 0.815275]\n",
      "epoch:20 step:15669[D loss: 0.397205, acc: 65.62%, op_acc: 38.28%] [G loss: 0.934916]\n",
      "epoch:20 step:15670[D loss: 0.437220, acc: 55.47%, op_acc: 35.94%] [G loss: 0.859000]\n",
      "epoch:20 step:15671[D loss: 0.406666, acc: 64.06%, op_acc: 38.28%] [G loss: 0.917115]\n",
      "epoch:20 step:15672[D loss: 0.441712, acc: 57.03%, op_acc: 42.19%] [G loss: 0.913930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15673[D loss: 0.470390, acc: 52.34%, op_acc: 34.38%] [G loss: 0.938335]\n",
      "epoch:20 step:15674[D loss: 0.450164, acc: 53.91%, op_acc: 41.41%] [G loss: 0.910724]\n",
      "epoch:20 step:15675[D loss: 0.426690, acc: 57.03%, op_acc: 42.19%] [G loss: 0.889803]\n",
      "epoch:20 step:15676[D loss: 0.424388, acc: 60.94%, op_acc: 39.84%] [G loss: 0.884649]\n",
      "epoch:20 step:15677[D loss: 0.403747, acc: 66.41%, op_acc: 41.41%] [G loss: 0.877689]\n",
      "epoch:20 step:15678[D loss: 0.433145, acc: 56.25%, op_acc: 42.19%] [G loss: 0.857712]\n",
      "epoch:20 step:15679[D loss: 0.407971, acc: 55.47%, op_acc: 40.62%] [G loss: 0.898548]\n",
      "epoch:20 step:15680[D loss: 0.422781, acc: 61.72%, op_acc: 39.06%] [G loss: 0.896112]\n",
      "epoch:20 step:15681[D loss: 0.435014, acc: 57.81%, op_acc: 36.72%] [G loss: 0.949528]\n",
      "epoch:20 step:15682[D loss: 0.413979, acc: 65.62%, op_acc: 39.84%] [G loss: 0.881748]\n",
      "epoch:20 step:15683[D loss: 0.443448, acc: 55.47%, op_acc: 35.16%] [G loss: 0.852865]\n",
      "epoch:20 step:15684[D loss: 0.441579, acc: 57.03%, op_acc: 33.59%] [G loss: 0.901862]\n",
      "epoch:20 step:15685[D loss: 0.450033, acc: 55.47%, op_acc: 39.06%] [G loss: 0.876544]\n",
      "epoch:20 step:15686[D loss: 0.467559, acc: 52.34%, op_acc: 32.81%] [G loss: 0.817059]\n",
      "epoch:20 step:15687[D loss: 0.415022, acc: 64.06%, op_acc: 39.06%] [G loss: 0.874615]\n",
      "epoch:20 step:15688[D loss: 0.429813, acc: 57.03%, op_acc: 39.84%] [G loss: 0.876775]\n",
      "epoch:20 step:15689[D loss: 0.407344, acc: 60.94%, op_acc: 43.75%] [G loss: 0.905591]\n",
      "epoch:20 step:15690[D loss: 0.426299, acc: 59.38%, op_acc: 39.84%] [G loss: 0.866908]\n",
      "epoch:20 step:15691[D loss: 0.454332, acc: 57.03%, op_acc: 36.72%] [G loss: 0.873687]\n",
      "epoch:20 step:15692[D loss: 0.416706, acc: 57.81%, op_acc: 42.19%] [G loss: 0.855936]\n",
      "epoch:20 step:15693[D loss: 0.447207, acc: 53.91%, op_acc: 38.28%] [G loss: 0.803662]\n",
      "epoch:20 step:15694[D loss: 0.391573, acc: 60.16%, op_acc: 43.75%] [G loss: 0.904196]\n",
      "epoch:20 step:15695[D loss: 0.388131, acc: 66.41%, op_acc: 38.28%] [G loss: 0.900411]\n",
      "epoch:20 step:15696[D loss: 0.418875, acc: 64.06%, op_acc: 39.06%] [G loss: 0.881542]\n",
      "epoch:20 step:15697[D loss: 0.435166, acc: 52.34%, op_acc: 37.50%] [G loss: 0.843404]\n",
      "epoch:20 step:15698[D loss: 0.448630, acc: 61.72%, op_acc: 34.38%] [G loss: 0.866067]\n",
      "epoch:20 step:15699[D loss: 0.424536, acc: 65.62%, op_acc: 38.28%] [G loss: 0.922500]\n",
      "epoch:20 step:15700[D loss: 0.445407, acc: 61.72%, op_acc: 34.38%] [G loss: 0.876414]\n",
      "##############\n",
      "[0.86894958 0.84193964 0.83661412 0.78444343 0.80285627 0.83101122\n",
      " 0.89273203 0.81954887 0.80919034 0.83918418]\n",
      "##########\n",
      "epoch:20 step:15701[D loss: 0.469526, acc: 55.47%, op_acc: 33.59%] [G loss: 0.912500]\n",
      "epoch:20 step:15702[D loss: 0.418193, acc: 62.50%, op_acc: 37.50%] [G loss: 0.956072]\n",
      "epoch:20 step:15703[D loss: 0.413018, acc: 63.28%, op_acc: 38.28%] [G loss: 0.933324]\n",
      "epoch:20 step:15704[D loss: 0.417907, acc: 57.81%, op_acc: 40.62%] [G loss: 0.881222]\n",
      "epoch:20 step:15705[D loss: 0.444568, acc: 54.69%, op_acc: 33.59%] [G loss: 0.942419]\n",
      "epoch:20 step:15706[D loss: 0.423021, acc: 60.16%, op_acc: 43.75%] [G loss: 0.896418]\n",
      "epoch:20 step:15707[D loss: 0.436744, acc: 57.81%, op_acc: 36.72%] [G loss: 0.850112]\n",
      "epoch:20 step:15708[D loss: 0.399501, acc: 64.84%, op_acc: 41.41%] [G loss: 0.867098]\n",
      "epoch:20 step:15709[D loss: 0.439337, acc: 58.59%, op_acc: 38.28%] [G loss: 0.834795]\n",
      "epoch:20 step:15710[D loss: 0.404039, acc: 65.62%, op_acc: 39.06%] [G loss: 0.858492]\n",
      "epoch:20 step:15711[D loss: 0.402770, acc: 66.41%, op_acc: 45.31%] [G loss: 0.914113]\n",
      "epoch:20 step:15712[D loss: 0.440308, acc: 57.81%, op_acc: 40.62%] [G loss: 0.834454]\n",
      "epoch:20 step:15713[D loss: 0.389185, acc: 67.97%, op_acc: 43.75%] [G loss: 0.979706]\n",
      "epoch:20 step:15714[D loss: 0.414236, acc: 56.25%, op_acc: 44.53%] [G loss: 0.886150]\n",
      "epoch:20 step:15715[D loss: 0.417065, acc: 62.50%, op_acc: 40.62%] [G loss: 0.920799]\n",
      "epoch:20 step:15716[D loss: 0.461436, acc: 53.12%, op_acc: 32.81%] [G loss: 0.828427]\n",
      "epoch:20 step:15717[D loss: 0.406233, acc: 59.38%, op_acc: 39.84%] [G loss: 0.901713]\n",
      "epoch:20 step:15718[D loss: 0.423879, acc: 62.50%, op_acc: 35.16%] [G loss: 0.911654]\n",
      "epoch:20 step:15719[D loss: 0.434551, acc: 52.34%, op_acc: 40.62%] [G loss: 0.951761]\n",
      "epoch:20 step:15720[D loss: 0.383977, acc: 64.06%, op_acc: 46.09%] [G loss: 0.935387]\n",
      "epoch:20 step:15721[D loss: 0.421408, acc: 62.50%, op_acc: 36.72%] [G loss: 0.851744]\n",
      "epoch:20 step:15722[D loss: 0.432344, acc: 55.47%, op_acc: 38.28%] [G loss: 0.950578]\n",
      "epoch:20 step:15723[D loss: 0.421101, acc: 59.38%, op_acc: 42.97%] [G loss: 0.976814]\n",
      "epoch:20 step:15724[D loss: 0.427615, acc: 59.38%, op_acc: 38.28%] [G loss: 0.930510]\n",
      "epoch:20 step:15725[D loss: 0.455299, acc: 46.88%, op_acc: 40.62%] [G loss: 0.880742]\n",
      "epoch:20 step:15726[D loss: 0.422335, acc: 60.16%, op_acc: 40.62%] [G loss: 0.807386]\n",
      "epoch:20 step:15727[D loss: 0.424717, acc: 59.38%, op_acc: 39.84%] [G loss: 0.887627]\n",
      "epoch:20 step:15728[D loss: 0.461726, acc: 58.59%, op_acc: 33.59%] [G loss: 0.915798]\n",
      "epoch:20 step:15729[D loss: 0.428223, acc: 63.28%, op_acc: 38.28%] [G loss: 0.924874]\n",
      "epoch:20 step:15730[D loss: 0.424129, acc: 58.59%, op_acc: 47.66%] [G loss: 0.914220]\n",
      "epoch:20 step:15731[D loss: 0.459954, acc: 51.56%, op_acc: 35.16%] [G loss: 0.807778]\n",
      "epoch:20 step:15732[D loss: 0.416966, acc: 58.59%, op_acc: 42.19%] [G loss: 0.786808]\n",
      "epoch:20 step:15733[D loss: 0.454026, acc: 52.34%, op_acc: 35.16%] [G loss: 0.955054]\n",
      "epoch:20 step:15734[D loss: 0.432897, acc: 50.00%, op_acc: 41.41%] [G loss: 0.809562]\n",
      "epoch:20 step:15735[D loss: 0.425043, acc: 54.69%, op_acc: 37.50%] [G loss: 0.878384]\n",
      "epoch:20 step:15736[D loss: 0.413971, acc: 66.41%, op_acc: 33.59%] [G loss: 0.850938]\n",
      "epoch:20 step:15737[D loss: 0.443549, acc: 53.91%, op_acc: 36.72%] [G loss: 0.777458]\n",
      "epoch:20 step:15738[D loss: 0.437743, acc: 53.91%, op_acc: 42.97%] [G loss: 0.862913]\n",
      "epoch:20 step:15739[D loss: 0.452658, acc: 51.56%, op_acc: 35.16%] [G loss: 0.889248]\n",
      "epoch:20 step:15740[D loss: 0.413343, acc: 60.94%, op_acc: 39.06%] [G loss: 0.897020]\n",
      "epoch:20 step:15741[D loss: 0.433526, acc: 60.16%, op_acc: 39.06%] [G loss: 0.893265]\n",
      "epoch:20 step:15742[D loss: 0.412123, acc: 57.03%, op_acc: 39.06%] [G loss: 0.919257]\n",
      "epoch:20 step:15743[D loss: 0.424124, acc: 59.38%, op_acc: 36.72%] [G loss: 0.834819]\n",
      "epoch:20 step:15744[D loss: 0.415534, acc: 61.72%, op_acc: 35.16%] [G loss: 0.804160]\n",
      "epoch:20 step:15745[D loss: 0.457442, acc: 53.91%, op_acc: 35.94%] [G loss: 0.829836]\n",
      "epoch:20 step:15746[D loss: 0.440856, acc: 53.12%, op_acc: 38.28%] [G loss: 0.840659]\n",
      "epoch:20 step:15747[D loss: 0.437052, acc: 60.16%, op_acc: 37.50%] [G loss: 0.902873]\n",
      "epoch:20 step:15748[D loss: 0.403711, acc: 71.09%, op_acc: 34.38%] [G loss: 0.902570]\n",
      "epoch:20 step:15749[D loss: 0.477457, acc: 50.00%, op_acc: 34.38%] [G loss: 0.908380]\n",
      "epoch:20 step:15750[D loss: 0.423593, acc: 55.47%, op_acc: 39.06%] [G loss: 0.859789]\n",
      "##############\n",
      "[0.86140303 0.85839236 0.81123152 0.79314181 0.79160822 0.80309576\n",
      " 0.8773559  0.81294794 0.81810773 0.83300367]\n",
      "##########\n",
      "epoch:20 step:15751[D loss: 0.431735, acc: 51.56%, op_acc: 35.94%] [G loss: 0.901491]\n",
      "epoch:20 step:15752[D loss: 0.394136, acc: 60.94%, op_acc: 43.75%] [G loss: 0.927375]\n",
      "epoch:20 step:15753[D loss: 0.471778, acc: 59.38%, op_acc: 32.03%] [G loss: 0.935937]\n",
      "epoch:20 step:15754[D loss: 0.424188, acc: 56.25%, op_acc: 39.84%] [G loss: 0.926451]\n",
      "epoch:20 step:15755[D loss: 0.443382, acc: 53.12%, op_acc: 35.16%] [G loss: 0.848912]\n",
      "epoch:20 step:15756[D loss: 0.410818, acc: 64.06%, op_acc: 39.06%] [G loss: 0.897373]\n",
      "epoch:20 step:15757[D loss: 0.408526, acc: 67.19%, op_acc: 35.94%] [G loss: 0.953621]\n",
      "epoch:20 step:15758[D loss: 0.439584, acc: 56.25%, op_acc: 37.50%] [G loss: 0.937264]\n",
      "epoch:20 step:15759[D loss: 0.428734, acc: 49.22%, op_acc: 35.94%] [G loss: 0.857334]\n",
      "epoch:20 step:15760[D loss: 0.430579, acc: 63.28%, op_acc: 39.84%] [G loss: 0.881211]\n",
      "epoch:20 step:15761[D loss: 0.450218, acc: 61.72%, op_acc: 34.38%] [G loss: 0.878412]\n",
      "epoch:20 step:15762[D loss: 0.388074, acc: 65.62%, op_acc: 40.62%] [G loss: 0.890553]\n",
      "epoch:20 step:15763[D loss: 0.413331, acc: 58.59%, op_acc: 43.75%] [G loss: 0.897087]\n",
      "epoch:20 step:15764[D loss: 0.438711, acc: 62.50%, op_acc: 36.72%] [G loss: 0.835120]\n",
      "epoch:20 step:15765[D loss: 0.450633, acc: 55.47%, op_acc: 35.94%] [G loss: 0.907849]\n",
      "epoch:20 step:15766[D loss: 0.420385, acc: 63.28%, op_acc: 38.28%] [G loss: 0.929412]\n",
      "epoch:20 step:15767[D loss: 0.411913, acc: 63.28%, op_acc: 37.50%] [G loss: 0.899356]\n",
      "epoch:20 step:15768[D loss: 0.428269, acc: 57.81%, op_acc: 41.41%] [G loss: 0.935263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15769[D loss: 0.404604, acc: 64.84%, op_acc: 39.84%] [G loss: 0.863522]\n",
      "epoch:20 step:15770[D loss: 0.444099, acc: 52.34%, op_acc: 39.06%] [G loss: 0.855816]\n",
      "epoch:20 step:15771[D loss: 0.377072, acc: 69.53%, op_acc: 46.88%] [G loss: 0.929354]\n",
      "epoch:20 step:15772[D loss: 0.411190, acc: 60.16%, op_acc: 41.41%] [G loss: 0.838818]\n",
      "epoch:20 step:15773[D loss: 0.426165, acc: 59.38%, op_acc: 35.94%] [G loss: 0.892972]\n",
      "epoch:20 step:15774[D loss: 0.425943, acc: 69.53%, op_acc: 39.84%] [G loss: 0.892099]\n",
      "epoch:20 step:15775[D loss: 0.421822, acc: 56.25%, op_acc: 40.62%] [G loss: 0.896390]\n",
      "epoch:20 step:15776[D loss: 0.425385, acc: 57.81%, op_acc: 40.62%] [G loss: 0.899861]\n",
      "epoch:20 step:15777[D loss: 0.453666, acc: 52.34%, op_acc: 38.28%] [G loss: 0.775451]\n",
      "epoch:20 step:15778[D loss: 0.435037, acc: 51.56%, op_acc: 41.41%] [G loss: 0.905589]\n",
      "epoch:20 step:15779[D loss: 0.425366, acc: 64.84%, op_acc: 39.84%] [G loss: 0.960976]\n",
      "epoch:20 step:15780[D loss: 0.419075, acc: 64.06%, op_acc: 39.06%] [G loss: 0.901527]\n",
      "epoch:20 step:15781[D loss: 0.437985, acc: 58.59%, op_acc: 39.84%] [G loss: 0.886377]\n",
      "epoch:20 step:15782[D loss: 0.410377, acc: 58.59%, op_acc: 43.75%] [G loss: 0.864566]\n",
      "epoch:20 step:15783[D loss: 0.423776, acc: 66.41%, op_acc: 35.16%] [G loss: 0.891765]\n",
      "epoch:20 step:15784[D loss: 0.438993, acc: 63.28%, op_acc: 35.94%] [G loss: 0.930056]\n",
      "epoch:20 step:15785[D loss: 0.384762, acc: 66.41%, op_acc: 38.28%] [G loss: 0.912062]\n",
      "epoch:20 step:15786[D loss: 0.453893, acc: 56.25%, op_acc: 39.06%] [G loss: 0.893810]\n",
      "epoch:20 step:15787[D loss: 0.427757, acc: 60.16%, op_acc: 39.06%] [G loss: 0.882905]\n",
      "epoch:20 step:15788[D loss: 0.410281, acc: 56.25%, op_acc: 42.97%] [G loss: 0.919754]\n",
      "epoch:20 step:15789[D loss: 0.447661, acc: 60.16%, op_acc: 37.50%] [G loss: 0.869461]\n",
      "epoch:20 step:15790[D loss: 0.437161, acc: 53.91%, op_acc: 39.06%] [G loss: 0.879826]\n",
      "epoch:20 step:15791[D loss: 0.425093, acc: 63.28%, op_acc: 37.50%] [G loss: 0.889389]\n",
      "epoch:20 step:15792[D loss: 0.399389, acc: 67.19%, op_acc: 40.62%] [G loss: 0.885681]\n",
      "epoch:20 step:15793[D loss: 0.461697, acc: 51.56%, op_acc: 35.16%] [G loss: 0.856274]\n",
      "epoch:20 step:15794[D loss: 0.468186, acc: 50.78%, op_acc: 34.38%] [G loss: 0.850590]\n",
      "epoch:20 step:15795[D loss: 0.401852, acc: 71.88%, op_acc: 40.62%] [G loss: 0.847003]\n",
      "epoch:20 step:15796[D loss: 0.429078, acc: 60.94%, op_acc: 43.75%] [G loss: 0.897449]\n",
      "epoch:20 step:15797[D loss: 0.431546, acc: 52.34%, op_acc: 42.19%] [G loss: 0.853232]\n",
      "epoch:20 step:15798[D loss: 0.431695, acc: 60.94%, op_acc: 36.72%] [G loss: 0.868304]\n",
      "epoch:20 step:15799[D loss: 0.407548, acc: 58.59%, op_acc: 39.84%] [G loss: 0.923144]\n",
      "epoch:20 step:15800[D loss: 0.416254, acc: 60.16%, op_acc: 42.19%] [G loss: 0.922304]\n",
      "##############\n",
      "[0.87217226 0.85130221 0.81167891 0.80844256 0.81345254 0.82280896\n",
      " 0.87731081 0.8215026  0.79467669 0.82022913]\n",
      "##########\n",
      "epoch:20 step:15801[D loss: 0.407684, acc: 55.47%, op_acc: 44.53%] [G loss: 0.927761]\n",
      "epoch:20 step:15802[D loss: 0.396816, acc: 67.97%, op_acc: 46.09%] [G loss: 0.902318]\n",
      "epoch:20 step:15803[D loss: 0.416248, acc: 58.59%, op_acc: 39.06%] [G loss: 0.919364]\n",
      "epoch:20 step:15804[D loss: 0.389913, acc: 67.97%, op_acc: 42.19%] [G loss: 0.956232]\n",
      "epoch:20 step:15805[D loss: 0.443622, acc: 59.38%, op_acc: 35.94%] [G loss: 0.884274]\n",
      "epoch:20 step:15806[D loss: 0.451141, acc: 53.91%, op_acc: 39.84%] [G loss: 0.903365]\n",
      "epoch:20 step:15807[D loss: 0.432336, acc: 50.78%, op_acc: 36.72%] [G loss: 0.890758]\n",
      "epoch:20 step:15808[D loss: 0.431384, acc: 55.47%, op_acc: 45.31%] [G loss: 0.907362]\n",
      "epoch:20 step:15809[D loss: 0.426866, acc: 64.06%, op_acc: 33.59%] [G loss: 0.871258]\n",
      "epoch:20 step:15810[D loss: 0.452533, acc: 53.12%, op_acc: 38.28%] [G loss: 0.890526]\n",
      "epoch:20 step:15811[D loss: 0.433489, acc: 55.47%, op_acc: 39.06%] [G loss: 0.789524]\n",
      "epoch:20 step:15812[D loss: 0.461783, acc: 57.81%, op_acc: 37.50%] [G loss: 0.887374]\n",
      "epoch:20 step:15813[D loss: 0.433326, acc: 64.84%, op_acc: 32.81%] [G loss: 0.850697]\n",
      "epoch:20 step:15814[D loss: 0.419341, acc: 55.47%, op_acc: 43.75%] [G loss: 0.846417]\n",
      "epoch:20 step:15815[D loss: 0.425358, acc: 59.38%, op_acc: 35.94%] [G loss: 0.847686]\n",
      "epoch:20 step:15816[D loss: 0.436838, acc: 58.59%, op_acc: 35.16%] [G loss: 0.836874]\n",
      "epoch:20 step:15817[D loss: 0.443977, acc: 53.91%, op_acc: 38.28%] [G loss: 0.916915]\n",
      "epoch:20 step:15818[D loss: 0.434826, acc: 59.38%, op_acc: 36.72%] [G loss: 0.897799]\n",
      "epoch:20 step:15819[D loss: 0.437470, acc: 57.03%, op_acc: 36.72%] [G loss: 0.841994]\n",
      "epoch:20 step:15820[D loss: 0.424988, acc: 56.25%, op_acc: 38.28%] [G loss: 0.847736]\n",
      "epoch:20 step:15821[D loss: 0.435513, acc: 53.12%, op_acc: 34.38%] [G loss: 0.843231]\n",
      "epoch:20 step:15822[D loss: 0.434204, acc: 57.03%, op_acc: 36.72%] [G loss: 0.798708]\n",
      "epoch:20 step:15823[D loss: 0.417990, acc: 64.84%, op_acc: 42.19%] [G loss: 0.830294]\n",
      "epoch:20 step:15824[D loss: 0.413171, acc: 64.84%, op_acc: 39.06%] [G loss: 0.836180]\n",
      "epoch:20 step:15825[D loss: 0.441932, acc: 57.81%, op_acc: 32.81%] [G loss: 0.868671]\n",
      "epoch:20 step:15826[D loss: 0.408283, acc: 57.81%, op_acc: 38.28%] [G loss: 0.854890]\n",
      "epoch:20 step:15827[D loss: 0.405589, acc: 63.28%, op_acc: 43.75%] [G loss: 0.930744]\n",
      "epoch:20 step:15828[D loss: 0.445562, acc: 58.59%, op_acc: 35.94%] [G loss: 0.929991]\n",
      "epoch:20 step:15829[D loss: 0.411760, acc: 60.16%, op_acc: 41.41%] [G loss: 0.922230]\n",
      "epoch:20 step:15830[D loss: 0.429030, acc: 58.59%, op_acc: 32.81%] [G loss: 0.881307]\n",
      "epoch:20 step:15831[D loss: 0.418213, acc: 58.59%, op_acc: 41.41%] [G loss: 0.839469]\n",
      "epoch:20 step:15832[D loss: 0.407141, acc: 66.41%, op_acc: 39.84%] [G loss: 0.923129]\n",
      "epoch:20 step:15833[D loss: 0.433835, acc: 56.25%, op_acc: 37.50%] [G loss: 0.917414]\n",
      "epoch:20 step:15834[D loss: 0.428044, acc: 64.06%, op_acc: 34.38%] [G loss: 0.973027]\n",
      "epoch:20 step:15835[D loss: 0.468725, acc: 52.34%, op_acc: 33.59%] [G loss: 0.894977]\n",
      "epoch:20 step:15836[D loss: 0.422158, acc: 61.72%, op_acc: 39.84%] [G loss: 0.895211]\n",
      "epoch:20 step:15837[D loss: 0.419491, acc: 58.59%, op_acc: 39.06%] [G loss: 0.957210]\n",
      "epoch:20 step:15838[D loss: 0.429370, acc: 60.94%, op_acc: 39.84%] [G loss: 0.926304]\n",
      "epoch:20 step:15839[D loss: 0.409539, acc: 59.38%, op_acc: 37.50%] [G loss: 0.874015]\n",
      "epoch:20 step:15840[D loss: 0.438174, acc: 57.03%, op_acc: 35.94%] [G loss: 0.879147]\n",
      "epoch:20 step:15841[D loss: 0.424244, acc: 57.81%, op_acc: 39.84%] [G loss: 0.900485]\n",
      "epoch:20 step:15842[D loss: 0.426641, acc: 64.06%, op_acc: 39.06%] [G loss: 0.924353]\n",
      "epoch:20 step:15843[D loss: 0.431118, acc: 57.03%, op_acc: 42.97%] [G loss: 0.816594]\n",
      "epoch:20 step:15844[D loss: 0.407583, acc: 59.38%, op_acc: 37.50%] [G loss: 0.826168]\n",
      "epoch:20 step:15845[D loss: 0.445102, acc: 61.72%, op_acc: 35.94%] [G loss: 0.852308]\n",
      "epoch:20 step:15846[D loss: 0.415909, acc: 63.28%, op_acc: 39.06%] [G loss: 0.853018]\n",
      "epoch:20 step:15847[D loss: 0.432677, acc: 57.03%, op_acc: 36.72%] [G loss: 0.875771]\n",
      "epoch:20 step:15848[D loss: 0.399693, acc: 61.72%, op_acc: 42.97%] [G loss: 0.958868]\n",
      "epoch:20 step:15849[D loss: 0.442540, acc: 53.12%, op_acc: 39.84%] [G loss: 0.972778]\n",
      "epoch:20 step:15850[D loss: 0.431798, acc: 60.94%, op_acc: 37.50%] [G loss: 0.936321]\n",
      "##############\n",
      "[0.84093744 0.85100273 0.82561083 0.79502977 0.79761898 0.85000811\n",
      " 0.89986429 0.83513602 0.81227608 0.85471768]\n",
      "##########\n",
      "epoch:20 step:15851[D loss: 0.413405, acc: 57.03%, op_acc: 42.19%] [G loss: 0.938100]\n",
      "epoch:20 step:15852[D loss: 0.428057, acc: 61.72%, op_acc: 41.41%] [G loss: 0.904670]\n",
      "epoch:20 step:15853[D loss: 0.403272, acc: 64.06%, op_acc: 40.62%] [G loss: 0.893349]\n",
      "epoch:20 step:15854[D loss: 0.432520, acc: 60.16%, op_acc: 35.16%] [G loss: 0.956344]\n",
      "epoch:20 step:15855[D loss: 0.411007, acc: 61.72%, op_acc: 41.41%] [G loss: 0.931857]\n",
      "epoch:20 step:15856[D loss: 0.421033, acc: 61.72%, op_acc: 39.06%] [G loss: 0.903764]\n",
      "epoch:20 step:15857[D loss: 0.422109, acc: 57.03%, op_acc: 39.06%] [G loss: 0.858438]\n",
      "epoch:20 step:15858[D loss: 0.436039, acc: 55.47%, op_acc: 38.28%] [G loss: 0.916866]\n",
      "epoch:20 step:15859[D loss: 0.430763, acc: 57.03%, op_acc: 41.41%] [G loss: 0.855522]\n",
      "epoch:20 step:15860[D loss: 0.470922, acc: 49.22%, op_acc: 33.59%] [G loss: 0.798034]\n",
      "epoch:20 step:15861[D loss: 0.413595, acc: 64.84%, op_acc: 41.41%] [G loss: 0.805001]\n",
      "epoch:20 step:15862[D loss: 0.381138, acc: 71.09%, op_acc: 43.75%] [G loss: 0.838135]\n",
      "epoch:20 step:15863[D loss: 0.418815, acc: 60.16%, op_acc: 43.75%] [G loss: 0.924828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15864[D loss: 0.448282, acc: 53.91%, op_acc: 35.94%] [G loss: 0.829521]\n",
      "epoch:20 step:15865[D loss: 0.425601, acc: 55.47%, op_acc: 41.41%] [G loss: 0.872190]\n",
      "epoch:20 step:15866[D loss: 0.408811, acc: 67.19%, op_acc: 33.59%] [G loss: 0.885714]\n",
      "epoch:20 step:15867[D loss: 0.408670, acc: 60.16%, op_acc: 39.84%] [G loss: 0.839619]\n",
      "epoch:20 step:15868[D loss: 0.420474, acc: 62.50%, op_acc: 39.84%] [G loss: 0.840088]\n",
      "epoch:20 step:15869[D loss: 0.428819, acc: 60.94%, op_acc: 38.28%] [G loss: 0.881681]\n",
      "epoch:20 step:15870[D loss: 0.448358, acc: 59.38%, op_acc: 35.94%] [G loss: 0.873904]\n",
      "epoch:20 step:15871[D loss: 0.423720, acc: 60.16%, op_acc: 42.19%] [G loss: 0.797250]\n",
      "epoch:20 step:15872[D loss: 0.405228, acc: 62.50%, op_acc: 40.62%] [G loss: 0.886674]\n",
      "epoch:20 step:15873[D loss: 0.413596, acc: 63.28%, op_acc: 39.84%] [G loss: 0.863632]\n",
      "epoch:20 step:15874[D loss: 0.451173, acc: 55.47%, op_acc: 34.38%] [G loss: 0.829927]\n",
      "epoch:20 step:15875[D loss: 0.409379, acc: 62.50%, op_acc: 34.38%] [G loss: 0.845921]\n",
      "epoch:20 step:15876[D loss: 0.401806, acc: 64.06%, op_acc: 37.50%] [G loss: 0.882013]\n",
      "epoch:20 step:15877[D loss: 0.459288, acc: 50.00%, op_acc: 30.47%] [G loss: 0.834717]\n",
      "epoch:20 step:15878[D loss: 0.449099, acc: 47.66%, op_acc: 38.28%] [G loss: 0.855562]\n",
      "epoch:20 step:15879[D loss: 0.434758, acc: 60.16%, op_acc: 35.16%] [G loss: 0.866632]\n",
      "epoch:20 step:15880[D loss: 0.422140, acc: 64.06%, op_acc: 40.62%] [G loss: 0.868199]\n",
      "epoch:20 step:15881[D loss: 0.420510, acc: 63.28%, op_acc: 35.94%] [G loss: 0.878330]\n",
      "epoch:20 step:15882[D loss: 0.437162, acc: 58.59%, op_acc: 35.94%] [G loss: 0.947571]\n",
      "epoch:20 step:15883[D loss: 0.444361, acc: 53.12%, op_acc: 42.19%] [G loss: 0.885997]\n",
      "epoch:20 step:15884[D loss: 0.423354, acc: 57.03%, op_acc: 36.72%] [G loss: 0.834344]\n",
      "epoch:20 step:15885[D loss: 0.411764, acc: 57.81%, op_acc: 38.28%] [G loss: 0.803166]\n",
      "epoch:20 step:15886[D loss: 0.415638, acc: 61.72%, op_acc: 36.72%] [G loss: 0.898996]\n",
      "epoch:20 step:15887[D loss: 0.459665, acc: 51.56%, op_acc: 34.38%] [G loss: 0.828361]\n",
      "epoch:20 step:15888[D loss: 0.405450, acc: 62.50%, op_acc: 42.97%] [G loss: 0.850897]\n",
      "epoch:20 step:15889[D loss: 0.412849, acc: 60.94%, op_acc: 41.41%] [G loss: 0.865715]\n",
      "epoch:20 step:15890[D loss: 0.436805, acc: 57.81%, op_acc: 40.62%] [G loss: 0.902905]\n",
      "epoch:20 step:15891[D loss: 0.428294, acc: 60.94%, op_acc: 33.59%] [G loss: 0.892704]\n",
      "epoch:20 step:15892[D loss: 0.405401, acc: 64.84%, op_acc: 38.28%] [G loss: 0.898349]\n",
      "epoch:20 step:15893[D loss: 0.406033, acc: 57.81%, op_acc: 42.19%] [G loss: 0.927993]\n",
      "epoch:20 step:15894[D loss: 0.431391, acc: 59.38%, op_acc: 40.62%] [G loss: 0.760816]\n",
      "epoch:20 step:15895[D loss: 0.442998, acc: 60.16%, op_acc: 35.16%] [G loss: 0.884296]\n",
      "epoch:20 step:15896[D loss: 0.450568, acc: 53.91%, op_acc: 39.84%] [G loss: 0.796179]\n",
      "epoch:20 step:15897[D loss: 0.415464, acc: 63.28%, op_acc: 33.59%] [G loss: 0.901567]\n",
      "epoch:20 step:15898[D loss: 0.434660, acc: 62.50%, op_acc: 38.28%] [G loss: 0.946542]\n",
      "epoch:20 step:15899[D loss: 0.445619, acc: 56.25%, op_acc: 36.72%] [G loss: 0.814072]\n",
      "epoch:20 step:15900[D loss: 0.415479, acc: 58.59%, op_acc: 35.94%] [G loss: 0.765179]\n",
      "##############\n",
      "[0.8640758  0.85991269 0.80216019 0.7980196  0.77216497 0.81104802\n",
      " 0.87402878 0.82094949 0.7990711  0.82855564]\n",
      "##########\n",
      "epoch:20 step:15901[D loss: 0.444646, acc: 60.16%, op_acc: 32.81%] [G loss: 0.851695]\n",
      "epoch:20 step:15902[D loss: 0.439450, acc: 56.25%, op_acc: 38.28%] [G loss: 0.933589]\n",
      "epoch:20 step:15903[D loss: 0.429665, acc: 56.25%, op_acc: 40.62%] [G loss: 0.839013]\n",
      "epoch:20 step:15904[D loss: 0.426637, acc: 62.50%, op_acc: 42.19%] [G loss: 0.866918]\n",
      "epoch:20 step:15905[D loss: 0.423923, acc: 60.94%, op_acc: 37.50%] [G loss: 0.867756]\n",
      "epoch:20 step:15906[D loss: 0.488543, acc: 53.12%, op_acc: 28.91%] [G loss: 0.864945]\n",
      "epoch:20 step:15907[D loss: 0.425200, acc: 56.25%, op_acc: 45.31%] [G loss: 0.905250]\n",
      "epoch:20 step:15908[D loss: 0.427688, acc: 57.03%, op_acc: 42.19%] [G loss: 0.912556]\n",
      "epoch:20 step:15909[D loss: 0.444219, acc: 55.47%, op_acc: 37.50%] [G loss: 0.817634]\n",
      "epoch:20 step:15910[D loss: 0.438893, acc: 56.25%, op_acc: 41.41%] [G loss: 0.914371]\n",
      "epoch:20 step:15911[D loss: 0.434393, acc: 56.25%, op_acc: 41.41%] [G loss: 0.876514]\n",
      "epoch:20 step:15912[D loss: 0.427678, acc: 62.50%, op_acc: 36.72%] [G loss: 0.907016]\n",
      "epoch:20 step:15913[D loss: 0.455777, acc: 46.09%, op_acc: 42.19%] [G loss: 0.789500]\n",
      "epoch:20 step:15914[D loss: 0.430775, acc: 58.59%, op_acc: 35.16%] [G loss: 0.859644]\n",
      "epoch:20 step:15915[D loss: 0.420149, acc: 53.91%, op_acc: 42.97%] [G loss: 0.832435]\n",
      "epoch:20 step:15916[D loss: 0.410166, acc: 62.50%, op_acc: 45.31%] [G loss: 0.955938]\n",
      "epoch:20 step:15917[D loss: 0.418560, acc: 65.62%, op_acc: 35.16%] [G loss: 0.858874]\n",
      "epoch:20 step:15918[D loss: 0.393587, acc: 67.19%, op_acc: 40.62%] [G loss: 0.920590]\n",
      "epoch:20 step:15919[D loss: 0.439139, acc: 57.03%, op_acc: 34.38%] [G loss: 0.878045]\n",
      "epoch:20 step:15920[D loss: 0.445254, acc: 52.34%, op_acc: 41.41%] [G loss: 0.856526]\n",
      "epoch:20 step:15921[D loss: 0.444733, acc: 57.03%, op_acc: 38.28%] [G loss: 0.804078]\n",
      "epoch:20 step:15922[D loss: 0.415342, acc: 59.38%, op_acc: 38.28%] [G loss: 0.874372]\n",
      "epoch:20 step:15923[D loss: 0.428596, acc: 63.28%, op_acc: 44.53%] [G loss: 0.854111]\n",
      "epoch:20 step:15924[D loss: 0.442686, acc: 50.00%, op_acc: 39.06%] [G loss: 0.866907]\n",
      "epoch:20 step:15925[D loss: 0.421012, acc: 60.16%, op_acc: 37.50%] [G loss: 0.885121]\n",
      "epoch:20 step:15926[D loss: 0.472050, acc: 57.03%, op_acc: 35.16%] [G loss: 0.909422]\n",
      "epoch:20 step:15927[D loss: 0.427131, acc: 53.12%, op_acc: 35.16%] [G loss: 0.933260]\n",
      "epoch:20 step:15928[D loss: 0.435460, acc: 60.16%, op_acc: 35.94%] [G loss: 0.961298]\n",
      "epoch:20 step:15929[D loss: 0.484894, acc: 53.12%, op_acc: 31.25%] [G loss: 0.882374]\n",
      "epoch:20 step:15930[D loss: 0.425658, acc: 62.50%, op_acc: 37.50%] [G loss: 0.872845]\n",
      "epoch:20 step:15931[D loss: 0.412993, acc: 64.06%, op_acc: 36.72%] [G loss: 0.893857]\n",
      "epoch:20 step:15932[D loss: 0.457747, acc: 47.66%, op_acc: 39.84%] [G loss: 0.869273]\n",
      "epoch:20 step:15933[D loss: 0.430130, acc: 59.38%, op_acc: 36.72%] [G loss: 0.821078]\n",
      "epoch:20 step:15934[D loss: 0.423883, acc: 58.59%, op_acc: 33.59%] [G loss: 0.888309]\n",
      "epoch:20 step:15935[D loss: 0.457137, acc: 50.78%, op_acc: 35.94%] [G loss: 0.807756]\n",
      "epoch:20 step:15936[D loss: 0.421230, acc: 56.25%, op_acc: 39.06%] [G loss: 0.997066]\n",
      "epoch:20 step:15937[D loss: 0.405240, acc: 64.06%, op_acc: 35.16%] [G loss: 0.897376]\n",
      "epoch:20 step:15938[D loss: 0.458560, acc: 49.22%, op_acc: 34.38%] [G loss: 0.875728]\n",
      "epoch:20 step:15939[D loss: 0.433752, acc: 60.16%, op_acc: 38.28%] [G loss: 0.844754]\n",
      "epoch:20 step:15940[D loss: 0.420348, acc: 60.94%, op_acc: 36.72%] [G loss: 0.881977]\n",
      "epoch:20 step:15941[D loss: 0.454995, acc: 50.78%, op_acc: 35.94%] [G loss: 0.888504]\n",
      "epoch:20 step:15942[D loss: 0.444671, acc: 59.38%, op_acc: 35.94%] [G loss: 0.871396]\n",
      "epoch:20 step:15943[D loss: 0.416106, acc: 65.62%, op_acc: 36.72%] [G loss: 0.869073]\n",
      "epoch:20 step:15944[D loss: 0.421871, acc: 57.81%, op_acc: 39.06%] [G loss: 0.946956]\n",
      "epoch:20 step:15945[D loss: 0.427038, acc: 60.94%, op_acc: 40.62%] [G loss: 0.870368]\n",
      "epoch:20 step:15946[D loss: 0.434807, acc: 51.56%, op_acc: 39.84%] [G loss: 0.800988]\n",
      "epoch:20 step:15947[D loss: 0.420810, acc: 59.38%, op_acc: 33.59%] [G loss: 0.899724]\n",
      "epoch:20 step:15948[D loss: 0.421524, acc: 67.19%, op_acc: 37.50%] [G loss: 0.875328]\n",
      "epoch:20 step:15949[D loss: 0.414085, acc: 60.16%, op_acc: 41.41%] [G loss: 0.862875]\n",
      "epoch:20 step:15950[D loss: 0.426033, acc: 57.03%, op_acc: 42.97%] [G loss: 0.822790]\n",
      "##############\n",
      "[0.86225782 0.88182776 0.85010242 0.82065459 0.79520678 0.81404632\n",
      " 0.88407443 0.82858301 0.8268674  0.82599687]\n",
      "##########\n",
      "epoch:20 step:15951[D loss: 0.417798, acc: 60.16%, op_acc: 37.50%] [G loss: 0.919085]\n",
      "epoch:20 step:15952[D loss: 0.417789, acc: 58.59%, op_acc: 39.06%] [G loss: 0.856034]\n",
      "epoch:20 step:15953[D loss: 0.425426, acc: 64.84%, op_acc: 39.84%] [G loss: 0.909765]\n",
      "epoch:20 step:15954[D loss: 0.409451, acc: 58.59%, op_acc: 34.38%] [G loss: 0.902913]\n",
      "epoch:20 step:15955[D loss: 0.415727, acc: 64.84%, op_acc: 34.38%] [G loss: 0.977712]\n",
      "epoch:20 step:15956[D loss: 0.437898, acc: 57.03%, op_acc: 38.28%] [G loss: 0.933121]\n",
      "epoch:20 step:15957[D loss: 0.445584, acc: 61.72%, op_acc: 33.59%] [G loss: 0.949352]\n",
      "epoch:20 step:15958[D loss: 0.412530, acc: 63.28%, op_acc: 44.53%] [G loss: 0.881800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15959[D loss: 0.432080, acc: 55.47%, op_acc: 42.19%] [G loss: 0.896565]\n",
      "epoch:20 step:15960[D loss: 0.445800, acc: 58.59%, op_acc: 35.16%] [G loss: 0.851424]\n",
      "epoch:20 step:15961[D loss: 0.433805, acc: 61.72%, op_acc: 37.50%] [G loss: 0.901407]\n",
      "epoch:20 step:15962[D loss: 0.441674, acc: 56.25%, op_acc: 36.72%] [G loss: 0.823148]\n",
      "epoch:20 step:15963[D loss: 0.443261, acc: 63.28%, op_acc: 34.38%] [G loss: 0.927005]\n",
      "epoch:20 step:15964[D loss: 0.425035, acc: 60.94%, op_acc: 42.97%] [G loss: 0.910223]\n",
      "epoch:20 step:15965[D loss: 0.415677, acc: 66.41%, op_acc: 36.72%] [G loss: 0.968926]\n",
      "epoch:20 step:15966[D loss: 0.434203, acc: 55.47%, op_acc: 39.06%] [G loss: 0.912223]\n",
      "epoch:20 step:15967[D loss: 0.401282, acc: 70.31%, op_acc: 39.06%] [G loss: 0.850164]\n",
      "epoch:20 step:15968[D loss: 0.410079, acc: 58.59%, op_acc: 37.50%] [G loss: 0.862833]\n",
      "epoch:20 step:15969[D loss: 0.421426, acc: 70.31%, op_acc: 32.81%] [G loss: 0.886462]\n",
      "epoch:20 step:15970[D loss: 0.441226, acc: 61.72%, op_acc: 32.81%] [G loss: 0.937146]\n",
      "epoch:20 step:15971[D loss: 0.450620, acc: 53.12%, op_acc: 40.62%] [G loss: 0.895408]\n",
      "epoch:20 step:15972[D loss: 0.425788, acc: 61.72%, op_acc: 34.38%] [G loss: 0.886372]\n",
      "epoch:20 step:15973[D loss: 0.391784, acc: 68.75%, op_acc: 43.75%] [G loss: 0.888574]\n",
      "epoch:20 step:15974[D loss: 0.437005, acc: 56.25%, op_acc: 37.50%] [G loss: 0.976434]\n",
      "epoch:20 step:15975[D loss: 0.424106, acc: 64.84%, op_acc: 39.06%] [G loss: 0.843581]\n",
      "epoch:20 step:15976[D loss: 0.401568, acc: 65.62%, op_acc: 44.53%] [G loss: 0.888038]\n",
      "epoch:20 step:15977[D loss: 0.406264, acc: 64.84%, op_acc: 35.16%] [G loss: 0.918279]\n",
      "epoch:20 step:15978[D loss: 0.439439, acc: 52.34%, op_acc: 40.62%] [G loss: 0.866318]\n",
      "epoch:20 step:15979[D loss: 0.428066, acc: 52.34%, op_acc: 38.28%] [G loss: 0.860276]\n",
      "epoch:20 step:15980[D loss: 0.399445, acc: 66.41%, op_acc: 41.41%] [G loss: 0.898438]\n",
      "epoch:20 step:15981[D loss: 0.424743, acc: 59.38%, op_acc: 38.28%] [G loss: 0.857723]\n",
      "epoch:20 step:15982[D loss: 0.389873, acc: 66.41%, op_acc: 42.97%] [G loss: 0.857674]\n",
      "epoch:20 step:15983[D loss: 0.419523, acc: 64.06%, op_acc: 44.53%] [G loss: 0.885354]\n",
      "epoch:20 step:15984[D loss: 0.445391, acc: 54.69%, op_acc: 35.94%] [G loss: 0.877001]\n",
      "epoch:20 step:15985[D loss: 0.388874, acc: 65.62%, op_acc: 36.72%] [G loss: 0.936403]\n",
      "epoch:20 step:15986[D loss: 0.426669, acc: 57.03%, op_acc: 38.28%] [G loss: 0.858418]\n",
      "epoch:20 step:15987[D loss: 0.431339, acc: 71.09%, op_acc: 36.72%] [G loss: 0.983353]\n",
      "epoch:20 step:15988[D loss: 0.411500, acc: 63.28%, op_acc: 40.62%] [G loss: 0.908838]\n",
      "epoch:20 step:15989[D loss: 0.426500, acc: 56.25%, op_acc: 36.72%] [G loss: 0.923466]\n",
      "epoch:20 step:15990[D loss: 0.428258, acc: 61.72%, op_acc: 39.06%] [G loss: 0.779373]\n",
      "epoch:20 step:15991[D loss: 0.417869, acc: 56.25%, op_acc: 45.31%] [G loss: 0.887406]\n",
      "epoch:20 step:15992[D loss: 0.412360, acc: 60.94%, op_acc: 42.19%] [G loss: 0.899068]\n",
      "epoch:20 step:15993[D loss: 0.425293, acc: 60.94%, op_acc: 39.84%] [G loss: 0.867545]\n",
      "epoch:20 step:15994[D loss: 0.402496, acc: 67.19%, op_acc: 46.09%] [G loss: 0.863064]\n",
      "epoch:20 step:15995[D loss: 0.414079, acc: 59.38%, op_acc: 38.28%] [G loss: 0.816778]\n",
      "epoch:20 step:15996[D loss: 0.433412, acc: 60.94%, op_acc: 33.59%] [G loss: 0.870690]\n",
      "epoch:20 step:15997[D loss: 0.422824, acc: 55.47%, op_acc: 37.50%] [G loss: 0.816714]\n",
      "epoch:20 step:15998[D loss: 0.433686, acc: 60.16%, op_acc: 32.81%] [G loss: 0.921870]\n",
      "epoch:20 step:15999[D loss: 0.399541, acc: 67.19%, op_acc: 41.41%] [G loss: 0.959230]\n",
      "epoch:20 step:16000[D loss: 0.443909, acc: 59.38%, op_acc: 40.62%] [G loss: 0.789589]\n",
      "##############\n",
      "[0.87079058 0.84802151 0.78990195 0.8311421  0.80303685 0.81925456\n",
      " 0.85798145 0.83348697 0.81713646 0.82830436]\n",
      "##########\n",
      "epoch:20 step:16001[D loss: 0.381870, acc: 74.22%, op_acc: 43.75%] [G loss: 0.996458]\n",
      "epoch:20 step:16002[D loss: 0.415660, acc: 61.72%, op_acc: 38.28%] [G loss: 0.924264]\n",
      "epoch:20 step:16003[D loss: 0.407448, acc: 65.62%, op_acc: 40.62%] [G loss: 0.926589]\n",
      "epoch:20 step:16004[D loss: 0.431622, acc: 60.94%, op_acc: 35.94%] [G loss: 0.859954]\n",
      "epoch:20 step:16005[D loss: 0.436398, acc: 56.25%, op_acc: 39.84%] [G loss: 0.776451]\n",
      "epoch:20 step:16006[D loss: 0.415042, acc: 60.94%, op_acc: 39.06%] [G loss: 0.912505]\n",
      "epoch:20 step:16007[D loss: 0.415935, acc: 58.59%, op_acc: 45.31%] [G loss: 0.874132]\n",
      "epoch:20 step:16008[D loss: 0.430918, acc: 64.06%, op_acc: 35.94%] [G loss: 0.835935]\n",
      "epoch:20 step:16009[D loss: 0.458988, acc: 50.00%, op_acc: 36.72%] [G loss: 0.871907]\n",
      "epoch:20 step:16010[D loss: 0.406178, acc: 63.28%, op_acc: 39.06%] [G loss: 0.897990]\n",
      "epoch:20 step:16011[D loss: 0.427356, acc: 58.59%, op_acc: 39.06%] [G loss: 0.863853]\n",
      "epoch:20 step:16012[D loss: 0.421981, acc: 62.50%, op_acc: 43.75%] [G loss: 0.876361]\n",
      "epoch:20 step:16013[D loss: 0.454651, acc: 50.00%, op_acc: 36.72%] [G loss: 0.873920]\n",
      "epoch:20 step:16014[D loss: 0.430725, acc: 65.62%, op_acc: 34.38%] [G loss: 0.913588]\n",
      "epoch:20 step:16015[D loss: 0.454699, acc: 53.91%, op_acc: 32.81%] [G loss: 0.939535]\n",
      "epoch:20 step:16016[D loss: 0.433951, acc: 57.81%, op_acc: 40.62%] [G loss: 0.908690]\n",
      "epoch:20 step:16017[D loss: 0.428772, acc: 53.12%, op_acc: 39.06%] [G loss: 0.884522]\n",
      "epoch:20 step:16018[D loss: 0.459610, acc: 56.25%, op_acc: 35.94%] [G loss: 0.880157]\n",
      "epoch:20 step:16019[D loss: 0.428186, acc: 62.50%, op_acc: 39.06%] [G loss: 0.930230]\n",
      "epoch:20 step:16020[D loss: 0.415625, acc: 64.06%, op_acc: 44.53%] [G loss: 0.964733]\n",
      "epoch:20 step:16021[D loss: 0.414038, acc: 60.16%, op_acc: 39.84%] [G loss: 0.902922]\n",
      "epoch:20 step:16022[D loss: 0.457953, acc: 46.88%, op_acc: 38.28%] [G loss: 0.868673]\n",
      "epoch:20 step:16023[D loss: 0.442109, acc: 60.94%, op_acc: 35.16%] [G loss: 0.894241]\n",
      "epoch:20 step:16024[D loss: 0.381246, acc: 66.41%, op_acc: 35.94%] [G loss: 0.971340]\n",
      "epoch:20 step:16025[D loss: 0.431880, acc: 62.50%, op_acc: 36.72%] [G loss: 0.916592]\n",
      "epoch:20 step:16026[D loss: 0.421456, acc: 53.91%, op_acc: 46.09%] [G loss: 0.932472]\n",
      "epoch:20 step:16027[D loss: 0.443218, acc: 56.25%, op_acc: 36.72%] [G loss: 0.852334]\n",
      "epoch:20 step:16028[D loss: 0.412983, acc: 61.72%, op_acc: 44.53%] [G loss: 0.919132]\n",
      "epoch:20 step:16029[D loss: 0.413146, acc: 64.06%, op_acc: 42.19%] [G loss: 0.844924]\n",
      "epoch:20 step:16030[D loss: 0.406778, acc: 57.81%, op_acc: 39.84%] [G loss: 0.912539]\n",
      "epoch:20 step:16031[D loss: 0.436229, acc: 53.91%, op_acc: 38.28%] [G loss: 0.925445]\n",
      "epoch:20 step:16032[D loss: 0.436142, acc: 51.56%, op_acc: 39.06%] [G loss: 0.809531]\n",
      "epoch:20 step:16033[D loss: 0.426456, acc: 59.38%, op_acc: 36.72%] [G loss: 0.935428]\n",
      "epoch:20 step:16034[D loss: 0.384576, acc: 66.41%, op_acc: 46.88%] [G loss: 0.931041]\n",
      "epoch:20 step:16035[D loss: 0.418818, acc: 55.47%, op_acc: 38.28%] [G loss: 0.929572]\n",
      "epoch:20 step:16036[D loss: 0.411104, acc: 60.94%, op_acc: 42.19%] [G loss: 0.908821]\n",
      "epoch:20 step:16037[D loss: 0.450483, acc: 52.34%, op_acc: 39.06%] [G loss: 0.855671]\n",
      "epoch:20 step:16038[D loss: 0.408231, acc: 57.81%, op_acc: 40.62%] [G loss: 0.997385]\n",
      "epoch:20 step:16039[D loss: 0.420194, acc: 64.84%, op_acc: 37.50%] [G loss: 0.820913]\n",
      "epoch:20 step:16040[D loss: 0.456438, acc: 53.91%, op_acc: 34.38%] [G loss: 0.891940]\n",
      "epoch:20 step:16041[D loss: 0.448985, acc: 50.78%, op_acc: 41.41%] [G loss: 0.891874]\n",
      "epoch:20 step:16042[D loss: 0.418921, acc: 54.69%, op_acc: 44.53%] [G loss: 0.925132]\n",
      "epoch:20 step:16043[D loss: 0.449133, acc: 53.91%, op_acc: 33.59%] [G loss: 0.840362]\n",
      "epoch:20 step:16044[D loss: 0.414085, acc: 63.28%, op_acc: 37.50%] [G loss: 0.851656]\n",
      "epoch:20 step:16045[D loss: 0.432614, acc: 56.25%, op_acc: 36.72%] [G loss: 0.862624]\n",
      "epoch:20 step:16046[D loss: 0.463211, acc: 48.44%, op_acc: 32.81%] [G loss: 0.872679]\n",
      "epoch:20 step:16047[D loss: 0.441901, acc: 59.38%, op_acc: 37.50%] [G loss: 0.866470]\n",
      "epoch:20 step:16048[D loss: 0.444887, acc: 55.47%, op_acc: 37.50%] [G loss: 0.919112]\n",
      "epoch:20 step:16049[D loss: 0.427141, acc: 53.12%, op_acc: 34.38%] [G loss: 0.917718]\n",
      "epoch:20 step:16050[D loss: 0.417182, acc: 65.62%, op_acc: 39.84%] [G loss: 0.865998]\n",
      "##############\n",
      "[0.86615028 0.86284404 0.83588692 0.79413109 0.78578643 0.82738462\n",
      " 0.88141513 0.81274215 0.80174458 0.83586232]\n",
      "##########\n",
      "epoch:20 step:16051[D loss: 0.437252, acc: 54.69%, op_acc: 39.06%] [G loss: 0.888606]\n",
      "epoch:20 step:16052[D loss: 0.375310, acc: 62.50%, op_acc: 43.75%] [G loss: 0.872559]\n",
      "epoch:20 step:16053[D loss: 0.437228, acc: 54.69%, op_acc: 39.06%] [G loss: 0.849217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16054[D loss: 0.418621, acc: 53.91%, op_acc: 42.19%] [G loss: 0.900578]\n",
      "epoch:20 step:16055[D loss: 0.430666, acc: 53.91%, op_acc: 43.75%] [G loss: 0.875727]\n",
      "epoch:20 step:16056[D loss: 0.463007, acc: 58.59%, op_acc: 32.81%] [G loss: 0.878825]\n",
      "epoch:20 step:16057[D loss: 0.432723, acc: 58.59%, op_acc: 40.62%] [G loss: 0.907453]\n",
      "epoch:20 step:16058[D loss: 0.430589, acc: 59.38%, op_acc: 33.59%] [G loss: 0.826976]\n",
      "epoch:20 step:16059[D loss: 0.413585, acc: 60.94%, op_acc: 44.53%] [G loss: 0.896345]\n",
      "epoch:20 step:16060[D loss: 0.451862, acc: 54.69%, op_acc: 37.50%] [G loss: 0.873786]\n",
      "epoch:20 step:16061[D loss: 0.431387, acc: 56.25%, op_acc: 41.41%] [G loss: 0.885830]\n",
      "epoch:20 step:16062[D loss: 0.398383, acc: 71.09%, op_acc: 35.16%] [G loss: 0.851628]\n",
      "epoch:20 step:16063[D loss: 0.429597, acc: 57.03%, op_acc: 33.59%] [G loss: 0.895363]\n",
      "epoch:20 step:16064[D loss: 0.404079, acc: 57.03%, op_acc: 42.97%] [G loss: 0.884280]\n",
      "epoch:20 step:16065[D loss: 0.425392, acc: 60.94%, op_acc: 36.72%] [G loss: 0.847816]\n",
      "epoch:20 step:16066[D loss: 0.446292, acc: 58.59%, op_acc: 41.41%] [G loss: 0.852845]\n",
      "epoch:20 step:16067[D loss: 0.416825, acc: 66.41%, op_acc: 35.16%] [G loss: 0.925986]\n",
      "epoch:20 step:16068[D loss: 0.423741, acc: 62.50%, op_acc: 38.28%] [G loss: 0.864515]\n",
      "epoch:20 step:16069[D loss: 0.429882, acc: 61.72%, op_acc: 32.81%] [G loss: 0.914643]\n",
      "epoch:20 step:16070[D loss: 0.414613, acc: 64.84%, op_acc: 37.50%] [G loss: 0.867589]\n",
      "epoch:20 step:16071[D loss: 0.392817, acc: 70.31%, op_acc: 37.50%] [G loss: 0.911050]\n",
      "epoch:20 step:16072[D loss: 0.411468, acc: 63.28%, op_acc: 34.38%] [G loss: 0.872548]\n",
      "epoch:20 step:16073[D loss: 0.416229, acc: 62.50%, op_acc: 42.19%] [G loss: 0.915518]\n",
      "epoch:20 step:16074[D loss: 0.423968, acc: 60.94%, op_acc: 39.06%] [G loss: 0.875851]\n",
      "epoch:20 step:16075[D loss: 0.462789, acc: 53.12%, op_acc: 38.28%] [G loss: 0.861559]\n",
      "epoch:20 step:16076[D loss: 0.420220, acc: 60.16%, op_acc: 41.41%] [G loss: 0.853369]\n",
      "epoch:20 step:16077[D loss: 0.432714, acc: 54.69%, op_acc: 39.06%] [G loss: 0.889799]\n",
      "epoch:20 step:16078[D loss: 0.399844, acc: 64.06%, op_acc: 39.06%] [G loss: 0.964340]\n",
      "epoch:20 step:16079[D loss: 0.384087, acc: 64.06%, op_acc: 45.31%] [G loss: 0.852274]\n",
      "epoch:20 step:16080[D loss: 0.436595, acc: 51.56%, op_acc: 39.06%] [G loss: 0.863232]\n",
      "epoch:20 step:16081[D loss: 0.421153, acc: 64.06%, op_acc: 38.28%] [G loss: 0.886067]\n",
      "epoch:20 step:16082[D loss: 0.443530, acc: 53.12%, op_acc: 37.50%] [G loss: 0.844288]\n",
      "epoch:20 step:16083[D loss: 0.436244, acc: 57.81%, op_acc: 39.84%] [G loss: 0.921185]\n",
      "epoch:20 step:16084[D loss: 0.406231, acc: 64.84%, op_acc: 35.94%] [G loss: 0.879245]\n",
      "epoch:20 step:16085[D loss: 0.432861, acc: 60.16%, op_acc: 39.84%] [G loss: 0.839751]\n",
      "epoch:20 step:16086[D loss: 0.399270, acc: 62.50%, op_acc: 41.41%] [G loss: 0.926555]\n",
      "epoch:20 step:16087[D loss: 0.431678, acc: 61.72%, op_acc: 30.47%] [G loss: 0.896362]\n",
      "epoch:20 step:16088[D loss: 0.414535, acc: 59.38%, op_acc: 38.28%] [G loss: 0.923956]\n",
      "epoch:20 step:16089[D loss: 0.396581, acc: 65.62%, op_acc: 42.19%] [G loss: 0.977625]\n",
      "epoch:20 step:16090[D loss: 0.435316, acc: 55.47%, op_acc: 38.28%] [G loss: 0.833542]\n",
      "epoch:20 step:16091[D loss: 0.460402, acc: 58.59%, op_acc: 34.38%] [G loss: 0.918743]\n",
      "epoch:20 step:16092[D loss: 0.437823, acc: 57.03%, op_acc: 29.69%] [G loss: 0.980313]\n",
      "epoch:20 step:16093[D loss: 0.414853, acc: 57.03%, op_acc: 40.62%] [G loss: 0.914052]\n",
      "epoch:20 step:16094[D loss: 0.441382, acc: 54.69%, op_acc: 39.06%] [G loss: 0.859930]\n",
      "epoch:20 step:16095[D loss: 0.409767, acc: 58.59%, op_acc: 49.22%] [G loss: 0.959665]\n",
      "epoch:20 step:16096[D loss: 0.445140, acc: 53.91%, op_acc: 39.06%] [G loss: 0.844226]\n",
      "epoch:20 step:16097[D loss: 0.440446, acc: 56.25%, op_acc: 39.84%] [G loss: 0.865401]\n",
      "epoch:20 step:16098[D loss: 0.420754, acc: 60.94%, op_acc: 41.41%] [G loss: 0.874558]\n",
      "epoch:20 step:16099[D loss: 0.430089, acc: 58.59%, op_acc: 32.81%] [G loss: 0.928564]\n",
      "epoch:20 step:16100[D loss: 0.463395, acc: 60.94%, op_acc: 32.03%] [G loss: 0.918882]\n",
      "##############\n",
      "[0.86138165 0.85816336 0.81281749 0.80998729 0.81405095 0.82829631\n",
      " 0.90685061 0.82511299 0.81727622 0.82546063]\n",
      "##########\n",
      "epoch:20 step:16101[D loss: 0.450280, acc: 58.59%, op_acc: 31.25%] [G loss: 0.842645]\n",
      "epoch:20 step:16102[D loss: 0.438951, acc: 56.25%, op_acc: 38.28%] [G loss: 0.911672]\n",
      "epoch:20 step:16103[D loss: 0.387434, acc: 70.31%, op_acc: 43.75%] [G loss: 0.927531]\n",
      "epoch:20 step:16104[D loss: 0.415509, acc: 61.72%, op_acc: 40.62%] [G loss: 0.847240]\n",
      "epoch:20 step:16105[D loss: 0.424815, acc: 59.38%, op_acc: 35.16%] [G loss: 0.918004]\n",
      "epoch:20 step:16106[D loss: 0.400913, acc: 63.28%, op_acc: 46.88%] [G loss: 0.906310]\n",
      "epoch:20 step:16107[D loss: 0.441797, acc: 54.69%, op_acc: 40.62%] [G loss: 0.842487]\n",
      "epoch:20 step:16108[D loss: 0.430640, acc: 63.28%, op_acc: 31.25%] [G loss: 0.845598]\n",
      "epoch:20 step:16109[D loss: 0.429583, acc: 57.81%, op_acc: 41.41%] [G loss: 0.846129]\n",
      "epoch:20 step:16110[D loss: 0.415828, acc: 57.03%, op_acc: 38.28%] [G loss: 0.872988]\n",
      "epoch:20 step:16111[D loss: 0.447235, acc: 59.38%, op_acc: 37.50%] [G loss: 0.915887]\n",
      "epoch:20 step:16112[D loss: 0.408175, acc: 60.16%, op_acc: 39.06%] [G loss: 0.865077]\n",
      "epoch:20 step:16113[D loss: 0.415279, acc: 61.72%, op_acc: 35.16%] [G loss: 0.874729]\n",
      "epoch:20 step:16114[D loss: 0.390286, acc: 67.19%, op_acc: 42.97%] [G loss: 0.892994]\n",
      "epoch:20 step:16115[D loss: 0.435781, acc: 60.16%, op_acc: 36.72%] [G loss: 0.866101]\n",
      "epoch:20 step:16116[D loss: 0.430752, acc: 60.94%, op_acc: 37.50%] [G loss: 0.850068]\n",
      "epoch:20 step:16117[D loss: 0.418723, acc: 58.59%, op_acc: 34.38%] [G loss: 0.925474]\n",
      "epoch:20 step:16118[D loss: 0.448517, acc: 57.03%, op_acc: 36.72%] [G loss: 0.838330]\n",
      "epoch:20 step:16119[D loss: 0.442373, acc: 60.16%, op_acc: 36.72%] [G loss: 0.874291]\n",
      "epoch:20 step:16120[D loss: 0.374464, acc: 69.53%, op_acc: 42.97%] [G loss: 0.910044]\n",
      "epoch:20 step:16121[D loss: 0.439451, acc: 58.59%, op_acc: 34.38%] [G loss: 0.924110]\n",
      "epoch:20 step:16122[D loss: 0.420918, acc: 60.16%, op_acc: 39.84%] [G loss: 0.854473]\n",
      "epoch:20 step:16123[D loss: 0.436330, acc: 58.59%, op_acc: 39.06%] [G loss: 0.853589]\n",
      "epoch:20 step:16124[D loss: 0.427679, acc: 53.91%, op_acc: 38.28%] [G loss: 0.946477]\n",
      "epoch:20 step:16125[D loss: 0.421788, acc: 56.25%, op_acc: 40.62%] [G loss: 0.851199]\n",
      "epoch:20 step:16126[D loss: 0.438315, acc: 54.69%, op_acc: 44.53%] [G loss: 0.842171]\n",
      "epoch:20 step:16127[D loss: 0.404491, acc: 56.25%, op_acc: 42.19%] [G loss: 0.961572]\n",
      "epoch:20 step:16128[D loss: 0.431957, acc: 57.81%, op_acc: 42.97%] [G loss: 0.944704]\n",
      "epoch:20 step:16129[D loss: 0.426866, acc: 56.25%, op_acc: 38.28%] [G loss: 0.943737]\n",
      "epoch:20 step:16130[D loss: 0.435757, acc: 59.38%, op_acc: 42.97%] [G loss: 0.917224]\n",
      "epoch:20 step:16131[D loss: 0.449130, acc: 56.25%, op_acc: 39.84%] [G loss: 0.909089]\n",
      "epoch:20 step:16132[D loss: 0.443459, acc: 54.69%, op_acc: 34.38%] [G loss: 0.898245]\n",
      "epoch:20 step:16133[D loss: 0.419897, acc: 70.31%, op_acc: 38.28%] [G loss: 0.801183]\n",
      "epoch:20 step:16134[D loss: 0.429738, acc: 57.03%, op_acc: 39.06%] [G loss: 0.884825]\n",
      "epoch:20 step:16135[D loss: 0.429828, acc: 57.03%, op_acc: 38.28%] [G loss: 0.829738]\n",
      "epoch:20 step:16136[D loss: 0.450822, acc: 55.47%, op_acc: 35.16%] [G loss: 0.855089]\n",
      "epoch:20 step:16137[D loss: 0.465713, acc: 55.47%, op_acc: 32.81%] [G loss: 0.827664]\n",
      "epoch:20 step:16138[D loss: 0.395989, acc: 64.84%, op_acc: 37.50%] [G loss: 0.909950]\n",
      "epoch:20 step:16139[D loss: 0.402538, acc: 69.53%, op_acc: 42.97%] [G loss: 0.908846]\n",
      "epoch:20 step:16140[D loss: 0.428020, acc: 63.28%, op_acc: 40.62%] [G loss: 0.885180]\n",
      "epoch:20 step:16141[D loss: 0.434411, acc: 60.94%, op_acc: 38.28%] [G loss: 0.909663]\n",
      "epoch:20 step:16142[D loss: 0.456608, acc: 56.25%, op_acc: 34.38%] [G loss: 0.853429]\n",
      "epoch:20 step:16143[D loss: 0.419354, acc: 63.28%, op_acc: 42.19%] [G loss: 0.916047]\n",
      "epoch:20 step:16144[D loss: 0.406456, acc: 71.09%, op_acc: 36.72%] [G loss: 0.882708]\n",
      "epoch:20 step:16145[D loss: 0.430472, acc: 63.28%, op_acc: 34.38%] [G loss: 0.864344]\n",
      "epoch:20 step:16146[D loss: 0.456066, acc: 53.91%, op_acc: 30.47%] [G loss: 0.932397]\n",
      "epoch:20 step:16147[D loss: 0.435313, acc: 57.03%, op_acc: 37.50%] [G loss: 0.896968]\n",
      "epoch:20 step:16148[D loss: 0.420742, acc: 57.81%, op_acc: 39.84%] [G loss: 0.893490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16149[D loss: 0.398575, acc: 65.62%, op_acc: 42.97%] [G loss: 0.861351]\n",
      "epoch:20 step:16150[D loss: 0.433901, acc: 60.16%, op_acc: 42.19%] [G loss: 0.965498]\n",
      "##############\n",
      "[0.83391562 0.86772959 0.81883182 0.80514132 0.78234441 0.81397049\n",
      " 0.89991134 0.80378279 0.81832727 0.83374124]\n",
      "##########\n",
      "epoch:20 step:16151[D loss: 0.427768, acc: 60.94%, op_acc: 32.81%] [G loss: 0.895502]\n",
      "epoch:20 step:16152[D loss: 0.452273, acc: 53.12%, op_acc: 37.50%] [G loss: 0.903728]\n",
      "epoch:20 step:16153[D loss: 0.411530, acc: 62.50%, op_acc: 42.97%] [G loss: 0.892478]\n",
      "epoch:20 step:16154[D loss: 0.438421, acc: 56.25%, op_acc: 43.75%] [G loss: 0.970856]\n",
      "epoch:20 step:16155[D loss: 0.460301, acc: 50.00%, op_acc: 37.50%] [G loss: 0.858852]\n",
      "epoch:20 step:16156[D loss: 0.398395, acc: 62.50%, op_acc: 40.62%] [G loss: 0.918483]\n",
      "epoch:20 step:16157[D loss: 0.452621, acc: 54.69%, op_acc: 31.25%] [G loss: 0.882459]\n",
      "epoch:20 step:16158[D loss: 0.430938, acc: 57.03%, op_acc: 37.50%] [G loss: 0.829688]\n",
      "epoch:20 step:16159[D loss: 0.440300, acc: 57.81%, op_acc: 32.03%] [G loss: 0.881649]\n",
      "epoch:20 step:16160[D loss: 0.433547, acc: 55.47%, op_acc: 38.28%] [G loss: 0.880133]\n",
      "epoch:20 step:16161[D loss: 0.415358, acc: 54.69%, op_acc: 39.06%] [G loss: 0.864603]\n",
      "epoch:20 step:16162[D loss: 0.438351, acc: 60.94%, op_acc: 36.72%] [G loss: 0.946770]\n",
      "epoch:20 step:16163[D loss: 0.432938, acc: 57.03%, op_acc: 39.84%] [G loss: 0.961976]\n",
      "epoch:20 step:16164[D loss: 0.402323, acc: 61.72%, op_acc: 45.31%] [G loss: 0.918852]\n",
      "epoch:20 step:16165[D loss: 0.423310, acc: 57.81%, op_acc: 39.06%] [G loss: 0.823602]\n",
      "epoch:20 step:16166[D loss: 0.441601, acc: 50.78%, op_acc: 34.38%] [G loss: 0.879789]\n",
      "epoch:20 step:16167[D loss: 0.436371, acc: 54.69%, op_acc: 39.84%] [G loss: 0.995067]\n",
      "epoch:20 step:16168[D loss: 0.409071, acc: 58.59%, op_acc: 39.84%] [G loss: 0.792304]\n",
      "epoch:20 step:16169[D loss: 0.434543, acc: 53.12%, op_acc: 44.53%] [G loss: 0.865904]\n",
      "epoch:20 step:16170[D loss: 0.399908, acc: 64.84%, op_acc: 46.09%] [G loss: 0.885455]\n",
      "epoch:20 step:16171[D loss: 0.443007, acc: 56.25%, op_acc: 41.41%] [G loss: 0.826725]\n",
      "epoch:20 step:16172[D loss: 0.449259, acc: 53.12%, op_acc: 37.50%] [G loss: 0.881222]\n",
      "epoch:20 step:16173[D loss: 0.413099, acc: 61.72%, op_acc: 44.53%] [G loss: 0.875007]\n",
      "epoch:20 step:16174[D loss: 0.406558, acc: 63.28%, op_acc: 41.41%] [G loss: 0.818592]\n",
      "epoch:20 step:16175[D loss: 0.409412, acc: 55.47%, op_acc: 39.84%] [G loss: 0.860212]\n",
      "epoch:20 step:16176[D loss: 0.423270, acc: 53.91%, op_acc: 42.97%] [G loss: 0.836711]\n",
      "epoch:20 step:16177[D loss: 0.459787, acc: 46.88%, op_acc: 35.94%] [G loss: 0.842696]\n",
      "epoch:20 step:16178[D loss: 0.402954, acc: 61.72%, op_acc: 43.75%] [G loss: 0.873988]\n",
      "epoch:20 step:16179[D loss: 0.381307, acc: 67.19%, op_acc: 39.06%] [G loss: 0.883779]\n",
      "epoch:20 step:16180[D loss: 0.437275, acc: 61.72%, op_acc: 38.28%] [G loss: 0.857234]\n",
      "epoch:20 step:16181[D loss: 0.420437, acc: 60.16%, op_acc: 39.84%] [G loss: 0.814677]\n",
      "epoch:20 step:16182[D loss: 0.451886, acc: 57.81%, op_acc: 38.28%] [G loss: 0.895852]\n",
      "epoch:20 step:16183[D loss: 0.422578, acc: 59.38%, op_acc: 34.38%] [G loss: 0.854557]\n",
      "epoch:20 step:16184[D loss: 0.398322, acc: 66.41%, op_acc: 40.62%] [G loss: 0.863908]\n",
      "epoch:20 step:16185[D loss: 0.430296, acc: 60.94%, op_acc: 41.41%] [G loss: 0.901045]\n",
      "epoch:20 step:16186[D loss: 0.421757, acc: 63.28%, op_acc: 39.06%] [G loss: 0.923220]\n",
      "epoch:20 step:16187[D loss: 0.405351, acc: 63.28%, op_acc: 42.19%] [G loss: 0.923797]\n",
      "epoch:20 step:16188[D loss: 0.416267, acc: 61.72%, op_acc: 45.31%] [G loss: 0.882185]\n",
      "epoch:20 step:16189[D loss: 0.414897, acc: 61.72%, op_acc: 39.06%] [G loss: 0.917763]\n",
      "epoch:20 step:16190[D loss: 0.425498, acc: 59.38%, op_acc: 37.50%] [G loss: 0.952699]\n",
      "epoch:20 step:16191[D loss: 0.421214, acc: 60.94%, op_acc: 40.62%] [G loss: 0.793850]\n",
      "epoch:20 step:16192[D loss: 0.447228, acc: 46.88%, op_acc: 39.84%] [G loss: 0.822188]\n",
      "epoch:20 step:16193[D loss: 0.428519, acc: 60.94%, op_acc: 40.62%] [G loss: 0.846390]\n",
      "epoch:20 step:16194[D loss: 0.431862, acc: 60.16%, op_acc: 35.94%] [G loss: 0.924317]\n",
      "epoch:20 step:16195[D loss: 0.435966, acc: 51.56%, op_acc: 36.72%] [G loss: 0.904527]\n",
      "epoch:20 step:16196[D loss: 0.395013, acc: 62.50%, op_acc: 44.53%] [G loss: 0.904559]\n",
      "epoch:20 step:16197[D loss: 0.465773, acc: 52.34%, op_acc: 35.16%] [G loss: 0.852179]\n",
      "epoch:20 step:16198[D loss: 0.439893, acc: 55.47%, op_acc: 39.06%] [G loss: 0.894384]\n",
      "epoch:20 step:16199[D loss: 0.426801, acc: 58.59%, op_acc: 38.28%] [G loss: 0.910429]\n",
      "epoch:20 step:16200[D loss: 0.400810, acc: 65.62%, op_acc: 44.53%] [G loss: 0.875069]\n",
      "##############\n",
      "[0.86399359 0.84702954 0.81239218 0.80827218 0.81214826 0.81408036\n",
      " 0.87532825 0.8592887  0.79099194 0.8138692 ]\n",
      "##########\n",
      "epoch:20 step:16201[D loss: 0.425197, acc: 62.50%, op_acc: 39.84%] [G loss: 0.949989]\n",
      "epoch:20 step:16202[D loss: 0.425669, acc: 59.38%, op_acc: 36.72%] [G loss: 0.889267]\n",
      "epoch:20 step:16203[D loss: 0.442060, acc: 58.59%, op_acc: 35.94%] [G loss: 0.875062]\n",
      "epoch:20 step:16204[D loss: 0.432337, acc: 58.59%, op_acc: 33.59%] [G loss: 0.937382]\n",
      "epoch:20 step:16205[D loss: 0.447183, acc: 52.34%, op_acc: 40.62%] [G loss: 0.927610]\n",
      "epoch:20 step:16206[D loss: 0.444876, acc: 57.81%, op_acc: 32.81%] [G loss: 0.896769]\n",
      "epoch:20 step:16207[D loss: 0.404842, acc: 70.31%, op_acc: 35.16%] [G loss: 0.892490]\n",
      "epoch:20 step:16208[D loss: 0.428985, acc: 57.03%, op_acc: 35.16%] [G loss: 0.893529]\n",
      "epoch:20 step:16209[D loss: 0.430729, acc: 60.16%, op_acc: 37.50%] [G loss: 0.916530]\n",
      "epoch:20 step:16210[D loss: 0.406927, acc: 66.41%, op_acc: 40.62%] [G loss: 0.932438]\n",
      "epoch:20 step:16211[D loss: 0.426909, acc: 59.38%, op_acc: 33.59%] [G loss: 0.875494]\n",
      "epoch:20 step:16212[D loss: 0.415774, acc: 60.16%, op_acc: 42.19%] [G loss: 0.931034]\n",
      "epoch:20 step:16213[D loss: 0.413975, acc: 61.72%, op_acc: 35.94%] [G loss: 0.895326]\n",
      "epoch:20 step:16214[D loss: 0.409205, acc: 66.41%, op_acc: 35.94%] [G loss: 0.914070]\n",
      "epoch:20 step:16215[D loss: 0.420922, acc: 63.28%, op_acc: 39.06%] [G loss: 0.883328]\n",
      "epoch:20 step:16216[D loss: 0.459098, acc: 57.03%, op_acc: 35.94%] [G loss: 0.796677]\n",
      "epoch:20 step:16217[D loss: 0.416335, acc: 63.28%, op_acc: 44.53%] [G loss: 0.868550]\n",
      "epoch:20 step:16218[D loss: 0.443233, acc: 50.78%, op_acc: 41.41%] [G loss: 0.894491]\n",
      "epoch:20 step:16219[D loss: 0.418492, acc: 73.44%, op_acc: 35.94%] [G loss: 0.936465]\n",
      "epoch:20 step:16220[D loss: 0.407195, acc: 64.84%, op_acc: 36.72%] [G loss: 0.916113]\n",
      "epoch:20 step:16221[D loss: 0.440140, acc: 60.94%, op_acc: 39.06%] [G loss: 0.911829]\n",
      "epoch:20 step:16222[D loss: 0.413396, acc: 60.94%, op_acc: 39.84%] [G loss: 0.930357]\n",
      "epoch:20 step:16223[D loss: 0.437880, acc: 54.69%, op_acc: 39.84%] [G loss: 0.856349]\n",
      "epoch:20 step:16224[D loss: 0.470436, acc: 54.69%, op_acc: 30.47%] [G loss: 0.800361]\n",
      "epoch:20 step:16225[D loss: 0.418178, acc: 58.59%, op_acc: 39.06%] [G loss: 0.797660]\n",
      "epoch:20 step:16226[D loss: 0.418051, acc: 65.62%, op_acc: 34.38%] [G loss: 0.880599]\n",
      "epoch:20 step:16227[D loss: 0.399430, acc: 67.97%, op_acc: 42.19%] [G loss: 0.872220]\n",
      "epoch:20 step:16228[D loss: 0.393998, acc: 65.62%, op_acc: 40.62%] [G loss: 0.840333]\n",
      "epoch:20 step:16229[D loss: 0.449576, acc: 51.56%, op_acc: 46.09%] [G loss: 0.878520]\n",
      "epoch:20 step:16230[D loss: 0.380105, acc: 70.31%, op_acc: 34.38%] [G loss: 0.856857]\n",
      "epoch:20 step:16231[D loss: 0.442589, acc: 50.78%, op_acc: 39.06%] [G loss: 0.900412]\n",
      "epoch:20 step:16232[D loss: 0.451815, acc: 53.91%, op_acc: 39.84%] [G loss: 0.779326]\n",
      "epoch:20 step:16233[D loss: 0.457632, acc: 44.53%, op_acc: 40.62%] [G loss: 0.803319]\n",
      "epoch:20 step:16234[D loss: 0.393328, acc: 60.16%, op_acc: 40.62%] [G loss: 0.927503]\n",
      "epoch:20 step:16235[D loss: 0.404057, acc: 65.62%, op_acc: 39.84%] [G loss: 0.843782]\n",
      "epoch:20 step:16236[D loss: 0.466022, acc: 49.22%, op_acc: 36.72%] [G loss: 0.843529]\n",
      "epoch:20 step:16237[D loss: 0.434649, acc: 60.16%, op_acc: 37.50%] [G loss: 0.916033]\n",
      "epoch:20 step:16238[D loss: 0.439794, acc: 55.47%, op_acc: 39.06%] [G loss: 0.933332]\n",
      "epoch:20 step:16239[D loss: 0.447055, acc: 61.72%, op_acc: 27.34%] [G loss: 0.962415]\n",
      "epoch:20 step:16240[D loss: 0.430022, acc: 62.50%, op_acc: 36.72%] [G loss: 0.869602]\n",
      "epoch:20 step:16241[D loss: 0.432914, acc: 57.03%, op_acc: 42.19%] [G loss: 0.913147]\n",
      "epoch:20 step:16242[D loss: 0.454456, acc: 57.03%, op_acc: 35.16%] [G loss: 0.922622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16243[D loss: 0.405953, acc: 65.62%, op_acc: 38.28%] [G loss: 0.938742]\n",
      "epoch:20 step:16244[D loss: 0.409114, acc: 60.94%, op_acc: 41.41%] [G loss: 0.905434]\n",
      "epoch:20 step:16245[D loss: 0.462333, acc: 57.03%, op_acc: 38.28%] [G loss: 0.875408]\n",
      "epoch:20 step:16246[D loss: 0.404343, acc: 67.19%, op_acc: 38.28%] [G loss: 0.973854]\n",
      "epoch:20 step:16247[D loss: 0.425828, acc: 57.81%, op_acc: 36.72%] [G loss: 0.849528]\n",
      "epoch:20 step:16248[D loss: 0.421494, acc: 58.59%, op_acc: 39.84%] [G loss: 0.885245]\n",
      "epoch:20 step:16249[D loss: 0.417961, acc: 66.41%, op_acc: 34.38%] [G loss: 1.005174]\n",
      "epoch:20 step:16250[D loss: 0.442839, acc: 52.34%, op_acc: 33.59%] [G loss: 0.882259]\n",
      "##############\n",
      "[0.86278841 0.83294127 0.82018912 0.8083969  0.79026291 0.81023737\n",
      " 0.87406292 0.8284756  0.80498464 0.80524356]\n",
      "##########\n",
      "epoch:20 step:16251[D loss: 0.466451, acc: 46.09%, op_acc: 35.16%] [G loss: 0.852582]\n",
      "epoch:20 step:16252[D loss: 0.435048, acc: 58.59%, op_acc: 38.28%] [G loss: 0.943010]\n",
      "epoch:20 step:16253[D loss: 0.421893, acc: 64.06%, op_acc: 38.28%] [G loss: 0.882398]\n",
      "epoch:20 step:16254[D loss: 0.427663, acc: 57.03%, op_acc: 41.41%] [G loss: 0.868824]\n",
      "epoch:20 step:16255[D loss: 0.469706, acc: 50.00%, op_acc: 28.91%] [G loss: 0.808094]\n",
      "epoch:20 step:16256[D loss: 0.447223, acc: 47.66%, op_acc: 40.62%] [G loss: 0.869341]\n",
      "epoch:20 step:16257[D loss: 0.414912, acc: 68.75%, op_acc: 37.50%] [G loss: 0.928094]\n",
      "epoch:20 step:16258[D loss: 0.418957, acc: 66.41%, op_acc: 35.16%] [G loss: 0.884739]\n",
      "epoch:20 step:16259[D loss: 0.439286, acc: 59.38%, op_acc: 42.97%] [G loss: 0.888375]\n",
      "epoch:20 step:16260[D loss: 0.418508, acc: 64.06%, op_acc: 40.62%] [G loss: 0.946246]\n",
      "epoch:20 step:16261[D loss: 0.439077, acc: 62.50%, op_acc: 35.16%] [G loss: 0.882192]\n",
      "epoch:20 step:16262[D loss: 0.442241, acc: 57.03%, op_acc: 38.28%] [G loss: 0.887642]\n",
      "epoch:20 step:16263[D loss: 0.450732, acc: 52.34%, op_acc: 32.81%] [G loss: 0.934319]\n",
      "epoch:20 step:16264[D loss: 0.393127, acc: 64.06%, op_acc: 45.31%] [G loss: 0.919684]\n",
      "epoch:20 step:16265[D loss: 0.426927, acc: 60.94%, op_acc: 38.28%] [G loss: 0.896324]\n",
      "epoch:20 step:16266[D loss: 0.421577, acc: 64.84%, op_acc: 37.50%] [G loss: 0.860715]\n",
      "epoch:20 step:16267[D loss: 0.402100, acc: 63.28%, op_acc: 42.19%] [G loss: 0.888062]\n",
      "epoch:20 step:16268[D loss: 0.457649, acc: 58.59%, op_acc: 29.69%] [G loss: 0.869869]\n",
      "epoch:20 step:16269[D loss: 0.439724, acc: 60.16%, op_acc: 38.28%] [G loss: 0.764018]\n",
      "epoch:20 step:16270[D loss: 0.434164, acc: 59.38%, op_acc: 39.06%] [G loss: 0.976905]\n",
      "epoch:20 step:16271[D loss: 0.442251, acc: 51.56%, op_acc: 37.50%] [G loss: 0.983083]\n",
      "epoch:20 step:16272[D loss: 0.404692, acc: 64.84%, op_acc: 39.84%] [G loss: 0.946998]\n",
      "epoch:20 step:16273[D loss: 0.406663, acc: 64.06%, op_acc: 39.84%] [G loss: 0.947860]\n",
      "epoch:20 step:16274[D loss: 0.438455, acc: 55.47%, op_acc: 35.16%] [G loss: 0.825439]\n",
      "epoch:20 step:16275[D loss: 0.423207, acc: 57.81%, op_acc: 36.72%] [G loss: 0.848887]\n",
      "epoch:20 step:16276[D loss: 0.457144, acc: 52.34%, op_acc: 35.16%] [G loss: 0.865056]\n",
      "epoch:20 step:16277[D loss: 0.451341, acc: 51.56%, op_acc: 41.41%] [G loss: 0.845698]\n",
      "epoch:20 step:16278[D loss: 0.463469, acc: 51.56%, op_acc: 32.81%] [G loss: 0.829651]\n",
      "epoch:20 step:16279[D loss: 0.430749, acc: 61.72%, op_acc: 37.50%] [G loss: 0.846932]\n",
      "epoch:20 step:16280[D loss: 0.401118, acc: 66.41%, op_acc: 46.09%] [G loss: 0.885135]\n",
      "epoch:20 step:16281[D loss: 0.442260, acc: 53.91%, op_acc: 37.50%] [G loss: 0.843411]\n",
      "epoch:20 step:16282[D loss: 0.418662, acc: 59.38%, op_acc: 42.97%] [G loss: 0.877142]\n",
      "epoch:20 step:16283[D loss: 0.412705, acc: 60.94%, op_acc: 47.66%] [G loss: 0.959734]\n",
      "epoch:20 step:16284[D loss: 0.431908, acc: 58.59%, op_acc: 37.50%] [G loss: 0.889522]\n",
      "epoch:20 step:16285[D loss: 0.467752, acc: 49.22%, op_acc: 29.69%] [G loss: 0.871273]\n",
      "epoch:20 step:16286[D loss: 0.415690, acc: 67.97%, op_acc: 38.28%] [G loss: 0.878819]\n",
      "epoch:20 step:16287[D loss: 0.409301, acc: 62.50%, op_acc: 46.09%] [G loss: 0.903876]\n",
      "epoch:20 step:16288[D loss: 0.414149, acc: 62.50%, op_acc: 40.62%] [G loss: 0.931811]\n",
      "epoch:20 step:16289[D loss: 0.430322, acc: 57.81%, op_acc: 36.72%] [G loss: 0.889829]\n",
      "epoch:20 step:16290[D loss: 0.421718, acc: 64.06%, op_acc: 40.62%] [G loss: 0.846367]\n",
      "epoch:20 step:16291[D loss: 0.437317, acc: 56.25%, op_acc: 40.62%] [G loss: 0.907709]\n",
      "epoch:20 step:16292[D loss: 0.445219, acc: 57.81%, op_acc: 35.94%] [G loss: 0.879685]\n",
      "epoch:20 step:16293[D loss: 0.414001, acc: 57.81%, op_acc: 40.62%] [G loss: 0.955721]\n",
      "epoch:20 step:16294[D loss: 0.409028, acc: 60.16%, op_acc: 39.84%] [G loss: 0.817211]\n",
      "epoch:20 step:16295[D loss: 0.440825, acc: 49.22%, op_acc: 35.94%] [G loss: 0.835515]\n",
      "epoch:20 step:16296[D loss: 0.439976, acc: 60.94%, op_acc: 34.38%] [G loss: 0.812261]\n",
      "epoch:20 step:16297[D loss: 0.451825, acc: 56.25%, op_acc: 37.50%] [G loss: 0.924532]\n",
      "epoch:20 step:16298[D loss: 0.413504, acc: 63.28%, op_acc: 42.19%] [G loss: 0.892594]\n",
      "epoch:20 step:16299[D loss: 0.410503, acc: 60.16%, op_acc: 42.19%] [G loss: 0.834267]\n",
      "epoch:20 step:16300[D loss: 0.443431, acc: 58.59%, op_acc: 37.50%] [G loss: 0.846782]\n",
      "##############\n",
      "[0.86023777 0.86276457 0.81196049 0.82066048 0.80378969 0.82939945\n",
      " 0.89518173 0.83020524 0.81281186 0.82738872]\n",
      "##########\n",
      "epoch:20 step:16301[D loss: 0.452709, acc: 60.94%, op_acc: 33.59%] [G loss: 0.927523]\n",
      "epoch:20 step:16302[D loss: 0.396633, acc: 55.47%, op_acc: 41.41%] [G loss: 0.819490]\n",
      "epoch:20 step:16303[D loss: 0.415017, acc: 60.16%, op_acc: 40.62%] [G loss: 0.867014]\n",
      "epoch:20 step:16304[D loss: 0.447450, acc: 57.81%, op_acc: 35.94%] [G loss: 0.850478]\n",
      "epoch:20 step:16305[D loss: 0.449854, acc: 55.47%, op_acc: 32.03%] [G loss: 0.851804]\n",
      "epoch:20 step:16306[D loss: 0.457703, acc: 52.34%, op_acc: 37.50%] [G loss: 0.864029]\n",
      "epoch:20 step:16307[D loss: 0.414347, acc: 60.94%, op_acc: 37.50%] [G loss: 0.824475]\n",
      "epoch:20 step:16308[D loss: 0.415260, acc: 60.16%, op_acc: 42.19%] [G loss: 0.895019]\n",
      "epoch:20 step:16309[D loss: 0.437176, acc: 48.44%, op_acc: 42.19%] [G loss: 0.879898]\n",
      "epoch:20 step:16310[D loss: 0.435263, acc: 61.72%, op_acc: 37.50%] [G loss: 0.935646]\n",
      "epoch:20 step:16311[D loss: 0.403340, acc: 66.41%, op_acc: 44.53%] [G loss: 0.843992]\n",
      "epoch:20 step:16312[D loss: 0.432161, acc: 53.91%, op_acc: 40.62%] [G loss: 0.913214]\n",
      "epoch:20 step:16313[D loss: 0.434173, acc: 63.28%, op_acc: 36.72%] [G loss: 0.876781]\n",
      "epoch:20 step:16314[D loss: 0.410891, acc: 60.94%, op_acc: 36.72%] [G loss: 0.877032]\n",
      "epoch:20 step:16315[D loss: 0.427567, acc: 58.59%, op_acc: 38.28%] [G loss: 0.760075]\n",
      "epoch:20 step:16316[D loss: 0.446566, acc: 54.69%, op_acc: 39.84%] [G loss: 0.867085]\n",
      "epoch:20 step:16317[D loss: 0.418379, acc: 59.38%, op_acc: 38.28%] [G loss: 0.922037]\n",
      "epoch:20 step:16318[D loss: 0.438264, acc: 61.72%, op_acc: 38.28%] [G loss: 0.846482]\n",
      "epoch:20 step:16319[D loss: 0.425841, acc: 58.59%, op_acc: 39.06%] [G loss: 0.905386]\n",
      "epoch:20 step:16320[D loss: 0.461704, acc: 56.25%, op_acc: 34.38%] [G loss: 0.838134]\n",
      "epoch:20 step:16321[D loss: 0.422009, acc: 58.59%, op_acc: 40.62%] [G loss: 0.844663]\n",
      "epoch:20 step:16322[D loss: 0.428952, acc: 57.03%, op_acc: 41.41%] [G loss: 0.818546]\n",
      "epoch:20 step:16323[D loss: 0.438886, acc: 57.81%, op_acc: 39.06%] [G loss: 0.935709]\n",
      "epoch:20 step:16324[D loss: 0.405728, acc: 60.16%, op_acc: 42.97%] [G loss: 0.868679]\n",
      "epoch:20 step:16325[D loss: 0.417746, acc: 64.06%, op_acc: 35.94%] [G loss: 0.863767]\n",
      "epoch:20 step:16326[D loss: 0.448603, acc: 53.12%, op_acc: 39.06%] [G loss: 0.759136]\n",
      "epoch:20 step:16327[D loss: 0.413707, acc: 60.16%, op_acc: 34.38%] [G loss: 0.866227]\n",
      "epoch:20 step:16328[D loss: 0.473063, acc: 50.78%, op_acc: 34.38%] [G loss: 0.836251]\n",
      "epoch:20 step:16329[D loss: 0.416592, acc: 60.16%, op_acc: 39.84%] [G loss: 0.807380]\n",
      "epoch:20 step:16330[D loss: 0.392299, acc: 60.16%, op_acc: 40.62%] [G loss: 0.866092]\n",
      "epoch:20 step:16331[D loss: 0.435816, acc: 61.72%, op_acc: 35.16%] [G loss: 0.940833]\n",
      "epoch:20 step:16332[D loss: 0.402558, acc: 61.72%, op_acc: 43.75%] [G loss: 0.954315]\n",
      "epoch:20 step:16333[D loss: 0.434783, acc: 50.00%, op_acc: 41.41%] [G loss: 0.909055]\n",
      "epoch:20 step:16334[D loss: 0.428262, acc: 65.62%, op_acc: 35.94%] [G loss: 0.884928]\n",
      "epoch:20 step:16335[D loss: 0.423940, acc: 58.59%, op_acc: 38.28%] [G loss: 0.847894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16336[D loss: 0.431497, acc: 56.25%, op_acc: 42.19%] [G loss: 0.849045]\n",
      "epoch:20 step:16337[D loss: 0.414406, acc: 60.94%, op_acc: 45.31%] [G loss: 0.886649]\n",
      "epoch:20 step:16338[D loss: 0.422757, acc: 59.38%, op_acc: 41.41%] [G loss: 0.904923]\n",
      "epoch:20 step:16339[D loss: 0.428494, acc: 60.94%, op_acc: 39.06%] [G loss: 0.929818]\n",
      "epoch:20 step:16340[D loss: 0.429859, acc: 59.38%, op_acc: 38.28%] [G loss: 0.838080]\n",
      "epoch:20 step:16341[D loss: 0.411259, acc: 57.81%, op_acc: 40.62%] [G loss: 0.984865]\n",
      "epoch:20 step:16342[D loss: 0.409140, acc: 67.19%, op_acc: 42.19%] [G loss: 0.929571]\n",
      "epoch:20 step:16343[D loss: 0.418724, acc: 61.72%, op_acc: 45.31%] [G loss: 0.887290]\n",
      "epoch:20 step:16344[D loss: 0.450576, acc: 64.84%, op_acc: 31.25%] [G loss: 0.894973]\n",
      "epoch:20 step:16345[D loss: 0.409537, acc: 58.59%, op_acc: 46.09%] [G loss: 0.869686]\n",
      "epoch:20 step:16346[D loss: 0.416926, acc: 63.28%, op_acc: 41.41%] [G loss: 0.953973]\n",
      "epoch:20 step:16347[D loss: 0.427200, acc: 56.25%, op_acc: 35.94%] [G loss: 0.831970]\n",
      "epoch:20 step:16348[D loss: 0.450159, acc: 56.25%, op_acc: 41.41%] [G loss: 0.837664]\n",
      "epoch:20 step:16349[D loss: 0.407956, acc: 60.94%, op_acc: 35.94%] [G loss: 0.856183]\n",
      "epoch:20 step:16350[D loss: 0.453350, acc: 46.88%, op_acc: 33.59%] [G loss: 0.890788]\n",
      "##############\n",
      "[0.859298   0.87330188 0.80006807 0.80508971 0.78703976 0.82606219\n",
      " 0.90570409 0.83152872 0.80152962 0.8159375 ]\n",
      "##########\n",
      "epoch:20 step:16351[D loss: 0.423798, acc: 56.25%, op_acc: 37.50%] [G loss: 0.815427]\n",
      "epoch:20 step:16352[D loss: 0.415049, acc: 60.94%, op_acc: 43.75%] [G loss: 0.842384]\n",
      "epoch:20 step:16353[D loss: 0.420425, acc: 56.25%, op_acc: 38.28%] [G loss: 0.869427]\n",
      "epoch:20 step:16354[D loss: 0.407309, acc: 70.31%, op_acc: 42.19%] [G loss: 0.829557]\n",
      "epoch:20 step:16355[D loss: 0.414844, acc: 65.62%, op_acc: 38.28%] [G loss: 0.875148]\n",
      "epoch:20 step:16356[D loss: 0.419073, acc: 63.28%, op_acc: 39.06%] [G loss: 0.944065]\n",
      "epoch:20 step:16357[D loss: 0.408747, acc: 64.84%, op_acc: 36.72%] [G loss: 0.875889]\n",
      "epoch:20 step:16358[D loss: 0.437218, acc: 64.06%, op_acc: 38.28%] [G loss: 0.880483]\n",
      "epoch:20 step:16359[D loss: 0.433844, acc: 57.81%, op_acc: 37.50%] [G loss: 0.908931]\n",
      "epoch:20 step:16360[D loss: 0.418751, acc: 57.81%, op_acc: 39.06%] [G loss: 0.969647]\n",
      "epoch:20 step:16361[D loss: 0.427330, acc: 59.38%, op_acc: 37.50%] [G loss: 0.861558]\n",
      "epoch:20 step:16362[D loss: 0.419510, acc: 62.50%, op_acc: 40.62%] [G loss: 0.826530]\n",
      "epoch:20 step:16363[D loss: 0.425980, acc: 57.03%, op_acc: 40.62%] [G loss: 0.830403]\n",
      "epoch:20 step:16364[D loss: 0.389720, acc: 63.28%, op_acc: 40.62%] [G loss: 0.990109]\n",
      "epoch:20 step:16365[D loss: 0.423505, acc: 57.81%, op_acc: 39.06%] [G loss: 0.885058]\n",
      "epoch:20 step:16366[D loss: 0.408750, acc: 60.94%, op_acc: 38.28%] [G loss: 0.877393]\n",
      "epoch:20 step:16367[D loss: 0.434305, acc: 55.47%, op_acc: 45.31%] [G loss: 0.897609]\n",
      "epoch:20 step:16368[D loss: 0.449902, acc: 50.00%, op_acc: 36.72%] [G loss: 0.875689]\n",
      "epoch:20 step:16369[D loss: 0.451694, acc: 60.16%, op_acc: 39.06%] [G loss: 0.946116]\n",
      "epoch:20 step:16370[D loss: 0.434704, acc: 57.81%, op_acc: 42.19%] [G loss: 0.870543]\n",
      "epoch:20 step:16371[D loss: 0.424332, acc: 66.41%, op_acc: 37.50%] [G loss: 0.961439]\n",
      "epoch:20 step:16372[D loss: 0.445303, acc: 53.91%, op_acc: 38.28%] [G loss: 0.966538]\n",
      "epoch:20 step:16373[D loss: 0.388798, acc: 66.41%, op_acc: 42.97%] [G loss: 1.035491]\n",
      "epoch:20 step:16374[D loss: 0.425601, acc: 61.72%, op_acc: 41.41%] [G loss: 0.950286]\n",
      "epoch:20 step:16375[D loss: 0.400704, acc: 67.19%, op_acc: 39.84%] [G loss: 0.915045]\n",
      "epoch:20 step:16376[D loss: 0.423100, acc: 57.03%, op_acc: 39.06%] [G loss: 0.799699]\n",
      "epoch:20 step:16377[D loss: 0.426213, acc: 53.91%, op_acc: 39.84%] [G loss: 0.914494]\n",
      "epoch:20 step:16378[D loss: 0.416409, acc: 59.38%, op_acc: 39.84%] [G loss: 0.851533]\n",
      "epoch:20 step:16379[D loss: 0.420004, acc: 66.41%, op_acc: 39.84%] [G loss: 0.845214]\n",
      "epoch:20 step:16380[D loss: 0.431186, acc: 54.69%, op_acc: 42.19%] [G loss: 0.777922]\n",
      "epoch:20 step:16381[D loss: 0.418714, acc: 58.59%, op_acc: 41.41%] [G loss: 0.815064]\n",
      "epoch:20 step:16382[D loss: 0.425952, acc: 59.38%, op_acc: 38.28%] [G loss: 0.896360]\n",
      "epoch:20 step:16383[D loss: 0.444288, acc: 57.81%, op_acc: 37.50%] [G loss: 0.854674]\n",
      "epoch:20 step:16384[D loss: 0.408757, acc: 60.94%, op_acc: 42.97%] [G loss: 0.877820]\n",
      "epoch:20 step:16385[D loss: 0.440775, acc: 59.38%, op_acc: 40.62%] [G loss: 0.797197]\n",
      "epoch:20 step:16386[D loss: 0.411403, acc: 66.41%, op_acc: 38.28%] [G loss: 0.930329]\n",
      "epoch:20 step:16387[D loss: 0.408474, acc: 63.28%, op_acc: 37.50%] [G loss: 0.889939]\n",
      "epoch:20 step:16388[D loss: 0.411575, acc: 66.41%, op_acc: 35.94%] [G loss: 0.898227]\n",
      "epoch:20 step:16389[D loss: 0.398777, acc: 65.62%, op_acc: 41.41%] [G loss: 1.008922]\n",
      "epoch:20 step:16390[D loss: 0.437721, acc: 54.69%, op_acc: 33.59%] [G loss: 0.809759]\n",
      "epoch:20 step:16391[D loss: 0.467714, acc: 55.47%, op_acc: 35.16%] [G loss: 0.865199]\n",
      "epoch:20 step:16392[D loss: 0.459384, acc: 53.91%, op_acc: 38.28%] [G loss: 0.894244]\n",
      "epoch:20 step:16393[D loss: 0.450463, acc: 54.69%, op_acc: 33.59%] [G loss: 0.838303]\n",
      "epoch:20 step:16394[D loss: 0.399977, acc: 67.19%, op_acc: 42.97%] [G loss: 0.859455]\n",
      "epoch:20 step:16395[D loss: 0.463165, acc: 58.59%, op_acc: 39.84%] [G loss: 0.902086]\n",
      "epoch:20 step:16396[D loss: 0.416344, acc: 60.16%, op_acc: 38.28%] [G loss: 0.839333]\n",
      "epoch:20 step:16397[D loss: 0.450092, acc: 53.91%, op_acc: 35.94%] [G loss: 0.930221]\n",
      "epoch:20 step:16398[D loss: 0.421635, acc: 63.28%, op_acc: 42.97%] [G loss: 0.821559]\n",
      "epoch:20 step:16399[D loss: 0.420795, acc: 58.59%, op_acc: 40.62%] [G loss: 0.963813]\n",
      "epoch:20 step:16400[D loss: 0.433738, acc: 56.25%, op_acc: 40.62%] [G loss: 0.886242]\n",
      "##############\n",
      "[0.84595064 0.85647996 0.81135594 0.80147428 0.79360264 0.81114291\n",
      " 0.85279053 0.820504   0.79250759 0.8272328 ]\n",
      "##########\n",
      "epoch:20 step:16401[D loss: 0.413313, acc: 59.38%, op_acc: 42.19%] [G loss: 0.931077]\n",
      "epoch:21 step:16402[D loss: 0.418604, acc: 57.81%, op_acc: 43.75%] [G loss: 0.778868]\n",
      "epoch:21 step:16403[D loss: 0.438073, acc: 52.34%, op_acc: 41.41%] [G loss: 0.853603]\n",
      "epoch:21 step:16404[D loss: 0.413605, acc: 63.28%, op_acc: 35.16%] [G loss: 0.873392]\n",
      "epoch:21 step:16405[D loss: 0.400465, acc: 62.50%, op_acc: 41.41%] [G loss: 0.875042]\n",
      "epoch:21 step:16406[D loss: 0.428472, acc: 55.47%, op_acc: 43.75%] [G loss: 0.845115]\n",
      "epoch:21 step:16407[D loss: 0.438562, acc: 56.25%, op_acc: 39.06%] [G loss: 1.024722]\n",
      "epoch:21 step:16408[D loss: 0.378676, acc: 69.53%, op_acc: 39.84%] [G loss: 0.960086]\n",
      "epoch:21 step:16409[D loss: 0.429385, acc: 53.12%, op_acc: 42.19%] [G loss: 0.858356]\n",
      "epoch:21 step:16410[D loss: 0.426250, acc: 55.47%, op_acc: 37.50%] [G loss: 0.909297]\n",
      "epoch:21 step:16411[D loss: 0.422172, acc: 63.28%, op_acc: 32.81%] [G loss: 0.852098]\n",
      "epoch:21 step:16412[D loss: 0.451100, acc: 52.34%, op_acc: 37.50%] [G loss: 0.813716]\n",
      "epoch:21 step:16413[D loss: 0.438367, acc: 56.25%, op_acc: 39.06%] [G loss: 0.852389]\n",
      "epoch:21 step:16414[D loss: 0.432096, acc: 59.38%, op_acc: 37.50%] [G loss: 0.838420]\n",
      "epoch:21 step:16415[D loss: 0.460115, acc: 54.69%, op_acc: 27.34%] [G loss: 0.900257]\n",
      "epoch:21 step:16416[D loss: 0.414429, acc: 64.84%, op_acc: 35.16%] [G loss: 0.833719]\n",
      "epoch:21 step:16417[D loss: 0.416879, acc: 57.03%, op_acc: 45.31%] [G loss: 0.793163]\n",
      "epoch:21 step:16418[D loss: 0.407771, acc: 64.84%, op_acc: 39.84%] [G loss: 0.888009]\n",
      "epoch:21 step:16419[D loss: 0.421359, acc: 58.59%, op_acc: 39.06%] [G loss: 0.846239]\n",
      "epoch:21 step:16420[D loss: 0.409885, acc: 57.81%, op_acc: 40.62%] [G loss: 0.891849]\n",
      "epoch:21 step:16421[D loss: 0.413714, acc: 55.47%, op_acc: 39.84%] [G loss: 0.772495]\n",
      "epoch:21 step:16422[D loss: 0.446429, acc: 60.16%, op_acc: 38.28%] [G loss: 0.888096]\n",
      "epoch:21 step:16423[D loss: 0.418708, acc: 60.94%, op_acc: 41.41%] [G loss: 0.921085]\n",
      "epoch:21 step:16424[D loss: 0.438055, acc: 54.69%, op_acc: 39.84%] [G loss: 0.898178]\n",
      "epoch:21 step:16425[D loss: 0.435116, acc: 64.84%, op_acc: 38.28%] [G loss: 0.885419]\n",
      "epoch:21 step:16426[D loss: 0.416096, acc: 63.28%, op_acc: 39.84%] [G loss: 0.928319]\n",
      "epoch:21 step:16427[D loss: 0.435906, acc: 59.38%, op_acc: 37.50%] [G loss: 0.845021]\n",
      "epoch:21 step:16428[D loss: 0.412048, acc: 66.41%, op_acc: 40.62%] [G loss: 0.846686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16429[D loss: 0.413838, acc: 58.59%, op_acc: 42.19%] [G loss: 0.864714]\n",
      "epoch:21 step:16430[D loss: 0.412391, acc: 64.06%, op_acc: 40.62%] [G loss: 0.913038]\n",
      "epoch:21 step:16431[D loss: 0.387276, acc: 65.62%, op_acc: 43.75%] [G loss: 0.832772]\n",
      "epoch:21 step:16432[D loss: 0.437166, acc: 61.72%, op_acc: 37.50%] [G loss: 0.848845]\n",
      "epoch:21 step:16433[D loss: 0.432394, acc: 62.50%, op_acc: 42.97%] [G loss: 0.866141]\n",
      "epoch:21 step:16434[D loss: 0.404883, acc: 69.53%, op_acc: 41.41%] [G loss: 0.844946]\n",
      "epoch:21 step:16435[D loss: 0.398294, acc: 58.59%, op_acc: 42.19%] [G loss: 0.925529]\n",
      "epoch:21 step:16436[D loss: 0.419487, acc: 64.06%, op_acc: 40.62%] [G loss: 0.966207]\n",
      "epoch:21 step:16437[D loss: 0.423785, acc: 57.03%, op_acc: 44.53%] [G loss: 0.882924]\n",
      "epoch:21 step:16438[D loss: 0.412104, acc: 62.50%, op_acc: 42.19%] [G loss: 0.858940]\n",
      "epoch:21 step:16439[D loss: 0.417652, acc: 60.16%, op_acc: 39.84%] [G loss: 0.831852]\n",
      "epoch:21 step:16440[D loss: 0.451665, acc: 50.00%, op_acc: 38.28%] [G loss: 0.853367]\n",
      "epoch:21 step:16441[D loss: 0.450520, acc: 49.22%, op_acc: 38.28%] [G loss: 0.871846]\n",
      "epoch:21 step:16442[D loss: 0.430626, acc: 53.12%, op_acc: 40.62%] [G loss: 0.841218]\n",
      "epoch:21 step:16443[D loss: 0.418269, acc: 55.47%, op_acc: 41.41%] [G loss: 0.909546]\n",
      "epoch:21 step:16444[D loss: 0.426238, acc: 58.59%, op_acc: 42.97%] [G loss: 0.976489]\n",
      "epoch:21 step:16445[D loss: 0.445505, acc: 42.97%, op_acc: 36.72%] [G loss: 0.897433]\n",
      "epoch:21 step:16446[D loss: 0.410549, acc: 64.84%, op_acc: 36.72%] [G loss: 0.931878]\n",
      "epoch:21 step:16447[D loss: 0.440066, acc: 60.94%, op_acc: 39.84%] [G loss: 0.843449]\n",
      "epoch:21 step:16448[D loss: 0.458267, acc: 54.69%, op_acc: 39.84%] [G loss: 0.833761]\n",
      "epoch:21 step:16449[D loss: 0.443442, acc: 60.94%, op_acc: 35.16%] [G loss: 0.858907]\n",
      "epoch:21 step:16450[D loss: 0.428412, acc: 62.50%, op_acc: 32.81%] [G loss: 0.886715]\n",
      "##############\n",
      "[0.85862927 0.86090902 0.81412726 0.82411372 0.80863558 0.82692821\n",
      " 0.87752942 0.79655292 0.81118095 0.83112403]\n",
      "##########\n",
      "epoch:21 step:16451[D loss: 0.459792, acc: 49.22%, op_acc: 39.06%] [G loss: 0.852363]\n",
      "epoch:21 step:16452[D loss: 0.394298, acc: 64.84%, op_acc: 39.84%] [G loss: 0.985922]\n",
      "epoch:21 step:16453[D loss: 0.423968, acc: 60.16%, op_acc: 36.72%] [G loss: 0.907414]\n",
      "epoch:21 step:16454[D loss: 0.454168, acc: 48.44%, op_acc: 37.50%] [G loss: 0.871931]\n",
      "epoch:21 step:16455[D loss: 0.477043, acc: 53.91%, op_acc: 35.16%] [G loss: 0.978678]\n",
      "epoch:21 step:16456[D loss: 0.431688, acc: 53.12%, op_acc: 35.94%] [G loss: 0.881416]\n",
      "epoch:21 step:16457[D loss: 0.415196, acc: 60.94%, op_acc: 33.59%] [G loss: 0.866202]\n",
      "epoch:21 step:16458[D loss: 0.443433, acc: 50.00%, op_acc: 35.16%] [G loss: 0.910670]\n",
      "epoch:21 step:16459[D loss: 0.416134, acc: 57.03%, op_acc: 45.31%] [G loss: 0.889458]\n",
      "epoch:21 step:16460[D loss: 0.405816, acc: 57.81%, op_acc: 42.19%] [G loss: 0.797600]\n",
      "epoch:21 step:16461[D loss: 0.431020, acc: 53.12%, op_acc: 38.28%] [G loss: 0.861576]\n",
      "epoch:21 step:16462[D loss: 0.418724, acc: 60.94%, op_acc: 41.41%] [G loss: 0.955056]\n",
      "epoch:21 step:16463[D loss: 0.415720, acc: 57.03%, op_acc: 42.19%] [G loss: 0.879140]\n",
      "epoch:21 step:16464[D loss: 0.437170, acc: 50.78%, op_acc: 41.41%] [G loss: 0.880808]\n",
      "epoch:21 step:16465[D loss: 0.422915, acc: 57.81%, op_acc: 36.72%] [G loss: 0.822250]\n",
      "epoch:21 step:16466[D loss: 0.435699, acc: 53.91%, op_acc: 41.41%] [G loss: 0.879250]\n",
      "epoch:21 step:16467[D loss: 0.414337, acc: 59.38%, op_acc: 44.53%] [G loss: 0.910628]\n",
      "epoch:21 step:16468[D loss: 0.407001, acc: 60.16%, op_acc: 43.75%] [G loss: 0.889995]\n",
      "epoch:21 step:16469[D loss: 0.434235, acc: 57.81%, op_acc: 34.38%] [G loss: 0.938854]\n",
      "epoch:21 step:16470[D loss: 0.419166, acc: 57.81%, op_acc: 39.06%] [G loss: 0.837107]\n",
      "epoch:21 step:16471[D loss: 0.439493, acc: 53.12%, op_acc: 38.28%] [G loss: 0.886147]\n",
      "epoch:21 step:16472[D loss: 0.449087, acc: 64.84%, op_acc: 34.38%] [G loss: 0.900483]\n",
      "epoch:21 step:16473[D loss: 0.402435, acc: 57.81%, op_acc: 42.19%] [G loss: 0.890706]\n",
      "epoch:21 step:16474[D loss: 0.414051, acc: 62.50%, op_acc: 43.75%] [G loss: 0.834128]\n",
      "epoch:21 step:16475[D loss: 0.419546, acc: 59.38%, op_acc: 38.28%] [G loss: 0.837818]\n",
      "epoch:21 step:16476[D loss: 0.414657, acc: 60.16%, op_acc: 40.62%] [G loss: 0.856964]\n",
      "epoch:21 step:16477[D loss: 0.443969, acc: 61.72%, op_acc: 40.62%] [G loss: 0.923643]\n",
      "epoch:21 step:16478[D loss: 0.437824, acc: 53.91%, op_acc: 35.16%] [G loss: 0.869876]\n",
      "epoch:21 step:16479[D loss: 0.428972, acc: 64.06%, op_acc: 30.47%] [G loss: 0.763486]\n",
      "epoch:21 step:16480[D loss: 0.415451, acc: 67.97%, op_acc: 37.50%] [G loss: 0.880112]\n",
      "epoch:21 step:16481[D loss: 0.434401, acc: 63.28%, op_acc: 32.03%] [G loss: 0.839162]\n",
      "epoch:21 step:16482[D loss: 0.460298, acc: 57.81%, op_acc: 34.38%] [G loss: 0.861516]\n",
      "epoch:21 step:16483[D loss: 0.430050, acc: 48.44%, op_acc: 38.28%] [G loss: 0.849632]\n",
      "epoch:21 step:16484[D loss: 0.438547, acc: 61.72%, op_acc: 40.62%] [G loss: 0.851631]\n",
      "epoch:21 step:16485[D loss: 0.421506, acc: 69.53%, op_acc: 32.81%] [G loss: 0.878733]\n",
      "epoch:21 step:16486[D loss: 0.442211, acc: 61.72%, op_acc: 31.25%] [G loss: 0.899330]\n",
      "epoch:21 step:16487[D loss: 0.382699, acc: 71.09%, op_acc: 42.19%] [G loss: 0.911717]\n",
      "epoch:21 step:16488[D loss: 0.442356, acc: 55.47%, op_acc: 36.72%] [G loss: 0.906419]\n",
      "epoch:21 step:16489[D loss: 0.430358, acc: 66.41%, op_acc: 34.38%] [G loss: 0.852273]\n",
      "epoch:21 step:16490[D loss: 0.462275, acc: 51.56%, op_acc: 35.94%] [G loss: 0.927978]\n",
      "epoch:21 step:16491[D loss: 0.416019, acc: 64.06%, op_acc: 39.84%] [G loss: 0.877235]\n",
      "epoch:21 step:16492[D loss: 0.422317, acc: 60.94%, op_acc: 37.50%] [G loss: 0.871450]\n",
      "epoch:21 step:16493[D loss: 0.454782, acc: 56.25%, op_acc: 31.25%] [G loss: 0.918608]\n",
      "epoch:21 step:16494[D loss: 0.401664, acc: 62.50%, op_acc: 39.06%] [G loss: 0.898075]\n",
      "epoch:21 step:16495[D loss: 0.397718, acc: 64.84%, op_acc: 41.41%] [G loss: 0.872259]\n",
      "epoch:21 step:16496[D loss: 0.401298, acc: 66.41%, op_acc: 35.16%] [G loss: 0.881430]\n",
      "epoch:21 step:16497[D loss: 0.441458, acc: 52.34%, op_acc: 35.16%] [G loss: 0.832973]\n",
      "epoch:21 step:16498[D loss: 0.417490, acc: 57.81%, op_acc: 45.31%] [G loss: 0.840463]\n",
      "epoch:21 step:16499[D loss: 0.418204, acc: 62.50%, op_acc: 36.72%] [G loss: 0.847514]\n",
      "epoch:21 step:16500[D loss: 0.410846, acc: 57.03%, op_acc: 42.19%] [G loss: 0.907444]\n",
      "##############\n",
      "[0.84356202 0.86285458 0.80935607 0.80574965 0.81837084 0.82870418\n",
      " 0.90027332 0.83695173 0.7968615  0.84582462]\n",
      "##########\n",
      "epoch:21 step:16501[D loss: 0.413762, acc: 59.38%, op_acc: 39.06%] [G loss: 0.969884]\n",
      "epoch:21 step:16502[D loss: 0.446615, acc: 58.59%, op_acc: 36.72%] [G loss: 0.880868]\n",
      "epoch:21 step:16503[D loss: 0.401012, acc: 65.62%, op_acc: 42.19%] [G loss: 0.983296]\n",
      "epoch:21 step:16504[D loss: 0.416920, acc: 60.94%, op_acc: 42.19%] [G loss: 0.885945]\n",
      "epoch:21 step:16505[D loss: 0.451014, acc: 53.91%, op_acc: 35.16%] [G loss: 0.836445]\n",
      "epoch:21 step:16506[D loss: 0.443088, acc: 57.81%, op_acc: 36.72%] [G loss: 0.950622]\n",
      "epoch:21 step:16507[D loss: 0.445963, acc: 50.00%, op_acc: 39.06%] [G loss: 0.832280]\n",
      "epoch:21 step:16508[D loss: 0.419087, acc: 65.62%, op_acc: 39.84%] [G loss: 0.880573]\n",
      "epoch:21 step:16509[D loss: 0.453301, acc: 53.12%, op_acc: 36.72%] [G loss: 0.901623]\n",
      "epoch:21 step:16510[D loss: 0.439849, acc: 60.16%, op_acc: 36.72%] [G loss: 0.924456]\n",
      "epoch:21 step:16511[D loss: 0.402240, acc: 59.38%, op_acc: 39.84%] [G loss: 0.945337]\n",
      "epoch:21 step:16512[D loss: 0.461804, acc: 53.12%, op_acc: 32.81%] [G loss: 0.915206]\n",
      "epoch:21 step:16513[D loss: 0.411428, acc: 63.28%, op_acc: 47.66%] [G loss: 0.933950]\n",
      "epoch:21 step:16514[D loss: 0.428022, acc: 62.50%, op_acc: 37.50%] [G loss: 0.956175]\n",
      "epoch:21 step:16515[D loss: 0.415205, acc: 58.59%, op_acc: 45.31%] [G loss: 0.909786]\n",
      "epoch:21 step:16516[D loss: 0.393407, acc: 65.62%, op_acc: 40.62%] [G loss: 0.905710]\n",
      "epoch:21 step:16517[D loss: 0.453265, acc: 56.25%, op_acc: 35.16%] [G loss: 0.913987]\n",
      "epoch:21 step:16518[D loss: 0.440573, acc: 52.34%, op_acc: 39.06%] [G loss: 0.966705]\n",
      "epoch:21 step:16519[D loss: 0.443208, acc: 56.25%, op_acc: 41.41%] [G loss: 0.827443]\n",
      "epoch:21 step:16520[D loss: 0.399342, acc: 71.09%, op_acc: 39.84%] [G loss: 0.905458]\n",
      "epoch:21 step:16521[D loss: 0.438809, acc: 57.03%, op_acc: 34.38%] [G loss: 0.869100]\n",
      "epoch:21 step:16522[D loss: 0.448243, acc: 59.38%, op_acc: 36.72%] [G loss: 0.906694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16523[D loss: 0.440201, acc: 50.00%, op_acc: 35.16%] [G loss: 0.865439]\n",
      "epoch:21 step:16524[D loss: 0.452951, acc: 58.59%, op_acc: 33.59%] [G loss: 0.808846]\n",
      "epoch:21 step:16525[D loss: 0.433857, acc: 59.38%, op_acc: 42.97%] [G loss: 0.837478]\n",
      "epoch:21 step:16526[D loss: 0.444407, acc: 56.25%, op_acc: 37.50%] [G loss: 0.862918]\n",
      "epoch:21 step:16527[D loss: 0.438601, acc: 53.12%, op_acc: 42.19%] [G loss: 0.873760]\n",
      "epoch:21 step:16528[D loss: 0.423499, acc: 60.16%, op_acc: 35.94%] [G loss: 0.847604]\n",
      "epoch:21 step:16529[D loss: 0.434370, acc: 57.03%, op_acc: 34.38%] [G loss: 0.856473]\n",
      "epoch:21 step:16530[D loss: 0.443789, acc: 54.69%, op_acc: 35.94%] [G loss: 0.845745]\n",
      "epoch:21 step:16531[D loss: 0.415145, acc: 58.59%, op_acc: 40.62%] [G loss: 0.891834]\n",
      "epoch:21 step:16532[D loss: 0.418949, acc: 57.81%, op_acc: 42.97%] [G loss: 0.867410]\n",
      "epoch:21 step:16533[D loss: 0.404893, acc: 56.25%, op_acc: 46.88%] [G loss: 0.933075]\n",
      "epoch:21 step:16534[D loss: 0.433324, acc: 64.06%, op_acc: 31.25%] [G loss: 0.834857]\n",
      "epoch:21 step:16535[D loss: 0.408445, acc: 62.50%, op_acc: 35.94%] [G loss: 0.880996]\n",
      "epoch:21 step:16536[D loss: 0.436431, acc: 53.91%, op_acc: 37.50%] [G loss: 0.930009]\n",
      "epoch:21 step:16537[D loss: 0.413960, acc: 57.81%, op_acc: 44.53%] [G loss: 0.877404]\n",
      "epoch:21 step:16538[D loss: 0.431734, acc: 63.28%, op_acc: 38.28%] [G loss: 0.906049]\n",
      "epoch:21 step:16539[D loss: 0.416717, acc: 63.28%, op_acc: 39.84%] [G loss: 0.948075]\n",
      "epoch:21 step:16540[D loss: 0.406903, acc: 59.38%, op_acc: 41.41%] [G loss: 0.928840]\n",
      "epoch:21 step:16541[D loss: 0.463821, acc: 50.00%, op_acc: 34.38%] [G loss: 0.915962]\n",
      "epoch:21 step:16542[D loss: 0.440760, acc: 55.47%, op_acc: 33.59%] [G loss: 0.928683]\n",
      "epoch:21 step:16543[D loss: 0.419841, acc: 68.75%, op_acc: 35.94%] [G loss: 0.869577]\n",
      "epoch:21 step:16544[D loss: 0.417181, acc: 57.81%, op_acc: 41.41%] [G loss: 0.862119]\n",
      "epoch:21 step:16545[D loss: 0.443453, acc: 54.69%, op_acc: 32.03%] [G loss: 0.849910]\n",
      "epoch:21 step:16546[D loss: 0.425627, acc: 60.94%, op_acc: 39.06%] [G loss: 0.883416]\n",
      "epoch:21 step:16547[D loss: 0.404665, acc: 67.97%, op_acc: 35.16%] [G loss: 0.940225]\n",
      "epoch:21 step:16548[D loss: 0.421208, acc: 57.81%, op_acc: 40.62%] [G loss: 0.864202]\n",
      "epoch:21 step:16549[D loss: 0.434355, acc: 55.47%, op_acc: 38.28%] [G loss: 0.859072]\n",
      "epoch:21 step:16550[D loss: 0.428068, acc: 54.69%, op_acc: 39.84%] [G loss: 0.921148]\n",
      "##############\n",
      "[0.86479409 0.87113098 0.81011342 0.81068917 0.77709483 0.82059885\n",
      " 0.88498367 0.82283073 0.80714752 0.83016978]\n",
      "##########\n",
      "epoch:21 step:16551[D loss: 0.434230, acc: 54.69%, op_acc: 40.62%] [G loss: 0.882723]\n",
      "epoch:21 step:16552[D loss: 0.443480, acc: 55.47%, op_acc: 35.16%] [G loss: 0.858721]\n",
      "epoch:21 step:16553[D loss: 0.428454, acc: 61.72%, op_acc: 40.62%] [G loss: 0.864032]\n",
      "epoch:21 step:16554[D loss: 0.428053, acc: 61.72%, op_acc: 31.25%] [G loss: 0.827644]\n",
      "epoch:21 step:16555[D loss: 0.402815, acc: 64.06%, op_acc: 39.06%] [G loss: 0.893444]\n",
      "epoch:21 step:16556[D loss: 0.443470, acc: 57.81%, op_acc: 38.28%] [G loss: 0.902980]\n",
      "epoch:21 step:16557[D loss: 0.441414, acc: 57.81%, op_acc: 39.84%] [G loss: 0.865186]\n",
      "epoch:21 step:16558[D loss: 0.397714, acc: 65.62%, op_acc: 37.50%] [G loss: 0.871853]\n",
      "epoch:21 step:16559[D loss: 0.433199, acc: 52.34%, op_acc: 39.84%] [G loss: 0.883344]\n",
      "epoch:21 step:16560[D loss: 0.433957, acc: 57.81%, op_acc: 38.28%] [G loss: 0.827989]\n",
      "epoch:21 step:16561[D loss: 0.413602, acc: 62.50%, op_acc: 35.94%] [G loss: 0.856173]\n",
      "epoch:21 step:16562[D loss: 0.412084, acc: 64.84%, op_acc: 42.97%] [G loss: 0.921964]\n",
      "epoch:21 step:16563[D loss: 0.411620, acc: 62.50%, op_acc: 42.19%] [G loss: 0.885317]\n",
      "epoch:21 step:16564[D loss: 0.426092, acc: 63.28%, op_acc: 38.28%] [G loss: 0.978298]\n",
      "epoch:21 step:16565[D loss: 0.461289, acc: 56.25%, op_acc: 32.03%] [G loss: 0.805819]\n",
      "epoch:21 step:16566[D loss: 0.422817, acc: 55.47%, op_acc: 41.41%] [G loss: 0.951454]\n",
      "epoch:21 step:16567[D loss: 0.461185, acc: 44.53%, op_acc: 37.50%] [G loss: 0.908563]\n",
      "epoch:21 step:16568[D loss: 0.423746, acc: 63.28%, op_acc: 39.84%] [G loss: 0.829465]\n",
      "epoch:21 step:16569[D loss: 0.414980, acc: 57.03%, op_acc: 43.75%] [G loss: 0.994721]\n",
      "epoch:21 step:16570[D loss: 0.434165, acc: 57.03%, op_acc: 35.16%] [G loss: 0.864543]\n",
      "epoch:21 step:16571[D loss: 0.460345, acc: 56.25%, op_acc: 39.06%] [G loss: 0.820926]\n",
      "epoch:21 step:16572[D loss: 0.429520, acc: 60.16%, op_acc: 38.28%] [G loss: 0.830940]\n",
      "epoch:21 step:16573[D loss: 0.419111, acc: 60.94%, op_acc: 42.97%] [G loss: 0.878967]\n",
      "epoch:21 step:16574[D loss: 0.427381, acc: 57.81%, op_acc: 35.16%] [G loss: 0.812097]\n",
      "epoch:21 step:16575[D loss: 0.465286, acc: 56.25%, op_acc: 38.28%] [G loss: 0.863778]\n",
      "epoch:21 step:16576[D loss: 0.414231, acc: 61.72%, op_acc: 39.84%] [G loss: 0.838009]\n",
      "epoch:21 step:16577[D loss: 0.423279, acc: 54.69%, op_acc: 36.72%] [G loss: 0.922246]\n",
      "epoch:21 step:16578[D loss: 0.428813, acc: 51.56%, op_acc: 40.62%] [G loss: 0.896265]\n",
      "epoch:21 step:16579[D loss: 0.451957, acc: 53.12%, op_acc: 32.81%] [G loss: 0.885752]\n",
      "epoch:21 step:16580[D loss: 0.395257, acc: 64.84%, op_acc: 48.44%] [G loss: 0.942102]\n",
      "epoch:21 step:16581[D loss: 0.432366, acc: 60.16%, op_acc: 41.41%] [G loss: 0.883599]\n",
      "epoch:21 step:16582[D loss: 0.400023, acc: 64.84%, op_acc: 41.41%] [G loss: 0.871900]\n",
      "epoch:21 step:16583[D loss: 0.428933, acc: 53.91%, op_acc: 36.72%] [G loss: 0.859230]\n",
      "epoch:21 step:16584[D loss: 0.397952, acc: 59.38%, op_acc: 45.31%] [G loss: 0.928865]\n",
      "epoch:21 step:16585[D loss: 0.413548, acc: 64.06%, op_acc: 42.19%] [G loss: 0.916986]\n",
      "epoch:21 step:16586[D loss: 0.418913, acc: 72.66%, op_acc: 32.81%] [G loss: 0.870494]\n",
      "epoch:21 step:16587[D loss: 0.444088, acc: 57.81%, op_acc: 37.50%] [G loss: 0.876621]\n",
      "epoch:21 step:16588[D loss: 0.416314, acc: 60.94%, op_acc: 39.84%] [G loss: 0.930867]\n",
      "epoch:21 step:16589[D loss: 0.410587, acc: 56.25%, op_acc: 39.06%] [G loss: 0.848095]\n",
      "epoch:21 step:16590[D loss: 0.408576, acc: 66.41%, op_acc: 41.41%] [G loss: 0.911926]\n",
      "epoch:21 step:16591[D loss: 0.429618, acc: 57.81%, op_acc: 39.06%] [G loss: 0.871888]\n",
      "epoch:21 step:16592[D loss: 0.413914, acc: 60.16%, op_acc: 44.53%] [G loss: 0.823444]\n",
      "epoch:21 step:16593[D loss: 0.413102, acc: 57.81%, op_acc: 42.19%] [G loss: 0.873193]\n",
      "epoch:21 step:16594[D loss: 0.451937, acc: 53.91%, op_acc: 35.16%] [G loss: 0.781950]\n",
      "epoch:21 step:16595[D loss: 0.414474, acc: 61.72%, op_acc: 42.19%] [G loss: 0.878096]\n",
      "epoch:21 step:16596[D loss: 0.420315, acc: 56.25%, op_acc: 35.94%] [G loss: 0.812268]\n",
      "epoch:21 step:16597[D loss: 0.433734, acc: 56.25%, op_acc: 39.84%] [G loss: 0.884610]\n",
      "epoch:21 step:16598[D loss: 0.460525, acc: 50.00%, op_acc: 39.06%] [G loss: 0.776505]\n",
      "epoch:21 step:16599[D loss: 0.460690, acc: 54.69%, op_acc: 34.38%] [G loss: 0.737250]\n",
      "epoch:21 step:16600[D loss: 0.427885, acc: 64.06%, op_acc: 37.50%] [G loss: 0.854870]\n",
      "##############\n",
      "[0.86547004 0.84873797 0.82959776 0.81769245 0.7893162  0.81470719\n",
      " 0.90203988 0.82618512 0.81649683 0.81536464]\n",
      "##########\n",
      "epoch:21 step:16601[D loss: 0.405049, acc: 60.16%, op_acc: 46.09%] [G loss: 0.815467]\n",
      "epoch:21 step:16602[D loss: 0.401379, acc: 62.50%, op_acc: 44.53%] [G loss: 0.902183]\n",
      "epoch:21 step:16603[D loss: 0.446525, acc: 51.56%, op_acc: 35.94%] [G loss: 0.811523]\n",
      "epoch:21 step:16604[D loss: 0.422430, acc: 57.03%, op_acc: 38.28%] [G loss: 0.842271]\n",
      "epoch:21 step:16605[D loss: 0.433944, acc: 61.72%, op_acc: 39.06%] [G loss: 0.871168]\n",
      "epoch:21 step:16606[D loss: 0.413295, acc: 62.50%, op_acc: 35.16%] [G loss: 0.892624]\n",
      "epoch:21 step:16607[D loss: 0.437030, acc: 56.25%, op_acc: 39.84%] [G loss: 0.870983]\n",
      "epoch:21 step:16608[D loss: 0.392647, acc: 60.94%, op_acc: 42.97%] [G loss: 0.903968]\n",
      "epoch:21 step:16609[D loss: 0.427894, acc: 60.16%, op_acc: 39.84%] [G loss: 0.862502]\n",
      "epoch:21 step:16610[D loss: 0.412071, acc: 67.19%, op_acc: 42.19%] [G loss: 0.962008]\n",
      "epoch:21 step:16611[D loss: 0.449020, acc: 58.59%, op_acc: 35.16%] [G loss: 0.880847]\n",
      "epoch:21 step:16612[D loss: 0.391490, acc: 63.28%, op_acc: 45.31%] [G loss: 0.832982]\n",
      "epoch:21 step:16613[D loss: 0.437683, acc: 58.59%, op_acc: 40.62%] [G loss: 0.946657]\n",
      "epoch:21 step:16614[D loss: 0.411580, acc: 63.28%, op_acc: 42.19%] [G loss: 0.880250]\n",
      "epoch:21 step:16615[D loss: 0.448544, acc: 60.16%, op_acc: 30.47%] [G loss: 0.908639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16616[D loss: 0.460409, acc: 49.22%, op_acc: 36.72%] [G loss: 0.874411]\n",
      "epoch:21 step:16617[D loss: 0.423029, acc: 66.41%, op_acc: 32.03%] [G loss: 0.866630]\n",
      "epoch:21 step:16618[D loss: 0.415424, acc: 60.94%, op_acc: 39.84%] [G loss: 0.839872]\n",
      "epoch:21 step:16619[D loss: 0.410164, acc: 60.16%, op_acc: 46.88%] [G loss: 0.945401]\n",
      "epoch:21 step:16620[D loss: 0.422704, acc: 61.72%, op_acc: 39.84%] [G loss: 0.936706]\n",
      "epoch:21 step:16621[D loss: 0.421304, acc: 64.06%, op_acc: 33.59%] [G loss: 0.898162]\n",
      "epoch:21 step:16622[D loss: 0.404374, acc: 62.50%, op_acc: 38.28%] [G loss: 0.848767]\n",
      "epoch:21 step:16623[D loss: 0.442737, acc: 53.91%, op_acc: 32.81%] [G loss: 0.903686]\n",
      "epoch:21 step:16624[D loss: 0.442027, acc: 57.81%, op_acc: 34.38%] [G loss: 0.880932]\n",
      "epoch:21 step:16625[D loss: 0.433647, acc: 57.03%, op_acc: 39.84%] [G loss: 0.842145]\n",
      "epoch:21 step:16626[D loss: 0.434757, acc: 60.94%, op_acc: 37.50%] [G loss: 0.982028]\n",
      "epoch:21 step:16627[D loss: 0.445958, acc: 54.69%, op_acc: 39.84%] [G loss: 0.942385]\n",
      "epoch:21 step:16628[D loss: 0.425969, acc: 58.59%, op_acc: 39.84%] [G loss: 0.974236]\n",
      "epoch:21 step:16629[D loss: 0.413736, acc: 56.25%, op_acc: 40.62%] [G loss: 0.879369]\n",
      "epoch:21 step:16630[D loss: 0.435665, acc: 60.16%, op_acc: 37.50%] [G loss: 0.823628]\n",
      "epoch:21 step:16631[D loss: 0.432843, acc: 54.69%, op_acc: 41.41%] [G loss: 0.805390]\n",
      "epoch:21 step:16632[D loss: 0.398862, acc: 64.84%, op_acc: 43.75%] [G loss: 0.936862]\n",
      "epoch:21 step:16633[D loss: 0.451720, acc: 50.78%, op_acc: 42.97%] [G loss: 0.861767]\n",
      "epoch:21 step:16634[D loss: 0.391653, acc: 64.84%, op_acc: 43.75%] [G loss: 0.875913]\n",
      "epoch:21 step:16635[D loss: 0.436651, acc: 60.94%, op_acc: 38.28%] [G loss: 0.865783]\n",
      "epoch:21 step:16636[D loss: 0.415743, acc: 53.91%, op_acc: 41.41%] [G loss: 0.903252]\n",
      "epoch:21 step:16637[D loss: 0.447194, acc: 60.94%, op_acc: 35.94%] [G loss: 0.856308]\n",
      "epoch:21 step:16638[D loss: 0.398393, acc: 67.97%, op_acc: 45.31%] [G loss: 0.916120]\n",
      "epoch:21 step:16639[D loss: 0.468963, acc: 46.09%, op_acc: 42.97%] [G loss: 0.895992]\n",
      "epoch:21 step:16640[D loss: 0.393807, acc: 64.84%, op_acc: 47.66%] [G loss: 0.915496]\n",
      "epoch:21 step:16641[D loss: 0.412946, acc: 59.38%, op_acc: 41.41%] [G loss: 0.849680]\n",
      "epoch:21 step:16642[D loss: 0.466894, acc: 47.66%, op_acc: 35.16%] [G loss: 0.853966]\n",
      "epoch:21 step:16643[D loss: 0.405542, acc: 66.41%, op_acc: 42.97%] [G loss: 0.932627]\n",
      "epoch:21 step:16644[D loss: 0.398976, acc: 65.62%, op_acc: 43.75%] [G loss: 0.934238]\n",
      "epoch:21 step:16645[D loss: 0.440544, acc: 58.59%, op_acc: 40.62%] [G loss: 0.832634]\n",
      "epoch:21 step:16646[D loss: 0.422600, acc: 55.47%, op_acc: 44.53%] [G loss: 0.913966]\n",
      "epoch:21 step:16647[D loss: 0.444895, acc: 64.06%, op_acc: 39.06%] [G loss: 0.869878]\n",
      "epoch:21 step:16648[D loss: 0.412994, acc: 60.94%, op_acc: 42.19%] [G loss: 0.826759]\n",
      "epoch:21 step:16649[D loss: 0.447937, acc: 55.47%, op_acc: 37.50%] [G loss: 0.856265]\n",
      "epoch:21 step:16650[D loss: 0.424173, acc: 64.06%, op_acc: 34.38%] [G loss: 0.931832]\n",
      "##############\n",
      "[0.86311073 0.86768133 0.81545388 0.8014603  0.81024218 0.82520268\n",
      " 0.89724175 0.83674865 0.80789182 0.83823968]\n",
      "##########\n",
      "epoch:21 step:16651[D loss: 0.468037, acc: 55.47%, op_acc: 32.81%] [G loss: 0.884675]\n",
      "epoch:21 step:16652[D loss: 0.410436, acc: 60.94%, op_acc: 43.75%] [G loss: 0.810930]\n",
      "epoch:21 step:16653[D loss: 0.426787, acc: 60.94%, op_acc: 41.41%] [G loss: 0.899263]\n",
      "epoch:21 step:16654[D loss: 0.421886, acc: 60.16%, op_acc: 37.50%] [G loss: 0.887245]\n",
      "epoch:21 step:16655[D loss: 0.428555, acc: 60.16%, op_acc: 38.28%] [G loss: 0.886664]\n",
      "epoch:21 step:16656[D loss: 0.439807, acc: 54.69%, op_acc: 36.72%] [G loss: 0.871571]\n",
      "epoch:21 step:16657[D loss: 0.455359, acc: 49.22%, op_acc: 36.72%] [G loss: 0.861916]\n",
      "epoch:21 step:16658[D loss: 0.450296, acc: 57.81%, op_acc: 34.38%] [G loss: 0.794734]\n",
      "epoch:21 step:16659[D loss: 0.444855, acc: 47.66%, op_acc: 38.28%] [G loss: 0.861723]\n",
      "epoch:21 step:16660[D loss: 0.449809, acc: 56.25%, op_acc: 35.94%] [G loss: 0.843154]\n",
      "epoch:21 step:16661[D loss: 0.443770, acc: 53.91%, op_acc: 33.59%] [G loss: 0.853850]\n",
      "epoch:21 step:16662[D loss: 0.416442, acc: 62.50%, op_acc: 35.94%] [G loss: 0.813872]\n",
      "epoch:21 step:16663[D loss: 0.416785, acc: 61.72%, op_acc: 39.84%] [G loss: 0.922090]\n",
      "epoch:21 step:16664[D loss: 0.404575, acc: 65.62%, op_acc: 39.84%] [G loss: 0.858150]\n",
      "epoch:21 step:16665[D loss: 0.419494, acc: 61.72%, op_acc: 39.84%] [G loss: 0.920310]\n",
      "epoch:21 step:16666[D loss: 0.388385, acc: 64.84%, op_acc: 45.31%] [G loss: 0.831504]\n",
      "epoch:21 step:16667[D loss: 0.426147, acc: 57.03%, op_acc: 42.97%] [G loss: 0.849290]\n",
      "epoch:21 step:16668[D loss: 0.461614, acc: 50.78%, op_acc: 35.94%] [G loss: 0.864151]\n",
      "epoch:21 step:16669[D loss: 0.413981, acc: 60.16%, op_acc: 46.09%] [G loss: 0.876039]\n",
      "epoch:21 step:16670[D loss: 0.424670, acc: 56.25%, op_acc: 38.28%] [G loss: 0.830768]\n",
      "epoch:21 step:16671[D loss: 0.404414, acc: 65.62%, op_acc: 37.50%] [G loss: 1.001949]\n",
      "epoch:21 step:16672[D loss: 0.434443, acc: 62.50%, op_acc: 32.03%] [G loss: 0.889060]\n",
      "epoch:21 step:16673[D loss: 0.421547, acc: 64.06%, op_acc: 39.84%] [G loss: 0.847549]\n",
      "epoch:21 step:16674[D loss: 0.429677, acc: 55.47%, op_acc: 39.06%] [G loss: 0.861030]\n",
      "epoch:21 step:16675[D loss: 0.469555, acc: 46.88%, op_acc: 33.59%] [G loss: 0.844282]\n",
      "epoch:21 step:16676[D loss: 0.441143, acc: 58.59%, op_acc: 41.41%] [G loss: 0.876302]\n",
      "epoch:21 step:16677[D loss: 0.423491, acc: 57.03%, op_acc: 40.62%] [G loss: 0.821086]\n",
      "epoch:21 step:16678[D loss: 0.468647, acc: 52.34%, op_acc: 28.91%] [G loss: 0.841285]\n",
      "epoch:21 step:16679[D loss: 0.474524, acc: 49.22%, op_acc: 36.72%] [G loss: 0.793268]\n",
      "epoch:21 step:16680[D loss: 0.424894, acc: 61.72%, op_acc: 36.72%] [G loss: 0.829292]\n",
      "epoch:21 step:16681[D loss: 0.419756, acc: 61.72%, op_acc: 42.97%] [G loss: 0.906363]\n",
      "epoch:21 step:16682[D loss: 0.435188, acc: 60.94%, op_acc: 38.28%] [G loss: 0.814529]\n",
      "epoch:21 step:16683[D loss: 0.450214, acc: 55.47%, op_acc: 38.28%] [G loss: 0.869926]\n",
      "epoch:21 step:16684[D loss: 0.405559, acc: 59.38%, op_acc: 41.41%] [G loss: 0.864473]\n",
      "epoch:21 step:16685[D loss: 0.449528, acc: 54.69%, op_acc: 35.94%] [G loss: 0.912359]\n",
      "epoch:21 step:16686[D loss: 0.424772, acc: 52.34%, op_acc: 35.16%] [G loss: 0.841708]\n",
      "epoch:21 step:16687[D loss: 0.433789, acc: 60.16%, op_acc: 33.59%] [G loss: 0.829707]\n",
      "epoch:21 step:16688[D loss: 0.457521, acc: 46.09%, op_acc: 38.28%] [G loss: 0.823722]\n",
      "epoch:21 step:16689[D loss: 0.422630, acc: 58.59%, op_acc: 39.06%] [G loss: 0.858957]\n",
      "epoch:21 step:16690[D loss: 0.449256, acc: 60.16%, op_acc: 35.16%] [G loss: 0.907405]\n",
      "epoch:21 step:16691[D loss: 0.386660, acc: 68.75%, op_acc: 42.19%] [G loss: 1.014399]\n",
      "epoch:21 step:16692[D loss: 0.397014, acc: 66.41%, op_acc: 43.75%] [G loss: 0.927799]\n",
      "epoch:21 step:16693[D loss: 0.454896, acc: 56.25%, op_acc: 32.81%] [G loss: 0.977633]\n",
      "epoch:21 step:16694[D loss: 0.427216, acc: 60.16%, op_acc: 39.06%] [G loss: 0.901551]\n",
      "epoch:21 step:16695[D loss: 0.421992, acc: 60.94%, op_acc: 40.62%] [G loss: 0.920566]\n",
      "epoch:21 step:16696[D loss: 0.419373, acc: 59.38%, op_acc: 39.84%] [G loss: 0.820206]\n",
      "epoch:21 step:16697[D loss: 0.420218, acc: 60.16%, op_acc: 42.97%] [G loss: 0.899484]\n",
      "epoch:21 step:16698[D loss: 0.446324, acc: 60.16%, op_acc: 32.03%] [G loss: 0.957659]\n",
      "epoch:21 step:16699[D loss: 0.425267, acc: 60.94%, op_acc: 35.16%] [G loss: 0.919044]\n",
      "epoch:21 step:16700[D loss: 0.433314, acc: 60.16%, op_acc: 36.72%] [G loss: 0.922348]\n",
      "##############\n",
      "[0.85598377 0.86628969 0.81692753 0.81520437 0.79411704 0.82141848\n",
      " 0.8895804  0.80693817 0.80805943 0.81742483]\n",
      "##########\n",
      "epoch:21 step:16701[D loss: 0.432274, acc: 59.38%, op_acc: 34.38%] [G loss: 0.906923]\n",
      "epoch:21 step:16702[D loss: 0.423204, acc: 63.28%, op_acc: 42.19%] [G loss: 0.881586]\n",
      "epoch:21 step:16703[D loss: 0.432856, acc: 54.69%, op_acc: 41.41%] [G loss: 0.865148]\n",
      "epoch:21 step:16704[D loss: 0.431638, acc: 57.81%, op_acc: 35.16%] [G loss: 0.837557]\n",
      "epoch:21 step:16705[D loss: 0.429349, acc: 57.81%, op_acc: 39.84%] [G loss: 0.915636]\n",
      "epoch:21 step:16706[D loss: 0.418311, acc: 64.06%, op_acc: 37.50%] [G loss: 0.933823]\n",
      "epoch:21 step:16707[D loss: 0.438161, acc: 60.16%, op_acc: 32.03%] [G loss: 0.919440]\n",
      "epoch:21 step:16708[D loss: 0.423162, acc: 58.59%, op_acc: 35.94%] [G loss: 0.861032]\n",
      "epoch:21 step:16709[D loss: 0.438575, acc: 53.12%, op_acc: 35.94%] [G loss: 0.968140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16710[D loss: 0.463247, acc: 53.91%, op_acc: 32.81%] [G loss: 0.917417]\n",
      "epoch:21 step:16711[D loss: 0.430654, acc: 57.81%, op_acc: 37.50%] [G loss: 0.898112]\n",
      "epoch:21 step:16712[D loss: 0.428862, acc: 58.59%, op_acc: 33.59%] [G loss: 0.910126]\n",
      "epoch:21 step:16713[D loss: 0.441650, acc: 59.38%, op_acc: 34.38%] [G loss: 0.881446]\n",
      "epoch:21 step:16714[D loss: 0.417652, acc: 65.62%, op_acc: 37.50%] [G loss: 0.935487]\n",
      "epoch:21 step:16715[D loss: 0.444889, acc: 57.03%, op_acc: 30.47%] [G loss: 0.871583]\n",
      "epoch:21 step:16716[D loss: 0.450667, acc: 60.16%, op_acc: 35.16%] [G loss: 0.866024]\n",
      "epoch:21 step:16717[D loss: 0.422486, acc: 55.47%, op_acc: 39.06%] [G loss: 0.827889]\n",
      "epoch:21 step:16718[D loss: 0.420858, acc: 66.41%, op_acc: 39.06%] [G loss: 0.863775]\n",
      "epoch:21 step:16719[D loss: 0.428044, acc: 60.94%, op_acc: 32.03%] [G loss: 0.849901]\n",
      "epoch:21 step:16720[D loss: 0.421634, acc: 56.25%, op_acc: 38.28%] [G loss: 0.824005]\n",
      "epoch:21 step:16721[D loss: 0.411501, acc: 62.50%, op_acc: 38.28%] [G loss: 0.876834]\n",
      "epoch:21 step:16722[D loss: 0.441072, acc: 54.69%, op_acc: 37.50%] [G loss: 0.846746]\n",
      "epoch:21 step:16723[D loss: 0.426531, acc: 57.03%, op_acc: 37.50%] [G loss: 0.898372]\n",
      "epoch:21 step:16724[D loss: 0.436489, acc: 53.12%, op_acc: 39.06%] [G loss: 0.896058]\n",
      "epoch:21 step:16725[D loss: 0.460568, acc: 55.47%, op_acc: 32.03%] [G loss: 0.847401]\n",
      "epoch:21 step:16726[D loss: 0.420518, acc: 64.06%, op_acc: 35.16%] [G loss: 0.878978]\n",
      "epoch:21 step:16727[D loss: 0.432723, acc: 55.47%, op_acc: 37.50%] [G loss: 0.931306]\n",
      "epoch:21 step:16728[D loss: 0.400666, acc: 67.19%, op_acc: 40.62%] [G loss: 0.881135]\n",
      "epoch:21 step:16729[D loss: 0.427918, acc: 64.84%, op_acc: 35.16%] [G loss: 0.840546]\n",
      "epoch:21 step:16730[D loss: 0.418801, acc: 60.16%, op_acc: 40.62%] [G loss: 0.900583]\n",
      "epoch:21 step:16731[D loss: 0.395671, acc: 60.94%, op_acc: 43.75%] [G loss: 0.905926]\n",
      "epoch:21 step:16732[D loss: 0.443393, acc: 64.84%, op_acc: 36.72%] [G loss: 0.892564]\n",
      "epoch:21 step:16733[D loss: 0.431883, acc: 59.38%, op_acc: 39.84%] [G loss: 0.842348]\n",
      "epoch:21 step:16734[D loss: 0.430865, acc: 58.59%, op_acc: 38.28%] [G loss: 0.820265]\n",
      "epoch:21 step:16735[D loss: 0.461150, acc: 50.00%, op_acc: 35.16%] [G loss: 0.802357]\n",
      "epoch:21 step:16736[D loss: 0.445586, acc: 59.38%, op_acc: 34.38%] [G loss: 0.808213]\n",
      "epoch:21 step:16737[D loss: 0.460550, acc: 57.03%, op_acc: 39.06%] [G loss: 0.788719]\n",
      "epoch:21 step:16738[D loss: 0.432842, acc: 60.94%, op_acc: 33.59%] [G loss: 0.829457]\n",
      "epoch:21 step:16739[D loss: 0.412483, acc: 58.59%, op_acc: 43.75%] [G loss: 0.793162]\n",
      "epoch:21 step:16740[D loss: 0.413960, acc: 59.38%, op_acc: 41.41%] [G loss: 0.877302]\n",
      "epoch:21 step:16741[D loss: 0.423493, acc: 58.59%, op_acc: 39.06%] [G loss: 0.879841]\n",
      "epoch:21 step:16742[D loss: 0.437959, acc: 59.38%, op_acc: 35.16%] [G loss: 0.903612]\n",
      "epoch:21 step:16743[D loss: 0.395784, acc: 69.53%, op_acc: 35.94%] [G loss: 0.892001]\n",
      "epoch:21 step:16744[D loss: 0.444578, acc: 56.25%, op_acc: 33.59%] [G loss: 0.912704]\n",
      "epoch:21 step:16745[D loss: 0.424280, acc: 56.25%, op_acc: 40.62%] [G loss: 0.965424]\n",
      "epoch:21 step:16746[D loss: 0.433283, acc: 59.38%, op_acc: 35.94%] [G loss: 0.915292]\n",
      "epoch:21 step:16747[D loss: 0.435209, acc: 58.59%, op_acc: 36.72%] [G loss: 0.866519]\n",
      "epoch:21 step:16748[D loss: 0.427911, acc: 54.69%, op_acc: 41.41%] [G loss: 0.892690]\n",
      "epoch:21 step:16749[D loss: 0.397250, acc: 65.62%, op_acc: 34.38%] [G loss: 0.931475]\n",
      "epoch:21 step:16750[D loss: 0.439155, acc: 51.56%, op_acc: 36.72%] [G loss: 0.904828]\n",
      "##############\n",
      "[0.85039718 0.86317479 0.80283995 0.79381226 0.78206239 0.83104014\n",
      " 0.90613957 0.81754492 0.82377386 0.82291262]\n",
      "##########\n",
      "epoch:21 step:16751[D loss: 0.445737, acc: 58.59%, op_acc: 32.81%] [G loss: 0.865245]\n",
      "epoch:21 step:16752[D loss: 0.433004, acc: 59.38%, op_acc: 36.72%] [G loss: 0.883709]\n",
      "epoch:21 step:16753[D loss: 0.414344, acc: 71.09%, op_acc: 37.50%] [G loss: 0.926600]\n",
      "epoch:21 step:16754[D loss: 0.406971, acc: 57.03%, op_acc: 45.31%] [G loss: 0.881729]\n",
      "epoch:21 step:16755[D loss: 0.408229, acc: 69.53%, op_acc: 39.06%] [G loss: 0.889147]\n",
      "epoch:21 step:16756[D loss: 0.426243, acc: 57.81%, op_acc: 39.84%] [G loss: 0.929363]\n",
      "epoch:21 step:16757[D loss: 0.430413, acc: 54.69%, op_acc: 38.28%] [G loss: 0.808152]\n",
      "epoch:21 step:16758[D loss: 0.428922, acc: 64.06%, op_acc: 34.38%] [G loss: 0.939260]\n",
      "epoch:21 step:16759[D loss: 0.451114, acc: 55.47%, op_acc: 34.38%] [G loss: 0.906856]\n",
      "epoch:21 step:16760[D loss: 0.453123, acc: 54.69%, op_acc: 32.81%] [G loss: 0.876975]\n",
      "epoch:21 step:16761[D loss: 0.432944, acc: 60.94%, op_acc: 39.06%] [G loss: 0.937341]\n",
      "epoch:21 step:16762[D loss: 0.427238, acc: 61.72%, op_acc: 43.75%] [G loss: 0.905105]\n",
      "epoch:21 step:16763[D loss: 0.376437, acc: 69.53%, op_acc: 37.50%] [G loss: 0.933477]\n",
      "epoch:21 step:16764[D loss: 0.437393, acc: 57.03%, op_acc: 39.06%] [G loss: 0.879693]\n",
      "epoch:21 step:16765[D loss: 0.432828, acc: 57.81%, op_acc: 38.28%] [G loss: 0.927679]\n",
      "epoch:21 step:16766[D loss: 0.413173, acc: 61.72%, op_acc: 38.28%] [G loss: 0.916731]\n",
      "epoch:21 step:16767[D loss: 0.411309, acc: 60.94%, op_acc: 44.53%] [G loss: 0.851978]\n",
      "epoch:21 step:16768[D loss: 0.416970, acc: 66.41%, op_acc: 37.50%] [G loss: 0.846815]\n",
      "epoch:21 step:16769[D loss: 0.450093, acc: 53.12%, op_acc: 36.72%] [G loss: 0.841948]\n",
      "epoch:21 step:16770[D loss: 0.411165, acc: 66.41%, op_acc: 36.72%] [G loss: 0.877150]\n",
      "epoch:21 step:16771[D loss: 0.434393, acc: 57.03%, op_acc: 41.41%] [G loss: 0.878082]\n",
      "epoch:21 step:16772[D loss: 0.390237, acc: 65.62%, op_acc: 43.75%] [G loss: 0.864875]\n",
      "epoch:21 step:16773[D loss: 0.418872, acc: 60.16%, op_acc: 37.50%] [G loss: 0.878843]\n",
      "epoch:21 step:16774[D loss: 0.414984, acc: 62.50%, op_acc: 42.97%] [G loss: 0.817215]\n",
      "epoch:21 step:16775[D loss: 0.439514, acc: 54.69%, op_acc: 36.72%] [G loss: 0.887586]\n",
      "epoch:21 step:16776[D loss: 0.413494, acc: 61.72%, op_acc: 34.38%] [G loss: 0.839208]\n",
      "epoch:21 step:16777[D loss: 0.436708, acc: 57.81%, op_acc: 31.25%] [G loss: 0.812037]\n",
      "epoch:21 step:16778[D loss: 0.426255, acc: 60.94%, op_acc: 35.16%] [G loss: 0.908477]\n",
      "epoch:21 step:16779[D loss: 0.397468, acc: 64.84%, op_acc: 42.97%] [G loss: 0.910241]\n",
      "epoch:21 step:16780[D loss: 0.364333, acc: 78.91%, op_acc: 44.53%] [G loss: 0.993247]\n",
      "epoch:21 step:16781[D loss: 0.401923, acc: 66.41%, op_acc: 39.84%] [G loss: 0.868087]\n",
      "epoch:21 step:16782[D loss: 0.408229, acc: 67.97%, op_acc: 39.06%] [G loss: 0.961818]\n",
      "epoch:21 step:16783[D loss: 0.455148, acc: 63.28%, op_acc: 35.16%] [G loss: 0.906771]\n",
      "epoch:21 step:16784[D loss: 0.420766, acc: 59.38%, op_acc: 41.41%] [G loss: 0.980385]\n",
      "epoch:21 step:16785[D loss: 0.423663, acc: 60.16%, op_acc: 41.41%] [G loss: 0.976967]\n",
      "epoch:21 step:16786[D loss: 0.424575, acc: 54.69%, op_acc: 35.94%] [G loss: 0.981054]\n",
      "epoch:21 step:16787[D loss: 0.384404, acc: 65.62%, op_acc: 44.53%] [G loss: 0.946104]\n",
      "epoch:21 step:16788[D loss: 0.438402, acc: 57.81%, op_acc: 35.16%] [G loss: 0.881316]\n",
      "epoch:21 step:16789[D loss: 0.444276, acc: 59.38%, op_acc: 37.50%] [G loss: 0.934610]\n",
      "epoch:21 step:16790[D loss: 0.472176, acc: 46.09%, op_acc: 39.06%] [G loss: 0.863850]\n",
      "epoch:21 step:16791[D loss: 0.423497, acc: 58.59%, op_acc: 38.28%] [G loss: 0.912857]\n",
      "epoch:21 step:16792[D loss: 0.427756, acc: 56.25%, op_acc: 42.97%] [G loss: 0.882170]\n",
      "epoch:21 step:16793[D loss: 0.432884, acc: 57.03%, op_acc: 38.28%] [G loss: 0.880429]\n",
      "epoch:21 step:16794[D loss: 0.410631, acc: 60.16%, op_acc: 40.62%] [G loss: 0.907906]\n",
      "epoch:21 step:16795[D loss: 0.409878, acc: 62.50%, op_acc: 41.41%] [G loss: 0.891769]\n",
      "epoch:21 step:16796[D loss: 0.447218, acc: 58.59%, op_acc: 35.16%] [G loss: 0.942574]\n",
      "epoch:21 step:16797[D loss: 0.412156, acc: 60.94%, op_acc: 42.19%] [G loss: 0.842648]\n",
      "epoch:21 step:16798[D loss: 0.433325, acc: 51.56%, op_acc: 39.06%] [G loss: 0.876273]\n",
      "epoch:21 step:16799[D loss: 0.449432, acc: 53.12%, op_acc: 40.62%] [G loss: 0.863048]\n",
      "epoch:21 step:16800[D loss: 0.427807, acc: 54.69%, op_acc: 40.62%] [G loss: 0.912300]\n",
      "##############\n",
      "[0.85543469 0.8519992  0.80695492 0.80501511 0.79199628 0.82305989\n",
      " 0.9014849  0.82214568 0.81757283 0.83416221]\n",
      "##########\n",
      "epoch:21 step:16801[D loss: 0.411149, acc: 58.59%, op_acc: 39.06%] [G loss: 0.923567]\n",
      "epoch:21 step:16802[D loss: 0.426520, acc: 60.16%, op_acc: 35.94%] [G loss: 0.916238]\n",
      "epoch:21 step:16803[D loss: 0.428495, acc: 60.94%, op_acc: 30.47%] [G loss: 0.962630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16804[D loss: 0.429749, acc: 57.03%, op_acc: 34.38%] [G loss: 0.966677]\n",
      "epoch:21 step:16805[D loss: 0.417056, acc: 60.16%, op_acc: 43.75%] [G loss: 0.980018]\n",
      "epoch:21 step:16806[D loss: 0.419148, acc: 67.97%, op_acc: 41.41%] [G loss: 1.027217]\n",
      "epoch:21 step:16807[D loss: 0.464021, acc: 46.09%, op_acc: 40.62%] [G loss: 0.807997]\n",
      "epoch:21 step:16808[D loss: 0.439704, acc: 51.56%, op_acc: 39.84%] [G loss: 0.843212]\n",
      "epoch:21 step:16809[D loss: 0.406443, acc: 63.28%, op_acc: 42.19%] [G loss: 0.866457]\n",
      "epoch:21 step:16810[D loss: 0.458736, acc: 50.78%, op_acc: 41.41%] [G loss: 0.803464]\n",
      "epoch:21 step:16811[D loss: 0.397824, acc: 59.38%, op_acc: 40.62%] [G loss: 0.857695]\n",
      "epoch:21 step:16812[D loss: 0.446508, acc: 58.59%, op_acc: 36.72%] [G loss: 0.837208]\n",
      "epoch:21 step:16813[D loss: 0.408944, acc: 63.28%, op_acc: 43.75%] [G loss: 0.957486]\n",
      "epoch:21 step:16814[D loss: 0.436109, acc: 55.47%, op_acc: 39.06%] [G loss: 0.862341]\n",
      "epoch:21 step:16815[D loss: 0.396393, acc: 64.84%, op_acc: 40.62%] [G loss: 0.885295]\n",
      "epoch:21 step:16816[D loss: 0.426799, acc: 55.47%, op_acc: 38.28%] [G loss: 0.906797]\n",
      "epoch:21 step:16817[D loss: 0.426701, acc: 61.72%, op_acc: 38.28%] [G loss: 0.908631]\n",
      "epoch:21 step:16818[D loss: 0.412210, acc: 68.75%, op_acc: 36.72%] [G loss: 0.922312]\n",
      "epoch:21 step:16819[D loss: 0.442104, acc: 54.69%, op_acc: 35.94%] [G loss: 0.926192]\n",
      "epoch:21 step:16820[D loss: 0.410854, acc: 59.38%, op_acc: 40.62%] [G loss: 0.993520]\n",
      "epoch:21 step:16821[D loss: 0.464207, acc: 44.53%, op_acc: 38.28%] [G loss: 0.873409]\n",
      "epoch:21 step:16822[D loss: 0.445718, acc: 53.12%, op_acc: 40.62%] [G loss: 0.875415]\n",
      "epoch:21 step:16823[D loss: 0.406942, acc: 60.94%, op_acc: 43.75%] [G loss: 0.923955]\n",
      "epoch:21 step:16824[D loss: 0.411612, acc: 65.62%, op_acc: 35.16%] [G loss: 0.922250]\n",
      "epoch:21 step:16825[D loss: 0.432437, acc: 62.50%, op_acc: 37.50%] [G loss: 0.818634]\n",
      "epoch:21 step:16826[D loss: 0.445742, acc: 51.56%, op_acc: 39.06%] [G loss: 0.880761]\n",
      "epoch:21 step:16827[D loss: 0.443231, acc: 60.94%, op_acc: 34.38%] [G loss: 0.980798]\n",
      "epoch:21 step:16828[D loss: 0.420405, acc: 61.72%, op_acc: 37.50%] [G loss: 0.876724]\n",
      "epoch:21 step:16829[D loss: 0.436121, acc: 58.59%, op_acc: 36.72%] [G loss: 0.925109]\n",
      "epoch:21 step:16830[D loss: 0.438561, acc: 58.59%, op_acc: 37.50%] [G loss: 0.843635]\n",
      "epoch:21 step:16831[D loss: 0.436204, acc: 52.34%, op_acc: 43.75%] [G loss: 0.922476]\n",
      "epoch:21 step:16832[D loss: 0.454336, acc: 57.03%, op_acc: 32.03%] [G loss: 0.849441]\n",
      "epoch:21 step:16833[D loss: 0.417789, acc: 55.47%, op_acc: 40.62%] [G loss: 0.813603]\n",
      "epoch:21 step:16834[D loss: 0.422043, acc: 57.81%, op_acc: 41.41%] [G loss: 0.860590]\n",
      "epoch:21 step:16835[D loss: 0.400119, acc: 61.72%, op_acc: 41.41%] [G loss: 0.894812]\n",
      "epoch:21 step:16836[D loss: 0.437836, acc: 48.44%, op_acc: 43.75%] [G loss: 0.793347]\n",
      "epoch:21 step:16837[D loss: 0.465340, acc: 54.69%, op_acc: 32.81%] [G loss: 0.805813]\n",
      "epoch:21 step:16838[D loss: 0.452484, acc: 61.72%, op_acc: 32.81%] [G loss: 0.925296]\n",
      "epoch:21 step:16839[D loss: 0.443346, acc: 50.00%, op_acc: 43.75%] [G loss: 0.853581]\n",
      "epoch:21 step:16840[D loss: 0.417116, acc: 61.72%, op_acc: 39.84%] [G loss: 0.896867]\n",
      "epoch:21 step:16841[D loss: 0.422190, acc: 60.94%, op_acc: 35.16%] [G loss: 0.875731]\n",
      "epoch:21 step:16842[D loss: 0.435282, acc: 57.03%, op_acc: 32.81%] [G loss: 0.956538]\n",
      "epoch:21 step:16843[D loss: 0.424034, acc: 61.72%, op_acc: 34.38%] [G loss: 0.855715]\n",
      "epoch:21 step:16844[D loss: 0.462371, acc: 51.56%, op_acc: 31.25%] [G loss: 0.872779]\n",
      "epoch:21 step:16845[D loss: 0.405799, acc: 64.84%, op_acc: 42.19%] [G loss: 0.923756]\n",
      "epoch:21 step:16846[D loss: 0.438419, acc: 56.25%, op_acc: 36.72%] [G loss: 0.987152]\n",
      "epoch:21 step:16847[D loss: 0.418816, acc: 57.03%, op_acc: 35.16%] [G loss: 0.910593]\n",
      "epoch:21 step:16848[D loss: 0.433885, acc: 58.59%, op_acc: 35.16%] [G loss: 0.896642]\n",
      "epoch:21 step:16849[D loss: 0.414912, acc: 58.59%, op_acc: 37.50%] [G loss: 0.883734]\n",
      "epoch:21 step:16850[D loss: 0.394505, acc: 71.88%, op_acc: 44.53%] [G loss: 0.920018]\n",
      "##############\n",
      "[0.85415599 0.88990111 0.78950958 0.82101592 0.78242629 0.81430187\n",
      " 0.883516   0.84645782 0.80996328 0.83637775]\n",
      "##########\n",
      "epoch:21 step:16851[D loss: 0.410751, acc: 66.41%, op_acc: 34.38%] [G loss: 0.974185]\n",
      "epoch:21 step:16852[D loss: 0.411589, acc: 66.41%, op_acc: 37.50%] [G loss: 0.893922]\n",
      "epoch:21 step:16853[D loss: 0.394532, acc: 60.94%, op_acc: 42.19%] [G loss: 0.862930]\n",
      "epoch:21 step:16854[D loss: 0.415837, acc: 58.59%, op_acc: 42.19%] [G loss: 0.861401]\n",
      "epoch:21 step:16855[D loss: 0.422244, acc: 57.03%, op_acc: 36.72%] [G loss: 0.982221]\n",
      "epoch:21 step:16856[D loss: 0.434359, acc: 52.34%, op_acc: 36.72%] [G loss: 0.908575]\n",
      "epoch:21 step:16857[D loss: 0.432413, acc: 56.25%, op_acc: 35.94%] [G loss: 0.922167]\n",
      "epoch:21 step:16858[D loss: 0.414475, acc: 61.72%, op_acc: 42.97%] [G loss: 0.852716]\n",
      "epoch:21 step:16859[D loss: 0.393993, acc: 61.72%, op_acc: 46.88%] [G loss: 0.847392]\n",
      "epoch:21 step:16860[D loss: 0.416558, acc: 57.03%, op_acc: 40.62%] [G loss: 0.920696]\n",
      "epoch:21 step:16861[D loss: 0.403872, acc: 66.41%, op_acc: 45.31%] [G loss: 0.847358]\n",
      "epoch:21 step:16862[D loss: 0.413651, acc: 59.38%, op_acc: 38.28%] [G loss: 0.877989]\n",
      "epoch:21 step:16863[D loss: 0.442886, acc: 56.25%, op_acc: 35.94%] [G loss: 0.926474]\n",
      "epoch:21 step:16864[D loss: 0.417599, acc: 60.94%, op_acc: 38.28%] [G loss: 0.869992]\n",
      "epoch:21 step:16865[D loss: 0.410150, acc: 60.94%, op_acc: 39.84%] [G loss: 0.853175]\n",
      "epoch:21 step:16866[D loss: 0.431686, acc: 58.59%, op_acc: 35.94%] [G loss: 0.899408]\n",
      "epoch:21 step:16867[D loss: 0.407435, acc: 64.06%, op_acc: 39.06%] [G loss: 0.848462]\n",
      "epoch:21 step:16868[D loss: 0.406407, acc: 72.66%, op_acc: 35.94%] [G loss: 0.854050]\n",
      "epoch:21 step:16869[D loss: 0.410777, acc: 64.06%, op_acc: 42.19%] [G loss: 0.922508]\n",
      "epoch:21 step:16870[D loss: 0.384414, acc: 61.72%, op_acc: 42.19%] [G loss: 0.875180]\n",
      "epoch:21 step:16871[D loss: 0.440800, acc: 51.56%, op_acc: 42.97%] [G loss: 0.866349]\n",
      "epoch:21 step:16872[D loss: 0.421652, acc: 61.72%, op_acc: 31.25%] [G loss: 0.845836]\n",
      "epoch:21 step:16873[D loss: 0.459810, acc: 53.12%, op_acc: 32.03%] [G loss: 0.867556]\n",
      "epoch:21 step:16874[D loss: 0.390963, acc: 67.19%, op_acc: 42.97%] [G loss: 0.929734]\n",
      "epoch:21 step:16875[D loss: 0.419608, acc: 60.16%, op_acc: 41.41%] [G loss: 0.948201]\n",
      "epoch:21 step:16876[D loss: 0.428285, acc: 54.69%, op_acc: 37.50%] [G loss: 0.819202]\n",
      "epoch:21 step:16877[D loss: 0.444587, acc: 55.47%, op_acc: 36.72%] [G loss: 0.872289]\n",
      "epoch:21 step:16878[D loss: 0.436727, acc: 53.91%, op_acc: 34.38%] [G loss: 0.790224]\n",
      "epoch:21 step:16879[D loss: 0.420979, acc: 58.59%, op_acc: 48.44%] [G loss: 0.926808]\n",
      "epoch:21 step:16880[D loss: 0.446701, acc: 50.78%, op_acc: 36.72%] [G loss: 0.910646]\n",
      "epoch:21 step:16881[D loss: 0.469729, acc: 57.81%, op_acc: 33.59%] [G loss: 0.893688]\n",
      "epoch:21 step:16882[D loss: 0.461737, acc: 57.03%, op_acc: 36.72%] [G loss: 0.848015]\n",
      "epoch:21 step:16883[D loss: 0.458568, acc: 55.47%, op_acc: 40.62%] [G loss: 0.941456]\n",
      "epoch:21 step:16884[D loss: 0.417665, acc: 63.28%, op_acc: 39.06%] [G loss: 0.918711]\n",
      "epoch:21 step:16885[D loss: 0.406116, acc: 56.25%, op_acc: 40.62%] [G loss: 0.897339]\n",
      "epoch:21 step:16886[D loss: 0.450617, acc: 59.38%, op_acc: 33.59%] [G loss: 0.862638]\n",
      "epoch:21 step:16887[D loss: 0.388357, acc: 68.75%, op_acc: 40.62%] [G loss: 0.870761]\n",
      "epoch:21 step:16888[D loss: 0.411086, acc: 58.59%, op_acc: 39.84%] [G loss: 0.945173]\n",
      "epoch:21 step:16889[D loss: 0.454445, acc: 50.78%, op_acc: 35.94%] [G loss: 0.887755]\n",
      "epoch:21 step:16890[D loss: 0.416064, acc: 61.72%, op_acc: 44.53%] [G loss: 0.881065]\n",
      "epoch:21 step:16891[D loss: 0.422345, acc: 57.81%, op_acc: 39.84%] [G loss: 0.851670]\n",
      "epoch:21 step:16892[D loss: 0.457918, acc: 57.81%, op_acc: 36.72%] [G loss: 0.869418]\n",
      "epoch:21 step:16893[D loss: 0.441085, acc: 51.56%, op_acc: 44.53%] [G loss: 0.885959]\n",
      "epoch:21 step:16894[D loss: 0.429590, acc: 60.16%, op_acc: 37.50%] [G loss: 0.858404]\n",
      "epoch:21 step:16895[D loss: 0.378240, acc: 67.97%, op_acc: 46.88%] [G loss: 0.895900]\n",
      "epoch:21 step:16896[D loss: 0.438958, acc: 54.69%, op_acc: 40.62%] [G loss: 0.837885]\n",
      "epoch:21 step:16897[D loss: 0.400361, acc: 60.16%, op_acc: 39.84%] [G loss: 0.878003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16898[D loss: 0.405288, acc: 59.38%, op_acc: 40.62%] [G loss: 0.862626]\n",
      "epoch:21 step:16899[D loss: 0.438727, acc: 61.72%, op_acc: 36.72%] [G loss: 0.939100]\n",
      "epoch:21 step:16900[D loss: 0.443426, acc: 62.50%, op_acc: 35.94%] [G loss: 0.874370]\n",
      "##############\n",
      "[0.85555365 0.86051852 0.79163715 0.80866411 0.80042498 0.82655499\n",
      " 0.88048041 0.84106595 0.82207344 0.82046004]\n",
      "##########\n",
      "epoch:21 step:16901[D loss: 0.399952, acc: 67.97%, op_acc: 43.75%] [G loss: 0.923096]\n",
      "epoch:21 step:16902[D loss: 0.464788, acc: 54.69%, op_acc: 25.78%] [G loss: 0.855705]\n",
      "epoch:21 step:16903[D loss: 0.442187, acc: 56.25%, op_acc: 40.62%] [G loss: 0.954334]\n",
      "epoch:21 step:16904[D loss: 0.423199, acc: 63.28%, op_acc: 40.62%] [G loss: 0.925997]\n",
      "epoch:21 step:16905[D loss: 0.457974, acc: 56.25%, op_acc: 35.94%] [G loss: 0.795321]\n",
      "epoch:21 step:16906[D loss: 0.414008, acc: 60.94%, op_acc: 41.41%] [G loss: 0.908229]\n",
      "epoch:21 step:16907[D loss: 0.420715, acc: 62.50%, op_acc: 38.28%] [G loss: 0.769199]\n",
      "epoch:21 step:16908[D loss: 0.384571, acc: 67.19%, op_acc: 42.19%] [G loss: 0.863415]\n",
      "epoch:21 step:16909[D loss: 0.430428, acc: 64.06%, op_acc: 36.72%] [G loss: 0.835679]\n",
      "epoch:21 step:16910[D loss: 0.471495, acc: 50.78%, op_acc: 34.38%] [G loss: 0.839124]\n",
      "epoch:21 step:16911[D loss: 0.456342, acc: 57.81%, op_acc: 42.97%] [G loss: 0.853062]\n",
      "epoch:21 step:16912[D loss: 0.413609, acc: 58.59%, op_acc: 40.62%] [G loss: 0.993289]\n",
      "epoch:21 step:16913[D loss: 0.454921, acc: 53.12%, op_acc: 36.72%] [G loss: 0.891879]\n",
      "epoch:21 step:16914[D loss: 0.450274, acc: 54.69%, op_acc: 34.38%] [G loss: 0.847579]\n",
      "epoch:21 step:16915[D loss: 0.457043, acc: 57.81%, op_acc: 32.81%] [G loss: 0.896010]\n",
      "epoch:21 step:16916[D loss: 0.430064, acc: 61.72%, op_acc: 37.50%] [G loss: 0.894469]\n",
      "epoch:21 step:16917[D loss: 0.464190, acc: 43.75%, op_acc: 35.94%] [G loss: 0.811639]\n",
      "epoch:21 step:16918[D loss: 0.454863, acc: 54.69%, op_acc: 35.16%] [G loss: 0.916125]\n",
      "epoch:21 step:16919[D loss: 0.402364, acc: 60.16%, op_acc: 42.97%] [G loss: 0.891232]\n",
      "epoch:21 step:16920[D loss: 0.407897, acc: 67.97%, op_acc: 39.84%] [G loss: 0.908187]\n",
      "epoch:21 step:16921[D loss: 0.438593, acc: 53.91%, op_acc: 36.72%] [G loss: 0.915782]\n",
      "epoch:21 step:16922[D loss: 0.440826, acc: 55.47%, op_acc: 35.16%] [G loss: 0.865665]\n",
      "epoch:21 step:16923[D loss: 0.433178, acc: 62.50%, op_acc: 36.72%] [G loss: 0.880819]\n",
      "epoch:21 step:16924[D loss: 0.398468, acc: 69.53%, op_acc: 38.28%] [G loss: 0.869573]\n",
      "epoch:21 step:16925[D loss: 0.467485, acc: 49.22%, op_acc: 37.50%] [G loss: 0.872338]\n",
      "epoch:21 step:16926[D loss: 0.456206, acc: 63.28%, op_acc: 34.38%] [G loss: 0.878932]\n",
      "epoch:21 step:16927[D loss: 0.458785, acc: 63.28%, op_acc: 29.69%] [G loss: 0.884783]\n",
      "epoch:21 step:16928[D loss: 0.458708, acc: 51.56%, op_acc: 38.28%] [G loss: 0.926485]\n",
      "epoch:21 step:16929[D loss: 0.456761, acc: 46.88%, op_acc: 38.28%] [G loss: 0.888803]\n",
      "epoch:21 step:16930[D loss: 0.413854, acc: 60.94%, op_acc: 42.19%] [G loss: 0.894883]\n",
      "epoch:21 step:16931[D loss: 0.436265, acc: 55.47%, op_acc: 34.38%] [G loss: 0.937279]\n",
      "epoch:21 step:16932[D loss: 0.441368, acc: 60.94%, op_acc: 38.28%] [G loss: 0.880258]\n",
      "epoch:21 step:16933[D loss: 0.420650, acc: 60.94%, op_acc: 39.84%] [G loss: 0.985265]\n",
      "epoch:21 step:16934[D loss: 0.417272, acc: 54.69%, op_acc: 46.09%] [G loss: 0.915345]\n",
      "epoch:21 step:16935[D loss: 0.409068, acc: 64.84%, op_acc: 45.31%] [G loss: 0.886594]\n",
      "epoch:21 step:16936[D loss: 0.410919, acc: 63.28%, op_acc: 40.62%] [G loss: 0.810081]\n",
      "epoch:21 step:16937[D loss: 0.412737, acc: 54.69%, op_acc: 45.31%] [G loss: 0.880570]\n",
      "epoch:21 step:16938[D loss: 0.458943, acc: 57.03%, op_acc: 32.03%] [G loss: 0.830627]\n",
      "epoch:21 step:16939[D loss: 0.404036, acc: 62.50%, op_acc: 42.19%] [G loss: 0.894594]\n",
      "epoch:21 step:16940[D loss: 0.434408, acc: 62.50%, op_acc: 41.41%] [G loss: 0.856261]\n",
      "epoch:21 step:16941[D loss: 0.429995, acc: 62.50%, op_acc: 38.28%] [G loss: 0.828602]\n",
      "epoch:21 step:16942[D loss: 0.420179, acc: 63.28%, op_acc: 40.62%] [G loss: 0.926316]\n",
      "epoch:21 step:16943[D loss: 0.449209, acc: 51.56%, op_acc: 35.16%] [G loss: 0.861111]\n",
      "epoch:21 step:16944[D loss: 0.428153, acc: 67.97%, op_acc: 41.41%] [G loss: 0.896441]\n",
      "epoch:21 step:16945[D loss: 0.428426, acc: 51.56%, op_acc: 40.62%] [G loss: 0.860860]\n",
      "epoch:21 step:16946[D loss: 0.404330, acc: 63.28%, op_acc: 39.06%] [G loss: 0.893184]\n",
      "epoch:21 step:16947[D loss: 0.390746, acc: 60.94%, op_acc: 42.19%] [G loss: 0.958419]\n",
      "epoch:21 step:16948[D loss: 0.435447, acc: 63.28%, op_acc: 33.59%] [G loss: 0.924756]\n",
      "epoch:21 step:16949[D loss: 0.453152, acc: 55.47%, op_acc: 33.59%] [G loss: 0.967701]\n",
      "epoch:21 step:16950[D loss: 0.424137, acc: 55.47%, op_acc: 40.62%] [G loss: 0.908556]\n",
      "##############\n",
      "[0.8753172  0.85968328 0.82472788 0.80190847 0.78408936 0.83132777\n",
      " 0.89370825 0.8337568  0.82418686 0.83695806]\n",
      "##########\n",
      "epoch:21 step:16951[D loss: 0.441972, acc: 53.91%, op_acc: 46.88%] [G loss: 0.890691]\n",
      "epoch:21 step:16952[D loss: 0.424903, acc: 59.38%, op_acc: 39.84%] [G loss: 0.939166]\n",
      "epoch:21 step:16953[D loss: 0.470615, acc: 53.12%, op_acc: 29.69%] [G loss: 0.874757]\n",
      "epoch:21 step:16954[D loss: 0.393793, acc: 71.09%, op_acc: 47.66%] [G loss: 0.888182]\n",
      "epoch:21 step:16955[D loss: 0.427430, acc: 57.81%, op_acc: 35.94%] [G loss: 0.880766]\n",
      "epoch:21 step:16956[D loss: 0.434325, acc: 50.78%, op_acc: 38.28%] [G loss: 0.874506]\n",
      "epoch:21 step:16957[D loss: 0.421344, acc: 64.84%, op_acc: 40.62%] [G loss: 0.911014]\n",
      "epoch:21 step:16958[D loss: 0.442062, acc: 58.59%, op_acc: 35.94%] [G loss: 0.893777]\n",
      "epoch:21 step:16959[D loss: 0.412472, acc: 61.72%, op_acc: 43.75%] [G loss: 0.895933]\n",
      "epoch:21 step:16960[D loss: 0.389774, acc: 66.41%, op_acc: 33.59%] [G loss: 0.912149]\n",
      "epoch:21 step:16961[D loss: 0.446290, acc: 57.81%, op_acc: 37.50%] [G loss: 0.834273]\n",
      "epoch:21 step:16962[D loss: 0.442641, acc: 50.78%, op_acc: 39.06%] [G loss: 0.841693]\n",
      "epoch:21 step:16963[D loss: 0.424991, acc: 59.38%, op_acc: 37.50%] [G loss: 0.877331]\n",
      "epoch:21 step:16964[D loss: 0.437683, acc: 58.59%, op_acc: 34.38%] [G loss: 0.789116]\n",
      "epoch:21 step:16965[D loss: 0.420490, acc: 60.16%, op_acc: 42.19%] [G loss: 0.965278]\n",
      "epoch:21 step:16966[D loss: 0.432315, acc: 53.12%, op_acc: 39.84%] [G loss: 0.894742]\n",
      "epoch:21 step:16967[D loss: 0.407830, acc: 64.84%, op_acc: 37.50%] [G loss: 0.846769]\n",
      "epoch:21 step:16968[D loss: 0.406651, acc: 60.16%, op_acc: 39.84%] [G loss: 0.924228]\n",
      "epoch:21 step:16969[D loss: 0.436587, acc: 56.25%, op_acc: 42.97%] [G loss: 0.834481]\n",
      "epoch:21 step:16970[D loss: 0.430026, acc: 59.38%, op_acc: 33.59%] [G loss: 0.927059]\n",
      "epoch:21 step:16971[D loss: 0.421810, acc: 61.72%, op_acc: 40.62%] [G loss: 0.895073]\n",
      "epoch:21 step:16972[D loss: 0.427006, acc: 58.59%, op_acc: 41.41%] [G loss: 0.882218]\n",
      "epoch:21 step:16973[D loss: 0.420579, acc: 60.16%, op_acc: 35.94%] [G loss: 0.857143]\n",
      "epoch:21 step:16974[D loss: 0.449102, acc: 48.44%, op_acc: 42.19%] [G loss: 0.897530]\n",
      "epoch:21 step:16975[D loss: 0.413468, acc: 63.28%, op_acc: 39.84%] [G loss: 0.896544]\n",
      "epoch:21 step:16976[D loss: 0.413873, acc: 60.16%, op_acc: 38.28%] [G loss: 0.883710]\n",
      "epoch:21 step:16977[D loss: 0.396681, acc: 65.62%, op_acc: 42.19%] [G loss: 0.966263]\n",
      "epoch:21 step:16978[D loss: 0.449742, acc: 55.47%, op_acc: 25.78%] [G loss: 0.854498]\n",
      "epoch:21 step:16979[D loss: 0.454493, acc: 55.47%, op_acc: 38.28%] [G loss: 0.836102]\n",
      "epoch:21 step:16980[D loss: 0.417734, acc: 51.56%, op_acc: 40.62%] [G loss: 0.885608]\n",
      "epoch:21 step:16981[D loss: 0.419149, acc: 60.94%, op_acc: 42.19%] [G loss: 0.898571]\n",
      "epoch:21 step:16982[D loss: 0.412932, acc: 64.06%, op_acc: 38.28%] [G loss: 0.887625]\n",
      "epoch:21 step:16983[D loss: 0.413428, acc: 60.94%, op_acc: 39.84%] [G loss: 0.852014]\n",
      "epoch:21 step:16984[D loss: 0.420359, acc: 56.25%, op_acc: 39.06%] [G loss: 0.919217]\n",
      "epoch:21 step:16985[D loss: 0.499361, acc: 53.91%, op_acc: 25.78%] [G loss: 0.848429]\n",
      "epoch:21 step:16986[D loss: 0.420074, acc: 62.50%, op_acc: 36.72%] [G loss: 0.947164]\n",
      "epoch:21 step:16987[D loss: 0.429971, acc: 61.72%, op_acc: 39.84%] [G loss: 0.828903]\n",
      "epoch:21 step:16988[D loss: 0.405977, acc: 65.62%, op_acc: 35.16%] [G loss: 0.807858]\n",
      "epoch:21 step:16989[D loss: 0.414652, acc: 57.03%, op_acc: 41.41%] [G loss: 0.850942]\n",
      "epoch:21 step:16990[D loss: 0.412134, acc: 59.38%, op_acc: 35.16%] [G loss: 0.901144]\n",
      "epoch:21 step:16991[D loss: 0.415935, acc: 58.59%, op_acc: 48.44%] [G loss: 0.898997]\n",
      "epoch:21 step:16992[D loss: 0.452222, acc: 64.06%, op_acc: 37.50%] [G loss: 0.896332]\n",
      "epoch:21 step:16993[D loss: 0.405268, acc: 62.50%, op_acc: 38.28%] [G loss: 0.890912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16994[D loss: 0.455448, acc: 51.56%, op_acc: 35.94%] [G loss: 0.832303]\n",
      "epoch:21 step:16995[D loss: 0.435461, acc: 60.16%, op_acc: 34.38%] [G loss: 0.804415]\n",
      "epoch:21 step:16996[D loss: 0.419550, acc: 64.06%, op_acc: 43.75%] [G loss: 0.854688]\n",
      "epoch:21 step:16997[D loss: 0.435671, acc: 66.41%, op_acc: 36.72%] [G loss: 0.857911]\n",
      "epoch:21 step:16998[D loss: 0.416407, acc: 59.38%, op_acc: 35.94%] [G loss: 0.960145]\n",
      "epoch:21 step:16999[D loss: 0.412249, acc: 65.62%, op_acc: 39.84%] [G loss: 0.849683]\n",
      "epoch:21 step:17000[D loss: 0.420169, acc: 64.84%, op_acc: 35.94%] [G loss: 0.880907]\n",
      "##############\n",
      "[0.86037985 0.86412937 0.81628304 0.81935154 0.78343486 0.82280354\n",
      " 0.87798028 0.8272974  0.82439568 0.82797551]\n",
      "##########\n",
      "epoch:21 step:17001[D loss: 0.439575, acc: 59.38%, op_acc: 39.84%] [G loss: 0.894276]\n",
      "epoch:21 step:17002[D loss: 0.433289, acc: 57.03%, op_acc: 38.28%] [G loss: 0.856838]\n",
      "epoch:21 step:17003[D loss: 0.386236, acc: 64.84%, op_acc: 46.09%] [G loss: 0.873579]\n",
      "epoch:21 step:17004[D loss: 0.394540, acc: 61.72%, op_acc: 41.41%] [G loss: 0.896784]\n",
      "epoch:21 step:17005[D loss: 0.472764, acc: 53.12%, op_acc: 30.47%] [G loss: 0.885478]\n",
      "epoch:21 step:17006[D loss: 0.444703, acc: 52.34%, op_acc: 35.16%] [G loss: 0.747683]\n",
      "epoch:21 step:17007[D loss: 0.409128, acc: 61.72%, op_acc: 41.41%] [G loss: 0.917632]\n",
      "epoch:21 step:17008[D loss: 0.409218, acc: 60.94%, op_acc: 40.62%] [G loss: 0.913813]\n",
      "epoch:21 step:17009[D loss: 0.417721, acc: 59.38%, op_acc: 42.19%] [G loss: 0.848228]\n",
      "epoch:21 step:17010[D loss: 0.438818, acc: 54.69%, op_acc: 39.84%] [G loss: 0.967367]\n",
      "epoch:21 step:17011[D loss: 0.404159, acc: 64.06%, op_acc: 32.81%] [G loss: 0.848424]\n",
      "epoch:21 step:17012[D loss: 0.458809, acc: 52.34%, op_acc: 36.72%] [G loss: 0.857854]\n",
      "epoch:21 step:17013[D loss: 0.421256, acc: 64.84%, op_acc: 33.59%] [G loss: 0.959383]\n",
      "epoch:21 step:17014[D loss: 0.441276, acc: 48.44%, op_acc: 35.94%] [G loss: 0.871217]\n",
      "epoch:21 step:17015[D loss: 0.382241, acc: 68.75%, op_acc: 43.75%] [G loss: 0.954504]\n",
      "epoch:21 step:17016[D loss: 0.452886, acc: 51.56%, op_acc: 40.62%] [G loss: 0.850434]\n",
      "epoch:21 step:17017[D loss: 0.445507, acc: 52.34%, op_acc: 38.28%] [G loss: 0.861341]\n",
      "epoch:21 step:17018[D loss: 0.435815, acc: 60.94%, op_acc: 33.59%] [G loss: 0.901321]\n",
      "epoch:21 step:17019[D loss: 0.405222, acc: 63.28%, op_acc: 41.41%] [G loss: 0.898957]\n",
      "epoch:21 step:17020[D loss: 0.445416, acc: 60.16%, op_acc: 38.28%] [G loss: 0.948920]\n",
      "epoch:21 step:17021[D loss: 0.415862, acc: 64.06%, op_acc: 40.62%] [G loss: 0.888435]\n",
      "epoch:21 step:17022[D loss: 0.411760, acc: 58.59%, op_acc: 46.09%] [G loss: 0.944312]\n",
      "epoch:21 step:17023[D loss: 0.430528, acc: 58.59%, op_acc: 40.62%] [G loss: 1.016135]\n",
      "epoch:21 step:17024[D loss: 0.415227, acc: 59.38%, op_acc: 39.84%] [G loss: 0.965838]\n",
      "epoch:21 step:17025[D loss: 0.410995, acc: 66.41%, op_acc: 39.06%] [G loss: 0.932928]\n",
      "epoch:21 step:17026[D loss: 0.436287, acc: 59.38%, op_acc: 39.06%] [G loss: 0.874588]\n",
      "epoch:21 step:17027[D loss: 0.384202, acc: 67.97%, op_acc: 48.44%] [G loss: 0.929789]\n",
      "epoch:21 step:17028[D loss: 0.420137, acc: 54.69%, op_acc: 43.75%] [G loss: 0.850448]\n",
      "epoch:21 step:17029[D loss: 0.451561, acc: 56.25%, op_acc: 31.25%] [G loss: 0.835633]\n",
      "epoch:21 step:17030[D loss: 0.426889, acc: 60.94%, op_acc: 42.97%] [G loss: 0.947851]\n",
      "epoch:21 step:17031[D loss: 0.431355, acc: 53.91%, op_acc: 39.84%] [G loss: 0.913426]\n",
      "epoch:21 step:17032[D loss: 0.435554, acc: 61.72%, op_acc: 39.84%] [G loss: 0.890452]\n",
      "epoch:21 step:17033[D loss: 0.452857, acc: 56.25%, op_acc: 32.81%] [G loss: 0.794692]\n",
      "epoch:21 step:17034[D loss: 0.445360, acc: 59.38%, op_acc: 35.94%] [G loss: 0.874359]\n",
      "epoch:21 step:17035[D loss: 0.443780, acc: 53.12%, op_acc: 42.19%] [G loss: 0.845419]\n",
      "epoch:21 step:17036[D loss: 0.433515, acc: 54.69%, op_acc: 36.72%] [G loss: 0.875556]\n",
      "epoch:21 step:17037[D loss: 0.409319, acc: 61.72%, op_acc: 44.53%] [G loss: 0.873487]\n",
      "epoch:21 step:17038[D loss: 0.423847, acc: 57.03%, op_acc: 34.38%] [G loss: 0.837690]\n",
      "epoch:21 step:17039[D loss: 0.428371, acc: 60.94%, op_acc: 40.62%] [G loss: 0.853798]\n",
      "epoch:21 step:17040[D loss: 0.436049, acc: 57.81%, op_acc: 37.50%] [G loss: 0.889526]\n",
      "epoch:21 step:17041[D loss: 0.407472, acc: 66.41%, op_acc: 39.06%] [G loss: 0.916789]\n",
      "epoch:21 step:17042[D loss: 0.428432, acc: 58.59%, op_acc: 37.50%] [G loss: 0.898954]\n",
      "epoch:21 step:17043[D loss: 0.450399, acc: 57.81%, op_acc: 35.16%] [G loss: 0.796434]\n",
      "epoch:21 step:17044[D loss: 0.450072, acc: 55.47%, op_acc: 34.38%] [G loss: 0.885286]\n",
      "epoch:21 step:17045[D loss: 0.418090, acc: 58.59%, op_acc: 42.19%] [G loss: 0.899747]\n",
      "epoch:21 step:17046[D loss: 0.398408, acc: 64.06%, op_acc: 37.50%] [G loss: 0.921414]\n",
      "epoch:21 step:17047[D loss: 0.423539, acc: 64.84%, op_acc: 35.16%] [G loss: 0.883848]\n",
      "epoch:21 step:17048[D loss: 0.402626, acc: 64.06%, op_acc: 46.09%] [G loss: 0.892966]\n",
      "epoch:21 step:17049[D loss: 0.439266, acc: 60.16%, op_acc: 31.25%] [G loss: 0.900840]\n",
      "epoch:21 step:17050[D loss: 0.421467, acc: 64.84%, op_acc: 39.06%] [G loss: 0.909123]\n",
      "##############\n",
      "[0.83545982 0.87166015 0.78308237 0.79689399 0.79117108 0.81997537\n",
      " 0.87119818 0.8311168  0.81298915 0.84711161]\n",
      "##########\n",
      "epoch:21 step:17051[D loss: 0.437756, acc: 60.94%, op_acc: 37.50%] [G loss: 0.858996]\n",
      "epoch:21 step:17052[D loss: 0.404919, acc: 64.84%, op_acc: 41.41%] [G loss: 0.841576]\n",
      "epoch:21 step:17053[D loss: 0.444823, acc: 56.25%, op_acc: 39.84%] [G loss: 0.912903]\n",
      "epoch:21 step:17054[D loss: 0.420021, acc: 55.47%, op_acc: 43.75%] [G loss: 0.974676]\n",
      "epoch:21 step:17055[D loss: 0.421033, acc: 55.47%, op_acc: 38.28%] [G loss: 0.850789]\n",
      "epoch:21 step:17056[D loss: 0.427434, acc: 57.81%, op_acc: 36.72%] [G loss: 0.907481]\n",
      "epoch:21 step:17057[D loss: 0.420583, acc: 60.16%, op_acc: 44.53%] [G loss: 0.855851]\n",
      "epoch:21 step:17058[D loss: 0.427719, acc: 60.16%, op_acc: 39.84%] [G loss: 0.868530]\n",
      "epoch:21 step:17059[D loss: 0.442413, acc: 60.94%, op_acc: 38.28%] [G loss: 0.831971]\n",
      "epoch:21 step:17060[D loss: 0.412943, acc: 67.19%, op_acc: 37.50%] [G loss: 0.924112]\n",
      "epoch:21 step:17061[D loss: 0.440852, acc: 55.47%, op_acc: 42.19%] [G loss: 0.847874]\n",
      "epoch:21 step:17062[D loss: 0.393968, acc: 62.50%, op_acc: 45.31%] [G loss: 0.883083]\n",
      "epoch:21 step:17063[D loss: 0.390661, acc: 68.75%, op_acc: 44.53%] [G loss: 0.829298]\n",
      "epoch:21 step:17064[D loss: 0.446734, acc: 53.12%, op_acc: 35.16%] [G loss: 0.846202]\n",
      "epoch:21 step:17065[D loss: 0.434725, acc: 56.25%, op_acc: 40.62%] [G loss: 0.803496]\n",
      "epoch:21 step:17066[D loss: 0.445008, acc: 57.81%, op_acc: 36.72%] [G loss: 0.857148]\n",
      "epoch:21 step:17067[D loss: 0.433797, acc: 64.84%, op_acc: 31.25%] [G loss: 0.852914]\n",
      "epoch:21 step:17068[D loss: 0.418752, acc: 60.16%, op_acc: 37.50%] [G loss: 0.861639]\n",
      "epoch:21 step:17069[D loss: 0.450797, acc: 50.00%, op_acc: 35.94%] [G loss: 0.905023]\n",
      "epoch:21 step:17070[D loss: 0.430681, acc: 62.50%, op_acc: 32.81%] [G loss: 0.839493]\n",
      "epoch:21 step:17071[D loss: 0.396041, acc: 59.38%, op_acc: 41.41%] [G loss: 0.912069]\n",
      "epoch:21 step:17072[D loss: 0.459278, acc: 51.56%, op_acc: 35.16%] [G loss: 0.873857]\n",
      "epoch:21 step:17073[D loss: 0.448958, acc: 57.03%, op_acc: 35.94%] [G loss: 0.877483]\n",
      "epoch:21 step:17074[D loss: 0.437638, acc: 60.16%, op_acc: 34.38%] [G loss: 0.870555]\n",
      "epoch:21 step:17075[D loss: 0.394659, acc: 64.06%, op_acc: 43.75%] [G loss: 0.944472]\n",
      "epoch:21 step:17076[D loss: 0.414498, acc: 63.28%, op_acc: 40.62%] [G loss: 0.874004]\n",
      "epoch:21 step:17077[D loss: 0.483316, acc: 53.91%, op_acc: 28.91%] [G loss: 0.870427]\n",
      "epoch:21 step:17078[D loss: 0.442387, acc: 53.91%, op_acc: 35.94%] [G loss: 0.866957]\n",
      "epoch:21 step:17079[D loss: 0.424301, acc: 56.25%, op_acc: 36.72%] [G loss: 0.843401]\n",
      "epoch:21 step:17080[D loss: 0.411184, acc: 58.59%, op_acc: 42.97%] [G loss: 0.780956]\n",
      "epoch:21 step:17081[D loss: 0.416786, acc: 59.38%, op_acc: 42.97%] [G loss: 0.897822]\n",
      "epoch:21 step:17082[D loss: 0.446772, acc: 60.94%, op_acc: 32.03%] [G loss: 0.922483]\n",
      "epoch:21 step:17083[D loss: 0.409704, acc: 59.38%, op_acc: 41.41%] [G loss: 0.852844]\n",
      "epoch:21 step:17084[D loss: 0.431123, acc: 52.34%, op_acc: 41.41%] [G loss: 0.869502]\n",
      "epoch:21 step:17085[D loss: 0.418682, acc: 62.50%, op_acc: 38.28%] [G loss: 0.890703]\n",
      "epoch:21 step:17086[D loss: 0.475779, acc: 49.22%, op_acc: 36.72%] [G loss: 0.940328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17087[D loss: 0.440870, acc: 58.59%, op_acc: 36.72%] [G loss: 0.898165]\n",
      "epoch:21 step:17088[D loss: 0.428558, acc: 57.03%, op_acc: 37.50%] [G loss: 0.853465]\n",
      "epoch:21 step:17089[D loss: 0.409132, acc: 60.16%, op_acc: 39.06%] [G loss: 0.791919]\n",
      "epoch:21 step:17090[D loss: 0.427129, acc: 54.69%, op_acc: 38.28%] [G loss: 0.857244]\n",
      "epoch:21 step:17091[D loss: 0.439112, acc: 62.50%, op_acc: 38.28%] [G loss: 0.821470]\n",
      "epoch:21 step:17092[D loss: 0.430910, acc: 61.72%, op_acc: 35.16%] [G loss: 0.917292]\n",
      "epoch:21 step:17093[D loss: 0.451038, acc: 53.12%, op_acc: 39.06%] [G loss: 0.918472]\n",
      "epoch:21 step:17094[D loss: 0.428328, acc: 56.25%, op_acc: 38.28%] [G loss: 0.901145]\n",
      "epoch:21 step:17095[D loss: 0.420677, acc: 56.25%, op_acc: 38.28%] [G loss: 0.929368]\n",
      "epoch:21 step:17096[D loss: 0.420279, acc: 62.50%, op_acc: 41.41%] [G loss: 0.871510]\n",
      "epoch:21 step:17097[D loss: 0.437232, acc: 53.12%, op_acc: 36.72%] [G loss: 0.879273]\n",
      "epoch:21 step:17098[D loss: 0.418919, acc: 59.38%, op_acc: 38.28%] [G loss: 0.957508]\n",
      "epoch:21 step:17099[D loss: 0.406700, acc: 61.72%, op_acc: 41.41%] [G loss: 0.815112]\n",
      "epoch:21 step:17100[D loss: 0.423064, acc: 60.16%, op_acc: 38.28%] [G loss: 0.829926]\n",
      "##############\n",
      "[0.85420499 0.86039331 0.81757216 0.81046786 0.80661943 0.83298732\n",
      " 0.89272102 0.82371301 0.81267914 0.82988759]\n",
      "##########\n",
      "epoch:21 step:17101[D loss: 0.460594, acc: 51.56%, op_acc: 38.28%] [G loss: 0.947433]\n",
      "epoch:21 step:17102[D loss: 0.454016, acc: 57.03%, op_acc: 38.28%] [G loss: 0.813668]\n",
      "epoch:21 step:17103[D loss: 0.423459, acc: 60.94%, op_acc: 35.16%] [G loss: 0.835706]\n",
      "epoch:21 step:17104[D loss: 0.498370, acc: 38.28%, op_acc: 34.38%] [G loss: 0.832745]\n",
      "epoch:21 step:17105[D loss: 0.388517, acc: 61.72%, op_acc: 50.00%] [G loss: 0.886022]\n",
      "epoch:21 step:17106[D loss: 0.473114, acc: 51.56%, op_acc: 31.25%] [G loss: 0.811289]\n",
      "epoch:21 step:17107[D loss: 0.453859, acc: 50.78%, op_acc: 39.06%] [G loss: 0.845119]\n",
      "epoch:21 step:17108[D loss: 0.418679, acc: 60.94%, op_acc: 35.94%] [G loss: 0.902662]\n",
      "epoch:21 step:17109[D loss: 0.439672, acc: 55.47%, op_acc: 34.38%] [G loss: 0.790022]\n",
      "epoch:21 step:17110[D loss: 0.431846, acc: 57.81%, op_acc: 35.94%] [G loss: 0.838216]\n",
      "epoch:21 step:17111[D loss: 0.382417, acc: 68.75%, op_acc: 43.75%] [G loss: 0.909003]\n",
      "epoch:21 step:17112[D loss: 0.410159, acc: 62.50%, op_acc: 39.06%] [G loss: 0.831557]\n",
      "epoch:21 step:17113[D loss: 0.400815, acc: 64.84%, op_acc: 39.84%] [G loss: 0.944446]\n",
      "epoch:21 step:17114[D loss: 0.424579, acc: 56.25%, op_acc: 36.72%] [G loss: 0.856112]\n",
      "epoch:21 step:17115[D loss: 0.424457, acc: 59.38%, op_acc: 36.72%] [G loss: 0.895485]\n",
      "epoch:21 step:17116[D loss: 0.431066, acc: 57.03%, op_acc: 35.94%] [G loss: 0.888362]\n",
      "epoch:21 step:17117[D loss: 0.412750, acc: 65.62%, op_acc: 40.62%] [G loss: 0.929249]\n",
      "epoch:21 step:17118[D loss: 0.417527, acc: 53.91%, op_acc: 40.62%] [G loss: 0.910291]\n",
      "epoch:21 step:17119[D loss: 0.426697, acc: 58.59%, op_acc: 35.94%] [G loss: 0.938642]\n",
      "epoch:21 step:17120[D loss: 0.452402, acc: 51.56%, op_acc: 40.62%] [G loss: 0.868922]\n",
      "epoch:21 step:17121[D loss: 0.449428, acc: 53.12%, op_acc: 35.16%] [G loss: 0.848561]\n",
      "epoch:21 step:17122[D loss: 0.435045, acc: 51.56%, op_acc: 40.62%] [G loss: 0.817909]\n",
      "epoch:21 step:17123[D loss: 0.442747, acc: 58.59%, op_acc: 36.72%] [G loss: 0.867859]\n",
      "epoch:21 step:17124[D loss: 0.403618, acc: 64.84%, op_acc: 39.06%] [G loss: 0.895358]\n",
      "epoch:21 step:17125[D loss: 0.489570, acc: 53.12%, op_acc: 31.25%] [G loss: 0.932451]\n",
      "epoch:21 step:17126[D loss: 0.450348, acc: 57.03%, op_acc: 35.94%] [G loss: 0.930717]\n",
      "epoch:21 step:17127[D loss: 0.433082, acc: 58.59%, op_acc: 38.28%] [G loss: 0.900947]\n",
      "epoch:21 step:17128[D loss: 0.437146, acc: 58.59%, op_acc: 35.94%] [G loss: 0.886254]\n",
      "epoch:21 step:17129[D loss: 0.409891, acc: 62.50%, op_acc: 42.97%] [G loss: 0.844253]\n",
      "epoch:21 step:17130[D loss: 0.442479, acc: 55.47%, op_acc: 33.59%] [G loss: 0.878465]\n",
      "epoch:21 step:17131[D loss: 0.417730, acc: 56.25%, op_acc: 39.84%] [G loss: 0.811847]\n",
      "epoch:21 step:17132[D loss: 0.383134, acc: 67.19%, op_acc: 45.31%] [G loss: 0.971246]\n",
      "epoch:21 step:17133[D loss: 0.409954, acc: 69.53%, op_acc: 36.72%] [G loss: 0.964655]\n",
      "epoch:21 step:17134[D loss: 0.418934, acc: 61.72%, op_acc: 36.72%] [G loss: 0.885302]\n",
      "epoch:21 step:17135[D loss: 0.445256, acc: 56.25%, op_acc: 42.19%] [G loss: 0.770321]\n",
      "epoch:21 step:17136[D loss: 0.445935, acc: 56.25%, op_acc: 32.81%] [G loss: 0.917859]\n",
      "epoch:21 step:17137[D loss: 0.406355, acc: 69.53%, op_acc: 37.50%] [G loss: 0.837518]\n",
      "epoch:21 step:17138[D loss: 0.405398, acc: 57.03%, op_acc: 42.97%] [G loss: 0.894086]\n",
      "epoch:21 step:17139[D loss: 0.451560, acc: 53.91%, op_acc: 39.06%] [G loss: 0.840925]\n",
      "epoch:21 step:17140[D loss: 0.423665, acc: 60.16%, op_acc: 42.19%] [G loss: 0.925564]\n",
      "epoch:21 step:17141[D loss: 0.426062, acc: 59.38%, op_acc: 39.06%] [G loss: 0.872170]\n",
      "epoch:21 step:17142[D loss: 0.408760, acc: 64.06%, op_acc: 37.50%] [G loss: 0.923865]\n",
      "epoch:21 step:17143[D loss: 0.419116, acc: 61.72%, op_acc: 38.28%] [G loss: 0.857847]\n",
      "epoch:21 step:17144[D loss: 0.419329, acc: 58.59%, op_acc: 36.72%] [G loss: 0.965179]\n",
      "epoch:21 step:17145[D loss: 0.388568, acc: 61.72%, op_acc: 40.62%] [G loss: 0.810574]\n",
      "epoch:21 step:17146[D loss: 0.434390, acc: 62.50%, op_acc: 41.41%] [G loss: 0.842661]\n",
      "epoch:21 step:17147[D loss: 0.430369, acc: 63.28%, op_acc: 40.62%] [G loss: 0.857539]\n",
      "epoch:21 step:17148[D loss: 0.402370, acc: 69.53%, op_acc: 36.72%] [G loss: 0.884184]\n",
      "epoch:21 step:17149[D loss: 0.446447, acc: 51.56%, op_acc: 37.50%] [G loss: 0.813210]\n",
      "epoch:21 step:17150[D loss: 0.457123, acc: 54.69%, op_acc: 37.50%] [G loss: 0.853971]\n",
      "##############\n",
      "[0.86037113 0.84467102 0.81381923 0.79498644 0.7869536  0.82303601\n",
      " 0.91168806 0.83002181 0.81738236 0.8320216 ]\n",
      "##########\n",
      "epoch:21 step:17151[D loss: 0.459128, acc: 52.34%, op_acc: 33.59%] [G loss: 0.868788]\n",
      "epoch:21 step:17152[D loss: 0.465377, acc: 56.25%, op_acc: 29.69%] [G loss: 0.862326]\n",
      "epoch:21 step:17153[D loss: 0.450698, acc: 55.47%, op_acc: 38.28%] [G loss: 0.880324]\n",
      "epoch:21 step:17154[D loss: 0.404907, acc: 64.06%, op_acc: 39.06%] [G loss: 0.908084]\n",
      "epoch:21 step:17155[D loss: 0.415631, acc: 64.06%, op_acc: 44.53%] [G loss: 0.952513]\n",
      "epoch:21 step:17156[D loss: 0.397625, acc: 62.50%, op_acc: 44.53%] [G loss: 0.886373]\n",
      "epoch:21 step:17157[D loss: 0.406144, acc: 60.94%, op_acc: 42.97%] [G loss: 0.946545]\n",
      "epoch:21 step:17158[D loss: 0.422988, acc: 60.94%, op_acc: 39.84%] [G loss: 0.879894]\n",
      "epoch:21 step:17159[D loss: 0.412024, acc: 59.38%, op_acc: 36.72%] [G loss: 0.938487]\n",
      "epoch:21 step:17160[D loss: 0.411624, acc: 64.06%, op_acc: 42.97%] [G loss: 0.924009]\n",
      "epoch:21 step:17161[D loss: 0.425734, acc: 55.47%, op_acc: 42.97%] [G loss: 0.944194]\n",
      "epoch:21 step:17162[D loss: 0.412357, acc: 60.94%, op_acc: 42.97%] [G loss: 0.959715]\n",
      "epoch:21 step:17163[D loss: 0.447883, acc: 57.03%, op_acc: 41.41%] [G loss: 0.860425]\n",
      "epoch:21 step:17164[D loss: 0.454802, acc: 53.91%, op_acc: 39.06%] [G loss: 0.883555]\n",
      "epoch:21 step:17165[D loss: 0.414735, acc: 57.81%, op_acc: 40.62%] [G loss: 0.878366]\n",
      "epoch:21 step:17166[D loss: 0.425686, acc: 62.50%, op_acc: 42.97%] [G loss: 0.908178]\n",
      "epoch:21 step:17167[D loss: 0.425477, acc: 63.28%, op_acc: 37.50%] [G loss: 0.923639]\n",
      "epoch:21 step:17168[D loss: 0.409974, acc: 59.38%, op_acc: 42.97%] [G loss: 0.925798]\n",
      "epoch:21 step:17169[D loss: 0.404873, acc: 61.72%, op_acc: 37.50%] [G loss: 0.911512]\n",
      "epoch:21 step:17170[D loss: 0.402857, acc: 57.03%, op_acc: 43.75%] [G loss: 0.811901]\n",
      "epoch:21 step:17171[D loss: 0.390924, acc: 67.19%, op_acc: 44.53%] [G loss: 0.948542]\n",
      "epoch:21 step:17172[D loss: 0.466500, acc: 55.47%, op_acc: 35.16%] [G loss: 0.914616]\n",
      "epoch:21 step:17173[D loss: 0.427033, acc: 65.62%, op_acc: 39.84%] [G loss: 0.888651]\n",
      "epoch:21 step:17174[D loss: 0.438093, acc: 67.19%, op_acc: 34.38%] [G loss: 0.796339]\n",
      "epoch:21 step:17175[D loss: 0.421890, acc: 58.59%, op_acc: 42.19%] [G loss: 0.898476]\n",
      "epoch:21 step:17176[D loss: 0.434041, acc: 62.50%, op_acc: 41.41%] [G loss: 0.874459]\n",
      "epoch:21 step:17177[D loss: 0.406631, acc: 64.84%, op_acc: 41.41%] [G loss: 0.950252]\n",
      "epoch:21 step:17178[D loss: 0.442679, acc: 60.16%, op_acc: 38.28%] [G loss: 0.883631]\n",
      "epoch:21 step:17179[D loss: 0.443978, acc: 57.03%, op_acc: 41.41%] [G loss: 0.885317]\n",
      "epoch:21 step:17180[D loss: 0.411245, acc: 62.50%, op_acc: 39.06%] [G loss: 0.947080]\n",
      "epoch:21 step:17181[D loss: 0.425794, acc: 55.47%, op_acc: 42.19%] [G loss: 0.875262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17182[D loss: 0.426708, acc: 62.50%, op_acc: 36.72%] [G loss: 0.824694]\n",
      "epoch:22 step:17183[D loss: 0.419558, acc: 51.56%, op_acc: 45.31%] [G loss: 0.904016]\n",
      "epoch:22 step:17184[D loss: 0.430034, acc: 57.03%, op_acc: 41.41%] [G loss: 0.937249]\n",
      "epoch:22 step:17185[D loss: 0.437428, acc: 61.72%, op_acc: 42.97%] [G loss: 0.849829]\n",
      "epoch:22 step:17186[D loss: 0.422696, acc: 53.12%, op_acc: 42.97%] [G loss: 0.843870]\n",
      "epoch:22 step:17187[D loss: 0.420733, acc: 54.69%, op_acc: 42.97%] [G loss: 0.907572]\n",
      "epoch:22 step:17188[D loss: 0.427030, acc: 58.59%, op_acc: 35.94%] [G loss: 0.848121]\n",
      "epoch:22 step:17189[D loss: 0.441770, acc: 57.81%, op_acc: 39.06%] [G loss: 0.925712]\n",
      "epoch:22 step:17190[D loss: 0.417248, acc: 60.94%, op_acc: 39.06%] [G loss: 0.829079]\n",
      "epoch:22 step:17191[D loss: 0.405103, acc: 58.59%, op_acc: 45.31%] [G loss: 0.905582]\n",
      "epoch:22 step:17192[D loss: 0.436283, acc: 60.16%, op_acc: 35.16%] [G loss: 0.917340]\n",
      "epoch:22 step:17193[D loss: 0.462432, acc: 55.47%, op_acc: 37.50%] [G loss: 0.830011]\n",
      "epoch:22 step:17194[D loss: 0.443380, acc: 51.56%, op_acc: 36.72%] [G loss: 0.798749]\n",
      "epoch:22 step:17195[D loss: 0.429363, acc: 60.16%, op_acc: 35.94%] [G loss: 0.882738]\n",
      "epoch:22 step:17196[D loss: 0.449856, acc: 57.03%, op_acc: 36.72%] [G loss: 0.866500]\n",
      "epoch:22 step:17197[D loss: 0.415020, acc: 64.84%, op_acc: 39.06%] [G loss: 0.872482]\n",
      "epoch:22 step:17198[D loss: 0.421250, acc: 54.69%, op_acc: 42.19%] [G loss: 0.901143]\n",
      "epoch:22 step:17199[D loss: 0.430543, acc: 57.03%, op_acc: 40.62%] [G loss: 0.808334]\n",
      "epoch:22 step:17200[D loss: 0.419481, acc: 63.28%, op_acc: 36.72%] [G loss: 0.847915]\n",
      "##############\n",
      "[0.84810222 0.88112235 0.83063882 0.80188232 0.79808754 0.82574225\n",
      " 0.85930145 0.81295406 0.80494064 0.83017008]\n",
      "##########\n",
      "epoch:22 step:17201[D loss: 0.400011, acc: 60.94%, op_acc: 39.84%] [G loss: 0.837459]\n",
      "epoch:22 step:17202[D loss: 0.426655, acc: 53.12%, op_acc: 39.84%] [G loss: 0.855705]\n",
      "epoch:22 step:17203[D loss: 0.438927, acc: 54.69%, op_acc: 39.06%] [G loss: 0.913682]\n",
      "epoch:22 step:17204[D loss: 0.395510, acc: 67.97%, op_acc: 40.62%] [G loss: 0.898966]\n",
      "epoch:22 step:17205[D loss: 0.425780, acc: 60.94%, op_acc: 45.31%] [G loss: 0.911132]\n",
      "epoch:22 step:17206[D loss: 0.429616, acc: 64.06%, op_acc: 36.72%] [G loss: 0.841199]\n",
      "epoch:22 step:17207[D loss: 0.432378, acc: 59.38%, op_acc: 38.28%] [G loss: 0.859421]\n",
      "epoch:22 step:17208[D loss: 0.436437, acc: 53.12%, op_acc: 38.28%] [G loss: 0.890961]\n",
      "epoch:22 step:17209[D loss: 0.416894, acc: 57.03%, op_acc: 41.41%] [G loss: 0.918616]\n",
      "epoch:22 step:17210[D loss: 0.414101, acc: 56.25%, op_acc: 40.62%] [G loss: 0.897339]\n",
      "epoch:22 step:17211[D loss: 0.400119, acc: 68.75%, op_acc: 42.19%] [G loss: 0.875623]\n",
      "epoch:22 step:17212[D loss: 0.399695, acc: 63.28%, op_acc: 43.75%] [G loss: 0.958337]\n",
      "epoch:22 step:17213[D loss: 0.426576, acc: 64.06%, op_acc: 37.50%] [G loss: 0.991253]\n",
      "epoch:22 step:17214[D loss: 0.423747, acc: 64.06%, op_acc: 39.06%] [G loss: 0.957155]\n",
      "epoch:22 step:17215[D loss: 0.414441, acc: 64.06%, op_acc: 46.09%] [G loss: 0.870596]\n",
      "epoch:22 step:17216[D loss: 0.411191, acc: 62.50%, op_acc: 39.84%] [G loss: 0.784031]\n",
      "epoch:22 step:17217[D loss: 0.422291, acc: 59.38%, op_acc: 34.38%] [G loss: 0.765589]\n",
      "epoch:22 step:17218[D loss: 0.432696, acc: 54.69%, op_acc: 36.72%] [G loss: 0.858704]\n",
      "epoch:22 step:17219[D loss: 0.398484, acc: 65.62%, op_acc: 42.19%] [G loss: 0.859819]\n",
      "epoch:22 step:17220[D loss: 0.414405, acc: 61.72%, op_acc: 40.62%] [G loss: 0.897079]\n",
      "epoch:22 step:17221[D loss: 0.415744, acc: 54.69%, op_acc: 43.75%] [G loss: 0.819547]\n",
      "epoch:22 step:17222[D loss: 0.453970, acc: 53.91%, op_acc: 37.50%] [G loss: 0.868521]\n",
      "epoch:22 step:17223[D loss: 0.412046, acc: 60.94%, op_acc: 40.62%] [G loss: 0.844110]\n",
      "epoch:22 step:17224[D loss: 0.377198, acc: 65.62%, op_acc: 50.00%] [G loss: 0.939896]\n",
      "epoch:22 step:17225[D loss: 0.422417, acc: 60.94%, op_acc: 35.94%] [G loss: 0.866284]\n",
      "epoch:22 step:17226[D loss: 0.436738, acc: 53.91%, op_acc: 41.41%] [G loss: 0.935867]\n",
      "epoch:22 step:17227[D loss: 0.409154, acc: 60.94%, op_acc: 44.53%] [G loss: 0.821067]\n",
      "epoch:22 step:17228[D loss: 0.415095, acc: 60.94%, op_acc: 36.72%] [G loss: 0.892595]\n",
      "epoch:22 step:17229[D loss: 0.440745, acc: 56.25%, op_acc: 36.72%] [G loss: 0.852491]\n",
      "epoch:22 step:17230[D loss: 0.422166, acc: 62.50%, op_acc: 35.94%] [G loss: 0.911393]\n",
      "epoch:22 step:17231[D loss: 0.428379, acc: 60.16%, op_acc: 35.16%] [G loss: 0.869667]\n",
      "epoch:22 step:17232[D loss: 0.436271, acc: 57.03%, op_acc: 35.94%] [G loss: 0.865154]\n",
      "epoch:22 step:17233[D loss: 0.409999, acc: 64.84%, op_acc: 35.16%] [G loss: 0.884770]\n",
      "epoch:22 step:17234[D loss: 0.424082, acc: 60.16%, op_acc: 37.50%] [G loss: 0.907481]\n",
      "epoch:22 step:17235[D loss: 0.423626, acc: 56.25%, op_acc: 35.16%] [G loss: 0.906967]\n",
      "epoch:22 step:17236[D loss: 0.432189, acc: 64.06%, op_acc: 43.75%] [G loss: 0.931467]\n",
      "epoch:22 step:17237[D loss: 0.393303, acc: 61.72%, op_acc: 38.28%] [G loss: 0.913413]\n",
      "epoch:22 step:17238[D loss: 0.439277, acc: 56.25%, op_acc: 37.50%] [G loss: 0.923719]\n",
      "epoch:22 step:17239[D loss: 0.431617, acc: 56.25%, op_acc: 39.84%] [G loss: 0.828230]\n",
      "epoch:22 step:17240[D loss: 0.430291, acc: 53.91%, op_acc: 44.53%] [G loss: 0.874034]\n",
      "epoch:22 step:17241[D loss: 0.384416, acc: 65.62%, op_acc: 43.75%] [G loss: 0.875767]\n",
      "epoch:22 step:17242[D loss: 0.436623, acc: 60.94%, op_acc: 32.03%] [G loss: 0.909648]\n",
      "epoch:22 step:17243[D loss: 0.429872, acc: 59.38%, op_acc: 42.19%] [G loss: 0.888438]\n",
      "epoch:22 step:17244[D loss: 0.429191, acc: 53.91%, op_acc: 38.28%] [G loss: 0.855283]\n",
      "epoch:22 step:17245[D loss: 0.442544, acc: 53.12%, op_acc: 35.16%] [G loss: 0.844284]\n",
      "epoch:22 step:17246[D loss: 0.419414, acc: 54.69%, op_acc: 43.75%] [G loss: 0.920933]\n",
      "epoch:22 step:17247[D loss: 0.446210, acc: 50.78%, op_acc: 32.81%] [G loss: 0.860309]\n",
      "epoch:22 step:17248[D loss: 0.404850, acc: 64.84%, op_acc: 39.84%] [G loss: 0.899626]\n",
      "epoch:22 step:17249[D loss: 0.415581, acc: 56.25%, op_acc: 41.41%] [G loss: 0.830697]\n",
      "epoch:22 step:17250[D loss: 0.432364, acc: 55.47%, op_acc: 39.84%] [G loss: 0.880315]\n",
      "##############\n",
      "[0.87276514 0.86430551 0.82785751 0.81510713 0.82168455 0.83343672\n",
      " 0.89725915 0.80734093 0.8175486  0.82030564]\n",
      "##########\n",
      "epoch:22 step:17251[D loss: 0.371787, acc: 67.19%, op_acc: 46.88%] [G loss: 0.857111]\n",
      "epoch:22 step:17252[D loss: 0.410465, acc: 57.81%, op_acc: 41.41%] [G loss: 0.866024]\n",
      "epoch:22 step:17253[D loss: 0.460678, acc: 54.69%, op_acc: 32.03%] [G loss: 0.899810]\n",
      "epoch:22 step:17254[D loss: 0.408103, acc: 57.81%, op_acc: 37.50%] [G loss: 0.907325]\n",
      "epoch:22 step:17255[D loss: 0.418277, acc: 54.69%, op_acc: 40.62%] [G loss: 0.858275]\n",
      "epoch:22 step:17256[D loss: 0.413534, acc: 56.25%, op_acc: 42.19%] [G loss: 0.786371]\n",
      "epoch:22 step:17257[D loss: 0.430960, acc: 62.50%, op_acc: 37.50%] [G loss: 0.877554]\n",
      "epoch:22 step:17258[D loss: 0.455806, acc: 50.78%, op_acc: 44.53%] [G loss: 0.860771]\n",
      "epoch:22 step:17259[D loss: 0.428237, acc: 58.59%, op_acc: 34.38%] [G loss: 0.893596]\n",
      "epoch:22 step:17260[D loss: 0.444116, acc: 51.56%, op_acc: 34.38%] [G loss: 0.827095]\n",
      "epoch:22 step:17261[D loss: 0.424584, acc: 58.59%, op_acc: 36.72%] [G loss: 0.795989]\n",
      "epoch:22 step:17262[D loss: 0.438861, acc: 60.16%, op_acc: 33.59%] [G loss: 0.873545]\n",
      "epoch:22 step:17263[D loss: 0.460189, acc: 54.69%, op_acc: 33.59%] [G loss: 0.944617]\n",
      "epoch:22 step:17264[D loss: 0.423619, acc: 53.91%, op_acc: 41.41%] [G loss: 0.872851]\n",
      "epoch:22 step:17265[D loss: 0.428449, acc: 61.72%, op_acc: 35.94%] [G loss: 0.861173]\n",
      "epoch:22 step:17266[D loss: 0.412315, acc: 63.28%, op_acc: 38.28%] [G loss: 0.876964]\n",
      "epoch:22 step:17267[D loss: 0.416415, acc: 60.94%, op_acc: 34.38%] [G loss: 0.957253]\n",
      "epoch:22 step:17268[D loss: 0.407016, acc: 61.72%, op_acc: 46.09%] [G loss: 0.841636]\n",
      "epoch:22 step:17269[D loss: 0.415820, acc: 62.50%, op_acc: 35.94%] [G loss: 0.942476]\n",
      "epoch:22 step:17270[D loss: 0.405326, acc: 68.75%, op_acc: 36.72%] [G loss: 0.953577]\n",
      "epoch:22 step:17271[D loss: 0.450697, acc: 54.69%, op_acc: 34.38%] [G loss: 0.925788]\n",
      "epoch:22 step:17272[D loss: 0.423350, acc: 58.59%, op_acc: 37.50%] [G loss: 0.900462]\n",
      "epoch:22 step:17273[D loss: 0.397612, acc: 68.75%, op_acc: 42.19%] [G loss: 0.879282]\n",
      "epoch:22 step:17274[D loss: 0.453674, acc: 58.59%, op_acc: 33.59%] [G loss: 0.829602]\n",
      "epoch:22 step:17275[D loss: 0.396869, acc: 64.84%, op_acc: 38.28%] [G loss: 0.903103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17276[D loss: 0.410211, acc: 59.38%, op_acc: 41.41%] [G loss: 0.868446]\n",
      "epoch:22 step:17277[D loss: 0.428781, acc: 55.47%, op_acc: 38.28%] [G loss: 0.889643]\n",
      "epoch:22 step:17278[D loss: 0.441243, acc: 50.78%, op_acc: 36.72%] [G loss: 0.878647]\n",
      "epoch:22 step:17279[D loss: 0.425115, acc: 56.25%, op_acc: 38.28%] [G loss: 0.805500]\n",
      "epoch:22 step:17280[D loss: 0.434366, acc: 60.16%, op_acc: 32.81%] [G loss: 0.927939]\n",
      "epoch:22 step:17281[D loss: 0.430219, acc: 56.25%, op_acc: 39.84%] [G loss: 0.798428]\n",
      "epoch:22 step:17282[D loss: 0.414553, acc: 55.47%, op_acc: 39.84%] [G loss: 0.886892]\n",
      "epoch:22 step:17283[D loss: 0.408741, acc: 64.06%, op_acc: 38.28%] [G loss: 0.836425]\n",
      "epoch:22 step:17284[D loss: 0.454808, acc: 60.16%, op_acc: 31.25%] [G loss: 0.774263]\n",
      "epoch:22 step:17285[D loss: 0.446720, acc: 54.69%, op_acc: 35.16%] [G loss: 0.885563]\n",
      "epoch:22 step:17286[D loss: 0.409170, acc: 63.28%, op_acc: 39.84%] [G loss: 0.874509]\n",
      "epoch:22 step:17287[D loss: 0.441092, acc: 53.12%, op_acc: 40.62%] [G loss: 0.900155]\n",
      "epoch:22 step:17288[D loss: 0.429430, acc: 56.25%, op_acc: 41.41%] [G loss: 0.883703]\n",
      "epoch:22 step:17289[D loss: 0.421992, acc: 60.16%, op_acc: 38.28%] [G loss: 0.943712]\n",
      "epoch:22 step:17290[D loss: 0.464060, acc: 55.47%, op_acc: 37.50%] [G loss: 0.885427]\n",
      "epoch:22 step:17291[D loss: 0.414568, acc: 60.16%, op_acc: 40.62%] [G loss: 0.924011]\n",
      "epoch:22 step:17292[D loss: 0.434974, acc: 53.12%, op_acc: 39.06%] [G loss: 0.895360]\n",
      "epoch:22 step:17293[D loss: 0.430867, acc: 64.06%, op_acc: 35.16%] [G loss: 0.870257]\n",
      "epoch:22 step:17294[D loss: 0.399803, acc: 64.06%, op_acc: 43.75%] [G loss: 0.877243]\n",
      "epoch:22 step:17295[D loss: 0.436248, acc: 56.25%, op_acc: 38.28%] [G loss: 0.902397]\n",
      "epoch:22 step:17296[D loss: 0.385979, acc: 64.06%, op_acc: 48.44%] [G loss: 0.919979]\n",
      "epoch:22 step:17297[D loss: 0.406082, acc: 63.28%, op_acc: 41.41%] [G loss: 0.868449]\n",
      "epoch:22 step:17298[D loss: 0.425165, acc: 60.94%, op_acc: 42.19%] [G loss: 0.918521]\n",
      "epoch:22 step:17299[D loss: 0.415223, acc: 60.16%, op_acc: 39.84%] [G loss: 0.847568]\n",
      "epoch:22 step:17300[D loss: 0.439571, acc: 56.25%, op_acc: 34.38%] [G loss: 0.899606]\n",
      "##############\n",
      "[0.86518507 0.87696759 0.81483097 0.81839323 0.79941046 0.80771054\n",
      " 0.87286291 0.80781232 0.81623681 0.81589335]\n",
      "##########\n",
      "epoch:22 step:17301[D loss: 0.416866, acc: 57.81%, op_acc: 38.28%] [G loss: 0.901898]\n",
      "epoch:22 step:17302[D loss: 0.428581, acc: 62.50%, op_acc: 38.28%] [G loss: 0.888047]\n",
      "epoch:22 step:17303[D loss: 0.421044, acc: 64.84%, op_acc: 39.84%] [G loss: 0.887464]\n",
      "epoch:22 step:17304[D loss: 0.448277, acc: 50.78%, op_acc: 39.06%] [G loss: 0.905286]\n",
      "epoch:22 step:17305[D loss: 0.435709, acc: 56.25%, op_acc: 39.06%] [G loss: 0.902927]\n",
      "epoch:22 step:17306[D loss: 0.410372, acc: 64.84%, op_acc: 34.38%] [G loss: 0.870918]\n",
      "epoch:22 step:17307[D loss: 0.428359, acc: 63.28%, op_acc: 36.72%] [G loss: 0.963371]\n",
      "epoch:22 step:17308[D loss: 0.427040, acc: 54.69%, op_acc: 42.19%] [G loss: 0.894943]\n",
      "epoch:22 step:17309[D loss: 0.424938, acc: 68.75%, op_acc: 35.94%] [G loss: 0.887057]\n",
      "epoch:22 step:17310[D loss: 0.424805, acc: 57.03%, op_acc: 43.75%] [G loss: 0.956204]\n",
      "epoch:22 step:17311[D loss: 0.463662, acc: 55.47%, op_acc: 33.59%] [G loss: 0.843633]\n",
      "epoch:22 step:17312[D loss: 0.396412, acc: 64.06%, op_acc: 42.97%] [G loss: 0.932167]\n",
      "epoch:22 step:17313[D loss: 0.416578, acc: 61.72%, op_acc: 39.06%] [G loss: 0.821103]\n",
      "epoch:22 step:17314[D loss: 0.411472, acc: 55.47%, op_acc: 45.31%] [G loss: 0.911930]\n",
      "epoch:22 step:17315[D loss: 0.456435, acc: 60.16%, op_acc: 29.69%] [G loss: 1.002872]\n",
      "epoch:22 step:17316[D loss: 0.380904, acc: 71.09%, op_acc: 44.53%] [G loss: 0.929333]\n",
      "epoch:22 step:17317[D loss: 0.452933, acc: 52.34%, op_acc: 37.50%] [G loss: 0.859132]\n",
      "epoch:22 step:17318[D loss: 0.393582, acc: 67.97%, op_acc: 44.53%] [G loss: 0.891847]\n",
      "epoch:22 step:17319[D loss: 0.419001, acc: 64.84%, op_acc: 35.94%] [G loss: 0.971059]\n",
      "epoch:22 step:17320[D loss: 0.440414, acc: 57.03%, op_acc: 33.59%] [G loss: 0.807879]\n",
      "epoch:22 step:17321[D loss: 0.430099, acc: 55.47%, op_acc: 43.75%] [G loss: 0.899463]\n",
      "epoch:22 step:17322[D loss: 0.436210, acc: 53.91%, op_acc: 38.28%] [G loss: 0.831203]\n",
      "epoch:22 step:17323[D loss: 0.446893, acc: 60.16%, op_acc: 33.59%] [G loss: 0.880646]\n",
      "epoch:22 step:17324[D loss: 0.456667, acc: 50.78%, op_acc: 36.72%] [G loss: 0.829146]\n",
      "epoch:22 step:17325[D loss: 0.425409, acc: 59.38%, op_acc: 37.50%] [G loss: 0.891583]\n",
      "epoch:22 step:17326[D loss: 0.425085, acc: 60.94%, op_acc: 36.72%] [G loss: 0.833251]\n",
      "epoch:22 step:17327[D loss: 0.423255, acc: 63.28%, op_acc: 39.84%] [G loss: 0.887381]\n",
      "epoch:22 step:17328[D loss: 0.403550, acc: 66.41%, op_acc: 40.62%] [G loss: 0.891304]\n",
      "epoch:22 step:17329[D loss: 0.424965, acc: 56.25%, op_acc: 39.84%] [G loss: 0.852584]\n",
      "epoch:22 step:17330[D loss: 0.416376, acc: 67.97%, op_acc: 36.72%] [G loss: 0.908246]\n",
      "epoch:22 step:17331[D loss: 0.404241, acc: 66.41%, op_acc: 38.28%] [G loss: 0.822882]\n",
      "epoch:22 step:17332[D loss: 0.431180, acc: 58.59%, op_acc: 39.84%] [G loss: 0.854142]\n",
      "epoch:22 step:17333[D loss: 0.422997, acc: 55.47%, op_acc: 42.97%] [G loss: 0.904256]\n",
      "epoch:22 step:17334[D loss: 0.426534, acc: 50.78%, op_acc: 46.09%] [G loss: 0.913332]\n",
      "epoch:22 step:17335[D loss: 0.437071, acc: 61.72%, op_acc: 28.91%] [G loss: 0.934320]\n",
      "epoch:22 step:17336[D loss: 0.430310, acc: 54.69%, op_acc: 36.72%] [G loss: 0.864529]\n",
      "epoch:22 step:17337[D loss: 0.461483, acc: 53.12%, op_acc: 37.50%] [G loss: 0.760336]\n",
      "epoch:22 step:17338[D loss: 0.455496, acc: 53.12%, op_acc: 37.50%] [G loss: 0.785482]\n",
      "epoch:22 step:17339[D loss: 0.391786, acc: 66.41%, op_acc: 39.84%] [G loss: 0.870937]\n",
      "epoch:22 step:17340[D loss: 0.418372, acc: 58.59%, op_acc: 39.84%] [G loss: 0.834186]\n",
      "epoch:22 step:17341[D loss: 0.421056, acc: 64.06%, op_acc: 42.19%] [G loss: 0.843320]\n",
      "epoch:22 step:17342[D loss: 0.448638, acc: 60.94%, op_acc: 35.94%] [G loss: 0.982932]\n",
      "epoch:22 step:17343[D loss: 0.425838, acc: 63.28%, op_acc: 39.84%] [G loss: 0.873380]\n",
      "epoch:22 step:17344[D loss: 0.432089, acc: 60.16%, op_acc: 34.38%] [G loss: 0.816897]\n",
      "epoch:22 step:17345[D loss: 0.420943, acc: 59.38%, op_acc: 34.38%] [G loss: 0.888382]\n",
      "epoch:22 step:17346[D loss: 0.427606, acc: 59.38%, op_acc: 35.16%] [G loss: 0.877205]\n",
      "epoch:22 step:17347[D loss: 0.394127, acc: 62.50%, op_acc: 42.19%] [G loss: 0.888166]\n",
      "epoch:22 step:17348[D loss: 0.433915, acc: 62.50%, op_acc: 39.84%] [G loss: 0.858180]\n",
      "epoch:22 step:17349[D loss: 0.416285, acc: 59.38%, op_acc: 40.62%] [G loss: 0.926019]\n",
      "epoch:22 step:17350[D loss: 0.418899, acc: 49.22%, op_acc: 45.31%] [G loss: 0.898366]\n",
      "##############\n",
      "[0.86636304 0.86464231 0.80368475 0.80725632 0.78504614 0.83496495\n",
      " 0.88701783 0.81710146 0.79627094 0.83229871]\n",
      "##########\n",
      "epoch:22 step:17351[D loss: 0.441566, acc: 58.59%, op_acc: 36.72%] [G loss: 0.874317]\n",
      "epoch:22 step:17352[D loss: 0.438575, acc: 59.38%, op_acc: 37.50%] [G loss: 0.870902]\n",
      "epoch:22 step:17353[D loss: 0.439859, acc: 61.72%, op_acc: 35.16%] [G loss: 0.923296]\n",
      "epoch:22 step:17354[D loss: 0.401288, acc: 65.62%, op_acc: 40.62%] [G loss: 0.910174]\n",
      "epoch:22 step:17355[D loss: 0.450714, acc: 51.56%, op_acc: 35.94%] [G loss: 0.836368]\n",
      "epoch:22 step:17356[D loss: 0.476190, acc: 45.31%, op_acc: 32.81%] [G loss: 0.831305]\n",
      "epoch:22 step:17357[D loss: 0.423024, acc: 66.41%, op_acc: 38.28%] [G loss: 0.889522]\n",
      "epoch:22 step:17358[D loss: 0.434008, acc: 57.81%, op_acc: 38.28%] [G loss: 0.886320]\n",
      "epoch:22 step:17359[D loss: 0.414796, acc: 64.84%, op_acc: 33.59%] [G loss: 0.904600]\n",
      "epoch:22 step:17360[D loss: 0.403446, acc: 64.84%, op_acc: 40.62%] [G loss: 0.868237]\n",
      "epoch:22 step:17361[D loss: 0.423048, acc: 59.38%, op_acc: 41.41%] [G loss: 0.885804]\n",
      "epoch:22 step:17362[D loss: 0.443329, acc: 50.00%, op_acc: 34.38%] [G loss: 0.922580]\n",
      "epoch:22 step:17363[D loss: 0.417232, acc: 63.28%, op_acc: 33.59%] [G loss: 0.886509]\n",
      "epoch:22 step:17364[D loss: 0.410283, acc: 61.72%, op_acc: 46.09%] [G loss: 0.896765]\n",
      "epoch:22 step:17365[D loss: 0.420817, acc: 57.03%, op_acc: 41.41%] [G loss: 0.869949]\n",
      "epoch:22 step:17366[D loss: 0.452206, acc: 52.34%, op_acc: 38.28%] [G loss: 0.891211]\n",
      "epoch:22 step:17367[D loss: 0.419520, acc: 60.94%, op_acc: 36.72%] [G loss: 0.924474]\n",
      "epoch:22 step:17368[D loss: 0.408367, acc: 64.06%, op_acc: 41.41%] [G loss: 0.985864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17369[D loss: 0.438669, acc: 55.47%, op_acc: 39.06%] [G loss: 0.898878]\n",
      "epoch:22 step:17370[D loss: 0.438599, acc: 54.69%, op_acc: 39.84%] [G loss: 1.019747]\n",
      "epoch:22 step:17371[D loss: 0.425544, acc: 55.47%, op_acc: 39.06%] [G loss: 0.982165]\n",
      "epoch:22 step:17372[D loss: 0.460388, acc: 58.59%, op_acc: 33.59%] [G loss: 0.986282]\n",
      "epoch:22 step:17373[D loss: 0.415353, acc: 60.94%, op_acc: 36.72%] [G loss: 0.906051]\n",
      "epoch:22 step:17374[D loss: 0.393044, acc: 64.06%, op_acc: 40.62%] [G loss: 0.878290]\n",
      "epoch:22 step:17375[D loss: 0.470911, acc: 50.00%, op_acc: 31.25%] [G loss: 0.959386]\n",
      "epoch:22 step:17376[D loss: 0.398485, acc: 65.62%, op_acc: 39.84%] [G loss: 0.864694]\n",
      "epoch:22 step:17377[D loss: 0.435534, acc: 63.28%, op_acc: 34.38%] [G loss: 0.942578]\n",
      "epoch:22 step:17378[D loss: 0.381853, acc: 72.66%, op_acc: 40.62%] [G loss: 0.906309]\n",
      "epoch:22 step:17379[D loss: 0.408916, acc: 65.62%, op_acc: 36.72%] [G loss: 0.804261]\n",
      "epoch:22 step:17380[D loss: 0.390343, acc: 69.53%, op_acc: 42.19%] [G loss: 0.938391]\n",
      "epoch:22 step:17381[D loss: 0.422433, acc: 64.84%, op_acc: 41.41%] [G loss: 0.904055]\n",
      "epoch:22 step:17382[D loss: 0.387047, acc: 69.53%, op_acc: 44.53%] [G loss: 0.898257]\n",
      "epoch:22 step:17383[D loss: 0.422136, acc: 51.56%, op_acc: 39.84%] [G loss: 0.791316]\n",
      "epoch:22 step:17384[D loss: 0.439427, acc: 53.12%, op_acc: 37.50%] [G loss: 0.960322]\n",
      "epoch:22 step:17385[D loss: 0.446623, acc: 57.81%, op_acc: 36.72%] [G loss: 0.904843]\n",
      "epoch:22 step:17386[D loss: 0.421478, acc: 56.25%, op_acc: 38.28%] [G loss: 0.902959]\n",
      "epoch:22 step:17387[D loss: 0.446619, acc: 57.03%, op_acc: 39.06%] [G loss: 0.916801]\n",
      "epoch:22 step:17388[D loss: 0.423993, acc: 59.38%, op_acc: 41.41%] [G loss: 0.992028]\n",
      "epoch:22 step:17389[D loss: 0.377715, acc: 68.75%, op_acc: 43.75%] [G loss: 0.907573]\n",
      "epoch:22 step:17390[D loss: 0.425003, acc: 56.25%, op_acc: 38.28%] [G loss: 0.942884]\n",
      "epoch:22 step:17391[D loss: 0.409455, acc: 64.06%, op_acc: 42.19%] [G loss: 0.912516]\n",
      "epoch:22 step:17392[D loss: 0.435913, acc: 61.72%, op_acc: 38.28%] [G loss: 0.965810]\n",
      "epoch:22 step:17393[D loss: 0.394660, acc: 61.72%, op_acc: 45.31%] [G loss: 0.927903]\n",
      "epoch:22 step:17394[D loss: 0.432029, acc: 62.50%, op_acc: 44.53%] [G loss: 0.953802]\n",
      "epoch:22 step:17395[D loss: 0.425796, acc: 57.03%, op_acc: 35.16%] [G loss: 0.832056]\n",
      "epoch:22 step:17396[D loss: 0.461470, acc: 60.94%, op_acc: 34.38%] [G loss: 0.880743]\n",
      "epoch:22 step:17397[D loss: 0.439353, acc: 59.38%, op_acc: 39.06%] [G loss: 0.893580]\n",
      "epoch:22 step:17398[D loss: 0.421734, acc: 60.94%, op_acc: 39.06%] [G loss: 0.875638]\n",
      "epoch:22 step:17399[D loss: 0.414142, acc: 57.81%, op_acc: 42.19%] [G loss: 0.874692]\n",
      "epoch:22 step:17400[D loss: 0.419714, acc: 60.16%, op_acc: 42.97%] [G loss: 0.923747]\n",
      "##############\n",
      "[0.84526197 0.86691482 0.80320091 0.80965042 0.82205683 0.81459597\n",
      " 0.89467793 0.82502242 0.80969091 0.83024248]\n",
      "##########\n",
      "epoch:22 step:17401[D loss: 0.426414, acc: 56.25%, op_acc: 42.19%] [G loss: 0.800833]\n",
      "epoch:22 step:17402[D loss: 0.436606, acc: 60.16%, op_acc: 42.97%] [G loss: 0.936928]\n",
      "epoch:22 step:17403[D loss: 0.425825, acc: 62.50%, op_acc: 36.72%] [G loss: 0.862028]\n",
      "epoch:22 step:17404[D loss: 0.418583, acc: 59.38%, op_acc: 40.62%] [G loss: 0.846450]\n",
      "epoch:22 step:17405[D loss: 0.423677, acc: 57.03%, op_acc: 37.50%] [G loss: 0.965767]\n",
      "epoch:22 step:17406[D loss: 0.417086, acc: 59.38%, op_acc: 42.97%] [G loss: 0.912578]\n",
      "epoch:22 step:17407[D loss: 0.426806, acc: 62.50%, op_acc: 40.62%] [G loss: 0.882105]\n",
      "epoch:22 step:17408[D loss: 0.447517, acc: 57.03%, op_acc: 37.50%] [G loss: 0.852314]\n",
      "epoch:22 step:17409[D loss: 0.425253, acc: 55.47%, op_acc: 39.06%] [G loss: 0.818430]\n",
      "epoch:22 step:17410[D loss: 0.418906, acc: 61.72%, op_acc: 39.84%] [G loss: 0.914077]\n",
      "epoch:22 step:17411[D loss: 0.440015, acc: 58.59%, op_acc: 38.28%] [G loss: 0.845219]\n",
      "epoch:22 step:17412[D loss: 0.422464, acc: 65.62%, op_acc: 36.72%] [G loss: 0.812605]\n",
      "epoch:22 step:17413[D loss: 0.402587, acc: 65.62%, op_acc: 46.09%] [G loss: 0.837713]\n",
      "epoch:22 step:17414[D loss: 0.406226, acc: 64.06%, op_acc: 43.75%] [G loss: 0.862723]\n",
      "epoch:22 step:17415[D loss: 0.413840, acc: 68.75%, op_acc: 35.94%] [G loss: 0.857510]\n",
      "epoch:22 step:17416[D loss: 0.473225, acc: 47.66%, op_acc: 36.72%] [G loss: 0.836916]\n",
      "epoch:22 step:17417[D loss: 0.419509, acc: 57.81%, op_acc: 42.97%] [G loss: 0.914625]\n",
      "epoch:22 step:17418[D loss: 0.433480, acc: 63.28%, op_acc: 39.06%] [G loss: 0.925997]\n",
      "epoch:22 step:17419[D loss: 0.418097, acc: 61.72%, op_acc: 39.84%] [G loss: 0.903600]\n",
      "epoch:22 step:17420[D loss: 0.438121, acc: 57.81%, op_acc: 36.72%] [G loss: 0.877750]\n",
      "epoch:22 step:17421[D loss: 0.438446, acc: 58.59%, op_acc: 39.84%] [G loss: 0.817150]\n",
      "epoch:22 step:17422[D loss: 0.426830, acc: 56.25%, op_acc: 38.28%] [G loss: 0.830866]\n",
      "epoch:22 step:17423[D loss: 0.426056, acc: 48.44%, op_acc: 40.62%] [G loss: 0.835657]\n",
      "epoch:22 step:17424[D loss: 0.393213, acc: 73.44%, op_acc: 42.19%] [G loss: 0.897507]\n",
      "epoch:22 step:17425[D loss: 0.413551, acc: 53.91%, op_acc: 42.97%] [G loss: 0.881005]\n",
      "epoch:22 step:17426[D loss: 0.426698, acc: 61.72%, op_acc: 37.50%] [G loss: 0.887920]\n",
      "epoch:22 step:17427[D loss: 0.438940, acc: 56.25%, op_acc: 35.16%] [G loss: 0.845706]\n",
      "epoch:22 step:17428[D loss: 0.427476, acc: 67.19%, op_acc: 34.38%] [G loss: 0.959205]\n",
      "epoch:22 step:17429[D loss: 0.418987, acc: 56.25%, op_acc: 39.06%] [G loss: 0.890998]\n",
      "epoch:22 step:17430[D loss: 0.455470, acc: 56.25%, op_acc: 39.84%] [G loss: 0.810116]\n",
      "epoch:22 step:17431[D loss: 0.394430, acc: 67.97%, op_acc: 46.88%] [G loss: 0.914202]\n",
      "epoch:22 step:17432[D loss: 0.438734, acc: 55.47%, op_acc: 42.19%] [G loss: 0.885983]\n",
      "epoch:22 step:17433[D loss: 0.385077, acc: 68.75%, op_acc: 39.06%] [G loss: 0.860252]\n",
      "epoch:22 step:17434[D loss: 0.403242, acc: 59.38%, op_acc: 42.97%] [G loss: 0.862366]\n",
      "epoch:22 step:17435[D loss: 0.415764, acc: 63.28%, op_acc: 36.72%] [G loss: 0.930871]\n",
      "epoch:22 step:17436[D loss: 0.422434, acc: 61.72%, op_acc: 36.72%] [G loss: 0.830309]\n",
      "epoch:22 step:17437[D loss: 0.432595, acc: 57.81%, op_acc: 33.59%] [G loss: 0.811528]\n",
      "epoch:22 step:17438[D loss: 0.433015, acc: 53.12%, op_acc: 39.84%] [G loss: 0.822806]\n",
      "epoch:22 step:17439[D loss: 0.435834, acc: 58.59%, op_acc: 34.38%] [G loss: 0.897320]\n",
      "epoch:22 step:17440[D loss: 0.408915, acc: 64.06%, op_acc: 43.75%] [G loss: 0.902068]\n",
      "epoch:22 step:17441[D loss: 0.441212, acc: 54.69%, op_acc: 39.06%] [G loss: 0.844459]\n",
      "epoch:22 step:17442[D loss: 0.422024, acc: 57.03%, op_acc: 34.38%] [G loss: 0.887758]\n",
      "epoch:22 step:17443[D loss: 0.402116, acc: 69.53%, op_acc: 42.19%] [G loss: 0.943404]\n",
      "epoch:22 step:17444[D loss: 0.423771, acc: 62.50%, op_acc: 41.41%] [G loss: 0.918291]\n",
      "epoch:22 step:17445[D loss: 0.415893, acc: 58.59%, op_acc: 42.19%] [G loss: 0.919541]\n",
      "epoch:22 step:17446[D loss: 0.419250, acc: 61.72%, op_acc: 38.28%] [G loss: 0.883629]\n",
      "epoch:22 step:17447[D loss: 0.416731, acc: 58.59%, op_acc: 33.59%] [G loss: 0.817246]\n",
      "epoch:22 step:17448[D loss: 0.392724, acc: 63.28%, op_acc: 41.41%] [G loss: 0.970467]\n",
      "epoch:22 step:17449[D loss: 0.446459, acc: 60.16%, op_acc: 33.59%] [G loss: 0.846381]\n",
      "epoch:22 step:17450[D loss: 0.415272, acc: 59.38%, op_acc: 46.09%] [G loss: 0.993551]\n",
      "##############\n",
      "[0.83749346 0.85610358 0.80510936 0.81360662 0.78728163 0.83589219\n",
      " 0.87288822 0.82494744 0.81340691 0.83059568]\n",
      "##########\n",
      "epoch:22 step:17451[D loss: 0.437221, acc: 56.25%, op_acc: 43.75%] [G loss: 0.928615]\n",
      "epoch:22 step:17452[D loss: 0.432125, acc: 58.59%, op_acc: 37.50%] [G loss: 0.899458]\n",
      "epoch:22 step:17453[D loss: 0.432619, acc: 60.94%, op_acc: 36.72%] [G loss: 0.911284]\n",
      "epoch:22 step:17454[D loss: 0.412332, acc: 69.53%, op_acc: 35.94%] [G loss: 0.870983]\n",
      "epoch:22 step:17455[D loss: 0.404861, acc: 66.41%, op_acc: 37.50%] [G loss: 0.953542]\n",
      "epoch:22 step:17456[D loss: 0.440833, acc: 50.78%, op_acc: 38.28%] [G loss: 0.917294]\n",
      "epoch:22 step:17457[D loss: 0.436038, acc: 61.72%, op_acc: 35.94%] [G loss: 0.890920]\n",
      "epoch:22 step:17458[D loss: 0.443263, acc: 56.25%, op_acc: 38.28%] [G loss: 0.890341]\n",
      "epoch:22 step:17459[D loss: 0.440869, acc: 57.81%, op_acc: 31.25%] [G loss: 0.783921]\n",
      "epoch:22 step:17460[D loss: 0.448734, acc: 56.25%, op_acc: 37.50%] [G loss: 0.815549]\n",
      "epoch:22 step:17461[D loss: 0.460161, acc: 49.22%, op_acc: 35.94%] [G loss: 0.796061]\n",
      "epoch:22 step:17462[D loss: 0.412291, acc: 61.72%, op_acc: 46.09%] [G loss: 0.806950]\n",
      "epoch:22 step:17463[D loss: 0.439849, acc: 62.50%, op_acc: 36.72%] [G loss: 0.848578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17464[D loss: 0.465869, acc: 52.34%, op_acc: 32.03%] [G loss: 0.862771]\n",
      "epoch:22 step:17465[D loss: 0.397978, acc: 69.53%, op_acc: 39.06%] [G loss: 0.939388]\n",
      "epoch:22 step:17466[D loss: 0.425679, acc: 55.47%, op_acc: 43.75%] [G loss: 0.908740]\n",
      "epoch:22 step:17467[D loss: 0.456672, acc: 47.66%, op_acc: 36.72%] [G loss: 0.927420]\n",
      "epoch:22 step:17468[D loss: 0.421424, acc: 64.84%, op_acc: 37.50%] [G loss: 0.903470]\n",
      "epoch:22 step:17469[D loss: 0.445855, acc: 57.81%, op_acc: 41.41%] [G loss: 0.911709]\n",
      "epoch:22 step:17470[D loss: 0.395238, acc: 65.62%, op_acc: 40.62%] [G loss: 0.867521]\n",
      "epoch:22 step:17471[D loss: 0.420543, acc: 60.94%, op_acc: 35.16%] [G loss: 0.890573]\n",
      "epoch:22 step:17472[D loss: 0.434846, acc: 59.38%, op_acc: 35.94%] [G loss: 0.918255]\n",
      "epoch:22 step:17473[D loss: 0.437766, acc: 61.72%, op_acc: 35.94%] [G loss: 0.900503]\n",
      "epoch:22 step:17474[D loss: 0.477583, acc: 46.88%, op_acc: 34.38%] [G loss: 0.828843]\n",
      "epoch:22 step:17475[D loss: 0.419906, acc: 58.59%, op_acc: 41.41%] [G loss: 0.915236]\n",
      "epoch:22 step:17476[D loss: 0.399072, acc: 68.75%, op_acc: 41.41%] [G loss: 0.848264]\n",
      "epoch:22 step:17477[D loss: 0.431232, acc: 53.12%, op_acc: 37.50%] [G loss: 0.819935]\n",
      "epoch:22 step:17478[D loss: 0.423273, acc: 57.03%, op_acc: 41.41%] [G loss: 0.874767]\n",
      "epoch:22 step:17479[D loss: 0.421056, acc: 69.53%, op_acc: 35.16%] [G loss: 0.840791]\n",
      "epoch:22 step:17480[D loss: 0.446813, acc: 57.03%, op_acc: 36.72%] [G loss: 0.814868]\n",
      "epoch:22 step:17481[D loss: 0.439756, acc: 56.25%, op_acc: 44.53%] [G loss: 0.856609]\n",
      "epoch:22 step:17482[D loss: 0.444460, acc: 55.47%, op_acc: 35.94%] [G loss: 0.885687]\n",
      "epoch:22 step:17483[D loss: 0.425948, acc: 55.47%, op_acc: 42.97%] [G loss: 0.833768]\n",
      "epoch:22 step:17484[D loss: 0.421025, acc: 55.47%, op_acc: 38.28%] [G loss: 0.804450]\n",
      "epoch:22 step:17485[D loss: 0.452881, acc: 50.00%, op_acc: 35.94%] [G loss: 0.982893]\n",
      "epoch:22 step:17486[D loss: 0.392516, acc: 67.19%, op_acc: 35.94%] [G loss: 0.899836]\n",
      "epoch:22 step:17487[D loss: 0.449488, acc: 55.47%, op_acc: 36.72%] [G loss: 0.902734]\n",
      "epoch:22 step:17488[D loss: 0.471054, acc: 59.38%, op_acc: 29.69%] [G loss: 0.745602]\n",
      "epoch:22 step:17489[D loss: 0.439567, acc: 54.69%, op_acc: 40.62%] [G loss: 0.822531]\n",
      "epoch:22 step:17490[D loss: 0.465140, acc: 53.12%, op_acc: 33.59%] [G loss: 0.874358]\n",
      "epoch:22 step:17491[D loss: 0.443633, acc: 58.59%, op_acc: 31.25%] [G loss: 0.878197]\n",
      "epoch:22 step:17492[D loss: 0.420191, acc: 54.69%, op_acc: 42.97%] [G loss: 0.875374]\n",
      "epoch:22 step:17493[D loss: 0.445466, acc: 57.03%, op_acc: 35.16%] [G loss: 0.892009]\n",
      "epoch:22 step:17494[D loss: 0.444178, acc: 53.91%, op_acc: 41.41%] [G loss: 0.841609]\n",
      "epoch:22 step:17495[D loss: 0.436893, acc: 59.38%, op_acc: 39.06%] [G loss: 0.926594]\n",
      "epoch:22 step:17496[D loss: 0.462020, acc: 49.22%, op_acc: 37.50%] [G loss: 0.866859]\n",
      "epoch:22 step:17497[D loss: 0.435120, acc: 58.59%, op_acc: 36.72%] [G loss: 0.959441]\n",
      "epoch:22 step:17498[D loss: 0.429771, acc: 57.03%, op_acc: 35.16%] [G loss: 0.840570]\n",
      "epoch:22 step:17499[D loss: 0.423367, acc: 64.06%, op_acc: 38.28%] [G loss: 0.909082]\n",
      "epoch:22 step:17500[D loss: 0.444431, acc: 54.69%, op_acc: 36.72%] [G loss: 0.896009]\n",
      "##############\n",
      "[0.85027229 0.86145254 0.81862046 0.81449538 0.80885999 0.8306054\n",
      " 0.89256197 0.82280561 0.79420297 0.82518054]\n",
      "##########\n",
      "epoch:22 step:17501[D loss: 0.420501, acc: 58.59%, op_acc: 36.72%] [G loss: 0.896024]\n",
      "epoch:22 step:17502[D loss: 0.417060, acc: 65.62%, op_acc: 37.50%] [G loss: 0.848426]\n",
      "epoch:22 step:17503[D loss: 0.460258, acc: 57.03%, op_acc: 35.94%] [G loss: 0.836069]\n",
      "epoch:22 step:17504[D loss: 0.424129, acc: 54.69%, op_acc: 41.41%] [G loss: 0.904051]\n",
      "epoch:22 step:17505[D loss: 0.408914, acc: 63.28%, op_acc: 35.94%] [G loss: 0.955309]\n",
      "epoch:22 step:17506[D loss: 0.429350, acc: 62.50%, op_acc: 33.59%] [G loss: 0.850245]\n",
      "epoch:22 step:17507[D loss: 0.403182, acc: 67.97%, op_acc: 38.28%] [G loss: 0.869359]\n",
      "epoch:22 step:17508[D loss: 0.420900, acc: 60.16%, op_acc: 37.50%] [G loss: 0.933541]\n",
      "epoch:22 step:17509[D loss: 0.426157, acc: 60.94%, op_acc: 32.81%] [G loss: 0.900376]\n",
      "epoch:22 step:17510[D loss: 0.446116, acc: 50.78%, op_acc: 39.84%] [G loss: 0.924268]\n",
      "epoch:22 step:17511[D loss: 0.434519, acc: 58.59%, op_acc: 38.28%] [G loss: 0.820619]\n",
      "epoch:22 step:17512[D loss: 0.430228, acc: 60.16%, op_acc: 35.94%] [G loss: 0.837749]\n",
      "epoch:22 step:17513[D loss: 0.416833, acc: 58.59%, op_acc: 41.41%] [G loss: 0.886798]\n",
      "epoch:22 step:17514[D loss: 0.424490, acc: 63.28%, op_acc: 41.41%] [G loss: 0.954273]\n",
      "epoch:22 step:17515[D loss: 0.399373, acc: 67.19%, op_acc: 40.62%] [G loss: 0.930109]\n",
      "epoch:22 step:17516[D loss: 0.406634, acc: 60.94%, op_acc: 42.97%] [G loss: 0.885174]\n",
      "epoch:22 step:17517[D loss: 0.413725, acc: 68.75%, op_acc: 37.50%] [G loss: 0.878233]\n",
      "epoch:22 step:17518[D loss: 0.430877, acc: 64.06%, op_acc: 37.50%] [G loss: 0.887634]\n",
      "epoch:22 step:17519[D loss: 0.447692, acc: 60.16%, op_acc: 30.47%] [G loss: 0.852838]\n",
      "epoch:22 step:17520[D loss: 0.403194, acc: 55.47%, op_acc: 46.88%] [G loss: 0.865560]\n",
      "epoch:22 step:17521[D loss: 0.426230, acc: 58.59%, op_acc: 41.41%] [G loss: 0.919806]\n",
      "epoch:22 step:17522[D loss: 0.393536, acc: 66.41%, op_acc: 36.72%] [G loss: 0.872804]\n",
      "epoch:22 step:17523[D loss: 0.427314, acc: 65.62%, op_acc: 36.72%] [G loss: 0.872041]\n",
      "epoch:22 step:17524[D loss: 0.436867, acc: 56.25%, op_acc: 38.28%] [G loss: 0.866467]\n",
      "epoch:22 step:17525[D loss: 0.436080, acc: 57.81%, op_acc: 39.84%] [G loss: 0.870184]\n",
      "epoch:22 step:17526[D loss: 0.440369, acc: 53.91%, op_acc: 38.28%] [G loss: 0.808738]\n",
      "epoch:22 step:17527[D loss: 0.406720, acc: 66.41%, op_acc: 39.06%] [G loss: 0.886058]\n",
      "epoch:22 step:17528[D loss: 0.432038, acc: 54.69%, op_acc: 35.94%] [G loss: 0.974519]\n",
      "epoch:22 step:17529[D loss: 0.405841, acc: 58.59%, op_acc: 39.06%] [G loss: 0.898595]\n",
      "epoch:22 step:17530[D loss: 0.412795, acc: 66.41%, op_acc: 39.84%] [G loss: 0.902067]\n",
      "epoch:22 step:17531[D loss: 0.400854, acc: 68.75%, op_acc: 42.19%] [G loss: 1.038326]\n",
      "epoch:22 step:17532[D loss: 0.456229, acc: 54.69%, op_acc: 34.38%] [G loss: 0.933246]\n",
      "epoch:22 step:17533[D loss: 0.425851, acc: 60.16%, op_acc: 35.16%] [G loss: 0.877486]\n",
      "epoch:22 step:17534[D loss: 0.413100, acc: 67.97%, op_acc: 38.28%] [G loss: 0.966256]\n",
      "epoch:22 step:17535[D loss: 0.417271, acc: 60.16%, op_acc: 42.19%] [G loss: 0.880975]\n",
      "epoch:22 step:17536[D loss: 0.392172, acc: 70.31%, op_acc: 39.06%] [G loss: 0.907412]\n",
      "epoch:22 step:17537[D loss: 0.417273, acc: 58.59%, op_acc: 37.50%] [G loss: 0.904640]\n",
      "epoch:22 step:17538[D loss: 0.441812, acc: 57.81%, op_acc: 41.41%] [G loss: 0.889760]\n",
      "epoch:22 step:17539[D loss: 0.412135, acc: 67.19%, op_acc: 38.28%] [G loss: 0.892575]\n",
      "epoch:22 step:17540[D loss: 0.441570, acc: 56.25%, op_acc: 41.41%] [G loss: 0.882534]\n",
      "epoch:22 step:17541[D loss: 0.425134, acc: 53.91%, op_acc: 35.94%] [G loss: 0.843576]\n",
      "epoch:22 step:17542[D loss: 0.420564, acc: 62.50%, op_acc: 33.59%] [G loss: 0.934200]\n",
      "epoch:22 step:17543[D loss: 0.425565, acc: 57.81%, op_acc: 37.50%] [G loss: 0.829897]\n",
      "epoch:22 step:17544[D loss: 0.402101, acc: 61.72%, op_acc: 42.19%] [G loss: 0.953979]\n",
      "epoch:22 step:17545[D loss: 0.410322, acc: 64.84%, op_acc: 43.75%] [G loss: 0.933389]\n",
      "epoch:22 step:17546[D loss: 0.425195, acc: 60.94%, op_acc: 32.81%] [G loss: 0.930126]\n",
      "epoch:22 step:17547[D loss: 0.383971, acc: 68.75%, op_acc: 43.75%] [G loss: 0.915725]\n",
      "epoch:22 step:17548[D loss: 0.439504, acc: 53.91%, op_acc: 35.94%] [G loss: 0.857183]\n",
      "epoch:22 step:17549[D loss: 0.433861, acc: 62.50%, op_acc: 35.94%] [G loss: 0.932728]\n",
      "epoch:22 step:17550[D loss: 0.436176, acc: 58.59%, op_acc: 38.28%] [G loss: 0.915977]\n",
      "##############\n",
      "[0.84450908 0.84799711 0.80364634 0.7906619  0.80492311 0.82630198\n",
      " 0.88706267 0.84088086 0.83705891 0.82190198]\n",
      "##########\n",
      "epoch:22 step:17551[D loss: 0.417500, acc: 59.38%, op_acc: 38.28%] [G loss: 0.826950]\n",
      "epoch:22 step:17552[D loss: 0.439626, acc: 60.16%, op_acc: 35.16%] [G loss: 0.882384]\n",
      "epoch:22 step:17553[D loss: 0.424858, acc: 58.59%, op_acc: 41.41%] [G loss: 0.829594]\n",
      "epoch:22 step:17554[D loss: 0.414866, acc: 55.47%, op_acc: 42.97%] [G loss: 0.899833]\n",
      "epoch:22 step:17555[D loss: 0.443133, acc: 49.22%, op_acc: 40.62%] [G loss: 0.807476]\n",
      "epoch:22 step:17556[D loss: 0.399788, acc: 67.19%, op_acc: 36.72%] [G loss: 0.891683]\n",
      "epoch:22 step:17557[D loss: 0.433701, acc: 57.03%, op_acc: 38.28%] [G loss: 0.863897]\n",
      "epoch:22 step:17558[D loss: 0.410677, acc: 65.62%, op_acc: 37.50%] [G loss: 0.920992]\n",
      "epoch:22 step:17559[D loss: 0.439093, acc: 57.03%, op_acc: 42.19%] [G loss: 0.886146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17560[D loss: 0.432665, acc: 60.94%, op_acc: 38.28%] [G loss: 0.845505]\n",
      "epoch:22 step:17561[D loss: 0.430030, acc: 58.59%, op_acc: 39.84%] [G loss: 0.827503]\n",
      "epoch:22 step:17562[D loss: 0.436527, acc: 57.03%, op_acc: 39.84%] [G loss: 0.908666]\n",
      "epoch:22 step:17563[D loss: 0.433457, acc: 66.41%, op_acc: 40.62%] [G loss: 0.910385]\n",
      "epoch:22 step:17564[D loss: 0.461532, acc: 55.47%, op_acc: 32.81%] [G loss: 0.842159]\n",
      "epoch:22 step:17565[D loss: 0.429882, acc: 58.59%, op_acc: 39.06%] [G loss: 0.882199]\n",
      "epoch:22 step:17566[D loss: 0.434869, acc: 60.16%, op_acc: 39.06%] [G loss: 0.886122]\n",
      "epoch:22 step:17567[D loss: 0.411759, acc: 61.72%, op_acc: 42.97%] [G loss: 0.899968]\n",
      "epoch:22 step:17568[D loss: 0.407886, acc: 58.59%, op_acc: 47.66%] [G loss: 0.875426]\n",
      "epoch:22 step:17569[D loss: 0.420204, acc: 64.06%, op_acc: 41.41%] [G loss: 0.874174]\n",
      "epoch:22 step:17570[D loss: 0.457597, acc: 51.56%, op_acc: 36.72%] [G loss: 0.855873]\n",
      "epoch:22 step:17571[D loss: 0.449459, acc: 59.38%, op_acc: 37.50%] [G loss: 0.933140]\n",
      "epoch:22 step:17572[D loss: 0.433368, acc: 55.47%, op_acc: 39.06%] [G loss: 0.939403]\n",
      "epoch:22 step:17573[D loss: 0.413034, acc: 55.47%, op_acc: 42.97%] [G loss: 0.931865]\n",
      "epoch:22 step:17574[D loss: 0.409009, acc: 60.16%, op_acc: 43.75%] [G loss: 0.845786]\n",
      "epoch:22 step:17575[D loss: 0.398560, acc: 66.41%, op_acc: 46.09%] [G loss: 0.902678]\n",
      "epoch:22 step:17576[D loss: 0.401950, acc: 67.19%, op_acc: 42.19%] [G loss: 0.839800]\n",
      "epoch:22 step:17577[D loss: 0.437863, acc: 61.72%, op_acc: 39.06%] [G loss: 0.915916]\n",
      "epoch:22 step:17578[D loss: 0.410142, acc: 61.72%, op_acc: 43.75%] [G loss: 0.818417]\n",
      "epoch:22 step:17579[D loss: 0.407276, acc: 61.72%, op_acc: 41.41%] [G loss: 0.937222]\n",
      "epoch:22 step:17580[D loss: 0.454131, acc: 52.34%, op_acc: 35.94%] [G loss: 0.858393]\n",
      "epoch:22 step:17581[D loss: 0.418662, acc: 53.12%, op_acc: 42.19%] [G loss: 0.825854]\n",
      "epoch:22 step:17582[D loss: 0.413218, acc: 60.94%, op_acc: 35.94%] [G loss: 0.928118]\n",
      "epoch:22 step:17583[D loss: 0.412838, acc: 57.81%, op_acc: 42.97%] [G loss: 0.887045]\n",
      "epoch:22 step:17584[D loss: 0.397317, acc: 67.19%, op_acc: 41.41%] [G loss: 0.907802]\n",
      "epoch:22 step:17585[D loss: 0.414692, acc: 59.38%, op_acc: 41.41%] [G loss: 0.881054]\n",
      "epoch:22 step:17586[D loss: 0.373146, acc: 67.97%, op_acc: 46.88%] [G loss: 0.893201]\n",
      "epoch:22 step:17587[D loss: 0.445683, acc: 60.94%, op_acc: 38.28%] [G loss: 0.926389]\n",
      "epoch:22 step:17588[D loss: 0.410951, acc: 61.72%, op_acc: 42.97%] [G loss: 0.896124]\n",
      "epoch:22 step:17589[D loss: 0.402141, acc: 68.75%, op_acc: 36.72%] [G loss: 0.861867]\n",
      "epoch:22 step:17590[D loss: 0.404641, acc: 60.94%, op_acc: 38.28%] [G loss: 0.828054]\n",
      "epoch:22 step:17591[D loss: 0.444543, acc: 53.12%, op_acc: 41.41%] [G loss: 0.804327]\n",
      "epoch:22 step:17592[D loss: 0.412460, acc: 53.91%, op_acc: 46.09%] [G loss: 0.809568]\n",
      "epoch:22 step:17593[D loss: 0.445394, acc: 57.03%, op_acc: 36.72%] [G loss: 0.817681]\n",
      "epoch:22 step:17594[D loss: 0.418413, acc: 56.25%, op_acc: 39.06%] [G loss: 0.858201]\n",
      "epoch:22 step:17595[D loss: 0.422733, acc: 60.16%, op_acc: 42.97%] [G loss: 0.886831]\n",
      "epoch:22 step:17596[D loss: 0.404881, acc: 57.03%, op_acc: 42.19%] [G loss: 0.894450]\n",
      "epoch:22 step:17597[D loss: 0.416515, acc: 62.50%, op_acc: 39.06%] [G loss: 0.860795]\n",
      "epoch:22 step:17598[D loss: 0.416561, acc: 63.28%, op_acc: 39.06%] [G loss: 0.862876]\n",
      "epoch:22 step:17599[D loss: 0.430597, acc: 64.84%, op_acc: 37.50%] [G loss: 0.949655]\n",
      "epoch:22 step:17600[D loss: 0.438679, acc: 57.81%, op_acc: 44.53%] [G loss: 0.893255]\n",
      "##############\n",
      "[0.87099628 0.8816221  0.7953489  0.8099132  0.79064094 0.85125248\n",
      " 0.90795182 0.80789356 0.80500372 0.84937915]\n",
      "##########\n",
      "epoch:22 step:17601[D loss: 0.428154, acc: 59.38%, op_acc: 38.28%] [G loss: 0.839500]\n",
      "epoch:22 step:17602[D loss: 0.432974, acc: 57.81%, op_acc: 44.53%] [G loss: 0.855314]\n",
      "epoch:22 step:17603[D loss: 0.441915, acc: 58.59%, op_acc: 36.72%] [G loss: 0.976898]\n",
      "epoch:22 step:17604[D loss: 0.404026, acc: 62.50%, op_acc: 50.78%] [G loss: 0.896419]\n",
      "epoch:22 step:17605[D loss: 0.439785, acc: 57.03%, op_acc: 35.94%] [G loss: 0.905586]\n",
      "epoch:22 step:17606[D loss: 0.446925, acc: 57.81%, op_acc: 33.59%] [G loss: 0.898297]\n",
      "epoch:22 step:17607[D loss: 0.436632, acc: 60.94%, op_acc: 35.94%] [G loss: 0.853789]\n",
      "epoch:22 step:17608[D loss: 0.445650, acc: 57.03%, op_acc: 42.97%] [G loss: 0.911219]\n",
      "epoch:22 step:17609[D loss: 0.430089, acc: 58.59%, op_acc: 40.62%] [G loss: 0.884595]\n",
      "epoch:22 step:17610[D loss: 0.416351, acc: 60.94%, op_acc: 40.62%] [G loss: 0.864907]\n",
      "epoch:22 step:17611[D loss: 0.420888, acc: 57.81%, op_acc: 39.84%] [G loss: 0.852208]\n",
      "epoch:22 step:17612[D loss: 0.405348, acc: 60.16%, op_acc: 42.97%] [G loss: 0.901183]\n",
      "epoch:22 step:17613[D loss: 0.459549, acc: 53.12%, op_acc: 38.28%] [G loss: 0.871841]\n",
      "epoch:22 step:17614[D loss: 0.391547, acc: 61.72%, op_acc: 46.09%] [G loss: 0.954063]\n",
      "epoch:22 step:17615[D loss: 0.421826, acc: 53.91%, op_acc: 43.75%] [G loss: 0.867029]\n",
      "epoch:22 step:17616[D loss: 0.415248, acc: 59.38%, op_acc: 42.97%] [G loss: 0.863916]\n",
      "epoch:22 step:17617[D loss: 0.416665, acc: 56.25%, op_acc: 42.19%] [G loss: 0.789511]\n",
      "epoch:22 step:17618[D loss: 0.448208, acc: 50.00%, op_acc: 34.38%] [G loss: 0.895845]\n",
      "epoch:22 step:17619[D loss: 0.440181, acc: 56.25%, op_acc: 43.75%] [G loss: 0.860063]\n",
      "epoch:22 step:17620[D loss: 0.423175, acc: 61.72%, op_acc: 39.84%] [G loss: 0.894607]\n",
      "epoch:22 step:17621[D loss: 0.417743, acc: 59.38%, op_acc: 41.41%] [G loss: 0.834694]\n",
      "epoch:22 step:17622[D loss: 0.433334, acc: 60.16%, op_acc: 33.59%] [G loss: 0.909298]\n",
      "epoch:22 step:17623[D loss: 0.432573, acc: 57.81%, op_acc: 32.81%] [G loss: 0.850493]\n",
      "epoch:22 step:17624[D loss: 0.422725, acc: 57.03%, op_acc: 46.88%] [G loss: 0.876130]\n",
      "epoch:22 step:17625[D loss: 0.426339, acc: 58.59%, op_acc: 33.59%] [G loss: 0.885941]\n",
      "epoch:22 step:17626[D loss: 0.388284, acc: 72.66%, op_acc: 39.06%] [G loss: 0.899951]\n",
      "epoch:22 step:17627[D loss: 0.431747, acc: 57.03%, op_acc: 36.72%] [G loss: 0.931416]\n",
      "epoch:22 step:17628[D loss: 0.486310, acc: 47.66%, op_acc: 37.50%] [G loss: 0.849698]\n",
      "epoch:22 step:17629[D loss: 0.449507, acc: 59.38%, op_acc: 35.94%] [G loss: 0.781635]\n",
      "epoch:22 step:17630[D loss: 0.397503, acc: 75.78%, op_acc: 34.38%] [G loss: 0.843409]\n",
      "epoch:22 step:17631[D loss: 0.420486, acc: 63.28%, op_acc: 32.81%] [G loss: 0.910697]\n",
      "epoch:22 step:17632[D loss: 0.464342, acc: 45.31%, op_acc: 31.25%] [G loss: 0.844609]\n",
      "epoch:22 step:17633[D loss: 0.435619, acc: 55.47%, op_acc: 38.28%] [G loss: 0.927355]\n",
      "epoch:22 step:17634[D loss: 0.400053, acc: 58.59%, op_acc: 44.53%] [G loss: 0.877615]\n",
      "epoch:22 step:17635[D loss: 0.422310, acc: 61.72%, op_acc: 45.31%] [G loss: 0.899196]\n",
      "epoch:22 step:17636[D loss: 0.443219, acc: 58.59%, op_acc: 36.72%] [G loss: 0.852546]\n",
      "epoch:22 step:17637[D loss: 0.422297, acc: 58.59%, op_acc: 48.44%] [G loss: 0.875448]\n",
      "epoch:22 step:17638[D loss: 0.421419, acc: 60.16%, op_acc: 35.16%] [G loss: 0.840648]\n",
      "epoch:22 step:17639[D loss: 0.443003, acc: 60.94%, op_acc: 40.62%] [G loss: 0.840570]\n",
      "epoch:22 step:17640[D loss: 0.450136, acc: 53.12%, op_acc: 39.06%] [G loss: 0.886155]\n",
      "epoch:22 step:17641[D loss: 0.392603, acc: 66.41%, op_acc: 39.06%] [G loss: 0.884847]\n",
      "epoch:22 step:17642[D loss: 0.391652, acc: 64.06%, op_acc: 41.41%] [G loss: 0.939280]\n",
      "epoch:22 step:17643[D loss: 0.428854, acc: 60.94%, op_acc: 35.94%] [G loss: 0.894380]\n",
      "epoch:22 step:17644[D loss: 0.450415, acc: 48.44%, op_acc: 41.41%] [G loss: 0.866371]\n",
      "epoch:22 step:17645[D loss: 0.420737, acc: 60.94%, op_acc: 42.19%] [G loss: 0.925265]\n",
      "epoch:22 step:17646[D loss: 0.443554, acc: 56.25%, op_acc: 37.50%] [G loss: 0.900638]\n",
      "epoch:22 step:17647[D loss: 0.432443, acc: 61.72%, op_acc: 39.06%] [G loss: 0.812732]\n",
      "epoch:22 step:17648[D loss: 0.400997, acc: 67.97%, op_acc: 39.84%] [G loss: 0.897652]\n",
      "epoch:22 step:17649[D loss: 0.441836, acc: 53.91%, op_acc: 37.50%] [G loss: 0.808872]\n",
      "epoch:22 step:17650[D loss: 0.387346, acc: 69.53%, op_acc: 41.41%] [G loss: 0.904322]\n",
      "##############\n",
      "[0.84360819 0.87889963 0.80464026 0.81484013 0.81352245 0.82342898\n",
      " 0.88931098 0.8133106  0.81967019 0.83301989]\n",
      "##########\n",
      "epoch:22 step:17651[D loss: 0.408292, acc: 60.16%, op_acc: 39.84%] [G loss: 0.812644]\n",
      "epoch:22 step:17652[D loss: 0.395619, acc: 66.41%, op_acc: 38.28%] [G loss: 0.802207]\n",
      "epoch:22 step:17653[D loss: 0.433629, acc: 59.38%, op_acc: 32.81%] [G loss: 0.963702]\n",
      "epoch:22 step:17654[D loss: 0.428439, acc: 64.84%, op_acc: 32.81%] [G loss: 0.827800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17655[D loss: 0.386301, acc: 68.75%, op_acc: 46.88%] [G loss: 0.917819]\n",
      "epoch:22 step:17656[D loss: 0.435167, acc: 60.16%, op_acc: 38.28%] [G loss: 0.952585]\n",
      "epoch:22 step:17657[D loss: 0.428809, acc: 53.12%, op_acc: 41.41%] [G loss: 0.901799]\n",
      "epoch:22 step:17658[D loss: 0.470668, acc: 50.78%, op_acc: 35.16%] [G loss: 0.878596]\n",
      "epoch:22 step:17659[D loss: 0.435535, acc: 62.50%, op_acc: 41.41%] [G loss: 0.857639]\n",
      "epoch:22 step:17660[D loss: 0.402289, acc: 61.72%, op_acc: 35.94%] [G loss: 0.908720]\n",
      "epoch:22 step:17661[D loss: 0.460601, acc: 48.44%, op_acc: 34.38%] [G loss: 0.845949]\n",
      "epoch:22 step:17662[D loss: 0.469910, acc: 57.81%, op_acc: 30.47%] [G loss: 0.815137]\n",
      "epoch:22 step:17663[D loss: 0.484119, acc: 48.44%, op_acc: 33.59%] [G loss: 0.839286]\n",
      "epoch:22 step:17664[D loss: 0.453104, acc: 59.38%, op_acc: 32.03%] [G loss: 0.837979]\n",
      "epoch:22 step:17665[D loss: 0.442148, acc: 57.03%, op_acc: 32.03%] [G loss: 0.911619]\n",
      "epoch:22 step:17666[D loss: 0.409554, acc: 56.25%, op_acc: 40.62%] [G loss: 0.892893]\n",
      "epoch:22 step:17667[D loss: 0.430989, acc: 61.72%, op_acc: 32.81%] [G loss: 0.854691]\n",
      "epoch:22 step:17668[D loss: 0.411093, acc: 57.81%, op_acc: 40.62%] [G loss: 0.870742]\n",
      "epoch:22 step:17669[D loss: 0.428628, acc: 55.47%, op_acc: 42.19%] [G loss: 0.885763]\n",
      "epoch:22 step:17670[D loss: 0.443474, acc: 54.69%, op_acc: 36.72%] [G loss: 0.865169]\n",
      "epoch:22 step:17671[D loss: 0.434667, acc: 58.59%, op_acc: 39.06%] [G loss: 0.928274]\n",
      "epoch:22 step:17672[D loss: 0.417433, acc: 57.03%, op_acc: 42.19%] [G loss: 0.932881]\n",
      "epoch:22 step:17673[D loss: 0.457295, acc: 56.25%, op_acc: 34.38%] [G loss: 0.875491]\n",
      "epoch:22 step:17674[D loss: 0.414596, acc: 63.28%, op_acc: 40.62%] [G loss: 0.954235]\n",
      "epoch:22 step:17675[D loss: 0.418745, acc: 66.41%, op_acc: 39.84%] [G loss: 0.862289]\n",
      "epoch:22 step:17676[D loss: 0.407014, acc: 64.84%, op_acc: 42.97%] [G loss: 0.894210]\n",
      "epoch:22 step:17677[D loss: 0.437423, acc: 57.03%, op_acc: 35.94%] [G loss: 0.879804]\n",
      "epoch:22 step:17678[D loss: 0.402945, acc: 67.97%, op_acc: 40.62%] [G loss: 0.969301]\n",
      "epoch:22 step:17679[D loss: 0.382439, acc: 66.41%, op_acc: 40.62%] [G loss: 0.871831]\n",
      "epoch:22 step:17680[D loss: 0.432507, acc: 57.81%, op_acc: 37.50%] [G loss: 0.857248]\n",
      "epoch:22 step:17681[D loss: 0.449468, acc: 61.72%, op_acc: 34.38%] [G loss: 0.924650]\n",
      "epoch:22 step:17682[D loss: 0.429483, acc: 57.81%, op_acc: 37.50%] [G loss: 0.811832]\n",
      "epoch:22 step:17683[D loss: 0.437790, acc: 61.72%, op_acc: 38.28%] [G loss: 0.917704]\n",
      "epoch:22 step:17684[D loss: 0.418674, acc: 54.69%, op_acc: 39.84%] [G loss: 0.893970]\n",
      "epoch:22 step:17685[D loss: 0.401605, acc: 64.84%, op_acc: 37.50%] [G loss: 0.876338]\n",
      "epoch:22 step:17686[D loss: 0.454300, acc: 55.47%, op_acc: 36.72%] [G loss: 0.812118]\n",
      "epoch:22 step:17687[D loss: 0.458382, acc: 50.00%, op_acc: 35.94%] [G loss: 0.898129]\n",
      "epoch:22 step:17688[D loss: 0.440226, acc: 46.88%, op_acc: 44.53%] [G loss: 0.853893]\n",
      "epoch:22 step:17689[D loss: 0.419740, acc: 58.59%, op_acc: 46.09%] [G loss: 0.924278]\n",
      "epoch:22 step:17690[D loss: 0.415814, acc: 64.84%, op_acc: 39.84%] [G loss: 0.898672]\n",
      "epoch:22 step:17691[D loss: 0.453523, acc: 53.91%, op_acc: 40.62%] [G loss: 0.856210]\n",
      "epoch:22 step:17692[D loss: 0.424225, acc: 67.19%, op_acc: 38.28%] [G loss: 0.853410]\n",
      "epoch:22 step:17693[D loss: 0.430416, acc: 59.38%, op_acc: 37.50%] [G loss: 0.961431]\n",
      "epoch:22 step:17694[D loss: 0.413529, acc: 63.28%, op_acc: 34.38%] [G loss: 0.918631]\n",
      "epoch:22 step:17695[D loss: 0.454870, acc: 51.56%, op_acc: 32.81%] [G loss: 0.884937]\n",
      "epoch:22 step:17696[D loss: 0.420144, acc: 64.06%, op_acc: 36.72%] [G loss: 0.925183]\n",
      "epoch:22 step:17697[D loss: 0.469000, acc: 51.56%, op_acc: 32.81%] [G loss: 0.865347]\n",
      "epoch:22 step:17698[D loss: 0.397645, acc: 68.75%, op_acc: 39.84%] [G loss: 0.970009]\n",
      "epoch:22 step:17699[D loss: 0.457511, acc: 56.25%, op_acc: 32.03%] [G loss: 0.905143]\n",
      "epoch:22 step:17700[D loss: 0.406594, acc: 55.47%, op_acc: 42.19%] [G loss: 0.807626]\n",
      "##############\n",
      "[0.85777604 0.8474055  0.80628423 0.81845027 0.80348729 0.82728751\n",
      " 0.88243539 0.82703697 0.79833693 0.81265727]\n",
      "##########\n",
      "epoch:22 step:17701[D loss: 0.442010, acc: 57.81%, op_acc: 36.72%] [G loss: 0.883242]\n",
      "epoch:22 step:17702[D loss: 0.449192, acc: 53.12%, op_acc: 36.72%] [G loss: 0.878591]\n",
      "epoch:22 step:17703[D loss: 0.423590, acc: 67.19%, op_acc: 35.94%] [G loss: 0.812290]\n",
      "epoch:22 step:17704[D loss: 0.454712, acc: 52.34%, op_acc: 38.28%] [G loss: 0.824035]\n",
      "epoch:22 step:17705[D loss: 0.404668, acc: 60.94%, op_acc: 42.19%] [G loss: 0.820277]\n",
      "epoch:22 step:17706[D loss: 0.444417, acc: 57.03%, op_acc: 39.06%] [G loss: 0.875146]\n",
      "epoch:22 step:17707[D loss: 0.396905, acc: 68.75%, op_acc: 43.75%] [G loss: 0.988343]\n",
      "epoch:22 step:17708[D loss: 0.466173, acc: 53.91%, op_acc: 33.59%] [G loss: 0.931814]\n",
      "epoch:22 step:17709[D loss: 0.451370, acc: 51.56%, op_acc: 38.28%] [G loss: 0.891904]\n",
      "epoch:22 step:17710[D loss: 0.432241, acc: 53.91%, op_acc: 39.84%] [G loss: 0.895987]\n",
      "epoch:22 step:17711[D loss: 0.440115, acc: 55.47%, op_acc: 38.28%] [G loss: 0.810448]\n",
      "epoch:22 step:17712[D loss: 0.412182, acc: 62.50%, op_acc: 41.41%] [G loss: 0.881902]\n",
      "epoch:22 step:17713[D loss: 0.436810, acc: 64.84%, op_acc: 41.41%] [G loss: 0.912406]\n",
      "epoch:22 step:17714[D loss: 0.427660, acc: 64.84%, op_acc: 32.03%] [G loss: 0.905854]\n",
      "epoch:22 step:17715[D loss: 0.406416, acc: 64.06%, op_acc: 41.41%] [G loss: 0.914881]\n",
      "epoch:22 step:17716[D loss: 0.412034, acc: 60.16%, op_acc: 42.97%] [G loss: 0.895571]\n",
      "epoch:22 step:17717[D loss: 0.441955, acc: 60.94%, op_acc: 37.50%] [G loss: 0.941865]\n",
      "epoch:22 step:17718[D loss: 0.401248, acc: 59.38%, op_acc: 41.41%] [G loss: 1.015433]\n",
      "epoch:22 step:17719[D loss: 0.431547, acc: 60.16%, op_acc: 40.62%] [G loss: 0.911153]\n",
      "epoch:22 step:17720[D loss: 0.414520, acc: 60.16%, op_acc: 37.50%] [G loss: 0.950076]\n",
      "epoch:22 step:17721[D loss: 0.417607, acc: 60.16%, op_acc: 39.84%] [G loss: 0.839275]\n",
      "epoch:22 step:17722[D loss: 0.409719, acc: 62.50%, op_acc: 39.06%] [G loss: 0.930841]\n",
      "epoch:22 step:17723[D loss: 0.394603, acc: 67.97%, op_acc: 43.75%] [G loss: 0.913011]\n",
      "epoch:22 step:17724[D loss: 0.465614, acc: 52.34%, op_acc: 32.03%] [G loss: 0.887649]\n",
      "epoch:22 step:17725[D loss: 0.426330, acc: 54.69%, op_acc: 36.72%] [G loss: 0.922794]\n",
      "epoch:22 step:17726[D loss: 0.426193, acc: 60.94%, op_acc: 38.28%] [G loss: 0.854852]\n",
      "epoch:22 step:17727[D loss: 0.399403, acc: 67.19%, op_acc: 40.62%] [G loss: 0.884849]\n",
      "epoch:22 step:17728[D loss: 0.435890, acc: 55.47%, op_acc: 36.72%] [G loss: 0.900128]\n",
      "epoch:22 step:17729[D loss: 0.414584, acc: 55.47%, op_acc: 36.72%] [G loss: 0.876350]\n",
      "epoch:22 step:17730[D loss: 0.444331, acc: 53.91%, op_acc: 41.41%] [G loss: 0.824452]\n",
      "epoch:22 step:17731[D loss: 0.407177, acc: 68.75%, op_acc: 47.66%] [G loss: 0.832007]\n",
      "epoch:22 step:17732[D loss: 0.412219, acc: 63.28%, op_acc: 43.75%] [G loss: 0.840911]\n",
      "epoch:22 step:17733[D loss: 0.420199, acc: 60.94%, op_acc: 39.06%] [G loss: 0.810581]\n",
      "epoch:22 step:17734[D loss: 0.455641, acc: 53.12%, op_acc: 39.06%] [G loss: 0.874731]\n",
      "epoch:22 step:17735[D loss: 0.436236, acc: 54.69%, op_acc: 40.62%] [G loss: 0.843269]\n",
      "epoch:22 step:17736[D loss: 0.439640, acc: 57.03%, op_acc: 36.72%] [G loss: 0.842725]\n",
      "epoch:22 step:17737[D loss: 0.419971, acc: 57.81%, op_acc: 36.72%] [G loss: 0.941558]\n",
      "epoch:22 step:17738[D loss: 0.416171, acc: 58.59%, op_acc: 40.62%] [G loss: 0.898979]\n",
      "epoch:22 step:17739[D loss: 0.439924, acc: 59.38%, op_acc: 33.59%] [G loss: 0.851473]\n",
      "epoch:22 step:17740[D loss: 0.408212, acc: 64.84%, op_acc: 42.97%] [G loss: 0.906359]\n",
      "epoch:22 step:17741[D loss: 0.397827, acc: 61.72%, op_acc: 40.62%] [G loss: 0.904868]\n",
      "epoch:22 step:17742[D loss: 0.410350, acc: 65.62%, op_acc: 39.84%] [G loss: 0.831658]\n",
      "epoch:22 step:17743[D loss: 0.429173, acc: 57.81%, op_acc: 37.50%] [G loss: 0.853101]\n",
      "epoch:22 step:17744[D loss: 0.413482, acc: 59.38%, op_acc: 40.62%] [G loss: 0.902787]\n",
      "epoch:22 step:17745[D loss: 0.404367, acc: 62.50%, op_acc: 41.41%] [G loss: 0.861470]\n",
      "epoch:22 step:17746[D loss: 0.404267, acc: 62.50%, op_acc: 43.75%] [G loss: 0.828670]\n",
      "epoch:22 step:17747[D loss: 0.402479, acc: 66.41%, op_acc: 42.19%] [G loss: 0.886393]\n",
      "epoch:22 step:17748[D loss: 0.406503, acc: 64.06%, op_acc: 33.59%] [G loss: 0.914405]\n",
      "epoch:22 step:17749[D loss: 0.415599, acc: 62.50%, op_acc: 42.97%] [G loss: 0.921767]\n",
      "epoch:22 step:17750[D loss: 0.425312, acc: 57.03%, op_acc: 41.41%] [G loss: 0.799012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.84727734 0.86656669 0.81693308 0.82394207 0.79405503 0.8220583\n",
      " 0.89209755 0.84207647 0.80078766 0.83029725]\n",
      "##########\n",
      "epoch:22 step:17751[D loss: 0.420436, acc: 64.06%, op_acc: 40.62%] [G loss: 0.874000]\n",
      "epoch:22 step:17752[D loss: 0.437734, acc: 57.03%, op_acc: 39.84%] [G loss: 0.841242]\n",
      "epoch:22 step:17753[D loss: 0.419302, acc: 57.03%, op_acc: 45.31%] [G loss: 0.890155]\n",
      "epoch:22 step:17754[D loss: 0.411764, acc: 60.16%, op_acc: 41.41%] [G loss: 0.849753]\n",
      "epoch:22 step:17755[D loss: 0.426750, acc: 57.81%, op_acc: 46.88%] [G loss: 0.889435]\n",
      "epoch:22 step:17756[D loss: 0.425071, acc: 60.16%, op_acc: 39.06%] [G loss: 0.878615]\n",
      "epoch:22 step:17757[D loss: 0.449677, acc: 51.56%, op_acc: 35.94%] [G loss: 0.841855]\n",
      "epoch:22 step:17758[D loss: 0.412884, acc: 54.69%, op_acc: 44.53%] [G loss: 0.909044]\n",
      "epoch:22 step:17759[D loss: 0.435225, acc: 64.84%, op_acc: 36.72%] [G loss: 0.888123]\n",
      "epoch:22 step:17760[D loss: 0.443061, acc: 55.47%, op_acc: 36.72%] [G loss: 0.908842]\n",
      "epoch:22 step:17761[D loss: 0.390978, acc: 62.50%, op_acc: 48.44%] [G loss: 0.823738]\n",
      "epoch:22 step:17762[D loss: 0.426803, acc: 57.03%, op_acc: 42.19%] [G loss: 0.806502]\n",
      "epoch:22 step:17763[D loss: 0.441277, acc: 57.81%, op_acc: 28.91%] [G loss: 0.841018]\n",
      "epoch:22 step:17764[D loss: 0.442733, acc: 57.81%, op_acc: 33.59%] [G loss: 0.831445]\n",
      "epoch:22 step:17765[D loss: 0.422189, acc: 59.38%, op_acc: 39.84%] [G loss: 0.900294]\n",
      "epoch:22 step:17766[D loss: 0.414554, acc: 74.22%, op_acc: 31.25%] [G loss: 0.923585]\n",
      "epoch:22 step:17767[D loss: 0.389948, acc: 67.19%, op_acc: 39.06%] [G loss: 0.903547]\n",
      "epoch:22 step:17768[D loss: 0.418244, acc: 64.06%, op_acc: 35.16%] [G loss: 0.852181]\n",
      "epoch:22 step:17769[D loss: 0.414628, acc: 66.41%, op_acc: 35.16%] [G loss: 0.929651]\n",
      "epoch:22 step:17770[D loss: 0.422747, acc: 54.69%, op_acc: 43.75%] [G loss: 0.828846]\n",
      "epoch:22 step:17771[D loss: 0.419352, acc: 60.94%, op_acc: 42.19%] [G loss: 0.962706]\n",
      "epoch:22 step:17772[D loss: 0.411483, acc: 63.28%, op_acc: 38.28%] [G loss: 0.941393]\n",
      "epoch:22 step:17773[D loss: 0.434519, acc: 53.12%, op_acc: 39.84%] [G loss: 0.880043]\n",
      "epoch:22 step:17774[D loss: 0.436186, acc: 53.91%, op_acc: 44.53%] [G loss: 0.899779]\n",
      "epoch:22 step:17775[D loss: 0.450832, acc: 53.12%, op_acc: 37.50%] [G loss: 0.842497]\n",
      "epoch:22 step:17776[D loss: 0.436801, acc: 57.81%, op_acc: 40.62%] [G loss: 0.892817]\n",
      "epoch:22 step:17777[D loss: 0.364461, acc: 77.34%, op_acc: 44.53%] [G loss: 0.897501]\n",
      "epoch:22 step:17778[D loss: 0.427609, acc: 58.59%, op_acc: 36.72%] [G loss: 0.847263]\n",
      "epoch:22 step:17779[D loss: 0.429108, acc: 60.16%, op_acc: 39.06%] [G loss: 0.882254]\n",
      "epoch:22 step:17780[D loss: 0.420052, acc: 57.03%, op_acc: 39.84%] [G loss: 0.816320]\n",
      "epoch:22 step:17781[D loss: 0.440840, acc: 56.25%, op_acc: 35.94%] [G loss: 0.819411]\n",
      "epoch:22 step:17782[D loss: 0.446654, acc: 54.69%, op_acc: 38.28%] [G loss: 0.824874]\n",
      "epoch:22 step:17783[D loss: 0.423944, acc: 54.69%, op_acc: 45.31%] [G loss: 0.825580]\n",
      "epoch:22 step:17784[D loss: 0.426653, acc: 57.81%, op_acc: 43.75%] [G loss: 0.891839]\n",
      "epoch:22 step:17785[D loss: 0.418837, acc: 58.59%, op_acc: 36.72%] [G loss: 0.916345]\n",
      "epoch:22 step:17786[D loss: 0.453042, acc: 64.06%, op_acc: 33.59%] [G loss: 0.932548]\n",
      "epoch:22 step:17787[D loss: 0.432169, acc: 58.59%, op_acc: 36.72%] [G loss: 0.874539]\n",
      "epoch:22 step:17788[D loss: 0.417019, acc: 60.16%, op_acc: 37.50%] [G loss: 0.956743]\n",
      "epoch:22 step:17789[D loss: 0.401779, acc: 60.16%, op_acc: 45.31%] [G loss: 0.958806]\n",
      "epoch:22 step:17790[D loss: 0.397278, acc: 64.84%, op_acc: 42.97%] [G loss: 0.801894]\n",
      "epoch:22 step:17791[D loss: 0.429082, acc: 56.25%, op_acc: 36.72%] [G loss: 0.930443]\n",
      "epoch:22 step:17792[D loss: 0.441718, acc: 57.03%, op_acc: 36.72%] [G loss: 0.863224]\n",
      "epoch:22 step:17793[D loss: 0.435629, acc: 53.91%, op_acc: 36.72%] [G loss: 0.828109]\n",
      "epoch:22 step:17794[D loss: 0.419467, acc: 63.28%, op_acc: 39.06%] [G loss: 0.898443]\n",
      "epoch:22 step:17795[D loss: 0.433774, acc: 58.59%, op_acc: 41.41%] [G loss: 0.905098]\n",
      "epoch:22 step:17796[D loss: 0.404052, acc: 62.50%, op_acc: 44.53%] [G loss: 0.834468]\n",
      "epoch:22 step:17797[D loss: 0.430282, acc: 57.03%, op_acc: 42.97%] [G loss: 0.915235]\n",
      "epoch:22 step:17798[D loss: 0.423546, acc: 63.28%, op_acc: 38.28%] [G loss: 0.847295]\n",
      "epoch:22 step:17799[D loss: 0.444234, acc: 55.47%, op_acc: 33.59%] [G loss: 0.856317]\n",
      "epoch:22 step:17800[D loss: 0.411039, acc: 59.38%, op_acc: 42.19%] [G loss: 0.882977]\n",
      "##############\n",
      "[0.84862401 0.83956556 0.80678682 0.82203952 0.81102743 0.84175267\n",
      " 0.87819291 0.83884971 0.80668632 0.82774985]\n",
      "##########\n",
      "epoch:22 step:17801[D loss: 0.452408, acc: 51.56%, op_acc: 42.97%] [G loss: 0.987122]\n",
      "epoch:22 step:17802[D loss: 0.419924, acc: 57.81%, op_acc: 39.06%] [G loss: 0.886817]\n",
      "epoch:22 step:17803[D loss: 0.446664, acc: 55.47%, op_acc: 36.72%] [G loss: 0.866623]\n",
      "epoch:22 step:17804[D loss: 0.452895, acc: 59.38%, op_acc: 38.28%] [G loss: 0.889293]\n",
      "epoch:22 step:17805[D loss: 0.428415, acc: 53.12%, op_acc: 36.72%] [G loss: 0.841107]\n",
      "epoch:22 step:17806[D loss: 0.429691, acc: 57.81%, op_acc: 39.06%] [G loss: 0.929593]\n",
      "epoch:22 step:17807[D loss: 0.417936, acc: 60.94%, op_acc: 35.94%] [G loss: 0.878584]\n",
      "epoch:22 step:17808[D loss: 0.401186, acc: 59.38%, op_acc: 41.41%] [G loss: 0.938199]\n",
      "epoch:22 step:17809[D loss: 0.414018, acc: 55.47%, op_acc: 40.62%] [G loss: 0.903968]\n",
      "epoch:22 step:17810[D loss: 0.420718, acc: 60.16%, op_acc: 39.06%] [G loss: 0.875888]\n",
      "epoch:22 step:17811[D loss: 0.450382, acc: 51.56%, op_acc: 35.94%] [G loss: 0.837204]\n",
      "epoch:22 step:17812[D loss: 0.373577, acc: 74.22%, op_acc: 45.31%] [G loss: 0.844418]\n",
      "epoch:22 step:17813[D loss: 0.440916, acc: 58.59%, op_acc: 35.94%] [G loss: 0.934771]\n",
      "epoch:22 step:17814[D loss: 0.428196, acc: 63.28%, op_acc: 32.81%] [G loss: 0.831745]\n",
      "epoch:22 step:17815[D loss: 0.436775, acc: 54.69%, op_acc: 39.06%] [G loss: 0.870504]\n",
      "epoch:22 step:17816[D loss: 0.417044, acc: 60.16%, op_acc: 44.53%] [G loss: 0.932508]\n",
      "epoch:22 step:17817[D loss: 0.446277, acc: 57.81%, op_acc: 34.38%] [G loss: 0.925137]\n",
      "epoch:22 step:17818[D loss: 0.406722, acc: 56.25%, op_acc: 43.75%] [G loss: 0.869390]\n",
      "epoch:22 step:17819[D loss: 0.424559, acc: 58.59%, op_acc: 35.16%] [G loss: 0.916315]\n",
      "epoch:22 step:17820[D loss: 0.420444, acc: 64.06%, op_acc: 40.62%] [G loss: 0.916420]\n",
      "epoch:22 step:17821[D loss: 0.417679, acc: 59.38%, op_acc: 34.38%] [G loss: 0.884920]\n",
      "epoch:22 step:17822[D loss: 0.415125, acc: 67.19%, op_acc: 36.72%] [G loss: 1.004137]\n",
      "epoch:22 step:17823[D loss: 0.426249, acc: 53.91%, op_acc: 40.62%] [G loss: 0.924263]\n",
      "epoch:22 step:17824[D loss: 0.445040, acc: 58.59%, op_acc: 32.03%] [G loss: 0.914375]\n",
      "epoch:22 step:17825[D loss: 0.464677, acc: 57.81%, op_acc: 28.91%] [G loss: 0.914157]\n",
      "epoch:22 step:17826[D loss: 0.400848, acc: 64.84%, op_acc: 42.19%] [G loss: 0.873092]\n",
      "epoch:22 step:17827[D loss: 0.438654, acc: 63.28%, op_acc: 42.19%] [G loss: 0.898457]\n",
      "epoch:22 step:17828[D loss: 0.431587, acc: 59.38%, op_acc: 32.81%] [G loss: 0.886497]\n",
      "epoch:22 step:17829[D loss: 0.431242, acc: 56.25%, op_acc: 40.62%] [G loss: 0.818962]\n",
      "epoch:22 step:17830[D loss: 0.437547, acc: 58.59%, op_acc: 38.28%] [G loss: 0.824966]\n",
      "epoch:22 step:17831[D loss: 0.423837, acc: 64.06%, op_acc: 38.28%] [G loss: 0.850246]\n",
      "epoch:22 step:17832[D loss: 0.458936, acc: 59.38%, op_acc: 34.38%] [G loss: 0.880621]\n",
      "epoch:22 step:17833[D loss: 0.426982, acc: 55.47%, op_acc: 40.62%] [G loss: 1.002214]\n",
      "epoch:22 step:17834[D loss: 0.402140, acc: 64.06%, op_acc: 43.75%] [G loss: 0.929984]\n",
      "epoch:22 step:17835[D loss: 0.391263, acc: 64.84%, op_acc: 41.41%] [G loss: 0.927298]\n",
      "epoch:22 step:17836[D loss: 0.411711, acc: 60.16%, op_acc: 40.62%] [G loss: 0.912485]\n",
      "epoch:22 step:17837[D loss: 0.442514, acc: 56.25%, op_acc: 38.28%] [G loss: 0.849147]\n",
      "epoch:22 step:17838[D loss: 0.436835, acc: 53.12%, op_acc: 39.06%] [G loss: 0.849721]\n",
      "epoch:22 step:17839[D loss: 0.433863, acc: 58.59%, op_acc: 32.03%] [G loss: 0.825182]\n",
      "epoch:22 step:17840[D loss: 0.430194, acc: 60.16%, op_acc: 37.50%] [G loss: 0.868270]\n",
      "epoch:22 step:17841[D loss: 0.410331, acc: 64.06%, op_acc: 41.41%] [G loss: 0.870685]\n",
      "epoch:22 step:17842[D loss: 0.452357, acc: 55.47%, op_acc: 37.50%] [G loss: 0.877355]\n",
      "epoch:22 step:17843[D loss: 0.416227, acc: 59.38%, op_acc: 42.19%] [G loss: 0.887472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17844[D loss: 0.431900, acc: 54.69%, op_acc: 39.06%] [G loss: 0.859712]\n",
      "epoch:22 step:17845[D loss: 0.418717, acc: 53.91%, op_acc: 38.28%] [G loss: 0.935295]\n",
      "epoch:22 step:17846[D loss: 0.431073, acc: 50.00%, op_acc: 40.62%] [G loss: 0.896201]\n",
      "epoch:22 step:17847[D loss: 0.422449, acc: 66.41%, op_acc: 37.50%] [G loss: 0.894048]\n",
      "epoch:22 step:17848[D loss: 0.421564, acc: 61.72%, op_acc: 41.41%] [G loss: 0.934697]\n",
      "epoch:22 step:17849[D loss: 0.411610, acc: 55.47%, op_acc: 37.50%] [G loss: 0.903502]\n",
      "epoch:22 step:17850[D loss: 0.420911, acc: 55.47%, op_acc: 43.75%] [G loss: 0.886836]\n",
      "##############\n",
      "[0.8542844  0.84594774 0.82779803 0.80241328 0.7987679  0.80760783\n",
      " 0.87929317 0.82130755 0.81998493 0.84294871]\n",
      "##########\n",
      "epoch:22 step:17851[D loss: 0.417051, acc: 59.38%, op_acc: 39.84%] [G loss: 0.841749]\n",
      "epoch:22 step:17852[D loss: 0.416153, acc: 63.28%, op_acc: 39.84%] [G loss: 0.816554]\n",
      "epoch:22 step:17853[D loss: 0.428452, acc: 53.12%, op_acc: 42.19%] [G loss: 0.903234]\n",
      "epoch:22 step:17854[D loss: 0.431101, acc: 65.62%, op_acc: 33.59%] [G loss: 0.814105]\n",
      "epoch:22 step:17855[D loss: 0.416988, acc: 61.72%, op_acc: 38.28%] [G loss: 0.820739]\n",
      "epoch:22 step:17856[D loss: 0.419098, acc: 60.16%, op_acc: 46.09%] [G loss: 0.872787]\n",
      "epoch:22 step:17857[D loss: 0.409553, acc: 64.84%, op_acc: 42.19%] [G loss: 1.049409]\n",
      "epoch:22 step:17858[D loss: 0.472271, acc: 53.12%, op_acc: 32.81%] [G loss: 0.883634]\n",
      "epoch:22 step:17859[D loss: 0.460657, acc: 58.59%, op_acc: 32.03%] [G loss: 0.875974]\n",
      "epoch:22 step:17860[D loss: 0.410129, acc: 59.38%, op_acc: 42.97%] [G loss: 0.881053]\n",
      "epoch:22 step:17861[D loss: 0.422241, acc: 57.81%, op_acc: 39.84%] [G loss: 0.803697]\n",
      "epoch:22 step:17862[D loss: 0.449013, acc: 60.94%, op_acc: 38.28%] [G loss: 0.918467]\n",
      "epoch:22 step:17863[D loss: 0.444390, acc: 53.91%, op_acc: 35.94%] [G loss: 0.826622]\n",
      "epoch:22 step:17864[D loss: 0.418327, acc: 57.03%, op_acc: 44.53%] [G loss: 0.876904]\n",
      "epoch:22 step:17865[D loss: 0.437770, acc: 51.56%, op_acc: 43.75%] [G loss: 0.838000]\n",
      "epoch:22 step:17866[D loss: 0.424976, acc: 61.72%, op_acc: 39.06%] [G loss: 0.884126]\n",
      "epoch:22 step:17867[D loss: 0.453472, acc: 51.56%, op_acc: 38.28%] [G loss: 0.834423]\n",
      "epoch:22 step:17868[D loss: 0.420308, acc: 63.28%, op_acc: 35.16%] [G loss: 0.885911]\n",
      "epoch:22 step:17869[D loss: 0.411121, acc: 58.59%, op_acc: 35.94%] [G loss: 0.890783]\n",
      "epoch:22 step:17870[D loss: 0.379064, acc: 74.22%, op_acc: 42.19%] [G loss: 0.933287]\n",
      "epoch:22 step:17871[D loss: 0.431997, acc: 49.22%, op_acc: 43.75%] [G loss: 0.859536]\n",
      "epoch:22 step:17872[D loss: 0.435756, acc: 63.28%, op_acc: 37.50%] [G loss: 0.871818]\n",
      "epoch:22 step:17873[D loss: 0.428892, acc: 61.72%, op_acc: 42.97%] [G loss: 0.939142]\n",
      "epoch:22 step:17874[D loss: 0.460058, acc: 53.91%, op_acc: 36.72%] [G loss: 0.909934]\n",
      "epoch:22 step:17875[D loss: 0.416458, acc: 68.75%, op_acc: 38.28%] [G loss: 0.936535]\n",
      "epoch:22 step:17876[D loss: 0.414396, acc: 64.06%, op_acc: 42.97%] [G loss: 0.935871]\n",
      "epoch:22 step:17877[D loss: 0.413074, acc: 63.28%, op_acc: 39.84%] [G loss: 0.853662]\n",
      "epoch:22 step:17878[D loss: 0.451450, acc: 53.91%, op_acc: 36.72%] [G loss: 0.904711]\n",
      "epoch:22 step:17879[D loss: 0.406738, acc: 61.72%, op_acc: 42.19%] [G loss: 0.870242]\n",
      "epoch:22 step:17880[D loss: 0.436179, acc: 60.94%, op_acc: 37.50%] [G loss: 0.868484]\n",
      "epoch:22 step:17881[D loss: 0.422908, acc: 57.03%, op_acc: 42.97%] [G loss: 0.867802]\n",
      "epoch:22 step:17882[D loss: 0.430525, acc: 60.16%, op_acc: 35.94%] [G loss: 0.830778]\n",
      "epoch:22 step:17883[D loss: 0.424441, acc: 62.50%, op_acc: 40.62%] [G loss: 0.821995]\n",
      "epoch:22 step:17884[D loss: 0.419758, acc: 65.62%, op_acc: 35.94%] [G loss: 0.911833]\n",
      "epoch:22 step:17885[D loss: 0.444700, acc: 57.81%, op_acc: 35.16%] [G loss: 0.862122]\n",
      "epoch:22 step:17886[D loss: 0.404705, acc: 55.47%, op_acc: 46.88%] [G loss: 0.822604]\n",
      "epoch:22 step:17887[D loss: 0.410889, acc: 67.97%, op_acc: 37.50%] [G loss: 0.841690]\n",
      "epoch:22 step:17888[D loss: 0.416035, acc: 65.62%, op_acc: 41.41%] [G loss: 0.775409]\n",
      "epoch:22 step:17889[D loss: 0.467645, acc: 51.56%, op_acc: 35.94%] [G loss: 0.923219]\n",
      "epoch:22 step:17890[D loss: 0.443186, acc: 52.34%, op_acc: 33.59%] [G loss: 0.874634]\n",
      "epoch:22 step:17891[D loss: 0.435482, acc: 51.56%, op_acc: 42.19%] [G loss: 0.857992]\n",
      "epoch:22 step:17892[D loss: 0.392389, acc: 65.62%, op_acc: 46.88%] [G loss: 0.859516]\n",
      "epoch:22 step:17893[D loss: 0.406146, acc: 67.19%, op_acc: 39.06%] [G loss: 0.861033]\n",
      "epoch:22 step:17894[D loss: 0.393068, acc: 64.84%, op_acc: 44.53%] [G loss: 0.951946]\n",
      "epoch:22 step:17895[D loss: 0.430631, acc: 56.25%, op_acc: 39.06%] [G loss: 0.919264]\n",
      "epoch:22 step:17896[D loss: 0.420240, acc: 64.06%, op_acc: 42.19%] [G loss: 0.911288]\n",
      "epoch:22 step:17897[D loss: 0.426939, acc: 50.78%, op_acc: 39.84%] [G loss: 0.939941]\n",
      "epoch:22 step:17898[D loss: 0.396123, acc: 69.53%, op_acc: 41.41%] [G loss: 0.953667]\n",
      "epoch:22 step:17899[D loss: 0.414173, acc: 57.81%, op_acc: 45.31%] [G loss: 0.869972]\n",
      "epoch:22 step:17900[D loss: 0.406183, acc: 64.06%, op_acc: 42.19%] [G loss: 0.926327]\n",
      "##############\n",
      "[0.85111604 0.87961883 0.80252584 0.82305546 0.77465826 0.82338989\n",
      " 0.89610036 0.83089442 0.80878863 0.82655666]\n",
      "##########\n",
      "epoch:22 step:17901[D loss: 0.431329, acc: 60.16%, op_acc: 43.75%] [G loss: 0.889192]\n",
      "epoch:22 step:17902[D loss: 0.396094, acc: 67.19%, op_acc: 40.62%] [G loss: 0.886205]\n",
      "epoch:22 step:17903[D loss: 0.415576, acc: 58.59%, op_acc: 39.84%] [G loss: 0.882506]\n",
      "epoch:22 step:17904[D loss: 0.426075, acc: 58.59%, op_acc: 40.62%] [G loss: 0.863450]\n",
      "epoch:22 step:17905[D loss: 0.428344, acc: 57.03%, op_acc: 37.50%] [G loss: 0.816080]\n",
      "epoch:22 step:17906[D loss: 0.454291, acc: 61.72%, op_acc: 30.47%] [G loss: 0.898368]\n",
      "epoch:22 step:17907[D loss: 0.402527, acc: 61.72%, op_acc: 42.19%] [G loss: 0.955998]\n",
      "epoch:22 step:17908[D loss: 0.425398, acc: 57.81%, op_acc: 41.41%] [G loss: 0.812812]\n",
      "epoch:22 step:17909[D loss: 0.466079, acc: 51.56%, op_acc: 38.28%] [G loss: 0.765626]\n",
      "epoch:22 step:17910[D loss: 0.455023, acc: 53.91%, op_acc: 38.28%] [G loss: 0.814213]\n",
      "epoch:22 step:17911[D loss: 0.438351, acc: 53.91%, op_acc: 42.97%] [G loss: 0.834282]\n",
      "epoch:22 step:17912[D loss: 0.426114, acc: 64.06%, op_acc: 37.50%] [G loss: 0.801235]\n",
      "epoch:22 step:17913[D loss: 0.423004, acc: 58.59%, op_acc: 38.28%] [G loss: 0.980006]\n",
      "epoch:22 step:17914[D loss: 0.435485, acc: 57.03%, op_acc: 41.41%] [G loss: 0.871910]\n",
      "epoch:22 step:17915[D loss: 0.391117, acc: 64.84%, op_acc: 33.59%] [G loss: 0.895743]\n",
      "epoch:22 step:17916[D loss: 0.428147, acc: 55.47%, op_acc: 37.50%] [G loss: 0.839329]\n",
      "epoch:22 step:17917[D loss: 0.435797, acc: 60.94%, op_acc: 39.06%] [G loss: 0.829776]\n",
      "epoch:22 step:17918[D loss: 0.419052, acc: 61.72%, op_acc: 39.84%] [G loss: 0.875828]\n",
      "epoch:22 step:17919[D loss: 0.409629, acc: 58.59%, op_acc: 41.41%] [G loss: 0.850913]\n",
      "epoch:22 step:17920[D loss: 0.428808, acc: 61.72%, op_acc: 37.50%] [G loss: 0.869882]\n",
      "epoch:22 step:17921[D loss: 0.406148, acc: 58.59%, op_acc: 41.41%] [G loss: 0.895281]\n",
      "epoch:22 step:17922[D loss: 0.401454, acc: 61.72%, op_acc: 43.75%] [G loss: 0.784026]\n",
      "epoch:22 step:17923[D loss: 0.426333, acc: 57.81%, op_acc: 38.28%] [G loss: 0.853116]\n",
      "epoch:22 step:17924[D loss: 0.446322, acc: 53.91%, op_acc: 39.06%] [G loss: 0.870497]\n",
      "epoch:22 step:17925[D loss: 0.414476, acc: 60.94%, op_acc: 42.19%] [G loss: 0.902326]\n",
      "epoch:22 step:17926[D loss: 0.398145, acc: 62.50%, op_acc: 42.19%] [G loss: 0.882105]\n",
      "epoch:22 step:17927[D loss: 0.400141, acc: 60.94%, op_acc: 42.19%] [G loss: 0.827715]\n",
      "epoch:22 step:17928[D loss: 0.439322, acc: 53.91%, op_acc: 39.84%] [G loss: 0.861150]\n",
      "epoch:22 step:17929[D loss: 0.443600, acc: 60.94%, op_acc: 40.62%] [G loss: 0.936192]\n",
      "epoch:22 step:17930[D loss: 0.420991, acc: 68.75%, op_acc: 35.16%] [G loss: 0.952974]\n",
      "epoch:22 step:17931[D loss: 0.438322, acc: 60.94%, op_acc: 34.38%] [G loss: 0.848493]\n",
      "epoch:22 step:17932[D loss: 0.431437, acc: 53.12%, op_acc: 36.72%] [G loss: 0.816070]\n",
      "epoch:22 step:17933[D loss: 0.445838, acc: 59.38%, op_acc: 32.03%] [G loss: 0.818876]\n",
      "epoch:22 step:17934[D loss: 0.429005, acc: 56.25%, op_acc: 42.97%] [G loss: 0.828163]\n",
      "epoch:22 step:17935[D loss: 0.423663, acc: 61.72%, op_acc: 42.97%] [G loss: 0.792522]\n",
      "epoch:22 step:17936[D loss: 0.426882, acc: 58.59%, op_acc: 39.06%] [G loss: 0.896548]\n",
      "epoch:22 step:17937[D loss: 0.429091, acc: 60.16%, op_acc: 42.19%] [G loss: 0.924655]\n",
      "epoch:22 step:17938[D loss: 0.455149, acc: 47.66%, op_acc: 43.75%] [G loss: 0.899560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17939[D loss: 0.399610, acc: 62.50%, op_acc: 37.50%] [G loss: 0.872183]\n",
      "epoch:22 step:17940[D loss: 0.423254, acc: 62.50%, op_acc: 41.41%] [G loss: 0.853399]\n",
      "epoch:22 step:17941[D loss: 0.443363, acc: 56.25%, op_acc: 41.41%] [G loss: 0.844111]\n",
      "epoch:22 step:17942[D loss: 0.431612, acc: 54.69%, op_acc: 41.41%] [G loss: 0.842001]\n",
      "epoch:22 step:17943[D loss: 0.397204, acc: 65.62%, op_acc: 43.75%] [G loss: 0.882453]\n",
      "epoch:22 step:17944[D loss: 0.454378, acc: 57.03%, op_acc: 35.94%] [G loss: 0.910333]\n",
      "epoch:22 step:17945[D loss: 0.433308, acc: 54.69%, op_acc: 39.06%] [G loss: 0.845015]\n",
      "epoch:22 step:17946[D loss: 0.413312, acc: 57.81%, op_acc: 45.31%] [G loss: 0.888001]\n",
      "epoch:22 step:17947[D loss: 0.418851, acc: 64.06%, op_acc: 40.62%] [G loss: 0.841160]\n",
      "epoch:22 step:17948[D loss: 0.436734, acc: 54.69%, op_acc: 39.84%] [G loss: 0.880469]\n",
      "epoch:22 step:17949[D loss: 0.406767, acc: 63.28%, op_acc: 36.72%] [G loss: 0.820270]\n",
      "epoch:22 step:17950[D loss: 0.435068, acc: 59.38%, op_acc: 32.81%] [G loss: 0.896294]\n",
      "##############\n",
      "[0.86720548 0.86803181 0.79507255 0.7965477  0.8067943  0.80150156\n",
      " 0.90250132 0.8258882  0.81139358 0.83470108]\n",
      "##########\n",
      "epoch:22 step:17951[D loss: 0.390783, acc: 66.41%, op_acc: 47.66%] [G loss: 0.809344]\n",
      "epoch:22 step:17952[D loss: 0.400585, acc: 60.16%, op_acc: 42.19%] [G loss: 0.952579]\n",
      "epoch:22 step:17953[D loss: 0.486984, acc: 45.31%, op_acc: 34.38%] [G loss: 0.839305]\n",
      "epoch:22 step:17954[D loss: 0.445759, acc: 57.03%, op_acc: 35.16%] [G loss: 0.866244]\n",
      "epoch:22 step:17955[D loss: 0.449356, acc: 56.25%, op_acc: 32.81%] [G loss: 0.847170]\n",
      "epoch:22 step:17956[D loss: 0.431403, acc: 53.12%, op_acc: 36.72%] [G loss: 0.839852]\n",
      "epoch:22 step:17957[D loss: 0.440176, acc: 58.59%, op_acc: 34.38%] [G loss: 0.881897]\n",
      "epoch:22 step:17958[D loss: 0.406357, acc: 57.03%, op_acc: 37.50%] [G loss: 0.991763]\n",
      "epoch:22 step:17959[D loss: 0.449705, acc: 60.16%, op_acc: 32.03%] [G loss: 0.880542]\n",
      "epoch:22 step:17960[D loss: 0.418129, acc: 57.03%, op_acc: 43.75%] [G loss: 0.843469]\n",
      "epoch:22 step:17961[D loss: 0.404343, acc: 63.28%, op_acc: 38.28%] [G loss: 0.916504]\n",
      "epoch:22 step:17962[D loss: 0.426407, acc: 57.03%, op_acc: 40.62%] [G loss: 0.914132]\n",
      "epoch:22 step:17963[D loss: 0.410464, acc: 62.50%, op_acc: 36.72%] [G loss: 0.932883]\n",
      "epoch:23 step:17964[D loss: 0.432955, acc: 50.00%, op_acc: 36.72%] [G loss: 0.887529]\n",
      "epoch:23 step:17965[D loss: 0.410584, acc: 57.81%, op_acc: 41.41%] [G loss: 0.909663]\n",
      "epoch:23 step:17966[D loss: 0.419407, acc: 64.06%, op_acc: 38.28%] [G loss: 0.898015]\n",
      "epoch:23 step:17967[D loss: 0.386182, acc: 64.06%, op_acc: 42.97%] [G loss: 0.849619]\n",
      "epoch:23 step:17968[D loss: 0.399340, acc: 63.28%, op_acc: 39.06%] [G loss: 0.945102]\n",
      "epoch:23 step:17969[D loss: 0.436119, acc: 56.25%, op_acc: 33.59%] [G loss: 0.840705]\n",
      "epoch:23 step:17970[D loss: 0.389265, acc: 64.84%, op_acc: 42.97%] [G loss: 0.848399]\n",
      "epoch:23 step:17971[D loss: 0.459699, acc: 47.66%, op_acc: 34.38%] [G loss: 0.885634]\n",
      "epoch:23 step:17972[D loss: 0.416106, acc: 56.25%, op_acc: 42.19%] [G loss: 0.844555]\n",
      "epoch:23 step:17973[D loss: 0.420844, acc: 59.38%, op_acc: 32.81%] [G loss: 0.875670]\n",
      "epoch:23 step:17974[D loss: 0.442148, acc: 57.03%, op_acc: 39.06%] [G loss: 0.887746]\n",
      "epoch:23 step:17975[D loss: 0.401306, acc: 67.97%, op_acc: 42.19%] [G loss: 0.878390]\n",
      "epoch:23 step:17976[D loss: 0.431667, acc: 55.47%, op_acc: 37.50%] [G loss: 0.874650]\n",
      "epoch:23 step:17977[D loss: 0.427116, acc: 65.62%, op_acc: 33.59%] [G loss: 0.914151]\n",
      "epoch:23 step:17978[D loss: 0.438630, acc: 56.25%, op_acc: 37.50%] [G loss: 0.860805]\n",
      "epoch:23 step:17979[D loss: 0.396369, acc: 65.62%, op_acc: 46.09%] [G loss: 0.899528]\n",
      "epoch:23 step:17980[D loss: 0.432276, acc: 53.91%, op_acc: 43.75%] [G loss: 0.789289]\n",
      "epoch:23 step:17981[D loss: 0.414369, acc: 62.50%, op_acc: 40.62%] [G loss: 0.866734]\n",
      "epoch:23 step:17982[D loss: 0.432055, acc: 55.47%, op_acc: 40.62%] [G loss: 0.853230]\n",
      "epoch:23 step:17983[D loss: 0.390120, acc: 64.06%, op_acc: 39.84%] [G loss: 0.907016]\n",
      "epoch:23 step:17984[D loss: 0.466771, acc: 50.78%, op_acc: 37.50%] [G loss: 0.830051]\n",
      "epoch:23 step:17985[D loss: 0.417669, acc: 61.72%, op_acc: 39.84%] [G loss: 0.862111]\n",
      "epoch:23 step:17986[D loss: 0.487538, acc: 53.12%, op_acc: 34.38%] [G loss: 0.850673]\n",
      "epoch:23 step:17987[D loss: 0.449633, acc: 58.59%, op_acc: 35.16%] [G loss: 0.948976]\n",
      "epoch:23 step:17988[D loss: 0.408110, acc: 71.09%, op_acc: 42.97%] [G loss: 0.941840]\n",
      "epoch:23 step:17989[D loss: 0.431170, acc: 53.91%, op_acc: 41.41%] [G loss: 0.841908]\n",
      "epoch:23 step:17990[D loss: 0.475076, acc: 49.22%, op_acc: 34.38%] [G loss: 0.896574]\n",
      "epoch:23 step:17991[D loss: 0.444039, acc: 50.00%, op_acc: 42.97%] [G loss: 0.821140]\n",
      "epoch:23 step:17992[D loss: 0.412700, acc: 60.16%, op_acc: 42.19%] [G loss: 0.853169]\n",
      "epoch:23 step:17993[D loss: 0.424875, acc: 57.03%, op_acc: 37.50%] [G loss: 0.916562]\n",
      "epoch:23 step:17994[D loss: 0.464235, acc: 54.69%, op_acc: 35.94%] [G loss: 0.809019]\n",
      "epoch:23 step:17995[D loss: 0.437821, acc: 59.38%, op_acc: 37.50%] [G loss: 0.832632]\n",
      "epoch:23 step:17996[D loss: 0.415546, acc: 65.62%, op_acc: 46.88%] [G loss: 0.900587]\n",
      "epoch:23 step:17997[D loss: 0.403072, acc: 63.28%, op_acc: 39.06%] [G loss: 0.854130]\n",
      "epoch:23 step:17998[D loss: 0.441752, acc: 62.50%, op_acc: 34.38%] [G loss: 0.784635]\n",
      "epoch:23 step:17999[D loss: 0.417431, acc: 55.47%, op_acc: 46.88%] [G loss: 0.846095]\n",
      "epoch:23 step:18000[D loss: 0.420804, acc: 60.94%, op_acc: 39.06%] [G loss: 0.893302]\n",
      "##############\n",
      "[0.85464631 0.85564107 0.81818736 0.79812085 0.79459011 0.83439944\n",
      " 0.87951949 0.8105059  0.81285444 0.83283974]\n",
      "##########\n",
      "epoch:23 step:18001[D loss: 0.421387, acc: 62.50%, op_acc: 36.72%] [G loss: 0.861636]\n",
      "epoch:23 step:18002[D loss: 0.420821, acc: 54.69%, op_acc: 40.62%] [G loss: 0.828595]\n",
      "epoch:23 step:18003[D loss: 0.432225, acc: 57.81%, op_acc: 36.72%] [G loss: 0.954383]\n",
      "epoch:23 step:18004[D loss: 0.407343, acc: 61.72%, op_acc: 40.62%] [G loss: 0.858286]\n",
      "epoch:23 step:18005[D loss: 0.403233, acc: 60.94%, op_acc: 40.62%] [G loss: 0.910726]\n",
      "epoch:23 step:18006[D loss: 0.399798, acc: 64.84%, op_acc: 40.62%] [G loss: 0.872908]\n",
      "epoch:23 step:18007[D loss: 0.416939, acc: 60.94%, op_acc: 37.50%] [G loss: 0.869801]\n",
      "epoch:23 step:18008[D loss: 0.404778, acc: 64.06%, op_acc: 42.97%] [G loss: 0.926897]\n",
      "epoch:23 step:18009[D loss: 0.412822, acc: 60.94%, op_acc: 37.50%] [G loss: 0.892406]\n",
      "epoch:23 step:18010[D loss: 0.442197, acc: 61.72%, op_acc: 33.59%] [G loss: 0.856162]\n",
      "epoch:23 step:18011[D loss: 0.475689, acc: 53.12%, op_acc: 29.69%] [G loss: 0.832366]\n",
      "epoch:23 step:18012[D loss: 0.433286, acc: 58.59%, op_acc: 35.94%] [G loss: 0.784781]\n",
      "epoch:23 step:18013[D loss: 0.437199, acc: 55.47%, op_acc: 39.84%] [G loss: 0.764394]\n",
      "epoch:23 step:18014[D loss: 0.405075, acc: 60.94%, op_acc: 42.19%] [G loss: 0.854477]\n",
      "epoch:23 step:18015[D loss: 0.405210, acc: 65.62%, op_acc: 39.06%] [G loss: 0.891105]\n",
      "epoch:23 step:18016[D loss: 0.466765, acc: 46.88%, op_acc: 37.50%] [G loss: 0.853972]\n",
      "epoch:23 step:18017[D loss: 0.435445, acc: 60.94%, op_acc: 45.31%] [G loss: 0.902172]\n",
      "epoch:23 step:18018[D loss: 0.439678, acc: 53.12%, op_acc: 34.38%] [G loss: 0.827111]\n",
      "epoch:23 step:18019[D loss: 0.385288, acc: 73.44%, op_acc: 42.19%] [G loss: 0.883083]\n",
      "epoch:23 step:18020[D loss: 0.433005, acc: 57.03%, op_acc: 44.53%] [G loss: 0.859652]\n",
      "epoch:23 step:18021[D loss: 0.431918, acc: 57.03%, op_acc: 42.97%] [G loss: 0.882929]\n",
      "epoch:23 step:18022[D loss: 0.380145, acc: 64.84%, op_acc: 41.41%] [G loss: 0.839116]\n",
      "epoch:23 step:18023[D loss: 0.416751, acc: 62.50%, op_acc: 41.41%] [G loss: 0.879096]\n",
      "epoch:23 step:18024[D loss: 0.458248, acc: 51.56%, op_acc: 36.72%] [G loss: 0.898746]\n",
      "epoch:23 step:18025[D loss: 0.421629, acc: 60.16%, op_acc: 44.53%] [G loss: 0.856860]\n",
      "epoch:23 step:18026[D loss: 0.428961, acc: 60.16%, op_acc: 37.50%] [G loss: 0.841929]\n",
      "epoch:23 step:18027[D loss: 0.420420, acc: 54.69%, op_acc: 39.06%] [G loss: 0.853467]\n",
      "epoch:23 step:18028[D loss: 0.436298, acc: 57.81%, op_acc: 36.72%] [G loss: 0.910545]\n",
      "epoch:23 step:18029[D loss: 0.459258, acc: 47.66%, op_acc: 41.41%] [G loss: 0.854980]\n",
      "epoch:23 step:18030[D loss: 0.395299, acc: 65.62%, op_acc: 45.31%] [G loss: 0.889351]\n",
      "epoch:23 step:18031[D loss: 0.422708, acc: 58.59%, op_acc: 37.50%] [G loss: 0.940159]\n",
      "epoch:23 step:18032[D loss: 0.393446, acc: 64.06%, op_acc: 43.75%] [G loss: 0.831822]\n",
      "epoch:23 step:18033[D loss: 0.427729, acc: 56.25%, op_acc: 40.62%] [G loss: 0.794167]\n",
      "epoch:23 step:18034[D loss: 0.472141, acc: 54.69%, op_acc: 32.03%] [G loss: 0.769428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18035[D loss: 0.387121, acc: 67.97%, op_acc: 39.84%] [G loss: 0.947777]\n",
      "epoch:23 step:18036[D loss: 0.397726, acc: 64.84%, op_acc: 42.97%] [G loss: 0.848109]\n",
      "epoch:23 step:18037[D loss: 0.431184, acc: 49.22%, op_acc: 39.06%] [G loss: 0.826344]\n",
      "epoch:23 step:18038[D loss: 0.418972, acc: 64.84%, op_acc: 39.06%] [G loss: 0.871654]\n",
      "epoch:23 step:18039[D loss: 0.447908, acc: 54.69%, op_acc: 42.19%] [G loss: 0.901185]\n",
      "epoch:23 step:18040[D loss: 0.418979, acc: 62.50%, op_acc: 42.19%] [G loss: 0.829768]\n",
      "epoch:23 step:18041[D loss: 0.483161, acc: 53.91%, op_acc: 30.47%] [G loss: 0.932193]\n",
      "epoch:23 step:18042[D loss: 0.426590, acc: 59.38%, op_acc: 37.50%] [G loss: 0.923161]\n",
      "epoch:23 step:18043[D loss: 0.424255, acc: 64.84%, op_acc: 38.28%] [G loss: 0.895498]\n",
      "epoch:23 step:18044[D loss: 0.453812, acc: 56.25%, op_acc: 38.28%] [G loss: 0.845823]\n",
      "epoch:23 step:18045[D loss: 0.402862, acc: 54.69%, op_acc: 45.31%] [G loss: 0.854473]\n",
      "epoch:23 step:18046[D loss: 0.408952, acc: 72.66%, op_acc: 39.84%] [G loss: 0.920409]\n",
      "epoch:23 step:18047[D loss: 0.383332, acc: 71.88%, op_acc: 43.75%] [G loss: 0.864267]\n",
      "epoch:23 step:18048[D loss: 0.429501, acc: 64.06%, op_acc: 31.25%] [G loss: 0.906536]\n",
      "epoch:23 step:18049[D loss: 0.401179, acc: 64.06%, op_acc: 42.97%] [G loss: 0.914214]\n",
      "epoch:23 step:18050[D loss: 0.434719, acc: 59.38%, op_acc: 37.50%] [G loss: 0.869221]\n",
      "##############\n",
      "[0.85459044 0.86009762 0.81327862 0.80809394 0.79930098 0.83039402\n",
      " 0.86580463 0.83615569 0.83513193 0.80805385]\n",
      "##########\n",
      "epoch:23 step:18051[D loss: 0.406779, acc: 62.50%, op_acc: 41.41%] [G loss: 0.899808]\n",
      "epoch:23 step:18052[D loss: 0.441637, acc: 51.56%, op_acc: 42.97%] [G loss: 0.902714]\n",
      "epoch:23 step:18053[D loss: 0.435524, acc: 53.91%, op_acc: 44.53%] [G loss: 0.869850]\n",
      "epoch:23 step:18054[D loss: 0.410024, acc: 55.47%, op_acc: 35.94%] [G loss: 0.907459]\n",
      "epoch:23 step:18055[D loss: 0.415042, acc: 65.62%, op_acc: 37.50%] [G loss: 0.848965]\n",
      "epoch:23 step:18056[D loss: 0.413789, acc: 62.50%, op_acc: 37.50%] [G loss: 0.827081]\n",
      "epoch:23 step:18057[D loss: 0.414821, acc: 59.38%, op_acc: 36.72%] [G loss: 0.831060]\n",
      "epoch:23 step:18058[D loss: 0.417471, acc: 59.38%, op_acc: 38.28%] [G loss: 0.891194]\n",
      "epoch:23 step:18059[D loss: 0.442948, acc: 56.25%, op_acc: 32.81%] [G loss: 0.916029]\n",
      "epoch:23 step:18060[D loss: 0.388761, acc: 65.62%, op_acc: 38.28%] [G loss: 0.851834]\n",
      "epoch:23 step:18061[D loss: 0.401848, acc: 73.44%, op_acc: 35.94%] [G loss: 0.949041]\n",
      "epoch:23 step:18062[D loss: 0.433610, acc: 52.34%, op_acc: 39.84%] [G loss: 0.924455]\n",
      "epoch:23 step:18063[D loss: 0.411920, acc: 56.25%, op_acc: 47.66%] [G loss: 0.915735]\n",
      "epoch:23 step:18064[D loss: 0.416770, acc: 59.38%, op_acc: 39.84%] [G loss: 0.854601]\n",
      "epoch:23 step:18065[D loss: 0.426064, acc: 62.50%, op_acc: 35.94%] [G loss: 0.868531]\n",
      "epoch:23 step:18066[D loss: 0.406735, acc: 62.50%, op_acc: 42.97%] [G loss: 0.908380]\n",
      "epoch:23 step:18067[D loss: 0.430697, acc: 63.28%, op_acc: 39.06%] [G loss: 0.784289]\n",
      "epoch:23 step:18068[D loss: 0.452772, acc: 53.12%, op_acc: 35.16%] [G loss: 0.862389]\n",
      "epoch:23 step:18069[D loss: 0.397349, acc: 65.62%, op_acc: 38.28%] [G loss: 0.867821]\n",
      "epoch:23 step:18070[D loss: 0.403989, acc: 66.41%, op_acc: 44.53%] [G loss: 0.869020]\n",
      "epoch:23 step:18071[D loss: 0.455253, acc: 54.69%, op_acc: 30.47%] [G loss: 0.873822]\n",
      "epoch:23 step:18072[D loss: 0.393108, acc: 63.28%, op_acc: 42.97%] [G loss: 0.928416]\n",
      "epoch:23 step:18073[D loss: 0.422689, acc: 60.94%, op_acc: 38.28%] [G loss: 0.823017]\n",
      "epoch:23 step:18074[D loss: 0.459286, acc: 53.91%, op_acc: 33.59%] [G loss: 0.867032]\n",
      "epoch:23 step:18075[D loss: 0.435442, acc: 56.25%, op_acc: 41.41%] [G loss: 0.955528]\n",
      "epoch:23 step:18076[D loss: 0.440821, acc: 58.59%, op_acc: 39.84%] [G loss: 0.896093]\n",
      "epoch:23 step:18077[D loss: 0.398541, acc: 67.19%, op_acc: 46.09%] [G loss: 0.879937]\n",
      "epoch:23 step:18078[D loss: 0.423951, acc: 53.12%, op_acc: 41.41%] [G loss: 0.876614]\n",
      "epoch:23 step:18079[D loss: 0.461797, acc: 56.25%, op_acc: 35.16%] [G loss: 0.851681]\n",
      "epoch:23 step:18080[D loss: 0.423525, acc: 58.59%, op_acc: 41.41%] [G loss: 0.905893]\n",
      "epoch:23 step:18081[D loss: 0.436982, acc: 57.03%, op_acc: 39.06%] [G loss: 0.836180]\n",
      "epoch:23 step:18082[D loss: 0.405784, acc: 63.28%, op_acc: 40.62%] [G loss: 0.822102]\n",
      "epoch:23 step:18083[D loss: 0.461285, acc: 50.78%, op_acc: 39.06%] [G loss: 0.908090]\n",
      "epoch:23 step:18084[D loss: 0.435906, acc: 62.50%, op_acc: 39.06%] [G loss: 0.793835]\n",
      "epoch:23 step:18085[D loss: 0.452483, acc: 52.34%, op_acc: 40.62%] [G loss: 0.855524]\n",
      "epoch:23 step:18086[D loss: 0.466222, acc: 50.78%, op_acc: 32.81%] [G loss: 0.816046]\n",
      "epoch:23 step:18087[D loss: 0.417332, acc: 58.59%, op_acc: 44.53%] [G loss: 0.852126]\n",
      "epoch:23 step:18088[D loss: 0.445517, acc: 57.81%, op_acc: 37.50%] [G loss: 0.853394]\n",
      "epoch:23 step:18089[D loss: 0.445379, acc: 54.69%, op_acc: 34.38%] [G loss: 0.770269]\n",
      "epoch:23 step:18090[D loss: 0.432439, acc: 64.06%, op_acc: 35.94%] [G loss: 0.826668]\n",
      "epoch:23 step:18091[D loss: 0.417735, acc: 60.94%, op_acc: 36.72%] [G loss: 0.865184]\n",
      "epoch:23 step:18092[D loss: 0.436133, acc: 63.28%, op_acc: 36.72%] [G loss: 0.885489]\n",
      "epoch:23 step:18093[D loss: 0.390335, acc: 65.62%, op_acc: 46.88%] [G loss: 0.936953]\n",
      "epoch:23 step:18094[D loss: 0.390707, acc: 67.97%, op_acc: 42.97%] [G loss: 0.842759]\n",
      "epoch:23 step:18095[D loss: 0.407672, acc: 63.28%, op_acc: 43.75%] [G loss: 0.830820]\n",
      "epoch:23 step:18096[D loss: 0.447116, acc: 56.25%, op_acc: 36.72%] [G loss: 0.893235]\n",
      "epoch:23 step:18097[D loss: 0.401075, acc: 66.41%, op_acc: 43.75%] [G loss: 0.841262]\n",
      "epoch:23 step:18098[D loss: 0.429477, acc: 60.94%, op_acc: 40.62%] [G loss: 0.838656]\n",
      "epoch:23 step:18099[D loss: 0.396354, acc: 61.72%, op_acc: 40.62%] [G loss: 0.950122]\n",
      "epoch:23 step:18100[D loss: 0.420399, acc: 57.81%, op_acc: 41.41%] [G loss: 0.870555]\n",
      "##############\n",
      "[0.85355293 0.87672367 0.81963946 0.82764761 0.79168597 0.82122456\n",
      " 0.87317637 0.82776652 0.80868338 0.83171384]\n",
      "##########\n",
      "epoch:23 step:18101[D loss: 0.430030, acc: 58.59%, op_acc: 39.06%] [G loss: 0.879747]\n",
      "epoch:23 step:18102[D loss: 0.391760, acc: 65.62%, op_acc: 39.06%] [G loss: 0.824268]\n",
      "epoch:23 step:18103[D loss: 0.475711, acc: 54.69%, op_acc: 34.38%] [G loss: 0.832065]\n",
      "epoch:23 step:18104[D loss: 0.440284, acc: 57.03%, op_acc: 38.28%] [G loss: 0.852731]\n",
      "epoch:23 step:18105[D loss: 0.425391, acc: 61.72%, op_acc: 36.72%] [G loss: 0.828764]\n",
      "epoch:23 step:18106[D loss: 0.444132, acc: 57.03%, op_acc: 36.72%] [G loss: 0.843038]\n",
      "epoch:23 step:18107[D loss: 0.472579, acc: 46.09%, op_acc: 37.50%] [G loss: 0.947681]\n",
      "epoch:23 step:18108[D loss: 0.417772, acc: 61.72%, op_acc: 42.19%] [G loss: 0.836968]\n",
      "epoch:23 step:18109[D loss: 0.414698, acc: 60.94%, op_acc: 38.28%] [G loss: 0.917520]\n",
      "epoch:23 step:18110[D loss: 0.414891, acc: 63.28%, op_acc: 37.50%] [G loss: 0.847194]\n",
      "epoch:23 step:18111[D loss: 0.426001, acc: 60.16%, op_acc: 35.16%] [G loss: 0.867814]\n",
      "epoch:23 step:18112[D loss: 0.404724, acc: 59.38%, op_acc: 42.97%] [G loss: 0.851079]\n",
      "epoch:23 step:18113[D loss: 0.433701, acc: 54.69%, op_acc: 42.97%] [G loss: 0.856645]\n",
      "epoch:23 step:18114[D loss: 0.447185, acc: 53.91%, op_acc: 39.06%] [G loss: 0.876172]\n",
      "epoch:23 step:18115[D loss: 0.424027, acc: 51.56%, op_acc: 39.06%] [G loss: 0.777245]\n",
      "epoch:23 step:18116[D loss: 0.409295, acc: 64.06%, op_acc: 36.72%] [G loss: 0.880091]\n",
      "epoch:23 step:18117[D loss: 0.410932, acc: 64.84%, op_acc: 42.19%] [G loss: 0.894731]\n",
      "epoch:23 step:18118[D loss: 0.443309, acc: 50.78%, op_acc: 39.06%] [G loss: 0.844268]\n",
      "epoch:23 step:18119[D loss: 0.430221, acc: 54.69%, op_acc: 37.50%] [G loss: 0.777319]\n",
      "epoch:23 step:18120[D loss: 0.455606, acc: 53.91%, op_acc: 37.50%] [G loss: 0.799495]\n",
      "epoch:23 step:18121[D loss: 0.408948, acc: 59.38%, op_acc: 36.72%] [G loss: 0.863950]\n",
      "epoch:23 step:18122[D loss: 0.429032, acc: 63.28%, op_acc: 35.94%] [G loss: 0.890188]\n",
      "epoch:23 step:18123[D loss: 0.435214, acc: 59.38%, op_acc: 32.03%] [G loss: 0.833006]\n",
      "epoch:23 step:18124[D loss: 0.439078, acc: 54.69%, op_acc: 37.50%] [G loss: 0.879551]\n",
      "epoch:23 step:18125[D loss: 0.446770, acc: 50.00%, op_acc: 39.06%] [G loss: 0.890558]\n",
      "epoch:23 step:18126[D loss: 0.434556, acc: 54.69%, op_acc: 36.72%] [G loss: 0.915934]\n",
      "epoch:23 step:18127[D loss: 0.442216, acc: 52.34%, op_acc: 35.94%] [G loss: 0.895149]\n",
      "epoch:23 step:18128[D loss: 0.408406, acc: 64.84%, op_acc: 39.84%] [G loss: 0.964334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18129[D loss: 0.472689, acc: 51.56%, op_acc: 37.50%] [G loss: 0.865086]\n",
      "epoch:23 step:18130[D loss: 0.407126, acc: 57.03%, op_acc: 45.31%] [G loss: 0.944234]\n",
      "epoch:23 step:18131[D loss: 0.417793, acc: 57.03%, op_acc: 43.75%] [G loss: 0.882558]\n",
      "epoch:23 step:18132[D loss: 0.433932, acc: 53.12%, op_acc: 42.19%] [G loss: 0.840676]\n",
      "epoch:23 step:18133[D loss: 0.448813, acc: 50.78%, op_acc: 39.06%] [G loss: 0.842256]\n",
      "epoch:23 step:18134[D loss: 0.447988, acc: 53.91%, op_acc: 32.81%] [G loss: 0.916057]\n",
      "epoch:23 step:18135[D loss: 0.421545, acc: 63.28%, op_acc: 41.41%] [G loss: 0.939652]\n",
      "epoch:23 step:18136[D loss: 0.463400, acc: 44.53%, op_acc: 35.94%] [G loss: 0.885237]\n",
      "epoch:23 step:18137[D loss: 0.455071, acc: 50.00%, op_acc: 36.72%] [G loss: 0.853981]\n",
      "epoch:23 step:18138[D loss: 0.405004, acc: 63.28%, op_acc: 40.62%] [G loss: 0.868054]\n",
      "epoch:23 step:18139[D loss: 0.442878, acc: 59.38%, op_acc: 39.06%] [G loss: 0.843088]\n",
      "epoch:23 step:18140[D loss: 0.432873, acc: 53.12%, op_acc: 39.06%] [G loss: 0.828158]\n",
      "epoch:23 step:18141[D loss: 0.455703, acc: 54.69%, op_acc: 34.38%] [G loss: 0.848098]\n",
      "epoch:23 step:18142[D loss: 0.406310, acc: 63.28%, op_acc: 42.19%] [G loss: 0.866992]\n",
      "epoch:23 step:18143[D loss: 0.401309, acc: 63.28%, op_acc: 40.62%] [G loss: 0.881796]\n",
      "epoch:23 step:18144[D loss: 0.386227, acc: 60.94%, op_acc: 42.97%] [G loss: 0.898018]\n",
      "epoch:23 step:18145[D loss: 0.396917, acc: 64.06%, op_acc: 39.06%] [G loss: 0.907480]\n",
      "epoch:23 step:18146[D loss: 0.409256, acc: 59.38%, op_acc: 39.84%] [G loss: 0.890464]\n",
      "epoch:23 step:18147[D loss: 0.410702, acc: 64.06%, op_acc: 38.28%] [G loss: 0.955844]\n",
      "epoch:23 step:18148[D loss: 0.423872, acc: 66.41%, op_acc: 38.28%] [G loss: 0.945576]\n",
      "epoch:23 step:18149[D loss: 0.423795, acc: 61.72%, op_acc: 37.50%] [G loss: 0.836458]\n",
      "epoch:23 step:18150[D loss: 0.429623, acc: 58.59%, op_acc: 42.19%] [G loss: 0.912046]\n",
      "##############\n",
      "[0.87656052 0.86299879 0.80772395 0.80322265 0.78018527 0.81128007\n",
      " 0.8826704  0.82194459 0.82661417 0.82750812]\n",
      "##########\n",
      "epoch:23 step:18151[D loss: 0.421564, acc: 49.22%, op_acc: 39.84%] [G loss: 0.880749]\n",
      "epoch:23 step:18152[D loss: 0.431643, acc: 60.16%, op_acc: 34.38%] [G loss: 0.911578]\n",
      "epoch:23 step:18153[D loss: 0.422485, acc: 66.41%, op_acc: 36.72%] [G loss: 0.939384]\n",
      "epoch:23 step:18154[D loss: 0.431040, acc: 54.69%, op_acc: 38.28%] [G loss: 0.803367]\n",
      "epoch:23 step:18155[D loss: 0.390593, acc: 71.09%, op_acc: 34.38%] [G loss: 0.912171]\n",
      "epoch:23 step:18156[D loss: 0.453269, acc: 56.25%, op_acc: 31.25%] [G loss: 0.848803]\n",
      "epoch:23 step:18157[D loss: 0.410095, acc: 70.31%, op_acc: 43.75%] [G loss: 0.925289]\n",
      "epoch:23 step:18158[D loss: 0.434946, acc: 57.81%, op_acc: 39.06%] [G loss: 0.850011]\n",
      "epoch:23 step:18159[D loss: 0.404072, acc: 66.41%, op_acc: 41.41%] [G loss: 0.932603]\n",
      "epoch:23 step:18160[D loss: 0.435747, acc: 60.16%, op_acc: 38.28%] [G loss: 0.912230]\n",
      "epoch:23 step:18161[D loss: 0.460245, acc: 51.56%, op_acc: 36.72%] [G loss: 0.867443]\n",
      "epoch:23 step:18162[D loss: 0.454528, acc: 53.12%, op_acc: 43.75%] [G loss: 0.844113]\n",
      "epoch:23 step:18163[D loss: 0.432566, acc: 56.25%, op_acc: 38.28%] [G loss: 0.902037]\n",
      "epoch:23 step:18164[D loss: 0.422245, acc: 57.03%, op_acc: 40.62%] [G loss: 0.866494]\n",
      "epoch:23 step:18165[D loss: 0.447741, acc: 57.81%, op_acc: 36.72%] [G loss: 0.860502]\n",
      "epoch:23 step:18166[D loss: 0.420716, acc: 67.97%, op_acc: 38.28%] [G loss: 0.912139]\n",
      "epoch:23 step:18167[D loss: 0.429577, acc: 60.16%, op_acc: 38.28%] [G loss: 0.891698]\n",
      "epoch:23 step:18168[D loss: 0.420325, acc: 65.62%, op_acc: 33.59%] [G loss: 0.952044]\n",
      "epoch:23 step:18169[D loss: 0.427964, acc: 51.56%, op_acc: 38.28%] [G loss: 0.907178]\n",
      "epoch:23 step:18170[D loss: 0.386157, acc: 67.19%, op_acc: 48.44%] [G loss: 0.975995]\n",
      "epoch:23 step:18171[D loss: 0.493931, acc: 42.19%, op_acc: 35.94%] [G loss: 0.855703]\n",
      "epoch:23 step:18172[D loss: 0.405165, acc: 63.28%, op_acc: 46.09%] [G loss: 0.980798]\n",
      "epoch:23 step:18173[D loss: 0.409693, acc: 66.41%, op_acc: 39.84%] [G loss: 0.914347]\n",
      "epoch:23 step:18174[D loss: 0.412700, acc: 63.28%, op_acc: 41.41%] [G loss: 0.957019]\n",
      "epoch:23 step:18175[D loss: 0.428011, acc: 58.59%, op_acc: 40.62%] [G loss: 0.918086]\n",
      "epoch:23 step:18176[D loss: 0.433241, acc: 53.91%, op_acc: 39.84%] [G loss: 0.959408]\n",
      "epoch:23 step:18177[D loss: 0.445720, acc: 57.03%, op_acc: 35.94%] [G loss: 0.828960]\n",
      "epoch:23 step:18178[D loss: 0.440812, acc: 60.16%, op_acc: 40.62%] [G loss: 0.832037]\n",
      "epoch:23 step:18179[D loss: 0.415481, acc: 62.50%, op_acc: 42.19%] [G loss: 0.851367]\n",
      "epoch:23 step:18180[D loss: 0.416745, acc: 65.62%, op_acc: 42.19%] [G loss: 0.933328]\n",
      "epoch:23 step:18181[D loss: 0.414199, acc: 60.94%, op_acc: 42.97%] [G loss: 0.900308]\n",
      "epoch:23 step:18182[D loss: 0.405002, acc: 60.94%, op_acc: 39.84%] [G loss: 0.965969]\n",
      "epoch:23 step:18183[D loss: 0.454362, acc: 55.47%, op_acc: 37.50%] [G loss: 0.921917]\n",
      "epoch:23 step:18184[D loss: 0.412546, acc: 67.19%, op_acc: 46.09%] [G loss: 0.881611]\n",
      "epoch:23 step:18185[D loss: 0.434876, acc: 57.03%, op_acc: 41.41%] [G loss: 0.902331]\n",
      "epoch:23 step:18186[D loss: 0.435976, acc: 54.69%, op_acc: 36.72%] [G loss: 0.901778]\n",
      "epoch:23 step:18187[D loss: 0.416083, acc: 57.03%, op_acc: 42.19%] [G loss: 0.833644]\n",
      "epoch:23 step:18188[D loss: 0.435175, acc: 59.38%, op_acc: 40.62%] [G loss: 0.837029]\n",
      "epoch:23 step:18189[D loss: 0.413263, acc: 62.50%, op_acc: 36.72%] [G loss: 0.910869]\n",
      "epoch:23 step:18190[D loss: 0.434471, acc: 51.56%, op_acc: 36.72%] [G loss: 0.892080]\n",
      "epoch:23 step:18191[D loss: 0.424403, acc: 56.25%, op_acc: 44.53%] [G loss: 0.865500]\n",
      "epoch:23 step:18192[D loss: 0.411631, acc: 65.62%, op_acc: 38.28%] [G loss: 0.899076]\n",
      "epoch:23 step:18193[D loss: 0.423510, acc: 67.97%, op_acc: 42.97%] [G loss: 0.931659]\n",
      "epoch:23 step:18194[D loss: 0.386892, acc: 67.97%, op_acc: 43.75%] [G loss: 0.881024]\n",
      "epoch:23 step:18195[D loss: 0.416496, acc: 60.16%, op_acc: 36.72%] [G loss: 0.890390]\n",
      "epoch:23 step:18196[D loss: 0.406933, acc: 60.94%, op_acc: 42.97%] [G loss: 0.896750]\n",
      "epoch:23 step:18197[D loss: 0.433751, acc: 67.97%, op_acc: 39.06%] [G loss: 0.916862]\n",
      "epoch:23 step:18198[D loss: 0.398180, acc: 64.84%, op_acc: 43.75%] [G loss: 0.824773]\n",
      "epoch:23 step:18199[D loss: 0.459293, acc: 56.25%, op_acc: 35.94%] [G loss: 0.989007]\n",
      "epoch:23 step:18200[D loss: 0.411786, acc: 59.38%, op_acc: 46.88%] [G loss: 0.910834]\n",
      "##############\n",
      "[0.83455783 0.85997582 0.79772633 0.81018761 0.80917417 0.84383835\n",
      " 0.90152252 0.83066077 0.80626754 0.82025784]\n",
      "##########\n",
      "epoch:23 step:18201[D loss: 0.429284, acc: 57.81%, op_acc: 44.53%] [G loss: 0.891566]\n",
      "epoch:23 step:18202[D loss: 0.433447, acc: 58.59%, op_acc: 39.06%] [G loss: 0.808787]\n",
      "epoch:23 step:18203[D loss: 0.422171, acc: 60.94%, op_acc: 35.16%] [G loss: 0.855980]\n",
      "epoch:23 step:18204[D loss: 0.432369, acc: 53.12%, op_acc: 44.53%] [G loss: 0.849143]\n",
      "epoch:23 step:18205[D loss: 0.389808, acc: 63.28%, op_acc: 43.75%] [G loss: 0.956657]\n",
      "epoch:23 step:18206[D loss: 0.429416, acc: 52.34%, op_acc: 44.53%] [G loss: 0.895436]\n",
      "epoch:23 step:18207[D loss: 0.450256, acc: 53.91%, op_acc: 38.28%] [G loss: 0.930325]\n",
      "epoch:23 step:18208[D loss: 0.428649, acc: 56.25%, op_acc: 42.97%] [G loss: 0.924219]\n",
      "epoch:23 step:18209[D loss: 0.458379, acc: 57.03%, op_acc: 35.16%] [G loss: 0.966333]\n",
      "epoch:23 step:18210[D loss: 0.433098, acc: 53.91%, op_acc: 41.41%] [G loss: 0.968023]\n",
      "epoch:23 step:18211[D loss: 0.423701, acc: 63.28%, op_acc: 36.72%] [G loss: 0.842436]\n",
      "epoch:23 step:18212[D loss: 0.436261, acc: 58.59%, op_acc: 39.06%] [G loss: 0.818160]\n",
      "epoch:23 step:18213[D loss: 0.472742, acc: 54.69%, op_acc: 27.34%] [G loss: 0.782727]\n",
      "epoch:23 step:18214[D loss: 0.399504, acc: 65.62%, op_acc: 42.97%] [G loss: 0.916942]\n",
      "epoch:23 step:18215[D loss: 0.426819, acc: 56.25%, op_acc: 35.94%] [G loss: 0.860520]\n",
      "epoch:23 step:18216[D loss: 0.455066, acc: 61.72%, op_acc: 28.91%] [G loss: 0.822842]\n",
      "epoch:23 step:18217[D loss: 0.437623, acc: 67.19%, op_acc: 36.72%] [G loss: 0.935600]\n",
      "epoch:23 step:18218[D loss: 0.432573, acc: 52.34%, op_acc: 36.72%] [G loss: 0.835025]\n",
      "epoch:23 step:18219[D loss: 0.459697, acc: 51.56%, op_acc: 36.72%] [G loss: 0.835188]\n",
      "epoch:23 step:18220[D loss: 0.434176, acc: 63.28%, op_acc: 34.38%] [G loss: 0.835948]\n",
      "epoch:23 step:18221[D loss: 0.429095, acc: 53.12%, op_acc: 39.84%] [G loss: 0.864124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18222[D loss: 0.449741, acc: 57.03%, op_acc: 32.81%] [G loss: 0.868755]\n",
      "epoch:23 step:18223[D loss: 0.416110, acc: 63.28%, op_acc: 42.19%] [G loss: 0.865572]\n",
      "epoch:23 step:18224[D loss: 0.435527, acc: 60.16%, op_acc: 35.16%] [G loss: 0.877088]\n",
      "epoch:23 step:18225[D loss: 0.397979, acc: 64.84%, op_acc: 35.16%] [G loss: 0.913261]\n",
      "epoch:23 step:18226[D loss: 0.460428, acc: 53.91%, op_acc: 36.72%] [G loss: 0.883469]\n",
      "epoch:23 step:18227[D loss: 0.438319, acc: 57.03%, op_acc: 35.94%] [G loss: 0.961124]\n",
      "epoch:23 step:18228[D loss: 0.427776, acc: 56.25%, op_acc: 39.06%] [G loss: 0.930002]\n",
      "epoch:23 step:18229[D loss: 0.462325, acc: 49.22%, op_acc: 38.28%] [G loss: 0.837945]\n",
      "epoch:23 step:18230[D loss: 0.470130, acc: 50.00%, op_acc: 33.59%] [G loss: 0.885004]\n",
      "epoch:23 step:18231[D loss: 0.434339, acc: 52.34%, op_acc: 39.84%] [G loss: 0.872078]\n",
      "epoch:23 step:18232[D loss: 0.427526, acc: 56.25%, op_acc: 36.72%] [G loss: 0.943275]\n",
      "epoch:23 step:18233[D loss: 0.440393, acc: 47.66%, op_acc: 38.28%] [G loss: 0.906833]\n",
      "epoch:23 step:18234[D loss: 0.431678, acc: 57.03%, op_acc: 37.50%] [G loss: 0.929768]\n",
      "epoch:23 step:18235[D loss: 0.423284, acc: 58.59%, op_acc: 40.62%] [G loss: 0.924458]\n",
      "epoch:23 step:18236[D loss: 0.428719, acc: 56.25%, op_acc: 39.84%] [G loss: 0.940125]\n",
      "epoch:23 step:18237[D loss: 0.437660, acc: 57.03%, op_acc: 39.06%] [G loss: 0.889601]\n",
      "epoch:23 step:18238[D loss: 0.441419, acc: 55.47%, op_acc: 40.62%] [G loss: 0.863475]\n",
      "epoch:23 step:18239[D loss: 0.444477, acc: 49.22%, op_acc: 41.41%] [G loss: 0.815457]\n",
      "epoch:23 step:18240[D loss: 0.463310, acc: 53.12%, op_acc: 35.16%] [G loss: 0.846972]\n",
      "epoch:23 step:18241[D loss: 0.452969, acc: 53.91%, op_acc: 35.94%] [G loss: 0.828313]\n",
      "epoch:23 step:18242[D loss: 0.425386, acc: 65.62%, op_acc: 38.28%] [G loss: 0.856351]\n",
      "epoch:23 step:18243[D loss: 0.448668, acc: 48.44%, op_acc: 39.84%] [G loss: 0.857955]\n",
      "epoch:23 step:18244[D loss: 0.426034, acc: 62.50%, op_acc: 32.81%] [G loss: 0.835390]\n",
      "epoch:23 step:18245[D loss: 0.443288, acc: 57.81%, op_acc: 39.84%] [G loss: 0.876389]\n",
      "epoch:23 step:18246[D loss: 0.431484, acc: 55.47%, op_acc: 42.19%] [G loss: 0.841130]\n",
      "epoch:23 step:18247[D loss: 0.400414, acc: 65.62%, op_acc: 41.41%] [G loss: 0.908297]\n",
      "epoch:23 step:18248[D loss: 0.431573, acc: 54.69%, op_acc: 39.84%] [G loss: 0.906767]\n",
      "epoch:23 step:18249[D loss: 0.421212, acc: 64.06%, op_acc: 35.94%] [G loss: 0.877932]\n",
      "epoch:23 step:18250[D loss: 0.440282, acc: 55.47%, op_acc: 40.62%] [G loss: 0.873730]\n",
      "##############\n",
      "[0.8609862  0.85977679 0.80063872 0.8118635  0.76840141 0.82357321\n",
      " 0.88245924 0.82720955 0.79879246 0.83391213]\n",
      "##########\n",
      "epoch:23 step:18251[D loss: 0.418709, acc: 58.59%, op_acc: 42.97%] [G loss: 0.823526]\n",
      "epoch:23 step:18252[D loss: 0.448200, acc: 50.78%, op_acc: 33.59%] [G loss: 0.918900]\n",
      "epoch:23 step:18253[D loss: 0.400025, acc: 63.28%, op_acc: 42.97%] [G loss: 0.828864]\n",
      "epoch:23 step:18254[D loss: 0.450952, acc: 51.56%, op_acc: 36.72%] [G loss: 0.934774]\n",
      "epoch:23 step:18255[D loss: 0.418095, acc: 62.50%, op_acc: 37.50%] [G loss: 0.856505]\n",
      "epoch:23 step:18256[D loss: 0.429653, acc: 56.25%, op_acc: 39.06%] [G loss: 0.883641]\n",
      "epoch:23 step:18257[D loss: 0.413588, acc: 64.84%, op_acc: 39.84%] [G loss: 0.885952]\n",
      "epoch:23 step:18258[D loss: 0.410187, acc: 57.81%, op_acc: 42.19%] [G loss: 0.909469]\n",
      "epoch:23 step:18259[D loss: 0.426655, acc: 61.72%, op_acc: 39.84%] [G loss: 0.864551]\n",
      "epoch:23 step:18260[D loss: 0.418529, acc: 63.28%, op_acc: 34.38%] [G loss: 0.908694]\n",
      "epoch:23 step:18261[D loss: 0.439952, acc: 54.69%, op_acc: 39.06%] [G loss: 0.942248]\n",
      "epoch:23 step:18262[D loss: 0.424641, acc: 56.25%, op_acc: 37.50%] [G loss: 0.869476]\n",
      "epoch:23 step:18263[D loss: 0.409699, acc: 62.50%, op_acc: 37.50%] [G loss: 0.857659]\n",
      "epoch:23 step:18264[D loss: 0.412985, acc: 62.50%, op_acc: 39.06%] [G loss: 0.918667]\n",
      "epoch:23 step:18265[D loss: 0.410857, acc: 61.72%, op_acc: 39.06%] [G loss: 0.875304]\n",
      "epoch:23 step:18266[D loss: 0.430114, acc: 60.16%, op_acc: 35.94%] [G loss: 0.846424]\n",
      "epoch:23 step:18267[D loss: 0.428086, acc: 60.16%, op_acc: 38.28%] [G loss: 0.865192]\n",
      "epoch:23 step:18268[D loss: 0.409209, acc: 67.19%, op_acc: 33.59%] [G loss: 0.951798]\n",
      "epoch:23 step:18269[D loss: 0.430932, acc: 63.28%, op_acc: 41.41%] [G loss: 0.887002]\n",
      "epoch:23 step:18270[D loss: 0.411653, acc: 64.06%, op_acc: 39.84%] [G loss: 0.939104]\n",
      "epoch:23 step:18271[D loss: 0.435949, acc: 57.03%, op_acc: 40.62%] [G loss: 0.861039]\n",
      "epoch:23 step:18272[D loss: 0.442124, acc: 54.69%, op_acc: 38.28%] [G loss: 0.799399]\n",
      "epoch:23 step:18273[D loss: 0.428658, acc: 58.59%, op_acc: 36.72%] [G loss: 0.816179]\n",
      "epoch:23 step:18274[D loss: 0.433977, acc: 54.69%, op_acc: 40.62%] [G loss: 0.850256]\n",
      "epoch:23 step:18275[D loss: 0.441018, acc: 57.81%, op_acc: 39.06%] [G loss: 0.857343]\n",
      "epoch:23 step:18276[D loss: 0.438357, acc: 55.47%, op_acc: 36.72%] [G loss: 0.824251]\n",
      "epoch:23 step:18277[D loss: 0.416652, acc: 60.94%, op_acc: 37.50%] [G loss: 0.855901]\n",
      "epoch:23 step:18278[D loss: 0.434095, acc: 58.59%, op_acc: 38.28%] [G loss: 0.949457]\n",
      "epoch:23 step:18279[D loss: 0.437559, acc: 56.25%, op_acc: 38.28%] [G loss: 0.830279]\n",
      "epoch:23 step:18280[D loss: 0.433686, acc: 57.03%, op_acc: 41.41%] [G loss: 0.806375]\n",
      "epoch:23 step:18281[D loss: 0.443874, acc: 53.91%, op_acc: 38.28%] [G loss: 0.830565]\n",
      "epoch:23 step:18282[D loss: 0.422242, acc: 58.59%, op_acc: 42.19%] [G loss: 0.780569]\n",
      "epoch:23 step:18283[D loss: 0.473564, acc: 52.34%, op_acc: 32.81%] [G loss: 0.849820]\n",
      "epoch:23 step:18284[D loss: 0.453619, acc: 51.56%, op_acc: 40.62%] [G loss: 0.948021]\n",
      "epoch:23 step:18285[D loss: 0.414658, acc: 62.50%, op_acc: 37.50%] [G loss: 0.859839]\n",
      "epoch:23 step:18286[D loss: 0.445267, acc: 53.12%, op_acc: 39.84%] [G loss: 0.860156]\n",
      "epoch:23 step:18287[D loss: 0.431948, acc: 62.50%, op_acc: 36.72%] [G loss: 0.887849]\n",
      "epoch:23 step:18288[D loss: 0.406568, acc: 57.81%, op_acc: 45.31%] [G loss: 0.931579]\n",
      "epoch:23 step:18289[D loss: 0.437309, acc: 55.47%, op_acc: 34.38%] [G loss: 0.869089]\n",
      "epoch:23 step:18290[D loss: 0.412669, acc: 64.06%, op_acc: 38.28%] [G loss: 0.907257]\n",
      "epoch:23 step:18291[D loss: 0.416445, acc: 60.16%, op_acc: 36.72%] [G loss: 0.927260]\n",
      "epoch:23 step:18292[D loss: 0.434791, acc: 53.91%, op_acc: 39.06%] [G loss: 0.876691]\n",
      "epoch:23 step:18293[D loss: 0.425812, acc: 56.25%, op_acc: 41.41%] [G loss: 0.813701]\n",
      "epoch:23 step:18294[D loss: 0.444457, acc: 52.34%, op_acc: 35.94%] [G loss: 0.792745]\n",
      "epoch:23 step:18295[D loss: 0.433511, acc: 53.91%, op_acc: 40.62%] [G loss: 0.751758]\n",
      "epoch:23 step:18296[D loss: 0.403213, acc: 66.41%, op_acc: 39.84%] [G loss: 0.867214]\n",
      "epoch:23 step:18297[D loss: 0.419762, acc: 58.59%, op_acc: 36.72%] [G loss: 0.895986]\n",
      "epoch:23 step:18298[D loss: 0.398351, acc: 70.31%, op_acc: 39.06%] [G loss: 0.905751]\n",
      "epoch:23 step:18299[D loss: 0.416370, acc: 60.16%, op_acc: 41.41%] [G loss: 0.881326]\n",
      "epoch:23 step:18300[D loss: 0.451797, acc: 56.25%, op_acc: 32.81%] [G loss: 1.001815]\n",
      "##############\n",
      "[0.84871174 0.86679985 0.80890063 0.79910124 0.82111176 0.82411749\n",
      " 0.88600678 0.81485752 0.8089262  0.82803731]\n",
      "##########\n",
      "epoch:23 step:18301[D loss: 0.385112, acc: 66.41%, op_acc: 46.88%] [G loss: 0.844508]\n",
      "epoch:23 step:18302[D loss: 0.416301, acc: 63.28%, op_acc: 40.62%] [G loss: 0.830588]\n",
      "epoch:23 step:18303[D loss: 0.439083, acc: 58.59%, op_acc: 35.16%] [G loss: 0.866715]\n",
      "epoch:23 step:18304[D loss: 0.433900, acc: 59.38%, op_acc: 33.59%] [G loss: 0.861567]\n",
      "epoch:23 step:18305[D loss: 0.436489, acc: 53.91%, op_acc: 35.16%] [G loss: 0.809663]\n",
      "epoch:23 step:18306[D loss: 0.443592, acc: 57.81%, op_acc: 35.16%] [G loss: 0.938124]\n",
      "epoch:23 step:18307[D loss: 0.429139, acc: 60.94%, op_acc: 39.84%] [G loss: 0.891773]\n",
      "epoch:23 step:18308[D loss: 0.415580, acc: 62.50%, op_acc: 36.72%] [G loss: 0.935123]\n",
      "epoch:23 step:18309[D loss: 0.420331, acc: 61.72%, op_acc: 38.28%] [G loss: 0.896507]\n",
      "epoch:23 step:18310[D loss: 0.415022, acc: 54.69%, op_acc: 42.97%] [G loss: 0.791672]\n",
      "epoch:23 step:18311[D loss: 0.416491, acc: 62.50%, op_acc: 35.94%] [G loss: 0.889462]\n",
      "epoch:23 step:18312[D loss: 0.422308, acc: 60.94%, op_acc: 39.84%] [G loss: 0.922425]\n",
      "epoch:23 step:18313[D loss: 0.454192, acc: 51.56%, op_acc: 38.28%] [G loss: 0.856059]\n",
      "epoch:23 step:18314[D loss: 0.441059, acc: 53.12%, op_acc: 37.50%] [G loss: 0.864062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18315[D loss: 0.427830, acc: 63.28%, op_acc: 35.16%] [G loss: 0.817552]\n",
      "epoch:23 step:18316[D loss: 0.394539, acc: 57.81%, op_acc: 45.31%] [G loss: 0.836816]\n",
      "epoch:23 step:18317[D loss: 0.416675, acc: 63.28%, op_acc: 36.72%] [G loss: 0.817493]\n",
      "epoch:23 step:18318[D loss: 0.408966, acc: 58.59%, op_acc: 40.62%] [G loss: 0.846304]\n",
      "epoch:23 step:18319[D loss: 0.439036, acc: 54.69%, op_acc: 39.84%] [G loss: 0.803115]\n",
      "epoch:23 step:18320[D loss: 0.429509, acc: 59.38%, op_acc: 40.62%] [G loss: 0.904074]\n",
      "epoch:23 step:18321[D loss: 0.429319, acc: 64.06%, op_acc: 39.06%] [G loss: 0.791264]\n",
      "epoch:23 step:18322[D loss: 0.399303, acc: 65.62%, op_acc: 36.72%] [G loss: 0.887720]\n",
      "epoch:23 step:18323[D loss: 0.445142, acc: 54.69%, op_acc: 35.94%] [G loss: 0.842963]\n",
      "epoch:23 step:18324[D loss: 0.423767, acc: 59.38%, op_acc: 38.28%] [G loss: 0.885068]\n",
      "epoch:23 step:18325[D loss: 0.418996, acc: 54.69%, op_acc: 39.06%] [G loss: 0.822049]\n",
      "epoch:23 step:18326[D loss: 0.439100, acc: 58.59%, op_acc: 39.06%] [G loss: 0.856215]\n",
      "epoch:23 step:18327[D loss: 0.399461, acc: 66.41%, op_acc: 39.06%] [G loss: 0.911586]\n",
      "epoch:23 step:18328[D loss: 0.385766, acc: 64.84%, op_acc: 41.41%] [G loss: 0.911939]\n",
      "epoch:23 step:18329[D loss: 0.432112, acc: 57.81%, op_acc: 41.41%] [G loss: 0.917306]\n",
      "epoch:23 step:18330[D loss: 0.411370, acc: 67.97%, op_acc: 38.28%] [G loss: 0.846383]\n",
      "epoch:23 step:18331[D loss: 0.422775, acc: 61.72%, op_acc: 36.72%] [G loss: 0.864941]\n",
      "epoch:23 step:18332[D loss: 0.444004, acc: 50.78%, op_acc: 47.66%] [G loss: 0.851553]\n",
      "epoch:23 step:18333[D loss: 0.407347, acc: 63.28%, op_acc: 39.06%] [G loss: 0.831916]\n",
      "epoch:23 step:18334[D loss: 0.379752, acc: 62.50%, op_acc: 47.66%] [G loss: 0.964939]\n",
      "epoch:23 step:18335[D loss: 0.405069, acc: 61.72%, op_acc: 42.19%] [G loss: 0.872886]\n",
      "epoch:23 step:18336[D loss: 0.424830, acc: 61.72%, op_acc: 42.19%] [G loss: 0.977745]\n",
      "epoch:23 step:18337[D loss: 0.441318, acc: 59.38%, op_acc: 39.84%] [G loss: 0.824784]\n",
      "epoch:23 step:18338[D loss: 0.399035, acc: 60.94%, op_acc: 44.53%] [G loss: 0.881340]\n",
      "epoch:23 step:18339[D loss: 0.405822, acc: 65.62%, op_acc: 36.72%] [G loss: 0.896703]\n",
      "epoch:23 step:18340[D loss: 0.423956, acc: 57.03%, op_acc: 44.53%] [G loss: 0.888579]\n",
      "epoch:23 step:18341[D loss: 0.412579, acc: 60.94%, op_acc: 42.97%] [G loss: 0.829511]\n",
      "epoch:23 step:18342[D loss: 0.401850, acc: 59.38%, op_acc: 40.62%] [G loss: 0.923347]\n",
      "epoch:23 step:18343[D loss: 0.407848, acc: 65.62%, op_acc: 38.28%] [G loss: 0.890145]\n",
      "epoch:23 step:18344[D loss: 0.383275, acc: 72.66%, op_acc: 39.06%] [G loss: 0.939084]\n",
      "epoch:23 step:18345[D loss: 0.442633, acc: 59.38%, op_acc: 36.72%] [G loss: 0.853427]\n",
      "epoch:23 step:18346[D loss: 0.425540, acc: 55.47%, op_acc: 45.31%] [G loss: 0.904188]\n",
      "epoch:23 step:18347[D loss: 0.402309, acc: 65.62%, op_acc: 36.72%] [G loss: 0.879247]\n",
      "epoch:23 step:18348[D loss: 0.437370, acc: 53.12%, op_acc: 41.41%] [G loss: 0.889645]\n",
      "epoch:23 step:18349[D loss: 0.430389, acc: 60.16%, op_acc: 43.75%] [G loss: 0.880272]\n",
      "epoch:23 step:18350[D loss: 0.440895, acc: 60.16%, op_acc: 34.38%] [G loss: 0.860178]\n",
      "##############\n",
      "[0.84839939 0.84720508 0.8113315  0.8248726  0.78221525 0.81182493\n",
      " 0.87581777 0.81174643 0.81801462 0.84765468]\n",
      "##########\n",
      "epoch:23 step:18351[D loss: 0.433175, acc: 61.72%, op_acc: 39.84%] [G loss: 0.845159]\n",
      "epoch:23 step:18352[D loss: 0.430240, acc: 56.25%, op_acc: 36.72%] [G loss: 0.915739]\n",
      "epoch:23 step:18353[D loss: 0.436774, acc: 57.03%, op_acc: 35.16%] [G loss: 0.898655]\n",
      "epoch:23 step:18354[D loss: 0.417049, acc: 60.16%, op_acc: 39.06%] [G loss: 0.888283]\n",
      "epoch:23 step:18355[D loss: 0.426364, acc: 58.59%, op_acc: 41.41%] [G loss: 0.871038]\n",
      "epoch:23 step:18356[D loss: 0.451606, acc: 56.25%, op_acc: 39.06%] [G loss: 0.844834]\n",
      "epoch:23 step:18357[D loss: 0.417008, acc: 66.41%, op_acc: 41.41%] [G loss: 0.852548]\n",
      "epoch:23 step:18358[D loss: 0.460153, acc: 56.25%, op_acc: 33.59%] [G loss: 0.777452]\n",
      "epoch:23 step:18359[D loss: 0.439792, acc: 56.25%, op_acc: 42.19%] [G loss: 0.860743]\n",
      "epoch:23 step:18360[D loss: 0.420440, acc: 61.72%, op_acc: 37.50%] [G loss: 0.868112]\n",
      "epoch:23 step:18361[D loss: 0.474539, acc: 46.09%, op_acc: 32.81%] [G loss: 0.862721]\n",
      "epoch:23 step:18362[D loss: 0.424414, acc: 61.72%, op_acc: 40.62%] [G loss: 0.919552]\n",
      "epoch:23 step:18363[D loss: 0.446605, acc: 50.78%, op_acc: 35.94%] [G loss: 0.853184]\n",
      "epoch:23 step:18364[D loss: 0.404773, acc: 63.28%, op_acc: 46.09%] [G loss: 0.905542]\n",
      "epoch:23 step:18365[D loss: 0.416561, acc: 62.50%, op_acc: 32.81%] [G loss: 0.899046]\n",
      "epoch:23 step:18366[D loss: 0.427427, acc: 62.50%, op_acc: 36.72%] [G loss: 0.878163]\n",
      "epoch:23 step:18367[D loss: 0.412187, acc: 61.72%, op_acc: 46.09%] [G loss: 0.871738]\n",
      "epoch:23 step:18368[D loss: 0.448251, acc: 57.81%, op_acc: 38.28%] [G loss: 0.864549]\n",
      "epoch:23 step:18369[D loss: 0.432182, acc: 53.12%, op_acc: 39.84%] [G loss: 0.859177]\n",
      "epoch:23 step:18370[D loss: 0.425772, acc: 57.03%, op_acc: 38.28%] [G loss: 0.809717]\n",
      "epoch:23 step:18371[D loss: 0.378659, acc: 71.09%, op_acc: 42.19%] [G loss: 0.863578]\n",
      "epoch:23 step:18372[D loss: 0.419784, acc: 58.59%, op_acc: 42.97%] [G loss: 0.907171]\n",
      "epoch:23 step:18373[D loss: 0.412584, acc: 58.59%, op_acc: 42.19%] [G loss: 0.930986]\n",
      "epoch:23 step:18374[D loss: 0.431867, acc: 56.25%, op_acc: 35.94%] [G loss: 0.900773]\n",
      "epoch:23 step:18375[D loss: 0.411774, acc: 60.16%, op_acc: 47.66%] [G loss: 0.830562]\n",
      "epoch:23 step:18376[D loss: 0.437843, acc: 60.16%, op_acc: 36.72%] [G loss: 0.956082]\n",
      "epoch:23 step:18377[D loss: 0.397808, acc: 60.16%, op_acc: 42.19%] [G loss: 0.881012]\n",
      "epoch:23 step:18378[D loss: 0.433380, acc: 55.47%, op_acc: 40.62%] [G loss: 0.841611]\n",
      "epoch:23 step:18379[D loss: 0.442849, acc: 53.91%, op_acc: 40.62%] [G loss: 0.861787]\n",
      "epoch:23 step:18380[D loss: 0.399336, acc: 67.97%, op_acc: 39.84%] [G loss: 0.923842]\n",
      "epoch:23 step:18381[D loss: 0.435210, acc: 56.25%, op_acc: 35.94%] [G loss: 0.859906]\n",
      "epoch:23 step:18382[D loss: 0.437602, acc: 57.03%, op_acc: 36.72%] [G loss: 0.834745]\n",
      "epoch:23 step:18383[D loss: 0.453280, acc: 58.59%, op_acc: 32.81%] [G loss: 0.925086]\n",
      "epoch:23 step:18384[D loss: 0.451030, acc: 57.03%, op_acc: 36.72%] [G loss: 0.913760]\n",
      "epoch:23 step:18385[D loss: 0.445600, acc: 56.25%, op_acc: 36.72%] [G loss: 0.848983]\n",
      "epoch:23 step:18386[D loss: 0.433556, acc: 60.94%, op_acc: 37.50%] [G loss: 0.896388]\n",
      "epoch:23 step:18387[D loss: 0.432378, acc: 60.94%, op_acc: 37.50%] [G loss: 0.965124]\n",
      "epoch:23 step:18388[D loss: 0.454192, acc: 56.25%, op_acc: 34.38%] [G loss: 0.881654]\n",
      "epoch:23 step:18389[D loss: 0.462932, acc: 56.25%, op_acc: 37.50%] [G loss: 0.847680]\n",
      "epoch:23 step:18390[D loss: 0.446981, acc: 54.69%, op_acc: 39.06%] [G loss: 0.826159]\n",
      "epoch:23 step:18391[D loss: 0.426673, acc: 54.69%, op_acc: 41.41%] [G loss: 0.904535]\n",
      "epoch:23 step:18392[D loss: 0.408731, acc: 54.69%, op_acc: 40.62%] [G loss: 0.897845]\n",
      "epoch:23 step:18393[D loss: 0.448883, acc: 53.91%, op_acc: 39.84%] [G loss: 0.819959]\n",
      "epoch:23 step:18394[D loss: 0.451599, acc: 52.34%, op_acc: 31.25%] [G loss: 0.849793]\n",
      "epoch:23 step:18395[D loss: 0.373478, acc: 64.06%, op_acc: 47.66%] [G loss: 0.891710]\n",
      "epoch:23 step:18396[D loss: 0.413400, acc: 60.16%, op_acc: 45.31%] [G loss: 0.949539]\n",
      "epoch:23 step:18397[D loss: 0.407884, acc: 66.41%, op_acc: 37.50%] [G loss: 0.946878]\n",
      "epoch:23 step:18398[D loss: 0.429325, acc: 54.69%, op_acc: 41.41%] [G loss: 0.854720]\n",
      "epoch:23 step:18399[D loss: 0.452762, acc: 57.81%, op_acc: 37.50%] [G loss: 0.919968]\n",
      "epoch:23 step:18400[D loss: 0.438060, acc: 49.22%, op_acc: 40.62%] [G loss: 0.886953]\n",
      "##############\n",
      "[0.86441205 0.86630428 0.80544852 0.80999634 0.76989078 0.84486119\n",
      " 0.92046578 0.81394907 0.81276262 0.83461262]\n",
      "##########\n",
      "epoch:23 step:18401[D loss: 0.399106, acc: 67.19%, op_acc: 41.41%] [G loss: 0.770245]\n",
      "epoch:23 step:18402[D loss: 0.429655, acc: 51.56%, op_acc: 39.84%] [G loss: 0.818321]\n",
      "epoch:23 step:18403[D loss: 0.412765, acc: 58.59%, op_acc: 41.41%] [G loss: 0.856645]\n",
      "epoch:23 step:18404[D loss: 0.435872, acc: 51.56%, op_acc: 39.84%] [G loss: 0.879429]\n",
      "epoch:23 step:18405[D loss: 0.418114, acc: 64.06%, op_acc: 38.28%] [G loss: 0.861987]\n",
      "epoch:23 step:18406[D loss: 0.438474, acc: 56.25%, op_acc: 35.94%] [G loss: 0.829257]\n",
      "epoch:23 step:18407[D loss: 0.449344, acc: 53.91%, op_acc: 39.84%] [G loss: 0.896642]\n",
      "epoch:23 step:18408[D loss: 0.432881, acc: 64.84%, op_acc: 36.72%] [G loss: 0.898428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18409[D loss: 0.444028, acc: 54.69%, op_acc: 39.06%] [G loss: 0.898377]\n",
      "epoch:23 step:18410[D loss: 0.443360, acc: 57.81%, op_acc: 36.72%] [G loss: 0.835547]\n",
      "epoch:23 step:18411[D loss: 0.416298, acc: 60.16%, op_acc: 43.75%] [G loss: 0.877334]\n",
      "epoch:23 step:18412[D loss: 0.426770, acc: 60.16%, op_acc: 35.16%] [G loss: 0.776088]\n",
      "epoch:23 step:18413[D loss: 0.423505, acc: 57.81%, op_acc: 35.16%] [G loss: 1.014561]\n",
      "epoch:23 step:18414[D loss: 0.417522, acc: 55.47%, op_acc: 39.06%] [G loss: 0.892154]\n",
      "epoch:23 step:18415[D loss: 0.404210, acc: 59.38%, op_acc: 47.66%] [G loss: 0.854439]\n",
      "epoch:23 step:18416[D loss: 0.393212, acc: 62.50%, op_acc: 43.75%] [G loss: 0.881763]\n",
      "epoch:23 step:18417[D loss: 0.417335, acc: 60.16%, op_acc: 41.41%] [G loss: 0.917252]\n",
      "epoch:23 step:18418[D loss: 0.441730, acc: 50.78%, op_acc: 37.50%] [G loss: 0.887195]\n",
      "epoch:23 step:18419[D loss: 0.395335, acc: 63.28%, op_acc: 39.84%] [G loss: 0.935609]\n",
      "epoch:23 step:18420[D loss: 0.457955, acc: 53.91%, op_acc: 28.91%] [G loss: 0.893473]\n",
      "epoch:23 step:18421[D loss: 0.414703, acc: 58.59%, op_acc: 43.75%] [G loss: 0.900256]\n",
      "epoch:23 step:18422[D loss: 0.445222, acc: 53.12%, op_acc: 43.75%] [G loss: 0.841238]\n",
      "epoch:23 step:18423[D loss: 0.418169, acc: 54.69%, op_acc: 44.53%] [G loss: 1.044564]\n",
      "epoch:23 step:18424[D loss: 0.448786, acc: 60.94%, op_acc: 34.38%] [G loss: 0.889976]\n",
      "epoch:23 step:18425[D loss: 0.418163, acc: 57.81%, op_acc: 35.94%] [G loss: 0.855757]\n",
      "epoch:23 step:18426[D loss: 0.451090, acc: 53.12%, op_acc: 40.62%] [G loss: 0.877828]\n",
      "epoch:23 step:18427[D loss: 0.425924, acc: 64.84%, op_acc: 33.59%] [G loss: 0.954573]\n",
      "epoch:23 step:18428[D loss: 0.428315, acc: 57.03%, op_acc: 37.50%] [G loss: 0.897237]\n",
      "epoch:23 step:18429[D loss: 0.423976, acc: 58.59%, op_acc: 38.28%] [G loss: 0.933121]\n",
      "epoch:23 step:18430[D loss: 0.412202, acc: 58.59%, op_acc: 42.97%] [G loss: 0.851882]\n",
      "epoch:23 step:18431[D loss: 0.408406, acc: 61.72%, op_acc: 40.62%] [G loss: 0.864501]\n",
      "epoch:23 step:18432[D loss: 0.404609, acc: 60.94%, op_acc: 39.06%] [G loss: 0.931259]\n",
      "epoch:23 step:18433[D loss: 0.407858, acc: 69.53%, op_acc: 39.84%] [G loss: 0.889676]\n",
      "epoch:23 step:18434[D loss: 0.442712, acc: 53.91%, op_acc: 41.41%] [G loss: 0.837911]\n",
      "epoch:23 step:18435[D loss: 0.419308, acc: 64.06%, op_acc: 36.72%] [G loss: 0.866941]\n",
      "epoch:23 step:18436[D loss: 0.415433, acc: 57.03%, op_acc: 39.06%] [G loss: 0.883547]\n",
      "epoch:23 step:18437[D loss: 0.432753, acc: 61.72%, op_acc: 37.50%] [G loss: 0.947307]\n",
      "epoch:23 step:18438[D loss: 0.432977, acc: 48.44%, op_acc: 42.97%] [G loss: 0.828599]\n",
      "epoch:23 step:18439[D loss: 0.443297, acc: 52.34%, op_acc: 39.06%] [G loss: 0.879165]\n",
      "epoch:23 step:18440[D loss: 0.424015, acc: 61.72%, op_acc: 36.72%] [G loss: 0.901629]\n",
      "epoch:23 step:18441[D loss: 0.407520, acc: 60.94%, op_acc: 40.62%] [G loss: 0.953210]\n",
      "epoch:23 step:18442[D loss: 0.423287, acc: 55.47%, op_acc: 40.62%] [G loss: 0.906025]\n",
      "epoch:23 step:18443[D loss: 0.439024, acc: 64.84%, op_acc: 31.25%] [G loss: 0.917893]\n",
      "epoch:23 step:18444[D loss: 0.449923, acc: 59.38%, op_acc: 36.72%] [G loss: 0.962205]\n",
      "epoch:23 step:18445[D loss: 0.441148, acc: 60.16%, op_acc: 34.38%] [G loss: 0.945122]\n",
      "epoch:23 step:18446[D loss: 0.419884, acc: 59.38%, op_acc: 35.94%] [G loss: 0.876032]\n",
      "epoch:23 step:18447[D loss: 0.422188, acc: 58.59%, op_acc: 44.53%] [G loss: 0.885131]\n",
      "epoch:23 step:18448[D loss: 0.444757, acc: 50.00%, op_acc: 35.94%] [G loss: 0.833984]\n",
      "epoch:23 step:18449[D loss: 0.427711, acc: 58.59%, op_acc: 35.94%] [G loss: 0.852493]\n",
      "epoch:23 step:18450[D loss: 0.448923, acc: 54.69%, op_acc: 37.50%] [G loss: 0.916062]\n",
      "##############\n",
      "[0.85079423 0.84621495 0.83629598 0.79616932 0.79544508 0.84040025\n",
      " 0.89889742 0.85556204 0.78859683 0.82274103]\n",
      "##########\n",
      "epoch:23 step:18451[D loss: 0.426719, acc: 59.38%, op_acc: 35.16%] [G loss: 0.921950]\n",
      "epoch:23 step:18452[D loss: 0.425357, acc: 56.25%, op_acc: 41.41%] [G loss: 0.905327]\n",
      "epoch:23 step:18453[D loss: 0.429785, acc: 58.59%, op_acc: 39.06%] [G loss: 0.866798]\n",
      "epoch:23 step:18454[D loss: 0.461516, acc: 52.34%, op_acc: 35.94%] [G loss: 0.876078]\n",
      "epoch:23 step:18455[D loss: 0.422290, acc: 59.38%, op_acc: 42.97%] [G loss: 0.823068]\n",
      "epoch:23 step:18456[D loss: 0.442135, acc: 56.25%, op_acc: 36.72%] [G loss: 0.891494]\n",
      "epoch:23 step:18457[D loss: 0.411378, acc: 62.50%, op_acc: 39.84%] [G loss: 0.801005]\n",
      "epoch:23 step:18458[D loss: 0.435997, acc: 60.16%, op_acc: 39.84%] [G loss: 0.885071]\n",
      "epoch:23 step:18459[D loss: 0.407249, acc: 63.28%, op_acc: 39.84%] [G loss: 0.841094]\n",
      "epoch:23 step:18460[D loss: 0.387466, acc: 64.84%, op_acc: 44.53%] [G loss: 0.824111]\n",
      "epoch:23 step:18461[D loss: 0.437996, acc: 56.25%, op_acc: 39.84%] [G loss: 0.897539]\n",
      "epoch:23 step:18462[D loss: 0.434237, acc: 56.25%, op_acc: 35.16%] [G loss: 0.882328]\n",
      "epoch:23 step:18463[D loss: 0.402110, acc: 60.94%, op_acc: 45.31%] [G loss: 0.865466]\n",
      "epoch:23 step:18464[D loss: 0.408214, acc: 64.84%, op_acc: 37.50%] [G loss: 0.960981]\n",
      "epoch:23 step:18465[D loss: 0.430031, acc: 57.81%, op_acc: 37.50%] [G loss: 0.954179]\n",
      "epoch:23 step:18466[D loss: 0.440838, acc: 59.38%, op_acc: 39.84%] [G loss: 0.875310]\n",
      "epoch:23 step:18467[D loss: 0.429260, acc: 55.47%, op_acc: 42.97%] [G loss: 0.885439]\n",
      "epoch:23 step:18468[D loss: 0.419084, acc: 66.41%, op_acc: 43.75%] [G loss: 0.841416]\n",
      "epoch:23 step:18469[D loss: 0.411926, acc: 65.62%, op_acc: 39.06%] [G loss: 0.873085]\n",
      "epoch:23 step:18470[D loss: 0.388807, acc: 64.06%, op_acc: 42.97%] [G loss: 0.904847]\n",
      "epoch:23 step:18471[D loss: 0.414297, acc: 60.16%, op_acc: 39.84%] [G loss: 0.879732]\n",
      "epoch:23 step:18472[D loss: 0.442104, acc: 53.91%, op_acc: 41.41%] [G loss: 0.893439]\n",
      "epoch:23 step:18473[D loss: 0.438428, acc: 60.94%, op_acc: 38.28%] [G loss: 0.899192]\n",
      "epoch:23 step:18474[D loss: 0.464980, acc: 51.56%, op_acc: 38.28%] [G loss: 0.808945]\n",
      "epoch:23 step:18475[D loss: 0.424169, acc: 52.34%, op_acc: 39.06%] [G loss: 0.814859]\n",
      "epoch:23 step:18476[D loss: 0.458239, acc: 53.12%, op_acc: 32.03%] [G loss: 0.872049]\n",
      "epoch:23 step:18477[D loss: 0.442155, acc: 51.56%, op_acc: 36.72%] [G loss: 0.796957]\n",
      "epoch:23 step:18478[D loss: 0.424882, acc: 62.50%, op_acc: 34.38%] [G loss: 0.882529]\n",
      "epoch:23 step:18479[D loss: 0.418975, acc: 62.50%, op_acc: 40.62%] [G loss: 0.822693]\n",
      "epoch:23 step:18480[D loss: 0.453386, acc: 51.56%, op_acc: 38.28%] [G loss: 0.918910]\n",
      "epoch:23 step:18481[D loss: 0.399460, acc: 63.28%, op_acc: 40.62%] [G loss: 0.841601]\n",
      "epoch:23 step:18482[D loss: 0.436101, acc: 50.78%, op_acc: 38.28%] [G loss: 0.874924]\n",
      "epoch:23 step:18483[D loss: 0.422618, acc: 54.69%, op_acc: 39.84%] [G loss: 0.873126]\n",
      "epoch:23 step:18484[D loss: 0.432158, acc: 59.38%, op_acc: 37.50%] [G loss: 0.900711]\n",
      "epoch:23 step:18485[D loss: 0.444811, acc: 57.03%, op_acc: 39.84%] [G loss: 0.883336]\n",
      "epoch:23 step:18486[D loss: 0.398553, acc: 67.97%, op_acc: 45.31%] [G loss: 0.872578]\n",
      "epoch:23 step:18487[D loss: 0.429857, acc: 61.72%, op_acc: 39.84%] [G loss: 0.853608]\n",
      "epoch:23 step:18488[D loss: 0.396442, acc: 64.84%, op_acc: 36.72%] [G loss: 0.885424]\n",
      "epoch:23 step:18489[D loss: 0.469199, acc: 50.00%, op_acc: 32.03%] [G loss: 0.827261]\n",
      "epoch:23 step:18490[D loss: 0.442023, acc: 57.81%, op_acc: 36.72%] [G loss: 0.858623]\n",
      "epoch:23 step:18491[D loss: 0.423258, acc: 52.34%, op_acc: 42.97%] [G loss: 0.821248]\n",
      "epoch:23 step:18492[D loss: 0.400018, acc: 65.62%, op_acc: 42.97%] [G loss: 0.893471]\n",
      "epoch:23 step:18493[D loss: 0.398464, acc: 64.84%, op_acc: 40.62%] [G loss: 0.837237]\n",
      "epoch:23 step:18494[D loss: 0.421496, acc: 59.38%, op_acc: 38.28%] [G loss: 0.903126]\n",
      "epoch:23 step:18495[D loss: 0.428524, acc: 55.47%, op_acc: 38.28%] [G loss: 0.892284]\n",
      "epoch:23 step:18496[D loss: 0.417738, acc: 62.50%, op_acc: 39.84%] [G loss: 0.848071]\n",
      "epoch:23 step:18497[D loss: 0.398200, acc: 61.72%, op_acc: 44.53%] [G loss: 0.922025]\n",
      "epoch:23 step:18498[D loss: 0.429592, acc: 64.06%, op_acc: 39.06%] [G loss: 0.825153]\n",
      "epoch:23 step:18499[D loss: 0.419831, acc: 59.38%, op_acc: 41.41%] [G loss: 0.939950]\n",
      "epoch:23 step:18500[D loss: 0.415869, acc: 62.50%, op_acc: 41.41%] [G loss: 0.897079]\n",
      "##############\n",
      "[0.84117374 0.84123983 0.81650012 0.81548766 0.79708205 0.83921781\n",
      " 0.86230456 0.83073117 0.82316427 0.80819048]\n",
      "##########\n",
      "epoch:23 step:18501[D loss: 0.408357, acc: 61.72%, op_acc: 40.62%] [G loss: 0.880505]\n",
      "epoch:23 step:18502[D loss: 0.422294, acc: 63.28%, op_acc: 37.50%] [G loss: 0.878583]\n",
      "epoch:23 step:18503[D loss: 0.424759, acc: 52.34%, op_acc: 45.31%] [G loss: 0.931255]\n",
      "epoch:23 step:18504[D loss: 0.411932, acc: 60.16%, op_acc: 39.06%] [G loss: 0.885667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18505[D loss: 0.427970, acc: 62.50%, op_acc: 39.84%] [G loss: 0.850545]\n",
      "epoch:23 step:18506[D loss: 0.442193, acc: 57.03%, op_acc: 41.41%] [G loss: 0.859177]\n",
      "epoch:23 step:18507[D loss: 0.411148, acc: 64.84%, op_acc: 46.09%] [G loss: 0.852746]\n",
      "epoch:23 step:18508[D loss: 0.388990, acc: 64.06%, op_acc: 41.41%] [G loss: 0.951247]\n",
      "epoch:23 step:18509[D loss: 0.459518, acc: 50.78%, op_acc: 36.72%] [G loss: 0.820685]\n",
      "epoch:23 step:18510[D loss: 0.429412, acc: 60.94%, op_acc: 36.72%] [G loss: 0.812682]\n",
      "epoch:23 step:18511[D loss: 0.438994, acc: 63.28%, op_acc: 36.72%] [G loss: 0.824649]\n",
      "epoch:23 step:18512[D loss: 0.418307, acc: 64.06%, op_acc: 38.28%] [G loss: 0.821477]\n",
      "epoch:23 step:18513[D loss: 0.442323, acc: 57.03%, op_acc: 39.06%] [G loss: 0.864697]\n",
      "epoch:23 step:18514[D loss: 0.409692, acc: 59.38%, op_acc: 42.97%] [G loss: 0.880690]\n",
      "epoch:23 step:18515[D loss: 0.447454, acc: 59.38%, op_acc: 32.81%] [G loss: 0.880956]\n",
      "epoch:23 step:18516[D loss: 0.425136, acc: 62.50%, op_acc: 34.38%] [G loss: 0.922107]\n",
      "epoch:23 step:18517[D loss: 0.399206, acc: 69.53%, op_acc: 43.75%] [G loss: 0.841029]\n",
      "epoch:23 step:18518[D loss: 0.388021, acc: 64.84%, op_acc: 39.06%] [G loss: 0.906827]\n",
      "epoch:23 step:18519[D loss: 0.412966, acc: 60.94%, op_acc: 45.31%] [G loss: 0.851231]\n",
      "epoch:23 step:18520[D loss: 0.448625, acc: 47.66%, op_acc: 36.72%] [G loss: 0.887132]\n",
      "epoch:23 step:18521[D loss: 0.411705, acc: 55.47%, op_acc: 43.75%] [G loss: 0.907391]\n",
      "epoch:23 step:18522[D loss: 0.388267, acc: 70.31%, op_acc: 39.06%] [G loss: 0.896278]\n",
      "epoch:23 step:18523[D loss: 0.444170, acc: 61.72%, op_acc: 32.81%] [G loss: 0.874228]\n",
      "epoch:23 step:18524[D loss: 0.409876, acc: 57.03%, op_acc: 42.19%] [G loss: 0.823573]\n",
      "epoch:23 step:18525[D loss: 0.424604, acc: 64.84%, op_acc: 42.19%] [G loss: 0.909243]\n",
      "epoch:23 step:18526[D loss: 0.423724, acc: 55.47%, op_acc: 36.72%] [G loss: 0.927801]\n",
      "epoch:23 step:18527[D loss: 0.408846, acc: 61.72%, op_acc: 44.53%] [G loss: 0.889846]\n",
      "epoch:23 step:18528[D loss: 0.442473, acc: 55.47%, op_acc: 35.16%] [G loss: 0.879119]\n",
      "epoch:23 step:18529[D loss: 0.430685, acc: 53.91%, op_acc: 35.94%] [G loss: 0.947378]\n",
      "epoch:23 step:18530[D loss: 0.424908, acc: 64.06%, op_acc: 35.94%] [G loss: 0.946884]\n",
      "epoch:23 step:18531[D loss: 0.426574, acc: 55.47%, op_acc: 41.41%] [G loss: 0.868041]\n",
      "epoch:23 step:18532[D loss: 0.445544, acc: 51.56%, op_acc: 39.84%] [G loss: 0.918427]\n",
      "epoch:23 step:18533[D loss: 0.412657, acc: 61.72%, op_acc: 41.41%] [G loss: 0.868043]\n",
      "epoch:23 step:18534[D loss: 0.418445, acc: 54.69%, op_acc: 42.97%] [G loss: 1.001620]\n",
      "epoch:23 step:18535[D loss: 0.417530, acc: 65.62%, op_acc: 35.16%] [G loss: 0.936991]\n",
      "epoch:23 step:18536[D loss: 0.433533, acc: 57.03%, op_acc: 35.94%] [G loss: 0.930840]\n",
      "epoch:23 step:18537[D loss: 0.411707, acc: 60.94%, op_acc: 34.38%] [G loss: 0.930371]\n",
      "epoch:23 step:18538[D loss: 0.457864, acc: 53.12%, op_acc: 34.38%] [G loss: 0.910081]\n",
      "epoch:23 step:18539[D loss: 0.430576, acc: 58.59%, op_acc: 40.62%] [G loss: 0.850881]\n",
      "epoch:23 step:18540[D loss: 0.460919, acc: 55.47%, op_acc: 38.28%] [G loss: 0.880521]\n",
      "epoch:23 step:18541[D loss: 0.423695, acc: 59.38%, op_acc: 38.28%] [G loss: 0.895412]\n",
      "epoch:23 step:18542[D loss: 0.409653, acc: 58.59%, op_acc: 41.41%] [G loss: 0.893953]\n",
      "epoch:23 step:18543[D loss: 0.408865, acc: 61.72%, op_acc: 42.97%] [G loss: 0.933390]\n",
      "epoch:23 step:18544[D loss: 0.413432, acc: 61.72%, op_acc: 32.81%] [G loss: 0.866731]\n",
      "epoch:23 step:18545[D loss: 0.412555, acc: 63.28%, op_acc: 38.28%] [G loss: 0.891968]\n",
      "epoch:23 step:18546[D loss: 0.415528, acc: 61.72%, op_acc: 39.84%] [G loss: 0.909299]\n",
      "epoch:23 step:18547[D loss: 0.471078, acc: 57.81%, op_acc: 29.69%] [G loss: 0.833624]\n",
      "epoch:23 step:18548[D loss: 0.418066, acc: 55.47%, op_acc: 42.19%] [G loss: 0.865029]\n",
      "epoch:23 step:18549[D loss: 0.399821, acc: 71.09%, op_acc: 41.41%] [G loss: 0.934425]\n",
      "epoch:23 step:18550[D loss: 0.409012, acc: 60.16%, op_acc: 41.41%] [G loss: 0.863617]\n",
      "##############\n",
      "[0.85917535 0.87101883 0.81694225 0.81575926 0.80112486 0.81970252\n",
      " 0.89219738 0.83257984 0.79914952 0.82012662]\n",
      "##########\n",
      "epoch:23 step:18551[D loss: 0.420002, acc: 61.72%, op_acc: 38.28%] [G loss: 0.880194]\n",
      "epoch:23 step:18552[D loss: 0.418613, acc: 60.16%, op_acc: 39.84%] [G loss: 0.896489]\n",
      "epoch:23 step:18553[D loss: 0.444664, acc: 55.47%, op_acc: 39.06%] [G loss: 0.870255]\n",
      "epoch:23 step:18554[D loss: 0.446623, acc: 53.91%, op_acc: 33.59%] [G loss: 0.836629]\n",
      "epoch:23 step:18555[D loss: 0.438902, acc: 52.34%, op_acc: 36.72%] [G loss: 0.804600]\n",
      "epoch:23 step:18556[D loss: 0.442812, acc: 57.03%, op_acc: 32.81%] [G loss: 0.927322]\n",
      "epoch:23 step:18557[D loss: 0.412013, acc: 58.59%, op_acc: 39.06%] [G loss: 0.815365]\n",
      "epoch:23 step:18558[D loss: 0.407837, acc: 62.50%, op_acc: 37.50%] [G loss: 0.878620]\n",
      "epoch:23 step:18559[D loss: 0.426853, acc: 60.94%, op_acc: 39.06%] [G loss: 0.835017]\n",
      "epoch:23 step:18560[D loss: 0.425789, acc: 61.72%, op_acc: 39.84%] [G loss: 0.827098]\n",
      "epoch:23 step:18561[D loss: 0.422129, acc: 60.16%, op_acc: 39.06%] [G loss: 0.802260]\n",
      "epoch:23 step:18562[D loss: 0.421276, acc: 60.94%, op_acc: 37.50%] [G loss: 0.877550]\n",
      "epoch:23 step:18563[D loss: 0.416836, acc: 59.38%, op_acc: 35.94%] [G loss: 0.882416]\n",
      "epoch:23 step:18564[D loss: 0.440655, acc: 53.91%, op_acc: 33.59%] [G loss: 0.867956]\n",
      "epoch:23 step:18565[D loss: 0.448972, acc: 50.00%, op_acc: 39.84%] [G loss: 0.869802]\n",
      "epoch:23 step:18566[D loss: 0.397675, acc: 56.25%, op_acc: 45.31%] [G loss: 0.936458]\n",
      "epoch:23 step:18567[D loss: 0.442962, acc: 56.25%, op_acc: 38.28%] [G loss: 0.839495]\n",
      "epoch:23 step:18568[D loss: 0.395223, acc: 71.09%, op_acc: 41.41%] [G loss: 0.857985]\n",
      "epoch:23 step:18569[D loss: 0.447912, acc: 51.56%, op_acc: 39.06%] [G loss: 0.837926]\n",
      "epoch:23 step:18570[D loss: 0.421536, acc: 56.25%, op_acc: 41.41%] [G loss: 0.886146]\n",
      "epoch:23 step:18571[D loss: 0.378558, acc: 67.97%, op_acc: 43.75%] [G loss: 0.864204]\n",
      "epoch:23 step:18572[D loss: 0.446325, acc: 55.47%, op_acc: 37.50%] [G loss: 0.884554]\n",
      "epoch:23 step:18573[D loss: 0.417729, acc: 60.94%, op_acc: 35.16%] [G loss: 0.913548]\n",
      "epoch:23 step:18574[D loss: 0.445014, acc: 57.81%, op_acc: 35.94%] [G loss: 0.855957]\n",
      "epoch:23 step:18575[D loss: 0.466754, acc: 50.00%, op_acc: 34.38%] [G loss: 0.811078]\n",
      "epoch:23 step:18576[D loss: 0.422596, acc: 51.56%, op_acc: 42.97%] [G loss: 0.915636]\n",
      "epoch:23 step:18577[D loss: 0.397141, acc: 64.06%, op_acc: 41.41%] [G loss: 0.915100]\n",
      "epoch:23 step:18578[D loss: 0.413895, acc: 56.25%, op_acc: 41.41%] [G loss: 0.874944]\n",
      "epoch:23 step:18579[D loss: 0.446205, acc: 55.47%, op_acc: 39.84%] [G loss: 0.869324]\n",
      "epoch:23 step:18580[D loss: 0.432995, acc: 57.81%, op_acc: 37.50%] [G loss: 0.953213]\n",
      "epoch:23 step:18581[D loss: 0.414663, acc: 57.03%, op_acc: 43.75%] [G loss: 0.883353]\n",
      "epoch:23 step:18582[D loss: 0.466823, acc: 53.91%, op_acc: 33.59%] [G loss: 0.826835]\n",
      "epoch:23 step:18583[D loss: 0.420171, acc: 57.03%, op_acc: 34.38%] [G loss: 0.962496]\n",
      "epoch:23 step:18584[D loss: 0.454869, acc: 53.91%, op_acc: 36.72%] [G loss: 0.923649]\n",
      "epoch:23 step:18585[D loss: 0.436262, acc: 60.16%, op_acc: 32.81%] [G loss: 0.880472]\n",
      "epoch:23 step:18586[D loss: 0.422298, acc: 59.38%, op_acc: 45.31%] [G loss: 0.926250]\n",
      "epoch:23 step:18587[D loss: 0.431339, acc: 56.25%, op_acc: 45.31%] [G loss: 0.887721]\n",
      "epoch:23 step:18588[D loss: 0.449561, acc: 53.12%, op_acc: 37.50%] [G loss: 0.867216]\n",
      "epoch:23 step:18589[D loss: 0.414632, acc: 57.81%, op_acc: 39.84%] [G loss: 0.930995]\n",
      "epoch:23 step:18590[D loss: 0.423840, acc: 57.81%, op_acc: 36.72%] [G loss: 0.865801]\n",
      "epoch:23 step:18591[D loss: 0.417017, acc: 60.94%, op_acc: 43.75%] [G loss: 0.868965]\n",
      "epoch:23 step:18592[D loss: 0.410685, acc: 61.72%, op_acc: 35.16%] [G loss: 0.920792]\n",
      "epoch:23 step:18593[D loss: 0.404253, acc: 60.16%, op_acc: 42.19%] [G loss: 0.854916]\n",
      "epoch:23 step:18594[D loss: 0.452402, acc: 49.22%, op_acc: 39.06%] [G loss: 0.933528]\n",
      "epoch:23 step:18595[D loss: 0.422257, acc: 56.25%, op_acc: 38.28%] [G loss: 0.907526]\n",
      "epoch:23 step:18596[D loss: 0.428126, acc: 57.81%, op_acc: 34.38%] [G loss: 0.876414]\n",
      "epoch:23 step:18597[D loss: 0.425058, acc: 52.34%, op_acc: 45.31%] [G loss: 0.926004]\n",
      "epoch:23 step:18598[D loss: 0.446099, acc: 56.25%, op_acc: 39.06%] [G loss: 0.850553]\n",
      "epoch:23 step:18599[D loss: 0.411525, acc: 62.50%, op_acc: 38.28%] [G loss: 0.831634]\n",
      "epoch:23 step:18600[D loss: 0.422254, acc: 58.59%, op_acc: 42.19%] [G loss: 0.828255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.84842454 0.85700383 0.82790395 0.8178407  0.81018778 0.83771964\n",
      " 0.87155175 0.83604317 0.79014248 0.83847333]\n",
      "##########\n",
      "epoch:23 step:18601[D loss: 0.414302, acc: 58.59%, op_acc: 40.62%] [G loss: 0.882959]\n",
      "epoch:23 step:18602[D loss: 0.425981, acc: 57.81%, op_acc: 40.62%] [G loss: 0.849167]\n",
      "epoch:23 step:18603[D loss: 0.448643, acc: 60.16%, op_acc: 30.47%] [G loss: 0.912259]\n",
      "epoch:23 step:18604[D loss: 0.412339, acc: 66.41%, op_acc: 41.41%] [G loss: 0.911089]\n",
      "epoch:23 step:18605[D loss: 0.433540, acc: 53.91%, op_acc: 35.94%] [G loss: 0.858794]\n",
      "epoch:23 step:18606[D loss: 0.457348, acc: 45.31%, op_acc: 35.94%] [G loss: 0.794204]\n",
      "epoch:23 step:18607[D loss: 0.413609, acc: 57.03%, op_acc: 42.19%] [G loss: 0.825933]\n",
      "epoch:23 step:18608[D loss: 0.426836, acc: 57.81%, op_acc: 39.06%] [G loss: 0.872008]\n",
      "epoch:23 step:18609[D loss: 0.426318, acc: 64.84%, op_acc: 34.38%] [G loss: 0.882744]\n",
      "epoch:23 step:18610[D loss: 0.424450, acc: 57.03%, op_acc: 40.62%] [G loss: 0.905398]\n",
      "epoch:23 step:18611[D loss: 0.415172, acc: 60.94%, op_acc: 34.38%] [G loss: 0.929611]\n",
      "epoch:23 step:18612[D loss: 0.429654, acc: 57.03%, op_acc: 36.72%] [G loss: 0.865821]\n",
      "epoch:23 step:18613[D loss: 0.465675, acc: 58.59%, op_acc: 37.50%] [G loss: 0.836501]\n",
      "epoch:23 step:18614[D loss: 0.429895, acc: 56.25%, op_acc: 35.94%] [G loss: 0.860681]\n",
      "epoch:23 step:18615[D loss: 0.430892, acc: 58.59%, op_acc: 38.28%] [G loss: 0.808917]\n",
      "epoch:23 step:18616[D loss: 0.412332, acc: 60.16%, op_acc: 41.41%] [G loss: 0.873929]\n",
      "epoch:23 step:18617[D loss: 0.431571, acc: 59.38%, op_acc: 42.97%] [G loss: 0.856662]\n",
      "epoch:23 step:18618[D loss: 0.443949, acc: 60.16%, op_acc: 32.81%] [G loss: 0.835737]\n",
      "epoch:23 step:18619[D loss: 0.426872, acc: 57.81%, op_acc: 41.41%] [G loss: 0.791245]\n",
      "epoch:23 step:18620[D loss: 0.432840, acc: 56.25%, op_acc: 35.16%] [G loss: 0.854681]\n",
      "epoch:23 step:18621[D loss: 0.408694, acc: 69.53%, op_acc: 35.94%] [G loss: 0.845015]\n",
      "epoch:23 step:18622[D loss: 0.406797, acc: 72.66%, op_acc: 41.41%] [G loss: 0.960936]\n",
      "epoch:23 step:18623[D loss: 0.408682, acc: 60.16%, op_acc: 40.62%] [G loss: 0.906503]\n",
      "epoch:23 step:18624[D loss: 0.414498, acc: 57.81%, op_acc: 37.50%] [G loss: 0.877302]\n",
      "epoch:23 step:18625[D loss: 0.405190, acc: 59.38%, op_acc: 42.97%] [G loss: 0.875528]\n",
      "epoch:23 step:18626[D loss: 0.392505, acc: 67.19%, op_acc: 42.19%] [G loss: 0.957264]\n",
      "epoch:23 step:18627[D loss: 0.412333, acc: 62.50%, op_acc: 39.84%] [G loss: 0.879898]\n",
      "epoch:23 step:18628[D loss: 0.431494, acc: 67.97%, op_acc: 32.03%] [G loss: 0.879528]\n",
      "epoch:23 step:18629[D loss: 0.429572, acc: 55.47%, op_acc: 38.28%] [G loss: 0.952644]\n",
      "epoch:23 step:18630[D loss: 0.403973, acc: 60.94%, op_acc: 39.06%] [G loss: 0.903151]\n",
      "epoch:23 step:18631[D loss: 0.427395, acc: 58.59%, op_acc: 41.41%] [G loss: 0.881693]\n",
      "epoch:23 step:18632[D loss: 0.453582, acc: 57.03%, op_acc: 35.16%] [G loss: 0.789208]\n",
      "epoch:23 step:18633[D loss: 0.435379, acc: 54.69%, op_acc: 35.94%] [G loss: 0.878813]\n",
      "epoch:23 step:18634[D loss: 0.409277, acc: 61.72%, op_acc: 39.06%] [G loss: 0.938027]\n",
      "epoch:23 step:18635[D loss: 0.448320, acc: 58.59%, op_acc: 33.59%] [G loss: 0.878002]\n",
      "epoch:23 step:18636[D loss: 0.424972, acc: 58.59%, op_acc: 39.84%] [G loss: 0.919528]\n",
      "epoch:23 step:18637[D loss: 0.414923, acc: 60.94%, op_acc: 36.72%] [G loss: 0.881537]\n",
      "epoch:23 step:18638[D loss: 0.416513, acc: 60.94%, op_acc: 42.19%] [G loss: 0.854489]\n",
      "epoch:23 step:18639[D loss: 0.437323, acc: 58.59%, op_acc: 39.06%] [G loss: 0.993661]\n",
      "epoch:23 step:18640[D loss: 0.454820, acc: 53.91%, op_acc: 32.81%] [G loss: 0.788461]\n",
      "epoch:23 step:18641[D loss: 0.414470, acc: 60.94%, op_acc: 41.41%] [G loss: 0.906253]\n",
      "epoch:23 step:18642[D loss: 0.404877, acc: 57.81%, op_acc: 42.19%] [G loss: 0.888058]\n",
      "epoch:23 step:18643[D loss: 0.435857, acc: 63.28%, op_acc: 39.06%] [G loss: 0.955718]\n",
      "epoch:23 step:18644[D loss: 0.425899, acc: 60.16%, op_acc: 38.28%] [G loss: 0.837731]\n",
      "epoch:23 step:18645[D loss: 0.382590, acc: 61.72%, op_acc: 44.53%] [G loss: 0.847669]\n",
      "epoch:23 step:18646[D loss: 0.409009, acc: 59.38%, op_acc: 42.19%] [G loss: 0.901667]\n",
      "epoch:23 step:18647[D loss: 0.424007, acc: 57.81%, op_acc: 35.16%] [G loss: 0.823020]\n",
      "epoch:23 step:18648[D loss: 0.438339, acc: 59.38%, op_acc: 32.03%] [G loss: 0.822065]\n",
      "epoch:23 step:18649[D loss: 0.419891, acc: 61.72%, op_acc: 35.94%] [G loss: 0.895112]\n",
      "epoch:23 step:18650[D loss: 0.464175, acc: 49.22%, op_acc: 35.94%] [G loss: 0.882497]\n",
      "##############\n",
      "[0.85287583 0.87014085 0.7899737  0.81614511 0.80597107 0.80876534\n",
      " 0.85018778 0.83063386 0.81998316 0.81643285]\n",
      "##########\n",
      "epoch:23 step:18651[D loss: 0.421400, acc: 61.72%, op_acc: 42.97%] [G loss: 0.859682]\n",
      "epoch:23 step:18652[D loss: 0.433456, acc: 50.78%, op_acc: 40.62%] [G loss: 0.794421]\n",
      "epoch:23 step:18653[D loss: 0.424435, acc: 58.59%, op_acc: 35.94%] [G loss: 0.885154]\n",
      "epoch:23 step:18654[D loss: 0.408408, acc: 64.06%, op_acc: 38.28%] [G loss: 0.942928]\n",
      "epoch:23 step:18655[D loss: 0.464030, acc: 48.44%, op_acc: 40.62%] [G loss: 0.785650]\n",
      "epoch:23 step:18656[D loss: 0.424140, acc: 60.16%, op_acc: 39.84%] [G loss: 0.908756]\n",
      "epoch:23 step:18657[D loss: 0.423464, acc: 55.47%, op_acc: 39.84%] [G loss: 0.868095]\n",
      "epoch:23 step:18658[D loss: 0.404221, acc: 64.84%, op_acc: 37.50%] [G loss: 0.831202]\n",
      "epoch:23 step:18659[D loss: 0.442411, acc: 54.69%, op_acc: 39.84%] [G loss: 0.862474]\n",
      "epoch:23 step:18660[D loss: 0.381070, acc: 72.66%, op_acc: 40.62%] [G loss: 0.937091]\n",
      "epoch:23 step:18661[D loss: 0.413611, acc: 66.41%, op_acc: 39.06%] [G loss: 0.947702]\n",
      "epoch:23 step:18662[D loss: 0.445919, acc: 57.81%, op_acc: 33.59%] [G loss: 0.838593]\n",
      "epoch:23 step:18663[D loss: 0.439471, acc: 53.91%, op_acc: 40.62%] [G loss: 0.899205]\n",
      "epoch:23 step:18664[D loss: 0.415446, acc: 64.06%, op_acc: 37.50%] [G loss: 0.956947]\n",
      "epoch:23 step:18665[D loss: 0.435326, acc: 58.59%, op_acc: 36.72%] [G loss: 0.900183]\n",
      "epoch:23 step:18666[D loss: 0.414543, acc: 61.72%, op_acc: 32.81%] [G loss: 0.830081]\n",
      "epoch:23 step:18667[D loss: 0.372788, acc: 67.19%, op_acc: 48.44%] [G loss: 0.864823]\n",
      "epoch:23 step:18668[D loss: 0.415327, acc: 60.16%, op_acc: 36.72%] [G loss: 0.883015]\n",
      "epoch:23 step:18669[D loss: 0.437582, acc: 53.91%, op_acc: 42.97%] [G loss: 0.867339]\n",
      "epoch:23 step:18670[D loss: 0.452372, acc: 53.12%, op_acc: 35.94%] [G loss: 0.838508]\n",
      "epoch:23 step:18671[D loss: 0.416599, acc: 60.16%, op_acc: 46.09%] [G loss: 0.904112]\n",
      "epoch:23 step:18672[D loss: 0.447526, acc: 53.12%, op_acc: 39.06%] [G loss: 0.774709]\n",
      "epoch:23 step:18673[D loss: 0.392622, acc: 64.06%, op_acc: 42.97%] [G loss: 0.845706]\n",
      "epoch:23 step:18674[D loss: 0.439075, acc: 57.81%, op_acc: 39.06%] [G loss: 0.851214]\n",
      "epoch:23 step:18675[D loss: 0.415949, acc: 59.38%, op_acc: 40.62%] [G loss: 0.869903]\n",
      "epoch:23 step:18676[D loss: 0.420210, acc: 60.16%, op_acc: 37.50%] [G loss: 0.878163]\n",
      "epoch:23 step:18677[D loss: 0.436028, acc: 57.03%, op_acc: 39.84%] [G loss: 0.870958]\n",
      "epoch:23 step:18678[D loss: 0.437717, acc: 54.69%, op_acc: 40.62%] [G loss: 0.867787]\n",
      "epoch:23 step:18679[D loss: 0.395837, acc: 66.41%, op_acc: 43.75%] [G loss: 0.915004]\n",
      "epoch:23 step:18680[D loss: 0.407980, acc: 61.72%, op_acc: 41.41%] [G loss: 0.825058]\n",
      "epoch:23 step:18681[D loss: 0.418378, acc: 57.03%, op_acc: 40.62%] [G loss: 0.848622]\n",
      "epoch:23 step:18682[D loss: 0.422485, acc: 60.16%, op_acc: 43.75%] [G loss: 0.941033]\n",
      "epoch:23 step:18683[D loss: 0.423759, acc: 64.06%, op_acc: 41.41%] [G loss: 0.903071]\n",
      "epoch:23 step:18684[D loss: 0.438926, acc: 50.78%, op_acc: 39.84%] [G loss: 0.881868]\n",
      "epoch:23 step:18685[D loss: 0.409980, acc: 60.94%, op_acc: 41.41%] [G loss: 0.919015]\n",
      "epoch:23 step:18686[D loss: 0.427648, acc: 56.25%, op_acc: 41.41%] [G loss: 0.883445]\n",
      "epoch:23 step:18687[D loss: 0.459244, acc: 57.81%, op_acc: 37.50%] [G loss: 0.848818]\n",
      "epoch:23 step:18688[D loss: 0.429676, acc: 56.25%, op_acc: 35.94%] [G loss: 0.925322]\n",
      "epoch:23 step:18689[D loss: 0.406169, acc: 61.72%, op_acc: 42.97%] [G loss: 0.909407]\n",
      "epoch:23 step:18690[D loss: 0.429632, acc: 55.47%, op_acc: 35.94%] [G loss: 0.908985]\n",
      "epoch:23 step:18691[D loss: 0.434519, acc: 63.28%, op_acc: 36.72%] [G loss: 0.936130]\n",
      "epoch:23 step:18692[D loss: 0.416251, acc: 64.84%, op_acc: 42.19%] [G loss: 0.882713]\n",
      "epoch:23 step:18693[D loss: 0.426615, acc: 61.72%, op_acc: 42.97%] [G loss: 0.798119]\n",
      "epoch:23 step:18694[D loss: 0.413445, acc: 56.25%, op_acc: 38.28%] [G loss: 0.842908]\n",
      "epoch:23 step:18695[D loss: 0.427483, acc: 57.03%, op_acc: 42.97%] [G loss: 0.903951]\n",
      "epoch:23 step:18696[D loss: 0.421690, acc: 56.25%, op_acc: 39.06%] [G loss: 0.898486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18697[D loss: 0.422826, acc: 62.50%, op_acc: 40.62%] [G loss: 0.900472]\n",
      "epoch:23 step:18698[D loss: 0.445480, acc: 51.56%, op_acc: 34.38%] [G loss: 0.876369]\n",
      "epoch:23 step:18699[D loss: 0.401764, acc: 71.09%, op_acc: 35.94%] [G loss: 0.900632]\n",
      "epoch:23 step:18700[D loss: 0.384393, acc: 65.62%, op_acc: 40.62%] [G loss: 0.918015]\n",
      "##############\n",
      "[0.86201963 0.84942743 0.81905768 0.79472643 0.78008146 0.82581426\n",
      " 0.89562889 0.80932654 0.80317648 0.81041058]\n",
      "##########\n",
      "epoch:23 step:18701[D loss: 0.430318, acc: 57.03%, op_acc: 36.72%] [G loss: 0.892067]\n",
      "epoch:23 step:18702[D loss: 0.437646, acc: 58.59%, op_acc: 39.06%] [G loss: 0.859393]\n",
      "epoch:23 step:18703[D loss: 0.398071, acc: 64.84%, op_acc: 47.66%] [G loss: 0.880892]\n",
      "epoch:23 step:18704[D loss: 0.420296, acc: 57.03%, op_acc: 38.28%] [G loss: 0.907627]\n",
      "epoch:23 step:18705[D loss: 0.449412, acc: 55.47%, op_acc: 39.06%] [G loss: 0.855285]\n",
      "epoch:23 step:18706[D loss: 0.440921, acc: 51.56%, op_acc: 42.19%] [G loss: 0.886607]\n",
      "epoch:23 step:18707[D loss: 0.397648, acc: 58.59%, op_acc: 39.84%] [G loss: 0.856794]\n",
      "epoch:23 step:18708[D loss: 0.426552, acc: 56.25%, op_acc: 40.62%] [G loss: 0.800180]\n",
      "epoch:23 step:18709[D loss: 0.442156, acc: 53.91%, op_acc: 38.28%] [G loss: 0.879617]\n",
      "epoch:23 step:18710[D loss: 0.444080, acc: 59.38%, op_acc: 36.72%] [G loss: 0.815800]\n",
      "epoch:23 step:18711[D loss: 0.436203, acc: 60.16%, op_acc: 34.38%] [G loss: 0.893664]\n",
      "epoch:23 step:18712[D loss: 0.437433, acc: 55.47%, op_acc: 37.50%] [G loss: 0.870710]\n",
      "epoch:23 step:18713[D loss: 0.408006, acc: 60.94%, op_acc: 42.97%] [G loss: 0.904223]\n",
      "epoch:23 step:18714[D loss: 0.439898, acc: 60.94%, op_acc: 31.25%] [G loss: 0.911342]\n",
      "epoch:23 step:18715[D loss: 0.409192, acc: 62.50%, op_acc: 42.19%] [G loss: 0.857517]\n",
      "epoch:23 step:18716[D loss: 0.428872, acc: 59.38%, op_acc: 38.28%] [G loss: 0.869873]\n",
      "epoch:23 step:18717[D loss: 0.403690, acc: 65.62%, op_acc: 42.19%] [G loss: 0.841597]\n",
      "epoch:23 step:18718[D loss: 0.446677, acc: 58.59%, op_acc: 39.84%] [G loss: 0.875695]\n",
      "epoch:23 step:18719[D loss: 0.415951, acc: 58.59%, op_acc: 41.41%] [G loss: 0.908647]\n",
      "epoch:23 step:18720[D loss: 0.416874, acc: 58.59%, op_acc: 42.19%] [G loss: 0.866972]\n",
      "epoch:23 step:18721[D loss: 0.418672, acc: 61.72%, op_acc: 38.28%] [G loss: 0.807848]\n",
      "epoch:23 step:18722[D loss: 0.444579, acc: 53.12%, op_acc: 42.19%] [G loss: 0.912767]\n",
      "epoch:23 step:18723[D loss: 0.417449, acc: 53.91%, op_acc: 42.97%] [G loss: 0.842937]\n",
      "epoch:23 step:18724[D loss: 0.408151, acc: 64.84%, op_acc: 42.19%] [G loss: 0.858941]\n",
      "epoch:23 step:18725[D loss: 0.453254, acc: 51.56%, op_acc: 39.84%] [G loss: 0.924055]\n",
      "epoch:23 step:18726[D loss: 0.443113, acc: 51.56%, op_acc: 37.50%] [G loss: 0.912246]\n",
      "epoch:23 step:18727[D loss: 0.413877, acc: 57.03%, op_acc: 42.19%] [G loss: 0.866543]\n",
      "epoch:23 step:18728[D loss: 0.420059, acc: 55.47%, op_acc: 39.06%] [G loss: 0.930259]\n",
      "epoch:23 step:18729[D loss: 0.440890, acc: 59.38%, op_acc: 35.16%] [G loss: 0.855605]\n",
      "epoch:23 step:18730[D loss: 0.426764, acc: 59.38%, op_acc: 40.62%] [G loss: 0.923644]\n",
      "epoch:23 step:18731[D loss: 0.436580, acc: 55.47%, op_acc: 41.41%] [G loss: 0.859842]\n",
      "epoch:23 step:18732[D loss: 0.397990, acc: 61.72%, op_acc: 37.50%] [G loss: 0.795832]\n",
      "epoch:23 step:18733[D loss: 0.420116, acc: 56.25%, op_acc: 40.62%] [G loss: 0.925942]\n",
      "epoch:23 step:18734[D loss: 0.467837, acc: 52.34%, op_acc: 35.94%] [G loss: 0.909098]\n",
      "epoch:23 step:18735[D loss: 0.444980, acc: 55.47%, op_acc: 37.50%] [G loss: 0.860814]\n",
      "epoch:23 step:18736[D loss: 0.438551, acc: 54.69%, op_acc: 36.72%] [G loss: 0.895191]\n",
      "epoch:23 step:18737[D loss: 0.394184, acc: 64.06%, op_acc: 47.66%] [G loss: 0.850827]\n",
      "epoch:23 step:18738[D loss: 0.413230, acc: 57.81%, op_acc: 44.53%] [G loss: 0.834876]\n",
      "epoch:23 step:18739[D loss: 0.426713, acc: 57.81%, op_acc: 32.81%] [G loss: 0.904350]\n",
      "epoch:23 step:18740[D loss: 0.457768, acc: 50.78%, op_acc: 35.94%] [G loss: 0.811083]\n",
      "epoch:23 step:18741[D loss: 0.408410, acc: 60.16%, op_acc: 40.62%] [G loss: 0.953335]\n",
      "epoch:23 step:18742[D loss: 0.409728, acc: 67.19%, op_acc: 37.50%] [G loss: 0.880221]\n",
      "epoch:23 step:18743[D loss: 0.420468, acc: 57.03%, op_acc: 43.75%] [G loss: 0.889617]\n",
      "epoch:23 step:18744[D loss: 0.419419, acc: 61.72%, op_acc: 41.41%] [G loss: 0.876915]\n",
      "epoch:24 step:18745[D loss: 0.439397, acc: 53.91%, op_acc: 40.62%] [G loss: 0.818159]\n",
      "epoch:24 step:18746[D loss: 0.413269, acc: 58.59%, op_acc: 43.75%] [G loss: 0.901298]\n",
      "epoch:24 step:18747[D loss: 0.450487, acc: 59.38%, op_acc: 32.03%] [G loss: 0.896842]\n",
      "epoch:24 step:18748[D loss: 0.404865, acc: 59.38%, op_acc: 45.31%] [G loss: 0.888493]\n",
      "epoch:24 step:18749[D loss: 0.414115, acc: 57.03%, op_acc: 41.41%] [G loss: 0.894363]\n",
      "epoch:24 step:18750[D loss: 0.444050, acc: 49.22%, op_acc: 40.62%] [G loss: 0.855601]\n",
      "##############\n",
      "[0.86007804 0.88185882 0.79673092 0.81521799 0.79524327 0.801449\n",
      " 0.8903499  0.83305597 0.82070607 0.83462391]\n",
      "##########\n",
      "epoch:24 step:18751[D loss: 0.383789, acc: 67.19%, op_acc: 42.19%] [G loss: 0.898607]\n",
      "epoch:24 step:18752[D loss: 0.418169, acc: 58.59%, op_acc: 36.72%] [G loss: 0.899827]\n",
      "epoch:24 step:18753[D loss: 0.401587, acc: 65.62%, op_acc: 43.75%] [G loss: 0.849076]\n",
      "epoch:24 step:18754[D loss: 0.434114, acc: 54.69%, op_acc: 34.38%] [G loss: 0.862573]\n",
      "epoch:24 step:18755[D loss: 0.432591, acc: 58.59%, op_acc: 42.97%] [G loss: 0.862876]\n",
      "epoch:24 step:18756[D loss: 0.417929, acc: 56.25%, op_acc: 37.50%] [G loss: 0.843452]\n",
      "epoch:24 step:18757[D loss: 0.428061, acc: 58.59%, op_acc: 35.94%] [G loss: 0.851805]\n",
      "epoch:24 step:18758[D loss: 0.438387, acc: 56.25%, op_acc: 29.69%] [G loss: 0.914229]\n",
      "epoch:24 step:18759[D loss: 0.413501, acc: 64.06%, op_acc: 42.19%] [G loss: 0.899436]\n",
      "epoch:24 step:18760[D loss: 0.390377, acc: 67.19%, op_acc: 46.09%] [G loss: 0.955768]\n",
      "epoch:24 step:18761[D loss: 0.415550, acc: 64.06%, op_acc: 39.06%] [G loss: 0.842572]\n",
      "epoch:24 step:18762[D loss: 0.437020, acc: 61.72%, op_acc: 42.19%] [G loss: 0.818990]\n",
      "epoch:24 step:18763[D loss: 0.412718, acc: 60.16%, op_acc: 38.28%] [G loss: 0.867981]\n",
      "epoch:24 step:18764[D loss: 0.404680, acc: 60.94%, op_acc: 42.19%] [G loss: 0.829625]\n",
      "epoch:24 step:18765[D loss: 0.414732, acc: 59.38%, op_acc: 40.62%] [G loss: 0.854357]\n",
      "epoch:24 step:18766[D loss: 0.418138, acc: 60.94%, op_acc: 37.50%] [G loss: 0.833500]\n",
      "epoch:24 step:18767[D loss: 0.424380, acc: 60.16%, op_acc: 41.41%] [G loss: 0.798760]\n",
      "epoch:24 step:18768[D loss: 0.433867, acc: 57.03%, op_acc: 41.41%] [G loss: 0.904531]\n",
      "epoch:24 step:18769[D loss: 0.445034, acc: 53.91%, op_acc: 39.84%] [G loss: 0.892082]\n",
      "epoch:24 step:18770[D loss: 0.410123, acc: 66.41%, op_acc: 40.62%] [G loss: 0.855682]\n",
      "epoch:24 step:18771[D loss: 0.440435, acc: 55.47%, op_acc: 37.50%] [G loss: 0.881735]\n",
      "epoch:24 step:18772[D loss: 0.412649, acc: 57.03%, op_acc: 44.53%] [G loss: 0.804830]\n",
      "epoch:24 step:18773[D loss: 0.419197, acc: 58.59%, op_acc: 42.97%] [G loss: 0.800021]\n",
      "epoch:24 step:18774[D loss: 0.409876, acc: 62.50%, op_acc: 42.19%] [G loss: 0.883761]\n",
      "epoch:24 step:18775[D loss: 0.443584, acc: 57.03%, op_acc: 39.84%] [G loss: 0.902233]\n",
      "epoch:24 step:18776[D loss: 0.415796, acc: 60.16%, op_acc: 35.16%] [G loss: 0.870625]\n",
      "epoch:24 step:18777[D loss: 0.397730, acc: 62.50%, op_acc: 44.53%] [G loss: 0.950488]\n",
      "epoch:24 step:18778[D loss: 0.393441, acc: 64.06%, op_acc: 40.62%] [G loss: 0.809994]\n",
      "epoch:24 step:18779[D loss: 0.424121, acc: 64.84%, op_acc: 37.50%] [G loss: 0.838659]\n",
      "epoch:24 step:18780[D loss: 0.419136, acc: 64.84%, op_acc: 42.19%] [G loss: 0.903734]\n",
      "epoch:24 step:18781[D loss: 0.395718, acc: 67.97%, op_acc: 41.41%] [G loss: 0.851063]\n",
      "epoch:24 step:18782[D loss: 0.396715, acc: 60.94%, op_acc: 43.75%] [G loss: 0.881690]\n",
      "epoch:24 step:18783[D loss: 0.426592, acc: 51.56%, op_acc: 45.31%] [G loss: 0.818183]\n",
      "epoch:24 step:18784[D loss: 0.420171, acc: 61.72%, op_acc: 42.19%] [G loss: 0.921238]\n",
      "epoch:24 step:18785[D loss: 0.421665, acc: 54.69%, op_acc: 42.97%] [G loss: 0.813307]\n",
      "epoch:24 step:18786[D loss: 0.382518, acc: 67.19%, op_acc: 43.75%] [G loss: 0.887223]\n",
      "epoch:24 step:18787[D loss: 0.431079, acc: 59.38%, op_acc: 34.38%] [G loss: 0.923251]\n",
      "epoch:24 step:18788[D loss: 0.451308, acc: 51.56%, op_acc: 39.84%] [G loss: 0.876822]\n",
      "epoch:24 step:18789[D loss: 0.430856, acc: 61.72%, op_acc: 42.19%] [G loss: 0.897741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18790[D loss: 0.429652, acc: 54.69%, op_acc: 35.94%] [G loss: 0.919016]\n",
      "epoch:24 step:18791[D loss: 0.435042, acc: 62.50%, op_acc: 35.16%] [G loss: 0.862810]\n",
      "epoch:24 step:18792[D loss: 0.467157, acc: 51.56%, op_acc: 38.28%] [G loss: 0.778240]\n",
      "epoch:24 step:18793[D loss: 0.403232, acc: 63.28%, op_acc: 40.62%] [G loss: 0.874352]\n",
      "epoch:24 step:18794[D loss: 0.452454, acc: 53.12%, op_acc: 38.28%] [G loss: 0.876063]\n",
      "epoch:24 step:18795[D loss: 0.414075, acc: 63.28%, op_acc: 39.84%] [G loss: 0.888371]\n",
      "epoch:24 step:18796[D loss: 0.421512, acc: 60.16%, op_acc: 40.62%] [G loss: 0.908940]\n",
      "epoch:24 step:18797[D loss: 0.442115, acc: 53.91%, op_acc: 34.38%] [G loss: 0.908589]\n",
      "epoch:24 step:18798[D loss: 0.447756, acc: 56.25%, op_acc: 42.97%] [G loss: 0.834203]\n",
      "epoch:24 step:18799[D loss: 0.447694, acc: 51.56%, op_acc: 39.84%] [G loss: 0.902551]\n",
      "epoch:24 step:18800[D loss: 0.414369, acc: 60.94%, op_acc: 42.97%] [G loss: 0.931156]\n",
      "##############\n",
      "[0.84501938 0.86076073 0.82233315 0.80032205 0.8146444  0.81011581\n",
      " 0.87858994 0.80967696 0.78562482 0.83302786]\n",
      "##########\n",
      "epoch:24 step:18801[D loss: 0.420815, acc: 60.94%, op_acc: 46.88%] [G loss: 0.847518]\n",
      "epoch:24 step:18802[D loss: 0.390918, acc: 57.03%, op_acc: 46.09%] [G loss: 1.010094]\n",
      "epoch:24 step:18803[D loss: 0.418051, acc: 54.69%, op_acc: 42.97%] [G loss: 0.958189]\n",
      "epoch:24 step:18804[D loss: 0.396803, acc: 64.84%, op_acc: 40.62%] [G loss: 0.858230]\n",
      "epoch:24 step:18805[D loss: 0.459075, acc: 53.12%, op_acc: 39.06%] [G loss: 0.832524]\n",
      "epoch:24 step:18806[D loss: 0.412649, acc: 61.72%, op_acc: 43.75%] [G loss: 0.911356]\n",
      "epoch:24 step:18807[D loss: 0.416829, acc: 63.28%, op_acc: 36.72%] [G loss: 0.842614]\n",
      "epoch:24 step:18808[D loss: 0.432565, acc: 55.47%, op_acc: 39.06%] [G loss: 0.889669]\n",
      "epoch:24 step:18809[D loss: 0.412543, acc: 65.62%, op_acc: 35.94%] [G loss: 0.857430]\n",
      "epoch:24 step:18810[D loss: 0.450065, acc: 50.78%, op_acc: 40.62%] [G loss: 0.847071]\n",
      "epoch:24 step:18811[D loss: 0.417016, acc: 60.16%, op_acc: 39.06%] [G loss: 0.821691]\n",
      "epoch:24 step:18812[D loss: 0.400007, acc: 64.84%, op_acc: 44.53%] [G loss: 0.947828]\n",
      "epoch:24 step:18813[D loss: 0.401601, acc: 58.59%, op_acc: 47.66%] [G loss: 0.833386]\n",
      "epoch:24 step:18814[D loss: 0.451985, acc: 53.91%, op_acc: 36.72%] [G loss: 0.933062]\n",
      "epoch:24 step:18815[D loss: 0.458818, acc: 54.69%, op_acc: 35.16%] [G loss: 0.858545]\n",
      "epoch:24 step:18816[D loss: 0.399163, acc: 57.03%, op_acc: 44.53%] [G loss: 0.923171]\n",
      "epoch:24 step:18817[D loss: 0.409163, acc: 61.72%, op_acc: 39.84%] [G loss: 0.890313]\n",
      "epoch:24 step:18818[D loss: 0.386326, acc: 63.28%, op_acc: 42.19%] [G loss: 0.970234]\n",
      "epoch:24 step:18819[D loss: 0.410008, acc: 59.38%, op_acc: 43.75%] [G loss: 0.896978]\n",
      "epoch:24 step:18820[D loss: 0.472600, acc: 45.31%, op_acc: 39.06%] [G loss: 0.831807]\n",
      "epoch:24 step:18821[D loss: 0.422807, acc: 53.12%, op_acc: 42.97%] [G loss: 0.881834]\n",
      "epoch:24 step:18822[D loss: 0.433822, acc: 64.84%, op_acc: 35.94%] [G loss: 0.846905]\n",
      "epoch:24 step:18823[D loss: 0.425131, acc: 57.81%, op_acc: 39.06%] [G loss: 0.840884]\n",
      "epoch:24 step:18824[D loss: 0.430175, acc: 61.72%, op_acc: 37.50%] [G loss: 0.773368]\n",
      "epoch:24 step:18825[D loss: 0.418050, acc: 64.06%, op_acc: 36.72%] [G loss: 0.901326]\n",
      "epoch:24 step:18826[D loss: 0.433710, acc: 53.91%, op_acc: 39.06%] [G loss: 0.828357]\n",
      "epoch:24 step:18827[D loss: 0.418732, acc: 57.81%, op_acc: 39.06%] [G loss: 0.820958]\n",
      "epoch:24 step:18828[D loss: 0.407900, acc: 64.06%, op_acc: 38.28%] [G loss: 0.823009]\n",
      "epoch:24 step:18829[D loss: 0.443628, acc: 58.59%, op_acc: 33.59%] [G loss: 0.892903]\n",
      "epoch:24 step:18830[D loss: 0.407968, acc: 68.75%, op_acc: 38.28%] [G loss: 0.853176]\n",
      "epoch:24 step:18831[D loss: 0.442544, acc: 60.16%, op_acc: 38.28%] [G loss: 0.852214]\n",
      "epoch:24 step:18832[D loss: 0.426189, acc: 57.81%, op_acc: 38.28%] [G loss: 0.949198]\n",
      "epoch:24 step:18833[D loss: 0.460665, acc: 46.09%, op_acc: 36.72%] [G loss: 0.833021]\n",
      "epoch:24 step:18834[D loss: 0.440556, acc: 62.50%, op_acc: 37.50%] [G loss: 0.857925]\n",
      "epoch:24 step:18835[D loss: 0.420156, acc: 60.16%, op_acc: 36.72%] [G loss: 0.869550]\n",
      "epoch:24 step:18836[D loss: 0.426622, acc: 61.72%, op_acc: 38.28%] [G loss: 0.924772]\n",
      "epoch:24 step:18837[D loss: 0.423114, acc: 59.38%, op_acc: 42.19%] [G loss: 0.850232]\n",
      "epoch:24 step:18838[D loss: 0.395877, acc: 64.06%, op_acc: 40.62%] [G loss: 0.931473]\n",
      "epoch:24 step:18839[D loss: 0.413049, acc: 59.38%, op_acc: 38.28%] [G loss: 0.865534]\n",
      "epoch:24 step:18840[D loss: 0.416086, acc: 60.16%, op_acc: 35.94%] [G loss: 0.886760]\n",
      "epoch:24 step:18841[D loss: 0.424711, acc: 60.16%, op_acc: 36.72%] [G loss: 0.947528]\n",
      "epoch:24 step:18842[D loss: 0.428735, acc: 65.62%, op_acc: 29.69%] [G loss: 0.892803]\n",
      "epoch:24 step:18843[D loss: 0.410998, acc: 63.28%, op_acc: 39.84%] [G loss: 0.867790]\n",
      "epoch:24 step:18844[D loss: 0.397786, acc: 60.16%, op_acc: 41.41%] [G loss: 0.800548]\n",
      "epoch:24 step:18845[D loss: 0.406607, acc: 70.31%, op_acc: 41.41%] [G loss: 0.929639]\n",
      "epoch:24 step:18846[D loss: 0.402150, acc: 65.62%, op_acc: 39.06%] [G loss: 0.952860]\n",
      "epoch:24 step:18847[D loss: 0.437282, acc: 58.59%, op_acc: 37.50%] [G loss: 0.928317]\n",
      "epoch:24 step:18848[D loss: 0.431151, acc: 61.72%, op_acc: 36.72%] [G loss: 0.845139]\n",
      "epoch:24 step:18849[D loss: 0.414440, acc: 64.84%, op_acc: 39.06%] [G loss: 0.890960]\n",
      "epoch:24 step:18850[D loss: 0.433934, acc: 53.91%, op_acc: 39.84%] [G loss: 0.875882]\n",
      "##############\n",
      "[0.88435242 0.86650891 0.80264003 0.81732599 0.78769115 0.83518968\n",
      " 0.87457646 0.82747975 0.80589953 0.83107114]\n",
      "##########\n",
      "epoch:24 step:18851[D loss: 0.406555, acc: 67.97%, op_acc: 36.72%] [G loss: 0.902769]\n",
      "epoch:24 step:18852[D loss: 0.451419, acc: 57.03%, op_acc: 35.16%] [G loss: 0.837585]\n",
      "epoch:24 step:18853[D loss: 0.427660, acc: 63.28%, op_acc: 38.28%] [G loss: 0.895946]\n",
      "epoch:24 step:18854[D loss: 0.404426, acc: 60.16%, op_acc: 40.62%] [G loss: 0.938065]\n",
      "epoch:24 step:18855[D loss: 0.442713, acc: 61.72%, op_acc: 35.94%] [G loss: 0.876253]\n",
      "epoch:24 step:18856[D loss: 0.413770, acc: 59.38%, op_acc: 42.19%] [G loss: 0.866026]\n",
      "epoch:24 step:18857[D loss: 0.441215, acc: 59.38%, op_acc: 34.38%] [G loss: 0.884212]\n",
      "epoch:24 step:18858[D loss: 0.442707, acc: 56.25%, op_acc: 42.97%] [G loss: 0.900835]\n",
      "epoch:24 step:18859[D loss: 0.394564, acc: 57.03%, op_acc: 42.19%] [G loss: 0.880777]\n",
      "epoch:24 step:18860[D loss: 0.454921, acc: 56.25%, op_acc: 35.16%] [G loss: 0.878844]\n",
      "epoch:24 step:18861[D loss: 0.425973, acc: 61.72%, op_acc: 44.53%] [G loss: 0.897669]\n",
      "epoch:24 step:18862[D loss: 0.443435, acc: 51.56%, op_acc: 39.84%] [G loss: 0.813432]\n",
      "epoch:24 step:18863[D loss: 0.403864, acc: 66.41%, op_acc: 39.06%] [G loss: 0.873169]\n",
      "epoch:24 step:18864[D loss: 0.445573, acc: 53.91%, op_acc: 34.38%] [G loss: 0.858895]\n",
      "epoch:24 step:18865[D loss: 0.421767, acc: 60.16%, op_acc: 40.62%] [G loss: 0.914602]\n",
      "epoch:24 step:18866[D loss: 0.436739, acc: 60.16%, op_acc: 37.50%] [G loss: 0.887209]\n",
      "epoch:24 step:18867[D loss: 0.447478, acc: 52.34%, op_acc: 35.16%] [G loss: 0.833312]\n",
      "epoch:24 step:18868[D loss: 0.400185, acc: 65.62%, op_acc: 40.62%] [G loss: 0.898888]\n",
      "epoch:24 step:18869[D loss: 0.442688, acc: 55.47%, op_acc: 37.50%] [G loss: 0.959023]\n",
      "epoch:24 step:18870[D loss: 0.448475, acc: 51.56%, op_acc: 39.84%] [G loss: 0.838014]\n",
      "epoch:24 step:18871[D loss: 0.407404, acc: 62.50%, op_acc: 39.06%] [G loss: 0.879061]\n",
      "epoch:24 step:18872[D loss: 0.396829, acc: 64.84%, op_acc: 42.97%] [G loss: 0.874701]\n",
      "epoch:24 step:18873[D loss: 0.434804, acc: 60.94%, op_acc: 36.72%] [G loss: 0.816971]\n",
      "epoch:24 step:18874[D loss: 0.405731, acc: 60.16%, op_acc: 44.53%] [G loss: 0.856716]\n",
      "epoch:24 step:18875[D loss: 0.415702, acc: 64.06%, op_acc: 38.28%] [G loss: 0.879187]\n",
      "epoch:24 step:18876[D loss: 0.401885, acc: 58.59%, op_acc: 42.97%] [G loss: 0.849501]\n",
      "epoch:24 step:18877[D loss: 0.456560, acc: 59.38%, op_acc: 29.69%] [G loss: 0.940805]\n",
      "epoch:24 step:18878[D loss: 0.414812, acc: 59.38%, op_acc: 44.53%] [G loss: 0.891229]\n",
      "epoch:24 step:18879[D loss: 0.435371, acc: 54.69%, op_acc: 35.16%] [G loss: 0.850172]\n",
      "epoch:24 step:18880[D loss: 0.376261, acc: 66.41%, op_acc: 42.19%] [G loss: 0.910645]\n",
      "epoch:24 step:18881[D loss: 0.431194, acc: 56.25%, op_acc: 40.62%] [G loss: 0.809472]\n",
      "epoch:24 step:18882[D loss: 0.453883, acc: 49.22%, op_acc: 38.28%] [G loss: 0.872011]\n",
      "epoch:24 step:18883[D loss: 0.416434, acc: 58.59%, op_acc: 43.75%] [G loss: 0.887375]\n",
      "epoch:24 step:18884[D loss: 0.456619, acc: 57.81%, op_acc: 36.72%] [G loss: 0.933167]\n",
      "epoch:24 step:18885[D loss: 0.403388, acc: 61.72%, op_acc: 32.03%] [G loss: 0.925656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18886[D loss: 0.418307, acc: 64.06%, op_acc: 35.94%] [G loss: 0.836752]\n",
      "epoch:24 step:18887[D loss: 0.443821, acc: 53.12%, op_acc: 43.75%] [G loss: 0.853079]\n",
      "epoch:24 step:18888[D loss: 0.414524, acc: 62.50%, op_acc: 36.72%] [G loss: 0.907080]\n",
      "epoch:24 step:18889[D loss: 0.447745, acc: 57.81%, op_acc: 39.06%] [G loss: 0.798759]\n",
      "epoch:24 step:18890[D loss: 0.434892, acc: 60.94%, op_acc: 33.59%] [G loss: 0.878800]\n",
      "epoch:24 step:18891[D loss: 0.411133, acc: 57.81%, op_acc: 42.97%] [G loss: 0.894627]\n",
      "epoch:24 step:18892[D loss: 0.427177, acc: 63.28%, op_acc: 37.50%] [G loss: 0.921914]\n",
      "epoch:24 step:18893[D loss: 0.401781, acc: 60.16%, op_acc: 44.53%] [G loss: 0.851824]\n",
      "epoch:24 step:18894[D loss: 0.447394, acc: 51.56%, op_acc: 39.84%] [G loss: 0.892993]\n",
      "epoch:24 step:18895[D loss: 0.391968, acc: 64.84%, op_acc: 44.53%] [G loss: 0.972324]\n",
      "epoch:24 step:18896[D loss: 0.410601, acc: 54.69%, op_acc: 42.97%] [G loss: 0.764261]\n",
      "epoch:24 step:18897[D loss: 0.424420, acc: 59.38%, op_acc: 38.28%] [G loss: 0.906169]\n",
      "epoch:24 step:18898[D loss: 0.422300, acc: 60.16%, op_acc: 35.94%] [G loss: 0.868142]\n",
      "epoch:24 step:18899[D loss: 0.433493, acc: 55.47%, op_acc: 39.84%] [G loss: 0.844455]\n",
      "epoch:24 step:18900[D loss: 0.451891, acc: 53.91%, op_acc: 41.41%] [G loss: 0.878975]\n",
      "##############\n",
      "[0.86120026 0.85491012 0.80707356 0.8216602  0.78844007 0.8390145\n",
      " 0.90114918 0.83386246 0.8177553  0.83137914]\n",
      "##########\n",
      "epoch:24 step:18901[D loss: 0.413701, acc: 60.16%, op_acc: 40.62%] [G loss: 0.791305]\n",
      "epoch:24 step:18902[D loss: 0.426918, acc: 52.34%, op_acc: 42.19%] [G loss: 0.870342]\n",
      "epoch:24 step:18903[D loss: 0.412067, acc: 64.84%, op_acc: 42.19%] [G loss: 0.778026]\n",
      "epoch:24 step:18904[D loss: 0.437738, acc: 59.38%, op_acc: 33.59%] [G loss: 0.847420]\n",
      "epoch:24 step:18905[D loss: 0.426943, acc: 56.25%, op_acc: 38.28%] [G loss: 0.834376]\n",
      "epoch:24 step:18906[D loss: 0.422459, acc: 52.34%, op_acc: 40.62%] [G loss: 0.837556]\n",
      "epoch:24 step:18907[D loss: 0.464064, acc: 50.78%, op_acc: 41.41%] [G loss: 0.792476]\n",
      "epoch:24 step:18908[D loss: 0.451547, acc: 57.81%, op_acc: 35.16%] [G loss: 0.857821]\n",
      "epoch:24 step:18909[D loss: 0.394287, acc: 71.88%, op_acc: 38.28%] [G loss: 0.878202]\n",
      "epoch:24 step:18910[D loss: 0.441340, acc: 60.94%, op_acc: 39.84%] [G loss: 0.903808]\n",
      "epoch:24 step:18911[D loss: 0.405988, acc: 60.16%, op_acc: 39.06%] [G loss: 0.850369]\n",
      "epoch:24 step:18912[D loss: 0.415710, acc: 60.16%, op_acc: 39.06%] [G loss: 0.900529]\n",
      "epoch:24 step:18913[D loss: 0.433312, acc: 57.81%, op_acc: 36.72%] [G loss: 0.877766]\n",
      "epoch:24 step:18914[D loss: 0.428019, acc: 57.81%, op_acc: 40.62%] [G loss: 0.875855]\n",
      "epoch:24 step:18915[D loss: 0.425365, acc: 57.81%, op_acc: 36.72%] [G loss: 0.855796]\n",
      "epoch:24 step:18916[D loss: 0.399744, acc: 63.28%, op_acc: 41.41%] [G loss: 0.870010]\n",
      "epoch:24 step:18917[D loss: 0.438004, acc: 53.91%, op_acc: 39.84%] [G loss: 0.868024]\n",
      "epoch:24 step:18918[D loss: 0.447691, acc: 56.25%, op_acc: 38.28%] [G loss: 0.861115]\n",
      "epoch:24 step:18919[D loss: 0.429797, acc: 57.03%, op_acc: 38.28%] [G loss: 0.832343]\n",
      "epoch:24 step:18920[D loss: 0.436009, acc: 53.91%, op_acc: 36.72%] [G loss: 0.786010]\n",
      "epoch:24 step:18921[D loss: 0.397725, acc: 60.94%, op_acc: 42.97%] [G loss: 0.841929]\n",
      "epoch:24 step:18922[D loss: 0.445038, acc: 57.81%, op_acc: 41.41%] [G loss: 0.883814]\n",
      "epoch:24 step:18923[D loss: 0.406256, acc: 61.72%, op_acc: 37.50%] [G loss: 0.899687]\n",
      "epoch:24 step:18924[D loss: 0.426484, acc: 63.28%, op_acc: 39.06%] [G loss: 0.882222]\n",
      "epoch:24 step:18925[D loss: 0.398716, acc: 64.84%, op_acc: 40.62%] [G loss: 0.890818]\n",
      "epoch:24 step:18926[D loss: 0.435990, acc: 54.69%, op_acc: 35.16%] [G loss: 0.875736]\n",
      "epoch:24 step:18927[D loss: 0.419327, acc: 62.50%, op_acc: 35.16%] [G loss: 0.911564]\n",
      "epoch:24 step:18928[D loss: 0.419297, acc: 60.94%, op_acc: 40.62%] [G loss: 0.917343]\n",
      "epoch:24 step:18929[D loss: 0.454594, acc: 60.16%, op_acc: 32.81%] [G loss: 0.896519]\n",
      "epoch:24 step:18930[D loss: 0.415377, acc: 64.06%, op_acc: 44.53%] [G loss: 0.902552]\n",
      "epoch:24 step:18931[D loss: 0.418185, acc: 60.16%, op_acc: 40.62%] [G loss: 0.876383]\n",
      "epoch:24 step:18932[D loss: 0.420654, acc: 57.03%, op_acc: 39.84%] [G loss: 0.969896]\n",
      "epoch:24 step:18933[D loss: 0.424427, acc: 60.94%, op_acc: 36.72%] [G loss: 0.855334]\n",
      "epoch:24 step:18934[D loss: 0.440274, acc: 59.38%, op_acc: 35.94%] [G loss: 0.880041]\n",
      "epoch:24 step:18935[D loss: 0.418150, acc: 60.16%, op_acc: 39.84%] [G loss: 0.859679]\n",
      "epoch:24 step:18936[D loss: 0.411920, acc: 60.94%, op_acc: 38.28%] [G loss: 0.775452]\n",
      "epoch:24 step:18937[D loss: 0.448700, acc: 59.38%, op_acc: 30.47%] [G loss: 0.827552]\n",
      "epoch:24 step:18938[D loss: 0.428871, acc: 56.25%, op_acc: 42.97%] [G loss: 0.869756]\n",
      "epoch:24 step:18939[D loss: 0.411451, acc: 64.84%, op_acc: 35.94%] [G loss: 0.889813]\n",
      "epoch:24 step:18940[D loss: 0.420280, acc: 64.84%, op_acc: 35.16%] [G loss: 0.911324]\n",
      "epoch:24 step:18941[D loss: 0.491579, acc: 48.44%, op_acc: 36.72%] [G loss: 0.894889]\n",
      "epoch:24 step:18942[D loss: 0.429980, acc: 58.59%, op_acc: 38.28%] [G loss: 0.897854]\n",
      "epoch:24 step:18943[D loss: 0.414561, acc: 60.94%, op_acc: 41.41%] [G loss: 0.850668]\n",
      "epoch:24 step:18944[D loss: 0.435930, acc: 57.03%, op_acc: 39.06%] [G loss: 0.891651]\n",
      "epoch:24 step:18945[D loss: 0.426812, acc: 49.22%, op_acc: 44.53%] [G loss: 0.922835]\n",
      "epoch:24 step:18946[D loss: 0.430059, acc: 63.28%, op_acc: 35.16%] [G loss: 0.873180]\n",
      "epoch:24 step:18947[D loss: 0.434419, acc: 58.59%, op_acc: 34.38%] [G loss: 0.931897]\n",
      "epoch:24 step:18948[D loss: 0.410521, acc: 59.38%, op_acc: 39.84%] [G loss: 0.887819]\n",
      "epoch:24 step:18949[D loss: 0.435328, acc: 58.59%, op_acc: 39.84%] [G loss: 0.884892]\n",
      "epoch:24 step:18950[D loss: 0.426051, acc: 58.59%, op_acc: 41.41%] [G loss: 0.811591]\n",
      "##############\n",
      "[0.84958982 0.86588204 0.83307056 0.81027148 0.78326784 0.82312293\n",
      " 0.87958309 0.81864735 0.80596959 0.82692369]\n",
      "##########\n",
      "epoch:24 step:18951[D loss: 0.392008, acc: 67.19%, op_acc: 39.06%] [G loss: 0.870777]\n",
      "epoch:24 step:18952[D loss: 0.438120, acc: 60.16%, op_acc: 39.06%] [G loss: 0.912690]\n",
      "epoch:24 step:18953[D loss: 0.413526, acc: 59.38%, op_acc: 43.75%] [G loss: 0.835257]\n",
      "epoch:24 step:18954[D loss: 0.458048, acc: 54.69%, op_acc: 37.50%] [G loss: 0.860266]\n",
      "epoch:24 step:18955[D loss: 0.417773, acc: 57.03%, op_acc: 45.31%] [G loss: 0.862345]\n",
      "epoch:24 step:18956[D loss: 0.407370, acc: 64.06%, op_acc: 43.75%] [G loss: 0.884170]\n",
      "epoch:24 step:18957[D loss: 0.426852, acc: 57.03%, op_acc: 41.41%] [G loss: 0.888064]\n",
      "epoch:24 step:18958[D loss: 0.431020, acc: 64.06%, op_acc: 35.16%] [G loss: 0.884833]\n",
      "epoch:24 step:18959[D loss: 0.458195, acc: 59.38%, op_acc: 31.25%] [G loss: 0.854486]\n",
      "epoch:24 step:18960[D loss: 0.429539, acc: 60.16%, op_acc: 36.72%] [G loss: 0.959804]\n",
      "epoch:24 step:18961[D loss: 0.388725, acc: 69.53%, op_acc: 39.84%] [G loss: 0.984006]\n",
      "epoch:24 step:18962[D loss: 0.431682, acc: 62.50%, op_acc: 42.19%] [G loss: 0.889738]\n",
      "epoch:24 step:18963[D loss: 0.415647, acc: 58.59%, op_acc: 38.28%] [G loss: 0.887697]\n",
      "epoch:24 step:18964[D loss: 0.421773, acc: 60.16%, op_acc: 40.62%] [G loss: 0.981747]\n",
      "epoch:24 step:18965[D loss: 0.432713, acc: 51.56%, op_acc: 42.19%] [G loss: 0.868426]\n",
      "epoch:24 step:18966[D loss: 0.428945, acc: 57.81%, op_acc: 42.19%] [G loss: 0.945404]\n",
      "epoch:24 step:18967[D loss: 0.431847, acc: 59.38%, op_acc: 39.06%] [G loss: 0.855977]\n",
      "epoch:24 step:18968[D loss: 0.415457, acc: 64.84%, op_acc: 39.06%] [G loss: 0.864697]\n",
      "epoch:24 step:18969[D loss: 0.446427, acc: 59.38%, op_acc: 37.50%] [G loss: 1.006310]\n",
      "epoch:24 step:18970[D loss: 0.438325, acc: 54.69%, op_acc: 36.72%] [G loss: 0.800932]\n",
      "epoch:24 step:18971[D loss: 0.434437, acc: 57.03%, op_acc: 35.16%] [G loss: 0.852786]\n",
      "epoch:24 step:18972[D loss: 0.434206, acc: 57.03%, op_acc: 40.62%] [G loss: 0.883078]\n",
      "epoch:24 step:18973[D loss: 0.469514, acc: 46.09%, op_acc: 38.28%] [G loss: 0.861327]\n",
      "epoch:24 step:18974[D loss: 0.433022, acc: 57.81%, op_acc: 36.72%] [G loss: 0.863046]\n",
      "epoch:24 step:18975[D loss: 0.415329, acc: 61.72%, op_acc: 42.19%] [G loss: 0.923022]\n",
      "epoch:24 step:18976[D loss: 0.432953, acc: 61.72%, op_acc: 37.50%] [G loss: 0.866687]\n",
      "epoch:24 step:18977[D loss: 0.414319, acc: 61.72%, op_acc: 39.84%] [G loss: 0.897528]\n",
      "epoch:24 step:18978[D loss: 0.428743, acc: 63.28%, op_acc: 37.50%] [G loss: 0.968989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18979[D loss: 0.400369, acc: 57.03%, op_acc: 45.31%] [G loss: 0.838603]\n",
      "epoch:24 step:18980[D loss: 0.431672, acc: 66.41%, op_acc: 35.94%] [G loss: 0.909188]\n",
      "epoch:24 step:18981[D loss: 0.396685, acc: 67.97%, op_acc: 37.50%] [G loss: 0.957136]\n",
      "epoch:24 step:18982[D loss: 0.448514, acc: 50.78%, op_acc: 41.41%] [G loss: 0.922302]\n",
      "epoch:24 step:18983[D loss: 0.398452, acc: 61.72%, op_acc: 40.62%] [G loss: 0.892600]\n",
      "epoch:24 step:18984[D loss: 0.428279, acc: 53.12%, op_acc: 37.50%] [G loss: 0.865399]\n",
      "epoch:24 step:18985[D loss: 0.440668, acc: 56.25%, op_acc: 42.19%] [G loss: 0.765103]\n",
      "epoch:24 step:18986[D loss: 0.409688, acc: 57.03%, op_acc: 42.97%] [G loss: 0.797322]\n",
      "epoch:24 step:18987[D loss: 0.417546, acc: 58.59%, op_acc: 39.84%] [G loss: 0.850679]\n",
      "epoch:24 step:18988[D loss: 0.449869, acc: 59.38%, op_acc: 35.94%] [G loss: 0.928921]\n",
      "epoch:24 step:18989[D loss: 0.418415, acc: 61.72%, op_acc: 38.28%] [G loss: 0.883386]\n",
      "epoch:24 step:18990[D loss: 0.450324, acc: 61.72%, op_acc: 32.03%] [G loss: 0.905833]\n",
      "epoch:24 step:18991[D loss: 0.450049, acc: 49.22%, op_acc: 34.38%] [G loss: 0.830375]\n",
      "epoch:24 step:18992[D loss: 0.449211, acc: 58.59%, op_acc: 36.72%] [G loss: 0.857888]\n",
      "epoch:24 step:18993[D loss: 0.441358, acc: 55.47%, op_acc: 40.62%] [G loss: 0.839222]\n",
      "epoch:24 step:18994[D loss: 0.458811, acc: 58.59%, op_acc: 34.38%] [G loss: 0.820599]\n",
      "epoch:24 step:18995[D loss: 0.379841, acc: 70.31%, op_acc: 45.31%] [G loss: 0.882263]\n",
      "epoch:24 step:18996[D loss: 0.429190, acc: 53.91%, op_acc: 40.62%] [G loss: 0.861181]\n",
      "epoch:24 step:18997[D loss: 0.419125, acc: 55.47%, op_acc: 38.28%] [G loss: 0.813382]\n",
      "epoch:24 step:18998[D loss: 0.433900, acc: 59.38%, op_acc: 31.25%] [G loss: 0.886014]\n",
      "epoch:24 step:18999[D loss: 0.433759, acc: 58.59%, op_acc: 40.62%] [G loss: 0.871376]\n",
      "epoch:24 step:19000[D loss: 0.411016, acc: 60.16%, op_acc: 38.28%] [G loss: 0.875792]\n",
      "##############\n",
      "[0.84735509 0.86481166 0.81843047 0.79643788 0.8020993  0.84003014\n",
      " 0.88501248 0.84722883 0.77913189 0.83314798]\n",
      "##########\n",
      "epoch:24 step:19001[D loss: 0.441380, acc: 57.03%, op_acc: 35.16%] [G loss: 0.817546]\n",
      "epoch:24 step:19002[D loss: 0.431918, acc: 57.81%, op_acc: 39.06%] [G loss: 0.875671]\n",
      "epoch:24 step:19003[D loss: 0.443377, acc: 53.91%, op_acc: 34.38%] [G loss: 0.952707]\n",
      "epoch:24 step:19004[D loss: 0.432799, acc: 60.94%, op_acc: 34.38%] [G loss: 0.875648]\n",
      "epoch:24 step:19005[D loss: 0.408470, acc: 57.03%, op_acc: 40.62%] [G loss: 0.896945]\n",
      "epoch:24 step:19006[D loss: 0.421353, acc: 64.06%, op_acc: 40.62%] [G loss: 0.821904]\n",
      "epoch:24 step:19007[D loss: 0.429199, acc: 57.81%, op_acc: 37.50%] [G loss: 0.877528]\n",
      "epoch:24 step:19008[D loss: 0.420503, acc: 66.41%, op_acc: 36.72%] [G loss: 0.899336]\n",
      "epoch:24 step:19009[D loss: 0.389517, acc: 66.41%, op_acc: 44.53%] [G loss: 0.882891]\n",
      "epoch:24 step:19010[D loss: 0.421188, acc: 55.47%, op_acc: 43.75%] [G loss: 0.884426]\n",
      "epoch:24 step:19011[D loss: 0.439394, acc: 61.72%, op_acc: 36.72%] [G loss: 0.881572]\n",
      "epoch:24 step:19012[D loss: 0.407362, acc: 67.19%, op_acc: 42.19%] [G loss: 0.849314]\n",
      "epoch:24 step:19013[D loss: 0.423506, acc: 51.56%, op_acc: 43.75%] [G loss: 0.887383]\n",
      "epoch:24 step:19014[D loss: 0.445630, acc: 57.03%, op_acc: 39.06%] [G loss: 0.827751]\n",
      "epoch:24 step:19015[D loss: 0.412597, acc: 62.50%, op_acc: 38.28%] [G loss: 0.827600]\n",
      "epoch:24 step:19016[D loss: 0.410970, acc: 69.53%, op_acc: 37.50%] [G loss: 0.862130]\n",
      "epoch:24 step:19017[D loss: 0.432353, acc: 52.34%, op_acc: 46.09%] [G loss: 0.842016]\n",
      "epoch:24 step:19018[D loss: 0.420923, acc: 59.38%, op_acc: 41.41%] [G loss: 0.841842]\n",
      "epoch:24 step:19019[D loss: 0.404250, acc: 65.62%, op_acc: 42.97%] [G loss: 0.897021]\n",
      "epoch:24 step:19020[D loss: 0.447869, acc: 43.75%, op_acc: 38.28%] [G loss: 0.867560]\n",
      "epoch:24 step:19021[D loss: 0.412745, acc: 64.06%, op_acc: 37.50%] [G loss: 0.894240]\n",
      "epoch:24 step:19022[D loss: 0.465653, acc: 50.00%, op_acc: 35.16%] [G loss: 0.876503]\n",
      "epoch:24 step:19023[D loss: 0.421974, acc: 59.38%, op_acc: 41.41%] [G loss: 0.857601]\n",
      "epoch:24 step:19024[D loss: 0.431152, acc: 56.25%, op_acc: 39.06%] [G loss: 0.878259]\n",
      "epoch:24 step:19025[D loss: 0.438621, acc: 55.47%, op_acc: 35.94%] [G loss: 0.837582]\n",
      "epoch:24 step:19026[D loss: 0.434484, acc: 58.59%, op_acc: 38.28%] [G loss: 0.840606]\n",
      "epoch:24 step:19027[D loss: 0.391261, acc: 65.62%, op_acc: 42.97%] [G loss: 0.854402]\n",
      "epoch:24 step:19028[D loss: 0.433630, acc: 56.25%, op_acc: 37.50%] [G loss: 0.859035]\n",
      "epoch:24 step:19029[D loss: 0.420718, acc: 62.50%, op_acc: 39.06%] [G loss: 0.872184]\n",
      "epoch:24 step:19030[D loss: 0.441294, acc: 60.16%, op_acc: 42.19%] [G loss: 0.854117]\n",
      "epoch:24 step:19031[D loss: 0.451726, acc: 51.56%, op_acc: 39.84%] [G loss: 0.818689]\n",
      "epoch:24 step:19032[D loss: 0.402070, acc: 64.84%, op_acc: 42.19%] [G loss: 0.909332]\n",
      "epoch:24 step:19033[D loss: 0.457698, acc: 54.69%, op_acc: 34.38%] [G loss: 0.893556]\n",
      "epoch:24 step:19034[D loss: 0.424058, acc: 60.94%, op_acc: 35.16%] [G loss: 0.861844]\n",
      "epoch:24 step:19035[D loss: 0.411723, acc: 62.50%, op_acc: 41.41%] [G loss: 0.842177]\n",
      "epoch:24 step:19036[D loss: 0.439154, acc: 57.03%, op_acc: 35.94%] [G loss: 0.922913]\n",
      "epoch:24 step:19037[D loss: 0.405796, acc: 60.94%, op_acc: 41.41%] [G loss: 0.912087]\n",
      "epoch:24 step:19038[D loss: 0.434165, acc: 65.62%, op_acc: 35.16%] [G loss: 0.871853]\n",
      "epoch:24 step:19039[D loss: 0.436408, acc: 56.25%, op_acc: 42.97%] [G loss: 0.890616]\n",
      "epoch:24 step:19040[D loss: 0.421903, acc: 57.03%, op_acc: 40.62%] [G loss: 0.807274]\n",
      "epoch:24 step:19041[D loss: 0.435919, acc: 54.69%, op_acc: 32.03%] [G loss: 0.931671]\n",
      "epoch:24 step:19042[D loss: 0.421281, acc: 64.84%, op_acc: 37.50%] [G loss: 0.987208]\n",
      "epoch:24 step:19043[D loss: 0.405171, acc: 60.94%, op_acc: 44.53%] [G loss: 0.895701]\n",
      "epoch:24 step:19044[D loss: 0.436658, acc: 53.91%, op_acc: 42.19%] [G loss: 0.922827]\n",
      "epoch:24 step:19045[D loss: 0.416019, acc: 61.72%, op_acc: 39.06%] [G loss: 0.842626]\n",
      "epoch:24 step:19046[D loss: 0.437381, acc: 51.56%, op_acc: 38.28%] [G loss: 0.845194]\n",
      "epoch:24 step:19047[D loss: 0.425537, acc: 62.50%, op_acc: 43.75%] [G loss: 0.845659]\n",
      "epoch:24 step:19048[D loss: 0.427877, acc: 63.28%, op_acc: 36.72%] [G loss: 0.917885]\n",
      "epoch:24 step:19049[D loss: 0.417915, acc: 58.59%, op_acc: 39.06%] [G loss: 0.860298]\n",
      "epoch:24 step:19050[D loss: 0.442713, acc: 60.94%, op_acc: 37.50%] [G loss: 0.924344]\n",
      "##############\n",
      "[0.85596903 0.85716377 0.80642425 0.80854947 0.7735629  0.8396177\n",
      " 0.88068589 0.81113732 0.80652301 0.82162991]\n",
      "##########\n",
      "epoch:24 step:19051[D loss: 0.426967, acc: 61.72%, op_acc: 39.84%] [G loss: 0.912095]\n",
      "epoch:24 step:19052[D loss: 0.422823, acc: 59.38%, op_acc: 39.06%] [G loss: 0.913572]\n",
      "epoch:24 step:19053[D loss: 0.460741, acc: 56.25%, op_acc: 32.81%] [G loss: 0.869288]\n",
      "epoch:24 step:19054[D loss: 0.444005, acc: 58.59%, op_acc: 38.28%] [G loss: 0.901289]\n",
      "epoch:24 step:19055[D loss: 0.432069, acc: 57.03%, op_acc: 43.75%] [G loss: 0.946239]\n",
      "epoch:24 step:19056[D loss: 0.416359, acc: 60.94%, op_acc: 36.72%] [G loss: 0.939428]\n",
      "epoch:24 step:19057[D loss: 0.441756, acc: 55.47%, op_acc: 41.41%] [G loss: 0.898292]\n",
      "epoch:24 step:19058[D loss: 0.446506, acc: 59.38%, op_acc: 37.50%] [G loss: 0.892952]\n",
      "epoch:24 step:19059[D loss: 0.428390, acc: 57.81%, op_acc: 38.28%] [G loss: 0.915987]\n",
      "epoch:24 step:19060[D loss: 0.443180, acc: 50.78%, op_acc: 38.28%] [G loss: 0.866694]\n",
      "epoch:24 step:19061[D loss: 0.412855, acc: 60.94%, op_acc: 42.19%] [G loss: 0.890677]\n",
      "epoch:24 step:19062[D loss: 0.448936, acc: 55.47%, op_acc: 33.59%] [G loss: 0.781899]\n",
      "epoch:24 step:19063[D loss: 0.425805, acc: 50.78%, op_acc: 44.53%] [G loss: 0.814753]\n",
      "epoch:24 step:19064[D loss: 0.416899, acc: 60.94%, op_acc: 39.06%] [G loss: 0.912085]\n",
      "epoch:24 step:19065[D loss: 0.449549, acc: 57.03%, op_acc: 41.41%] [G loss: 0.869896]\n",
      "epoch:24 step:19066[D loss: 0.441088, acc: 53.91%, op_acc: 39.84%] [G loss: 0.835990]\n",
      "epoch:24 step:19067[D loss: 0.407926, acc: 60.94%, op_acc: 39.06%] [G loss: 0.857026]\n",
      "epoch:24 step:19068[D loss: 0.430547, acc: 60.16%, op_acc: 35.16%] [G loss: 0.891598]\n",
      "epoch:24 step:19069[D loss: 0.429075, acc: 60.16%, op_acc: 37.50%] [G loss: 0.860294]\n",
      "epoch:24 step:19070[D loss: 0.424944, acc: 57.03%, op_acc: 39.06%] [G loss: 0.877195]\n",
      "epoch:24 step:19071[D loss: 0.449557, acc: 50.00%, op_acc: 35.16%] [G loss: 0.775567]\n",
      "epoch:24 step:19072[D loss: 0.438466, acc: 55.47%, op_acc: 37.50%] [G loss: 0.892163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19073[D loss: 0.438654, acc: 53.12%, op_acc: 35.94%] [G loss: 0.893330]\n",
      "epoch:24 step:19074[D loss: 0.400227, acc: 65.62%, op_acc: 40.62%] [G loss: 0.882811]\n",
      "epoch:24 step:19075[D loss: 0.421542, acc: 59.38%, op_acc: 36.72%] [G loss: 0.908395]\n",
      "epoch:24 step:19076[D loss: 0.394967, acc: 64.84%, op_acc: 42.97%] [G loss: 0.861676]\n",
      "epoch:24 step:19077[D loss: 0.428268, acc: 64.06%, op_acc: 38.28%] [G loss: 0.885409]\n",
      "epoch:24 step:19078[D loss: 0.417655, acc: 54.69%, op_acc: 46.09%] [G loss: 0.913350]\n",
      "epoch:24 step:19079[D loss: 0.440646, acc: 57.81%, op_acc: 35.94%] [G loss: 0.829452]\n",
      "epoch:24 step:19080[D loss: 0.446263, acc: 52.34%, op_acc: 39.84%] [G loss: 0.802074]\n",
      "epoch:24 step:19081[D loss: 0.456277, acc: 55.47%, op_acc: 34.38%] [G loss: 0.817454]\n",
      "epoch:24 step:19082[D loss: 0.389365, acc: 60.16%, op_acc: 43.75%] [G loss: 0.980818]\n",
      "epoch:24 step:19083[D loss: 0.418029, acc: 62.50%, op_acc: 38.28%] [G loss: 0.884372]\n",
      "epoch:24 step:19084[D loss: 0.434928, acc: 60.94%, op_acc: 35.94%] [G loss: 0.878340]\n",
      "epoch:24 step:19085[D loss: 0.458504, acc: 55.47%, op_acc: 31.25%] [G loss: 0.817694]\n",
      "epoch:24 step:19086[D loss: 0.438631, acc: 55.47%, op_acc: 37.50%] [G loss: 0.828552]\n",
      "epoch:24 step:19087[D loss: 0.435529, acc: 56.25%, op_acc: 39.84%] [G loss: 0.879519]\n",
      "epoch:24 step:19088[D loss: 0.434799, acc: 59.38%, op_acc: 31.25%] [G loss: 0.881936]\n",
      "epoch:24 step:19089[D loss: 0.425696, acc: 61.72%, op_acc: 35.16%] [G loss: 0.939085]\n",
      "epoch:24 step:19090[D loss: 0.408574, acc: 67.19%, op_acc: 37.50%] [G loss: 0.852256]\n",
      "epoch:24 step:19091[D loss: 0.412663, acc: 57.03%, op_acc: 35.94%] [G loss: 0.968786]\n",
      "epoch:24 step:19092[D loss: 0.396777, acc: 69.53%, op_acc: 40.62%] [G loss: 0.948790]\n",
      "epoch:24 step:19093[D loss: 0.408812, acc: 60.16%, op_acc: 44.53%] [G loss: 0.947598]\n",
      "epoch:24 step:19094[D loss: 0.397420, acc: 68.75%, op_acc: 41.41%] [G loss: 0.934002]\n",
      "epoch:24 step:19095[D loss: 0.437779, acc: 57.03%, op_acc: 39.06%] [G loss: 0.891191]\n",
      "epoch:24 step:19096[D loss: 0.433554, acc: 63.28%, op_acc: 33.59%] [G loss: 0.890463]\n",
      "epoch:24 step:19097[D loss: 0.409830, acc: 59.38%, op_acc: 45.31%] [G loss: 0.889905]\n",
      "epoch:24 step:19098[D loss: 0.457706, acc: 52.34%, op_acc: 35.94%] [G loss: 0.884792]\n",
      "epoch:24 step:19099[D loss: 0.448285, acc: 55.47%, op_acc: 36.72%] [G loss: 0.917420]\n",
      "epoch:24 step:19100[D loss: 0.427307, acc: 64.06%, op_acc: 33.59%] [G loss: 0.869863]\n",
      "##############\n",
      "[0.84928873 0.87609906 0.79672584 0.82059216 0.78661922 0.82513988\n",
      " 0.86431763 0.82459958 0.83367089 0.83305317]\n",
      "##########\n",
      "epoch:24 step:19101[D loss: 0.419754, acc: 65.62%, op_acc: 34.38%] [G loss: 0.824711]\n",
      "epoch:24 step:19102[D loss: 0.448501, acc: 51.56%, op_acc: 41.41%] [G loss: 0.796624]\n",
      "epoch:24 step:19103[D loss: 0.412202, acc: 60.94%, op_acc: 39.84%] [G loss: 0.883160]\n",
      "epoch:24 step:19104[D loss: 0.411335, acc: 67.97%, op_acc: 36.72%] [G loss: 0.867860]\n",
      "epoch:24 step:19105[D loss: 0.426341, acc: 56.25%, op_acc: 41.41%] [G loss: 0.872693]\n",
      "epoch:24 step:19106[D loss: 0.407799, acc: 65.62%, op_acc: 41.41%] [G loss: 0.839789]\n",
      "epoch:24 step:19107[D loss: 0.437054, acc: 60.16%, op_acc: 37.50%] [G loss: 0.936007]\n",
      "epoch:24 step:19108[D loss: 0.423295, acc: 57.81%, op_acc: 40.62%] [G loss: 0.875403]\n",
      "epoch:24 step:19109[D loss: 0.409282, acc: 60.16%, op_acc: 43.75%] [G loss: 0.892992]\n",
      "epoch:24 step:19110[D loss: 0.415626, acc: 53.12%, op_acc: 46.88%] [G loss: 0.907839]\n",
      "epoch:24 step:19111[D loss: 0.462192, acc: 52.34%, op_acc: 36.72%] [G loss: 0.820208]\n",
      "epoch:24 step:19112[D loss: 0.445483, acc: 57.81%, op_acc: 34.38%] [G loss: 0.815787]\n",
      "epoch:24 step:19113[D loss: 0.431687, acc: 49.22%, op_acc: 36.72%] [G loss: 0.895932]\n",
      "epoch:24 step:19114[D loss: 0.458317, acc: 50.78%, op_acc: 39.06%] [G loss: 0.773862]\n",
      "epoch:24 step:19115[D loss: 0.404244, acc: 58.59%, op_acc: 47.66%] [G loss: 0.885379]\n",
      "epoch:24 step:19116[D loss: 0.421912, acc: 60.16%, op_acc: 39.84%] [G loss: 0.931656]\n",
      "epoch:24 step:19117[D loss: 0.413360, acc: 60.16%, op_acc: 44.53%] [G loss: 0.853180]\n",
      "epoch:24 step:19118[D loss: 0.408984, acc: 67.19%, op_acc: 40.62%] [G loss: 0.946239]\n",
      "epoch:24 step:19119[D loss: 0.423045, acc: 61.72%, op_acc: 38.28%] [G loss: 0.962910]\n",
      "epoch:24 step:19120[D loss: 0.378983, acc: 64.06%, op_acc: 42.97%] [G loss: 0.978316]\n",
      "epoch:24 step:19121[D loss: 0.427196, acc: 54.69%, op_acc: 39.06%] [G loss: 0.840833]\n",
      "epoch:24 step:19122[D loss: 0.397686, acc: 68.75%, op_acc: 43.75%] [G loss: 0.907711]\n",
      "epoch:24 step:19123[D loss: 0.417705, acc: 60.16%, op_acc: 44.53%] [G loss: 0.914062]\n",
      "epoch:24 step:19124[D loss: 0.443251, acc: 52.34%, op_acc: 40.62%] [G loss: 0.850694]\n",
      "epoch:24 step:19125[D loss: 0.422021, acc: 64.06%, op_acc: 38.28%] [G loss: 0.870314]\n",
      "epoch:24 step:19126[D loss: 0.429799, acc: 58.59%, op_acc: 38.28%] [G loss: 0.915361]\n",
      "epoch:24 step:19127[D loss: 0.430765, acc: 54.69%, op_acc: 39.84%] [G loss: 0.816919]\n",
      "epoch:24 step:19128[D loss: 0.423705, acc: 61.72%, op_acc: 37.50%] [G loss: 0.832015]\n",
      "epoch:24 step:19129[D loss: 0.431592, acc: 56.25%, op_acc: 35.94%] [G loss: 0.803771]\n",
      "epoch:24 step:19130[D loss: 0.415304, acc: 61.72%, op_acc: 39.06%] [G loss: 0.909084]\n",
      "epoch:24 step:19131[D loss: 0.435418, acc: 59.38%, op_acc: 42.97%] [G loss: 0.852431]\n",
      "epoch:24 step:19132[D loss: 0.449093, acc: 60.94%, op_acc: 38.28%] [G loss: 0.870057]\n",
      "epoch:24 step:19133[D loss: 0.423572, acc: 57.81%, op_acc: 35.94%] [G loss: 0.851792]\n",
      "epoch:24 step:19134[D loss: 0.414361, acc: 59.38%, op_acc: 42.97%] [G loss: 0.820663]\n",
      "epoch:24 step:19135[D loss: 0.429500, acc: 55.47%, op_acc: 39.84%] [G loss: 0.893093]\n",
      "epoch:24 step:19136[D loss: 0.421035, acc: 53.12%, op_acc: 41.41%] [G loss: 0.761849]\n",
      "epoch:24 step:19137[D loss: 0.447885, acc: 51.56%, op_acc: 36.72%] [G loss: 0.858107]\n",
      "epoch:24 step:19138[D loss: 0.430882, acc: 60.16%, op_acc: 38.28%] [G loss: 0.932720]\n",
      "epoch:24 step:19139[D loss: 0.441252, acc: 53.91%, op_acc: 35.16%] [G loss: 0.900105]\n",
      "epoch:24 step:19140[D loss: 0.417094, acc: 58.59%, op_acc: 43.75%] [G loss: 0.855275]\n",
      "epoch:24 step:19141[D loss: 0.409274, acc: 64.06%, op_acc: 45.31%] [G loss: 0.849575]\n",
      "epoch:24 step:19142[D loss: 0.408135, acc: 64.06%, op_acc: 38.28%] [G loss: 0.926530]\n",
      "epoch:24 step:19143[D loss: 0.409441, acc: 57.81%, op_acc: 39.84%] [G loss: 0.893286]\n",
      "epoch:24 step:19144[D loss: 0.414937, acc: 66.41%, op_acc: 36.72%] [G loss: 0.830296]\n",
      "epoch:24 step:19145[D loss: 0.426109, acc: 60.94%, op_acc: 39.84%] [G loss: 0.807579]\n",
      "epoch:24 step:19146[D loss: 0.405515, acc: 66.41%, op_acc: 39.84%] [G loss: 0.850771]\n",
      "epoch:24 step:19147[D loss: 0.419102, acc: 62.50%, op_acc: 42.19%] [G loss: 0.890649]\n",
      "epoch:24 step:19148[D loss: 0.402764, acc: 62.50%, op_acc: 40.62%] [G loss: 0.948692]\n",
      "epoch:24 step:19149[D loss: 0.438911, acc: 60.94%, op_acc: 38.28%] [G loss: 0.985284]\n",
      "epoch:24 step:19150[D loss: 0.445293, acc: 51.56%, op_acc: 40.62%] [G loss: 0.855672]\n",
      "##############\n",
      "[0.860962   0.87361737 0.80863257 0.80755202 0.79684292 0.84182602\n",
      " 0.89915316 0.83225531 0.81932533 0.83274421]\n",
      "##########\n",
      "epoch:24 step:19151[D loss: 0.408252, acc: 67.19%, op_acc: 35.16%] [G loss: 0.924855]\n",
      "epoch:24 step:19152[D loss: 0.410157, acc: 57.03%, op_acc: 42.19%] [G loss: 0.851248]\n",
      "epoch:24 step:19153[D loss: 0.410431, acc: 64.06%, op_acc: 46.09%] [G loss: 0.875528]\n",
      "epoch:24 step:19154[D loss: 0.410107, acc: 64.06%, op_acc: 39.06%] [G loss: 0.839925]\n",
      "epoch:24 step:19155[D loss: 0.435328, acc: 58.59%, op_acc: 39.06%] [G loss: 0.865328]\n",
      "epoch:24 step:19156[D loss: 0.416835, acc: 61.72%, op_acc: 39.84%] [G loss: 0.830811]\n",
      "epoch:24 step:19157[D loss: 0.426655, acc: 60.16%, op_acc: 35.16%] [G loss: 0.905147]\n",
      "epoch:24 step:19158[D loss: 0.424290, acc: 57.03%, op_acc: 42.97%] [G loss: 0.837702]\n",
      "epoch:24 step:19159[D loss: 0.436419, acc: 55.47%, op_acc: 41.41%] [G loss: 0.823679]\n",
      "epoch:24 step:19160[D loss: 0.427710, acc: 62.50%, op_acc: 37.50%] [G loss: 0.859070]\n",
      "epoch:24 step:19161[D loss: 0.447726, acc: 58.59%, op_acc: 39.06%] [G loss: 0.886436]\n",
      "epoch:24 step:19162[D loss: 0.437696, acc: 63.28%, op_acc: 32.03%] [G loss: 1.002430]\n",
      "epoch:24 step:19163[D loss: 0.434357, acc: 57.81%, op_acc: 42.97%] [G loss: 0.955131]\n",
      "epoch:24 step:19164[D loss: 0.457999, acc: 47.66%, op_acc: 33.59%] [G loss: 0.864728]\n",
      "epoch:24 step:19165[D loss: 0.436081, acc: 64.84%, op_acc: 37.50%] [G loss: 0.858931]\n",
      "epoch:24 step:19166[D loss: 0.406708, acc: 64.84%, op_acc: 42.97%] [G loss: 0.871824]\n",
      "epoch:24 step:19167[D loss: 0.411601, acc: 65.62%, op_acc: 39.84%] [G loss: 0.908019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19168[D loss: 0.441858, acc: 56.25%, op_acc: 34.38%] [G loss: 0.956597]\n",
      "epoch:24 step:19169[D loss: 0.444101, acc: 57.03%, op_acc: 39.06%] [G loss: 0.932780]\n",
      "epoch:24 step:19170[D loss: 0.428271, acc: 59.38%, op_acc: 41.41%] [G loss: 0.982414]\n",
      "epoch:24 step:19171[D loss: 0.383797, acc: 67.97%, op_acc: 45.31%] [G loss: 0.989019]\n",
      "epoch:24 step:19172[D loss: 0.444402, acc: 57.03%, op_acc: 36.72%] [G loss: 0.877828]\n",
      "epoch:24 step:19173[D loss: 0.414355, acc: 58.59%, op_acc: 39.84%] [G loss: 0.830774]\n",
      "epoch:24 step:19174[D loss: 0.407674, acc: 62.50%, op_acc: 40.62%] [G loss: 0.859110]\n",
      "epoch:24 step:19175[D loss: 0.433173, acc: 57.03%, op_acc: 38.28%] [G loss: 0.896610]\n",
      "epoch:24 step:19176[D loss: 0.415008, acc: 56.25%, op_acc: 42.19%] [G loss: 0.915734]\n",
      "epoch:24 step:19177[D loss: 0.431485, acc: 58.59%, op_acc: 39.06%] [G loss: 0.913837]\n",
      "epoch:24 step:19178[D loss: 0.397845, acc: 68.75%, op_acc: 35.94%] [G loss: 0.937068]\n",
      "epoch:24 step:19179[D loss: 0.422334, acc: 61.72%, op_acc: 39.84%] [G loss: 0.903596]\n",
      "epoch:24 step:19180[D loss: 0.431557, acc: 59.38%, op_acc: 36.72%] [G loss: 0.804287]\n",
      "epoch:24 step:19181[D loss: 0.423408, acc: 62.50%, op_acc: 37.50%] [G loss: 0.877556]\n",
      "epoch:24 step:19182[D loss: 0.423519, acc: 58.59%, op_acc: 39.84%] [G loss: 0.879341]\n",
      "epoch:24 step:19183[D loss: 0.430132, acc: 53.91%, op_acc: 40.62%] [G loss: 0.816425]\n",
      "epoch:24 step:19184[D loss: 0.426183, acc: 58.59%, op_acc: 39.84%] [G loss: 0.893637]\n",
      "epoch:24 step:19185[D loss: 0.446192, acc: 52.34%, op_acc: 41.41%] [G loss: 0.860589]\n",
      "epoch:24 step:19186[D loss: 0.413176, acc: 58.59%, op_acc: 42.19%] [G loss: 0.856766]\n",
      "epoch:24 step:19187[D loss: 0.434659, acc: 54.69%, op_acc: 35.94%] [G loss: 0.900851]\n",
      "epoch:24 step:19188[D loss: 0.415594, acc: 57.81%, op_acc: 39.06%] [G loss: 0.925092]\n",
      "epoch:24 step:19189[D loss: 0.442401, acc: 57.03%, op_acc: 29.69%] [G loss: 0.813312]\n",
      "epoch:24 step:19190[D loss: 0.426255, acc: 64.84%, op_acc: 37.50%] [G loss: 1.008143]\n",
      "epoch:24 step:19191[D loss: 0.455815, acc: 50.78%, op_acc: 36.72%] [G loss: 0.879539]\n",
      "epoch:24 step:19192[D loss: 0.420832, acc: 58.59%, op_acc: 39.84%] [G loss: 0.903846]\n",
      "epoch:24 step:19193[D loss: 0.406645, acc: 65.62%, op_acc: 38.28%] [G loss: 0.921417]\n",
      "epoch:24 step:19194[D loss: 0.422564, acc: 59.38%, op_acc: 38.28%] [G loss: 0.877570]\n",
      "epoch:24 step:19195[D loss: 0.422726, acc: 53.91%, op_acc: 39.84%] [G loss: 0.891798]\n",
      "epoch:24 step:19196[D loss: 0.393948, acc: 64.06%, op_acc: 37.50%] [G loss: 0.908317]\n",
      "epoch:24 step:19197[D loss: 0.411815, acc: 59.38%, op_acc: 39.06%] [G loss: 0.889472]\n",
      "epoch:24 step:19198[D loss: 0.419065, acc: 60.16%, op_acc: 39.06%] [G loss: 0.891067]\n",
      "epoch:24 step:19199[D loss: 0.418770, acc: 63.28%, op_acc: 42.19%] [G loss: 0.892706]\n",
      "epoch:24 step:19200[D loss: 0.431156, acc: 63.28%, op_acc: 38.28%] [G loss: 0.972771]\n",
      "##############\n",
      "[0.86037057 0.85358081 0.82027284 0.81360345 0.78064612 0.82651175\n",
      " 0.88830717 0.82636648 0.81345499 0.80585112]\n",
      "##########\n",
      "epoch:24 step:19201[D loss: 0.416071, acc: 62.50%, op_acc: 35.94%] [G loss: 0.841104]\n",
      "epoch:24 step:19202[D loss: 0.410727, acc: 62.50%, op_acc: 44.53%] [G loss: 0.890018]\n",
      "epoch:24 step:19203[D loss: 0.410503, acc: 57.03%, op_acc: 43.75%] [G loss: 0.901103]\n",
      "epoch:24 step:19204[D loss: 0.409303, acc: 57.03%, op_acc: 38.28%] [G loss: 0.801057]\n",
      "epoch:24 step:19205[D loss: 0.443881, acc: 55.47%, op_acc: 33.59%] [G loss: 0.873616]\n",
      "epoch:24 step:19206[D loss: 0.441068, acc: 48.44%, op_acc: 35.94%] [G loss: 0.859240]\n",
      "epoch:24 step:19207[D loss: 0.431175, acc: 54.69%, op_acc: 43.75%] [G loss: 0.825809]\n",
      "epoch:24 step:19208[D loss: 0.425210, acc: 63.28%, op_acc: 34.38%] [G loss: 0.837705]\n",
      "epoch:24 step:19209[D loss: 0.436348, acc: 57.03%, op_acc: 35.94%] [G loss: 0.826470]\n",
      "epoch:24 step:19210[D loss: 0.415636, acc: 59.38%, op_acc: 34.38%] [G loss: 0.897819]\n",
      "epoch:24 step:19211[D loss: 0.431374, acc: 58.59%, op_acc: 39.06%] [G loss: 0.886314]\n",
      "epoch:24 step:19212[D loss: 0.423758, acc: 61.72%, op_acc: 40.62%] [G loss: 0.906051]\n",
      "epoch:24 step:19213[D loss: 0.409422, acc: 61.72%, op_acc: 39.06%] [G loss: 0.862283]\n",
      "epoch:24 step:19214[D loss: 0.406736, acc: 57.03%, op_acc: 43.75%] [G loss: 0.907469]\n",
      "epoch:24 step:19215[D loss: 0.435165, acc: 62.50%, op_acc: 34.38%] [G loss: 0.978687]\n",
      "epoch:24 step:19216[D loss: 0.442831, acc: 60.16%, op_acc: 36.72%] [G loss: 0.888203]\n",
      "epoch:24 step:19217[D loss: 0.390251, acc: 64.84%, op_acc: 45.31%] [G loss: 0.959405]\n",
      "epoch:24 step:19218[D loss: 0.446999, acc: 50.78%, op_acc: 40.62%] [G loss: 0.904484]\n",
      "epoch:24 step:19219[D loss: 0.435756, acc: 48.44%, op_acc: 45.31%] [G loss: 0.924017]\n",
      "epoch:24 step:19220[D loss: 0.426875, acc: 60.16%, op_acc: 39.84%] [G loss: 0.902258]\n",
      "epoch:24 step:19221[D loss: 0.424511, acc: 61.72%, op_acc: 33.59%] [G loss: 0.913138]\n",
      "epoch:24 step:19222[D loss: 0.381183, acc: 67.97%, op_acc: 39.06%] [G loss: 0.885569]\n",
      "epoch:24 step:19223[D loss: 0.421586, acc: 66.41%, op_acc: 39.06%] [G loss: 0.868631]\n",
      "epoch:24 step:19224[D loss: 0.429590, acc: 62.50%, op_acc: 41.41%] [G loss: 0.851255]\n",
      "epoch:24 step:19225[D loss: 0.462962, acc: 57.81%, op_acc: 32.03%] [G loss: 0.892985]\n",
      "epoch:24 step:19226[D loss: 0.410136, acc: 62.50%, op_acc: 38.28%] [G loss: 0.887320]\n",
      "epoch:24 step:19227[D loss: 0.410773, acc: 63.28%, op_acc: 42.19%] [G loss: 0.854828]\n",
      "epoch:24 step:19228[D loss: 0.414206, acc: 62.50%, op_acc: 40.62%] [G loss: 1.000584]\n",
      "epoch:24 step:19229[D loss: 0.420089, acc: 63.28%, op_acc: 38.28%] [G loss: 0.804809]\n",
      "epoch:24 step:19230[D loss: 0.414123, acc: 57.03%, op_acc: 42.19%] [G loss: 0.974640]\n",
      "epoch:24 step:19231[D loss: 0.411723, acc: 64.06%, op_acc: 40.62%] [G loss: 0.939373]\n",
      "epoch:24 step:19232[D loss: 0.458629, acc: 55.47%, op_acc: 33.59%] [G loss: 0.895703]\n",
      "epoch:24 step:19233[D loss: 0.433349, acc: 61.72%, op_acc: 36.72%] [G loss: 0.866822]\n",
      "epoch:24 step:19234[D loss: 0.393376, acc: 65.62%, op_acc: 40.62%] [G loss: 0.937938]\n",
      "epoch:24 step:19235[D loss: 0.434964, acc: 61.72%, op_acc: 33.59%] [G loss: 0.889765]\n",
      "epoch:24 step:19236[D loss: 0.404483, acc: 60.16%, op_acc: 45.31%] [G loss: 0.812827]\n",
      "epoch:24 step:19237[D loss: 0.412086, acc: 61.72%, op_acc: 40.62%] [G loss: 0.826640]\n",
      "epoch:24 step:19238[D loss: 0.402668, acc: 63.28%, op_acc: 42.97%] [G loss: 0.837486]\n",
      "epoch:24 step:19239[D loss: 0.423763, acc: 64.06%, op_acc: 38.28%] [G loss: 0.844951]\n",
      "epoch:24 step:19240[D loss: 0.416550, acc: 62.50%, op_acc: 38.28%] [G loss: 0.860324]\n",
      "epoch:24 step:19241[D loss: 0.411786, acc: 58.59%, op_acc: 39.84%] [G loss: 0.875317]\n",
      "epoch:24 step:19242[D loss: 0.441149, acc: 58.59%, op_acc: 35.94%] [G loss: 0.876638]\n",
      "epoch:24 step:19243[D loss: 0.431361, acc: 58.59%, op_acc: 44.53%] [G loss: 1.037169]\n",
      "epoch:24 step:19244[D loss: 0.436843, acc: 56.25%, op_acc: 37.50%] [G loss: 0.872207]\n",
      "epoch:24 step:19245[D loss: 0.422216, acc: 59.38%, op_acc: 38.28%] [G loss: 0.874190]\n",
      "epoch:24 step:19246[D loss: 0.417509, acc: 57.03%, op_acc: 39.06%] [G loss: 0.813194]\n",
      "epoch:24 step:19247[D loss: 0.421131, acc: 57.81%, op_acc: 36.72%] [G loss: 0.909269]\n",
      "epoch:24 step:19248[D loss: 0.430160, acc: 59.38%, op_acc: 39.06%] [G loss: 0.902508]\n",
      "epoch:24 step:19249[D loss: 0.424620, acc: 62.50%, op_acc: 39.06%] [G loss: 0.928862]\n",
      "epoch:24 step:19250[D loss: 0.452731, acc: 53.12%, op_acc: 40.62%] [G loss: 0.878177]\n",
      "##############\n",
      "[0.85749133 0.84750233 0.81406995 0.82718968 0.78676233 0.83212328\n",
      " 0.89481656 0.82978093 0.82523717 0.82596654]\n",
      "##########\n",
      "epoch:24 step:19251[D loss: 0.421519, acc: 56.25%, op_acc: 40.62%] [G loss: 0.835386]\n",
      "epoch:24 step:19252[D loss: 0.400755, acc: 60.16%, op_acc: 43.75%] [G loss: 0.860269]\n",
      "epoch:24 step:19253[D loss: 0.407017, acc: 61.72%, op_acc: 44.53%] [G loss: 0.962835]\n",
      "epoch:24 step:19254[D loss: 0.400848, acc: 70.31%, op_acc: 39.06%] [G loss: 0.841934]\n",
      "epoch:24 step:19255[D loss: 0.418495, acc: 60.94%, op_acc: 42.19%] [G loss: 0.911674]\n",
      "epoch:24 step:19256[D loss: 0.432023, acc: 60.16%, op_acc: 39.84%] [G loss: 0.914091]\n",
      "epoch:24 step:19257[D loss: 0.442932, acc: 57.03%, op_acc: 35.94%] [G loss: 0.892020]\n",
      "epoch:24 step:19258[D loss: 0.432027, acc: 57.03%, op_acc: 37.50%] [G loss: 0.883608]\n",
      "epoch:24 step:19259[D loss: 0.466291, acc: 48.44%, op_acc: 36.72%] [G loss: 0.868386]\n",
      "epoch:24 step:19260[D loss: 0.439111, acc: 53.91%, op_acc: 36.72%] [G loss: 0.787694]\n",
      "epoch:24 step:19261[D loss: 0.443435, acc: 64.06%, op_acc: 36.72%] [G loss: 0.842634]\n",
      "epoch:24 step:19262[D loss: 0.414944, acc: 58.59%, op_acc: 41.41%] [G loss: 0.905642]\n",
      "epoch:24 step:19263[D loss: 0.398492, acc: 67.97%, op_acc: 36.72%] [G loss: 0.931739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19264[D loss: 0.431575, acc: 61.72%, op_acc: 39.84%] [G loss: 0.939474]\n",
      "epoch:24 step:19265[D loss: 0.426935, acc: 64.06%, op_acc: 37.50%] [G loss: 0.916150]\n",
      "epoch:24 step:19266[D loss: 0.433165, acc: 60.16%, op_acc: 32.81%] [G loss: 0.952065]\n",
      "epoch:24 step:19267[D loss: 0.431398, acc: 60.94%, op_acc: 38.28%] [G loss: 0.897124]\n",
      "epoch:24 step:19268[D loss: 0.411183, acc: 64.06%, op_acc: 36.72%] [G loss: 0.915406]\n",
      "epoch:24 step:19269[D loss: 0.400184, acc: 67.19%, op_acc: 32.81%] [G loss: 0.850107]\n",
      "epoch:24 step:19270[D loss: 0.445761, acc: 58.59%, op_acc: 35.16%] [G loss: 0.902664]\n",
      "epoch:24 step:19271[D loss: 0.448282, acc: 52.34%, op_acc: 35.16%] [G loss: 0.773403]\n",
      "epoch:24 step:19272[D loss: 0.445034, acc: 53.12%, op_acc: 38.28%] [G loss: 0.901323]\n",
      "epoch:24 step:19273[D loss: 0.406462, acc: 67.97%, op_acc: 39.06%] [G loss: 0.877801]\n",
      "epoch:24 step:19274[D loss: 0.449980, acc: 55.47%, op_acc: 32.03%] [G loss: 0.802488]\n",
      "epoch:24 step:19275[D loss: 0.429816, acc: 60.94%, op_acc: 38.28%] [G loss: 0.897236]\n",
      "epoch:24 step:19276[D loss: 0.436538, acc: 57.03%, op_acc: 33.59%] [G loss: 0.848902]\n",
      "epoch:24 step:19277[D loss: 0.428562, acc: 52.34%, op_acc: 42.19%] [G loss: 0.893935]\n",
      "epoch:24 step:19278[D loss: 0.415318, acc: 59.38%, op_acc: 41.41%] [G loss: 0.894486]\n",
      "epoch:24 step:19279[D loss: 0.428302, acc: 58.59%, op_acc: 39.06%] [G loss: 0.869748]\n",
      "epoch:24 step:19280[D loss: 0.441059, acc: 46.09%, op_acc: 42.97%] [G loss: 0.870497]\n",
      "epoch:24 step:19281[D loss: 0.464121, acc: 54.69%, op_acc: 29.69%] [G loss: 0.883742]\n",
      "epoch:24 step:19282[D loss: 0.417637, acc: 64.06%, op_acc: 43.75%] [G loss: 0.925520]\n",
      "epoch:24 step:19283[D loss: 0.406142, acc: 60.94%, op_acc: 40.62%] [G loss: 0.953380]\n",
      "epoch:24 step:19284[D loss: 0.428353, acc: 64.06%, op_acc: 37.50%] [G loss: 0.829877]\n",
      "epoch:24 step:19285[D loss: 0.415648, acc: 63.28%, op_acc: 36.72%] [G loss: 0.919113]\n",
      "epoch:24 step:19286[D loss: 0.426655, acc: 59.38%, op_acc: 34.38%] [G loss: 0.932915]\n",
      "epoch:24 step:19287[D loss: 0.417161, acc: 62.50%, op_acc: 42.19%] [G loss: 0.923147]\n",
      "epoch:24 step:19288[D loss: 0.434663, acc: 49.22%, op_acc: 40.62%] [G loss: 0.904416]\n",
      "epoch:24 step:19289[D loss: 0.424684, acc: 57.81%, op_acc: 34.38%] [G loss: 0.832854]\n",
      "epoch:24 step:19290[D loss: 0.425758, acc: 59.38%, op_acc: 40.62%] [G loss: 0.791416]\n",
      "epoch:24 step:19291[D loss: 0.412247, acc: 60.94%, op_acc: 37.50%] [G loss: 0.880881]\n",
      "epoch:24 step:19292[D loss: 0.417661, acc: 61.72%, op_acc: 38.28%] [G loss: 0.927340]\n",
      "epoch:24 step:19293[D loss: 0.439051, acc: 51.56%, op_acc: 41.41%] [G loss: 0.881927]\n",
      "epoch:24 step:19294[D loss: 0.412176, acc: 59.38%, op_acc: 42.19%] [G loss: 0.902355]\n",
      "epoch:24 step:19295[D loss: 0.429782, acc: 57.03%, op_acc: 42.97%] [G loss: 0.925416]\n",
      "epoch:24 step:19296[D loss: 0.462228, acc: 53.91%, op_acc: 32.03%] [G loss: 0.803546]\n",
      "epoch:24 step:19297[D loss: 0.415563, acc: 66.41%, op_acc: 39.84%] [G loss: 0.846595]\n",
      "epoch:24 step:19298[D loss: 0.427422, acc: 57.03%, op_acc: 39.06%] [G loss: 0.877024]\n",
      "epoch:24 step:19299[D loss: 0.414142, acc: 62.50%, op_acc: 42.97%] [G loss: 0.898998]\n",
      "epoch:24 step:19300[D loss: 0.440297, acc: 49.22%, op_acc: 37.50%] [G loss: 0.844091]\n",
      "##############\n",
      "[0.85352753 0.84102699 0.8142262  0.81270559 0.7794273  0.8147211\n",
      " 0.87295363 0.83683232 0.81213131 0.83015346]\n",
      "##########\n",
      "epoch:24 step:19301[D loss: 0.423397, acc: 62.50%, op_acc: 36.72%] [G loss: 0.863465]\n",
      "epoch:24 step:19302[D loss: 0.421654, acc: 53.12%, op_acc: 48.44%] [G loss: 0.848086]\n",
      "epoch:24 step:19303[D loss: 0.399648, acc: 66.41%, op_acc: 43.75%] [G loss: 0.917492]\n",
      "epoch:24 step:19304[D loss: 0.445038, acc: 50.78%, op_acc: 35.94%] [G loss: 0.898172]\n",
      "epoch:24 step:19305[D loss: 0.423499, acc: 50.00%, op_acc: 45.31%] [G loss: 0.886662]\n",
      "epoch:24 step:19306[D loss: 0.464686, acc: 48.44%, op_acc: 32.81%] [G loss: 0.944283]\n",
      "epoch:24 step:19307[D loss: 0.406177, acc: 66.41%, op_acc: 38.28%] [G loss: 0.928197]\n",
      "epoch:24 step:19308[D loss: 0.421695, acc: 64.06%, op_acc: 42.19%] [G loss: 0.905057]\n",
      "epoch:24 step:19309[D loss: 0.454097, acc: 53.12%, op_acc: 33.59%] [G loss: 0.874805]\n",
      "epoch:24 step:19310[D loss: 0.419932, acc: 58.59%, op_acc: 35.94%] [G loss: 0.911490]\n",
      "epoch:24 step:19311[D loss: 0.411798, acc: 60.94%, op_acc: 42.97%] [G loss: 0.868700]\n",
      "epoch:24 step:19312[D loss: 0.419519, acc: 62.50%, op_acc: 47.66%] [G loss: 0.886764]\n",
      "epoch:24 step:19313[D loss: 0.411202, acc: 54.69%, op_acc: 44.53%] [G loss: 0.822845]\n",
      "epoch:24 step:19314[D loss: 0.428120, acc: 63.28%, op_acc: 36.72%] [G loss: 0.885021]\n",
      "epoch:24 step:19315[D loss: 0.406570, acc: 63.28%, op_acc: 39.06%] [G loss: 0.928595]\n",
      "epoch:24 step:19316[D loss: 0.422525, acc: 56.25%, op_acc: 39.84%] [G loss: 0.873829]\n",
      "epoch:24 step:19317[D loss: 0.411491, acc: 62.50%, op_acc: 44.53%] [G loss: 0.914615]\n",
      "epoch:24 step:19318[D loss: 0.421105, acc: 63.28%, op_acc: 40.62%] [G loss: 0.910870]\n",
      "epoch:24 step:19319[D loss: 0.428878, acc: 60.16%, op_acc: 33.59%] [G loss: 0.901044]\n",
      "epoch:24 step:19320[D loss: 0.421052, acc: 64.84%, op_acc: 33.59%] [G loss: 0.852544]\n",
      "epoch:24 step:19321[D loss: 0.459357, acc: 51.56%, op_acc: 35.16%] [G loss: 0.879974]\n",
      "epoch:24 step:19322[D loss: 0.473236, acc: 53.91%, op_acc: 37.50%] [G loss: 0.881621]\n",
      "epoch:24 step:19323[D loss: 0.427418, acc: 57.03%, op_acc: 41.41%] [G loss: 0.946273]\n",
      "epoch:24 step:19324[D loss: 0.411579, acc: 67.19%, op_acc: 40.62%] [G loss: 0.881971]\n",
      "epoch:24 step:19325[D loss: 0.444213, acc: 50.00%, op_acc: 34.38%] [G loss: 0.895126]\n",
      "epoch:24 step:19326[D loss: 0.441713, acc: 60.16%, op_acc: 35.16%] [G loss: 0.867523]\n",
      "epoch:24 step:19327[D loss: 0.401872, acc: 61.72%, op_acc: 36.72%] [G loss: 0.854419]\n",
      "epoch:24 step:19328[D loss: 0.481241, acc: 50.78%, op_acc: 35.16%] [G loss: 0.860332]\n",
      "epoch:24 step:19329[D loss: 0.409577, acc: 60.16%, op_acc: 41.41%] [G loss: 0.930686]\n",
      "epoch:24 step:19330[D loss: 0.434242, acc: 60.16%, op_acc: 41.41%] [G loss: 0.883601]\n",
      "epoch:24 step:19331[D loss: 0.393452, acc: 64.84%, op_acc: 36.72%] [G loss: 0.907727]\n",
      "epoch:24 step:19332[D loss: 0.471622, acc: 42.19%, op_acc: 39.06%] [G loss: 0.840350]\n",
      "epoch:24 step:19333[D loss: 0.421858, acc: 57.81%, op_acc: 36.72%] [G loss: 0.821674]\n",
      "epoch:24 step:19334[D loss: 0.423455, acc: 56.25%, op_acc: 39.84%] [G loss: 0.880370]\n",
      "epoch:24 step:19335[D loss: 0.411374, acc: 64.06%, op_acc: 38.28%] [G loss: 0.884114]\n",
      "epoch:24 step:19336[D loss: 0.414844, acc: 62.50%, op_acc: 40.62%] [G loss: 0.884840]\n",
      "epoch:24 step:19337[D loss: 0.446687, acc: 55.47%, op_acc: 35.94%] [G loss: 0.870461]\n",
      "epoch:24 step:19338[D loss: 0.401694, acc: 66.41%, op_acc: 36.72%] [G loss: 0.877084]\n",
      "epoch:24 step:19339[D loss: 0.392963, acc: 69.53%, op_acc: 35.94%] [G loss: 0.870017]\n",
      "epoch:24 step:19340[D loss: 0.432525, acc: 63.28%, op_acc: 42.97%] [G loss: 0.870138]\n",
      "epoch:24 step:19341[D loss: 0.412167, acc: 60.94%, op_acc: 39.06%] [G loss: 0.917762]\n",
      "epoch:24 step:19342[D loss: 0.404880, acc: 58.59%, op_acc: 42.19%] [G loss: 0.843399]\n",
      "epoch:24 step:19343[D loss: 0.412156, acc: 69.53%, op_acc: 33.59%] [G loss: 0.923819]\n",
      "epoch:24 step:19344[D loss: 0.420490, acc: 62.50%, op_acc: 41.41%] [G loss: 0.948352]\n",
      "epoch:24 step:19345[D loss: 0.444802, acc: 57.03%, op_acc: 41.41%] [G loss: 0.967213]\n",
      "epoch:24 step:19346[D loss: 0.445529, acc: 54.69%, op_acc: 39.06%] [G loss: 0.842375]\n",
      "epoch:24 step:19347[D loss: 0.384653, acc: 63.28%, op_acc: 46.88%] [G loss: 0.832165]\n",
      "epoch:24 step:19348[D loss: 0.466384, acc: 53.91%, op_acc: 35.16%] [G loss: 0.837022]\n",
      "epoch:24 step:19349[D loss: 0.409187, acc: 63.28%, op_acc: 39.84%] [G loss: 0.938702]\n",
      "epoch:24 step:19350[D loss: 0.415384, acc: 54.69%, op_acc: 45.31%] [G loss: 0.859609]\n",
      "##############\n",
      "[0.84914452 0.85106874 0.82127516 0.80755397 0.7873584  0.83906519\n",
      " 0.89034908 0.84050615 0.79069832 0.83487273]\n",
      "##########\n",
      "epoch:24 step:19351[D loss: 0.412881, acc: 57.03%, op_acc: 42.97%] [G loss: 0.872083]\n",
      "epoch:24 step:19352[D loss: 0.382046, acc: 66.41%, op_acc: 44.53%] [G loss: 0.905019]\n",
      "epoch:24 step:19353[D loss: 0.430639, acc: 58.59%, op_acc: 41.41%] [G loss: 0.858504]\n",
      "epoch:24 step:19354[D loss: 0.398302, acc: 70.31%, op_acc: 37.50%] [G loss: 0.870018]\n",
      "epoch:24 step:19355[D loss: 0.421151, acc: 60.16%, op_acc: 45.31%] [G loss: 0.888895]\n",
      "epoch:24 step:19356[D loss: 0.417480, acc: 64.84%, op_acc: 39.06%] [G loss: 0.851612]\n",
      "epoch:24 step:19357[D loss: 0.413904, acc: 66.41%, op_acc: 44.53%] [G loss: 0.882420]\n",
      "epoch:24 step:19358[D loss: 0.404388, acc: 63.28%, op_acc: 40.62%] [G loss: 0.878281]\n",
      "epoch:24 step:19359[D loss: 0.425508, acc: 56.25%, op_acc: 41.41%] [G loss: 0.896176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19360[D loss: 0.442775, acc: 56.25%, op_acc: 37.50%] [G loss: 0.804354]\n",
      "epoch:24 step:19361[D loss: 0.457546, acc: 53.91%, op_acc: 29.69%] [G loss: 0.854429]\n",
      "epoch:24 step:19362[D loss: 0.425332, acc: 53.91%, op_acc: 44.53%] [G loss: 0.772869]\n",
      "epoch:24 step:19363[D loss: 0.456514, acc: 60.94%, op_acc: 33.59%] [G loss: 0.884398]\n",
      "epoch:24 step:19364[D loss: 0.404995, acc: 64.06%, op_acc: 36.72%] [G loss: 0.917705]\n",
      "epoch:24 step:19365[D loss: 0.403620, acc: 63.28%, op_acc: 41.41%] [G loss: 0.850281]\n",
      "epoch:24 step:19366[D loss: 0.454810, acc: 60.16%, op_acc: 35.16%] [G loss: 0.866573]\n",
      "epoch:24 step:19367[D loss: 0.433988, acc: 53.91%, op_acc: 42.19%] [G loss: 0.905021]\n",
      "epoch:24 step:19368[D loss: 0.453686, acc: 55.47%, op_acc: 37.50%] [G loss: 0.869870]\n",
      "epoch:24 step:19369[D loss: 0.466151, acc: 53.12%, op_acc: 35.94%] [G loss: 0.851371]\n",
      "epoch:24 step:19370[D loss: 0.408923, acc: 55.47%, op_acc: 42.97%] [G loss: 0.842149]\n",
      "epoch:24 step:19371[D loss: 0.396502, acc: 66.41%, op_acc: 38.28%] [G loss: 0.910236]\n",
      "epoch:24 step:19372[D loss: 0.376996, acc: 71.88%, op_acc: 46.88%] [G loss: 0.979956]\n",
      "epoch:24 step:19373[D loss: 0.434756, acc: 57.81%, op_acc: 35.16%] [G loss: 0.878275]\n",
      "epoch:24 step:19374[D loss: 0.423306, acc: 61.72%, op_acc: 41.41%] [G loss: 0.846328]\n",
      "epoch:24 step:19375[D loss: 0.444585, acc: 51.56%, op_acc: 35.94%] [G loss: 0.855600]\n",
      "epoch:24 step:19376[D loss: 0.438276, acc: 58.59%, op_acc: 38.28%] [G loss: 0.867154]\n",
      "epoch:24 step:19377[D loss: 0.419283, acc: 65.62%, op_acc: 39.84%] [G loss: 0.916583]\n",
      "epoch:24 step:19378[D loss: 0.428989, acc: 53.12%, op_acc: 46.09%] [G loss: 0.873707]\n",
      "epoch:24 step:19379[D loss: 0.446554, acc: 56.25%, op_acc: 34.38%] [G loss: 0.902695]\n",
      "epoch:24 step:19380[D loss: 0.411750, acc: 58.59%, op_acc: 45.31%] [G loss: 0.864386]\n",
      "epoch:24 step:19381[D loss: 0.423271, acc: 59.38%, op_acc: 35.16%] [G loss: 0.927841]\n",
      "epoch:24 step:19382[D loss: 0.434322, acc: 58.59%, op_acc: 38.28%] [G loss: 0.861413]\n",
      "epoch:24 step:19383[D loss: 0.442548, acc: 51.56%, op_acc: 39.84%] [G loss: 0.876993]\n",
      "epoch:24 step:19384[D loss: 0.439728, acc: 60.16%, op_acc: 39.06%] [G loss: 0.846446]\n",
      "epoch:24 step:19385[D loss: 0.434841, acc: 59.38%, op_acc: 32.03%] [G loss: 0.874354]\n",
      "epoch:24 step:19386[D loss: 0.424048, acc: 60.16%, op_acc: 37.50%] [G loss: 0.916631]\n",
      "epoch:24 step:19387[D loss: 0.432573, acc: 61.72%, op_acc: 39.84%] [G loss: 0.889012]\n",
      "epoch:24 step:19388[D loss: 0.389742, acc: 63.28%, op_acc: 44.53%] [G loss: 0.926352]\n",
      "epoch:24 step:19389[D loss: 0.419754, acc: 59.38%, op_acc: 36.72%] [G loss: 0.937007]\n",
      "epoch:24 step:19390[D loss: 0.439850, acc: 65.62%, op_acc: 33.59%] [G loss: 0.960943]\n",
      "epoch:24 step:19391[D loss: 0.416119, acc: 60.16%, op_acc: 42.97%] [G loss: 0.857435]\n",
      "epoch:24 step:19392[D loss: 0.418889, acc: 59.38%, op_acc: 36.72%] [G loss: 0.819546]\n",
      "epoch:24 step:19393[D loss: 0.423675, acc: 59.38%, op_acc: 40.62%] [G loss: 0.951825]\n",
      "epoch:24 step:19394[D loss: 0.461418, acc: 58.59%, op_acc: 33.59%] [G loss: 0.826095]\n",
      "epoch:24 step:19395[D loss: 0.422991, acc: 60.94%, op_acc: 39.06%] [G loss: 0.928423]\n",
      "epoch:24 step:19396[D loss: 0.416255, acc: 63.28%, op_acc: 38.28%] [G loss: 0.870153]\n",
      "epoch:24 step:19397[D loss: 0.392893, acc: 62.50%, op_acc: 40.62%] [G loss: 0.868286]\n",
      "epoch:24 step:19398[D loss: 0.397744, acc: 59.38%, op_acc: 45.31%] [G loss: 0.912877]\n",
      "epoch:24 step:19399[D loss: 0.408383, acc: 64.06%, op_acc: 38.28%] [G loss: 0.927991]\n",
      "epoch:24 step:19400[D loss: 0.410394, acc: 60.16%, op_acc: 42.97%] [G loss: 0.873571]\n",
      "##############\n",
      "[0.85673506 0.86017679 0.81004051 0.82362671 0.8017459  0.81528354\n",
      " 0.86552296 0.81522244 0.79994488 0.81155695]\n",
      "##########\n",
      "epoch:24 step:19401[D loss: 0.402385, acc: 63.28%, op_acc: 42.19%] [G loss: 0.840935]\n",
      "epoch:24 step:19402[D loss: 0.451854, acc: 54.69%, op_acc: 32.03%] [G loss: 0.867219]\n",
      "epoch:24 step:19403[D loss: 0.416966, acc: 64.84%, op_acc: 33.59%] [G loss: 0.883870]\n",
      "epoch:24 step:19404[D loss: 0.429330, acc: 57.03%, op_acc: 38.28%] [G loss: 0.904499]\n",
      "epoch:24 step:19405[D loss: 0.415229, acc: 54.69%, op_acc: 41.41%] [G loss: 0.872683]\n",
      "epoch:24 step:19406[D loss: 0.431484, acc: 49.22%, op_acc: 45.31%] [G loss: 0.835413]\n",
      "epoch:24 step:19407[D loss: 0.403792, acc: 59.38%, op_acc: 45.31%] [G loss: 0.863331]\n",
      "epoch:24 step:19408[D loss: 0.417401, acc: 53.91%, op_acc: 39.84%] [G loss: 0.788081]\n",
      "epoch:24 step:19409[D loss: 0.419006, acc: 64.84%, op_acc: 34.38%] [G loss: 0.971293]\n",
      "epoch:24 step:19410[D loss: 0.409231, acc: 63.28%, op_acc: 36.72%] [G loss: 0.886984]\n",
      "epoch:24 step:19411[D loss: 0.424407, acc: 58.59%, op_acc: 37.50%] [G loss: 0.966667]\n",
      "epoch:24 step:19412[D loss: 0.452547, acc: 57.03%, op_acc: 42.19%] [G loss: 0.937123]\n",
      "epoch:24 step:19413[D loss: 0.425495, acc: 60.16%, op_acc: 42.97%] [G loss: 0.878878]\n",
      "epoch:24 step:19414[D loss: 0.445207, acc: 57.03%, op_acc: 39.84%] [G loss: 0.835904]\n",
      "epoch:24 step:19415[D loss: 0.443229, acc: 57.81%, op_acc: 36.72%] [G loss: 0.869959]\n",
      "epoch:24 step:19416[D loss: 0.409060, acc: 68.75%, op_acc: 36.72%] [G loss: 0.838109]\n",
      "epoch:24 step:19417[D loss: 0.444771, acc: 53.91%, op_acc: 39.84%] [G loss: 0.878508]\n",
      "epoch:24 step:19418[D loss: 0.425431, acc: 55.47%, op_acc: 45.31%] [G loss: 0.864036]\n",
      "epoch:24 step:19419[D loss: 0.427681, acc: 56.25%, op_acc: 39.84%] [G loss: 0.891516]\n",
      "epoch:24 step:19420[D loss: 0.453924, acc: 57.03%, op_acc: 34.38%] [G loss: 0.910683]\n",
      "epoch:24 step:19421[D loss: 0.439964, acc: 60.16%, op_acc: 39.06%] [G loss: 0.895701]\n",
      "epoch:24 step:19422[D loss: 0.432748, acc: 57.81%, op_acc: 35.94%] [G loss: 0.871419]\n",
      "epoch:24 step:19423[D loss: 0.398828, acc: 61.72%, op_acc: 39.84%] [G loss: 0.916214]\n",
      "epoch:24 step:19424[D loss: 0.435108, acc: 64.06%, op_acc: 35.94%] [G loss: 0.906193]\n",
      "epoch:24 step:19425[D loss: 0.435968, acc: 60.94%, op_acc: 35.16%] [G loss: 0.887525]\n",
      "epoch:24 step:19426[D loss: 0.399554, acc: 59.38%, op_acc: 43.75%] [G loss: 0.825487]\n",
      "epoch:24 step:19427[D loss: 0.445997, acc: 50.78%, op_acc: 37.50%] [G loss: 0.867670]\n",
      "epoch:24 step:19428[D loss: 0.421958, acc: 63.28%, op_acc: 39.06%] [G loss: 0.882645]\n",
      "epoch:24 step:19429[D loss: 0.442121, acc: 57.03%, op_acc: 40.62%] [G loss: 0.896795]\n",
      "epoch:24 step:19430[D loss: 0.393969, acc: 67.97%, op_acc: 39.06%] [G loss: 0.985751]\n",
      "epoch:24 step:19431[D loss: 0.422835, acc: 60.16%, op_acc: 42.19%] [G loss: 0.927529]\n",
      "epoch:24 step:19432[D loss: 0.420725, acc: 53.91%, op_acc: 42.97%] [G loss: 0.899843]\n",
      "epoch:24 step:19433[D loss: 0.459133, acc: 46.09%, op_acc: 38.28%] [G loss: 0.854282]\n",
      "epoch:24 step:19434[D loss: 0.411463, acc: 67.19%, op_acc: 40.62%] [G loss: 0.933857]\n",
      "epoch:24 step:19435[D loss: 0.440259, acc: 65.62%, op_acc: 37.50%] [G loss: 0.850516]\n",
      "epoch:24 step:19436[D loss: 0.435594, acc: 57.03%, op_acc: 39.06%] [G loss: 0.914611]\n",
      "epoch:24 step:19437[D loss: 0.425139, acc: 61.72%, op_acc: 42.97%] [G loss: 0.877697]\n",
      "epoch:24 step:19438[D loss: 0.404211, acc: 69.53%, op_acc: 36.72%] [G loss: 0.894265]\n",
      "epoch:24 step:19439[D loss: 0.423552, acc: 56.25%, op_acc: 39.06%] [G loss: 0.780918]\n",
      "epoch:24 step:19440[D loss: 0.434884, acc: 57.81%, op_acc: 32.81%] [G loss: 0.793221]\n",
      "epoch:24 step:19441[D loss: 0.424703, acc: 57.03%, op_acc: 41.41%] [G loss: 0.902891]\n",
      "epoch:24 step:19442[D loss: 0.405820, acc: 62.50%, op_acc: 39.84%] [G loss: 0.895222]\n",
      "epoch:24 step:19443[D loss: 0.416061, acc: 55.47%, op_acc: 43.75%] [G loss: 0.918009]\n",
      "epoch:24 step:19444[D loss: 0.444114, acc: 54.69%, op_acc: 35.94%] [G loss: 0.875549]\n",
      "epoch:24 step:19445[D loss: 0.424104, acc: 64.06%, op_acc: 32.03%] [G loss: 0.882319]\n",
      "epoch:24 step:19446[D loss: 0.432218, acc: 60.16%, op_acc: 35.94%] [G loss: 0.825681]\n",
      "epoch:24 step:19447[D loss: 0.418665, acc: 65.62%, op_acc: 33.59%] [G loss: 0.839087]\n",
      "epoch:24 step:19448[D loss: 0.414715, acc: 55.47%, op_acc: 41.41%] [G loss: 0.838643]\n",
      "epoch:24 step:19449[D loss: 0.444675, acc: 53.12%, op_acc: 35.16%] [G loss: 0.890385]\n",
      "epoch:24 step:19450[D loss: 0.410920, acc: 65.62%, op_acc: 37.50%] [G loss: 0.855094]\n",
      "##############\n",
      "[0.84544221 0.85956136 0.81495156 0.8123454  0.80151126 0.82186719\n",
      " 0.881329   0.82547564 0.80375033 0.84455296]\n",
      "##########\n",
      "epoch:24 step:19451[D loss: 0.418995, acc: 63.28%, op_acc: 33.59%] [G loss: 0.945757]\n",
      "epoch:24 step:19452[D loss: 0.418123, acc: 64.06%, op_acc: 38.28%] [G loss: 0.861383]\n",
      "epoch:24 step:19453[D loss: 0.395493, acc: 63.28%, op_acc: 39.06%] [G loss: 0.802148]\n",
      "epoch:24 step:19454[D loss: 0.409562, acc: 60.16%, op_acc: 39.84%] [G loss: 0.804289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19455[D loss: 0.442305, acc: 54.69%, op_acc: 33.59%] [G loss: 0.847844]\n",
      "epoch:24 step:19456[D loss: 0.393368, acc: 67.19%, op_acc: 41.41%] [G loss: 0.900213]\n",
      "epoch:24 step:19457[D loss: 0.412688, acc: 60.94%, op_acc: 39.06%] [G loss: 0.917790]\n",
      "epoch:24 step:19458[D loss: 0.477307, acc: 48.44%, op_acc: 32.03%] [G loss: 0.854177]\n",
      "epoch:24 step:19459[D loss: 0.427213, acc: 57.81%, op_acc: 40.62%] [G loss: 0.841106]\n",
      "epoch:24 step:19460[D loss: 0.443108, acc: 58.59%, op_acc: 40.62%] [G loss: 0.858257]\n",
      "epoch:24 step:19461[D loss: 0.415583, acc: 58.59%, op_acc: 47.66%] [G loss: 0.845285]\n",
      "epoch:24 step:19462[D loss: 0.410531, acc: 66.41%, op_acc: 39.06%] [G loss: 0.883345]\n",
      "epoch:24 step:19463[D loss: 0.414994, acc: 51.56%, op_acc: 43.75%] [G loss: 0.842619]\n",
      "epoch:24 step:19464[D loss: 0.431417, acc: 61.72%, op_acc: 35.94%] [G loss: 0.820088]\n",
      "epoch:24 step:19465[D loss: 0.416944, acc: 60.94%, op_acc: 38.28%] [G loss: 0.879195]\n",
      "epoch:24 step:19466[D loss: 0.440967, acc: 54.69%, op_acc: 42.97%] [G loss: 0.837599]\n",
      "epoch:24 step:19467[D loss: 0.437916, acc: 58.59%, op_acc: 37.50%] [G loss: 0.861967]\n",
      "epoch:24 step:19468[D loss: 0.465634, acc: 55.47%, op_acc: 32.81%] [G loss: 0.878330]\n",
      "epoch:24 step:19469[D loss: 0.421247, acc: 60.94%, op_acc: 39.06%] [G loss: 0.872936]\n",
      "epoch:24 step:19470[D loss: 0.441967, acc: 50.00%, op_acc: 42.19%] [G loss: 0.865267]\n",
      "epoch:24 step:19471[D loss: 0.466520, acc: 53.91%, op_acc: 29.69%] [G loss: 0.877225]\n",
      "epoch:24 step:19472[D loss: 0.458970, acc: 52.34%, op_acc: 33.59%] [G loss: 0.862315]\n",
      "epoch:24 step:19473[D loss: 0.438732, acc: 52.34%, op_acc: 36.72%] [G loss: 0.801363]\n",
      "epoch:24 step:19474[D loss: 0.434424, acc: 52.34%, op_acc: 35.94%] [G loss: 0.918641]\n",
      "epoch:24 step:19475[D loss: 0.406231, acc: 60.16%, op_acc: 44.53%] [G loss: 0.926074]\n",
      "epoch:24 step:19476[D loss: 0.427724, acc: 56.25%, op_acc: 35.16%] [G loss: 0.908413]\n",
      "epoch:24 step:19477[D loss: 0.396063, acc: 65.62%, op_acc: 39.84%] [G loss: 0.875421]\n",
      "epoch:24 step:19478[D loss: 0.424471, acc: 60.16%, op_acc: 42.19%] [G loss: 0.920727]\n",
      "epoch:24 step:19479[D loss: 0.433378, acc: 54.69%, op_acc: 34.38%] [G loss: 0.885019]\n",
      "epoch:24 step:19480[D loss: 0.413389, acc: 66.41%, op_acc: 35.16%] [G loss: 0.919641]\n",
      "epoch:24 step:19481[D loss: 0.402383, acc: 61.72%, op_acc: 42.97%] [G loss: 0.881368]\n",
      "epoch:24 step:19482[D loss: 0.441535, acc: 60.16%, op_acc: 39.06%] [G loss: 0.850825]\n",
      "epoch:24 step:19483[D loss: 0.429235, acc: 60.16%, op_acc: 34.38%] [G loss: 0.807078]\n",
      "epoch:24 step:19484[D loss: 0.426083, acc: 53.91%, op_acc: 42.97%] [G loss: 0.903431]\n",
      "epoch:24 step:19485[D loss: 0.435013, acc: 58.59%, op_acc: 35.94%] [G loss: 0.827093]\n",
      "epoch:24 step:19486[D loss: 0.429734, acc: 66.41%, op_acc: 39.84%] [G loss: 0.900103]\n",
      "epoch:24 step:19487[D loss: 0.438613, acc: 66.41%, op_acc: 35.16%] [G loss: 0.924321]\n",
      "epoch:24 step:19488[D loss: 0.384111, acc: 68.75%, op_acc: 40.62%] [G loss: 0.848288]\n",
      "epoch:24 step:19489[D loss: 0.435601, acc: 57.81%, op_acc: 35.16%] [G loss: 0.868414]\n",
      "epoch:24 step:19490[D loss: 0.443420, acc: 50.00%, op_acc: 39.06%] [G loss: 0.826125]\n",
      "epoch:24 step:19491[D loss: 0.441173, acc: 56.25%, op_acc: 38.28%] [G loss: 0.853626]\n",
      "epoch:24 step:19492[D loss: 0.420074, acc: 65.62%, op_acc: 37.50%] [G loss: 0.879613]\n",
      "epoch:24 step:19493[D loss: 0.423138, acc: 62.50%, op_acc: 39.06%] [G loss: 0.867515]\n",
      "epoch:24 step:19494[D loss: 0.435615, acc: 55.47%, op_acc: 41.41%] [G loss: 0.853176]\n",
      "epoch:24 step:19495[D loss: 0.455627, acc: 54.69%, op_acc: 37.50%] [G loss: 0.859365]\n",
      "epoch:24 step:19496[D loss: 0.410070, acc: 66.41%, op_acc: 39.84%] [G loss: 0.806805]\n",
      "epoch:24 step:19497[D loss: 0.425317, acc: 57.81%, op_acc: 35.16%] [G loss: 0.904979]\n",
      "epoch:24 step:19498[D loss: 0.415707, acc: 64.84%, op_acc: 42.97%] [G loss: 0.939146]\n",
      "epoch:24 step:19499[D loss: 0.403300, acc: 61.72%, op_acc: 41.41%] [G loss: 0.897754]\n",
      "epoch:24 step:19500[D loss: 0.425338, acc: 56.25%, op_acc: 40.62%] [G loss: 0.923343]\n",
      "##############\n",
      "[0.86037511 0.86254791 0.81768591 0.80732718 0.78610926 0.82055248\n",
      " 0.87627996 0.8321237  0.78674455 0.8113736 ]\n",
      "##########\n",
      "epoch:24 step:19501[D loss: 0.420095, acc: 57.03%, op_acc: 40.62%] [G loss: 0.881257]\n",
      "epoch:24 step:19502[D loss: 0.382254, acc: 67.97%, op_acc: 42.19%] [G loss: 0.899512]\n",
      "epoch:24 step:19503[D loss: 0.428109, acc: 57.81%, op_acc: 43.75%] [G loss: 0.921795]\n",
      "epoch:24 step:19504[D loss: 0.434461, acc: 51.56%, op_acc: 42.19%] [G loss: 0.954440]\n",
      "epoch:24 step:19505[D loss: 0.406959, acc: 57.81%, op_acc: 43.75%] [G loss: 0.873649]\n",
      "epoch:24 step:19506[D loss: 0.459218, acc: 52.34%, op_acc: 29.69%] [G loss: 0.906754]\n",
      "epoch:24 step:19507[D loss: 0.448698, acc: 53.12%, op_acc: 36.72%] [G loss: 0.851149]\n",
      "epoch:24 step:19508[D loss: 0.417027, acc: 58.59%, op_acc: 40.62%] [G loss: 0.915461]\n",
      "epoch:24 step:19509[D loss: 0.420158, acc: 60.16%, op_acc: 35.16%] [G loss: 0.913274]\n",
      "epoch:24 step:19510[D loss: 0.408200, acc: 63.28%, op_acc: 35.94%] [G loss: 0.845365]\n",
      "epoch:24 step:19511[D loss: 0.410589, acc: 55.47%, op_acc: 44.53%] [G loss: 0.904829]\n",
      "epoch:24 step:19512[D loss: 0.429690, acc: 54.69%, op_acc: 39.06%] [G loss: 0.829595]\n",
      "epoch:24 step:19513[D loss: 0.413504, acc: 57.81%, op_acc: 37.50%] [G loss: 0.834470]\n",
      "epoch:24 step:19514[D loss: 0.430197, acc: 53.12%, op_acc: 39.06%] [G loss: 0.914650]\n",
      "epoch:24 step:19515[D loss: 0.439701, acc: 60.16%, op_acc: 37.50%] [G loss: 0.861581]\n",
      "epoch:24 step:19516[D loss: 0.450069, acc: 57.81%, op_acc: 34.38%] [G loss: 0.873421]\n",
      "epoch:24 step:19517[D loss: 0.423136, acc: 63.28%, op_acc: 35.94%] [G loss: 0.900708]\n",
      "epoch:24 step:19518[D loss: 0.437669, acc: 52.34%, op_acc: 42.97%] [G loss: 0.834827]\n",
      "epoch:24 step:19519[D loss: 0.415335, acc: 64.06%, op_acc: 36.72%] [G loss: 0.897000]\n",
      "epoch:24 step:19520[D loss: 0.409118, acc: 59.38%, op_acc: 37.50%] [G loss: 0.815729]\n",
      "epoch:24 step:19521[D loss: 0.469504, acc: 55.47%, op_acc: 28.12%] [G loss: 0.928949]\n",
      "epoch:24 step:19522[D loss: 0.440349, acc: 57.03%, op_acc: 40.62%] [G loss: 0.890289]\n",
      "epoch:24 step:19523[D loss: 0.434739, acc: 62.50%, op_acc: 32.81%] [G loss: 0.814547]\n",
      "epoch:24 step:19524[D loss: 0.426640, acc: 57.03%, op_acc: 42.19%] [G loss: 0.881403]\n",
      "epoch:24 step:19525[D loss: 0.406437, acc: 60.16%, op_acc: 39.06%] [G loss: 0.869470]\n",
      "epoch:25 step:19526[D loss: 0.434144, acc: 57.81%, op_acc: 43.75%] [G loss: 0.895664]\n",
      "epoch:25 step:19527[D loss: 0.431021, acc: 52.34%, op_acc: 37.50%] [G loss: 0.928623]\n",
      "epoch:25 step:19528[D loss: 0.443645, acc: 54.69%, op_acc: 39.06%] [G loss: 0.906109]\n",
      "epoch:25 step:19529[D loss: 0.410303, acc: 57.03%, op_acc: 42.97%] [G loss: 0.845596]\n",
      "epoch:25 step:19530[D loss: 0.400201, acc: 67.19%, op_acc: 36.72%] [G loss: 0.889481]\n",
      "epoch:25 step:19531[D loss: 0.429267, acc: 66.41%, op_acc: 37.50%] [G loss: 0.933939]\n",
      "epoch:25 step:19532[D loss: 0.413056, acc: 65.62%, op_acc: 39.84%] [G loss: 0.846213]\n",
      "epoch:25 step:19533[D loss: 0.440513, acc: 50.78%, op_acc: 39.06%] [G loss: 0.889850]\n",
      "epoch:25 step:19534[D loss: 0.399724, acc: 58.59%, op_acc: 44.53%] [G loss: 0.904152]\n",
      "epoch:25 step:19535[D loss: 0.437177, acc: 59.38%, op_acc: 40.62%] [G loss: 0.913427]\n",
      "epoch:25 step:19536[D loss: 0.453861, acc: 50.78%, op_acc: 35.94%] [G loss: 0.812694]\n",
      "epoch:25 step:19537[D loss: 0.453085, acc: 53.91%, op_acc: 34.38%] [G loss: 0.920000]\n",
      "epoch:25 step:19538[D loss: 0.415461, acc: 58.59%, op_acc: 35.94%] [G loss: 0.782623]\n",
      "epoch:25 step:19539[D loss: 0.440295, acc: 60.16%, op_acc: 38.28%] [G loss: 0.841052]\n",
      "epoch:25 step:19540[D loss: 0.427423, acc: 60.16%, op_acc: 37.50%] [G loss: 0.825413]\n",
      "epoch:25 step:19541[D loss: 0.406868, acc: 57.03%, op_acc: 41.41%] [G loss: 0.923968]\n",
      "epoch:25 step:19542[D loss: 0.406099, acc: 60.94%, op_acc: 42.19%] [G loss: 0.912351]\n",
      "epoch:25 step:19543[D loss: 0.411996, acc: 60.94%, op_acc: 36.72%] [G loss: 0.914778]\n",
      "epoch:25 step:19544[D loss: 0.413594, acc: 57.81%, op_acc: 39.06%] [G loss: 0.890231]\n",
      "epoch:25 step:19545[D loss: 0.430081, acc: 60.16%, op_acc: 34.38%] [G loss: 0.906128]\n",
      "epoch:25 step:19546[D loss: 0.451634, acc: 50.78%, op_acc: 36.72%] [G loss: 0.892043]\n",
      "epoch:25 step:19547[D loss: 0.425888, acc: 61.72%, op_acc: 42.19%] [G loss: 0.872265]\n",
      "epoch:25 step:19548[D loss: 0.410547, acc: 55.47%, op_acc: 42.19%] [G loss: 0.904448]\n",
      "epoch:25 step:19549[D loss: 0.454348, acc: 60.16%, op_acc: 35.16%] [G loss: 0.835991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19550[D loss: 0.440406, acc: 53.91%, op_acc: 35.16%] [G loss: 0.862836]\n",
      "##############\n",
      "[0.85570647 0.85007026 0.81017576 0.79358201 0.78673816 0.86001211\n",
      " 0.88998344 0.83862106 0.80268832 0.81373314]\n",
      "##########\n",
      "epoch:25 step:19551[D loss: 0.432303, acc: 57.81%, op_acc: 40.62%] [G loss: 0.831453]\n",
      "epoch:25 step:19552[D loss: 0.420799, acc: 61.72%, op_acc: 34.38%] [G loss: 0.842526]\n",
      "epoch:25 step:19553[D loss: 0.413315, acc: 60.94%, op_acc: 43.75%] [G loss: 0.892337]\n",
      "epoch:25 step:19554[D loss: 0.440326, acc: 46.09%, op_acc: 40.62%] [G loss: 0.960119]\n",
      "epoch:25 step:19555[D loss: 0.406890, acc: 64.06%, op_acc: 39.84%] [G loss: 0.971213]\n",
      "epoch:25 step:19556[D loss: 0.437797, acc: 60.94%, op_acc: 40.62%] [G loss: 0.878332]\n",
      "epoch:25 step:19557[D loss: 0.430281, acc: 61.72%, op_acc: 35.16%] [G loss: 0.897442]\n",
      "epoch:25 step:19558[D loss: 0.398187, acc: 64.06%, op_acc: 44.53%] [G loss: 0.886750]\n",
      "epoch:25 step:19559[D loss: 0.412535, acc: 63.28%, op_acc: 46.88%] [G loss: 0.885591]\n",
      "epoch:25 step:19560[D loss: 0.449645, acc: 55.47%, op_acc: 36.72%] [G loss: 0.921139]\n",
      "epoch:25 step:19561[D loss: 0.393249, acc: 64.84%, op_acc: 46.09%] [G loss: 0.906809]\n",
      "epoch:25 step:19562[D loss: 0.419243, acc: 62.50%, op_acc: 35.94%] [G loss: 0.872705]\n",
      "epoch:25 step:19563[D loss: 0.421343, acc: 60.94%, op_acc: 35.16%] [G loss: 0.865309]\n",
      "epoch:25 step:19564[D loss: 0.397854, acc: 62.50%, op_acc: 46.09%] [G loss: 0.916680]\n",
      "epoch:25 step:19565[D loss: 0.442616, acc: 51.56%, op_acc: 35.94%] [G loss: 0.855386]\n",
      "epoch:25 step:19566[D loss: 0.403689, acc: 60.94%, op_acc: 41.41%] [G loss: 0.783908]\n",
      "epoch:25 step:19567[D loss: 0.404617, acc: 62.50%, op_acc: 41.41%] [G loss: 0.881495]\n",
      "epoch:25 step:19568[D loss: 0.454297, acc: 54.69%, op_acc: 34.38%] [G loss: 0.846308]\n",
      "epoch:25 step:19569[D loss: 0.417823, acc: 58.59%, op_acc: 38.28%] [G loss: 0.816855]\n",
      "epoch:25 step:19570[D loss: 0.417340, acc: 63.28%, op_acc: 40.62%] [G loss: 0.857219]\n",
      "epoch:25 step:19571[D loss: 0.400932, acc: 65.62%, op_acc: 42.19%] [G loss: 0.857241]\n",
      "epoch:25 step:19572[D loss: 0.451788, acc: 50.00%, op_acc: 33.59%] [G loss: 0.764630]\n",
      "epoch:25 step:19573[D loss: 0.449190, acc: 56.25%, op_acc: 35.16%] [G loss: 0.905560]\n",
      "epoch:25 step:19574[D loss: 0.397470, acc: 65.62%, op_acc: 44.53%] [G loss: 0.908385]\n",
      "epoch:25 step:19575[D loss: 0.440696, acc: 50.78%, op_acc: 42.97%] [G loss: 0.888782]\n",
      "epoch:25 step:19576[D loss: 0.415727, acc: 64.84%, op_acc: 32.03%] [G loss: 0.864685]\n",
      "epoch:25 step:19577[D loss: 0.435152, acc: 60.94%, op_acc: 33.59%] [G loss: 0.878054]\n",
      "epoch:25 step:19578[D loss: 0.445716, acc: 57.81%, op_acc: 36.72%] [G loss: 0.802211]\n",
      "epoch:25 step:19579[D loss: 0.432593, acc: 61.72%, op_acc: 43.75%] [G loss: 0.862224]\n",
      "epoch:25 step:19580[D loss: 0.427132, acc: 53.12%, op_acc: 39.84%] [G loss: 0.789058]\n",
      "epoch:25 step:19581[D loss: 0.418731, acc: 61.72%, op_acc: 38.28%] [G loss: 0.866753]\n",
      "epoch:25 step:19582[D loss: 0.428860, acc: 60.94%, op_acc: 39.84%] [G loss: 0.887978]\n",
      "epoch:25 step:19583[D loss: 0.442354, acc: 46.88%, op_acc: 43.75%] [G loss: 0.832736]\n",
      "epoch:25 step:19584[D loss: 0.412383, acc: 60.16%, op_acc: 40.62%] [G loss: 0.821535]\n",
      "epoch:25 step:19585[D loss: 0.449258, acc: 50.00%, op_acc: 38.28%] [G loss: 0.875579]\n",
      "epoch:25 step:19586[D loss: 0.442987, acc: 58.59%, op_acc: 39.06%] [G loss: 0.839865]\n",
      "epoch:25 step:19587[D loss: 0.422770, acc: 57.03%, op_acc: 38.28%] [G loss: 0.912072]\n",
      "epoch:25 step:19588[D loss: 0.431890, acc: 57.03%, op_acc: 36.72%] [G loss: 0.800558]\n",
      "epoch:25 step:19589[D loss: 0.403781, acc: 63.28%, op_acc: 40.62%] [G loss: 0.911778]\n",
      "epoch:25 step:19590[D loss: 0.438696, acc: 53.91%, op_acc: 36.72%] [G loss: 0.834751]\n",
      "epoch:25 step:19591[D loss: 0.433430, acc: 57.03%, op_acc: 37.50%] [G loss: 0.904139]\n",
      "epoch:25 step:19592[D loss: 0.411264, acc: 59.38%, op_acc: 41.41%] [G loss: 0.817788]\n",
      "epoch:25 step:19593[D loss: 0.427064, acc: 60.94%, op_acc: 40.62%] [G loss: 0.895421]\n",
      "epoch:25 step:19594[D loss: 0.388300, acc: 66.41%, op_acc: 43.75%] [G loss: 0.901886]\n",
      "epoch:25 step:19595[D loss: 0.424891, acc: 56.25%, op_acc: 41.41%] [G loss: 0.925255]\n",
      "epoch:25 step:19596[D loss: 0.474467, acc: 54.69%, op_acc: 32.03%] [G loss: 0.796850]\n",
      "epoch:25 step:19597[D loss: 0.401763, acc: 61.72%, op_acc: 42.19%] [G loss: 0.858665]\n",
      "epoch:25 step:19598[D loss: 0.400653, acc: 64.84%, op_acc: 44.53%] [G loss: 0.861236]\n",
      "epoch:25 step:19599[D loss: 0.409516, acc: 61.72%, op_acc: 39.06%] [G loss: 0.858921]\n",
      "epoch:25 step:19600[D loss: 0.407713, acc: 60.94%, op_acc: 35.16%] [G loss: 0.873668]\n",
      "##############\n",
      "[0.85832595 0.86925161 0.79816123 0.8345851  0.8122962  0.81822794\n",
      " 0.87958488 0.8293185  0.81098852 0.84308184]\n",
      "##########\n",
      "epoch:25 step:19601[D loss: 0.431122, acc: 58.59%, op_acc: 39.06%] [G loss: 0.824755]\n",
      "epoch:25 step:19602[D loss: 0.400998, acc: 64.84%, op_acc: 39.06%] [G loss: 0.886480]\n",
      "epoch:25 step:19603[D loss: 0.443880, acc: 57.81%, op_acc: 37.50%] [G loss: 0.790450]\n",
      "epoch:25 step:19604[D loss: 0.419216, acc: 67.19%, op_acc: 41.41%] [G loss: 0.784925]\n",
      "epoch:25 step:19605[D loss: 0.436603, acc: 59.38%, op_acc: 34.38%] [G loss: 0.855728]\n",
      "epoch:25 step:19606[D loss: 0.419280, acc: 67.97%, op_acc: 37.50%] [G loss: 0.902972]\n",
      "epoch:25 step:19607[D loss: 0.407132, acc: 59.38%, op_acc: 42.97%] [G loss: 0.896914]\n",
      "epoch:25 step:19608[D loss: 0.425112, acc: 64.06%, op_acc: 41.41%] [G loss: 0.910715]\n",
      "epoch:25 step:19609[D loss: 0.432296, acc: 57.03%, op_acc: 40.62%] [G loss: 0.849618]\n",
      "epoch:25 step:19610[D loss: 0.405158, acc: 62.50%, op_acc: 42.19%] [G loss: 0.889157]\n",
      "epoch:25 step:19611[D loss: 0.442980, acc: 57.81%, op_acc: 39.06%] [G loss: 0.977095]\n",
      "epoch:25 step:19612[D loss: 0.423554, acc: 60.94%, op_acc: 34.38%] [G loss: 0.862445]\n",
      "epoch:25 step:19613[D loss: 0.418967, acc: 59.38%, op_acc: 38.28%] [G loss: 0.830072]\n",
      "epoch:25 step:19614[D loss: 0.454155, acc: 57.81%, op_acc: 32.03%] [G loss: 0.915472]\n",
      "epoch:25 step:19615[D loss: 0.422933, acc: 59.38%, op_acc: 38.28%] [G loss: 0.868242]\n",
      "epoch:25 step:19616[D loss: 0.413830, acc: 61.72%, op_acc: 40.62%] [G loss: 0.893486]\n",
      "epoch:25 step:19617[D loss: 0.451116, acc: 56.25%, op_acc: 40.62%] [G loss: 0.875701]\n",
      "epoch:25 step:19618[D loss: 0.411690, acc: 57.03%, op_acc: 42.97%] [G loss: 0.837415]\n",
      "epoch:25 step:19619[D loss: 0.411996, acc: 54.69%, op_acc: 39.84%] [G loss: 0.791108]\n",
      "epoch:25 step:19620[D loss: 0.397159, acc: 67.97%, op_acc: 39.84%] [G loss: 0.909460]\n",
      "epoch:25 step:19621[D loss: 0.466239, acc: 57.03%, op_acc: 35.94%] [G loss: 0.814630]\n",
      "epoch:25 step:19622[D loss: 0.405062, acc: 61.72%, op_acc: 39.84%] [G loss: 0.887925]\n",
      "epoch:25 step:19623[D loss: 0.415262, acc: 65.62%, op_acc: 35.16%] [G loss: 0.908949]\n",
      "epoch:25 step:19624[D loss: 0.415297, acc: 61.72%, op_acc: 38.28%] [G loss: 0.881829]\n",
      "epoch:25 step:19625[D loss: 0.417004, acc: 55.47%, op_acc: 40.62%] [G loss: 0.825461]\n",
      "epoch:25 step:19626[D loss: 0.426349, acc: 64.84%, op_acc: 31.25%] [G loss: 0.962061]\n",
      "epoch:25 step:19627[D loss: 0.401904, acc: 65.62%, op_acc: 36.72%] [G loss: 0.931156]\n",
      "epoch:25 step:19628[D loss: 0.386023, acc: 69.53%, op_acc: 38.28%] [G loss: 0.871002]\n",
      "epoch:25 step:19629[D loss: 0.403352, acc: 61.72%, op_acc: 44.53%] [G loss: 0.871036]\n",
      "epoch:25 step:19630[D loss: 0.415135, acc: 58.59%, op_acc: 45.31%] [G loss: 0.886198]\n",
      "epoch:25 step:19631[D loss: 0.427130, acc: 57.03%, op_acc: 37.50%] [G loss: 0.942405]\n",
      "epoch:25 step:19632[D loss: 0.414314, acc: 64.06%, op_acc: 41.41%] [G loss: 0.849934]\n",
      "epoch:25 step:19633[D loss: 0.444320, acc: 54.69%, op_acc: 33.59%] [G loss: 0.897583]\n",
      "epoch:25 step:19634[D loss: 0.421269, acc: 56.25%, op_acc: 42.19%] [G loss: 0.884170]\n",
      "epoch:25 step:19635[D loss: 0.426260, acc: 52.34%, op_acc: 42.97%] [G loss: 0.868362]\n",
      "epoch:25 step:19636[D loss: 0.440086, acc: 65.62%, op_acc: 32.81%] [G loss: 0.886244]\n",
      "epoch:25 step:19637[D loss: 0.442694, acc: 55.47%, op_acc: 42.97%] [G loss: 0.861680]\n",
      "epoch:25 step:19638[D loss: 0.421454, acc: 60.94%, op_acc: 35.94%] [G loss: 0.914237]\n",
      "epoch:25 step:19639[D loss: 0.415920, acc: 58.59%, op_acc: 40.62%] [G loss: 0.849048]\n",
      "epoch:25 step:19640[D loss: 0.394894, acc: 60.16%, op_acc: 47.66%] [G loss: 0.898903]\n",
      "epoch:25 step:19641[D loss: 0.428579, acc: 60.16%, op_acc: 39.84%] [G loss: 0.885835]\n",
      "epoch:25 step:19642[D loss: 0.411582, acc: 63.28%, op_acc: 39.84%] [G loss: 0.870397]\n",
      "epoch:25 step:19643[D loss: 0.441467, acc: 55.47%, op_acc: 36.72%] [G loss: 0.862351]\n",
      "epoch:25 step:19644[D loss: 0.407400, acc: 62.50%, op_acc: 36.72%] [G loss: 0.873420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19645[D loss: 0.443663, acc: 54.69%, op_acc: 39.84%] [G loss: 0.890368]\n",
      "epoch:25 step:19646[D loss: 0.414787, acc: 65.62%, op_acc: 39.06%] [G loss: 0.851766]\n",
      "epoch:25 step:19647[D loss: 0.400082, acc: 67.19%, op_acc: 41.41%] [G loss: 0.915326]\n",
      "epoch:25 step:19648[D loss: 0.460315, acc: 51.56%, op_acc: 33.59%] [G loss: 0.799030]\n",
      "epoch:25 step:19649[D loss: 0.399154, acc: 69.53%, op_acc: 37.50%] [G loss: 0.906206]\n",
      "epoch:25 step:19650[D loss: 0.459128, acc: 50.00%, op_acc: 35.94%] [G loss: 0.835677]\n",
      "##############\n",
      "[0.85727628 0.85707863 0.81941221 0.80278435 0.78506495 0.82641446\n",
      " 0.87853608 0.8313529  0.81476996 0.83346933]\n",
      "##########\n",
      "epoch:25 step:19651[D loss: 0.413329, acc: 58.59%, op_acc: 42.97%] [G loss: 0.870889]\n",
      "epoch:25 step:19652[D loss: 0.414590, acc: 60.94%, op_acc: 35.16%] [G loss: 0.882489]\n",
      "epoch:25 step:19653[D loss: 0.384569, acc: 72.66%, op_acc: 42.19%] [G loss: 0.893450]\n",
      "epoch:25 step:19654[D loss: 0.422498, acc: 60.16%, op_acc: 37.50%] [G loss: 0.914141]\n",
      "epoch:25 step:19655[D loss: 0.411351, acc: 60.94%, op_acc: 42.19%] [G loss: 0.845215]\n",
      "epoch:25 step:19656[D loss: 0.411462, acc: 62.50%, op_acc: 38.28%] [G loss: 0.810156]\n",
      "epoch:25 step:19657[D loss: 0.390258, acc: 57.81%, op_acc: 47.66%] [G loss: 0.874212]\n",
      "epoch:25 step:19658[D loss: 0.446134, acc: 62.50%, op_acc: 29.69%] [G loss: 0.873399]\n",
      "epoch:25 step:19659[D loss: 0.424561, acc: 56.25%, op_acc: 38.28%] [G loss: 0.863931]\n",
      "epoch:25 step:19660[D loss: 0.433226, acc: 61.72%, op_acc: 39.06%] [G loss: 0.849637]\n",
      "epoch:25 step:19661[D loss: 0.414322, acc: 60.16%, op_acc: 39.06%] [G loss: 0.828242]\n",
      "epoch:25 step:19662[D loss: 0.489197, acc: 41.41%, op_acc: 37.50%] [G loss: 0.874488]\n",
      "epoch:25 step:19663[D loss: 0.430715, acc: 57.03%, op_acc: 40.62%] [G loss: 0.868068]\n",
      "epoch:25 step:19664[D loss: 0.427117, acc: 50.78%, op_acc: 41.41%] [G loss: 0.855694]\n",
      "epoch:25 step:19665[D loss: 0.448210, acc: 55.47%, op_acc: 39.84%] [G loss: 0.832465]\n",
      "epoch:25 step:19666[D loss: 0.447419, acc: 54.69%, op_acc: 40.62%] [G loss: 0.867563]\n",
      "epoch:25 step:19667[D loss: 0.427351, acc: 56.25%, op_acc: 46.09%] [G loss: 0.794114]\n",
      "epoch:25 step:19668[D loss: 0.419400, acc: 63.28%, op_acc: 39.06%] [G loss: 0.830080]\n",
      "epoch:25 step:19669[D loss: 0.430467, acc: 58.59%, op_acc: 35.94%] [G loss: 0.785485]\n",
      "epoch:25 step:19670[D loss: 0.415918, acc: 62.50%, op_acc: 43.75%] [G loss: 0.966000]\n",
      "epoch:25 step:19671[D loss: 0.433546, acc: 63.28%, op_acc: 32.81%] [G loss: 0.823647]\n",
      "epoch:25 step:19672[D loss: 0.401200, acc: 66.41%, op_acc: 43.75%] [G loss: 0.891296]\n",
      "epoch:25 step:19673[D loss: 0.422902, acc: 61.72%, op_acc: 42.97%] [G loss: 0.944224]\n",
      "epoch:25 step:19674[D loss: 0.419670, acc: 54.69%, op_acc: 39.84%] [G loss: 0.946282]\n",
      "epoch:25 step:19675[D loss: 0.413781, acc: 53.91%, op_acc: 42.19%] [G loss: 0.935726]\n",
      "epoch:25 step:19676[D loss: 0.426180, acc: 58.59%, op_acc: 38.28%] [G loss: 0.819843]\n",
      "epoch:25 step:19677[D loss: 0.434665, acc: 52.34%, op_acc: 40.62%] [G loss: 0.804664]\n",
      "epoch:25 step:19678[D loss: 0.418573, acc: 60.94%, op_acc: 36.72%] [G loss: 0.938706]\n",
      "epoch:25 step:19679[D loss: 0.432479, acc: 58.59%, op_acc: 39.84%] [G loss: 0.854269]\n",
      "epoch:25 step:19680[D loss: 0.434600, acc: 56.25%, op_acc: 41.41%] [G loss: 0.842249]\n",
      "epoch:25 step:19681[D loss: 0.440610, acc: 60.16%, op_acc: 37.50%] [G loss: 0.916355]\n",
      "epoch:25 step:19682[D loss: 0.427160, acc: 57.03%, op_acc: 35.94%] [G loss: 0.909295]\n",
      "epoch:25 step:19683[D loss: 0.396597, acc: 64.84%, op_acc: 41.41%] [G loss: 0.862226]\n",
      "epoch:25 step:19684[D loss: 0.442433, acc: 51.56%, op_acc: 37.50%] [G loss: 0.850930]\n",
      "epoch:25 step:19685[D loss: 0.439194, acc: 53.12%, op_acc: 38.28%] [G loss: 0.880371]\n",
      "epoch:25 step:19686[D loss: 0.422879, acc: 55.47%, op_acc: 40.62%] [G loss: 0.776923]\n",
      "epoch:25 step:19687[D loss: 0.398244, acc: 64.84%, op_acc: 41.41%] [G loss: 0.843583]\n",
      "epoch:25 step:19688[D loss: 0.462570, acc: 51.56%, op_acc: 29.69%] [G loss: 0.826541]\n",
      "epoch:25 step:19689[D loss: 0.427330, acc: 64.06%, op_acc: 42.19%] [G loss: 0.901283]\n",
      "epoch:25 step:19690[D loss: 0.411206, acc: 55.47%, op_acc: 43.75%] [G loss: 0.845139]\n",
      "epoch:25 step:19691[D loss: 0.436491, acc: 56.25%, op_acc: 38.28%] [G loss: 0.795016]\n",
      "epoch:25 step:19692[D loss: 0.405175, acc: 64.84%, op_acc: 40.62%] [G loss: 0.865170]\n",
      "epoch:25 step:19693[D loss: 0.409637, acc: 57.03%, op_acc: 39.84%] [G loss: 0.943350]\n",
      "epoch:25 step:19694[D loss: 0.451708, acc: 49.22%, op_acc: 40.62%] [G loss: 0.901015]\n",
      "epoch:25 step:19695[D loss: 0.433179, acc: 53.91%, op_acc: 40.62%] [G loss: 0.891691]\n",
      "epoch:25 step:19696[D loss: 0.440691, acc: 61.72%, op_acc: 39.84%] [G loss: 0.869210]\n",
      "epoch:25 step:19697[D loss: 0.405688, acc: 62.50%, op_acc: 45.31%] [G loss: 0.848566]\n",
      "epoch:25 step:19698[D loss: 0.422478, acc: 60.94%, op_acc: 36.72%] [G loss: 0.932008]\n",
      "epoch:25 step:19699[D loss: 0.468871, acc: 55.47%, op_acc: 34.38%] [G loss: 0.795331]\n",
      "epoch:25 step:19700[D loss: 0.400514, acc: 69.53%, op_acc: 40.62%] [G loss: 0.854181]\n",
      "##############\n",
      "[0.87055997 0.84976186 0.79262285 0.80040798 0.78556419 0.82301192\n",
      " 0.90640538 0.80609185 0.806049   0.83003389]\n",
      "##########\n",
      "epoch:25 step:19701[D loss: 0.437606, acc: 59.38%, op_acc: 40.62%] [G loss: 0.814409]\n",
      "epoch:25 step:19702[D loss: 0.384000, acc: 61.72%, op_acc: 43.75%] [G loss: 0.837390]\n",
      "epoch:25 step:19703[D loss: 0.444133, acc: 60.16%, op_acc: 33.59%] [G loss: 0.812517]\n",
      "epoch:25 step:19704[D loss: 0.418924, acc: 60.16%, op_acc: 39.06%] [G loss: 0.872571]\n",
      "epoch:25 step:19705[D loss: 0.430569, acc: 62.50%, op_acc: 37.50%] [G loss: 0.884542]\n",
      "epoch:25 step:19706[D loss: 0.406639, acc: 57.81%, op_acc: 46.09%] [G loss: 0.968126]\n",
      "epoch:25 step:19707[D loss: 0.423716, acc: 58.59%, op_acc: 38.28%] [G loss: 0.915093]\n",
      "epoch:25 step:19708[D loss: 0.430160, acc: 59.38%, op_acc: 36.72%] [G loss: 0.897161]\n",
      "epoch:25 step:19709[D loss: 0.429623, acc: 58.59%, op_acc: 37.50%] [G loss: 0.805128]\n",
      "epoch:25 step:19710[D loss: 0.402821, acc: 69.53%, op_acc: 36.72%] [G loss: 0.897501]\n",
      "epoch:25 step:19711[D loss: 0.423375, acc: 64.06%, op_acc: 35.16%] [G loss: 0.854500]\n",
      "epoch:25 step:19712[D loss: 0.455241, acc: 50.78%, op_acc: 42.97%] [G loss: 0.832717]\n",
      "epoch:25 step:19713[D loss: 0.406157, acc: 61.72%, op_acc: 39.06%] [G loss: 1.013592]\n",
      "epoch:25 step:19714[D loss: 0.392614, acc: 68.75%, op_acc: 36.72%] [G loss: 0.891621]\n",
      "epoch:25 step:19715[D loss: 0.439918, acc: 57.03%, op_acc: 42.19%] [G loss: 0.877678]\n",
      "epoch:25 step:19716[D loss: 0.396431, acc: 60.16%, op_acc: 42.19%] [G loss: 0.870646]\n",
      "epoch:25 step:19717[D loss: 0.413501, acc: 63.28%, op_acc: 40.62%] [G loss: 0.962451]\n",
      "epoch:25 step:19718[D loss: 0.417161, acc: 59.38%, op_acc: 42.97%] [G loss: 0.828593]\n",
      "epoch:25 step:19719[D loss: 0.440411, acc: 57.81%, op_acc: 38.28%] [G loss: 0.859979]\n",
      "epoch:25 step:19720[D loss: 0.430207, acc: 61.72%, op_acc: 37.50%] [G loss: 0.840539]\n",
      "epoch:25 step:19721[D loss: 0.415895, acc: 62.50%, op_acc: 38.28%] [G loss: 0.847746]\n",
      "epoch:25 step:19722[D loss: 0.437110, acc: 62.50%, op_acc: 39.84%] [G loss: 0.911378]\n",
      "epoch:25 step:19723[D loss: 0.398919, acc: 63.28%, op_acc: 40.62%] [G loss: 0.896549]\n",
      "epoch:25 step:19724[D loss: 0.431052, acc: 62.50%, op_acc: 37.50%] [G loss: 0.949335]\n",
      "epoch:25 step:19725[D loss: 0.413608, acc: 62.50%, op_acc: 44.53%] [G loss: 0.898408]\n",
      "epoch:25 step:19726[D loss: 0.418887, acc: 56.25%, op_acc: 39.84%] [G loss: 0.934764]\n",
      "epoch:25 step:19727[D loss: 0.446859, acc: 55.47%, op_acc: 35.16%] [G loss: 0.928792]\n",
      "epoch:25 step:19728[D loss: 0.434454, acc: 58.59%, op_acc: 35.16%] [G loss: 0.793829]\n",
      "epoch:25 step:19729[D loss: 0.436488, acc: 59.38%, op_acc: 39.84%] [G loss: 0.887037]\n",
      "epoch:25 step:19730[D loss: 0.420183, acc: 64.06%, op_acc: 34.38%] [G loss: 0.864088]\n",
      "epoch:25 step:19731[D loss: 0.409048, acc: 60.94%, op_acc: 41.41%] [G loss: 0.837699]\n",
      "epoch:25 step:19732[D loss: 0.385368, acc: 71.09%, op_acc: 44.53%] [G loss: 1.047956]\n",
      "epoch:25 step:19733[D loss: 0.425245, acc: 62.50%, op_acc: 40.62%] [G loss: 1.031621]\n",
      "epoch:25 step:19734[D loss: 0.413951, acc: 60.16%, op_acc: 39.84%] [G loss: 0.890512]\n",
      "epoch:25 step:19735[D loss: 0.430237, acc: 66.41%, op_acc: 30.47%] [G loss: 0.895561]\n",
      "epoch:25 step:19736[D loss: 0.403840, acc: 64.84%, op_acc: 42.19%] [G loss: 0.816581]\n",
      "epoch:25 step:19737[D loss: 0.413850, acc: 57.81%, op_acc: 41.41%] [G loss: 0.812086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19738[D loss: 0.429058, acc: 56.25%, op_acc: 36.72%] [G loss: 0.847986]\n",
      "epoch:25 step:19739[D loss: 0.438458, acc: 53.12%, op_acc: 40.62%] [G loss: 0.852674]\n",
      "epoch:25 step:19740[D loss: 0.431563, acc: 62.50%, op_acc: 37.50%] [G loss: 0.880801]\n",
      "epoch:25 step:19741[D loss: 0.434054, acc: 56.25%, op_acc: 35.94%] [G loss: 0.953869]\n",
      "epoch:25 step:19742[D loss: 0.418362, acc: 57.03%, op_acc: 39.84%] [G loss: 0.931701]\n",
      "epoch:25 step:19743[D loss: 0.401802, acc: 66.41%, op_acc: 42.97%] [G loss: 0.972392]\n",
      "epoch:25 step:19744[D loss: 0.391947, acc: 64.84%, op_acc: 42.97%] [G loss: 0.926508]\n",
      "epoch:25 step:19745[D loss: 0.413395, acc: 58.59%, op_acc: 39.06%] [G loss: 0.981059]\n",
      "epoch:25 step:19746[D loss: 0.441987, acc: 54.69%, op_acc: 38.28%] [G loss: 0.874931]\n",
      "epoch:25 step:19747[D loss: 0.411942, acc: 61.72%, op_acc: 35.16%] [G loss: 0.881525]\n",
      "epoch:25 step:19748[D loss: 0.448600, acc: 52.34%, op_acc: 42.19%] [G loss: 0.905383]\n",
      "epoch:25 step:19749[D loss: 0.447620, acc: 59.38%, op_acc: 39.06%] [G loss: 0.939639]\n",
      "epoch:25 step:19750[D loss: 0.443145, acc: 61.72%, op_acc: 37.50%] [G loss: 0.884572]\n",
      "##############\n",
      "[0.84647359 0.8531009  0.81117996 0.80233087 0.78086814 0.83290247\n",
      " 0.87955903 0.82305378 0.80409741 0.82869957]\n",
      "##########\n",
      "epoch:25 step:19751[D loss: 0.441834, acc: 54.69%, op_acc: 37.50%] [G loss: 0.817639]\n",
      "epoch:25 step:19752[D loss: 0.398676, acc: 61.72%, op_acc: 40.62%] [G loss: 0.978145]\n",
      "epoch:25 step:19753[D loss: 0.402308, acc: 62.50%, op_acc: 44.53%] [G loss: 0.918655]\n",
      "epoch:25 step:19754[D loss: 0.424595, acc: 59.38%, op_acc: 37.50%] [G loss: 0.945612]\n",
      "epoch:25 step:19755[D loss: 0.447952, acc: 56.25%, op_acc: 42.19%] [G loss: 0.881967]\n",
      "epoch:25 step:19756[D loss: 0.421962, acc: 54.69%, op_acc: 44.53%] [G loss: 0.895766]\n",
      "epoch:25 step:19757[D loss: 0.427256, acc: 60.94%, op_acc: 39.06%] [G loss: 0.874019]\n",
      "epoch:25 step:19758[D loss: 0.440352, acc: 57.03%, op_acc: 36.72%] [G loss: 0.851775]\n",
      "epoch:25 step:19759[D loss: 0.436215, acc: 61.72%, op_acc: 33.59%] [G loss: 0.866784]\n",
      "epoch:25 step:19760[D loss: 0.419623, acc: 62.50%, op_acc: 38.28%] [G loss: 0.862630]\n",
      "epoch:25 step:19761[D loss: 0.451967, acc: 47.66%, op_acc: 43.75%] [G loss: 0.872785]\n",
      "epoch:25 step:19762[D loss: 0.401528, acc: 64.84%, op_acc: 41.41%] [G loss: 0.876547]\n",
      "epoch:25 step:19763[D loss: 0.438651, acc: 52.34%, op_acc: 39.84%] [G loss: 0.900900]\n",
      "epoch:25 step:19764[D loss: 0.427457, acc: 57.81%, op_acc: 39.84%] [G loss: 0.817377]\n",
      "epoch:25 step:19765[D loss: 0.436521, acc: 59.38%, op_acc: 35.16%] [G loss: 0.869432]\n",
      "epoch:25 step:19766[D loss: 0.390557, acc: 65.62%, op_acc: 42.97%] [G loss: 0.964553]\n",
      "epoch:25 step:19767[D loss: 0.393826, acc: 64.06%, op_acc: 46.88%] [G loss: 0.882419]\n",
      "epoch:25 step:19768[D loss: 0.421532, acc: 58.59%, op_acc: 43.75%] [G loss: 0.835675]\n",
      "epoch:25 step:19769[D loss: 0.422104, acc: 60.94%, op_acc: 45.31%] [G loss: 0.819868]\n",
      "epoch:25 step:19770[D loss: 0.423208, acc: 53.12%, op_acc: 35.94%] [G loss: 0.854587]\n",
      "epoch:25 step:19771[D loss: 0.446150, acc: 64.84%, op_acc: 34.38%] [G loss: 0.860328]\n",
      "epoch:25 step:19772[D loss: 0.409443, acc: 65.62%, op_acc: 43.75%] [G loss: 0.821931]\n",
      "epoch:25 step:19773[D loss: 0.449775, acc: 57.81%, op_acc: 33.59%] [G loss: 0.957644]\n",
      "epoch:25 step:19774[D loss: 0.428480, acc: 60.94%, op_acc: 36.72%] [G loss: 0.823941]\n",
      "epoch:25 step:19775[D loss: 0.441660, acc: 60.16%, op_acc: 34.38%] [G loss: 0.845224]\n",
      "epoch:25 step:19776[D loss: 0.407829, acc: 59.38%, op_acc: 40.62%] [G loss: 0.879057]\n",
      "epoch:25 step:19777[D loss: 0.434795, acc: 57.81%, op_acc: 39.84%] [G loss: 0.843632]\n",
      "epoch:25 step:19778[D loss: 0.406589, acc: 60.94%, op_acc: 39.84%] [G loss: 0.950180]\n",
      "epoch:25 step:19779[D loss: 0.451643, acc: 54.69%, op_acc: 40.62%] [G loss: 0.812362]\n",
      "epoch:25 step:19780[D loss: 0.415944, acc: 54.69%, op_acc: 39.84%] [G loss: 0.871363]\n",
      "epoch:25 step:19781[D loss: 0.434942, acc: 55.47%, op_acc: 38.28%] [G loss: 0.906333]\n",
      "epoch:25 step:19782[D loss: 0.438229, acc: 54.69%, op_acc: 39.84%] [G loss: 0.903966]\n",
      "epoch:25 step:19783[D loss: 0.422204, acc: 60.16%, op_acc: 40.62%] [G loss: 0.885311]\n",
      "epoch:25 step:19784[D loss: 0.429172, acc: 60.94%, op_acc: 32.81%] [G loss: 0.841713]\n",
      "epoch:25 step:19785[D loss: 0.419345, acc: 57.81%, op_acc: 40.62%] [G loss: 0.885697]\n",
      "epoch:25 step:19786[D loss: 0.423426, acc: 60.94%, op_acc: 36.72%] [G loss: 0.898558]\n",
      "epoch:25 step:19787[D loss: 0.427083, acc: 61.72%, op_acc: 39.84%] [G loss: 0.884294]\n",
      "epoch:25 step:19788[D loss: 0.425523, acc: 56.25%, op_acc: 34.38%] [G loss: 0.866650]\n",
      "epoch:25 step:19789[D loss: 0.425071, acc: 63.28%, op_acc: 39.84%] [G loss: 0.926412]\n",
      "epoch:25 step:19790[D loss: 0.426325, acc: 57.81%, op_acc: 39.84%] [G loss: 0.775239]\n",
      "epoch:25 step:19791[D loss: 0.433367, acc: 54.69%, op_acc: 42.97%] [G loss: 0.920758]\n",
      "epoch:25 step:19792[D loss: 0.429380, acc: 55.47%, op_acc: 35.16%] [G loss: 0.913169]\n",
      "epoch:25 step:19793[D loss: 0.410225, acc: 60.16%, op_acc: 41.41%] [G loss: 0.893162]\n",
      "epoch:25 step:19794[D loss: 0.405766, acc: 59.38%, op_acc: 44.53%] [G loss: 0.894450]\n",
      "epoch:25 step:19795[D loss: 0.379494, acc: 69.53%, op_acc: 46.09%] [G loss: 0.925387]\n",
      "epoch:25 step:19796[D loss: 0.437381, acc: 61.72%, op_acc: 37.50%] [G loss: 0.917254]\n",
      "epoch:25 step:19797[D loss: 0.384719, acc: 72.66%, op_acc: 36.72%] [G loss: 0.868028]\n",
      "epoch:25 step:19798[D loss: 0.430395, acc: 50.78%, op_acc: 39.84%] [G loss: 0.879235]\n",
      "epoch:25 step:19799[D loss: 0.433329, acc: 53.91%, op_acc: 39.84%] [G loss: 0.871500]\n",
      "epoch:25 step:19800[D loss: 0.430208, acc: 54.69%, op_acc: 39.06%] [G loss: 0.907765]\n",
      "##############\n",
      "[0.86065472 0.86284044 0.80894755 0.82068866 0.79814009 0.83124486\n",
      " 0.86987437 0.83196788 0.8101861  0.82154141]\n",
      "##########\n",
      "epoch:25 step:19801[D loss: 0.438783, acc: 50.78%, op_acc: 42.19%] [G loss: 0.930178]\n",
      "epoch:25 step:19802[D loss: 0.400382, acc: 64.84%, op_acc: 37.50%] [G loss: 0.963363]\n",
      "epoch:25 step:19803[D loss: 0.462477, acc: 53.12%, op_acc: 39.84%] [G loss: 0.879748]\n",
      "epoch:25 step:19804[D loss: 0.475088, acc: 50.00%, op_acc: 38.28%] [G loss: 0.845919]\n",
      "epoch:25 step:19805[D loss: 0.382792, acc: 67.19%, op_acc: 47.66%] [G loss: 0.835280]\n",
      "epoch:25 step:19806[D loss: 0.412070, acc: 64.06%, op_acc: 35.94%] [G loss: 0.851751]\n",
      "epoch:25 step:19807[D loss: 0.475583, acc: 53.91%, op_acc: 35.94%] [G loss: 0.901576]\n",
      "epoch:25 step:19808[D loss: 0.391949, acc: 66.41%, op_acc: 45.31%] [G loss: 0.854399]\n",
      "epoch:25 step:19809[D loss: 0.427621, acc: 60.94%, op_acc: 37.50%] [G loss: 0.903554]\n",
      "epoch:25 step:19810[D loss: 0.408110, acc: 60.94%, op_acc: 43.75%] [G loss: 0.886037]\n",
      "epoch:25 step:19811[D loss: 0.426273, acc: 63.28%, op_acc: 33.59%] [G loss: 0.960010]\n",
      "epoch:25 step:19812[D loss: 0.432863, acc: 53.91%, op_acc: 42.97%] [G loss: 0.844769]\n",
      "epoch:25 step:19813[D loss: 0.413253, acc: 61.72%, op_acc: 39.06%] [G loss: 0.862063]\n",
      "epoch:25 step:19814[D loss: 0.478262, acc: 50.78%, op_acc: 33.59%] [G loss: 0.820306]\n",
      "epoch:25 step:19815[D loss: 0.404104, acc: 67.19%, op_acc: 36.72%] [G loss: 0.844014]\n",
      "epoch:25 step:19816[D loss: 0.417598, acc: 60.94%, op_acc: 40.62%] [G loss: 0.916459]\n",
      "epoch:25 step:19817[D loss: 0.426124, acc: 58.59%, op_acc: 36.72%] [G loss: 0.905427]\n",
      "epoch:25 step:19818[D loss: 0.426004, acc: 57.03%, op_acc: 39.84%] [G loss: 0.874182]\n",
      "epoch:25 step:19819[D loss: 0.436843, acc: 52.34%, op_acc: 34.38%] [G loss: 0.916637]\n",
      "epoch:25 step:19820[D loss: 0.412142, acc: 62.50%, op_acc: 39.06%] [G loss: 0.954071]\n",
      "epoch:25 step:19821[D loss: 0.431109, acc: 57.03%, op_acc: 39.06%] [G loss: 0.945374]\n",
      "epoch:25 step:19822[D loss: 0.479426, acc: 47.66%, op_acc: 36.72%] [G loss: 0.832550]\n",
      "epoch:25 step:19823[D loss: 0.427604, acc: 57.81%, op_acc: 40.62%] [G loss: 0.986886]\n",
      "epoch:25 step:19824[D loss: 0.441314, acc: 56.25%, op_acc: 39.06%] [G loss: 0.875942]\n",
      "epoch:25 step:19825[D loss: 0.438423, acc: 57.81%, op_acc: 40.62%] [G loss: 0.865370]\n",
      "epoch:25 step:19826[D loss: 0.452384, acc: 56.25%, op_acc: 36.72%] [G loss: 0.847155]\n",
      "epoch:25 step:19827[D loss: 0.404633, acc: 58.59%, op_acc: 40.62%] [G loss: 0.857156]\n",
      "epoch:25 step:19828[D loss: 0.432409, acc: 58.59%, op_acc: 36.72%] [G loss: 0.934767]\n",
      "epoch:25 step:19829[D loss: 0.397722, acc: 67.97%, op_acc: 43.75%] [G loss: 0.844753]\n",
      "epoch:25 step:19830[D loss: 0.440405, acc: 56.25%, op_acc: 37.50%] [G loss: 0.960236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19831[D loss: 0.444559, acc: 63.28%, op_acc: 31.25%] [G loss: 0.949469]\n",
      "epoch:25 step:19832[D loss: 0.429500, acc: 53.12%, op_acc: 42.19%] [G loss: 0.942969]\n",
      "epoch:25 step:19833[D loss: 0.410379, acc: 68.75%, op_acc: 37.50%] [G loss: 0.903493]\n",
      "epoch:25 step:19834[D loss: 0.455260, acc: 50.78%, op_acc: 35.16%] [G loss: 0.804300]\n",
      "epoch:25 step:19835[D loss: 0.434324, acc: 54.69%, op_acc: 35.16%] [G loss: 0.847851]\n",
      "epoch:25 step:19836[D loss: 0.424967, acc: 60.94%, op_acc: 39.06%] [G loss: 0.859922]\n",
      "epoch:25 step:19837[D loss: 0.440635, acc: 56.25%, op_acc: 35.16%] [G loss: 0.852097]\n",
      "epoch:25 step:19838[D loss: 0.436354, acc: 57.03%, op_acc: 38.28%] [G loss: 0.922925]\n",
      "epoch:25 step:19839[D loss: 0.432154, acc: 55.47%, op_acc: 39.06%] [G loss: 0.849041]\n",
      "epoch:25 step:19840[D loss: 0.451971, acc: 48.44%, op_acc: 35.94%] [G loss: 0.849935]\n",
      "epoch:25 step:19841[D loss: 0.442624, acc: 56.25%, op_acc: 37.50%] [G loss: 0.855994]\n",
      "epoch:25 step:19842[D loss: 0.428277, acc: 62.50%, op_acc: 42.97%] [G loss: 0.903669]\n",
      "epoch:25 step:19843[D loss: 0.465040, acc: 49.22%, op_acc: 33.59%] [G loss: 0.965129]\n",
      "epoch:25 step:19844[D loss: 0.408851, acc: 62.50%, op_acc: 38.28%] [G loss: 0.859299]\n",
      "epoch:25 step:19845[D loss: 0.414643, acc: 64.84%, op_acc: 39.06%] [G loss: 0.889763]\n",
      "epoch:25 step:19846[D loss: 0.447961, acc: 52.34%, op_acc: 39.06%] [G loss: 0.947599]\n",
      "epoch:25 step:19847[D loss: 0.428130, acc: 63.28%, op_acc: 37.50%] [G loss: 0.854037]\n",
      "epoch:25 step:19848[D loss: 0.420346, acc: 60.94%, op_acc: 37.50%] [G loss: 0.838028]\n",
      "epoch:25 step:19849[D loss: 0.446447, acc: 54.69%, op_acc: 31.25%] [G loss: 0.838905]\n",
      "epoch:25 step:19850[D loss: 0.420298, acc: 61.72%, op_acc: 43.75%] [G loss: 0.835475]\n",
      "##############\n",
      "[0.85084864 0.84601591 0.81189314 0.81919176 0.80665464 0.82545908\n",
      " 0.88442699 0.82121975 0.79846397 0.84441207]\n",
      "##########\n",
      "epoch:25 step:19851[D loss: 0.423797, acc: 56.25%, op_acc: 41.41%] [G loss: 0.832170]\n",
      "epoch:25 step:19852[D loss: 0.429917, acc: 60.16%, op_acc: 36.72%] [G loss: 0.903302]\n",
      "epoch:25 step:19853[D loss: 0.441827, acc: 56.25%, op_acc: 38.28%] [G loss: 0.856619]\n",
      "epoch:25 step:19854[D loss: 0.427768, acc: 55.47%, op_acc: 39.06%] [G loss: 0.883366]\n",
      "epoch:25 step:19855[D loss: 0.423572, acc: 51.56%, op_acc: 39.84%] [G loss: 0.855686]\n",
      "epoch:25 step:19856[D loss: 0.410269, acc: 59.38%, op_acc: 40.62%] [G loss: 0.830895]\n",
      "epoch:25 step:19857[D loss: 0.401974, acc: 62.50%, op_acc: 43.75%] [G loss: 0.899731]\n",
      "epoch:25 step:19858[D loss: 0.447892, acc: 53.91%, op_acc: 36.72%] [G loss: 0.913743]\n",
      "epoch:25 step:19859[D loss: 0.424105, acc: 57.03%, op_acc: 42.19%] [G loss: 0.872800]\n",
      "epoch:25 step:19860[D loss: 0.444006, acc: 53.12%, op_acc: 35.16%] [G loss: 0.895095]\n",
      "epoch:25 step:19861[D loss: 0.461626, acc: 57.03%, op_acc: 39.06%] [G loss: 0.834001]\n",
      "epoch:25 step:19862[D loss: 0.462175, acc: 54.69%, op_acc: 32.03%] [G loss: 0.928498]\n",
      "epoch:25 step:19863[D loss: 0.409502, acc: 62.50%, op_acc: 43.75%] [G loss: 0.864428]\n",
      "epoch:25 step:19864[D loss: 0.451644, acc: 56.25%, op_acc: 36.72%] [G loss: 0.842409]\n",
      "epoch:25 step:19865[D loss: 0.434682, acc: 53.91%, op_acc: 39.84%] [G loss: 0.872974]\n",
      "epoch:25 step:19866[D loss: 0.407548, acc: 66.41%, op_acc: 37.50%] [G loss: 0.861132]\n",
      "epoch:25 step:19867[D loss: 0.443084, acc: 60.16%, op_acc: 32.03%] [G loss: 0.820169]\n",
      "epoch:25 step:19868[D loss: 0.436309, acc: 58.59%, op_acc: 35.16%] [G loss: 0.997133]\n",
      "epoch:25 step:19869[D loss: 0.421369, acc: 60.16%, op_acc: 39.06%] [G loss: 0.892720]\n",
      "epoch:25 step:19870[D loss: 0.394239, acc: 68.75%, op_acc: 44.53%] [G loss: 0.891847]\n",
      "epoch:25 step:19871[D loss: 0.413539, acc: 58.59%, op_acc: 38.28%] [G loss: 0.949021]\n",
      "epoch:25 step:19872[D loss: 0.394879, acc: 62.50%, op_acc: 43.75%] [G loss: 0.883462]\n",
      "epoch:25 step:19873[D loss: 0.417051, acc: 59.38%, op_acc: 40.62%] [G loss: 0.865908]\n",
      "epoch:25 step:19874[D loss: 0.408351, acc: 61.72%, op_acc: 42.19%] [G loss: 0.876183]\n",
      "epoch:25 step:19875[D loss: 0.432128, acc: 59.38%, op_acc: 34.38%] [G loss: 0.943561]\n",
      "epoch:25 step:19876[D loss: 0.446306, acc: 57.81%, op_acc: 33.59%] [G loss: 0.819688]\n",
      "epoch:25 step:19877[D loss: 0.424439, acc: 62.50%, op_acc: 32.81%] [G loss: 0.933463]\n",
      "epoch:25 step:19878[D loss: 0.377715, acc: 66.41%, op_acc: 46.88%] [G loss: 0.829581]\n",
      "epoch:25 step:19879[D loss: 0.430312, acc: 60.94%, op_acc: 33.59%] [G loss: 0.911713]\n",
      "epoch:25 step:19880[D loss: 0.438037, acc: 50.00%, op_acc: 41.41%] [G loss: 0.879562]\n",
      "epoch:25 step:19881[D loss: 0.408247, acc: 60.94%, op_acc: 38.28%] [G loss: 0.906038]\n",
      "epoch:25 step:19882[D loss: 0.441864, acc: 60.16%, op_acc: 38.28%] [G loss: 0.858015]\n",
      "epoch:25 step:19883[D loss: 0.409901, acc: 65.62%, op_acc: 40.62%] [G loss: 0.857613]\n",
      "epoch:25 step:19884[D loss: 0.409097, acc: 59.38%, op_acc: 39.06%] [G loss: 0.932275]\n",
      "epoch:25 step:19885[D loss: 0.421585, acc: 60.94%, op_acc: 42.19%] [G loss: 0.897110]\n",
      "epoch:25 step:19886[D loss: 0.432938, acc: 57.81%, op_acc: 38.28%] [G loss: 0.856541]\n",
      "epoch:25 step:19887[D loss: 0.404888, acc: 67.97%, op_acc: 41.41%] [G loss: 0.855116]\n",
      "epoch:25 step:19888[D loss: 0.417187, acc: 59.38%, op_acc: 39.84%] [G loss: 0.924102]\n",
      "epoch:25 step:19889[D loss: 0.407161, acc: 63.28%, op_acc: 39.06%] [G loss: 0.903922]\n",
      "epoch:25 step:19890[D loss: 0.391343, acc: 62.50%, op_acc: 38.28%] [G loss: 0.894527]\n",
      "epoch:25 step:19891[D loss: 0.401232, acc: 62.50%, op_acc: 39.84%] [G loss: 0.864075]\n",
      "epoch:25 step:19892[D loss: 0.429777, acc: 60.16%, op_acc: 39.06%] [G loss: 0.885553]\n",
      "epoch:25 step:19893[D loss: 0.435729, acc: 53.91%, op_acc: 40.62%] [G loss: 0.909645]\n",
      "epoch:25 step:19894[D loss: 0.445039, acc: 58.59%, op_acc: 38.28%] [G loss: 0.918188]\n",
      "epoch:25 step:19895[D loss: 0.430446, acc: 57.03%, op_acc: 39.06%] [G loss: 0.848643]\n",
      "epoch:25 step:19896[D loss: 0.397294, acc: 57.03%, op_acc: 46.88%] [G loss: 0.791425]\n",
      "epoch:25 step:19897[D loss: 0.401851, acc: 66.41%, op_acc: 42.19%] [G loss: 0.872029]\n",
      "epoch:25 step:19898[D loss: 0.426743, acc: 51.56%, op_acc: 41.41%] [G loss: 0.848799]\n",
      "epoch:25 step:19899[D loss: 0.444958, acc: 57.03%, op_acc: 38.28%] [G loss: 0.917472]\n",
      "epoch:25 step:19900[D loss: 0.423558, acc: 57.81%, op_acc: 36.72%] [G loss: 0.872253]\n",
      "##############\n",
      "[0.84348099 0.83096407 0.82741547 0.80663482 0.79509987 0.80514251\n",
      " 0.8935716  0.83727164 0.80612356 0.8303657 ]\n",
      "##########\n",
      "epoch:25 step:19901[D loss: 0.428580, acc: 60.94%, op_acc: 39.06%] [G loss: 0.864452]\n",
      "epoch:25 step:19902[D loss: 0.420431, acc: 59.38%, op_acc: 42.97%] [G loss: 0.858154]\n",
      "epoch:25 step:19903[D loss: 0.433324, acc: 60.16%, op_acc: 39.06%] [G loss: 0.941313]\n",
      "epoch:25 step:19904[D loss: 0.386194, acc: 68.75%, op_acc: 49.22%] [G loss: 0.849503]\n",
      "epoch:25 step:19905[D loss: 0.428333, acc: 57.03%, op_acc: 42.19%] [G loss: 0.884776]\n",
      "epoch:25 step:19906[D loss: 0.412456, acc: 60.94%, op_acc: 46.09%] [G loss: 0.860354]\n",
      "epoch:25 step:19907[D loss: 0.442802, acc: 56.25%, op_acc: 37.50%] [G loss: 0.929189]\n",
      "epoch:25 step:19908[D loss: 0.405249, acc: 60.94%, op_acc: 49.22%] [G loss: 0.922484]\n",
      "epoch:25 step:19909[D loss: 0.440035, acc: 56.25%, op_acc: 33.59%] [G loss: 0.826847]\n",
      "epoch:25 step:19910[D loss: 0.399814, acc: 62.50%, op_acc: 43.75%] [G loss: 0.824706]\n",
      "epoch:25 step:19911[D loss: 0.400654, acc: 64.84%, op_acc: 36.72%] [G loss: 0.925869]\n",
      "epoch:25 step:19912[D loss: 0.460490, acc: 52.34%, op_acc: 35.16%] [G loss: 0.856455]\n",
      "epoch:25 step:19913[D loss: 0.417564, acc: 69.53%, op_acc: 37.50%] [G loss: 0.904452]\n",
      "epoch:25 step:19914[D loss: 0.432734, acc: 60.16%, op_acc: 36.72%] [G loss: 0.872430]\n",
      "epoch:25 step:19915[D loss: 0.448527, acc: 52.34%, op_acc: 39.06%] [G loss: 0.849505]\n",
      "epoch:25 step:19916[D loss: 0.407839, acc: 59.38%, op_acc: 42.19%] [G loss: 0.905911]\n",
      "epoch:25 step:19917[D loss: 0.437584, acc: 54.69%, op_acc: 37.50%] [G loss: 0.912160]\n",
      "epoch:25 step:19918[D loss: 0.424841, acc: 61.72%, op_acc: 38.28%] [G loss: 0.858477]\n",
      "epoch:25 step:19919[D loss: 0.427329, acc: 57.03%, op_acc: 33.59%] [G loss: 0.858051]\n",
      "epoch:25 step:19920[D loss: 0.438084, acc: 59.38%, op_acc: 36.72%] [G loss: 0.921171]\n",
      "epoch:25 step:19921[D loss: 0.410516, acc: 59.38%, op_acc: 36.72%] [G loss: 0.959256]\n",
      "epoch:25 step:19922[D loss: 0.432117, acc: 60.16%, op_acc: 39.84%] [G loss: 0.832076]\n",
      "epoch:25 step:19923[D loss: 0.410604, acc: 63.28%, op_acc: 45.31%] [G loss: 0.904278]\n",
      "epoch:25 step:19924[D loss: 0.443990, acc: 55.47%, op_acc: 36.72%] [G loss: 0.827909]\n",
      "epoch:25 step:19925[D loss: 0.396903, acc: 67.19%, op_acc: 39.84%] [G loss: 0.876989]\n",
      "epoch:25 step:19926[D loss: 0.427171, acc: 54.69%, op_acc: 38.28%] [G loss: 0.836428]\n",
      "epoch:25 step:19927[D loss: 0.435083, acc: 61.72%, op_acc: 35.16%] [G loss: 0.956967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19928[D loss: 0.415388, acc: 61.72%, op_acc: 35.16%] [G loss: 0.861734]\n",
      "epoch:25 step:19929[D loss: 0.401936, acc: 64.84%, op_acc: 42.19%] [G loss: 0.873850]\n",
      "epoch:25 step:19930[D loss: 0.450220, acc: 53.12%, op_acc: 43.75%] [G loss: 0.860513]\n",
      "epoch:25 step:19931[D loss: 0.439708, acc: 60.16%, op_acc: 36.72%] [G loss: 0.803204]\n",
      "epoch:25 step:19932[D loss: 0.422756, acc: 63.28%, op_acc: 34.38%] [G loss: 0.896937]\n",
      "epoch:25 step:19933[D loss: 0.407065, acc: 60.16%, op_acc: 39.84%] [G loss: 0.927069]\n",
      "epoch:25 step:19934[D loss: 0.421137, acc: 54.69%, op_acc: 42.19%] [G loss: 0.864632]\n",
      "epoch:25 step:19935[D loss: 0.414693, acc: 58.59%, op_acc: 46.09%] [G loss: 0.919755]\n",
      "epoch:25 step:19936[D loss: 0.428834, acc: 59.38%, op_acc: 34.38%] [G loss: 0.909071]\n",
      "epoch:25 step:19937[D loss: 0.414864, acc: 59.38%, op_acc: 42.97%] [G loss: 0.902062]\n",
      "epoch:25 step:19938[D loss: 0.416072, acc: 63.28%, op_acc: 35.16%] [G loss: 0.950813]\n",
      "epoch:25 step:19939[D loss: 0.429722, acc: 50.78%, op_acc: 39.06%] [G loss: 0.840977]\n",
      "epoch:25 step:19940[D loss: 0.402769, acc: 63.28%, op_acc: 42.97%] [G loss: 0.830989]\n",
      "epoch:25 step:19941[D loss: 0.416809, acc: 60.16%, op_acc: 35.94%] [G loss: 0.876500]\n",
      "epoch:25 step:19942[D loss: 0.423923, acc: 61.72%, op_acc: 42.19%] [G loss: 0.835859]\n",
      "epoch:25 step:19943[D loss: 0.418400, acc: 63.28%, op_acc: 41.41%] [G loss: 0.814111]\n",
      "epoch:25 step:19944[D loss: 0.404762, acc: 67.97%, op_acc: 39.06%] [G loss: 0.920450]\n",
      "epoch:25 step:19945[D loss: 0.434468, acc: 63.28%, op_acc: 35.94%] [G loss: 0.864298]\n",
      "epoch:25 step:19946[D loss: 0.427970, acc: 60.94%, op_acc: 38.28%] [G loss: 0.869570]\n",
      "epoch:25 step:19947[D loss: 0.408529, acc: 61.72%, op_acc: 43.75%] [G loss: 0.861220]\n",
      "epoch:25 step:19948[D loss: 0.412281, acc: 65.62%, op_acc: 40.62%] [G loss: 0.901046]\n",
      "epoch:25 step:19949[D loss: 0.438568, acc: 59.38%, op_acc: 39.06%] [G loss: 0.816384]\n",
      "epoch:25 step:19950[D loss: 0.455854, acc: 49.22%, op_acc: 35.16%] [G loss: 0.858999]\n",
      "##############\n",
      "[0.86396818 0.86166228 0.80767373 0.81070839 0.78768772 0.84546034\n",
      " 0.88338027 0.81236457 0.79937687 0.83382549]\n",
      "##########\n",
      "epoch:25 step:19951[D loss: 0.430254, acc: 55.47%, op_acc: 36.72%] [G loss: 0.930305]\n",
      "epoch:25 step:19952[D loss: 0.435562, acc: 63.28%, op_acc: 38.28%] [G loss: 0.917925]\n",
      "epoch:25 step:19953[D loss: 0.404612, acc: 60.16%, op_acc: 37.50%] [G loss: 0.951438]\n",
      "epoch:25 step:19954[D loss: 0.424111, acc: 56.25%, op_acc: 35.94%] [G loss: 0.822691]\n",
      "epoch:25 step:19955[D loss: 0.435179, acc: 55.47%, op_acc: 39.84%] [G loss: 0.817734]\n",
      "epoch:25 step:19956[D loss: 0.399596, acc: 67.97%, op_acc: 40.62%] [G loss: 0.921773]\n",
      "epoch:25 step:19957[D loss: 0.403598, acc: 62.50%, op_acc: 46.09%] [G loss: 0.867555]\n",
      "epoch:25 step:19958[D loss: 0.402810, acc: 61.72%, op_acc: 42.97%] [G loss: 0.858190]\n",
      "epoch:25 step:19959[D loss: 0.429836, acc: 56.25%, op_acc: 37.50%] [G loss: 0.889277]\n",
      "epoch:25 step:19960[D loss: 0.422027, acc: 54.69%, op_acc: 39.84%] [G loss: 0.826105]\n",
      "epoch:25 step:19961[D loss: 0.465486, acc: 57.03%, op_acc: 28.12%] [G loss: 0.864750]\n",
      "epoch:25 step:19962[D loss: 0.433962, acc: 59.38%, op_acc: 30.47%] [G loss: 0.893770]\n",
      "epoch:25 step:19963[D loss: 0.423771, acc: 53.91%, op_acc: 39.84%] [G loss: 0.782421]\n",
      "epoch:25 step:19964[D loss: 0.441393, acc: 53.12%, op_acc: 37.50%] [G loss: 0.831501]\n",
      "epoch:25 step:19965[D loss: 0.407955, acc: 60.94%, op_acc: 43.75%] [G loss: 0.882790]\n",
      "epoch:25 step:19966[D loss: 0.423187, acc: 59.38%, op_acc: 38.28%] [G loss: 0.934764]\n",
      "epoch:25 step:19967[D loss: 0.397354, acc: 64.84%, op_acc: 39.06%] [G loss: 0.866487]\n",
      "epoch:25 step:19968[D loss: 0.423580, acc: 57.81%, op_acc: 35.16%] [G loss: 0.858064]\n",
      "epoch:25 step:19969[D loss: 0.424685, acc: 64.06%, op_acc: 40.62%] [G loss: 0.939488]\n",
      "epoch:25 step:19970[D loss: 0.461826, acc: 53.12%, op_acc: 34.38%] [G loss: 0.836862]\n",
      "epoch:25 step:19971[D loss: 0.408334, acc: 63.28%, op_acc: 35.16%] [G loss: 0.762480]\n",
      "epoch:25 step:19972[D loss: 0.439921, acc: 58.59%, op_acc: 35.94%] [G loss: 0.827670]\n",
      "epoch:25 step:19973[D loss: 0.415470, acc: 63.28%, op_acc: 40.62%] [G loss: 0.851344]\n",
      "epoch:25 step:19974[D loss: 0.423113, acc: 60.94%, op_acc: 39.84%] [G loss: 0.787764]\n",
      "epoch:25 step:19975[D loss: 0.436836, acc: 50.78%, op_acc: 35.94%] [G loss: 0.834259]\n",
      "epoch:25 step:19976[D loss: 0.400941, acc: 62.50%, op_acc: 42.19%] [G loss: 0.891282]\n",
      "epoch:25 step:19977[D loss: 0.374600, acc: 65.62%, op_acc: 46.09%] [G loss: 0.932540]\n",
      "epoch:25 step:19978[D loss: 0.418546, acc: 61.72%, op_acc: 40.62%] [G loss: 0.909025]\n",
      "epoch:25 step:19979[D loss: 0.415035, acc: 61.72%, op_acc: 37.50%] [G loss: 0.880119]\n",
      "epoch:25 step:19980[D loss: 0.412620, acc: 63.28%, op_acc: 39.84%] [G loss: 0.841867]\n",
      "epoch:25 step:19981[D loss: 0.466087, acc: 47.66%, op_acc: 38.28%] [G loss: 0.816761]\n",
      "epoch:25 step:19982[D loss: 0.406727, acc: 67.97%, op_acc: 42.19%] [G loss: 0.893168]\n",
      "epoch:25 step:19983[D loss: 0.418226, acc: 60.94%, op_acc: 37.50%] [G loss: 0.873552]\n",
      "epoch:25 step:19984[D loss: 0.399761, acc: 61.72%, op_acc: 46.09%] [G loss: 0.850914]\n",
      "epoch:25 step:19985[D loss: 0.412202, acc: 57.81%, op_acc: 46.09%] [G loss: 0.869463]\n",
      "epoch:25 step:19986[D loss: 0.422848, acc: 60.94%, op_acc: 39.84%] [G loss: 0.878350]\n",
      "epoch:25 step:19987[D loss: 0.432489, acc: 55.47%, op_acc: 37.50%] [G loss: 0.902268]\n",
      "epoch:25 step:19988[D loss: 0.417258, acc: 60.16%, op_acc: 44.53%] [G loss: 0.861884]\n",
      "epoch:25 step:19989[D loss: 0.444221, acc: 55.47%, op_acc: 35.16%] [G loss: 0.801849]\n",
      "epoch:25 step:19990[D loss: 0.426512, acc: 51.56%, op_acc: 42.19%] [G loss: 0.852553]\n",
      "epoch:25 step:19991[D loss: 0.393527, acc: 64.84%, op_acc: 43.75%] [G loss: 0.881605]\n",
      "epoch:25 step:19992[D loss: 0.435095, acc: 55.47%, op_acc: 38.28%] [G loss: 0.905371]\n",
      "epoch:25 step:19993[D loss: 0.407713, acc: 56.25%, op_acc: 41.41%] [G loss: 0.873574]\n",
      "epoch:25 step:19994[D loss: 0.445492, acc: 54.69%, op_acc: 44.53%] [G loss: 0.835183]\n",
      "epoch:25 step:19995[D loss: 0.406783, acc: 60.94%, op_acc: 39.84%] [G loss: 0.945529]\n",
      "epoch:25 step:19996[D loss: 0.437332, acc: 60.16%, op_acc: 39.84%] [G loss: 0.902788]\n",
      "epoch:25 step:19997[D loss: 0.405716, acc: 67.19%, op_acc: 42.19%] [G loss: 0.916131]\n",
      "epoch:25 step:19998[D loss: 0.398165, acc: 60.94%, op_acc: 45.31%] [G loss: 0.884052]\n",
      "epoch:25 step:19999[D loss: 0.414798, acc: 63.28%, op_acc: 42.97%] [G loss: 0.965659]\n",
      "epoch:25 step:20000[D loss: 0.411144, acc: 57.03%, op_acc: 41.41%] [G loss: 0.801402]\n",
      "##############\n",
      "[0.86497729 0.86580397 0.81075259 0.81857044 0.80148216 0.82374475\n",
      " 0.86721906 0.83621248 0.81857997 0.82413538]\n",
      "##########\n",
      "epoch:25 step:20001[D loss: 0.441443, acc: 62.50%, op_acc: 37.50%] [G loss: 0.908095]\n",
      "epoch:25 step:20002[D loss: 0.409127, acc: 64.84%, op_acc: 37.50%] [G loss: 0.815443]\n",
      "epoch:25 step:20003[D loss: 0.384675, acc: 64.84%, op_acc: 46.88%] [G loss: 0.948732]\n",
      "epoch:25 step:20004[D loss: 0.427637, acc: 56.25%, op_acc: 41.41%] [G loss: 0.895049]\n",
      "epoch:25 step:20005[D loss: 0.460623, acc: 57.03%, op_acc: 29.69%] [G loss: 0.897675]\n",
      "epoch:25 step:20006[D loss: 0.500342, acc: 50.00%, op_acc: 34.38%] [G loss: 0.884366]\n",
      "epoch:25 step:20007[D loss: 0.435455, acc: 59.38%, op_acc: 35.94%] [G loss: 0.930386]\n",
      "epoch:25 step:20008[D loss: 0.416233, acc: 59.38%, op_acc: 42.19%] [G loss: 0.922222]\n",
      "epoch:25 step:20009[D loss: 0.415579, acc: 53.91%, op_acc: 42.19%] [G loss: 0.887866]\n",
      "epoch:25 step:20010[D loss: 0.420518, acc: 55.47%, op_acc: 40.62%] [G loss: 0.950247]\n",
      "epoch:25 step:20011[D loss: 0.426564, acc: 57.81%, op_acc: 39.06%] [G loss: 0.908774]\n",
      "epoch:25 step:20012[D loss: 0.418235, acc: 65.62%, op_acc: 36.72%] [G loss: 0.890469]\n",
      "epoch:25 step:20013[D loss: 0.442573, acc: 59.38%, op_acc: 32.81%] [G loss: 0.958832]\n",
      "epoch:25 step:20014[D loss: 0.456684, acc: 50.78%, op_acc: 39.84%] [G loss: 0.857735]\n",
      "epoch:25 step:20015[D loss: 0.390140, acc: 64.06%, op_acc: 51.56%] [G loss: 0.835369]\n",
      "epoch:25 step:20016[D loss: 0.446619, acc: 61.72%, op_acc: 34.38%] [G loss: 0.903878]\n",
      "epoch:25 step:20017[D loss: 0.418524, acc: 62.50%, op_acc: 38.28%] [G loss: 0.831689]\n",
      "epoch:25 step:20018[D loss: 0.422664, acc: 59.38%, op_acc: 42.19%] [G loss: 0.810475]\n",
      "epoch:25 step:20019[D loss: 0.414067, acc: 59.38%, op_acc: 38.28%] [G loss: 0.863488]\n",
      "epoch:25 step:20020[D loss: 0.455063, acc: 50.00%, op_acc: 39.06%] [G loss: 0.850060]\n",
      "epoch:25 step:20021[D loss: 0.403846, acc: 60.16%, op_acc: 46.09%] [G loss: 0.865819]\n",
      "epoch:25 step:20022[D loss: 0.426813, acc: 54.69%, op_acc: 36.72%] [G loss: 0.948214]\n",
      "epoch:25 step:20023[D loss: 0.425128, acc: 58.59%, op_acc: 40.62%] [G loss: 0.963558]\n",
      "epoch:25 step:20024[D loss: 0.445762, acc: 60.16%, op_acc: 35.94%] [G loss: 0.941580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20025[D loss: 0.447845, acc: 57.03%, op_acc: 36.72%] [G loss: 0.889440]\n",
      "epoch:25 step:20026[D loss: 0.421144, acc: 63.28%, op_acc: 37.50%] [G loss: 0.927340]\n",
      "epoch:25 step:20027[D loss: 0.424991, acc: 58.59%, op_acc: 35.94%] [G loss: 0.881077]\n",
      "epoch:25 step:20028[D loss: 0.415441, acc: 61.72%, op_acc: 39.84%] [G loss: 0.860968]\n",
      "epoch:25 step:20029[D loss: 0.429204, acc: 50.78%, op_acc: 35.94%] [G loss: 0.881180]\n",
      "epoch:25 step:20030[D loss: 0.455907, acc: 54.69%, op_acc: 31.25%] [G loss: 0.901979]\n",
      "epoch:25 step:20031[D loss: 0.418974, acc: 56.25%, op_acc: 41.41%] [G loss: 0.944422]\n",
      "epoch:25 step:20032[D loss: 0.401238, acc: 69.53%, op_acc: 39.84%] [G loss: 0.870363]\n",
      "epoch:25 step:20033[D loss: 0.420647, acc: 61.72%, op_acc: 39.84%] [G loss: 0.858771]\n",
      "epoch:25 step:20034[D loss: 0.486560, acc: 49.22%, op_acc: 32.81%] [G loss: 0.861216]\n",
      "epoch:25 step:20035[D loss: 0.428971, acc: 60.16%, op_acc: 41.41%] [G loss: 0.877176]\n",
      "epoch:25 step:20036[D loss: 0.429101, acc: 57.81%, op_acc: 39.06%] [G loss: 0.967230]\n",
      "epoch:25 step:20037[D loss: 0.444745, acc: 52.34%, op_acc: 36.72%] [G loss: 0.870636]\n",
      "epoch:25 step:20038[D loss: 0.463706, acc: 53.12%, op_acc: 35.16%] [G loss: 0.837484]\n",
      "epoch:25 step:20039[D loss: 0.453426, acc: 50.78%, op_acc: 39.84%] [G loss: 0.801885]\n",
      "epoch:25 step:20040[D loss: 0.424250, acc: 63.28%, op_acc: 38.28%] [G loss: 0.885667]\n",
      "epoch:25 step:20041[D loss: 0.436874, acc: 53.91%, op_acc: 35.16%] [G loss: 0.819663]\n",
      "epoch:25 step:20042[D loss: 0.429871, acc: 59.38%, op_acc: 34.38%] [G loss: 0.889888]\n",
      "epoch:25 step:20043[D loss: 0.411510, acc: 61.72%, op_acc: 39.84%] [G loss: 0.878178]\n",
      "epoch:25 step:20044[D loss: 0.404767, acc: 63.28%, op_acc: 38.28%] [G loss: 0.861813]\n",
      "epoch:25 step:20045[D loss: 0.415892, acc: 58.59%, op_acc: 38.28%] [G loss: 0.969390]\n",
      "epoch:25 step:20046[D loss: 0.438615, acc: 60.94%, op_acc: 36.72%] [G loss: 0.904025]\n",
      "epoch:25 step:20047[D loss: 0.447757, acc: 60.16%, op_acc: 34.38%] [G loss: 0.810859]\n",
      "epoch:25 step:20048[D loss: 0.443036, acc: 50.00%, op_acc: 37.50%] [G loss: 0.874409]\n",
      "epoch:25 step:20049[D loss: 0.434392, acc: 57.03%, op_acc: 38.28%] [G loss: 0.860528]\n",
      "epoch:25 step:20050[D loss: 0.404893, acc: 67.19%, op_acc: 38.28%] [G loss: 0.926115]\n",
      "##############\n",
      "[0.85934003 0.84016785 0.83858445 0.80351091 0.78390572 0.81112162\n",
      " 0.88877781 0.83777351 0.79910605 0.84612762]\n",
      "##########\n",
      "epoch:25 step:20051[D loss: 0.469095, acc: 54.69%, op_acc: 32.81%] [G loss: 0.869390]\n",
      "epoch:25 step:20052[D loss: 0.448005, acc: 51.56%, op_acc: 40.62%] [G loss: 0.848823]\n",
      "epoch:25 step:20053[D loss: 0.421578, acc: 60.16%, op_acc: 35.16%] [G loss: 0.864711]\n",
      "epoch:25 step:20054[D loss: 0.420793, acc: 59.38%, op_acc: 39.84%] [G loss: 0.858667]\n",
      "epoch:25 step:20055[D loss: 0.446420, acc: 52.34%, op_acc: 35.16%] [G loss: 0.829697]\n",
      "epoch:25 step:20056[D loss: 0.410567, acc: 67.97%, op_acc: 39.06%] [G loss: 0.879953]\n",
      "epoch:25 step:20057[D loss: 0.433437, acc: 60.94%, op_acc: 34.38%] [G loss: 0.914416]\n",
      "epoch:25 step:20058[D loss: 0.423451, acc: 55.47%, op_acc: 39.84%] [G loss: 0.845998]\n",
      "epoch:25 step:20059[D loss: 0.426785, acc: 55.47%, op_acc: 42.19%] [G loss: 0.875945]\n",
      "epoch:25 step:20060[D loss: 0.416921, acc: 64.06%, op_acc: 40.62%] [G loss: 0.937938]\n",
      "epoch:25 step:20061[D loss: 0.393130, acc: 64.06%, op_acc: 44.53%] [G loss: 0.909460]\n",
      "epoch:25 step:20062[D loss: 0.430727, acc: 57.03%, op_acc: 40.62%] [G loss: 0.871816]\n",
      "epoch:25 step:20063[D loss: 0.416992, acc: 64.06%, op_acc: 42.19%] [G loss: 0.872404]\n",
      "epoch:25 step:20064[D loss: 0.428012, acc: 64.84%, op_acc: 35.16%] [G loss: 0.852272]\n",
      "epoch:25 step:20065[D loss: 0.403857, acc: 61.72%, op_acc: 41.41%] [G loss: 0.858941]\n",
      "epoch:25 step:20066[D loss: 0.406772, acc: 63.28%, op_acc: 39.06%] [G loss: 0.829945]\n",
      "epoch:25 step:20067[D loss: 0.422382, acc: 60.94%, op_acc: 39.06%] [G loss: 0.943519]\n",
      "epoch:25 step:20068[D loss: 0.451355, acc: 57.81%, op_acc: 37.50%] [G loss: 0.933396]\n",
      "epoch:25 step:20069[D loss: 0.427180, acc: 58.59%, op_acc: 46.09%] [G loss: 1.002215]\n",
      "epoch:25 step:20070[D loss: 0.419314, acc: 64.06%, op_acc: 39.84%] [G loss: 0.809306]\n",
      "epoch:25 step:20071[D loss: 0.400383, acc: 63.28%, op_acc: 41.41%] [G loss: 0.884406]\n",
      "epoch:25 step:20072[D loss: 0.460397, acc: 53.12%, op_acc: 32.81%] [G loss: 0.931834]\n",
      "epoch:25 step:20073[D loss: 0.452302, acc: 60.94%, op_acc: 36.72%] [G loss: 0.889563]\n",
      "epoch:25 step:20074[D loss: 0.409098, acc: 60.94%, op_acc: 41.41%] [G loss: 0.840848]\n",
      "epoch:25 step:20075[D loss: 0.417570, acc: 64.06%, op_acc: 42.97%] [G loss: 0.967524]\n",
      "epoch:25 step:20076[D loss: 0.403916, acc: 60.16%, op_acc: 42.97%] [G loss: 0.890507]\n",
      "epoch:25 step:20077[D loss: 0.472348, acc: 56.25%, op_acc: 31.25%] [G loss: 0.796250]\n",
      "epoch:25 step:20078[D loss: 0.409085, acc: 62.50%, op_acc: 36.72%] [G loss: 0.874549]\n",
      "epoch:25 step:20079[D loss: 0.428178, acc: 58.59%, op_acc: 42.19%] [G loss: 0.837005]\n",
      "epoch:25 step:20080[D loss: 0.400547, acc: 55.47%, op_acc: 38.28%] [G loss: 0.901631]\n",
      "epoch:25 step:20081[D loss: 0.434016, acc: 53.91%, op_acc: 40.62%] [G loss: 0.888231]\n",
      "epoch:25 step:20082[D loss: 0.450148, acc: 54.69%, op_acc: 34.38%] [G loss: 0.866612]\n",
      "epoch:25 step:20083[D loss: 0.425223, acc: 61.72%, op_acc: 42.19%] [G loss: 0.872609]\n",
      "epoch:25 step:20084[D loss: 0.451772, acc: 47.66%, op_acc: 39.84%] [G loss: 0.877679]\n",
      "epoch:25 step:20085[D loss: 0.421968, acc: 63.28%, op_acc: 39.84%] [G loss: 0.747166]\n",
      "epoch:25 step:20086[D loss: 0.421459, acc: 57.81%, op_acc: 39.84%] [G loss: 0.829882]\n",
      "epoch:25 step:20087[D loss: 0.425404, acc: 54.69%, op_acc: 40.62%] [G loss: 0.892127]\n",
      "epoch:25 step:20088[D loss: 0.410627, acc: 61.72%, op_acc: 39.06%] [G loss: 0.931364]\n",
      "epoch:25 step:20089[D loss: 0.417785, acc: 61.72%, op_acc: 40.62%] [G loss: 0.980900]\n",
      "epoch:25 step:20090[D loss: 0.408198, acc: 62.50%, op_acc: 39.06%] [G loss: 0.847153]\n",
      "epoch:25 step:20091[D loss: 0.423718, acc: 57.81%, op_acc: 36.72%] [G loss: 0.883541]\n",
      "epoch:25 step:20092[D loss: 0.405591, acc: 64.84%, op_acc: 40.62%] [G loss: 0.919242]\n",
      "epoch:25 step:20093[D loss: 0.402964, acc: 64.06%, op_acc: 44.53%] [G loss: 0.907837]\n",
      "epoch:25 step:20094[D loss: 0.420125, acc: 63.28%, op_acc: 42.19%] [G loss: 0.849974]\n",
      "epoch:25 step:20095[D loss: 0.426403, acc: 52.34%, op_acc: 39.06%] [G loss: 0.842528]\n",
      "epoch:25 step:20096[D loss: 0.380721, acc: 69.53%, op_acc: 46.88%] [G loss: 0.905722]\n",
      "epoch:25 step:20097[D loss: 0.426450, acc: 59.38%, op_acc: 41.41%] [G loss: 0.860838]\n",
      "epoch:25 step:20098[D loss: 0.420284, acc: 53.91%, op_acc: 44.53%] [G loss: 0.895614]\n",
      "epoch:25 step:20099[D loss: 0.448703, acc: 62.50%, op_acc: 32.03%] [G loss: 0.951216]\n",
      "epoch:25 step:20100[D loss: 0.432164, acc: 53.91%, op_acc: 39.06%] [G loss: 0.859681]\n",
      "##############\n",
      "[0.85751843 0.86445981 0.83197464 0.82167809 0.78284118 0.81367888\n",
      " 0.86105007 0.82409762 0.81362787 0.83194506]\n",
      "##########\n",
      "epoch:25 step:20101[D loss: 0.392290, acc: 71.09%, op_acc: 42.19%] [G loss: 0.877900]\n",
      "epoch:25 step:20102[D loss: 0.435633, acc: 58.59%, op_acc: 37.50%] [G loss: 0.921260]\n",
      "epoch:25 step:20103[D loss: 0.472983, acc: 48.44%, op_acc: 32.81%] [G loss: 0.864247]\n",
      "epoch:25 step:20104[D loss: 0.402804, acc: 64.06%, op_acc: 43.75%] [G loss: 0.855370]\n",
      "epoch:25 step:20105[D loss: 0.427435, acc: 64.84%, op_acc: 34.38%] [G loss: 0.860013]\n",
      "epoch:25 step:20106[D loss: 0.413466, acc: 63.28%, op_acc: 40.62%] [G loss: 0.933716]\n",
      "epoch:25 step:20107[D loss: 0.421053, acc: 63.28%, op_acc: 37.50%] [G loss: 0.921876]\n",
      "epoch:25 step:20108[D loss: 0.415541, acc: 62.50%, op_acc: 35.16%] [G loss: 0.853820]\n",
      "epoch:25 step:20109[D loss: 0.453793, acc: 60.16%, op_acc: 30.47%] [G loss: 0.876866]\n",
      "epoch:25 step:20110[D loss: 0.383497, acc: 66.41%, op_acc: 44.53%] [G loss: 0.908939]\n",
      "epoch:25 step:20111[D loss: 0.427739, acc: 57.03%, op_acc: 38.28%] [G loss: 0.855113]\n",
      "epoch:25 step:20112[D loss: 0.397370, acc: 62.50%, op_acc: 38.28%] [G loss: 0.917479]\n",
      "epoch:25 step:20113[D loss: 0.415841, acc: 61.72%, op_acc: 40.62%] [G loss: 0.805068]\n",
      "epoch:25 step:20114[D loss: 0.411408, acc: 57.03%, op_acc: 40.62%] [G loss: 0.885419]\n",
      "epoch:25 step:20115[D loss: 0.441766, acc: 55.47%, op_acc: 36.72%] [G loss: 0.899319]\n",
      "epoch:25 step:20116[D loss: 0.427287, acc: 58.59%, op_acc: 34.38%] [G loss: 0.972029]\n",
      "epoch:25 step:20117[D loss: 0.463679, acc: 46.88%, op_acc: 36.72%] [G loss: 0.938269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20118[D loss: 0.424655, acc: 60.16%, op_acc: 36.72%] [G loss: 0.987469]\n",
      "epoch:25 step:20119[D loss: 0.434607, acc: 54.69%, op_acc: 35.94%] [G loss: 0.875808]\n",
      "epoch:25 step:20120[D loss: 0.427557, acc: 57.81%, op_acc: 30.47%] [G loss: 0.908398]\n",
      "epoch:25 step:20121[D loss: 0.446088, acc: 52.34%, op_acc: 37.50%] [G loss: 0.869571]\n",
      "epoch:25 step:20122[D loss: 0.430686, acc: 49.22%, op_acc: 36.72%] [G loss: 0.849525]\n",
      "epoch:25 step:20123[D loss: 0.415927, acc: 64.06%, op_acc: 41.41%] [G loss: 0.847732]\n",
      "epoch:25 step:20124[D loss: 0.420115, acc: 67.19%, op_acc: 39.06%] [G loss: 0.837568]\n",
      "epoch:25 step:20125[D loss: 0.417249, acc: 63.28%, op_acc: 39.84%] [G loss: 0.883538]\n",
      "epoch:25 step:20126[D loss: 0.429650, acc: 62.50%, op_acc: 42.97%] [G loss: 0.918546]\n",
      "epoch:25 step:20127[D loss: 0.429789, acc: 51.56%, op_acc: 38.28%] [G loss: 0.854762]\n",
      "epoch:25 step:20128[D loss: 0.400843, acc: 62.50%, op_acc: 36.72%] [G loss: 0.821067]\n",
      "epoch:25 step:20129[D loss: 0.431173, acc: 62.50%, op_acc: 36.72%] [G loss: 0.811855]\n",
      "epoch:25 step:20130[D loss: 0.427249, acc: 53.12%, op_acc: 36.72%] [G loss: 0.879095]\n",
      "epoch:25 step:20131[D loss: 0.420348, acc: 58.59%, op_acc: 40.62%] [G loss: 0.900161]\n",
      "epoch:25 step:20132[D loss: 0.437977, acc: 51.56%, op_acc: 39.06%] [G loss: 0.895996]\n",
      "epoch:25 step:20133[D loss: 0.382632, acc: 66.41%, op_acc: 39.06%] [G loss: 0.911539]\n",
      "epoch:25 step:20134[D loss: 0.457188, acc: 46.09%, op_acc: 37.50%] [G loss: 0.847969]\n",
      "epoch:25 step:20135[D loss: 0.434725, acc: 64.84%, op_acc: 35.94%] [G loss: 0.916728]\n",
      "epoch:25 step:20136[D loss: 0.423520, acc: 58.59%, op_acc: 40.62%] [G loss: 0.863820]\n",
      "epoch:25 step:20137[D loss: 0.434492, acc: 57.03%, op_acc: 38.28%] [G loss: 0.837643]\n",
      "epoch:25 step:20138[D loss: 0.414105, acc: 62.50%, op_acc: 37.50%] [G loss: 0.920872]\n",
      "epoch:25 step:20139[D loss: 0.423804, acc: 60.94%, op_acc: 36.72%] [G loss: 0.862899]\n",
      "epoch:25 step:20140[D loss: 0.411917, acc: 57.03%, op_acc: 44.53%] [G loss: 0.906252]\n",
      "epoch:25 step:20141[D loss: 0.423357, acc: 56.25%, op_acc: 43.75%] [G loss: 0.963754]\n",
      "epoch:25 step:20142[D loss: 0.463170, acc: 47.66%, op_acc: 35.16%] [G loss: 0.815071]\n",
      "epoch:25 step:20143[D loss: 0.411762, acc: 55.47%, op_acc: 46.88%] [G loss: 0.893205]\n",
      "epoch:25 step:20144[D loss: 0.429249, acc: 53.12%, op_acc: 39.84%] [G loss: 0.871676]\n",
      "epoch:25 step:20145[D loss: 0.418876, acc: 60.16%, op_acc: 39.84%] [G loss: 0.917336]\n",
      "epoch:25 step:20146[D loss: 0.415233, acc: 63.28%, op_acc: 46.88%] [G loss: 0.918270]\n",
      "epoch:25 step:20147[D loss: 0.452780, acc: 57.81%, op_acc: 35.94%] [G loss: 0.923579]\n",
      "epoch:25 step:20148[D loss: 0.394168, acc: 66.41%, op_acc: 39.84%] [G loss: 0.880373]\n",
      "epoch:25 step:20149[D loss: 0.399765, acc: 66.41%, op_acc: 39.84%] [G loss: 0.953026]\n",
      "epoch:25 step:20150[D loss: 0.434076, acc: 52.34%, op_acc: 42.19%] [G loss: 0.895731]\n",
      "##############\n",
      "[0.85444214 0.85461371 0.79763551 0.79514986 0.77557264 0.82617519\n",
      " 0.91726034 0.80566365 0.80397326 0.83126136]\n",
      "##########\n",
      "epoch:25 step:20151[D loss: 0.403122, acc: 60.16%, op_acc: 42.19%] [G loss: 0.904627]\n",
      "epoch:25 step:20152[D loss: 0.394416, acc: 65.62%, op_acc: 46.09%] [G loss: 0.798342]\n",
      "epoch:25 step:20153[D loss: 0.444674, acc: 53.91%, op_acc: 40.62%] [G loss: 0.844049]\n",
      "epoch:25 step:20154[D loss: 0.428589, acc: 53.91%, op_acc: 38.28%] [G loss: 0.860801]\n",
      "epoch:25 step:20155[D loss: 0.409780, acc: 61.72%, op_acc: 40.62%] [G loss: 0.852461]\n",
      "epoch:25 step:20156[D loss: 0.440975, acc: 62.50%, op_acc: 34.38%] [G loss: 0.865372]\n",
      "epoch:25 step:20157[D loss: 0.411828, acc: 67.97%, op_acc: 39.06%] [G loss: 0.912075]\n",
      "epoch:25 step:20158[D loss: 0.432130, acc: 57.81%, op_acc: 35.16%] [G loss: 0.862568]\n",
      "epoch:25 step:20159[D loss: 0.456768, acc: 48.44%, op_acc: 37.50%] [G loss: 0.843154]\n",
      "epoch:25 step:20160[D loss: 0.416646, acc: 63.28%, op_acc: 38.28%] [G loss: 0.852588]\n",
      "epoch:25 step:20161[D loss: 0.430352, acc: 59.38%, op_acc: 44.53%] [G loss: 0.816742]\n",
      "epoch:25 step:20162[D loss: 0.435332, acc: 49.22%, op_acc: 39.06%] [G loss: 0.873865]\n",
      "epoch:25 step:20163[D loss: 0.426820, acc: 60.16%, op_acc: 37.50%] [G loss: 0.917507]\n",
      "epoch:25 step:20164[D loss: 0.407643, acc: 61.72%, op_acc: 38.28%] [G loss: 0.924598]\n",
      "epoch:25 step:20165[D loss: 0.472175, acc: 45.31%, op_acc: 32.03%] [G loss: 0.831232]\n",
      "epoch:25 step:20166[D loss: 0.429825, acc: 56.25%, op_acc: 37.50%] [G loss: 0.842581]\n",
      "epoch:25 step:20167[D loss: 0.440919, acc: 47.66%, op_acc: 40.62%] [G loss: 0.946401]\n",
      "epoch:25 step:20168[D loss: 0.423298, acc: 64.84%, op_acc: 32.03%] [G loss: 0.892572]\n",
      "epoch:25 step:20169[D loss: 0.417304, acc: 58.59%, op_acc: 39.84%] [G loss: 0.859223]\n",
      "epoch:25 step:20170[D loss: 0.395685, acc: 67.19%, op_acc: 40.62%] [G loss: 0.870653]\n",
      "epoch:25 step:20171[D loss: 0.414946, acc: 66.41%, op_acc: 41.41%] [G loss: 0.885738]\n",
      "epoch:25 step:20172[D loss: 0.434919, acc: 53.91%, op_acc: 36.72%] [G loss: 0.822031]\n",
      "epoch:25 step:20173[D loss: 0.411388, acc: 63.28%, op_acc: 36.72%] [G loss: 0.905704]\n",
      "epoch:25 step:20174[D loss: 0.419652, acc: 64.84%, op_acc: 36.72%] [G loss: 0.883195]\n",
      "epoch:25 step:20175[D loss: 0.477299, acc: 53.91%, op_acc: 34.38%] [G loss: 0.903901]\n",
      "epoch:25 step:20176[D loss: 0.421146, acc: 57.81%, op_acc: 36.72%] [G loss: 0.934581]\n",
      "epoch:25 step:20177[D loss: 0.414866, acc: 63.28%, op_acc: 43.75%] [G loss: 0.896978]\n",
      "epoch:25 step:20178[D loss: 0.383519, acc: 60.94%, op_acc: 47.66%] [G loss: 0.937173]\n",
      "epoch:25 step:20179[D loss: 0.434907, acc: 56.25%, op_acc: 41.41%] [G loss: 0.880327]\n",
      "epoch:25 step:20180[D loss: 0.418556, acc: 61.72%, op_acc: 41.41%] [G loss: 0.887735]\n",
      "epoch:25 step:20181[D loss: 0.431520, acc: 61.72%, op_acc: 37.50%] [G loss: 0.966075]\n",
      "epoch:25 step:20182[D loss: 0.426635, acc: 56.25%, op_acc: 42.97%] [G loss: 0.895127]\n",
      "epoch:25 step:20183[D loss: 0.430968, acc: 58.59%, op_acc: 35.94%] [G loss: 0.868131]\n",
      "epoch:25 step:20184[D loss: 0.423190, acc: 64.06%, op_acc: 31.25%] [G loss: 0.928875]\n",
      "epoch:25 step:20185[D loss: 0.443328, acc: 52.34%, op_acc: 42.19%] [G loss: 0.811058]\n",
      "epoch:25 step:20186[D loss: 0.427427, acc: 53.91%, op_acc: 44.53%] [G loss: 0.895660]\n",
      "epoch:25 step:20187[D loss: 0.413125, acc: 58.59%, op_acc: 40.62%] [G loss: 0.854817]\n",
      "epoch:25 step:20188[D loss: 0.404917, acc: 64.06%, op_acc: 39.06%] [G loss: 0.899124]\n",
      "epoch:25 step:20189[D loss: 0.386768, acc: 66.41%, op_acc: 39.84%] [G loss: 0.897054]\n",
      "epoch:25 step:20190[D loss: 0.451255, acc: 57.03%, op_acc: 32.03%] [G loss: 0.906613]\n",
      "epoch:25 step:20191[D loss: 0.405083, acc: 60.16%, op_acc: 40.62%] [G loss: 0.893019]\n",
      "epoch:25 step:20192[D loss: 0.383413, acc: 64.84%, op_acc: 41.41%] [G loss: 0.919652]\n",
      "epoch:25 step:20193[D loss: 0.436042, acc: 59.38%, op_acc: 37.50%] [G loss: 0.912712]\n",
      "epoch:25 step:20194[D loss: 0.425031, acc: 60.94%, op_acc: 41.41%] [G loss: 0.953559]\n",
      "epoch:25 step:20195[D loss: 0.417643, acc: 61.72%, op_acc: 41.41%] [G loss: 0.799828]\n",
      "epoch:25 step:20196[D loss: 0.406325, acc: 60.94%, op_acc: 37.50%] [G loss: 0.846068]\n",
      "epoch:25 step:20197[D loss: 0.465069, acc: 54.69%, op_acc: 36.72%] [G loss: 0.803468]\n",
      "epoch:25 step:20198[D loss: 0.441329, acc: 49.22%, op_acc: 34.38%] [G loss: 0.849367]\n",
      "epoch:25 step:20199[D loss: 0.399722, acc: 67.97%, op_acc: 41.41%] [G loss: 0.967109]\n",
      "epoch:25 step:20200[D loss: 0.448591, acc: 52.34%, op_acc: 46.09%] [G loss: 0.868162]\n",
      "##############\n",
      "[0.86465826 0.86874259 0.81393458 0.79727183 0.78501511 0.83027641\n",
      " 0.87090683 0.81287303 0.8258688  0.83052672]\n",
      "##########\n",
      "epoch:25 step:20201[D loss: 0.456897, acc: 59.38%, op_acc: 34.38%] [G loss: 0.850479]\n",
      "epoch:25 step:20202[D loss: 0.474900, acc: 45.31%, op_acc: 38.28%] [G loss: 0.849193]\n",
      "epoch:25 step:20203[D loss: 0.421008, acc: 56.25%, op_acc: 39.06%] [G loss: 0.970364]\n",
      "epoch:25 step:20204[D loss: 0.387926, acc: 67.97%, op_acc: 44.53%] [G loss: 0.892891]\n",
      "epoch:25 step:20205[D loss: 0.417259, acc: 61.72%, op_acc: 41.41%] [G loss: 0.934298]\n",
      "epoch:25 step:20206[D loss: 0.427900, acc: 66.41%, op_acc: 33.59%] [G loss: 0.945586]\n",
      "epoch:25 step:20207[D loss: 0.377776, acc: 64.84%, op_acc: 45.31%] [G loss: 0.944357]\n",
      "epoch:25 step:20208[D loss: 0.449230, acc: 50.00%, op_acc: 43.75%] [G loss: 0.835158]\n",
      "epoch:25 step:20209[D loss: 0.450346, acc: 53.91%, op_acc: 36.72%] [G loss: 0.912304]\n",
      "epoch:25 step:20210[D loss: 0.417770, acc: 64.06%, op_acc: 39.06%] [G loss: 0.848935]\n",
      "epoch:25 step:20211[D loss: 0.431214, acc: 56.25%, op_acc: 39.84%] [G loss: 0.849080]\n",
      "epoch:25 step:20212[D loss: 0.415657, acc: 67.19%, op_acc: 40.62%] [G loss: 0.893528]\n",
      "epoch:25 step:20213[D loss: 0.424355, acc: 53.12%, op_acc: 42.97%] [G loss: 0.871074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20214[D loss: 0.428100, acc: 49.22%, op_acc: 40.62%] [G loss: 0.849918]\n",
      "epoch:25 step:20215[D loss: 0.424721, acc: 64.84%, op_acc: 36.72%] [G loss: 0.917364]\n",
      "epoch:25 step:20216[D loss: 0.423077, acc: 61.72%, op_acc: 39.06%] [G loss: 0.929830]\n",
      "epoch:25 step:20217[D loss: 0.428998, acc: 54.69%, op_acc: 40.62%] [G loss: 0.880941]\n",
      "epoch:25 step:20218[D loss: 0.405519, acc: 64.06%, op_acc: 42.19%] [G loss: 0.890446]\n",
      "epoch:25 step:20219[D loss: 0.432823, acc: 53.12%, op_acc: 37.50%] [G loss: 0.886471]\n",
      "epoch:25 step:20220[D loss: 0.421656, acc: 60.94%, op_acc: 38.28%] [G loss: 0.895935]\n",
      "epoch:25 step:20221[D loss: 0.455647, acc: 48.44%, op_acc: 35.94%] [G loss: 0.843836]\n",
      "epoch:25 step:20222[D loss: 0.407053, acc: 64.06%, op_acc: 37.50%] [G loss: 0.869078]\n",
      "epoch:25 step:20223[D loss: 0.410291, acc: 65.62%, op_acc: 41.41%] [G loss: 0.900404]\n",
      "epoch:25 step:20224[D loss: 0.406124, acc: 62.50%, op_acc: 39.84%] [G loss: 0.861362]\n",
      "epoch:25 step:20225[D loss: 0.411157, acc: 63.28%, op_acc: 42.19%] [G loss: 0.906365]\n",
      "epoch:25 step:20226[D loss: 0.430934, acc: 62.50%, op_acc: 32.03%] [G loss: 0.889722]\n",
      "epoch:25 step:20227[D loss: 0.423311, acc: 60.16%, op_acc: 36.72%] [G loss: 0.873275]\n",
      "epoch:25 step:20228[D loss: 0.465674, acc: 47.66%, op_acc: 35.16%] [G loss: 0.813827]\n",
      "epoch:25 step:20229[D loss: 0.384345, acc: 57.03%, op_acc: 46.88%] [G loss: 0.868702]\n",
      "epoch:25 step:20230[D loss: 0.446962, acc: 53.12%, op_acc: 35.16%] [G loss: 0.835557]\n",
      "epoch:25 step:20231[D loss: 0.438691, acc: 60.94%, op_acc: 40.62%] [G loss: 0.876175]\n",
      "epoch:25 step:20232[D loss: 0.435074, acc: 61.72%, op_acc: 37.50%] [G loss: 0.834198]\n",
      "epoch:25 step:20233[D loss: 0.422843, acc: 59.38%, op_acc: 41.41%] [G loss: 0.931544]\n",
      "epoch:25 step:20234[D loss: 0.420691, acc: 60.94%, op_acc: 40.62%] [G loss: 0.837269]\n",
      "epoch:25 step:20235[D loss: 0.385689, acc: 62.50%, op_acc: 47.66%] [G loss: 0.909513]\n",
      "epoch:25 step:20236[D loss: 0.435478, acc: 60.94%, op_acc: 39.06%] [G loss: 0.894093]\n",
      "epoch:25 step:20237[D loss: 0.391692, acc: 61.72%, op_acc: 43.75%] [G loss: 0.941458]\n",
      "epoch:25 step:20238[D loss: 0.417703, acc: 57.81%, op_acc: 43.75%] [G loss: 0.867157]\n",
      "epoch:25 step:20239[D loss: 0.408354, acc: 65.62%, op_acc: 42.19%] [G loss: 0.883227]\n",
      "epoch:25 step:20240[D loss: 0.432541, acc: 55.47%, op_acc: 42.19%] [G loss: 0.828717]\n",
      "epoch:25 step:20241[D loss: 0.435941, acc: 55.47%, op_acc: 35.94%] [G loss: 0.814101]\n",
      "epoch:25 step:20242[D loss: 0.394130, acc: 61.72%, op_acc: 47.66%] [G loss: 0.920572]\n",
      "epoch:25 step:20243[D loss: 0.414114, acc: 59.38%, op_acc: 42.19%] [G loss: 0.962134]\n",
      "epoch:25 step:20244[D loss: 0.432843, acc: 60.94%, op_acc: 42.97%] [G loss: 0.869772]\n",
      "epoch:25 step:20245[D loss: 0.428722, acc: 60.94%, op_acc: 40.62%] [G loss: 0.844509]\n",
      "epoch:25 step:20246[D loss: 0.442334, acc: 46.09%, op_acc: 34.38%] [G loss: 0.815915]\n",
      "epoch:25 step:20247[D loss: 0.456121, acc: 53.91%, op_acc: 38.28%] [G loss: 0.874862]\n",
      "epoch:25 step:20248[D loss: 0.405689, acc: 62.50%, op_acc: 41.41%] [G loss: 0.945274]\n",
      "epoch:25 step:20249[D loss: 0.464800, acc: 54.69%, op_acc: 33.59%] [G loss: 0.912853]\n",
      "epoch:25 step:20250[D loss: 0.429803, acc: 59.38%, op_acc: 42.19%] [G loss: 0.830823]\n",
      "##############\n",
      "[0.84529024 0.86236984 0.82684582 0.80753746 0.80884138 0.81604264\n",
      " 0.91285477 0.8056023  0.79705987 0.81086041]\n",
      "##########\n",
      "epoch:25 step:20251[D loss: 0.422003, acc: 60.16%, op_acc: 40.62%] [G loss: 0.867691]\n",
      "epoch:25 step:20252[D loss: 0.441660, acc: 57.03%, op_acc: 37.50%] [G loss: 0.824778]\n",
      "epoch:25 step:20253[D loss: 0.428641, acc: 64.06%, op_acc: 39.84%] [G loss: 0.803908]\n",
      "epoch:25 step:20254[D loss: 0.432299, acc: 57.81%, op_acc: 38.28%] [G loss: 0.862911]\n",
      "epoch:25 step:20255[D loss: 0.459417, acc: 48.44%, op_acc: 37.50%] [G loss: 0.803602]\n",
      "epoch:25 step:20256[D loss: 0.386737, acc: 64.84%, op_acc: 42.19%] [G loss: 0.879409]\n",
      "epoch:25 step:20257[D loss: 0.434405, acc: 58.59%, op_acc: 37.50%] [G loss: 0.853181]\n",
      "epoch:25 step:20258[D loss: 0.398708, acc: 69.53%, op_acc: 39.84%] [G loss: 0.829274]\n",
      "epoch:25 step:20259[D loss: 0.466148, acc: 53.12%, op_acc: 36.72%] [G loss: 0.847907]\n",
      "epoch:25 step:20260[D loss: 0.418423, acc: 62.50%, op_acc: 39.06%] [G loss: 0.894746]\n",
      "epoch:25 step:20261[D loss: 0.426020, acc: 59.38%, op_acc: 39.06%] [G loss: 0.896402]\n",
      "epoch:25 step:20262[D loss: 0.399978, acc: 62.50%, op_acc: 39.84%] [G loss: 0.890749]\n",
      "epoch:25 step:20263[D loss: 0.416996, acc: 67.19%, op_acc: 44.53%] [G loss: 0.905706]\n",
      "epoch:25 step:20264[D loss: 0.410510, acc: 57.81%, op_acc: 39.84%] [G loss: 0.937771]\n",
      "epoch:25 step:20265[D loss: 0.410054, acc: 68.75%, op_acc: 38.28%] [G loss: 0.829391]\n",
      "epoch:25 step:20266[D loss: 0.408420, acc: 56.25%, op_acc: 41.41%] [G loss: 0.864718]\n",
      "epoch:25 step:20267[D loss: 0.431903, acc: 58.59%, op_acc: 43.75%] [G loss: 0.842664]\n",
      "epoch:25 step:20268[D loss: 0.442091, acc: 57.03%, op_acc: 36.72%] [G loss: 0.839450]\n",
      "epoch:25 step:20269[D loss: 0.399725, acc: 64.84%, op_acc: 46.09%] [G loss: 0.874438]\n",
      "epoch:25 step:20270[D loss: 0.467443, acc: 46.88%, op_acc: 44.53%] [G loss: 0.824064]\n",
      "epoch:25 step:20271[D loss: 0.438703, acc: 60.16%, op_acc: 34.38%] [G loss: 0.863532]\n",
      "epoch:25 step:20272[D loss: 0.429311, acc: 60.16%, op_acc: 42.97%] [G loss: 0.876198]\n",
      "epoch:25 step:20273[D loss: 0.450400, acc: 46.88%, op_acc: 36.72%] [G loss: 0.851842]\n",
      "epoch:25 step:20274[D loss: 0.440220, acc: 56.25%, op_acc: 39.06%] [G loss: 0.855644]\n",
      "epoch:25 step:20275[D loss: 0.435752, acc: 49.22%, op_acc: 41.41%] [G loss: 0.890460]\n",
      "epoch:25 step:20276[D loss: 0.425752, acc: 60.94%, op_acc: 36.72%] [G loss: 0.797571]\n",
      "epoch:25 step:20277[D loss: 0.423166, acc: 60.16%, op_acc: 39.06%] [G loss: 0.924817]\n",
      "epoch:25 step:20278[D loss: 0.388924, acc: 61.72%, op_acc: 42.19%] [G loss: 0.867408]\n",
      "epoch:25 step:20279[D loss: 0.424419, acc: 56.25%, op_acc: 42.97%] [G loss: 0.838548]\n",
      "epoch:25 step:20280[D loss: 0.395913, acc: 68.75%, op_acc: 42.19%] [G loss: 1.022855]\n",
      "epoch:25 step:20281[D loss: 0.442724, acc: 57.03%, op_acc: 42.19%] [G loss: 0.871319]\n",
      "epoch:25 step:20282[D loss: 0.417349, acc: 60.16%, op_acc: 40.62%] [G loss: 0.834600]\n",
      "epoch:25 step:20283[D loss: 0.412855, acc: 60.16%, op_acc: 43.75%] [G loss: 0.845367]\n",
      "epoch:25 step:20284[D loss: 0.401249, acc: 68.75%, op_acc: 42.19%] [G loss: 0.878213]\n",
      "epoch:25 step:20285[D loss: 0.418855, acc: 61.72%, op_acc: 41.41%] [G loss: 0.895112]\n",
      "epoch:25 step:20286[D loss: 0.399239, acc: 60.94%, op_acc: 38.28%] [G loss: 0.855830]\n",
      "epoch:25 step:20287[D loss: 0.450138, acc: 53.12%, op_acc: 38.28%] [G loss: 0.834687]\n",
      "epoch:25 step:20288[D loss: 0.429589, acc: 52.34%, op_acc: 40.62%] [G loss: 0.889469]\n",
      "epoch:25 step:20289[D loss: 0.390627, acc: 64.84%, op_acc: 39.84%] [G loss: 0.926174]\n",
      "epoch:25 step:20290[D loss: 0.408354, acc: 58.59%, op_acc: 38.28%] [G loss: 0.931008]\n",
      "epoch:25 step:20291[D loss: 0.440078, acc: 50.78%, op_acc: 38.28%] [G loss: 0.899290]\n",
      "epoch:25 step:20292[D loss: 0.418745, acc: 58.59%, op_acc: 41.41%] [G loss: 0.804898]\n",
      "epoch:25 step:20293[D loss: 0.442744, acc: 60.94%, op_acc: 38.28%] [G loss: 0.843603]\n",
      "epoch:25 step:20294[D loss: 0.392443, acc: 68.75%, op_acc: 45.31%] [G loss: 0.957057]\n",
      "epoch:25 step:20295[D loss: 0.429493, acc: 61.72%, op_acc: 39.06%] [G loss: 0.892267]\n",
      "epoch:25 step:20296[D loss: 0.477619, acc: 50.00%, op_acc: 36.72%] [G loss: 0.864998]\n",
      "epoch:25 step:20297[D loss: 0.451527, acc: 50.00%, op_acc: 39.84%] [G loss: 0.948424]\n",
      "epoch:25 step:20298[D loss: 0.422107, acc: 62.50%, op_acc: 39.84%] [G loss: 0.894412]\n",
      "epoch:25 step:20299[D loss: 0.403542, acc: 60.94%, op_acc: 42.97%] [G loss: 0.842602]\n",
      "epoch:25 step:20300[D loss: 0.388531, acc: 75.00%, op_acc: 34.38%] [G loss: 0.945764]\n",
      "##############\n",
      "[0.87269505 0.86123476 0.81538695 0.80613453 0.80586297 0.81582934\n",
      " 0.86329675 0.81883898 0.80025862 0.82877159]\n",
      "##########\n",
      "epoch:25 step:20301[D loss: 0.415406, acc: 64.06%, op_acc: 43.75%] [G loss: 0.783984]\n",
      "epoch:25 step:20302[D loss: 0.492088, acc: 42.19%, op_acc: 30.47%] [G loss: 0.840929]\n",
      "epoch:25 step:20303[D loss: 0.410611, acc: 64.06%, op_acc: 40.62%] [G loss: 0.944139]\n",
      "epoch:25 step:20304[D loss: 0.446939, acc: 55.47%, op_acc: 36.72%] [G loss: 0.917948]\n",
      "epoch:25 step:20305[D loss: 0.414477, acc: 60.94%, op_acc: 39.84%] [G loss: 0.854816]\n",
      "epoch:25 step:20306[D loss: 0.432053, acc: 60.16%, op_acc: 41.41%] [G loss: 0.836373]\n",
      "epoch:26 step:20307[D loss: 0.410672, acc: 62.50%, op_acc: 39.84%] [G loss: 0.862829]\n",
      "epoch:26 step:20308[D loss: 0.397724, acc: 60.16%, op_acc: 46.09%] [G loss: 0.868415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20309[D loss: 0.422920, acc: 60.94%, op_acc: 36.72%] [G loss: 0.861609]\n",
      "epoch:26 step:20310[D loss: 0.426894, acc: 57.03%, op_acc: 42.19%] [G loss: 0.897889]\n",
      "epoch:26 step:20311[D loss: 0.425901, acc: 60.16%, op_acc: 42.19%] [G loss: 0.878619]\n",
      "epoch:26 step:20312[D loss: 0.441690, acc: 57.03%, op_acc: 38.28%] [G loss: 0.982240]\n",
      "epoch:26 step:20313[D loss: 0.396493, acc: 64.84%, op_acc: 46.88%] [G loss: 0.867939]\n",
      "epoch:26 step:20314[D loss: 0.443727, acc: 60.16%, op_acc: 36.72%] [G loss: 0.848815]\n",
      "epoch:26 step:20315[D loss: 0.411108, acc: 56.25%, op_acc: 44.53%] [G loss: 0.871890]\n",
      "epoch:26 step:20316[D loss: 0.428466, acc: 56.25%, op_acc: 38.28%] [G loss: 0.939986]\n",
      "epoch:26 step:20317[D loss: 0.464546, acc: 51.56%, op_acc: 35.16%] [G loss: 0.846466]\n",
      "epoch:26 step:20318[D loss: 0.454023, acc: 53.91%, op_acc: 36.72%] [G loss: 0.900640]\n",
      "epoch:26 step:20319[D loss: 0.408494, acc: 60.94%, op_acc: 39.84%] [G loss: 0.899356]\n",
      "epoch:26 step:20320[D loss: 0.463066, acc: 51.56%, op_acc: 39.84%] [G loss: 0.867175]\n",
      "epoch:26 step:20321[D loss: 0.400057, acc: 60.16%, op_acc: 43.75%] [G loss: 0.972183]\n",
      "epoch:26 step:20322[D loss: 0.415708, acc: 60.94%, op_acc: 40.62%] [G loss: 0.923143]\n",
      "epoch:26 step:20323[D loss: 0.391114, acc: 67.19%, op_acc: 41.41%] [G loss: 0.849526]\n",
      "epoch:26 step:20324[D loss: 0.414579, acc: 64.06%, op_acc: 40.62%] [G loss: 0.880147]\n",
      "epoch:26 step:20325[D loss: 0.403301, acc: 63.28%, op_acc: 42.97%] [G loss: 0.850581]\n",
      "epoch:26 step:20326[D loss: 0.399136, acc: 65.62%, op_acc: 36.72%] [G loss: 0.891583]\n",
      "epoch:26 step:20327[D loss: 0.464777, acc: 52.34%, op_acc: 39.06%] [G loss: 0.851142]\n",
      "epoch:26 step:20328[D loss: 0.407561, acc: 59.38%, op_acc: 44.53%] [G loss: 0.862440]\n",
      "epoch:26 step:20329[D loss: 0.453005, acc: 51.56%, op_acc: 39.06%] [G loss: 0.867307]\n",
      "epoch:26 step:20330[D loss: 0.431970, acc: 57.81%, op_acc: 36.72%] [G loss: 0.987555]\n",
      "epoch:26 step:20331[D loss: 0.440599, acc: 57.03%, op_acc: 37.50%] [G loss: 0.848689]\n",
      "epoch:26 step:20332[D loss: 0.426276, acc: 54.69%, op_acc: 41.41%] [G loss: 0.848161]\n",
      "epoch:26 step:20333[D loss: 0.420828, acc: 64.06%, op_acc: 40.62%] [G loss: 0.926622]\n",
      "epoch:26 step:20334[D loss: 0.416792, acc: 56.25%, op_acc: 44.53%] [G loss: 0.866910]\n",
      "epoch:26 step:20335[D loss: 0.417226, acc: 60.16%, op_acc: 36.72%] [G loss: 0.859777]\n",
      "epoch:26 step:20336[D loss: 0.397081, acc: 61.72%, op_acc: 44.53%] [G loss: 0.956424]\n",
      "epoch:26 step:20337[D loss: 0.452211, acc: 57.03%, op_acc: 35.16%] [G loss: 0.952491]\n",
      "epoch:26 step:20338[D loss: 0.404607, acc: 67.19%, op_acc: 37.50%] [G loss: 0.937604]\n",
      "epoch:26 step:20339[D loss: 0.407612, acc: 59.38%, op_acc: 44.53%] [G loss: 0.910983]\n",
      "epoch:26 step:20340[D loss: 0.436775, acc: 59.38%, op_acc: 35.94%] [G loss: 0.858568]\n",
      "epoch:26 step:20341[D loss: 0.416828, acc: 64.84%, op_acc: 35.94%] [G loss: 0.897093]\n",
      "epoch:26 step:20342[D loss: 0.455675, acc: 46.09%, op_acc: 41.41%] [G loss: 0.798198]\n",
      "epoch:26 step:20343[D loss: 0.391175, acc: 64.84%, op_acc: 40.62%] [G loss: 0.962859]\n",
      "epoch:26 step:20344[D loss: 0.437262, acc: 53.91%, op_acc: 35.16%] [G loss: 0.863380]\n",
      "epoch:26 step:20345[D loss: 0.431386, acc: 55.47%, op_acc: 39.06%] [G loss: 0.910110]\n",
      "epoch:26 step:20346[D loss: 0.424025, acc: 60.16%, op_acc: 36.72%] [G loss: 0.874114]\n",
      "epoch:26 step:20347[D loss: 0.412231, acc: 61.72%, op_acc: 39.84%] [G loss: 0.867193]\n",
      "epoch:26 step:20348[D loss: 0.431954, acc: 57.81%, op_acc: 38.28%] [G loss: 0.864320]\n",
      "epoch:26 step:20349[D loss: 0.441986, acc: 59.38%, op_acc: 35.16%] [G loss: 0.898647]\n",
      "epoch:26 step:20350[D loss: 0.425908, acc: 51.56%, op_acc: 42.19%] [G loss: 0.923905]\n",
      "##############\n",
      "[0.86947452 0.86310884 0.79838587 0.81026531 0.8015139  0.83182125\n",
      " 0.88820689 0.82060445 0.81367897 0.82992015]\n",
      "##########\n",
      "epoch:26 step:20351[D loss: 0.389152, acc: 67.97%, op_acc: 44.53%] [G loss: 0.809733]\n",
      "epoch:26 step:20352[D loss: 0.431139, acc: 60.16%, op_acc: 36.72%] [G loss: 0.886620]\n",
      "epoch:26 step:20353[D loss: 0.448256, acc: 58.59%, op_acc: 36.72%] [G loss: 0.913526]\n",
      "epoch:26 step:20354[D loss: 0.438669, acc: 59.38%, op_acc: 31.25%] [G loss: 0.881260]\n",
      "epoch:26 step:20355[D loss: 0.435761, acc: 52.34%, op_acc: 37.50%] [G loss: 0.881231]\n",
      "epoch:26 step:20356[D loss: 0.447744, acc: 60.16%, op_acc: 39.84%] [G loss: 0.824449]\n",
      "epoch:26 step:20357[D loss: 0.400598, acc: 74.22%, op_acc: 34.38%] [G loss: 0.918275]\n",
      "epoch:26 step:20358[D loss: 0.424882, acc: 66.41%, op_acc: 32.03%] [G loss: 0.835817]\n",
      "epoch:26 step:20359[D loss: 0.417519, acc: 62.50%, op_acc: 36.72%] [G loss: 0.850116]\n",
      "epoch:26 step:20360[D loss: 0.427616, acc: 58.59%, op_acc: 42.19%] [G loss: 0.929192]\n",
      "epoch:26 step:20361[D loss: 0.406904, acc: 62.50%, op_acc: 37.50%] [G loss: 0.831353]\n",
      "epoch:26 step:20362[D loss: 0.417394, acc: 60.94%, op_acc: 38.28%] [G loss: 0.918022]\n",
      "epoch:26 step:20363[D loss: 0.418291, acc: 64.84%, op_acc: 37.50%] [G loss: 0.889065]\n",
      "epoch:26 step:20364[D loss: 0.402325, acc: 62.50%, op_acc: 43.75%] [G loss: 0.836665]\n",
      "epoch:26 step:20365[D loss: 0.398940, acc: 63.28%, op_acc: 42.19%] [G loss: 0.880966]\n",
      "epoch:26 step:20366[D loss: 0.455476, acc: 55.47%, op_acc: 33.59%] [G loss: 0.870093]\n",
      "epoch:26 step:20367[D loss: 0.451999, acc: 54.69%, op_acc: 35.94%] [G loss: 0.803368]\n",
      "epoch:26 step:20368[D loss: 0.451282, acc: 52.34%, op_acc: 39.84%] [G loss: 0.785595]\n",
      "epoch:26 step:20369[D loss: 0.436934, acc: 47.66%, op_acc: 38.28%] [G loss: 0.880294]\n",
      "epoch:26 step:20370[D loss: 0.415335, acc: 55.47%, op_acc: 46.09%] [G loss: 0.856832]\n",
      "epoch:26 step:20371[D loss: 0.440995, acc: 48.44%, op_acc: 39.06%] [G loss: 0.858764]\n",
      "epoch:26 step:20372[D loss: 0.424112, acc: 60.94%, op_acc: 42.19%] [G loss: 0.864031]\n",
      "epoch:26 step:20373[D loss: 0.436661, acc: 55.47%, op_acc: 37.50%] [G loss: 0.963505]\n",
      "epoch:26 step:20374[D loss: 0.434551, acc: 56.25%, op_acc: 35.16%] [G loss: 0.864009]\n",
      "epoch:26 step:20375[D loss: 0.394017, acc: 58.59%, op_acc: 42.97%] [G loss: 0.844589]\n",
      "epoch:26 step:20376[D loss: 0.453448, acc: 47.66%, op_acc: 38.28%] [G loss: 0.933494]\n",
      "epoch:26 step:20377[D loss: 0.445192, acc: 54.69%, op_acc: 35.94%] [G loss: 0.894164]\n",
      "epoch:26 step:20378[D loss: 0.414758, acc: 60.16%, op_acc: 43.75%] [G loss: 0.864966]\n",
      "epoch:26 step:20379[D loss: 0.383353, acc: 67.97%, op_acc: 42.19%] [G loss: 0.882237]\n",
      "epoch:26 step:20380[D loss: 0.385689, acc: 62.50%, op_acc: 49.22%] [G loss: 0.910998]\n",
      "epoch:26 step:20381[D loss: 0.396717, acc: 69.53%, op_acc: 35.94%] [G loss: 0.900421]\n",
      "epoch:26 step:20382[D loss: 0.453935, acc: 55.47%, op_acc: 35.16%] [G loss: 0.811719]\n",
      "epoch:26 step:20383[D loss: 0.449861, acc: 57.03%, op_acc: 33.59%] [G loss: 0.888055]\n",
      "epoch:26 step:20384[D loss: 0.451852, acc: 61.72%, op_acc: 29.69%] [G loss: 0.859559]\n",
      "epoch:26 step:20385[D loss: 0.394808, acc: 64.06%, op_acc: 48.44%] [G loss: 0.865033]\n",
      "epoch:26 step:20386[D loss: 0.463579, acc: 53.91%, op_acc: 35.16%] [G loss: 0.931685]\n",
      "epoch:26 step:20387[D loss: 0.438175, acc: 60.16%, op_acc: 33.59%] [G loss: 0.921217]\n",
      "epoch:26 step:20388[D loss: 0.412880, acc: 63.28%, op_acc: 42.19%] [G loss: 0.858182]\n",
      "epoch:26 step:20389[D loss: 0.441099, acc: 57.81%, op_acc: 33.59%] [G loss: 0.899474]\n",
      "epoch:26 step:20390[D loss: 0.420425, acc: 64.84%, op_acc: 42.97%] [G loss: 0.888494]\n",
      "epoch:26 step:20391[D loss: 0.425558, acc: 59.38%, op_acc: 35.16%] [G loss: 0.875079]\n",
      "epoch:26 step:20392[D loss: 0.415527, acc: 63.28%, op_acc: 35.94%] [G loss: 0.901648]\n",
      "epoch:26 step:20393[D loss: 0.424052, acc: 60.16%, op_acc: 38.28%] [G loss: 0.899651]\n",
      "epoch:26 step:20394[D loss: 0.433395, acc: 56.25%, op_acc: 41.41%] [G loss: 0.923235]\n",
      "epoch:26 step:20395[D loss: 0.455971, acc: 58.59%, op_acc: 35.16%] [G loss: 0.912495]\n",
      "epoch:26 step:20396[D loss: 0.400626, acc: 60.94%, op_acc: 42.19%] [G loss: 0.849406]\n",
      "epoch:26 step:20397[D loss: 0.408504, acc: 64.06%, op_acc: 36.72%] [G loss: 0.871296]\n",
      "epoch:26 step:20398[D loss: 0.420319, acc: 66.41%, op_acc: 41.41%] [G loss: 0.834868]\n",
      "epoch:26 step:20399[D loss: 0.394981, acc: 62.50%, op_acc: 43.75%] [G loss: 0.950168]\n",
      "epoch:26 step:20400[D loss: 0.402779, acc: 62.50%, op_acc: 42.97%] [G loss: 0.882362]\n",
      "##############\n",
      "[0.85533774 0.85304618 0.81806762 0.8019571  0.80025748 0.81668195\n",
      " 0.92603009 0.81820698 0.83978602 0.83585012]\n",
      "##########\n",
      "epoch:26 step:20401[D loss: 0.420440, acc: 60.16%, op_acc: 40.62%] [G loss: 0.910751]\n",
      "epoch:26 step:20402[D loss: 0.477545, acc: 50.78%, op_acc: 35.16%] [G loss: 0.853972]\n",
      "epoch:26 step:20403[D loss: 0.420078, acc: 54.69%, op_acc: 39.06%] [G loss: 0.882016]\n",
      "epoch:26 step:20404[D loss: 0.419148, acc: 63.28%, op_acc: 38.28%] [G loss: 0.882246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20405[D loss: 0.402642, acc: 57.81%, op_acc: 39.84%] [G loss: 0.896756]\n",
      "epoch:26 step:20406[D loss: 0.396456, acc: 57.03%, op_acc: 44.53%] [G loss: 0.882284]\n",
      "epoch:26 step:20407[D loss: 0.439252, acc: 59.38%, op_acc: 36.72%] [G loss: 0.875900]\n",
      "epoch:26 step:20408[D loss: 0.433723, acc: 58.59%, op_acc: 38.28%] [G loss: 0.849597]\n",
      "epoch:26 step:20409[D loss: 0.438073, acc: 51.56%, op_acc: 35.94%] [G loss: 0.920152]\n",
      "epoch:26 step:20410[D loss: 0.421959, acc: 62.50%, op_acc: 35.94%] [G loss: 0.922188]\n",
      "epoch:26 step:20411[D loss: 0.415347, acc: 60.16%, op_acc: 45.31%] [G loss: 0.896793]\n",
      "epoch:26 step:20412[D loss: 0.409138, acc: 60.94%, op_acc: 42.19%] [G loss: 0.885427]\n",
      "epoch:26 step:20413[D loss: 0.418082, acc: 62.50%, op_acc: 40.62%] [G loss: 0.845438]\n",
      "epoch:26 step:20414[D loss: 0.459875, acc: 52.34%, op_acc: 34.38%] [G loss: 0.880462]\n",
      "epoch:26 step:20415[D loss: 0.429339, acc: 54.69%, op_acc: 43.75%] [G loss: 0.861270]\n",
      "epoch:26 step:20416[D loss: 0.407029, acc: 55.47%, op_acc: 41.41%] [G loss: 0.839217]\n",
      "epoch:26 step:20417[D loss: 0.438474, acc: 52.34%, op_acc: 39.84%] [G loss: 0.857737]\n",
      "epoch:26 step:20418[D loss: 0.402640, acc: 67.19%, op_acc: 40.62%] [G loss: 0.870221]\n",
      "epoch:26 step:20419[D loss: 0.448734, acc: 53.91%, op_acc: 38.28%] [G loss: 0.889453]\n",
      "epoch:26 step:20420[D loss: 0.410033, acc: 60.94%, op_acc: 42.19%] [G loss: 0.880505]\n",
      "epoch:26 step:20421[D loss: 0.398312, acc: 60.94%, op_acc: 40.62%] [G loss: 0.849262]\n",
      "epoch:26 step:20422[D loss: 0.474404, acc: 44.53%, op_acc: 35.16%] [G loss: 0.868571]\n",
      "epoch:26 step:20423[D loss: 0.435181, acc: 57.03%, op_acc: 46.09%] [G loss: 0.873234]\n",
      "epoch:26 step:20424[D loss: 0.439256, acc: 49.22%, op_acc: 38.28%] [G loss: 0.789846]\n",
      "epoch:26 step:20425[D loss: 0.421424, acc: 59.38%, op_acc: 39.06%] [G loss: 0.895340]\n",
      "epoch:26 step:20426[D loss: 0.417075, acc: 58.59%, op_acc: 34.38%] [G loss: 0.892681]\n",
      "epoch:26 step:20427[D loss: 0.425409, acc: 61.72%, op_acc: 43.75%] [G loss: 0.952689]\n",
      "epoch:26 step:20428[D loss: 0.422312, acc: 60.16%, op_acc: 35.16%] [G loss: 0.854813]\n",
      "epoch:26 step:20429[D loss: 0.435045, acc: 58.59%, op_acc: 40.62%] [G loss: 0.898463]\n",
      "epoch:26 step:20430[D loss: 0.428508, acc: 57.03%, op_acc: 41.41%] [G loss: 0.901428]\n",
      "epoch:26 step:20431[D loss: 0.438364, acc: 53.91%, op_acc: 39.06%] [G loss: 0.843405]\n",
      "epoch:26 step:20432[D loss: 0.453670, acc: 51.56%, op_acc: 38.28%] [G loss: 0.820094]\n",
      "epoch:26 step:20433[D loss: 0.405950, acc: 60.94%, op_acc: 42.97%] [G loss: 0.889711]\n",
      "epoch:26 step:20434[D loss: 0.418218, acc: 63.28%, op_acc: 37.50%] [G loss: 0.825517]\n",
      "epoch:26 step:20435[D loss: 0.423891, acc: 59.38%, op_acc: 37.50%] [G loss: 0.861853]\n",
      "epoch:26 step:20436[D loss: 0.405471, acc: 57.03%, op_acc: 42.97%] [G loss: 0.854324]\n",
      "epoch:26 step:20437[D loss: 0.412934, acc: 66.41%, op_acc: 34.38%] [G loss: 0.920620]\n",
      "epoch:26 step:20438[D loss: 0.408894, acc: 57.81%, op_acc: 44.53%] [G loss: 0.825095]\n",
      "epoch:26 step:20439[D loss: 0.437061, acc: 65.62%, op_acc: 32.03%] [G loss: 0.852066]\n",
      "epoch:26 step:20440[D loss: 0.418161, acc: 58.59%, op_acc: 39.84%] [G loss: 0.868129]\n",
      "epoch:26 step:20441[D loss: 0.421053, acc: 65.62%, op_acc: 37.50%] [G loss: 0.977908]\n",
      "epoch:26 step:20442[D loss: 0.419943, acc: 57.03%, op_acc: 37.50%] [G loss: 0.836502]\n",
      "epoch:26 step:20443[D loss: 0.441113, acc: 53.91%, op_acc: 36.72%] [G loss: 0.925816]\n",
      "epoch:26 step:20444[D loss: 0.431777, acc: 56.25%, op_acc: 36.72%] [G loss: 0.843499]\n",
      "epoch:26 step:20445[D loss: 0.382967, acc: 70.31%, op_acc: 49.22%] [G loss: 0.889361]\n",
      "epoch:26 step:20446[D loss: 0.432184, acc: 57.03%, op_acc: 40.62%] [G loss: 0.838706]\n",
      "epoch:26 step:20447[D loss: 0.439148, acc: 56.25%, op_acc: 34.38%] [G loss: 0.867661]\n",
      "epoch:26 step:20448[D loss: 0.412023, acc: 59.38%, op_acc: 41.41%] [G loss: 0.923584]\n",
      "epoch:26 step:20449[D loss: 0.439707, acc: 55.47%, op_acc: 38.28%] [G loss: 0.866466]\n",
      "epoch:26 step:20450[D loss: 0.420267, acc: 60.16%, op_acc: 40.62%] [G loss: 0.765439]\n",
      "##############\n",
      "[0.85717145 0.84106224 0.81269839 0.80768251 0.7771972  0.8209456\n",
      " 0.8725509  0.81801876 0.80674737 0.83448756]\n",
      "##########\n",
      "epoch:26 step:20451[D loss: 0.405200, acc: 62.50%, op_acc: 42.19%] [G loss: 0.840654]\n",
      "epoch:26 step:20452[D loss: 0.423888, acc: 60.94%, op_acc: 41.41%] [G loss: 0.912026]\n",
      "epoch:26 step:20453[D loss: 0.372944, acc: 75.78%, op_acc: 45.31%] [G loss: 0.884328]\n",
      "epoch:26 step:20454[D loss: 0.412189, acc: 60.94%, op_acc: 39.06%] [G loss: 0.911307]\n",
      "epoch:26 step:20455[D loss: 0.408121, acc: 58.59%, op_acc: 42.97%] [G loss: 0.938229]\n",
      "epoch:26 step:20456[D loss: 0.408815, acc: 59.38%, op_acc: 45.31%] [G loss: 0.924127]\n",
      "epoch:26 step:20457[D loss: 0.412189, acc: 57.03%, op_acc: 36.72%] [G loss: 0.946804]\n",
      "epoch:26 step:20458[D loss: 0.434122, acc: 53.91%, op_acc: 37.50%] [G loss: 0.886621]\n",
      "epoch:26 step:20459[D loss: 0.418801, acc: 58.59%, op_acc: 43.75%] [G loss: 0.870306]\n",
      "epoch:26 step:20460[D loss: 0.412746, acc: 64.84%, op_acc: 33.59%] [G loss: 0.859370]\n",
      "epoch:26 step:20461[D loss: 0.449547, acc: 46.88%, op_acc: 35.94%] [G loss: 0.787533]\n",
      "epoch:26 step:20462[D loss: 0.422173, acc: 61.72%, op_acc: 42.19%] [G loss: 0.844683]\n",
      "epoch:26 step:20463[D loss: 0.441857, acc: 53.91%, op_acc: 36.72%] [G loss: 0.768341]\n",
      "epoch:26 step:20464[D loss: 0.409175, acc: 60.16%, op_acc: 41.41%] [G loss: 0.795554]\n",
      "epoch:26 step:20465[D loss: 0.405515, acc: 62.50%, op_acc: 36.72%] [G loss: 0.904292]\n",
      "epoch:26 step:20466[D loss: 0.479059, acc: 53.91%, op_acc: 34.38%] [G loss: 0.823865]\n",
      "epoch:26 step:20467[D loss: 0.430075, acc: 58.59%, op_acc: 36.72%] [G loss: 0.889110]\n",
      "epoch:26 step:20468[D loss: 0.404968, acc: 60.94%, op_acc: 40.62%] [G loss: 0.924806]\n",
      "epoch:26 step:20469[D loss: 0.420958, acc: 64.06%, op_acc: 37.50%] [G loss: 0.935648]\n",
      "epoch:26 step:20470[D loss: 0.421790, acc: 65.62%, op_acc: 37.50%] [G loss: 0.914282]\n",
      "epoch:26 step:20471[D loss: 0.420528, acc: 54.69%, op_acc: 39.84%] [G loss: 0.817515]\n",
      "epoch:26 step:20472[D loss: 0.424168, acc: 66.41%, op_acc: 40.62%] [G loss: 0.919414]\n",
      "epoch:26 step:20473[D loss: 0.425090, acc: 57.81%, op_acc: 43.75%] [G loss: 0.871943]\n",
      "epoch:26 step:20474[D loss: 0.409357, acc: 59.38%, op_acc: 37.50%] [G loss: 0.940906]\n",
      "epoch:26 step:20475[D loss: 0.455715, acc: 48.44%, op_acc: 39.06%] [G loss: 0.913267]\n",
      "epoch:26 step:20476[D loss: 0.438252, acc: 57.03%, op_acc: 38.28%] [G loss: 0.922226]\n",
      "epoch:26 step:20477[D loss: 0.449137, acc: 56.25%, op_acc: 35.16%] [G loss: 0.784221]\n",
      "epoch:26 step:20478[D loss: 0.427572, acc: 56.25%, op_acc: 36.72%] [G loss: 0.853840]\n",
      "epoch:26 step:20479[D loss: 0.449963, acc: 57.03%, op_acc: 31.25%] [G loss: 0.916759]\n",
      "epoch:26 step:20480[D loss: 0.456783, acc: 52.34%, op_acc: 35.94%] [G loss: 0.847718]\n",
      "epoch:26 step:20481[D loss: 0.423665, acc: 58.59%, op_acc: 39.84%] [G loss: 0.847983]\n",
      "epoch:26 step:20482[D loss: 0.421100, acc: 61.72%, op_acc: 42.97%] [G loss: 0.908286]\n",
      "epoch:26 step:20483[D loss: 0.408814, acc: 60.16%, op_acc: 41.41%] [G loss: 0.822572]\n",
      "epoch:26 step:20484[D loss: 0.429131, acc: 57.03%, op_acc: 39.84%] [G loss: 0.887287]\n",
      "epoch:26 step:20485[D loss: 0.392582, acc: 61.72%, op_acc: 47.66%] [G loss: 0.845946]\n",
      "epoch:26 step:20486[D loss: 0.449745, acc: 56.25%, op_acc: 33.59%] [G loss: 0.820590]\n",
      "epoch:26 step:20487[D loss: 0.413291, acc: 60.94%, op_acc: 39.84%] [G loss: 0.909051]\n",
      "epoch:26 step:20488[D loss: 0.398037, acc: 67.97%, op_acc: 37.50%] [G loss: 0.902100]\n",
      "epoch:26 step:20489[D loss: 0.410171, acc: 61.72%, op_acc: 39.84%] [G loss: 0.906704]\n",
      "epoch:26 step:20490[D loss: 0.417033, acc: 58.59%, op_acc: 39.84%] [G loss: 0.878866]\n",
      "epoch:26 step:20491[D loss: 0.436838, acc: 60.16%, op_acc: 39.06%] [G loss: 0.915756]\n",
      "epoch:26 step:20492[D loss: 0.406266, acc: 62.50%, op_acc: 42.19%] [G loss: 0.898813]\n",
      "epoch:26 step:20493[D loss: 0.422503, acc: 58.59%, op_acc: 43.75%] [G loss: 0.813548]\n",
      "epoch:26 step:20494[D loss: 0.440653, acc: 53.91%, op_acc: 35.94%] [G loss: 0.892572]\n",
      "epoch:26 step:20495[D loss: 0.441118, acc: 55.47%, op_acc: 34.38%] [G loss: 0.927607]\n",
      "epoch:26 step:20496[D loss: 0.470252, acc: 46.09%, op_acc: 37.50%] [G loss: 0.833800]\n",
      "epoch:26 step:20497[D loss: 0.414544, acc: 60.94%, op_acc: 39.06%] [G loss: 0.923845]\n",
      "epoch:26 step:20498[D loss: 0.389578, acc: 75.78%, op_acc: 39.06%] [G loss: 0.906053]\n",
      "epoch:26 step:20499[D loss: 0.447672, acc: 57.03%, op_acc: 35.16%] [G loss: 0.886265]\n",
      "epoch:26 step:20500[D loss: 0.408695, acc: 53.91%, op_acc: 46.09%] [G loss: 0.936548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.85025048 0.87858524 0.80839749 0.80243044 0.79275363 0.82264647\n",
      " 0.90769205 0.83663211 0.78669019 0.83122459]\n",
      "##########\n",
      "epoch:26 step:20501[D loss: 0.419830, acc: 57.81%, op_acc: 39.84%] [G loss: 0.900764]\n",
      "epoch:26 step:20502[D loss: 0.415164, acc: 67.19%, op_acc: 38.28%] [G loss: 0.955724]\n",
      "epoch:26 step:20503[D loss: 0.466551, acc: 51.56%, op_acc: 32.03%] [G loss: 0.918005]\n",
      "epoch:26 step:20504[D loss: 0.441173, acc: 55.47%, op_acc: 42.19%] [G loss: 0.842024]\n",
      "epoch:26 step:20505[D loss: 0.454846, acc: 51.56%, op_acc: 39.06%] [G loss: 0.879350]\n",
      "epoch:26 step:20506[D loss: 0.415554, acc: 63.28%, op_acc: 38.28%] [G loss: 0.903013]\n",
      "epoch:26 step:20507[D loss: 0.408522, acc: 61.72%, op_acc: 39.84%] [G loss: 0.877666]\n",
      "epoch:26 step:20508[D loss: 0.428562, acc: 61.72%, op_acc: 35.94%] [G loss: 0.901268]\n",
      "epoch:26 step:20509[D loss: 0.419874, acc: 62.50%, op_acc: 40.62%] [G loss: 0.803126]\n",
      "epoch:26 step:20510[D loss: 0.420626, acc: 58.59%, op_acc: 36.72%] [G loss: 0.888002]\n",
      "epoch:26 step:20511[D loss: 0.425679, acc: 60.16%, op_acc: 38.28%] [G loss: 0.833512]\n",
      "epoch:26 step:20512[D loss: 0.446404, acc: 53.91%, op_acc: 39.84%] [G loss: 0.847828]\n",
      "epoch:26 step:20513[D loss: 0.392869, acc: 64.84%, op_acc: 38.28%] [G loss: 0.930105]\n",
      "epoch:26 step:20514[D loss: 0.444168, acc: 55.47%, op_acc: 39.06%] [G loss: 0.936466]\n",
      "epoch:26 step:20515[D loss: 0.426785, acc: 54.69%, op_acc: 37.50%] [G loss: 0.838923]\n",
      "epoch:26 step:20516[D loss: 0.456646, acc: 51.56%, op_acc: 37.50%] [G loss: 0.798313]\n",
      "epoch:26 step:20517[D loss: 0.412584, acc: 57.81%, op_acc: 45.31%] [G loss: 0.907117]\n",
      "epoch:26 step:20518[D loss: 0.420759, acc: 58.59%, op_acc: 46.88%] [G loss: 0.872721]\n",
      "epoch:26 step:20519[D loss: 0.394561, acc: 66.41%, op_acc: 39.84%] [G loss: 0.865229]\n",
      "epoch:26 step:20520[D loss: 0.428091, acc: 64.84%, op_acc: 39.06%] [G loss: 0.864698]\n",
      "epoch:26 step:20521[D loss: 0.467548, acc: 53.12%, op_acc: 40.62%] [G loss: 0.848807]\n",
      "epoch:26 step:20522[D loss: 0.442048, acc: 57.81%, op_acc: 37.50%] [G loss: 0.937486]\n",
      "epoch:26 step:20523[D loss: 0.402014, acc: 67.19%, op_acc: 38.28%] [G loss: 0.927410]\n",
      "epoch:26 step:20524[D loss: 0.427800, acc: 59.38%, op_acc: 42.19%] [G loss: 0.868856]\n",
      "epoch:26 step:20525[D loss: 0.396277, acc: 61.72%, op_acc: 45.31%] [G loss: 0.893104]\n",
      "epoch:26 step:20526[D loss: 0.453262, acc: 50.00%, op_acc: 39.84%] [G loss: 0.862662]\n",
      "epoch:26 step:20527[D loss: 0.424786, acc: 61.72%, op_acc: 34.38%] [G loss: 0.852640]\n",
      "epoch:26 step:20528[D loss: 0.426852, acc: 61.72%, op_acc: 39.84%] [G loss: 0.855692]\n",
      "epoch:26 step:20529[D loss: 0.402214, acc: 64.84%, op_acc: 44.53%] [G loss: 0.848847]\n",
      "epoch:26 step:20530[D loss: 0.379036, acc: 71.09%, op_acc: 42.19%] [G loss: 0.899046]\n",
      "epoch:26 step:20531[D loss: 0.429951, acc: 57.03%, op_acc: 42.97%] [G loss: 0.916583]\n",
      "epoch:26 step:20532[D loss: 0.413143, acc: 59.38%, op_acc: 42.97%] [G loss: 0.883965]\n",
      "epoch:26 step:20533[D loss: 0.417059, acc: 58.59%, op_acc: 39.84%] [G loss: 0.902632]\n",
      "epoch:26 step:20534[D loss: 0.420619, acc: 56.25%, op_acc: 42.19%] [G loss: 0.837130]\n",
      "epoch:26 step:20535[D loss: 0.404716, acc: 60.94%, op_acc: 39.06%] [G loss: 0.895730]\n",
      "epoch:26 step:20536[D loss: 0.445602, acc: 61.72%, op_acc: 36.72%] [G loss: 0.813191]\n",
      "epoch:26 step:20537[D loss: 0.414576, acc: 59.38%, op_acc: 39.84%] [G loss: 0.853411]\n",
      "epoch:26 step:20538[D loss: 0.415557, acc: 62.50%, op_acc: 39.84%] [G loss: 0.868439]\n",
      "epoch:26 step:20539[D loss: 0.414127, acc: 65.62%, op_acc: 42.19%] [G loss: 0.806773]\n",
      "epoch:26 step:20540[D loss: 0.459513, acc: 60.94%, op_acc: 32.03%] [G loss: 0.967892]\n",
      "epoch:26 step:20541[D loss: 0.392477, acc: 67.97%, op_acc: 36.72%] [G loss: 0.888168]\n",
      "epoch:26 step:20542[D loss: 0.418469, acc: 68.75%, op_acc: 40.62%] [G loss: 0.793597]\n",
      "epoch:26 step:20543[D loss: 0.436073, acc: 51.56%, op_acc: 40.62%] [G loss: 0.846838]\n",
      "epoch:26 step:20544[D loss: 0.437773, acc: 52.34%, op_acc: 35.94%] [G loss: 0.952146]\n",
      "epoch:26 step:20545[D loss: 0.409034, acc: 60.94%, op_acc: 44.53%] [G loss: 0.923794]\n",
      "epoch:26 step:20546[D loss: 0.434346, acc: 58.59%, op_acc: 40.62%] [G loss: 0.848049]\n",
      "epoch:26 step:20547[D loss: 0.410597, acc: 55.47%, op_acc: 41.41%] [G loss: 0.902760]\n",
      "epoch:26 step:20548[D loss: 0.388920, acc: 61.72%, op_acc: 46.88%] [G loss: 0.860612]\n",
      "epoch:26 step:20549[D loss: 0.441569, acc: 56.25%, op_acc: 39.06%] [G loss: 0.911498]\n",
      "epoch:26 step:20550[D loss: 0.448783, acc: 55.47%, op_acc: 38.28%] [G loss: 0.915464]\n",
      "##############\n",
      "[0.8728272  0.85926887 0.82769415 0.81118614 0.81555557 0.83206276\n",
      " 0.8452491  0.84691602 0.80642966 0.83611036]\n",
      "##########\n",
      "epoch:26 step:20551[D loss: 0.428192, acc: 60.94%, op_acc: 37.50%] [G loss: 0.837642]\n",
      "epoch:26 step:20552[D loss: 0.442382, acc: 58.59%, op_acc: 39.06%] [G loss: 0.833543]\n",
      "epoch:26 step:20553[D loss: 0.415432, acc: 60.94%, op_acc: 33.59%] [G loss: 0.853310]\n",
      "epoch:26 step:20554[D loss: 0.414336, acc: 64.06%, op_acc: 41.41%] [G loss: 0.846335]\n",
      "epoch:26 step:20555[D loss: 0.409622, acc: 65.62%, op_acc: 43.75%] [G loss: 0.812572]\n",
      "epoch:26 step:20556[D loss: 0.458050, acc: 53.91%, op_acc: 33.59%] [G loss: 0.861768]\n",
      "epoch:26 step:20557[D loss: 0.394592, acc: 67.97%, op_acc: 47.66%] [G loss: 0.944750]\n",
      "epoch:26 step:20558[D loss: 0.433808, acc: 56.25%, op_acc: 44.53%] [G loss: 0.856116]\n",
      "epoch:26 step:20559[D loss: 0.439676, acc: 57.03%, op_acc: 42.19%] [G loss: 0.896722]\n",
      "epoch:26 step:20560[D loss: 0.421304, acc: 58.59%, op_acc: 40.62%] [G loss: 0.857000]\n",
      "epoch:26 step:20561[D loss: 0.437553, acc: 60.16%, op_acc: 37.50%] [G loss: 0.820002]\n",
      "epoch:26 step:20562[D loss: 0.402336, acc: 64.84%, op_acc: 43.75%] [G loss: 0.847792]\n",
      "epoch:26 step:20563[D loss: 0.444165, acc: 52.34%, op_acc: 35.94%] [G loss: 0.856194]\n",
      "epoch:26 step:20564[D loss: 0.430976, acc: 57.81%, op_acc: 43.75%] [G loss: 0.875774]\n",
      "epoch:26 step:20565[D loss: 0.445220, acc: 55.47%, op_acc: 29.69%] [G loss: 0.904016]\n",
      "epoch:26 step:20566[D loss: 0.415754, acc: 60.94%, op_acc: 41.41%] [G loss: 0.862012]\n",
      "epoch:26 step:20567[D loss: 0.433531, acc: 58.59%, op_acc: 39.84%] [G loss: 0.852950]\n",
      "epoch:26 step:20568[D loss: 0.436156, acc: 57.03%, op_acc: 40.62%] [G loss: 0.838323]\n",
      "epoch:26 step:20569[D loss: 0.399481, acc: 65.62%, op_acc: 42.19%] [G loss: 0.892724]\n",
      "epoch:26 step:20570[D loss: 0.403339, acc: 67.19%, op_acc: 45.31%] [G loss: 0.877816]\n",
      "epoch:26 step:20571[D loss: 0.405866, acc: 61.72%, op_acc: 35.94%] [G loss: 0.844185]\n",
      "epoch:26 step:20572[D loss: 0.415184, acc: 55.47%, op_acc: 43.75%] [G loss: 0.811073]\n",
      "epoch:26 step:20573[D loss: 0.418000, acc: 59.38%, op_acc: 33.59%] [G loss: 0.929113]\n",
      "epoch:26 step:20574[D loss: 0.423667, acc: 53.91%, op_acc: 45.31%] [G loss: 0.830948]\n",
      "epoch:26 step:20575[D loss: 0.426347, acc: 60.94%, op_acc: 38.28%] [G loss: 0.916530]\n",
      "epoch:26 step:20576[D loss: 0.412628, acc: 64.06%, op_acc: 42.19%] [G loss: 0.847854]\n",
      "epoch:26 step:20577[D loss: 0.439193, acc: 57.03%, op_acc: 41.41%] [G loss: 0.894027]\n",
      "epoch:26 step:20578[D loss: 0.418500, acc: 61.72%, op_acc: 32.81%] [G loss: 0.925165]\n",
      "epoch:26 step:20579[D loss: 0.435523, acc: 57.81%, op_acc: 37.50%] [G loss: 0.910403]\n",
      "epoch:26 step:20580[D loss: 0.430161, acc: 64.06%, op_acc: 39.06%] [G loss: 0.899284]\n",
      "epoch:26 step:20581[D loss: 0.429929, acc: 58.59%, op_acc: 41.41%] [G loss: 0.792867]\n",
      "epoch:26 step:20582[D loss: 0.437652, acc: 57.03%, op_acc: 37.50%] [G loss: 0.980593]\n",
      "epoch:26 step:20583[D loss: 0.422739, acc: 67.19%, op_acc: 36.72%] [G loss: 0.844919]\n",
      "epoch:26 step:20584[D loss: 0.428362, acc: 57.03%, op_acc: 41.41%] [G loss: 0.859531]\n",
      "epoch:26 step:20585[D loss: 0.417393, acc: 60.94%, op_acc: 38.28%] [G loss: 0.934355]\n",
      "epoch:26 step:20586[D loss: 0.431565, acc: 54.69%, op_acc: 39.84%] [G loss: 0.854951]\n",
      "epoch:26 step:20587[D loss: 0.414526, acc: 60.94%, op_acc: 39.84%] [G loss: 0.874339]\n",
      "epoch:26 step:20588[D loss: 0.443154, acc: 58.59%, op_acc: 35.16%] [G loss: 0.870941]\n",
      "epoch:26 step:20589[D loss: 0.408093, acc: 60.94%, op_acc: 42.19%] [G loss: 0.884126]\n",
      "epoch:26 step:20590[D loss: 0.441207, acc: 54.69%, op_acc: 35.94%] [G loss: 0.884249]\n",
      "epoch:26 step:20591[D loss: 0.408508, acc: 64.84%, op_acc: 35.94%] [G loss: 0.981125]\n",
      "epoch:26 step:20592[D loss: 0.432888, acc: 58.59%, op_acc: 35.94%] [G loss: 0.858144]\n",
      "epoch:26 step:20593[D loss: 0.443563, acc: 50.00%, op_acc: 42.19%] [G loss: 0.831463]\n",
      "epoch:26 step:20594[D loss: 0.423110, acc: 57.03%, op_acc: 38.28%] [G loss: 0.827663]\n",
      "epoch:26 step:20595[D loss: 0.418124, acc: 62.50%, op_acc: 36.72%] [G loss: 0.839015]\n",
      "epoch:26 step:20596[D loss: 0.405899, acc: 63.28%, op_acc: 42.19%] [G loss: 0.841249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20597[D loss: 0.431555, acc: 58.59%, op_acc: 44.53%] [G loss: 0.869685]\n",
      "epoch:26 step:20598[D loss: 0.439413, acc: 58.59%, op_acc: 34.38%] [G loss: 0.910524]\n",
      "epoch:26 step:20599[D loss: 0.412118, acc: 57.03%, op_acc: 42.19%] [G loss: 0.889733]\n",
      "epoch:26 step:20600[D loss: 0.424398, acc: 66.41%, op_acc: 38.28%] [G loss: 0.903473]\n",
      "##############\n",
      "[0.86802072 0.82667839 0.81876664 0.79836469 0.82120513 0.82244296\n",
      " 0.89497079 0.82368169 0.82114645 0.84101248]\n",
      "##########\n",
      "epoch:26 step:20601[D loss: 0.413418, acc: 53.91%, op_acc: 42.97%] [G loss: 0.900472]\n",
      "epoch:26 step:20602[D loss: 0.389340, acc: 65.62%, op_acc: 39.06%] [G loss: 0.849098]\n",
      "epoch:26 step:20603[D loss: 0.401352, acc: 66.41%, op_acc: 34.38%] [G loss: 0.912460]\n",
      "epoch:26 step:20604[D loss: 0.410913, acc: 67.97%, op_acc: 41.41%] [G loss: 0.847190]\n",
      "epoch:26 step:20605[D loss: 0.425147, acc: 57.03%, op_acc: 42.97%] [G loss: 0.906109]\n",
      "epoch:26 step:20606[D loss: 0.436951, acc: 55.47%, op_acc: 39.84%] [G loss: 0.815246]\n",
      "epoch:26 step:20607[D loss: 0.402495, acc: 67.97%, op_acc: 38.28%] [G loss: 0.884781]\n",
      "epoch:26 step:20608[D loss: 0.416068, acc: 59.38%, op_acc: 36.72%] [G loss: 0.886303]\n",
      "epoch:26 step:20609[D loss: 0.409855, acc: 70.31%, op_acc: 33.59%] [G loss: 0.901246]\n",
      "epoch:26 step:20610[D loss: 0.416090, acc: 60.16%, op_acc: 43.75%] [G loss: 0.933049]\n",
      "epoch:26 step:20611[D loss: 0.420693, acc: 57.03%, op_acc: 41.41%] [G loss: 0.958287]\n",
      "epoch:26 step:20612[D loss: 0.460022, acc: 59.38%, op_acc: 33.59%] [G loss: 0.873925]\n",
      "epoch:26 step:20613[D loss: 0.382511, acc: 69.53%, op_acc: 43.75%] [G loss: 0.833852]\n",
      "epoch:26 step:20614[D loss: 0.414009, acc: 64.84%, op_acc: 41.41%] [G loss: 0.849705]\n",
      "epoch:26 step:20615[D loss: 0.439716, acc: 57.81%, op_acc: 31.25%] [G loss: 0.867885]\n",
      "epoch:26 step:20616[D loss: 0.414423, acc: 57.81%, op_acc: 42.19%] [G loss: 0.919160]\n",
      "epoch:26 step:20617[D loss: 0.449822, acc: 52.34%, op_acc: 40.62%] [G loss: 0.852913]\n",
      "epoch:26 step:20618[D loss: 0.442336, acc: 50.00%, op_acc: 42.97%] [G loss: 0.850801]\n",
      "epoch:26 step:20619[D loss: 0.450375, acc: 43.75%, op_acc: 39.06%] [G loss: 0.870362]\n",
      "epoch:26 step:20620[D loss: 0.431168, acc: 60.94%, op_acc: 38.28%] [G loss: 0.859323]\n",
      "epoch:26 step:20621[D loss: 0.441159, acc: 58.59%, op_acc: 42.19%] [G loss: 0.884596]\n",
      "epoch:26 step:20622[D loss: 0.431808, acc: 58.59%, op_acc: 35.16%] [G loss: 0.855347]\n",
      "epoch:26 step:20623[D loss: 0.428228, acc: 62.50%, op_acc: 40.62%] [G loss: 0.833274]\n",
      "epoch:26 step:20624[D loss: 0.470129, acc: 44.53%, op_acc: 34.38%] [G loss: 0.841112]\n",
      "epoch:26 step:20625[D loss: 0.444711, acc: 46.88%, op_acc: 40.62%] [G loss: 0.902264]\n",
      "epoch:26 step:20626[D loss: 0.409760, acc: 60.94%, op_acc: 42.97%] [G loss: 0.811721]\n",
      "epoch:26 step:20627[D loss: 0.446605, acc: 58.59%, op_acc: 34.38%] [G loss: 0.794647]\n",
      "epoch:26 step:20628[D loss: 0.411684, acc: 61.72%, op_acc: 37.50%] [G loss: 0.835326]\n",
      "epoch:26 step:20629[D loss: 0.436798, acc: 56.25%, op_acc: 38.28%] [G loss: 0.812429]\n",
      "epoch:26 step:20630[D loss: 0.443499, acc: 60.94%, op_acc: 39.06%] [G loss: 0.846165]\n",
      "epoch:26 step:20631[D loss: 0.404168, acc: 68.75%, op_acc: 42.19%] [G loss: 0.901469]\n",
      "epoch:26 step:20632[D loss: 0.443300, acc: 49.22%, op_acc: 41.41%] [G loss: 0.818978]\n",
      "epoch:26 step:20633[D loss: 0.414611, acc: 60.94%, op_acc: 41.41%] [G loss: 0.873563]\n",
      "epoch:26 step:20634[D loss: 0.456872, acc: 54.69%, op_acc: 34.38%] [G loss: 0.817218]\n",
      "epoch:26 step:20635[D loss: 0.438439, acc: 61.72%, op_acc: 34.38%] [G loss: 0.886756]\n",
      "epoch:26 step:20636[D loss: 0.428020, acc: 56.25%, op_acc: 39.06%] [G loss: 0.913254]\n",
      "epoch:26 step:20637[D loss: 0.438848, acc: 55.47%, op_acc: 37.50%] [G loss: 0.922515]\n",
      "epoch:26 step:20638[D loss: 0.424695, acc: 59.38%, op_acc: 43.75%] [G loss: 0.814544]\n",
      "epoch:26 step:20639[D loss: 0.410663, acc: 65.62%, op_acc: 44.53%] [G loss: 0.935631]\n",
      "epoch:26 step:20640[D loss: 0.417445, acc: 57.03%, op_acc: 39.84%] [G loss: 0.893632]\n",
      "epoch:26 step:20641[D loss: 0.424989, acc: 60.16%, op_acc: 35.16%] [G loss: 0.769737]\n",
      "epoch:26 step:20642[D loss: 0.416763, acc: 63.28%, op_acc: 36.72%] [G loss: 0.951245]\n",
      "epoch:26 step:20643[D loss: 0.438819, acc: 59.38%, op_acc: 32.03%] [G loss: 0.907575]\n",
      "epoch:26 step:20644[D loss: 0.389847, acc: 61.72%, op_acc: 42.19%] [G loss: 0.870738]\n",
      "epoch:26 step:20645[D loss: 0.416013, acc: 61.72%, op_acc: 43.75%] [G loss: 0.922179]\n",
      "epoch:26 step:20646[D loss: 0.416998, acc: 57.81%, op_acc: 40.62%] [G loss: 0.860684]\n",
      "epoch:26 step:20647[D loss: 0.448711, acc: 59.38%, op_acc: 35.94%] [G loss: 0.841413]\n",
      "epoch:26 step:20648[D loss: 0.420091, acc: 65.62%, op_acc: 35.94%] [G loss: 0.881902]\n",
      "epoch:26 step:20649[D loss: 0.473986, acc: 53.91%, op_acc: 32.03%] [G loss: 0.837496]\n",
      "epoch:26 step:20650[D loss: 0.414099, acc: 53.12%, op_acc: 39.84%] [G loss: 0.958666]\n",
      "##############\n",
      "[0.87538583 0.86349196 0.79009891 0.77446071 0.7915877  0.83503762\n",
      " 0.89294998 0.80544472 0.82208201 0.83692641]\n",
      "##########\n",
      "epoch:26 step:20651[D loss: 0.421334, acc: 60.16%, op_acc: 39.06%] [G loss: 0.920061]\n",
      "epoch:26 step:20652[D loss: 0.436312, acc: 52.34%, op_acc: 35.16%] [G loss: 0.905290]\n",
      "epoch:26 step:20653[D loss: 0.421307, acc: 55.47%, op_acc: 39.06%] [G loss: 0.905400]\n",
      "epoch:26 step:20654[D loss: 0.394728, acc: 66.41%, op_acc: 46.09%] [G loss: 0.885505]\n",
      "epoch:26 step:20655[D loss: 0.416325, acc: 57.81%, op_acc: 43.75%] [G loss: 0.919801]\n",
      "epoch:26 step:20656[D loss: 0.448428, acc: 57.03%, op_acc: 36.72%] [G loss: 0.982080]\n",
      "epoch:26 step:20657[D loss: 0.447546, acc: 55.47%, op_acc: 38.28%] [G loss: 0.897415]\n",
      "epoch:26 step:20658[D loss: 0.427956, acc: 57.03%, op_acc: 37.50%] [G loss: 0.892133]\n",
      "epoch:26 step:20659[D loss: 0.407282, acc: 64.06%, op_acc: 41.41%] [G loss: 0.902032]\n",
      "epoch:26 step:20660[D loss: 0.426530, acc: 59.38%, op_acc: 42.19%] [G loss: 0.959222]\n",
      "epoch:26 step:20661[D loss: 0.420976, acc: 58.59%, op_acc: 40.62%] [G loss: 0.911980]\n",
      "epoch:26 step:20662[D loss: 0.407531, acc: 60.16%, op_acc: 47.66%] [G loss: 0.861025]\n",
      "epoch:26 step:20663[D loss: 0.425673, acc: 57.81%, op_acc: 35.16%] [G loss: 0.926500]\n",
      "epoch:26 step:20664[D loss: 0.435095, acc: 53.91%, op_acc: 44.53%] [G loss: 0.837541]\n",
      "epoch:26 step:20665[D loss: 0.423377, acc: 60.94%, op_acc: 36.72%] [G loss: 0.870940]\n",
      "epoch:26 step:20666[D loss: 0.414988, acc: 57.81%, op_acc: 38.28%] [G loss: 0.909611]\n",
      "epoch:26 step:20667[D loss: 0.416206, acc: 61.72%, op_acc: 44.53%] [G loss: 0.860314]\n",
      "epoch:26 step:20668[D loss: 0.390159, acc: 61.72%, op_acc: 39.06%] [G loss: 0.916652]\n",
      "epoch:26 step:20669[D loss: 0.414878, acc: 64.06%, op_acc: 41.41%] [G loss: 0.939051]\n",
      "epoch:26 step:20670[D loss: 0.410508, acc: 65.62%, op_acc: 42.97%] [G loss: 0.964347]\n",
      "epoch:26 step:20671[D loss: 0.390872, acc: 60.94%, op_acc: 45.31%] [G loss: 0.868701]\n",
      "epoch:26 step:20672[D loss: 0.420893, acc: 60.16%, op_acc: 41.41%] [G loss: 0.870082]\n",
      "epoch:26 step:20673[D loss: 0.429390, acc: 66.41%, op_acc: 41.41%] [G loss: 0.916052]\n",
      "epoch:26 step:20674[D loss: 0.402499, acc: 64.84%, op_acc: 38.28%] [G loss: 0.905584]\n",
      "epoch:26 step:20675[D loss: 0.436598, acc: 60.16%, op_acc: 38.28%] [G loss: 0.950324]\n",
      "epoch:26 step:20676[D loss: 0.407888, acc: 61.72%, op_acc: 44.53%] [G loss: 0.886950]\n",
      "epoch:26 step:20677[D loss: 0.395070, acc: 60.94%, op_acc: 46.09%] [G loss: 0.878291]\n",
      "epoch:26 step:20678[D loss: 0.427945, acc: 60.94%, op_acc: 43.75%] [G loss: 0.976169]\n",
      "epoch:26 step:20679[D loss: 0.443064, acc: 53.91%, op_acc: 37.50%] [G loss: 0.939086]\n",
      "epoch:26 step:20680[D loss: 0.429637, acc: 63.28%, op_acc: 42.97%] [G loss: 0.876447]\n",
      "epoch:26 step:20681[D loss: 0.432070, acc: 58.59%, op_acc: 35.94%] [G loss: 0.837797]\n",
      "epoch:26 step:20682[D loss: 0.391892, acc: 67.19%, op_acc: 32.81%] [G loss: 0.949603]\n",
      "epoch:26 step:20683[D loss: 0.427208, acc: 57.81%, op_acc: 38.28%] [G loss: 0.912529]\n",
      "epoch:26 step:20684[D loss: 0.410375, acc: 60.94%, op_acc: 41.41%] [G loss: 0.886324]\n",
      "epoch:26 step:20685[D loss: 0.415441, acc: 59.38%, op_acc: 41.41%] [G loss: 0.979510]\n",
      "epoch:26 step:20686[D loss: 0.409849, acc: 61.72%, op_acc: 41.41%] [G loss: 0.859175]\n",
      "epoch:26 step:20687[D loss: 0.401763, acc: 65.62%, op_acc: 41.41%] [G loss: 0.913704]\n",
      "epoch:26 step:20688[D loss: 0.438833, acc: 57.03%, op_acc: 37.50%] [G loss: 0.895932]\n",
      "epoch:26 step:20689[D loss: 0.402927, acc: 62.50%, op_acc: 42.97%] [G loss: 0.916691]\n",
      "epoch:26 step:20690[D loss: 0.419907, acc: 54.69%, op_acc: 39.84%] [G loss: 0.919536]\n",
      "epoch:26 step:20691[D loss: 0.422329, acc: 56.25%, op_acc: 40.62%] [G loss: 1.019351]\n",
      "epoch:26 step:20692[D loss: 0.426287, acc: 57.03%, op_acc: 41.41%] [G loss: 0.907072]\n",
      "epoch:26 step:20693[D loss: 0.419291, acc: 60.16%, op_acc: 43.75%] [G loss: 0.857565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20694[D loss: 0.435302, acc: 60.16%, op_acc: 35.16%] [G loss: 0.862737]\n",
      "epoch:26 step:20695[D loss: 0.398966, acc: 67.97%, op_acc: 39.84%] [G loss: 0.884927]\n",
      "epoch:26 step:20696[D loss: 0.407061, acc: 66.41%, op_acc: 38.28%] [G loss: 0.853281]\n",
      "epoch:26 step:20697[D loss: 0.392268, acc: 63.28%, op_acc: 45.31%] [G loss: 0.892744]\n",
      "epoch:26 step:20698[D loss: 0.424376, acc: 57.03%, op_acc: 43.75%] [G loss: 0.924270]\n",
      "epoch:26 step:20699[D loss: 0.417201, acc: 55.47%, op_acc: 40.62%] [G loss: 0.841181]\n",
      "epoch:26 step:20700[D loss: 0.426748, acc: 60.94%, op_acc: 38.28%] [G loss: 0.888981]\n",
      "##############\n",
      "[0.85777373 0.85288251 0.82414385 0.81261929 0.7988957  0.82821944\n",
      " 0.89004196 0.83382234 0.8059203  0.82182509]\n",
      "##########\n",
      "epoch:26 step:20701[D loss: 0.456194, acc: 53.12%, op_acc: 35.16%] [G loss: 0.922506]\n",
      "epoch:26 step:20702[D loss: 0.420102, acc: 57.81%, op_acc: 42.19%] [G loss: 0.914407]\n",
      "epoch:26 step:20703[D loss: 0.402370, acc: 63.28%, op_acc: 50.78%] [G loss: 0.841713]\n",
      "epoch:26 step:20704[D loss: 0.465881, acc: 52.34%, op_acc: 35.16%] [G loss: 0.819703]\n",
      "epoch:26 step:20705[D loss: 0.402688, acc: 61.72%, op_acc: 35.16%] [G loss: 0.878172]\n",
      "epoch:26 step:20706[D loss: 0.429484, acc: 58.59%, op_acc: 38.28%] [G loss: 0.941798]\n",
      "epoch:26 step:20707[D loss: 0.416907, acc: 64.06%, op_acc: 37.50%] [G loss: 0.922027]\n",
      "epoch:26 step:20708[D loss: 0.409353, acc: 65.62%, op_acc: 39.06%] [G loss: 0.851880]\n",
      "epoch:26 step:20709[D loss: 0.397809, acc: 67.19%, op_acc: 39.84%] [G loss: 0.991107]\n",
      "epoch:26 step:20710[D loss: 0.385627, acc: 64.06%, op_acc: 41.41%] [G loss: 0.900052]\n",
      "epoch:26 step:20711[D loss: 0.455634, acc: 55.47%, op_acc: 34.38%] [G loss: 0.886580]\n",
      "epoch:26 step:20712[D loss: 0.433309, acc: 53.91%, op_acc: 41.41%] [G loss: 0.862480]\n",
      "epoch:26 step:20713[D loss: 0.396355, acc: 64.84%, op_acc: 38.28%] [G loss: 0.976171]\n",
      "epoch:26 step:20714[D loss: 0.405168, acc: 60.16%, op_acc: 39.06%] [G loss: 0.821243]\n",
      "epoch:26 step:20715[D loss: 0.419166, acc: 64.06%, op_acc: 35.94%] [G loss: 0.920483]\n",
      "epoch:26 step:20716[D loss: 0.426218, acc: 57.03%, op_acc: 42.19%] [G loss: 0.880891]\n",
      "epoch:26 step:20717[D loss: 0.431744, acc: 60.94%, op_acc: 41.41%] [G loss: 0.803909]\n",
      "epoch:26 step:20718[D loss: 0.418927, acc: 53.91%, op_acc: 42.19%] [G loss: 0.844928]\n",
      "epoch:26 step:20719[D loss: 0.392558, acc: 62.50%, op_acc: 43.75%] [G loss: 0.882124]\n",
      "epoch:26 step:20720[D loss: 0.386152, acc: 64.84%, op_acc: 41.41%] [G loss: 0.861215]\n",
      "epoch:26 step:20721[D loss: 0.416362, acc: 60.94%, op_acc: 40.62%] [G loss: 0.883534]\n",
      "epoch:26 step:20722[D loss: 0.398086, acc: 67.19%, op_acc: 42.19%] [G loss: 0.883645]\n",
      "epoch:26 step:20723[D loss: 0.411545, acc: 61.72%, op_acc: 34.38%] [G loss: 0.850337]\n",
      "epoch:26 step:20724[D loss: 0.402577, acc: 66.41%, op_acc: 36.72%] [G loss: 0.903548]\n",
      "epoch:26 step:20725[D loss: 0.408707, acc: 61.72%, op_acc: 36.72%] [G loss: 0.827648]\n",
      "epoch:26 step:20726[D loss: 0.402685, acc: 66.41%, op_acc: 37.50%] [G loss: 0.858649]\n",
      "epoch:26 step:20727[D loss: 0.427270, acc: 66.41%, op_acc: 32.81%] [G loss: 0.826869]\n",
      "epoch:26 step:20728[D loss: 0.424317, acc: 57.03%, op_acc: 36.72%] [G loss: 0.903964]\n",
      "epoch:26 step:20729[D loss: 0.437911, acc: 56.25%, op_acc: 39.84%] [G loss: 0.852845]\n",
      "epoch:26 step:20730[D loss: 0.421790, acc: 66.41%, op_acc: 40.62%] [G loss: 0.864937]\n",
      "epoch:26 step:20731[D loss: 0.432736, acc: 61.72%, op_acc: 38.28%] [G loss: 0.915145]\n",
      "epoch:26 step:20732[D loss: 0.433506, acc: 57.81%, op_acc: 39.06%] [G loss: 0.871027]\n",
      "epoch:26 step:20733[D loss: 0.435269, acc: 54.69%, op_acc: 36.72%] [G loss: 0.863257]\n",
      "epoch:26 step:20734[D loss: 0.429256, acc: 60.94%, op_acc: 39.06%] [G loss: 0.862104]\n",
      "epoch:26 step:20735[D loss: 0.426604, acc: 65.62%, op_acc: 34.38%] [G loss: 0.871719]\n",
      "epoch:26 step:20736[D loss: 0.408898, acc: 58.59%, op_acc: 42.97%] [G loss: 0.897662]\n",
      "epoch:26 step:20737[D loss: 0.414092, acc: 64.84%, op_acc: 39.84%] [G loss: 0.795475]\n",
      "epoch:26 step:20738[D loss: 0.404432, acc: 58.59%, op_acc: 45.31%] [G loss: 0.858422]\n",
      "epoch:26 step:20739[D loss: 0.427607, acc: 62.50%, op_acc: 34.38%] [G loss: 0.863224]\n",
      "epoch:26 step:20740[D loss: 0.410630, acc: 62.50%, op_acc: 40.62%] [G loss: 0.865559]\n",
      "epoch:26 step:20741[D loss: 0.446816, acc: 53.12%, op_acc: 42.19%] [G loss: 0.852058]\n",
      "epoch:26 step:20742[D loss: 0.418294, acc: 59.38%, op_acc: 38.28%] [G loss: 0.900740]\n",
      "epoch:26 step:20743[D loss: 0.415461, acc: 64.06%, op_acc: 37.50%] [G loss: 0.885099]\n",
      "epoch:26 step:20744[D loss: 0.388723, acc: 67.19%, op_acc: 43.75%] [G loss: 0.946974]\n",
      "epoch:26 step:20745[D loss: 0.430883, acc: 56.25%, op_acc: 43.75%] [G loss: 0.927932]\n",
      "epoch:26 step:20746[D loss: 0.408129, acc: 60.16%, op_acc: 45.31%] [G loss: 0.824504]\n",
      "epoch:26 step:20747[D loss: 0.416576, acc: 55.47%, op_acc: 38.28%] [G loss: 0.922172]\n",
      "epoch:26 step:20748[D loss: 0.428988, acc: 53.91%, op_acc: 38.28%] [G loss: 0.840705]\n",
      "epoch:26 step:20749[D loss: 0.426798, acc: 60.94%, op_acc: 33.59%] [G loss: 0.875407]\n",
      "epoch:26 step:20750[D loss: 0.398803, acc: 63.28%, op_acc: 45.31%] [G loss: 0.902101]\n",
      "##############\n",
      "[0.85739541 0.84837603 0.82145383 0.80006227 0.80493909 0.82621756\n",
      " 0.87638589 0.82478551 0.83668621 0.82873919]\n",
      "##########\n",
      "epoch:26 step:20751[D loss: 0.455407, acc: 50.00%, op_acc: 35.94%] [G loss: 0.841395]\n",
      "epoch:26 step:20752[D loss: 0.469742, acc: 46.88%, op_acc: 36.72%] [G loss: 0.870445]\n",
      "epoch:26 step:20753[D loss: 0.453600, acc: 56.25%, op_acc: 34.38%] [G loss: 0.829560]\n",
      "epoch:26 step:20754[D loss: 0.387205, acc: 65.62%, op_acc: 49.22%] [G loss: 0.929806]\n",
      "epoch:26 step:20755[D loss: 0.431360, acc: 64.84%, op_acc: 38.28%] [G loss: 0.883115]\n",
      "epoch:26 step:20756[D loss: 0.406128, acc: 67.19%, op_acc: 40.62%] [G loss: 0.939544]\n",
      "epoch:26 step:20757[D loss: 0.423840, acc: 50.78%, op_acc: 41.41%] [G loss: 0.853158]\n",
      "epoch:26 step:20758[D loss: 0.419222, acc: 57.03%, op_acc: 46.09%] [G loss: 0.855371]\n",
      "epoch:26 step:20759[D loss: 0.409715, acc: 58.59%, op_acc: 47.66%] [G loss: 0.863529]\n",
      "epoch:26 step:20760[D loss: 0.431869, acc: 57.81%, op_acc: 39.06%] [G loss: 0.857289]\n",
      "epoch:26 step:20761[D loss: 0.451105, acc: 52.34%, op_acc: 38.28%] [G loss: 0.884915]\n",
      "epoch:26 step:20762[D loss: 0.422556, acc: 60.94%, op_acc: 35.94%] [G loss: 0.935111]\n",
      "epoch:26 step:20763[D loss: 0.419414, acc: 63.28%, op_acc: 40.62%] [G loss: 0.882213]\n",
      "epoch:26 step:20764[D loss: 0.435107, acc: 55.47%, op_acc: 40.62%] [G loss: 0.869369]\n",
      "epoch:26 step:20765[D loss: 0.416800, acc: 57.81%, op_acc: 42.97%] [G loss: 0.895677]\n",
      "epoch:26 step:20766[D loss: 0.412598, acc: 54.69%, op_acc: 44.53%] [G loss: 0.846806]\n",
      "epoch:26 step:20767[D loss: 0.447775, acc: 52.34%, op_acc: 39.06%] [G loss: 0.787650]\n",
      "epoch:26 step:20768[D loss: 0.451082, acc: 51.56%, op_acc: 35.94%] [G loss: 0.853260]\n",
      "epoch:26 step:20769[D loss: 0.424740, acc: 57.81%, op_acc: 43.75%] [G loss: 0.858499]\n",
      "epoch:26 step:20770[D loss: 0.415225, acc: 64.84%, op_acc: 35.94%] [G loss: 0.873806]\n",
      "epoch:26 step:20771[D loss: 0.421906, acc: 62.50%, op_acc: 38.28%] [G loss: 0.872611]\n",
      "epoch:26 step:20772[D loss: 0.376961, acc: 65.62%, op_acc: 42.97%] [G loss: 0.849991]\n",
      "epoch:26 step:20773[D loss: 0.415003, acc: 58.59%, op_acc: 41.41%] [G loss: 0.942928]\n",
      "epoch:26 step:20774[D loss: 0.419690, acc: 60.94%, op_acc: 42.97%] [G loss: 0.953045]\n",
      "epoch:26 step:20775[D loss: 0.384189, acc: 67.97%, op_acc: 42.19%] [G loss: 0.888415]\n",
      "epoch:26 step:20776[D loss: 0.405271, acc: 56.25%, op_acc: 39.06%] [G loss: 0.858113]\n",
      "epoch:26 step:20777[D loss: 0.424337, acc: 57.03%, op_acc: 41.41%] [G loss: 0.880807]\n",
      "epoch:26 step:20778[D loss: 0.427732, acc: 58.59%, op_acc: 35.94%] [G loss: 0.850792]\n",
      "epoch:26 step:20779[D loss: 0.401211, acc: 57.81%, op_acc: 44.53%] [G loss: 0.900733]\n",
      "epoch:26 step:20780[D loss: 0.427762, acc: 56.25%, op_acc: 39.84%] [G loss: 0.867023]\n",
      "epoch:26 step:20781[D loss: 0.404243, acc: 59.38%, op_acc: 42.19%] [G loss: 0.849229]\n",
      "epoch:26 step:20782[D loss: 0.403482, acc: 66.41%, op_acc: 43.75%] [G loss: 0.898627]\n",
      "epoch:26 step:20783[D loss: 0.449312, acc: 56.25%, op_acc: 38.28%] [G loss: 0.871276]\n",
      "epoch:26 step:20784[D loss: 0.428350, acc: 55.47%, op_acc: 40.62%] [G loss: 0.819881]\n",
      "epoch:26 step:20785[D loss: 0.444764, acc: 53.12%, op_acc: 41.41%] [G loss: 0.878543]\n",
      "epoch:26 step:20786[D loss: 0.456355, acc: 58.59%, op_acc: 36.72%] [G loss: 0.896427]\n",
      "epoch:26 step:20787[D loss: 0.429021, acc: 66.41%, op_acc: 32.03%] [G loss: 0.947892]\n",
      "epoch:26 step:20788[D loss: 0.429783, acc: 62.50%, op_acc: 34.38%] [G loss: 0.933616]\n",
      "epoch:26 step:20789[D loss: 0.417320, acc: 63.28%, op_acc: 42.19%] [G loss: 0.922087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20790[D loss: 0.408661, acc: 62.50%, op_acc: 42.19%] [G loss: 0.904158]\n",
      "epoch:26 step:20791[D loss: 0.415525, acc: 60.16%, op_acc: 36.72%] [G loss: 0.916199]\n",
      "epoch:26 step:20792[D loss: 0.396097, acc: 60.94%, op_acc: 39.84%] [G loss: 0.889847]\n",
      "epoch:26 step:20793[D loss: 0.415299, acc: 57.81%, op_acc: 39.84%] [G loss: 0.899238]\n",
      "epoch:26 step:20794[D loss: 0.421255, acc: 60.94%, op_acc: 39.06%] [G loss: 0.808554]\n",
      "epoch:26 step:20795[D loss: 0.449495, acc: 52.34%, op_acc: 39.06%] [G loss: 0.798626]\n",
      "epoch:26 step:20796[D loss: 0.412525, acc: 64.84%, op_acc: 40.62%] [G loss: 0.967021]\n",
      "epoch:26 step:20797[D loss: 0.436512, acc: 61.72%, op_acc: 39.84%] [G loss: 0.944004]\n",
      "epoch:26 step:20798[D loss: 0.402856, acc: 67.97%, op_acc: 40.62%] [G loss: 0.879754]\n",
      "epoch:26 step:20799[D loss: 0.424605, acc: 61.72%, op_acc: 37.50%] [G loss: 0.895139]\n",
      "epoch:26 step:20800[D loss: 0.395919, acc: 59.38%, op_acc: 40.62%] [G loss: 0.887274]\n",
      "##############\n",
      "[0.85869773 0.85819621 0.83269488 0.81087346 0.80803979 0.81250682\n",
      " 0.89837034 0.83203934 0.80378553 0.83212414]\n",
      "##########\n",
      "epoch:26 step:20801[D loss: 0.388432, acc: 69.53%, op_acc: 41.41%] [G loss: 0.920990]\n",
      "epoch:26 step:20802[D loss: 0.413174, acc: 60.16%, op_acc: 46.88%] [G loss: 0.820087]\n",
      "epoch:26 step:20803[D loss: 0.405542, acc: 60.16%, op_acc: 37.50%] [G loss: 0.829673]\n",
      "epoch:26 step:20804[D loss: 0.423114, acc: 60.94%, op_acc: 34.38%] [G loss: 0.955564]\n",
      "epoch:26 step:20805[D loss: 0.453051, acc: 54.69%, op_acc: 35.94%] [G loss: 0.812991]\n",
      "epoch:26 step:20806[D loss: 0.399987, acc: 64.84%, op_acc: 43.75%] [G loss: 0.864135]\n",
      "epoch:26 step:20807[D loss: 0.468163, acc: 53.91%, op_acc: 36.72%] [G loss: 0.887167]\n",
      "epoch:26 step:20808[D loss: 0.420638, acc: 55.47%, op_acc: 40.62%] [G loss: 0.850582]\n",
      "epoch:26 step:20809[D loss: 0.421797, acc: 60.16%, op_acc: 35.94%] [G loss: 0.835339]\n",
      "epoch:26 step:20810[D loss: 0.413737, acc: 64.06%, op_acc: 42.97%] [G loss: 0.818403]\n",
      "epoch:26 step:20811[D loss: 0.450588, acc: 56.25%, op_acc: 32.81%] [G loss: 0.878251]\n",
      "epoch:26 step:20812[D loss: 0.408134, acc: 57.81%, op_acc: 45.31%] [G loss: 0.943462]\n",
      "epoch:26 step:20813[D loss: 0.411808, acc: 60.94%, op_acc: 46.09%] [G loss: 0.867200]\n",
      "epoch:26 step:20814[D loss: 0.433426, acc: 60.16%, op_acc: 30.47%] [G loss: 0.972379]\n",
      "epoch:26 step:20815[D loss: 0.436807, acc: 54.69%, op_acc: 35.16%] [G loss: 0.888553]\n",
      "epoch:26 step:20816[D loss: 0.400771, acc: 64.06%, op_acc: 42.19%] [G loss: 0.868164]\n",
      "epoch:26 step:20817[D loss: 0.435493, acc: 54.69%, op_acc: 39.06%] [G loss: 0.806684]\n",
      "epoch:26 step:20818[D loss: 0.428885, acc: 62.50%, op_acc: 39.84%] [G loss: 0.963791]\n",
      "epoch:26 step:20819[D loss: 0.445065, acc: 58.59%, op_acc: 39.84%] [G loss: 0.869261]\n",
      "epoch:26 step:20820[D loss: 0.426929, acc: 62.50%, op_acc: 34.38%] [G loss: 0.898140]\n",
      "epoch:26 step:20821[D loss: 0.422248, acc: 60.16%, op_acc: 36.72%] [G loss: 0.924473]\n",
      "epoch:26 step:20822[D loss: 0.435031, acc: 64.06%, op_acc: 34.38%] [G loss: 0.808545]\n",
      "epoch:26 step:20823[D loss: 0.424561, acc: 60.16%, op_acc: 38.28%] [G loss: 0.886802]\n",
      "epoch:26 step:20824[D loss: 0.391842, acc: 67.19%, op_acc: 42.97%] [G loss: 0.908128]\n",
      "epoch:26 step:20825[D loss: 0.405105, acc: 67.19%, op_acc: 38.28%] [G loss: 0.909723]\n",
      "epoch:26 step:20826[D loss: 0.411887, acc: 60.94%, op_acc: 42.97%] [G loss: 0.830705]\n",
      "epoch:26 step:20827[D loss: 0.432979, acc: 59.38%, op_acc: 39.06%] [G loss: 0.876761]\n",
      "epoch:26 step:20828[D loss: 0.420868, acc: 60.94%, op_acc: 42.97%] [G loss: 0.850623]\n",
      "epoch:26 step:20829[D loss: 0.412178, acc: 60.94%, op_acc: 36.72%] [G loss: 0.777458]\n",
      "epoch:26 step:20830[D loss: 0.413783, acc: 60.94%, op_acc: 42.97%] [G loss: 0.856020]\n",
      "epoch:26 step:20831[D loss: 0.417245, acc: 62.50%, op_acc: 33.59%] [G loss: 0.894889]\n",
      "epoch:26 step:20832[D loss: 0.475448, acc: 46.09%, op_acc: 31.25%] [G loss: 0.881088]\n",
      "epoch:26 step:20833[D loss: 0.431510, acc: 53.91%, op_acc: 39.84%] [G loss: 0.911852]\n",
      "epoch:26 step:20834[D loss: 0.429371, acc: 53.91%, op_acc: 37.50%] [G loss: 0.804815]\n",
      "epoch:26 step:20835[D loss: 0.417628, acc: 59.38%, op_acc: 41.41%] [G loss: 0.897105]\n",
      "epoch:26 step:20836[D loss: 0.431441, acc: 59.38%, op_acc: 39.06%] [G loss: 0.914511]\n",
      "epoch:26 step:20837[D loss: 0.438028, acc: 64.06%, op_acc: 32.81%] [G loss: 0.914280]\n",
      "epoch:26 step:20838[D loss: 0.442489, acc: 51.56%, op_acc: 34.38%] [G loss: 0.803672]\n",
      "epoch:26 step:20839[D loss: 0.435600, acc: 53.91%, op_acc: 42.19%] [G loss: 0.917215]\n",
      "epoch:26 step:20840[D loss: 0.424029, acc: 57.03%, op_acc: 38.28%] [G loss: 0.901905]\n",
      "epoch:26 step:20841[D loss: 0.436801, acc: 57.81%, op_acc: 37.50%] [G loss: 0.814722]\n",
      "epoch:26 step:20842[D loss: 0.391960, acc: 64.84%, op_acc: 44.53%] [G loss: 0.887428]\n",
      "epoch:26 step:20843[D loss: 0.457138, acc: 58.59%, op_acc: 35.94%] [G loss: 0.881655]\n",
      "epoch:26 step:20844[D loss: 0.408408, acc: 60.94%, op_acc: 44.53%] [G loss: 0.886821]\n",
      "epoch:26 step:20845[D loss: 0.410086, acc: 66.41%, op_acc: 39.84%] [G loss: 0.828436]\n",
      "epoch:26 step:20846[D loss: 0.439702, acc: 57.81%, op_acc: 37.50%] [G loss: 0.821398]\n",
      "epoch:26 step:20847[D loss: 0.416118, acc: 63.28%, op_acc: 42.19%] [G loss: 0.924384]\n",
      "epoch:26 step:20848[D loss: 0.435904, acc: 61.72%, op_acc: 38.28%] [G loss: 0.850278]\n",
      "epoch:26 step:20849[D loss: 0.472229, acc: 54.69%, op_acc: 32.03%] [G loss: 0.932501]\n",
      "epoch:26 step:20850[D loss: 0.446401, acc: 55.47%, op_acc: 41.41%] [G loss: 0.875447]\n",
      "##############\n",
      "[0.86843182 0.86762023 0.79896738 0.7959462  0.80959324 0.8240529\n",
      " 0.88971994 0.83041071 0.81465896 0.82363935]\n",
      "##########\n",
      "epoch:26 step:20851[D loss: 0.428858, acc: 51.56%, op_acc: 42.97%] [G loss: 0.884214]\n",
      "epoch:26 step:20852[D loss: 0.427152, acc: 58.59%, op_acc: 42.19%] [G loss: 0.908381]\n",
      "epoch:26 step:20853[D loss: 0.455285, acc: 50.78%, op_acc: 41.41%] [G loss: 0.876594]\n",
      "epoch:26 step:20854[D loss: 0.433195, acc: 63.28%, op_acc: 31.25%] [G loss: 0.875839]\n",
      "epoch:26 step:20855[D loss: 0.403210, acc: 57.81%, op_acc: 46.88%] [G loss: 0.942060]\n",
      "epoch:26 step:20856[D loss: 0.427995, acc: 58.59%, op_acc: 41.41%] [G loss: 0.929070]\n",
      "epoch:26 step:20857[D loss: 0.417751, acc: 62.50%, op_acc: 43.75%] [G loss: 0.835069]\n",
      "epoch:26 step:20858[D loss: 0.451071, acc: 54.69%, op_acc: 36.72%] [G loss: 0.826225]\n",
      "epoch:26 step:20859[D loss: 0.419479, acc: 53.12%, op_acc: 40.62%] [G loss: 0.854120]\n",
      "epoch:26 step:20860[D loss: 0.436600, acc: 53.12%, op_acc: 37.50%] [G loss: 0.820789]\n",
      "epoch:26 step:20861[D loss: 0.415245, acc: 55.47%, op_acc: 38.28%] [G loss: 0.822886]\n",
      "epoch:26 step:20862[D loss: 0.423231, acc: 52.34%, op_acc: 44.53%] [G loss: 0.849584]\n",
      "epoch:26 step:20863[D loss: 0.453695, acc: 57.03%, op_acc: 35.16%] [G loss: 0.892460]\n",
      "epoch:26 step:20864[D loss: 0.404596, acc: 62.50%, op_acc: 41.41%] [G loss: 0.927506]\n",
      "epoch:26 step:20865[D loss: 0.432568, acc: 58.59%, op_acc: 36.72%] [G loss: 0.865240]\n",
      "epoch:26 step:20866[D loss: 0.421741, acc: 60.16%, op_acc: 38.28%] [G loss: 0.932599]\n",
      "epoch:26 step:20867[D loss: 0.411651, acc: 58.59%, op_acc: 44.53%] [G loss: 0.931411]\n",
      "epoch:26 step:20868[D loss: 0.436317, acc: 62.50%, op_acc: 35.94%] [G loss: 0.891510]\n",
      "epoch:26 step:20869[D loss: 0.404879, acc: 71.88%, op_acc: 42.19%] [G loss: 0.873208]\n",
      "epoch:26 step:20870[D loss: 0.421444, acc: 57.81%, op_acc: 43.75%] [G loss: 0.886203]\n",
      "epoch:26 step:20871[D loss: 0.415460, acc: 58.59%, op_acc: 41.41%] [G loss: 0.849172]\n",
      "epoch:26 step:20872[D loss: 0.382806, acc: 74.22%, op_acc: 35.94%] [G loss: 0.854585]\n",
      "epoch:26 step:20873[D loss: 0.411568, acc: 60.16%, op_acc: 40.62%] [G loss: 0.801841]\n",
      "epoch:26 step:20874[D loss: 0.430225, acc: 53.91%, op_acc: 44.53%] [G loss: 0.936283]\n",
      "epoch:26 step:20875[D loss: 0.395325, acc: 64.06%, op_acc: 41.41%] [G loss: 0.933717]\n",
      "epoch:26 step:20876[D loss: 0.421517, acc: 61.72%, op_acc: 38.28%] [G loss: 0.903297]\n",
      "epoch:26 step:20877[D loss: 0.386877, acc: 63.28%, op_acc: 46.88%] [G loss: 0.880346]\n",
      "epoch:26 step:20878[D loss: 0.433320, acc: 57.81%, op_acc: 39.06%] [G loss: 0.887928]\n",
      "epoch:26 step:20879[D loss: 0.429994, acc: 57.03%, op_acc: 46.88%] [G loss: 0.828549]\n",
      "epoch:26 step:20880[D loss: 0.426566, acc: 57.03%, op_acc: 42.19%] [G loss: 0.827029]\n",
      "epoch:26 step:20881[D loss: 0.421038, acc: 61.72%, op_acc: 36.72%] [G loss: 0.867351]\n",
      "epoch:26 step:20882[D loss: 0.376926, acc: 65.62%, op_acc: 46.88%] [G loss: 0.776665]\n",
      "epoch:26 step:20883[D loss: 0.462649, acc: 53.91%, op_acc: 35.16%] [G loss: 0.792273]\n",
      "epoch:26 step:20884[D loss: 0.452396, acc: 60.16%, op_acc: 40.62%] [G loss: 0.958800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20885[D loss: 0.409468, acc: 54.69%, op_acc: 44.53%] [G loss: 0.849465]\n",
      "epoch:26 step:20886[D loss: 0.434943, acc: 52.34%, op_acc: 38.28%] [G loss: 0.896598]\n",
      "epoch:26 step:20887[D loss: 0.433735, acc: 57.03%, op_acc: 40.62%] [G loss: 0.885818]\n",
      "epoch:26 step:20888[D loss: 0.415897, acc: 57.81%, op_acc: 37.50%] [G loss: 0.887218]\n",
      "epoch:26 step:20889[D loss: 0.419472, acc: 67.19%, op_acc: 40.62%] [G loss: 0.906031]\n",
      "epoch:26 step:20890[D loss: 0.473862, acc: 46.88%, op_acc: 30.47%] [G loss: 0.892732]\n",
      "epoch:26 step:20891[D loss: 0.400609, acc: 64.84%, op_acc: 36.72%] [G loss: 0.901674]\n",
      "epoch:26 step:20892[D loss: 0.431467, acc: 53.91%, op_acc: 45.31%] [G loss: 0.854154]\n",
      "epoch:26 step:20893[D loss: 0.418473, acc: 60.94%, op_acc: 41.41%] [G loss: 0.889320]\n",
      "epoch:26 step:20894[D loss: 0.412443, acc: 62.50%, op_acc: 39.84%] [G loss: 0.870258]\n",
      "epoch:26 step:20895[D loss: 0.422088, acc: 60.94%, op_acc: 40.62%] [G loss: 0.859530]\n",
      "epoch:26 step:20896[D loss: 0.436139, acc: 51.56%, op_acc: 39.06%] [G loss: 0.893013]\n",
      "epoch:26 step:20897[D loss: 0.419009, acc: 62.50%, op_acc: 39.84%] [G loss: 0.833825]\n",
      "epoch:26 step:20898[D loss: 0.435238, acc: 53.91%, op_acc: 37.50%] [G loss: 0.896332]\n",
      "epoch:26 step:20899[D loss: 0.450555, acc: 51.56%, op_acc: 38.28%] [G loss: 0.897078]\n",
      "epoch:26 step:20900[D loss: 0.410409, acc: 63.28%, op_acc: 43.75%] [G loss: 0.877875]\n",
      "##############\n",
      "[0.86191456 0.84588899 0.82405932 0.80111516 0.80404409 0.82253894\n",
      " 0.88740329 0.83073454 0.81696341 0.8006494 ]\n",
      "##########\n",
      "epoch:26 step:20901[D loss: 0.412887, acc: 64.84%, op_acc: 34.38%] [G loss: 0.934969]\n",
      "epoch:26 step:20902[D loss: 0.440450, acc: 55.47%, op_acc: 40.62%] [G loss: 0.913391]\n",
      "epoch:26 step:20903[D loss: 0.401207, acc: 62.50%, op_acc: 41.41%] [G loss: 1.051002]\n",
      "epoch:26 step:20904[D loss: 0.428922, acc: 54.69%, op_acc: 39.06%] [G loss: 0.861191]\n",
      "epoch:26 step:20905[D loss: 0.446409, acc: 51.56%, op_acc: 39.84%] [G loss: 0.823822]\n",
      "epoch:26 step:20906[D loss: 0.420496, acc: 60.16%, op_acc: 35.94%] [G loss: 0.850133]\n",
      "epoch:26 step:20907[D loss: 0.427212, acc: 58.59%, op_acc: 36.72%] [G loss: 0.796931]\n",
      "epoch:26 step:20908[D loss: 0.399700, acc: 66.41%, op_acc: 43.75%] [G loss: 0.968553]\n",
      "epoch:26 step:20909[D loss: 0.410719, acc: 61.72%, op_acc: 43.75%] [G loss: 0.944664]\n",
      "epoch:26 step:20910[D loss: 0.457338, acc: 60.16%, op_acc: 39.06%] [G loss: 0.913264]\n",
      "epoch:26 step:20911[D loss: 0.421365, acc: 55.47%, op_acc: 39.06%] [G loss: 0.938840]\n",
      "epoch:26 step:20912[D loss: 0.435951, acc: 56.25%, op_acc: 41.41%] [G loss: 0.848723]\n",
      "epoch:26 step:20913[D loss: 0.401728, acc: 57.03%, op_acc: 44.53%] [G loss: 0.887486]\n",
      "epoch:26 step:20914[D loss: 0.392394, acc: 66.41%, op_acc: 40.62%] [G loss: 0.921976]\n",
      "epoch:26 step:20915[D loss: 0.425220, acc: 52.34%, op_acc: 44.53%] [G loss: 0.801896]\n",
      "epoch:26 step:20916[D loss: 0.415531, acc: 64.06%, op_acc: 35.94%] [G loss: 0.932752]\n",
      "epoch:26 step:20917[D loss: 0.424945, acc: 57.81%, op_acc: 42.97%] [G loss: 0.897242]\n",
      "epoch:26 step:20918[D loss: 0.420517, acc: 60.16%, op_acc: 41.41%] [G loss: 0.863831]\n",
      "epoch:26 step:20919[D loss: 0.429011, acc: 54.69%, op_acc: 42.97%] [G loss: 0.931691]\n",
      "epoch:26 step:20920[D loss: 0.371934, acc: 70.31%, op_acc: 42.97%] [G loss: 0.972107]\n",
      "epoch:26 step:20921[D loss: 0.410279, acc: 59.38%, op_acc: 42.19%] [G loss: 0.839671]\n",
      "epoch:26 step:20922[D loss: 0.434872, acc: 65.62%, op_acc: 38.28%] [G loss: 0.920191]\n",
      "epoch:26 step:20923[D loss: 0.453480, acc: 57.81%, op_acc: 35.16%] [G loss: 0.859949]\n",
      "epoch:26 step:20924[D loss: 0.395384, acc: 59.38%, op_acc: 42.97%] [G loss: 0.961607]\n",
      "epoch:26 step:20925[D loss: 0.409971, acc: 60.94%, op_acc: 36.72%] [G loss: 0.989683]\n",
      "epoch:26 step:20926[D loss: 0.428026, acc: 57.03%, op_acc: 38.28%] [G loss: 0.889464]\n",
      "epoch:26 step:20927[D loss: 0.429055, acc: 57.81%, op_acc: 40.62%] [G loss: 0.857430]\n",
      "epoch:26 step:20928[D loss: 0.436835, acc: 63.28%, op_acc: 36.72%] [G loss: 0.878053]\n",
      "epoch:26 step:20929[D loss: 0.405320, acc: 59.38%, op_acc: 40.62%] [G loss: 0.844614]\n",
      "epoch:26 step:20930[D loss: 0.424616, acc: 62.50%, op_acc: 44.53%] [G loss: 0.915797]\n",
      "epoch:26 step:20931[D loss: 0.436919, acc: 51.56%, op_acc: 39.06%] [G loss: 0.833713]\n",
      "epoch:26 step:20932[D loss: 0.410716, acc: 53.91%, op_acc: 38.28%] [G loss: 0.904179]\n",
      "epoch:26 step:20933[D loss: 0.427411, acc: 56.25%, op_acc: 39.84%] [G loss: 0.926108]\n",
      "epoch:26 step:20934[D loss: 0.433913, acc: 57.03%, op_acc: 35.94%] [G loss: 0.755535]\n",
      "epoch:26 step:20935[D loss: 0.455446, acc: 51.56%, op_acc: 34.38%] [G loss: 0.849697]\n",
      "epoch:26 step:20936[D loss: 0.450077, acc: 49.22%, op_acc: 42.19%] [G loss: 0.854700]\n",
      "epoch:26 step:20937[D loss: 0.436721, acc: 61.72%, op_acc: 40.62%] [G loss: 0.812922]\n",
      "epoch:26 step:20938[D loss: 0.437832, acc: 57.81%, op_acc: 40.62%] [G loss: 0.925074]\n",
      "epoch:26 step:20939[D loss: 0.428648, acc: 64.84%, op_acc: 35.16%] [G loss: 0.935796]\n",
      "epoch:26 step:20940[D loss: 0.446290, acc: 52.34%, op_acc: 39.84%] [G loss: 0.824529]\n",
      "epoch:26 step:20941[D loss: 0.434793, acc: 54.69%, op_acc: 37.50%] [G loss: 0.853174]\n",
      "epoch:26 step:20942[D loss: 0.375300, acc: 65.62%, op_acc: 39.84%] [G loss: 0.840319]\n",
      "epoch:26 step:20943[D loss: 0.417766, acc: 55.47%, op_acc: 41.41%] [G loss: 0.868082]\n",
      "epoch:26 step:20944[D loss: 0.430140, acc: 64.06%, op_acc: 37.50%] [G loss: 0.811663]\n",
      "epoch:26 step:20945[D loss: 0.454434, acc: 53.12%, op_acc: 39.06%] [G loss: 0.847565]\n",
      "epoch:26 step:20946[D loss: 0.436466, acc: 57.03%, op_acc: 34.38%] [G loss: 0.878564]\n",
      "epoch:26 step:20947[D loss: 0.442340, acc: 54.69%, op_acc: 38.28%] [G loss: 0.891858]\n",
      "epoch:26 step:20948[D loss: 0.439330, acc: 60.16%, op_acc: 39.06%] [G loss: 0.839404]\n",
      "epoch:26 step:20949[D loss: 0.428169, acc: 64.84%, op_acc: 32.81%] [G loss: 0.830243]\n",
      "epoch:26 step:20950[D loss: 0.418337, acc: 60.16%, op_acc: 39.84%] [G loss: 0.885526]\n",
      "##############\n",
      "[0.86335786 0.85775224 0.80325991 0.79689902 0.77857285 0.84035042\n",
      " 0.90440369 0.82176264 0.7849199  0.82581125]\n",
      "##########\n",
      "epoch:26 step:20951[D loss: 0.388688, acc: 66.41%, op_acc: 42.97%] [G loss: 0.918514]\n",
      "epoch:26 step:20952[D loss: 0.439851, acc: 56.25%, op_acc: 35.94%] [G loss: 0.858447]\n",
      "epoch:26 step:20953[D loss: 0.418068, acc: 58.59%, op_acc: 42.97%] [G loss: 0.789824]\n",
      "epoch:26 step:20954[D loss: 0.417245, acc: 64.06%, op_acc: 40.62%] [G loss: 0.867505]\n",
      "epoch:26 step:20955[D loss: 0.418151, acc: 58.59%, op_acc: 37.50%] [G loss: 0.853097]\n",
      "epoch:26 step:20956[D loss: 0.423796, acc: 65.62%, op_acc: 36.72%] [G loss: 0.889831]\n",
      "epoch:26 step:20957[D loss: 0.409957, acc: 60.94%, op_acc: 47.66%] [G loss: 0.902392]\n",
      "epoch:26 step:20958[D loss: 0.422575, acc: 61.72%, op_acc: 38.28%] [G loss: 0.861630]\n",
      "epoch:26 step:20959[D loss: 0.390654, acc: 67.19%, op_acc: 44.53%] [G loss: 0.885186]\n",
      "epoch:26 step:20960[D loss: 0.443986, acc: 55.47%, op_acc: 34.38%] [G loss: 0.833024]\n",
      "epoch:26 step:20961[D loss: 0.412598, acc: 58.59%, op_acc: 44.53%] [G loss: 0.811871]\n",
      "epoch:26 step:20962[D loss: 0.436386, acc: 55.47%, op_acc: 35.94%] [G loss: 0.886705]\n",
      "epoch:26 step:20963[D loss: 0.436470, acc: 52.34%, op_acc: 37.50%] [G loss: 0.864081]\n",
      "epoch:26 step:20964[D loss: 0.423504, acc: 69.53%, op_acc: 37.50%] [G loss: 0.873775]\n",
      "epoch:26 step:20965[D loss: 0.416280, acc: 60.16%, op_acc: 40.62%] [G loss: 0.893347]\n",
      "epoch:26 step:20966[D loss: 0.419769, acc: 58.59%, op_acc: 42.97%] [G loss: 0.852891]\n",
      "epoch:26 step:20967[D loss: 0.397373, acc: 60.94%, op_acc: 50.00%] [G loss: 0.930960]\n",
      "epoch:26 step:20968[D loss: 0.406332, acc: 60.94%, op_acc: 46.88%] [G loss: 0.852528]\n",
      "epoch:26 step:20969[D loss: 0.429729, acc: 58.59%, op_acc: 36.72%] [G loss: 0.803918]\n",
      "epoch:26 step:20970[D loss: 0.414160, acc: 60.94%, op_acc: 42.19%] [G loss: 0.907185]\n",
      "epoch:26 step:20971[D loss: 0.422624, acc: 71.09%, op_acc: 39.06%] [G loss: 0.927830]\n",
      "epoch:26 step:20972[D loss: 0.402922, acc: 64.84%, op_acc: 38.28%] [G loss: 0.860804]\n",
      "epoch:26 step:20973[D loss: 0.406073, acc: 60.94%, op_acc: 42.97%] [G loss: 0.901501]\n",
      "epoch:26 step:20974[D loss: 0.435614, acc: 53.91%, op_acc: 39.84%] [G loss: 0.887585]\n",
      "epoch:26 step:20975[D loss: 0.453782, acc: 48.44%, op_acc: 38.28%] [G loss: 0.871385]\n",
      "epoch:26 step:20976[D loss: 0.421798, acc: 58.59%, op_acc: 43.75%] [G loss: 0.849298]\n",
      "epoch:26 step:20977[D loss: 0.411213, acc: 64.84%, op_acc: 39.06%] [G loss: 0.841173]\n",
      "epoch:26 step:20978[D loss: 0.455555, acc: 52.34%, op_acc: 35.94%] [G loss: 0.915580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20979[D loss: 0.417875, acc: 56.25%, op_acc: 34.38%] [G loss: 0.859146]\n",
      "epoch:26 step:20980[D loss: 0.401562, acc: 59.38%, op_acc: 47.66%] [G loss: 0.909066]\n",
      "epoch:26 step:20981[D loss: 0.426073, acc: 56.25%, op_acc: 43.75%] [G loss: 0.867560]\n",
      "epoch:26 step:20982[D loss: 0.444541, acc: 51.56%, op_acc: 34.38%] [G loss: 0.857134]\n",
      "epoch:26 step:20983[D loss: 0.460735, acc: 50.78%, op_acc: 36.72%] [G loss: 0.806240]\n",
      "epoch:26 step:20984[D loss: 0.415783, acc: 57.81%, op_acc: 43.75%] [G loss: 0.850822]\n",
      "epoch:26 step:20985[D loss: 0.388387, acc: 68.75%, op_acc: 41.41%] [G loss: 0.824476]\n",
      "epoch:26 step:20986[D loss: 0.442144, acc: 57.81%, op_acc: 35.94%] [G loss: 0.896289]\n",
      "epoch:26 step:20987[D loss: 0.457727, acc: 55.47%, op_acc: 33.59%] [G loss: 0.838977]\n",
      "epoch:26 step:20988[D loss: 0.401855, acc: 60.16%, op_acc: 45.31%] [G loss: 0.958995]\n",
      "epoch:26 step:20989[D loss: 0.418220, acc: 62.50%, op_acc: 42.19%] [G loss: 0.814330]\n",
      "epoch:26 step:20990[D loss: 0.484005, acc: 46.88%, op_acc: 35.16%] [G loss: 0.793833]\n",
      "epoch:26 step:20991[D loss: 0.442810, acc: 53.91%, op_acc: 37.50%] [G loss: 0.800959]\n",
      "epoch:26 step:20992[D loss: 0.425270, acc: 55.47%, op_acc: 39.84%] [G loss: 0.857580]\n",
      "epoch:26 step:20993[D loss: 0.405615, acc: 65.62%, op_acc: 43.75%] [G loss: 0.945869]\n",
      "epoch:26 step:20994[D loss: 0.406393, acc: 54.69%, op_acc: 46.09%] [G loss: 0.960406]\n",
      "epoch:26 step:20995[D loss: 0.422264, acc: 60.16%, op_acc: 37.50%] [G loss: 0.937501]\n",
      "epoch:26 step:20996[D loss: 0.435085, acc: 60.16%, op_acc: 35.16%] [G loss: 0.885819]\n",
      "epoch:26 step:20997[D loss: 0.420045, acc: 67.19%, op_acc: 43.75%] [G loss: 0.917882]\n",
      "epoch:26 step:20998[D loss: 0.427154, acc: 60.16%, op_acc: 39.06%] [G loss: 0.823449]\n",
      "epoch:26 step:20999[D loss: 0.444095, acc: 57.03%, op_acc: 33.59%] [G loss: 0.839191]\n",
      "epoch:26 step:21000[D loss: 0.440770, acc: 62.50%, op_acc: 31.25%] [G loss: 0.951064]\n",
      "##############\n",
      "[0.85809486 0.86814111 0.82514557 0.81540187 0.77014451 0.81959068\n",
      " 0.87331306 0.85434835 0.80565287 0.81931925]\n",
      "##########\n",
      "epoch:26 step:21001[D loss: 0.398559, acc: 63.28%, op_acc: 39.06%] [G loss: 0.948743]\n",
      "epoch:26 step:21002[D loss: 0.463845, acc: 47.66%, op_acc: 38.28%] [G loss: 0.917628]\n",
      "epoch:26 step:21003[D loss: 0.407647, acc: 64.06%, op_acc: 37.50%] [G loss: 0.913017]\n",
      "epoch:26 step:21004[D loss: 0.428723, acc: 58.59%, op_acc: 42.19%] [G loss: 0.827646]\n",
      "epoch:26 step:21005[D loss: 0.402189, acc: 65.62%, op_acc: 39.06%] [G loss: 0.749655]\n",
      "epoch:26 step:21006[D loss: 0.448991, acc: 58.59%, op_acc: 36.72%] [G loss: 0.830946]\n",
      "epoch:26 step:21007[D loss: 0.407089, acc: 64.06%, op_acc: 40.62%] [G loss: 0.874399]\n",
      "epoch:26 step:21008[D loss: 0.437568, acc: 56.25%, op_acc: 35.94%] [G loss: 0.802294]\n",
      "epoch:26 step:21009[D loss: 0.451479, acc: 49.22%, op_acc: 39.06%] [G loss: 0.819077]\n",
      "epoch:26 step:21010[D loss: 0.390413, acc: 64.84%, op_acc: 43.75%] [G loss: 0.854016]\n",
      "epoch:26 step:21011[D loss: 0.453766, acc: 49.22%, op_acc: 37.50%] [G loss: 0.791235]\n",
      "epoch:26 step:21012[D loss: 0.415111, acc: 62.50%, op_acc: 32.81%] [G loss: 0.918518]\n",
      "epoch:26 step:21013[D loss: 0.470414, acc: 46.88%, op_acc: 35.94%] [G loss: 0.899130]\n",
      "epoch:26 step:21014[D loss: 0.459816, acc: 48.44%, op_acc: 35.94%] [G loss: 0.820934]\n",
      "epoch:26 step:21015[D loss: 0.426980, acc: 64.84%, op_acc: 39.06%] [G loss: 0.814258]\n",
      "epoch:26 step:21016[D loss: 0.404243, acc: 64.06%, op_acc: 42.97%] [G loss: 0.934329]\n",
      "epoch:26 step:21017[D loss: 0.427129, acc: 60.94%, op_acc: 41.41%] [G loss: 0.865276]\n",
      "epoch:26 step:21018[D loss: 0.385644, acc: 67.19%, op_acc: 41.41%] [G loss: 0.883095]\n",
      "epoch:26 step:21019[D loss: 0.420765, acc: 56.25%, op_acc: 42.97%] [G loss: 0.849530]\n",
      "epoch:26 step:21020[D loss: 0.405297, acc: 69.53%, op_acc: 42.19%] [G loss: 0.870671]\n",
      "epoch:26 step:21021[D loss: 0.424093, acc: 52.34%, op_acc: 42.19%] [G loss: 0.863518]\n",
      "epoch:26 step:21022[D loss: 0.420676, acc: 60.16%, op_acc: 47.66%] [G loss: 0.887180]\n",
      "epoch:26 step:21023[D loss: 0.408468, acc: 61.72%, op_acc: 46.09%] [G loss: 0.873755]\n",
      "epoch:26 step:21024[D loss: 0.401640, acc: 66.41%, op_acc: 39.84%] [G loss: 0.880478]\n",
      "epoch:26 step:21025[D loss: 0.424957, acc: 57.81%, op_acc: 38.28%] [G loss: 0.808807]\n",
      "epoch:26 step:21026[D loss: 0.444910, acc: 55.47%, op_acc: 33.59%] [G loss: 0.882139]\n",
      "epoch:26 step:21027[D loss: 0.387404, acc: 60.94%, op_acc: 49.22%] [G loss: 0.947894]\n",
      "epoch:26 step:21028[D loss: 0.396584, acc: 63.28%, op_acc: 39.06%] [G loss: 0.862873]\n",
      "epoch:26 step:21029[D loss: 0.444537, acc: 52.34%, op_acc: 36.72%] [G loss: 0.818361]\n",
      "epoch:26 step:21030[D loss: 0.452986, acc: 50.78%, op_acc: 35.94%] [G loss: 0.838538]\n",
      "epoch:26 step:21031[D loss: 0.425997, acc: 56.25%, op_acc: 42.19%] [G loss: 0.910286]\n",
      "epoch:26 step:21032[D loss: 0.428557, acc: 59.38%, op_acc: 41.41%] [G loss: 0.854182]\n",
      "epoch:26 step:21033[D loss: 0.443948, acc: 53.91%, op_acc: 34.38%] [G loss: 0.791366]\n",
      "epoch:26 step:21034[D loss: 0.424193, acc: 62.50%, op_acc: 38.28%] [G loss: 0.861655]\n",
      "epoch:26 step:21035[D loss: 0.429051, acc: 60.16%, op_acc: 35.94%] [G loss: 0.804714]\n",
      "epoch:26 step:21036[D loss: 0.414143, acc: 59.38%, op_acc: 41.41%] [G loss: 0.806407]\n",
      "epoch:26 step:21037[D loss: 0.401225, acc: 64.84%, op_acc: 44.53%] [G loss: 0.941911]\n",
      "epoch:26 step:21038[D loss: 0.456875, acc: 48.44%, op_acc: 36.72%] [G loss: 0.848218]\n",
      "epoch:26 step:21039[D loss: 0.402087, acc: 64.84%, op_acc: 39.84%] [G loss: 0.823240]\n",
      "epoch:26 step:21040[D loss: 0.441609, acc: 64.06%, op_acc: 35.94%] [G loss: 0.912503]\n",
      "epoch:26 step:21041[D loss: 0.407799, acc: 64.84%, op_acc: 39.84%] [G loss: 0.826958]\n",
      "epoch:26 step:21042[D loss: 0.445231, acc: 55.47%, op_acc: 35.94%] [G loss: 0.789875]\n",
      "epoch:26 step:21043[D loss: 0.393648, acc: 63.28%, op_acc: 43.75%] [G loss: 0.858659]\n",
      "epoch:26 step:21044[D loss: 0.425005, acc: 56.25%, op_acc: 39.06%] [G loss: 0.806991]\n",
      "epoch:26 step:21045[D loss: 0.401496, acc: 64.84%, op_acc: 35.94%] [G loss: 0.868034]\n",
      "epoch:26 step:21046[D loss: 0.403506, acc: 63.28%, op_acc: 46.88%] [G loss: 0.897947]\n",
      "epoch:26 step:21047[D loss: 0.426803, acc: 60.16%, op_acc: 39.84%] [G loss: 0.819349]\n",
      "epoch:26 step:21048[D loss: 0.420022, acc: 64.84%, op_acc: 39.06%] [G loss: 0.912555]\n",
      "epoch:26 step:21049[D loss: 0.410655, acc: 63.28%, op_acc: 38.28%] [G loss: 0.947177]\n",
      "epoch:26 step:21050[D loss: 0.410038, acc: 57.03%, op_acc: 39.06%] [G loss: 0.826381]\n",
      "##############\n",
      "[0.87148971 0.86389195 0.81439144 0.80447983 0.77210263 0.83423623\n",
      " 0.88758807 0.83891892 0.82094609 0.82154578]\n",
      "##########\n",
      "epoch:26 step:21051[D loss: 0.431068, acc: 61.72%, op_acc: 38.28%] [G loss: 0.815956]\n",
      "epoch:26 step:21052[D loss: 0.424882, acc: 58.59%, op_acc: 45.31%] [G loss: 0.925788]\n",
      "epoch:26 step:21053[D loss: 0.472021, acc: 46.09%, op_acc: 36.72%] [G loss: 0.823017]\n",
      "epoch:26 step:21054[D loss: 0.429898, acc: 60.16%, op_acc: 35.94%] [G loss: 0.846849]\n",
      "epoch:26 step:21055[D loss: 0.446214, acc: 56.25%, op_acc: 39.06%] [G loss: 0.831599]\n",
      "epoch:26 step:21056[D loss: 0.443844, acc: 53.12%, op_acc: 35.94%] [G loss: 0.863225]\n",
      "epoch:26 step:21057[D loss: 0.439539, acc: 56.25%, op_acc: 39.84%] [G loss: 0.858331]\n",
      "epoch:26 step:21058[D loss: 0.434972, acc: 52.34%, op_acc: 42.97%] [G loss: 0.885557]\n",
      "epoch:26 step:21059[D loss: 0.426088, acc: 53.12%, op_acc: 41.41%] [G loss: 0.853754]\n",
      "epoch:26 step:21060[D loss: 0.416258, acc: 62.50%, op_acc: 36.72%] [G loss: 0.843145]\n",
      "epoch:26 step:21061[D loss: 0.416494, acc: 58.59%, op_acc: 46.88%] [G loss: 0.853280]\n",
      "epoch:26 step:21062[D loss: 0.406038, acc: 63.28%, op_acc: 42.97%] [G loss: 0.931561]\n",
      "epoch:26 step:21063[D loss: 0.428768, acc: 58.59%, op_acc: 37.50%] [G loss: 0.965127]\n",
      "epoch:26 step:21064[D loss: 0.402921, acc: 60.16%, op_acc: 41.41%] [G loss: 0.929141]\n",
      "epoch:26 step:21065[D loss: 0.451894, acc: 53.91%, op_acc: 39.06%] [G loss: 0.807462]\n",
      "epoch:26 step:21066[D loss: 0.396307, acc: 62.50%, op_acc: 43.75%] [G loss: 0.878976]\n",
      "epoch:26 step:21067[D loss: 0.403107, acc: 58.59%, op_acc: 46.09%] [G loss: 0.847048]\n",
      "epoch:26 step:21068[D loss: 0.442580, acc: 53.91%, op_acc: 35.16%] [G loss: 0.835050]\n",
      "epoch:26 step:21069[D loss: 0.453984, acc: 53.12%, op_acc: 37.50%] [G loss: 0.825962]\n",
      "epoch:26 step:21070[D loss: 0.438625, acc: 53.91%, op_acc: 33.59%] [G loss: 0.860743]\n",
      "epoch:26 step:21071[D loss: 0.418614, acc: 60.94%, op_acc: 45.31%] [G loss: 0.923411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:21072[D loss: 0.433463, acc: 50.78%, op_acc: 43.75%] [G loss: 0.927253]\n",
      "epoch:26 step:21073[D loss: 0.392347, acc: 64.84%, op_acc: 41.41%] [G loss: 0.861358]\n",
      "epoch:26 step:21074[D loss: 0.398425, acc: 57.81%, op_acc: 42.97%] [G loss: 0.878732]\n",
      "epoch:26 step:21075[D loss: 0.387604, acc: 60.16%, op_acc: 46.88%] [G loss: 0.901943]\n",
      "epoch:26 step:21076[D loss: 0.422789, acc: 57.81%, op_acc: 37.50%] [G loss: 0.861180]\n",
      "epoch:26 step:21077[D loss: 0.463126, acc: 52.34%, op_acc: 39.06%] [G loss: 0.803855]\n",
      "epoch:26 step:21078[D loss: 0.433925, acc: 61.72%, op_acc: 40.62%] [G loss: 0.923398]\n",
      "epoch:26 step:21079[D loss: 0.417868, acc: 61.72%, op_acc: 42.97%] [G loss: 0.867932]\n",
      "epoch:26 step:21080[D loss: 0.406206, acc: 60.94%, op_acc: 41.41%] [G loss: 0.887335]\n",
      "epoch:26 step:21081[D loss: 0.418644, acc: 59.38%, op_acc: 40.62%] [G loss: 0.931376]\n",
      "epoch:26 step:21082[D loss: 0.429391, acc: 62.50%, op_acc: 39.06%] [G loss: 0.890840]\n",
      "epoch:26 step:21083[D loss: 0.473106, acc: 49.22%, op_acc: 35.94%] [G loss: 0.909193]\n",
      "epoch:26 step:21084[D loss: 0.413678, acc: 62.50%, op_acc: 44.53%] [G loss: 0.926285]\n",
      "epoch:26 step:21085[D loss: 0.420651, acc: 59.38%, op_acc: 44.53%] [G loss: 0.829809]\n",
      "epoch:26 step:21086[D loss: 0.429399, acc: 58.59%, op_acc: 38.28%] [G loss: 0.767049]\n",
      "epoch:26 step:21087[D loss: 0.399759, acc: 67.19%, op_acc: 42.97%] [G loss: 0.856527]\n",
      "epoch:27 step:21088[D loss: 0.421333, acc: 55.47%, op_acc: 37.50%] [G loss: 0.886649]\n",
      "epoch:27 step:21089[D loss: 0.415964, acc: 59.38%, op_acc: 39.84%] [G loss: 0.917430]\n",
      "epoch:27 step:21090[D loss: 0.434875, acc: 56.25%, op_acc: 39.84%] [G loss: 0.980656]\n",
      "epoch:27 step:21091[D loss: 0.432929, acc: 50.78%, op_acc: 42.19%] [G loss: 0.881317]\n",
      "epoch:27 step:21092[D loss: 0.417951, acc: 57.81%, op_acc: 38.28%] [G loss: 0.929905]\n",
      "epoch:27 step:21093[D loss: 0.443280, acc: 53.91%, op_acc: 35.94%] [G loss: 0.869239]\n",
      "epoch:27 step:21094[D loss: 0.425497, acc: 57.81%, op_acc: 40.62%] [G loss: 0.869221]\n",
      "epoch:27 step:21095[D loss: 0.451562, acc: 55.47%, op_acc: 37.50%] [G loss: 0.928547]\n",
      "epoch:27 step:21096[D loss: 0.411603, acc: 57.03%, op_acc: 40.62%] [G loss: 0.798888]\n",
      "epoch:27 step:21097[D loss: 0.406683, acc: 65.62%, op_acc: 37.50%] [G loss: 0.892202]\n",
      "epoch:27 step:21098[D loss: 0.436460, acc: 53.91%, op_acc: 34.38%] [G loss: 0.876005]\n",
      "epoch:27 step:21099[D loss: 0.443013, acc: 53.12%, op_acc: 39.06%] [G loss: 0.874481]\n",
      "epoch:27 step:21100[D loss: 0.422002, acc: 60.16%, op_acc: 35.16%] [G loss: 0.813142]\n",
      "##############\n",
      "[0.87442966 0.87401199 0.81746421 0.81057018 0.79551589 0.84016589\n",
      " 0.86846619 0.84802246 0.78166889 0.83652936]\n",
      "##########\n",
      "epoch:27 step:21101[D loss: 0.439918, acc: 52.34%, op_acc: 38.28%] [G loss: 0.935220]\n",
      "epoch:27 step:21102[D loss: 0.427227, acc: 54.69%, op_acc: 44.53%] [G loss: 0.927266]\n",
      "epoch:27 step:21103[D loss: 0.389261, acc: 64.84%, op_acc: 42.97%] [G loss: 0.926083]\n",
      "epoch:27 step:21104[D loss: 0.426694, acc: 53.91%, op_acc: 36.72%] [G loss: 0.864345]\n",
      "epoch:27 step:21105[D loss: 0.408167, acc: 59.38%, op_acc: 41.41%] [G loss: 0.891260]\n",
      "epoch:27 step:21106[D loss: 0.408459, acc: 57.03%, op_acc: 44.53%] [G loss: 0.874412]\n",
      "epoch:27 step:21107[D loss: 0.410188, acc: 60.94%, op_acc: 39.06%] [G loss: 0.927661]\n",
      "epoch:27 step:21108[D loss: 0.412216, acc: 62.50%, op_acc: 33.59%] [G loss: 0.952677]\n",
      "epoch:27 step:21109[D loss: 0.388916, acc: 70.31%, op_acc: 42.97%] [G loss: 0.832121]\n",
      "epoch:27 step:21110[D loss: 0.406708, acc: 60.16%, op_acc: 44.53%] [G loss: 0.815694]\n",
      "epoch:27 step:21111[D loss: 0.451086, acc: 62.50%, op_acc: 33.59%] [G loss: 0.890061]\n",
      "epoch:27 step:21112[D loss: 0.421840, acc: 64.06%, op_acc: 39.06%] [G loss: 0.851826]\n",
      "epoch:27 step:21113[D loss: 0.387753, acc: 70.31%, op_acc: 43.75%] [G loss: 0.929596]\n",
      "epoch:27 step:21114[D loss: 0.433744, acc: 58.59%, op_acc: 39.84%] [G loss: 0.908859]\n",
      "epoch:27 step:21115[D loss: 0.426285, acc: 54.69%, op_acc: 38.28%] [G loss: 0.851374]\n",
      "epoch:27 step:21116[D loss: 0.415215, acc: 64.84%, op_acc: 40.62%] [G loss: 0.945720]\n",
      "epoch:27 step:21117[D loss: 0.402284, acc: 60.16%, op_acc: 44.53%] [G loss: 0.949299]\n",
      "epoch:27 step:21118[D loss: 0.438605, acc: 59.38%, op_acc: 39.84%] [G loss: 0.950152]\n",
      "epoch:27 step:21119[D loss: 0.413754, acc: 68.75%, op_acc: 37.50%] [G loss: 0.877305]\n",
      "epoch:27 step:21120[D loss: 0.422739, acc: 57.81%, op_acc: 41.41%] [G loss: 0.889947]\n",
      "epoch:27 step:21121[D loss: 0.415085, acc: 60.16%, op_acc: 39.84%] [G loss: 0.855323]\n",
      "epoch:27 step:21122[D loss: 0.415322, acc: 63.28%, op_acc: 39.84%] [G loss: 0.814182]\n",
      "epoch:27 step:21123[D loss: 0.406280, acc: 59.38%, op_acc: 42.97%] [G loss: 0.900101]\n",
      "epoch:27 step:21124[D loss: 0.433517, acc: 54.69%, op_acc: 42.19%] [G loss: 0.832769]\n",
      "epoch:27 step:21125[D loss: 0.417011, acc: 58.59%, op_acc: 41.41%] [G loss: 0.872616]\n",
      "epoch:27 step:21126[D loss: 0.410665, acc: 60.16%, op_acc: 43.75%] [G loss: 0.926933]\n",
      "epoch:27 step:21127[D loss: 0.420383, acc: 60.94%, op_acc: 38.28%] [G loss: 0.874955]\n",
      "epoch:27 step:21128[D loss: 0.399014, acc: 58.59%, op_acc: 43.75%] [G loss: 0.787159]\n",
      "epoch:27 step:21129[D loss: 0.418069, acc: 54.69%, op_acc: 44.53%] [G loss: 0.879149]\n",
      "epoch:27 step:21130[D loss: 0.423417, acc: 61.72%, op_acc: 44.53%] [G loss: 0.878268]\n",
      "epoch:27 step:21131[D loss: 0.418736, acc: 61.72%, op_acc: 45.31%] [G loss: 0.868559]\n",
      "epoch:27 step:21132[D loss: 0.418822, acc: 58.59%, op_acc: 37.50%] [G loss: 0.856171]\n",
      "epoch:27 step:21133[D loss: 0.428409, acc: 61.72%, op_acc: 35.16%] [G loss: 0.857323]\n",
      "epoch:27 step:21134[D loss: 0.426271, acc: 62.50%, op_acc: 39.06%] [G loss: 0.774593]\n",
      "epoch:27 step:21135[D loss: 0.440060, acc: 60.94%, op_acc: 36.72%] [G loss: 0.883705]\n",
      "epoch:27 step:21136[D loss: 0.452911, acc: 52.34%, op_acc: 35.16%] [G loss: 0.840618]\n",
      "epoch:27 step:21137[D loss: 0.459183, acc: 53.12%, op_acc: 41.41%] [G loss: 0.881127]\n",
      "epoch:27 step:21138[D loss: 0.429070, acc: 60.16%, op_acc: 37.50%] [G loss: 0.845254]\n",
      "epoch:27 step:21139[D loss: 0.424036, acc: 56.25%, op_acc: 41.41%] [G loss: 0.894060]\n",
      "epoch:27 step:21140[D loss: 0.451894, acc: 53.91%, op_acc: 37.50%] [G loss: 0.863462]\n",
      "epoch:27 step:21141[D loss: 0.423021, acc: 57.03%, op_acc: 41.41%] [G loss: 0.819954]\n",
      "epoch:27 step:21142[D loss: 0.418007, acc: 55.47%, op_acc: 39.84%] [G loss: 0.880319]\n",
      "epoch:27 step:21143[D loss: 0.408107, acc: 60.94%, op_acc: 36.72%] [G loss: 0.790075]\n",
      "epoch:27 step:21144[D loss: 0.450761, acc: 54.69%, op_acc: 36.72%] [G loss: 0.840423]\n",
      "epoch:27 step:21145[D loss: 0.435388, acc: 58.59%, op_acc: 42.19%] [G loss: 0.815169]\n",
      "epoch:27 step:21146[D loss: 0.410462, acc: 57.81%, op_acc: 41.41%] [G loss: 0.846945]\n",
      "epoch:27 step:21147[D loss: 0.399954, acc: 54.69%, op_acc: 42.19%] [G loss: 0.938020]\n",
      "epoch:27 step:21148[D loss: 0.443841, acc: 57.03%, op_acc: 36.72%] [G loss: 0.871305]\n",
      "epoch:27 step:21149[D loss: 0.433448, acc: 53.91%, op_acc: 32.03%] [G loss: 0.888028]\n",
      "epoch:27 step:21150[D loss: 0.427706, acc: 60.16%, op_acc: 42.19%] [G loss: 0.909388]\n",
      "##############\n",
      "[0.86374039 0.85378461 0.82107181 0.79196995 0.78021937 0.80664969\n",
      " 0.87521207 0.84764306 0.8004418  0.83643583]\n",
      "##########\n",
      "epoch:27 step:21151[D loss: 0.391502, acc: 68.75%, op_acc: 38.28%] [G loss: 0.877891]\n",
      "epoch:27 step:21152[D loss: 0.449287, acc: 50.78%, op_acc: 42.19%] [G loss: 0.884644]\n",
      "epoch:27 step:21153[D loss: 0.428004, acc: 60.16%, op_acc: 44.53%] [G loss: 0.826709]\n",
      "epoch:27 step:21154[D loss: 0.381428, acc: 66.41%, op_acc: 42.19%] [G loss: 0.976769]\n",
      "epoch:27 step:21155[D loss: 0.419206, acc: 63.28%, op_acc: 35.94%] [G loss: 0.935976]\n",
      "epoch:27 step:21156[D loss: 0.383398, acc: 66.41%, op_acc: 46.09%] [G loss: 0.895401]\n",
      "epoch:27 step:21157[D loss: 0.416090, acc: 64.84%, op_acc: 39.84%] [G loss: 0.900754]\n",
      "epoch:27 step:21158[D loss: 0.476832, acc: 48.44%, op_acc: 32.03%] [G loss: 0.843823]\n",
      "epoch:27 step:21159[D loss: 0.427061, acc: 57.03%, op_acc: 39.84%] [G loss: 0.849481]\n",
      "epoch:27 step:21160[D loss: 0.397009, acc: 63.28%, op_acc: 42.19%] [G loss: 0.880444]\n",
      "epoch:27 step:21161[D loss: 0.406934, acc: 63.28%, op_acc: 39.06%] [G loss: 0.846864]\n",
      "epoch:27 step:21162[D loss: 0.427118, acc: 59.38%, op_acc: 40.62%] [G loss: 0.874050]\n",
      "epoch:27 step:21163[D loss: 0.428268, acc: 60.16%, op_acc: 44.53%] [G loss: 0.917744]\n",
      "epoch:27 step:21164[D loss: 0.422357, acc: 63.28%, op_acc: 38.28%] [G loss: 0.857787]\n",
      "epoch:27 step:21165[D loss: 0.425689, acc: 60.16%, op_acc: 35.16%] [G loss: 0.891962]\n",
      "epoch:27 step:21166[D loss: 0.455202, acc: 57.03%, op_acc: 39.84%] [G loss: 0.846277]\n",
      "epoch:27 step:21167[D loss: 0.447068, acc: 58.59%, op_acc: 33.59%] [G loss: 0.797866]\n",
      "epoch:27 step:21168[D loss: 0.438293, acc: 64.06%, op_acc: 35.16%] [G loss: 0.851670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21169[D loss: 0.430046, acc: 53.91%, op_acc: 40.62%] [G loss: 0.829995]\n",
      "epoch:27 step:21170[D loss: 0.442374, acc: 60.16%, op_acc: 34.38%] [G loss: 0.813191]\n",
      "epoch:27 step:21171[D loss: 0.443375, acc: 56.25%, op_acc: 38.28%] [G loss: 0.845861]\n",
      "epoch:27 step:21172[D loss: 0.447592, acc: 57.81%, op_acc: 33.59%] [G loss: 0.892148]\n",
      "epoch:27 step:21173[D loss: 0.390126, acc: 63.28%, op_acc: 48.44%] [G loss: 0.922091]\n",
      "epoch:27 step:21174[D loss: 0.423278, acc: 52.34%, op_acc: 35.94%] [G loss: 0.928911]\n",
      "epoch:27 step:21175[D loss: 0.409152, acc: 61.72%, op_acc: 43.75%] [G loss: 0.942555]\n",
      "epoch:27 step:21176[D loss: 0.439429, acc: 57.03%, op_acc: 38.28%] [G loss: 0.893159]\n",
      "epoch:27 step:21177[D loss: 0.419063, acc: 55.47%, op_acc: 36.72%] [G loss: 0.871063]\n",
      "epoch:27 step:21178[D loss: 0.397929, acc: 66.41%, op_acc: 38.28%] [G loss: 0.835174]\n",
      "epoch:27 step:21179[D loss: 0.479241, acc: 39.84%, op_acc: 34.38%] [G loss: 0.825868]\n",
      "epoch:27 step:21180[D loss: 0.402373, acc: 59.38%, op_acc: 43.75%] [G loss: 0.853045]\n",
      "epoch:27 step:21181[D loss: 0.367842, acc: 71.88%, op_acc: 46.09%] [G loss: 0.870833]\n",
      "epoch:27 step:21182[D loss: 0.413013, acc: 61.72%, op_acc: 35.94%] [G loss: 0.835072]\n",
      "epoch:27 step:21183[D loss: 0.416551, acc: 64.06%, op_acc: 34.38%] [G loss: 0.906176]\n",
      "epoch:27 step:21184[D loss: 0.420707, acc: 55.47%, op_acc: 40.62%] [G loss: 0.866020]\n",
      "epoch:27 step:21185[D loss: 0.413890, acc: 62.50%, op_acc: 36.72%] [G loss: 0.864195]\n",
      "epoch:27 step:21186[D loss: 0.406480, acc: 57.81%, op_acc: 40.62%] [G loss: 0.899471]\n",
      "epoch:27 step:21187[D loss: 0.411957, acc: 60.16%, op_acc: 43.75%] [G loss: 0.881911]\n",
      "epoch:27 step:21188[D loss: 0.429872, acc: 62.50%, op_acc: 33.59%] [G loss: 0.937494]\n",
      "epoch:27 step:21189[D loss: 0.402920, acc: 58.59%, op_acc: 42.97%] [G loss: 0.934446]\n",
      "epoch:27 step:21190[D loss: 0.420504, acc: 61.72%, op_acc: 39.06%] [G loss: 0.884181]\n",
      "epoch:27 step:21191[D loss: 0.412616, acc: 59.38%, op_acc: 41.41%] [G loss: 0.912139]\n",
      "epoch:27 step:21192[D loss: 0.435198, acc: 53.91%, op_acc: 35.16%] [G loss: 0.830405]\n",
      "epoch:27 step:21193[D loss: 0.405055, acc: 62.50%, op_acc: 43.75%] [G loss: 0.910073]\n",
      "epoch:27 step:21194[D loss: 0.379823, acc: 66.41%, op_acc: 46.88%] [G loss: 0.931625]\n",
      "epoch:27 step:21195[D loss: 0.450087, acc: 59.38%, op_acc: 32.81%] [G loss: 0.914072]\n",
      "epoch:27 step:21196[D loss: 0.424800, acc: 55.47%, op_acc: 40.62%] [G loss: 0.915651]\n",
      "epoch:27 step:21197[D loss: 0.401055, acc: 61.72%, op_acc: 46.09%] [G loss: 0.903012]\n",
      "epoch:27 step:21198[D loss: 0.442888, acc: 55.47%, op_acc: 36.72%] [G loss: 0.908867]\n",
      "epoch:27 step:21199[D loss: 0.393862, acc: 65.62%, op_acc: 46.88%] [G loss: 0.888599]\n",
      "epoch:27 step:21200[D loss: 0.462997, acc: 51.56%, op_acc: 33.59%] [G loss: 0.845389]\n",
      "##############\n",
      "[0.83992767 0.86894421 0.80969344 0.81588536 0.78421554 0.80878911\n",
      " 0.89007869 0.82093516 0.81328148 0.82356001]\n",
      "##########\n",
      "epoch:27 step:21201[D loss: 0.432821, acc: 53.12%, op_acc: 42.19%] [G loss: 0.935105]\n",
      "epoch:27 step:21202[D loss: 0.401877, acc: 60.16%, op_acc: 43.75%] [G loss: 0.869820]\n",
      "epoch:27 step:21203[D loss: 0.429292, acc: 57.03%, op_acc: 35.94%] [G loss: 0.924253]\n",
      "epoch:27 step:21204[D loss: 0.401956, acc: 62.50%, op_acc: 46.88%] [G loss: 0.837197]\n",
      "epoch:27 step:21205[D loss: 0.438544, acc: 53.91%, op_acc: 35.16%] [G loss: 0.915447]\n",
      "epoch:27 step:21206[D loss: 0.422042, acc: 58.59%, op_acc: 40.62%] [G loss: 0.881829]\n",
      "epoch:27 step:21207[D loss: 0.423740, acc: 60.94%, op_acc: 37.50%] [G loss: 0.834842]\n",
      "epoch:27 step:21208[D loss: 0.401347, acc: 68.75%, op_acc: 39.84%] [G loss: 0.844161]\n",
      "epoch:27 step:21209[D loss: 0.440243, acc: 56.25%, op_acc: 39.84%] [G loss: 0.903292]\n",
      "epoch:27 step:21210[D loss: 0.453584, acc: 50.78%, op_acc: 38.28%] [G loss: 0.881811]\n",
      "epoch:27 step:21211[D loss: 0.407228, acc: 60.94%, op_acc: 44.53%] [G loss: 0.905168]\n",
      "epoch:27 step:21212[D loss: 0.467164, acc: 52.34%, op_acc: 40.62%] [G loss: 0.846064]\n",
      "epoch:27 step:21213[D loss: 0.416034, acc: 58.59%, op_acc: 40.62%] [G loss: 0.798026]\n",
      "epoch:27 step:21214[D loss: 0.409340, acc: 62.50%, op_acc: 47.66%] [G loss: 0.827780]\n",
      "epoch:27 step:21215[D loss: 0.417976, acc: 60.94%, op_acc: 37.50%] [G loss: 0.850256]\n",
      "epoch:27 step:21216[D loss: 0.436852, acc: 56.25%, op_acc: 37.50%] [G loss: 0.824334]\n",
      "epoch:27 step:21217[D loss: 0.429292, acc: 52.34%, op_acc: 38.28%] [G loss: 0.840116]\n",
      "epoch:27 step:21218[D loss: 0.428289, acc: 59.38%, op_acc: 37.50%] [G loss: 0.837871]\n",
      "epoch:27 step:21219[D loss: 0.397189, acc: 60.94%, op_acc: 38.28%] [G loss: 0.793749]\n",
      "epoch:27 step:21220[D loss: 0.468532, acc: 53.91%, op_acc: 36.72%] [G loss: 0.811246]\n",
      "epoch:27 step:21221[D loss: 0.418570, acc: 63.28%, op_acc: 35.16%] [G loss: 0.840513]\n",
      "epoch:27 step:21222[D loss: 0.444007, acc: 55.47%, op_acc: 33.59%] [G loss: 0.867578]\n",
      "epoch:27 step:21223[D loss: 0.405484, acc: 58.59%, op_acc: 40.62%] [G loss: 0.849609]\n",
      "epoch:27 step:21224[D loss: 0.440764, acc: 57.81%, op_acc: 36.72%] [G loss: 0.825155]\n",
      "epoch:27 step:21225[D loss: 0.441056, acc: 56.25%, op_acc: 39.06%] [G loss: 0.855031]\n",
      "epoch:27 step:21226[D loss: 0.412103, acc: 63.28%, op_acc: 42.97%] [G loss: 0.894759]\n",
      "epoch:27 step:21227[D loss: 0.439851, acc: 58.59%, op_acc: 35.16%] [G loss: 0.828730]\n",
      "epoch:27 step:21228[D loss: 0.447382, acc: 53.12%, op_acc: 37.50%] [G loss: 0.871462]\n",
      "epoch:27 step:21229[D loss: 0.383607, acc: 67.97%, op_acc: 42.19%] [G loss: 0.894415]\n",
      "epoch:27 step:21230[D loss: 0.443790, acc: 53.91%, op_acc: 38.28%] [G loss: 0.792973]\n",
      "epoch:27 step:21231[D loss: 0.430539, acc: 54.69%, op_acc: 42.19%] [G loss: 0.794724]\n",
      "epoch:27 step:21232[D loss: 0.422165, acc: 57.81%, op_acc: 42.97%] [G loss: 0.837538]\n",
      "epoch:27 step:21233[D loss: 0.426547, acc: 60.94%, op_acc: 37.50%] [G loss: 0.817619]\n",
      "epoch:27 step:21234[D loss: 0.377520, acc: 66.41%, op_acc: 45.31%] [G loss: 0.910748]\n",
      "epoch:27 step:21235[D loss: 0.433079, acc: 57.03%, op_acc: 39.06%] [G loss: 0.826553]\n",
      "epoch:27 step:21236[D loss: 0.395000, acc: 60.16%, op_acc: 41.41%] [G loss: 0.867430]\n",
      "epoch:27 step:21237[D loss: 0.407324, acc: 57.81%, op_acc: 40.62%] [G loss: 0.900475]\n",
      "epoch:27 step:21238[D loss: 0.446352, acc: 56.25%, op_acc: 34.38%] [G loss: 0.880825]\n",
      "epoch:27 step:21239[D loss: 0.429909, acc: 53.12%, op_acc: 40.62%] [G loss: 0.917378]\n",
      "epoch:27 step:21240[D loss: 0.425070, acc: 57.81%, op_acc: 37.50%] [G loss: 0.892479]\n",
      "epoch:27 step:21241[D loss: 0.407804, acc: 65.62%, op_acc: 44.53%] [G loss: 0.918098]\n",
      "epoch:27 step:21242[D loss: 0.427894, acc: 57.81%, op_acc: 35.16%] [G loss: 0.856728]\n",
      "epoch:27 step:21243[D loss: 0.452894, acc: 50.00%, op_acc: 43.75%] [G loss: 0.829611]\n",
      "epoch:27 step:21244[D loss: 0.409923, acc: 63.28%, op_acc: 35.94%] [G loss: 0.932169]\n",
      "epoch:27 step:21245[D loss: 0.411173, acc: 57.81%, op_acc: 37.50%] [G loss: 0.879112]\n",
      "epoch:27 step:21246[D loss: 0.412793, acc: 60.94%, op_acc: 43.75%] [G loss: 0.949081]\n",
      "epoch:27 step:21247[D loss: 0.448416, acc: 56.25%, op_acc: 35.16%] [G loss: 0.859154]\n",
      "epoch:27 step:21248[D loss: 0.435549, acc: 54.69%, op_acc: 41.41%] [G loss: 0.930418]\n",
      "epoch:27 step:21249[D loss: 0.389816, acc: 65.62%, op_acc: 46.09%] [G loss: 0.888482]\n",
      "epoch:27 step:21250[D loss: 0.432040, acc: 62.50%, op_acc: 35.94%] [G loss: 0.860283]\n",
      "##############\n",
      "[0.88675006 0.84250374 0.81926994 0.79231634 0.77737601 0.82531412\n",
      " 0.90262474 0.82640842 0.80832018 0.83029376]\n",
      "##########\n",
      "epoch:27 step:21251[D loss: 0.427575, acc: 65.62%, op_acc: 40.62%] [G loss: 0.941875]\n",
      "epoch:27 step:21252[D loss: 0.403167, acc: 58.59%, op_acc: 46.09%] [G loss: 0.920105]\n",
      "epoch:27 step:21253[D loss: 0.415616, acc: 60.94%, op_acc: 37.50%] [G loss: 0.859367]\n",
      "epoch:27 step:21254[D loss: 0.412897, acc: 62.50%, op_acc: 42.19%] [G loss: 0.834978]\n",
      "epoch:27 step:21255[D loss: 0.417528, acc: 61.72%, op_acc: 40.62%] [G loss: 0.999262]\n",
      "epoch:27 step:21256[D loss: 0.430327, acc: 56.25%, op_acc: 39.06%] [G loss: 0.916924]\n",
      "epoch:27 step:21257[D loss: 0.450089, acc: 60.94%, op_acc: 35.16%] [G loss: 0.932835]\n",
      "epoch:27 step:21258[D loss: 0.452391, acc: 60.16%, op_acc: 38.28%] [G loss: 0.922751]\n",
      "epoch:27 step:21259[D loss: 0.396876, acc: 67.19%, op_acc: 39.84%] [G loss: 0.857062]\n",
      "epoch:27 step:21260[D loss: 0.427052, acc: 61.72%, op_acc: 37.50%] [G loss: 0.890248]\n",
      "epoch:27 step:21261[D loss: 0.441161, acc: 58.59%, op_acc: 36.72%] [G loss: 0.823942]\n",
      "epoch:27 step:21262[D loss: 0.428981, acc: 60.94%, op_acc: 35.94%] [G loss: 0.853749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21263[D loss: 0.447228, acc: 59.38%, op_acc: 36.72%] [G loss: 0.788594]\n",
      "epoch:27 step:21264[D loss: 0.400400, acc: 66.41%, op_acc: 40.62%] [G loss: 0.867948]\n",
      "epoch:27 step:21265[D loss: 0.434393, acc: 60.16%, op_acc: 36.72%] [G loss: 0.830441]\n",
      "epoch:27 step:21266[D loss: 0.393512, acc: 65.62%, op_acc: 38.28%] [G loss: 0.922468]\n",
      "epoch:27 step:21267[D loss: 0.423113, acc: 63.28%, op_acc: 35.94%] [G loss: 0.827811]\n",
      "epoch:27 step:21268[D loss: 0.420090, acc: 69.53%, op_acc: 39.84%] [G loss: 0.862247]\n",
      "epoch:27 step:21269[D loss: 0.418270, acc: 58.59%, op_acc: 40.62%] [G loss: 0.926115]\n",
      "epoch:27 step:21270[D loss: 0.422033, acc: 58.59%, op_acc: 44.53%] [G loss: 0.915365]\n",
      "epoch:27 step:21271[D loss: 0.400597, acc: 63.28%, op_acc: 48.44%] [G loss: 0.933415]\n",
      "epoch:27 step:21272[D loss: 0.415266, acc: 67.19%, op_acc: 36.72%] [G loss: 0.971072]\n",
      "epoch:27 step:21273[D loss: 0.414899, acc: 58.59%, op_acc: 42.19%] [G loss: 0.833248]\n",
      "epoch:27 step:21274[D loss: 0.435066, acc: 57.03%, op_acc: 41.41%] [G loss: 0.969220]\n",
      "epoch:27 step:21275[D loss: 0.403047, acc: 61.72%, op_acc: 45.31%] [G loss: 0.937836]\n",
      "epoch:27 step:21276[D loss: 0.418757, acc: 60.94%, op_acc: 41.41%] [G loss: 0.902785]\n",
      "epoch:27 step:21277[D loss: 0.459877, acc: 54.69%, op_acc: 36.72%] [G loss: 0.835790]\n",
      "epoch:27 step:21278[D loss: 0.398791, acc: 67.19%, op_acc: 41.41%] [G loss: 0.902508]\n",
      "epoch:27 step:21279[D loss: 0.401475, acc: 61.72%, op_acc: 39.84%] [G loss: 1.000763]\n",
      "epoch:27 step:21280[D loss: 0.414153, acc: 67.19%, op_acc: 39.06%] [G loss: 0.823045]\n",
      "epoch:27 step:21281[D loss: 0.424663, acc: 57.81%, op_acc: 38.28%] [G loss: 0.903874]\n",
      "epoch:27 step:21282[D loss: 0.430943, acc: 51.56%, op_acc: 37.50%] [G loss: 0.932324]\n",
      "epoch:27 step:21283[D loss: 0.415630, acc: 60.16%, op_acc: 37.50%] [G loss: 0.901623]\n",
      "epoch:27 step:21284[D loss: 0.504113, acc: 42.19%, op_acc: 32.81%] [G loss: 0.925373]\n",
      "epoch:27 step:21285[D loss: 0.464115, acc: 56.25%, op_acc: 35.16%] [G loss: 0.860662]\n",
      "epoch:27 step:21286[D loss: 0.421760, acc: 60.94%, op_acc: 39.06%] [G loss: 0.895589]\n",
      "epoch:27 step:21287[D loss: 0.428308, acc: 59.38%, op_acc: 34.38%] [G loss: 0.798157]\n",
      "epoch:27 step:21288[D loss: 0.401237, acc: 64.06%, op_acc: 41.41%] [G loss: 0.927736]\n",
      "epoch:27 step:21289[D loss: 0.435539, acc: 57.81%, op_acc: 42.19%] [G loss: 0.850113]\n",
      "epoch:27 step:21290[D loss: 0.427523, acc: 54.69%, op_acc: 36.72%] [G loss: 0.904369]\n",
      "epoch:27 step:21291[D loss: 0.438202, acc: 57.03%, op_acc: 42.19%] [G loss: 0.882485]\n",
      "epoch:27 step:21292[D loss: 0.390919, acc: 64.06%, op_acc: 38.28%] [G loss: 0.904310]\n",
      "epoch:27 step:21293[D loss: 0.442283, acc: 53.91%, op_acc: 39.06%] [G loss: 0.863323]\n",
      "epoch:27 step:21294[D loss: 0.417721, acc: 60.16%, op_acc: 45.31%] [G loss: 0.897536]\n",
      "epoch:27 step:21295[D loss: 0.425230, acc: 62.50%, op_acc: 33.59%] [G loss: 0.949132]\n",
      "epoch:27 step:21296[D loss: 0.421649, acc: 61.72%, op_acc: 44.53%] [G loss: 0.903270]\n",
      "epoch:27 step:21297[D loss: 0.454962, acc: 53.12%, op_acc: 37.50%] [G loss: 0.912256]\n",
      "epoch:27 step:21298[D loss: 0.405290, acc: 62.50%, op_acc: 42.97%] [G loss: 0.851834]\n",
      "epoch:27 step:21299[D loss: 0.422794, acc: 56.25%, op_acc: 36.72%] [G loss: 0.971940]\n",
      "epoch:27 step:21300[D loss: 0.430909, acc: 51.56%, op_acc: 40.62%] [G loss: 0.877736]\n",
      "##############\n",
      "[0.85712996 0.87475184 0.81092371 0.80167343 0.79532121 0.82213995\n",
      " 0.8981506  0.82820074 0.80668696 0.84426461]\n",
      "##########\n",
      "epoch:27 step:21301[D loss: 0.435012, acc: 58.59%, op_acc: 38.28%] [G loss: 0.884041]\n",
      "epoch:27 step:21302[D loss: 0.457161, acc: 62.50%, op_acc: 31.25%] [G loss: 0.911143]\n",
      "epoch:27 step:21303[D loss: 0.435193, acc: 58.59%, op_acc: 39.84%] [G loss: 0.895739]\n",
      "epoch:27 step:21304[D loss: 0.396931, acc: 65.62%, op_acc: 43.75%] [G loss: 0.937744]\n",
      "epoch:27 step:21305[D loss: 0.428842, acc: 58.59%, op_acc: 42.97%] [G loss: 0.923188]\n",
      "epoch:27 step:21306[D loss: 0.393462, acc: 68.75%, op_acc: 48.44%] [G loss: 0.941833]\n",
      "epoch:27 step:21307[D loss: 0.462123, acc: 50.78%, op_acc: 35.94%] [G loss: 0.848719]\n",
      "epoch:27 step:21308[D loss: 0.417742, acc: 61.72%, op_acc: 39.06%] [G loss: 0.852703]\n",
      "epoch:27 step:21309[D loss: 0.431761, acc: 60.94%, op_acc: 36.72%] [G loss: 0.859844]\n",
      "epoch:27 step:21310[D loss: 0.421379, acc: 56.25%, op_acc: 38.28%] [G loss: 0.884515]\n",
      "epoch:27 step:21311[D loss: 0.413406, acc: 64.06%, op_acc: 39.06%] [G loss: 0.935892]\n",
      "epoch:27 step:21312[D loss: 0.422397, acc: 57.81%, op_acc: 39.84%] [G loss: 0.839934]\n",
      "epoch:27 step:21313[D loss: 0.440477, acc: 54.69%, op_acc: 39.84%] [G loss: 0.831648]\n",
      "epoch:27 step:21314[D loss: 0.423360, acc: 57.03%, op_acc: 41.41%] [G loss: 0.926862]\n",
      "epoch:27 step:21315[D loss: 0.389259, acc: 65.62%, op_acc: 41.41%] [G loss: 0.863280]\n",
      "epoch:27 step:21316[D loss: 0.412958, acc: 62.50%, op_acc: 38.28%] [G loss: 0.830889]\n",
      "epoch:27 step:21317[D loss: 0.428082, acc: 63.28%, op_acc: 39.06%] [G loss: 0.840724]\n",
      "epoch:27 step:21318[D loss: 0.435334, acc: 51.56%, op_acc: 38.28%] [G loss: 0.850241]\n",
      "epoch:27 step:21319[D loss: 0.419938, acc: 56.25%, op_acc: 38.28%] [G loss: 0.837898]\n",
      "epoch:27 step:21320[D loss: 0.408447, acc: 60.94%, op_acc: 42.19%] [G loss: 0.853418]\n",
      "epoch:27 step:21321[D loss: 0.446568, acc: 60.94%, op_acc: 36.72%] [G loss: 0.917451]\n",
      "epoch:27 step:21322[D loss: 0.410186, acc: 53.91%, op_acc: 41.41%] [G loss: 0.901041]\n",
      "epoch:27 step:21323[D loss: 0.463949, acc: 53.12%, op_acc: 33.59%] [G loss: 0.796720]\n",
      "epoch:27 step:21324[D loss: 0.394685, acc: 67.19%, op_acc: 39.06%] [G loss: 0.916852]\n",
      "epoch:27 step:21325[D loss: 0.475124, acc: 46.88%, op_acc: 37.50%] [G loss: 0.868930]\n",
      "epoch:27 step:21326[D loss: 0.394442, acc: 68.75%, op_acc: 37.50%] [G loss: 0.895590]\n",
      "epoch:27 step:21327[D loss: 0.426744, acc: 57.03%, op_acc: 35.16%] [G loss: 0.902484]\n",
      "epoch:27 step:21328[D loss: 0.420538, acc: 59.38%, op_acc: 39.06%] [G loss: 0.953083]\n",
      "epoch:27 step:21329[D loss: 0.401343, acc: 59.38%, op_acc: 40.62%] [G loss: 0.882993]\n",
      "epoch:27 step:21330[D loss: 0.399973, acc: 58.59%, op_acc: 48.44%] [G loss: 0.895190]\n",
      "epoch:27 step:21331[D loss: 0.424976, acc: 57.03%, op_acc: 39.84%] [G loss: 0.870595]\n",
      "epoch:27 step:21332[D loss: 0.395513, acc: 64.84%, op_acc: 42.97%] [G loss: 0.917398]\n",
      "epoch:27 step:21333[D loss: 0.433374, acc: 61.72%, op_acc: 35.16%] [G loss: 0.794963]\n",
      "epoch:27 step:21334[D loss: 0.390704, acc: 65.62%, op_acc: 40.62%] [G loss: 0.889947]\n",
      "epoch:27 step:21335[D loss: 0.451519, acc: 57.03%, op_acc: 33.59%] [G loss: 0.895845]\n",
      "epoch:27 step:21336[D loss: 0.420154, acc: 59.38%, op_acc: 38.28%] [G loss: 0.908879]\n",
      "epoch:27 step:21337[D loss: 0.459836, acc: 54.69%, op_acc: 32.81%] [G loss: 0.799313]\n",
      "epoch:27 step:21338[D loss: 0.384754, acc: 64.06%, op_acc: 45.31%] [G loss: 0.887943]\n",
      "epoch:27 step:21339[D loss: 0.415714, acc: 60.16%, op_acc: 42.19%] [G loss: 0.839727]\n",
      "epoch:27 step:21340[D loss: 0.414109, acc: 63.28%, op_acc: 39.06%] [G loss: 0.947222]\n",
      "epoch:27 step:21341[D loss: 0.438866, acc: 53.12%, op_acc: 35.94%] [G loss: 0.904056]\n",
      "epoch:27 step:21342[D loss: 0.440918, acc: 52.34%, op_acc: 39.06%] [G loss: 0.900129]\n",
      "epoch:27 step:21343[D loss: 0.432315, acc: 59.38%, op_acc: 36.72%] [G loss: 0.885852]\n",
      "epoch:27 step:21344[D loss: 0.428270, acc: 62.50%, op_acc: 37.50%] [G loss: 0.810404]\n",
      "epoch:27 step:21345[D loss: 0.424579, acc: 60.94%, op_acc: 42.97%] [G loss: 0.924234]\n",
      "epoch:27 step:21346[D loss: 0.436217, acc: 60.94%, op_acc: 37.50%] [G loss: 0.784990]\n",
      "epoch:27 step:21347[D loss: 0.428286, acc: 62.50%, op_acc: 32.81%] [G loss: 0.878642]\n",
      "epoch:27 step:21348[D loss: 0.427899, acc: 62.50%, op_acc: 40.62%] [G loss: 0.806396]\n",
      "epoch:27 step:21349[D loss: 0.406718, acc: 60.16%, op_acc: 41.41%] [G loss: 0.889822]\n",
      "epoch:27 step:21350[D loss: 0.417870, acc: 60.16%, op_acc: 38.28%] [G loss: 0.884538]\n",
      "##############\n",
      "[0.85634713 0.84488794 0.80830699 0.80638725 0.78938924 0.83267675\n",
      " 0.87896896 0.81519914 0.81715223 0.82999345]\n",
      "##########\n",
      "epoch:27 step:21351[D loss: 0.408927, acc: 60.94%, op_acc: 42.19%] [G loss: 0.831645]\n",
      "epoch:27 step:21352[D loss: 0.393038, acc: 67.19%, op_acc: 41.41%] [G loss: 0.979362]\n",
      "epoch:27 step:21353[D loss: 0.408514, acc: 63.28%, op_acc: 38.28%] [G loss: 0.861941]\n",
      "epoch:27 step:21354[D loss: 0.424088, acc: 60.94%, op_acc: 36.72%] [G loss: 0.795860]\n",
      "epoch:27 step:21355[D loss: 0.403154, acc: 65.62%, op_acc: 42.97%] [G loss: 0.940684]\n",
      "epoch:27 step:21356[D loss: 0.403178, acc: 60.94%, op_acc: 45.31%] [G loss: 0.950629]\n",
      "epoch:27 step:21357[D loss: 0.425585, acc: 55.47%, op_acc: 39.84%] [G loss: 0.841859]\n",
      "epoch:27 step:21358[D loss: 0.405476, acc: 59.38%, op_acc: 38.28%] [G loss: 0.856750]\n",
      "epoch:27 step:21359[D loss: 0.413251, acc: 60.94%, op_acc: 41.41%] [G loss: 0.867944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21360[D loss: 0.412562, acc: 54.69%, op_acc: 41.41%] [G loss: 0.833579]\n",
      "epoch:27 step:21361[D loss: 0.446818, acc: 53.91%, op_acc: 34.38%] [G loss: 0.889176]\n",
      "epoch:27 step:21362[D loss: 0.415435, acc: 63.28%, op_acc: 39.06%] [G loss: 0.786897]\n",
      "epoch:27 step:21363[D loss: 0.414997, acc: 60.16%, op_acc: 37.50%] [G loss: 0.856578]\n",
      "epoch:27 step:21364[D loss: 0.439099, acc: 55.47%, op_acc: 36.72%] [G loss: 0.883106]\n",
      "epoch:27 step:21365[D loss: 0.395704, acc: 72.66%, op_acc: 42.97%] [G loss: 0.838037]\n",
      "epoch:27 step:21366[D loss: 0.420422, acc: 57.81%, op_acc: 39.84%] [G loss: 0.850875]\n",
      "epoch:27 step:21367[D loss: 0.438328, acc: 51.56%, op_acc: 42.97%] [G loss: 0.817430]\n",
      "epoch:27 step:21368[D loss: 0.415325, acc: 61.72%, op_acc: 39.84%] [G loss: 0.898484]\n",
      "epoch:27 step:21369[D loss: 0.448480, acc: 55.47%, op_acc: 36.72%] [G loss: 0.829631]\n",
      "epoch:27 step:21370[D loss: 0.427703, acc: 60.16%, op_acc: 36.72%] [G loss: 0.837247]\n",
      "epoch:27 step:21371[D loss: 0.435043, acc: 53.91%, op_acc: 38.28%] [G loss: 0.836980]\n",
      "epoch:27 step:21372[D loss: 0.427755, acc: 64.06%, op_acc: 41.41%] [G loss: 0.794426]\n",
      "epoch:27 step:21373[D loss: 0.426927, acc: 58.59%, op_acc: 36.72%] [G loss: 0.879323]\n",
      "epoch:27 step:21374[D loss: 0.442156, acc: 49.22%, op_acc: 42.97%] [G loss: 0.827655]\n",
      "epoch:27 step:21375[D loss: 0.408516, acc: 67.19%, op_acc: 41.41%] [G loss: 0.896965]\n",
      "epoch:27 step:21376[D loss: 0.458810, acc: 56.25%, op_acc: 36.72%] [G loss: 0.841514]\n",
      "epoch:27 step:21377[D loss: 0.395917, acc: 64.84%, op_acc: 40.62%] [G loss: 0.969487]\n",
      "epoch:27 step:21378[D loss: 0.425655, acc: 64.84%, op_acc: 41.41%] [G loss: 0.890120]\n",
      "epoch:27 step:21379[D loss: 0.468270, acc: 47.66%, op_acc: 32.81%] [G loss: 0.811526]\n",
      "epoch:27 step:21380[D loss: 0.388126, acc: 69.53%, op_acc: 42.19%] [G loss: 0.918701]\n",
      "epoch:27 step:21381[D loss: 0.439538, acc: 49.22%, op_acc: 41.41%] [G loss: 0.869739]\n",
      "epoch:27 step:21382[D loss: 0.414399, acc: 63.28%, op_acc: 40.62%] [G loss: 0.893128]\n",
      "epoch:27 step:21383[D loss: 0.426669, acc: 58.59%, op_acc: 46.09%] [G loss: 0.807840]\n",
      "epoch:27 step:21384[D loss: 0.427253, acc: 57.81%, op_acc: 38.28%] [G loss: 0.925858]\n",
      "epoch:27 step:21385[D loss: 0.441931, acc: 51.56%, op_acc: 39.06%] [G loss: 0.834059]\n",
      "epoch:27 step:21386[D loss: 0.417343, acc: 55.47%, op_acc: 34.38%] [G loss: 0.856292]\n",
      "epoch:27 step:21387[D loss: 0.453549, acc: 57.81%, op_acc: 35.94%] [G loss: 0.900626]\n",
      "epoch:27 step:21388[D loss: 0.422157, acc: 58.59%, op_acc: 40.62%] [G loss: 0.940473]\n",
      "epoch:27 step:21389[D loss: 0.399478, acc: 64.06%, op_acc: 42.19%] [G loss: 1.001114]\n",
      "epoch:27 step:21390[D loss: 0.410450, acc: 64.06%, op_acc: 41.41%] [G loss: 0.840316]\n",
      "epoch:27 step:21391[D loss: 0.422889, acc: 53.12%, op_acc: 42.97%] [G loss: 0.893098]\n",
      "epoch:27 step:21392[D loss: 0.422657, acc: 52.34%, op_acc: 39.84%] [G loss: 0.924951]\n",
      "epoch:27 step:21393[D loss: 0.465303, acc: 52.34%, op_acc: 35.16%] [G loss: 0.922025]\n",
      "epoch:27 step:21394[D loss: 0.447117, acc: 53.91%, op_acc: 40.62%] [G loss: 0.857721]\n",
      "epoch:27 step:21395[D loss: 0.435779, acc: 59.38%, op_acc: 38.28%] [G loss: 0.827034]\n",
      "epoch:27 step:21396[D loss: 0.420771, acc: 57.03%, op_acc: 41.41%] [G loss: 0.848958]\n",
      "epoch:27 step:21397[D loss: 0.435060, acc: 56.25%, op_acc: 37.50%] [G loss: 0.867647]\n",
      "epoch:27 step:21398[D loss: 0.443692, acc: 56.25%, op_acc: 38.28%] [G loss: 0.874848]\n",
      "epoch:27 step:21399[D loss: 0.427155, acc: 59.38%, op_acc: 39.84%] [G loss: 0.935723]\n",
      "epoch:27 step:21400[D loss: 0.432514, acc: 57.03%, op_acc: 36.72%] [G loss: 0.909735]\n",
      "##############\n",
      "[0.85785331 0.87000184 0.82449312 0.8338766  0.80673257 0.80912188\n",
      " 0.87038192 0.83267655 0.77947144 0.82619624]\n",
      "##########\n",
      "epoch:27 step:21401[D loss: 0.444948, acc: 52.34%, op_acc: 37.50%] [G loss: 0.892969]\n",
      "epoch:27 step:21402[D loss: 0.432815, acc: 60.16%, op_acc: 37.50%] [G loss: 0.860495]\n",
      "epoch:27 step:21403[D loss: 0.423116, acc: 60.94%, op_acc: 39.84%] [G loss: 0.805083]\n",
      "epoch:27 step:21404[D loss: 0.448278, acc: 57.03%, op_acc: 34.38%] [G loss: 0.758678]\n",
      "epoch:27 step:21405[D loss: 0.481019, acc: 49.22%, op_acc: 33.59%] [G loss: 0.812394]\n",
      "epoch:27 step:21406[D loss: 0.411209, acc: 61.72%, op_acc: 35.94%] [G loss: 0.783538]\n",
      "epoch:27 step:21407[D loss: 0.415829, acc: 58.59%, op_acc: 38.28%] [G loss: 0.945294]\n",
      "epoch:27 step:21408[D loss: 0.439681, acc: 53.12%, op_acc: 40.62%] [G loss: 0.930401]\n",
      "epoch:27 step:21409[D loss: 0.409931, acc: 64.84%, op_acc: 42.97%] [G loss: 0.918216]\n",
      "epoch:27 step:21410[D loss: 0.424641, acc: 57.81%, op_acc: 42.97%] [G loss: 0.840775]\n",
      "epoch:27 step:21411[D loss: 0.437664, acc: 58.59%, op_acc: 33.59%] [G loss: 0.905680]\n",
      "epoch:27 step:21412[D loss: 0.420746, acc: 62.50%, op_acc: 39.84%] [G loss: 0.847032]\n",
      "epoch:27 step:21413[D loss: 0.432950, acc: 55.47%, op_acc: 39.06%] [G loss: 0.909105]\n",
      "epoch:27 step:21414[D loss: 0.419042, acc: 60.94%, op_acc: 40.62%] [G loss: 0.885200]\n",
      "epoch:27 step:21415[D loss: 0.435115, acc: 58.59%, op_acc: 39.06%] [G loss: 0.954631]\n",
      "epoch:27 step:21416[D loss: 0.416177, acc: 60.16%, op_acc: 37.50%] [G loss: 0.930318]\n",
      "epoch:27 step:21417[D loss: 0.394495, acc: 65.62%, op_acc: 43.75%] [G loss: 0.812755]\n",
      "epoch:27 step:21418[D loss: 0.417596, acc: 64.06%, op_acc: 37.50%] [G loss: 0.921080]\n",
      "epoch:27 step:21419[D loss: 0.402325, acc: 59.38%, op_acc: 46.09%] [G loss: 0.872657]\n",
      "epoch:27 step:21420[D loss: 0.420574, acc: 60.16%, op_acc: 40.62%] [G loss: 0.899389]\n",
      "epoch:27 step:21421[D loss: 0.441397, acc: 54.69%, op_acc: 36.72%] [G loss: 0.874869]\n",
      "epoch:27 step:21422[D loss: 0.436381, acc: 65.62%, op_acc: 41.41%] [G loss: 0.880077]\n",
      "epoch:27 step:21423[D loss: 0.460170, acc: 51.56%, op_acc: 36.72%] [G loss: 0.759619]\n",
      "epoch:27 step:21424[D loss: 0.397385, acc: 65.62%, op_acc: 40.62%] [G loss: 0.909890]\n",
      "epoch:27 step:21425[D loss: 0.399247, acc: 61.72%, op_acc: 44.53%] [G loss: 0.843764]\n",
      "epoch:27 step:21426[D loss: 0.417571, acc: 63.28%, op_acc: 42.19%] [G loss: 0.932189]\n",
      "epoch:27 step:21427[D loss: 0.413459, acc: 59.38%, op_acc: 39.84%] [G loss: 0.932056]\n",
      "epoch:27 step:21428[D loss: 0.434566, acc: 66.41%, op_acc: 36.72%] [G loss: 0.886913]\n",
      "epoch:27 step:21429[D loss: 0.428407, acc: 58.59%, op_acc: 37.50%] [G loss: 0.879408]\n",
      "epoch:27 step:21430[D loss: 0.414026, acc: 64.84%, op_acc: 37.50%] [G loss: 0.843195]\n",
      "epoch:27 step:21431[D loss: 0.426117, acc: 55.47%, op_acc: 41.41%] [G loss: 0.853394]\n",
      "epoch:27 step:21432[D loss: 0.398722, acc: 65.62%, op_acc: 36.72%] [G loss: 0.947746]\n",
      "epoch:27 step:21433[D loss: 0.419067, acc: 59.38%, op_acc: 38.28%] [G loss: 0.875279]\n",
      "epoch:27 step:21434[D loss: 0.405245, acc: 59.38%, op_acc: 39.06%] [G loss: 0.907729]\n",
      "epoch:27 step:21435[D loss: 0.416831, acc: 60.94%, op_acc: 35.16%] [G loss: 0.970718]\n",
      "epoch:27 step:21436[D loss: 0.426287, acc: 53.91%, op_acc: 40.62%] [G loss: 0.927795]\n",
      "epoch:27 step:21437[D loss: 0.418887, acc: 64.06%, op_acc: 35.94%] [G loss: 0.969115]\n",
      "epoch:27 step:21438[D loss: 0.423097, acc: 66.41%, op_acc: 39.06%] [G loss: 0.961595]\n",
      "epoch:27 step:21439[D loss: 0.445354, acc: 58.59%, op_acc: 40.62%] [G loss: 0.841958]\n",
      "epoch:27 step:21440[D loss: 0.434102, acc: 50.00%, op_acc: 39.84%] [G loss: 0.868557]\n",
      "epoch:27 step:21441[D loss: 0.445254, acc: 49.22%, op_acc: 40.62%] [G loss: 0.850706]\n",
      "epoch:27 step:21442[D loss: 0.419160, acc: 58.59%, op_acc: 37.50%] [G loss: 0.866501]\n",
      "epoch:27 step:21443[D loss: 0.424444, acc: 59.38%, op_acc: 36.72%] [G loss: 0.858779]\n",
      "epoch:27 step:21444[D loss: 0.410233, acc: 61.72%, op_acc: 40.62%] [G loss: 0.924140]\n",
      "epoch:27 step:21445[D loss: 0.447587, acc: 54.69%, op_acc: 35.16%] [G loss: 0.809523]\n",
      "epoch:27 step:21446[D loss: 0.426472, acc: 60.16%, op_acc: 41.41%] [G loss: 0.872993]\n",
      "epoch:27 step:21447[D loss: 0.408806, acc: 61.72%, op_acc: 40.62%] [G loss: 0.838751]\n",
      "epoch:27 step:21448[D loss: 0.405160, acc: 61.72%, op_acc: 42.19%] [G loss: 0.855886]\n",
      "epoch:27 step:21449[D loss: 0.408969, acc: 54.69%, op_acc: 44.53%] [G loss: 0.828543]\n",
      "epoch:27 step:21450[D loss: 0.430153, acc: 64.84%, op_acc: 42.97%] [G loss: 0.879197]\n",
      "##############\n",
      "[0.85120176 0.87095222 0.81634369 0.80007721 0.78138514 0.83332624\n",
      " 0.89171622 0.83272453 0.81383846 0.83519181]\n",
      "##########\n",
      "epoch:27 step:21451[D loss: 0.407291, acc: 59.38%, op_acc: 42.19%] [G loss: 0.902802]\n",
      "epoch:27 step:21452[D loss: 0.405606, acc: 57.81%, op_acc: 42.97%] [G loss: 0.833352]\n",
      "epoch:27 step:21453[D loss: 0.426658, acc: 58.59%, op_acc: 38.28%] [G loss: 0.878951]\n",
      "epoch:27 step:21454[D loss: 0.414752, acc: 63.28%, op_acc: 38.28%] [G loss: 0.896284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21455[D loss: 0.411661, acc: 63.28%, op_acc: 39.06%] [G loss: 0.811883]\n",
      "epoch:27 step:21456[D loss: 0.421316, acc: 63.28%, op_acc: 42.97%] [G loss: 0.862565]\n",
      "epoch:27 step:21457[D loss: 0.424324, acc: 59.38%, op_acc: 40.62%] [G loss: 0.892293]\n",
      "epoch:27 step:21458[D loss: 0.409641, acc: 55.47%, op_acc: 42.97%] [G loss: 0.931812]\n",
      "epoch:27 step:21459[D loss: 0.422181, acc: 57.03%, op_acc: 42.19%] [G loss: 0.855367]\n",
      "epoch:27 step:21460[D loss: 0.450876, acc: 54.69%, op_acc: 42.19%] [G loss: 0.828509]\n",
      "epoch:27 step:21461[D loss: 0.417033, acc: 60.16%, op_acc: 46.88%] [G loss: 0.887175]\n",
      "epoch:27 step:21462[D loss: 0.447349, acc: 59.38%, op_acc: 38.28%] [G loss: 0.822026]\n",
      "epoch:27 step:21463[D loss: 0.423598, acc: 60.94%, op_acc: 39.06%] [G loss: 0.938496]\n",
      "epoch:27 step:21464[D loss: 0.439716, acc: 56.25%, op_acc: 39.84%] [G loss: 0.895155]\n",
      "epoch:27 step:21465[D loss: 0.428783, acc: 59.38%, op_acc: 46.09%] [G loss: 0.825257]\n",
      "epoch:27 step:21466[D loss: 0.412556, acc: 59.38%, op_acc: 42.97%] [G loss: 0.838170]\n",
      "epoch:27 step:21467[D loss: 0.422546, acc: 58.59%, op_acc: 43.75%] [G loss: 0.920106]\n",
      "epoch:27 step:21468[D loss: 0.438659, acc: 56.25%, op_acc: 33.59%] [G loss: 0.894114]\n",
      "epoch:27 step:21469[D loss: 0.408676, acc: 64.06%, op_acc: 39.06%] [G loss: 0.926365]\n",
      "epoch:27 step:21470[D loss: 0.395690, acc: 64.84%, op_acc: 42.97%] [G loss: 0.898983]\n",
      "epoch:27 step:21471[D loss: 0.434904, acc: 60.94%, op_acc: 38.28%] [G loss: 0.921445]\n",
      "epoch:27 step:21472[D loss: 0.420908, acc: 56.25%, op_acc: 43.75%] [G loss: 0.844967]\n",
      "epoch:27 step:21473[D loss: 0.424691, acc: 55.47%, op_acc: 39.84%] [G loss: 0.882839]\n",
      "epoch:27 step:21474[D loss: 0.442717, acc: 51.56%, op_acc: 34.38%] [G loss: 0.887593]\n",
      "epoch:27 step:21475[D loss: 0.435802, acc: 64.06%, op_acc: 32.03%] [G loss: 0.849162]\n",
      "epoch:27 step:21476[D loss: 0.441831, acc: 52.34%, op_acc: 42.19%] [G loss: 0.847078]\n",
      "epoch:27 step:21477[D loss: 0.419393, acc: 57.81%, op_acc: 41.41%] [G loss: 0.887212]\n",
      "epoch:27 step:21478[D loss: 0.406760, acc: 59.38%, op_acc: 46.09%] [G loss: 0.933216]\n",
      "epoch:27 step:21479[D loss: 0.417494, acc: 58.59%, op_acc: 41.41%] [G loss: 0.863387]\n",
      "epoch:27 step:21480[D loss: 0.420662, acc: 59.38%, op_acc: 41.41%] [G loss: 0.850377]\n",
      "epoch:27 step:21481[D loss: 0.427895, acc: 59.38%, op_acc: 39.06%] [G loss: 0.958237]\n",
      "epoch:27 step:21482[D loss: 0.442953, acc: 57.03%, op_acc: 32.03%] [G loss: 0.830990]\n",
      "epoch:27 step:21483[D loss: 0.425258, acc: 56.25%, op_acc: 46.09%] [G loss: 0.861207]\n",
      "epoch:27 step:21484[D loss: 0.414711, acc: 57.03%, op_acc: 45.31%] [G loss: 0.900936]\n",
      "epoch:27 step:21485[D loss: 0.454744, acc: 53.12%, op_acc: 34.38%] [G loss: 0.904103]\n",
      "epoch:27 step:21486[D loss: 0.399302, acc: 64.06%, op_acc: 46.09%] [G loss: 0.848975]\n",
      "epoch:27 step:21487[D loss: 0.401063, acc: 68.75%, op_acc: 41.41%] [G loss: 0.897869]\n",
      "epoch:27 step:21488[D loss: 0.415436, acc: 61.72%, op_acc: 36.72%] [G loss: 0.839537]\n",
      "epoch:27 step:21489[D loss: 0.430252, acc: 57.81%, op_acc: 37.50%] [G loss: 0.865950]\n",
      "epoch:27 step:21490[D loss: 0.413347, acc: 62.50%, op_acc: 39.06%] [G loss: 0.922047]\n",
      "epoch:27 step:21491[D loss: 0.368735, acc: 71.88%, op_acc: 50.00%] [G loss: 0.947491]\n",
      "epoch:27 step:21492[D loss: 0.450030, acc: 53.91%, op_acc: 37.50%] [G loss: 0.844589]\n",
      "epoch:27 step:21493[D loss: 0.443366, acc: 56.25%, op_acc: 39.84%] [G loss: 0.811947]\n",
      "epoch:27 step:21494[D loss: 0.413149, acc: 57.81%, op_acc: 39.06%] [G loss: 0.932358]\n",
      "epoch:27 step:21495[D loss: 0.406982, acc: 57.81%, op_acc: 44.53%] [G loss: 0.853036]\n",
      "epoch:27 step:21496[D loss: 0.413147, acc: 50.78%, op_acc: 45.31%] [G loss: 0.871127]\n",
      "epoch:27 step:21497[D loss: 0.404743, acc: 63.28%, op_acc: 39.84%] [G loss: 0.822517]\n",
      "epoch:27 step:21498[D loss: 0.428420, acc: 60.94%, op_acc: 42.97%] [G loss: 0.851380]\n",
      "epoch:27 step:21499[D loss: 0.434697, acc: 57.03%, op_acc: 40.62%] [G loss: 0.862495]\n",
      "epoch:27 step:21500[D loss: 0.420726, acc: 60.94%, op_acc: 39.06%] [G loss: 0.865999]\n",
      "##############\n",
      "[0.84427516 0.87848076 0.80107952 0.79407672 0.79520731 0.81237107\n",
      " 0.88842814 0.82703723 0.82985222 0.82184592]\n",
      "##########\n",
      "epoch:27 step:21501[D loss: 0.409894, acc: 58.59%, op_acc: 46.88%] [G loss: 0.864234]\n",
      "epoch:27 step:21502[D loss: 0.423165, acc: 57.03%, op_acc: 36.72%] [G loss: 0.877909]\n",
      "epoch:27 step:21503[D loss: 0.418194, acc: 54.69%, op_acc: 37.50%] [G loss: 0.815393]\n",
      "epoch:27 step:21504[D loss: 0.408632, acc: 60.94%, op_acc: 43.75%] [G loss: 0.836212]\n",
      "epoch:27 step:21505[D loss: 0.436024, acc: 46.09%, op_acc: 44.53%] [G loss: 0.853106]\n",
      "epoch:27 step:21506[D loss: 0.413246, acc: 59.38%, op_acc: 38.28%] [G loss: 0.940687]\n",
      "epoch:27 step:21507[D loss: 0.426560, acc: 60.16%, op_acc: 39.06%] [G loss: 0.806871]\n",
      "epoch:27 step:21508[D loss: 0.457473, acc: 53.91%, op_acc: 33.59%] [G loss: 0.830343]\n",
      "epoch:27 step:21509[D loss: 0.385849, acc: 71.88%, op_acc: 45.31%] [G loss: 0.955590]\n",
      "epoch:27 step:21510[D loss: 0.420014, acc: 64.06%, op_acc: 37.50%] [G loss: 0.907462]\n",
      "epoch:27 step:21511[D loss: 0.426289, acc: 61.72%, op_acc: 39.84%] [G loss: 0.890645]\n",
      "epoch:27 step:21512[D loss: 0.432217, acc: 56.25%, op_acc: 42.19%] [G loss: 0.949958]\n",
      "epoch:27 step:21513[D loss: 0.408780, acc: 63.28%, op_acc: 38.28%] [G loss: 0.834723]\n",
      "epoch:27 step:21514[D loss: 0.407488, acc: 67.97%, op_acc: 35.94%] [G loss: 0.858551]\n",
      "epoch:27 step:21515[D loss: 0.427902, acc: 53.12%, op_acc: 39.84%] [G loss: 0.875437]\n",
      "epoch:27 step:21516[D loss: 0.385500, acc: 61.72%, op_acc: 48.44%] [G loss: 0.890745]\n",
      "epoch:27 step:21517[D loss: 0.407635, acc: 55.47%, op_acc: 42.97%] [G loss: 0.893484]\n",
      "epoch:27 step:21518[D loss: 0.389571, acc: 68.75%, op_acc: 39.06%] [G loss: 0.961629]\n",
      "epoch:27 step:21519[D loss: 0.385791, acc: 68.75%, op_acc: 44.53%] [G loss: 0.861262]\n",
      "epoch:27 step:21520[D loss: 0.409959, acc: 60.16%, op_acc: 40.62%] [G loss: 0.880575]\n",
      "epoch:27 step:21521[D loss: 0.390231, acc: 66.41%, op_acc: 42.97%] [G loss: 0.865771]\n",
      "epoch:27 step:21522[D loss: 0.424434, acc: 60.94%, op_acc: 45.31%] [G loss: 0.891199]\n",
      "epoch:27 step:21523[D loss: 0.442279, acc: 55.47%, op_acc: 41.41%] [G loss: 0.908521]\n",
      "epoch:27 step:21524[D loss: 0.426010, acc: 63.28%, op_acc: 43.75%] [G loss: 0.866779]\n",
      "epoch:27 step:21525[D loss: 0.428858, acc: 51.56%, op_acc: 43.75%] [G loss: 0.822432]\n",
      "epoch:27 step:21526[D loss: 0.411149, acc: 63.28%, op_acc: 44.53%] [G loss: 0.885536]\n",
      "epoch:27 step:21527[D loss: 0.423570, acc: 60.94%, op_acc: 36.72%] [G loss: 0.823831]\n",
      "epoch:27 step:21528[D loss: 0.411148, acc: 57.03%, op_acc: 42.19%] [G loss: 0.842909]\n",
      "epoch:27 step:21529[D loss: 0.413436, acc: 57.03%, op_acc: 46.09%] [G loss: 0.918972]\n",
      "epoch:27 step:21530[D loss: 0.441778, acc: 61.72%, op_acc: 34.38%] [G loss: 0.870463]\n",
      "epoch:27 step:21531[D loss: 0.383064, acc: 67.19%, op_acc: 39.06%] [G loss: 0.864414]\n",
      "epoch:27 step:21532[D loss: 0.454935, acc: 59.38%, op_acc: 36.72%] [G loss: 0.938023]\n",
      "epoch:27 step:21533[D loss: 0.439174, acc: 52.34%, op_acc: 39.84%] [G loss: 0.832946]\n",
      "epoch:27 step:21534[D loss: 0.427695, acc: 66.41%, op_acc: 35.94%] [G loss: 0.900785]\n",
      "epoch:27 step:21535[D loss: 0.397784, acc: 63.28%, op_acc: 42.19%] [G loss: 0.827019]\n",
      "epoch:27 step:21536[D loss: 0.395971, acc: 67.97%, op_acc: 39.84%] [G loss: 0.813241]\n",
      "epoch:27 step:21537[D loss: 0.436351, acc: 60.94%, op_acc: 38.28%] [G loss: 0.827149]\n",
      "epoch:27 step:21538[D loss: 0.398762, acc: 64.84%, op_acc: 42.97%] [G loss: 0.800036]\n",
      "epoch:27 step:21539[D loss: 0.421791, acc: 54.69%, op_acc: 40.62%] [G loss: 0.822181]\n",
      "epoch:27 step:21540[D loss: 0.429915, acc: 53.12%, op_acc: 46.88%] [G loss: 0.935096]\n",
      "epoch:27 step:21541[D loss: 0.419827, acc: 53.12%, op_acc: 39.06%] [G loss: 0.868350]\n",
      "epoch:27 step:21542[D loss: 0.433430, acc: 53.91%, op_acc: 42.19%] [G loss: 0.909863]\n",
      "epoch:27 step:21543[D loss: 0.401734, acc: 67.19%, op_acc: 36.72%] [G loss: 0.885056]\n",
      "epoch:27 step:21544[D loss: 0.409666, acc: 62.50%, op_acc: 43.75%] [G loss: 0.987602]\n",
      "epoch:27 step:21545[D loss: 0.411871, acc: 57.81%, op_acc: 39.06%] [G loss: 0.876804]\n",
      "epoch:27 step:21546[D loss: 0.392531, acc: 71.09%, op_acc: 43.75%] [G loss: 0.837373]\n",
      "epoch:27 step:21547[D loss: 0.423889, acc: 54.69%, op_acc: 39.06%] [G loss: 0.871011]\n",
      "epoch:27 step:21548[D loss: 0.456507, acc: 47.66%, op_acc: 36.72%] [G loss: 0.896628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21549[D loss: 0.405053, acc: 60.16%, op_acc: 42.97%] [G loss: 0.952731]\n",
      "epoch:27 step:21550[D loss: 0.433517, acc: 55.47%, op_acc: 42.19%] [G loss: 0.791036]\n",
      "##############\n",
      "[0.86216956 0.85360045 0.80634202 0.7909745  0.79812449 0.81201128\n",
      " 0.87722732 0.82208938 0.81394746 0.82938377]\n",
      "##########\n",
      "epoch:27 step:21551[D loss: 0.443005, acc: 51.56%, op_acc: 38.28%] [G loss: 0.866939]\n",
      "epoch:27 step:21552[D loss: 0.390513, acc: 70.31%, op_acc: 43.75%] [G loss: 0.875008]\n",
      "epoch:27 step:21553[D loss: 0.388604, acc: 64.06%, op_acc: 45.31%] [G loss: 0.862568]\n",
      "epoch:27 step:21554[D loss: 0.439595, acc: 55.47%, op_acc: 39.06%] [G loss: 0.936247]\n",
      "epoch:27 step:21555[D loss: 0.441628, acc: 57.03%, op_acc: 35.94%] [G loss: 0.796303]\n",
      "epoch:27 step:21556[D loss: 0.396943, acc: 59.38%, op_acc: 45.31%] [G loss: 0.971111]\n",
      "epoch:27 step:21557[D loss: 0.436365, acc: 56.25%, op_acc: 36.72%] [G loss: 0.853647]\n",
      "epoch:27 step:21558[D loss: 0.423810, acc: 60.16%, op_acc: 38.28%] [G loss: 0.971269]\n",
      "epoch:27 step:21559[D loss: 0.445511, acc: 51.56%, op_acc: 39.84%] [G loss: 0.857865]\n",
      "epoch:27 step:21560[D loss: 0.415297, acc: 51.56%, op_acc: 44.53%] [G loss: 0.883104]\n",
      "epoch:27 step:21561[D loss: 0.395270, acc: 64.06%, op_acc: 39.84%] [G loss: 0.906849]\n",
      "epoch:27 step:21562[D loss: 0.408572, acc: 57.03%, op_acc: 42.19%] [G loss: 0.869862]\n",
      "epoch:27 step:21563[D loss: 0.433035, acc: 62.50%, op_acc: 39.84%] [G loss: 0.834450]\n",
      "epoch:27 step:21564[D loss: 0.439263, acc: 55.47%, op_acc: 42.97%] [G loss: 0.945339]\n",
      "epoch:27 step:21565[D loss: 0.417306, acc: 61.72%, op_acc: 46.88%] [G loss: 0.847377]\n",
      "epoch:27 step:21566[D loss: 0.424044, acc: 57.03%, op_acc: 42.97%] [G loss: 0.863480]\n",
      "epoch:27 step:21567[D loss: 0.447679, acc: 55.47%, op_acc: 36.72%] [G loss: 0.867330]\n",
      "epoch:27 step:21568[D loss: 0.435437, acc: 58.59%, op_acc: 38.28%] [G loss: 0.897579]\n",
      "epoch:27 step:21569[D loss: 0.447756, acc: 57.81%, op_acc: 38.28%] [G loss: 0.871395]\n",
      "epoch:27 step:21570[D loss: 0.416053, acc: 66.41%, op_acc: 39.06%] [G loss: 0.906846]\n",
      "epoch:27 step:21571[D loss: 0.398347, acc: 61.72%, op_acc: 46.09%] [G loss: 0.885899]\n",
      "epoch:27 step:21572[D loss: 0.420489, acc: 64.06%, op_acc: 42.19%] [G loss: 0.875162]\n",
      "epoch:27 step:21573[D loss: 0.411334, acc: 60.94%, op_acc: 46.09%] [G loss: 0.879862]\n",
      "epoch:27 step:21574[D loss: 0.406243, acc: 61.72%, op_acc: 39.06%] [G loss: 0.890934]\n",
      "epoch:27 step:21575[D loss: 0.437426, acc: 66.41%, op_acc: 34.38%] [G loss: 0.953605]\n",
      "epoch:27 step:21576[D loss: 0.407808, acc: 60.16%, op_acc: 42.19%] [G loss: 0.879960]\n",
      "epoch:27 step:21577[D loss: 0.389359, acc: 64.84%, op_acc: 43.75%] [G loss: 0.885007]\n",
      "epoch:27 step:21578[D loss: 0.453007, acc: 53.91%, op_acc: 35.94%] [G loss: 0.921077]\n",
      "epoch:27 step:21579[D loss: 0.404932, acc: 63.28%, op_acc: 44.53%] [G loss: 1.012919]\n",
      "epoch:27 step:21580[D loss: 0.448758, acc: 50.00%, op_acc: 38.28%] [G loss: 0.858153]\n",
      "epoch:27 step:21581[D loss: 0.398237, acc: 60.16%, op_acc: 42.19%] [G loss: 0.913886]\n",
      "epoch:27 step:21582[D loss: 0.433258, acc: 58.59%, op_acc: 39.84%] [G loss: 0.872293]\n",
      "epoch:27 step:21583[D loss: 0.463166, acc: 52.34%, op_acc: 36.72%] [G loss: 0.817419]\n",
      "epoch:27 step:21584[D loss: 0.399433, acc: 59.38%, op_acc: 45.31%] [G loss: 0.887132]\n",
      "epoch:27 step:21585[D loss: 0.458912, acc: 53.12%, op_acc: 39.84%] [G loss: 0.923407]\n",
      "epoch:27 step:21586[D loss: 0.446995, acc: 55.47%, op_acc: 37.50%] [G loss: 0.930166]\n",
      "epoch:27 step:21587[D loss: 0.429154, acc: 54.69%, op_acc: 39.06%] [G loss: 0.865355]\n",
      "epoch:27 step:21588[D loss: 0.427046, acc: 57.03%, op_acc: 40.62%] [G loss: 0.937883]\n",
      "epoch:27 step:21589[D loss: 0.440143, acc: 53.12%, op_acc: 45.31%] [G loss: 0.940391]\n",
      "epoch:27 step:21590[D loss: 0.409428, acc: 62.50%, op_acc: 41.41%] [G loss: 0.863308]\n",
      "epoch:27 step:21591[D loss: 0.453459, acc: 61.72%, op_acc: 32.81%] [G loss: 0.858627]\n",
      "epoch:27 step:21592[D loss: 0.428071, acc: 67.97%, op_acc: 42.97%] [G loss: 0.853446]\n",
      "epoch:27 step:21593[D loss: 0.414998, acc: 57.81%, op_acc: 43.75%] [G loss: 0.773036]\n",
      "epoch:27 step:21594[D loss: 0.400137, acc: 64.84%, op_acc: 47.66%] [G loss: 0.871706]\n",
      "epoch:27 step:21595[D loss: 0.419453, acc: 63.28%, op_acc: 39.06%] [G loss: 0.907724]\n",
      "epoch:27 step:21596[D loss: 0.449479, acc: 57.03%, op_acc: 38.28%] [G loss: 0.811436]\n",
      "epoch:27 step:21597[D loss: 0.407216, acc: 61.72%, op_acc: 39.84%] [G loss: 0.919812]\n",
      "epoch:27 step:21598[D loss: 0.427892, acc: 60.16%, op_acc: 38.28%] [G loss: 0.884079]\n",
      "epoch:27 step:21599[D loss: 0.455693, acc: 56.25%, op_acc: 37.50%] [G loss: 0.795445]\n",
      "epoch:27 step:21600[D loss: 0.455916, acc: 53.12%, op_acc: 39.06%] [G loss: 0.795055]\n",
      "##############\n",
      "[0.88467457 0.85152988 0.81862366 0.80683666 0.82476628 0.82617349\n",
      " 0.88678058 0.83112851 0.80331998 0.82368709]\n",
      "##########\n",
      "epoch:27 step:21601[D loss: 0.432527, acc: 58.59%, op_acc: 38.28%] [G loss: 0.823875]\n",
      "epoch:27 step:21602[D loss: 0.426132, acc: 63.28%, op_acc: 35.16%] [G loss: 0.915125]\n",
      "epoch:27 step:21603[D loss: 0.436646, acc: 57.03%, op_acc: 35.16%] [G loss: 0.794979]\n",
      "epoch:27 step:21604[D loss: 0.461569, acc: 48.44%, op_acc: 41.41%] [G loss: 0.893642]\n",
      "epoch:27 step:21605[D loss: 0.417341, acc: 59.38%, op_acc: 38.28%] [G loss: 0.908256]\n",
      "epoch:27 step:21606[D loss: 0.380026, acc: 66.41%, op_acc: 41.41%] [G loss: 0.930517]\n",
      "epoch:27 step:21607[D loss: 0.411413, acc: 65.62%, op_acc: 39.06%] [G loss: 0.946630]\n",
      "epoch:27 step:21608[D loss: 0.440957, acc: 53.12%, op_acc: 33.59%] [G loss: 0.899988]\n",
      "epoch:27 step:21609[D loss: 0.455818, acc: 53.91%, op_acc: 34.38%] [G loss: 0.912887]\n",
      "epoch:27 step:21610[D loss: 0.421757, acc: 59.38%, op_acc: 38.28%] [G loss: 0.899103]\n",
      "epoch:27 step:21611[D loss: 0.429783, acc: 58.59%, op_acc: 39.84%] [G loss: 0.925514]\n",
      "epoch:27 step:21612[D loss: 0.421364, acc: 61.72%, op_acc: 37.50%] [G loss: 0.937854]\n",
      "epoch:27 step:21613[D loss: 0.470475, acc: 42.97%, op_acc: 34.38%] [G loss: 0.867004]\n",
      "epoch:27 step:21614[D loss: 0.440102, acc: 49.22%, op_acc: 41.41%] [G loss: 0.930745]\n",
      "epoch:27 step:21615[D loss: 0.407587, acc: 55.47%, op_acc: 47.66%] [G loss: 0.932047]\n",
      "epoch:27 step:21616[D loss: 0.420555, acc: 60.16%, op_acc: 39.06%] [G loss: 0.884544]\n",
      "epoch:27 step:21617[D loss: 0.405409, acc: 60.94%, op_acc: 39.84%] [G loss: 0.921674]\n",
      "epoch:27 step:21618[D loss: 0.456872, acc: 50.00%, op_acc: 36.72%] [G loss: 0.841310]\n",
      "epoch:27 step:21619[D loss: 0.451503, acc: 53.12%, op_acc: 34.38%] [G loss: 0.916573]\n",
      "epoch:27 step:21620[D loss: 0.438508, acc: 46.88%, op_acc: 43.75%] [G loss: 0.857609]\n",
      "epoch:27 step:21621[D loss: 0.436435, acc: 57.03%, op_acc: 39.84%] [G loss: 0.959993]\n",
      "epoch:27 step:21622[D loss: 0.412251, acc: 56.25%, op_acc: 44.53%] [G loss: 0.957909]\n",
      "epoch:27 step:21623[D loss: 0.401249, acc: 61.72%, op_acc: 35.94%] [G loss: 0.882671]\n",
      "epoch:27 step:21624[D loss: 0.459706, acc: 46.09%, op_acc: 41.41%] [G loss: 0.875543]\n",
      "epoch:27 step:21625[D loss: 0.410004, acc: 57.81%, op_acc: 43.75%] [G loss: 0.935280]\n",
      "epoch:27 step:21626[D loss: 0.452186, acc: 56.25%, op_acc: 35.16%] [G loss: 0.977515]\n",
      "epoch:27 step:21627[D loss: 0.411673, acc: 57.81%, op_acc: 40.62%] [G loss: 0.897592]\n",
      "epoch:27 step:21628[D loss: 0.397900, acc: 70.31%, op_acc: 39.84%] [G loss: 0.867920]\n",
      "epoch:27 step:21629[D loss: 0.442167, acc: 57.03%, op_acc: 37.50%] [G loss: 0.851270]\n",
      "epoch:27 step:21630[D loss: 0.448568, acc: 56.25%, op_acc: 41.41%] [G loss: 0.824680]\n",
      "epoch:27 step:21631[D loss: 0.416034, acc: 59.38%, op_acc: 45.31%] [G loss: 0.891730]\n",
      "epoch:27 step:21632[D loss: 0.402529, acc: 71.88%, op_acc: 35.94%] [G loss: 0.878296]\n",
      "epoch:27 step:21633[D loss: 0.417088, acc: 54.69%, op_acc: 42.97%] [G loss: 0.952701]\n",
      "epoch:27 step:21634[D loss: 0.404663, acc: 71.09%, op_acc: 32.81%] [G loss: 0.962377]\n",
      "epoch:27 step:21635[D loss: 0.412181, acc: 64.06%, op_acc: 37.50%] [G loss: 0.859548]\n",
      "epoch:27 step:21636[D loss: 0.434970, acc: 57.03%, op_acc: 39.84%] [G loss: 0.854603]\n",
      "epoch:27 step:21637[D loss: 0.447072, acc: 49.22%, op_acc: 39.06%] [G loss: 0.810085]\n",
      "epoch:27 step:21638[D loss: 0.426867, acc: 55.47%, op_acc: 46.88%] [G loss: 0.894447]\n",
      "epoch:27 step:21639[D loss: 0.440274, acc: 59.38%, op_acc: 37.50%] [G loss: 0.821022]\n",
      "epoch:27 step:21640[D loss: 0.408478, acc: 67.97%, op_acc: 41.41%] [G loss: 0.924276]\n",
      "epoch:27 step:21641[D loss: 0.416273, acc: 62.50%, op_acc: 35.16%] [G loss: 0.821879]\n",
      "epoch:27 step:21642[D loss: 0.416643, acc: 58.59%, op_acc: 38.28%] [G loss: 0.865734]\n",
      "epoch:27 step:21643[D loss: 0.405653, acc: 64.84%, op_acc: 43.75%] [G loss: 0.826630]\n",
      "epoch:27 step:21644[D loss: 0.444937, acc: 55.47%, op_acc: 36.72%] [G loss: 0.810792]\n",
      "epoch:27 step:21645[D loss: 0.395200, acc: 59.38%, op_acc: 46.09%] [G loss: 0.941296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21646[D loss: 0.382687, acc: 71.09%, op_acc: 39.06%] [G loss: 0.953448]\n",
      "epoch:27 step:21647[D loss: 0.419586, acc: 64.06%, op_acc: 39.06%] [G loss: 0.816084]\n",
      "epoch:27 step:21648[D loss: 0.424588, acc: 53.91%, op_acc: 42.19%] [G loss: 0.914863]\n",
      "epoch:27 step:21649[D loss: 0.450534, acc: 53.12%, op_acc: 32.81%] [G loss: 0.896934]\n",
      "epoch:27 step:21650[D loss: 0.417479, acc: 64.84%, op_acc: 35.94%] [G loss: 0.896769]\n",
      "##############\n",
      "[0.85756739 0.86153483 0.81168518 0.80860512 0.7817965  0.84255198\n",
      " 0.87126374 0.80897761 0.80165088 0.8078812 ]\n",
      "##########\n",
      "epoch:27 step:21651[D loss: 0.407229, acc: 60.94%, op_acc: 41.41%] [G loss: 0.943456]\n",
      "epoch:27 step:21652[D loss: 0.411931, acc: 50.78%, op_acc: 42.97%] [G loss: 0.917527]\n",
      "epoch:27 step:21653[D loss: 0.425110, acc: 59.38%, op_acc: 36.72%] [G loss: 0.899751]\n",
      "epoch:27 step:21654[D loss: 0.404496, acc: 60.94%, op_acc: 43.75%] [G loss: 0.911829]\n",
      "epoch:27 step:21655[D loss: 0.414477, acc: 60.16%, op_acc: 46.09%] [G loss: 0.844346]\n",
      "epoch:27 step:21656[D loss: 0.412000, acc: 58.59%, op_acc: 45.31%] [G loss: 0.804619]\n",
      "epoch:27 step:21657[D loss: 0.429523, acc: 58.59%, op_acc: 39.84%] [G loss: 0.837923]\n",
      "epoch:27 step:21658[D loss: 0.410518, acc: 60.16%, op_acc: 44.53%] [G loss: 0.931175]\n",
      "epoch:27 step:21659[D loss: 0.417483, acc: 58.59%, op_acc: 39.06%] [G loss: 0.822801]\n",
      "epoch:27 step:21660[D loss: 0.405408, acc: 60.94%, op_acc: 47.66%] [G loss: 0.844543]\n",
      "epoch:27 step:21661[D loss: 0.410681, acc: 64.06%, op_acc: 42.97%] [G loss: 0.898754]\n",
      "epoch:27 step:21662[D loss: 0.415323, acc: 58.59%, op_acc: 37.50%] [G loss: 0.876195]\n",
      "epoch:27 step:21663[D loss: 0.411490, acc: 60.16%, op_acc: 38.28%] [G loss: 0.925414]\n",
      "epoch:27 step:21664[D loss: 0.430860, acc: 59.38%, op_acc: 37.50%] [G loss: 0.838573]\n",
      "epoch:27 step:21665[D loss: 0.448696, acc: 61.72%, op_acc: 38.28%] [G loss: 0.879427]\n",
      "epoch:27 step:21666[D loss: 0.362632, acc: 70.31%, op_acc: 42.97%] [G loss: 0.898592]\n",
      "epoch:27 step:21667[D loss: 0.435619, acc: 59.38%, op_acc: 40.62%] [G loss: 0.880282]\n",
      "epoch:27 step:21668[D loss: 0.410391, acc: 67.19%, op_acc: 45.31%] [G loss: 0.882978]\n",
      "epoch:27 step:21669[D loss: 0.437884, acc: 58.59%, op_acc: 38.28%] [G loss: 0.853666]\n",
      "epoch:27 step:21670[D loss: 0.416281, acc: 60.16%, op_acc: 41.41%] [G loss: 0.910380]\n",
      "epoch:27 step:21671[D loss: 0.466905, acc: 57.03%, op_acc: 28.12%] [G loss: 0.883134]\n",
      "epoch:27 step:21672[D loss: 0.421193, acc: 56.25%, op_acc: 41.41%] [G loss: 0.829139]\n",
      "epoch:27 step:21673[D loss: 0.413935, acc: 67.19%, op_acc: 40.62%] [G loss: 0.910910]\n",
      "epoch:27 step:21674[D loss: 0.432902, acc: 58.59%, op_acc: 35.94%] [G loss: 0.877417]\n",
      "epoch:27 step:21675[D loss: 0.412834, acc: 58.59%, op_acc: 42.19%] [G loss: 0.924656]\n",
      "epoch:27 step:21676[D loss: 0.438647, acc: 63.28%, op_acc: 36.72%] [G loss: 0.868890]\n",
      "epoch:27 step:21677[D loss: 0.419480, acc: 58.59%, op_acc: 43.75%] [G loss: 0.865101]\n",
      "epoch:27 step:21678[D loss: 0.406821, acc: 64.06%, op_acc: 41.41%] [G loss: 0.847799]\n",
      "epoch:27 step:21679[D loss: 0.424564, acc: 58.59%, op_acc: 35.16%] [G loss: 0.890767]\n",
      "epoch:27 step:21680[D loss: 0.444153, acc: 51.56%, op_acc: 37.50%] [G loss: 0.840077]\n",
      "epoch:27 step:21681[D loss: 0.411211, acc: 58.59%, op_acc: 39.84%] [G loss: 0.875220]\n",
      "epoch:27 step:21682[D loss: 0.424234, acc: 59.38%, op_acc: 39.84%] [G loss: 0.911027]\n",
      "epoch:27 step:21683[D loss: 0.443037, acc: 59.38%, op_acc: 37.50%] [G loss: 0.872691]\n",
      "epoch:27 step:21684[D loss: 0.399683, acc: 60.94%, op_acc: 42.97%] [G loss: 0.936896]\n",
      "epoch:27 step:21685[D loss: 0.418626, acc: 65.62%, op_acc: 39.06%] [G loss: 0.843221]\n",
      "epoch:27 step:21686[D loss: 0.431594, acc: 67.97%, op_acc: 36.72%] [G loss: 0.927757]\n",
      "epoch:27 step:21687[D loss: 0.410854, acc: 62.50%, op_acc: 39.06%] [G loss: 0.899735]\n",
      "epoch:27 step:21688[D loss: 0.436792, acc: 57.81%, op_acc: 42.19%] [G loss: 0.863792]\n",
      "epoch:27 step:21689[D loss: 0.411989, acc: 63.28%, op_acc: 42.19%] [G loss: 0.814565]\n",
      "epoch:27 step:21690[D loss: 0.401862, acc: 62.50%, op_acc: 46.09%] [G loss: 0.862932]\n",
      "epoch:27 step:21691[D loss: 0.444683, acc: 54.69%, op_acc: 31.25%] [G loss: 0.805070]\n",
      "epoch:27 step:21692[D loss: 0.421919, acc: 57.03%, op_acc: 38.28%] [G loss: 0.798519]\n",
      "epoch:27 step:21693[D loss: 0.407324, acc: 58.59%, op_acc: 42.19%] [G loss: 0.857480]\n",
      "epoch:27 step:21694[D loss: 0.429787, acc: 55.47%, op_acc: 39.84%] [G loss: 0.863867]\n",
      "epoch:27 step:21695[D loss: 0.389189, acc: 65.62%, op_acc: 43.75%] [G loss: 0.919495]\n",
      "epoch:27 step:21696[D loss: 0.433235, acc: 50.78%, op_acc: 39.84%] [G loss: 0.908242]\n",
      "epoch:27 step:21697[D loss: 0.402994, acc: 68.75%, op_acc: 38.28%] [G loss: 0.896437]\n",
      "epoch:27 step:21698[D loss: 0.423777, acc: 59.38%, op_acc: 40.62%] [G loss: 0.916342]\n",
      "epoch:27 step:21699[D loss: 0.456287, acc: 46.88%, op_acc: 41.41%] [G loss: 0.801345]\n",
      "epoch:27 step:21700[D loss: 0.465144, acc: 47.66%, op_acc: 39.84%] [G loss: 0.974643]\n",
      "##############\n",
      "[0.84100029 0.84902309 0.82827268 0.80296066 0.78320829 0.83002665\n",
      " 0.87903288 0.82079837 0.80444612 0.83653842]\n",
      "##########\n",
      "epoch:27 step:21701[D loss: 0.412374, acc: 67.19%, op_acc: 38.28%] [G loss: 0.888851]\n",
      "epoch:27 step:21702[D loss: 0.409485, acc: 61.72%, op_acc: 39.84%] [G loss: 1.020007]\n",
      "epoch:27 step:21703[D loss: 0.443260, acc: 56.25%, op_acc: 37.50%] [G loss: 0.909159]\n",
      "epoch:27 step:21704[D loss: 0.436384, acc: 52.34%, op_acc: 38.28%] [G loss: 0.879410]\n",
      "epoch:27 step:21705[D loss: 0.412470, acc: 60.16%, op_acc: 41.41%] [G loss: 0.927214]\n",
      "epoch:27 step:21706[D loss: 0.415601, acc: 68.75%, op_acc: 38.28%] [G loss: 0.872911]\n",
      "epoch:27 step:21707[D loss: 0.442212, acc: 52.34%, op_acc: 36.72%] [G loss: 0.932389]\n",
      "epoch:27 step:21708[D loss: 0.457211, acc: 51.56%, op_acc: 36.72%] [G loss: 0.820890]\n",
      "epoch:27 step:21709[D loss: 0.442233, acc: 69.53%, op_acc: 35.94%] [G loss: 0.923363]\n",
      "epoch:27 step:21710[D loss: 0.415890, acc: 64.06%, op_acc: 41.41%] [G loss: 0.906007]\n",
      "epoch:27 step:21711[D loss: 0.427882, acc: 61.72%, op_acc: 41.41%] [G loss: 0.954677]\n",
      "epoch:27 step:21712[D loss: 0.425915, acc: 54.69%, op_acc: 43.75%] [G loss: 0.883862]\n",
      "epoch:27 step:21713[D loss: 0.415716, acc: 60.16%, op_acc: 43.75%] [G loss: 0.837087]\n",
      "epoch:27 step:21714[D loss: 0.411736, acc: 57.03%, op_acc: 42.19%] [G loss: 0.942327]\n",
      "epoch:27 step:21715[D loss: 0.438670, acc: 56.25%, op_acc: 35.94%] [G loss: 0.937612]\n",
      "epoch:27 step:21716[D loss: 0.433798, acc: 59.38%, op_acc: 37.50%] [G loss: 0.868619]\n",
      "epoch:27 step:21717[D loss: 0.398724, acc: 64.84%, op_acc: 44.53%] [G loss: 0.787323]\n",
      "epoch:27 step:21718[D loss: 0.453276, acc: 57.03%, op_acc: 35.94%] [G loss: 0.893093]\n",
      "epoch:27 step:21719[D loss: 0.434156, acc: 60.16%, op_acc: 37.50%] [G loss: 0.880898]\n",
      "epoch:27 step:21720[D loss: 0.418529, acc: 63.28%, op_acc: 37.50%] [G loss: 0.910670]\n",
      "epoch:27 step:21721[D loss: 0.393098, acc: 64.84%, op_acc: 44.53%] [G loss: 0.971480]\n",
      "epoch:27 step:21722[D loss: 0.462613, acc: 48.44%, op_acc: 35.94%] [G loss: 0.809650]\n",
      "epoch:27 step:21723[D loss: 0.398903, acc: 61.72%, op_acc: 46.09%] [G loss: 0.882860]\n",
      "epoch:27 step:21724[D loss: 0.411658, acc: 55.47%, op_acc: 42.19%] [G loss: 0.908354]\n",
      "epoch:27 step:21725[D loss: 0.433630, acc: 58.59%, op_acc: 41.41%] [G loss: 0.912604]\n",
      "epoch:27 step:21726[D loss: 0.408990, acc: 63.28%, op_acc: 39.06%] [G loss: 0.905400]\n",
      "epoch:27 step:21727[D loss: 0.428246, acc: 62.50%, op_acc: 34.38%] [G loss: 0.917538]\n",
      "epoch:27 step:21728[D loss: 0.448156, acc: 49.22%, op_acc: 34.38%] [G loss: 0.774150]\n",
      "epoch:27 step:21729[D loss: 0.417007, acc: 62.50%, op_acc: 37.50%] [G loss: 0.831300]\n",
      "epoch:27 step:21730[D loss: 0.434039, acc: 61.72%, op_acc: 39.06%] [G loss: 0.893287]\n",
      "epoch:27 step:21731[D loss: 0.401780, acc: 59.38%, op_acc: 45.31%] [G loss: 0.972851]\n",
      "epoch:27 step:21732[D loss: 0.401196, acc: 60.94%, op_acc: 34.38%] [G loss: 0.830533]\n",
      "epoch:27 step:21733[D loss: 0.421473, acc: 61.72%, op_acc: 41.41%] [G loss: 0.929269]\n",
      "epoch:27 step:21734[D loss: 0.423898, acc: 56.25%, op_acc: 43.75%] [G loss: 0.913414]\n",
      "epoch:27 step:21735[D loss: 0.394019, acc: 71.88%, op_acc: 39.84%] [G loss: 0.967660]\n",
      "epoch:27 step:21736[D loss: 0.400934, acc: 64.06%, op_acc: 42.19%] [G loss: 0.901798]\n",
      "epoch:27 step:21737[D loss: 0.440327, acc: 56.25%, op_acc: 31.25%] [G loss: 0.847772]\n",
      "epoch:27 step:21738[D loss: 0.413161, acc: 61.72%, op_acc: 41.41%] [G loss: 0.880147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21739[D loss: 0.430814, acc: 55.47%, op_acc: 42.19%] [G loss: 0.845091]\n",
      "epoch:27 step:21740[D loss: 0.399510, acc: 60.16%, op_acc: 45.31%] [G loss: 0.741459]\n",
      "epoch:27 step:21741[D loss: 0.423731, acc: 55.47%, op_acc: 43.75%] [G loss: 0.850075]\n",
      "epoch:27 step:21742[D loss: 0.398939, acc: 64.84%, op_acc: 49.22%] [G loss: 0.927813]\n",
      "epoch:27 step:21743[D loss: 0.429819, acc: 58.59%, op_acc: 40.62%] [G loss: 0.845719]\n",
      "epoch:27 step:21744[D loss: 0.419480, acc: 60.94%, op_acc: 43.75%] [G loss: 0.844819]\n",
      "epoch:27 step:21745[D loss: 0.427040, acc: 60.16%, op_acc: 40.62%] [G loss: 0.915239]\n",
      "epoch:27 step:21746[D loss: 0.429708, acc: 60.94%, op_acc: 35.94%] [G loss: 0.850267]\n",
      "epoch:27 step:21747[D loss: 0.443246, acc: 50.78%, op_acc: 36.72%] [G loss: 0.915831]\n",
      "epoch:27 step:21748[D loss: 0.456309, acc: 50.00%, op_acc: 42.19%] [G loss: 0.912049]\n",
      "epoch:27 step:21749[D loss: 0.422015, acc: 57.03%, op_acc: 38.28%] [G loss: 0.920562]\n",
      "epoch:27 step:21750[D loss: 0.420082, acc: 62.50%, op_acc: 38.28%] [G loss: 0.863976]\n",
      "##############\n",
      "[0.85155806 0.85423174 0.80199624 0.79223099 0.79503199 0.83589969\n",
      " 0.88595717 0.83293949 0.80139193 0.82462126]\n",
      "##########\n",
      "epoch:27 step:21751[D loss: 0.421585, acc: 57.81%, op_acc: 39.84%] [G loss: 0.927680]\n",
      "epoch:27 step:21752[D loss: 0.419160, acc: 63.28%, op_acc: 36.72%] [G loss: 0.879037]\n",
      "epoch:27 step:21753[D loss: 0.419624, acc: 59.38%, op_acc: 38.28%] [G loss: 0.873845]\n",
      "epoch:27 step:21754[D loss: 0.398413, acc: 62.50%, op_acc: 35.16%] [G loss: 0.802977]\n",
      "epoch:27 step:21755[D loss: 0.411887, acc: 61.72%, op_acc: 41.41%] [G loss: 0.907844]\n",
      "epoch:27 step:21756[D loss: 0.400813, acc: 62.50%, op_acc: 36.72%] [G loss: 0.910756]\n",
      "epoch:27 step:21757[D loss: 0.434399, acc: 60.94%, op_acc: 39.84%] [G loss: 0.872361]\n",
      "epoch:27 step:21758[D loss: 0.406809, acc: 64.84%, op_acc: 35.94%] [G loss: 0.947589]\n",
      "epoch:27 step:21759[D loss: 0.444618, acc: 56.25%, op_acc: 35.16%] [G loss: 0.817795]\n",
      "epoch:27 step:21760[D loss: 0.427001, acc: 53.12%, op_acc: 39.06%] [G loss: 0.847311]\n",
      "epoch:27 step:21761[D loss: 0.439851, acc: 49.22%, op_acc: 41.41%] [G loss: 0.876874]\n",
      "epoch:27 step:21762[D loss: 0.417050, acc: 56.25%, op_acc: 43.75%] [G loss: 0.941689]\n",
      "epoch:27 step:21763[D loss: 0.453662, acc: 50.00%, op_acc: 32.81%] [G loss: 0.799228]\n",
      "epoch:27 step:21764[D loss: 0.458828, acc: 57.03%, op_acc: 35.16%] [G loss: 0.893461]\n",
      "epoch:27 step:21765[D loss: 0.423019, acc: 53.91%, op_acc: 41.41%] [G loss: 0.861355]\n",
      "epoch:27 step:21766[D loss: 0.393362, acc: 62.50%, op_acc: 43.75%] [G loss: 0.889214]\n",
      "epoch:27 step:21767[D loss: 0.416619, acc: 65.62%, op_acc: 37.50%] [G loss: 0.871425]\n",
      "epoch:27 step:21768[D loss: 0.467972, acc: 55.47%, op_acc: 31.25%] [G loss: 0.819323]\n",
      "epoch:27 step:21769[D loss: 0.399119, acc: 61.72%, op_acc: 40.62%] [G loss: 0.911473]\n",
      "epoch:27 step:21770[D loss: 0.406462, acc: 60.94%, op_acc: 42.97%] [G loss: 0.898240]\n",
      "epoch:27 step:21771[D loss: 0.471200, acc: 52.34%, op_acc: 39.06%] [G loss: 0.839827]\n",
      "epoch:27 step:21772[D loss: 0.428549, acc: 55.47%, op_acc: 42.19%] [G loss: 0.839287]\n",
      "epoch:27 step:21773[D loss: 0.430110, acc: 62.50%, op_acc: 36.72%] [G loss: 0.859576]\n",
      "epoch:27 step:21774[D loss: 0.422330, acc: 59.38%, op_acc: 39.06%] [G loss: 0.836886]\n",
      "epoch:27 step:21775[D loss: 0.424452, acc: 60.16%, op_acc: 42.97%] [G loss: 0.999392]\n",
      "epoch:27 step:21776[D loss: 0.437301, acc: 53.91%, op_acc: 42.19%] [G loss: 0.883679]\n",
      "epoch:27 step:21777[D loss: 0.415891, acc: 67.97%, op_acc: 43.75%] [G loss: 0.841178]\n",
      "epoch:27 step:21778[D loss: 0.449208, acc: 53.12%, op_acc: 37.50%] [G loss: 0.806299]\n",
      "epoch:27 step:21779[D loss: 0.450083, acc: 55.47%, op_acc: 37.50%] [G loss: 0.888652]\n",
      "epoch:27 step:21780[D loss: 0.410868, acc: 61.72%, op_acc: 44.53%] [G loss: 0.916940]\n",
      "epoch:27 step:21781[D loss: 0.439100, acc: 56.25%, op_acc: 34.38%] [G loss: 0.908214]\n",
      "epoch:27 step:21782[D loss: 0.425921, acc: 59.38%, op_acc: 32.81%] [G loss: 0.851835]\n",
      "epoch:27 step:21783[D loss: 0.454405, acc: 56.25%, op_acc: 35.94%] [G loss: 0.905424]\n",
      "epoch:27 step:21784[D loss: 0.432284, acc: 54.69%, op_acc: 42.19%] [G loss: 0.822277]\n",
      "epoch:27 step:21785[D loss: 0.432131, acc: 60.94%, op_acc: 39.84%] [G loss: 0.868553]\n",
      "epoch:27 step:21786[D loss: 0.455273, acc: 47.66%, op_acc: 38.28%] [G loss: 0.834941]\n",
      "epoch:27 step:21787[D loss: 0.433757, acc: 55.47%, op_acc: 36.72%] [G loss: 0.832121]\n",
      "epoch:27 step:21788[D loss: 0.451954, acc: 53.91%, op_acc: 39.84%] [G loss: 0.815794]\n",
      "epoch:27 step:21789[D loss: 0.407440, acc: 67.19%, op_acc: 37.50%] [G loss: 0.906739]\n",
      "epoch:27 step:21790[D loss: 0.432578, acc: 55.47%, op_acc: 35.94%] [G loss: 0.874334]\n",
      "epoch:27 step:21791[D loss: 0.408576, acc: 63.28%, op_acc: 39.84%] [G loss: 0.854450]\n",
      "epoch:27 step:21792[D loss: 0.441989, acc: 54.69%, op_acc: 39.84%] [G loss: 0.893162]\n",
      "epoch:27 step:21793[D loss: 0.435581, acc: 60.94%, op_acc: 33.59%] [G loss: 0.861944]\n",
      "epoch:27 step:21794[D loss: 0.438596, acc: 57.03%, op_acc: 37.50%] [G loss: 0.865355]\n",
      "epoch:27 step:21795[D loss: 0.420317, acc: 58.59%, op_acc: 36.72%] [G loss: 0.858922]\n",
      "epoch:27 step:21796[D loss: 0.427661, acc: 57.81%, op_acc: 39.84%] [G loss: 0.854530]\n",
      "epoch:27 step:21797[D loss: 0.391089, acc: 59.38%, op_acc: 40.62%] [G loss: 0.885864]\n",
      "epoch:27 step:21798[D loss: 0.431414, acc: 58.59%, op_acc: 39.06%] [G loss: 0.880980]\n",
      "epoch:27 step:21799[D loss: 0.425273, acc: 51.56%, op_acc: 41.41%] [G loss: 0.854499]\n",
      "epoch:27 step:21800[D loss: 0.451356, acc: 50.78%, op_acc: 35.94%] [G loss: 0.871392]\n",
      "##############\n",
      "[0.85080625 0.85532857 0.81046179 0.78712692 0.79425634 0.81327649\n",
      " 0.85444371 0.81330865 0.81102851 0.8301164 ]\n",
      "##########\n",
      "epoch:27 step:21801[D loss: 0.453975, acc: 51.56%, op_acc: 35.94%] [G loss: 0.823266]\n",
      "epoch:27 step:21802[D loss: 0.397652, acc: 64.84%, op_acc: 38.28%] [G loss: 0.931873]\n",
      "epoch:27 step:21803[D loss: 0.437506, acc: 57.03%, op_acc: 39.06%] [G loss: 0.880314]\n",
      "epoch:27 step:21804[D loss: 0.407672, acc: 63.28%, op_acc: 44.53%] [G loss: 0.874051]\n",
      "epoch:27 step:21805[D loss: 0.431765, acc: 60.94%, op_acc: 37.50%] [G loss: 0.921833]\n",
      "epoch:27 step:21806[D loss: 0.416405, acc: 61.72%, op_acc: 45.31%] [G loss: 0.900272]\n",
      "epoch:27 step:21807[D loss: 0.430196, acc: 57.03%, op_acc: 39.06%] [G loss: 0.892964]\n",
      "epoch:27 step:21808[D loss: 0.452545, acc: 50.00%, op_acc: 36.72%] [G loss: 0.814511]\n",
      "epoch:27 step:21809[D loss: 0.425543, acc: 52.34%, op_acc: 40.62%] [G loss: 0.860609]\n",
      "epoch:27 step:21810[D loss: 0.422303, acc: 60.94%, op_acc: 45.31%] [G loss: 0.815654]\n",
      "epoch:27 step:21811[D loss: 0.418097, acc: 62.50%, op_acc: 41.41%] [G loss: 0.895476]\n",
      "epoch:27 step:21812[D loss: 0.427260, acc: 67.19%, op_acc: 36.72%] [G loss: 0.880454]\n",
      "epoch:27 step:21813[D loss: 0.426845, acc: 55.47%, op_acc: 40.62%] [G loss: 0.835303]\n",
      "epoch:27 step:21814[D loss: 0.438686, acc: 54.69%, op_acc: 36.72%] [G loss: 0.918887]\n",
      "epoch:27 step:21815[D loss: 0.414894, acc: 60.94%, op_acc: 45.31%] [G loss: 0.897083]\n",
      "epoch:27 step:21816[D loss: 0.438656, acc: 53.12%, op_acc: 37.50%] [G loss: 0.849719]\n",
      "epoch:27 step:21817[D loss: 0.417426, acc: 61.72%, op_acc: 35.94%] [G loss: 0.859318]\n",
      "epoch:27 step:21818[D loss: 0.399649, acc: 63.28%, op_acc: 39.06%] [G loss: 0.887475]\n",
      "epoch:27 step:21819[D loss: 0.434838, acc: 52.34%, op_acc: 41.41%] [G loss: 0.869583]\n",
      "epoch:27 step:21820[D loss: 0.420131, acc: 62.50%, op_acc: 40.62%] [G loss: 0.804356]\n",
      "epoch:27 step:21821[D loss: 0.434461, acc: 58.59%, op_acc: 38.28%] [G loss: 0.942693]\n",
      "epoch:27 step:21822[D loss: 0.396882, acc: 67.97%, op_acc: 42.19%] [G loss: 0.904152]\n",
      "epoch:27 step:21823[D loss: 0.429252, acc: 61.72%, op_acc: 40.62%] [G loss: 0.853046]\n",
      "epoch:27 step:21824[D loss: 0.407256, acc: 60.16%, op_acc: 43.75%] [G loss: 0.953181]\n",
      "epoch:27 step:21825[D loss: 0.421452, acc: 57.81%, op_acc: 39.06%] [G loss: 0.865420]\n",
      "epoch:27 step:21826[D loss: 0.404314, acc: 57.81%, op_acc: 43.75%] [G loss: 0.912761]\n",
      "epoch:27 step:21827[D loss: 0.399190, acc: 62.50%, op_acc: 42.19%] [G loss: 0.859103]\n",
      "epoch:27 step:21828[D loss: 0.430861, acc: 53.12%, op_acc: 39.06%] [G loss: 0.823007]\n",
      "epoch:27 step:21829[D loss: 0.421508, acc: 60.16%, op_acc: 44.53%] [G loss: 0.896748]\n",
      "epoch:27 step:21830[D loss: 0.429649, acc: 59.38%, op_acc: 37.50%] [G loss: 0.947760]\n",
      "epoch:27 step:21831[D loss: 0.404228, acc: 58.59%, op_acc: 42.97%] [G loss: 0.857808]\n",
      "epoch:27 step:21832[D loss: 0.434372, acc: 63.28%, op_acc: 37.50%] [G loss: 0.826568]\n",
      "epoch:27 step:21833[D loss: 0.424764, acc: 61.72%, op_acc: 39.84%] [G loss: 0.819507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21834[D loss: 0.419846, acc: 58.59%, op_acc: 43.75%] [G loss: 0.906471]\n",
      "epoch:27 step:21835[D loss: 0.421979, acc: 62.50%, op_acc: 41.41%] [G loss: 0.905919]\n",
      "epoch:27 step:21836[D loss: 0.433187, acc: 56.25%, op_acc: 41.41%] [G loss: 0.907020]\n",
      "epoch:27 step:21837[D loss: 0.415157, acc: 58.59%, op_acc: 39.84%] [G loss: 0.803228]\n",
      "epoch:27 step:21838[D loss: 0.472333, acc: 50.78%, op_acc: 32.03%] [G loss: 0.866047]\n",
      "epoch:27 step:21839[D loss: 0.435552, acc: 53.91%, op_acc: 37.50%] [G loss: 0.884533]\n",
      "epoch:27 step:21840[D loss: 0.429192, acc: 55.47%, op_acc: 45.31%] [G loss: 0.784612]\n",
      "epoch:27 step:21841[D loss: 0.419194, acc: 57.03%, op_acc: 47.66%] [G loss: 0.836347]\n",
      "epoch:27 step:21842[D loss: 0.407045, acc: 65.62%, op_acc: 39.06%] [G loss: 0.853848]\n",
      "epoch:27 step:21843[D loss: 0.409680, acc: 63.28%, op_acc: 44.53%] [G loss: 0.854482]\n",
      "epoch:27 step:21844[D loss: 0.406683, acc: 62.50%, op_acc: 39.06%] [G loss: 0.883306]\n",
      "epoch:27 step:21845[D loss: 0.394977, acc: 56.25%, op_acc: 46.88%] [G loss: 0.890683]\n",
      "epoch:27 step:21846[D loss: 0.451972, acc: 54.69%, op_acc: 36.72%] [G loss: 0.863929]\n",
      "epoch:27 step:21847[D loss: 0.421100, acc: 61.72%, op_acc: 40.62%] [G loss: 0.852690]\n",
      "epoch:27 step:21848[D loss: 0.405363, acc: 66.41%, op_acc: 41.41%] [G loss: 0.844426]\n",
      "epoch:27 step:21849[D loss: 0.435904, acc: 54.69%, op_acc: 38.28%] [G loss: 0.832206]\n",
      "epoch:27 step:21850[D loss: 0.430776, acc: 54.69%, op_acc: 37.50%] [G loss: 0.854426]\n",
      "##############\n",
      "[0.86953091 0.8637331  0.82959676 0.81290417 0.79929737 0.81893087\n",
      " 0.90089823 0.80300282 0.80332448 0.84512144]\n",
      "##########\n",
      "epoch:27 step:21851[D loss: 0.443764, acc: 51.56%, op_acc: 42.19%] [G loss: 0.836631]\n",
      "epoch:27 step:21852[D loss: 0.403175, acc: 60.94%, op_acc: 43.75%] [G loss: 0.871675]\n",
      "epoch:27 step:21853[D loss: 0.408765, acc: 54.69%, op_acc: 45.31%] [G loss: 0.848663]\n",
      "epoch:27 step:21854[D loss: 0.404953, acc: 62.50%, op_acc: 38.28%] [G loss: 0.808398]\n",
      "epoch:27 step:21855[D loss: 0.439440, acc: 54.69%, op_acc: 39.06%] [G loss: 0.869314]\n",
      "epoch:27 step:21856[D loss: 0.383651, acc: 71.88%, op_acc: 39.84%] [G loss: 0.873581]\n",
      "epoch:27 step:21857[D loss: 0.444008, acc: 53.91%, op_acc: 42.19%] [G loss: 0.875531]\n",
      "epoch:27 step:21858[D loss: 0.454819, acc: 50.00%, op_acc: 35.94%] [G loss: 0.892521]\n",
      "epoch:27 step:21859[D loss: 0.436538, acc: 58.59%, op_acc: 35.16%] [G loss: 0.908205]\n",
      "epoch:27 step:21860[D loss: 0.421637, acc: 62.50%, op_acc: 40.62%] [G loss: 0.808152]\n",
      "epoch:27 step:21861[D loss: 0.423514, acc: 60.16%, op_acc: 40.62%] [G loss: 0.850234]\n",
      "epoch:27 step:21862[D loss: 0.414579, acc: 64.84%, op_acc: 40.62%] [G loss: 0.909874]\n",
      "epoch:27 step:21863[D loss: 0.449794, acc: 57.03%, op_acc: 40.62%] [G loss: 0.894768]\n",
      "epoch:27 step:21864[D loss: 0.452947, acc: 50.78%, op_acc: 34.38%] [G loss: 0.887584]\n",
      "epoch:27 step:21865[D loss: 0.416408, acc: 60.94%, op_acc: 40.62%] [G loss: 0.918466]\n",
      "epoch:27 step:21866[D loss: 0.415220, acc: 60.16%, op_acc: 35.94%] [G loss: 0.867278]\n",
      "epoch:27 step:21867[D loss: 0.416837, acc: 55.47%, op_acc: 37.50%] [G loss: 0.850526]\n",
      "epoch:27 step:21868[D loss: 0.437692, acc: 55.47%, op_acc: 39.06%] [G loss: 0.829628]\n",
      "epoch:28 step:21869[D loss: 0.403356, acc: 60.16%, op_acc: 42.19%] [G loss: 0.938586]\n",
      "epoch:28 step:21870[D loss: 0.405216, acc: 61.72%, op_acc: 43.75%] [G loss: 0.846557]\n",
      "epoch:28 step:21871[D loss: 0.425404, acc: 64.06%, op_acc: 39.06%] [G loss: 0.897754]\n",
      "epoch:28 step:21872[D loss: 0.403256, acc: 58.59%, op_acc: 42.19%] [G loss: 0.896058]\n",
      "epoch:28 step:21873[D loss: 0.409295, acc: 53.12%, op_acc: 40.62%] [G loss: 0.902444]\n",
      "epoch:28 step:21874[D loss: 0.426822, acc: 62.50%, op_acc: 42.97%] [G loss: 0.851492]\n",
      "epoch:28 step:21875[D loss: 0.421426, acc: 55.47%, op_acc: 40.62%] [G loss: 0.912101]\n",
      "epoch:28 step:21876[D loss: 0.430185, acc: 58.59%, op_acc: 41.41%] [G loss: 0.862120]\n",
      "epoch:28 step:21877[D loss: 0.427837, acc: 53.91%, op_acc: 36.72%] [G loss: 0.897694]\n",
      "epoch:28 step:21878[D loss: 0.431431, acc: 51.56%, op_acc: 36.72%] [G loss: 0.860876]\n",
      "epoch:28 step:21879[D loss: 0.450057, acc: 55.47%, op_acc: 39.84%] [G loss: 0.931358]\n",
      "epoch:28 step:21880[D loss: 0.418890, acc: 54.69%, op_acc: 39.06%] [G loss: 0.912994]\n",
      "epoch:28 step:21881[D loss: 0.421281, acc: 62.50%, op_acc: 36.72%] [G loss: 0.912947]\n",
      "epoch:28 step:21882[D loss: 0.445291, acc: 50.78%, op_acc: 39.84%] [G loss: 0.937196]\n",
      "epoch:28 step:21883[D loss: 0.421200, acc: 58.59%, op_acc: 39.06%] [G loss: 0.869976]\n",
      "epoch:28 step:21884[D loss: 0.406026, acc: 57.81%, op_acc: 45.31%] [G loss: 0.943847]\n",
      "epoch:28 step:21885[D loss: 0.398434, acc: 64.84%, op_acc: 43.75%] [G loss: 0.891878]\n",
      "epoch:28 step:21886[D loss: 0.417575, acc: 61.72%, op_acc: 39.06%] [G loss: 0.844824]\n",
      "epoch:28 step:21887[D loss: 0.421589, acc: 60.16%, op_acc: 44.53%] [G loss: 0.856738]\n",
      "epoch:28 step:21888[D loss: 0.441680, acc: 57.03%, op_acc: 35.94%] [G loss: 0.815546]\n",
      "epoch:28 step:21889[D loss: 0.400298, acc: 71.88%, op_acc: 32.81%] [G loss: 0.901853]\n",
      "epoch:28 step:21890[D loss: 0.457730, acc: 49.22%, op_acc: 42.97%] [G loss: 0.848273]\n",
      "epoch:28 step:21891[D loss: 0.429803, acc: 54.69%, op_acc: 42.19%] [G loss: 0.848755]\n",
      "epoch:28 step:21892[D loss: 0.461406, acc: 56.25%, op_acc: 35.94%] [G loss: 0.831292]\n",
      "epoch:28 step:21893[D loss: 0.451359, acc: 59.38%, op_acc: 35.94%] [G loss: 0.905798]\n",
      "epoch:28 step:21894[D loss: 0.445335, acc: 55.47%, op_acc: 39.06%] [G loss: 0.868387]\n",
      "epoch:28 step:21895[D loss: 0.420793, acc: 67.19%, op_acc: 42.97%] [G loss: 0.880375]\n",
      "epoch:28 step:21896[D loss: 0.412165, acc: 60.94%, op_acc: 39.06%] [G loss: 0.924994]\n",
      "epoch:28 step:21897[D loss: 0.411226, acc: 60.16%, op_acc: 43.75%] [G loss: 0.872934]\n",
      "epoch:28 step:21898[D loss: 0.424980, acc: 52.34%, op_acc: 42.19%] [G loss: 0.883966]\n",
      "epoch:28 step:21899[D loss: 0.446646, acc: 54.69%, op_acc: 37.50%] [G loss: 1.016485]\n",
      "epoch:28 step:21900[D loss: 0.441086, acc: 55.47%, op_acc: 35.94%] [G loss: 0.911514]\n",
      "##############\n",
      "[0.86627601 0.85956706 0.81013672 0.80770295 0.80966921 0.81122953\n",
      " 0.88071596 0.83350311 0.8046539  0.81637821]\n",
      "##########\n",
      "epoch:28 step:21901[D loss: 0.393146, acc: 57.03%, op_acc: 48.44%] [G loss: 0.983711]\n",
      "epoch:28 step:21902[D loss: 0.393299, acc: 65.62%, op_acc: 42.19%] [G loss: 0.823765]\n",
      "epoch:28 step:21903[D loss: 0.429602, acc: 57.81%, op_acc: 39.84%] [G loss: 0.991186]\n",
      "epoch:28 step:21904[D loss: 0.399271, acc: 65.62%, op_acc: 42.97%] [G loss: 0.881280]\n",
      "epoch:28 step:21905[D loss: 0.397800, acc: 69.53%, op_acc: 41.41%] [G loss: 0.817675]\n",
      "epoch:28 step:21906[D loss: 0.402877, acc: 65.62%, op_acc: 42.97%] [G loss: 0.877484]\n",
      "epoch:28 step:21907[D loss: 0.408179, acc: 57.03%, op_acc: 42.97%] [G loss: 0.846197]\n",
      "epoch:28 step:21908[D loss: 0.445260, acc: 51.56%, op_acc: 38.28%] [G loss: 0.851023]\n",
      "epoch:28 step:21909[D loss: 0.404872, acc: 60.94%, op_acc: 39.06%] [G loss: 0.895336]\n",
      "epoch:28 step:21910[D loss: 0.405514, acc: 56.25%, op_acc: 41.41%] [G loss: 0.871385]\n",
      "epoch:28 step:21911[D loss: 0.424060, acc: 64.06%, op_acc: 41.41%] [G loss: 0.890947]\n",
      "epoch:28 step:21912[D loss: 0.415190, acc: 59.38%, op_acc: 40.62%] [G loss: 0.869805]\n",
      "epoch:28 step:21913[D loss: 0.407072, acc: 63.28%, op_acc: 40.62%] [G loss: 0.859638]\n",
      "epoch:28 step:21914[D loss: 0.411251, acc: 59.38%, op_acc: 41.41%] [G loss: 0.859459]\n",
      "epoch:28 step:21915[D loss: 0.419324, acc: 59.38%, op_acc: 37.50%] [G loss: 0.894580]\n",
      "epoch:28 step:21916[D loss: 0.446091, acc: 60.16%, op_acc: 36.72%] [G loss: 0.764494]\n",
      "epoch:28 step:21917[D loss: 0.409357, acc: 59.38%, op_acc: 43.75%] [G loss: 0.820596]\n",
      "epoch:28 step:21918[D loss: 0.433371, acc: 59.38%, op_acc: 34.38%] [G loss: 0.817869]\n",
      "epoch:28 step:21919[D loss: 0.428245, acc: 62.50%, op_acc: 40.62%] [G loss: 0.821329]\n",
      "epoch:28 step:21920[D loss: 0.443184, acc: 57.81%, op_acc: 34.38%] [G loss: 0.971538]\n",
      "epoch:28 step:21921[D loss: 0.445757, acc: 60.94%, op_acc: 35.16%] [G loss: 0.784733]\n",
      "epoch:28 step:21922[D loss: 0.455774, acc: 57.81%, op_acc: 40.62%] [G loss: 0.850951]\n",
      "epoch:28 step:21923[D loss: 0.416094, acc: 60.16%, op_acc: 42.19%] [G loss: 0.794781]\n",
      "epoch:28 step:21924[D loss: 0.412457, acc: 63.28%, op_acc: 40.62%] [G loss: 0.809447]\n",
      "epoch:28 step:21925[D loss: 0.429518, acc: 57.81%, op_acc: 37.50%] [G loss: 0.920727]\n",
      "epoch:28 step:21926[D loss: 0.417301, acc: 56.25%, op_acc: 47.66%] [G loss: 0.943772]\n",
      "epoch:28 step:21927[D loss: 0.423329, acc: 53.91%, op_acc: 36.72%] [G loss: 0.798879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:21928[D loss: 0.401047, acc: 64.06%, op_acc: 42.97%] [G loss: 0.871103]\n",
      "epoch:28 step:21929[D loss: 0.440171, acc: 60.94%, op_acc: 36.72%] [G loss: 0.913473]\n",
      "epoch:28 step:21930[D loss: 0.426042, acc: 60.94%, op_acc: 38.28%] [G loss: 0.824484]\n",
      "epoch:28 step:21931[D loss: 0.410226, acc: 57.03%, op_acc: 40.62%] [G loss: 0.890506]\n",
      "epoch:28 step:21932[D loss: 0.406966, acc: 59.38%, op_acc: 44.53%] [G loss: 0.856801]\n",
      "epoch:28 step:21933[D loss: 0.424912, acc: 56.25%, op_acc: 41.41%] [G loss: 0.861764]\n",
      "epoch:28 step:21934[D loss: 0.436502, acc: 50.78%, op_acc: 39.84%] [G loss: 0.830478]\n",
      "epoch:28 step:21935[D loss: 0.411196, acc: 60.94%, op_acc: 37.50%] [G loss: 0.915981]\n",
      "epoch:28 step:21936[D loss: 0.390144, acc: 69.53%, op_acc: 50.00%] [G loss: 0.960446]\n",
      "epoch:28 step:21937[D loss: 0.388138, acc: 60.94%, op_acc: 45.31%] [G loss: 0.922768]\n",
      "epoch:28 step:21938[D loss: 0.409364, acc: 63.28%, op_acc: 42.19%] [G loss: 0.915706]\n",
      "epoch:28 step:21939[D loss: 0.468928, acc: 57.03%, op_acc: 35.94%] [G loss: 0.911285]\n",
      "epoch:28 step:21940[D loss: 0.424234, acc: 61.72%, op_acc: 35.16%] [G loss: 0.885960]\n",
      "epoch:28 step:21941[D loss: 0.411537, acc: 61.72%, op_acc: 46.88%] [G loss: 0.940011]\n",
      "epoch:28 step:21942[D loss: 0.391726, acc: 58.59%, op_acc: 44.53%] [G loss: 0.900521]\n",
      "epoch:28 step:21943[D loss: 0.424623, acc: 60.16%, op_acc: 39.84%] [G loss: 0.926122]\n",
      "epoch:28 step:21944[D loss: 0.423463, acc: 59.38%, op_acc: 41.41%] [G loss: 0.862716]\n",
      "epoch:28 step:21945[D loss: 0.424628, acc: 61.72%, op_acc: 36.72%] [G loss: 0.809152]\n",
      "epoch:28 step:21946[D loss: 0.477120, acc: 50.78%, op_acc: 28.91%] [G loss: 0.824207]\n",
      "epoch:28 step:21947[D loss: 0.414009, acc: 56.25%, op_acc: 40.62%] [G loss: 0.852822]\n",
      "epoch:28 step:21948[D loss: 0.451691, acc: 60.16%, op_acc: 35.94%] [G loss: 0.905038]\n",
      "epoch:28 step:21949[D loss: 0.451826, acc: 59.38%, op_acc: 30.47%] [G loss: 0.822411]\n",
      "epoch:28 step:21950[D loss: 0.410030, acc: 63.28%, op_acc: 37.50%] [G loss: 0.914177]\n",
      "##############\n",
      "[0.8688997  0.85402535 0.81026874 0.83225902 0.79603859 0.80952338\n",
      " 0.89185922 0.81342821 0.80373322 0.8487119 ]\n",
      "##########\n",
      "epoch:28 step:21951[D loss: 0.436889, acc: 55.47%, op_acc: 35.16%] [G loss: 0.820658]\n",
      "epoch:28 step:21952[D loss: 0.427312, acc: 60.16%, op_acc: 35.16%] [G loss: 0.892529]\n",
      "epoch:28 step:21953[D loss: 0.439138, acc: 59.38%, op_acc: 38.28%] [G loss: 0.840886]\n",
      "epoch:28 step:21954[D loss: 0.420390, acc: 53.12%, op_acc: 42.19%] [G loss: 0.885392]\n",
      "epoch:28 step:21955[D loss: 0.405114, acc: 64.84%, op_acc: 35.16%] [G loss: 0.914335]\n",
      "epoch:28 step:21956[D loss: 0.432879, acc: 52.34%, op_acc: 40.62%] [G loss: 0.781681]\n",
      "epoch:28 step:21957[D loss: 0.444194, acc: 53.91%, op_acc: 41.41%] [G loss: 0.855850]\n",
      "epoch:28 step:21958[D loss: 0.449751, acc: 57.03%, op_acc: 42.97%] [G loss: 0.822702]\n",
      "epoch:28 step:21959[D loss: 0.415346, acc: 57.03%, op_acc: 40.62%] [G loss: 0.829093]\n",
      "epoch:28 step:21960[D loss: 0.404303, acc: 62.50%, op_acc: 43.75%] [G loss: 0.912433]\n",
      "epoch:28 step:21961[D loss: 0.389473, acc: 63.28%, op_acc: 44.53%] [G loss: 0.911244]\n",
      "epoch:28 step:21962[D loss: 0.429234, acc: 59.38%, op_acc: 42.19%] [G loss: 0.858641]\n",
      "epoch:28 step:21963[D loss: 0.433149, acc: 63.28%, op_acc: 37.50%] [G loss: 0.812433]\n",
      "epoch:28 step:21964[D loss: 0.469112, acc: 53.91%, op_acc: 38.28%] [G loss: 0.897360]\n",
      "epoch:28 step:21965[D loss: 0.404383, acc: 60.16%, op_acc: 41.41%] [G loss: 0.940130]\n",
      "epoch:28 step:21966[D loss: 0.435959, acc: 57.03%, op_acc: 37.50%] [G loss: 0.765974]\n",
      "epoch:28 step:21967[D loss: 0.411963, acc: 63.28%, op_acc: 42.19%] [G loss: 0.829328]\n",
      "epoch:28 step:21968[D loss: 0.402521, acc: 61.72%, op_acc: 42.19%] [G loss: 0.817422]\n",
      "epoch:28 step:21969[D loss: 0.437207, acc: 50.00%, op_acc: 38.28%] [G loss: 0.866159]\n",
      "epoch:28 step:21970[D loss: 0.416067, acc: 55.47%, op_acc: 42.19%] [G loss: 0.881921]\n",
      "epoch:28 step:21971[D loss: 0.430388, acc: 54.69%, op_acc: 38.28%] [G loss: 0.838065]\n",
      "epoch:28 step:21972[D loss: 0.406397, acc: 57.81%, op_acc: 35.94%] [G loss: 0.888043]\n",
      "epoch:28 step:21973[D loss: 0.445274, acc: 51.56%, op_acc: 36.72%] [G loss: 0.862942]\n",
      "epoch:28 step:21974[D loss: 0.428985, acc: 52.34%, op_acc: 41.41%] [G loss: 0.830078]\n",
      "epoch:28 step:21975[D loss: 0.402957, acc: 70.31%, op_acc: 42.97%] [G loss: 0.841765]\n",
      "epoch:28 step:21976[D loss: 0.443206, acc: 62.50%, op_acc: 34.38%] [G loss: 0.952575]\n",
      "epoch:28 step:21977[D loss: 0.415322, acc: 57.03%, op_acc: 39.06%] [G loss: 0.821350]\n",
      "epoch:28 step:21978[D loss: 0.384747, acc: 67.19%, op_acc: 49.22%] [G loss: 0.911363]\n",
      "epoch:28 step:21979[D loss: 0.438672, acc: 59.38%, op_acc: 37.50%] [G loss: 0.942154]\n",
      "epoch:28 step:21980[D loss: 0.387290, acc: 63.28%, op_acc: 44.53%] [G loss: 0.869273]\n",
      "epoch:28 step:21981[D loss: 0.431218, acc: 53.12%, op_acc: 37.50%] [G loss: 0.911537]\n",
      "epoch:28 step:21982[D loss: 0.441619, acc: 53.12%, op_acc: 40.62%] [G loss: 0.851656]\n",
      "epoch:28 step:21983[D loss: 0.388558, acc: 62.50%, op_acc: 45.31%] [G loss: 0.886178]\n",
      "epoch:28 step:21984[D loss: 0.435244, acc: 60.94%, op_acc: 42.19%] [G loss: 0.950263]\n",
      "epoch:28 step:21985[D loss: 0.427467, acc: 60.94%, op_acc: 39.06%] [G loss: 0.915326]\n",
      "epoch:28 step:21986[D loss: 0.436337, acc: 54.69%, op_acc: 39.06%] [G loss: 0.838485]\n",
      "epoch:28 step:21987[D loss: 0.429024, acc: 64.06%, op_acc: 38.28%] [G loss: 0.872895]\n",
      "epoch:28 step:21988[D loss: 0.433901, acc: 57.03%, op_acc: 38.28%] [G loss: 0.892053]\n",
      "epoch:28 step:21989[D loss: 0.415419, acc: 56.25%, op_acc: 35.16%] [G loss: 0.907847]\n",
      "epoch:28 step:21990[D loss: 0.414542, acc: 55.47%, op_acc: 43.75%] [G loss: 0.811408]\n",
      "epoch:28 step:21991[D loss: 0.442155, acc: 54.69%, op_acc: 40.62%] [G loss: 0.841462]\n",
      "epoch:28 step:21992[D loss: 0.436070, acc: 55.47%, op_acc: 39.06%] [G loss: 0.917395]\n",
      "epoch:28 step:21993[D loss: 0.441691, acc: 60.16%, op_acc: 35.94%] [G loss: 0.901548]\n",
      "epoch:28 step:21994[D loss: 0.420948, acc: 57.03%, op_acc: 44.53%] [G loss: 0.831847]\n",
      "epoch:28 step:21995[D loss: 0.425161, acc: 58.59%, op_acc: 39.84%] [G loss: 0.852687]\n",
      "epoch:28 step:21996[D loss: 0.424857, acc: 59.38%, op_acc: 32.81%] [G loss: 0.859018]\n",
      "epoch:28 step:21997[D loss: 0.431162, acc: 60.16%, op_acc: 34.38%] [G loss: 0.895509]\n",
      "epoch:28 step:21998[D loss: 0.439061, acc: 50.00%, op_acc: 36.72%] [G loss: 0.873472]\n",
      "epoch:28 step:21999[D loss: 0.419235, acc: 60.16%, op_acc: 35.94%] [G loss: 0.849540]\n",
      "epoch:28 step:22000[D loss: 0.389509, acc: 67.19%, op_acc: 43.75%] [G loss: 0.871816]\n",
      "##############\n",
      "[0.86472172 0.86963985 0.80817072 0.82524041 0.79748155 0.82197068\n",
      " 0.8920502  0.8336902  0.80698481 0.81419062]\n",
      "##########\n",
      "epoch:28 step:22001[D loss: 0.454021, acc: 57.03%, op_acc: 35.16%] [G loss: 0.882716]\n",
      "epoch:28 step:22002[D loss: 0.437244, acc: 60.16%, op_acc: 35.94%] [G loss: 0.830048]\n",
      "epoch:28 step:22003[D loss: 0.439845, acc: 51.56%, op_acc: 39.84%] [G loss: 0.880096]\n",
      "epoch:28 step:22004[D loss: 0.417036, acc: 56.25%, op_acc: 44.53%] [G loss: 0.884036]\n",
      "epoch:28 step:22005[D loss: 0.437480, acc: 54.69%, op_acc: 39.84%] [G loss: 0.903409]\n",
      "epoch:28 step:22006[D loss: 0.425756, acc: 59.38%, op_acc: 39.84%] [G loss: 0.948091]\n",
      "epoch:28 step:22007[D loss: 0.438779, acc: 52.34%, op_acc: 39.06%] [G loss: 0.846948]\n",
      "epoch:28 step:22008[D loss: 0.442860, acc: 55.47%, op_acc: 38.28%] [G loss: 0.896703]\n",
      "epoch:28 step:22009[D loss: 0.427909, acc: 57.03%, op_acc: 40.62%] [G loss: 0.782638]\n",
      "epoch:28 step:22010[D loss: 0.411667, acc: 59.38%, op_acc: 39.84%] [G loss: 0.894541]\n",
      "epoch:28 step:22011[D loss: 0.419247, acc: 55.47%, op_acc: 39.84%] [G loss: 0.870933]\n",
      "epoch:28 step:22012[D loss: 0.438721, acc: 56.25%, op_acc: 38.28%] [G loss: 0.812729]\n",
      "epoch:28 step:22013[D loss: 0.417144, acc: 59.38%, op_acc: 42.97%] [G loss: 0.889212]\n",
      "epoch:28 step:22014[D loss: 0.418434, acc: 59.38%, op_acc: 38.28%] [G loss: 0.829412]\n",
      "epoch:28 step:22015[D loss: 0.407000, acc: 59.38%, op_acc: 39.84%] [G loss: 0.922791]\n",
      "epoch:28 step:22016[D loss: 0.456403, acc: 51.56%, op_acc: 37.50%] [G loss: 0.915451]\n",
      "epoch:28 step:22017[D loss: 0.411084, acc: 56.25%, op_acc: 43.75%] [G loss: 0.818200]\n",
      "epoch:28 step:22018[D loss: 0.393995, acc: 58.59%, op_acc: 41.41%] [G loss: 0.860142]\n",
      "epoch:28 step:22019[D loss: 0.426352, acc: 57.81%, op_acc: 42.97%] [G loss: 0.858513]\n",
      "epoch:28 step:22020[D loss: 0.445004, acc: 57.03%, op_acc: 39.06%] [G loss: 0.897848]\n",
      "epoch:28 step:22021[D loss: 0.439567, acc: 54.69%, op_acc: 41.41%] [G loss: 0.844498]\n",
      "epoch:28 step:22022[D loss: 0.408727, acc: 64.84%, op_acc: 39.06%] [G loss: 0.831919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22023[D loss: 0.412098, acc: 57.81%, op_acc: 42.19%] [G loss: 0.907270]\n",
      "epoch:28 step:22024[D loss: 0.405170, acc: 61.72%, op_acc: 35.94%] [G loss: 0.955082]\n",
      "epoch:28 step:22025[D loss: 0.435358, acc: 54.69%, op_acc: 43.75%] [G loss: 0.825603]\n",
      "epoch:28 step:22026[D loss: 0.408205, acc: 57.81%, op_acc: 43.75%] [G loss: 0.879314]\n",
      "epoch:28 step:22027[D loss: 0.421290, acc: 57.03%, op_acc: 40.62%] [G loss: 0.967640]\n",
      "epoch:28 step:22028[D loss: 0.451615, acc: 55.47%, op_acc: 37.50%] [G loss: 0.883570]\n",
      "epoch:28 step:22029[D loss: 0.423718, acc: 59.38%, op_acc: 38.28%] [G loss: 0.827740]\n",
      "epoch:28 step:22030[D loss: 0.419404, acc: 56.25%, op_acc: 42.19%] [G loss: 0.845861]\n",
      "epoch:28 step:22031[D loss: 0.424623, acc: 66.41%, op_acc: 38.28%] [G loss: 0.943182]\n",
      "epoch:28 step:22032[D loss: 0.427372, acc: 61.72%, op_acc: 31.25%] [G loss: 0.939283]\n",
      "epoch:28 step:22033[D loss: 0.437595, acc: 50.00%, op_acc: 35.94%] [G loss: 0.822239]\n",
      "epoch:28 step:22034[D loss: 0.430108, acc: 63.28%, op_acc: 39.84%] [G loss: 0.876453]\n",
      "epoch:28 step:22035[D loss: 0.432396, acc: 57.03%, op_acc: 40.62%] [G loss: 0.867561]\n",
      "epoch:28 step:22036[D loss: 0.412172, acc: 62.50%, op_acc: 45.31%] [G loss: 0.771546]\n",
      "epoch:28 step:22037[D loss: 0.413642, acc: 68.75%, op_acc: 37.50%] [G loss: 0.892070]\n",
      "epoch:28 step:22038[D loss: 0.439383, acc: 58.59%, op_acc: 37.50%] [G loss: 0.833438]\n",
      "epoch:28 step:22039[D loss: 0.449002, acc: 50.00%, op_acc: 39.84%] [G loss: 0.825494]\n",
      "epoch:28 step:22040[D loss: 0.432982, acc: 52.34%, op_acc: 37.50%] [G loss: 0.906338]\n",
      "epoch:28 step:22041[D loss: 0.432419, acc: 60.16%, op_acc: 35.94%] [G loss: 0.894400]\n",
      "epoch:28 step:22042[D loss: 0.439695, acc: 56.25%, op_acc: 37.50%] [G loss: 0.955127]\n",
      "epoch:28 step:22043[D loss: 0.391181, acc: 64.84%, op_acc: 45.31%] [G loss: 0.873871]\n",
      "epoch:28 step:22044[D loss: 0.404804, acc: 66.41%, op_acc: 42.97%] [G loss: 0.901181]\n",
      "epoch:28 step:22045[D loss: 0.415155, acc: 64.84%, op_acc: 43.75%] [G loss: 0.873364]\n",
      "epoch:28 step:22046[D loss: 0.427984, acc: 57.81%, op_acc: 39.84%] [G loss: 0.863652]\n",
      "epoch:28 step:22047[D loss: 0.367933, acc: 78.12%, op_acc: 40.62%] [G loss: 0.883149]\n",
      "epoch:28 step:22048[D loss: 0.425385, acc: 58.59%, op_acc: 35.16%] [G loss: 0.879356]\n",
      "epoch:28 step:22049[D loss: 0.394357, acc: 67.19%, op_acc: 42.19%] [G loss: 0.942763]\n",
      "epoch:28 step:22050[D loss: 0.412516, acc: 59.38%, op_acc: 39.06%] [G loss: 0.880796]\n",
      "##############\n",
      "[0.85657292 0.84949316 0.80830273 0.82436214 0.80502377 0.82303795\n",
      " 0.87167001 0.82249677 0.81385982 0.83696817]\n",
      "##########\n",
      "epoch:28 step:22051[D loss: 0.405567, acc: 63.28%, op_acc: 39.84%] [G loss: 0.833822]\n",
      "epoch:28 step:22052[D loss: 0.417198, acc: 56.25%, op_acc: 39.84%] [G loss: 0.866539]\n",
      "epoch:28 step:22053[D loss: 0.433964, acc: 63.28%, op_acc: 33.59%] [G loss: 0.907284]\n",
      "epoch:28 step:22054[D loss: 0.429431, acc: 56.25%, op_acc: 39.06%] [G loss: 0.925710]\n",
      "epoch:28 step:22055[D loss: 0.397039, acc: 67.97%, op_acc: 46.88%] [G loss: 0.952404]\n",
      "epoch:28 step:22056[D loss: 0.414624, acc: 57.03%, op_acc: 43.75%] [G loss: 0.887453]\n",
      "epoch:28 step:22057[D loss: 0.384792, acc: 70.31%, op_acc: 39.06%] [G loss: 0.924513]\n",
      "epoch:28 step:22058[D loss: 0.427933, acc: 57.81%, op_acc: 39.06%] [G loss: 0.922027]\n",
      "epoch:28 step:22059[D loss: 0.409871, acc: 60.16%, op_acc: 43.75%] [G loss: 0.798243]\n",
      "epoch:28 step:22060[D loss: 0.421024, acc: 63.28%, op_acc: 41.41%] [G loss: 0.842355]\n",
      "epoch:28 step:22061[D loss: 0.445912, acc: 53.91%, op_acc: 40.62%] [G loss: 0.967237]\n",
      "epoch:28 step:22062[D loss: 0.412669, acc: 57.03%, op_acc: 46.09%] [G loss: 0.902850]\n",
      "epoch:28 step:22063[D loss: 0.419896, acc: 56.25%, op_acc: 41.41%] [G loss: 0.814243]\n",
      "epoch:28 step:22064[D loss: 0.422920, acc: 64.06%, op_acc: 39.06%] [G loss: 0.892480]\n",
      "epoch:28 step:22065[D loss: 0.433319, acc: 57.03%, op_acc: 36.72%] [G loss: 0.847435]\n",
      "epoch:28 step:22066[D loss: 0.423021, acc: 62.50%, op_acc: 44.53%] [G loss: 0.934735]\n",
      "epoch:28 step:22067[D loss: 0.418794, acc: 60.94%, op_acc: 39.84%] [G loss: 0.830487]\n",
      "epoch:28 step:22068[D loss: 0.436465, acc: 54.69%, op_acc: 44.53%] [G loss: 0.904504]\n",
      "epoch:28 step:22069[D loss: 0.434174, acc: 53.91%, op_acc: 39.84%] [G loss: 0.900786]\n",
      "epoch:28 step:22070[D loss: 0.432786, acc: 61.72%, op_acc: 41.41%] [G loss: 0.924735]\n",
      "epoch:28 step:22071[D loss: 0.441324, acc: 56.25%, op_acc: 39.06%] [G loss: 0.912368]\n",
      "epoch:28 step:22072[D loss: 0.409185, acc: 67.97%, op_acc: 42.19%] [G loss: 0.840859]\n",
      "epoch:28 step:22073[D loss: 0.441902, acc: 60.94%, op_acc: 34.38%] [G loss: 0.804816]\n",
      "epoch:28 step:22074[D loss: 0.388635, acc: 69.53%, op_acc: 40.62%] [G loss: 0.908581]\n",
      "epoch:28 step:22075[D loss: 0.393501, acc: 60.16%, op_acc: 45.31%] [G loss: 0.981087]\n",
      "epoch:28 step:22076[D loss: 0.434901, acc: 62.50%, op_acc: 33.59%] [G loss: 0.961838]\n",
      "epoch:28 step:22077[D loss: 0.416747, acc: 62.50%, op_acc: 38.28%] [G loss: 0.871881]\n",
      "epoch:28 step:22078[D loss: 0.422033, acc: 61.72%, op_acc: 38.28%] [G loss: 0.894566]\n",
      "epoch:28 step:22079[D loss: 0.418846, acc: 54.69%, op_acc: 42.19%] [G loss: 0.889148]\n",
      "epoch:28 step:22080[D loss: 0.406608, acc: 61.72%, op_acc: 42.19%] [G loss: 0.836860]\n",
      "epoch:28 step:22081[D loss: 0.428983, acc: 55.47%, op_acc: 39.84%] [G loss: 0.924072]\n",
      "epoch:28 step:22082[D loss: 0.435947, acc: 63.28%, op_acc: 39.84%] [G loss: 0.948408]\n",
      "epoch:28 step:22083[D loss: 0.433482, acc: 64.06%, op_acc: 34.38%] [G loss: 0.925045]\n",
      "epoch:28 step:22084[D loss: 0.442262, acc: 57.03%, op_acc: 41.41%] [G loss: 0.801744]\n",
      "epoch:28 step:22085[D loss: 0.421032, acc: 58.59%, op_acc: 36.72%] [G loss: 0.932208]\n",
      "epoch:28 step:22086[D loss: 0.414503, acc: 64.84%, op_acc: 45.31%] [G loss: 0.846220]\n",
      "epoch:28 step:22087[D loss: 0.397578, acc: 66.41%, op_acc: 42.97%] [G loss: 0.846716]\n",
      "epoch:28 step:22088[D loss: 0.425217, acc: 53.91%, op_acc: 38.28%] [G loss: 0.936585]\n",
      "epoch:28 step:22089[D loss: 0.412458, acc: 61.72%, op_acc: 39.06%] [G loss: 0.878735]\n",
      "epoch:28 step:22090[D loss: 0.433670, acc: 60.94%, op_acc: 39.84%] [G loss: 0.862519]\n",
      "epoch:28 step:22091[D loss: 0.448106, acc: 50.00%, op_acc: 38.28%] [G loss: 0.817104]\n",
      "epoch:28 step:22092[D loss: 0.445314, acc: 55.47%, op_acc: 39.06%] [G loss: 0.930396]\n",
      "epoch:28 step:22093[D loss: 0.426331, acc: 53.12%, op_acc: 40.62%] [G loss: 0.860493]\n",
      "epoch:28 step:22094[D loss: 0.414877, acc: 60.16%, op_acc: 43.75%] [G loss: 0.926276]\n",
      "epoch:28 step:22095[D loss: 0.406110, acc: 58.59%, op_acc: 42.19%] [G loss: 0.898432]\n",
      "epoch:28 step:22096[D loss: 0.399836, acc: 60.94%, op_acc: 42.97%] [G loss: 0.884427]\n",
      "epoch:28 step:22097[D loss: 0.425142, acc: 57.81%, op_acc: 40.62%] [G loss: 0.943565]\n",
      "epoch:28 step:22098[D loss: 0.436963, acc: 57.81%, op_acc: 43.75%] [G loss: 0.849021]\n",
      "epoch:28 step:22099[D loss: 0.439494, acc: 54.69%, op_acc: 39.06%] [G loss: 0.851205]\n",
      "epoch:28 step:22100[D loss: 0.425102, acc: 57.81%, op_acc: 42.19%] [G loss: 0.892226]\n",
      "##############\n",
      "[0.85091622 0.86648022 0.83500718 0.81297492 0.81560448 0.84567188\n",
      " 0.88622991 0.79964804 0.78856209 0.839252  ]\n",
      "##########\n",
      "epoch:28 step:22101[D loss: 0.406733, acc: 64.84%, op_acc: 40.62%] [G loss: 0.898223]\n",
      "epoch:28 step:22102[D loss: 0.429232, acc: 62.50%, op_acc: 38.28%] [G loss: 0.825966]\n",
      "epoch:28 step:22103[D loss: 0.407498, acc: 64.84%, op_acc: 38.28%] [G loss: 0.913340]\n",
      "epoch:28 step:22104[D loss: 0.416592, acc: 58.59%, op_acc: 39.84%] [G loss: 0.932716]\n",
      "epoch:28 step:22105[D loss: 0.441940, acc: 53.12%, op_acc: 37.50%] [G loss: 0.876086]\n",
      "epoch:28 step:22106[D loss: 0.409269, acc: 62.50%, op_acc: 36.72%] [G loss: 0.914430]\n",
      "epoch:28 step:22107[D loss: 0.406755, acc: 65.62%, op_acc: 39.84%] [G loss: 0.928525]\n",
      "epoch:28 step:22108[D loss: 0.433555, acc: 55.47%, op_acc: 42.19%] [G loss: 0.865245]\n",
      "epoch:28 step:22109[D loss: 0.397323, acc: 64.84%, op_acc: 43.75%] [G loss: 0.878610]\n",
      "epoch:28 step:22110[D loss: 0.392103, acc: 65.62%, op_acc: 44.53%] [G loss: 0.834650]\n",
      "epoch:28 step:22111[D loss: 0.416881, acc: 57.03%, op_acc: 46.09%] [G loss: 0.884222]\n",
      "epoch:28 step:22112[D loss: 0.404318, acc: 67.97%, op_acc: 40.62%] [G loss: 0.923200]\n",
      "epoch:28 step:22113[D loss: 0.408219, acc: 63.28%, op_acc: 39.06%] [G loss: 0.955495]\n",
      "epoch:28 step:22114[D loss: 0.443028, acc: 60.16%, op_acc: 37.50%] [G loss: 0.883014]\n",
      "epoch:28 step:22115[D loss: 0.453109, acc: 50.00%, op_acc: 35.16%] [G loss: 0.788410]\n",
      "epoch:28 step:22116[D loss: 0.441032, acc: 57.81%, op_acc: 40.62%] [G loss: 0.859968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22117[D loss: 0.424968, acc: 57.81%, op_acc: 39.06%] [G loss: 0.954751]\n",
      "epoch:28 step:22118[D loss: 0.427120, acc: 60.94%, op_acc: 36.72%] [G loss: 0.915192]\n",
      "epoch:28 step:22119[D loss: 0.394338, acc: 60.94%, op_acc: 44.53%] [G loss: 0.961797]\n",
      "epoch:28 step:22120[D loss: 0.438328, acc: 50.78%, op_acc: 38.28%] [G loss: 0.887865]\n",
      "epoch:28 step:22121[D loss: 0.422520, acc: 64.06%, op_acc: 35.16%] [G loss: 0.838984]\n",
      "epoch:28 step:22122[D loss: 0.433048, acc: 61.72%, op_acc: 35.94%] [G loss: 0.828133]\n",
      "epoch:28 step:22123[D loss: 0.414204, acc: 60.94%, op_acc: 39.84%] [G loss: 0.859591]\n",
      "epoch:28 step:22124[D loss: 0.423213, acc: 60.16%, op_acc: 37.50%] [G loss: 0.861517]\n",
      "epoch:28 step:22125[D loss: 0.433989, acc: 56.25%, op_acc: 37.50%] [G loss: 0.902837]\n",
      "epoch:28 step:22126[D loss: 0.397372, acc: 60.16%, op_acc: 42.97%] [G loss: 0.883919]\n",
      "epoch:28 step:22127[D loss: 0.426478, acc: 58.59%, op_acc: 35.16%] [G loss: 0.871420]\n",
      "epoch:28 step:22128[D loss: 0.435653, acc: 62.50%, op_acc: 36.72%] [G loss: 0.933616]\n",
      "epoch:28 step:22129[D loss: 0.395058, acc: 66.41%, op_acc: 39.06%] [G loss: 0.835435]\n",
      "epoch:28 step:22130[D loss: 0.415676, acc: 60.94%, op_acc: 36.72%] [G loss: 0.890799]\n",
      "epoch:28 step:22131[D loss: 0.454063, acc: 53.91%, op_acc: 29.69%] [G loss: 0.910472]\n",
      "epoch:28 step:22132[D loss: 0.419336, acc: 63.28%, op_acc: 35.94%] [G loss: 0.990805]\n",
      "epoch:28 step:22133[D loss: 0.410348, acc: 60.16%, op_acc: 45.31%] [G loss: 0.882242]\n",
      "epoch:28 step:22134[D loss: 0.409413, acc: 59.38%, op_acc: 43.75%] [G loss: 0.849451]\n",
      "epoch:28 step:22135[D loss: 0.447076, acc: 50.00%, op_acc: 40.62%] [G loss: 0.887027]\n",
      "epoch:28 step:22136[D loss: 0.436282, acc: 53.12%, op_acc: 42.19%] [G loss: 0.849758]\n",
      "epoch:28 step:22137[D loss: 0.412166, acc: 60.94%, op_acc: 42.19%] [G loss: 0.799705]\n",
      "epoch:28 step:22138[D loss: 0.392778, acc: 64.06%, op_acc: 42.97%] [G loss: 0.952206]\n",
      "epoch:28 step:22139[D loss: 0.413516, acc: 60.94%, op_acc: 39.84%] [G loss: 0.909757]\n",
      "epoch:28 step:22140[D loss: 0.410307, acc: 67.19%, op_acc: 39.84%] [G loss: 0.884065]\n",
      "epoch:28 step:22141[D loss: 0.419310, acc: 58.59%, op_acc: 37.50%] [G loss: 0.873352]\n",
      "epoch:28 step:22142[D loss: 0.430599, acc: 57.81%, op_acc: 41.41%] [G loss: 0.874275]\n",
      "epoch:28 step:22143[D loss: 0.436319, acc: 54.69%, op_acc: 35.94%] [G loss: 0.853272]\n",
      "epoch:28 step:22144[D loss: 0.450115, acc: 57.03%, op_acc: 35.16%] [G loss: 0.892205]\n",
      "epoch:28 step:22145[D loss: 0.431041, acc: 63.28%, op_acc: 33.59%] [G loss: 0.926619]\n",
      "epoch:28 step:22146[D loss: 0.410668, acc: 61.72%, op_acc: 44.53%] [G loss: 0.800327]\n",
      "epoch:28 step:22147[D loss: 0.432308, acc: 58.59%, op_acc: 43.75%] [G loss: 0.880095]\n",
      "epoch:28 step:22148[D loss: 0.424536, acc: 60.16%, op_acc: 45.31%] [G loss: 0.793747]\n",
      "epoch:28 step:22149[D loss: 0.434878, acc: 53.12%, op_acc: 39.06%] [G loss: 0.911902]\n",
      "epoch:28 step:22150[D loss: 0.441150, acc: 55.47%, op_acc: 41.41%] [G loss: 0.821407]\n",
      "##############\n",
      "[0.86512683 0.86201972 0.8157386  0.79349251 0.81004052 0.82412313\n",
      " 0.85743735 0.85571945 0.80434259 0.8161034 ]\n",
      "##########\n",
      "epoch:28 step:22151[D loss: 0.407097, acc: 55.47%, op_acc: 46.88%] [G loss: 0.878208]\n",
      "epoch:28 step:22152[D loss: 0.428470, acc: 56.25%, op_acc: 36.72%] [G loss: 0.854251]\n",
      "epoch:28 step:22153[D loss: 0.453082, acc: 53.12%, op_acc: 38.28%] [G loss: 0.843535]\n",
      "epoch:28 step:22154[D loss: 0.429181, acc: 65.62%, op_acc: 39.84%] [G loss: 0.872791]\n",
      "epoch:28 step:22155[D loss: 0.432297, acc: 56.25%, op_acc: 42.19%] [G loss: 0.844460]\n",
      "epoch:28 step:22156[D loss: 0.424359, acc: 55.47%, op_acc: 39.06%] [G loss: 0.837149]\n",
      "epoch:28 step:22157[D loss: 0.445351, acc: 55.47%, op_acc: 36.72%] [G loss: 0.842035]\n",
      "epoch:28 step:22158[D loss: 0.408834, acc: 60.94%, op_acc: 38.28%] [G loss: 0.868098]\n",
      "epoch:28 step:22159[D loss: 0.428329, acc: 57.81%, op_acc: 39.84%] [G loss: 0.895331]\n",
      "epoch:28 step:22160[D loss: 0.427237, acc: 60.16%, op_acc: 37.50%] [G loss: 0.930049]\n",
      "epoch:28 step:22161[D loss: 0.410156, acc: 57.81%, op_acc: 46.09%] [G loss: 0.862468]\n",
      "epoch:28 step:22162[D loss: 0.438080, acc: 53.91%, op_acc: 41.41%] [G loss: 0.815962]\n",
      "epoch:28 step:22163[D loss: 0.395891, acc: 66.41%, op_acc: 39.84%] [G loss: 0.824930]\n",
      "epoch:28 step:22164[D loss: 0.403773, acc: 61.72%, op_acc: 42.19%] [G loss: 0.866394]\n",
      "epoch:28 step:22165[D loss: 0.450103, acc: 56.25%, op_acc: 34.38%] [G loss: 0.862944]\n",
      "epoch:28 step:22166[D loss: 0.414638, acc: 64.06%, op_acc: 40.62%] [G loss: 0.882777]\n",
      "epoch:28 step:22167[D loss: 0.409285, acc: 59.38%, op_acc: 37.50%] [G loss: 0.916180]\n",
      "epoch:28 step:22168[D loss: 0.435988, acc: 59.38%, op_acc: 36.72%] [G loss: 0.899169]\n",
      "epoch:28 step:22169[D loss: 0.413319, acc: 60.94%, op_acc: 39.84%] [G loss: 0.874466]\n",
      "epoch:28 step:22170[D loss: 0.421320, acc: 60.16%, op_acc: 39.06%] [G loss: 0.852483]\n",
      "epoch:28 step:22171[D loss: 0.432390, acc: 53.12%, op_acc: 35.16%] [G loss: 0.856462]\n",
      "epoch:28 step:22172[D loss: 0.422987, acc: 53.91%, op_acc: 39.06%] [G loss: 0.905831]\n",
      "epoch:28 step:22173[D loss: 0.413571, acc: 62.50%, op_acc: 39.06%] [G loss: 0.937393]\n",
      "epoch:28 step:22174[D loss: 0.437301, acc: 58.59%, op_acc: 39.06%] [G loss: 0.882885]\n",
      "epoch:28 step:22175[D loss: 0.408397, acc: 59.38%, op_acc: 42.19%] [G loss: 0.853084]\n",
      "epoch:28 step:22176[D loss: 0.421826, acc: 60.16%, op_acc: 37.50%] [G loss: 0.891451]\n",
      "epoch:28 step:22177[D loss: 0.434265, acc: 58.59%, op_acc: 30.47%] [G loss: 0.888248]\n",
      "epoch:28 step:22178[D loss: 0.421541, acc: 60.94%, op_acc: 37.50%] [G loss: 0.850889]\n",
      "epoch:28 step:22179[D loss: 0.421645, acc: 60.16%, op_acc: 35.94%] [G loss: 0.846168]\n",
      "epoch:28 step:22180[D loss: 0.423196, acc: 58.59%, op_acc: 39.84%] [G loss: 0.914246]\n",
      "epoch:28 step:22181[D loss: 0.442484, acc: 50.00%, op_acc: 34.38%] [G loss: 0.884853]\n",
      "epoch:28 step:22182[D loss: 0.406089, acc: 64.84%, op_acc: 38.28%] [G loss: 0.808665]\n",
      "epoch:28 step:22183[D loss: 0.444568, acc: 49.22%, op_acc: 36.72%] [G loss: 0.861480]\n",
      "epoch:28 step:22184[D loss: 0.431556, acc: 52.34%, op_acc: 39.84%] [G loss: 0.871455]\n",
      "epoch:28 step:22185[D loss: 0.403994, acc: 64.84%, op_acc: 40.62%] [G loss: 0.859088]\n",
      "epoch:28 step:22186[D loss: 0.435564, acc: 53.12%, op_acc: 40.62%] [G loss: 0.905169]\n",
      "epoch:28 step:22187[D loss: 0.438399, acc: 51.56%, op_acc: 38.28%] [G loss: 0.880115]\n",
      "epoch:28 step:22188[D loss: 0.429686, acc: 55.47%, op_acc: 39.06%] [G loss: 0.828100]\n",
      "epoch:28 step:22189[D loss: 0.423614, acc: 64.06%, op_acc: 31.25%] [G loss: 0.943209]\n",
      "epoch:28 step:22190[D loss: 0.421048, acc: 64.84%, op_acc: 41.41%] [G loss: 0.907604]\n",
      "epoch:28 step:22191[D loss: 0.411517, acc: 57.81%, op_acc: 41.41%] [G loss: 0.857278]\n",
      "epoch:28 step:22192[D loss: 0.439893, acc: 57.81%, op_acc: 33.59%] [G loss: 0.911716]\n",
      "epoch:28 step:22193[D loss: 0.413483, acc: 60.16%, op_acc: 43.75%] [G loss: 0.886116]\n",
      "epoch:28 step:22194[D loss: 0.405132, acc: 59.38%, op_acc: 39.84%] [G loss: 0.890954]\n",
      "epoch:28 step:22195[D loss: 0.401426, acc: 62.50%, op_acc: 38.28%] [G loss: 0.852438]\n",
      "epoch:28 step:22196[D loss: 0.446142, acc: 57.03%, op_acc: 38.28%] [G loss: 0.876566]\n",
      "epoch:28 step:22197[D loss: 0.451191, acc: 53.91%, op_acc: 38.28%] [G loss: 0.870286]\n",
      "epoch:28 step:22198[D loss: 0.435002, acc: 57.03%, op_acc: 42.19%] [G loss: 0.873435]\n",
      "epoch:28 step:22199[D loss: 0.407236, acc: 63.28%, op_acc: 38.28%] [G loss: 0.910099]\n",
      "epoch:28 step:22200[D loss: 0.435379, acc: 55.47%, op_acc: 45.31%] [G loss: 0.852845]\n",
      "##############\n",
      "[0.85487721 0.85835492 0.80615467 0.81131925 0.77406968 0.82551498\n",
      " 0.88390166 0.83712331 0.80796942 0.83576468]\n",
      "##########\n",
      "epoch:28 step:22201[D loss: 0.406898, acc: 64.84%, op_acc: 36.72%] [G loss: 0.858289]\n",
      "epoch:28 step:22202[D loss: 0.440607, acc: 50.78%, op_acc: 38.28%] [G loss: 0.871955]\n",
      "epoch:28 step:22203[D loss: 0.415896, acc: 56.25%, op_acc: 36.72%] [G loss: 0.884258]\n",
      "epoch:28 step:22204[D loss: 0.435627, acc: 54.69%, op_acc: 35.16%] [G loss: 0.870192]\n",
      "epoch:28 step:22205[D loss: 0.418465, acc: 66.41%, op_acc: 39.84%] [G loss: 0.809590]\n",
      "epoch:28 step:22206[D loss: 0.419649, acc: 57.81%, op_acc: 40.62%] [G loss: 0.886032]\n",
      "epoch:28 step:22207[D loss: 0.404093, acc: 61.72%, op_acc: 39.06%] [G loss: 0.886501]\n",
      "epoch:28 step:22208[D loss: 0.451040, acc: 51.56%, op_acc: 38.28%] [G loss: 0.832596]\n",
      "epoch:28 step:22209[D loss: 0.439055, acc: 58.59%, op_acc: 39.06%] [G loss: 0.920478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22210[D loss: 0.446144, acc: 53.91%, op_acc: 39.84%] [G loss: 0.847691]\n",
      "epoch:28 step:22211[D loss: 0.474202, acc: 53.91%, op_acc: 41.41%] [G loss: 0.924432]\n",
      "epoch:28 step:22212[D loss: 0.428008, acc: 53.91%, op_acc: 39.06%] [G loss: 0.915919]\n",
      "epoch:28 step:22213[D loss: 0.414123, acc: 63.28%, op_acc: 39.06%] [G loss: 0.924172]\n",
      "epoch:28 step:22214[D loss: 0.413012, acc: 66.41%, op_acc: 43.75%] [G loss: 0.861240]\n",
      "epoch:28 step:22215[D loss: 0.418443, acc: 62.50%, op_acc: 46.09%] [G loss: 0.885396]\n",
      "epoch:28 step:22216[D loss: 0.422566, acc: 60.16%, op_acc: 40.62%] [G loss: 0.889289]\n",
      "epoch:28 step:22217[D loss: 0.421042, acc: 58.59%, op_acc: 43.75%] [G loss: 0.909492]\n",
      "epoch:28 step:22218[D loss: 0.437338, acc: 60.16%, op_acc: 38.28%] [G loss: 0.860790]\n",
      "epoch:28 step:22219[D loss: 0.448170, acc: 57.03%, op_acc: 41.41%] [G loss: 0.952917]\n",
      "epoch:28 step:22220[D loss: 0.451707, acc: 59.38%, op_acc: 33.59%] [G loss: 0.900744]\n",
      "epoch:28 step:22221[D loss: 0.399963, acc: 65.62%, op_acc: 43.75%] [G loss: 0.846415]\n",
      "epoch:28 step:22222[D loss: 0.409947, acc: 63.28%, op_acc: 39.06%] [G loss: 0.918105]\n",
      "epoch:28 step:22223[D loss: 0.425180, acc: 61.72%, op_acc: 45.31%] [G loss: 0.873669]\n",
      "epoch:28 step:22224[D loss: 0.425858, acc: 57.03%, op_acc: 41.41%] [G loss: 0.900143]\n",
      "epoch:28 step:22225[D loss: 0.425825, acc: 63.28%, op_acc: 38.28%] [G loss: 0.903548]\n",
      "epoch:28 step:22226[D loss: 0.439199, acc: 57.81%, op_acc: 40.62%] [G loss: 0.843265]\n",
      "epoch:28 step:22227[D loss: 0.415247, acc: 53.91%, op_acc: 45.31%] [G loss: 0.817388]\n",
      "epoch:28 step:22228[D loss: 0.433610, acc: 55.47%, op_acc: 37.50%] [G loss: 0.816378]\n",
      "epoch:28 step:22229[D loss: 0.427196, acc: 55.47%, op_acc: 39.84%] [G loss: 0.834329]\n",
      "epoch:28 step:22230[D loss: 0.392100, acc: 63.28%, op_acc: 41.41%] [G loss: 0.950728]\n",
      "epoch:28 step:22231[D loss: 0.412622, acc: 60.94%, op_acc: 42.19%] [G loss: 0.932768]\n",
      "epoch:28 step:22232[D loss: 0.437493, acc: 53.12%, op_acc: 38.28%] [G loss: 0.774855]\n",
      "epoch:28 step:22233[D loss: 0.388851, acc: 67.97%, op_acc: 42.97%] [G loss: 0.907578]\n",
      "epoch:28 step:22234[D loss: 0.411358, acc: 64.84%, op_acc: 38.28%] [G loss: 0.841217]\n",
      "epoch:28 step:22235[D loss: 0.414293, acc: 65.62%, op_acc: 39.06%] [G loss: 0.926818]\n",
      "epoch:28 step:22236[D loss: 0.441879, acc: 59.38%, op_acc: 38.28%] [G loss: 0.810580]\n",
      "epoch:28 step:22237[D loss: 0.405693, acc: 58.59%, op_acc: 42.97%] [G loss: 0.850409]\n",
      "epoch:28 step:22238[D loss: 0.417156, acc: 60.94%, op_acc: 39.84%] [G loss: 0.926380]\n",
      "epoch:28 step:22239[D loss: 0.398371, acc: 60.16%, op_acc: 46.09%] [G loss: 0.928554]\n",
      "epoch:28 step:22240[D loss: 0.413382, acc: 57.03%, op_acc: 42.97%] [G loss: 0.832043]\n",
      "epoch:28 step:22241[D loss: 0.413923, acc: 55.47%, op_acc: 42.97%] [G loss: 0.841901]\n",
      "epoch:28 step:22242[D loss: 0.434512, acc: 60.16%, op_acc: 39.84%] [G loss: 0.898817]\n",
      "epoch:28 step:22243[D loss: 0.430994, acc: 54.69%, op_acc: 32.03%] [G loss: 0.926309]\n",
      "epoch:28 step:22244[D loss: 0.401711, acc: 66.41%, op_acc: 40.62%] [G loss: 0.955481]\n",
      "epoch:28 step:22245[D loss: 0.417445, acc: 60.94%, op_acc: 38.28%] [G loss: 0.914793]\n",
      "epoch:28 step:22246[D loss: 0.425138, acc: 64.06%, op_acc: 39.84%] [G loss: 0.883342]\n",
      "epoch:28 step:22247[D loss: 0.389611, acc: 63.28%, op_acc: 43.75%] [G loss: 0.829080]\n",
      "epoch:28 step:22248[D loss: 0.416153, acc: 63.28%, op_acc: 40.62%] [G loss: 0.949308]\n",
      "epoch:28 step:22249[D loss: 0.407113, acc: 60.16%, op_acc: 43.75%] [G loss: 0.887173]\n",
      "epoch:28 step:22250[D loss: 0.436729, acc: 54.69%, op_acc: 34.38%] [G loss: 0.898969]\n",
      "##############\n",
      "[0.84539506 0.85684065 0.80071986 0.80733963 0.80527025 0.8194082\n",
      " 0.87389541 0.83951886 0.80634452 0.83369648]\n",
      "##########\n",
      "epoch:28 step:22251[D loss: 0.410616, acc: 56.25%, op_acc: 42.19%] [G loss: 0.870319]\n",
      "epoch:28 step:22252[D loss: 0.402405, acc: 66.41%, op_acc: 41.41%] [G loss: 0.998900]\n",
      "epoch:28 step:22253[D loss: 0.408520, acc: 57.81%, op_acc: 42.19%] [G loss: 0.859012]\n",
      "epoch:28 step:22254[D loss: 0.410813, acc: 60.16%, op_acc: 40.62%] [G loss: 0.882154]\n",
      "epoch:28 step:22255[D loss: 0.444484, acc: 52.34%, op_acc: 35.16%] [G loss: 0.896522]\n",
      "epoch:28 step:22256[D loss: 0.461583, acc: 55.47%, op_acc: 35.16%] [G loss: 0.949543]\n",
      "epoch:28 step:22257[D loss: 0.436640, acc: 57.03%, op_acc: 41.41%] [G loss: 0.897210]\n",
      "epoch:28 step:22258[D loss: 0.414299, acc: 58.59%, op_acc: 42.97%] [G loss: 0.791002]\n",
      "epoch:28 step:22259[D loss: 0.407875, acc: 54.69%, op_acc: 45.31%] [G loss: 0.853740]\n",
      "epoch:28 step:22260[D loss: 0.426639, acc: 58.59%, op_acc: 40.62%] [G loss: 0.925563]\n",
      "epoch:28 step:22261[D loss: 0.415422, acc: 62.50%, op_acc: 42.97%] [G loss: 0.852747]\n",
      "epoch:28 step:22262[D loss: 0.423657, acc: 59.38%, op_acc: 36.72%] [G loss: 0.820905]\n",
      "epoch:28 step:22263[D loss: 0.427556, acc: 67.97%, op_acc: 37.50%] [G loss: 0.879266]\n",
      "epoch:28 step:22264[D loss: 0.415784, acc: 55.47%, op_acc: 45.31%] [G loss: 0.867002]\n",
      "epoch:28 step:22265[D loss: 0.447634, acc: 50.78%, op_acc: 42.97%] [G loss: 0.803086]\n",
      "epoch:28 step:22266[D loss: 0.437798, acc: 57.03%, op_acc: 42.97%] [G loss: 0.849219]\n",
      "epoch:28 step:22267[D loss: 0.445890, acc: 52.34%, op_acc: 42.19%] [G loss: 0.848940]\n",
      "epoch:28 step:22268[D loss: 0.412684, acc: 63.28%, op_acc: 41.41%] [G loss: 0.953182]\n",
      "epoch:28 step:22269[D loss: 0.431945, acc: 54.69%, op_acc: 36.72%] [G loss: 0.920266]\n",
      "epoch:28 step:22270[D loss: 0.416516, acc: 66.41%, op_acc: 35.94%] [G loss: 0.867582]\n",
      "epoch:28 step:22271[D loss: 0.411681, acc: 61.72%, op_acc: 35.16%] [G loss: 0.963080]\n",
      "epoch:28 step:22272[D loss: 0.382477, acc: 64.84%, op_acc: 49.22%] [G loss: 0.912822]\n",
      "epoch:28 step:22273[D loss: 0.426634, acc: 60.16%, op_acc: 42.19%] [G loss: 0.951108]\n",
      "epoch:28 step:22274[D loss: 0.401827, acc: 62.50%, op_acc: 42.97%] [G loss: 0.957437]\n",
      "epoch:28 step:22275[D loss: 0.432103, acc: 58.59%, op_acc: 42.19%] [G loss: 0.879902]\n",
      "epoch:28 step:22276[D loss: 0.398822, acc: 65.62%, op_acc: 41.41%] [G loss: 0.840532]\n",
      "epoch:28 step:22277[D loss: 0.439825, acc: 54.69%, op_acc: 44.53%] [G loss: 0.940743]\n",
      "epoch:28 step:22278[D loss: 0.399014, acc: 67.97%, op_acc: 40.62%] [G loss: 0.939034]\n",
      "epoch:28 step:22279[D loss: 0.444853, acc: 60.94%, op_acc: 40.62%] [G loss: 0.938132]\n",
      "epoch:28 step:22280[D loss: 0.416114, acc: 59.38%, op_acc: 41.41%] [G loss: 0.961663]\n",
      "epoch:28 step:22281[D loss: 0.426609, acc: 54.69%, op_acc: 39.06%] [G loss: 0.843827]\n",
      "epoch:28 step:22282[D loss: 0.410446, acc: 56.25%, op_acc: 42.19%] [G loss: 0.950722]\n",
      "epoch:28 step:22283[D loss: 0.407240, acc: 59.38%, op_acc: 42.19%] [G loss: 0.930283]\n",
      "epoch:28 step:22284[D loss: 0.400580, acc: 68.75%, op_acc: 38.28%] [G loss: 0.931643]\n",
      "epoch:28 step:22285[D loss: 0.413605, acc: 61.72%, op_acc: 40.62%] [G loss: 0.895381]\n",
      "epoch:28 step:22286[D loss: 0.425989, acc: 55.47%, op_acc: 42.97%] [G loss: 0.931328]\n",
      "epoch:28 step:22287[D loss: 0.425915, acc: 58.59%, op_acc: 37.50%] [G loss: 0.838890]\n",
      "epoch:28 step:22288[D loss: 0.423498, acc: 58.59%, op_acc: 42.97%] [G loss: 0.871888]\n",
      "epoch:28 step:22289[D loss: 0.427404, acc: 61.72%, op_acc: 43.75%] [G loss: 0.786783]\n",
      "epoch:28 step:22290[D loss: 0.389616, acc: 60.94%, op_acc: 42.19%] [G loss: 0.893404]\n",
      "epoch:28 step:22291[D loss: 0.436499, acc: 61.72%, op_acc: 38.28%] [G loss: 0.890433]\n",
      "epoch:28 step:22292[D loss: 0.427074, acc: 67.97%, op_acc: 35.94%] [G loss: 0.937803]\n",
      "epoch:28 step:22293[D loss: 0.442488, acc: 57.81%, op_acc: 40.62%] [G loss: 0.906880]\n",
      "epoch:28 step:22294[D loss: 0.418278, acc: 61.72%, op_acc: 37.50%] [G loss: 0.881396]\n",
      "epoch:28 step:22295[D loss: 0.422941, acc: 64.06%, op_acc: 36.72%] [G loss: 0.897569]\n",
      "epoch:28 step:22296[D loss: 0.438219, acc: 54.69%, op_acc: 39.06%] [G loss: 0.900458]\n",
      "epoch:28 step:22297[D loss: 0.396561, acc: 62.50%, op_acc: 44.53%] [G loss: 0.955610]\n",
      "epoch:28 step:22298[D loss: 0.394811, acc: 64.06%, op_acc: 46.09%] [G loss: 0.887420]\n",
      "epoch:28 step:22299[D loss: 0.414493, acc: 60.16%, op_acc: 43.75%] [G loss: 0.892957]\n",
      "epoch:28 step:22300[D loss: 0.415656, acc: 57.81%, op_acc: 42.97%] [G loss: 0.962965]\n",
      "##############\n",
      "[0.86435143 0.85646288 0.82077729 0.77981185 0.78450274 0.82817765\n",
      " 0.90653493 0.81604703 0.84731204 0.84201025]\n",
      "##########\n",
      "epoch:28 step:22301[D loss: 0.414401, acc: 53.12%, op_acc: 42.97%] [G loss: 0.866437]\n",
      "epoch:28 step:22302[D loss: 0.375442, acc: 61.72%, op_acc: 49.22%] [G loss: 0.892194]\n",
      "epoch:28 step:22303[D loss: 0.398076, acc: 66.41%, op_acc: 40.62%] [G loss: 0.880153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22304[D loss: 0.455555, acc: 56.25%, op_acc: 34.38%] [G loss: 0.915661]\n",
      "epoch:28 step:22305[D loss: 0.435410, acc: 57.03%, op_acc: 39.84%] [G loss: 0.814014]\n",
      "epoch:28 step:22306[D loss: 0.442348, acc: 51.56%, op_acc: 42.97%] [G loss: 0.802836]\n",
      "epoch:28 step:22307[D loss: 0.448340, acc: 59.38%, op_acc: 35.94%] [G loss: 0.837980]\n",
      "epoch:28 step:22308[D loss: 0.415603, acc: 59.38%, op_acc: 41.41%] [G loss: 0.952723]\n",
      "epoch:28 step:22309[D loss: 0.397244, acc: 64.84%, op_acc: 39.06%] [G loss: 0.854696]\n",
      "epoch:28 step:22310[D loss: 0.402674, acc: 64.06%, op_acc: 40.62%] [G loss: 0.825307]\n",
      "epoch:28 step:22311[D loss: 0.417823, acc: 64.84%, op_acc: 42.19%] [G loss: 0.845741]\n",
      "epoch:28 step:22312[D loss: 0.411942, acc: 61.72%, op_acc: 39.84%] [G loss: 0.831092]\n",
      "epoch:28 step:22313[D loss: 0.430671, acc: 53.91%, op_acc: 39.84%] [G loss: 0.889908]\n",
      "epoch:28 step:22314[D loss: 0.416430, acc: 61.72%, op_acc: 41.41%] [G loss: 0.934985]\n",
      "epoch:28 step:22315[D loss: 0.426625, acc: 57.81%, op_acc: 38.28%] [G loss: 0.919079]\n",
      "epoch:28 step:22316[D loss: 0.385819, acc: 72.66%, op_acc: 40.62%] [G loss: 0.883380]\n",
      "epoch:28 step:22317[D loss: 0.393886, acc: 61.72%, op_acc: 38.28%] [G loss: 0.898635]\n",
      "epoch:28 step:22318[D loss: 0.436076, acc: 61.72%, op_acc: 34.38%] [G loss: 0.885131]\n",
      "epoch:28 step:22319[D loss: 0.416255, acc: 63.28%, op_acc: 39.84%] [G loss: 0.825282]\n",
      "epoch:28 step:22320[D loss: 0.420003, acc: 59.38%, op_acc: 41.41%] [G loss: 0.888912]\n",
      "epoch:28 step:22321[D loss: 0.398913, acc: 60.16%, op_acc: 43.75%] [G loss: 0.796180]\n",
      "epoch:28 step:22322[D loss: 0.408135, acc: 54.69%, op_acc: 44.53%] [G loss: 0.837925]\n",
      "epoch:28 step:22323[D loss: 0.429351, acc: 60.16%, op_acc: 40.62%] [G loss: 0.863236]\n",
      "epoch:28 step:22324[D loss: 0.434678, acc: 57.81%, op_acc: 39.06%] [G loss: 0.966074]\n",
      "epoch:28 step:22325[D loss: 0.422204, acc: 59.38%, op_acc: 42.97%] [G loss: 0.860139]\n",
      "epoch:28 step:22326[D loss: 0.419421, acc: 61.72%, op_acc: 42.19%] [G loss: 0.858425]\n",
      "epoch:28 step:22327[D loss: 0.448889, acc: 46.09%, op_acc: 38.28%] [G loss: 0.863487]\n",
      "epoch:28 step:22328[D loss: 0.418199, acc: 57.03%, op_acc: 40.62%] [G loss: 0.861243]\n",
      "epoch:28 step:22329[D loss: 0.429032, acc: 60.94%, op_acc: 32.03%] [G loss: 0.927694]\n",
      "epoch:28 step:22330[D loss: 0.449419, acc: 49.22%, op_acc: 39.06%] [G loss: 0.857397]\n",
      "epoch:28 step:22331[D loss: 0.399241, acc: 57.81%, op_acc: 44.53%] [G loss: 0.867744]\n",
      "epoch:28 step:22332[D loss: 0.423348, acc: 61.72%, op_acc: 34.38%] [G loss: 0.805386]\n",
      "epoch:28 step:22333[D loss: 0.431511, acc: 58.59%, op_acc: 38.28%] [G loss: 0.895930]\n",
      "epoch:28 step:22334[D loss: 0.379094, acc: 67.19%, op_acc: 42.97%] [G loss: 0.955430]\n",
      "epoch:28 step:22335[D loss: 0.409057, acc: 59.38%, op_acc: 46.88%] [G loss: 0.922323]\n",
      "epoch:28 step:22336[D loss: 0.416230, acc: 53.91%, op_acc: 45.31%] [G loss: 0.874805]\n",
      "epoch:28 step:22337[D loss: 0.435890, acc: 54.69%, op_acc: 38.28%] [G loss: 0.827612]\n",
      "epoch:28 step:22338[D loss: 0.406167, acc: 57.81%, op_acc: 42.97%] [G loss: 0.805182]\n",
      "epoch:28 step:22339[D loss: 0.448706, acc: 60.16%, op_acc: 38.28%] [G loss: 0.909016]\n",
      "epoch:28 step:22340[D loss: 0.413998, acc: 63.28%, op_acc: 32.81%] [G loss: 0.874757]\n",
      "epoch:28 step:22341[D loss: 0.411445, acc: 50.78%, op_acc: 44.53%] [G loss: 0.907583]\n",
      "epoch:28 step:22342[D loss: 0.448362, acc: 62.50%, op_acc: 39.06%] [G loss: 0.891686]\n",
      "epoch:28 step:22343[D loss: 0.411365, acc: 58.59%, op_acc: 43.75%] [G loss: 0.867955]\n",
      "epoch:28 step:22344[D loss: 0.448740, acc: 53.12%, op_acc: 39.84%] [G loss: 0.874379]\n",
      "epoch:28 step:22345[D loss: 0.428830, acc: 56.25%, op_acc: 42.19%] [G loss: 0.892904]\n",
      "epoch:28 step:22346[D loss: 0.407903, acc: 64.84%, op_acc: 38.28%] [G loss: 0.873795]\n",
      "epoch:28 step:22347[D loss: 0.416694, acc: 56.25%, op_acc: 37.50%] [G loss: 0.925798]\n",
      "epoch:28 step:22348[D loss: 0.425327, acc: 61.72%, op_acc: 44.53%] [G loss: 1.005242]\n",
      "epoch:28 step:22349[D loss: 0.462065, acc: 60.16%, op_acc: 37.50%] [G loss: 0.920283]\n",
      "epoch:28 step:22350[D loss: 0.417621, acc: 63.28%, op_acc: 40.62%] [G loss: 0.975148]\n",
      "##############\n",
      "[0.87183157 0.85758244 0.81120128 0.80461079 0.79135156 0.81098503\n",
      " 0.88449984 0.81455756 0.82075264 0.8250363 ]\n",
      "##########\n",
      "epoch:28 step:22351[D loss: 0.433421, acc: 58.59%, op_acc: 41.41%] [G loss: 0.886703]\n",
      "epoch:28 step:22352[D loss: 0.400402, acc: 60.16%, op_acc: 45.31%] [G loss: 0.945686]\n",
      "epoch:28 step:22353[D loss: 0.414165, acc: 66.41%, op_acc: 45.31%] [G loss: 0.980386]\n",
      "epoch:28 step:22354[D loss: 0.408742, acc: 59.38%, op_acc: 42.19%] [G loss: 0.876882]\n",
      "epoch:28 step:22355[D loss: 0.401267, acc: 61.72%, op_acc: 44.53%] [G loss: 0.930536]\n",
      "epoch:28 step:22356[D loss: 0.453816, acc: 50.78%, op_acc: 34.38%] [G loss: 0.867184]\n",
      "epoch:28 step:22357[D loss: 0.430702, acc: 60.16%, op_acc: 41.41%] [G loss: 0.849911]\n",
      "epoch:28 step:22358[D loss: 0.416790, acc: 59.38%, op_acc: 39.06%] [G loss: 0.924556]\n",
      "epoch:28 step:22359[D loss: 0.436708, acc: 58.59%, op_acc: 39.06%] [G loss: 0.941805]\n",
      "epoch:28 step:22360[D loss: 0.415461, acc: 57.81%, op_acc: 43.75%] [G loss: 0.845632]\n",
      "epoch:28 step:22361[D loss: 0.425992, acc: 56.25%, op_acc: 40.62%] [G loss: 0.898732]\n",
      "epoch:28 step:22362[D loss: 0.441798, acc: 48.44%, op_acc: 40.62%] [G loss: 0.878273]\n",
      "epoch:28 step:22363[D loss: 0.419303, acc: 60.16%, op_acc: 41.41%] [G loss: 0.829345]\n",
      "epoch:28 step:22364[D loss: 0.387111, acc: 68.75%, op_acc: 38.28%] [G loss: 0.919410]\n",
      "epoch:28 step:22365[D loss: 0.435911, acc: 51.56%, op_acc: 36.72%] [G loss: 0.795108]\n",
      "epoch:28 step:22366[D loss: 0.430651, acc: 58.59%, op_acc: 32.03%] [G loss: 0.879063]\n",
      "epoch:28 step:22367[D loss: 0.419310, acc: 67.19%, op_acc: 39.06%] [G loss: 0.910918]\n",
      "epoch:28 step:22368[D loss: 0.414693, acc: 59.38%, op_acc: 39.84%] [G loss: 0.936745]\n",
      "epoch:28 step:22369[D loss: 0.445290, acc: 48.44%, op_acc: 41.41%] [G loss: 0.928932]\n",
      "epoch:28 step:22370[D loss: 0.425645, acc: 58.59%, op_acc: 41.41%] [G loss: 0.859893]\n",
      "epoch:28 step:22371[D loss: 0.450008, acc: 50.78%, op_acc: 38.28%] [G loss: 0.854329]\n",
      "epoch:28 step:22372[D loss: 0.432373, acc: 60.16%, op_acc: 42.19%] [G loss: 0.918700]\n",
      "epoch:28 step:22373[D loss: 0.411461, acc: 61.72%, op_acc: 42.97%] [G loss: 0.870505]\n",
      "epoch:28 step:22374[D loss: 0.445522, acc: 53.12%, op_acc: 39.84%] [G loss: 0.872816]\n",
      "epoch:28 step:22375[D loss: 0.394171, acc: 67.19%, op_acc: 43.75%] [G loss: 0.864530]\n",
      "epoch:28 step:22376[D loss: 0.450266, acc: 54.69%, op_acc: 32.03%] [G loss: 0.836722]\n",
      "epoch:28 step:22377[D loss: 0.428564, acc: 61.72%, op_acc: 39.84%] [G loss: 0.824127]\n",
      "epoch:28 step:22378[D loss: 0.418804, acc: 64.06%, op_acc: 44.53%] [G loss: 0.846215]\n",
      "epoch:28 step:22379[D loss: 0.440982, acc: 50.00%, op_acc: 42.97%] [G loss: 0.919538]\n",
      "epoch:28 step:22380[D loss: 0.444705, acc: 56.25%, op_acc: 37.50%] [G loss: 0.881169]\n",
      "epoch:28 step:22381[D loss: 0.428948, acc: 53.91%, op_acc: 38.28%] [G loss: 0.862782]\n",
      "epoch:28 step:22382[D loss: 0.447507, acc: 52.34%, op_acc: 44.53%] [G loss: 0.931363]\n",
      "epoch:28 step:22383[D loss: 0.420578, acc: 58.59%, op_acc: 37.50%] [G loss: 0.833052]\n",
      "epoch:28 step:22384[D loss: 0.405334, acc: 60.16%, op_acc: 43.75%] [G loss: 0.929488]\n",
      "epoch:28 step:22385[D loss: 0.413267, acc: 70.31%, op_acc: 40.62%] [G loss: 0.913293]\n",
      "epoch:28 step:22386[D loss: 0.384753, acc: 64.84%, op_acc: 46.09%] [G loss: 0.912456]\n",
      "epoch:28 step:22387[D loss: 0.402499, acc: 64.06%, op_acc: 39.06%] [G loss: 0.893682]\n",
      "epoch:28 step:22388[D loss: 0.444784, acc: 50.78%, op_acc: 37.50%] [G loss: 0.882625]\n",
      "epoch:28 step:22389[D loss: 0.438522, acc: 57.81%, op_acc: 37.50%] [G loss: 0.957281]\n",
      "epoch:28 step:22390[D loss: 0.455987, acc: 48.44%, op_acc: 37.50%] [G loss: 0.913156]\n",
      "epoch:28 step:22391[D loss: 0.433756, acc: 64.84%, op_acc: 38.28%] [G loss: 0.929189]\n",
      "epoch:28 step:22392[D loss: 0.410260, acc: 67.97%, op_acc: 42.19%] [G loss: 0.916509]\n",
      "epoch:28 step:22393[D loss: 0.453473, acc: 54.69%, op_acc: 32.81%] [G loss: 0.924448]\n",
      "epoch:28 step:22394[D loss: 0.440369, acc: 59.38%, op_acc: 35.94%] [G loss: 0.858602]\n",
      "epoch:28 step:22395[D loss: 0.408396, acc: 59.38%, op_acc: 47.66%] [G loss: 0.931103]\n",
      "epoch:28 step:22396[D loss: 0.441420, acc: 53.12%, op_acc: 40.62%] [G loss: 0.951814]\n",
      "epoch:28 step:22397[D loss: 0.400219, acc: 60.94%, op_acc: 39.84%] [G loss: 0.884634]\n",
      "epoch:28 step:22398[D loss: 0.409375, acc: 63.28%, op_acc: 40.62%] [G loss: 0.842747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22399[D loss: 0.395907, acc: 67.97%, op_acc: 41.41%] [G loss: 0.971096]\n",
      "epoch:28 step:22400[D loss: 0.393544, acc: 67.97%, op_acc: 44.53%] [G loss: 0.917966]\n",
      "##############\n",
      "[0.87828156 0.85251484 0.80903685 0.79200685 0.781631   0.83523981\n",
      " 0.8937515  0.8225714  0.80342592 0.82193333]\n",
      "##########\n",
      "epoch:28 step:22401[D loss: 0.444759, acc: 53.12%, op_acc: 42.97%] [G loss: 0.849498]\n",
      "epoch:28 step:22402[D loss: 0.417352, acc: 54.69%, op_acc: 44.53%] [G loss: 0.897869]\n",
      "epoch:28 step:22403[D loss: 0.422001, acc: 60.16%, op_acc: 41.41%] [G loss: 0.843317]\n",
      "epoch:28 step:22404[D loss: 0.382919, acc: 64.84%, op_acc: 44.53%] [G loss: 0.883327]\n",
      "epoch:28 step:22405[D loss: 0.429117, acc: 56.25%, op_acc: 38.28%] [G loss: 0.889086]\n",
      "epoch:28 step:22406[D loss: 0.409488, acc: 59.38%, op_acc: 38.28%] [G loss: 0.929600]\n",
      "epoch:28 step:22407[D loss: 0.422417, acc: 60.16%, op_acc: 36.72%] [G loss: 0.809587]\n",
      "epoch:28 step:22408[D loss: 0.417108, acc: 59.38%, op_acc: 46.09%] [G loss: 0.871369]\n",
      "epoch:28 step:22409[D loss: 0.390630, acc: 69.53%, op_acc: 36.72%] [G loss: 0.896358]\n",
      "epoch:28 step:22410[D loss: 0.450668, acc: 49.22%, op_acc: 35.16%] [G loss: 0.864762]\n",
      "epoch:28 step:22411[D loss: 0.441129, acc: 53.12%, op_acc: 38.28%] [G loss: 0.872402]\n",
      "epoch:28 step:22412[D loss: 0.449791, acc: 57.03%, op_acc: 41.41%] [G loss: 0.892956]\n",
      "epoch:28 step:22413[D loss: 0.395334, acc: 66.41%, op_acc: 38.28%] [G loss: 0.846269]\n",
      "epoch:28 step:22414[D loss: 0.425875, acc: 61.72%, op_acc: 42.19%] [G loss: 0.949270]\n",
      "epoch:28 step:22415[D loss: 0.441117, acc: 56.25%, op_acc: 38.28%] [G loss: 0.878736]\n",
      "epoch:28 step:22416[D loss: 0.421245, acc: 64.84%, op_acc: 35.94%] [G loss: 0.979118]\n",
      "epoch:28 step:22417[D loss: 0.406400, acc: 63.28%, op_acc: 40.62%] [G loss: 0.963659]\n",
      "epoch:28 step:22418[D loss: 0.416301, acc: 56.25%, op_acc: 42.19%] [G loss: 0.935133]\n",
      "epoch:28 step:22419[D loss: 0.410104, acc: 63.28%, op_acc: 43.75%] [G loss: 0.999650]\n",
      "epoch:28 step:22420[D loss: 0.462285, acc: 51.56%, op_acc: 35.94%] [G loss: 0.828961]\n",
      "epoch:28 step:22421[D loss: 0.406939, acc: 65.62%, op_acc: 36.72%] [G loss: 0.926584]\n",
      "epoch:28 step:22422[D loss: 0.417061, acc: 65.62%, op_acc: 35.94%] [G loss: 0.861008]\n",
      "epoch:28 step:22423[D loss: 0.417189, acc: 58.59%, op_acc: 38.28%] [G loss: 0.888801]\n",
      "epoch:28 step:22424[D loss: 0.410950, acc: 60.94%, op_acc: 41.41%] [G loss: 0.896257]\n",
      "epoch:28 step:22425[D loss: 0.422644, acc: 61.72%, op_acc: 36.72%] [G loss: 0.936439]\n",
      "epoch:28 step:22426[D loss: 0.404913, acc: 57.81%, op_acc: 45.31%] [G loss: 0.809805]\n",
      "epoch:28 step:22427[D loss: 0.407571, acc: 59.38%, op_acc: 42.19%] [G loss: 0.849631]\n",
      "epoch:28 step:22428[D loss: 0.459114, acc: 54.69%, op_acc: 35.16%] [G loss: 0.895929]\n",
      "epoch:28 step:22429[D loss: 0.413744, acc: 58.59%, op_acc: 40.62%] [G loss: 0.864264]\n",
      "epoch:28 step:22430[D loss: 0.447376, acc: 57.03%, op_acc: 39.06%] [G loss: 0.929763]\n",
      "epoch:28 step:22431[D loss: 0.419319, acc: 60.16%, op_acc: 35.94%] [G loss: 0.828754]\n",
      "epoch:28 step:22432[D loss: 0.437890, acc: 49.22%, op_acc: 44.53%] [G loss: 0.884088]\n",
      "epoch:28 step:22433[D loss: 0.426101, acc: 60.94%, op_acc: 41.41%] [G loss: 0.942979]\n",
      "epoch:28 step:22434[D loss: 0.424559, acc: 58.59%, op_acc: 32.81%] [G loss: 0.872231]\n",
      "epoch:28 step:22435[D loss: 0.418440, acc: 59.38%, op_acc: 42.97%] [G loss: 0.881765]\n",
      "epoch:28 step:22436[D loss: 0.448104, acc: 51.56%, op_acc: 38.28%] [G loss: 0.771146]\n",
      "epoch:28 step:22437[D loss: 0.381201, acc: 70.31%, op_acc: 42.97%] [G loss: 0.897273]\n",
      "epoch:28 step:22438[D loss: 0.407501, acc: 63.28%, op_acc: 40.62%] [G loss: 0.902295]\n",
      "epoch:28 step:22439[D loss: 0.420109, acc: 60.16%, op_acc: 41.41%] [G loss: 0.863303]\n",
      "epoch:28 step:22440[D loss: 0.429238, acc: 50.78%, op_acc: 41.41%] [G loss: 0.811982]\n",
      "epoch:28 step:22441[D loss: 0.447484, acc: 54.69%, op_acc: 35.94%] [G loss: 0.921542]\n",
      "epoch:28 step:22442[D loss: 0.415512, acc: 59.38%, op_acc: 39.06%] [G loss: 0.916824]\n",
      "epoch:28 step:22443[D loss: 0.440726, acc: 56.25%, op_acc: 42.19%] [G loss: 0.816992]\n",
      "epoch:28 step:22444[D loss: 0.442418, acc: 55.47%, op_acc: 34.38%] [G loss: 0.811686]\n",
      "epoch:28 step:22445[D loss: 0.471340, acc: 54.69%, op_acc: 32.81%] [G loss: 0.912448]\n",
      "epoch:28 step:22446[D loss: 0.469090, acc: 54.69%, op_acc: 35.94%] [G loss: 0.926451]\n",
      "epoch:28 step:22447[D loss: 0.402840, acc: 62.50%, op_acc: 43.75%] [G loss: 0.890647]\n",
      "epoch:28 step:22448[D loss: 0.395932, acc: 63.28%, op_acc: 45.31%] [G loss: 0.966638]\n",
      "epoch:28 step:22449[D loss: 0.438371, acc: 56.25%, op_acc: 38.28%] [G loss: 0.863395]\n",
      "epoch:28 step:22450[D loss: 0.442376, acc: 53.12%, op_acc: 35.94%] [G loss: 0.853338]\n",
      "##############\n",
      "[0.85735937 0.845506   0.81028624 0.81883361 0.79876952 0.84219377\n",
      " 0.88514779 0.8384135  0.80564477 0.82831412]\n",
      "##########\n",
      "epoch:28 step:22451[D loss: 0.407189, acc: 61.72%, op_acc: 46.09%] [G loss: 0.844770]\n",
      "epoch:28 step:22452[D loss: 0.477371, acc: 43.75%, op_acc: 30.47%] [G loss: 0.826446]\n",
      "epoch:28 step:22453[D loss: 0.402392, acc: 62.50%, op_acc: 40.62%] [G loss: 0.885500]\n",
      "epoch:28 step:22454[D loss: 0.430645, acc: 60.16%, op_acc: 41.41%] [G loss: 0.906727]\n",
      "epoch:28 step:22455[D loss: 0.389794, acc: 70.31%, op_acc: 39.06%] [G loss: 0.862304]\n",
      "epoch:28 step:22456[D loss: 0.390989, acc: 65.62%, op_acc: 42.19%] [G loss: 0.877837]\n",
      "epoch:28 step:22457[D loss: 0.423746, acc: 57.03%, op_acc: 39.84%] [G loss: 0.786367]\n",
      "epoch:28 step:22458[D loss: 0.423264, acc: 60.94%, op_acc: 38.28%] [G loss: 0.843619]\n",
      "epoch:28 step:22459[D loss: 0.453653, acc: 43.75%, op_acc: 34.38%] [G loss: 0.891855]\n",
      "epoch:28 step:22460[D loss: 0.442152, acc: 49.22%, op_acc: 38.28%] [G loss: 0.840182]\n",
      "epoch:28 step:22461[D loss: 0.453245, acc: 55.47%, op_acc: 32.81%] [G loss: 0.951398]\n",
      "epoch:28 step:22462[D loss: 0.384469, acc: 68.75%, op_acc: 37.50%] [G loss: 0.945671]\n",
      "epoch:28 step:22463[D loss: 0.409270, acc: 65.62%, op_acc: 42.19%] [G loss: 0.789529]\n",
      "epoch:28 step:22464[D loss: 0.421678, acc: 57.03%, op_acc: 42.97%] [G loss: 0.909537]\n",
      "epoch:28 step:22465[D loss: 0.418647, acc: 60.16%, op_acc: 38.28%] [G loss: 0.954681]\n",
      "epoch:28 step:22466[D loss: 0.408180, acc: 64.84%, op_acc: 45.31%] [G loss: 0.936356]\n",
      "epoch:28 step:22467[D loss: 0.424840, acc: 56.25%, op_acc: 37.50%] [G loss: 0.874940]\n",
      "epoch:28 step:22468[D loss: 0.436630, acc: 52.34%, op_acc: 39.06%] [G loss: 0.917797]\n",
      "epoch:28 step:22469[D loss: 0.424430, acc: 63.28%, op_acc: 42.19%] [G loss: 0.811017]\n",
      "epoch:28 step:22470[D loss: 0.413513, acc: 60.94%, op_acc: 40.62%] [G loss: 0.860452]\n",
      "epoch:28 step:22471[D loss: 0.390208, acc: 64.84%, op_acc: 46.88%] [G loss: 0.912797]\n",
      "epoch:28 step:22472[D loss: 0.442524, acc: 57.81%, op_acc: 38.28%] [G loss: 0.861664]\n",
      "epoch:28 step:22473[D loss: 0.416288, acc: 64.84%, op_acc: 36.72%] [G loss: 0.965555]\n",
      "epoch:28 step:22474[D loss: 0.437723, acc: 51.56%, op_acc: 40.62%] [G loss: 0.883677]\n",
      "epoch:28 step:22475[D loss: 0.437135, acc: 50.78%, op_acc: 42.19%] [G loss: 0.847075]\n",
      "epoch:28 step:22476[D loss: 0.374035, acc: 68.75%, op_acc: 40.62%] [G loss: 0.968208]\n",
      "epoch:28 step:22477[D loss: 0.420317, acc: 50.00%, op_acc: 38.28%] [G loss: 0.860370]\n",
      "epoch:28 step:22478[D loss: 0.407139, acc: 67.19%, op_acc: 39.84%] [G loss: 0.898677]\n",
      "epoch:28 step:22479[D loss: 0.448585, acc: 53.12%, op_acc: 34.38%] [G loss: 0.833252]\n",
      "epoch:28 step:22480[D loss: 0.437108, acc: 49.22%, op_acc: 39.84%] [G loss: 0.874828]\n",
      "epoch:28 step:22481[D loss: 0.429406, acc: 54.69%, op_acc: 42.19%] [G loss: 0.865671]\n",
      "epoch:28 step:22482[D loss: 0.412220, acc: 59.38%, op_acc: 42.97%] [G loss: 0.848134]\n",
      "epoch:28 step:22483[D loss: 0.440843, acc: 43.75%, op_acc: 40.62%] [G loss: 0.862520]\n",
      "epoch:28 step:22484[D loss: 0.416882, acc: 60.94%, op_acc: 39.84%] [G loss: 0.895094]\n",
      "epoch:28 step:22485[D loss: 0.425879, acc: 61.72%, op_acc: 42.19%] [G loss: 0.870853]\n",
      "epoch:28 step:22486[D loss: 0.425927, acc: 55.47%, op_acc: 38.28%] [G loss: 0.892877]\n",
      "epoch:28 step:22487[D loss: 0.474351, acc: 53.12%, op_acc: 36.72%] [G loss: 0.934379]\n",
      "epoch:28 step:22488[D loss: 0.418993, acc: 58.59%, op_acc: 39.84%] [G loss: 0.878307]\n",
      "epoch:28 step:22489[D loss: 0.450477, acc: 56.25%, op_acc: 40.62%] [G loss: 0.868020]\n",
      "epoch:28 step:22490[D loss: 0.456122, acc: 63.28%, op_acc: 34.38%] [G loss: 0.888547]\n",
      "epoch:28 step:22491[D loss: 0.425327, acc: 53.91%, op_acc: 41.41%] [G loss: 0.836306]\n",
      "epoch:28 step:22492[D loss: 0.424043, acc: 53.91%, op_acc: 41.41%] [G loss: 0.900741]\n",
      "epoch:28 step:22493[D loss: 0.422869, acc: 58.59%, op_acc: 44.53%] [G loss: 0.942744]\n",
      "epoch:28 step:22494[D loss: 0.413326, acc: 57.81%, op_acc: 43.75%] [G loss: 0.863424]\n",
      "epoch:28 step:22495[D loss: 0.413793, acc: 58.59%, op_acc: 44.53%] [G loss: 0.890408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22496[D loss: 0.405042, acc: 62.50%, op_acc: 42.19%] [G loss: 0.869846]\n",
      "epoch:28 step:22497[D loss: 0.435958, acc: 62.50%, op_acc: 35.94%] [G loss: 0.859078]\n",
      "epoch:28 step:22498[D loss: 0.417553, acc: 60.94%, op_acc: 45.31%] [G loss: 0.866976]\n",
      "epoch:28 step:22499[D loss: 0.463752, acc: 50.78%, op_acc: 35.94%] [G loss: 0.825774]\n",
      "epoch:28 step:22500[D loss: 0.422605, acc: 62.50%, op_acc: 38.28%] [G loss: 0.895240]\n",
      "##############\n",
      "[0.86601016 0.86119248 0.80476806 0.82475743 0.8062413  0.8028237\n",
      " 0.89295078 0.82378202 0.80195155 0.83485052]\n",
      "##########\n",
      "epoch:28 step:22501[D loss: 0.449942, acc: 53.12%, op_acc: 34.38%] [G loss: 0.817340]\n",
      "epoch:28 step:22502[D loss: 0.412846, acc: 58.59%, op_acc: 42.97%] [G loss: 0.903603]\n",
      "epoch:28 step:22503[D loss: 0.406979, acc: 64.06%, op_acc: 35.94%] [G loss: 0.858279]\n",
      "epoch:28 step:22504[D loss: 0.393081, acc: 60.94%, op_acc: 42.19%] [G loss: 0.795644]\n",
      "epoch:28 step:22505[D loss: 0.442776, acc: 54.69%, op_acc: 42.19%] [G loss: 0.912301]\n",
      "epoch:28 step:22506[D loss: 0.407862, acc: 63.28%, op_acc: 41.41%] [G loss: 0.923638]\n",
      "epoch:28 step:22507[D loss: 0.447737, acc: 56.25%, op_acc: 36.72%] [G loss: 0.903954]\n",
      "epoch:28 step:22508[D loss: 0.438339, acc: 60.94%, op_acc: 37.50%] [G loss: 0.822866]\n",
      "epoch:28 step:22509[D loss: 0.427371, acc: 52.34%, op_acc: 40.62%] [G loss: 0.864535]\n",
      "epoch:28 step:22510[D loss: 0.419074, acc: 62.50%, op_acc: 41.41%] [G loss: 0.917141]\n",
      "epoch:28 step:22511[D loss: 0.468020, acc: 53.91%, op_acc: 34.38%] [G loss: 0.855238]\n",
      "epoch:28 step:22512[D loss: 0.394552, acc: 64.06%, op_acc: 40.62%] [G loss: 0.876478]\n",
      "epoch:28 step:22513[D loss: 0.393671, acc: 64.84%, op_acc: 43.75%] [G loss: 0.836366]\n",
      "epoch:28 step:22514[D loss: 0.437068, acc: 63.28%, op_acc: 39.84%] [G loss: 0.934508]\n",
      "epoch:28 step:22515[D loss: 0.396779, acc: 66.41%, op_acc: 42.19%] [G loss: 0.995279]\n",
      "epoch:28 step:22516[D loss: 0.448763, acc: 54.69%, op_acc: 32.81%] [G loss: 0.888570]\n",
      "epoch:28 step:22517[D loss: 0.415109, acc: 63.28%, op_acc: 39.84%] [G loss: 0.851888]\n",
      "epoch:28 step:22518[D loss: 0.431518, acc: 62.50%, op_acc: 36.72%] [G loss: 0.888278]\n",
      "epoch:28 step:22519[D loss: 0.427426, acc: 59.38%, op_acc: 41.41%] [G loss: 0.859363]\n",
      "epoch:28 step:22520[D loss: 0.405723, acc: 60.94%, op_acc: 40.62%] [G loss: 0.920480]\n",
      "epoch:28 step:22521[D loss: 0.387512, acc: 61.72%, op_acc: 42.97%] [G loss: 0.913821]\n",
      "epoch:28 step:22522[D loss: 0.412880, acc: 57.81%, op_acc: 41.41%] [G loss: 1.001004]\n",
      "epoch:28 step:22523[D loss: 0.404491, acc: 63.28%, op_acc: 44.53%] [G loss: 0.865779]\n",
      "epoch:28 step:22524[D loss: 0.452425, acc: 48.44%, op_acc: 32.03%] [G loss: 0.791112]\n",
      "epoch:28 step:22525[D loss: 0.386609, acc: 64.84%, op_acc: 38.28%] [G loss: 0.973286]\n",
      "epoch:28 step:22526[D loss: 0.409252, acc: 67.97%, op_acc: 42.97%] [G loss: 0.895517]\n",
      "epoch:28 step:22527[D loss: 0.422021, acc: 60.16%, op_acc: 39.84%] [G loss: 0.878338]\n",
      "epoch:28 step:22528[D loss: 0.444399, acc: 50.78%, op_acc: 41.41%] [G loss: 0.851200]\n",
      "epoch:28 step:22529[D loss: 0.431343, acc: 55.47%, op_acc: 41.41%] [G loss: 0.839448]\n",
      "epoch:28 step:22530[D loss: 0.405488, acc: 61.72%, op_acc: 42.97%] [G loss: 0.834613]\n",
      "epoch:28 step:22531[D loss: 0.417060, acc: 61.72%, op_acc: 41.41%] [G loss: 0.860183]\n",
      "epoch:28 step:22532[D loss: 0.400171, acc: 65.62%, op_acc: 42.97%] [G loss: 0.850235]\n",
      "epoch:28 step:22533[D loss: 0.423237, acc: 62.50%, op_acc: 33.59%] [G loss: 0.964509]\n",
      "epoch:28 step:22534[D loss: 0.409697, acc: 65.62%, op_acc: 39.84%] [G loss: 0.884039]\n",
      "epoch:28 step:22535[D loss: 0.424550, acc: 60.16%, op_acc: 39.06%] [G loss: 0.872380]\n",
      "epoch:28 step:22536[D loss: 0.435888, acc: 56.25%, op_acc: 43.75%] [G loss: 0.919249]\n",
      "epoch:28 step:22537[D loss: 0.416969, acc: 66.41%, op_acc: 42.97%] [G loss: 0.844249]\n",
      "epoch:28 step:22538[D loss: 0.415285, acc: 64.84%, op_acc: 40.62%] [G loss: 0.929212]\n",
      "epoch:28 step:22539[D loss: 0.410058, acc: 67.97%, op_acc: 39.06%] [G loss: 0.941372]\n",
      "epoch:28 step:22540[D loss: 0.422200, acc: 58.59%, op_acc: 37.50%] [G loss: 0.813803]\n",
      "epoch:28 step:22541[D loss: 0.419485, acc: 55.47%, op_acc: 37.50%] [G loss: 0.869355]\n",
      "epoch:28 step:22542[D loss: 0.431030, acc: 49.22%, op_acc: 42.97%] [G loss: 0.844722]\n",
      "epoch:28 step:22543[D loss: 0.409729, acc: 64.06%, op_acc: 37.50%] [G loss: 0.833270]\n",
      "epoch:28 step:22544[D loss: 0.450152, acc: 50.00%, op_acc: 35.94%] [G loss: 0.822237]\n",
      "epoch:28 step:22545[D loss: 0.464174, acc: 50.78%, op_acc: 35.94%] [G loss: 0.849920]\n",
      "epoch:28 step:22546[D loss: 0.421805, acc: 58.59%, op_acc: 38.28%] [G loss: 0.766758]\n",
      "epoch:28 step:22547[D loss: 0.414979, acc: 63.28%, op_acc: 42.19%] [G loss: 0.889925]\n",
      "epoch:28 step:22548[D loss: 0.422236, acc: 63.28%, op_acc: 39.06%] [G loss: 0.938753]\n",
      "epoch:28 step:22549[D loss: 0.470554, acc: 56.25%, op_acc: 33.59%] [G loss: 0.913956]\n",
      "epoch:28 step:22550[D loss: 0.412263, acc: 58.59%, op_acc: 40.62%] [G loss: 0.903129]\n",
      "##############\n",
      "[0.86756429 0.86360047 0.81059852 0.80637922 0.78464946 0.81171443\n",
      " 0.87643015 0.82408588 0.80561978 0.81932885]\n",
      "##########\n",
      "epoch:28 step:22551[D loss: 0.410067, acc: 60.94%, op_acc: 41.41%] [G loss: 0.888629]\n",
      "epoch:28 step:22552[D loss: 0.443072, acc: 60.16%, op_acc: 36.72%] [G loss: 0.945680]\n",
      "epoch:28 step:22553[D loss: 0.436717, acc: 57.03%, op_acc: 32.81%] [G loss: 0.872532]\n",
      "epoch:28 step:22554[D loss: 0.439063, acc: 56.25%, op_acc: 38.28%] [G loss: 0.846934]\n",
      "epoch:28 step:22555[D loss: 0.413326, acc: 59.38%, op_acc: 38.28%] [G loss: 0.803991]\n",
      "epoch:28 step:22556[D loss: 0.420376, acc: 60.94%, op_acc: 38.28%] [G loss: 0.843952]\n",
      "epoch:28 step:22557[D loss: 0.409342, acc: 60.94%, op_acc: 44.53%] [G loss: 0.886107]\n",
      "epoch:28 step:22558[D loss: 0.414256, acc: 60.16%, op_acc: 38.28%] [G loss: 0.882566]\n",
      "epoch:28 step:22559[D loss: 0.400647, acc: 64.06%, op_acc: 45.31%] [G loss: 0.857324]\n",
      "epoch:28 step:22560[D loss: 0.412016, acc: 57.81%, op_acc: 42.19%] [G loss: 0.956060]\n",
      "epoch:28 step:22561[D loss: 0.420421, acc: 60.94%, op_acc: 40.62%] [G loss: 0.877023]\n",
      "epoch:28 step:22562[D loss: 0.423764, acc: 61.72%, op_acc: 36.72%] [G loss: 0.925380]\n",
      "epoch:28 step:22563[D loss: 0.410951, acc: 61.72%, op_acc: 38.28%] [G loss: 0.971635]\n",
      "epoch:28 step:22564[D loss: 0.446467, acc: 52.34%, op_acc: 40.62%] [G loss: 0.871384]\n",
      "epoch:28 step:22565[D loss: 0.390768, acc: 63.28%, op_acc: 45.31%] [G loss: 0.876145]\n",
      "epoch:28 step:22566[D loss: 0.386251, acc: 71.88%, op_acc: 38.28%] [G loss: 0.915202]\n",
      "epoch:28 step:22567[D loss: 0.386078, acc: 61.72%, op_acc: 42.97%] [G loss: 0.920775]\n",
      "epoch:28 step:22568[D loss: 0.437421, acc: 56.25%, op_acc: 35.16%] [G loss: 0.818909]\n",
      "epoch:28 step:22569[D loss: 0.408562, acc: 67.97%, op_acc: 35.16%] [G loss: 0.875802]\n",
      "epoch:28 step:22570[D loss: 0.418769, acc: 60.16%, op_acc: 38.28%] [G loss: 0.852033]\n",
      "epoch:28 step:22571[D loss: 0.444390, acc: 55.47%, op_acc: 36.72%] [G loss: 0.801274]\n",
      "epoch:28 step:22572[D loss: 0.405509, acc: 59.38%, op_acc: 42.97%] [G loss: 0.862395]\n",
      "epoch:28 step:22573[D loss: 0.406829, acc: 66.41%, op_acc: 37.50%] [G loss: 0.813075]\n",
      "epoch:28 step:22574[D loss: 0.419242, acc: 58.59%, op_acc: 41.41%] [G loss: 0.852749]\n",
      "epoch:28 step:22575[D loss: 0.432526, acc: 54.69%, op_acc: 41.41%] [G loss: 0.871096]\n",
      "epoch:28 step:22576[D loss: 0.441216, acc: 57.81%, op_acc: 39.84%] [G loss: 0.860243]\n",
      "epoch:28 step:22577[D loss: 0.410428, acc: 58.59%, op_acc: 39.84%] [G loss: 0.852607]\n",
      "epoch:28 step:22578[D loss: 0.404633, acc: 57.81%, op_acc: 46.09%] [G loss: 0.855898]\n",
      "epoch:28 step:22579[D loss: 0.423508, acc: 56.25%, op_acc: 42.97%] [G loss: 0.888435]\n",
      "epoch:28 step:22580[D loss: 0.398704, acc: 63.28%, op_acc: 48.44%] [G loss: 0.886693]\n",
      "epoch:28 step:22581[D loss: 0.414004, acc: 57.03%, op_acc: 40.62%] [G loss: 0.804753]\n",
      "epoch:28 step:22582[D loss: 0.434335, acc: 61.72%, op_acc: 39.84%] [G loss: 0.880081]\n",
      "epoch:28 step:22583[D loss: 0.434213, acc: 54.69%, op_acc: 42.97%] [G loss: 0.911184]\n",
      "epoch:28 step:22584[D loss: 0.421847, acc: 63.28%, op_acc: 42.97%] [G loss: 0.806896]\n",
      "epoch:28 step:22585[D loss: 0.422263, acc: 53.12%, op_acc: 44.53%] [G loss: 0.867577]\n",
      "epoch:28 step:22586[D loss: 0.407438, acc: 64.06%, op_acc: 46.09%] [G loss: 0.937726]\n",
      "epoch:28 step:22587[D loss: 0.416219, acc: 60.16%, op_acc: 41.41%] [G loss: 0.856242]\n",
      "epoch:28 step:22588[D loss: 0.432814, acc: 57.81%, op_acc: 36.72%] [G loss: 0.861625]\n",
      "epoch:28 step:22589[D loss: 0.411903, acc: 65.62%, op_acc: 39.06%] [G loss: 0.829019]\n",
      "epoch:28 step:22590[D loss: 0.410320, acc: 62.50%, op_acc: 43.75%] [G loss: 0.905689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22591[D loss: 0.424246, acc: 57.81%, op_acc: 39.84%] [G loss: 0.836265]\n",
      "epoch:28 step:22592[D loss: 0.469018, acc: 50.78%, op_acc: 36.72%] [G loss: 0.926429]\n",
      "epoch:28 step:22593[D loss: 0.418113, acc: 61.72%, op_acc: 35.16%] [G loss: 0.923538]\n",
      "epoch:28 step:22594[D loss: 0.426654, acc: 60.16%, op_acc: 39.06%] [G loss: 0.929742]\n",
      "epoch:28 step:22595[D loss: 0.470418, acc: 47.66%, op_acc: 36.72%] [G loss: 0.832871]\n",
      "epoch:28 step:22596[D loss: 0.445390, acc: 53.91%, op_acc: 39.06%] [G loss: 0.876197]\n",
      "epoch:28 step:22597[D loss: 0.434836, acc: 56.25%, op_acc: 39.84%] [G loss: 0.838081]\n",
      "epoch:28 step:22598[D loss: 0.426004, acc: 65.62%, op_acc: 39.06%] [G loss: 0.889934]\n",
      "epoch:28 step:22599[D loss: 0.410738, acc: 60.16%, op_acc: 42.97%] [G loss: 0.879087]\n",
      "epoch:28 step:22600[D loss: 0.409971, acc: 61.72%, op_acc: 34.38%] [G loss: 0.819329]\n",
      "##############\n",
      "[0.86530656 0.86263177 0.79894087 0.79735208 0.79966786 0.83273896\n",
      " 0.85995858 0.82527703 0.81435037 0.82322759]\n",
      "##########\n",
      "epoch:28 step:22601[D loss: 0.394966, acc: 63.28%, op_acc: 39.06%] [G loss: 0.877329]\n",
      "epoch:28 step:22602[D loss: 0.443601, acc: 55.47%, op_acc: 39.06%] [G loss: 0.811842]\n",
      "epoch:28 step:22603[D loss: 0.399902, acc: 63.28%, op_acc: 42.19%] [G loss: 0.888841]\n",
      "epoch:28 step:22604[D loss: 0.398161, acc: 64.84%, op_acc: 39.06%] [G loss: 0.904405]\n",
      "epoch:28 step:22605[D loss: 0.387962, acc: 65.62%, op_acc: 48.44%] [G loss: 0.855653]\n",
      "epoch:28 step:22606[D loss: 0.407390, acc: 64.06%, op_acc: 42.97%] [G loss: 0.877650]\n",
      "epoch:28 step:22607[D loss: 0.404033, acc: 63.28%, op_acc: 39.84%] [G loss: 0.935043]\n",
      "epoch:28 step:22608[D loss: 0.406643, acc: 57.81%, op_acc: 39.06%] [G loss: 0.968941]\n",
      "epoch:28 step:22609[D loss: 0.404950, acc: 53.91%, op_acc: 44.53%] [G loss: 0.925261]\n",
      "epoch:28 step:22610[D loss: 0.414777, acc: 59.38%, op_acc: 37.50%] [G loss: 0.864787]\n",
      "epoch:28 step:22611[D loss: 0.419746, acc: 57.81%, op_acc: 39.06%] [G loss: 0.880158]\n",
      "epoch:28 step:22612[D loss: 0.390905, acc: 60.16%, op_acc: 42.97%] [G loss: 0.908057]\n",
      "epoch:28 step:22613[D loss: 0.393741, acc: 59.38%, op_acc: 43.75%] [G loss: 0.875068]\n",
      "epoch:28 step:22614[D loss: 0.430421, acc: 57.03%, op_acc: 42.97%] [G loss: 0.907439]\n",
      "epoch:28 step:22615[D loss: 0.431769, acc: 60.16%, op_acc: 38.28%] [G loss: 0.880950]\n",
      "epoch:28 step:22616[D loss: 0.423120, acc: 58.59%, op_acc: 38.28%] [G loss: 0.853537]\n",
      "epoch:28 step:22617[D loss: 0.437241, acc: 61.72%, op_acc: 37.50%] [G loss: 0.794138]\n",
      "epoch:28 step:22618[D loss: 0.429889, acc: 60.94%, op_acc: 39.84%] [G loss: 0.830385]\n",
      "epoch:28 step:22619[D loss: 0.439440, acc: 59.38%, op_acc: 38.28%] [G loss: 0.899648]\n",
      "epoch:28 step:22620[D loss: 0.429067, acc: 57.03%, op_acc: 39.06%] [G loss: 0.802825]\n",
      "epoch:28 step:22621[D loss: 0.414066, acc: 60.94%, op_acc: 44.53%] [G loss: 0.867732]\n",
      "epoch:28 step:22622[D loss: 0.406264, acc: 67.97%, op_acc: 42.19%] [G loss: 0.827957]\n",
      "epoch:28 step:22623[D loss: 0.427669, acc: 57.03%, op_acc: 42.97%] [G loss: 0.904696]\n",
      "epoch:28 step:22624[D loss: 0.402099, acc: 60.94%, op_acc: 45.31%] [G loss: 0.941451]\n",
      "epoch:28 step:22625[D loss: 0.424723, acc: 55.47%, op_acc: 40.62%] [G loss: 0.909235]\n",
      "epoch:28 step:22626[D loss: 0.401546, acc: 60.16%, op_acc: 43.75%] [G loss: 0.899328]\n",
      "epoch:28 step:22627[D loss: 0.428316, acc: 58.59%, op_acc: 40.62%] [G loss: 0.898295]\n",
      "epoch:28 step:22628[D loss: 0.437467, acc: 52.34%, op_acc: 39.84%] [G loss: 0.862682]\n",
      "epoch:28 step:22629[D loss: 0.403298, acc: 60.16%, op_acc: 45.31%] [G loss: 0.922671]\n",
      "epoch:28 step:22630[D loss: 0.429438, acc: 57.03%, op_acc: 39.06%] [G loss: 0.866871]\n",
      "epoch:28 step:22631[D loss: 0.435572, acc: 53.12%, op_acc: 46.88%] [G loss: 0.817863]\n",
      "epoch:28 step:22632[D loss: 0.436543, acc: 53.12%, op_acc: 36.72%] [G loss: 0.898931]\n",
      "epoch:28 step:22633[D loss: 0.409883, acc: 63.28%, op_acc: 41.41%] [G loss: 0.933357]\n",
      "epoch:28 step:22634[D loss: 0.448794, acc: 53.91%, op_acc: 36.72%] [G loss: 0.853959]\n",
      "epoch:28 step:22635[D loss: 0.410263, acc: 61.72%, op_acc: 40.62%] [G loss: 0.834913]\n",
      "epoch:28 step:22636[D loss: 0.414359, acc: 61.72%, op_acc: 39.06%] [G loss: 0.921832]\n",
      "epoch:28 step:22637[D loss: 0.386106, acc: 67.19%, op_acc: 43.75%] [G loss: 0.899964]\n",
      "epoch:28 step:22638[D loss: 0.398990, acc: 62.50%, op_acc: 45.31%] [G loss: 0.953214]\n",
      "epoch:28 step:22639[D loss: 0.478855, acc: 52.34%, op_acc: 34.38%] [G loss: 0.872195]\n",
      "epoch:28 step:22640[D loss: 0.446260, acc: 52.34%, op_acc: 41.41%] [G loss: 0.838015]\n",
      "epoch:28 step:22641[D loss: 0.436329, acc: 59.38%, op_acc: 42.97%] [G loss: 0.870187]\n",
      "epoch:28 step:22642[D loss: 0.405615, acc: 57.03%, op_acc: 40.62%] [G loss: 0.881210]\n",
      "epoch:28 step:22643[D loss: 0.400364, acc: 67.19%, op_acc: 41.41%] [G loss: 0.898669]\n",
      "epoch:28 step:22644[D loss: 0.412914, acc: 61.72%, op_acc: 38.28%] [G loss: 0.929580]\n",
      "epoch:28 step:22645[D loss: 0.445506, acc: 48.44%, op_acc: 35.94%] [G loss: 0.918890]\n",
      "epoch:28 step:22646[D loss: 0.410272, acc: 61.72%, op_acc: 46.09%] [G loss: 0.862800]\n",
      "epoch:28 step:22647[D loss: 0.416138, acc: 58.59%, op_acc: 39.06%] [G loss: 0.901557]\n",
      "epoch:28 step:22648[D loss: 0.435503, acc: 57.03%, op_acc: 40.62%] [G loss: 0.867123]\n",
      "epoch:28 step:22649[D loss: 0.442505, acc: 56.25%, op_acc: 38.28%] [G loss: 0.927108]\n",
      "epoch:29 step:22650[D loss: 0.396805, acc: 63.28%, op_acc: 42.97%] [G loss: 0.925370]\n",
      "##############\n",
      "[0.86838056 0.85784663 0.82889441 0.78010883 0.79730826 0.81335795\n",
      " 0.8845751  0.83251361 0.79746696 0.83314296]\n",
      "##########\n",
      "epoch:29 step:22651[D loss: 0.384885, acc: 65.62%, op_acc: 47.66%] [G loss: 0.890907]\n",
      "epoch:29 step:22652[D loss: 0.437987, acc: 50.78%, op_acc: 40.62%] [G loss: 0.855620]\n",
      "epoch:29 step:22653[D loss: 0.429439, acc: 52.34%, op_acc: 41.41%] [G loss: 0.926016]\n",
      "epoch:29 step:22654[D loss: 0.431411, acc: 62.50%, op_acc: 42.19%] [G loss: 0.895361]\n",
      "epoch:29 step:22655[D loss: 0.423452, acc: 53.12%, op_acc: 43.75%] [G loss: 0.907029]\n",
      "epoch:29 step:22656[D loss: 0.378955, acc: 67.19%, op_acc: 43.75%] [G loss: 0.927307]\n",
      "epoch:29 step:22657[D loss: 0.417100, acc: 60.16%, op_acc: 39.84%] [G loss: 0.829563]\n",
      "epoch:29 step:22658[D loss: 0.436703, acc: 50.00%, op_acc: 39.84%] [G loss: 0.898197]\n",
      "epoch:29 step:22659[D loss: 0.429726, acc: 57.81%, op_acc: 35.94%] [G loss: 0.904120]\n",
      "epoch:29 step:22660[D loss: 0.429557, acc: 56.25%, op_acc: 43.75%] [G loss: 0.952559]\n",
      "epoch:29 step:22661[D loss: 0.408894, acc: 62.50%, op_acc: 42.97%] [G loss: 0.888352]\n",
      "epoch:29 step:22662[D loss: 0.416012, acc: 54.69%, op_acc: 41.41%] [G loss: 0.931070]\n",
      "epoch:29 step:22663[D loss: 0.464070, acc: 49.22%, op_acc: 37.50%] [G loss: 0.886607]\n",
      "epoch:29 step:22664[D loss: 0.425728, acc: 53.91%, op_acc: 46.88%] [G loss: 0.828532]\n",
      "epoch:29 step:22665[D loss: 0.447177, acc: 49.22%, op_acc: 40.62%] [G loss: 0.872399]\n",
      "epoch:29 step:22666[D loss: 0.460526, acc: 47.66%, op_acc: 40.62%] [G loss: 0.870845]\n",
      "epoch:29 step:22667[D loss: 0.442051, acc: 52.34%, op_acc: 39.84%] [G loss: 0.800537]\n",
      "epoch:29 step:22668[D loss: 0.431802, acc: 55.47%, op_acc: 40.62%] [G loss: 0.896837]\n",
      "epoch:29 step:22669[D loss: 0.431025, acc: 55.47%, op_acc: 35.94%] [G loss: 0.753733]\n",
      "epoch:29 step:22670[D loss: 0.435550, acc: 60.94%, op_acc: 34.38%] [G loss: 0.896049]\n",
      "epoch:29 step:22671[D loss: 0.406203, acc: 60.94%, op_acc: 42.19%] [G loss: 0.921706]\n",
      "epoch:29 step:22672[D loss: 0.409674, acc: 60.94%, op_acc: 43.75%] [G loss: 0.883629]\n",
      "epoch:29 step:22673[D loss: 0.450946, acc: 52.34%, op_acc: 36.72%] [G loss: 0.796002]\n",
      "epoch:29 step:22674[D loss: 0.455733, acc: 53.12%, op_acc: 35.94%] [G loss: 0.799835]\n",
      "epoch:29 step:22675[D loss: 0.449463, acc: 51.56%, op_acc: 41.41%] [G loss: 0.856768]\n",
      "epoch:29 step:22676[D loss: 0.411461, acc: 61.72%, op_acc: 35.94%] [G loss: 0.913012]\n",
      "epoch:29 step:22677[D loss: 0.414375, acc: 60.94%, op_acc: 39.84%] [G loss: 0.808819]\n",
      "epoch:29 step:22678[D loss: 0.398914, acc: 61.72%, op_acc: 44.53%] [G loss: 0.951271]\n",
      "epoch:29 step:22679[D loss: 0.410582, acc: 60.16%, op_acc: 39.06%] [G loss: 0.912817]\n",
      "epoch:29 step:22680[D loss: 0.453182, acc: 54.69%, op_acc: 37.50%] [G loss: 0.945350]\n",
      "epoch:29 step:22681[D loss: 0.434871, acc: 61.72%, op_acc: 35.16%] [G loss: 0.927443]\n",
      "epoch:29 step:22682[D loss: 0.418135, acc: 57.03%, op_acc: 43.75%] [G loss: 0.901101]\n",
      "epoch:29 step:22683[D loss: 0.418033, acc: 64.06%, op_acc: 37.50%] [G loss: 0.857740]\n",
      "epoch:29 step:22684[D loss: 0.424280, acc: 63.28%, op_acc: 34.38%] [G loss: 0.912809]\n",
      "epoch:29 step:22685[D loss: 0.426463, acc: 57.03%, op_acc: 44.53%] [G loss: 0.815507]\n",
      "epoch:29 step:22686[D loss: 0.371068, acc: 71.09%, op_acc: 48.44%] [G loss: 0.872184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22687[D loss: 0.391030, acc: 64.84%, op_acc: 41.41%] [G loss: 0.837802]\n",
      "epoch:29 step:22688[D loss: 0.417238, acc: 64.06%, op_acc: 46.09%] [G loss: 0.862040]\n",
      "epoch:29 step:22689[D loss: 0.455237, acc: 59.38%, op_acc: 35.94%] [G loss: 0.834649]\n",
      "epoch:29 step:22690[D loss: 0.428202, acc: 50.78%, op_acc: 39.84%] [G loss: 0.914203]\n",
      "epoch:29 step:22691[D loss: 0.379949, acc: 65.62%, op_acc: 45.31%] [G loss: 0.914073]\n",
      "epoch:29 step:22692[D loss: 0.385015, acc: 71.09%, op_acc: 42.97%] [G loss: 0.862016]\n",
      "epoch:29 step:22693[D loss: 0.439470, acc: 50.78%, op_acc: 39.84%] [G loss: 0.836179]\n",
      "epoch:29 step:22694[D loss: 0.419145, acc: 57.81%, op_acc: 42.19%] [G loss: 0.902216]\n",
      "epoch:29 step:22695[D loss: 0.410380, acc: 60.94%, op_acc: 39.84%] [G loss: 0.846782]\n",
      "epoch:29 step:22696[D loss: 0.400183, acc: 71.09%, op_acc: 36.72%] [G loss: 0.925478]\n",
      "epoch:29 step:22697[D loss: 0.465006, acc: 53.12%, op_acc: 32.81%] [G loss: 0.897168]\n",
      "epoch:29 step:22698[D loss: 0.417728, acc: 60.16%, op_acc: 42.97%] [G loss: 0.857577]\n",
      "epoch:29 step:22699[D loss: 0.417774, acc: 60.94%, op_acc: 41.41%] [G loss: 0.907465]\n",
      "epoch:29 step:22700[D loss: 0.409147, acc: 64.84%, op_acc: 37.50%] [G loss: 0.848383]\n",
      "##############\n",
      "[0.86990785 0.86115075 0.78754407 0.79590345 0.79203872 0.84228462\n",
      " 0.88685486 0.82635642 0.7979589  0.80935231]\n",
      "##########\n",
      "epoch:29 step:22701[D loss: 0.390706, acc: 64.84%, op_acc: 42.97%] [G loss: 0.871755]\n",
      "epoch:29 step:22702[D loss: 0.452012, acc: 54.69%, op_acc: 34.38%] [G loss: 0.875004]\n",
      "epoch:29 step:22703[D loss: 0.436881, acc: 57.03%, op_acc: 38.28%] [G loss: 0.836643]\n",
      "epoch:29 step:22704[D loss: 0.387427, acc: 66.41%, op_acc: 45.31%] [G loss: 0.920844]\n",
      "epoch:29 step:22705[D loss: 0.429655, acc: 61.72%, op_acc: 41.41%] [G loss: 0.864030]\n",
      "epoch:29 step:22706[D loss: 0.438295, acc: 55.47%, op_acc: 33.59%] [G loss: 0.788353]\n",
      "epoch:29 step:22707[D loss: 0.415327, acc: 59.38%, op_acc: 42.97%] [G loss: 0.869133]\n",
      "epoch:29 step:22708[D loss: 0.402577, acc: 64.84%, op_acc: 37.50%] [G loss: 0.907672]\n",
      "epoch:29 step:22709[D loss: 0.420325, acc: 57.03%, op_acc: 39.84%] [G loss: 0.860905]\n",
      "epoch:29 step:22710[D loss: 0.432876, acc: 60.16%, op_acc: 39.06%] [G loss: 0.796501]\n",
      "epoch:29 step:22711[D loss: 0.428533, acc: 49.22%, op_acc: 38.28%] [G loss: 0.856525]\n",
      "epoch:29 step:22712[D loss: 0.439513, acc: 59.38%, op_acc: 35.94%] [G loss: 0.869244]\n",
      "epoch:29 step:22713[D loss: 0.416312, acc: 62.50%, op_acc: 39.84%] [G loss: 0.840903]\n",
      "epoch:29 step:22714[D loss: 0.428012, acc: 60.16%, op_acc: 43.75%] [G loss: 0.870856]\n",
      "epoch:29 step:22715[D loss: 0.432089, acc: 56.25%, op_acc: 42.97%] [G loss: 0.835580]\n",
      "epoch:29 step:22716[D loss: 0.409968, acc: 62.50%, op_acc: 41.41%] [G loss: 0.815287]\n",
      "epoch:29 step:22717[D loss: 0.435745, acc: 57.03%, op_acc: 39.84%] [G loss: 0.876508]\n",
      "epoch:29 step:22718[D loss: 0.371391, acc: 63.28%, op_acc: 49.22%] [G loss: 0.887757]\n",
      "epoch:29 step:22719[D loss: 0.406198, acc: 64.06%, op_acc: 40.62%] [G loss: 0.917460]\n",
      "epoch:29 step:22720[D loss: 0.471998, acc: 53.12%, op_acc: 33.59%] [G loss: 0.840655]\n",
      "epoch:29 step:22721[D loss: 0.403864, acc: 63.28%, op_acc: 41.41%] [G loss: 0.826280]\n",
      "epoch:29 step:22722[D loss: 0.394152, acc: 64.06%, op_acc: 39.84%] [G loss: 0.877711]\n",
      "epoch:29 step:22723[D loss: 0.411808, acc: 59.38%, op_acc: 43.75%] [G loss: 0.855088]\n",
      "epoch:29 step:22724[D loss: 0.414826, acc: 63.28%, op_acc: 40.62%] [G loss: 0.882126]\n",
      "epoch:29 step:22725[D loss: 0.468631, acc: 46.09%, op_acc: 39.84%] [G loss: 0.806913]\n",
      "epoch:29 step:22726[D loss: 0.399861, acc: 57.03%, op_acc: 45.31%] [G loss: 0.818550]\n",
      "epoch:29 step:22727[D loss: 0.453644, acc: 61.72%, op_acc: 30.47%] [G loss: 0.781415]\n",
      "epoch:29 step:22728[D loss: 0.400940, acc: 64.84%, op_acc: 42.19%] [G loss: 0.791053]\n",
      "epoch:29 step:22729[D loss: 0.433547, acc: 62.50%, op_acc: 33.59%] [G loss: 0.818857]\n",
      "epoch:29 step:22730[D loss: 0.466539, acc: 55.47%, op_acc: 32.81%] [G loss: 0.855875]\n",
      "epoch:29 step:22731[D loss: 0.390041, acc: 67.97%, op_acc: 39.06%] [G loss: 0.856419]\n",
      "epoch:29 step:22732[D loss: 0.429462, acc: 57.81%, op_acc: 38.28%] [G loss: 0.882406]\n",
      "epoch:29 step:22733[D loss: 0.416014, acc: 57.81%, op_acc: 40.62%] [G loss: 0.854528]\n",
      "epoch:29 step:22734[D loss: 0.424440, acc: 67.19%, op_acc: 37.50%] [G loss: 0.852714]\n",
      "epoch:29 step:22735[D loss: 0.420379, acc: 51.56%, op_acc: 43.75%] [G loss: 0.847941]\n",
      "epoch:29 step:22736[D loss: 0.403148, acc: 68.75%, op_acc: 36.72%] [G loss: 0.914369]\n",
      "epoch:29 step:22737[D loss: 0.425839, acc: 58.59%, op_acc: 36.72%] [G loss: 0.982792]\n",
      "epoch:29 step:22738[D loss: 0.426105, acc: 59.38%, op_acc: 39.06%] [G loss: 0.878784]\n",
      "epoch:29 step:22739[D loss: 0.442431, acc: 53.12%, op_acc: 42.97%] [G loss: 0.869684]\n",
      "epoch:29 step:22740[D loss: 0.421875, acc: 57.03%, op_acc: 41.41%] [G loss: 0.862947]\n",
      "epoch:29 step:22741[D loss: 0.444158, acc: 54.69%, op_acc: 37.50%] [G loss: 0.888952]\n",
      "epoch:29 step:22742[D loss: 0.405078, acc: 61.72%, op_acc: 43.75%] [G loss: 0.839460]\n",
      "epoch:29 step:22743[D loss: 0.405554, acc: 65.62%, op_acc: 40.62%] [G loss: 0.863182]\n",
      "epoch:29 step:22744[D loss: 0.423314, acc: 61.72%, op_acc: 37.50%] [G loss: 0.924869]\n",
      "epoch:29 step:22745[D loss: 0.434343, acc: 59.38%, op_acc: 37.50%] [G loss: 0.906227]\n",
      "epoch:29 step:22746[D loss: 0.451346, acc: 41.41%, op_acc: 41.41%] [G loss: 0.926107]\n",
      "epoch:29 step:22747[D loss: 0.415285, acc: 66.41%, op_acc: 37.50%] [G loss: 0.886597]\n",
      "epoch:29 step:22748[D loss: 0.392412, acc: 65.62%, op_acc: 47.66%] [G loss: 0.838598]\n",
      "epoch:29 step:22749[D loss: 0.378329, acc: 65.62%, op_acc: 45.31%] [G loss: 0.922260]\n",
      "epoch:29 step:22750[D loss: 0.435078, acc: 53.12%, op_acc: 34.38%] [G loss: 0.902971]\n",
      "##############\n",
      "[0.85478467 0.85882306 0.81947286 0.83165923 0.79338401 0.81964175\n",
      " 0.89193176 0.82193158 0.79502626 0.82791113]\n",
      "##########\n",
      "epoch:29 step:22751[D loss: 0.432659, acc: 53.91%, op_acc: 40.62%] [G loss: 0.889122]\n",
      "epoch:29 step:22752[D loss: 0.440134, acc: 51.56%, op_acc: 38.28%] [G loss: 0.921746]\n",
      "epoch:29 step:22753[D loss: 0.441764, acc: 55.47%, op_acc: 39.06%] [G loss: 0.875745]\n",
      "epoch:29 step:22754[D loss: 0.439330, acc: 59.38%, op_acc: 39.84%] [G loss: 0.890881]\n",
      "epoch:29 step:22755[D loss: 0.415766, acc: 60.16%, op_acc: 42.19%] [G loss: 0.824559]\n",
      "epoch:29 step:22756[D loss: 0.389786, acc: 68.75%, op_acc: 43.75%] [G loss: 0.918836]\n",
      "epoch:29 step:22757[D loss: 0.452244, acc: 58.59%, op_acc: 34.38%] [G loss: 0.847069]\n",
      "epoch:29 step:22758[D loss: 0.435255, acc: 57.03%, op_acc: 42.97%] [G loss: 0.915962]\n",
      "epoch:29 step:22759[D loss: 0.389180, acc: 63.28%, op_acc: 44.53%] [G loss: 0.951915]\n",
      "epoch:29 step:22760[D loss: 0.433635, acc: 62.50%, op_acc: 38.28%] [G loss: 0.860924]\n",
      "epoch:29 step:22761[D loss: 0.420475, acc: 58.59%, op_acc: 46.09%] [G loss: 0.787520]\n",
      "epoch:29 step:22762[D loss: 0.430672, acc: 64.06%, op_acc: 35.94%] [G loss: 0.891008]\n",
      "epoch:29 step:22763[D loss: 0.403598, acc: 61.72%, op_acc: 43.75%] [G loss: 0.868791]\n",
      "epoch:29 step:22764[D loss: 0.400883, acc: 63.28%, op_acc: 47.66%] [G loss: 0.894413]\n",
      "epoch:29 step:22765[D loss: 0.426900, acc: 62.50%, op_acc: 35.16%] [G loss: 0.873434]\n",
      "epoch:29 step:22766[D loss: 0.422655, acc: 56.25%, op_acc: 45.31%] [G loss: 0.756198]\n",
      "epoch:29 step:22767[D loss: 0.449044, acc: 49.22%, op_acc: 39.84%] [G loss: 0.788237]\n",
      "epoch:29 step:22768[D loss: 0.459647, acc: 54.69%, op_acc: 34.38%] [G loss: 0.798383]\n",
      "epoch:29 step:22769[D loss: 0.424723, acc: 53.91%, op_acc: 36.72%] [G loss: 0.813142]\n",
      "epoch:29 step:22770[D loss: 0.447046, acc: 57.03%, op_acc: 34.38%] [G loss: 0.852641]\n",
      "epoch:29 step:22771[D loss: 0.421039, acc: 52.34%, op_acc: 36.72%] [G loss: 0.844992]\n",
      "epoch:29 step:22772[D loss: 0.438151, acc: 54.69%, op_acc: 42.19%] [G loss: 0.843860]\n",
      "epoch:29 step:22773[D loss: 0.415708, acc: 64.06%, op_acc: 37.50%] [G loss: 0.846257]\n",
      "epoch:29 step:22774[D loss: 0.465035, acc: 47.66%, op_acc: 36.72%] [G loss: 0.856741]\n",
      "epoch:29 step:22775[D loss: 0.409343, acc: 66.41%, op_acc: 37.50%] [G loss: 0.896540]\n",
      "epoch:29 step:22776[D loss: 0.406521, acc: 56.25%, op_acc: 41.41%] [G loss: 0.838252]\n",
      "epoch:29 step:22777[D loss: 0.432661, acc: 57.81%, op_acc: 40.62%] [G loss: 0.816608]\n",
      "epoch:29 step:22778[D loss: 0.461830, acc: 47.66%, op_acc: 41.41%] [G loss: 0.894610]\n",
      "epoch:29 step:22779[D loss: 0.416323, acc: 57.81%, op_acc: 39.84%] [G loss: 0.875303]\n",
      "epoch:29 step:22780[D loss: 0.416043, acc: 57.81%, op_acc: 40.62%] [G loss: 0.870824]\n",
      "epoch:29 step:22781[D loss: 0.398409, acc: 64.06%, op_acc: 42.19%] [G loss: 0.856601]\n",
      "epoch:29 step:22782[D loss: 0.448586, acc: 58.59%, op_acc: 33.59%] [G loss: 0.874872]\n",
      "epoch:29 step:22783[D loss: 0.437908, acc: 58.59%, op_acc: 34.38%] [G loss: 0.792008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22784[D loss: 0.450541, acc: 50.00%, op_acc: 38.28%] [G loss: 0.819191]\n",
      "epoch:29 step:22785[D loss: 0.398933, acc: 60.16%, op_acc: 40.62%] [G loss: 0.868676]\n",
      "epoch:29 step:22786[D loss: 0.443106, acc: 54.69%, op_acc: 42.19%] [G loss: 0.862200]\n",
      "epoch:29 step:22787[D loss: 0.427545, acc: 51.56%, op_acc: 39.06%] [G loss: 0.939470]\n",
      "epoch:29 step:22788[D loss: 0.404310, acc: 63.28%, op_acc: 43.75%] [G loss: 0.942813]\n",
      "epoch:29 step:22789[D loss: 0.439288, acc: 58.59%, op_acc: 39.06%] [G loss: 0.840227]\n",
      "epoch:29 step:22790[D loss: 0.441058, acc: 58.59%, op_acc: 36.72%] [G loss: 0.923519]\n",
      "epoch:29 step:22791[D loss: 0.427770, acc: 59.38%, op_acc: 37.50%] [G loss: 0.929846]\n",
      "epoch:29 step:22792[D loss: 0.414848, acc: 59.38%, op_acc: 44.53%] [G loss: 0.871558]\n",
      "epoch:29 step:22793[D loss: 0.442561, acc: 51.56%, op_acc: 39.06%] [G loss: 0.842807]\n",
      "epoch:29 step:22794[D loss: 0.412857, acc: 59.38%, op_acc: 40.62%] [G loss: 0.887460]\n",
      "epoch:29 step:22795[D loss: 0.427152, acc: 62.50%, op_acc: 38.28%] [G loss: 0.849087]\n",
      "epoch:29 step:22796[D loss: 0.427061, acc: 63.28%, op_acc: 41.41%] [G loss: 0.890979]\n",
      "epoch:29 step:22797[D loss: 0.442813, acc: 60.94%, op_acc: 32.81%] [G loss: 0.831628]\n",
      "epoch:29 step:22798[D loss: 0.381480, acc: 60.94%, op_acc: 48.44%] [G loss: 0.870095]\n",
      "epoch:29 step:22799[D loss: 0.430585, acc: 61.72%, op_acc: 37.50%] [G loss: 0.868544]\n",
      "epoch:29 step:22800[D loss: 0.411034, acc: 68.75%, op_acc: 43.75%] [G loss: 0.879425]\n",
      "##############\n",
      "[0.86843154 0.85613357 0.80170268 0.81020913 0.77336485 0.82882404\n",
      " 0.87122557 0.82705742 0.79949126 0.81248635]\n",
      "##########\n",
      "epoch:29 step:22801[D loss: 0.401874, acc: 59.38%, op_acc: 39.84%] [G loss: 0.908097]\n",
      "epoch:29 step:22802[D loss: 0.399582, acc: 60.94%, op_acc: 46.88%] [G loss: 0.939030]\n",
      "epoch:29 step:22803[D loss: 0.437435, acc: 57.03%, op_acc: 36.72%] [G loss: 0.849306]\n",
      "epoch:29 step:22804[D loss: 0.465804, acc: 51.56%, op_acc: 36.72%] [G loss: 0.803566]\n",
      "epoch:29 step:22805[D loss: 0.409433, acc: 60.16%, op_acc: 42.19%] [G loss: 0.853036]\n",
      "epoch:29 step:22806[D loss: 0.398100, acc: 67.97%, op_acc: 41.41%] [G loss: 0.903003]\n",
      "epoch:29 step:22807[D loss: 0.395878, acc: 67.19%, op_acc: 44.53%] [G loss: 0.921854]\n",
      "epoch:29 step:22808[D loss: 0.391853, acc: 67.97%, op_acc: 40.62%] [G loss: 0.919360]\n",
      "epoch:29 step:22809[D loss: 0.435955, acc: 57.81%, op_acc: 39.06%] [G loss: 0.881307]\n",
      "epoch:29 step:22810[D loss: 0.438295, acc: 58.59%, op_acc: 37.50%] [G loss: 0.923041]\n",
      "epoch:29 step:22811[D loss: 0.397374, acc: 64.06%, op_acc: 46.09%] [G loss: 0.893943]\n",
      "epoch:29 step:22812[D loss: 0.418321, acc: 60.16%, op_acc: 40.62%] [G loss: 0.856483]\n",
      "epoch:29 step:22813[D loss: 0.432451, acc: 65.62%, op_acc: 34.38%] [G loss: 0.889293]\n",
      "epoch:29 step:22814[D loss: 0.413902, acc: 52.34%, op_acc: 43.75%] [G loss: 0.919098]\n",
      "epoch:29 step:22815[D loss: 0.435172, acc: 61.72%, op_acc: 39.06%] [G loss: 1.028699]\n",
      "epoch:29 step:22816[D loss: 0.428610, acc: 57.81%, op_acc: 41.41%] [G loss: 0.841590]\n",
      "epoch:29 step:22817[D loss: 0.425973, acc: 56.25%, op_acc: 38.28%] [G loss: 0.826647]\n",
      "epoch:29 step:22818[D loss: 0.435609, acc: 54.69%, op_acc: 43.75%] [G loss: 0.879875]\n",
      "epoch:29 step:22819[D loss: 0.466795, acc: 46.88%, op_acc: 40.62%] [G loss: 0.835777]\n",
      "epoch:29 step:22820[D loss: 0.436666, acc: 65.62%, op_acc: 35.16%] [G loss: 0.845089]\n",
      "epoch:29 step:22821[D loss: 0.417011, acc: 51.56%, op_acc: 41.41%] [G loss: 0.829996]\n",
      "epoch:29 step:22822[D loss: 0.426259, acc: 57.81%, op_acc: 32.81%] [G loss: 0.842663]\n",
      "epoch:29 step:22823[D loss: 0.463681, acc: 53.12%, op_acc: 32.81%] [G loss: 0.890815]\n",
      "epoch:29 step:22824[D loss: 0.380124, acc: 68.75%, op_acc: 46.09%] [G loss: 0.877156]\n",
      "epoch:29 step:22825[D loss: 0.436463, acc: 58.59%, op_acc: 36.72%] [G loss: 0.808107]\n",
      "epoch:29 step:22826[D loss: 0.439365, acc: 55.47%, op_acc: 39.06%] [G loss: 0.889515]\n",
      "epoch:29 step:22827[D loss: 0.424109, acc: 59.38%, op_acc: 41.41%] [G loss: 0.900466]\n",
      "epoch:29 step:22828[D loss: 0.410406, acc: 58.59%, op_acc: 41.41%] [G loss: 0.818070]\n",
      "epoch:29 step:22829[D loss: 0.427105, acc: 60.16%, op_acc: 33.59%] [G loss: 0.843897]\n",
      "epoch:29 step:22830[D loss: 0.431203, acc: 54.69%, op_acc: 42.19%] [G loss: 0.855944]\n",
      "epoch:29 step:22831[D loss: 0.403034, acc: 66.41%, op_acc: 42.97%] [G loss: 0.913942]\n",
      "epoch:29 step:22832[D loss: 0.422420, acc: 53.91%, op_acc: 45.31%] [G loss: 0.932661]\n",
      "epoch:29 step:22833[D loss: 0.436065, acc: 53.12%, op_acc: 35.94%] [G loss: 0.880184]\n",
      "epoch:29 step:22834[D loss: 0.402705, acc: 68.75%, op_acc: 41.41%] [G loss: 0.880210]\n",
      "epoch:29 step:22835[D loss: 0.399919, acc: 60.16%, op_acc: 45.31%] [G loss: 0.907155]\n",
      "epoch:29 step:22836[D loss: 0.430567, acc: 55.47%, op_acc: 42.97%] [G loss: 0.971305]\n",
      "epoch:29 step:22837[D loss: 0.432732, acc: 57.03%, op_acc: 39.06%] [G loss: 0.920666]\n",
      "epoch:29 step:22838[D loss: 0.401330, acc: 68.75%, op_acc: 39.84%] [G loss: 0.947007]\n",
      "epoch:29 step:22839[D loss: 0.464944, acc: 50.00%, op_acc: 38.28%] [G loss: 0.897164]\n",
      "epoch:29 step:22840[D loss: 0.406855, acc: 65.62%, op_acc: 46.09%] [G loss: 0.955241]\n",
      "epoch:29 step:22841[D loss: 0.425361, acc: 59.38%, op_acc: 40.62%] [G loss: 0.822298]\n",
      "epoch:29 step:22842[D loss: 0.465014, acc: 48.44%, op_acc: 35.16%] [G loss: 0.852211]\n",
      "epoch:29 step:22843[D loss: 0.425459, acc: 58.59%, op_acc: 42.19%] [G loss: 0.813584]\n",
      "epoch:29 step:22844[D loss: 0.466891, acc: 48.44%, op_acc: 37.50%] [G loss: 0.814549]\n",
      "epoch:29 step:22845[D loss: 0.433677, acc: 57.81%, op_acc: 40.62%] [G loss: 0.826878]\n",
      "epoch:29 step:22846[D loss: 0.429201, acc: 58.59%, op_acc: 41.41%] [G loss: 0.873632]\n",
      "epoch:29 step:22847[D loss: 0.412061, acc: 64.06%, op_acc: 37.50%] [G loss: 0.927979]\n",
      "epoch:29 step:22848[D loss: 0.427766, acc: 61.72%, op_acc: 39.06%] [G loss: 0.881293]\n",
      "epoch:29 step:22849[D loss: 0.421630, acc: 68.75%, op_acc: 42.19%] [G loss: 0.821283]\n",
      "epoch:29 step:22850[D loss: 0.410171, acc: 61.72%, op_acc: 44.53%] [G loss: 0.888207]\n",
      "##############\n",
      "[0.84244644 0.8445211  0.81823406 0.7877478  0.79451217 0.8392954\n",
      " 0.89134165 0.84134468 0.78904612 0.81745306]\n",
      "##########\n",
      "epoch:29 step:22851[D loss: 0.418272, acc: 58.59%, op_acc: 35.94%] [G loss: 0.860842]\n",
      "epoch:29 step:22852[D loss: 0.450123, acc: 59.38%, op_acc: 37.50%] [G loss: 0.867808]\n",
      "epoch:29 step:22853[D loss: 0.436582, acc: 59.38%, op_acc: 38.28%] [G loss: 0.866192]\n",
      "epoch:29 step:22854[D loss: 0.442174, acc: 56.25%, op_acc: 42.19%] [G loss: 0.817305]\n",
      "epoch:29 step:22855[D loss: 0.428406, acc: 54.69%, op_acc: 34.38%] [G loss: 0.877194]\n",
      "epoch:29 step:22856[D loss: 0.370412, acc: 71.88%, op_acc: 41.41%] [G loss: 0.915693]\n",
      "epoch:29 step:22857[D loss: 0.426507, acc: 60.94%, op_acc: 35.16%] [G loss: 0.850869]\n",
      "epoch:29 step:22858[D loss: 0.405848, acc: 61.72%, op_acc: 43.75%] [G loss: 0.869218]\n",
      "epoch:29 step:22859[D loss: 0.423735, acc: 64.06%, op_acc: 36.72%] [G loss: 0.794492]\n",
      "epoch:29 step:22860[D loss: 0.404832, acc: 58.59%, op_acc: 38.28%] [G loss: 0.802036]\n",
      "epoch:29 step:22861[D loss: 0.417971, acc: 59.38%, op_acc: 40.62%] [G loss: 0.946323]\n",
      "epoch:29 step:22862[D loss: 0.418741, acc: 65.62%, op_acc: 36.72%] [G loss: 0.873088]\n",
      "epoch:29 step:22863[D loss: 0.455013, acc: 59.38%, op_acc: 39.84%] [G loss: 0.835572]\n",
      "epoch:29 step:22864[D loss: 0.454489, acc: 57.81%, op_acc: 39.06%] [G loss: 0.873567]\n",
      "epoch:29 step:22865[D loss: 0.422955, acc: 57.81%, op_acc: 39.84%] [G loss: 0.818687]\n",
      "epoch:29 step:22866[D loss: 0.405496, acc: 63.28%, op_acc: 39.84%] [G loss: 0.805741]\n",
      "epoch:29 step:22867[D loss: 0.417005, acc: 61.72%, op_acc: 39.84%] [G loss: 0.927955]\n",
      "epoch:29 step:22868[D loss: 0.408372, acc: 61.72%, op_acc: 45.31%] [G loss: 0.830627]\n",
      "epoch:29 step:22869[D loss: 0.430703, acc: 62.50%, op_acc: 43.75%] [G loss: 0.901825]\n",
      "epoch:29 step:22870[D loss: 0.419623, acc: 66.41%, op_acc: 37.50%] [G loss: 0.851803]\n",
      "epoch:29 step:22871[D loss: 0.407990, acc: 63.28%, op_acc: 38.28%] [G loss: 0.891649]\n",
      "epoch:29 step:22872[D loss: 0.453482, acc: 54.69%, op_acc: 36.72%] [G loss: 0.857260]\n",
      "epoch:29 step:22873[D loss: 0.398132, acc: 69.53%, op_acc: 40.62%] [G loss: 0.936360]\n",
      "epoch:29 step:22874[D loss: 0.420430, acc: 62.50%, op_acc: 36.72%] [G loss: 0.842298]\n",
      "epoch:29 step:22875[D loss: 0.436254, acc: 61.72%, op_acc: 38.28%] [G loss: 0.882539]\n",
      "epoch:29 step:22876[D loss: 0.419288, acc: 55.47%, op_acc: 42.97%] [G loss: 0.930223]\n",
      "epoch:29 step:22877[D loss: 0.424878, acc: 53.12%, op_acc: 35.94%] [G loss: 0.838891]\n",
      "epoch:29 step:22878[D loss: 0.436252, acc: 60.16%, op_acc: 41.41%] [G loss: 0.893424]\n",
      "epoch:29 step:22879[D loss: 0.443385, acc: 62.50%, op_acc: 35.16%] [G loss: 0.860794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22880[D loss: 0.394188, acc: 67.97%, op_acc: 42.97%] [G loss: 0.881372]\n",
      "epoch:29 step:22881[D loss: 0.420925, acc: 60.94%, op_acc: 32.81%] [G loss: 0.899879]\n",
      "epoch:29 step:22882[D loss: 0.410841, acc: 54.69%, op_acc: 42.19%] [G loss: 0.870792]\n",
      "epoch:29 step:22883[D loss: 0.408511, acc: 67.19%, op_acc: 37.50%] [G loss: 0.912617]\n",
      "epoch:29 step:22884[D loss: 0.366226, acc: 69.53%, op_acc: 46.88%] [G loss: 1.019153]\n",
      "epoch:29 step:22885[D loss: 0.412739, acc: 65.62%, op_acc: 43.75%] [G loss: 0.994694]\n",
      "epoch:29 step:22886[D loss: 0.379901, acc: 65.62%, op_acc: 44.53%] [G loss: 0.927052]\n",
      "epoch:29 step:22887[D loss: 0.451243, acc: 50.00%, op_acc: 35.16%] [G loss: 0.891787]\n",
      "epoch:29 step:22888[D loss: 0.422583, acc: 52.34%, op_acc: 38.28%] [G loss: 0.844727]\n",
      "epoch:29 step:22889[D loss: 0.461468, acc: 45.31%, op_acc: 42.97%] [G loss: 0.865992]\n",
      "epoch:29 step:22890[D loss: 0.404090, acc: 65.62%, op_acc: 42.19%] [G loss: 0.924413]\n",
      "epoch:29 step:22891[D loss: 0.382785, acc: 67.97%, op_acc: 44.53%] [G loss: 0.848762]\n",
      "epoch:29 step:22892[D loss: 0.409967, acc: 53.12%, op_acc: 46.09%] [G loss: 0.885872]\n",
      "epoch:29 step:22893[D loss: 0.432473, acc: 52.34%, op_acc: 39.06%] [G loss: 0.895713]\n",
      "epoch:29 step:22894[D loss: 0.444750, acc: 50.78%, op_acc: 36.72%] [G loss: 0.787447]\n",
      "epoch:29 step:22895[D loss: 0.438104, acc: 61.72%, op_acc: 32.03%] [G loss: 0.903177]\n",
      "epoch:29 step:22896[D loss: 0.412797, acc: 57.03%, op_acc: 45.31%] [G loss: 0.896176]\n",
      "epoch:29 step:22897[D loss: 0.423686, acc: 63.28%, op_acc: 38.28%] [G loss: 0.890915]\n",
      "epoch:29 step:22898[D loss: 0.417515, acc: 61.72%, op_acc: 43.75%] [G loss: 0.884572]\n",
      "epoch:29 step:22899[D loss: 0.437484, acc: 53.91%, op_acc: 38.28%] [G loss: 0.840236]\n",
      "epoch:29 step:22900[D loss: 0.413205, acc: 60.16%, op_acc: 41.41%] [G loss: 0.863285]\n",
      "##############\n",
      "[0.86729585 0.86418479 0.82178565 0.80710192 0.77776342 0.82324467\n",
      " 0.86845072 0.84212456 0.80582427 0.82442487]\n",
      "##########\n",
      "epoch:29 step:22901[D loss: 0.403997, acc: 67.19%, op_acc: 40.62%] [G loss: 0.869113]\n",
      "epoch:29 step:22902[D loss: 0.441406, acc: 58.59%, op_acc: 39.06%] [G loss: 0.874334]\n",
      "epoch:29 step:22903[D loss: 0.441335, acc: 47.66%, op_acc: 39.06%] [G loss: 0.823567]\n",
      "epoch:29 step:22904[D loss: 0.432643, acc: 46.88%, op_acc: 42.19%] [G loss: 0.849972]\n",
      "epoch:29 step:22905[D loss: 0.418070, acc: 54.69%, op_acc: 38.28%] [G loss: 0.919109]\n",
      "epoch:29 step:22906[D loss: 0.415543, acc: 64.84%, op_acc: 35.94%] [G loss: 0.900655]\n",
      "epoch:29 step:22907[D loss: 0.407682, acc: 68.75%, op_acc: 40.62%] [G loss: 0.857436]\n",
      "epoch:29 step:22908[D loss: 0.423287, acc: 60.94%, op_acc: 37.50%] [G loss: 0.864229]\n",
      "epoch:29 step:22909[D loss: 0.440113, acc: 58.59%, op_acc: 36.72%] [G loss: 0.854991]\n",
      "epoch:29 step:22910[D loss: 0.399001, acc: 62.50%, op_acc: 41.41%] [G loss: 0.867448]\n",
      "epoch:29 step:22911[D loss: 0.417774, acc: 62.50%, op_acc: 39.06%] [G loss: 0.875697]\n",
      "epoch:29 step:22912[D loss: 0.443403, acc: 57.81%, op_acc: 37.50%] [G loss: 0.899705]\n",
      "epoch:29 step:22913[D loss: 0.428995, acc: 58.59%, op_acc: 41.41%] [G loss: 0.916007]\n",
      "epoch:29 step:22914[D loss: 0.412786, acc: 57.03%, op_acc: 37.50%] [G loss: 0.919740]\n",
      "epoch:29 step:22915[D loss: 0.422761, acc: 57.81%, op_acc: 39.84%] [G loss: 0.913303]\n",
      "epoch:29 step:22916[D loss: 0.426615, acc: 60.16%, op_acc: 39.84%] [G loss: 0.955470]\n",
      "epoch:29 step:22917[D loss: 0.422653, acc: 56.25%, op_acc: 42.97%] [G loss: 0.917124]\n",
      "epoch:29 step:22918[D loss: 0.370775, acc: 70.31%, op_acc: 46.88%] [G loss: 0.969097]\n",
      "epoch:29 step:22919[D loss: 0.435078, acc: 56.25%, op_acc: 38.28%] [G loss: 0.885592]\n",
      "epoch:29 step:22920[D loss: 0.431458, acc: 61.72%, op_acc: 29.69%] [G loss: 0.921588]\n",
      "epoch:29 step:22921[D loss: 0.433040, acc: 57.81%, op_acc: 35.94%] [G loss: 0.879241]\n",
      "epoch:29 step:22922[D loss: 0.402365, acc: 65.62%, op_acc: 40.62%] [G loss: 0.819341]\n",
      "epoch:29 step:22923[D loss: 0.426973, acc: 56.25%, op_acc: 39.84%] [G loss: 0.881991]\n",
      "epoch:29 step:22924[D loss: 0.434403, acc: 53.91%, op_acc: 36.72%] [G loss: 0.912875]\n",
      "epoch:29 step:22925[D loss: 0.444820, acc: 51.56%, op_acc: 40.62%] [G loss: 0.861931]\n",
      "epoch:29 step:22926[D loss: 0.421059, acc: 63.28%, op_acc: 38.28%] [G loss: 0.856510]\n",
      "epoch:29 step:22927[D loss: 0.445832, acc: 49.22%, op_acc: 38.28%] [G loss: 0.856437]\n",
      "epoch:29 step:22928[D loss: 0.441272, acc: 57.03%, op_acc: 40.62%] [G loss: 0.787242]\n",
      "epoch:29 step:22929[D loss: 0.427337, acc: 56.25%, op_acc: 39.84%] [G loss: 0.935129]\n",
      "epoch:29 step:22930[D loss: 0.416644, acc: 59.38%, op_acc: 39.84%] [G loss: 0.873501]\n",
      "epoch:29 step:22931[D loss: 0.428268, acc: 63.28%, op_acc: 37.50%] [G loss: 0.774788]\n",
      "epoch:29 step:22932[D loss: 0.405205, acc: 63.28%, op_acc: 42.97%] [G loss: 0.883561]\n",
      "epoch:29 step:22933[D loss: 0.420006, acc: 58.59%, op_acc: 40.62%] [G loss: 0.865411]\n",
      "epoch:29 step:22934[D loss: 0.431469, acc: 61.72%, op_acc: 34.38%] [G loss: 0.884776]\n",
      "epoch:29 step:22935[D loss: 0.427589, acc: 60.16%, op_acc: 34.38%] [G loss: 0.791658]\n",
      "epoch:29 step:22936[D loss: 0.461900, acc: 50.78%, op_acc: 42.19%] [G loss: 0.889080]\n",
      "epoch:29 step:22937[D loss: 0.401649, acc: 67.97%, op_acc: 36.72%] [G loss: 0.900115]\n",
      "epoch:29 step:22938[D loss: 0.421038, acc: 66.41%, op_acc: 35.94%] [G loss: 0.959505]\n",
      "epoch:29 step:22939[D loss: 0.424961, acc: 57.81%, op_acc: 39.06%] [G loss: 0.808490]\n",
      "epoch:29 step:22940[D loss: 0.417889, acc: 62.50%, op_acc: 39.84%] [G loss: 0.908685]\n",
      "epoch:29 step:22941[D loss: 0.458154, acc: 53.91%, op_acc: 35.16%] [G loss: 0.846321]\n",
      "epoch:29 step:22942[D loss: 0.423452, acc: 59.38%, op_acc: 39.06%] [G loss: 0.856841]\n",
      "epoch:29 step:22943[D loss: 0.432007, acc: 53.12%, op_acc: 37.50%] [G loss: 0.918119]\n",
      "epoch:29 step:22944[D loss: 0.412833, acc: 57.03%, op_acc: 36.72%] [G loss: 0.823830]\n",
      "epoch:29 step:22945[D loss: 0.402379, acc: 58.59%, op_acc: 44.53%] [G loss: 0.887291]\n",
      "epoch:29 step:22946[D loss: 0.449897, acc: 57.03%, op_acc: 30.47%] [G loss: 0.861870]\n",
      "epoch:29 step:22947[D loss: 0.441422, acc: 55.47%, op_acc: 40.62%] [G loss: 0.925727]\n",
      "epoch:29 step:22948[D loss: 0.424826, acc: 58.59%, op_acc: 36.72%] [G loss: 0.917619]\n",
      "epoch:29 step:22949[D loss: 0.445730, acc: 56.25%, op_acc: 37.50%] [G loss: 0.843690]\n",
      "epoch:29 step:22950[D loss: 0.423280, acc: 57.81%, op_acc: 39.84%] [G loss: 0.854666]\n",
      "##############\n",
      "[0.84081732 0.8839845  0.81168618 0.81574823 0.79969244 0.82446642\n",
      " 0.89831441 0.83846194 0.80903918 0.82746157]\n",
      "##########\n",
      "epoch:29 step:22951[D loss: 0.437748, acc: 52.34%, op_acc: 39.06%] [G loss: 0.801857]\n",
      "epoch:29 step:22952[D loss: 0.409164, acc: 62.50%, op_acc: 43.75%] [G loss: 0.924541]\n",
      "epoch:29 step:22953[D loss: 0.396045, acc: 64.06%, op_acc: 41.41%] [G loss: 0.850666]\n",
      "epoch:29 step:22954[D loss: 0.401776, acc: 59.38%, op_acc: 45.31%] [G loss: 0.940687]\n",
      "epoch:29 step:22955[D loss: 0.434211, acc: 59.38%, op_acc: 38.28%] [G loss: 0.902547]\n",
      "epoch:29 step:22956[D loss: 0.398916, acc: 65.62%, op_acc: 39.84%] [G loss: 0.906887]\n",
      "epoch:29 step:22957[D loss: 0.409928, acc: 59.38%, op_acc: 42.19%] [G loss: 0.798595]\n",
      "epoch:29 step:22958[D loss: 0.431760, acc: 56.25%, op_acc: 35.94%] [G loss: 0.858105]\n",
      "epoch:29 step:22959[D loss: 0.438073, acc: 58.59%, op_acc: 39.06%] [G loss: 0.901574]\n",
      "epoch:29 step:22960[D loss: 0.431933, acc: 55.47%, op_acc: 35.94%] [G loss: 0.887168]\n",
      "epoch:29 step:22961[D loss: 0.451600, acc: 57.03%, op_acc: 38.28%] [G loss: 0.870589]\n",
      "epoch:29 step:22962[D loss: 0.417070, acc: 61.72%, op_acc: 42.97%] [G loss: 0.919957]\n",
      "epoch:29 step:22963[D loss: 0.428479, acc: 58.59%, op_acc: 46.09%] [G loss: 0.888399]\n",
      "epoch:29 step:22964[D loss: 0.452150, acc: 45.31%, op_acc: 39.84%] [G loss: 0.905672]\n",
      "epoch:29 step:22965[D loss: 0.420502, acc: 57.81%, op_acc: 43.75%] [G loss: 0.875584]\n",
      "epoch:29 step:22966[D loss: 0.428401, acc: 62.50%, op_acc: 43.75%] [G loss: 0.881820]\n",
      "epoch:29 step:22967[D loss: 0.447462, acc: 56.25%, op_acc: 34.38%] [G loss: 0.839244]\n",
      "epoch:29 step:22968[D loss: 0.416024, acc: 60.94%, op_acc: 39.84%] [G loss: 0.811963]\n",
      "epoch:29 step:22969[D loss: 0.442418, acc: 53.12%, op_acc: 39.84%] [G loss: 0.902085]\n",
      "epoch:29 step:22970[D loss: 0.427751, acc: 57.81%, op_acc: 40.62%] [G loss: 0.911509]\n",
      "epoch:29 step:22971[D loss: 0.435629, acc: 57.03%, op_acc: 43.75%] [G loss: 0.890364]\n",
      "epoch:29 step:22972[D loss: 0.423916, acc: 58.59%, op_acc: 39.84%] [G loss: 0.905148]\n",
      "epoch:29 step:22973[D loss: 0.410108, acc: 64.84%, op_acc: 41.41%] [G loss: 0.853450]\n",
      "epoch:29 step:22974[D loss: 0.435261, acc: 54.69%, op_acc: 42.19%] [G loss: 0.857090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22975[D loss: 0.401154, acc: 64.06%, op_acc: 39.84%] [G loss: 0.925077]\n",
      "epoch:29 step:22976[D loss: 0.413166, acc: 64.06%, op_acc: 40.62%] [G loss: 0.836214]\n",
      "epoch:29 step:22977[D loss: 0.411083, acc: 60.94%, op_acc: 44.53%] [G loss: 0.860003]\n",
      "epoch:29 step:22978[D loss: 0.442253, acc: 54.69%, op_acc: 44.53%] [G loss: 0.840233]\n",
      "epoch:29 step:22979[D loss: 0.425694, acc: 58.59%, op_acc: 42.19%] [G loss: 0.951096]\n",
      "epoch:29 step:22980[D loss: 0.399537, acc: 63.28%, op_acc: 41.41%] [G loss: 0.846637]\n",
      "epoch:29 step:22981[D loss: 0.415560, acc: 64.06%, op_acc: 44.53%] [G loss: 0.868176]\n",
      "epoch:29 step:22982[D loss: 0.431679, acc: 60.16%, op_acc: 38.28%] [G loss: 0.865197]\n",
      "epoch:29 step:22983[D loss: 0.409186, acc: 60.94%, op_acc: 44.53%] [G loss: 0.852030]\n",
      "epoch:29 step:22984[D loss: 0.416045, acc: 61.72%, op_acc: 42.19%] [G loss: 0.867368]\n",
      "epoch:29 step:22985[D loss: 0.460778, acc: 43.75%, op_acc: 38.28%] [G loss: 0.863132]\n",
      "epoch:29 step:22986[D loss: 0.420032, acc: 64.84%, op_acc: 39.06%] [G loss: 0.870373]\n",
      "epoch:29 step:22987[D loss: 0.391783, acc: 64.06%, op_acc: 45.31%] [G loss: 0.920307]\n",
      "epoch:29 step:22988[D loss: 0.420773, acc: 57.81%, op_acc: 38.28%] [G loss: 0.923144]\n",
      "epoch:29 step:22989[D loss: 0.417671, acc: 57.81%, op_acc: 41.41%] [G loss: 0.877453]\n",
      "epoch:29 step:22990[D loss: 0.441457, acc: 57.81%, op_acc: 37.50%] [G loss: 0.856025]\n",
      "epoch:29 step:22991[D loss: 0.433623, acc: 53.12%, op_acc: 41.41%] [G loss: 0.867277]\n",
      "epoch:29 step:22992[D loss: 0.431344, acc: 57.81%, op_acc: 37.50%] [G loss: 0.892447]\n",
      "epoch:29 step:22993[D loss: 0.437773, acc: 51.56%, op_acc: 39.84%] [G loss: 0.884922]\n",
      "epoch:29 step:22994[D loss: 0.399607, acc: 64.06%, op_acc: 42.97%] [G loss: 0.911599]\n",
      "epoch:29 step:22995[D loss: 0.424484, acc: 58.59%, op_acc: 37.50%] [G loss: 0.901067]\n",
      "epoch:29 step:22996[D loss: 0.412688, acc: 57.03%, op_acc: 42.97%] [G loss: 0.869573]\n",
      "epoch:29 step:22997[D loss: 0.430335, acc: 56.25%, op_acc: 37.50%] [G loss: 0.797398]\n",
      "epoch:29 step:22998[D loss: 0.430012, acc: 60.16%, op_acc: 40.62%] [G loss: 0.898367]\n",
      "epoch:29 step:22999[D loss: 0.440752, acc: 63.28%, op_acc: 36.72%] [G loss: 0.887069]\n",
      "epoch:29 step:23000[D loss: 0.435231, acc: 54.69%, op_acc: 40.62%] [G loss: 0.814987]\n",
      "##############\n",
      "[0.85685298 0.8519033  0.81120566 0.80946716 0.77720241 0.82345303\n",
      " 0.87418154 0.83641978 0.7876662  0.84583534]\n",
      "##########\n",
      "epoch:29 step:23001[D loss: 0.448727, acc: 57.81%, op_acc: 32.03%] [G loss: 0.870486]\n",
      "epoch:29 step:23002[D loss: 0.414492, acc: 61.72%, op_acc: 44.53%] [G loss: 0.811243]\n",
      "epoch:29 step:23003[D loss: 0.405622, acc: 62.50%, op_acc: 42.19%] [G loss: 0.968834]\n",
      "epoch:29 step:23004[D loss: 0.438542, acc: 56.25%, op_acc: 42.19%] [G loss: 0.873771]\n",
      "epoch:29 step:23005[D loss: 0.403902, acc: 65.62%, op_acc: 39.06%] [G loss: 0.855135]\n",
      "epoch:29 step:23006[D loss: 0.434286, acc: 60.16%, op_acc: 39.84%] [G loss: 0.855286]\n",
      "epoch:29 step:23007[D loss: 0.451055, acc: 60.94%, op_acc: 35.94%] [G loss: 0.848573]\n",
      "epoch:29 step:23008[D loss: 0.433913, acc: 60.94%, op_acc: 36.72%] [G loss: 0.937662]\n",
      "epoch:29 step:23009[D loss: 0.422602, acc: 61.72%, op_acc: 42.19%] [G loss: 0.947945]\n",
      "epoch:29 step:23010[D loss: 0.423179, acc: 60.16%, op_acc: 41.41%] [G loss: 0.857834]\n",
      "epoch:29 step:23011[D loss: 0.414868, acc: 60.16%, op_acc: 38.28%] [G loss: 0.915400]\n",
      "epoch:29 step:23012[D loss: 0.444833, acc: 53.12%, op_acc: 34.38%] [G loss: 0.865192]\n",
      "epoch:29 step:23013[D loss: 0.459989, acc: 49.22%, op_acc: 41.41%] [G loss: 0.877204]\n",
      "epoch:29 step:23014[D loss: 0.388420, acc: 59.38%, op_acc: 46.09%] [G loss: 0.846017]\n",
      "epoch:29 step:23015[D loss: 0.381162, acc: 67.97%, op_acc: 42.97%] [G loss: 0.835122]\n",
      "epoch:29 step:23016[D loss: 0.419124, acc: 63.28%, op_acc: 39.84%] [G loss: 0.843849]\n",
      "epoch:29 step:23017[D loss: 0.422443, acc: 63.28%, op_acc: 35.94%] [G loss: 0.805050]\n",
      "epoch:29 step:23018[D loss: 0.417663, acc: 60.16%, op_acc: 41.41%] [G loss: 0.852644]\n",
      "epoch:29 step:23019[D loss: 0.451434, acc: 51.56%, op_acc: 42.97%] [G loss: 0.912622]\n",
      "epoch:29 step:23020[D loss: 0.406264, acc: 64.06%, op_acc: 41.41%] [G loss: 0.846843]\n",
      "epoch:29 step:23021[D loss: 0.420030, acc: 54.69%, op_acc: 42.19%] [G loss: 0.875188]\n",
      "epoch:29 step:23022[D loss: 0.420203, acc: 61.72%, op_acc: 39.84%] [G loss: 0.891174]\n",
      "epoch:29 step:23023[D loss: 0.412917, acc: 61.72%, op_acc: 41.41%] [G loss: 0.932957]\n",
      "epoch:29 step:23024[D loss: 0.437675, acc: 58.59%, op_acc: 35.16%] [G loss: 0.903710]\n",
      "epoch:29 step:23025[D loss: 0.424707, acc: 63.28%, op_acc: 37.50%] [G loss: 0.886197]\n",
      "epoch:29 step:23026[D loss: 0.405646, acc: 57.81%, op_acc: 40.62%] [G loss: 0.872068]\n",
      "epoch:29 step:23027[D loss: 0.398529, acc: 68.75%, op_acc: 45.31%] [G loss: 0.907429]\n",
      "epoch:29 step:23028[D loss: 0.407113, acc: 60.94%, op_acc: 41.41%] [G loss: 0.908817]\n",
      "epoch:29 step:23029[D loss: 0.413267, acc: 58.59%, op_acc: 43.75%] [G loss: 0.897379]\n",
      "epoch:29 step:23030[D loss: 0.412672, acc: 67.19%, op_acc: 44.53%] [G loss: 0.782028]\n",
      "epoch:29 step:23031[D loss: 0.443136, acc: 53.12%, op_acc: 35.16%] [G loss: 0.856205]\n",
      "epoch:29 step:23032[D loss: 0.407027, acc: 63.28%, op_acc: 48.44%] [G loss: 0.868151]\n",
      "epoch:29 step:23033[D loss: 0.412507, acc: 60.16%, op_acc: 35.94%] [G loss: 0.878915]\n",
      "epoch:29 step:23034[D loss: 0.376016, acc: 66.41%, op_acc: 46.88%] [G loss: 0.897342]\n",
      "epoch:29 step:23035[D loss: 0.381177, acc: 67.19%, op_acc: 45.31%] [G loss: 0.973174]\n",
      "epoch:29 step:23036[D loss: 0.433556, acc: 62.50%, op_acc: 37.50%] [G loss: 0.873069]\n",
      "epoch:29 step:23037[D loss: 0.422178, acc: 58.59%, op_acc: 40.62%] [G loss: 0.849701]\n",
      "epoch:29 step:23038[D loss: 0.464499, acc: 53.12%, op_acc: 39.06%] [G loss: 0.783816]\n",
      "epoch:29 step:23039[D loss: 0.439252, acc: 56.25%, op_acc: 36.72%] [G loss: 0.833432]\n",
      "epoch:29 step:23040[D loss: 0.423643, acc: 57.81%, op_acc: 43.75%] [G loss: 0.880819]\n",
      "epoch:29 step:23041[D loss: 0.422556, acc: 55.47%, op_acc: 49.22%] [G loss: 0.873834]\n",
      "epoch:29 step:23042[D loss: 0.392749, acc: 67.97%, op_acc: 46.09%] [G loss: 0.871799]\n",
      "epoch:29 step:23043[D loss: 0.415230, acc: 58.59%, op_acc: 40.62%] [G loss: 0.901656]\n",
      "epoch:29 step:23044[D loss: 0.443222, acc: 58.59%, op_acc: 34.38%] [G loss: 0.851254]\n",
      "epoch:29 step:23045[D loss: 0.407845, acc: 61.72%, op_acc: 44.53%] [G loss: 0.865782]\n",
      "epoch:29 step:23046[D loss: 0.391029, acc: 61.72%, op_acc: 46.09%] [G loss: 0.913737]\n",
      "epoch:29 step:23047[D loss: 0.416824, acc: 67.19%, op_acc: 35.16%] [G loss: 0.821520]\n",
      "epoch:29 step:23048[D loss: 0.392939, acc: 67.97%, op_acc: 42.97%] [G loss: 0.884241]\n",
      "epoch:29 step:23049[D loss: 0.430698, acc: 56.25%, op_acc: 42.19%] [G loss: 0.863820]\n",
      "epoch:29 step:23050[D loss: 0.421593, acc: 56.25%, op_acc: 42.19%] [G loss: 0.962163]\n",
      "##############\n",
      "[0.86173516 0.8629376  0.81828871 0.79162573 0.79542777 0.79963272\n",
      " 0.87430192 0.80961311 0.82123561 0.83408435]\n",
      "##########\n",
      "epoch:29 step:23051[D loss: 0.459969, acc: 52.34%, op_acc: 33.59%] [G loss: 0.835593]\n",
      "epoch:29 step:23052[D loss: 0.407399, acc: 60.94%, op_acc: 44.53%] [G loss: 0.885700]\n",
      "epoch:29 step:23053[D loss: 0.388680, acc: 63.28%, op_acc: 49.22%] [G loss: 0.890386]\n",
      "epoch:29 step:23054[D loss: 0.461167, acc: 53.12%, op_acc: 37.50%] [G loss: 0.837887]\n",
      "epoch:29 step:23055[D loss: 0.421114, acc: 63.28%, op_acc: 39.06%] [G loss: 0.853680]\n",
      "epoch:29 step:23056[D loss: 0.422734, acc: 60.94%, op_acc: 34.38%] [G loss: 0.822612]\n",
      "epoch:29 step:23057[D loss: 0.410519, acc: 56.25%, op_acc: 42.97%] [G loss: 0.915300]\n",
      "epoch:29 step:23058[D loss: 0.424490, acc: 57.03%, op_acc: 43.75%] [G loss: 0.904393]\n",
      "epoch:29 step:23059[D loss: 0.391015, acc: 66.41%, op_acc: 42.19%] [G loss: 0.889640]\n",
      "epoch:29 step:23060[D loss: 0.428974, acc: 60.16%, op_acc: 32.03%] [G loss: 0.860142]\n",
      "epoch:29 step:23061[D loss: 0.402196, acc: 63.28%, op_acc: 41.41%] [G loss: 0.838533]\n",
      "epoch:29 step:23062[D loss: 0.421645, acc: 60.94%, op_acc: 38.28%] [G loss: 0.864540]\n",
      "epoch:29 step:23063[D loss: 0.410295, acc: 58.59%, op_acc: 40.62%] [G loss: 0.855088]\n",
      "epoch:29 step:23064[D loss: 0.427718, acc: 55.47%, op_acc: 37.50%] [G loss: 0.937712]\n",
      "epoch:29 step:23065[D loss: 0.396091, acc: 69.53%, op_acc: 40.62%] [G loss: 0.902743]\n",
      "epoch:29 step:23066[D loss: 0.398497, acc: 63.28%, op_acc: 45.31%] [G loss: 0.931295]\n",
      "epoch:29 step:23067[D loss: 0.419157, acc: 61.72%, op_acc: 39.84%] [G loss: 0.861999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23068[D loss: 0.408640, acc: 61.72%, op_acc: 40.62%] [G loss: 0.900227]\n",
      "epoch:29 step:23069[D loss: 0.439114, acc: 54.69%, op_acc: 39.84%] [G loss: 0.915695]\n",
      "epoch:29 step:23070[D loss: 0.410674, acc: 64.06%, op_acc: 38.28%] [G loss: 0.923253]\n",
      "epoch:29 step:23071[D loss: 0.388352, acc: 60.94%, op_acc: 42.97%] [G loss: 0.900244]\n",
      "epoch:29 step:23072[D loss: 0.439080, acc: 60.16%, op_acc: 36.72%] [G loss: 0.849460]\n",
      "epoch:29 step:23073[D loss: 0.437154, acc: 60.16%, op_acc: 35.94%] [G loss: 0.906883]\n",
      "epoch:29 step:23074[D loss: 0.435533, acc: 51.56%, op_acc: 40.62%] [G loss: 0.985124]\n",
      "epoch:29 step:23075[D loss: 0.438591, acc: 54.69%, op_acc: 39.06%] [G loss: 0.827533]\n",
      "epoch:29 step:23076[D loss: 0.448834, acc: 57.81%, op_acc: 35.16%] [G loss: 0.791262]\n",
      "epoch:29 step:23077[D loss: 0.423701, acc: 50.78%, op_acc: 38.28%] [G loss: 0.878882]\n",
      "epoch:29 step:23078[D loss: 0.423713, acc: 55.47%, op_acc: 40.62%] [G loss: 0.880889]\n",
      "epoch:29 step:23079[D loss: 0.390261, acc: 67.97%, op_acc: 39.84%] [G loss: 1.029948]\n",
      "epoch:29 step:23080[D loss: 0.437738, acc: 48.44%, op_acc: 38.28%] [G loss: 0.858702]\n",
      "epoch:29 step:23081[D loss: 0.370079, acc: 67.97%, op_acc: 44.53%] [G loss: 0.811325]\n",
      "epoch:29 step:23082[D loss: 0.409649, acc: 60.16%, op_acc: 43.75%] [G loss: 0.803764]\n",
      "epoch:29 step:23083[D loss: 0.430598, acc: 58.59%, op_acc: 43.75%] [G loss: 0.808422]\n",
      "epoch:29 step:23084[D loss: 0.421137, acc: 58.59%, op_acc: 41.41%] [G loss: 0.873363]\n",
      "epoch:29 step:23085[D loss: 0.451874, acc: 49.22%, op_acc: 38.28%] [G loss: 0.829172]\n",
      "epoch:29 step:23086[D loss: 0.422842, acc: 54.69%, op_acc: 38.28%] [G loss: 0.813818]\n",
      "epoch:29 step:23087[D loss: 0.419114, acc: 60.94%, op_acc: 37.50%] [G loss: 0.854721]\n",
      "epoch:29 step:23088[D loss: 0.397332, acc: 64.84%, op_acc: 42.19%] [G loss: 0.891513]\n",
      "epoch:29 step:23089[D loss: 0.420731, acc: 54.69%, op_acc: 39.84%] [G loss: 0.866671]\n",
      "epoch:29 step:23090[D loss: 0.430005, acc: 61.72%, op_acc: 38.28%] [G loss: 0.839382]\n",
      "epoch:29 step:23091[D loss: 0.434590, acc: 59.38%, op_acc: 41.41%] [G loss: 0.803699]\n",
      "epoch:29 step:23092[D loss: 0.447435, acc: 54.69%, op_acc: 32.03%] [G loss: 0.873163]\n",
      "epoch:29 step:23093[D loss: 0.386492, acc: 66.41%, op_acc: 41.41%] [G loss: 0.921637]\n",
      "epoch:29 step:23094[D loss: 0.421979, acc: 60.16%, op_acc: 40.62%] [G loss: 0.878416]\n",
      "epoch:29 step:23095[D loss: 0.436164, acc: 53.12%, op_acc: 39.84%] [G loss: 0.805648]\n",
      "epoch:29 step:23096[D loss: 0.444954, acc: 63.28%, op_acc: 34.38%] [G loss: 0.852727]\n",
      "epoch:29 step:23097[D loss: 0.416094, acc: 60.16%, op_acc: 40.62%] [G loss: 0.934415]\n",
      "epoch:29 step:23098[D loss: 0.407292, acc: 59.38%, op_acc: 42.19%] [G loss: 0.860227]\n",
      "epoch:29 step:23099[D loss: 0.393739, acc: 68.75%, op_acc: 36.72%] [G loss: 0.896781]\n",
      "epoch:29 step:23100[D loss: 0.415593, acc: 59.38%, op_acc: 36.72%] [G loss: 0.820697]\n",
      "##############\n",
      "[0.86618632 0.8380624  0.81462594 0.79003114 0.78216725 0.85039596\n",
      " 0.87879106 0.83088363 0.81946632 0.82617204]\n",
      "##########\n",
      "epoch:29 step:23101[D loss: 0.401398, acc: 64.84%, op_acc: 39.84%] [G loss: 0.937607]\n",
      "epoch:29 step:23102[D loss: 0.426402, acc: 56.25%, op_acc: 41.41%] [G loss: 0.843818]\n",
      "epoch:29 step:23103[D loss: 0.435976, acc: 57.03%, op_acc: 36.72%] [G loss: 0.867193]\n",
      "epoch:29 step:23104[D loss: 0.439511, acc: 50.78%, op_acc: 35.16%] [G loss: 0.869984]\n",
      "epoch:29 step:23105[D loss: 0.414120, acc: 67.19%, op_acc: 38.28%] [G loss: 0.936312]\n",
      "epoch:29 step:23106[D loss: 0.400086, acc: 66.41%, op_acc: 42.97%] [G loss: 0.921283]\n",
      "epoch:29 step:23107[D loss: 0.410041, acc: 62.50%, op_acc: 43.75%] [G loss: 0.792739]\n",
      "epoch:29 step:23108[D loss: 0.418498, acc: 53.91%, op_acc: 42.97%] [G loss: 0.880615]\n",
      "epoch:29 step:23109[D loss: 0.400643, acc: 60.94%, op_acc: 45.31%] [G loss: 0.902749]\n",
      "epoch:29 step:23110[D loss: 0.436858, acc: 55.47%, op_acc: 41.41%] [G loss: 0.950206]\n",
      "epoch:29 step:23111[D loss: 0.417391, acc: 58.59%, op_acc: 38.28%] [G loss: 0.832639]\n",
      "epoch:29 step:23112[D loss: 0.431105, acc: 57.03%, op_acc: 42.19%] [G loss: 0.872620]\n",
      "epoch:29 step:23113[D loss: 0.444725, acc: 55.47%, op_acc: 33.59%] [G loss: 0.907446]\n",
      "epoch:29 step:23114[D loss: 0.433118, acc: 58.59%, op_acc: 43.75%] [G loss: 0.860381]\n",
      "epoch:29 step:23115[D loss: 0.416418, acc: 64.84%, op_acc: 42.97%] [G loss: 0.806559]\n",
      "epoch:29 step:23116[D loss: 0.413963, acc: 60.16%, op_acc: 39.84%] [G loss: 0.908892]\n",
      "epoch:29 step:23117[D loss: 0.393361, acc: 63.28%, op_acc: 42.97%] [G loss: 0.940537]\n",
      "epoch:29 step:23118[D loss: 0.414527, acc: 61.72%, op_acc: 37.50%] [G loss: 0.888174]\n",
      "epoch:29 step:23119[D loss: 0.409792, acc: 61.72%, op_acc: 43.75%] [G loss: 0.799292]\n",
      "epoch:29 step:23120[D loss: 0.431626, acc: 60.94%, op_acc: 38.28%] [G loss: 0.782550]\n",
      "epoch:29 step:23121[D loss: 0.425527, acc: 61.72%, op_acc: 38.28%] [G loss: 0.834771]\n",
      "epoch:29 step:23122[D loss: 0.395562, acc: 63.28%, op_acc: 44.53%] [G loss: 0.911815]\n",
      "epoch:29 step:23123[D loss: 0.420808, acc: 64.06%, op_acc: 37.50%] [G loss: 0.869004]\n",
      "epoch:29 step:23124[D loss: 0.432711, acc: 57.03%, op_acc: 41.41%] [G loss: 0.898615]\n",
      "epoch:29 step:23125[D loss: 0.427079, acc: 57.03%, op_acc: 40.62%] [G loss: 0.850585]\n",
      "epoch:29 step:23126[D loss: 0.461568, acc: 48.44%, op_acc: 39.06%] [G loss: 0.892713]\n",
      "epoch:29 step:23127[D loss: 0.406821, acc: 58.59%, op_acc: 41.41%] [G loss: 0.921944]\n",
      "epoch:29 step:23128[D loss: 0.402712, acc: 67.19%, op_acc: 41.41%] [G loss: 0.837962]\n",
      "epoch:29 step:23129[D loss: 0.444103, acc: 60.16%, op_acc: 35.16%] [G loss: 0.830229]\n",
      "epoch:29 step:23130[D loss: 0.450277, acc: 57.03%, op_acc: 39.84%] [G loss: 0.828792]\n",
      "epoch:29 step:23131[D loss: 0.421216, acc: 60.94%, op_acc: 38.28%] [G loss: 0.906130]\n",
      "epoch:29 step:23132[D loss: 0.427877, acc: 59.38%, op_acc: 38.28%] [G loss: 0.858318]\n",
      "epoch:29 step:23133[D loss: 0.445704, acc: 47.66%, op_acc: 42.97%] [G loss: 0.821253]\n",
      "epoch:29 step:23134[D loss: 0.436214, acc: 57.81%, op_acc: 34.38%] [G loss: 0.898531]\n",
      "epoch:29 step:23135[D loss: 0.404360, acc: 61.72%, op_acc: 39.84%] [G loss: 0.928533]\n",
      "epoch:29 step:23136[D loss: 0.387252, acc: 69.53%, op_acc: 36.72%] [G loss: 0.946215]\n",
      "epoch:29 step:23137[D loss: 0.441648, acc: 55.47%, op_acc: 39.06%] [G loss: 0.889303]\n",
      "epoch:29 step:23138[D loss: 0.423184, acc: 60.94%, op_acc: 38.28%] [G loss: 0.864765]\n",
      "epoch:29 step:23139[D loss: 0.421272, acc: 57.81%, op_acc: 36.72%] [G loss: 0.914454]\n",
      "epoch:29 step:23140[D loss: 0.439292, acc: 59.38%, op_acc: 38.28%] [G loss: 0.904405]\n",
      "epoch:29 step:23141[D loss: 0.432173, acc: 57.81%, op_acc: 40.62%] [G loss: 0.952901]\n",
      "epoch:29 step:23142[D loss: 0.413360, acc: 60.16%, op_acc: 39.84%] [G loss: 0.893733]\n",
      "epoch:29 step:23143[D loss: 0.404960, acc: 70.31%, op_acc: 42.19%] [G loss: 0.912493]\n",
      "epoch:29 step:23144[D loss: 0.439217, acc: 56.25%, op_acc: 39.06%] [G loss: 0.859316]\n",
      "epoch:29 step:23145[D loss: 0.397297, acc: 65.62%, op_acc: 42.19%] [G loss: 0.909535]\n",
      "epoch:29 step:23146[D loss: 0.422285, acc: 60.16%, op_acc: 38.28%] [G loss: 0.941952]\n",
      "epoch:29 step:23147[D loss: 0.440517, acc: 54.69%, op_acc: 42.97%] [G loss: 0.859662]\n",
      "epoch:29 step:23148[D loss: 0.446670, acc: 60.16%, op_acc: 38.28%] [G loss: 0.932697]\n",
      "epoch:29 step:23149[D loss: 0.430959, acc: 57.03%, op_acc: 39.06%] [G loss: 0.890820]\n",
      "epoch:29 step:23150[D loss: 0.408390, acc: 59.38%, op_acc: 39.84%] [G loss: 0.895091]\n",
      "##############\n",
      "[0.86531362 0.85240594 0.81610247 0.79978787 0.77858216 0.80202066\n",
      " 0.86436666 0.81566767 0.7902619  0.84033625]\n",
      "##########\n",
      "epoch:29 step:23151[D loss: 0.412399, acc: 62.50%, op_acc: 38.28%] [G loss: 0.849677]\n",
      "epoch:29 step:23152[D loss: 0.390960, acc: 66.41%, op_acc: 36.72%] [G loss: 0.933984]\n",
      "epoch:29 step:23153[D loss: 0.425153, acc: 59.38%, op_acc: 34.38%] [G loss: 0.836126]\n",
      "epoch:29 step:23154[D loss: 0.444430, acc: 57.03%, op_acc: 36.72%] [G loss: 0.814441]\n",
      "epoch:29 step:23155[D loss: 0.421766, acc: 55.47%, op_acc: 42.97%] [G loss: 0.734783]\n",
      "epoch:29 step:23156[D loss: 0.407025, acc: 61.72%, op_acc: 42.19%] [G loss: 0.869498]\n",
      "epoch:29 step:23157[D loss: 0.423916, acc: 63.28%, op_acc: 38.28%] [G loss: 0.871418]\n",
      "epoch:29 step:23158[D loss: 0.449207, acc: 57.03%, op_acc: 41.41%] [G loss: 0.819830]\n",
      "epoch:29 step:23159[D loss: 0.411585, acc: 56.25%, op_acc: 39.84%] [G loss: 0.793902]\n",
      "epoch:29 step:23160[D loss: 0.415213, acc: 58.59%, op_acc: 40.62%] [G loss: 0.904651]\n",
      "epoch:29 step:23161[D loss: 0.451380, acc: 55.47%, op_acc: 35.94%] [G loss: 0.885951]\n",
      "epoch:29 step:23162[D loss: 0.485135, acc: 47.66%, op_acc: 30.47%] [G loss: 0.880833]\n",
      "epoch:29 step:23163[D loss: 0.440164, acc: 58.59%, op_acc: 40.62%] [G loss: 0.845531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23164[D loss: 0.439253, acc: 59.38%, op_acc: 33.59%] [G loss: 0.854985]\n",
      "epoch:29 step:23165[D loss: 0.405560, acc: 66.41%, op_acc: 39.84%] [G loss: 0.888848]\n",
      "epoch:29 step:23166[D loss: 0.430079, acc: 59.38%, op_acc: 38.28%] [G loss: 0.921927]\n",
      "epoch:29 step:23167[D loss: 0.407895, acc: 60.16%, op_acc: 40.62%] [G loss: 0.953309]\n",
      "epoch:29 step:23168[D loss: 0.400983, acc: 64.84%, op_acc: 41.41%] [G loss: 0.888739]\n",
      "epoch:29 step:23169[D loss: 0.429099, acc: 54.69%, op_acc: 41.41%] [G loss: 0.993091]\n",
      "epoch:29 step:23170[D loss: 0.439824, acc: 58.59%, op_acc: 39.06%] [G loss: 0.929892]\n",
      "epoch:29 step:23171[D loss: 0.443167, acc: 50.78%, op_acc: 41.41%] [G loss: 0.853160]\n",
      "epoch:29 step:23172[D loss: 0.447932, acc: 53.12%, op_acc: 39.06%] [G loss: 0.889013]\n",
      "epoch:29 step:23173[D loss: 0.436487, acc: 51.56%, op_acc: 39.06%] [G loss: 0.891108]\n",
      "epoch:29 step:23174[D loss: 0.411649, acc: 62.50%, op_acc: 43.75%] [G loss: 0.867110]\n",
      "epoch:29 step:23175[D loss: 0.452719, acc: 57.03%, op_acc: 35.16%] [G loss: 0.910463]\n",
      "epoch:29 step:23176[D loss: 0.428513, acc: 56.25%, op_acc: 39.84%] [G loss: 0.925215]\n",
      "epoch:29 step:23177[D loss: 0.416103, acc: 58.59%, op_acc: 37.50%] [G loss: 0.861624]\n",
      "epoch:29 step:23178[D loss: 0.428867, acc: 56.25%, op_acc: 39.84%] [G loss: 0.873592]\n",
      "epoch:29 step:23179[D loss: 0.418410, acc: 69.53%, op_acc: 35.16%] [G loss: 0.915242]\n",
      "epoch:29 step:23180[D loss: 0.459399, acc: 54.69%, op_acc: 34.38%] [G loss: 0.838840]\n",
      "epoch:29 step:23181[D loss: 0.449277, acc: 52.34%, op_acc: 38.28%] [G loss: 0.904554]\n",
      "epoch:29 step:23182[D loss: 0.417142, acc: 54.69%, op_acc: 39.84%] [G loss: 0.804224]\n",
      "epoch:29 step:23183[D loss: 0.441730, acc: 60.16%, op_acc: 35.16%] [G loss: 0.877357]\n",
      "epoch:29 step:23184[D loss: 0.417768, acc: 59.38%, op_acc: 40.62%] [G loss: 0.836797]\n",
      "epoch:29 step:23185[D loss: 0.392211, acc: 63.28%, op_acc: 45.31%] [G loss: 0.853757]\n",
      "epoch:29 step:23186[D loss: 0.464991, acc: 51.56%, op_acc: 34.38%] [G loss: 0.862911]\n",
      "epoch:29 step:23187[D loss: 0.386688, acc: 67.19%, op_acc: 42.97%] [G loss: 0.885586]\n",
      "epoch:29 step:23188[D loss: 0.428090, acc: 55.47%, op_acc: 42.19%] [G loss: 0.845541]\n",
      "epoch:29 step:23189[D loss: 0.419432, acc: 64.06%, op_acc: 43.75%] [G loss: 0.923561]\n",
      "epoch:29 step:23190[D loss: 0.400592, acc: 64.84%, op_acc: 38.28%] [G loss: 0.894091]\n",
      "epoch:29 step:23191[D loss: 0.415655, acc: 64.06%, op_acc: 40.62%] [G loss: 0.905554]\n",
      "epoch:29 step:23192[D loss: 0.404609, acc: 65.62%, op_acc: 41.41%] [G loss: 0.891669]\n",
      "epoch:29 step:23193[D loss: 0.428336, acc: 61.72%, op_acc: 39.06%] [G loss: 0.907321]\n",
      "epoch:29 step:23194[D loss: 0.401462, acc: 65.62%, op_acc: 41.41%] [G loss: 0.805838]\n",
      "epoch:29 step:23195[D loss: 0.411177, acc: 66.41%, op_acc: 38.28%] [G loss: 0.890269]\n",
      "epoch:29 step:23196[D loss: 0.410826, acc: 60.94%, op_acc: 42.97%] [G loss: 0.877656]\n",
      "epoch:29 step:23197[D loss: 0.436425, acc: 57.81%, op_acc: 42.19%] [G loss: 0.938190]\n",
      "epoch:29 step:23198[D loss: 0.416201, acc: 60.94%, op_acc: 40.62%] [G loss: 0.883642]\n",
      "epoch:29 step:23199[D loss: 0.402297, acc: 62.50%, op_acc: 43.75%] [G loss: 0.960169]\n",
      "epoch:29 step:23200[D loss: 0.405578, acc: 60.16%, op_acc: 45.31%] [G loss: 0.933374]\n",
      "##############\n",
      "[0.85259789 0.85163899 0.82407455 0.79185716 0.79901578 0.80989382\n",
      " 0.88043935 0.8274392  0.79697875 0.83453308]\n",
      "##########\n",
      "epoch:29 step:23201[D loss: 0.456662, acc: 51.56%, op_acc: 39.84%] [G loss: 0.850797]\n",
      "epoch:29 step:23202[D loss: 0.414094, acc: 60.94%, op_acc: 39.06%] [G loss: 0.873318]\n",
      "epoch:29 step:23203[D loss: 0.445174, acc: 59.38%, op_acc: 35.94%] [G loss: 0.893013]\n",
      "epoch:29 step:23204[D loss: 0.412024, acc: 60.16%, op_acc: 38.28%] [G loss: 0.837848]\n",
      "epoch:29 step:23205[D loss: 0.453687, acc: 50.00%, op_acc: 38.28%] [G loss: 0.774752]\n",
      "epoch:29 step:23206[D loss: 0.420949, acc: 60.94%, op_acc: 45.31%] [G loss: 0.820904]\n",
      "epoch:29 step:23207[D loss: 0.427985, acc: 61.72%, op_acc: 36.72%] [G loss: 0.846935]\n",
      "epoch:29 step:23208[D loss: 0.393403, acc: 66.41%, op_acc: 43.75%] [G loss: 0.864551]\n",
      "epoch:29 step:23209[D loss: 0.422378, acc: 63.28%, op_acc: 36.72%] [G loss: 0.855933]\n",
      "epoch:29 step:23210[D loss: 0.417301, acc: 58.59%, op_acc: 42.97%] [G loss: 0.890140]\n",
      "epoch:29 step:23211[D loss: 0.442065, acc: 53.12%, op_acc: 35.16%] [G loss: 0.899936]\n",
      "epoch:29 step:23212[D loss: 0.391841, acc: 67.19%, op_acc: 40.62%] [G loss: 0.879063]\n",
      "epoch:29 step:23213[D loss: 0.403568, acc: 67.19%, op_acc: 41.41%] [G loss: 0.904989]\n",
      "epoch:29 step:23214[D loss: 0.440161, acc: 59.38%, op_acc: 39.06%] [G loss: 0.936421]\n",
      "epoch:29 step:23215[D loss: 0.436677, acc: 54.69%, op_acc: 36.72%] [G loss: 0.878584]\n",
      "epoch:29 step:23216[D loss: 0.412595, acc: 64.84%, op_acc: 41.41%] [G loss: 0.965348]\n",
      "epoch:29 step:23217[D loss: 0.450978, acc: 48.44%, op_acc: 41.41%] [G loss: 0.842082]\n",
      "epoch:29 step:23218[D loss: 0.418100, acc: 59.38%, op_acc: 39.84%] [G loss: 0.894253]\n",
      "epoch:29 step:23219[D loss: 0.428152, acc: 53.12%, op_acc: 42.19%] [G loss: 0.884798]\n",
      "epoch:29 step:23220[D loss: 0.430498, acc: 57.81%, op_acc: 39.06%] [G loss: 0.956233]\n",
      "epoch:29 step:23221[D loss: 0.427401, acc: 55.47%, op_acc: 42.97%] [G loss: 0.857700]\n",
      "epoch:29 step:23222[D loss: 0.456668, acc: 53.91%, op_acc: 40.62%] [G loss: 0.878451]\n",
      "epoch:29 step:23223[D loss: 0.418423, acc: 60.16%, op_acc: 39.06%] [G loss: 0.882686]\n",
      "epoch:29 step:23224[D loss: 0.434232, acc: 58.59%, op_acc: 33.59%] [G loss: 0.854980]\n",
      "epoch:29 step:23225[D loss: 0.406915, acc: 70.31%, op_acc: 41.41%] [G loss: 0.839474]\n",
      "epoch:29 step:23226[D loss: 0.465312, acc: 51.56%, op_acc: 39.84%] [G loss: 0.795873]\n",
      "epoch:29 step:23227[D loss: 0.471618, acc: 51.56%, op_acc: 30.47%] [G loss: 0.823932]\n",
      "epoch:29 step:23228[D loss: 0.388802, acc: 67.19%, op_acc: 42.19%] [G loss: 0.853624]\n",
      "epoch:29 step:23229[D loss: 0.438026, acc: 59.38%, op_acc: 35.94%] [G loss: 0.863997]\n",
      "epoch:29 step:23230[D loss: 0.421219, acc: 59.38%, op_acc: 35.94%] [G loss: 0.886562]\n",
      "epoch:29 step:23231[D loss: 0.404976, acc: 65.62%, op_acc: 36.72%] [G loss: 0.918711]\n",
      "epoch:29 step:23232[D loss: 0.400634, acc: 67.19%, op_acc: 39.06%] [G loss: 0.857188]\n",
      "epoch:29 step:23233[D loss: 0.448842, acc: 59.38%, op_acc: 35.16%] [G loss: 0.830725]\n",
      "epoch:29 step:23234[D loss: 0.399551, acc: 61.72%, op_acc: 42.97%] [G loss: 0.834321]\n",
      "epoch:29 step:23235[D loss: 0.431452, acc: 57.03%, op_acc: 38.28%] [G loss: 0.854199]\n",
      "epoch:29 step:23236[D loss: 0.428989, acc: 57.81%, op_acc: 35.94%] [G loss: 0.889026]\n",
      "epoch:29 step:23237[D loss: 0.408304, acc: 57.81%, op_acc: 39.84%] [G loss: 0.895920]\n",
      "epoch:29 step:23238[D loss: 0.415822, acc: 66.41%, op_acc: 46.09%] [G loss: 0.872488]\n",
      "epoch:29 step:23239[D loss: 0.430908, acc: 56.25%, op_acc: 40.62%] [G loss: 0.830292]\n",
      "epoch:29 step:23240[D loss: 0.422890, acc: 60.16%, op_acc: 36.72%] [G loss: 0.814961]\n",
      "epoch:29 step:23241[D loss: 0.420564, acc: 58.59%, op_acc: 37.50%] [G loss: 0.876583]\n",
      "epoch:29 step:23242[D loss: 0.447337, acc: 57.03%, op_acc: 40.62%] [G loss: 0.846717]\n",
      "epoch:29 step:23243[D loss: 0.421684, acc: 63.28%, op_acc: 39.84%] [G loss: 0.920701]\n",
      "epoch:29 step:23244[D loss: 0.409058, acc: 60.16%, op_acc: 41.41%] [G loss: 0.893083]\n",
      "epoch:29 step:23245[D loss: 0.430951, acc: 57.03%, op_acc: 42.97%] [G loss: 0.913906]\n",
      "epoch:29 step:23246[D loss: 0.426042, acc: 60.94%, op_acc: 42.97%] [G loss: 0.881910]\n",
      "epoch:29 step:23247[D loss: 0.412691, acc: 59.38%, op_acc: 37.50%] [G loss: 0.815874]\n",
      "epoch:29 step:23248[D loss: 0.433430, acc: 57.03%, op_acc: 32.81%] [G loss: 0.800175]\n",
      "epoch:29 step:23249[D loss: 0.424931, acc: 64.84%, op_acc: 33.59%] [G loss: 0.932808]\n",
      "epoch:29 step:23250[D loss: 0.425000, acc: 58.59%, op_acc: 39.84%] [G loss: 0.853302]\n",
      "##############\n",
      "[0.8539648  0.84545487 0.79631062 0.79850132 0.79509242 0.83030749\n",
      " 0.85535657 0.82066487 0.82066391 0.83399978]\n",
      "##########\n",
      "epoch:29 step:23251[D loss: 0.395261, acc: 64.06%, op_acc: 44.53%] [G loss: 0.934356]\n",
      "epoch:29 step:23252[D loss: 0.438961, acc: 52.34%, op_acc: 39.06%] [G loss: 0.877967]\n",
      "epoch:29 step:23253[D loss: 0.454979, acc: 51.56%, op_acc: 32.81%] [G loss: 0.868975]\n",
      "epoch:29 step:23254[D loss: 0.410185, acc: 63.28%, op_acc: 37.50%] [G loss: 0.923600]\n",
      "epoch:29 step:23255[D loss: 0.420822, acc: 56.25%, op_acc: 39.84%] [G loss: 0.849318]\n",
      "epoch:29 step:23256[D loss: 0.428340, acc: 56.25%, op_acc: 42.19%] [G loss: 0.872960]\n",
      "epoch:29 step:23257[D loss: 0.381424, acc: 67.19%, op_acc: 43.75%] [G loss: 0.839472]\n",
      "epoch:29 step:23258[D loss: 0.389899, acc: 59.38%, op_acc: 45.31%] [G loss: 0.852342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23259[D loss: 0.436039, acc: 52.34%, op_acc: 41.41%] [G loss: 0.762739]\n",
      "epoch:29 step:23260[D loss: 0.397092, acc: 63.28%, op_acc: 39.84%] [G loss: 0.858257]\n",
      "epoch:29 step:23261[D loss: 0.417269, acc: 64.84%, op_acc: 39.06%] [G loss: 0.825789]\n",
      "epoch:29 step:23262[D loss: 0.439558, acc: 54.69%, op_acc: 41.41%] [G loss: 0.901098]\n",
      "epoch:29 step:23263[D loss: 0.403709, acc: 58.59%, op_acc: 45.31%] [G loss: 0.908677]\n",
      "epoch:29 step:23264[D loss: 0.406521, acc: 63.28%, op_acc: 46.88%] [G loss: 0.876528]\n",
      "epoch:29 step:23265[D loss: 0.433627, acc: 53.91%, op_acc: 37.50%] [G loss: 0.871706]\n",
      "epoch:29 step:23266[D loss: 0.439474, acc: 56.25%, op_acc: 34.38%] [G loss: 0.776656]\n",
      "epoch:29 step:23267[D loss: 0.416548, acc: 57.81%, op_acc: 42.97%] [G loss: 0.867598]\n",
      "epoch:29 step:23268[D loss: 0.449444, acc: 55.47%, op_acc: 33.59%] [G loss: 0.902463]\n",
      "epoch:29 step:23269[D loss: 0.435765, acc: 52.34%, op_acc: 35.16%] [G loss: 0.863219]\n",
      "epoch:29 step:23270[D loss: 0.405256, acc: 60.16%, op_acc: 41.41%] [G loss: 0.826134]\n",
      "epoch:29 step:23271[D loss: 0.462935, acc: 52.34%, op_acc: 34.38%] [G loss: 0.889143]\n",
      "epoch:29 step:23272[D loss: 0.415512, acc: 62.50%, op_acc: 42.97%] [G loss: 0.853453]\n",
      "epoch:29 step:23273[D loss: 0.428179, acc: 53.91%, op_acc: 40.62%] [G loss: 0.882666]\n",
      "epoch:29 step:23274[D loss: 0.444984, acc: 53.91%, op_acc: 35.94%] [G loss: 0.869263]\n",
      "epoch:29 step:23275[D loss: 0.388623, acc: 60.94%, op_acc: 42.19%] [G loss: 0.848861]\n",
      "epoch:29 step:23276[D loss: 0.414035, acc: 56.25%, op_acc: 42.19%] [G loss: 0.848334]\n",
      "epoch:29 step:23277[D loss: 0.433903, acc: 57.81%, op_acc: 39.84%] [G loss: 0.850884]\n",
      "epoch:29 step:23278[D loss: 0.409972, acc: 64.06%, op_acc: 40.62%] [G loss: 0.847529]\n",
      "epoch:29 step:23279[D loss: 0.411409, acc: 65.62%, op_acc: 37.50%] [G loss: 0.825177]\n",
      "epoch:29 step:23280[D loss: 0.450297, acc: 58.59%, op_acc: 34.38%] [G loss: 0.863730]\n",
      "epoch:29 step:23281[D loss: 0.423737, acc: 58.59%, op_acc: 36.72%] [G loss: 0.850518]\n",
      "epoch:29 step:23282[D loss: 0.420396, acc: 56.25%, op_acc: 42.97%] [G loss: 0.878199]\n",
      "epoch:29 step:23283[D loss: 0.412176, acc: 55.47%, op_acc: 44.53%] [G loss: 0.912555]\n",
      "epoch:29 step:23284[D loss: 0.414630, acc: 60.16%, op_acc: 38.28%] [G loss: 0.903322]\n",
      "epoch:29 step:23285[D loss: 0.419497, acc: 57.03%, op_acc: 40.62%] [G loss: 0.893571]\n",
      "epoch:29 step:23286[D loss: 0.432131, acc: 56.25%, op_acc: 40.62%] [G loss: 0.876252]\n",
      "epoch:29 step:23287[D loss: 0.423582, acc: 64.06%, op_acc: 35.94%] [G loss: 0.906477]\n",
      "epoch:29 step:23288[D loss: 0.467390, acc: 48.44%, op_acc: 39.06%] [G loss: 0.886001]\n",
      "epoch:29 step:23289[D loss: 0.436179, acc: 56.25%, op_acc: 37.50%] [G loss: 0.934351]\n",
      "epoch:29 step:23290[D loss: 0.440083, acc: 55.47%, op_acc: 35.16%] [G loss: 0.851819]\n",
      "epoch:29 step:23291[D loss: 0.430929, acc: 57.03%, op_acc: 41.41%] [G loss: 0.872288]\n",
      "epoch:29 step:23292[D loss: 0.438699, acc: 55.47%, op_acc: 40.62%] [G loss: 0.903634]\n",
      "epoch:29 step:23293[D loss: 0.385474, acc: 61.72%, op_acc: 46.09%] [G loss: 0.898687]\n",
      "epoch:29 step:23294[D loss: 0.398812, acc: 71.09%, op_acc: 42.19%] [G loss: 0.817053]\n",
      "epoch:29 step:23295[D loss: 0.429727, acc: 61.72%, op_acc: 37.50%] [G loss: 0.801191]\n",
      "epoch:29 step:23296[D loss: 0.401034, acc: 64.84%, op_acc: 46.09%] [G loss: 0.869860]\n",
      "epoch:29 step:23297[D loss: 0.432179, acc: 53.12%, op_acc: 42.19%] [G loss: 0.837238]\n",
      "epoch:29 step:23298[D loss: 0.422031, acc: 58.59%, op_acc: 35.16%] [G loss: 0.861572]\n",
      "epoch:29 step:23299[D loss: 0.418225, acc: 70.31%, op_acc: 36.72%] [G loss: 0.946161]\n",
      "epoch:29 step:23300[D loss: 0.381202, acc: 64.84%, op_acc: 45.31%] [G loss: 0.877895]\n",
      "##############\n",
      "[0.86383128 0.85952676 0.80572498 0.79595919 0.82202066 0.8215906\n",
      " 0.86534994 0.83119965 0.81791115 0.82255967]\n",
      "##########\n",
      "epoch:29 step:23301[D loss: 0.411327, acc: 57.81%, op_acc: 36.72%] [G loss: 0.882074]\n",
      "epoch:29 step:23302[D loss: 0.412132, acc: 59.38%, op_acc: 42.97%] [G loss: 0.876528]\n",
      "epoch:29 step:23303[D loss: 0.413872, acc: 57.03%, op_acc: 39.06%] [G loss: 0.923312]\n",
      "epoch:29 step:23304[D loss: 0.443107, acc: 49.22%, op_acc: 46.88%] [G loss: 0.853226]\n",
      "epoch:29 step:23305[D loss: 0.435086, acc: 62.50%, op_acc: 38.28%] [G loss: 0.907227]\n",
      "epoch:29 step:23306[D loss: 0.404759, acc: 67.19%, op_acc: 40.62%] [G loss: 0.837636]\n",
      "epoch:29 step:23307[D loss: 0.437769, acc: 53.91%, op_acc: 35.94%] [G loss: 0.820321]\n",
      "epoch:29 step:23308[D loss: 0.428646, acc: 58.59%, op_acc: 38.28%] [G loss: 0.900259]\n",
      "epoch:29 step:23309[D loss: 0.419890, acc: 59.38%, op_acc: 44.53%] [G loss: 0.872428]\n",
      "epoch:29 step:23310[D loss: 0.408278, acc: 60.16%, op_acc: 39.06%] [G loss: 0.840730]\n",
      "epoch:29 step:23311[D loss: 0.425487, acc: 53.91%, op_acc: 42.19%] [G loss: 0.853948]\n",
      "epoch:29 step:23312[D loss: 0.414911, acc: 60.16%, op_acc: 48.44%] [G loss: 0.812542]\n",
      "epoch:29 step:23313[D loss: 0.437186, acc: 53.12%, op_acc: 42.19%] [G loss: 0.797985]\n",
      "epoch:29 step:23314[D loss: 0.443089, acc: 58.59%, op_acc: 36.72%] [G loss: 0.849728]\n",
      "epoch:29 step:23315[D loss: 0.424607, acc: 61.72%, op_acc: 42.19%] [G loss: 0.920804]\n",
      "epoch:29 step:23316[D loss: 0.408977, acc: 60.94%, op_acc: 39.06%] [G loss: 0.935557]\n",
      "epoch:29 step:23317[D loss: 0.431726, acc: 60.94%, op_acc: 33.59%] [G loss: 0.897425]\n",
      "epoch:29 step:23318[D loss: 0.408738, acc: 60.16%, op_acc: 39.06%] [G loss: 0.916545]\n",
      "epoch:29 step:23319[D loss: 0.430976, acc: 57.81%, op_acc: 42.97%] [G loss: 0.851036]\n",
      "epoch:29 step:23320[D loss: 0.417372, acc: 58.59%, op_acc: 38.28%] [G loss: 0.937303]\n",
      "epoch:29 step:23321[D loss: 0.428151, acc: 54.69%, op_acc: 44.53%] [G loss: 0.857313]\n",
      "epoch:29 step:23322[D loss: 0.460319, acc: 50.78%, op_acc: 34.38%] [G loss: 0.836803]\n",
      "epoch:29 step:23323[D loss: 0.425357, acc: 57.81%, op_acc: 44.53%] [G loss: 0.866260]\n",
      "epoch:29 step:23324[D loss: 0.415539, acc: 60.94%, op_acc: 46.09%] [G loss: 0.906920]\n",
      "epoch:29 step:23325[D loss: 0.446432, acc: 55.47%, op_acc: 37.50%] [G loss: 0.906862]\n",
      "epoch:29 step:23326[D loss: 0.431308, acc: 53.91%, op_acc: 33.59%] [G loss: 0.795436]\n",
      "epoch:29 step:23327[D loss: 0.419738, acc: 57.81%, op_acc: 35.16%] [G loss: 0.818190]\n",
      "epoch:29 step:23328[D loss: 0.430459, acc: 51.56%, op_acc: 42.19%] [G loss: 0.848679]\n",
      "epoch:29 step:23329[D loss: 0.433159, acc: 56.25%, op_acc: 38.28%] [G loss: 0.903283]\n",
      "epoch:29 step:23330[D loss: 0.457880, acc: 56.25%, op_acc: 39.06%] [G loss: 0.939006]\n",
      "epoch:29 step:23331[D loss: 0.436587, acc: 53.12%, op_acc: 40.62%] [G loss: 0.898586]\n",
      "epoch:29 step:23332[D loss: 0.407248, acc: 56.25%, op_acc: 45.31%] [G loss: 0.830004]\n",
      "epoch:29 step:23333[D loss: 0.424274, acc: 62.50%, op_acc: 38.28%] [G loss: 0.916964]\n",
      "epoch:29 step:23334[D loss: 0.425743, acc: 58.59%, op_acc: 40.62%] [G loss: 0.854540]\n",
      "epoch:29 step:23335[D loss: 0.423094, acc: 60.16%, op_acc: 37.50%] [G loss: 0.860964]\n",
      "epoch:29 step:23336[D loss: 0.428208, acc: 60.94%, op_acc: 34.38%] [G loss: 0.836752]\n",
      "epoch:29 step:23337[D loss: 0.414251, acc: 64.06%, op_acc: 37.50%] [G loss: 0.919981]\n",
      "epoch:29 step:23338[D loss: 0.438452, acc: 52.34%, op_acc: 37.50%] [G loss: 0.886141]\n",
      "epoch:29 step:23339[D loss: 0.456460, acc: 56.25%, op_acc: 38.28%] [G loss: 0.891869]\n",
      "epoch:29 step:23340[D loss: 0.407906, acc: 57.81%, op_acc: 41.41%] [G loss: 0.916686]\n",
      "epoch:29 step:23341[D loss: 0.434324, acc: 57.03%, op_acc: 39.06%] [G loss: 0.899389]\n",
      "epoch:29 step:23342[D loss: 0.408797, acc: 64.84%, op_acc: 42.19%] [G loss: 0.807079]\n",
      "epoch:29 step:23343[D loss: 0.442520, acc: 53.12%, op_acc: 36.72%] [G loss: 0.846165]\n",
      "epoch:29 step:23344[D loss: 0.411611, acc: 62.50%, op_acc: 38.28%] [G loss: 0.874629]\n",
      "epoch:29 step:23345[D loss: 0.416308, acc: 60.94%, op_acc: 42.97%] [G loss: 0.909733]\n",
      "epoch:29 step:23346[D loss: 0.406781, acc: 62.50%, op_acc: 44.53%] [G loss: 0.925943]\n",
      "epoch:29 step:23347[D loss: 0.434799, acc: 60.16%, op_acc: 42.97%] [G loss: 0.806831]\n",
      "epoch:29 step:23348[D loss: 0.448387, acc: 47.66%, op_acc: 41.41%] [G loss: 0.820815]\n",
      "epoch:29 step:23349[D loss: 0.436509, acc: 61.72%, op_acc: 39.84%] [G loss: 0.818761]\n",
      "epoch:29 step:23350[D loss: 0.443489, acc: 53.12%, op_acc: 39.06%] [G loss: 0.839676]\n",
      "##############\n",
      "[0.85121643 0.86717469 0.80755129 0.80750723 0.77340467 0.83231866\n",
      " 0.88781793 0.82821495 0.82583959 0.81274634]\n",
      "##########\n",
      "epoch:29 step:23351[D loss: 0.458767, acc: 59.38%, op_acc: 39.06%] [G loss: 0.802695]\n",
      "epoch:29 step:23352[D loss: 0.449528, acc: 48.44%, op_acc: 34.38%] [G loss: 0.930610]\n",
      "epoch:29 step:23353[D loss: 0.411918, acc: 53.12%, op_acc: 41.41%] [G loss: 0.875929]\n",
      "epoch:29 step:23354[D loss: 0.421123, acc: 67.19%, op_acc: 40.62%] [G loss: 0.881374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23355[D loss: 0.432585, acc: 58.59%, op_acc: 36.72%] [G loss: 0.909500]\n",
      "epoch:29 step:23356[D loss: 0.422975, acc: 65.62%, op_acc: 39.84%] [G loss: 0.932600]\n",
      "epoch:29 step:23357[D loss: 0.448472, acc: 52.34%, op_acc: 42.97%] [G loss: 0.868852]\n",
      "epoch:29 step:23358[D loss: 0.410973, acc: 57.81%, op_acc: 40.62%] [G loss: 0.840895]\n",
      "epoch:29 step:23359[D loss: 0.406379, acc: 60.94%, op_acc: 42.19%] [G loss: 0.789897]\n",
      "epoch:29 step:23360[D loss: 0.421205, acc: 61.72%, op_acc: 38.28%] [G loss: 0.867343]\n",
      "epoch:29 step:23361[D loss: 0.414745, acc: 60.94%, op_acc: 41.41%] [G loss: 0.867751]\n",
      "epoch:29 step:23362[D loss: 0.397278, acc: 64.84%, op_acc: 42.19%] [G loss: 0.936247]\n",
      "epoch:29 step:23363[D loss: 0.459915, acc: 51.56%, op_acc: 40.62%] [G loss: 0.802402]\n",
      "epoch:29 step:23364[D loss: 0.417770, acc: 51.56%, op_acc: 43.75%] [G loss: 0.838892]\n",
      "epoch:29 step:23365[D loss: 0.398261, acc: 60.94%, op_acc: 43.75%] [G loss: 0.834407]\n",
      "epoch:29 step:23366[D loss: 0.409510, acc: 60.94%, op_acc: 39.06%] [G loss: 0.846969]\n",
      "epoch:29 step:23367[D loss: 0.396640, acc: 63.28%, op_acc: 44.53%] [G loss: 0.946659]\n",
      "epoch:29 step:23368[D loss: 0.434317, acc: 55.47%, op_acc: 43.75%] [G loss: 0.873141]\n",
      "epoch:29 step:23369[D loss: 0.418779, acc: 64.84%, op_acc: 39.06%] [G loss: 0.858561]\n",
      "epoch:29 step:23370[D loss: 0.415655, acc: 53.12%, op_acc: 46.09%] [G loss: 0.825338]\n",
      "epoch:29 step:23371[D loss: 0.411480, acc: 62.50%, op_acc: 37.50%] [G loss: 0.867896]\n",
      "epoch:29 step:23372[D loss: 0.429379, acc: 61.72%, op_acc: 35.16%] [G loss: 0.840029]\n",
      "epoch:29 step:23373[D loss: 0.438253, acc: 57.03%, op_acc: 42.19%] [G loss: 0.967979]\n",
      "epoch:29 step:23374[D loss: 0.426034, acc: 62.50%, op_acc: 39.84%] [G loss: 0.880929]\n",
      "epoch:29 step:23375[D loss: 0.433440, acc: 52.34%, op_acc: 40.62%] [G loss: 0.831815]\n",
      "epoch:29 step:23376[D loss: 0.452881, acc: 52.34%, op_acc: 31.25%] [G loss: 0.925526]\n",
      "epoch:29 step:23377[D loss: 0.404606, acc: 67.19%, op_acc: 42.19%] [G loss: 0.914939]\n",
      "epoch:29 step:23378[D loss: 0.422935, acc: 63.28%, op_acc: 41.41%] [G loss: 0.813372]\n",
      "epoch:29 step:23379[D loss: 0.431414, acc: 55.47%, op_acc: 37.50%] [G loss: 0.824913]\n",
      "epoch:29 step:23380[D loss: 0.417283, acc: 53.12%, op_acc: 42.19%] [G loss: 0.903743]\n",
      "epoch:29 step:23381[D loss: 0.416066, acc: 59.38%, op_acc: 40.62%] [G loss: 0.886106]\n",
      "epoch:29 step:23382[D loss: 0.414794, acc: 60.94%, op_acc: 36.72%] [G loss: 0.894373]\n",
      "epoch:29 step:23383[D loss: 0.429157, acc: 60.94%, op_acc: 41.41%] [G loss: 0.829642]\n",
      "epoch:29 step:23384[D loss: 0.426804, acc: 55.47%, op_acc: 36.72%] [G loss: 0.846690]\n",
      "epoch:29 step:23385[D loss: 0.444647, acc: 55.47%, op_acc: 43.75%] [G loss: 0.912113]\n",
      "epoch:29 step:23386[D loss: 0.409746, acc: 58.59%, op_acc: 46.09%] [G loss: 0.843657]\n",
      "epoch:29 step:23387[D loss: 0.416983, acc: 60.16%, op_acc: 38.28%] [G loss: 0.828380]\n",
      "epoch:29 step:23388[D loss: 0.394299, acc: 60.16%, op_acc: 46.09%] [G loss: 0.886680]\n",
      "epoch:29 step:23389[D loss: 0.414471, acc: 60.94%, op_acc: 40.62%] [G loss: 0.880691]\n",
      "epoch:29 step:23390[D loss: 0.403215, acc: 60.94%, op_acc: 40.62%] [G loss: 0.848340]\n",
      "epoch:29 step:23391[D loss: 0.414956, acc: 62.50%, op_acc: 39.06%] [G loss: 0.817371]\n",
      "epoch:29 step:23392[D loss: 0.435871, acc: 51.56%, op_acc: 40.62%] [G loss: 0.863272]\n",
      "epoch:29 step:23393[D loss: 0.390775, acc: 64.84%, op_acc: 40.62%] [G loss: 0.834314]\n",
      "epoch:29 step:23394[D loss: 0.426715, acc: 53.12%, op_acc: 42.19%] [G loss: 0.859046]\n",
      "epoch:29 step:23395[D loss: 0.425771, acc: 57.03%, op_acc: 40.62%] [G loss: 0.889619]\n",
      "epoch:29 step:23396[D loss: 0.405706, acc: 64.84%, op_acc: 39.06%] [G loss: 0.885980]\n",
      "epoch:29 step:23397[D loss: 0.435645, acc: 50.78%, op_acc: 34.38%] [G loss: 0.833215]\n",
      "epoch:29 step:23398[D loss: 0.426624, acc: 58.59%, op_acc: 39.84%] [G loss: 0.938831]\n",
      "epoch:29 step:23399[D loss: 0.425275, acc: 51.56%, op_acc: 42.97%] [G loss: 0.901265]\n",
      "epoch:29 step:23400[D loss: 0.452852, acc: 60.16%, op_acc: 38.28%] [G loss: 0.835397]\n",
      "##############\n",
      "[0.8497187  0.86852877 0.82712993 0.82431795 0.7811229  0.8246342\n",
      " 0.88919354 0.8205328  0.79078275 0.82510387]\n",
      "##########\n",
      "epoch:29 step:23401[D loss: 0.424062, acc: 57.81%, op_acc: 41.41%] [G loss: 0.877932]\n",
      "epoch:29 step:23402[D loss: 0.423325, acc: 60.16%, op_acc: 40.62%] [G loss: 0.881800]\n",
      "epoch:29 step:23403[D loss: 0.433763, acc: 56.25%, op_acc: 37.50%] [G loss: 0.865227]\n",
      "epoch:29 step:23404[D loss: 0.433655, acc: 58.59%, op_acc: 37.50%] [G loss: 0.912742]\n",
      "epoch:29 step:23405[D loss: 0.430592, acc: 57.81%, op_acc: 37.50%] [G loss: 0.863189]\n",
      "epoch:29 step:23406[D loss: 0.430333, acc: 53.12%, op_acc: 42.19%] [G loss: 0.870129]\n",
      "epoch:29 step:23407[D loss: 0.393976, acc: 65.62%, op_acc: 42.19%] [G loss: 0.915595]\n",
      "epoch:29 step:23408[D loss: 0.434323, acc: 57.03%, op_acc: 38.28%] [G loss: 0.876121]\n",
      "epoch:29 step:23409[D loss: 0.420488, acc: 53.91%, op_acc: 40.62%] [G loss: 0.801961]\n",
      "epoch:29 step:23410[D loss: 0.378913, acc: 66.41%, op_acc: 42.19%] [G loss: 0.858923]\n",
      "epoch:29 step:23411[D loss: 0.438266, acc: 54.69%, op_acc: 38.28%] [G loss: 0.849930]\n",
      "epoch:29 step:23412[D loss: 0.423049, acc: 53.12%, op_acc: 42.19%] [G loss: 0.810211]\n",
      "epoch:29 step:23413[D loss: 0.418404, acc: 57.03%, op_acc: 44.53%] [G loss: 0.880851]\n",
      "epoch:29 step:23414[D loss: 0.385573, acc: 64.06%, op_acc: 46.88%] [G loss: 0.875105]\n",
      "epoch:29 step:23415[D loss: 0.416115, acc: 60.16%, op_acc: 39.06%] [G loss: 0.840641]\n",
      "epoch:29 step:23416[D loss: 0.400241, acc: 60.94%, op_acc: 44.53%] [G loss: 0.860527]\n",
      "epoch:29 step:23417[D loss: 0.423870, acc: 53.12%, op_acc: 36.72%] [G loss: 0.908633]\n",
      "epoch:29 step:23418[D loss: 0.390429, acc: 64.06%, op_acc: 39.06%] [G loss: 0.847288]\n",
      "epoch:29 step:23419[D loss: 0.423213, acc: 52.34%, op_acc: 47.66%] [G loss: 0.826272]\n",
      "epoch:29 step:23420[D loss: 0.453816, acc: 53.91%, op_acc: 34.38%] [G loss: 0.870775]\n",
      "epoch:29 step:23421[D loss: 0.452835, acc: 53.12%, op_acc: 38.28%] [G loss: 0.895976]\n",
      "epoch:29 step:23422[D loss: 0.394475, acc: 65.62%, op_acc: 41.41%] [G loss: 0.923311]\n",
      "epoch:29 step:23423[D loss: 0.403092, acc: 61.72%, op_acc: 46.09%] [G loss: 0.871615]\n",
      "epoch:29 step:23424[D loss: 0.415419, acc: 60.16%, op_acc: 40.62%] [G loss: 0.984467]\n",
      "epoch:29 step:23425[D loss: 0.425093, acc: 60.94%, op_acc: 42.97%] [G loss: 0.848089]\n",
      "epoch:29 step:23426[D loss: 0.446566, acc: 52.34%, op_acc: 41.41%] [G loss: 0.867369]\n",
      "epoch:29 step:23427[D loss: 0.421960, acc: 51.56%, op_acc: 44.53%] [G loss: 0.928246]\n",
      "epoch:29 step:23428[D loss: 0.423829, acc: 51.56%, op_acc: 40.62%] [G loss: 0.910569]\n",
      "epoch:29 step:23429[D loss: 0.405869, acc: 60.16%, op_acc: 44.53%] [G loss: 0.871537]\n",
      "epoch:29 step:23430[D loss: 0.412002, acc: 53.91%, op_acc: 39.06%] [G loss: 0.876193]\n",
      "epoch:30 step:23431[D loss: 0.399673, acc: 67.97%, op_acc: 42.97%] [G loss: 0.894446]\n",
      "epoch:30 step:23432[D loss: 0.391405, acc: 64.84%, op_acc: 46.09%] [G loss: 0.888575]\n",
      "epoch:30 step:23433[D loss: 0.436263, acc: 54.69%, op_acc: 34.38%] [G loss: 0.849690]\n",
      "epoch:30 step:23434[D loss: 0.406334, acc: 58.59%, op_acc: 50.00%] [G loss: 0.860708]\n",
      "epoch:30 step:23435[D loss: 0.413718, acc: 60.16%, op_acc: 42.19%] [G loss: 0.888375]\n",
      "epoch:30 step:23436[D loss: 0.421952, acc: 60.94%, op_acc: 46.09%] [G loss: 0.891651]\n",
      "epoch:30 step:23437[D loss: 0.392991, acc: 60.16%, op_acc: 45.31%] [G loss: 0.946831]\n",
      "epoch:30 step:23438[D loss: 0.408249, acc: 63.28%, op_acc: 37.50%] [G loss: 0.952101]\n",
      "epoch:30 step:23439[D loss: 0.406521, acc: 62.50%, op_acc: 42.19%] [G loss: 0.892073]\n",
      "epoch:30 step:23440[D loss: 0.397701, acc: 65.62%, op_acc: 39.84%] [G loss: 0.924962]\n",
      "epoch:30 step:23441[D loss: 0.464350, acc: 47.66%, op_acc: 42.97%] [G loss: 0.855086]\n",
      "epoch:30 step:23442[D loss: 0.427203, acc: 58.59%, op_acc: 37.50%] [G loss: 0.842213]\n",
      "epoch:30 step:23443[D loss: 0.415676, acc: 53.91%, op_acc: 42.19%] [G loss: 0.776598]\n",
      "epoch:30 step:23444[D loss: 0.466991, acc: 51.56%, op_acc: 34.38%] [G loss: 0.894662]\n",
      "epoch:30 step:23445[D loss: 0.438442, acc: 61.72%, op_acc: 38.28%] [G loss: 0.858128]\n",
      "epoch:30 step:23446[D loss: 0.414844, acc: 57.03%, op_acc: 43.75%] [G loss: 0.893328]\n",
      "epoch:30 step:23447[D loss: 0.415628, acc: 62.50%, op_acc: 39.84%] [G loss: 0.931154]\n",
      "epoch:30 step:23448[D loss: 0.431610, acc: 58.59%, op_acc: 39.84%] [G loss: 0.838419]\n",
      "epoch:30 step:23449[D loss: 0.402179, acc: 60.16%, op_acc: 42.97%] [G loss: 0.802069]\n",
      "epoch:30 step:23450[D loss: 0.387000, acc: 67.19%, op_acc: 42.19%] [G loss: 0.958642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.86341601 0.85967371 0.82487077 0.79770634 0.80336241 0.82247137\n",
      " 0.88189133 0.82351456 0.81694897 0.81902082]\n",
      "##########\n",
      "epoch:30 step:23451[D loss: 0.461607, acc: 51.56%, op_acc: 35.94%] [G loss: 0.889403]\n",
      "epoch:30 step:23452[D loss: 0.430014, acc: 59.38%, op_acc: 43.75%] [G loss: 0.875435]\n",
      "epoch:30 step:23453[D loss: 0.406669, acc: 63.28%, op_acc: 43.75%] [G loss: 0.850982]\n",
      "epoch:30 step:23454[D loss: 0.412267, acc: 65.62%, op_acc: 34.38%] [G loss: 0.948028]\n",
      "epoch:30 step:23455[D loss: 0.429162, acc: 55.47%, op_acc: 39.84%] [G loss: 0.860577]\n",
      "epoch:30 step:23456[D loss: 0.392107, acc: 65.62%, op_acc: 40.62%] [G loss: 0.925699]\n",
      "epoch:30 step:23457[D loss: 0.401345, acc: 64.84%, op_acc: 39.84%] [G loss: 0.816205]\n",
      "epoch:30 step:23458[D loss: 0.428995, acc: 53.91%, op_acc: 44.53%] [G loss: 0.844208]\n",
      "epoch:30 step:23459[D loss: 0.396630, acc: 61.72%, op_acc: 42.97%] [G loss: 0.794037]\n",
      "epoch:30 step:23460[D loss: 0.416032, acc: 60.16%, op_acc: 45.31%] [G loss: 0.854702]\n",
      "epoch:30 step:23461[D loss: 0.467084, acc: 53.12%, op_acc: 35.94%] [G loss: 0.951990]\n",
      "epoch:30 step:23462[D loss: 0.442640, acc: 57.81%, op_acc: 38.28%] [G loss: 0.948546]\n",
      "epoch:30 step:23463[D loss: 0.419859, acc: 60.16%, op_acc: 42.97%] [G loss: 0.917675]\n",
      "epoch:30 step:23464[D loss: 0.428213, acc: 53.12%, op_acc: 35.16%] [G loss: 0.929353]\n",
      "epoch:30 step:23465[D loss: 0.413603, acc: 58.59%, op_acc: 39.84%] [G loss: 0.917653]\n",
      "epoch:30 step:23466[D loss: 0.411996, acc: 60.94%, op_acc: 42.19%] [G loss: 0.888860]\n",
      "epoch:30 step:23467[D loss: 0.408867, acc: 63.28%, op_acc: 42.19%] [G loss: 0.875439]\n",
      "epoch:30 step:23468[D loss: 0.402407, acc: 67.97%, op_acc: 42.97%] [G loss: 0.880262]\n",
      "epoch:30 step:23469[D loss: 0.408234, acc: 57.03%, op_acc: 40.62%] [G loss: 0.859362]\n",
      "epoch:30 step:23470[D loss: 0.441150, acc: 60.94%, op_acc: 42.19%] [G loss: 0.866552]\n",
      "epoch:30 step:23471[D loss: 0.407001, acc: 60.94%, op_acc: 42.19%] [G loss: 0.902881]\n",
      "epoch:30 step:23472[D loss: 0.389555, acc: 64.06%, op_acc: 42.19%] [G loss: 0.855401]\n",
      "epoch:30 step:23473[D loss: 0.433581, acc: 62.50%, op_acc: 37.50%] [G loss: 0.858999]\n",
      "epoch:30 step:23474[D loss: 0.410943, acc: 61.72%, op_acc: 42.97%] [G loss: 0.845614]\n",
      "epoch:30 step:23475[D loss: 0.385813, acc: 64.06%, op_acc: 41.41%] [G loss: 0.875609]\n",
      "epoch:30 step:23476[D loss: 0.410911, acc: 60.16%, op_acc: 37.50%] [G loss: 0.907967]\n",
      "epoch:30 step:23477[D loss: 0.408701, acc: 71.09%, op_acc: 39.84%] [G loss: 0.927198]\n",
      "epoch:30 step:23478[D loss: 0.424758, acc: 58.59%, op_acc: 42.19%] [G loss: 0.949388]\n",
      "epoch:30 step:23479[D loss: 0.427214, acc: 56.25%, op_acc: 42.19%] [G loss: 0.873728]\n",
      "epoch:30 step:23480[D loss: 0.465827, acc: 48.44%, op_acc: 37.50%] [G loss: 0.840117]\n",
      "epoch:30 step:23481[D loss: 0.396359, acc: 66.41%, op_acc: 36.72%] [G loss: 0.817393]\n",
      "epoch:30 step:23482[D loss: 0.444888, acc: 52.34%, op_acc: 37.50%] [G loss: 0.912832]\n",
      "epoch:30 step:23483[D loss: 0.470364, acc: 48.44%, op_acc: 32.03%] [G loss: 0.898095]\n",
      "epoch:30 step:23484[D loss: 0.431151, acc: 53.91%, op_acc: 42.19%] [G loss: 0.943923]\n",
      "epoch:30 step:23485[D loss: 0.399379, acc: 63.28%, op_acc: 39.84%] [G loss: 0.910537]\n",
      "epoch:30 step:23486[D loss: 0.423141, acc: 57.81%, op_acc: 40.62%] [G loss: 0.885274]\n",
      "epoch:30 step:23487[D loss: 0.437577, acc: 56.25%, op_acc: 37.50%] [G loss: 0.963863]\n",
      "epoch:30 step:23488[D loss: 0.417409, acc: 57.81%, op_acc: 42.97%] [G loss: 0.861174]\n",
      "epoch:30 step:23489[D loss: 0.421315, acc: 57.81%, op_acc: 40.62%] [G loss: 0.836724]\n",
      "epoch:30 step:23490[D loss: 0.412218, acc: 56.25%, op_acc: 41.41%] [G loss: 0.879261]\n",
      "epoch:30 step:23491[D loss: 0.438804, acc: 55.47%, op_acc: 35.16%] [G loss: 0.906712]\n",
      "epoch:30 step:23492[D loss: 0.453411, acc: 54.69%, op_acc: 36.72%] [G loss: 0.789697]\n",
      "epoch:30 step:23493[D loss: 0.452922, acc: 57.81%, op_acc: 40.62%] [G loss: 0.845930]\n",
      "epoch:30 step:23494[D loss: 0.402988, acc: 65.62%, op_acc: 43.75%] [G loss: 0.853162]\n",
      "epoch:30 step:23495[D loss: 0.439701, acc: 57.81%, op_acc: 39.06%] [G loss: 0.882512]\n",
      "epoch:30 step:23496[D loss: 0.404142, acc: 56.25%, op_acc: 45.31%] [G loss: 0.849103]\n",
      "epoch:30 step:23497[D loss: 0.422824, acc: 59.38%, op_acc: 42.19%] [G loss: 0.861913]\n",
      "epoch:30 step:23498[D loss: 0.387646, acc: 65.62%, op_acc: 40.62%] [G loss: 0.876969]\n",
      "epoch:30 step:23499[D loss: 0.381513, acc: 63.28%, op_acc: 44.53%] [G loss: 0.847954]\n",
      "epoch:30 step:23500[D loss: 0.424795, acc: 64.06%, op_acc: 34.38%] [G loss: 0.876271]\n",
      "##############\n",
      "[0.87103692 0.84403928 0.82833253 0.81271706 0.77722595 0.81696057\n",
      " 0.90397376 0.82251032 0.80242446 0.85558494]\n",
      "##########\n",
      "epoch:30 step:23501[D loss: 0.448828, acc: 56.25%, op_acc: 36.72%] [G loss: 0.848203]\n",
      "epoch:30 step:23502[D loss: 0.392881, acc: 66.41%, op_acc: 39.06%] [G loss: 0.887969]\n",
      "epoch:30 step:23503[D loss: 0.414113, acc: 57.03%, op_acc: 39.84%] [G loss: 0.826598]\n",
      "epoch:30 step:23504[D loss: 0.406188, acc: 60.94%, op_acc: 39.06%] [G loss: 0.816849]\n",
      "epoch:30 step:23505[D loss: 0.398443, acc: 62.50%, op_acc: 41.41%] [G loss: 0.909431]\n",
      "epoch:30 step:23506[D loss: 0.432178, acc: 57.81%, op_acc: 42.97%] [G loss: 0.886186]\n",
      "epoch:30 step:23507[D loss: 0.443962, acc: 50.00%, op_acc: 42.19%] [G loss: 0.863073]\n",
      "epoch:30 step:23508[D loss: 0.429458, acc: 63.28%, op_acc: 32.81%] [G loss: 0.883577]\n",
      "epoch:30 step:23509[D loss: 0.425195, acc: 60.16%, op_acc: 41.41%] [G loss: 0.905302]\n",
      "epoch:30 step:23510[D loss: 0.455091, acc: 56.25%, op_acc: 33.59%] [G loss: 0.930848]\n",
      "epoch:30 step:23511[D loss: 0.433313, acc: 60.94%, op_acc: 35.94%] [G loss: 0.816975]\n",
      "epoch:30 step:23512[D loss: 0.403360, acc: 63.28%, op_acc: 42.19%] [G loss: 0.883264]\n",
      "epoch:30 step:23513[D loss: 0.431074, acc: 57.03%, op_acc: 39.84%] [G loss: 0.821318]\n",
      "epoch:30 step:23514[D loss: 0.411577, acc: 57.03%, op_acc: 46.88%] [G loss: 0.849033]\n",
      "epoch:30 step:23515[D loss: 0.480308, acc: 53.91%, op_acc: 30.47%] [G loss: 0.862916]\n",
      "epoch:30 step:23516[D loss: 0.409772, acc: 61.72%, op_acc: 41.41%] [G loss: 0.861276]\n",
      "epoch:30 step:23517[D loss: 0.396786, acc: 65.62%, op_acc: 40.62%] [G loss: 0.929630]\n",
      "epoch:30 step:23518[D loss: 0.419242, acc: 62.50%, op_acc: 34.38%] [G loss: 0.892534]\n",
      "epoch:30 step:23519[D loss: 0.427827, acc: 59.38%, op_acc: 36.72%] [G loss: 0.859663]\n",
      "epoch:30 step:23520[D loss: 0.420247, acc: 56.25%, op_acc: 38.28%] [G loss: 0.819439]\n",
      "epoch:30 step:23521[D loss: 0.424115, acc: 60.16%, op_acc: 39.84%] [G loss: 0.898595]\n",
      "epoch:30 step:23522[D loss: 0.438596, acc: 59.38%, op_acc: 35.16%] [G loss: 0.863173]\n",
      "epoch:30 step:23523[D loss: 0.403580, acc: 59.38%, op_acc: 46.88%] [G loss: 0.868245]\n",
      "epoch:30 step:23524[D loss: 0.414460, acc: 53.91%, op_acc: 41.41%] [G loss: 0.883268]\n",
      "epoch:30 step:23525[D loss: 0.403483, acc: 61.72%, op_acc: 42.19%] [G loss: 0.895350]\n",
      "epoch:30 step:23526[D loss: 0.446577, acc: 51.56%, op_acc: 41.41%] [G loss: 0.908828]\n",
      "epoch:30 step:23527[D loss: 0.427395, acc: 50.78%, op_acc: 42.97%] [G loss: 0.878178]\n",
      "epoch:30 step:23528[D loss: 0.429074, acc: 58.59%, op_acc: 38.28%] [G loss: 0.823846]\n",
      "epoch:30 step:23529[D loss: 0.426887, acc: 57.03%, op_acc: 41.41%] [G loss: 0.958506]\n",
      "epoch:30 step:23530[D loss: 0.397324, acc: 65.62%, op_acc: 41.41%] [G loss: 0.888301]\n",
      "epoch:30 step:23531[D loss: 0.415985, acc: 56.25%, op_acc: 39.06%] [G loss: 0.835732]\n",
      "epoch:30 step:23532[D loss: 0.434504, acc: 60.94%, op_acc: 35.94%] [G loss: 0.888883]\n",
      "epoch:30 step:23533[D loss: 0.407485, acc: 62.50%, op_acc: 38.28%] [G loss: 0.889515]\n",
      "epoch:30 step:23534[D loss: 0.436730, acc: 55.47%, op_acc: 39.06%] [G loss: 0.839861]\n",
      "epoch:30 step:23535[D loss: 0.419661, acc: 63.28%, op_acc: 39.06%] [G loss: 0.854376]\n",
      "epoch:30 step:23536[D loss: 0.418397, acc: 59.38%, op_acc: 39.06%] [G loss: 0.837272]\n",
      "epoch:30 step:23537[D loss: 0.429503, acc: 55.47%, op_acc: 40.62%] [G loss: 0.821851]\n",
      "epoch:30 step:23538[D loss: 0.448637, acc: 52.34%, op_acc: 32.81%] [G loss: 0.877582]\n",
      "epoch:30 step:23539[D loss: 0.401334, acc: 63.28%, op_acc: 44.53%] [G loss: 0.917857]\n",
      "epoch:30 step:23540[D loss: 0.406345, acc: 60.16%, op_acc: 46.88%] [G loss: 0.835239]\n",
      "epoch:30 step:23541[D loss: 0.443378, acc: 60.16%, op_acc: 35.94%] [G loss: 0.839795]\n",
      "epoch:30 step:23542[D loss: 0.417434, acc: 59.38%, op_acc: 41.41%] [G loss: 0.869897]\n",
      "epoch:30 step:23543[D loss: 0.452482, acc: 53.91%, op_acc: 36.72%] [G loss: 0.875892]\n",
      "epoch:30 step:23544[D loss: 0.435243, acc: 44.53%, op_acc: 42.97%] [G loss: 0.872185]\n",
      "epoch:30 step:23545[D loss: 0.417463, acc: 53.12%, op_acc: 41.41%] [G loss: 0.856013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23546[D loss: 0.436008, acc: 53.12%, op_acc: 42.19%] [G loss: 0.830609]\n",
      "epoch:30 step:23547[D loss: 0.425735, acc: 53.12%, op_acc: 41.41%] [G loss: 0.854935]\n",
      "epoch:30 step:23548[D loss: 0.423469, acc: 55.47%, op_acc: 41.41%] [G loss: 0.877499]\n",
      "epoch:30 step:23549[D loss: 0.418854, acc: 64.06%, op_acc: 39.84%] [G loss: 0.876003]\n",
      "epoch:30 step:23550[D loss: 0.404643, acc: 60.94%, op_acc: 43.75%] [G loss: 0.847353]\n",
      "##############\n",
      "[0.86809775 0.8366053  0.81179994 0.8111253  0.80375523 0.81668804\n",
      " 0.85394174 0.8385611  0.83371992 0.84255648]\n",
      "##########\n",
      "epoch:30 step:23551[D loss: 0.404159, acc: 71.09%, op_acc: 39.84%] [G loss: 0.921925]\n",
      "epoch:30 step:23552[D loss: 0.434076, acc: 52.34%, op_acc: 34.38%] [G loss: 0.887898]\n",
      "epoch:30 step:23553[D loss: 0.443699, acc: 57.03%, op_acc: 38.28%] [G loss: 0.832148]\n",
      "epoch:30 step:23554[D loss: 0.422516, acc: 61.72%, op_acc: 39.06%] [G loss: 0.902277]\n",
      "epoch:30 step:23555[D loss: 0.456024, acc: 46.09%, op_acc: 37.50%] [G loss: 0.836714]\n",
      "epoch:30 step:23556[D loss: 0.421367, acc: 60.16%, op_acc: 39.06%] [G loss: 0.877618]\n",
      "epoch:30 step:23557[D loss: 0.406010, acc: 67.19%, op_acc: 37.50%] [G loss: 0.852918]\n",
      "epoch:30 step:23558[D loss: 0.432647, acc: 60.94%, op_acc: 40.62%] [G loss: 0.917044]\n",
      "epoch:30 step:23559[D loss: 0.458902, acc: 55.47%, op_acc: 37.50%] [G loss: 0.829097]\n",
      "epoch:30 step:23560[D loss: 0.402383, acc: 61.72%, op_acc: 42.19%] [G loss: 0.866744]\n",
      "epoch:30 step:23561[D loss: 0.411102, acc: 59.38%, op_acc: 43.75%] [G loss: 0.815555]\n",
      "epoch:30 step:23562[D loss: 0.402549, acc: 58.59%, op_acc: 45.31%] [G loss: 0.891396]\n",
      "epoch:30 step:23563[D loss: 0.450070, acc: 59.38%, op_acc: 35.94%] [G loss: 0.886269]\n",
      "epoch:30 step:23564[D loss: 0.438355, acc: 50.78%, op_acc: 38.28%] [G loss: 0.824844]\n",
      "epoch:30 step:23565[D loss: 0.464038, acc: 50.00%, op_acc: 39.84%] [G loss: 0.808782]\n",
      "epoch:30 step:23566[D loss: 0.398968, acc: 65.62%, op_acc: 36.72%] [G loss: 0.933289]\n",
      "epoch:30 step:23567[D loss: 0.435979, acc: 58.59%, op_acc: 35.94%] [G loss: 0.858777]\n",
      "epoch:30 step:23568[D loss: 0.425093, acc: 59.38%, op_acc: 36.72%] [G loss: 0.956003]\n",
      "epoch:30 step:23569[D loss: 0.428357, acc: 57.81%, op_acc: 41.41%] [G loss: 0.826365]\n",
      "epoch:30 step:23570[D loss: 0.465736, acc: 53.12%, op_acc: 37.50%] [G loss: 0.891963]\n",
      "epoch:30 step:23571[D loss: 0.415205, acc: 62.50%, op_acc: 37.50%] [G loss: 0.912303]\n",
      "epoch:30 step:23572[D loss: 0.461116, acc: 51.56%, op_acc: 38.28%] [G loss: 0.804217]\n",
      "epoch:30 step:23573[D loss: 0.420353, acc: 55.47%, op_acc: 35.16%] [G loss: 0.880217]\n",
      "epoch:30 step:23574[D loss: 0.441919, acc: 50.00%, op_acc: 40.62%] [G loss: 0.908895]\n",
      "epoch:30 step:23575[D loss: 0.443778, acc: 50.78%, op_acc: 42.97%] [G loss: 0.820111]\n",
      "epoch:30 step:23576[D loss: 0.405353, acc: 57.03%, op_acc: 41.41%] [G loss: 0.935827]\n",
      "epoch:30 step:23577[D loss: 0.403787, acc: 66.41%, op_acc: 44.53%] [G loss: 0.833247]\n",
      "epoch:30 step:23578[D loss: 0.462464, acc: 58.59%, op_acc: 32.81%] [G loss: 0.878203]\n",
      "epoch:30 step:23579[D loss: 0.409667, acc: 55.47%, op_acc: 42.97%] [G loss: 0.905717]\n",
      "epoch:30 step:23580[D loss: 0.408883, acc: 57.81%, op_acc: 44.53%] [G loss: 0.926322]\n",
      "epoch:30 step:23581[D loss: 0.415157, acc: 60.16%, op_acc: 46.09%] [G loss: 0.810939]\n",
      "epoch:30 step:23582[D loss: 0.400867, acc: 61.72%, op_acc: 44.53%] [G loss: 0.932748]\n",
      "epoch:30 step:23583[D loss: 0.427503, acc: 58.59%, op_acc: 35.16%] [G loss: 0.897593]\n",
      "epoch:30 step:23584[D loss: 0.407816, acc: 59.38%, op_acc: 37.50%] [G loss: 0.879697]\n",
      "epoch:30 step:23585[D loss: 0.418724, acc: 59.38%, op_acc: 41.41%] [G loss: 0.836691]\n",
      "epoch:30 step:23586[D loss: 0.422444, acc: 62.50%, op_acc: 41.41%] [G loss: 0.852896]\n",
      "epoch:30 step:23587[D loss: 0.396383, acc: 67.19%, op_acc: 45.31%] [G loss: 0.898938]\n",
      "epoch:30 step:23588[D loss: 0.421381, acc: 57.81%, op_acc: 44.53%] [G loss: 0.788507]\n",
      "epoch:30 step:23589[D loss: 0.439852, acc: 54.69%, op_acc: 41.41%] [G loss: 0.881146]\n",
      "epoch:30 step:23590[D loss: 0.442317, acc: 51.56%, op_acc: 42.19%] [G loss: 0.829734]\n",
      "epoch:30 step:23591[D loss: 0.418587, acc: 60.16%, op_acc: 42.97%] [G loss: 0.911029]\n",
      "epoch:30 step:23592[D loss: 0.410226, acc: 60.16%, op_acc: 42.97%] [G loss: 0.922949]\n",
      "epoch:30 step:23593[D loss: 0.406409, acc: 64.84%, op_acc: 42.19%] [G loss: 0.880015]\n",
      "epoch:30 step:23594[D loss: 0.409530, acc: 69.53%, op_acc: 35.16%] [G loss: 0.835566]\n",
      "epoch:30 step:23595[D loss: 0.395553, acc: 62.50%, op_acc: 42.19%] [G loss: 0.854347]\n",
      "epoch:30 step:23596[D loss: 0.419006, acc: 63.28%, op_acc: 39.06%] [G loss: 0.832096]\n",
      "epoch:30 step:23597[D loss: 0.425321, acc: 59.38%, op_acc: 41.41%] [G loss: 0.847682]\n",
      "epoch:30 step:23598[D loss: 0.391951, acc: 63.28%, op_acc: 46.88%] [G loss: 0.932481]\n",
      "epoch:30 step:23599[D loss: 0.411744, acc: 60.16%, op_acc: 45.31%] [G loss: 0.828884]\n",
      "epoch:30 step:23600[D loss: 0.424223, acc: 60.16%, op_acc: 41.41%] [G loss: 0.815801]\n",
      "##############\n",
      "[0.84869485 0.85240794 0.82322778 0.80374199 0.81207918 0.79711211\n",
      " 0.87448708 0.83486476 0.79235976 0.83072928]\n",
      "##########\n",
      "epoch:30 step:23601[D loss: 0.432549, acc: 60.16%, op_acc: 34.38%] [G loss: 0.889387]\n",
      "epoch:30 step:23602[D loss: 0.395431, acc: 66.41%, op_acc: 42.19%] [G loss: 0.849519]\n",
      "epoch:30 step:23603[D loss: 0.412197, acc: 63.28%, op_acc: 39.84%] [G loss: 0.879587]\n",
      "epoch:30 step:23604[D loss: 0.462076, acc: 50.78%, op_acc: 36.72%] [G loss: 0.920078]\n",
      "epoch:30 step:23605[D loss: 0.404367, acc: 59.38%, op_acc: 38.28%] [G loss: 0.877338]\n",
      "epoch:30 step:23606[D loss: 0.419971, acc: 59.38%, op_acc: 41.41%] [G loss: 0.890691]\n",
      "epoch:30 step:23607[D loss: 0.427169, acc: 58.59%, op_acc: 37.50%] [G loss: 0.843437]\n",
      "epoch:30 step:23608[D loss: 0.450266, acc: 56.25%, op_acc: 35.94%] [G loss: 0.800124]\n",
      "epoch:30 step:23609[D loss: 0.399921, acc: 58.59%, op_acc: 39.84%] [G loss: 0.935454]\n",
      "epoch:30 step:23610[D loss: 0.418552, acc: 63.28%, op_acc: 40.62%] [G loss: 0.875604]\n",
      "epoch:30 step:23611[D loss: 0.410759, acc: 60.94%, op_acc: 39.84%] [G loss: 0.973097]\n",
      "epoch:30 step:23612[D loss: 0.419777, acc: 55.47%, op_acc: 45.31%] [G loss: 0.986261]\n",
      "epoch:30 step:23613[D loss: 0.392119, acc: 68.75%, op_acc: 41.41%] [G loss: 0.899066]\n",
      "epoch:30 step:23614[D loss: 0.416648, acc: 59.38%, op_acc: 39.06%] [G loss: 0.883280]\n",
      "epoch:30 step:23615[D loss: 0.424696, acc: 66.41%, op_acc: 36.72%] [G loss: 0.885671]\n",
      "epoch:30 step:23616[D loss: 0.430580, acc: 56.25%, op_acc: 42.97%] [G loss: 0.905890]\n",
      "epoch:30 step:23617[D loss: 0.421585, acc: 60.16%, op_acc: 38.28%] [G loss: 0.916430]\n",
      "epoch:30 step:23618[D loss: 0.404592, acc: 61.72%, op_acc: 41.41%] [G loss: 0.839633]\n",
      "epoch:30 step:23619[D loss: 0.434210, acc: 60.94%, op_acc: 35.16%] [G loss: 0.861325]\n",
      "epoch:30 step:23620[D loss: 0.425757, acc: 56.25%, op_acc: 41.41%] [G loss: 0.830958]\n",
      "epoch:30 step:23621[D loss: 0.401549, acc: 64.06%, op_acc: 39.84%] [G loss: 0.916060]\n",
      "epoch:30 step:23622[D loss: 0.435409, acc: 53.12%, op_acc: 36.72%] [G loss: 0.879901]\n",
      "epoch:30 step:23623[D loss: 0.456945, acc: 53.12%, op_acc: 30.47%] [G loss: 0.846996]\n",
      "epoch:30 step:23624[D loss: 0.432572, acc: 57.81%, op_acc: 40.62%] [G loss: 0.831753]\n",
      "epoch:30 step:23625[D loss: 0.420896, acc: 59.38%, op_acc: 38.28%] [G loss: 0.898818]\n",
      "epoch:30 step:23626[D loss: 0.416247, acc: 60.16%, op_acc: 39.06%] [G loss: 0.798267]\n",
      "epoch:30 step:23627[D loss: 0.427951, acc: 55.47%, op_acc: 34.38%] [G loss: 0.871799]\n",
      "epoch:30 step:23628[D loss: 0.421018, acc: 59.38%, op_acc: 39.84%] [G loss: 0.892675]\n",
      "epoch:30 step:23629[D loss: 0.433662, acc: 52.34%, op_acc: 40.62%] [G loss: 0.903293]\n",
      "epoch:30 step:23630[D loss: 0.414026, acc: 57.81%, op_acc: 39.06%] [G loss: 0.883776]\n",
      "epoch:30 step:23631[D loss: 0.389529, acc: 60.16%, op_acc: 45.31%] [G loss: 0.913166]\n",
      "epoch:30 step:23632[D loss: 0.459745, acc: 49.22%, op_acc: 36.72%] [G loss: 0.797072]\n",
      "epoch:30 step:23633[D loss: 0.436451, acc: 60.94%, op_acc: 39.06%] [G loss: 0.897854]\n",
      "epoch:30 step:23634[D loss: 0.403543, acc: 62.50%, op_acc: 44.53%] [G loss: 0.843300]\n",
      "epoch:30 step:23635[D loss: 0.433236, acc: 60.16%, op_acc: 37.50%] [G loss: 0.841525]\n",
      "epoch:30 step:23636[D loss: 0.422960, acc: 57.03%, op_acc: 39.06%] [G loss: 0.891165]\n",
      "epoch:30 step:23637[D loss: 0.399542, acc: 65.62%, op_acc: 42.19%] [G loss: 0.898734]\n",
      "epoch:30 step:23638[D loss: 0.412092, acc: 60.16%, op_acc: 42.19%] [G loss: 0.990608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23639[D loss: 0.413530, acc: 56.25%, op_acc: 44.53%] [G loss: 0.859009]\n",
      "epoch:30 step:23640[D loss: 0.436196, acc: 59.38%, op_acc: 40.62%] [G loss: 0.917560]\n",
      "epoch:30 step:23641[D loss: 0.385040, acc: 68.75%, op_acc: 41.41%] [G loss: 0.903595]\n",
      "epoch:30 step:23642[D loss: 0.446681, acc: 53.91%, op_acc: 39.06%] [G loss: 0.912403]\n",
      "epoch:30 step:23643[D loss: 0.435855, acc: 56.25%, op_acc: 39.84%] [G loss: 0.864650]\n",
      "epoch:30 step:23644[D loss: 0.436735, acc: 57.81%, op_acc: 39.84%] [G loss: 0.825131]\n",
      "epoch:30 step:23645[D loss: 0.438905, acc: 53.12%, op_acc: 38.28%] [G loss: 0.836550]\n",
      "epoch:30 step:23646[D loss: 0.436156, acc: 54.69%, op_acc: 38.28%] [G loss: 0.901644]\n",
      "epoch:30 step:23647[D loss: 0.409758, acc: 59.38%, op_acc: 42.97%] [G loss: 0.930559]\n",
      "epoch:30 step:23648[D loss: 0.422766, acc: 57.81%, op_acc: 43.75%] [G loss: 0.963881]\n",
      "epoch:30 step:23649[D loss: 0.401538, acc: 61.72%, op_acc: 45.31%] [G loss: 0.901929]\n",
      "epoch:30 step:23650[D loss: 0.446505, acc: 53.91%, op_acc: 40.62%] [G loss: 0.823326]\n",
      "##############\n",
      "[0.84661887 0.86807976 0.81902696 0.80025261 0.80173954 0.83524247\n",
      " 0.8945625  0.83199323 0.82308543 0.82096067]\n",
      "##########\n",
      "epoch:30 step:23651[D loss: 0.412493, acc: 60.94%, op_acc: 39.84%] [G loss: 0.868768]\n",
      "epoch:30 step:23652[D loss: 0.425978, acc: 54.69%, op_acc: 37.50%] [G loss: 0.944991]\n",
      "epoch:30 step:23653[D loss: 0.445202, acc: 57.03%, op_acc: 39.84%] [G loss: 0.920584]\n",
      "epoch:30 step:23654[D loss: 0.420662, acc: 63.28%, op_acc: 42.97%] [G loss: 0.913234]\n",
      "epoch:30 step:23655[D loss: 0.423395, acc: 59.38%, op_acc: 36.72%] [G loss: 0.839272]\n",
      "epoch:30 step:23656[D loss: 0.430128, acc: 60.94%, op_acc: 42.19%] [G loss: 0.880950]\n",
      "epoch:30 step:23657[D loss: 0.410935, acc: 63.28%, op_acc: 42.19%] [G loss: 0.815237]\n",
      "epoch:30 step:23658[D loss: 0.394864, acc: 57.03%, op_acc: 42.97%] [G loss: 0.832505]\n",
      "epoch:30 step:23659[D loss: 0.406198, acc: 71.88%, op_acc: 40.62%] [G loss: 0.806466]\n",
      "epoch:30 step:23660[D loss: 0.442432, acc: 54.69%, op_acc: 36.72%] [G loss: 0.850929]\n",
      "epoch:30 step:23661[D loss: 0.399346, acc: 61.72%, op_acc: 50.78%] [G loss: 0.910403]\n",
      "epoch:30 step:23662[D loss: 0.428746, acc: 57.81%, op_acc: 44.53%] [G loss: 0.910355]\n",
      "epoch:30 step:23663[D loss: 0.388326, acc: 70.31%, op_acc: 43.75%] [G loss: 0.879038]\n",
      "epoch:30 step:23664[D loss: 0.428780, acc: 63.28%, op_acc: 38.28%] [G loss: 0.889944]\n",
      "epoch:30 step:23665[D loss: 0.399298, acc: 60.16%, op_acc: 43.75%] [G loss: 0.918674]\n",
      "epoch:30 step:23666[D loss: 0.416959, acc: 63.28%, op_acc: 39.84%] [G loss: 0.864850]\n",
      "epoch:30 step:23667[D loss: 0.382429, acc: 64.06%, op_acc: 44.53%] [G loss: 0.907909]\n",
      "epoch:30 step:23668[D loss: 0.404769, acc: 64.84%, op_acc: 39.84%] [G loss: 0.852863]\n",
      "epoch:30 step:23669[D loss: 0.441149, acc: 51.56%, op_acc: 33.59%] [G loss: 0.832870]\n",
      "epoch:30 step:23670[D loss: 0.441381, acc: 57.81%, op_acc: 39.06%] [G loss: 0.876233]\n",
      "epoch:30 step:23671[D loss: 0.419347, acc: 55.47%, op_acc: 43.75%] [G loss: 0.856207]\n",
      "epoch:30 step:23672[D loss: 0.390207, acc: 65.62%, op_acc: 41.41%] [G loss: 0.903502]\n",
      "epoch:30 step:23673[D loss: 0.424140, acc: 58.59%, op_acc: 50.78%] [G loss: 0.847438]\n",
      "epoch:30 step:23674[D loss: 0.443269, acc: 54.69%, op_acc: 39.84%] [G loss: 0.909159]\n",
      "epoch:30 step:23675[D loss: 0.401868, acc: 60.16%, op_acc: 44.53%] [G loss: 0.935132]\n",
      "epoch:30 step:23676[D loss: 0.439225, acc: 62.50%, op_acc: 31.25%] [G loss: 0.883710]\n",
      "epoch:30 step:23677[D loss: 0.422274, acc: 51.56%, op_acc: 43.75%] [G loss: 0.797500]\n",
      "epoch:30 step:23678[D loss: 0.434421, acc: 55.47%, op_acc: 35.94%] [G loss: 0.807864]\n",
      "epoch:30 step:23679[D loss: 0.420112, acc: 63.28%, op_acc: 41.41%] [G loss: 0.827770]\n",
      "epoch:30 step:23680[D loss: 0.438181, acc: 56.25%, op_acc: 34.38%] [G loss: 0.907723]\n",
      "epoch:30 step:23681[D loss: 0.389655, acc: 66.41%, op_acc: 46.09%] [G loss: 0.924110]\n",
      "epoch:30 step:23682[D loss: 0.384516, acc: 63.28%, op_acc: 46.88%] [G loss: 0.844069]\n",
      "epoch:30 step:23683[D loss: 0.415147, acc: 58.59%, op_acc: 39.84%] [G loss: 0.827254]\n",
      "epoch:30 step:23684[D loss: 0.437070, acc: 53.91%, op_acc: 43.75%] [G loss: 0.879382]\n",
      "epoch:30 step:23685[D loss: 0.422200, acc: 61.72%, op_acc: 33.59%] [G loss: 0.854019]\n",
      "epoch:30 step:23686[D loss: 0.401872, acc: 58.59%, op_acc: 41.41%] [G loss: 0.818256]\n",
      "epoch:30 step:23687[D loss: 0.421048, acc: 59.38%, op_acc: 39.84%] [G loss: 0.868915]\n",
      "epoch:30 step:23688[D loss: 0.442494, acc: 54.69%, op_acc: 39.84%] [G loss: 0.891725]\n",
      "epoch:30 step:23689[D loss: 0.451240, acc: 55.47%, op_acc: 36.72%] [G loss: 0.898816]\n",
      "epoch:30 step:23690[D loss: 0.434657, acc: 56.25%, op_acc: 38.28%] [G loss: 0.949789]\n",
      "epoch:30 step:23691[D loss: 0.416156, acc: 61.72%, op_acc: 32.03%] [G loss: 0.960089]\n",
      "epoch:30 step:23692[D loss: 0.412419, acc: 61.72%, op_acc: 39.06%] [G loss: 0.896351]\n",
      "epoch:30 step:23693[D loss: 0.416937, acc: 60.16%, op_acc: 36.72%] [G loss: 0.836706]\n",
      "epoch:30 step:23694[D loss: 0.403138, acc: 66.41%, op_acc: 42.19%] [G loss: 0.933554]\n",
      "epoch:30 step:23695[D loss: 0.404079, acc: 53.12%, op_acc: 41.41%] [G loss: 0.889513]\n",
      "epoch:30 step:23696[D loss: 0.420182, acc: 58.59%, op_acc: 40.62%] [G loss: 0.882316]\n",
      "epoch:30 step:23697[D loss: 0.450788, acc: 57.81%, op_acc: 35.16%] [G loss: 0.869221]\n",
      "epoch:30 step:23698[D loss: 0.389639, acc: 64.84%, op_acc: 45.31%] [G loss: 0.883651]\n",
      "epoch:30 step:23699[D loss: 0.418289, acc: 60.94%, op_acc: 42.19%] [G loss: 0.904794]\n",
      "epoch:30 step:23700[D loss: 0.418239, acc: 62.50%, op_acc: 38.28%] [G loss: 0.950229]\n",
      "##############\n",
      "[0.86389171 0.84307475 0.7940569  0.8077529  0.76886484 0.82205763\n",
      " 0.90465836 0.82789574 0.81361751 0.83630468]\n",
      "##########\n",
      "epoch:30 step:23701[D loss: 0.430230, acc: 57.03%, op_acc: 39.06%] [G loss: 0.911922]\n",
      "epoch:30 step:23702[D loss: 0.414597, acc: 63.28%, op_acc: 43.75%] [G loss: 0.953408]\n",
      "epoch:30 step:23703[D loss: 0.424979, acc: 50.00%, op_acc: 42.19%] [G loss: 0.842346]\n",
      "epoch:30 step:23704[D loss: 0.423087, acc: 53.91%, op_acc: 39.06%] [G loss: 0.892848]\n",
      "epoch:30 step:23705[D loss: 0.416975, acc: 62.50%, op_acc: 42.19%] [G loss: 0.815365]\n",
      "epoch:30 step:23706[D loss: 0.449043, acc: 50.78%, op_acc: 39.84%] [G loss: 0.850552]\n",
      "epoch:30 step:23707[D loss: 0.451372, acc: 60.16%, op_acc: 29.69%] [G loss: 0.794767]\n",
      "epoch:30 step:23708[D loss: 0.421888, acc: 60.16%, op_acc: 41.41%] [G loss: 0.902459]\n",
      "epoch:30 step:23709[D loss: 0.407542, acc: 58.59%, op_acc: 41.41%] [G loss: 0.950268]\n",
      "epoch:30 step:23710[D loss: 0.415390, acc: 55.47%, op_acc: 39.06%] [G loss: 0.890592]\n",
      "epoch:30 step:23711[D loss: 0.438049, acc: 57.03%, op_acc: 40.62%] [G loss: 0.833275]\n",
      "epoch:30 step:23712[D loss: 0.460520, acc: 45.31%, op_acc: 35.16%] [G loss: 0.830505]\n",
      "epoch:30 step:23713[D loss: 0.426374, acc: 57.81%, op_acc: 39.84%] [G loss: 0.847108]\n",
      "epoch:30 step:23714[D loss: 0.426345, acc: 59.38%, op_acc: 40.62%] [G loss: 0.811230]\n",
      "epoch:30 step:23715[D loss: 0.426760, acc: 61.72%, op_acc: 37.50%] [G loss: 0.820096]\n",
      "epoch:30 step:23716[D loss: 0.405909, acc: 62.50%, op_acc: 35.94%] [G loss: 0.857536]\n",
      "epoch:30 step:23717[D loss: 0.422671, acc: 61.72%, op_acc: 39.06%] [G loss: 0.850578]\n",
      "epoch:30 step:23718[D loss: 0.399074, acc: 65.62%, op_acc: 40.62%] [G loss: 0.833719]\n",
      "epoch:30 step:23719[D loss: 0.418101, acc: 59.38%, op_acc: 38.28%] [G loss: 0.852452]\n",
      "epoch:30 step:23720[D loss: 0.436823, acc: 55.47%, op_acc: 37.50%] [G loss: 0.884964]\n",
      "epoch:30 step:23721[D loss: 0.414284, acc: 61.72%, op_acc: 43.75%] [G loss: 0.879413]\n",
      "epoch:30 step:23722[D loss: 0.446088, acc: 58.59%, op_acc: 39.06%] [G loss: 0.828027]\n",
      "epoch:30 step:23723[D loss: 0.455330, acc: 52.34%, op_acc: 35.94%] [G loss: 0.791347]\n",
      "epoch:30 step:23724[D loss: 0.443958, acc: 60.16%, op_acc: 39.84%] [G loss: 0.852597]\n",
      "epoch:30 step:23725[D loss: 0.409472, acc: 53.91%, op_acc: 46.88%] [G loss: 0.873616]\n",
      "epoch:30 step:23726[D loss: 0.461448, acc: 49.22%, op_acc: 39.84%] [G loss: 0.826077]\n",
      "epoch:30 step:23727[D loss: 0.420507, acc: 61.72%, op_acc: 42.19%] [G loss: 0.891047]\n",
      "epoch:30 step:23728[D loss: 0.422660, acc: 62.50%, op_acc: 40.62%] [G loss: 0.912016]\n",
      "epoch:30 step:23729[D loss: 0.398761, acc: 70.31%, op_acc: 43.75%] [G loss: 0.929602]\n",
      "epoch:30 step:23730[D loss: 0.436697, acc: 53.91%, op_acc: 35.16%] [G loss: 0.854049]\n",
      "epoch:30 step:23731[D loss: 0.422846, acc: 60.16%, op_acc: 31.25%] [G loss: 0.810120]\n",
      "epoch:30 step:23732[D loss: 0.413555, acc: 58.59%, op_acc: 41.41%] [G loss: 0.832464]\n",
      "epoch:30 step:23733[D loss: 0.413094, acc: 64.06%, op_acc: 41.41%] [G loss: 0.865586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23734[D loss: 0.420272, acc: 62.50%, op_acc: 41.41%] [G loss: 0.922643]\n",
      "epoch:30 step:23735[D loss: 0.431234, acc: 53.12%, op_acc: 40.62%] [G loss: 0.961848]\n",
      "epoch:30 step:23736[D loss: 0.453968, acc: 56.25%, op_acc: 38.28%] [G loss: 0.856226]\n",
      "epoch:30 step:23737[D loss: 0.403373, acc: 64.06%, op_acc: 46.09%] [G loss: 0.818910]\n",
      "epoch:30 step:23738[D loss: 0.420319, acc: 60.94%, op_acc: 45.31%] [G loss: 0.866254]\n",
      "epoch:30 step:23739[D loss: 0.448186, acc: 55.47%, op_acc: 35.16%] [G loss: 0.882158]\n",
      "epoch:30 step:23740[D loss: 0.424825, acc: 57.03%, op_acc: 38.28%] [G loss: 0.849414]\n",
      "epoch:30 step:23741[D loss: 0.427451, acc: 57.03%, op_acc: 39.06%] [G loss: 0.875600]\n",
      "epoch:30 step:23742[D loss: 0.436040, acc: 55.47%, op_acc: 42.97%] [G loss: 0.874335]\n",
      "epoch:30 step:23743[D loss: 0.440536, acc: 57.81%, op_acc: 35.16%] [G loss: 0.826370]\n",
      "epoch:30 step:23744[D loss: 0.417055, acc: 63.28%, op_acc: 39.06%] [G loss: 0.897533]\n",
      "epoch:30 step:23745[D loss: 0.455711, acc: 52.34%, op_acc: 35.94%] [G loss: 0.811510]\n",
      "epoch:30 step:23746[D loss: 0.435871, acc: 60.16%, op_acc: 33.59%] [G loss: 0.828148]\n",
      "epoch:30 step:23747[D loss: 0.436184, acc: 51.56%, op_acc: 39.06%] [G loss: 0.804491]\n",
      "epoch:30 step:23748[D loss: 0.423317, acc: 60.16%, op_acc: 35.16%] [G loss: 0.882756]\n",
      "epoch:30 step:23749[D loss: 0.448681, acc: 57.03%, op_acc: 32.03%] [G loss: 0.831954]\n",
      "epoch:30 step:23750[D loss: 0.407874, acc: 67.97%, op_acc: 37.50%] [G loss: 0.855528]\n",
      "##############\n",
      "[0.85561949 0.85986616 0.83032282 0.80094999 0.79670104 0.80655713\n",
      " 0.88365573 0.83176399 0.80439718 0.81778158]\n",
      "##########\n",
      "epoch:30 step:23751[D loss: 0.424671, acc: 64.06%, op_acc: 42.19%] [G loss: 0.889152]\n",
      "epoch:30 step:23752[D loss: 0.418456, acc: 60.16%, op_acc: 36.72%] [G loss: 0.859101]\n",
      "epoch:30 step:23753[D loss: 0.448235, acc: 57.03%, op_acc: 36.72%] [G loss: 0.838199]\n",
      "epoch:30 step:23754[D loss: 0.444088, acc: 59.38%, op_acc: 35.94%] [G loss: 0.999781]\n",
      "epoch:30 step:23755[D loss: 0.426360, acc: 57.81%, op_acc: 39.06%] [G loss: 0.924288]\n",
      "epoch:30 step:23756[D loss: 0.390987, acc: 66.41%, op_acc: 42.97%] [G loss: 0.861059]\n",
      "epoch:30 step:23757[D loss: 0.425585, acc: 54.69%, op_acc: 39.06%] [G loss: 0.884771]\n",
      "epoch:30 step:23758[D loss: 0.449350, acc: 57.03%, op_acc: 33.59%] [G loss: 0.828166]\n",
      "epoch:30 step:23759[D loss: 0.423267, acc: 57.81%, op_acc: 38.28%] [G loss: 0.878107]\n",
      "epoch:30 step:23760[D loss: 0.411437, acc: 59.38%, op_acc: 45.31%] [G loss: 0.784352]\n",
      "epoch:30 step:23761[D loss: 0.427423, acc: 55.47%, op_acc: 39.84%] [G loss: 0.772877]\n",
      "epoch:30 step:23762[D loss: 0.408033, acc: 66.41%, op_acc: 39.06%] [G loss: 0.857706]\n",
      "epoch:30 step:23763[D loss: 0.420976, acc: 57.03%, op_acc: 39.06%] [G loss: 0.879044]\n",
      "epoch:30 step:23764[D loss: 0.439017, acc: 57.81%, op_acc: 38.28%] [G loss: 0.901968]\n",
      "epoch:30 step:23765[D loss: 0.431583, acc: 61.72%, op_acc: 36.72%] [G loss: 0.830932]\n",
      "epoch:30 step:23766[D loss: 0.413525, acc: 60.94%, op_acc: 42.19%] [G loss: 0.925762]\n",
      "epoch:30 step:23767[D loss: 0.436206, acc: 62.50%, op_acc: 38.28%] [G loss: 0.863550]\n",
      "epoch:30 step:23768[D loss: 0.384916, acc: 64.84%, op_acc: 39.06%] [G loss: 0.902137]\n",
      "epoch:30 step:23769[D loss: 0.399930, acc: 64.84%, op_acc: 40.62%] [G loss: 0.882317]\n",
      "epoch:30 step:23770[D loss: 0.431208, acc: 60.16%, op_acc: 40.62%] [G loss: 0.835981]\n",
      "epoch:30 step:23771[D loss: 0.444110, acc: 54.69%, op_acc: 37.50%] [G loss: 0.899744]\n",
      "epoch:30 step:23772[D loss: 0.438962, acc: 53.91%, op_acc: 41.41%] [G loss: 0.846802]\n",
      "epoch:30 step:23773[D loss: 0.428953, acc: 64.06%, op_acc: 37.50%] [G loss: 0.888699]\n",
      "epoch:30 step:23774[D loss: 0.417363, acc: 53.91%, op_acc: 39.06%] [G loss: 0.897820]\n",
      "epoch:30 step:23775[D loss: 0.400703, acc: 64.84%, op_acc: 39.84%] [G loss: 0.902231]\n",
      "epoch:30 step:23776[D loss: 0.405057, acc: 59.38%, op_acc: 42.19%] [G loss: 0.826701]\n",
      "epoch:30 step:23777[D loss: 0.414992, acc: 57.03%, op_acc: 40.62%] [G loss: 0.784713]\n",
      "epoch:30 step:23778[D loss: 0.407237, acc: 66.41%, op_acc: 39.06%] [G loss: 0.874299]\n",
      "epoch:30 step:23779[D loss: 0.412498, acc: 57.03%, op_acc: 46.88%] [G loss: 0.829673]\n",
      "epoch:30 step:23780[D loss: 0.455967, acc: 52.34%, op_acc: 36.72%] [G loss: 0.857199]\n",
      "epoch:30 step:23781[D loss: 0.427620, acc: 57.03%, op_acc: 35.16%] [G loss: 0.819511]\n",
      "epoch:30 step:23782[D loss: 0.418136, acc: 60.94%, op_acc: 35.16%] [G loss: 0.878236]\n",
      "epoch:30 step:23783[D loss: 0.385609, acc: 57.81%, op_acc: 48.44%] [G loss: 0.889892]\n",
      "epoch:30 step:23784[D loss: 0.434011, acc: 59.38%, op_acc: 35.94%] [G loss: 0.886643]\n",
      "epoch:30 step:23785[D loss: 0.398567, acc: 61.72%, op_acc: 39.84%] [G loss: 0.802001]\n",
      "epoch:30 step:23786[D loss: 0.418627, acc: 57.81%, op_acc: 43.75%] [G loss: 0.847929]\n",
      "epoch:30 step:23787[D loss: 0.438394, acc: 57.81%, op_acc: 39.06%] [G loss: 0.872937]\n",
      "epoch:30 step:23788[D loss: 0.409178, acc: 64.06%, op_acc: 42.97%] [G loss: 0.957851]\n",
      "epoch:30 step:23789[D loss: 0.440117, acc: 57.03%, op_acc: 35.94%] [G loss: 0.928127]\n",
      "epoch:30 step:23790[D loss: 0.424944, acc: 57.81%, op_acc: 37.50%] [G loss: 0.895030]\n",
      "epoch:30 step:23791[D loss: 0.407487, acc: 61.72%, op_acc: 42.19%] [G loss: 0.898073]\n",
      "epoch:30 step:23792[D loss: 0.391141, acc: 64.06%, op_acc: 39.84%] [G loss: 0.865495]\n",
      "epoch:30 step:23793[D loss: 0.440579, acc: 53.12%, op_acc: 37.50%] [G loss: 0.876629]\n",
      "epoch:30 step:23794[D loss: 0.416311, acc: 58.59%, op_acc: 42.19%] [G loss: 0.854993]\n",
      "epoch:30 step:23795[D loss: 0.395051, acc: 62.50%, op_acc: 46.88%] [G loss: 0.930755]\n",
      "epoch:30 step:23796[D loss: 0.407575, acc: 60.94%, op_acc: 41.41%] [G loss: 0.909990]\n",
      "epoch:30 step:23797[D loss: 0.420834, acc: 60.94%, op_acc: 37.50%] [G loss: 0.868230]\n",
      "epoch:30 step:23798[D loss: 0.435271, acc: 60.16%, op_acc: 39.84%] [G loss: 0.865738]\n",
      "epoch:30 step:23799[D loss: 0.425226, acc: 57.03%, op_acc: 39.84%] [G loss: 0.826342]\n",
      "epoch:30 step:23800[D loss: 0.436858, acc: 56.25%, op_acc: 37.50%] [G loss: 0.873723]\n",
      "##############\n",
      "[0.86386742 0.87487794 0.79607298 0.81896904 0.80236427 0.82073437\n",
      " 0.86786316 0.8279473  0.80719165 0.8159428 ]\n",
      "##########\n",
      "epoch:30 step:23801[D loss: 0.430488, acc: 51.56%, op_acc: 46.09%] [G loss: 0.836576]\n",
      "epoch:30 step:23802[D loss: 0.393974, acc: 70.31%, op_acc: 39.84%] [G loss: 0.868812]\n",
      "epoch:30 step:23803[D loss: 0.426135, acc: 57.03%, op_acc: 39.06%] [G loss: 0.789982]\n",
      "epoch:30 step:23804[D loss: 0.426876, acc: 54.69%, op_acc: 42.19%] [G loss: 0.875510]\n",
      "epoch:30 step:23805[D loss: 0.432184, acc: 57.81%, op_acc: 42.19%] [G loss: 0.809208]\n",
      "epoch:30 step:23806[D loss: 0.410096, acc: 61.72%, op_acc: 38.28%] [G loss: 0.890495]\n",
      "epoch:30 step:23807[D loss: 0.420698, acc: 56.25%, op_acc: 39.84%] [G loss: 0.902589]\n",
      "epoch:30 step:23808[D loss: 0.419611, acc: 55.47%, op_acc: 42.19%] [G loss: 0.904243]\n",
      "epoch:30 step:23809[D loss: 0.387427, acc: 71.09%, op_acc: 42.19%] [G loss: 0.859087]\n",
      "epoch:30 step:23810[D loss: 0.394581, acc: 63.28%, op_acc: 46.09%] [G loss: 0.963654]\n",
      "epoch:30 step:23811[D loss: 0.396232, acc: 64.84%, op_acc: 44.53%] [G loss: 0.939183]\n",
      "epoch:30 step:23812[D loss: 0.413051, acc: 60.16%, op_acc: 39.84%] [G loss: 0.910893]\n",
      "epoch:30 step:23813[D loss: 0.414540, acc: 57.03%, op_acc: 42.19%] [G loss: 0.835696]\n",
      "epoch:30 step:23814[D loss: 0.401602, acc: 64.06%, op_acc: 45.31%] [G loss: 0.869476]\n",
      "epoch:30 step:23815[D loss: 0.410607, acc: 62.50%, op_acc: 36.72%] [G loss: 0.831471]\n",
      "epoch:30 step:23816[D loss: 0.394708, acc: 67.97%, op_acc: 39.06%] [G loss: 0.955920]\n",
      "epoch:30 step:23817[D loss: 0.432392, acc: 56.25%, op_acc: 39.06%] [G loss: 0.893025]\n",
      "epoch:30 step:23818[D loss: 0.427232, acc: 64.84%, op_acc: 42.19%] [G loss: 0.971322]\n",
      "epoch:30 step:23819[D loss: 0.409185, acc: 64.84%, op_acc: 39.84%] [G loss: 0.875962]\n",
      "epoch:30 step:23820[D loss: 0.385086, acc: 65.62%, op_acc: 42.19%] [G loss: 0.893042]\n",
      "epoch:30 step:23821[D loss: 0.430883, acc: 55.47%, op_acc: 43.75%] [G loss: 0.783058]\n",
      "epoch:30 step:23822[D loss: 0.416106, acc: 53.12%, op_acc: 45.31%] [G loss: 0.885238]\n",
      "epoch:30 step:23823[D loss: 0.421037, acc: 60.16%, op_acc: 41.41%] [G loss: 0.834210]\n",
      "epoch:30 step:23824[D loss: 0.412532, acc: 64.84%, op_acc: 40.62%] [G loss: 0.886082]\n",
      "epoch:30 step:23825[D loss: 0.436449, acc: 61.72%, op_acc: 32.03%] [G loss: 0.825075]\n",
      "epoch:30 step:23826[D loss: 0.397753, acc: 62.50%, op_acc: 41.41%] [G loss: 0.868327]\n",
      "epoch:30 step:23827[D loss: 0.436284, acc: 50.78%, op_acc: 39.06%] [G loss: 0.900357]\n",
      "epoch:30 step:23828[D loss: 0.447448, acc: 50.00%, op_acc: 42.19%] [G loss: 0.888711]\n",
      "epoch:30 step:23829[D loss: 0.417334, acc: 55.47%, op_acc: 41.41%] [G loss: 0.923751]\n",
      "epoch:30 step:23830[D loss: 0.422383, acc: 59.38%, op_acc: 42.19%] [G loss: 0.867314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23831[D loss: 0.409164, acc: 59.38%, op_acc: 40.62%] [G loss: 0.851516]\n",
      "epoch:30 step:23832[D loss: 0.419688, acc: 64.84%, op_acc: 34.38%] [G loss: 0.875653]\n",
      "epoch:30 step:23833[D loss: 0.420482, acc: 60.94%, op_acc: 39.84%] [G loss: 0.855736]\n",
      "epoch:30 step:23834[D loss: 0.369853, acc: 65.62%, op_acc: 45.31%] [G loss: 0.937231]\n",
      "epoch:30 step:23835[D loss: 0.419974, acc: 60.94%, op_acc: 35.16%] [G loss: 0.926972]\n",
      "epoch:30 step:23836[D loss: 0.417307, acc: 57.03%, op_acc: 43.75%] [G loss: 0.860870]\n",
      "epoch:30 step:23837[D loss: 0.392051, acc: 63.28%, op_acc: 44.53%] [G loss: 0.896034]\n",
      "epoch:30 step:23838[D loss: 0.398871, acc: 59.38%, op_acc: 47.66%] [G loss: 0.835052]\n",
      "epoch:30 step:23839[D loss: 0.421991, acc: 59.38%, op_acc: 39.06%] [G loss: 0.859919]\n",
      "epoch:30 step:23840[D loss: 0.389064, acc: 64.84%, op_acc: 42.19%] [G loss: 0.946287]\n",
      "epoch:30 step:23841[D loss: 0.429709, acc: 57.81%, op_acc: 45.31%] [G loss: 0.834290]\n",
      "epoch:30 step:23842[D loss: 0.391154, acc: 59.38%, op_acc: 45.31%] [G loss: 0.831731]\n",
      "epoch:30 step:23843[D loss: 0.426210, acc: 56.25%, op_acc: 41.41%] [G loss: 0.922390]\n",
      "epoch:30 step:23844[D loss: 0.420081, acc: 57.81%, op_acc: 42.97%] [G loss: 0.934511]\n",
      "epoch:30 step:23845[D loss: 0.416375, acc: 62.50%, op_acc: 38.28%] [G loss: 0.916812]\n",
      "epoch:30 step:23846[D loss: 0.399603, acc: 65.62%, op_acc: 44.53%] [G loss: 0.891132]\n",
      "epoch:30 step:23847[D loss: 0.420464, acc: 57.81%, op_acc: 41.41%] [G loss: 0.858139]\n",
      "epoch:30 step:23848[D loss: 0.429904, acc: 60.16%, op_acc: 42.19%] [G loss: 0.827490]\n",
      "epoch:30 step:23849[D loss: 0.422212, acc: 65.62%, op_acc: 39.84%] [G loss: 0.857864]\n",
      "epoch:30 step:23850[D loss: 0.442109, acc: 56.25%, op_acc: 35.94%] [G loss: 0.883335]\n",
      "##############\n",
      "[0.86003093 0.84618384 0.81804268 0.8193853  0.78331604 0.81979123\n",
      " 0.84965518 0.82836026 0.79989162 0.84091157]\n",
      "##########\n",
      "epoch:30 step:23851[D loss: 0.428750, acc: 57.81%, op_acc: 42.19%] [G loss: 0.907623]\n",
      "epoch:30 step:23852[D loss: 0.403309, acc: 65.62%, op_acc: 40.62%] [G loss: 0.866564]\n",
      "epoch:30 step:23853[D loss: 0.408767, acc: 60.94%, op_acc: 39.84%] [G loss: 0.817017]\n",
      "epoch:30 step:23854[D loss: 0.420681, acc: 63.28%, op_acc: 41.41%] [G loss: 0.966072]\n",
      "epoch:30 step:23855[D loss: 0.444456, acc: 53.12%, op_acc: 38.28%] [G loss: 0.795069]\n",
      "epoch:30 step:23856[D loss: 0.458621, acc: 52.34%, op_acc: 33.59%] [G loss: 0.845356]\n",
      "epoch:30 step:23857[D loss: 0.422924, acc: 64.84%, op_acc: 37.50%] [G loss: 0.825042]\n",
      "epoch:30 step:23858[D loss: 0.427933, acc: 50.78%, op_acc: 40.62%] [G loss: 0.817238]\n",
      "epoch:30 step:23859[D loss: 0.416758, acc: 64.06%, op_acc: 39.06%] [G loss: 0.850599]\n",
      "epoch:30 step:23860[D loss: 0.439977, acc: 53.12%, op_acc: 40.62%] [G loss: 0.939527]\n",
      "epoch:30 step:23861[D loss: 0.439242, acc: 59.38%, op_acc: 37.50%] [G loss: 0.845020]\n",
      "epoch:30 step:23862[D loss: 0.428956, acc: 55.47%, op_acc: 36.72%] [G loss: 0.818714]\n",
      "epoch:30 step:23863[D loss: 0.389765, acc: 64.06%, op_acc: 44.53%] [G loss: 0.868834]\n",
      "epoch:30 step:23864[D loss: 0.417386, acc: 55.47%, op_acc: 41.41%] [G loss: 0.866313]\n",
      "epoch:30 step:23865[D loss: 0.417891, acc: 60.16%, op_acc: 47.66%] [G loss: 0.931852]\n",
      "epoch:30 step:23866[D loss: 0.467634, acc: 53.91%, op_acc: 39.84%] [G loss: 0.888294]\n",
      "epoch:30 step:23867[D loss: 0.449512, acc: 52.34%, op_acc: 38.28%] [G loss: 0.909285]\n",
      "epoch:30 step:23868[D loss: 0.416116, acc: 58.59%, op_acc: 42.97%] [G loss: 0.947611]\n",
      "epoch:30 step:23869[D loss: 0.435668, acc: 50.78%, op_acc: 39.84%] [G loss: 0.844711]\n",
      "epoch:30 step:23870[D loss: 0.419527, acc: 58.59%, op_acc: 39.06%] [G loss: 0.893616]\n",
      "epoch:30 step:23871[D loss: 0.408431, acc: 60.94%, op_acc: 43.75%] [G loss: 0.850615]\n",
      "epoch:30 step:23872[D loss: 0.416414, acc: 62.50%, op_acc: 39.84%] [G loss: 0.978877]\n",
      "epoch:30 step:23873[D loss: 0.401724, acc: 62.50%, op_acc: 42.19%] [G loss: 0.886165]\n",
      "epoch:30 step:23874[D loss: 0.405448, acc: 60.16%, op_acc: 39.06%] [G loss: 0.781551]\n",
      "epoch:30 step:23875[D loss: 0.422111, acc: 57.03%, op_acc: 39.06%] [G loss: 0.957618]\n",
      "epoch:30 step:23876[D loss: 0.425187, acc: 59.38%, op_acc: 44.53%] [G loss: 0.829253]\n",
      "epoch:30 step:23877[D loss: 0.457715, acc: 57.03%, op_acc: 36.72%] [G loss: 0.863560]\n",
      "epoch:30 step:23878[D loss: 0.439101, acc: 52.34%, op_acc: 41.41%] [G loss: 0.878229]\n",
      "epoch:30 step:23879[D loss: 0.435591, acc: 49.22%, op_acc: 39.06%] [G loss: 0.901021]\n",
      "epoch:30 step:23880[D loss: 0.434815, acc: 62.50%, op_acc: 35.94%] [G loss: 0.917155]\n",
      "epoch:30 step:23881[D loss: 0.399522, acc: 62.50%, op_acc: 46.88%] [G loss: 0.933473]\n",
      "epoch:30 step:23882[D loss: 0.410816, acc: 62.50%, op_acc: 50.00%] [G loss: 0.947384]\n",
      "epoch:30 step:23883[D loss: 0.399347, acc: 60.16%, op_acc: 44.53%] [G loss: 0.912863]\n",
      "epoch:30 step:23884[D loss: 0.413326, acc: 61.72%, op_acc: 39.06%] [G loss: 0.828168]\n",
      "epoch:30 step:23885[D loss: 0.423419, acc: 65.62%, op_acc: 36.72%] [G loss: 0.908110]\n",
      "epoch:30 step:23886[D loss: 0.410877, acc: 60.94%, op_acc: 39.06%] [G loss: 0.899772]\n",
      "epoch:30 step:23887[D loss: 0.411639, acc: 63.28%, op_acc: 42.19%] [G loss: 0.820898]\n",
      "epoch:30 step:23888[D loss: 0.394091, acc: 63.28%, op_acc: 42.97%] [G loss: 0.885129]\n",
      "epoch:30 step:23889[D loss: 0.405312, acc: 60.16%, op_acc: 44.53%] [G loss: 0.902213]\n",
      "epoch:30 step:23890[D loss: 0.408247, acc: 60.16%, op_acc: 41.41%] [G loss: 0.855514]\n",
      "epoch:30 step:23891[D loss: 0.416563, acc: 58.59%, op_acc: 39.06%] [G loss: 0.855228]\n",
      "epoch:30 step:23892[D loss: 0.396219, acc: 64.06%, op_acc: 37.50%] [G loss: 0.886349]\n",
      "epoch:30 step:23893[D loss: 0.424820, acc: 56.25%, op_acc: 41.41%] [G loss: 0.872223]\n",
      "epoch:30 step:23894[D loss: 0.429219, acc: 64.06%, op_acc: 40.62%] [G loss: 0.950471]\n",
      "epoch:30 step:23895[D loss: 0.424209, acc: 63.28%, op_acc: 39.84%] [G loss: 0.866413]\n",
      "epoch:30 step:23896[D loss: 0.393352, acc: 64.84%, op_acc: 39.84%] [G loss: 0.942886]\n",
      "epoch:30 step:23897[D loss: 0.452435, acc: 57.81%, op_acc: 37.50%] [G loss: 1.011477]\n",
      "epoch:30 step:23898[D loss: 0.388649, acc: 64.06%, op_acc: 43.75%] [G loss: 0.879377]\n",
      "epoch:30 step:23899[D loss: 0.379717, acc: 67.97%, op_acc: 45.31%] [G loss: 0.752801]\n",
      "epoch:30 step:23900[D loss: 0.420702, acc: 56.25%, op_acc: 40.62%] [G loss: 0.961466]\n",
      "##############\n",
      "[0.8704742  0.83808952 0.80536955 0.80681707 0.76504396 0.83322168\n",
      " 0.90204835 0.82496785 0.80036524 0.82654246]\n",
      "##########\n",
      "epoch:30 step:23901[D loss: 0.421318, acc: 62.50%, op_acc: 41.41%] [G loss: 0.829745]\n",
      "epoch:30 step:23902[D loss: 0.437332, acc: 58.59%, op_acc: 38.28%] [G loss: 0.875154]\n",
      "epoch:30 step:23903[D loss: 0.400659, acc: 60.16%, op_acc: 45.31%] [G loss: 0.794300]\n",
      "epoch:30 step:23904[D loss: 0.439404, acc: 56.25%, op_acc: 44.53%] [G loss: 0.832219]\n",
      "epoch:30 step:23905[D loss: 0.389459, acc: 62.50%, op_acc: 48.44%] [G loss: 0.924608]\n",
      "epoch:30 step:23906[D loss: 0.408435, acc: 66.41%, op_acc: 35.16%] [G loss: 0.849783]\n",
      "epoch:30 step:23907[D loss: 0.441013, acc: 63.28%, op_acc: 39.84%] [G loss: 0.842109]\n",
      "epoch:30 step:23908[D loss: 0.431519, acc: 50.78%, op_acc: 46.09%] [G loss: 0.790385]\n",
      "epoch:30 step:23909[D loss: 0.374477, acc: 70.31%, op_acc: 44.53%] [G loss: 0.934575]\n",
      "epoch:30 step:23910[D loss: 0.451169, acc: 56.25%, op_acc: 37.50%] [G loss: 0.987612]\n",
      "epoch:30 step:23911[D loss: 0.434011, acc: 63.28%, op_acc: 39.06%] [G loss: 0.837395]\n",
      "epoch:30 step:23912[D loss: 0.413733, acc: 67.97%, op_acc: 37.50%] [G loss: 0.878692]\n",
      "epoch:30 step:23913[D loss: 0.402758, acc: 63.28%, op_acc: 40.62%] [G loss: 0.888629]\n",
      "epoch:30 step:23914[D loss: 0.372921, acc: 64.84%, op_acc: 47.66%] [G loss: 0.898078]\n",
      "epoch:30 step:23915[D loss: 0.424409, acc: 57.81%, op_acc: 41.41%] [G loss: 0.950637]\n",
      "epoch:30 step:23916[D loss: 0.389669, acc: 64.06%, op_acc: 40.62%] [G loss: 0.938846]\n",
      "epoch:30 step:23917[D loss: 0.416892, acc: 62.50%, op_acc: 36.72%] [G loss: 0.924553]\n",
      "epoch:30 step:23918[D loss: 0.386072, acc: 71.88%, op_acc: 41.41%] [G loss: 0.848794]\n",
      "epoch:30 step:23919[D loss: 0.432216, acc: 55.47%, op_acc: 38.28%] [G loss: 0.793989]\n",
      "epoch:30 step:23920[D loss: 0.416275, acc: 57.03%, op_acc: 37.50%] [G loss: 0.864810]\n",
      "epoch:30 step:23921[D loss: 0.410089, acc: 67.97%, op_acc: 35.94%] [G loss: 0.840903]\n",
      "epoch:30 step:23922[D loss: 0.424832, acc: 60.94%, op_acc: 42.19%] [G loss: 0.941407]\n",
      "epoch:30 step:23923[D loss: 0.431229, acc: 55.47%, op_acc: 40.62%] [G loss: 0.911763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23924[D loss: 0.398128, acc: 70.31%, op_acc: 39.06%] [G loss: 0.911499]\n",
      "epoch:30 step:23925[D loss: 0.405377, acc: 65.62%, op_acc: 40.62%] [G loss: 0.936767]\n",
      "epoch:30 step:23926[D loss: 0.428270, acc: 60.16%, op_acc: 41.41%] [G loss: 0.855284]\n",
      "epoch:30 step:23927[D loss: 0.391290, acc: 65.62%, op_acc: 45.31%] [G loss: 0.980967]\n",
      "epoch:30 step:23928[D loss: 0.437451, acc: 62.50%, op_acc: 39.06%] [G loss: 0.988452]\n",
      "epoch:30 step:23929[D loss: 0.425695, acc: 66.41%, op_acc: 39.84%] [G loss: 0.966051]\n",
      "epoch:30 step:23930[D loss: 0.442945, acc: 54.69%, op_acc: 39.84%] [G loss: 0.840085]\n",
      "epoch:30 step:23931[D loss: 0.415930, acc: 66.41%, op_acc: 39.06%] [G loss: 0.990100]\n",
      "epoch:30 step:23932[D loss: 0.433609, acc: 58.59%, op_acc: 42.19%] [G loss: 0.944408]\n",
      "epoch:30 step:23933[D loss: 0.429799, acc: 57.03%, op_acc: 39.06%] [G loss: 0.842601]\n",
      "epoch:30 step:23934[D loss: 0.436043, acc: 57.81%, op_acc: 43.75%] [G loss: 0.817072]\n",
      "epoch:30 step:23935[D loss: 0.442829, acc: 57.81%, op_acc: 32.03%] [G loss: 0.945564]\n",
      "epoch:30 step:23936[D loss: 0.427848, acc: 64.06%, op_acc: 36.72%] [G loss: 0.836023]\n",
      "epoch:30 step:23937[D loss: 0.405361, acc: 62.50%, op_acc: 43.75%] [G loss: 0.899175]\n",
      "epoch:30 step:23938[D loss: 0.418507, acc: 60.94%, op_acc: 36.72%] [G loss: 0.890475]\n",
      "epoch:30 step:23939[D loss: 0.445553, acc: 54.69%, op_acc: 39.06%] [G loss: 0.856392]\n",
      "epoch:30 step:23940[D loss: 0.414131, acc: 60.94%, op_acc: 42.97%] [G loss: 0.831041]\n",
      "epoch:30 step:23941[D loss: 0.455856, acc: 46.09%, op_acc: 38.28%] [G loss: 0.842713]\n",
      "epoch:30 step:23942[D loss: 0.439390, acc: 57.03%, op_acc: 40.62%] [G loss: 0.898586]\n",
      "epoch:30 step:23943[D loss: 0.426356, acc: 53.91%, op_acc: 38.28%] [G loss: 0.958078]\n",
      "epoch:30 step:23944[D loss: 0.413317, acc: 60.94%, op_acc: 37.50%] [G loss: 0.944316]\n",
      "epoch:30 step:23945[D loss: 0.413734, acc: 60.16%, op_acc: 38.28%] [G loss: 0.862490]\n",
      "epoch:30 step:23946[D loss: 0.442371, acc: 53.91%, op_acc: 35.94%] [G loss: 0.864477]\n",
      "epoch:30 step:23947[D loss: 0.429806, acc: 57.81%, op_acc: 35.16%] [G loss: 0.907766]\n",
      "epoch:30 step:23948[D loss: 0.399103, acc: 63.28%, op_acc: 42.19%] [G loss: 0.849105]\n",
      "epoch:30 step:23949[D loss: 0.400297, acc: 64.06%, op_acc: 42.97%] [G loss: 0.875782]\n",
      "epoch:30 step:23950[D loss: 0.434565, acc: 60.94%, op_acc: 39.06%] [G loss: 0.901315]\n",
      "##############\n",
      "[0.86038238 0.8662761  0.80457198 0.81101364 0.79943397 0.81801679\n",
      " 0.85426768 0.81923675 0.81228596 0.83241465]\n",
      "##########\n",
      "epoch:30 step:23951[D loss: 0.423994, acc: 55.47%, op_acc: 34.38%] [G loss: 0.879371]\n",
      "epoch:30 step:23952[D loss: 0.431810, acc: 58.59%, op_acc: 39.06%] [G loss: 0.841067]\n",
      "epoch:30 step:23953[D loss: 0.429269, acc: 59.38%, op_acc: 40.62%] [G loss: 0.816959]\n",
      "epoch:30 step:23954[D loss: 0.416394, acc: 63.28%, op_acc: 37.50%] [G loss: 0.931543]\n",
      "epoch:30 step:23955[D loss: 0.422129, acc: 63.28%, op_acc: 39.06%] [G loss: 0.852113]\n",
      "epoch:30 step:23956[D loss: 0.460319, acc: 51.56%, op_acc: 36.72%] [G loss: 0.946053]\n",
      "epoch:30 step:23957[D loss: 0.440208, acc: 58.59%, op_acc: 39.06%] [G loss: 0.868321]\n",
      "epoch:30 step:23958[D loss: 0.421838, acc: 63.28%, op_acc: 35.94%] [G loss: 0.985573]\n",
      "epoch:30 step:23959[D loss: 0.393517, acc: 64.84%, op_acc: 39.06%] [G loss: 0.909782]\n",
      "epoch:30 step:23960[D loss: 0.414415, acc: 65.62%, op_acc: 36.72%] [G loss: 0.930925]\n",
      "epoch:30 step:23961[D loss: 0.436689, acc: 60.16%, op_acc: 35.94%] [G loss: 0.890045]\n",
      "epoch:30 step:23962[D loss: 0.420030, acc: 53.91%, op_acc: 42.19%] [G loss: 0.965865]\n",
      "epoch:30 step:23963[D loss: 0.450474, acc: 49.22%, op_acc: 42.97%] [G loss: 0.893227]\n",
      "epoch:30 step:23964[D loss: 0.404959, acc: 64.84%, op_acc: 39.84%] [G loss: 0.871320]\n",
      "epoch:30 step:23965[D loss: 0.450781, acc: 43.75%, op_acc: 39.06%] [G loss: 0.815878]\n",
      "epoch:30 step:23966[D loss: 0.397646, acc: 61.72%, op_acc: 42.97%] [G loss: 0.892723]\n",
      "epoch:30 step:23967[D loss: 0.443139, acc: 62.50%, op_acc: 32.81%] [G loss: 0.984038]\n",
      "epoch:30 step:23968[D loss: 0.428919, acc: 57.03%, op_acc: 39.84%] [G loss: 0.837765]\n",
      "epoch:30 step:23969[D loss: 0.424338, acc: 64.06%, op_acc: 38.28%] [G loss: 0.948091]\n",
      "epoch:30 step:23970[D loss: 0.411432, acc: 60.94%, op_acc: 37.50%] [G loss: 0.860713]\n",
      "epoch:30 step:23971[D loss: 0.410348, acc: 56.25%, op_acc: 39.06%] [G loss: 0.783916]\n",
      "epoch:30 step:23972[D loss: 0.423850, acc: 60.94%, op_acc: 37.50%] [G loss: 0.827246]\n",
      "epoch:30 step:23973[D loss: 0.409579, acc: 63.28%, op_acc: 39.84%] [G loss: 0.824512]\n",
      "epoch:30 step:23974[D loss: 0.388267, acc: 68.75%, op_acc: 45.31%] [G loss: 0.880207]\n",
      "epoch:30 step:23975[D loss: 0.402781, acc: 66.41%, op_acc: 42.19%] [G loss: 0.930554]\n",
      "epoch:30 step:23976[D loss: 0.414609, acc: 60.94%, op_acc: 35.16%] [G loss: 0.907297]\n",
      "epoch:30 step:23977[D loss: 0.419587, acc: 62.50%, op_acc: 38.28%] [G loss: 0.854124]\n",
      "epoch:30 step:23978[D loss: 0.441771, acc: 57.81%, op_acc: 36.72%] [G loss: 1.003495]\n",
      "epoch:30 step:23979[D loss: 0.409759, acc: 57.81%, op_acc: 46.09%] [G loss: 0.829477]\n",
      "epoch:30 step:23980[D loss: 0.437056, acc: 54.69%, op_acc: 46.09%] [G loss: 0.917224]\n",
      "epoch:30 step:23981[D loss: 0.436592, acc: 53.91%, op_acc: 39.06%] [G loss: 0.877115]\n",
      "epoch:30 step:23982[D loss: 0.468887, acc: 53.91%, op_acc: 33.59%] [G loss: 0.868266]\n",
      "epoch:30 step:23983[D loss: 0.430101, acc: 60.16%, op_acc: 43.75%] [G loss: 0.865376]\n",
      "epoch:30 step:23984[D loss: 0.430308, acc: 57.81%, op_acc: 41.41%] [G loss: 0.905117]\n",
      "epoch:30 step:23985[D loss: 0.400124, acc: 60.94%, op_acc: 42.97%] [G loss: 0.846480]\n",
      "epoch:30 step:23986[D loss: 0.414094, acc: 57.81%, op_acc: 41.41%] [G loss: 0.835015]\n",
      "epoch:30 step:23987[D loss: 0.445795, acc: 59.38%, op_acc: 35.16%] [G loss: 0.861093]\n",
      "epoch:30 step:23988[D loss: 0.392814, acc: 67.97%, op_acc: 44.53%] [G loss: 0.868598]\n",
      "epoch:30 step:23989[D loss: 0.414118, acc: 53.91%, op_acc: 45.31%] [G loss: 0.918118]\n",
      "epoch:30 step:23990[D loss: 0.451449, acc: 56.25%, op_acc: 35.94%] [G loss: 0.881792]\n",
      "epoch:30 step:23991[D loss: 0.422942, acc: 53.91%, op_acc: 43.75%] [G loss: 0.873896]\n",
      "epoch:30 step:23992[D loss: 0.454843, acc: 46.09%, op_acc: 35.94%] [G loss: 0.875903]\n",
      "epoch:30 step:23993[D loss: 0.414194, acc: 63.28%, op_acc: 38.28%] [G loss: 0.870595]\n",
      "epoch:30 step:23994[D loss: 0.414563, acc: 59.38%, op_acc: 35.94%] [G loss: 0.920325]\n",
      "epoch:30 step:23995[D loss: 0.432677, acc: 51.56%, op_acc: 44.53%] [G loss: 0.925444]\n",
      "epoch:30 step:23996[D loss: 0.429587, acc: 59.38%, op_acc: 36.72%] [G loss: 0.872637]\n",
      "epoch:30 step:23997[D loss: 0.412169, acc: 57.81%, op_acc: 43.75%] [G loss: 0.893637]\n",
      "epoch:30 step:23998[D loss: 0.411015, acc: 64.84%, op_acc: 39.84%] [G loss: 0.950443]\n",
      "epoch:30 step:23999[D loss: 0.396170, acc: 64.06%, op_acc: 40.62%] [G loss: 0.959602]\n",
      "epoch:30 step:24000[D loss: 0.400092, acc: 66.41%, op_acc: 39.06%] [G loss: 0.956105]\n",
      "##############\n",
      "[0.84937712 0.84421397 0.80591093 0.80022834 0.7851183  0.83717358\n",
      " 0.87117954 0.83090441 0.79234869 0.85443986]\n",
      "##########\n",
      "epoch:30 step:24001[D loss: 0.434039, acc: 58.59%, op_acc: 43.75%] [G loss: 0.875519]\n",
      "epoch:30 step:24002[D loss: 0.404337, acc: 63.28%, op_acc: 39.84%] [G loss: 0.927555]\n",
      "epoch:30 step:24003[D loss: 0.423651, acc: 60.94%, op_acc: 41.41%] [G loss: 0.874293]\n",
      "epoch:30 step:24004[D loss: 0.478507, acc: 49.22%, op_acc: 32.81%] [G loss: 0.899290]\n",
      "epoch:30 step:24005[D loss: 0.436420, acc: 57.81%, op_acc: 32.03%] [G loss: 0.803782]\n",
      "epoch:30 step:24006[D loss: 0.406521, acc: 61.72%, op_acc: 39.84%] [G loss: 0.857356]\n",
      "epoch:30 step:24007[D loss: 0.454874, acc: 58.59%, op_acc: 34.38%] [G loss: 0.806666]\n",
      "epoch:30 step:24008[D loss: 0.481820, acc: 50.00%, op_acc: 34.38%] [G loss: 0.817122]\n",
      "epoch:30 step:24009[D loss: 0.410383, acc: 61.72%, op_acc: 42.97%] [G loss: 0.941095]\n",
      "epoch:30 step:24010[D loss: 0.447862, acc: 59.38%, op_acc: 35.94%] [G loss: 0.827979]\n",
      "epoch:30 step:24011[D loss: 0.452110, acc: 55.47%, op_acc: 35.94%] [G loss: 0.897311]\n",
      "epoch:30 step:24012[D loss: 0.415062, acc: 60.16%, op_acc: 38.28%] [G loss: 0.869878]\n",
      "epoch:30 step:24013[D loss: 0.398552, acc: 63.28%, op_acc: 37.50%] [G loss: 0.900671]\n",
      "epoch:30 step:24014[D loss: 0.471189, acc: 53.12%, op_acc: 32.81%] [G loss: 0.918199]\n",
      "epoch:30 step:24015[D loss: 0.418806, acc: 56.25%, op_acc: 39.84%] [G loss: 0.839286]\n",
      "epoch:30 step:24016[D loss: 0.447059, acc: 57.03%, op_acc: 42.19%] [G loss: 0.871809]\n",
      "epoch:30 step:24017[D loss: 0.405616, acc: 59.38%, op_acc: 34.38%] [G loss: 0.968408]\n",
      "epoch:30 step:24018[D loss: 0.414266, acc: 54.69%, op_acc: 42.97%] [G loss: 0.861292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24019[D loss: 0.435327, acc: 53.91%, op_acc: 36.72%] [G loss: 0.814283]\n",
      "epoch:30 step:24020[D loss: 0.408908, acc: 57.81%, op_acc: 43.75%] [G loss: 0.890847]\n",
      "epoch:30 step:24021[D loss: 0.427028, acc: 58.59%, op_acc: 35.16%] [G loss: 0.907876]\n",
      "epoch:30 step:24022[D loss: 0.431001, acc: 54.69%, op_acc: 39.06%] [G loss: 0.876495]\n",
      "epoch:30 step:24023[D loss: 0.469011, acc: 49.22%, op_acc: 33.59%] [G loss: 0.932988]\n",
      "epoch:30 step:24024[D loss: 0.406890, acc: 62.50%, op_acc: 38.28%] [G loss: 0.904051]\n",
      "epoch:30 step:24025[D loss: 0.409678, acc: 64.84%, op_acc: 40.62%] [G loss: 0.870518]\n",
      "epoch:30 step:24026[D loss: 0.411440, acc: 64.06%, op_acc: 39.84%] [G loss: 0.849976]\n",
      "epoch:30 step:24027[D loss: 0.400627, acc: 63.28%, op_acc: 45.31%] [G loss: 0.813436]\n",
      "epoch:30 step:24028[D loss: 0.421960, acc: 57.03%, op_acc: 38.28%] [G loss: 0.892305]\n",
      "epoch:30 step:24029[D loss: 0.419458, acc: 61.72%, op_acc: 38.28%] [G loss: 0.897865]\n",
      "epoch:30 step:24030[D loss: 0.414641, acc: 63.28%, op_acc: 37.50%] [G loss: 0.879750]\n",
      "epoch:30 step:24031[D loss: 0.433452, acc: 53.91%, op_acc: 41.41%] [G loss: 0.788108]\n",
      "epoch:30 step:24032[D loss: 0.399872, acc: 64.84%, op_acc: 42.97%] [G loss: 0.932558]\n",
      "epoch:30 step:24033[D loss: 0.397058, acc: 59.38%, op_acc: 50.78%] [G loss: 0.903378]\n",
      "epoch:30 step:24034[D loss: 0.423793, acc: 60.16%, op_acc: 36.72%] [G loss: 0.858455]\n",
      "epoch:30 step:24035[D loss: 0.404247, acc: 66.41%, op_acc: 37.50%] [G loss: 0.850362]\n",
      "epoch:30 step:24036[D loss: 0.383043, acc: 67.97%, op_acc: 42.19%] [G loss: 0.926427]\n",
      "epoch:30 step:24037[D loss: 0.441740, acc: 53.91%, op_acc: 36.72%] [G loss: 0.909886]\n",
      "epoch:30 step:24038[D loss: 0.382280, acc: 67.19%, op_acc: 45.31%] [G loss: 0.905875]\n",
      "epoch:30 step:24039[D loss: 0.415200, acc: 62.50%, op_acc: 39.06%] [G loss: 0.851970]\n",
      "epoch:30 step:24040[D loss: 0.406170, acc: 65.62%, op_acc: 40.62%] [G loss: 0.844507]\n",
      "epoch:30 step:24041[D loss: 0.404903, acc: 62.50%, op_acc: 43.75%] [G loss: 0.937967]\n",
      "epoch:30 step:24042[D loss: 0.417304, acc: 57.81%, op_acc: 45.31%] [G loss: 0.841471]\n",
      "epoch:30 step:24043[D loss: 0.414106, acc: 57.81%, op_acc: 43.75%] [G loss: 0.808143]\n",
      "epoch:30 step:24044[D loss: 0.437389, acc: 56.25%, op_acc: 38.28%] [G loss: 0.875371]\n",
      "epoch:30 step:24045[D loss: 0.422188, acc: 55.47%, op_acc: 37.50%] [G loss: 0.911363]\n",
      "epoch:30 step:24046[D loss: 0.438072, acc: 55.47%, op_acc: 39.84%] [G loss: 0.886874]\n",
      "epoch:30 step:24047[D loss: 0.423974, acc: 60.94%, op_acc: 35.94%] [G loss: 0.846237]\n",
      "epoch:30 step:24048[D loss: 0.398741, acc: 62.50%, op_acc: 45.31%] [G loss: 0.952200]\n",
      "epoch:30 step:24049[D loss: 0.440843, acc: 62.50%, op_acc: 37.50%] [G loss: 0.884011]\n",
      "epoch:30 step:24050[D loss: 0.425433, acc: 55.47%, op_acc: 32.81%] [G loss: 0.865301]\n",
      "##############\n",
      "[0.84089072 0.85431965 0.79867026 0.80176564 0.8041178  0.83275188\n",
      " 0.88226816 0.81723031 0.82071431 0.81657135]\n",
      "##########\n",
      "epoch:30 step:24051[D loss: 0.402724, acc: 66.41%, op_acc: 43.75%] [G loss: 0.863856]\n",
      "epoch:30 step:24052[D loss: 0.452190, acc: 58.59%, op_acc: 37.50%] [G loss: 0.857292]\n",
      "epoch:30 step:24053[D loss: 0.375028, acc: 71.09%, op_acc: 46.88%] [G loss: 0.976504]\n",
      "epoch:30 step:24054[D loss: 0.412417, acc: 57.03%, op_acc: 46.09%] [G loss: 0.849960]\n",
      "epoch:30 step:24055[D loss: 0.420760, acc: 64.06%, op_acc: 38.28%] [G loss: 0.884175]\n",
      "epoch:30 step:24056[D loss: 0.406168, acc: 62.50%, op_acc: 42.97%] [G loss: 0.901381]\n",
      "epoch:30 step:24057[D loss: 0.428192, acc: 52.34%, op_acc: 42.97%] [G loss: 0.818500]\n",
      "epoch:30 step:24058[D loss: 0.427061, acc: 61.72%, op_acc: 36.72%] [G loss: 0.875436]\n",
      "epoch:30 step:24059[D loss: 0.439717, acc: 54.69%, op_acc: 36.72%] [G loss: 0.870477]\n",
      "epoch:30 step:24060[D loss: 0.406022, acc: 64.06%, op_acc: 39.06%] [G loss: 0.867663]\n",
      "epoch:30 step:24061[D loss: 0.451471, acc: 51.56%, op_acc: 38.28%] [G loss: 0.915091]\n",
      "epoch:30 step:24062[D loss: 0.436888, acc: 58.59%, op_acc: 36.72%] [G loss: 0.871098]\n",
      "epoch:30 step:24063[D loss: 0.418328, acc: 57.03%, op_acc: 39.84%] [G loss: 0.811618]\n",
      "epoch:30 step:24064[D loss: 0.405358, acc: 62.50%, op_acc: 41.41%] [G loss: 0.846449]\n",
      "epoch:30 step:24065[D loss: 0.420637, acc: 60.94%, op_acc: 39.84%] [G loss: 0.942330]\n",
      "epoch:30 step:24066[D loss: 0.397636, acc: 65.62%, op_acc: 42.19%] [G loss: 0.885410]\n",
      "epoch:30 step:24067[D loss: 0.429760, acc: 54.69%, op_acc: 42.97%] [G loss: 0.895334]\n",
      "epoch:30 step:24068[D loss: 0.455211, acc: 50.00%, op_acc: 37.50%] [G loss: 0.851240]\n",
      "epoch:30 step:24069[D loss: 0.430026, acc: 57.03%, op_acc: 45.31%] [G loss: 0.926936]\n",
      "epoch:30 step:24070[D loss: 0.432478, acc: 55.47%, op_acc: 40.62%] [G loss: 0.935316]\n",
      "epoch:30 step:24071[D loss: 0.423490, acc: 64.84%, op_acc: 35.16%] [G loss: 0.826210]\n",
      "epoch:30 step:24072[D loss: 0.428337, acc: 59.38%, op_acc: 38.28%] [G loss: 0.883847]\n",
      "epoch:30 step:24073[D loss: 0.433295, acc: 60.94%, op_acc: 35.16%] [G loss: 0.939134]\n",
      "epoch:30 step:24074[D loss: 0.394132, acc: 62.50%, op_acc: 46.09%] [G loss: 0.855216]\n",
      "epoch:30 step:24075[D loss: 0.399689, acc: 63.28%, op_acc: 45.31%] [G loss: 0.881072]\n",
      "epoch:30 step:24076[D loss: 0.426581, acc: 57.81%, op_acc: 38.28%] [G loss: 0.874353]\n",
      "epoch:30 step:24077[D loss: 0.414328, acc: 58.59%, op_acc: 38.28%] [G loss: 0.869574]\n",
      "epoch:30 step:24078[D loss: 0.434101, acc: 63.28%, op_acc: 39.06%] [G loss: 0.937481]\n",
      "epoch:30 step:24079[D loss: 0.410104, acc: 67.97%, op_acc: 39.06%] [G loss: 0.857149]\n",
      "epoch:30 step:24080[D loss: 0.436778, acc: 64.84%, op_acc: 41.41%] [G loss: 0.888077]\n",
      "epoch:30 step:24081[D loss: 0.427268, acc: 56.25%, op_acc: 40.62%] [G loss: 0.855751]\n",
      "epoch:30 step:24082[D loss: 0.411000, acc: 57.81%, op_acc: 39.84%] [G loss: 0.821332]\n",
      "epoch:30 step:24083[D loss: 0.422945, acc: 60.16%, op_acc: 41.41%] [G loss: 0.848986]\n",
      "epoch:30 step:24084[D loss: 0.425505, acc: 50.78%, op_acc: 37.50%] [G loss: 0.911780]\n",
      "epoch:30 step:24085[D loss: 0.403911, acc: 61.72%, op_acc: 42.19%] [G loss: 0.852921]\n",
      "epoch:30 step:24086[D loss: 0.419399, acc: 60.16%, op_acc: 42.97%] [G loss: 0.989839]\n",
      "epoch:30 step:24087[D loss: 0.433678, acc: 56.25%, op_acc: 35.94%] [G loss: 0.888146]\n",
      "epoch:30 step:24088[D loss: 0.413036, acc: 64.06%, op_acc: 37.50%] [G loss: 0.913443]\n",
      "epoch:30 step:24089[D loss: 0.435839, acc: 60.94%, op_acc: 39.84%] [G loss: 0.850609]\n",
      "epoch:30 step:24090[D loss: 0.409219, acc: 62.50%, op_acc: 39.06%] [G loss: 0.872667]\n",
      "epoch:30 step:24091[D loss: 0.414925, acc: 57.03%, op_acc: 41.41%] [G loss: 0.774581]\n",
      "epoch:30 step:24092[D loss: 0.408668, acc: 58.59%, op_acc: 43.75%] [G loss: 0.882821]\n",
      "epoch:30 step:24093[D loss: 0.395679, acc: 68.75%, op_acc: 43.75%] [G loss: 0.951836]\n",
      "epoch:30 step:24094[D loss: 0.421300, acc: 57.03%, op_acc: 41.41%] [G loss: 0.860147]\n",
      "epoch:30 step:24095[D loss: 0.438614, acc: 60.94%, op_acc: 34.38%] [G loss: 0.903724]\n",
      "epoch:30 step:24096[D loss: 0.420731, acc: 57.03%, op_acc: 37.50%] [G loss: 0.821587]\n",
      "epoch:30 step:24097[D loss: 0.394145, acc: 61.72%, op_acc: 44.53%] [G loss: 0.904532]\n",
      "epoch:30 step:24098[D loss: 0.441954, acc: 53.91%, op_acc: 40.62%] [G loss: 0.811644]\n",
      "epoch:30 step:24099[D loss: 0.432388, acc: 59.38%, op_acc: 36.72%] [G loss: 0.804596]\n",
      "epoch:30 step:24100[D loss: 0.413156, acc: 55.47%, op_acc: 41.41%] [G loss: 0.905857]\n",
      "##############\n",
      "[0.85658504 0.85657968 0.82289215 0.79166554 0.79228314 0.79921114\n",
      " 0.90024023 0.81005113 0.84979217 0.81597917]\n",
      "##########\n",
      "epoch:30 step:24101[D loss: 0.423930, acc: 61.72%, op_acc: 37.50%] [G loss: 0.903370]\n",
      "epoch:30 step:24102[D loss: 0.442242, acc: 55.47%, op_acc: 38.28%] [G loss: 0.836242]\n",
      "epoch:30 step:24103[D loss: 0.458365, acc: 54.69%, op_acc: 41.41%] [G loss: 0.903905]\n",
      "epoch:30 step:24104[D loss: 0.431998, acc: 51.56%, op_acc: 36.72%] [G loss: 0.846354]\n",
      "epoch:30 step:24105[D loss: 0.399638, acc: 66.41%, op_acc: 43.75%] [G loss: 0.896536]\n",
      "epoch:30 step:24106[D loss: 0.469793, acc: 55.47%, op_acc: 33.59%] [G loss: 0.863727]\n",
      "epoch:30 step:24107[D loss: 0.436772, acc: 63.28%, op_acc: 32.81%] [G loss: 0.870280]\n",
      "epoch:30 step:24108[D loss: 0.435343, acc: 51.56%, op_acc: 42.97%] [G loss: 0.853883]\n",
      "epoch:30 step:24109[D loss: 0.392566, acc: 61.72%, op_acc: 49.22%] [G loss: 0.857747]\n",
      "epoch:30 step:24110[D loss: 0.440500, acc: 58.59%, op_acc: 38.28%] [G loss: 0.847021]\n",
      "epoch:30 step:24111[D loss: 0.427095, acc: 65.62%, op_acc: 38.28%] [G loss: 0.890991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24112[D loss: 0.384990, acc: 70.31%, op_acc: 39.84%] [G loss: 0.941636]\n",
      "epoch:30 step:24113[D loss: 0.404811, acc: 66.41%, op_acc: 37.50%] [G loss: 0.852503]\n",
      "epoch:30 step:24114[D loss: 0.401205, acc: 65.62%, op_acc: 41.41%] [G loss: 0.792862]\n",
      "epoch:30 step:24115[D loss: 0.465896, acc: 47.66%, op_acc: 39.06%] [G loss: 0.800243]\n",
      "epoch:30 step:24116[D loss: 0.439562, acc: 56.25%, op_acc: 36.72%] [G loss: 0.790735]\n",
      "epoch:30 step:24117[D loss: 0.434335, acc: 55.47%, op_acc: 40.62%] [G loss: 0.856734]\n",
      "epoch:30 step:24118[D loss: 0.417960, acc: 53.91%, op_acc: 43.75%] [G loss: 0.905647]\n",
      "epoch:30 step:24119[D loss: 0.453571, acc: 53.12%, op_acc: 36.72%] [G loss: 0.820114]\n",
      "epoch:30 step:24120[D loss: 0.414483, acc: 64.84%, op_acc: 39.84%] [G loss: 0.844789]\n",
      "epoch:30 step:24121[D loss: 0.424780, acc: 57.81%, op_acc: 44.53%] [G loss: 0.890211]\n",
      "epoch:30 step:24122[D loss: 0.444276, acc: 57.03%, op_acc: 38.28%] [G loss: 0.874006]\n",
      "epoch:30 step:24123[D loss: 0.402271, acc: 60.16%, op_acc: 42.19%] [G loss: 0.814736]\n",
      "epoch:30 step:24124[D loss: 0.414359, acc: 60.16%, op_acc: 39.84%] [G loss: 0.864167]\n",
      "epoch:30 step:24125[D loss: 0.420893, acc: 54.69%, op_acc: 37.50%] [G loss: 0.924730]\n",
      "epoch:30 step:24126[D loss: 0.448955, acc: 54.69%, op_acc: 32.03%] [G loss: 0.812521]\n",
      "epoch:30 step:24127[D loss: 0.426663, acc: 63.28%, op_acc: 39.84%] [G loss: 0.871645]\n",
      "epoch:30 step:24128[D loss: 0.417469, acc: 64.06%, op_acc: 43.75%] [G loss: 0.849860]\n",
      "epoch:30 step:24129[D loss: 0.428953, acc: 57.03%, op_acc: 42.19%] [G loss: 0.812148]\n",
      "epoch:30 step:24130[D loss: 0.441063, acc: 46.09%, op_acc: 37.50%] [G loss: 0.835886]\n",
      "epoch:30 step:24131[D loss: 0.453884, acc: 52.34%, op_acc: 39.06%] [G loss: 0.883552]\n",
      "epoch:30 step:24132[D loss: 0.408269, acc: 58.59%, op_acc: 41.41%] [G loss: 0.858162]\n",
      "epoch:30 step:24133[D loss: 0.442993, acc: 54.69%, op_acc: 34.38%] [G loss: 0.820944]\n",
      "epoch:30 step:24134[D loss: 0.409479, acc: 55.47%, op_acc: 46.09%] [G loss: 0.851487]\n",
      "epoch:30 step:24135[D loss: 0.423647, acc: 63.28%, op_acc: 42.19%] [G loss: 0.809964]\n",
      "epoch:30 step:24136[D loss: 0.423947, acc: 58.59%, op_acc: 38.28%] [G loss: 0.889911]\n",
      "epoch:30 step:24137[D loss: 0.449505, acc: 57.81%, op_acc: 39.06%] [G loss: 0.934517]\n",
      "epoch:30 step:24138[D loss: 0.414416, acc: 63.28%, op_acc: 40.62%] [G loss: 0.953180]\n",
      "epoch:30 step:24139[D loss: 0.416868, acc: 57.81%, op_acc: 43.75%] [G loss: 0.875496]\n",
      "epoch:30 step:24140[D loss: 0.398297, acc: 60.94%, op_acc: 43.75%] [G loss: 0.862157]\n",
      "epoch:30 step:24141[D loss: 0.431504, acc: 58.59%, op_acc: 38.28%] [G loss: 0.836960]\n",
      "epoch:30 step:24142[D loss: 0.407136, acc: 58.59%, op_acc: 41.41%] [G loss: 0.792273]\n",
      "epoch:30 step:24143[D loss: 0.408598, acc: 59.38%, op_acc: 45.31%] [G loss: 0.874948]\n",
      "epoch:30 step:24144[D loss: 0.440724, acc: 55.47%, op_acc: 40.62%] [G loss: 0.802597]\n",
      "epoch:30 step:24145[D loss: 0.404746, acc: 62.50%, op_acc: 43.75%] [G loss: 0.858681]\n",
      "epoch:30 step:24146[D loss: 0.407069, acc: 63.28%, op_acc: 46.88%] [G loss: 0.829563]\n",
      "epoch:30 step:24147[D loss: 0.412659, acc: 61.72%, op_acc: 39.06%] [G loss: 0.837364]\n",
      "epoch:30 step:24148[D loss: 0.414214, acc: 58.59%, op_acc: 36.72%] [G loss: 0.856900]\n",
      "epoch:30 step:24149[D loss: 0.446605, acc: 57.03%, op_acc: 37.50%] [G loss: 0.809541]\n",
      "epoch:30 step:24150[D loss: 0.458849, acc: 55.47%, op_acc: 37.50%] [G loss: 0.836524]\n",
      "##############\n",
      "[0.8535885  0.85250178 0.8219354  0.79496882 0.78873136 0.81345931\n",
      " 0.89503011 0.84920652 0.81204653 0.85452258]\n",
      "##########\n",
      "epoch:30 step:24151[D loss: 0.430166, acc: 54.69%, op_acc: 43.75%] [G loss: 0.830893]\n",
      "epoch:30 step:24152[D loss: 0.409994, acc: 63.28%, op_acc: 41.41%] [G loss: 0.854975]\n",
      "epoch:30 step:24153[D loss: 0.393761, acc: 70.31%, op_acc: 37.50%] [G loss: 0.797877]\n",
      "epoch:30 step:24154[D loss: 0.465161, acc: 53.91%, op_acc: 35.16%] [G loss: 0.840291]\n",
      "epoch:30 step:24155[D loss: 0.429104, acc: 53.91%, op_acc: 42.19%] [G loss: 0.853872]\n",
      "epoch:30 step:24156[D loss: 0.386124, acc: 64.06%, op_acc: 39.84%] [G loss: 0.970690]\n",
      "epoch:30 step:24157[D loss: 0.431719, acc: 63.28%, op_acc: 35.16%] [G loss: 0.876688]\n",
      "epoch:30 step:24158[D loss: 0.431070, acc: 56.25%, op_acc: 42.19%] [G loss: 0.846798]\n",
      "epoch:30 step:24159[D loss: 0.437307, acc: 60.94%, op_acc: 33.59%] [G loss: 0.824479]\n",
      "epoch:30 step:24160[D loss: 0.455550, acc: 52.34%, op_acc: 39.84%] [G loss: 0.874483]\n",
      "epoch:30 step:24161[D loss: 0.411222, acc: 60.16%, op_acc: 40.62%] [G loss: 0.919419]\n",
      "epoch:30 step:24162[D loss: 0.417071, acc: 59.38%, op_acc: 41.41%] [G loss: 0.894430]\n",
      "epoch:30 step:24163[D loss: 0.395422, acc: 64.84%, op_acc: 41.41%] [G loss: 0.869415]\n",
      "epoch:30 step:24164[D loss: 0.442996, acc: 57.03%, op_acc: 39.84%] [G loss: 0.881464]\n",
      "epoch:30 step:24165[D loss: 0.440499, acc: 55.47%, op_acc: 40.62%] [G loss: 0.838874]\n",
      "epoch:30 step:24166[D loss: 0.427880, acc: 59.38%, op_acc: 36.72%] [G loss: 0.928064]\n",
      "epoch:30 step:24167[D loss: 0.394612, acc: 58.59%, op_acc: 42.19%] [G loss: 0.826218]\n",
      "epoch:30 step:24168[D loss: 0.425048, acc: 61.72%, op_acc: 44.53%] [G loss: 0.904193]\n",
      "epoch:30 step:24169[D loss: 0.418754, acc: 62.50%, op_acc: 36.72%] [G loss: 0.865806]\n",
      "epoch:30 step:24170[D loss: 0.417689, acc: 59.38%, op_acc: 42.97%] [G loss: 0.830073]\n",
      "epoch:30 step:24171[D loss: 0.443419, acc: 57.81%, op_acc: 35.16%] [G loss: 0.908838]\n",
      "epoch:30 step:24172[D loss: 0.428428, acc: 57.03%, op_acc: 39.84%] [G loss: 0.802737]\n",
      "epoch:30 step:24173[D loss: 0.429548, acc: 55.47%, op_acc: 37.50%] [G loss: 0.863320]\n",
      "epoch:30 step:24174[D loss: 0.386179, acc: 67.19%, op_acc: 47.66%] [G loss: 0.856566]\n",
      "epoch:30 step:24175[D loss: 0.404321, acc: 53.91%, op_acc: 43.75%] [G loss: 0.881976]\n",
      "epoch:30 step:24176[D loss: 0.417410, acc: 53.12%, op_acc: 42.97%] [G loss: 0.876650]\n",
      "epoch:30 step:24177[D loss: 0.414765, acc: 61.72%, op_acc: 39.06%] [G loss: 0.849923]\n",
      "epoch:30 step:24178[D loss: 0.454323, acc: 54.69%, op_acc: 35.94%] [G loss: 0.885129]\n",
      "epoch:30 step:24179[D loss: 0.459145, acc: 53.12%, op_acc: 38.28%] [G loss: 0.775347]\n",
      "epoch:30 step:24180[D loss: 0.428047, acc: 57.81%, op_acc: 38.28%] [G loss: 0.828221]\n",
      "epoch:30 step:24181[D loss: 0.453399, acc: 51.56%, op_acc: 35.94%] [G loss: 0.825036]\n",
      "epoch:30 step:24182[D loss: 0.421512, acc: 56.25%, op_acc: 42.97%] [G loss: 0.823313]\n",
      "epoch:30 step:24183[D loss: 0.435440, acc: 56.25%, op_acc: 36.72%] [G loss: 0.800773]\n",
      "epoch:30 step:24184[D loss: 0.408731, acc: 66.41%, op_acc: 41.41%] [G loss: 0.805896]\n",
      "epoch:30 step:24185[D loss: 0.431778, acc: 54.69%, op_acc: 41.41%] [G loss: 0.884262]\n",
      "epoch:30 step:24186[D loss: 0.420149, acc: 60.94%, op_acc: 40.62%] [G loss: 0.847563]\n",
      "epoch:30 step:24187[D loss: 0.417473, acc: 57.03%, op_acc: 39.84%] [G loss: 0.799220]\n",
      "epoch:30 step:24188[D loss: 0.408131, acc: 53.91%, op_acc: 44.53%] [G loss: 0.843804]\n",
      "epoch:30 step:24189[D loss: 0.412446, acc: 62.50%, op_acc: 42.97%] [G loss: 0.861500]\n",
      "epoch:30 step:24190[D loss: 0.438385, acc: 53.12%, op_acc: 39.06%] [G loss: 0.880916]\n",
      "epoch:30 step:24191[D loss: 0.401913, acc: 66.41%, op_acc: 44.53%] [G loss: 0.831888]\n",
      "epoch:30 step:24192[D loss: 0.449271, acc: 53.12%, op_acc: 36.72%] [G loss: 0.819135]\n",
      "epoch:30 step:24193[D loss: 0.449298, acc: 55.47%, op_acc: 32.81%] [G loss: 0.756946]\n",
      "epoch:30 step:24194[D loss: 0.414006, acc: 57.81%, op_acc: 42.19%] [G loss: 0.757276]\n",
      "epoch:30 step:24195[D loss: 0.423566, acc: 57.81%, op_acc: 43.75%] [G loss: 0.891251]\n",
      "epoch:30 step:24196[D loss: 0.434288, acc: 57.81%, op_acc: 39.06%] [G loss: 0.843894]\n",
      "epoch:30 step:24197[D loss: 0.376655, acc: 72.66%, op_acc: 43.75%] [G loss: 0.868154]\n",
      "epoch:30 step:24198[D loss: 0.403113, acc: 63.28%, op_acc: 40.62%] [G loss: 0.948932]\n",
      "epoch:30 step:24199[D loss: 0.407098, acc: 64.84%, op_acc: 41.41%] [G loss: 0.789699]\n",
      "epoch:30 step:24200[D loss: 0.424233, acc: 57.81%, op_acc: 38.28%] [G loss: 0.917170]\n",
      "##############\n",
      "[0.86149456 0.84402232 0.80937535 0.80275651 0.80326399 0.83329126\n",
      " 0.87811826 0.83409453 0.80025812 0.83520229]\n",
      "##########\n",
      "epoch:30 step:24201[D loss: 0.499469, acc: 41.41%, op_acc: 30.47%] [G loss: 0.879281]\n",
      "epoch:30 step:24202[D loss: 0.423797, acc: 64.84%, op_acc: 37.50%] [G loss: 0.808637]\n",
      "epoch:30 step:24203[D loss: 0.402288, acc: 67.19%, op_acc: 34.38%] [G loss: 0.749093]\n",
      "epoch:30 step:24204[D loss: 0.395022, acc: 60.94%, op_acc: 46.88%] [G loss: 0.845400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24205[D loss: 0.405771, acc: 61.72%, op_acc: 43.75%] [G loss: 0.777037]\n",
      "epoch:30 step:24206[D loss: 0.416770, acc: 60.16%, op_acc: 42.97%] [G loss: 0.914488]\n",
      "epoch:30 step:24207[D loss: 0.438061, acc: 61.72%, op_acc: 37.50%] [G loss: 0.896258]\n",
      "epoch:30 step:24208[D loss: 0.422987, acc: 55.47%, op_acc: 40.62%] [G loss: 0.954985]\n",
      "epoch:30 step:24209[D loss: 0.405690, acc: 59.38%, op_acc: 39.84%] [G loss: 0.873530]\n",
      "epoch:30 step:24210[D loss: 0.416455, acc: 56.25%, op_acc: 40.62%] [G loss: 0.809633]\n",
      "epoch:30 step:24211[D loss: 0.426018, acc: 54.69%, op_acc: 42.19%] [G loss: 0.852139]\n",
      "epoch:31 step:24212[D loss: 0.396300, acc: 64.84%, op_acc: 42.19%] [G loss: 0.912042]\n",
      "epoch:31 step:24213[D loss: 0.436047, acc: 56.25%, op_acc: 39.06%] [G loss: 0.917006]\n",
      "epoch:31 step:24214[D loss: 0.445870, acc: 55.47%, op_acc: 34.38%] [G loss: 0.862240]\n",
      "epoch:31 step:24215[D loss: 0.408180, acc: 51.56%, op_acc: 43.75%] [G loss: 0.822026]\n",
      "epoch:31 step:24216[D loss: 0.409326, acc: 62.50%, op_acc: 44.53%] [G loss: 0.838362]\n",
      "epoch:31 step:24217[D loss: 0.462740, acc: 52.34%, op_acc: 34.38%] [G loss: 0.811572]\n",
      "epoch:31 step:24218[D loss: 0.425276, acc: 57.03%, op_acc: 39.84%] [G loss: 0.911860]\n",
      "epoch:31 step:24219[D loss: 0.432794, acc: 53.91%, op_acc: 38.28%] [G loss: 0.847177]\n",
      "epoch:31 step:24220[D loss: 0.422862, acc: 53.91%, op_acc: 40.62%] [G loss: 0.885630]\n",
      "epoch:31 step:24221[D loss: 0.422593, acc: 66.41%, op_acc: 34.38%] [G loss: 0.881421]\n",
      "epoch:31 step:24222[D loss: 0.431447, acc: 54.69%, op_acc: 41.41%] [G loss: 0.870508]\n",
      "epoch:31 step:24223[D loss: 0.405980, acc: 60.94%, op_acc: 41.41%] [G loss: 0.831478]\n",
      "epoch:31 step:24224[D loss: 0.430233, acc: 59.38%, op_acc: 37.50%] [G loss: 0.935660]\n",
      "epoch:31 step:24225[D loss: 0.449499, acc: 56.25%, op_acc: 32.81%] [G loss: 0.870136]\n",
      "epoch:31 step:24226[D loss: 0.432807, acc: 54.69%, op_acc: 42.97%] [G loss: 0.846208]\n",
      "epoch:31 step:24227[D loss: 0.391851, acc: 60.94%, op_acc: 42.97%] [G loss: 0.929154]\n",
      "epoch:31 step:24228[D loss: 0.430637, acc: 53.91%, op_acc: 39.06%] [G loss: 0.875749]\n",
      "epoch:31 step:24229[D loss: 0.407113, acc: 57.81%, op_acc: 39.84%] [G loss: 0.838958]\n",
      "epoch:31 step:24230[D loss: 0.425186, acc: 57.81%, op_acc: 43.75%] [G loss: 0.804981]\n",
      "epoch:31 step:24231[D loss: 0.376593, acc: 65.62%, op_acc: 43.75%] [G loss: 0.862761]\n",
      "epoch:31 step:24232[D loss: 0.414441, acc: 64.06%, op_acc: 39.84%] [G loss: 0.897187]\n",
      "epoch:31 step:24233[D loss: 0.430914, acc: 50.00%, op_acc: 46.09%] [G loss: 0.870348]\n",
      "epoch:31 step:24234[D loss: 0.426764, acc: 59.38%, op_acc: 37.50%] [G loss: 0.800538]\n",
      "epoch:31 step:24235[D loss: 0.430386, acc: 59.38%, op_acc: 37.50%] [G loss: 0.883224]\n",
      "epoch:31 step:24236[D loss: 0.442100, acc: 60.16%, op_acc: 38.28%] [G loss: 0.868239]\n",
      "epoch:31 step:24237[D loss: 0.408752, acc: 57.03%, op_acc: 40.62%] [G loss: 0.884971]\n",
      "epoch:31 step:24238[D loss: 0.422834, acc: 62.50%, op_acc: 39.84%] [G loss: 0.818829]\n",
      "epoch:31 step:24239[D loss: 0.422044, acc: 55.47%, op_acc: 39.84%] [G loss: 0.918556]\n",
      "epoch:31 step:24240[D loss: 0.404859, acc: 60.94%, op_acc: 42.97%] [G loss: 0.874111]\n",
      "epoch:31 step:24241[D loss: 0.427284, acc: 54.69%, op_acc: 40.62%] [G loss: 0.924488]\n",
      "epoch:31 step:24242[D loss: 0.430580, acc: 61.72%, op_acc: 37.50%] [G loss: 0.952668]\n",
      "epoch:31 step:24243[D loss: 0.410556, acc: 61.72%, op_acc: 37.50%] [G loss: 0.890284]\n",
      "epoch:31 step:24244[D loss: 0.403596, acc: 57.03%, op_acc: 44.53%] [G loss: 0.932962]\n",
      "epoch:31 step:24245[D loss: 0.441066, acc: 51.56%, op_acc: 43.75%] [G loss: 0.806269]\n",
      "epoch:31 step:24246[D loss: 0.423271, acc: 60.94%, op_acc: 42.97%] [G loss: 0.889628]\n",
      "epoch:31 step:24247[D loss: 0.423770, acc: 55.47%, op_acc: 41.41%] [G loss: 0.761032]\n",
      "epoch:31 step:24248[D loss: 0.415931, acc: 58.59%, op_acc: 41.41%] [G loss: 0.878419]\n",
      "epoch:31 step:24249[D loss: 0.402917, acc: 62.50%, op_acc: 39.84%] [G loss: 0.894949]\n",
      "epoch:31 step:24250[D loss: 0.397981, acc: 64.06%, op_acc: 42.97%] [G loss: 0.891596]\n",
      "##############\n",
      "[0.85338047 0.8515877  0.82831045 0.79267471 0.80045134 0.82617699\n",
      " 0.89976967 0.83136277 0.80063442 0.82870695]\n",
      "##########\n",
      "epoch:31 step:24251[D loss: 0.428601, acc: 62.50%, op_acc: 38.28%] [G loss: 0.909936]\n",
      "epoch:31 step:24252[D loss: 0.414318, acc: 59.38%, op_acc: 42.19%] [G loss: 0.889698]\n",
      "epoch:31 step:24253[D loss: 0.390130, acc: 63.28%, op_acc: 41.41%] [G loss: 0.929886]\n",
      "epoch:31 step:24254[D loss: 0.426199, acc: 62.50%, op_acc: 35.94%] [G loss: 0.942986]\n",
      "epoch:31 step:24255[D loss: 0.423211, acc: 54.69%, op_acc: 40.62%] [G loss: 0.911297]\n",
      "epoch:31 step:24256[D loss: 0.427981, acc: 58.59%, op_acc: 39.84%] [G loss: 0.860231]\n",
      "epoch:31 step:24257[D loss: 0.422976, acc: 57.03%, op_acc: 39.06%] [G loss: 0.909386]\n",
      "epoch:31 step:24258[D loss: 0.447963, acc: 53.12%, op_acc: 34.38%] [G loss: 0.889418]\n",
      "epoch:31 step:24259[D loss: 0.406479, acc: 66.41%, op_acc: 37.50%] [G loss: 0.922180]\n",
      "epoch:31 step:24260[D loss: 0.437392, acc: 58.59%, op_acc: 39.84%] [G loss: 0.830378]\n",
      "epoch:31 step:24261[D loss: 0.408198, acc: 67.97%, op_acc: 39.06%] [G loss: 0.906227]\n",
      "epoch:31 step:24262[D loss: 0.402896, acc: 62.50%, op_acc: 39.84%] [G loss: 0.879297]\n",
      "epoch:31 step:24263[D loss: 0.411563, acc: 60.94%, op_acc: 40.62%] [G loss: 0.916372]\n",
      "epoch:31 step:24264[D loss: 0.448328, acc: 54.69%, op_acc: 35.94%] [G loss: 0.928231]\n",
      "epoch:31 step:24265[D loss: 0.429882, acc: 60.94%, op_acc: 42.97%] [G loss: 0.953268]\n",
      "epoch:31 step:24266[D loss: 0.382771, acc: 69.53%, op_acc: 39.84%] [G loss: 0.927162]\n",
      "epoch:31 step:24267[D loss: 0.417677, acc: 62.50%, op_acc: 38.28%] [G loss: 0.916223]\n",
      "epoch:31 step:24268[D loss: 0.422808, acc: 60.16%, op_acc: 42.97%] [G loss: 0.922495]\n",
      "epoch:31 step:24269[D loss: 0.416102, acc: 57.81%, op_acc: 41.41%] [G loss: 0.871681]\n",
      "epoch:31 step:24270[D loss: 0.398472, acc: 58.59%, op_acc: 36.72%] [G loss: 0.876136]\n",
      "epoch:31 step:24271[D loss: 0.392201, acc: 66.41%, op_acc: 39.84%] [G loss: 0.873704]\n",
      "epoch:31 step:24272[D loss: 0.418584, acc: 57.81%, op_acc: 42.19%] [G loss: 0.826502]\n",
      "epoch:31 step:24273[D loss: 0.415633, acc: 56.25%, op_acc: 40.62%] [G loss: 0.872692]\n",
      "epoch:31 step:24274[D loss: 0.441625, acc: 52.34%, op_acc: 41.41%] [G loss: 0.882520]\n",
      "epoch:31 step:24275[D loss: 0.420275, acc: 62.50%, op_acc: 40.62%] [G loss: 0.831002]\n",
      "epoch:31 step:24276[D loss: 0.413829, acc: 60.94%, op_acc: 39.84%] [G loss: 0.804747]\n",
      "epoch:31 step:24277[D loss: 0.426724, acc: 55.47%, op_acc: 40.62%] [G loss: 0.856411]\n",
      "epoch:31 step:24278[D loss: 0.426192, acc: 57.03%, op_acc: 46.88%] [G loss: 0.838468]\n",
      "epoch:31 step:24279[D loss: 0.424167, acc: 59.38%, op_acc: 42.97%] [G loss: 0.885236]\n",
      "epoch:31 step:24280[D loss: 0.396503, acc: 60.94%, op_acc: 46.09%] [G loss: 0.906931]\n",
      "epoch:31 step:24281[D loss: 0.424285, acc: 55.47%, op_acc: 42.19%] [G loss: 0.852063]\n",
      "epoch:31 step:24282[D loss: 0.460048, acc: 59.38%, op_acc: 32.03%] [G loss: 0.818155]\n",
      "epoch:31 step:24283[D loss: 0.429751, acc: 54.69%, op_acc: 42.97%] [G loss: 0.901881]\n",
      "epoch:31 step:24284[D loss: 0.415743, acc: 57.81%, op_acc: 43.75%] [G loss: 0.842475]\n",
      "epoch:31 step:24285[D loss: 0.394721, acc: 58.59%, op_acc: 45.31%] [G loss: 0.854642]\n",
      "epoch:31 step:24286[D loss: 0.366669, acc: 71.09%, op_acc: 39.84%] [G loss: 0.988307]\n",
      "epoch:31 step:24287[D loss: 0.455348, acc: 53.91%, op_acc: 40.62%] [G loss: 0.830905]\n",
      "epoch:31 step:24288[D loss: 0.403310, acc: 64.06%, op_acc: 40.62%] [G loss: 0.799185]\n",
      "epoch:31 step:24289[D loss: 0.457707, acc: 53.91%, op_acc: 35.16%] [G loss: 0.757363]\n",
      "epoch:31 step:24290[D loss: 0.443434, acc: 58.59%, op_acc: 38.28%] [G loss: 0.886462]\n",
      "epoch:31 step:24291[D loss: 0.441534, acc: 57.81%, op_acc: 32.81%] [G loss: 0.840756]\n",
      "epoch:31 step:24292[D loss: 0.418965, acc: 61.72%, op_acc: 39.06%] [G loss: 0.949260]\n",
      "epoch:31 step:24293[D loss: 0.403172, acc: 69.53%, op_acc: 39.06%] [G loss: 0.964788]\n",
      "epoch:31 step:24294[D loss: 0.424716, acc: 63.28%, op_acc: 39.06%] [G loss: 0.841494]\n",
      "epoch:31 step:24295[D loss: 0.402053, acc: 63.28%, op_acc: 46.09%] [G loss: 0.980893]\n",
      "epoch:31 step:24296[D loss: 0.452335, acc: 56.25%, op_acc: 35.16%] [G loss: 0.891990]\n",
      "epoch:31 step:24297[D loss: 0.416783, acc: 61.72%, op_acc: 39.06%] [G loss: 0.910842]\n",
      "epoch:31 step:24298[D loss: 0.405553, acc: 62.50%, op_acc: 42.97%] [G loss: 0.954344]\n",
      "epoch:31 step:24299[D loss: 0.436220, acc: 53.91%, op_acc: 39.06%] [G loss: 0.812115]\n",
      "epoch:31 step:24300[D loss: 0.454150, acc: 51.56%, op_acc: 37.50%] [G loss: 0.861995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.85408852 0.88250575 0.81953513 0.77942119 0.82180789 0.83556503\n",
      " 0.8834066  0.82409407 0.79113832 0.8267963 ]\n",
      "##########\n",
      "epoch:31 step:24301[D loss: 0.438314, acc: 53.12%, op_acc: 40.62%] [G loss: 0.888545]\n",
      "epoch:31 step:24302[D loss: 0.412735, acc: 58.59%, op_acc: 45.31%] [G loss: 0.876991]\n",
      "epoch:31 step:24303[D loss: 0.460371, acc: 50.00%, op_acc: 32.81%] [G loss: 0.851190]\n",
      "epoch:31 step:24304[D loss: 0.401541, acc: 66.41%, op_acc: 39.84%] [G loss: 0.786207]\n",
      "epoch:31 step:24305[D loss: 0.444747, acc: 53.91%, op_acc: 45.31%] [G loss: 0.854115]\n",
      "epoch:31 step:24306[D loss: 0.417477, acc: 60.94%, op_acc: 40.62%] [G loss: 0.852437]\n",
      "epoch:31 step:24307[D loss: 0.455176, acc: 56.25%, op_acc: 36.72%] [G loss: 0.812688]\n",
      "epoch:31 step:24308[D loss: 0.424572, acc: 52.34%, op_acc: 39.06%] [G loss: 0.919393]\n",
      "epoch:31 step:24309[D loss: 0.436678, acc: 56.25%, op_acc: 37.50%] [G loss: 0.877788]\n",
      "epoch:31 step:24310[D loss: 0.391905, acc: 61.72%, op_acc: 44.53%] [G loss: 0.885006]\n",
      "epoch:31 step:24311[D loss: 0.410804, acc: 59.38%, op_acc: 42.97%] [G loss: 0.780947]\n",
      "epoch:31 step:24312[D loss: 0.408545, acc: 62.50%, op_acc: 40.62%] [G loss: 0.882255]\n",
      "epoch:31 step:24313[D loss: 0.431789, acc: 51.56%, op_acc: 39.84%] [G loss: 0.879144]\n",
      "epoch:31 step:24314[D loss: 0.414735, acc: 60.16%, op_acc: 35.94%] [G loss: 0.833570]\n",
      "epoch:31 step:24315[D loss: 0.407477, acc: 56.25%, op_acc: 44.53%] [G loss: 0.861777]\n",
      "epoch:31 step:24316[D loss: 0.413255, acc: 65.62%, op_acc: 38.28%] [G loss: 0.938213]\n",
      "epoch:31 step:24317[D loss: 0.443898, acc: 51.56%, op_acc: 45.31%] [G loss: 0.798765]\n",
      "epoch:31 step:24318[D loss: 0.429056, acc: 58.59%, op_acc: 39.84%] [G loss: 0.863991]\n",
      "epoch:31 step:24319[D loss: 0.417285, acc: 56.25%, op_acc: 43.75%] [G loss: 0.959125]\n",
      "epoch:31 step:24320[D loss: 0.414126, acc: 59.38%, op_acc: 39.84%] [G loss: 0.896314]\n",
      "epoch:31 step:24321[D loss: 0.434988, acc: 53.12%, op_acc: 41.41%] [G loss: 0.868616]\n",
      "epoch:31 step:24322[D loss: 0.432169, acc: 56.25%, op_acc: 36.72%] [G loss: 0.780997]\n",
      "epoch:31 step:24323[D loss: 0.432820, acc: 57.81%, op_acc: 39.84%] [G loss: 0.891072]\n",
      "epoch:31 step:24324[D loss: 0.443711, acc: 52.34%, op_acc: 43.75%] [G loss: 0.941844]\n",
      "epoch:31 step:24325[D loss: 0.369771, acc: 65.62%, op_acc: 49.22%] [G loss: 0.952183]\n",
      "epoch:31 step:24326[D loss: 0.422857, acc: 50.78%, op_acc: 45.31%] [G loss: 0.893504]\n",
      "epoch:31 step:24327[D loss: 0.426236, acc: 60.16%, op_acc: 39.06%] [G loss: 0.827730]\n",
      "epoch:31 step:24328[D loss: 0.393511, acc: 58.59%, op_acc: 44.53%] [G loss: 0.861366]\n",
      "epoch:31 step:24329[D loss: 0.455882, acc: 45.31%, op_acc: 39.06%] [G loss: 0.854534]\n",
      "epoch:31 step:24330[D loss: 0.399435, acc: 53.12%, op_acc: 42.97%] [G loss: 0.888706]\n",
      "epoch:31 step:24331[D loss: 0.431362, acc: 54.69%, op_acc: 42.97%] [G loss: 0.802891]\n",
      "epoch:31 step:24332[D loss: 0.398708, acc: 69.53%, op_acc: 46.09%] [G loss: 0.896270]\n",
      "epoch:31 step:24333[D loss: 0.440772, acc: 50.78%, op_acc: 37.50%] [G loss: 0.901206]\n",
      "epoch:31 step:24334[D loss: 0.420632, acc: 60.94%, op_acc: 39.84%] [G loss: 0.868078]\n",
      "epoch:31 step:24335[D loss: 0.420656, acc: 54.69%, op_acc: 43.75%] [G loss: 0.880971]\n",
      "epoch:31 step:24336[D loss: 0.455261, acc: 57.03%, op_acc: 35.94%] [G loss: 0.818242]\n",
      "epoch:31 step:24337[D loss: 0.412723, acc: 65.62%, op_acc: 42.19%] [G loss: 0.886775]\n",
      "epoch:31 step:24338[D loss: 0.403515, acc: 60.16%, op_acc: 43.75%] [G loss: 0.850122]\n",
      "epoch:31 step:24339[D loss: 0.399579, acc: 60.94%, op_acc: 42.19%] [G loss: 0.905331]\n",
      "epoch:31 step:24340[D loss: 0.410855, acc: 64.06%, op_acc: 38.28%] [G loss: 0.879023]\n",
      "epoch:31 step:24341[D loss: 0.423854, acc: 54.69%, op_acc: 35.94%] [G loss: 0.872463]\n",
      "epoch:31 step:24342[D loss: 0.435051, acc: 54.69%, op_acc: 34.38%] [G loss: 0.845683]\n",
      "epoch:31 step:24343[D loss: 0.381235, acc: 64.06%, op_acc: 45.31%] [G loss: 0.855089]\n",
      "epoch:31 step:24344[D loss: 0.428372, acc: 66.41%, op_acc: 32.03%] [G loss: 0.873901]\n",
      "epoch:31 step:24345[D loss: 0.411317, acc: 62.50%, op_acc: 40.62%] [G loss: 0.955644]\n",
      "epoch:31 step:24346[D loss: 0.443274, acc: 56.25%, op_acc: 46.88%] [G loss: 0.882619]\n",
      "epoch:31 step:24347[D loss: 0.402478, acc: 63.28%, op_acc: 42.19%] [G loss: 0.899627]\n",
      "epoch:31 step:24348[D loss: 0.424555, acc: 60.16%, op_acc: 39.84%] [G loss: 0.853190]\n",
      "epoch:31 step:24349[D loss: 0.451057, acc: 49.22%, op_acc: 39.84%] [G loss: 0.862502]\n",
      "epoch:31 step:24350[D loss: 0.431282, acc: 56.25%, op_acc: 45.31%] [G loss: 0.941081]\n",
      "##############\n",
      "[0.86804081 0.86607894 0.81359147 0.81486088 0.81933076 0.83897542\n",
      " 0.870152   0.82890031 0.82568359 0.82845707]\n",
      "##########\n",
      "epoch:31 step:24351[D loss: 0.435006, acc: 62.50%, op_acc: 34.38%] [G loss: 0.864733]\n",
      "epoch:31 step:24352[D loss: 0.427308, acc: 62.50%, op_acc: 35.94%] [G loss: 0.876816]\n",
      "epoch:31 step:24353[D loss: 0.404386, acc: 58.59%, op_acc: 40.62%] [G loss: 0.864753]\n",
      "epoch:31 step:24354[D loss: 0.415994, acc: 57.03%, op_acc: 42.19%] [G loss: 0.832688]\n",
      "epoch:31 step:24355[D loss: 0.431279, acc: 54.69%, op_acc: 37.50%] [G loss: 0.907148]\n",
      "epoch:31 step:24356[D loss: 0.439753, acc: 53.12%, op_acc: 39.84%] [G loss: 0.877789]\n",
      "epoch:31 step:24357[D loss: 0.394639, acc: 64.06%, op_acc: 45.31%] [G loss: 0.982230]\n",
      "epoch:31 step:24358[D loss: 0.432884, acc: 56.25%, op_acc: 44.53%] [G loss: 0.815917]\n",
      "epoch:31 step:24359[D loss: 0.426300, acc: 60.94%, op_acc: 39.06%] [G loss: 0.987198]\n",
      "epoch:31 step:24360[D loss: 0.389216, acc: 63.28%, op_acc: 47.66%] [G loss: 0.791366]\n",
      "epoch:31 step:24361[D loss: 0.406827, acc: 62.50%, op_acc: 42.19%] [G loss: 0.798330]\n",
      "epoch:31 step:24362[D loss: 0.397142, acc: 60.16%, op_acc: 43.75%] [G loss: 0.895818]\n",
      "epoch:31 step:24363[D loss: 0.416026, acc: 60.94%, op_acc: 41.41%] [G loss: 0.901171]\n",
      "epoch:31 step:24364[D loss: 0.438516, acc: 54.69%, op_acc: 43.75%] [G loss: 0.822152]\n",
      "epoch:31 step:24365[D loss: 0.462094, acc: 44.53%, op_acc: 39.84%] [G loss: 0.846545]\n",
      "epoch:31 step:24366[D loss: 0.427316, acc: 53.12%, op_acc: 35.16%] [G loss: 0.866997]\n",
      "epoch:31 step:24367[D loss: 0.415097, acc: 62.50%, op_acc: 40.62%] [G loss: 0.915591]\n",
      "epoch:31 step:24368[D loss: 0.422556, acc: 59.38%, op_acc: 37.50%] [G loss: 0.898249]\n",
      "epoch:31 step:24369[D loss: 0.384814, acc: 67.19%, op_acc: 44.53%] [G loss: 0.901106]\n",
      "epoch:31 step:24370[D loss: 0.426110, acc: 55.47%, op_acc: 42.19%] [G loss: 0.937369]\n",
      "epoch:31 step:24371[D loss: 0.426250, acc: 59.38%, op_acc: 40.62%] [G loss: 0.877788]\n",
      "epoch:31 step:24372[D loss: 0.429436, acc: 53.12%, op_acc: 41.41%] [G loss: 0.957384]\n",
      "epoch:31 step:24373[D loss: 0.411293, acc: 58.59%, op_acc: 42.19%] [G loss: 0.920649]\n",
      "epoch:31 step:24374[D loss: 0.444315, acc: 53.91%, op_acc: 39.84%] [G loss: 0.788128]\n",
      "epoch:31 step:24375[D loss: 0.419652, acc: 65.62%, op_acc: 33.59%] [G loss: 0.937426]\n",
      "epoch:31 step:24376[D loss: 0.406080, acc: 63.28%, op_acc: 40.62%] [G loss: 0.846613]\n",
      "epoch:31 step:24377[D loss: 0.405542, acc: 65.62%, op_acc: 42.97%] [G loss: 0.955213]\n",
      "epoch:31 step:24378[D loss: 0.424221, acc: 60.16%, op_acc: 42.19%] [G loss: 0.941590]\n",
      "epoch:31 step:24379[D loss: 0.421183, acc: 57.81%, op_acc: 42.19%] [G loss: 0.913837]\n",
      "epoch:31 step:24380[D loss: 0.420264, acc: 61.72%, op_acc: 45.31%] [G loss: 0.852331]\n",
      "epoch:31 step:24381[D loss: 0.406431, acc: 60.94%, op_acc: 48.44%] [G loss: 0.932690]\n",
      "epoch:31 step:24382[D loss: 0.445810, acc: 57.81%, op_acc: 32.81%] [G loss: 0.894839]\n",
      "epoch:31 step:24383[D loss: 0.397194, acc: 64.06%, op_acc: 41.41%] [G loss: 0.947502]\n",
      "epoch:31 step:24384[D loss: 0.442710, acc: 60.16%, op_acc: 35.16%] [G loss: 0.895287]\n",
      "epoch:31 step:24385[D loss: 0.473869, acc: 51.56%, op_acc: 38.28%] [G loss: 0.826020]\n",
      "epoch:31 step:24386[D loss: 0.416707, acc: 60.94%, op_acc: 39.84%] [G loss: 0.925905]\n",
      "epoch:31 step:24387[D loss: 0.445500, acc: 50.78%, op_acc: 40.62%] [G loss: 0.862726]\n",
      "epoch:31 step:24388[D loss: 0.408404, acc: 57.81%, op_acc: 41.41%] [G loss: 0.871124]\n",
      "epoch:31 step:24389[D loss: 0.427629, acc: 64.84%, op_acc: 41.41%] [G loss: 0.906171]\n",
      "epoch:31 step:24390[D loss: 0.406912, acc: 61.72%, op_acc: 41.41%] [G loss: 0.872686]\n",
      "epoch:31 step:24391[D loss: 0.422003, acc: 62.50%, op_acc: 38.28%] [G loss: 0.925376]\n",
      "epoch:31 step:24392[D loss: 0.379584, acc: 62.50%, op_acc: 41.41%] [G loss: 0.905192]\n",
      "epoch:31 step:24393[D loss: 0.410062, acc: 60.94%, op_acc: 37.50%] [G loss: 0.830198]\n",
      "epoch:31 step:24394[D loss: 0.405063, acc: 62.50%, op_acc: 44.53%] [G loss: 0.862335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24395[D loss: 0.430502, acc: 57.03%, op_acc: 37.50%] [G loss: 0.902329]\n",
      "epoch:31 step:24396[D loss: 0.438605, acc: 62.50%, op_acc: 33.59%] [G loss: 0.944355]\n",
      "epoch:31 step:24397[D loss: 0.415219, acc: 58.59%, op_acc: 39.84%] [G loss: 0.876378]\n",
      "epoch:31 step:24398[D loss: 0.423659, acc: 57.81%, op_acc: 42.97%] [G loss: 0.955763]\n",
      "epoch:31 step:24399[D loss: 0.392804, acc: 65.62%, op_acc: 42.19%] [G loss: 0.885868]\n",
      "epoch:31 step:24400[D loss: 0.423300, acc: 63.28%, op_acc: 37.50%] [G loss: 0.950491]\n",
      "##############\n",
      "[0.8572003  0.85615378 0.82156202 0.81924096 0.78368572 0.82587284\n",
      " 0.88633025 0.83112395 0.83218374 0.83675221]\n",
      "##########\n",
      "epoch:31 step:24401[D loss: 0.442848, acc: 61.72%, op_acc: 36.72%] [G loss: 0.905355]\n",
      "epoch:31 step:24402[D loss: 0.442109, acc: 56.25%, op_acc: 39.06%] [G loss: 0.848116]\n",
      "epoch:31 step:24403[D loss: 0.416144, acc: 57.81%, op_acc: 39.84%] [G loss: 0.859322]\n",
      "epoch:31 step:24404[D loss: 0.440210, acc: 57.81%, op_acc: 39.06%] [G loss: 0.942035]\n",
      "epoch:31 step:24405[D loss: 0.423205, acc: 59.38%, op_acc: 39.84%] [G loss: 0.871919]\n",
      "epoch:31 step:24406[D loss: 0.436829, acc: 53.12%, op_acc: 37.50%] [G loss: 0.900759]\n",
      "epoch:31 step:24407[D loss: 0.415742, acc: 58.59%, op_acc: 39.06%] [G loss: 0.858961]\n",
      "epoch:31 step:24408[D loss: 0.430712, acc: 60.94%, op_acc: 37.50%] [G loss: 0.852109]\n",
      "epoch:31 step:24409[D loss: 0.440174, acc: 59.38%, op_acc: 33.59%] [G loss: 0.868031]\n",
      "epoch:31 step:24410[D loss: 0.412692, acc: 54.69%, op_acc: 39.84%] [G loss: 0.848769]\n",
      "epoch:31 step:24411[D loss: 0.425558, acc: 59.38%, op_acc: 43.75%] [G loss: 0.879831]\n",
      "epoch:31 step:24412[D loss: 0.412178, acc: 60.16%, op_acc: 39.06%] [G loss: 0.934454]\n",
      "epoch:31 step:24413[D loss: 0.438542, acc: 63.28%, op_acc: 36.72%] [G loss: 0.820922]\n",
      "epoch:31 step:24414[D loss: 0.434273, acc: 64.84%, op_acc: 40.62%] [G loss: 0.865869]\n",
      "epoch:31 step:24415[D loss: 0.428618, acc: 60.16%, op_acc: 36.72%] [G loss: 0.845026]\n",
      "epoch:31 step:24416[D loss: 0.406467, acc: 64.84%, op_acc: 39.84%] [G loss: 0.845707]\n",
      "epoch:31 step:24417[D loss: 0.434637, acc: 57.81%, op_acc: 37.50%] [G loss: 0.810328]\n",
      "epoch:31 step:24418[D loss: 0.381524, acc: 68.75%, op_acc: 44.53%] [G loss: 0.933236]\n",
      "epoch:31 step:24419[D loss: 0.433168, acc: 60.16%, op_acc: 36.72%] [G loss: 0.894345]\n",
      "epoch:31 step:24420[D loss: 0.424001, acc: 56.25%, op_acc: 42.19%] [G loss: 0.806930]\n",
      "epoch:31 step:24421[D loss: 0.439787, acc: 64.84%, op_acc: 35.94%] [G loss: 0.985227]\n",
      "epoch:31 step:24422[D loss: 0.400974, acc: 61.72%, op_acc: 48.44%] [G loss: 0.907442]\n",
      "epoch:31 step:24423[D loss: 0.406361, acc: 63.28%, op_acc: 40.62%] [G loss: 0.897789]\n",
      "epoch:31 step:24424[D loss: 0.418897, acc: 58.59%, op_acc: 46.09%] [G loss: 0.916313]\n",
      "epoch:31 step:24425[D loss: 0.442831, acc: 57.81%, op_acc: 39.06%] [G loss: 0.878445]\n",
      "epoch:31 step:24426[D loss: 0.449100, acc: 57.81%, op_acc: 35.94%] [G loss: 0.872685]\n",
      "epoch:31 step:24427[D loss: 0.462759, acc: 50.78%, op_acc: 34.38%] [G loss: 0.805981]\n",
      "epoch:31 step:24428[D loss: 0.409713, acc: 64.84%, op_acc: 44.53%] [G loss: 0.913094]\n",
      "epoch:31 step:24429[D loss: 0.402995, acc: 63.28%, op_acc: 40.62%] [G loss: 0.851589]\n",
      "epoch:31 step:24430[D loss: 0.421984, acc: 53.12%, op_acc: 46.09%] [G loss: 0.825626]\n",
      "epoch:31 step:24431[D loss: 0.443161, acc: 54.69%, op_acc: 35.94%] [G loss: 0.815793]\n",
      "epoch:31 step:24432[D loss: 0.397790, acc: 64.84%, op_acc: 39.06%] [G loss: 0.874518]\n",
      "epoch:31 step:24433[D loss: 0.393692, acc: 65.62%, op_acc: 42.19%] [G loss: 0.798774]\n",
      "epoch:31 step:24434[D loss: 0.428815, acc: 55.47%, op_acc: 35.16%] [G loss: 0.848803]\n",
      "epoch:31 step:24435[D loss: 0.419545, acc: 58.59%, op_acc: 41.41%] [G loss: 0.870948]\n",
      "epoch:31 step:24436[D loss: 0.429229, acc: 56.25%, op_acc: 41.41%] [G loss: 0.786652]\n",
      "epoch:31 step:24437[D loss: 0.442016, acc: 54.69%, op_acc: 36.72%] [G loss: 0.811483]\n",
      "epoch:31 step:24438[D loss: 0.409327, acc: 56.25%, op_acc: 41.41%] [G loss: 0.864396]\n",
      "epoch:31 step:24439[D loss: 0.430696, acc: 57.03%, op_acc: 36.72%] [G loss: 0.793496]\n",
      "epoch:31 step:24440[D loss: 0.428023, acc: 59.38%, op_acc: 37.50%] [G loss: 0.858384]\n",
      "epoch:31 step:24441[D loss: 0.413801, acc: 67.97%, op_acc: 35.16%] [G loss: 0.830390]\n",
      "epoch:31 step:24442[D loss: 0.404395, acc: 60.16%, op_acc: 44.53%] [G loss: 0.857319]\n",
      "epoch:31 step:24443[D loss: 0.435180, acc: 57.03%, op_acc: 40.62%] [G loss: 0.913019]\n",
      "epoch:31 step:24444[D loss: 0.404956, acc: 57.81%, op_acc: 44.53%] [G loss: 0.926334]\n",
      "epoch:31 step:24445[D loss: 0.439106, acc: 64.06%, op_acc: 39.84%] [G loss: 0.877516]\n",
      "epoch:31 step:24446[D loss: 0.414528, acc: 60.16%, op_acc: 42.19%] [G loss: 0.902959]\n",
      "epoch:31 step:24447[D loss: 0.425708, acc: 57.03%, op_acc: 42.19%] [G loss: 0.848758]\n",
      "epoch:31 step:24448[D loss: 0.396479, acc: 64.84%, op_acc: 42.19%] [G loss: 0.928593]\n",
      "epoch:31 step:24449[D loss: 0.429995, acc: 57.03%, op_acc: 42.97%] [G loss: 0.847126]\n",
      "epoch:31 step:24450[D loss: 0.436222, acc: 55.47%, op_acc: 35.94%] [G loss: 0.926362]\n",
      "##############\n",
      "[0.86715737 0.8377117  0.82621387 0.80699934 0.81970162 0.82316556\n",
      " 0.87946764 0.8065904  0.82942692 0.83645925]\n",
      "##########\n",
      "epoch:31 step:24451[D loss: 0.445062, acc: 51.56%, op_acc: 40.62%] [G loss: 0.868173]\n",
      "epoch:31 step:24452[D loss: 0.400697, acc: 64.84%, op_acc: 38.28%] [G loss: 0.855841]\n",
      "epoch:31 step:24453[D loss: 0.402173, acc: 61.72%, op_acc: 46.88%] [G loss: 0.912933]\n",
      "epoch:31 step:24454[D loss: 0.423837, acc: 51.56%, op_acc: 42.19%] [G loss: 0.874808]\n",
      "epoch:31 step:24455[D loss: 0.440786, acc: 53.12%, op_acc: 41.41%] [G loss: 0.874949]\n",
      "epoch:31 step:24456[D loss: 0.430861, acc: 53.12%, op_acc: 35.94%] [G loss: 0.826228]\n",
      "epoch:31 step:24457[D loss: 0.410554, acc: 57.81%, op_acc: 39.06%] [G loss: 0.926018]\n",
      "epoch:31 step:24458[D loss: 0.398360, acc: 65.62%, op_acc: 44.53%] [G loss: 0.938230]\n",
      "epoch:31 step:24459[D loss: 0.445437, acc: 51.56%, op_acc: 38.28%] [G loss: 0.936905]\n",
      "epoch:31 step:24460[D loss: 0.402382, acc: 68.75%, op_acc: 42.97%] [G loss: 0.890022]\n",
      "epoch:31 step:24461[D loss: 0.451269, acc: 57.81%, op_acc: 35.94%] [G loss: 0.848788]\n",
      "epoch:31 step:24462[D loss: 0.420507, acc: 59.38%, op_acc: 45.31%] [G loss: 0.820437]\n",
      "epoch:31 step:24463[D loss: 0.392144, acc: 64.84%, op_acc: 41.41%] [G loss: 0.919226]\n",
      "epoch:31 step:24464[D loss: 0.443664, acc: 53.12%, op_acc: 38.28%] [G loss: 0.876109]\n",
      "epoch:31 step:24465[D loss: 0.452600, acc: 52.34%, op_acc: 37.50%] [G loss: 0.813346]\n",
      "epoch:31 step:24466[D loss: 0.432489, acc: 59.38%, op_acc: 37.50%] [G loss: 0.813896]\n",
      "epoch:31 step:24467[D loss: 0.409462, acc: 59.38%, op_acc: 47.66%] [G loss: 0.843183]\n",
      "epoch:31 step:24468[D loss: 0.394919, acc: 61.72%, op_acc: 44.53%] [G loss: 0.927517]\n",
      "epoch:31 step:24469[D loss: 0.454658, acc: 51.56%, op_acc: 38.28%] [G loss: 0.864113]\n",
      "epoch:31 step:24470[D loss: 0.455792, acc: 50.78%, op_acc: 35.16%] [G loss: 0.870837]\n",
      "epoch:31 step:24471[D loss: 0.414849, acc: 67.97%, op_acc: 39.06%] [G loss: 0.834739]\n",
      "epoch:31 step:24472[D loss: 0.399419, acc: 62.50%, op_acc: 43.75%] [G loss: 0.885439]\n",
      "epoch:31 step:24473[D loss: 0.434640, acc: 57.03%, op_acc: 39.06%] [G loss: 0.861968]\n",
      "epoch:31 step:24474[D loss: 0.419933, acc: 60.16%, op_acc: 39.84%] [G loss: 0.880849]\n",
      "epoch:31 step:24475[D loss: 0.409094, acc: 56.25%, op_acc: 41.41%] [G loss: 0.891338]\n",
      "epoch:31 step:24476[D loss: 0.430596, acc: 52.34%, op_acc: 39.84%] [G loss: 0.868177]\n",
      "epoch:31 step:24477[D loss: 0.405444, acc: 65.62%, op_acc: 44.53%] [G loss: 0.792806]\n",
      "epoch:31 step:24478[D loss: 0.433156, acc: 57.03%, op_acc: 39.84%] [G loss: 0.825278]\n",
      "epoch:31 step:24479[D loss: 0.434973, acc: 53.91%, op_acc: 41.41%] [G loss: 0.840412]\n",
      "epoch:31 step:24480[D loss: 0.398659, acc: 66.41%, op_acc: 43.75%] [G loss: 0.920290]\n",
      "epoch:31 step:24481[D loss: 0.431647, acc: 60.16%, op_acc: 32.81%] [G loss: 0.929975]\n",
      "epoch:31 step:24482[D loss: 0.414756, acc: 59.38%, op_acc: 39.84%] [G loss: 0.877746]\n",
      "epoch:31 step:24483[D loss: 0.439190, acc: 61.72%, op_acc: 36.72%] [G loss: 0.901719]\n",
      "epoch:31 step:24484[D loss: 0.429812, acc: 58.59%, op_acc: 39.06%] [G loss: 0.863223]\n",
      "epoch:31 step:24485[D loss: 0.427166, acc: 56.25%, op_acc: 40.62%] [G loss: 0.845010]\n",
      "epoch:31 step:24486[D loss: 0.436184, acc: 60.16%, op_acc: 39.06%] [G loss: 0.864382]\n",
      "epoch:31 step:24487[D loss: 0.429997, acc: 57.81%, op_acc: 38.28%] [G loss: 0.906300]\n",
      "epoch:31 step:24488[D loss: 0.434035, acc: 64.06%, op_acc: 35.16%] [G loss: 0.857795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24489[D loss: 0.425579, acc: 53.91%, op_acc: 42.19%] [G loss: 0.795527]\n",
      "epoch:31 step:24490[D loss: 0.449460, acc: 47.66%, op_acc: 42.97%] [G loss: 0.797987]\n",
      "epoch:31 step:24491[D loss: 0.430739, acc: 50.00%, op_acc: 42.19%] [G loss: 0.939645]\n",
      "epoch:31 step:24492[D loss: 0.404936, acc: 64.06%, op_acc: 45.31%] [G loss: 0.954573]\n",
      "epoch:31 step:24493[D loss: 0.459717, acc: 57.03%, op_acc: 32.03%] [G loss: 0.821455]\n",
      "epoch:31 step:24494[D loss: 0.417625, acc: 54.69%, op_acc: 43.75%] [G loss: 0.874181]\n",
      "epoch:31 step:24495[D loss: 0.438062, acc: 61.72%, op_acc: 35.94%] [G loss: 0.848699]\n",
      "epoch:31 step:24496[D loss: 0.428024, acc: 56.25%, op_acc: 39.84%] [G loss: 0.841723]\n",
      "epoch:31 step:24497[D loss: 0.461015, acc: 53.12%, op_acc: 36.72%] [G loss: 0.858808]\n",
      "epoch:31 step:24498[D loss: 0.409917, acc: 59.38%, op_acc: 47.66%] [G loss: 0.852609]\n",
      "epoch:31 step:24499[D loss: 0.445270, acc: 57.81%, op_acc: 38.28%] [G loss: 0.851555]\n",
      "epoch:31 step:24500[D loss: 0.444939, acc: 53.12%, op_acc: 35.94%] [G loss: 0.839761]\n",
      "##############\n",
      "[0.86245981 0.84896294 0.81562879 0.83060001 0.78822957 0.84921839\n",
      " 0.89782767 0.82170636 0.80230417 0.81056649]\n",
      "##########\n",
      "epoch:31 step:24501[D loss: 0.447009, acc: 58.59%, op_acc: 32.81%] [G loss: 0.883618]\n",
      "epoch:31 step:24502[D loss: 0.443860, acc: 55.47%, op_acc: 36.72%] [G loss: 0.837405]\n",
      "epoch:31 step:24503[D loss: 0.418337, acc: 60.94%, op_acc: 41.41%] [G loss: 0.932666]\n",
      "epoch:31 step:24504[D loss: 0.408279, acc: 56.25%, op_acc: 42.19%] [G loss: 0.855752]\n",
      "epoch:31 step:24505[D loss: 0.406668, acc: 66.41%, op_acc: 41.41%] [G loss: 0.812689]\n",
      "epoch:31 step:24506[D loss: 0.408646, acc: 57.81%, op_acc: 39.84%] [G loss: 0.880353]\n",
      "epoch:31 step:24507[D loss: 0.402117, acc: 60.94%, op_acc: 43.75%] [G loss: 0.873001]\n",
      "epoch:31 step:24508[D loss: 0.441138, acc: 51.56%, op_acc: 35.16%] [G loss: 0.837665]\n",
      "epoch:31 step:24509[D loss: 0.428102, acc: 65.62%, op_acc: 37.50%] [G loss: 0.938286]\n",
      "epoch:31 step:24510[D loss: 0.419442, acc: 59.38%, op_acc: 45.31%] [G loss: 0.885618]\n",
      "epoch:31 step:24511[D loss: 0.436931, acc: 57.81%, op_acc: 32.81%] [G loss: 0.862489]\n",
      "epoch:31 step:24512[D loss: 0.424181, acc: 59.38%, op_acc: 42.19%] [G loss: 0.894159]\n",
      "epoch:31 step:24513[D loss: 0.400090, acc: 65.62%, op_acc: 43.75%] [G loss: 0.901236]\n",
      "epoch:31 step:24514[D loss: 0.432843, acc: 59.38%, op_acc: 43.75%] [G loss: 0.845445]\n",
      "epoch:31 step:24515[D loss: 0.403549, acc: 60.16%, op_acc: 47.66%] [G loss: 0.871854]\n",
      "epoch:31 step:24516[D loss: 0.412290, acc: 54.69%, op_acc: 43.75%] [G loss: 0.898408]\n",
      "epoch:31 step:24517[D loss: 0.465706, acc: 54.69%, op_acc: 34.38%] [G loss: 1.002315]\n",
      "epoch:31 step:24518[D loss: 0.414252, acc: 54.69%, op_acc: 43.75%] [G loss: 0.905583]\n",
      "epoch:31 step:24519[D loss: 0.410690, acc: 62.50%, op_acc: 42.19%] [G loss: 0.985178]\n",
      "epoch:31 step:24520[D loss: 0.444678, acc: 57.03%, op_acc: 35.16%] [G loss: 0.878271]\n",
      "epoch:31 step:24521[D loss: 0.423254, acc: 63.28%, op_acc: 35.94%] [G loss: 0.891571]\n",
      "epoch:31 step:24522[D loss: 0.420383, acc: 57.03%, op_acc: 43.75%] [G loss: 0.869876]\n",
      "epoch:31 step:24523[D loss: 0.463246, acc: 51.56%, op_acc: 35.94%] [G loss: 0.908730]\n",
      "epoch:31 step:24524[D loss: 0.426016, acc: 58.59%, op_acc: 39.06%] [G loss: 0.805986]\n",
      "epoch:31 step:24525[D loss: 0.439556, acc: 56.25%, op_acc: 35.16%] [G loss: 0.938238]\n",
      "epoch:31 step:24526[D loss: 0.446792, acc: 59.38%, op_acc: 39.06%] [G loss: 0.862976]\n",
      "epoch:31 step:24527[D loss: 0.426823, acc: 60.94%, op_acc: 40.62%] [G loss: 0.877250]\n",
      "epoch:31 step:24528[D loss: 0.422150, acc: 61.72%, op_acc: 42.19%] [G loss: 0.895690]\n",
      "epoch:31 step:24529[D loss: 0.429133, acc: 58.59%, op_acc: 32.81%] [G loss: 0.923887]\n",
      "epoch:31 step:24530[D loss: 0.406453, acc: 57.03%, op_acc: 42.97%] [G loss: 0.887121]\n",
      "epoch:31 step:24531[D loss: 0.407153, acc: 67.19%, op_acc: 38.28%] [G loss: 0.924408]\n",
      "epoch:31 step:24532[D loss: 0.476081, acc: 45.31%, op_acc: 36.72%] [G loss: 0.815872]\n",
      "epoch:31 step:24533[D loss: 0.417791, acc: 63.28%, op_acc: 39.84%] [G loss: 0.914271]\n",
      "epoch:31 step:24534[D loss: 0.437977, acc: 59.38%, op_acc: 39.84%] [G loss: 0.865670]\n",
      "epoch:31 step:24535[D loss: 0.399520, acc: 64.84%, op_acc: 39.84%] [G loss: 0.871464]\n",
      "epoch:31 step:24536[D loss: 0.424903, acc: 51.56%, op_acc: 38.28%] [G loss: 0.797232]\n",
      "epoch:31 step:24537[D loss: 0.428203, acc: 54.69%, op_acc: 39.06%] [G loss: 0.879020]\n",
      "epoch:31 step:24538[D loss: 0.382426, acc: 68.75%, op_acc: 42.19%] [G loss: 0.860047]\n",
      "epoch:31 step:24539[D loss: 0.438336, acc: 50.00%, op_acc: 42.97%] [G loss: 0.950876]\n",
      "epoch:31 step:24540[D loss: 0.412536, acc: 64.06%, op_acc: 37.50%] [G loss: 0.869973]\n",
      "epoch:31 step:24541[D loss: 0.392484, acc: 63.28%, op_acc: 44.53%] [G loss: 0.890136]\n",
      "epoch:31 step:24542[D loss: 0.391380, acc: 67.97%, op_acc: 39.84%] [G loss: 0.869890]\n",
      "epoch:31 step:24543[D loss: 0.427573, acc: 59.38%, op_acc: 39.06%] [G loss: 0.907429]\n",
      "epoch:31 step:24544[D loss: 0.407951, acc: 71.09%, op_acc: 38.28%] [G loss: 0.851049]\n",
      "epoch:31 step:24545[D loss: 0.423083, acc: 63.28%, op_acc: 41.41%] [G loss: 0.883738]\n",
      "epoch:31 step:24546[D loss: 0.438287, acc: 57.81%, op_acc: 36.72%] [G loss: 0.806526]\n",
      "epoch:31 step:24547[D loss: 0.427280, acc: 57.81%, op_acc: 41.41%] [G loss: 0.916613]\n",
      "epoch:31 step:24548[D loss: 0.459797, acc: 50.00%, op_acc: 34.38%] [G loss: 0.868209]\n",
      "epoch:31 step:24549[D loss: 0.397643, acc: 57.03%, op_acc: 44.53%] [G loss: 0.822857]\n",
      "epoch:31 step:24550[D loss: 0.446375, acc: 53.12%, op_acc: 35.94%] [G loss: 0.843661]\n",
      "##############\n",
      "[0.85245004 0.84423479 0.80609947 0.80606938 0.79398141 0.82552859\n",
      " 0.89316106 0.80781944 0.8170451  0.8264395 ]\n",
      "##########\n",
      "epoch:31 step:24551[D loss: 0.404566, acc: 60.94%, op_acc: 42.19%] [G loss: 0.820181]\n",
      "epoch:31 step:24552[D loss: 0.427899, acc: 56.25%, op_acc: 38.28%] [G loss: 0.943746]\n",
      "epoch:31 step:24553[D loss: 0.441029, acc: 46.88%, op_acc: 35.94%] [G loss: 0.780059]\n",
      "epoch:31 step:24554[D loss: 0.432107, acc: 51.56%, op_acc: 35.16%] [G loss: 0.886432]\n",
      "epoch:31 step:24555[D loss: 0.443659, acc: 50.78%, op_acc: 37.50%] [G loss: 0.788165]\n",
      "epoch:31 step:24556[D loss: 0.391470, acc: 70.31%, op_acc: 38.28%] [G loss: 0.858915]\n",
      "epoch:31 step:24557[D loss: 0.421191, acc: 54.69%, op_acc: 39.06%] [G loss: 0.879257]\n",
      "epoch:31 step:24558[D loss: 0.412714, acc: 59.38%, op_acc: 43.75%] [G loss: 0.842107]\n",
      "epoch:31 step:24559[D loss: 0.429983, acc: 60.16%, op_acc: 43.75%] [G loss: 0.863884]\n",
      "epoch:31 step:24560[D loss: 0.426006, acc: 58.59%, op_acc: 40.62%] [G loss: 0.841371]\n",
      "epoch:31 step:24561[D loss: 0.443698, acc: 60.94%, op_acc: 35.16%] [G loss: 0.896476]\n",
      "epoch:31 step:24562[D loss: 0.398144, acc: 65.62%, op_acc: 38.28%] [G loss: 0.870268]\n",
      "epoch:31 step:24563[D loss: 0.464210, acc: 52.34%, op_acc: 32.03%] [G loss: 0.893401]\n",
      "epoch:31 step:24564[D loss: 0.380700, acc: 65.62%, op_acc: 44.53%] [G loss: 0.863512]\n",
      "epoch:31 step:24565[D loss: 0.421990, acc: 53.91%, op_acc: 39.06%] [G loss: 0.929698]\n",
      "epoch:31 step:24566[D loss: 0.420571, acc: 57.03%, op_acc: 41.41%] [G loss: 0.840401]\n",
      "epoch:31 step:24567[D loss: 0.412788, acc: 51.56%, op_acc: 36.72%] [G loss: 0.784401]\n",
      "epoch:31 step:24568[D loss: 0.418373, acc: 63.28%, op_acc: 40.62%] [G loss: 0.944310]\n",
      "epoch:31 step:24569[D loss: 0.424608, acc: 60.94%, op_acc: 42.19%] [G loss: 0.852024]\n",
      "epoch:31 step:24570[D loss: 0.446250, acc: 54.69%, op_acc: 35.16%] [G loss: 0.782475]\n",
      "epoch:31 step:24571[D loss: 0.436329, acc: 50.00%, op_acc: 42.19%] [G loss: 0.894911]\n",
      "epoch:31 step:24572[D loss: 0.428813, acc: 62.50%, op_acc: 36.72%] [G loss: 0.859341]\n",
      "epoch:31 step:24573[D loss: 0.395434, acc: 59.38%, op_acc: 44.53%] [G loss: 0.873257]\n",
      "epoch:31 step:24574[D loss: 0.422081, acc: 52.34%, op_acc: 43.75%] [G loss: 0.873815]\n",
      "epoch:31 step:24575[D loss: 0.407812, acc: 60.94%, op_acc: 39.06%] [G loss: 0.929357]\n",
      "epoch:31 step:24576[D loss: 0.373256, acc: 66.41%, op_acc: 45.31%] [G loss: 0.871848]\n",
      "epoch:31 step:24577[D loss: 0.387676, acc: 63.28%, op_acc: 44.53%] [G loss: 0.887880]\n",
      "epoch:31 step:24578[D loss: 0.389461, acc: 64.06%, op_acc: 41.41%] [G loss: 0.952662]\n",
      "epoch:31 step:24579[D loss: 0.402485, acc: 69.53%, op_acc: 43.75%] [G loss: 0.813927]\n",
      "epoch:31 step:24580[D loss: 0.412327, acc: 60.16%, op_acc: 46.09%] [G loss: 0.836031]\n",
      "epoch:31 step:24581[D loss: 0.436062, acc: 53.12%, op_acc: 35.94%] [G loss: 0.875859]\n",
      "epoch:31 step:24582[D loss: 0.409951, acc: 57.81%, op_acc: 46.09%] [G loss: 0.855834]\n",
      "epoch:31 step:24583[D loss: 0.412916, acc: 60.94%, op_acc: 39.06%] [G loss: 0.849079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24584[D loss: 0.432884, acc: 53.91%, op_acc: 41.41%] [G loss: 0.924173]\n",
      "epoch:31 step:24585[D loss: 0.422738, acc: 53.91%, op_acc: 42.19%] [G loss: 0.910403]\n",
      "epoch:31 step:24586[D loss: 0.431206, acc: 53.91%, op_acc: 34.38%] [G loss: 0.873397]\n",
      "epoch:31 step:24587[D loss: 0.425154, acc: 60.16%, op_acc: 42.97%] [G loss: 0.865509]\n",
      "epoch:31 step:24588[D loss: 0.413665, acc: 58.59%, op_acc: 45.31%] [G loss: 0.907592]\n",
      "epoch:31 step:24589[D loss: 0.437736, acc: 56.25%, op_acc: 37.50%] [G loss: 0.873943]\n",
      "epoch:31 step:24590[D loss: 0.401163, acc: 66.41%, op_acc: 37.50%] [G loss: 0.867714]\n",
      "epoch:31 step:24591[D loss: 0.419858, acc: 60.16%, op_acc: 41.41%] [G loss: 0.911806]\n",
      "epoch:31 step:24592[D loss: 0.406836, acc: 63.28%, op_acc: 36.72%] [G loss: 0.871757]\n",
      "epoch:31 step:24593[D loss: 0.432167, acc: 57.03%, op_acc: 42.19%] [G loss: 0.838036]\n",
      "epoch:31 step:24594[D loss: 0.407558, acc: 64.06%, op_acc: 44.53%] [G loss: 0.928288]\n",
      "epoch:31 step:24595[D loss: 0.438309, acc: 54.69%, op_acc: 37.50%] [G loss: 0.862349]\n",
      "epoch:31 step:24596[D loss: 0.386690, acc: 57.81%, op_acc: 45.31%] [G loss: 0.837981]\n",
      "epoch:31 step:24597[D loss: 0.409729, acc: 60.16%, op_acc: 45.31%] [G loss: 0.883327]\n",
      "epoch:31 step:24598[D loss: 0.429166, acc: 60.94%, op_acc: 39.84%] [G loss: 0.865594]\n",
      "epoch:31 step:24599[D loss: 0.450049, acc: 56.25%, op_acc: 34.38%] [G loss: 0.847569]\n",
      "epoch:31 step:24600[D loss: 0.409460, acc: 62.50%, op_acc: 44.53%] [G loss: 0.891613]\n",
      "##############\n",
      "[0.85120102 0.86776431 0.79201772 0.82121722 0.79560284 0.82099369\n",
      " 0.87560178 0.82789977 0.79655676 0.82101367]\n",
      "##########\n",
      "epoch:31 step:24601[D loss: 0.439787, acc: 55.47%, op_acc: 36.72%] [G loss: 0.927207]\n",
      "epoch:31 step:24602[D loss: 0.406175, acc: 57.03%, op_acc: 41.41%] [G loss: 0.846123]\n",
      "epoch:31 step:24603[D loss: 0.411188, acc: 60.94%, op_acc: 42.19%] [G loss: 0.853937]\n",
      "epoch:31 step:24604[D loss: 0.405534, acc: 58.59%, op_acc: 44.53%] [G loss: 0.944461]\n",
      "epoch:31 step:24605[D loss: 0.421559, acc: 55.47%, op_acc: 40.62%] [G loss: 0.924965]\n",
      "epoch:31 step:24606[D loss: 0.428433, acc: 61.72%, op_acc: 38.28%] [G loss: 0.887625]\n",
      "epoch:31 step:24607[D loss: 0.392914, acc: 64.84%, op_acc: 43.75%] [G loss: 0.902432]\n",
      "epoch:31 step:24608[D loss: 0.422842, acc: 53.12%, op_acc: 42.97%] [G loss: 0.844714]\n",
      "epoch:31 step:24609[D loss: 0.440388, acc: 55.47%, op_acc: 39.06%] [G loss: 0.856590]\n",
      "epoch:31 step:24610[D loss: 0.414868, acc: 54.69%, op_acc: 39.06%] [G loss: 0.877534]\n",
      "epoch:31 step:24611[D loss: 0.396948, acc: 71.88%, op_acc: 42.19%] [G loss: 0.796713]\n",
      "epoch:31 step:24612[D loss: 0.418249, acc: 57.81%, op_acc: 42.19%] [G loss: 0.847671]\n",
      "epoch:31 step:24613[D loss: 0.444998, acc: 55.47%, op_acc: 36.72%] [G loss: 0.864554]\n",
      "epoch:31 step:24614[D loss: 0.429206, acc: 57.81%, op_acc: 37.50%] [G loss: 0.893134]\n",
      "epoch:31 step:24615[D loss: 0.380046, acc: 65.62%, op_acc: 45.31%] [G loss: 0.907116]\n",
      "epoch:31 step:24616[D loss: 0.423525, acc: 59.38%, op_acc: 39.06%] [G loss: 0.917831]\n",
      "epoch:31 step:24617[D loss: 0.410752, acc: 60.16%, op_acc: 44.53%] [G loss: 0.871711]\n",
      "epoch:31 step:24618[D loss: 0.428778, acc: 57.03%, op_acc: 40.62%] [G loss: 0.919412]\n",
      "epoch:31 step:24619[D loss: 0.381234, acc: 62.50%, op_acc: 47.66%] [G loss: 0.877658]\n",
      "epoch:31 step:24620[D loss: 0.430470, acc: 53.12%, op_acc: 44.53%] [G loss: 0.800357]\n",
      "epoch:31 step:24621[D loss: 0.406759, acc: 59.38%, op_acc: 42.19%] [G loss: 0.820527]\n",
      "epoch:31 step:24622[D loss: 0.414964, acc: 57.03%, op_acc: 39.84%] [G loss: 0.924541]\n",
      "epoch:31 step:24623[D loss: 0.384984, acc: 61.72%, op_acc: 46.09%] [G loss: 0.879847]\n",
      "epoch:31 step:24624[D loss: 0.438361, acc: 55.47%, op_acc: 39.06%] [G loss: 0.832416]\n",
      "epoch:31 step:24625[D loss: 0.396079, acc: 62.50%, op_acc: 40.62%] [G loss: 0.887851]\n",
      "epoch:31 step:24626[D loss: 0.412884, acc: 66.41%, op_acc: 46.09%] [G loss: 0.852143]\n",
      "epoch:31 step:24627[D loss: 0.427556, acc: 57.81%, op_acc: 41.41%] [G loss: 0.866946]\n",
      "epoch:31 step:24628[D loss: 0.421345, acc: 54.69%, op_acc: 43.75%] [G loss: 0.847426]\n",
      "epoch:31 step:24629[D loss: 0.426804, acc: 59.38%, op_acc: 41.41%] [G loss: 0.814088]\n",
      "epoch:31 step:24630[D loss: 0.434671, acc: 60.16%, op_acc: 35.16%] [G loss: 0.910603]\n",
      "epoch:31 step:24631[D loss: 0.454800, acc: 57.81%, op_acc: 35.94%] [G loss: 0.825484]\n",
      "epoch:31 step:24632[D loss: 0.434859, acc: 62.50%, op_acc: 38.28%] [G loss: 0.824943]\n",
      "epoch:31 step:24633[D loss: 0.427373, acc: 53.12%, op_acc: 40.62%] [G loss: 0.908760]\n",
      "epoch:31 step:24634[D loss: 0.428368, acc: 57.03%, op_acc: 42.97%] [G loss: 0.856804]\n",
      "epoch:31 step:24635[D loss: 0.419152, acc: 63.28%, op_acc: 38.28%] [G loss: 0.922456]\n",
      "epoch:31 step:24636[D loss: 0.409242, acc: 62.50%, op_acc: 35.16%] [G loss: 0.869791]\n",
      "epoch:31 step:24637[D loss: 0.438866, acc: 61.72%, op_acc: 38.28%] [G loss: 0.916479]\n",
      "epoch:31 step:24638[D loss: 0.419267, acc: 60.16%, op_acc: 36.72%] [G loss: 0.880347]\n",
      "epoch:31 step:24639[D loss: 0.415342, acc: 56.25%, op_acc: 44.53%] [G loss: 0.857532]\n",
      "epoch:31 step:24640[D loss: 0.401065, acc: 59.38%, op_acc: 42.97%] [G loss: 0.894996]\n",
      "epoch:31 step:24641[D loss: 0.411586, acc: 60.94%, op_acc: 42.19%] [G loss: 0.826487]\n",
      "epoch:31 step:24642[D loss: 0.420809, acc: 60.94%, op_acc: 38.28%] [G loss: 0.934268]\n",
      "epoch:31 step:24643[D loss: 0.419449, acc: 59.38%, op_acc: 42.97%] [G loss: 0.886076]\n",
      "epoch:31 step:24644[D loss: 0.405306, acc: 60.16%, op_acc: 40.62%] [G loss: 0.907828]\n",
      "epoch:31 step:24645[D loss: 0.409975, acc: 61.72%, op_acc: 46.88%] [G loss: 0.845342]\n",
      "epoch:31 step:24646[D loss: 0.398649, acc: 59.38%, op_acc: 46.09%] [G loss: 0.897811]\n",
      "epoch:31 step:24647[D loss: 0.448135, acc: 61.72%, op_acc: 32.81%] [G loss: 0.852475]\n",
      "epoch:31 step:24648[D loss: 0.436686, acc: 59.38%, op_acc: 41.41%] [G loss: 0.867864]\n",
      "epoch:31 step:24649[D loss: 0.403979, acc: 64.84%, op_acc: 41.41%] [G loss: 0.825188]\n",
      "epoch:31 step:24650[D loss: 0.450322, acc: 54.69%, op_acc: 39.06%] [G loss: 0.799242]\n",
      "##############\n",
      "[0.84819683 0.86592996 0.80907443 0.80556328 0.7830543  0.82421744\n",
      " 0.89112703 0.83238426 0.81627698 0.84884098]\n",
      "##########\n",
      "epoch:31 step:24651[D loss: 0.416044, acc: 61.72%, op_acc: 39.06%] [G loss: 0.888558]\n",
      "epoch:31 step:24652[D loss: 0.410947, acc: 63.28%, op_acc: 38.28%] [G loss: 0.841210]\n",
      "epoch:31 step:24653[D loss: 0.440899, acc: 57.03%, op_acc: 40.62%] [G loss: 0.897923]\n",
      "epoch:31 step:24654[D loss: 0.452616, acc: 49.22%, op_acc: 39.84%] [G loss: 0.860851]\n",
      "epoch:31 step:24655[D loss: 0.385673, acc: 67.97%, op_acc: 45.31%] [G loss: 0.862010]\n",
      "epoch:31 step:24656[D loss: 0.450824, acc: 50.78%, op_acc: 38.28%] [G loss: 0.899533]\n",
      "epoch:31 step:24657[D loss: 0.426582, acc: 54.69%, op_acc: 38.28%] [G loss: 0.940187]\n",
      "epoch:31 step:24658[D loss: 0.440894, acc: 58.59%, op_acc: 35.94%] [G loss: 0.874928]\n",
      "epoch:31 step:24659[D loss: 0.422370, acc: 59.38%, op_acc: 42.97%] [G loss: 0.878565]\n",
      "epoch:31 step:24660[D loss: 0.415980, acc: 63.28%, op_acc: 39.06%] [G loss: 0.942976]\n",
      "epoch:31 step:24661[D loss: 0.411797, acc: 66.41%, op_acc: 39.84%] [G loss: 0.936288]\n",
      "epoch:31 step:24662[D loss: 0.404011, acc: 62.50%, op_acc: 40.62%] [G loss: 0.924244]\n",
      "epoch:31 step:24663[D loss: 0.415673, acc: 55.47%, op_acc: 41.41%] [G loss: 0.913373]\n",
      "epoch:31 step:24664[D loss: 0.417618, acc: 59.38%, op_acc: 40.62%] [G loss: 0.856029]\n",
      "epoch:31 step:24665[D loss: 0.438355, acc: 58.59%, op_acc: 38.28%] [G loss: 0.898770]\n",
      "epoch:31 step:24666[D loss: 0.437585, acc: 57.03%, op_acc: 40.62%] [G loss: 0.826561]\n",
      "epoch:31 step:24667[D loss: 0.440578, acc: 56.25%, op_acc: 37.50%] [G loss: 0.899208]\n",
      "epoch:31 step:24668[D loss: 0.431979, acc: 54.69%, op_acc: 38.28%] [G loss: 0.823797]\n",
      "epoch:31 step:24669[D loss: 0.400261, acc: 67.97%, op_acc: 41.41%] [G loss: 0.890081]\n",
      "epoch:31 step:24670[D loss: 0.381221, acc: 63.28%, op_acc: 45.31%] [G loss: 0.815110]\n",
      "epoch:31 step:24671[D loss: 0.410937, acc: 60.94%, op_acc: 43.75%] [G loss: 0.871783]\n",
      "epoch:31 step:24672[D loss: 0.466458, acc: 50.00%, op_acc: 34.38%] [G loss: 0.867229]\n",
      "epoch:31 step:24673[D loss: 0.423969, acc: 63.28%, op_acc: 42.19%] [G loss: 0.872952]\n",
      "epoch:31 step:24674[D loss: 0.423151, acc: 54.69%, op_acc: 39.84%] [G loss: 0.835386]\n",
      "epoch:31 step:24675[D loss: 0.413584, acc: 63.28%, op_acc: 40.62%] [G loss: 0.890707]\n",
      "epoch:31 step:24676[D loss: 0.421537, acc: 59.38%, op_acc: 36.72%] [G loss: 0.845555]\n",
      "epoch:31 step:24677[D loss: 0.408128, acc: 67.19%, op_acc: 40.62%] [G loss: 0.874733]\n",
      "epoch:31 step:24678[D loss: 0.417635, acc: 61.72%, op_acc: 42.19%] [G loss: 0.894324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24679[D loss: 0.412510, acc: 60.16%, op_acc: 42.19%] [G loss: 0.911538]\n",
      "epoch:31 step:24680[D loss: 0.402907, acc: 59.38%, op_acc: 45.31%] [G loss: 0.880782]\n",
      "epoch:31 step:24681[D loss: 0.398125, acc: 60.16%, op_acc: 42.97%] [G loss: 0.918597]\n",
      "epoch:31 step:24682[D loss: 0.426350, acc: 55.47%, op_acc: 41.41%] [G loss: 0.932473]\n",
      "epoch:31 step:24683[D loss: 0.433700, acc: 58.59%, op_acc: 42.19%] [G loss: 0.875129]\n",
      "epoch:31 step:24684[D loss: 0.388217, acc: 66.41%, op_acc: 46.09%] [G loss: 0.917801]\n",
      "epoch:31 step:24685[D loss: 0.420125, acc: 61.72%, op_acc: 37.50%] [G loss: 0.876231]\n",
      "epoch:31 step:24686[D loss: 0.405537, acc: 60.94%, op_acc: 42.97%] [G loss: 0.878457]\n",
      "epoch:31 step:24687[D loss: 0.416626, acc: 64.06%, op_acc: 36.72%] [G loss: 0.901174]\n",
      "epoch:31 step:24688[D loss: 0.449843, acc: 54.69%, op_acc: 41.41%] [G loss: 0.864366]\n",
      "epoch:31 step:24689[D loss: 0.414304, acc: 54.69%, op_acc: 42.19%] [G loss: 0.906689]\n",
      "epoch:31 step:24690[D loss: 0.422413, acc: 60.94%, op_acc: 38.28%] [G loss: 0.879192]\n",
      "epoch:31 step:24691[D loss: 0.460586, acc: 54.69%, op_acc: 36.72%] [G loss: 0.858447]\n",
      "epoch:31 step:24692[D loss: 0.463563, acc: 53.91%, op_acc: 35.16%] [G loss: 0.798877]\n",
      "epoch:31 step:24693[D loss: 0.429487, acc: 55.47%, op_acc: 42.19%] [G loss: 0.923547]\n",
      "epoch:31 step:24694[D loss: 0.419468, acc: 59.38%, op_acc: 45.31%] [G loss: 0.983132]\n",
      "epoch:31 step:24695[D loss: 0.407295, acc: 65.62%, op_acc: 43.75%] [G loss: 0.910602]\n",
      "epoch:31 step:24696[D loss: 0.445069, acc: 56.25%, op_acc: 39.06%] [G loss: 0.874629]\n",
      "epoch:31 step:24697[D loss: 0.412132, acc: 64.84%, op_acc: 40.62%] [G loss: 0.840407]\n",
      "epoch:31 step:24698[D loss: 0.414343, acc: 60.16%, op_acc: 39.06%] [G loss: 0.917872]\n",
      "epoch:31 step:24699[D loss: 0.428206, acc: 54.69%, op_acc: 39.06%] [G loss: 0.878297]\n",
      "epoch:31 step:24700[D loss: 0.451477, acc: 49.22%, op_acc: 40.62%] [G loss: 0.907807]\n",
      "##############\n",
      "[0.8352252  0.84206709 0.82361697 0.80985319 0.78846306 0.8199379\n",
      " 0.88886325 0.82404871 0.80997072 0.85449173]\n",
      "##########\n",
      "epoch:31 step:24701[D loss: 0.402888, acc: 60.16%, op_acc: 39.84%] [G loss: 0.862070]\n",
      "epoch:31 step:24702[D loss: 0.453139, acc: 53.91%, op_acc: 33.59%] [G loss: 0.912081]\n",
      "epoch:31 step:24703[D loss: 0.396508, acc: 64.06%, op_acc: 46.88%] [G loss: 0.876413]\n",
      "epoch:31 step:24704[D loss: 0.424003, acc: 60.94%, op_acc: 42.19%] [G loss: 1.029843]\n",
      "epoch:31 step:24705[D loss: 0.380751, acc: 71.09%, op_acc: 45.31%] [G loss: 0.999771]\n",
      "epoch:31 step:24706[D loss: 0.406853, acc: 60.94%, op_acc: 42.19%] [G loss: 0.899971]\n",
      "epoch:31 step:24707[D loss: 0.421844, acc: 60.16%, op_acc: 43.75%] [G loss: 0.941757]\n",
      "epoch:31 step:24708[D loss: 0.421372, acc: 57.81%, op_acc: 39.84%] [G loss: 0.896886]\n",
      "epoch:31 step:24709[D loss: 0.444832, acc: 53.91%, op_acc: 41.41%] [G loss: 0.875866]\n",
      "epoch:31 step:24710[D loss: 0.417116, acc: 63.28%, op_acc: 43.75%] [G loss: 0.899308]\n",
      "epoch:31 step:24711[D loss: 0.419893, acc: 58.59%, op_acc: 38.28%] [G loss: 0.845960]\n",
      "epoch:31 step:24712[D loss: 0.433383, acc: 62.50%, op_acc: 36.72%] [G loss: 0.854859]\n",
      "epoch:31 step:24713[D loss: 0.430816, acc: 44.53%, op_acc: 42.97%] [G loss: 0.895129]\n",
      "epoch:31 step:24714[D loss: 0.423712, acc: 57.03%, op_acc: 39.06%] [G loss: 0.829422]\n",
      "epoch:31 step:24715[D loss: 0.421021, acc: 55.47%, op_acc: 40.62%] [G loss: 0.880376]\n",
      "epoch:31 step:24716[D loss: 0.426621, acc: 58.59%, op_acc: 39.84%] [G loss: 0.857643]\n",
      "epoch:31 step:24717[D loss: 0.409222, acc: 62.50%, op_acc: 49.22%] [G loss: 0.881979]\n",
      "epoch:31 step:24718[D loss: 0.423882, acc: 62.50%, op_acc: 42.19%] [G loss: 0.816064]\n",
      "epoch:31 step:24719[D loss: 0.418782, acc: 65.62%, op_acc: 39.84%] [G loss: 0.861074]\n",
      "epoch:31 step:24720[D loss: 0.438977, acc: 54.69%, op_acc: 41.41%] [G loss: 0.867357]\n",
      "epoch:31 step:24721[D loss: 0.419308, acc: 56.25%, op_acc: 43.75%] [G loss: 0.809071]\n",
      "epoch:31 step:24722[D loss: 0.406478, acc: 60.16%, op_acc: 45.31%] [G loss: 0.916072]\n",
      "epoch:31 step:24723[D loss: 0.422984, acc: 60.94%, op_acc: 42.19%] [G loss: 0.869530]\n",
      "epoch:31 step:24724[D loss: 0.451003, acc: 53.12%, op_acc: 35.16%] [G loss: 0.884182]\n",
      "epoch:31 step:24725[D loss: 0.428137, acc: 53.91%, op_acc: 41.41%] [G loss: 0.763157]\n",
      "epoch:31 step:24726[D loss: 0.420278, acc: 64.06%, op_acc: 33.59%] [G loss: 0.859205]\n",
      "epoch:31 step:24727[D loss: 0.425768, acc: 60.16%, op_acc: 36.72%] [G loss: 0.890721]\n",
      "epoch:31 step:24728[D loss: 0.433677, acc: 52.34%, op_acc: 35.16%] [G loss: 0.913117]\n",
      "epoch:31 step:24729[D loss: 0.369270, acc: 69.53%, op_acc: 46.88%] [G loss: 0.906454]\n",
      "epoch:31 step:24730[D loss: 0.420301, acc: 61.72%, op_acc: 43.75%] [G loss: 0.841118]\n",
      "epoch:31 step:24731[D loss: 0.447473, acc: 53.12%, op_acc: 41.41%] [G loss: 0.920963]\n",
      "epoch:31 step:24732[D loss: 0.381716, acc: 73.44%, op_acc: 39.84%] [G loss: 0.866505]\n",
      "epoch:31 step:24733[D loss: 0.458096, acc: 50.78%, op_acc: 39.06%] [G loss: 0.836042]\n",
      "epoch:31 step:24734[D loss: 0.395440, acc: 67.97%, op_acc: 42.97%] [G loss: 0.898155]\n",
      "epoch:31 step:24735[D loss: 0.418022, acc: 64.06%, op_acc: 35.94%] [G loss: 0.978020]\n",
      "epoch:31 step:24736[D loss: 0.423701, acc: 62.50%, op_acc: 35.16%] [G loss: 0.896780]\n",
      "epoch:31 step:24737[D loss: 0.464095, acc: 54.69%, op_acc: 31.25%] [G loss: 0.871241]\n",
      "epoch:31 step:24738[D loss: 0.405321, acc: 63.28%, op_acc: 35.16%] [G loss: 0.863657]\n",
      "epoch:31 step:24739[D loss: 0.413844, acc: 59.38%, op_acc: 38.28%] [G loss: 0.886730]\n",
      "epoch:31 step:24740[D loss: 0.395523, acc: 67.19%, op_acc: 46.09%] [G loss: 0.906548]\n",
      "epoch:31 step:24741[D loss: 0.430321, acc: 57.81%, op_acc: 37.50%] [G loss: 0.936893]\n",
      "epoch:31 step:24742[D loss: 0.424210, acc: 67.19%, op_acc: 35.16%] [G loss: 0.891939]\n",
      "epoch:31 step:24743[D loss: 0.435489, acc: 56.25%, op_acc: 42.19%] [G loss: 0.880201]\n",
      "epoch:31 step:24744[D loss: 0.419992, acc: 57.81%, op_acc: 44.53%] [G loss: 0.894590]\n",
      "epoch:31 step:24745[D loss: 0.385194, acc: 70.31%, op_acc: 43.75%] [G loss: 0.900080]\n",
      "epoch:31 step:24746[D loss: 0.441194, acc: 55.47%, op_acc: 39.06%] [G loss: 0.859492]\n",
      "epoch:31 step:24747[D loss: 0.415675, acc: 63.28%, op_acc: 41.41%] [G loss: 0.900301]\n",
      "epoch:31 step:24748[D loss: 0.462060, acc: 49.22%, op_acc: 32.81%] [G loss: 0.797933]\n",
      "epoch:31 step:24749[D loss: 0.418825, acc: 58.59%, op_acc: 46.09%] [G loss: 0.877424]\n",
      "epoch:31 step:24750[D loss: 0.433856, acc: 60.94%, op_acc: 40.62%] [G loss: 0.802234]\n",
      "##############\n",
      "[0.84970474 0.85144641 0.82099727 0.79737343 0.78071987 0.8264158\n",
      " 0.8766352  0.82198755 0.84184254 0.83932594]\n",
      "##########\n",
      "epoch:31 step:24751[D loss: 0.397375, acc: 57.81%, op_acc: 47.66%] [G loss: 0.926561]\n",
      "epoch:31 step:24752[D loss: 0.416940, acc: 67.19%, op_acc: 33.59%] [G loss: 0.956448]\n",
      "epoch:31 step:24753[D loss: 0.418487, acc: 65.62%, op_acc: 39.84%] [G loss: 0.907169]\n",
      "epoch:31 step:24754[D loss: 0.435067, acc: 62.50%, op_acc: 35.16%] [G loss: 0.880742]\n",
      "epoch:31 step:24755[D loss: 0.415171, acc: 64.84%, op_acc: 42.97%] [G loss: 0.932569]\n",
      "epoch:31 step:24756[D loss: 0.425427, acc: 60.94%, op_acc: 42.19%] [G loss: 0.833836]\n",
      "epoch:31 step:24757[D loss: 0.438997, acc: 56.25%, op_acc: 44.53%] [G loss: 0.887964]\n",
      "epoch:31 step:24758[D loss: 0.444923, acc: 56.25%, op_acc: 40.62%] [G loss: 0.909546]\n",
      "epoch:31 step:24759[D loss: 0.426338, acc: 57.03%, op_acc: 42.97%] [G loss: 0.791871]\n",
      "epoch:31 step:24760[D loss: 0.402507, acc: 67.19%, op_acc: 44.53%] [G loss: 0.939222]\n",
      "epoch:31 step:24761[D loss: 0.411915, acc: 57.81%, op_acc: 43.75%] [G loss: 0.873636]\n",
      "epoch:31 step:24762[D loss: 0.428864, acc: 57.81%, op_acc: 42.97%] [G loss: 0.931758]\n",
      "epoch:31 step:24763[D loss: 0.437943, acc: 57.81%, op_acc: 34.38%] [G loss: 0.868610]\n",
      "epoch:31 step:24764[D loss: 0.425589, acc: 56.25%, op_acc: 39.84%] [G loss: 0.937725]\n",
      "epoch:31 step:24765[D loss: 0.439289, acc: 53.12%, op_acc: 38.28%] [G loss: 0.855744]\n",
      "epoch:31 step:24766[D loss: 0.414301, acc: 60.94%, op_acc: 42.19%] [G loss: 0.872897]\n",
      "epoch:31 step:24767[D loss: 0.420769, acc: 56.25%, op_acc: 42.19%] [G loss: 0.832209]\n",
      "epoch:31 step:24768[D loss: 0.424845, acc: 62.50%, op_acc: 33.59%] [G loss: 0.864540]\n",
      "epoch:31 step:24769[D loss: 0.415419, acc: 59.38%, op_acc: 42.19%] [G loss: 0.853377]\n",
      "epoch:31 step:24770[D loss: 0.390037, acc: 64.84%, op_acc: 39.06%] [G loss: 0.951510]\n",
      "epoch:31 step:24771[D loss: 0.437893, acc: 57.81%, op_acc: 41.41%] [G loss: 0.871522]\n",
      "epoch:31 step:24772[D loss: 0.415745, acc: 55.47%, op_acc: 42.97%] [G loss: 0.951596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24773[D loss: 0.424935, acc: 64.06%, op_acc: 36.72%] [G loss: 0.920462]\n",
      "epoch:31 step:24774[D loss: 0.420680, acc: 60.16%, op_acc: 35.94%] [G loss: 0.874597]\n",
      "epoch:31 step:24775[D loss: 0.388203, acc: 61.72%, op_acc: 46.88%] [G loss: 0.939671]\n",
      "epoch:31 step:24776[D loss: 0.397339, acc: 62.50%, op_acc: 41.41%] [G loss: 0.926748]\n",
      "epoch:31 step:24777[D loss: 0.425702, acc: 57.03%, op_acc: 40.62%] [G loss: 0.940709]\n",
      "epoch:31 step:24778[D loss: 0.399418, acc: 58.59%, op_acc: 45.31%] [G loss: 0.930766]\n",
      "epoch:31 step:24779[D loss: 0.415177, acc: 57.03%, op_acc: 47.66%] [G loss: 0.938157]\n",
      "epoch:31 step:24780[D loss: 0.412485, acc: 60.16%, op_acc: 39.84%] [G loss: 0.910695]\n",
      "epoch:31 step:24781[D loss: 0.430623, acc: 57.03%, op_acc: 41.41%] [G loss: 0.870621]\n",
      "epoch:31 step:24782[D loss: 0.400763, acc: 60.94%, op_acc: 50.00%] [G loss: 0.892923]\n",
      "epoch:31 step:24783[D loss: 0.395465, acc: 60.94%, op_acc: 43.75%] [G loss: 0.820185]\n",
      "epoch:31 step:24784[D loss: 0.414934, acc: 66.41%, op_acc: 42.19%] [G loss: 0.928154]\n",
      "epoch:31 step:24785[D loss: 0.406612, acc: 58.59%, op_acc: 44.53%] [G loss: 0.847302]\n",
      "epoch:31 step:24786[D loss: 0.439739, acc: 53.12%, op_acc: 39.84%] [G loss: 0.938826]\n",
      "epoch:31 step:24787[D loss: 0.398160, acc: 62.50%, op_acc: 46.09%] [G loss: 0.917714]\n",
      "epoch:31 step:24788[D loss: 0.432822, acc: 60.16%, op_acc: 38.28%] [G loss: 0.874356]\n",
      "epoch:31 step:24789[D loss: 0.465312, acc: 52.34%, op_acc: 36.72%] [G loss: 0.859835]\n",
      "epoch:31 step:24790[D loss: 0.408911, acc: 64.84%, op_acc: 40.62%] [G loss: 0.871873]\n",
      "epoch:31 step:24791[D loss: 0.432399, acc: 64.84%, op_acc: 37.50%] [G loss: 0.854572]\n",
      "epoch:31 step:24792[D loss: 0.437401, acc: 56.25%, op_acc: 42.97%] [G loss: 0.885928]\n",
      "epoch:31 step:24793[D loss: 0.416844, acc: 64.06%, op_acc: 42.97%] [G loss: 0.896292]\n",
      "epoch:31 step:24794[D loss: 0.442267, acc: 53.91%, op_acc: 42.97%] [G loss: 0.892245]\n",
      "epoch:31 step:24795[D loss: 0.476696, acc: 48.44%, op_acc: 31.25%] [G loss: 0.897586]\n",
      "epoch:31 step:24796[D loss: 0.401451, acc: 53.12%, op_acc: 43.75%] [G loss: 0.912482]\n",
      "epoch:31 step:24797[D loss: 0.426222, acc: 58.59%, op_acc: 36.72%] [G loss: 0.855403]\n",
      "epoch:31 step:24798[D loss: 0.390432, acc: 71.88%, op_acc: 38.28%] [G loss: 0.856294]\n",
      "epoch:31 step:24799[D loss: 0.408722, acc: 65.62%, op_acc: 44.53%] [G loss: 0.931233]\n",
      "epoch:31 step:24800[D loss: 0.408107, acc: 57.03%, op_acc: 42.19%] [G loss: 0.919443]\n",
      "##############\n",
      "[0.87681653 0.85790535 0.81232516 0.79642217 0.79700795 0.84239106\n",
      " 0.86169538 0.83925786 0.81405072 0.83178067]\n",
      "##########\n",
      "epoch:31 step:24801[D loss: 0.412169, acc: 64.06%, op_acc: 39.06%] [G loss: 0.852306]\n",
      "epoch:31 step:24802[D loss: 0.447517, acc: 54.69%, op_acc: 35.94%] [G loss: 0.848985]\n",
      "epoch:31 step:24803[D loss: 0.432799, acc: 54.69%, op_acc: 35.16%] [G loss: 0.894185]\n",
      "epoch:31 step:24804[D loss: 0.457855, acc: 53.12%, op_acc: 34.38%] [G loss: 0.891050]\n",
      "epoch:31 step:24805[D loss: 0.406421, acc: 62.50%, op_acc: 41.41%] [G loss: 0.948744]\n",
      "epoch:31 step:24806[D loss: 0.415339, acc: 63.28%, op_acc: 37.50%] [G loss: 0.916030]\n",
      "epoch:31 step:24807[D loss: 0.441767, acc: 58.59%, op_acc: 35.94%] [G loss: 0.892141]\n",
      "epoch:31 step:24808[D loss: 0.387020, acc: 75.00%, op_acc: 41.41%] [G loss: 0.905346]\n",
      "epoch:31 step:24809[D loss: 0.417092, acc: 54.69%, op_acc: 36.72%] [G loss: 0.885895]\n",
      "epoch:31 step:24810[D loss: 0.419814, acc: 62.50%, op_acc: 40.62%] [G loss: 0.949850]\n",
      "epoch:31 step:24811[D loss: 0.440083, acc: 51.56%, op_acc: 35.16%] [G loss: 0.848390]\n",
      "epoch:31 step:24812[D loss: 0.415583, acc: 61.72%, op_acc: 44.53%] [G loss: 0.914116]\n",
      "epoch:31 step:24813[D loss: 0.419161, acc: 57.81%, op_acc: 44.53%] [G loss: 0.913530]\n",
      "epoch:31 step:24814[D loss: 0.378092, acc: 67.19%, op_acc: 46.88%] [G loss: 0.929632]\n",
      "epoch:31 step:24815[D loss: 0.444367, acc: 62.50%, op_acc: 34.38%] [G loss: 0.865161]\n",
      "epoch:31 step:24816[D loss: 0.428188, acc: 57.03%, op_acc: 39.06%] [G loss: 0.824489]\n",
      "epoch:31 step:24817[D loss: 0.430807, acc: 57.03%, op_acc: 42.19%] [G loss: 0.814075]\n",
      "epoch:31 step:24818[D loss: 0.401578, acc: 57.03%, op_acc: 46.09%] [G loss: 0.846672]\n",
      "epoch:31 step:24819[D loss: 0.367711, acc: 69.53%, op_acc: 47.66%] [G loss: 0.959038]\n",
      "epoch:31 step:24820[D loss: 0.418785, acc: 61.72%, op_acc: 38.28%] [G loss: 0.908658]\n",
      "epoch:31 step:24821[D loss: 0.390222, acc: 70.31%, op_acc: 38.28%] [G loss: 0.883673]\n",
      "epoch:31 step:24822[D loss: 0.426199, acc: 57.81%, op_acc: 38.28%] [G loss: 0.849440]\n",
      "epoch:31 step:24823[D loss: 0.412476, acc: 60.16%, op_acc: 42.97%] [G loss: 0.841195]\n",
      "epoch:31 step:24824[D loss: 0.419797, acc: 55.47%, op_acc: 41.41%] [G loss: 0.876780]\n",
      "epoch:31 step:24825[D loss: 0.408449, acc: 64.84%, op_acc: 41.41%] [G loss: 0.896934]\n",
      "epoch:31 step:24826[D loss: 0.421850, acc: 60.16%, op_acc: 44.53%] [G loss: 0.838038]\n",
      "epoch:31 step:24827[D loss: 0.378406, acc: 71.09%, op_acc: 43.75%] [G loss: 0.930652]\n",
      "epoch:31 step:24828[D loss: 0.415368, acc: 62.50%, op_acc: 41.41%] [G loss: 0.990099]\n",
      "epoch:31 step:24829[D loss: 0.407212, acc: 62.50%, op_acc: 44.53%] [G loss: 0.823748]\n",
      "epoch:31 step:24830[D loss: 0.417474, acc: 60.94%, op_acc: 39.06%] [G loss: 0.893705]\n",
      "epoch:31 step:24831[D loss: 0.410002, acc: 67.19%, op_acc: 31.25%] [G loss: 0.912542]\n",
      "epoch:31 step:24832[D loss: 0.412192, acc: 60.94%, op_acc: 45.31%] [G loss: 0.862514]\n",
      "epoch:31 step:24833[D loss: 0.436857, acc: 64.06%, op_acc: 39.84%] [G loss: 0.878758]\n",
      "epoch:31 step:24834[D loss: 0.404042, acc: 66.41%, op_acc: 42.19%] [G loss: 0.860199]\n",
      "epoch:31 step:24835[D loss: 0.416672, acc: 55.47%, op_acc: 43.75%] [G loss: 0.867745]\n",
      "epoch:31 step:24836[D loss: 0.424351, acc: 53.12%, op_acc: 37.50%] [G loss: 0.796233]\n",
      "epoch:31 step:24837[D loss: 0.425768, acc: 50.78%, op_acc: 42.19%] [G loss: 0.876563]\n",
      "epoch:31 step:24838[D loss: 0.431740, acc: 52.34%, op_acc: 40.62%] [G loss: 0.870290]\n",
      "epoch:31 step:24839[D loss: 0.424989, acc: 56.25%, op_acc: 42.19%] [G loss: 0.742250]\n",
      "epoch:31 step:24840[D loss: 0.441624, acc: 55.47%, op_acc: 39.06%] [G loss: 0.876620]\n",
      "epoch:31 step:24841[D loss: 0.406425, acc: 62.50%, op_acc: 49.22%] [G loss: 0.856052]\n",
      "epoch:31 step:24842[D loss: 0.444835, acc: 58.59%, op_acc: 38.28%] [G loss: 0.818931]\n",
      "epoch:31 step:24843[D loss: 0.458075, acc: 49.22%, op_acc: 40.62%] [G loss: 0.795493]\n",
      "epoch:31 step:24844[D loss: 0.424587, acc: 58.59%, op_acc: 35.16%] [G loss: 0.861478]\n",
      "epoch:31 step:24845[D loss: 0.423441, acc: 56.25%, op_acc: 42.97%] [G loss: 0.828400]\n",
      "epoch:31 step:24846[D loss: 0.424226, acc: 56.25%, op_acc: 40.62%] [G loss: 0.914421]\n",
      "epoch:31 step:24847[D loss: 0.384518, acc: 67.19%, op_acc: 42.97%] [G loss: 0.844933]\n",
      "epoch:31 step:24848[D loss: 0.437887, acc: 57.03%, op_acc: 42.19%] [G loss: 0.888894]\n",
      "epoch:31 step:24849[D loss: 0.440345, acc: 53.12%, op_acc: 35.94%] [G loss: 0.894294]\n",
      "epoch:31 step:24850[D loss: 0.415961, acc: 64.06%, op_acc: 35.94%] [G loss: 0.942862]\n",
      "##############\n",
      "[0.8351828  0.85534664 0.81032217 0.81356059 0.79111865 0.85706704\n",
      " 0.90805929 0.82810399 0.81711266 0.82084955]\n",
      "##########\n",
      "epoch:31 step:24851[D loss: 0.407467, acc: 58.59%, op_acc: 48.44%] [G loss: 0.921484]\n",
      "epoch:31 step:24852[D loss: 0.422768, acc: 63.28%, op_acc: 42.97%] [G loss: 0.910607]\n",
      "epoch:31 step:24853[D loss: 0.435378, acc: 50.78%, op_acc: 40.62%] [G loss: 0.889243]\n",
      "epoch:31 step:24854[D loss: 0.433460, acc: 56.25%, op_acc: 42.97%] [G loss: 0.923336]\n",
      "epoch:31 step:24855[D loss: 0.393975, acc: 61.72%, op_acc: 46.88%] [G loss: 0.881906]\n",
      "epoch:31 step:24856[D loss: 0.415119, acc: 63.28%, op_acc: 35.94%] [G loss: 0.909632]\n",
      "epoch:31 step:24857[D loss: 0.424121, acc: 57.81%, op_acc: 42.19%] [G loss: 0.915018]\n",
      "epoch:31 step:24858[D loss: 0.412875, acc: 56.25%, op_acc: 46.09%] [G loss: 0.876885]\n",
      "epoch:31 step:24859[D loss: 0.409388, acc: 64.06%, op_acc: 44.53%] [G loss: 0.911208]\n",
      "epoch:31 step:24860[D loss: 0.392059, acc: 60.94%, op_acc: 42.97%] [G loss: 0.858053]\n",
      "epoch:31 step:24861[D loss: 0.421225, acc: 66.41%, op_acc: 35.94%] [G loss: 0.954116]\n",
      "epoch:31 step:24862[D loss: 0.417751, acc: 57.03%, op_acc: 39.84%] [G loss: 0.905921]\n",
      "epoch:31 step:24863[D loss: 0.430298, acc: 54.69%, op_acc: 40.62%] [G loss: 0.844431]\n",
      "epoch:31 step:24864[D loss: 0.399685, acc: 63.28%, op_acc: 43.75%] [G loss: 0.853427]\n",
      "epoch:31 step:24865[D loss: 0.438472, acc: 50.78%, op_acc: 39.06%] [G loss: 0.920380]\n",
      "epoch:31 step:24866[D loss: 0.431892, acc: 57.81%, op_acc: 42.97%] [G loss: 0.907619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24867[D loss: 0.389738, acc: 66.41%, op_acc: 42.19%] [G loss: 0.972120]\n",
      "epoch:31 step:24868[D loss: 0.413864, acc: 60.94%, op_acc: 41.41%] [G loss: 0.825842]\n",
      "epoch:31 step:24869[D loss: 0.392937, acc: 71.09%, op_acc: 40.62%] [G loss: 0.945056]\n",
      "epoch:31 step:24870[D loss: 0.423475, acc: 59.38%, op_acc: 39.84%] [G loss: 0.916696]\n",
      "epoch:31 step:24871[D loss: 0.406191, acc: 67.19%, op_acc: 40.62%] [G loss: 0.921967]\n",
      "epoch:31 step:24872[D loss: 0.398405, acc: 60.16%, op_acc: 50.78%] [G loss: 0.941988]\n",
      "epoch:31 step:24873[D loss: 0.395268, acc: 59.38%, op_acc: 42.97%] [G loss: 0.903138]\n",
      "epoch:31 step:24874[D loss: 0.422426, acc: 57.03%, op_acc: 46.09%] [G loss: 0.874290]\n",
      "epoch:31 step:24875[D loss: 0.412548, acc: 60.94%, op_acc: 42.19%] [G loss: 0.842171]\n",
      "epoch:31 step:24876[D loss: 0.442913, acc: 64.06%, op_acc: 31.25%] [G loss: 0.882616]\n",
      "epoch:31 step:24877[D loss: 0.397996, acc: 61.72%, op_acc: 40.62%] [G loss: 0.921717]\n",
      "epoch:31 step:24878[D loss: 0.402731, acc: 67.19%, op_acc: 37.50%] [G loss: 0.925535]\n",
      "epoch:31 step:24879[D loss: 0.431961, acc: 53.12%, op_acc: 40.62%] [G loss: 0.880422]\n",
      "epoch:31 step:24880[D loss: 0.412306, acc: 65.62%, op_acc: 37.50%] [G loss: 0.925475]\n",
      "epoch:31 step:24881[D loss: 0.411624, acc: 61.72%, op_acc: 39.84%] [G loss: 0.954363]\n",
      "epoch:31 step:24882[D loss: 0.417701, acc: 57.81%, op_acc: 41.41%] [G loss: 0.848794]\n",
      "epoch:31 step:24883[D loss: 0.446663, acc: 55.47%, op_acc: 41.41%] [G loss: 0.975555]\n",
      "epoch:31 step:24884[D loss: 0.440319, acc: 53.12%, op_acc: 36.72%] [G loss: 0.869778]\n",
      "epoch:31 step:24885[D loss: 0.425651, acc: 63.28%, op_acc: 35.16%] [G loss: 0.884471]\n",
      "epoch:31 step:24886[D loss: 0.401135, acc: 64.84%, op_acc: 42.19%] [G loss: 0.947361]\n",
      "epoch:31 step:24887[D loss: 0.432349, acc: 60.16%, op_acc: 38.28%] [G loss: 0.902781]\n",
      "epoch:31 step:24888[D loss: 0.442977, acc: 52.34%, op_acc: 41.41%] [G loss: 0.971419]\n",
      "epoch:31 step:24889[D loss: 0.391393, acc: 59.38%, op_acc: 45.31%] [G loss: 0.857041]\n",
      "epoch:31 step:24890[D loss: 0.410322, acc: 64.84%, op_acc: 42.97%] [G loss: 0.873190]\n",
      "epoch:31 step:24891[D loss: 0.467117, acc: 51.56%, op_acc: 38.28%] [G loss: 0.814636]\n",
      "epoch:31 step:24892[D loss: 0.442195, acc: 60.94%, op_acc: 38.28%] [G loss: 0.948272]\n",
      "epoch:31 step:24893[D loss: 0.375434, acc: 71.88%, op_acc: 39.06%] [G loss: 0.900211]\n",
      "epoch:31 step:24894[D loss: 0.442450, acc: 52.34%, op_acc: 40.62%] [G loss: 0.870099]\n",
      "epoch:31 step:24895[D loss: 0.408467, acc: 59.38%, op_acc: 43.75%] [G loss: 0.850816]\n",
      "epoch:31 step:24896[D loss: 0.454579, acc: 53.91%, op_acc: 40.62%] [G loss: 0.889219]\n",
      "epoch:31 step:24897[D loss: 0.444856, acc: 50.00%, op_acc: 39.84%] [G loss: 0.864733]\n",
      "epoch:31 step:24898[D loss: 0.434441, acc: 57.81%, op_acc: 40.62%] [G loss: 0.868869]\n",
      "epoch:31 step:24899[D loss: 0.404899, acc: 61.72%, op_acc: 44.53%] [G loss: 0.992251]\n",
      "epoch:31 step:24900[D loss: 0.404655, acc: 63.28%, op_acc: 42.19%] [G loss: 0.888938]\n",
      "##############\n",
      "[0.85360682 0.84388141 0.80730873 0.78989618 0.78520958 0.82351267\n",
      " 0.88256828 0.83413028 0.77939715 0.83441881]\n",
      "##########\n",
      "epoch:31 step:24901[D loss: 0.437572, acc: 59.38%, op_acc: 34.38%] [G loss: 0.892480]\n",
      "epoch:31 step:24902[D loss: 0.409351, acc: 65.62%, op_acc: 42.97%] [G loss: 0.896581]\n",
      "epoch:31 step:24903[D loss: 0.424247, acc: 57.81%, op_acc: 42.19%] [G loss: 0.963347]\n",
      "epoch:31 step:24904[D loss: 0.457451, acc: 53.91%, op_acc: 34.38%] [G loss: 0.876664]\n",
      "epoch:31 step:24905[D loss: 0.419628, acc: 57.03%, op_acc: 43.75%] [G loss: 0.814882]\n",
      "epoch:31 step:24906[D loss: 0.425234, acc: 59.38%, op_acc: 38.28%] [G loss: 0.904686]\n",
      "epoch:31 step:24907[D loss: 0.432846, acc: 57.81%, op_acc: 38.28%] [G loss: 0.959259]\n",
      "epoch:31 step:24908[D loss: 0.423881, acc: 53.91%, op_acc: 45.31%] [G loss: 0.911686]\n",
      "epoch:31 step:24909[D loss: 0.416165, acc: 61.72%, op_acc: 43.75%] [G loss: 0.906155]\n",
      "epoch:31 step:24910[D loss: 0.414213, acc: 60.16%, op_acc: 40.62%] [G loss: 0.899440]\n",
      "epoch:31 step:24911[D loss: 0.419909, acc: 57.81%, op_acc: 39.84%] [G loss: 0.798105]\n",
      "epoch:31 step:24912[D loss: 0.443014, acc: 57.03%, op_acc: 35.94%] [G loss: 0.797086]\n",
      "epoch:31 step:24913[D loss: 0.420325, acc: 60.16%, op_acc: 39.84%] [G loss: 0.920404]\n",
      "epoch:31 step:24914[D loss: 0.451650, acc: 51.56%, op_acc: 38.28%] [G loss: 0.848939]\n",
      "epoch:31 step:24915[D loss: 0.401331, acc: 57.03%, op_acc: 42.19%] [G loss: 0.856413]\n",
      "epoch:31 step:24916[D loss: 0.417630, acc: 64.06%, op_acc: 32.81%] [G loss: 0.856160]\n",
      "epoch:31 step:24917[D loss: 0.435182, acc: 50.78%, op_acc: 37.50%] [G loss: 0.784337]\n",
      "epoch:31 step:24918[D loss: 0.431889, acc: 54.69%, op_acc: 38.28%] [G loss: 0.845862]\n",
      "epoch:31 step:24919[D loss: 0.444729, acc: 55.47%, op_acc: 38.28%] [G loss: 0.842887]\n",
      "epoch:31 step:24920[D loss: 0.406428, acc: 57.03%, op_acc: 44.53%] [G loss: 0.824064]\n",
      "epoch:31 step:24921[D loss: 0.381638, acc: 58.59%, op_acc: 46.09%] [G loss: 0.873053]\n",
      "epoch:31 step:24922[D loss: 0.432232, acc: 50.00%, op_acc: 40.62%] [G loss: 0.846403]\n",
      "epoch:31 step:24923[D loss: 0.438985, acc: 50.00%, op_acc: 43.75%] [G loss: 0.905136]\n",
      "epoch:31 step:24924[D loss: 0.433302, acc: 60.94%, op_acc: 38.28%] [G loss: 0.880744]\n",
      "epoch:31 step:24925[D loss: 0.428915, acc: 57.81%, op_acc: 40.62%] [G loss: 0.824786]\n",
      "epoch:31 step:24926[D loss: 0.392127, acc: 66.41%, op_acc: 48.44%] [G loss: 0.900905]\n",
      "epoch:31 step:24927[D loss: 0.397111, acc: 64.06%, op_acc: 40.62%] [G loss: 0.812633]\n",
      "epoch:31 step:24928[D loss: 0.377124, acc: 70.31%, op_acc: 50.00%] [G loss: 0.922708]\n",
      "epoch:31 step:24929[D loss: 0.412065, acc: 62.50%, op_acc: 39.84%] [G loss: 0.862592]\n",
      "epoch:31 step:24930[D loss: 0.437546, acc: 54.69%, op_acc: 37.50%] [G loss: 0.836961]\n",
      "epoch:31 step:24931[D loss: 0.443369, acc: 57.03%, op_acc: 39.06%] [G loss: 0.866129]\n",
      "epoch:31 step:24932[D loss: 0.417446, acc: 56.25%, op_acc: 35.94%] [G loss: 0.839590]\n",
      "epoch:31 step:24933[D loss: 0.398640, acc: 67.97%, op_acc: 41.41%] [G loss: 0.859587]\n",
      "epoch:31 step:24934[D loss: 0.412201, acc: 57.03%, op_acc: 45.31%] [G loss: 0.919501]\n",
      "epoch:31 step:24935[D loss: 0.460410, acc: 48.44%, op_acc: 35.16%] [G loss: 0.900557]\n",
      "epoch:31 step:24936[D loss: 0.436311, acc: 60.94%, op_acc: 42.19%] [G loss: 0.908718]\n",
      "epoch:31 step:24937[D loss: 0.419042, acc: 62.50%, op_acc: 37.50%] [G loss: 0.865829]\n",
      "epoch:31 step:24938[D loss: 0.422357, acc: 60.16%, op_acc: 37.50%] [G loss: 0.989680]\n",
      "epoch:31 step:24939[D loss: 0.430702, acc: 58.59%, op_acc: 39.84%] [G loss: 0.828125]\n",
      "epoch:31 step:24940[D loss: 0.432563, acc: 55.47%, op_acc: 42.97%] [G loss: 0.880124]\n",
      "epoch:31 step:24941[D loss: 0.402359, acc: 64.06%, op_acc: 40.62%] [G loss: 0.821374]\n",
      "epoch:31 step:24942[D loss: 0.397678, acc: 64.06%, op_acc: 46.88%] [G loss: 0.896778]\n",
      "epoch:31 step:24943[D loss: 0.401351, acc: 63.28%, op_acc: 44.53%] [G loss: 0.856374]\n",
      "epoch:31 step:24944[D loss: 0.417083, acc: 60.94%, op_acc: 39.06%] [G loss: 0.860690]\n",
      "epoch:31 step:24945[D loss: 0.444570, acc: 54.69%, op_acc: 45.31%] [G loss: 0.933585]\n",
      "epoch:31 step:24946[D loss: 0.421216, acc: 55.47%, op_acc: 45.31%] [G loss: 0.897049]\n",
      "epoch:31 step:24947[D loss: 0.415778, acc: 60.94%, op_acc: 40.62%] [G loss: 0.922379]\n",
      "epoch:31 step:24948[D loss: 0.411644, acc: 56.25%, op_acc: 40.62%] [G loss: 0.837796]\n",
      "epoch:31 step:24949[D loss: 0.407382, acc: 61.72%, op_acc: 42.19%] [G loss: 0.869703]\n",
      "epoch:31 step:24950[D loss: 0.410114, acc: 60.16%, op_acc: 42.19%] [G loss: 0.892408]\n",
      "##############\n",
      "[0.86407061 0.83991049 0.8308679  0.81397278 0.79102966 0.81905058\n",
      " 0.89719213 0.83380462 0.81570672 0.82969495]\n",
      "##########\n",
      "epoch:31 step:24951[D loss: 0.412335, acc: 55.47%, op_acc: 39.06%] [G loss: 0.793889]\n",
      "epoch:31 step:24952[D loss: 0.403633, acc: 64.84%, op_acc: 39.84%] [G loss: 0.899249]\n",
      "epoch:31 step:24953[D loss: 0.431095, acc: 60.94%, op_acc: 38.28%] [G loss: 0.892033]\n",
      "epoch:31 step:24954[D loss: 0.426982, acc: 61.72%, op_acc: 35.16%] [G loss: 0.869582]\n",
      "epoch:31 step:24955[D loss: 0.408513, acc: 54.69%, op_acc: 40.62%] [G loss: 0.852290]\n",
      "epoch:31 step:24956[D loss: 0.442258, acc: 50.00%, op_acc: 42.19%] [G loss: 0.843520]\n",
      "epoch:31 step:24957[D loss: 0.393544, acc: 65.62%, op_acc: 41.41%] [G loss: 0.887215]\n",
      "epoch:31 step:24958[D loss: 0.453804, acc: 53.12%, op_acc: 39.06%] [G loss: 0.814481]\n",
      "epoch:31 step:24959[D loss: 0.441382, acc: 58.59%, op_acc: 39.84%] [G loss: 0.879367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24960[D loss: 0.443214, acc: 57.03%, op_acc: 34.38%] [G loss: 0.899326]\n",
      "epoch:31 step:24961[D loss: 0.422533, acc: 59.38%, op_acc: 39.84%] [G loss: 0.850858]\n",
      "epoch:31 step:24962[D loss: 0.448704, acc: 60.94%, op_acc: 35.16%] [G loss: 0.868282]\n",
      "epoch:31 step:24963[D loss: 0.428544, acc: 54.69%, op_acc: 39.84%] [G loss: 0.795845]\n",
      "epoch:31 step:24964[D loss: 0.393893, acc: 63.28%, op_acc: 40.62%] [G loss: 0.892361]\n",
      "epoch:31 step:24965[D loss: 0.420626, acc: 60.94%, op_acc: 40.62%] [G loss: 0.919315]\n",
      "epoch:31 step:24966[D loss: 0.399809, acc: 64.06%, op_acc: 39.84%] [G loss: 0.830622]\n",
      "epoch:31 step:24967[D loss: 0.389020, acc: 65.62%, op_acc: 43.75%] [G loss: 0.936809]\n",
      "epoch:31 step:24968[D loss: 0.437739, acc: 53.91%, op_acc: 35.94%] [G loss: 0.861742]\n",
      "epoch:31 step:24969[D loss: 0.408475, acc: 58.59%, op_acc: 42.19%] [G loss: 0.854734]\n",
      "epoch:31 step:24970[D loss: 0.405819, acc: 62.50%, op_acc: 45.31%] [G loss: 0.877926]\n",
      "epoch:31 step:24971[D loss: 0.429783, acc: 52.34%, op_acc: 39.06%] [G loss: 0.814011]\n",
      "epoch:31 step:24972[D loss: 0.398429, acc: 62.50%, op_acc: 39.84%] [G loss: 0.859662]\n",
      "epoch:31 step:24973[D loss: 0.419804, acc: 56.25%, op_acc: 39.84%] [G loss: 0.838817]\n",
      "epoch:31 step:24974[D loss: 0.446388, acc: 52.34%, op_acc: 42.19%] [G loss: 0.853368]\n",
      "epoch:31 step:24975[D loss: 0.426712, acc: 59.38%, op_acc: 39.84%] [G loss: 0.821290]\n",
      "epoch:31 step:24976[D loss: 0.410515, acc: 59.38%, op_acc: 47.66%] [G loss: 0.883044]\n",
      "epoch:31 step:24977[D loss: 0.433381, acc: 50.00%, op_acc: 39.06%] [G loss: 0.795615]\n",
      "epoch:31 step:24978[D loss: 0.431943, acc: 51.56%, op_acc: 34.38%] [G loss: 0.961858]\n",
      "epoch:31 step:24979[D loss: 0.449626, acc: 46.09%, op_acc: 39.84%] [G loss: 0.870342]\n",
      "epoch:31 step:24980[D loss: 0.414701, acc: 55.47%, op_acc: 41.41%] [G loss: 0.854372]\n",
      "epoch:31 step:24981[D loss: 0.409892, acc: 61.72%, op_acc: 38.28%] [G loss: 0.853412]\n",
      "epoch:31 step:24982[D loss: 0.455413, acc: 49.22%, op_acc: 35.94%] [G loss: 0.895712]\n",
      "epoch:31 step:24983[D loss: 0.446477, acc: 55.47%, op_acc: 37.50%] [G loss: 1.004641]\n",
      "epoch:31 step:24984[D loss: 0.420579, acc: 63.28%, op_acc: 38.28%] [G loss: 0.958919]\n",
      "epoch:31 step:24985[D loss: 0.383707, acc: 66.41%, op_acc: 47.66%] [G loss: 0.944073]\n",
      "epoch:31 step:24986[D loss: 0.422563, acc: 59.38%, op_acc: 42.19%] [G loss: 0.902234]\n",
      "epoch:31 step:24987[D loss: 0.437610, acc: 55.47%, op_acc: 35.94%] [G loss: 0.899182]\n",
      "epoch:31 step:24988[D loss: 0.439492, acc: 57.03%, op_acc: 39.84%] [G loss: 0.850171]\n",
      "epoch:31 step:24989[D loss: 0.444057, acc: 50.78%, op_acc: 40.62%] [G loss: 0.915715]\n",
      "epoch:31 step:24990[D loss: 0.407153, acc: 65.62%, op_acc: 40.62%] [G loss: 0.855866]\n",
      "epoch:31 step:24991[D loss: 0.410133, acc: 64.06%, op_acc: 41.41%] [G loss: 0.919373]\n",
      "epoch:31 step:24992[D loss: 0.441206, acc: 50.00%, op_acc: 37.50%] [G loss: 0.824261]\n",
      "epoch:32 step:24993[D loss: 0.403725, acc: 60.16%, op_acc: 43.75%] [G loss: 0.878963]\n",
      "epoch:32 step:24994[D loss: 0.423794, acc: 60.16%, op_acc: 39.06%] [G loss: 0.958343]\n",
      "epoch:32 step:24995[D loss: 0.395430, acc: 66.41%, op_acc: 39.06%] [G loss: 0.879902]\n",
      "epoch:32 step:24996[D loss: 0.410114, acc: 57.81%, op_acc: 40.62%] [G loss: 0.887149]\n",
      "epoch:32 step:24997[D loss: 0.405473, acc: 67.19%, op_acc: 42.97%] [G loss: 0.916038]\n",
      "epoch:32 step:24998[D loss: 0.422023, acc: 59.38%, op_acc: 39.84%] [G loss: 0.926118]\n",
      "epoch:32 step:24999[D loss: 0.399008, acc: 64.06%, op_acc: 44.53%] [G loss: 0.793487]\n",
      "epoch:32 step:25000[D loss: 0.441293, acc: 54.69%, op_acc: 39.84%] [G loss: 0.939258]\n",
      "##############\n",
      "[0.85308803 0.86727376 0.82053249 0.79981379 0.80213217 0.81530966\n",
      " 0.90003925 0.8400714  0.81714591 0.82281664]\n",
      "##########\n",
      "epoch:32 step:25001[D loss: 0.406263, acc: 60.94%, op_acc: 42.19%] [G loss: 0.918278]\n",
      "epoch:32 step:25002[D loss: 0.425482, acc: 63.28%, op_acc: 36.72%] [G loss: 0.918101]\n",
      "epoch:32 step:25003[D loss: 0.424783, acc: 60.16%, op_acc: 42.19%] [G loss: 0.912649]\n",
      "epoch:32 step:25004[D loss: 0.423514, acc: 61.72%, op_acc: 39.84%] [G loss: 0.874234]\n",
      "epoch:32 step:25005[D loss: 0.414628, acc: 63.28%, op_acc: 38.28%] [G loss: 0.964931]\n",
      "epoch:32 step:25006[D loss: 0.410534, acc: 65.62%, op_acc: 37.50%] [G loss: 0.914592]\n",
      "epoch:32 step:25007[D loss: 0.422242, acc: 54.69%, op_acc: 46.88%] [G loss: 0.871168]\n",
      "epoch:32 step:25008[D loss: 0.395598, acc: 57.81%, op_acc: 45.31%] [G loss: 0.867164]\n",
      "epoch:32 step:25009[D loss: 0.406547, acc: 57.81%, op_acc: 43.75%] [G loss: 0.870368]\n",
      "epoch:32 step:25010[D loss: 0.447931, acc: 53.91%, op_acc: 35.16%] [G loss: 0.794803]\n",
      "epoch:32 step:25011[D loss: 0.394268, acc: 64.84%, op_acc: 43.75%] [G loss: 0.874064]\n",
      "epoch:32 step:25012[D loss: 0.400117, acc: 59.38%, op_acc: 41.41%] [G loss: 0.892225]\n",
      "epoch:32 step:25013[D loss: 0.428774, acc: 58.59%, op_acc: 39.06%] [G loss: 0.853743]\n",
      "epoch:32 step:25014[D loss: 0.433907, acc: 52.34%, op_acc: 39.84%] [G loss: 0.896859]\n",
      "epoch:32 step:25015[D loss: 0.409803, acc: 62.50%, op_acc: 42.97%] [G loss: 0.919264]\n",
      "epoch:32 step:25016[D loss: 0.474424, acc: 55.47%, op_acc: 35.16%] [G loss: 0.833256]\n",
      "epoch:32 step:25017[D loss: 0.450535, acc: 57.03%, op_acc: 35.16%] [G loss: 0.868876]\n",
      "epoch:32 step:25018[D loss: 0.417099, acc: 57.03%, op_acc: 42.19%] [G loss: 0.838386]\n",
      "epoch:32 step:25019[D loss: 0.406160, acc: 69.53%, op_acc: 39.06%] [G loss: 0.844757]\n",
      "epoch:32 step:25020[D loss: 0.402756, acc: 65.62%, op_acc: 42.19%] [G loss: 0.920094]\n",
      "epoch:32 step:25021[D loss: 0.412450, acc: 59.38%, op_acc: 40.62%] [G loss: 0.849611]\n",
      "epoch:32 step:25022[D loss: 0.402521, acc: 59.38%, op_acc: 38.28%] [G loss: 0.850850]\n",
      "epoch:32 step:25023[D loss: 0.443035, acc: 57.03%, op_acc: 35.16%] [G loss: 0.939400]\n",
      "epoch:32 step:25024[D loss: 0.444381, acc: 47.66%, op_acc: 39.06%] [G loss: 0.894343]\n",
      "epoch:32 step:25025[D loss: 0.415912, acc: 59.38%, op_acc: 44.53%] [G loss: 0.874592]\n",
      "epoch:32 step:25026[D loss: 0.389636, acc: 67.97%, op_acc: 39.84%] [G loss: 0.912638]\n",
      "epoch:32 step:25027[D loss: 0.451257, acc: 54.69%, op_acc: 38.28%] [G loss: 0.865215]\n",
      "epoch:32 step:25028[D loss: 0.415958, acc: 53.91%, op_acc: 40.62%] [G loss: 0.912791]\n",
      "epoch:32 step:25029[D loss: 0.406099, acc: 58.59%, op_acc: 47.66%] [G loss: 0.951062]\n",
      "epoch:32 step:25030[D loss: 0.417367, acc: 56.25%, op_acc: 40.62%] [G loss: 0.893122]\n",
      "epoch:32 step:25031[D loss: 0.393115, acc: 59.38%, op_acc: 47.66%] [G loss: 0.877939]\n",
      "epoch:32 step:25032[D loss: 0.384172, acc: 73.44%, op_acc: 39.06%] [G loss: 0.905659]\n",
      "epoch:32 step:25033[D loss: 0.411839, acc: 62.50%, op_acc: 39.84%] [G loss: 0.955526]\n",
      "epoch:32 step:25034[D loss: 0.404242, acc: 61.72%, op_acc: 46.09%] [G loss: 0.950503]\n",
      "epoch:32 step:25035[D loss: 0.409452, acc: 65.62%, op_acc: 39.06%] [G loss: 0.921629]\n",
      "epoch:32 step:25036[D loss: 0.398886, acc: 60.94%, op_acc: 40.62%] [G loss: 0.903770]\n",
      "epoch:32 step:25037[D loss: 0.405564, acc: 60.94%, op_acc: 46.09%] [G loss: 0.888194]\n",
      "epoch:32 step:25038[D loss: 0.402649, acc: 64.06%, op_acc: 40.62%] [G loss: 0.885679]\n",
      "epoch:32 step:25039[D loss: 0.426670, acc: 59.38%, op_acc: 35.94%] [G loss: 0.859186]\n",
      "epoch:32 step:25040[D loss: 0.444533, acc: 52.34%, op_acc: 38.28%] [G loss: 0.887440]\n",
      "epoch:32 step:25041[D loss: 0.408880, acc: 63.28%, op_acc: 39.06%] [G loss: 0.884274]\n",
      "epoch:32 step:25042[D loss: 0.444624, acc: 57.03%, op_acc: 36.72%] [G loss: 0.845959]\n",
      "epoch:32 step:25043[D loss: 0.399028, acc: 61.72%, op_acc: 38.28%] [G loss: 0.851102]\n",
      "epoch:32 step:25044[D loss: 0.411700, acc: 62.50%, op_acc: 37.50%] [G loss: 0.891721]\n",
      "epoch:32 step:25045[D loss: 0.435843, acc: 60.16%, op_acc: 34.38%] [G loss: 0.921113]\n",
      "epoch:32 step:25046[D loss: 0.433438, acc: 60.94%, op_acc: 36.72%] [G loss: 0.905971]\n",
      "epoch:32 step:25047[D loss: 0.417053, acc: 50.00%, op_acc: 44.53%] [G loss: 0.866944]\n",
      "epoch:32 step:25048[D loss: 0.403039, acc: 60.16%, op_acc: 40.62%] [G loss: 0.940685]\n",
      "epoch:32 step:25049[D loss: 0.432536, acc: 57.81%, op_acc: 37.50%] [G loss: 0.810844]\n",
      "epoch:32 step:25050[D loss: 0.404121, acc: 54.69%, op_acc: 43.75%] [G loss: 0.982270]\n",
      "##############\n",
      "[0.84108172 0.86880071 0.80138074 0.80501892 0.79175315 0.83514434\n",
      " 0.89014838 0.82969197 0.79675625 0.83010923]\n",
      "##########\n",
      "epoch:32 step:25051[D loss: 0.397882, acc: 63.28%, op_acc: 41.41%] [G loss: 0.941085]\n",
      "epoch:32 step:25052[D loss: 0.409752, acc: 59.38%, op_acc: 39.06%] [G loss: 0.882313]\n",
      "epoch:32 step:25053[D loss: 0.442563, acc: 57.81%, op_acc: 36.72%] [G loss: 0.868320]\n",
      "epoch:32 step:25054[D loss: 0.422111, acc: 57.03%, op_acc: 42.19%] [G loss: 0.911649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25055[D loss: 0.419363, acc: 60.16%, op_acc: 45.31%] [G loss: 0.885552]\n",
      "epoch:32 step:25056[D loss: 0.400557, acc: 64.06%, op_acc: 40.62%] [G loss: 0.868637]\n",
      "epoch:32 step:25057[D loss: 0.458258, acc: 53.12%, op_acc: 36.72%] [G loss: 0.916048]\n",
      "epoch:32 step:25058[D loss: 0.424836, acc: 55.47%, op_acc: 39.06%] [G loss: 0.937496]\n",
      "epoch:32 step:25059[D loss: 0.412044, acc: 62.50%, op_acc: 40.62%] [G loss: 0.956111]\n",
      "epoch:32 step:25060[D loss: 0.417676, acc: 62.50%, op_acc: 40.62%] [G loss: 0.907049]\n",
      "epoch:32 step:25061[D loss: 0.375123, acc: 72.66%, op_acc: 46.88%] [G loss: 0.873899]\n",
      "epoch:32 step:25062[D loss: 0.418200, acc: 62.50%, op_acc: 46.88%] [G loss: 0.841136]\n",
      "epoch:32 step:25063[D loss: 0.462747, acc: 51.56%, op_acc: 39.84%] [G loss: 0.906739]\n",
      "epoch:32 step:25064[D loss: 0.415732, acc: 58.59%, op_acc: 39.06%] [G loss: 0.746553]\n",
      "epoch:32 step:25065[D loss: 0.441299, acc: 54.69%, op_acc: 35.16%] [G loss: 0.858064]\n",
      "epoch:32 step:25066[D loss: 0.387098, acc: 64.06%, op_acc: 36.72%] [G loss: 0.849614]\n",
      "epoch:32 step:25067[D loss: 0.391306, acc: 66.41%, op_acc: 42.19%] [G loss: 0.940723]\n",
      "epoch:32 step:25068[D loss: 0.461336, acc: 57.03%, op_acc: 36.72%] [G loss: 0.854440]\n",
      "epoch:32 step:25069[D loss: 0.425164, acc: 55.47%, op_acc: 42.97%] [G loss: 0.897105]\n",
      "epoch:32 step:25070[D loss: 0.435463, acc: 60.16%, op_acc: 31.25%] [G loss: 0.909806]\n",
      "epoch:32 step:25071[D loss: 0.432600, acc: 52.34%, op_acc: 42.19%] [G loss: 0.856075]\n",
      "epoch:32 step:25072[D loss: 0.428496, acc: 64.84%, op_acc: 37.50%] [G loss: 0.922204]\n",
      "epoch:32 step:25073[D loss: 0.428428, acc: 60.94%, op_acc: 34.38%] [G loss: 0.869769]\n",
      "epoch:32 step:25074[D loss: 0.423368, acc: 57.03%, op_acc: 42.97%] [G loss: 0.883497]\n",
      "epoch:32 step:25075[D loss: 0.439837, acc: 58.59%, op_acc: 35.16%] [G loss: 0.819702]\n",
      "epoch:32 step:25076[D loss: 0.413514, acc: 62.50%, op_acc: 41.41%] [G loss: 0.855215]\n",
      "epoch:32 step:25077[D loss: 0.450810, acc: 53.12%, op_acc: 39.06%] [G loss: 0.827528]\n",
      "epoch:32 step:25078[D loss: 0.414211, acc: 62.50%, op_acc: 42.97%] [G loss: 0.865730]\n",
      "epoch:32 step:25079[D loss: 0.429063, acc: 54.69%, op_acc: 39.06%] [G loss: 0.879914]\n",
      "epoch:32 step:25080[D loss: 0.412351, acc: 64.84%, op_acc: 41.41%] [G loss: 0.934950]\n",
      "epoch:32 step:25081[D loss: 0.408050, acc: 61.72%, op_acc: 45.31%] [G loss: 0.976594]\n",
      "epoch:32 step:25082[D loss: 0.433566, acc: 51.56%, op_acc: 42.97%] [G loss: 0.903666]\n",
      "epoch:32 step:25083[D loss: 0.399374, acc: 58.59%, op_acc: 42.97%] [G loss: 0.861059]\n",
      "epoch:32 step:25084[D loss: 0.443138, acc: 54.69%, op_acc: 37.50%] [G loss: 0.849710]\n",
      "epoch:32 step:25085[D loss: 0.374020, acc: 67.19%, op_acc: 39.06%] [G loss: 0.910696]\n",
      "epoch:32 step:25086[D loss: 0.419923, acc: 53.12%, op_acc: 42.19%] [G loss: 0.874680]\n",
      "epoch:32 step:25087[D loss: 0.400061, acc: 64.06%, op_acc: 39.06%] [G loss: 0.862999]\n",
      "epoch:32 step:25088[D loss: 0.429852, acc: 60.94%, op_acc: 39.84%] [G loss: 0.798371]\n",
      "epoch:32 step:25089[D loss: 0.415307, acc: 60.16%, op_acc: 43.75%] [G loss: 0.854598]\n",
      "epoch:32 step:25090[D loss: 0.433108, acc: 56.25%, op_acc: 37.50%] [G loss: 0.851756]\n",
      "epoch:32 step:25091[D loss: 0.396562, acc: 65.62%, op_acc: 45.31%] [G loss: 0.843397]\n",
      "epoch:32 step:25092[D loss: 0.433942, acc: 52.34%, op_acc: 40.62%] [G loss: 0.826081]\n",
      "epoch:32 step:25093[D loss: 0.409961, acc: 67.19%, op_acc: 42.19%] [G loss: 0.928647]\n",
      "epoch:32 step:25094[D loss: 0.420776, acc: 57.03%, op_acc: 39.84%] [G loss: 0.937427]\n",
      "epoch:32 step:25095[D loss: 0.414688, acc: 57.03%, op_acc: 42.97%] [G loss: 0.821046]\n",
      "epoch:32 step:25096[D loss: 0.449938, acc: 53.12%, op_acc: 32.81%] [G loss: 0.920193]\n",
      "epoch:32 step:25097[D loss: 0.421642, acc: 63.28%, op_acc: 38.28%] [G loss: 0.865941]\n",
      "epoch:32 step:25098[D loss: 0.415642, acc: 59.38%, op_acc: 40.62%] [G loss: 0.876770]\n",
      "epoch:32 step:25099[D loss: 0.459619, acc: 53.91%, op_acc: 31.25%] [G loss: 0.944806]\n",
      "epoch:32 step:25100[D loss: 0.425250, acc: 66.41%, op_acc: 37.50%] [G loss: 0.924665]\n",
      "##############\n",
      "[0.86372969 0.86422173 0.8036985  0.80725237 0.78825662 0.82589131\n",
      " 0.90322213 0.81753947 0.80473169 0.83700352]\n",
      "##########\n",
      "epoch:32 step:25101[D loss: 0.421986, acc: 58.59%, op_acc: 44.53%] [G loss: 0.875898]\n",
      "epoch:32 step:25102[D loss: 0.420510, acc: 57.03%, op_acc: 42.19%] [G loss: 0.916069]\n",
      "epoch:32 step:25103[D loss: 0.422481, acc: 62.50%, op_acc: 36.72%] [G loss: 0.908475]\n",
      "epoch:32 step:25104[D loss: 0.429196, acc: 57.81%, op_acc: 40.62%] [G loss: 0.894948]\n",
      "epoch:32 step:25105[D loss: 0.427299, acc: 57.81%, op_acc: 39.84%] [G loss: 0.943434]\n",
      "epoch:32 step:25106[D loss: 0.400768, acc: 65.62%, op_acc: 47.66%] [G loss: 0.891847]\n",
      "epoch:32 step:25107[D loss: 0.375501, acc: 65.62%, op_acc: 44.53%] [G loss: 0.901395]\n",
      "epoch:32 step:25108[D loss: 0.424260, acc: 61.72%, op_acc: 38.28%] [G loss: 0.924409]\n",
      "epoch:32 step:25109[D loss: 0.407583, acc: 61.72%, op_acc: 38.28%] [G loss: 0.855688]\n",
      "epoch:32 step:25110[D loss: 0.425080, acc: 57.03%, op_acc: 41.41%] [G loss: 0.875399]\n",
      "epoch:32 step:25111[D loss: 0.420619, acc: 61.72%, op_acc: 37.50%] [G loss: 0.906032]\n",
      "epoch:32 step:25112[D loss: 0.388236, acc: 67.97%, op_acc: 42.19%] [G loss: 0.889561]\n",
      "epoch:32 step:25113[D loss: 0.392211, acc: 70.31%, op_acc: 39.84%] [G loss: 0.898444]\n",
      "epoch:32 step:25114[D loss: 0.423997, acc: 57.03%, op_acc: 42.97%] [G loss: 0.828841]\n",
      "epoch:32 step:25115[D loss: 0.446216, acc: 54.69%, op_acc: 40.62%] [G loss: 0.828288]\n",
      "epoch:32 step:25116[D loss: 0.415173, acc: 64.06%, op_acc: 39.84%] [G loss: 0.807606]\n",
      "epoch:32 step:25117[D loss: 0.439167, acc: 56.25%, op_acc: 41.41%] [G loss: 0.849187]\n",
      "epoch:32 step:25118[D loss: 0.407992, acc: 61.72%, op_acc: 43.75%] [G loss: 0.932992]\n",
      "epoch:32 step:25119[D loss: 0.405793, acc: 58.59%, op_acc: 44.53%] [G loss: 0.896890]\n",
      "epoch:32 step:25120[D loss: 0.429706, acc: 57.03%, op_acc: 35.16%] [G loss: 0.802699]\n",
      "epoch:32 step:25121[D loss: 0.449803, acc: 58.59%, op_acc: 35.94%] [G loss: 0.860836]\n",
      "epoch:32 step:25122[D loss: 0.424924, acc: 55.47%, op_acc: 44.53%] [G loss: 0.887574]\n",
      "epoch:32 step:25123[D loss: 0.405824, acc: 64.06%, op_acc: 40.62%] [G loss: 0.890970]\n",
      "epoch:32 step:25124[D loss: 0.411034, acc: 59.38%, op_acc: 42.19%] [G loss: 0.864315]\n",
      "epoch:32 step:25125[D loss: 0.457736, acc: 58.59%, op_acc: 35.16%] [G loss: 0.926887]\n",
      "epoch:32 step:25126[D loss: 0.409892, acc: 61.72%, op_acc: 39.84%] [G loss: 0.864698]\n",
      "epoch:32 step:25127[D loss: 0.445988, acc: 53.12%, op_acc: 40.62%] [G loss: 0.889797]\n",
      "epoch:32 step:25128[D loss: 0.403964, acc: 60.94%, op_acc: 43.75%] [G loss: 0.898548]\n",
      "epoch:32 step:25129[D loss: 0.413718, acc: 62.50%, op_acc: 39.06%] [G loss: 0.891494]\n",
      "epoch:32 step:25130[D loss: 0.447100, acc: 57.03%, op_acc: 42.19%] [G loss: 0.917664]\n",
      "epoch:32 step:25131[D loss: 0.414903, acc: 60.94%, op_acc: 42.97%] [G loss: 0.913728]\n",
      "epoch:32 step:25132[D loss: 0.465451, acc: 50.00%, op_acc: 41.41%] [G loss: 0.910841]\n",
      "epoch:32 step:25133[D loss: 0.417647, acc: 63.28%, op_acc: 38.28%] [G loss: 0.834601]\n",
      "epoch:32 step:25134[D loss: 0.420806, acc: 58.59%, op_acc: 47.66%] [G loss: 0.853003]\n",
      "epoch:32 step:25135[D loss: 0.456924, acc: 49.22%, op_acc: 38.28%] [G loss: 0.840061]\n",
      "epoch:32 step:25136[D loss: 0.414116, acc: 64.06%, op_acc: 37.50%] [G loss: 0.912342]\n",
      "epoch:32 step:25137[D loss: 0.433397, acc: 58.59%, op_acc: 41.41%] [G loss: 0.822964]\n",
      "epoch:32 step:25138[D loss: 0.412170, acc: 60.94%, op_acc: 38.28%] [G loss: 0.843758]\n",
      "epoch:32 step:25139[D loss: 0.406536, acc: 61.72%, op_acc: 41.41%] [G loss: 0.842634]\n",
      "epoch:32 step:25140[D loss: 0.426439, acc: 60.16%, op_acc: 41.41%] [G loss: 0.871331]\n",
      "epoch:32 step:25141[D loss: 0.408467, acc: 63.28%, op_acc: 42.97%] [G loss: 0.859669]\n",
      "epoch:32 step:25142[D loss: 0.411805, acc: 59.38%, op_acc: 43.75%] [G loss: 0.905456]\n",
      "epoch:32 step:25143[D loss: 0.430780, acc: 58.59%, op_acc: 36.72%] [G loss: 0.875265]\n",
      "epoch:32 step:25144[D loss: 0.384915, acc: 71.88%, op_acc: 43.75%] [G loss: 0.987777]\n",
      "epoch:32 step:25145[D loss: 0.453533, acc: 57.81%, op_acc: 36.72%] [G loss: 0.827031]\n",
      "epoch:32 step:25146[D loss: 0.408646, acc: 60.16%, op_acc: 39.84%] [G loss: 0.971471]\n",
      "epoch:32 step:25147[D loss: 0.419454, acc: 56.25%, op_acc: 35.94%] [G loss: 0.916553]\n",
      "epoch:32 step:25148[D loss: 0.411530, acc: 58.59%, op_acc: 40.62%] [G loss: 0.874899]\n",
      "epoch:32 step:25149[D loss: 0.426012, acc: 60.94%, op_acc: 39.84%] [G loss: 0.912790]\n",
      "epoch:32 step:25150[D loss: 0.428008, acc: 51.56%, op_acc: 40.62%] [G loss: 0.899644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.85919507 0.85611677 0.82557621 0.80996011 0.76025972 0.82340281\n",
      " 0.87735339 0.82404499 0.81650703 0.80190721]\n",
      "##########\n",
      "epoch:32 step:25151[D loss: 0.413020, acc: 60.16%, op_acc: 41.41%] [G loss: 0.893615]\n",
      "epoch:32 step:25152[D loss: 0.387623, acc: 64.84%, op_acc: 42.19%] [G loss: 0.956493]\n",
      "epoch:32 step:25153[D loss: 0.420068, acc: 60.16%, op_acc: 42.19%] [G loss: 0.845402]\n",
      "epoch:32 step:25154[D loss: 0.428402, acc: 57.03%, op_acc: 44.53%] [G loss: 0.904047]\n",
      "epoch:32 step:25155[D loss: 0.421190, acc: 66.41%, op_acc: 36.72%] [G loss: 0.945089]\n",
      "epoch:32 step:25156[D loss: 0.407218, acc: 68.75%, op_acc: 35.16%] [G loss: 0.894720]\n",
      "epoch:32 step:25157[D loss: 0.382476, acc: 64.84%, op_acc: 44.53%] [G loss: 0.909709]\n",
      "epoch:32 step:25158[D loss: 0.406365, acc: 67.97%, op_acc: 36.72%] [G loss: 0.894061]\n",
      "epoch:32 step:25159[D loss: 0.408533, acc: 57.81%, op_acc: 46.09%] [G loss: 0.856977]\n",
      "epoch:32 step:25160[D loss: 0.400083, acc: 64.84%, op_acc: 39.06%] [G loss: 0.890582]\n",
      "epoch:32 step:25161[D loss: 0.429284, acc: 56.25%, op_acc: 36.72%] [G loss: 0.891494]\n",
      "epoch:32 step:25162[D loss: 0.419103, acc: 58.59%, op_acc: 42.97%] [G loss: 0.872075]\n",
      "epoch:32 step:25163[D loss: 0.398945, acc: 68.75%, op_acc: 40.62%] [G loss: 0.867121]\n",
      "epoch:32 step:25164[D loss: 0.431930, acc: 52.34%, op_acc: 42.97%] [G loss: 0.843282]\n",
      "epoch:32 step:25165[D loss: 0.428751, acc: 54.69%, op_acc: 36.72%] [G loss: 0.834370]\n",
      "epoch:32 step:25166[D loss: 0.450942, acc: 50.78%, op_acc: 36.72%] [G loss: 0.851737]\n",
      "epoch:32 step:25167[D loss: 0.414573, acc: 56.25%, op_acc: 42.97%] [G loss: 0.926883]\n",
      "epoch:32 step:25168[D loss: 0.439263, acc: 50.78%, op_acc: 35.94%] [G loss: 0.836195]\n",
      "epoch:32 step:25169[D loss: 0.432586, acc: 48.44%, op_acc: 40.62%] [G loss: 0.799062]\n",
      "epoch:32 step:25170[D loss: 0.430694, acc: 57.81%, op_acc: 35.16%] [G loss: 0.925388]\n",
      "epoch:32 step:25171[D loss: 0.394683, acc: 64.84%, op_acc: 46.88%] [G loss: 0.921292]\n",
      "epoch:32 step:25172[D loss: 0.413527, acc: 64.84%, op_acc: 38.28%] [G loss: 0.843589]\n",
      "epoch:32 step:25173[D loss: 0.394075, acc: 63.28%, op_acc: 41.41%] [G loss: 0.922173]\n",
      "epoch:32 step:25174[D loss: 0.412808, acc: 62.50%, op_acc: 40.62%] [G loss: 0.922161]\n",
      "epoch:32 step:25175[D loss: 0.388689, acc: 72.66%, op_acc: 39.84%] [G loss: 0.871020]\n",
      "epoch:32 step:25176[D loss: 0.421346, acc: 59.38%, op_acc: 42.97%] [G loss: 0.875255]\n",
      "epoch:32 step:25177[D loss: 0.447483, acc: 57.03%, op_acc: 31.25%] [G loss: 0.919547]\n",
      "epoch:32 step:25178[D loss: 0.429965, acc: 52.34%, op_acc: 43.75%] [G loss: 0.905364]\n",
      "epoch:32 step:25179[D loss: 0.398225, acc: 63.28%, op_acc: 42.19%] [G loss: 0.857011]\n",
      "epoch:32 step:25180[D loss: 0.430233, acc: 53.12%, op_acc: 41.41%] [G loss: 0.874846]\n",
      "epoch:32 step:25181[D loss: 0.419252, acc: 61.72%, op_acc: 41.41%] [G loss: 0.904689]\n",
      "epoch:32 step:25182[D loss: 0.460264, acc: 52.34%, op_acc: 35.94%] [G loss: 0.901130]\n",
      "epoch:32 step:25183[D loss: 0.386096, acc: 68.75%, op_acc: 50.00%] [G loss: 0.940790]\n",
      "epoch:32 step:25184[D loss: 0.442642, acc: 53.91%, op_acc: 42.97%] [G loss: 0.845188]\n",
      "epoch:32 step:25185[D loss: 0.436275, acc: 56.25%, op_acc: 39.84%] [G loss: 0.972554]\n",
      "epoch:32 step:25186[D loss: 0.402092, acc: 56.25%, op_acc: 41.41%] [G loss: 0.968262]\n",
      "epoch:32 step:25187[D loss: 0.418300, acc: 62.50%, op_acc: 41.41%] [G loss: 0.938816]\n",
      "epoch:32 step:25188[D loss: 0.403766, acc: 67.97%, op_acc: 42.19%] [G loss: 0.981779]\n",
      "epoch:32 step:25189[D loss: 0.427457, acc: 58.59%, op_acc: 41.41%] [G loss: 0.907928]\n",
      "epoch:32 step:25190[D loss: 0.411502, acc: 62.50%, op_acc: 42.97%] [G loss: 0.849468]\n",
      "epoch:32 step:25191[D loss: 0.413966, acc: 58.59%, op_acc: 44.53%] [G loss: 0.854092]\n",
      "epoch:32 step:25192[D loss: 0.402180, acc: 56.25%, op_acc: 46.88%] [G loss: 0.929955]\n",
      "epoch:32 step:25193[D loss: 0.417179, acc: 59.38%, op_acc: 42.97%] [G loss: 0.901010]\n",
      "epoch:32 step:25194[D loss: 0.415523, acc: 65.62%, op_acc: 39.84%] [G loss: 0.939491]\n",
      "epoch:32 step:25195[D loss: 0.454652, acc: 49.22%, op_acc: 38.28%] [G loss: 0.878254]\n",
      "epoch:32 step:25196[D loss: 0.418936, acc: 60.16%, op_acc: 42.97%] [G loss: 0.876332]\n",
      "epoch:32 step:25197[D loss: 0.410758, acc: 60.94%, op_acc: 43.75%] [G loss: 0.876844]\n",
      "epoch:32 step:25198[D loss: 0.444125, acc: 49.22%, op_acc: 38.28%] [G loss: 0.877421]\n",
      "epoch:32 step:25199[D loss: 0.403862, acc: 60.94%, op_acc: 39.84%] [G loss: 0.941609]\n",
      "epoch:32 step:25200[D loss: 0.429837, acc: 60.94%, op_acc: 38.28%] [G loss: 0.820152]\n",
      "##############\n",
      "[0.86532116 0.8500546  0.81146573 0.80800483 0.7599543  0.83006672\n",
      " 0.87607577 0.82267384 0.80133129 0.82670648]\n",
      "##########\n",
      "epoch:32 step:25201[D loss: 0.425145, acc: 54.69%, op_acc: 45.31%] [G loss: 0.857683]\n",
      "epoch:32 step:25202[D loss: 0.425464, acc: 62.50%, op_acc: 41.41%] [G loss: 0.875358]\n",
      "epoch:32 step:25203[D loss: 0.406970, acc: 57.81%, op_acc: 42.19%] [G loss: 0.819661]\n",
      "epoch:32 step:25204[D loss: 0.416120, acc: 64.06%, op_acc: 37.50%] [G loss: 0.848344]\n",
      "epoch:32 step:25205[D loss: 0.388606, acc: 67.19%, op_acc: 46.88%] [G loss: 0.975345]\n",
      "epoch:32 step:25206[D loss: 0.452772, acc: 55.47%, op_acc: 37.50%] [G loss: 0.823731]\n",
      "epoch:32 step:25207[D loss: 0.446611, acc: 55.47%, op_acc: 39.06%] [G loss: 0.884196]\n",
      "epoch:32 step:25208[D loss: 0.436188, acc: 59.38%, op_acc: 40.62%] [G loss: 0.850244]\n",
      "epoch:32 step:25209[D loss: 0.414167, acc: 61.72%, op_acc: 40.62%] [G loss: 0.929177]\n",
      "epoch:32 step:25210[D loss: 0.428867, acc: 59.38%, op_acc: 36.72%] [G loss: 0.853278]\n",
      "epoch:32 step:25211[D loss: 0.410363, acc: 59.38%, op_acc: 42.97%] [G loss: 0.978220]\n",
      "epoch:32 step:25212[D loss: 0.421136, acc: 61.72%, op_acc: 37.50%] [G loss: 0.860168]\n",
      "epoch:32 step:25213[D loss: 0.438203, acc: 53.91%, op_acc: 35.94%] [G loss: 0.873040]\n",
      "epoch:32 step:25214[D loss: 0.440916, acc: 55.47%, op_acc: 39.06%] [G loss: 0.900635]\n",
      "epoch:32 step:25215[D loss: 0.449862, acc: 57.03%, op_acc: 44.53%] [G loss: 0.946712]\n",
      "epoch:32 step:25216[D loss: 0.447961, acc: 55.47%, op_acc: 37.50%] [G loss: 0.839971]\n",
      "epoch:32 step:25217[D loss: 0.399579, acc: 67.19%, op_acc: 43.75%] [G loss: 0.871531]\n",
      "epoch:32 step:25218[D loss: 0.449175, acc: 55.47%, op_acc: 43.75%] [G loss: 0.896655]\n",
      "epoch:32 step:25219[D loss: 0.439928, acc: 50.78%, op_acc: 39.84%] [G loss: 0.846546]\n",
      "epoch:32 step:25220[D loss: 0.401371, acc: 57.81%, op_acc: 42.19%] [G loss: 0.808326]\n",
      "epoch:32 step:25221[D loss: 0.405812, acc: 61.72%, op_acc: 41.41%] [G loss: 0.902230]\n",
      "epoch:32 step:25222[D loss: 0.446517, acc: 57.03%, op_acc: 32.81%] [G loss: 0.807162]\n",
      "epoch:32 step:25223[D loss: 0.407189, acc: 64.06%, op_acc: 43.75%] [G loss: 0.906885]\n",
      "epoch:32 step:25224[D loss: 0.397795, acc: 64.84%, op_acc: 40.62%] [G loss: 0.860385]\n",
      "epoch:32 step:25225[D loss: 0.425991, acc: 54.69%, op_acc: 41.41%] [G loss: 0.863152]\n",
      "epoch:32 step:25226[D loss: 0.393160, acc: 70.31%, op_acc: 40.62%] [G loss: 1.008196]\n",
      "epoch:32 step:25227[D loss: 0.386370, acc: 64.84%, op_acc: 43.75%] [G loss: 1.001360]\n",
      "epoch:32 step:25228[D loss: 0.416503, acc: 53.91%, op_acc: 42.19%] [G loss: 0.837008]\n",
      "epoch:32 step:25229[D loss: 0.401702, acc: 62.50%, op_acc: 35.16%] [G loss: 0.920608]\n",
      "epoch:32 step:25230[D loss: 0.441580, acc: 53.91%, op_acc: 40.62%] [G loss: 0.890378]\n",
      "epoch:32 step:25231[D loss: 0.423123, acc: 57.81%, op_acc: 37.50%] [G loss: 0.934347]\n",
      "epoch:32 step:25232[D loss: 0.427578, acc: 55.47%, op_acc: 37.50%] [G loss: 0.917631]\n",
      "epoch:32 step:25233[D loss: 0.422985, acc: 57.03%, op_acc: 42.97%] [G loss: 0.834256]\n",
      "epoch:32 step:25234[D loss: 0.388360, acc: 64.84%, op_acc: 45.31%] [G loss: 0.874163]\n",
      "epoch:32 step:25235[D loss: 0.404515, acc: 61.72%, op_acc: 38.28%] [G loss: 0.934251]\n",
      "epoch:32 step:25236[D loss: 0.431890, acc: 61.72%, op_acc: 38.28%] [G loss: 0.813783]\n",
      "epoch:32 step:25237[D loss: 0.417643, acc: 58.59%, op_acc: 39.84%] [G loss: 0.805236]\n",
      "epoch:32 step:25238[D loss: 0.435500, acc: 67.97%, op_acc: 41.41%] [G loss: 0.882345]\n",
      "epoch:32 step:25239[D loss: 0.408904, acc: 63.28%, op_acc: 38.28%] [G loss: 0.860581]\n",
      "epoch:32 step:25240[D loss: 0.457460, acc: 53.91%, op_acc: 34.38%] [G loss: 0.916291]\n",
      "epoch:32 step:25241[D loss: 0.434478, acc: 57.03%, op_acc: 38.28%] [G loss: 0.867632]\n",
      "epoch:32 step:25242[D loss: 0.416266, acc: 59.38%, op_acc: 39.84%] [G loss: 0.901826]\n",
      "epoch:32 step:25243[D loss: 0.408142, acc: 60.94%, op_acc: 45.31%] [G loss: 0.853873]\n",
      "epoch:32 step:25244[D loss: 0.420065, acc: 55.47%, op_acc: 41.41%] [G loss: 0.819712]\n",
      "epoch:32 step:25245[D loss: 0.433533, acc: 58.59%, op_acc: 36.72%] [G loss: 0.834397]\n",
      "epoch:32 step:25246[D loss: 0.418074, acc: 63.28%, op_acc: 39.84%] [G loss: 0.829235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25247[D loss: 0.452247, acc: 55.47%, op_acc: 33.59%] [G loss: 0.810955]\n",
      "epoch:32 step:25248[D loss: 0.429667, acc: 55.47%, op_acc: 35.94%] [G loss: 0.911301]\n",
      "epoch:32 step:25249[D loss: 0.423520, acc: 55.47%, op_acc: 36.72%] [G loss: 0.828554]\n",
      "epoch:32 step:25250[D loss: 0.393452, acc: 64.06%, op_acc: 39.84%] [G loss: 0.837727]\n",
      "##############\n",
      "[0.85966919 0.86736776 0.8050482  0.78915429 0.80112066 0.82756603\n",
      " 0.87138342 0.82624753 0.80413277 0.8277443 ]\n",
      "##########\n",
      "epoch:32 step:25251[D loss: 0.425867, acc: 66.41%, op_acc: 34.38%] [G loss: 0.890864]\n",
      "epoch:32 step:25252[D loss: 0.430670, acc: 55.47%, op_acc: 40.62%] [G loss: 0.832228]\n",
      "epoch:32 step:25253[D loss: 0.410347, acc: 60.16%, op_acc: 39.84%] [G loss: 0.858770]\n",
      "epoch:32 step:25254[D loss: 0.407345, acc: 60.16%, op_acc: 39.06%] [G loss: 0.915534]\n",
      "epoch:32 step:25255[D loss: 0.418677, acc: 62.50%, op_acc: 36.72%] [G loss: 0.894441]\n",
      "epoch:32 step:25256[D loss: 0.392510, acc: 64.84%, op_acc: 43.75%] [G loss: 0.850879]\n",
      "epoch:32 step:25257[D loss: 0.409400, acc: 59.38%, op_acc: 43.75%] [G loss: 0.881616]\n",
      "epoch:32 step:25258[D loss: 0.396118, acc: 62.50%, op_acc: 39.06%] [G loss: 0.835978]\n",
      "epoch:32 step:25259[D loss: 0.467705, acc: 51.56%, op_acc: 38.28%] [G loss: 0.870497]\n",
      "epoch:32 step:25260[D loss: 0.411668, acc: 62.50%, op_acc: 43.75%] [G loss: 0.830553]\n",
      "epoch:32 step:25261[D loss: 0.402032, acc: 60.16%, op_acc: 46.09%] [G loss: 0.954825]\n",
      "epoch:32 step:25262[D loss: 0.425322, acc: 54.69%, op_acc: 43.75%] [G loss: 0.827407]\n",
      "epoch:32 step:25263[D loss: 0.411593, acc: 63.28%, op_acc: 40.62%] [G loss: 0.990392]\n",
      "epoch:32 step:25264[D loss: 0.416647, acc: 64.06%, op_acc: 34.38%] [G loss: 0.952303]\n",
      "epoch:32 step:25265[D loss: 0.423026, acc: 58.59%, op_acc: 35.16%] [G loss: 0.848936]\n",
      "epoch:32 step:25266[D loss: 0.410743, acc: 63.28%, op_acc: 40.62%] [G loss: 0.870106]\n",
      "epoch:32 step:25267[D loss: 0.436628, acc: 53.91%, op_acc: 30.47%] [G loss: 0.855221]\n",
      "epoch:32 step:25268[D loss: 0.442992, acc: 54.69%, op_acc: 34.38%] [G loss: 0.838939]\n",
      "epoch:32 step:25269[D loss: 0.430716, acc: 55.47%, op_acc: 39.06%] [G loss: 0.924582]\n",
      "epoch:32 step:25270[D loss: 0.412608, acc: 70.31%, op_acc: 39.84%] [G loss: 0.928023]\n",
      "epoch:32 step:25271[D loss: 0.408516, acc: 66.41%, op_acc: 39.84%] [G loss: 0.907430]\n",
      "epoch:32 step:25272[D loss: 0.413098, acc: 70.31%, op_acc: 39.06%] [G loss: 0.866288]\n",
      "epoch:32 step:25273[D loss: 0.409785, acc: 62.50%, op_acc: 41.41%] [G loss: 0.872555]\n",
      "epoch:32 step:25274[D loss: 0.430238, acc: 60.94%, op_acc: 39.06%] [G loss: 0.843089]\n",
      "epoch:32 step:25275[D loss: 0.398886, acc: 64.06%, op_acc: 43.75%] [G loss: 0.843339]\n",
      "epoch:32 step:25276[D loss: 0.423949, acc: 58.59%, op_acc: 38.28%] [G loss: 0.928794]\n",
      "epoch:32 step:25277[D loss: 0.430463, acc: 60.94%, op_acc: 40.62%] [G loss: 0.878018]\n",
      "epoch:32 step:25278[D loss: 0.441928, acc: 53.91%, op_acc: 35.94%] [G loss: 0.861234]\n",
      "epoch:32 step:25279[D loss: 0.442184, acc: 52.34%, op_acc: 39.84%] [G loss: 0.825907]\n",
      "epoch:32 step:25280[D loss: 0.439534, acc: 51.56%, op_acc: 39.84%] [G loss: 0.948930]\n",
      "epoch:32 step:25281[D loss: 0.440566, acc: 55.47%, op_acc: 37.50%] [G loss: 0.849166]\n",
      "epoch:32 step:25282[D loss: 0.386149, acc: 73.44%, op_acc: 39.06%] [G loss: 0.850412]\n",
      "epoch:32 step:25283[D loss: 0.432989, acc: 60.94%, op_acc: 39.84%] [G loss: 0.900041]\n",
      "epoch:32 step:25284[D loss: 0.414379, acc: 67.19%, op_acc: 37.50%] [G loss: 0.981746]\n",
      "epoch:32 step:25285[D loss: 0.425567, acc: 60.94%, op_acc: 38.28%] [G loss: 0.872516]\n",
      "epoch:32 step:25286[D loss: 0.409854, acc: 60.16%, op_acc: 40.62%] [G loss: 0.900100]\n",
      "epoch:32 step:25287[D loss: 0.394656, acc: 66.41%, op_acc: 46.09%] [G loss: 0.833682]\n",
      "epoch:32 step:25288[D loss: 0.410525, acc: 64.06%, op_acc: 38.28%] [G loss: 0.819021]\n",
      "epoch:32 step:25289[D loss: 0.440032, acc: 49.22%, op_acc: 40.62%] [G loss: 0.877211]\n",
      "epoch:32 step:25290[D loss: 0.385651, acc: 67.97%, op_acc: 45.31%] [G loss: 0.904151]\n",
      "epoch:32 step:25291[D loss: 0.459109, acc: 48.44%, op_acc: 38.28%] [G loss: 0.817464]\n",
      "epoch:32 step:25292[D loss: 0.443580, acc: 54.69%, op_acc: 41.41%] [G loss: 0.821834]\n",
      "epoch:32 step:25293[D loss: 0.391961, acc: 64.84%, op_acc: 41.41%] [G loss: 0.898332]\n",
      "epoch:32 step:25294[D loss: 0.431308, acc: 53.91%, op_acc: 39.06%] [G loss: 0.890607]\n",
      "epoch:32 step:25295[D loss: 0.424576, acc: 60.94%, op_acc: 36.72%] [G loss: 0.954642]\n",
      "epoch:32 step:25296[D loss: 0.412939, acc: 62.50%, op_acc: 41.41%] [G loss: 0.958816]\n",
      "epoch:32 step:25297[D loss: 0.435356, acc: 54.69%, op_acc: 39.06%] [G loss: 0.830508]\n",
      "epoch:32 step:25298[D loss: 0.462713, acc: 59.38%, op_acc: 39.06%] [G loss: 0.904233]\n",
      "epoch:32 step:25299[D loss: 0.401926, acc: 62.50%, op_acc: 40.62%] [G loss: 0.934911]\n",
      "epoch:32 step:25300[D loss: 0.425375, acc: 62.50%, op_acc: 40.62%] [G loss: 0.852807]\n",
      "##############\n",
      "[0.85224902 0.85363616 0.80260754 0.80549128 0.78446483 0.81138284\n",
      " 0.87671476 0.83709698 0.81425759 0.83643798]\n",
      "##########\n",
      "epoch:32 step:25301[D loss: 0.431657, acc: 59.38%, op_acc: 39.84%] [G loss: 0.824067]\n",
      "epoch:32 step:25302[D loss: 0.398976, acc: 65.62%, op_acc: 42.19%] [G loss: 0.918129]\n",
      "epoch:32 step:25303[D loss: 0.430827, acc: 50.00%, op_acc: 41.41%] [G loss: 0.796154]\n",
      "epoch:32 step:25304[D loss: 0.429326, acc: 54.69%, op_acc: 49.22%] [G loss: 0.907733]\n",
      "epoch:32 step:25305[D loss: 0.401233, acc: 56.25%, op_acc: 39.84%] [G loss: 0.875104]\n",
      "epoch:32 step:25306[D loss: 0.435590, acc: 50.78%, op_acc: 40.62%] [G loss: 0.777602]\n",
      "epoch:32 step:25307[D loss: 0.418904, acc: 63.28%, op_acc: 40.62%] [G loss: 0.898340]\n",
      "epoch:32 step:25308[D loss: 0.415681, acc: 57.81%, op_acc: 42.19%] [G loss: 0.851435]\n",
      "epoch:32 step:25309[D loss: 0.420459, acc: 54.69%, op_acc: 42.97%] [G loss: 0.830782]\n",
      "epoch:32 step:25310[D loss: 0.432305, acc: 60.94%, op_acc: 36.72%] [G loss: 0.826594]\n",
      "epoch:32 step:25311[D loss: 0.419496, acc: 56.25%, op_acc: 40.62%] [G loss: 0.891768]\n",
      "epoch:32 step:25312[D loss: 0.419070, acc: 62.50%, op_acc: 39.84%] [G loss: 0.903784]\n",
      "epoch:32 step:25313[D loss: 0.425358, acc: 61.72%, op_acc: 42.19%] [G loss: 0.884899]\n",
      "epoch:32 step:25314[D loss: 0.457229, acc: 57.81%, op_acc: 39.84%] [G loss: 0.875593]\n",
      "epoch:32 step:25315[D loss: 0.426316, acc: 60.94%, op_acc: 42.19%] [G loss: 0.904798]\n",
      "epoch:32 step:25316[D loss: 0.447159, acc: 54.69%, op_acc: 37.50%] [G loss: 0.857249]\n",
      "epoch:32 step:25317[D loss: 0.382587, acc: 71.88%, op_acc: 40.62%] [G loss: 0.899559]\n",
      "epoch:32 step:25318[D loss: 0.429796, acc: 58.59%, op_acc: 33.59%] [G loss: 0.903785]\n",
      "epoch:32 step:25319[D loss: 0.400976, acc: 66.41%, op_acc: 38.28%] [G loss: 0.881799]\n",
      "epoch:32 step:25320[D loss: 0.387080, acc: 68.75%, op_acc: 39.06%] [G loss: 0.912650]\n",
      "epoch:32 step:25321[D loss: 0.413780, acc: 66.41%, op_acc: 39.84%] [G loss: 0.992636]\n",
      "epoch:32 step:25322[D loss: 0.411352, acc: 64.06%, op_acc: 37.50%] [G loss: 0.876078]\n",
      "epoch:32 step:25323[D loss: 0.428710, acc: 59.38%, op_acc: 34.38%] [G loss: 0.906424]\n",
      "epoch:32 step:25324[D loss: 0.420428, acc: 57.81%, op_acc: 40.62%] [G loss: 0.883928]\n",
      "epoch:32 step:25325[D loss: 0.432447, acc: 56.25%, op_acc: 40.62%] [G loss: 0.934523]\n",
      "epoch:32 step:25326[D loss: 0.429813, acc: 52.34%, op_acc: 35.16%] [G loss: 0.829417]\n",
      "epoch:32 step:25327[D loss: 0.438819, acc: 56.25%, op_acc: 34.38%] [G loss: 0.891807]\n",
      "epoch:32 step:25328[D loss: 0.435867, acc: 58.59%, op_acc: 35.94%] [G loss: 0.797096]\n",
      "epoch:32 step:25329[D loss: 0.400460, acc: 68.75%, op_acc: 41.41%] [G loss: 0.954278]\n",
      "epoch:32 step:25330[D loss: 0.387927, acc: 66.41%, op_acc: 42.19%] [G loss: 0.877104]\n",
      "epoch:32 step:25331[D loss: 0.418436, acc: 62.50%, op_acc: 41.41%] [G loss: 0.853375]\n",
      "epoch:32 step:25332[D loss: 0.435885, acc: 57.81%, op_acc: 36.72%] [G loss: 0.934431]\n",
      "epoch:32 step:25333[D loss: 0.458733, acc: 46.09%, op_acc: 35.94%] [G loss: 0.866970]\n",
      "epoch:32 step:25334[D loss: 0.453569, acc: 57.81%, op_acc: 36.72%] [G loss: 0.860262]\n",
      "epoch:32 step:25335[D loss: 0.427869, acc: 57.81%, op_acc: 38.28%] [G loss: 0.860902]\n",
      "epoch:32 step:25336[D loss: 0.418901, acc: 63.28%, op_acc: 38.28%] [G loss: 0.886141]\n",
      "epoch:32 step:25337[D loss: 0.431334, acc: 60.16%, op_acc: 38.28%] [G loss: 0.927894]\n",
      "epoch:32 step:25338[D loss: 0.418569, acc: 59.38%, op_acc: 39.84%] [G loss: 0.881073]\n",
      "epoch:32 step:25339[D loss: 0.414243, acc: 61.72%, op_acc: 43.75%] [G loss: 0.817956]\n",
      "epoch:32 step:25340[D loss: 0.420641, acc: 64.06%, op_acc: 41.41%] [G loss: 0.876462]\n",
      "epoch:32 step:25341[D loss: 0.409941, acc: 63.28%, op_acc: 39.06%] [G loss: 0.866323]\n",
      "epoch:32 step:25342[D loss: 0.423094, acc: 61.72%, op_acc: 32.81%] [G loss: 0.865348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25343[D loss: 0.450429, acc: 53.91%, op_acc: 40.62%] [G loss: 0.826283]\n",
      "epoch:32 step:25344[D loss: 0.437238, acc: 60.16%, op_acc: 42.19%] [G loss: 0.850734]\n",
      "epoch:32 step:25345[D loss: 0.369501, acc: 64.84%, op_acc: 47.66%] [G loss: 0.897314]\n",
      "epoch:32 step:25346[D loss: 0.420353, acc: 63.28%, op_acc: 39.06%] [G loss: 0.892009]\n",
      "epoch:32 step:25347[D loss: 0.439462, acc: 53.91%, op_acc: 39.84%] [G loss: 0.852052]\n",
      "epoch:32 step:25348[D loss: 0.416653, acc: 64.06%, op_acc: 37.50%] [G loss: 0.924297]\n",
      "epoch:32 step:25349[D loss: 0.414974, acc: 64.06%, op_acc: 39.06%] [G loss: 0.866651]\n",
      "epoch:32 step:25350[D loss: 0.451204, acc: 56.25%, op_acc: 39.06%] [G loss: 0.877020]\n",
      "##############\n",
      "[0.83553121 0.85551165 0.82492641 0.82492388 0.80173153 0.82434157\n",
      " 0.88880516 0.80470046 0.82712177 0.82038937]\n",
      "##########\n",
      "epoch:32 step:25351[D loss: 0.432200, acc: 59.38%, op_acc: 36.72%] [G loss: 0.917538]\n",
      "epoch:32 step:25352[D loss: 0.436134, acc: 53.12%, op_acc: 42.19%] [G loss: 0.889677]\n",
      "epoch:32 step:25353[D loss: 0.425465, acc: 59.38%, op_acc: 39.06%] [G loss: 0.878270]\n",
      "epoch:32 step:25354[D loss: 0.407420, acc: 64.06%, op_acc: 39.84%] [G loss: 0.943773]\n",
      "epoch:32 step:25355[D loss: 0.425928, acc: 54.69%, op_acc: 42.19%] [G loss: 0.888272]\n",
      "epoch:32 step:25356[D loss: 0.392272, acc: 67.97%, op_acc: 46.09%] [G loss: 0.904332]\n",
      "epoch:32 step:25357[D loss: 0.386965, acc: 70.31%, op_acc: 41.41%] [G loss: 0.881090]\n",
      "epoch:32 step:25358[D loss: 0.401659, acc: 59.38%, op_acc: 41.41%] [G loss: 0.877576]\n",
      "epoch:32 step:25359[D loss: 0.397202, acc: 73.44%, op_acc: 40.62%] [G loss: 0.885177]\n",
      "epoch:32 step:25360[D loss: 0.398621, acc: 68.75%, op_acc: 41.41%] [G loss: 0.894340]\n",
      "epoch:32 step:25361[D loss: 0.423250, acc: 60.16%, op_acc: 39.06%] [G loss: 0.870832]\n",
      "epoch:32 step:25362[D loss: 0.414614, acc: 62.50%, op_acc: 37.50%] [G loss: 0.903826]\n",
      "epoch:32 step:25363[D loss: 0.412234, acc: 56.25%, op_acc: 41.41%] [G loss: 0.914142]\n",
      "epoch:32 step:25364[D loss: 0.406889, acc: 64.06%, op_acc: 40.62%] [G loss: 0.866706]\n",
      "epoch:32 step:25365[D loss: 0.419894, acc: 57.03%, op_acc: 46.09%] [G loss: 0.879710]\n",
      "epoch:32 step:25366[D loss: 0.420394, acc: 60.16%, op_acc: 42.19%] [G loss: 0.873840]\n",
      "epoch:32 step:25367[D loss: 0.430304, acc: 60.16%, op_acc: 31.25%] [G loss: 0.936301]\n",
      "epoch:32 step:25368[D loss: 0.410238, acc: 64.06%, op_acc: 34.38%] [G loss: 0.871126]\n",
      "epoch:32 step:25369[D loss: 0.416866, acc: 59.38%, op_acc: 45.31%] [G loss: 0.863645]\n",
      "epoch:32 step:25370[D loss: 0.426713, acc: 57.03%, op_acc: 39.06%] [G loss: 0.875235]\n",
      "epoch:32 step:25371[D loss: 0.387363, acc: 57.81%, op_acc: 45.31%] [G loss: 0.906987]\n",
      "epoch:32 step:25372[D loss: 0.391823, acc: 70.31%, op_acc: 39.06%] [G loss: 0.897527]\n",
      "epoch:32 step:25373[D loss: 0.380597, acc: 72.66%, op_acc: 41.41%] [G loss: 0.947362]\n",
      "epoch:32 step:25374[D loss: 0.439082, acc: 55.47%, op_acc: 38.28%] [G loss: 0.886120]\n",
      "epoch:32 step:25375[D loss: 0.408439, acc: 59.38%, op_acc: 46.09%] [G loss: 0.913440]\n",
      "epoch:32 step:25376[D loss: 0.397688, acc: 63.28%, op_acc: 42.19%] [G loss: 0.852178]\n",
      "epoch:32 step:25377[D loss: 0.414882, acc: 60.16%, op_acc: 45.31%] [G loss: 0.923174]\n",
      "epoch:32 step:25378[D loss: 0.428002, acc: 60.94%, op_acc: 41.41%] [G loss: 0.816574]\n",
      "epoch:32 step:25379[D loss: 0.446071, acc: 59.38%, op_acc: 39.84%] [G loss: 0.864880]\n",
      "epoch:32 step:25380[D loss: 0.442507, acc: 57.03%, op_acc: 36.72%] [G loss: 0.850820]\n",
      "epoch:32 step:25381[D loss: 0.414776, acc: 60.16%, op_acc: 41.41%] [G loss: 0.949176]\n",
      "epoch:32 step:25382[D loss: 0.401190, acc: 60.16%, op_acc: 43.75%] [G loss: 0.970954]\n",
      "epoch:32 step:25383[D loss: 0.410961, acc: 59.38%, op_acc: 44.53%] [G loss: 0.836841]\n",
      "epoch:32 step:25384[D loss: 0.410744, acc: 58.59%, op_acc: 44.53%] [G loss: 0.881664]\n",
      "epoch:32 step:25385[D loss: 0.423068, acc: 56.25%, op_acc: 38.28%] [G loss: 0.872624]\n",
      "epoch:32 step:25386[D loss: 0.409651, acc: 57.81%, op_acc: 39.84%] [G loss: 0.893123]\n",
      "epoch:32 step:25387[D loss: 0.480694, acc: 46.88%, op_acc: 41.41%] [G loss: 0.928978]\n",
      "epoch:32 step:25388[D loss: 0.417538, acc: 61.72%, op_acc: 41.41%] [G loss: 0.941395]\n",
      "epoch:32 step:25389[D loss: 0.413977, acc: 54.69%, op_acc: 41.41%] [G loss: 0.925799]\n",
      "epoch:32 step:25390[D loss: 0.434565, acc: 57.81%, op_acc: 42.19%] [G loss: 0.904492]\n",
      "epoch:32 step:25391[D loss: 0.449845, acc: 50.78%, op_acc: 39.84%] [G loss: 0.836342]\n",
      "epoch:32 step:25392[D loss: 0.406953, acc: 57.81%, op_acc: 37.50%] [G loss: 0.882221]\n",
      "epoch:32 step:25393[D loss: 0.443264, acc: 52.34%, op_acc: 39.06%] [G loss: 0.803347]\n",
      "epoch:32 step:25394[D loss: 0.407364, acc: 60.94%, op_acc: 41.41%] [G loss: 0.847851]\n",
      "epoch:32 step:25395[D loss: 0.407909, acc: 60.16%, op_acc: 37.50%] [G loss: 0.958801]\n",
      "epoch:32 step:25396[D loss: 0.386685, acc: 69.53%, op_acc: 47.66%] [G loss: 0.879814]\n",
      "epoch:32 step:25397[D loss: 0.415906, acc: 62.50%, op_acc: 39.84%] [G loss: 0.895639]\n",
      "epoch:32 step:25398[D loss: 0.439021, acc: 51.56%, op_acc: 41.41%] [G loss: 0.872866]\n",
      "epoch:32 step:25399[D loss: 0.414057, acc: 59.38%, op_acc: 36.72%] [G loss: 0.923443]\n",
      "epoch:32 step:25400[D loss: 0.398983, acc: 53.91%, op_acc: 42.19%] [G loss: 0.878083]\n",
      "##############\n",
      "[0.84582033 0.82489404 0.80456293 0.80328356 0.79494047 0.80427223\n",
      " 0.8921489  0.82031875 0.82510816 0.83908119]\n",
      "##########\n",
      "epoch:32 step:25401[D loss: 0.459087, acc: 54.69%, op_acc: 44.53%] [G loss: 0.945739]\n",
      "epoch:32 step:25402[D loss: 0.412053, acc: 54.69%, op_acc: 42.19%] [G loss: 0.856158]\n",
      "epoch:32 step:25403[D loss: 0.434288, acc: 54.69%, op_acc: 37.50%] [G loss: 0.904833]\n",
      "epoch:32 step:25404[D loss: 0.401269, acc: 61.72%, op_acc: 42.97%] [G loss: 0.962435]\n",
      "epoch:32 step:25405[D loss: 0.430484, acc: 60.94%, op_acc: 38.28%] [G loss: 0.901511]\n",
      "epoch:32 step:25406[D loss: 0.385428, acc: 64.06%, op_acc: 44.53%] [G loss: 0.892746]\n",
      "epoch:32 step:25407[D loss: 0.402674, acc: 64.06%, op_acc: 39.06%] [G loss: 0.936054]\n",
      "epoch:32 step:25408[D loss: 0.417506, acc: 61.72%, op_acc: 42.19%] [G loss: 0.919818]\n",
      "epoch:32 step:25409[D loss: 0.439912, acc: 53.12%, op_acc: 42.19%] [G loss: 0.887147]\n",
      "epoch:32 step:25410[D loss: 0.427819, acc: 60.16%, op_acc: 40.62%] [G loss: 0.901145]\n",
      "epoch:32 step:25411[D loss: 0.421912, acc: 59.38%, op_acc: 40.62%] [G loss: 0.877078]\n",
      "epoch:32 step:25412[D loss: 0.429640, acc: 52.34%, op_acc: 36.72%] [G loss: 0.965748]\n",
      "epoch:32 step:25413[D loss: 0.442018, acc: 53.91%, op_acc: 39.06%] [G loss: 0.854179]\n",
      "epoch:32 step:25414[D loss: 0.422157, acc: 54.69%, op_acc: 46.88%] [G loss: 0.889033]\n",
      "epoch:32 step:25415[D loss: 0.439119, acc: 63.28%, op_acc: 35.94%] [G loss: 0.855488]\n",
      "epoch:32 step:25416[D loss: 0.438819, acc: 56.25%, op_acc: 35.94%] [G loss: 0.849877]\n",
      "epoch:32 step:25417[D loss: 0.453400, acc: 51.56%, op_acc: 41.41%] [G loss: 0.840408]\n",
      "epoch:32 step:25418[D loss: 0.447466, acc: 53.91%, op_acc: 32.81%] [G loss: 0.842498]\n",
      "epoch:32 step:25419[D loss: 0.445149, acc: 53.91%, op_acc: 40.62%] [G loss: 0.858706]\n",
      "epoch:32 step:25420[D loss: 0.414985, acc: 55.47%, op_acc: 46.88%] [G loss: 0.900526]\n",
      "epoch:32 step:25421[D loss: 0.412342, acc: 57.03%, op_acc: 40.62%] [G loss: 0.886953]\n",
      "epoch:32 step:25422[D loss: 0.404788, acc: 62.50%, op_acc: 45.31%] [G loss: 0.867952]\n",
      "epoch:32 step:25423[D loss: 0.450828, acc: 51.56%, op_acc: 41.41%] [G loss: 0.796488]\n",
      "epoch:32 step:25424[D loss: 0.390129, acc: 66.41%, op_acc: 39.84%] [G loss: 0.815751]\n",
      "epoch:32 step:25425[D loss: 0.398011, acc: 65.62%, op_acc: 39.84%] [G loss: 0.931430]\n",
      "epoch:32 step:25426[D loss: 0.383480, acc: 63.28%, op_acc: 46.09%] [G loss: 0.845758]\n",
      "epoch:32 step:25427[D loss: 0.410347, acc: 60.94%, op_acc: 44.53%] [G loss: 0.887523]\n",
      "epoch:32 step:25428[D loss: 0.463943, acc: 53.12%, op_acc: 37.50%] [G loss: 0.838334]\n",
      "epoch:32 step:25429[D loss: 0.401183, acc: 62.50%, op_acc: 39.84%] [G loss: 0.856158]\n",
      "epoch:32 step:25430[D loss: 0.402117, acc: 63.28%, op_acc: 42.97%] [G loss: 0.893064]\n",
      "epoch:32 step:25431[D loss: 0.422672, acc: 55.47%, op_acc: 40.62%] [G loss: 0.862744]\n",
      "epoch:32 step:25432[D loss: 0.428417, acc: 55.47%, op_acc: 35.94%] [G loss: 0.888636]\n",
      "epoch:32 step:25433[D loss: 0.430537, acc: 53.12%, op_acc: 45.31%] [G loss: 0.891394]\n",
      "epoch:32 step:25434[D loss: 0.432135, acc: 53.91%, op_acc: 42.19%] [G loss: 0.787785]\n",
      "epoch:32 step:25435[D loss: 0.425267, acc: 63.28%, op_acc: 37.50%] [G loss: 0.929802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25436[D loss: 0.409903, acc: 60.16%, op_acc: 42.97%] [G loss: 0.909302]\n",
      "epoch:32 step:25437[D loss: 0.434351, acc: 53.12%, op_acc: 41.41%] [G loss: 0.937792]\n",
      "epoch:32 step:25438[D loss: 0.429860, acc: 56.25%, op_acc: 39.84%] [G loss: 0.866573]\n",
      "epoch:32 step:25439[D loss: 0.431163, acc: 64.84%, op_acc: 34.38%] [G loss: 0.872537]\n",
      "epoch:32 step:25440[D loss: 0.416689, acc: 59.38%, op_acc: 37.50%] [G loss: 0.861342]\n",
      "epoch:32 step:25441[D loss: 0.423728, acc: 57.03%, op_acc: 37.50%] [G loss: 0.727744]\n",
      "epoch:32 step:25442[D loss: 0.426528, acc: 58.59%, op_acc: 39.06%] [G loss: 0.841837]\n",
      "epoch:32 step:25443[D loss: 0.398399, acc: 55.47%, op_acc: 49.22%] [G loss: 0.923914]\n",
      "epoch:32 step:25444[D loss: 0.416820, acc: 57.03%, op_acc: 42.19%] [G loss: 0.980117]\n",
      "epoch:32 step:25445[D loss: 0.399042, acc: 56.25%, op_acc: 40.62%] [G loss: 0.868955]\n",
      "epoch:32 step:25446[D loss: 0.427688, acc: 55.47%, op_acc: 39.84%] [G loss: 0.849003]\n",
      "epoch:32 step:25447[D loss: 0.434788, acc: 61.72%, op_acc: 41.41%] [G loss: 0.827913]\n",
      "epoch:32 step:25448[D loss: 0.453899, acc: 58.59%, op_acc: 36.72%] [G loss: 0.813788]\n",
      "epoch:32 step:25449[D loss: 0.435058, acc: 58.59%, op_acc: 41.41%] [G loss: 0.819721]\n",
      "epoch:32 step:25450[D loss: 0.382736, acc: 64.84%, op_acc: 43.75%] [G loss: 0.839999]\n",
      "##############\n",
      "[0.86517311 0.86895475 0.79835745 0.81583617 0.7890342  0.84134737\n",
      " 0.89181634 0.83009933 0.8087453  0.81559347]\n",
      "##########\n",
      "epoch:32 step:25451[D loss: 0.408602, acc: 53.12%, op_acc: 48.44%] [G loss: 0.831481]\n",
      "epoch:32 step:25452[D loss: 0.415097, acc: 57.03%, op_acc: 47.66%] [G loss: 0.883433]\n",
      "epoch:32 step:25453[D loss: 0.460446, acc: 50.78%, op_acc: 39.84%] [G loss: 0.850943]\n",
      "epoch:32 step:25454[D loss: 0.414310, acc: 53.91%, op_acc: 42.97%] [G loss: 0.896408]\n",
      "epoch:32 step:25455[D loss: 0.411402, acc: 62.50%, op_acc: 46.09%] [G loss: 0.952911]\n",
      "epoch:32 step:25456[D loss: 0.423782, acc: 59.38%, op_acc: 40.62%] [G loss: 0.922004]\n",
      "epoch:32 step:25457[D loss: 0.446652, acc: 48.44%, op_acc: 39.06%] [G loss: 0.866533]\n",
      "epoch:32 step:25458[D loss: 0.379565, acc: 67.97%, op_acc: 43.75%] [G loss: 0.832271]\n",
      "epoch:32 step:25459[D loss: 0.431289, acc: 55.47%, op_acc: 40.62%] [G loss: 0.916272]\n",
      "epoch:32 step:25460[D loss: 0.399740, acc: 66.41%, op_acc: 44.53%] [G loss: 0.825560]\n",
      "epoch:32 step:25461[D loss: 0.398333, acc: 59.38%, op_acc: 43.75%] [G loss: 0.814058]\n",
      "epoch:32 step:25462[D loss: 0.407113, acc: 63.28%, op_acc: 40.62%] [G loss: 0.874245]\n",
      "epoch:32 step:25463[D loss: 0.449905, acc: 57.03%, op_acc: 33.59%] [G loss: 0.896942]\n",
      "epoch:32 step:25464[D loss: 0.454537, acc: 54.69%, op_acc: 36.72%] [G loss: 0.898083]\n",
      "epoch:32 step:25465[D loss: 0.385206, acc: 61.72%, op_acc: 46.09%] [G loss: 0.918441]\n",
      "epoch:32 step:25466[D loss: 0.409798, acc: 60.94%, op_acc: 39.84%] [G loss: 0.834813]\n",
      "epoch:32 step:25467[D loss: 0.441377, acc: 53.12%, op_acc: 39.06%] [G loss: 0.888718]\n",
      "epoch:32 step:25468[D loss: 0.439614, acc: 57.03%, op_acc: 33.59%] [G loss: 0.908223]\n",
      "epoch:32 step:25469[D loss: 0.459840, acc: 56.25%, op_acc: 32.81%] [G loss: 0.833524]\n",
      "epoch:32 step:25470[D loss: 0.394507, acc: 60.16%, op_acc: 39.84%] [G loss: 0.875243]\n",
      "epoch:32 step:25471[D loss: 0.409171, acc: 60.94%, op_acc: 42.97%] [G loss: 0.868737]\n",
      "epoch:32 step:25472[D loss: 0.429205, acc: 61.72%, op_acc: 35.94%] [G loss: 0.855676]\n",
      "epoch:32 step:25473[D loss: 0.462146, acc: 58.59%, op_acc: 32.81%] [G loss: 0.909780]\n",
      "epoch:32 step:25474[D loss: 0.452578, acc: 58.59%, op_acc: 35.94%] [G loss: 0.918080]\n",
      "epoch:32 step:25475[D loss: 0.406776, acc: 65.62%, op_acc: 38.28%] [G loss: 0.926126]\n",
      "epoch:32 step:25476[D loss: 0.394268, acc: 59.38%, op_acc: 46.88%] [G loss: 0.880934]\n",
      "epoch:32 step:25477[D loss: 0.431186, acc: 54.69%, op_acc: 38.28%] [G loss: 0.905244]\n",
      "epoch:32 step:25478[D loss: 0.369843, acc: 71.88%, op_acc: 42.19%] [G loss: 0.868241]\n",
      "epoch:32 step:25479[D loss: 0.402562, acc: 56.25%, op_acc: 39.84%] [G loss: 0.782449]\n",
      "epoch:32 step:25480[D loss: 0.439418, acc: 57.81%, op_acc: 43.75%] [G loss: 0.946230]\n",
      "epoch:32 step:25481[D loss: 0.422600, acc: 63.28%, op_acc: 39.06%] [G loss: 0.891323]\n",
      "epoch:32 step:25482[D loss: 0.365272, acc: 70.31%, op_acc: 46.09%] [G loss: 0.908682]\n",
      "epoch:32 step:25483[D loss: 0.437659, acc: 57.03%, op_acc: 42.97%] [G loss: 0.876982]\n",
      "epoch:32 step:25484[D loss: 0.390500, acc: 68.75%, op_acc: 42.97%] [G loss: 0.882126]\n",
      "epoch:32 step:25485[D loss: 0.412392, acc: 58.59%, op_acc: 38.28%] [G loss: 0.863536]\n",
      "epoch:32 step:25486[D loss: 0.423007, acc: 56.25%, op_acc: 37.50%] [G loss: 0.857723]\n",
      "epoch:32 step:25487[D loss: 0.395413, acc: 63.28%, op_acc: 37.50%] [G loss: 0.958354]\n",
      "epoch:32 step:25488[D loss: 0.430432, acc: 60.16%, op_acc: 41.41%] [G loss: 0.886607]\n",
      "epoch:32 step:25489[D loss: 0.405259, acc: 59.38%, op_acc: 41.41%] [G loss: 0.871176]\n",
      "epoch:32 step:25490[D loss: 0.421278, acc: 60.94%, op_acc: 39.84%] [G loss: 0.853164]\n",
      "epoch:32 step:25491[D loss: 0.441896, acc: 55.47%, op_acc: 35.16%] [G loss: 0.894686]\n",
      "epoch:32 step:25492[D loss: 0.427646, acc: 56.25%, op_acc: 42.97%] [G loss: 0.846127]\n",
      "epoch:32 step:25493[D loss: 0.436964, acc: 58.59%, op_acc: 39.84%] [G loss: 0.856567]\n",
      "epoch:32 step:25494[D loss: 0.424259, acc: 57.03%, op_acc: 42.97%] [G loss: 0.853023]\n",
      "epoch:32 step:25495[D loss: 0.432124, acc: 63.28%, op_acc: 37.50%] [G loss: 0.870411]\n",
      "epoch:32 step:25496[D loss: 0.438602, acc: 54.69%, op_acc: 39.06%] [G loss: 0.919534]\n",
      "epoch:32 step:25497[D loss: 0.407014, acc: 62.50%, op_acc: 43.75%] [G loss: 0.909034]\n",
      "epoch:32 step:25498[D loss: 0.433692, acc: 53.91%, op_acc: 41.41%] [G loss: 0.893321]\n",
      "epoch:32 step:25499[D loss: 0.410772, acc: 57.81%, op_acc: 42.97%] [G loss: 0.798665]\n",
      "epoch:32 step:25500[D loss: 0.438654, acc: 54.69%, op_acc: 35.16%] [G loss: 0.871241]\n",
      "##############\n",
      "[0.85689816 0.85782054 0.81893334 0.80918416 0.80276356 0.83505421\n",
      " 0.88919492 0.84067667 0.80647097 0.81653736]\n",
      "##########\n",
      "epoch:32 step:25501[D loss: 0.450797, acc: 50.00%, op_acc: 39.06%] [G loss: 0.923351]\n",
      "epoch:32 step:25502[D loss: 0.380457, acc: 65.62%, op_acc: 42.97%] [G loss: 0.900042]\n",
      "epoch:32 step:25503[D loss: 0.416504, acc: 62.50%, op_acc: 39.06%] [G loss: 0.833792]\n",
      "epoch:32 step:25504[D loss: 0.429194, acc: 54.69%, op_acc: 35.94%] [G loss: 0.917997]\n",
      "epoch:32 step:25505[D loss: 0.448015, acc: 56.25%, op_acc: 37.50%] [G loss: 0.896684]\n",
      "epoch:32 step:25506[D loss: 0.424733, acc: 53.91%, op_acc: 45.31%] [G loss: 0.876998]\n",
      "epoch:32 step:25507[D loss: 0.437176, acc: 57.81%, op_acc: 36.72%] [G loss: 0.848801]\n",
      "epoch:32 step:25508[D loss: 0.428028, acc: 58.59%, op_acc: 37.50%] [G loss: 0.834486]\n",
      "epoch:32 step:25509[D loss: 0.431559, acc: 59.38%, op_acc: 37.50%] [G loss: 0.831516]\n",
      "epoch:32 step:25510[D loss: 0.383181, acc: 70.31%, op_acc: 39.06%] [G loss: 0.909756]\n",
      "epoch:32 step:25511[D loss: 0.393314, acc: 61.72%, op_acc: 46.88%] [G loss: 0.898401]\n",
      "epoch:32 step:25512[D loss: 0.437482, acc: 58.59%, op_acc: 38.28%] [G loss: 0.878631]\n",
      "epoch:32 step:25513[D loss: 0.390121, acc: 62.50%, op_acc: 40.62%] [G loss: 0.893525]\n",
      "epoch:32 step:25514[D loss: 0.431448, acc: 59.38%, op_acc: 38.28%] [G loss: 0.853789]\n",
      "epoch:32 step:25515[D loss: 0.419458, acc: 60.16%, op_acc: 35.16%] [G loss: 0.909218]\n",
      "epoch:32 step:25516[D loss: 0.434956, acc: 56.25%, op_acc: 36.72%] [G loss: 0.906442]\n",
      "epoch:32 step:25517[D loss: 0.424964, acc: 61.72%, op_acc: 36.72%] [G loss: 0.841839]\n",
      "epoch:32 step:25518[D loss: 0.450277, acc: 50.78%, op_acc: 42.97%] [G loss: 0.856328]\n",
      "epoch:32 step:25519[D loss: 0.432139, acc: 57.03%, op_acc: 40.62%] [G loss: 0.850534]\n",
      "epoch:32 step:25520[D loss: 0.402096, acc: 61.72%, op_acc: 43.75%] [G loss: 0.868920]\n",
      "epoch:32 step:25521[D loss: 0.416838, acc: 60.94%, op_acc: 41.41%] [G loss: 0.845938]\n",
      "epoch:32 step:25522[D loss: 0.404926, acc: 63.28%, op_acc: 38.28%] [G loss: 0.851129]\n",
      "epoch:32 step:25523[D loss: 0.414320, acc: 61.72%, op_acc: 43.75%] [G loss: 0.892175]\n",
      "epoch:32 step:25524[D loss: 0.419835, acc: 60.94%, op_acc: 34.38%] [G loss: 0.890940]\n",
      "epoch:32 step:25525[D loss: 0.405091, acc: 60.16%, op_acc: 44.53%] [G loss: 0.836483]\n",
      "epoch:32 step:25526[D loss: 0.416103, acc: 58.59%, op_acc: 39.84%] [G loss: 1.015837]\n",
      "epoch:32 step:25527[D loss: 0.444652, acc: 55.47%, op_acc: 42.97%] [G loss: 0.904123]\n",
      "epoch:32 step:25528[D loss: 0.376656, acc: 66.41%, op_acc: 46.09%] [G loss: 0.877832]\n",
      "epoch:32 step:25529[D loss: 0.431220, acc: 57.81%, op_acc: 39.84%] [G loss: 0.856950]\n",
      "epoch:32 step:25530[D loss: 0.435882, acc: 52.34%, op_acc: 42.97%] [G loss: 0.836924]\n",
      "epoch:32 step:25531[D loss: 0.453369, acc: 53.12%, op_acc: 41.41%] [G loss: 0.913279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25532[D loss: 0.404066, acc: 60.16%, op_acc: 48.44%] [G loss: 0.913023]\n",
      "epoch:32 step:25533[D loss: 0.404509, acc: 64.06%, op_acc: 45.31%] [G loss: 0.879543]\n",
      "epoch:32 step:25534[D loss: 0.439837, acc: 52.34%, op_acc: 37.50%] [G loss: 0.817825]\n",
      "epoch:32 step:25535[D loss: 0.432877, acc: 56.25%, op_acc: 38.28%] [G loss: 0.815628]\n",
      "epoch:32 step:25536[D loss: 0.427078, acc: 55.47%, op_acc: 42.19%] [G loss: 0.910306]\n",
      "epoch:32 step:25537[D loss: 0.400079, acc: 57.81%, op_acc: 42.97%] [G loss: 0.850429]\n",
      "epoch:32 step:25538[D loss: 0.425901, acc: 60.94%, op_acc: 39.06%] [G loss: 0.823586]\n",
      "epoch:32 step:25539[D loss: 0.430195, acc: 58.59%, op_acc: 39.84%] [G loss: 0.903252]\n",
      "epoch:32 step:25540[D loss: 0.410936, acc: 67.19%, op_acc: 40.62%] [G loss: 0.829977]\n",
      "epoch:32 step:25541[D loss: 0.446001, acc: 51.56%, op_acc: 36.72%] [G loss: 0.811903]\n",
      "epoch:32 step:25542[D loss: 0.401206, acc: 68.75%, op_acc: 35.94%] [G loss: 0.870916]\n",
      "epoch:32 step:25543[D loss: 0.412358, acc: 58.59%, op_acc: 42.97%] [G loss: 0.791304]\n",
      "epoch:32 step:25544[D loss: 0.433850, acc: 56.25%, op_acc: 40.62%] [G loss: 0.962376]\n",
      "epoch:32 step:25545[D loss: 0.421107, acc: 60.16%, op_acc: 35.16%] [G loss: 0.834995]\n",
      "epoch:32 step:25546[D loss: 0.417704, acc: 60.16%, op_acc: 38.28%] [G loss: 0.918046]\n",
      "epoch:32 step:25547[D loss: 0.424893, acc: 57.81%, op_acc: 42.97%] [G loss: 0.880213]\n",
      "epoch:32 step:25548[D loss: 0.422780, acc: 53.91%, op_acc: 42.19%] [G loss: 0.876798]\n",
      "epoch:32 step:25549[D loss: 0.453048, acc: 61.72%, op_acc: 29.69%] [G loss: 0.812809]\n",
      "epoch:32 step:25550[D loss: 0.400695, acc: 59.38%, op_acc: 48.44%] [G loss: 0.885604]\n",
      "##############\n",
      "[0.86745424 0.85966244 0.81075118 0.80440604 0.78897735 0.84203778\n",
      " 0.88105974 0.80693315 0.81287785 0.81886601]\n",
      "##########\n",
      "epoch:32 step:25551[D loss: 0.409767, acc: 57.81%, op_acc: 41.41%] [G loss: 0.908334]\n",
      "epoch:32 step:25552[D loss: 0.461034, acc: 53.12%, op_acc: 33.59%] [G loss: 0.944173]\n",
      "epoch:32 step:25553[D loss: 0.454480, acc: 50.00%, op_acc: 36.72%] [G loss: 0.871093]\n",
      "epoch:32 step:25554[D loss: 0.449909, acc: 57.81%, op_acc: 35.94%] [G loss: 0.741420]\n",
      "epoch:32 step:25555[D loss: 0.429663, acc: 63.28%, op_acc: 37.50%] [G loss: 0.946774]\n",
      "epoch:32 step:25556[D loss: 0.405830, acc: 62.50%, op_acc: 42.97%] [G loss: 0.843648]\n",
      "epoch:32 step:25557[D loss: 0.422113, acc: 58.59%, op_acc: 44.53%] [G loss: 0.869649]\n",
      "epoch:32 step:25558[D loss: 0.380214, acc: 68.75%, op_acc: 42.97%] [G loss: 0.891531]\n",
      "epoch:32 step:25559[D loss: 0.442650, acc: 58.59%, op_acc: 46.09%] [G loss: 0.868001]\n",
      "epoch:32 step:25560[D loss: 0.418366, acc: 60.94%, op_acc: 42.19%] [G loss: 0.863292]\n",
      "epoch:32 step:25561[D loss: 0.412323, acc: 61.72%, op_acc: 44.53%] [G loss: 0.922857]\n",
      "epoch:32 step:25562[D loss: 0.424331, acc: 53.91%, op_acc: 44.53%] [G loss: 0.779998]\n",
      "epoch:32 step:25563[D loss: 0.401594, acc: 64.84%, op_acc: 46.09%] [G loss: 0.941127]\n",
      "epoch:32 step:25564[D loss: 0.456162, acc: 50.78%, op_acc: 32.81%] [G loss: 0.805581]\n",
      "epoch:32 step:25565[D loss: 0.391790, acc: 60.94%, op_acc: 42.97%] [G loss: 0.896263]\n",
      "epoch:32 step:25566[D loss: 0.424962, acc: 62.50%, op_acc: 36.72%] [G loss: 0.890865]\n",
      "epoch:32 step:25567[D loss: 0.464813, acc: 46.09%, op_acc: 37.50%] [G loss: 0.902375]\n",
      "epoch:32 step:25568[D loss: 0.390723, acc: 67.97%, op_acc: 44.53%] [G loss: 0.849437]\n",
      "epoch:32 step:25569[D loss: 0.432420, acc: 60.16%, op_acc: 45.31%] [G loss: 0.956727]\n",
      "epoch:32 step:25570[D loss: 0.426493, acc: 62.50%, op_acc: 35.94%] [G loss: 0.903073]\n",
      "epoch:32 step:25571[D loss: 0.416369, acc: 58.59%, op_acc: 46.88%] [G loss: 0.850234]\n",
      "epoch:32 step:25572[D loss: 0.422658, acc: 61.72%, op_acc: 37.50%] [G loss: 0.937744]\n",
      "epoch:32 step:25573[D loss: 0.472638, acc: 50.00%, op_acc: 33.59%] [G loss: 0.863553]\n",
      "epoch:32 step:25574[D loss: 0.419429, acc: 58.59%, op_acc: 42.19%] [G loss: 0.852295]\n",
      "epoch:32 step:25575[D loss: 0.396721, acc: 60.16%, op_acc: 41.41%] [G loss: 0.862084]\n",
      "epoch:32 step:25576[D loss: 0.472852, acc: 46.88%, op_acc: 33.59%] [G loss: 0.890529]\n",
      "epoch:32 step:25577[D loss: 0.414687, acc: 60.94%, op_acc: 35.94%] [G loss: 0.847015]\n",
      "epoch:32 step:25578[D loss: 0.395408, acc: 65.62%, op_acc: 42.19%] [G loss: 0.878555]\n",
      "epoch:32 step:25579[D loss: 0.388491, acc: 63.28%, op_acc: 40.62%] [G loss: 0.877642]\n",
      "epoch:32 step:25580[D loss: 0.413141, acc: 64.06%, op_acc: 46.88%] [G loss: 0.897907]\n",
      "epoch:32 step:25581[D loss: 0.424784, acc: 55.47%, op_acc: 40.62%] [G loss: 0.924445]\n",
      "epoch:32 step:25582[D loss: 0.428883, acc: 59.38%, op_acc: 40.62%] [G loss: 0.828667]\n",
      "epoch:32 step:25583[D loss: 0.419236, acc: 55.47%, op_acc: 39.84%] [G loss: 0.855085]\n",
      "epoch:32 step:25584[D loss: 0.440091, acc: 53.12%, op_acc: 41.41%] [G loss: 0.875004]\n",
      "epoch:32 step:25585[D loss: 0.434108, acc: 55.47%, op_acc: 42.97%] [G loss: 0.850815]\n",
      "epoch:32 step:25586[D loss: 0.434270, acc: 61.72%, op_acc: 36.72%] [G loss: 0.768238]\n",
      "epoch:32 step:25587[D loss: 0.423880, acc: 54.69%, op_acc: 42.19%] [G loss: 0.878677]\n",
      "epoch:32 step:25588[D loss: 0.404622, acc: 63.28%, op_acc: 42.19%] [G loss: 0.882826]\n",
      "epoch:32 step:25589[D loss: 0.415039, acc: 60.94%, op_acc: 41.41%] [G loss: 0.820955]\n",
      "epoch:32 step:25590[D loss: 0.400482, acc: 69.53%, op_acc: 41.41%] [G loss: 0.872947]\n",
      "epoch:32 step:25591[D loss: 0.440843, acc: 56.25%, op_acc: 33.59%] [G loss: 0.794601]\n",
      "epoch:32 step:25592[D loss: 0.418008, acc: 60.16%, op_acc: 39.84%] [G loss: 0.908245]\n",
      "epoch:32 step:25593[D loss: 0.434069, acc: 57.03%, op_acc: 38.28%] [G loss: 0.826026]\n",
      "epoch:32 step:25594[D loss: 0.406785, acc: 59.38%, op_acc: 38.28%] [G loss: 0.847346]\n",
      "epoch:32 step:25595[D loss: 0.385680, acc: 71.09%, op_acc: 45.31%] [G loss: 0.760228]\n",
      "epoch:32 step:25596[D loss: 0.433223, acc: 62.50%, op_acc: 38.28%] [G loss: 0.934648]\n",
      "epoch:32 step:25597[D loss: 0.418318, acc: 59.38%, op_acc: 40.62%] [G loss: 0.850388]\n",
      "epoch:32 step:25598[D loss: 0.427414, acc: 60.16%, op_acc: 43.75%] [G loss: 0.815269]\n",
      "epoch:32 step:25599[D loss: 0.407076, acc: 59.38%, op_acc: 43.75%] [G loss: 0.879135]\n",
      "epoch:32 step:25600[D loss: 0.412812, acc: 57.03%, op_acc: 45.31%] [G loss: 0.873979]\n",
      "##############\n",
      "[0.83343838 0.84397063 0.79334837 0.80341893 0.79574802 0.8392193\n",
      " 0.88597115 0.84057093 0.79903627 0.80932467]\n",
      "##########\n",
      "epoch:32 step:25601[D loss: 0.412144, acc: 59.38%, op_acc: 39.84%] [G loss: 0.901543]\n",
      "epoch:32 step:25602[D loss: 0.412866, acc: 60.16%, op_acc: 42.97%] [G loss: 0.904083]\n",
      "epoch:32 step:25603[D loss: 0.413682, acc: 61.72%, op_acc: 40.62%] [G loss: 1.010127]\n",
      "epoch:32 step:25604[D loss: 0.424226, acc: 64.84%, op_acc: 41.41%] [G loss: 0.901099]\n",
      "epoch:32 step:25605[D loss: 0.432576, acc: 58.59%, op_acc: 40.62%] [G loss: 0.913009]\n",
      "epoch:32 step:25606[D loss: 0.405065, acc: 62.50%, op_acc: 41.41%] [G loss: 0.865806]\n",
      "epoch:32 step:25607[D loss: 0.433082, acc: 58.59%, op_acc: 43.75%] [G loss: 0.897310]\n",
      "epoch:32 step:25608[D loss: 0.447666, acc: 57.81%, op_acc: 35.94%] [G loss: 0.845637]\n",
      "epoch:32 step:25609[D loss: 0.442984, acc: 53.91%, op_acc: 36.72%] [G loss: 0.919390]\n",
      "epoch:32 step:25610[D loss: 0.398447, acc: 56.25%, op_acc: 48.44%] [G loss: 0.915309]\n",
      "epoch:32 step:25611[D loss: 0.443056, acc: 54.69%, op_acc: 38.28%] [G loss: 0.881800]\n",
      "epoch:32 step:25612[D loss: 0.429198, acc: 60.94%, op_acc: 39.84%] [G loss: 0.965752]\n",
      "epoch:32 step:25613[D loss: 0.409633, acc: 61.72%, op_acc: 42.97%] [G loss: 0.939528]\n",
      "epoch:32 step:25614[D loss: 0.442437, acc: 62.50%, op_acc: 36.72%] [G loss: 0.852938]\n",
      "epoch:32 step:25615[D loss: 0.408669, acc: 58.59%, op_acc: 52.34%] [G loss: 0.930757]\n",
      "epoch:32 step:25616[D loss: 0.449435, acc: 55.47%, op_acc: 39.06%] [G loss: 0.853278]\n",
      "epoch:32 step:25617[D loss: 0.424300, acc: 56.25%, op_acc: 35.94%] [G loss: 0.871024]\n",
      "epoch:32 step:25618[D loss: 0.422441, acc: 51.56%, op_acc: 44.53%] [G loss: 0.969297]\n",
      "epoch:32 step:25619[D loss: 0.408149, acc: 60.94%, op_acc: 38.28%] [G loss: 0.974840]\n",
      "epoch:32 step:25620[D loss: 0.417858, acc: 58.59%, op_acc: 42.19%] [G loss: 0.951511]\n",
      "epoch:32 step:25621[D loss: 0.433215, acc: 64.06%, op_acc: 39.06%] [G loss: 0.918216]\n",
      "epoch:32 step:25622[D loss: 0.389609, acc: 62.50%, op_acc: 39.84%] [G loss: 0.907337]\n",
      "epoch:32 step:25623[D loss: 0.432259, acc: 56.25%, op_acc: 41.41%] [G loss: 0.871622]\n",
      "epoch:32 step:25624[D loss: 0.408111, acc: 66.41%, op_acc: 38.28%] [G loss: 0.916008]\n",
      "epoch:32 step:25625[D loss: 0.442151, acc: 60.94%, op_acc: 34.38%] [G loss: 0.895938]\n",
      "epoch:32 step:25626[D loss: 0.419421, acc: 57.81%, op_acc: 46.09%] [G loss: 0.819161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25627[D loss: 0.455888, acc: 55.47%, op_acc: 30.47%] [G loss: 0.851004]\n",
      "epoch:32 step:25628[D loss: 0.420147, acc: 56.25%, op_acc: 43.75%] [G loss: 0.815564]\n",
      "epoch:32 step:25629[D loss: 0.405883, acc: 54.69%, op_acc: 42.19%] [G loss: 0.845669]\n",
      "epoch:32 step:25630[D loss: 0.419107, acc: 58.59%, op_acc: 37.50%] [G loss: 0.866584]\n",
      "epoch:32 step:25631[D loss: 0.410762, acc: 62.50%, op_acc: 39.06%] [G loss: 0.891357]\n",
      "epoch:32 step:25632[D loss: 0.430628, acc: 63.28%, op_acc: 34.38%] [G loss: 0.813848]\n",
      "epoch:32 step:25633[D loss: 0.411282, acc: 61.72%, op_acc: 41.41%] [G loss: 0.923658]\n",
      "epoch:32 step:25634[D loss: 0.411269, acc: 61.72%, op_acc: 42.19%] [G loss: 0.906112]\n",
      "epoch:32 step:25635[D loss: 0.445431, acc: 56.25%, op_acc: 35.16%] [G loss: 0.874640]\n",
      "epoch:32 step:25636[D loss: 0.400124, acc: 54.69%, op_acc: 44.53%] [G loss: 0.843857]\n",
      "epoch:32 step:25637[D loss: 0.439225, acc: 57.03%, op_acc: 37.50%] [G loss: 0.840360]\n",
      "epoch:32 step:25638[D loss: 0.417965, acc: 66.41%, op_acc: 41.41%] [G loss: 0.968871]\n",
      "epoch:32 step:25639[D loss: 0.391007, acc: 60.94%, op_acc: 42.19%] [G loss: 0.838957]\n",
      "epoch:32 step:25640[D loss: 0.424718, acc: 64.84%, op_acc: 38.28%] [G loss: 0.866819]\n",
      "epoch:32 step:25641[D loss: 0.409791, acc: 64.84%, op_acc: 42.19%] [G loss: 0.798887]\n",
      "epoch:32 step:25642[D loss: 0.435108, acc: 53.12%, op_acc: 41.41%] [G loss: 0.880706]\n",
      "epoch:32 step:25643[D loss: 0.419376, acc: 60.94%, op_acc: 43.75%] [G loss: 0.844617]\n",
      "epoch:32 step:25644[D loss: 0.401852, acc: 63.28%, op_acc: 42.19%] [G loss: 0.883515]\n",
      "epoch:32 step:25645[D loss: 0.422254, acc: 60.16%, op_acc: 42.19%] [G loss: 0.889837]\n",
      "epoch:32 step:25646[D loss: 0.412788, acc: 57.03%, op_acc: 41.41%] [G loss: 0.960811]\n",
      "epoch:32 step:25647[D loss: 0.456697, acc: 56.25%, op_acc: 32.81%] [G loss: 0.803226]\n",
      "epoch:32 step:25648[D loss: 0.420596, acc: 60.94%, op_acc: 39.06%] [G loss: 0.857310]\n",
      "epoch:32 step:25649[D loss: 0.416554, acc: 60.16%, op_acc: 38.28%] [G loss: 0.804816]\n",
      "epoch:32 step:25650[D loss: 0.403321, acc: 60.94%, op_acc: 41.41%] [G loss: 0.945616]\n",
      "##############\n",
      "[0.84490331 0.84509015 0.80728832 0.80614646 0.8135787  0.82892305\n",
      " 0.88473867 0.829764   0.80908838 0.84892689]\n",
      "##########\n",
      "epoch:32 step:25651[D loss: 0.421556, acc: 64.06%, op_acc: 35.94%] [G loss: 0.854244]\n",
      "epoch:32 step:25652[D loss: 0.406391, acc: 60.94%, op_acc: 45.31%] [G loss: 0.858217]\n",
      "epoch:32 step:25653[D loss: 0.381286, acc: 60.94%, op_acc: 41.41%] [G loss: 0.827763]\n",
      "epoch:32 step:25654[D loss: 0.434554, acc: 55.47%, op_acc: 40.62%] [G loss: 0.810620]\n",
      "epoch:32 step:25655[D loss: 0.415178, acc: 56.25%, op_acc: 44.53%] [G loss: 0.812915]\n",
      "epoch:32 step:25656[D loss: 0.398592, acc: 59.38%, op_acc: 48.44%] [G loss: 0.849196]\n",
      "epoch:32 step:25657[D loss: 0.436711, acc: 64.06%, op_acc: 36.72%] [G loss: 0.854891]\n",
      "epoch:32 step:25658[D loss: 0.432554, acc: 59.38%, op_acc: 38.28%] [G loss: 0.894941]\n",
      "epoch:32 step:25659[D loss: 0.395146, acc: 68.75%, op_acc: 38.28%] [G loss: 0.897422]\n",
      "epoch:32 step:25660[D loss: 0.424817, acc: 60.16%, op_acc: 44.53%] [G loss: 0.942591]\n",
      "epoch:32 step:25661[D loss: 0.416684, acc: 61.72%, op_acc: 35.16%] [G loss: 0.842976]\n",
      "epoch:32 step:25662[D loss: 0.422465, acc: 60.94%, op_acc: 35.16%] [G loss: 0.848475]\n",
      "epoch:32 step:25663[D loss: 0.428077, acc: 52.34%, op_acc: 39.06%] [G loss: 0.889271]\n",
      "epoch:32 step:25664[D loss: 0.464356, acc: 54.69%, op_acc: 35.94%] [G loss: 0.809821]\n",
      "epoch:32 step:25665[D loss: 0.413122, acc: 60.94%, op_acc: 40.62%] [G loss: 0.893631]\n",
      "epoch:32 step:25666[D loss: 0.416084, acc: 59.38%, op_acc: 39.06%] [G loss: 0.857080]\n",
      "epoch:32 step:25667[D loss: 0.394448, acc: 60.16%, op_acc: 51.56%] [G loss: 0.890951]\n",
      "epoch:32 step:25668[D loss: 0.450382, acc: 56.25%, op_acc: 34.38%] [G loss: 0.888958]\n",
      "epoch:32 step:25669[D loss: 0.465080, acc: 55.47%, op_acc: 34.38%] [G loss: 0.820050]\n",
      "epoch:32 step:25670[D loss: 0.388606, acc: 67.97%, op_acc: 39.84%] [G loss: 0.916013]\n",
      "epoch:32 step:25671[D loss: 0.400603, acc: 63.28%, op_acc: 39.06%] [G loss: 0.900637]\n",
      "epoch:32 step:25672[D loss: 0.459003, acc: 49.22%, op_acc: 39.06%] [G loss: 0.930938]\n",
      "epoch:32 step:25673[D loss: 0.426816, acc: 55.47%, op_acc: 39.84%] [G loss: 0.880090]\n",
      "epoch:32 step:25674[D loss: 0.397095, acc: 63.28%, op_acc: 41.41%] [G loss: 0.917935]\n",
      "epoch:32 step:25675[D loss: 0.420005, acc: 57.81%, op_acc: 44.53%] [G loss: 0.894069]\n",
      "epoch:32 step:25676[D loss: 0.385973, acc: 68.75%, op_acc: 40.62%] [G loss: 0.932182]\n",
      "epoch:32 step:25677[D loss: 0.452944, acc: 58.59%, op_acc: 38.28%] [G loss: 0.941965]\n",
      "epoch:32 step:25678[D loss: 0.431485, acc: 65.62%, op_acc: 38.28%] [G loss: 0.882945]\n",
      "epoch:32 step:25679[D loss: 0.436223, acc: 53.12%, op_acc: 38.28%] [G loss: 0.846444]\n",
      "epoch:32 step:25680[D loss: 0.427456, acc: 59.38%, op_acc: 42.19%] [G loss: 0.893884]\n",
      "epoch:32 step:25681[D loss: 0.400202, acc: 61.72%, op_acc: 42.97%] [G loss: 0.927940]\n",
      "epoch:32 step:25682[D loss: 0.409319, acc: 65.62%, op_acc: 37.50%] [G loss: 0.875947]\n",
      "epoch:32 step:25683[D loss: 0.407170, acc: 68.75%, op_acc: 43.75%] [G loss: 0.990196]\n",
      "epoch:32 step:25684[D loss: 0.404843, acc: 66.41%, op_acc: 40.62%] [G loss: 0.929286]\n",
      "epoch:32 step:25685[D loss: 0.418558, acc: 58.59%, op_acc: 45.31%] [G loss: 0.866494]\n",
      "epoch:32 step:25686[D loss: 0.417949, acc: 60.16%, op_acc: 37.50%] [G loss: 0.913934]\n",
      "epoch:32 step:25687[D loss: 0.411802, acc: 65.62%, op_acc: 38.28%] [G loss: 0.867634]\n",
      "epoch:32 step:25688[D loss: 0.454797, acc: 57.03%, op_acc: 39.84%] [G loss: 0.957819]\n",
      "epoch:32 step:25689[D loss: 0.382266, acc: 63.28%, op_acc: 42.19%] [G loss: 0.969221]\n",
      "epoch:32 step:25690[D loss: 0.452044, acc: 57.81%, op_acc: 43.75%] [G loss: 0.846351]\n",
      "epoch:32 step:25691[D loss: 0.404572, acc: 57.81%, op_acc: 41.41%] [G loss: 0.884857]\n",
      "epoch:32 step:25692[D loss: 0.426825, acc: 58.59%, op_acc: 38.28%] [G loss: 0.903965]\n",
      "epoch:32 step:25693[D loss: 0.415698, acc: 57.81%, op_acc: 44.53%] [G loss: 0.807049]\n",
      "epoch:32 step:25694[D loss: 0.443706, acc: 60.94%, op_acc: 38.28%] [G loss: 0.862244]\n",
      "epoch:32 step:25695[D loss: 0.453097, acc: 49.22%, op_acc: 41.41%] [G loss: 0.869936]\n",
      "epoch:32 step:25696[D loss: 0.410961, acc: 57.03%, op_acc: 46.88%] [G loss: 0.919941]\n",
      "epoch:32 step:25697[D loss: 0.415537, acc: 60.94%, op_acc: 40.62%] [G loss: 0.885982]\n",
      "epoch:32 step:25698[D loss: 0.413944, acc: 63.28%, op_acc: 42.97%] [G loss: 0.873272]\n",
      "epoch:32 step:25699[D loss: 0.451267, acc: 46.09%, op_acc: 38.28%] [G loss: 0.852141]\n",
      "epoch:32 step:25700[D loss: 0.421440, acc: 57.03%, op_acc: 41.41%] [G loss: 0.875937]\n",
      "##############\n",
      "[0.86272681 0.84992434 0.81866964 0.79503431 0.78106251 0.82088169\n",
      " 0.90169572 0.83559696 0.7939067  0.82016415]\n",
      "##########\n",
      "epoch:32 step:25701[D loss: 0.428282, acc: 53.12%, op_acc: 43.75%] [G loss: 0.816972]\n",
      "epoch:32 step:25702[D loss: 0.420161, acc: 57.81%, op_acc: 42.97%] [G loss: 0.849537]\n",
      "epoch:32 step:25703[D loss: 0.417900, acc: 62.50%, op_acc: 35.94%] [G loss: 0.911405]\n",
      "epoch:32 step:25704[D loss: 0.397420, acc: 60.16%, op_acc: 40.62%] [G loss: 0.820587]\n",
      "epoch:32 step:25705[D loss: 0.433808, acc: 47.66%, op_acc: 43.75%] [G loss: 0.823508]\n",
      "epoch:32 step:25706[D loss: 0.445002, acc: 61.72%, op_acc: 32.03%] [G loss: 0.902772]\n",
      "epoch:32 step:25707[D loss: 0.431007, acc: 58.59%, op_acc: 39.84%] [G loss: 0.860760]\n",
      "epoch:32 step:25708[D loss: 0.395531, acc: 64.84%, op_acc: 42.97%] [G loss: 0.889234]\n",
      "epoch:32 step:25709[D loss: 0.394021, acc: 60.94%, op_acc: 43.75%] [G loss: 0.945517]\n",
      "epoch:32 step:25710[D loss: 0.413642, acc: 57.03%, op_acc: 41.41%] [G loss: 0.906122]\n",
      "epoch:32 step:25711[D loss: 0.431332, acc: 49.22%, op_acc: 42.97%] [G loss: 0.830645]\n",
      "epoch:32 step:25712[D loss: 0.417594, acc: 60.16%, op_acc: 39.84%] [G loss: 0.905728]\n",
      "epoch:32 step:25713[D loss: 0.439494, acc: 57.81%, op_acc: 41.41%] [G loss: 0.837822]\n",
      "epoch:32 step:25714[D loss: 0.438179, acc: 56.25%, op_acc: 41.41%] [G loss: 0.823737]\n",
      "epoch:32 step:25715[D loss: 0.416879, acc: 54.69%, op_acc: 43.75%] [G loss: 0.871401]\n",
      "epoch:32 step:25716[D loss: 0.451174, acc: 46.88%, op_acc: 34.38%] [G loss: 0.917303]\n",
      "epoch:32 step:25717[D loss: 0.409859, acc: 59.38%, op_acc: 42.97%] [G loss: 0.942444]\n",
      "epoch:32 step:25718[D loss: 0.423476, acc: 57.81%, op_acc: 32.03%] [G loss: 0.879744]\n",
      "epoch:32 step:25719[D loss: 0.452002, acc: 60.16%, op_acc: 34.38%] [G loss: 0.853049]\n",
      "epoch:32 step:25720[D loss: 0.418315, acc: 66.41%, op_acc: 33.59%] [G loss: 0.831499]\n",
      "epoch:32 step:25721[D loss: 0.397424, acc: 67.19%, op_acc: 40.62%] [G loss: 0.901263]\n",
      "epoch:32 step:25722[D loss: 0.435067, acc: 59.38%, op_acc: 38.28%] [G loss: 0.827155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25723[D loss: 0.417316, acc: 53.91%, op_acc: 46.88%] [G loss: 0.763946]\n",
      "epoch:32 step:25724[D loss: 0.429738, acc: 57.03%, op_acc: 42.19%] [G loss: 0.853371]\n",
      "epoch:32 step:25725[D loss: 0.421833, acc: 53.12%, op_acc: 39.84%] [G loss: 0.911351]\n",
      "epoch:32 step:25726[D loss: 0.422071, acc: 53.12%, op_acc: 37.50%] [G loss: 0.860531]\n",
      "epoch:32 step:25727[D loss: 0.426225, acc: 62.50%, op_acc: 35.16%] [G loss: 1.032338]\n",
      "epoch:32 step:25728[D loss: 0.421132, acc: 62.50%, op_acc: 37.50%] [G loss: 0.880813]\n",
      "epoch:32 step:25729[D loss: 0.412207, acc: 60.94%, op_acc: 42.97%] [G loss: 0.952733]\n",
      "epoch:32 step:25730[D loss: 0.412966, acc: 63.28%, op_acc: 37.50%] [G loss: 0.929035]\n",
      "epoch:32 step:25731[D loss: 0.394397, acc: 57.03%, op_acc: 48.44%] [G loss: 0.935675]\n",
      "epoch:32 step:25732[D loss: 0.389397, acc: 65.62%, op_acc: 44.53%] [G loss: 0.882115]\n",
      "epoch:32 step:25733[D loss: 0.371779, acc: 72.66%, op_acc: 43.75%] [G loss: 0.959989]\n",
      "epoch:32 step:25734[D loss: 0.422536, acc: 57.03%, op_acc: 43.75%] [G loss: 0.897097]\n",
      "epoch:32 step:25735[D loss: 0.448852, acc: 57.81%, op_acc: 37.50%] [G loss: 0.774134]\n",
      "epoch:32 step:25736[D loss: 0.406715, acc: 59.38%, op_acc: 43.75%] [G loss: 0.899554]\n",
      "epoch:32 step:25737[D loss: 0.391945, acc: 61.72%, op_acc: 38.28%] [G loss: 0.923272]\n",
      "epoch:32 step:25738[D loss: 0.442252, acc: 56.25%, op_acc: 41.41%] [G loss: 0.888744]\n",
      "epoch:32 step:25739[D loss: 0.431521, acc: 60.94%, op_acc: 38.28%] [G loss: 0.912554]\n",
      "epoch:32 step:25740[D loss: 0.422973, acc: 61.72%, op_acc: 39.06%] [G loss: 0.906232]\n",
      "epoch:32 step:25741[D loss: 0.440231, acc: 57.81%, op_acc: 36.72%] [G loss: 0.937036]\n",
      "epoch:32 step:25742[D loss: 0.435878, acc: 59.38%, op_acc: 43.75%] [G loss: 0.940797]\n",
      "epoch:32 step:25743[D loss: 0.458707, acc: 52.34%, op_acc: 37.50%] [G loss: 0.869569]\n",
      "epoch:32 step:25744[D loss: 0.412312, acc: 66.41%, op_acc: 50.78%] [G loss: 0.811240]\n",
      "epoch:32 step:25745[D loss: 0.394857, acc: 64.06%, op_acc: 41.41%] [G loss: 0.867609]\n",
      "epoch:32 step:25746[D loss: 0.414028, acc: 60.16%, op_acc: 41.41%] [G loss: 0.845946]\n",
      "epoch:32 step:25747[D loss: 0.405143, acc: 63.28%, op_acc: 39.06%] [G loss: 0.772187]\n",
      "epoch:32 step:25748[D loss: 0.438425, acc: 53.12%, op_acc: 44.53%] [G loss: 0.883720]\n",
      "epoch:32 step:25749[D loss: 0.427011, acc: 57.81%, op_acc: 43.75%] [G loss: 0.819595]\n",
      "epoch:32 step:25750[D loss: 0.408455, acc: 61.72%, op_acc: 45.31%] [G loss: 0.842306]\n",
      "##############\n",
      "[0.84781803 0.85456505 0.81726596 0.8177972  0.78996092 0.82374189\n",
      " 0.89126668 0.82230401 0.8124994  0.84001751]\n",
      "##########\n",
      "epoch:32 step:25751[D loss: 0.441429, acc: 53.91%, op_acc: 40.62%] [G loss: 0.854173]\n",
      "epoch:32 step:25752[D loss: 0.400725, acc: 63.28%, op_acc: 39.84%] [G loss: 0.905175]\n",
      "epoch:32 step:25753[D loss: 0.389453, acc: 61.72%, op_acc: 48.44%] [G loss: 0.965185]\n",
      "epoch:32 step:25754[D loss: 0.426794, acc: 55.47%, op_acc: 42.19%] [G loss: 0.953079]\n",
      "epoch:32 step:25755[D loss: 0.448370, acc: 42.97%, op_acc: 42.97%] [G loss: 0.922375]\n",
      "epoch:32 step:25756[D loss: 0.399104, acc: 59.38%, op_acc: 44.53%] [G loss: 0.781997]\n",
      "epoch:32 step:25757[D loss: 0.433482, acc: 56.25%, op_acc: 41.41%] [G loss: 0.883913]\n",
      "epoch:32 step:25758[D loss: 0.426282, acc: 60.16%, op_acc: 33.59%] [G loss: 0.862811]\n",
      "epoch:32 step:25759[D loss: 0.400062, acc: 65.62%, op_acc: 44.53%] [G loss: 0.847135]\n",
      "epoch:32 step:25760[D loss: 0.433152, acc: 57.03%, op_acc: 37.50%] [G loss: 0.889586]\n",
      "epoch:32 step:25761[D loss: 0.397412, acc: 65.62%, op_acc: 44.53%] [G loss: 0.956643]\n",
      "epoch:32 step:25762[D loss: 0.389747, acc: 67.19%, op_acc: 42.19%] [G loss: 0.911390]\n",
      "epoch:32 step:25763[D loss: 0.466001, acc: 47.66%, op_acc: 32.03%] [G loss: 0.937593]\n",
      "epoch:32 step:25764[D loss: 0.457219, acc: 52.34%, op_acc: 37.50%] [G loss: 0.907612]\n",
      "epoch:32 step:25765[D loss: 0.446639, acc: 60.16%, op_acc: 39.06%] [G loss: 0.849077]\n",
      "epoch:32 step:25766[D loss: 0.422491, acc: 57.81%, op_acc: 39.84%] [G loss: 0.839152]\n",
      "epoch:32 step:25767[D loss: 0.423754, acc: 62.50%, op_acc: 39.84%] [G loss: 0.963995]\n",
      "epoch:32 step:25768[D loss: 0.419763, acc: 54.69%, op_acc: 37.50%] [G loss: 0.845426]\n",
      "epoch:32 step:25769[D loss: 0.457254, acc: 57.81%, op_acc: 35.16%] [G loss: 0.879856]\n",
      "epoch:32 step:25770[D loss: 0.410912, acc: 60.94%, op_acc: 48.44%] [G loss: 0.839138]\n",
      "epoch:32 step:25771[D loss: 0.379288, acc: 64.06%, op_acc: 42.97%] [G loss: 0.843600]\n",
      "epoch:32 step:25772[D loss: 0.418520, acc: 53.91%, op_acc: 46.09%] [G loss: 0.887790]\n",
      "epoch:32 step:25773[D loss: 0.417934, acc: 58.59%, op_acc: 35.94%] [G loss: 0.893847]\n",
      "epoch:33 step:25774[D loss: 0.392955, acc: 64.06%, op_acc: 45.31%] [G loss: 0.944973]\n",
      "epoch:33 step:25775[D loss: 0.422839, acc: 54.69%, op_acc: 42.97%] [G loss: 0.868240]\n",
      "epoch:33 step:25776[D loss: 0.423044, acc: 58.59%, op_acc: 39.84%] [G loss: 0.929390]\n",
      "epoch:33 step:25777[D loss: 0.421576, acc: 59.38%, op_acc: 44.53%] [G loss: 0.869417]\n",
      "epoch:33 step:25778[D loss: 0.420034, acc: 60.94%, op_acc: 39.84%] [G loss: 0.932734]\n",
      "epoch:33 step:25779[D loss: 0.442100, acc: 53.12%, op_acc: 35.16%] [G loss: 0.965009]\n",
      "epoch:33 step:25780[D loss: 0.422656, acc: 57.03%, op_acc: 43.75%] [G loss: 0.911045]\n",
      "epoch:33 step:25781[D loss: 0.443904, acc: 50.00%, op_acc: 38.28%] [G loss: 0.861219]\n",
      "epoch:33 step:25782[D loss: 0.403942, acc: 57.03%, op_acc: 40.62%] [G loss: 0.835996]\n",
      "epoch:33 step:25783[D loss: 0.425133, acc: 60.16%, op_acc: 39.06%] [G loss: 0.792165]\n",
      "epoch:33 step:25784[D loss: 0.446529, acc: 49.22%, op_acc: 41.41%] [G loss: 0.867729]\n",
      "epoch:33 step:25785[D loss: 0.415742, acc: 61.72%, op_acc: 42.19%] [G loss: 0.830068]\n",
      "epoch:33 step:25786[D loss: 0.390136, acc: 67.97%, op_acc: 39.06%] [G loss: 0.904729]\n",
      "epoch:33 step:25787[D loss: 0.455862, acc: 55.47%, op_acc: 32.81%] [G loss: 0.818770]\n",
      "epoch:33 step:25788[D loss: 0.395836, acc: 65.62%, op_acc: 39.84%] [G loss: 0.850992]\n",
      "epoch:33 step:25789[D loss: 0.412855, acc: 60.16%, op_acc: 41.41%] [G loss: 0.762408]\n",
      "epoch:33 step:25790[D loss: 0.413790, acc: 60.16%, op_acc: 38.28%] [G loss: 0.854813]\n",
      "epoch:33 step:25791[D loss: 0.410156, acc: 60.94%, op_acc: 37.50%] [G loss: 0.828121]\n",
      "epoch:33 step:25792[D loss: 0.422522, acc: 55.47%, op_acc: 37.50%] [G loss: 0.879640]\n",
      "epoch:33 step:25793[D loss: 0.410266, acc: 66.41%, op_acc: 44.53%] [G loss: 0.870061]\n",
      "epoch:33 step:25794[D loss: 0.426435, acc: 60.16%, op_acc: 40.62%] [G loss: 0.875458]\n",
      "epoch:33 step:25795[D loss: 0.423255, acc: 59.38%, op_acc: 39.06%] [G loss: 0.840982]\n",
      "epoch:33 step:25796[D loss: 0.445096, acc: 55.47%, op_acc: 38.28%] [G loss: 0.814072]\n",
      "epoch:33 step:25797[D loss: 0.441563, acc: 57.81%, op_acc: 38.28%] [G loss: 0.896499]\n",
      "epoch:33 step:25798[D loss: 0.443889, acc: 58.59%, op_acc: 36.72%] [G loss: 0.807555]\n",
      "epoch:33 step:25799[D loss: 0.413916, acc: 60.16%, op_acc: 39.06%] [G loss: 0.830962]\n",
      "epoch:33 step:25800[D loss: 0.409088, acc: 65.62%, op_acc: 36.72%] [G loss: 0.908114]\n",
      "##############\n",
      "[0.86236528 0.85770701 0.82366277 0.80474931 0.78856848 0.82748204\n",
      " 0.8760114  0.80874435 0.80920738 0.83001341]\n",
      "##########\n",
      "epoch:33 step:25801[D loss: 0.415201, acc: 53.12%, op_acc: 47.66%] [G loss: 0.875313]\n",
      "epoch:33 step:25802[D loss: 0.405914, acc: 63.28%, op_acc: 45.31%] [G loss: 0.891093]\n",
      "epoch:33 step:25803[D loss: 0.395285, acc: 60.94%, op_acc: 44.53%] [G loss: 0.870193]\n",
      "epoch:33 step:25804[D loss: 0.474214, acc: 48.44%, op_acc: 39.84%] [G loss: 0.755499]\n",
      "epoch:33 step:25805[D loss: 0.418581, acc: 57.81%, op_acc: 41.41%] [G loss: 0.974012]\n",
      "epoch:33 step:25806[D loss: 0.389478, acc: 66.41%, op_acc: 48.44%] [G loss: 0.915044]\n",
      "epoch:33 step:25807[D loss: 0.413800, acc: 58.59%, op_acc: 40.62%] [G loss: 0.900470]\n",
      "epoch:33 step:25808[D loss: 0.403836, acc: 64.06%, op_acc: 40.62%] [G loss: 0.854094]\n",
      "epoch:33 step:25809[D loss: 0.404665, acc: 62.50%, op_acc: 40.62%] [G loss: 0.828241]\n",
      "epoch:33 step:25810[D loss: 0.419449, acc: 63.28%, op_acc: 39.06%] [G loss: 0.851208]\n",
      "epoch:33 step:25811[D loss: 0.408717, acc: 64.06%, op_acc: 37.50%] [G loss: 0.899932]\n",
      "epoch:33 step:25812[D loss: 0.399347, acc: 54.69%, op_acc: 43.75%] [G loss: 0.914401]\n",
      "epoch:33 step:25813[D loss: 0.439836, acc: 57.03%, op_acc: 38.28%] [G loss: 0.916329]\n",
      "epoch:33 step:25814[D loss: 0.413514, acc: 66.41%, op_acc: 42.97%] [G loss: 0.879048]\n",
      "epoch:33 step:25815[D loss: 0.411260, acc: 55.47%, op_acc: 46.09%] [G loss: 0.891486]\n",
      "epoch:33 step:25816[D loss: 0.433024, acc: 56.25%, op_acc: 41.41%] [G loss: 0.893026]\n",
      "epoch:33 step:25817[D loss: 0.426985, acc: 53.91%, op_acc: 40.62%] [G loss: 0.913719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25818[D loss: 0.402635, acc: 64.06%, op_acc: 40.62%] [G loss: 0.901638]\n",
      "epoch:33 step:25819[D loss: 0.424446, acc: 56.25%, op_acc: 37.50%] [G loss: 0.855197]\n",
      "epoch:33 step:25820[D loss: 0.446985, acc: 56.25%, op_acc: 37.50%] [G loss: 0.891311]\n",
      "epoch:33 step:25821[D loss: 0.451595, acc: 53.12%, op_acc: 35.16%] [G loss: 0.865292]\n",
      "epoch:33 step:25822[D loss: 0.402764, acc: 60.94%, op_acc: 42.19%] [G loss: 0.902329]\n",
      "epoch:33 step:25823[D loss: 0.443189, acc: 53.12%, op_acc: 39.84%] [G loss: 0.845132]\n",
      "epoch:33 step:25824[D loss: 0.397701, acc: 69.53%, op_acc: 42.97%] [G loss: 0.855346]\n",
      "epoch:33 step:25825[D loss: 0.407466, acc: 65.62%, op_acc: 42.97%] [G loss: 0.914373]\n",
      "epoch:33 step:25826[D loss: 0.448131, acc: 55.47%, op_acc: 38.28%] [G loss: 0.841891]\n",
      "epoch:33 step:25827[D loss: 0.452768, acc: 49.22%, op_acc: 43.75%] [G loss: 0.877249]\n",
      "epoch:33 step:25828[D loss: 0.377212, acc: 70.31%, op_acc: 42.97%] [G loss: 0.903235]\n",
      "epoch:33 step:25829[D loss: 0.413531, acc: 60.94%, op_acc: 40.62%] [G loss: 0.884680]\n",
      "epoch:33 step:25830[D loss: 0.425656, acc: 53.91%, op_acc: 41.41%] [G loss: 0.891924]\n",
      "epoch:33 step:25831[D loss: 0.403977, acc: 64.06%, op_acc: 41.41%] [G loss: 0.873196]\n",
      "epoch:33 step:25832[D loss: 0.410061, acc: 53.91%, op_acc: 43.75%] [G loss: 0.937444]\n",
      "epoch:33 step:25833[D loss: 0.381402, acc: 67.97%, op_acc: 46.88%] [G loss: 0.888101]\n",
      "epoch:33 step:25834[D loss: 0.410472, acc: 57.81%, op_acc: 36.72%] [G loss: 0.840268]\n",
      "epoch:33 step:25835[D loss: 0.426509, acc: 54.69%, op_acc: 40.62%] [G loss: 0.925045]\n",
      "epoch:33 step:25836[D loss: 0.402018, acc: 56.25%, op_acc: 42.97%] [G loss: 0.827055]\n",
      "epoch:33 step:25837[D loss: 0.417468, acc: 53.91%, op_acc: 41.41%] [G loss: 0.854614]\n",
      "epoch:33 step:25838[D loss: 0.467466, acc: 46.88%, op_acc: 36.72%] [G loss: 0.861519]\n",
      "epoch:33 step:25839[D loss: 0.412105, acc: 60.16%, op_acc: 43.75%] [G loss: 0.934467]\n",
      "epoch:33 step:25840[D loss: 0.395762, acc: 67.19%, op_acc: 39.84%] [G loss: 0.832895]\n",
      "epoch:33 step:25841[D loss: 0.429846, acc: 57.81%, op_acc: 42.97%] [G loss: 0.945264]\n",
      "epoch:33 step:25842[D loss: 0.411720, acc: 54.69%, op_acc: 42.97%] [G loss: 0.867668]\n",
      "epoch:33 step:25843[D loss: 0.423332, acc: 60.94%, op_acc: 42.19%] [G loss: 0.850788]\n",
      "epoch:33 step:25844[D loss: 0.447360, acc: 54.69%, op_acc: 34.38%] [G loss: 0.755833]\n",
      "epoch:33 step:25845[D loss: 0.414266, acc: 50.78%, op_acc: 44.53%] [G loss: 0.891559]\n",
      "epoch:33 step:25846[D loss: 0.427133, acc: 53.12%, op_acc: 37.50%] [G loss: 0.817341]\n",
      "epoch:33 step:25847[D loss: 0.421244, acc: 61.72%, op_acc: 35.94%] [G loss: 0.816675]\n",
      "epoch:33 step:25848[D loss: 0.420673, acc: 57.81%, op_acc: 42.97%] [G loss: 0.841841]\n",
      "epoch:33 step:25849[D loss: 0.460457, acc: 56.25%, op_acc: 35.94%] [G loss: 0.955135]\n",
      "epoch:33 step:25850[D loss: 0.424374, acc: 60.94%, op_acc: 39.06%] [G loss: 0.793540]\n",
      "##############\n",
      "[0.86575199 0.87423121 0.81443528 0.80958705 0.79133905 0.82790201\n",
      " 0.88749195 0.8233103  0.82860916 0.82814721]\n",
      "##########\n",
      "epoch:33 step:25851[D loss: 0.472521, acc: 53.12%, op_acc: 31.25%] [G loss: 0.964270]\n",
      "epoch:33 step:25852[D loss: 0.409907, acc: 61.72%, op_acc: 43.75%] [G loss: 0.873950]\n",
      "epoch:33 step:25853[D loss: 0.448884, acc: 57.03%, op_acc: 35.94%] [G loss: 0.899574]\n",
      "epoch:33 step:25854[D loss: 0.400588, acc: 68.75%, op_acc: 40.62%] [G loss: 0.909135]\n",
      "epoch:33 step:25855[D loss: 0.408965, acc: 60.16%, op_acc: 42.97%] [G loss: 0.913378]\n",
      "epoch:33 step:25856[D loss: 0.407582, acc: 64.84%, op_acc: 35.16%] [G loss: 0.897466]\n",
      "epoch:33 step:25857[D loss: 0.406969, acc: 60.16%, op_acc: 39.06%] [G loss: 0.811987]\n",
      "epoch:33 step:25858[D loss: 0.461644, acc: 59.38%, op_acc: 33.59%] [G loss: 0.866902]\n",
      "epoch:33 step:25859[D loss: 0.433294, acc: 51.56%, op_acc: 39.06%] [G loss: 0.847771]\n",
      "epoch:33 step:25860[D loss: 0.417620, acc: 63.28%, op_acc: 39.06%] [G loss: 0.861432]\n",
      "epoch:33 step:25861[D loss: 0.377345, acc: 71.88%, op_acc: 38.28%] [G loss: 0.938944]\n",
      "epoch:33 step:25862[D loss: 0.434604, acc: 61.72%, op_acc: 40.62%] [G loss: 0.938453]\n",
      "epoch:33 step:25863[D loss: 0.431878, acc: 56.25%, op_acc: 42.19%] [G loss: 0.959358]\n",
      "epoch:33 step:25864[D loss: 0.408424, acc: 60.94%, op_acc: 39.84%] [G loss: 0.839336]\n",
      "epoch:33 step:25865[D loss: 0.437593, acc: 57.81%, op_acc: 37.50%] [G loss: 0.811336]\n",
      "epoch:33 step:25866[D loss: 0.412257, acc: 57.81%, op_acc: 46.09%] [G loss: 0.919365]\n",
      "epoch:33 step:25867[D loss: 0.435382, acc: 57.03%, op_acc: 37.50%] [G loss: 0.827334]\n",
      "epoch:33 step:25868[D loss: 0.397184, acc: 57.03%, op_acc: 39.84%] [G loss: 0.863817]\n",
      "epoch:33 step:25869[D loss: 0.418029, acc: 60.94%, op_acc: 35.94%] [G loss: 0.858295]\n",
      "epoch:33 step:25870[D loss: 0.401464, acc: 60.16%, op_acc: 42.19%] [G loss: 0.875443]\n",
      "epoch:33 step:25871[D loss: 0.412043, acc: 67.97%, op_acc: 39.84%] [G loss: 0.914890]\n",
      "epoch:33 step:25872[D loss: 0.408306, acc: 59.38%, op_acc: 40.62%] [G loss: 0.857320]\n",
      "epoch:33 step:25873[D loss: 0.395809, acc: 63.28%, op_acc: 42.19%] [G loss: 0.866030]\n",
      "epoch:33 step:25874[D loss: 0.415109, acc: 64.84%, op_acc: 39.06%] [G loss: 0.891305]\n",
      "epoch:33 step:25875[D loss: 0.406281, acc: 62.50%, op_acc: 45.31%] [G loss: 0.875484]\n",
      "epoch:33 step:25876[D loss: 0.417641, acc: 64.84%, op_acc: 40.62%] [G loss: 0.912717]\n",
      "epoch:33 step:25877[D loss: 0.438462, acc: 56.25%, op_acc: 38.28%] [G loss: 0.754956]\n",
      "epoch:33 step:25878[D loss: 0.416832, acc: 59.38%, op_acc: 40.62%] [G loss: 0.781518]\n",
      "epoch:33 step:25879[D loss: 0.401146, acc: 64.06%, op_acc: 42.19%] [G loss: 0.984406]\n",
      "epoch:33 step:25880[D loss: 0.419554, acc: 60.94%, op_acc: 38.28%] [G loss: 0.876124]\n",
      "epoch:33 step:25881[D loss: 0.436677, acc: 50.78%, op_acc: 39.84%] [G loss: 0.836741]\n",
      "epoch:33 step:25882[D loss: 0.411647, acc: 60.94%, op_acc: 41.41%] [G loss: 0.906148]\n",
      "epoch:33 step:25883[D loss: 0.409263, acc: 58.59%, op_acc: 39.84%] [G loss: 0.834031]\n",
      "epoch:33 step:25884[D loss: 0.432283, acc: 58.59%, op_acc: 39.84%] [G loss: 0.951903]\n",
      "epoch:33 step:25885[D loss: 0.422965, acc: 61.72%, op_acc: 45.31%] [G loss: 0.929439]\n",
      "epoch:33 step:25886[D loss: 0.433380, acc: 56.25%, op_acc: 39.84%] [G loss: 0.864430]\n",
      "epoch:33 step:25887[D loss: 0.416452, acc: 55.47%, op_acc: 41.41%] [G loss: 0.893507]\n",
      "epoch:33 step:25888[D loss: 0.384461, acc: 60.94%, op_acc: 43.75%] [G loss: 0.941394]\n",
      "epoch:33 step:25889[D loss: 0.432095, acc: 55.47%, op_acc: 38.28%] [G loss: 0.929143]\n",
      "epoch:33 step:25890[D loss: 0.419383, acc: 57.81%, op_acc: 38.28%] [G loss: 0.894866]\n",
      "epoch:33 step:25891[D loss: 0.443479, acc: 51.56%, op_acc: 38.28%] [G loss: 0.818894]\n",
      "epoch:33 step:25892[D loss: 0.438198, acc: 56.25%, op_acc: 40.62%] [G loss: 0.852860]\n",
      "epoch:33 step:25893[D loss: 0.412942, acc: 58.59%, op_acc: 43.75%] [G loss: 0.809163]\n",
      "epoch:33 step:25894[D loss: 0.392444, acc: 67.97%, op_acc: 40.62%] [G loss: 0.905867]\n",
      "epoch:33 step:25895[D loss: 0.439696, acc: 53.91%, op_acc: 40.62%] [G loss: 0.808507]\n",
      "epoch:33 step:25896[D loss: 0.422380, acc: 57.03%, op_acc: 39.06%] [G loss: 0.854456]\n",
      "epoch:33 step:25897[D loss: 0.407573, acc: 64.06%, op_acc: 39.06%] [G loss: 0.912411]\n",
      "epoch:33 step:25898[D loss: 0.447551, acc: 52.34%, op_acc: 33.59%] [G loss: 0.855725]\n",
      "epoch:33 step:25899[D loss: 0.422775, acc: 59.38%, op_acc: 39.06%] [G loss: 0.925565]\n",
      "epoch:33 step:25900[D loss: 0.394657, acc: 63.28%, op_acc: 39.06%] [G loss: 0.870448]\n",
      "##############\n",
      "[0.86505236 0.8685611  0.7988515  0.80250199 0.7945242  0.83623261\n",
      " 0.88438288 0.8236091  0.80269624 0.83793984]\n",
      "##########\n",
      "epoch:33 step:25901[D loss: 0.417250, acc: 53.12%, op_acc: 36.72%] [G loss: 0.815805]\n",
      "epoch:33 step:25902[D loss: 0.433788, acc: 57.03%, op_acc: 33.59%] [G loss: 0.849142]\n",
      "epoch:33 step:25903[D loss: 0.417142, acc: 58.59%, op_acc: 43.75%] [G loss: 0.816773]\n",
      "epoch:33 step:25904[D loss: 0.399081, acc: 66.41%, op_acc: 39.84%] [G loss: 0.858611]\n",
      "epoch:33 step:25905[D loss: 0.390678, acc: 61.72%, op_acc: 45.31%] [G loss: 0.879445]\n",
      "epoch:33 step:25906[D loss: 0.448692, acc: 60.94%, op_acc: 39.84%] [G loss: 0.830326]\n",
      "epoch:33 step:25907[D loss: 0.432569, acc: 55.47%, op_acc: 38.28%] [G loss: 0.877981]\n",
      "epoch:33 step:25908[D loss: 0.441488, acc: 53.12%, op_acc: 41.41%] [G loss: 0.880451]\n",
      "epoch:33 step:25909[D loss: 0.409782, acc: 60.94%, op_acc: 38.28%] [G loss: 0.864779]\n",
      "epoch:33 step:25910[D loss: 0.418812, acc: 57.81%, op_acc: 36.72%] [G loss: 0.926378]\n",
      "epoch:33 step:25911[D loss: 0.408634, acc: 60.94%, op_acc: 42.19%] [G loss: 0.897463]\n",
      "epoch:33 step:25912[D loss: 0.419239, acc: 55.47%, op_acc: 37.50%] [G loss: 0.884345]\n",
      "epoch:33 step:25913[D loss: 0.463833, acc: 45.31%, op_acc: 39.06%] [G loss: 0.760828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25914[D loss: 0.437592, acc: 63.28%, op_acc: 35.16%] [G loss: 0.844234]\n",
      "epoch:33 step:25915[D loss: 0.407679, acc: 64.84%, op_acc: 39.84%] [G loss: 0.844573]\n",
      "epoch:33 step:25916[D loss: 0.457176, acc: 51.56%, op_acc: 34.38%] [G loss: 0.883138]\n",
      "epoch:33 step:25917[D loss: 0.432154, acc: 58.59%, op_acc: 40.62%] [G loss: 0.885434]\n",
      "epoch:33 step:25918[D loss: 0.429033, acc: 53.91%, op_acc: 39.06%] [G loss: 0.885993]\n",
      "epoch:33 step:25919[D loss: 0.407968, acc: 66.41%, op_acc: 35.94%] [G loss: 0.901392]\n",
      "epoch:33 step:25920[D loss: 0.393321, acc: 68.75%, op_acc: 45.31%] [G loss: 0.926879]\n",
      "epoch:33 step:25921[D loss: 0.446793, acc: 54.69%, op_acc: 39.84%] [G loss: 0.839303]\n",
      "epoch:33 step:25922[D loss: 0.412816, acc: 62.50%, op_acc: 40.62%] [G loss: 0.861655]\n",
      "epoch:33 step:25923[D loss: 0.424732, acc: 57.03%, op_acc: 42.19%] [G loss: 0.935910]\n",
      "epoch:33 step:25924[D loss: 0.388260, acc: 63.28%, op_acc: 46.09%] [G loss: 0.899499]\n",
      "epoch:33 step:25925[D loss: 0.430898, acc: 53.91%, op_acc: 37.50%] [G loss: 0.901935]\n",
      "epoch:33 step:25926[D loss: 0.436320, acc: 57.81%, op_acc: 37.50%] [G loss: 0.891057]\n",
      "epoch:33 step:25927[D loss: 0.415368, acc: 60.16%, op_acc: 42.97%] [G loss: 0.902088]\n",
      "epoch:33 step:25928[D loss: 0.427497, acc: 63.28%, op_acc: 38.28%] [G loss: 0.874661]\n",
      "epoch:33 step:25929[D loss: 0.453980, acc: 52.34%, op_acc: 39.06%] [G loss: 0.839715]\n",
      "epoch:33 step:25930[D loss: 0.419300, acc: 60.94%, op_acc: 41.41%] [G loss: 0.896722]\n",
      "epoch:33 step:25931[D loss: 0.402184, acc: 60.16%, op_acc: 42.19%] [G loss: 0.935105]\n",
      "epoch:33 step:25932[D loss: 0.420150, acc: 57.81%, op_acc: 39.06%] [G loss: 0.889801]\n",
      "epoch:33 step:25933[D loss: 0.442157, acc: 55.47%, op_acc: 37.50%] [G loss: 0.926931]\n",
      "epoch:33 step:25934[D loss: 0.427602, acc: 57.81%, op_acc: 45.31%] [G loss: 0.861613]\n",
      "epoch:33 step:25935[D loss: 0.435974, acc: 56.25%, op_acc: 42.19%] [G loss: 0.876991]\n",
      "epoch:33 step:25936[D loss: 0.408986, acc: 64.06%, op_acc: 42.19%] [G loss: 0.914742]\n",
      "epoch:33 step:25937[D loss: 0.426576, acc: 60.94%, op_acc: 36.72%] [G loss: 0.842209]\n",
      "epoch:33 step:25938[D loss: 0.387116, acc: 67.97%, op_acc: 38.28%] [G loss: 0.840302]\n",
      "epoch:33 step:25939[D loss: 0.415700, acc: 68.75%, op_acc: 42.19%] [G loss: 0.884788]\n",
      "epoch:33 step:25940[D loss: 0.406668, acc: 65.62%, op_acc: 40.62%] [G loss: 0.831418]\n",
      "epoch:33 step:25941[D loss: 0.422278, acc: 53.91%, op_acc: 39.84%] [G loss: 0.836722]\n",
      "epoch:33 step:25942[D loss: 0.424616, acc: 57.81%, op_acc: 39.06%] [G loss: 0.839084]\n",
      "epoch:33 step:25943[D loss: 0.415401, acc: 62.50%, op_acc: 40.62%] [G loss: 0.841681]\n",
      "epoch:33 step:25944[D loss: 0.466250, acc: 53.91%, op_acc: 28.91%] [G loss: 0.850433]\n",
      "epoch:33 step:25945[D loss: 0.417516, acc: 57.03%, op_acc: 42.19%] [G loss: 0.830873]\n",
      "epoch:33 step:25946[D loss: 0.421288, acc: 58.59%, op_acc: 41.41%] [G loss: 0.859314]\n",
      "epoch:33 step:25947[D loss: 0.461328, acc: 50.78%, op_acc: 35.16%] [G loss: 0.822167]\n",
      "epoch:33 step:25948[D loss: 0.398412, acc: 64.06%, op_acc: 40.62%] [G loss: 0.836400]\n",
      "epoch:33 step:25949[D loss: 0.422227, acc: 55.47%, op_acc: 43.75%] [G loss: 0.868561]\n",
      "epoch:33 step:25950[D loss: 0.393813, acc: 60.16%, op_acc: 42.97%] [G loss: 0.966806]\n",
      "##############\n",
      "[0.85467541 0.87967045 0.82432662 0.78366412 0.78987825 0.84351391\n",
      " 0.89775575 0.83699921 0.80827091 0.81409087]\n",
      "##########\n",
      "epoch:33 step:25951[D loss: 0.406701, acc: 66.41%, op_acc: 39.06%] [G loss: 0.930263]\n",
      "epoch:33 step:25952[D loss: 0.406023, acc: 61.72%, op_acc: 39.84%] [G loss: 0.946587]\n",
      "epoch:33 step:25953[D loss: 0.429692, acc: 58.59%, op_acc: 39.06%] [G loss: 0.870686]\n",
      "epoch:33 step:25954[D loss: 0.392314, acc: 58.59%, op_acc: 46.88%] [G loss: 0.917395]\n",
      "epoch:33 step:25955[D loss: 0.416342, acc: 62.50%, op_acc: 39.84%] [G loss: 0.761922]\n",
      "epoch:33 step:25956[D loss: 0.411442, acc: 64.84%, op_acc: 42.19%] [G loss: 0.934363]\n",
      "epoch:33 step:25957[D loss: 0.407894, acc: 60.16%, op_acc: 46.09%] [G loss: 0.899046]\n",
      "epoch:33 step:25958[D loss: 0.422185, acc: 54.69%, op_acc: 40.62%] [G loss: 0.893306]\n",
      "epoch:33 step:25959[D loss: 0.405584, acc: 65.62%, op_acc: 39.84%] [G loss: 0.958816]\n",
      "epoch:33 step:25960[D loss: 0.416068, acc: 58.59%, op_acc: 41.41%] [G loss: 0.962269]\n",
      "epoch:33 step:25961[D loss: 0.403024, acc: 57.81%, op_acc: 43.75%] [G loss: 0.912074]\n",
      "epoch:33 step:25962[D loss: 0.437651, acc: 53.12%, op_acc: 39.06%] [G loss: 0.873588]\n",
      "epoch:33 step:25963[D loss: 0.435909, acc: 57.81%, op_acc: 38.28%] [G loss: 0.913285]\n",
      "epoch:33 step:25964[D loss: 0.409965, acc: 56.25%, op_acc: 45.31%] [G loss: 0.879385]\n",
      "epoch:33 step:25965[D loss: 0.418387, acc: 55.47%, op_acc: 41.41%] [G loss: 0.871429]\n",
      "epoch:33 step:25966[D loss: 0.435544, acc: 55.47%, op_acc: 40.62%] [G loss: 0.989459]\n",
      "epoch:33 step:25967[D loss: 0.405950, acc: 66.41%, op_acc: 39.06%] [G loss: 0.894134]\n",
      "epoch:33 step:25968[D loss: 0.414552, acc: 63.28%, op_acc: 37.50%] [G loss: 0.844890]\n",
      "epoch:33 step:25969[D loss: 0.398517, acc: 73.44%, op_acc: 39.84%] [G loss: 0.884480]\n",
      "epoch:33 step:25970[D loss: 0.437143, acc: 53.91%, op_acc: 40.62%] [G loss: 0.858325]\n",
      "epoch:33 step:25971[D loss: 0.435323, acc: 58.59%, op_acc: 41.41%] [G loss: 0.943167]\n",
      "epoch:33 step:25972[D loss: 0.429750, acc: 59.38%, op_acc: 39.06%] [G loss: 0.885309]\n",
      "epoch:33 step:25973[D loss: 0.425111, acc: 57.81%, op_acc: 41.41%] [G loss: 0.904179]\n",
      "epoch:33 step:25974[D loss: 0.421455, acc: 53.91%, op_acc: 45.31%] [G loss: 0.889886]\n",
      "epoch:33 step:25975[D loss: 0.438669, acc: 58.59%, op_acc: 37.50%] [G loss: 0.879922]\n",
      "epoch:33 step:25976[D loss: 0.429538, acc: 58.59%, op_acc: 39.84%] [G loss: 0.821045]\n",
      "epoch:33 step:25977[D loss: 0.441990, acc: 53.91%, op_acc: 37.50%] [G loss: 0.827027]\n",
      "epoch:33 step:25978[D loss: 0.390259, acc: 67.97%, op_acc: 41.41%] [G loss: 0.909597]\n",
      "epoch:33 step:25979[D loss: 0.410766, acc: 57.03%, op_acc: 46.88%] [G loss: 0.861039]\n",
      "epoch:33 step:25980[D loss: 0.424834, acc: 60.94%, op_acc: 40.62%] [G loss: 0.813067]\n",
      "epoch:33 step:25981[D loss: 0.414177, acc: 63.28%, op_acc: 35.16%] [G loss: 0.891237]\n",
      "epoch:33 step:25982[D loss: 0.414036, acc: 55.47%, op_acc: 42.19%] [G loss: 0.936038]\n",
      "epoch:33 step:25983[D loss: 0.434522, acc: 56.25%, op_acc: 36.72%] [G loss: 0.867677]\n",
      "epoch:33 step:25984[D loss: 0.415193, acc: 67.97%, op_acc: 37.50%] [G loss: 0.872071]\n",
      "epoch:33 step:25985[D loss: 0.399673, acc: 67.19%, op_acc: 43.75%] [G loss: 0.945302]\n",
      "epoch:33 step:25986[D loss: 0.417372, acc: 58.59%, op_acc: 37.50%] [G loss: 0.867634]\n",
      "epoch:33 step:25987[D loss: 0.444164, acc: 53.91%, op_acc: 37.50%] [G loss: 1.003407]\n",
      "epoch:33 step:25988[D loss: 0.415837, acc: 63.28%, op_acc: 38.28%] [G loss: 0.907307]\n",
      "epoch:33 step:25989[D loss: 0.432679, acc: 55.47%, op_acc: 36.72%] [G loss: 0.942451]\n",
      "epoch:33 step:25990[D loss: 0.392432, acc: 68.75%, op_acc: 39.06%] [G loss: 0.872528]\n",
      "epoch:33 step:25991[D loss: 0.401415, acc: 60.94%, op_acc: 42.97%] [G loss: 0.893609]\n",
      "epoch:33 step:25992[D loss: 0.416579, acc: 57.81%, op_acc: 45.31%] [G loss: 0.868490]\n",
      "epoch:33 step:25993[D loss: 0.441819, acc: 55.47%, op_acc: 41.41%] [G loss: 0.918729]\n",
      "epoch:33 step:25994[D loss: 0.421562, acc: 64.06%, op_acc: 38.28%] [G loss: 0.876291]\n",
      "epoch:33 step:25995[D loss: 0.408571, acc: 71.09%, op_acc: 37.50%] [G loss: 0.899705]\n",
      "epoch:33 step:25996[D loss: 0.423042, acc: 58.59%, op_acc: 42.97%] [G loss: 0.921652]\n",
      "epoch:33 step:25997[D loss: 0.433720, acc: 51.56%, op_acc: 38.28%] [G loss: 0.890780]\n",
      "epoch:33 step:25998[D loss: 0.456961, acc: 46.09%, op_acc: 40.62%] [G loss: 0.818518]\n",
      "epoch:33 step:25999[D loss: 0.435310, acc: 58.59%, op_acc: 39.84%] [G loss: 0.860973]\n",
      "epoch:33 step:26000[D loss: 0.422302, acc: 59.38%, op_acc: 41.41%] [G loss: 0.925234]\n",
      "##############\n",
      "[0.8780239  0.85030963 0.81008416 0.81760183 0.81144118 0.82882278\n",
      " 0.87101899 0.83193067 0.79678917 0.83950629]\n",
      "##########\n",
      "epoch:33 step:26001[D loss: 0.421288, acc: 60.16%, op_acc: 43.75%] [G loss: 0.887132]\n",
      "epoch:33 step:26002[D loss: 0.417997, acc: 59.38%, op_acc: 42.19%] [G loss: 0.887983]\n",
      "epoch:33 step:26003[D loss: 0.436208, acc: 58.59%, op_acc: 39.06%] [G loss: 0.959021]\n",
      "epoch:33 step:26004[D loss: 0.408759, acc: 55.47%, op_acc: 46.09%] [G loss: 0.932808]\n",
      "epoch:33 step:26005[D loss: 0.426649, acc: 59.38%, op_acc: 40.62%] [G loss: 0.862826]\n",
      "epoch:33 step:26006[D loss: 0.388660, acc: 67.19%, op_acc: 42.19%] [G loss: 0.910035]\n",
      "epoch:33 step:26007[D loss: 0.418083, acc: 61.72%, op_acc: 42.97%] [G loss: 0.916503]\n",
      "epoch:33 step:26008[D loss: 0.414434, acc: 59.38%, op_acc: 44.53%] [G loss: 0.874017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26009[D loss: 0.442144, acc: 53.12%, op_acc: 40.62%] [G loss: 0.881918]\n",
      "epoch:33 step:26010[D loss: 0.405649, acc: 62.50%, op_acc: 39.84%] [G loss: 1.025919]\n",
      "epoch:33 step:26011[D loss: 0.421878, acc: 60.16%, op_acc: 46.09%] [G loss: 0.930194]\n",
      "epoch:33 step:26012[D loss: 0.429182, acc: 53.91%, op_acc: 37.50%] [G loss: 0.812769]\n",
      "epoch:33 step:26013[D loss: 0.396898, acc: 66.41%, op_acc: 47.66%] [G loss: 0.903595]\n",
      "epoch:33 step:26014[D loss: 0.422303, acc: 58.59%, op_acc: 42.19%] [G loss: 0.910332]\n",
      "epoch:33 step:26015[D loss: 0.399643, acc: 58.59%, op_acc: 44.53%] [G loss: 0.974131]\n",
      "epoch:33 step:26016[D loss: 0.405803, acc: 58.59%, op_acc: 46.09%] [G loss: 0.900717]\n",
      "epoch:33 step:26017[D loss: 0.437624, acc: 53.91%, op_acc: 37.50%] [G loss: 0.893451]\n",
      "epoch:33 step:26018[D loss: 0.435410, acc: 52.34%, op_acc: 41.41%] [G loss: 0.813146]\n",
      "epoch:33 step:26019[D loss: 0.453430, acc: 55.47%, op_acc: 36.72%] [G loss: 0.919547]\n",
      "epoch:33 step:26020[D loss: 0.424277, acc: 53.91%, op_acc: 42.97%] [G loss: 0.920326]\n",
      "epoch:33 step:26021[D loss: 0.465514, acc: 46.09%, op_acc: 33.59%] [G loss: 0.849205]\n",
      "epoch:33 step:26022[D loss: 0.405924, acc: 62.50%, op_acc: 42.97%] [G loss: 0.880242]\n",
      "epoch:33 step:26023[D loss: 0.449694, acc: 67.19%, op_acc: 37.50%] [G loss: 0.915596]\n",
      "epoch:33 step:26024[D loss: 0.399858, acc: 66.41%, op_acc: 42.19%] [G loss: 0.841033]\n",
      "epoch:33 step:26025[D loss: 0.415318, acc: 57.81%, op_acc: 42.97%] [G loss: 0.888847]\n",
      "epoch:33 step:26026[D loss: 0.427233, acc: 56.25%, op_acc: 35.94%] [G loss: 0.874665]\n",
      "epoch:33 step:26027[D loss: 0.428023, acc: 57.81%, op_acc: 35.94%] [G loss: 0.913000]\n",
      "epoch:33 step:26028[D loss: 0.419885, acc: 55.47%, op_acc: 42.19%] [G loss: 0.821428]\n",
      "epoch:33 step:26029[D loss: 0.428447, acc: 54.69%, op_acc: 39.84%] [G loss: 0.922425]\n",
      "epoch:33 step:26030[D loss: 0.398837, acc: 65.62%, op_acc: 39.06%] [G loss: 0.815733]\n",
      "epoch:33 step:26031[D loss: 0.424284, acc: 53.12%, op_acc: 37.50%] [G loss: 0.852556]\n",
      "epoch:33 step:26032[D loss: 0.455503, acc: 56.25%, op_acc: 33.59%] [G loss: 0.834994]\n",
      "epoch:33 step:26033[D loss: 0.420234, acc: 59.38%, op_acc: 38.28%] [G loss: 0.844823]\n",
      "epoch:33 step:26034[D loss: 0.424415, acc: 65.62%, op_acc: 41.41%] [G loss: 0.832485]\n",
      "epoch:33 step:26035[D loss: 0.408017, acc: 63.28%, op_acc: 39.06%] [G loss: 0.927490]\n",
      "epoch:33 step:26036[D loss: 0.410789, acc: 65.62%, op_acc: 39.84%] [G loss: 0.883898]\n",
      "epoch:33 step:26037[D loss: 0.401104, acc: 59.38%, op_acc: 41.41%] [G loss: 0.948887]\n",
      "epoch:33 step:26038[D loss: 0.417053, acc: 57.81%, op_acc: 36.72%] [G loss: 0.913770]\n",
      "epoch:33 step:26039[D loss: 0.408198, acc: 63.28%, op_acc: 39.06%] [G loss: 0.903026]\n",
      "epoch:33 step:26040[D loss: 0.430078, acc: 54.69%, op_acc: 42.19%] [G loss: 0.896298]\n",
      "epoch:33 step:26041[D loss: 0.388023, acc: 64.06%, op_acc: 47.66%] [G loss: 0.878815]\n",
      "epoch:33 step:26042[D loss: 0.384554, acc: 69.53%, op_acc: 46.88%] [G loss: 0.917745]\n",
      "epoch:33 step:26043[D loss: 0.415294, acc: 63.28%, op_acc: 35.94%] [G loss: 0.861232]\n",
      "epoch:33 step:26044[D loss: 0.447224, acc: 50.78%, op_acc: 38.28%] [G loss: 0.873275]\n",
      "epoch:33 step:26045[D loss: 0.416320, acc: 62.50%, op_acc: 38.28%] [G loss: 0.901673]\n",
      "epoch:33 step:26046[D loss: 0.407687, acc: 58.59%, op_acc: 46.09%] [G loss: 0.890619]\n",
      "epoch:33 step:26047[D loss: 0.425762, acc: 62.50%, op_acc: 36.72%] [G loss: 0.925628]\n",
      "epoch:33 step:26048[D loss: 0.433289, acc: 53.12%, op_acc: 42.19%] [G loss: 0.893474]\n",
      "epoch:33 step:26049[D loss: 0.440330, acc: 57.81%, op_acc: 32.03%] [G loss: 0.903752]\n",
      "epoch:33 step:26050[D loss: 0.412738, acc: 64.84%, op_acc: 33.59%] [G loss: 0.921809]\n",
      "##############\n",
      "[0.84989336 0.84554074 0.81369952 0.81318879 0.80085707 0.81220321\n",
      " 0.8746754  0.81884823 0.80997457 0.83559562]\n",
      "##########\n",
      "epoch:33 step:26051[D loss: 0.438447, acc: 53.91%, op_acc: 35.94%] [G loss: 0.885948]\n",
      "epoch:33 step:26052[D loss: 0.426887, acc: 56.25%, op_acc: 41.41%] [G loss: 0.849301]\n",
      "epoch:33 step:26053[D loss: 0.416182, acc: 59.38%, op_acc: 40.62%] [G loss: 0.825911]\n",
      "epoch:33 step:26054[D loss: 0.440257, acc: 54.69%, op_acc: 35.16%] [G loss: 0.866829]\n",
      "epoch:33 step:26055[D loss: 0.436033, acc: 61.72%, op_acc: 39.84%] [G loss: 0.898828]\n",
      "epoch:33 step:26056[D loss: 0.417787, acc: 63.28%, op_acc: 40.62%] [G loss: 0.924360]\n",
      "epoch:33 step:26057[D loss: 0.404697, acc: 65.62%, op_acc: 40.62%] [G loss: 0.941367]\n",
      "epoch:33 step:26058[D loss: 0.395450, acc: 68.75%, op_acc: 39.84%] [G loss: 0.885972]\n",
      "epoch:33 step:26059[D loss: 0.439121, acc: 57.81%, op_acc: 38.28%] [G loss: 0.880051]\n",
      "epoch:33 step:26060[D loss: 0.404687, acc: 70.31%, op_acc: 43.75%] [G loss: 0.871966]\n",
      "epoch:33 step:26061[D loss: 0.427758, acc: 55.47%, op_acc: 41.41%] [G loss: 0.856748]\n",
      "epoch:33 step:26062[D loss: 0.426239, acc: 63.28%, op_acc: 37.50%] [G loss: 0.834836]\n",
      "epoch:33 step:26063[D loss: 0.418158, acc: 57.03%, op_acc: 44.53%] [G loss: 0.802669]\n",
      "epoch:33 step:26064[D loss: 0.422817, acc: 66.41%, op_acc: 44.53%] [G loss: 0.881288]\n",
      "epoch:33 step:26065[D loss: 0.477752, acc: 46.88%, op_acc: 33.59%] [G loss: 0.817789]\n",
      "epoch:33 step:26066[D loss: 0.427528, acc: 57.81%, op_acc: 37.50%] [G loss: 0.835113]\n",
      "epoch:33 step:26067[D loss: 0.408729, acc: 62.50%, op_acc: 38.28%] [G loss: 0.840010]\n",
      "epoch:33 step:26068[D loss: 0.416837, acc: 60.94%, op_acc: 39.84%] [G loss: 0.908610]\n",
      "epoch:33 step:26069[D loss: 0.395280, acc: 64.84%, op_acc: 39.06%] [G loss: 0.892806]\n",
      "epoch:33 step:26070[D loss: 0.423125, acc: 60.94%, op_acc: 36.72%] [G loss: 0.822240]\n",
      "epoch:33 step:26071[D loss: 0.407040, acc: 64.84%, op_acc: 43.75%] [G loss: 0.844560]\n",
      "epoch:33 step:26072[D loss: 0.426908, acc: 59.38%, op_acc: 36.72%] [G loss: 0.845478]\n",
      "epoch:33 step:26073[D loss: 0.425778, acc: 64.84%, op_acc: 36.72%] [G loss: 0.803635]\n",
      "epoch:33 step:26074[D loss: 0.427026, acc: 61.72%, op_acc: 41.41%] [G loss: 0.792577]\n",
      "epoch:33 step:26075[D loss: 0.434723, acc: 61.72%, op_acc: 34.38%] [G loss: 0.893880]\n",
      "epoch:33 step:26076[D loss: 0.427606, acc: 60.16%, op_acc: 40.62%] [G loss: 0.902410]\n",
      "epoch:33 step:26077[D loss: 0.418118, acc: 59.38%, op_acc: 43.75%] [G loss: 0.840936]\n",
      "epoch:33 step:26078[D loss: 0.406133, acc: 64.06%, op_acc: 39.84%] [G loss: 0.869417]\n",
      "epoch:33 step:26079[D loss: 0.434995, acc: 59.38%, op_acc: 39.06%] [G loss: 0.947184]\n",
      "epoch:33 step:26080[D loss: 0.372229, acc: 71.88%, op_acc: 43.75%] [G loss: 0.883273]\n",
      "epoch:33 step:26081[D loss: 0.443899, acc: 57.81%, op_acc: 38.28%] [G loss: 0.916597]\n",
      "epoch:33 step:26082[D loss: 0.456031, acc: 53.12%, op_acc: 35.94%] [G loss: 0.850903]\n",
      "epoch:33 step:26083[D loss: 0.425312, acc: 65.62%, op_acc: 39.06%] [G loss: 0.886176]\n",
      "epoch:33 step:26084[D loss: 0.416955, acc: 58.59%, op_acc: 38.28%] [G loss: 0.920517]\n",
      "epoch:33 step:26085[D loss: 0.410835, acc: 58.59%, op_acc: 43.75%] [G loss: 0.916914]\n",
      "epoch:33 step:26086[D loss: 0.447529, acc: 49.22%, op_acc: 40.62%] [G loss: 0.841549]\n",
      "epoch:33 step:26087[D loss: 0.390799, acc: 67.19%, op_acc: 43.75%] [G loss: 0.887072]\n",
      "epoch:33 step:26088[D loss: 0.406756, acc: 65.62%, op_acc: 40.62%] [G loss: 0.986051]\n",
      "epoch:33 step:26089[D loss: 0.397233, acc: 61.72%, op_acc: 45.31%] [G loss: 0.942062]\n",
      "epoch:33 step:26090[D loss: 0.419877, acc: 57.03%, op_acc: 41.41%] [G loss: 0.901163]\n",
      "epoch:33 step:26091[D loss: 0.440754, acc: 57.03%, op_acc: 32.81%] [G loss: 0.834979]\n",
      "epoch:33 step:26092[D loss: 0.454650, acc: 55.47%, op_acc: 33.59%] [G loss: 0.896661]\n",
      "epoch:33 step:26093[D loss: 0.409918, acc: 64.06%, op_acc: 42.19%] [G loss: 0.972728]\n",
      "epoch:33 step:26094[D loss: 0.413887, acc: 70.31%, op_acc: 40.62%] [G loss: 0.855434]\n",
      "epoch:33 step:26095[D loss: 0.396207, acc: 67.97%, op_acc: 38.28%] [G loss: 0.848678]\n",
      "epoch:33 step:26096[D loss: 0.426995, acc: 55.47%, op_acc: 41.41%] [G loss: 0.786549]\n",
      "epoch:33 step:26097[D loss: 0.426197, acc: 61.72%, op_acc: 35.16%] [G loss: 0.800395]\n",
      "epoch:33 step:26098[D loss: 0.417804, acc: 59.38%, op_acc: 44.53%] [G loss: 0.874116]\n",
      "epoch:33 step:26099[D loss: 0.413825, acc: 66.41%, op_acc: 41.41%] [G loss: 0.853754]\n",
      "epoch:33 step:26100[D loss: 0.426312, acc: 59.38%, op_acc: 39.84%] [G loss: 0.836060]\n",
      "##############\n",
      "[0.84935081 0.86431434 0.806411   0.80744645 0.77983886 0.81908199\n",
      " 0.88225219 0.80879538 0.78938969 0.83253558]\n",
      "##########\n",
      "epoch:33 step:26101[D loss: 0.424531, acc: 57.81%, op_acc: 38.28%] [G loss: 0.884877]\n",
      "epoch:33 step:26102[D loss: 0.438879, acc: 55.47%, op_acc: 33.59%] [G loss: 0.840096]\n",
      "epoch:33 step:26103[D loss: 0.411012, acc: 57.81%, op_acc: 46.88%] [G loss: 0.813372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26104[D loss: 0.420150, acc: 63.28%, op_acc: 35.16%] [G loss: 0.892510]\n",
      "epoch:33 step:26105[D loss: 0.426141, acc: 55.47%, op_acc: 40.62%] [G loss: 0.831840]\n",
      "epoch:33 step:26106[D loss: 0.441449, acc: 54.69%, op_acc: 39.84%] [G loss: 0.880561]\n",
      "epoch:33 step:26107[D loss: 0.408964, acc: 59.38%, op_acc: 42.97%] [G loss: 0.871567]\n",
      "epoch:33 step:26108[D loss: 0.432131, acc: 57.81%, op_acc: 36.72%] [G loss: 0.887034]\n",
      "epoch:33 step:26109[D loss: 0.427741, acc: 57.03%, op_acc: 36.72%] [G loss: 0.855841]\n",
      "epoch:33 step:26110[D loss: 0.441459, acc: 64.06%, op_acc: 38.28%] [G loss: 0.903754]\n",
      "epoch:33 step:26111[D loss: 0.393537, acc: 60.16%, op_acc: 42.97%] [G loss: 0.907785]\n",
      "epoch:33 step:26112[D loss: 0.395500, acc: 69.53%, op_acc: 41.41%] [G loss: 0.945507]\n",
      "epoch:33 step:26113[D loss: 0.429212, acc: 58.59%, op_acc: 41.41%] [G loss: 0.952332]\n",
      "epoch:33 step:26114[D loss: 0.441135, acc: 57.03%, op_acc: 37.50%] [G loss: 0.821961]\n",
      "epoch:33 step:26115[D loss: 0.452008, acc: 53.91%, op_acc: 37.50%] [G loss: 0.855471]\n",
      "epoch:33 step:26116[D loss: 0.402182, acc: 65.62%, op_acc: 44.53%] [G loss: 0.827983]\n",
      "epoch:33 step:26117[D loss: 0.387259, acc: 62.50%, op_acc: 45.31%] [G loss: 0.877662]\n",
      "epoch:33 step:26118[D loss: 0.399556, acc: 72.66%, op_acc: 38.28%] [G loss: 0.813915]\n",
      "epoch:33 step:26119[D loss: 0.393553, acc: 67.19%, op_acc: 40.62%] [G loss: 0.964834]\n",
      "epoch:33 step:26120[D loss: 0.421528, acc: 56.25%, op_acc: 41.41%] [G loss: 0.932175]\n",
      "epoch:33 step:26121[D loss: 0.422777, acc: 61.72%, op_acc: 37.50%] [G loss: 0.859326]\n",
      "epoch:33 step:26122[D loss: 0.407661, acc: 66.41%, op_acc: 37.50%] [G loss: 0.890685]\n",
      "epoch:33 step:26123[D loss: 0.426784, acc: 60.94%, op_acc: 37.50%] [G loss: 0.847348]\n",
      "epoch:33 step:26124[D loss: 0.433944, acc: 57.03%, op_acc: 41.41%] [G loss: 0.896646]\n",
      "epoch:33 step:26125[D loss: 0.434279, acc: 59.38%, op_acc: 35.94%] [G loss: 0.902763]\n",
      "epoch:33 step:26126[D loss: 0.406193, acc: 58.59%, op_acc: 46.09%] [G loss: 0.903757]\n",
      "epoch:33 step:26127[D loss: 0.440381, acc: 56.25%, op_acc: 37.50%] [G loss: 0.897907]\n",
      "epoch:33 step:26128[D loss: 0.430018, acc: 59.38%, op_acc: 39.84%] [G loss: 0.861581]\n",
      "epoch:33 step:26129[D loss: 0.411946, acc: 61.72%, op_acc: 40.62%] [G loss: 0.851201]\n",
      "epoch:33 step:26130[D loss: 0.442571, acc: 59.38%, op_acc: 36.72%] [G loss: 0.878492]\n",
      "epoch:33 step:26131[D loss: 0.424298, acc: 60.94%, op_acc: 36.72%] [G loss: 0.818634]\n",
      "epoch:33 step:26132[D loss: 0.431757, acc: 57.03%, op_acc: 38.28%] [G loss: 0.859574]\n",
      "epoch:33 step:26133[D loss: 0.403815, acc: 61.72%, op_acc: 42.19%] [G loss: 0.879873]\n",
      "epoch:33 step:26134[D loss: 0.403806, acc: 62.50%, op_acc: 42.97%] [G loss: 0.948924]\n",
      "epoch:33 step:26135[D loss: 0.394995, acc: 61.72%, op_acc: 40.62%] [G loss: 0.959091]\n",
      "epoch:33 step:26136[D loss: 0.423389, acc: 60.16%, op_acc: 44.53%] [G loss: 0.825786]\n",
      "epoch:33 step:26137[D loss: 0.415879, acc: 60.16%, op_acc: 44.53%] [G loss: 0.897027]\n",
      "epoch:33 step:26138[D loss: 0.393954, acc: 65.62%, op_acc: 41.41%] [G loss: 0.939035]\n",
      "epoch:33 step:26139[D loss: 0.421506, acc: 54.69%, op_acc: 38.28%] [G loss: 0.832339]\n",
      "epoch:33 step:26140[D loss: 0.413455, acc: 64.84%, op_acc: 42.97%] [G loss: 0.890651]\n",
      "epoch:33 step:26141[D loss: 0.416789, acc: 60.16%, op_acc: 41.41%] [G loss: 0.836011]\n",
      "epoch:33 step:26142[D loss: 0.401100, acc: 61.72%, op_acc: 48.44%] [G loss: 0.926223]\n",
      "epoch:33 step:26143[D loss: 0.414471, acc: 57.03%, op_acc: 49.22%] [G loss: 0.901139]\n",
      "epoch:33 step:26144[D loss: 0.412265, acc: 57.81%, op_acc: 40.62%] [G loss: 0.840801]\n",
      "epoch:33 step:26145[D loss: 0.431036, acc: 59.38%, op_acc: 39.84%] [G loss: 0.898554]\n",
      "epoch:33 step:26146[D loss: 0.413477, acc: 57.03%, op_acc: 41.41%] [G loss: 0.829346]\n",
      "epoch:33 step:26147[D loss: 0.425166, acc: 60.16%, op_acc: 39.84%] [G loss: 0.850242]\n",
      "epoch:33 step:26148[D loss: 0.397788, acc: 68.75%, op_acc: 42.19%] [G loss: 0.946981]\n",
      "epoch:33 step:26149[D loss: 0.422840, acc: 59.38%, op_acc: 39.84%] [G loss: 0.818594]\n",
      "epoch:33 step:26150[D loss: 0.389970, acc: 65.62%, op_acc: 44.53%] [G loss: 0.893693]\n",
      "##############\n",
      "[0.86507084 0.84967181 0.80122752 0.82027315 0.80782488 0.81460098\n",
      " 0.87357683 0.82443778 0.8095574  0.83867872]\n",
      "##########\n",
      "epoch:33 step:26151[D loss: 0.425397, acc: 60.16%, op_acc: 39.06%] [G loss: 0.868145]\n",
      "epoch:33 step:26152[D loss: 0.432076, acc: 58.59%, op_acc: 40.62%] [G loss: 0.799787]\n",
      "epoch:33 step:26153[D loss: 0.422162, acc: 58.59%, op_acc: 35.16%] [G loss: 0.915443]\n",
      "epoch:33 step:26154[D loss: 0.426324, acc: 57.03%, op_acc: 37.50%] [G loss: 0.855172]\n",
      "epoch:33 step:26155[D loss: 0.435305, acc: 56.25%, op_acc: 40.62%] [G loss: 0.864940]\n",
      "epoch:33 step:26156[D loss: 0.410090, acc: 62.50%, op_acc: 41.41%] [G loss: 0.866942]\n",
      "epoch:33 step:26157[D loss: 0.389071, acc: 64.06%, op_acc: 42.19%] [G loss: 0.958059]\n",
      "epoch:33 step:26158[D loss: 0.409832, acc: 61.72%, op_acc: 43.75%] [G loss: 0.866883]\n",
      "epoch:33 step:26159[D loss: 0.401884, acc: 63.28%, op_acc: 42.97%] [G loss: 0.862809]\n",
      "epoch:33 step:26160[D loss: 0.432918, acc: 62.50%, op_acc: 39.84%] [G loss: 0.830892]\n",
      "epoch:33 step:26161[D loss: 0.416313, acc: 65.62%, op_acc: 39.06%] [G loss: 0.843830]\n",
      "epoch:33 step:26162[D loss: 0.407508, acc: 64.06%, op_acc: 45.31%] [G loss: 0.901900]\n",
      "epoch:33 step:26163[D loss: 0.412043, acc: 67.97%, op_acc: 38.28%] [G loss: 0.921584]\n",
      "epoch:33 step:26164[D loss: 0.426770, acc: 55.47%, op_acc: 42.19%] [G loss: 0.951441]\n",
      "epoch:33 step:26165[D loss: 0.410516, acc: 59.38%, op_acc: 45.31%] [G loss: 0.893361]\n",
      "epoch:33 step:26166[D loss: 0.408900, acc: 57.81%, op_acc: 48.44%] [G loss: 0.853730]\n",
      "epoch:33 step:26167[D loss: 0.439060, acc: 53.12%, op_acc: 37.50%] [G loss: 0.822758]\n",
      "epoch:33 step:26168[D loss: 0.437887, acc: 55.47%, op_acc: 35.16%] [G loss: 0.954723]\n",
      "epoch:33 step:26169[D loss: 0.409511, acc: 57.81%, op_acc: 46.09%] [G loss: 0.925221]\n",
      "epoch:33 step:26170[D loss: 0.396402, acc: 59.38%, op_acc: 41.41%] [G loss: 0.874357]\n",
      "epoch:33 step:26171[D loss: 0.422659, acc: 55.47%, op_acc: 37.50%] [G loss: 0.896005]\n",
      "epoch:33 step:26172[D loss: 0.413624, acc: 65.62%, op_acc: 36.72%] [G loss: 0.903975]\n",
      "epoch:33 step:26173[D loss: 0.408514, acc: 59.38%, op_acc: 44.53%] [G loss: 0.877433]\n",
      "epoch:33 step:26174[D loss: 0.424660, acc: 63.28%, op_acc: 42.19%] [G loss: 0.843537]\n",
      "epoch:33 step:26175[D loss: 0.400765, acc: 61.72%, op_acc: 41.41%] [G loss: 0.918051]\n",
      "epoch:33 step:26176[D loss: 0.406242, acc: 63.28%, op_acc: 42.97%] [G loss: 0.868250]\n",
      "epoch:33 step:26177[D loss: 0.378722, acc: 64.06%, op_acc: 42.19%] [G loss: 0.923034]\n",
      "epoch:33 step:26178[D loss: 0.440229, acc: 60.94%, op_acc: 39.84%] [G loss: 0.887886]\n",
      "epoch:33 step:26179[D loss: 0.428835, acc: 57.81%, op_acc: 41.41%] [G loss: 0.863056]\n",
      "epoch:33 step:26180[D loss: 0.424558, acc: 59.38%, op_acc: 40.62%] [G loss: 0.925577]\n",
      "epoch:33 step:26181[D loss: 0.376250, acc: 62.50%, op_acc: 45.31%] [G loss: 0.969266]\n",
      "epoch:33 step:26182[D loss: 0.440044, acc: 50.78%, op_acc: 41.41%] [G loss: 0.929788]\n",
      "epoch:33 step:26183[D loss: 0.387201, acc: 64.84%, op_acc: 46.09%] [G loss: 0.922639]\n",
      "epoch:33 step:26184[D loss: 0.453424, acc: 52.34%, op_acc: 34.38%] [G loss: 0.918657]\n",
      "epoch:33 step:26185[D loss: 0.395426, acc: 60.16%, op_acc: 50.78%] [G loss: 0.890456]\n",
      "epoch:33 step:26186[D loss: 0.427280, acc: 56.25%, op_acc: 42.97%] [G loss: 0.863802]\n",
      "epoch:33 step:26187[D loss: 0.414924, acc: 59.38%, op_acc: 42.97%] [G loss: 0.884966]\n",
      "epoch:33 step:26188[D loss: 0.415702, acc: 64.06%, op_acc: 46.09%] [G loss: 0.909675]\n",
      "epoch:33 step:26189[D loss: 0.420259, acc: 57.81%, op_acc: 43.75%] [G loss: 0.883989]\n",
      "epoch:33 step:26190[D loss: 0.426693, acc: 58.59%, op_acc: 41.41%] [G loss: 0.844187]\n",
      "epoch:33 step:26191[D loss: 0.417182, acc: 60.16%, op_acc: 43.75%] [G loss: 0.859098]\n",
      "epoch:33 step:26192[D loss: 0.402496, acc: 64.84%, op_acc: 42.97%] [G loss: 0.924892]\n",
      "epoch:33 step:26193[D loss: 0.410468, acc: 61.72%, op_acc: 44.53%] [G loss: 0.882337]\n",
      "epoch:33 step:26194[D loss: 0.413558, acc: 67.19%, op_acc: 39.06%] [G loss: 0.884925]\n",
      "epoch:33 step:26195[D loss: 0.394356, acc: 67.19%, op_acc: 43.75%] [G loss: 0.942033]\n",
      "epoch:33 step:26196[D loss: 0.466513, acc: 52.34%, op_acc: 38.28%] [G loss: 0.890456]\n",
      "epoch:33 step:26197[D loss: 0.427831, acc: 53.91%, op_acc: 44.53%] [G loss: 0.885239]\n",
      "epoch:33 step:26198[D loss: 0.471272, acc: 50.78%, op_acc: 38.28%] [G loss: 0.877567]\n",
      "epoch:33 step:26199[D loss: 0.409411, acc: 62.50%, op_acc: 44.53%] [G loss: 0.885641]\n",
      "epoch:33 step:26200[D loss: 0.447094, acc: 54.69%, op_acc: 30.47%] [G loss: 0.913452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.83155946 0.86412519 0.80608546 0.80726981 0.80464687 0.81236968\n",
      " 0.88250791 0.81564443 0.80625651 0.84502222]\n",
      "##########\n",
      "epoch:33 step:26201[D loss: 0.439000, acc: 45.31%, op_acc: 44.53%] [G loss: 0.901878]\n",
      "epoch:33 step:26202[D loss: 0.435938, acc: 53.91%, op_acc: 38.28%] [G loss: 0.818341]\n",
      "epoch:33 step:26203[D loss: 0.423869, acc: 61.72%, op_acc: 39.06%] [G loss: 0.869719]\n",
      "epoch:33 step:26204[D loss: 0.414093, acc: 60.94%, op_acc: 37.50%] [G loss: 0.917463]\n",
      "epoch:33 step:26205[D loss: 0.393056, acc: 67.19%, op_acc: 46.09%] [G loss: 0.859718]\n",
      "epoch:33 step:26206[D loss: 0.423747, acc: 57.81%, op_acc: 40.62%] [G loss: 0.858285]\n",
      "epoch:33 step:26207[D loss: 0.381583, acc: 64.06%, op_acc: 43.75%] [G loss: 0.879984]\n",
      "epoch:33 step:26208[D loss: 0.420535, acc: 56.25%, op_acc: 42.19%] [G loss: 0.886715]\n",
      "epoch:33 step:26209[D loss: 0.422736, acc: 58.59%, op_acc: 45.31%] [G loss: 0.846145]\n",
      "epoch:33 step:26210[D loss: 0.417182, acc: 64.06%, op_acc: 44.53%] [G loss: 0.933546]\n",
      "epoch:33 step:26211[D loss: 0.426087, acc: 60.16%, op_acc: 37.50%] [G loss: 0.865825]\n",
      "epoch:33 step:26212[D loss: 0.415909, acc: 61.72%, op_acc: 41.41%] [G loss: 0.829623]\n",
      "epoch:33 step:26213[D loss: 0.390019, acc: 68.75%, op_acc: 39.06%] [G loss: 0.823269]\n",
      "epoch:33 step:26214[D loss: 0.410713, acc: 58.59%, op_acc: 39.84%] [G loss: 0.915675]\n",
      "epoch:33 step:26215[D loss: 0.431235, acc: 53.12%, op_acc: 38.28%] [G loss: 0.860020]\n",
      "epoch:33 step:26216[D loss: 0.416176, acc: 57.81%, op_acc: 42.19%] [G loss: 0.838509]\n",
      "epoch:33 step:26217[D loss: 0.401284, acc: 65.62%, op_acc: 42.19%] [G loss: 0.892668]\n",
      "epoch:33 step:26218[D loss: 0.417136, acc: 64.06%, op_acc: 35.16%] [G loss: 0.877378]\n",
      "epoch:33 step:26219[D loss: 0.435624, acc: 57.03%, op_acc: 38.28%] [G loss: 0.887393]\n",
      "epoch:33 step:26220[D loss: 0.421432, acc: 64.06%, op_acc: 37.50%] [G loss: 0.909703]\n",
      "epoch:33 step:26221[D loss: 0.392328, acc: 71.09%, op_acc: 41.41%] [G loss: 0.905830]\n",
      "epoch:33 step:26222[D loss: 0.422588, acc: 61.72%, op_acc: 37.50%] [G loss: 0.838149]\n",
      "epoch:33 step:26223[D loss: 0.426088, acc: 59.38%, op_acc: 45.31%] [G loss: 0.948320]\n",
      "epoch:33 step:26224[D loss: 0.400617, acc: 59.38%, op_acc: 43.75%] [G loss: 0.810478]\n",
      "epoch:33 step:26225[D loss: 0.403331, acc: 62.50%, op_acc: 43.75%] [G loss: 0.881475]\n",
      "epoch:33 step:26226[D loss: 0.394256, acc: 60.16%, op_acc: 41.41%] [G loss: 0.856555]\n",
      "epoch:33 step:26227[D loss: 0.437959, acc: 60.16%, op_acc: 38.28%] [G loss: 0.856373]\n",
      "epoch:33 step:26228[D loss: 0.416480, acc: 58.59%, op_acc: 41.41%] [G loss: 0.818029]\n",
      "epoch:33 step:26229[D loss: 0.426714, acc: 62.50%, op_acc: 42.19%] [G loss: 0.931779]\n",
      "epoch:33 step:26230[D loss: 0.401831, acc: 68.75%, op_acc: 39.84%] [G loss: 0.966253]\n",
      "epoch:33 step:26231[D loss: 0.409967, acc: 57.81%, op_acc: 45.31%] [G loss: 0.919623]\n",
      "epoch:33 step:26232[D loss: 0.403869, acc: 59.38%, op_acc: 46.09%] [G loss: 0.888188]\n",
      "epoch:33 step:26233[D loss: 0.393271, acc: 58.59%, op_acc: 46.09%] [G loss: 0.884658]\n",
      "epoch:33 step:26234[D loss: 0.441710, acc: 60.16%, op_acc: 39.84%] [G loss: 0.911167]\n",
      "epoch:33 step:26235[D loss: 0.393775, acc: 57.81%, op_acc: 44.53%] [G loss: 0.886584]\n",
      "epoch:33 step:26236[D loss: 0.449683, acc: 57.81%, op_acc: 43.75%] [G loss: 0.910391]\n",
      "epoch:33 step:26237[D loss: 0.416534, acc: 54.69%, op_acc: 35.94%] [G loss: 0.952910]\n",
      "epoch:33 step:26238[D loss: 0.413945, acc: 71.88%, op_acc: 39.06%] [G loss: 0.872845]\n",
      "epoch:33 step:26239[D loss: 0.370174, acc: 67.97%, op_acc: 40.62%] [G loss: 0.838250]\n",
      "epoch:33 step:26240[D loss: 0.410014, acc: 64.06%, op_acc: 35.16%] [G loss: 0.828092]\n",
      "epoch:33 step:26241[D loss: 0.393471, acc: 66.41%, op_acc: 47.66%] [G loss: 0.855097]\n",
      "epoch:33 step:26242[D loss: 0.416821, acc: 62.50%, op_acc: 39.06%] [G loss: 0.770560]\n",
      "epoch:33 step:26243[D loss: 0.403344, acc: 67.19%, op_acc: 37.50%] [G loss: 0.890734]\n",
      "epoch:33 step:26244[D loss: 0.403044, acc: 66.41%, op_acc: 36.72%] [G loss: 0.860968]\n",
      "epoch:33 step:26245[D loss: 0.408742, acc: 65.62%, op_acc: 38.28%] [G loss: 0.922633]\n",
      "epoch:33 step:26246[D loss: 0.420886, acc: 54.69%, op_acc: 40.62%] [G loss: 0.913636]\n",
      "epoch:33 step:26247[D loss: 0.416730, acc: 63.28%, op_acc: 33.59%] [G loss: 0.871007]\n",
      "epoch:33 step:26248[D loss: 0.437846, acc: 53.12%, op_acc: 41.41%] [G loss: 0.800881]\n",
      "epoch:33 step:26249[D loss: 0.452003, acc: 47.66%, op_acc: 39.06%] [G loss: 0.854468]\n",
      "epoch:33 step:26250[D loss: 0.421011, acc: 59.38%, op_acc: 44.53%] [G loss: 0.901190]\n",
      "##############\n",
      "[0.8579804  0.86306764 0.80620889 0.8136437  0.79261902 0.81661186\n",
      " 0.89155485 0.81438219 0.79683118 0.83202119]\n",
      "##########\n",
      "epoch:33 step:26251[D loss: 0.433161, acc: 53.12%, op_acc: 40.62%] [G loss: 0.885677]\n",
      "epoch:33 step:26252[D loss: 0.425071, acc: 59.38%, op_acc: 39.84%] [G loss: 0.874977]\n",
      "epoch:33 step:26253[D loss: 0.459323, acc: 53.91%, op_acc: 29.69%] [G loss: 0.886983]\n",
      "epoch:33 step:26254[D loss: 0.451270, acc: 53.12%, op_acc: 41.41%] [G loss: 0.829747]\n",
      "epoch:33 step:26255[D loss: 0.434197, acc: 60.16%, op_acc: 42.19%] [G loss: 0.877101]\n",
      "epoch:33 step:26256[D loss: 0.400868, acc: 60.94%, op_acc: 40.62%] [G loss: 0.857905]\n",
      "epoch:33 step:26257[D loss: 0.400529, acc: 55.47%, op_acc: 46.09%] [G loss: 0.935947]\n",
      "epoch:33 step:26258[D loss: 0.422470, acc: 58.59%, op_acc: 35.94%] [G loss: 0.868038]\n",
      "epoch:33 step:26259[D loss: 0.408851, acc: 65.62%, op_acc: 41.41%] [G loss: 0.916439]\n",
      "epoch:33 step:26260[D loss: 0.433241, acc: 52.34%, op_acc: 43.75%] [G loss: 0.883104]\n",
      "epoch:33 step:26261[D loss: 0.406717, acc: 64.84%, op_acc: 39.84%] [G loss: 0.815666]\n",
      "epoch:33 step:26262[D loss: 0.429035, acc: 53.12%, op_acc: 41.41%] [G loss: 0.802371]\n",
      "epoch:33 step:26263[D loss: 0.400896, acc: 59.38%, op_acc: 44.53%] [G loss: 0.860578]\n",
      "epoch:33 step:26264[D loss: 0.462017, acc: 53.91%, op_acc: 38.28%] [G loss: 0.888983]\n",
      "epoch:33 step:26265[D loss: 0.388315, acc: 62.50%, op_acc: 46.09%] [G loss: 0.887790]\n",
      "epoch:33 step:26266[D loss: 0.412335, acc: 54.69%, op_acc: 37.50%] [G loss: 0.887447]\n",
      "epoch:33 step:26267[D loss: 0.400351, acc: 67.19%, op_acc: 40.62%] [G loss: 0.864787]\n",
      "epoch:33 step:26268[D loss: 0.411072, acc: 64.06%, op_acc: 39.06%] [G loss: 0.925853]\n",
      "epoch:33 step:26269[D loss: 0.398360, acc: 61.72%, op_acc: 41.41%] [G loss: 0.802676]\n",
      "epoch:33 step:26270[D loss: 0.406014, acc: 61.72%, op_acc: 42.97%] [G loss: 0.908728]\n",
      "epoch:33 step:26271[D loss: 0.447572, acc: 51.56%, op_acc: 41.41%] [G loss: 0.805403]\n",
      "epoch:33 step:26272[D loss: 0.419156, acc: 64.06%, op_acc: 36.72%] [G loss: 0.907010]\n",
      "epoch:33 step:26273[D loss: 0.440431, acc: 53.91%, op_acc: 39.06%] [G loss: 0.845275]\n",
      "epoch:33 step:26274[D loss: 0.420401, acc: 60.16%, op_acc: 39.84%] [G loss: 0.864076]\n",
      "epoch:33 step:26275[D loss: 0.416835, acc: 56.25%, op_acc: 43.75%] [G loss: 0.841268]\n",
      "epoch:33 step:26276[D loss: 0.411116, acc: 58.59%, op_acc: 37.50%] [G loss: 0.841268]\n",
      "epoch:33 step:26277[D loss: 0.420447, acc: 60.16%, op_acc: 40.62%] [G loss: 0.886340]\n",
      "epoch:33 step:26278[D loss: 0.416697, acc: 58.59%, op_acc: 40.62%] [G loss: 0.879581]\n",
      "epoch:33 step:26279[D loss: 0.422495, acc: 60.94%, op_acc: 42.19%] [G loss: 0.798932]\n",
      "epoch:33 step:26280[D loss: 0.398604, acc: 61.72%, op_acc: 45.31%] [G loss: 0.874610]\n",
      "epoch:33 step:26281[D loss: 0.420720, acc: 63.28%, op_acc: 35.16%] [G loss: 0.908128]\n",
      "epoch:33 step:26282[D loss: 0.451759, acc: 50.00%, op_acc: 40.62%] [G loss: 0.869315]\n",
      "epoch:33 step:26283[D loss: 0.432324, acc: 57.03%, op_acc: 41.41%] [G loss: 0.851542]\n",
      "epoch:33 step:26284[D loss: 0.419958, acc: 57.03%, op_acc: 42.19%] [G loss: 0.929182]\n",
      "epoch:33 step:26285[D loss: 0.413072, acc: 60.16%, op_acc: 41.41%] [G loss: 0.918134]\n",
      "epoch:33 step:26286[D loss: 0.439033, acc: 59.38%, op_acc: 37.50%] [G loss: 0.827082]\n",
      "epoch:33 step:26287[D loss: 0.443762, acc: 53.91%, op_acc: 40.62%] [G loss: 0.872767]\n",
      "epoch:33 step:26288[D loss: 0.434939, acc: 56.25%, op_acc: 39.06%] [G loss: 0.913164]\n",
      "epoch:33 step:26289[D loss: 0.403257, acc: 58.59%, op_acc: 42.97%] [G loss: 0.854951]\n",
      "epoch:33 step:26290[D loss: 0.405628, acc: 64.06%, op_acc: 37.50%] [G loss: 0.880950]\n",
      "epoch:33 step:26291[D loss: 0.405937, acc: 54.69%, op_acc: 41.41%] [G loss: 0.867584]\n",
      "epoch:33 step:26292[D loss: 0.422962, acc: 61.72%, op_acc: 39.06%] [G loss: 0.782897]\n",
      "epoch:33 step:26293[D loss: 0.427812, acc: 53.12%, op_acc: 38.28%] [G loss: 0.870531]\n",
      "epoch:33 step:26294[D loss: 0.417492, acc: 64.06%, op_acc: 36.72%] [G loss: 0.929367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26295[D loss: 0.431467, acc: 53.12%, op_acc: 41.41%] [G loss: 0.912575]\n",
      "epoch:33 step:26296[D loss: 0.398946, acc: 59.38%, op_acc: 41.41%] [G loss: 0.920931]\n",
      "epoch:33 step:26297[D loss: 0.401504, acc: 67.19%, op_acc: 45.31%] [G loss: 0.913943]\n",
      "epoch:33 step:26298[D loss: 0.406488, acc: 63.28%, op_acc: 38.28%] [G loss: 0.896141]\n",
      "epoch:33 step:26299[D loss: 0.430372, acc: 57.81%, op_acc: 35.94%] [G loss: 0.862003]\n",
      "epoch:33 step:26300[D loss: 0.431578, acc: 54.69%, op_acc: 39.84%] [G loss: 0.891721]\n",
      "##############\n",
      "[0.85223898 0.87461394 0.81003646 0.81405278 0.77422413 0.83387631\n",
      " 0.87916343 0.82043767 0.80296426 0.82317335]\n",
      "##########\n",
      "epoch:33 step:26301[D loss: 0.387585, acc: 66.41%, op_acc: 41.41%] [G loss: 0.952751]\n",
      "epoch:33 step:26302[D loss: 0.413332, acc: 63.28%, op_acc: 39.06%] [G loss: 0.855151]\n",
      "epoch:33 step:26303[D loss: 0.433948, acc: 55.47%, op_acc: 34.38%] [G loss: 0.856193]\n",
      "epoch:33 step:26304[D loss: 0.452238, acc: 53.91%, op_acc: 39.84%] [G loss: 0.848689]\n",
      "epoch:33 step:26305[D loss: 0.430237, acc: 59.38%, op_acc: 38.28%] [G loss: 0.874651]\n",
      "epoch:33 step:26306[D loss: 0.409397, acc: 56.25%, op_acc: 45.31%] [G loss: 0.963732]\n",
      "epoch:33 step:26307[D loss: 0.394982, acc: 57.81%, op_acc: 47.66%] [G loss: 0.917750]\n",
      "epoch:33 step:26308[D loss: 0.431883, acc: 59.38%, op_acc: 41.41%] [G loss: 0.997875]\n",
      "epoch:33 step:26309[D loss: 0.403087, acc: 57.81%, op_acc: 44.53%] [G loss: 0.922832]\n",
      "epoch:33 step:26310[D loss: 0.456536, acc: 59.38%, op_acc: 34.38%] [G loss: 0.847901]\n",
      "epoch:33 step:26311[D loss: 0.426878, acc: 61.72%, op_acc: 36.72%] [G loss: 0.882535]\n",
      "epoch:33 step:26312[D loss: 0.445852, acc: 57.81%, op_acc: 35.94%] [G loss: 0.910726]\n",
      "epoch:33 step:26313[D loss: 0.396819, acc: 60.94%, op_acc: 42.97%] [G loss: 0.873558]\n",
      "epoch:33 step:26314[D loss: 0.406202, acc: 60.16%, op_acc: 42.97%] [G loss: 0.867915]\n",
      "epoch:33 step:26315[D loss: 0.443337, acc: 51.56%, op_acc: 38.28%] [G loss: 0.813035]\n",
      "epoch:33 step:26316[D loss: 0.416212, acc: 63.28%, op_acc: 43.75%] [G loss: 0.921996]\n",
      "epoch:33 step:26317[D loss: 0.431964, acc: 60.94%, op_acc: 37.50%] [G loss: 0.826778]\n",
      "epoch:33 step:26318[D loss: 0.419464, acc: 63.28%, op_acc: 41.41%] [G loss: 0.896320]\n",
      "epoch:33 step:26319[D loss: 0.393193, acc: 64.06%, op_acc: 39.84%] [G loss: 0.902069]\n",
      "epoch:33 step:26320[D loss: 0.478262, acc: 42.97%, op_acc: 33.59%] [G loss: 0.888937]\n",
      "epoch:33 step:26321[D loss: 0.432805, acc: 61.72%, op_acc: 39.84%] [G loss: 0.859290]\n",
      "epoch:33 step:26322[D loss: 0.411990, acc: 66.41%, op_acc: 43.75%] [G loss: 0.948747]\n",
      "epoch:33 step:26323[D loss: 0.396940, acc: 64.06%, op_acc: 48.44%] [G loss: 0.920741]\n",
      "epoch:33 step:26324[D loss: 0.415139, acc: 60.16%, op_acc: 39.06%] [G loss: 0.936877]\n",
      "epoch:33 step:26325[D loss: 0.428168, acc: 60.94%, op_acc: 36.72%] [G loss: 0.834543]\n",
      "epoch:33 step:26326[D loss: 0.401708, acc: 68.75%, op_acc: 41.41%] [G loss: 0.931882]\n",
      "epoch:33 step:26327[D loss: 0.407031, acc: 61.72%, op_acc: 41.41%] [G loss: 0.946679]\n",
      "epoch:33 step:26328[D loss: 0.431656, acc: 54.69%, op_acc: 39.84%] [G loss: 0.815075]\n",
      "epoch:33 step:26329[D loss: 0.405069, acc: 62.50%, op_acc: 39.06%] [G loss: 0.927620]\n",
      "epoch:33 step:26330[D loss: 0.426474, acc: 54.69%, op_acc: 40.62%] [G loss: 0.941500]\n",
      "epoch:33 step:26331[D loss: 0.383800, acc: 60.16%, op_acc: 46.09%] [G loss: 0.871074]\n",
      "epoch:33 step:26332[D loss: 0.427086, acc: 57.81%, op_acc: 34.38%] [G loss: 0.884325]\n",
      "epoch:33 step:26333[D loss: 0.459025, acc: 56.25%, op_acc: 35.16%] [G loss: 0.800085]\n",
      "epoch:33 step:26334[D loss: 0.434022, acc: 53.91%, op_acc: 36.72%] [G loss: 0.880374]\n",
      "epoch:33 step:26335[D loss: 0.436615, acc: 61.72%, op_acc: 35.94%] [G loss: 0.940138]\n",
      "epoch:33 step:26336[D loss: 0.418906, acc: 66.41%, op_acc: 40.62%] [G loss: 0.953150]\n",
      "epoch:33 step:26337[D loss: 0.411512, acc: 53.91%, op_acc: 43.75%] [G loss: 0.928443]\n",
      "epoch:33 step:26338[D loss: 0.420716, acc: 57.03%, op_acc: 44.53%] [G loss: 0.960431]\n",
      "epoch:33 step:26339[D loss: 0.425314, acc: 60.16%, op_acc: 39.84%] [G loss: 0.964318]\n",
      "epoch:33 step:26340[D loss: 0.414850, acc: 57.03%, op_acc: 46.88%] [G loss: 0.884830]\n",
      "epoch:33 step:26341[D loss: 0.409212, acc: 60.16%, op_acc: 43.75%] [G loss: 0.909260]\n",
      "epoch:33 step:26342[D loss: 0.420479, acc: 51.56%, op_acc: 42.19%] [G loss: 0.841798]\n",
      "epoch:33 step:26343[D loss: 0.400249, acc: 62.50%, op_acc: 41.41%] [G loss: 0.881610]\n",
      "epoch:33 step:26344[D loss: 0.400360, acc: 61.72%, op_acc: 44.53%] [G loss: 0.855195]\n",
      "epoch:33 step:26345[D loss: 0.407551, acc: 66.41%, op_acc: 35.16%] [G loss: 0.841726]\n",
      "epoch:33 step:26346[D loss: 0.439264, acc: 61.72%, op_acc: 39.84%] [G loss: 0.875702]\n",
      "epoch:33 step:26347[D loss: 0.444483, acc: 54.69%, op_acc: 37.50%] [G loss: 0.887163]\n",
      "epoch:33 step:26348[D loss: 0.423047, acc: 53.12%, op_acc: 40.62%] [G loss: 0.886795]\n",
      "epoch:33 step:26349[D loss: 0.414202, acc: 57.81%, op_acc: 45.31%] [G loss: 0.829794]\n",
      "epoch:33 step:26350[D loss: 0.412595, acc: 60.16%, op_acc: 39.06%] [G loss: 0.894716]\n",
      "##############\n",
      "[0.85825881 0.86228033 0.81102435 0.81992976 0.79038311 0.81496058\n",
      " 0.87511379 0.82583388 0.79714249 0.8366104 ]\n",
      "##########\n",
      "epoch:33 step:26351[D loss: 0.435611, acc: 58.59%, op_acc: 34.38%] [G loss: 0.874280]\n",
      "epoch:33 step:26352[D loss: 0.414793, acc: 65.62%, op_acc: 42.97%] [G loss: 0.861288]\n",
      "epoch:33 step:26353[D loss: 0.426846, acc: 58.59%, op_acc: 35.94%] [G loss: 0.874659]\n",
      "epoch:33 step:26354[D loss: 0.426328, acc: 60.16%, op_acc: 39.06%] [G loss: 0.919944]\n",
      "epoch:33 step:26355[D loss: 0.430933, acc: 53.91%, op_acc: 39.06%] [G loss: 0.796155]\n",
      "epoch:33 step:26356[D loss: 0.400877, acc: 60.94%, op_acc: 43.75%] [G loss: 0.904571]\n",
      "epoch:33 step:26357[D loss: 0.454624, acc: 57.81%, op_acc: 31.25%] [G loss: 0.907528]\n",
      "epoch:33 step:26358[D loss: 0.381743, acc: 70.31%, op_acc: 44.53%] [G loss: 0.941260]\n",
      "epoch:33 step:26359[D loss: 0.427108, acc: 60.94%, op_acc: 42.19%] [G loss: 0.802702]\n",
      "epoch:33 step:26360[D loss: 0.413138, acc: 61.72%, op_acc: 39.84%] [G loss: 0.791027]\n",
      "epoch:33 step:26361[D loss: 0.412588, acc: 60.94%, op_acc: 38.28%] [G loss: 0.832339]\n",
      "epoch:33 step:26362[D loss: 0.407851, acc: 62.50%, op_acc: 35.94%] [G loss: 0.931757]\n",
      "epoch:33 step:26363[D loss: 0.402844, acc: 64.06%, op_acc: 45.31%] [G loss: 0.884122]\n",
      "epoch:33 step:26364[D loss: 0.434628, acc: 53.91%, op_acc: 40.62%] [G loss: 0.902009]\n",
      "epoch:33 step:26365[D loss: 0.429371, acc: 57.81%, op_acc: 35.94%] [G loss: 0.824648]\n",
      "epoch:33 step:26366[D loss: 0.442274, acc: 60.94%, op_acc: 37.50%] [G loss: 0.875228]\n",
      "epoch:33 step:26367[D loss: 0.399048, acc: 60.16%, op_acc: 39.84%] [G loss: 0.922406]\n",
      "epoch:33 step:26368[D loss: 0.404863, acc: 62.50%, op_acc: 39.84%] [G loss: 0.984730]\n",
      "epoch:33 step:26369[D loss: 0.430426, acc: 59.38%, op_acc: 38.28%] [G loss: 0.943875]\n",
      "epoch:33 step:26370[D loss: 0.386175, acc: 68.75%, op_acc: 42.97%] [G loss: 0.916597]\n",
      "epoch:33 step:26371[D loss: 0.415862, acc: 57.81%, op_acc: 46.09%] [G loss: 0.834914]\n",
      "epoch:33 step:26372[D loss: 0.449141, acc: 50.00%, op_acc: 40.62%] [G loss: 0.928185]\n",
      "epoch:33 step:26373[D loss: 0.438920, acc: 55.47%, op_acc: 41.41%] [G loss: 0.839056]\n",
      "epoch:33 step:26374[D loss: 0.420100, acc: 60.16%, op_acc: 42.19%] [G loss: 0.900712]\n",
      "epoch:33 step:26375[D loss: 0.423381, acc: 53.12%, op_acc: 41.41%] [G loss: 0.773387]\n",
      "epoch:33 step:26376[D loss: 0.429983, acc: 48.44%, op_acc: 42.19%] [G loss: 0.881099]\n",
      "epoch:33 step:26377[D loss: 0.442026, acc: 55.47%, op_acc: 32.81%] [G loss: 0.920742]\n",
      "epoch:33 step:26378[D loss: 0.415987, acc: 53.12%, op_acc: 43.75%] [G loss: 0.826061]\n",
      "epoch:33 step:26379[D loss: 0.425610, acc: 56.25%, op_acc: 44.53%] [G loss: 0.896482]\n",
      "epoch:33 step:26380[D loss: 0.419773, acc: 60.94%, op_acc: 40.62%] [G loss: 0.896485]\n",
      "epoch:33 step:26381[D loss: 0.416982, acc: 57.81%, op_acc: 45.31%] [G loss: 0.851884]\n",
      "epoch:33 step:26382[D loss: 0.411972, acc: 64.06%, op_acc: 39.06%] [G loss: 0.839766]\n",
      "epoch:33 step:26383[D loss: 0.419520, acc: 62.50%, op_acc: 38.28%] [G loss: 0.837544]\n",
      "epoch:33 step:26384[D loss: 0.434750, acc: 60.94%, op_acc: 39.84%] [G loss: 0.848639]\n",
      "epoch:33 step:26385[D loss: 0.421335, acc: 60.16%, op_acc: 39.06%] [G loss: 0.870361]\n",
      "epoch:33 step:26386[D loss: 0.444933, acc: 50.00%, op_acc: 43.75%] [G loss: 0.848150]\n",
      "epoch:33 step:26387[D loss: 0.423843, acc: 55.47%, op_acc: 41.41%] [G loss: 0.905936]\n",
      "epoch:33 step:26388[D loss: 0.444766, acc: 56.25%, op_acc: 36.72%] [G loss: 0.879289]\n",
      "epoch:33 step:26389[D loss: 0.423418, acc: 60.16%, op_acc: 42.97%] [G loss: 0.832284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26390[D loss: 0.427488, acc: 61.72%, op_acc: 39.84%] [G loss: 0.849386]\n",
      "epoch:33 step:26391[D loss: 0.404902, acc: 60.16%, op_acc: 41.41%] [G loss: 0.845794]\n",
      "epoch:33 step:26392[D loss: 0.449103, acc: 57.03%, op_acc: 40.62%] [G loss: 0.891605]\n",
      "epoch:33 step:26393[D loss: 0.428319, acc: 64.84%, op_acc: 38.28%] [G loss: 0.983581]\n",
      "epoch:33 step:26394[D loss: 0.404694, acc: 67.19%, op_acc: 38.28%] [G loss: 0.909018]\n",
      "epoch:33 step:26395[D loss: 0.431553, acc: 60.94%, op_acc: 37.50%] [G loss: 0.917547]\n",
      "epoch:33 step:26396[D loss: 0.396042, acc: 64.84%, op_acc: 43.75%] [G loss: 0.858136]\n",
      "epoch:33 step:26397[D loss: 0.393105, acc: 61.72%, op_acc: 44.53%] [G loss: 0.858755]\n",
      "epoch:33 step:26398[D loss: 0.408739, acc: 61.72%, op_acc: 42.19%] [G loss: 0.889658]\n",
      "epoch:33 step:26399[D loss: 0.414052, acc: 59.38%, op_acc: 39.06%] [G loss: 0.938826]\n",
      "epoch:33 step:26400[D loss: 0.408459, acc: 57.81%, op_acc: 43.75%] [G loss: 0.835566]\n",
      "##############\n",
      "[0.83734627 0.85663354 0.82665435 0.79094144 0.79718328 0.82288223\n",
      " 0.8767035  0.83878918 0.79560843 0.8134683 ]\n",
      "##########\n",
      "epoch:33 step:26401[D loss: 0.412371, acc: 60.94%, op_acc: 35.94%] [G loss: 0.847725]\n",
      "epoch:33 step:26402[D loss: 0.433557, acc: 60.16%, op_acc: 39.84%] [G loss: 0.904470]\n",
      "epoch:33 step:26403[D loss: 0.417997, acc: 59.38%, op_acc: 42.19%] [G loss: 0.899505]\n",
      "epoch:33 step:26404[D loss: 0.453475, acc: 54.69%, op_acc: 41.41%] [G loss: 0.805164]\n",
      "epoch:33 step:26405[D loss: 0.404956, acc: 61.72%, op_acc: 41.41%] [G loss: 0.917610]\n",
      "epoch:33 step:26406[D loss: 0.411192, acc: 62.50%, op_acc: 38.28%] [G loss: 0.868396]\n",
      "epoch:33 step:26407[D loss: 0.413389, acc: 61.72%, op_acc: 42.97%] [G loss: 0.865226]\n",
      "epoch:33 step:26408[D loss: 0.406110, acc: 60.16%, op_acc: 42.19%] [G loss: 0.820394]\n",
      "epoch:33 step:26409[D loss: 0.399003, acc: 61.72%, op_acc: 44.53%] [G loss: 0.820352]\n",
      "epoch:33 step:26410[D loss: 0.410310, acc: 61.72%, op_acc: 41.41%] [G loss: 0.829612]\n",
      "epoch:33 step:26411[D loss: 0.419220, acc: 59.38%, op_acc: 38.28%] [G loss: 0.943690]\n",
      "epoch:33 step:26412[D loss: 0.437524, acc: 57.81%, op_acc: 40.62%] [G loss: 0.975929]\n",
      "epoch:33 step:26413[D loss: 0.426119, acc: 58.59%, op_acc: 37.50%] [G loss: 0.885589]\n",
      "epoch:33 step:26414[D loss: 0.405313, acc: 63.28%, op_acc: 35.94%] [G loss: 0.888709]\n",
      "epoch:33 step:26415[D loss: 0.423035, acc: 57.03%, op_acc: 42.19%] [G loss: 0.874934]\n",
      "epoch:33 step:26416[D loss: 0.433131, acc: 66.41%, op_acc: 35.16%] [G loss: 0.873598]\n",
      "epoch:33 step:26417[D loss: 0.402151, acc: 63.28%, op_acc: 44.53%] [G loss: 0.914137]\n",
      "epoch:33 step:26418[D loss: 0.394732, acc: 67.19%, op_acc: 39.84%] [G loss: 0.938034]\n",
      "epoch:33 step:26419[D loss: 0.416211, acc: 67.97%, op_acc: 42.97%] [G loss: 0.885291]\n",
      "epoch:33 step:26420[D loss: 0.408650, acc: 55.47%, op_acc: 42.97%] [G loss: 0.930136]\n",
      "epoch:33 step:26421[D loss: 0.414016, acc: 63.28%, op_acc: 39.06%] [G loss: 0.899342]\n",
      "epoch:33 step:26422[D loss: 0.419289, acc: 60.16%, op_acc: 42.19%] [G loss: 0.862910]\n",
      "epoch:33 step:26423[D loss: 0.428585, acc: 56.25%, op_acc: 41.41%] [G loss: 0.871377]\n",
      "epoch:33 step:26424[D loss: 0.395994, acc: 64.06%, op_acc: 39.84%] [G loss: 0.913759]\n",
      "epoch:33 step:26425[D loss: 0.407088, acc: 64.84%, op_acc: 39.06%] [G loss: 0.878052]\n",
      "epoch:33 step:26426[D loss: 0.413679, acc: 55.47%, op_acc: 42.19%] [G loss: 0.898489]\n",
      "epoch:33 step:26427[D loss: 0.428122, acc: 57.81%, op_acc: 36.72%] [G loss: 0.904662]\n",
      "epoch:33 step:26428[D loss: 0.433731, acc: 51.56%, op_acc: 38.28%] [G loss: 0.872639]\n",
      "epoch:33 step:26429[D loss: 0.421198, acc: 62.50%, op_acc: 41.41%] [G loss: 0.921228]\n",
      "epoch:33 step:26430[D loss: 0.424464, acc: 53.91%, op_acc: 41.41%] [G loss: 0.956604]\n",
      "epoch:33 step:26431[D loss: 0.410825, acc: 62.50%, op_acc: 39.84%] [G loss: 0.844867]\n",
      "epoch:33 step:26432[D loss: 0.403467, acc: 64.06%, op_acc: 38.28%] [G loss: 0.991148]\n",
      "epoch:33 step:26433[D loss: 0.418393, acc: 59.38%, op_acc: 41.41%] [G loss: 0.848725]\n",
      "epoch:33 step:26434[D loss: 0.411107, acc: 55.47%, op_acc: 42.97%] [G loss: 0.798788]\n",
      "epoch:33 step:26435[D loss: 0.394687, acc: 61.72%, op_acc: 42.19%] [G loss: 0.856773]\n",
      "epoch:33 step:26436[D loss: 0.422327, acc: 57.81%, op_acc: 42.19%] [G loss: 0.900067]\n",
      "epoch:33 step:26437[D loss: 0.394560, acc: 64.06%, op_acc: 43.75%] [G loss: 0.851941]\n",
      "epoch:33 step:26438[D loss: 0.429082, acc: 63.28%, op_acc: 35.94%] [G loss: 0.876766]\n",
      "epoch:33 step:26439[D loss: 0.428583, acc: 53.12%, op_acc: 39.84%] [G loss: 0.916715]\n",
      "epoch:33 step:26440[D loss: 0.397488, acc: 61.72%, op_acc: 38.28%] [G loss: 0.862277]\n",
      "epoch:33 step:26441[D loss: 0.425211, acc: 67.19%, op_acc: 39.84%] [G loss: 0.907511]\n",
      "epoch:33 step:26442[D loss: 0.416583, acc: 59.38%, op_acc: 41.41%] [G loss: 0.850063]\n",
      "epoch:33 step:26443[D loss: 0.418502, acc: 55.47%, op_acc: 41.41%] [G loss: 0.890089]\n",
      "epoch:33 step:26444[D loss: 0.414954, acc: 57.03%, op_acc: 39.06%] [G loss: 0.880593]\n",
      "epoch:33 step:26445[D loss: 0.448222, acc: 62.50%, op_acc: 34.38%] [G loss: 0.808175]\n",
      "epoch:33 step:26446[D loss: 0.458096, acc: 53.91%, op_acc: 36.72%] [G loss: 0.916942]\n",
      "epoch:33 step:26447[D loss: 0.429914, acc: 55.47%, op_acc: 43.75%] [G loss: 0.818262]\n",
      "epoch:33 step:26448[D loss: 0.413402, acc: 59.38%, op_acc: 38.28%] [G loss: 0.777801]\n",
      "epoch:33 step:26449[D loss: 0.468999, acc: 44.53%, op_acc: 39.84%] [G loss: 0.826409]\n",
      "epoch:33 step:26450[D loss: 0.435490, acc: 62.50%, op_acc: 36.72%] [G loss: 0.830138]\n",
      "##############\n",
      "[0.84235256 0.87277245 0.79881873 0.80961795 0.76263434 0.81386491\n",
      " 0.90556045 0.82053385 0.80981726 0.80607701]\n",
      "##########\n",
      "epoch:33 step:26451[D loss: 0.403136, acc: 61.72%, op_acc: 41.41%] [G loss: 0.825077]\n",
      "epoch:33 step:26452[D loss: 0.400526, acc: 59.38%, op_acc: 44.53%] [G loss: 0.883052]\n",
      "epoch:33 step:26453[D loss: 0.432618, acc: 58.59%, op_acc: 35.94%] [G loss: 0.886870]\n",
      "epoch:33 step:26454[D loss: 0.421836, acc: 62.50%, op_acc: 33.59%] [G loss: 0.828414]\n",
      "epoch:33 step:26455[D loss: 0.400644, acc: 59.38%, op_acc: 42.97%] [G loss: 0.874725]\n",
      "epoch:33 step:26456[D loss: 0.412573, acc: 55.47%, op_acc: 39.06%] [G loss: 0.944337]\n",
      "epoch:33 step:26457[D loss: 0.445045, acc: 57.81%, op_acc: 39.84%] [G loss: 0.854274]\n",
      "epoch:33 step:26458[D loss: 0.443870, acc: 60.16%, op_acc: 38.28%] [G loss: 0.841503]\n",
      "epoch:33 step:26459[D loss: 0.443134, acc: 50.78%, op_acc: 40.62%] [G loss: 0.841581]\n",
      "epoch:33 step:26460[D loss: 0.411837, acc: 62.50%, op_acc: 38.28%] [G loss: 0.946004]\n",
      "epoch:33 step:26461[D loss: 0.414891, acc: 63.28%, op_acc: 44.53%] [G loss: 0.886108]\n",
      "epoch:33 step:26462[D loss: 0.393713, acc: 62.50%, op_acc: 46.09%] [G loss: 0.925962]\n",
      "epoch:33 step:26463[D loss: 0.421955, acc: 67.97%, op_acc: 39.06%] [G loss: 0.890996]\n",
      "epoch:33 step:26464[D loss: 0.433721, acc: 62.50%, op_acc: 39.84%] [G loss: 0.905638]\n",
      "epoch:33 step:26465[D loss: 0.448195, acc: 52.34%, op_acc: 41.41%] [G loss: 0.869092]\n",
      "epoch:33 step:26466[D loss: 0.414749, acc: 60.16%, op_acc: 41.41%] [G loss: 0.885470]\n",
      "epoch:33 step:26467[D loss: 0.435006, acc: 55.47%, op_acc: 37.50%] [G loss: 0.844179]\n",
      "epoch:33 step:26468[D loss: 0.419573, acc: 61.72%, op_acc: 41.41%] [G loss: 0.890457]\n",
      "epoch:33 step:26469[D loss: 0.427489, acc: 57.03%, op_acc: 38.28%] [G loss: 0.941784]\n",
      "epoch:33 step:26470[D loss: 0.415156, acc: 57.81%, op_acc: 41.41%] [G loss: 0.887131]\n",
      "epoch:33 step:26471[D loss: 0.391702, acc: 71.88%, op_acc: 40.62%] [G loss: 0.917052]\n",
      "epoch:33 step:26472[D loss: 0.450978, acc: 52.34%, op_acc: 39.84%] [G loss: 0.906165]\n",
      "epoch:33 step:26473[D loss: 0.433408, acc: 60.94%, op_acc: 37.50%] [G loss: 0.892625]\n",
      "epoch:33 step:26474[D loss: 0.441848, acc: 56.25%, op_acc: 42.97%] [G loss: 0.893745]\n",
      "epoch:33 step:26475[D loss: 0.436353, acc: 51.56%, op_acc: 42.97%] [G loss: 0.902509]\n",
      "epoch:33 step:26476[D loss: 0.426394, acc: 59.38%, op_acc: 37.50%] [G loss: 0.909960]\n",
      "epoch:33 step:26477[D loss: 0.399652, acc: 63.28%, op_acc: 46.88%] [G loss: 0.894339]\n",
      "epoch:33 step:26478[D loss: 0.434349, acc: 60.94%, op_acc: 36.72%] [G loss: 0.930097]\n",
      "epoch:33 step:26479[D loss: 0.443446, acc: 50.78%, op_acc: 42.97%] [G loss: 0.907660]\n",
      "epoch:33 step:26480[D loss: 0.419550, acc: 57.81%, op_acc: 41.41%] [G loss: 0.881790]\n",
      "epoch:33 step:26481[D loss: 0.405893, acc: 57.03%, op_acc: 40.62%] [G loss: 0.800450]\n",
      "epoch:33 step:26482[D loss: 0.435628, acc: 49.22%, op_acc: 41.41%] [G loss: 0.826515]\n",
      "epoch:33 step:26483[D loss: 0.408262, acc: 57.81%, op_acc: 46.88%] [G loss: 0.824986]\n",
      "epoch:33 step:26484[D loss: 0.443796, acc: 53.12%, op_acc: 35.16%] [G loss: 0.828119]\n",
      "epoch:33 step:26485[D loss: 0.396377, acc: 67.19%, op_acc: 43.75%] [G loss: 0.821766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26486[D loss: 0.393290, acc: 64.84%, op_acc: 46.09%] [G loss: 0.863402]\n",
      "epoch:33 step:26487[D loss: 0.411164, acc: 63.28%, op_acc: 40.62%] [G loss: 0.841449]\n",
      "epoch:33 step:26488[D loss: 0.396854, acc: 63.28%, op_acc: 39.84%] [G loss: 0.921769]\n",
      "epoch:33 step:26489[D loss: 0.417573, acc: 60.16%, op_acc: 43.75%] [G loss: 0.924493]\n",
      "epoch:33 step:26490[D loss: 0.411518, acc: 57.03%, op_acc: 43.75%] [G loss: 0.871868]\n",
      "epoch:33 step:26491[D loss: 0.435962, acc: 58.59%, op_acc: 38.28%] [G loss: 0.946137]\n",
      "epoch:33 step:26492[D loss: 0.414034, acc: 65.62%, op_acc: 44.53%] [G loss: 0.922963]\n",
      "epoch:33 step:26493[D loss: 0.429889, acc: 56.25%, op_acc: 39.84%] [G loss: 0.831680]\n",
      "epoch:33 step:26494[D loss: 0.423406, acc: 57.81%, op_acc: 40.62%] [G loss: 0.875737]\n",
      "epoch:33 step:26495[D loss: 0.428203, acc: 60.16%, op_acc: 39.84%] [G loss: 0.809926]\n",
      "epoch:33 step:26496[D loss: 0.415742, acc: 64.84%, op_acc: 45.31%] [G loss: 0.857952]\n",
      "epoch:33 step:26497[D loss: 0.454879, acc: 52.34%, op_acc: 39.84%] [G loss: 0.862205]\n",
      "epoch:33 step:26498[D loss: 0.403337, acc: 64.84%, op_acc: 39.06%] [G loss: 0.949085]\n",
      "epoch:33 step:26499[D loss: 0.414661, acc: 60.16%, op_acc: 43.75%] [G loss: 0.852609]\n",
      "epoch:33 step:26500[D loss: 0.434352, acc: 57.81%, op_acc: 41.41%] [G loss: 0.836093]\n",
      "##############\n",
      "[0.87155996 0.83534776 0.81896528 0.80426761 0.80334759 0.82634299\n",
      " 0.90146387 0.82049332 0.80187806 0.81661349]\n",
      "##########\n",
      "epoch:33 step:26501[D loss: 0.397197, acc: 67.97%, op_acc: 39.84%] [G loss: 0.840986]\n",
      "epoch:33 step:26502[D loss: 0.435677, acc: 60.94%, op_acc: 40.62%] [G loss: 0.757774]\n",
      "epoch:33 step:26503[D loss: 0.451564, acc: 53.12%, op_acc: 41.41%] [G loss: 0.860530]\n",
      "epoch:33 step:26504[D loss: 0.425244, acc: 55.47%, op_acc: 40.62%] [G loss: 0.904042]\n",
      "epoch:33 step:26505[D loss: 0.386223, acc: 66.41%, op_acc: 40.62%] [G loss: 0.903112]\n",
      "epoch:33 step:26506[D loss: 0.398553, acc: 63.28%, op_acc: 35.94%] [G loss: 0.802550]\n",
      "epoch:33 step:26507[D loss: 0.394659, acc: 66.41%, op_acc: 48.44%] [G loss: 0.977318]\n",
      "epoch:33 step:26508[D loss: 0.429848, acc: 55.47%, op_acc: 39.06%] [G loss: 0.869771]\n",
      "epoch:33 step:26509[D loss: 0.437794, acc: 57.81%, op_acc: 41.41%] [G loss: 0.877549]\n",
      "epoch:33 step:26510[D loss: 0.440875, acc: 53.12%, op_acc: 43.75%] [G loss: 0.897353]\n",
      "epoch:33 step:26511[D loss: 0.450457, acc: 56.25%, op_acc: 41.41%] [G loss: 0.867078]\n",
      "epoch:33 step:26512[D loss: 0.405164, acc: 62.50%, op_acc: 42.97%] [G loss: 0.825499]\n",
      "epoch:33 step:26513[D loss: 0.422979, acc: 57.81%, op_acc: 41.41%] [G loss: 0.854958]\n",
      "epoch:33 step:26514[D loss: 0.411763, acc: 65.62%, op_acc: 39.06%] [G loss: 0.949705]\n",
      "epoch:33 step:26515[D loss: 0.438379, acc: 56.25%, op_acc: 38.28%] [G loss: 0.852080]\n",
      "epoch:33 step:26516[D loss: 0.413782, acc: 64.84%, op_acc: 36.72%] [G loss: 0.857908]\n",
      "epoch:33 step:26517[D loss: 0.403883, acc: 58.59%, op_acc: 46.88%] [G loss: 0.853118]\n",
      "epoch:33 step:26518[D loss: 0.413965, acc: 54.69%, op_acc: 41.41%] [G loss: 0.887541]\n",
      "epoch:33 step:26519[D loss: 0.401598, acc: 65.62%, op_acc: 39.06%] [G loss: 0.934448]\n",
      "epoch:33 step:26520[D loss: 0.447394, acc: 53.91%, op_acc: 35.94%] [G loss: 0.890345]\n",
      "epoch:33 step:26521[D loss: 0.417505, acc: 60.94%, op_acc: 36.72%] [G loss: 0.874150]\n",
      "epoch:33 step:26522[D loss: 0.431259, acc: 62.50%, op_acc: 41.41%] [G loss: 0.925577]\n",
      "epoch:33 step:26523[D loss: 0.424387, acc: 57.03%, op_acc: 43.75%] [G loss: 0.796466]\n",
      "epoch:33 step:26524[D loss: 0.453762, acc: 57.81%, op_acc: 35.94%] [G loss: 0.829361]\n",
      "epoch:33 step:26525[D loss: 0.419620, acc: 58.59%, op_acc: 41.41%] [G loss: 0.877579]\n",
      "epoch:33 step:26526[D loss: 0.413340, acc: 59.38%, op_acc: 37.50%] [G loss: 0.839502]\n",
      "epoch:33 step:26527[D loss: 0.423457, acc: 59.38%, op_acc: 40.62%] [G loss: 0.850016]\n",
      "epoch:33 step:26528[D loss: 0.438430, acc: 62.50%, op_acc: 40.62%] [G loss: 0.876740]\n",
      "epoch:33 step:26529[D loss: 0.406134, acc: 57.81%, op_acc: 46.09%] [G loss: 0.842458]\n",
      "epoch:33 step:26530[D loss: 0.403569, acc: 65.62%, op_acc: 41.41%] [G loss: 0.917733]\n",
      "epoch:33 step:26531[D loss: 0.398871, acc: 63.28%, op_acc: 42.19%] [G loss: 0.839286]\n",
      "epoch:33 step:26532[D loss: 0.412826, acc: 63.28%, op_acc: 44.53%] [G loss: 0.859360]\n",
      "epoch:33 step:26533[D loss: 0.428939, acc: 57.03%, op_acc: 36.72%] [G loss: 0.847746]\n",
      "epoch:33 step:26534[D loss: 0.401530, acc: 63.28%, op_acc: 39.06%] [G loss: 0.916593]\n",
      "epoch:33 step:26535[D loss: 0.436457, acc: 53.91%, op_acc: 42.19%] [G loss: 0.834442]\n",
      "epoch:33 step:26536[D loss: 0.442949, acc: 50.78%, op_acc: 39.84%] [G loss: 0.812306]\n",
      "epoch:33 step:26537[D loss: 0.411210, acc: 61.72%, op_acc: 41.41%] [G loss: 0.819457]\n",
      "epoch:33 step:26538[D loss: 0.391671, acc: 62.50%, op_acc: 42.97%] [G loss: 0.889861]\n",
      "epoch:33 step:26539[D loss: 0.431470, acc: 57.03%, op_acc: 36.72%] [G loss: 0.876913]\n",
      "epoch:33 step:26540[D loss: 0.411765, acc: 57.03%, op_acc: 42.19%] [G loss: 0.884668]\n",
      "epoch:33 step:26541[D loss: 0.422408, acc: 58.59%, op_acc: 38.28%] [G loss: 0.885833]\n",
      "epoch:33 step:26542[D loss: 0.386879, acc: 60.94%, op_acc: 43.75%] [G loss: 0.872282]\n",
      "epoch:33 step:26543[D loss: 0.425394, acc: 60.94%, op_acc: 40.62%] [G loss: 0.907577]\n",
      "epoch:33 step:26544[D loss: 0.467015, acc: 48.44%, op_acc: 35.16%] [G loss: 0.883381]\n",
      "epoch:33 step:26545[D loss: 0.446092, acc: 57.81%, op_acc: 40.62%] [G loss: 0.881665]\n",
      "epoch:33 step:26546[D loss: 0.415808, acc: 66.41%, op_acc: 41.41%] [G loss: 0.873829]\n",
      "epoch:33 step:26547[D loss: 0.406972, acc: 59.38%, op_acc: 38.28%] [G loss: 0.870322]\n",
      "epoch:33 step:26548[D loss: 0.446178, acc: 51.56%, op_acc: 39.84%] [G loss: 0.829275]\n",
      "epoch:33 step:26549[D loss: 0.405586, acc: 63.28%, op_acc: 40.62%] [G loss: 0.954363]\n",
      "epoch:33 step:26550[D loss: 0.459211, acc: 53.91%, op_acc: 37.50%] [G loss: 0.918679]\n",
      "##############\n",
      "[0.86029378 0.8635628  0.81525948 0.81153622 0.78954911 0.82221238\n",
      " 0.89700013 0.81538699 0.82713221 0.82426582]\n",
      "##########\n",
      "epoch:33 step:26551[D loss: 0.408552, acc: 63.28%, op_acc: 47.66%] [G loss: 0.870334]\n",
      "epoch:33 step:26552[D loss: 0.419073, acc: 64.06%, op_acc: 35.94%] [G loss: 0.894011]\n",
      "epoch:33 step:26553[D loss: 0.419277, acc: 62.50%, op_acc: 39.84%] [G loss: 0.883916]\n",
      "epoch:33 step:26554[D loss: 0.408860, acc: 60.16%, op_acc: 36.72%] [G loss: 0.888748]\n",
      "epoch:34 step:26555[D loss: 0.388716, acc: 67.19%, op_acc: 47.66%] [G loss: 0.988668]\n",
      "epoch:34 step:26556[D loss: 0.394159, acc: 64.84%, op_acc: 42.97%] [G loss: 0.898106]\n",
      "epoch:34 step:26557[D loss: 0.433786, acc: 55.47%, op_acc: 35.94%] [G loss: 0.865754]\n",
      "epoch:34 step:26558[D loss: 0.426610, acc: 59.38%, op_acc: 46.09%] [G loss: 0.920138]\n",
      "epoch:34 step:26559[D loss: 0.419896, acc: 55.47%, op_acc: 42.97%] [G loss: 0.834346]\n",
      "epoch:34 step:26560[D loss: 0.448038, acc: 62.50%, op_acc: 40.62%] [G loss: 0.905635]\n",
      "epoch:34 step:26561[D loss: 0.437462, acc: 53.12%, op_acc: 42.19%] [G loss: 0.855674]\n",
      "epoch:34 step:26562[D loss: 0.437669, acc: 54.69%, op_acc: 38.28%] [G loss: 0.846882]\n",
      "epoch:34 step:26563[D loss: 0.452729, acc: 51.56%, op_acc: 39.06%] [G loss: 0.932052]\n",
      "epoch:34 step:26564[D loss: 0.431843, acc: 56.25%, op_acc: 42.19%] [G loss: 0.822733]\n",
      "epoch:34 step:26565[D loss: 0.422261, acc: 60.94%, op_acc: 41.41%] [G loss: 0.805585]\n",
      "epoch:34 step:26566[D loss: 0.417121, acc: 61.72%, op_acc: 34.38%] [G loss: 0.869938]\n",
      "epoch:34 step:26567[D loss: 0.422337, acc: 57.81%, op_acc: 39.84%] [G loss: 0.857935]\n",
      "epoch:34 step:26568[D loss: 0.454058, acc: 60.16%, op_acc: 35.94%] [G loss: 0.910224]\n",
      "epoch:34 step:26569[D loss: 0.384683, acc: 70.31%, op_acc: 47.66%] [G loss: 0.875548]\n",
      "epoch:34 step:26570[D loss: 0.415891, acc: 53.91%, op_acc: 41.41%] [G loss: 0.908201]\n",
      "epoch:34 step:26571[D loss: 0.404852, acc: 62.50%, op_acc: 41.41%] [G loss: 0.790259]\n",
      "epoch:34 step:26572[D loss: 0.422890, acc: 55.47%, op_acc: 39.84%] [G loss: 0.868518]\n",
      "epoch:34 step:26573[D loss: 0.453707, acc: 58.59%, op_acc: 39.06%] [G loss: 0.973880]\n",
      "epoch:34 step:26574[D loss: 0.416970, acc: 53.91%, op_acc: 44.53%] [G loss: 0.922793]\n",
      "epoch:34 step:26575[D loss: 0.428839, acc: 60.16%, op_acc: 35.94%] [G loss: 0.805258]\n",
      "epoch:34 step:26576[D loss: 0.410848, acc: 60.16%, op_acc: 39.06%] [G loss: 0.886881]\n",
      "epoch:34 step:26577[D loss: 0.421483, acc: 62.50%, op_acc: 39.84%] [G loss: 0.926516]\n",
      "epoch:34 step:26578[D loss: 0.440329, acc: 58.59%, op_acc: 36.72%] [G loss: 0.924531]\n",
      "epoch:34 step:26579[D loss: 0.422334, acc: 59.38%, op_acc: 44.53%] [G loss: 0.908970]\n",
      "epoch:34 step:26580[D loss: 0.411072, acc: 63.28%, op_acc: 44.53%] [G loss: 0.889729]\n",
      "epoch:34 step:26581[D loss: 0.440969, acc: 53.12%, op_acc: 41.41%] [G loss: 0.790871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26582[D loss: 0.411297, acc: 65.62%, op_acc: 42.97%] [G loss: 0.812993]\n",
      "epoch:34 step:26583[D loss: 0.401892, acc: 53.12%, op_acc: 42.19%] [G loss: 0.869456]\n",
      "epoch:34 step:26584[D loss: 0.406541, acc: 58.59%, op_acc: 41.41%] [G loss: 0.816682]\n",
      "epoch:34 step:26585[D loss: 0.429258, acc: 60.94%, op_acc: 36.72%] [G loss: 0.861400]\n",
      "epoch:34 step:26586[D loss: 0.431915, acc: 54.69%, op_acc: 45.31%] [G loss: 0.871043]\n",
      "epoch:34 step:26587[D loss: 0.433522, acc: 54.69%, op_acc: 43.75%] [G loss: 0.823722]\n",
      "epoch:34 step:26588[D loss: 0.402748, acc: 61.72%, op_acc: 47.66%] [G loss: 0.851543]\n",
      "epoch:34 step:26589[D loss: 0.439425, acc: 54.69%, op_acc: 39.84%] [G loss: 0.869314]\n",
      "epoch:34 step:26590[D loss: 0.404679, acc: 55.47%, op_acc: 40.62%] [G loss: 0.879305]\n",
      "epoch:34 step:26591[D loss: 0.418340, acc: 60.16%, op_acc: 36.72%] [G loss: 0.844647]\n",
      "epoch:34 step:26592[D loss: 0.422165, acc: 58.59%, op_acc: 38.28%] [G loss: 0.837068]\n",
      "epoch:34 step:26593[D loss: 0.388658, acc: 61.72%, op_acc: 42.97%] [G loss: 0.885528]\n",
      "epoch:34 step:26594[D loss: 0.403779, acc: 58.59%, op_acc: 41.41%] [G loss: 0.881573]\n",
      "epoch:34 step:26595[D loss: 0.412096, acc: 53.91%, op_acc: 46.09%] [G loss: 0.889898]\n",
      "epoch:34 step:26596[D loss: 0.380797, acc: 64.06%, op_acc: 46.88%] [G loss: 0.838734]\n",
      "epoch:34 step:26597[D loss: 0.440813, acc: 58.59%, op_acc: 36.72%] [G loss: 0.847563]\n",
      "epoch:34 step:26598[D loss: 0.434017, acc: 52.34%, op_acc: 39.06%] [G loss: 0.873935]\n",
      "epoch:34 step:26599[D loss: 0.429588, acc: 57.81%, op_acc: 37.50%] [G loss: 0.909125]\n",
      "epoch:34 step:26600[D loss: 0.408947, acc: 60.16%, op_acc: 40.62%] [G loss: 0.865824]\n",
      "##############\n",
      "[0.85683727 0.86193179 0.82134641 0.80010883 0.78194294 0.82499154\n",
      " 0.88021504 0.81846918 0.78903691 0.82908364]\n",
      "##########\n",
      "epoch:34 step:26601[D loss: 0.443181, acc: 55.47%, op_acc: 39.06%] [G loss: 0.921930]\n",
      "epoch:34 step:26602[D loss: 0.465529, acc: 57.03%, op_acc: 36.72%] [G loss: 0.885171]\n",
      "epoch:34 step:26603[D loss: 0.408337, acc: 64.06%, op_acc: 45.31%] [G loss: 0.883057]\n",
      "epoch:34 step:26604[D loss: 0.440128, acc: 55.47%, op_acc: 31.25%] [G loss: 0.865239]\n",
      "epoch:34 step:26605[D loss: 0.394854, acc: 65.62%, op_acc: 39.06%] [G loss: 0.866191]\n",
      "epoch:34 step:26606[D loss: 0.407373, acc: 65.62%, op_acc: 39.84%] [G loss: 0.918036]\n",
      "epoch:34 step:26607[D loss: 0.448870, acc: 63.28%, op_acc: 39.06%] [G loss: 0.932451]\n",
      "epoch:34 step:26608[D loss: 0.428327, acc: 60.16%, op_acc: 38.28%] [G loss: 0.954546]\n",
      "epoch:34 step:26609[D loss: 0.412310, acc: 57.03%, op_acc: 43.75%] [G loss: 0.907403]\n",
      "epoch:34 step:26610[D loss: 0.414400, acc: 63.28%, op_acc: 35.94%] [G loss: 0.957707]\n",
      "epoch:34 step:26611[D loss: 0.402795, acc: 60.94%, op_acc: 39.06%] [G loss: 0.925990]\n",
      "epoch:34 step:26612[D loss: 0.398861, acc: 61.72%, op_acc: 46.09%] [G loss: 0.871710]\n",
      "epoch:34 step:26613[D loss: 0.403909, acc: 59.38%, op_acc: 41.41%] [G loss: 0.877383]\n",
      "epoch:34 step:26614[D loss: 0.391721, acc: 63.28%, op_acc: 39.06%] [G loss: 0.908947]\n",
      "epoch:34 step:26615[D loss: 0.431874, acc: 51.56%, op_acc: 35.16%] [G loss: 0.825727]\n",
      "epoch:34 step:26616[D loss: 0.452945, acc: 50.78%, op_acc: 42.19%] [G loss: 0.864469]\n",
      "epoch:34 step:26617[D loss: 0.442057, acc: 51.56%, op_acc: 36.72%] [G loss: 0.903730]\n",
      "epoch:34 step:26618[D loss: 0.399527, acc: 67.97%, op_acc: 39.84%] [G loss: 0.873768]\n",
      "epoch:34 step:26619[D loss: 0.435430, acc: 56.25%, op_acc: 41.41%] [G loss: 0.887685]\n",
      "epoch:34 step:26620[D loss: 0.392237, acc: 68.75%, op_acc: 39.84%] [G loss: 0.850728]\n",
      "epoch:34 step:26621[D loss: 0.406260, acc: 65.62%, op_acc: 42.97%] [G loss: 0.923183]\n",
      "epoch:34 step:26622[D loss: 0.438987, acc: 60.16%, op_acc: 41.41%] [G loss: 0.830490]\n",
      "epoch:34 step:26623[D loss: 0.408587, acc: 59.38%, op_acc: 50.00%] [G loss: 0.931442]\n",
      "epoch:34 step:26624[D loss: 0.411552, acc: 59.38%, op_acc: 45.31%] [G loss: 0.867118]\n",
      "epoch:34 step:26625[D loss: 0.440414, acc: 57.81%, op_acc: 36.72%] [G loss: 0.885231]\n",
      "epoch:34 step:26626[D loss: 0.398121, acc: 63.28%, op_acc: 43.75%] [G loss: 0.834553]\n",
      "epoch:34 step:26627[D loss: 0.416063, acc: 57.81%, op_acc: 45.31%] [G loss: 0.906985]\n",
      "epoch:34 step:26628[D loss: 0.402347, acc: 54.69%, op_acc: 44.53%] [G loss: 0.876104]\n",
      "epoch:34 step:26629[D loss: 0.418332, acc: 59.38%, op_acc: 37.50%] [G loss: 0.854976]\n",
      "epoch:34 step:26630[D loss: 0.446258, acc: 55.47%, op_acc: 40.62%] [G loss: 0.919172]\n",
      "epoch:34 step:26631[D loss: 0.419981, acc: 59.38%, op_acc: 38.28%] [G loss: 0.843455]\n",
      "epoch:34 step:26632[D loss: 0.459606, acc: 58.59%, op_acc: 31.25%] [G loss: 0.896691]\n",
      "epoch:34 step:26633[D loss: 0.407918, acc: 63.28%, op_acc: 42.19%] [G loss: 0.891649]\n",
      "epoch:34 step:26634[D loss: 0.437798, acc: 58.59%, op_acc: 32.03%] [G loss: 0.931230]\n",
      "epoch:34 step:26635[D loss: 0.430658, acc: 62.50%, op_acc: 38.28%] [G loss: 0.882078]\n",
      "epoch:34 step:26636[D loss: 0.425476, acc: 53.12%, op_acc: 43.75%] [G loss: 0.874761]\n",
      "epoch:34 step:26637[D loss: 0.420808, acc: 60.16%, op_acc: 38.28%] [G loss: 0.872412]\n",
      "epoch:34 step:26638[D loss: 0.412157, acc: 59.38%, op_acc: 42.97%] [G loss: 0.814726]\n",
      "epoch:34 step:26639[D loss: 0.426661, acc: 56.25%, op_acc: 42.19%] [G loss: 0.855990]\n",
      "epoch:34 step:26640[D loss: 0.410704, acc: 62.50%, op_acc: 37.50%] [G loss: 0.896712]\n",
      "epoch:34 step:26641[D loss: 0.424327, acc: 64.84%, op_acc: 40.62%] [G loss: 0.919618]\n",
      "epoch:34 step:26642[D loss: 0.415870, acc: 60.94%, op_acc: 39.06%] [G loss: 0.867773]\n",
      "epoch:34 step:26643[D loss: 0.428290, acc: 59.38%, op_acc: 39.84%] [G loss: 0.871181]\n",
      "epoch:34 step:26644[D loss: 0.420927, acc: 57.81%, op_acc: 41.41%] [G loss: 0.870321]\n",
      "epoch:34 step:26645[D loss: 0.423142, acc: 60.16%, op_acc: 37.50%] [G loss: 0.848342]\n",
      "epoch:34 step:26646[D loss: 0.424054, acc: 57.81%, op_acc: 42.97%] [G loss: 0.910092]\n",
      "epoch:34 step:26647[D loss: 0.382270, acc: 62.50%, op_acc: 42.97%] [G loss: 0.912852]\n",
      "epoch:34 step:26648[D loss: 0.427707, acc: 62.50%, op_acc: 37.50%] [G loss: 0.894626]\n",
      "epoch:34 step:26649[D loss: 0.423042, acc: 59.38%, op_acc: 39.84%] [G loss: 0.842699]\n",
      "epoch:34 step:26650[D loss: 0.436044, acc: 60.94%, op_acc: 39.84%] [G loss: 0.944395]\n",
      "##############\n",
      "[0.86683902 0.86346343 0.8144504  0.81841887 0.79010462 0.82077642\n",
      " 0.89250661 0.82528378 0.8040644  0.83318232]\n",
      "##########\n",
      "epoch:34 step:26651[D loss: 0.418949, acc: 56.25%, op_acc: 40.62%] [G loss: 0.871492]\n",
      "epoch:34 step:26652[D loss: 0.456238, acc: 56.25%, op_acc: 39.84%] [G loss: 0.943045]\n",
      "epoch:34 step:26653[D loss: 0.403111, acc: 60.94%, op_acc: 45.31%] [G loss: 0.948671]\n",
      "epoch:34 step:26654[D loss: 0.407106, acc: 57.03%, op_acc: 43.75%] [G loss: 0.947946]\n",
      "epoch:34 step:26655[D loss: 0.449277, acc: 53.91%, op_acc: 42.97%] [G loss: 0.908528]\n",
      "epoch:34 step:26656[D loss: 0.421599, acc: 61.72%, op_acc: 40.62%] [G loss: 0.788546]\n",
      "epoch:34 step:26657[D loss: 0.431835, acc: 53.12%, op_acc: 43.75%] [G loss: 0.864091]\n",
      "epoch:34 step:26658[D loss: 0.445949, acc: 53.12%, op_acc: 34.38%] [G loss: 0.937267]\n",
      "epoch:34 step:26659[D loss: 0.434073, acc: 58.59%, op_acc: 39.84%] [G loss: 0.862429]\n",
      "epoch:34 step:26660[D loss: 0.430786, acc: 56.25%, op_acc: 41.41%] [G loss: 0.838456]\n",
      "epoch:34 step:26661[D loss: 0.402611, acc: 62.50%, op_acc: 41.41%] [G loss: 0.929974]\n",
      "epoch:34 step:26662[D loss: 0.428793, acc: 59.38%, op_acc: 42.97%] [G loss: 0.947519]\n",
      "epoch:34 step:26663[D loss: 0.427713, acc: 56.25%, op_acc: 42.19%] [G loss: 0.919799]\n",
      "epoch:34 step:26664[D loss: 0.449925, acc: 50.00%, op_acc: 39.84%] [G loss: 0.884409]\n",
      "epoch:34 step:26665[D loss: 0.424320, acc: 64.84%, op_acc: 36.72%] [G loss: 0.948369]\n",
      "epoch:34 step:26666[D loss: 0.429706, acc: 59.38%, op_acc: 40.62%] [G loss: 0.909823]\n",
      "epoch:34 step:26667[D loss: 0.445518, acc: 53.12%, op_acc: 38.28%] [G loss: 0.956476]\n",
      "epoch:34 step:26668[D loss: 0.415509, acc: 61.72%, op_acc: 40.62%] [G loss: 0.862380]\n",
      "epoch:34 step:26669[D loss: 0.415166, acc: 50.78%, op_acc: 41.41%] [G loss: 0.902608]\n",
      "epoch:34 step:26670[D loss: 0.432543, acc: 55.47%, op_acc: 37.50%] [G loss: 0.903554]\n",
      "epoch:34 step:26671[D loss: 0.420420, acc: 60.16%, op_acc: 40.62%] [G loss: 0.883830]\n",
      "epoch:34 step:26672[D loss: 0.440038, acc: 64.06%, op_acc: 36.72%] [G loss: 0.833174]\n",
      "epoch:34 step:26673[D loss: 0.416354, acc: 67.19%, op_acc: 38.28%] [G loss: 0.931779]\n",
      "epoch:34 step:26674[D loss: 0.409647, acc: 65.62%, op_acc: 39.06%] [G loss: 0.910613]\n",
      "epoch:34 step:26675[D loss: 0.409512, acc: 65.62%, op_acc: 42.97%] [G loss: 0.866607]\n",
      "epoch:34 step:26676[D loss: 0.418554, acc: 57.81%, op_acc: 41.41%] [G loss: 0.879475]\n",
      "epoch:34 step:26677[D loss: 0.419027, acc: 61.72%, op_acc: 43.75%] [G loss: 0.914771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26678[D loss: 0.415454, acc: 64.84%, op_acc: 40.62%] [G loss: 0.822775]\n",
      "epoch:34 step:26679[D loss: 0.428400, acc: 60.16%, op_acc: 41.41%] [G loss: 0.898240]\n",
      "epoch:34 step:26680[D loss: 0.408404, acc: 63.28%, op_acc: 40.62%] [G loss: 0.965565]\n",
      "epoch:34 step:26681[D loss: 0.409065, acc: 65.62%, op_acc: 38.28%] [G loss: 0.864640]\n",
      "epoch:34 step:26682[D loss: 0.412927, acc: 63.28%, op_acc: 37.50%] [G loss: 0.820929]\n",
      "epoch:34 step:26683[D loss: 0.439364, acc: 54.69%, op_acc: 39.84%] [G loss: 0.808756]\n",
      "epoch:34 step:26684[D loss: 0.424440, acc: 55.47%, op_acc: 42.97%] [G loss: 0.887046]\n",
      "epoch:34 step:26685[D loss: 0.421232, acc: 58.59%, op_acc: 41.41%] [G loss: 0.936603]\n",
      "epoch:34 step:26686[D loss: 0.386704, acc: 60.16%, op_acc: 44.53%] [G loss: 0.891949]\n",
      "epoch:34 step:26687[D loss: 0.469796, acc: 46.88%, op_acc: 38.28%] [G loss: 0.829611]\n",
      "epoch:34 step:26688[D loss: 0.418875, acc: 57.81%, op_acc: 39.84%] [G loss: 0.860043]\n",
      "epoch:34 step:26689[D loss: 0.425126, acc: 57.81%, op_acc: 38.28%] [G loss: 0.826509]\n",
      "epoch:34 step:26690[D loss: 0.404823, acc: 61.72%, op_acc: 44.53%] [G loss: 0.937626]\n",
      "epoch:34 step:26691[D loss: 0.411756, acc: 63.28%, op_acc: 39.84%] [G loss: 0.844822]\n",
      "epoch:34 step:26692[D loss: 0.440130, acc: 53.91%, op_acc: 41.41%] [G loss: 0.873258]\n",
      "epoch:34 step:26693[D loss: 0.432486, acc: 57.03%, op_acc: 39.84%] [G loss: 0.848315]\n",
      "epoch:34 step:26694[D loss: 0.446537, acc: 50.78%, op_acc: 37.50%] [G loss: 0.815177]\n",
      "epoch:34 step:26695[D loss: 0.406794, acc: 64.84%, op_acc: 39.84%] [G loss: 0.853443]\n",
      "epoch:34 step:26696[D loss: 0.430893, acc: 63.28%, op_acc: 39.06%] [G loss: 0.902327]\n",
      "epoch:34 step:26697[D loss: 0.419491, acc: 64.84%, op_acc: 39.06%] [G loss: 0.964048]\n",
      "epoch:34 step:26698[D loss: 0.397701, acc: 64.84%, op_acc: 39.84%] [G loss: 0.841694]\n",
      "epoch:34 step:26699[D loss: 0.441648, acc: 50.78%, op_acc: 39.06%] [G loss: 0.916858]\n",
      "epoch:34 step:26700[D loss: 0.390127, acc: 65.62%, op_acc: 35.94%] [G loss: 0.879953]\n",
      "##############\n",
      "[0.85388795 0.87902639 0.8202706  0.79944799 0.76371249 0.82116253\n",
      " 0.87951594 0.81362532 0.79771477 0.81047439]\n",
      "##########\n",
      "epoch:34 step:26701[D loss: 0.396128, acc: 67.19%, op_acc: 43.75%] [G loss: 0.887630]\n",
      "epoch:34 step:26702[D loss: 0.437961, acc: 57.03%, op_acc: 39.06%] [G loss: 0.813599]\n",
      "epoch:34 step:26703[D loss: 0.379932, acc: 65.62%, op_acc: 42.97%] [G loss: 0.938141]\n",
      "epoch:34 step:26704[D loss: 0.387491, acc: 64.84%, op_acc: 42.19%] [G loss: 0.883956]\n",
      "epoch:34 step:26705[D loss: 0.397328, acc: 65.62%, op_acc: 44.53%] [G loss: 1.017506]\n",
      "epoch:34 step:26706[D loss: 0.391256, acc: 64.06%, op_acc: 41.41%] [G loss: 0.890451]\n",
      "epoch:34 step:26707[D loss: 0.452248, acc: 52.34%, op_acc: 34.38%] [G loss: 0.911361]\n",
      "epoch:34 step:26708[D loss: 0.445921, acc: 53.91%, op_acc: 40.62%] [G loss: 0.833377]\n",
      "epoch:34 step:26709[D loss: 0.412335, acc: 64.84%, op_acc: 36.72%] [G loss: 0.878808]\n",
      "epoch:34 step:26710[D loss: 0.428633, acc: 60.16%, op_acc: 45.31%] [G loss: 0.886566]\n",
      "epoch:34 step:26711[D loss: 0.422743, acc: 62.50%, op_acc: 40.62%] [G loss: 0.887067]\n",
      "epoch:34 step:26712[D loss: 0.393698, acc: 61.72%, op_acc: 44.53%] [G loss: 0.941067]\n",
      "epoch:34 step:26713[D loss: 0.430188, acc: 57.81%, op_acc: 34.38%] [G loss: 0.952366]\n",
      "epoch:34 step:26714[D loss: 0.421910, acc: 64.06%, op_acc: 36.72%] [G loss: 0.848909]\n",
      "epoch:34 step:26715[D loss: 0.418599, acc: 58.59%, op_acc: 42.97%] [G loss: 0.918112]\n",
      "epoch:34 step:26716[D loss: 0.397992, acc: 64.84%, op_acc: 42.97%] [G loss: 0.922653]\n",
      "epoch:34 step:26717[D loss: 0.419271, acc: 65.62%, op_acc: 38.28%] [G loss: 0.898015]\n",
      "epoch:34 step:26718[D loss: 0.399309, acc: 63.28%, op_acc: 37.50%] [G loss: 0.859216]\n",
      "epoch:34 step:26719[D loss: 0.424511, acc: 58.59%, op_acc: 36.72%] [G loss: 0.874445]\n",
      "epoch:34 step:26720[D loss: 0.449909, acc: 57.81%, op_acc: 35.94%] [G loss: 0.814512]\n",
      "epoch:34 step:26721[D loss: 0.406137, acc: 61.72%, op_acc: 42.19%] [G loss: 0.954690]\n",
      "epoch:34 step:26722[D loss: 0.401389, acc: 61.72%, op_acc: 40.62%] [G loss: 0.825194]\n",
      "epoch:34 step:26723[D loss: 0.397203, acc: 60.94%, op_acc: 43.75%] [G loss: 0.913561]\n",
      "epoch:34 step:26724[D loss: 0.431919, acc: 56.25%, op_acc: 43.75%] [G loss: 0.927167]\n",
      "epoch:34 step:26725[D loss: 0.389712, acc: 73.44%, op_acc: 37.50%] [G loss: 0.903760]\n",
      "epoch:34 step:26726[D loss: 0.390733, acc: 64.06%, op_acc: 42.19%] [G loss: 0.821008]\n",
      "epoch:34 step:26727[D loss: 0.398138, acc: 68.75%, op_acc: 39.06%] [G loss: 0.922027]\n",
      "epoch:34 step:26728[D loss: 0.457346, acc: 54.69%, op_acc: 39.06%] [G loss: 0.852304]\n",
      "epoch:34 step:26729[D loss: 0.394521, acc: 64.84%, op_acc: 44.53%] [G loss: 0.949013]\n",
      "epoch:34 step:26730[D loss: 0.410551, acc: 61.72%, op_acc: 45.31%] [G loss: 0.985830]\n",
      "epoch:34 step:26731[D loss: 0.412607, acc: 57.81%, op_acc: 38.28%] [G loss: 0.903069]\n",
      "epoch:34 step:26732[D loss: 0.431635, acc: 57.81%, op_acc: 36.72%] [G loss: 0.985210]\n",
      "epoch:34 step:26733[D loss: 0.380117, acc: 65.62%, op_acc: 43.75%] [G loss: 0.930500]\n",
      "epoch:34 step:26734[D loss: 0.429813, acc: 56.25%, op_acc: 37.50%] [G loss: 0.857143]\n",
      "epoch:34 step:26735[D loss: 0.377580, acc: 64.06%, op_acc: 45.31%] [G loss: 0.919467]\n",
      "epoch:34 step:26736[D loss: 0.421182, acc: 59.38%, op_acc: 42.19%] [G loss: 0.899920]\n",
      "epoch:34 step:26737[D loss: 0.398621, acc: 64.06%, op_acc: 40.62%] [G loss: 0.911272]\n",
      "epoch:34 step:26738[D loss: 0.440615, acc: 50.78%, op_acc: 40.62%] [G loss: 0.892540]\n",
      "epoch:34 step:26739[D loss: 0.420130, acc: 64.06%, op_acc: 39.84%] [G loss: 0.947676]\n",
      "epoch:34 step:26740[D loss: 0.449380, acc: 50.78%, op_acc: 39.06%] [G loss: 0.861807]\n",
      "epoch:34 step:26741[D loss: 0.420625, acc: 60.94%, op_acc: 42.97%] [G loss: 0.887325]\n",
      "epoch:34 step:26742[D loss: 0.413024, acc: 58.59%, op_acc: 39.06%] [G loss: 0.933714]\n",
      "epoch:34 step:26743[D loss: 0.375314, acc: 75.00%, op_acc: 41.41%] [G loss: 0.935259]\n",
      "epoch:34 step:26744[D loss: 0.427825, acc: 60.94%, op_acc: 41.41%] [G loss: 0.959021]\n",
      "epoch:34 step:26745[D loss: 0.387127, acc: 61.72%, op_acc: 48.44%] [G loss: 0.792613]\n",
      "epoch:34 step:26746[D loss: 0.369847, acc: 67.97%, op_acc: 42.97%] [G loss: 0.950018]\n",
      "epoch:34 step:26747[D loss: 0.475322, acc: 48.44%, op_acc: 35.94%] [G loss: 0.944176]\n",
      "epoch:34 step:26748[D loss: 0.406885, acc: 67.19%, op_acc: 42.97%] [G loss: 0.911820]\n",
      "epoch:34 step:26749[D loss: 0.441135, acc: 54.69%, op_acc: 32.03%] [G loss: 0.896760]\n",
      "epoch:34 step:26750[D loss: 0.411853, acc: 64.84%, op_acc: 35.94%] [G loss: 0.937615]\n",
      "##############\n",
      "[0.84629572 0.82582093 0.81111427 0.80044335 0.80403133 0.81308443\n",
      " 0.87882154 0.84145651 0.79251331 0.7882136 ]\n",
      "##########\n",
      "epoch:34 step:26751[D loss: 0.479932, acc: 46.88%, op_acc: 37.50%] [G loss: 0.791264]\n",
      "epoch:34 step:26752[D loss: 0.435173, acc: 52.34%, op_acc: 42.97%] [G loss: 0.843437]\n",
      "epoch:34 step:26753[D loss: 0.432596, acc: 52.34%, op_acc: 38.28%] [G loss: 0.778235]\n",
      "epoch:34 step:26754[D loss: 0.448224, acc: 56.25%, op_acc: 34.38%] [G loss: 0.912090]\n",
      "epoch:34 step:26755[D loss: 0.410291, acc: 62.50%, op_acc: 39.06%] [G loss: 0.953769]\n",
      "epoch:34 step:26756[D loss: 0.443368, acc: 55.47%, op_acc: 33.59%] [G loss: 0.905482]\n",
      "epoch:34 step:26757[D loss: 0.423746, acc: 62.50%, op_acc: 39.84%] [G loss: 0.914613]\n",
      "epoch:34 step:26758[D loss: 0.427610, acc: 60.94%, op_acc: 37.50%] [G loss: 0.866391]\n",
      "epoch:34 step:26759[D loss: 0.432277, acc: 59.38%, op_acc: 38.28%] [G loss: 0.852341]\n",
      "epoch:34 step:26760[D loss: 0.405657, acc: 64.06%, op_acc: 43.75%] [G loss: 0.996117]\n",
      "epoch:34 step:26761[D loss: 0.367799, acc: 71.88%, op_acc: 45.31%] [G loss: 0.909027]\n",
      "epoch:34 step:26762[D loss: 0.393608, acc: 67.19%, op_acc: 39.06%] [G loss: 0.996326]\n",
      "epoch:34 step:26763[D loss: 0.402837, acc: 57.03%, op_acc: 41.41%] [G loss: 0.894636]\n",
      "epoch:34 step:26764[D loss: 0.424915, acc: 68.75%, op_acc: 31.25%] [G loss: 0.881251]\n",
      "epoch:34 step:26765[D loss: 0.403792, acc: 65.62%, op_acc: 41.41%] [G loss: 0.944935]\n",
      "epoch:34 step:26766[D loss: 0.415434, acc: 61.72%, op_acc: 40.62%] [G loss: 0.837420]\n",
      "epoch:34 step:26767[D loss: 0.424533, acc: 58.59%, op_acc: 40.62%] [G loss: 0.859072]\n",
      "epoch:34 step:26768[D loss: 0.399314, acc: 66.41%, op_acc: 42.19%] [G loss: 0.939241]\n",
      "epoch:34 step:26769[D loss: 0.428047, acc: 60.94%, op_acc: 36.72%] [G loss: 0.862399]\n",
      "epoch:34 step:26770[D loss: 0.392755, acc: 64.06%, op_acc: 42.19%] [G loss: 0.937986]\n",
      "epoch:34 step:26771[D loss: 0.404357, acc: 64.06%, op_acc: 41.41%] [G loss: 0.940296]\n",
      "epoch:34 step:26772[D loss: 0.431154, acc: 60.94%, op_acc: 39.84%] [G loss: 0.915122]\n",
      "epoch:34 step:26773[D loss: 0.425061, acc: 57.03%, op_acc: 45.31%] [G loss: 0.904903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26774[D loss: 0.434556, acc: 60.16%, op_acc: 40.62%] [G loss: 0.862282]\n",
      "epoch:34 step:26775[D loss: 0.420064, acc: 60.94%, op_acc: 41.41%] [G loss: 0.878905]\n",
      "epoch:34 step:26776[D loss: 0.438650, acc: 55.47%, op_acc: 43.75%] [G loss: 1.022038]\n",
      "epoch:34 step:26777[D loss: 0.426733, acc: 55.47%, op_acc: 42.97%] [G loss: 0.841341]\n",
      "epoch:34 step:26778[D loss: 0.420029, acc: 61.72%, op_acc: 36.72%] [G loss: 0.872226]\n",
      "epoch:34 step:26779[D loss: 0.411823, acc: 61.72%, op_acc: 44.53%] [G loss: 0.879200]\n",
      "epoch:34 step:26780[D loss: 0.433383, acc: 61.72%, op_acc: 46.09%] [G loss: 0.873157]\n",
      "epoch:34 step:26781[D loss: 0.414347, acc: 57.03%, op_acc: 42.19%] [G loss: 0.892607]\n",
      "epoch:34 step:26782[D loss: 0.408595, acc: 59.38%, op_acc: 42.97%] [G loss: 0.837853]\n",
      "epoch:34 step:26783[D loss: 0.418008, acc: 55.47%, op_acc: 42.19%] [G loss: 0.908767]\n",
      "epoch:34 step:26784[D loss: 0.447066, acc: 54.69%, op_acc: 39.06%] [G loss: 0.814324]\n",
      "epoch:34 step:26785[D loss: 0.410203, acc: 59.38%, op_acc: 45.31%] [G loss: 0.895583]\n",
      "epoch:34 step:26786[D loss: 0.432080, acc: 63.28%, op_acc: 39.84%] [G loss: 0.866139]\n",
      "epoch:34 step:26787[D loss: 0.408183, acc: 59.38%, op_acc: 42.97%] [G loss: 0.836015]\n",
      "epoch:34 step:26788[D loss: 0.429114, acc: 59.38%, op_acc: 40.62%] [G loss: 0.961556]\n",
      "epoch:34 step:26789[D loss: 0.406065, acc: 56.25%, op_acc: 42.19%] [G loss: 0.841152]\n",
      "epoch:34 step:26790[D loss: 0.437590, acc: 62.50%, op_acc: 39.06%] [G loss: 0.864103]\n",
      "epoch:34 step:26791[D loss: 0.379105, acc: 67.19%, op_acc: 40.62%] [G loss: 0.929513]\n",
      "epoch:34 step:26792[D loss: 0.431230, acc: 60.94%, op_acc: 44.53%] [G loss: 0.928623]\n",
      "epoch:34 step:26793[D loss: 0.404461, acc: 64.06%, op_acc: 39.84%] [G loss: 0.917601]\n",
      "epoch:34 step:26794[D loss: 0.428672, acc: 61.72%, op_acc: 42.19%] [G loss: 0.766497]\n",
      "epoch:34 step:26795[D loss: 0.407422, acc: 57.81%, op_acc: 44.53%] [G loss: 0.886980]\n",
      "epoch:34 step:26796[D loss: 0.371123, acc: 67.19%, op_acc: 44.53%] [G loss: 0.841531]\n",
      "epoch:34 step:26797[D loss: 0.404407, acc: 62.50%, op_acc: 42.19%] [G loss: 0.882404]\n",
      "epoch:34 step:26798[D loss: 0.462510, acc: 46.88%, op_acc: 39.84%] [G loss: 0.815423]\n",
      "epoch:34 step:26799[D loss: 0.432773, acc: 57.81%, op_acc: 42.19%] [G loss: 0.871054]\n",
      "epoch:34 step:26800[D loss: 0.405502, acc: 64.06%, op_acc: 39.06%] [G loss: 0.827125]\n",
      "##############\n",
      "[0.86431354 0.86612658 0.81699616 0.79781237 0.79190444 0.84652047\n",
      " 0.86836762 0.82893696 0.81639786 0.8421719 ]\n",
      "##########\n",
      "epoch:34 step:26801[D loss: 0.437255, acc: 55.47%, op_acc: 41.41%] [G loss: 0.911103]\n",
      "epoch:34 step:26802[D loss: 0.444379, acc: 54.69%, op_acc: 36.72%] [G loss: 0.868183]\n",
      "epoch:34 step:26803[D loss: 0.413448, acc: 58.59%, op_acc: 42.97%] [G loss: 0.853674]\n",
      "epoch:34 step:26804[D loss: 0.460537, acc: 48.44%, op_acc: 32.03%] [G loss: 0.895950]\n",
      "epoch:34 step:26805[D loss: 0.378597, acc: 67.97%, op_acc: 42.19%] [G loss: 0.847353]\n",
      "epoch:34 step:26806[D loss: 0.427294, acc: 54.69%, op_acc: 42.97%] [G loss: 0.935523]\n",
      "epoch:34 step:26807[D loss: 0.368897, acc: 71.88%, op_acc: 42.97%] [G loss: 0.886177]\n",
      "epoch:34 step:26808[D loss: 0.405791, acc: 60.16%, op_acc: 44.53%] [G loss: 0.939621]\n",
      "epoch:34 step:26809[D loss: 0.422897, acc: 60.16%, op_acc: 39.84%] [G loss: 0.833573]\n",
      "epoch:34 step:26810[D loss: 0.413548, acc: 60.94%, op_acc: 39.06%] [G loss: 0.822202]\n",
      "epoch:34 step:26811[D loss: 0.415738, acc: 62.50%, op_acc: 39.06%] [G loss: 0.886373]\n",
      "epoch:34 step:26812[D loss: 0.423691, acc: 51.56%, op_acc: 42.19%] [G loss: 0.892004]\n",
      "epoch:34 step:26813[D loss: 0.421471, acc: 60.94%, op_acc: 33.59%] [G loss: 0.839614]\n",
      "epoch:34 step:26814[D loss: 0.435409, acc: 60.94%, op_acc: 36.72%] [G loss: 0.907360]\n",
      "epoch:34 step:26815[D loss: 0.409408, acc: 61.72%, op_acc: 40.62%] [G loss: 0.889357]\n",
      "epoch:34 step:26816[D loss: 0.411989, acc: 60.94%, op_acc: 40.62%] [G loss: 0.919526]\n",
      "epoch:34 step:26817[D loss: 0.418439, acc: 60.94%, op_acc: 38.28%] [G loss: 0.939623]\n",
      "epoch:34 step:26818[D loss: 0.413384, acc: 55.47%, op_acc: 42.19%] [G loss: 0.799497]\n",
      "epoch:34 step:26819[D loss: 0.404171, acc: 61.72%, op_acc: 39.84%] [G loss: 0.953885]\n",
      "epoch:34 step:26820[D loss: 0.413854, acc: 60.16%, op_acc: 44.53%] [G loss: 0.893382]\n",
      "epoch:34 step:26821[D loss: 0.459460, acc: 53.12%, op_acc: 38.28%] [G loss: 0.962412]\n",
      "epoch:34 step:26822[D loss: 0.407241, acc: 57.03%, op_acc: 43.75%] [G loss: 0.850394]\n",
      "epoch:34 step:26823[D loss: 0.416116, acc: 58.59%, op_acc: 39.84%] [G loss: 0.898762]\n",
      "epoch:34 step:26824[D loss: 0.386156, acc: 69.53%, op_acc: 35.94%] [G loss: 0.901345]\n",
      "epoch:34 step:26825[D loss: 0.419172, acc: 60.94%, op_acc: 38.28%] [G loss: 0.958630]\n",
      "epoch:34 step:26826[D loss: 0.391780, acc: 64.84%, op_acc: 39.06%] [G loss: 0.941847]\n",
      "epoch:34 step:26827[D loss: 0.392512, acc: 65.62%, op_acc: 42.97%] [G loss: 0.917478]\n",
      "epoch:34 step:26828[D loss: 0.407351, acc: 59.38%, op_acc: 35.94%] [G loss: 0.944093]\n",
      "epoch:34 step:26829[D loss: 0.408257, acc: 63.28%, op_acc: 40.62%] [G loss: 0.854487]\n",
      "epoch:34 step:26830[D loss: 0.416018, acc: 64.84%, op_acc: 42.19%] [G loss: 0.886328]\n",
      "epoch:34 step:26831[D loss: 0.420663, acc: 59.38%, op_acc: 35.16%] [G loss: 0.906554]\n",
      "epoch:34 step:26832[D loss: 0.444179, acc: 56.25%, op_acc: 35.16%] [G loss: 0.873728]\n",
      "epoch:34 step:26833[D loss: 0.418876, acc: 60.16%, op_acc: 39.84%] [G loss: 0.869589]\n",
      "epoch:34 step:26834[D loss: 0.441537, acc: 53.12%, op_acc: 47.66%] [G loss: 0.920948]\n",
      "epoch:34 step:26835[D loss: 0.389743, acc: 67.19%, op_acc: 41.41%] [G loss: 0.877816]\n",
      "epoch:34 step:26836[D loss: 0.421243, acc: 57.03%, op_acc: 43.75%] [G loss: 0.872867]\n",
      "epoch:34 step:26837[D loss: 0.413705, acc: 66.41%, op_acc: 40.62%] [G loss: 0.838837]\n",
      "epoch:34 step:26838[D loss: 0.437318, acc: 56.25%, op_acc: 39.84%] [G loss: 0.791329]\n",
      "epoch:34 step:26839[D loss: 0.454974, acc: 55.47%, op_acc: 32.81%] [G loss: 0.827934]\n",
      "epoch:34 step:26840[D loss: 0.448634, acc: 56.25%, op_acc: 36.72%] [G loss: 0.763278]\n",
      "epoch:34 step:26841[D loss: 0.437524, acc: 52.34%, op_acc: 42.19%] [G loss: 0.959775]\n",
      "epoch:34 step:26842[D loss: 0.386066, acc: 63.28%, op_acc: 41.41%] [G loss: 0.952670]\n",
      "epoch:34 step:26843[D loss: 0.436201, acc: 57.81%, op_acc: 35.16%] [G loss: 0.952198]\n",
      "epoch:34 step:26844[D loss: 0.434725, acc: 57.03%, op_acc: 36.72%] [G loss: 0.752419]\n",
      "epoch:34 step:26845[D loss: 0.401964, acc: 67.19%, op_acc: 46.09%] [G loss: 0.987679]\n",
      "epoch:34 step:26846[D loss: 0.443223, acc: 55.47%, op_acc: 37.50%] [G loss: 0.834929]\n",
      "epoch:34 step:26847[D loss: 0.396299, acc: 62.50%, op_acc: 42.97%] [G loss: 0.949432]\n",
      "epoch:34 step:26848[D loss: 0.458051, acc: 52.34%, op_acc: 33.59%] [G loss: 0.828103]\n",
      "epoch:34 step:26849[D loss: 0.393228, acc: 60.94%, op_acc: 45.31%] [G loss: 0.844195]\n",
      "epoch:34 step:26850[D loss: 0.415355, acc: 55.47%, op_acc: 39.84%] [G loss: 0.921401]\n",
      "##############\n",
      "[0.85766213 0.86244772 0.81521358 0.80142721 0.7998021  0.84745564\n",
      " 0.89337317 0.82937893 0.80048319 0.81931654]\n",
      "##########\n",
      "epoch:34 step:26851[D loss: 0.445311, acc: 54.69%, op_acc: 37.50%] [G loss: 0.931912]\n",
      "epoch:34 step:26852[D loss: 0.414451, acc: 60.94%, op_acc: 41.41%] [G loss: 0.863232]\n",
      "epoch:34 step:26853[D loss: 0.413287, acc: 66.41%, op_acc: 35.16%] [G loss: 0.825782]\n",
      "epoch:34 step:26854[D loss: 0.446701, acc: 61.72%, op_acc: 34.38%] [G loss: 0.869553]\n",
      "epoch:34 step:26855[D loss: 0.405020, acc: 60.94%, op_acc: 40.62%] [G loss: 0.978585]\n",
      "epoch:34 step:26856[D loss: 0.413463, acc: 60.94%, op_acc: 36.72%] [G loss: 0.912346]\n",
      "epoch:34 step:26857[D loss: 0.411350, acc: 62.50%, op_acc: 41.41%] [G loss: 0.862409]\n",
      "epoch:34 step:26858[D loss: 0.409386, acc: 60.16%, op_acc: 37.50%] [G loss: 0.894772]\n",
      "epoch:34 step:26859[D loss: 0.428333, acc: 56.25%, op_acc: 40.62%] [G loss: 0.827677]\n",
      "epoch:34 step:26860[D loss: 0.471350, acc: 47.66%, op_acc: 35.94%] [G loss: 0.920356]\n",
      "epoch:34 step:26861[D loss: 0.424750, acc: 57.81%, op_acc: 38.28%] [G loss: 0.961548]\n",
      "epoch:34 step:26862[D loss: 0.408549, acc: 61.72%, op_acc: 44.53%] [G loss: 0.813765]\n",
      "epoch:34 step:26863[D loss: 0.466683, acc: 46.88%, op_acc: 37.50%] [G loss: 0.877685]\n",
      "epoch:34 step:26864[D loss: 0.415605, acc: 60.16%, op_acc: 40.62%] [G loss: 0.847980]\n",
      "epoch:34 step:26865[D loss: 0.424769, acc: 57.03%, op_acc: 41.41%] [G loss: 0.887930]\n",
      "epoch:34 step:26866[D loss: 0.403175, acc: 68.75%, op_acc: 37.50%] [G loss: 0.890750]\n",
      "epoch:34 step:26867[D loss: 0.416055, acc: 60.94%, op_acc: 44.53%] [G loss: 0.892806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26868[D loss: 0.397843, acc: 61.72%, op_acc: 46.09%] [G loss: 0.941768]\n",
      "epoch:34 step:26869[D loss: 0.451741, acc: 51.56%, op_acc: 37.50%] [G loss: 0.844431]\n",
      "epoch:34 step:26870[D loss: 0.438535, acc: 54.69%, op_acc: 39.06%] [G loss: 0.925421]\n",
      "epoch:34 step:26871[D loss: 0.421250, acc: 65.62%, op_acc: 41.41%] [G loss: 0.867007]\n",
      "epoch:34 step:26872[D loss: 0.457125, acc: 54.69%, op_acc: 30.47%] [G loss: 0.858580]\n",
      "epoch:34 step:26873[D loss: 0.416922, acc: 57.03%, op_acc: 41.41%] [G loss: 0.819941]\n",
      "epoch:34 step:26874[D loss: 0.394751, acc: 71.88%, op_acc: 38.28%] [G loss: 0.911105]\n",
      "epoch:34 step:26875[D loss: 0.440089, acc: 53.91%, op_acc: 39.06%] [G loss: 0.841813]\n",
      "epoch:34 step:26876[D loss: 0.419185, acc: 54.69%, op_acc: 37.50%] [G loss: 0.895655]\n",
      "epoch:34 step:26877[D loss: 0.431055, acc: 52.34%, op_acc: 41.41%] [G loss: 0.910916]\n",
      "epoch:34 step:26878[D loss: 0.420086, acc: 63.28%, op_acc: 36.72%] [G loss: 0.871185]\n",
      "epoch:34 step:26879[D loss: 0.413597, acc: 60.16%, op_acc: 42.19%] [G loss: 0.913038]\n",
      "epoch:34 step:26880[D loss: 0.396843, acc: 64.06%, op_acc: 39.84%] [G loss: 0.953335]\n",
      "epoch:34 step:26881[D loss: 0.406527, acc: 62.50%, op_acc: 40.62%] [G loss: 0.924790]\n",
      "epoch:34 step:26882[D loss: 0.442477, acc: 53.12%, op_acc: 42.19%] [G loss: 0.888132]\n",
      "epoch:34 step:26883[D loss: 0.422681, acc: 60.16%, op_acc: 36.72%] [G loss: 0.799902]\n",
      "epoch:34 step:26884[D loss: 0.425851, acc: 53.91%, op_acc: 46.09%] [G loss: 0.862574]\n",
      "epoch:34 step:26885[D loss: 0.450917, acc: 50.00%, op_acc: 39.06%] [G loss: 0.790520]\n",
      "epoch:34 step:26886[D loss: 0.442183, acc: 54.69%, op_acc: 40.62%] [G loss: 0.882373]\n",
      "epoch:34 step:26887[D loss: 0.415703, acc: 66.41%, op_acc: 39.84%] [G loss: 0.888571]\n",
      "epoch:34 step:26888[D loss: 0.411852, acc: 60.16%, op_acc: 41.41%] [G loss: 0.837154]\n",
      "epoch:34 step:26889[D loss: 0.414790, acc: 60.16%, op_acc: 37.50%] [G loss: 0.883038]\n",
      "epoch:34 step:26890[D loss: 0.429347, acc: 57.81%, op_acc: 35.16%] [G loss: 0.907139]\n",
      "epoch:34 step:26891[D loss: 0.448129, acc: 55.47%, op_acc: 41.41%] [G loss: 0.911709]\n",
      "epoch:34 step:26892[D loss: 0.379789, acc: 63.28%, op_acc: 48.44%] [G loss: 0.973936]\n",
      "epoch:34 step:26893[D loss: 0.408941, acc: 59.38%, op_acc: 42.97%] [G loss: 0.875841]\n",
      "epoch:34 step:26894[D loss: 0.389952, acc: 71.09%, op_acc: 36.72%] [G loss: 0.920120]\n",
      "epoch:34 step:26895[D loss: 0.396680, acc: 73.44%, op_acc: 42.19%] [G loss: 0.897035]\n",
      "epoch:34 step:26896[D loss: 0.437632, acc: 50.00%, op_acc: 44.53%] [G loss: 0.912100]\n",
      "epoch:34 step:26897[D loss: 0.407392, acc: 67.19%, op_acc: 39.06%] [G loss: 0.977943]\n",
      "epoch:34 step:26898[D loss: 0.388270, acc: 64.84%, op_acc: 42.97%] [G loss: 0.907752]\n",
      "epoch:34 step:26899[D loss: 0.424472, acc: 61.72%, op_acc: 32.03%] [G loss: 0.915564]\n",
      "epoch:34 step:26900[D loss: 0.433582, acc: 53.91%, op_acc: 43.75%] [G loss: 0.826231]\n",
      "##############\n",
      "[0.85360593 0.87665208 0.8250168  0.82000708 0.79934316 0.81142328\n",
      " 0.89522341 0.81887298 0.81131096 0.82087789]\n",
      "##########\n",
      "epoch:34 step:26901[D loss: 0.426602, acc: 56.25%, op_acc: 44.53%] [G loss: 0.917306]\n",
      "epoch:34 step:26902[D loss: 0.399576, acc: 69.53%, op_acc: 42.19%] [G loss: 0.915384]\n",
      "epoch:34 step:26903[D loss: 0.398218, acc: 62.50%, op_acc: 42.19%] [G loss: 0.923818]\n",
      "epoch:34 step:26904[D loss: 0.407185, acc: 63.28%, op_acc: 38.28%] [G loss: 0.914708]\n",
      "epoch:34 step:26905[D loss: 0.430690, acc: 54.69%, op_acc: 37.50%] [G loss: 0.880118]\n",
      "epoch:34 step:26906[D loss: 0.441624, acc: 58.59%, op_acc: 35.16%] [G loss: 0.832911]\n",
      "epoch:34 step:26907[D loss: 0.411181, acc: 59.38%, op_acc: 43.75%] [G loss: 0.842659]\n",
      "epoch:34 step:26908[D loss: 0.416780, acc: 59.38%, op_acc: 42.19%] [G loss: 0.922504]\n",
      "epoch:34 step:26909[D loss: 0.419734, acc: 59.38%, op_acc: 37.50%] [G loss: 0.838150]\n",
      "epoch:34 step:26910[D loss: 0.409750, acc: 59.38%, op_acc: 43.75%] [G loss: 0.861759]\n",
      "epoch:34 step:26911[D loss: 0.394099, acc: 68.75%, op_acc: 39.84%] [G loss: 0.918607]\n",
      "epoch:34 step:26912[D loss: 0.418981, acc: 62.50%, op_acc: 46.88%] [G loss: 0.913291]\n",
      "epoch:34 step:26913[D loss: 0.433181, acc: 53.91%, op_acc: 42.19%] [G loss: 0.856308]\n",
      "epoch:34 step:26914[D loss: 0.416625, acc: 60.16%, op_acc: 42.19%] [G loss: 0.897850]\n",
      "epoch:34 step:26915[D loss: 0.409526, acc: 64.06%, op_acc: 42.19%] [G loss: 0.903434]\n",
      "epoch:34 step:26916[D loss: 0.424776, acc: 59.38%, op_acc: 38.28%] [G loss: 0.854795]\n",
      "epoch:34 step:26917[D loss: 0.420799, acc: 58.59%, op_acc: 42.19%] [G loss: 0.926872]\n",
      "epoch:34 step:26918[D loss: 0.422882, acc: 61.72%, op_acc: 38.28%] [G loss: 0.885376]\n",
      "epoch:34 step:26919[D loss: 0.402991, acc: 64.06%, op_acc: 47.66%] [G loss: 0.925046]\n",
      "epoch:34 step:26920[D loss: 0.417606, acc: 57.81%, op_acc: 46.88%] [G loss: 0.894644]\n",
      "epoch:34 step:26921[D loss: 0.423128, acc: 60.94%, op_acc: 39.06%] [G loss: 0.892543]\n",
      "epoch:34 step:26922[D loss: 0.400434, acc: 62.50%, op_acc: 39.84%] [G loss: 0.918723]\n",
      "epoch:34 step:26923[D loss: 0.433429, acc: 59.38%, op_acc: 39.06%] [G loss: 1.025017]\n",
      "epoch:34 step:26924[D loss: 0.414943, acc: 58.59%, op_acc: 42.19%] [G loss: 0.922540]\n",
      "epoch:34 step:26925[D loss: 0.401791, acc: 60.94%, op_acc: 44.53%] [G loss: 0.973443]\n",
      "epoch:34 step:26926[D loss: 0.389492, acc: 63.28%, op_acc: 41.41%] [G loss: 0.945095]\n",
      "epoch:34 step:26927[D loss: 0.413691, acc: 65.62%, op_acc: 39.06%] [G loss: 0.865470]\n",
      "epoch:34 step:26928[D loss: 0.410838, acc: 58.59%, op_acc: 44.53%] [G loss: 0.946752]\n",
      "epoch:34 step:26929[D loss: 0.400782, acc: 64.06%, op_acc: 40.62%] [G loss: 0.908620]\n",
      "epoch:34 step:26930[D loss: 0.431112, acc: 62.50%, op_acc: 32.81%] [G loss: 0.912627]\n",
      "epoch:34 step:26931[D loss: 0.399518, acc: 65.62%, op_acc: 44.53%] [G loss: 0.874949]\n",
      "epoch:34 step:26932[D loss: 0.414005, acc: 61.72%, op_acc: 39.84%] [G loss: 0.843300]\n",
      "epoch:34 step:26933[D loss: 0.407637, acc: 54.69%, op_acc: 48.44%] [G loss: 0.868541]\n",
      "epoch:34 step:26934[D loss: 0.407841, acc: 64.84%, op_acc: 42.97%] [G loss: 0.851973]\n",
      "epoch:34 step:26935[D loss: 0.416256, acc: 60.94%, op_acc: 40.62%] [G loss: 0.855389]\n",
      "epoch:34 step:26936[D loss: 0.419956, acc: 56.25%, op_acc: 39.84%] [G loss: 0.873508]\n",
      "epoch:34 step:26937[D loss: 0.391032, acc: 60.16%, op_acc: 46.09%] [G loss: 0.957624]\n",
      "epoch:34 step:26938[D loss: 0.415380, acc: 57.81%, op_acc: 38.28%] [G loss: 0.940505]\n",
      "epoch:34 step:26939[D loss: 0.449252, acc: 56.25%, op_acc: 36.72%] [G loss: 0.896366]\n",
      "epoch:34 step:26940[D loss: 0.424132, acc: 60.94%, op_acc: 39.06%] [G loss: 0.896454]\n",
      "epoch:34 step:26941[D loss: 0.421758, acc: 60.16%, op_acc: 37.50%] [G loss: 0.949506]\n",
      "epoch:34 step:26942[D loss: 0.461564, acc: 50.00%, op_acc: 37.50%] [G loss: 0.936668]\n",
      "epoch:34 step:26943[D loss: 0.422670, acc: 60.94%, op_acc: 41.41%] [G loss: 0.951297]\n",
      "epoch:34 step:26944[D loss: 0.419177, acc: 59.38%, op_acc: 39.84%] [G loss: 0.847341]\n",
      "epoch:34 step:26945[D loss: 0.403810, acc: 58.59%, op_acc: 40.62%] [G loss: 0.933819]\n",
      "epoch:34 step:26946[D loss: 0.393522, acc: 57.81%, op_acc: 48.44%] [G loss: 0.902430]\n",
      "epoch:34 step:26947[D loss: 0.406345, acc: 61.72%, op_acc: 44.53%] [G loss: 0.909593]\n",
      "epoch:34 step:26948[D loss: 0.424019, acc: 60.16%, op_acc: 45.31%] [G loss: 0.870366]\n",
      "epoch:34 step:26949[D loss: 0.426516, acc: 61.72%, op_acc: 32.81%] [G loss: 0.912064]\n",
      "epoch:34 step:26950[D loss: 0.382415, acc: 71.09%, op_acc: 42.97%] [G loss: 0.959926]\n",
      "##############\n",
      "[0.85332125 0.8550574  0.81163728 0.82384619 0.79233393 0.82131175\n",
      " 0.88351507 0.82794356 0.80441659 0.85447925]\n",
      "##########\n",
      "epoch:34 step:26951[D loss: 0.433328, acc: 52.34%, op_acc: 41.41%] [G loss: 0.847664]\n",
      "epoch:34 step:26952[D loss: 0.452995, acc: 54.69%, op_acc: 39.84%] [G loss: 0.831976]\n",
      "epoch:34 step:26953[D loss: 0.420248, acc: 53.91%, op_acc: 43.75%] [G loss: 0.784681]\n",
      "epoch:34 step:26954[D loss: 0.397212, acc: 63.28%, op_acc: 45.31%] [G loss: 0.866859]\n",
      "epoch:34 step:26955[D loss: 0.425779, acc: 58.59%, op_acc: 40.62%] [G loss: 0.857298]\n",
      "epoch:34 step:26956[D loss: 0.408610, acc: 63.28%, op_acc: 36.72%] [G loss: 0.835324]\n",
      "epoch:34 step:26957[D loss: 0.406004, acc: 71.09%, op_acc: 39.84%] [G loss: 0.900987]\n",
      "epoch:34 step:26958[D loss: 0.393846, acc: 64.84%, op_acc: 46.09%] [G loss: 0.889941]\n",
      "epoch:34 step:26959[D loss: 0.456927, acc: 50.78%, op_acc: 39.84%] [G loss: 0.921457]\n",
      "epoch:34 step:26960[D loss: 0.407211, acc: 56.25%, op_acc: 48.44%] [G loss: 0.915611]\n",
      "epoch:34 step:26961[D loss: 0.398781, acc: 66.41%, op_acc: 47.66%] [G loss: 0.912539]\n",
      "epoch:34 step:26962[D loss: 0.389549, acc: 62.50%, op_acc: 44.53%] [G loss: 0.987727]\n",
      "epoch:34 step:26963[D loss: 0.430761, acc: 53.12%, op_acc: 43.75%] [G loss: 0.892214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26964[D loss: 0.420684, acc: 53.12%, op_acc: 42.97%] [G loss: 0.881293]\n",
      "epoch:34 step:26965[D loss: 0.405876, acc: 59.38%, op_acc: 42.97%] [G loss: 0.848980]\n",
      "epoch:34 step:26966[D loss: 0.404152, acc: 57.03%, op_acc: 43.75%] [G loss: 0.877741]\n",
      "epoch:34 step:26967[D loss: 0.435084, acc: 54.69%, op_acc: 39.06%] [G loss: 0.865589]\n",
      "epoch:34 step:26968[D loss: 0.403334, acc: 59.38%, op_acc: 44.53%] [G loss: 0.830636]\n",
      "epoch:34 step:26969[D loss: 0.395688, acc: 67.19%, op_acc: 44.53%] [G loss: 0.951772]\n",
      "epoch:34 step:26970[D loss: 0.397733, acc: 68.75%, op_acc: 38.28%] [G loss: 0.929227]\n",
      "epoch:34 step:26971[D loss: 0.438969, acc: 56.25%, op_acc: 36.72%] [G loss: 0.921211]\n",
      "epoch:34 step:26972[D loss: 0.449021, acc: 50.78%, op_acc: 42.19%] [G loss: 0.887185]\n",
      "epoch:34 step:26973[D loss: 0.406422, acc: 56.25%, op_acc: 39.06%] [G loss: 0.908660]\n",
      "epoch:34 step:26974[D loss: 0.444644, acc: 50.78%, op_acc: 36.72%] [G loss: 0.884655]\n",
      "epoch:34 step:26975[D loss: 0.398181, acc: 65.62%, op_acc: 39.06%] [G loss: 0.845016]\n",
      "epoch:34 step:26976[D loss: 0.430374, acc: 61.72%, op_acc: 39.06%] [G loss: 0.888661]\n",
      "epoch:34 step:26977[D loss: 0.422940, acc: 58.59%, op_acc: 42.19%] [G loss: 0.925029]\n",
      "epoch:34 step:26978[D loss: 0.430578, acc: 61.72%, op_acc: 39.84%] [G loss: 0.882867]\n",
      "epoch:34 step:26979[D loss: 0.431869, acc: 57.03%, op_acc: 39.84%] [G loss: 0.892448]\n",
      "epoch:34 step:26980[D loss: 0.442027, acc: 57.81%, op_acc: 41.41%] [G loss: 0.836297]\n",
      "epoch:34 step:26981[D loss: 0.455247, acc: 54.69%, op_acc: 35.16%] [G loss: 0.872307]\n",
      "epoch:34 step:26982[D loss: 0.405922, acc: 59.38%, op_acc: 43.75%] [G loss: 0.909174]\n",
      "epoch:34 step:26983[D loss: 0.417728, acc: 52.34%, op_acc: 39.06%] [G loss: 0.857894]\n",
      "epoch:34 step:26984[D loss: 0.407208, acc: 64.06%, op_acc: 41.41%] [G loss: 0.919651]\n",
      "epoch:34 step:26985[D loss: 0.403662, acc: 60.94%, op_acc: 41.41%] [G loss: 0.876121]\n",
      "epoch:34 step:26986[D loss: 0.386918, acc: 68.75%, op_acc: 44.53%] [G loss: 0.851288]\n",
      "epoch:34 step:26987[D loss: 0.431387, acc: 55.47%, op_acc: 44.53%] [G loss: 0.848364]\n",
      "epoch:34 step:26988[D loss: 0.393855, acc: 60.16%, op_acc: 47.66%] [G loss: 0.785673]\n",
      "epoch:34 step:26989[D loss: 0.420115, acc: 54.69%, op_acc: 50.78%] [G loss: 0.825931]\n",
      "epoch:34 step:26990[D loss: 0.438873, acc: 57.81%, op_acc: 39.06%] [G loss: 0.880616]\n",
      "epoch:34 step:26991[D loss: 0.425001, acc: 57.03%, op_acc: 42.19%] [G loss: 0.883567]\n",
      "epoch:34 step:26992[D loss: 0.414651, acc: 67.97%, op_acc: 39.84%] [G loss: 0.843389]\n",
      "epoch:34 step:26993[D loss: 0.415407, acc: 60.94%, op_acc: 42.19%] [G loss: 0.857001]\n",
      "epoch:34 step:26994[D loss: 0.420075, acc: 57.03%, op_acc: 40.62%] [G loss: 0.912810]\n",
      "epoch:34 step:26995[D loss: 0.402802, acc: 64.06%, op_acc: 42.97%] [G loss: 0.873927]\n",
      "epoch:34 step:26996[D loss: 0.430807, acc: 56.25%, op_acc: 40.62%] [G loss: 0.829700]\n",
      "epoch:34 step:26997[D loss: 0.426394, acc: 59.38%, op_acc: 40.62%] [G loss: 0.862882]\n",
      "epoch:34 step:26998[D loss: 0.377151, acc: 65.62%, op_acc: 42.97%] [G loss: 0.922698]\n",
      "epoch:34 step:26999[D loss: 0.442853, acc: 58.59%, op_acc: 32.03%] [G loss: 0.830317]\n",
      "epoch:34 step:27000[D loss: 0.431766, acc: 65.62%, op_acc: 39.84%] [G loss: 0.915763]\n",
      "##############\n",
      "[0.86244466 0.87059324 0.81663898 0.78941693 0.78200973 0.86059714\n",
      " 0.88011362 0.83787006 0.81041048 0.83299441]\n",
      "##########\n",
      "epoch:34 step:27001[D loss: 0.448811, acc: 57.03%, op_acc: 37.50%] [G loss: 0.842717]\n",
      "epoch:34 step:27002[D loss: 0.401925, acc: 63.28%, op_acc: 39.06%] [G loss: 0.904974]\n",
      "epoch:34 step:27003[D loss: 0.428327, acc: 59.38%, op_acc: 35.16%] [G loss: 0.859447]\n",
      "epoch:34 step:27004[D loss: 0.406765, acc: 64.06%, op_acc: 40.62%] [G loss: 0.756962]\n",
      "epoch:34 step:27005[D loss: 0.395765, acc: 64.84%, op_acc: 47.66%] [G loss: 0.855583]\n",
      "epoch:34 step:27006[D loss: 0.425384, acc: 57.03%, op_acc: 42.97%] [G loss: 0.924688]\n",
      "epoch:34 step:27007[D loss: 0.385475, acc: 67.19%, op_acc: 42.19%] [G loss: 0.889953]\n",
      "epoch:34 step:27008[D loss: 0.409623, acc: 57.81%, op_acc: 39.06%] [G loss: 0.850346]\n",
      "epoch:34 step:27009[D loss: 0.426949, acc: 59.38%, op_acc: 39.06%] [G loss: 0.799590]\n",
      "epoch:34 step:27010[D loss: 0.426912, acc: 56.25%, op_acc: 35.16%] [G loss: 0.948850]\n",
      "epoch:34 step:27011[D loss: 0.397003, acc: 64.84%, op_acc: 46.09%] [G loss: 0.850098]\n",
      "epoch:34 step:27012[D loss: 0.419610, acc: 50.78%, op_acc: 39.84%] [G loss: 0.789340]\n",
      "epoch:34 step:27013[D loss: 0.393940, acc: 58.59%, op_acc: 44.53%] [G loss: 0.900251]\n",
      "epoch:34 step:27014[D loss: 0.416441, acc: 60.16%, op_acc: 39.84%] [G loss: 0.866338]\n",
      "epoch:34 step:27015[D loss: 0.405096, acc: 61.72%, op_acc: 43.75%] [G loss: 0.841806]\n",
      "epoch:34 step:27016[D loss: 0.408132, acc: 65.62%, op_acc: 39.84%] [G loss: 0.868262]\n",
      "epoch:34 step:27017[D loss: 0.440010, acc: 53.12%, op_acc: 39.06%] [G loss: 0.852921]\n",
      "epoch:34 step:27018[D loss: 0.417531, acc: 61.72%, op_acc: 42.97%] [G loss: 0.867334]\n",
      "epoch:34 step:27019[D loss: 0.440650, acc: 55.47%, op_acc: 43.75%] [G loss: 0.910618]\n",
      "epoch:34 step:27020[D loss: 0.421676, acc: 55.47%, op_acc: 41.41%] [G loss: 0.975371]\n",
      "epoch:34 step:27021[D loss: 0.457797, acc: 49.22%, op_acc: 32.81%] [G loss: 0.896672]\n",
      "epoch:34 step:27022[D loss: 0.402706, acc: 64.06%, op_acc: 43.75%] [G loss: 0.921337]\n",
      "epoch:34 step:27023[D loss: 0.385218, acc: 63.28%, op_acc: 46.09%] [G loss: 0.932366]\n",
      "epoch:34 step:27024[D loss: 0.412058, acc: 60.16%, op_acc: 48.44%] [G loss: 0.870479]\n",
      "epoch:34 step:27025[D loss: 0.433298, acc: 56.25%, op_acc: 39.06%] [G loss: 0.906572]\n",
      "epoch:34 step:27026[D loss: 0.432997, acc: 56.25%, op_acc: 40.62%] [G loss: 0.946477]\n",
      "epoch:34 step:27027[D loss: 0.397331, acc: 56.25%, op_acc: 44.53%] [G loss: 0.841298]\n",
      "epoch:34 step:27028[D loss: 0.421255, acc: 59.38%, op_acc: 37.50%] [G loss: 0.879274]\n",
      "epoch:34 step:27029[D loss: 0.443866, acc: 53.12%, op_acc: 42.97%] [G loss: 0.893678]\n",
      "epoch:34 step:27030[D loss: 0.410090, acc: 58.59%, op_acc: 44.53%] [G loss: 0.931941]\n",
      "epoch:34 step:27031[D loss: 0.415911, acc: 66.41%, op_acc: 40.62%] [G loss: 0.886011]\n",
      "epoch:34 step:27032[D loss: 0.401099, acc: 57.03%, op_acc: 44.53%] [G loss: 0.969412]\n",
      "epoch:34 step:27033[D loss: 0.408220, acc: 62.50%, op_acc: 42.19%] [G loss: 1.027857]\n",
      "epoch:34 step:27034[D loss: 0.430465, acc: 60.16%, op_acc: 36.72%] [G loss: 0.853836]\n",
      "epoch:34 step:27035[D loss: 0.436789, acc: 60.16%, op_acc: 37.50%] [G loss: 0.923164]\n",
      "epoch:34 step:27036[D loss: 0.429919, acc: 59.38%, op_acc: 44.53%] [G loss: 0.841864]\n",
      "epoch:34 step:27037[D loss: 0.417740, acc: 59.38%, op_acc: 43.75%] [G loss: 0.872952]\n",
      "epoch:34 step:27038[D loss: 0.394306, acc: 64.84%, op_acc: 48.44%] [G loss: 0.876909]\n",
      "epoch:34 step:27039[D loss: 0.420391, acc: 57.03%, op_acc: 39.84%] [G loss: 0.823927]\n",
      "epoch:34 step:27040[D loss: 0.411521, acc: 63.28%, op_acc: 40.62%] [G loss: 0.766205]\n",
      "epoch:34 step:27041[D loss: 0.413665, acc: 61.72%, op_acc: 40.62%] [G loss: 0.864093]\n",
      "epoch:34 step:27042[D loss: 0.398778, acc: 64.06%, op_acc: 44.53%] [G loss: 0.866975]\n",
      "epoch:34 step:27043[D loss: 0.435290, acc: 53.91%, op_acc: 41.41%] [G loss: 0.853525]\n",
      "epoch:34 step:27044[D loss: 0.397955, acc: 64.84%, op_acc: 42.19%] [G loss: 0.825000]\n",
      "epoch:34 step:27045[D loss: 0.448662, acc: 57.03%, op_acc: 38.28%] [G loss: 0.894365]\n",
      "epoch:34 step:27046[D loss: 0.407201, acc: 58.59%, op_acc: 43.75%] [G loss: 0.877546]\n",
      "epoch:34 step:27047[D loss: 0.420515, acc: 60.94%, op_acc: 45.31%] [G loss: 0.981473]\n",
      "epoch:34 step:27048[D loss: 0.394228, acc: 60.16%, op_acc: 38.28%] [G loss: 0.884773]\n",
      "epoch:34 step:27049[D loss: 0.395887, acc: 67.19%, op_acc: 45.31%] [G loss: 0.897826]\n",
      "epoch:34 step:27050[D loss: 0.419815, acc: 57.81%, op_acc: 42.97%] [G loss: 0.886840]\n",
      "##############\n",
      "[0.85364585 0.84285041 0.81330453 0.8085887  0.8132311  0.8136759\n",
      " 0.88001739 0.83908136 0.80563326 0.82422451]\n",
      "##########\n",
      "epoch:34 step:27051[D loss: 0.403741, acc: 60.94%, op_acc: 43.75%] [G loss: 0.876093]\n",
      "epoch:34 step:27052[D loss: 0.455143, acc: 51.56%, op_acc: 39.84%] [G loss: 0.864648]\n",
      "epoch:34 step:27053[D loss: 0.432057, acc: 60.94%, op_acc: 41.41%] [G loss: 0.894952]\n",
      "epoch:34 step:27054[D loss: 0.414032, acc: 62.50%, op_acc: 39.84%] [G loss: 0.893336]\n",
      "epoch:34 step:27055[D loss: 0.459627, acc: 47.66%, op_acc: 36.72%] [G loss: 0.760392]\n",
      "epoch:34 step:27056[D loss: 0.447060, acc: 47.66%, op_acc: 41.41%] [G loss: 0.909848]\n",
      "epoch:34 step:27057[D loss: 0.427114, acc: 60.16%, op_acc: 35.94%] [G loss: 0.942406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27058[D loss: 0.419547, acc: 65.62%, op_acc: 39.06%] [G loss: 0.802967]\n",
      "epoch:34 step:27059[D loss: 0.430758, acc: 61.72%, op_acc: 36.72%] [G loss: 0.825100]\n",
      "epoch:34 step:27060[D loss: 0.422746, acc: 60.16%, op_acc: 37.50%] [G loss: 0.852544]\n",
      "epoch:34 step:27061[D loss: 0.384041, acc: 64.06%, op_acc: 44.53%] [G loss: 0.921096]\n",
      "epoch:34 step:27062[D loss: 0.414303, acc: 57.81%, op_acc: 40.62%] [G loss: 0.936514]\n",
      "epoch:34 step:27063[D loss: 0.438878, acc: 56.25%, op_acc: 37.50%] [G loss: 0.896428]\n",
      "epoch:34 step:27064[D loss: 0.428086, acc: 58.59%, op_acc: 42.97%] [G loss: 0.865805]\n",
      "epoch:34 step:27065[D loss: 0.430398, acc: 54.69%, op_acc: 42.97%] [G loss: 0.887366]\n",
      "epoch:34 step:27066[D loss: 0.431470, acc: 50.78%, op_acc: 36.72%] [G loss: 0.836261]\n",
      "epoch:34 step:27067[D loss: 0.430644, acc: 56.25%, op_acc: 43.75%] [G loss: 0.914940]\n",
      "epoch:34 step:27068[D loss: 0.410374, acc: 63.28%, op_acc: 38.28%] [G loss: 0.906786]\n",
      "epoch:34 step:27069[D loss: 0.412354, acc: 60.94%, op_acc: 42.97%] [G loss: 0.935222]\n",
      "epoch:34 step:27070[D loss: 0.457142, acc: 50.78%, op_acc: 35.16%] [G loss: 0.876746]\n",
      "epoch:34 step:27071[D loss: 0.456295, acc: 45.31%, op_acc: 38.28%] [G loss: 0.832308]\n",
      "epoch:34 step:27072[D loss: 0.415028, acc: 51.56%, op_acc: 37.50%] [G loss: 0.754019]\n",
      "epoch:34 step:27073[D loss: 0.404276, acc: 60.16%, op_acc: 41.41%] [G loss: 0.878945]\n",
      "epoch:34 step:27074[D loss: 0.435187, acc: 52.34%, op_acc: 42.19%] [G loss: 0.831395]\n",
      "epoch:34 step:27075[D loss: 0.436445, acc: 62.50%, op_acc: 38.28%] [G loss: 0.923218]\n",
      "epoch:34 step:27076[D loss: 0.430987, acc: 55.47%, op_acc: 39.06%] [G loss: 0.806509]\n",
      "epoch:34 step:27077[D loss: 0.414122, acc: 57.81%, op_acc: 37.50%] [G loss: 0.890817]\n",
      "epoch:34 step:27078[D loss: 0.407647, acc: 64.84%, op_acc: 40.62%] [G loss: 0.935194]\n",
      "epoch:34 step:27079[D loss: 0.427759, acc: 61.72%, op_acc: 40.62%] [G loss: 0.837017]\n",
      "epoch:34 step:27080[D loss: 0.427526, acc: 60.16%, op_acc: 39.84%] [G loss: 0.918522]\n",
      "epoch:34 step:27081[D loss: 0.461827, acc: 50.00%, op_acc: 35.94%] [G loss: 0.877908]\n",
      "epoch:34 step:27082[D loss: 0.419707, acc: 57.81%, op_acc: 45.31%] [G loss: 0.865019]\n",
      "epoch:34 step:27083[D loss: 0.431286, acc: 54.69%, op_acc: 39.84%] [G loss: 0.795930]\n",
      "epoch:34 step:27084[D loss: 0.419877, acc: 63.28%, op_acc: 35.16%] [G loss: 0.937164]\n",
      "epoch:34 step:27085[D loss: 0.434184, acc: 58.59%, op_acc: 39.06%] [G loss: 0.838100]\n",
      "epoch:34 step:27086[D loss: 0.425381, acc: 61.72%, op_acc: 44.53%] [G loss: 0.922441]\n",
      "epoch:34 step:27087[D loss: 0.426998, acc: 54.69%, op_acc: 46.09%] [G loss: 0.872465]\n",
      "epoch:34 step:27088[D loss: 0.400361, acc: 62.50%, op_acc: 46.09%] [G loss: 0.891371]\n",
      "epoch:34 step:27089[D loss: 0.405508, acc: 60.16%, op_acc: 41.41%] [G loss: 0.902142]\n",
      "epoch:34 step:27090[D loss: 0.409664, acc: 58.59%, op_acc: 42.19%] [G loss: 0.912208]\n",
      "epoch:34 step:27091[D loss: 0.422244, acc: 60.16%, op_acc: 39.84%] [G loss: 0.960156]\n",
      "epoch:34 step:27092[D loss: 0.393147, acc: 66.41%, op_acc: 45.31%] [G loss: 0.928954]\n",
      "epoch:34 step:27093[D loss: 0.408565, acc: 65.62%, op_acc: 42.97%] [G loss: 0.878446]\n",
      "epoch:34 step:27094[D loss: 0.390158, acc: 61.72%, op_acc: 39.06%] [G loss: 0.844671]\n",
      "epoch:34 step:27095[D loss: 0.429012, acc: 47.66%, op_acc: 40.62%] [G loss: 0.843300]\n",
      "epoch:34 step:27096[D loss: 0.429017, acc: 62.50%, op_acc: 33.59%] [G loss: 0.857735]\n",
      "epoch:34 step:27097[D loss: 0.423277, acc: 57.03%, op_acc: 35.94%] [G loss: 0.826989]\n",
      "epoch:34 step:27098[D loss: 0.421379, acc: 55.47%, op_acc: 43.75%] [G loss: 0.817959]\n",
      "epoch:34 step:27099[D loss: 0.393378, acc: 68.75%, op_acc: 40.62%] [G loss: 0.930219]\n",
      "epoch:34 step:27100[D loss: 0.413147, acc: 53.12%, op_acc: 46.09%] [G loss: 0.901510]\n",
      "##############\n",
      "[0.85289841 0.86688441 0.81413917 0.79674996 0.7968249  0.82586829\n",
      " 0.87574417 0.83521336 0.82125001 0.82877133]\n",
      "##########\n",
      "epoch:34 step:27101[D loss: 0.404834, acc: 70.31%, op_acc: 42.19%] [G loss: 0.990488]\n",
      "epoch:34 step:27102[D loss: 0.432081, acc: 64.84%, op_acc: 36.72%] [G loss: 0.949768]\n",
      "epoch:34 step:27103[D loss: 0.457098, acc: 53.12%, op_acc: 42.19%] [G loss: 0.912309]\n",
      "epoch:34 step:27104[D loss: 0.449411, acc: 46.88%, op_acc: 42.19%] [G loss: 0.820469]\n",
      "epoch:34 step:27105[D loss: 0.448351, acc: 49.22%, op_acc: 44.53%] [G loss: 0.872605]\n",
      "epoch:34 step:27106[D loss: 0.444664, acc: 60.16%, op_acc: 35.94%] [G loss: 0.927199]\n",
      "epoch:34 step:27107[D loss: 0.413777, acc: 66.41%, op_acc: 38.28%] [G loss: 0.909770]\n",
      "epoch:34 step:27108[D loss: 0.437197, acc: 55.47%, op_acc: 38.28%] [G loss: 0.934565]\n",
      "epoch:34 step:27109[D loss: 0.414174, acc: 60.16%, op_acc: 35.94%] [G loss: 0.865459]\n",
      "epoch:34 step:27110[D loss: 0.425499, acc: 53.91%, op_acc: 42.19%] [G loss: 0.818123]\n",
      "epoch:34 step:27111[D loss: 0.425654, acc: 55.47%, op_acc: 37.50%] [G loss: 0.905123]\n",
      "epoch:34 step:27112[D loss: 0.405754, acc: 59.38%, op_acc: 41.41%] [G loss: 0.858528]\n",
      "epoch:34 step:27113[D loss: 0.406547, acc: 60.16%, op_acc: 37.50%] [G loss: 0.940441]\n",
      "epoch:34 step:27114[D loss: 0.417196, acc: 62.50%, op_acc: 39.84%] [G loss: 0.873746]\n",
      "epoch:34 step:27115[D loss: 0.422339, acc: 53.91%, op_acc: 46.09%] [G loss: 0.775211]\n",
      "epoch:34 step:27116[D loss: 0.410560, acc: 64.84%, op_acc: 38.28%] [G loss: 0.883845]\n",
      "epoch:34 step:27117[D loss: 0.446685, acc: 60.16%, op_acc: 32.81%] [G loss: 0.895087]\n",
      "epoch:34 step:27118[D loss: 0.408110, acc: 62.50%, op_acc: 42.97%] [G loss: 0.841647]\n",
      "epoch:34 step:27119[D loss: 0.408879, acc: 64.06%, op_acc: 40.62%] [G loss: 0.842955]\n",
      "epoch:34 step:27120[D loss: 0.422177, acc: 59.38%, op_acc: 35.94%] [G loss: 0.910417]\n",
      "epoch:34 step:27121[D loss: 0.379010, acc: 67.19%, op_acc: 46.88%] [G loss: 0.921558]\n",
      "epoch:34 step:27122[D loss: 0.396375, acc: 64.06%, op_acc: 40.62%] [G loss: 0.940001]\n",
      "epoch:34 step:27123[D loss: 0.426885, acc: 57.03%, op_acc: 39.84%] [G loss: 0.844757]\n",
      "epoch:34 step:27124[D loss: 0.429681, acc: 57.81%, op_acc: 38.28%] [G loss: 0.883156]\n",
      "epoch:34 step:27125[D loss: 0.434177, acc: 56.25%, op_acc: 44.53%] [G loss: 0.836403]\n",
      "epoch:34 step:27126[D loss: 0.456390, acc: 55.47%, op_acc: 39.06%] [G loss: 0.875104]\n",
      "epoch:34 step:27127[D loss: 0.422103, acc: 67.19%, op_acc: 42.97%] [G loss: 0.897349]\n",
      "epoch:34 step:27128[D loss: 0.411671, acc: 56.25%, op_acc: 39.84%] [G loss: 0.878697]\n",
      "epoch:34 step:27129[D loss: 0.383352, acc: 64.06%, op_acc: 42.19%] [G loss: 0.827182]\n",
      "epoch:34 step:27130[D loss: 0.408027, acc: 64.84%, op_acc: 43.75%] [G loss: 0.883865]\n",
      "epoch:34 step:27131[D loss: 0.434840, acc: 55.47%, op_acc: 38.28%] [G loss: 0.888739]\n",
      "epoch:34 step:27132[D loss: 0.429002, acc: 59.38%, op_acc: 38.28%] [G loss: 0.891805]\n",
      "epoch:34 step:27133[D loss: 0.422598, acc: 64.06%, op_acc: 32.81%] [G loss: 0.869637]\n",
      "epoch:34 step:27134[D loss: 0.428012, acc: 57.81%, op_acc: 38.28%] [G loss: 0.899068]\n",
      "epoch:34 step:27135[D loss: 0.436497, acc: 57.03%, op_acc: 39.06%] [G loss: 0.870700]\n",
      "epoch:34 step:27136[D loss: 0.412721, acc: 66.41%, op_acc: 39.84%] [G loss: 0.839743]\n",
      "epoch:34 step:27137[D loss: 0.429173, acc: 53.91%, op_acc: 40.62%] [G loss: 0.884176]\n",
      "epoch:34 step:27138[D loss: 0.455719, acc: 57.03%, op_acc: 30.47%] [G loss: 0.893228]\n",
      "epoch:34 step:27139[D loss: 0.404235, acc: 62.50%, op_acc: 39.84%] [G loss: 0.836667]\n",
      "epoch:34 step:27140[D loss: 0.395600, acc: 67.19%, op_acc: 42.97%] [G loss: 0.908244]\n",
      "epoch:34 step:27141[D loss: 0.394549, acc: 64.06%, op_acc: 39.84%] [G loss: 0.834313]\n",
      "epoch:34 step:27142[D loss: 0.400082, acc: 57.81%, op_acc: 46.09%] [G loss: 0.892614]\n",
      "epoch:34 step:27143[D loss: 0.406257, acc: 64.06%, op_acc: 42.19%] [G loss: 0.886560]\n",
      "epoch:34 step:27144[D loss: 0.436471, acc: 51.56%, op_acc: 46.09%] [G loss: 0.835501]\n",
      "epoch:34 step:27145[D loss: 0.419833, acc: 61.72%, op_acc: 41.41%] [G loss: 0.890817]\n",
      "epoch:34 step:27146[D loss: 0.429467, acc: 51.56%, op_acc: 40.62%] [G loss: 0.935557]\n",
      "epoch:34 step:27147[D loss: 0.462828, acc: 57.81%, op_acc: 33.59%] [G loss: 0.982793]\n",
      "epoch:34 step:27148[D loss: 0.419407, acc: 63.28%, op_acc: 38.28%] [G loss: 0.875709]\n",
      "epoch:34 step:27149[D loss: 0.407092, acc: 61.72%, op_acc: 39.84%] [G loss: 0.902160]\n",
      "epoch:34 step:27150[D loss: 0.419098, acc: 61.72%, op_acc: 40.62%] [G loss: 0.877560]\n",
      "##############\n",
      "[0.85828378 0.85912041 0.82092825 0.79891499 0.77150956 0.82309105\n",
      " 0.85417673 0.84039805 0.83788996 0.82266774]\n",
      "##########\n",
      "epoch:34 step:27151[D loss: 0.406704, acc: 64.06%, op_acc: 38.28%] [G loss: 0.873920]\n",
      "epoch:34 step:27152[D loss: 0.400550, acc: 59.38%, op_acc: 41.41%] [G loss: 0.835401]\n",
      "epoch:34 step:27153[D loss: 0.426349, acc: 59.38%, op_acc: 42.97%] [G loss: 0.877824]\n",
      "epoch:34 step:27154[D loss: 0.423218, acc: 58.59%, op_acc: 38.28%] [G loss: 0.797671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27155[D loss: 0.395923, acc: 68.75%, op_acc: 44.53%] [G loss: 0.851000]\n",
      "epoch:34 step:27156[D loss: 0.410564, acc: 60.94%, op_acc: 44.53%] [G loss: 0.809770]\n",
      "epoch:34 step:27157[D loss: 0.418368, acc: 57.03%, op_acc: 46.09%] [G loss: 0.826692]\n",
      "epoch:34 step:27158[D loss: 0.463984, acc: 45.31%, op_acc: 36.72%] [G loss: 0.840876]\n",
      "epoch:34 step:27159[D loss: 0.419964, acc: 58.59%, op_acc: 40.62%] [G loss: 0.886527]\n",
      "epoch:34 step:27160[D loss: 0.408792, acc: 60.94%, op_acc: 42.97%] [G loss: 0.848231]\n",
      "epoch:34 step:27161[D loss: 0.433574, acc: 50.00%, op_acc: 40.62%] [G loss: 0.826147]\n",
      "epoch:34 step:27162[D loss: 0.386093, acc: 66.41%, op_acc: 43.75%] [G loss: 0.957410]\n",
      "epoch:34 step:27163[D loss: 0.424699, acc: 58.59%, op_acc: 38.28%] [G loss: 0.860148]\n",
      "epoch:34 step:27164[D loss: 0.409587, acc: 64.84%, op_acc: 42.97%] [G loss: 0.881936]\n",
      "epoch:34 step:27165[D loss: 0.422430, acc: 58.59%, op_acc: 39.06%] [G loss: 0.869421]\n",
      "epoch:34 step:27166[D loss: 0.416333, acc: 56.25%, op_acc: 42.97%] [G loss: 0.854259]\n",
      "epoch:34 step:27167[D loss: 0.423385, acc: 58.59%, op_acc: 41.41%] [G loss: 0.916204]\n",
      "epoch:34 step:27168[D loss: 0.390014, acc: 63.28%, op_acc: 42.97%] [G loss: 0.829908]\n",
      "epoch:34 step:27169[D loss: 0.413686, acc: 60.16%, op_acc: 42.19%] [G loss: 0.811790]\n",
      "epoch:34 step:27170[D loss: 0.431021, acc: 64.84%, op_acc: 41.41%] [G loss: 0.939572]\n",
      "epoch:34 step:27171[D loss: 0.423726, acc: 57.81%, op_acc: 38.28%] [G loss: 0.834828]\n",
      "epoch:34 step:27172[D loss: 0.412604, acc: 59.38%, op_acc: 42.19%] [G loss: 0.897219]\n",
      "epoch:34 step:27173[D loss: 0.435804, acc: 63.28%, op_acc: 37.50%] [G loss: 0.922110]\n",
      "epoch:34 step:27174[D loss: 0.416729, acc: 62.50%, op_acc: 40.62%] [G loss: 0.907357]\n",
      "epoch:34 step:27175[D loss: 0.418729, acc: 63.28%, op_acc: 42.19%] [G loss: 0.935862]\n",
      "epoch:34 step:27176[D loss: 0.441489, acc: 60.16%, op_acc: 31.25%] [G loss: 0.859370]\n",
      "epoch:34 step:27177[D loss: 0.412682, acc: 60.16%, op_acc: 36.72%] [G loss: 0.854241]\n",
      "epoch:34 step:27178[D loss: 0.447579, acc: 52.34%, op_acc: 39.84%] [G loss: 0.825883]\n",
      "epoch:34 step:27179[D loss: 0.421122, acc: 63.28%, op_acc: 42.97%] [G loss: 0.829878]\n",
      "epoch:34 step:27180[D loss: 0.401110, acc: 60.94%, op_acc: 42.97%] [G loss: 0.883462]\n",
      "epoch:34 step:27181[D loss: 0.408921, acc: 66.41%, op_acc: 45.31%] [G loss: 0.837106]\n",
      "epoch:34 step:27182[D loss: 0.417571, acc: 57.03%, op_acc: 39.06%] [G loss: 0.889562]\n",
      "epoch:34 step:27183[D loss: 0.424255, acc: 59.38%, op_acc: 36.72%] [G loss: 0.950006]\n",
      "epoch:34 step:27184[D loss: 0.391286, acc: 67.19%, op_acc: 42.97%] [G loss: 0.941568]\n",
      "epoch:34 step:27185[D loss: 0.419983, acc: 61.72%, op_acc: 35.16%] [G loss: 0.852350]\n",
      "epoch:34 step:27186[D loss: 0.440991, acc: 53.91%, op_acc: 45.31%] [G loss: 0.979903]\n",
      "epoch:34 step:27187[D loss: 0.410689, acc: 66.41%, op_acc: 38.28%] [G loss: 0.904892]\n",
      "epoch:34 step:27188[D loss: 0.421548, acc: 58.59%, op_acc: 42.97%] [G loss: 0.898791]\n",
      "epoch:34 step:27189[D loss: 0.441313, acc: 54.69%, op_acc: 35.16%] [G loss: 0.910163]\n",
      "epoch:34 step:27190[D loss: 0.424004, acc: 58.59%, op_acc: 42.19%] [G loss: 0.927589]\n",
      "epoch:34 step:27191[D loss: 0.399019, acc: 64.06%, op_acc: 41.41%] [G loss: 0.955412]\n",
      "epoch:34 step:27192[D loss: 0.430082, acc: 63.28%, op_acc: 40.62%] [G loss: 0.919073]\n",
      "epoch:34 step:27193[D loss: 0.424525, acc: 52.34%, op_acc: 47.66%] [G loss: 0.944373]\n",
      "epoch:34 step:27194[D loss: 0.443635, acc: 58.59%, op_acc: 34.38%] [G loss: 0.889734]\n",
      "epoch:34 step:27195[D loss: 0.427796, acc: 59.38%, op_acc: 39.84%] [G loss: 0.884308]\n",
      "epoch:34 step:27196[D loss: 0.408415, acc: 60.94%, op_acc: 42.97%] [G loss: 0.878127]\n",
      "epoch:34 step:27197[D loss: 0.425776, acc: 63.28%, op_acc: 39.06%] [G loss: 0.854520]\n",
      "epoch:34 step:27198[D loss: 0.390114, acc: 60.94%, op_acc: 47.66%] [G loss: 0.940475]\n",
      "epoch:34 step:27199[D loss: 0.386931, acc: 68.75%, op_acc: 38.28%] [G loss: 0.882347]\n",
      "epoch:34 step:27200[D loss: 0.435004, acc: 61.72%, op_acc: 39.84%] [G loss: 0.879342]\n",
      "##############\n",
      "[0.86771633 0.8537909  0.83415742 0.81603708 0.7851678  0.81841058\n",
      " 0.89382606 0.83891749 0.80993295 0.82592178]\n",
      "##########\n",
      "epoch:34 step:27201[D loss: 0.440695, acc: 55.47%, op_acc: 39.06%] [G loss: 0.941827]\n",
      "epoch:34 step:27202[D loss: 0.421703, acc: 54.69%, op_acc: 38.28%] [G loss: 0.885695]\n",
      "epoch:34 step:27203[D loss: 0.405020, acc: 67.19%, op_acc: 41.41%] [G loss: 0.890877]\n",
      "epoch:34 step:27204[D loss: 0.436036, acc: 64.06%, op_acc: 35.94%] [G loss: 0.817291]\n",
      "epoch:34 step:27205[D loss: 0.405798, acc: 58.59%, op_acc: 42.19%] [G loss: 0.888073]\n",
      "epoch:34 step:27206[D loss: 0.419975, acc: 53.12%, op_acc: 41.41%] [G loss: 0.945834]\n",
      "epoch:34 step:27207[D loss: 0.384118, acc: 68.75%, op_acc: 43.75%] [G loss: 0.893651]\n",
      "epoch:34 step:27208[D loss: 0.415065, acc: 59.38%, op_acc: 42.19%] [G loss: 0.931264]\n",
      "epoch:34 step:27209[D loss: 0.418516, acc: 59.38%, op_acc: 42.97%] [G loss: 0.918456]\n",
      "epoch:34 step:27210[D loss: 0.392844, acc: 62.50%, op_acc: 39.84%] [G loss: 0.871573]\n",
      "epoch:34 step:27211[D loss: 0.412389, acc: 57.03%, op_acc: 35.16%] [G loss: 0.883170]\n",
      "epoch:34 step:27212[D loss: 0.426059, acc: 61.72%, op_acc: 38.28%] [G loss: 0.862038]\n",
      "epoch:34 step:27213[D loss: 0.428358, acc: 57.03%, op_acc: 39.06%] [G loss: 0.939573]\n",
      "epoch:34 step:27214[D loss: 0.427346, acc: 57.81%, op_acc: 40.62%] [G loss: 0.816772]\n",
      "epoch:34 step:27215[D loss: 0.392984, acc: 58.59%, op_acc: 48.44%] [G loss: 0.855416]\n",
      "epoch:34 step:27216[D loss: 0.423269, acc: 62.50%, op_acc: 39.84%] [G loss: 0.833009]\n",
      "epoch:34 step:27217[D loss: 0.435517, acc: 50.00%, op_acc: 39.06%] [G loss: 0.811355]\n",
      "epoch:34 step:27218[D loss: 0.423530, acc: 58.59%, op_acc: 41.41%] [G loss: 0.826703]\n",
      "epoch:34 step:27219[D loss: 0.429202, acc: 60.94%, op_acc: 38.28%] [G loss: 0.840323]\n",
      "epoch:34 step:27220[D loss: 0.433186, acc: 53.12%, op_acc: 37.50%] [G loss: 0.851034]\n",
      "epoch:34 step:27221[D loss: 0.403797, acc: 64.06%, op_acc: 41.41%] [G loss: 0.876307]\n",
      "epoch:34 step:27222[D loss: 0.417024, acc: 54.69%, op_acc: 37.50%] [G loss: 0.847124]\n",
      "epoch:34 step:27223[D loss: 0.394652, acc: 68.75%, op_acc: 39.06%] [G loss: 0.850006]\n",
      "epoch:34 step:27224[D loss: 0.406015, acc: 61.72%, op_acc: 42.97%] [G loss: 0.924050]\n",
      "epoch:34 step:27225[D loss: 0.451008, acc: 55.47%, op_acc: 38.28%] [G loss: 0.847540]\n",
      "epoch:34 step:27226[D loss: 0.403760, acc: 68.75%, op_acc: 38.28%] [G loss: 0.946389]\n",
      "epoch:34 step:27227[D loss: 0.421187, acc: 58.59%, op_acc: 32.81%] [G loss: 0.784607]\n",
      "epoch:34 step:27228[D loss: 0.395706, acc: 64.06%, op_acc: 42.97%] [G loss: 0.848653]\n",
      "epoch:34 step:27229[D loss: 0.381467, acc: 70.31%, op_acc: 41.41%] [G loss: 0.931772]\n",
      "epoch:34 step:27230[D loss: 0.462209, acc: 55.47%, op_acc: 33.59%] [G loss: 0.861352]\n",
      "epoch:34 step:27231[D loss: 0.454696, acc: 55.47%, op_acc: 34.38%] [G loss: 0.834930]\n",
      "epoch:34 step:27232[D loss: 0.404592, acc: 57.03%, op_acc: 42.97%] [G loss: 0.881920]\n",
      "epoch:34 step:27233[D loss: 0.414789, acc: 53.12%, op_acc: 41.41%] [G loss: 0.750635]\n",
      "epoch:34 step:27234[D loss: 0.415980, acc: 61.72%, op_acc: 38.28%] [G loss: 0.894792]\n",
      "epoch:34 step:27235[D loss: 0.453179, acc: 67.97%, op_acc: 32.81%] [G loss: 0.941260]\n",
      "epoch:34 step:27236[D loss: 0.407136, acc: 60.16%, op_acc: 43.75%] [G loss: 0.928404]\n",
      "epoch:34 step:27237[D loss: 0.436770, acc: 55.47%, op_acc: 46.09%] [G loss: 0.871401]\n",
      "epoch:34 step:27238[D loss: 0.435987, acc: 56.25%, op_acc: 39.06%] [G loss: 0.896174]\n",
      "epoch:34 step:27239[D loss: 0.435240, acc: 56.25%, op_acc: 40.62%] [G loss: 0.837292]\n",
      "epoch:34 step:27240[D loss: 0.409552, acc: 62.50%, op_acc: 35.94%] [G loss: 0.921059]\n",
      "epoch:34 step:27241[D loss: 0.406283, acc: 64.06%, op_acc: 40.62%] [G loss: 0.925006]\n",
      "epoch:34 step:27242[D loss: 0.417795, acc: 57.03%, op_acc: 46.88%] [G loss: 0.926512]\n",
      "epoch:34 step:27243[D loss: 0.430414, acc: 51.56%, op_acc: 40.62%] [G loss: 0.929579]\n",
      "epoch:34 step:27244[D loss: 0.425494, acc: 58.59%, op_acc: 42.97%] [G loss: 0.875077]\n",
      "epoch:34 step:27245[D loss: 0.445464, acc: 55.47%, op_acc: 40.62%] [G loss: 0.803651]\n",
      "epoch:34 step:27246[D loss: 0.404303, acc: 60.94%, op_acc: 40.62%] [G loss: 1.015788]\n",
      "epoch:34 step:27247[D loss: 0.386770, acc: 71.09%, op_acc: 41.41%] [G loss: 0.965313]\n",
      "epoch:34 step:27248[D loss: 0.421709, acc: 60.94%, op_acc: 37.50%] [G loss: 0.917370]\n",
      "epoch:34 step:27249[D loss: 0.426164, acc: 57.03%, op_acc: 40.62%] [G loss: 0.896658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27250[D loss: 0.412384, acc: 62.50%, op_acc: 38.28%] [G loss: 0.942938]\n",
      "##############\n",
      "[0.84799446 0.85991288 0.79725763 0.80463443 0.78028777 0.83314151\n",
      " 0.88661479 0.83686675 0.80436823 0.82462359]\n",
      "##########\n",
      "epoch:34 step:27251[D loss: 0.419850, acc: 60.94%, op_acc: 39.84%] [G loss: 0.923464]\n",
      "epoch:34 step:27252[D loss: 0.417459, acc: 67.19%, op_acc: 40.62%] [G loss: 0.941394]\n",
      "epoch:34 step:27253[D loss: 0.420107, acc: 56.25%, op_acc: 37.50%] [G loss: 0.823601]\n",
      "epoch:34 step:27254[D loss: 0.409824, acc: 64.06%, op_acc: 42.19%] [G loss: 0.996210]\n",
      "epoch:34 step:27255[D loss: 0.427058, acc: 55.47%, op_acc: 39.06%] [G loss: 0.845945]\n",
      "epoch:34 step:27256[D loss: 0.432253, acc: 60.16%, op_acc: 40.62%] [G loss: 0.919800]\n",
      "epoch:34 step:27257[D loss: 0.458795, acc: 50.00%, op_acc: 44.53%] [G loss: 0.862596]\n",
      "epoch:34 step:27258[D loss: 0.389582, acc: 64.06%, op_acc: 46.09%] [G loss: 0.915802]\n",
      "epoch:34 step:27259[D loss: 0.441863, acc: 50.78%, op_acc: 39.84%] [G loss: 0.849111]\n",
      "epoch:34 step:27260[D loss: 0.423983, acc: 57.03%, op_acc: 44.53%] [G loss: 0.875573]\n",
      "epoch:34 step:27261[D loss: 0.432620, acc: 57.81%, op_acc: 42.19%] [G loss: 0.874666]\n",
      "epoch:34 step:27262[D loss: 0.433751, acc: 56.25%, op_acc: 36.72%] [G loss: 0.880881]\n",
      "epoch:34 step:27263[D loss: 0.397310, acc: 67.19%, op_acc: 43.75%] [G loss: 0.914240]\n",
      "epoch:34 step:27264[D loss: 0.412748, acc: 60.94%, op_acc: 40.62%] [G loss: 0.851847]\n",
      "epoch:34 step:27265[D loss: 0.417025, acc: 57.03%, op_acc: 38.28%] [G loss: 0.884249]\n",
      "epoch:34 step:27266[D loss: 0.399190, acc: 69.53%, op_acc: 46.09%] [G loss: 0.904033]\n",
      "epoch:34 step:27267[D loss: 0.376697, acc: 67.97%, op_acc: 42.97%] [G loss: 0.920539]\n",
      "epoch:34 step:27268[D loss: 0.419055, acc: 62.50%, op_acc: 35.16%] [G loss: 0.800058]\n",
      "epoch:34 step:27269[D loss: 0.407079, acc: 57.81%, op_acc: 42.97%] [G loss: 0.881098]\n",
      "epoch:34 step:27270[D loss: 0.441919, acc: 50.00%, op_acc: 42.19%] [G loss: 0.870295]\n",
      "epoch:34 step:27271[D loss: 0.411192, acc: 53.91%, op_acc: 46.88%] [G loss: 0.879384]\n",
      "epoch:34 step:27272[D loss: 0.425569, acc: 60.16%, op_acc: 38.28%] [G loss: 0.814566]\n",
      "epoch:34 step:27273[D loss: 0.418835, acc: 56.25%, op_acc: 42.19%] [G loss: 0.895558]\n",
      "epoch:34 step:27274[D loss: 0.435715, acc: 54.69%, op_acc: 39.06%] [G loss: 0.887644]\n",
      "epoch:34 step:27275[D loss: 0.399352, acc: 59.38%, op_acc: 46.88%] [G loss: 0.901309]\n",
      "epoch:34 step:27276[D loss: 0.421103, acc: 57.81%, op_acc: 41.41%] [G loss: 0.906299]\n",
      "epoch:34 step:27277[D loss: 0.419184, acc: 57.03%, op_acc: 39.06%] [G loss: 0.846102]\n",
      "epoch:34 step:27278[D loss: 0.454603, acc: 53.12%, op_acc: 37.50%] [G loss: 0.839717]\n",
      "epoch:34 step:27279[D loss: 0.426987, acc: 64.06%, op_acc: 38.28%] [G loss: 0.865471]\n",
      "epoch:34 step:27280[D loss: 0.385786, acc: 63.28%, op_acc: 43.75%] [G loss: 0.924573]\n",
      "epoch:34 step:27281[D loss: 0.441606, acc: 66.41%, op_acc: 40.62%] [G loss: 0.858352]\n",
      "epoch:34 step:27282[D loss: 0.415529, acc: 64.84%, op_acc: 41.41%] [G loss: 0.876259]\n",
      "epoch:34 step:27283[D loss: 0.411740, acc: 61.72%, op_acc: 42.19%] [G loss: 0.876709]\n",
      "epoch:34 step:27284[D loss: 0.403039, acc: 68.75%, op_acc: 41.41%] [G loss: 0.894166]\n",
      "epoch:34 step:27285[D loss: 0.381550, acc: 60.94%, op_acc: 45.31%] [G loss: 0.845350]\n",
      "epoch:34 step:27286[D loss: 0.411896, acc: 67.19%, op_acc: 41.41%] [G loss: 0.921491]\n",
      "epoch:34 step:27287[D loss: 0.421524, acc: 60.94%, op_acc: 41.41%] [G loss: 0.889503]\n",
      "epoch:34 step:27288[D loss: 0.421332, acc: 63.28%, op_acc: 41.41%] [G loss: 0.852093]\n",
      "epoch:34 step:27289[D loss: 0.422809, acc: 57.03%, op_acc: 36.72%] [G loss: 0.787689]\n",
      "epoch:34 step:27290[D loss: 0.396786, acc: 67.97%, op_acc: 42.97%] [G loss: 0.936645]\n",
      "epoch:34 step:27291[D loss: 0.423504, acc: 56.25%, op_acc: 44.53%] [G loss: 0.944671]\n",
      "epoch:34 step:27292[D loss: 0.433668, acc: 59.38%, op_acc: 43.75%] [G loss: 0.868050]\n",
      "epoch:34 step:27293[D loss: 0.450895, acc: 52.34%, op_acc: 39.84%] [G loss: 0.844677]\n",
      "epoch:34 step:27294[D loss: 0.425006, acc: 53.12%, op_acc: 45.31%] [G loss: 0.919721]\n",
      "epoch:34 step:27295[D loss: 0.413132, acc: 60.94%, op_acc: 42.97%] [G loss: 0.837305]\n",
      "epoch:34 step:27296[D loss: 0.431951, acc: 57.03%, op_acc: 39.06%] [G loss: 0.913446]\n",
      "epoch:34 step:27297[D loss: 0.404124, acc: 66.41%, op_acc: 42.97%] [G loss: 0.875095]\n",
      "epoch:34 step:27298[D loss: 0.403751, acc: 62.50%, op_acc: 45.31%] [G loss: 0.868506]\n",
      "epoch:34 step:27299[D loss: 0.420974, acc: 55.47%, op_acc: 45.31%] [G loss: 0.862880]\n",
      "epoch:34 step:27300[D loss: 0.410189, acc: 63.28%, op_acc: 42.19%] [G loss: 0.894998]\n",
      "##############\n",
      "[0.85484364 0.85615282 0.82521276 0.8012183  0.79299155 0.8309188\n",
      " 0.91237735 0.8281996  0.79661533 0.83831298]\n",
      "##########\n",
      "epoch:34 step:27301[D loss: 0.416526, acc: 65.62%, op_acc: 43.75%] [G loss: 0.865587]\n",
      "epoch:34 step:27302[D loss: 0.460055, acc: 57.03%, op_acc: 39.06%] [G loss: 0.868886]\n",
      "epoch:34 step:27303[D loss: 0.438936, acc: 57.03%, op_acc: 40.62%] [G loss: 0.858378]\n",
      "epoch:34 step:27304[D loss: 0.424010, acc: 57.03%, op_acc: 40.62%] [G loss: 0.861432]\n",
      "epoch:34 step:27305[D loss: 0.423994, acc: 60.16%, op_acc: 33.59%] [G loss: 0.900979]\n",
      "epoch:34 step:27306[D loss: 0.422019, acc: 61.72%, op_acc: 42.19%] [G loss: 0.911261]\n",
      "epoch:34 step:27307[D loss: 0.405910, acc: 60.16%, op_acc: 41.41%] [G loss: 0.901344]\n",
      "epoch:34 step:27308[D loss: 0.411923, acc: 68.75%, op_acc: 39.06%] [G loss: 0.869672]\n",
      "epoch:34 step:27309[D loss: 0.393211, acc: 63.28%, op_acc: 40.62%] [G loss: 0.916679]\n",
      "epoch:34 step:27310[D loss: 0.386118, acc: 64.84%, op_acc: 45.31%] [G loss: 0.908294]\n",
      "epoch:34 step:27311[D loss: 0.419311, acc: 57.81%, op_acc: 39.06%] [G loss: 0.842379]\n",
      "epoch:34 step:27312[D loss: 0.384690, acc: 64.84%, op_acc: 46.88%] [G loss: 0.857529]\n",
      "epoch:34 step:27313[D loss: 0.438900, acc: 54.69%, op_acc: 43.75%] [G loss: 0.783264]\n",
      "epoch:34 step:27314[D loss: 0.401732, acc: 60.16%, op_acc: 43.75%] [G loss: 0.926776]\n",
      "epoch:34 step:27315[D loss: 0.414299, acc: 58.59%, op_acc: 42.97%] [G loss: 0.868981]\n",
      "epoch:34 step:27316[D loss: 0.406699, acc: 64.06%, op_acc: 38.28%] [G loss: 0.885633]\n",
      "epoch:34 step:27317[D loss: 0.436212, acc: 58.59%, op_acc: 39.06%] [G loss: 0.867669]\n",
      "epoch:34 step:27318[D loss: 0.408685, acc: 58.59%, op_acc: 42.97%] [G loss: 0.851378]\n",
      "epoch:34 step:27319[D loss: 0.388676, acc: 68.75%, op_acc: 42.19%] [G loss: 0.892833]\n",
      "epoch:34 step:27320[D loss: 0.419082, acc: 60.94%, op_acc: 42.19%] [G loss: 0.926333]\n",
      "epoch:34 step:27321[D loss: 0.396249, acc: 60.94%, op_acc: 44.53%] [G loss: 0.857428]\n",
      "epoch:34 step:27322[D loss: 0.403757, acc: 58.59%, op_acc: 40.62%] [G loss: 0.929492]\n",
      "epoch:34 step:27323[D loss: 0.398683, acc: 66.41%, op_acc: 44.53%] [G loss: 0.894382]\n",
      "epoch:34 step:27324[D loss: 0.430956, acc: 60.94%, op_acc: 39.06%] [G loss: 0.924951]\n",
      "epoch:34 step:27325[D loss: 0.434259, acc: 57.81%, op_acc: 37.50%] [G loss: 0.916720]\n",
      "epoch:34 step:27326[D loss: 0.447693, acc: 58.59%, op_acc: 35.16%] [G loss: 0.895510]\n",
      "epoch:34 step:27327[D loss: 0.420360, acc: 58.59%, op_acc: 39.06%] [G loss: 0.881017]\n",
      "epoch:34 step:27328[D loss: 0.404001, acc: 61.72%, op_acc: 46.09%] [G loss: 0.973080]\n",
      "epoch:34 step:27329[D loss: 0.409507, acc: 61.72%, op_acc: 37.50%] [G loss: 0.884504]\n",
      "epoch:34 step:27330[D loss: 0.381600, acc: 68.75%, op_acc: 44.53%] [G loss: 0.992944]\n",
      "epoch:34 step:27331[D loss: 0.445828, acc: 54.69%, op_acc: 34.38%] [G loss: 0.886859]\n",
      "epoch:34 step:27332[D loss: 0.379594, acc: 69.53%, op_acc: 49.22%] [G loss: 0.896356]\n",
      "epoch:34 step:27333[D loss: 0.420340, acc: 60.16%, op_acc: 39.84%] [G loss: 0.890833]\n",
      "epoch:34 step:27334[D loss: 0.409463, acc: 60.16%, op_acc: 39.06%] [G loss: 0.836240]\n",
      "epoch:34 step:27335[D loss: 0.420483, acc: 58.59%, op_acc: 36.72%] [G loss: 0.953619]\n",
      "epoch:35 step:27336[D loss: 0.382509, acc: 68.75%, op_acc: 46.09%] [G loss: 1.015055]\n",
      "epoch:35 step:27337[D loss: 0.411601, acc: 56.25%, op_acc: 39.06%] [G loss: 0.880115]\n",
      "epoch:35 step:27338[D loss: 0.423795, acc: 57.03%, op_acc: 41.41%] [G loss: 0.900323]\n",
      "epoch:35 step:27339[D loss: 0.399253, acc: 60.94%, op_acc: 44.53%] [G loss: 0.926789]\n",
      "epoch:35 step:27340[D loss: 0.425646, acc: 53.91%, op_acc: 38.28%] [G loss: 0.849588]\n",
      "epoch:35 step:27341[D loss: 0.429187, acc: 57.81%, op_acc: 42.97%] [G loss: 0.862625]\n",
      "epoch:35 step:27342[D loss: 0.420771, acc: 59.38%, op_acc: 43.75%] [G loss: 0.840929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27343[D loss: 0.395201, acc: 65.62%, op_acc: 39.84%] [G loss: 0.940715]\n",
      "epoch:35 step:27344[D loss: 0.406762, acc: 59.38%, op_acc: 41.41%] [G loss: 0.859080]\n",
      "epoch:35 step:27345[D loss: 0.437792, acc: 63.28%, op_acc: 38.28%] [G loss: 0.915453]\n",
      "epoch:35 step:27346[D loss: 0.452398, acc: 46.88%, op_acc: 43.75%] [G loss: 0.897437]\n",
      "epoch:35 step:27347[D loss: 0.429587, acc: 62.50%, op_acc: 38.28%] [G loss: 0.878158]\n",
      "epoch:35 step:27348[D loss: 0.413475, acc: 63.28%, op_acc: 39.84%] [G loss: 0.902856]\n",
      "epoch:35 step:27349[D loss: 0.467372, acc: 48.44%, op_acc: 32.03%] [G loss: 0.899661]\n",
      "epoch:35 step:27350[D loss: 0.422372, acc: 57.81%, op_acc: 41.41%] [G loss: 0.921319]\n",
      "##############\n",
      "[0.85179717 0.85973509 0.82265287 0.79751827 0.76846378 0.82937849\n",
      " 0.86787453 0.84633388 0.81482317 0.83204001]\n",
      "##########\n",
      "epoch:35 step:27351[D loss: 0.436558, acc: 52.34%, op_acc: 40.62%] [G loss: 0.865742]\n",
      "epoch:35 step:27352[D loss: 0.414032, acc: 58.59%, op_acc: 38.28%] [G loss: 0.882903]\n",
      "epoch:35 step:27353[D loss: 0.405361, acc: 68.75%, op_acc: 42.19%] [G loss: 0.980595]\n",
      "epoch:35 step:27354[D loss: 0.405992, acc: 59.38%, op_acc: 39.84%] [G loss: 0.988308]\n",
      "epoch:35 step:27355[D loss: 0.395586, acc: 64.84%, op_acc: 42.19%] [G loss: 0.903105]\n",
      "epoch:35 step:27356[D loss: 0.447860, acc: 56.25%, op_acc: 41.41%] [G loss: 0.881355]\n",
      "epoch:35 step:27357[D loss: 0.395827, acc: 65.62%, op_acc: 44.53%] [G loss: 0.916234]\n",
      "epoch:35 step:27358[D loss: 0.396254, acc: 64.06%, op_acc: 46.88%] [G loss: 0.859263]\n",
      "epoch:35 step:27359[D loss: 0.437748, acc: 59.38%, op_acc: 37.50%] [G loss: 0.850420]\n",
      "epoch:35 step:27360[D loss: 0.442267, acc: 54.69%, op_acc: 38.28%] [G loss: 0.912504]\n",
      "epoch:35 step:27361[D loss: 0.416749, acc: 59.38%, op_acc: 43.75%] [G loss: 0.901296]\n",
      "epoch:35 step:27362[D loss: 0.413724, acc: 61.72%, op_acc: 40.62%] [G loss: 0.893371]\n",
      "epoch:35 step:27363[D loss: 0.401384, acc: 64.06%, op_acc: 37.50%] [G loss: 0.926316]\n",
      "epoch:35 step:27364[D loss: 0.391281, acc: 60.94%, op_acc: 42.19%] [G loss: 0.932769]\n",
      "epoch:35 step:27365[D loss: 0.413570, acc: 63.28%, op_acc: 42.97%] [G loss: 0.915481]\n",
      "epoch:35 step:27366[D loss: 0.446636, acc: 59.38%, op_acc: 39.84%] [G loss: 0.860257]\n",
      "epoch:35 step:27367[D loss: 0.452315, acc: 58.59%, op_acc: 37.50%] [G loss: 0.948675]\n",
      "epoch:35 step:27368[D loss: 0.407558, acc: 57.81%, op_acc: 48.44%] [G loss: 0.873981]\n",
      "epoch:35 step:27369[D loss: 0.412809, acc: 56.25%, op_acc: 44.53%] [G loss: 0.872419]\n",
      "epoch:35 step:27370[D loss: 0.407258, acc: 62.50%, op_acc: 42.19%] [G loss: 0.840300]\n",
      "epoch:35 step:27371[D loss: 0.404779, acc: 60.16%, op_acc: 42.97%] [G loss: 0.963042]\n",
      "epoch:35 step:27372[D loss: 0.390622, acc: 65.62%, op_acc: 40.62%] [G loss: 0.873005]\n",
      "epoch:35 step:27373[D loss: 0.406224, acc: 57.81%, op_acc: 47.66%] [G loss: 0.855456]\n",
      "epoch:35 step:27374[D loss: 0.429298, acc: 50.00%, op_acc: 47.66%] [G loss: 0.942618]\n",
      "epoch:35 step:27375[D loss: 0.436979, acc: 57.81%, op_acc: 42.19%] [G loss: 0.885268]\n",
      "epoch:35 step:27376[D loss: 0.415135, acc: 53.12%, op_acc: 42.19%] [G loss: 0.946200]\n",
      "epoch:35 step:27377[D loss: 0.382437, acc: 67.19%, op_acc: 44.53%] [G loss: 0.952829]\n",
      "epoch:35 step:27378[D loss: 0.435631, acc: 56.25%, op_acc: 42.19%] [G loss: 0.819324]\n",
      "epoch:35 step:27379[D loss: 0.465793, acc: 46.88%, op_acc: 39.06%] [G loss: 0.855931]\n",
      "epoch:35 step:27380[D loss: 0.413262, acc: 64.84%, op_acc: 37.50%] [G loss: 0.952025]\n",
      "epoch:35 step:27381[D loss: 0.417112, acc: 60.16%, op_acc: 44.53%] [G loss: 0.919052]\n",
      "epoch:35 step:27382[D loss: 0.427441, acc: 56.25%, op_acc: 37.50%] [G loss: 0.925371]\n",
      "epoch:35 step:27383[D loss: 0.439220, acc: 63.28%, op_acc: 39.06%] [G loss: 0.869028]\n",
      "epoch:35 step:27384[D loss: 0.389503, acc: 64.06%, op_acc: 38.28%] [G loss: 0.916402]\n",
      "epoch:35 step:27385[D loss: 0.464820, acc: 49.22%, op_acc: 36.72%] [G loss: 0.806494]\n",
      "epoch:35 step:27386[D loss: 0.385445, acc: 69.53%, op_acc: 42.97%] [G loss: 0.909012]\n",
      "epoch:35 step:27387[D loss: 0.404353, acc: 65.62%, op_acc: 38.28%] [G loss: 0.798036]\n",
      "epoch:35 step:27388[D loss: 0.440119, acc: 57.81%, op_acc: 42.19%] [G loss: 0.875507]\n",
      "epoch:35 step:27389[D loss: 0.427589, acc: 55.47%, op_acc: 45.31%] [G loss: 0.883149]\n",
      "epoch:35 step:27390[D loss: 0.403880, acc: 60.16%, op_acc: 40.62%] [G loss: 0.866831]\n",
      "epoch:35 step:27391[D loss: 0.415408, acc: 57.03%, op_acc: 39.84%] [G loss: 0.956256]\n",
      "epoch:35 step:27392[D loss: 0.407698, acc: 65.62%, op_acc: 39.06%] [G loss: 0.946524]\n",
      "epoch:35 step:27393[D loss: 0.419569, acc: 54.69%, op_acc: 43.75%] [G loss: 0.812486]\n",
      "epoch:35 step:27394[D loss: 0.400444, acc: 60.94%, op_acc: 36.72%] [G loss: 0.857498]\n",
      "epoch:35 step:27395[D loss: 0.409720, acc: 56.25%, op_acc: 46.09%] [G loss: 0.867950]\n",
      "epoch:35 step:27396[D loss: 0.413330, acc: 56.25%, op_acc: 39.84%] [G loss: 0.841129]\n",
      "epoch:35 step:27397[D loss: 0.445075, acc: 60.94%, op_acc: 37.50%] [G loss: 0.925992]\n",
      "epoch:35 step:27398[D loss: 0.441227, acc: 57.03%, op_acc: 36.72%] [G loss: 0.919224]\n",
      "epoch:35 step:27399[D loss: 0.412889, acc: 57.03%, op_acc: 42.19%] [G loss: 0.897796]\n",
      "epoch:35 step:27400[D loss: 0.432399, acc: 57.81%, op_acc: 36.72%] [G loss: 0.829575]\n",
      "##############\n",
      "[0.86263645 0.86067949 0.81078191 0.8056343  0.81757939 0.8201317\n",
      " 0.90252331 0.82460865 0.81014221 0.80925768]\n",
      "##########\n",
      "epoch:35 step:27401[D loss: 0.419985, acc: 52.34%, op_acc: 45.31%] [G loss: 0.892774]\n",
      "epoch:35 step:27402[D loss: 0.403880, acc: 64.06%, op_acc: 43.75%] [G loss: 0.867211]\n",
      "epoch:35 step:27403[D loss: 0.436550, acc: 52.34%, op_acc: 39.84%] [G loss: 0.817614]\n",
      "epoch:35 step:27404[D loss: 0.361992, acc: 67.97%, op_acc: 47.66%] [G loss: 0.965693]\n",
      "epoch:35 step:27405[D loss: 0.404207, acc: 64.06%, op_acc: 39.84%] [G loss: 0.950244]\n",
      "epoch:35 step:27406[D loss: 0.460373, acc: 52.34%, op_acc: 38.28%] [G loss: 0.856420]\n",
      "epoch:35 step:27407[D loss: 0.378190, acc: 70.31%, op_acc: 43.75%] [G loss: 0.936204]\n",
      "epoch:35 step:27408[D loss: 0.421794, acc: 53.12%, op_acc: 43.75%] [G loss: 0.870542]\n",
      "epoch:35 step:27409[D loss: 0.397266, acc: 61.72%, op_acc: 39.84%] [G loss: 0.867478]\n",
      "epoch:35 step:27410[D loss: 0.386948, acc: 59.38%, op_acc: 46.09%] [G loss: 0.890931]\n",
      "epoch:35 step:27411[D loss: 0.469630, acc: 51.56%, op_acc: 43.75%] [G loss: 0.903426]\n",
      "epoch:35 step:27412[D loss: 0.448683, acc: 51.56%, op_acc: 41.41%] [G loss: 0.778930]\n",
      "epoch:35 step:27413[D loss: 0.450326, acc: 58.59%, op_acc: 37.50%] [G loss: 0.852490]\n",
      "epoch:35 step:27414[D loss: 0.396625, acc: 62.50%, op_acc: 42.97%] [G loss: 0.923676]\n",
      "epoch:35 step:27415[D loss: 0.470189, acc: 55.47%, op_acc: 32.81%] [G loss: 0.888779]\n",
      "epoch:35 step:27416[D loss: 0.423890, acc: 61.72%, op_acc: 36.72%] [G loss: 0.849348]\n",
      "epoch:35 step:27417[D loss: 0.425554, acc: 56.25%, op_acc: 42.19%] [G loss: 0.868715]\n",
      "epoch:35 step:27418[D loss: 0.413917, acc: 61.72%, op_acc: 39.84%] [G loss: 0.896929]\n",
      "epoch:35 step:27419[D loss: 0.392837, acc: 65.62%, op_acc: 44.53%] [G loss: 0.898278]\n",
      "epoch:35 step:27420[D loss: 0.417949, acc: 64.84%, op_acc: 36.72%] [G loss: 0.845262]\n",
      "epoch:35 step:27421[D loss: 0.396968, acc: 59.38%, op_acc: 44.53%] [G loss: 0.899851]\n",
      "epoch:35 step:27422[D loss: 0.420998, acc: 57.81%, op_acc: 41.41%] [G loss: 0.914776]\n",
      "epoch:35 step:27423[D loss: 0.407637, acc: 61.72%, op_acc: 38.28%] [G loss: 0.885406]\n",
      "epoch:35 step:27424[D loss: 0.445872, acc: 52.34%, op_acc: 38.28%] [G loss: 0.877800]\n",
      "epoch:35 step:27425[D loss: 0.415715, acc: 55.47%, op_acc: 43.75%] [G loss: 0.806777]\n",
      "epoch:35 step:27426[D loss: 0.388595, acc: 62.50%, op_acc: 48.44%] [G loss: 0.863544]\n",
      "epoch:35 step:27427[D loss: 0.438238, acc: 53.12%, op_acc: 40.62%] [G loss: 0.768766]\n",
      "epoch:35 step:27428[D loss: 0.378021, acc: 65.62%, op_acc: 44.53%] [G loss: 0.894576]\n",
      "epoch:35 step:27429[D loss: 0.395421, acc: 64.06%, op_acc: 46.88%] [G loss: 0.925378]\n",
      "epoch:35 step:27430[D loss: 0.386766, acc: 69.53%, op_acc: 45.31%] [G loss: 0.940197]\n",
      "epoch:35 step:27431[D loss: 0.449670, acc: 59.38%, op_acc: 35.94%] [G loss: 0.856288]\n",
      "epoch:35 step:27432[D loss: 0.431096, acc: 62.50%, op_acc: 36.72%] [G loss: 0.855945]\n",
      "epoch:35 step:27433[D loss: 0.422384, acc: 58.59%, op_acc: 35.94%] [G loss: 0.800628]\n",
      "epoch:35 step:27434[D loss: 0.405901, acc: 58.59%, op_acc: 43.75%] [G loss: 0.861517]\n",
      "epoch:35 step:27435[D loss: 0.404160, acc: 62.50%, op_acc: 43.75%] [G loss: 0.793311]\n",
      "epoch:35 step:27436[D loss: 0.408199, acc: 63.28%, op_acc: 37.50%] [G loss: 0.858086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27437[D loss: 0.426594, acc: 63.28%, op_acc: 42.19%] [G loss: 0.873355]\n",
      "epoch:35 step:27438[D loss: 0.416614, acc: 64.06%, op_acc: 37.50%] [G loss: 0.902222]\n",
      "epoch:35 step:27439[D loss: 0.410873, acc: 58.59%, op_acc: 41.41%] [G loss: 0.880737]\n",
      "epoch:35 step:27440[D loss: 0.404269, acc: 65.62%, op_acc: 41.41%] [G loss: 0.872294]\n",
      "epoch:35 step:27441[D loss: 0.427895, acc: 59.38%, op_acc: 42.19%] [G loss: 0.915579]\n",
      "epoch:35 step:27442[D loss: 0.401368, acc: 66.41%, op_acc: 42.19%] [G loss: 0.896715]\n",
      "epoch:35 step:27443[D loss: 0.430138, acc: 60.16%, op_acc: 39.84%] [G loss: 0.966161]\n",
      "epoch:35 step:27444[D loss: 0.423910, acc: 53.12%, op_acc: 41.41%] [G loss: 0.832763]\n",
      "epoch:35 step:27445[D loss: 0.398444, acc: 62.50%, op_acc: 42.19%] [G loss: 0.929742]\n",
      "epoch:35 step:27446[D loss: 0.460842, acc: 53.91%, op_acc: 35.94%] [G loss: 0.946376]\n",
      "epoch:35 step:27447[D loss: 0.419758, acc: 57.81%, op_acc: 45.31%] [G loss: 0.987238]\n",
      "epoch:35 step:27448[D loss: 0.430998, acc: 59.38%, op_acc: 37.50%] [G loss: 0.844625]\n",
      "epoch:35 step:27449[D loss: 0.475182, acc: 46.09%, op_acc: 38.28%] [G loss: 0.871749]\n",
      "epoch:35 step:27450[D loss: 0.409459, acc: 58.59%, op_acc: 46.09%] [G loss: 0.811443]\n",
      "##############\n",
      "[0.8545937  0.84413384 0.80883759 0.8142759  0.78183518 0.80485452\n",
      " 0.88358319 0.83094338 0.81181967 0.83955126]\n",
      "##########\n",
      "epoch:35 step:27451[D loss: 0.407268, acc: 62.50%, op_acc: 36.72%] [G loss: 0.887057]\n",
      "epoch:35 step:27452[D loss: 0.407186, acc: 60.16%, op_acc: 42.19%] [G loss: 0.815528]\n",
      "epoch:35 step:27453[D loss: 0.426560, acc: 56.25%, op_acc: 38.28%] [G loss: 0.806186]\n",
      "epoch:35 step:27454[D loss: 0.437369, acc: 52.34%, op_acc: 35.16%] [G loss: 0.860749]\n",
      "epoch:35 step:27455[D loss: 0.418256, acc: 60.16%, op_acc: 38.28%] [G loss: 0.858530]\n",
      "epoch:35 step:27456[D loss: 0.398156, acc: 64.06%, op_acc: 44.53%] [G loss: 0.911372]\n",
      "epoch:35 step:27457[D loss: 0.403809, acc: 60.94%, op_acc: 47.66%] [G loss: 0.928229]\n",
      "epoch:35 step:27458[D loss: 0.417855, acc: 58.59%, op_acc: 39.84%] [G loss: 0.921260]\n",
      "epoch:35 step:27459[D loss: 0.423630, acc: 57.81%, op_acc: 40.62%] [G loss: 0.889464]\n",
      "epoch:35 step:27460[D loss: 0.451458, acc: 53.91%, op_acc: 34.38%] [G loss: 0.889426]\n",
      "epoch:35 step:27461[D loss: 0.408010, acc: 62.50%, op_acc: 38.28%] [G loss: 0.788168]\n",
      "epoch:35 step:27462[D loss: 0.390059, acc: 61.72%, op_acc: 39.84%] [G loss: 0.921802]\n",
      "epoch:35 step:27463[D loss: 0.408206, acc: 57.81%, op_acc: 41.41%] [G loss: 0.916750]\n",
      "epoch:35 step:27464[D loss: 0.437872, acc: 58.59%, op_acc: 41.41%] [G loss: 0.827484]\n",
      "epoch:35 step:27465[D loss: 0.399801, acc: 67.19%, op_acc: 42.97%] [G loss: 0.889199]\n",
      "epoch:35 step:27466[D loss: 0.414914, acc: 61.72%, op_acc: 42.19%] [G loss: 0.864746]\n",
      "epoch:35 step:27467[D loss: 0.404158, acc: 53.91%, op_acc: 42.19%] [G loss: 0.799733]\n",
      "epoch:35 step:27468[D loss: 0.461488, acc: 56.25%, op_acc: 32.81%] [G loss: 0.832878]\n",
      "epoch:35 step:27469[D loss: 0.430048, acc: 57.03%, op_acc: 42.19%] [G loss: 0.916213]\n",
      "epoch:35 step:27470[D loss: 0.429710, acc: 50.00%, op_acc: 39.06%] [G loss: 0.889384]\n",
      "epoch:35 step:27471[D loss: 0.414936, acc: 57.81%, op_acc: 42.19%] [G loss: 0.852657]\n",
      "epoch:35 step:27472[D loss: 0.413889, acc: 66.41%, op_acc: 37.50%] [G loss: 0.940876]\n",
      "epoch:35 step:27473[D loss: 0.433892, acc: 57.81%, op_acc: 35.94%] [G loss: 0.902438]\n",
      "epoch:35 step:27474[D loss: 0.395912, acc: 64.84%, op_acc: 42.19%] [G loss: 0.863999]\n",
      "epoch:35 step:27475[D loss: 0.444986, acc: 57.81%, op_acc: 41.41%] [G loss: 0.926142]\n",
      "epoch:35 step:27476[D loss: 0.418607, acc: 60.94%, op_acc: 39.84%] [G loss: 0.833635]\n",
      "epoch:35 step:27477[D loss: 0.400615, acc: 59.38%, op_acc: 36.72%] [G loss: 0.890834]\n",
      "epoch:35 step:27478[D loss: 0.412760, acc: 66.41%, op_acc: 40.62%] [G loss: 0.977039]\n",
      "epoch:35 step:27479[D loss: 0.425138, acc: 58.59%, op_acc: 42.97%] [G loss: 0.881248]\n",
      "epoch:35 step:27480[D loss: 0.422855, acc: 58.59%, op_acc: 40.62%] [G loss: 0.879010]\n",
      "epoch:35 step:27481[D loss: 0.384217, acc: 65.62%, op_acc: 44.53%] [G loss: 0.912715]\n",
      "epoch:35 step:27482[D loss: 0.415191, acc: 57.81%, op_acc: 43.75%] [G loss: 0.939373]\n",
      "epoch:35 step:27483[D loss: 0.433955, acc: 57.81%, op_acc: 39.84%] [G loss: 0.922633]\n",
      "epoch:35 step:27484[D loss: 0.391465, acc: 62.50%, op_acc: 39.06%] [G loss: 0.839638]\n",
      "epoch:35 step:27485[D loss: 0.381917, acc: 65.62%, op_acc: 48.44%] [G loss: 0.836654]\n",
      "epoch:35 step:27486[D loss: 0.436692, acc: 53.91%, op_acc: 44.53%] [G loss: 0.871822]\n",
      "epoch:35 step:27487[D loss: 0.417638, acc: 50.00%, op_acc: 48.44%] [G loss: 0.824416]\n",
      "epoch:35 step:27488[D loss: 0.419030, acc: 55.47%, op_acc: 42.19%] [G loss: 0.919981]\n",
      "epoch:35 step:27489[D loss: 0.428108, acc: 60.94%, op_acc: 38.28%] [G loss: 0.936288]\n",
      "epoch:35 step:27490[D loss: 0.420527, acc: 60.16%, op_acc: 35.16%] [G loss: 0.830146]\n",
      "epoch:35 step:27491[D loss: 0.399733, acc: 62.50%, op_acc: 42.97%] [G loss: 0.771284]\n",
      "epoch:35 step:27492[D loss: 0.408084, acc: 60.16%, op_acc: 42.97%] [G loss: 0.832819]\n",
      "epoch:35 step:27493[D loss: 0.388051, acc: 65.62%, op_acc: 48.44%] [G loss: 0.914325]\n",
      "epoch:35 step:27494[D loss: 0.403806, acc: 59.38%, op_acc: 44.53%] [G loss: 0.902915]\n",
      "epoch:35 step:27495[D loss: 0.447164, acc: 57.03%, op_acc: 37.50%] [G loss: 0.792760]\n",
      "epoch:35 step:27496[D loss: 0.418702, acc: 58.59%, op_acc: 42.97%] [G loss: 0.869164]\n",
      "epoch:35 step:27497[D loss: 0.397893, acc: 59.38%, op_acc: 42.97%] [G loss: 0.863969]\n",
      "epoch:35 step:27498[D loss: 0.445113, acc: 55.47%, op_acc: 38.28%] [G loss: 0.892975]\n",
      "epoch:35 step:27499[D loss: 0.428970, acc: 57.81%, op_acc: 35.16%] [G loss: 0.874337]\n",
      "epoch:35 step:27500[D loss: 0.400862, acc: 58.59%, op_acc: 42.19%] [G loss: 0.996976]\n",
      "##############\n",
      "[0.85209286 0.85127372 0.82074145 0.8037744  0.77913683 0.82316462\n",
      " 0.90040034 0.84241253 0.79880208 0.81814351]\n",
      "##########\n",
      "epoch:35 step:27501[D loss: 0.437587, acc: 57.03%, op_acc: 36.72%] [G loss: 0.864724]\n",
      "epoch:35 step:27502[D loss: 0.410984, acc: 61.72%, op_acc: 44.53%] [G loss: 0.987943]\n",
      "epoch:35 step:27503[D loss: 0.408320, acc: 59.38%, op_acc: 41.41%] [G loss: 0.814101]\n",
      "epoch:35 step:27504[D loss: 0.448902, acc: 51.56%, op_acc: 42.97%] [G loss: 0.862332]\n",
      "epoch:35 step:27505[D loss: 0.430359, acc: 63.28%, op_acc: 44.53%] [G loss: 0.964809]\n",
      "epoch:35 step:27506[D loss: 0.437663, acc: 56.25%, op_acc: 35.94%] [G loss: 0.835673]\n",
      "epoch:35 step:27507[D loss: 0.410967, acc: 61.72%, op_acc: 44.53%] [G loss: 0.858608]\n",
      "epoch:35 step:27508[D loss: 0.460681, acc: 52.34%, op_acc: 30.47%] [G loss: 0.813035]\n",
      "epoch:35 step:27509[D loss: 0.435920, acc: 57.03%, op_acc: 39.06%] [G loss: 0.873655]\n",
      "epoch:35 step:27510[D loss: 0.430374, acc: 57.81%, op_acc: 39.84%] [G loss: 0.950010]\n",
      "epoch:35 step:27511[D loss: 0.433474, acc: 58.59%, op_acc: 42.19%] [G loss: 0.866113]\n",
      "epoch:35 step:27512[D loss: 0.406732, acc: 58.59%, op_acc: 44.53%] [G loss: 0.928517]\n",
      "epoch:35 step:27513[D loss: 0.415910, acc: 59.38%, op_acc: 38.28%] [G loss: 0.949355]\n",
      "epoch:35 step:27514[D loss: 0.406268, acc: 60.16%, op_acc: 42.19%] [G loss: 0.858656]\n",
      "epoch:35 step:27515[D loss: 0.440138, acc: 60.16%, op_acc: 36.72%] [G loss: 0.970628]\n",
      "epoch:35 step:27516[D loss: 0.414654, acc: 56.25%, op_acc: 39.06%] [G loss: 0.827315]\n",
      "epoch:35 step:27517[D loss: 0.423947, acc: 55.47%, op_acc: 34.38%] [G loss: 0.853114]\n",
      "epoch:35 step:27518[D loss: 0.397336, acc: 64.84%, op_acc: 38.28%] [G loss: 0.939180]\n",
      "epoch:35 step:27519[D loss: 0.391869, acc: 67.19%, op_acc: 42.97%] [G loss: 0.861859]\n",
      "epoch:35 step:27520[D loss: 0.396430, acc: 73.44%, op_acc: 34.38%] [G loss: 0.929193]\n",
      "epoch:35 step:27521[D loss: 0.406097, acc: 60.94%, op_acc: 39.84%] [G loss: 0.829809]\n",
      "epoch:35 step:27522[D loss: 0.396059, acc: 64.84%, op_acc: 42.19%] [G loss: 0.874066]\n",
      "epoch:35 step:27523[D loss: 0.416309, acc: 56.25%, op_acc: 44.53%] [G loss: 0.907343]\n",
      "epoch:35 step:27524[D loss: 0.411582, acc: 61.72%, op_acc: 39.84%] [G loss: 0.887434]\n",
      "epoch:35 step:27525[D loss: 0.443717, acc: 56.25%, op_acc: 36.72%] [G loss: 0.941310]\n",
      "epoch:35 step:27526[D loss: 0.395524, acc: 58.59%, op_acc: 46.09%] [G loss: 0.913777]\n",
      "epoch:35 step:27527[D loss: 0.398255, acc: 67.19%, op_acc: 41.41%] [G loss: 0.935312]\n",
      "epoch:35 step:27528[D loss: 0.443196, acc: 55.47%, op_acc: 35.94%] [G loss: 0.887641]\n",
      "epoch:35 step:27529[D loss: 0.374800, acc: 71.88%, op_acc: 43.75%] [G loss: 0.920804]\n",
      "epoch:35 step:27530[D loss: 0.416583, acc: 60.94%, op_acc: 39.06%] [G loss: 0.834675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27531[D loss: 0.430917, acc: 61.72%, op_acc: 36.72%] [G loss: 0.889701]\n",
      "epoch:35 step:27532[D loss: 0.449909, acc: 53.12%, op_acc: 32.81%] [G loss: 0.989101]\n",
      "epoch:35 step:27533[D loss: 0.428253, acc: 58.59%, op_acc: 40.62%] [G loss: 0.930694]\n",
      "epoch:35 step:27534[D loss: 0.435506, acc: 59.38%, op_acc: 37.50%] [G loss: 0.819507]\n",
      "epoch:35 step:27535[D loss: 0.422694, acc: 57.03%, op_acc: 43.75%] [G loss: 0.858752]\n",
      "epoch:35 step:27536[D loss: 0.413716, acc: 60.16%, op_acc: 41.41%] [G loss: 0.914697]\n",
      "epoch:35 step:27537[D loss: 0.421596, acc: 60.94%, op_acc: 40.62%] [G loss: 0.846463]\n",
      "epoch:35 step:27538[D loss: 0.424367, acc: 57.81%, op_acc: 42.19%] [G loss: 0.931919]\n",
      "epoch:35 step:27539[D loss: 0.445854, acc: 54.69%, op_acc: 36.72%] [G loss: 0.889801]\n",
      "epoch:35 step:27540[D loss: 0.426442, acc: 58.59%, op_acc: 39.84%] [G loss: 0.834805]\n",
      "epoch:35 step:27541[D loss: 0.389019, acc: 68.75%, op_acc: 39.84%] [G loss: 0.889271]\n",
      "epoch:35 step:27542[D loss: 0.391763, acc: 67.97%, op_acc: 42.19%] [G loss: 0.961338]\n",
      "epoch:35 step:27543[D loss: 0.418261, acc: 66.41%, op_acc: 37.50%] [G loss: 0.914436]\n",
      "epoch:35 step:27544[D loss: 0.389397, acc: 62.50%, op_acc: 46.88%] [G loss: 0.918164]\n",
      "epoch:35 step:27545[D loss: 0.428056, acc: 59.38%, op_acc: 37.50%] [G loss: 0.916294]\n",
      "epoch:35 step:27546[D loss: 0.407476, acc: 62.50%, op_acc: 44.53%] [G loss: 0.867225]\n",
      "epoch:35 step:27547[D loss: 0.418100, acc: 64.06%, op_acc: 35.94%] [G loss: 0.908549]\n",
      "epoch:35 step:27548[D loss: 0.406187, acc: 60.94%, op_acc: 44.53%] [G loss: 0.898710]\n",
      "epoch:35 step:27549[D loss: 0.450054, acc: 55.47%, op_acc: 34.38%] [G loss: 0.852854]\n",
      "epoch:35 step:27550[D loss: 0.448270, acc: 57.03%, op_acc: 43.75%] [G loss: 0.850321]\n",
      "##############\n",
      "[0.85762601 0.85085978 0.81720152 0.81925342 0.79130785 0.83341561\n",
      " 0.86541544 0.83059877 0.80109289 0.82835673]\n",
      "##########\n",
      "epoch:35 step:27551[D loss: 0.432934, acc: 59.38%, op_acc: 38.28%] [G loss: 0.832491]\n",
      "epoch:35 step:27552[D loss: 0.386255, acc: 64.06%, op_acc: 44.53%] [G loss: 0.838384]\n",
      "epoch:35 step:27553[D loss: 0.436121, acc: 56.25%, op_acc: 46.88%] [G loss: 0.885018]\n",
      "epoch:35 step:27554[D loss: 0.401964, acc: 63.28%, op_acc: 41.41%] [G loss: 0.889747]\n",
      "epoch:35 step:27555[D loss: 0.420231, acc: 56.25%, op_acc: 43.75%] [G loss: 0.927524]\n",
      "epoch:35 step:27556[D loss: 0.393161, acc: 67.19%, op_acc: 41.41%] [G loss: 0.863968]\n",
      "epoch:35 step:27557[D loss: 0.444234, acc: 57.03%, op_acc: 36.72%] [G loss: 0.873179]\n",
      "epoch:35 step:27558[D loss: 0.457131, acc: 49.22%, op_acc: 38.28%] [G loss: 0.846205]\n",
      "epoch:35 step:27559[D loss: 0.432547, acc: 56.25%, op_acc: 41.41%] [G loss: 0.788381]\n",
      "epoch:35 step:27560[D loss: 0.427650, acc: 57.03%, op_acc: 35.94%] [G loss: 0.881267]\n",
      "epoch:35 step:27561[D loss: 0.426242, acc: 58.59%, op_acc: 40.62%] [G loss: 0.942957]\n",
      "epoch:35 step:27562[D loss: 0.429229, acc: 55.47%, op_acc: 35.94%] [G loss: 0.957311]\n",
      "epoch:35 step:27563[D loss: 0.400832, acc: 64.84%, op_acc: 43.75%] [G loss: 0.865649]\n",
      "epoch:35 step:27564[D loss: 0.371507, acc: 62.50%, op_acc: 42.97%] [G loss: 0.906055]\n",
      "epoch:35 step:27565[D loss: 0.420964, acc: 63.28%, op_acc: 38.28%] [G loss: 0.901545]\n",
      "epoch:35 step:27566[D loss: 0.389227, acc: 67.19%, op_acc: 44.53%] [G loss: 0.876056]\n",
      "epoch:35 step:27567[D loss: 0.422362, acc: 60.16%, op_acc: 38.28%] [G loss: 0.837493]\n",
      "epoch:35 step:27568[D loss: 0.395066, acc: 62.50%, op_acc: 46.88%] [G loss: 0.865867]\n",
      "epoch:35 step:27569[D loss: 0.484470, acc: 46.09%, op_acc: 38.28%] [G loss: 0.854469]\n",
      "epoch:35 step:27570[D loss: 0.409285, acc: 59.38%, op_acc: 39.84%] [G loss: 0.905075]\n",
      "epoch:35 step:27571[D loss: 0.419744, acc: 60.94%, op_acc: 36.72%] [G loss: 0.834579]\n",
      "epoch:35 step:27572[D loss: 0.397896, acc: 59.38%, op_acc: 43.75%] [G loss: 0.923338]\n",
      "epoch:35 step:27573[D loss: 0.410694, acc: 66.41%, op_acc: 45.31%] [G loss: 0.891005]\n",
      "epoch:35 step:27574[D loss: 0.387478, acc: 66.41%, op_acc: 40.62%] [G loss: 0.830061]\n",
      "epoch:35 step:27575[D loss: 0.423173, acc: 57.03%, op_acc: 39.84%] [G loss: 0.876313]\n",
      "epoch:35 step:27576[D loss: 0.415739, acc: 55.47%, op_acc: 47.66%] [G loss: 0.919040]\n",
      "epoch:35 step:27577[D loss: 0.393884, acc: 65.62%, op_acc: 42.19%] [G loss: 0.948057]\n",
      "epoch:35 step:27578[D loss: 0.431090, acc: 47.66%, op_acc: 42.97%] [G loss: 0.883115]\n",
      "epoch:35 step:27579[D loss: 0.451512, acc: 50.78%, op_acc: 32.81%] [G loss: 0.901363]\n",
      "epoch:35 step:27580[D loss: 0.453595, acc: 51.56%, op_acc: 42.97%] [G loss: 0.935438]\n",
      "epoch:35 step:27581[D loss: 0.447032, acc: 60.16%, op_acc: 35.16%] [G loss: 0.855447]\n",
      "epoch:35 step:27582[D loss: 0.426778, acc: 59.38%, op_acc: 42.97%] [G loss: 0.861569]\n",
      "epoch:35 step:27583[D loss: 0.426943, acc: 57.03%, op_acc: 35.16%] [G loss: 0.909422]\n",
      "epoch:35 step:27584[D loss: 0.416452, acc: 61.72%, op_acc: 40.62%] [G loss: 0.803968]\n",
      "epoch:35 step:27585[D loss: 0.415357, acc: 63.28%, op_acc: 42.19%] [G loss: 0.868113]\n",
      "epoch:35 step:27586[D loss: 0.374005, acc: 69.53%, op_acc: 49.22%] [G loss: 0.859673]\n",
      "epoch:35 step:27587[D loss: 0.379953, acc: 64.06%, op_acc: 45.31%] [G loss: 0.849972]\n",
      "epoch:35 step:27588[D loss: 0.452466, acc: 57.81%, op_acc: 32.81%] [G loss: 0.826096]\n",
      "epoch:35 step:27589[D loss: 0.422436, acc: 57.03%, op_acc: 40.62%] [G loss: 0.913686]\n",
      "epoch:35 step:27590[D loss: 0.441373, acc: 51.56%, op_acc: 39.06%] [G loss: 0.826959]\n",
      "epoch:35 step:27591[D loss: 0.393431, acc: 61.72%, op_acc: 39.84%] [G loss: 0.852058]\n",
      "epoch:35 step:27592[D loss: 0.426297, acc: 56.25%, op_acc: 39.06%] [G loss: 0.795331]\n",
      "epoch:35 step:27593[D loss: 0.407525, acc: 60.94%, op_acc: 39.06%] [G loss: 0.885732]\n",
      "epoch:35 step:27594[D loss: 0.445995, acc: 59.38%, op_acc: 35.16%] [G loss: 0.881432]\n",
      "epoch:35 step:27595[D loss: 0.453872, acc: 53.12%, op_acc: 35.94%] [G loss: 0.876602]\n",
      "epoch:35 step:27596[D loss: 0.413933, acc: 63.28%, op_acc: 39.84%] [G loss: 0.919372]\n",
      "epoch:35 step:27597[D loss: 0.407685, acc: 62.50%, op_acc: 43.75%] [G loss: 0.915717]\n",
      "epoch:35 step:27598[D loss: 0.407640, acc: 60.94%, op_acc: 40.62%] [G loss: 0.896357]\n",
      "epoch:35 step:27599[D loss: 0.413162, acc: 60.16%, op_acc: 43.75%] [G loss: 0.858849]\n",
      "epoch:35 step:27600[D loss: 0.428552, acc: 50.78%, op_acc: 42.97%] [G loss: 0.892351]\n",
      "##############\n",
      "[0.85421904 0.84572423 0.81135604 0.82874232 0.80083299 0.83877353\n",
      " 0.89003959 0.83686731 0.8065446  0.83612992]\n",
      "##########\n",
      "epoch:35 step:27601[D loss: 0.391407, acc: 65.62%, op_acc: 39.06%] [G loss: 0.953078]\n",
      "epoch:35 step:27602[D loss: 0.414237, acc: 59.38%, op_acc: 37.50%] [G loss: 0.915780]\n",
      "epoch:35 step:27603[D loss: 0.416518, acc: 53.12%, op_acc: 45.31%] [G loss: 0.833069]\n",
      "epoch:35 step:27604[D loss: 0.400842, acc: 67.19%, op_acc: 43.75%] [G loss: 0.939121]\n",
      "epoch:35 step:27605[D loss: 0.412340, acc: 62.50%, op_acc: 42.19%] [G loss: 0.878615]\n",
      "epoch:35 step:27606[D loss: 0.427984, acc: 66.41%, op_acc: 37.50%] [G loss: 0.828086]\n",
      "epoch:35 step:27607[D loss: 0.426130, acc: 63.28%, op_acc: 36.72%] [G loss: 0.911174]\n",
      "epoch:35 step:27608[D loss: 0.410769, acc: 62.50%, op_acc: 41.41%] [G loss: 0.855965]\n",
      "epoch:35 step:27609[D loss: 0.424174, acc: 55.47%, op_acc: 41.41%] [G loss: 0.915699]\n",
      "epoch:35 step:27610[D loss: 0.435633, acc: 55.47%, op_acc: 42.97%] [G loss: 0.888731]\n",
      "epoch:35 step:27611[D loss: 0.435650, acc: 53.91%, op_acc: 42.97%] [G loss: 0.901093]\n",
      "epoch:35 step:27612[D loss: 0.417856, acc: 63.28%, op_acc: 37.50%] [G loss: 0.920451]\n",
      "epoch:35 step:27613[D loss: 0.461211, acc: 47.66%, op_acc: 37.50%] [G loss: 0.920236]\n",
      "epoch:35 step:27614[D loss: 0.400810, acc: 64.84%, op_acc: 39.06%] [G loss: 0.812972]\n",
      "epoch:35 step:27615[D loss: 0.431824, acc: 55.47%, op_acc: 39.06%] [G loss: 0.883012]\n",
      "epoch:35 step:27616[D loss: 0.425554, acc: 56.25%, op_acc: 35.94%] [G loss: 0.838596]\n",
      "epoch:35 step:27617[D loss: 0.437829, acc: 56.25%, op_acc: 35.16%] [G loss: 0.807353]\n",
      "epoch:35 step:27618[D loss: 0.412283, acc: 61.72%, op_acc: 41.41%] [G loss: 0.889100]\n",
      "epoch:35 step:27619[D loss: 0.405423, acc: 60.94%, op_acc: 39.06%] [G loss: 0.912149]\n",
      "epoch:35 step:27620[D loss: 0.398515, acc: 68.75%, op_acc: 40.62%] [G loss: 0.952321]\n",
      "epoch:35 step:27621[D loss: 0.433781, acc: 59.38%, op_acc: 37.50%] [G loss: 0.978386]\n",
      "epoch:35 step:27622[D loss: 0.440402, acc: 55.47%, op_acc: 42.19%] [G loss: 0.905226]\n",
      "epoch:35 step:27623[D loss: 0.381333, acc: 67.19%, op_acc: 41.41%] [G loss: 0.967471]\n",
      "epoch:35 step:27624[D loss: 0.463943, acc: 47.66%, op_acc: 34.38%] [G loss: 0.844273]\n",
      "epoch:35 step:27625[D loss: 0.394807, acc: 64.84%, op_acc: 40.62%] [G loss: 0.849020]\n",
      "epoch:35 step:27626[D loss: 0.405323, acc: 71.88%, op_acc: 40.62%] [G loss: 0.907578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27627[D loss: 0.432499, acc: 62.50%, op_acc: 37.50%] [G loss: 0.827150]\n",
      "epoch:35 step:27628[D loss: 0.413605, acc: 60.94%, op_acc: 42.97%] [G loss: 0.830903]\n",
      "epoch:35 step:27629[D loss: 0.444904, acc: 57.81%, op_acc: 42.19%] [G loss: 0.894831]\n",
      "epoch:35 step:27630[D loss: 0.431226, acc: 58.59%, op_acc: 39.84%] [G loss: 0.894770]\n",
      "epoch:35 step:27631[D loss: 0.402600, acc: 61.72%, op_acc: 44.53%] [G loss: 0.923927]\n",
      "epoch:35 step:27632[D loss: 0.435010, acc: 60.16%, op_acc: 35.16%] [G loss: 0.847360]\n",
      "epoch:35 step:27633[D loss: 0.420749, acc: 62.50%, op_acc: 38.28%] [G loss: 0.832763]\n",
      "epoch:35 step:27634[D loss: 0.421291, acc: 57.81%, op_acc: 41.41%] [G loss: 0.952788]\n",
      "epoch:35 step:27635[D loss: 0.454762, acc: 52.34%, op_acc: 33.59%] [G loss: 0.796829]\n",
      "epoch:35 step:27636[D loss: 0.399962, acc: 62.50%, op_acc: 42.19%] [G loss: 0.900912]\n",
      "epoch:35 step:27637[D loss: 0.443947, acc: 58.59%, op_acc: 37.50%] [G loss: 0.820319]\n",
      "epoch:35 step:27638[D loss: 0.444900, acc: 56.25%, op_acc: 38.28%] [G loss: 0.833872]\n",
      "epoch:35 step:27639[D loss: 0.387765, acc: 66.41%, op_acc: 44.53%] [G loss: 0.917245]\n",
      "epoch:35 step:27640[D loss: 0.405885, acc: 65.62%, op_acc: 35.94%] [G loss: 0.889624]\n",
      "epoch:35 step:27641[D loss: 0.420526, acc: 60.16%, op_acc: 37.50%] [G loss: 0.862014]\n",
      "epoch:35 step:27642[D loss: 0.411781, acc: 51.56%, op_acc: 42.97%] [G loss: 0.919192]\n",
      "epoch:35 step:27643[D loss: 0.413832, acc: 64.84%, op_acc: 35.94%] [G loss: 0.825762]\n",
      "epoch:35 step:27644[D loss: 0.471638, acc: 54.69%, op_acc: 32.03%] [G loss: 0.885128]\n",
      "epoch:35 step:27645[D loss: 0.447597, acc: 52.34%, op_acc: 35.94%] [G loss: 0.888850]\n",
      "epoch:35 step:27646[D loss: 0.451268, acc: 49.22%, op_acc: 40.62%] [G loss: 0.874605]\n",
      "epoch:35 step:27647[D loss: 0.423366, acc: 56.25%, op_acc: 41.41%] [G loss: 0.908993]\n",
      "epoch:35 step:27648[D loss: 0.421367, acc: 55.47%, op_acc: 45.31%] [G loss: 0.854548]\n",
      "epoch:35 step:27649[D loss: 0.415532, acc: 64.06%, op_acc: 39.06%] [G loss: 0.894785]\n",
      "epoch:35 step:27650[D loss: 0.427135, acc: 54.69%, op_acc: 44.53%] [G loss: 0.819847]\n",
      "##############\n",
      "[0.85545867 0.86774627 0.81781921 0.79956442 0.80420755 0.83730571\n",
      " 0.86562627 0.82444346 0.80492241 0.8073786 ]\n",
      "##########\n",
      "epoch:35 step:27651[D loss: 0.405316, acc: 63.28%, op_acc: 36.72%] [G loss: 0.860386]\n",
      "epoch:35 step:27652[D loss: 0.442249, acc: 53.91%, op_acc: 37.50%] [G loss: 0.784049]\n",
      "epoch:35 step:27653[D loss: 0.445636, acc: 50.78%, op_acc: 39.06%] [G loss: 0.851325]\n",
      "epoch:35 step:27654[D loss: 0.426542, acc: 57.81%, op_acc: 39.84%] [G loss: 0.846724]\n",
      "epoch:35 step:27655[D loss: 0.419044, acc: 64.84%, op_acc: 37.50%] [G loss: 0.869144]\n",
      "epoch:35 step:27656[D loss: 0.443298, acc: 55.47%, op_acc: 42.19%] [G loss: 0.974803]\n",
      "epoch:35 step:27657[D loss: 0.420286, acc: 61.72%, op_acc: 39.06%] [G loss: 0.881406]\n",
      "epoch:35 step:27658[D loss: 0.415027, acc: 60.94%, op_acc: 42.19%] [G loss: 0.823863]\n",
      "epoch:35 step:27659[D loss: 0.444596, acc: 56.25%, op_acc: 37.50%] [G loss: 0.840826]\n",
      "epoch:35 step:27660[D loss: 0.407801, acc: 60.16%, op_acc: 37.50%] [G loss: 0.812944]\n",
      "epoch:35 step:27661[D loss: 0.411278, acc: 59.38%, op_acc: 42.19%] [G loss: 0.820734]\n",
      "epoch:35 step:27662[D loss: 0.402927, acc: 61.72%, op_acc: 37.50%] [G loss: 0.865501]\n",
      "epoch:35 step:27663[D loss: 0.443296, acc: 58.59%, op_acc: 39.06%] [G loss: 0.821184]\n",
      "epoch:35 step:27664[D loss: 0.404528, acc: 63.28%, op_acc: 43.75%] [G loss: 0.847101]\n",
      "epoch:35 step:27665[D loss: 0.422793, acc: 55.47%, op_acc: 41.41%] [G loss: 0.878011]\n",
      "epoch:35 step:27666[D loss: 0.426066, acc: 49.22%, op_acc: 36.72%] [G loss: 0.915116]\n",
      "epoch:35 step:27667[D loss: 0.422763, acc: 53.12%, op_acc: 41.41%] [G loss: 0.837708]\n",
      "epoch:35 step:27668[D loss: 0.402392, acc: 67.19%, op_acc: 42.97%] [G loss: 0.914565]\n",
      "epoch:35 step:27669[D loss: 0.395835, acc: 63.28%, op_acc: 44.53%] [G loss: 0.878810]\n",
      "epoch:35 step:27670[D loss: 0.381293, acc: 72.66%, op_acc: 40.62%] [G loss: 0.924527]\n",
      "epoch:35 step:27671[D loss: 0.441130, acc: 57.81%, op_acc: 33.59%] [G loss: 0.890182]\n",
      "epoch:35 step:27672[D loss: 0.417503, acc: 61.72%, op_acc: 37.50%] [G loss: 0.934864]\n",
      "epoch:35 step:27673[D loss: 0.398157, acc: 64.84%, op_acc: 41.41%] [G loss: 0.871857]\n",
      "epoch:35 step:27674[D loss: 0.412017, acc: 64.06%, op_acc: 39.06%] [G loss: 0.919520]\n",
      "epoch:35 step:27675[D loss: 0.405694, acc: 62.50%, op_acc: 41.41%] [G loss: 0.889812]\n",
      "epoch:35 step:27676[D loss: 0.418059, acc: 62.50%, op_acc: 34.38%] [G loss: 0.854264]\n",
      "epoch:35 step:27677[D loss: 0.441087, acc: 49.22%, op_acc: 39.84%] [G loss: 0.903560]\n",
      "epoch:35 step:27678[D loss: 0.429167, acc: 60.94%, op_acc: 39.84%] [G loss: 0.874372]\n",
      "epoch:35 step:27679[D loss: 0.392852, acc: 67.97%, op_acc: 43.75%] [G loss: 0.915770]\n",
      "epoch:35 step:27680[D loss: 0.398092, acc: 67.97%, op_acc: 40.62%] [G loss: 0.902191]\n",
      "epoch:35 step:27681[D loss: 0.415621, acc: 57.03%, op_acc: 43.75%] [G loss: 0.889420]\n",
      "epoch:35 step:27682[D loss: 0.417363, acc: 57.81%, op_acc: 40.62%] [G loss: 0.878522]\n",
      "epoch:35 step:27683[D loss: 0.423515, acc: 61.72%, op_acc: 42.97%] [G loss: 0.777610]\n",
      "epoch:35 step:27684[D loss: 0.391033, acc: 60.94%, op_acc: 44.53%] [G loss: 0.788802]\n",
      "epoch:35 step:27685[D loss: 0.423688, acc: 58.59%, op_acc: 42.19%] [G loss: 0.897655]\n",
      "epoch:35 step:27686[D loss: 0.399049, acc: 60.16%, op_acc: 39.84%] [G loss: 0.962058]\n",
      "epoch:35 step:27687[D loss: 0.406825, acc: 71.09%, op_acc: 39.84%] [G loss: 0.841475]\n",
      "epoch:35 step:27688[D loss: 0.429057, acc: 55.47%, op_acc: 40.62%] [G loss: 0.858670]\n",
      "epoch:35 step:27689[D loss: 0.387699, acc: 60.16%, op_acc: 45.31%] [G loss: 0.955985]\n",
      "epoch:35 step:27690[D loss: 0.418039, acc: 57.81%, op_acc: 44.53%] [G loss: 0.874979]\n",
      "epoch:35 step:27691[D loss: 0.408887, acc: 57.81%, op_acc: 47.66%] [G loss: 0.845589]\n",
      "epoch:35 step:27692[D loss: 0.411419, acc: 65.62%, op_acc: 40.62%] [G loss: 0.865549]\n",
      "epoch:35 step:27693[D loss: 0.451330, acc: 54.69%, op_acc: 39.06%] [G loss: 0.917879]\n",
      "epoch:35 step:27694[D loss: 0.428477, acc: 53.91%, op_acc: 40.62%] [G loss: 0.863431]\n",
      "epoch:35 step:27695[D loss: 0.418705, acc: 59.38%, op_acc: 42.97%] [G loss: 0.850806]\n",
      "epoch:35 step:27696[D loss: 0.414537, acc: 59.38%, op_acc: 42.19%] [G loss: 0.941902]\n",
      "epoch:35 step:27697[D loss: 0.410322, acc: 57.03%, op_acc: 41.41%] [G loss: 0.820751]\n",
      "epoch:35 step:27698[D loss: 0.415793, acc: 62.50%, op_acc: 41.41%] [G loss: 0.924483]\n",
      "epoch:35 step:27699[D loss: 0.439536, acc: 51.56%, op_acc: 42.19%] [G loss: 0.933720]\n",
      "epoch:35 step:27700[D loss: 0.379706, acc: 67.97%, op_acc: 43.75%] [G loss: 0.907636]\n",
      "##############\n",
      "[0.85275744 0.86656546 0.82451491 0.78802053 0.80374415 0.84981704\n",
      " 0.87787405 0.83267734 0.81375722 0.86537893]\n",
      "##########\n",
      "epoch:35 step:27701[D loss: 0.404494, acc: 58.59%, op_acc: 44.53%] [G loss: 0.889247]\n",
      "epoch:35 step:27702[D loss: 0.416111, acc: 64.06%, op_acc: 39.06%] [G loss: 1.027140]\n",
      "epoch:35 step:27703[D loss: 0.446110, acc: 53.91%, op_acc: 37.50%] [G loss: 0.809570]\n",
      "epoch:35 step:27704[D loss: 0.436251, acc: 58.59%, op_acc: 34.38%] [G loss: 0.875320]\n",
      "epoch:35 step:27705[D loss: 0.427942, acc: 61.72%, op_acc: 40.62%] [G loss: 0.906945]\n",
      "epoch:35 step:27706[D loss: 0.402258, acc: 55.47%, op_acc: 48.44%] [G loss: 0.907232]\n",
      "epoch:35 step:27707[D loss: 0.414965, acc: 53.91%, op_acc: 40.62%] [G loss: 0.922986]\n",
      "epoch:35 step:27708[D loss: 0.403931, acc: 59.38%, op_acc: 41.41%] [G loss: 0.801150]\n",
      "epoch:35 step:27709[D loss: 0.443354, acc: 50.00%, op_acc: 40.62%] [G loss: 0.918045]\n",
      "epoch:35 step:27710[D loss: 0.454351, acc: 53.91%, op_acc: 37.50%] [G loss: 0.781456]\n",
      "epoch:35 step:27711[D loss: 0.431422, acc: 54.69%, op_acc: 36.72%] [G loss: 0.788681]\n",
      "epoch:35 step:27712[D loss: 0.455968, acc: 47.66%, op_acc: 39.06%] [G loss: 0.843486]\n",
      "epoch:35 step:27713[D loss: 0.417285, acc: 60.16%, op_acc: 43.75%] [G loss: 0.991849]\n",
      "epoch:35 step:27714[D loss: 0.413804, acc: 61.72%, op_acc: 42.97%] [G loss: 0.979524]\n",
      "epoch:35 step:27715[D loss: 0.408397, acc: 66.41%, op_acc: 42.97%] [G loss: 0.915956]\n",
      "epoch:35 step:27716[D loss: 0.401852, acc: 69.53%, op_acc: 42.19%] [G loss: 0.941226]\n",
      "epoch:35 step:27717[D loss: 0.409433, acc: 65.62%, op_acc: 43.75%] [G loss: 0.951912]\n",
      "epoch:35 step:27718[D loss: 0.406629, acc: 56.25%, op_acc: 42.97%] [G loss: 0.961745]\n",
      "epoch:35 step:27719[D loss: 0.435849, acc: 57.81%, op_acc: 41.41%] [G loss: 0.966036]\n",
      "epoch:35 step:27720[D loss: 0.398955, acc: 59.38%, op_acc: 45.31%] [G loss: 0.908704]\n",
      "epoch:35 step:27721[D loss: 0.420880, acc: 57.81%, op_acc: 44.53%] [G loss: 0.888308]\n",
      "epoch:35 step:27722[D loss: 0.428184, acc: 59.38%, op_acc: 42.19%] [G loss: 0.873361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27723[D loss: 0.432908, acc: 58.59%, op_acc: 37.50%] [G loss: 0.906754]\n",
      "epoch:35 step:27724[D loss: 0.432549, acc: 57.03%, op_acc: 43.75%] [G loss: 0.832259]\n",
      "epoch:35 step:27725[D loss: 0.407703, acc: 62.50%, op_acc: 39.06%] [G loss: 0.980418]\n",
      "epoch:35 step:27726[D loss: 0.401455, acc: 59.38%, op_acc: 42.19%] [G loss: 0.902898]\n",
      "epoch:35 step:27727[D loss: 0.395904, acc: 60.16%, op_acc: 46.88%] [G loss: 0.933996]\n",
      "epoch:35 step:27728[D loss: 0.422795, acc: 61.72%, op_acc: 41.41%] [G loss: 0.997177]\n",
      "epoch:35 step:27729[D loss: 0.436698, acc: 49.22%, op_acc: 38.28%] [G loss: 0.830949]\n",
      "epoch:35 step:27730[D loss: 0.437294, acc: 57.03%, op_acc: 36.72%] [G loss: 0.914157]\n",
      "epoch:35 step:27731[D loss: 0.433668, acc: 56.25%, op_acc: 43.75%] [G loss: 0.804906]\n",
      "epoch:35 step:27732[D loss: 0.438967, acc: 48.44%, op_acc: 42.19%] [G loss: 0.858807]\n",
      "epoch:35 step:27733[D loss: 0.418789, acc: 60.16%, op_acc: 42.19%] [G loss: 0.804241]\n",
      "epoch:35 step:27734[D loss: 0.399124, acc: 63.28%, op_acc: 39.84%] [G loss: 0.970809]\n",
      "epoch:35 step:27735[D loss: 0.415879, acc: 55.47%, op_acc: 41.41%] [G loss: 0.835446]\n",
      "epoch:35 step:27736[D loss: 0.415356, acc: 56.25%, op_acc: 41.41%] [G loss: 0.889683]\n",
      "epoch:35 step:27737[D loss: 0.405808, acc: 61.72%, op_acc: 41.41%] [G loss: 0.938904]\n",
      "epoch:35 step:27738[D loss: 0.410777, acc: 64.06%, op_acc: 37.50%] [G loss: 0.942186]\n",
      "epoch:35 step:27739[D loss: 0.407901, acc: 57.81%, op_acc: 49.22%] [G loss: 0.905712]\n",
      "epoch:35 step:27740[D loss: 0.436249, acc: 57.03%, op_acc: 39.06%] [G loss: 0.866785]\n",
      "epoch:35 step:27741[D loss: 0.409460, acc: 57.03%, op_acc: 43.75%] [G loss: 0.841365]\n",
      "epoch:35 step:27742[D loss: 0.435649, acc: 57.81%, op_acc: 37.50%] [G loss: 0.940562]\n",
      "epoch:35 step:27743[D loss: 0.418892, acc: 52.34%, op_acc: 42.19%] [G loss: 0.914338]\n",
      "epoch:35 step:27744[D loss: 0.435030, acc: 58.59%, op_acc: 47.66%] [G loss: 0.903238]\n",
      "epoch:35 step:27745[D loss: 0.450058, acc: 53.91%, op_acc: 35.94%] [G loss: 0.828676]\n",
      "epoch:35 step:27746[D loss: 0.409479, acc: 60.94%, op_acc: 40.62%] [G loss: 0.918333]\n",
      "epoch:35 step:27747[D loss: 0.397961, acc: 61.72%, op_acc: 44.53%] [G loss: 0.906376]\n",
      "epoch:35 step:27748[D loss: 0.401997, acc: 60.94%, op_acc: 47.66%] [G loss: 0.837445]\n",
      "epoch:35 step:27749[D loss: 0.426091, acc: 55.47%, op_acc: 43.75%] [G loss: 0.823155]\n",
      "epoch:35 step:27750[D loss: 0.407571, acc: 60.94%, op_acc: 42.19%] [G loss: 0.933550]\n",
      "##############\n",
      "[0.86860071 0.86666705 0.80594786 0.80289931 0.7924067  0.8290375\n",
      " 0.89067732 0.83151384 0.81627758 0.86576753]\n",
      "##########\n",
      "epoch:35 step:27751[D loss: 0.437497, acc: 59.38%, op_acc: 39.84%] [G loss: 0.868528]\n",
      "epoch:35 step:27752[D loss: 0.401510, acc: 65.62%, op_acc: 42.19%] [G loss: 0.809463]\n",
      "epoch:35 step:27753[D loss: 0.424688, acc: 59.38%, op_acc: 37.50%] [G loss: 0.987207]\n",
      "epoch:35 step:27754[D loss: 0.424732, acc: 56.25%, op_acc: 39.06%] [G loss: 0.945692]\n",
      "epoch:35 step:27755[D loss: 0.447823, acc: 57.03%, op_acc: 39.84%] [G loss: 0.926944]\n",
      "epoch:35 step:27756[D loss: 0.403183, acc: 61.72%, op_acc: 41.41%] [G loss: 0.877787]\n",
      "epoch:35 step:27757[D loss: 0.423688, acc: 56.25%, op_acc: 40.62%] [G loss: 0.918989]\n",
      "epoch:35 step:27758[D loss: 0.417605, acc: 59.38%, op_acc: 40.62%] [G loss: 0.866916]\n",
      "epoch:35 step:27759[D loss: 0.424166, acc: 63.28%, op_acc: 39.84%] [G loss: 0.868844]\n",
      "epoch:35 step:27760[D loss: 0.447001, acc: 57.81%, op_acc: 37.50%] [G loss: 0.848472]\n",
      "epoch:35 step:27761[D loss: 0.435602, acc: 58.59%, op_acc: 37.50%] [G loss: 0.881880]\n",
      "epoch:35 step:27762[D loss: 0.405676, acc: 66.41%, op_acc: 36.72%] [G loss: 0.920564]\n",
      "epoch:35 step:27763[D loss: 0.394936, acc: 55.47%, op_acc: 46.88%] [G loss: 0.958746]\n",
      "epoch:35 step:27764[D loss: 0.414751, acc: 56.25%, op_acc: 42.97%] [G loss: 0.842540]\n",
      "epoch:35 step:27765[D loss: 0.422224, acc: 57.81%, op_acc: 41.41%] [G loss: 0.848560]\n",
      "epoch:35 step:27766[D loss: 0.450984, acc: 50.78%, op_acc: 35.16%] [G loss: 0.811996]\n",
      "epoch:35 step:27767[D loss: 0.397306, acc: 60.16%, op_acc: 39.84%] [G loss: 0.955331]\n",
      "epoch:35 step:27768[D loss: 0.428057, acc: 54.69%, op_acc: 41.41%] [G loss: 0.798334]\n",
      "epoch:35 step:27769[D loss: 0.398284, acc: 60.16%, op_acc: 43.75%] [G loss: 0.891365]\n",
      "epoch:35 step:27770[D loss: 0.414047, acc: 54.69%, op_acc: 45.31%] [G loss: 0.877558]\n",
      "epoch:35 step:27771[D loss: 0.442843, acc: 59.38%, op_acc: 36.72%] [G loss: 0.822453]\n",
      "epoch:35 step:27772[D loss: 0.425319, acc: 60.94%, op_acc: 36.72%] [G loss: 0.858629]\n",
      "epoch:35 step:27773[D loss: 0.429404, acc: 53.91%, op_acc: 41.41%] [G loss: 0.846551]\n",
      "epoch:35 step:27774[D loss: 0.435809, acc: 55.47%, op_acc: 35.16%] [G loss: 0.887925]\n",
      "epoch:35 step:27775[D loss: 0.421939, acc: 61.72%, op_acc: 34.38%] [G loss: 0.911134]\n",
      "epoch:35 step:27776[D loss: 0.412834, acc: 61.72%, op_acc: 42.19%] [G loss: 0.901584]\n",
      "epoch:35 step:27777[D loss: 0.419137, acc: 60.94%, op_acc: 41.41%] [G loss: 0.960934]\n",
      "epoch:35 step:27778[D loss: 0.411235, acc: 65.62%, op_acc: 37.50%] [G loss: 0.870960]\n",
      "epoch:35 step:27779[D loss: 0.405713, acc: 60.94%, op_acc: 41.41%] [G loss: 0.884366]\n",
      "epoch:35 step:27780[D loss: 0.443298, acc: 50.00%, op_acc: 33.59%] [G loss: 0.882433]\n",
      "epoch:35 step:27781[D loss: 0.454212, acc: 48.44%, op_acc: 39.06%] [G loss: 0.953767]\n",
      "epoch:35 step:27782[D loss: 0.404585, acc: 65.62%, op_acc: 31.25%] [G loss: 0.989983]\n",
      "epoch:35 step:27783[D loss: 0.385600, acc: 67.19%, op_acc: 41.41%] [G loss: 0.951878]\n",
      "epoch:35 step:27784[D loss: 0.391946, acc: 67.97%, op_acc: 41.41%] [G loss: 0.905674]\n",
      "epoch:35 step:27785[D loss: 0.386391, acc: 67.97%, op_acc: 43.75%] [G loss: 0.961747]\n",
      "epoch:35 step:27786[D loss: 0.411511, acc: 55.47%, op_acc: 43.75%] [G loss: 0.945916]\n",
      "epoch:35 step:27787[D loss: 0.376717, acc: 67.97%, op_acc: 43.75%] [G loss: 0.881700]\n",
      "epoch:35 step:27788[D loss: 0.436530, acc: 57.81%, op_acc: 39.84%] [G loss: 0.911267]\n",
      "epoch:35 step:27789[D loss: 0.407286, acc: 63.28%, op_acc: 44.53%] [G loss: 0.890867]\n",
      "epoch:35 step:27790[D loss: 0.418379, acc: 58.59%, op_acc: 42.97%] [G loss: 0.873065]\n",
      "epoch:35 step:27791[D loss: 0.441185, acc: 61.72%, op_acc: 36.72%] [G loss: 0.892988]\n",
      "epoch:35 step:27792[D loss: 0.434140, acc: 59.38%, op_acc: 38.28%] [G loss: 0.903819]\n",
      "epoch:35 step:27793[D loss: 0.426831, acc: 56.25%, op_acc: 42.97%] [G loss: 0.852541]\n",
      "epoch:35 step:27794[D loss: 0.415367, acc: 56.25%, op_acc: 46.88%] [G loss: 0.831140]\n",
      "epoch:35 step:27795[D loss: 0.404581, acc: 55.47%, op_acc: 46.88%] [G loss: 0.842957]\n",
      "epoch:35 step:27796[D loss: 0.445611, acc: 49.22%, op_acc: 38.28%] [G loss: 0.879831]\n",
      "epoch:35 step:27797[D loss: 0.424564, acc: 59.38%, op_acc: 40.62%] [G loss: 0.890549]\n",
      "epoch:35 step:27798[D loss: 0.434069, acc: 50.00%, op_acc: 41.41%] [G loss: 0.870148]\n",
      "epoch:35 step:27799[D loss: 0.436660, acc: 61.72%, op_acc: 37.50%] [G loss: 0.897268]\n",
      "epoch:35 step:27800[D loss: 0.385396, acc: 66.41%, op_acc: 49.22%] [G loss: 0.927117]\n",
      "##############\n",
      "[0.87035879 0.86022831 0.80694731 0.78735422 0.80744166 0.83661086\n",
      " 0.89824606 0.81158104 0.81442333 0.83484217]\n",
      "##########\n",
      "epoch:35 step:27801[D loss: 0.415991, acc: 58.59%, op_acc: 41.41%] [G loss: 0.874481]\n",
      "epoch:35 step:27802[D loss: 0.440404, acc: 50.78%, op_acc: 38.28%] [G loss: 0.806378]\n",
      "epoch:35 step:27803[D loss: 0.401443, acc: 59.38%, op_acc: 42.19%] [G loss: 0.902525]\n",
      "epoch:35 step:27804[D loss: 0.379124, acc: 66.41%, op_acc: 40.62%] [G loss: 0.887972]\n",
      "epoch:35 step:27805[D loss: 0.396423, acc: 68.75%, op_acc: 39.84%] [G loss: 0.894078]\n",
      "epoch:35 step:27806[D loss: 0.414221, acc: 65.62%, op_acc: 38.28%] [G loss: 0.896909]\n",
      "epoch:35 step:27807[D loss: 0.419800, acc: 66.41%, op_acc: 30.47%] [G loss: 0.888890]\n",
      "epoch:35 step:27808[D loss: 0.407704, acc: 59.38%, op_acc: 46.88%] [G loss: 0.907566]\n",
      "epoch:35 step:27809[D loss: 0.411953, acc: 57.03%, op_acc: 39.06%] [G loss: 0.833529]\n",
      "epoch:35 step:27810[D loss: 0.426266, acc: 53.12%, op_acc: 38.28%] [G loss: 0.842295]\n",
      "epoch:35 step:27811[D loss: 0.424952, acc: 60.16%, op_acc: 37.50%] [G loss: 0.944534]\n",
      "epoch:35 step:27812[D loss: 0.450014, acc: 60.94%, op_acc: 42.19%] [G loss: 0.857636]\n",
      "epoch:35 step:27813[D loss: 0.364304, acc: 67.97%, op_acc: 49.22%] [G loss: 0.911311]\n",
      "epoch:35 step:27814[D loss: 0.404929, acc: 63.28%, op_acc: 40.62%] [G loss: 0.928622]\n",
      "epoch:35 step:27815[D loss: 0.461826, acc: 53.12%, op_acc: 35.94%] [G loss: 0.828607]\n",
      "epoch:35 step:27816[D loss: 0.418824, acc: 65.62%, op_acc: 42.19%] [G loss: 0.911306]\n",
      "epoch:35 step:27817[D loss: 0.414366, acc: 66.41%, op_acc: 40.62%] [G loss: 0.929765]\n",
      "epoch:35 step:27818[D loss: 0.410489, acc: 57.81%, op_acc: 42.97%] [G loss: 0.907298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27819[D loss: 0.425645, acc: 55.47%, op_acc: 46.09%] [G loss: 0.904369]\n",
      "epoch:35 step:27820[D loss: 0.423368, acc: 57.81%, op_acc: 38.28%] [G loss: 0.903656]\n",
      "epoch:35 step:27821[D loss: 0.400948, acc: 54.69%, op_acc: 42.19%] [G loss: 0.887145]\n",
      "epoch:35 step:27822[D loss: 0.421829, acc: 60.94%, op_acc: 41.41%] [G loss: 0.946086]\n",
      "epoch:35 step:27823[D loss: 0.399601, acc: 69.53%, op_acc: 42.19%] [G loss: 0.917433]\n",
      "epoch:35 step:27824[D loss: 0.436803, acc: 58.59%, op_acc: 42.97%] [G loss: 0.937867]\n",
      "epoch:35 step:27825[D loss: 0.373002, acc: 64.84%, op_acc: 46.09%] [G loss: 0.883501]\n",
      "epoch:35 step:27826[D loss: 0.480490, acc: 45.31%, op_acc: 37.50%] [G loss: 0.853004]\n",
      "epoch:35 step:27827[D loss: 0.414488, acc: 62.50%, op_acc: 42.19%] [G loss: 0.941581]\n",
      "epoch:35 step:27828[D loss: 0.423614, acc: 59.38%, op_acc: 39.84%] [G loss: 0.865141]\n",
      "epoch:35 step:27829[D loss: 0.408583, acc: 59.38%, op_acc: 39.84%] [G loss: 0.847482]\n",
      "epoch:35 step:27830[D loss: 0.416469, acc: 63.28%, op_acc: 42.19%] [G loss: 0.883888]\n",
      "epoch:35 step:27831[D loss: 0.435358, acc: 53.91%, op_acc: 41.41%] [G loss: 0.879637]\n",
      "epoch:35 step:27832[D loss: 0.437591, acc: 62.50%, op_acc: 40.62%] [G loss: 0.857420]\n",
      "epoch:35 step:27833[D loss: 0.439018, acc: 57.81%, op_acc: 46.09%] [G loss: 0.872480]\n",
      "epoch:35 step:27834[D loss: 0.416702, acc: 63.28%, op_acc: 39.84%] [G loss: 0.955983]\n",
      "epoch:35 step:27835[D loss: 0.414813, acc: 58.59%, op_acc: 36.72%] [G loss: 0.889248]\n",
      "epoch:35 step:27836[D loss: 0.419816, acc: 60.94%, op_acc: 41.41%] [G loss: 0.899836]\n",
      "epoch:35 step:27837[D loss: 0.413380, acc: 59.38%, op_acc: 42.97%] [G loss: 0.838015]\n",
      "epoch:35 step:27838[D loss: 0.432085, acc: 54.69%, op_acc: 39.06%] [G loss: 0.893431]\n",
      "epoch:35 step:27839[D loss: 0.450357, acc: 53.91%, op_acc: 37.50%] [G loss: 0.909899]\n",
      "epoch:35 step:27840[D loss: 0.429109, acc: 61.72%, op_acc: 38.28%] [G loss: 0.863230]\n",
      "epoch:35 step:27841[D loss: 0.412734, acc: 62.50%, op_acc: 41.41%] [G loss: 0.867245]\n",
      "epoch:35 step:27842[D loss: 0.396216, acc: 64.06%, op_acc: 43.75%] [G loss: 0.966578]\n",
      "epoch:35 step:27843[D loss: 0.426207, acc: 57.81%, op_acc: 39.84%] [G loss: 0.849996]\n",
      "epoch:35 step:27844[D loss: 0.455883, acc: 57.03%, op_acc: 34.38%] [G loss: 0.912891]\n",
      "epoch:35 step:27845[D loss: 0.409376, acc: 61.72%, op_acc: 42.19%] [G loss: 0.899950]\n",
      "epoch:35 step:27846[D loss: 0.428793, acc: 58.59%, op_acc: 43.75%] [G loss: 0.854003]\n",
      "epoch:35 step:27847[D loss: 0.429607, acc: 54.69%, op_acc: 36.72%] [G loss: 0.889866]\n",
      "epoch:35 step:27848[D loss: 0.412789, acc: 60.16%, op_acc: 37.50%] [G loss: 0.843400]\n",
      "epoch:35 step:27849[D loss: 0.451925, acc: 51.56%, op_acc: 37.50%] [G loss: 0.840681]\n",
      "epoch:35 step:27850[D loss: 0.407155, acc: 64.84%, op_acc: 38.28%] [G loss: 0.823851]\n",
      "##############\n",
      "[0.83654557 0.86268194 0.82052829 0.7868822  0.80093676 0.81498983\n",
      " 0.90084447 0.84661018 0.8232248  0.80684588]\n",
      "##########\n",
      "epoch:35 step:27851[D loss: 0.430274, acc: 60.94%, op_acc: 39.84%] [G loss: 0.831343]\n",
      "epoch:35 step:27852[D loss: 0.441163, acc: 53.12%, op_acc: 43.75%] [G loss: 0.870358]\n",
      "epoch:35 step:27853[D loss: 0.390869, acc: 66.41%, op_acc: 44.53%] [G loss: 0.931822]\n",
      "epoch:35 step:27854[D loss: 0.400543, acc: 62.50%, op_acc: 40.62%] [G loss: 0.975768]\n",
      "epoch:35 step:27855[D loss: 0.436038, acc: 50.00%, op_acc: 38.28%] [G loss: 0.809435]\n",
      "epoch:35 step:27856[D loss: 0.410765, acc: 60.16%, op_acc: 39.06%] [G loss: 0.847721]\n",
      "epoch:35 step:27857[D loss: 0.459710, acc: 53.12%, op_acc: 32.81%] [G loss: 0.840926]\n",
      "epoch:35 step:27858[D loss: 0.403281, acc: 67.19%, op_acc: 42.97%] [G loss: 0.883577]\n",
      "epoch:35 step:27859[D loss: 0.402911, acc: 64.06%, op_acc: 39.06%] [G loss: 0.897961]\n",
      "epoch:35 step:27860[D loss: 0.409968, acc: 60.16%, op_acc: 41.41%] [G loss: 0.926649]\n",
      "epoch:35 step:27861[D loss: 0.444327, acc: 59.38%, op_acc: 37.50%] [G loss: 0.887770]\n",
      "epoch:35 step:27862[D loss: 0.410006, acc: 64.06%, op_acc: 34.38%] [G loss: 0.914553]\n",
      "epoch:35 step:27863[D loss: 0.396650, acc: 60.16%, op_acc: 43.75%] [G loss: 0.973500]\n",
      "epoch:35 step:27864[D loss: 0.393914, acc: 60.94%, op_acc: 47.66%] [G loss: 0.952403]\n",
      "epoch:35 step:27865[D loss: 0.412758, acc: 64.06%, op_acc: 39.84%] [G loss: 0.952056]\n",
      "epoch:35 step:27866[D loss: 0.417090, acc: 59.38%, op_acc: 39.06%] [G loss: 0.935960]\n",
      "epoch:35 step:27867[D loss: 0.405687, acc: 60.16%, op_acc: 40.62%] [G loss: 0.902630]\n",
      "epoch:35 step:27868[D loss: 0.405249, acc: 56.25%, op_acc: 44.53%] [G loss: 0.863838]\n",
      "epoch:35 step:27869[D loss: 0.399156, acc: 64.06%, op_acc: 46.88%] [G loss: 0.923284]\n",
      "epoch:35 step:27870[D loss: 0.434043, acc: 60.94%, op_acc: 39.06%] [G loss: 0.866538]\n",
      "epoch:35 step:27871[D loss: 0.403590, acc: 59.38%, op_acc: 44.53%] [G loss: 0.974306]\n",
      "epoch:35 step:27872[D loss: 0.433701, acc: 53.91%, op_acc: 38.28%] [G loss: 0.872846]\n",
      "epoch:35 step:27873[D loss: 0.400996, acc: 62.50%, op_acc: 44.53%] [G loss: 0.936834]\n",
      "epoch:35 step:27874[D loss: 0.403090, acc: 60.16%, op_acc: 39.84%] [G loss: 0.912079]\n",
      "epoch:35 step:27875[D loss: 0.399983, acc: 60.16%, op_acc: 40.62%] [G loss: 0.954576]\n",
      "epoch:35 step:27876[D loss: 0.388738, acc: 66.41%, op_acc: 49.22%] [G loss: 0.914997]\n",
      "epoch:35 step:27877[D loss: 0.420504, acc: 65.62%, op_acc: 35.94%] [G loss: 0.848354]\n",
      "epoch:35 step:27878[D loss: 0.419427, acc: 62.50%, op_acc: 38.28%] [G loss: 0.872608]\n",
      "epoch:35 step:27879[D loss: 0.396168, acc: 66.41%, op_acc: 43.75%] [G loss: 0.937633]\n",
      "epoch:35 step:27880[D loss: 0.391933, acc: 68.75%, op_acc: 38.28%] [G loss: 0.852424]\n",
      "epoch:35 step:27881[D loss: 0.433570, acc: 50.00%, op_acc: 35.94%] [G loss: 0.822024]\n",
      "epoch:35 step:27882[D loss: 0.438317, acc: 53.91%, op_acc: 39.84%] [G loss: 0.904198]\n",
      "epoch:35 step:27883[D loss: 0.415042, acc: 67.19%, op_acc: 35.94%] [G loss: 0.869996]\n",
      "epoch:35 step:27884[D loss: 0.415766, acc: 62.50%, op_acc: 42.97%] [G loss: 0.850493]\n",
      "epoch:35 step:27885[D loss: 0.435819, acc: 52.34%, op_acc: 42.97%] [G loss: 0.938611]\n",
      "epoch:35 step:27886[D loss: 0.424008, acc: 61.72%, op_acc: 40.62%] [G loss: 0.957796]\n",
      "epoch:35 step:27887[D loss: 0.457850, acc: 55.47%, op_acc: 34.38%] [G loss: 0.862009]\n",
      "epoch:35 step:27888[D loss: 0.397057, acc: 60.16%, op_acc: 44.53%] [G loss: 0.881644]\n",
      "epoch:35 step:27889[D loss: 0.420311, acc: 57.81%, op_acc: 42.97%] [G loss: 0.952657]\n",
      "epoch:35 step:27890[D loss: 0.413584, acc: 50.78%, op_acc: 40.62%] [G loss: 0.929433]\n",
      "epoch:35 step:27891[D loss: 0.396772, acc: 59.38%, op_acc: 42.97%] [G loss: 0.899867]\n",
      "epoch:35 step:27892[D loss: 0.447669, acc: 54.69%, op_acc: 39.84%] [G loss: 0.838303]\n",
      "epoch:35 step:27893[D loss: 0.383642, acc: 59.38%, op_acc: 44.53%] [G loss: 0.844611]\n",
      "epoch:35 step:27894[D loss: 0.386867, acc: 63.28%, op_acc: 41.41%] [G loss: 0.875540]\n",
      "epoch:35 step:27895[D loss: 0.433558, acc: 59.38%, op_acc: 39.84%] [G loss: 0.877366]\n",
      "epoch:35 step:27896[D loss: 0.422897, acc: 61.72%, op_acc: 41.41%] [G loss: 0.906751]\n",
      "epoch:35 step:27897[D loss: 0.433906, acc: 60.16%, op_acc: 41.41%] [G loss: 0.903498]\n",
      "epoch:35 step:27898[D loss: 0.424765, acc: 64.84%, op_acc: 38.28%] [G loss: 0.908073]\n",
      "epoch:35 step:27899[D loss: 0.434801, acc: 56.25%, op_acc: 40.62%] [G loss: 0.914357]\n",
      "epoch:35 step:27900[D loss: 0.426523, acc: 55.47%, op_acc: 42.97%] [G loss: 0.913448]\n",
      "##############\n",
      "[0.85200991 0.85400486 0.82060649 0.80491076 0.79275021 0.82880287\n",
      " 0.89603841 0.85634925 0.81864259 0.85065707]\n",
      "##########\n",
      "epoch:35 step:27901[D loss: 0.412813, acc: 56.25%, op_acc: 42.19%] [G loss: 0.960258]\n",
      "epoch:35 step:27902[D loss: 0.394989, acc: 59.38%, op_acc: 41.41%] [G loss: 0.917642]\n",
      "epoch:35 step:27903[D loss: 0.400381, acc: 61.72%, op_acc: 48.44%] [G loss: 0.876504]\n",
      "epoch:35 step:27904[D loss: 0.397128, acc: 60.16%, op_acc: 44.53%] [G loss: 0.937047]\n",
      "epoch:35 step:27905[D loss: 0.460285, acc: 57.03%, op_acc: 38.28%] [G loss: 0.819764]\n",
      "epoch:35 step:27906[D loss: 0.438639, acc: 66.41%, op_acc: 43.75%] [G loss: 0.813499]\n",
      "epoch:35 step:27907[D loss: 0.391811, acc: 65.62%, op_acc: 41.41%] [G loss: 0.964318]\n",
      "epoch:35 step:27908[D loss: 0.445811, acc: 53.12%, op_acc: 40.62%] [G loss: 0.801180]\n",
      "epoch:35 step:27909[D loss: 0.410911, acc: 68.75%, op_acc: 39.06%] [G loss: 0.794573]\n",
      "epoch:35 step:27910[D loss: 0.430047, acc: 55.47%, op_acc: 39.06%] [G loss: 0.870202]\n",
      "epoch:35 step:27911[D loss: 0.360391, acc: 74.22%, op_acc: 43.75%] [G loss: 0.977149]\n",
      "epoch:35 step:27912[D loss: 0.443883, acc: 57.03%, op_acc: 38.28%] [G loss: 0.848358]\n",
      "epoch:35 step:27913[D loss: 0.470340, acc: 54.69%, op_acc: 35.16%] [G loss: 0.824585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27914[D loss: 0.370065, acc: 64.06%, op_acc: 44.53%] [G loss: 0.961632]\n",
      "epoch:35 step:27915[D loss: 0.436216, acc: 54.69%, op_acc: 40.62%] [G loss: 0.856801]\n",
      "epoch:35 step:27916[D loss: 0.440069, acc: 56.25%, op_acc: 40.62%] [G loss: 0.849247]\n",
      "epoch:35 step:27917[D loss: 0.440331, acc: 55.47%, op_acc: 37.50%] [G loss: 0.806942]\n",
      "epoch:35 step:27918[D loss: 0.395168, acc: 63.28%, op_acc: 42.97%] [G loss: 0.901177]\n",
      "epoch:35 step:27919[D loss: 0.446101, acc: 57.03%, op_acc: 33.59%] [G loss: 0.863834]\n",
      "epoch:35 step:27920[D loss: 0.414082, acc: 60.94%, op_acc: 40.62%] [G loss: 0.933144]\n",
      "epoch:35 step:27921[D loss: 0.409544, acc: 65.62%, op_acc: 39.84%] [G loss: 0.923695]\n",
      "epoch:35 step:27922[D loss: 0.415258, acc: 66.41%, op_acc: 41.41%] [G loss: 0.936347]\n",
      "epoch:35 step:27923[D loss: 0.438402, acc: 57.03%, op_acc: 37.50%] [G loss: 0.837471]\n",
      "epoch:35 step:27924[D loss: 0.415838, acc: 57.81%, op_acc: 41.41%] [G loss: 0.899776]\n",
      "epoch:35 step:27925[D loss: 0.424298, acc: 57.03%, op_acc: 40.62%] [G loss: 0.854339]\n",
      "epoch:35 step:27926[D loss: 0.421534, acc: 66.41%, op_acc: 42.19%] [G loss: 0.890095]\n",
      "epoch:35 step:27927[D loss: 0.420864, acc: 54.69%, op_acc: 42.97%] [G loss: 0.947683]\n",
      "epoch:35 step:27928[D loss: 0.415286, acc: 61.72%, op_acc: 37.50%] [G loss: 0.828239]\n",
      "epoch:35 step:27929[D loss: 0.399336, acc: 64.06%, op_acc: 42.97%] [G loss: 0.913469]\n",
      "epoch:35 step:27930[D loss: 0.418746, acc: 63.28%, op_acc: 40.62%] [G loss: 0.809215]\n",
      "epoch:35 step:27931[D loss: 0.432776, acc: 58.59%, op_acc: 42.97%] [G loss: 0.892779]\n",
      "epoch:35 step:27932[D loss: 0.419432, acc: 56.25%, op_acc: 40.62%] [G loss: 0.922109]\n",
      "epoch:35 step:27933[D loss: 0.407446, acc: 60.16%, op_acc: 42.19%] [G loss: 0.932611]\n",
      "epoch:35 step:27934[D loss: 0.437739, acc: 53.91%, op_acc: 34.38%] [G loss: 0.819337]\n",
      "epoch:35 step:27935[D loss: 0.431295, acc: 58.59%, op_acc: 39.06%] [G loss: 0.852643]\n",
      "epoch:35 step:27936[D loss: 0.443974, acc: 53.12%, op_acc: 36.72%] [G loss: 0.910435]\n",
      "epoch:35 step:27937[D loss: 0.425165, acc: 59.38%, op_acc: 39.84%] [G loss: 0.911404]\n",
      "epoch:35 step:27938[D loss: 0.406305, acc: 53.12%, op_acc: 46.09%] [G loss: 0.888335]\n",
      "epoch:35 step:27939[D loss: 0.438724, acc: 56.25%, op_acc: 42.19%] [G loss: 0.840150]\n",
      "epoch:35 step:27940[D loss: 0.394006, acc: 67.97%, op_acc: 42.19%] [G loss: 0.903297]\n",
      "epoch:35 step:27941[D loss: 0.413464, acc: 60.94%, op_acc: 47.66%] [G loss: 0.915209]\n",
      "epoch:35 step:27942[D loss: 0.391757, acc: 60.16%, op_acc: 42.19%] [G loss: 0.911250]\n",
      "epoch:35 step:27943[D loss: 0.371342, acc: 67.97%, op_acc: 41.41%] [G loss: 0.844024]\n",
      "epoch:35 step:27944[D loss: 0.448423, acc: 54.69%, op_acc: 38.28%] [G loss: 0.821376]\n",
      "epoch:35 step:27945[D loss: 0.416286, acc: 67.97%, op_acc: 40.62%] [G loss: 0.878681]\n",
      "epoch:35 step:27946[D loss: 0.404184, acc: 64.84%, op_acc: 39.84%] [G loss: 0.888254]\n",
      "epoch:35 step:27947[D loss: 0.416273, acc: 64.84%, op_acc: 36.72%] [G loss: 0.810493]\n",
      "epoch:35 step:27948[D loss: 0.409165, acc: 59.38%, op_acc: 45.31%] [G loss: 0.906498]\n",
      "epoch:35 step:27949[D loss: 0.392829, acc: 63.28%, op_acc: 41.41%] [G loss: 0.887617]\n",
      "epoch:35 step:27950[D loss: 0.419944, acc: 54.69%, op_acc: 47.66%] [G loss: 0.889999]\n",
      "##############\n",
      "[0.87406157 0.86597284 0.80058686 0.79891686 0.78160294 0.83139855\n",
      " 0.88378541 0.84686148 0.81243576 0.82537917]\n",
      "##########\n",
      "epoch:35 step:27951[D loss: 0.418976, acc: 63.28%, op_acc: 39.06%] [G loss: 0.951078]\n",
      "epoch:35 step:27952[D loss: 0.436847, acc: 57.03%, op_acc: 38.28%] [G loss: 0.865684]\n",
      "epoch:35 step:27953[D loss: 0.408859, acc: 61.72%, op_acc: 42.19%] [G loss: 0.953991]\n",
      "epoch:35 step:27954[D loss: 0.437841, acc: 57.03%, op_acc: 37.50%] [G loss: 0.948541]\n",
      "epoch:35 step:27955[D loss: 0.414470, acc: 63.28%, op_acc: 39.84%] [G loss: 0.974306]\n",
      "epoch:35 step:27956[D loss: 0.415794, acc: 57.81%, op_acc: 45.31%] [G loss: 0.885967]\n",
      "epoch:35 step:27957[D loss: 0.413630, acc: 71.88%, op_acc: 39.84%] [G loss: 0.871274]\n",
      "epoch:35 step:27958[D loss: 0.439322, acc: 48.44%, op_acc: 43.75%] [G loss: 0.961595]\n",
      "epoch:35 step:27959[D loss: 0.417772, acc: 54.69%, op_acc: 42.97%] [G loss: 0.833542]\n",
      "epoch:35 step:27960[D loss: 0.417312, acc: 64.84%, op_acc: 39.06%] [G loss: 0.886294]\n",
      "epoch:35 step:27961[D loss: 0.403813, acc: 59.38%, op_acc: 42.97%] [G loss: 0.867593]\n",
      "epoch:35 step:27962[D loss: 0.436405, acc: 57.81%, op_acc: 42.97%] [G loss: 0.923378]\n",
      "epoch:35 step:27963[D loss: 0.407915, acc: 62.50%, op_acc: 40.62%] [G loss: 0.974281]\n",
      "epoch:35 step:27964[D loss: 0.453907, acc: 53.12%, op_acc: 37.50%] [G loss: 0.965165]\n",
      "epoch:35 step:27965[D loss: 0.410219, acc: 60.94%, op_acc: 39.84%] [G loss: 0.928701]\n",
      "epoch:35 step:27966[D loss: 0.452988, acc: 50.78%, op_acc: 36.72%] [G loss: 0.832416]\n",
      "epoch:35 step:27967[D loss: 0.406759, acc: 64.06%, op_acc: 42.97%] [G loss: 0.833335]\n",
      "epoch:35 step:27968[D loss: 0.430074, acc: 56.25%, op_acc: 43.75%] [G loss: 0.897989]\n",
      "epoch:35 step:27969[D loss: 0.418691, acc: 55.47%, op_acc: 46.09%] [G loss: 0.866984]\n",
      "epoch:35 step:27970[D loss: 0.423931, acc: 62.50%, op_acc: 40.62%] [G loss: 0.839568]\n",
      "epoch:35 step:27971[D loss: 0.391392, acc: 60.16%, op_acc: 42.19%] [G loss: 0.907112]\n",
      "epoch:35 step:27972[D loss: 0.370422, acc: 70.31%, op_acc: 46.09%] [G loss: 0.937534]\n",
      "epoch:35 step:27973[D loss: 0.439237, acc: 53.12%, op_acc: 39.84%] [G loss: 0.907555]\n",
      "epoch:35 step:27974[D loss: 0.431093, acc: 57.03%, op_acc: 42.19%] [G loss: 0.896151]\n",
      "epoch:35 step:27975[D loss: 0.436823, acc: 60.94%, op_acc: 36.72%] [G loss: 0.947868]\n",
      "epoch:35 step:27976[D loss: 0.426977, acc: 59.38%, op_acc: 40.62%] [G loss: 0.918270]\n",
      "epoch:35 step:27977[D loss: 0.435204, acc: 56.25%, op_acc: 42.97%] [G loss: 0.929155]\n",
      "epoch:35 step:27978[D loss: 0.456724, acc: 50.78%, op_acc: 34.38%] [G loss: 0.864441]\n",
      "epoch:35 step:27979[D loss: 0.389572, acc: 69.53%, op_acc: 43.75%] [G loss: 0.936182]\n",
      "epoch:35 step:27980[D loss: 0.403129, acc: 62.50%, op_acc: 36.72%] [G loss: 0.899211]\n",
      "epoch:35 step:27981[D loss: 0.404483, acc: 64.06%, op_acc: 46.09%] [G loss: 0.877652]\n",
      "epoch:35 step:27982[D loss: 0.414010, acc: 64.84%, op_acc: 40.62%] [G loss: 0.949311]\n",
      "epoch:35 step:27983[D loss: 0.398400, acc: 63.28%, op_acc: 46.09%] [G loss: 0.834336]\n",
      "epoch:35 step:27984[D loss: 0.423357, acc: 60.94%, op_acc: 39.84%] [G loss: 0.881869]\n",
      "epoch:35 step:27985[D loss: 0.407254, acc: 64.84%, op_acc: 42.19%] [G loss: 0.875970]\n",
      "epoch:35 step:27986[D loss: 0.414069, acc: 64.06%, op_acc: 42.97%] [G loss: 0.879538]\n",
      "epoch:35 step:27987[D loss: 0.398116, acc: 57.81%, op_acc: 42.19%] [G loss: 0.890448]\n",
      "epoch:35 step:27988[D loss: 0.371972, acc: 67.97%, op_acc: 46.88%] [G loss: 0.853108]\n",
      "epoch:35 step:27989[D loss: 0.414684, acc: 57.03%, op_acc: 41.41%] [G loss: 0.904314]\n",
      "epoch:35 step:27990[D loss: 0.417644, acc: 63.28%, op_acc: 39.06%] [G loss: 0.886294]\n",
      "epoch:35 step:27991[D loss: 0.432170, acc: 58.59%, op_acc: 38.28%] [G loss: 0.848293]\n",
      "epoch:35 step:27992[D loss: 0.427325, acc: 64.84%, op_acc: 38.28%] [G loss: 0.869125]\n",
      "epoch:35 step:27993[D loss: 0.391056, acc: 71.09%, op_acc: 35.16%] [G loss: 0.952267]\n",
      "epoch:35 step:27994[D loss: 0.414909, acc: 58.59%, op_acc: 39.06%] [G loss: 0.904446]\n",
      "epoch:35 step:27995[D loss: 0.417804, acc: 50.78%, op_acc: 46.09%] [G loss: 0.958695]\n",
      "epoch:35 step:27996[D loss: 0.410688, acc: 59.38%, op_acc: 44.53%] [G loss: 0.859049]\n",
      "epoch:35 step:27997[D loss: 0.432909, acc: 53.91%, op_acc: 36.72%] [G loss: 0.894300]\n",
      "epoch:35 step:27998[D loss: 0.407954, acc: 58.59%, op_acc: 42.19%] [G loss: 0.910193]\n",
      "epoch:35 step:27999[D loss: 0.414575, acc: 60.16%, op_acc: 37.50%] [G loss: 0.869590]\n",
      "epoch:35 step:28000[D loss: 0.413094, acc: 57.81%, op_acc: 35.94%] [G loss: 0.902146]\n",
      "##############\n",
      "[0.86156356 0.84496918 0.81802565 0.80092696 0.79899398 0.82088438\n",
      " 0.89851286 0.83325143 0.77706199 0.82167048]\n",
      "##########\n",
      "epoch:35 step:28001[D loss: 0.429808, acc: 53.91%, op_acc: 37.50%] [G loss: 0.849018]\n",
      "epoch:35 step:28002[D loss: 0.378441, acc: 62.50%, op_acc: 41.41%] [G loss: 0.868382]\n",
      "epoch:35 step:28003[D loss: 0.411960, acc: 60.16%, op_acc: 42.19%] [G loss: 0.927476]\n",
      "epoch:35 step:28004[D loss: 0.410749, acc: 53.91%, op_acc: 41.41%] [G loss: 0.916321]\n",
      "epoch:35 step:28005[D loss: 0.411378, acc: 62.50%, op_acc: 44.53%] [G loss: 0.834762]\n",
      "epoch:35 step:28006[D loss: 0.456893, acc: 52.34%, op_acc: 31.25%] [G loss: 0.828845]\n",
      "epoch:35 step:28007[D loss: 0.419255, acc: 64.84%, op_acc: 34.38%] [G loss: 0.875100]\n",
      "epoch:35 step:28008[D loss: 0.416416, acc: 61.72%, op_acc: 41.41%] [G loss: 0.859216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:28009[D loss: 0.429938, acc: 51.56%, op_acc: 40.62%] [G loss: 0.889640]\n",
      "epoch:35 step:28010[D loss: 0.396483, acc: 67.19%, op_acc: 44.53%] [G loss: 0.937865]\n",
      "epoch:35 step:28011[D loss: 0.449809, acc: 59.38%, op_acc: 30.47%] [G loss: 0.888166]\n",
      "epoch:35 step:28012[D loss: 0.448920, acc: 53.91%, op_acc: 36.72%] [G loss: 0.847188]\n",
      "epoch:35 step:28013[D loss: 0.407881, acc: 64.06%, op_acc: 40.62%] [G loss: 0.915243]\n",
      "epoch:35 step:28014[D loss: 0.360856, acc: 66.41%, op_acc: 48.44%] [G loss: 0.939891]\n",
      "epoch:35 step:28015[D loss: 0.447020, acc: 57.81%, op_acc: 34.38%] [G loss: 0.875288]\n",
      "epoch:35 step:28016[D loss: 0.445898, acc: 60.94%, op_acc: 35.16%] [G loss: 0.920351]\n",
      "epoch:35 step:28017[D loss: 0.392012, acc: 61.72%, op_acc: 42.19%] [G loss: 0.954456]\n",
      "epoch:35 step:28018[D loss: 0.404215, acc: 60.16%, op_acc: 38.28%] [G loss: 0.841035]\n",
      "epoch:35 step:28019[D loss: 0.406840, acc: 64.06%, op_acc: 44.53%] [G loss: 0.851148]\n",
      "epoch:35 step:28020[D loss: 0.429739, acc: 61.72%, op_acc: 35.94%] [G loss: 0.842970]\n",
      "epoch:35 step:28021[D loss: 0.387662, acc: 64.84%, op_acc: 45.31%] [G loss: 0.917672]\n",
      "epoch:35 step:28022[D loss: 0.402142, acc: 67.19%, op_acc: 40.62%] [G loss: 0.989289]\n",
      "epoch:35 step:28023[D loss: 0.420208, acc: 59.38%, op_acc: 40.62%] [G loss: 0.878981]\n",
      "epoch:35 step:28024[D loss: 0.400230, acc: 55.47%, op_acc: 46.09%] [G loss: 1.010747]\n",
      "epoch:35 step:28025[D loss: 0.402398, acc: 67.97%, op_acc: 38.28%] [G loss: 0.890692]\n",
      "epoch:35 step:28026[D loss: 0.428973, acc: 56.25%, op_acc: 40.62%] [G loss: 0.963038]\n",
      "epoch:35 step:28027[D loss: 0.447205, acc: 51.56%, op_acc: 41.41%] [G loss: 0.901254]\n",
      "epoch:35 step:28028[D loss: 0.426737, acc: 56.25%, op_acc: 40.62%] [G loss: 0.892267]\n",
      "epoch:35 step:28029[D loss: 0.421575, acc: 54.69%, op_acc: 39.84%] [G loss: 0.887249]\n",
      "epoch:35 step:28030[D loss: 0.403091, acc: 63.28%, op_acc: 42.97%] [G loss: 0.933928]\n",
      "epoch:35 step:28031[D loss: 0.446618, acc: 57.81%, op_acc: 39.06%] [G loss: 0.901964]\n",
      "epoch:35 step:28032[D loss: 0.404201, acc: 58.59%, op_acc: 44.53%] [G loss: 0.912443]\n",
      "epoch:35 step:28033[D loss: 0.419929, acc: 64.06%, op_acc: 40.62%] [G loss: 0.927277]\n",
      "epoch:35 step:28034[D loss: 0.390616, acc: 60.94%, op_acc: 42.97%] [G loss: 0.926130]\n",
      "epoch:35 step:28035[D loss: 0.433791, acc: 54.69%, op_acc: 39.84%] [G loss: 0.919770]\n",
      "epoch:35 step:28036[D loss: 0.434424, acc: 57.81%, op_acc: 40.62%] [G loss: 0.851278]\n",
      "epoch:35 step:28037[D loss: 0.423733, acc: 57.81%, op_acc: 38.28%] [G loss: 0.837620]\n",
      "epoch:35 step:28038[D loss: 0.437423, acc: 60.94%, op_acc: 39.06%] [G loss: 0.851963]\n",
      "epoch:35 step:28039[D loss: 0.399085, acc: 61.72%, op_acc: 43.75%] [G loss: 0.830103]\n",
      "epoch:35 step:28040[D loss: 0.422721, acc: 57.81%, op_acc: 42.19%] [G loss: 0.872075]\n",
      "epoch:35 step:28041[D loss: 0.447853, acc: 55.47%, op_acc: 40.62%] [G loss: 0.773460]\n",
      "epoch:35 step:28042[D loss: 0.420003, acc: 57.81%, op_acc: 40.62%] [G loss: 0.828385]\n",
      "epoch:35 step:28043[D loss: 0.444754, acc: 57.81%, op_acc: 35.16%] [G loss: 0.918884]\n",
      "epoch:35 step:28044[D loss: 0.402963, acc: 70.31%, op_acc: 46.09%] [G loss: 0.881519]\n",
      "epoch:35 step:28045[D loss: 0.421097, acc: 56.25%, op_acc: 42.19%] [G loss: 0.815950]\n",
      "epoch:35 step:28046[D loss: 0.422409, acc: 63.28%, op_acc: 37.50%] [G loss: 0.883373]\n",
      "epoch:35 step:28047[D loss: 0.414254, acc: 61.72%, op_acc: 39.84%] [G loss: 0.860850]\n",
      "epoch:35 step:28048[D loss: 0.398610, acc: 60.94%, op_acc: 44.53%] [G loss: 0.893176]\n",
      "epoch:35 step:28049[D loss: 0.461160, acc: 56.25%, op_acc: 37.50%] [G loss: 0.906424]\n",
      "epoch:35 step:28050[D loss: 0.423828, acc: 53.91%, op_acc: 39.84%] [G loss: 0.900584]\n",
      "##############\n",
      "[0.85653607 0.84699234 0.81180363 0.79657896 0.80482327 0.8126214\n",
      " 0.8660812  0.81865019 0.82293507 0.86407956]\n",
      "##########\n",
      "epoch:35 step:28051[D loss: 0.425922, acc: 53.91%, op_acc: 41.41%] [G loss: 0.912510]\n",
      "epoch:35 step:28052[D loss: 0.380828, acc: 65.62%, op_acc: 47.66%] [G loss: 0.924186]\n",
      "epoch:35 step:28053[D loss: 0.405651, acc: 62.50%, op_acc: 43.75%] [G loss: 0.941519]\n",
      "epoch:35 step:28054[D loss: 0.414978, acc: 61.72%, op_acc: 42.19%] [G loss: 0.902017]\n",
      "epoch:35 step:28055[D loss: 0.418049, acc: 64.84%, op_acc: 38.28%] [G loss: 0.870191]\n",
      "epoch:35 step:28056[D loss: 0.426498, acc: 55.47%, op_acc: 41.41%] [G loss: 0.844076]\n",
      "epoch:35 step:28057[D loss: 0.432456, acc: 48.44%, op_acc: 44.53%] [G loss: 0.821774]\n",
      "epoch:35 step:28058[D loss: 0.410615, acc: 62.50%, op_acc: 43.75%] [G loss: 0.936469]\n",
      "epoch:35 step:28059[D loss: 0.471511, acc: 48.44%, op_acc: 29.69%] [G loss: 0.914580]\n",
      "epoch:35 step:28060[D loss: 0.424271, acc: 55.47%, op_acc: 39.06%] [G loss: 0.836881]\n",
      "epoch:35 step:28061[D loss: 0.384495, acc: 68.75%, op_acc: 41.41%] [G loss: 0.886528]\n",
      "epoch:35 step:28062[D loss: 0.440917, acc: 55.47%, op_acc: 32.03%] [G loss: 0.876082]\n",
      "epoch:35 step:28063[D loss: 0.433841, acc: 56.25%, op_acc: 35.16%] [G loss: 0.882333]\n",
      "epoch:35 step:28064[D loss: 0.434467, acc: 50.00%, op_acc: 42.97%] [G loss: 0.806840]\n",
      "epoch:35 step:28065[D loss: 0.403012, acc: 61.72%, op_acc: 34.38%] [G loss: 0.871783]\n",
      "epoch:35 step:28066[D loss: 0.425361, acc: 53.91%, op_acc: 42.19%] [G loss: 0.822994]\n",
      "epoch:35 step:28067[D loss: 0.416176, acc: 56.25%, op_acc: 42.19%] [G loss: 0.851312]\n",
      "epoch:35 step:28068[D loss: 0.418730, acc: 60.16%, op_acc: 39.84%] [G loss: 0.815112]\n",
      "epoch:35 step:28069[D loss: 0.423634, acc: 56.25%, op_acc: 40.62%] [G loss: 0.887665]\n",
      "epoch:35 step:28070[D loss: 0.417791, acc: 61.72%, op_acc: 37.50%] [G loss: 0.911155]\n",
      "epoch:35 step:28071[D loss: 0.394888, acc: 73.44%, op_acc: 42.19%] [G loss: 0.883609]\n",
      "epoch:35 step:28072[D loss: 0.411178, acc: 60.94%, op_acc: 45.31%] [G loss: 0.874069]\n",
      "epoch:35 step:28073[D loss: 0.428743, acc: 56.25%, op_acc: 42.19%] [G loss: 0.905319]\n",
      "epoch:35 step:28074[D loss: 0.403211, acc: 60.16%, op_acc: 41.41%] [G loss: 0.890332]\n",
      "epoch:35 step:28075[D loss: 0.418794, acc: 57.81%, op_acc: 43.75%] [G loss: 0.834319]\n",
      "epoch:35 step:28076[D loss: 0.424162, acc: 54.69%, op_acc: 42.19%] [G loss: 0.807111]\n",
      "epoch:35 step:28077[D loss: 0.423576, acc: 55.47%, op_acc: 41.41%] [G loss: 0.875523]\n",
      "epoch:35 step:28078[D loss: 0.440941, acc: 58.59%, op_acc: 39.06%] [G loss: 0.845520]\n",
      "epoch:35 step:28079[D loss: 0.402215, acc: 55.47%, op_acc: 46.88%] [G loss: 0.945361]\n",
      "epoch:35 step:28080[D loss: 0.430850, acc: 56.25%, op_acc: 39.84%] [G loss: 0.895649]\n",
      "epoch:35 step:28081[D loss: 0.420873, acc: 58.59%, op_acc: 42.97%] [G loss: 0.837111]\n",
      "epoch:35 step:28082[D loss: 0.439303, acc: 58.59%, op_acc: 35.94%] [G loss: 0.913655]\n",
      "epoch:35 step:28083[D loss: 0.406756, acc: 66.41%, op_acc: 40.62%] [G loss: 0.855726]\n",
      "epoch:35 step:28084[D loss: 0.411872, acc: 64.06%, op_acc: 39.06%] [G loss: 0.938738]\n",
      "epoch:35 step:28085[D loss: 0.404903, acc: 53.91%, op_acc: 42.19%] [G loss: 0.905839]\n",
      "epoch:35 step:28086[D loss: 0.438790, acc: 53.12%, op_acc: 36.72%] [G loss: 0.948272]\n",
      "epoch:35 step:28087[D loss: 0.456044, acc: 49.22%, op_acc: 35.16%] [G loss: 0.965291]\n",
      "epoch:35 step:28088[D loss: 0.411270, acc: 63.28%, op_acc: 39.84%] [G loss: 0.894065]\n",
      "epoch:35 step:28089[D loss: 0.400596, acc: 65.62%, op_acc: 44.53%] [G loss: 0.876605]\n",
      "epoch:35 step:28090[D loss: 0.407332, acc: 60.94%, op_acc: 44.53%] [G loss: 0.840020]\n",
      "epoch:35 step:28091[D loss: 0.416666, acc: 60.94%, op_acc: 39.06%] [G loss: 0.907011]\n",
      "epoch:35 step:28092[D loss: 0.389601, acc: 64.84%, op_acc: 44.53%] [G loss: 0.902815]\n",
      "epoch:35 step:28093[D loss: 0.399417, acc: 60.16%, op_acc: 42.19%] [G loss: 0.895028]\n",
      "epoch:35 step:28094[D loss: 0.424933, acc: 65.62%, op_acc: 46.88%] [G loss: 0.937642]\n",
      "epoch:35 step:28095[D loss: 0.400227, acc: 64.84%, op_acc: 41.41%] [G loss: 0.843395]\n",
      "epoch:35 step:28096[D loss: 0.403087, acc: 60.16%, op_acc: 46.88%] [G loss: 0.912934]\n",
      "epoch:35 step:28097[D loss: 0.435139, acc: 57.03%, op_acc: 44.53%] [G loss: 0.909922]\n",
      "epoch:35 step:28098[D loss: 0.412407, acc: 61.72%, op_acc: 42.97%] [G loss: 0.976254]\n",
      "epoch:35 step:28099[D loss: 0.429277, acc: 53.91%, op_acc: 36.72%] [G loss: 0.948250]\n",
      "epoch:35 step:28100[D loss: 0.401528, acc: 58.59%, op_acc: 43.75%] [G loss: 0.890364]\n",
      "##############\n",
      "[0.84921562 0.85656645 0.81051266 0.81651815 0.79744697 0.84468827\n",
      " 0.87864086 0.80880035 0.82879741 0.83493484]\n",
      "##########\n",
      "epoch:35 step:28101[D loss: 0.412951, acc: 56.25%, op_acc: 36.72%] [G loss: 0.867420]\n",
      "epoch:35 step:28102[D loss: 0.405168, acc: 60.94%, op_acc: 40.62%] [G loss: 0.889320]\n",
      "epoch:35 step:28103[D loss: 0.381849, acc: 67.19%, op_acc: 42.19%] [G loss: 0.915098]\n",
      "epoch:35 step:28104[D loss: 0.405476, acc: 60.16%, op_acc: 44.53%] [G loss: 0.866578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:28105[D loss: 0.425313, acc: 53.12%, op_acc: 42.19%] [G loss: 0.833064]\n",
      "epoch:35 step:28106[D loss: 0.466505, acc: 51.56%, op_acc: 34.38%] [G loss: 0.923792]\n",
      "epoch:35 step:28107[D loss: 0.432725, acc: 59.38%, op_acc: 39.84%] [G loss: 0.865743]\n",
      "epoch:35 step:28108[D loss: 0.424288, acc: 60.94%, op_acc: 37.50%] [G loss: 0.896842]\n",
      "epoch:35 step:28109[D loss: 0.404533, acc: 59.38%, op_acc: 41.41%] [G loss: 0.932307]\n",
      "epoch:35 step:28110[D loss: 0.417871, acc: 64.84%, op_acc: 39.84%] [G loss: 1.016494]\n",
      "epoch:35 step:28111[D loss: 0.396621, acc: 61.72%, op_acc: 43.75%] [G loss: 0.888781]\n",
      "epoch:35 step:28112[D loss: 0.431262, acc: 55.47%, op_acc: 35.16%] [G loss: 0.863958]\n",
      "epoch:35 step:28113[D loss: 0.427326, acc: 57.81%, op_acc: 45.31%] [G loss: 0.878612]\n",
      "epoch:35 step:28114[D loss: 0.422429, acc: 60.16%, op_acc: 37.50%] [G loss: 0.886676]\n",
      "epoch:35 step:28115[D loss: 0.395990, acc: 60.16%, op_acc: 40.62%] [G loss: 0.804613]\n",
      "epoch:35 step:28116[D loss: 0.408996, acc: 59.38%, op_acc: 36.72%] [G loss: 0.899639]\n",
      "epoch:36 step:28117[D loss: 0.393120, acc: 65.62%, op_acc: 46.09%] [G loss: 0.897022]\n",
      "epoch:36 step:28118[D loss: 0.405952, acc: 58.59%, op_acc: 40.62%] [G loss: 0.967566]\n",
      "epoch:36 step:28119[D loss: 0.426440, acc: 61.72%, op_acc: 43.75%] [G loss: 0.969594]\n",
      "epoch:36 step:28120[D loss: 0.407418, acc: 56.25%, op_acc: 46.09%] [G loss: 0.897002]\n",
      "epoch:36 step:28121[D loss: 0.435951, acc: 53.91%, op_acc: 43.75%] [G loss: 0.929505]\n",
      "epoch:36 step:28122[D loss: 0.417031, acc: 63.28%, op_acc: 38.28%] [G loss: 0.914140]\n",
      "epoch:36 step:28123[D loss: 0.403824, acc: 60.16%, op_acc: 41.41%] [G loss: 0.894245]\n",
      "epoch:36 step:28124[D loss: 0.449510, acc: 52.34%, op_acc: 42.97%] [G loss: 0.829037]\n",
      "epoch:36 step:28125[D loss: 0.396017, acc: 62.50%, op_acc: 46.09%] [G loss: 0.909042]\n",
      "epoch:36 step:28126[D loss: 0.422839, acc: 55.47%, op_acc: 39.06%] [G loss: 0.924201]\n",
      "epoch:36 step:28127[D loss: 0.456482, acc: 53.12%, op_acc: 35.94%] [G loss: 0.887155]\n",
      "epoch:36 step:28128[D loss: 0.433314, acc: 60.94%, op_acc: 36.72%] [G loss: 0.879713]\n",
      "epoch:36 step:28129[D loss: 0.375787, acc: 67.97%, op_acc: 44.53%] [G loss: 0.933132]\n",
      "epoch:36 step:28130[D loss: 0.417490, acc: 61.72%, op_acc: 40.62%] [G loss: 0.879640]\n",
      "epoch:36 step:28131[D loss: 0.409814, acc: 60.94%, op_acc: 42.19%] [G loss: 0.905798]\n",
      "epoch:36 step:28132[D loss: 0.382111, acc: 63.28%, op_acc: 49.22%] [G loss: 1.010632]\n",
      "epoch:36 step:28133[D loss: 0.409882, acc: 58.59%, op_acc: 41.41%] [G loss: 0.882559]\n",
      "epoch:36 step:28134[D loss: 0.424661, acc: 59.38%, op_acc: 40.62%] [G loss: 0.943677]\n",
      "epoch:36 step:28135[D loss: 0.412806, acc: 60.16%, op_acc: 41.41%] [G loss: 0.932710]\n",
      "epoch:36 step:28136[D loss: 0.403777, acc: 58.59%, op_acc: 41.41%] [G loss: 0.859697]\n",
      "epoch:36 step:28137[D loss: 0.429619, acc: 57.81%, op_acc: 38.28%] [G loss: 0.875993]\n",
      "epoch:36 step:28138[D loss: 0.406687, acc: 62.50%, op_acc: 42.97%] [G loss: 0.884824]\n",
      "epoch:36 step:28139[D loss: 0.401461, acc: 61.72%, op_acc: 45.31%] [G loss: 0.807689]\n",
      "epoch:36 step:28140[D loss: 0.445441, acc: 60.94%, op_acc: 37.50%] [G loss: 0.915408]\n",
      "epoch:36 step:28141[D loss: 0.431813, acc: 55.47%, op_acc: 37.50%] [G loss: 0.825514]\n",
      "epoch:36 step:28142[D loss: 0.400674, acc: 62.50%, op_acc: 41.41%] [G loss: 0.808946]\n",
      "epoch:36 step:28143[D loss: 0.439716, acc: 53.91%, op_acc: 42.97%] [G loss: 0.873863]\n",
      "epoch:36 step:28144[D loss: 0.400942, acc: 56.25%, op_acc: 43.75%] [G loss: 0.867616]\n",
      "epoch:36 step:28145[D loss: 0.382696, acc: 58.59%, op_acc: 44.53%] [G loss: 0.898953]\n",
      "epoch:36 step:28146[D loss: 0.380999, acc: 65.62%, op_acc: 41.41%] [G loss: 0.876064]\n",
      "epoch:36 step:28147[D loss: 0.399759, acc: 62.50%, op_acc: 42.19%] [G loss: 0.876332]\n",
      "epoch:36 step:28148[D loss: 0.419183, acc: 62.50%, op_acc: 37.50%] [G loss: 0.927241]\n",
      "epoch:36 step:28149[D loss: 0.415690, acc: 62.50%, op_acc: 42.19%] [G loss: 0.959983]\n",
      "epoch:36 step:28150[D loss: 0.408596, acc: 58.59%, op_acc: 42.19%] [G loss: 0.991066]\n",
      "##############\n",
      "[0.87290021 0.86156925 0.81513068 0.79298795 0.8114834  0.83017058\n",
      " 0.88282681 0.81311222 0.8039229  0.83613092]\n",
      "##########\n",
      "epoch:36 step:28151[D loss: 0.441083, acc: 61.72%, op_acc: 36.72%] [G loss: 0.846453]\n",
      "epoch:36 step:28152[D loss: 0.425478, acc: 55.47%, op_acc: 40.62%] [G loss: 0.878903]\n",
      "epoch:36 step:28153[D loss: 0.383727, acc: 71.09%, op_acc: 40.62%] [G loss: 0.934506]\n",
      "epoch:36 step:28154[D loss: 0.403530, acc: 60.94%, op_acc: 41.41%] [G loss: 0.958477]\n",
      "epoch:36 step:28155[D loss: 0.388247, acc: 63.28%, op_acc: 41.41%] [G loss: 0.870770]\n",
      "epoch:36 step:28156[D loss: 0.415457, acc: 63.28%, op_acc: 39.06%] [G loss: 0.934694]\n",
      "epoch:36 step:28157[D loss: 0.379825, acc: 64.06%, op_acc: 46.88%] [G loss: 0.870082]\n",
      "epoch:36 step:28158[D loss: 0.395231, acc: 58.59%, op_acc: 45.31%] [G loss: 0.879972]\n",
      "epoch:36 step:28159[D loss: 0.430475, acc: 60.16%, op_acc: 40.62%] [G loss: 0.878157]\n",
      "epoch:36 step:28160[D loss: 0.412647, acc: 55.47%, op_acc: 43.75%] [G loss: 0.881027]\n",
      "epoch:36 step:28161[D loss: 0.408461, acc: 61.72%, op_acc: 42.19%] [G loss: 0.871050]\n",
      "epoch:36 step:28162[D loss: 0.423403, acc: 57.81%, op_acc: 40.62%] [G loss: 0.883136]\n",
      "epoch:36 step:28163[D loss: 0.423660, acc: 65.62%, op_acc: 40.62%] [G loss: 0.887052]\n",
      "epoch:36 step:28164[D loss: 0.438845, acc: 56.25%, op_acc: 33.59%] [G loss: 0.854999]\n",
      "epoch:36 step:28165[D loss: 0.408497, acc: 60.16%, op_acc: 45.31%] [G loss: 0.927900]\n",
      "epoch:36 step:28166[D loss: 0.436302, acc: 55.47%, op_acc: 42.19%] [G loss: 0.903575]\n",
      "epoch:36 step:28167[D loss: 0.397610, acc: 57.81%, op_acc: 45.31%] [G loss: 0.885495]\n",
      "epoch:36 step:28168[D loss: 0.424005, acc: 64.06%, op_acc: 44.53%] [G loss: 0.844362]\n",
      "epoch:36 step:28169[D loss: 0.443534, acc: 55.47%, op_acc: 38.28%] [G loss: 0.952467]\n",
      "epoch:36 step:28170[D loss: 0.447220, acc: 59.38%, op_acc: 42.97%] [G loss: 0.895102]\n",
      "epoch:36 step:28171[D loss: 0.431055, acc: 53.12%, op_acc: 42.97%] [G loss: 0.916348]\n",
      "epoch:36 step:28172[D loss: 0.416112, acc: 60.16%, op_acc: 42.97%] [G loss: 0.868824]\n",
      "epoch:36 step:28173[D loss: 0.441684, acc: 55.47%, op_acc: 41.41%] [G loss: 0.853110]\n",
      "epoch:36 step:28174[D loss: 0.405079, acc: 57.81%, op_acc: 45.31%] [G loss: 0.891795]\n",
      "epoch:36 step:28175[D loss: 0.387384, acc: 59.38%, op_acc: 44.53%] [G loss: 0.825712]\n",
      "epoch:36 step:28176[D loss: 0.377484, acc: 65.62%, op_acc: 38.28%] [G loss: 0.874682]\n",
      "epoch:36 step:28177[D loss: 0.415566, acc: 56.25%, op_acc: 39.06%] [G loss: 0.903916]\n",
      "epoch:36 step:28178[D loss: 0.436578, acc: 54.69%, op_acc: 39.84%] [G loss: 0.815892]\n",
      "epoch:36 step:28179[D loss: 0.421478, acc: 57.03%, op_acc: 42.19%] [G loss: 0.788673]\n",
      "epoch:36 step:28180[D loss: 0.415097, acc: 59.38%, op_acc: 38.28%] [G loss: 0.918701]\n",
      "epoch:36 step:28181[D loss: 0.423087, acc: 53.12%, op_acc: 40.62%] [G loss: 0.815636]\n",
      "epoch:36 step:28182[D loss: 0.399042, acc: 60.94%, op_acc: 43.75%] [G loss: 0.884814]\n",
      "epoch:36 step:28183[D loss: 0.394281, acc: 63.28%, op_acc: 38.28%] [G loss: 0.870076]\n",
      "epoch:36 step:28184[D loss: 0.431989, acc: 55.47%, op_acc: 40.62%] [G loss: 0.950013]\n",
      "epoch:36 step:28185[D loss: 0.402313, acc: 60.16%, op_acc: 44.53%] [G loss: 0.884624]\n",
      "epoch:36 step:28186[D loss: 0.439316, acc: 54.69%, op_acc: 39.06%] [G loss: 0.954852]\n",
      "epoch:36 step:28187[D loss: 0.480224, acc: 54.69%, op_acc: 36.72%] [G loss: 0.963444]\n",
      "epoch:36 step:28188[D loss: 0.396605, acc: 64.06%, op_acc: 42.97%] [G loss: 0.908643]\n",
      "epoch:36 step:28189[D loss: 0.399353, acc: 66.41%, op_acc: 45.31%] [G loss: 0.931320]\n",
      "epoch:36 step:28190[D loss: 0.393486, acc: 62.50%, op_acc: 45.31%] [G loss: 0.880569]\n",
      "epoch:36 step:28191[D loss: 0.425292, acc: 58.59%, op_acc: 35.94%] [G loss: 0.770900]\n",
      "epoch:36 step:28192[D loss: 0.414895, acc: 57.81%, op_acc: 43.75%] [G loss: 0.982871]\n",
      "epoch:36 step:28193[D loss: 0.415612, acc: 60.16%, op_acc: 45.31%] [G loss: 0.850419]\n",
      "epoch:36 step:28194[D loss: 0.439519, acc: 58.59%, op_acc: 32.81%] [G loss: 0.840005]\n",
      "epoch:36 step:28195[D loss: 0.424128, acc: 57.03%, op_acc: 41.41%] [G loss: 0.847365]\n",
      "epoch:36 step:28196[D loss: 0.406109, acc: 69.53%, op_acc: 37.50%] [G loss: 0.864926]\n",
      "epoch:36 step:28197[D loss: 0.433977, acc: 59.38%, op_acc: 34.38%] [G loss: 0.843585]\n",
      "epoch:36 step:28198[D loss: 0.424864, acc: 53.91%, op_acc: 42.19%] [G loss: 0.883916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28199[D loss: 0.427667, acc: 56.25%, op_acc: 35.94%] [G loss: 0.977316]\n",
      "epoch:36 step:28200[D loss: 0.418584, acc: 62.50%, op_acc: 40.62%] [G loss: 0.893607]\n",
      "##############\n",
      "[0.84901689 0.86359845 0.81991139 0.80934273 0.77139668 0.82257501\n",
      " 0.87295949 0.84455264 0.79621838 0.82816762]\n",
      "##########\n",
      "epoch:36 step:28201[D loss: 0.439676, acc: 60.16%, op_acc: 39.06%] [G loss: 0.880497]\n",
      "epoch:36 step:28202[D loss: 0.377898, acc: 63.28%, op_acc: 43.75%] [G loss: 0.885270]\n",
      "epoch:36 step:28203[D loss: 0.429745, acc: 58.59%, op_acc: 41.41%] [G loss: 0.785494]\n",
      "epoch:36 step:28204[D loss: 0.450443, acc: 50.00%, op_acc: 39.06%] [G loss: 0.869326]\n",
      "epoch:36 step:28205[D loss: 0.414495, acc: 64.84%, op_acc: 39.84%] [G loss: 0.814463]\n",
      "epoch:36 step:28206[D loss: 0.428467, acc: 52.34%, op_acc: 42.97%] [G loss: 0.855652]\n",
      "epoch:36 step:28207[D loss: 0.405551, acc: 56.25%, op_acc: 41.41%] [G loss: 0.888360]\n",
      "epoch:36 step:28208[D loss: 0.410759, acc: 60.94%, op_acc: 39.06%] [G loss: 0.900658]\n",
      "epoch:36 step:28209[D loss: 0.388777, acc: 67.19%, op_acc: 44.53%] [G loss: 0.937580]\n",
      "epoch:36 step:28210[D loss: 0.406674, acc: 66.41%, op_acc: 42.19%] [G loss: 0.870243]\n",
      "epoch:36 step:28211[D loss: 0.397279, acc: 63.28%, op_acc: 44.53%] [G loss: 0.921739]\n",
      "epoch:36 step:28212[D loss: 0.439332, acc: 56.25%, op_acc: 34.38%] [G loss: 0.818489]\n",
      "epoch:36 step:28213[D loss: 0.422514, acc: 56.25%, op_acc: 42.19%] [G loss: 0.905422]\n",
      "epoch:36 step:28214[D loss: 0.418722, acc: 66.41%, op_acc: 39.84%] [G loss: 0.834829]\n",
      "epoch:36 step:28215[D loss: 0.413385, acc: 57.03%, op_acc: 42.19%] [G loss: 0.848255]\n",
      "epoch:36 step:28216[D loss: 0.395107, acc: 60.16%, op_acc: 45.31%] [G loss: 0.927948]\n",
      "epoch:36 step:28217[D loss: 0.406448, acc: 61.72%, op_acc: 42.97%] [G loss: 0.938684]\n",
      "epoch:36 step:28218[D loss: 0.407703, acc: 64.06%, op_acc: 40.62%] [G loss: 0.855128]\n",
      "epoch:36 step:28219[D loss: 0.429193, acc: 57.03%, op_acc: 38.28%] [G loss: 0.897521]\n",
      "epoch:36 step:28220[D loss: 0.425370, acc: 60.16%, op_acc: 36.72%] [G loss: 0.835327]\n",
      "epoch:36 step:28221[D loss: 0.415679, acc: 57.03%, op_acc: 38.28%] [G loss: 0.837239]\n",
      "epoch:36 step:28222[D loss: 0.437230, acc: 53.91%, op_acc: 39.84%] [G loss: 0.814832]\n",
      "epoch:36 step:28223[D loss: 0.405870, acc: 64.84%, op_acc: 43.75%] [G loss: 0.881095]\n",
      "epoch:36 step:28224[D loss: 0.407988, acc: 68.75%, op_acc: 43.75%] [G loss: 0.848903]\n",
      "epoch:36 step:28225[D loss: 0.398061, acc: 58.59%, op_acc: 46.09%] [G loss: 0.880576]\n",
      "epoch:36 step:28226[D loss: 0.423548, acc: 57.81%, op_acc: 41.41%] [G loss: 0.878465]\n",
      "epoch:36 step:28227[D loss: 0.430947, acc: 59.38%, op_acc: 39.06%] [G loss: 0.931989]\n",
      "epoch:36 step:28228[D loss: 0.403507, acc: 59.38%, op_acc: 43.75%] [G loss: 0.924681]\n",
      "epoch:36 step:28229[D loss: 0.458765, acc: 50.78%, op_acc: 38.28%] [G loss: 0.817664]\n",
      "epoch:36 step:28230[D loss: 0.382100, acc: 66.41%, op_acc: 50.00%] [G loss: 0.866984]\n",
      "epoch:36 step:28231[D loss: 0.406718, acc: 57.03%, op_acc: 43.75%] [G loss: 1.020319]\n",
      "epoch:36 step:28232[D loss: 0.455962, acc: 53.91%, op_acc: 42.97%] [G loss: 0.880912]\n",
      "epoch:36 step:28233[D loss: 0.414588, acc: 61.72%, op_acc: 41.41%] [G loss: 0.873035]\n",
      "epoch:36 step:28234[D loss: 0.450410, acc: 54.69%, op_acc: 37.50%] [G loss: 0.833652]\n",
      "epoch:36 step:28235[D loss: 0.419279, acc: 51.56%, op_acc: 41.41%] [G loss: 0.844014]\n",
      "epoch:36 step:28236[D loss: 0.412101, acc: 60.16%, op_acc: 45.31%] [G loss: 0.837005]\n",
      "epoch:36 step:28237[D loss: 0.405223, acc: 61.72%, op_acc: 40.62%] [G loss: 0.978153]\n",
      "epoch:36 step:28238[D loss: 0.402339, acc: 61.72%, op_acc: 38.28%] [G loss: 0.858620]\n",
      "epoch:36 step:28239[D loss: 0.432547, acc: 56.25%, op_acc: 39.06%] [G loss: 0.891845]\n",
      "epoch:36 step:28240[D loss: 0.404089, acc: 64.06%, op_acc: 42.19%] [G loss: 0.886644]\n",
      "epoch:36 step:28241[D loss: 0.443253, acc: 54.69%, op_acc: 43.75%] [G loss: 0.839816]\n",
      "epoch:36 step:28242[D loss: 0.420467, acc: 60.16%, op_acc: 39.06%] [G loss: 0.831372]\n",
      "epoch:36 step:28243[D loss: 0.403772, acc: 70.31%, op_acc: 40.62%] [G loss: 0.881442]\n",
      "epoch:36 step:28244[D loss: 0.393223, acc: 72.66%, op_acc: 42.97%] [G loss: 0.888307]\n",
      "epoch:36 step:28245[D loss: 0.422357, acc: 63.28%, op_acc: 39.84%] [G loss: 0.960417]\n",
      "epoch:36 step:28246[D loss: 0.431916, acc: 51.56%, op_acc: 40.62%] [G loss: 0.925349]\n",
      "epoch:36 step:28247[D loss: 0.425891, acc: 56.25%, op_acc: 41.41%] [G loss: 0.864913]\n",
      "epoch:36 step:28248[D loss: 0.385165, acc: 58.59%, op_acc: 47.66%] [G loss: 0.831824]\n",
      "epoch:36 step:28249[D loss: 0.436200, acc: 59.38%, op_acc: 40.62%] [G loss: 0.950845]\n",
      "epoch:36 step:28250[D loss: 0.410854, acc: 59.38%, op_acc: 44.53%] [G loss: 0.872722]\n",
      "##############\n",
      "[0.85656098 0.86305082 0.81049295 0.8025461  0.79913907 0.81970544\n",
      " 0.88182086 0.84076431 0.8008577  0.82753855]\n",
      "##########\n",
      "epoch:36 step:28251[D loss: 0.438166, acc: 52.34%, op_acc: 37.50%] [G loss: 0.864748]\n",
      "epoch:36 step:28252[D loss: 0.402144, acc: 55.47%, op_acc: 43.75%] [G loss: 0.887987]\n",
      "epoch:36 step:28253[D loss: 0.411837, acc: 64.84%, op_acc: 43.75%] [G loss: 0.866676]\n",
      "epoch:36 step:28254[D loss: 0.427007, acc: 57.03%, op_acc: 42.19%] [G loss: 0.892410]\n",
      "epoch:36 step:28255[D loss: 0.415640, acc: 57.03%, op_acc: 42.97%] [G loss: 0.917801]\n",
      "epoch:36 step:28256[D loss: 0.423167, acc: 66.41%, op_acc: 42.97%] [G loss: 0.882538]\n",
      "epoch:36 step:28257[D loss: 0.413325, acc: 66.41%, op_acc: 38.28%] [G loss: 0.885765]\n",
      "epoch:36 step:28258[D loss: 0.410062, acc: 64.84%, op_acc: 40.62%] [G loss: 0.931316]\n",
      "epoch:36 step:28259[D loss: 0.419457, acc: 57.81%, op_acc: 41.41%] [G loss: 0.832563]\n",
      "epoch:36 step:28260[D loss: 0.415953, acc: 60.16%, op_acc: 41.41%] [G loss: 0.843441]\n",
      "epoch:36 step:28261[D loss: 0.433694, acc: 54.69%, op_acc: 42.97%] [G loss: 0.818192]\n",
      "epoch:36 step:28262[D loss: 0.397131, acc: 64.84%, op_acc: 38.28%] [G loss: 0.867054]\n",
      "epoch:36 step:28263[D loss: 0.404888, acc: 66.41%, op_acc: 47.66%] [G loss: 0.908935]\n",
      "epoch:36 step:28264[D loss: 0.419716, acc: 60.16%, op_acc: 36.72%] [G loss: 0.848577]\n",
      "epoch:36 step:28265[D loss: 0.403845, acc: 67.97%, op_acc: 42.97%] [G loss: 0.847547]\n",
      "epoch:36 step:28266[D loss: 0.413408, acc: 62.50%, op_acc: 39.06%] [G loss: 0.877127]\n",
      "epoch:36 step:28267[D loss: 0.403990, acc: 60.94%, op_acc: 42.19%] [G loss: 0.960912]\n",
      "epoch:36 step:28268[D loss: 0.403683, acc: 56.25%, op_acc: 43.75%] [G loss: 0.855484]\n",
      "epoch:36 step:28269[D loss: 0.411965, acc: 57.81%, op_acc: 41.41%] [G loss: 0.913892]\n",
      "epoch:36 step:28270[D loss: 0.416924, acc: 60.16%, op_acc: 46.09%] [G loss: 0.879943]\n",
      "epoch:36 step:28271[D loss: 0.438320, acc: 57.03%, op_acc: 41.41%] [G loss: 0.835709]\n",
      "epoch:36 step:28272[D loss: 0.402221, acc: 62.50%, op_acc: 42.97%] [G loss: 0.802495]\n",
      "epoch:36 step:28273[D loss: 0.426200, acc: 56.25%, op_acc: 43.75%] [G loss: 0.907804]\n",
      "epoch:36 step:28274[D loss: 0.435729, acc: 57.03%, op_acc: 39.84%] [G loss: 0.975816]\n",
      "epoch:36 step:28275[D loss: 0.399991, acc: 70.31%, op_acc: 44.53%] [G loss: 0.923008]\n",
      "epoch:36 step:28276[D loss: 0.412572, acc: 64.06%, op_acc: 39.06%] [G loss: 0.895539]\n",
      "epoch:36 step:28277[D loss: 0.427629, acc: 57.03%, op_acc: 40.62%] [G loss: 0.874284]\n",
      "epoch:36 step:28278[D loss: 0.423826, acc: 55.47%, op_acc: 38.28%] [G loss: 0.836657]\n",
      "epoch:36 step:28279[D loss: 0.456610, acc: 53.91%, op_acc: 37.50%] [G loss: 0.851313]\n",
      "epoch:36 step:28280[D loss: 0.431373, acc: 56.25%, op_acc: 33.59%] [G loss: 0.883416]\n",
      "epoch:36 step:28281[D loss: 0.435864, acc: 58.59%, op_acc: 39.84%] [G loss: 0.810986]\n",
      "epoch:36 step:28282[D loss: 0.423703, acc: 58.59%, op_acc: 36.72%] [G loss: 0.912521]\n",
      "epoch:36 step:28283[D loss: 0.414621, acc: 57.03%, op_acc: 43.75%] [G loss: 0.849687]\n",
      "epoch:36 step:28284[D loss: 0.413347, acc: 61.72%, op_acc: 49.22%] [G loss: 0.889656]\n",
      "epoch:36 step:28285[D loss: 0.436526, acc: 55.47%, op_acc: 42.19%] [G loss: 0.956414]\n",
      "epoch:36 step:28286[D loss: 0.393886, acc: 64.84%, op_acc: 44.53%] [G loss: 0.866104]\n",
      "epoch:36 step:28287[D loss: 0.441173, acc: 56.25%, op_acc: 37.50%] [G loss: 0.850736]\n",
      "epoch:36 step:28288[D loss: 0.403945, acc: 60.94%, op_acc: 44.53%] [G loss: 0.809615]\n",
      "epoch:36 step:28289[D loss: 0.472228, acc: 43.75%, op_acc: 39.84%] [G loss: 0.925959]\n",
      "epoch:36 step:28290[D loss: 0.431775, acc: 60.16%, op_acc: 38.28%] [G loss: 0.912619]\n",
      "epoch:36 step:28291[D loss: 0.395342, acc: 64.84%, op_acc: 40.62%] [G loss: 0.914022]\n",
      "epoch:36 step:28292[D loss: 0.434380, acc: 58.59%, op_acc: 42.97%] [G loss: 0.918180]\n",
      "epoch:36 step:28293[D loss: 0.397281, acc: 60.16%, op_acc: 39.84%] [G loss: 0.952834]\n",
      "epoch:36 step:28294[D loss: 0.418797, acc: 57.81%, op_acc: 41.41%] [G loss: 0.952873]\n",
      "epoch:36 step:28295[D loss: 0.411332, acc: 63.28%, op_acc: 43.75%] [G loss: 0.943894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28296[D loss: 0.417449, acc: 66.41%, op_acc: 39.84%] [G loss: 0.913322]\n",
      "epoch:36 step:28297[D loss: 0.394353, acc: 67.97%, op_acc: 42.97%] [G loss: 0.903736]\n",
      "epoch:36 step:28298[D loss: 0.385614, acc: 64.84%, op_acc: 39.06%] [G loss: 0.875718]\n",
      "epoch:36 step:28299[D loss: 0.436940, acc: 48.44%, op_acc: 38.28%] [G loss: 0.898220]\n",
      "epoch:36 step:28300[D loss: 0.398597, acc: 60.94%, op_acc: 35.94%] [G loss: 0.910714]\n",
      "##############\n",
      "[0.85246124 0.86057391 0.81192319 0.80989931 0.79059079 0.81674222\n",
      " 0.86843694 0.80316951 0.82261858 0.84378226]\n",
      "##########\n",
      "epoch:36 step:28301[D loss: 0.431129, acc: 57.81%, op_acc: 33.59%] [G loss: 0.897644]\n",
      "epoch:36 step:28302[D loss: 0.432819, acc: 53.91%, op_acc: 43.75%] [G loss: 0.873033]\n",
      "epoch:36 step:28303[D loss: 0.425764, acc: 57.03%, op_acc: 39.84%] [G loss: 0.934816]\n",
      "epoch:36 step:28304[D loss: 0.415682, acc: 58.59%, op_acc: 41.41%] [G loss: 0.890944]\n",
      "epoch:36 step:28305[D loss: 0.405267, acc: 63.28%, op_acc: 37.50%] [G loss: 0.854858]\n",
      "epoch:36 step:28306[D loss: 0.433702, acc: 57.03%, op_acc: 41.41%] [G loss: 0.784286]\n",
      "epoch:36 step:28307[D loss: 0.413603, acc: 56.25%, op_acc: 46.88%] [G loss: 0.925781]\n",
      "epoch:36 step:28308[D loss: 0.424426, acc: 52.34%, op_acc: 38.28%] [G loss: 0.841404]\n",
      "epoch:36 step:28309[D loss: 0.432882, acc: 57.03%, op_acc: 36.72%] [G loss: 0.881298]\n",
      "epoch:36 step:28310[D loss: 0.393052, acc: 61.72%, op_acc: 46.09%] [G loss: 0.878692]\n",
      "epoch:36 step:28311[D loss: 0.443214, acc: 53.91%, op_acc: 35.94%] [G loss: 0.857505]\n",
      "epoch:36 step:28312[D loss: 0.416372, acc: 64.84%, op_acc: 43.75%] [G loss: 0.868509]\n",
      "epoch:36 step:28313[D loss: 0.447094, acc: 50.78%, op_acc: 38.28%] [G loss: 0.917923]\n",
      "epoch:36 step:28314[D loss: 0.415085, acc: 59.38%, op_acc: 41.41%] [G loss: 0.865300]\n",
      "epoch:36 step:28315[D loss: 0.453857, acc: 53.12%, op_acc: 39.06%] [G loss: 0.900567]\n",
      "epoch:36 step:28316[D loss: 0.428636, acc: 57.03%, op_acc: 35.94%] [G loss: 0.970054]\n",
      "epoch:36 step:28317[D loss: 0.404218, acc: 67.19%, op_acc: 44.53%] [G loss: 0.830123]\n",
      "epoch:36 step:28318[D loss: 0.417417, acc: 61.72%, op_acc: 42.19%] [G loss: 0.856016]\n",
      "epoch:36 step:28319[D loss: 0.426737, acc: 63.28%, op_acc: 35.94%] [G loss: 0.937224]\n",
      "epoch:36 step:28320[D loss: 0.404542, acc: 58.59%, op_acc: 42.19%] [G loss: 0.803228]\n",
      "epoch:36 step:28321[D loss: 0.404359, acc: 57.81%, op_acc: 44.53%] [G loss: 0.823577]\n",
      "epoch:36 step:28322[D loss: 0.411716, acc: 53.91%, op_acc: 42.19%] [G loss: 0.823408]\n",
      "epoch:36 step:28323[D loss: 0.390778, acc: 59.38%, op_acc: 47.66%] [G loss: 0.958463]\n",
      "epoch:36 step:28324[D loss: 0.417295, acc: 67.97%, op_acc: 35.94%] [G loss: 0.921500]\n",
      "epoch:36 step:28325[D loss: 0.427756, acc: 53.91%, op_acc: 41.41%] [G loss: 0.939512]\n",
      "epoch:36 step:28326[D loss: 0.447444, acc: 55.47%, op_acc: 39.84%] [G loss: 0.886907]\n",
      "epoch:36 step:28327[D loss: 0.370248, acc: 73.44%, op_acc: 40.62%] [G loss: 0.952339]\n",
      "epoch:36 step:28328[D loss: 0.409482, acc: 60.16%, op_acc: 42.97%] [G loss: 0.877444]\n",
      "epoch:36 step:28329[D loss: 0.404647, acc: 64.06%, op_acc: 42.19%] [G loss: 0.908488]\n",
      "epoch:36 step:28330[D loss: 0.424484, acc: 63.28%, op_acc: 35.16%] [G loss: 0.862711]\n",
      "epoch:36 step:28331[D loss: 0.444094, acc: 60.16%, op_acc: 39.06%] [G loss: 0.816536]\n",
      "epoch:36 step:28332[D loss: 0.410376, acc: 63.28%, op_acc: 38.28%] [G loss: 0.899232]\n",
      "epoch:36 step:28333[D loss: 0.408052, acc: 62.50%, op_acc: 40.62%] [G loss: 0.920225]\n",
      "epoch:36 step:28334[D loss: 0.420278, acc: 56.25%, op_acc: 43.75%] [G loss: 0.972723]\n",
      "epoch:36 step:28335[D loss: 0.396962, acc: 64.84%, op_acc: 42.19%] [G loss: 0.868515]\n",
      "epoch:36 step:28336[D loss: 0.426355, acc: 55.47%, op_acc: 39.06%] [G loss: 0.881574]\n",
      "epoch:36 step:28337[D loss: 0.406112, acc: 64.06%, op_acc: 40.62%] [G loss: 0.904511]\n",
      "epoch:36 step:28338[D loss: 0.440782, acc: 60.16%, op_acc: 37.50%] [G loss: 0.849358]\n",
      "epoch:36 step:28339[D loss: 0.433210, acc: 55.47%, op_acc: 40.62%] [G loss: 0.867146]\n",
      "epoch:36 step:28340[D loss: 0.434310, acc: 57.03%, op_acc: 40.62%] [G loss: 0.906946]\n",
      "epoch:36 step:28341[D loss: 0.411646, acc: 62.50%, op_acc: 45.31%] [G loss: 0.990354]\n",
      "epoch:36 step:28342[D loss: 0.446701, acc: 53.91%, op_acc: 40.62%] [G loss: 0.890788]\n",
      "epoch:36 step:28343[D loss: 0.414697, acc: 58.59%, op_acc: 46.09%] [G loss: 0.817878]\n",
      "epoch:36 step:28344[D loss: 0.414730, acc: 60.16%, op_acc: 40.62%] [G loss: 0.826208]\n",
      "epoch:36 step:28345[D loss: 0.424705, acc: 59.38%, op_acc: 45.31%] [G loss: 0.835844]\n",
      "epoch:36 step:28346[D loss: 0.437917, acc: 52.34%, op_acc: 42.19%] [G loss: 0.914739]\n",
      "epoch:36 step:28347[D loss: 0.393032, acc: 58.59%, op_acc: 48.44%] [G loss: 0.846359]\n",
      "epoch:36 step:28348[D loss: 0.392400, acc: 66.41%, op_acc: 42.97%] [G loss: 0.908812]\n",
      "epoch:36 step:28349[D loss: 0.405313, acc: 64.06%, op_acc: 42.19%] [G loss: 0.907062]\n",
      "epoch:36 step:28350[D loss: 0.422508, acc: 64.06%, op_acc: 40.62%] [G loss: 0.906816]\n",
      "##############\n",
      "[0.85968233 0.87174294 0.81119443 0.81644922 0.79061128 0.82754602\n",
      " 0.90041382 0.84065463 0.81139089 0.81864152]\n",
      "##########\n",
      "epoch:36 step:28351[D loss: 0.391018, acc: 61.72%, op_acc: 47.66%] [G loss: 0.836734]\n",
      "epoch:36 step:28352[D loss: 0.414874, acc: 60.16%, op_acc: 39.06%] [G loss: 0.918617]\n",
      "epoch:36 step:28353[D loss: 0.440047, acc: 55.47%, op_acc: 35.16%] [G loss: 0.855301]\n",
      "epoch:36 step:28354[D loss: 0.418902, acc: 60.94%, op_acc: 41.41%] [G loss: 0.941747]\n",
      "epoch:36 step:28355[D loss: 0.396771, acc: 64.06%, op_acc: 42.19%] [G loss: 0.884757]\n",
      "epoch:36 step:28356[D loss: 0.434643, acc: 53.12%, op_acc: 46.09%] [G loss: 0.898091]\n",
      "epoch:36 step:28357[D loss: 0.435932, acc: 52.34%, op_acc: 42.19%] [G loss: 0.862592]\n",
      "epoch:36 step:28358[D loss: 0.390481, acc: 64.06%, op_acc: 48.44%] [G loss: 0.931422]\n",
      "epoch:36 step:28359[D loss: 0.411336, acc: 59.38%, op_acc: 39.06%] [G loss: 0.876514]\n",
      "epoch:36 step:28360[D loss: 0.444802, acc: 59.38%, op_acc: 40.62%] [G loss: 0.953750]\n",
      "epoch:36 step:28361[D loss: 0.436298, acc: 50.00%, op_acc: 40.62%] [G loss: 0.833774]\n",
      "epoch:36 step:28362[D loss: 0.402205, acc: 67.19%, op_acc: 42.97%] [G loss: 0.879231]\n",
      "epoch:36 step:28363[D loss: 0.377128, acc: 69.53%, op_acc: 43.75%] [G loss: 0.860999]\n",
      "epoch:36 step:28364[D loss: 0.438297, acc: 53.12%, op_acc: 40.62%] [G loss: 0.878172]\n",
      "epoch:36 step:28365[D loss: 0.426949, acc: 61.72%, op_acc: 42.19%] [G loss: 0.841786]\n",
      "epoch:36 step:28366[D loss: 0.432069, acc: 63.28%, op_acc: 35.16%] [G loss: 0.911148]\n",
      "epoch:36 step:28367[D loss: 0.395723, acc: 62.50%, op_acc: 40.62%] [G loss: 0.897722]\n",
      "epoch:36 step:28368[D loss: 0.426945, acc: 57.03%, op_acc: 42.97%] [G loss: 0.860627]\n",
      "epoch:36 step:28369[D loss: 0.429061, acc: 51.56%, op_acc: 39.84%] [G loss: 0.824755]\n",
      "epoch:36 step:28370[D loss: 0.442523, acc: 56.25%, op_acc: 35.94%] [G loss: 0.832470]\n",
      "epoch:36 step:28371[D loss: 0.425156, acc: 61.72%, op_acc: 38.28%] [G loss: 0.778966]\n",
      "epoch:36 step:28372[D loss: 0.418372, acc: 59.38%, op_acc: 41.41%] [G loss: 0.835001]\n",
      "epoch:36 step:28373[D loss: 0.422339, acc: 58.59%, op_acc: 42.19%] [G loss: 0.982948]\n",
      "epoch:36 step:28374[D loss: 0.424422, acc: 58.59%, op_acc: 43.75%] [G loss: 0.885331]\n",
      "epoch:36 step:28375[D loss: 0.431274, acc: 58.59%, op_acc: 42.97%] [G loss: 0.871739]\n",
      "epoch:36 step:28376[D loss: 0.430967, acc: 56.25%, op_acc: 39.84%] [G loss: 0.842089]\n",
      "epoch:36 step:28377[D loss: 0.383772, acc: 67.19%, op_acc: 42.97%] [G loss: 0.954935]\n",
      "epoch:36 step:28378[D loss: 0.414054, acc: 60.16%, op_acc: 40.62%] [G loss: 0.873542]\n",
      "epoch:36 step:28379[D loss: 0.424414, acc: 60.16%, op_acc: 35.94%] [G loss: 0.834034]\n",
      "epoch:36 step:28380[D loss: 0.395590, acc: 64.84%, op_acc: 42.97%] [G loss: 0.849290]\n",
      "epoch:36 step:28381[D loss: 0.394740, acc: 62.50%, op_acc: 43.75%] [G loss: 0.942202]\n",
      "epoch:36 step:28382[D loss: 0.408087, acc: 60.94%, op_acc: 42.19%] [G loss: 0.868793]\n",
      "epoch:36 step:28383[D loss: 0.442174, acc: 51.56%, op_acc: 35.16%] [G loss: 0.930475]\n",
      "epoch:36 step:28384[D loss: 0.413324, acc: 54.69%, op_acc: 43.75%] [G loss: 0.878667]\n",
      "epoch:36 step:28385[D loss: 0.415111, acc: 57.03%, op_acc: 42.97%] [G loss: 0.894164]\n",
      "epoch:36 step:28386[D loss: 0.380415, acc: 65.62%, op_acc: 46.88%] [G loss: 0.984625]\n",
      "epoch:36 step:28387[D loss: 0.437728, acc: 56.25%, op_acc: 39.06%] [G loss: 0.866663]\n",
      "epoch:36 step:28388[D loss: 0.446530, acc: 56.25%, op_acc: 35.16%] [G loss: 0.872799]\n",
      "epoch:36 step:28389[D loss: 0.411690, acc: 56.25%, op_acc: 42.97%] [G loss: 0.929153]\n",
      "epoch:36 step:28390[D loss: 0.414336, acc: 63.28%, op_acc: 43.75%] [G loss: 0.813069]\n",
      "epoch:36 step:28391[D loss: 0.433262, acc: 59.38%, op_acc: 42.19%] [G loss: 0.885537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28392[D loss: 0.437517, acc: 51.56%, op_acc: 39.84%] [G loss: 0.976472]\n",
      "epoch:36 step:28393[D loss: 0.405986, acc: 65.62%, op_acc: 39.06%] [G loss: 0.896582]\n",
      "epoch:36 step:28394[D loss: 0.433547, acc: 59.38%, op_acc: 35.94%] [G loss: 0.808846]\n",
      "epoch:36 step:28395[D loss: 0.418812, acc: 57.81%, op_acc: 41.41%] [G loss: 0.855781]\n",
      "epoch:36 step:28396[D loss: 0.424015, acc: 56.25%, op_acc: 42.97%] [G loss: 0.822651]\n",
      "epoch:36 step:28397[D loss: 0.420754, acc: 63.28%, op_acc: 39.84%] [G loss: 0.886046]\n",
      "epoch:36 step:28398[D loss: 0.425443, acc: 63.28%, op_acc: 43.75%] [G loss: 0.862989]\n",
      "epoch:36 step:28399[D loss: 0.382055, acc: 66.41%, op_acc: 39.84%] [G loss: 0.868145]\n",
      "epoch:36 step:28400[D loss: 0.422529, acc: 59.38%, op_acc: 40.62%] [G loss: 0.961391]\n",
      "##############\n",
      "[0.85903713 0.86603353 0.80520638 0.81376935 0.79106505 0.82748586\n",
      " 0.8861996  0.81373959 0.82191619 0.8165165 ]\n",
      "##########\n",
      "epoch:36 step:28401[D loss: 0.447940, acc: 47.66%, op_acc: 35.16%] [G loss: 0.892589]\n",
      "epoch:36 step:28402[D loss: 0.422026, acc: 54.69%, op_acc: 38.28%] [G loss: 0.891818]\n",
      "epoch:36 step:28403[D loss: 0.440692, acc: 57.81%, op_acc: 41.41%] [G loss: 0.870493]\n",
      "epoch:36 step:28404[D loss: 0.414392, acc: 61.72%, op_acc: 43.75%] [G loss: 0.848099]\n",
      "epoch:36 step:28405[D loss: 0.447047, acc: 55.47%, op_acc: 42.97%] [G loss: 0.863775]\n",
      "epoch:36 step:28406[D loss: 0.390486, acc: 67.97%, op_acc: 45.31%] [G loss: 0.857995]\n",
      "epoch:36 step:28407[D loss: 0.419876, acc: 62.50%, op_acc: 41.41%] [G loss: 0.842295]\n",
      "epoch:36 step:28408[D loss: 0.450704, acc: 55.47%, op_acc: 35.94%] [G loss: 0.857675]\n",
      "epoch:36 step:28409[D loss: 0.428496, acc: 52.34%, op_acc: 35.16%] [G loss: 0.828707]\n",
      "epoch:36 step:28410[D loss: 0.438574, acc: 56.25%, op_acc: 38.28%] [G loss: 0.915558]\n",
      "epoch:36 step:28411[D loss: 0.439274, acc: 55.47%, op_acc: 36.72%] [G loss: 0.904894]\n",
      "epoch:36 step:28412[D loss: 0.397406, acc: 60.16%, op_acc: 46.09%] [G loss: 0.851277]\n",
      "epoch:36 step:28413[D loss: 0.416316, acc: 61.72%, op_acc: 38.28%] [G loss: 0.916639]\n",
      "epoch:36 step:28414[D loss: 0.438704, acc: 60.94%, op_acc: 38.28%] [G loss: 0.843631]\n",
      "epoch:36 step:28415[D loss: 0.413799, acc: 56.25%, op_acc: 46.09%] [G loss: 0.870946]\n",
      "epoch:36 step:28416[D loss: 0.445720, acc: 53.12%, op_acc: 34.38%] [G loss: 0.873536]\n",
      "epoch:36 step:28417[D loss: 0.422029, acc: 55.47%, op_acc: 35.94%] [G loss: 0.864941]\n",
      "epoch:36 step:28418[D loss: 0.400547, acc: 60.16%, op_acc: 42.19%] [G loss: 0.904602]\n",
      "epoch:36 step:28419[D loss: 0.424926, acc: 60.16%, op_acc: 42.97%] [G loss: 0.836500]\n",
      "epoch:36 step:28420[D loss: 0.404824, acc: 62.50%, op_acc: 44.53%] [G loss: 0.967459]\n",
      "epoch:36 step:28421[D loss: 0.407690, acc: 62.50%, op_acc: 39.06%] [G loss: 0.828197]\n",
      "epoch:36 step:28422[D loss: 0.438833, acc: 55.47%, op_acc: 38.28%] [G loss: 0.908467]\n",
      "epoch:36 step:28423[D loss: 0.418365, acc: 63.28%, op_acc: 42.97%] [G loss: 0.906154]\n",
      "epoch:36 step:28424[D loss: 0.423680, acc: 57.03%, op_acc: 42.19%] [G loss: 0.924027]\n",
      "epoch:36 step:28425[D loss: 0.480260, acc: 53.12%, op_acc: 37.50%] [G loss: 0.900582]\n",
      "epoch:36 step:28426[D loss: 0.409602, acc: 63.28%, op_acc: 45.31%] [G loss: 0.869033]\n",
      "epoch:36 step:28427[D loss: 0.411844, acc: 64.84%, op_acc: 42.97%] [G loss: 0.921422]\n",
      "epoch:36 step:28428[D loss: 0.443479, acc: 54.69%, op_acc: 38.28%] [G loss: 0.884482]\n",
      "epoch:36 step:28429[D loss: 0.436026, acc: 50.78%, op_acc: 45.31%] [G loss: 0.822453]\n",
      "epoch:36 step:28430[D loss: 0.435511, acc: 57.03%, op_acc: 38.28%] [G loss: 0.808512]\n",
      "epoch:36 step:28431[D loss: 0.425875, acc: 53.91%, op_acc: 46.88%] [G loss: 0.894937]\n",
      "epoch:36 step:28432[D loss: 0.440392, acc: 59.38%, op_acc: 35.94%] [G loss: 0.945898]\n",
      "epoch:36 step:28433[D loss: 0.396714, acc: 67.19%, op_acc: 39.84%] [G loss: 0.954260]\n",
      "epoch:36 step:28434[D loss: 0.432979, acc: 60.16%, op_acc: 35.94%] [G loss: 0.876747]\n",
      "epoch:36 step:28435[D loss: 0.457537, acc: 51.56%, op_acc: 35.16%] [G loss: 0.904934]\n",
      "epoch:36 step:28436[D loss: 0.419266, acc: 58.59%, op_acc: 35.16%] [G loss: 0.814913]\n",
      "epoch:36 step:28437[D loss: 0.414365, acc: 61.72%, op_acc: 41.41%] [G loss: 1.074116]\n",
      "epoch:36 step:28438[D loss: 0.402876, acc: 64.84%, op_acc: 40.62%] [G loss: 0.976926]\n",
      "epoch:36 step:28439[D loss: 0.429961, acc: 61.72%, op_acc: 40.62%] [G loss: 0.853406]\n",
      "epoch:36 step:28440[D loss: 0.450866, acc: 50.00%, op_acc: 39.84%] [G loss: 0.865973]\n",
      "epoch:36 step:28441[D loss: 0.439825, acc: 54.69%, op_acc: 40.62%] [G loss: 0.920084]\n",
      "epoch:36 step:28442[D loss: 0.417431, acc: 55.47%, op_acc: 41.41%] [G loss: 0.852607]\n",
      "epoch:36 step:28443[D loss: 0.425037, acc: 53.91%, op_acc: 41.41%] [G loss: 0.823705]\n",
      "epoch:36 step:28444[D loss: 0.423440, acc: 64.84%, op_acc: 39.84%] [G loss: 0.928539]\n",
      "epoch:36 step:28445[D loss: 0.411871, acc: 57.81%, op_acc: 42.19%] [G loss: 0.863698]\n",
      "epoch:36 step:28446[D loss: 0.399588, acc: 60.94%, op_acc: 42.97%] [G loss: 0.880215]\n",
      "epoch:36 step:28447[D loss: 0.413628, acc: 60.16%, op_acc: 40.62%] [G loss: 0.866844]\n",
      "epoch:36 step:28448[D loss: 0.429234, acc: 53.91%, op_acc: 36.72%] [G loss: 0.898028]\n",
      "epoch:36 step:28449[D loss: 0.447422, acc: 55.47%, op_acc: 33.59%] [G loss: 0.788338]\n",
      "epoch:36 step:28450[D loss: 0.432125, acc: 57.03%, op_acc: 41.41%] [G loss: 0.898199]\n",
      "##############\n",
      "[0.86070034 0.88406749 0.81155742 0.79873696 0.78517629 0.82835434\n",
      " 0.87260116 0.8198715  0.79149961 0.82168214]\n",
      "##########\n",
      "epoch:36 step:28451[D loss: 0.423514, acc: 55.47%, op_acc: 38.28%] [G loss: 0.879679]\n",
      "epoch:36 step:28452[D loss: 0.404352, acc: 62.50%, op_acc: 39.06%] [G loss: 0.844173]\n",
      "epoch:36 step:28453[D loss: 0.434642, acc: 60.94%, op_acc: 38.28%] [G loss: 0.909521]\n",
      "epoch:36 step:28454[D loss: 0.402045, acc: 61.72%, op_acc: 43.75%] [G loss: 0.837407]\n",
      "epoch:36 step:28455[D loss: 0.412126, acc: 62.50%, op_acc: 42.97%] [G loss: 0.924482]\n",
      "epoch:36 step:28456[D loss: 0.424268, acc: 61.72%, op_acc: 42.19%] [G loss: 0.896910]\n",
      "epoch:36 step:28457[D loss: 0.450932, acc: 50.00%, op_acc: 38.28%] [G loss: 0.946711]\n",
      "epoch:36 step:28458[D loss: 0.438184, acc: 53.12%, op_acc: 41.41%] [G loss: 0.798831]\n",
      "epoch:36 step:28459[D loss: 0.434302, acc: 60.94%, op_acc: 40.62%] [G loss: 0.892615]\n",
      "epoch:36 step:28460[D loss: 0.407668, acc: 57.81%, op_acc: 42.97%] [G loss: 0.846393]\n",
      "epoch:36 step:28461[D loss: 0.408476, acc: 64.06%, op_acc: 39.84%] [G loss: 0.871889]\n",
      "epoch:36 step:28462[D loss: 0.421296, acc: 57.03%, op_acc: 43.75%] [G loss: 0.918507]\n",
      "epoch:36 step:28463[D loss: 0.428886, acc: 59.38%, op_acc: 41.41%] [G loss: 0.905266]\n",
      "epoch:36 step:28464[D loss: 0.407267, acc: 62.50%, op_acc: 40.62%] [G loss: 0.901906]\n",
      "epoch:36 step:28465[D loss: 0.415996, acc: 56.25%, op_acc: 40.62%] [G loss: 0.887515]\n",
      "epoch:36 step:28466[D loss: 0.411811, acc: 60.16%, op_acc: 37.50%] [G loss: 0.969973]\n",
      "epoch:36 step:28467[D loss: 0.447019, acc: 59.38%, op_acc: 38.28%] [G loss: 0.861402]\n",
      "epoch:36 step:28468[D loss: 0.426212, acc: 58.59%, op_acc: 39.84%] [G loss: 0.909945]\n",
      "epoch:36 step:28469[D loss: 0.374641, acc: 67.19%, op_acc: 46.88%] [G loss: 0.894374]\n",
      "epoch:36 step:28470[D loss: 0.412451, acc: 59.38%, op_acc: 38.28%] [G loss: 0.847350]\n",
      "epoch:36 step:28471[D loss: 0.407227, acc: 67.19%, op_acc: 37.50%] [G loss: 0.886957]\n",
      "epoch:36 step:28472[D loss: 0.408862, acc: 59.38%, op_acc: 46.09%] [G loss: 0.944487]\n",
      "epoch:36 step:28473[D loss: 0.423390, acc: 60.94%, op_acc: 35.16%] [G loss: 0.873379]\n",
      "epoch:36 step:28474[D loss: 0.422153, acc: 63.28%, op_acc: 39.84%] [G loss: 0.874007]\n",
      "epoch:36 step:28475[D loss: 0.427635, acc: 58.59%, op_acc: 42.97%] [G loss: 0.984874]\n",
      "epoch:36 step:28476[D loss: 0.384601, acc: 69.53%, op_acc: 39.84%] [G loss: 0.917398]\n",
      "epoch:36 step:28477[D loss: 0.413376, acc: 62.50%, op_acc: 39.06%] [G loss: 0.896133]\n",
      "epoch:36 step:28478[D loss: 0.381822, acc: 67.19%, op_acc: 41.41%] [G loss: 0.908700]\n",
      "epoch:36 step:28479[D loss: 0.415826, acc: 63.28%, op_acc: 44.53%] [G loss: 0.930926]\n",
      "epoch:36 step:28480[D loss: 0.409544, acc: 63.28%, op_acc: 42.19%] [G loss: 0.951325]\n",
      "epoch:36 step:28481[D loss: 0.381377, acc: 57.81%, op_acc: 46.88%] [G loss: 0.897849]\n",
      "epoch:36 step:28482[D loss: 0.399728, acc: 64.06%, op_acc: 42.19%] [G loss: 0.882317]\n",
      "epoch:36 step:28483[D loss: 0.449403, acc: 60.16%, op_acc: 33.59%] [G loss: 0.919556]\n",
      "epoch:36 step:28484[D loss: 0.409380, acc: 63.28%, op_acc: 36.72%] [G loss: 0.891266]\n",
      "epoch:36 step:28485[D loss: 0.407928, acc: 62.50%, op_acc: 39.84%] [G loss: 0.893135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28486[D loss: 0.404556, acc: 60.94%, op_acc: 40.62%] [G loss: 0.840112]\n",
      "epoch:36 step:28487[D loss: 0.415969, acc: 55.47%, op_acc: 45.31%] [G loss: 0.875758]\n",
      "epoch:36 step:28488[D loss: 0.427501, acc: 53.91%, op_acc: 41.41%] [G loss: 0.794724]\n",
      "epoch:36 step:28489[D loss: 0.392598, acc: 62.50%, op_acc: 46.88%] [G loss: 0.956421]\n",
      "epoch:36 step:28490[D loss: 0.410451, acc: 64.06%, op_acc: 39.06%] [G loss: 0.894014]\n",
      "epoch:36 step:28491[D loss: 0.388586, acc: 66.41%, op_acc: 38.28%] [G loss: 0.932490]\n",
      "epoch:36 step:28492[D loss: 0.382576, acc: 69.53%, op_acc: 42.19%] [G loss: 0.887877]\n",
      "epoch:36 step:28493[D loss: 0.411814, acc: 62.50%, op_acc: 36.72%] [G loss: 0.885980]\n",
      "epoch:36 step:28494[D loss: 0.442627, acc: 58.59%, op_acc: 38.28%] [G loss: 0.848433]\n",
      "epoch:36 step:28495[D loss: 0.385945, acc: 62.50%, op_acc: 44.53%] [G loss: 0.932463]\n",
      "epoch:36 step:28496[D loss: 0.395454, acc: 62.50%, op_acc: 44.53%] [G loss: 0.908308]\n",
      "epoch:36 step:28497[D loss: 0.411972, acc: 60.16%, op_acc: 38.28%] [G loss: 0.881578]\n",
      "epoch:36 step:28498[D loss: 0.430723, acc: 56.25%, op_acc: 40.62%] [G loss: 0.898551]\n",
      "epoch:36 step:28499[D loss: 0.389488, acc: 62.50%, op_acc: 46.88%] [G loss: 0.912408]\n",
      "epoch:36 step:28500[D loss: 0.414646, acc: 61.72%, op_acc: 39.84%] [G loss: 0.864732]\n",
      "##############\n",
      "[0.87313243 0.84521617 0.79984025 0.81196682 0.7883359  0.82821428\n",
      " 0.87235915 0.81623192 0.80391622 0.81044235]\n",
      "##########\n",
      "epoch:36 step:28501[D loss: 0.410650, acc: 63.28%, op_acc: 44.53%] [G loss: 0.859208]\n",
      "epoch:36 step:28502[D loss: 0.417776, acc: 63.28%, op_acc: 42.19%] [G loss: 0.873580]\n",
      "epoch:36 step:28503[D loss: 0.434219, acc: 57.03%, op_acc: 40.62%] [G loss: 0.912187]\n",
      "epoch:36 step:28504[D loss: 0.438490, acc: 58.59%, op_acc: 39.84%] [G loss: 0.951066]\n",
      "epoch:36 step:28505[D loss: 0.419359, acc: 61.72%, op_acc: 42.97%] [G loss: 0.879336]\n",
      "epoch:36 step:28506[D loss: 0.417379, acc: 63.28%, op_acc: 43.75%] [G loss: 0.871379]\n",
      "epoch:36 step:28507[D loss: 0.399440, acc: 61.72%, op_acc: 42.19%] [G loss: 0.908633]\n",
      "epoch:36 step:28508[D loss: 0.406057, acc: 60.94%, op_acc: 42.19%] [G loss: 0.864762]\n",
      "epoch:36 step:28509[D loss: 0.409485, acc: 60.16%, op_acc: 40.62%] [G loss: 0.848792]\n",
      "epoch:36 step:28510[D loss: 0.404068, acc: 63.28%, op_acc: 39.06%] [G loss: 0.886322]\n",
      "epoch:36 step:28511[D loss: 0.455051, acc: 53.12%, op_acc: 33.59%] [G loss: 0.923305]\n",
      "epoch:36 step:28512[D loss: 0.394679, acc: 63.28%, op_acc: 39.84%] [G loss: 0.898413]\n",
      "epoch:36 step:28513[D loss: 0.400270, acc: 58.59%, op_acc: 42.97%] [G loss: 0.859785]\n",
      "epoch:36 step:28514[D loss: 0.425421, acc: 59.38%, op_acc: 37.50%] [G loss: 0.881715]\n",
      "epoch:36 step:28515[D loss: 0.418431, acc: 63.28%, op_acc: 42.19%] [G loss: 0.873245]\n",
      "epoch:36 step:28516[D loss: 0.398601, acc: 63.28%, op_acc: 42.97%] [G loss: 0.876442]\n",
      "epoch:36 step:28517[D loss: 0.389843, acc: 67.19%, op_acc: 42.97%] [G loss: 0.866825]\n",
      "epoch:36 step:28518[D loss: 0.431739, acc: 60.16%, op_acc: 37.50%] [G loss: 0.935097]\n",
      "epoch:36 step:28519[D loss: 0.412050, acc: 64.84%, op_acc: 41.41%] [G loss: 0.926593]\n",
      "epoch:36 step:28520[D loss: 0.372124, acc: 71.09%, op_acc: 52.34%] [G loss: 0.915190]\n",
      "epoch:36 step:28521[D loss: 0.426567, acc: 58.59%, op_acc: 38.28%] [G loss: 0.894046]\n",
      "epoch:36 step:28522[D loss: 0.400001, acc: 60.94%, op_acc: 44.53%] [G loss: 0.923086]\n",
      "epoch:36 step:28523[D loss: 0.392117, acc: 65.62%, op_acc: 46.88%] [G loss: 0.963955]\n",
      "epoch:36 step:28524[D loss: 0.392266, acc: 61.72%, op_acc: 52.34%] [G loss: 0.945808]\n",
      "epoch:36 step:28525[D loss: 0.401394, acc: 60.16%, op_acc: 47.66%] [G loss: 0.944835]\n",
      "epoch:36 step:28526[D loss: 0.394357, acc: 65.62%, op_acc: 43.75%] [G loss: 0.897937]\n",
      "epoch:36 step:28527[D loss: 0.427175, acc: 56.25%, op_acc: 40.62%] [G loss: 0.868128]\n",
      "epoch:36 step:28528[D loss: 0.415460, acc: 57.03%, op_acc: 44.53%] [G loss: 0.866377]\n",
      "epoch:36 step:28529[D loss: 0.423421, acc: 56.25%, op_acc: 44.53%] [G loss: 0.895166]\n",
      "epoch:36 step:28530[D loss: 0.433937, acc: 47.66%, op_acc: 42.97%] [G loss: 0.890192]\n",
      "epoch:36 step:28531[D loss: 0.420900, acc: 55.47%, op_acc: 39.84%] [G loss: 0.839207]\n",
      "epoch:36 step:28532[D loss: 0.382437, acc: 64.84%, op_acc: 42.19%] [G loss: 0.897888]\n",
      "epoch:36 step:28533[D loss: 0.397992, acc: 67.19%, op_acc: 46.09%] [G loss: 0.932785]\n",
      "epoch:36 step:28534[D loss: 0.426813, acc: 57.03%, op_acc: 39.06%] [G loss: 0.939196]\n",
      "epoch:36 step:28535[D loss: 0.448027, acc: 53.91%, op_acc: 36.72%] [G loss: 0.910524]\n",
      "epoch:36 step:28536[D loss: 0.443735, acc: 53.12%, op_acc: 40.62%] [G loss: 0.817042]\n",
      "epoch:36 step:28537[D loss: 0.464449, acc: 49.22%, op_acc: 35.16%] [G loss: 0.869323]\n",
      "epoch:36 step:28538[D loss: 0.386847, acc: 67.19%, op_acc: 45.31%] [G loss: 0.917229]\n",
      "epoch:36 step:28539[D loss: 0.405783, acc: 60.16%, op_acc: 42.97%] [G loss: 0.973449]\n",
      "epoch:36 step:28540[D loss: 0.418825, acc: 60.16%, op_acc: 46.09%] [G loss: 0.973826]\n",
      "epoch:36 step:28541[D loss: 0.415181, acc: 58.59%, op_acc: 42.97%] [G loss: 0.802767]\n",
      "epoch:36 step:28542[D loss: 0.387968, acc: 66.41%, op_acc: 43.75%] [G loss: 0.921137]\n",
      "epoch:36 step:28543[D loss: 0.434019, acc: 58.59%, op_acc: 36.72%] [G loss: 0.884851]\n",
      "epoch:36 step:28544[D loss: 0.417255, acc: 49.22%, op_acc: 48.44%] [G loss: 0.855410]\n",
      "epoch:36 step:28545[D loss: 0.447008, acc: 53.12%, op_acc: 39.84%] [G loss: 0.868139]\n",
      "epoch:36 step:28546[D loss: 0.434151, acc: 54.69%, op_acc: 38.28%] [G loss: 0.885869]\n",
      "epoch:36 step:28547[D loss: 0.409506, acc: 60.94%, op_acc: 42.19%] [G loss: 0.853238]\n",
      "epoch:36 step:28548[D loss: 0.409872, acc: 55.47%, op_acc: 44.53%] [G loss: 0.903962]\n",
      "epoch:36 step:28549[D loss: 0.390566, acc: 60.94%, op_acc: 47.66%] [G loss: 0.913494]\n",
      "epoch:36 step:28550[D loss: 0.396035, acc: 57.03%, op_acc: 42.97%] [G loss: 0.937630]\n",
      "##############\n",
      "[0.86087877 0.8488577  0.80464751 0.79008991 0.79909051 0.84141444\n",
      " 0.86998201 0.8148809  0.82843003 0.82874215]\n",
      "##########\n",
      "epoch:36 step:28551[D loss: 0.429763, acc: 53.91%, op_acc: 43.75%] [G loss: 0.876310]\n",
      "epoch:36 step:28552[D loss: 0.457993, acc: 57.81%, op_acc: 39.84%] [G loss: 0.868365]\n",
      "epoch:36 step:28553[D loss: 0.428727, acc: 57.03%, op_acc: 35.16%] [G loss: 0.931399]\n",
      "epoch:36 step:28554[D loss: 0.429291, acc: 57.03%, op_acc: 39.06%] [G loss: 0.865863]\n",
      "epoch:36 step:28555[D loss: 0.391510, acc: 60.94%, op_acc: 48.44%] [G loss: 0.864069]\n",
      "epoch:36 step:28556[D loss: 0.429229, acc: 54.69%, op_acc: 39.84%] [G loss: 0.902692]\n",
      "epoch:36 step:28557[D loss: 0.425187, acc: 53.91%, op_acc: 43.75%] [G loss: 0.916121]\n",
      "epoch:36 step:28558[D loss: 0.402662, acc: 60.94%, op_acc: 46.09%] [G loss: 0.886899]\n",
      "epoch:36 step:28559[D loss: 0.458722, acc: 55.47%, op_acc: 35.16%] [G loss: 0.789774]\n",
      "epoch:36 step:28560[D loss: 0.366302, acc: 70.31%, op_acc: 46.09%] [G loss: 0.913257]\n",
      "epoch:36 step:28561[D loss: 0.415712, acc: 60.94%, op_acc: 39.06%] [G loss: 0.903673]\n",
      "epoch:36 step:28562[D loss: 0.427528, acc: 56.25%, op_acc: 45.31%] [G loss: 0.848839]\n",
      "epoch:36 step:28563[D loss: 0.429333, acc: 66.41%, op_acc: 36.72%] [G loss: 0.877752]\n",
      "epoch:36 step:28564[D loss: 0.422271, acc: 53.91%, op_acc: 44.53%] [G loss: 0.863535]\n",
      "epoch:36 step:28565[D loss: 0.432469, acc: 58.59%, op_acc: 38.28%] [G loss: 0.873103]\n",
      "epoch:36 step:28566[D loss: 0.414590, acc: 64.06%, op_acc: 38.28%] [G loss: 0.925054]\n",
      "epoch:36 step:28567[D loss: 0.404553, acc: 61.72%, op_acc: 40.62%] [G loss: 0.952981]\n",
      "epoch:36 step:28568[D loss: 0.388949, acc: 60.16%, op_acc: 45.31%] [G loss: 0.961385]\n",
      "epoch:36 step:28569[D loss: 0.398140, acc: 60.16%, op_acc: 44.53%] [G loss: 0.881321]\n",
      "epoch:36 step:28570[D loss: 0.389032, acc: 68.75%, op_acc: 46.09%] [G loss: 0.881717]\n",
      "epoch:36 step:28571[D loss: 0.417597, acc: 60.16%, op_acc: 42.19%] [G loss: 0.899771]\n",
      "epoch:36 step:28572[D loss: 0.395823, acc: 67.19%, op_acc: 40.62%] [G loss: 0.892566]\n",
      "epoch:36 step:28573[D loss: 0.395398, acc: 65.62%, op_acc: 40.62%] [G loss: 0.864067]\n",
      "epoch:36 step:28574[D loss: 0.419456, acc: 53.91%, op_acc: 41.41%] [G loss: 0.909590]\n",
      "epoch:36 step:28575[D loss: 0.408416, acc: 57.03%, op_acc: 44.53%] [G loss: 0.882847]\n",
      "epoch:36 step:28576[D loss: 0.409215, acc: 60.94%, op_acc: 39.06%] [G loss: 0.838234]\n",
      "epoch:36 step:28577[D loss: 0.431650, acc: 57.03%, op_acc: 39.06%] [G loss: 0.892180]\n",
      "epoch:36 step:28578[D loss: 0.412454, acc: 61.72%, op_acc: 41.41%] [G loss: 0.876109]\n",
      "epoch:36 step:28579[D loss: 0.446027, acc: 53.12%, op_acc: 40.62%] [G loss: 0.870638]\n",
      "epoch:36 step:28580[D loss: 0.441533, acc: 58.59%, op_acc: 37.50%] [G loss: 0.883047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28581[D loss: 0.416272, acc: 59.38%, op_acc: 38.28%] [G loss: 0.902539]\n",
      "epoch:36 step:28582[D loss: 0.410980, acc: 64.06%, op_acc: 42.19%] [G loss: 0.822462]\n",
      "epoch:36 step:28583[D loss: 0.435106, acc: 54.69%, op_acc: 46.88%] [G loss: 0.832721]\n",
      "epoch:36 step:28584[D loss: 0.421767, acc: 54.69%, op_acc: 44.53%] [G loss: 0.932443]\n",
      "epoch:36 step:28585[D loss: 0.406967, acc: 62.50%, op_acc: 43.75%] [G loss: 0.998551]\n",
      "epoch:36 step:28586[D loss: 0.388241, acc: 63.28%, op_acc: 42.19%] [G loss: 0.892526]\n",
      "epoch:36 step:28587[D loss: 0.409360, acc: 64.84%, op_acc: 42.19%] [G loss: 0.936450]\n",
      "epoch:36 step:28588[D loss: 0.435432, acc: 57.81%, op_acc: 36.72%] [G loss: 0.814716]\n",
      "epoch:36 step:28589[D loss: 0.383435, acc: 65.62%, op_acc: 47.66%] [G loss: 0.840991]\n",
      "epoch:36 step:28590[D loss: 0.385008, acc: 72.66%, op_acc: 44.53%] [G loss: 0.897544]\n",
      "epoch:36 step:28591[D loss: 0.444138, acc: 47.66%, op_acc: 41.41%] [G loss: 0.890928]\n",
      "epoch:36 step:28592[D loss: 0.445802, acc: 56.25%, op_acc: 38.28%] [G loss: 0.931120]\n",
      "epoch:36 step:28593[D loss: 0.437226, acc: 60.94%, op_acc: 43.75%] [G loss: 0.858564]\n",
      "epoch:36 step:28594[D loss: 0.446003, acc: 53.12%, op_acc: 39.84%] [G loss: 0.901380]\n",
      "epoch:36 step:28595[D loss: 0.413095, acc: 57.81%, op_acc: 42.19%] [G loss: 0.908621]\n",
      "epoch:36 step:28596[D loss: 0.452964, acc: 55.47%, op_acc: 32.03%] [G loss: 0.928206]\n",
      "epoch:36 step:28597[D loss: 0.434606, acc: 60.16%, op_acc: 39.84%] [G loss: 0.830878]\n",
      "epoch:36 step:28598[D loss: 0.436629, acc: 57.03%, op_acc: 37.50%] [G loss: 0.871284]\n",
      "epoch:36 step:28599[D loss: 0.388293, acc: 62.50%, op_acc: 49.22%] [G loss: 0.914581]\n",
      "epoch:36 step:28600[D loss: 0.389365, acc: 65.62%, op_acc: 42.19%] [G loss: 0.878490]\n",
      "##############\n",
      "[0.86909442 0.87603444 0.80417357 0.80469882 0.80847844 0.82759654\n",
      " 0.88629792 0.83736293 0.7972113  0.83243163]\n",
      "##########\n",
      "epoch:36 step:28601[D loss: 0.442754, acc: 56.25%, op_acc: 40.62%] [G loss: 0.859330]\n",
      "epoch:36 step:28602[D loss: 0.435466, acc: 52.34%, op_acc: 43.75%] [G loss: 0.781498]\n",
      "epoch:36 step:28603[D loss: 0.405664, acc: 67.19%, op_acc: 38.28%] [G loss: 0.855726]\n",
      "epoch:36 step:28604[D loss: 0.422990, acc: 60.94%, op_acc: 46.88%] [G loss: 0.877526]\n",
      "epoch:36 step:28605[D loss: 0.451990, acc: 57.81%, op_acc: 41.41%] [G loss: 0.822373]\n",
      "epoch:36 step:28606[D loss: 0.400438, acc: 66.41%, op_acc: 38.28%] [G loss: 0.881312]\n",
      "epoch:36 step:28607[D loss: 0.437808, acc: 58.59%, op_acc: 34.38%] [G loss: 0.802232]\n",
      "epoch:36 step:28608[D loss: 0.416296, acc: 56.25%, op_acc: 43.75%] [G loss: 0.863367]\n",
      "epoch:36 step:28609[D loss: 0.451898, acc: 50.78%, op_acc: 34.38%] [G loss: 0.820833]\n",
      "epoch:36 step:28610[D loss: 0.403587, acc: 64.84%, op_acc: 39.06%] [G loss: 0.885347]\n",
      "epoch:36 step:28611[D loss: 0.413011, acc: 56.25%, op_acc: 40.62%] [G loss: 0.893567]\n",
      "epoch:36 step:28612[D loss: 0.415847, acc: 60.94%, op_acc: 39.84%] [G loss: 0.834726]\n",
      "epoch:36 step:28613[D loss: 0.416603, acc: 60.94%, op_acc: 44.53%] [G loss: 0.889327]\n",
      "epoch:36 step:28614[D loss: 0.432084, acc: 57.81%, op_acc: 37.50%] [G loss: 0.905676]\n",
      "epoch:36 step:28615[D loss: 0.407431, acc: 64.84%, op_acc: 42.19%] [G loss: 0.956555]\n",
      "epoch:36 step:28616[D loss: 0.412831, acc: 61.72%, op_acc: 41.41%] [G loss: 0.904578]\n",
      "epoch:36 step:28617[D loss: 0.443056, acc: 54.69%, op_acc: 37.50%] [G loss: 0.907856]\n",
      "epoch:36 step:28618[D loss: 0.434826, acc: 56.25%, op_acc: 39.06%] [G loss: 0.897802]\n",
      "epoch:36 step:28619[D loss: 0.412451, acc: 64.06%, op_acc: 37.50%] [G loss: 0.949780]\n",
      "epoch:36 step:28620[D loss: 0.439495, acc: 53.12%, op_acc: 37.50%] [G loss: 0.907702]\n",
      "epoch:36 step:28621[D loss: 0.439056, acc: 58.59%, op_acc: 37.50%] [G loss: 0.813090]\n",
      "epoch:36 step:28622[D loss: 0.411273, acc: 64.06%, op_acc: 36.72%] [G loss: 0.892322]\n",
      "epoch:36 step:28623[D loss: 0.404227, acc: 60.94%, op_acc: 41.41%] [G loss: 0.955450]\n",
      "epoch:36 step:28624[D loss: 0.421565, acc: 62.50%, op_acc: 39.06%] [G loss: 0.929506]\n",
      "epoch:36 step:28625[D loss: 0.418398, acc: 56.25%, op_acc: 42.19%] [G loss: 0.942967]\n",
      "epoch:36 step:28626[D loss: 0.410744, acc: 60.16%, op_acc: 39.84%] [G loss: 0.866674]\n",
      "epoch:36 step:28627[D loss: 0.432661, acc: 55.47%, op_acc: 39.06%] [G loss: 0.934075]\n",
      "epoch:36 step:28628[D loss: 0.448803, acc: 55.47%, op_acc: 40.62%] [G loss: 0.866031]\n",
      "epoch:36 step:28629[D loss: 0.451204, acc: 48.44%, op_acc: 38.28%] [G loss: 0.888171]\n",
      "epoch:36 step:28630[D loss: 0.422399, acc: 62.50%, op_acc: 42.97%] [G loss: 0.880049]\n",
      "epoch:36 step:28631[D loss: 0.411571, acc: 57.81%, op_acc: 38.28%] [G loss: 0.921450]\n",
      "epoch:36 step:28632[D loss: 0.437071, acc: 53.91%, op_acc: 39.84%] [G loss: 0.865823]\n",
      "epoch:36 step:28633[D loss: 0.437354, acc: 56.25%, op_acc: 39.06%] [G loss: 0.906736]\n",
      "epoch:36 step:28634[D loss: 0.396521, acc: 63.28%, op_acc: 35.94%] [G loss: 0.867260]\n",
      "epoch:36 step:28635[D loss: 0.410338, acc: 57.81%, op_acc: 41.41%] [G loss: 0.958314]\n",
      "epoch:36 step:28636[D loss: 0.423330, acc: 55.47%, op_acc: 37.50%] [G loss: 0.963192]\n",
      "epoch:36 step:28637[D loss: 0.419697, acc: 61.72%, op_acc: 37.50%] [G loss: 0.938835]\n",
      "epoch:36 step:28638[D loss: 0.416855, acc: 64.06%, op_acc: 41.41%] [G loss: 0.841677]\n",
      "epoch:36 step:28639[D loss: 0.420734, acc: 63.28%, op_acc: 42.97%] [G loss: 0.867876]\n",
      "epoch:36 step:28640[D loss: 0.422143, acc: 55.47%, op_acc: 39.06%] [G loss: 0.860841]\n",
      "epoch:36 step:28641[D loss: 0.415054, acc: 65.62%, op_acc: 39.84%] [G loss: 0.840008]\n",
      "epoch:36 step:28642[D loss: 0.436448, acc: 58.59%, op_acc: 33.59%] [G loss: 0.844183]\n",
      "epoch:36 step:28643[D loss: 0.446332, acc: 49.22%, op_acc: 35.94%] [G loss: 0.812940]\n",
      "epoch:36 step:28644[D loss: 0.414421, acc: 62.50%, op_acc: 38.28%] [G loss: 0.856903]\n",
      "epoch:36 step:28645[D loss: 0.414310, acc: 57.81%, op_acc: 44.53%] [G loss: 0.919137]\n",
      "epoch:36 step:28646[D loss: 0.405270, acc: 66.41%, op_acc: 39.84%] [G loss: 0.997990]\n",
      "epoch:36 step:28647[D loss: 0.446452, acc: 55.47%, op_acc: 39.06%] [G loss: 0.841573]\n",
      "epoch:36 step:28648[D loss: 0.420312, acc: 57.81%, op_acc: 38.28%] [G loss: 0.873917]\n",
      "epoch:36 step:28649[D loss: 0.404824, acc: 57.03%, op_acc: 42.97%] [G loss: 0.916247]\n",
      "epoch:36 step:28650[D loss: 0.404389, acc: 58.59%, op_acc: 41.41%] [G loss: 0.906639]\n",
      "##############\n",
      "[0.87698497 0.84591228 0.81383404 0.80465209 0.78869573 0.83225009\n",
      " 0.89142454 0.80421862 0.8054769  0.84752093]\n",
      "##########\n",
      "epoch:36 step:28651[D loss: 0.425089, acc: 63.28%, op_acc: 47.66%] [G loss: 0.893980]\n",
      "epoch:36 step:28652[D loss: 0.392239, acc: 60.94%, op_acc: 45.31%] [G loss: 0.906595]\n",
      "epoch:36 step:28653[D loss: 0.465820, acc: 47.66%, op_acc: 32.81%] [G loss: 0.898312]\n",
      "epoch:36 step:28654[D loss: 0.416491, acc: 58.59%, op_acc: 47.66%] [G loss: 0.884567]\n",
      "epoch:36 step:28655[D loss: 0.427704, acc: 60.16%, op_acc: 39.84%] [G loss: 0.866417]\n",
      "epoch:36 step:28656[D loss: 0.401371, acc: 61.72%, op_acc: 46.09%] [G loss: 0.903464]\n",
      "epoch:36 step:28657[D loss: 0.420443, acc: 60.94%, op_acc: 42.19%] [G loss: 0.809921]\n",
      "epoch:36 step:28658[D loss: 0.399772, acc: 67.97%, op_acc: 38.28%] [G loss: 0.819339]\n",
      "epoch:36 step:28659[D loss: 0.432218, acc: 59.38%, op_acc: 40.62%] [G loss: 0.908412]\n",
      "epoch:36 step:28660[D loss: 0.413813, acc: 63.28%, op_acc: 43.75%] [G loss: 0.862720]\n",
      "epoch:36 step:28661[D loss: 0.393492, acc: 65.62%, op_acc: 39.84%] [G loss: 0.862559]\n",
      "epoch:36 step:28662[D loss: 0.411541, acc: 62.50%, op_acc: 42.19%] [G loss: 1.020780]\n",
      "epoch:36 step:28663[D loss: 0.462889, acc: 53.12%, op_acc: 34.38%] [G loss: 0.928650]\n",
      "epoch:36 step:28664[D loss: 0.418228, acc: 61.72%, op_acc: 38.28%] [G loss: 0.921182]\n",
      "epoch:36 step:28665[D loss: 0.426520, acc: 53.12%, op_acc: 42.97%] [G loss: 0.894816]\n",
      "epoch:36 step:28666[D loss: 0.430653, acc: 52.34%, op_acc: 39.84%] [G loss: 0.916875]\n",
      "epoch:36 step:28667[D loss: 0.427655, acc: 58.59%, op_acc: 42.19%] [G loss: 0.867693]\n",
      "epoch:36 step:28668[D loss: 0.436590, acc: 60.94%, op_acc: 34.38%] [G loss: 0.874391]\n",
      "epoch:36 step:28669[D loss: 0.406913, acc: 61.72%, op_acc: 42.97%] [G loss: 0.820864]\n",
      "epoch:36 step:28670[D loss: 0.421301, acc: 61.72%, op_acc: 38.28%] [G loss: 0.842320]\n",
      "epoch:36 step:28671[D loss: 0.398420, acc: 56.25%, op_acc: 47.66%] [G loss: 0.874489]\n",
      "epoch:36 step:28672[D loss: 0.432462, acc: 51.56%, op_acc: 48.44%] [G loss: 0.896582]\n",
      "epoch:36 step:28673[D loss: 0.423261, acc: 62.50%, op_acc: 38.28%] [G loss: 0.908236]\n",
      "epoch:36 step:28674[D loss: 0.405050, acc: 61.72%, op_acc: 42.19%] [G loss: 0.936752]\n",
      "epoch:36 step:28675[D loss: 0.390354, acc: 63.28%, op_acc: 46.09%] [G loss: 0.871831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28676[D loss: 0.424731, acc: 62.50%, op_acc: 39.84%] [G loss: 0.906833]\n",
      "epoch:36 step:28677[D loss: 0.397479, acc: 63.28%, op_acc: 47.66%] [G loss: 0.828361]\n",
      "epoch:36 step:28678[D loss: 0.439401, acc: 62.50%, op_acc: 37.50%] [G loss: 0.936243]\n",
      "epoch:36 step:28679[D loss: 0.404756, acc: 64.84%, op_acc: 43.75%] [G loss: 0.937004]\n",
      "epoch:36 step:28680[D loss: 0.422136, acc: 57.03%, op_acc: 43.75%] [G loss: 0.872405]\n",
      "epoch:36 step:28681[D loss: 0.416884, acc: 59.38%, op_acc: 42.19%] [G loss: 0.862052]\n",
      "epoch:36 step:28682[D loss: 0.401222, acc: 66.41%, op_acc: 39.06%] [G loss: 0.882815]\n",
      "epoch:36 step:28683[D loss: 0.379567, acc: 69.53%, op_acc: 44.53%] [G loss: 0.883466]\n",
      "epoch:36 step:28684[D loss: 0.436301, acc: 48.44%, op_acc: 38.28%] [G loss: 0.817230]\n",
      "epoch:36 step:28685[D loss: 0.392811, acc: 67.19%, op_acc: 42.97%] [G loss: 0.938011]\n",
      "epoch:36 step:28686[D loss: 0.422017, acc: 60.94%, op_acc: 39.84%] [G loss: 0.933634]\n",
      "epoch:36 step:28687[D loss: 0.418875, acc: 60.16%, op_acc: 44.53%] [G loss: 0.880377]\n",
      "epoch:36 step:28688[D loss: 0.402116, acc: 60.16%, op_acc: 38.28%] [G loss: 0.968051]\n",
      "epoch:36 step:28689[D loss: 0.414878, acc: 64.06%, op_acc: 45.31%] [G loss: 0.889706]\n",
      "epoch:36 step:28690[D loss: 0.427843, acc: 55.47%, op_acc: 35.16%] [G loss: 0.900720]\n",
      "epoch:36 step:28691[D loss: 0.420420, acc: 57.03%, op_acc: 42.97%] [G loss: 0.942628]\n",
      "epoch:36 step:28692[D loss: 0.413246, acc: 60.94%, op_acc: 42.19%] [G loss: 0.964697]\n",
      "epoch:36 step:28693[D loss: 0.427107, acc: 59.38%, op_acc: 42.97%] [G loss: 0.947915]\n",
      "epoch:36 step:28694[D loss: 0.439939, acc: 57.81%, op_acc: 39.84%] [G loss: 0.909811]\n",
      "epoch:36 step:28695[D loss: 0.445509, acc: 51.56%, op_acc: 39.84%] [G loss: 0.883607]\n",
      "epoch:36 step:28696[D loss: 0.446326, acc: 57.81%, op_acc: 39.84%] [G loss: 0.942414]\n",
      "epoch:36 step:28697[D loss: 0.423832, acc: 60.16%, op_acc: 35.94%] [G loss: 0.832307]\n",
      "epoch:36 step:28698[D loss: 0.436650, acc: 53.12%, op_acc: 42.97%] [G loss: 0.872689]\n",
      "epoch:36 step:28699[D loss: 0.410719, acc: 59.38%, op_acc: 41.41%] [G loss: 0.915965]\n",
      "epoch:36 step:28700[D loss: 0.448724, acc: 59.38%, op_acc: 29.69%] [G loss: 0.877019]\n",
      "##############\n",
      "[0.86185007 0.88144449 0.80960195 0.83019051 0.78871199 0.83348723\n",
      " 0.89040274 0.83153157 0.78453115 0.80838799]\n",
      "##########\n",
      "epoch:36 step:28701[D loss: 0.418549, acc: 64.06%, op_acc: 44.53%] [G loss: 0.933837]\n",
      "epoch:36 step:28702[D loss: 0.415142, acc: 62.50%, op_acc: 39.84%] [G loss: 0.854306]\n",
      "epoch:36 step:28703[D loss: 0.397262, acc: 68.75%, op_acc: 36.72%] [G loss: 0.942390]\n",
      "epoch:36 step:28704[D loss: 0.431353, acc: 53.12%, op_acc: 44.53%] [G loss: 0.882227]\n",
      "epoch:36 step:28705[D loss: 0.422103, acc: 62.50%, op_acc: 35.16%] [G loss: 0.847451]\n",
      "epoch:36 step:28706[D loss: 0.398892, acc: 58.59%, op_acc: 44.53%] [G loss: 0.891073]\n",
      "epoch:36 step:28707[D loss: 0.400311, acc: 64.06%, op_acc: 43.75%] [G loss: 0.885618]\n",
      "epoch:36 step:28708[D loss: 0.410710, acc: 63.28%, op_acc: 37.50%] [G loss: 0.900730]\n",
      "epoch:36 step:28709[D loss: 0.446947, acc: 54.69%, op_acc: 40.62%] [G loss: 0.905126]\n",
      "epoch:36 step:28710[D loss: 0.380785, acc: 69.53%, op_acc: 50.78%] [G loss: 0.858107]\n",
      "epoch:36 step:28711[D loss: 0.426432, acc: 65.62%, op_acc: 39.84%] [G loss: 0.876261]\n",
      "epoch:36 step:28712[D loss: 0.400701, acc: 63.28%, op_acc: 39.06%] [G loss: 0.864516]\n",
      "epoch:36 step:28713[D loss: 0.432205, acc: 53.91%, op_acc: 43.75%] [G loss: 0.831247]\n",
      "epoch:36 step:28714[D loss: 0.389137, acc: 67.97%, op_acc: 44.53%] [G loss: 0.878742]\n",
      "epoch:36 step:28715[D loss: 0.426064, acc: 57.81%, op_acc: 39.84%] [G loss: 0.859342]\n",
      "epoch:36 step:28716[D loss: 0.406084, acc: 68.75%, op_acc: 40.62%] [G loss: 0.925562]\n",
      "epoch:36 step:28717[D loss: 0.418487, acc: 60.16%, op_acc: 42.97%] [G loss: 0.907061]\n",
      "epoch:36 step:28718[D loss: 0.419101, acc: 60.16%, op_acc: 41.41%] [G loss: 0.890023]\n",
      "epoch:36 step:28719[D loss: 0.377325, acc: 65.62%, op_acc: 47.66%] [G loss: 0.934950]\n",
      "epoch:36 step:28720[D loss: 0.462891, acc: 53.12%, op_acc: 39.06%] [G loss: 0.898759]\n",
      "epoch:36 step:28721[D loss: 0.395977, acc: 66.41%, op_acc: 39.06%] [G loss: 0.907992]\n",
      "epoch:36 step:28722[D loss: 0.424503, acc: 55.47%, op_acc: 50.00%] [G loss: 0.886637]\n",
      "epoch:36 step:28723[D loss: 0.378748, acc: 64.06%, op_acc: 47.66%] [G loss: 0.854572]\n",
      "epoch:36 step:28724[D loss: 0.385426, acc: 66.41%, op_acc: 46.88%] [G loss: 0.919546]\n",
      "epoch:36 step:28725[D loss: 0.428024, acc: 62.50%, op_acc: 41.41%] [G loss: 0.893066]\n",
      "epoch:36 step:28726[D loss: 0.404440, acc: 64.06%, op_acc: 39.84%] [G loss: 0.917840]\n",
      "epoch:36 step:28727[D loss: 0.429169, acc: 56.25%, op_acc: 42.19%] [G loss: 0.969699]\n",
      "epoch:36 step:28728[D loss: 0.411538, acc: 61.72%, op_acc: 43.75%] [G loss: 0.876153]\n",
      "epoch:36 step:28729[D loss: 0.462408, acc: 50.00%, op_acc: 39.06%] [G loss: 0.811305]\n",
      "epoch:36 step:28730[D loss: 0.405573, acc: 57.81%, op_acc: 39.06%] [G loss: 0.844937]\n",
      "epoch:36 step:28731[D loss: 0.409400, acc: 64.06%, op_acc: 42.97%] [G loss: 0.864589]\n",
      "epoch:36 step:28732[D loss: 0.443594, acc: 55.47%, op_acc: 35.94%] [G loss: 0.804370]\n",
      "epoch:36 step:28733[D loss: 0.425775, acc: 53.91%, op_acc: 39.84%] [G loss: 0.902449]\n",
      "epoch:36 step:28734[D loss: 0.394804, acc: 60.16%, op_acc: 45.31%] [G loss: 0.972786]\n",
      "epoch:36 step:28735[D loss: 0.418776, acc: 64.84%, op_acc: 39.84%] [G loss: 0.868418]\n",
      "epoch:36 step:28736[D loss: 0.418080, acc: 56.25%, op_acc: 43.75%] [G loss: 0.818288]\n",
      "epoch:36 step:28737[D loss: 0.423048, acc: 57.81%, op_acc: 45.31%] [G loss: 0.828807]\n",
      "epoch:36 step:28738[D loss: 0.433619, acc: 65.62%, op_acc: 36.72%] [G loss: 0.909992]\n",
      "epoch:36 step:28739[D loss: 0.429555, acc: 57.03%, op_acc: 38.28%] [G loss: 0.948776]\n",
      "epoch:36 step:28740[D loss: 0.419259, acc: 60.94%, op_acc: 46.09%] [G loss: 0.771992]\n",
      "epoch:36 step:28741[D loss: 0.416534, acc: 62.50%, op_acc: 40.62%] [G loss: 0.862548]\n",
      "epoch:36 step:28742[D loss: 0.414319, acc: 60.16%, op_acc: 36.72%] [G loss: 0.910271]\n",
      "epoch:36 step:28743[D loss: 0.427844, acc: 57.03%, op_acc: 45.31%] [G loss: 0.861345]\n",
      "epoch:36 step:28744[D loss: 0.392874, acc: 67.19%, op_acc: 44.53%] [G loss: 0.915648]\n",
      "epoch:36 step:28745[D loss: 0.454265, acc: 56.25%, op_acc: 37.50%] [G loss: 0.854048]\n",
      "epoch:36 step:28746[D loss: 0.404112, acc: 65.62%, op_acc: 39.84%] [G loss: 0.932228]\n",
      "epoch:36 step:28747[D loss: 0.439226, acc: 54.69%, op_acc: 41.41%] [G loss: 0.909383]\n",
      "epoch:36 step:28748[D loss: 0.398463, acc: 69.53%, op_acc: 37.50%] [G loss: 0.872905]\n",
      "epoch:36 step:28749[D loss: 0.438006, acc: 53.12%, op_acc: 39.06%] [G loss: 0.918478]\n",
      "epoch:36 step:28750[D loss: 0.424148, acc: 56.25%, op_acc: 41.41%] [G loss: 0.841197]\n",
      "##############\n",
      "[0.87034074 0.86425999 0.80937917 0.81096952 0.78992562 0.82899989\n",
      " 0.88818417 0.83764849 0.80304015 0.80205455]\n",
      "##########\n",
      "epoch:36 step:28751[D loss: 0.424657, acc: 61.72%, op_acc: 39.84%] [G loss: 0.903327]\n",
      "epoch:36 step:28752[D loss: 0.429708, acc: 58.59%, op_acc: 39.84%] [G loss: 0.873240]\n",
      "epoch:36 step:28753[D loss: 0.412491, acc: 59.38%, op_acc: 42.19%] [G loss: 0.846767]\n",
      "epoch:36 step:28754[D loss: 0.434947, acc: 55.47%, op_acc: 43.75%] [G loss: 0.924357]\n",
      "epoch:36 step:28755[D loss: 0.438470, acc: 53.91%, op_acc: 36.72%] [G loss: 0.859139]\n",
      "epoch:36 step:28756[D loss: 0.440656, acc: 57.81%, op_acc: 39.84%] [G loss: 0.945581]\n",
      "epoch:36 step:28757[D loss: 0.441992, acc: 56.25%, op_acc: 37.50%] [G loss: 0.863185]\n",
      "epoch:36 step:28758[D loss: 0.406720, acc: 63.28%, op_acc: 42.19%] [G loss: 0.855174]\n",
      "epoch:36 step:28759[D loss: 0.421748, acc: 57.03%, op_acc: 36.72%] [G loss: 0.874112]\n",
      "epoch:36 step:28760[D loss: 0.368586, acc: 66.41%, op_acc: 47.66%] [G loss: 0.846393]\n",
      "epoch:36 step:28761[D loss: 0.416696, acc: 61.72%, op_acc: 37.50%] [G loss: 0.914391]\n",
      "epoch:36 step:28762[D loss: 0.450098, acc: 50.78%, op_acc: 37.50%] [G loss: 0.849913]\n",
      "epoch:36 step:28763[D loss: 0.418620, acc: 57.81%, op_acc: 39.06%] [G loss: 0.940174]\n",
      "epoch:36 step:28764[D loss: 0.397240, acc: 61.72%, op_acc: 42.19%] [G loss: 0.897521]\n",
      "epoch:36 step:28765[D loss: 0.418222, acc: 60.94%, op_acc: 41.41%] [G loss: 0.887130]\n",
      "epoch:36 step:28766[D loss: 0.456588, acc: 52.34%, op_acc: 39.06%] [G loss: 0.936565]\n",
      "epoch:36 step:28767[D loss: 0.394592, acc: 68.75%, op_acc: 43.75%] [G loss: 0.874644]\n",
      "epoch:36 step:28768[D loss: 0.407819, acc: 60.16%, op_acc: 40.62%] [G loss: 0.866104]\n",
      "epoch:36 step:28769[D loss: 0.400470, acc: 58.59%, op_acc: 45.31%] [G loss: 0.894987]\n",
      "epoch:36 step:28770[D loss: 0.399519, acc: 64.06%, op_acc: 44.53%] [G loss: 0.886144]\n",
      "epoch:36 step:28771[D loss: 0.408897, acc: 64.84%, op_acc: 40.62%] [G loss: 0.846162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28772[D loss: 0.405371, acc: 70.31%, op_acc: 41.41%] [G loss: 0.917180]\n",
      "epoch:36 step:28773[D loss: 0.424215, acc: 63.28%, op_acc: 39.06%] [G loss: 0.859326]\n",
      "epoch:36 step:28774[D loss: 0.432484, acc: 58.59%, op_acc: 35.16%] [G loss: 0.824786]\n",
      "epoch:36 step:28775[D loss: 0.394820, acc: 65.62%, op_acc: 44.53%] [G loss: 0.950856]\n",
      "epoch:36 step:28776[D loss: 0.396484, acc: 63.28%, op_acc: 42.97%] [G loss: 0.891339]\n",
      "epoch:36 step:28777[D loss: 0.388562, acc: 64.06%, op_acc: 45.31%] [G loss: 0.841223]\n",
      "epoch:36 step:28778[D loss: 0.405847, acc: 59.38%, op_acc: 42.19%] [G loss: 0.923151]\n",
      "epoch:36 step:28779[D loss: 0.396491, acc: 64.06%, op_acc: 47.66%] [G loss: 0.934021]\n",
      "epoch:36 step:28780[D loss: 0.384404, acc: 66.41%, op_acc: 44.53%] [G loss: 0.875773]\n",
      "epoch:36 step:28781[D loss: 0.439952, acc: 57.03%, op_acc: 35.16%] [G loss: 0.903670]\n",
      "epoch:36 step:28782[D loss: 0.422826, acc: 57.81%, op_acc: 39.06%] [G loss: 0.928530]\n",
      "epoch:36 step:28783[D loss: 0.412200, acc: 57.03%, op_acc: 38.28%] [G loss: 0.886346]\n",
      "epoch:36 step:28784[D loss: 0.429572, acc: 59.38%, op_acc: 39.84%] [G loss: 0.925880]\n",
      "epoch:36 step:28785[D loss: 0.399747, acc: 64.06%, op_acc: 37.50%] [G loss: 0.882017]\n",
      "epoch:36 step:28786[D loss: 0.458068, acc: 50.00%, op_acc: 46.09%] [G loss: 0.812099]\n",
      "epoch:36 step:28787[D loss: 0.415223, acc: 60.94%, op_acc: 42.97%] [G loss: 0.909985]\n",
      "epoch:36 step:28788[D loss: 0.421542, acc: 61.72%, op_acc: 39.84%] [G loss: 0.862260]\n",
      "epoch:36 step:28789[D loss: 0.412147, acc: 57.03%, op_acc: 43.75%] [G loss: 0.914449]\n",
      "epoch:36 step:28790[D loss: 0.426451, acc: 53.12%, op_acc: 42.19%] [G loss: 0.887237]\n",
      "epoch:36 step:28791[D loss: 0.414282, acc: 57.03%, op_acc: 43.75%] [G loss: 0.903052]\n",
      "epoch:36 step:28792[D loss: 0.464924, acc: 53.12%, op_acc: 35.94%] [G loss: 0.847375]\n",
      "epoch:36 step:28793[D loss: 0.445868, acc: 57.81%, op_acc: 33.59%] [G loss: 0.911787]\n",
      "epoch:36 step:28794[D loss: 0.452643, acc: 55.47%, op_acc: 38.28%] [G loss: 0.882660]\n",
      "epoch:36 step:28795[D loss: 0.383435, acc: 60.16%, op_acc: 47.66%] [G loss: 0.927166]\n",
      "epoch:36 step:28796[D loss: 0.418626, acc: 60.16%, op_acc: 35.94%] [G loss: 0.951407]\n",
      "epoch:36 step:28797[D loss: 0.435590, acc: 53.12%, op_acc: 36.72%] [G loss: 0.838792]\n",
      "epoch:36 step:28798[D loss: 0.360687, acc: 64.84%, op_acc: 43.75%] [G loss: 0.949302]\n",
      "epoch:36 step:28799[D loss: 0.435137, acc: 52.34%, op_acc: 42.19%] [G loss: 0.980219]\n",
      "epoch:36 step:28800[D loss: 0.433640, acc: 58.59%, op_acc: 39.84%] [G loss: 0.815725]\n",
      "##############\n",
      "[0.85514451 0.86161987 0.81113519 0.79063866 0.78376291 0.81847408\n",
      " 0.86678768 0.82790735 0.80880059 0.83998421]\n",
      "##########\n",
      "epoch:36 step:28801[D loss: 0.413241, acc: 63.28%, op_acc: 39.84%] [G loss: 0.899044]\n",
      "epoch:36 step:28802[D loss: 0.427819, acc: 62.50%, op_acc: 41.41%] [G loss: 0.905139]\n",
      "epoch:36 step:28803[D loss: 0.408131, acc: 57.03%, op_acc: 39.84%] [G loss: 0.852949]\n",
      "epoch:36 step:28804[D loss: 0.418172, acc: 61.72%, op_acc: 41.41%] [G loss: 0.891504]\n",
      "epoch:36 step:28805[D loss: 0.426457, acc: 61.72%, op_acc: 39.06%] [G loss: 0.924781]\n",
      "epoch:36 step:28806[D loss: 0.436994, acc: 60.16%, op_acc: 35.94%] [G loss: 0.853495]\n",
      "epoch:36 step:28807[D loss: 0.403939, acc: 58.59%, op_acc: 38.28%] [G loss: 0.962115]\n",
      "epoch:36 step:28808[D loss: 0.417592, acc: 60.16%, op_acc: 41.41%] [G loss: 0.904269]\n",
      "epoch:36 step:28809[D loss: 0.377031, acc: 67.97%, op_acc: 46.09%] [G loss: 0.933092]\n",
      "epoch:36 step:28810[D loss: 0.404207, acc: 57.81%, op_acc: 42.19%] [G loss: 0.925551]\n",
      "epoch:36 step:28811[D loss: 0.421240, acc: 57.03%, op_acc: 34.38%] [G loss: 0.883944]\n",
      "epoch:36 step:28812[D loss: 0.440290, acc: 53.91%, op_acc: 38.28%] [G loss: 0.857517]\n",
      "epoch:36 step:28813[D loss: 0.396895, acc: 64.06%, op_acc: 42.19%] [G loss: 0.864146]\n",
      "epoch:36 step:28814[D loss: 0.430967, acc: 51.56%, op_acc: 44.53%] [G loss: 0.885570]\n",
      "epoch:36 step:28815[D loss: 0.419846, acc: 53.12%, op_acc: 41.41%] [G loss: 0.860204]\n",
      "epoch:36 step:28816[D loss: 0.427750, acc: 61.72%, op_acc: 35.16%] [G loss: 0.896144]\n",
      "epoch:36 step:28817[D loss: 0.440353, acc: 61.72%, op_acc: 37.50%] [G loss: 0.865040]\n",
      "epoch:36 step:28818[D loss: 0.458146, acc: 53.12%, op_acc: 38.28%] [G loss: 0.863239]\n",
      "epoch:36 step:28819[D loss: 0.457229, acc: 46.88%, op_acc: 36.72%] [G loss: 0.836514]\n",
      "epoch:36 step:28820[D loss: 0.381555, acc: 63.28%, op_acc: 47.66%] [G loss: 0.931847]\n",
      "epoch:36 step:28821[D loss: 0.420804, acc: 59.38%, op_acc: 39.06%] [G loss: 0.939682]\n",
      "epoch:36 step:28822[D loss: 0.417892, acc: 58.59%, op_acc: 42.19%] [G loss: 0.884790]\n",
      "epoch:36 step:28823[D loss: 0.459632, acc: 46.09%, op_acc: 42.97%] [G loss: 0.850136]\n",
      "epoch:36 step:28824[D loss: 0.470781, acc: 46.09%, op_acc: 36.72%] [G loss: 0.893677]\n",
      "epoch:36 step:28825[D loss: 0.415312, acc: 58.59%, op_acc: 45.31%] [G loss: 0.808650]\n",
      "epoch:36 step:28826[D loss: 0.403790, acc: 60.94%, op_acc: 41.41%] [G loss: 0.974737]\n",
      "epoch:36 step:28827[D loss: 0.410522, acc: 63.28%, op_acc: 41.41%] [G loss: 0.919560]\n",
      "epoch:36 step:28828[D loss: 0.403836, acc: 60.16%, op_acc: 36.72%] [G loss: 0.843376]\n",
      "epoch:36 step:28829[D loss: 0.423248, acc: 60.94%, op_acc: 41.41%] [G loss: 0.926222]\n",
      "epoch:36 step:28830[D loss: 0.450847, acc: 57.03%, op_acc: 35.94%] [G loss: 0.807290]\n",
      "epoch:36 step:28831[D loss: 0.433518, acc: 54.69%, op_acc: 42.97%] [G loss: 0.946962]\n",
      "epoch:36 step:28832[D loss: 0.402742, acc: 64.06%, op_acc: 40.62%] [G loss: 0.951315]\n",
      "epoch:36 step:28833[D loss: 0.419062, acc: 52.34%, op_acc: 45.31%] [G loss: 0.868569]\n",
      "epoch:36 step:28834[D loss: 0.399317, acc: 63.28%, op_acc: 37.50%] [G loss: 1.002384]\n",
      "epoch:36 step:28835[D loss: 0.425877, acc: 57.03%, op_acc: 37.50%] [G loss: 0.977361]\n",
      "epoch:36 step:28836[D loss: 0.423311, acc: 55.47%, op_acc: 42.19%] [G loss: 0.943691]\n",
      "epoch:36 step:28837[D loss: 0.413780, acc: 56.25%, op_acc: 42.97%] [G loss: 0.875275]\n",
      "epoch:36 step:28838[D loss: 0.437758, acc: 52.34%, op_acc: 42.19%] [G loss: 0.879773]\n",
      "epoch:36 step:28839[D loss: 0.408506, acc: 56.25%, op_acc: 42.19%] [G loss: 0.901101]\n",
      "epoch:36 step:28840[D loss: 0.450908, acc: 58.59%, op_acc: 35.94%] [G loss: 0.900320]\n",
      "epoch:36 step:28841[D loss: 0.418326, acc: 59.38%, op_acc: 39.06%] [G loss: 0.909173]\n",
      "epoch:36 step:28842[D loss: 0.437981, acc: 50.78%, op_acc: 42.97%] [G loss: 0.948177]\n",
      "epoch:36 step:28843[D loss: 0.444939, acc: 58.59%, op_acc: 35.16%] [G loss: 0.982586]\n",
      "epoch:36 step:28844[D loss: 0.425602, acc: 61.72%, op_acc: 42.19%] [G loss: 0.885959]\n",
      "epoch:36 step:28845[D loss: 0.405892, acc: 64.84%, op_acc: 43.75%] [G loss: 0.938515]\n",
      "epoch:36 step:28846[D loss: 0.421080, acc: 53.12%, op_acc: 39.84%] [G loss: 0.862333]\n",
      "epoch:36 step:28847[D loss: 0.386078, acc: 67.97%, op_acc: 44.53%] [G loss: 0.924297]\n",
      "epoch:36 step:28848[D loss: 0.427572, acc: 50.78%, op_acc: 46.88%] [G loss: 0.937823]\n",
      "epoch:36 step:28849[D loss: 0.423218, acc: 57.03%, op_acc: 39.06%] [G loss: 0.885480]\n",
      "epoch:36 step:28850[D loss: 0.432016, acc: 55.47%, op_acc: 39.06%] [G loss: 0.927492]\n",
      "##############\n",
      "[0.85807749 0.85949089 0.82521839 0.81828277 0.78474555 0.80571243\n",
      " 0.90184466 0.82072534 0.80640306 0.81437886]\n",
      "##########\n",
      "epoch:36 step:28851[D loss: 0.440159, acc: 57.03%, op_acc: 41.41%] [G loss: 0.908086]\n",
      "epoch:36 step:28852[D loss: 0.424311, acc: 63.28%, op_acc: 42.19%] [G loss: 0.826496]\n",
      "epoch:36 step:28853[D loss: 0.403641, acc: 55.47%, op_acc: 46.88%] [G loss: 0.893430]\n",
      "epoch:36 step:28854[D loss: 0.435501, acc: 54.69%, op_acc: 42.97%] [G loss: 0.842143]\n",
      "epoch:36 step:28855[D loss: 0.389706, acc: 64.84%, op_acc: 43.75%] [G loss: 0.866358]\n",
      "epoch:36 step:28856[D loss: 0.404328, acc: 58.59%, op_acc: 46.88%] [G loss: 0.824474]\n",
      "epoch:36 step:28857[D loss: 0.405315, acc: 64.84%, op_acc: 39.84%] [G loss: 0.903446]\n",
      "epoch:36 step:28858[D loss: 0.453101, acc: 55.47%, op_acc: 37.50%] [G loss: 0.845025]\n",
      "epoch:36 step:28859[D loss: 0.414911, acc: 60.16%, op_acc: 42.97%] [G loss: 0.833991]\n",
      "epoch:36 step:28860[D loss: 0.370537, acc: 67.19%, op_acc: 50.00%] [G loss: 0.867483]\n",
      "epoch:36 step:28861[D loss: 0.405763, acc: 61.72%, op_acc: 44.53%] [G loss: 0.988848]\n",
      "epoch:36 step:28862[D loss: 0.418901, acc: 60.16%, op_acc: 43.75%] [G loss: 0.836781]\n",
      "epoch:36 step:28863[D loss: 0.444367, acc: 55.47%, op_acc: 38.28%] [G loss: 0.887594]\n",
      "epoch:36 step:28864[D loss: 0.450607, acc: 53.91%, op_acc: 32.81%] [G loss: 0.852805]\n",
      "epoch:36 step:28865[D loss: 0.434156, acc: 59.38%, op_acc: 37.50%] [G loss: 0.846913]\n",
      "epoch:36 step:28866[D loss: 0.448868, acc: 51.56%, op_acc: 40.62%] [G loss: 0.865954]\n",
      "epoch:36 step:28867[D loss: 0.437488, acc: 60.94%, op_acc: 37.50%] [G loss: 0.845847]\n",
      "epoch:36 step:28868[D loss: 0.445381, acc: 61.72%, op_acc: 40.62%] [G loss: 0.783652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28869[D loss: 0.405740, acc: 60.94%, op_acc: 41.41%] [G loss: 0.838081]\n",
      "epoch:36 step:28870[D loss: 0.403977, acc: 60.16%, op_acc: 47.66%] [G loss: 0.894288]\n",
      "epoch:36 step:28871[D loss: 0.440109, acc: 53.91%, op_acc: 44.53%] [G loss: 0.829190]\n",
      "epoch:36 step:28872[D loss: 0.419220, acc: 56.25%, op_acc: 42.19%] [G loss: 0.995299]\n",
      "epoch:36 step:28873[D loss: 0.433760, acc: 60.94%, op_acc: 39.84%] [G loss: 0.867167]\n",
      "epoch:36 step:28874[D loss: 0.392498, acc: 65.62%, op_acc: 41.41%] [G loss: 0.934320]\n",
      "epoch:36 step:28875[D loss: 0.426399, acc: 57.03%, op_acc: 39.84%] [G loss: 0.824659]\n",
      "epoch:36 step:28876[D loss: 0.423724, acc: 51.56%, op_acc: 46.88%] [G loss: 0.811815]\n",
      "epoch:36 step:28877[D loss: 0.382910, acc: 65.62%, op_acc: 45.31%] [G loss: 0.826336]\n",
      "epoch:36 step:28878[D loss: 0.457810, acc: 46.09%, op_acc: 42.97%] [G loss: 0.773234]\n",
      "epoch:36 step:28879[D loss: 0.422514, acc: 54.69%, op_acc: 42.19%] [G loss: 0.836864]\n",
      "epoch:36 step:28880[D loss: 0.467365, acc: 43.75%, op_acc: 39.06%] [G loss: 0.884055]\n",
      "epoch:36 step:28881[D loss: 0.389217, acc: 63.28%, op_acc: 41.41%] [G loss: 0.925918]\n",
      "epoch:36 step:28882[D loss: 0.416396, acc: 65.62%, op_acc: 39.06%] [G loss: 0.902056]\n",
      "epoch:36 step:28883[D loss: 0.425300, acc: 56.25%, op_acc: 40.62%] [G loss: 0.893127]\n",
      "epoch:36 step:28884[D loss: 0.406450, acc: 60.94%, op_acc: 39.84%] [G loss: 0.903678]\n",
      "epoch:36 step:28885[D loss: 0.388928, acc: 65.62%, op_acc: 42.97%] [G loss: 0.879331]\n",
      "epoch:36 step:28886[D loss: 0.421973, acc: 52.34%, op_acc: 40.62%] [G loss: 0.857296]\n",
      "epoch:36 step:28887[D loss: 0.449953, acc: 50.78%, op_acc: 39.84%] [G loss: 0.818806]\n",
      "epoch:36 step:28888[D loss: 0.446146, acc: 57.81%, op_acc: 35.94%] [G loss: 0.877667]\n",
      "epoch:36 step:28889[D loss: 0.440428, acc: 57.03%, op_acc: 41.41%] [G loss: 0.901317]\n",
      "epoch:36 step:28890[D loss: 0.408756, acc: 58.59%, op_acc: 42.97%] [G loss: 0.866642]\n",
      "epoch:36 step:28891[D loss: 0.417587, acc: 64.84%, op_acc: 39.84%] [G loss: 0.970763]\n",
      "epoch:36 step:28892[D loss: 0.410020, acc: 61.72%, op_acc: 41.41%] [G loss: 0.873580]\n",
      "epoch:36 step:28893[D loss: 0.456400, acc: 54.69%, op_acc: 36.72%] [G loss: 0.891121]\n",
      "epoch:36 step:28894[D loss: 0.398818, acc: 61.72%, op_acc: 44.53%] [G loss: 0.937358]\n",
      "epoch:36 step:28895[D loss: 0.413996, acc: 60.16%, op_acc: 39.84%] [G loss: 0.882987]\n",
      "epoch:36 step:28896[D loss: 0.431151, acc: 57.03%, op_acc: 40.62%] [G loss: 0.827013]\n",
      "epoch:36 step:28897[D loss: 0.393255, acc: 69.53%, op_acc: 37.50%] [G loss: 0.867978]\n",
      "epoch:37 step:28898[D loss: 0.403739, acc: 61.72%, op_acc: 47.66%] [G loss: 0.841213]\n",
      "epoch:37 step:28899[D loss: 0.405337, acc: 61.72%, op_acc: 39.06%] [G loss: 0.911790]\n",
      "epoch:37 step:28900[D loss: 0.422498, acc: 60.16%, op_acc: 38.28%] [G loss: 0.983043]\n",
      "##############\n",
      "[0.86168296 0.85783957 0.82409248 0.79521993 0.79741519 0.85014795\n",
      " 0.88901187 0.81879797 0.81048995 0.85157349]\n",
      "##########\n",
      "epoch:37 step:28901[D loss: 0.416270, acc: 53.12%, op_acc: 47.66%] [G loss: 0.804690]\n",
      "epoch:37 step:28902[D loss: 0.434627, acc: 50.00%, op_acc: 43.75%] [G loss: 0.839615]\n",
      "epoch:37 step:28903[D loss: 0.449950, acc: 54.69%, op_acc: 36.72%] [G loss: 0.952459]\n",
      "epoch:37 step:28904[D loss: 0.413881, acc: 55.47%, op_acc: 42.19%] [G loss: 0.854118]\n",
      "epoch:37 step:28905[D loss: 0.400676, acc: 59.38%, op_acc: 46.09%] [G loss: 0.878990]\n",
      "epoch:37 step:28906[D loss: 0.423363, acc: 55.47%, op_acc: 44.53%] [G loss: 0.845597]\n",
      "epoch:37 step:28907[D loss: 0.445071, acc: 53.91%, op_acc: 33.59%] [G loss: 0.809665]\n",
      "epoch:37 step:28908[D loss: 0.452781, acc: 54.69%, op_acc: 36.72%] [G loss: 0.890481]\n",
      "epoch:37 step:28909[D loss: 0.432022, acc: 61.72%, op_acc: 41.41%] [G loss: 0.842541]\n",
      "epoch:37 step:28910[D loss: 0.395340, acc: 66.41%, op_acc: 43.75%] [G loss: 0.853507]\n",
      "epoch:37 step:28911[D loss: 0.460301, acc: 53.91%, op_acc: 34.38%] [G loss: 0.841333]\n",
      "epoch:37 step:28912[D loss: 0.410217, acc: 58.59%, op_acc: 46.09%] [G loss: 0.914451]\n",
      "epoch:37 step:28913[D loss: 0.414431, acc: 56.25%, op_acc: 46.88%] [G loss: 0.926347]\n",
      "epoch:37 step:28914[D loss: 0.389215, acc: 58.59%, op_acc: 43.75%] [G loss: 0.864029]\n",
      "epoch:37 step:28915[D loss: 0.425985, acc: 53.91%, op_acc: 39.06%] [G loss: 0.927534]\n",
      "epoch:37 step:28916[D loss: 0.398891, acc: 64.84%, op_acc: 50.78%] [G loss: 0.840935]\n",
      "epoch:37 step:28917[D loss: 0.401459, acc: 59.38%, op_acc: 39.84%] [G loss: 0.864124]\n",
      "epoch:37 step:28918[D loss: 0.451041, acc: 56.25%, op_acc: 34.38%] [G loss: 0.902872]\n",
      "epoch:37 step:28919[D loss: 0.420588, acc: 61.72%, op_acc: 39.06%] [G loss: 0.848587]\n",
      "epoch:37 step:28920[D loss: 0.397439, acc: 64.84%, op_acc: 44.53%] [G loss: 0.906363]\n",
      "epoch:37 step:28921[D loss: 0.427034, acc: 61.72%, op_acc: 39.06%] [G loss: 0.822138]\n",
      "epoch:37 step:28922[D loss: 0.440656, acc: 54.69%, op_acc: 39.84%] [G loss: 0.870155]\n",
      "epoch:37 step:28923[D loss: 0.414891, acc: 56.25%, op_acc: 36.72%] [G loss: 0.872870]\n",
      "epoch:37 step:28924[D loss: 0.400748, acc: 64.84%, op_acc: 43.75%] [G loss: 0.855100]\n",
      "epoch:37 step:28925[D loss: 0.387843, acc: 68.75%, op_acc: 39.06%] [G loss: 0.820647]\n",
      "epoch:37 step:28926[D loss: 0.390098, acc: 58.59%, op_acc: 52.34%] [G loss: 0.903280]\n",
      "epoch:37 step:28927[D loss: 0.418667, acc: 56.25%, op_acc: 42.97%] [G loss: 0.857057]\n",
      "epoch:37 step:28928[D loss: 0.420186, acc: 65.62%, op_acc: 40.62%] [G loss: 0.873706]\n",
      "epoch:37 step:28929[D loss: 0.449549, acc: 63.28%, op_acc: 34.38%] [G loss: 0.921696]\n",
      "epoch:37 step:28930[D loss: 0.399632, acc: 56.25%, op_acc: 50.78%] [G loss: 0.853754]\n",
      "epoch:37 step:28931[D loss: 0.388301, acc: 62.50%, op_acc: 42.97%] [G loss: 0.858147]\n",
      "epoch:37 step:28932[D loss: 0.437349, acc: 59.38%, op_acc: 40.62%] [G loss: 0.893431]\n",
      "epoch:37 step:28933[D loss: 0.395112, acc: 60.94%, op_acc: 40.62%] [G loss: 0.888413]\n",
      "epoch:37 step:28934[D loss: 0.388391, acc: 62.50%, op_acc: 44.53%] [G loss: 0.903113]\n",
      "epoch:37 step:28935[D loss: 0.400788, acc: 64.06%, op_acc: 38.28%] [G loss: 0.902476]\n",
      "epoch:37 step:28936[D loss: 0.385725, acc: 56.25%, op_acc: 52.34%] [G loss: 0.956598]\n",
      "epoch:37 step:28937[D loss: 0.433149, acc: 57.03%, op_acc: 38.28%] [G loss: 0.880424]\n",
      "epoch:37 step:28938[D loss: 0.383776, acc: 60.94%, op_acc: 46.88%] [G loss: 0.888274]\n",
      "epoch:37 step:28939[D loss: 0.404959, acc: 55.47%, op_acc: 44.53%] [G loss: 0.852458]\n",
      "epoch:37 step:28940[D loss: 0.436396, acc: 57.03%, op_acc: 35.16%] [G loss: 0.885132]\n",
      "epoch:37 step:28941[D loss: 0.438653, acc: 57.81%, op_acc: 42.19%] [G loss: 0.903555]\n",
      "epoch:37 step:28942[D loss: 0.402014, acc: 64.06%, op_acc: 42.19%] [G loss: 0.885239]\n",
      "epoch:37 step:28943[D loss: 0.431495, acc: 59.38%, op_acc: 38.28%] [G loss: 0.906511]\n",
      "epoch:37 step:28944[D loss: 0.432215, acc: 57.03%, op_acc: 31.25%] [G loss: 0.931691]\n",
      "epoch:37 step:28945[D loss: 0.442716, acc: 59.38%, op_acc: 31.25%] [G loss: 0.817898]\n",
      "epoch:37 step:28946[D loss: 0.405245, acc: 59.38%, op_acc: 42.19%] [G loss: 0.830825]\n",
      "epoch:37 step:28947[D loss: 0.446996, acc: 53.12%, op_acc: 35.94%] [G loss: 0.884363]\n",
      "epoch:37 step:28948[D loss: 0.376218, acc: 71.09%, op_acc: 43.75%] [G loss: 0.851461]\n",
      "epoch:37 step:28949[D loss: 0.428506, acc: 54.69%, op_acc: 42.19%] [G loss: 0.804047]\n",
      "epoch:37 step:28950[D loss: 0.419047, acc: 67.19%, op_acc: 36.72%] [G loss: 0.883725]\n",
      "##############\n",
      "[0.8376587  0.84557032 0.81834244 0.80120802 0.78431908 0.81617879\n",
      " 0.88291848 0.82656999 0.81062852 0.82622574]\n",
      "##########\n",
      "epoch:37 step:28951[D loss: 0.408866, acc: 60.94%, op_acc: 44.53%] [G loss: 0.920526]\n",
      "epoch:37 step:28952[D loss: 0.396207, acc: 66.41%, op_acc: 38.28%] [G loss: 0.824203]\n",
      "epoch:37 step:28953[D loss: 0.411476, acc: 66.41%, op_acc: 36.72%] [G loss: 0.867734]\n",
      "epoch:37 step:28954[D loss: 0.439511, acc: 55.47%, op_acc: 39.06%] [G loss: 0.891763]\n",
      "epoch:37 step:28955[D loss: 0.426544, acc: 54.69%, op_acc: 42.19%] [G loss: 0.899610]\n",
      "epoch:37 step:28956[D loss: 0.389472, acc: 61.72%, op_acc: 42.97%] [G loss: 0.885545]\n",
      "epoch:37 step:28957[D loss: 0.391666, acc: 66.41%, op_acc: 43.75%] [G loss: 0.950444]\n",
      "epoch:37 step:28958[D loss: 0.431350, acc: 59.38%, op_acc: 42.97%] [G loss: 0.945875]\n",
      "epoch:37 step:28959[D loss: 0.452647, acc: 51.56%, op_acc: 35.94%] [G loss: 0.891979]\n",
      "epoch:37 step:28960[D loss: 0.441219, acc: 53.12%, op_acc: 42.19%] [G loss: 0.853558]\n",
      "epoch:37 step:28961[D loss: 0.418904, acc: 57.81%, op_acc: 41.41%] [G loss: 0.860969]\n",
      "epoch:37 step:28962[D loss: 0.411972, acc: 56.25%, op_acc: 40.62%] [G loss: 0.896783]\n",
      "epoch:37 step:28963[D loss: 0.431136, acc: 59.38%, op_acc: 42.19%] [G loss: 0.910402]\n",
      "epoch:37 step:28964[D loss: 0.417637, acc: 55.47%, op_acc: 39.06%] [G loss: 0.806035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:28965[D loss: 0.418565, acc: 63.28%, op_acc: 45.31%] [G loss: 0.928730]\n",
      "epoch:37 step:28966[D loss: 0.394008, acc: 60.94%, op_acc: 48.44%] [G loss: 0.888729]\n",
      "epoch:37 step:28967[D loss: 0.453516, acc: 53.91%, op_acc: 39.84%] [G loss: 0.880033]\n",
      "epoch:37 step:28968[D loss: 0.438518, acc: 62.50%, op_acc: 35.16%] [G loss: 0.853677]\n",
      "epoch:37 step:28969[D loss: 0.407754, acc: 62.50%, op_acc: 42.97%] [G loss: 0.850448]\n",
      "epoch:37 step:28970[D loss: 0.403737, acc: 58.59%, op_acc: 41.41%] [G loss: 0.910508]\n",
      "epoch:37 step:28971[D loss: 0.420266, acc: 53.91%, op_acc: 42.97%] [G loss: 0.875927]\n",
      "epoch:37 step:28972[D loss: 0.386319, acc: 60.16%, op_acc: 42.19%] [G loss: 0.930362]\n",
      "epoch:37 step:28973[D loss: 0.457309, acc: 49.22%, op_acc: 38.28%] [G loss: 0.870659]\n",
      "epoch:37 step:28974[D loss: 0.413024, acc: 60.94%, op_acc: 35.94%] [G loss: 0.841876]\n",
      "epoch:37 step:28975[D loss: 0.432435, acc: 61.72%, op_acc: 37.50%] [G loss: 0.961612]\n",
      "epoch:37 step:28976[D loss: 0.416401, acc: 59.38%, op_acc: 43.75%] [G loss: 0.919143]\n",
      "epoch:37 step:28977[D loss: 0.432920, acc: 65.62%, op_acc: 33.59%] [G loss: 0.903143]\n",
      "epoch:37 step:28978[D loss: 0.416916, acc: 64.84%, op_acc: 38.28%] [G loss: 0.844393]\n",
      "epoch:37 step:28979[D loss: 0.400535, acc: 69.53%, op_acc: 39.06%] [G loss: 0.891165]\n",
      "epoch:37 step:28980[D loss: 0.415188, acc: 64.06%, op_acc: 33.59%] [G loss: 0.887013]\n",
      "epoch:37 step:28981[D loss: 0.414226, acc: 58.59%, op_acc: 39.84%] [G loss: 0.873785]\n",
      "epoch:37 step:28982[D loss: 0.448109, acc: 58.59%, op_acc: 34.38%] [G loss: 0.873726]\n",
      "epoch:37 step:28983[D loss: 0.410058, acc: 59.38%, op_acc: 43.75%] [G loss: 0.935832]\n",
      "epoch:37 step:28984[D loss: 0.401322, acc: 63.28%, op_acc: 43.75%] [G loss: 0.851995]\n",
      "epoch:37 step:28985[D loss: 0.440532, acc: 56.25%, op_acc: 39.84%] [G loss: 0.894946]\n",
      "epoch:37 step:28986[D loss: 0.445764, acc: 54.69%, op_acc: 29.69%] [G loss: 0.896023]\n",
      "epoch:37 step:28987[D loss: 0.403981, acc: 61.72%, op_acc: 44.53%] [G loss: 0.907696]\n",
      "epoch:37 step:28988[D loss: 0.433941, acc: 50.00%, op_acc: 38.28%] [G loss: 0.864664]\n",
      "epoch:37 step:28989[D loss: 0.448890, acc: 57.81%, op_acc: 36.72%] [G loss: 0.888051]\n",
      "epoch:37 step:28990[D loss: 0.427974, acc: 60.94%, op_acc: 40.62%] [G loss: 0.868967]\n",
      "epoch:37 step:28991[D loss: 0.396703, acc: 61.72%, op_acc: 41.41%] [G loss: 0.899240]\n",
      "epoch:37 step:28992[D loss: 0.396235, acc: 56.25%, op_acc: 43.75%] [G loss: 0.929761]\n",
      "epoch:37 step:28993[D loss: 0.436993, acc: 58.59%, op_acc: 40.62%] [G loss: 0.926210]\n",
      "epoch:37 step:28994[D loss: 0.433739, acc: 51.56%, op_acc: 37.50%] [G loss: 0.772887]\n",
      "epoch:37 step:28995[D loss: 0.419070, acc: 60.94%, op_acc: 38.28%] [G loss: 0.963921]\n",
      "epoch:37 step:28996[D loss: 0.404136, acc: 56.25%, op_acc: 45.31%] [G loss: 0.926437]\n",
      "epoch:37 step:28997[D loss: 0.400014, acc: 64.06%, op_acc: 35.94%] [G loss: 0.925856]\n",
      "epoch:37 step:28998[D loss: 0.433008, acc: 58.59%, op_acc: 39.84%] [G loss: 0.797389]\n",
      "epoch:37 step:28999[D loss: 0.421057, acc: 60.94%, op_acc: 36.72%] [G loss: 0.929978]\n",
      "epoch:37 step:29000[D loss: 0.427304, acc: 60.16%, op_acc: 39.06%] [G loss: 0.838513]\n",
      "##############\n",
      "[0.86550555 0.85817264 0.81974061 0.81336329 0.80178359 0.8183367\n",
      " 0.8970444  0.82485408 0.79119629 0.83182511]\n",
      "##########\n",
      "epoch:37 step:29001[D loss: 0.457172, acc: 49.22%, op_acc: 43.75%] [G loss: 0.836675]\n",
      "epoch:37 step:29002[D loss: 0.402568, acc: 62.50%, op_acc: 40.62%] [G loss: 0.860133]\n",
      "epoch:37 step:29003[D loss: 0.402053, acc: 57.03%, op_acc: 42.97%] [G loss: 0.910546]\n",
      "epoch:37 step:29004[D loss: 0.418319, acc: 61.72%, op_acc: 42.19%] [G loss: 0.911586]\n",
      "epoch:37 step:29005[D loss: 0.434352, acc: 65.62%, op_acc: 34.38%] [G loss: 0.876717]\n",
      "epoch:37 step:29006[D loss: 0.398180, acc: 60.16%, op_acc: 41.41%] [G loss: 0.933091]\n",
      "epoch:37 step:29007[D loss: 0.404271, acc: 60.94%, op_acc: 45.31%] [G loss: 0.856101]\n",
      "epoch:37 step:29008[D loss: 0.412754, acc: 67.97%, op_acc: 38.28%] [G loss: 0.951575]\n",
      "epoch:37 step:29009[D loss: 0.411716, acc: 57.81%, op_acc: 45.31%] [G loss: 0.894081]\n",
      "epoch:37 step:29010[D loss: 0.428562, acc: 53.91%, op_acc: 39.84%] [G loss: 0.914288]\n",
      "epoch:37 step:29011[D loss: 0.399565, acc: 57.81%, op_acc: 46.88%] [G loss: 0.870825]\n",
      "epoch:37 step:29012[D loss: 0.383314, acc: 64.84%, op_acc: 42.19%] [G loss: 0.948379]\n",
      "epoch:37 step:29013[D loss: 0.422998, acc: 55.47%, op_acc: 39.06%] [G loss: 0.896798]\n",
      "epoch:37 step:29014[D loss: 0.430420, acc: 53.91%, op_acc: 41.41%] [G loss: 0.903193]\n",
      "epoch:37 step:29015[D loss: 0.407867, acc: 57.03%, op_acc: 46.88%] [G loss: 0.883309]\n",
      "epoch:37 step:29016[D loss: 0.412892, acc: 58.59%, op_acc: 37.50%] [G loss: 0.846002]\n",
      "epoch:37 step:29017[D loss: 0.409702, acc: 59.38%, op_acc: 43.75%] [G loss: 0.831427]\n",
      "epoch:37 step:29018[D loss: 0.406681, acc: 62.50%, op_acc: 42.19%] [G loss: 0.904374]\n",
      "epoch:37 step:29019[D loss: 0.421655, acc: 64.06%, op_acc: 39.06%] [G loss: 0.929726]\n",
      "epoch:37 step:29020[D loss: 0.420321, acc: 60.94%, op_acc: 41.41%] [G loss: 0.926439]\n",
      "epoch:37 step:29021[D loss: 0.394775, acc: 64.84%, op_acc: 43.75%] [G loss: 0.916670]\n",
      "epoch:37 step:29022[D loss: 0.419153, acc: 59.38%, op_acc: 39.84%] [G loss: 0.807628]\n",
      "epoch:37 step:29023[D loss: 0.404999, acc: 62.50%, op_acc: 41.41%] [G loss: 0.919170]\n",
      "epoch:37 step:29024[D loss: 0.417078, acc: 57.03%, op_acc: 40.62%] [G loss: 0.793900]\n",
      "epoch:37 step:29025[D loss: 0.413767, acc: 64.06%, op_acc: 42.19%] [G loss: 0.842454]\n",
      "epoch:37 step:29026[D loss: 0.414687, acc: 63.28%, op_acc: 37.50%] [G loss: 0.883052]\n",
      "epoch:37 step:29027[D loss: 0.413895, acc: 53.12%, op_acc: 42.97%] [G loss: 0.864151]\n",
      "epoch:37 step:29028[D loss: 0.373518, acc: 71.88%, op_acc: 48.44%] [G loss: 0.905427]\n",
      "epoch:37 step:29029[D loss: 0.392299, acc: 64.06%, op_acc: 44.53%] [G loss: 0.797481]\n",
      "epoch:37 step:29030[D loss: 0.443419, acc: 60.94%, op_acc: 39.06%] [G loss: 0.847173]\n",
      "epoch:37 step:29031[D loss: 0.401189, acc: 58.59%, op_acc: 42.97%] [G loss: 0.863665]\n",
      "epoch:37 step:29032[D loss: 0.432101, acc: 55.47%, op_acc: 38.28%] [G loss: 0.854026]\n",
      "epoch:37 step:29033[D loss: 0.404362, acc: 58.59%, op_acc: 39.06%] [G loss: 0.919682]\n",
      "epoch:37 step:29034[D loss: 0.412629, acc: 54.69%, op_acc: 41.41%] [G loss: 0.906925]\n",
      "epoch:37 step:29035[D loss: 0.431788, acc: 60.16%, op_acc: 38.28%] [G loss: 0.921663]\n",
      "epoch:37 step:29036[D loss: 0.388528, acc: 65.62%, op_acc: 42.97%] [G loss: 0.993448]\n",
      "epoch:37 step:29037[D loss: 0.420214, acc: 59.38%, op_acc: 39.84%] [G loss: 0.865227]\n",
      "epoch:37 step:29038[D loss: 0.424588, acc: 60.94%, op_acc: 42.19%] [G loss: 0.893707]\n",
      "epoch:37 step:29039[D loss: 0.376466, acc: 69.53%, op_acc: 39.06%] [G loss: 0.854766]\n",
      "epoch:37 step:29040[D loss: 0.414637, acc: 64.84%, op_acc: 38.28%] [G loss: 0.902154]\n",
      "epoch:37 step:29041[D loss: 0.417716, acc: 61.72%, op_acc: 41.41%] [G loss: 0.816094]\n",
      "epoch:37 step:29042[D loss: 0.379471, acc: 65.62%, op_acc: 41.41%] [G loss: 0.919694]\n",
      "epoch:37 step:29043[D loss: 0.379383, acc: 68.75%, op_acc: 43.75%] [G loss: 0.867726]\n",
      "epoch:37 step:29044[D loss: 0.401765, acc: 61.72%, op_acc: 46.88%] [G loss: 0.850222]\n",
      "epoch:37 step:29045[D loss: 0.458093, acc: 51.56%, op_acc: 37.50%] [G loss: 0.818370]\n",
      "epoch:37 step:29046[D loss: 0.382218, acc: 66.41%, op_acc: 48.44%] [G loss: 0.900930]\n",
      "epoch:37 step:29047[D loss: 0.403674, acc: 60.94%, op_acc: 37.50%] [G loss: 0.848706]\n",
      "epoch:37 step:29048[D loss: 0.409136, acc: 59.38%, op_acc: 46.88%] [G loss: 0.920716]\n",
      "epoch:37 step:29049[D loss: 0.424260, acc: 56.25%, op_acc: 42.19%] [G loss: 0.936324]\n",
      "epoch:37 step:29050[D loss: 0.394564, acc: 64.06%, op_acc: 41.41%] [G loss: 0.866773]\n",
      "##############\n",
      "[0.84942938 0.85716878 0.81796233 0.80930156 0.79700402 0.82839956\n",
      " 0.89122764 0.83209797 0.812824   0.83312032]\n",
      "##########\n",
      "epoch:37 step:29051[D loss: 0.436892, acc: 57.81%, op_acc: 41.41%] [G loss: 0.845141]\n",
      "epoch:37 step:29052[D loss: 0.417574, acc: 55.47%, op_acc: 39.06%] [G loss: 0.857214]\n",
      "epoch:37 step:29053[D loss: 0.406019, acc: 60.16%, op_acc: 41.41%] [G loss: 0.961673]\n",
      "epoch:37 step:29054[D loss: 0.410058, acc: 61.72%, op_acc: 38.28%] [G loss: 0.892274]\n",
      "epoch:37 step:29055[D loss: 0.415550, acc: 53.91%, op_acc: 41.41%] [G loss: 0.848930]\n",
      "epoch:37 step:29056[D loss: 0.414806, acc: 55.47%, op_acc: 40.62%] [G loss: 0.908715]\n",
      "epoch:37 step:29057[D loss: 0.430389, acc: 68.75%, op_acc: 39.84%] [G loss: 0.915896]\n",
      "epoch:37 step:29058[D loss: 0.422262, acc: 53.91%, op_acc: 42.97%] [G loss: 0.915085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29059[D loss: 0.396100, acc: 58.59%, op_acc: 44.53%] [G loss: 0.853901]\n",
      "epoch:37 step:29060[D loss: 0.438375, acc: 53.91%, op_acc: 43.75%] [G loss: 0.939775]\n",
      "epoch:37 step:29061[D loss: 0.411763, acc: 67.97%, op_acc: 39.84%] [G loss: 0.943099]\n",
      "epoch:37 step:29062[D loss: 0.410353, acc: 64.06%, op_acc: 40.62%] [G loss: 0.885942]\n",
      "epoch:37 step:29063[D loss: 0.419356, acc: 58.59%, op_acc: 39.84%] [G loss: 0.851019]\n",
      "epoch:37 step:29064[D loss: 0.406117, acc: 58.59%, op_acc: 42.19%] [G loss: 0.850213]\n",
      "epoch:37 step:29065[D loss: 0.418158, acc: 61.72%, op_acc: 44.53%] [G loss: 0.879553]\n",
      "epoch:37 step:29066[D loss: 0.418026, acc: 64.06%, op_acc: 43.75%] [G loss: 0.894139]\n",
      "epoch:37 step:29067[D loss: 0.437923, acc: 51.56%, op_acc: 40.62%] [G loss: 0.887942]\n",
      "epoch:37 step:29068[D loss: 0.445400, acc: 55.47%, op_acc: 37.50%] [G loss: 0.900823]\n",
      "epoch:37 step:29069[D loss: 0.420970, acc: 58.59%, op_acc: 37.50%] [G loss: 0.862657]\n",
      "epoch:37 step:29070[D loss: 0.424783, acc: 60.16%, op_acc: 42.19%] [G loss: 0.906174]\n",
      "epoch:37 step:29071[D loss: 0.429295, acc: 53.91%, op_acc: 39.06%] [G loss: 0.932411]\n",
      "epoch:37 step:29072[D loss: 0.429572, acc: 60.16%, op_acc: 39.84%] [G loss: 0.877067]\n",
      "epoch:37 step:29073[D loss: 0.439538, acc: 54.69%, op_acc: 34.38%] [G loss: 0.842714]\n",
      "epoch:37 step:29074[D loss: 0.387894, acc: 67.19%, op_acc: 41.41%] [G loss: 0.958119]\n",
      "epoch:37 step:29075[D loss: 0.416930, acc: 60.94%, op_acc: 34.38%] [G loss: 0.882390]\n",
      "epoch:37 step:29076[D loss: 0.409489, acc: 61.72%, op_acc: 42.97%] [G loss: 0.912736]\n",
      "epoch:37 step:29077[D loss: 0.420948, acc: 62.50%, op_acc: 43.75%] [G loss: 0.880787]\n",
      "epoch:37 step:29078[D loss: 0.438929, acc: 53.91%, op_acc: 40.62%] [G loss: 0.827935]\n",
      "epoch:37 step:29079[D loss: 0.411578, acc: 60.94%, op_acc: 39.84%] [G loss: 0.827952]\n",
      "epoch:37 step:29080[D loss: 0.425810, acc: 56.25%, op_acc: 37.50%] [G loss: 0.867306]\n",
      "epoch:37 step:29081[D loss: 0.425301, acc: 56.25%, op_acc: 38.28%] [G loss: 0.800687]\n",
      "epoch:37 step:29082[D loss: 0.431484, acc: 57.81%, op_acc: 39.06%] [G loss: 0.813547]\n",
      "epoch:37 step:29083[D loss: 0.436636, acc: 53.12%, op_acc: 40.62%] [G loss: 0.845632]\n",
      "epoch:37 step:29084[D loss: 0.404976, acc: 60.16%, op_acc: 43.75%] [G loss: 0.859481]\n",
      "epoch:37 step:29085[D loss: 0.442999, acc: 51.56%, op_acc: 38.28%] [G loss: 0.824161]\n",
      "epoch:37 step:29086[D loss: 0.426067, acc: 58.59%, op_acc: 34.38%] [G loss: 0.780562]\n",
      "epoch:37 step:29087[D loss: 0.427114, acc: 57.81%, op_acc: 37.50%] [G loss: 0.904766]\n",
      "epoch:37 step:29088[D loss: 0.408066, acc: 64.84%, op_acc: 40.62%] [G loss: 0.889805]\n",
      "epoch:37 step:29089[D loss: 0.398199, acc: 63.28%, op_acc: 42.97%] [G loss: 0.839309]\n",
      "epoch:37 step:29090[D loss: 0.443086, acc: 49.22%, op_acc: 35.94%] [G loss: 0.902094]\n",
      "epoch:37 step:29091[D loss: 0.417992, acc: 58.59%, op_acc: 41.41%] [G loss: 0.843503]\n",
      "epoch:37 step:29092[D loss: 0.435874, acc: 53.12%, op_acc: 38.28%] [G loss: 0.909816]\n",
      "epoch:37 step:29093[D loss: 0.433539, acc: 61.72%, op_acc: 38.28%] [G loss: 0.780616]\n",
      "epoch:37 step:29094[D loss: 0.445126, acc: 53.91%, op_acc: 39.84%] [G loss: 0.867081]\n",
      "epoch:37 step:29095[D loss: 0.424981, acc: 54.69%, op_acc: 38.28%] [G loss: 0.888333]\n",
      "epoch:37 step:29096[D loss: 0.445431, acc: 56.25%, op_acc: 38.28%] [G loss: 0.873857]\n",
      "epoch:37 step:29097[D loss: 0.388187, acc: 65.62%, op_acc: 42.19%] [G loss: 0.910969]\n",
      "epoch:37 step:29098[D loss: 0.400236, acc: 60.94%, op_acc: 45.31%] [G loss: 0.865792]\n",
      "epoch:37 step:29099[D loss: 0.434880, acc: 57.81%, op_acc: 39.84%] [G loss: 0.838642]\n",
      "epoch:37 step:29100[D loss: 0.417649, acc: 58.59%, op_acc: 39.84%] [G loss: 0.839579]\n",
      "##############\n",
      "[0.84187351 0.8551433  0.82082307 0.81979106 0.81411365 0.81687979\n",
      " 0.90038953 0.84045569 0.80383403 0.8240153 ]\n",
      "##########\n",
      "epoch:37 step:29101[D loss: 0.401339, acc: 64.06%, op_acc: 43.75%] [G loss: 0.897323]\n",
      "epoch:37 step:29102[D loss: 0.422651, acc: 55.47%, op_acc: 39.84%] [G loss: 0.831273]\n",
      "epoch:37 step:29103[D loss: 0.424015, acc: 56.25%, op_acc: 39.06%] [G loss: 0.866486]\n",
      "epoch:37 step:29104[D loss: 0.400117, acc: 56.25%, op_acc: 41.41%] [G loss: 0.894604]\n",
      "epoch:37 step:29105[D loss: 0.457773, acc: 56.25%, op_acc: 40.62%] [G loss: 0.893305]\n",
      "epoch:37 step:29106[D loss: 0.414803, acc: 55.47%, op_acc: 39.84%] [G loss: 0.961358]\n",
      "epoch:37 step:29107[D loss: 0.394766, acc: 70.31%, op_acc: 39.06%] [G loss: 0.905151]\n",
      "epoch:37 step:29108[D loss: 0.405770, acc: 57.81%, op_acc: 42.97%] [G loss: 0.899970]\n",
      "epoch:37 step:29109[D loss: 0.399664, acc: 60.16%, op_acc: 44.53%] [G loss: 0.946823]\n",
      "epoch:37 step:29110[D loss: 0.428156, acc: 55.47%, op_acc: 42.97%] [G loss: 0.898350]\n",
      "epoch:37 step:29111[D loss: 0.404466, acc: 59.38%, op_acc: 39.84%] [G loss: 0.922895]\n",
      "epoch:37 step:29112[D loss: 0.448586, acc: 53.91%, op_acc: 41.41%] [G loss: 0.828043]\n",
      "epoch:37 step:29113[D loss: 0.403816, acc: 64.06%, op_acc: 38.28%] [G loss: 0.851802]\n",
      "epoch:37 step:29114[D loss: 0.410784, acc: 58.59%, op_acc: 45.31%] [G loss: 1.022230]\n",
      "epoch:37 step:29115[D loss: 0.411755, acc: 65.62%, op_acc: 40.62%] [G loss: 0.957462]\n",
      "epoch:37 step:29116[D loss: 0.410758, acc: 55.47%, op_acc: 42.97%] [G loss: 0.889047]\n",
      "epoch:37 step:29117[D loss: 0.428043, acc: 61.72%, op_acc: 39.06%] [G loss: 0.993625]\n",
      "epoch:37 step:29118[D loss: 0.421138, acc: 64.06%, op_acc: 42.19%] [G loss: 0.970193]\n",
      "epoch:37 step:29119[D loss: 0.423820, acc: 59.38%, op_acc: 39.06%] [G loss: 0.882946]\n",
      "epoch:37 step:29120[D loss: 0.424159, acc: 58.59%, op_acc: 43.75%] [G loss: 0.894626]\n",
      "epoch:37 step:29121[D loss: 0.432266, acc: 57.81%, op_acc: 36.72%] [G loss: 0.890641]\n",
      "epoch:37 step:29122[D loss: 0.433868, acc: 54.69%, op_acc: 35.94%] [G loss: 0.930366]\n",
      "epoch:37 step:29123[D loss: 0.426264, acc: 61.72%, op_acc: 39.06%] [G loss: 0.907476]\n",
      "epoch:37 step:29124[D loss: 0.408509, acc: 64.06%, op_acc: 42.19%] [G loss: 0.920401]\n",
      "epoch:37 step:29125[D loss: 0.413953, acc: 61.72%, op_acc: 42.19%] [G loss: 0.820074]\n",
      "epoch:37 step:29126[D loss: 0.405834, acc: 57.03%, op_acc: 41.41%] [G loss: 0.876259]\n",
      "epoch:37 step:29127[D loss: 0.407521, acc: 64.84%, op_acc: 42.19%] [G loss: 0.879337]\n",
      "epoch:37 step:29128[D loss: 0.403532, acc: 57.03%, op_acc: 42.19%] [G loss: 0.897628]\n",
      "epoch:37 step:29129[D loss: 0.416777, acc: 64.84%, op_acc: 40.62%] [G loss: 0.987985]\n",
      "epoch:37 step:29130[D loss: 0.400673, acc: 64.84%, op_acc: 39.84%] [G loss: 0.881708]\n",
      "epoch:37 step:29131[D loss: 0.423586, acc: 57.81%, op_acc: 41.41%] [G loss: 0.829725]\n",
      "epoch:37 step:29132[D loss: 0.443965, acc: 55.47%, op_acc: 42.19%] [G loss: 0.832277]\n",
      "epoch:37 step:29133[D loss: 0.432384, acc: 55.47%, op_acc: 38.28%] [G loss: 0.838776]\n",
      "epoch:37 step:29134[D loss: 0.421654, acc: 52.34%, op_acc: 41.41%] [G loss: 0.899439]\n",
      "epoch:37 step:29135[D loss: 0.421641, acc: 57.81%, op_acc: 39.84%] [G loss: 0.832975]\n",
      "epoch:37 step:29136[D loss: 0.416212, acc: 56.25%, op_acc: 39.84%] [G loss: 0.876988]\n",
      "epoch:37 step:29137[D loss: 0.420469, acc: 59.38%, op_acc: 45.31%] [G loss: 0.847679]\n",
      "epoch:37 step:29138[D loss: 0.411208, acc: 64.06%, op_acc: 42.19%] [G loss: 0.880379]\n",
      "epoch:37 step:29139[D loss: 0.403189, acc: 60.94%, op_acc: 40.62%] [G loss: 0.857660]\n",
      "epoch:37 step:29140[D loss: 0.425820, acc: 53.12%, op_acc: 45.31%] [G loss: 0.883220]\n",
      "epoch:37 step:29141[D loss: 0.425049, acc: 59.38%, op_acc: 38.28%] [G loss: 0.913884]\n",
      "epoch:37 step:29142[D loss: 0.434284, acc: 54.69%, op_acc: 40.62%] [G loss: 0.776072]\n",
      "epoch:37 step:29143[D loss: 0.451533, acc: 59.38%, op_acc: 36.72%] [G loss: 0.835903]\n",
      "epoch:37 step:29144[D loss: 0.425958, acc: 52.34%, op_acc: 43.75%] [G loss: 0.883096]\n",
      "epoch:37 step:29145[D loss: 0.438061, acc: 55.47%, op_acc: 35.94%] [G loss: 0.855127]\n",
      "epoch:37 step:29146[D loss: 0.414567, acc: 63.28%, op_acc: 46.09%] [G loss: 0.899529]\n",
      "epoch:37 step:29147[D loss: 0.419057, acc: 64.06%, op_acc: 38.28%] [G loss: 0.877204]\n",
      "epoch:37 step:29148[D loss: 0.396287, acc: 56.25%, op_acc: 45.31%] [G loss: 0.866474]\n",
      "epoch:37 step:29149[D loss: 0.437266, acc: 57.81%, op_acc: 38.28%] [G loss: 0.865615]\n",
      "epoch:37 step:29150[D loss: 0.411008, acc: 61.72%, op_acc: 42.97%] [G loss: 0.865783]\n",
      "##############\n",
      "[0.86889941 0.84473844 0.81515908 0.81200611 0.80117359 0.83613387\n",
      " 0.88529166 0.80602639 0.81507379 0.82232065]\n",
      "##########\n",
      "epoch:37 step:29151[D loss: 0.413712, acc: 61.72%, op_acc: 41.41%] [G loss: 0.934436]\n",
      "epoch:37 step:29152[D loss: 0.424409, acc: 60.16%, op_acc: 37.50%] [G loss: 0.903121]\n",
      "epoch:37 step:29153[D loss: 0.424994, acc: 56.25%, op_acc: 39.06%] [G loss: 0.905079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29154[D loss: 0.417433, acc: 57.03%, op_acc: 41.41%] [G loss: 0.854788]\n",
      "epoch:37 step:29155[D loss: 0.417348, acc: 63.28%, op_acc: 37.50%] [G loss: 0.893396]\n",
      "epoch:37 step:29156[D loss: 0.434193, acc: 60.94%, op_acc: 35.94%] [G loss: 0.880272]\n",
      "epoch:37 step:29157[D loss: 0.423379, acc: 62.50%, op_acc: 40.62%] [G loss: 0.849600]\n",
      "epoch:37 step:29158[D loss: 0.437009, acc: 55.47%, op_acc: 39.84%] [G loss: 0.862893]\n",
      "epoch:37 step:29159[D loss: 0.416159, acc: 60.16%, op_acc: 39.06%] [G loss: 0.859498]\n",
      "epoch:37 step:29160[D loss: 0.427568, acc: 60.16%, op_acc: 38.28%] [G loss: 0.867931]\n",
      "epoch:37 step:29161[D loss: 0.429312, acc: 56.25%, op_acc: 40.62%] [G loss: 0.845701]\n",
      "epoch:37 step:29162[D loss: 0.392933, acc: 63.28%, op_acc: 47.66%] [G loss: 0.900840]\n",
      "epoch:37 step:29163[D loss: 0.442223, acc: 50.78%, op_acc: 37.50%] [G loss: 0.873516]\n",
      "epoch:37 step:29164[D loss: 0.460273, acc: 50.78%, op_acc: 39.84%] [G loss: 0.830988]\n",
      "epoch:37 step:29165[D loss: 0.432355, acc: 57.81%, op_acc: 42.19%] [G loss: 0.824520]\n",
      "epoch:37 step:29166[D loss: 0.389406, acc: 67.97%, op_acc: 42.19%] [G loss: 0.833465]\n",
      "epoch:37 step:29167[D loss: 0.401930, acc: 64.06%, op_acc: 38.28%] [G loss: 0.948165]\n",
      "epoch:37 step:29168[D loss: 0.409936, acc: 59.38%, op_acc: 42.97%] [G loss: 0.924870]\n",
      "epoch:37 step:29169[D loss: 0.424370, acc: 59.38%, op_acc: 38.28%] [G loss: 0.852321]\n",
      "epoch:37 step:29170[D loss: 0.389302, acc: 63.28%, op_acc: 43.75%] [G loss: 0.898348]\n",
      "epoch:37 step:29171[D loss: 0.423981, acc: 59.38%, op_acc: 42.19%] [G loss: 0.898690]\n",
      "epoch:37 step:29172[D loss: 0.404435, acc: 69.53%, op_acc: 41.41%] [G loss: 0.984800]\n",
      "epoch:37 step:29173[D loss: 0.396192, acc: 64.06%, op_acc: 42.97%] [G loss: 0.962098]\n",
      "epoch:37 step:29174[D loss: 0.418995, acc: 63.28%, op_acc: 38.28%] [G loss: 0.907840]\n",
      "epoch:37 step:29175[D loss: 0.421332, acc: 64.06%, op_acc: 35.16%] [G loss: 0.921012]\n",
      "epoch:37 step:29176[D loss: 0.420885, acc: 60.16%, op_acc: 36.72%] [G loss: 0.832433]\n",
      "epoch:37 step:29177[D loss: 0.390820, acc: 65.62%, op_acc: 50.00%] [G loss: 0.889923]\n",
      "epoch:37 step:29178[D loss: 0.440306, acc: 53.91%, op_acc: 36.72%] [G loss: 0.815865]\n",
      "epoch:37 step:29179[D loss: 0.424708, acc: 61.72%, op_acc: 38.28%] [G loss: 0.869654]\n",
      "epoch:37 step:29180[D loss: 0.391479, acc: 60.94%, op_acc: 45.31%] [G loss: 0.865061]\n",
      "epoch:37 step:29181[D loss: 0.427749, acc: 57.03%, op_acc: 41.41%] [G loss: 0.936373]\n",
      "epoch:37 step:29182[D loss: 0.395961, acc: 67.97%, op_acc: 42.97%] [G loss: 1.006856]\n",
      "epoch:37 step:29183[D loss: 0.418643, acc: 63.28%, op_acc: 39.84%] [G loss: 0.952723]\n",
      "epoch:37 step:29184[D loss: 0.442394, acc: 59.38%, op_acc: 45.31%] [G loss: 0.845512]\n",
      "epoch:37 step:29185[D loss: 0.372684, acc: 69.53%, op_acc: 43.75%] [G loss: 0.828953]\n",
      "epoch:37 step:29186[D loss: 0.456925, acc: 56.25%, op_acc: 38.28%] [G loss: 0.833600]\n",
      "epoch:37 step:29187[D loss: 0.416926, acc: 67.97%, op_acc: 39.06%] [G loss: 0.819883]\n",
      "epoch:37 step:29188[D loss: 0.441579, acc: 57.81%, op_acc: 39.84%] [G loss: 0.906707]\n",
      "epoch:37 step:29189[D loss: 0.437221, acc: 57.81%, op_acc: 37.50%] [G loss: 0.851241]\n",
      "epoch:37 step:29190[D loss: 0.411922, acc: 56.25%, op_acc: 42.19%] [G loss: 0.852376]\n",
      "epoch:37 step:29191[D loss: 0.438572, acc: 60.94%, op_acc: 39.84%] [G loss: 0.855850]\n",
      "epoch:37 step:29192[D loss: 0.401108, acc: 66.41%, op_acc: 39.84%] [G loss: 0.933628]\n",
      "epoch:37 step:29193[D loss: 0.412302, acc: 57.03%, op_acc: 42.97%] [G loss: 0.895453]\n",
      "epoch:37 step:29194[D loss: 0.401612, acc: 62.50%, op_acc: 39.06%] [G loss: 0.888591]\n",
      "epoch:37 step:29195[D loss: 0.439965, acc: 49.22%, op_acc: 42.19%] [G loss: 0.908702]\n",
      "epoch:37 step:29196[D loss: 0.437435, acc: 56.25%, op_acc: 39.84%] [G loss: 0.927298]\n",
      "epoch:37 step:29197[D loss: 0.425292, acc: 58.59%, op_acc: 35.94%] [G loss: 0.883374]\n",
      "epoch:37 step:29198[D loss: 0.432273, acc: 57.81%, op_acc: 38.28%] [G loss: 0.902602]\n",
      "epoch:37 step:29199[D loss: 0.395117, acc: 64.06%, op_acc: 44.53%] [G loss: 0.871417]\n",
      "epoch:37 step:29200[D loss: 0.407828, acc: 60.94%, op_acc: 36.72%] [G loss: 0.929467]\n",
      "##############\n",
      "[0.86694636 0.85591225 0.82142182 0.81744285 0.80057567 0.83295698\n",
      " 0.89552993 0.80152223 0.80412116 0.83235033]\n",
      "##########\n",
      "epoch:37 step:29201[D loss: 0.436355, acc: 54.69%, op_acc: 39.84%] [G loss: 0.888906]\n",
      "epoch:37 step:29202[D loss: 0.409844, acc: 60.94%, op_acc: 39.84%] [G loss: 0.893516]\n",
      "epoch:37 step:29203[D loss: 0.419081, acc: 59.38%, op_acc: 38.28%] [G loss: 0.911967]\n",
      "epoch:37 step:29204[D loss: 0.419535, acc: 61.72%, op_acc: 40.62%] [G loss: 0.922679]\n",
      "epoch:37 step:29205[D loss: 0.395811, acc: 58.59%, op_acc: 43.75%] [G loss: 0.929499]\n",
      "epoch:37 step:29206[D loss: 0.441164, acc: 59.38%, op_acc: 35.94%] [G loss: 0.856413]\n",
      "epoch:37 step:29207[D loss: 0.377721, acc: 71.88%, op_acc: 42.97%] [G loss: 0.847527]\n",
      "epoch:37 step:29208[D loss: 0.423700, acc: 55.47%, op_acc: 42.19%] [G loss: 0.820220]\n",
      "epoch:37 step:29209[D loss: 0.429024, acc: 61.72%, op_acc: 35.16%] [G loss: 0.850216]\n",
      "epoch:37 step:29210[D loss: 0.437064, acc: 52.34%, op_acc: 42.97%] [G loss: 0.880290]\n",
      "epoch:37 step:29211[D loss: 0.431766, acc: 58.59%, op_acc: 36.72%] [G loss: 0.907622]\n",
      "epoch:37 step:29212[D loss: 0.429398, acc: 59.38%, op_acc: 39.06%] [G loss: 0.865715]\n",
      "epoch:37 step:29213[D loss: 0.425785, acc: 54.69%, op_acc: 35.94%] [G loss: 0.876404]\n",
      "epoch:37 step:29214[D loss: 0.381828, acc: 71.88%, op_acc: 47.66%] [G loss: 0.909484]\n",
      "epoch:37 step:29215[D loss: 0.428878, acc: 59.38%, op_acc: 43.75%] [G loss: 0.913585]\n",
      "epoch:37 step:29216[D loss: 0.398598, acc: 63.28%, op_acc: 40.62%] [G loss: 0.887061]\n",
      "epoch:37 step:29217[D loss: 0.410527, acc: 63.28%, op_acc: 41.41%] [G loss: 0.893748]\n",
      "epoch:37 step:29218[D loss: 0.441071, acc: 58.59%, op_acc: 37.50%] [G loss: 0.893508]\n",
      "epoch:37 step:29219[D loss: 0.418405, acc: 62.50%, op_acc: 36.72%] [G loss: 0.888204]\n",
      "epoch:37 step:29220[D loss: 0.429653, acc: 53.12%, op_acc: 40.62%] [G loss: 0.915363]\n",
      "epoch:37 step:29221[D loss: 0.417721, acc: 62.50%, op_acc: 40.62%] [G loss: 0.899263]\n",
      "epoch:37 step:29222[D loss: 0.408458, acc: 59.38%, op_acc: 40.62%] [G loss: 0.886093]\n",
      "epoch:37 step:29223[D loss: 0.402825, acc: 61.72%, op_acc: 42.97%] [G loss: 0.907821]\n",
      "epoch:37 step:29224[D loss: 0.393367, acc: 67.97%, op_acc: 37.50%] [G loss: 0.852690]\n",
      "epoch:37 step:29225[D loss: 0.457228, acc: 56.25%, op_acc: 38.28%] [G loss: 0.881227]\n",
      "epoch:37 step:29226[D loss: 0.400155, acc: 61.72%, op_acc: 41.41%] [G loss: 0.851884]\n",
      "epoch:37 step:29227[D loss: 0.403833, acc: 66.41%, op_acc: 43.75%] [G loss: 0.846809]\n",
      "epoch:37 step:29228[D loss: 0.442397, acc: 53.12%, op_acc: 43.75%] [G loss: 0.871908]\n",
      "epoch:37 step:29229[D loss: 0.407564, acc: 56.25%, op_acc: 45.31%] [G loss: 0.896391]\n",
      "epoch:37 step:29230[D loss: 0.419256, acc: 60.16%, op_acc: 42.19%] [G loss: 0.896223]\n",
      "epoch:37 step:29231[D loss: 0.443124, acc: 55.47%, op_acc: 42.97%] [G loss: 0.814267]\n",
      "epoch:37 step:29232[D loss: 0.443029, acc: 60.16%, op_acc: 35.94%] [G loss: 0.886812]\n",
      "epoch:37 step:29233[D loss: 0.412226, acc: 60.94%, op_acc: 41.41%] [G loss: 0.908989]\n",
      "epoch:37 step:29234[D loss: 0.420263, acc: 62.50%, op_acc: 42.19%] [G loss: 0.801872]\n",
      "epoch:37 step:29235[D loss: 0.380060, acc: 68.75%, op_acc: 45.31%] [G loss: 0.886426]\n",
      "epoch:37 step:29236[D loss: 0.425717, acc: 59.38%, op_acc: 37.50%] [G loss: 0.933985]\n",
      "epoch:37 step:29237[D loss: 0.414971, acc: 60.94%, op_acc: 39.84%] [G loss: 0.908921]\n",
      "epoch:37 step:29238[D loss: 0.405877, acc: 61.72%, op_acc: 45.31%] [G loss: 0.912075]\n",
      "epoch:37 step:29239[D loss: 0.426430, acc: 60.94%, op_acc: 40.62%] [G loss: 0.808576]\n",
      "epoch:37 step:29240[D loss: 0.441635, acc: 54.69%, op_acc: 35.16%] [G loss: 0.890280]\n",
      "epoch:37 step:29241[D loss: 0.411431, acc: 53.91%, op_acc: 45.31%] [G loss: 0.862470]\n",
      "epoch:37 step:29242[D loss: 0.414317, acc: 61.72%, op_acc: 40.62%] [G loss: 0.911543]\n",
      "epoch:37 step:29243[D loss: 0.431923, acc: 53.12%, op_acc: 35.16%] [G loss: 0.867237]\n",
      "epoch:37 step:29244[D loss: 0.405195, acc: 61.72%, op_acc: 43.75%] [G loss: 0.925107]\n",
      "epoch:37 step:29245[D loss: 0.408062, acc: 62.50%, op_acc: 38.28%] [G loss: 0.952838]\n",
      "epoch:37 step:29246[D loss: 0.393267, acc: 62.50%, op_acc: 43.75%] [G loss: 0.889211]\n",
      "epoch:37 step:29247[D loss: 0.412658, acc: 57.03%, op_acc: 42.97%] [G loss: 0.860371]\n",
      "epoch:37 step:29248[D loss: 0.419160, acc: 57.03%, op_acc: 39.06%] [G loss: 0.934935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29249[D loss: 0.437291, acc: 59.38%, op_acc: 35.94%] [G loss: 0.899672]\n",
      "epoch:37 step:29250[D loss: 0.392482, acc: 64.06%, op_acc: 42.97%] [G loss: 0.926466]\n",
      "##############\n",
      "[0.86457308 0.85727993 0.82850066 0.81139005 0.81393856 0.83260442\n",
      " 0.89689767 0.81497103 0.80313729 0.82640179]\n",
      "##########\n",
      "epoch:37 step:29251[D loss: 0.406897, acc: 58.59%, op_acc: 41.41%] [G loss: 0.851524]\n",
      "epoch:37 step:29252[D loss: 0.418136, acc: 62.50%, op_acc: 39.06%] [G loss: 0.861793]\n",
      "epoch:37 step:29253[D loss: 0.431253, acc: 60.16%, op_acc: 42.19%] [G loss: 0.925583]\n",
      "epoch:37 step:29254[D loss: 0.415065, acc: 64.84%, op_acc: 39.84%] [G loss: 0.900250]\n",
      "epoch:37 step:29255[D loss: 0.437936, acc: 60.94%, op_acc: 41.41%] [G loss: 0.844262]\n",
      "epoch:37 step:29256[D loss: 0.416918, acc: 59.38%, op_acc: 39.06%] [G loss: 0.914983]\n",
      "epoch:37 step:29257[D loss: 0.429422, acc: 55.47%, op_acc: 38.28%] [G loss: 0.799599]\n",
      "epoch:37 step:29258[D loss: 0.394392, acc: 66.41%, op_acc: 43.75%] [G loss: 0.826297]\n",
      "epoch:37 step:29259[D loss: 0.389608, acc: 68.75%, op_acc: 39.06%] [G loss: 0.863752]\n",
      "epoch:37 step:29260[D loss: 0.409578, acc: 60.94%, op_acc: 39.06%] [G loss: 0.940252]\n",
      "epoch:37 step:29261[D loss: 0.404710, acc: 57.03%, op_acc: 46.88%] [G loss: 0.957746]\n",
      "epoch:37 step:29262[D loss: 0.381489, acc: 62.50%, op_acc: 46.88%] [G loss: 0.891086]\n",
      "epoch:37 step:29263[D loss: 0.391920, acc: 65.62%, op_acc: 44.53%] [G loss: 0.921920]\n",
      "epoch:37 step:29264[D loss: 0.426100, acc: 57.81%, op_acc: 34.38%] [G loss: 0.859450]\n",
      "epoch:37 step:29265[D loss: 0.405726, acc: 64.84%, op_acc: 39.06%] [G loss: 0.902594]\n",
      "epoch:37 step:29266[D loss: 0.422823, acc: 55.47%, op_acc: 37.50%] [G loss: 0.805981]\n",
      "epoch:37 step:29267[D loss: 0.424330, acc: 63.28%, op_acc: 38.28%] [G loss: 0.901966]\n",
      "epoch:37 step:29268[D loss: 0.379608, acc: 62.50%, op_acc: 45.31%] [G loss: 0.849723]\n",
      "epoch:37 step:29269[D loss: 0.407373, acc: 61.72%, op_acc: 44.53%] [G loss: 0.818800]\n",
      "epoch:37 step:29270[D loss: 0.373007, acc: 70.31%, op_acc: 46.09%] [G loss: 0.928751]\n",
      "epoch:37 step:29271[D loss: 0.388708, acc: 64.06%, op_acc: 43.75%] [G loss: 0.861568]\n",
      "epoch:37 step:29272[D loss: 0.412630, acc: 53.12%, op_acc: 41.41%] [G loss: 0.902725]\n",
      "epoch:37 step:29273[D loss: 0.407046, acc: 65.62%, op_acc: 37.50%] [G loss: 0.909549]\n",
      "epoch:37 step:29274[D loss: 0.425395, acc: 54.69%, op_acc: 41.41%] [G loss: 0.870540]\n",
      "epoch:37 step:29275[D loss: 0.446289, acc: 53.12%, op_acc: 38.28%] [G loss: 0.903023]\n",
      "epoch:37 step:29276[D loss: 0.381315, acc: 70.31%, op_acc: 39.84%] [G loss: 0.918493]\n",
      "epoch:37 step:29277[D loss: 0.417176, acc: 62.50%, op_acc: 39.84%] [G loss: 0.877867]\n",
      "epoch:37 step:29278[D loss: 0.423894, acc: 64.06%, op_acc: 37.50%] [G loss: 0.916388]\n",
      "epoch:37 step:29279[D loss: 0.432087, acc: 60.94%, op_acc: 42.97%] [G loss: 0.996820]\n",
      "epoch:37 step:29280[D loss: 0.397215, acc: 57.03%, op_acc: 47.66%] [G loss: 0.854313]\n",
      "epoch:37 step:29281[D loss: 0.417532, acc: 58.59%, op_acc: 42.19%] [G loss: 0.911387]\n",
      "epoch:37 step:29282[D loss: 0.382848, acc: 64.84%, op_acc: 48.44%] [G loss: 0.822772]\n",
      "epoch:37 step:29283[D loss: 0.416061, acc: 53.12%, op_acc: 39.84%] [G loss: 0.857875]\n",
      "epoch:37 step:29284[D loss: 0.460773, acc: 54.69%, op_acc: 35.16%] [G loss: 0.907002]\n",
      "epoch:37 step:29285[D loss: 0.440058, acc: 57.03%, op_acc: 39.84%] [G loss: 0.912995]\n",
      "epoch:37 step:29286[D loss: 0.418067, acc: 57.03%, op_acc: 43.75%] [G loss: 0.876620]\n",
      "epoch:37 step:29287[D loss: 0.425892, acc: 53.91%, op_acc: 50.00%] [G loss: 0.977165]\n",
      "epoch:37 step:29288[D loss: 0.425100, acc: 58.59%, op_acc: 42.19%] [G loss: 0.916348]\n",
      "epoch:37 step:29289[D loss: 0.395898, acc: 63.28%, op_acc: 39.84%] [G loss: 0.929002]\n",
      "epoch:37 step:29290[D loss: 0.421001, acc: 59.38%, op_acc: 41.41%] [G loss: 0.864531]\n",
      "epoch:37 step:29291[D loss: 0.405423, acc: 62.50%, op_acc: 44.53%] [G loss: 0.927957]\n",
      "epoch:37 step:29292[D loss: 0.447176, acc: 53.91%, op_acc: 35.94%] [G loss: 0.825615]\n",
      "epoch:37 step:29293[D loss: 0.413981, acc: 59.38%, op_acc: 41.41%] [G loss: 0.854018]\n",
      "epoch:37 step:29294[D loss: 0.432182, acc: 57.03%, op_acc: 39.84%] [G loss: 0.806975]\n",
      "epoch:37 step:29295[D loss: 0.433146, acc: 60.16%, op_acc: 44.53%] [G loss: 0.899873]\n",
      "epoch:37 step:29296[D loss: 0.426741, acc: 56.25%, op_acc: 38.28%] [G loss: 0.861616]\n",
      "epoch:37 step:29297[D loss: 0.398672, acc: 60.16%, op_acc: 43.75%] [G loss: 0.856932]\n",
      "epoch:37 step:29298[D loss: 0.422054, acc: 59.38%, op_acc: 43.75%] [G loss: 0.875271]\n",
      "epoch:37 step:29299[D loss: 0.432230, acc: 60.16%, op_acc: 37.50%] [G loss: 0.872292]\n",
      "epoch:37 step:29300[D loss: 0.386797, acc: 68.75%, op_acc: 39.06%] [G loss: 0.893663]\n",
      "##############\n",
      "[0.84170748 0.85068557 0.80358866 0.81327931 0.80019663 0.84935028\n",
      " 0.89588322 0.83813182 0.79634462 0.81524428]\n",
      "##########\n",
      "epoch:37 step:29301[D loss: 0.371225, acc: 71.88%, op_acc: 44.53%] [G loss: 0.945054]\n",
      "epoch:37 step:29302[D loss: 0.419941, acc: 59.38%, op_acc: 42.19%] [G loss: 0.928898]\n",
      "epoch:37 step:29303[D loss: 0.432826, acc: 52.34%, op_acc: 39.84%] [G loss: 0.893076]\n",
      "epoch:37 step:29304[D loss: 0.412037, acc: 62.50%, op_acc: 37.50%] [G loss: 0.987374]\n",
      "epoch:37 step:29305[D loss: 0.402837, acc: 57.81%, op_acc: 43.75%] [G loss: 0.832208]\n",
      "epoch:37 step:29306[D loss: 0.390486, acc: 67.19%, op_acc: 47.66%] [G loss: 0.786795]\n",
      "epoch:37 step:29307[D loss: 0.416286, acc: 56.25%, op_acc: 41.41%] [G loss: 0.897274]\n",
      "epoch:37 step:29308[D loss: 0.437236, acc: 56.25%, op_acc: 38.28%] [G loss: 0.883726]\n",
      "epoch:37 step:29309[D loss: 0.441211, acc: 52.34%, op_acc: 41.41%] [G loss: 0.899180]\n",
      "epoch:37 step:29310[D loss: 0.400277, acc: 67.19%, op_acc: 37.50%] [G loss: 0.832679]\n",
      "epoch:37 step:29311[D loss: 0.413783, acc: 54.69%, op_acc: 46.09%] [G loss: 0.857497]\n",
      "epoch:37 step:29312[D loss: 0.433045, acc: 60.16%, op_acc: 40.62%] [G loss: 0.872547]\n",
      "epoch:37 step:29313[D loss: 0.400496, acc: 61.72%, op_acc: 42.97%] [G loss: 0.824766]\n",
      "epoch:37 step:29314[D loss: 0.414187, acc: 61.72%, op_acc: 39.84%] [G loss: 0.800457]\n",
      "epoch:37 step:29315[D loss: 0.418032, acc: 57.03%, op_acc: 39.84%] [G loss: 0.885672]\n",
      "epoch:37 step:29316[D loss: 0.422231, acc: 53.12%, op_acc: 41.41%] [G loss: 0.846132]\n",
      "epoch:37 step:29317[D loss: 0.400058, acc: 64.84%, op_acc: 41.41%] [G loss: 0.880578]\n",
      "epoch:37 step:29318[D loss: 0.417214, acc: 61.72%, op_acc: 40.62%] [G loss: 0.853644]\n",
      "epoch:37 step:29319[D loss: 0.410944, acc: 57.03%, op_acc: 42.19%] [G loss: 0.940331]\n",
      "epoch:37 step:29320[D loss: 0.459020, acc: 53.91%, op_acc: 36.72%] [G loss: 0.868743]\n",
      "epoch:37 step:29321[D loss: 0.454834, acc: 55.47%, op_acc: 35.16%] [G loss: 0.843186]\n",
      "epoch:37 step:29322[D loss: 0.444037, acc: 52.34%, op_acc: 37.50%] [G loss: 0.886345]\n",
      "epoch:37 step:29323[D loss: 0.459118, acc: 52.34%, op_acc: 35.94%] [G loss: 0.955549]\n",
      "epoch:37 step:29324[D loss: 0.397424, acc: 64.84%, op_acc: 40.62%] [G loss: 0.951141]\n",
      "epoch:37 step:29325[D loss: 0.422042, acc: 53.12%, op_acc: 43.75%] [G loss: 0.923637]\n",
      "epoch:37 step:29326[D loss: 0.404170, acc: 65.62%, op_acc: 42.97%] [G loss: 0.871018]\n",
      "epoch:37 step:29327[D loss: 0.427237, acc: 54.69%, op_acc: 45.31%] [G loss: 0.898205]\n",
      "epoch:37 step:29328[D loss: 0.406712, acc: 66.41%, op_acc: 42.97%] [G loss: 0.870882]\n",
      "epoch:37 step:29329[D loss: 0.396468, acc: 54.69%, op_acc: 43.75%] [G loss: 0.918652]\n",
      "epoch:37 step:29330[D loss: 0.405746, acc: 58.59%, op_acc: 44.53%] [G loss: 0.842998]\n",
      "epoch:37 step:29331[D loss: 0.400076, acc: 60.16%, op_acc: 43.75%] [G loss: 0.958469]\n",
      "epoch:37 step:29332[D loss: 0.428506, acc: 57.03%, op_acc: 42.97%] [G loss: 0.867456]\n",
      "epoch:37 step:29333[D loss: 0.456506, acc: 53.91%, op_acc: 36.72%] [G loss: 1.020135]\n",
      "epoch:37 step:29334[D loss: 0.405667, acc: 63.28%, op_acc: 46.09%] [G loss: 0.829467]\n",
      "epoch:37 step:29335[D loss: 0.415478, acc: 66.41%, op_acc: 39.84%] [G loss: 0.875103]\n",
      "epoch:37 step:29336[D loss: 0.397822, acc: 61.72%, op_acc: 50.00%] [G loss: 0.931563]\n",
      "epoch:37 step:29337[D loss: 0.420944, acc: 56.25%, op_acc: 42.19%] [G loss: 0.893543]\n",
      "epoch:37 step:29338[D loss: 0.392226, acc: 60.94%, op_acc: 43.75%] [G loss: 0.868198]\n",
      "epoch:37 step:29339[D loss: 0.414153, acc: 64.84%, op_acc: 42.97%] [G loss: 0.895054]\n",
      "epoch:37 step:29340[D loss: 0.421724, acc: 60.94%, op_acc: 38.28%] [G loss: 0.830920]\n",
      "epoch:37 step:29341[D loss: 0.401494, acc: 64.06%, op_acc: 43.75%] [G loss: 0.905203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29342[D loss: 0.420587, acc: 60.94%, op_acc: 42.97%] [G loss: 0.854654]\n",
      "epoch:37 step:29343[D loss: 0.427397, acc: 53.91%, op_acc: 43.75%] [G loss: 0.899426]\n",
      "epoch:37 step:29344[D loss: 0.445044, acc: 57.03%, op_acc: 36.72%] [G loss: 0.903234]\n",
      "epoch:37 step:29345[D loss: 0.410175, acc: 65.62%, op_acc: 44.53%] [G loss: 0.779921]\n",
      "epoch:37 step:29346[D loss: 0.414400, acc: 57.81%, op_acc: 36.72%] [G loss: 0.848095]\n",
      "epoch:37 step:29347[D loss: 0.406781, acc: 60.16%, op_acc: 45.31%] [G loss: 0.827901]\n",
      "epoch:37 step:29348[D loss: 0.410659, acc: 57.81%, op_acc: 39.84%] [G loss: 0.886081]\n",
      "epoch:37 step:29349[D loss: 0.424034, acc: 55.47%, op_acc: 41.41%] [G loss: 0.839955]\n",
      "epoch:37 step:29350[D loss: 0.398528, acc: 54.69%, op_acc: 42.97%] [G loss: 0.902349]\n",
      "##############\n",
      "[0.85245657 0.85809604 0.81138303 0.82163516 0.78806702 0.82007991\n",
      " 0.87346844 0.82905732 0.82249283 0.82969078]\n",
      "##########\n",
      "epoch:37 step:29351[D loss: 0.430802, acc: 62.50%, op_acc: 36.72%] [G loss: 0.873438]\n",
      "epoch:37 step:29352[D loss: 0.414046, acc: 59.38%, op_acc: 42.19%] [G loss: 0.890171]\n",
      "epoch:37 step:29353[D loss: 0.396270, acc: 59.38%, op_acc: 39.84%] [G loss: 0.952461]\n",
      "epoch:37 step:29354[D loss: 0.431523, acc: 59.38%, op_acc: 39.06%] [G loss: 0.909069]\n",
      "epoch:37 step:29355[D loss: 0.406497, acc: 60.16%, op_acc: 42.97%] [G loss: 0.827359]\n",
      "epoch:37 step:29356[D loss: 0.441028, acc: 53.12%, op_acc: 41.41%] [G loss: 0.876575]\n",
      "epoch:37 step:29357[D loss: 0.403558, acc: 57.81%, op_acc: 44.53%] [G loss: 0.898959]\n",
      "epoch:37 step:29358[D loss: 0.429640, acc: 49.22%, op_acc: 41.41%] [G loss: 0.892963]\n",
      "epoch:37 step:29359[D loss: 0.396130, acc: 69.53%, op_acc: 40.62%] [G loss: 0.905586]\n",
      "epoch:37 step:29360[D loss: 0.434242, acc: 50.00%, op_acc: 38.28%] [G loss: 0.851322]\n",
      "epoch:37 step:29361[D loss: 0.428554, acc: 61.72%, op_acc: 42.19%] [G loss: 0.869913]\n",
      "epoch:37 step:29362[D loss: 0.418508, acc: 57.03%, op_acc: 45.31%] [G loss: 0.907133]\n",
      "epoch:37 step:29363[D loss: 0.392657, acc: 62.50%, op_acc: 40.62%] [G loss: 0.864275]\n",
      "epoch:37 step:29364[D loss: 0.448666, acc: 55.47%, op_acc: 35.16%] [G loss: 0.833314]\n",
      "epoch:37 step:29365[D loss: 0.409067, acc: 55.47%, op_acc: 47.66%] [G loss: 0.882018]\n",
      "epoch:37 step:29366[D loss: 0.405106, acc: 66.41%, op_acc: 43.75%] [G loss: 0.877986]\n",
      "epoch:37 step:29367[D loss: 0.398345, acc: 64.84%, op_acc: 44.53%] [G loss: 0.932246]\n",
      "epoch:37 step:29368[D loss: 0.406564, acc: 61.72%, op_acc: 40.62%] [G loss: 0.807805]\n",
      "epoch:37 step:29369[D loss: 0.412333, acc: 58.59%, op_acc: 42.97%] [G loss: 0.920832]\n",
      "epoch:37 step:29370[D loss: 0.417700, acc: 52.34%, op_acc: 45.31%] [G loss: 0.870017]\n",
      "epoch:37 step:29371[D loss: 0.404732, acc: 60.94%, op_acc: 45.31%] [G loss: 0.907107]\n",
      "epoch:37 step:29372[D loss: 0.415305, acc: 56.25%, op_acc: 44.53%] [G loss: 0.893307]\n",
      "epoch:37 step:29373[D loss: 0.396466, acc: 66.41%, op_acc: 44.53%] [G loss: 0.841168]\n",
      "epoch:37 step:29374[D loss: 0.421775, acc: 61.72%, op_acc: 38.28%] [G loss: 0.891052]\n",
      "epoch:37 step:29375[D loss: 0.390444, acc: 61.72%, op_acc: 44.53%] [G loss: 0.925676]\n",
      "epoch:37 step:29376[D loss: 0.415666, acc: 60.94%, op_acc: 42.19%] [G loss: 0.814285]\n",
      "epoch:37 step:29377[D loss: 0.422807, acc: 60.94%, op_acc: 37.50%] [G loss: 0.898674]\n",
      "epoch:37 step:29378[D loss: 0.463246, acc: 57.81%, op_acc: 39.06%] [G loss: 0.868967]\n",
      "epoch:37 step:29379[D loss: 0.402157, acc: 63.28%, op_acc: 48.44%] [G loss: 0.928420]\n",
      "epoch:37 step:29380[D loss: 0.430509, acc: 50.78%, op_acc: 42.19%] [G loss: 0.866890]\n",
      "epoch:37 step:29381[D loss: 0.407867, acc: 59.38%, op_acc: 41.41%] [G loss: 0.872196]\n",
      "epoch:37 step:29382[D loss: 0.421852, acc: 57.81%, op_acc: 33.59%] [G loss: 0.887968]\n",
      "epoch:37 step:29383[D loss: 0.434695, acc: 53.12%, op_acc: 39.84%] [G loss: 0.890718]\n",
      "epoch:37 step:29384[D loss: 0.446452, acc: 52.34%, op_acc: 40.62%] [G loss: 0.889019]\n",
      "epoch:37 step:29385[D loss: 0.391746, acc: 67.19%, op_acc: 41.41%] [G loss: 0.912369]\n",
      "epoch:37 step:29386[D loss: 0.419756, acc: 54.69%, op_acc: 42.19%] [G loss: 0.866323]\n",
      "epoch:37 step:29387[D loss: 0.411608, acc: 61.72%, op_acc: 41.41%] [G loss: 0.843588]\n",
      "epoch:37 step:29388[D loss: 0.446846, acc: 59.38%, op_acc: 34.38%] [G loss: 0.858071]\n",
      "epoch:37 step:29389[D loss: 0.426622, acc: 58.59%, op_acc: 38.28%] [G loss: 0.882922]\n",
      "epoch:37 step:29390[D loss: 0.409862, acc: 60.94%, op_acc: 38.28%] [G loss: 0.899501]\n",
      "epoch:37 step:29391[D loss: 0.396701, acc: 64.84%, op_acc: 45.31%] [G loss: 0.898141]\n",
      "epoch:37 step:29392[D loss: 0.401088, acc: 67.19%, op_acc: 35.16%] [G loss: 0.857567]\n",
      "epoch:37 step:29393[D loss: 0.411697, acc: 64.84%, op_acc: 38.28%] [G loss: 0.966194]\n",
      "epoch:37 step:29394[D loss: 0.420429, acc: 57.81%, op_acc: 38.28%] [G loss: 0.839172]\n",
      "epoch:37 step:29395[D loss: 0.442546, acc: 59.38%, op_acc: 44.53%] [G loss: 0.847726]\n",
      "epoch:37 step:29396[D loss: 0.444125, acc: 53.91%, op_acc: 37.50%] [G loss: 0.880125]\n",
      "epoch:37 step:29397[D loss: 0.446825, acc: 49.22%, op_acc: 35.94%] [G loss: 0.883730]\n",
      "epoch:37 step:29398[D loss: 0.410184, acc: 63.28%, op_acc: 39.06%] [G loss: 0.895733]\n",
      "epoch:37 step:29399[D loss: 0.410949, acc: 55.47%, op_acc: 45.31%] [G loss: 0.921668]\n",
      "epoch:37 step:29400[D loss: 0.392123, acc: 59.38%, op_acc: 43.75%] [G loss: 0.962282]\n",
      "##############\n",
      "[0.86281387 0.85198679 0.80489585 0.80453364 0.80553296 0.85390027\n",
      " 0.86112088 0.83746548 0.79776177 0.83839473]\n",
      "##########\n",
      "epoch:37 step:29401[D loss: 0.471286, acc: 50.00%, op_acc: 38.28%] [G loss: 0.852833]\n",
      "epoch:37 step:29402[D loss: 0.425975, acc: 61.72%, op_acc: 38.28%] [G loss: 0.966606]\n",
      "epoch:37 step:29403[D loss: 0.427333, acc: 53.91%, op_acc: 43.75%] [G loss: 0.917640]\n",
      "epoch:37 step:29404[D loss: 0.405221, acc: 65.62%, op_acc: 42.19%] [G loss: 0.907770]\n",
      "epoch:37 step:29405[D loss: 0.417068, acc: 60.16%, op_acc: 37.50%] [G loss: 0.890221]\n",
      "epoch:37 step:29406[D loss: 0.448548, acc: 51.56%, op_acc: 39.06%] [G loss: 0.837201]\n",
      "epoch:37 step:29407[D loss: 0.457291, acc: 53.91%, op_acc: 37.50%] [G loss: 0.901390]\n",
      "epoch:37 step:29408[D loss: 0.449955, acc: 50.00%, op_acc: 40.62%] [G loss: 0.835946]\n",
      "epoch:37 step:29409[D loss: 0.428075, acc: 60.16%, op_acc: 42.19%] [G loss: 0.856011]\n",
      "epoch:37 step:29410[D loss: 0.457557, acc: 53.12%, op_acc: 32.81%] [G loss: 0.815563]\n",
      "epoch:37 step:29411[D loss: 0.466511, acc: 47.66%, op_acc: 38.28%] [G loss: 0.828840]\n",
      "epoch:37 step:29412[D loss: 0.403233, acc: 59.38%, op_acc: 37.50%] [G loss: 0.843905]\n",
      "epoch:37 step:29413[D loss: 0.404140, acc: 64.06%, op_acc: 39.06%] [G loss: 0.866973]\n",
      "epoch:37 step:29414[D loss: 0.458014, acc: 58.59%, op_acc: 38.28%] [G loss: 0.855596]\n",
      "epoch:37 step:29415[D loss: 0.398479, acc: 62.50%, op_acc: 42.97%] [G loss: 0.921652]\n",
      "epoch:37 step:29416[D loss: 0.429065, acc: 53.12%, op_acc: 35.16%] [G loss: 0.872359]\n",
      "epoch:37 step:29417[D loss: 0.424437, acc: 54.69%, op_acc: 43.75%] [G loss: 0.989102]\n",
      "epoch:37 step:29418[D loss: 0.411049, acc: 61.72%, op_acc: 41.41%] [G loss: 0.860090]\n",
      "epoch:37 step:29419[D loss: 0.447434, acc: 54.69%, op_acc: 38.28%] [G loss: 0.871368]\n",
      "epoch:37 step:29420[D loss: 0.424446, acc: 63.28%, op_acc: 38.28%] [G loss: 0.977267]\n",
      "epoch:37 step:29421[D loss: 0.419097, acc: 65.62%, op_acc: 35.16%] [G loss: 0.928295]\n",
      "epoch:37 step:29422[D loss: 0.421078, acc: 61.72%, op_acc: 35.94%] [G loss: 0.786490]\n",
      "epoch:37 step:29423[D loss: 0.425135, acc: 60.16%, op_acc: 38.28%] [G loss: 0.914350]\n",
      "epoch:37 step:29424[D loss: 0.423773, acc: 55.47%, op_acc: 41.41%] [G loss: 0.851794]\n",
      "epoch:37 step:29425[D loss: 0.430126, acc: 55.47%, op_acc: 39.84%] [G loss: 0.843499]\n",
      "epoch:37 step:29426[D loss: 0.395360, acc: 60.94%, op_acc: 41.41%] [G loss: 0.847091]\n",
      "epoch:37 step:29427[D loss: 0.437331, acc: 59.38%, op_acc: 37.50%] [G loss: 0.793798]\n",
      "epoch:37 step:29428[D loss: 0.420249, acc: 54.69%, op_acc: 42.19%] [G loss: 0.875133]\n",
      "epoch:37 step:29429[D loss: 0.431605, acc: 61.72%, op_acc: 41.41%] [G loss: 0.859207]\n",
      "epoch:37 step:29430[D loss: 0.403899, acc: 58.59%, op_acc: 42.19%] [G loss: 1.005069]\n",
      "epoch:37 step:29431[D loss: 0.387796, acc: 66.41%, op_acc: 48.44%] [G loss: 0.873992]\n",
      "epoch:37 step:29432[D loss: 0.400168, acc: 67.97%, op_acc: 39.84%] [G loss: 0.944199]\n",
      "epoch:37 step:29433[D loss: 0.391229, acc: 58.59%, op_acc: 42.97%] [G loss: 0.862337]\n",
      "epoch:37 step:29434[D loss: 0.452392, acc: 53.12%, op_acc: 35.94%] [G loss: 0.844123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29435[D loss: 0.439411, acc: 57.03%, op_acc: 43.75%] [G loss: 0.864377]\n",
      "epoch:37 step:29436[D loss: 0.439173, acc: 58.59%, op_acc: 36.72%] [G loss: 0.897816]\n",
      "epoch:37 step:29437[D loss: 0.448521, acc: 49.22%, op_acc: 40.62%] [G loss: 0.829861]\n",
      "epoch:37 step:29438[D loss: 0.410052, acc: 60.94%, op_acc: 39.06%] [G loss: 0.862576]\n",
      "epoch:37 step:29439[D loss: 0.438391, acc: 54.69%, op_acc: 42.97%] [G loss: 0.867744]\n",
      "epoch:37 step:29440[D loss: 0.421206, acc: 65.62%, op_acc: 36.72%] [G loss: 0.881100]\n",
      "epoch:37 step:29441[D loss: 0.407157, acc: 60.16%, op_acc: 38.28%] [G loss: 0.919441]\n",
      "epoch:37 step:29442[D loss: 0.393855, acc: 64.84%, op_acc: 39.84%] [G loss: 0.898350]\n",
      "epoch:37 step:29443[D loss: 0.412422, acc: 61.72%, op_acc: 39.06%] [G loss: 0.866856]\n",
      "epoch:37 step:29444[D loss: 0.412427, acc: 60.94%, op_acc: 41.41%] [G loss: 0.938049]\n",
      "epoch:37 step:29445[D loss: 0.429138, acc: 64.06%, op_acc: 40.62%] [G loss: 0.907348]\n",
      "epoch:37 step:29446[D loss: 0.459028, acc: 50.00%, op_acc: 40.62%] [G loss: 0.871905]\n",
      "epoch:37 step:29447[D loss: 0.406957, acc: 60.16%, op_acc: 47.66%] [G loss: 0.952054]\n",
      "epoch:37 step:29448[D loss: 0.409583, acc: 57.03%, op_acc: 42.97%] [G loss: 0.878663]\n",
      "epoch:37 step:29449[D loss: 0.446811, acc: 56.25%, op_acc: 34.38%] [G loss: 0.853599]\n",
      "epoch:37 step:29450[D loss: 0.395489, acc: 62.50%, op_acc: 44.53%] [G loss: 0.895538]\n",
      "##############\n",
      "[0.84686877 0.85145249 0.81566562 0.81119767 0.801346   0.82951204\n",
      " 0.89438274 0.81090738 0.79879492 0.82482601]\n",
      "##########\n",
      "epoch:37 step:29451[D loss: 0.404852, acc: 66.41%, op_acc: 36.72%] [G loss: 0.925663]\n",
      "epoch:37 step:29452[D loss: 0.399705, acc: 60.94%, op_acc: 42.19%] [G loss: 0.792360]\n",
      "epoch:37 step:29453[D loss: 0.411509, acc: 57.03%, op_acc: 43.75%] [G loss: 0.868642]\n",
      "epoch:37 step:29454[D loss: 0.433659, acc: 58.59%, op_acc: 35.16%] [G loss: 0.878219]\n",
      "epoch:37 step:29455[D loss: 0.412774, acc: 58.59%, op_acc: 47.66%] [G loss: 0.848289]\n",
      "epoch:37 step:29456[D loss: 0.396135, acc: 71.09%, op_acc: 39.84%] [G loss: 0.982723]\n",
      "epoch:37 step:29457[D loss: 0.452167, acc: 54.69%, op_acc: 37.50%] [G loss: 0.899730]\n",
      "epoch:37 step:29458[D loss: 0.435750, acc: 53.12%, op_acc: 41.41%] [G loss: 0.835543]\n",
      "epoch:37 step:29459[D loss: 0.436603, acc: 60.94%, op_acc: 36.72%] [G loss: 0.954923]\n",
      "epoch:37 step:29460[D loss: 0.431310, acc: 55.47%, op_acc: 35.94%] [G loss: 0.917752]\n",
      "epoch:37 step:29461[D loss: 0.415618, acc: 59.38%, op_acc: 40.62%] [G loss: 0.872596]\n",
      "epoch:37 step:29462[D loss: 0.406360, acc: 60.94%, op_acc: 42.19%] [G loss: 0.964760]\n",
      "epoch:37 step:29463[D loss: 0.400157, acc: 61.72%, op_acc: 42.97%] [G loss: 0.879366]\n",
      "epoch:37 step:29464[D loss: 0.388628, acc: 65.62%, op_acc: 43.75%] [G loss: 0.950127]\n",
      "epoch:37 step:29465[D loss: 0.408849, acc: 62.50%, op_acc: 40.62%] [G loss: 0.916662]\n",
      "epoch:37 step:29466[D loss: 0.372573, acc: 67.97%, op_acc: 42.97%] [G loss: 0.986783]\n",
      "epoch:37 step:29467[D loss: 0.405268, acc: 63.28%, op_acc: 41.41%] [G loss: 0.976932]\n",
      "epoch:37 step:29468[D loss: 0.424270, acc: 60.16%, op_acc: 40.62%] [G loss: 0.815034]\n",
      "epoch:37 step:29469[D loss: 0.419802, acc: 60.94%, op_acc: 37.50%] [G loss: 0.824695]\n",
      "epoch:37 step:29470[D loss: 0.405578, acc: 50.78%, op_acc: 44.53%] [G loss: 0.866796]\n",
      "epoch:37 step:29471[D loss: 0.430074, acc: 60.16%, op_acc: 39.06%] [G loss: 0.848260]\n",
      "epoch:37 step:29472[D loss: 0.416095, acc: 60.94%, op_acc: 43.75%] [G loss: 0.784423]\n",
      "epoch:37 step:29473[D loss: 0.405148, acc: 64.84%, op_acc: 44.53%] [G loss: 0.865443]\n",
      "epoch:37 step:29474[D loss: 0.416770, acc: 70.31%, op_acc: 38.28%] [G loss: 0.816434]\n",
      "epoch:37 step:29475[D loss: 0.472820, acc: 48.44%, op_acc: 36.72%] [G loss: 0.887394]\n",
      "epoch:37 step:29476[D loss: 0.409104, acc: 64.06%, op_acc: 38.28%] [G loss: 0.926235]\n",
      "epoch:37 step:29477[D loss: 0.403543, acc: 58.59%, op_acc: 40.62%] [G loss: 0.864962]\n",
      "epoch:37 step:29478[D loss: 0.442065, acc: 57.81%, op_acc: 39.06%] [G loss: 0.873823]\n",
      "epoch:37 step:29479[D loss: 0.442285, acc: 56.25%, op_acc: 36.72%] [G loss: 0.896686]\n",
      "epoch:37 step:29480[D loss: 0.412447, acc: 58.59%, op_acc: 41.41%] [G loss: 0.823007]\n",
      "epoch:37 step:29481[D loss: 0.452337, acc: 57.03%, op_acc: 41.41%] [G loss: 0.927174]\n",
      "epoch:37 step:29482[D loss: 0.419306, acc: 68.75%, op_acc: 40.62%] [G loss: 0.799174]\n",
      "epoch:37 step:29483[D loss: 0.449901, acc: 56.25%, op_acc: 37.50%] [G loss: 0.816110]\n",
      "epoch:37 step:29484[D loss: 0.379257, acc: 70.31%, op_acc: 44.53%] [G loss: 0.818766]\n",
      "epoch:37 step:29485[D loss: 0.429946, acc: 56.25%, op_acc: 40.62%] [G loss: 0.872900]\n",
      "epoch:37 step:29486[D loss: 0.408920, acc: 58.59%, op_acc: 41.41%] [G loss: 0.851835]\n",
      "epoch:37 step:29487[D loss: 0.412580, acc: 56.25%, op_acc: 46.09%] [G loss: 0.836672]\n",
      "epoch:37 step:29488[D loss: 0.446169, acc: 53.91%, op_acc: 35.16%] [G loss: 0.816433]\n",
      "epoch:37 step:29489[D loss: 0.431389, acc: 53.12%, op_acc: 42.19%] [G loss: 0.893382]\n",
      "epoch:37 step:29490[D loss: 0.439046, acc: 58.59%, op_acc: 35.16%] [G loss: 0.874350]\n",
      "epoch:37 step:29491[D loss: 0.418039, acc: 60.16%, op_acc: 36.72%] [G loss: 0.861245]\n",
      "epoch:37 step:29492[D loss: 0.427969, acc: 60.16%, op_acc: 35.16%] [G loss: 0.861184]\n",
      "epoch:37 step:29493[D loss: 0.411038, acc: 60.94%, op_acc: 38.28%] [G loss: 0.831828]\n",
      "epoch:37 step:29494[D loss: 0.405755, acc: 64.06%, op_acc: 42.19%] [G loss: 0.894510]\n",
      "epoch:37 step:29495[D loss: 0.422651, acc: 58.59%, op_acc: 43.75%] [G loss: 0.814532]\n",
      "epoch:37 step:29496[D loss: 0.423919, acc: 65.62%, op_acc: 38.28%] [G loss: 0.855360]\n",
      "epoch:37 step:29497[D loss: 0.430099, acc: 59.38%, op_acc: 42.19%] [G loss: 0.860241]\n",
      "epoch:37 step:29498[D loss: 0.422477, acc: 57.03%, op_acc: 41.41%] [G loss: 0.848958]\n",
      "epoch:37 step:29499[D loss: 0.419698, acc: 58.59%, op_acc: 43.75%] [G loss: 0.843207]\n",
      "epoch:37 step:29500[D loss: 0.405907, acc: 54.69%, op_acc: 45.31%] [G loss: 0.836753]\n",
      "##############\n",
      "[0.8656037  0.85699848 0.84143223 0.82214796 0.80805007 0.82849441\n",
      " 0.90026958 0.80710182 0.80797969 0.80375488]\n",
      "##########\n",
      "epoch:37 step:29501[D loss: 0.472224, acc: 50.78%, op_acc: 37.50%] [G loss: 0.872569]\n",
      "epoch:37 step:29502[D loss: 0.412635, acc: 60.16%, op_acc: 40.62%] [G loss: 0.839637]\n",
      "epoch:37 step:29503[D loss: 0.410734, acc: 62.50%, op_acc: 47.66%] [G loss: 0.876752]\n",
      "epoch:37 step:29504[D loss: 0.388631, acc: 61.72%, op_acc: 50.00%] [G loss: 0.983491]\n",
      "epoch:37 step:29505[D loss: 0.393339, acc: 64.84%, op_acc: 50.00%] [G loss: 0.927423]\n",
      "epoch:37 step:29506[D loss: 0.407426, acc: 61.72%, op_acc: 42.19%] [G loss: 0.947962]\n",
      "epoch:37 step:29507[D loss: 0.402224, acc: 63.28%, op_acc: 46.88%] [G loss: 0.891590]\n",
      "epoch:37 step:29508[D loss: 0.429853, acc: 59.38%, op_acc: 40.62%] [G loss: 0.854324]\n",
      "epoch:37 step:29509[D loss: 0.442859, acc: 46.88%, op_acc: 39.06%] [G loss: 0.868351]\n",
      "epoch:37 step:29510[D loss: 0.437565, acc: 52.34%, op_acc: 42.19%] [G loss: 0.898605]\n",
      "epoch:37 step:29511[D loss: 0.403630, acc: 57.81%, op_acc: 39.84%] [G loss: 0.934299]\n",
      "epoch:37 step:29512[D loss: 0.417850, acc: 57.81%, op_acc: 41.41%] [G loss: 0.940775]\n",
      "epoch:37 step:29513[D loss: 0.401603, acc: 68.75%, op_acc: 46.88%] [G loss: 0.897715]\n",
      "epoch:37 step:29514[D loss: 0.420998, acc: 60.16%, op_acc: 35.16%] [G loss: 0.873269]\n",
      "epoch:37 step:29515[D loss: 0.391939, acc: 64.06%, op_acc: 43.75%] [G loss: 0.909267]\n",
      "epoch:37 step:29516[D loss: 0.453997, acc: 57.03%, op_acc: 42.19%] [G loss: 0.929700]\n",
      "epoch:37 step:29517[D loss: 0.393009, acc: 70.31%, op_acc: 34.38%] [G loss: 0.940320]\n",
      "epoch:37 step:29518[D loss: 0.391168, acc: 67.97%, op_acc: 42.19%] [G loss: 0.936774]\n",
      "epoch:37 step:29519[D loss: 0.446364, acc: 60.16%, op_acc: 36.72%] [G loss: 0.911110]\n",
      "epoch:37 step:29520[D loss: 0.390498, acc: 67.97%, op_acc: 39.84%] [G loss: 0.957081]\n",
      "epoch:37 step:29521[D loss: 0.431541, acc: 53.12%, op_acc: 39.06%] [G loss: 0.894674]\n",
      "epoch:37 step:29522[D loss: 0.398588, acc: 67.19%, op_acc: 43.75%] [G loss: 0.871501]\n",
      "epoch:37 step:29523[D loss: 0.403655, acc: 58.59%, op_acc: 41.41%] [G loss: 0.922282]\n",
      "epoch:37 step:29524[D loss: 0.412893, acc: 57.03%, op_acc: 43.75%] [G loss: 0.868981]\n",
      "epoch:37 step:29525[D loss: 0.426827, acc: 59.38%, op_acc: 38.28%] [G loss: 0.867655]\n",
      "epoch:37 step:29526[D loss: 0.428188, acc: 58.59%, op_acc: 43.75%] [G loss: 0.852286]\n",
      "epoch:37 step:29527[D loss: 0.405123, acc: 57.81%, op_acc: 41.41%] [G loss: 0.876010]\n",
      "epoch:37 step:29528[D loss: 0.439603, acc: 60.16%, op_acc: 35.94%] [G loss: 0.850856]\n",
      "epoch:37 step:29529[D loss: 0.420572, acc: 56.25%, op_acc: 42.97%] [G loss: 0.858222]\n",
      "epoch:37 step:29530[D loss: 0.441406, acc: 53.91%, op_acc: 38.28%] [G loss: 0.798468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29531[D loss: 0.416015, acc: 59.38%, op_acc: 42.97%] [G loss: 0.824110]\n",
      "epoch:37 step:29532[D loss: 0.459287, acc: 55.47%, op_acc: 36.72%] [G loss: 0.869911]\n",
      "epoch:37 step:29533[D loss: 0.403085, acc: 64.84%, op_acc: 43.75%] [G loss: 0.878699]\n",
      "epoch:37 step:29534[D loss: 0.414813, acc: 52.34%, op_acc: 50.78%] [G loss: 0.862920]\n",
      "epoch:37 step:29535[D loss: 0.425217, acc: 66.41%, op_acc: 36.72%] [G loss: 0.896756]\n",
      "epoch:37 step:29536[D loss: 0.427702, acc: 60.16%, op_acc: 39.06%] [G loss: 0.911885]\n",
      "epoch:37 step:29537[D loss: 0.426541, acc: 67.19%, op_acc: 44.53%] [G loss: 0.862611]\n",
      "epoch:37 step:29538[D loss: 0.422518, acc: 59.38%, op_acc: 40.62%] [G loss: 0.907979]\n",
      "epoch:37 step:29539[D loss: 0.442210, acc: 49.22%, op_acc: 40.62%] [G loss: 0.859621]\n",
      "epoch:37 step:29540[D loss: 0.441320, acc: 56.25%, op_acc: 40.62%] [G loss: 0.854690]\n",
      "epoch:37 step:29541[D loss: 0.382196, acc: 65.62%, op_acc: 45.31%] [G loss: 0.920403]\n",
      "epoch:37 step:29542[D loss: 0.387568, acc: 64.84%, op_acc: 38.28%] [G loss: 0.894743]\n",
      "epoch:37 step:29543[D loss: 0.414514, acc: 61.72%, op_acc: 42.97%] [G loss: 0.897480]\n",
      "epoch:37 step:29544[D loss: 0.395193, acc: 62.50%, op_acc: 43.75%] [G loss: 0.893388]\n",
      "epoch:37 step:29545[D loss: 0.403957, acc: 62.50%, op_acc: 38.28%] [G loss: 0.929762]\n",
      "epoch:37 step:29546[D loss: 0.420773, acc: 58.59%, op_acc: 39.84%] [G loss: 0.809611]\n",
      "epoch:37 step:29547[D loss: 0.452968, acc: 50.78%, op_acc: 38.28%] [G loss: 0.845274]\n",
      "epoch:37 step:29548[D loss: 0.406254, acc: 67.97%, op_acc: 46.09%] [G loss: 0.869707]\n",
      "epoch:37 step:29549[D loss: 0.406681, acc: 60.16%, op_acc: 39.06%] [G loss: 0.869226]\n",
      "epoch:37 step:29550[D loss: 0.398559, acc: 64.84%, op_acc: 43.75%] [G loss: 0.892964]\n",
      "##############\n",
      "[0.85317845 0.84719822 0.82182486 0.81724163 0.78057272 0.83292558\n",
      " 0.89923242 0.8424004  0.82856422 0.82523884]\n",
      "##########\n",
      "epoch:37 step:29551[D loss: 0.415300, acc: 58.59%, op_acc: 45.31%] [G loss: 0.952297]\n",
      "epoch:37 step:29552[D loss: 0.397577, acc: 57.03%, op_acc: 43.75%] [G loss: 0.887997]\n",
      "epoch:37 step:29553[D loss: 0.434291, acc: 58.59%, op_acc: 39.84%] [G loss: 0.878328]\n",
      "epoch:37 step:29554[D loss: 0.415598, acc: 60.16%, op_acc: 42.19%] [G loss: 0.880520]\n",
      "epoch:37 step:29555[D loss: 0.388505, acc: 66.41%, op_acc: 41.41%] [G loss: 0.877288]\n",
      "epoch:37 step:29556[D loss: 0.446696, acc: 52.34%, op_acc: 36.72%] [G loss: 0.823832]\n",
      "epoch:37 step:29557[D loss: 0.415387, acc: 59.38%, op_acc: 43.75%] [G loss: 0.844346]\n",
      "epoch:37 step:29558[D loss: 0.399011, acc: 59.38%, op_acc: 47.66%] [G loss: 0.875314]\n",
      "epoch:37 step:29559[D loss: 0.409918, acc: 59.38%, op_acc: 44.53%] [G loss: 0.808931]\n",
      "epoch:37 step:29560[D loss: 0.440441, acc: 57.03%, op_acc: 44.53%] [G loss: 0.848054]\n",
      "epoch:37 step:29561[D loss: 0.397347, acc: 60.16%, op_acc: 45.31%] [G loss: 0.869129]\n",
      "epoch:37 step:29562[D loss: 0.401197, acc: 67.19%, op_acc: 38.28%] [G loss: 0.893013]\n",
      "epoch:37 step:29563[D loss: 0.410810, acc: 52.34%, op_acc: 44.53%] [G loss: 0.915738]\n",
      "epoch:37 step:29564[D loss: 0.403723, acc: 61.72%, op_acc: 39.84%] [G loss: 0.890873]\n",
      "epoch:37 step:29565[D loss: 0.438215, acc: 64.84%, op_acc: 33.59%] [G loss: 0.857578]\n",
      "epoch:37 step:29566[D loss: 0.385881, acc: 63.28%, op_acc: 37.50%] [G loss: 0.918728]\n",
      "epoch:37 step:29567[D loss: 0.420924, acc: 59.38%, op_acc: 39.06%] [G loss: 0.876813]\n",
      "epoch:37 step:29568[D loss: 0.400963, acc: 60.94%, op_acc: 43.75%] [G loss: 0.919790]\n",
      "epoch:37 step:29569[D loss: 0.460732, acc: 58.59%, op_acc: 37.50%] [G loss: 0.917353]\n",
      "epoch:37 step:29570[D loss: 0.425800, acc: 62.50%, op_acc: 34.38%] [G loss: 0.836015]\n",
      "epoch:37 step:29571[D loss: 0.393076, acc: 64.84%, op_acc: 49.22%] [G loss: 0.855347]\n",
      "epoch:37 step:29572[D loss: 0.413774, acc: 63.28%, op_acc: 35.94%] [G loss: 0.794157]\n",
      "epoch:37 step:29573[D loss: 0.463599, acc: 50.00%, op_acc: 35.94%] [G loss: 0.885263]\n",
      "epoch:37 step:29574[D loss: 0.451531, acc: 60.16%, op_acc: 33.59%] [G loss: 0.808817]\n",
      "epoch:37 step:29575[D loss: 0.428738, acc: 57.81%, op_acc: 38.28%] [G loss: 0.838771]\n",
      "epoch:37 step:29576[D loss: 0.370881, acc: 68.75%, op_acc: 45.31%] [G loss: 0.854775]\n",
      "epoch:37 step:29577[D loss: 0.449777, acc: 57.03%, op_acc: 36.72%] [G loss: 0.823352]\n",
      "epoch:37 step:29578[D loss: 0.446287, acc: 57.03%, op_acc: 33.59%] [G loss: 0.790884]\n",
      "epoch:37 step:29579[D loss: 0.407735, acc: 62.50%, op_acc: 41.41%] [G loss: 0.798333]\n",
      "epoch:37 step:29580[D loss: 0.409205, acc: 61.72%, op_acc: 40.62%] [G loss: 0.875896]\n",
      "epoch:37 step:29581[D loss: 0.457589, acc: 50.00%, op_acc: 36.72%] [G loss: 0.780555]\n",
      "epoch:37 step:29582[D loss: 0.433669, acc: 64.06%, op_acc: 40.62%] [G loss: 0.922628]\n",
      "epoch:37 step:29583[D loss: 0.397930, acc: 61.72%, op_acc: 39.84%] [G loss: 0.972322]\n",
      "epoch:37 step:29584[D loss: 0.421831, acc: 60.94%, op_acc: 39.06%] [G loss: 0.910414]\n",
      "epoch:37 step:29585[D loss: 0.418456, acc: 56.25%, op_acc: 39.84%] [G loss: 0.856088]\n",
      "epoch:37 step:29586[D loss: 0.399150, acc: 61.72%, op_acc: 45.31%] [G loss: 0.842409]\n",
      "epoch:37 step:29587[D loss: 0.396752, acc: 71.88%, op_acc: 42.19%] [G loss: 0.945719]\n",
      "epoch:37 step:29588[D loss: 0.421214, acc: 61.72%, op_acc: 39.84%] [G loss: 0.873864]\n",
      "epoch:37 step:29589[D loss: 0.429127, acc: 57.81%, op_acc: 39.06%] [G loss: 0.882405]\n",
      "epoch:37 step:29590[D loss: 0.410539, acc: 64.06%, op_acc: 35.94%] [G loss: 0.902504]\n",
      "epoch:37 step:29591[D loss: 0.400806, acc: 66.41%, op_acc: 42.97%] [G loss: 0.985035]\n",
      "epoch:37 step:29592[D loss: 0.414192, acc: 64.06%, op_acc: 41.41%] [G loss: 0.899188]\n",
      "epoch:37 step:29593[D loss: 0.442986, acc: 56.25%, op_acc: 39.06%] [G loss: 0.881727]\n",
      "epoch:37 step:29594[D loss: 0.403594, acc: 62.50%, op_acc: 39.84%] [G loss: 0.937314]\n",
      "epoch:37 step:29595[D loss: 0.396560, acc: 63.28%, op_acc: 45.31%] [G loss: 0.899568]\n",
      "epoch:37 step:29596[D loss: 0.428986, acc: 53.12%, op_acc: 41.41%] [G loss: 0.874761]\n",
      "epoch:37 step:29597[D loss: 0.412094, acc: 67.97%, op_acc: 42.19%] [G loss: 0.892284]\n",
      "epoch:37 step:29598[D loss: 0.429746, acc: 60.16%, op_acc: 39.84%] [G loss: 0.884151]\n",
      "epoch:37 step:29599[D loss: 0.431497, acc: 57.03%, op_acc: 40.62%] [G loss: 0.891019]\n",
      "epoch:37 step:29600[D loss: 0.452762, acc: 53.12%, op_acc: 39.84%] [G loss: 0.822170]\n",
      "##############\n",
      "[0.85995521 0.84811205 0.80663953 0.78867994 0.8103374  0.81963004\n",
      " 0.88959134 0.81543467 0.82835251 0.80532001]\n",
      "##########\n",
      "epoch:37 step:29601[D loss: 0.387408, acc: 62.50%, op_acc: 46.88%] [G loss: 0.848908]\n",
      "epoch:37 step:29602[D loss: 0.441578, acc: 54.69%, op_acc: 35.94%] [G loss: 0.819799]\n",
      "epoch:37 step:29603[D loss: 0.409508, acc: 64.06%, op_acc: 44.53%] [G loss: 0.854008]\n",
      "epoch:37 step:29604[D loss: 0.422140, acc: 53.12%, op_acc: 42.97%] [G loss: 0.833783]\n",
      "epoch:37 step:29605[D loss: 0.423966, acc: 59.38%, op_acc: 36.72%] [G loss: 0.859401]\n",
      "epoch:37 step:29606[D loss: 0.431243, acc: 57.81%, op_acc: 44.53%] [G loss: 0.906147]\n",
      "epoch:37 step:29607[D loss: 0.378900, acc: 63.28%, op_acc: 48.44%] [G loss: 0.888484]\n",
      "epoch:37 step:29608[D loss: 0.413348, acc: 60.16%, op_acc: 41.41%] [G loss: 0.978911]\n",
      "epoch:37 step:29609[D loss: 0.405399, acc: 57.03%, op_acc: 48.44%] [G loss: 0.811076]\n",
      "epoch:37 step:29610[D loss: 0.388338, acc: 61.72%, op_acc: 44.53%] [G loss: 0.879031]\n",
      "epoch:37 step:29611[D loss: 0.451766, acc: 52.34%, op_acc: 42.97%] [G loss: 0.969694]\n",
      "epoch:37 step:29612[D loss: 0.447855, acc: 51.56%, op_acc: 40.62%] [G loss: 0.852335]\n",
      "epoch:37 step:29613[D loss: 0.425829, acc: 59.38%, op_acc: 40.62%] [G loss: 0.925703]\n",
      "epoch:37 step:29614[D loss: 0.402776, acc: 59.38%, op_acc: 43.75%] [G loss: 0.938543]\n",
      "epoch:37 step:29615[D loss: 0.409550, acc: 64.84%, op_acc: 38.28%] [G loss: 0.853492]\n",
      "epoch:37 step:29616[D loss: 0.415361, acc: 58.59%, op_acc: 42.19%] [G loss: 0.835024]\n",
      "epoch:37 step:29617[D loss: 0.415767, acc: 58.59%, op_acc: 44.53%] [G loss: 0.842642]\n",
      "epoch:37 step:29618[D loss: 0.411441, acc: 64.06%, op_acc: 37.50%] [G loss: 0.892229]\n",
      "epoch:37 step:29619[D loss: 0.436712, acc: 51.56%, op_acc: 42.97%] [G loss: 0.916738]\n",
      "epoch:37 step:29620[D loss: 0.422258, acc: 62.50%, op_acc: 39.06%] [G loss: 0.795056]\n",
      "epoch:37 step:29621[D loss: 0.455376, acc: 56.25%, op_acc: 36.72%] [G loss: 0.859247]\n",
      "epoch:37 step:29622[D loss: 0.405239, acc: 64.06%, op_acc: 43.75%] [G loss: 0.816229]\n",
      "epoch:37 step:29623[D loss: 0.408417, acc: 59.38%, op_acc: 42.97%] [G loss: 0.886212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29624[D loss: 0.421457, acc: 63.28%, op_acc: 36.72%] [G loss: 0.879506]\n",
      "epoch:37 step:29625[D loss: 0.425606, acc: 57.81%, op_acc: 39.84%] [G loss: 0.910051]\n",
      "epoch:37 step:29626[D loss: 0.411852, acc: 60.16%, op_acc: 40.62%] [G loss: 0.869270]\n",
      "epoch:37 step:29627[D loss: 0.416253, acc: 60.16%, op_acc: 39.84%] [G loss: 0.846341]\n",
      "epoch:37 step:29628[D loss: 0.388047, acc: 64.84%, op_acc: 42.97%] [G loss: 0.918352]\n",
      "epoch:37 step:29629[D loss: 0.413178, acc: 59.38%, op_acc: 41.41%] [G loss: 0.854244]\n",
      "epoch:37 step:29630[D loss: 0.417384, acc: 59.38%, op_acc: 39.84%] [G loss: 0.919158]\n",
      "epoch:37 step:29631[D loss: 0.431209, acc: 54.69%, op_acc: 41.41%] [G loss: 0.863256]\n",
      "epoch:37 step:29632[D loss: 0.422947, acc: 53.91%, op_acc: 45.31%] [G loss: 0.878894]\n",
      "epoch:37 step:29633[D loss: 0.393932, acc: 69.53%, op_acc: 37.50%] [G loss: 0.863495]\n",
      "epoch:37 step:29634[D loss: 0.400678, acc: 60.16%, op_acc: 40.62%] [G loss: 0.857254]\n",
      "epoch:37 step:29635[D loss: 0.413685, acc: 55.47%, op_acc: 42.19%] [G loss: 0.819866]\n",
      "epoch:37 step:29636[D loss: 0.419070, acc: 56.25%, op_acc: 37.50%] [G loss: 0.909673]\n",
      "epoch:37 step:29637[D loss: 0.398385, acc: 56.25%, op_acc: 42.97%] [G loss: 0.838550]\n",
      "epoch:37 step:29638[D loss: 0.413222, acc: 62.50%, op_acc: 38.28%] [G loss: 0.838164]\n",
      "epoch:37 step:29639[D loss: 0.421336, acc: 60.16%, op_acc: 39.84%] [G loss: 0.908486]\n",
      "epoch:37 step:29640[D loss: 0.437256, acc: 58.59%, op_acc: 36.72%] [G loss: 0.822329]\n",
      "epoch:37 step:29641[D loss: 0.403726, acc: 62.50%, op_acc: 46.09%] [G loss: 0.893993]\n",
      "epoch:37 step:29642[D loss: 0.420476, acc: 53.91%, op_acc: 44.53%] [G loss: 0.894596]\n",
      "epoch:37 step:29643[D loss: 0.424419, acc: 56.25%, op_acc: 39.06%] [G loss: 0.809434]\n",
      "epoch:37 step:29644[D loss: 0.397093, acc: 64.84%, op_acc: 43.75%] [G loss: 0.849457]\n",
      "epoch:37 step:29645[D loss: 0.429953, acc: 60.94%, op_acc: 38.28%] [G loss: 0.920015]\n",
      "epoch:37 step:29646[D loss: 0.423817, acc: 61.72%, op_acc: 39.06%] [G loss: 0.823901]\n",
      "epoch:37 step:29647[D loss: 0.419896, acc: 57.03%, op_acc: 50.00%] [G loss: 0.866372]\n",
      "epoch:37 step:29648[D loss: 0.428824, acc: 60.94%, op_acc: 38.28%] [G loss: 0.845935]\n",
      "epoch:37 step:29649[D loss: 0.405337, acc: 66.41%, op_acc: 42.19%] [G loss: 0.758128]\n",
      "epoch:37 step:29650[D loss: 0.398452, acc: 60.16%, op_acc: 45.31%] [G loss: 0.886068]\n",
      "##############\n",
      "[0.86152323 0.84431827 0.8134682  0.79087899 0.7845296  0.82966043\n",
      " 0.86996915 0.82368609 0.82415719 0.85038965]\n",
      "##########\n",
      "epoch:37 step:29651[D loss: 0.392366, acc: 64.06%, op_acc: 39.84%] [G loss: 0.907426]\n",
      "epoch:37 step:29652[D loss: 0.403412, acc: 60.94%, op_acc: 42.97%] [G loss: 0.908264]\n",
      "epoch:37 step:29653[D loss: 0.400272, acc: 59.38%, op_acc: 48.44%] [G loss: 0.867011]\n",
      "epoch:37 step:29654[D loss: 0.388604, acc: 63.28%, op_acc: 48.44%] [G loss: 0.930921]\n",
      "epoch:37 step:29655[D loss: 0.401136, acc: 57.81%, op_acc: 41.41%] [G loss: 0.905788]\n",
      "epoch:37 step:29656[D loss: 0.431030, acc: 64.06%, op_acc: 42.19%] [G loss: 0.878870]\n",
      "epoch:37 step:29657[D loss: 0.389883, acc: 68.75%, op_acc: 43.75%] [G loss: 0.971117]\n",
      "epoch:37 step:29658[D loss: 0.394656, acc: 70.31%, op_acc: 41.41%] [G loss: 0.962869]\n",
      "epoch:37 step:29659[D loss: 0.418361, acc: 57.03%, op_acc: 46.09%] [G loss: 0.890535]\n",
      "epoch:37 step:29660[D loss: 0.409375, acc: 57.81%, op_acc: 42.97%] [G loss: 0.913673]\n",
      "epoch:37 step:29661[D loss: 0.423771, acc: 57.81%, op_acc: 40.62%] [G loss: 0.851187]\n",
      "epoch:37 step:29662[D loss: 0.412989, acc: 58.59%, op_acc: 43.75%] [G loss: 0.867860]\n",
      "epoch:37 step:29663[D loss: 0.436459, acc: 51.56%, op_acc: 36.72%] [G loss: 0.893186]\n",
      "epoch:37 step:29664[D loss: 0.445614, acc: 53.12%, op_acc: 39.06%] [G loss: 0.909253]\n",
      "epoch:37 step:29665[D loss: 0.416636, acc: 60.16%, op_acc: 41.41%] [G loss: 1.008044]\n",
      "epoch:37 step:29666[D loss: 0.373614, acc: 64.84%, op_acc: 44.53%] [G loss: 0.951148]\n",
      "epoch:37 step:29667[D loss: 0.434986, acc: 52.34%, op_acc: 42.97%] [G loss: 0.862940]\n",
      "epoch:37 step:29668[D loss: 0.442443, acc: 52.34%, op_acc: 33.59%] [G loss: 0.939159]\n",
      "epoch:37 step:29669[D loss: 0.453528, acc: 51.56%, op_acc: 39.06%] [G loss: 0.813082]\n",
      "epoch:37 step:29670[D loss: 0.430599, acc: 57.81%, op_acc: 38.28%] [G loss: 0.857192]\n",
      "epoch:37 step:29671[D loss: 0.415153, acc: 60.94%, op_acc: 42.19%] [G loss: 0.871838]\n",
      "epoch:37 step:29672[D loss: 0.440996, acc: 59.38%, op_acc: 42.97%] [G loss: 0.839724]\n",
      "epoch:37 step:29673[D loss: 0.397680, acc: 64.06%, op_acc: 45.31%] [G loss: 0.888255]\n",
      "epoch:37 step:29674[D loss: 0.433834, acc: 53.91%, op_acc: 33.59%] [G loss: 0.897191]\n",
      "epoch:37 step:29675[D loss: 0.414269, acc: 59.38%, op_acc: 45.31%] [G loss: 0.942507]\n",
      "epoch:37 step:29676[D loss: 0.435749, acc: 60.16%, op_acc: 39.06%] [G loss: 0.950572]\n",
      "epoch:37 step:29677[D loss: 0.391981, acc: 66.41%, op_acc: 41.41%] [G loss: 0.993179]\n",
      "epoch:37 step:29678[D loss: 0.434045, acc: 51.56%, op_acc: 41.41%] [G loss: 0.878887]\n",
      "epoch:38 step:29679[D loss: 0.388969, acc: 67.97%, op_acc: 45.31%] [G loss: 0.906884]\n",
      "epoch:38 step:29680[D loss: 0.390031, acc: 64.84%, op_acc: 45.31%] [G loss: 0.905550]\n",
      "epoch:38 step:29681[D loss: 0.402933, acc: 65.62%, op_acc: 40.62%] [G loss: 0.901527]\n",
      "epoch:38 step:29682[D loss: 0.416069, acc: 57.81%, op_acc: 44.53%] [G loss: 0.953156]\n",
      "epoch:38 step:29683[D loss: 0.428250, acc: 55.47%, op_acc: 42.19%] [G loss: 0.881886]\n",
      "epoch:38 step:29684[D loss: 0.403353, acc: 65.62%, op_acc: 44.53%] [G loss: 0.906878]\n",
      "epoch:38 step:29685[D loss: 0.419761, acc: 62.50%, op_acc: 41.41%] [G loss: 1.010327]\n",
      "epoch:38 step:29686[D loss: 0.386795, acc: 60.94%, op_acc: 47.66%] [G loss: 0.912007]\n",
      "epoch:38 step:29687[D loss: 0.434737, acc: 54.69%, op_acc: 43.75%] [G loss: 0.897544]\n",
      "epoch:38 step:29688[D loss: 0.435248, acc: 57.81%, op_acc: 35.94%] [G loss: 0.830507]\n",
      "epoch:38 step:29689[D loss: 0.445608, acc: 49.22%, op_acc: 37.50%] [G loss: 0.839144]\n",
      "epoch:38 step:29690[D loss: 0.424300, acc: 65.62%, op_acc: 39.84%] [G loss: 0.890365]\n",
      "epoch:38 step:29691[D loss: 0.380726, acc: 72.66%, op_acc: 42.19%] [G loss: 0.885187]\n",
      "epoch:38 step:29692[D loss: 0.411229, acc: 64.84%, op_acc: 37.50%] [G loss: 0.897040]\n",
      "epoch:38 step:29693[D loss: 0.400792, acc: 62.50%, op_acc: 45.31%] [G loss: 0.871998]\n",
      "epoch:38 step:29694[D loss: 0.407299, acc: 56.25%, op_acc: 39.06%] [G loss: 0.827709]\n",
      "epoch:38 step:29695[D loss: 0.421967, acc: 60.16%, op_acc: 42.19%] [G loss: 0.931131]\n",
      "epoch:38 step:29696[D loss: 0.391627, acc: 63.28%, op_acc: 40.62%] [G loss: 1.007488]\n",
      "epoch:38 step:29697[D loss: 0.411398, acc: 61.72%, op_acc: 42.19%] [G loss: 0.872703]\n",
      "epoch:38 step:29698[D loss: 0.382677, acc: 63.28%, op_acc: 44.53%] [G loss: 0.901455]\n",
      "epoch:38 step:29699[D loss: 0.442010, acc: 54.69%, op_acc: 35.94%] [G loss: 0.825729]\n",
      "epoch:38 step:29700[D loss: 0.398408, acc: 64.06%, op_acc: 44.53%] [G loss: 0.919631]\n",
      "##############\n",
      "[0.84357338 0.85338739 0.80880296 0.80984849 0.79908913 0.82264534\n",
      " 0.90935321 0.81537549 0.80465713 0.82244156]\n",
      "##########\n",
      "epoch:38 step:29701[D loss: 0.405848, acc: 57.81%, op_acc: 42.19%] [G loss: 0.831094]\n",
      "epoch:38 step:29702[D loss: 0.418110, acc: 64.06%, op_acc: 38.28%] [G loss: 0.922548]\n",
      "epoch:38 step:29703[D loss: 0.466247, acc: 47.66%, op_acc: 39.06%] [G loss: 0.843083]\n",
      "epoch:38 step:29704[D loss: 0.382819, acc: 64.84%, op_acc: 42.19%] [G loss: 0.868756]\n",
      "epoch:38 step:29705[D loss: 0.398621, acc: 66.41%, op_acc: 41.41%] [G loss: 0.883587]\n",
      "epoch:38 step:29706[D loss: 0.420926, acc: 55.47%, op_acc: 45.31%] [G loss: 0.929578]\n",
      "epoch:38 step:29707[D loss: 0.414388, acc: 60.94%, op_acc: 42.97%] [G loss: 0.953218]\n",
      "epoch:38 step:29708[D loss: 0.405882, acc: 58.59%, op_acc: 49.22%] [G loss: 0.889353]\n",
      "epoch:38 step:29709[D loss: 0.424958, acc: 60.94%, op_acc: 37.50%] [G loss: 0.947250]\n",
      "epoch:38 step:29710[D loss: 0.407576, acc: 63.28%, op_acc: 37.50%] [G loss: 0.900854]\n",
      "epoch:38 step:29711[D loss: 0.389595, acc: 65.62%, op_acc: 45.31%] [G loss: 0.939408]\n",
      "epoch:38 step:29712[D loss: 0.411919, acc: 67.19%, op_acc: 39.84%] [G loss: 0.823565]\n",
      "epoch:38 step:29713[D loss: 0.417154, acc: 63.28%, op_acc: 42.19%] [G loss: 0.861072]\n",
      "epoch:38 step:29714[D loss: 0.403683, acc: 61.72%, op_acc: 45.31%] [G loss: 0.986584]\n",
      "epoch:38 step:29715[D loss: 0.383782, acc: 71.09%, op_acc: 43.75%] [G loss: 0.908061]\n",
      "epoch:38 step:29716[D loss: 0.404042, acc: 62.50%, op_acc: 38.28%] [G loss: 0.948931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29717[D loss: 0.392647, acc: 60.94%, op_acc: 39.06%] [G loss: 0.864427]\n",
      "epoch:38 step:29718[D loss: 0.429118, acc: 57.81%, op_acc: 36.72%] [G loss: 0.804430]\n",
      "epoch:38 step:29719[D loss: 0.393526, acc: 63.28%, op_acc: 46.09%] [G loss: 0.824562]\n",
      "epoch:38 step:29720[D loss: 0.392415, acc: 60.16%, op_acc: 50.00%] [G loss: 0.877729]\n",
      "epoch:38 step:29721[D loss: 0.425064, acc: 60.16%, op_acc: 35.94%] [G loss: 0.849278]\n",
      "epoch:38 step:29722[D loss: 0.447096, acc: 51.56%, op_acc: 43.75%] [G loss: 0.878452]\n",
      "epoch:38 step:29723[D loss: 0.406698, acc: 63.28%, op_acc: 40.62%] [G loss: 0.903193]\n",
      "epoch:38 step:29724[D loss: 0.412594, acc: 58.59%, op_acc: 41.41%] [G loss: 0.804071]\n",
      "epoch:38 step:29725[D loss: 0.420035, acc: 54.69%, op_acc: 38.28%] [G loss: 0.820134]\n",
      "epoch:38 step:29726[D loss: 0.415737, acc: 60.16%, op_acc: 37.50%] [G loss: 0.882323]\n",
      "epoch:38 step:29727[D loss: 0.400795, acc: 62.50%, op_acc: 35.16%] [G loss: 0.897193]\n",
      "epoch:38 step:29728[D loss: 0.436232, acc: 52.34%, op_acc: 42.19%] [G loss: 0.904576]\n",
      "epoch:38 step:29729[D loss: 0.422132, acc: 62.50%, op_acc: 36.72%] [G loss: 0.918459]\n",
      "epoch:38 step:29730[D loss: 0.415470, acc: 66.41%, op_acc: 36.72%] [G loss: 0.931062]\n",
      "epoch:38 step:29731[D loss: 0.445692, acc: 57.03%, op_acc: 35.16%] [G loss: 0.850291]\n",
      "epoch:38 step:29732[D loss: 0.415721, acc: 60.94%, op_acc: 46.88%] [G loss: 0.825144]\n",
      "epoch:38 step:29733[D loss: 0.398380, acc: 60.16%, op_acc: 43.75%] [G loss: 0.822886]\n",
      "epoch:38 step:29734[D loss: 0.425065, acc: 64.06%, op_acc: 36.72%] [G loss: 0.868325]\n",
      "epoch:38 step:29735[D loss: 0.448927, acc: 52.34%, op_acc: 38.28%] [G loss: 0.835511]\n",
      "epoch:38 step:29736[D loss: 0.451163, acc: 51.56%, op_acc: 39.84%] [G loss: 0.844250]\n",
      "epoch:38 step:29737[D loss: 0.412539, acc: 64.84%, op_acc: 42.19%] [G loss: 0.941231]\n",
      "epoch:38 step:29738[D loss: 0.411841, acc: 56.25%, op_acc: 39.84%] [G loss: 0.810776]\n",
      "epoch:38 step:29739[D loss: 0.408500, acc: 62.50%, op_acc: 39.84%] [G loss: 0.974110]\n",
      "epoch:38 step:29740[D loss: 0.402477, acc: 63.28%, op_acc: 39.84%] [G loss: 0.940507]\n",
      "epoch:38 step:29741[D loss: 0.445694, acc: 50.00%, op_acc: 42.97%] [G loss: 0.926642]\n",
      "epoch:38 step:29742[D loss: 0.415442, acc: 62.50%, op_acc: 39.06%] [G loss: 0.915078]\n",
      "epoch:38 step:29743[D loss: 0.426712, acc: 58.59%, op_acc: 36.72%] [G loss: 0.886010]\n",
      "epoch:38 step:29744[D loss: 0.385823, acc: 67.97%, op_acc: 42.19%] [G loss: 0.938908]\n",
      "epoch:38 step:29745[D loss: 0.409756, acc: 65.62%, op_acc: 45.31%] [G loss: 0.943370]\n",
      "epoch:38 step:29746[D loss: 0.420804, acc: 57.81%, op_acc: 43.75%] [G loss: 0.862628]\n",
      "epoch:38 step:29747[D loss: 0.379680, acc: 67.97%, op_acc: 46.09%] [G loss: 0.919470]\n",
      "epoch:38 step:29748[D loss: 0.417974, acc: 59.38%, op_acc: 38.28%] [G loss: 0.948665]\n",
      "epoch:38 step:29749[D loss: 0.405096, acc: 66.41%, op_acc: 43.75%] [G loss: 0.978571]\n",
      "epoch:38 step:29750[D loss: 0.400995, acc: 64.06%, op_acc: 46.09%] [G loss: 0.913617]\n",
      "##############\n",
      "[0.86248975 0.85922086 0.79489295 0.8195276  0.79258434 0.83235743\n",
      " 0.89581639 0.84188252 0.82081135 0.80673708]\n",
      "##########\n",
      "epoch:38 step:29751[D loss: 0.408438, acc: 66.41%, op_acc: 44.53%] [G loss: 0.947355]\n",
      "epoch:38 step:29752[D loss: 0.395871, acc: 63.28%, op_acc: 41.41%] [G loss: 0.915022]\n",
      "epoch:38 step:29753[D loss: 0.389323, acc: 69.53%, op_acc: 42.19%] [G loss: 0.885406]\n",
      "epoch:38 step:29754[D loss: 0.433052, acc: 55.47%, op_acc: 46.09%] [G loss: 0.945025]\n",
      "epoch:38 step:29755[D loss: 0.432484, acc: 57.03%, op_acc: 40.62%] [G loss: 0.874895]\n",
      "epoch:38 step:29756[D loss: 0.472081, acc: 55.47%, op_acc: 33.59%] [G loss: 0.867063]\n",
      "epoch:38 step:29757[D loss: 0.442282, acc: 51.56%, op_acc: 41.41%] [G loss: 0.971367]\n",
      "epoch:38 step:29758[D loss: 0.433393, acc: 57.81%, op_acc: 35.94%] [G loss: 0.862129]\n",
      "epoch:38 step:29759[D loss: 0.411208, acc: 58.59%, op_acc: 35.94%] [G loss: 0.936194]\n",
      "epoch:38 step:29760[D loss: 0.404431, acc: 59.38%, op_acc: 46.88%] [G loss: 0.875481]\n",
      "epoch:38 step:29761[D loss: 0.411966, acc: 58.59%, op_acc: 43.75%] [G loss: 0.891422]\n",
      "epoch:38 step:29762[D loss: 0.379629, acc: 67.97%, op_acc: 39.84%] [G loss: 0.975605]\n",
      "epoch:38 step:29763[D loss: 0.441957, acc: 54.69%, op_acc: 32.03%] [G loss: 0.898876]\n",
      "epoch:38 step:29764[D loss: 0.435581, acc: 59.38%, op_acc: 39.06%] [G loss: 0.990982]\n",
      "epoch:38 step:29765[D loss: 0.422663, acc: 60.94%, op_acc: 35.94%] [G loss: 0.852279]\n",
      "epoch:38 step:29766[D loss: 0.396078, acc: 64.84%, op_acc: 43.75%] [G loss: 0.943183]\n",
      "epoch:38 step:29767[D loss: 0.410166, acc: 64.84%, op_acc: 42.97%] [G loss: 0.920776]\n",
      "epoch:38 step:29768[D loss: 0.393857, acc: 61.72%, op_acc: 42.19%] [G loss: 0.848626]\n",
      "epoch:38 step:29769[D loss: 0.391603, acc: 63.28%, op_acc: 39.06%] [G loss: 0.795092]\n",
      "epoch:38 step:29770[D loss: 0.444792, acc: 58.59%, op_acc: 35.16%] [G loss: 0.904493]\n",
      "epoch:38 step:29771[D loss: 0.387801, acc: 64.84%, op_acc: 43.75%] [G loss: 0.845911]\n",
      "epoch:38 step:29772[D loss: 0.410431, acc: 65.62%, op_acc: 44.53%] [G loss: 0.807495]\n",
      "epoch:38 step:29773[D loss: 0.454958, acc: 50.78%, op_acc: 39.06%] [G loss: 0.869902]\n",
      "epoch:38 step:29774[D loss: 0.424199, acc: 65.62%, op_acc: 40.62%] [G loss: 0.980868]\n",
      "epoch:38 step:29775[D loss: 0.433500, acc: 57.81%, op_acc: 40.62%] [G loss: 0.872192]\n",
      "epoch:38 step:29776[D loss: 0.413442, acc: 61.72%, op_acc: 39.06%] [G loss: 0.858875]\n",
      "epoch:38 step:29777[D loss: 0.401527, acc: 60.94%, op_acc: 43.75%] [G loss: 0.852648]\n",
      "epoch:38 step:29778[D loss: 0.400258, acc: 57.81%, op_acc: 43.75%] [G loss: 0.834601]\n",
      "epoch:38 step:29779[D loss: 0.419201, acc: 67.19%, op_acc: 39.84%] [G loss: 0.837730]\n",
      "epoch:38 step:29780[D loss: 0.433694, acc: 52.34%, op_acc: 42.97%] [G loss: 0.926023]\n",
      "epoch:38 step:29781[D loss: 0.398751, acc: 57.81%, op_acc: 42.97%] [G loss: 0.990581]\n",
      "epoch:38 step:29782[D loss: 0.393560, acc: 64.84%, op_acc: 39.06%] [G loss: 0.995533]\n",
      "epoch:38 step:29783[D loss: 0.418770, acc: 60.94%, op_acc: 41.41%] [G loss: 0.964863]\n",
      "epoch:38 step:29784[D loss: 0.410108, acc: 59.38%, op_acc: 38.28%] [G loss: 0.922920]\n",
      "epoch:38 step:29785[D loss: 0.403677, acc: 62.50%, op_acc: 41.41%] [G loss: 0.902957]\n",
      "epoch:38 step:29786[D loss: 0.410385, acc: 71.88%, op_acc: 41.41%] [G loss: 0.941810]\n",
      "epoch:38 step:29787[D loss: 0.407198, acc: 62.50%, op_acc: 36.72%] [G loss: 0.832960]\n",
      "epoch:38 step:29788[D loss: 0.382848, acc: 70.31%, op_acc: 43.75%] [G loss: 0.951748]\n",
      "epoch:38 step:29789[D loss: 0.447115, acc: 61.72%, op_acc: 35.94%] [G loss: 0.875115]\n",
      "epoch:38 step:29790[D loss: 0.428219, acc: 60.94%, op_acc: 38.28%] [G loss: 0.934311]\n",
      "epoch:38 step:29791[D loss: 0.439440, acc: 56.25%, op_acc: 33.59%] [G loss: 0.938141]\n",
      "epoch:38 step:29792[D loss: 0.426293, acc: 54.69%, op_acc: 41.41%] [G loss: 0.838898]\n",
      "epoch:38 step:29793[D loss: 0.388449, acc: 60.16%, op_acc: 44.53%] [G loss: 0.904223]\n",
      "epoch:38 step:29794[D loss: 0.428600, acc: 52.34%, op_acc: 44.53%] [G loss: 0.796819]\n",
      "epoch:38 step:29795[D loss: 0.415364, acc: 59.38%, op_acc: 35.16%] [G loss: 0.875817]\n",
      "epoch:38 step:29796[D loss: 0.423150, acc: 57.03%, op_acc: 43.75%] [G loss: 0.880555]\n",
      "epoch:38 step:29797[D loss: 0.393558, acc: 68.75%, op_acc: 43.75%] [G loss: 0.821497]\n",
      "epoch:38 step:29798[D loss: 0.408367, acc: 63.28%, op_acc: 42.97%] [G loss: 0.851594]\n",
      "epoch:38 step:29799[D loss: 0.405898, acc: 64.84%, op_acc: 43.75%] [G loss: 0.902046]\n",
      "epoch:38 step:29800[D loss: 0.398444, acc: 58.59%, op_acc: 39.06%] [G loss: 0.845338]\n",
      "##############\n",
      "[0.84825364 0.84647837 0.81773385 0.81847947 0.80162752 0.83496797\n",
      " 0.90998358 0.83803342 0.80061149 0.82576444]\n",
      "##########\n",
      "epoch:38 step:29801[D loss: 0.453436, acc: 58.59%, op_acc: 42.19%] [G loss: 0.805175]\n",
      "epoch:38 step:29802[D loss: 0.427195, acc: 56.25%, op_acc: 40.62%] [G loss: 0.886732]\n",
      "epoch:38 step:29803[D loss: 0.450527, acc: 57.81%, op_acc: 34.38%] [G loss: 0.848158]\n",
      "epoch:38 step:29804[D loss: 0.423784, acc: 50.78%, op_acc: 42.19%] [G loss: 0.866117]\n",
      "epoch:38 step:29805[D loss: 0.400058, acc: 64.84%, op_acc: 41.41%] [G loss: 0.855928]\n",
      "epoch:38 step:29806[D loss: 0.413451, acc: 64.84%, op_acc: 39.84%] [G loss: 0.873830]\n",
      "epoch:38 step:29807[D loss: 0.446901, acc: 53.12%, op_acc: 37.50%] [G loss: 0.894749]\n",
      "epoch:38 step:29808[D loss: 0.420406, acc: 57.03%, op_acc: 35.94%] [G loss: 0.887857]\n",
      "epoch:38 step:29809[D loss: 0.408769, acc: 61.72%, op_acc: 42.19%] [G loss: 0.932199]\n",
      "epoch:38 step:29810[D loss: 0.359805, acc: 67.97%, op_acc: 47.66%] [G loss: 0.935277]\n",
      "epoch:38 step:29811[D loss: 0.439547, acc: 60.16%, op_acc: 39.84%] [G loss: 0.865928]\n",
      "epoch:38 step:29812[D loss: 0.386808, acc: 70.31%, op_acc: 40.62%] [G loss: 0.864523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29813[D loss: 0.434185, acc: 53.12%, op_acc: 42.97%] [G loss: 0.898365]\n",
      "epoch:38 step:29814[D loss: 0.397341, acc: 61.72%, op_acc: 37.50%] [G loss: 0.918384]\n",
      "epoch:38 step:29815[D loss: 0.422876, acc: 61.72%, op_acc: 39.06%] [G loss: 0.948547]\n",
      "epoch:38 step:29816[D loss: 0.390902, acc: 63.28%, op_acc: 42.97%] [G loss: 0.958007]\n",
      "epoch:38 step:29817[D loss: 0.416049, acc: 61.72%, op_acc: 39.84%] [G loss: 0.897076]\n",
      "epoch:38 step:29818[D loss: 0.402910, acc: 65.62%, op_acc: 41.41%] [G loss: 0.956269]\n",
      "epoch:38 step:29819[D loss: 0.457331, acc: 57.03%, op_acc: 41.41%] [G loss: 0.917312]\n",
      "epoch:38 step:29820[D loss: 0.387396, acc: 66.41%, op_acc: 44.53%] [G loss: 0.899352]\n",
      "epoch:38 step:29821[D loss: 0.422185, acc: 59.38%, op_acc: 42.97%] [G loss: 0.914124]\n",
      "epoch:38 step:29822[D loss: 0.449435, acc: 59.38%, op_acc: 37.50%] [G loss: 0.858645]\n",
      "epoch:38 step:29823[D loss: 0.417961, acc: 59.38%, op_acc: 41.41%] [G loss: 0.980240]\n",
      "epoch:38 step:29824[D loss: 0.400079, acc: 69.53%, op_acc: 41.41%] [G loss: 0.964648]\n",
      "epoch:38 step:29825[D loss: 0.399192, acc: 61.72%, op_acc: 40.62%] [G loss: 0.934953]\n",
      "epoch:38 step:29826[D loss: 0.409629, acc: 63.28%, op_acc: 40.62%] [G loss: 0.887200]\n",
      "epoch:38 step:29827[D loss: 0.384302, acc: 61.72%, op_acc: 46.88%] [G loss: 0.933349]\n",
      "epoch:38 step:29828[D loss: 0.443722, acc: 45.31%, op_acc: 41.41%] [G loss: 0.847314]\n",
      "epoch:38 step:29829[D loss: 0.387878, acc: 69.53%, op_acc: 39.84%] [G loss: 0.924487]\n",
      "epoch:38 step:29830[D loss: 0.421106, acc: 57.03%, op_acc: 41.41%] [G loss: 0.911950]\n",
      "epoch:38 step:29831[D loss: 0.457667, acc: 53.91%, op_acc: 41.41%] [G loss: 0.757077]\n",
      "epoch:38 step:29832[D loss: 0.428374, acc: 60.94%, op_acc: 44.53%] [G loss: 0.978350]\n",
      "epoch:38 step:29833[D loss: 0.445900, acc: 52.34%, op_acc: 37.50%] [G loss: 0.812345]\n",
      "epoch:38 step:29834[D loss: 0.436817, acc: 51.56%, op_acc: 36.72%] [G loss: 0.905960]\n",
      "epoch:38 step:29835[D loss: 0.407796, acc: 65.62%, op_acc: 39.06%] [G loss: 0.912081]\n",
      "epoch:38 step:29836[D loss: 0.423607, acc: 55.47%, op_acc: 41.41%] [G loss: 0.897258]\n",
      "epoch:38 step:29837[D loss: 0.399279, acc: 61.72%, op_acc: 42.97%] [G loss: 0.926079]\n",
      "epoch:38 step:29838[D loss: 0.417251, acc: 63.28%, op_acc: 37.50%] [G loss: 0.902545]\n",
      "epoch:38 step:29839[D loss: 0.412605, acc: 60.16%, op_acc: 45.31%] [G loss: 0.960272]\n",
      "epoch:38 step:29840[D loss: 0.415270, acc: 57.03%, op_acc: 42.97%] [G loss: 0.881390]\n",
      "epoch:38 step:29841[D loss: 0.427763, acc: 59.38%, op_acc: 42.97%] [G loss: 0.906964]\n",
      "epoch:38 step:29842[D loss: 0.454228, acc: 53.91%, op_acc: 35.16%] [G loss: 0.862374]\n",
      "epoch:38 step:29843[D loss: 0.413837, acc: 58.59%, op_acc: 42.97%] [G loss: 0.889231]\n",
      "epoch:38 step:29844[D loss: 0.411577, acc: 59.38%, op_acc: 42.19%] [G loss: 0.905427]\n",
      "epoch:38 step:29845[D loss: 0.431876, acc: 58.59%, op_acc: 43.75%] [G loss: 0.898018]\n",
      "epoch:38 step:29846[D loss: 0.416744, acc: 60.94%, op_acc: 46.09%] [G loss: 0.919906]\n",
      "epoch:38 step:29847[D loss: 0.440774, acc: 56.25%, op_acc: 36.72%] [G loss: 0.902291]\n",
      "epoch:38 step:29848[D loss: 0.394275, acc: 67.19%, op_acc: 46.09%] [G loss: 0.924156]\n",
      "epoch:38 step:29849[D loss: 0.438552, acc: 54.69%, op_acc: 41.41%] [G loss: 0.816356]\n",
      "epoch:38 step:29850[D loss: 0.407835, acc: 59.38%, op_acc: 42.19%] [G loss: 0.916014]\n",
      "##############\n",
      "[0.86551459 0.86757202 0.80580778 0.79634119 0.7997605  0.82871744\n",
      " 0.85966618 0.83923642 0.79756339 0.81821382]\n",
      "##########\n",
      "epoch:38 step:29851[D loss: 0.419421, acc: 58.59%, op_acc: 39.84%] [G loss: 0.865795]\n",
      "epoch:38 step:29852[D loss: 0.449024, acc: 59.38%, op_acc: 35.94%] [G loss: 0.918165]\n",
      "epoch:38 step:29853[D loss: 0.427247, acc: 59.38%, op_acc: 41.41%] [G loss: 0.825600]\n",
      "epoch:38 step:29854[D loss: 0.416450, acc: 61.72%, op_acc: 37.50%] [G loss: 0.953106]\n",
      "epoch:38 step:29855[D loss: 0.405141, acc: 61.72%, op_acc: 42.19%] [G loss: 0.854717]\n",
      "epoch:38 step:29856[D loss: 0.434043, acc: 60.16%, op_acc: 42.97%] [G loss: 0.872390]\n",
      "epoch:38 step:29857[D loss: 0.408690, acc: 66.41%, op_acc: 40.62%] [G loss: 0.905387]\n",
      "epoch:38 step:29858[D loss: 0.437615, acc: 61.72%, op_acc: 44.53%] [G loss: 0.959562]\n",
      "epoch:38 step:29859[D loss: 0.363543, acc: 69.53%, op_acc: 46.88%] [G loss: 0.982013]\n",
      "epoch:38 step:29860[D loss: 0.409474, acc: 56.25%, op_acc: 42.19%] [G loss: 0.902599]\n",
      "epoch:38 step:29861[D loss: 0.405227, acc: 56.25%, op_acc: 39.84%] [G loss: 0.975368]\n",
      "epoch:38 step:29862[D loss: 0.394628, acc: 67.19%, op_acc: 43.75%] [G loss: 0.943971]\n",
      "epoch:38 step:29863[D loss: 0.378352, acc: 71.88%, op_acc: 45.31%] [G loss: 0.971941]\n",
      "epoch:38 step:29864[D loss: 0.441818, acc: 53.91%, op_acc: 40.62%] [G loss: 0.906445]\n",
      "epoch:38 step:29865[D loss: 0.417475, acc: 57.03%, op_acc: 43.75%] [G loss: 0.998008]\n",
      "epoch:38 step:29866[D loss: 0.416104, acc: 60.16%, op_acc: 43.75%] [G loss: 0.902977]\n",
      "epoch:38 step:29867[D loss: 0.374174, acc: 71.09%, op_acc: 42.19%] [G loss: 1.011219]\n",
      "epoch:38 step:29868[D loss: 0.403555, acc: 61.72%, op_acc: 46.09%] [G loss: 0.929599]\n",
      "epoch:38 step:29869[D loss: 0.422379, acc: 56.25%, op_acc: 44.53%] [G loss: 0.860164]\n",
      "epoch:38 step:29870[D loss: 0.381985, acc: 66.41%, op_acc: 46.09%] [G loss: 0.903392]\n",
      "epoch:38 step:29871[D loss: 0.414670, acc: 68.75%, op_acc: 39.06%] [G loss: 0.903622]\n",
      "epoch:38 step:29872[D loss: 0.398523, acc: 59.38%, op_acc: 39.06%] [G loss: 0.839514]\n",
      "epoch:38 step:29873[D loss: 0.426785, acc: 62.50%, op_acc: 39.84%] [G loss: 0.902444]\n",
      "epoch:38 step:29874[D loss: 0.403608, acc: 63.28%, op_acc: 45.31%] [G loss: 0.951327]\n",
      "epoch:38 step:29875[D loss: 0.439720, acc: 59.38%, op_acc: 45.31%] [G loss: 0.925383]\n",
      "epoch:38 step:29876[D loss: 0.432355, acc: 61.72%, op_acc: 40.62%] [G loss: 0.936147]\n",
      "epoch:38 step:29877[D loss: 0.437406, acc: 50.00%, op_acc: 41.41%] [G loss: 0.840928]\n",
      "epoch:38 step:29878[D loss: 0.432996, acc: 59.38%, op_acc: 40.62%] [G loss: 0.908841]\n",
      "epoch:38 step:29879[D loss: 0.426173, acc: 50.78%, op_acc: 43.75%] [G loss: 0.762282]\n",
      "epoch:38 step:29880[D loss: 0.435334, acc: 52.34%, op_acc: 42.97%] [G loss: 0.913599]\n",
      "epoch:38 step:29881[D loss: 0.451695, acc: 53.91%, op_acc: 35.94%] [G loss: 0.914145]\n",
      "epoch:38 step:29882[D loss: 0.454251, acc: 59.38%, op_acc: 35.16%] [G loss: 0.864004]\n",
      "epoch:38 step:29883[D loss: 0.453424, acc: 56.25%, op_acc: 35.16%] [G loss: 0.915856]\n",
      "epoch:38 step:29884[D loss: 0.398217, acc: 60.94%, op_acc: 36.72%] [G loss: 0.895399]\n",
      "epoch:38 step:29885[D loss: 0.401687, acc: 53.91%, op_acc: 41.41%] [G loss: 0.832837]\n",
      "epoch:38 step:29886[D loss: 0.415661, acc: 62.50%, op_acc: 42.97%] [G loss: 0.903738]\n",
      "epoch:38 step:29887[D loss: 0.444036, acc: 48.44%, op_acc: 45.31%] [G loss: 0.872874]\n",
      "epoch:38 step:29888[D loss: 0.409884, acc: 58.59%, op_acc: 42.97%] [G loss: 0.917028]\n",
      "epoch:38 step:29889[D loss: 0.402215, acc: 56.25%, op_acc: 49.22%] [G loss: 0.889499]\n",
      "epoch:38 step:29890[D loss: 0.377889, acc: 67.19%, op_acc: 41.41%] [G loss: 0.895735]\n",
      "epoch:38 step:29891[D loss: 0.421143, acc: 57.81%, op_acc: 39.06%] [G loss: 0.910676]\n",
      "epoch:38 step:29892[D loss: 0.434913, acc: 60.94%, op_acc: 42.97%] [G loss: 0.882037]\n",
      "epoch:38 step:29893[D loss: 0.434238, acc: 60.94%, op_acc: 36.72%] [G loss: 0.842455]\n",
      "epoch:38 step:29894[D loss: 0.433832, acc: 56.25%, op_acc: 35.16%] [G loss: 0.868114]\n",
      "epoch:38 step:29895[D loss: 0.405871, acc: 58.59%, op_acc: 41.41%] [G loss: 0.890434]\n",
      "epoch:38 step:29896[D loss: 0.424049, acc: 59.38%, op_acc: 44.53%] [G loss: 0.890202]\n",
      "epoch:38 step:29897[D loss: 0.410031, acc: 52.34%, op_acc: 43.75%] [G loss: 0.935614]\n",
      "epoch:38 step:29898[D loss: 0.411617, acc: 62.50%, op_acc: 39.06%] [G loss: 0.913903]\n",
      "epoch:38 step:29899[D loss: 0.420868, acc: 57.03%, op_acc: 39.84%] [G loss: 0.882313]\n",
      "epoch:38 step:29900[D loss: 0.433263, acc: 52.34%, op_acc: 40.62%] [G loss: 0.843382]\n",
      "##############\n",
      "[0.8736528  0.86925424 0.81314305 0.81263633 0.79773023 0.80088198\n",
      " 0.8692406  0.84696086 0.8096945  0.82015053]\n",
      "##########\n",
      "epoch:38 step:29901[D loss: 0.438356, acc: 53.12%, op_acc: 41.41%] [G loss: 0.906691]\n",
      "epoch:38 step:29902[D loss: 0.403543, acc: 64.84%, op_acc: 41.41%] [G loss: 0.893633]\n",
      "epoch:38 step:29903[D loss: 0.404419, acc: 63.28%, op_acc: 42.97%] [G loss: 0.858483]\n",
      "epoch:38 step:29904[D loss: 0.409095, acc: 60.94%, op_acc: 45.31%] [G loss: 0.818712]\n",
      "epoch:38 step:29905[D loss: 0.410737, acc: 64.06%, op_acc: 45.31%] [G loss: 0.855073]\n",
      "epoch:38 step:29906[D loss: 0.410799, acc: 65.62%, op_acc: 42.97%] [G loss: 0.891400]\n",
      "epoch:38 step:29907[D loss: 0.416692, acc: 60.94%, op_acc: 38.28%] [G loss: 0.948902]\n",
      "epoch:38 step:29908[D loss: 0.427073, acc: 62.50%, op_acc: 43.75%] [G loss: 0.836991]\n",
      "epoch:38 step:29909[D loss: 0.402678, acc: 60.94%, op_acc: 40.62%] [G loss: 0.856946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29910[D loss: 0.410757, acc: 57.81%, op_acc: 47.66%] [G loss: 0.905105]\n",
      "epoch:38 step:29911[D loss: 0.393048, acc: 64.84%, op_acc: 47.66%] [G loss: 0.889124]\n",
      "epoch:38 step:29912[D loss: 0.397889, acc: 64.06%, op_acc: 41.41%] [G loss: 0.935175]\n",
      "epoch:38 step:29913[D loss: 0.418171, acc: 57.81%, op_acc: 39.84%] [G loss: 0.918913]\n",
      "epoch:38 step:29914[D loss: 0.430390, acc: 60.16%, op_acc: 34.38%] [G loss: 0.870274]\n",
      "epoch:38 step:29915[D loss: 0.402686, acc: 62.50%, op_acc: 39.06%] [G loss: 0.922036]\n",
      "epoch:38 step:29916[D loss: 0.426354, acc: 56.25%, op_acc: 38.28%] [G loss: 0.941043]\n",
      "epoch:38 step:29917[D loss: 0.400666, acc: 57.81%, op_acc: 43.75%] [G loss: 0.897640]\n",
      "epoch:38 step:29918[D loss: 0.414915, acc: 61.72%, op_acc: 45.31%] [G loss: 0.914880]\n",
      "epoch:38 step:29919[D loss: 0.406209, acc: 60.16%, op_acc: 42.19%] [G loss: 0.945828]\n",
      "epoch:38 step:29920[D loss: 0.401470, acc: 67.97%, op_acc: 40.62%] [G loss: 0.967328]\n",
      "epoch:38 step:29921[D loss: 0.424105, acc: 59.38%, op_acc: 43.75%] [G loss: 0.960303]\n",
      "epoch:38 step:29922[D loss: 0.436705, acc: 53.91%, op_acc: 42.97%] [G loss: 0.848512]\n",
      "epoch:38 step:29923[D loss: 0.398500, acc: 59.38%, op_acc: 41.41%] [G loss: 0.870299]\n",
      "epoch:38 step:29924[D loss: 0.441306, acc: 56.25%, op_acc: 32.03%] [G loss: 0.851941]\n",
      "epoch:38 step:29925[D loss: 0.401982, acc: 60.94%, op_acc: 39.84%] [G loss: 0.832862]\n",
      "epoch:38 step:29926[D loss: 0.469484, acc: 46.88%, op_acc: 36.72%] [G loss: 0.763362]\n",
      "epoch:38 step:29927[D loss: 0.414130, acc: 59.38%, op_acc: 38.28%] [G loss: 0.875343]\n",
      "epoch:38 step:29928[D loss: 0.432045, acc: 65.62%, op_acc: 39.06%] [G loss: 0.956691]\n",
      "epoch:38 step:29929[D loss: 0.419741, acc: 59.38%, op_acc: 45.31%] [G loss: 0.891535]\n",
      "epoch:38 step:29930[D loss: 0.430698, acc: 57.03%, op_acc: 41.41%] [G loss: 0.919744]\n",
      "epoch:38 step:29931[D loss: 0.392684, acc: 64.84%, op_acc: 42.97%] [G loss: 0.925864]\n",
      "epoch:38 step:29932[D loss: 0.398493, acc: 65.62%, op_acc: 37.50%] [G loss: 0.934358]\n",
      "epoch:38 step:29933[D loss: 0.452679, acc: 55.47%, op_acc: 39.84%] [G loss: 0.822305]\n",
      "epoch:38 step:29934[D loss: 0.443986, acc: 58.59%, op_acc: 36.72%] [G loss: 0.850601]\n",
      "epoch:38 step:29935[D loss: 0.423230, acc: 57.81%, op_acc: 40.62%] [G loss: 0.853082]\n",
      "epoch:38 step:29936[D loss: 0.416358, acc: 57.03%, op_acc: 42.19%] [G loss: 0.816807]\n",
      "epoch:38 step:29937[D loss: 0.443130, acc: 61.72%, op_acc: 39.06%] [G loss: 0.849071]\n",
      "epoch:38 step:29938[D loss: 0.430011, acc: 57.03%, op_acc: 37.50%] [G loss: 0.866389]\n",
      "epoch:38 step:29939[D loss: 0.403139, acc: 67.19%, op_acc: 41.41%] [G loss: 0.932797]\n",
      "epoch:38 step:29940[D loss: 0.387927, acc: 67.97%, op_acc: 50.00%] [G loss: 0.926683]\n",
      "epoch:38 step:29941[D loss: 0.411956, acc: 60.94%, op_acc: 39.84%] [G loss: 0.875317]\n",
      "epoch:38 step:29942[D loss: 0.384613, acc: 65.62%, op_acc: 46.88%] [G loss: 0.902006]\n",
      "epoch:38 step:29943[D loss: 0.437019, acc: 55.47%, op_acc: 36.72%] [G loss: 0.821966]\n",
      "epoch:38 step:29944[D loss: 0.400650, acc: 70.31%, op_acc: 39.06%] [G loss: 0.954690]\n",
      "epoch:38 step:29945[D loss: 0.460032, acc: 51.56%, op_acc: 41.41%] [G loss: 0.928190]\n",
      "epoch:38 step:29946[D loss: 0.377142, acc: 68.75%, op_acc: 47.66%] [G loss: 0.841005]\n",
      "epoch:38 step:29947[D loss: 0.421111, acc: 61.72%, op_acc: 40.62%] [G loss: 0.861552]\n",
      "epoch:38 step:29948[D loss: 0.411025, acc: 55.47%, op_acc: 39.06%] [G loss: 0.874844]\n",
      "epoch:38 step:29949[D loss: 0.421532, acc: 64.06%, op_acc: 39.06%] [G loss: 0.953061]\n",
      "epoch:38 step:29950[D loss: 0.422630, acc: 60.94%, op_acc: 37.50%] [G loss: 0.910308]\n",
      "##############\n",
      "[0.87303153 0.85513829 0.81969267 0.8012163  0.80631763 0.82371507\n",
      " 0.89787483 0.83045039 0.8216615  0.82830773]\n",
      "##########\n",
      "epoch:38 step:29951[D loss: 0.414859, acc: 53.91%, op_acc: 44.53%] [G loss: 0.874095]\n",
      "epoch:38 step:29952[D loss: 0.431720, acc: 57.03%, op_acc: 39.84%] [G loss: 0.886328]\n",
      "epoch:38 step:29953[D loss: 0.442399, acc: 51.56%, op_acc: 39.84%] [G loss: 0.908494]\n",
      "epoch:38 step:29954[D loss: 0.425236, acc: 56.25%, op_acc: 42.19%] [G loss: 0.898168]\n",
      "epoch:38 step:29955[D loss: 0.424416, acc: 63.28%, op_acc: 36.72%] [G loss: 0.919016]\n",
      "epoch:38 step:29956[D loss: 0.440576, acc: 63.28%, op_acc: 37.50%] [G loss: 0.845441]\n",
      "epoch:38 step:29957[D loss: 0.448123, acc: 58.59%, op_acc: 35.94%] [G loss: 0.957595]\n",
      "epoch:38 step:29958[D loss: 0.428961, acc: 53.12%, op_acc: 35.94%] [G loss: 0.902340]\n",
      "epoch:38 step:29959[D loss: 0.446372, acc: 51.56%, op_acc: 35.16%] [G loss: 0.872972]\n",
      "epoch:38 step:29960[D loss: 0.422458, acc: 54.69%, op_acc: 44.53%] [G loss: 0.836316]\n",
      "epoch:38 step:29961[D loss: 0.372980, acc: 67.97%, op_acc: 48.44%] [G loss: 0.866177]\n",
      "epoch:38 step:29962[D loss: 0.430907, acc: 62.50%, op_acc: 36.72%] [G loss: 0.887114]\n",
      "epoch:38 step:29963[D loss: 0.418329, acc: 59.38%, op_acc: 42.19%] [G loss: 0.848470]\n",
      "epoch:38 step:29964[D loss: 0.436981, acc: 60.94%, op_acc: 39.06%] [G loss: 0.910595]\n",
      "epoch:38 step:29965[D loss: 0.466870, acc: 56.25%, op_acc: 39.06%] [G loss: 0.878533]\n",
      "epoch:38 step:29966[D loss: 0.409202, acc: 63.28%, op_acc: 37.50%] [G loss: 0.786780]\n",
      "epoch:38 step:29967[D loss: 0.401262, acc: 60.94%, op_acc: 42.19%] [G loss: 0.869748]\n",
      "epoch:38 step:29968[D loss: 0.413467, acc: 60.16%, op_acc: 39.84%] [G loss: 0.900098]\n",
      "epoch:38 step:29969[D loss: 0.414428, acc: 60.94%, op_acc: 44.53%] [G loss: 0.857826]\n",
      "epoch:38 step:29970[D loss: 0.444390, acc: 52.34%, op_acc: 46.09%] [G loss: 0.808320]\n",
      "epoch:38 step:29971[D loss: 0.431019, acc: 51.56%, op_acc: 39.06%] [G loss: 0.865063]\n",
      "epoch:38 step:29972[D loss: 0.432757, acc: 50.78%, op_acc: 39.06%] [G loss: 0.867067]\n",
      "epoch:38 step:29973[D loss: 0.413333, acc: 57.81%, op_acc: 42.19%] [G loss: 0.930440]\n",
      "epoch:38 step:29974[D loss: 0.394989, acc: 64.06%, op_acc: 45.31%] [G loss: 0.901538]\n",
      "epoch:38 step:29975[D loss: 0.404248, acc: 62.50%, op_acc: 42.97%] [G loss: 0.922092]\n",
      "epoch:38 step:29976[D loss: 0.406347, acc: 64.06%, op_acc: 39.84%] [G loss: 0.839129]\n",
      "epoch:38 step:29977[D loss: 0.425726, acc: 61.72%, op_acc: 37.50%] [G loss: 0.851365]\n",
      "epoch:38 step:29978[D loss: 0.414664, acc: 64.06%, op_acc: 41.41%] [G loss: 0.835455]\n",
      "epoch:38 step:29979[D loss: 0.397900, acc: 60.94%, op_acc: 43.75%] [G loss: 0.962130]\n",
      "epoch:38 step:29980[D loss: 0.416762, acc: 62.50%, op_acc: 38.28%] [G loss: 0.916553]\n",
      "epoch:38 step:29981[D loss: 0.422079, acc: 58.59%, op_acc: 39.06%] [G loss: 0.884218]\n",
      "epoch:38 step:29982[D loss: 0.388954, acc: 70.31%, op_acc: 42.97%] [G loss: 0.853462]\n",
      "epoch:38 step:29983[D loss: 0.409225, acc: 57.03%, op_acc: 43.75%] [G loss: 0.870792]\n",
      "epoch:38 step:29984[D loss: 0.435280, acc: 61.72%, op_acc: 39.06%] [G loss: 0.857807]\n",
      "epoch:38 step:29985[D loss: 0.436193, acc: 56.25%, op_acc: 41.41%] [G loss: 0.874098]\n",
      "epoch:38 step:29986[D loss: 0.424847, acc: 59.38%, op_acc: 39.06%] [G loss: 0.950648]\n",
      "epoch:38 step:29987[D loss: 0.421809, acc: 60.94%, op_acc: 38.28%] [G loss: 0.958539]\n",
      "epoch:38 step:29988[D loss: 0.410048, acc: 65.62%, op_acc: 39.06%] [G loss: 0.902073]\n",
      "epoch:38 step:29989[D loss: 0.401515, acc: 64.06%, op_acc: 43.75%] [G loss: 0.930877]\n",
      "epoch:38 step:29990[D loss: 0.438166, acc: 53.12%, op_acc: 35.94%] [G loss: 0.907706]\n",
      "epoch:38 step:29991[D loss: 0.428423, acc: 56.25%, op_acc: 42.97%] [G loss: 0.952888]\n",
      "epoch:38 step:29992[D loss: 0.411667, acc: 62.50%, op_acc: 41.41%] [G loss: 0.891255]\n",
      "epoch:38 step:29993[D loss: 0.434818, acc: 50.78%, op_acc: 41.41%] [G loss: 0.939286]\n",
      "epoch:38 step:29994[D loss: 0.380448, acc: 66.41%, op_acc: 46.88%] [G loss: 0.981564]\n",
      "epoch:38 step:29995[D loss: 0.415907, acc: 63.28%, op_acc: 39.06%] [G loss: 0.830894]\n",
      "epoch:38 step:29996[D loss: 0.422788, acc: 61.72%, op_acc: 33.59%] [G loss: 0.897498]\n",
      "epoch:38 step:29997[D loss: 0.415329, acc: 57.81%, op_acc: 39.06%] [G loss: 0.906442]\n",
      "epoch:38 step:29998[D loss: 0.395641, acc: 65.62%, op_acc: 39.06%] [G loss: 0.850020]\n",
      "epoch:38 step:29999[D loss: 0.441971, acc: 57.81%, op_acc: 38.28%] [G loss: 0.875939]\n",
      "epoch:38 step:30000[D loss: 0.407349, acc: 66.41%, op_acc: 49.22%] [G loss: 0.883372]\n",
      "##############\n",
      "[0.85879605 0.86014383 0.82325505 0.8047997  0.81494363 0.83159837\n",
      " 0.88143709 0.82126855 0.79213333 0.81194141]\n",
      "##########\n",
      "epoch:38 step:30001[D loss: 0.412034, acc: 62.50%, op_acc: 40.62%] [G loss: 0.864025]\n",
      "epoch:38 step:30002[D loss: 0.431854, acc: 57.81%, op_acc: 35.94%] [G loss: 0.900853]\n",
      "epoch:38 step:30003[D loss: 0.400410, acc: 62.50%, op_acc: 36.72%] [G loss: 0.879190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30004[D loss: 0.418414, acc: 57.81%, op_acc: 38.28%] [G loss: 0.932527]\n",
      "epoch:38 step:30005[D loss: 0.406727, acc: 65.62%, op_acc: 39.84%] [G loss: 0.887334]\n",
      "epoch:38 step:30006[D loss: 0.432960, acc: 53.91%, op_acc: 44.53%] [G loss: 0.862134]\n",
      "epoch:38 step:30007[D loss: 0.388692, acc: 63.28%, op_acc: 39.84%] [G loss: 0.936257]\n",
      "epoch:38 step:30008[D loss: 0.394168, acc: 64.84%, op_acc: 42.19%] [G loss: 0.867071]\n",
      "epoch:38 step:30009[D loss: 0.436820, acc: 53.12%, op_acc: 38.28%] [G loss: 0.892260]\n",
      "epoch:38 step:30010[D loss: 0.416735, acc: 59.38%, op_acc: 39.06%] [G loss: 0.870720]\n",
      "epoch:38 step:30011[D loss: 0.399452, acc: 67.97%, op_acc: 37.50%] [G loss: 0.935037]\n",
      "epoch:38 step:30012[D loss: 0.417225, acc: 64.84%, op_acc: 42.19%] [G loss: 0.909685]\n",
      "epoch:38 step:30013[D loss: 0.422919, acc: 59.38%, op_acc: 35.94%] [G loss: 0.928940]\n",
      "epoch:38 step:30014[D loss: 0.422332, acc: 60.94%, op_acc: 35.94%] [G loss: 0.914774]\n",
      "epoch:38 step:30015[D loss: 0.426233, acc: 57.81%, op_acc: 39.06%] [G loss: 0.911122]\n",
      "epoch:38 step:30016[D loss: 0.381902, acc: 62.50%, op_acc: 46.09%] [G loss: 0.906147]\n",
      "epoch:38 step:30017[D loss: 0.431699, acc: 59.38%, op_acc: 37.50%] [G loss: 0.890561]\n",
      "epoch:38 step:30018[D loss: 0.423674, acc: 59.38%, op_acc: 42.19%] [G loss: 0.785128]\n",
      "epoch:38 step:30019[D loss: 0.411642, acc: 64.06%, op_acc: 42.19%] [G loss: 0.933843]\n",
      "epoch:38 step:30020[D loss: 0.431771, acc: 61.72%, op_acc: 36.72%] [G loss: 0.821457]\n",
      "epoch:38 step:30021[D loss: 0.412948, acc: 63.28%, op_acc: 38.28%] [G loss: 0.828302]\n",
      "epoch:38 step:30022[D loss: 0.435935, acc: 53.91%, op_acc: 40.62%] [G loss: 0.902673]\n",
      "epoch:38 step:30023[D loss: 0.416062, acc: 61.72%, op_acc: 39.06%] [G loss: 0.934457]\n",
      "epoch:38 step:30024[D loss: 0.408079, acc: 62.50%, op_acc: 40.62%] [G loss: 0.895505]\n",
      "epoch:38 step:30025[D loss: 0.381723, acc: 72.66%, op_acc: 40.62%] [G loss: 0.819006]\n",
      "epoch:38 step:30026[D loss: 0.409448, acc: 62.50%, op_acc: 35.94%] [G loss: 0.942758]\n",
      "epoch:38 step:30027[D loss: 0.390248, acc: 68.75%, op_acc: 48.44%] [G loss: 0.839688]\n",
      "epoch:38 step:30028[D loss: 0.392713, acc: 72.66%, op_acc: 44.53%] [G loss: 0.975637]\n",
      "epoch:38 step:30029[D loss: 0.443217, acc: 54.69%, op_acc: 37.50%] [G loss: 0.876585]\n",
      "epoch:38 step:30030[D loss: 0.436570, acc: 60.16%, op_acc: 36.72%] [G loss: 0.918360]\n",
      "epoch:38 step:30031[D loss: 0.381001, acc: 63.28%, op_acc: 39.84%] [G loss: 0.922284]\n",
      "epoch:38 step:30032[D loss: 0.406204, acc: 61.72%, op_acc: 43.75%] [G loss: 0.954931]\n",
      "epoch:38 step:30033[D loss: 0.419055, acc: 64.84%, op_acc: 37.50%] [G loss: 0.872717]\n",
      "epoch:38 step:30034[D loss: 0.429054, acc: 63.28%, op_acc: 35.94%] [G loss: 0.896236]\n",
      "epoch:38 step:30035[D loss: 0.392950, acc: 67.19%, op_acc: 43.75%] [G loss: 0.963787]\n",
      "epoch:38 step:30036[D loss: 0.400648, acc: 67.19%, op_acc: 40.62%] [G loss: 0.945255]\n",
      "epoch:38 step:30037[D loss: 0.420983, acc: 64.06%, op_acc: 37.50%] [G loss: 0.902026]\n",
      "epoch:38 step:30038[D loss: 0.428011, acc: 53.91%, op_acc: 39.06%] [G loss: 0.862990]\n",
      "epoch:38 step:30039[D loss: 0.378675, acc: 68.75%, op_acc: 46.88%] [G loss: 0.891776]\n",
      "epoch:38 step:30040[D loss: 0.383348, acc: 62.50%, op_acc: 46.88%] [G loss: 0.877466]\n",
      "epoch:38 step:30041[D loss: 0.433611, acc: 57.81%, op_acc: 36.72%] [G loss: 0.893165]\n",
      "epoch:38 step:30042[D loss: 0.388271, acc: 62.50%, op_acc: 41.41%] [G loss: 0.874826]\n",
      "epoch:38 step:30043[D loss: 0.389787, acc: 63.28%, op_acc: 51.56%] [G loss: 0.887302]\n",
      "epoch:38 step:30044[D loss: 0.384231, acc: 63.28%, op_acc: 52.34%] [G loss: 1.015036]\n",
      "epoch:38 step:30045[D loss: 0.425780, acc: 60.16%, op_acc: 37.50%] [G loss: 0.919247]\n",
      "epoch:38 step:30046[D loss: 0.406251, acc: 62.50%, op_acc: 38.28%] [G loss: 0.914992]\n",
      "epoch:38 step:30047[D loss: 0.413445, acc: 57.03%, op_acc: 41.41%] [G loss: 0.886433]\n",
      "epoch:38 step:30048[D loss: 0.424695, acc: 58.59%, op_acc: 37.50%] [G loss: 0.970466]\n",
      "epoch:38 step:30049[D loss: 0.390191, acc: 60.94%, op_acc: 48.44%] [G loss: 0.889030]\n",
      "epoch:38 step:30050[D loss: 0.417124, acc: 62.50%, op_acc: 42.97%] [G loss: 0.917956]\n",
      "##############\n",
      "[0.85316783 0.84101001 0.82257313 0.82137882 0.79821932 0.82528179\n",
      " 0.85765933 0.82659509 0.80208862 0.82296068]\n",
      "##########\n",
      "epoch:38 step:30051[D loss: 0.399087, acc: 60.16%, op_acc: 38.28%] [G loss: 0.952630]\n",
      "epoch:38 step:30052[D loss: 0.407303, acc: 59.38%, op_acc: 43.75%] [G loss: 0.878034]\n",
      "epoch:38 step:30053[D loss: 0.428039, acc: 59.38%, op_acc: 41.41%] [G loss: 0.882690]\n",
      "epoch:38 step:30054[D loss: 0.399733, acc: 64.06%, op_acc: 38.28%] [G loss: 0.895084]\n",
      "epoch:38 step:30055[D loss: 0.399696, acc: 65.62%, op_acc: 40.62%] [G loss: 0.857959]\n",
      "epoch:38 step:30056[D loss: 0.421411, acc: 61.72%, op_acc: 40.62%] [G loss: 0.892740]\n",
      "epoch:38 step:30057[D loss: 0.389442, acc: 68.75%, op_acc: 39.06%] [G loss: 0.943894]\n",
      "epoch:38 step:30058[D loss: 0.416411, acc: 63.28%, op_acc: 36.72%] [G loss: 0.828662]\n",
      "epoch:38 step:30059[D loss: 0.391386, acc: 67.97%, op_acc: 42.19%] [G loss: 0.969323]\n",
      "epoch:38 step:30060[D loss: 0.405808, acc: 61.72%, op_acc: 40.62%] [G loss: 0.906241]\n",
      "epoch:38 step:30061[D loss: 0.429526, acc: 59.38%, op_acc: 47.66%] [G loss: 0.847722]\n",
      "epoch:38 step:30062[D loss: 0.416631, acc: 62.50%, op_acc: 44.53%] [G loss: 0.932269]\n",
      "epoch:38 step:30063[D loss: 0.428571, acc: 55.47%, op_acc: 37.50%] [G loss: 0.865152]\n",
      "epoch:38 step:30064[D loss: 0.420807, acc: 53.91%, op_acc: 42.19%] [G loss: 0.901993]\n",
      "epoch:38 step:30065[D loss: 0.440867, acc: 60.94%, op_acc: 35.94%] [G loss: 0.910108]\n",
      "epoch:38 step:30066[D loss: 0.419770, acc: 65.62%, op_acc: 36.72%] [G loss: 0.914669]\n",
      "epoch:38 step:30067[D loss: 0.424304, acc: 57.03%, op_acc: 39.06%] [G loss: 0.843368]\n",
      "epoch:38 step:30068[D loss: 0.426444, acc: 55.47%, op_acc: 41.41%] [G loss: 0.860486]\n",
      "epoch:38 step:30069[D loss: 0.419244, acc: 50.78%, op_acc: 42.19%] [G loss: 0.810213]\n",
      "epoch:38 step:30070[D loss: 0.429720, acc: 57.03%, op_acc: 42.97%] [G loss: 0.885326]\n",
      "epoch:38 step:30071[D loss: 0.441372, acc: 52.34%, op_acc: 42.97%] [G loss: 0.855503]\n",
      "epoch:38 step:30072[D loss: 0.423750, acc: 58.59%, op_acc: 36.72%] [G loss: 0.880080]\n",
      "epoch:38 step:30073[D loss: 0.442533, acc: 57.81%, op_acc: 39.84%] [G loss: 0.867370]\n",
      "epoch:38 step:30074[D loss: 0.402402, acc: 64.06%, op_acc: 45.31%] [G loss: 0.813860]\n",
      "epoch:38 step:30075[D loss: 0.426649, acc: 57.03%, op_acc: 44.53%] [G loss: 0.836050]\n",
      "epoch:38 step:30076[D loss: 0.441343, acc: 54.69%, op_acc: 37.50%] [G loss: 0.910375]\n",
      "epoch:38 step:30077[D loss: 0.454402, acc: 50.00%, op_acc: 41.41%] [G loss: 0.840815]\n",
      "epoch:38 step:30078[D loss: 0.407720, acc: 58.59%, op_acc: 45.31%] [G loss: 0.919606]\n",
      "epoch:38 step:30079[D loss: 0.433111, acc: 56.25%, op_acc: 39.06%] [G loss: 0.913955]\n",
      "epoch:38 step:30080[D loss: 0.422284, acc: 62.50%, op_acc: 41.41%] [G loss: 0.886643]\n",
      "epoch:38 step:30081[D loss: 0.399587, acc: 64.06%, op_acc: 38.28%] [G loss: 0.886828]\n",
      "epoch:38 step:30082[D loss: 0.389977, acc: 62.50%, op_acc: 42.97%] [G loss: 0.854183]\n",
      "epoch:38 step:30083[D loss: 0.420188, acc: 64.06%, op_acc: 44.53%] [G loss: 0.866011]\n",
      "epoch:38 step:30084[D loss: 0.397669, acc: 60.94%, op_acc: 42.97%] [G loss: 0.923222]\n",
      "epoch:38 step:30085[D loss: 0.407167, acc: 64.06%, op_acc: 40.62%] [G loss: 0.996418]\n",
      "epoch:38 step:30086[D loss: 0.390533, acc: 67.19%, op_acc: 44.53%] [G loss: 0.918434]\n",
      "epoch:38 step:30087[D loss: 0.400994, acc: 61.72%, op_acc: 46.88%] [G loss: 0.883597]\n",
      "epoch:38 step:30088[D loss: 0.392748, acc: 65.62%, op_acc: 41.41%] [G loss: 0.921451]\n",
      "epoch:38 step:30089[D loss: 0.400768, acc: 62.50%, op_acc: 38.28%] [G loss: 0.958944]\n",
      "epoch:38 step:30090[D loss: 0.418119, acc: 57.03%, op_acc: 43.75%] [G loss: 0.876772]\n",
      "epoch:38 step:30091[D loss: 0.407364, acc: 60.94%, op_acc: 41.41%] [G loss: 0.919647]\n",
      "epoch:38 step:30092[D loss: 0.420375, acc: 55.47%, op_acc: 43.75%] [G loss: 0.844752]\n",
      "epoch:38 step:30093[D loss: 0.393852, acc: 64.06%, op_acc: 44.53%] [G loss: 0.925760]\n",
      "epoch:38 step:30094[D loss: 0.414836, acc: 62.50%, op_acc: 40.62%] [G loss: 0.898121]\n",
      "epoch:38 step:30095[D loss: 0.408109, acc: 63.28%, op_acc: 42.19%] [G loss: 0.827392]\n",
      "epoch:38 step:30096[D loss: 0.409941, acc: 59.38%, op_acc: 37.50%] [G loss: 0.884287]\n",
      "epoch:38 step:30097[D loss: 0.404941, acc: 64.06%, op_acc: 36.72%] [G loss: 0.790699]\n",
      "epoch:38 step:30098[D loss: 0.422361, acc: 57.03%, op_acc: 46.09%] [G loss: 0.879207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30099[D loss: 0.414191, acc: 63.28%, op_acc: 41.41%] [G loss: 0.843382]\n",
      "epoch:38 step:30100[D loss: 0.428524, acc: 53.91%, op_acc: 45.31%] [G loss: 0.872555]\n",
      "##############\n",
      "[0.85039666 0.87692254 0.8243463  0.82403537 0.79045221 0.8379624\n",
      " 0.88454683 0.80400857 0.80533198 0.81735472]\n",
      "##########\n",
      "epoch:38 step:30101[D loss: 0.436499, acc: 59.38%, op_acc: 42.97%] [G loss: 0.876678]\n",
      "epoch:38 step:30102[D loss: 0.428397, acc: 54.69%, op_acc: 42.97%] [G loss: 0.883204]\n",
      "epoch:38 step:30103[D loss: 0.442535, acc: 54.69%, op_acc: 41.41%] [G loss: 0.816296]\n",
      "epoch:38 step:30104[D loss: 0.455470, acc: 52.34%, op_acc: 39.84%] [G loss: 0.927051]\n",
      "epoch:38 step:30105[D loss: 0.437843, acc: 53.91%, op_acc: 39.06%] [G loss: 0.869141]\n",
      "epoch:38 step:30106[D loss: 0.419225, acc: 57.81%, op_acc: 45.31%] [G loss: 0.854838]\n",
      "epoch:38 step:30107[D loss: 0.415133, acc: 57.81%, op_acc: 42.19%] [G loss: 0.818662]\n",
      "epoch:38 step:30108[D loss: 0.421239, acc: 55.47%, op_acc: 45.31%] [G loss: 0.773330]\n",
      "epoch:38 step:30109[D loss: 0.449240, acc: 56.25%, op_acc: 40.62%] [G loss: 0.903426]\n",
      "epoch:38 step:30110[D loss: 0.392032, acc: 61.72%, op_acc: 46.88%] [G loss: 0.903466]\n",
      "epoch:38 step:30111[D loss: 0.417877, acc: 58.59%, op_acc: 43.75%] [G loss: 0.861146]\n",
      "epoch:38 step:30112[D loss: 0.390003, acc: 56.25%, op_acc: 46.09%] [G loss: 0.887872]\n",
      "epoch:38 step:30113[D loss: 0.418389, acc: 61.72%, op_acc: 41.41%] [G loss: 0.844535]\n",
      "epoch:38 step:30114[D loss: 0.453352, acc: 54.69%, op_acc: 36.72%] [G loss: 0.876018]\n",
      "epoch:38 step:30115[D loss: 0.442644, acc: 54.69%, op_acc: 40.62%] [G loss: 0.933044]\n",
      "epoch:38 step:30116[D loss: 0.408731, acc: 60.94%, op_acc: 43.75%] [G loss: 0.897099]\n",
      "epoch:38 step:30117[D loss: 0.426459, acc: 60.16%, op_acc: 35.16%] [G loss: 0.908478]\n",
      "epoch:38 step:30118[D loss: 0.398157, acc: 66.41%, op_acc: 39.06%] [G loss: 0.829842]\n",
      "epoch:38 step:30119[D loss: 0.440957, acc: 53.91%, op_acc: 34.38%] [G loss: 0.924361]\n",
      "epoch:38 step:30120[D loss: 0.397586, acc: 64.84%, op_acc: 42.19%] [G loss: 0.951318]\n",
      "epoch:38 step:30121[D loss: 0.432705, acc: 58.59%, op_acc: 42.97%] [G loss: 0.906899]\n",
      "epoch:38 step:30122[D loss: 0.366331, acc: 72.66%, op_acc: 45.31%] [G loss: 0.921082]\n",
      "epoch:38 step:30123[D loss: 0.425740, acc: 54.69%, op_acc: 39.84%] [G loss: 0.865693]\n",
      "epoch:38 step:30124[D loss: 0.426500, acc: 60.16%, op_acc: 43.75%] [G loss: 0.930204]\n",
      "epoch:38 step:30125[D loss: 0.440277, acc: 63.28%, op_acc: 35.94%] [G loss: 0.742626]\n",
      "epoch:38 step:30126[D loss: 0.412908, acc: 64.84%, op_acc: 39.06%] [G loss: 0.835078]\n",
      "epoch:38 step:30127[D loss: 0.413832, acc: 56.25%, op_acc: 41.41%] [G loss: 0.915046]\n",
      "epoch:38 step:30128[D loss: 0.439702, acc: 58.59%, op_acc: 35.16%] [G loss: 0.983048]\n",
      "epoch:38 step:30129[D loss: 0.418198, acc: 58.59%, op_acc: 42.19%] [G loss: 0.939091]\n",
      "epoch:38 step:30130[D loss: 0.396755, acc: 63.28%, op_acc: 48.44%] [G loss: 0.859689]\n",
      "epoch:38 step:30131[D loss: 0.416083, acc: 49.22%, op_acc: 42.97%] [G loss: 0.799697]\n",
      "epoch:38 step:30132[D loss: 0.425199, acc: 53.12%, op_acc: 42.19%] [G loss: 0.943255]\n",
      "epoch:38 step:30133[D loss: 0.409219, acc: 60.16%, op_acc: 40.62%] [G loss: 0.929341]\n",
      "epoch:38 step:30134[D loss: 0.451351, acc: 56.25%, op_acc: 38.28%] [G loss: 0.913723]\n",
      "epoch:38 step:30135[D loss: 0.422249, acc: 58.59%, op_acc: 39.06%] [G loss: 0.875250]\n",
      "epoch:38 step:30136[D loss: 0.371693, acc: 68.75%, op_acc: 41.41%] [G loss: 0.885427]\n",
      "epoch:38 step:30137[D loss: 0.405956, acc: 58.59%, op_acc: 44.53%] [G loss: 0.870055]\n",
      "epoch:38 step:30138[D loss: 0.381264, acc: 70.31%, op_acc: 45.31%] [G loss: 0.835130]\n",
      "epoch:38 step:30139[D loss: 0.443771, acc: 51.56%, op_acc: 42.19%] [G loss: 0.874953]\n",
      "epoch:38 step:30140[D loss: 0.382056, acc: 68.75%, op_acc: 39.84%] [G loss: 0.872628]\n",
      "epoch:38 step:30141[D loss: 0.429428, acc: 51.56%, op_acc: 41.41%] [G loss: 0.863148]\n",
      "epoch:38 step:30142[D loss: 0.411941, acc: 64.84%, op_acc: 39.06%] [G loss: 0.863369]\n",
      "epoch:38 step:30143[D loss: 0.452996, acc: 54.69%, op_acc: 36.72%] [G loss: 0.837860]\n",
      "epoch:38 step:30144[D loss: 0.402122, acc: 55.47%, op_acc: 42.97%] [G loss: 0.835525]\n",
      "epoch:38 step:30145[D loss: 0.434994, acc: 52.34%, op_acc: 41.41%] [G loss: 0.887516]\n",
      "epoch:38 step:30146[D loss: 0.402379, acc: 60.16%, op_acc: 46.88%] [G loss: 0.930636]\n",
      "epoch:38 step:30147[D loss: 0.381138, acc: 68.75%, op_acc: 42.97%] [G loss: 0.886456]\n",
      "epoch:38 step:30148[D loss: 0.404509, acc: 64.84%, op_acc: 40.62%] [G loss: 0.868653]\n",
      "epoch:38 step:30149[D loss: 0.418723, acc: 61.72%, op_acc: 40.62%] [G loss: 0.934196]\n",
      "epoch:38 step:30150[D loss: 0.454901, acc: 52.34%, op_acc: 40.62%] [G loss: 0.807704]\n",
      "##############\n",
      "[0.85359094 0.85471795 0.82517364 0.80323051 0.78036257 0.82378374\n",
      " 0.8685911  0.82269352 0.79698942 0.83329174]\n",
      "##########\n",
      "epoch:38 step:30151[D loss: 0.415962, acc: 51.56%, op_acc: 44.53%] [G loss: 0.878221]\n",
      "epoch:38 step:30152[D loss: 0.410132, acc: 70.31%, op_acc: 42.97%] [G loss: 0.882041]\n",
      "epoch:38 step:30153[D loss: 0.428494, acc: 51.56%, op_acc: 41.41%] [G loss: 0.870936]\n",
      "epoch:38 step:30154[D loss: 0.439490, acc: 58.59%, op_acc: 33.59%] [G loss: 0.975123]\n",
      "epoch:38 step:30155[D loss: 0.414860, acc: 64.84%, op_acc: 46.88%] [G loss: 0.869354]\n",
      "epoch:38 step:30156[D loss: 0.402291, acc: 59.38%, op_acc: 42.97%] [G loss: 0.901387]\n",
      "epoch:38 step:30157[D loss: 0.414085, acc: 58.59%, op_acc: 39.84%] [G loss: 0.961930]\n",
      "epoch:38 step:30158[D loss: 0.454364, acc: 57.03%, op_acc: 39.84%] [G loss: 0.823314]\n",
      "epoch:38 step:30159[D loss: 0.469790, acc: 48.44%, op_acc: 34.38%] [G loss: 0.857595]\n",
      "epoch:38 step:30160[D loss: 0.429644, acc: 56.25%, op_acc: 42.19%] [G loss: 0.847391]\n",
      "epoch:38 step:30161[D loss: 0.401082, acc: 66.41%, op_acc: 39.84%] [G loss: 0.815747]\n",
      "epoch:38 step:30162[D loss: 0.413007, acc: 60.94%, op_acc: 44.53%] [G loss: 0.890912]\n",
      "epoch:38 step:30163[D loss: 0.414772, acc: 64.84%, op_acc: 39.06%] [G loss: 0.904903]\n",
      "epoch:38 step:30164[D loss: 0.388538, acc: 65.62%, op_acc: 42.19%] [G loss: 0.866761]\n",
      "epoch:38 step:30165[D loss: 0.415388, acc: 57.03%, op_acc: 39.06%] [G loss: 0.871892]\n",
      "epoch:38 step:30166[D loss: 0.435077, acc: 54.69%, op_acc: 39.06%] [G loss: 0.813903]\n",
      "epoch:38 step:30167[D loss: 0.410818, acc: 54.69%, op_acc: 47.66%] [G loss: 0.872524]\n",
      "epoch:38 step:30168[D loss: 0.388762, acc: 63.28%, op_acc: 44.53%] [G loss: 0.811367]\n",
      "epoch:38 step:30169[D loss: 0.472254, acc: 55.47%, op_acc: 33.59%] [G loss: 0.876334]\n",
      "epoch:38 step:30170[D loss: 0.386645, acc: 68.75%, op_acc: 44.53%] [G loss: 0.950518]\n",
      "epoch:38 step:30171[D loss: 0.414561, acc: 60.94%, op_acc: 40.62%] [G loss: 0.850202]\n",
      "epoch:38 step:30172[D loss: 0.430684, acc: 56.25%, op_acc: 39.84%] [G loss: 0.890449]\n",
      "epoch:38 step:30173[D loss: 0.408581, acc: 61.72%, op_acc: 42.19%] [G loss: 0.836270]\n",
      "epoch:38 step:30174[D loss: 0.403280, acc: 57.81%, op_acc: 46.88%] [G loss: 0.919158]\n",
      "epoch:38 step:30175[D loss: 0.410356, acc: 55.47%, op_acc: 42.97%] [G loss: 0.884517]\n",
      "epoch:38 step:30176[D loss: 0.408630, acc: 65.62%, op_acc: 40.62%] [G loss: 0.929345]\n",
      "epoch:38 step:30177[D loss: 0.407206, acc: 67.19%, op_acc: 37.50%] [G loss: 0.862649]\n",
      "epoch:38 step:30178[D loss: 0.428047, acc: 53.91%, op_acc: 46.09%] [G loss: 0.879494]\n",
      "epoch:38 step:30179[D loss: 0.436942, acc: 56.25%, op_acc: 39.84%] [G loss: 0.930623]\n",
      "epoch:38 step:30180[D loss: 0.410035, acc: 60.94%, op_acc: 44.53%] [G loss: 0.910195]\n",
      "epoch:38 step:30181[D loss: 0.427167, acc: 60.94%, op_acc: 40.62%] [G loss: 0.913086]\n",
      "epoch:38 step:30182[D loss: 0.430196, acc: 56.25%, op_acc: 38.28%] [G loss: 0.868177]\n",
      "epoch:38 step:30183[D loss: 0.420068, acc: 62.50%, op_acc: 38.28%] [G loss: 0.840489]\n",
      "epoch:38 step:30184[D loss: 0.403138, acc: 61.72%, op_acc: 45.31%] [G loss: 0.899369]\n",
      "epoch:38 step:30185[D loss: 0.387814, acc: 61.72%, op_acc: 49.22%] [G loss: 0.852860]\n",
      "epoch:38 step:30186[D loss: 0.402710, acc: 57.81%, op_acc: 45.31%] [G loss: 0.946422]\n",
      "epoch:38 step:30187[D loss: 0.425686, acc: 59.38%, op_acc: 39.06%] [G loss: 0.752930]\n",
      "epoch:38 step:30188[D loss: 0.415778, acc: 64.06%, op_acc: 45.31%] [G loss: 0.895844]\n",
      "epoch:38 step:30189[D loss: 0.394932, acc: 61.72%, op_acc: 42.19%] [G loss: 0.893869]\n",
      "epoch:38 step:30190[D loss: 0.407489, acc: 66.41%, op_acc: 39.84%] [G loss: 0.918717]\n",
      "epoch:38 step:30191[D loss: 0.431066, acc: 60.94%, op_acc: 37.50%] [G loss: 0.912190]\n",
      "epoch:38 step:30192[D loss: 0.432883, acc: 50.00%, op_acc: 41.41%] [G loss: 0.860551]\n",
      "epoch:38 step:30193[D loss: 0.437016, acc: 59.38%, op_acc: 38.28%] [G loss: 0.924056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30194[D loss: 0.408025, acc: 66.41%, op_acc: 40.62%] [G loss: 0.898944]\n",
      "epoch:38 step:30195[D loss: 0.454275, acc: 57.81%, op_acc: 39.06%] [G loss: 0.831837]\n",
      "epoch:38 step:30196[D loss: 0.371333, acc: 71.88%, op_acc: 48.44%] [G loss: 0.828407]\n",
      "epoch:38 step:30197[D loss: 0.401248, acc: 63.28%, op_acc: 46.09%] [G loss: 0.909240]\n",
      "epoch:38 step:30198[D loss: 0.411340, acc: 58.59%, op_acc: 43.75%] [G loss: 0.895123]\n",
      "epoch:38 step:30199[D loss: 0.394621, acc: 63.28%, op_acc: 39.84%] [G loss: 0.965293]\n",
      "epoch:38 step:30200[D loss: 0.429099, acc: 58.59%, op_acc: 39.06%] [G loss: 0.865280]\n",
      "##############\n",
      "[0.87077691 0.84772743 0.79741839 0.7910479  0.77561045 0.82108634\n",
      " 0.89655528 0.82989589 0.80979505 0.84410463]\n",
      "##########\n",
      "epoch:38 step:30201[D loss: 0.418184, acc: 61.72%, op_acc: 39.84%] [G loss: 0.844283]\n",
      "epoch:38 step:30202[D loss: 0.442823, acc: 60.16%, op_acc: 35.16%] [G loss: 0.872701]\n",
      "epoch:38 step:30203[D loss: 0.422803, acc: 61.72%, op_acc: 35.94%] [G loss: 0.926975]\n",
      "epoch:38 step:30204[D loss: 0.438543, acc: 57.81%, op_acc: 33.59%] [G loss: 0.902437]\n",
      "epoch:38 step:30205[D loss: 0.423438, acc: 53.12%, op_acc: 41.41%] [G loss: 0.920072]\n",
      "epoch:38 step:30206[D loss: 0.410619, acc: 60.16%, op_acc: 41.41%] [G loss: 0.956327]\n",
      "epoch:38 step:30207[D loss: 0.389245, acc: 64.84%, op_acc: 43.75%] [G loss: 0.944385]\n",
      "epoch:38 step:30208[D loss: 0.404215, acc: 61.72%, op_acc: 42.19%] [G loss: 0.937747]\n",
      "epoch:38 step:30209[D loss: 0.418235, acc: 60.94%, op_acc: 35.16%] [G loss: 0.938398]\n",
      "epoch:38 step:30210[D loss: 0.411478, acc: 60.16%, op_acc: 40.62%] [G loss: 0.912930]\n",
      "epoch:38 step:30211[D loss: 0.420034, acc: 59.38%, op_acc: 42.97%] [G loss: 0.959286]\n",
      "epoch:38 step:30212[D loss: 0.420600, acc: 57.81%, op_acc: 39.84%] [G loss: 0.917984]\n",
      "epoch:38 step:30213[D loss: 0.415265, acc: 66.41%, op_acc: 37.50%] [G loss: 0.888754]\n",
      "epoch:38 step:30214[D loss: 0.394553, acc: 61.72%, op_acc: 50.00%] [G loss: 0.888425]\n",
      "epoch:38 step:30215[D loss: 0.412530, acc: 57.81%, op_acc: 46.88%] [G loss: 0.801913]\n",
      "epoch:38 step:30216[D loss: 0.413173, acc: 58.59%, op_acc: 41.41%] [G loss: 0.836418]\n",
      "epoch:38 step:30217[D loss: 0.444539, acc: 56.25%, op_acc: 35.94%] [G loss: 0.965356]\n",
      "epoch:38 step:30218[D loss: 0.413834, acc: 64.06%, op_acc: 41.41%] [G loss: 0.832530]\n",
      "epoch:38 step:30219[D loss: 0.383631, acc: 68.75%, op_acc: 46.88%] [G loss: 0.861246]\n",
      "epoch:38 step:30220[D loss: 0.447757, acc: 53.91%, op_acc: 37.50%] [G loss: 0.919601]\n",
      "epoch:38 step:30221[D loss: 0.440650, acc: 60.16%, op_acc: 35.94%] [G loss: 0.925195]\n",
      "epoch:38 step:30222[D loss: 0.417810, acc: 63.28%, op_acc: 41.41%] [G loss: 0.980902]\n",
      "epoch:38 step:30223[D loss: 0.393773, acc: 72.66%, op_acc: 42.19%] [G loss: 0.962590]\n",
      "epoch:38 step:30224[D loss: 0.437338, acc: 50.00%, op_acc: 39.84%] [G loss: 0.887647]\n",
      "epoch:38 step:30225[D loss: 0.425884, acc: 65.62%, op_acc: 38.28%] [G loss: 0.967545]\n",
      "epoch:38 step:30226[D loss: 0.426682, acc: 64.84%, op_acc: 39.06%] [G loss: 0.868065]\n",
      "epoch:38 step:30227[D loss: 0.411884, acc: 60.94%, op_acc: 45.31%] [G loss: 0.934810]\n",
      "epoch:38 step:30228[D loss: 0.414836, acc: 60.16%, op_acc: 36.72%] [G loss: 0.876654]\n",
      "epoch:38 step:30229[D loss: 0.395317, acc: 64.06%, op_acc: 46.88%] [G loss: 0.909978]\n",
      "epoch:38 step:30230[D loss: 0.442519, acc: 56.25%, op_acc: 37.50%] [G loss: 0.909220]\n",
      "epoch:38 step:30231[D loss: 0.396508, acc: 67.97%, op_acc: 40.62%] [G loss: 0.859874]\n",
      "epoch:38 step:30232[D loss: 0.425722, acc: 58.59%, op_acc: 35.16%] [G loss: 0.923605]\n",
      "epoch:38 step:30233[D loss: 0.388381, acc: 62.50%, op_acc: 46.88%] [G loss: 0.906694]\n",
      "epoch:38 step:30234[D loss: 0.403428, acc: 63.28%, op_acc: 42.19%] [G loss: 0.849693]\n",
      "epoch:38 step:30235[D loss: 0.412763, acc: 63.28%, op_acc: 33.59%] [G loss: 0.911131]\n",
      "epoch:38 step:30236[D loss: 0.376056, acc: 70.31%, op_acc: 43.75%] [G loss: 0.894756]\n",
      "epoch:38 step:30237[D loss: 0.389822, acc: 59.38%, op_acc: 41.41%] [G loss: 0.938910]\n",
      "epoch:38 step:30238[D loss: 0.438907, acc: 60.94%, op_acc: 39.06%] [G loss: 0.869649]\n",
      "epoch:38 step:30239[D loss: 0.431190, acc: 55.47%, op_acc: 43.75%] [G loss: 0.902117]\n",
      "epoch:38 step:30240[D loss: 0.440995, acc: 51.56%, op_acc: 38.28%] [G loss: 0.934153]\n",
      "epoch:38 step:30241[D loss: 0.418044, acc: 57.03%, op_acc: 38.28%] [G loss: 0.921221]\n",
      "epoch:38 step:30242[D loss: 0.398270, acc: 64.06%, op_acc: 45.31%] [G loss: 0.937234]\n",
      "epoch:38 step:30243[D loss: 0.443532, acc: 57.03%, op_acc: 41.41%] [G loss: 0.862620]\n",
      "epoch:38 step:30244[D loss: 0.400432, acc: 58.59%, op_acc: 42.19%] [G loss: 0.975676]\n",
      "epoch:38 step:30245[D loss: 0.377206, acc: 64.06%, op_acc: 46.88%] [G loss: 0.968240]\n",
      "epoch:38 step:30246[D loss: 0.436684, acc: 59.38%, op_acc: 42.19%] [G loss: 0.838307]\n",
      "epoch:38 step:30247[D loss: 0.383483, acc: 64.84%, op_acc: 42.97%] [G loss: 0.977389]\n",
      "epoch:38 step:30248[D loss: 0.400041, acc: 66.41%, op_acc: 40.62%] [G loss: 0.966857]\n",
      "epoch:38 step:30249[D loss: 0.412748, acc: 57.03%, op_acc: 43.75%] [G loss: 0.968956]\n",
      "epoch:38 step:30250[D loss: 0.401692, acc: 63.28%, op_acc: 41.41%] [G loss: 0.925595]\n",
      "##############\n",
      "[0.84316862 0.86020378 0.81115669 0.8078784  0.81138342 0.83116696\n",
      " 0.87407974 0.81742277 0.82547105 0.84451468]\n",
      "##########\n",
      "epoch:38 step:30251[D loss: 0.410035, acc: 58.59%, op_acc: 48.44%] [G loss: 0.847575]\n",
      "epoch:38 step:30252[D loss: 0.404755, acc: 63.28%, op_acc: 39.84%] [G loss: 0.905012]\n",
      "epoch:38 step:30253[D loss: 0.444760, acc: 52.34%, op_acc: 39.84%] [G loss: 0.875461]\n",
      "epoch:38 step:30254[D loss: 0.383421, acc: 64.06%, op_acc: 44.53%] [G loss: 0.926797]\n",
      "epoch:38 step:30255[D loss: 0.429711, acc: 60.94%, op_acc: 45.31%] [G loss: 0.919131]\n",
      "epoch:38 step:30256[D loss: 0.454830, acc: 58.59%, op_acc: 34.38%] [G loss: 0.954698]\n",
      "epoch:38 step:30257[D loss: 0.360534, acc: 65.62%, op_acc: 50.00%] [G loss: 0.899828]\n",
      "epoch:38 step:30258[D loss: 0.436411, acc: 53.91%, op_acc: 39.06%] [G loss: 0.819507]\n",
      "epoch:38 step:30259[D loss: 0.434581, acc: 52.34%, op_acc: 41.41%] [G loss: 0.899117]\n",
      "epoch:38 step:30260[D loss: 0.410457, acc: 62.50%, op_acc: 42.97%] [G loss: 0.900105]\n",
      "epoch:38 step:30261[D loss: 0.390479, acc: 69.53%, op_acc: 41.41%] [G loss: 0.942051]\n",
      "epoch:38 step:30262[D loss: 0.464514, acc: 57.03%, op_acc: 35.16%] [G loss: 0.860736]\n",
      "epoch:38 step:30263[D loss: 0.419736, acc: 57.81%, op_acc: 36.72%] [G loss: 0.950875]\n",
      "epoch:38 step:30264[D loss: 0.439907, acc: 57.81%, op_acc: 40.62%] [G loss: 0.872766]\n",
      "epoch:38 step:30265[D loss: 0.412506, acc: 61.72%, op_acc: 42.97%] [G loss: 0.857658]\n",
      "epoch:38 step:30266[D loss: 0.394453, acc: 63.28%, op_acc: 42.97%] [G loss: 0.923542]\n",
      "epoch:38 step:30267[D loss: 0.421076, acc: 55.47%, op_acc: 42.97%] [G loss: 0.879298]\n",
      "epoch:38 step:30268[D loss: 0.433474, acc: 57.81%, op_acc: 38.28%] [G loss: 0.909909]\n",
      "epoch:38 step:30269[D loss: 0.444965, acc: 53.12%, op_acc: 44.53%] [G loss: 0.861393]\n",
      "epoch:38 step:30270[D loss: 0.419331, acc: 62.50%, op_acc: 42.19%] [G loss: 0.915112]\n",
      "epoch:38 step:30271[D loss: 0.419119, acc: 60.94%, op_acc: 39.06%] [G loss: 0.813216]\n",
      "epoch:38 step:30272[D loss: 0.409207, acc: 64.06%, op_acc: 39.84%] [G loss: 0.877843]\n",
      "epoch:38 step:30273[D loss: 0.398605, acc: 66.41%, op_acc: 39.06%] [G loss: 0.916963]\n",
      "epoch:38 step:30274[D loss: 0.414864, acc: 54.69%, op_acc: 42.19%] [G loss: 0.887319]\n",
      "epoch:38 step:30275[D loss: 0.396434, acc: 63.28%, op_acc: 41.41%] [G loss: 0.857884]\n",
      "epoch:38 step:30276[D loss: 0.408661, acc: 60.94%, op_acc: 45.31%] [G loss: 0.863498]\n",
      "epoch:38 step:30277[D loss: 0.424092, acc: 62.50%, op_acc: 42.97%] [G loss: 0.850968]\n",
      "epoch:38 step:30278[D loss: 0.430208, acc: 58.59%, op_acc: 40.62%] [G loss: 0.845891]\n",
      "epoch:38 step:30279[D loss: 0.441399, acc: 53.12%, op_acc: 44.53%] [G loss: 0.777534]\n",
      "epoch:38 step:30280[D loss: 0.412754, acc: 61.72%, op_acc: 44.53%] [G loss: 0.896140]\n",
      "epoch:38 step:30281[D loss: 0.390558, acc: 63.28%, op_acc: 46.09%] [G loss: 0.962930]\n",
      "epoch:38 step:30282[D loss: 0.463329, acc: 50.78%, op_acc: 36.72%] [G loss: 0.901464]\n",
      "epoch:38 step:30283[D loss: 0.410690, acc: 58.59%, op_acc: 37.50%] [G loss: 0.957455]\n",
      "epoch:38 step:30284[D loss: 0.418355, acc: 52.34%, op_acc: 38.28%] [G loss: 0.859732]\n",
      "epoch:38 step:30285[D loss: 0.398503, acc: 57.81%, op_acc: 42.19%] [G loss: 0.987600]\n",
      "epoch:38 step:30286[D loss: 0.366098, acc: 67.19%, op_acc: 47.66%] [G loss: 0.865791]\n",
      "epoch:38 step:30287[D loss: 0.416697, acc: 57.81%, op_acc: 40.62%] [G loss: 0.864991]\n",
      "epoch:38 step:30288[D loss: 0.389138, acc: 64.84%, op_acc: 39.84%] [G loss: 0.868982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30289[D loss: 0.408492, acc: 59.38%, op_acc: 46.88%] [G loss: 0.884171]\n",
      "epoch:38 step:30290[D loss: 0.421636, acc: 63.28%, op_acc: 38.28%] [G loss: 0.914576]\n",
      "epoch:38 step:30291[D loss: 0.406429, acc: 53.91%, op_acc: 44.53%] [G loss: 0.846274]\n",
      "epoch:38 step:30292[D loss: 0.384902, acc: 71.88%, op_acc: 39.06%] [G loss: 0.871004]\n",
      "epoch:38 step:30293[D loss: 0.384766, acc: 66.41%, op_acc: 43.75%] [G loss: 0.971466]\n",
      "epoch:38 step:30294[D loss: 0.443142, acc: 53.91%, op_acc: 40.62%] [G loss: 0.860707]\n",
      "epoch:38 step:30295[D loss: 0.415521, acc: 57.03%, op_acc: 42.97%] [G loss: 0.923002]\n",
      "epoch:38 step:30296[D loss: 0.414024, acc: 53.91%, op_acc: 42.97%] [G loss: 0.886760]\n",
      "epoch:38 step:30297[D loss: 0.433719, acc: 54.69%, op_acc: 36.72%] [G loss: 0.922370]\n",
      "epoch:38 step:30298[D loss: 0.410409, acc: 64.84%, op_acc: 35.94%] [G loss: 0.946463]\n",
      "epoch:38 step:30299[D loss: 0.413337, acc: 63.28%, op_acc: 39.84%] [G loss: 0.790855]\n",
      "epoch:38 step:30300[D loss: 0.446418, acc: 58.59%, op_acc: 35.94%] [G loss: 0.907410]\n",
      "##############\n",
      "[0.86906991 0.8548115  0.81186148 0.80564317 0.7937974  0.81538686\n",
      " 0.87362511 0.82643955 0.78445748 0.83618631]\n",
      "##########\n",
      "epoch:38 step:30301[D loss: 0.422152, acc: 63.28%, op_acc: 40.62%] [G loss: 0.838349]\n",
      "epoch:38 step:30302[D loss: 0.404597, acc: 63.28%, op_acc: 45.31%] [G loss: 0.826064]\n",
      "epoch:38 step:30303[D loss: 0.406997, acc: 60.94%, op_acc: 43.75%] [G loss: 0.919782]\n",
      "epoch:38 step:30304[D loss: 0.361319, acc: 70.31%, op_acc: 44.53%] [G loss: 0.876564]\n",
      "epoch:38 step:30305[D loss: 0.402068, acc: 56.25%, op_acc: 47.66%] [G loss: 0.846866]\n",
      "epoch:38 step:30306[D loss: 0.388657, acc: 71.88%, op_acc: 42.19%] [G loss: 0.901064]\n",
      "epoch:38 step:30307[D loss: 0.419178, acc: 60.94%, op_acc: 41.41%] [G loss: 0.887167]\n",
      "epoch:38 step:30308[D loss: 0.397579, acc: 59.38%, op_acc: 47.66%] [G loss: 0.982687]\n",
      "epoch:38 step:30309[D loss: 0.422858, acc: 58.59%, op_acc: 39.06%] [G loss: 0.861976]\n",
      "epoch:38 step:30310[D loss: 0.409654, acc: 67.97%, op_acc: 35.94%] [G loss: 0.848567]\n",
      "epoch:38 step:30311[D loss: 0.455133, acc: 48.44%, op_acc: 41.41%] [G loss: 0.840231]\n",
      "epoch:38 step:30312[D loss: 0.404215, acc: 60.94%, op_acc: 42.97%] [G loss: 0.940510]\n",
      "epoch:38 step:30313[D loss: 0.431286, acc: 57.81%, op_acc: 42.19%] [G loss: 0.952172]\n",
      "epoch:38 step:30314[D loss: 0.402118, acc: 63.28%, op_acc: 39.06%] [G loss: 0.890580]\n",
      "epoch:38 step:30315[D loss: 0.413453, acc: 55.47%, op_acc: 47.66%] [G loss: 0.907669]\n",
      "epoch:38 step:30316[D loss: 0.448331, acc: 57.81%, op_acc: 35.16%] [G loss: 0.956090]\n",
      "epoch:38 step:30317[D loss: 0.445553, acc: 53.91%, op_acc: 40.62%] [G loss: 0.973510]\n",
      "epoch:38 step:30318[D loss: 0.426480, acc: 58.59%, op_acc: 35.94%] [G loss: 0.922898]\n",
      "epoch:38 step:30319[D loss: 0.403564, acc: 68.75%, op_acc: 35.16%] [G loss: 0.882576]\n",
      "epoch:38 step:30320[D loss: 0.413518, acc: 56.25%, op_acc: 45.31%] [G loss: 0.838757]\n",
      "epoch:38 step:30321[D loss: 0.434190, acc: 53.91%, op_acc: 38.28%] [G loss: 0.814416]\n",
      "epoch:38 step:30322[D loss: 0.399922, acc: 62.50%, op_acc: 44.53%] [G loss: 0.890300]\n",
      "epoch:38 step:30323[D loss: 0.405789, acc: 67.19%, op_acc: 39.06%] [G loss: 0.876920]\n",
      "epoch:38 step:30324[D loss: 0.422780, acc: 60.16%, op_acc: 35.94%] [G loss: 0.908780]\n",
      "epoch:38 step:30325[D loss: 0.378947, acc: 65.62%, op_acc: 48.44%] [G loss: 0.923615]\n",
      "epoch:38 step:30326[D loss: 0.398404, acc: 64.06%, op_acc: 43.75%] [G loss: 0.828536]\n",
      "epoch:38 step:30327[D loss: 0.400658, acc: 63.28%, op_acc: 37.50%] [G loss: 0.978198]\n",
      "epoch:38 step:30328[D loss: 0.444410, acc: 60.94%, op_acc: 35.94%] [G loss: 0.876817]\n",
      "epoch:38 step:30329[D loss: 0.416156, acc: 59.38%, op_acc: 41.41%] [G loss: 0.938748]\n",
      "epoch:38 step:30330[D loss: 0.379667, acc: 65.62%, op_acc: 44.53%] [G loss: 0.943134]\n",
      "epoch:38 step:30331[D loss: 0.368873, acc: 64.84%, op_acc: 47.66%] [G loss: 0.945157]\n",
      "epoch:38 step:30332[D loss: 0.425641, acc: 52.34%, op_acc: 39.06%] [G loss: 0.881811]\n",
      "epoch:38 step:30333[D loss: 0.408583, acc: 66.41%, op_acc: 38.28%] [G loss: 0.875818]\n",
      "epoch:38 step:30334[D loss: 0.433565, acc: 60.16%, op_acc: 39.84%] [G loss: 0.877329]\n",
      "epoch:38 step:30335[D loss: 0.431817, acc: 54.69%, op_acc: 39.84%] [G loss: 0.972298]\n",
      "epoch:38 step:30336[D loss: 0.420427, acc: 60.16%, op_acc: 36.72%] [G loss: 0.819353]\n",
      "epoch:38 step:30337[D loss: 0.388772, acc: 64.06%, op_acc: 35.94%] [G loss: 0.832638]\n",
      "epoch:38 step:30338[D loss: 0.425156, acc: 57.03%, op_acc: 38.28%] [G loss: 0.901660]\n",
      "epoch:38 step:30339[D loss: 0.414572, acc: 55.47%, op_acc: 50.78%] [G loss: 0.871489]\n",
      "epoch:38 step:30340[D loss: 0.412871, acc: 57.81%, op_acc: 40.62%] [G loss: 0.940737]\n",
      "epoch:38 step:30341[D loss: 0.389000, acc: 67.97%, op_acc: 43.75%] [G loss: 0.900925]\n",
      "epoch:38 step:30342[D loss: 0.397410, acc: 63.28%, op_acc: 43.75%] [G loss: 0.910352]\n",
      "epoch:38 step:30343[D loss: 0.426634, acc: 62.50%, op_acc: 37.50%] [G loss: 0.923467]\n",
      "epoch:38 step:30344[D loss: 0.417628, acc: 53.12%, op_acc: 37.50%] [G loss: 0.854104]\n",
      "epoch:38 step:30345[D loss: 0.382073, acc: 63.28%, op_acc: 40.62%] [G loss: 0.948692]\n",
      "epoch:38 step:30346[D loss: 0.421132, acc: 53.91%, op_acc: 40.62%] [G loss: 0.841632]\n",
      "epoch:38 step:30347[D loss: 0.431950, acc: 60.16%, op_acc: 35.94%] [G loss: 0.763560]\n",
      "epoch:38 step:30348[D loss: 0.420758, acc: 52.34%, op_acc: 46.09%] [G loss: 0.890967]\n",
      "epoch:38 step:30349[D loss: 0.404691, acc: 61.72%, op_acc: 37.50%] [G loss: 0.990475]\n",
      "epoch:38 step:30350[D loss: 0.437263, acc: 60.16%, op_acc: 38.28%] [G loss: 0.794511]\n",
      "##############\n",
      "[0.86373945 0.85751149 0.8197072  0.82121498 0.79268462 0.82763989\n",
      " 0.86241235 0.81994322 0.80926961 0.83848292]\n",
      "##########\n",
      "epoch:38 step:30351[D loss: 0.422747, acc: 64.84%, op_acc: 39.84%] [G loss: 0.831895]\n",
      "epoch:38 step:30352[D loss: 0.415720, acc: 55.47%, op_acc: 44.53%] [G loss: 0.828335]\n",
      "epoch:38 step:30353[D loss: 0.427046, acc: 56.25%, op_acc: 42.19%] [G loss: 0.867216]\n",
      "epoch:38 step:30354[D loss: 0.481854, acc: 53.12%, op_acc: 31.25%] [G loss: 0.759019]\n",
      "epoch:38 step:30355[D loss: 0.449597, acc: 50.78%, op_acc: 33.59%] [G loss: 0.875566]\n",
      "epoch:38 step:30356[D loss: 0.457614, acc: 50.78%, op_acc: 36.72%] [G loss: 0.839826]\n",
      "epoch:38 step:30357[D loss: 0.404364, acc: 59.38%, op_acc: 51.56%] [G loss: 0.862287]\n",
      "epoch:38 step:30358[D loss: 0.451617, acc: 53.12%, op_acc: 36.72%] [G loss: 0.848744]\n",
      "epoch:38 step:30359[D loss: 0.455712, acc: 51.56%, op_acc: 39.06%] [G loss: 0.895620]\n",
      "epoch:38 step:30360[D loss: 0.442790, acc: 54.69%, op_acc: 40.62%] [G loss: 0.875184]\n",
      "epoch:38 step:30361[D loss: 0.426958, acc: 53.91%, op_acc: 39.06%] [G loss: 0.871232]\n",
      "epoch:38 step:30362[D loss: 0.432930, acc: 54.69%, op_acc: 42.97%] [G loss: 0.867949]\n",
      "epoch:38 step:30363[D loss: 0.428571, acc: 50.00%, op_acc: 44.53%] [G loss: 0.886932]\n",
      "epoch:38 step:30364[D loss: 0.404628, acc: 60.94%, op_acc: 39.06%] [G loss: 0.900428]\n",
      "epoch:38 step:30365[D loss: 0.401923, acc: 64.06%, op_acc: 42.19%] [G loss: 0.920685]\n",
      "epoch:38 step:30366[D loss: 0.418190, acc: 57.81%, op_acc: 41.41%] [G loss: 0.868709]\n",
      "epoch:38 step:30367[D loss: 0.400990, acc: 60.16%, op_acc: 49.22%] [G loss: 0.887801]\n",
      "epoch:38 step:30368[D loss: 0.403542, acc: 64.84%, op_acc: 43.75%] [G loss: 0.943017]\n",
      "epoch:38 step:30369[D loss: 0.413776, acc: 62.50%, op_acc: 42.97%] [G loss: 0.878339]\n",
      "epoch:38 step:30370[D loss: 0.454900, acc: 50.78%, op_acc: 38.28%] [G loss: 0.970983]\n",
      "epoch:38 step:30371[D loss: 0.413459, acc: 62.50%, op_acc: 42.97%] [G loss: 0.854081]\n",
      "epoch:38 step:30372[D loss: 0.396241, acc: 63.28%, op_acc: 42.97%] [G loss: 0.902439]\n",
      "epoch:38 step:30373[D loss: 0.410741, acc: 62.50%, op_acc: 43.75%] [G loss: 0.887547]\n",
      "epoch:38 step:30374[D loss: 0.460833, acc: 51.56%, op_acc: 39.84%] [G loss: 0.875679]\n",
      "epoch:38 step:30375[D loss: 0.435092, acc: 58.59%, op_acc: 40.62%] [G loss: 0.825181]\n",
      "epoch:38 step:30376[D loss: 0.376709, acc: 68.75%, op_acc: 46.09%] [G loss: 0.903287]\n",
      "epoch:38 step:30377[D loss: 0.422370, acc: 59.38%, op_acc: 41.41%] [G loss: 0.890084]\n",
      "epoch:38 step:30378[D loss: 0.422459, acc: 61.72%, op_acc: 38.28%] [G loss: 0.900308]\n",
      "epoch:38 step:30379[D loss: 0.432782, acc: 51.56%, op_acc: 42.97%] [G loss: 0.896584]\n",
      "epoch:38 step:30380[D loss: 0.445311, acc: 50.78%, op_acc: 41.41%] [G loss: 0.815981]\n",
      "epoch:38 step:30381[D loss: 0.432859, acc: 58.59%, op_acc: 39.06%] [G loss: 0.838317]\n",
      "epoch:38 step:30382[D loss: 0.404643, acc: 57.03%, op_acc: 45.31%] [G loss: 0.841983]\n",
      "epoch:38 step:30383[D loss: 0.430991, acc: 61.72%, op_acc: 39.84%] [G loss: 0.845353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30384[D loss: 0.437294, acc: 59.38%, op_acc: 39.84%] [G loss: 0.848645]\n",
      "epoch:38 step:30385[D loss: 0.431321, acc: 57.81%, op_acc: 44.53%] [G loss: 0.878381]\n",
      "epoch:38 step:30386[D loss: 0.418064, acc: 59.38%, op_acc: 45.31%] [G loss: 0.987849]\n",
      "epoch:38 step:30387[D loss: 0.396439, acc: 64.06%, op_acc: 40.62%] [G loss: 0.887410]\n",
      "epoch:38 step:30388[D loss: 0.392335, acc: 58.59%, op_acc: 42.19%] [G loss: 0.925396]\n",
      "epoch:38 step:30389[D loss: 0.426643, acc: 57.03%, op_acc: 38.28%] [G loss: 0.891007]\n",
      "epoch:38 step:30390[D loss: 0.403244, acc: 57.81%, op_acc: 46.09%] [G loss: 0.855631]\n",
      "epoch:38 step:30391[D loss: 0.407531, acc: 61.72%, op_acc: 44.53%] [G loss: 0.864616]\n",
      "epoch:38 step:30392[D loss: 0.419961, acc: 64.84%, op_acc: 35.94%] [G loss: 0.921771]\n",
      "epoch:38 step:30393[D loss: 0.436269, acc: 53.91%, op_acc: 42.97%] [G loss: 0.916712]\n",
      "epoch:38 step:30394[D loss: 0.425400, acc: 53.91%, op_acc: 44.53%] [G loss: 0.899376]\n",
      "epoch:38 step:30395[D loss: 0.388328, acc: 56.25%, op_acc: 45.31%] [G loss: 0.810593]\n",
      "epoch:38 step:30396[D loss: 0.405519, acc: 64.84%, op_acc: 39.06%] [G loss: 0.943447]\n",
      "epoch:38 step:30397[D loss: 0.434898, acc: 57.03%, op_acc: 42.97%] [G loss: 0.854188]\n",
      "epoch:38 step:30398[D loss: 0.383787, acc: 61.72%, op_acc: 45.31%] [G loss: 0.985204]\n",
      "epoch:38 step:30399[D loss: 0.386013, acc: 66.41%, op_acc: 42.19%] [G loss: 0.895785]\n",
      "epoch:38 step:30400[D loss: 0.417735, acc: 51.56%, op_acc: 40.62%] [G loss: 0.835010]\n",
      "##############\n",
      "[0.85149484 0.87996996 0.80885254 0.80947158 0.78335118 0.79894005\n",
      " 0.88076438 0.85446686 0.80028156 0.83168167]\n",
      "##########\n",
      "epoch:38 step:30401[D loss: 0.402695, acc: 60.16%, op_acc: 48.44%] [G loss: 0.896095]\n",
      "epoch:38 step:30402[D loss: 0.437406, acc: 60.16%, op_acc: 33.59%] [G loss: 0.858462]\n",
      "epoch:38 step:30403[D loss: 0.409568, acc: 57.81%, op_acc: 43.75%] [G loss: 0.829247]\n",
      "epoch:38 step:30404[D loss: 0.402439, acc: 63.28%, op_acc: 46.88%] [G loss: 0.872921]\n",
      "epoch:38 step:30405[D loss: 0.449435, acc: 57.03%, op_acc: 34.38%] [G loss: 0.862423]\n",
      "epoch:38 step:30406[D loss: 0.421090, acc: 60.94%, op_acc: 35.94%] [G loss: 0.870329]\n",
      "epoch:38 step:30407[D loss: 0.403069, acc: 62.50%, op_acc: 43.75%] [G loss: 0.838261]\n",
      "epoch:38 step:30408[D loss: 0.412185, acc: 61.72%, op_acc: 40.62%] [G loss: 0.851105]\n",
      "epoch:38 step:30409[D loss: 0.403264, acc: 60.16%, op_acc: 42.19%] [G loss: 0.877229]\n",
      "epoch:38 step:30410[D loss: 0.412237, acc: 62.50%, op_acc: 40.62%] [G loss: 0.888705]\n",
      "epoch:38 step:30411[D loss: 0.397037, acc: 67.97%, op_acc: 40.62%] [G loss: 0.868431]\n",
      "epoch:38 step:30412[D loss: 0.415548, acc: 60.16%, op_acc: 42.19%] [G loss: 0.871521]\n",
      "epoch:38 step:30413[D loss: 0.413112, acc: 61.72%, op_acc: 45.31%] [G loss: 0.944775]\n",
      "epoch:38 step:30414[D loss: 0.418009, acc: 65.62%, op_acc: 35.94%] [G loss: 0.837879]\n",
      "epoch:38 step:30415[D loss: 0.411198, acc: 64.06%, op_acc: 44.53%] [G loss: 0.944003]\n",
      "epoch:38 step:30416[D loss: 0.400204, acc: 61.72%, op_acc: 42.19%] [G loss: 0.888288]\n",
      "epoch:38 step:30417[D loss: 0.385940, acc: 59.38%, op_acc: 42.97%] [G loss: 0.906716]\n",
      "epoch:38 step:30418[D loss: 0.377995, acc: 67.19%, op_acc: 46.09%] [G loss: 0.833382]\n",
      "epoch:38 step:30419[D loss: 0.420953, acc: 61.72%, op_acc: 39.06%] [G loss: 0.898992]\n",
      "epoch:38 step:30420[D loss: 0.450109, acc: 54.69%, op_acc: 36.72%] [G loss: 0.967414]\n",
      "epoch:38 step:30421[D loss: 0.405873, acc: 68.75%, op_acc: 43.75%] [G loss: 0.868997]\n",
      "epoch:38 step:30422[D loss: 0.394681, acc: 59.38%, op_acc: 46.88%] [G loss: 0.877929]\n",
      "epoch:38 step:30423[D loss: 0.439967, acc: 51.56%, op_acc: 47.66%] [G loss: 0.831192]\n",
      "epoch:38 step:30424[D loss: 0.440396, acc: 57.81%, op_acc: 39.84%] [G loss: 0.872910]\n",
      "epoch:38 step:30425[D loss: 0.398151, acc: 61.72%, op_acc: 47.66%] [G loss: 0.962972]\n",
      "epoch:38 step:30426[D loss: 0.409036, acc: 62.50%, op_acc: 35.94%] [G loss: 0.814897]\n",
      "epoch:38 step:30427[D loss: 0.436735, acc: 56.25%, op_acc: 35.94%] [G loss: 0.945813]\n",
      "epoch:38 step:30428[D loss: 0.407606, acc: 60.16%, op_acc: 39.84%] [G loss: 0.927431]\n",
      "epoch:38 step:30429[D loss: 0.450792, acc: 52.34%, op_acc: 35.94%] [G loss: 0.785189]\n",
      "epoch:38 step:30430[D loss: 0.410840, acc: 61.72%, op_acc: 45.31%] [G loss: 0.856324]\n",
      "epoch:38 step:30431[D loss: 0.402759, acc: 64.84%, op_acc: 44.53%] [G loss: 0.783978]\n",
      "epoch:38 step:30432[D loss: 0.425441, acc: 63.28%, op_acc: 40.62%] [G loss: 0.808853]\n",
      "epoch:38 step:30433[D loss: 0.406367, acc: 57.81%, op_acc: 44.53%] [G loss: 0.820763]\n",
      "epoch:38 step:30434[D loss: 0.426670, acc: 59.38%, op_acc: 41.41%] [G loss: 0.952834]\n",
      "epoch:38 step:30435[D loss: 0.396709, acc: 63.28%, op_acc: 46.09%] [G loss: 0.965581]\n",
      "epoch:38 step:30436[D loss: 0.407886, acc: 59.38%, op_acc: 41.41%] [G loss: 0.845359]\n",
      "epoch:38 step:30437[D loss: 0.412269, acc: 59.38%, op_acc: 44.53%] [G loss: 0.932428]\n",
      "epoch:38 step:30438[D loss: 0.412901, acc: 55.47%, op_acc: 40.62%] [G loss: 0.862130]\n",
      "epoch:38 step:30439[D loss: 0.431220, acc: 59.38%, op_acc: 40.62%] [G loss: 0.885580]\n",
      "epoch:38 step:30440[D loss: 0.421176, acc: 64.06%, op_acc: 39.84%] [G loss: 0.830339]\n",
      "epoch:38 step:30441[D loss: 0.439713, acc: 53.12%, op_acc: 45.31%] [G loss: 0.834835]\n",
      "epoch:38 step:30442[D loss: 0.405845, acc: 60.16%, op_acc: 46.88%] [G loss: 0.864736]\n",
      "epoch:38 step:30443[D loss: 0.411108, acc: 62.50%, op_acc: 44.53%] [G loss: 0.857081]\n",
      "epoch:38 step:30444[D loss: 0.433283, acc: 58.59%, op_acc: 37.50%] [G loss: 0.921453]\n",
      "epoch:38 step:30445[D loss: 0.406998, acc: 64.06%, op_acc: 44.53%] [G loss: 0.905258]\n",
      "epoch:38 step:30446[D loss: 0.410161, acc: 60.16%, op_acc: 42.97%] [G loss: 0.939581]\n",
      "epoch:38 step:30447[D loss: 0.371967, acc: 70.31%, op_acc: 45.31%] [G loss: 0.906635]\n",
      "epoch:38 step:30448[D loss: 0.450681, acc: 52.34%, op_acc: 35.94%] [G loss: 0.888680]\n",
      "epoch:38 step:30449[D loss: 0.432736, acc: 58.59%, op_acc: 42.19%] [G loss: 0.905142]\n",
      "epoch:38 step:30450[D loss: 0.419016, acc: 58.59%, op_acc: 46.09%] [G loss: 0.907174]\n",
      "##############\n",
      "[0.84342727 0.87673574 0.8038927  0.80507005 0.7999084  0.8085462\n",
      " 0.89884445 0.84072133 0.80448073 0.83593727]\n",
      "##########\n",
      "epoch:38 step:30451[D loss: 0.415370, acc: 61.72%, op_acc: 39.84%] [G loss: 0.895183]\n",
      "epoch:38 step:30452[D loss: 0.401020, acc: 64.84%, op_acc: 47.66%] [G loss: 0.849704]\n",
      "epoch:38 step:30453[D loss: 0.427820, acc: 56.25%, op_acc: 38.28%] [G loss: 0.867153]\n",
      "epoch:38 step:30454[D loss: 0.438332, acc: 63.28%, op_acc: 35.94%] [G loss: 0.882246]\n",
      "epoch:38 step:30455[D loss: 0.465884, acc: 53.91%, op_acc: 38.28%] [G loss: 0.903053]\n",
      "epoch:38 step:30456[D loss: 0.416178, acc: 52.34%, op_acc: 39.84%] [G loss: 1.008227]\n",
      "epoch:38 step:30457[D loss: 0.374413, acc: 71.09%, op_acc: 41.41%] [G loss: 0.905626]\n",
      "epoch:38 step:30458[D loss: 0.441817, acc: 50.00%, op_acc: 41.41%] [G loss: 0.873139]\n",
      "epoch:38 step:30459[D loss: 0.414423, acc: 63.28%, op_acc: 39.06%] [G loss: 0.968981]\n",
      "epoch:39 step:30460[D loss: 0.401875, acc: 67.19%, op_acc: 46.09%] [G loss: 0.938311]\n",
      "epoch:39 step:30461[D loss: 0.407897, acc: 56.25%, op_acc: 47.66%] [G loss: 0.920869]\n",
      "epoch:39 step:30462[D loss: 0.401128, acc: 62.50%, op_acc: 44.53%] [G loss: 0.846956]\n",
      "epoch:39 step:30463[D loss: 0.416733, acc: 54.69%, op_acc: 46.88%] [G loss: 0.936810]\n",
      "epoch:39 step:30464[D loss: 0.423448, acc: 53.91%, op_acc: 38.28%] [G loss: 0.813515]\n",
      "epoch:39 step:30465[D loss: 0.440588, acc: 59.38%, op_acc: 35.94%] [G loss: 0.848708]\n",
      "epoch:39 step:30466[D loss: 0.402588, acc: 60.94%, op_acc: 41.41%] [G loss: 0.946095]\n",
      "epoch:39 step:30467[D loss: 0.419074, acc: 58.59%, op_acc: 42.97%] [G loss: 0.906646]\n",
      "epoch:39 step:30468[D loss: 0.397523, acc: 56.25%, op_acc: 50.78%] [G loss: 0.973620]\n",
      "epoch:39 step:30469[D loss: 0.419760, acc: 59.38%, op_acc: 43.75%] [G loss: 0.793928]\n",
      "epoch:39 step:30470[D loss: 0.425604, acc: 61.72%, op_acc: 46.09%] [G loss: 0.911643]\n",
      "epoch:39 step:30471[D loss: 0.444153, acc: 58.59%, op_acc: 39.84%] [G loss: 0.905365]\n",
      "epoch:39 step:30472[D loss: 0.425100, acc: 57.03%, op_acc: 42.19%] [G loss: 0.970285]\n",
      "epoch:39 step:30473[D loss: 0.439330, acc: 50.78%, op_acc: 40.62%] [G loss: 0.890732]\n",
      "epoch:39 step:30474[D loss: 0.430944, acc: 48.44%, op_acc: 39.84%] [G loss: 0.827754]\n",
      "epoch:39 step:30475[D loss: 0.402098, acc: 55.47%, op_acc: 48.44%] [G loss: 0.912142]\n",
      "epoch:39 step:30476[D loss: 0.405839, acc: 63.28%, op_acc: 45.31%] [G loss: 0.894135]\n",
      "epoch:39 step:30477[D loss: 0.420520, acc: 57.03%, op_acc: 37.50%] [G loss: 0.869702]\n",
      "epoch:39 step:30478[D loss: 0.412315, acc: 59.38%, op_acc: 43.75%] [G loss: 0.898151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30479[D loss: 0.407193, acc: 59.38%, op_acc: 44.53%] [G loss: 0.863852]\n",
      "epoch:39 step:30480[D loss: 0.423305, acc: 54.69%, op_acc: 43.75%] [G loss: 0.786407]\n",
      "epoch:39 step:30481[D loss: 0.405235, acc: 61.72%, op_acc: 42.97%] [G loss: 0.878868]\n",
      "epoch:39 step:30482[D loss: 0.424149, acc: 57.81%, op_acc: 45.31%] [G loss: 0.821968]\n",
      "epoch:39 step:30483[D loss: 0.427091, acc: 57.03%, op_acc: 40.62%] [G loss: 0.880013]\n",
      "epoch:39 step:30484[D loss: 0.458736, acc: 55.47%, op_acc: 37.50%] [G loss: 0.835965]\n",
      "epoch:39 step:30485[D loss: 0.397599, acc: 61.72%, op_acc: 41.41%] [G loss: 0.815154]\n",
      "epoch:39 step:30486[D loss: 0.411768, acc: 62.50%, op_acc: 41.41%] [G loss: 0.824028]\n",
      "epoch:39 step:30487[D loss: 0.408197, acc: 59.38%, op_acc: 44.53%] [G loss: 0.958911]\n",
      "epoch:39 step:30488[D loss: 0.408318, acc: 63.28%, op_acc: 46.09%] [G loss: 0.971409]\n",
      "epoch:39 step:30489[D loss: 0.372926, acc: 60.94%, op_acc: 47.66%] [G loss: 0.886130]\n",
      "epoch:39 step:30490[D loss: 0.420888, acc: 63.28%, op_acc: 41.41%] [G loss: 1.034177]\n",
      "epoch:39 step:30491[D loss: 0.426084, acc: 60.94%, op_acc: 37.50%] [G loss: 0.880705]\n",
      "epoch:39 step:30492[D loss: 0.404650, acc: 56.25%, op_acc: 42.97%] [G loss: 0.899254]\n",
      "epoch:39 step:30493[D loss: 0.393097, acc: 64.06%, op_acc: 43.75%] [G loss: 0.979953]\n",
      "epoch:39 step:30494[D loss: 0.418462, acc: 58.59%, op_acc: 42.19%] [G loss: 0.874650]\n",
      "epoch:39 step:30495[D loss: 0.381103, acc: 64.06%, op_acc: 42.97%] [G loss: 0.885907]\n",
      "epoch:39 step:30496[D loss: 0.400977, acc: 63.28%, op_acc: 42.97%] [G loss: 0.935420]\n",
      "epoch:39 step:30497[D loss: 0.400125, acc: 65.62%, op_acc: 43.75%] [G loss: 0.957216]\n",
      "epoch:39 step:30498[D loss: 0.415214, acc: 57.03%, op_acc: 45.31%] [G loss: 0.927948]\n",
      "epoch:39 step:30499[D loss: 0.432088, acc: 54.69%, op_acc: 39.06%] [G loss: 0.775787]\n",
      "epoch:39 step:30500[D loss: 0.399606, acc: 56.25%, op_acc: 42.97%] [G loss: 0.889160]\n",
      "##############\n",
      "[0.85310456 0.87489477 0.81443618 0.80602863 0.78342223 0.8466735\n",
      " 0.87640783 0.81573135 0.80519355 0.82939374]\n",
      "##########\n",
      "epoch:39 step:30501[D loss: 0.406303, acc: 60.94%, op_acc: 44.53%] [G loss: 0.904927]\n",
      "epoch:39 step:30502[D loss: 0.401192, acc: 63.28%, op_acc: 39.84%] [G loss: 0.907348]\n",
      "epoch:39 step:30503[D loss: 0.442404, acc: 47.66%, op_acc: 41.41%] [G loss: 0.855283]\n",
      "epoch:39 step:30504[D loss: 0.437510, acc: 57.81%, op_acc: 43.75%] [G loss: 0.887312]\n",
      "epoch:39 step:30505[D loss: 0.424767, acc: 53.12%, op_acc: 45.31%] [G loss: 0.946553]\n",
      "epoch:39 step:30506[D loss: 0.413280, acc: 65.62%, op_acc: 42.97%] [G loss: 0.884880]\n",
      "epoch:39 step:30507[D loss: 0.431832, acc: 57.03%, op_acc: 36.72%] [G loss: 0.901881]\n",
      "epoch:39 step:30508[D loss: 0.412194, acc: 59.38%, op_acc: 42.97%] [G loss: 0.850360]\n",
      "epoch:39 step:30509[D loss: 0.424090, acc: 54.69%, op_acc: 42.19%] [G loss: 0.842255]\n",
      "epoch:39 step:30510[D loss: 0.413439, acc: 60.94%, op_acc: 42.19%] [G loss: 0.863615]\n",
      "epoch:39 step:30511[D loss: 0.421481, acc: 62.50%, op_acc: 35.94%] [G loss: 0.863325]\n",
      "epoch:39 step:30512[D loss: 0.430687, acc: 54.69%, op_acc: 41.41%] [G loss: 0.926330]\n",
      "epoch:39 step:30513[D loss: 0.441095, acc: 53.91%, op_acc: 41.41%] [G loss: 0.924663]\n",
      "epoch:39 step:30514[D loss: 0.402101, acc: 61.72%, op_acc: 46.88%] [G loss: 0.811065]\n",
      "epoch:39 step:30515[D loss: 0.425072, acc: 57.03%, op_acc: 36.72%] [G loss: 0.943743]\n",
      "epoch:39 step:30516[D loss: 0.441694, acc: 51.56%, op_acc: 36.72%] [G loss: 0.919779]\n",
      "epoch:39 step:30517[D loss: 0.408669, acc: 58.59%, op_acc: 46.09%] [G loss: 0.824201]\n",
      "epoch:39 step:30518[D loss: 0.385886, acc: 61.72%, op_acc: 47.66%] [G loss: 0.838986]\n",
      "epoch:39 step:30519[D loss: 0.420765, acc: 51.56%, op_acc: 39.84%] [G loss: 0.921376]\n",
      "epoch:39 step:30520[D loss: 0.436321, acc: 58.59%, op_acc: 39.84%] [G loss: 0.885384]\n",
      "epoch:39 step:30521[D loss: 0.425439, acc: 56.25%, op_acc: 39.06%] [G loss: 0.861185]\n",
      "epoch:39 step:30522[D loss: 0.433268, acc: 60.16%, op_acc: 36.72%] [G loss: 0.940019]\n",
      "epoch:39 step:30523[D loss: 0.401388, acc: 56.25%, op_acc: 46.88%] [G loss: 0.926004]\n",
      "epoch:39 step:30524[D loss: 0.454640, acc: 52.34%, op_acc: 37.50%] [G loss: 0.911078]\n",
      "epoch:39 step:30525[D loss: 0.403819, acc: 63.28%, op_acc: 43.75%] [G loss: 0.930573]\n",
      "epoch:39 step:30526[D loss: 0.403837, acc: 57.81%, op_acc: 40.62%] [G loss: 0.914860]\n",
      "epoch:39 step:30527[D loss: 0.435147, acc: 51.56%, op_acc: 39.84%] [G loss: 0.868370]\n",
      "epoch:39 step:30528[D loss: 0.368357, acc: 63.28%, op_acc: 49.22%] [G loss: 0.894251]\n",
      "epoch:39 step:30529[D loss: 0.428283, acc: 57.81%, op_acc: 42.19%] [G loss: 0.850214]\n",
      "epoch:39 step:30530[D loss: 0.444507, acc: 56.25%, op_acc: 39.06%] [G loss: 0.909618]\n",
      "epoch:39 step:30531[D loss: 0.385038, acc: 65.62%, op_acc: 44.53%] [G loss: 0.855774]\n",
      "epoch:39 step:30532[D loss: 0.420588, acc: 60.94%, op_acc: 39.06%] [G loss: 0.960487]\n",
      "epoch:39 step:30533[D loss: 0.392513, acc: 64.06%, op_acc: 42.19%] [G loss: 0.910879]\n",
      "epoch:39 step:30534[D loss: 0.389823, acc: 59.38%, op_acc: 43.75%] [G loss: 0.846483]\n",
      "epoch:39 step:30535[D loss: 0.442987, acc: 52.34%, op_acc: 42.19%] [G loss: 0.800533]\n",
      "epoch:39 step:30536[D loss: 0.421429, acc: 57.81%, op_acc: 39.84%] [G loss: 0.919709]\n",
      "epoch:39 step:30537[D loss: 0.474165, acc: 52.34%, op_acc: 34.38%] [G loss: 0.940664]\n",
      "epoch:39 step:30538[D loss: 0.393039, acc: 62.50%, op_acc: 44.53%] [G loss: 0.801007]\n",
      "epoch:39 step:30539[D loss: 0.452054, acc: 62.50%, op_acc: 33.59%] [G loss: 0.887796]\n",
      "epoch:39 step:30540[D loss: 0.400181, acc: 66.41%, op_acc: 35.94%] [G loss: 0.854076]\n",
      "epoch:39 step:30541[D loss: 0.398386, acc: 60.16%, op_acc: 45.31%] [G loss: 0.923030]\n",
      "epoch:39 step:30542[D loss: 0.420254, acc: 57.03%, op_acc: 39.84%] [G loss: 0.867302]\n",
      "epoch:39 step:30543[D loss: 0.413783, acc: 60.16%, op_acc: 40.62%] [G loss: 0.866223]\n",
      "epoch:39 step:30544[D loss: 0.440654, acc: 55.47%, op_acc: 36.72%] [G loss: 0.917866]\n",
      "epoch:39 step:30545[D loss: 0.401312, acc: 65.62%, op_acc: 42.19%] [G loss: 0.873587]\n",
      "epoch:39 step:30546[D loss: 0.407873, acc: 60.94%, op_acc: 39.84%] [G loss: 0.880720]\n",
      "epoch:39 step:30547[D loss: 0.425982, acc: 52.34%, op_acc: 42.19%] [G loss: 0.906628]\n",
      "epoch:39 step:30548[D loss: 0.430636, acc: 56.25%, op_acc: 42.19%] [G loss: 0.848204]\n",
      "epoch:39 step:30549[D loss: 0.377910, acc: 67.19%, op_acc: 47.66%] [G loss: 0.936327]\n",
      "epoch:39 step:30550[D loss: 0.415559, acc: 60.16%, op_acc: 43.75%] [G loss: 0.872736]\n",
      "##############\n",
      "[0.87066407 0.8657823  0.81326508 0.81725915 0.79328908 0.82337379\n",
      " 0.89030251 0.82850769 0.80116527 0.81855613]\n",
      "##########\n",
      "epoch:39 step:30551[D loss: 0.435012, acc: 53.91%, op_acc: 37.50%] [G loss: 0.905642]\n",
      "epoch:39 step:30552[D loss: 0.425443, acc: 57.03%, op_acc: 42.97%] [G loss: 0.903704]\n",
      "epoch:39 step:30553[D loss: 0.385884, acc: 65.62%, op_acc: 42.19%] [G loss: 0.870223]\n",
      "epoch:39 step:30554[D loss: 0.385912, acc: 64.06%, op_acc: 40.62%] [G loss: 0.856043]\n",
      "epoch:39 step:30555[D loss: 0.446459, acc: 57.81%, op_acc: 33.59%] [G loss: 0.801572]\n",
      "epoch:39 step:30556[D loss: 0.403138, acc: 67.97%, op_acc: 44.53%] [G loss: 0.880967]\n",
      "epoch:39 step:30557[D loss: 0.395486, acc: 65.62%, op_acc: 44.53%] [G loss: 0.902282]\n",
      "epoch:39 step:30558[D loss: 0.405909, acc: 64.84%, op_acc: 41.41%] [G loss: 0.906278]\n",
      "epoch:39 step:30559[D loss: 0.392865, acc: 63.28%, op_acc: 43.75%] [G loss: 0.917311]\n",
      "epoch:39 step:30560[D loss: 0.437944, acc: 50.00%, op_acc: 38.28%] [G loss: 0.874913]\n",
      "epoch:39 step:30561[D loss: 0.414517, acc: 65.62%, op_acc: 42.97%] [G loss: 0.945289]\n",
      "epoch:39 step:30562[D loss: 0.453019, acc: 53.12%, op_acc: 34.38%] [G loss: 0.850127]\n",
      "epoch:39 step:30563[D loss: 0.406987, acc: 64.06%, op_acc: 46.88%] [G loss: 0.940737]\n",
      "epoch:39 step:30564[D loss: 0.411585, acc: 61.72%, op_acc: 40.62%] [G loss: 0.812294]\n",
      "epoch:39 step:30565[D loss: 0.433554, acc: 57.81%, op_acc: 35.16%] [G loss: 0.890980]\n",
      "epoch:39 step:30566[D loss: 0.430435, acc: 57.03%, op_acc: 42.97%] [G loss: 0.863920]\n",
      "epoch:39 step:30567[D loss: 0.416884, acc: 63.28%, op_acc: 35.94%] [G loss: 0.921085]\n",
      "epoch:39 step:30568[D loss: 0.384550, acc: 60.94%, op_acc: 46.88%] [G loss: 0.863138]\n",
      "epoch:39 step:30569[D loss: 0.424394, acc: 53.91%, op_acc: 41.41%] [G loss: 0.824155]\n",
      "epoch:39 step:30570[D loss: 0.422540, acc: 60.94%, op_acc: 35.94%] [G loss: 0.931603]\n",
      "epoch:39 step:30571[D loss: 0.414827, acc: 60.94%, op_acc: 46.88%] [G loss: 0.892907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30572[D loss: 0.427759, acc: 55.47%, op_acc: 38.28%] [G loss: 0.864345]\n",
      "epoch:39 step:30573[D loss: 0.430475, acc: 53.91%, op_acc: 45.31%] [G loss: 0.861061]\n",
      "epoch:39 step:30574[D loss: 0.381625, acc: 62.50%, op_acc: 45.31%] [G loss: 0.866772]\n",
      "epoch:39 step:30575[D loss: 0.414232, acc: 58.59%, op_acc: 39.84%] [G loss: 0.950197]\n",
      "epoch:39 step:30576[D loss: 0.422908, acc: 56.25%, op_acc: 45.31%] [G loss: 0.874161]\n",
      "epoch:39 step:30577[D loss: 0.432306, acc: 60.16%, op_acc: 32.81%] [G loss: 0.860228]\n",
      "epoch:39 step:30578[D loss: 0.398160, acc: 66.41%, op_acc: 40.62%] [G loss: 0.971923]\n",
      "epoch:39 step:30579[D loss: 0.436034, acc: 56.25%, op_acc: 35.16%] [G loss: 0.926380]\n",
      "epoch:39 step:30580[D loss: 0.407297, acc: 67.19%, op_acc: 38.28%] [G loss: 0.875475]\n",
      "epoch:39 step:30581[D loss: 0.426685, acc: 61.72%, op_acc: 43.75%] [G loss: 0.918538]\n",
      "epoch:39 step:30582[D loss: 0.430323, acc: 57.81%, op_acc: 38.28%] [G loss: 0.879883]\n",
      "epoch:39 step:30583[D loss: 0.428480, acc: 50.00%, op_acc: 43.75%] [G loss: 0.944412]\n",
      "epoch:39 step:30584[D loss: 0.427551, acc: 60.16%, op_acc: 35.94%] [G loss: 0.921803]\n",
      "epoch:39 step:30585[D loss: 0.444588, acc: 48.44%, op_acc: 43.75%] [G loss: 0.866449]\n",
      "epoch:39 step:30586[D loss: 0.411234, acc: 60.16%, op_acc: 40.62%] [G loss: 0.923791]\n",
      "epoch:39 step:30587[D loss: 0.425460, acc: 60.94%, op_acc: 41.41%] [G loss: 0.888475]\n",
      "epoch:39 step:30588[D loss: 0.441135, acc: 50.78%, op_acc: 39.06%] [G loss: 0.833584]\n",
      "epoch:39 step:30589[D loss: 0.425452, acc: 57.81%, op_acc: 46.09%] [G loss: 0.912456]\n",
      "epoch:39 step:30590[D loss: 0.439380, acc: 52.34%, op_acc: 37.50%] [G loss: 0.846231]\n",
      "epoch:39 step:30591[D loss: 0.398419, acc: 56.25%, op_acc: 46.88%] [G loss: 0.877881]\n",
      "epoch:39 step:30592[D loss: 0.441798, acc: 60.94%, op_acc: 37.50%] [G loss: 0.917109]\n",
      "epoch:39 step:30593[D loss: 0.422633, acc: 61.72%, op_acc: 42.19%] [G loss: 0.879613]\n",
      "epoch:39 step:30594[D loss: 0.432380, acc: 58.59%, op_acc: 38.28%] [G loss: 0.889274]\n",
      "epoch:39 step:30595[D loss: 0.391306, acc: 65.62%, op_acc: 39.06%] [G loss: 0.916289]\n",
      "epoch:39 step:30596[D loss: 0.419482, acc: 59.38%, op_acc: 37.50%] [G loss: 0.995386]\n",
      "epoch:39 step:30597[D loss: 0.423108, acc: 60.16%, op_acc: 42.19%] [G loss: 0.939517]\n",
      "epoch:39 step:30598[D loss: 0.435845, acc: 50.78%, op_acc: 41.41%] [G loss: 0.844251]\n",
      "epoch:39 step:30599[D loss: 0.466331, acc: 53.91%, op_acc: 34.38%] [G loss: 0.900671]\n",
      "epoch:39 step:30600[D loss: 0.427510, acc: 64.06%, op_acc: 36.72%] [G loss: 0.781200]\n",
      "##############\n",
      "[0.86601235 0.87409182 0.81663867 0.79964029 0.77881159 0.8016508\n",
      " 0.87502236 0.83344014 0.80492191 0.83616739]\n",
      "##########\n",
      "epoch:39 step:30601[D loss: 0.418014, acc: 60.16%, op_acc: 42.97%] [G loss: 0.864138]\n",
      "epoch:39 step:30602[D loss: 0.417582, acc: 64.06%, op_acc: 45.31%] [G loss: 0.900098]\n",
      "epoch:39 step:30603[D loss: 0.437551, acc: 56.25%, op_acc: 38.28%] [G loss: 0.915325]\n",
      "epoch:39 step:30604[D loss: 0.408845, acc: 56.25%, op_acc: 42.19%] [G loss: 0.886305]\n",
      "epoch:39 step:30605[D loss: 0.427849, acc: 55.47%, op_acc: 39.06%] [G loss: 0.812461]\n",
      "epoch:39 step:30606[D loss: 0.422645, acc: 59.38%, op_acc: 42.97%] [G loss: 0.925534]\n",
      "epoch:39 step:30607[D loss: 0.420782, acc: 57.81%, op_acc: 42.97%] [G loss: 0.861888]\n",
      "epoch:39 step:30608[D loss: 0.386071, acc: 67.19%, op_acc: 44.53%] [G loss: 0.942092]\n",
      "epoch:39 step:30609[D loss: 0.390213, acc: 62.50%, op_acc: 39.84%] [G loss: 0.846615]\n",
      "epoch:39 step:30610[D loss: 0.408575, acc: 62.50%, op_acc: 42.97%] [G loss: 0.902910]\n",
      "epoch:39 step:30611[D loss: 0.404187, acc: 57.03%, op_acc: 46.09%] [G loss: 0.855700]\n",
      "epoch:39 step:30612[D loss: 0.405145, acc: 63.28%, op_acc: 46.09%] [G loss: 0.901598]\n",
      "epoch:39 step:30613[D loss: 0.410024, acc: 64.84%, op_acc: 35.94%] [G loss: 0.906739]\n",
      "epoch:39 step:30614[D loss: 0.403173, acc: 56.25%, op_acc: 43.75%] [G loss: 0.944565]\n",
      "epoch:39 step:30615[D loss: 0.419820, acc: 57.03%, op_acc: 38.28%] [G loss: 0.875102]\n",
      "epoch:39 step:30616[D loss: 0.442333, acc: 56.25%, op_acc: 40.62%] [G loss: 0.832843]\n",
      "epoch:39 step:30617[D loss: 0.422501, acc: 59.38%, op_acc: 42.19%] [G loss: 0.968408]\n",
      "epoch:39 step:30618[D loss: 0.421947, acc: 57.81%, op_acc: 44.53%] [G loss: 0.883509]\n",
      "epoch:39 step:30619[D loss: 0.424332, acc: 64.06%, op_acc: 39.84%] [G loss: 0.888508]\n",
      "epoch:39 step:30620[D loss: 0.436403, acc: 56.25%, op_acc: 37.50%] [G loss: 0.897472]\n",
      "epoch:39 step:30621[D loss: 0.389448, acc: 68.75%, op_acc: 39.06%] [G loss: 0.969877]\n",
      "epoch:39 step:30622[D loss: 0.400400, acc: 69.53%, op_acc: 39.06%] [G loss: 0.949882]\n",
      "epoch:39 step:30623[D loss: 0.426722, acc: 62.50%, op_acc: 37.50%] [G loss: 0.920192]\n",
      "epoch:39 step:30624[D loss: 0.404262, acc: 61.72%, op_acc: 39.84%] [G loss: 0.868866]\n",
      "epoch:39 step:30625[D loss: 0.420090, acc: 63.28%, op_acc: 42.19%] [G loss: 0.896391]\n",
      "epoch:39 step:30626[D loss: 0.413495, acc: 53.12%, op_acc: 42.19%] [G loss: 0.868509]\n",
      "epoch:39 step:30627[D loss: 0.402386, acc: 61.72%, op_acc: 45.31%] [G loss: 0.876088]\n",
      "epoch:39 step:30628[D loss: 0.406798, acc: 60.94%, op_acc: 44.53%] [G loss: 0.923431]\n",
      "epoch:39 step:30629[D loss: 0.426149, acc: 60.94%, op_acc: 40.62%] [G loss: 0.895912]\n",
      "epoch:39 step:30630[D loss: 0.442509, acc: 57.81%, op_acc: 38.28%] [G loss: 0.807418]\n",
      "epoch:39 step:30631[D loss: 0.386656, acc: 63.28%, op_acc: 46.09%] [G loss: 0.868212]\n",
      "epoch:39 step:30632[D loss: 0.423539, acc: 64.06%, op_acc: 33.59%] [G loss: 0.877563]\n",
      "epoch:39 step:30633[D loss: 0.422814, acc: 67.97%, op_acc: 34.38%] [G loss: 0.882438]\n",
      "epoch:39 step:30634[D loss: 0.429802, acc: 57.81%, op_acc: 41.41%] [G loss: 0.863077]\n",
      "epoch:39 step:30635[D loss: 0.417066, acc: 59.38%, op_acc: 44.53%] [G loss: 0.922680]\n",
      "epoch:39 step:30636[D loss: 0.402528, acc: 58.59%, op_acc: 41.41%] [G loss: 0.947422]\n",
      "epoch:39 step:30637[D loss: 0.382831, acc: 64.84%, op_acc: 47.66%] [G loss: 0.972379]\n",
      "epoch:39 step:30638[D loss: 0.408479, acc: 59.38%, op_acc: 47.66%] [G loss: 0.934039]\n",
      "epoch:39 step:30639[D loss: 0.434496, acc: 64.06%, op_acc: 35.94%] [G loss: 0.971708]\n",
      "epoch:39 step:30640[D loss: 0.402098, acc: 64.06%, op_acc: 45.31%] [G loss: 0.905841]\n",
      "epoch:39 step:30641[D loss: 0.381278, acc: 67.97%, op_acc: 46.09%] [G loss: 0.900584]\n",
      "epoch:39 step:30642[D loss: 0.394893, acc: 64.06%, op_acc: 42.19%] [G loss: 0.856749]\n",
      "epoch:39 step:30643[D loss: 0.413506, acc: 59.38%, op_acc: 39.84%] [G loss: 0.901409]\n",
      "epoch:39 step:30644[D loss: 0.388656, acc: 69.53%, op_acc: 37.50%] [G loss: 0.884927]\n",
      "epoch:39 step:30645[D loss: 0.423278, acc: 53.91%, op_acc: 46.09%] [G loss: 0.911334]\n",
      "epoch:39 step:30646[D loss: 0.391805, acc: 62.50%, op_acc: 42.19%] [G loss: 0.909127]\n",
      "epoch:39 step:30647[D loss: 0.442219, acc: 53.91%, op_acc: 39.06%] [G loss: 0.906970]\n",
      "epoch:39 step:30648[D loss: 0.396315, acc: 71.88%, op_acc: 39.84%] [G loss: 0.912341]\n",
      "epoch:39 step:30649[D loss: 0.430621, acc: 56.25%, op_acc: 38.28%] [G loss: 0.924806]\n",
      "epoch:39 step:30650[D loss: 0.410861, acc: 65.62%, op_acc: 43.75%] [G loss: 0.912903]\n",
      "##############\n",
      "[0.84790596 0.84148316 0.82592956 0.78795407 0.78166246 0.83472965\n",
      " 0.89891496 0.82279775 0.79688389 0.81384498]\n",
      "##########\n",
      "epoch:39 step:30651[D loss: 0.402316, acc: 66.41%, op_acc: 36.72%] [G loss: 0.905266]\n",
      "epoch:39 step:30652[D loss: 0.445756, acc: 57.81%, op_acc: 39.06%] [G loss: 0.823222]\n",
      "epoch:39 step:30653[D loss: 0.408878, acc: 64.06%, op_acc: 42.19%] [G loss: 0.911540]\n",
      "epoch:39 step:30654[D loss: 0.425095, acc: 53.91%, op_acc: 39.84%] [G loss: 0.887731]\n",
      "epoch:39 step:30655[D loss: 0.399677, acc: 68.75%, op_acc: 40.62%] [G loss: 0.892283]\n",
      "epoch:39 step:30656[D loss: 0.427877, acc: 59.38%, op_acc: 40.62%] [G loss: 0.839127]\n",
      "epoch:39 step:30657[D loss: 0.423117, acc: 60.94%, op_acc: 35.94%] [G loss: 0.952620]\n",
      "epoch:39 step:30658[D loss: 0.428002, acc: 59.38%, op_acc: 39.06%] [G loss: 0.897556]\n",
      "epoch:39 step:30659[D loss: 0.396989, acc: 62.50%, op_acc: 43.75%] [G loss: 0.962946]\n",
      "epoch:39 step:30660[D loss: 0.411953, acc: 55.47%, op_acc: 40.62%] [G loss: 0.819181]\n",
      "epoch:39 step:30661[D loss: 0.418540, acc: 63.28%, op_acc: 35.94%] [G loss: 0.845927]\n",
      "epoch:39 step:30662[D loss: 0.445644, acc: 55.47%, op_acc: 39.06%] [G loss: 0.816084]\n",
      "epoch:39 step:30663[D loss: 0.403891, acc: 67.19%, op_acc: 45.31%] [G loss: 0.880248]\n",
      "epoch:39 step:30664[D loss: 0.418153, acc: 60.94%, op_acc: 40.62%] [G loss: 0.950623]\n",
      "epoch:39 step:30665[D loss: 0.405102, acc: 57.81%, op_acc: 42.19%] [G loss: 0.850721]\n",
      "epoch:39 step:30666[D loss: 0.353920, acc: 74.22%, op_acc: 50.78%] [G loss: 0.855963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30667[D loss: 0.409307, acc: 61.72%, op_acc: 39.06%] [G loss: 0.944809]\n",
      "epoch:39 step:30668[D loss: 0.416677, acc: 60.16%, op_acc: 35.94%] [G loss: 0.870223]\n",
      "epoch:39 step:30669[D loss: 0.442505, acc: 57.03%, op_acc: 37.50%] [G loss: 0.869372]\n",
      "epoch:39 step:30670[D loss: 0.402128, acc: 61.72%, op_acc: 48.44%] [G loss: 0.835527]\n",
      "epoch:39 step:30671[D loss: 0.405979, acc: 65.62%, op_acc: 40.62%] [G loss: 0.898924]\n",
      "epoch:39 step:30672[D loss: 0.415489, acc: 62.50%, op_acc: 39.84%] [G loss: 0.896577]\n",
      "epoch:39 step:30673[D loss: 0.414881, acc: 58.59%, op_acc: 38.28%] [G loss: 0.916789]\n",
      "epoch:39 step:30674[D loss: 0.410778, acc: 67.19%, op_acc: 39.84%] [G loss: 0.847941]\n",
      "epoch:39 step:30675[D loss: 0.411032, acc: 61.72%, op_acc: 44.53%] [G loss: 0.966171]\n",
      "epoch:39 step:30676[D loss: 0.391353, acc: 66.41%, op_acc: 47.66%] [G loss: 0.893070]\n",
      "epoch:39 step:30677[D loss: 0.415154, acc: 60.94%, op_acc: 42.97%] [G loss: 0.910609]\n",
      "epoch:39 step:30678[D loss: 0.430702, acc: 59.38%, op_acc: 37.50%] [G loss: 0.898026]\n",
      "epoch:39 step:30679[D loss: 0.446698, acc: 55.47%, op_acc: 33.59%] [G loss: 0.858774]\n",
      "epoch:39 step:30680[D loss: 0.424067, acc: 57.81%, op_acc: 37.50%] [G loss: 0.947919]\n",
      "epoch:39 step:30681[D loss: 0.405495, acc: 70.31%, op_acc: 38.28%] [G loss: 0.895629]\n",
      "epoch:39 step:30682[D loss: 0.407406, acc: 63.28%, op_acc: 44.53%] [G loss: 0.989375]\n",
      "epoch:39 step:30683[D loss: 0.442026, acc: 57.81%, op_acc: 37.50%] [G loss: 0.839178]\n",
      "epoch:39 step:30684[D loss: 0.440552, acc: 64.06%, op_acc: 41.41%] [G loss: 0.873168]\n",
      "epoch:39 step:30685[D loss: 0.413668, acc: 56.25%, op_acc: 46.88%] [G loss: 0.930801]\n",
      "epoch:39 step:30686[D loss: 0.380224, acc: 71.09%, op_acc: 46.09%] [G loss: 0.918502]\n",
      "epoch:39 step:30687[D loss: 0.422400, acc: 57.81%, op_acc: 43.75%] [G loss: 0.891502]\n",
      "epoch:39 step:30688[D loss: 0.394570, acc: 64.84%, op_acc: 45.31%] [G loss: 0.901643]\n",
      "epoch:39 step:30689[D loss: 0.458647, acc: 59.38%, op_acc: 36.72%] [G loss: 0.882589]\n",
      "epoch:39 step:30690[D loss: 0.415482, acc: 58.59%, op_acc: 42.19%] [G loss: 0.882968]\n",
      "epoch:39 step:30691[D loss: 0.399746, acc: 58.59%, op_acc: 44.53%] [G loss: 0.922626]\n",
      "epoch:39 step:30692[D loss: 0.396665, acc: 67.97%, op_acc: 41.41%] [G loss: 0.820371]\n",
      "epoch:39 step:30693[D loss: 0.417050, acc: 64.84%, op_acc: 39.84%] [G loss: 0.857508]\n",
      "epoch:39 step:30694[D loss: 0.403536, acc: 59.38%, op_acc: 46.09%] [G loss: 0.914230]\n",
      "epoch:39 step:30695[D loss: 0.414796, acc: 64.84%, op_acc: 39.84%] [G loss: 0.933562]\n",
      "epoch:39 step:30696[D loss: 0.385972, acc: 64.84%, op_acc: 46.88%] [G loss: 0.844815]\n",
      "epoch:39 step:30697[D loss: 0.412669, acc: 64.84%, op_acc: 41.41%] [G loss: 0.969378]\n",
      "epoch:39 step:30698[D loss: 0.381773, acc: 70.31%, op_acc: 40.62%] [G loss: 0.922131]\n",
      "epoch:39 step:30699[D loss: 0.405750, acc: 67.97%, op_acc: 38.28%] [G loss: 0.946404]\n",
      "epoch:39 step:30700[D loss: 0.391199, acc: 67.97%, op_acc: 41.41%] [G loss: 0.943802]\n",
      "##############\n",
      "[0.84268868 0.84857186 0.82320276 0.81637284 0.79863873 0.83850592\n",
      " 0.88869489 0.83305734 0.79553806 0.84242665]\n",
      "##########\n",
      "epoch:39 step:30701[D loss: 0.417389, acc: 56.25%, op_acc: 46.88%] [G loss: 0.919759]\n",
      "epoch:39 step:30702[D loss: 0.414303, acc: 57.03%, op_acc: 43.75%] [G loss: 0.894445]\n",
      "epoch:39 step:30703[D loss: 0.418434, acc: 60.94%, op_acc: 40.62%] [G loss: 0.874015]\n",
      "epoch:39 step:30704[D loss: 0.394353, acc: 64.06%, op_acc: 48.44%] [G loss: 0.895837]\n",
      "epoch:39 step:30705[D loss: 0.423518, acc: 57.81%, op_acc: 38.28%] [G loss: 0.787290]\n",
      "epoch:39 step:30706[D loss: 0.391627, acc: 61.72%, op_acc: 42.19%] [G loss: 0.934990]\n",
      "epoch:39 step:30707[D loss: 0.405289, acc: 64.84%, op_acc: 42.19%] [G loss: 1.012246]\n",
      "epoch:39 step:30708[D loss: 0.427587, acc: 59.38%, op_acc: 40.62%] [G loss: 0.887746]\n",
      "epoch:39 step:30709[D loss: 0.425193, acc: 63.28%, op_acc: 38.28%] [G loss: 0.901942]\n",
      "epoch:39 step:30710[D loss: 0.413837, acc: 64.06%, op_acc: 43.75%] [G loss: 0.874317]\n",
      "epoch:39 step:30711[D loss: 0.422030, acc: 56.25%, op_acc: 43.75%] [G loss: 0.894751]\n",
      "epoch:39 step:30712[D loss: 0.405989, acc: 62.50%, op_acc: 40.62%] [G loss: 0.864238]\n",
      "epoch:39 step:30713[D loss: 0.402913, acc: 66.41%, op_acc: 37.50%] [G loss: 0.751844]\n",
      "epoch:39 step:30714[D loss: 0.405251, acc: 68.75%, op_acc: 39.84%] [G loss: 0.895284]\n",
      "epoch:39 step:30715[D loss: 0.397304, acc: 66.41%, op_acc: 46.88%] [G loss: 0.907279]\n",
      "epoch:39 step:30716[D loss: 0.406625, acc: 60.16%, op_acc: 43.75%] [G loss: 0.859202]\n",
      "epoch:39 step:30717[D loss: 0.401876, acc: 60.16%, op_acc: 45.31%] [G loss: 0.869484]\n",
      "epoch:39 step:30718[D loss: 0.414579, acc: 64.84%, op_acc: 40.62%] [G loss: 0.915201]\n",
      "epoch:39 step:30719[D loss: 0.429568, acc: 60.94%, op_acc: 36.72%] [G loss: 0.941112]\n",
      "epoch:39 step:30720[D loss: 0.413510, acc: 55.47%, op_acc: 37.50%] [G loss: 0.907221]\n",
      "epoch:39 step:30721[D loss: 0.385100, acc: 64.84%, op_acc: 43.75%] [G loss: 0.813721]\n",
      "epoch:39 step:30722[D loss: 0.419697, acc: 60.16%, op_acc: 41.41%] [G loss: 0.931870]\n",
      "epoch:39 step:30723[D loss: 0.417855, acc: 57.81%, op_acc: 39.84%] [G loss: 0.905918]\n",
      "epoch:39 step:30724[D loss: 0.379188, acc: 63.28%, op_acc: 46.09%] [G loss: 0.918529]\n",
      "epoch:39 step:30725[D loss: 0.427787, acc: 59.38%, op_acc: 43.75%] [G loss: 0.934960]\n",
      "epoch:39 step:30726[D loss: 0.478423, acc: 43.75%, op_acc: 41.41%] [G loss: 0.933449]\n",
      "epoch:39 step:30727[D loss: 0.397637, acc: 60.94%, op_acc: 45.31%] [G loss: 0.918881]\n",
      "epoch:39 step:30728[D loss: 0.391960, acc: 64.84%, op_acc: 42.19%] [G loss: 0.896327]\n",
      "epoch:39 step:30729[D loss: 0.398878, acc: 68.75%, op_acc: 38.28%] [G loss: 0.992244]\n",
      "epoch:39 step:30730[D loss: 0.407664, acc: 62.50%, op_acc: 40.62%] [G loss: 0.859997]\n",
      "epoch:39 step:30731[D loss: 0.395566, acc: 69.53%, op_acc: 40.62%] [G loss: 0.967615]\n",
      "epoch:39 step:30732[D loss: 0.401535, acc: 60.94%, op_acc: 39.84%] [G loss: 0.934654]\n",
      "epoch:39 step:30733[D loss: 0.423320, acc: 58.59%, op_acc: 41.41%] [G loss: 0.937443]\n",
      "epoch:39 step:30734[D loss: 0.404055, acc: 64.84%, op_acc: 42.97%] [G loss: 0.932989]\n",
      "epoch:39 step:30735[D loss: 0.428809, acc: 50.78%, op_acc: 34.38%] [G loss: 0.894137]\n",
      "epoch:39 step:30736[D loss: 0.420693, acc: 64.06%, op_acc: 35.94%] [G loss: 0.967469]\n",
      "epoch:39 step:30737[D loss: 0.419086, acc: 64.84%, op_acc: 39.84%] [G loss: 0.928498]\n",
      "epoch:39 step:30738[D loss: 0.388476, acc: 69.53%, op_acc: 45.31%] [G loss: 1.039368]\n",
      "epoch:39 step:30739[D loss: 0.408203, acc: 54.69%, op_acc: 40.62%] [G loss: 0.935314]\n",
      "epoch:39 step:30740[D loss: 0.416100, acc: 60.16%, op_acc: 42.97%] [G loss: 0.863335]\n",
      "epoch:39 step:30741[D loss: 0.433611, acc: 62.50%, op_acc: 39.84%] [G loss: 0.847760]\n",
      "epoch:39 step:30742[D loss: 0.423015, acc: 50.78%, op_acc: 39.06%] [G loss: 0.871155]\n",
      "epoch:39 step:30743[D loss: 0.404301, acc: 66.41%, op_acc: 46.88%] [G loss: 0.876140]\n",
      "epoch:39 step:30744[D loss: 0.434869, acc: 57.81%, op_acc: 40.62%] [G loss: 0.835113]\n",
      "epoch:39 step:30745[D loss: 0.441691, acc: 50.00%, op_acc: 37.50%] [G loss: 0.834126]\n",
      "epoch:39 step:30746[D loss: 0.423580, acc: 58.59%, op_acc: 39.84%] [G loss: 0.816340]\n",
      "epoch:39 step:30747[D loss: 0.379227, acc: 65.62%, op_acc: 44.53%] [G loss: 0.850441]\n",
      "epoch:39 step:30748[D loss: 0.436648, acc: 52.34%, op_acc: 39.06%] [G loss: 0.816519]\n",
      "epoch:39 step:30749[D loss: 0.422253, acc: 62.50%, op_acc: 41.41%] [G loss: 0.956701]\n",
      "epoch:39 step:30750[D loss: 0.433199, acc: 50.78%, op_acc: 40.62%] [G loss: 0.797505]\n",
      "##############\n",
      "[0.86205192 0.86384017 0.81052086 0.81344318 0.797565   0.85447439\n",
      " 0.87722513 0.84469823 0.79445147 0.82565565]\n",
      "##########\n",
      "epoch:39 step:30751[D loss: 0.416021, acc: 63.28%, op_acc: 40.62%] [G loss: 0.742527]\n",
      "epoch:39 step:30752[D loss: 0.385635, acc: 64.84%, op_acc: 42.97%] [G loss: 0.964884]\n",
      "epoch:39 step:30753[D loss: 0.430259, acc: 50.78%, op_acc: 42.19%] [G loss: 0.890056]\n",
      "epoch:39 step:30754[D loss: 0.389996, acc: 64.84%, op_acc: 39.06%] [G loss: 0.848040]\n",
      "epoch:39 step:30755[D loss: 0.393139, acc: 64.84%, op_acc: 42.97%] [G loss: 0.935245]\n",
      "epoch:39 step:30756[D loss: 0.419153, acc: 60.94%, op_acc: 35.94%] [G loss: 0.931423]\n",
      "epoch:39 step:30757[D loss: 0.406800, acc: 60.16%, op_acc: 42.97%] [G loss: 0.917496]\n",
      "epoch:39 step:30758[D loss: 0.390602, acc: 65.62%, op_acc: 44.53%] [G loss: 0.931132]\n",
      "epoch:39 step:30759[D loss: 0.414644, acc: 66.41%, op_acc: 36.72%] [G loss: 0.859221]\n",
      "epoch:39 step:30760[D loss: 0.389294, acc: 65.62%, op_acc: 44.53%] [G loss: 0.973745]\n",
      "epoch:39 step:30761[D loss: 0.408003, acc: 57.81%, op_acc: 44.53%] [G loss: 0.874172]\n",
      "epoch:39 step:30762[D loss: 0.423553, acc: 58.59%, op_acc: 39.84%] [G loss: 0.911940]\n",
      "epoch:39 step:30763[D loss: 0.387511, acc: 62.50%, op_acc: 42.19%] [G loss: 0.875639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30764[D loss: 0.382468, acc: 70.31%, op_acc: 42.19%] [G loss: 0.950121]\n",
      "epoch:39 step:30765[D loss: 0.417688, acc: 64.06%, op_acc: 46.09%] [G loss: 0.938709]\n",
      "epoch:39 step:30766[D loss: 0.391630, acc: 74.22%, op_acc: 39.84%] [G loss: 0.955456]\n",
      "epoch:39 step:30767[D loss: 0.435658, acc: 56.25%, op_acc: 40.62%] [G loss: 0.866194]\n",
      "epoch:39 step:30768[D loss: 0.443214, acc: 55.47%, op_acc: 36.72%] [G loss: 0.861094]\n",
      "epoch:39 step:30769[D loss: 0.400472, acc: 61.72%, op_acc: 39.06%] [G loss: 0.911604]\n",
      "epoch:39 step:30770[D loss: 0.428511, acc: 61.72%, op_acc: 41.41%] [G loss: 0.925310]\n",
      "epoch:39 step:30771[D loss: 0.425536, acc: 57.03%, op_acc: 43.75%] [G loss: 0.925993]\n",
      "epoch:39 step:30772[D loss: 0.425082, acc: 57.03%, op_acc: 42.19%] [G loss: 0.848677]\n",
      "epoch:39 step:30773[D loss: 0.440210, acc: 53.12%, op_acc: 41.41%] [G loss: 0.928779]\n",
      "epoch:39 step:30774[D loss: 0.424758, acc: 56.25%, op_acc: 39.84%] [G loss: 0.905164]\n",
      "epoch:39 step:30775[D loss: 0.407440, acc: 61.72%, op_acc: 41.41%] [G loss: 0.787909]\n",
      "epoch:39 step:30776[D loss: 0.431328, acc: 57.81%, op_acc: 40.62%] [G loss: 0.844600]\n",
      "epoch:39 step:30777[D loss: 0.448590, acc: 56.25%, op_acc: 36.72%] [G loss: 0.759241]\n",
      "epoch:39 step:30778[D loss: 0.406621, acc: 60.94%, op_acc: 40.62%] [G loss: 0.863339]\n",
      "epoch:39 step:30779[D loss: 0.410467, acc: 60.94%, op_acc: 40.62%] [G loss: 0.899537]\n",
      "epoch:39 step:30780[D loss: 0.428436, acc: 57.03%, op_acc: 40.62%] [G loss: 0.924599]\n",
      "epoch:39 step:30781[D loss: 0.408984, acc: 60.16%, op_acc: 42.19%] [G loss: 0.930709]\n",
      "epoch:39 step:30782[D loss: 0.390314, acc: 61.72%, op_acc: 48.44%] [G loss: 0.888587]\n",
      "epoch:39 step:30783[D loss: 0.451596, acc: 47.66%, op_acc: 37.50%] [G loss: 0.836992]\n",
      "epoch:39 step:30784[D loss: 0.406019, acc: 64.06%, op_acc: 40.62%] [G loss: 0.854140]\n",
      "epoch:39 step:30785[D loss: 0.407342, acc: 60.94%, op_acc: 44.53%] [G loss: 0.986323]\n",
      "epoch:39 step:30786[D loss: 0.407005, acc: 57.81%, op_acc: 42.19%] [G loss: 0.846534]\n",
      "epoch:39 step:30787[D loss: 0.420594, acc: 55.47%, op_acc: 40.62%] [G loss: 0.884854]\n",
      "epoch:39 step:30788[D loss: 0.396249, acc: 69.53%, op_acc: 42.97%] [G loss: 0.844027]\n",
      "epoch:39 step:30789[D loss: 0.403900, acc: 63.28%, op_acc: 42.19%] [G loss: 0.926046]\n",
      "epoch:39 step:30790[D loss: 0.388652, acc: 66.41%, op_acc: 42.19%] [G loss: 0.965517]\n",
      "epoch:39 step:30791[D loss: 0.421922, acc: 53.12%, op_acc: 42.19%] [G loss: 0.829154]\n",
      "epoch:39 step:30792[D loss: 0.385499, acc: 64.06%, op_acc: 45.31%] [G loss: 0.934069]\n",
      "epoch:39 step:30793[D loss: 0.400336, acc: 59.38%, op_acc: 46.09%] [G loss: 0.909109]\n",
      "epoch:39 step:30794[D loss: 0.425554, acc: 62.50%, op_acc: 42.19%] [G loss: 0.908431]\n",
      "epoch:39 step:30795[D loss: 0.460034, acc: 55.47%, op_acc: 41.41%] [G loss: 0.886615]\n",
      "epoch:39 step:30796[D loss: 0.451253, acc: 56.25%, op_acc: 36.72%] [G loss: 0.808073]\n",
      "epoch:39 step:30797[D loss: 0.370144, acc: 64.06%, op_acc: 46.09%] [G loss: 0.925592]\n",
      "epoch:39 step:30798[D loss: 0.406694, acc: 56.25%, op_acc: 46.09%] [G loss: 0.976763]\n",
      "epoch:39 step:30799[D loss: 0.393009, acc: 63.28%, op_acc: 37.50%] [G loss: 0.935047]\n",
      "epoch:39 step:30800[D loss: 0.421792, acc: 53.12%, op_acc: 40.62%] [G loss: 0.904127]\n",
      "##############\n",
      "[0.87007253 0.84985701 0.83918563 0.81694173 0.82033663 0.82038997\n",
      " 0.88874569 0.836648   0.78801263 0.82142887]\n",
      "##########\n",
      "epoch:39 step:30801[D loss: 0.405889, acc: 63.28%, op_acc: 39.84%] [G loss: 1.003639]\n",
      "epoch:39 step:30802[D loss: 0.422136, acc: 59.38%, op_acc: 42.19%] [G loss: 0.893209]\n",
      "epoch:39 step:30803[D loss: 0.421634, acc: 55.47%, op_acc: 40.62%] [G loss: 0.893596]\n",
      "epoch:39 step:30804[D loss: 0.441762, acc: 60.16%, op_acc: 36.72%] [G loss: 0.927649]\n",
      "epoch:39 step:30805[D loss: 0.429188, acc: 53.12%, op_acc: 46.09%] [G loss: 0.943004]\n",
      "epoch:39 step:30806[D loss: 0.382058, acc: 67.19%, op_acc: 45.31%] [G loss: 0.928469]\n",
      "epoch:39 step:30807[D loss: 0.398722, acc: 63.28%, op_acc: 43.75%] [G loss: 0.955600]\n",
      "epoch:39 step:30808[D loss: 0.382792, acc: 61.72%, op_acc: 46.09%] [G loss: 0.956273]\n",
      "epoch:39 step:30809[D loss: 0.420782, acc: 63.28%, op_acc: 42.19%] [G loss: 0.941476]\n",
      "epoch:39 step:30810[D loss: 0.408521, acc: 62.50%, op_acc: 42.19%] [G loss: 0.977381]\n",
      "epoch:39 step:30811[D loss: 0.440386, acc: 56.25%, op_acc: 37.50%] [G loss: 0.793613]\n",
      "epoch:39 step:30812[D loss: 0.389117, acc: 60.16%, op_acc: 49.22%] [G loss: 0.911054]\n",
      "epoch:39 step:30813[D loss: 0.402663, acc: 65.62%, op_acc: 44.53%] [G loss: 0.866981]\n",
      "epoch:39 step:30814[D loss: 0.413761, acc: 67.19%, op_acc: 44.53%] [G loss: 0.878087]\n",
      "epoch:39 step:30815[D loss: 0.410266, acc: 59.38%, op_acc: 39.06%] [G loss: 0.886985]\n",
      "epoch:39 step:30816[D loss: 0.416610, acc: 61.72%, op_acc: 42.97%] [G loss: 0.945932]\n",
      "epoch:39 step:30817[D loss: 0.414781, acc: 54.69%, op_acc: 36.72%] [G loss: 0.956005]\n",
      "epoch:39 step:30818[D loss: 0.438561, acc: 63.28%, op_acc: 35.16%] [G loss: 0.893316]\n",
      "epoch:39 step:30819[D loss: 0.417651, acc: 64.06%, op_acc: 37.50%] [G loss: 0.961773]\n",
      "epoch:39 step:30820[D loss: 0.416651, acc: 58.59%, op_acc: 43.75%] [G loss: 0.925721]\n",
      "epoch:39 step:30821[D loss: 0.411612, acc: 63.28%, op_acc: 42.19%] [G loss: 1.000561]\n",
      "epoch:39 step:30822[D loss: 0.399707, acc: 65.62%, op_acc: 38.28%] [G loss: 0.909444]\n",
      "epoch:39 step:30823[D loss: 0.403605, acc: 61.72%, op_acc: 38.28%] [G loss: 0.859440]\n",
      "epoch:39 step:30824[D loss: 0.383395, acc: 64.06%, op_acc: 51.56%] [G loss: 0.945327]\n",
      "epoch:39 step:30825[D loss: 0.384504, acc: 65.62%, op_acc: 47.66%] [G loss: 0.901908]\n",
      "epoch:39 step:30826[D loss: 0.410242, acc: 67.97%, op_acc: 35.94%] [G loss: 0.955202]\n",
      "epoch:39 step:30827[D loss: 0.421559, acc: 61.72%, op_acc: 35.16%] [G loss: 0.876712]\n",
      "epoch:39 step:30828[D loss: 0.405068, acc: 58.59%, op_acc: 40.62%] [G loss: 0.948892]\n",
      "epoch:39 step:30829[D loss: 0.418403, acc: 60.94%, op_acc: 38.28%] [G loss: 0.847028]\n",
      "epoch:39 step:30830[D loss: 0.385734, acc: 64.06%, op_acc: 44.53%] [G loss: 0.943046]\n",
      "epoch:39 step:30831[D loss: 0.427149, acc: 62.50%, op_acc: 39.06%] [G loss: 0.947990]\n",
      "epoch:39 step:30832[D loss: 0.392079, acc: 60.16%, op_acc: 46.88%] [G loss: 1.002441]\n",
      "epoch:39 step:30833[D loss: 0.457884, acc: 50.78%, op_acc: 36.72%] [G loss: 0.903673]\n",
      "epoch:39 step:30834[D loss: 0.429845, acc: 53.12%, op_acc: 37.50%] [G loss: 0.926394]\n",
      "epoch:39 step:30835[D loss: 0.415719, acc: 60.16%, op_acc: 43.75%] [G loss: 0.853368]\n",
      "epoch:39 step:30836[D loss: 0.438192, acc: 57.81%, op_acc: 41.41%] [G loss: 0.931399]\n",
      "epoch:39 step:30837[D loss: 0.419241, acc: 62.50%, op_acc: 39.06%] [G loss: 0.890911]\n",
      "epoch:39 step:30838[D loss: 0.385830, acc: 67.19%, op_acc: 41.41%] [G loss: 0.854543]\n",
      "epoch:39 step:30839[D loss: 0.394029, acc: 65.62%, op_acc: 40.62%] [G loss: 0.922308]\n",
      "epoch:39 step:30840[D loss: 0.403223, acc: 61.72%, op_acc: 41.41%] [G loss: 0.871823]\n",
      "epoch:39 step:30841[D loss: 0.395048, acc: 60.94%, op_acc: 42.97%] [G loss: 0.874932]\n",
      "epoch:39 step:30842[D loss: 0.412194, acc: 58.59%, op_acc: 45.31%] [G loss: 0.862022]\n",
      "epoch:39 step:30843[D loss: 0.407433, acc: 60.94%, op_acc: 40.62%] [G loss: 0.926979]\n",
      "epoch:39 step:30844[D loss: 0.421433, acc: 60.94%, op_acc: 39.84%] [G loss: 0.903124]\n",
      "epoch:39 step:30845[D loss: 0.395441, acc: 63.28%, op_acc: 46.88%] [G loss: 0.877906]\n",
      "epoch:39 step:30846[D loss: 0.412297, acc: 60.94%, op_acc: 35.16%] [G loss: 0.789356]\n",
      "epoch:39 step:30847[D loss: 0.450381, acc: 49.22%, op_acc: 30.47%] [G loss: 0.906365]\n",
      "epoch:39 step:30848[D loss: 0.423841, acc: 60.16%, op_acc: 42.19%] [G loss: 0.891727]\n",
      "epoch:39 step:30849[D loss: 0.410950, acc: 62.50%, op_acc: 42.19%] [G loss: 0.890790]\n",
      "epoch:39 step:30850[D loss: 0.414819, acc: 60.94%, op_acc: 39.84%] [G loss: 0.914966]\n",
      "##############\n",
      "[0.85205157 0.83416216 0.80041119 0.79724284 0.80735176 0.81616447\n",
      " 0.875102   0.80969909 0.82632677 0.84334451]\n",
      "##########\n",
      "epoch:39 step:30851[D loss: 0.407754, acc: 54.69%, op_acc: 42.97%] [G loss: 0.827109]\n",
      "epoch:39 step:30852[D loss: 0.405106, acc: 60.94%, op_acc: 44.53%] [G loss: 0.848370]\n",
      "epoch:39 step:30853[D loss: 0.378976, acc: 67.97%, op_acc: 41.41%] [G loss: 0.953098]\n",
      "epoch:39 step:30854[D loss: 0.453616, acc: 54.69%, op_acc: 35.94%] [G loss: 0.892792]\n",
      "epoch:39 step:30855[D loss: 0.397148, acc: 62.50%, op_acc: 45.31%] [G loss: 0.909831]\n",
      "epoch:39 step:30856[D loss: 0.414412, acc: 57.03%, op_acc: 39.84%] [G loss: 0.866509]\n",
      "epoch:39 step:30857[D loss: 0.411049, acc: 62.50%, op_acc: 45.31%] [G loss: 0.926772]\n",
      "epoch:39 step:30858[D loss: 0.398600, acc: 63.28%, op_acc: 46.09%] [G loss: 0.903796]\n",
      "epoch:39 step:30859[D loss: 0.408762, acc: 62.50%, op_acc: 45.31%] [G loss: 0.886094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30860[D loss: 0.402490, acc: 67.97%, op_acc: 41.41%] [G loss: 0.908519]\n",
      "epoch:39 step:30861[D loss: 0.434073, acc: 58.59%, op_acc: 39.06%] [G loss: 0.960601]\n",
      "epoch:39 step:30862[D loss: 0.431659, acc: 61.72%, op_acc: 38.28%] [G loss: 0.950610]\n",
      "epoch:39 step:30863[D loss: 0.389379, acc: 64.06%, op_acc: 45.31%] [G loss: 1.021064]\n",
      "epoch:39 step:30864[D loss: 0.406764, acc: 67.97%, op_acc: 39.84%] [G loss: 0.922822]\n",
      "epoch:39 step:30865[D loss: 0.410787, acc: 63.28%, op_acc: 41.41%] [G loss: 0.889396]\n",
      "epoch:39 step:30866[D loss: 0.383820, acc: 62.50%, op_acc: 42.19%] [G loss: 1.037884]\n",
      "epoch:39 step:30867[D loss: 0.376753, acc: 70.31%, op_acc: 52.34%] [G loss: 0.938653]\n",
      "epoch:39 step:30868[D loss: 0.433490, acc: 57.81%, op_acc: 40.62%] [G loss: 0.884879]\n",
      "epoch:39 step:30869[D loss: 0.404988, acc: 52.34%, op_acc: 39.84%] [G loss: 0.818511]\n",
      "epoch:39 step:30870[D loss: 0.409463, acc: 64.06%, op_acc: 40.62%] [G loss: 0.886536]\n",
      "epoch:39 step:30871[D loss: 0.412456, acc: 52.34%, op_acc: 42.19%] [G loss: 0.943398]\n",
      "epoch:39 step:30872[D loss: 0.401441, acc: 61.72%, op_acc: 42.97%] [G loss: 0.835506]\n",
      "epoch:39 step:30873[D loss: 0.399181, acc: 63.28%, op_acc: 41.41%] [G loss: 0.827175]\n",
      "epoch:39 step:30874[D loss: 0.387519, acc: 67.97%, op_acc: 41.41%] [G loss: 0.888222]\n",
      "epoch:39 step:30875[D loss: 0.397077, acc: 64.84%, op_acc: 40.62%] [G loss: 0.885132]\n",
      "epoch:39 step:30876[D loss: 0.423323, acc: 59.38%, op_acc: 38.28%] [G loss: 0.857506]\n",
      "epoch:39 step:30877[D loss: 0.445842, acc: 50.00%, op_acc: 40.62%] [G loss: 0.916824]\n",
      "epoch:39 step:30878[D loss: 0.394188, acc: 62.50%, op_acc: 42.19%] [G loss: 0.870856]\n",
      "epoch:39 step:30879[D loss: 0.445426, acc: 54.69%, op_acc: 36.72%] [G loss: 0.881009]\n",
      "epoch:39 step:30880[D loss: 0.400578, acc: 63.28%, op_acc: 38.28%] [G loss: 0.885944]\n",
      "epoch:39 step:30881[D loss: 0.419558, acc: 57.03%, op_acc: 39.84%] [G loss: 0.879524]\n",
      "epoch:39 step:30882[D loss: 0.458655, acc: 53.12%, op_acc: 35.94%] [G loss: 0.941617]\n",
      "epoch:39 step:30883[D loss: 0.409746, acc: 66.41%, op_acc: 44.53%] [G loss: 0.906117]\n",
      "epoch:39 step:30884[D loss: 0.436928, acc: 60.16%, op_acc: 36.72%] [G loss: 0.934323]\n",
      "epoch:39 step:30885[D loss: 0.430881, acc: 57.81%, op_acc: 36.72%] [G loss: 0.905268]\n",
      "epoch:39 step:30886[D loss: 0.451845, acc: 53.91%, op_acc: 39.84%] [G loss: 0.915552]\n",
      "epoch:39 step:30887[D loss: 0.397867, acc: 64.06%, op_acc: 47.66%] [G loss: 0.837984]\n",
      "epoch:39 step:30888[D loss: 0.410152, acc: 60.16%, op_acc: 42.97%] [G loss: 0.980582]\n",
      "epoch:39 step:30889[D loss: 0.386520, acc: 66.41%, op_acc: 43.75%] [G loss: 0.906843]\n",
      "epoch:39 step:30890[D loss: 0.406833, acc: 60.94%, op_acc: 41.41%] [G loss: 0.831953]\n",
      "epoch:39 step:30891[D loss: 0.377773, acc: 69.53%, op_acc: 46.09%] [G loss: 0.914471]\n",
      "epoch:39 step:30892[D loss: 0.416613, acc: 55.47%, op_acc: 39.84%] [G loss: 0.884395]\n",
      "epoch:39 step:30893[D loss: 0.407639, acc: 60.16%, op_acc: 42.97%] [G loss: 0.855382]\n",
      "epoch:39 step:30894[D loss: 0.421945, acc: 61.72%, op_acc: 41.41%] [G loss: 0.809877]\n",
      "epoch:39 step:30895[D loss: 0.421734, acc: 58.59%, op_acc: 36.72%] [G loss: 0.853750]\n",
      "epoch:39 step:30896[D loss: 0.448965, acc: 57.03%, op_acc: 42.19%] [G loss: 0.835485]\n",
      "epoch:39 step:30897[D loss: 0.415066, acc: 60.16%, op_acc: 39.84%] [G loss: 0.958433]\n",
      "epoch:39 step:30898[D loss: 0.432569, acc: 54.69%, op_acc: 39.84%] [G loss: 0.862427]\n",
      "epoch:39 step:30899[D loss: 0.406580, acc: 60.16%, op_acc: 43.75%] [G loss: 0.976571]\n",
      "epoch:39 step:30900[D loss: 0.400523, acc: 64.06%, op_acc: 41.41%] [G loss: 0.905839]\n",
      "##############\n",
      "[0.86299543 0.86414711 0.81893604 0.80239347 0.77993708 0.82893578\n",
      " 0.87853415 0.85147921 0.81183692 0.81795428]\n",
      "##########\n",
      "epoch:39 step:30901[D loss: 0.416328, acc: 58.59%, op_acc: 47.66%] [G loss: 0.894291]\n",
      "epoch:39 step:30902[D loss: 0.391829, acc: 71.88%, op_acc: 39.06%] [G loss: 0.836268]\n",
      "epoch:39 step:30903[D loss: 0.396669, acc: 60.94%, op_acc: 50.00%] [G loss: 0.869662]\n",
      "epoch:39 step:30904[D loss: 0.464989, acc: 51.56%, op_acc: 35.94%] [G loss: 0.825468]\n",
      "epoch:39 step:30905[D loss: 0.412043, acc: 62.50%, op_acc: 39.06%] [G loss: 0.853119]\n",
      "epoch:39 step:30906[D loss: 0.476030, acc: 53.91%, op_acc: 33.59%] [G loss: 0.902092]\n",
      "epoch:39 step:30907[D loss: 0.443880, acc: 52.34%, op_acc: 38.28%] [G loss: 0.856602]\n",
      "epoch:39 step:30908[D loss: 0.420034, acc: 58.59%, op_acc: 44.53%] [G loss: 0.870327]\n",
      "epoch:39 step:30909[D loss: 0.459595, acc: 57.03%, op_acc: 30.47%] [G loss: 0.913516]\n",
      "epoch:39 step:30910[D loss: 0.408708, acc: 61.72%, op_acc: 42.19%] [G loss: 1.049938]\n",
      "epoch:39 step:30911[D loss: 0.399587, acc: 61.72%, op_acc: 44.53%] [G loss: 0.852958]\n",
      "epoch:39 step:30912[D loss: 0.424090, acc: 55.47%, op_acc: 40.62%] [G loss: 0.911788]\n",
      "epoch:39 step:30913[D loss: 0.412309, acc: 61.72%, op_acc: 38.28%] [G loss: 0.900013]\n",
      "epoch:39 step:30914[D loss: 0.417343, acc: 57.81%, op_acc: 40.62%] [G loss: 0.925878]\n",
      "epoch:39 step:30915[D loss: 0.416153, acc: 62.50%, op_acc: 41.41%] [G loss: 0.922432]\n",
      "epoch:39 step:30916[D loss: 0.407831, acc: 59.38%, op_acc: 46.88%] [G loss: 0.854401]\n",
      "epoch:39 step:30917[D loss: 0.428355, acc: 53.12%, op_acc: 41.41%] [G loss: 0.860801]\n",
      "epoch:39 step:30918[D loss: 0.424911, acc: 52.34%, op_acc: 46.09%] [G loss: 0.852120]\n",
      "epoch:39 step:30919[D loss: 0.395824, acc: 62.50%, op_acc: 44.53%] [G loss: 0.901394]\n",
      "epoch:39 step:30920[D loss: 0.448372, acc: 52.34%, op_acc: 42.19%] [G loss: 0.954267]\n",
      "epoch:39 step:30921[D loss: 0.405316, acc: 63.28%, op_acc: 42.19%] [G loss: 0.942735]\n",
      "epoch:39 step:30922[D loss: 0.398612, acc: 61.72%, op_acc: 39.06%] [G loss: 0.924249]\n",
      "epoch:39 step:30923[D loss: 0.438963, acc: 60.16%, op_acc: 34.38%] [G loss: 0.887298]\n",
      "epoch:39 step:30924[D loss: 0.413421, acc: 57.81%, op_acc: 43.75%] [G loss: 0.906195]\n",
      "epoch:39 step:30925[D loss: 0.391023, acc: 63.28%, op_acc: 43.75%] [G loss: 0.884814]\n",
      "epoch:39 step:30926[D loss: 0.439167, acc: 55.47%, op_acc: 39.06%] [G loss: 0.899561]\n",
      "epoch:39 step:30927[D loss: 0.402359, acc: 65.62%, op_acc: 44.53%] [G loss: 0.887367]\n",
      "epoch:39 step:30928[D loss: 0.396669, acc: 63.28%, op_acc: 38.28%] [G loss: 0.861797]\n",
      "epoch:39 step:30929[D loss: 0.396299, acc: 58.59%, op_acc: 50.78%] [G loss: 0.876557]\n",
      "epoch:39 step:30930[D loss: 0.419719, acc: 64.06%, op_acc: 37.50%] [G loss: 0.801958]\n",
      "epoch:39 step:30931[D loss: 0.420309, acc: 58.59%, op_acc: 39.84%] [G loss: 0.959356]\n",
      "epoch:39 step:30932[D loss: 0.403854, acc: 53.12%, op_acc: 47.66%] [G loss: 0.965255]\n",
      "epoch:39 step:30933[D loss: 0.428187, acc: 64.84%, op_acc: 40.62%] [G loss: 0.813313]\n",
      "epoch:39 step:30934[D loss: 0.420399, acc: 55.47%, op_acc: 41.41%] [G loss: 0.827742]\n",
      "epoch:39 step:30935[D loss: 0.431156, acc: 54.69%, op_acc: 35.94%] [G loss: 0.882907]\n",
      "epoch:39 step:30936[D loss: 0.453965, acc: 60.94%, op_acc: 40.62%] [G loss: 0.888692]\n",
      "epoch:39 step:30937[D loss: 0.404754, acc: 64.84%, op_acc: 44.53%] [G loss: 0.961327]\n",
      "epoch:39 step:30938[D loss: 0.401561, acc: 60.94%, op_acc: 47.66%] [G loss: 0.888574]\n",
      "epoch:39 step:30939[D loss: 0.411586, acc: 71.09%, op_acc: 39.84%] [G loss: 0.924833]\n",
      "epoch:39 step:30940[D loss: 0.417944, acc: 64.84%, op_acc: 36.72%] [G loss: 0.882054]\n",
      "epoch:39 step:30941[D loss: 0.429227, acc: 65.62%, op_acc: 40.62%] [G loss: 0.909091]\n",
      "epoch:39 step:30942[D loss: 0.409947, acc: 50.78%, op_acc: 43.75%] [G loss: 0.846959]\n",
      "epoch:39 step:30943[D loss: 0.427170, acc: 51.56%, op_acc: 45.31%] [G loss: 0.787164]\n",
      "epoch:39 step:30944[D loss: 0.420444, acc: 59.38%, op_acc: 39.84%] [G loss: 0.867893]\n",
      "epoch:39 step:30945[D loss: 0.382544, acc: 62.50%, op_acc: 48.44%] [G loss: 0.876376]\n",
      "epoch:39 step:30946[D loss: 0.403957, acc: 57.81%, op_acc: 41.41%] [G loss: 0.900634]\n",
      "epoch:39 step:30947[D loss: 0.401715, acc: 63.28%, op_acc: 41.41%] [G loss: 0.931401]\n",
      "epoch:39 step:30948[D loss: 0.409043, acc: 63.28%, op_acc: 45.31%] [G loss: 0.924102]\n",
      "epoch:39 step:30949[D loss: 0.394220, acc: 60.94%, op_acc: 42.97%] [G loss: 0.958449]\n",
      "epoch:39 step:30950[D loss: 0.450943, acc: 53.91%, op_acc: 34.38%] [G loss: 0.874670]\n",
      "##############\n",
      "[0.85195499 0.86336331 0.80398174 0.80748807 0.78212845 0.80760659\n",
      " 0.89515747 0.82265522 0.81648889 0.83503931]\n",
      "##########\n",
      "epoch:39 step:30951[D loss: 0.394746, acc: 60.94%, op_acc: 42.19%] [G loss: 0.863124]\n",
      "epoch:39 step:30952[D loss: 0.409899, acc: 61.72%, op_acc: 38.28%] [G loss: 0.920245]\n",
      "epoch:39 step:30953[D loss: 0.383134, acc: 67.97%, op_acc: 47.66%] [G loss: 0.913342]\n",
      "epoch:39 step:30954[D loss: 0.408173, acc: 60.94%, op_acc: 43.75%] [G loss: 0.876818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30955[D loss: 0.430905, acc: 58.59%, op_acc: 39.06%] [G loss: 0.895042]\n",
      "epoch:39 step:30956[D loss: 0.435075, acc: 55.47%, op_acc: 42.97%] [G loss: 0.882304]\n",
      "epoch:39 step:30957[D loss: 0.432187, acc: 59.38%, op_acc: 41.41%] [G loss: 0.907475]\n",
      "epoch:39 step:30958[D loss: 0.412485, acc: 68.75%, op_acc: 35.16%] [G loss: 0.893920]\n",
      "epoch:39 step:30959[D loss: 0.391937, acc: 64.84%, op_acc: 40.62%] [G loss: 0.859117]\n",
      "epoch:39 step:30960[D loss: 0.425562, acc: 59.38%, op_acc: 37.50%] [G loss: 0.909549]\n",
      "epoch:39 step:30961[D loss: 0.428634, acc: 57.03%, op_acc: 40.62%] [G loss: 0.885670]\n",
      "epoch:39 step:30962[D loss: 0.393967, acc: 62.50%, op_acc: 42.19%] [G loss: 0.878522]\n",
      "epoch:39 step:30963[D loss: 0.469700, acc: 48.44%, op_acc: 37.50%] [G loss: 0.860247]\n",
      "epoch:39 step:30964[D loss: 0.423173, acc: 56.25%, op_acc: 41.41%] [G loss: 0.834772]\n",
      "epoch:39 step:30965[D loss: 0.410730, acc: 60.16%, op_acc: 41.41%] [G loss: 1.021611]\n",
      "epoch:39 step:30966[D loss: 0.381578, acc: 67.19%, op_acc: 46.88%] [G loss: 0.892793]\n",
      "epoch:39 step:30967[D loss: 0.418791, acc: 65.62%, op_acc: 35.16%] [G loss: 0.887089]\n",
      "epoch:39 step:30968[D loss: 0.439080, acc: 57.03%, op_acc: 40.62%] [G loss: 0.937056]\n",
      "epoch:39 step:30969[D loss: 0.405450, acc: 66.41%, op_acc: 39.06%] [G loss: 0.863244]\n",
      "epoch:39 step:30970[D loss: 0.405657, acc: 57.03%, op_acc: 46.09%] [G loss: 0.897395]\n",
      "epoch:39 step:30971[D loss: 0.431762, acc: 61.72%, op_acc: 39.06%] [G loss: 0.858577]\n",
      "epoch:39 step:30972[D loss: 0.450147, acc: 54.69%, op_acc: 32.03%] [G loss: 0.989358]\n",
      "epoch:39 step:30973[D loss: 0.439536, acc: 50.78%, op_acc: 40.62%] [G loss: 0.788711]\n",
      "epoch:39 step:30974[D loss: 0.393920, acc: 64.06%, op_acc: 43.75%] [G loss: 0.904310]\n",
      "epoch:39 step:30975[D loss: 0.410344, acc: 64.06%, op_acc: 41.41%] [G loss: 0.920272]\n",
      "epoch:39 step:30976[D loss: 0.441909, acc: 57.03%, op_acc: 36.72%] [G loss: 0.878328]\n",
      "epoch:39 step:30977[D loss: 0.400911, acc: 59.38%, op_acc: 39.06%] [G loss: 0.900761]\n",
      "epoch:39 step:30978[D loss: 0.403221, acc: 59.38%, op_acc: 43.75%] [G loss: 0.891247]\n",
      "epoch:39 step:30979[D loss: 0.417295, acc: 55.47%, op_acc: 42.97%] [G loss: 0.862174]\n",
      "epoch:39 step:30980[D loss: 0.430091, acc: 57.81%, op_acc: 34.38%] [G loss: 0.871803]\n",
      "epoch:39 step:30981[D loss: 0.425082, acc: 57.81%, op_acc: 42.19%] [G loss: 0.782211]\n",
      "epoch:39 step:30982[D loss: 0.414626, acc: 60.94%, op_acc: 42.19%] [G loss: 0.873025]\n",
      "epoch:39 step:30983[D loss: 0.407510, acc: 64.06%, op_acc: 41.41%] [G loss: 0.916150]\n",
      "epoch:39 step:30984[D loss: 0.396360, acc: 68.75%, op_acc: 39.06%] [G loss: 0.925855]\n",
      "epoch:39 step:30985[D loss: 0.458232, acc: 57.03%, op_acc: 33.59%] [G loss: 0.895480]\n",
      "epoch:39 step:30986[D loss: 0.421163, acc: 57.03%, op_acc: 44.53%] [G loss: 0.905707]\n",
      "epoch:39 step:30987[D loss: 0.410524, acc: 61.72%, op_acc: 43.75%] [G loss: 0.935395]\n",
      "epoch:39 step:30988[D loss: 0.424996, acc: 55.47%, op_acc: 39.06%] [G loss: 1.003394]\n",
      "epoch:39 step:30989[D loss: 0.427719, acc: 61.72%, op_acc: 32.81%] [G loss: 0.957510]\n",
      "epoch:39 step:30990[D loss: 0.383502, acc: 67.97%, op_acc: 50.78%] [G loss: 0.851849]\n",
      "epoch:39 step:30991[D loss: 0.413439, acc: 60.94%, op_acc: 39.06%] [G loss: 0.962254]\n",
      "epoch:39 step:30992[D loss: 0.415569, acc: 62.50%, op_acc: 47.66%] [G loss: 0.964330]\n",
      "epoch:39 step:30993[D loss: 0.407402, acc: 53.91%, op_acc: 44.53%] [G loss: 0.936983]\n",
      "epoch:39 step:30994[D loss: 0.429217, acc: 55.47%, op_acc: 39.06%] [G loss: 0.959330]\n",
      "epoch:39 step:30995[D loss: 0.386366, acc: 69.53%, op_acc: 39.84%] [G loss: 0.901127]\n",
      "epoch:39 step:30996[D loss: 0.418497, acc: 54.69%, op_acc: 40.62%] [G loss: 0.852296]\n",
      "epoch:39 step:30997[D loss: 0.397193, acc: 61.72%, op_acc: 44.53%] [G loss: 0.886154]\n",
      "epoch:39 step:30998[D loss: 0.456986, acc: 53.12%, op_acc: 41.41%] [G loss: 0.899007]\n",
      "epoch:39 step:30999[D loss: 0.396495, acc: 65.62%, op_acc: 39.06%] [G loss: 0.855466]\n",
      "epoch:39 step:31000[D loss: 0.413311, acc: 60.94%, op_acc: 35.94%] [G loss: 0.928901]\n",
      "##############\n",
      "[0.84786614 0.84762365 0.79841845 0.79536048 0.78664436 0.8442771\n",
      " 0.87189571 0.83196605 0.82471474 0.84991208]\n",
      "##########\n",
      "epoch:39 step:31001[D loss: 0.429758, acc: 57.81%, op_acc: 35.94%] [G loss: 0.904926]\n",
      "epoch:39 step:31002[D loss: 0.436301, acc: 53.12%, op_acc: 39.06%] [G loss: 0.863500]\n",
      "epoch:39 step:31003[D loss: 0.416122, acc: 64.84%, op_acc: 39.06%] [G loss: 0.933347]\n",
      "epoch:39 step:31004[D loss: 0.382921, acc: 67.97%, op_acc: 39.84%] [G loss: 0.935164]\n",
      "epoch:39 step:31005[D loss: 0.441461, acc: 53.12%, op_acc: 38.28%] [G loss: 0.831017]\n",
      "epoch:39 step:31006[D loss: 0.425447, acc: 57.81%, op_acc: 40.62%] [G loss: 0.913255]\n",
      "epoch:39 step:31007[D loss: 0.453727, acc: 53.12%, op_acc: 39.84%] [G loss: 0.883829]\n",
      "epoch:39 step:31008[D loss: 0.446623, acc: 53.91%, op_acc: 35.94%] [G loss: 0.853501]\n",
      "epoch:39 step:31009[D loss: 0.418647, acc: 59.38%, op_acc: 38.28%] [G loss: 0.877503]\n",
      "epoch:39 step:31010[D loss: 0.423949, acc: 57.03%, op_acc: 38.28%] [G loss: 0.868390]\n",
      "epoch:39 step:31011[D loss: 0.463485, acc: 46.88%, op_acc: 38.28%] [G loss: 0.798646]\n",
      "epoch:39 step:31012[D loss: 0.415001, acc: 60.94%, op_acc: 42.19%] [G loss: 0.849002]\n",
      "epoch:39 step:31013[D loss: 0.387069, acc: 62.50%, op_acc: 43.75%] [G loss: 0.932160]\n",
      "epoch:39 step:31014[D loss: 0.403711, acc: 61.72%, op_acc: 45.31%] [G loss: 0.866182]\n",
      "epoch:39 step:31015[D loss: 0.422941, acc: 55.47%, op_acc: 44.53%] [G loss: 0.829328]\n",
      "epoch:39 step:31016[D loss: 0.398409, acc: 64.06%, op_acc: 42.19%] [G loss: 0.936973]\n",
      "epoch:39 step:31017[D loss: 0.387300, acc: 60.16%, op_acc: 46.88%] [G loss: 0.896383]\n",
      "epoch:39 step:31018[D loss: 0.408686, acc: 57.81%, op_acc: 46.09%] [G loss: 0.874277]\n",
      "epoch:39 step:31019[D loss: 0.436426, acc: 51.56%, op_acc: 35.94%] [G loss: 0.876713]\n",
      "epoch:39 step:31020[D loss: 0.428399, acc: 58.59%, op_acc: 42.19%] [G loss: 0.849111]\n",
      "epoch:39 step:31021[D loss: 0.435680, acc: 63.28%, op_acc: 38.28%] [G loss: 0.909233]\n",
      "epoch:39 step:31022[D loss: 0.418163, acc: 56.25%, op_acc: 41.41%] [G loss: 0.892525]\n",
      "epoch:39 step:31023[D loss: 0.402988, acc: 61.72%, op_acc: 39.84%] [G loss: 0.841280]\n",
      "epoch:39 step:31024[D loss: 0.442818, acc: 51.56%, op_acc: 47.66%] [G loss: 0.991173]\n",
      "epoch:39 step:31025[D loss: 0.450204, acc: 50.78%, op_acc: 38.28%] [G loss: 0.824540]\n",
      "epoch:39 step:31026[D loss: 0.398173, acc: 61.72%, op_acc: 42.19%] [G loss: 0.871819]\n",
      "epoch:39 step:31027[D loss: 0.405703, acc: 58.59%, op_acc: 42.97%] [G loss: 0.867855]\n",
      "epoch:39 step:31028[D loss: 0.389817, acc: 66.41%, op_acc: 39.06%] [G loss: 0.961816]\n",
      "epoch:39 step:31029[D loss: 0.411247, acc: 62.50%, op_acc: 43.75%] [G loss: 0.904954]\n",
      "epoch:39 step:31030[D loss: 0.411561, acc: 63.28%, op_acc: 44.53%] [G loss: 0.912239]\n",
      "epoch:39 step:31031[D loss: 0.417749, acc: 61.72%, op_acc: 42.19%] [G loss: 0.899132]\n",
      "epoch:39 step:31032[D loss: 0.434257, acc: 53.12%, op_acc: 39.06%] [G loss: 0.853227]\n",
      "epoch:39 step:31033[D loss: 0.384550, acc: 68.75%, op_acc: 44.53%] [G loss: 0.967960]\n",
      "epoch:39 step:31034[D loss: 0.401639, acc: 64.84%, op_acc: 41.41%] [G loss: 0.914743]\n",
      "epoch:39 step:31035[D loss: 0.418052, acc: 55.47%, op_acc: 46.09%] [G loss: 0.851795]\n",
      "epoch:39 step:31036[D loss: 0.423783, acc: 61.72%, op_acc: 38.28%] [G loss: 0.915378]\n",
      "epoch:39 step:31037[D loss: 0.441319, acc: 58.59%, op_acc: 33.59%] [G loss: 0.922139]\n",
      "epoch:39 step:31038[D loss: 0.395754, acc: 57.81%, op_acc: 41.41%] [G loss: 0.878642]\n",
      "epoch:39 step:31039[D loss: 0.399427, acc: 65.62%, op_acc: 43.75%] [G loss: 0.904167]\n",
      "epoch:39 step:31040[D loss: 0.429888, acc: 57.81%, op_acc: 40.62%] [G loss: 0.922933]\n",
      "epoch:39 step:31041[D loss: 0.455565, acc: 54.69%, op_acc: 36.72%] [G loss: 0.852527]\n",
      "epoch:39 step:31042[D loss: 0.393907, acc: 63.28%, op_acc: 43.75%] [G loss: 1.011837]\n",
      "epoch:39 step:31043[D loss: 0.424976, acc: 67.97%, op_acc: 36.72%] [G loss: 0.858265]\n",
      "epoch:39 step:31044[D loss: 0.362063, acc: 68.75%, op_acc: 43.75%] [G loss: 0.992490]\n",
      "epoch:39 step:31045[D loss: 0.405982, acc: 64.84%, op_acc: 42.97%] [G loss: 0.861734]\n",
      "epoch:39 step:31046[D loss: 0.407752, acc: 64.06%, op_acc: 40.62%] [G loss: 0.919247]\n",
      "epoch:39 step:31047[D loss: 0.421322, acc: 57.03%, op_acc: 42.19%] [G loss: 0.981871]\n",
      "epoch:39 step:31048[D loss: 0.416667, acc: 64.84%, op_acc: 39.84%] [G loss: 0.849956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31049[D loss: 0.399731, acc: 64.84%, op_acc: 39.06%] [G loss: 0.928823]\n",
      "epoch:39 step:31050[D loss: 0.394020, acc: 68.75%, op_acc: 40.62%] [G loss: 0.917122]\n",
      "##############\n",
      "[0.85667165 0.8800536  0.79703852 0.79676554 0.80533275 0.8232216\n",
      " 0.87961983 0.82325637 0.82080374 0.81589598]\n",
      "##########\n",
      "epoch:39 step:31051[D loss: 0.410329, acc: 59.38%, op_acc: 46.88%] [G loss: 0.894533]\n",
      "epoch:39 step:31052[D loss: 0.435277, acc: 57.03%, op_acc: 39.06%] [G loss: 0.937067]\n",
      "epoch:39 step:31053[D loss: 0.415734, acc: 55.47%, op_acc: 37.50%] [G loss: 0.994414]\n",
      "epoch:39 step:31054[D loss: 0.410680, acc: 56.25%, op_acc: 41.41%] [G loss: 0.917807]\n",
      "epoch:39 step:31055[D loss: 0.430933, acc: 61.72%, op_acc: 42.97%] [G loss: 0.898273]\n",
      "epoch:39 step:31056[D loss: 0.434939, acc: 57.03%, op_acc: 40.62%] [G loss: 0.937339]\n",
      "epoch:39 step:31057[D loss: 0.384463, acc: 71.88%, op_acc: 47.66%] [G loss: 0.955443]\n",
      "epoch:39 step:31058[D loss: 0.431261, acc: 60.16%, op_acc: 38.28%] [G loss: 0.851317]\n",
      "epoch:39 step:31059[D loss: 0.426251, acc: 63.28%, op_acc: 38.28%] [G loss: 0.840457]\n",
      "epoch:39 step:31060[D loss: 0.429382, acc: 57.03%, op_acc: 35.94%] [G loss: 0.918560]\n",
      "epoch:39 step:31061[D loss: 0.444587, acc: 54.69%, op_acc: 40.62%] [G loss: 0.851212]\n",
      "epoch:39 step:31062[D loss: 0.403387, acc: 60.94%, op_acc: 42.19%] [G loss: 0.931733]\n",
      "epoch:39 step:31063[D loss: 0.446620, acc: 55.47%, op_acc: 33.59%] [G loss: 0.937511]\n",
      "epoch:39 step:31064[D loss: 0.426889, acc: 53.12%, op_acc: 41.41%] [G loss: 0.871843]\n",
      "epoch:39 step:31065[D loss: 0.416955, acc: 59.38%, op_acc: 41.41%] [G loss: 0.809920]\n",
      "epoch:39 step:31066[D loss: 0.439570, acc: 53.91%, op_acc: 42.97%] [G loss: 0.818724]\n",
      "epoch:39 step:31067[D loss: 0.365168, acc: 71.88%, op_acc: 44.53%] [G loss: 0.869312]\n",
      "epoch:39 step:31068[D loss: 0.418206, acc: 57.81%, op_acc: 44.53%] [G loss: 0.897950]\n",
      "epoch:39 step:31069[D loss: 0.376168, acc: 71.09%, op_acc: 42.19%] [G loss: 1.021019]\n",
      "epoch:39 step:31070[D loss: 0.389821, acc: 69.53%, op_acc: 43.75%] [G loss: 0.945044]\n",
      "epoch:39 step:31071[D loss: 0.403115, acc: 59.38%, op_acc: 42.97%] [G loss: 0.870203]\n",
      "epoch:39 step:31072[D loss: 0.454752, acc: 46.09%, op_acc: 39.84%] [G loss: 0.881166]\n",
      "epoch:39 step:31073[D loss: 0.393693, acc: 62.50%, op_acc: 45.31%] [G loss: 0.835526]\n",
      "epoch:39 step:31074[D loss: 0.426913, acc: 60.94%, op_acc: 39.06%] [G loss: 0.906566]\n",
      "epoch:39 step:31075[D loss: 0.433634, acc: 62.50%, op_acc: 38.28%] [G loss: 0.870084]\n",
      "epoch:39 step:31076[D loss: 0.411101, acc: 59.38%, op_acc: 46.09%] [G loss: 0.932786]\n",
      "epoch:39 step:31077[D loss: 0.400343, acc: 59.38%, op_acc: 47.66%] [G loss: 0.891868]\n",
      "epoch:39 step:31078[D loss: 0.410163, acc: 66.41%, op_acc: 37.50%] [G loss: 0.939453]\n",
      "epoch:39 step:31079[D loss: 0.440735, acc: 59.38%, op_acc: 40.62%] [G loss: 0.989609]\n",
      "epoch:39 step:31080[D loss: 0.412714, acc: 69.53%, op_acc: 42.19%] [G loss: 0.949734]\n",
      "epoch:39 step:31081[D loss: 0.421404, acc: 60.16%, op_acc: 38.28%] [G loss: 0.826334]\n",
      "epoch:39 step:31082[D loss: 0.384683, acc: 67.19%, op_acc: 47.66%] [G loss: 1.042835]\n",
      "epoch:39 step:31083[D loss: 0.427892, acc: 60.94%, op_acc: 39.06%] [G loss: 0.976066]\n",
      "epoch:39 step:31084[D loss: 0.384822, acc: 69.53%, op_acc: 39.06%] [G loss: 1.004956]\n",
      "epoch:39 step:31085[D loss: 0.407026, acc: 60.94%, op_acc: 43.75%] [G loss: 0.933813]\n",
      "epoch:39 step:31086[D loss: 0.411645, acc: 57.81%, op_acc: 41.41%] [G loss: 0.851627]\n",
      "epoch:39 step:31087[D loss: 0.427034, acc: 61.72%, op_acc: 42.19%] [G loss: 0.949942]\n",
      "epoch:39 step:31088[D loss: 0.414488, acc: 65.62%, op_acc: 37.50%] [G loss: 0.923577]\n",
      "epoch:39 step:31089[D loss: 0.435090, acc: 53.91%, op_acc: 38.28%] [G loss: 0.883773]\n",
      "epoch:39 step:31090[D loss: 0.458099, acc: 57.81%, op_acc: 38.28%] [G loss: 0.962504]\n",
      "epoch:39 step:31091[D loss: 0.446507, acc: 54.69%, op_acc: 40.62%] [G loss: 0.848079]\n",
      "epoch:39 step:31092[D loss: 0.428723, acc: 58.59%, op_acc: 39.84%] [G loss: 0.864200]\n",
      "epoch:39 step:31093[D loss: 0.408027, acc: 63.28%, op_acc: 46.09%] [G loss: 0.887103]\n",
      "epoch:39 step:31094[D loss: 0.423322, acc: 62.50%, op_acc: 46.09%] [G loss: 0.888461]\n",
      "epoch:39 step:31095[D loss: 0.426410, acc: 56.25%, op_acc: 43.75%] [G loss: 0.821446]\n",
      "epoch:39 step:31096[D loss: 0.403245, acc: 61.72%, op_acc: 40.62%] [G loss: 0.937089]\n",
      "epoch:39 step:31097[D loss: 0.407144, acc: 57.03%, op_acc: 38.28%] [G loss: 0.848447]\n",
      "epoch:39 step:31098[D loss: 0.412955, acc: 61.72%, op_acc: 42.97%] [G loss: 0.852027]\n",
      "epoch:39 step:31099[D loss: 0.420458, acc: 57.03%, op_acc: 43.75%] [G loss: 0.966444]\n",
      "epoch:39 step:31100[D loss: 0.400655, acc: 62.50%, op_acc: 42.97%] [G loss: 0.911705]\n",
      "##############\n",
      "[0.86567342 0.85656742 0.81150131 0.79799491 0.80582523 0.84776179\n",
      " 0.90340566 0.84279467 0.80937306 0.81111238]\n",
      "##########\n",
      "epoch:39 step:31101[D loss: 0.426532, acc: 56.25%, op_acc: 43.75%] [G loss: 0.949303]\n",
      "epoch:39 step:31102[D loss: 0.443008, acc: 56.25%, op_acc: 35.94%] [G loss: 0.858891]\n",
      "epoch:39 step:31103[D loss: 0.365274, acc: 64.84%, op_acc: 51.56%] [G loss: 0.906419]\n",
      "epoch:39 step:31104[D loss: 0.387786, acc: 73.44%, op_acc: 41.41%] [G loss: 1.000529]\n",
      "epoch:39 step:31105[D loss: 0.390052, acc: 68.75%, op_acc: 45.31%] [G loss: 0.938265]\n",
      "epoch:39 step:31106[D loss: 0.394428, acc: 60.94%, op_acc: 46.09%] [G loss: 0.900014]\n",
      "epoch:39 step:31107[D loss: 0.442575, acc: 56.25%, op_acc: 39.06%] [G loss: 0.915481]\n",
      "epoch:39 step:31108[D loss: 0.392401, acc: 61.72%, op_acc: 39.06%] [G loss: 0.930386]\n",
      "epoch:39 step:31109[D loss: 0.439780, acc: 55.47%, op_acc: 41.41%] [G loss: 0.942437]\n",
      "epoch:39 step:31110[D loss: 0.411527, acc: 58.59%, op_acc: 39.84%] [G loss: 0.942056]\n",
      "epoch:39 step:31111[D loss: 0.383836, acc: 64.84%, op_acc: 49.22%] [G loss: 0.905512]\n",
      "epoch:39 step:31112[D loss: 0.372327, acc: 65.62%, op_acc: 44.53%] [G loss: 0.896406]\n",
      "epoch:39 step:31113[D loss: 0.422539, acc: 57.81%, op_acc: 43.75%] [G loss: 0.808743]\n",
      "epoch:39 step:31114[D loss: 0.418189, acc: 62.50%, op_acc: 39.06%] [G loss: 0.839251]\n",
      "epoch:39 step:31115[D loss: 0.414245, acc: 67.19%, op_acc: 42.97%] [G loss: 0.824164]\n",
      "epoch:39 step:31116[D loss: 0.395765, acc: 62.50%, op_acc: 41.41%] [G loss: 0.881847]\n",
      "epoch:39 step:31117[D loss: 0.427051, acc: 58.59%, op_acc: 40.62%] [G loss: 0.909247]\n",
      "epoch:39 step:31118[D loss: 0.431609, acc: 63.28%, op_acc: 39.06%] [G loss: 0.805163]\n",
      "epoch:39 step:31119[D loss: 0.420215, acc: 66.41%, op_acc: 37.50%] [G loss: 0.928569]\n",
      "epoch:39 step:31120[D loss: 0.376240, acc: 61.72%, op_acc: 46.09%] [G loss: 0.898121]\n",
      "epoch:39 step:31121[D loss: 0.413152, acc: 60.16%, op_acc: 36.72%] [G loss: 0.918300]\n",
      "epoch:39 step:31122[D loss: 0.401959, acc: 60.94%, op_acc: 45.31%] [G loss: 0.946589]\n",
      "epoch:39 step:31123[D loss: 0.405417, acc: 64.84%, op_acc: 41.41%] [G loss: 0.906892]\n",
      "epoch:39 step:31124[D loss: 0.417532, acc: 62.50%, op_acc: 37.50%] [G loss: 0.905737]\n",
      "epoch:39 step:31125[D loss: 0.407082, acc: 61.72%, op_acc: 43.75%] [G loss: 0.959583]\n",
      "epoch:39 step:31126[D loss: 0.412738, acc: 57.03%, op_acc: 42.19%] [G loss: 0.860574]\n",
      "epoch:39 step:31127[D loss: 0.419684, acc: 52.34%, op_acc: 43.75%] [G loss: 0.877785]\n",
      "epoch:39 step:31128[D loss: 0.429660, acc: 53.12%, op_acc: 41.41%] [G loss: 0.827046]\n",
      "epoch:39 step:31129[D loss: 0.418468, acc: 55.47%, op_acc: 45.31%] [G loss: 0.907547]\n",
      "epoch:39 step:31130[D loss: 0.432953, acc: 57.03%, op_acc: 41.41%] [G loss: 0.886279]\n",
      "epoch:39 step:31131[D loss: 0.433688, acc: 58.59%, op_acc: 39.84%] [G loss: 0.969633]\n",
      "epoch:39 step:31132[D loss: 0.415490, acc: 68.75%, op_acc: 40.62%] [G loss: 0.867632]\n",
      "epoch:39 step:31133[D loss: 0.406330, acc: 60.94%, op_acc: 39.84%] [G loss: 0.867429]\n",
      "epoch:39 step:31134[D loss: 0.396368, acc: 66.41%, op_acc: 40.62%] [G loss: 0.974908]\n",
      "epoch:39 step:31135[D loss: 0.470115, acc: 53.91%, op_acc: 33.59%] [G loss: 0.882381]\n",
      "epoch:39 step:31136[D loss: 0.435829, acc: 60.16%, op_acc: 37.50%] [G loss: 0.890322]\n",
      "epoch:39 step:31137[D loss: 0.388579, acc: 64.84%, op_acc: 40.62%] [G loss: 0.937644]\n",
      "epoch:39 step:31138[D loss: 0.378261, acc: 66.41%, op_acc: 46.88%] [G loss: 0.901733]\n",
      "epoch:39 step:31139[D loss: 0.435532, acc: 54.69%, op_acc: 41.41%] [G loss: 0.909991]\n",
      "epoch:39 step:31140[D loss: 0.415224, acc: 64.84%, op_acc: 39.84%] [G loss: 0.929231]\n",
      "epoch:39 step:31141[D loss: 0.423717, acc: 56.25%, op_acc: 39.84%] [G loss: 0.850965]\n",
      "epoch:39 step:31142[D loss: 0.421949, acc: 50.00%, op_acc: 45.31%] [G loss: 0.848015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31143[D loss: 0.427133, acc: 57.81%, op_acc: 38.28%] [G loss: 0.884803]\n",
      "epoch:39 step:31144[D loss: 0.423856, acc: 60.94%, op_acc: 44.53%] [G loss: 0.844728]\n",
      "epoch:39 step:31145[D loss: 0.421775, acc: 51.56%, op_acc: 42.19%] [G loss: 0.900468]\n",
      "epoch:39 step:31146[D loss: 0.421015, acc: 62.50%, op_acc: 39.06%] [G loss: 0.890675]\n",
      "epoch:39 step:31147[D loss: 0.427715, acc: 56.25%, op_acc: 42.97%] [G loss: 0.872916]\n",
      "epoch:39 step:31148[D loss: 0.441076, acc: 51.56%, op_acc: 39.06%] [G loss: 0.871018]\n",
      "epoch:39 step:31149[D loss: 0.413230, acc: 67.19%, op_acc: 36.72%] [G loss: 0.906043]\n",
      "epoch:39 step:31150[D loss: 0.406026, acc: 66.41%, op_acc: 37.50%] [G loss: 0.886531]\n",
      "##############\n",
      "[0.8453525  0.86888201 0.80198784 0.79089971 0.78574764 0.82568756\n",
      " 0.89797016 0.84230065 0.82308102 0.81172727]\n",
      "##########\n",
      "epoch:39 step:31151[D loss: 0.426482, acc: 57.81%, op_acc: 35.16%] [G loss: 0.867630]\n",
      "epoch:39 step:31152[D loss: 0.414851, acc: 64.84%, op_acc: 42.19%] [G loss: 0.950006]\n",
      "epoch:39 step:31153[D loss: 0.410887, acc: 67.19%, op_acc: 45.31%] [G loss: 0.812828]\n",
      "epoch:39 step:31154[D loss: 0.381688, acc: 65.62%, op_acc: 45.31%] [G loss: 0.946827]\n",
      "epoch:39 step:31155[D loss: 0.387949, acc: 60.16%, op_acc: 42.97%] [G loss: 0.906265]\n",
      "epoch:39 step:31156[D loss: 0.432937, acc: 57.81%, op_acc: 35.94%] [G loss: 0.874033]\n",
      "epoch:39 step:31157[D loss: 0.439844, acc: 60.94%, op_acc: 38.28%] [G loss: 0.860528]\n",
      "epoch:39 step:31158[D loss: 0.405201, acc: 59.38%, op_acc: 43.75%] [G loss: 0.929449]\n",
      "epoch:39 step:31159[D loss: 0.431298, acc: 53.91%, op_acc: 46.88%] [G loss: 0.825458]\n",
      "epoch:39 step:31160[D loss: 0.423763, acc: 57.03%, op_acc: 39.06%] [G loss: 0.833832]\n",
      "epoch:39 step:31161[D loss: 0.459909, acc: 56.25%, op_acc: 35.94%] [G loss: 0.918090]\n",
      "epoch:39 step:31162[D loss: 0.429958, acc: 55.47%, op_acc: 34.38%] [G loss: 0.840301]\n",
      "epoch:39 step:31163[D loss: 0.419236, acc: 47.66%, op_acc: 45.31%] [G loss: 0.840731]\n",
      "epoch:39 step:31164[D loss: 0.416748, acc: 60.16%, op_acc: 39.06%] [G loss: 0.860694]\n",
      "epoch:39 step:31165[D loss: 0.440894, acc: 56.25%, op_acc: 36.72%] [G loss: 0.906213]\n",
      "epoch:39 step:31166[D loss: 0.428993, acc: 57.81%, op_acc: 41.41%] [G loss: 0.817240]\n",
      "epoch:39 step:31167[D loss: 0.419304, acc: 62.50%, op_acc: 40.62%] [G loss: 0.859402]\n",
      "epoch:39 step:31168[D loss: 0.386134, acc: 63.28%, op_acc: 47.66%] [G loss: 0.907198]\n",
      "epoch:39 step:31169[D loss: 0.411473, acc: 64.06%, op_acc: 39.84%] [G loss: 0.917157]\n",
      "epoch:39 step:31170[D loss: 0.417078, acc: 60.16%, op_acc: 42.19%] [G loss: 0.858718]\n",
      "epoch:39 step:31171[D loss: 0.412014, acc: 58.59%, op_acc: 46.09%] [G loss: 0.978488]\n",
      "epoch:39 step:31172[D loss: 0.414553, acc: 61.72%, op_acc: 42.97%] [G loss: 0.937905]\n",
      "epoch:39 step:31173[D loss: 0.428327, acc: 60.94%, op_acc: 40.62%] [G loss: 0.924726]\n",
      "epoch:39 step:31174[D loss: 0.427487, acc: 53.91%, op_acc: 46.88%] [G loss: 0.877550]\n",
      "epoch:39 step:31175[D loss: 0.409526, acc: 58.59%, op_acc: 43.75%] [G loss: 0.908493]\n",
      "epoch:39 step:31176[D loss: 0.398243, acc: 58.59%, op_acc: 42.19%] [G loss: 0.987701]\n",
      "epoch:39 step:31177[D loss: 0.400740, acc: 64.06%, op_acc: 39.06%] [G loss: 1.028049]\n",
      "epoch:39 step:31178[D loss: 0.401542, acc: 60.16%, op_acc: 42.97%] [G loss: 0.895344]\n",
      "epoch:39 step:31179[D loss: 0.434095, acc: 54.69%, op_acc: 39.84%] [G loss: 0.883645]\n",
      "epoch:39 step:31180[D loss: 0.422917, acc: 50.00%, op_acc: 46.09%] [G loss: 0.810826]\n",
      "epoch:39 step:31181[D loss: 0.425762, acc: 61.72%, op_acc: 40.62%] [G loss: 0.942320]\n",
      "epoch:39 step:31182[D loss: 0.396196, acc: 67.97%, op_acc: 38.28%] [G loss: 0.920124]\n",
      "epoch:39 step:31183[D loss: 0.417241, acc: 63.28%, op_acc: 36.72%] [G loss: 0.866816]\n",
      "epoch:39 step:31184[D loss: 0.407741, acc: 63.28%, op_acc: 39.84%] [G loss: 0.818200]\n",
      "epoch:39 step:31185[D loss: 0.418702, acc: 58.59%, op_acc: 39.84%] [G loss: 0.902222]\n",
      "epoch:39 step:31186[D loss: 0.455911, acc: 48.44%, op_acc: 39.84%] [G loss: 0.841906]\n",
      "epoch:39 step:31187[D loss: 0.416348, acc: 62.50%, op_acc: 42.19%] [G loss: 0.854089]\n",
      "epoch:39 step:31188[D loss: 0.410928, acc: 57.81%, op_acc: 36.72%] [G loss: 0.866170]\n",
      "epoch:39 step:31189[D loss: 0.451033, acc: 58.59%, op_acc: 42.97%] [G loss: 0.884213]\n",
      "epoch:39 step:31190[D loss: 0.423897, acc: 57.81%, op_acc: 46.09%] [G loss: 0.795372]\n",
      "epoch:39 step:31191[D loss: 0.396200, acc: 64.84%, op_acc: 43.75%] [G loss: 0.869990]\n",
      "epoch:39 step:31192[D loss: 0.396357, acc: 60.16%, op_acc: 47.66%] [G loss: 0.784998]\n",
      "epoch:39 step:31193[D loss: 0.429133, acc: 59.38%, op_acc: 42.97%] [G loss: 0.850377]\n",
      "epoch:39 step:31194[D loss: 0.438790, acc: 53.12%, op_acc: 38.28%] [G loss: 0.874617]\n",
      "epoch:39 step:31195[D loss: 0.445138, acc: 53.12%, op_acc: 37.50%] [G loss: 0.830120]\n",
      "epoch:39 step:31196[D loss: 0.397421, acc: 57.81%, op_acc: 45.31%] [G loss: 0.893874]\n",
      "epoch:39 step:31197[D loss: 0.411419, acc: 54.69%, op_acc: 43.75%] [G loss: 0.839866]\n",
      "epoch:39 step:31198[D loss: 0.384850, acc: 67.97%, op_acc: 46.09%] [G loss: 0.949534]\n",
      "epoch:39 step:31199[D loss: 0.406296, acc: 62.50%, op_acc: 42.19%] [G loss: 0.868686]\n",
      "epoch:39 step:31200[D loss: 0.429870, acc: 56.25%, op_acc: 39.06%] [G loss: 1.005239]\n",
      "##############\n",
      "[0.84961564 0.83712709 0.82112248 0.78816288 0.78640004 0.82469747\n",
      " 0.86580308 0.82603391 0.83979417 0.82745429]\n",
      "##########\n",
      "epoch:39 step:31201[D loss: 0.438572, acc: 62.50%, op_acc: 38.28%] [G loss: 0.918072]\n",
      "epoch:39 step:31202[D loss: 0.451713, acc: 52.34%, op_acc: 42.97%] [G loss: 0.836210]\n",
      "epoch:39 step:31203[D loss: 0.380745, acc: 64.06%, op_acc: 42.97%] [G loss: 0.922748]\n",
      "epoch:39 step:31204[D loss: 0.399423, acc: 61.72%, op_acc: 42.19%] [G loss: 0.893785]\n",
      "epoch:39 step:31205[D loss: 0.435831, acc: 60.16%, op_acc: 36.72%] [G loss: 0.895812]\n",
      "epoch:39 step:31206[D loss: 0.410938, acc: 62.50%, op_acc: 41.41%] [G loss: 0.837249]\n",
      "epoch:39 step:31207[D loss: 0.418021, acc: 54.69%, op_acc: 42.19%] [G loss: 0.866324]\n",
      "epoch:39 step:31208[D loss: 0.426624, acc: 62.50%, op_acc: 35.94%] [G loss: 0.907670]\n",
      "epoch:39 step:31209[D loss: 0.421791, acc: 62.50%, op_acc: 42.97%] [G loss: 0.791587]\n",
      "epoch:39 step:31210[D loss: 0.438424, acc: 62.50%, op_acc: 42.19%] [G loss: 0.865600]\n",
      "epoch:39 step:31211[D loss: 0.409896, acc: 61.72%, op_acc: 42.19%] [G loss: 0.944584]\n",
      "epoch:39 step:31212[D loss: 0.413574, acc: 56.25%, op_acc: 46.09%] [G loss: 0.858105]\n",
      "epoch:39 step:31213[D loss: 0.410994, acc: 63.28%, op_acc: 37.50%] [G loss: 0.902145]\n",
      "epoch:39 step:31214[D loss: 0.389584, acc: 64.84%, op_acc: 48.44%] [G loss: 0.977371]\n",
      "epoch:39 step:31215[D loss: 0.417430, acc: 62.50%, op_acc: 41.41%] [G loss: 0.906819]\n",
      "epoch:39 step:31216[D loss: 0.405316, acc: 63.28%, op_acc: 41.41%] [G loss: 0.825475]\n",
      "epoch:39 step:31217[D loss: 0.394535, acc: 64.06%, op_acc: 46.09%] [G loss: 0.925004]\n",
      "epoch:39 step:31218[D loss: 0.432321, acc: 55.47%, op_acc: 35.94%] [G loss: 0.864002]\n",
      "epoch:39 step:31219[D loss: 0.420483, acc: 60.94%, op_acc: 40.62%] [G loss: 0.819330]\n",
      "epoch:39 step:31220[D loss: 0.385366, acc: 67.97%, op_acc: 41.41%] [G loss: 0.868938]\n",
      "epoch:39 step:31221[D loss: 0.431657, acc: 55.47%, op_acc: 43.75%] [G loss: 0.876871]\n",
      "epoch:39 step:31222[D loss: 0.433685, acc: 57.03%, op_acc: 46.88%] [G loss: 0.860639]\n",
      "epoch:39 step:31223[D loss: 0.431663, acc: 57.03%, op_acc: 35.94%] [G loss: 0.854541]\n",
      "epoch:39 step:31224[D loss: 0.419043, acc: 53.12%, op_acc: 40.62%] [G loss: 0.887044]\n",
      "epoch:39 step:31225[D loss: 0.409818, acc: 58.59%, op_acc: 41.41%] [G loss: 0.843497]\n",
      "epoch:39 step:31226[D loss: 0.379664, acc: 64.06%, op_acc: 44.53%] [G loss: 0.901148]\n",
      "epoch:39 step:31227[D loss: 0.404222, acc: 60.94%, op_acc: 39.84%] [G loss: 0.930666]\n",
      "epoch:39 step:31228[D loss: 0.399338, acc: 69.53%, op_acc: 44.53%] [G loss: 0.851912]\n",
      "epoch:39 step:31229[D loss: 0.411402, acc: 57.03%, op_acc: 40.62%] [G loss: 0.928323]\n",
      "epoch:39 step:31230[D loss: 0.482057, acc: 45.31%, op_acc: 27.34%] [G loss: 0.858668]\n",
      "epoch:39 step:31231[D loss: 0.412128, acc: 64.06%, op_acc: 39.06%] [G loss: 0.963898]\n",
      "epoch:39 step:31232[D loss: 0.432047, acc: 63.28%, op_acc: 39.84%] [G loss: 0.856615]\n",
      "epoch:39 step:31233[D loss: 0.381987, acc: 67.97%, op_acc: 46.88%] [G loss: 0.932745]\n",
      "epoch:39 step:31234[D loss: 0.430239, acc: 58.59%, op_acc: 36.72%] [G loss: 0.829275]\n",
      "epoch:39 step:31235[D loss: 0.410030, acc: 57.03%, op_acc: 42.19%] [G loss: 0.977707]\n",
      "epoch:39 step:31236[D loss: 0.445057, acc: 46.09%, op_acc: 41.41%] [G loss: 0.860830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31237[D loss: 0.387960, acc: 63.28%, op_acc: 48.44%] [G loss: 0.786935]\n",
      "epoch:39 step:31238[D loss: 0.387356, acc: 64.84%, op_acc: 42.97%] [G loss: 0.893793]\n",
      "epoch:39 step:31239[D loss: 0.395166, acc: 62.50%, op_acc: 42.97%] [G loss: 0.925849]\n",
      "epoch:39 step:31240[D loss: 0.403865, acc: 63.28%, op_acc: 37.50%] [G loss: 1.007676]\n",
      "epoch:40 step:31241[D loss: 0.397236, acc: 64.06%, op_acc: 42.97%] [G loss: 0.863119]\n",
      "epoch:40 step:31242[D loss: 0.392058, acc: 63.28%, op_acc: 39.84%] [G loss: 0.868558]\n",
      "epoch:40 step:31243[D loss: 0.427527, acc: 57.03%, op_acc: 39.06%] [G loss: 1.039757]\n",
      "epoch:40 step:31244[D loss: 0.414574, acc: 59.38%, op_acc: 43.75%] [G loss: 0.757167]\n",
      "epoch:40 step:31245[D loss: 0.395818, acc: 66.41%, op_acc: 42.97%] [G loss: 0.925485]\n",
      "epoch:40 step:31246[D loss: 0.447776, acc: 47.66%, op_acc: 42.97%] [G loss: 0.792644]\n",
      "epoch:40 step:31247[D loss: 0.430365, acc: 52.34%, op_acc: 41.41%] [G loss: 0.907326]\n",
      "epoch:40 step:31248[D loss: 0.416890, acc: 58.59%, op_acc: 41.41%] [G loss: 0.925163]\n",
      "epoch:40 step:31249[D loss: 0.432263, acc: 53.12%, op_acc: 43.75%] [G loss: 0.856146]\n",
      "epoch:40 step:31250[D loss: 0.434375, acc: 57.03%, op_acc: 39.06%] [G loss: 0.855216]\n",
      "##############\n",
      "[0.83280523 0.87132403 0.8207116  0.81297732 0.77625078 0.84655525\n",
      " 0.88540818 0.82654598 0.79796683 0.81225093]\n",
      "##########\n",
      "epoch:40 step:31251[D loss: 0.428079, acc: 53.91%, op_acc: 39.84%] [G loss: 0.908907]\n",
      "epoch:40 step:31252[D loss: 0.422605, acc: 59.38%, op_acc: 36.72%] [G loss: 0.870352]\n",
      "epoch:40 step:31253[D loss: 0.395241, acc: 65.62%, op_acc: 43.75%] [G loss: 0.930704]\n",
      "epoch:40 step:31254[D loss: 0.406156, acc: 60.16%, op_acc: 40.62%] [G loss: 0.944579]\n",
      "epoch:40 step:31255[D loss: 0.396927, acc: 68.75%, op_acc: 43.75%] [G loss: 0.950569]\n",
      "epoch:40 step:31256[D loss: 0.436344, acc: 53.91%, op_acc: 41.41%] [G loss: 0.810428]\n",
      "epoch:40 step:31257[D loss: 0.435311, acc: 52.34%, op_acc: 34.38%] [G loss: 0.819710]\n",
      "epoch:40 step:31258[D loss: 0.429006, acc: 54.69%, op_acc: 37.50%] [G loss: 0.841201]\n",
      "epoch:40 step:31259[D loss: 0.450250, acc: 53.12%, op_acc: 39.06%] [G loss: 0.824355]\n",
      "epoch:40 step:31260[D loss: 0.404429, acc: 60.94%, op_acc: 39.06%] [G loss: 0.883735]\n",
      "epoch:40 step:31261[D loss: 0.442303, acc: 50.00%, op_acc: 40.62%] [G loss: 0.926191]\n",
      "epoch:40 step:31262[D loss: 0.389975, acc: 69.53%, op_acc: 42.97%] [G loss: 0.865481]\n",
      "epoch:40 step:31263[D loss: 0.425380, acc: 59.38%, op_acc: 43.75%] [G loss: 0.901550]\n",
      "epoch:40 step:31264[D loss: 0.429062, acc: 60.16%, op_acc: 38.28%] [G loss: 0.944893]\n",
      "epoch:40 step:31265[D loss: 0.441040, acc: 54.69%, op_acc: 42.19%] [G loss: 0.951482]\n",
      "epoch:40 step:31266[D loss: 0.400365, acc: 63.28%, op_acc: 39.06%] [G loss: 0.934713]\n",
      "epoch:40 step:31267[D loss: 0.421300, acc: 60.16%, op_acc: 39.84%] [G loss: 0.971279]\n",
      "epoch:40 step:31268[D loss: 0.433838, acc: 54.69%, op_acc: 45.31%] [G loss: 0.945397]\n",
      "epoch:40 step:31269[D loss: 0.396928, acc: 64.06%, op_acc: 46.09%] [G loss: 0.842340]\n",
      "epoch:40 step:31270[D loss: 0.402376, acc: 60.16%, op_acc: 45.31%] [G loss: 0.807918]\n",
      "epoch:40 step:31271[D loss: 0.451058, acc: 53.12%, op_acc: 35.94%] [G loss: 0.917467]\n",
      "epoch:40 step:31272[D loss: 0.409751, acc: 60.94%, op_acc: 40.62%] [G loss: 0.922337]\n",
      "epoch:40 step:31273[D loss: 0.420675, acc: 59.38%, op_acc: 38.28%] [G loss: 0.914182]\n",
      "epoch:40 step:31274[D loss: 0.416963, acc: 55.47%, op_acc: 45.31%] [G loss: 0.944249]\n",
      "epoch:40 step:31275[D loss: 0.417760, acc: 65.62%, op_acc: 40.62%] [G loss: 0.830642]\n",
      "epoch:40 step:31276[D loss: 0.403300, acc: 61.72%, op_acc: 42.19%] [G loss: 0.880197]\n",
      "epoch:40 step:31277[D loss: 0.390705, acc: 69.53%, op_acc: 44.53%] [G loss: 0.889816]\n",
      "epoch:40 step:31278[D loss: 0.419709, acc: 57.03%, op_acc: 43.75%] [G loss: 0.870884]\n",
      "epoch:40 step:31279[D loss: 0.442925, acc: 53.12%, op_acc: 40.62%] [G loss: 0.892668]\n",
      "epoch:40 step:31280[D loss: 0.421541, acc: 60.16%, op_acc: 40.62%] [G loss: 0.924427]\n",
      "epoch:40 step:31281[D loss: 0.417385, acc: 55.47%, op_acc: 34.38%] [G loss: 0.861016]\n",
      "epoch:40 step:31282[D loss: 0.365517, acc: 62.50%, op_acc: 48.44%] [G loss: 0.857461]\n",
      "epoch:40 step:31283[D loss: 0.415585, acc: 59.38%, op_acc: 39.06%] [G loss: 0.915419]\n",
      "epoch:40 step:31284[D loss: 0.418637, acc: 55.47%, op_acc: 37.50%] [G loss: 0.909563]\n",
      "epoch:40 step:31285[D loss: 0.420333, acc: 53.91%, op_acc: 42.97%] [G loss: 0.962214]\n",
      "epoch:40 step:31286[D loss: 0.393544, acc: 65.62%, op_acc: 40.62%] [G loss: 0.864431]\n",
      "epoch:40 step:31287[D loss: 0.419776, acc: 60.94%, op_acc: 37.50%] [G loss: 0.911069]\n",
      "epoch:40 step:31288[D loss: 0.414148, acc: 60.94%, op_acc: 44.53%] [G loss: 0.883757]\n",
      "epoch:40 step:31289[D loss: 0.393472, acc: 62.50%, op_acc: 45.31%] [G loss: 0.795515]\n",
      "epoch:40 step:31290[D loss: 0.431050, acc: 57.03%, op_acc: 39.84%] [G loss: 0.855891]\n",
      "epoch:40 step:31291[D loss: 0.393806, acc: 65.62%, op_acc: 42.19%] [G loss: 0.912284]\n",
      "epoch:40 step:31292[D loss: 0.414328, acc: 64.84%, op_acc: 35.94%] [G loss: 0.973217]\n",
      "epoch:40 step:31293[D loss: 0.449852, acc: 53.91%, op_acc: 32.81%] [G loss: 0.893100]\n",
      "epoch:40 step:31294[D loss: 0.409751, acc: 63.28%, op_acc: 42.19%] [G loss: 0.925142]\n",
      "epoch:40 step:31295[D loss: 0.380447, acc: 64.84%, op_acc: 43.75%] [G loss: 0.929230]\n",
      "epoch:40 step:31296[D loss: 0.381932, acc: 74.22%, op_acc: 44.53%] [G loss: 0.841476]\n",
      "epoch:40 step:31297[D loss: 0.407042, acc: 60.94%, op_acc: 42.97%] [G loss: 0.827916]\n",
      "epoch:40 step:31298[D loss: 0.427236, acc: 53.91%, op_acc: 42.97%] [G loss: 0.843030]\n",
      "epoch:40 step:31299[D loss: 0.385273, acc: 61.72%, op_acc: 46.09%] [G loss: 0.879502]\n",
      "epoch:40 step:31300[D loss: 0.386767, acc: 69.53%, op_acc: 42.97%] [G loss: 0.846364]\n",
      "##############\n",
      "[0.83229192 0.86536474 0.82186276 0.81636009 0.79704515 0.84392625\n",
      " 0.89234255 0.85062454 0.78980024 0.83292617]\n",
      "##########\n",
      "epoch:40 step:31301[D loss: 0.425354, acc: 55.47%, op_acc: 40.62%] [G loss: 0.849082]\n",
      "epoch:40 step:31302[D loss: 0.408240, acc: 61.72%, op_acc: 48.44%] [G loss: 0.928688]\n",
      "epoch:40 step:31303[D loss: 0.420081, acc: 55.47%, op_acc: 40.62%] [G loss: 0.885648]\n",
      "epoch:40 step:31304[D loss: 0.386910, acc: 67.19%, op_acc: 44.53%] [G loss: 0.857981]\n",
      "epoch:40 step:31305[D loss: 0.448094, acc: 53.12%, op_acc: 40.62%] [G loss: 0.785151]\n",
      "epoch:40 step:31306[D loss: 0.411575, acc: 60.16%, op_acc: 39.06%] [G loss: 0.835926]\n",
      "epoch:40 step:31307[D loss: 0.422010, acc: 60.16%, op_acc: 40.62%] [G loss: 0.840582]\n",
      "epoch:40 step:31308[D loss: 0.416179, acc: 57.03%, op_acc: 46.88%] [G loss: 0.856272]\n",
      "epoch:40 step:31309[D loss: 0.414573, acc: 55.47%, op_acc: 45.31%] [G loss: 0.815229]\n",
      "epoch:40 step:31310[D loss: 0.437917, acc: 58.59%, op_acc: 43.75%] [G loss: 0.901934]\n",
      "epoch:40 step:31311[D loss: 0.474994, acc: 50.00%, op_acc: 32.03%] [G loss: 0.937838]\n",
      "epoch:40 step:31312[D loss: 0.384171, acc: 68.75%, op_acc: 43.75%] [G loss: 0.909192]\n",
      "epoch:40 step:31313[D loss: 0.413719, acc: 62.50%, op_acc: 41.41%] [G loss: 0.882482]\n",
      "epoch:40 step:31314[D loss: 0.410644, acc: 59.38%, op_acc: 45.31%] [G loss: 0.843927]\n",
      "epoch:40 step:31315[D loss: 0.403488, acc: 64.06%, op_acc: 46.09%] [G loss: 0.911548]\n",
      "epoch:40 step:31316[D loss: 0.427242, acc: 59.38%, op_acc: 41.41%] [G loss: 0.978765]\n",
      "epoch:40 step:31317[D loss: 0.417024, acc: 67.19%, op_acc: 39.06%] [G loss: 0.936055]\n",
      "epoch:40 step:31318[D loss: 0.418658, acc: 66.41%, op_acc: 37.50%] [G loss: 0.913781]\n",
      "epoch:40 step:31319[D loss: 0.397717, acc: 67.97%, op_acc: 47.66%] [G loss: 0.930575]\n",
      "epoch:40 step:31320[D loss: 0.471243, acc: 55.47%, op_acc: 34.38%] [G loss: 0.886796]\n",
      "epoch:40 step:31321[D loss: 0.414098, acc: 71.09%, op_acc: 38.28%] [G loss: 0.904738]\n",
      "epoch:40 step:31322[D loss: 0.369931, acc: 67.97%, op_acc: 44.53%] [G loss: 0.922745]\n",
      "epoch:40 step:31323[D loss: 0.430990, acc: 53.91%, op_acc: 42.19%] [G loss: 0.964266]\n",
      "epoch:40 step:31324[D loss: 0.423347, acc: 55.47%, op_acc: 36.72%] [G loss: 1.021070]\n",
      "epoch:40 step:31325[D loss: 0.415269, acc: 64.06%, op_acc: 35.94%] [G loss: 1.037009]\n",
      "epoch:40 step:31326[D loss: 0.385446, acc: 68.75%, op_acc: 46.88%] [G loss: 0.957515]\n",
      "epoch:40 step:31327[D loss: 0.407132, acc: 64.06%, op_acc: 43.75%] [G loss: 0.849546]\n",
      "epoch:40 step:31328[D loss: 0.467134, acc: 54.69%, op_acc: 32.81%] [G loss: 0.807917]\n",
      "epoch:40 step:31329[D loss: 0.433802, acc: 50.00%, op_acc: 37.50%] [G loss: 0.880393]\n",
      "epoch:40 step:31330[D loss: 0.428217, acc: 57.03%, op_acc: 37.50%] [G loss: 0.808446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31331[D loss: 0.410314, acc: 58.59%, op_acc: 42.19%] [G loss: 0.954478]\n",
      "epoch:40 step:31332[D loss: 0.425815, acc: 59.38%, op_acc: 41.41%] [G loss: 0.870811]\n",
      "epoch:40 step:31333[D loss: 0.403843, acc: 61.72%, op_acc: 46.09%] [G loss: 0.875169]\n",
      "epoch:40 step:31334[D loss: 0.392843, acc: 62.50%, op_acc: 43.75%] [G loss: 0.870782]\n",
      "epoch:40 step:31335[D loss: 0.413855, acc: 55.47%, op_acc: 43.75%] [G loss: 0.912957]\n",
      "epoch:40 step:31336[D loss: 0.417048, acc: 67.19%, op_acc: 42.97%] [G loss: 0.986040]\n",
      "epoch:40 step:31337[D loss: 0.368563, acc: 67.19%, op_acc: 48.44%] [G loss: 0.918479]\n",
      "epoch:40 step:31338[D loss: 0.407193, acc: 59.38%, op_acc: 42.97%] [G loss: 0.912446]\n",
      "epoch:40 step:31339[D loss: 0.410561, acc: 58.59%, op_acc: 39.06%] [G loss: 0.828787]\n",
      "epoch:40 step:31340[D loss: 0.393352, acc: 58.59%, op_acc: 49.22%] [G loss: 0.881822]\n",
      "epoch:40 step:31341[D loss: 0.412872, acc: 62.50%, op_acc: 35.94%] [G loss: 0.941863]\n",
      "epoch:40 step:31342[D loss: 0.429023, acc: 57.03%, op_acc: 40.62%] [G loss: 0.924760]\n",
      "epoch:40 step:31343[D loss: 0.416098, acc: 62.50%, op_acc: 41.41%] [G loss: 0.990460]\n",
      "epoch:40 step:31344[D loss: 0.398962, acc: 69.53%, op_acc: 38.28%] [G loss: 0.960466]\n",
      "epoch:40 step:31345[D loss: 0.400769, acc: 63.28%, op_acc: 44.53%] [G loss: 0.908077]\n",
      "epoch:40 step:31346[D loss: 0.427780, acc: 60.16%, op_acc: 40.62%] [G loss: 0.875000]\n",
      "epoch:40 step:31347[D loss: 0.395146, acc: 61.72%, op_acc: 43.75%] [G loss: 0.946907]\n",
      "epoch:40 step:31348[D loss: 0.433047, acc: 64.06%, op_acc: 37.50%] [G loss: 0.926338]\n",
      "epoch:40 step:31349[D loss: 0.405367, acc: 60.16%, op_acc: 49.22%] [G loss: 0.905465]\n",
      "epoch:40 step:31350[D loss: 0.382839, acc: 67.97%, op_acc: 43.75%] [G loss: 0.935023]\n",
      "##############\n",
      "[0.85831226 0.85564727 0.81509735 0.80907242 0.79614769 0.81359157\n",
      " 0.87563419 0.82681236 0.80754276 0.83458511]\n",
      "##########\n",
      "epoch:40 step:31351[D loss: 0.414080, acc: 62.50%, op_acc: 43.75%] [G loss: 0.914559]\n",
      "epoch:40 step:31352[D loss: 0.411818, acc: 58.59%, op_acc: 42.97%] [G loss: 0.848228]\n",
      "epoch:40 step:31353[D loss: 0.437794, acc: 52.34%, op_acc: 37.50%] [G loss: 0.792015]\n",
      "epoch:40 step:31354[D loss: 0.394288, acc: 65.62%, op_acc: 45.31%] [G loss: 0.891767]\n",
      "epoch:40 step:31355[D loss: 0.414957, acc: 56.25%, op_acc: 46.88%] [G loss: 0.845994]\n",
      "epoch:40 step:31356[D loss: 0.403395, acc: 66.41%, op_acc: 35.94%] [G loss: 0.853071]\n",
      "epoch:40 step:31357[D loss: 0.424086, acc: 53.12%, op_acc: 46.88%] [G loss: 0.901210]\n",
      "epoch:40 step:31358[D loss: 0.403666, acc: 65.62%, op_acc: 44.53%] [G loss: 0.900447]\n",
      "epoch:40 step:31359[D loss: 0.418790, acc: 60.16%, op_acc: 41.41%] [G loss: 0.786572]\n",
      "epoch:40 step:31360[D loss: 0.408319, acc: 60.94%, op_acc: 40.62%] [G loss: 0.836040]\n",
      "epoch:40 step:31361[D loss: 0.385150, acc: 70.31%, op_acc: 41.41%] [G loss: 0.878926]\n",
      "epoch:40 step:31362[D loss: 0.407518, acc: 63.28%, op_acc: 41.41%] [G loss: 0.931762]\n",
      "epoch:40 step:31363[D loss: 0.434369, acc: 53.12%, op_acc: 42.97%] [G loss: 0.818012]\n",
      "epoch:40 step:31364[D loss: 0.413822, acc: 56.25%, op_acc: 40.62%] [G loss: 0.947075]\n",
      "epoch:40 step:31365[D loss: 0.428163, acc: 54.69%, op_acc: 42.19%] [G loss: 0.904926]\n",
      "epoch:40 step:31366[D loss: 0.401047, acc: 65.62%, op_acc: 42.19%] [G loss: 0.920849]\n",
      "epoch:40 step:31367[D loss: 0.391331, acc: 60.94%, op_acc: 45.31%] [G loss: 0.811858]\n",
      "epoch:40 step:31368[D loss: 0.415147, acc: 60.16%, op_acc: 38.28%] [G loss: 0.817741]\n",
      "epoch:40 step:31369[D loss: 0.449992, acc: 51.56%, op_acc: 39.06%] [G loss: 0.846238]\n",
      "epoch:40 step:31370[D loss: 0.439919, acc: 56.25%, op_acc: 39.06%] [G loss: 0.912305]\n",
      "epoch:40 step:31371[D loss: 0.389597, acc: 66.41%, op_acc: 49.22%] [G loss: 0.837214]\n",
      "epoch:40 step:31372[D loss: 0.369146, acc: 67.19%, op_acc: 45.31%] [G loss: 0.936567]\n",
      "epoch:40 step:31373[D loss: 0.442621, acc: 64.06%, op_acc: 35.16%] [G loss: 0.833208]\n",
      "epoch:40 step:31374[D loss: 0.402948, acc: 61.72%, op_acc: 43.75%] [G loss: 0.922193]\n",
      "epoch:40 step:31375[D loss: 0.457758, acc: 47.66%, op_acc: 41.41%] [G loss: 0.821963]\n",
      "epoch:40 step:31376[D loss: 0.395283, acc: 63.28%, op_acc: 46.09%] [G loss: 0.919686]\n",
      "epoch:40 step:31377[D loss: 0.419787, acc: 61.72%, op_acc: 40.62%] [G loss: 0.947752]\n",
      "epoch:40 step:31378[D loss: 0.405274, acc: 63.28%, op_acc: 41.41%] [G loss: 0.875313]\n",
      "epoch:40 step:31379[D loss: 0.391102, acc: 69.53%, op_acc: 44.53%] [G loss: 0.945896]\n",
      "epoch:40 step:31380[D loss: 0.444355, acc: 57.03%, op_acc: 39.84%] [G loss: 0.776139]\n",
      "epoch:40 step:31381[D loss: 0.424267, acc: 58.59%, op_acc: 39.06%] [G loss: 0.907353]\n",
      "epoch:40 step:31382[D loss: 0.399377, acc: 60.94%, op_acc: 44.53%] [G loss: 0.835993]\n",
      "epoch:40 step:31383[D loss: 0.400977, acc: 61.72%, op_acc: 44.53%] [G loss: 0.983204]\n",
      "epoch:40 step:31384[D loss: 0.397310, acc: 62.50%, op_acc: 46.09%] [G loss: 0.881926]\n",
      "epoch:40 step:31385[D loss: 0.398441, acc: 64.84%, op_acc: 42.97%] [G loss: 0.836239]\n",
      "epoch:40 step:31386[D loss: 0.383752, acc: 61.72%, op_acc: 38.28%] [G loss: 0.925321]\n",
      "epoch:40 step:31387[D loss: 0.384438, acc: 67.19%, op_acc: 46.88%] [G loss: 0.851486]\n",
      "epoch:40 step:31388[D loss: 0.438752, acc: 53.12%, op_acc: 42.19%] [G loss: 0.908544]\n",
      "epoch:40 step:31389[D loss: 0.415871, acc: 57.03%, op_acc: 39.06%] [G loss: 0.874825]\n",
      "epoch:40 step:31390[D loss: 0.427280, acc: 55.47%, op_acc: 40.62%] [G loss: 1.017613]\n",
      "epoch:40 step:31391[D loss: 0.379421, acc: 64.84%, op_acc: 46.88%] [G loss: 0.897197]\n",
      "epoch:40 step:31392[D loss: 0.392599, acc: 67.19%, op_acc: 48.44%] [G loss: 0.926921]\n",
      "epoch:40 step:31393[D loss: 0.407299, acc: 65.62%, op_acc: 40.62%] [G loss: 0.875104]\n",
      "epoch:40 step:31394[D loss: 0.413343, acc: 60.16%, op_acc: 45.31%] [G loss: 0.905930]\n",
      "epoch:40 step:31395[D loss: 0.431481, acc: 55.47%, op_acc: 35.94%] [G loss: 0.927537]\n",
      "epoch:40 step:31396[D loss: 0.411039, acc: 61.72%, op_acc: 41.41%] [G loss: 1.003882]\n",
      "epoch:40 step:31397[D loss: 0.414066, acc: 59.38%, op_acc: 39.84%] [G loss: 0.828908]\n",
      "epoch:40 step:31398[D loss: 0.422478, acc: 56.25%, op_acc: 40.62%] [G loss: 0.882968]\n",
      "epoch:40 step:31399[D loss: 0.388869, acc: 67.19%, op_acc: 39.06%] [G loss: 0.834701]\n",
      "epoch:40 step:31400[D loss: 0.430470, acc: 56.25%, op_acc: 39.84%] [G loss: 1.008169]\n",
      "##############\n",
      "[0.8749164  0.8510639  0.81678756 0.82236279 0.80007553 0.83760488\n",
      " 0.89173927 0.83613972 0.78737938 0.83960044]\n",
      "##########\n",
      "epoch:40 step:31401[D loss: 0.426466, acc: 51.56%, op_acc: 46.09%] [G loss: 0.878241]\n",
      "epoch:40 step:31402[D loss: 0.387850, acc: 66.41%, op_acc: 51.56%] [G loss: 0.846808]\n",
      "epoch:40 step:31403[D loss: 0.424886, acc: 61.72%, op_acc: 35.94%] [G loss: 0.855283]\n",
      "epoch:40 step:31404[D loss: 0.428374, acc: 59.38%, op_acc: 39.06%] [G loss: 0.881407]\n",
      "epoch:40 step:31405[D loss: 0.409905, acc: 57.03%, op_acc: 46.88%] [G loss: 0.877093]\n",
      "epoch:40 step:31406[D loss: 0.424435, acc: 55.47%, op_acc: 40.62%] [G loss: 0.880313]\n",
      "epoch:40 step:31407[D loss: 0.426073, acc: 55.47%, op_acc: 42.19%] [G loss: 0.918698]\n",
      "epoch:40 step:31408[D loss: 0.428882, acc: 59.38%, op_acc: 40.62%] [G loss: 0.879850]\n",
      "epoch:40 step:31409[D loss: 0.413592, acc: 55.47%, op_acc: 46.88%] [G loss: 0.934664]\n",
      "epoch:40 step:31410[D loss: 0.428414, acc: 53.91%, op_acc: 40.62%] [G loss: 0.816146]\n",
      "epoch:40 step:31411[D loss: 0.460967, acc: 51.56%, op_acc: 34.38%] [G loss: 0.874719]\n",
      "epoch:40 step:31412[D loss: 0.405849, acc: 65.62%, op_acc: 34.38%] [G loss: 0.838363]\n",
      "epoch:40 step:31413[D loss: 0.427108, acc: 60.94%, op_acc: 45.31%] [G loss: 0.910459]\n",
      "epoch:40 step:31414[D loss: 0.467100, acc: 54.69%, op_acc: 39.84%] [G loss: 0.835239]\n",
      "epoch:40 step:31415[D loss: 0.399992, acc: 62.50%, op_acc: 38.28%] [G loss: 0.894840]\n",
      "epoch:40 step:31416[D loss: 0.441109, acc: 52.34%, op_acc: 41.41%] [G loss: 0.824116]\n",
      "epoch:40 step:31417[D loss: 0.409319, acc: 59.38%, op_acc: 40.62%] [G loss: 0.929480]\n",
      "epoch:40 step:31418[D loss: 0.413680, acc: 59.38%, op_acc: 37.50%] [G loss: 0.897902]\n",
      "epoch:40 step:31419[D loss: 0.391339, acc: 60.94%, op_acc: 42.19%] [G loss: 0.928169]\n",
      "epoch:40 step:31420[D loss: 0.397677, acc: 69.53%, op_acc: 42.97%] [G loss: 0.925774]\n",
      "epoch:40 step:31421[D loss: 0.421981, acc: 50.78%, op_acc: 41.41%] [G loss: 0.890198]\n",
      "epoch:40 step:31422[D loss: 0.429892, acc: 58.59%, op_acc: 39.06%] [G loss: 0.855701]\n",
      "epoch:40 step:31423[D loss: 0.436765, acc: 58.59%, op_acc: 42.19%] [G loss: 0.922546]\n",
      "epoch:40 step:31424[D loss: 0.402597, acc: 59.38%, op_acc: 39.06%] [G loss: 0.880965]\n",
      "epoch:40 step:31425[D loss: 0.413746, acc: 60.16%, op_acc: 37.50%] [G loss: 0.837370]\n",
      "epoch:40 step:31426[D loss: 0.426778, acc: 58.59%, op_acc: 36.72%] [G loss: 0.826066]\n",
      "epoch:40 step:31427[D loss: 0.446647, acc: 54.69%, op_acc: 39.06%] [G loss: 0.864646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31428[D loss: 0.416120, acc: 55.47%, op_acc: 41.41%] [G loss: 0.857475]\n",
      "epoch:40 step:31429[D loss: 0.405175, acc: 64.06%, op_acc: 38.28%] [G loss: 0.907668]\n",
      "epoch:40 step:31430[D loss: 0.432447, acc: 60.94%, op_acc: 43.75%] [G loss: 0.947100]\n",
      "epoch:40 step:31431[D loss: 0.401633, acc: 63.28%, op_acc: 46.09%] [G loss: 0.867330]\n",
      "epoch:40 step:31432[D loss: 0.389152, acc: 73.44%, op_acc: 39.06%] [G loss: 0.940446]\n",
      "epoch:40 step:31433[D loss: 0.407860, acc: 62.50%, op_acc: 35.94%] [G loss: 0.848845]\n",
      "epoch:40 step:31434[D loss: 0.409386, acc: 63.28%, op_acc: 39.84%] [G loss: 0.969992]\n",
      "epoch:40 step:31435[D loss: 0.415723, acc: 61.72%, op_acc: 39.06%] [G loss: 0.912430]\n",
      "epoch:40 step:31436[D loss: 0.394225, acc: 67.97%, op_acc: 40.62%] [G loss: 0.961006]\n",
      "epoch:40 step:31437[D loss: 0.460512, acc: 50.78%, op_acc: 40.62%] [G loss: 0.865299]\n",
      "epoch:40 step:31438[D loss: 0.421558, acc: 58.59%, op_acc: 41.41%] [G loss: 0.963276]\n",
      "epoch:40 step:31439[D loss: 0.409762, acc: 60.94%, op_acc: 44.53%] [G loss: 0.889980]\n",
      "epoch:40 step:31440[D loss: 0.400140, acc: 67.19%, op_acc: 40.62%] [G loss: 0.879887]\n",
      "epoch:40 step:31441[D loss: 0.422038, acc: 57.03%, op_acc: 43.75%] [G loss: 0.864249]\n",
      "epoch:40 step:31442[D loss: 0.445872, acc: 51.56%, op_acc: 37.50%] [G loss: 0.863466]\n",
      "epoch:40 step:31443[D loss: 0.402405, acc: 63.28%, op_acc: 45.31%] [G loss: 0.918068]\n",
      "epoch:40 step:31444[D loss: 0.426690, acc: 64.06%, op_acc: 42.97%] [G loss: 0.897835]\n",
      "epoch:40 step:31445[D loss: 0.407646, acc: 60.16%, op_acc: 41.41%] [G loss: 0.938938]\n",
      "epoch:40 step:31446[D loss: 0.410962, acc: 66.41%, op_acc: 39.06%] [G loss: 0.904511]\n",
      "epoch:40 step:31447[D loss: 0.382055, acc: 72.66%, op_acc: 40.62%] [G loss: 0.867336]\n",
      "epoch:40 step:31448[D loss: 0.440116, acc: 56.25%, op_acc: 43.75%] [G loss: 0.895274]\n",
      "epoch:40 step:31449[D loss: 0.430856, acc: 55.47%, op_acc: 37.50%] [G loss: 0.846749]\n",
      "epoch:40 step:31450[D loss: 0.410247, acc: 64.84%, op_acc: 41.41%] [G loss: 0.933939]\n",
      "##############\n",
      "[0.85236911 0.84915508 0.83360286 0.81184349 0.77450873 0.82254002\n",
      " 0.90435741 0.84569925 0.79548452 0.82809105]\n",
      "##########\n",
      "epoch:40 step:31451[D loss: 0.426524, acc: 56.25%, op_acc: 40.62%] [G loss: 0.904705]\n",
      "epoch:40 step:31452[D loss: 0.431398, acc: 61.72%, op_acc: 38.28%] [G loss: 0.851770]\n",
      "epoch:40 step:31453[D loss: 0.419251, acc: 57.03%, op_acc: 37.50%] [G loss: 0.899358]\n",
      "epoch:40 step:31454[D loss: 0.397498, acc: 63.28%, op_acc: 46.09%] [G loss: 0.905582]\n",
      "epoch:40 step:31455[D loss: 0.444016, acc: 56.25%, op_acc: 35.94%] [G loss: 0.820539]\n",
      "epoch:40 step:31456[D loss: 0.407273, acc: 61.72%, op_acc: 38.28%] [G loss: 0.998743]\n",
      "epoch:40 step:31457[D loss: 0.412048, acc: 53.91%, op_acc: 44.53%] [G loss: 0.873119]\n",
      "epoch:40 step:31458[D loss: 0.420970, acc: 58.59%, op_acc: 45.31%] [G loss: 0.920035]\n",
      "epoch:40 step:31459[D loss: 0.403082, acc: 63.28%, op_acc: 35.16%] [G loss: 0.988405]\n",
      "epoch:40 step:31460[D loss: 0.433307, acc: 57.81%, op_acc: 42.97%] [G loss: 0.939331]\n",
      "epoch:40 step:31461[D loss: 0.405892, acc: 61.72%, op_acc: 39.06%] [G loss: 0.956491]\n",
      "epoch:40 step:31462[D loss: 0.413359, acc: 61.72%, op_acc: 44.53%] [G loss: 0.864874]\n",
      "epoch:40 step:31463[D loss: 0.408601, acc: 62.50%, op_acc: 46.09%] [G loss: 0.857374]\n",
      "epoch:40 step:31464[D loss: 0.408789, acc: 62.50%, op_acc: 45.31%] [G loss: 0.850325]\n",
      "epoch:40 step:31465[D loss: 0.421163, acc: 63.28%, op_acc: 42.97%] [G loss: 0.817353]\n",
      "epoch:40 step:31466[D loss: 0.424441, acc: 54.69%, op_acc: 41.41%] [G loss: 0.882163]\n",
      "epoch:40 step:31467[D loss: 0.419871, acc: 60.94%, op_acc: 42.97%] [G loss: 0.870377]\n",
      "epoch:40 step:31468[D loss: 0.394050, acc: 67.97%, op_acc: 44.53%] [G loss: 0.847561]\n",
      "epoch:40 step:31469[D loss: 0.425498, acc: 57.81%, op_acc: 42.97%] [G loss: 0.930180]\n",
      "epoch:40 step:31470[D loss: 0.404967, acc: 67.97%, op_acc: 38.28%] [G loss: 0.871386]\n",
      "epoch:40 step:31471[D loss: 0.399097, acc: 60.16%, op_acc: 43.75%] [G loss: 0.853849]\n",
      "epoch:40 step:31472[D loss: 0.386909, acc: 67.19%, op_acc: 42.19%] [G loss: 0.871413]\n",
      "epoch:40 step:31473[D loss: 0.378247, acc: 71.88%, op_acc: 46.09%] [G loss: 0.861137]\n",
      "epoch:40 step:31474[D loss: 0.401290, acc: 67.19%, op_acc: 39.06%] [G loss: 0.829010]\n",
      "epoch:40 step:31475[D loss: 0.393586, acc: 60.94%, op_acc: 42.97%] [G loss: 0.861146]\n",
      "epoch:40 step:31476[D loss: 0.396278, acc: 67.19%, op_acc: 42.19%] [G loss: 0.888869]\n",
      "epoch:40 step:31477[D loss: 0.377615, acc: 68.75%, op_acc: 48.44%] [G loss: 0.953853]\n",
      "epoch:40 step:31478[D loss: 0.409077, acc: 56.25%, op_acc: 41.41%] [G loss: 0.925624]\n",
      "epoch:40 step:31479[D loss: 0.398788, acc: 62.50%, op_acc: 42.19%] [G loss: 0.893403]\n",
      "epoch:40 step:31480[D loss: 0.415483, acc: 60.94%, op_acc: 38.28%] [G loss: 0.958946]\n",
      "epoch:40 step:31481[D loss: 0.403357, acc: 60.16%, op_acc: 42.19%] [G loss: 0.879581]\n",
      "epoch:40 step:31482[D loss: 0.380124, acc: 66.41%, op_acc: 46.88%] [G loss: 0.867926]\n",
      "epoch:40 step:31483[D loss: 0.428541, acc: 56.25%, op_acc: 41.41%] [G loss: 0.764421]\n",
      "epoch:40 step:31484[D loss: 0.413015, acc: 63.28%, op_acc: 45.31%] [G loss: 0.959001]\n",
      "epoch:40 step:31485[D loss: 0.434824, acc: 58.59%, op_acc: 44.53%] [G loss: 0.911894]\n",
      "epoch:40 step:31486[D loss: 0.431306, acc: 67.19%, op_acc: 31.25%] [G loss: 0.879468]\n",
      "epoch:40 step:31487[D loss: 0.426368, acc: 56.25%, op_acc: 36.72%] [G loss: 0.928227]\n",
      "epoch:40 step:31488[D loss: 0.432175, acc: 57.03%, op_acc: 39.84%] [G loss: 0.874649]\n",
      "epoch:40 step:31489[D loss: 0.415161, acc: 63.28%, op_acc: 43.75%] [G loss: 0.862050]\n",
      "epoch:40 step:31490[D loss: 0.445008, acc: 59.38%, op_acc: 39.84%] [G loss: 0.851743]\n",
      "epoch:40 step:31491[D loss: 0.383802, acc: 69.53%, op_acc: 44.53%] [G loss: 0.933084]\n",
      "epoch:40 step:31492[D loss: 0.386341, acc: 67.19%, op_acc: 45.31%] [G loss: 0.842690]\n",
      "epoch:40 step:31493[D loss: 0.418760, acc: 58.59%, op_acc: 43.75%] [G loss: 0.891690]\n",
      "epoch:40 step:31494[D loss: 0.405839, acc: 64.84%, op_acc: 43.75%] [G loss: 0.939758]\n",
      "epoch:40 step:31495[D loss: 0.423641, acc: 58.59%, op_acc: 38.28%] [G loss: 0.915285]\n",
      "epoch:40 step:31496[D loss: 0.428086, acc: 54.69%, op_acc: 40.62%] [G loss: 0.811021]\n",
      "epoch:40 step:31497[D loss: 0.395282, acc: 66.41%, op_acc: 46.09%] [G loss: 0.882022]\n",
      "epoch:40 step:31498[D loss: 0.418910, acc: 66.41%, op_acc: 39.06%] [G loss: 0.900132]\n",
      "epoch:40 step:31499[D loss: 0.434816, acc: 56.25%, op_acc: 40.62%] [G loss: 0.893836]\n",
      "epoch:40 step:31500[D loss: 0.400883, acc: 65.62%, op_acc: 45.31%] [G loss: 0.915172]\n",
      "##############\n",
      "[0.88823603 0.85516198 0.81100568 0.80797267 0.79674972 0.82457838\n",
      " 0.87783202 0.83395725 0.79946892 0.82049161]\n",
      "##########\n",
      "epoch:40 step:31501[D loss: 0.379398, acc: 71.09%, op_acc: 41.41%] [G loss: 1.026280]\n",
      "epoch:40 step:31502[D loss: 0.397809, acc: 62.50%, op_acc: 42.97%] [G loss: 0.831250]\n",
      "epoch:40 step:31503[D loss: 0.435525, acc: 53.91%, op_acc: 42.19%] [G loss: 0.888041]\n",
      "epoch:40 step:31504[D loss: 0.419465, acc: 64.06%, op_acc: 44.53%] [G loss: 0.873043]\n",
      "epoch:40 step:31505[D loss: 0.412841, acc: 57.81%, op_acc: 40.62%] [G loss: 0.880173]\n",
      "epoch:40 step:31506[D loss: 0.395342, acc: 64.06%, op_acc: 41.41%] [G loss: 0.886328]\n",
      "epoch:40 step:31507[D loss: 0.447870, acc: 54.69%, op_acc: 42.19%] [G loss: 0.839519]\n",
      "epoch:40 step:31508[D loss: 0.399639, acc: 53.12%, op_acc: 42.97%] [G loss: 0.926240]\n",
      "epoch:40 step:31509[D loss: 0.404545, acc: 56.25%, op_acc: 44.53%] [G loss: 0.934421]\n",
      "epoch:40 step:31510[D loss: 0.405820, acc: 65.62%, op_acc: 39.84%] [G loss: 0.937945]\n",
      "epoch:40 step:31511[D loss: 0.429537, acc: 55.47%, op_acc: 37.50%] [G loss: 0.880206]\n",
      "epoch:40 step:31512[D loss: 0.394052, acc: 68.75%, op_acc: 38.28%] [G loss: 0.921131]\n",
      "epoch:40 step:31513[D loss: 0.377797, acc: 64.84%, op_acc: 48.44%] [G loss: 0.910737]\n",
      "epoch:40 step:31514[D loss: 0.399609, acc: 62.50%, op_acc: 44.53%] [G loss: 0.930530]\n",
      "epoch:40 step:31515[D loss: 0.431418, acc: 58.59%, op_acc: 46.88%] [G loss: 0.882631]\n",
      "epoch:40 step:31516[D loss: 0.444504, acc: 51.56%, op_acc: 38.28%] [G loss: 0.829418]\n",
      "epoch:40 step:31517[D loss: 0.398009, acc: 67.19%, op_acc: 34.38%] [G loss: 0.934623]\n",
      "epoch:40 step:31518[D loss: 0.416862, acc: 57.81%, op_acc: 35.16%] [G loss: 0.924730]\n",
      "epoch:40 step:31519[D loss: 0.415251, acc: 57.81%, op_acc: 46.09%] [G loss: 0.961448]\n",
      "epoch:40 step:31520[D loss: 0.426679, acc: 53.12%, op_acc: 36.72%] [G loss: 0.922722]\n",
      "epoch:40 step:31521[D loss: 0.413821, acc: 60.16%, op_acc: 44.53%] [G loss: 0.958820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31522[D loss: 0.428552, acc: 57.03%, op_acc: 40.62%] [G loss: 0.964728]\n",
      "epoch:40 step:31523[D loss: 0.408058, acc: 59.38%, op_acc: 44.53%] [G loss: 0.944231]\n",
      "epoch:40 step:31524[D loss: 0.398799, acc: 65.62%, op_acc: 41.41%] [G loss: 0.942849]\n",
      "epoch:40 step:31525[D loss: 0.413474, acc: 62.50%, op_acc: 39.84%] [G loss: 0.900194]\n",
      "epoch:40 step:31526[D loss: 0.429390, acc: 59.38%, op_acc: 39.84%] [G loss: 0.890673]\n",
      "epoch:40 step:31527[D loss: 0.426788, acc: 54.69%, op_acc: 41.41%] [G loss: 0.927351]\n",
      "epoch:40 step:31528[D loss: 0.391891, acc: 68.75%, op_acc: 41.41%] [G loss: 0.839977]\n",
      "epoch:40 step:31529[D loss: 0.446123, acc: 56.25%, op_acc: 37.50%] [G loss: 0.949378]\n",
      "epoch:40 step:31530[D loss: 0.399373, acc: 60.16%, op_acc: 41.41%] [G loss: 0.780213]\n",
      "epoch:40 step:31531[D loss: 0.398373, acc: 67.19%, op_acc: 43.75%] [G loss: 0.878369]\n",
      "epoch:40 step:31532[D loss: 0.394905, acc: 67.19%, op_acc: 40.62%] [G loss: 0.913715]\n",
      "epoch:40 step:31533[D loss: 0.410108, acc: 59.38%, op_acc: 40.62%] [G loss: 0.960440]\n",
      "epoch:40 step:31534[D loss: 0.452450, acc: 54.69%, op_acc: 36.72%] [G loss: 0.899809]\n",
      "epoch:40 step:31535[D loss: 0.400907, acc: 64.84%, op_acc: 45.31%] [G loss: 0.897298]\n",
      "epoch:40 step:31536[D loss: 0.398291, acc: 62.50%, op_acc: 43.75%] [G loss: 0.952494]\n",
      "epoch:40 step:31537[D loss: 0.419205, acc: 61.72%, op_acc: 35.94%] [G loss: 0.912718]\n",
      "epoch:40 step:31538[D loss: 0.407153, acc: 62.50%, op_acc: 42.97%] [G loss: 0.933974]\n",
      "epoch:40 step:31539[D loss: 0.414746, acc: 61.72%, op_acc: 39.84%] [G loss: 1.030503]\n",
      "epoch:40 step:31540[D loss: 0.452978, acc: 52.34%, op_acc: 35.94%] [G loss: 0.874069]\n",
      "epoch:40 step:31541[D loss: 0.424208, acc: 54.69%, op_acc: 39.06%] [G loss: 0.910347]\n",
      "epoch:40 step:31542[D loss: 0.416778, acc: 65.62%, op_acc: 39.84%] [G loss: 0.888549]\n",
      "epoch:40 step:31543[D loss: 0.394193, acc: 60.94%, op_acc: 43.75%] [G loss: 0.914376]\n",
      "epoch:40 step:31544[D loss: 0.409639, acc: 58.59%, op_acc: 41.41%] [G loss: 0.916412]\n",
      "epoch:40 step:31545[D loss: 0.424663, acc: 57.03%, op_acc: 38.28%] [G loss: 0.897729]\n",
      "epoch:40 step:31546[D loss: 0.432454, acc: 65.62%, op_acc: 40.62%] [G loss: 0.974668]\n",
      "epoch:40 step:31547[D loss: 0.415618, acc: 61.72%, op_acc: 43.75%] [G loss: 0.927903]\n",
      "epoch:40 step:31548[D loss: 0.419796, acc: 56.25%, op_acc: 38.28%] [G loss: 0.965572]\n",
      "epoch:40 step:31549[D loss: 0.447288, acc: 58.59%, op_acc: 42.19%] [G loss: 0.897202]\n",
      "epoch:40 step:31550[D loss: 0.456275, acc: 49.22%, op_acc: 39.84%] [G loss: 0.931566]\n",
      "##############\n",
      "[0.86066771 0.86850726 0.81942871 0.80380171 0.81154407 0.82068638\n",
      " 0.88723927 0.80390375 0.81943008 0.81719212]\n",
      "##########\n",
      "epoch:40 step:31551[D loss: 0.411386, acc: 58.59%, op_acc: 40.62%] [G loss: 0.908946]\n",
      "epoch:40 step:31552[D loss: 0.426693, acc: 51.56%, op_acc: 39.84%] [G loss: 0.880703]\n",
      "epoch:40 step:31553[D loss: 0.382263, acc: 64.06%, op_acc: 40.62%] [G loss: 0.968341]\n",
      "epoch:40 step:31554[D loss: 0.418181, acc: 57.81%, op_acc: 41.41%] [G loss: 0.850658]\n",
      "epoch:40 step:31555[D loss: 0.436451, acc: 63.28%, op_acc: 37.50%] [G loss: 0.814469]\n",
      "epoch:40 step:31556[D loss: 0.398206, acc: 60.16%, op_acc: 42.19%] [G loss: 0.884189]\n",
      "epoch:40 step:31557[D loss: 0.441308, acc: 53.12%, op_acc: 32.81%] [G loss: 0.839922]\n",
      "epoch:40 step:31558[D loss: 0.444302, acc: 50.00%, op_acc: 34.38%] [G loss: 0.885837]\n",
      "epoch:40 step:31559[D loss: 0.405518, acc: 61.72%, op_acc: 42.97%] [G loss: 0.860893]\n",
      "epoch:40 step:31560[D loss: 0.397499, acc: 66.41%, op_acc: 38.28%] [G loss: 0.868866]\n",
      "epoch:40 step:31561[D loss: 0.431143, acc: 62.50%, op_acc: 38.28%] [G loss: 0.891138]\n",
      "epoch:40 step:31562[D loss: 0.408670, acc: 64.84%, op_acc: 38.28%] [G loss: 0.876703]\n",
      "epoch:40 step:31563[D loss: 0.392356, acc: 61.72%, op_acc: 41.41%] [G loss: 0.952824]\n",
      "epoch:40 step:31564[D loss: 0.472800, acc: 47.66%, op_acc: 32.81%] [G loss: 0.944513]\n",
      "epoch:40 step:31565[D loss: 0.430942, acc: 53.91%, op_acc: 37.50%] [G loss: 0.842079]\n",
      "epoch:40 step:31566[D loss: 0.414300, acc: 55.47%, op_acc: 47.66%] [G loss: 0.967770]\n",
      "epoch:40 step:31567[D loss: 0.405860, acc: 60.16%, op_acc: 38.28%] [G loss: 0.815921]\n",
      "epoch:40 step:31568[D loss: 0.423580, acc: 62.50%, op_acc: 37.50%] [G loss: 0.907247]\n",
      "epoch:40 step:31569[D loss: 0.429790, acc: 52.34%, op_acc: 42.97%] [G loss: 0.851813]\n",
      "epoch:40 step:31570[D loss: 0.405671, acc: 54.69%, op_acc: 43.75%] [G loss: 0.863003]\n",
      "epoch:40 step:31571[D loss: 0.419381, acc: 51.56%, op_acc: 45.31%] [G loss: 0.923543]\n",
      "epoch:40 step:31572[D loss: 0.394832, acc: 60.94%, op_acc: 47.66%] [G loss: 0.901297]\n",
      "epoch:40 step:31573[D loss: 0.412856, acc: 64.06%, op_acc: 40.62%] [G loss: 0.869904]\n",
      "epoch:40 step:31574[D loss: 0.438524, acc: 57.81%, op_acc: 43.75%] [G loss: 0.932172]\n",
      "epoch:40 step:31575[D loss: 0.400247, acc: 66.41%, op_acc: 39.06%] [G loss: 0.921157]\n",
      "epoch:40 step:31576[D loss: 0.418550, acc: 57.03%, op_acc: 41.41%] [G loss: 0.925700]\n",
      "epoch:40 step:31577[D loss: 0.434987, acc: 60.94%, op_acc: 33.59%] [G loss: 0.879233]\n",
      "epoch:40 step:31578[D loss: 0.370801, acc: 70.31%, op_acc: 45.31%] [G loss: 0.873815]\n",
      "epoch:40 step:31579[D loss: 0.433730, acc: 51.56%, op_acc: 42.97%] [G loss: 0.895584]\n",
      "epoch:40 step:31580[D loss: 0.408376, acc: 67.97%, op_acc: 42.97%] [G loss: 0.925010]\n",
      "epoch:40 step:31581[D loss: 0.414951, acc: 62.50%, op_acc: 39.06%] [G loss: 0.893322]\n",
      "epoch:40 step:31582[D loss: 0.441661, acc: 57.81%, op_acc: 38.28%] [G loss: 0.917799]\n",
      "epoch:40 step:31583[D loss: 0.419331, acc: 64.06%, op_acc: 39.84%] [G loss: 0.852260]\n",
      "epoch:40 step:31584[D loss: 0.394733, acc: 67.19%, op_acc: 42.19%] [G loss: 0.927692]\n",
      "epoch:40 step:31585[D loss: 0.410670, acc: 64.84%, op_acc: 41.41%] [G loss: 0.931181]\n",
      "epoch:40 step:31586[D loss: 0.402975, acc: 64.84%, op_acc: 39.06%] [G loss: 0.914119]\n",
      "epoch:40 step:31587[D loss: 0.421633, acc: 56.25%, op_acc: 39.84%] [G loss: 0.914213]\n",
      "epoch:40 step:31588[D loss: 0.401502, acc: 67.19%, op_acc: 40.62%] [G loss: 0.882113]\n",
      "epoch:40 step:31589[D loss: 0.358886, acc: 67.97%, op_acc: 50.00%] [G loss: 0.927812]\n",
      "epoch:40 step:31590[D loss: 0.417435, acc: 67.97%, op_acc: 39.84%] [G loss: 0.831923]\n",
      "epoch:40 step:31591[D loss: 0.428187, acc: 55.47%, op_acc: 37.50%] [G loss: 0.944127]\n",
      "epoch:40 step:31592[D loss: 0.435808, acc: 57.81%, op_acc: 35.94%] [G loss: 0.815875]\n",
      "epoch:40 step:31593[D loss: 0.397297, acc: 56.25%, op_acc: 46.88%] [G loss: 0.977069]\n",
      "epoch:40 step:31594[D loss: 0.424416, acc: 58.59%, op_acc: 40.62%] [G loss: 0.862215]\n",
      "epoch:40 step:31595[D loss: 0.405197, acc: 67.19%, op_acc: 38.28%] [G loss: 0.937687]\n",
      "epoch:40 step:31596[D loss: 0.385356, acc: 64.06%, op_acc: 41.41%] [G loss: 0.892283]\n",
      "epoch:40 step:31597[D loss: 0.427352, acc: 59.38%, op_acc: 35.94%] [G loss: 0.941846]\n",
      "epoch:40 step:31598[D loss: 0.427282, acc: 59.38%, op_acc: 41.41%] [G loss: 0.963940]\n",
      "epoch:40 step:31599[D loss: 0.398283, acc: 60.16%, op_acc: 40.62%] [G loss: 0.887438]\n",
      "epoch:40 step:31600[D loss: 0.399790, acc: 65.62%, op_acc: 38.28%] [G loss: 0.876029]\n",
      "##############\n",
      "[0.85641217 0.8574661  0.82043258 0.81604576 0.76676389 0.83454562\n",
      " 0.8748967  0.81764857 0.82126404 0.84441658]\n",
      "##########\n",
      "epoch:40 step:31601[D loss: 0.399883, acc: 61.72%, op_acc: 46.09%] [G loss: 0.907373]\n",
      "epoch:40 step:31602[D loss: 0.376675, acc: 67.19%, op_acc: 46.09%] [G loss: 0.945514]\n",
      "epoch:40 step:31603[D loss: 0.428012, acc: 56.25%, op_acc: 45.31%] [G loss: 0.910715]\n",
      "epoch:40 step:31604[D loss: 0.434386, acc: 57.03%, op_acc: 39.06%] [G loss: 0.943927]\n",
      "epoch:40 step:31605[D loss: 0.395028, acc: 59.38%, op_acc: 44.53%] [G loss: 0.935822]\n",
      "epoch:40 step:31606[D loss: 0.380074, acc: 62.50%, op_acc: 44.53%] [G loss: 0.957911]\n",
      "epoch:40 step:31607[D loss: 0.423542, acc: 64.84%, op_acc: 41.41%] [G loss: 0.904014]\n",
      "epoch:40 step:31608[D loss: 0.386593, acc: 68.75%, op_acc: 42.97%] [G loss: 0.896022]\n",
      "epoch:40 step:31609[D loss: 0.402641, acc: 61.72%, op_acc: 47.66%] [G loss: 0.937310]\n",
      "epoch:40 step:31610[D loss: 0.424473, acc: 58.59%, op_acc: 42.97%] [G loss: 0.833692]\n",
      "epoch:40 step:31611[D loss: 0.413049, acc: 58.59%, op_acc: 46.88%] [G loss: 0.869231]\n",
      "epoch:40 step:31612[D loss: 0.388033, acc: 62.50%, op_acc: 42.97%] [G loss: 0.861994]\n",
      "epoch:40 step:31613[D loss: 0.386053, acc: 69.53%, op_acc: 42.19%] [G loss: 0.920166]\n",
      "epoch:40 step:31614[D loss: 0.410128, acc: 60.94%, op_acc: 39.84%] [G loss: 0.832004]\n",
      "epoch:40 step:31615[D loss: 0.391109, acc: 62.50%, op_acc: 46.09%] [G loss: 0.948353]\n",
      "epoch:40 step:31616[D loss: 0.369461, acc: 68.75%, op_acc: 49.22%] [G loss: 0.879808]\n",
      "epoch:40 step:31617[D loss: 0.399284, acc: 60.94%, op_acc: 43.75%] [G loss: 0.866643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31618[D loss: 0.388889, acc: 71.09%, op_acc: 45.31%] [G loss: 0.914129]\n",
      "epoch:40 step:31619[D loss: 0.396379, acc: 65.62%, op_acc: 42.97%] [G loss: 0.891013]\n",
      "epoch:40 step:31620[D loss: 0.399845, acc: 64.06%, op_acc: 37.50%] [G loss: 0.836396]\n",
      "epoch:40 step:31621[D loss: 0.399577, acc: 68.75%, op_acc: 46.09%] [G loss: 0.923287]\n",
      "epoch:40 step:31622[D loss: 0.443399, acc: 46.09%, op_acc: 40.62%] [G loss: 0.905267]\n",
      "epoch:40 step:31623[D loss: 0.387886, acc: 59.38%, op_acc: 45.31%] [G loss: 0.854191]\n",
      "epoch:40 step:31624[D loss: 0.422019, acc: 60.16%, op_acc: 41.41%] [G loss: 0.908998]\n",
      "epoch:40 step:31625[D loss: 0.426607, acc: 57.03%, op_acc: 35.94%] [G loss: 0.785089]\n",
      "epoch:40 step:31626[D loss: 0.405682, acc: 64.06%, op_acc: 41.41%] [G loss: 0.806562]\n",
      "epoch:40 step:31627[D loss: 0.436438, acc: 57.03%, op_acc: 42.97%] [G loss: 0.850841]\n",
      "epoch:40 step:31628[D loss: 0.435914, acc: 61.72%, op_acc: 38.28%] [G loss: 0.799509]\n",
      "epoch:40 step:31629[D loss: 0.392489, acc: 66.41%, op_acc: 42.97%] [G loss: 0.900802]\n",
      "epoch:40 step:31630[D loss: 0.439573, acc: 52.34%, op_acc: 36.72%] [G loss: 0.848613]\n",
      "epoch:40 step:31631[D loss: 0.440726, acc: 53.12%, op_acc: 42.19%] [G loss: 0.897808]\n",
      "epoch:40 step:31632[D loss: 0.408313, acc: 58.59%, op_acc: 46.88%] [G loss: 0.915489]\n",
      "epoch:40 step:31633[D loss: 0.423447, acc: 58.59%, op_acc: 43.75%] [G loss: 0.883005]\n",
      "epoch:40 step:31634[D loss: 0.434681, acc: 59.38%, op_acc: 39.06%] [G loss: 0.901189]\n",
      "epoch:40 step:31635[D loss: 0.445878, acc: 59.38%, op_acc: 35.94%] [G loss: 0.992951]\n",
      "epoch:40 step:31636[D loss: 0.406468, acc: 58.59%, op_acc: 45.31%] [G loss: 0.887740]\n",
      "epoch:40 step:31637[D loss: 0.422624, acc: 55.47%, op_acc: 42.97%] [G loss: 0.868259]\n",
      "epoch:40 step:31638[D loss: 0.403948, acc: 62.50%, op_acc: 44.53%] [G loss: 0.989672]\n",
      "epoch:40 step:31639[D loss: 0.422421, acc: 60.16%, op_acc: 45.31%] [G loss: 0.941493]\n",
      "epoch:40 step:31640[D loss: 0.392191, acc: 65.62%, op_acc: 43.75%] [G loss: 1.048511]\n",
      "epoch:40 step:31641[D loss: 0.417127, acc: 53.91%, op_acc: 41.41%] [G loss: 0.883691]\n",
      "epoch:40 step:31642[D loss: 0.420319, acc: 57.03%, op_acc: 37.50%] [G loss: 0.841101]\n",
      "epoch:40 step:31643[D loss: 0.390276, acc: 66.41%, op_acc: 42.19%] [G loss: 0.990051]\n",
      "epoch:40 step:31644[D loss: 0.377968, acc: 60.16%, op_acc: 47.66%] [G loss: 0.973114]\n",
      "epoch:40 step:31645[D loss: 0.430291, acc: 57.81%, op_acc: 42.19%] [G loss: 0.895038]\n",
      "epoch:40 step:31646[D loss: 0.414082, acc: 60.94%, op_acc: 41.41%] [G loss: 0.932938]\n",
      "epoch:40 step:31647[D loss: 0.392045, acc: 65.62%, op_acc: 44.53%] [G loss: 0.898673]\n",
      "epoch:40 step:31648[D loss: 0.388123, acc: 62.50%, op_acc: 49.22%] [G loss: 0.922536]\n",
      "epoch:40 step:31649[D loss: 0.420140, acc: 59.38%, op_acc: 45.31%] [G loss: 0.815697]\n",
      "epoch:40 step:31650[D loss: 0.397555, acc: 64.84%, op_acc: 38.28%] [G loss: 0.909125]\n",
      "##############\n",
      "[0.8622849  0.84122835 0.81134902 0.81288428 0.78672153 0.81899519\n",
      " 0.90555684 0.83974793 0.78167463 0.81939265]\n",
      "##########\n",
      "epoch:40 step:31651[D loss: 0.430937, acc: 59.38%, op_acc: 46.88%] [G loss: 0.931733]\n",
      "epoch:40 step:31652[D loss: 0.401454, acc: 61.72%, op_acc: 44.53%] [G loss: 0.861915]\n",
      "epoch:40 step:31653[D loss: 0.410363, acc: 62.50%, op_acc: 42.19%] [G loss: 0.860050]\n",
      "epoch:40 step:31654[D loss: 0.388207, acc: 64.84%, op_acc: 46.09%] [G loss: 0.905210]\n",
      "epoch:40 step:31655[D loss: 0.385680, acc: 67.97%, op_acc: 43.75%] [G loss: 0.929981]\n",
      "epoch:40 step:31656[D loss: 0.380852, acc: 67.97%, op_acc: 42.19%] [G loss: 0.998918]\n",
      "epoch:40 step:31657[D loss: 0.404951, acc: 64.06%, op_acc: 44.53%] [G loss: 0.853896]\n",
      "epoch:40 step:31658[D loss: 0.446859, acc: 56.25%, op_acc: 35.16%] [G loss: 0.918179]\n",
      "epoch:40 step:31659[D loss: 0.406847, acc: 61.72%, op_acc: 39.84%] [G loss: 0.914437]\n",
      "epoch:40 step:31660[D loss: 0.435721, acc: 57.81%, op_acc: 40.62%] [G loss: 0.956195]\n",
      "epoch:40 step:31661[D loss: 0.415756, acc: 66.41%, op_acc: 41.41%] [G loss: 0.858941]\n",
      "epoch:40 step:31662[D loss: 0.380394, acc: 72.66%, op_acc: 45.31%] [G loss: 0.915444]\n",
      "epoch:40 step:31663[D loss: 0.392659, acc: 67.19%, op_acc: 45.31%] [G loss: 0.897035]\n",
      "epoch:40 step:31664[D loss: 0.397484, acc: 70.31%, op_acc: 47.66%] [G loss: 0.863676]\n",
      "epoch:40 step:31665[D loss: 0.428260, acc: 57.03%, op_acc: 40.62%] [G loss: 0.858556]\n",
      "epoch:40 step:31666[D loss: 0.417110, acc: 67.19%, op_acc: 44.53%] [G loss: 0.957447]\n",
      "epoch:40 step:31667[D loss: 0.433059, acc: 57.81%, op_acc: 42.19%] [G loss: 0.885927]\n",
      "epoch:40 step:31668[D loss: 0.406352, acc: 64.06%, op_acc: 42.97%] [G loss: 0.919473]\n",
      "epoch:40 step:31669[D loss: 0.402198, acc: 64.06%, op_acc: 39.06%] [G loss: 0.902776]\n",
      "epoch:40 step:31670[D loss: 0.419167, acc: 57.81%, op_acc: 36.72%] [G loss: 0.817651]\n",
      "epoch:40 step:31671[D loss: 0.421329, acc: 60.16%, op_acc: 37.50%] [G loss: 0.967271]\n",
      "epoch:40 step:31672[D loss: 0.417873, acc: 57.81%, op_acc: 42.19%] [G loss: 0.877732]\n",
      "epoch:40 step:31673[D loss: 0.390061, acc: 66.41%, op_acc: 43.75%] [G loss: 0.914507]\n",
      "epoch:40 step:31674[D loss: 0.387675, acc: 64.06%, op_acc: 49.22%] [G loss: 0.909268]\n",
      "epoch:40 step:31675[D loss: 0.382786, acc: 64.84%, op_acc: 48.44%] [G loss: 0.985477]\n",
      "epoch:40 step:31676[D loss: 0.441176, acc: 55.47%, op_acc: 39.06%] [G loss: 0.824186]\n",
      "epoch:40 step:31677[D loss: 0.385639, acc: 72.66%, op_acc: 40.62%] [G loss: 1.039885]\n",
      "epoch:40 step:31678[D loss: 0.407474, acc: 64.84%, op_acc: 46.09%] [G loss: 0.878958]\n",
      "epoch:40 step:31679[D loss: 0.404781, acc: 60.16%, op_acc: 45.31%] [G loss: 0.982004]\n",
      "epoch:40 step:31680[D loss: 0.387387, acc: 65.62%, op_acc: 45.31%] [G loss: 0.893823]\n",
      "epoch:40 step:31681[D loss: 0.391510, acc: 66.41%, op_acc: 43.75%] [G loss: 0.912121]\n",
      "epoch:40 step:31682[D loss: 0.417920, acc: 57.81%, op_acc: 42.97%] [G loss: 0.863342]\n",
      "epoch:40 step:31683[D loss: 0.414878, acc: 60.16%, op_acc: 42.19%] [G loss: 0.910231]\n",
      "epoch:40 step:31684[D loss: 0.415169, acc: 60.16%, op_acc: 44.53%] [G loss: 0.849053]\n",
      "epoch:40 step:31685[D loss: 0.443372, acc: 53.12%, op_acc: 39.84%] [G loss: 0.813206]\n",
      "epoch:40 step:31686[D loss: 0.422309, acc: 58.59%, op_acc: 38.28%] [G loss: 0.858648]\n",
      "epoch:40 step:31687[D loss: 0.448127, acc: 62.50%, op_acc: 34.38%] [G loss: 0.873283]\n",
      "epoch:40 step:31688[D loss: 0.398185, acc: 66.41%, op_acc: 39.84%] [G loss: 0.956355]\n",
      "epoch:40 step:31689[D loss: 0.381202, acc: 70.31%, op_acc: 44.53%] [G loss: 1.011398]\n",
      "epoch:40 step:31690[D loss: 0.452039, acc: 53.91%, op_acc: 46.09%] [G loss: 0.938159]\n",
      "epoch:40 step:31691[D loss: 0.392668, acc: 61.72%, op_acc: 53.12%] [G loss: 0.906433]\n",
      "epoch:40 step:31692[D loss: 0.400229, acc: 60.94%, op_acc: 42.97%] [G loss: 0.856236]\n",
      "epoch:40 step:31693[D loss: 0.443952, acc: 57.81%, op_acc: 42.97%] [G loss: 0.840563]\n",
      "epoch:40 step:31694[D loss: 0.422665, acc: 53.12%, op_acc: 44.53%] [G loss: 0.897556]\n",
      "epoch:40 step:31695[D loss: 0.422759, acc: 55.47%, op_acc: 43.75%] [G loss: 0.878261]\n",
      "epoch:40 step:31696[D loss: 0.392147, acc: 64.06%, op_acc: 42.97%] [G loss: 0.886790]\n",
      "epoch:40 step:31697[D loss: 0.430553, acc: 59.38%, op_acc: 36.72%] [G loss: 0.870852]\n",
      "epoch:40 step:31698[D loss: 0.406588, acc: 56.25%, op_acc: 43.75%] [G loss: 0.875387]\n",
      "epoch:40 step:31699[D loss: 0.398670, acc: 58.59%, op_acc: 43.75%] [G loss: 0.923590]\n",
      "epoch:40 step:31700[D loss: 0.416563, acc: 59.38%, op_acc: 39.06%] [G loss: 0.971006]\n",
      "##############\n",
      "[0.86455231 0.84517464 0.80584514 0.80632649 0.80076061 0.8155945\n",
      " 0.85326559 0.80267787 0.80138366 0.81692041]\n",
      "##########\n",
      "epoch:40 step:31701[D loss: 0.453214, acc: 53.12%, op_acc: 39.84%] [G loss: 0.918479]\n",
      "epoch:40 step:31702[D loss: 0.399461, acc: 61.72%, op_acc: 39.06%] [G loss: 0.856739]\n",
      "epoch:40 step:31703[D loss: 0.436901, acc: 53.12%, op_acc: 42.97%] [G loss: 0.773624]\n",
      "epoch:40 step:31704[D loss: 0.437160, acc: 53.12%, op_acc: 43.75%] [G loss: 0.920137]\n",
      "epoch:40 step:31705[D loss: 0.425061, acc: 60.16%, op_acc: 41.41%] [G loss: 0.914499]\n",
      "epoch:40 step:31706[D loss: 0.386445, acc: 63.28%, op_acc: 44.53%] [G loss: 0.932572]\n",
      "epoch:40 step:31707[D loss: 0.432981, acc: 60.94%, op_acc: 42.19%] [G loss: 0.887900]\n",
      "epoch:40 step:31708[D loss: 0.413128, acc: 59.38%, op_acc: 38.28%] [G loss: 0.946936]\n",
      "epoch:40 step:31709[D loss: 0.382638, acc: 61.72%, op_acc: 42.19%] [G loss: 0.895592]\n",
      "epoch:40 step:31710[D loss: 0.432779, acc: 55.47%, op_acc: 44.53%] [G loss: 0.845199]\n",
      "epoch:40 step:31711[D loss: 0.391942, acc: 64.84%, op_acc: 41.41%] [G loss: 0.891810]\n",
      "epoch:40 step:31712[D loss: 0.460405, acc: 48.44%, op_acc: 37.50%] [G loss: 0.880699]\n",
      "epoch:40 step:31713[D loss: 0.420927, acc: 53.91%, op_acc: 45.31%] [G loss: 0.889434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31714[D loss: 0.401822, acc: 64.06%, op_acc: 41.41%] [G loss: 0.890606]\n",
      "epoch:40 step:31715[D loss: 0.413141, acc: 57.03%, op_acc: 47.66%] [G loss: 0.921224]\n",
      "epoch:40 step:31716[D loss: 0.401968, acc: 61.72%, op_acc: 40.62%] [G loss: 0.863456]\n",
      "epoch:40 step:31717[D loss: 0.423671, acc: 60.94%, op_acc: 38.28%] [G loss: 0.856200]\n",
      "epoch:40 step:31718[D loss: 0.372239, acc: 66.41%, op_acc: 52.34%] [G loss: 0.818504]\n",
      "epoch:40 step:31719[D loss: 0.424663, acc: 54.69%, op_acc: 42.19%] [G loss: 0.869559]\n",
      "epoch:40 step:31720[D loss: 0.434966, acc: 53.91%, op_acc: 38.28%] [G loss: 0.974408]\n",
      "epoch:40 step:31721[D loss: 0.460597, acc: 58.59%, op_acc: 31.25%] [G loss: 0.820283]\n",
      "epoch:40 step:31722[D loss: 0.406849, acc: 64.06%, op_acc: 40.62%] [G loss: 0.894691]\n",
      "epoch:40 step:31723[D loss: 0.427202, acc: 60.94%, op_acc: 46.09%] [G loss: 0.953958]\n",
      "epoch:40 step:31724[D loss: 0.378214, acc: 67.19%, op_acc: 45.31%] [G loss: 0.977391]\n",
      "epoch:40 step:31725[D loss: 0.400047, acc: 60.94%, op_acc: 41.41%] [G loss: 0.934423]\n",
      "epoch:40 step:31726[D loss: 0.391883, acc: 64.06%, op_acc: 45.31%] [G loss: 0.863955]\n",
      "epoch:40 step:31727[D loss: 0.396964, acc: 67.97%, op_acc: 44.53%] [G loss: 0.809716]\n",
      "epoch:40 step:31728[D loss: 0.422044, acc: 62.50%, op_acc: 39.84%] [G loss: 0.901550]\n",
      "epoch:40 step:31729[D loss: 0.428113, acc: 59.38%, op_acc: 37.50%] [G loss: 0.839813]\n",
      "epoch:40 step:31730[D loss: 0.400277, acc: 57.03%, op_acc: 49.22%] [G loss: 0.939524]\n",
      "epoch:40 step:31731[D loss: 0.467808, acc: 52.34%, op_acc: 39.06%] [G loss: 0.897633]\n",
      "epoch:40 step:31732[D loss: 0.412832, acc: 54.69%, op_acc: 43.75%] [G loss: 0.856507]\n",
      "epoch:40 step:31733[D loss: 0.413927, acc: 67.19%, op_acc: 39.84%] [G loss: 0.916051]\n",
      "epoch:40 step:31734[D loss: 0.367325, acc: 67.19%, op_acc: 44.53%] [G loss: 0.998643]\n",
      "epoch:40 step:31735[D loss: 0.410462, acc: 63.28%, op_acc: 41.41%] [G loss: 0.893231]\n",
      "epoch:40 step:31736[D loss: 0.400950, acc: 57.03%, op_acc: 40.62%] [G loss: 0.817015]\n",
      "epoch:40 step:31737[D loss: 0.397459, acc: 67.19%, op_acc: 44.53%] [G loss: 0.804672]\n",
      "epoch:40 step:31738[D loss: 0.434511, acc: 62.50%, op_acc: 39.84%] [G loss: 0.910885]\n",
      "epoch:40 step:31739[D loss: 0.418520, acc: 64.06%, op_acc: 41.41%] [G loss: 0.884469]\n",
      "epoch:40 step:31740[D loss: 0.401394, acc: 62.50%, op_acc: 46.88%] [G loss: 0.856545]\n",
      "epoch:40 step:31741[D loss: 0.431715, acc: 56.25%, op_acc: 39.84%] [G loss: 0.870721]\n",
      "epoch:40 step:31742[D loss: 0.429815, acc: 53.12%, op_acc: 42.97%] [G loss: 0.850277]\n",
      "epoch:40 step:31743[D loss: 0.417274, acc: 56.25%, op_acc: 46.09%] [G loss: 0.971939]\n",
      "epoch:40 step:31744[D loss: 0.427806, acc: 60.16%, op_acc: 38.28%] [G loss: 0.934167]\n",
      "epoch:40 step:31745[D loss: 0.404477, acc: 65.62%, op_acc: 42.97%] [G loss: 0.926444]\n",
      "epoch:40 step:31746[D loss: 0.459126, acc: 52.34%, op_acc: 37.50%] [G loss: 0.886099]\n",
      "epoch:40 step:31747[D loss: 0.375471, acc: 64.84%, op_acc: 49.22%] [G loss: 0.929805]\n",
      "epoch:40 step:31748[D loss: 0.423141, acc: 55.47%, op_acc: 42.19%] [G loss: 0.916122]\n",
      "epoch:40 step:31749[D loss: 0.412030, acc: 57.03%, op_acc: 46.88%] [G loss: 0.921929]\n",
      "epoch:40 step:31750[D loss: 0.411531, acc: 65.62%, op_acc: 46.09%] [G loss: 0.896192]\n",
      "##############\n",
      "[0.86676149 0.87372242 0.80746341 0.8109512  0.79035892 0.83634858\n",
      " 0.90091176 0.79297921 0.84341198 0.82491988]\n",
      "##########\n",
      "epoch:40 step:31751[D loss: 0.436229, acc: 54.69%, op_acc: 39.84%] [G loss: 0.907336]\n",
      "epoch:40 step:31752[D loss: 0.429180, acc: 59.38%, op_acc: 39.84%] [G loss: 0.964369]\n",
      "epoch:40 step:31753[D loss: 0.436259, acc: 59.38%, op_acc: 33.59%] [G loss: 0.816587]\n",
      "epoch:40 step:31754[D loss: 0.431951, acc: 58.59%, op_acc: 39.06%] [G loss: 0.936561]\n",
      "epoch:40 step:31755[D loss: 0.419374, acc: 58.59%, op_acc: 37.50%] [G loss: 0.894325]\n",
      "epoch:40 step:31756[D loss: 0.405604, acc: 66.41%, op_acc: 47.66%] [G loss: 0.934298]\n",
      "epoch:40 step:31757[D loss: 0.396570, acc: 66.41%, op_acc: 39.84%] [G loss: 0.862616]\n",
      "epoch:40 step:31758[D loss: 0.373729, acc: 67.19%, op_acc: 48.44%] [G loss: 0.888448]\n",
      "epoch:40 step:31759[D loss: 0.393793, acc: 66.41%, op_acc: 41.41%] [G loss: 0.935854]\n",
      "epoch:40 step:31760[D loss: 0.402220, acc: 62.50%, op_acc: 42.97%] [G loss: 0.910230]\n",
      "epoch:40 step:31761[D loss: 0.402990, acc: 69.53%, op_acc: 39.06%] [G loss: 0.919103]\n",
      "epoch:40 step:31762[D loss: 0.391010, acc: 63.28%, op_acc: 39.84%] [G loss: 0.841549]\n",
      "epoch:40 step:31763[D loss: 0.404081, acc: 61.72%, op_acc: 41.41%] [G loss: 0.869903]\n",
      "epoch:40 step:31764[D loss: 0.405354, acc: 71.09%, op_acc: 39.06%] [G loss: 0.893933]\n",
      "epoch:40 step:31765[D loss: 0.439052, acc: 56.25%, op_acc: 35.94%] [G loss: 0.958686]\n",
      "epoch:40 step:31766[D loss: 0.429711, acc: 60.94%, op_acc: 35.16%] [G loss: 0.807603]\n",
      "epoch:40 step:31767[D loss: 0.430110, acc: 56.25%, op_acc: 41.41%] [G loss: 0.781528]\n",
      "epoch:40 step:31768[D loss: 0.408809, acc: 59.38%, op_acc: 42.97%] [G loss: 0.923883]\n",
      "epoch:40 step:31769[D loss: 0.397827, acc: 62.50%, op_acc: 42.19%] [G loss: 0.893879]\n",
      "epoch:40 step:31770[D loss: 0.412225, acc: 64.06%, op_acc: 38.28%] [G loss: 0.900249]\n",
      "epoch:40 step:31771[D loss: 0.427634, acc: 61.72%, op_acc: 39.06%] [G loss: 0.889003]\n",
      "epoch:40 step:31772[D loss: 0.440153, acc: 56.25%, op_acc: 35.94%] [G loss: 0.894683]\n",
      "epoch:40 step:31773[D loss: 0.405788, acc: 58.59%, op_acc: 39.84%] [G loss: 0.938972]\n",
      "epoch:40 step:31774[D loss: 0.402536, acc: 60.94%, op_acc: 46.88%] [G loss: 0.890229]\n",
      "epoch:40 step:31775[D loss: 0.403604, acc: 65.62%, op_acc: 47.66%] [G loss: 0.954192]\n",
      "epoch:40 step:31776[D loss: 0.388039, acc: 63.28%, op_acc: 48.44%] [G loss: 0.910902]\n",
      "epoch:40 step:31777[D loss: 0.471968, acc: 50.78%, op_acc: 34.38%] [G loss: 0.943102]\n",
      "epoch:40 step:31778[D loss: 0.415055, acc: 58.59%, op_acc: 42.19%] [G loss: 0.883023]\n",
      "epoch:40 step:31779[D loss: 0.428855, acc: 61.72%, op_acc: 42.19%] [G loss: 0.911823]\n",
      "epoch:40 step:31780[D loss: 0.401644, acc: 56.25%, op_acc: 42.19%] [G loss: 0.961213]\n",
      "epoch:40 step:31781[D loss: 0.374714, acc: 63.28%, op_acc: 46.09%] [G loss: 0.965717]\n",
      "epoch:40 step:31782[D loss: 0.439091, acc: 58.59%, op_acc: 40.62%] [G loss: 0.907224]\n",
      "epoch:40 step:31783[D loss: 0.411542, acc: 64.84%, op_acc: 35.94%] [G loss: 0.944888]\n",
      "epoch:40 step:31784[D loss: 0.421232, acc: 55.47%, op_acc: 43.75%] [G loss: 0.871958]\n",
      "epoch:40 step:31785[D loss: 0.393630, acc: 61.72%, op_acc: 46.09%] [G loss: 0.927476]\n",
      "epoch:40 step:31786[D loss: 0.418378, acc: 61.72%, op_acc: 35.94%] [G loss: 1.004802]\n",
      "epoch:40 step:31787[D loss: 0.438769, acc: 62.50%, op_acc: 35.16%] [G loss: 0.919085]\n",
      "epoch:40 step:31788[D loss: 0.416411, acc: 62.50%, op_acc: 37.50%] [G loss: 0.925306]\n",
      "epoch:40 step:31789[D loss: 0.391820, acc: 65.62%, op_acc: 46.88%] [G loss: 0.950014]\n",
      "epoch:40 step:31790[D loss: 0.433199, acc: 56.25%, op_acc: 44.53%] [G loss: 0.843516]\n",
      "epoch:40 step:31791[D loss: 0.417337, acc: 60.94%, op_acc: 39.06%] [G loss: 0.923575]\n",
      "epoch:40 step:31792[D loss: 0.453818, acc: 53.91%, op_acc: 40.62%] [G loss: 0.865980]\n",
      "epoch:40 step:31793[D loss: 0.383363, acc: 70.31%, op_acc: 46.88%] [G loss: 0.865774]\n",
      "epoch:40 step:31794[D loss: 0.414603, acc: 58.59%, op_acc: 37.50%] [G loss: 0.948375]\n",
      "epoch:40 step:31795[D loss: 0.418165, acc: 53.91%, op_acc: 42.19%] [G loss: 0.836838]\n",
      "epoch:40 step:31796[D loss: 0.405805, acc: 61.72%, op_acc: 42.97%] [G loss: 0.901973]\n",
      "epoch:40 step:31797[D loss: 0.425996, acc: 60.94%, op_acc: 36.72%] [G loss: 0.977434]\n",
      "epoch:40 step:31798[D loss: 0.387686, acc: 63.28%, op_acc: 50.00%] [G loss: 0.878450]\n",
      "epoch:40 step:31799[D loss: 0.387030, acc: 64.06%, op_acc: 43.75%] [G loss: 0.990966]\n",
      "epoch:40 step:31800[D loss: 0.410058, acc: 64.06%, op_acc: 45.31%] [G loss: 0.868626]\n",
      "##############\n",
      "[0.8306648  0.84625566 0.79820183 0.79437083 0.78515848 0.83379179\n",
      " 0.90016291 0.81895954 0.79620981 0.8478309 ]\n",
      "##########\n",
      "epoch:40 step:31801[D loss: 0.396293, acc: 58.59%, op_acc: 41.41%] [G loss: 0.774441]\n",
      "epoch:40 step:31802[D loss: 0.409578, acc: 63.28%, op_acc: 41.41%] [G loss: 0.927688]\n",
      "epoch:40 step:31803[D loss: 0.399896, acc: 60.16%, op_acc: 42.97%] [G loss: 0.882715]\n",
      "epoch:40 step:31804[D loss: 0.438585, acc: 50.00%, op_acc: 42.97%] [G loss: 0.845199]\n",
      "epoch:40 step:31805[D loss: 0.440162, acc: 58.59%, op_acc: 44.53%] [G loss: 0.770891]\n",
      "epoch:40 step:31806[D loss: 0.434858, acc: 57.81%, op_acc: 39.06%] [G loss: 0.908203]\n",
      "epoch:40 step:31807[D loss: 0.418029, acc: 60.94%, op_acc: 42.97%] [G loss: 0.911280]\n",
      "epoch:40 step:31808[D loss: 0.411717, acc: 63.28%, op_acc: 47.66%] [G loss: 0.942757]\n",
      "epoch:40 step:31809[D loss: 0.394006, acc: 59.38%, op_acc: 48.44%] [G loss: 0.959308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31810[D loss: 0.430365, acc: 56.25%, op_acc: 40.62%] [G loss: 0.830233]\n",
      "epoch:40 step:31811[D loss: 0.403853, acc: 59.38%, op_acc: 46.09%] [G loss: 0.877775]\n",
      "epoch:40 step:31812[D loss: 0.376598, acc: 67.97%, op_acc: 39.84%] [G loss: 0.973030]\n",
      "epoch:40 step:31813[D loss: 0.428349, acc: 57.81%, op_acc: 42.97%] [G loss: 0.863821]\n",
      "epoch:40 step:31814[D loss: 0.403565, acc: 67.97%, op_acc: 41.41%] [G loss: 0.893044]\n",
      "epoch:40 step:31815[D loss: 0.424533, acc: 59.38%, op_acc: 44.53%] [G loss: 0.882566]\n",
      "epoch:40 step:31816[D loss: 0.383032, acc: 67.19%, op_acc: 43.75%] [G loss: 0.855039]\n",
      "epoch:40 step:31817[D loss: 0.442168, acc: 60.16%, op_acc: 41.41%] [G loss: 0.833855]\n",
      "epoch:40 step:31818[D loss: 0.461381, acc: 52.34%, op_acc: 34.38%] [G loss: 0.889809]\n",
      "epoch:40 step:31819[D loss: 0.386775, acc: 64.06%, op_acc: 46.09%] [G loss: 0.907351]\n",
      "epoch:40 step:31820[D loss: 0.414534, acc: 60.94%, op_acc: 42.19%] [G loss: 0.851385]\n",
      "epoch:40 step:31821[D loss: 0.426701, acc: 58.59%, op_acc: 39.84%] [G loss: 0.879262]\n",
      "epoch:40 step:31822[D loss: 0.429487, acc: 61.72%, op_acc: 37.50%] [G loss: 0.873642]\n",
      "epoch:40 step:31823[D loss: 0.400072, acc: 67.97%, op_acc: 43.75%] [G loss: 0.808467]\n",
      "epoch:40 step:31824[D loss: 0.428367, acc: 68.75%, op_acc: 32.81%] [G loss: 0.823855]\n",
      "epoch:40 step:31825[D loss: 0.421412, acc: 54.69%, op_acc: 43.75%] [G loss: 0.897081]\n",
      "epoch:40 step:31826[D loss: 0.418366, acc: 55.47%, op_acc: 39.84%] [G loss: 0.925148]\n",
      "epoch:40 step:31827[D loss: 0.376039, acc: 72.66%, op_acc: 39.06%] [G loss: 0.910576]\n",
      "epoch:40 step:31828[D loss: 0.375969, acc: 60.16%, op_acc: 46.88%] [G loss: 0.886286]\n",
      "epoch:40 step:31829[D loss: 0.407391, acc: 63.28%, op_acc: 42.97%] [G loss: 0.905279]\n",
      "epoch:40 step:31830[D loss: 0.422569, acc: 60.94%, op_acc: 42.19%] [G loss: 0.927292]\n",
      "epoch:40 step:31831[D loss: 0.435284, acc: 63.28%, op_acc: 42.19%] [G loss: 0.995115]\n",
      "epoch:40 step:31832[D loss: 0.411634, acc: 59.38%, op_acc: 42.97%] [G loss: 0.979307]\n",
      "epoch:40 step:31833[D loss: 0.404679, acc: 60.16%, op_acc: 40.62%] [G loss: 0.957372]\n",
      "epoch:40 step:31834[D loss: 0.406715, acc: 63.28%, op_acc: 43.75%] [G loss: 0.903342]\n",
      "epoch:40 step:31835[D loss: 0.396143, acc: 66.41%, op_acc: 42.19%] [G loss: 1.007837]\n",
      "epoch:40 step:31836[D loss: 0.431972, acc: 53.91%, op_acc: 42.19%] [G loss: 0.916826]\n",
      "epoch:40 step:31837[D loss: 0.394739, acc: 67.97%, op_acc: 46.09%] [G loss: 0.946236]\n",
      "epoch:40 step:31838[D loss: 0.387887, acc: 66.41%, op_acc: 39.06%] [G loss: 0.838112]\n",
      "epoch:40 step:31839[D loss: 0.434231, acc: 56.25%, op_acc: 40.62%] [G loss: 0.957858]\n",
      "epoch:40 step:31840[D loss: 0.403023, acc: 60.94%, op_acc: 44.53%] [G loss: 0.888038]\n",
      "epoch:40 step:31841[D loss: 0.408268, acc: 62.50%, op_acc: 42.19%] [G loss: 1.077468]\n",
      "epoch:40 step:31842[D loss: 0.416199, acc: 61.72%, op_acc: 42.97%] [G loss: 1.021331]\n",
      "epoch:40 step:31843[D loss: 0.390271, acc: 60.94%, op_acc: 41.41%] [G loss: 1.025752]\n",
      "epoch:40 step:31844[D loss: 0.432268, acc: 60.94%, op_acc: 43.75%] [G loss: 0.991386]\n",
      "epoch:40 step:31845[D loss: 0.412252, acc: 60.94%, op_acc: 42.19%] [G loss: 1.014151]\n",
      "epoch:40 step:31846[D loss: 0.376256, acc: 67.19%, op_acc: 46.88%] [G loss: 1.005138]\n",
      "epoch:40 step:31847[D loss: 0.365286, acc: 71.09%, op_acc: 48.44%] [G loss: 0.946968]\n",
      "epoch:40 step:31848[D loss: 0.366948, acc: 69.53%, op_acc: 46.09%] [G loss: 0.850420]\n",
      "epoch:40 step:31849[D loss: 0.420211, acc: 60.16%, op_acc: 39.84%] [G loss: 0.893530]\n",
      "epoch:40 step:31850[D loss: 0.419636, acc: 57.03%, op_acc: 38.28%] [G loss: 0.891691]\n",
      "##############\n",
      "[0.82536398 0.88590334 0.80078121 0.78530136 0.7821283  0.82547601\n",
      " 0.89075311 0.8364716  0.82429514 0.83365724]\n",
      "##########\n",
      "epoch:40 step:31851[D loss: 0.459932, acc: 52.34%, op_acc: 46.09%] [G loss: 0.734298]\n",
      "epoch:40 step:31852[D loss: 0.435908, acc: 57.03%, op_acc: 44.53%] [G loss: 0.726820]\n",
      "epoch:40 step:31853[D loss: 0.419620, acc: 53.91%, op_acc: 43.75%] [G loss: 0.916812]\n",
      "epoch:40 step:31854[D loss: 0.422216, acc: 58.59%, op_acc: 36.72%] [G loss: 0.868803]\n",
      "epoch:40 step:31855[D loss: 0.391357, acc: 65.62%, op_acc: 46.09%] [G loss: 0.891709]\n",
      "epoch:40 step:31856[D loss: 0.435343, acc: 57.81%, op_acc: 36.72%] [G loss: 0.818360]\n",
      "epoch:40 step:31857[D loss: 0.479592, acc: 41.41%, op_acc: 35.16%] [G loss: 0.791295]\n",
      "epoch:40 step:31858[D loss: 0.414923, acc: 64.84%, op_acc: 40.62%] [G loss: 0.870718]\n",
      "epoch:40 step:31859[D loss: 0.486588, acc: 53.12%, op_acc: 37.50%] [G loss: 0.870608]\n",
      "epoch:40 step:31860[D loss: 0.447447, acc: 53.12%, op_acc: 35.16%] [G loss: 0.826940]\n",
      "epoch:40 step:31861[D loss: 0.422760, acc: 63.28%, op_acc: 45.31%] [G loss: 0.932874]\n",
      "epoch:40 step:31862[D loss: 0.433605, acc: 56.25%, op_acc: 42.97%] [G loss: 0.873062]\n",
      "epoch:40 step:31863[D loss: 0.395954, acc: 66.41%, op_acc: 39.06%] [G loss: 0.914119]\n",
      "epoch:40 step:31864[D loss: 0.423224, acc: 60.16%, op_acc: 41.41%] [G loss: 0.872691]\n",
      "epoch:40 step:31865[D loss: 0.414210, acc: 58.59%, op_acc: 46.88%] [G loss: 0.858417]\n",
      "epoch:40 step:31866[D loss: 0.395171, acc: 60.94%, op_acc: 44.53%] [G loss: 0.877299]\n",
      "epoch:40 step:31867[D loss: 0.435303, acc: 57.03%, op_acc: 39.06%] [G loss: 0.905620]\n",
      "epoch:40 step:31868[D loss: 0.422996, acc: 59.38%, op_acc: 42.19%] [G loss: 0.861683]\n",
      "epoch:40 step:31869[D loss: 0.440993, acc: 50.00%, op_acc: 40.62%] [G loss: 0.864888]\n",
      "epoch:40 step:31870[D loss: 0.377725, acc: 68.75%, op_acc: 44.53%] [G loss: 0.980028]\n",
      "epoch:40 step:31871[D loss: 0.442113, acc: 60.16%, op_acc: 38.28%] [G loss: 0.880090]\n",
      "epoch:40 step:31872[D loss: 0.444749, acc: 57.03%, op_acc: 41.41%] [G loss: 0.963759]\n",
      "epoch:40 step:31873[D loss: 0.429748, acc: 56.25%, op_acc: 39.06%] [G loss: 0.933592]\n",
      "epoch:40 step:31874[D loss: 0.408947, acc: 59.38%, op_acc: 43.75%] [G loss: 0.933502]\n",
      "epoch:40 step:31875[D loss: 0.450670, acc: 52.34%, op_acc: 39.84%] [G loss: 0.912446]\n",
      "epoch:40 step:31876[D loss: 0.400009, acc: 64.06%, op_acc: 44.53%] [G loss: 0.917136]\n",
      "epoch:40 step:31877[D loss: 0.406064, acc: 65.62%, op_acc: 41.41%] [G loss: 0.871417]\n",
      "epoch:40 step:31878[D loss: 0.405143, acc: 60.94%, op_acc: 44.53%] [G loss: 0.946572]\n",
      "epoch:40 step:31879[D loss: 0.426921, acc: 55.47%, op_acc: 42.19%] [G loss: 0.919893]\n",
      "epoch:40 step:31880[D loss: 0.418465, acc: 64.84%, op_acc: 42.97%] [G loss: 0.952400]\n",
      "epoch:40 step:31881[D loss: 0.385811, acc: 75.00%, op_acc: 44.53%] [G loss: 0.933683]\n",
      "epoch:40 step:31882[D loss: 0.407439, acc: 62.50%, op_acc: 43.75%] [G loss: 0.934818]\n",
      "epoch:40 step:31883[D loss: 0.434292, acc: 54.69%, op_acc: 42.97%] [G loss: 0.895240]\n",
      "epoch:40 step:31884[D loss: 0.377412, acc: 67.97%, op_acc: 45.31%] [G loss: 0.911022]\n",
      "epoch:40 step:31885[D loss: 0.384281, acc: 68.75%, op_acc: 42.19%] [G loss: 1.015074]\n",
      "epoch:40 step:31886[D loss: 0.425194, acc: 64.06%, op_acc: 38.28%] [G loss: 0.923944]\n",
      "epoch:40 step:31887[D loss: 0.407061, acc: 60.94%, op_acc: 37.50%] [G loss: 0.934591]\n",
      "epoch:40 step:31888[D loss: 0.423322, acc: 56.25%, op_acc: 41.41%] [G loss: 0.978514]\n",
      "epoch:40 step:31889[D loss: 0.442991, acc: 53.12%, op_acc: 41.41%] [G loss: 0.861069]\n",
      "epoch:40 step:31890[D loss: 0.443384, acc: 57.81%, op_acc: 41.41%] [G loss: 0.882017]\n",
      "epoch:40 step:31891[D loss: 0.427658, acc: 53.91%, op_acc: 40.62%] [G loss: 0.882394]\n",
      "epoch:40 step:31892[D loss: 0.396868, acc: 64.84%, op_acc: 41.41%] [G loss: 0.949157]\n",
      "epoch:40 step:31893[D loss: 0.392977, acc: 65.62%, op_acc: 47.66%] [G loss: 0.835745]\n",
      "epoch:40 step:31894[D loss: 0.419340, acc: 53.91%, op_acc: 46.88%] [G loss: 0.893763]\n",
      "epoch:40 step:31895[D loss: 0.428065, acc: 57.81%, op_acc: 34.38%] [G loss: 0.948232]\n",
      "epoch:40 step:31896[D loss: 0.438958, acc: 57.81%, op_acc: 38.28%] [G loss: 0.992803]\n",
      "epoch:40 step:31897[D loss: 0.422466, acc: 59.38%, op_acc: 33.59%] [G loss: 0.841194]\n",
      "epoch:40 step:31898[D loss: 0.414591, acc: 60.94%, op_acc: 39.84%] [G loss: 0.835757]\n",
      "epoch:40 step:31899[D loss: 0.407474, acc: 66.41%, op_acc: 42.19%] [G loss: 1.001773]\n",
      "epoch:40 step:31900[D loss: 0.383891, acc: 69.53%, op_acc: 46.88%] [G loss: 0.930198]\n",
      "##############\n",
      "[0.84588894 0.86070007 0.82797323 0.79888058 0.78928365 0.81003796\n",
      " 0.86746247 0.83068356 0.80596742 0.83138195]\n",
      "##########\n",
      "epoch:40 step:31901[D loss: 0.391772, acc: 59.38%, op_acc: 46.09%] [G loss: 0.897105]\n",
      "epoch:40 step:31902[D loss: 0.397634, acc: 60.94%, op_acc: 43.75%] [G loss: 0.900210]\n",
      "epoch:40 step:31903[D loss: 0.438738, acc: 53.12%, op_acc: 40.62%] [G loss: 0.854514]\n",
      "epoch:40 step:31904[D loss: 0.377690, acc: 66.41%, op_acc: 42.19%] [G loss: 0.819872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31905[D loss: 0.434582, acc: 62.50%, op_acc: 34.38%] [G loss: 0.938843]\n",
      "epoch:40 step:31906[D loss: 0.403032, acc: 65.62%, op_acc: 41.41%] [G loss: 0.889919]\n",
      "epoch:40 step:31907[D loss: 0.384317, acc: 64.84%, op_acc: 44.53%] [G loss: 0.935242]\n",
      "epoch:40 step:31908[D loss: 0.403765, acc: 64.06%, op_acc: 39.84%] [G loss: 0.783690]\n",
      "epoch:40 step:31909[D loss: 0.427600, acc: 60.94%, op_acc: 40.62%] [G loss: 0.893699]\n",
      "epoch:40 step:31910[D loss: 0.367034, acc: 71.88%, op_acc: 46.09%] [G loss: 0.916869]\n",
      "epoch:40 step:31911[D loss: 0.401858, acc: 67.97%, op_acc: 40.62%] [G loss: 0.850118]\n",
      "epoch:40 step:31912[D loss: 0.422969, acc: 55.47%, op_acc: 40.62%] [G loss: 0.915791]\n",
      "epoch:40 step:31913[D loss: 0.409592, acc: 62.50%, op_acc: 37.50%] [G loss: 0.840364]\n",
      "epoch:40 step:31914[D loss: 0.411695, acc: 55.47%, op_acc: 42.97%] [G loss: 0.874732]\n",
      "epoch:40 step:31915[D loss: 0.438502, acc: 51.56%, op_acc: 41.41%] [G loss: 0.837966]\n",
      "epoch:40 step:31916[D loss: 0.410512, acc: 64.84%, op_acc: 42.97%] [G loss: 0.951000]\n",
      "epoch:40 step:31917[D loss: 0.435263, acc: 56.25%, op_acc: 42.19%] [G loss: 0.933402]\n",
      "epoch:40 step:31918[D loss: 0.411473, acc: 57.81%, op_acc: 41.41%] [G loss: 0.871771]\n",
      "epoch:40 step:31919[D loss: 0.383660, acc: 64.84%, op_acc: 51.56%] [G loss: 0.862170]\n",
      "epoch:40 step:31920[D loss: 0.406761, acc: 62.50%, op_acc: 41.41%] [G loss: 0.885060]\n",
      "epoch:40 step:31921[D loss: 0.429135, acc: 54.69%, op_acc: 43.75%] [G loss: 0.913857]\n",
      "epoch:40 step:31922[D loss: 0.363216, acc: 69.53%, op_acc: 46.09%] [G loss: 0.992254]\n",
      "epoch:40 step:31923[D loss: 0.414417, acc: 57.81%, op_acc: 36.72%] [G loss: 0.943315]\n",
      "epoch:40 step:31924[D loss: 0.404170, acc: 65.62%, op_acc: 38.28%] [G loss: 0.930597]\n",
      "epoch:40 step:31925[D loss: 0.421068, acc: 56.25%, op_acc: 42.97%] [G loss: 0.942800]\n",
      "epoch:40 step:31926[D loss: 0.400156, acc: 60.94%, op_acc: 44.53%] [G loss: 0.927333]\n",
      "epoch:40 step:31927[D loss: 0.410948, acc: 60.16%, op_acc: 41.41%] [G loss: 1.008922]\n",
      "epoch:40 step:31928[D loss: 0.410791, acc: 55.47%, op_acc: 46.09%] [G loss: 0.921981]\n",
      "epoch:40 step:31929[D loss: 0.421554, acc: 58.59%, op_acc: 39.84%] [G loss: 0.919399]\n",
      "epoch:40 step:31930[D loss: 0.445176, acc: 60.16%, op_acc: 38.28%] [G loss: 0.928114]\n",
      "epoch:40 step:31931[D loss: 0.397221, acc: 67.19%, op_acc: 39.84%] [G loss: 0.852909]\n",
      "epoch:40 step:31932[D loss: 0.417381, acc: 64.06%, op_acc: 43.75%] [G loss: 1.005076]\n",
      "epoch:40 step:31933[D loss: 0.404998, acc: 63.28%, op_acc: 40.62%] [G loss: 1.012993]\n",
      "epoch:40 step:31934[D loss: 0.445929, acc: 55.47%, op_acc: 39.84%] [G loss: 0.882411]\n",
      "epoch:40 step:31935[D loss: 0.431405, acc: 60.94%, op_acc: 37.50%] [G loss: 0.858567]\n",
      "epoch:40 step:31936[D loss: 0.452519, acc: 50.78%, op_acc: 41.41%] [G loss: 0.885740]\n",
      "epoch:40 step:31937[D loss: 0.394922, acc: 64.06%, op_acc: 42.97%] [G loss: 0.934529]\n",
      "epoch:40 step:31938[D loss: 0.407765, acc: 64.06%, op_acc: 41.41%] [G loss: 0.887014]\n",
      "epoch:40 step:31939[D loss: 0.432094, acc: 54.69%, op_acc: 43.75%] [G loss: 0.874194]\n",
      "epoch:40 step:31940[D loss: 0.454883, acc: 57.03%, op_acc: 38.28%] [G loss: 0.806605]\n",
      "epoch:40 step:31941[D loss: 0.421000, acc: 64.84%, op_acc: 39.06%] [G loss: 0.853742]\n",
      "epoch:40 step:31942[D loss: 0.421259, acc: 57.03%, op_acc: 41.41%] [G loss: 0.809396]\n",
      "epoch:40 step:31943[D loss: 0.473076, acc: 48.44%, op_acc: 35.94%] [G loss: 0.842368]\n",
      "epoch:40 step:31944[D loss: 0.409898, acc: 57.81%, op_acc: 42.97%] [G loss: 0.879060]\n",
      "epoch:40 step:31945[D loss: 0.429556, acc: 55.47%, op_acc: 39.06%] [G loss: 0.891830]\n",
      "epoch:40 step:31946[D loss: 0.406038, acc: 60.94%, op_acc: 42.97%] [G loss: 0.934423]\n",
      "epoch:40 step:31947[D loss: 0.424617, acc: 62.50%, op_acc: 39.84%] [G loss: 0.916708]\n",
      "epoch:40 step:31948[D loss: 0.425616, acc: 58.59%, op_acc: 40.62%] [G loss: 0.833704]\n",
      "epoch:40 step:31949[D loss: 0.391920, acc: 60.94%, op_acc: 36.72%] [G loss: 0.838921]\n",
      "epoch:40 step:31950[D loss: 0.387425, acc: 59.38%, op_acc: 44.53%] [G loss: 0.866868]\n",
      "##############\n",
      "[0.842005   0.84616672 0.81746715 0.80002927 0.78377426 0.81496411\n",
      " 0.89372341 0.83554686 0.79658934 0.82620159]\n",
      "##########\n",
      "epoch:40 step:31951[D loss: 0.403647, acc: 63.28%, op_acc: 36.72%] [G loss: 0.960665]\n",
      "epoch:40 step:31952[D loss: 0.406091, acc: 54.69%, op_acc: 45.31%] [G loss: 0.861174]\n",
      "epoch:40 step:31953[D loss: 0.403808, acc: 57.81%, op_acc: 50.00%] [G loss: 0.834456]\n",
      "epoch:40 step:31954[D loss: 0.423230, acc: 62.50%, op_acc: 37.50%] [G loss: 0.832191]\n",
      "epoch:40 step:31955[D loss: 0.413363, acc: 60.16%, op_acc: 41.41%] [G loss: 0.911373]\n",
      "epoch:40 step:31956[D loss: 0.413612, acc: 60.16%, op_acc: 44.53%] [G loss: 0.847501]\n",
      "epoch:40 step:31957[D loss: 0.405098, acc: 60.94%, op_acc: 44.53%] [G loss: 0.772613]\n",
      "epoch:40 step:31958[D loss: 0.414721, acc: 60.94%, op_acc: 39.06%] [G loss: 0.918673]\n",
      "epoch:40 step:31959[D loss: 0.408049, acc: 61.72%, op_acc: 40.62%] [G loss: 0.980222]\n",
      "epoch:40 step:31960[D loss: 0.445704, acc: 57.03%, op_acc: 40.62%] [G loss: 0.842994]\n",
      "epoch:40 step:31961[D loss: 0.443233, acc: 49.22%, op_acc: 38.28%] [G loss: 0.870373]\n",
      "epoch:40 step:31962[D loss: 0.407243, acc: 61.72%, op_acc: 42.97%] [G loss: 0.802339]\n",
      "epoch:40 step:31963[D loss: 0.410529, acc: 63.28%, op_acc: 42.97%] [G loss: 0.847413]\n",
      "epoch:40 step:31964[D loss: 0.438938, acc: 60.94%, op_acc: 40.62%] [G loss: 0.928498]\n",
      "epoch:40 step:31965[D loss: 0.409755, acc: 65.62%, op_acc: 41.41%] [G loss: 0.884882]\n",
      "epoch:40 step:31966[D loss: 0.437943, acc: 53.91%, op_acc: 39.06%] [G loss: 0.863438]\n",
      "epoch:40 step:31967[D loss: 0.444505, acc: 58.59%, op_acc: 37.50%] [G loss: 0.849729]\n",
      "epoch:40 step:31968[D loss: 0.426401, acc: 60.16%, op_acc: 39.06%] [G loss: 0.868188]\n",
      "epoch:40 step:31969[D loss: 0.403960, acc: 61.72%, op_acc: 42.97%] [G loss: 0.961475]\n",
      "epoch:40 step:31970[D loss: 0.424276, acc: 56.25%, op_acc: 39.06%] [G loss: 0.891689]\n",
      "epoch:40 step:31971[D loss: 0.387371, acc: 60.94%, op_acc: 50.78%] [G loss: 0.908330]\n",
      "epoch:40 step:31972[D loss: 0.426096, acc: 60.16%, op_acc: 39.84%] [G loss: 0.958076]\n",
      "epoch:40 step:31973[D loss: 0.403706, acc: 59.38%, op_acc: 39.84%] [G loss: 0.869062]\n",
      "epoch:40 step:31974[D loss: 0.438170, acc: 51.56%, op_acc: 39.06%] [G loss: 0.937107]\n",
      "epoch:40 step:31975[D loss: 0.453177, acc: 48.44%, op_acc: 42.97%] [G loss: 0.852383]\n",
      "epoch:40 step:31976[D loss: 0.422673, acc: 64.06%, op_acc: 39.06%] [G loss: 0.957197]\n",
      "epoch:40 step:31977[D loss: 0.389621, acc: 64.84%, op_acc: 43.75%] [G loss: 0.881106]\n",
      "epoch:40 step:31978[D loss: 0.410425, acc: 62.50%, op_acc: 46.09%] [G loss: 0.918699]\n",
      "epoch:40 step:31979[D loss: 0.381975, acc: 67.97%, op_acc: 41.41%] [G loss: 1.039121]\n",
      "epoch:40 step:31980[D loss: 0.395989, acc: 64.06%, op_acc: 42.19%] [G loss: 0.851829]\n",
      "epoch:40 step:31981[D loss: 0.405918, acc: 61.72%, op_acc: 41.41%] [G loss: 1.015540]\n",
      "epoch:40 step:31982[D loss: 0.435780, acc: 52.34%, op_acc: 41.41%] [G loss: 0.845674]\n",
      "epoch:40 step:31983[D loss: 0.446135, acc: 57.81%, op_acc: 39.06%] [G loss: 0.897756]\n",
      "epoch:40 step:31984[D loss: 0.369361, acc: 69.53%, op_acc: 49.22%] [G loss: 0.842157]\n",
      "epoch:40 step:31985[D loss: 0.415294, acc: 53.91%, op_acc: 39.84%] [G loss: 0.879256]\n",
      "epoch:40 step:31986[D loss: 0.418023, acc: 64.06%, op_acc: 35.16%] [G loss: 0.814345]\n",
      "epoch:40 step:31987[D loss: 0.426721, acc: 54.69%, op_acc: 42.19%] [G loss: 0.808980]\n",
      "epoch:40 step:31988[D loss: 0.440592, acc: 59.38%, op_acc: 35.94%] [G loss: 0.994459]\n",
      "epoch:40 step:31989[D loss: 0.405672, acc: 61.72%, op_acc: 39.84%] [G loss: 0.909963]\n",
      "epoch:40 step:31990[D loss: 0.415876, acc: 56.25%, op_acc: 45.31%] [G loss: 0.886751]\n",
      "epoch:40 step:31991[D loss: 0.433958, acc: 63.28%, op_acc: 32.81%] [G loss: 0.925990]\n",
      "epoch:40 step:31992[D loss: 0.424563, acc: 58.59%, op_acc: 42.19%] [G loss: 0.851738]\n",
      "epoch:40 step:31993[D loss: 0.403704, acc: 61.72%, op_acc: 43.75%] [G loss: 0.937845]\n",
      "epoch:40 step:31994[D loss: 0.408528, acc: 62.50%, op_acc: 39.06%] [G loss: 0.935794]\n",
      "epoch:40 step:31995[D loss: 0.383795, acc: 64.06%, op_acc: 46.88%] [G loss: 0.935592]\n",
      "epoch:40 step:31996[D loss: 0.394449, acc: 60.94%, op_acc: 44.53%] [G loss: 0.990677]\n",
      "epoch:40 step:31997[D loss: 0.412352, acc: 58.59%, op_acc: 40.62%] [G loss: 1.017247]\n",
      "epoch:40 step:31998[D loss: 0.392829, acc: 61.72%, op_acc: 45.31%] [G loss: 0.970447]\n",
      "epoch:40 step:31999[D loss: 0.405523, acc: 64.06%, op_acc: 46.88%] [G loss: 0.949666]\n",
      "epoch:40 step:32000[D loss: 0.421101, acc: 56.25%, op_acc: 46.09%] [G loss: 1.001510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.87104706 0.85313915 0.82286369 0.80908448 0.79564718 0.83972388\n",
      " 0.86595929 0.82567398 0.81905411 0.82853287]\n",
      "##########\n",
      "epoch:40 step:32001[D loss: 0.404932, acc: 54.69%, op_acc: 42.19%] [G loss: 0.963726]\n",
      "epoch:40 step:32002[D loss: 0.417911, acc: 59.38%, op_acc: 39.06%] [G loss: 0.879014]\n",
      "epoch:40 step:32003[D loss: 0.413872, acc: 63.28%, op_acc: 39.06%] [G loss: 0.814614]\n",
      "epoch:40 step:32004[D loss: 0.431070, acc: 57.81%, op_acc: 46.88%] [G loss: 0.956231]\n",
      "epoch:40 step:32005[D loss: 0.420550, acc: 55.47%, op_acc: 45.31%] [G loss: 0.865051]\n",
      "epoch:40 step:32006[D loss: 0.402502, acc: 58.59%, op_acc: 42.19%] [G loss: 0.910620]\n",
      "epoch:40 step:32007[D loss: 0.422951, acc: 54.69%, op_acc: 47.66%] [G loss: 0.856185]\n",
      "epoch:40 step:32008[D loss: 0.396807, acc: 65.62%, op_acc: 38.28%] [G loss: 0.862661]\n",
      "epoch:40 step:32009[D loss: 0.381145, acc: 67.19%, op_acc: 42.19%] [G loss: 0.902256]\n",
      "epoch:40 step:32010[D loss: 0.374042, acc: 67.97%, op_acc: 47.66%] [G loss: 0.926862]\n",
      "epoch:40 step:32011[D loss: 0.431103, acc: 59.38%, op_acc: 40.62%] [G loss: 0.871972]\n",
      "epoch:40 step:32012[D loss: 0.410719, acc: 56.25%, op_acc: 44.53%] [G loss: 0.842642]\n",
      "epoch:40 step:32013[D loss: 0.423106, acc: 63.28%, op_acc: 36.72%] [G loss: 0.879093]\n",
      "epoch:40 step:32014[D loss: 0.396913, acc: 67.97%, op_acc: 43.75%] [G loss: 0.926765]\n",
      "epoch:40 step:32015[D loss: 0.391487, acc: 66.41%, op_acc: 41.41%] [G loss: 0.958598]\n",
      "epoch:40 step:32016[D loss: 0.443401, acc: 54.69%, op_acc: 35.94%] [G loss: 0.912839]\n",
      "epoch:40 step:32017[D loss: 0.425875, acc: 58.59%, op_acc: 36.72%] [G loss: 0.909458]\n",
      "epoch:40 step:32018[D loss: 0.419510, acc: 60.16%, op_acc: 47.66%] [G loss: 0.818566]\n",
      "epoch:40 step:32019[D loss: 0.426332, acc: 59.38%, op_acc: 39.84%] [G loss: 0.922752]\n",
      "epoch:40 step:32020[D loss: 0.386339, acc: 63.28%, op_acc: 46.88%] [G loss: 0.889772]\n",
      "epoch:40 step:32021[D loss: 0.410201, acc: 64.06%, op_acc: 43.75%] [G loss: 0.940152]\n",
      "epoch:41 step:32022[D loss: 0.415634, acc: 59.38%, op_acc: 42.19%] [G loss: 0.910176]\n",
      "epoch:41 step:32023[D loss: 0.395984, acc: 62.50%, op_acc: 44.53%] [G loss: 0.953131]\n",
      "epoch:41 step:32024[D loss: 0.406035, acc: 62.50%, op_acc: 42.97%] [G loss: 0.940609]\n",
      "epoch:41 step:32025[D loss: 0.408500, acc: 57.03%, op_acc: 42.19%] [G loss: 0.951131]\n",
      "epoch:41 step:32026[D loss: 0.422311, acc: 57.03%, op_acc: 36.72%] [G loss: 0.882818]\n",
      "epoch:41 step:32027[D loss: 0.403806, acc: 65.62%, op_acc: 38.28%] [G loss: 0.873135]\n",
      "epoch:41 step:32028[D loss: 0.373668, acc: 67.19%, op_acc: 46.88%] [G loss: 1.033960]\n",
      "epoch:41 step:32029[D loss: 0.400151, acc: 64.84%, op_acc: 46.09%] [G loss: 0.879109]\n",
      "epoch:41 step:32030[D loss: 0.404140, acc: 60.16%, op_acc: 50.00%] [G loss: 0.897050]\n",
      "epoch:41 step:32031[D loss: 0.428656, acc: 56.25%, op_acc: 32.81%] [G loss: 0.888767]\n",
      "epoch:41 step:32032[D loss: 0.433133, acc: 57.03%, op_acc: 42.19%] [G loss: 0.924927]\n",
      "epoch:41 step:32033[D loss: 0.410423, acc: 67.19%, op_acc: 40.62%] [G loss: 0.890396]\n",
      "epoch:41 step:32034[D loss: 0.405815, acc: 64.06%, op_acc: 36.72%] [G loss: 0.783217]\n",
      "epoch:41 step:32035[D loss: 0.414769, acc: 60.16%, op_acc: 40.62%] [G loss: 0.889608]\n",
      "epoch:41 step:32036[D loss: 0.388099, acc: 60.94%, op_acc: 45.31%] [G loss: 0.870895]\n",
      "epoch:41 step:32037[D loss: 0.393323, acc: 67.19%, op_acc: 43.75%] [G loss: 0.970326]\n",
      "epoch:41 step:32038[D loss: 0.440118, acc: 53.91%, op_acc: 42.19%] [G loss: 0.889360]\n",
      "epoch:41 step:32039[D loss: 0.423406, acc: 58.59%, op_acc: 42.97%] [G loss: 0.851819]\n",
      "epoch:41 step:32040[D loss: 0.445426, acc: 50.00%, op_acc: 42.19%] [G loss: 0.868967]\n",
      "epoch:41 step:32041[D loss: 0.393941, acc: 62.50%, op_acc: 39.84%] [G loss: 0.884413]\n",
      "epoch:41 step:32042[D loss: 0.421634, acc: 58.59%, op_acc: 38.28%] [G loss: 0.833064]\n",
      "epoch:41 step:32043[D loss: 0.379083, acc: 65.62%, op_acc: 44.53%] [G loss: 0.875023]\n",
      "epoch:41 step:32044[D loss: 0.390397, acc: 67.97%, op_acc: 45.31%] [G loss: 0.863697]\n",
      "epoch:41 step:32045[D loss: 0.405675, acc: 68.75%, op_acc: 39.06%] [G loss: 0.910724]\n",
      "epoch:41 step:32046[D loss: 0.415233, acc: 62.50%, op_acc: 43.75%] [G loss: 0.841271]\n",
      "epoch:41 step:32047[D loss: 0.407773, acc: 60.16%, op_acc: 43.75%] [G loss: 0.959715]\n",
      "epoch:41 step:32048[D loss: 0.393553, acc: 67.97%, op_acc: 43.75%] [G loss: 0.914728]\n",
      "epoch:41 step:32049[D loss: 0.439852, acc: 53.12%, op_acc: 37.50%] [G loss: 0.825261]\n",
      "epoch:41 step:32050[D loss: 0.410466, acc: 56.25%, op_acc: 41.41%] [G loss: 0.849261]\n",
      "##############\n",
      "[0.85302575 0.86696437 0.83297667 0.79929019 0.79703263 0.83250665\n",
      " 0.90285217 0.82676898 0.80924452 0.81841771]\n",
      "##########\n",
      "epoch:41 step:32051[D loss: 0.391094, acc: 63.28%, op_acc: 47.66%] [G loss: 0.959559]\n",
      "epoch:41 step:32052[D loss: 0.413273, acc: 60.16%, op_acc: 38.28%] [G loss: 0.875665]\n",
      "epoch:41 step:32053[D loss: 0.408372, acc: 67.97%, op_acc: 41.41%] [G loss: 0.866108]\n",
      "epoch:41 step:32054[D loss: 0.410243, acc: 58.59%, op_acc: 50.78%] [G loss: 0.963646]\n",
      "epoch:41 step:32055[D loss: 0.384706, acc: 67.19%, op_acc: 42.97%] [G loss: 0.858392]\n",
      "epoch:41 step:32056[D loss: 0.408858, acc: 57.81%, op_acc: 40.62%] [G loss: 0.906142]\n",
      "epoch:41 step:32057[D loss: 0.369762, acc: 71.88%, op_acc: 43.75%] [G loss: 0.859581]\n",
      "epoch:41 step:32058[D loss: 0.374094, acc: 68.75%, op_acc: 42.97%] [G loss: 0.856977]\n",
      "epoch:41 step:32059[D loss: 0.420765, acc: 53.91%, op_acc: 35.94%] [G loss: 0.890711]\n",
      "epoch:41 step:32060[D loss: 0.407853, acc: 65.62%, op_acc: 46.09%] [G loss: 0.756743]\n",
      "epoch:41 step:32061[D loss: 0.441417, acc: 58.59%, op_acc: 39.84%] [G loss: 0.876476]\n",
      "epoch:41 step:32062[D loss: 0.372388, acc: 63.28%, op_acc: 48.44%] [G loss: 0.930305]\n",
      "epoch:41 step:32063[D loss: 0.372234, acc: 67.19%, op_acc: 45.31%] [G loss: 0.893871]\n",
      "epoch:41 step:32064[D loss: 0.416412, acc: 58.59%, op_acc: 38.28%] [G loss: 0.964390]\n",
      "epoch:41 step:32065[D loss: 0.412288, acc: 57.03%, op_acc: 40.62%] [G loss: 0.876800]\n",
      "epoch:41 step:32066[D loss: 0.409085, acc: 60.94%, op_acc: 46.09%] [G loss: 0.853983]\n",
      "epoch:41 step:32067[D loss: 0.424852, acc: 54.69%, op_acc: 40.62%] [G loss: 0.914434]\n",
      "epoch:41 step:32068[D loss: 0.439851, acc: 58.59%, op_acc: 35.16%] [G loss: 0.886597]\n",
      "epoch:41 step:32069[D loss: 0.404110, acc: 64.06%, op_acc: 40.62%] [G loss: 0.877096]\n",
      "epoch:41 step:32070[D loss: 0.374965, acc: 65.62%, op_acc: 44.53%] [G loss: 0.849318]\n",
      "epoch:41 step:32071[D loss: 0.425724, acc: 57.03%, op_acc: 42.19%] [G loss: 0.932413]\n",
      "epoch:41 step:32072[D loss: 0.399517, acc: 63.28%, op_acc: 39.84%] [G loss: 0.906639]\n",
      "epoch:41 step:32073[D loss: 0.403082, acc: 65.62%, op_acc: 45.31%] [G loss: 0.948301]\n",
      "epoch:41 step:32074[D loss: 0.424917, acc: 53.91%, op_acc: 39.84%] [G loss: 0.791064]\n",
      "epoch:41 step:32075[D loss: 0.418610, acc: 64.84%, op_acc: 46.88%] [G loss: 0.903018]\n",
      "epoch:41 step:32076[D loss: 0.397938, acc: 55.47%, op_acc: 50.78%] [G loss: 0.938987]\n",
      "epoch:41 step:32077[D loss: 0.429377, acc: 54.69%, op_acc: 37.50%] [G loss: 0.824573]\n",
      "epoch:41 step:32078[D loss: 0.390152, acc: 64.84%, op_acc: 45.31%] [G loss: 0.873831]\n",
      "epoch:41 step:32079[D loss: 0.398300, acc: 58.59%, op_acc: 41.41%] [G loss: 0.891248]\n",
      "epoch:41 step:32080[D loss: 0.404207, acc: 64.84%, op_acc: 45.31%] [G loss: 0.840820]\n",
      "epoch:41 step:32081[D loss: 0.390287, acc: 64.84%, op_acc: 39.84%] [G loss: 1.068020]\n",
      "epoch:41 step:32082[D loss: 0.424986, acc: 53.91%, op_acc: 41.41%] [G loss: 1.008390]\n",
      "epoch:41 step:32083[D loss: 0.400269, acc: 62.50%, op_acc: 42.19%] [G loss: 0.920767]\n",
      "epoch:41 step:32084[D loss: 0.436883, acc: 54.69%, op_acc: 35.94%] [G loss: 0.862306]\n",
      "epoch:41 step:32085[D loss: 0.405952, acc: 60.94%, op_acc: 42.19%] [G loss: 0.888619]\n",
      "epoch:41 step:32086[D loss: 0.416036, acc: 60.94%, op_acc: 42.19%] [G loss: 0.871591]\n",
      "epoch:41 step:32087[D loss: 0.415974, acc: 51.56%, op_acc: 50.00%] [G loss: 0.934547]\n",
      "epoch:41 step:32088[D loss: 0.432904, acc: 55.47%, op_acc: 40.62%] [G loss: 0.880918]\n",
      "epoch:41 step:32089[D loss: 0.416849, acc: 60.94%, op_acc: 38.28%] [G loss: 0.946203]\n",
      "epoch:41 step:32090[D loss: 0.378963, acc: 58.59%, op_acc: 46.88%] [G loss: 0.913227]\n",
      "epoch:41 step:32091[D loss: 0.405698, acc: 64.06%, op_acc: 42.19%] [G loss: 0.941735]\n",
      "epoch:41 step:32092[D loss: 0.441861, acc: 62.50%, op_acc: 39.06%] [G loss: 0.863241]\n",
      "epoch:41 step:32093[D loss: 0.401087, acc: 64.06%, op_acc: 35.94%] [G loss: 0.945213]\n",
      "epoch:41 step:32094[D loss: 0.431753, acc: 52.34%, op_acc: 41.41%] [G loss: 0.846641]\n",
      "epoch:41 step:32095[D loss: 0.419514, acc: 55.47%, op_acc: 44.53%] [G loss: 0.856433]\n",
      "epoch:41 step:32096[D loss: 0.420534, acc: 56.25%, op_acc: 40.62%] [G loss: 0.875698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32097[D loss: 0.427232, acc: 60.16%, op_acc: 38.28%] [G loss: 0.922516]\n",
      "epoch:41 step:32098[D loss: 0.422687, acc: 61.72%, op_acc: 37.50%] [G loss: 0.852390]\n",
      "epoch:41 step:32099[D loss: 0.418693, acc: 68.75%, op_acc: 29.69%] [G loss: 0.947607]\n",
      "epoch:41 step:32100[D loss: 0.397818, acc: 65.62%, op_acc: 41.41%] [G loss: 0.916129]\n",
      "##############\n",
      "[0.86769292 0.85052913 0.8144728  0.79626891 0.7767353  0.83491093\n",
      " 0.88828325 0.81736571 0.80983423 0.83367638]\n",
      "##########\n",
      "epoch:41 step:32101[D loss: 0.425597, acc: 63.28%, op_acc: 35.16%] [G loss: 0.876086]\n",
      "epoch:41 step:32102[D loss: 0.432004, acc: 57.81%, op_acc: 34.38%] [G loss: 0.782098]\n",
      "epoch:41 step:32103[D loss: 0.399041, acc: 57.81%, op_acc: 44.53%] [G loss: 0.873734]\n",
      "epoch:41 step:32104[D loss: 0.414320, acc: 66.41%, op_acc: 42.19%] [G loss: 0.859011]\n",
      "epoch:41 step:32105[D loss: 0.410657, acc: 60.94%, op_acc: 42.97%] [G loss: 0.905962]\n",
      "epoch:41 step:32106[D loss: 0.435509, acc: 57.81%, op_acc: 35.94%] [G loss: 0.835412]\n",
      "epoch:41 step:32107[D loss: 0.383583, acc: 62.50%, op_acc: 42.97%] [G loss: 0.924152]\n",
      "epoch:41 step:32108[D loss: 0.400680, acc: 57.81%, op_acc: 42.19%] [G loss: 0.861855]\n",
      "epoch:41 step:32109[D loss: 0.428118, acc: 61.72%, op_acc: 37.50%] [G loss: 0.980446]\n",
      "epoch:41 step:32110[D loss: 0.409255, acc: 65.62%, op_acc: 39.84%] [G loss: 0.917310]\n",
      "epoch:41 step:32111[D loss: 0.437135, acc: 57.81%, op_acc: 42.19%] [G loss: 0.871176]\n",
      "epoch:41 step:32112[D loss: 0.382832, acc: 64.06%, op_acc: 45.31%] [G loss: 0.847885]\n",
      "epoch:41 step:32113[D loss: 0.415352, acc: 60.16%, op_acc: 42.19%] [G loss: 0.851277]\n",
      "epoch:41 step:32114[D loss: 0.410129, acc: 60.94%, op_acc: 46.88%] [G loss: 0.924090]\n",
      "epoch:41 step:32115[D loss: 0.419573, acc: 57.03%, op_acc: 39.06%] [G loss: 0.819061]\n",
      "epoch:41 step:32116[D loss: 0.397259, acc: 62.50%, op_acc: 42.19%] [G loss: 0.878827]\n",
      "epoch:41 step:32117[D loss: 0.428659, acc: 58.59%, op_acc: 40.62%] [G loss: 0.958904]\n",
      "epoch:41 step:32118[D loss: 0.449011, acc: 53.91%, op_acc: 42.19%] [G loss: 0.869568]\n",
      "epoch:41 step:32119[D loss: 0.436777, acc: 59.38%, op_acc: 37.50%] [G loss: 0.818000]\n",
      "epoch:41 step:32120[D loss: 0.404898, acc: 64.84%, op_acc: 38.28%] [G loss: 0.947856]\n",
      "epoch:41 step:32121[D loss: 0.421299, acc: 60.16%, op_acc: 44.53%] [G loss: 0.842095]\n",
      "epoch:41 step:32122[D loss: 0.431465, acc: 57.81%, op_acc: 35.16%] [G loss: 0.965268]\n",
      "epoch:41 step:32123[D loss: 0.405485, acc: 60.94%, op_acc: 42.19%] [G loss: 0.856276]\n",
      "epoch:41 step:32124[D loss: 0.417288, acc: 60.94%, op_acc: 43.75%] [G loss: 0.950798]\n",
      "epoch:41 step:32125[D loss: 0.429708, acc: 57.81%, op_acc: 42.97%] [G loss: 0.978678]\n",
      "epoch:41 step:32126[D loss: 0.396251, acc: 61.72%, op_acc: 46.09%] [G loss: 0.957691]\n",
      "epoch:41 step:32127[D loss: 0.392644, acc: 64.84%, op_acc: 44.53%] [G loss: 0.882645]\n",
      "epoch:41 step:32128[D loss: 0.384179, acc: 65.62%, op_acc: 42.19%] [G loss: 0.979699]\n",
      "epoch:41 step:32129[D loss: 0.430877, acc: 60.94%, op_acc: 32.81%] [G loss: 0.845067]\n",
      "epoch:41 step:32130[D loss: 0.412999, acc: 57.03%, op_acc: 46.88%] [G loss: 0.847666]\n",
      "epoch:41 step:32131[D loss: 0.380446, acc: 67.97%, op_acc: 52.34%] [G loss: 0.922667]\n",
      "epoch:41 step:32132[D loss: 0.430793, acc: 56.25%, op_acc: 42.19%] [G loss: 0.860813]\n",
      "epoch:41 step:32133[D loss: 0.403589, acc: 57.03%, op_acc: 41.41%] [G loss: 0.883959]\n",
      "epoch:41 step:32134[D loss: 0.429126, acc: 56.25%, op_acc: 38.28%] [G loss: 0.889028]\n",
      "epoch:41 step:32135[D loss: 0.426744, acc: 56.25%, op_acc: 43.75%] [G loss: 0.992061]\n",
      "epoch:41 step:32136[D loss: 0.368651, acc: 71.09%, op_acc: 44.53%] [G loss: 0.854924]\n",
      "epoch:41 step:32137[D loss: 0.405952, acc: 61.72%, op_acc: 45.31%] [G loss: 0.935094]\n",
      "epoch:41 step:32138[D loss: 0.428866, acc: 58.59%, op_acc: 38.28%] [G loss: 0.892006]\n",
      "epoch:41 step:32139[D loss: 0.393916, acc: 64.06%, op_acc: 42.19%] [G loss: 0.868916]\n",
      "epoch:41 step:32140[D loss: 0.399077, acc: 64.06%, op_acc: 42.97%] [G loss: 0.902794]\n",
      "epoch:41 step:32141[D loss: 0.432010, acc: 54.69%, op_acc: 44.53%] [G loss: 0.893049]\n",
      "epoch:41 step:32142[D loss: 0.426938, acc: 58.59%, op_acc: 41.41%] [G loss: 0.791499]\n",
      "epoch:41 step:32143[D loss: 0.387878, acc: 64.06%, op_acc: 39.84%] [G loss: 0.887638]\n",
      "epoch:41 step:32144[D loss: 0.429742, acc: 58.59%, op_acc: 41.41%] [G loss: 0.875608]\n",
      "epoch:41 step:32145[D loss: 0.395315, acc: 60.16%, op_acc: 50.00%] [G loss: 0.895967]\n",
      "epoch:41 step:32146[D loss: 0.436314, acc: 54.69%, op_acc: 40.62%] [G loss: 0.858289]\n",
      "epoch:41 step:32147[D loss: 0.423045, acc: 52.34%, op_acc: 39.84%] [G loss: 0.847494]\n",
      "epoch:41 step:32148[D loss: 0.412963, acc: 64.06%, op_acc: 46.09%] [G loss: 0.875059]\n",
      "epoch:41 step:32149[D loss: 0.397449, acc: 64.06%, op_acc: 39.84%] [G loss: 0.851816]\n",
      "epoch:41 step:32150[D loss: 0.410119, acc: 68.75%, op_acc: 40.62%] [G loss: 0.928869]\n",
      "##############\n",
      "[0.85130932 0.87421242 0.83257388 0.811194   0.80412205 0.82666549\n",
      " 0.87344814 0.83274685 0.83112818 0.80777431]\n",
      "##########\n",
      "epoch:41 step:32151[D loss: 0.419910, acc: 57.81%, op_acc: 44.53%] [G loss: 0.817608]\n",
      "epoch:41 step:32152[D loss: 0.386855, acc: 64.06%, op_acc: 47.66%] [G loss: 0.846311]\n",
      "epoch:41 step:32153[D loss: 0.372478, acc: 67.19%, op_acc: 46.09%] [G loss: 0.928260]\n",
      "epoch:41 step:32154[D loss: 0.457085, acc: 54.69%, op_acc: 36.72%] [G loss: 0.860074]\n",
      "epoch:41 step:32155[D loss: 0.409622, acc: 63.28%, op_acc: 44.53%] [G loss: 0.938402]\n",
      "epoch:41 step:32156[D loss: 0.420279, acc: 63.28%, op_acc: 42.19%] [G loss: 0.809088]\n",
      "epoch:41 step:32157[D loss: 0.359168, acc: 69.53%, op_acc: 53.12%] [G loss: 0.908147]\n",
      "epoch:41 step:32158[D loss: 0.424541, acc: 60.94%, op_acc: 36.72%] [G loss: 0.862092]\n",
      "epoch:41 step:32159[D loss: 0.383907, acc: 57.81%, op_acc: 53.91%] [G loss: 0.929780]\n",
      "epoch:41 step:32160[D loss: 0.396345, acc: 66.41%, op_acc: 42.19%] [G loss: 0.870607]\n",
      "epoch:41 step:32161[D loss: 0.447301, acc: 50.78%, op_acc: 39.06%] [G loss: 0.985754]\n",
      "epoch:41 step:32162[D loss: 0.435837, acc: 59.38%, op_acc: 30.47%] [G loss: 1.028803]\n",
      "epoch:41 step:32163[D loss: 0.422392, acc: 60.16%, op_acc: 42.19%] [G loss: 0.876182]\n",
      "epoch:41 step:32164[D loss: 0.419068, acc: 57.81%, op_acc: 46.88%] [G loss: 0.965153]\n",
      "epoch:41 step:32165[D loss: 0.427834, acc: 57.81%, op_acc: 41.41%] [G loss: 0.878114]\n",
      "epoch:41 step:32166[D loss: 0.395413, acc: 67.97%, op_acc: 43.75%] [G loss: 0.794570]\n",
      "epoch:41 step:32167[D loss: 0.389413, acc: 64.84%, op_acc: 47.66%] [G loss: 0.870290]\n",
      "epoch:41 step:32168[D loss: 0.409454, acc: 62.50%, op_acc: 45.31%] [G loss: 0.920048]\n",
      "epoch:41 step:32169[D loss: 0.434738, acc: 57.81%, op_acc: 41.41%] [G loss: 0.913896]\n",
      "epoch:41 step:32170[D loss: 0.400432, acc: 62.50%, op_acc: 43.75%] [G loss: 0.926957]\n",
      "epoch:41 step:32171[D loss: 0.397097, acc: 57.81%, op_acc: 41.41%] [G loss: 0.941664]\n",
      "epoch:41 step:32172[D loss: 0.396239, acc: 59.38%, op_acc: 45.31%] [G loss: 0.964756]\n",
      "epoch:41 step:32173[D loss: 0.397338, acc: 64.84%, op_acc: 45.31%] [G loss: 0.976837]\n",
      "epoch:41 step:32174[D loss: 0.421744, acc: 63.28%, op_acc: 42.97%] [G loss: 0.915820]\n",
      "epoch:41 step:32175[D loss: 0.405918, acc: 64.84%, op_acc: 42.97%] [G loss: 0.974073]\n",
      "epoch:41 step:32176[D loss: 0.406864, acc: 60.94%, op_acc: 42.19%] [G loss: 0.856927]\n",
      "epoch:41 step:32177[D loss: 0.430210, acc: 56.25%, op_acc: 40.62%] [G loss: 0.930877]\n",
      "epoch:41 step:32178[D loss: 0.409878, acc: 62.50%, op_acc: 38.28%] [G loss: 0.853242]\n",
      "epoch:41 step:32179[D loss: 0.372275, acc: 67.97%, op_acc: 45.31%] [G loss: 0.892675]\n",
      "epoch:41 step:32180[D loss: 0.392193, acc: 68.75%, op_acc: 39.06%] [G loss: 0.988337]\n",
      "epoch:41 step:32181[D loss: 0.409319, acc: 64.84%, op_acc: 39.06%] [G loss: 1.044635]\n",
      "epoch:41 step:32182[D loss: 0.421681, acc: 62.50%, op_acc: 41.41%] [G loss: 0.859559]\n",
      "epoch:41 step:32183[D loss: 0.408977, acc: 55.47%, op_acc: 45.31%] [G loss: 0.912055]\n",
      "epoch:41 step:32184[D loss: 0.394467, acc: 70.31%, op_acc: 39.84%] [G loss: 0.952895]\n",
      "epoch:41 step:32185[D loss: 0.425008, acc: 64.84%, op_acc: 39.84%] [G loss: 1.004591]\n",
      "epoch:41 step:32186[D loss: 0.429503, acc: 55.47%, op_acc: 41.41%] [G loss: 0.913961]\n",
      "epoch:41 step:32187[D loss: 0.383792, acc: 67.97%, op_acc: 42.97%] [G loss: 0.905665]\n",
      "epoch:41 step:32188[D loss: 0.438531, acc: 52.34%, op_acc: 45.31%] [G loss: 0.904404]\n",
      "epoch:41 step:32189[D loss: 0.386414, acc: 63.28%, op_acc: 45.31%] [G loss: 0.935946]\n",
      "epoch:41 step:32190[D loss: 0.412125, acc: 60.94%, op_acc: 40.62%] [G loss: 1.018515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32191[D loss: 0.409387, acc: 67.19%, op_acc: 45.31%] [G loss: 0.873617]\n",
      "epoch:41 step:32192[D loss: 0.411634, acc: 57.81%, op_acc: 41.41%] [G loss: 0.898907]\n",
      "epoch:41 step:32193[D loss: 0.370612, acc: 69.53%, op_acc: 46.09%] [G loss: 0.900136]\n",
      "epoch:41 step:32194[D loss: 0.407658, acc: 63.28%, op_acc: 36.72%] [G loss: 0.881096]\n",
      "epoch:41 step:32195[D loss: 0.454454, acc: 50.78%, op_acc: 36.72%] [G loss: 0.813962]\n",
      "epoch:41 step:32196[D loss: 0.421331, acc: 61.72%, op_acc: 38.28%] [G loss: 0.873225]\n",
      "epoch:41 step:32197[D loss: 0.435910, acc: 60.94%, op_acc: 38.28%] [G loss: 0.909552]\n",
      "epoch:41 step:32198[D loss: 0.421533, acc: 56.25%, op_acc: 42.19%] [G loss: 0.740143]\n",
      "epoch:41 step:32199[D loss: 0.439551, acc: 56.25%, op_acc: 37.50%] [G loss: 0.966933]\n",
      "epoch:41 step:32200[D loss: 0.430789, acc: 57.81%, op_acc: 38.28%] [G loss: 1.017080]\n",
      "##############\n",
      "[0.85466768 0.84782615 0.8178541  0.80781694 0.78815129 0.81742592\n",
      " 0.90620506 0.83129148 0.79085446 0.85176373]\n",
      "##########\n",
      "epoch:41 step:32201[D loss: 0.437205, acc: 62.50%, op_acc: 41.41%] [G loss: 0.929871]\n",
      "epoch:41 step:32202[D loss: 0.457626, acc: 47.66%, op_acc: 40.62%] [G loss: 0.936021]\n",
      "epoch:41 step:32203[D loss: 0.399071, acc: 62.50%, op_acc: 42.97%] [G loss: 0.955652]\n",
      "epoch:41 step:32204[D loss: 0.456323, acc: 57.03%, op_acc: 36.72%] [G loss: 0.812684]\n",
      "epoch:41 step:32205[D loss: 0.408326, acc: 62.50%, op_acc: 42.19%] [G loss: 0.954087]\n",
      "epoch:41 step:32206[D loss: 0.423967, acc: 63.28%, op_acc: 38.28%] [G loss: 0.936904]\n",
      "epoch:41 step:32207[D loss: 0.443646, acc: 53.12%, op_acc: 42.97%] [G loss: 0.777868]\n",
      "epoch:41 step:32208[D loss: 0.415582, acc: 59.38%, op_acc: 40.62%] [G loss: 0.835819]\n",
      "epoch:41 step:32209[D loss: 0.456829, acc: 53.12%, op_acc: 37.50%] [G loss: 0.858138]\n",
      "epoch:41 step:32210[D loss: 0.399573, acc: 67.19%, op_acc: 38.28%] [G loss: 0.960361]\n",
      "epoch:41 step:32211[D loss: 0.465491, acc: 39.84%, op_acc: 39.84%] [G loss: 0.912812]\n",
      "epoch:41 step:32212[D loss: 0.396790, acc: 60.16%, op_acc: 42.19%] [G loss: 0.864676]\n",
      "epoch:41 step:32213[D loss: 0.409982, acc: 60.94%, op_acc: 42.19%] [G loss: 0.980571]\n",
      "epoch:41 step:32214[D loss: 0.424809, acc: 64.84%, op_acc: 42.97%] [G loss: 0.892846]\n",
      "epoch:41 step:32215[D loss: 0.380931, acc: 65.62%, op_acc: 42.19%] [G loss: 0.982194]\n",
      "epoch:41 step:32216[D loss: 0.432250, acc: 57.03%, op_acc: 39.06%] [G loss: 0.950988]\n",
      "epoch:41 step:32217[D loss: 0.398286, acc: 69.53%, op_acc: 39.84%] [G loss: 0.935410]\n",
      "epoch:41 step:32218[D loss: 0.449447, acc: 55.47%, op_acc: 38.28%] [G loss: 0.886899]\n",
      "epoch:41 step:32219[D loss: 0.456501, acc: 49.22%, op_acc: 35.94%] [G loss: 0.952389]\n",
      "epoch:41 step:32220[D loss: 0.447506, acc: 49.22%, op_acc: 43.75%] [G loss: 0.804430]\n",
      "epoch:41 step:32221[D loss: 0.402169, acc: 60.94%, op_acc: 46.88%] [G loss: 0.965458]\n",
      "epoch:41 step:32222[D loss: 0.394729, acc: 64.06%, op_acc: 41.41%] [G loss: 0.902380]\n",
      "epoch:41 step:32223[D loss: 0.414725, acc: 61.72%, op_acc: 41.41%] [G loss: 0.844528]\n",
      "epoch:41 step:32224[D loss: 0.423456, acc: 61.72%, op_acc: 37.50%] [G loss: 0.868205]\n",
      "epoch:41 step:32225[D loss: 0.396118, acc: 67.19%, op_acc: 42.19%] [G loss: 0.903405]\n",
      "epoch:41 step:32226[D loss: 0.403289, acc: 65.62%, op_acc: 42.97%] [G loss: 0.890113]\n",
      "epoch:41 step:32227[D loss: 0.373398, acc: 68.75%, op_acc: 47.66%] [G loss: 0.918284]\n",
      "epoch:41 step:32228[D loss: 0.388990, acc: 67.97%, op_acc: 35.94%] [G loss: 0.869093]\n",
      "epoch:41 step:32229[D loss: 0.432523, acc: 57.03%, op_acc: 35.94%] [G loss: 0.915504]\n",
      "epoch:41 step:32230[D loss: 0.411214, acc: 59.38%, op_acc: 40.62%] [G loss: 0.801897]\n",
      "epoch:41 step:32231[D loss: 0.441352, acc: 57.03%, op_acc: 35.16%] [G loss: 0.930455]\n",
      "epoch:41 step:32232[D loss: 0.392266, acc: 60.94%, op_acc: 44.53%] [G loss: 0.893412]\n",
      "epoch:41 step:32233[D loss: 0.399542, acc: 62.50%, op_acc: 39.84%] [G loss: 1.050362]\n",
      "epoch:41 step:32234[D loss: 0.400475, acc: 62.50%, op_acc: 39.84%] [G loss: 1.000282]\n",
      "epoch:41 step:32235[D loss: 0.410297, acc: 60.16%, op_acc: 39.06%] [G loss: 0.891267]\n",
      "epoch:41 step:32236[D loss: 0.447759, acc: 57.81%, op_acc: 39.84%] [G loss: 0.908002]\n",
      "epoch:41 step:32237[D loss: 0.433124, acc: 53.91%, op_acc: 39.06%] [G loss: 1.117888]\n",
      "epoch:41 step:32238[D loss: 0.395977, acc: 62.50%, op_acc: 49.22%] [G loss: 1.025591]\n",
      "epoch:41 step:32239[D loss: 0.420554, acc: 57.03%, op_acc: 50.00%] [G loss: 0.831803]\n",
      "epoch:41 step:32240[D loss: 0.392814, acc: 67.97%, op_acc: 41.41%] [G loss: 0.859687]\n",
      "epoch:41 step:32241[D loss: 0.434035, acc: 57.81%, op_acc: 42.97%] [G loss: 0.939323]\n",
      "epoch:41 step:32242[D loss: 0.368870, acc: 70.31%, op_acc: 38.28%] [G loss: 0.981846]\n",
      "epoch:41 step:32243[D loss: 0.419592, acc: 60.94%, op_acc: 39.84%] [G loss: 0.919413]\n",
      "epoch:41 step:32244[D loss: 0.384036, acc: 69.53%, op_acc: 46.09%] [G loss: 0.923636]\n",
      "epoch:41 step:32245[D loss: 0.392195, acc: 67.97%, op_acc: 44.53%] [G loss: 0.851175]\n",
      "epoch:41 step:32246[D loss: 0.416682, acc: 57.81%, op_acc: 37.50%] [G loss: 0.886879]\n",
      "epoch:41 step:32247[D loss: 0.416597, acc: 61.72%, op_acc: 39.06%] [G loss: 0.917970]\n",
      "epoch:41 step:32248[D loss: 0.435772, acc: 60.16%, op_acc: 36.72%] [G loss: 0.812703]\n",
      "epoch:41 step:32249[D loss: 0.393159, acc: 61.72%, op_acc: 45.31%] [G loss: 0.923723]\n",
      "epoch:41 step:32250[D loss: 0.430924, acc: 52.34%, op_acc: 41.41%] [G loss: 0.868014]\n",
      "##############\n",
      "[0.8525204  0.85618689 0.81179899 0.79902315 0.77687537 0.81765739\n",
      " 0.88160285 0.82253788 0.82731785 0.8386347 ]\n",
      "##########\n",
      "epoch:41 step:32251[D loss: 0.406892, acc: 64.84%, op_acc: 41.41%] [G loss: 0.932787]\n",
      "epoch:41 step:32252[D loss: 0.396195, acc: 58.59%, op_acc: 45.31%] [G loss: 0.955506]\n",
      "epoch:41 step:32253[D loss: 0.378031, acc: 71.09%, op_acc: 44.53%] [G loss: 0.784317]\n",
      "epoch:41 step:32254[D loss: 0.402188, acc: 60.16%, op_acc: 42.19%] [G loss: 0.894869]\n",
      "epoch:41 step:32255[D loss: 0.415955, acc: 64.84%, op_acc: 37.50%] [G loss: 0.909484]\n",
      "epoch:41 step:32256[D loss: 0.401200, acc: 60.16%, op_acc: 38.28%] [G loss: 0.895886]\n",
      "epoch:41 step:32257[D loss: 0.402569, acc: 64.06%, op_acc: 38.28%] [G loss: 1.015204]\n",
      "epoch:41 step:32258[D loss: 0.403214, acc: 58.59%, op_acc: 39.06%] [G loss: 0.959001]\n",
      "epoch:41 step:32259[D loss: 0.417234, acc: 57.03%, op_acc: 39.84%] [G loss: 0.976621]\n",
      "epoch:41 step:32260[D loss: 0.385305, acc: 66.41%, op_acc: 38.28%] [G loss: 0.968622]\n",
      "epoch:41 step:32261[D loss: 0.411489, acc: 67.19%, op_acc: 44.53%] [G loss: 0.904477]\n",
      "epoch:41 step:32262[D loss: 0.409335, acc: 57.03%, op_acc: 45.31%] [G loss: 0.912155]\n",
      "epoch:41 step:32263[D loss: 0.380797, acc: 63.28%, op_acc: 45.31%] [G loss: 0.933305]\n",
      "epoch:41 step:32264[D loss: 0.403152, acc: 58.59%, op_acc: 47.66%] [G loss: 0.898921]\n",
      "epoch:41 step:32265[D loss: 0.424788, acc: 62.50%, op_acc: 37.50%] [G loss: 0.869927]\n",
      "epoch:41 step:32266[D loss: 0.423737, acc: 61.72%, op_acc: 42.19%] [G loss: 0.931810]\n",
      "epoch:41 step:32267[D loss: 0.405344, acc: 69.53%, op_acc: 38.28%] [G loss: 0.856779]\n",
      "epoch:41 step:32268[D loss: 0.414677, acc: 58.59%, op_acc: 40.62%] [G loss: 0.845121]\n",
      "epoch:41 step:32269[D loss: 0.430856, acc: 60.94%, op_acc: 38.28%] [G loss: 0.941112]\n",
      "epoch:41 step:32270[D loss: 0.417940, acc: 56.25%, op_acc: 40.62%] [G loss: 0.921540]\n",
      "epoch:41 step:32271[D loss: 0.442639, acc: 57.03%, op_acc: 41.41%] [G loss: 0.834216]\n",
      "epoch:41 step:32272[D loss: 0.381752, acc: 65.62%, op_acc: 48.44%] [G loss: 0.964271]\n",
      "epoch:41 step:32273[D loss: 0.413394, acc: 60.94%, op_acc: 45.31%] [G loss: 0.773768]\n",
      "epoch:41 step:32274[D loss: 0.444757, acc: 52.34%, op_acc: 37.50%] [G loss: 0.771652]\n",
      "epoch:41 step:32275[D loss: 0.411673, acc: 54.69%, op_acc: 41.41%] [G loss: 0.795980]\n",
      "epoch:41 step:32276[D loss: 0.414955, acc: 57.03%, op_acc: 39.84%] [G loss: 0.920664]\n",
      "epoch:41 step:32277[D loss: 0.393617, acc: 58.59%, op_acc: 46.88%] [G loss: 0.829326]\n",
      "epoch:41 step:32278[D loss: 0.402113, acc: 65.62%, op_acc: 41.41%] [G loss: 0.886702]\n",
      "epoch:41 step:32279[D loss: 0.428759, acc: 56.25%, op_acc: 42.97%] [G loss: 0.763856]\n",
      "epoch:41 step:32280[D loss: 0.422773, acc: 59.38%, op_acc: 42.19%] [G loss: 0.882116]\n",
      "epoch:41 step:32281[D loss: 0.413882, acc: 63.28%, op_acc: 37.50%] [G loss: 0.918650]\n",
      "epoch:41 step:32282[D loss: 0.439185, acc: 57.81%, op_acc: 35.94%] [G loss: 0.883563]\n",
      "epoch:41 step:32283[D loss: 0.386046, acc: 64.84%, op_acc: 46.09%] [G loss: 0.878210]\n",
      "epoch:41 step:32284[D loss: 0.424737, acc: 58.59%, op_acc: 42.97%] [G loss: 0.906244]\n",
      "epoch:41 step:32285[D loss: 0.400992, acc: 60.94%, op_acc: 46.09%] [G loss: 0.988369]\n",
      "epoch:41 step:32286[D loss: 0.413280, acc: 57.03%, op_acc: 42.19%] [G loss: 0.903269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32287[D loss: 0.407954, acc: 60.16%, op_acc: 39.84%] [G loss: 0.883016]\n",
      "epoch:41 step:32288[D loss: 0.451781, acc: 57.81%, op_acc: 39.06%] [G loss: 0.929613]\n",
      "epoch:41 step:32289[D loss: 0.409581, acc: 60.94%, op_acc: 42.97%] [G loss: 0.936077]\n",
      "epoch:41 step:32290[D loss: 0.419869, acc: 59.38%, op_acc: 42.97%] [G loss: 0.925636]\n",
      "epoch:41 step:32291[D loss: 0.373755, acc: 71.09%, op_acc: 44.53%] [G loss: 0.919385]\n",
      "epoch:41 step:32292[D loss: 0.409546, acc: 63.28%, op_acc: 41.41%] [G loss: 0.876147]\n",
      "epoch:41 step:32293[D loss: 0.413174, acc: 64.06%, op_acc: 37.50%] [G loss: 0.907349]\n",
      "epoch:41 step:32294[D loss: 0.431474, acc: 54.69%, op_acc: 37.50%] [G loss: 0.948161]\n",
      "epoch:41 step:32295[D loss: 0.384245, acc: 63.28%, op_acc: 43.75%] [G loss: 0.955121]\n",
      "epoch:41 step:32296[D loss: 0.418409, acc: 62.50%, op_acc: 42.19%] [G loss: 0.936035]\n",
      "epoch:41 step:32297[D loss: 0.423763, acc: 53.91%, op_acc: 41.41%] [G loss: 0.934908]\n",
      "epoch:41 step:32298[D loss: 0.423799, acc: 63.28%, op_acc: 38.28%] [G loss: 0.996846]\n",
      "epoch:41 step:32299[D loss: 0.412311, acc: 61.72%, op_acc: 38.28%] [G loss: 0.989587]\n",
      "epoch:41 step:32300[D loss: 0.413692, acc: 60.94%, op_acc: 41.41%] [G loss: 0.931906]\n",
      "##############\n",
      "[0.88009321 0.86100302 0.80413632 0.80667183 0.78942207 0.8364392\n",
      " 0.885383   0.85370363 0.82948705 0.82596305]\n",
      "##########\n",
      "epoch:41 step:32301[D loss: 0.409285, acc: 55.47%, op_acc: 42.19%] [G loss: 0.882717]\n",
      "epoch:41 step:32302[D loss: 0.405406, acc: 60.94%, op_acc: 37.50%] [G loss: 0.901314]\n",
      "epoch:41 step:32303[D loss: 0.423837, acc: 58.59%, op_acc: 39.84%] [G loss: 0.840640]\n",
      "epoch:41 step:32304[D loss: 0.384854, acc: 66.41%, op_acc: 42.19%] [G loss: 0.992282]\n",
      "epoch:41 step:32305[D loss: 0.406163, acc: 60.16%, op_acc: 43.75%] [G loss: 1.005391]\n",
      "epoch:41 step:32306[D loss: 0.412819, acc: 60.16%, op_acc: 39.06%] [G loss: 1.008788]\n",
      "epoch:41 step:32307[D loss: 0.408103, acc: 60.16%, op_acc: 44.53%] [G loss: 0.862060]\n",
      "epoch:41 step:32308[D loss: 0.418108, acc: 59.38%, op_acc: 41.41%] [G loss: 0.911043]\n",
      "epoch:41 step:32309[D loss: 0.378408, acc: 67.97%, op_acc: 46.09%] [G loss: 0.933154]\n",
      "epoch:41 step:32310[D loss: 0.391727, acc: 65.62%, op_acc: 43.75%] [G loss: 0.838439]\n",
      "epoch:41 step:32311[D loss: 0.371899, acc: 62.50%, op_acc: 42.97%] [G loss: 0.933821]\n",
      "epoch:41 step:32312[D loss: 0.424535, acc: 56.25%, op_acc: 36.72%] [G loss: 0.839232]\n",
      "epoch:41 step:32313[D loss: 0.427768, acc: 60.16%, op_acc: 40.62%] [G loss: 0.951073]\n",
      "epoch:41 step:32314[D loss: 0.415899, acc: 62.50%, op_acc: 41.41%] [G loss: 0.948102]\n",
      "epoch:41 step:32315[D loss: 0.401423, acc: 67.97%, op_acc: 39.06%] [G loss: 0.869935]\n",
      "epoch:41 step:32316[D loss: 0.412266, acc: 59.38%, op_acc: 40.62%] [G loss: 0.950273]\n",
      "epoch:41 step:32317[D loss: 0.406111, acc: 64.84%, op_acc: 47.66%] [G loss: 0.866073]\n",
      "epoch:41 step:32318[D loss: 0.391360, acc: 63.28%, op_acc: 39.84%] [G loss: 0.901382]\n",
      "epoch:41 step:32319[D loss: 0.403220, acc: 62.50%, op_acc: 39.06%] [G loss: 0.912635]\n",
      "epoch:41 step:32320[D loss: 0.385997, acc: 64.84%, op_acc: 41.41%] [G loss: 0.879593]\n",
      "epoch:41 step:32321[D loss: 0.426164, acc: 57.03%, op_acc: 39.06%] [G loss: 0.915978]\n",
      "epoch:41 step:32322[D loss: 0.387784, acc: 64.84%, op_acc: 42.19%] [G loss: 0.911659]\n",
      "epoch:41 step:32323[D loss: 0.404834, acc: 61.72%, op_acc: 50.78%] [G loss: 0.959789]\n",
      "epoch:41 step:32324[D loss: 0.390112, acc: 70.31%, op_acc: 42.19%] [G loss: 0.829339]\n",
      "epoch:41 step:32325[D loss: 0.393566, acc: 60.16%, op_acc: 44.53%] [G loss: 0.891901]\n",
      "epoch:41 step:32326[D loss: 0.412672, acc: 55.47%, op_acc: 42.19%] [G loss: 0.964666]\n",
      "epoch:41 step:32327[D loss: 0.411638, acc: 61.72%, op_acc: 35.94%] [G loss: 0.967219]\n",
      "epoch:41 step:32328[D loss: 0.415532, acc: 61.72%, op_acc: 39.84%] [G loss: 0.968100]\n",
      "epoch:41 step:32329[D loss: 0.425404, acc: 59.38%, op_acc: 39.06%] [G loss: 0.811074]\n",
      "epoch:41 step:32330[D loss: 0.408664, acc: 62.50%, op_acc: 37.50%] [G loss: 0.852154]\n",
      "epoch:41 step:32331[D loss: 0.400620, acc: 62.50%, op_acc: 42.19%] [G loss: 0.893934]\n",
      "epoch:41 step:32332[D loss: 0.401405, acc: 58.59%, op_acc: 43.75%] [G loss: 0.921354]\n",
      "epoch:41 step:32333[D loss: 0.436450, acc: 53.12%, op_acc: 39.84%] [G loss: 0.923215]\n",
      "epoch:41 step:32334[D loss: 0.405711, acc: 61.72%, op_acc: 44.53%] [G loss: 0.916178]\n",
      "epoch:41 step:32335[D loss: 0.396276, acc: 65.62%, op_acc: 46.09%] [G loss: 0.924349]\n",
      "epoch:41 step:32336[D loss: 0.425165, acc: 57.03%, op_acc: 39.84%] [G loss: 0.938025]\n",
      "epoch:41 step:32337[D loss: 0.403930, acc: 62.50%, op_acc: 42.19%] [G loss: 0.888937]\n",
      "epoch:41 step:32338[D loss: 0.429730, acc: 57.03%, op_acc: 40.62%] [G loss: 0.781814]\n",
      "epoch:41 step:32339[D loss: 0.409010, acc: 60.16%, op_acc: 38.28%] [G loss: 0.912190]\n",
      "epoch:41 step:32340[D loss: 0.440264, acc: 54.69%, op_acc: 43.75%] [G loss: 0.890700]\n",
      "epoch:41 step:32341[D loss: 0.404088, acc: 70.31%, op_acc: 37.50%] [G loss: 0.899474]\n",
      "epoch:41 step:32342[D loss: 0.439148, acc: 58.59%, op_acc: 40.62%] [G loss: 0.924912]\n",
      "epoch:41 step:32343[D loss: 0.420945, acc: 57.81%, op_acc: 38.28%] [G loss: 0.927211]\n",
      "epoch:41 step:32344[D loss: 0.400205, acc: 64.84%, op_acc: 41.41%] [G loss: 0.858923]\n",
      "epoch:41 step:32345[D loss: 0.443575, acc: 60.94%, op_acc: 37.50%] [G loss: 0.915373]\n",
      "epoch:41 step:32346[D loss: 0.430960, acc: 50.78%, op_acc: 40.62%] [G loss: 0.864327]\n",
      "epoch:41 step:32347[D loss: 0.401354, acc: 60.94%, op_acc: 42.19%] [G loss: 0.945286]\n",
      "epoch:41 step:32348[D loss: 0.445330, acc: 56.25%, op_acc: 39.84%] [G loss: 0.944237]\n",
      "epoch:41 step:32349[D loss: 0.404805, acc: 60.16%, op_acc: 49.22%] [G loss: 0.902358]\n",
      "epoch:41 step:32350[D loss: 0.406308, acc: 60.94%, op_acc: 45.31%] [G loss: 0.936636]\n",
      "##############\n",
      "[0.8506966  0.83948763 0.8143715  0.80311009 0.83370952 0.84704892\n",
      " 0.87671966 0.83309643 0.78876211 0.80817577]\n",
      "##########\n",
      "epoch:41 step:32351[D loss: 0.416312, acc: 56.25%, op_acc: 41.41%] [G loss: 0.873637]\n",
      "epoch:41 step:32352[D loss: 0.412137, acc: 57.81%, op_acc: 42.19%] [G loss: 0.919400]\n",
      "epoch:41 step:32353[D loss: 0.407419, acc: 58.59%, op_acc: 42.97%] [G loss: 0.859125]\n",
      "epoch:41 step:32354[D loss: 0.444363, acc: 57.81%, op_acc: 40.62%] [G loss: 0.882417]\n",
      "epoch:41 step:32355[D loss: 0.421062, acc: 56.25%, op_acc: 42.19%] [G loss: 0.934884]\n",
      "epoch:41 step:32356[D loss: 0.396959, acc: 65.62%, op_acc: 35.94%] [G loss: 0.928495]\n",
      "epoch:41 step:32357[D loss: 0.423099, acc: 58.59%, op_acc: 35.94%] [G loss: 0.785489]\n",
      "epoch:41 step:32358[D loss: 0.432481, acc: 53.12%, op_acc: 42.97%] [G loss: 0.851397]\n",
      "epoch:41 step:32359[D loss: 0.399348, acc: 55.47%, op_acc: 50.00%] [G loss: 0.975711]\n",
      "epoch:41 step:32360[D loss: 0.432958, acc: 54.69%, op_acc: 42.19%] [G loss: 0.872157]\n",
      "epoch:41 step:32361[D loss: 0.456228, acc: 49.22%, op_acc: 41.41%] [G loss: 0.979062]\n",
      "epoch:41 step:32362[D loss: 0.435327, acc: 63.28%, op_acc: 33.59%] [G loss: 0.970210]\n",
      "epoch:41 step:32363[D loss: 0.437048, acc: 53.91%, op_acc: 46.09%] [G loss: 0.930714]\n",
      "epoch:41 step:32364[D loss: 0.461751, acc: 53.12%, op_acc: 35.94%] [G loss: 0.819547]\n",
      "epoch:41 step:32365[D loss: 0.401177, acc: 58.59%, op_acc: 42.19%] [G loss: 0.881232]\n",
      "epoch:41 step:32366[D loss: 0.427136, acc: 61.72%, op_acc: 35.16%] [G loss: 0.928869]\n",
      "epoch:41 step:32367[D loss: 0.396426, acc: 68.75%, op_acc: 41.41%] [G loss: 0.851407]\n",
      "epoch:41 step:32368[D loss: 0.408586, acc: 61.72%, op_acc: 48.44%] [G loss: 0.887836]\n",
      "epoch:41 step:32369[D loss: 0.379220, acc: 64.84%, op_acc: 43.75%] [G loss: 0.777238]\n",
      "epoch:41 step:32370[D loss: 0.401696, acc: 61.72%, op_acc: 43.75%] [G loss: 0.920596]\n",
      "epoch:41 step:32371[D loss: 0.451347, acc: 52.34%, op_acc: 41.41%] [G loss: 0.951411]\n",
      "epoch:41 step:32372[D loss: 0.447593, acc: 51.56%, op_acc: 40.62%] [G loss: 0.808278]\n",
      "epoch:41 step:32373[D loss: 0.414102, acc: 61.72%, op_acc: 39.06%] [G loss: 0.754989]\n",
      "epoch:41 step:32374[D loss: 0.357891, acc: 73.44%, op_acc: 47.66%] [G loss: 0.778738]\n",
      "epoch:41 step:32375[D loss: 0.419495, acc: 58.59%, op_acc: 39.06%] [G loss: 0.866443]\n",
      "epoch:41 step:32376[D loss: 0.428327, acc: 62.50%, op_acc: 43.75%] [G loss: 0.998776]\n",
      "epoch:41 step:32377[D loss: 0.418068, acc: 58.59%, op_acc: 40.62%] [G loss: 0.822195]\n",
      "epoch:41 step:32378[D loss: 0.424248, acc: 64.06%, op_acc: 41.41%] [G loss: 0.860885]\n",
      "epoch:41 step:32379[D loss: 0.422091, acc: 61.72%, op_acc: 42.19%] [G loss: 0.941410]\n",
      "epoch:41 step:32380[D loss: 0.431957, acc: 53.91%, op_acc: 42.19%] [G loss: 0.992679]\n",
      "epoch:41 step:32381[D loss: 0.394240, acc: 68.75%, op_acc: 43.75%] [G loss: 0.947713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32382[D loss: 0.392525, acc: 64.06%, op_acc: 48.44%] [G loss: 0.943551]\n",
      "epoch:41 step:32383[D loss: 0.409973, acc: 57.03%, op_acc: 42.97%] [G loss: 0.882569]\n",
      "epoch:41 step:32384[D loss: 0.368600, acc: 69.53%, op_acc: 46.88%] [G loss: 0.859229]\n",
      "epoch:41 step:32385[D loss: 0.404757, acc: 67.19%, op_acc: 44.53%] [G loss: 0.895524]\n",
      "epoch:41 step:32386[D loss: 0.362354, acc: 69.53%, op_acc: 50.00%] [G loss: 0.859920]\n",
      "epoch:41 step:32387[D loss: 0.379529, acc: 67.97%, op_acc: 42.19%] [G loss: 0.932897]\n",
      "epoch:41 step:32388[D loss: 0.440028, acc: 54.69%, op_acc: 31.25%] [G loss: 0.844322]\n",
      "epoch:41 step:32389[D loss: 0.416290, acc: 53.12%, op_acc: 40.62%] [G loss: 0.872005]\n",
      "epoch:41 step:32390[D loss: 0.409237, acc: 59.38%, op_acc: 40.62%] [G loss: 0.885338]\n",
      "epoch:41 step:32391[D loss: 0.434604, acc: 59.38%, op_acc: 35.16%] [G loss: 0.854530]\n",
      "epoch:41 step:32392[D loss: 0.368482, acc: 69.53%, op_acc: 45.31%] [G loss: 0.905852]\n",
      "epoch:41 step:32393[D loss: 0.419092, acc: 58.59%, op_acc: 41.41%] [G loss: 0.929145]\n",
      "epoch:41 step:32394[D loss: 0.415423, acc: 64.84%, op_acc: 40.62%] [G loss: 0.847581]\n",
      "epoch:41 step:32395[D loss: 0.383492, acc: 66.41%, op_acc: 50.78%] [G loss: 0.821501]\n",
      "epoch:41 step:32396[D loss: 0.424262, acc: 55.47%, op_acc: 43.75%] [G loss: 0.822611]\n",
      "epoch:41 step:32397[D loss: 0.386140, acc: 70.31%, op_acc: 35.94%] [G loss: 0.893383]\n",
      "epoch:41 step:32398[D loss: 0.407212, acc: 64.06%, op_acc: 41.41%] [G loss: 0.899287]\n",
      "epoch:41 step:32399[D loss: 0.409272, acc: 63.28%, op_acc: 38.28%] [G loss: 0.922746]\n",
      "epoch:41 step:32400[D loss: 0.391101, acc: 63.28%, op_acc: 42.97%] [G loss: 0.928423]\n",
      "##############\n",
      "[0.85959458 0.85174562 0.80895309 0.80810477 0.79833917 0.82489847\n",
      " 0.88778946 0.82847869 0.8165883  0.83550965]\n",
      "##########\n",
      "epoch:41 step:32401[D loss: 0.413947, acc: 64.84%, op_acc: 43.75%] [G loss: 0.913684]\n",
      "epoch:41 step:32402[D loss: 0.381940, acc: 72.66%, op_acc: 41.41%] [G loss: 0.847218]\n",
      "epoch:41 step:32403[D loss: 0.404219, acc: 66.41%, op_acc: 42.19%] [G loss: 0.935455]\n",
      "epoch:41 step:32404[D loss: 0.394660, acc: 60.16%, op_acc: 48.44%] [G loss: 1.035180]\n",
      "epoch:41 step:32405[D loss: 0.400106, acc: 60.16%, op_acc: 46.88%] [G loss: 0.890061]\n",
      "epoch:41 step:32406[D loss: 0.390534, acc: 65.62%, op_acc: 44.53%] [G loss: 0.918363]\n",
      "epoch:41 step:32407[D loss: 0.424476, acc: 62.50%, op_acc: 39.06%] [G loss: 0.870663]\n",
      "epoch:41 step:32408[D loss: 0.437371, acc: 60.16%, op_acc: 40.62%] [G loss: 0.873076]\n",
      "epoch:41 step:32409[D loss: 0.426661, acc: 66.41%, op_acc: 40.62%] [G loss: 0.864354]\n",
      "epoch:41 step:32410[D loss: 0.446773, acc: 56.25%, op_acc: 37.50%] [G loss: 0.907825]\n",
      "epoch:41 step:32411[D loss: 0.396339, acc: 69.53%, op_acc: 42.19%] [G loss: 1.039885]\n",
      "epoch:41 step:32412[D loss: 0.421493, acc: 61.72%, op_acc: 40.62%] [G loss: 0.960808]\n",
      "epoch:41 step:32413[D loss: 0.382754, acc: 67.97%, op_acc: 42.97%] [G loss: 0.862080]\n",
      "epoch:41 step:32414[D loss: 0.427770, acc: 60.16%, op_acc: 44.53%] [G loss: 0.866635]\n",
      "epoch:41 step:32415[D loss: 0.434394, acc: 54.69%, op_acc: 39.84%] [G loss: 0.832309]\n",
      "epoch:41 step:32416[D loss: 0.433785, acc: 66.41%, op_acc: 37.50%] [G loss: 0.841510]\n",
      "epoch:41 step:32417[D loss: 0.401999, acc: 59.38%, op_acc: 38.28%] [G loss: 0.852821]\n",
      "epoch:41 step:32418[D loss: 0.400635, acc: 67.97%, op_acc: 45.31%] [G loss: 0.938678]\n",
      "epoch:41 step:32419[D loss: 0.442710, acc: 55.47%, op_acc: 35.94%] [G loss: 0.863810]\n",
      "epoch:41 step:32420[D loss: 0.397977, acc: 62.50%, op_acc: 48.44%] [G loss: 0.915078]\n",
      "epoch:41 step:32421[D loss: 0.392133, acc: 67.19%, op_acc: 46.09%] [G loss: 0.961439]\n",
      "epoch:41 step:32422[D loss: 0.398286, acc: 65.62%, op_acc: 40.62%] [G loss: 1.003780]\n",
      "epoch:41 step:32423[D loss: 0.409125, acc: 61.72%, op_acc: 46.88%] [G loss: 0.854086]\n",
      "epoch:41 step:32424[D loss: 0.377373, acc: 66.41%, op_acc: 40.62%] [G loss: 0.832085]\n",
      "epoch:41 step:32425[D loss: 0.389703, acc: 62.50%, op_acc: 44.53%] [G loss: 0.867065]\n",
      "epoch:41 step:32426[D loss: 0.418460, acc: 63.28%, op_acc: 37.50%] [G loss: 0.925487]\n",
      "epoch:41 step:32427[D loss: 0.438142, acc: 55.47%, op_acc: 45.31%] [G loss: 0.819831]\n",
      "epoch:41 step:32428[D loss: 0.407067, acc: 62.50%, op_acc: 35.94%] [G loss: 0.960918]\n",
      "epoch:41 step:32429[D loss: 0.370141, acc: 64.84%, op_acc: 42.97%] [G loss: 0.899833]\n",
      "epoch:41 step:32430[D loss: 0.442822, acc: 56.25%, op_acc: 46.09%] [G loss: 0.870343]\n",
      "epoch:41 step:32431[D loss: 0.362807, acc: 69.53%, op_acc: 47.66%] [G loss: 0.912258]\n",
      "epoch:41 step:32432[D loss: 0.444351, acc: 67.19%, op_acc: 35.94%] [G loss: 0.902190]\n",
      "epoch:41 step:32433[D loss: 0.399319, acc: 64.84%, op_acc: 42.97%] [G loss: 0.794959]\n",
      "epoch:41 step:32434[D loss: 0.398979, acc: 57.81%, op_acc: 42.19%] [G loss: 0.955301]\n",
      "epoch:41 step:32435[D loss: 0.375104, acc: 67.97%, op_acc: 42.97%] [G loss: 0.941586]\n",
      "epoch:41 step:32436[D loss: 0.411547, acc: 58.59%, op_acc: 45.31%] [G loss: 0.963620]\n",
      "epoch:41 step:32437[D loss: 0.400504, acc: 58.59%, op_acc: 42.97%] [G loss: 0.892687]\n",
      "epoch:41 step:32438[D loss: 0.434435, acc: 62.50%, op_acc: 38.28%] [G loss: 0.946043]\n",
      "epoch:41 step:32439[D loss: 0.419597, acc: 54.69%, op_acc: 42.19%] [G loss: 0.899280]\n",
      "epoch:41 step:32440[D loss: 0.409073, acc: 64.84%, op_acc: 41.41%] [G loss: 0.944558]\n",
      "epoch:41 step:32441[D loss: 0.421893, acc: 57.81%, op_acc: 43.75%] [G loss: 0.990788]\n",
      "epoch:41 step:32442[D loss: 0.438524, acc: 61.72%, op_acc: 35.16%] [G loss: 0.909983]\n",
      "epoch:41 step:32443[D loss: 0.421265, acc: 56.25%, op_acc: 42.97%] [G loss: 0.875503]\n",
      "epoch:41 step:32444[D loss: 0.428410, acc: 60.16%, op_acc: 36.72%] [G loss: 0.869895]\n",
      "epoch:41 step:32445[D loss: 0.424106, acc: 60.94%, op_acc: 39.06%] [G loss: 0.957816]\n",
      "epoch:41 step:32446[D loss: 0.432685, acc: 58.59%, op_acc: 40.62%] [G loss: 0.920257]\n",
      "epoch:41 step:32447[D loss: 0.419804, acc: 64.06%, op_acc: 42.97%] [G loss: 0.890497]\n",
      "epoch:41 step:32448[D loss: 0.436467, acc: 57.03%, op_acc: 41.41%] [G loss: 0.885554]\n",
      "epoch:41 step:32449[D loss: 0.431306, acc: 56.25%, op_acc: 41.41%] [G loss: 0.938979]\n",
      "epoch:41 step:32450[D loss: 0.431829, acc: 51.56%, op_acc: 42.97%] [G loss: 0.896396]\n",
      "##############\n",
      "[0.83588817 0.85482855 0.81223492 0.80083245 0.79626623 0.80122197\n",
      " 0.88754054 0.85194448 0.80338457 0.8093751 ]\n",
      "##########\n",
      "epoch:41 step:32451[D loss: 0.400239, acc: 64.06%, op_acc: 44.53%] [G loss: 0.922484]\n",
      "epoch:41 step:32452[D loss: 0.469552, acc: 46.88%, op_acc: 38.28%] [G loss: 0.899739]\n",
      "epoch:41 step:32453[D loss: 0.396737, acc: 64.06%, op_acc: 42.97%] [G loss: 0.946230]\n",
      "epoch:41 step:32454[D loss: 0.411731, acc: 53.12%, op_acc: 42.97%] [G loss: 0.863601]\n",
      "epoch:41 step:32455[D loss: 0.397880, acc: 62.50%, op_acc: 43.75%] [G loss: 0.916956]\n",
      "epoch:41 step:32456[D loss: 0.404745, acc: 59.38%, op_acc: 43.75%] [G loss: 0.915541]\n",
      "epoch:41 step:32457[D loss: 0.432521, acc: 59.38%, op_acc: 36.72%] [G loss: 0.850165]\n",
      "epoch:41 step:32458[D loss: 0.407770, acc: 66.41%, op_acc: 41.41%] [G loss: 0.908166]\n",
      "epoch:41 step:32459[D loss: 0.424556, acc: 53.91%, op_acc: 40.62%] [G loss: 0.886513]\n",
      "epoch:41 step:32460[D loss: 0.402350, acc: 61.72%, op_acc: 38.28%] [G loss: 0.905148]\n",
      "epoch:41 step:32461[D loss: 0.409404, acc: 58.59%, op_acc: 39.06%] [G loss: 0.936418]\n",
      "epoch:41 step:32462[D loss: 0.404711, acc: 64.06%, op_acc: 45.31%] [G loss: 0.924895]\n",
      "epoch:41 step:32463[D loss: 0.416984, acc: 63.28%, op_acc: 39.84%] [G loss: 0.880072]\n",
      "epoch:41 step:32464[D loss: 0.403604, acc: 62.50%, op_acc: 39.84%] [G loss: 0.880087]\n",
      "epoch:41 step:32465[D loss: 0.399928, acc: 64.06%, op_acc: 42.97%] [G loss: 0.918569]\n",
      "epoch:41 step:32466[D loss: 0.435939, acc: 63.28%, op_acc: 35.16%] [G loss: 1.008945]\n",
      "epoch:41 step:32467[D loss: 0.412502, acc: 62.50%, op_acc: 45.31%] [G loss: 0.970222]\n",
      "epoch:41 step:32468[D loss: 0.423610, acc: 60.94%, op_acc: 39.84%] [G loss: 0.945409]\n",
      "epoch:41 step:32469[D loss: 0.407184, acc: 62.50%, op_acc: 44.53%] [G loss: 0.960944]\n",
      "epoch:41 step:32470[D loss: 0.399237, acc: 65.62%, op_acc: 42.97%] [G loss: 0.846801]\n",
      "epoch:41 step:32471[D loss: 0.432939, acc: 58.59%, op_acc: 33.59%] [G loss: 0.864730]\n",
      "epoch:41 step:32472[D loss: 0.401161, acc: 69.53%, op_acc: 46.09%] [G loss: 0.987195]\n",
      "epoch:41 step:32473[D loss: 0.443111, acc: 46.09%, op_acc: 41.41%] [G loss: 0.872853]\n",
      "epoch:41 step:32474[D loss: 0.394477, acc: 62.50%, op_acc: 42.19%] [G loss: 0.872062]\n",
      "epoch:41 step:32475[D loss: 0.383817, acc: 67.19%, op_acc: 39.84%] [G loss: 0.827997]\n",
      "epoch:41 step:32476[D loss: 0.392309, acc: 74.22%, op_acc: 42.19%] [G loss: 0.845602]\n",
      "epoch:41 step:32477[D loss: 0.407871, acc: 65.62%, op_acc: 42.19%] [G loss: 0.822179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32478[D loss: 0.391448, acc: 61.72%, op_acc: 41.41%] [G loss: 0.811956]\n",
      "epoch:41 step:32479[D loss: 0.380428, acc: 69.53%, op_acc: 53.12%] [G loss: 0.826609]\n",
      "epoch:41 step:32480[D loss: 0.397087, acc: 58.59%, op_acc: 49.22%] [G loss: 0.821277]\n",
      "epoch:41 step:32481[D loss: 0.408173, acc: 60.94%, op_acc: 44.53%] [G loss: 0.964323]\n",
      "epoch:41 step:32482[D loss: 0.433951, acc: 53.91%, op_acc: 43.75%] [G loss: 0.909089]\n",
      "epoch:41 step:32483[D loss: 0.401965, acc: 63.28%, op_acc: 39.06%] [G loss: 1.001976]\n",
      "epoch:41 step:32484[D loss: 0.430179, acc: 56.25%, op_acc: 39.06%] [G loss: 0.946868]\n",
      "epoch:41 step:32485[D loss: 0.414646, acc: 66.41%, op_acc: 42.19%] [G loss: 0.861707]\n",
      "epoch:41 step:32486[D loss: 0.443834, acc: 54.69%, op_acc: 38.28%] [G loss: 0.850781]\n",
      "epoch:41 step:32487[D loss: 0.387853, acc: 65.62%, op_acc: 49.22%] [G loss: 1.048337]\n",
      "epoch:41 step:32488[D loss: 0.416581, acc: 51.56%, op_acc: 45.31%] [G loss: 0.884191]\n",
      "epoch:41 step:32489[D loss: 0.394008, acc: 67.97%, op_acc: 42.19%] [G loss: 0.859997]\n",
      "epoch:41 step:32490[D loss: 0.375949, acc: 64.06%, op_acc: 45.31%] [G loss: 0.817842]\n",
      "epoch:41 step:32491[D loss: 0.421259, acc: 63.28%, op_acc: 39.06%] [G loss: 0.783221]\n",
      "epoch:41 step:32492[D loss: 0.388130, acc: 66.41%, op_acc: 37.50%] [G loss: 0.887290]\n",
      "epoch:41 step:32493[D loss: 0.437750, acc: 53.12%, op_acc: 40.62%] [G loss: 0.828455]\n",
      "epoch:41 step:32494[D loss: 0.399218, acc: 63.28%, op_acc: 41.41%] [G loss: 0.824149]\n",
      "epoch:41 step:32495[D loss: 0.430526, acc: 60.16%, op_acc: 36.72%] [G loss: 0.876827]\n",
      "epoch:41 step:32496[D loss: 0.410969, acc: 58.59%, op_acc: 46.09%] [G loss: 0.894678]\n",
      "epoch:41 step:32497[D loss: 0.411131, acc: 63.28%, op_acc: 43.75%] [G loss: 0.915119]\n",
      "epoch:41 step:32498[D loss: 0.403578, acc: 64.84%, op_acc: 44.53%] [G loss: 0.821321]\n",
      "epoch:41 step:32499[D loss: 0.416540, acc: 53.12%, op_acc: 42.97%] [G loss: 0.904573]\n",
      "epoch:41 step:32500[D loss: 0.419351, acc: 57.81%, op_acc: 43.75%] [G loss: 0.878764]\n",
      "##############\n",
      "[0.84805886 0.85069327 0.81838651 0.79494036 0.79459054 0.83656465\n",
      " 0.88700523 0.83818543 0.80284322 0.83485218]\n",
      "##########\n",
      "epoch:41 step:32501[D loss: 0.468428, acc: 53.91%, op_acc: 37.50%] [G loss: 0.869356]\n",
      "epoch:41 step:32502[D loss: 0.456053, acc: 54.69%, op_acc: 40.62%] [G loss: 0.881525]\n",
      "epoch:41 step:32503[D loss: 0.446250, acc: 53.12%, op_acc: 39.84%] [G loss: 0.855070]\n",
      "epoch:41 step:32504[D loss: 0.424917, acc: 61.72%, op_acc: 36.72%] [G loss: 0.933121]\n",
      "epoch:41 step:32505[D loss: 0.381507, acc: 67.97%, op_acc: 46.88%] [G loss: 0.909637]\n",
      "epoch:41 step:32506[D loss: 0.425702, acc: 63.28%, op_acc: 42.19%] [G loss: 0.843984]\n",
      "epoch:41 step:32507[D loss: 0.400668, acc: 59.38%, op_acc: 40.62%] [G loss: 0.899778]\n",
      "epoch:41 step:32508[D loss: 0.403123, acc: 64.84%, op_acc: 42.97%] [G loss: 0.965483]\n",
      "epoch:41 step:32509[D loss: 0.407022, acc: 64.06%, op_acc: 40.62%] [G loss: 0.872108]\n",
      "epoch:41 step:32510[D loss: 0.402847, acc: 61.72%, op_acc: 44.53%] [G loss: 1.011123]\n",
      "epoch:41 step:32511[D loss: 0.385567, acc: 70.31%, op_acc: 42.97%] [G loss: 0.859532]\n",
      "epoch:41 step:32512[D loss: 0.431277, acc: 60.16%, op_acc: 41.41%] [G loss: 0.804716]\n",
      "epoch:41 step:32513[D loss: 0.393902, acc: 59.38%, op_acc: 42.19%] [G loss: 0.918179]\n",
      "epoch:41 step:32514[D loss: 0.404953, acc: 64.84%, op_acc: 37.50%] [G loss: 0.917473]\n",
      "epoch:41 step:32515[D loss: 0.419064, acc: 62.50%, op_acc: 36.72%] [G loss: 0.888971]\n",
      "epoch:41 step:32516[D loss: 0.422405, acc: 58.59%, op_acc: 36.72%] [G loss: 0.844924]\n",
      "epoch:41 step:32517[D loss: 0.401018, acc: 60.94%, op_acc: 43.75%] [G loss: 0.993846]\n",
      "epoch:41 step:32518[D loss: 0.386521, acc: 64.06%, op_acc: 42.97%] [G loss: 0.931319]\n",
      "epoch:41 step:32519[D loss: 0.427036, acc: 60.16%, op_acc: 34.38%] [G loss: 0.967702]\n",
      "epoch:41 step:32520[D loss: 0.392046, acc: 62.50%, op_acc: 45.31%] [G loss: 0.843615]\n",
      "epoch:41 step:32521[D loss: 0.378081, acc: 67.19%, op_acc: 40.62%] [G loss: 0.854953]\n",
      "epoch:41 step:32522[D loss: 0.399532, acc: 65.62%, op_acc: 41.41%] [G loss: 0.969665]\n",
      "epoch:41 step:32523[D loss: 0.433402, acc: 53.91%, op_acc: 42.97%] [G loss: 0.778076]\n",
      "epoch:41 step:32524[D loss: 0.389148, acc: 60.94%, op_acc: 49.22%] [G loss: 0.824836]\n",
      "epoch:41 step:32525[D loss: 0.417389, acc: 60.16%, op_acc: 38.28%] [G loss: 0.913847]\n",
      "epoch:41 step:32526[D loss: 0.404241, acc: 63.28%, op_acc: 35.94%] [G loss: 0.825761]\n",
      "epoch:41 step:32527[D loss: 0.426866, acc: 58.59%, op_acc: 39.84%] [G loss: 0.924640]\n",
      "epoch:41 step:32528[D loss: 0.389187, acc: 66.41%, op_acc: 44.53%] [G loss: 0.820719]\n",
      "epoch:41 step:32529[D loss: 0.414544, acc: 59.38%, op_acc: 39.06%] [G loss: 0.862443]\n",
      "epoch:41 step:32530[D loss: 0.444878, acc: 53.12%, op_acc: 42.97%] [G loss: 1.020216]\n",
      "epoch:41 step:32531[D loss: 0.405187, acc: 64.06%, op_acc: 40.62%] [G loss: 0.880290]\n",
      "epoch:41 step:32532[D loss: 0.436760, acc: 53.12%, op_acc: 43.75%] [G loss: 0.907004]\n",
      "epoch:41 step:32533[D loss: 0.436393, acc: 52.34%, op_acc: 39.84%] [G loss: 0.914470]\n",
      "epoch:41 step:32534[D loss: 0.448377, acc: 55.47%, op_acc: 35.94%] [G loss: 0.934710]\n",
      "epoch:41 step:32535[D loss: 0.442228, acc: 58.59%, op_acc: 43.75%] [G loss: 0.871974]\n",
      "epoch:41 step:32536[D loss: 0.402460, acc: 62.50%, op_acc: 39.84%] [G loss: 0.896587]\n",
      "epoch:41 step:32537[D loss: 0.433839, acc: 62.50%, op_acc: 39.06%] [G loss: 0.847743]\n",
      "epoch:41 step:32538[D loss: 0.428008, acc: 60.94%, op_acc: 40.62%] [G loss: 0.940580]\n",
      "epoch:41 step:32539[D loss: 0.412966, acc: 54.69%, op_acc: 41.41%] [G loss: 0.878397]\n",
      "epoch:41 step:32540[D loss: 0.421727, acc: 59.38%, op_acc: 41.41%] [G loss: 0.988854]\n",
      "epoch:41 step:32541[D loss: 0.460516, acc: 41.41%, op_acc: 38.28%] [G loss: 0.861601]\n",
      "epoch:41 step:32542[D loss: 0.405870, acc: 67.97%, op_acc: 40.62%] [G loss: 1.013340]\n",
      "epoch:41 step:32543[D loss: 0.454675, acc: 46.88%, op_acc: 43.75%] [G loss: 0.877050]\n",
      "epoch:41 step:32544[D loss: 0.414800, acc: 62.50%, op_acc: 44.53%] [G loss: 0.910648]\n",
      "epoch:41 step:32545[D loss: 0.442450, acc: 56.25%, op_acc: 35.94%] [G loss: 0.976097]\n",
      "epoch:41 step:32546[D loss: 0.387441, acc: 66.41%, op_acc: 38.28%] [G loss: 0.889830]\n",
      "epoch:41 step:32547[D loss: 0.435744, acc: 59.38%, op_acc: 34.38%] [G loss: 0.898196]\n",
      "epoch:41 step:32548[D loss: 0.447128, acc: 46.09%, op_acc: 38.28%] [G loss: 0.901279]\n",
      "epoch:41 step:32549[D loss: 0.409756, acc: 62.50%, op_acc: 42.97%] [G loss: 0.977062]\n",
      "epoch:41 step:32550[D loss: 0.410150, acc: 59.38%, op_acc: 45.31%] [G loss: 0.914647]\n",
      "##############\n",
      "[0.87142062 0.86935872 0.80186236 0.78437199 0.80068886 0.80974352\n",
      " 0.88015149 0.83188681 0.78968542 0.81019083]\n",
      "##########\n",
      "epoch:41 step:32551[D loss: 0.410142, acc: 61.72%, op_acc: 36.72%] [G loss: 0.965078]\n",
      "epoch:41 step:32552[D loss: 0.422610, acc: 61.72%, op_acc: 44.53%] [G loss: 0.930510]\n",
      "epoch:41 step:32553[D loss: 0.410371, acc: 61.72%, op_acc: 40.62%] [G loss: 0.951116]\n",
      "epoch:41 step:32554[D loss: 0.413953, acc: 54.69%, op_acc: 41.41%] [G loss: 0.930157]\n",
      "epoch:41 step:32555[D loss: 0.404825, acc: 59.38%, op_acc: 45.31%] [G loss: 0.942866]\n",
      "epoch:41 step:32556[D loss: 0.410242, acc: 60.16%, op_acc: 41.41%] [G loss: 0.829252]\n",
      "epoch:41 step:32557[D loss: 0.385238, acc: 57.03%, op_acc: 48.44%] [G loss: 0.812983]\n",
      "epoch:41 step:32558[D loss: 0.428348, acc: 55.47%, op_acc: 41.41%] [G loss: 0.934907]\n",
      "epoch:41 step:32559[D loss: 0.427089, acc: 59.38%, op_acc: 43.75%] [G loss: 0.962655]\n",
      "epoch:41 step:32560[D loss: 0.406506, acc: 67.97%, op_acc: 39.84%] [G loss: 0.837434]\n",
      "epoch:41 step:32561[D loss: 0.409418, acc: 58.59%, op_acc: 41.41%] [G loss: 0.912758]\n",
      "epoch:41 step:32562[D loss: 0.419588, acc: 59.38%, op_acc: 42.97%] [G loss: 1.001163]\n",
      "epoch:41 step:32563[D loss: 0.411388, acc: 65.62%, op_acc: 39.84%] [G loss: 0.806542]\n",
      "epoch:41 step:32564[D loss: 0.453146, acc: 56.25%, op_acc: 42.19%] [G loss: 0.809076]\n",
      "epoch:41 step:32565[D loss: 0.412323, acc: 58.59%, op_acc: 47.66%] [G loss: 0.945216]\n",
      "epoch:41 step:32566[D loss: 0.389502, acc: 67.19%, op_acc: 40.62%] [G loss: 0.964527]\n",
      "epoch:41 step:32567[D loss: 0.414735, acc: 60.16%, op_acc: 41.41%] [G loss: 0.915581]\n",
      "epoch:41 step:32568[D loss: 0.445037, acc: 54.69%, op_acc: 33.59%] [G loss: 0.880153]\n",
      "epoch:41 step:32569[D loss: 0.456200, acc: 53.91%, op_acc: 35.94%] [G loss: 0.862684]\n",
      "epoch:41 step:32570[D loss: 0.391688, acc: 72.66%, op_acc: 40.62%] [G loss: 0.991516]\n",
      "epoch:41 step:32571[D loss: 0.404427, acc: 62.50%, op_acc: 45.31%] [G loss: 0.824927]\n",
      "epoch:41 step:32572[D loss: 0.415067, acc: 61.72%, op_acc: 40.62%] [G loss: 0.819967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32573[D loss: 0.429857, acc: 57.81%, op_acc: 36.72%] [G loss: 0.863691]\n",
      "epoch:41 step:32574[D loss: 0.390552, acc: 63.28%, op_acc: 40.62%] [G loss: 0.901493]\n",
      "epoch:41 step:32575[D loss: 0.407239, acc: 61.72%, op_acc: 42.19%] [G loss: 0.895312]\n",
      "epoch:41 step:32576[D loss: 0.417314, acc: 52.34%, op_acc: 44.53%] [G loss: 0.916416]\n",
      "epoch:41 step:32577[D loss: 0.389655, acc: 63.28%, op_acc: 46.09%] [G loss: 0.841605]\n",
      "epoch:41 step:32578[D loss: 0.414387, acc: 60.16%, op_acc: 42.97%] [G loss: 0.786258]\n",
      "epoch:41 step:32579[D loss: 0.411627, acc: 58.59%, op_acc: 43.75%] [G loss: 0.743439]\n",
      "epoch:41 step:32580[D loss: 0.364237, acc: 71.09%, op_acc: 47.66%] [G loss: 0.881407]\n",
      "epoch:41 step:32581[D loss: 0.407564, acc: 60.16%, op_acc: 43.75%] [G loss: 0.893318]\n",
      "epoch:41 step:32582[D loss: 0.394367, acc: 64.06%, op_acc: 46.88%] [G loss: 0.908668]\n",
      "epoch:41 step:32583[D loss: 0.414517, acc: 64.06%, op_acc: 40.62%] [G loss: 0.893743]\n",
      "epoch:41 step:32584[D loss: 0.400418, acc: 61.72%, op_acc: 42.97%] [G loss: 0.942372]\n",
      "epoch:41 step:32585[D loss: 0.380690, acc: 66.41%, op_acc: 46.88%] [G loss: 0.960599]\n",
      "epoch:41 step:32586[D loss: 0.399716, acc: 66.41%, op_acc: 42.19%] [G loss: 0.974929]\n",
      "epoch:41 step:32587[D loss: 0.432445, acc: 55.47%, op_acc: 39.06%] [G loss: 0.886332]\n",
      "epoch:41 step:32588[D loss: 0.388762, acc: 67.19%, op_acc: 42.19%] [G loss: 0.857953]\n",
      "epoch:41 step:32589[D loss: 0.404385, acc: 59.38%, op_acc: 41.41%] [G loss: 0.845738]\n",
      "epoch:41 step:32590[D loss: 0.388973, acc: 69.53%, op_acc: 46.09%] [G loss: 0.965965]\n",
      "epoch:41 step:32591[D loss: 0.411204, acc: 62.50%, op_acc: 42.19%] [G loss: 0.880562]\n",
      "epoch:41 step:32592[D loss: 0.392637, acc: 66.41%, op_acc: 52.34%] [G loss: 0.872745]\n",
      "epoch:41 step:32593[D loss: 0.439369, acc: 54.69%, op_acc: 39.06%] [G loss: 0.832132]\n",
      "epoch:41 step:32594[D loss: 0.425782, acc: 60.94%, op_acc: 44.53%] [G loss: 0.857851]\n",
      "epoch:41 step:32595[D loss: 0.403834, acc: 66.41%, op_acc: 39.84%] [G loss: 0.869926]\n",
      "epoch:41 step:32596[D loss: 0.444513, acc: 55.47%, op_acc: 38.28%] [G loss: 0.956596]\n",
      "epoch:41 step:32597[D loss: 0.428958, acc: 55.47%, op_acc: 41.41%] [G loss: 0.899683]\n",
      "epoch:41 step:32598[D loss: 0.455994, acc: 53.91%, op_acc: 39.84%] [G loss: 0.760815]\n",
      "epoch:41 step:32599[D loss: 0.423248, acc: 63.28%, op_acc: 37.50%] [G loss: 0.940274]\n",
      "epoch:41 step:32600[D loss: 0.418907, acc: 60.16%, op_acc: 42.97%] [G loss: 0.911610]\n",
      "##############\n",
      "[0.82889557 0.87868332 0.82428886 0.80879882 0.80397465 0.82307089\n",
      " 0.87869744 0.82934088 0.79458664 0.82410315]\n",
      "##########\n",
      "epoch:41 step:32601[D loss: 0.436582, acc: 56.25%, op_acc: 38.28%] [G loss: 0.861615]\n",
      "epoch:41 step:32602[D loss: 0.449538, acc: 50.78%, op_acc: 38.28%] [G loss: 0.843441]\n",
      "epoch:41 step:32603[D loss: 0.413719, acc: 61.72%, op_acc: 40.62%] [G loss: 0.854634]\n",
      "epoch:41 step:32604[D loss: 0.382814, acc: 69.53%, op_acc: 43.75%] [G loss: 0.935242]\n",
      "epoch:41 step:32605[D loss: 0.430813, acc: 64.84%, op_acc: 32.03%] [G loss: 0.840599]\n",
      "epoch:41 step:32606[D loss: 0.396474, acc: 65.62%, op_acc: 42.97%] [G loss: 0.813700]\n",
      "epoch:41 step:32607[D loss: 0.412776, acc: 63.28%, op_acc: 40.62%] [G loss: 0.968228]\n",
      "epoch:41 step:32608[D loss: 0.418486, acc: 57.03%, op_acc: 39.84%] [G loss: 0.862748]\n",
      "epoch:41 step:32609[D loss: 0.389533, acc: 67.19%, op_acc: 49.22%] [G loss: 0.901822]\n",
      "epoch:41 step:32610[D loss: 0.425286, acc: 59.38%, op_acc: 39.06%] [G loss: 0.919892]\n",
      "epoch:41 step:32611[D loss: 0.430116, acc: 53.12%, op_acc: 39.84%] [G loss: 0.862418]\n",
      "epoch:41 step:32612[D loss: 0.420503, acc: 59.38%, op_acc: 45.31%] [G loss: 0.906909]\n",
      "epoch:41 step:32613[D loss: 0.419848, acc: 56.25%, op_acc: 41.41%] [G loss: 0.839378]\n",
      "epoch:41 step:32614[D loss: 0.434804, acc: 56.25%, op_acc: 38.28%] [G loss: 0.835266]\n",
      "epoch:41 step:32615[D loss: 0.440261, acc: 50.78%, op_acc: 47.66%] [G loss: 0.874157]\n",
      "epoch:41 step:32616[D loss: 0.417275, acc: 64.06%, op_acc: 42.97%] [G loss: 0.969520]\n",
      "epoch:41 step:32617[D loss: 0.400163, acc: 65.62%, op_acc: 42.97%] [G loss: 0.871755]\n",
      "epoch:41 step:32618[D loss: 0.401096, acc: 63.28%, op_acc: 37.50%] [G loss: 0.863938]\n",
      "epoch:41 step:32619[D loss: 0.406015, acc: 64.84%, op_acc: 42.19%] [G loss: 0.876416]\n",
      "epoch:41 step:32620[D loss: 0.415917, acc: 61.72%, op_acc: 38.28%] [G loss: 0.902130]\n",
      "epoch:41 step:32621[D loss: 0.393772, acc: 64.06%, op_acc: 43.75%] [G loss: 0.908307]\n",
      "epoch:41 step:32622[D loss: 0.430284, acc: 58.59%, op_acc: 37.50%] [G loss: 0.907452]\n",
      "epoch:41 step:32623[D loss: 0.411316, acc: 67.97%, op_acc: 44.53%] [G loss: 0.855256]\n",
      "epoch:41 step:32624[D loss: 0.373166, acc: 66.41%, op_acc: 47.66%] [G loss: 0.889233]\n",
      "epoch:41 step:32625[D loss: 0.451706, acc: 53.12%, op_acc: 38.28%] [G loss: 0.856047]\n",
      "epoch:41 step:32626[D loss: 0.409723, acc: 63.28%, op_acc: 41.41%] [G loss: 0.900616]\n",
      "epoch:41 step:32627[D loss: 0.388258, acc: 61.72%, op_acc: 42.97%] [G loss: 1.062417]\n",
      "epoch:41 step:32628[D loss: 0.402910, acc: 61.72%, op_acc: 39.84%] [G loss: 0.887993]\n",
      "epoch:41 step:32629[D loss: 0.394334, acc: 62.50%, op_acc: 43.75%] [G loss: 0.945657]\n",
      "epoch:41 step:32630[D loss: 0.419332, acc: 57.81%, op_acc: 43.75%] [G loss: 0.885143]\n",
      "epoch:41 step:32631[D loss: 0.387309, acc: 63.28%, op_acc: 49.22%] [G loss: 0.938320]\n",
      "epoch:41 step:32632[D loss: 0.395242, acc: 64.06%, op_acc: 42.97%] [G loss: 0.914274]\n",
      "epoch:41 step:32633[D loss: 0.402689, acc: 62.50%, op_acc: 42.97%] [G loss: 0.912668]\n",
      "epoch:41 step:32634[D loss: 0.396939, acc: 65.62%, op_acc: 46.88%] [G loss: 0.951079]\n",
      "epoch:41 step:32635[D loss: 0.378242, acc: 62.50%, op_acc: 47.66%] [G loss: 0.909515]\n",
      "epoch:41 step:32636[D loss: 0.388453, acc: 64.06%, op_acc: 40.62%] [G loss: 0.865408]\n",
      "epoch:41 step:32637[D loss: 0.424333, acc: 64.06%, op_acc: 41.41%] [G loss: 0.926995]\n",
      "epoch:41 step:32638[D loss: 0.416500, acc: 56.25%, op_acc: 42.97%] [G loss: 0.975589]\n",
      "epoch:41 step:32639[D loss: 0.368567, acc: 68.75%, op_acc: 45.31%] [G loss: 1.034696]\n",
      "epoch:41 step:32640[D loss: 0.406820, acc: 68.75%, op_acc: 35.16%] [G loss: 1.099829]\n",
      "epoch:41 step:32641[D loss: 0.398071, acc: 67.97%, op_acc: 38.28%] [G loss: 1.060719]\n",
      "epoch:41 step:32642[D loss: 0.390773, acc: 69.53%, op_acc: 42.97%] [G loss: 0.907058]\n",
      "epoch:41 step:32643[D loss: 0.424518, acc: 63.28%, op_acc: 35.94%] [G loss: 0.988530]\n",
      "epoch:41 step:32644[D loss: 0.377503, acc: 64.84%, op_acc: 47.66%] [G loss: 0.918202]\n",
      "epoch:41 step:32645[D loss: 0.363259, acc: 64.84%, op_acc: 45.31%] [G loss: 0.757829]\n",
      "epoch:41 step:32646[D loss: 0.396698, acc: 63.28%, op_acc: 43.75%] [G loss: 0.805815]\n",
      "epoch:41 step:32647[D loss: 0.376656, acc: 61.72%, op_acc: 45.31%] [G loss: 0.933709]\n",
      "epoch:41 step:32648[D loss: 0.452158, acc: 47.66%, op_acc: 36.72%] [G loss: 0.794677]\n",
      "epoch:41 step:32649[D loss: 0.399834, acc: 62.50%, op_acc: 42.19%] [G loss: 0.842033]\n",
      "epoch:41 step:32650[D loss: 0.405657, acc: 66.41%, op_acc: 40.62%] [G loss: 1.003040]\n",
      "##############\n",
      "[0.86235376 0.85766978 0.81952991 0.79929274 0.79446216 0.82565188\n",
      " 0.86583097 0.84631327 0.79826122 0.83533121]\n",
      "##########\n",
      "epoch:41 step:32651[D loss: 0.389548, acc: 65.62%, op_acc: 44.53%] [G loss: 1.023584]\n",
      "epoch:41 step:32652[D loss: 0.443726, acc: 57.03%, op_acc: 41.41%] [G loss: 0.845653]\n",
      "epoch:41 step:32653[D loss: 0.406073, acc: 65.62%, op_acc: 46.09%] [G loss: 0.909991]\n",
      "epoch:41 step:32654[D loss: 0.438194, acc: 53.91%, op_acc: 37.50%] [G loss: 0.968448]\n",
      "epoch:41 step:32655[D loss: 0.397128, acc: 64.84%, op_acc: 45.31%] [G loss: 0.985224]\n",
      "epoch:41 step:32656[D loss: 0.439072, acc: 55.47%, op_acc: 36.72%] [G loss: 0.799638]\n",
      "epoch:41 step:32657[D loss: 0.386458, acc: 66.41%, op_acc: 39.84%] [G loss: 0.983701]\n",
      "epoch:41 step:32658[D loss: 0.389727, acc: 66.41%, op_acc: 41.41%] [G loss: 0.955002]\n",
      "epoch:41 step:32659[D loss: 0.399371, acc: 62.50%, op_acc: 42.19%] [G loss: 0.929343]\n",
      "epoch:41 step:32660[D loss: 0.451636, acc: 53.12%, op_acc: 33.59%] [G loss: 0.965603]\n",
      "epoch:41 step:32661[D loss: 0.444651, acc: 65.62%, op_acc: 43.75%] [G loss: 0.957214]\n",
      "epoch:41 step:32662[D loss: 0.420889, acc: 58.59%, op_acc: 38.28%] [G loss: 0.955942]\n",
      "epoch:41 step:32663[D loss: 0.432044, acc: 57.81%, op_acc: 43.75%] [G loss: 0.934595]\n",
      "epoch:41 step:32664[D loss: 0.399452, acc: 63.28%, op_acc: 42.19%] [G loss: 0.914364]\n",
      "epoch:41 step:32665[D loss: 0.396187, acc: 54.69%, op_acc: 45.31%] [G loss: 0.937066]\n",
      "epoch:41 step:32666[D loss: 0.398723, acc: 67.19%, op_acc: 39.84%] [G loss: 0.945318]\n",
      "epoch:41 step:32667[D loss: 0.431121, acc: 59.38%, op_acc: 40.62%] [G loss: 0.957626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32668[D loss: 0.368626, acc: 64.84%, op_acc: 54.69%] [G loss: 0.806878]\n",
      "epoch:41 step:32669[D loss: 0.405648, acc: 64.84%, op_acc: 39.84%] [G loss: 0.872128]\n",
      "epoch:41 step:32670[D loss: 0.408114, acc: 62.50%, op_acc: 42.97%] [G loss: 0.963690]\n",
      "epoch:41 step:32671[D loss: 0.456478, acc: 51.56%, op_acc: 37.50%] [G loss: 0.931969]\n",
      "epoch:41 step:32672[D loss: 0.402429, acc: 63.28%, op_acc: 42.19%] [G loss: 0.883605]\n",
      "epoch:41 step:32673[D loss: 0.390417, acc: 63.28%, op_acc: 48.44%] [G loss: 0.906359]\n",
      "epoch:41 step:32674[D loss: 0.380826, acc: 62.50%, op_acc: 47.66%] [G loss: 0.894307]\n",
      "epoch:41 step:32675[D loss: 0.399203, acc: 64.84%, op_acc: 44.53%] [G loss: 0.861920]\n",
      "epoch:41 step:32676[D loss: 0.424188, acc: 59.38%, op_acc: 46.09%] [G loss: 0.989513]\n",
      "epoch:41 step:32677[D loss: 0.410303, acc: 67.19%, op_acc: 37.50%] [G loss: 0.974408]\n",
      "epoch:41 step:32678[D loss: 0.421229, acc: 57.81%, op_acc: 43.75%] [G loss: 0.830376]\n",
      "epoch:41 step:32679[D loss: 0.393792, acc: 66.41%, op_acc: 39.84%] [G loss: 0.797835]\n",
      "epoch:41 step:32680[D loss: 0.403261, acc: 62.50%, op_acc: 48.44%] [G loss: 0.926191]\n",
      "epoch:41 step:32681[D loss: 0.401496, acc: 62.50%, op_acc: 39.84%] [G loss: 0.940032]\n",
      "epoch:41 step:32682[D loss: 0.411959, acc: 57.81%, op_acc: 46.09%] [G loss: 0.936162]\n",
      "epoch:41 step:32683[D loss: 0.401715, acc: 57.81%, op_acc: 47.66%] [G loss: 0.847780]\n",
      "epoch:41 step:32684[D loss: 0.428456, acc: 55.47%, op_acc: 42.19%] [G loss: 0.901489]\n",
      "epoch:41 step:32685[D loss: 0.391732, acc: 62.50%, op_acc: 42.19%] [G loss: 0.926787]\n",
      "epoch:41 step:32686[D loss: 0.433786, acc: 60.94%, op_acc: 35.16%] [G loss: 0.972528]\n",
      "epoch:41 step:32687[D loss: 0.381657, acc: 71.09%, op_acc: 46.09%] [G loss: 0.956488]\n",
      "epoch:41 step:32688[D loss: 0.396603, acc: 61.72%, op_acc: 43.75%] [G loss: 0.917241]\n",
      "epoch:41 step:32689[D loss: 0.398450, acc: 65.62%, op_acc: 42.19%] [G loss: 0.925681]\n",
      "epoch:41 step:32690[D loss: 0.412548, acc: 60.94%, op_acc: 38.28%] [G loss: 0.914301]\n",
      "epoch:41 step:32691[D loss: 0.396228, acc: 60.94%, op_acc: 43.75%] [G loss: 0.875659]\n",
      "epoch:41 step:32692[D loss: 0.392742, acc: 67.97%, op_acc: 44.53%] [G loss: 0.929638]\n",
      "epoch:41 step:32693[D loss: 0.431083, acc: 60.94%, op_acc: 36.72%] [G loss: 0.985046]\n",
      "epoch:41 step:32694[D loss: 0.417461, acc: 61.72%, op_acc: 39.06%] [G loss: 0.842147]\n",
      "epoch:41 step:32695[D loss: 0.402394, acc: 57.81%, op_acc: 43.75%] [G loss: 0.834668]\n",
      "epoch:41 step:32696[D loss: 0.400635, acc: 60.16%, op_acc: 41.41%] [G loss: 0.839793]\n",
      "epoch:41 step:32697[D loss: 0.438391, acc: 58.59%, op_acc: 39.84%] [G loss: 0.874136]\n",
      "epoch:41 step:32698[D loss: 0.436763, acc: 56.25%, op_acc: 39.84%] [G loss: 0.835219]\n",
      "epoch:41 step:32699[D loss: 0.401021, acc: 67.97%, op_acc: 41.41%] [G loss: 0.924241]\n",
      "epoch:41 step:32700[D loss: 0.403402, acc: 63.28%, op_acc: 39.84%] [G loss: 0.924264]\n",
      "##############\n",
      "[0.84540116 0.84643575 0.81245766 0.82361487 0.78782228 0.81255345\n",
      " 0.86503022 0.80316997 0.80116162 0.83642938]\n",
      "##########\n",
      "epoch:41 step:32701[D loss: 0.419475, acc: 61.72%, op_acc: 38.28%] [G loss: 0.973945]\n",
      "epoch:41 step:32702[D loss: 0.433244, acc: 57.03%, op_acc: 37.50%] [G loss: 0.897605]\n",
      "epoch:41 step:32703[D loss: 0.419075, acc: 57.03%, op_acc: 46.88%] [G loss: 0.926856]\n",
      "epoch:41 step:32704[D loss: 0.417531, acc: 57.03%, op_acc: 44.53%] [G loss: 0.959879]\n",
      "epoch:41 step:32705[D loss: 0.407145, acc: 60.94%, op_acc: 42.97%] [G loss: 0.858068]\n",
      "epoch:41 step:32706[D loss: 0.437898, acc: 59.38%, op_acc: 42.97%] [G loss: 0.833503]\n",
      "epoch:41 step:32707[D loss: 0.398212, acc: 67.19%, op_acc: 43.75%] [G loss: 0.976905]\n",
      "epoch:41 step:32708[D loss: 0.427779, acc: 57.81%, op_acc: 42.97%] [G loss: 0.950968]\n",
      "epoch:41 step:32709[D loss: 0.437025, acc: 49.22%, op_acc: 39.84%] [G loss: 0.911666]\n",
      "epoch:41 step:32710[D loss: 0.408823, acc: 55.47%, op_acc: 44.53%] [G loss: 1.036394]\n",
      "epoch:41 step:32711[D loss: 0.443129, acc: 59.38%, op_acc: 40.62%] [G loss: 0.917465]\n",
      "epoch:41 step:32712[D loss: 0.412849, acc: 67.97%, op_acc: 40.62%] [G loss: 0.829470]\n",
      "epoch:41 step:32713[D loss: 0.424291, acc: 58.59%, op_acc: 39.06%] [G loss: 0.846394]\n",
      "epoch:41 step:32714[D loss: 0.418466, acc: 60.16%, op_acc: 40.62%] [G loss: 0.956527]\n",
      "epoch:41 step:32715[D loss: 0.422812, acc: 60.94%, op_acc: 42.19%] [G loss: 0.887375]\n",
      "epoch:41 step:32716[D loss: 0.417025, acc: 60.94%, op_acc: 42.19%] [G loss: 0.815853]\n",
      "epoch:41 step:32717[D loss: 0.448603, acc: 60.16%, op_acc: 35.94%] [G loss: 0.827171]\n",
      "epoch:41 step:32718[D loss: 0.433720, acc: 57.81%, op_acc: 42.19%] [G loss: 0.871103]\n",
      "epoch:41 step:32719[D loss: 0.441466, acc: 53.12%, op_acc: 40.62%] [G loss: 0.879437]\n",
      "epoch:41 step:32720[D loss: 0.414112, acc: 58.59%, op_acc: 41.41%] [G loss: 0.839717]\n",
      "epoch:41 step:32721[D loss: 0.421123, acc: 60.94%, op_acc: 42.19%] [G loss: 0.934588]\n",
      "epoch:41 step:32722[D loss: 0.456705, acc: 53.12%, op_acc: 37.50%] [G loss: 0.961807]\n",
      "epoch:41 step:32723[D loss: 0.427995, acc: 58.59%, op_acc: 41.41%] [G loss: 0.755738]\n",
      "epoch:41 step:32724[D loss: 0.444580, acc: 50.00%, op_acc: 41.41%] [G loss: 0.864269]\n",
      "epoch:41 step:32725[D loss: 0.373651, acc: 65.62%, op_acc: 45.31%] [G loss: 0.899153]\n",
      "epoch:41 step:32726[D loss: 0.418424, acc: 56.25%, op_acc: 45.31%] [G loss: 0.761451]\n",
      "epoch:41 step:32727[D loss: 0.396971, acc: 60.16%, op_acc: 45.31%] [G loss: 0.968280]\n",
      "epoch:41 step:32728[D loss: 0.463413, acc: 48.44%, op_acc: 39.84%] [G loss: 0.887530]\n",
      "epoch:41 step:32729[D loss: 0.412118, acc: 60.94%, op_acc: 43.75%] [G loss: 0.834045]\n",
      "epoch:41 step:32730[D loss: 0.423682, acc: 58.59%, op_acc: 37.50%] [G loss: 0.889001]\n",
      "epoch:41 step:32731[D loss: 0.392113, acc: 61.72%, op_acc: 44.53%] [G loss: 0.826709]\n",
      "epoch:41 step:32732[D loss: 0.410371, acc: 63.28%, op_acc: 37.50%] [G loss: 0.970622]\n",
      "epoch:41 step:32733[D loss: 0.392702, acc: 61.72%, op_acc: 43.75%] [G loss: 0.923116]\n",
      "epoch:41 step:32734[D loss: 0.400917, acc: 57.81%, op_acc: 43.75%] [G loss: 0.842811]\n",
      "epoch:41 step:32735[D loss: 0.427798, acc: 55.47%, op_acc: 35.94%] [G loss: 0.951911]\n",
      "epoch:41 step:32736[D loss: 0.416773, acc: 63.28%, op_acc: 39.84%] [G loss: 0.781129]\n",
      "epoch:41 step:32737[D loss: 0.401246, acc: 56.25%, op_acc: 41.41%] [G loss: 0.932957]\n",
      "epoch:41 step:32738[D loss: 0.393324, acc: 58.59%, op_acc: 43.75%] [G loss: 0.942936]\n",
      "epoch:41 step:32739[D loss: 0.418729, acc: 59.38%, op_acc: 34.38%] [G loss: 0.819563]\n",
      "epoch:41 step:32740[D loss: 0.429939, acc: 60.94%, op_acc: 45.31%] [G loss: 0.882911]\n",
      "epoch:41 step:32741[D loss: 0.408502, acc: 68.75%, op_acc: 44.53%] [G loss: 0.878573]\n",
      "epoch:41 step:32742[D loss: 0.408046, acc: 59.38%, op_acc: 40.62%] [G loss: 1.001574]\n",
      "epoch:41 step:32743[D loss: 0.424086, acc: 55.47%, op_acc: 41.41%] [G loss: 0.904072]\n",
      "epoch:41 step:32744[D loss: 0.413457, acc: 60.94%, op_acc: 43.75%] [G loss: 0.844761]\n",
      "epoch:41 step:32745[D loss: 0.430871, acc: 63.28%, op_acc: 35.94%] [G loss: 1.030310]\n",
      "epoch:41 step:32746[D loss: 0.451478, acc: 51.56%, op_acc: 38.28%] [G loss: 0.925354]\n",
      "epoch:41 step:32747[D loss: 0.456721, acc: 53.12%, op_acc: 36.72%] [G loss: 0.918443]\n",
      "epoch:41 step:32748[D loss: 0.427159, acc: 59.38%, op_acc: 39.84%] [G loss: 0.902394]\n",
      "epoch:41 step:32749[D loss: 0.395786, acc: 65.62%, op_acc: 41.41%] [G loss: 0.888734]\n",
      "epoch:41 step:32750[D loss: 0.406229, acc: 63.28%, op_acc: 41.41%] [G loss: 0.748794]\n",
      "##############\n",
      "[0.86579335 0.83689579 0.81363735 0.80664127 0.7934655  0.81101359\n",
      " 0.89349102 0.82614959 0.83065243 0.83436861]\n",
      "##########\n",
      "epoch:41 step:32751[D loss: 0.387164, acc: 65.62%, op_acc: 45.31%] [G loss: 0.848859]\n",
      "epoch:41 step:32752[D loss: 0.401652, acc: 60.94%, op_acc: 42.19%] [G loss: 0.922934]\n",
      "epoch:41 step:32753[D loss: 0.391222, acc: 66.41%, op_acc: 39.84%] [G loss: 0.860780]\n",
      "epoch:41 step:32754[D loss: 0.406783, acc: 64.06%, op_acc: 40.62%] [G loss: 0.947513]\n",
      "epoch:41 step:32755[D loss: 0.412239, acc: 55.47%, op_acc: 37.50%] [G loss: 0.990023]\n",
      "epoch:41 step:32756[D loss: 0.410812, acc: 61.72%, op_acc: 42.97%] [G loss: 0.867202]\n",
      "epoch:41 step:32757[D loss: 0.432868, acc: 60.16%, op_acc: 37.50%] [G loss: 0.831130]\n",
      "epoch:41 step:32758[D loss: 0.388644, acc: 64.06%, op_acc: 42.19%] [G loss: 0.830855]\n",
      "epoch:41 step:32759[D loss: 0.388379, acc: 65.62%, op_acc: 42.19%] [G loss: 0.845574]\n",
      "epoch:41 step:32760[D loss: 0.453072, acc: 53.12%, op_acc: 38.28%] [G loss: 0.946012]\n",
      "epoch:41 step:32761[D loss: 0.405677, acc: 61.72%, op_acc: 46.09%] [G loss: 1.016984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32762[D loss: 0.404132, acc: 61.72%, op_acc: 39.84%] [G loss: 0.803720]\n",
      "epoch:41 step:32763[D loss: 0.410157, acc: 64.84%, op_acc: 41.41%] [G loss: 0.964898]\n",
      "epoch:41 step:32764[D loss: 0.406617, acc: 58.59%, op_acc: 48.44%] [G loss: 0.857565]\n",
      "epoch:41 step:32765[D loss: 0.387582, acc: 61.72%, op_acc: 47.66%] [G loss: 0.899548]\n",
      "epoch:41 step:32766[D loss: 0.406945, acc: 64.84%, op_acc: 50.78%] [G loss: 0.839580]\n",
      "epoch:41 step:32767[D loss: 0.420404, acc: 64.06%, op_acc: 48.44%] [G loss: 0.870540]\n",
      "epoch:41 step:32768[D loss: 0.426896, acc: 60.94%, op_acc: 39.06%] [G loss: 0.859143]\n",
      "epoch:41 step:32769[D loss: 0.425099, acc: 64.84%, op_acc: 39.84%] [G loss: 0.758285]\n",
      "epoch:41 step:32770[D loss: 0.423509, acc: 59.38%, op_acc: 42.97%] [G loss: 0.815913]\n",
      "epoch:41 step:32771[D loss: 0.436912, acc: 52.34%, op_acc: 44.53%] [G loss: 0.811266]\n",
      "epoch:41 step:32772[D loss: 0.437219, acc: 62.50%, op_acc: 42.19%] [G loss: 0.879166]\n",
      "epoch:41 step:32773[D loss: 0.421746, acc: 63.28%, op_acc: 41.41%] [G loss: 0.891503]\n",
      "epoch:41 step:32774[D loss: 0.433220, acc: 59.38%, op_acc: 43.75%] [G loss: 0.798984]\n",
      "epoch:41 step:32775[D loss: 0.410850, acc: 60.94%, op_acc: 36.72%] [G loss: 0.862478]\n",
      "epoch:41 step:32776[D loss: 0.390950, acc: 62.50%, op_acc: 43.75%] [G loss: 0.896872]\n",
      "epoch:41 step:32777[D loss: 0.379890, acc: 61.72%, op_acc: 49.22%] [G loss: 0.833986]\n",
      "epoch:41 step:32778[D loss: 0.400573, acc: 58.59%, op_acc: 47.66%] [G loss: 0.868167]\n",
      "epoch:41 step:32779[D loss: 0.427541, acc: 54.69%, op_acc: 44.53%] [G loss: 0.947758]\n",
      "epoch:41 step:32780[D loss: 0.386992, acc: 68.75%, op_acc: 42.19%] [G loss: 0.915809]\n",
      "epoch:41 step:32781[D loss: 0.410003, acc: 55.47%, op_acc: 46.09%] [G loss: 0.844449]\n",
      "epoch:41 step:32782[D loss: 0.385350, acc: 63.28%, op_acc: 42.97%] [G loss: 0.978291]\n",
      "epoch:41 step:32783[D loss: 0.414038, acc: 60.94%, op_acc: 43.75%] [G loss: 0.922862]\n",
      "epoch:41 step:32784[D loss: 0.415454, acc: 57.81%, op_acc: 42.97%] [G loss: 0.814906]\n",
      "epoch:41 step:32785[D loss: 0.412534, acc: 59.38%, op_acc: 43.75%] [G loss: 0.921189]\n",
      "epoch:41 step:32786[D loss: 0.384165, acc: 67.97%, op_acc: 50.00%] [G loss: 0.916144]\n",
      "epoch:41 step:32787[D loss: 0.412137, acc: 64.06%, op_acc: 44.53%] [G loss: 0.922174]\n",
      "epoch:41 step:32788[D loss: 0.382223, acc: 63.28%, op_acc: 45.31%] [G loss: 0.869705]\n",
      "epoch:41 step:32789[D loss: 0.382548, acc: 65.62%, op_acc: 42.97%] [G loss: 0.942953]\n",
      "epoch:41 step:32790[D loss: 0.408699, acc: 60.16%, op_acc: 46.09%] [G loss: 0.912561]\n",
      "epoch:41 step:32791[D loss: 0.416842, acc: 56.25%, op_acc: 42.97%] [G loss: 0.925380]\n",
      "epoch:41 step:32792[D loss: 0.439736, acc: 53.91%, op_acc: 37.50%] [G loss: 0.956286]\n",
      "epoch:41 step:32793[D loss: 0.443495, acc: 59.38%, op_acc: 35.16%] [G loss: 0.973811]\n",
      "epoch:41 step:32794[D loss: 0.408457, acc: 64.06%, op_acc: 39.84%] [G loss: 0.890151]\n",
      "epoch:41 step:32795[D loss: 0.424157, acc: 55.47%, op_acc: 41.41%] [G loss: 0.958880]\n",
      "epoch:41 step:32796[D loss: 0.408440, acc: 62.50%, op_acc: 42.97%] [G loss: 0.927530]\n",
      "epoch:41 step:32797[D loss: 0.395687, acc: 64.06%, op_acc: 41.41%] [G loss: 0.971819]\n",
      "epoch:41 step:32798[D loss: 0.440390, acc: 53.12%, op_acc: 35.16%] [G loss: 0.945188]\n",
      "epoch:41 step:32799[D loss: 0.415034, acc: 51.56%, op_acc: 44.53%] [G loss: 0.810336]\n",
      "epoch:41 step:32800[D loss: 0.405812, acc: 64.84%, op_acc: 39.06%] [G loss: 0.898319]\n",
      "##############\n",
      "[0.85285687 0.85941775 0.81923169 0.81784839 0.79153132 0.8141025\n",
      " 0.88857759 0.83230894 0.83062113 0.82394136]\n",
      "##########\n",
      "epoch:41 step:32801[D loss: 0.411785, acc: 57.03%, op_acc: 43.75%] [G loss: 0.857571]\n",
      "epoch:41 step:32802[D loss: 0.430798, acc: 58.59%, op_acc: 35.94%] [G loss: 1.058954]\n",
      "epoch:42 step:32803[D loss: 0.372994, acc: 70.31%, op_acc: 46.09%] [G loss: 0.883183]\n",
      "epoch:42 step:32804[D loss: 0.392701, acc: 65.62%, op_acc: 36.72%] [G loss: 0.917939]\n",
      "epoch:42 step:32805[D loss: 0.422420, acc: 60.94%, op_acc: 42.97%] [G loss: 0.958655]\n",
      "epoch:42 step:32806[D loss: 0.431776, acc: 56.25%, op_acc: 45.31%] [G loss: 0.930231]\n",
      "epoch:42 step:32807[D loss: 0.389116, acc: 64.06%, op_acc: 46.88%] [G loss: 0.847795]\n",
      "epoch:42 step:32808[D loss: 0.443857, acc: 48.44%, op_acc: 39.06%] [G loss: 0.753656]\n",
      "epoch:42 step:32809[D loss: 0.390929, acc: 63.28%, op_acc: 44.53%] [G loss: 0.840734]\n",
      "epoch:42 step:32810[D loss: 0.432526, acc: 55.47%, op_acc: 41.41%] [G loss: 0.933173]\n",
      "epoch:42 step:32811[D loss: 0.393651, acc: 60.94%, op_acc: 42.19%] [G loss: 0.942318]\n",
      "epoch:42 step:32812[D loss: 0.466215, acc: 57.03%, op_acc: 36.72%] [G loss: 0.931502]\n",
      "epoch:42 step:32813[D loss: 0.441512, acc: 53.91%, op_acc: 41.41%] [G loss: 0.892659]\n",
      "epoch:42 step:32814[D loss: 0.476593, acc: 49.22%, op_acc: 35.16%] [G loss: 0.871227]\n",
      "epoch:42 step:32815[D loss: 0.388229, acc: 68.75%, op_acc: 41.41%] [G loss: 0.932717]\n",
      "epoch:42 step:32816[D loss: 0.438291, acc: 58.59%, op_acc: 38.28%] [G loss: 0.928198]\n",
      "epoch:42 step:32817[D loss: 0.401512, acc: 62.50%, op_acc: 41.41%] [G loss: 0.908839]\n",
      "epoch:42 step:32818[D loss: 0.384535, acc: 63.28%, op_acc: 45.31%] [G loss: 0.884378]\n",
      "epoch:42 step:32819[D loss: 0.426253, acc: 57.81%, op_acc: 42.19%] [G loss: 0.939764]\n",
      "epoch:42 step:32820[D loss: 0.444379, acc: 57.03%, op_acc: 43.75%] [G loss: 0.908041]\n",
      "epoch:42 step:32821[D loss: 0.398886, acc: 58.59%, op_acc: 45.31%] [G loss: 0.916540]\n",
      "epoch:42 step:32822[D loss: 0.415145, acc: 57.03%, op_acc: 49.22%] [G loss: 0.937495]\n",
      "epoch:42 step:32823[D loss: 0.429267, acc: 60.16%, op_acc: 35.16%] [G loss: 0.916799]\n",
      "epoch:42 step:32824[D loss: 0.409873, acc: 64.84%, op_acc: 42.19%] [G loss: 0.918178]\n",
      "epoch:42 step:32825[D loss: 0.385357, acc: 64.06%, op_acc: 47.66%] [G loss: 0.871563]\n",
      "epoch:42 step:32826[D loss: 0.437814, acc: 56.25%, op_acc: 37.50%] [G loss: 0.845257]\n",
      "epoch:42 step:32827[D loss: 0.423309, acc: 57.03%, op_acc: 40.62%] [G loss: 0.926068]\n",
      "epoch:42 step:32828[D loss: 0.416367, acc: 57.81%, op_acc: 42.19%] [G loss: 0.953066]\n",
      "epoch:42 step:32829[D loss: 0.396821, acc: 65.62%, op_acc: 42.19%] [G loss: 1.027879]\n",
      "epoch:42 step:32830[D loss: 0.400686, acc: 60.16%, op_acc: 44.53%] [G loss: 0.982793]\n",
      "epoch:42 step:32831[D loss: 0.410216, acc: 60.16%, op_acc: 50.00%] [G loss: 0.947654]\n",
      "epoch:42 step:32832[D loss: 0.389731, acc: 57.03%, op_acc: 41.41%] [G loss: 0.904729]\n",
      "epoch:42 step:32833[D loss: 0.404678, acc: 61.72%, op_acc: 44.53%] [G loss: 0.949901]\n",
      "epoch:42 step:32834[D loss: 0.408994, acc: 65.62%, op_acc: 39.06%] [G loss: 0.911296]\n",
      "epoch:42 step:32835[D loss: 0.386328, acc: 63.28%, op_acc: 42.97%] [G loss: 0.892611]\n",
      "epoch:42 step:32836[D loss: 0.417136, acc: 59.38%, op_acc: 41.41%] [G loss: 0.908697]\n",
      "epoch:42 step:32837[D loss: 0.396803, acc: 67.97%, op_acc: 42.97%] [G loss: 0.970441]\n",
      "epoch:42 step:32838[D loss: 0.410772, acc: 59.38%, op_acc: 42.97%] [G loss: 0.970742]\n",
      "epoch:42 step:32839[D loss: 0.428939, acc: 57.81%, op_acc: 41.41%] [G loss: 0.836544]\n",
      "epoch:42 step:32840[D loss: 0.413839, acc: 57.03%, op_acc: 48.44%] [G loss: 0.942880]\n",
      "epoch:42 step:32841[D loss: 0.397990, acc: 62.50%, op_acc: 47.66%] [G loss: 0.832258]\n",
      "epoch:42 step:32842[D loss: 0.422917, acc: 60.16%, op_acc: 39.84%] [G loss: 0.812231]\n",
      "epoch:42 step:32843[D loss: 0.377219, acc: 64.06%, op_acc: 50.00%] [G loss: 0.932962]\n",
      "epoch:42 step:32844[D loss: 0.421017, acc: 58.59%, op_acc: 46.09%] [G loss: 0.817074]\n",
      "epoch:42 step:32845[D loss: 0.424144, acc: 60.94%, op_acc: 43.75%] [G loss: 1.009837]\n",
      "epoch:42 step:32846[D loss: 0.426375, acc: 57.03%, op_acc: 42.97%] [G loss: 0.916449]\n",
      "epoch:42 step:32847[D loss: 0.430603, acc: 57.03%, op_acc: 42.97%] [G loss: 1.007396]\n",
      "epoch:42 step:32848[D loss: 0.429934, acc: 59.38%, op_acc: 42.19%] [G loss: 0.799090]\n",
      "epoch:42 step:32849[D loss: 0.428167, acc: 58.59%, op_acc: 39.06%] [G loss: 0.903668]\n",
      "epoch:42 step:32850[D loss: 0.423824, acc: 59.38%, op_acc: 41.41%] [G loss: 0.930840]\n",
      "##############\n",
      "[0.83258628 0.84373983 0.82016565 0.79354431 0.77383335 0.84203302\n",
      " 0.90804106 0.83265971 0.81371951 0.81960066]\n",
      "##########\n",
      "epoch:42 step:32851[D loss: 0.386257, acc: 67.97%, op_acc: 40.62%] [G loss: 0.856047]\n",
      "epoch:42 step:32852[D loss: 0.413186, acc: 64.06%, op_acc: 35.94%] [G loss: 0.886295]\n",
      "epoch:42 step:32853[D loss: 0.415774, acc: 60.94%, op_acc: 40.62%] [G loss: 0.798410]\n",
      "epoch:42 step:32854[D loss: 0.399095, acc: 68.75%, op_acc: 43.75%] [G loss: 0.963466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:32855[D loss: 0.443515, acc: 57.81%, op_acc: 39.06%] [G loss: 0.786665]\n",
      "epoch:42 step:32856[D loss: 0.426784, acc: 60.16%, op_acc: 41.41%] [G loss: 0.939665]\n",
      "epoch:42 step:32857[D loss: 0.404994, acc: 64.84%, op_acc: 37.50%] [G loss: 0.862112]\n",
      "epoch:42 step:32858[D loss: 0.389010, acc: 62.50%, op_acc: 38.28%] [G loss: 0.905527]\n",
      "epoch:42 step:32859[D loss: 0.439459, acc: 53.12%, op_acc: 36.72%] [G loss: 0.836753]\n",
      "epoch:42 step:32860[D loss: 0.359353, acc: 69.53%, op_acc: 49.22%] [G loss: 0.878819]\n",
      "epoch:42 step:32861[D loss: 0.385819, acc: 61.72%, op_acc: 46.09%] [G loss: 0.880777]\n",
      "epoch:42 step:32862[D loss: 0.411713, acc: 62.50%, op_acc: 40.62%] [G loss: 0.934330]\n",
      "epoch:42 step:32863[D loss: 0.415943, acc: 60.94%, op_acc: 38.28%] [G loss: 0.873564]\n",
      "epoch:42 step:32864[D loss: 0.424646, acc: 56.25%, op_acc: 40.62%] [G loss: 0.935618]\n",
      "epoch:42 step:32865[D loss: 0.416504, acc: 58.59%, op_acc: 41.41%] [G loss: 0.761434]\n",
      "epoch:42 step:32866[D loss: 0.379960, acc: 69.53%, op_acc: 44.53%] [G loss: 0.816518]\n",
      "epoch:42 step:32867[D loss: 0.432199, acc: 61.72%, op_acc: 34.38%] [G loss: 0.813053]\n",
      "epoch:42 step:32868[D loss: 0.403998, acc: 62.50%, op_acc: 45.31%] [G loss: 0.854066]\n",
      "epoch:42 step:32869[D loss: 0.391195, acc: 65.62%, op_acc: 39.84%] [G loss: 0.912257]\n",
      "epoch:42 step:32870[D loss: 0.422242, acc: 54.69%, op_acc: 47.66%] [G loss: 0.936529]\n",
      "epoch:42 step:32871[D loss: 0.396109, acc: 59.38%, op_acc: 48.44%] [G loss: 0.914276]\n",
      "epoch:42 step:32872[D loss: 0.419205, acc: 56.25%, op_acc: 42.19%] [G loss: 0.920611]\n",
      "epoch:42 step:32873[D loss: 0.430023, acc: 53.91%, op_acc: 39.06%] [G loss: 0.877660]\n",
      "epoch:42 step:32874[D loss: 0.408879, acc: 60.94%, op_acc: 41.41%] [G loss: 0.881611]\n",
      "epoch:42 step:32875[D loss: 0.407880, acc: 57.81%, op_acc: 46.88%] [G loss: 0.891649]\n",
      "epoch:42 step:32876[D loss: 0.411976, acc: 56.25%, op_acc: 43.75%] [G loss: 0.963343]\n",
      "epoch:42 step:32877[D loss: 0.413082, acc: 63.28%, op_acc: 40.62%] [G loss: 0.905538]\n",
      "epoch:42 step:32878[D loss: 0.418763, acc: 61.72%, op_acc: 38.28%] [G loss: 0.962774]\n",
      "epoch:42 step:32879[D loss: 0.396666, acc: 67.19%, op_acc: 46.09%] [G loss: 0.860843]\n",
      "epoch:42 step:32880[D loss: 0.437245, acc: 57.81%, op_acc: 38.28%] [G loss: 0.907118]\n",
      "epoch:42 step:32881[D loss: 0.394226, acc: 62.50%, op_acc: 44.53%] [G loss: 0.860221]\n",
      "epoch:42 step:32882[D loss: 0.450136, acc: 56.25%, op_acc: 34.38%] [G loss: 0.943139]\n",
      "epoch:42 step:32883[D loss: 0.437878, acc: 54.69%, op_acc: 41.41%] [G loss: 0.948992]\n",
      "epoch:42 step:32884[D loss: 0.413057, acc: 64.84%, op_acc: 43.75%] [G loss: 0.893984]\n",
      "epoch:42 step:32885[D loss: 0.419348, acc: 55.47%, op_acc: 39.06%] [G loss: 1.013276]\n",
      "epoch:42 step:32886[D loss: 0.374729, acc: 67.19%, op_acc: 45.31%] [G loss: 0.898504]\n",
      "epoch:42 step:32887[D loss: 0.415285, acc: 60.94%, op_acc: 42.19%] [G loss: 0.970234]\n",
      "epoch:42 step:32888[D loss: 0.410909, acc: 59.38%, op_acc: 44.53%] [G loss: 0.897202]\n",
      "epoch:42 step:32889[D loss: 0.398765, acc: 62.50%, op_acc: 40.62%] [G loss: 0.905021]\n",
      "epoch:42 step:32890[D loss: 0.389369, acc: 66.41%, op_acc: 46.88%] [G loss: 0.928883]\n",
      "epoch:42 step:32891[D loss: 0.467680, acc: 50.78%, op_acc: 33.59%] [G loss: 0.838821]\n",
      "epoch:42 step:32892[D loss: 0.462772, acc: 45.31%, op_acc: 44.53%] [G loss: 0.868282]\n",
      "epoch:42 step:32893[D loss: 0.409089, acc: 56.25%, op_acc: 43.75%] [G loss: 0.943560]\n",
      "epoch:42 step:32894[D loss: 0.421436, acc: 66.41%, op_acc: 42.97%] [G loss: 0.906111]\n",
      "epoch:42 step:32895[D loss: 0.406650, acc: 58.59%, op_acc: 38.28%] [G loss: 0.908968]\n",
      "epoch:42 step:32896[D loss: 0.410127, acc: 60.94%, op_acc: 40.62%] [G loss: 1.001402]\n",
      "epoch:42 step:32897[D loss: 0.425907, acc: 58.59%, op_acc: 40.62%] [G loss: 0.885300]\n",
      "epoch:42 step:32898[D loss: 0.447929, acc: 55.47%, op_acc: 40.62%] [G loss: 0.909123]\n",
      "epoch:42 step:32899[D loss: 0.387702, acc: 64.84%, op_acc: 39.84%] [G loss: 0.897431]\n",
      "epoch:42 step:32900[D loss: 0.415748, acc: 60.16%, op_acc: 40.62%] [G loss: 0.848675]\n",
      "##############\n",
      "[0.85611492 0.86056957 0.80798037 0.81920641 0.79153695 0.83909079\n",
      " 0.89223334 0.81488001 0.77412237 0.81815538]\n",
      "##########\n",
      "epoch:42 step:32901[D loss: 0.434540, acc: 52.34%, op_acc: 44.53%] [G loss: 0.934185]\n",
      "epoch:42 step:32902[D loss: 0.388905, acc: 67.19%, op_acc: 40.62%] [G loss: 0.822547]\n",
      "epoch:42 step:32903[D loss: 0.427267, acc: 57.03%, op_acc: 35.16%] [G loss: 0.914787]\n",
      "epoch:42 step:32904[D loss: 0.419496, acc: 63.28%, op_acc: 40.62%] [G loss: 0.883475]\n",
      "epoch:42 step:32905[D loss: 0.414232, acc: 63.28%, op_acc: 42.97%] [G loss: 0.953500]\n",
      "epoch:42 step:32906[D loss: 0.421784, acc: 57.03%, op_acc: 43.75%] [G loss: 0.898486]\n",
      "epoch:42 step:32907[D loss: 0.406953, acc: 67.97%, op_acc: 36.72%] [G loss: 0.945105]\n",
      "epoch:42 step:32908[D loss: 0.415014, acc: 57.03%, op_acc: 44.53%] [G loss: 0.934427]\n",
      "epoch:42 step:32909[D loss: 0.410425, acc: 66.41%, op_acc: 39.06%] [G loss: 0.938118]\n",
      "epoch:42 step:32910[D loss: 0.401325, acc: 64.06%, op_acc: 42.97%] [G loss: 0.970672]\n",
      "epoch:42 step:32911[D loss: 0.404080, acc: 64.06%, op_acc: 40.62%] [G loss: 0.951310]\n",
      "epoch:42 step:32912[D loss: 0.393166, acc: 66.41%, op_acc: 51.56%] [G loss: 0.892058]\n",
      "epoch:42 step:32913[D loss: 0.429477, acc: 65.62%, op_acc: 37.50%] [G loss: 0.893260]\n",
      "epoch:42 step:32914[D loss: 0.395588, acc: 67.19%, op_acc: 45.31%] [G loss: 0.853402]\n",
      "epoch:42 step:32915[D loss: 0.421728, acc: 66.41%, op_acc: 29.69%] [G loss: 0.866328]\n",
      "epoch:42 step:32916[D loss: 0.392546, acc: 61.72%, op_acc: 47.66%] [G loss: 0.910739]\n",
      "epoch:42 step:32917[D loss: 0.404763, acc: 56.25%, op_acc: 43.75%] [G loss: 0.833557]\n",
      "epoch:42 step:32918[D loss: 0.439981, acc: 56.25%, op_acc: 41.41%] [G loss: 0.793856]\n",
      "epoch:42 step:32919[D loss: 0.407267, acc: 58.59%, op_acc: 44.53%] [G loss: 0.928975]\n",
      "epoch:42 step:32920[D loss: 0.435011, acc: 58.59%, op_acc: 38.28%] [G loss: 0.871377]\n",
      "epoch:42 step:32921[D loss: 0.421649, acc: 60.16%, op_acc: 40.62%] [G loss: 0.840958]\n",
      "epoch:42 step:32922[D loss: 0.403725, acc: 60.16%, op_acc: 39.06%] [G loss: 0.950793]\n",
      "epoch:42 step:32923[D loss: 0.400537, acc: 60.94%, op_acc: 43.75%] [G loss: 0.897758]\n",
      "epoch:42 step:32924[D loss: 0.422190, acc: 57.03%, op_acc: 38.28%] [G loss: 0.859474]\n",
      "epoch:42 step:32925[D loss: 0.438980, acc: 57.81%, op_acc: 42.19%] [G loss: 0.822501]\n",
      "epoch:42 step:32926[D loss: 0.460869, acc: 53.12%, op_acc: 38.28%] [G loss: 0.833490]\n",
      "epoch:42 step:32927[D loss: 0.415098, acc: 57.81%, op_acc: 43.75%] [G loss: 0.901194]\n",
      "epoch:42 step:32928[D loss: 0.400647, acc: 60.16%, op_acc: 46.88%] [G loss: 0.872016]\n",
      "epoch:42 step:32929[D loss: 0.417231, acc: 62.50%, op_acc: 40.62%] [G loss: 0.809891]\n",
      "epoch:42 step:32930[D loss: 0.397478, acc: 61.72%, op_acc: 42.97%] [G loss: 0.911397]\n",
      "epoch:42 step:32931[D loss: 0.423538, acc: 64.06%, op_acc: 39.06%] [G loss: 0.868690]\n",
      "epoch:42 step:32932[D loss: 0.411570, acc: 57.81%, op_acc: 44.53%] [G loss: 0.881403]\n",
      "epoch:42 step:32933[D loss: 0.405232, acc: 62.50%, op_acc: 42.19%] [G loss: 0.930232]\n",
      "epoch:42 step:32934[D loss: 0.383890, acc: 63.28%, op_acc: 48.44%] [G loss: 0.946832]\n",
      "epoch:42 step:32935[D loss: 0.400162, acc: 68.75%, op_acc: 39.84%] [G loss: 0.897734]\n",
      "epoch:42 step:32936[D loss: 0.387204, acc: 65.62%, op_acc: 46.88%] [G loss: 0.881852]\n",
      "epoch:42 step:32937[D loss: 0.411927, acc: 59.38%, op_acc: 42.19%] [G loss: 0.947549]\n",
      "epoch:42 step:32938[D loss: 0.361737, acc: 71.88%, op_acc: 48.44%] [G loss: 0.893611]\n",
      "epoch:42 step:32939[D loss: 0.415203, acc: 58.59%, op_acc: 41.41%] [G loss: 0.969610]\n",
      "epoch:42 step:32940[D loss: 0.418451, acc: 57.81%, op_acc: 40.62%] [G loss: 0.872303]\n",
      "epoch:42 step:32941[D loss: 0.395546, acc: 62.50%, op_acc: 42.97%] [G loss: 0.938229]\n",
      "epoch:42 step:32942[D loss: 0.434223, acc: 59.38%, op_acc: 36.72%] [G loss: 0.911768]\n",
      "epoch:42 step:32943[D loss: 0.416369, acc: 67.97%, op_acc: 35.94%] [G loss: 0.863099]\n",
      "epoch:42 step:32944[D loss: 0.417002, acc: 64.06%, op_acc: 35.94%] [G loss: 0.895385]\n",
      "epoch:42 step:32945[D loss: 0.416265, acc: 54.69%, op_acc: 46.09%] [G loss: 0.937027]\n",
      "epoch:42 step:32946[D loss: 0.407510, acc: 64.84%, op_acc: 40.62%] [G loss: 0.884893]\n",
      "epoch:42 step:32947[D loss: 0.444212, acc: 58.59%, op_acc: 39.06%] [G loss: 0.853135]\n",
      "epoch:42 step:32948[D loss: 0.401900, acc: 64.06%, op_acc: 39.06%] [G loss: 0.904763]\n",
      "epoch:42 step:32949[D loss: 0.382277, acc: 63.28%, op_acc: 43.75%] [G loss: 0.873724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:32950[D loss: 0.414968, acc: 54.69%, op_acc: 38.28%] [G loss: 0.919399]\n",
      "##############\n",
      "[0.86109938 0.86650071 0.81901677 0.79119337 0.78513115 0.80595044\n",
      " 0.90906677 0.83404766 0.80501154 0.83445009]\n",
      "##########\n",
      "epoch:42 step:32951[D loss: 0.394907, acc: 58.59%, op_acc: 40.62%] [G loss: 0.889458]\n",
      "epoch:42 step:32952[D loss: 0.410439, acc: 62.50%, op_acc: 42.97%] [G loss: 0.894634]\n",
      "epoch:42 step:32953[D loss: 0.378894, acc: 65.62%, op_acc: 46.09%] [G loss: 0.917652]\n",
      "epoch:42 step:32954[D loss: 0.416998, acc: 62.50%, op_acc: 42.19%] [G loss: 0.972596]\n",
      "epoch:42 step:32955[D loss: 0.393701, acc: 67.19%, op_acc: 42.19%] [G loss: 0.941025]\n",
      "epoch:42 step:32956[D loss: 0.414110, acc: 57.81%, op_acc: 41.41%] [G loss: 0.796600]\n",
      "epoch:42 step:32957[D loss: 0.419039, acc: 61.72%, op_acc: 40.62%] [G loss: 0.888854]\n",
      "epoch:42 step:32958[D loss: 0.414029, acc: 58.59%, op_acc: 40.62%] [G loss: 0.937885]\n",
      "epoch:42 step:32959[D loss: 0.406498, acc: 64.06%, op_acc: 39.06%] [G loss: 0.822658]\n",
      "epoch:42 step:32960[D loss: 0.396760, acc: 62.50%, op_acc: 46.88%] [G loss: 0.889977]\n",
      "epoch:42 step:32961[D loss: 0.396945, acc: 62.50%, op_acc: 41.41%] [G loss: 0.961518]\n",
      "epoch:42 step:32962[D loss: 0.391498, acc: 67.19%, op_acc: 42.97%] [G loss: 0.867095]\n",
      "epoch:42 step:32963[D loss: 0.406614, acc: 61.72%, op_acc: 46.88%] [G loss: 0.876347]\n",
      "epoch:42 step:32964[D loss: 0.411172, acc: 61.72%, op_acc: 45.31%] [G loss: 0.973671]\n",
      "epoch:42 step:32965[D loss: 0.388895, acc: 73.44%, op_acc: 40.62%] [G loss: 0.925087]\n",
      "epoch:42 step:32966[D loss: 0.395845, acc: 66.41%, op_acc: 45.31%] [G loss: 0.961377]\n",
      "epoch:42 step:32967[D loss: 0.411726, acc: 57.03%, op_acc: 39.06%] [G loss: 0.922255]\n",
      "epoch:42 step:32968[D loss: 0.400379, acc: 63.28%, op_acc: 38.28%] [G loss: 0.948366]\n",
      "epoch:42 step:32969[D loss: 0.400033, acc: 63.28%, op_acc: 40.62%] [G loss: 0.872857]\n",
      "epoch:42 step:32970[D loss: 0.399015, acc: 64.06%, op_acc: 45.31%] [G loss: 0.895676]\n",
      "epoch:42 step:32971[D loss: 0.413739, acc: 62.50%, op_acc: 41.41%] [G loss: 0.937755]\n",
      "epoch:42 step:32972[D loss: 0.401544, acc: 65.62%, op_acc: 46.88%] [G loss: 0.849957]\n",
      "epoch:42 step:32973[D loss: 0.408159, acc: 63.28%, op_acc: 42.97%] [G loss: 0.915004]\n",
      "epoch:42 step:32974[D loss: 0.393046, acc: 60.94%, op_acc: 46.09%] [G loss: 0.901455]\n",
      "epoch:42 step:32975[D loss: 0.437306, acc: 64.06%, op_acc: 34.38%] [G loss: 0.828336]\n",
      "epoch:42 step:32976[D loss: 0.455617, acc: 52.34%, op_acc: 36.72%] [G loss: 0.945568]\n",
      "epoch:42 step:32977[D loss: 0.384675, acc: 71.09%, op_acc: 44.53%] [G loss: 0.851646]\n",
      "epoch:42 step:32978[D loss: 0.424519, acc: 57.81%, op_acc: 43.75%] [G loss: 0.845953]\n",
      "epoch:42 step:32979[D loss: 0.399429, acc: 67.97%, op_acc: 39.06%] [G loss: 0.813891]\n",
      "epoch:42 step:32980[D loss: 0.457303, acc: 54.69%, op_acc: 38.28%] [G loss: 0.901444]\n",
      "epoch:42 step:32981[D loss: 0.385308, acc: 66.41%, op_acc: 40.62%] [G loss: 0.930062]\n",
      "epoch:42 step:32982[D loss: 0.408638, acc: 64.06%, op_acc: 32.03%] [G loss: 0.920147]\n",
      "epoch:42 step:32983[D loss: 0.383676, acc: 69.53%, op_acc: 45.31%] [G loss: 0.915309]\n",
      "epoch:42 step:32984[D loss: 0.398486, acc: 63.28%, op_acc: 40.62%] [G loss: 0.935075]\n",
      "epoch:42 step:32985[D loss: 0.401993, acc: 60.94%, op_acc: 42.97%] [G loss: 0.923974]\n",
      "epoch:42 step:32986[D loss: 0.390112, acc: 61.72%, op_acc: 50.00%] [G loss: 0.934573]\n",
      "epoch:42 step:32987[D loss: 0.380027, acc: 65.62%, op_acc: 39.06%] [G loss: 1.036285]\n",
      "epoch:42 step:32988[D loss: 0.418774, acc: 55.47%, op_acc: 35.94%] [G loss: 0.918172]\n",
      "epoch:42 step:32989[D loss: 0.409082, acc: 59.38%, op_acc: 35.94%] [G loss: 0.894251]\n",
      "epoch:42 step:32990[D loss: 0.393485, acc: 66.41%, op_acc: 47.66%] [G loss: 0.933260]\n",
      "epoch:42 step:32991[D loss: 0.400660, acc: 69.53%, op_acc: 38.28%] [G loss: 0.861490]\n",
      "epoch:42 step:32992[D loss: 0.409064, acc: 62.50%, op_acc: 40.62%] [G loss: 0.808969]\n",
      "epoch:42 step:32993[D loss: 0.417140, acc: 61.72%, op_acc: 40.62%] [G loss: 0.901945]\n",
      "epoch:42 step:32994[D loss: 0.400990, acc: 62.50%, op_acc: 38.28%] [G loss: 0.984056]\n",
      "epoch:42 step:32995[D loss: 0.438854, acc: 58.59%, op_acc: 39.06%] [G loss: 0.910616]\n",
      "epoch:42 step:32996[D loss: 0.380292, acc: 66.41%, op_acc: 45.31%] [G loss: 0.978059]\n",
      "epoch:42 step:32997[D loss: 0.418298, acc: 64.06%, op_acc: 43.75%] [G loss: 0.980482]\n",
      "epoch:42 step:32998[D loss: 0.412157, acc: 69.53%, op_acc: 35.16%] [G loss: 0.823463]\n",
      "epoch:42 step:32999[D loss: 0.417806, acc: 64.06%, op_acc: 45.31%] [G loss: 0.969919]\n",
      "epoch:42 step:33000[D loss: 0.408732, acc: 58.59%, op_acc: 42.19%] [G loss: 0.893496]\n",
      "##############\n",
      "[0.85773058 0.83801175 0.80430391 0.81100354 0.80312368 0.80719155\n",
      " 0.89218741 0.83970936 0.78247095 0.82429013]\n",
      "##########\n",
      "epoch:42 step:33001[D loss: 0.418132, acc: 63.28%, op_acc: 38.28%] [G loss: 0.888087]\n",
      "epoch:42 step:33002[D loss: 0.438298, acc: 51.56%, op_acc: 43.75%] [G loss: 0.946767]\n",
      "epoch:42 step:33003[D loss: 0.368523, acc: 65.62%, op_acc: 51.56%] [G loss: 0.972951]\n",
      "epoch:42 step:33004[D loss: 0.402325, acc: 62.50%, op_acc: 45.31%] [G loss: 0.840966]\n",
      "epoch:42 step:33005[D loss: 0.455483, acc: 52.34%, op_acc: 42.97%] [G loss: 0.941799]\n",
      "epoch:42 step:33006[D loss: 0.451997, acc: 54.69%, op_acc: 37.50%] [G loss: 0.880996]\n",
      "epoch:42 step:33007[D loss: 0.390586, acc: 68.75%, op_acc: 42.19%] [G loss: 0.970500]\n",
      "epoch:42 step:33008[D loss: 0.372412, acc: 77.34%, op_acc: 43.75%] [G loss: 0.905077]\n",
      "epoch:42 step:33009[D loss: 0.371618, acc: 66.41%, op_acc: 45.31%] [G loss: 0.898660]\n",
      "epoch:42 step:33010[D loss: 0.422150, acc: 64.06%, op_acc: 36.72%] [G loss: 0.947156]\n",
      "epoch:42 step:33011[D loss: 0.402568, acc: 66.41%, op_acc: 38.28%] [G loss: 0.882292]\n",
      "epoch:42 step:33012[D loss: 0.416710, acc: 60.16%, op_acc: 38.28%] [G loss: 0.984977]\n",
      "epoch:42 step:33013[D loss: 0.385646, acc: 56.25%, op_acc: 50.00%] [G loss: 0.885323]\n",
      "epoch:42 step:33014[D loss: 0.410286, acc: 63.28%, op_acc: 42.19%] [G loss: 0.878111]\n",
      "epoch:42 step:33015[D loss: 0.411660, acc: 57.81%, op_acc: 36.72%] [G loss: 0.824020]\n",
      "epoch:42 step:33016[D loss: 0.448739, acc: 56.25%, op_acc: 38.28%] [G loss: 1.023217]\n",
      "epoch:42 step:33017[D loss: 0.407454, acc: 67.19%, op_acc: 42.19%] [G loss: 0.785092]\n",
      "epoch:42 step:33018[D loss: 0.400695, acc: 62.50%, op_acc: 39.06%] [G loss: 0.962232]\n",
      "epoch:42 step:33019[D loss: 0.374229, acc: 67.19%, op_acc: 43.75%] [G loss: 0.949849]\n",
      "epoch:42 step:33020[D loss: 0.398160, acc: 61.72%, op_acc: 42.97%] [G loss: 0.873349]\n",
      "epoch:42 step:33021[D loss: 0.389824, acc: 64.84%, op_acc: 43.75%] [G loss: 0.947439]\n",
      "epoch:42 step:33022[D loss: 0.431159, acc: 58.59%, op_acc: 39.84%] [G loss: 0.873187]\n",
      "epoch:42 step:33023[D loss: 0.419857, acc: 60.16%, op_acc: 39.84%] [G loss: 0.891542]\n",
      "epoch:42 step:33024[D loss: 0.417369, acc: 68.75%, op_acc: 35.16%] [G loss: 0.882711]\n",
      "epoch:42 step:33025[D loss: 0.438346, acc: 60.94%, op_acc: 40.62%] [G loss: 0.814038]\n",
      "epoch:42 step:33026[D loss: 0.394015, acc: 67.19%, op_acc: 39.84%] [G loss: 0.747572]\n",
      "epoch:42 step:33027[D loss: 0.409209, acc: 61.72%, op_acc: 41.41%] [G loss: 1.013787]\n",
      "epoch:42 step:33028[D loss: 0.426499, acc: 60.16%, op_acc: 44.53%] [G loss: 1.054927]\n",
      "epoch:42 step:33029[D loss: 0.416001, acc: 57.81%, op_acc: 43.75%] [G loss: 0.948135]\n",
      "epoch:42 step:33030[D loss: 0.370610, acc: 66.41%, op_acc: 45.31%] [G loss: 0.830748]\n",
      "epoch:42 step:33031[D loss: 0.418048, acc: 59.38%, op_acc: 39.84%] [G loss: 0.919762]\n",
      "epoch:42 step:33032[D loss: 0.423518, acc: 60.16%, op_acc: 41.41%] [G loss: 1.009662]\n",
      "epoch:42 step:33033[D loss: 0.390253, acc: 64.84%, op_acc: 41.41%] [G loss: 0.800330]\n",
      "epoch:42 step:33034[D loss: 0.421690, acc: 64.84%, op_acc: 38.28%] [G loss: 1.015409]\n",
      "epoch:42 step:33035[D loss: 0.376563, acc: 72.66%, op_acc: 40.62%] [G loss: 1.042649]\n",
      "epoch:42 step:33036[D loss: 0.462698, acc: 50.00%, op_acc: 36.72%] [G loss: 0.982616]\n",
      "epoch:42 step:33037[D loss: 0.390754, acc: 66.41%, op_acc: 45.31%] [G loss: 0.940749]\n",
      "epoch:42 step:33038[D loss: 0.413634, acc: 67.97%, op_acc: 39.06%] [G loss: 0.856198]\n",
      "epoch:42 step:33039[D loss: 0.369611, acc: 74.22%, op_acc: 45.31%] [G loss: 1.000210]\n",
      "epoch:42 step:33040[D loss: 0.373381, acc: 71.88%, op_acc: 42.19%] [G loss: 0.917970]\n",
      "epoch:42 step:33041[D loss: 0.404386, acc: 61.72%, op_acc: 42.19%] [G loss: 0.963720]\n",
      "epoch:42 step:33042[D loss: 0.411153, acc: 61.72%, op_acc: 39.06%] [G loss: 0.807627]\n",
      "epoch:42 step:33043[D loss: 0.388147, acc: 64.06%, op_acc: 50.00%] [G loss: 0.848438]\n",
      "epoch:42 step:33044[D loss: 0.403500, acc: 67.97%, op_acc: 43.75%] [G loss: 0.950669]\n",
      "epoch:42 step:33045[D loss: 0.425996, acc: 53.91%, op_acc: 46.88%] [G loss: 0.891176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33046[D loss: 0.394440, acc: 64.84%, op_acc: 42.97%] [G loss: 0.858614]\n",
      "epoch:42 step:33047[D loss: 0.418822, acc: 60.94%, op_acc: 39.84%] [G loss: 0.909265]\n",
      "epoch:42 step:33048[D loss: 0.425569, acc: 57.81%, op_acc: 39.84%] [G loss: 0.944197]\n",
      "epoch:42 step:33049[D loss: 0.420121, acc: 55.47%, op_acc: 39.84%] [G loss: 0.825281]\n",
      "epoch:42 step:33050[D loss: 0.454866, acc: 52.34%, op_acc: 39.84%] [G loss: 0.836878]\n",
      "##############\n",
      "[0.85466114 0.85747398 0.82433445 0.80730107 0.78106079 0.83631013\n",
      " 0.87106112 0.78583661 0.77578786 0.82406009]\n",
      "##########\n",
      "epoch:42 step:33051[D loss: 0.411596, acc: 61.72%, op_acc: 42.97%] [G loss: 0.973247]\n",
      "epoch:42 step:33052[D loss: 0.403208, acc: 69.53%, op_acc: 39.06%] [G loss: 0.997676]\n",
      "epoch:42 step:33053[D loss: 0.381065, acc: 64.84%, op_acc: 49.22%] [G loss: 1.068919]\n",
      "epoch:42 step:33054[D loss: 0.412704, acc: 63.28%, op_acc: 44.53%] [G loss: 0.983060]\n",
      "epoch:42 step:33055[D loss: 0.428749, acc: 55.47%, op_acc: 43.75%] [G loss: 1.007413]\n",
      "epoch:42 step:33056[D loss: 0.407453, acc: 67.97%, op_acc: 35.94%] [G loss: 0.872440]\n",
      "epoch:42 step:33057[D loss: 0.430149, acc: 58.59%, op_acc: 38.28%] [G loss: 1.014667]\n",
      "epoch:42 step:33058[D loss: 0.424196, acc: 57.03%, op_acc: 44.53%] [G loss: 0.877178]\n",
      "epoch:42 step:33059[D loss: 0.414950, acc: 66.41%, op_acc: 39.84%] [G loss: 0.974841]\n",
      "epoch:42 step:33060[D loss: 0.428620, acc: 56.25%, op_acc: 38.28%] [G loss: 0.937942]\n",
      "epoch:42 step:33061[D loss: 0.446735, acc: 57.03%, op_acc: 35.16%] [G loss: 0.888341]\n",
      "epoch:42 step:33062[D loss: 0.439292, acc: 57.81%, op_acc: 42.97%] [G loss: 0.957862]\n",
      "epoch:42 step:33063[D loss: 0.428176, acc: 57.03%, op_acc: 39.84%] [G loss: 0.988059]\n",
      "epoch:42 step:33064[D loss: 0.388979, acc: 67.19%, op_acc: 40.62%] [G loss: 0.942520]\n",
      "epoch:42 step:33065[D loss: 0.432734, acc: 57.81%, op_acc: 42.97%] [G loss: 0.846491]\n",
      "epoch:42 step:33066[D loss: 0.423161, acc: 55.47%, op_acc: 42.97%] [G loss: 0.947556]\n",
      "epoch:42 step:33067[D loss: 0.417518, acc: 55.47%, op_acc: 46.09%] [G loss: 0.913268]\n",
      "epoch:42 step:33068[D loss: 0.380226, acc: 64.84%, op_acc: 44.53%] [G loss: 0.928716]\n",
      "epoch:42 step:33069[D loss: 0.434839, acc: 57.81%, op_acc: 32.03%] [G loss: 0.959645]\n",
      "epoch:42 step:33070[D loss: 0.419208, acc: 55.47%, op_acc: 42.97%] [G loss: 0.884671]\n",
      "epoch:42 step:33071[D loss: 0.390109, acc: 60.16%, op_acc: 44.53%] [G loss: 0.835996]\n",
      "epoch:42 step:33072[D loss: 0.395990, acc: 64.06%, op_acc: 39.84%] [G loss: 0.755677]\n",
      "epoch:42 step:33073[D loss: 0.416751, acc: 59.38%, op_acc: 48.44%] [G loss: 0.971232]\n",
      "epoch:42 step:33074[D loss: 0.434406, acc: 57.81%, op_acc: 33.59%] [G loss: 0.999532]\n",
      "epoch:42 step:33075[D loss: 0.388016, acc: 60.94%, op_acc: 44.53%] [G loss: 0.910935]\n",
      "epoch:42 step:33076[D loss: 0.426362, acc: 58.59%, op_acc: 42.19%] [G loss: 0.902159]\n",
      "epoch:42 step:33077[D loss: 0.443609, acc: 53.12%, op_acc: 40.62%] [G loss: 0.875557]\n",
      "epoch:42 step:33078[D loss: 0.435265, acc: 53.91%, op_acc: 42.19%] [G loss: 0.935072]\n",
      "epoch:42 step:33079[D loss: 0.400002, acc: 63.28%, op_acc: 42.19%] [G loss: 0.887088]\n",
      "epoch:42 step:33080[D loss: 0.425712, acc: 57.03%, op_acc: 39.06%] [G loss: 0.932739]\n",
      "epoch:42 step:33081[D loss: 0.429378, acc: 59.38%, op_acc: 39.84%] [G loss: 0.814963]\n",
      "epoch:42 step:33082[D loss: 0.383863, acc: 67.97%, op_acc: 42.97%] [G loss: 0.778160]\n",
      "epoch:42 step:33083[D loss: 0.427121, acc: 64.06%, op_acc: 39.06%] [G loss: 0.911215]\n",
      "epoch:42 step:33084[D loss: 0.438274, acc: 53.91%, op_acc: 38.28%] [G loss: 0.819945]\n",
      "epoch:42 step:33085[D loss: 0.403258, acc: 60.94%, op_acc: 45.31%] [G loss: 0.833483]\n",
      "epoch:42 step:33086[D loss: 0.392201, acc: 61.72%, op_acc: 45.31%] [G loss: 0.952564]\n",
      "epoch:42 step:33087[D loss: 0.375890, acc: 71.09%, op_acc: 42.19%] [G loss: 0.898236]\n",
      "epoch:42 step:33088[D loss: 0.428494, acc: 55.47%, op_acc: 39.84%] [G loss: 0.931283]\n",
      "epoch:42 step:33089[D loss: 0.406315, acc: 62.50%, op_acc: 50.00%] [G loss: 0.922691]\n",
      "epoch:42 step:33090[D loss: 0.395845, acc: 55.47%, op_acc: 50.78%] [G loss: 0.871869]\n",
      "epoch:42 step:33091[D loss: 0.415597, acc: 61.72%, op_acc: 42.19%] [G loss: 0.903007]\n",
      "epoch:42 step:33092[D loss: 0.390026, acc: 64.84%, op_acc: 43.75%] [G loss: 0.880382]\n",
      "epoch:42 step:33093[D loss: 0.397606, acc: 63.28%, op_acc: 47.66%] [G loss: 0.933309]\n",
      "epoch:42 step:33094[D loss: 0.412682, acc: 67.97%, op_acc: 39.84%] [G loss: 0.871259]\n",
      "epoch:42 step:33095[D loss: 0.382063, acc: 60.94%, op_acc: 47.66%] [G loss: 0.793997]\n",
      "epoch:42 step:33096[D loss: 0.381839, acc: 65.62%, op_acc: 37.50%] [G loss: 0.849340]\n",
      "epoch:42 step:33097[D loss: 0.401842, acc: 64.84%, op_acc: 47.66%] [G loss: 0.921753]\n",
      "epoch:42 step:33098[D loss: 0.393034, acc: 57.81%, op_acc: 50.78%] [G loss: 0.821607]\n",
      "epoch:42 step:33099[D loss: 0.424202, acc: 60.16%, op_acc: 40.62%] [G loss: 0.930040]\n",
      "epoch:42 step:33100[D loss: 0.403668, acc: 60.94%, op_acc: 39.06%] [G loss: 0.907455]\n",
      "##############\n",
      "[0.86392525 0.85362838 0.81164833 0.80357192 0.80812988 0.83000576\n",
      " 0.87644139 0.83312831 0.81187585 0.83977143]\n",
      "##########\n",
      "epoch:42 step:33101[D loss: 0.456215, acc: 49.22%, op_acc: 37.50%] [G loss: 0.832754]\n",
      "epoch:42 step:33102[D loss: 0.412757, acc: 62.50%, op_acc: 37.50%] [G loss: 0.959873]\n",
      "epoch:42 step:33103[D loss: 0.398161, acc: 63.28%, op_acc: 43.75%] [G loss: 0.961163]\n",
      "epoch:42 step:33104[D loss: 0.414754, acc: 61.72%, op_acc: 36.72%] [G loss: 0.927376]\n",
      "epoch:42 step:33105[D loss: 0.376817, acc: 67.97%, op_acc: 42.97%] [G loss: 0.870467]\n",
      "epoch:42 step:33106[D loss: 0.397465, acc: 66.41%, op_acc: 43.75%] [G loss: 0.982520]\n",
      "epoch:42 step:33107[D loss: 0.398702, acc: 60.94%, op_acc: 45.31%] [G loss: 0.990532]\n",
      "epoch:42 step:33108[D loss: 0.400411, acc: 69.53%, op_acc: 42.19%] [G loss: 0.914251]\n",
      "epoch:42 step:33109[D loss: 0.404142, acc: 56.25%, op_acc: 39.06%] [G loss: 0.949813]\n",
      "epoch:42 step:33110[D loss: 0.425207, acc: 57.81%, op_acc: 39.06%] [G loss: 0.827628]\n",
      "epoch:42 step:33111[D loss: 0.447484, acc: 55.47%, op_acc: 33.59%] [G loss: 0.881136]\n",
      "epoch:42 step:33112[D loss: 0.402425, acc: 63.28%, op_acc: 41.41%] [G loss: 1.031985]\n",
      "epoch:42 step:33113[D loss: 0.396302, acc: 62.50%, op_acc: 46.09%] [G loss: 0.931477]\n",
      "epoch:42 step:33114[D loss: 0.453492, acc: 52.34%, op_acc: 33.59%] [G loss: 0.795200]\n",
      "epoch:42 step:33115[D loss: 0.422639, acc: 60.94%, op_acc: 39.84%] [G loss: 1.008135]\n",
      "epoch:42 step:33116[D loss: 0.399248, acc: 68.75%, op_acc: 41.41%] [G loss: 0.921590]\n",
      "epoch:42 step:33117[D loss: 0.408849, acc: 59.38%, op_acc: 42.97%] [G loss: 0.912068]\n",
      "epoch:42 step:33118[D loss: 0.441648, acc: 46.88%, op_acc: 40.62%] [G loss: 0.842338]\n",
      "epoch:42 step:33119[D loss: 0.447928, acc: 54.69%, op_acc: 39.84%] [G loss: 0.821966]\n",
      "epoch:42 step:33120[D loss: 0.431268, acc: 56.25%, op_acc: 36.72%] [G loss: 0.897566]\n",
      "epoch:42 step:33121[D loss: 0.423777, acc: 62.50%, op_acc: 37.50%] [G loss: 0.892950]\n",
      "epoch:42 step:33122[D loss: 0.418182, acc: 59.38%, op_acc: 35.94%] [G loss: 0.873625]\n",
      "epoch:42 step:33123[D loss: 0.425295, acc: 62.50%, op_acc: 37.50%] [G loss: 0.942856]\n",
      "epoch:42 step:33124[D loss: 0.421186, acc: 60.16%, op_acc: 45.31%] [G loss: 0.947405]\n",
      "epoch:42 step:33125[D loss: 0.435443, acc: 56.25%, op_acc: 36.72%] [G loss: 0.933723]\n",
      "epoch:42 step:33126[D loss: 0.397973, acc: 64.84%, op_acc: 39.84%] [G loss: 0.873478]\n",
      "epoch:42 step:33127[D loss: 0.392227, acc: 63.28%, op_acc: 40.62%] [G loss: 0.908304]\n",
      "epoch:42 step:33128[D loss: 0.404480, acc: 60.16%, op_acc: 41.41%] [G loss: 0.977010]\n",
      "epoch:42 step:33129[D loss: 0.390213, acc: 71.09%, op_acc: 42.19%] [G loss: 0.891271]\n",
      "epoch:42 step:33130[D loss: 0.402890, acc: 65.62%, op_acc: 39.84%] [G loss: 0.909188]\n",
      "epoch:42 step:33131[D loss: 0.420147, acc: 61.72%, op_acc: 39.84%] [G loss: 0.941463]\n",
      "epoch:42 step:33132[D loss: 0.419911, acc: 58.59%, op_acc: 43.75%] [G loss: 1.024623]\n",
      "epoch:42 step:33133[D loss: 0.421775, acc: 56.25%, op_acc: 39.84%] [G loss: 0.938246]\n",
      "epoch:42 step:33134[D loss: 0.386650, acc: 64.06%, op_acc: 43.75%] [G loss: 0.945700]\n",
      "epoch:42 step:33135[D loss: 0.392647, acc: 65.62%, op_acc: 44.53%] [G loss: 0.869069]\n",
      "epoch:42 step:33136[D loss: 0.430123, acc: 55.47%, op_acc: 42.19%] [G loss: 0.825352]\n",
      "epoch:42 step:33137[D loss: 0.423047, acc: 65.62%, op_acc: 39.06%] [G loss: 0.814268]\n",
      "epoch:42 step:33138[D loss: 0.403022, acc: 71.09%, op_acc: 39.84%] [G loss: 0.934560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33139[D loss: 0.433465, acc: 52.34%, op_acc: 36.72%] [G loss: 0.828978]\n",
      "epoch:42 step:33140[D loss: 0.373541, acc: 64.84%, op_acc: 50.78%] [G loss: 0.912722]\n",
      "epoch:42 step:33141[D loss: 0.390459, acc: 71.09%, op_acc: 40.62%] [G loss: 0.856893]\n",
      "epoch:42 step:33142[D loss: 0.411671, acc: 62.50%, op_acc: 42.19%] [G loss: 1.008216]\n",
      "epoch:42 step:33143[D loss: 0.418452, acc: 63.28%, op_acc: 39.06%] [G loss: 0.899239]\n",
      "epoch:42 step:33144[D loss: 0.429870, acc: 60.94%, op_acc: 34.38%] [G loss: 0.867378]\n",
      "epoch:42 step:33145[D loss: 0.428226, acc: 62.50%, op_acc: 44.53%] [G loss: 0.808207]\n",
      "epoch:42 step:33146[D loss: 0.426923, acc: 60.16%, op_acc: 37.50%] [G loss: 0.854748]\n",
      "epoch:42 step:33147[D loss: 0.412827, acc: 59.38%, op_acc: 45.31%] [G loss: 0.908367]\n",
      "epoch:42 step:33148[D loss: 0.391608, acc: 57.81%, op_acc: 46.09%] [G loss: 0.866547]\n",
      "epoch:42 step:33149[D loss: 0.406415, acc: 58.59%, op_acc: 43.75%] [G loss: 0.870811]\n",
      "epoch:42 step:33150[D loss: 0.371255, acc: 70.31%, op_acc: 45.31%] [G loss: 0.931477]\n",
      "##############\n",
      "[0.8396384  0.86942968 0.79312744 0.80830546 0.78023554 0.83164955\n",
      " 0.87844045 0.81526476 0.82426253 0.83091883]\n",
      "##########\n",
      "epoch:42 step:33151[D loss: 0.363267, acc: 69.53%, op_acc: 48.44%] [G loss: 0.984439]\n",
      "epoch:42 step:33152[D loss: 0.418343, acc: 64.84%, op_acc: 35.94%] [G loss: 0.902046]\n",
      "epoch:42 step:33153[D loss: 0.438911, acc: 54.69%, op_acc: 42.97%] [G loss: 0.929589]\n",
      "epoch:42 step:33154[D loss: 0.420881, acc: 63.28%, op_acc: 35.94%] [G loss: 0.959775]\n",
      "epoch:42 step:33155[D loss: 0.367170, acc: 69.53%, op_acc: 51.56%] [G loss: 0.929418]\n",
      "epoch:42 step:33156[D loss: 0.446979, acc: 52.34%, op_acc: 41.41%] [G loss: 0.906915]\n",
      "epoch:42 step:33157[D loss: 0.420535, acc: 62.50%, op_acc: 40.62%] [G loss: 0.833656]\n",
      "epoch:42 step:33158[D loss: 0.435845, acc: 54.69%, op_acc: 37.50%] [G loss: 0.908029]\n",
      "epoch:42 step:33159[D loss: 0.405426, acc: 62.50%, op_acc: 35.94%] [G loss: 0.998062]\n",
      "epoch:42 step:33160[D loss: 0.373008, acc: 70.31%, op_acc: 42.97%] [G loss: 0.998575]\n",
      "epoch:42 step:33161[D loss: 0.439669, acc: 53.12%, op_acc: 40.62%] [G loss: 0.973406]\n",
      "epoch:42 step:33162[D loss: 0.388972, acc: 64.84%, op_acc: 45.31%] [G loss: 0.963051]\n",
      "epoch:42 step:33163[D loss: 0.374649, acc: 66.41%, op_acc: 45.31%] [G loss: 0.986813]\n",
      "epoch:42 step:33164[D loss: 0.353838, acc: 71.88%, op_acc: 49.22%] [G loss: 0.984117]\n",
      "epoch:42 step:33165[D loss: 0.393761, acc: 66.41%, op_acc: 45.31%] [G loss: 0.914055]\n",
      "epoch:42 step:33166[D loss: 0.421830, acc: 60.94%, op_acc: 37.50%] [G loss: 0.989334]\n",
      "epoch:42 step:33167[D loss: 0.354293, acc: 71.09%, op_acc: 49.22%] [G loss: 0.922364]\n",
      "epoch:42 step:33168[D loss: 0.407205, acc: 57.81%, op_acc: 43.75%] [G loss: 0.949506]\n",
      "epoch:42 step:33169[D loss: 0.424916, acc: 65.62%, op_acc: 36.72%] [G loss: 1.084674]\n",
      "epoch:42 step:33170[D loss: 0.409138, acc: 64.84%, op_acc: 40.62%] [G loss: 0.847675]\n",
      "epoch:42 step:33171[D loss: 0.442974, acc: 61.72%, op_acc: 32.81%] [G loss: 0.798402]\n",
      "epoch:42 step:33172[D loss: 0.426986, acc: 57.81%, op_acc: 39.84%] [G loss: 1.015408]\n",
      "epoch:42 step:33173[D loss: 0.391492, acc: 69.53%, op_acc: 39.06%] [G loss: 0.844793]\n",
      "epoch:42 step:33174[D loss: 0.448546, acc: 47.66%, op_acc: 43.75%] [G loss: 1.023757]\n",
      "epoch:42 step:33175[D loss: 0.421154, acc: 60.94%, op_acc: 41.41%] [G loss: 0.979753]\n",
      "epoch:42 step:33176[D loss: 0.402842, acc: 66.41%, op_acc: 39.06%] [G loss: 0.930896]\n",
      "epoch:42 step:33177[D loss: 0.407014, acc: 61.72%, op_acc: 38.28%] [G loss: 0.917532]\n",
      "epoch:42 step:33178[D loss: 0.404755, acc: 54.69%, op_acc: 39.06%] [G loss: 0.876240]\n",
      "epoch:42 step:33179[D loss: 0.393613, acc: 66.41%, op_acc: 40.62%] [G loss: 0.869055]\n",
      "epoch:42 step:33180[D loss: 0.388169, acc: 66.41%, op_acc: 41.41%] [G loss: 0.952848]\n",
      "epoch:42 step:33181[D loss: 0.384620, acc: 63.28%, op_acc: 48.44%] [G loss: 0.964510]\n",
      "epoch:42 step:33182[D loss: 0.400598, acc: 64.84%, op_acc: 47.66%] [G loss: 0.837629]\n",
      "epoch:42 step:33183[D loss: 0.363129, acc: 68.75%, op_acc: 44.53%] [G loss: 0.911971]\n",
      "epoch:42 step:33184[D loss: 0.443529, acc: 55.47%, op_acc: 36.72%] [G loss: 0.971355]\n",
      "epoch:42 step:33185[D loss: 0.417597, acc: 53.91%, op_acc: 45.31%] [G loss: 0.959212]\n",
      "epoch:42 step:33186[D loss: 0.455837, acc: 52.34%, op_acc: 39.84%] [G loss: 0.840638]\n",
      "epoch:42 step:33187[D loss: 0.407440, acc: 56.25%, op_acc: 42.97%] [G loss: 0.932307]\n",
      "epoch:42 step:33188[D loss: 0.440524, acc: 55.47%, op_acc: 37.50%] [G loss: 0.915469]\n",
      "epoch:42 step:33189[D loss: 0.457172, acc: 54.69%, op_acc: 43.75%] [G loss: 0.889206]\n",
      "epoch:42 step:33190[D loss: 0.422268, acc: 60.16%, op_acc: 36.72%] [G loss: 0.959013]\n",
      "epoch:42 step:33191[D loss: 0.408134, acc: 64.84%, op_acc: 38.28%] [G loss: 1.001713]\n",
      "epoch:42 step:33192[D loss: 0.409993, acc: 60.16%, op_acc: 41.41%] [G loss: 1.004098]\n",
      "epoch:42 step:33193[D loss: 0.426584, acc: 53.91%, op_acc: 44.53%] [G loss: 1.033946]\n",
      "epoch:42 step:33194[D loss: 0.389403, acc: 59.38%, op_acc: 44.53%] [G loss: 0.905276]\n",
      "epoch:42 step:33195[D loss: 0.393665, acc: 66.41%, op_acc: 43.75%] [G loss: 0.933240]\n",
      "epoch:42 step:33196[D loss: 0.400614, acc: 62.50%, op_acc: 42.97%] [G loss: 0.923504]\n",
      "epoch:42 step:33197[D loss: 0.463444, acc: 53.12%, op_acc: 42.19%] [G loss: 0.953816]\n",
      "epoch:42 step:33198[D loss: 0.389145, acc: 62.50%, op_acc: 42.19%] [G loss: 0.942917]\n",
      "epoch:42 step:33199[D loss: 0.430022, acc: 57.81%, op_acc: 45.31%] [G loss: 0.924114]\n",
      "epoch:42 step:33200[D loss: 0.408041, acc: 54.69%, op_acc: 47.66%] [G loss: 0.901493]\n",
      "##############\n",
      "[0.84070681 0.83691524 0.80157614 0.80120589 0.78244903 0.82143169\n",
      " 0.89741429 0.82668149 0.80813994 0.81627157]\n",
      "##########\n",
      "epoch:42 step:33201[D loss: 0.447089, acc: 53.12%, op_acc: 42.97%] [G loss: 0.841267]\n",
      "epoch:42 step:33202[D loss: 0.414452, acc: 59.38%, op_acc: 42.19%] [G loss: 1.013425]\n",
      "epoch:42 step:33203[D loss: 0.414673, acc: 60.94%, op_acc: 36.72%] [G loss: 0.942826]\n",
      "epoch:42 step:33204[D loss: 0.409647, acc: 66.41%, op_acc: 39.06%] [G loss: 0.974280]\n",
      "epoch:42 step:33205[D loss: 0.417430, acc: 62.50%, op_acc: 37.50%] [G loss: 0.901290]\n",
      "epoch:42 step:33206[D loss: 0.375101, acc: 69.53%, op_acc: 49.22%] [G loss: 0.990410]\n",
      "epoch:42 step:33207[D loss: 0.406283, acc: 66.41%, op_acc: 42.19%] [G loss: 0.915278]\n",
      "epoch:42 step:33208[D loss: 0.412011, acc: 61.72%, op_acc: 48.44%] [G loss: 0.879803]\n",
      "epoch:42 step:33209[D loss: 0.407911, acc: 60.16%, op_acc: 40.62%] [G loss: 0.914257]\n",
      "epoch:42 step:33210[D loss: 0.386997, acc: 63.28%, op_acc: 39.84%] [G loss: 0.967172]\n",
      "epoch:42 step:33211[D loss: 0.414503, acc: 60.16%, op_acc: 46.88%] [G loss: 0.868110]\n",
      "epoch:42 step:33212[D loss: 0.419096, acc: 58.59%, op_acc: 42.19%] [G loss: 0.878003]\n",
      "epoch:42 step:33213[D loss: 0.408672, acc: 61.72%, op_acc: 45.31%] [G loss: 0.859396]\n",
      "epoch:42 step:33214[D loss: 0.393050, acc: 63.28%, op_acc: 46.88%] [G loss: 0.768526]\n",
      "epoch:42 step:33215[D loss: 0.399258, acc: 60.16%, op_acc: 46.88%] [G loss: 0.793566]\n",
      "epoch:42 step:33216[D loss: 0.415516, acc: 63.28%, op_acc: 40.62%] [G loss: 0.994640]\n",
      "epoch:42 step:33217[D loss: 0.425475, acc: 58.59%, op_acc: 42.97%] [G loss: 0.959170]\n",
      "epoch:42 step:33218[D loss: 0.419490, acc: 63.28%, op_acc: 40.62%] [G loss: 0.932158]\n",
      "epoch:42 step:33219[D loss: 0.398054, acc: 68.75%, op_acc: 46.09%] [G loss: 0.847110]\n",
      "epoch:42 step:33220[D loss: 0.423182, acc: 60.16%, op_acc: 40.62%] [G loss: 0.851783]\n",
      "epoch:42 step:33221[D loss: 0.404601, acc: 61.72%, op_acc: 40.62%] [G loss: 0.843634]\n",
      "epoch:42 step:33222[D loss: 0.449432, acc: 52.34%, op_acc: 38.28%] [G loss: 0.819374]\n",
      "epoch:42 step:33223[D loss: 0.405734, acc: 63.28%, op_acc: 39.84%] [G loss: 0.869162]\n",
      "epoch:42 step:33224[D loss: 0.388935, acc: 65.62%, op_acc: 48.44%] [G loss: 0.878467]\n",
      "epoch:42 step:33225[D loss: 0.423909, acc: 62.50%, op_acc: 39.06%] [G loss: 1.046486]\n",
      "epoch:42 step:33226[D loss: 0.421934, acc: 63.28%, op_acc: 39.84%] [G loss: 0.983654]\n",
      "epoch:42 step:33227[D loss: 0.412747, acc: 63.28%, op_acc: 42.97%] [G loss: 0.834531]\n",
      "epoch:42 step:33228[D loss: 0.412872, acc: 58.59%, op_acc: 42.19%] [G loss: 0.894751]\n",
      "epoch:42 step:33229[D loss: 0.428996, acc: 59.38%, op_acc: 38.28%] [G loss: 0.860852]\n",
      "epoch:42 step:33230[D loss: 0.384877, acc: 64.06%, op_acc: 48.44%] [G loss: 0.871916]\n",
      "epoch:42 step:33231[D loss: 0.421597, acc: 55.47%, op_acc: 44.53%] [G loss: 0.890032]\n",
      "epoch:42 step:33232[D loss: 0.421616, acc: 55.47%, op_acc: 42.97%] [G loss: 0.831872]\n",
      "epoch:42 step:33233[D loss: 0.423155, acc: 60.94%, op_acc: 42.19%] [G loss: 0.905850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33234[D loss: 0.369574, acc: 64.84%, op_acc: 46.88%] [G loss: 0.928339]\n",
      "epoch:42 step:33235[D loss: 0.395143, acc: 67.97%, op_acc: 46.09%] [G loss: 0.849791]\n",
      "epoch:42 step:33236[D loss: 0.408356, acc: 59.38%, op_acc: 46.09%] [G loss: 0.911461]\n",
      "epoch:42 step:33237[D loss: 0.403407, acc: 63.28%, op_acc: 40.62%] [G loss: 0.961448]\n",
      "epoch:42 step:33238[D loss: 0.405922, acc: 64.84%, op_acc: 44.53%] [G loss: 1.004079]\n",
      "epoch:42 step:33239[D loss: 0.400526, acc: 60.94%, op_acc: 43.75%] [G loss: 0.977082]\n",
      "epoch:42 step:33240[D loss: 0.412212, acc: 63.28%, op_acc: 37.50%] [G loss: 0.905984]\n",
      "epoch:42 step:33241[D loss: 0.456103, acc: 51.56%, op_acc: 39.06%] [G loss: 0.817467]\n",
      "epoch:42 step:33242[D loss: 0.374580, acc: 67.19%, op_acc: 39.84%] [G loss: 0.934975]\n",
      "epoch:42 step:33243[D loss: 0.409241, acc: 56.25%, op_acc: 39.84%] [G loss: 0.818778]\n",
      "epoch:42 step:33244[D loss: 0.405303, acc: 65.62%, op_acc: 42.97%] [G loss: 0.939275]\n",
      "epoch:42 step:33245[D loss: 0.382431, acc: 70.31%, op_acc: 40.62%] [G loss: 0.868049]\n",
      "epoch:42 step:33246[D loss: 0.380195, acc: 67.19%, op_acc: 41.41%] [G loss: 0.947478]\n",
      "epoch:42 step:33247[D loss: 0.422192, acc: 60.16%, op_acc: 40.62%] [G loss: 0.916850]\n",
      "epoch:42 step:33248[D loss: 0.419966, acc: 60.16%, op_acc: 42.19%] [G loss: 0.811849]\n",
      "epoch:42 step:33249[D loss: 0.431359, acc: 67.97%, op_acc: 37.50%] [G loss: 0.911965]\n",
      "epoch:42 step:33250[D loss: 0.424689, acc: 57.81%, op_acc: 41.41%] [G loss: 0.836753]\n",
      "##############\n",
      "[0.83323913 0.86523756 0.81385573 0.81509336 0.78978914 0.83541767\n",
      " 0.90319705 0.82491482 0.81258282 0.8356003 ]\n",
      "##########\n",
      "epoch:42 step:33251[D loss: 0.380129, acc: 65.62%, op_acc: 39.84%] [G loss: 0.866070]\n",
      "epoch:42 step:33252[D loss: 0.410256, acc: 62.50%, op_acc: 37.50%] [G loss: 0.932782]\n",
      "epoch:42 step:33253[D loss: 0.425390, acc: 59.38%, op_acc: 41.41%] [G loss: 0.831982]\n",
      "epoch:42 step:33254[D loss: 0.410214, acc: 61.72%, op_acc: 43.75%] [G loss: 0.884088]\n",
      "epoch:42 step:33255[D loss: 0.408620, acc: 53.91%, op_acc: 40.62%] [G loss: 0.911786]\n",
      "epoch:42 step:33256[D loss: 0.425631, acc: 58.59%, op_acc: 44.53%] [G loss: 0.871787]\n",
      "epoch:42 step:33257[D loss: 0.408260, acc: 57.81%, op_acc: 42.19%] [G loss: 0.984124]\n",
      "epoch:42 step:33258[D loss: 0.433898, acc: 56.25%, op_acc: 39.06%] [G loss: 0.874400]\n",
      "epoch:42 step:33259[D loss: 0.423788, acc: 60.94%, op_acc: 39.84%] [G loss: 0.800884]\n",
      "epoch:42 step:33260[D loss: 0.376638, acc: 73.44%, op_acc: 46.09%] [G loss: 0.944002]\n",
      "epoch:42 step:33261[D loss: 0.397723, acc: 59.38%, op_acc: 45.31%] [G loss: 0.891737]\n",
      "epoch:42 step:33262[D loss: 0.386253, acc: 64.84%, op_acc: 44.53%] [G loss: 0.841317]\n",
      "epoch:42 step:33263[D loss: 0.381338, acc: 67.97%, op_acc: 42.97%] [G loss: 0.870946]\n",
      "epoch:42 step:33264[D loss: 0.410100, acc: 64.06%, op_acc: 46.09%] [G loss: 0.878741]\n",
      "epoch:42 step:33265[D loss: 0.401469, acc: 60.94%, op_acc: 41.41%] [G loss: 0.906448]\n",
      "epoch:42 step:33266[D loss: 0.447664, acc: 58.59%, op_acc: 40.62%] [G loss: 0.879404]\n",
      "epoch:42 step:33267[D loss: 0.406196, acc: 58.59%, op_acc: 42.97%] [G loss: 0.746157]\n",
      "epoch:42 step:33268[D loss: 0.418486, acc: 55.47%, op_acc: 41.41%] [G loss: 0.890375]\n",
      "epoch:42 step:33269[D loss: 0.427236, acc: 60.94%, op_acc: 41.41%] [G loss: 0.839034]\n",
      "epoch:42 step:33270[D loss: 0.407765, acc: 58.59%, op_acc: 42.19%] [G loss: 0.856191]\n",
      "epoch:42 step:33271[D loss: 0.393831, acc: 64.84%, op_acc: 44.53%] [G loss: 0.870386]\n",
      "epoch:42 step:33272[D loss: 0.435299, acc: 49.22%, op_acc: 45.31%] [G loss: 0.836446]\n",
      "epoch:42 step:33273[D loss: 0.427557, acc: 60.94%, op_acc: 42.19%] [G loss: 0.924507]\n",
      "epoch:42 step:33274[D loss: 0.437756, acc: 58.59%, op_acc: 35.94%] [G loss: 0.909659]\n",
      "epoch:42 step:33275[D loss: 0.428754, acc: 55.47%, op_acc: 50.78%] [G loss: 0.899277]\n",
      "epoch:42 step:33276[D loss: 0.382501, acc: 69.53%, op_acc: 40.62%] [G loss: 1.060637]\n",
      "epoch:42 step:33277[D loss: 0.399734, acc: 61.72%, op_acc: 53.12%] [G loss: 0.921090]\n",
      "epoch:42 step:33278[D loss: 0.418825, acc: 58.59%, op_acc: 42.97%] [G loss: 0.880404]\n",
      "epoch:42 step:33279[D loss: 0.444370, acc: 57.03%, op_acc: 39.06%] [G loss: 0.881234]\n",
      "epoch:42 step:33280[D loss: 0.389564, acc: 64.84%, op_acc: 43.75%] [G loss: 1.055877]\n",
      "epoch:42 step:33281[D loss: 0.441105, acc: 57.81%, op_acc: 41.41%] [G loss: 0.826559]\n",
      "epoch:42 step:33282[D loss: 0.425257, acc: 58.59%, op_acc: 39.06%] [G loss: 0.887981]\n",
      "epoch:42 step:33283[D loss: 0.467229, acc: 52.34%, op_acc: 35.94%] [G loss: 0.862815]\n",
      "epoch:42 step:33284[D loss: 0.393251, acc: 76.56%, op_acc: 42.97%] [G loss: 0.940671]\n",
      "epoch:42 step:33285[D loss: 0.410024, acc: 60.94%, op_acc: 41.41%] [G loss: 0.862136]\n",
      "epoch:42 step:33286[D loss: 0.384570, acc: 64.06%, op_acc: 45.31%] [G loss: 0.922190]\n",
      "epoch:42 step:33287[D loss: 0.430320, acc: 60.94%, op_acc: 42.19%] [G loss: 0.863304]\n",
      "epoch:42 step:33288[D loss: 0.393403, acc: 60.16%, op_acc: 38.28%] [G loss: 0.815036]\n",
      "epoch:42 step:33289[D loss: 0.426589, acc: 55.47%, op_acc: 36.72%] [G loss: 0.800544]\n",
      "epoch:42 step:33290[D loss: 0.407067, acc: 60.94%, op_acc: 39.84%] [G loss: 0.805849]\n",
      "epoch:42 step:33291[D loss: 0.434636, acc: 61.72%, op_acc: 39.06%] [G loss: 0.800421]\n",
      "epoch:42 step:33292[D loss: 0.389533, acc: 64.84%, op_acc: 42.97%] [G loss: 0.896080]\n",
      "epoch:42 step:33293[D loss: 0.440324, acc: 58.59%, op_acc: 34.38%] [G loss: 1.008158]\n",
      "epoch:42 step:33294[D loss: 0.422626, acc: 52.34%, op_acc: 43.75%] [G loss: 0.926315]\n",
      "epoch:42 step:33295[D loss: 0.421142, acc: 61.72%, op_acc: 36.72%] [G loss: 0.784749]\n",
      "epoch:42 step:33296[D loss: 0.404598, acc: 57.81%, op_acc: 41.41%] [G loss: 0.957709]\n",
      "epoch:42 step:33297[D loss: 0.426870, acc: 59.38%, op_acc: 40.62%] [G loss: 0.943301]\n",
      "epoch:42 step:33298[D loss: 0.414918, acc: 54.69%, op_acc: 42.97%] [G loss: 0.858169]\n",
      "epoch:42 step:33299[D loss: 0.381590, acc: 67.97%, op_acc: 47.66%] [G loss: 0.936617]\n",
      "epoch:42 step:33300[D loss: 0.429426, acc: 57.81%, op_acc: 39.84%] [G loss: 0.902223]\n",
      "##############\n",
      "[0.85263952 0.85586746 0.82501533 0.81293278 0.7896902  0.83123795\n",
      " 0.88782784 0.81018945 0.80834179 0.8394089 ]\n",
      "##########\n",
      "epoch:42 step:33301[D loss: 0.436895, acc: 63.28%, op_acc: 35.94%] [G loss: 0.795107]\n",
      "epoch:42 step:33302[D loss: 0.428754, acc: 56.25%, op_acc: 36.72%] [G loss: 0.865192]\n",
      "epoch:42 step:33303[D loss: 0.402065, acc: 70.31%, op_acc: 37.50%] [G loss: 0.828824]\n",
      "epoch:42 step:33304[D loss: 0.404652, acc: 60.94%, op_acc: 40.62%] [G loss: 0.809184]\n",
      "epoch:42 step:33305[D loss: 0.398004, acc: 64.06%, op_acc: 42.19%] [G loss: 0.807034]\n",
      "epoch:42 step:33306[D loss: 0.422989, acc: 58.59%, op_acc: 50.00%] [G loss: 0.904828]\n",
      "epoch:42 step:33307[D loss: 0.407441, acc: 63.28%, op_acc: 39.84%] [G loss: 0.930035]\n",
      "epoch:42 step:33308[D loss: 0.414663, acc: 55.47%, op_acc: 45.31%] [G loss: 0.919836]\n",
      "epoch:42 step:33309[D loss: 0.397865, acc: 59.38%, op_acc: 46.09%] [G loss: 0.909273]\n",
      "epoch:42 step:33310[D loss: 0.407231, acc: 57.81%, op_acc: 42.97%] [G loss: 0.897902]\n",
      "epoch:42 step:33311[D loss: 0.423932, acc: 54.69%, op_acc: 41.41%] [G loss: 0.865497]\n",
      "epoch:42 step:33312[D loss: 0.414478, acc: 60.94%, op_acc: 39.84%] [G loss: 1.002686]\n",
      "epoch:42 step:33313[D loss: 0.425592, acc: 59.38%, op_acc: 46.09%] [G loss: 0.860095]\n",
      "epoch:42 step:33314[D loss: 0.425365, acc: 53.91%, op_acc: 42.97%] [G loss: 0.907552]\n",
      "epoch:42 step:33315[D loss: 0.420405, acc: 59.38%, op_acc: 42.19%] [G loss: 0.855296]\n",
      "epoch:42 step:33316[D loss: 0.394666, acc: 67.19%, op_acc: 43.75%] [G loss: 0.871600]\n",
      "epoch:42 step:33317[D loss: 0.402006, acc: 64.06%, op_acc: 35.16%] [G loss: 0.891607]\n",
      "epoch:42 step:33318[D loss: 0.402703, acc: 67.97%, op_acc: 41.41%] [G loss: 0.942716]\n",
      "epoch:42 step:33319[D loss: 0.415518, acc: 58.59%, op_acc: 42.97%] [G loss: 0.914730]\n",
      "epoch:42 step:33320[D loss: 0.411421, acc: 58.59%, op_acc: 42.97%] [G loss: 0.937678]\n",
      "epoch:42 step:33321[D loss: 0.399496, acc: 62.50%, op_acc: 43.75%] [G loss: 0.871079]\n",
      "epoch:42 step:33322[D loss: 0.418453, acc: 54.69%, op_acc: 41.41%] [G loss: 0.960321]\n",
      "epoch:42 step:33323[D loss: 0.373739, acc: 75.00%, op_acc: 42.97%] [G loss: 0.912930]\n",
      "epoch:42 step:33324[D loss: 0.383555, acc: 62.50%, op_acc: 44.53%] [G loss: 0.853361]\n",
      "epoch:42 step:33325[D loss: 0.374023, acc: 67.97%, op_acc: 42.19%] [G loss: 0.884409]\n",
      "epoch:42 step:33326[D loss: 0.396353, acc: 71.09%, op_acc: 40.62%] [G loss: 0.904148]\n",
      "epoch:42 step:33327[D loss: 0.430397, acc: 60.94%, op_acc: 39.84%] [G loss: 0.874761]\n",
      "epoch:42 step:33328[D loss: 0.463357, acc: 54.69%, op_acc: 38.28%] [G loss: 0.944135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33329[D loss: 0.438487, acc: 51.56%, op_acc: 36.72%] [G loss: 0.863009]\n",
      "epoch:42 step:33330[D loss: 0.410824, acc: 60.16%, op_acc: 43.75%] [G loss: 0.965202]\n",
      "epoch:42 step:33331[D loss: 0.404045, acc: 63.28%, op_acc: 42.19%] [G loss: 1.026983]\n",
      "epoch:42 step:33332[D loss: 0.430284, acc: 59.38%, op_acc: 42.19%] [G loss: 0.957641]\n",
      "epoch:42 step:33333[D loss: 0.419703, acc: 59.38%, op_acc: 37.50%] [G loss: 0.922239]\n",
      "epoch:42 step:33334[D loss: 0.435374, acc: 64.84%, op_acc: 39.84%] [G loss: 0.941779]\n",
      "epoch:42 step:33335[D loss: 0.411507, acc: 57.81%, op_acc: 39.06%] [G loss: 0.938027]\n",
      "epoch:42 step:33336[D loss: 0.386633, acc: 61.72%, op_acc: 47.66%] [G loss: 0.872983]\n",
      "epoch:42 step:33337[D loss: 0.444442, acc: 57.03%, op_acc: 42.19%] [G loss: 0.982488]\n",
      "epoch:42 step:33338[D loss: 0.385656, acc: 60.16%, op_acc: 42.19%] [G loss: 0.892879]\n",
      "epoch:42 step:33339[D loss: 0.439769, acc: 57.03%, op_acc: 38.28%] [G loss: 0.927920]\n",
      "epoch:42 step:33340[D loss: 0.393316, acc: 60.94%, op_acc: 41.41%] [G loss: 0.908195]\n",
      "epoch:42 step:33341[D loss: 0.419919, acc: 56.25%, op_acc: 39.06%] [G loss: 0.940381]\n",
      "epoch:42 step:33342[D loss: 0.416755, acc: 55.47%, op_acc: 45.31%] [G loss: 0.922890]\n",
      "epoch:42 step:33343[D loss: 0.413027, acc: 57.03%, op_acc: 39.84%] [G loss: 0.915336]\n",
      "epoch:42 step:33344[D loss: 0.434572, acc: 50.78%, op_acc: 39.84%] [G loss: 0.904361]\n",
      "epoch:42 step:33345[D loss: 0.417193, acc: 59.38%, op_acc: 39.84%] [G loss: 0.943111]\n",
      "epoch:42 step:33346[D loss: 0.401250, acc: 65.62%, op_acc: 46.09%] [G loss: 0.792245]\n",
      "epoch:42 step:33347[D loss: 0.370595, acc: 72.66%, op_acc: 42.19%] [G loss: 0.950065]\n",
      "epoch:42 step:33348[D loss: 0.402606, acc: 63.28%, op_acc: 36.72%] [G loss: 0.968781]\n",
      "epoch:42 step:33349[D loss: 0.429736, acc: 57.81%, op_acc: 42.97%] [G loss: 0.918412]\n",
      "epoch:42 step:33350[D loss: 0.416649, acc: 65.62%, op_acc: 39.06%] [G loss: 0.899700]\n",
      "##############\n",
      "[0.85687518 0.85815234 0.79397299 0.79960999 0.80332835 0.83323907\n",
      " 0.8873919  0.8292071  0.8168418  0.80642231]\n",
      "##########\n",
      "epoch:42 step:33351[D loss: 0.386381, acc: 63.28%, op_acc: 42.97%] [G loss: 0.976202]\n",
      "epoch:42 step:33352[D loss: 0.403985, acc: 57.81%, op_acc: 44.53%] [G loss: 0.876793]\n",
      "epoch:42 step:33353[D loss: 0.405660, acc: 62.50%, op_acc: 42.19%] [G loss: 0.879643]\n",
      "epoch:42 step:33354[D loss: 0.450919, acc: 56.25%, op_acc: 38.28%] [G loss: 0.880361]\n",
      "epoch:42 step:33355[D loss: 0.388468, acc: 67.19%, op_acc: 38.28%] [G loss: 0.865605]\n",
      "epoch:42 step:33356[D loss: 0.385653, acc: 64.84%, op_acc: 42.19%] [G loss: 0.952599]\n",
      "epoch:42 step:33357[D loss: 0.410516, acc: 61.72%, op_acc: 40.62%] [G loss: 0.877288]\n",
      "epoch:42 step:33358[D loss: 0.418792, acc: 57.81%, op_acc: 40.62%] [G loss: 0.964645]\n",
      "epoch:42 step:33359[D loss: 0.427573, acc: 53.91%, op_acc: 39.84%] [G loss: 0.986112]\n",
      "epoch:42 step:33360[D loss: 0.385022, acc: 66.41%, op_acc: 42.97%] [G loss: 0.944220]\n",
      "epoch:42 step:33361[D loss: 0.389241, acc: 66.41%, op_acc: 44.53%] [G loss: 0.860733]\n",
      "epoch:42 step:33362[D loss: 0.409867, acc: 63.28%, op_acc: 44.53%] [G loss: 0.885241]\n",
      "epoch:42 step:33363[D loss: 0.426153, acc: 55.47%, op_acc: 41.41%] [G loss: 0.867788]\n",
      "epoch:42 step:33364[D loss: 0.431200, acc: 53.12%, op_acc: 38.28%] [G loss: 0.896842]\n",
      "epoch:42 step:33365[D loss: 0.398643, acc: 71.09%, op_acc: 40.62%] [G loss: 0.954946]\n",
      "epoch:42 step:33366[D loss: 0.409947, acc: 59.38%, op_acc: 42.19%] [G loss: 0.835121]\n",
      "epoch:42 step:33367[D loss: 0.446651, acc: 48.44%, op_acc: 39.84%] [G loss: 0.943188]\n",
      "epoch:42 step:33368[D loss: 0.404448, acc: 60.94%, op_acc: 39.84%] [G loss: 0.874638]\n",
      "epoch:42 step:33369[D loss: 0.388650, acc: 64.06%, op_acc: 45.31%] [G loss: 0.823699]\n",
      "epoch:42 step:33370[D loss: 0.431552, acc: 57.03%, op_acc: 38.28%] [G loss: 0.849448]\n",
      "epoch:42 step:33371[D loss: 0.384695, acc: 58.59%, op_acc: 40.62%] [G loss: 0.907950]\n",
      "epoch:42 step:33372[D loss: 0.412758, acc: 63.28%, op_acc: 43.75%] [G loss: 0.960813]\n",
      "epoch:42 step:33373[D loss: 0.409782, acc: 57.81%, op_acc: 50.78%] [G loss: 0.860142]\n",
      "epoch:42 step:33374[D loss: 0.374170, acc: 71.88%, op_acc: 44.53%] [G loss: 0.869903]\n",
      "epoch:42 step:33375[D loss: 0.413241, acc: 65.62%, op_acc: 44.53%] [G loss: 0.861213]\n",
      "epoch:42 step:33376[D loss: 0.401170, acc: 64.84%, op_acc: 43.75%] [G loss: 0.771750]\n",
      "epoch:42 step:33377[D loss: 0.393429, acc: 63.28%, op_acc: 46.88%] [G loss: 0.902055]\n",
      "epoch:42 step:33378[D loss: 0.397489, acc: 68.75%, op_acc: 42.19%] [G loss: 0.942500]\n",
      "epoch:42 step:33379[D loss: 0.463751, acc: 56.25%, op_acc: 36.72%] [G loss: 0.823356]\n",
      "epoch:42 step:33380[D loss: 0.416866, acc: 60.94%, op_acc: 41.41%] [G loss: 0.951104]\n",
      "epoch:42 step:33381[D loss: 0.404824, acc: 65.62%, op_acc: 44.53%] [G loss: 1.021339]\n",
      "epoch:42 step:33382[D loss: 0.399604, acc: 64.06%, op_acc: 43.75%] [G loss: 1.030034]\n",
      "epoch:42 step:33383[D loss: 0.423503, acc: 57.03%, op_acc: 42.97%] [G loss: 0.924174]\n",
      "epoch:42 step:33384[D loss: 0.408103, acc: 64.84%, op_acc: 43.75%] [G loss: 0.948243]\n",
      "epoch:42 step:33385[D loss: 0.380362, acc: 67.97%, op_acc: 45.31%] [G loss: 0.963620]\n",
      "epoch:42 step:33386[D loss: 0.424156, acc: 57.03%, op_acc: 41.41%] [G loss: 0.952926]\n",
      "epoch:42 step:33387[D loss: 0.397021, acc: 60.16%, op_acc: 42.97%] [G loss: 0.938708]\n",
      "epoch:42 step:33388[D loss: 0.386934, acc: 70.31%, op_acc: 45.31%] [G loss: 0.923480]\n",
      "epoch:42 step:33389[D loss: 0.393730, acc: 66.41%, op_acc: 42.19%] [G loss: 0.965501]\n",
      "epoch:42 step:33390[D loss: 0.384903, acc: 66.41%, op_acc: 45.31%] [G loss: 1.018382]\n",
      "epoch:42 step:33391[D loss: 0.423664, acc: 57.81%, op_acc: 42.97%] [G loss: 0.925940]\n",
      "epoch:42 step:33392[D loss: 0.394850, acc: 64.06%, op_acc: 46.09%] [G loss: 0.826734]\n",
      "epoch:42 step:33393[D loss: 0.451094, acc: 47.66%, op_acc: 36.72%] [G loss: 0.800869]\n",
      "epoch:42 step:33394[D loss: 0.410958, acc: 59.38%, op_acc: 48.44%] [G loss: 0.908877]\n",
      "epoch:42 step:33395[D loss: 0.431698, acc: 66.41%, op_acc: 38.28%] [G loss: 0.888478]\n",
      "epoch:42 step:33396[D loss: 0.416414, acc: 63.28%, op_acc: 40.62%] [G loss: 0.939376]\n",
      "epoch:42 step:33397[D loss: 0.395122, acc: 66.41%, op_acc: 39.84%] [G loss: 1.073711]\n",
      "epoch:42 step:33398[D loss: 0.391207, acc: 60.94%, op_acc: 42.19%] [G loss: 0.876210]\n",
      "epoch:42 step:33399[D loss: 0.391741, acc: 67.19%, op_acc: 42.97%] [G loss: 0.924011]\n",
      "epoch:42 step:33400[D loss: 0.409821, acc: 62.50%, op_acc: 44.53%] [G loss: 0.948751]\n",
      "##############\n",
      "[0.8599189  0.87410265 0.81758311 0.78772201 0.78442533 0.84031946\n",
      " 0.86046096 0.82425708 0.8018006  0.8337737 ]\n",
      "##########\n",
      "epoch:42 step:33401[D loss: 0.442448, acc: 58.59%, op_acc: 38.28%] [G loss: 0.858748]\n",
      "epoch:42 step:33402[D loss: 0.464681, acc: 48.44%, op_acc: 42.19%] [G loss: 0.863465]\n",
      "epoch:42 step:33403[D loss: 0.421395, acc: 56.25%, op_acc: 39.84%] [G loss: 0.829141]\n",
      "epoch:42 step:33404[D loss: 0.386554, acc: 65.62%, op_acc: 43.75%] [G loss: 0.930103]\n",
      "epoch:42 step:33405[D loss: 0.411179, acc: 61.72%, op_acc: 44.53%] [G loss: 0.875407]\n",
      "epoch:42 step:33406[D loss: 0.445437, acc: 60.94%, op_acc: 32.03%] [G loss: 0.924127]\n",
      "epoch:42 step:33407[D loss: 0.416057, acc: 65.62%, op_acc: 38.28%] [G loss: 0.929239]\n",
      "epoch:42 step:33408[D loss: 0.412330, acc: 57.81%, op_acc: 45.31%] [G loss: 0.940152]\n",
      "epoch:42 step:33409[D loss: 0.415922, acc: 59.38%, op_acc: 41.41%] [G loss: 0.898353]\n",
      "epoch:42 step:33410[D loss: 0.356661, acc: 76.56%, op_acc: 46.09%] [G loss: 0.987832]\n",
      "epoch:42 step:33411[D loss: 0.401521, acc: 66.41%, op_acc: 42.97%] [G loss: 0.939508]\n",
      "epoch:42 step:33412[D loss: 0.387328, acc: 67.97%, op_acc: 46.88%] [G loss: 0.847587]\n",
      "epoch:42 step:33413[D loss: 0.419123, acc: 60.94%, op_acc: 48.44%] [G loss: 0.889398]\n",
      "epoch:42 step:33414[D loss: 0.412287, acc: 54.69%, op_acc: 46.09%] [G loss: 0.899542]\n",
      "epoch:42 step:33415[D loss: 0.452524, acc: 48.44%, op_acc: 42.97%] [G loss: 0.839154]\n",
      "epoch:42 step:33416[D loss: 0.395792, acc: 65.62%, op_acc: 42.19%] [G loss: 0.915297]\n",
      "epoch:42 step:33417[D loss: 0.404535, acc: 60.16%, op_acc: 42.97%] [G loss: 0.802174]\n",
      "epoch:42 step:33418[D loss: 0.452655, acc: 52.34%, op_acc: 35.16%] [G loss: 0.891545]\n",
      "epoch:42 step:33419[D loss: 0.426060, acc: 54.69%, op_acc: 41.41%] [G loss: 0.890852]\n",
      "epoch:42 step:33420[D loss: 0.390964, acc: 60.94%, op_acc: 43.75%] [G loss: 0.832649]\n",
      "epoch:42 step:33421[D loss: 0.428421, acc: 59.38%, op_acc: 39.84%] [G loss: 0.909756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33422[D loss: 0.390734, acc: 65.62%, op_acc: 42.19%] [G loss: 0.948445]\n",
      "epoch:42 step:33423[D loss: 0.404276, acc: 67.19%, op_acc: 39.06%] [G loss: 0.878101]\n",
      "epoch:42 step:33424[D loss: 0.455629, acc: 57.81%, op_acc: 32.81%] [G loss: 0.935728]\n",
      "epoch:42 step:33425[D loss: 0.395926, acc: 63.28%, op_acc: 44.53%] [G loss: 0.890697]\n",
      "epoch:42 step:33426[D loss: 0.430222, acc: 53.91%, op_acc: 45.31%] [G loss: 0.962101]\n",
      "epoch:42 step:33427[D loss: 0.445989, acc: 50.00%, op_acc: 42.19%] [G loss: 0.926619]\n",
      "epoch:42 step:33428[D loss: 0.378081, acc: 66.41%, op_acc: 46.09%] [G loss: 1.063146]\n",
      "epoch:42 step:33429[D loss: 0.410022, acc: 59.38%, op_acc: 45.31%] [G loss: 0.814986]\n",
      "epoch:42 step:33430[D loss: 0.426458, acc: 56.25%, op_acc: 40.62%] [G loss: 0.973449]\n",
      "epoch:42 step:33431[D loss: 0.448685, acc: 53.12%, op_acc: 42.97%] [G loss: 0.942370]\n",
      "epoch:42 step:33432[D loss: 0.392523, acc: 64.06%, op_acc: 42.97%] [G loss: 0.964318]\n",
      "epoch:42 step:33433[D loss: 0.406348, acc: 64.84%, op_acc: 46.88%] [G loss: 1.073422]\n",
      "epoch:42 step:33434[D loss: 0.412942, acc: 60.94%, op_acc: 41.41%] [G loss: 0.882071]\n",
      "epoch:42 step:33435[D loss: 0.408668, acc: 68.75%, op_acc: 34.38%] [G loss: 0.878343]\n",
      "epoch:42 step:33436[D loss: 0.421188, acc: 58.59%, op_acc: 43.75%] [G loss: 0.799751]\n",
      "epoch:42 step:33437[D loss: 0.427154, acc: 60.16%, op_acc: 37.50%] [G loss: 0.917174]\n",
      "epoch:42 step:33438[D loss: 0.432896, acc: 57.03%, op_acc: 42.97%] [G loss: 0.950959]\n",
      "epoch:42 step:33439[D loss: 0.369346, acc: 70.31%, op_acc: 43.75%] [G loss: 1.011460]\n",
      "epoch:42 step:33440[D loss: 0.403620, acc: 53.12%, op_acc: 44.53%] [G loss: 0.950244]\n",
      "epoch:42 step:33441[D loss: 0.405017, acc: 60.94%, op_acc: 42.97%] [G loss: 0.800716]\n",
      "epoch:42 step:33442[D loss: 0.396348, acc: 66.41%, op_acc: 44.53%] [G loss: 1.034752]\n",
      "epoch:42 step:33443[D loss: 0.430385, acc: 57.03%, op_acc: 40.62%] [G loss: 0.825839]\n",
      "epoch:42 step:33444[D loss: 0.455081, acc: 56.25%, op_acc: 38.28%] [G loss: 0.967690]\n",
      "epoch:42 step:33445[D loss: 0.402529, acc: 63.28%, op_acc: 39.06%] [G loss: 1.000174]\n",
      "epoch:42 step:33446[D loss: 0.369265, acc: 64.84%, op_acc: 52.34%] [G loss: 1.084478]\n",
      "epoch:42 step:33447[D loss: 0.369098, acc: 75.00%, op_acc: 40.62%] [G loss: 1.002847]\n",
      "epoch:42 step:33448[D loss: 0.383985, acc: 71.88%, op_acc: 43.75%] [G loss: 1.017379]\n",
      "epoch:42 step:33449[D loss: 0.411137, acc: 57.81%, op_acc: 44.53%] [G loss: 0.871503]\n",
      "epoch:42 step:33450[D loss: 0.384707, acc: 62.50%, op_acc: 42.97%] [G loss: 0.972842]\n",
      "##############\n",
      "[0.85772227 0.87513857 0.81837018 0.80386246 0.80393056 0.82955705\n",
      " 0.88386363 0.83908839 0.80580291 0.82969268]\n",
      "##########\n",
      "epoch:42 step:33451[D loss: 0.395181, acc: 62.50%, op_acc: 39.84%] [G loss: 0.917242]\n",
      "epoch:42 step:33452[D loss: 0.439636, acc: 58.59%, op_acc: 43.75%] [G loss: 0.966458]\n",
      "epoch:42 step:33453[D loss: 0.398297, acc: 64.06%, op_acc: 42.19%] [G loss: 0.989833]\n",
      "epoch:42 step:33454[D loss: 0.428665, acc: 53.12%, op_acc: 46.09%] [G loss: 0.867014]\n",
      "epoch:42 step:33455[D loss: 0.392375, acc: 61.72%, op_acc: 46.88%] [G loss: 0.916199]\n",
      "epoch:42 step:33456[D loss: 0.397962, acc: 64.06%, op_acc: 46.09%] [G loss: 0.864538]\n",
      "epoch:42 step:33457[D loss: 0.398708, acc: 64.06%, op_acc: 43.75%] [G loss: 0.972329]\n",
      "epoch:42 step:33458[D loss: 0.411755, acc: 66.41%, op_acc: 43.75%] [G loss: 0.884730]\n",
      "epoch:42 step:33459[D loss: 0.452930, acc: 56.25%, op_acc: 40.62%] [G loss: 0.904481]\n",
      "epoch:42 step:33460[D loss: 0.408995, acc: 67.97%, op_acc: 42.19%] [G loss: 0.963051]\n",
      "epoch:42 step:33461[D loss: 0.418338, acc: 60.16%, op_acc: 41.41%] [G loss: 1.016739]\n",
      "epoch:42 step:33462[D loss: 0.397373, acc: 66.41%, op_acc: 45.31%] [G loss: 0.961401]\n",
      "epoch:42 step:33463[D loss: 0.410691, acc: 55.47%, op_acc: 46.88%] [G loss: 0.856629]\n",
      "epoch:42 step:33464[D loss: 0.395994, acc: 60.16%, op_acc: 42.97%] [G loss: 0.913120]\n",
      "epoch:42 step:33465[D loss: 0.412499, acc: 53.91%, op_acc: 43.75%] [G loss: 0.831208]\n",
      "epoch:42 step:33466[D loss: 0.399320, acc: 64.84%, op_acc: 38.28%] [G loss: 0.897245]\n",
      "epoch:42 step:33467[D loss: 0.462083, acc: 55.47%, op_acc: 34.38%] [G loss: 0.986542]\n",
      "epoch:42 step:33468[D loss: 0.430504, acc: 57.81%, op_acc: 39.06%] [G loss: 1.011546]\n",
      "epoch:42 step:33469[D loss: 0.403393, acc: 60.94%, op_acc: 47.66%] [G loss: 1.022240]\n",
      "epoch:42 step:33470[D loss: 0.427624, acc: 58.59%, op_acc: 42.19%] [G loss: 0.830901]\n",
      "epoch:42 step:33471[D loss: 0.415056, acc: 60.16%, op_acc: 38.28%] [G loss: 0.964045]\n",
      "epoch:42 step:33472[D loss: 0.424124, acc: 56.25%, op_acc: 40.62%] [G loss: 0.957541]\n",
      "epoch:42 step:33473[D loss: 0.419061, acc: 53.12%, op_acc: 39.06%] [G loss: 1.016068]\n",
      "epoch:42 step:33474[D loss: 0.443586, acc: 55.47%, op_acc: 39.06%] [G loss: 0.887688]\n",
      "epoch:42 step:33475[D loss: 0.434313, acc: 60.94%, op_acc: 36.72%] [G loss: 0.919861]\n",
      "epoch:42 step:33476[D loss: 0.409913, acc: 61.72%, op_acc: 42.19%] [G loss: 0.922253]\n",
      "epoch:42 step:33477[D loss: 0.443112, acc: 51.56%, op_acc: 38.28%] [G loss: 0.884470]\n",
      "epoch:42 step:33478[D loss: 0.460064, acc: 53.91%, op_acc: 32.03%] [G loss: 0.892766]\n",
      "epoch:42 step:33479[D loss: 0.431036, acc: 55.47%, op_acc: 37.50%] [G loss: 0.917683]\n",
      "epoch:42 step:33480[D loss: 0.421134, acc: 56.25%, op_acc: 39.84%] [G loss: 0.826071]\n",
      "epoch:42 step:33481[D loss: 0.386794, acc: 58.59%, op_acc: 49.22%] [G loss: 0.980971]\n",
      "epoch:42 step:33482[D loss: 0.433207, acc: 60.16%, op_acc: 42.97%] [G loss: 0.848550]\n",
      "epoch:42 step:33483[D loss: 0.411884, acc: 64.06%, op_acc: 39.84%] [G loss: 0.869922]\n",
      "epoch:42 step:33484[D loss: 0.400486, acc: 57.03%, op_acc: 44.53%] [G loss: 0.983975]\n",
      "epoch:42 step:33485[D loss: 0.393337, acc: 71.09%, op_acc: 41.41%] [G loss: 0.675735]\n",
      "epoch:42 step:33486[D loss: 0.438722, acc: 58.59%, op_acc: 39.84%] [G loss: 0.894445]\n",
      "epoch:42 step:33487[D loss: 0.410289, acc: 64.84%, op_acc: 45.31%] [G loss: 0.848095]\n",
      "epoch:42 step:33488[D loss: 0.456321, acc: 50.78%, op_acc: 39.06%] [G loss: 0.839248]\n",
      "epoch:42 step:33489[D loss: 0.421769, acc: 57.81%, op_acc: 39.06%] [G loss: 0.840053]\n",
      "epoch:42 step:33490[D loss: 0.409793, acc: 57.81%, op_acc: 44.53%] [G loss: 0.979822]\n",
      "epoch:42 step:33491[D loss: 0.431555, acc: 55.47%, op_acc: 39.06%] [G loss: 0.941541]\n",
      "epoch:42 step:33492[D loss: 0.411757, acc: 61.72%, op_acc: 39.84%] [G loss: 0.938225]\n",
      "epoch:42 step:33493[D loss: 0.402533, acc: 68.75%, op_acc: 41.41%] [G loss: 0.875336]\n",
      "epoch:42 step:33494[D loss: 0.422632, acc: 60.94%, op_acc: 40.62%] [G loss: 0.909455]\n",
      "epoch:42 step:33495[D loss: 0.387924, acc: 64.84%, op_acc: 44.53%] [G loss: 1.021933]\n",
      "epoch:42 step:33496[D loss: 0.430799, acc: 53.12%, op_acc: 43.75%] [G loss: 0.804929]\n",
      "epoch:42 step:33497[D loss: 0.405323, acc: 65.62%, op_acc: 42.19%] [G loss: 0.874094]\n",
      "epoch:42 step:33498[D loss: 0.394354, acc: 60.16%, op_acc: 45.31%] [G loss: 0.893931]\n",
      "epoch:42 step:33499[D loss: 0.419552, acc: 57.03%, op_acc: 41.41%] [G loss: 0.930995]\n",
      "epoch:42 step:33500[D loss: 0.386334, acc: 67.19%, op_acc: 44.53%] [G loss: 0.821279]\n",
      "##############\n",
      "[0.85238045 0.86125794 0.81306007 0.80968826 0.80589855 0.84366422\n",
      " 0.85993177 0.82938459 0.81726821 0.83127234]\n",
      "##########\n",
      "epoch:42 step:33501[D loss: 0.412633, acc: 60.16%, op_acc: 37.50%] [G loss: 0.853578]\n",
      "epoch:42 step:33502[D loss: 0.394588, acc: 65.62%, op_acc: 45.31%] [G loss: 0.846296]\n",
      "epoch:42 step:33503[D loss: 0.418566, acc: 60.16%, op_acc: 39.84%] [G loss: 0.833479]\n",
      "epoch:42 step:33504[D loss: 0.417335, acc: 57.81%, op_acc: 40.62%] [G loss: 0.940191]\n",
      "epoch:42 step:33505[D loss: 0.450630, acc: 55.47%, op_acc: 39.84%] [G loss: 0.977464]\n",
      "epoch:42 step:33506[D loss: 0.423203, acc: 57.03%, op_acc: 45.31%] [G loss: 0.913735]\n",
      "epoch:42 step:33507[D loss: 0.413557, acc: 68.75%, op_acc: 35.94%] [G loss: 0.929953]\n",
      "epoch:42 step:33508[D loss: 0.423377, acc: 58.59%, op_acc: 42.19%] [G loss: 0.965053]\n",
      "epoch:42 step:33509[D loss: 0.425783, acc: 57.81%, op_acc: 38.28%] [G loss: 0.917260]\n",
      "epoch:42 step:33510[D loss: 0.424883, acc: 61.72%, op_acc: 43.75%] [G loss: 0.899492]\n",
      "epoch:42 step:33511[D loss: 0.410087, acc: 58.59%, op_acc: 43.75%] [G loss: 0.867216]\n",
      "epoch:42 step:33512[D loss: 0.369431, acc: 64.06%, op_acc: 45.31%] [G loss: 0.934299]\n",
      "epoch:42 step:33513[D loss: 0.437214, acc: 56.25%, op_acc: 35.94%] [G loss: 0.889270]\n",
      "epoch:42 step:33514[D loss: 0.396510, acc: 64.06%, op_acc: 46.09%] [G loss: 0.932088]\n",
      "epoch:42 step:33515[D loss: 0.398854, acc: 64.84%, op_acc: 43.75%] [G loss: 0.802555]\n",
      "epoch:42 step:33516[D loss: 0.401472, acc: 60.94%, op_acc: 43.75%] [G loss: 0.925475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33517[D loss: 0.393246, acc: 60.94%, op_acc: 46.09%] [G loss: 0.938670]\n",
      "epoch:42 step:33518[D loss: 0.384668, acc: 61.72%, op_acc: 42.19%] [G loss: 0.798052]\n",
      "epoch:42 step:33519[D loss: 0.400171, acc: 60.16%, op_acc: 44.53%] [G loss: 0.956153]\n",
      "epoch:42 step:33520[D loss: 0.389916, acc: 64.84%, op_acc: 47.66%] [G loss: 1.025404]\n",
      "epoch:42 step:33521[D loss: 0.410320, acc: 61.72%, op_acc: 46.09%] [G loss: 0.820659]\n",
      "epoch:42 step:33522[D loss: 0.400325, acc: 73.44%, op_acc: 44.53%] [G loss: 0.855873]\n",
      "epoch:42 step:33523[D loss: 0.415357, acc: 57.03%, op_acc: 43.75%] [G loss: 0.842913]\n",
      "epoch:42 step:33524[D loss: 0.395732, acc: 67.19%, op_acc: 42.19%] [G loss: 0.814644]\n",
      "epoch:42 step:33525[D loss: 0.415703, acc: 61.72%, op_acc: 39.84%] [G loss: 0.940980]\n",
      "epoch:42 step:33526[D loss: 0.438071, acc: 64.84%, op_acc: 35.94%] [G loss: 0.935398]\n",
      "epoch:42 step:33527[D loss: 0.425146, acc: 59.38%, op_acc: 37.50%] [G loss: 0.843209]\n",
      "epoch:42 step:33528[D loss: 0.413038, acc: 63.28%, op_acc: 39.84%] [G loss: 0.958982]\n",
      "epoch:42 step:33529[D loss: 0.441713, acc: 52.34%, op_acc: 39.06%] [G loss: 0.887842]\n",
      "epoch:42 step:33530[D loss: 0.430404, acc: 60.94%, op_acc: 35.94%] [G loss: 0.878737]\n",
      "epoch:42 step:33531[D loss: 0.380814, acc: 67.19%, op_acc: 48.44%] [G loss: 0.857644]\n",
      "epoch:42 step:33532[D loss: 0.389244, acc: 65.62%, op_acc: 41.41%] [G loss: 0.830337]\n",
      "epoch:42 step:33533[D loss: 0.363862, acc: 71.09%, op_acc: 47.66%] [G loss: 1.000328]\n",
      "epoch:42 step:33534[D loss: 0.429261, acc: 60.16%, op_acc: 46.09%] [G loss: 1.037277]\n",
      "epoch:42 step:33535[D loss: 0.395104, acc: 67.19%, op_acc: 39.84%] [G loss: 0.876011]\n",
      "epoch:42 step:33536[D loss: 0.420120, acc: 57.03%, op_acc: 42.19%] [G loss: 0.913076]\n",
      "epoch:42 step:33537[D loss: 0.407940, acc: 58.59%, op_acc: 46.09%] [G loss: 0.968963]\n",
      "epoch:42 step:33538[D loss: 0.382966, acc: 68.75%, op_acc: 39.06%] [G loss: 1.016194]\n",
      "epoch:42 step:33539[D loss: 0.366655, acc: 70.31%, op_acc: 43.75%] [G loss: 0.832712]\n",
      "epoch:42 step:33540[D loss: 0.411635, acc: 60.94%, op_acc: 46.88%] [G loss: 0.873195]\n",
      "epoch:42 step:33541[D loss: 0.389465, acc: 65.62%, op_acc: 43.75%] [G loss: 1.049001]\n",
      "epoch:42 step:33542[D loss: 0.407260, acc: 57.81%, op_acc: 47.66%] [G loss: 0.819916]\n",
      "epoch:42 step:33543[D loss: 0.410451, acc: 64.06%, op_acc: 36.72%] [G loss: 0.938579]\n",
      "epoch:42 step:33544[D loss: 0.453504, acc: 45.31%, op_acc: 39.06%] [G loss: 0.896020]\n",
      "epoch:42 step:33545[D loss: 0.433843, acc: 56.25%, op_acc: 43.75%] [G loss: 0.988605]\n",
      "epoch:42 step:33546[D loss: 0.361477, acc: 70.31%, op_acc: 43.75%] [G loss: 0.969656]\n",
      "epoch:42 step:33547[D loss: 0.389183, acc: 64.84%, op_acc: 41.41%] [G loss: 0.888424]\n",
      "epoch:42 step:33548[D loss: 0.435678, acc: 50.00%, op_acc: 46.88%] [G loss: 0.978467]\n",
      "epoch:42 step:33549[D loss: 0.474734, acc: 52.34%, op_acc: 37.50%] [G loss: 0.882859]\n",
      "epoch:42 step:33550[D loss: 0.429159, acc: 58.59%, op_acc: 36.72%] [G loss: 0.884921]\n",
      "##############\n",
      "[0.85643152 0.88668849 0.82865953 0.78456518 0.79804522 0.83120244\n",
      " 0.89391964 0.8228013  0.78709082 0.82517495]\n",
      "##########\n",
      "epoch:42 step:33551[D loss: 0.401353, acc: 56.25%, op_acc: 43.75%] [G loss: 0.897194]\n",
      "epoch:42 step:33552[D loss: 0.415559, acc: 59.38%, op_acc: 44.53%] [G loss: 0.843607]\n",
      "epoch:42 step:33553[D loss: 0.450021, acc: 55.47%, op_acc: 38.28%] [G loss: 0.925270]\n",
      "epoch:42 step:33554[D loss: 0.425088, acc: 64.84%, op_acc: 38.28%] [G loss: 0.878490]\n",
      "epoch:42 step:33555[D loss: 0.422769, acc: 59.38%, op_acc: 43.75%] [G loss: 0.892564]\n",
      "epoch:42 step:33556[D loss: 0.412243, acc: 58.59%, op_acc: 42.97%] [G loss: 0.932010]\n",
      "epoch:42 step:33557[D loss: 0.419721, acc: 55.47%, op_acc: 42.97%] [G loss: 0.883580]\n",
      "epoch:42 step:33558[D loss: 0.427824, acc: 55.47%, op_acc: 42.97%] [G loss: 0.932825]\n",
      "epoch:42 step:33559[D loss: 0.390302, acc: 67.19%, op_acc: 41.41%] [G loss: 1.030903]\n",
      "epoch:42 step:33560[D loss: 0.385328, acc: 64.84%, op_acc: 48.44%] [G loss: 0.867470]\n",
      "epoch:42 step:33561[D loss: 0.440869, acc: 58.59%, op_acc: 39.06%] [G loss: 0.876654]\n",
      "epoch:42 step:33562[D loss: 0.434057, acc: 59.38%, op_acc: 43.75%] [G loss: 0.937418]\n",
      "epoch:42 step:33563[D loss: 0.379659, acc: 65.62%, op_acc: 43.75%] [G loss: 0.876662]\n",
      "epoch:42 step:33564[D loss: 0.450891, acc: 53.12%, op_acc: 39.84%] [G loss: 0.834713]\n",
      "epoch:42 step:33565[D loss: 0.413790, acc: 58.59%, op_acc: 37.50%] [G loss: 0.902074]\n",
      "epoch:42 step:33566[D loss: 0.398781, acc: 64.84%, op_acc: 39.84%] [G loss: 0.861386]\n",
      "epoch:42 step:33567[D loss: 0.442143, acc: 53.12%, op_acc: 41.41%] [G loss: 0.810640]\n",
      "epoch:42 step:33568[D loss: 0.393548, acc: 69.53%, op_acc: 37.50%] [G loss: 0.873757]\n",
      "epoch:42 step:33569[D loss: 0.394418, acc: 57.03%, op_acc: 45.31%] [G loss: 0.853268]\n",
      "epoch:42 step:33570[D loss: 0.392395, acc: 60.94%, op_acc: 43.75%] [G loss: 0.948121]\n",
      "epoch:42 step:33571[D loss: 0.365022, acc: 67.97%, op_acc: 47.66%] [G loss: 0.886455]\n",
      "epoch:42 step:33572[D loss: 0.407393, acc: 65.62%, op_acc: 46.09%] [G loss: 0.935225]\n",
      "epoch:42 step:33573[D loss: 0.463889, acc: 58.59%, op_acc: 37.50%] [G loss: 0.947866]\n",
      "epoch:42 step:33574[D loss: 0.440535, acc: 57.03%, op_acc: 39.06%] [G loss: 0.901657]\n",
      "epoch:42 step:33575[D loss: 0.444791, acc: 55.47%, op_acc: 40.62%] [G loss: 0.877631]\n",
      "epoch:42 step:33576[D loss: 0.370554, acc: 67.97%, op_acc: 49.22%] [G loss: 0.929087]\n",
      "epoch:42 step:33577[D loss: 0.402137, acc: 68.75%, op_acc: 45.31%] [G loss: 0.903937]\n",
      "epoch:42 step:33578[D loss: 0.418832, acc: 59.38%, op_acc: 35.16%] [G loss: 0.901617]\n",
      "epoch:42 step:33579[D loss: 0.436978, acc: 57.81%, op_acc: 42.97%] [G loss: 0.888002]\n",
      "epoch:42 step:33580[D loss: 0.399293, acc: 57.03%, op_acc: 47.66%] [G loss: 0.856642]\n",
      "epoch:42 step:33581[D loss: 0.376893, acc: 70.31%, op_acc: 41.41%] [G loss: 0.906995]\n",
      "epoch:42 step:33582[D loss: 0.398227, acc: 60.94%, op_acc: 46.09%] [G loss: 0.893474]\n",
      "epoch:42 step:33583[D loss: 0.422167, acc: 59.38%, op_acc: 42.97%] [G loss: 0.967465]\n",
      "epoch:43 step:33584[D loss: 0.408130, acc: 53.91%, op_acc: 50.00%] [G loss: 0.975649]\n",
      "epoch:43 step:33585[D loss: 0.410272, acc: 55.47%, op_acc: 48.44%] [G loss: 0.873449]\n",
      "epoch:43 step:33586[D loss: 0.425906, acc: 60.16%, op_acc: 35.16%] [G loss: 0.744131]\n",
      "epoch:43 step:33587[D loss: 0.367105, acc: 66.41%, op_acc: 49.22%] [G loss: 0.873770]\n",
      "epoch:43 step:33588[D loss: 0.418789, acc: 60.94%, op_acc: 42.97%] [G loss: 0.868323]\n",
      "epoch:43 step:33589[D loss: 0.424615, acc: 62.50%, op_acc: 41.41%] [G loss: 0.871665]\n",
      "epoch:43 step:33590[D loss: 0.425097, acc: 58.59%, op_acc: 42.97%] [G loss: 0.842753]\n",
      "epoch:43 step:33591[D loss: 0.403726, acc: 64.06%, op_acc: 42.19%] [G loss: 0.842798]\n",
      "epoch:43 step:33592[D loss: 0.413499, acc: 60.94%, op_acc: 48.44%] [G loss: 0.928121]\n",
      "epoch:43 step:33593[D loss: 0.428968, acc: 61.72%, op_acc: 39.06%] [G loss: 0.776543]\n",
      "epoch:43 step:33594[D loss: 0.425442, acc: 57.03%, op_acc: 40.62%] [G loss: 0.859658]\n",
      "epoch:43 step:33595[D loss: 0.435267, acc: 60.16%, op_acc: 37.50%] [G loss: 0.933823]\n",
      "epoch:43 step:33596[D loss: 0.403202, acc: 61.72%, op_acc: 43.75%] [G loss: 0.865374]\n",
      "epoch:43 step:33597[D loss: 0.393908, acc: 67.19%, op_acc: 39.06%] [G loss: 0.817885]\n",
      "epoch:43 step:33598[D loss: 0.380560, acc: 70.31%, op_acc: 40.62%] [G loss: 0.954209]\n",
      "epoch:43 step:33599[D loss: 0.388691, acc: 64.84%, op_acc: 42.19%] [G loss: 0.857142]\n",
      "epoch:43 step:33600[D loss: 0.427065, acc: 57.03%, op_acc: 40.62%] [G loss: 0.896278]\n",
      "##############\n",
      "[0.85173882 0.88949112 0.8259173  0.80358883 0.81087442 0.84627432\n",
      " 0.88507934 0.83023593 0.83154299 0.83245022]\n",
      "##########\n",
      "epoch:43 step:33601[D loss: 0.386314, acc: 64.06%, op_acc: 45.31%] [G loss: 0.935437]\n",
      "epoch:43 step:33602[D loss: 0.406021, acc: 61.72%, op_acc: 41.41%] [G loss: 0.883381]\n",
      "epoch:43 step:33603[D loss: 0.381089, acc: 67.19%, op_acc: 46.09%] [G loss: 0.943490]\n",
      "epoch:43 step:33604[D loss: 0.377720, acc: 68.75%, op_acc: 46.09%] [G loss: 0.877074]\n",
      "epoch:43 step:33605[D loss: 0.377934, acc: 65.62%, op_acc: 49.22%] [G loss: 1.029837]\n",
      "epoch:43 step:33606[D loss: 0.388897, acc: 65.62%, op_acc: 39.84%] [G loss: 0.883537]\n",
      "epoch:43 step:33607[D loss: 0.432781, acc: 57.81%, op_acc: 40.62%] [G loss: 0.871558]\n",
      "epoch:43 step:33608[D loss: 0.470991, acc: 50.00%, op_acc: 39.84%] [G loss: 0.774962]\n",
      "epoch:43 step:33609[D loss: 0.403207, acc: 58.59%, op_acc: 39.06%] [G loss: 0.823351]\n",
      "epoch:43 step:33610[D loss: 0.437475, acc: 55.47%, op_acc: 38.28%] [G loss: 1.002814]\n",
      "epoch:43 step:33611[D loss: 0.384311, acc: 60.94%, op_acc: 46.88%] [G loss: 1.004474]\n",
      "epoch:43 step:33612[D loss: 0.419323, acc: 58.59%, op_acc: 42.19%] [G loss: 0.975220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33613[D loss: 0.393696, acc: 60.16%, op_acc: 42.97%] [G loss: 1.048933]\n",
      "epoch:43 step:33614[D loss: 0.423877, acc: 62.50%, op_acc: 38.28%] [G loss: 0.973583]\n",
      "epoch:43 step:33615[D loss: 0.426835, acc: 59.38%, op_acc: 44.53%] [G loss: 1.003806]\n",
      "epoch:43 step:33616[D loss: 0.363942, acc: 72.66%, op_acc: 47.66%] [G loss: 1.001193]\n",
      "epoch:43 step:33617[D loss: 0.394724, acc: 62.50%, op_acc: 42.97%] [G loss: 0.928531]\n",
      "epoch:43 step:33618[D loss: 0.424985, acc: 53.12%, op_acc: 50.78%] [G loss: 1.048982]\n",
      "epoch:43 step:33619[D loss: 0.401768, acc: 57.81%, op_acc: 43.75%] [G loss: 0.902151]\n",
      "epoch:43 step:33620[D loss: 0.427830, acc: 60.16%, op_acc: 39.06%] [G loss: 0.976732]\n",
      "epoch:43 step:33621[D loss: 0.422675, acc: 59.38%, op_acc: 42.19%] [G loss: 0.925777]\n",
      "epoch:43 step:33622[D loss: 0.410962, acc: 58.59%, op_acc: 47.66%] [G loss: 1.059937]\n",
      "epoch:43 step:33623[D loss: 0.408138, acc: 62.50%, op_acc: 39.06%] [G loss: 0.905279]\n",
      "epoch:43 step:33624[D loss: 0.372817, acc: 64.84%, op_acc: 46.88%] [G loss: 1.000952]\n",
      "epoch:43 step:33625[D loss: 0.383436, acc: 62.50%, op_acc: 46.88%] [G loss: 0.949969]\n",
      "epoch:43 step:33626[D loss: 0.437012, acc: 53.12%, op_acc: 39.84%] [G loss: 0.882446]\n",
      "epoch:43 step:33627[D loss: 0.425053, acc: 56.25%, op_acc: 42.19%] [G loss: 0.960673]\n",
      "epoch:43 step:33628[D loss: 0.449034, acc: 56.25%, op_acc: 35.94%] [G loss: 0.927765]\n",
      "epoch:43 step:33629[D loss: 0.401966, acc: 59.38%, op_acc: 44.53%] [G loss: 0.938329]\n",
      "epoch:43 step:33630[D loss: 0.451918, acc: 53.91%, op_acc: 36.72%] [G loss: 0.881993]\n",
      "epoch:43 step:33631[D loss: 0.448962, acc: 55.47%, op_acc: 35.94%] [G loss: 0.875607]\n",
      "epoch:43 step:33632[D loss: 0.394140, acc: 62.50%, op_acc: 46.09%] [G loss: 0.936023]\n",
      "epoch:43 step:33633[D loss: 0.440793, acc: 59.38%, op_acc: 37.50%] [G loss: 0.903692]\n",
      "epoch:43 step:33634[D loss: 0.386866, acc: 63.28%, op_acc: 40.62%] [G loss: 0.876301]\n",
      "epoch:43 step:33635[D loss: 0.396394, acc: 66.41%, op_acc: 41.41%] [G loss: 0.877061]\n",
      "epoch:43 step:33636[D loss: 0.419395, acc: 61.72%, op_acc: 39.06%] [G loss: 0.837592]\n",
      "epoch:43 step:33637[D loss: 0.423221, acc: 64.84%, op_acc: 39.84%] [G loss: 0.930478]\n",
      "epoch:43 step:33638[D loss: 0.402891, acc: 60.94%, op_acc: 42.97%] [G loss: 0.946478]\n",
      "epoch:43 step:33639[D loss: 0.368585, acc: 67.19%, op_acc: 46.09%] [G loss: 0.943751]\n",
      "epoch:43 step:33640[D loss: 0.422325, acc: 55.47%, op_acc: 46.09%] [G loss: 0.793122]\n",
      "epoch:43 step:33641[D loss: 0.355644, acc: 67.97%, op_acc: 49.22%] [G loss: 0.944103]\n",
      "epoch:43 step:33642[D loss: 0.384496, acc: 68.75%, op_acc: 43.75%] [G loss: 0.770677]\n",
      "epoch:43 step:33643[D loss: 0.368384, acc: 67.19%, op_acc: 47.66%] [G loss: 0.912735]\n",
      "epoch:43 step:33644[D loss: 0.427294, acc: 54.69%, op_acc: 38.28%] [G loss: 0.888291]\n",
      "epoch:43 step:33645[D loss: 0.434991, acc: 51.56%, op_acc: 42.19%] [G loss: 0.892690]\n",
      "epoch:43 step:33646[D loss: 0.417415, acc: 62.50%, op_acc: 46.09%] [G loss: 0.949239]\n",
      "epoch:43 step:33647[D loss: 0.435247, acc: 55.47%, op_acc: 39.84%] [G loss: 0.908057]\n",
      "epoch:43 step:33648[D loss: 0.415083, acc: 62.50%, op_acc: 45.31%] [G loss: 0.927513]\n",
      "epoch:43 step:33649[D loss: 0.388880, acc: 60.94%, op_acc: 46.09%] [G loss: 0.835202]\n",
      "epoch:43 step:33650[D loss: 0.402519, acc: 57.81%, op_acc: 46.09%] [G loss: 1.010402]\n",
      "##############\n",
      "[0.85442956 0.86116583 0.80483498 0.80390137 0.78133442 0.82514994\n",
      " 0.8691458  0.82218748 0.79853071 0.82165129]\n",
      "##########\n",
      "epoch:43 step:33651[D loss: 0.404271, acc: 65.62%, op_acc: 37.50%] [G loss: 0.789207]\n",
      "epoch:43 step:33652[D loss: 0.369103, acc: 64.06%, op_acc: 49.22%] [G loss: 0.994598]\n",
      "epoch:43 step:33653[D loss: 0.381753, acc: 63.28%, op_acc: 39.84%] [G loss: 0.809321]\n",
      "epoch:43 step:33654[D loss: 0.451552, acc: 55.47%, op_acc: 39.84%] [G loss: 0.850437]\n",
      "epoch:43 step:33655[D loss: 0.374828, acc: 70.31%, op_acc: 45.31%] [G loss: 0.805931]\n",
      "epoch:43 step:33656[D loss: 0.422118, acc: 57.81%, op_acc: 38.28%] [G loss: 0.773693]\n",
      "epoch:43 step:33657[D loss: 0.399325, acc: 59.38%, op_acc: 41.41%] [G loss: 0.894428]\n",
      "epoch:43 step:33658[D loss: 0.375524, acc: 66.41%, op_acc: 49.22%] [G loss: 0.791410]\n",
      "epoch:43 step:33659[D loss: 0.455028, acc: 48.44%, op_acc: 43.75%] [G loss: 0.822188]\n",
      "epoch:43 step:33660[D loss: 0.402662, acc: 56.25%, op_acc: 43.75%] [G loss: 0.878095]\n",
      "epoch:43 step:33661[D loss: 0.431549, acc: 56.25%, op_acc: 35.94%] [G loss: 0.965786]\n",
      "epoch:43 step:33662[D loss: 0.405611, acc: 64.06%, op_acc: 39.84%] [G loss: 0.771621]\n",
      "epoch:43 step:33663[D loss: 0.408399, acc: 61.72%, op_acc: 37.50%] [G loss: 0.940988]\n",
      "epoch:43 step:33664[D loss: 0.418786, acc: 58.59%, op_acc: 36.72%] [G loss: 0.833884]\n",
      "epoch:43 step:33665[D loss: 0.396942, acc: 64.84%, op_acc: 46.09%] [G loss: 0.947104]\n",
      "epoch:43 step:33666[D loss: 0.391650, acc: 64.84%, op_acc: 40.62%] [G loss: 0.841550]\n",
      "epoch:43 step:33667[D loss: 0.375353, acc: 62.50%, op_acc: 45.31%] [G loss: 0.971531]\n",
      "epoch:43 step:33668[D loss: 0.441958, acc: 57.03%, op_acc: 39.84%] [G loss: 0.907106]\n",
      "epoch:43 step:33669[D loss: 0.391704, acc: 60.94%, op_acc: 42.19%] [G loss: 0.897330]\n",
      "epoch:43 step:33670[D loss: 0.367395, acc: 73.44%, op_acc: 42.97%] [G loss: 0.988047]\n",
      "epoch:43 step:33671[D loss: 0.433801, acc: 53.12%, op_acc: 38.28%] [G loss: 0.772426]\n",
      "epoch:43 step:33672[D loss: 0.415311, acc: 59.38%, op_acc: 42.19%] [G loss: 0.798224]\n",
      "epoch:43 step:33673[D loss: 0.398717, acc: 60.94%, op_acc: 45.31%] [G loss: 0.983622]\n",
      "epoch:43 step:33674[D loss: 0.390699, acc: 58.59%, op_acc: 45.31%] [G loss: 0.730072]\n",
      "epoch:43 step:33675[D loss: 0.467896, acc: 51.56%, op_acc: 37.50%] [G loss: 0.865404]\n",
      "epoch:43 step:33676[D loss: 0.394712, acc: 61.72%, op_acc: 46.09%] [G loss: 0.876480]\n",
      "epoch:43 step:33677[D loss: 0.411991, acc: 61.72%, op_acc: 43.75%] [G loss: 0.774021]\n",
      "epoch:43 step:33678[D loss: 0.434627, acc: 59.38%, op_acc: 42.19%] [G loss: 0.861696]\n",
      "epoch:43 step:33679[D loss: 0.441538, acc: 54.69%, op_acc: 37.50%] [G loss: 0.944019]\n",
      "epoch:43 step:33680[D loss: 0.376000, acc: 60.94%, op_acc: 46.09%] [G loss: 0.920333]\n",
      "epoch:43 step:33681[D loss: 0.376952, acc: 71.88%, op_acc: 41.41%] [G loss: 0.881775]\n",
      "epoch:43 step:33682[D loss: 0.407538, acc: 58.59%, op_acc: 43.75%] [G loss: 0.820560]\n",
      "epoch:43 step:33683[D loss: 0.378040, acc: 64.84%, op_acc: 47.66%] [G loss: 0.846703]\n",
      "epoch:43 step:33684[D loss: 0.416485, acc: 60.94%, op_acc: 41.41%] [G loss: 0.895648]\n",
      "epoch:43 step:33685[D loss: 0.416366, acc: 62.50%, op_acc: 46.09%] [G loss: 0.739824]\n",
      "epoch:43 step:33686[D loss: 0.409743, acc: 58.59%, op_acc: 44.53%] [G loss: 0.852149]\n",
      "epoch:43 step:33687[D loss: 0.398441, acc: 63.28%, op_acc: 38.28%] [G loss: 0.832987]\n",
      "epoch:43 step:33688[D loss: 0.440878, acc: 55.47%, op_acc: 38.28%] [G loss: 0.845601]\n",
      "epoch:43 step:33689[D loss: 0.425820, acc: 57.81%, op_acc: 37.50%] [G loss: 0.906944]\n",
      "epoch:43 step:33690[D loss: 0.358746, acc: 69.53%, op_acc: 46.09%] [G loss: 0.913781]\n",
      "epoch:43 step:33691[D loss: 0.424128, acc: 57.03%, op_acc: 43.75%] [G loss: 0.832785]\n",
      "epoch:43 step:33692[D loss: 0.389800, acc: 64.84%, op_acc: 44.53%] [G loss: 0.904380]\n",
      "epoch:43 step:33693[D loss: 0.390679, acc: 62.50%, op_acc: 47.66%] [G loss: 0.843506]\n",
      "epoch:43 step:33694[D loss: 0.434071, acc: 55.47%, op_acc: 41.41%] [G loss: 0.856629]\n",
      "epoch:43 step:33695[D loss: 0.424932, acc: 60.16%, op_acc: 42.19%] [G loss: 0.903704]\n",
      "epoch:43 step:33696[D loss: 0.400377, acc: 65.62%, op_acc: 42.19%] [G loss: 0.901691]\n",
      "epoch:43 step:33697[D loss: 0.388574, acc: 67.97%, op_acc: 43.75%] [G loss: 0.971087]\n",
      "epoch:43 step:33698[D loss: 0.390022, acc: 55.47%, op_acc: 52.34%] [G loss: 0.885641]\n",
      "epoch:43 step:33699[D loss: 0.435248, acc: 54.69%, op_acc: 43.75%] [G loss: 0.911608]\n",
      "epoch:43 step:33700[D loss: 0.392749, acc: 61.72%, op_acc: 41.41%] [G loss: 0.830167]\n",
      "##############\n",
      "[0.83422318 0.87528403 0.79564086 0.81171141 0.78271201 0.83611734\n",
      " 0.86867824 0.80581515 0.82130396 0.85591054]\n",
      "##########\n",
      "epoch:43 step:33701[D loss: 0.409318, acc: 63.28%, op_acc: 42.19%] [G loss: 0.816390]\n",
      "epoch:43 step:33702[D loss: 0.389607, acc: 67.97%, op_acc: 38.28%] [G loss: 0.862239]\n",
      "epoch:43 step:33703[D loss: 0.412483, acc: 58.59%, op_acc: 42.97%] [G loss: 0.875364]\n",
      "epoch:43 step:33704[D loss: 0.405982, acc: 60.16%, op_acc: 44.53%] [G loss: 0.884014]\n",
      "epoch:43 step:33705[D loss: 0.405001, acc: 64.06%, op_acc: 45.31%] [G loss: 0.964106]\n",
      "epoch:43 step:33706[D loss: 0.419393, acc: 59.38%, op_acc: 37.50%] [G loss: 0.964501]\n",
      "epoch:43 step:33707[D loss: 0.377816, acc: 75.00%, op_acc: 46.88%] [G loss: 0.912928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33708[D loss: 0.424406, acc: 60.94%, op_acc: 39.84%] [G loss: 0.868181]\n",
      "epoch:43 step:33709[D loss: 0.389132, acc: 61.72%, op_acc: 42.19%] [G loss: 0.945444]\n",
      "epoch:43 step:33710[D loss: 0.368245, acc: 69.53%, op_acc: 50.78%] [G loss: 0.925077]\n",
      "epoch:43 step:33711[D loss: 0.394232, acc: 64.84%, op_acc: 38.28%] [G loss: 0.994952]\n",
      "epoch:43 step:33712[D loss: 0.395270, acc: 67.97%, op_acc: 32.81%] [G loss: 1.032287]\n",
      "epoch:43 step:33713[D loss: 0.368322, acc: 65.62%, op_acc: 43.75%] [G loss: 0.907027]\n",
      "epoch:43 step:33714[D loss: 0.402045, acc: 69.53%, op_acc: 41.41%] [G loss: 0.898535]\n",
      "epoch:43 step:33715[D loss: 0.385770, acc: 57.03%, op_acc: 45.31%] [G loss: 0.827052]\n",
      "epoch:43 step:33716[D loss: 0.410301, acc: 65.62%, op_acc: 38.28%] [G loss: 0.797298]\n",
      "epoch:43 step:33717[D loss: 0.405452, acc: 62.50%, op_acc: 39.06%] [G loss: 1.089470]\n",
      "epoch:43 step:33718[D loss: 0.405063, acc: 61.72%, op_acc: 42.97%] [G loss: 1.028751]\n",
      "epoch:43 step:33719[D loss: 0.389606, acc: 71.09%, op_acc: 42.19%] [G loss: 0.952356]\n",
      "epoch:43 step:33720[D loss: 0.423433, acc: 57.81%, op_acc: 41.41%] [G loss: 0.893220]\n",
      "epoch:43 step:33721[D loss: 0.403770, acc: 68.75%, op_acc: 40.62%] [G loss: 1.057669]\n",
      "epoch:43 step:33722[D loss: 0.433809, acc: 53.91%, op_acc: 42.19%] [G loss: 0.765346]\n",
      "epoch:43 step:33723[D loss: 0.460792, acc: 52.34%, op_acc: 38.28%] [G loss: 1.128747]\n",
      "epoch:43 step:33724[D loss: 0.412647, acc: 65.62%, op_acc: 37.50%] [G loss: 0.801900]\n",
      "epoch:43 step:33725[D loss: 0.443562, acc: 54.69%, op_acc: 40.62%] [G loss: 0.874694]\n",
      "epoch:43 step:33726[D loss: 0.415855, acc: 64.06%, op_acc: 44.53%] [G loss: 0.807027]\n",
      "epoch:43 step:33727[D loss: 0.397704, acc: 63.28%, op_acc: 45.31%] [G loss: 0.916955]\n",
      "epoch:43 step:33728[D loss: 0.442038, acc: 51.56%, op_acc: 39.06%] [G loss: 0.888213]\n",
      "epoch:43 step:33729[D loss: 0.440878, acc: 56.25%, op_acc: 40.62%] [G loss: 0.899001]\n",
      "epoch:43 step:33730[D loss: 0.411186, acc: 64.06%, op_acc: 44.53%] [G loss: 0.910490]\n",
      "epoch:43 step:33731[D loss: 0.398587, acc: 64.84%, op_acc: 46.09%] [G loss: 1.076033]\n",
      "epoch:43 step:33732[D loss: 0.397027, acc: 60.94%, op_acc: 44.53%] [G loss: 0.963111]\n",
      "epoch:43 step:33733[D loss: 0.384997, acc: 66.41%, op_acc: 42.19%] [G loss: 0.941707]\n",
      "epoch:43 step:33734[D loss: 0.374140, acc: 71.88%, op_acc: 46.09%] [G loss: 0.910854]\n",
      "epoch:43 step:33735[D loss: 0.406075, acc: 59.38%, op_acc: 42.19%] [G loss: 0.962697]\n",
      "epoch:43 step:33736[D loss: 0.447852, acc: 54.69%, op_acc: 35.16%] [G loss: 0.924501]\n",
      "epoch:43 step:33737[D loss: 0.454236, acc: 56.25%, op_acc: 35.94%] [G loss: 0.971851]\n",
      "epoch:43 step:33738[D loss: 0.440400, acc: 51.56%, op_acc: 40.62%] [G loss: 0.927154]\n",
      "epoch:43 step:33739[D loss: 0.426711, acc: 55.47%, op_acc: 37.50%] [G loss: 0.906020]\n",
      "epoch:43 step:33740[D loss: 0.441746, acc: 52.34%, op_acc: 41.41%] [G loss: 0.844538]\n",
      "epoch:43 step:33741[D loss: 0.383530, acc: 60.94%, op_acc: 43.75%] [G loss: 0.824408]\n",
      "epoch:43 step:33742[D loss: 0.413897, acc: 58.59%, op_acc: 41.41%] [G loss: 0.887988]\n",
      "epoch:43 step:33743[D loss: 0.397879, acc: 73.44%, op_acc: 35.16%] [G loss: 1.000781]\n",
      "epoch:43 step:33744[D loss: 0.401913, acc: 60.94%, op_acc: 42.19%] [G loss: 0.917388]\n",
      "epoch:43 step:33745[D loss: 0.403100, acc: 57.03%, op_acc: 41.41%] [G loss: 0.967350]\n",
      "epoch:43 step:33746[D loss: 0.399798, acc: 61.72%, op_acc: 38.28%] [G loss: 0.967963]\n",
      "epoch:43 step:33747[D loss: 0.444692, acc: 60.94%, op_acc: 37.50%] [G loss: 0.953601]\n",
      "epoch:43 step:33748[D loss: 0.390977, acc: 60.16%, op_acc: 49.22%] [G loss: 0.859181]\n",
      "epoch:43 step:33749[D loss: 0.399692, acc: 64.84%, op_acc: 43.75%] [G loss: 0.952854]\n",
      "epoch:43 step:33750[D loss: 0.404288, acc: 60.16%, op_acc: 46.09%] [G loss: 0.850537]\n",
      "##############\n",
      "[0.86482875 0.85958589 0.80247246 0.81147368 0.7821196  0.82548566\n",
      " 0.88792567 0.8269135  0.8119182  0.81188731]\n",
      "##########\n",
      "epoch:43 step:33751[D loss: 0.421886, acc: 59.38%, op_acc: 41.41%] [G loss: 0.950568]\n",
      "epoch:43 step:33752[D loss: 0.417543, acc: 60.94%, op_acc: 38.28%] [G loss: 0.897879]\n",
      "epoch:43 step:33753[D loss: 0.422776, acc: 58.59%, op_acc: 38.28%] [G loss: 0.856453]\n",
      "epoch:43 step:33754[D loss: 0.450734, acc: 50.00%, op_acc: 42.97%] [G loss: 1.002894]\n",
      "epoch:43 step:33755[D loss: 0.401327, acc: 66.41%, op_acc: 43.75%] [G loss: 0.932699]\n",
      "epoch:43 step:33756[D loss: 0.432756, acc: 56.25%, op_acc: 36.72%] [G loss: 0.899030]\n",
      "epoch:43 step:33757[D loss: 0.446172, acc: 53.12%, op_acc: 42.19%] [G loss: 0.760784]\n",
      "epoch:43 step:33758[D loss: 0.389645, acc: 67.19%, op_acc: 38.28%] [G loss: 0.898006]\n",
      "epoch:43 step:33759[D loss: 0.421559, acc: 61.72%, op_acc: 42.19%] [G loss: 1.017727]\n",
      "epoch:43 step:33760[D loss: 0.399083, acc: 61.72%, op_acc: 41.41%] [G loss: 0.911124]\n",
      "epoch:43 step:33761[D loss: 0.423576, acc: 59.38%, op_acc: 41.41%] [G loss: 0.954290]\n",
      "epoch:43 step:33762[D loss: 0.387540, acc: 65.62%, op_acc: 49.22%] [G loss: 0.806603]\n",
      "epoch:43 step:33763[D loss: 0.407496, acc: 63.28%, op_acc: 38.28%] [G loss: 0.928449]\n",
      "epoch:43 step:33764[D loss: 0.389945, acc: 63.28%, op_acc: 44.53%] [G loss: 0.800554]\n",
      "epoch:43 step:33765[D loss: 0.416511, acc: 53.91%, op_acc: 48.44%] [G loss: 1.026034]\n",
      "epoch:43 step:33766[D loss: 0.414573, acc: 64.06%, op_acc: 39.84%] [G loss: 0.823302]\n",
      "epoch:43 step:33767[D loss: 0.405414, acc: 63.28%, op_acc: 39.06%] [G loss: 0.926283]\n",
      "epoch:43 step:33768[D loss: 0.412152, acc: 66.41%, op_acc: 34.38%] [G loss: 0.966851]\n",
      "epoch:43 step:33769[D loss: 0.415171, acc: 62.50%, op_acc: 41.41%] [G loss: 0.992107]\n",
      "epoch:43 step:33770[D loss: 0.398301, acc: 64.06%, op_acc: 42.19%] [G loss: 0.966148]\n",
      "epoch:43 step:33771[D loss: 0.479434, acc: 52.34%, op_acc: 40.62%] [G loss: 0.887946]\n",
      "epoch:43 step:33772[D loss: 0.404657, acc: 65.62%, op_acc: 39.06%] [G loss: 0.857324]\n",
      "epoch:43 step:33773[D loss: 0.438061, acc: 55.47%, op_acc: 38.28%] [G loss: 0.782411]\n",
      "epoch:43 step:33774[D loss: 0.415054, acc: 60.16%, op_acc: 41.41%] [G loss: 0.954091]\n",
      "epoch:43 step:33775[D loss: 0.378346, acc: 71.09%, op_acc: 41.41%] [G loss: 0.914452]\n",
      "epoch:43 step:33776[D loss: 0.443727, acc: 56.25%, op_acc: 37.50%] [G loss: 0.769127]\n",
      "epoch:43 step:33777[D loss: 0.407099, acc: 57.03%, op_acc: 36.72%] [G loss: 0.764609]\n",
      "epoch:43 step:33778[D loss: 0.404043, acc: 61.72%, op_acc: 41.41%] [G loss: 0.846273]\n",
      "epoch:43 step:33779[D loss: 0.385659, acc: 65.62%, op_acc: 45.31%] [G loss: 0.808348]\n",
      "epoch:43 step:33780[D loss: 0.429400, acc: 62.50%, op_acc: 39.84%] [G loss: 0.857324]\n",
      "epoch:43 step:33781[D loss: 0.416048, acc: 64.06%, op_acc: 42.97%] [G loss: 0.898247]\n",
      "epoch:43 step:33782[D loss: 0.433640, acc: 53.12%, op_acc: 42.19%] [G loss: 0.855783]\n",
      "epoch:43 step:33783[D loss: 0.384407, acc: 66.41%, op_acc: 44.53%] [G loss: 0.998942]\n",
      "epoch:43 step:33784[D loss: 0.397856, acc: 61.72%, op_acc: 44.53%] [G loss: 0.861442]\n",
      "epoch:43 step:33785[D loss: 0.401266, acc: 61.72%, op_acc: 42.19%] [G loss: 0.932151]\n",
      "epoch:43 step:33786[D loss: 0.459543, acc: 52.34%, op_acc: 38.28%] [G loss: 0.876072]\n",
      "epoch:43 step:33787[D loss: 0.389970, acc: 68.75%, op_acc: 41.41%] [G loss: 0.908009]\n",
      "epoch:43 step:33788[D loss: 0.396213, acc: 62.50%, op_acc: 43.75%] [G loss: 0.956176]\n",
      "epoch:43 step:33789[D loss: 0.385799, acc: 63.28%, op_acc: 42.97%] [G loss: 0.948844]\n",
      "epoch:43 step:33790[D loss: 0.391443, acc: 60.16%, op_acc: 45.31%] [G loss: 0.916455]\n",
      "epoch:43 step:33791[D loss: 0.411887, acc: 65.62%, op_acc: 39.06%] [G loss: 0.966504]\n",
      "epoch:43 step:33792[D loss: 0.381524, acc: 64.84%, op_acc: 45.31%] [G loss: 1.036689]\n",
      "epoch:43 step:33793[D loss: 0.389558, acc: 65.62%, op_acc: 40.62%] [G loss: 0.873925]\n",
      "epoch:43 step:33794[D loss: 0.398329, acc: 67.19%, op_acc: 46.09%] [G loss: 0.932390]\n",
      "epoch:43 step:33795[D loss: 0.387704, acc: 69.53%, op_acc: 49.22%] [G loss: 1.048945]\n",
      "epoch:43 step:33796[D loss: 0.383545, acc: 68.75%, op_acc: 42.97%] [G loss: 0.744940]\n",
      "epoch:43 step:33797[D loss: 0.445470, acc: 56.25%, op_acc: 34.38%] [G loss: 0.954748]\n",
      "epoch:43 step:33798[D loss: 0.423162, acc: 60.94%, op_acc: 39.84%] [G loss: 0.960863]\n",
      "epoch:43 step:33799[D loss: 0.408767, acc: 62.50%, op_acc: 44.53%] [G loss: 0.827192]\n",
      "epoch:43 step:33800[D loss: 0.395082, acc: 61.72%, op_acc: 40.62%] [G loss: 1.043559]\n",
      "##############\n",
      "[0.84525056 0.88229864 0.81320596 0.83168505 0.80151942 0.84053688\n",
      " 0.88068125 0.83549391 0.81014235 0.8208877 ]\n",
      "##########\n",
      "epoch:43 step:33801[D loss: 0.414643, acc: 60.94%, op_acc: 46.88%] [G loss: 0.947115]\n",
      "epoch:43 step:33802[D loss: 0.433884, acc: 60.16%, op_acc: 42.19%] [G loss: 0.832296]\n",
      "epoch:43 step:33803[D loss: 0.419443, acc: 59.38%, op_acc: 41.41%] [G loss: 0.847041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33804[D loss: 0.409211, acc: 63.28%, op_acc: 42.19%] [G loss: 1.009131]\n",
      "epoch:43 step:33805[D loss: 0.408949, acc: 64.06%, op_acc: 44.53%] [G loss: 0.925989]\n",
      "epoch:43 step:33806[D loss: 0.416184, acc: 53.91%, op_acc: 46.09%] [G loss: 1.065215]\n",
      "epoch:43 step:33807[D loss: 0.409535, acc: 64.06%, op_acc: 43.75%] [G loss: 0.934651]\n",
      "epoch:43 step:33808[D loss: 0.386851, acc: 65.62%, op_acc: 43.75%] [G loss: 0.924623]\n",
      "epoch:43 step:33809[D loss: 0.425680, acc: 62.50%, op_acc: 34.38%] [G loss: 0.901212]\n",
      "epoch:43 step:33810[D loss: 0.412551, acc: 61.72%, op_acc: 43.75%] [G loss: 0.872007]\n",
      "epoch:43 step:33811[D loss: 0.405793, acc: 58.59%, op_acc: 39.06%] [G loss: 0.880373]\n",
      "epoch:43 step:33812[D loss: 0.419478, acc: 59.38%, op_acc: 43.75%] [G loss: 0.979204]\n",
      "epoch:43 step:33813[D loss: 0.401869, acc: 65.62%, op_acc: 45.31%] [G loss: 0.917702]\n",
      "epoch:43 step:33814[D loss: 0.399092, acc: 60.94%, op_acc: 46.09%] [G loss: 0.924124]\n",
      "epoch:43 step:33815[D loss: 0.387727, acc: 65.62%, op_acc: 43.75%] [G loss: 0.840945]\n",
      "epoch:43 step:33816[D loss: 0.384841, acc: 65.62%, op_acc: 47.66%] [G loss: 0.856829]\n",
      "epoch:43 step:33817[D loss: 0.380375, acc: 72.66%, op_acc: 45.31%] [G loss: 1.007468]\n",
      "epoch:43 step:33818[D loss: 0.367118, acc: 67.19%, op_acc: 50.00%] [G loss: 1.045855]\n",
      "epoch:43 step:33819[D loss: 0.414388, acc: 57.81%, op_acc: 43.75%] [G loss: 0.887994]\n",
      "epoch:43 step:33820[D loss: 0.408201, acc: 60.16%, op_acc: 42.19%] [G loss: 0.965355]\n",
      "epoch:43 step:33821[D loss: 0.437144, acc: 57.03%, op_acc: 41.41%] [G loss: 0.897502]\n",
      "epoch:43 step:33822[D loss: 0.405737, acc: 59.38%, op_acc: 41.41%] [G loss: 0.872392]\n",
      "epoch:43 step:33823[D loss: 0.431618, acc: 51.56%, op_acc: 46.09%] [G loss: 0.926655]\n",
      "epoch:43 step:33824[D loss: 0.432481, acc: 55.47%, op_acc: 44.53%] [G loss: 0.895071]\n",
      "epoch:43 step:33825[D loss: 0.422128, acc: 58.59%, op_acc: 41.41%] [G loss: 0.788489]\n",
      "epoch:43 step:33826[D loss: 0.430057, acc: 58.59%, op_acc: 44.53%] [G loss: 0.911433]\n",
      "epoch:43 step:33827[D loss: 0.414727, acc: 60.16%, op_acc: 46.88%] [G loss: 0.848543]\n",
      "epoch:43 step:33828[D loss: 0.419042, acc: 57.81%, op_acc: 44.53%] [G loss: 0.888087]\n",
      "epoch:43 step:33829[D loss: 0.436987, acc: 67.19%, op_acc: 32.03%] [G loss: 0.875731]\n",
      "epoch:43 step:33830[D loss: 0.390826, acc: 71.09%, op_acc: 42.19%] [G loss: 0.951552]\n",
      "epoch:43 step:33831[D loss: 0.397879, acc: 63.28%, op_acc: 44.53%] [G loss: 0.918388]\n",
      "epoch:43 step:33832[D loss: 0.395863, acc: 64.84%, op_acc: 46.88%] [G loss: 0.954443]\n",
      "epoch:43 step:33833[D loss: 0.443898, acc: 58.59%, op_acc: 36.72%] [G loss: 0.928297]\n",
      "epoch:43 step:33834[D loss: 0.395403, acc: 60.94%, op_acc: 40.62%] [G loss: 0.868045]\n",
      "epoch:43 step:33835[D loss: 0.418581, acc: 59.38%, op_acc: 48.44%] [G loss: 0.894418]\n",
      "epoch:43 step:33836[D loss: 0.405022, acc: 63.28%, op_acc: 40.62%] [G loss: 0.925808]\n",
      "epoch:43 step:33837[D loss: 0.383558, acc: 65.62%, op_acc: 42.19%] [G loss: 0.911281]\n",
      "epoch:43 step:33838[D loss: 0.402435, acc: 65.62%, op_acc: 42.97%] [G loss: 0.992566]\n",
      "epoch:43 step:33839[D loss: 0.428330, acc: 57.03%, op_acc: 40.62%] [G loss: 0.893547]\n",
      "epoch:43 step:33840[D loss: 0.425261, acc: 57.81%, op_acc: 41.41%] [G loss: 0.930577]\n",
      "epoch:43 step:33841[D loss: 0.401677, acc: 62.50%, op_acc: 43.75%] [G loss: 0.924346]\n",
      "epoch:43 step:33842[D loss: 0.421715, acc: 67.97%, op_acc: 37.50%] [G loss: 0.893910]\n",
      "epoch:43 step:33843[D loss: 0.406424, acc: 62.50%, op_acc: 40.62%] [G loss: 0.884946]\n",
      "epoch:43 step:33844[D loss: 0.400213, acc: 64.06%, op_acc: 41.41%] [G loss: 0.942011]\n",
      "epoch:43 step:33845[D loss: 0.382629, acc: 67.97%, op_acc: 46.88%] [G loss: 0.900788]\n",
      "epoch:43 step:33846[D loss: 0.391750, acc: 67.97%, op_acc: 42.97%] [G loss: 0.912432]\n",
      "epoch:43 step:33847[D loss: 0.416128, acc: 67.19%, op_acc: 40.62%] [G loss: 0.967060]\n",
      "epoch:43 step:33848[D loss: 0.390181, acc: 59.38%, op_acc: 42.19%] [G loss: 0.880144]\n",
      "epoch:43 step:33849[D loss: 0.383960, acc: 65.62%, op_acc: 44.53%] [G loss: 0.917373]\n",
      "epoch:43 step:33850[D loss: 0.418051, acc: 62.50%, op_acc: 42.97%] [G loss: 1.032364]\n",
      "##############\n",
      "[0.85820169 0.85982601 0.81961465 0.80088835 0.8166943  0.82296344\n",
      " 0.89353163 0.84369001 0.81710712 0.82747374]\n",
      "##########\n",
      "epoch:43 step:33851[D loss: 0.434316, acc: 54.69%, op_acc: 47.66%] [G loss: 0.889776]\n",
      "epoch:43 step:33852[D loss: 0.398804, acc: 63.28%, op_acc: 45.31%] [G loss: 0.878790]\n",
      "epoch:43 step:33853[D loss: 0.375300, acc: 68.75%, op_acc: 42.19%] [G loss: 1.071532]\n",
      "epoch:43 step:33854[D loss: 0.441088, acc: 56.25%, op_acc: 33.59%] [G loss: 0.876321]\n",
      "epoch:43 step:33855[D loss: 0.376318, acc: 71.09%, op_acc: 42.97%] [G loss: 0.951094]\n",
      "epoch:43 step:33856[D loss: 0.396789, acc: 65.62%, op_acc: 39.84%] [G loss: 0.965930]\n",
      "epoch:43 step:33857[D loss: 0.399906, acc: 60.94%, op_acc: 44.53%] [G loss: 0.890270]\n",
      "epoch:43 step:33858[D loss: 0.402776, acc: 64.06%, op_acc: 42.97%] [G loss: 0.986577]\n",
      "epoch:43 step:33859[D loss: 0.406259, acc: 54.69%, op_acc: 42.97%] [G loss: 0.802191]\n",
      "epoch:43 step:33860[D loss: 0.412561, acc: 69.53%, op_acc: 33.59%] [G loss: 0.902040]\n",
      "epoch:43 step:33861[D loss: 0.409392, acc: 60.94%, op_acc: 39.06%] [G loss: 0.996817]\n",
      "epoch:43 step:33862[D loss: 0.417998, acc: 60.16%, op_acc: 44.53%] [G loss: 0.938657]\n",
      "epoch:43 step:33863[D loss: 0.416450, acc: 63.28%, op_acc: 39.06%] [G loss: 0.940484]\n",
      "epoch:43 step:33864[D loss: 0.431822, acc: 57.81%, op_acc: 37.50%] [G loss: 0.887263]\n",
      "epoch:43 step:33865[D loss: 0.427146, acc: 62.50%, op_acc: 41.41%] [G loss: 1.042318]\n",
      "epoch:43 step:33866[D loss: 0.385683, acc: 66.41%, op_acc: 45.31%] [G loss: 0.957808]\n",
      "epoch:43 step:33867[D loss: 0.406540, acc: 66.41%, op_acc: 43.75%] [G loss: 0.841064]\n",
      "epoch:43 step:33868[D loss: 0.381038, acc: 69.53%, op_acc: 39.84%] [G loss: 0.821087]\n",
      "epoch:43 step:33869[D loss: 0.415487, acc: 64.06%, op_acc: 43.75%] [G loss: 0.990343]\n",
      "epoch:43 step:33870[D loss: 0.414223, acc: 60.16%, op_acc: 46.09%] [G loss: 1.013321]\n",
      "epoch:43 step:33871[D loss: 0.424605, acc: 57.81%, op_acc: 48.44%] [G loss: 0.873156]\n",
      "epoch:43 step:33872[D loss: 0.410697, acc: 63.28%, op_acc: 43.75%] [G loss: 0.886929]\n",
      "epoch:43 step:33873[D loss: 0.392940, acc: 69.53%, op_acc: 43.75%] [G loss: 0.812570]\n",
      "epoch:43 step:33874[D loss: 0.400193, acc: 64.84%, op_acc: 41.41%] [G loss: 0.935470]\n",
      "epoch:43 step:33875[D loss: 0.412456, acc: 64.84%, op_acc: 35.94%] [G loss: 0.858517]\n",
      "epoch:43 step:33876[D loss: 0.396680, acc: 64.84%, op_acc: 41.41%] [G loss: 0.821821]\n",
      "epoch:43 step:33877[D loss: 0.415923, acc: 61.72%, op_acc: 41.41%] [G loss: 0.911863]\n",
      "epoch:43 step:33878[D loss: 0.421151, acc: 50.78%, op_acc: 43.75%] [G loss: 0.888891]\n",
      "epoch:43 step:33879[D loss: 0.402320, acc: 63.28%, op_acc: 46.09%] [G loss: 0.962674]\n",
      "epoch:43 step:33880[D loss: 0.427849, acc: 53.91%, op_acc: 38.28%] [G loss: 0.989719]\n",
      "epoch:43 step:33881[D loss: 0.390395, acc: 64.06%, op_acc: 35.94%] [G loss: 1.008555]\n",
      "epoch:43 step:33882[D loss: 0.425233, acc: 53.12%, op_acc: 45.31%] [G loss: 1.079035]\n",
      "epoch:43 step:33883[D loss: 0.452810, acc: 57.81%, op_acc: 36.72%] [G loss: 0.956045]\n",
      "epoch:43 step:33884[D loss: 0.420334, acc: 57.81%, op_acc: 41.41%] [G loss: 0.837443]\n",
      "epoch:43 step:33885[D loss: 0.388787, acc: 67.97%, op_acc: 41.41%] [G loss: 0.936787]\n",
      "epoch:43 step:33886[D loss: 0.422697, acc: 60.94%, op_acc: 42.19%] [G loss: 0.805278]\n",
      "epoch:43 step:33887[D loss: 0.398452, acc: 62.50%, op_acc: 42.19%] [G loss: 0.875898]\n",
      "epoch:43 step:33888[D loss: 0.406675, acc: 63.28%, op_acc: 37.50%] [G loss: 0.805074]\n",
      "epoch:43 step:33889[D loss: 0.447376, acc: 57.03%, op_acc: 36.72%] [G loss: 0.909912]\n",
      "epoch:43 step:33890[D loss: 0.385658, acc: 67.97%, op_acc: 45.31%] [G loss: 0.847035]\n",
      "epoch:43 step:33891[D loss: 0.409884, acc: 70.31%, op_acc: 36.72%] [G loss: 0.853817]\n",
      "epoch:43 step:33892[D loss: 0.468149, acc: 51.56%, op_acc: 35.16%] [G loss: 0.835161]\n",
      "epoch:43 step:33893[D loss: 0.381452, acc: 69.53%, op_acc: 37.50%] [G loss: 0.976318]\n",
      "epoch:43 step:33894[D loss: 0.399207, acc: 67.19%, op_acc: 47.66%] [G loss: 0.879233]\n",
      "epoch:43 step:33895[D loss: 0.453025, acc: 53.91%, op_acc: 37.50%] [G loss: 0.892520]\n",
      "epoch:43 step:33896[D loss: 0.415388, acc: 59.38%, op_acc: 43.75%] [G loss: 0.938265]\n",
      "epoch:43 step:33897[D loss: 0.428556, acc: 57.03%, op_acc: 46.09%] [G loss: 0.876058]\n",
      "epoch:43 step:33898[D loss: 0.407757, acc: 65.62%, op_acc: 46.88%] [G loss: 0.996864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33899[D loss: 0.376760, acc: 63.28%, op_acc: 48.44%] [G loss: 0.924485]\n",
      "epoch:43 step:33900[D loss: 0.362616, acc: 72.66%, op_acc: 49.22%] [G loss: 0.967586]\n",
      "##############\n",
      "[0.86051127 0.87354016 0.80689866 0.81892966 0.79926976 0.83059468\n",
      " 0.8906191  0.82765473 0.81786825 0.84981712]\n",
      "##########\n",
      "epoch:43 step:33901[D loss: 0.446251, acc: 59.38%, op_acc: 36.72%] [G loss: 0.850240]\n",
      "epoch:43 step:33902[D loss: 0.416352, acc: 54.69%, op_acc: 42.19%] [G loss: 1.025832]\n",
      "epoch:43 step:33903[D loss: 0.367861, acc: 70.31%, op_acc: 42.97%] [G loss: 1.114314]\n",
      "epoch:43 step:33904[D loss: 0.427544, acc: 61.72%, op_acc: 35.94%] [G loss: 0.855245]\n",
      "epoch:43 step:33905[D loss: 0.402086, acc: 62.50%, op_acc: 41.41%] [G loss: 0.958772]\n",
      "epoch:43 step:33906[D loss: 0.393215, acc: 66.41%, op_acc: 47.66%] [G loss: 0.846093]\n",
      "epoch:43 step:33907[D loss: 0.410350, acc: 65.62%, op_acc: 33.59%] [G loss: 0.753340]\n",
      "epoch:43 step:33908[D loss: 0.396558, acc: 62.50%, op_acc: 41.41%] [G loss: 1.052549]\n",
      "epoch:43 step:33909[D loss: 0.375090, acc: 71.09%, op_acc: 45.31%] [G loss: 1.073129]\n",
      "epoch:43 step:33910[D loss: 0.404693, acc: 64.84%, op_acc: 39.84%] [G loss: 1.127881]\n",
      "epoch:43 step:33911[D loss: 0.423006, acc: 59.38%, op_acc: 46.88%] [G loss: 1.014776]\n",
      "epoch:43 step:33912[D loss: 0.389987, acc: 67.97%, op_acc: 44.53%] [G loss: 1.064917]\n",
      "epoch:43 step:33913[D loss: 0.363113, acc: 68.75%, op_acc: 46.88%] [G loss: 0.772604]\n",
      "epoch:43 step:33914[D loss: 0.370533, acc: 71.09%, op_acc: 41.41%] [G loss: 0.991384]\n",
      "epoch:43 step:33915[D loss: 0.367536, acc: 67.19%, op_acc: 40.62%] [G loss: 0.818970]\n",
      "epoch:43 step:33916[D loss: 0.421816, acc: 60.94%, op_acc: 39.06%] [G loss: 0.820070]\n",
      "epoch:43 step:33917[D loss: 0.417169, acc: 56.25%, op_acc: 42.97%] [G loss: 1.052567]\n",
      "epoch:43 step:33918[D loss: 0.428574, acc: 57.03%, op_acc: 41.41%] [G loss: 1.099424]\n",
      "epoch:43 step:33919[D loss: 0.408127, acc: 66.41%, op_acc: 39.84%] [G loss: 0.928884]\n",
      "epoch:43 step:33920[D loss: 0.437131, acc: 60.94%, op_acc: 37.50%] [G loss: 1.135927]\n",
      "epoch:43 step:33921[D loss: 0.399089, acc: 63.28%, op_acc: 42.19%] [G loss: 0.873015]\n",
      "epoch:43 step:33922[D loss: 0.406735, acc: 58.59%, op_acc: 47.66%] [G loss: 1.075625]\n",
      "epoch:43 step:33923[D loss: 0.408682, acc: 64.06%, op_acc: 36.72%] [G loss: 0.903570]\n",
      "epoch:43 step:33924[D loss: 0.412477, acc: 57.81%, op_acc: 49.22%] [G loss: 1.015327]\n",
      "epoch:43 step:33925[D loss: 0.449020, acc: 56.25%, op_acc: 41.41%] [G loss: 0.874024]\n",
      "epoch:43 step:33926[D loss: 0.447975, acc: 57.03%, op_acc: 39.06%] [G loss: 1.017735]\n",
      "epoch:43 step:33927[D loss: 0.423658, acc: 55.47%, op_acc: 40.62%] [G loss: 0.923656]\n",
      "epoch:43 step:33928[D loss: 0.430750, acc: 55.47%, op_acc: 39.84%] [G loss: 0.988448]\n",
      "epoch:43 step:33929[D loss: 0.432459, acc: 61.72%, op_acc: 39.06%] [G loss: 0.856622]\n",
      "epoch:43 step:33930[D loss: 0.399587, acc: 56.25%, op_acc: 44.53%] [G loss: 0.978094]\n",
      "epoch:43 step:33931[D loss: 0.407624, acc: 60.94%, op_acc: 42.97%] [G loss: 0.963911]\n",
      "epoch:43 step:33932[D loss: 0.431415, acc: 52.34%, op_acc: 44.53%] [G loss: 0.881966]\n",
      "epoch:43 step:33933[D loss: 0.437760, acc: 57.03%, op_acc: 39.06%] [G loss: 0.876743]\n",
      "epoch:43 step:33934[D loss: 0.444115, acc: 50.00%, op_acc: 39.06%] [G loss: 0.945720]\n",
      "epoch:43 step:33935[D loss: 0.392982, acc: 65.62%, op_acc: 38.28%] [G loss: 0.995788]\n",
      "epoch:43 step:33936[D loss: 0.407298, acc: 61.72%, op_acc: 42.19%] [G loss: 0.975652]\n",
      "epoch:43 step:33937[D loss: 0.414560, acc: 60.16%, op_acc: 46.09%] [G loss: 0.954842]\n",
      "epoch:43 step:33938[D loss: 0.418789, acc: 58.59%, op_acc: 41.41%] [G loss: 0.877002]\n",
      "epoch:43 step:33939[D loss: 0.419253, acc: 61.72%, op_acc: 41.41%] [G loss: 0.990273]\n",
      "epoch:43 step:33940[D loss: 0.459203, acc: 56.25%, op_acc: 34.38%] [G loss: 0.911077]\n",
      "epoch:43 step:33941[D loss: 0.437507, acc: 58.59%, op_acc: 39.06%] [G loss: 0.980581]\n",
      "epoch:43 step:33942[D loss: 0.434553, acc: 55.47%, op_acc: 36.72%] [G loss: 0.873611]\n",
      "epoch:43 step:33943[D loss: 0.392638, acc: 64.84%, op_acc: 45.31%] [G loss: 0.924531]\n",
      "epoch:43 step:33944[D loss: 0.391784, acc: 65.62%, op_acc: 42.97%] [G loss: 0.926038]\n",
      "epoch:43 step:33945[D loss: 0.405413, acc: 63.28%, op_acc: 40.62%] [G loss: 0.897867]\n",
      "epoch:43 step:33946[D loss: 0.419986, acc: 63.28%, op_acc: 39.06%] [G loss: 0.959809]\n",
      "epoch:43 step:33947[D loss: 0.420156, acc: 64.84%, op_acc: 35.94%] [G loss: 0.955729]\n",
      "epoch:43 step:33948[D loss: 0.411755, acc: 57.03%, op_acc: 49.22%] [G loss: 0.947549]\n",
      "epoch:43 step:33949[D loss: 0.396432, acc: 59.38%, op_acc: 46.09%] [G loss: 1.002523]\n",
      "epoch:43 step:33950[D loss: 0.418013, acc: 63.28%, op_acc: 39.06%] [G loss: 0.883504]\n",
      "##############\n",
      "[0.8568577  0.86947255 0.82444902 0.80915356 0.79476727 0.81765247\n",
      " 0.89772875 0.80522406 0.80696002 0.81715237]\n",
      "##########\n",
      "epoch:43 step:33951[D loss: 0.389599, acc: 69.53%, op_acc: 45.31%] [G loss: 1.013057]\n",
      "epoch:43 step:33952[D loss: 0.415167, acc: 61.72%, op_acc: 38.28%] [G loss: 0.927602]\n",
      "epoch:43 step:33953[D loss: 0.406920, acc: 60.94%, op_acc: 44.53%] [G loss: 0.771878]\n",
      "epoch:43 step:33954[D loss: 0.391372, acc: 58.59%, op_acc: 44.53%] [G loss: 0.942906]\n",
      "epoch:43 step:33955[D loss: 0.391994, acc: 63.28%, op_acc: 45.31%] [G loss: 0.858685]\n",
      "epoch:43 step:33956[D loss: 0.421958, acc: 54.69%, op_acc: 41.41%] [G loss: 0.905513]\n",
      "epoch:43 step:33957[D loss: 0.386180, acc: 64.84%, op_acc: 43.75%] [G loss: 0.866126]\n",
      "epoch:43 step:33958[D loss: 0.409780, acc: 55.47%, op_acc: 38.28%] [G loss: 0.913236]\n",
      "epoch:43 step:33959[D loss: 0.407786, acc: 62.50%, op_acc: 39.06%] [G loss: 0.915187]\n",
      "epoch:43 step:33960[D loss: 0.422421, acc: 55.47%, op_acc: 41.41%] [G loss: 0.905078]\n",
      "epoch:43 step:33961[D loss: 0.398025, acc: 63.28%, op_acc: 46.88%] [G loss: 0.984161]\n",
      "epoch:43 step:33962[D loss: 0.350427, acc: 72.66%, op_acc: 50.00%] [G loss: 0.955968]\n",
      "epoch:43 step:33963[D loss: 0.401410, acc: 66.41%, op_acc: 44.53%] [G loss: 1.038434]\n",
      "epoch:43 step:33964[D loss: 0.398220, acc: 67.19%, op_acc: 41.41%] [G loss: 0.817073]\n",
      "epoch:43 step:33965[D loss: 0.411459, acc: 64.84%, op_acc: 38.28%] [G loss: 1.058954]\n",
      "epoch:43 step:33966[D loss: 0.368749, acc: 69.53%, op_acc: 46.09%] [G loss: 0.855193]\n",
      "epoch:43 step:33967[D loss: 0.403392, acc: 60.16%, op_acc: 44.53%] [G loss: 0.872148]\n",
      "epoch:43 step:33968[D loss: 0.377790, acc: 66.41%, op_acc: 43.75%] [G loss: 0.798580]\n",
      "epoch:43 step:33969[D loss: 0.427959, acc: 60.16%, op_acc: 38.28%] [G loss: 0.926372]\n",
      "epoch:43 step:33970[D loss: 0.422754, acc: 60.16%, op_acc: 39.84%] [G loss: 0.881716]\n",
      "epoch:43 step:33971[D loss: 0.415118, acc: 68.75%, op_acc: 35.94%] [G loss: 0.912588]\n",
      "epoch:43 step:33972[D loss: 0.412585, acc: 54.69%, op_acc: 36.72%] [G loss: 1.020942]\n",
      "epoch:43 step:33973[D loss: 0.381637, acc: 68.75%, op_acc: 43.75%] [G loss: 0.879703]\n",
      "epoch:43 step:33974[D loss: 0.408757, acc: 60.94%, op_acc: 47.66%] [G loss: 0.841058]\n",
      "epoch:43 step:33975[D loss: 0.391179, acc: 59.38%, op_acc: 46.09%] [G loss: 1.027909]\n",
      "epoch:43 step:33976[D loss: 0.393368, acc: 64.84%, op_acc: 42.97%] [G loss: 0.865095]\n",
      "epoch:43 step:33977[D loss: 0.413509, acc: 60.16%, op_acc: 41.41%] [G loss: 0.800374]\n",
      "epoch:43 step:33978[D loss: 0.422005, acc: 62.50%, op_acc: 40.62%] [G loss: 0.938803]\n",
      "epoch:43 step:33979[D loss: 0.435534, acc: 60.94%, op_acc: 40.62%] [G loss: 0.846011]\n",
      "epoch:43 step:33980[D loss: 0.422501, acc: 54.69%, op_acc: 42.19%] [G loss: 0.790310]\n",
      "epoch:43 step:33981[D loss: 0.436001, acc: 56.25%, op_acc: 40.62%] [G loss: 0.933075]\n",
      "epoch:43 step:33982[D loss: 0.385534, acc: 67.97%, op_acc: 41.41%] [G loss: 0.821508]\n",
      "epoch:43 step:33983[D loss: 0.405024, acc: 60.16%, op_acc: 39.84%] [G loss: 0.889879]\n",
      "epoch:43 step:33984[D loss: 0.414082, acc: 60.16%, op_acc: 42.97%] [G loss: 0.855480]\n",
      "epoch:43 step:33985[D loss: 0.424883, acc: 64.06%, op_acc: 32.03%] [G loss: 0.820319]\n",
      "epoch:43 step:33986[D loss: 0.399181, acc: 67.19%, op_acc: 39.84%] [G loss: 0.918784]\n",
      "epoch:43 step:33987[D loss: 0.370101, acc: 67.97%, op_acc: 46.88%] [G loss: 0.927583]\n",
      "epoch:43 step:33988[D loss: 0.400737, acc: 69.53%, op_acc: 45.31%] [G loss: 0.945879]\n",
      "epoch:43 step:33989[D loss: 0.406864, acc: 60.94%, op_acc: 39.06%] [G loss: 0.883019]\n",
      "epoch:43 step:33990[D loss: 0.362849, acc: 72.66%, op_acc: 45.31%] [G loss: 0.834057]\n",
      "epoch:43 step:33991[D loss: 0.371930, acc: 67.19%, op_acc: 41.41%] [G loss: 0.879722]\n",
      "epoch:43 step:33992[D loss: 0.400526, acc: 62.50%, op_acc: 47.66%] [G loss: 0.799165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33993[D loss: 0.400007, acc: 63.28%, op_acc: 42.97%] [G loss: 0.856444]\n",
      "epoch:43 step:33994[D loss: 0.441273, acc: 50.78%, op_acc: 40.62%] [G loss: 0.859979]\n",
      "epoch:43 step:33995[D loss: 0.401162, acc: 62.50%, op_acc: 47.66%] [G loss: 0.900074]\n",
      "epoch:43 step:33996[D loss: 0.390687, acc: 60.16%, op_acc: 46.88%] [G loss: 0.829319]\n",
      "epoch:43 step:33997[D loss: 0.378684, acc: 64.84%, op_acc: 40.62%] [G loss: 0.909445]\n",
      "epoch:43 step:33998[D loss: 0.373772, acc: 67.19%, op_acc: 42.19%] [G loss: 0.978019]\n",
      "epoch:43 step:33999[D loss: 0.385201, acc: 62.50%, op_acc: 46.09%] [G loss: 0.981298]\n",
      "epoch:43 step:34000[D loss: 0.377320, acc: 71.09%, op_acc: 45.31%] [G loss: 1.017212]\n",
      "##############\n",
      "[0.85418031 0.8527738  0.8129439  0.81082413 0.80435917 0.82892565\n",
      " 0.90371372 0.82371708 0.80233443 0.83738245]\n",
      "##########\n",
      "epoch:43 step:34001[D loss: 0.417723, acc: 59.38%, op_acc: 39.06%] [G loss: 0.802749]\n",
      "epoch:43 step:34002[D loss: 0.398720, acc: 62.50%, op_acc: 38.28%] [G loss: 1.012628]\n",
      "epoch:43 step:34003[D loss: 0.417484, acc: 62.50%, op_acc: 46.09%] [G loss: 0.991913]\n",
      "epoch:43 step:34004[D loss: 0.405925, acc: 61.72%, op_acc: 39.84%] [G loss: 0.825842]\n",
      "epoch:43 step:34005[D loss: 0.398248, acc: 63.28%, op_acc: 47.66%] [G loss: 1.117969]\n",
      "epoch:43 step:34006[D loss: 0.392199, acc: 67.97%, op_acc: 42.19%] [G loss: 1.078201]\n",
      "epoch:43 step:34007[D loss: 0.382531, acc: 68.75%, op_acc: 44.53%] [G loss: 0.957306]\n",
      "epoch:43 step:34008[D loss: 0.412810, acc: 58.59%, op_acc: 41.41%] [G loss: 1.036040]\n",
      "epoch:43 step:34009[D loss: 0.413929, acc: 71.09%, op_acc: 41.41%] [G loss: 0.996868]\n",
      "epoch:43 step:34010[D loss: 0.395056, acc: 66.41%, op_acc: 42.19%] [G loss: 0.788298]\n",
      "epoch:43 step:34011[D loss: 0.438369, acc: 53.12%, op_acc: 40.62%] [G loss: 0.941870]\n",
      "epoch:43 step:34012[D loss: 0.413737, acc: 62.50%, op_acc: 41.41%] [G loss: 0.806182]\n",
      "epoch:43 step:34013[D loss: 0.457591, acc: 50.78%, op_acc: 37.50%] [G loss: 0.704834]\n",
      "epoch:43 step:34014[D loss: 0.446293, acc: 54.69%, op_acc: 40.62%] [G loss: 0.902901]\n",
      "epoch:43 step:34015[D loss: 0.408589, acc: 55.47%, op_acc: 39.84%] [G loss: 0.817532]\n",
      "epoch:43 step:34016[D loss: 0.389131, acc: 73.44%, op_acc: 42.97%] [G loss: 0.967512]\n",
      "epoch:43 step:34017[D loss: 0.373731, acc: 64.06%, op_acc: 45.31%] [G loss: 0.953822]\n",
      "epoch:43 step:34018[D loss: 0.429573, acc: 53.91%, op_acc: 42.19%] [G loss: 0.840434]\n",
      "epoch:43 step:34019[D loss: 0.412295, acc: 62.50%, op_acc: 37.50%] [G loss: 0.932208]\n",
      "epoch:43 step:34020[D loss: 0.445395, acc: 55.47%, op_acc: 39.06%] [G loss: 0.876623]\n",
      "epoch:43 step:34021[D loss: 0.417436, acc: 58.59%, op_acc: 44.53%] [G loss: 0.929369]\n",
      "epoch:43 step:34022[D loss: 0.394402, acc: 66.41%, op_acc: 44.53%] [G loss: 0.856953]\n",
      "epoch:43 step:34023[D loss: 0.393300, acc: 65.62%, op_acc: 41.41%] [G loss: 0.866541]\n",
      "epoch:43 step:34024[D loss: 0.427438, acc: 56.25%, op_acc: 35.94%] [G loss: 0.855200]\n",
      "epoch:43 step:34025[D loss: 0.414170, acc: 64.06%, op_acc: 41.41%] [G loss: 0.910248]\n",
      "epoch:43 step:34026[D loss: 0.429352, acc: 52.34%, op_acc: 40.62%] [G loss: 0.845918]\n",
      "epoch:43 step:34027[D loss: 0.384994, acc: 67.97%, op_acc: 44.53%] [G loss: 0.941706]\n",
      "epoch:43 step:34028[D loss: 0.430560, acc: 62.50%, op_acc: 42.97%] [G loss: 0.889562]\n",
      "epoch:43 step:34029[D loss: 0.428997, acc: 59.38%, op_acc: 39.06%] [G loss: 0.885818]\n",
      "epoch:43 step:34030[D loss: 0.439525, acc: 59.38%, op_acc: 38.28%] [G loss: 0.813877]\n",
      "epoch:43 step:34031[D loss: 0.374001, acc: 70.31%, op_acc: 41.41%] [G loss: 0.904972]\n",
      "epoch:43 step:34032[D loss: 0.383771, acc: 66.41%, op_acc: 40.62%] [G loss: 0.947341]\n",
      "epoch:43 step:34033[D loss: 0.433984, acc: 61.72%, op_acc: 37.50%] [G loss: 0.879104]\n",
      "epoch:43 step:34034[D loss: 0.417299, acc: 60.94%, op_acc: 43.75%] [G loss: 0.917367]\n",
      "epoch:43 step:34035[D loss: 0.405443, acc: 58.59%, op_acc: 46.88%] [G loss: 0.973040]\n",
      "epoch:43 step:34036[D loss: 0.422874, acc: 57.81%, op_acc: 42.97%] [G loss: 0.955198]\n",
      "epoch:43 step:34037[D loss: 0.369978, acc: 71.88%, op_acc: 47.66%] [G loss: 0.922921]\n",
      "epoch:43 step:34038[D loss: 0.367320, acc: 71.09%, op_acc: 46.88%] [G loss: 0.809561]\n",
      "epoch:43 step:34039[D loss: 0.412752, acc: 63.28%, op_acc: 38.28%] [G loss: 0.988127]\n",
      "epoch:43 step:34040[D loss: 0.398627, acc: 66.41%, op_acc: 42.19%] [G loss: 0.873816]\n",
      "epoch:43 step:34041[D loss: 0.380231, acc: 70.31%, op_acc: 41.41%] [G loss: 0.895402]\n",
      "epoch:43 step:34042[D loss: 0.379008, acc: 64.84%, op_acc: 50.78%] [G loss: 0.815539]\n",
      "epoch:43 step:34043[D loss: 0.384753, acc: 63.28%, op_acc: 50.00%] [G loss: 0.967371]\n",
      "epoch:43 step:34044[D loss: 0.432293, acc: 49.22%, op_acc: 46.09%] [G loss: 0.868287]\n",
      "epoch:43 step:34045[D loss: 0.389968, acc: 67.97%, op_acc: 44.53%] [G loss: 0.922975]\n",
      "epoch:43 step:34046[D loss: 0.387824, acc: 62.50%, op_acc: 48.44%] [G loss: 1.045719]\n",
      "epoch:43 step:34047[D loss: 0.422704, acc: 61.72%, op_acc: 39.84%] [G loss: 0.959399]\n",
      "epoch:43 step:34048[D loss: 0.399810, acc: 63.28%, op_acc: 45.31%] [G loss: 0.986428]\n",
      "epoch:43 step:34049[D loss: 0.395803, acc: 65.62%, op_acc: 43.75%] [G loss: 0.961531]\n",
      "epoch:43 step:34050[D loss: 0.404743, acc: 61.72%, op_acc: 42.97%] [G loss: 0.981842]\n",
      "##############\n",
      "[0.85687498 0.87329522 0.82948041 0.80575814 0.8157463  0.82093928\n",
      " 0.90194959 0.81844558 0.83050299 0.83969648]\n",
      "##########\n",
      "epoch:43 step:34051[D loss: 0.416892, acc: 60.94%, op_acc: 45.31%] [G loss: 0.904796]\n",
      "epoch:43 step:34052[D loss: 0.366098, acc: 70.31%, op_acc: 40.62%] [G loss: 0.886400]\n",
      "epoch:43 step:34053[D loss: 0.394079, acc: 67.19%, op_acc: 46.88%] [G loss: 0.888199]\n",
      "epoch:43 step:34054[D loss: 0.395479, acc: 71.09%, op_acc: 39.84%] [G loss: 0.904620]\n",
      "epoch:43 step:34055[D loss: 0.385508, acc: 64.84%, op_acc: 45.31%] [G loss: 0.880978]\n",
      "epoch:43 step:34056[D loss: 0.411190, acc: 53.12%, op_acc: 45.31%] [G loss: 0.899254]\n",
      "epoch:43 step:34057[D loss: 0.403583, acc: 59.38%, op_acc: 45.31%] [G loss: 0.924663]\n",
      "epoch:43 step:34058[D loss: 0.422322, acc: 57.81%, op_acc: 46.88%] [G loss: 0.836941]\n",
      "epoch:43 step:34059[D loss: 0.428135, acc: 57.81%, op_acc: 40.62%] [G loss: 0.811991]\n",
      "epoch:43 step:34060[D loss: 0.391002, acc: 70.31%, op_acc: 44.53%] [G loss: 0.964998]\n",
      "epoch:43 step:34061[D loss: 0.398873, acc: 60.94%, op_acc: 40.62%] [G loss: 0.940333]\n",
      "epoch:43 step:34062[D loss: 0.404211, acc: 65.62%, op_acc: 41.41%] [G loss: 0.953675]\n",
      "epoch:43 step:34063[D loss: 0.439040, acc: 60.94%, op_acc: 33.59%] [G loss: 0.990106]\n",
      "epoch:43 step:34064[D loss: 0.412806, acc: 67.19%, op_acc: 39.06%] [G loss: 0.923245]\n",
      "epoch:43 step:34065[D loss: 0.403061, acc: 67.19%, op_acc: 42.19%] [G loss: 0.898754]\n",
      "epoch:43 step:34066[D loss: 0.389825, acc: 73.44%, op_acc: 46.09%] [G loss: 1.006150]\n",
      "epoch:43 step:34067[D loss: 0.383608, acc: 60.16%, op_acc: 46.88%] [G loss: 0.908224]\n",
      "epoch:43 step:34068[D loss: 0.449171, acc: 55.47%, op_acc: 35.16%] [G loss: 0.933133]\n",
      "epoch:43 step:34069[D loss: 0.381758, acc: 67.19%, op_acc: 44.53%] [G loss: 0.871283]\n",
      "epoch:43 step:34070[D loss: 0.395261, acc: 63.28%, op_acc: 42.97%] [G loss: 0.871763]\n",
      "epoch:43 step:34071[D loss: 0.413149, acc: 58.59%, op_acc: 39.84%] [G loss: 0.924210]\n",
      "epoch:43 step:34072[D loss: 0.413342, acc: 64.84%, op_acc: 46.09%] [G loss: 0.912343]\n",
      "epoch:43 step:34073[D loss: 0.366383, acc: 71.88%, op_acc: 49.22%] [G loss: 0.917483]\n",
      "epoch:43 step:34074[D loss: 0.453321, acc: 54.69%, op_acc: 40.62%] [G loss: 0.845769]\n",
      "epoch:43 step:34075[D loss: 0.420379, acc: 56.25%, op_acc: 42.19%] [G loss: 0.905852]\n",
      "epoch:43 step:34076[D loss: 0.427347, acc: 57.03%, op_acc: 41.41%] [G loss: 0.987630]\n",
      "epoch:43 step:34077[D loss: 0.397406, acc: 64.84%, op_acc: 47.66%] [G loss: 0.932337]\n",
      "epoch:43 step:34078[D loss: 0.405154, acc: 65.62%, op_acc: 38.28%] [G loss: 0.951401]\n",
      "epoch:43 step:34079[D loss: 0.393334, acc: 65.62%, op_acc: 46.88%] [G loss: 0.863580]\n",
      "epoch:43 step:34080[D loss: 0.390502, acc: 62.50%, op_acc: 46.88%] [G loss: 0.846087]\n",
      "epoch:43 step:34081[D loss: 0.435380, acc: 56.25%, op_acc: 35.94%] [G loss: 0.902011]\n",
      "epoch:43 step:34082[D loss: 0.405745, acc: 64.84%, op_acc: 35.94%] [G loss: 0.978430]\n",
      "epoch:43 step:34083[D loss: 0.359066, acc: 74.22%, op_acc: 41.41%] [G loss: 0.912799]\n",
      "epoch:43 step:34084[D loss: 0.411789, acc: 61.72%, op_acc: 42.97%] [G loss: 0.988920]\n",
      "epoch:43 step:34085[D loss: 0.428350, acc: 54.69%, op_acc: 39.84%] [G loss: 0.927064]\n",
      "epoch:43 step:34086[D loss: 0.383255, acc: 58.59%, op_acc: 46.09%] [G loss: 0.879618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34087[D loss: 0.413961, acc: 60.16%, op_acc: 46.88%] [G loss: 0.925086]\n",
      "epoch:43 step:34088[D loss: 0.419545, acc: 64.84%, op_acc: 45.31%] [G loss: 0.857523]\n",
      "epoch:43 step:34089[D loss: 0.411461, acc: 60.94%, op_acc: 46.09%] [G loss: 0.854248]\n",
      "epoch:43 step:34090[D loss: 0.386723, acc: 67.19%, op_acc: 46.88%] [G loss: 0.853406]\n",
      "epoch:43 step:34091[D loss: 0.389011, acc: 66.41%, op_acc: 39.84%] [G loss: 0.903780]\n",
      "epoch:43 step:34092[D loss: 0.416358, acc: 63.28%, op_acc: 40.62%] [G loss: 0.944404]\n",
      "epoch:43 step:34093[D loss: 0.394721, acc: 68.75%, op_acc: 42.19%] [G loss: 0.888720]\n",
      "epoch:43 step:34094[D loss: 0.416392, acc: 57.81%, op_acc: 49.22%] [G loss: 0.912792]\n",
      "epoch:43 step:34095[D loss: 0.424719, acc: 58.59%, op_acc: 42.19%] [G loss: 0.816356]\n",
      "epoch:43 step:34096[D loss: 0.419426, acc: 60.94%, op_acc: 39.84%] [G loss: 0.906129]\n",
      "epoch:43 step:34097[D loss: 0.408224, acc: 65.62%, op_acc: 41.41%] [G loss: 0.853860]\n",
      "epoch:43 step:34098[D loss: 0.373554, acc: 71.09%, op_acc: 42.97%] [G loss: 0.975096]\n",
      "epoch:43 step:34099[D loss: 0.405218, acc: 62.50%, op_acc: 44.53%] [G loss: 1.003277]\n",
      "epoch:43 step:34100[D loss: 0.426937, acc: 64.06%, op_acc: 40.62%] [G loss: 0.900945]\n",
      "##############\n",
      "[0.85923117 0.8533063  0.80193684 0.78555795 0.79503886 0.82645317\n",
      " 0.92046414 0.82469267 0.80788719 0.81584825]\n",
      "##########\n",
      "epoch:43 step:34101[D loss: 0.359674, acc: 75.78%, op_acc: 44.53%] [G loss: 0.981410]\n",
      "epoch:43 step:34102[D loss: 0.373995, acc: 66.41%, op_acc: 44.53%] [G loss: 0.959935]\n",
      "epoch:43 step:34103[D loss: 0.401185, acc: 63.28%, op_acc: 48.44%] [G loss: 0.983730]\n",
      "epoch:43 step:34104[D loss: 0.399399, acc: 63.28%, op_acc: 42.19%] [G loss: 0.930998]\n",
      "epoch:43 step:34105[D loss: 0.413024, acc: 58.59%, op_acc: 47.66%] [G loss: 0.931130]\n",
      "epoch:43 step:34106[D loss: 0.419252, acc: 61.72%, op_acc: 39.06%] [G loss: 1.025545]\n",
      "epoch:43 step:34107[D loss: 0.400220, acc: 67.19%, op_acc: 40.62%] [G loss: 0.942515]\n",
      "epoch:43 step:34108[D loss: 0.398295, acc: 64.84%, op_acc: 41.41%] [G loss: 0.987408]\n",
      "epoch:43 step:34109[D loss: 0.439897, acc: 55.47%, op_acc: 35.94%] [G loss: 0.906864]\n",
      "epoch:43 step:34110[D loss: 0.396968, acc: 60.94%, op_acc: 44.53%] [G loss: 1.022638]\n",
      "epoch:43 step:34111[D loss: 0.402563, acc: 57.03%, op_acc: 46.88%] [G loss: 0.938086]\n",
      "epoch:43 step:34112[D loss: 0.392508, acc: 64.84%, op_acc: 40.62%] [G loss: 1.102990]\n",
      "epoch:43 step:34113[D loss: 0.399024, acc: 67.19%, op_acc: 43.75%] [G loss: 0.939476]\n",
      "epoch:43 step:34114[D loss: 0.407187, acc: 69.53%, op_acc: 45.31%] [G loss: 0.974734]\n",
      "epoch:43 step:34115[D loss: 0.395452, acc: 66.41%, op_acc: 43.75%] [G loss: 1.087453]\n",
      "epoch:43 step:34116[D loss: 0.420506, acc: 57.03%, op_acc: 46.88%] [G loss: 0.911155]\n",
      "epoch:43 step:34117[D loss: 0.408346, acc: 57.81%, op_acc: 46.88%] [G loss: 0.923135]\n",
      "epoch:43 step:34118[D loss: 0.411146, acc: 64.06%, op_acc: 44.53%] [G loss: 0.898435]\n",
      "epoch:43 step:34119[D loss: 0.396143, acc: 57.81%, op_acc: 50.00%] [G loss: 0.884942]\n",
      "epoch:43 step:34120[D loss: 0.480751, acc: 46.88%, op_acc: 35.16%] [G loss: 0.891256]\n",
      "epoch:43 step:34121[D loss: 0.421762, acc: 58.59%, op_acc: 42.97%] [G loss: 0.897646]\n",
      "epoch:43 step:34122[D loss: 0.405355, acc: 57.81%, op_acc: 46.09%] [G loss: 0.971309]\n",
      "epoch:43 step:34123[D loss: 0.424911, acc: 53.91%, op_acc: 42.97%] [G loss: 0.990755]\n",
      "epoch:43 step:34124[D loss: 0.403760, acc: 63.28%, op_acc: 41.41%] [G loss: 0.891853]\n",
      "epoch:43 step:34125[D loss: 0.411700, acc: 64.06%, op_acc: 41.41%] [G loss: 0.991329]\n",
      "epoch:43 step:34126[D loss: 0.418692, acc: 62.50%, op_acc: 43.75%] [G loss: 0.929759]\n",
      "epoch:43 step:34127[D loss: 0.422490, acc: 62.50%, op_acc: 43.75%] [G loss: 0.862721]\n",
      "epoch:43 step:34128[D loss: 0.371897, acc: 73.44%, op_acc: 43.75%] [G loss: 0.887665]\n",
      "epoch:43 step:34129[D loss: 0.427984, acc: 54.69%, op_acc: 44.53%] [G loss: 0.957920]\n",
      "epoch:43 step:34130[D loss: 0.432974, acc: 54.69%, op_acc: 39.06%] [G loss: 0.917751]\n",
      "epoch:43 step:34131[D loss: 0.433550, acc: 60.16%, op_acc: 35.94%] [G loss: 0.957189]\n",
      "epoch:43 step:34132[D loss: 0.412423, acc: 64.06%, op_acc: 43.75%] [G loss: 0.863694]\n",
      "epoch:43 step:34133[D loss: 0.388312, acc: 66.41%, op_acc: 40.62%] [G loss: 0.887818]\n",
      "epoch:43 step:34134[D loss: 0.453722, acc: 50.78%, op_acc: 37.50%] [G loss: 0.907212]\n",
      "epoch:43 step:34135[D loss: 0.456043, acc: 50.00%, op_acc: 39.84%] [G loss: 0.919606]\n",
      "epoch:43 step:34136[D loss: 0.391591, acc: 68.75%, op_acc: 42.19%] [G loss: 1.001087]\n",
      "epoch:43 step:34137[D loss: 0.397103, acc: 66.41%, op_acc: 40.62%] [G loss: 0.904444]\n",
      "epoch:43 step:34138[D loss: 0.406274, acc: 60.94%, op_acc: 42.97%] [G loss: 0.890167]\n",
      "epoch:43 step:34139[D loss: 0.401858, acc: 66.41%, op_acc: 41.41%] [G loss: 0.951014]\n",
      "epoch:43 step:34140[D loss: 0.412843, acc: 61.72%, op_acc: 39.84%] [G loss: 0.850282]\n",
      "epoch:43 step:34141[D loss: 0.419931, acc: 54.69%, op_acc: 43.75%] [G loss: 0.888167]\n",
      "epoch:43 step:34142[D loss: 0.383751, acc: 65.62%, op_acc: 40.62%] [G loss: 0.849062]\n",
      "epoch:43 step:34143[D loss: 0.459366, acc: 53.91%, op_acc: 32.81%] [G loss: 0.847036]\n",
      "epoch:43 step:34144[D loss: 0.443257, acc: 56.25%, op_acc: 41.41%] [G loss: 0.920119]\n",
      "epoch:43 step:34145[D loss: 0.432063, acc: 58.59%, op_acc: 42.19%] [G loss: 0.925167]\n",
      "epoch:43 step:34146[D loss: 0.363008, acc: 72.66%, op_acc: 47.66%] [G loss: 0.975516]\n",
      "epoch:43 step:34147[D loss: 0.387241, acc: 64.84%, op_acc: 47.66%] [G loss: 0.881907]\n",
      "epoch:43 step:34148[D loss: 0.422890, acc: 59.38%, op_acc: 40.62%] [G loss: 0.822092]\n",
      "epoch:43 step:34149[D loss: 0.419188, acc: 60.16%, op_acc: 39.84%] [G loss: 0.933835]\n",
      "epoch:43 step:34150[D loss: 0.365976, acc: 67.19%, op_acc: 45.31%] [G loss: 0.963717]\n",
      "##############\n",
      "[0.85620645 0.86232653 0.81386946 0.79022273 0.77325852 0.8279741\n",
      " 0.87579918 0.8355546  0.80590395 0.82732478]\n",
      "##########\n",
      "epoch:43 step:34151[D loss: 0.380440, acc: 63.28%, op_acc: 45.31%] [G loss: 0.841996]\n",
      "epoch:43 step:34152[D loss: 0.387672, acc: 64.84%, op_acc: 39.84%] [G loss: 0.955782]\n",
      "epoch:43 step:34153[D loss: 0.418603, acc: 61.72%, op_acc: 37.50%] [G loss: 0.940305]\n",
      "epoch:43 step:34154[D loss: 0.420073, acc: 56.25%, op_acc: 44.53%] [G loss: 0.792712]\n",
      "epoch:43 step:34155[D loss: 0.385401, acc: 58.59%, op_acc: 46.09%] [G loss: 1.002278]\n",
      "epoch:43 step:34156[D loss: 0.450702, acc: 50.78%, op_acc: 39.06%] [G loss: 0.868075]\n",
      "epoch:43 step:34157[D loss: 0.410047, acc: 66.41%, op_acc: 37.50%] [G loss: 0.942768]\n",
      "epoch:43 step:34158[D loss: 0.404217, acc: 63.28%, op_acc: 38.28%] [G loss: 0.790438]\n",
      "epoch:43 step:34159[D loss: 0.388275, acc: 67.19%, op_acc: 43.75%] [G loss: 0.934479]\n",
      "epoch:43 step:34160[D loss: 0.447648, acc: 60.16%, op_acc: 37.50%] [G loss: 0.779662]\n",
      "epoch:43 step:34161[D loss: 0.439069, acc: 58.59%, op_acc: 34.38%] [G loss: 0.950679]\n",
      "epoch:43 step:34162[D loss: 0.391205, acc: 67.19%, op_acc: 42.97%] [G loss: 0.856880]\n",
      "epoch:43 step:34163[D loss: 0.420232, acc: 64.06%, op_acc: 41.41%] [G loss: 0.900740]\n",
      "epoch:43 step:34164[D loss: 0.411493, acc: 64.06%, op_acc: 48.44%] [G loss: 0.848722]\n",
      "epoch:43 step:34165[D loss: 0.448386, acc: 51.56%, op_acc: 42.97%] [G loss: 0.905408]\n",
      "epoch:43 step:34166[D loss: 0.377623, acc: 67.97%, op_acc: 50.00%] [G loss: 0.725389]\n",
      "epoch:43 step:34167[D loss: 0.452334, acc: 57.03%, op_acc: 37.50%] [G loss: 0.859344]\n",
      "epoch:43 step:34168[D loss: 0.414917, acc: 64.84%, op_acc: 40.62%] [G loss: 0.848798]\n",
      "epoch:43 step:34169[D loss: 0.383657, acc: 70.31%, op_acc: 39.84%] [G loss: 0.796989]\n",
      "epoch:43 step:34170[D loss: 0.408021, acc: 63.28%, op_acc: 44.53%] [G loss: 0.860634]\n",
      "epoch:43 step:34171[D loss: 0.400744, acc: 56.25%, op_acc: 48.44%] [G loss: 0.832959]\n",
      "epoch:43 step:34172[D loss: 0.412336, acc: 68.75%, op_acc: 41.41%] [G loss: 0.963490]\n",
      "epoch:43 step:34173[D loss: 0.366512, acc: 69.53%, op_acc: 39.84%] [G loss: 0.893431]\n",
      "epoch:43 step:34174[D loss: 0.411815, acc: 62.50%, op_acc: 43.75%] [G loss: 0.855554]\n",
      "epoch:43 step:34175[D loss: 0.432358, acc: 53.12%, op_acc: 39.06%] [G loss: 0.924324]\n",
      "epoch:43 step:34176[D loss: 0.414894, acc: 62.50%, op_acc: 36.72%] [G loss: 0.937493]\n",
      "epoch:43 step:34177[D loss: 0.455728, acc: 57.03%, op_acc: 41.41%] [G loss: 0.878647]\n",
      "epoch:43 step:34178[D loss: 0.409383, acc: 63.28%, op_acc: 42.19%] [G loss: 0.990257]\n",
      "epoch:43 step:34179[D loss: 0.401620, acc: 65.62%, op_acc: 39.84%] [G loss: 0.870022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34180[D loss: 0.394242, acc: 67.97%, op_acc: 42.97%] [G loss: 1.002248]\n",
      "epoch:43 step:34181[D loss: 0.386640, acc: 63.28%, op_acc: 44.53%] [G loss: 0.988956]\n",
      "epoch:43 step:34182[D loss: 0.383726, acc: 68.75%, op_acc: 38.28%] [G loss: 0.947014]\n",
      "epoch:43 step:34183[D loss: 0.407995, acc: 57.81%, op_acc: 44.53%] [G loss: 0.971447]\n",
      "epoch:43 step:34184[D loss: 0.411184, acc: 58.59%, op_acc: 43.75%] [G loss: 1.024256]\n",
      "epoch:43 step:34185[D loss: 0.395317, acc: 60.16%, op_acc: 45.31%] [G loss: 0.950615]\n",
      "epoch:43 step:34186[D loss: 0.376256, acc: 64.06%, op_acc: 43.75%] [G loss: 0.771749]\n",
      "epoch:43 step:34187[D loss: 0.457873, acc: 55.47%, op_acc: 37.50%] [G loss: 0.726990]\n",
      "epoch:43 step:34188[D loss: 0.410279, acc: 61.72%, op_acc: 37.50%] [G loss: 0.798799]\n",
      "epoch:43 step:34189[D loss: 0.420018, acc: 60.16%, op_acc: 42.97%] [G loss: 0.849990]\n",
      "epoch:43 step:34190[D loss: 0.407442, acc: 57.81%, op_acc: 45.31%] [G loss: 0.905154]\n",
      "epoch:43 step:34191[D loss: 0.363935, acc: 71.09%, op_acc: 48.44%] [G loss: 0.915091]\n",
      "epoch:43 step:34192[D loss: 0.385897, acc: 63.28%, op_acc: 44.53%] [G loss: 0.855513]\n",
      "epoch:43 step:34193[D loss: 0.407004, acc: 64.06%, op_acc: 42.97%] [G loss: 0.970250]\n",
      "epoch:43 step:34194[D loss: 0.386057, acc: 68.75%, op_acc: 46.09%] [G loss: 0.927315]\n",
      "epoch:43 step:34195[D loss: 0.399523, acc: 63.28%, op_acc: 43.75%] [G loss: 0.914712]\n",
      "epoch:43 step:34196[D loss: 0.409747, acc: 57.81%, op_acc: 44.53%] [G loss: 0.911466]\n",
      "epoch:43 step:34197[D loss: 0.407246, acc: 67.19%, op_acc: 39.06%] [G loss: 0.896105]\n",
      "epoch:43 step:34198[D loss: 0.399251, acc: 67.19%, op_acc: 40.62%] [G loss: 0.910507]\n",
      "epoch:43 step:34199[D loss: 0.405024, acc: 64.84%, op_acc: 42.97%] [G loss: 0.873689]\n",
      "epoch:43 step:34200[D loss: 0.421621, acc: 56.25%, op_acc: 43.75%] [G loss: 0.955696]\n",
      "##############\n",
      "[0.86146063 0.85643543 0.8117774  0.8136173  0.78169971 0.82277758\n",
      " 0.89613709 0.83928464 0.81805631 0.84421747]\n",
      "##########\n",
      "epoch:43 step:34201[D loss: 0.386448, acc: 65.62%, op_acc: 43.75%] [G loss: 0.879735]\n",
      "epoch:43 step:34202[D loss: 0.414027, acc: 63.28%, op_acc: 40.62%] [G loss: 0.847858]\n",
      "epoch:43 step:34203[D loss: 0.451592, acc: 56.25%, op_acc: 38.28%] [G loss: 0.865096]\n",
      "epoch:43 step:34204[D loss: 0.386481, acc: 66.41%, op_acc: 41.41%] [G loss: 0.919573]\n",
      "epoch:43 step:34205[D loss: 0.452915, acc: 54.69%, op_acc: 40.62%] [G loss: 0.861523]\n",
      "epoch:43 step:34206[D loss: 0.410652, acc: 59.38%, op_acc: 40.62%] [G loss: 0.944860]\n",
      "epoch:43 step:34207[D loss: 0.394245, acc: 57.03%, op_acc: 46.88%] [G loss: 0.948555]\n",
      "epoch:43 step:34208[D loss: 0.388801, acc: 65.62%, op_acc: 42.19%] [G loss: 0.943088]\n",
      "epoch:43 step:34209[D loss: 0.399172, acc: 64.06%, op_acc: 42.19%] [G loss: 0.886897]\n",
      "epoch:43 step:34210[D loss: 0.399905, acc: 67.19%, op_acc: 43.75%] [G loss: 0.935959]\n",
      "epoch:43 step:34211[D loss: 0.384188, acc: 64.06%, op_acc: 42.19%] [G loss: 0.964712]\n",
      "epoch:43 step:34212[D loss: 0.426792, acc: 60.16%, op_acc: 40.62%] [G loss: 0.971239]\n",
      "epoch:43 step:34213[D loss: 0.420655, acc: 57.81%, op_acc: 44.53%] [G loss: 0.974942]\n",
      "epoch:43 step:34214[D loss: 0.425338, acc: 61.72%, op_acc: 41.41%] [G loss: 0.964012]\n",
      "epoch:43 step:34215[D loss: 0.432191, acc: 60.16%, op_acc: 41.41%] [G loss: 0.911383]\n",
      "epoch:43 step:34216[D loss: 0.432932, acc: 57.81%, op_acc: 42.19%] [G loss: 0.946143]\n",
      "epoch:43 step:34217[D loss: 0.415596, acc: 63.28%, op_acc: 42.97%] [G loss: 0.861338]\n",
      "epoch:43 step:34218[D loss: 0.430511, acc: 51.56%, op_acc: 46.88%] [G loss: 0.897329]\n",
      "epoch:43 step:34219[D loss: 0.392555, acc: 67.97%, op_acc: 45.31%] [G loss: 0.969732]\n",
      "epoch:43 step:34220[D loss: 0.406325, acc: 59.38%, op_acc: 42.19%] [G loss: 0.918500]\n",
      "epoch:43 step:34221[D loss: 0.418269, acc: 63.28%, op_acc: 45.31%] [G loss: 0.989622]\n",
      "epoch:43 step:34222[D loss: 0.419621, acc: 59.38%, op_acc: 39.84%] [G loss: 0.704406]\n",
      "epoch:43 step:34223[D loss: 0.414001, acc: 62.50%, op_acc: 45.31%] [G loss: 0.793584]\n",
      "epoch:43 step:34224[D loss: 0.363510, acc: 68.75%, op_acc: 46.88%] [G loss: 0.879195]\n",
      "epoch:43 step:34225[D loss: 0.408171, acc: 60.16%, op_acc: 41.41%] [G loss: 0.863415]\n",
      "epoch:43 step:34226[D loss: 0.410805, acc: 61.72%, op_acc: 43.75%] [G loss: 0.896604]\n",
      "epoch:43 step:34227[D loss: 0.375397, acc: 68.75%, op_acc: 46.09%] [G loss: 0.914304]\n",
      "epoch:43 step:34228[D loss: 0.380513, acc: 69.53%, op_acc: 42.97%] [G loss: 0.924901]\n",
      "epoch:43 step:34229[D loss: 0.392358, acc: 69.53%, op_acc: 39.06%] [G loss: 0.920469]\n",
      "epoch:43 step:34230[D loss: 0.384953, acc: 66.41%, op_acc: 44.53%] [G loss: 0.917748]\n",
      "epoch:43 step:34231[D loss: 0.421725, acc: 67.19%, op_acc: 42.19%] [G loss: 0.968442]\n",
      "epoch:43 step:34232[D loss: 0.389362, acc: 70.31%, op_acc: 41.41%] [G loss: 0.851428]\n",
      "epoch:43 step:34233[D loss: 0.412993, acc: 66.41%, op_acc: 40.62%] [G loss: 0.944980]\n",
      "epoch:43 step:34234[D loss: 0.402932, acc: 59.38%, op_acc: 48.44%] [G loss: 0.896816]\n",
      "epoch:43 step:34235[D loss: 0.400986, acc: 70.31%, op_acc: 43.75%] [G loss: 0.955562]\n",
      "epoch:43 step:34236[D loss: 0.366417, acc: 65.62%, op_acc: 47.66%] [G loss: 0.913525]\n",
      "epoch:43 step:34237[D loss: 0.402440, acc: 57.03%, op_acc: 49.22%] [G loss: 0.955911]\n",
      "epoch:43 step:34238[D loss: 0.383575, acc: 61.72%, op_acc: 46.88%] [G loss: 0.956974]\n",
      "epoch:43 step:34239[D loss: 0.425548, acc: 66.41%, op_acc: 36.72%] [G loss: 0.814023]\n",
      "epoch:43 step:34240[D loss: 0.421356, acc: 60.16%, op_acc: 42.19%] [G loss: 0.840262]\n",
      "epoch:43 step:34241[D loss: 0.425461, acc: 59.38%, op_acc: 33.59%] [G loss: 0.913025]\n",
      "epoch:43 step:34242[D loss: 0.384661, acc: 65.62%, op_acc: 46.88%] [G loss: 0.923932]\n",
      "epoch:43 step:34243[D loss: 0.434274, acc: 54.69%, op_acc: 46.88%] [G loss: 1.000923]\n",
      "epoch:43 step:34244[D loss: 0.399672, acc: 59.38%, op_acc: 42.19%] [G loss: 0.983240]\n",
      "epoch:43 step:34245[D loss: 0.434329, acc: 55.47%, op_acc: 41.41%] [G loss: 0.823410]\n",
      "epoch:43 step:34246[D loss: 0.397103, acc: 62.50%, op_acc: 46.09%] [G loss: 1.010049]\n",
      "epoch:43 step:34247[D loss: 0.386200, acc: 66.41%, op_acc: 42.19%] [G loss: 0.820748]\n",
      "epoch:43 step:34248[D loss: 0.404757, acc: 66.41%, op_acc: 33.59%] [G loss: 0.940948]\n",
      "epoch:43 step:34249[D loss: 0.384878, acc: 67.19%, op_acc: 46.88%] [G loss: 0.841104]\n",
      "epoch:43 step:34250[D loss: 0.373545, acc: 67.19%, op_acc: 46.88%] [G loss: 0.919488]\n",
      "##############\n",
      "[0.86176936 0.85134977 0.81098025 0.80863396 0.8036203  0.83555307\n",
      " 0.88948665 0.83625979 0.80082553 0.83138596]\n",
      "##########\n",
      "epoch:43 step:34251[D loss: 0.428690, acc: 54.69%, op_acc: 43.75%] [G loss: 0.897437]\n",
      "epoch:43 step:34252[D loss: 0.391669, acc: 64.84%, op_acc: 45.31%] [G loss: 0.910993]\n",
      "epoch:43 step:34253[D loss: 0.426170, acc: 56.25%, op_acc: 52.34%] [G loss: 1.042593]\n",
      "epoch:43 step:34254[D loss: 0.410930, acc: 67.19%, op_acc: 46.09%] [G loss: 0.883657]\n",
      "epoch:43 step:34255[D loss: 0.425889, acc: 62.50%, op_acc: 40.62%] [G loss: 0.852376]\n",
      "epoch:43 step:34256[D loss: 0.401204, acc: 65.62%, op_acc: 41.41%] [G loss: 0.997960]\n",
      "epoch:43 step:34257[D loss: 0.407358, acc: 61.72%, op_acc: 38.28%] [G loss: 0.766297]\n",
      "epoch:43 step:34258[D loss: 0.388345, acc: 62.50%, op_acc: 49.22%] [G loss: 0.707608]\n",
      "epoch:43 step:34259[D loss: 0.421924, acc: 57.81%, op_acc: 40.62%] [G loss: 0.818045]\n",
      "epoch:43 step:34260[D loss: 0.452625, acc: 59.38%, op_acc: 34.38%] [G loss: 0.932599]\n",
      "epoch:43 step:34261[D loss: 0.401880, acc: 60.16%, op_acc: 42.19%] [G loss: 0.975084]\n",
      "epoch:43 step:34262[D loss: 0.385666, acc: 63.28%, op_acc: 45.31%] [G loss: 0.862252]\n",
      "epoch:43 step:34263[D loss: 0.402193, acc: 66.41%, op_acc: 39.84%] [G loss: 0.968696]\n",
      "epoch:43 step:34264[D loss: 0.425718, acc: 63.28%, op_acc: 39.84%] [G loss: 0.812191]\n",
      "epoch:43 step:34265[D loss: 0.377764, acc: 61.72%, op_acc: 46.88%] [G loss: 0.862036]\n",
      "epoch:43 step:34266[D loss: 0.426048, acc: 61.72%, op_acc: 40.62%] [G loss: 0.919871]\n",
      "epoch:43 step:34267[D loss: 0.391199, acc: 64.06%, op_acc: 42.97%] [G loss: 0.727912]\n",
      "epoch:43 step:34268[D loss: 0.432806, acc: 54.69%, op_acc: 42.97%] [G loss: 0.847646]\n",
      "epoch:43 step:34269[D loss: 0.387048, acc: 62.50%, op_acc: 46.09%] [G loss: 0.815157]\n",
      "epoch:43 step:34270[D loss: 0.447358, acc: 57.81%, op_acc: 38.28%] [G loss: 0.970058]\n",
      "epoch:43 step:34271[D loss: 0.416252, acc: 60.94%, op_acc: 43.75%] [G loss: 0.963634]\n",
      "epoch:43 step:34272[D loss: 0.364725, acc: 71.09%, op_acc: 47.66%] [G loss: 1.000996]\n",
      "epoch:43 step:34273[D loss: 0.416901, acc: 60.94%, op_acc: 41.41%] [G loss: 0.946459]\n",
      "epoch:43 step:34274[D loss: 0.406941, acc: 61.72%, op_acc: 43.75%] [G loss: 0.707299]\n",
      "epoch:43 step:34275[D loss: 0.417307, acc: 58.59%, op_acc: 43.75%] [G loss: 0.755447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34276[D loss: 0.391855, acc: 64.06%, op_acc: 45.31%] [G loss: 0.744270]\n",
      "epoch:43 step:34277[D loss: 0.440371, acc: 53.91%, op_acc: 41.41%] [G loss: 0.744270]\n",
      "epoch:43 step:34278[D loss: 0.402355, acc: 64.06%, op_acc: 39.84%] [G loss: 0.924990]\n",
      "epoch:43 step:34279[D loss: 0.446160, acc: 57.81%, op_acc: 35.94%] [G loss: 0.825149]\n",
      "epoch:43 step:34280[D loss: 0.423250, acc: 54.69%, op_acc: 46.88%] [G loss: 0.753033]\n",
      "epoch:43 step:34281[D loss: 0.409671, acc: 61.72%, op_acc: 37.50%] [G loss: 0.818738]\n",
      "epoch:43 step:34282[D loss: 0.399863, acc: 59.38%, op_acc: 42.19%] [G loss: 0.875094]\n",
      "epoch:43 step:34283[D loss: 0.423983, acc: 60.94%, op_acc: 38.28%] [G loss: 0.793370]\n",
      "epoch:43 step:34284[D loss: 0.399057, acc: 59.38%, op_acc: 43.75%] [G loss: 1.001345]\n",
      "epoch:43 step:34285[D loss: 0.406458, acc: 59.38%, op_acc: 38.28%] [G loss: 0.927152]\n",
      "epoch:43 step:34286[D loss: 0.420512, acc: 60.16%, op_acc: 42.97%] [G loss: 0.796835]\n",
      "epoch:43 step:34287[D loss: 0.375020, acc: 61.72%, op_acc: 50.00%] [G loss: 0.815048]\n",
      "epoch:43 step:34288[D loss: 0.412389, acc: 64.84%, op_acc: 42.97%] [G loss: 0.991790]\n",
      "epoch:43 step:34289[D loss: 0.417202, acc: 57.03%, op_acc: 43.75%] [G loss: 0.842381]\n",
      "epoch:43 step:34290[D loss: 0.445921, acc: 52.34%, op_acc: 36.72%] [G loss: 0.911387]\n",
      "epoch:43 step:34291[D loss: 0.439514, acc: 53.12%, op_acc: 42.19%] [G loss: 0.908264]\n",
      "epoch:43 step:34292[D loss: 0.368026, acc: 68.75%, op_acc: 42.19%] [G loss: 1.034256]\n",
      "epoch:43 step:34293[D loss: 0.368226, acc: 62.50%, op_acc: 50.00%] [G loss: 1.029647]\n",
      "epoch:43 step:34294[D loss: 0.376790, acc: 69.53%, op_acc: 44.53%] [G loss: 1.022920]\n",
      "epoch:43 step:34295[D loss: 0.369469, acc: 66.41%, op_acc: 48.44%] [G loss: 1.001466]\n",
      "epoch:43 step:34296[D loss: 0.380325, acc: 67.19%, op_acc: 44.53%] [G loss: 1.038175]\n",
      "epoch:43 step:34297[D loss: 0.408423, acc: 65.62%, op_acc: 34.38%] [G loss: 0.824372]\n",
      "epoch:43 step:34298[D loss: 0.424728, acc: 60.94%, op_acc: 40.62%] [G loss: 1.028550]\n",
      "epoch:43 step:34299[D loss: 0.338032, acc: 75.78%, op_acc: 50.00%] [G loss: 1.060418]\n",
      "epoch:43 step:34300[D loss: 0.386839, acc: 64.06%, op_acc: 42.97%] [G loss: 0.897234]\n",
      "##############\n",
      "[0.86545724 0.88369186 0.81861967 0.80869252 0.78493347 0.85522787\n",
      " 0.87768242 0.83354247 0.81984667 0.82707954]\n",
      "##########\n",
      "epoch:43 step:34301[D loss: 0.352928, acc: 68.75%, op_acc: 46.88%] [G loss: 0.806446]\n",
      "epoch:43 step:34302[D loss: 0.409123, acc: 60.94%, op_acc: 46.09%] [G loss: 1.010751]\n",
      "epoch:43 step:34303[D loss: 0.430759, acc: 64.84%, op_acc: 37.50%] [G loss: 1.158515]\n",
      "epoch:43 step:34304[D loss: 0.429998, acc: 59.38%, op_acc: 40.62%] [G loss: 1.112664]\n",
      "epoch:43 step:34305[D loss: 0.376962, acc: 69.53%, op_acc: 44.53%] [G loss: 0.815773]\n",
      "epoch:43 step:34306[D loss: 0.422019, acc: 58.59%, op_acc: 43.75%] [G loss: 1.266292]\n",
      "epoch:43 step:34307[D loss: 0.411473, acc: 66.41%, op_acc: 37.50%] [G loss: 1.022308]\n",
      "epoch:43 step:34308[D loss: 0.376424, acc: 70.31%, op_acc: 41.41%] [G loss: 0.893314]\n",
      "epoch:43 step:34309[D loss: 0.408590, acc: 59.38%, op_acc: 36.72%] [G loss: 0.975135]\n",
      "epoch:43 step:34310[D loss: 0.427552, acc: 63.28%, op_acc: 42.97%] [G loss: 0.992698]\n",
      "epoch:43 step:34311[D loss: 0.407387, acc: 61.72%, op_acc: 42.19%] [G loss: 0.792889]\n",
      "epoch:43 step:34312[D loss: 0.421528, acc: 59.38%, op_acc: 42.97%] [G loss: 1.071423]\n",
      "epoch:43 step:34313[D loss: 0.382403, acc: 62.50%, op_acc: 45.31%] [G loss: 1.064840]\n",
      "epoch:43 step:34314[D loss: 0.412061, acc: 60.16%, op_acc: 39.06%] [G loss: 0.881403]\n",
      "epoch:43 step:34315[D loss: 0.455451, acc: 49.22%, op_acc: 39.84%] [G loss: 0.869264]\n",
      "epoch:43 step:34316[D loss: 0.394291, acc: 67.19%, op_acc: 46.09%] [G loss: 0.961907]\n",
      "epoch:43 step:34317[D loss: 0.419750, acc: 58.59%, op_acc: 37.50%] [G loss: 1.043468]\n",
      "epoch:43 step:34318[D loss: 0.412852, acc: 62.50%, op_acc: 46.09%] [G loss: 1.062795]\n",
      "epoch:43 step:34319[D loss: 0.411014, acc: 62.50%, op_acc: 41.41%] [G loss: 0.988256]\n",
      "epoch:43 step:34320[D loss: 0.400869, acc: 64.06%, op_acc: 39.84%] [G loss: 1.042982]\n",
      "epoch:43 step:34321[D loss: 0.450819, acc: 50.78%, op_acc: 39.06%] [G loss: 0.819147]\n",
      "epoch:43 step:34322[D loss: 0.425901, acc: 62.50%, op_acc: 42.19%] [G loss: 1.048362]\n",
      "epoch:43 step:34323[D loss: 0.419359, acc: 60.94%, op_acc: 42.97%] [G loss: 0.923169]\n",
      "epoch:43 step:34324[D loss: 0.415017, acc: 55.47%, op_acc: 41.41%] [G loss: 0.887814]\n",
      "epoch:43 step:34325[D loss: 0.435451, acc: 59.38%, op_acc: 36.72%] [G loss: 0.990803]\n",
      "epoch:43 step:34326[D loss: 0.375717, acc: 71.09%, op_acc: 46.88%] [G loss: 1.032866]\n",
      "epoch:43 step:34327[D loss: 0.388380, acc: 59.38%, op_acc: 45.31%] [G loss: 0.947694]\n",
      "epoch:43 step:34328[D loss: 0.425646, acc: 50.00%, op_acc: 42.19%] [G loss: 0.973226]\n",
      "epoch:43 step:34329[D loss: 0.409709, acc: 66.41%, op_acc: 33.59%] [G loss: 1.025697]\n",
      "epoch:43 step:34330[D loss: 0.431888, acc: 60.94%, op_acc: 41.41%] [G loss: 0.902243]\n",
      "epoch:43 step:34331[D loss: 0.429718, acc: 58.59%, op_acc: 39.84%] [G loss: 0.909056]\n",
      "epoch:43 step:34332[D loss: 0.437543, acc: 62.50%, op_acc: 40.62%] [G loss: 0.801904]\n",
      "epoch:43 step:34333[D loss: 0.434315, acc: 53.12%, op_acc: 40.62%] [G loss: 0.834345]\n",
      "epoch:43 step:34334[D loss: 0.463891, acc: 54.69%, op_acc: 36.72%] [G loss: 0.837966]\n",
      "epoch:43 step:34335[D loss: 0.417378, acc: 61.72%, op_acc: 42.97%] [G loss: 0.881888]\n",
      "epoch:43 step:34336[D loss: 0.365333, acc: 69.53%, op_acc: 48.44%] [G loss: 0.937511]\n",
      "epoch:43 step:34337[D loss: 0.407319, acc: 59.38%, op_acc: 42.97%] [G loss: 0.888193]\n",
      "epoch:43 step:34338[D loss: 0.413572, acc: 63.28%, op_acc: 42.19%] [G loss: 0.919023]\n",
      "epoch:43 step:34339[D loss: 0.410093, acc: 59.38%, op_acc: 40.62%] [G loss: 0.823942]\n",
      "epoch:43 step:34340[D loss: 0.395656, acc: 64.06%, op_acc: 43.75%] [G loss: 0.953740]\n",
      "epoch:43 step:34341[D loss: 0.374466, acc: 68.75%, op_acc: 42.19%] [G loss: 0.931402]\n",
      "epoch:43 step:34342[D loss: 0.423575, acc: 60.94%, op_acc: 44.53%] [G loss: 0.913370]\n",
      "epoch:43 step:34343[D loss: 0.398297, acc: 64.06%, op_acc: 43.75%] [G loss: 0.913634]\n",
      "epoch:43 step:34344[D loss: 0.385358, acc: 63.28%, op_acc: 45.31%] [G loss: 0.930244]\n",
      "epoch:43 step:34345[D loss: 0.441865, acc: 63.28%, op_acc: 41.41%] [G loss: 0.917801]\n",
      "epoch:43 step:34346[D loss: 0.427783, acc: 57.81%, op_acc: 40.62%] [G loss: 0.861992]\n",
      "epoch:43 step:34347[D loss: 0.381841, acc: 62.50%, op_acc: 50.00%] [G loss: 0.910084]\n",
      "epoch:43 step:34348[D loss: 0.396586, acc: 57.81%, op_acc: 46.88%] [G loss: 0.937987]\n",
      "epoch:43 step:34349[D loss: 0.412422, acc: 62.50%, op_acc: 37.50%] [G loss: 0.779721]\n",
      "epoch:43 step:34350[D loss: 0.402667, acc: 61.72%, op_acc: 45.31%] [G loss: 0.842388]\n",
      "##############\n",
      "[0.85933439 0.85593431 0.80889159 0.81069699 0.79046717 0.83032352\n",
      " 0.88882773 0.80957249 0.82733401 0.84439801]\n",
      "##########\n",
      "epoch:43 step:34351[D loss: 0.393135, acc: 65.62%, op_acc: 42.19%] [G loss: 0.974831]\n",
      "epoch:43 step:34352[D loss: 0.378270, acc: 63.28%, op_acc: 50.00%] [G loss: 0.915200]\n",
      "epoch:43 step:34353[D loss: 0.393299, acc: 61.72%, op_acc: 46.88%] [G loss: 0.952989]\n",
      "epoch:43 step:34354[D loss: 0.430190, acc: 60.16%, op_acc: 46.09%] [G loss: 0.932656]\n",
      "epoch:43 step:34355[D loss: 0.423717, acc: 67.19%, op_acc: 39.06%] [G loss: 0.797298]\n",
      "epoch:43 step:34356[D loss: 0.407706, acc: 67.97%, op_acc: 40.62%] [G loss: 0.889437]\n",
      "epoch:43 step:34357[D loss: 0.355121, acc: 71.09%, op_acc: 44.53%] [G loss: 0.903260]\n",
      "epoch:43 step:34358[D loss: 0.425391, acc: 62.50%, op_acc: 37.50%] [G loss: 0.958788]\n",
      "epoch:43 step:34359[D loss: 0.416229, acc: 57.03%, op_acc: 39.84%] [G loss: 0.827900]\n",
      "epoch:43 step:34360[D loss: 0.412802, acc: 60.16%, op_acc: 46.88%] [G loss: 0.873128]\n",
      "epoch:43 step:34361[D loss: 0.388516, acc: 66.41%, op_acc: 45.31%] [G loss: 0.950384]\n",
      "epoch:43 step:34362[D loss: 0.391114, acc: 65.62%, op_acc: 42.19%] [G loss: 0.886215]\n",
      "epoch:43 step:34363[D loss: 0.409854, acc: 60.16%, op_acc: 41.41%] [G loss: 0.850633]\n",
      "epoch:43 step:34364[D loss: 0.418548, acc: 67.97%, op_acc: 39.84%] [G loss: 0.957439]\n",
      "epoch:44 step:34365[D loss: 0.369667, acc: 69.53%, op_acc: 42.19%] [G loss: 0.960613]\n",
      "epoch:44 step:34366[D loss: 0.403425, acc: 64.84%, op_acc: 42.19%] [G loss: 1.059938]\n",
      "epoch:44 step:34367[D loss: 0.378170, acc: 72.66%, op_acc: 46.88%] [G loss: 0.954820]\n",
      "epoch:44 step:34368[D loss: 0.380221, acc: 66.41%, op_acc: 48.44%] [G loss: 0.928902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34369[D loss: 0.381376, acc: 68.75%, op_acc: 44.53%] [G loss: 0.839253]\n",
      "epoch:44 step:34370[D loss: 0.422311, acc: 60.16%, op_acc: 42.19%] [G loss: 0.813196]\n",
      "epoch:44 step:34371[D loss: 0.391731, acc: 66.41%, op_acc: 47.66%] [G loss: 0.942725]\n",
      "epoch:44 step:34372[D loss: 0.413605, acc: 59.38%, op_acc: 40.62%] [G loss: 0.998785]\n",
      "epoch:44 step:34373[D loss: 0.387431, acc: 59.38%, op_acc: 47.66%] [G loss: 0.912824]\n",
      "epoch:44 step:34374[D loss: 0.438033, acc: 53.91%, op_acc: 46.09%] [G loss: 0.892413]\n",
      "epoch:44 step:34375[D loss: 0.406023, acc: 64.84%, op_acc: 41.41%] [G loss: 0.872368]\n",
      "epoch:44 step:34376[D loss: 0.401560, acc: 62.50%, op_acc: 40.62%] [G loss: 0.871643]\n",
      "epoch:44 step:34377[D loss: 0.409777, acc: 62.50%, op_acc: 40.62%] [G loss: 0.890301]\n",
      "epoch:44 step:34378[D loss: 0.386069, acc: 73.44%, op_acc: 41.41%] [G loss: 1.019355]\n",
      "epoch:44 step:34379[D loss: 0.377307, acc: 61.72%, op_acc: 46.88%] [G loss: 0.847104]\n",
      "epoch:44 step:34380[D loss: 0.387068, acc: 64.84%, op_acc: 45.31%] [G loss: 0.932063]\n",
      "epoch:44 step:34381[D loss: 0.394622, acc: 64.06%, op_acc: 45.31%] [G loss: 0.895169]\n",
      "epoch:44 step:34382[D loss: 0.425712, acc: 53.12%, op_acc: 37.50%] [G loss: 1.033970]\n",
      "epoch:44 step:34383[D loss: 0.421800, acc: 57.81%, op_acc: 46.09%] [G loss: 0.868217]\n",
      "epoch:44 step:34384[D loss: 0.385483, acc: 64.84%, op_acc: 41.41%] [G loss: 0.907366]\n",
      "epoch:44 step:34385[D loss: 0.406016, acc: 62.50%, op_acc: 39.84%] [G loss: 0.983827]\n",
      "epoch:44 step:34386[D loss: 0.405902, acc: 66.41%, op_acc: 46.09%] [G loss: 0.891639]\n",
      "epoch:44 step:34387[D loss: 0.407947, acc: 57.03%, op_acc: 43.75%] [G loss: 0.934928]\n",
      "epoch:44 step:34388[D loss: 0.428345, acc: 59.38%, op_acc: 44.53%] [G loss: 0.831515]\n",
      "epoch:44 step:34389[D loss: 0.415753, acc: 58.59%, op_acc: 41.41%] [G loss: 0.832538]\n",
      "epoch:44 step:34390[D loss: 0.371254, acc: 69.53%, op_acc: 48.44%] [G loss: 0.877144]\n",
      "epoch:44 step:34391[D loss: 0.383259, acc: 66.41%, op_acc: 47.66%] [G loss: 0.957835]\n",
      "epoch:44 step:34392[D loss: 0.428033, acc: 55.47%, op_acc: 40.62%] [G loss: 0.813155]\n",
      "epoch:44 step:34393[D loss: 0.392952, acc: 64.84%, op_acc: 39.84%] [G loss: 0.978448]\n",
      "epoch:44 step:34394[D loss: 0.403960, acc: 62.50%, op_acc: 46.09%] [G loss: 0.850251]\n",
      "epoch:44 step:34395[D loss: 0.390588, acc: 68.75%, op_acc: 48.44%] [G loss: 0.991974]\n",
      "epoch:44 step:34396[D loss: 0.393244, acc: 63.28%, op_acc: 41.41%] [G loss: 0.926933]\n",
      "epoch:44 step:34397[D loss: 0.386901, acc: 61.72%, op_acc: 44.53%] [G loss: 0.818474]\n",
      "epoch:44 step:34398[D loss: 0.421171, acc: 57.81%, op_acc: 42.19%] [G loss: 0.761635]\n",
      "epoch:44 step:34399[D loss: 0.391284, acc: 67.19%, op_acc: 48.44%] [G loss: 0.905974]\n",
      "epoch:44 step:34400[D loss: 0.390652, acc: 60.94%, op_acc: 45.31%] [G loss: 0.798419]\n",
      "##############\n",
      "[0.85793642 0.86962847 0.7954174  0.81540357 0.77722995 0.83542702\n",
      " 0.90527257 0.83364157 0.82253338 0.81731352]\n",
      "##########\n",
      "epoch:44 step:34401[D loss: 0.400999, acc: 64.84%, op_acc: 45.31%] [G loss: 0.812242]\n",
      "epoch:44 step:34402[D loss: 0.405728, acc: 53.91%, op_acc: 45.31%] [G loss: 0.757994]\n",
      "epoch:44 step:34403[D loss: 0.370800, acc: 64.06%, op_acc: 47.66%] [G loss: 0.744202]\n",
      "epoch:44 step:34404[D loss: 0.444786, acc: 55.47%, op_acc: 41.41%] [G loss: 0.766649]\n",
      "epoch:44 step:34405[D loss: 0.385573, acc: 64.06%, op_acc: 50.00%] [G loss: 0.843866]\n",
      "epoch:44 step:34406[D loss: 0.376883, acc: 60.16%, op_acc: 44.53%] [G loss: 0.838961]\n",
      "epoch:44 step:34407[D loss: 0.410010, acc: 59.38%, op_acc: 42.19%] [G loss: 0.855407]\n",
      "epoch:44 step:34408[D loss: 0.471291, acc: 50.78%, op_acc: 44.53%] [G loss: 0.825000]\n",
      "epoch:44 step:34409[D loss: 0.384450, acc: 67.19%, op_acc: 42.19%] [G loss: 0.924026]\n",
      "epoch:44 step:34410[D loss: 0.384139, acc: 70.31%, op_acc: 40.62%] [G loss: 0.912736]\n",
      "epoch:44 step:34411[D loss: 0.435806, acc: 60.16%, op_acc: 33.59%] [G loss: 0.991178]\n",
      "epoch:44 step:34412[D loss: 0.433471, acc: 55.47%, op_acc: 43.75%] [G loss: 0.825746]\n",
      "epoch:44 step:34413[D loss: 0.365800, acc: 70.31%, op_acc: 49.22%] [G loss: 0.907153]\n",
      "epoch:44 step:34414[D loss: 0.380403, acc: 71.09%, op_acc: 42.97%] [G loss: 0.976985]\n",
      "epoch:44 step:34415[D loss: 0.369777, acc: 71.88%, op_acc: 44.53%] [G loss: 0.955699]\n",
      "epoch:44 step:34416[D loss: 0.385994, acc: 66.41%, op_acc: 36.72%] [G loss: 0.965488]\n",
      "epoch:44 step:34417[D loss: 0.423922, acc: 60.94%, op_acc: 39.84%] [G loss: 0.917991]\n",
      "epoch:44 step:34418[D loss: 0.399485, acc: 64.84%, op_acc: 42.97%] [G loss: 0.955775]\n",
      "epoch:44 step:34419[D loss: 0.378506, acc: 65.62%, op_acc: 47.66%] [G loss: 0.991852]\n",
      "epoch:44 step:34420[D loss: 0.388943, acc: 67.97%, op_acc: 42.19%] [G loss: 0.951169]\n",
      "epoch:44 step:34421[D loss: 0.397934, acc: 67.19%, op_acc: 40.62%] [G loss: 0.982785]\n",
      "epoch:44 step:34422[D loss: 0.361534, acc: 69.53%, op_acc: 50.78%] [G loss: 1.008154]\n",
      "epoch:44 step:34423[D loss: 0.345997, acc: 74.22%, op_acc: 48.44%] [G loss: 0.760633]\n",
      "epoch:44 step:34424[D loss: 0.362296, acc: 72.66%, op_acc: 40.62%] [G loss: 1.154047]\n",
      "epoch:44 step:34425[D loss: 0.387774, acc: 66.41%, op_acc: 40.62%] [G loss: 1.038729]\n",
      "epoch:44 step:34426[D loss: 0.409795, acc: 64.84%, op_acc: 35.94%] [G loss: 0.997055]\n",
      "epoch:44 step:34427[D loss: 0.422819, acc: 57.03%, op_acc: 42.19%] [G loss: 1.042414]\n",
      "epoch:44 step:34428[D loss: 0.391562, acc: 64.06%, op_acc: 39.84%] [G loss: 0.964697]\n",
      "epoch:44 step:34429[D loss: 0.404161, acc: 58.59%, op_acc: 40.62%] [G loss: 0.824611]\n",
      "epoch:44 step:34430[D loss: 0.408317, acc: 60.94%, op_acc: 48.44%] [G loss: 1.096670]\n",
      "epoch:44 step:34431[D loss: 0.387900, acc: 65.62%, op_acc: 44.53%] [G loss: 1.059143]\n",
      "epoch:44 step:34432[D loss: 0.393979, acc: 61.72%, op_acc: 43.75%] [G loss: 1.022513]\n",
      "epoch:44 step:34433[D loss: 0.392828, acc: 64.06%, op_acc: 42.97%] [G loss: 0.955388]\n",
      "epoch:44 step:34434[D loss: 0.391726, acc: 64.84%, op_acc: 43.75%] [G loss: 1.073590]\n",
      "epoch:44 step:34435[D loss: 0.412175, acc: 64.06%, op_acc: 39.84%] [G loss: 1.045910]\n",
      "epoch:44 step:34436[D loss: 0.363012, acc: 70.31%, op_acc: 44.53%] [G loss: 0.933043]\n",
      "epoch:44 step:34437[D loss: 0.398215, acc: 64.06%, op_acc: 40.62%] [G loss: 1.059544]\n",
      "epoch:44 step:34438[D loss: 0.324702, acc: 80.47%, op_acc: 45.31%] [G loss: 0.986456]\n",
      "epoch:44 step:34439[D loss: 0.361607, acc: 70.31%, op_acc: 46.88%] [G loss: 1.079102]\n",
      "epoch:44 step:34440[D loss: 0.400028, acc: 66.41%, op_acc: 42.97%] [G loss: 0.617064]\n",
      "epoch:44 step:34441[D loss: 0.443422, acc: 54.69%, op_acc: 39.84%] [G loss: 0.953652]\n",
      "epoch:44 step:34442[D loss: 0.419298, acc: 65.62%, op_acc: 32.81%] [G loss: 0.934817]\n",
      "epoch:44 step:34443[D loss: 0.361518, acc: 72.66%, op_acc: 43.75%] [G loss: 1.050593]\n",
      "epoch:44 step:34444[D loss: 0.387170, acc: 71.09%, op_acc: 44.53%] [G loss: 1.085659]\n",
      "epoch:44 step:34445[D loss: 0.381232, acc: 72.66%, op_acc: 42.19%] [G loss: 1.171897]\n",
      "epoch:44 step:34446[D loss: 0.379865, acc: 68.75%, op_acc: 46.88%] [G loss: 0.803666]\n",
      "epoch:44 step:34447[D loss: 0.406700, acc: 66.41%, op_acc: 40.62%] [G loss: 0.688593]\n",
      "epoch:44 step:34448[D loss: 0.411684, acc: 66.41%, op_acc: 40.62%] [G loss: 0.779423]\n",
      "epoch:44 step:34449[D loss: 0.427231, acc: 62.50%, op_acc: 39.06%] [G loss: 1.098414]\n",
      "epoch:44 step:34450[D loss: 0.377332, acc: 63.28%, op_acc: 45.31%] [G loss: 1.161616]\n",
      "##############\n",
      "[0.87041009 0.8567271  0.81692555 0.80913171 0.79301478 0.82321742\n",
      " 0.89067016 0.82176086 0.80478834 0.82880023]\n",
      "##########\n",
      "epoch:44 step:34451[D loss: 0.407512, acc: 64.06%, op_acc: 42.97%] [G loss: 1.109354]\n",
      "epoch:44 step:34452[D loss: 0.392355, acc: 62.50%, op_acc: 42.97%] [G loss: 1.110102]\n",
      "epoch:44 step:34453[D loss: 0.409886, acc: 60.94%, op_acc: 49.22%] [G loss: 1.224561]\n",
      "epoch:44 step:34454[D loss: 0.421421, acc: 53.12%, op_acc: 46.09%] [G loss: 1.156737]\n",
      "epoch:44 step:34455[D loss: 0.401534, acc: 63.28%, op_acc: 39.06%] [G loss: 0.863921]\n",
      "epoch:44 step:34456[D loss: 0.414651, acc: 61.72%, op_acc: 38.28%] [G loss: 1.021143]\n",
      "epoch:44 step:34457[D loss: 0.404071, acc: 57.03%, op_acc: 45.31%] [G loss: 0.907133]\n",
      "epoch:44 step:34458[D loss: 0.407089, acc: 62.50%, op_acc: 42.19%] [G loss: 0.869431]\n",
      "epoch:44 step:34459[D loss: 0.396245, acc: 67.97%, op_acc: 35.94%] [G loss: 1.161505]\n",
      "epoch:44 step:34460[D loss: 0.426650, acc: 64.06%, op_acc: 39.06%] [G loss: 1.108725]\n",
      "epoch:44 step:34461[D loss: 0.389716, acc: 61.72%, op_acc: 45.31%] [G loss: 1.124896]\n",
      "epoch:44 step:34462[D loss: 0.451684, acc: 52.34%, op_acc: 40.62%] [G loss: 1.074004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34463[D loss: 0.393599, acc: 66.41%, op_acc: 42.97%] [G loss: 1.148956]\n",
      "epoch:44 step:34464[D loss: 0.401512, acc: 62.50%, op_acc: 43.75%] [G loss: 1.041698]\n",
      "epoch:44 step:34465[D loss: 0.412965, acc: 59.38%, op_acc: 45.31%] [G loss: 0.842281]\n",
      "epoch:44 step:34466[D loss: 0.378917, acc: 64.84%, op_acc: 42.19%] [G loss: 0.984572]\n",
      "epoch:44 step:34467[D loss: 0.396930, acc: 65.62%, op_acc: 39.84%] [G loss: 0.842007]\n",
      "epoch:44 step:34468[D loss: 0.407440, acc: 59.38%, op_acc: 39.84%] [G loss: 0.932942]\n",
      "epoch:44 step:34469[D loss: 0.398488, acc: 60.94%, op_acc: 45.31%] [G loss: 1.093297]\n",
      "epoch:44 step:34470[D loss: 0.384642, acc: 63.28%, op_acc: 44.53%] [G loss: 0.934451]\n",
      "epoch:44 step:34471[D loss: 0.408090, acc: 59.38%, op_acc: 47.66%] [G loss: 0.986031]\n",
      "epoch:44 step:34472[D loss: 0.425832, acc: 56.25%, op_acc: 40.62%] [G loss: 0.930461]\n",
      "epoch:44 step:34473[D loss: 0.408613, acc: 60.94%, op_acc: 41.41%] [G loss: 0.956252]\n",
      "epoch:44 step:34474[D loss: 0.387603, acc: 67.19%, op_acc: 42.97%] [G loss: 1.006785]\n",
      "epoch:44 step:34475[D loss: 0.423085, acc: 60.16%, op_acc: 41.41%] [G loss: 1.005147]\n",
      "epoch:44 step:34476[D loss: 0.401280, acc: 62.50%, op_acc: 51.56%] [G loss: 0.980098]\n",
      "epoch:44 step:34477[D loss: 0.408294, acc: 61.72%, op_acc: 38.28%] [G loss: 0.972590]\n",
      "epoch:44 step:34478[D loss: 0.408230, acc: 62.50%, op_acc: 44.53%] [G loss: 0.956953]\n",
      "epoch:44 step:34479[D loss: 0.423078, acc: 55.47%, op_acc: 46.09%] [G loss: 1.067564]\n",
      "epoch:44 step:34480[D loss: 0.422178, acc: 62.50%, op_acc: 39.84%] [G loss: 0.949857]\n",
      "epoch:44 step:34481[D loss: 0.404112, acc: 58.59%, op_acc: 42.19%] [G loss: 0.914491]\n",
      "epoch:44 step:34482[D loss: 0.407535, acc: 58.59%, op_acc: 45.31%] [G loss: 0.919083]\n",
      "epoch:44 step:34483[D loss: 0.388500, acc: 68.75%, op_acc: 42.97%] [G loss: 0.967916]\n",
      "epoch:44 step:34484[D loss: 0.417707, acc: 60.16%, op_acc: 43.75%] [G loss: 0.919334]\n",
      "epoch:44 step:34485[D loss: 0.399303, acc: 60.94%, op_acc: 46.88%] [G loss: 0.912065]\n",
      "epoch:44 step:34486[D loss: 0.428068, acc: 56.25%, op_acc: 38.28%] [G loss: 0.881729]\n",
      "epoch:44 step:34487[D loss: 0.410712, acc: 69.53%, op_acc: 41.41%] [G loss: 0.927745]\n",
      "epoch:44 step:34488[D loss: 0.400416, acc: 60.16%, op_acc: 43.75%] [G loss: 0.883171]\n",
      "epoch:44 step:34489[D loss: 0.427443, acc: 57.03%, op_acc: 41.41%] [G loss: 0.917440]\n",
      "epoch:44 step:34490[D loss: 0.429173, acc: 56.25%, op_acc: 39.84%] [G loss: 0.891238]\n",
      "epoch:44 step:34491[D loss: 0.443115, acc: 50.00%, op_acc: 39.84%] [G loss: 1.043822]\n",
      "epoch:44 step:34492[D loss: 0.421588, acc: 55.47%, op_acc: 39.06%] [G loss: 0.889787]\n",
      "epoch:44 step:34493[D loss: 0.466238, acc: 53.12%, op_acc: 42.19%] [G loss: 0.962247]\n",
      "epoch:44 step:34494[D loss: 0.391171, acc: 66.41%, op_acc: 41.41%] [G loss: 0.862796]\n",
      "epoch:44 step:34495[D loss: 0.405765, acc: 61.72%, op_acc: 42.97%] [G loss: 0.928194]\n",
      "epoch:44 step:34496[D loss: 0.374756, acc: 68.75%, op_acc: 48.44%] [G loss: 0.930524]\n",
      "epoch:44 step:34497[D loss: 0.446487, acc: 54.69%, op_acc: 39.06%] [G loss: 0.949194]\n",
      "epoch:44 step:34498[D loss: 0.379425, acc: 71.09%, op_acc: 44.53%] [G loss: 0.960134]\n",
      "epoch:44 step:34499[D loss: 0.420713, acc: 57.81%, op_acc: 41.41%] [G loss: 0.871034]\n",
      "epoch:44 step:34500[D loss: 0.404894, acc: 64.84%, op_acc: 42.97%] [G loss: 0.964964]\n",
      "##############\n",
      "[0.87194869 0.85704424 0.80287924 0.80301511 0.78655333 0.80533396\n",
      " 0.88208923 0.82917724 0.79234908 0.81247015]\n",
      "##########\n",
      "epoch:44 step:34501[D loss: 0.408187, acc: 56.25%, op_acc: 38.28%] [G loss: 0.882358]\n",
      "epoch:44 step:34502[D loss: 0.392706, acc: 70.31%, op_acc: 42.19%] [G loss: 0.982494]\n",
      "epoch:44 step:34503[D loss: 0.391384, acc: 62.50%, op_acc: 44.53%] [G loss: 0.902207]\n",
      "epoch:44 step:34504[D loss: 0.439014, acc: 50.78%, op_acc: 39.06%] [G loss: 0.864416]\n",
      "epoch:44 step:34505[D loss: 0.409440, acc: 64.84%, op_acc: 38.28%] [G loss: 0.852119]\n",
      "epoch:44 step:34506[D loss: 0.381802, acc: 70.31%, op_acc: 43.75%] [G loss: 0.921079]\n",
      "epoch:44 step:34507[D loss: 0.399072, acc: 59.38%, op_acc: 45.31%] [G loss: 0.903004]\n",
      "epoch:44 step:34508[D loss: 0.394374, acc: 64.06%, op_acc: 41.41%] [G loss: 0.886360]\n",
      "epoch:44 step:34509[D loss: 0.407384, acc: 63.28%, op_acc: 46.09%] [G loss: 0.723215]\n",
      "epoch:44 step:34510[D loss: 0.405794, acc: 60.16%, op_acc: 41.41%] [G loss: 0.847346]\n",
      "epoch:44 step:34511[D loss: 0.378316, acc: 68.75%, op_acc: 46.09%] [G loss: 0.968327]\n",
      "epoch:44 step:34512[D loss: 0.421616, acc: 58.59%, op_acc: 39.84%] [G loss: 0.754352]\n",
      "epoch:44 step:34513[D loss: 0.368670, acc: 64.06%, op_acc: 50.00%] [G loss: 1.004446]\n",
      "epoch:44 step:34514[D loss: 0.394979, acc: 65.62%, op_acc: 48.44%] [G loss: 0.958462]\n",
      "epoch:44 step:34515[D loss: 0.406761, acc: 60.16%, op_acc: 48.44%] [G loss: 0.879567]\n",
      "epoch:44 step:34516[D loss: 0.389683, acc: 69.53%, op_acc: 42.19%] [G loss: 0.926565]\n",
      "epoch:44 step:34517[D loss: 0.402369, acc: 67.19%, op_acc: 47.66%] [G loss: 0.989927]\n",
      "epoch:44 step:34518[D loss: 0.411037, acc: 65.62%, op_acc: 41.41%] [G loss: 0.829177]\n",
      "epoch:44 step:34519[D loss: 0.428442, acc: 59.38%, op_acc: 42.97%] [G loss: 1.057462]\n",
      "epoch:44 step:34520[D loss: 0.430418, acc: 60.94%, op_acc: 39.06%] [G loss: 0.928812]\n",
      "epoch:44 step:34521[D loss: 0.371939, acc: 70.31%, op_acc: 42.97%] [G loss: 0.993987]\n",
      "epoch:44 step:34522[D loss: 0.383816, acc: 70.31%, op_acc: 42.97%] [G loss: 0.933697]\n",
      "epoch:44 step:34523[D loss: 0.394171, acc: 64.06%, op_acc: 43.75%] [G loss: 0.784157]\n",
      "epoch:44 step:34524[D loss: 0.425143, acc: 61.72%, op_acc: 33.59%] [G loss: 0.801227]\n",
      "epoch:44 step:34525[D loss: 0.426204, acc: 60.94%, op_acc: 38.28%] [G loss: 0.954636]\n",
      "epoch:44 step:34526[D loss: 0.398788, acc: 60.94%, op_acc: 44.53%] [G loss: 0.847948]\n",
      "epoch:44 step:34527[D loss: 0.391450, acc: 65.62%, op_acc: 45.31%] [G loss: 0.992406]\n",
      "epoch:44 step:34528[D loss: 0.449376, acc: 57.81%, op_acc: 35.94%] [G loss: 0.916637]\n",
      "epoch:44 step:34529[D loss: 0.385707, acc: 64.84%, op_acc: 45.31%] [G loss: 0.983394]\n",
      "epoch:44 step:34530[D loss: 0.400293, acc: 61.72%, op_acc: 44.53%] [G loss: 0.726488]\n",
      "epoch:44 step:34531[D loss: 0.377894, acc: 64.06%, op_acc: 50.00%] [G loss: 0.885950]\n",
      "epoch:44 step:34532[D loss: 0.388625, acc: 68.75%, op_acc: 48.44%] [G loss: 0.750252]\n",
      "epoch:44 step:34533[D loss: 0.434151, acc: 56.25%, op_acc: 43.75%] [G loss: 0.798511]\n",
      "epoch:44 step:34534[D loss: 0.396794, acc: 66.41%, op_acc: 44.53%] [G loss: 1.001878]\n",
      "epoch:44 step:34535[D loss: 0.457209, acc: 55.47%, op_acc: 36.72%] [G loss: 0.793272]\n",
      "epoch:44 step:34536[D loss: 0.364969, acc: 72.66%, op_acc: 47.66%] [G loss: 0.870070]\n",
      "epoch:44 step:34537[D loss: 0.369833, acc: 71.88%, op_acc: 42.97%] [G loss: 1.108997]\n",
      "epoch:44 step:34538[D loss: 0.412529, acc: 62.50%, op_acc: 38.28%] [G loss: 0.965718]\n",
      "epoch:44 step:34539[D loss: 0.386162, acc: 65.62%, op_acc: 42.97%] [G loss: 0.923451]\n",
      "epoch:44 step:34540[D loss: 0.416925, acc: 55.47%, op_acc: 46.09%] [G loss: 0.932812]\n",
      "epoch:44 step:34541[D loss: 0.403718, acc: 55.47%, op_acc: 44.53%] [G loss: 0.953593]\n",
      "epoch:44 step:34542[D loss: 0.437060, acc: 60.16%, op_acc: 46.09%] [G loss: 0.959267]\n",
      "epoch:44 step:34543[D loss: 0.383699, acc: 64.06%, op_acc: 51.56%] [G loss: 0.977138]\n",
      "epoch:44 step:34544[D loss: 0.389347, acc: 62.50%, op_acc: 42.19%] [G loss: 0.922219]\n",
      "epoch:44 step:34545[D loss: 0.377293, acc: 71.88%, op_acc: 49.22%] [G loss: 0.995126]\n",
      "epoch:44 step:34546[D loss: 0.390369, acc: 64.06%, op_acc: 38.28%] [G loss: 0.942617]\n",
      "epoch:44 step:34547[D loss: 0.401850, acc: 61.72%, op_acc: 39.84%] [G loss: 0.981764]\n",
      "epoch:44 step:34548[D loss: 0.401815, acc: 64.84%, op_acc: 44.53%] [G loss: 1.051034]\n",
      "epoch:44 step:34549[D loss: 0.397587, acc: 69.53%, op_acc: 39.84%] [G loss: 1.087912]\n",
      "epoch:44 step:34550[D loss: 0.430887, acc: 57.03%, op_acc: 42.97%] [G loss: 1.017022]\n",
      "##############\n",
      "[0.8533891  0.86458384 0.79804919 0.80971849 0.79667542 0.82130097\n",
      " 0.8999872  0.82233937 0.80518369 0.85663946]\n",
      "##########\n",
      "epoch:44 step:34551[D loss: 0.402974, acc: 63.28%, op_acc: 40.62%] [G loss: 0.911381]\n",
      "epoch:44 step:34552[D loss: 0.395435, acc: 66.41%, op_acc: 42.19%] [G loss: 1.041850]\n",
      "epoch:44 step:34553[D loss: 0.400646, acc: 62.50%, op_acc: 43.75%] [G loss: 0.958653]\n",
      "epoch:44 step:34554[D loss: 0.409603, acc: 61.72%, op_acc: 41.41%] [G loss: 0.958876]\n",
      "epoch:44 step:34555[D loss: 0.426931, acc: 54.69%, op_acc: 40.62%] [G loss: 0.902064]\n",
      "epoch:44 step:34556[D loss: 0.386594, acc: 66.41%, op_acc: 45.31%] [G loss: 0.895973]\n",
      "epoch:44 step:34557[D loss: 0.446547, acc: 56.25%, op_acc: 38.28%] [G loss: 1.055696]\n",
      "epoch:44 step:34558[D loss: 0.427900, acc: 56.25%, op_acc: 40.62%] [G loss: 0.954316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34559[D loss: 0.392123, acc: 64.84%, op_acc: 42.19%] [G loss: 1.031278]\n",
      "epoch:44 step:34560[D loss: 0.403825, acc: 69.53%, op_acc: 35.16%] [G loss: 0.846277]\n",
      "epoch:44 step:34561[D loss: 0.426100, acc: 54.69%, op_acc: 42.19%] [G loss: 1.047706]\n",
      "epoch:44 step:34562[D loss: 0.462053, acc: 47.66%, op_acc: 42.19%] [G loss: 0.935903]\n",
      "epoch:44 step:34563[D loss: 0.399706, acc: 62.50%, op_acc: 33.59%] [G loss: 0.930754]\n",
      "epoch:44 step:34564[D loss: 0.402447, acc: 62.50%, op_acc: 43.75%] [G loss: 1.110310]\n",
      "epoch:44 step:34565[D loss: 0.386110, acc: 59.38%, op_acc: 41.41%] [G loss: 0.961349]\n",
      "epoch:44 step:34566[D loss: 0.428988, acc: 57.81%, op_acc: 39.84%] [G loss: 0.867513]\n",
      "epoch:44 step:34567[D loss: 0.405820, acc: 57.81%, op_acc: 45.31%] [G loss: 0.974585]\n",
      "epoch:44 step:34568[D loss: 0.449346, acc: 55.47%, op_acc: 35.94%] [G loss: 1.033774]\n",
      "epoch:44 step:34569[D loss: 0.397581, acc: 62.50%, op_acc: 43.75%] [G loss: 1.020867]\n",
      "epoch:44 step:34570[D loss: 0.401529, acc: 64.84%, op_acc: 43.75%] [G loss: 0.968591]\n",
      "epoch:44 step:34571[D loss: 0.325261, acc: 74.22%, op_acc: 42.19%] [G loss: 1.111164]\n",
      "epoch:44 step:34572[D loss: 0.419122, acc: 59.38%, op_acc: 36.72%] [G loss: 0.903904]\n",
      "epoch:44 step:34573[D loss: 0.381363, acc: 67.97%, op_acc: 43.75%] [G loss: 0.981546]\n",
      "epoch:44 step:34574[D loss: 0.429430, acc: 56.25%, op_acc: 38.28%] [G loss: 0.937186]\n",
      "epoch:44 step:34575[D loss: 0.405872, acc: 58.59%, op_acc: 42.19%] [G loss: 0.984029]\n",
      "epoch:44 step:34576[D loss: 0.401782, acc: 58.59%, op_acc: 42.19%] [G loss: 0.920720]\n",
      "epoch:44 step:34577[D loss: 0.385375, acc: 67.97%, op_acc: 50.78%] [G loss: 0.907852]\n",
      "epoch:44 step:34578[D loss: 0.385058, acc: 64.84%, op_acc: 50.78%] [G loss: 0.884471]\n",
      "epoch:44 step:34579[D loss: 0.449162, acc: 57.81%, op_acc: 40.62%] [G loss: 0.998326]\n",
      "epoch:44 step:34580[D loss: 0.385273, acc: 67.97%, op_acc: 43.75%] [G loss: 0.917206]\n",
      "epoch:44 step:34581[D loss: 0.379450, acc: 71.88%, op_acc: 42.19%] [G loss: 1.005506]\n",
      "epoch:44 step:34582[D loss: 0.395373, acc: 64.06%, op_acc: 42.97%] [G loss: 0.892778]\n",
      "epoch:44 step:34583[D loss: 0.353194, acc: 75.78%, op_acc: 38.28%] [G loss: 1.000105]\n",
      "epoch:44 step:34584[D loss: 0.414085, acc: 63.28%, op_acc: 39.84%] [G loss: 0.851883]\n",
      "epoch:44 step:34585[D loss: 0.379553, acc: 70.31%, op_acc: 39.84%] [G loss: 1.034297]\n",
      "epoch:44 step:34586[D loss: 0.387073, acc: 73.44%, op_acc: 39.84%] [G loss: 0.944648]\n",
      "epoch:44 step:34587[D loss: 0.400468, acc: 69.53%, op_acc: 49.22%] [G loss: 0.783184]\n",
      "epoch:44 step:34588[D loss: 0.389980, acc: 66.41%, op_acc: 39.84%] [G loss: 0.969538]\n",
      "epoch:44 step:34589[D loss: 0.417806, acc: 58.59%, op_acc: 39.06%] [G loss: 0.989827]\n",
      "epoch:44 step:34590[D loss: 0.416711, acc: 63.28%, op_acc: 37.50%] [G loss: 0.906915]\n",
      "epoch:44 step:34591[D loss: 0.407116, acc: 64.06%, op_acc: 38.28%] [G loss: 0.973825]\n",
      "epoch:44 step:34592[D loss: 0.384188, acc: 63.28%, op_acc: 44.53%] [G loss: 0.979044]\n",
      "epoch:44 step:34593[D loss: 0.412328, acc: 64.06%, op_acc: 46.88%] [G loss: 0.688069]\n",
      "epoch:44 step:34594[D loss: 0.404386, acc: 59.38%, op_acc: 44.53%] [G loss: 0.940971]\n",
      "epoch:44 step:34595[D loss: 0.398453, acc: 59.38%, op_acc: 46.09%] [G loss: 0.946829]\n",
      "epoch:44 step:34596[D loss: 0.374487, acc: 70.31%, op_acc: 44.53%] [G loss: 1.009990]\n",
      "epoch:44 step:34597[D loss: 0.425153, acc: 52.34%, op_acc: 45.31%] [G loss: 1.038658]\n",
      "epoch:44 step:34598[D loss: 0.383193, acc: 71.09%, op_acc: 44.53%] [G loss: 0.990327]\n",
      "epoch:44 step:34599[D loss: 0.397780, acc: 60.16%, op_acc: 47.66%] [G loss: 0.877356]\n",
      "epoch:44 step:34600[D loss: 0.431414, acc: 57.81%, op_acc: 41.41%] [G loss: 0.884155]\n",
      "##############\n",
      "[0.86654305 0.85434332 0.82019034 0.82848543 0.79120675 0.80437422\n",
      " 0.87590473 0.80925349 0.79533533 0.82886169]\n",
      "##########\n",
      "epoch:44 step:34601[D loss: 0.371577, acc: 74.22%, op_acc: 46.88%] [G loss: 0.914268]\n",
      "epoch:44 step:34602[D loss: 0.382544, acc: 71.88%, op_acc: 42.97%] [G loss: 0.998705]\n",
      "epoch:44 step:34603[D loss: 0.419463, acc: 60.94%, op_acc: 39.84%] [G loss: 0.880788]\n",
      "epoch:44 step:34604[D loss: 0.430477, acc: 59.38%, op_acc: 46.09%] [G loss: 0.960084]\n",
      "epoch:44 step:34605[D loss: 0.438839, acc: 56.25%, op_acc: 44.53%] [G loss: 0.983241]\n",
      "epoch:44 step:34606[D loss: 0.378296, acc: 67.97%, op_acc: 46.88%] [G loss: 0.889200]\n",
      "epoch:44 step:34607[D loss: 0.434744, acc: 56.25%, op_acc: 39.84%] [G loss: 0.950039]\n",
      "epoch:44 step:34608[D loss: 0.448358, acc: 53.12%, op_acc: 39.06%] [G loss: 0.961410]\n",
      "epoch:44 step:34609[D loss: 0.425783, acc: 60.94%, op_acc: 42.19%] [G loss: 0.882283]\n",
      "epoch:44 step:34610[D loss: 0.412993, acc: 61.72%, op_acc: 38.28%] [G loss: 0.911774]\n",
      "epoch:44 step:34611[D loss: 0.374146, acc: 64.84%, op_acc: 41.41%] [G loss: 0.915002]\n",
      "epoch:44 step:34612[D loss: 0.411564, acc: 60.16%, op_acc: 41.41%] [G loss: 0.929300]\n",
      "epoch:44 step:34613[D loss: 0.399616, acc: 62.50%, op_acc: 47.66%] [G loss: 0.833373]\n",
      "epoch:44 step:34614[D loss: 0.401617, acc: 66.41%, op_acc: 42.19%] [G loss: 0.894076]\n",
      "epoch:44 step:34615[D loss: 0.405565, acc: 62.50%, op_acc: 42.19%] [G loss: 0.977146]\n",
      "epoch:44 step:34616[D loss: 0.419224, acc: 54.69%, op_acc: 44.53%] [G loss: 0.921303]\n",
      "epoch:44 step:34617[D loss: 0.428209, acc: 58.59%, op_acc: 41.41%] [G loss: 0.974947]\n",
      "epoch:44 step:34618[D loss: 0.419292, acc: 61.72%, op_acc: 39.06%] [G loss: 0.910834]\n",
      "epoch:44 step:34619[D loss: 0.446460, acc: 55.47%, op_acc: 38.28%] [G loss: 0.899831]\n",
      "epoch:44 step:34620[D loss: 0.424552, acc: 60.94%, op_acc: 38.28%] [G loss: 0.931494]\n",
      "epoch:44 step:34621[D loss: 0.411731, acc: 60.94%, op_acc: 37.50%] [G loss: 1.135180]\n",
      "epoch:44 step:34622[D loss: 0.396423, acc: 63.28%, op_acc: 42.97%] [G loss: 0.918138]\n",
      "epoch:44 step:34623[D loss: 0.450250, acc: 63.28%, op_acc: 28.91%] [G loss: 0.906916]\n",
      "epoch:44 step:34624[D loss: 0.422497, acc: 62.50%, op_acc: 38.28%] [G loss: 0.922986]\n",
      "epoch:44 step:34625[D loss: 0.379801, acc: 67.19%, op_acc: 42.97%] [G loss: 0.879928]\n",
      "epoch:44 step:34626[D loss: 0.365662, acc: 70.31%, op_acc: 44.53%] [G loss: 0.999795]\n",
      "epoch:44 step:34627[D loss: 0.395456, acc: 64.06%, op_acc: 40.62%] [G loss: 0.914478]\n",
      "epoch:44 step:34628[D loss: 0.393428, acc: 70.31%, op_acc: 37.50%] [G loss: 1.035938]\n",
      "epoch:44 step:34629[D loss: 0.363451, acc: 67.97%, op_acc: 42.19%] [G loss: 0.945146]\n",
      "epoch:44 step:34630[D loss: 0.357370, acc: 75.00%, op_acc: 42.19%] [G loss: 1.043333]\n",
      "epoch:44 step:34631[D loss: 0.483251, acc: 45.31%, op_acc: 35.94%] [G loss: 0.815158]\n",
      "epoch:44 step:34632[D loss: 0.393739, acc: 60.94%, op_acc: 46.09%] [G loss: 0.910348]\n",
      "epoch:44 step:34633[D loss: 0.418710, acc: 57.81%, op_acc: 47.66%] [G loss: 0.797208]\n",
      "epoch:44 step:34634[D loss: 0.393634, acc: 63.28%, op_acc: 47.66%] [G loss: 0.777894]\n",
      "epoch:44 step:34635[D loss: 0.417178, acc: 64.84%, op_acc: 39.84%] [G loss: 0.821859]\n",
      "epoch:44 step:34636[D loss: 0.430853, acc: 60.16%, op_acc: 37.50%] [G loss: 0.865371]\n",
      "epoch:44 step:34637[D loss: 0.417946, acc: 57.81%, op_acc: 51.56%] [G loss: 1.040416]\n",
      "epoch:44 step:34638[D loss: 0.376882, acc: 71.09%, op_acc: 45.31%] [G loss: 0.954749]\n",
      "epoch:44 step:34639[D loss: 0.407565, acc: 64.06%, op_acc: 39.06%] [G loss: 0.841734]\n",
      "epoch:44 step:34640[D loss: 0.410180, acc: 65.62%, op_acc: 42.97%] [G loss: 0.789961]\n",
      "epoch:44 step:34641[D loss: 0.449907, acc: 57.81%, op_acc: 39.84%] [G loss: 0.884304]\n",
      "epoch:44 step:34642[D loss: 0.427238, acc: 62.50%, op_acc: 44.53%] [G loss: 0.895261]\n",
      "epoch:44 step:34643[D loss: 0.392132, acc: 65.62%, op_acc: 39.06%] [G loss: 0.864069]\n",
      "epoch:44 step:34644[D loss: 0.405131, acc: 57.03%, op_acc: 46.88%] [G loss: 1.024450]\n",
      "epoch:44 step:34645[D loss: 0.428735, acc: 54.69%, op_acc: 43.75%] [G loss: 0.915156]\n",
      "epoch:44 step:34646[D loss: 0.415281, acc: 57.81%, op_acc: 42.97%] [G loss: 0.875193]\n",
      "epoch:44 step:34647[D loss: 0.377185, acc: 69.53%, op_acc: 44.53%] [G loss: 1.052726]\n",
      "epoch:44 step:34648[D loss: 0.436202, acc: 53.91%, op_acc: 41.41%] [G loss: 0.785212]\n",
      "epoch:44 step:34649[D loss: 0.407182, acc: 64.06%, op_acc: 41.41%] [G loss: 0.849159]\n",
      "epoch:44 step:34650[D loss: 0.445605, acc: 57.03%, op_acc: 35.94%] [G loss: 1.014214]\n",
      "##############\n",
      "[0.8476216  0.87141386 0.80761901 0.80098366 0.79890907 0.82416246\n",
      " 0.89740276 0.84594999 0.81403721 0.84863098]\n",
      "##########\n",
      "epoch:44 step:34651[D loss: 0.422934, acc: 58.59%, op_acc: 43.75%] [G loss: 0.779353]\n",
      "epoch:44 step:34652[D loss: 0.379034, acc: 63.28%, op_acc: 43.75%] [G loss: 1.077738]\n",
      "epoch:44 step:34653[D loss: 0.418919, acc: 57.81%, op_acc: 39.06%] [G loss: 0.777074]\n",
      "epoch:44 step:34654[D loss: 0.459468, acc: 56.25%, op_acc: 36.72%] [G loss: 0.845491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34655[D loss: 0.396523, acc: 70.31%, op_acc: 41.41%] [G loss: 0.890259]\n",
      "epoch:44 step:34656[D loss: 0.403189, acc: 64.84%, op_acc: 46.88%] [G loss: 0.952543]\n",
      "epoch:44 step:34657[D loss: 0.389163, acc: 67.19%, op_acc: 43.75%] [G loss: 0.790177]\n",
      "epoch:44 step:34658[D loss: 0.368792, acc: 71.09%, op_acc: 43.75%] [G loss: 0.946670]\n",
      "epoch:44 step:34659[D loss: 0.384085, acc: 64.06%, op_acc: 43.75%] [G loss: 0.940975]\n",
      "epoch:44 step:34660[D loss: 0.357138, acc: 70.31%, op_acc: 48.44%] [G loss: 0.962685]\n",
      "epoch:44 step:34661[D loss: 0.395100, acc: 69.53%, op_acc: 41.41%] [G loss: 0.821912]\n",
      "epoch:44 step:34662[D loss: 0.394993, acc: 63.28%, op_acc: 42.19%] [G loss: 0.943064]\n",
      "epoch:44 step:34663[D loss: 0.396424, acc: 64.84%, op_acc: 45.31%] [G loss: 0.855231]\n",
      "epoch:44 step:34664[D loss: 0.429099, acc: 56.25%, op_acc: 43.75%] [G loss: 0.852744]\n",
      "epoch:44 step:34665[D loss: 0.379202, acc: 75.00%, op_acc: 41.41%] [G loss: 0.961820]\n",
      "epoch:44 step:34666[D loss: 0.402691, acc: 60.94%, op_acc: 43.75%] [G loss: 0.926091]\n",
      "epoch:44 step:34667[D loss: 0.397799, acc: 69.53%, op_acc: 42.19%] [G loss: 0.943941]\n",
      "epoch:44 step:34668[D loss: 0.342285, acc: 73.44%, op_acc: 50.00%] [G loss: 1.002374]\n",
      "epoch:44 step:34669[D loss: 0.395927, acc: 54.69%, op_acc: 44.53%] [G loss: 1.002898]\n",
      "epoch:44 step:34670[D loss: 0.398838, acc: 66.41%, op_acc: 39.06%] [G loss: 1.000498]\n",
      "epoch:44 step:34671[D loss: 0.394367, acc: 67.19%, op_acc: 44.53%] [G loss: 1.040308]\n",
      "epoch:44 step:34672[D loss: 0.402850, acc: 62.50%, op_acc: 40.62%] [G loss: 0.964177]\n",
      "epoch:44 step:34673[D loss: 0.460884, acc: 53.12%, op_acc: 35.16%] [G loss: 0.876769]\n",
      "epoch:44 step:34674[D loss: 0.390294, acc: 60.94%, op_acc: 42.19%] [G loss: 0.903487]\n",
      "epoch:44 step:34675[D loss: 0.461045, acc: 50.78%, op_acc: 39.06%] [G loss: 1.004795]\n",
      "epoch:44 step:34676[D loss: 0.396260, acc: 64.06%, op_acc: 42.97%] [G loss: 0.920749]\n",
      "epoch:44 step:34677[D loss: 0.378257, acc: 69.53%, op_acc: 46.09%] [G loss: 1.062608]\n",
      "epoch:44 step:34678[D loss: 0.365787, acc: 67.19%, op_acc: 46.88%] [G loss: 1.004054]\n",
      "epoch:44 step:34679[D loss: 0.403889, acc: 69.53%, op_acc: 37.50%] [G loss: 0.740771]\n",
      "epoch:44 step:34680[D loss: 0.403776, acc: 58.59%, op_acc: 43.75%] [G loss: 1.048025]\n",
      "epoch:44 step:34681[D loss: 0.391546, acc: 66.41%, op_acc: 45.31%] [G loss: 0.908789]\n",
      "epoch:44 step:34682[D loss: 0.412947, acc: 59.38%, op_acc: 39.06%] [G loss: 0.878375]\n",
      "epoch:44 step:34683[D loss: 0.407097, acc: 64.84%, op_acc: 45.31%] [G loss: 0.852705]\n",
      "epoch:44 step:34684[D loss: 0.400853, acc: 59.38%, op_acc: 46.09%] [G loss: 0.890239]\n",
      "epoch:44 step:34685[D loss: 0.450066, acc: 56.25%, op_acc: 39.84%] [G loss: 0.843845]\n",
      "epoch:44 step:34686[D loss: 0.416161, acc: 60.94%, op_acc: 44.53%] [G loss: 0.965414]\n",
      "epoch:44 step:34687[D loss: 0.378130, acc: 67.19%, op_acc: 42.19%] [G loss: 1.068990]\n",
      "epoch:44 step:34688[D loss: 0.399253, acc: 65.62%, op_acc: 42.19%] [G loss: 0.871592]\n",
      "epoch:44 step:34689[D loss: 0.377881, acc: 67.19%, op_acc: 44.53%] [G loss: 1.041700]\n",
      "epoch:44 step:34690[D loss: 0.409583, acc: 58.59%, op_acc: 44.53%] [G loss: 0.897695]\n",
      "epoch:44 step:34691[D loss: 0.413658, acc: 60.94%, op_acc: 38.28%] [G loss: 1.081612]\n",
      "epoch:44 step:34692[D loss: 0.427117, acc: 55.47%, op_acc: 39.06%] [G loss: 0.885521]\n",
      "epoch:44 step:34693[D loss: 0.376432, acc: 71.09%, op_acc: 40.62%] [G loss: 1.020619]\n",
      "epoch:44 step:34694[D loss: 0.385014, acc: 64.84%, op_acc: 44.53%] [G loss: 0.991258]\n",
      "epoch:44 step:34695[D loss: 0.387201, acc: 65.62%, op_acc: 46.88%] [G loss: 1.069641]\n",
      "epoch:44 step:34696[D loss: 0.383317, acc: 60.94%, op_acc: 45.31%] [G loss: 0.943272]\n",
      "epoch:44 step:34697[D loss: 0.387473, acc: 70.31%, op_acc: 43.75%] [G loss: 0.903649]\n",
      "epoch:44 step:34698[D loss: 0.435016, acc: 59.38%, op_acc: 44.53%] [G loss: 0.966998]\n",
      "epoch:44 step:34699[D loss: 0.386067, acc: 69.53%, op_acc: 39.84%] [G loss: 0.986197]\n",
      "epoch:44 step:34700[D loss: 0.420617, acc: 54.69%, op_acc: 41.41%] [G loss: 0.945174]\n",
      "##############\n",
      "[0.86317923 0.85957679 0.80914796 0.80208463 0.80838906 0.82580792\n",
      " 0.8751463  0.82414734 0.82203132 0.82687655]\n",
      "##########\n",
      "epoch:44 step:34701[D loss: 0.426518, acc: 60.16%, op_acc: 37.50%] [G loss: 1.119513]\n",
      "epoch:44 step:34702[D loss: 0.351893, acc: 70.31%, op_acc: 48.44%] [G loss: 0.917470]\n",
      "epoch:44 step:34703[D loss: 0.411960, acc: 64.84%, op_acc: 44.53%] [G loss: 0.907552]\n",
      "epoch:44 step:34704[D loss: 0.462996, acc: 53.91%, op_acc: 41.41%] [G loss: 1.072338]\n",
      "epoch:44 step:34705[D loss: 0.405974, acc: 61.72%, op_acc: 36.72%] [G loss: 0.885059]\n",
      "epoch:44 step:34706[D loss: 0.455690, acc: 49.22%, op_acc: 39.84%] [G loss: 0.993136]\n",
      "epoch:44 step:34707[D loss: 0.428320, acc: 59.38%, op_acc: 42.19%] [G loss: 0.942392]\n",
      "epoch:44 step:34708[D loss: 0.393144, acc: 64.84%, op_acc: 42.19%] [G loss: 0.785701]\n",
      "epoch:44 step:34709[D loss: 0.415073, acc: 58.59%, op_acc: 37.50%] [G loss: 0.942334]\n",
      "epoch:44 step:34710[D loss: 0.402789, acc: 60.16%, op_acc: 40.62%] [G loss: 0.915210]\n",
      "epoch:44 step:34711[D loss: 0.391760, acc: 61.72%, op_acc: 43.75%] [G loss: 0.850107]\n",
      "epoch:44 step:34712[D loss: 0.388941, acc: 63.28%, op_acc: 38.28%] [G loss: 1.028297]\n",
      "epoch:44 step:34713[D loss: 0.385632, acc: 63.28%, op_acc: 42.19%] [G loss: 1.041219]\n",
      "epoch:44 step:34714[D loss: 0.415170, acc: 62.50%, op_acc: 35.16%] [G loss: 0.966215]\n",
      "epoch:44 step:34715[D loss: 0.455909, acc: 52.34%, op_acc: 42.19%] [G loss: 0.793392]\n",
      "epoch:44 step:34716[D loss: 0.417294, acc: 61.72%, op_acc: 41.41%] [G loss: 0.812183]\n",
      "epoch:44 step:34717[D loss: 0.398136, acc: 64.84%, op_acc: 41.41%] [G loss: 0.882418]\n",
      "epoch:44 step:34718[D loss: 0.433742, acc: 58.59%, op_acc: 42.97%] [G loss: 0.910957]\n",
      "epoch:44 step:34719[D loss: 0.417433, acc: 57.81%, op_acc: 42.97%] [G loss: 0.990268]\n",
      "epoch:44 step:34720[D loss: 0.402872, acc: 60.16%, op_acc: 47.66%] [G loss: 0.940963]\n",
      "epoch:44 step:34721[D loss: 0.409419, acc: 63.28%, op_acc: 39.84%] [G loss: 1.007616]\n",
      "epoch:44 step:34722[D loss: 0.439965, acc: 55.47%, op_acc: 37.50%] [G loss: 1.026041]\n",
      "epoch:44 step:34723[D loss: 0.399278, acc: 69.53%, op_acc: 42.19%] [G loss: 1.012925]\n",
      "epoch:44 step:34724[D loss: 0.395916, acc: 63.28%, op_acc: 39.84%] [G loss: 0.939042]\n",
      "epoch:44 step:34725[D loss: 0.418431, acc: 64.06%, op_acc: 42.19%] [G loss: 0.971791]\n",
      "epoch:44 step:34726[D loss: 0.379077, acc: 65.62%, op_acc: 42.97%] [G loss: 0.946212]\n",
      "epoch:44 step:34727[D loss: 0.406549, acc: 64.06%, op_acc: 42.19%] [G loss: 0.878469]\n",
      "epoch:44 step:34728[D loss: 0.390791, acc: 64.06%, op_acc: 44.53%] [G loss: 0.994163]\n",
      "epoch:44 step:34729[D loss: 0.356346, acc: 72.66%, op_acc: 46.88%] [G loss: 1.035045]\n",
      "epoch:44 step:34730[D loss: 0.407795, acc: 60.94%, op_acc: 42.97%] [G loss: 0.897342]\n",
      "epoch:44 step:34731[D loss: 0.435235, acc: 57.03%, op_acc: 39.06%] [G loss: 0.888222]\n",
      "epoch:44 step:34732[D loss: 0.400927, acc: 65.62%, op_acc: 43.75%] [G loss: 0.950532]\n",
      "epoch:44 step:34733[D loss: 0.406694, acc: 63.28%, op_acc: 41.41%] [G loss: 1.011178]\n",
      "epoch:44 step:34734[D loss: 0.398251, acc: 62.50%, op_acc: 40.62%] [G loss: 0.977448]\n",
      "epoch:44 step:34735[D loss: 0.378416, acc: 61.72%, op_acc: 48.44%] [G loss: 0.901914]\n",
      "epoch:44 step:34736[D loss: 0.425615, acc: 59.38%, op_acc: 39.84%] [G loss: 1.049589]\n",
      "epoch:44 step:34737[D loss: 0.391037, acc: 63.28%, op_acc: 42.19%] [G loss: 1.009347]\n",
      "epoch:44 step:34738[D loss: 0.378937, acc: 73.44%, op_acc: 42.97%] [G loss: 0.855908]\n",
      "epoch:44 step:34739[D loss: 0.385796, acc: 65.62%, op_acc: 47.66%] [G loss: 0.858936]\n",
      "epoch:44 step:34740[D loss: 0.392004, acc: 63.28%, op_acc: 44.53%] [G loss: 0.972218]\n",
      "epoch:44 step:34741[D loss: 0.379293, acc: 60.94%, op_acc: 40.62%] [G loss: 0.979620]\n",
      "epoch:44 step:34742[D loss: 0.381162, acc: 65.62%, op_acc: 43.75%] [G loss: 1.082996]\n",
      "epoch:44 step:34743[D loss: 0.392129, acc: 64.84%, op_acc: 45.31%] [G loss: 1.095407]\n",
      "epoch:44 step:34744[D loss: 0.382456, acc: 66.41%, op_acc: 42.97%] [G loss: 0.945047]\n",
      "epoch:44 step:34745[D loss: 0.383220, acc: 69.53%, op_acc: 38.28%] [G loss: 0.920523]\n",
      "epoch:44 step:34746[D loss: 0.421597, acc: 57.81%, op_acc: 42.19%] [G loss: 0.940750]\n",
      "epoch:44 step:34747[D loss: 0.384117, acc: 68.75%, op_acc: 50.78%] [G loss: 0.958565]\n",
      "epoch:44 step:34748[D loss: 0.379888, acc: 66.41%, op_acc: 40.62%] [G loss: 0.972719]\n",
      "epoch:44 step:34749[D loss: 0.375419, acc: 68.75%, op_acc: 45.31%] [G loss: 1.092828]\n",
      "epoch:44 step:34750[D loss: 0.407644, acc: 60.94%, op_acc: 46.09%] [G loss: 0.799370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.84003583 0.85514579 0.79784335 0.8023317  0.79556711 0.8282786\n",
      " 0.88213166 0.81535982 0.80092606 0.85481731]\n",
      "##########\n",
      "epoch:44 step:34751[D loss: 0.374951, acc: 64.84%, op_acc: 43.75%] [G loss: 1.076143]\n",
      "epoch:44 step:34752[D loss: 0.416011, acc: 56.25%, op_acc: 38.28%] [G loss: 0.690352]\n",
      "epoch:44 step:34753[D loss: 0.452563, acc: 50.00%, op_acc: 42.19%] [G loss: 0.918750]\n",
      "epoch:44 step:34754[D loss: 0.425027, acc: 59.38%, op_acc: 40.62%] [G loss: 0.831906]\n",
      "epoch:44 step:34755[D loss: 0.390021, acc: 64.06%, op_acc: 46.09%] [G loss: 1.059709]\n",
      "epoch:44 step:34756[D loss: 0.381863, acc: 59.38%, op_acc: 48.44%] [G loss: 0.972925]\n",
      "epoch:44 step:34757[D loss: 0.387866, acc: 67.97%, op_acc: 39.84%] [G loss: 0.858716]\n",
      "epoch:44 step:34758[D loss: 0.375398, acc: 70.31%, op_acc: 45.31%] [G loss: 0.589593]\n",
      "epoch:44 step:34759[D loss: 0.410788, acc: 67.19%, op_acc: 41.41%] [G loss: 0.830196]\n",
      "epoch:44 step:34760[D loss: 0.391142, acc: 64.84%, op_acc: 48.44%] [G loss: 0.757150]\n",
      "epoch:44 step:34761[D loss: 0.459786, acc: 50.00%, op_acc: 45.31%] [G loss: 0.986092]\n",
      "epoch:44 step:34762[D loss: 0.423142, acc: 60.94%, op_acc: 42.97%] [G loss: 0.648697]\n",
      "epoch:44 step:34763[D loss: 0.408215, acc: 57.03%, op_acc: 42.97%] [G loss: 0.729361]\n",
      "epoch:44 step:34764[D loss: 0.397605, acc: 58.59%, op_acc: 44.53%] [G loss: 0.844012]\n",
      "epoch:44 step:34765[D loss: 0.403790, acc: 64.84%, op_acc: 45.31%] [G loss: 0.891575]\n",
      "epoch:44 step:34766[D loss: 0.500611, acc: 44.53%, op_acc: 35.94%] [G loss: 0.854628]\n",
      "epoch:44 step:34767[D loss: 0.407912, acc: 61.72%, op_acc: 39.06%] [G loss: 0.844042]\n",
      "epoch:44 step:34768[D loss: 0.379496, acc: 64.06%, op_acc: 48.44%] [G loss: 1.143230]\n",
      "epoch:44 step:34769[D loss: 0.413584, acc: 63.28%, op_acc: 38.28%] [G loss: 0.929895]\n",
      "epoch:44 step:34770[D loss: 0.419522, acc: 56.25%, op_acc: 39.06%] [G loss: 0.829337]\n",
      "epoch:44 step:34771[D loss: 0.375359, acc: 64.84%, op_acc: 46.09%] [G loss: 0.868184]\n",
      "epoch:44 step:34772[D loss: 0.409992, acc: 58.59%, op_acc: 44.53%] [G loss: 0.861965]\n",
      "epoch:44 step:34773[D loss: 0.409670, acc: 59.38%, op_acc: 49.22%] [G loss: 0.912354]\n",
      "epoch:44 step:34774[D loss: 0.403070, acc: 59.38%, op_acc: 47.66%] [G loss: 0.943023]\n",
      "epoch:44 step:34775[D loss: 0.405865, acc: 64.06%, op_acc: 42.19%] [G loss: 0.908471]\n",
      "epoch:44 step:34776[D loss: 0.375905, acc: 63.28%, op_acc: 45.31%] [G loss: 0.924913]\n",
      "epoch:44 step:34777[D loss: 0.405401, acc: 57.03%, op_acc: 42.97%] [G loss: 0.898952]\n",
      "epoch:44 step:34778[D loss: 0.412658, acc: 60.94%, op_acc: 43.75%] [G loss: 0.884757]\n",
      "epoch:44 step:34779[D loss: 0.401696, acc: 67.19%, op_acc: 40.62%] [G loss: 0.997055]\n",
      "epoch:44 step:34780[D loss: 0.390840, acc: 65.62%, op_acc: 40.62%] [G loss: 0.926463]\n",
      "epoch:44 step:34781[D loss: 0.393618, acc: 66.41%, op_acc: 44.53%] [G loss: 0.935136]\n",
      "epoch:44 step:34782[D loss: 0.395047, acc: 67.97%, op_acc: 43.75%] [G loss: 0.912466]\n",
      "epoch:44 step:34783[D loss: 0.414494, acc: 62.50%, op_acc: 41.41%] [G loss: 1.028961]\n",
      "epoch:44 step:34784[D loss: 0.407445, acc: 63.28%, op_acc: 44.53%] [G loss: 0.995623]\n",
      "epoch:44 step:34785[D loss: 0.406787, acc: 67.97%, op_acc: 47.66%] [G loss: 1.005738]\n",
      "epoch:44 step:34786[D loss: 0.373527, acc: 68.75%, op_acc: 48.44%] [G loss: 0.949291]\n",
      "epoch:44 step:34787[D loss: 0.412852, acc: 66.41%, op_acc: 42.97%] [G loss: 1.042204]\n",
      "epoch:44 step:34788[D loss: 0.392659, acc: 66.41%, op_acc: 45.31%] [G loss: 1.032670]\n",
      "epoch:44 step:34789[D loss: 0.424237, acc: 56.25%, op_acc: 43.75%] [G loss: 1.043575]\n",
      "epoch:44 step:34790[D loss: 0.366098, acc: 71.88%, op_acc: 43.75%] [G loss: 0.974976]\n",
      "epoch:44 step:34791[D loss: 0.388134, acc: 66.41%, op_acc: 45.31%] [G loss: 1.039660]\n",
      "epoch:44 step:34792[D loss: 0.380339, acc: 63.28%, op_acc: 44.53%] [G loss: 0.983256]\n",
      "epoch:44 step:34793[D loss: 0.391296, acc: 64.84%, op_acc: 45.31%] [G loss: 0.968076]\n",
      "epoch:44 step:34794[D loss: 0.381542, acc: 68.75%, op_acc: 49.22%] [G loss: 0.922582]\n",
      "epoch:44 step:34795[D loss: 0.417638, acc: 60.16%, op_acc: 41.41%] [G loss: 0.792924]\n",
      "epoch:44 step:34796[D loss: 0.369098, acc: 68.75%, op_acc: 47.66%] [G loss: 0.927927]\n",
      "epoch:44 step:34797[D loss: 0.354995, acc: 70.31%, op_acc: 42.97%] [G loss: 0.977308]\n",
      "epoch:44 step:34798[D loss: 0.372565, acc: 65.62%, op_acc: 47.66%] [G loss: 0.937660]\n",
      "epoch:44 step:34799[D loss: 0.391918, acc: 66.41%, op_acc: 42.97%] [G loss: 0.765439]\n",
      "epoch:44 step:34800[D loss: 0.425187, acc: 58.59%, op_acc: 41.41%] [G loss: 0.836870]\n",
      "##############\n",
      "[0.87504078 0.88153495 0.81958876 0.80642248 0.79087765 0.82570514\n",
      " 0.88404963 0.82195299 0.80505737 0.84000253]\n",
      "##########\n",
      "epoch:44 step:34801[D loss: 0.438541, acc: 58.59%, op_acc: 41.41%] [G loss: 1.014433]\n",
      "epoch:44 step:34802[D loss: 0.402018, acc: 65.62%, op_acc: 46.88%] [G loss: 1.091708]\n",
      "epoch:44 step:34803[D loss: 0.410821, acc: 56.25%, op_acc: 47.66%] [G loss: 0.816379]\n",
      "epoch:44 step:34804[D loss: 0.406065, acc: 60.94%, op_acc: 45.31%] [G loss: 0.789566]\n",
      "epoch:44 step:34805[D loss: 0.391098, acc: 69.53%, op_acc: 36.72%] [G loss: 1.101369]\n",
      "epoch:44 step:34806[D loss: 0.412672, acc: 60.16%, op_acc: 42.19%] [G loss: 0.917375]\n",
      "epoch:44 step:34807[D loss: 0.429280, acc: 59.38%, op_acc: 39.84%] [G loss: 0.965969]\n",
      "epoch:44 step:34808[D loss: 0.361690, acc: 69.53%, op_acc: 49.22%] [G loss: 0.967034]\n",
      "epoch:44 step:34809[D loss: 0.428378, acc: 57.81%, op_acc: 42.19%] [G loss: 0.885303]\n",
      "epoch:44 step:34810[D loss: 0.407989, acc: 60.16%, op_acc: 44.53%] [G loss: 0.964702]\n",
      "epoch:44 step:34811[D loss: 0.448621, acc: 55.47%, op_acc: 35.16%] [G loss: 0.965361]\n",
      "epoch:44 step:34812[D loss: 0.402392, acc: 65.62%, op_acc: 39.84%] [G loss: 1.010486]\n",
      "epoch:44 step:34813[D loss: 0.415744, acc: 60.94%, op_acc: 44.53%] [G loss: 0.922883]\n",
      "epoch:44 step:34814[D loss: 0.379331, acc: 71.88%, op_acc: 42.19%] [G loss: 1.058961]\n",
      "epoch:44 step:34815[D loss: 0.371497, acc: 70.31%, op_acc: 44.53%] [G loss: 1.020603]\n",
      "epoch:44 step:34816[D loss: 0.366414, acc: 65.62%, op_acc: 53.12%] [G loss: 0.858914]\n",
      "epoch:44 step:34817[D loss: 0.382868, acc: 63.28%, op_acc: 44.53%] [G loss: 0.924985]\n",
      "epoch:44 step:34818[D loss: 0.430651, acc: 60.16%, op_acc: 44.53%] [G loss: 1.005276]\n",
      "epoch:44 step:34819[D loss: 0.412029, acc: 63.28%, op_acc: 42.97%] [G loss: 1.037403]\n",
      "epoch:44 step:34820[D loss: 0.449763, acc: 54.69%, op_acc: 40.62%] [G loss: 1.081252]\n",
      "epoch:44 step:34821[D loss: 0.392536, acc: 69.53%, op_acc: 47.66%] [G loss: 1.005961]\n",
      "epoch:44 step:34822[D loss: 0.387687, acc: 67.19%, op_acc: 39.06%] [G loss: 1.012941]\n",
      "epoch:44 step:34823[D loss: 0.398529, acc: 58.59%, op_acc: 42.97%] [G loss: 0.908310]\n",
      "epoch:44 step:34824[D loss: 0.380998, acc: 64.84%, op_acc: 46.09%] [G loss: 0.838467]\n",
      "epoch:44 step:34825[D loss: 0.401076, acc: 68.75%, op_acc: 42.19%] [G loss: 0.967208]\n",
      "epoch:44 step:34826[D loss: 0.392016, acc: 61.72%, op_acc: 48.44%] [G loss: 0.977045]\n",
      "epoch:44 step:34827[D loss: 0.398969, acc: 62.50%, op_acc: 46.09%] [G loss: 0.917076]\n",
      "epoch:44 step:34828[D loss: 0.396136, acc: 72.66%, op_acc: 37.50%] [G loss: 0.961643]\n",
      "epoch:44 step:34829[D loss: 0.384650, acc: 67.97%, op_acc: 42.19%] [G loss: 1.075070]\n",
      "epoch:44 step:34830[D loss: 0.349759, acc: 70.31%, op_acc: 44.53%] [G loss: 1.087680]\n",
      "epoch:44 step:34831[D loss: 0.390136, acc: 64.06%, op_acc: 44.53%] [G loss: 1.039747]\n",
      "epoch:44 step:34832[D loss: 0.349388, acc: 71.88%, op_acc: 43.75%] [G loss: 0.775522]\n",
      "epoch:44 step:34833[D loss: 0.374501, acc: 66.41%, op_acc: 47.66%] [G loss: 1.033059]\n",
      "epoch:44 step:34834[D loss: 0.394645, acc: 60.94%, op_acc: 46.88%] [G loss: 1.046353]\n",
      "epoch:44 step:34835[D loss: 0.395152, acc: 70.31%, op_acc: 43.75%] [G loss: 1.225646]\n",
      "epoch:44 step:34836[D loss: 0.461690, acc: 54.69%, op_acc: 39.06%] [G loss: 0.845571]\n",
      "epoch:44 step:34837[D loss: 0.390751, acc: 58.59%, op_acc: 47.66%] [G loss: 1.074748]\n",
      "epoch:44 step:34838[D loss: 0.373135, acc: 69.53%, op_acc: 49.22%] [G loss: 1.048177]\n",
      "epoch:44 step:34839[D loss: 0.448931, acc: 51.56%, op_acc: 42.19%] [G loss: 1.034648]\n",
      "epoch:44 step:34840[D loss: 0.431195, acc: 57.81%, op_acc: 43.75%] [G loss: 0.955769]\n",
      "epoch:44 step:34841[D loss: 0.411690, acc: 64.06%, op_acc: 42.97%] [G loss: 1.047063]\n",
      "epoch:44 step:34842[D loss: 0.385289, acc: 71.09%, op_acc: 42.97%] [G loss: 1.109452]\n",
      "epoch:44 step:34843[D loss: 0.375767, acc: 64.06%, op_acc: 43.75%] [G loss: 0.841281]\n",
      "epoch:44 step:34844[D loss: 0.420603, acc: 62.50%, op_acc: 34.38%] [G loss: 1.141706]\n",
      "epoch:44 step:34845[D loss: 0.427136, acc: 60.94%, op_acc: 41.41%] [G loss: 0.754839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34846[D loss: 0.407972, acc: 67.19%, op_acc: 44.53%] [G loss: 0.958471]\n",
      "epoch:44 step:34847[D loss: 0.421028, acc: 57.81%, op_acc: 43.75%] [G loss: 1.066200]\n",
      "epoch:44 step:34848[D loss: 0.377797, acc: 68.75%, op_acc: 48.44%] [G loss: 0.812652]\n",
      "epoch:44 step:34849[D loss: 0.401858, acc: 67.97%, op_acc: 41.41%] [G loss: 1.038677]\n",
      "epoch:44 step:34850[D loss: 0.405781, acc: 61.72%, op_acc: 39.84%] [G loss: 0.734455]\n",
      "##############\n",
      "[0.85790917 0.84893528 0.81273056 0.80597795 0.79758555 0.82734397\n",
      " 0.86652517 0.81609264 0.78531343 0.84172253]\n",
      "##########\n",
      "epoch:44 step:34851[D loss: 0.432986, acc: 58.59%, op_acc: 34.38%] [G loss: 0.815143]\n",
      "epoch:44 step:34852[D loss: 0.454629, acc: 54.69%, op_acc: 32.81%] [G loss: 0.788599]\n",
      "epoch:44 step:34853[D loss: 0.423506, acc: 56.25%, op_acc: 39.84%] [G loss: 0.941759]\n",
      "epoch:44 step:34854[D loss: 0.419463, acc: 57.03%, op_acc: 41.41%] [G loss: 0.875619]\n",
      "epoch:44 step:34855[D loss: 0.436050, acc: 57.81%, op_acc: 36.72%] [G loss: 0.853155]\n",
      "epoch:44 step:34856[D loss: 0.382403, acc: 66.41%, op_acc: 47.66%] [G loss: 0.920933]\n",
      "epoch:44 step:34857[D loss: 0.403509, acc: 56.25%, op_acc: 45.31%] [G loss: 1.000952]\n",
      "epoch:44 step:34858[D loss: 0.412332, acc: 63.28%, op_acc: 46.88%] [G loss: 1.054824]\n",
      "epoch:44 step:34859[D loss: 0.414969, acc: 61.72%, op_acc: 45.31%] [G loss: 1.012293]\n",
      "epoch:44 step:34860[D loss: 0.409088, acc: 64.06%, op_acc: 44.53%] [G loss: 1.035154]\n",
      "epoch:44 step:34861[D loss: 0.399426, acc: 61.72%, op_acc: 42.19%] [G loss: 1.073566]\n",
      "epoch:44 step:34862[D loss: 0.394015, acc: 66.41%, op_acc: 46.09%] [G loss: 0.981164]\n",
      "epoch:44 step:34863[D loss: 0.375850, acc: 69.53%, op_acc: 41.41%] [G loss: 0.929265]\n",
      "epoch:44 step:34864[D loss: 0.374603, acc: 67.19%, op_acc: 48.44%] [G loss: 0.962151]\n",
      "epoch:44 step:34865[D loss: 0.397916, acc: 70.31%, op_acc: 39.84%] [G loss: 0.887648]\n",
      "epoch:44 step:34866[D loss: 0.403772, acc: 61.72%, op_acc: 44.53%] [G loss: 0.954609]\n",
      "epoch:44 step:34867[D loss: 0.405853, acc: 61.72%, op_acc: 46.88%] [G loss: 1.030565]\n",
      "epoch:44 step:34868[D loss: 0.426263, acc: 54.69%, op_acc: 37.50%] [G loss: 0.946225]\n",
      "epoch:44 step:34869[D loss: 0.424760, acc: 63.28%, op_acc: 39.06%] [G loss: 0.921827]\n",
      "epoch:44 step:34870[D loss: 0.409286, acc: 56.25%, op_acc: 42.97%] [G loss: 0.974475]\n",
      "epoch:44 step:34871[D loss: 0.387534, acc: 64.06%, op_acc: 46.09%] [G loss: 1.026142]\n",
      "epoch:44 step:34872[D loss: 0.409648, acc: 62.50%, op_acc: 45.31%] [G loss: 0.902169]\n",
      "epoch:44 step:34873[D loss: 0.415478, acc: 60.94%, op_acc: 38.28%] [G loss: 0.887073]\n",
      "epoch:44 step:34874[D loss: 0.381125, acc: 71.09%, op_acc: 42.19%] [G loss: 0.860146]\n",
      "epoch:44 step:34875[D loss: 0.423405, acc: 51.56%, op_acc: 48.44%] [G loss: 0.926095]\n",
      "epoch:44 step:34876[D loss: 0.426283, acc: 57.03%, op_acc: 41.41%] [G loss: 1.026597]\n",
      "epoch:44 step:34877[D loss: 0.477053, acc: 52.34%, op_acc: 36.72%] [G loss: 0.807253]\n",
      "epoch:44 step:34878[D loss: 0.442436, acc: 59.38%, op_acc: 39.84%] [G loss: 0.806888]\n",
      "epoch:44 step:34879[D loss: 0.444866, acc: 60.94%, op_acc: 34.38%] [G loss: 0.830948]\n",
      "epoch:44 step:34880[D loss: 0.412150, acc: 63.28%, op_acc: 39.84%] [G loss: 1.033326]\n",
      "epoch:44 step:34881[D loss: 0.434779, acc: 53.12%, op_acc: 42.19%] [G loss: 0.966539]\n",
      "epoch:44 step:34882[D loss: 0.408589, acc: 64.84%, op_acc: 39.84%] [G loss: 0.994564]\n",
      "epoch:44 step:34883[D loss: 0.393971, acc: 63.28%, op_acc: 42.97%] [G loss: 1.023787]\n",
      "epoch:44 step:34884[D loss: 0.401845, acc: 60.16%, op_acc: 45.31%] [G loss: 0.957294]\n",
      "epoch:44 step:34885[D loss: 0.446040, acc: 56.25%, op_acc: 40.62%] [G loss: 0.896209]\n",
      "epoch:44 step:34886[D loss: 0.439513, acc: 50.78%, op_acc: 42.19%] [G loss: 0.900869]\n",
      "epoch:44 step:34887[D loss: 0.359066, acc: 65.62%, op_acc: 44.53%] [G loss: 1.058624]\n",
      "epoch:44 step:34888[D loss: 0.414937, acc: 64.84%, op_acc: 35.16%] [G loss: 1.004019]\n",
      "epoch:44 step:34889[D loss: 0.407264, acc: 60.94%, op_acc: 39.84%] [G loss: 0.943143]\n",
      "epoch:44 step:34890[D loss: 0.479112, acc: 50.78%, op_acc: 30.47%] [G loss: 0.809332]\n",
      "epoch:44 step:34891[D loss: 0.427506, acc: 56.25%, op_acc: 43.75%] [G loss: 1.001119]\n",
      "epoch:44 step:34892[D loss: 0.388456, acc: 67.19%, op_acc: 47.66%] [G loss: 1.073549]\n",
      "epoch:44 step:34893[D loss: 0.386415, acc: 64.84%, op_acc: 42.97%] [G loss: 0.810728]\n",
      "epoch:44 step:34894[D loss: 0.421800, acc: 63.28%, op_acc: 40.62%] [G loss: 0.897552]\n",
      "epoch:44 step:34895[D loss: 0.393765, acc: 65.62%, op_acc: 42.19%] [G loss: 0.781727]\n",
      "epoch:44 step:34896[D loss: 0.398361, acc: 65.62%, op_acc: 45.31%] [G loss: 0.970331]\n",
      "epoch:44 step:34897[D loss: 0.393570, acc: 64.06%, op_acc: 42.97%] [G loss: 0.802631]\n",
      "epoch:44 step:34898[D loss: 0.372595, acc: 66.41%, op_acc: 49.22%] [G loss: 0.956703]\n",
      "epoch:44 step:34899[D loss: 0.394043, acc: 64.06%, op_acc: 45.31%] [G loss: 0.826168]\n",
      "epoch:44 step:34900[D loss: 0.366352, acc: 71.88%, op_acc: 46.09%] [G loss: 1.035969]\n",
      "##############\n",
      "[0.85222169 0.84910722 0.80791674 0.80691162 0.77700521 0.82354454\n",
      " 0.84761501 0.79819431 0.81836058 0.82204474]\n",
      "##########\n",
      "epoch:44 step:34901[D loss: 0.398885, acc: 64.84%, op_acc: 39.06%] [G loss: 0.842103]\n",
      "epoch:44 step:34902[D loss: 0.406183, acc: 55.47%, op_acc: 39.84%] [G loss: 0.828368]\n",
      "epoch:44 step:34903[D loss: 0.425808, acc: 63.28%, op_acc: 39.84%] [G loss: 0.789730]\n",
      "epoch:44 step:34904[D loss: 0.399147, acc: 64.06%, op_acc: 41.41%] [G loss: 0.947305]\n",
      "epoch:44 step:34905[D loss: 0.395748, acc: 63.28%, op_acc: 52.34%] [G loss: 0.865583]\n",
      "epoch:44 step:34906[D loss: 0.419779, acc: 60.94%, op_acc: 38.28%] [G loss: 0.879800]\n",
      "epoch:44 step:34907[D loss: 0.413423, acc: 57.03%, op_acc: 43.75%] [G loss: 0.815248]\n",
      "epoch:44 step:34908[D loss: 0.401437, acc: 64.84%, op_acc: 42.97%] [G loss: 0.865201]\n",
      "epoch:44 step:34909[D loss: 0.408030, acc: 58.59%, op_acc: 46.09%] [G loss: 0.789315]\n",
      "epoch:44 step:34910[D loss: 0.394034, acc: 66.41%, op_acc: 47.66%] [G loss: 0.969347]\n",
      "epoch:44 step:34911[D loss: 0.364783, acc: 71.09%, op_acc: 42.97%] [G loss: 0.981222]\n",
      "epoch:44 step:34912[D loss: 0.382813, acc: 66.41%, op_acc: 44.53%] [G loss: 0.991326]\n",
      "epoch:44 step:34913[D loss: 0.391126, acc: 63.28%, op_acc: 46.09%] [G loss: 0.960387]\n",
      "epoch:44 step:34914[D loss: 0.360653, acc: 71.88%, op_acc: 49.22%] [G loss: 1.029768]\n",
      "epoch:44 step:34915[D loss: 0.403556, acc: 55.47%, op_acc: 48.44%] [G loss: 0.871095]\n",
      "epoch:44 step:34916[D loss: 0.435307, acc: 57.81%, op_acc: 38.28%] [G loss: 0.982520]\n",
      "epoch:44 step:34917[D loss: 0.407092, acc: 67.97%, op_acc: 39.84%] [G loss: 0.798360]\n",
      "epoch:44 step:34918[D loss: 0.355538, acc: 80.47%, op_acc: 41.41%] [G loss: 0.993459]\n",
      "epoch:44 step:34919[D loss: 0.367277, acc: 67.19%, op_acc: 46.09%] [G loss: 0.958207]\n",
      "epoch:44 step:34920[D loss: 0.401065, acc: 64.84%, op_acc: 47.66%] [G loss: 1.024416]\n",
      "epoch:44 step:34921[D loss: 0.401516, acc: 62.50%, op_acc: 45.31%] [G loss: 0.941045]\n",
      "epoch:44 step:34922[D loss: 0.363526, acc: 64.84%, op_acc: 49.22%] [G loss: 0.870083]\n",
      "epoch:44 step:34923[D loss: 0.401107, acc: 64.06%, op_acc: 41.41%] [G loss: 1.060799]\n",
      "epoch:44 step:34924[D loss: 0.430002, acc: 60.16%, op_acc: 38.28%] [G loss: 1.044278]\n",
      "epoch:44 step:34925[D loss: 0.370254, acc: 64.06%, op_acc: 46.09%] [G loss: 0.852804]\n",
      "epoch:44 step:34926[D loss: 0.398790, acc: 67.97%, op_acc: 39.84%] [G loss: 1.088795]\n",
      "epoch:44 step:34927[D loss: 0.387184, acc: 67.19%, op_acc: 40.62%] [G loss: 0.931942]\n",
      "epoch:44 step:34928[D loss: 0.370267, acc: 67.97%, op_acc: 43.75%] [G loss: 0.873903]\n",
      "epoch:44 step:34929[D loss: 0.474448, acc: 47.66%, op_acc: 39.84%] [G loss: 1.058154]\n",
      "epoch:44 step:34930[D loss: 0.385005, acc: 71.88%, op_acc: 39.06%] [G loss: 0.928919]\n",
      "epoch:44 step:34931[D loss: 0.392100, acc: 70.31%, op_acc: 43.75%] [G loss: 0.979914]\n",
      "epoch:44 step:34932[D loss: 0.404497, acc: 62.50%, op_acc: 49.22%] [G loss: 0.953493]\n",
      "epoch:44 step:34933[D loss: 0.389370, acc: 65.62%, op_acc: 42.97%] [G loss: 1.009404]\n",
      "epoch:44 step:34934[D loss: 0.415198, acc: 60.16%, op_acc: 42.19%] [G loss: 0.983004]\n",
      "epoch:44 step:34935[D loss: 0.419811, acc: 55.47%, op_acc: 42.97%] [G loss: 1.026575]\n",
      "epoch:44 step:34936[D loss: 0.427461, acc: 59.38%, op_acc: 41.41%] [G loss: 0.953302]\n",
      "epoch:44 step:34937[D loss: 0.427586, acc: 60.16%, op_acc: 44.53%] [G loss: 1.062759]\n",
      "epoch:44 step:34938[D loss: 0.431388, acc: 54.69%, op_acc: 39.84%] [G loss: 0.877549]\n",
      "epoch:44 step:34939[D loss: 0.418580, acc: 56.25%, op_acc: 41.41%] [G loss: 0.979778]\n",
      "epoch:44 step:34940[D loss: 0.409508, acc: 62.50%, op_acc: 44.53%] [G loss: 0.991097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34941[D loss: 0.471046, acc: 58.59%, op_acc: 34.38%] [G loss: 0.832246]\n",
      "epoch:44 step:34942[D loss: 0.414182, acc: 60.16%, op_acc: 39.84%] [G loss: 0.990313]\n",
      "epoch:44 step:34943[D loss: 0.369574, acc: 69.53%, op_acc: 42.19%] [G loss: 0.985669]\n",
      "epoch:44 step:34944[D loss: 0.415721, acc: 62.50%, op_acc: 40.62%] [G loss: 0.909781]\n",
      "epoch:44 step:34945[D loss: 0.432323, acc: 54.69%, op_acc: 37.50%] [G loss: 0.956459]\n",
      "epoch:44 step:34946[D loss: 0.441571, acc: 56.25%, op_acc: 42.19%] [G loss: 0.806769]\n",
      "epoch:44 step:34947[D loss: 0.372808, acc: 71.88%, op_acc: 41.41%] [G loss: 0.838515]\n",
      "epoch:44 step:34948[D loss: 0.425478, acc: 62.50%, op_acc: 40.62%] [G loss: 0.980006]\n",
      "epoch:44 step:34949[D loss: 0.398952, acc: 59.38%, op_acc: 40.62%] [G loss: 0.975545]\n",
      "epoch:44 step:34950[D loss: 0.432777, acc: 55.47%, op_acc: 41.41%] [G loss: 0.788312]\n",
      "##############\n",
      "[0.85317746 0.85575186 0.82228023 0.80794183 0.78774017 0.8351885\n",
      " 0.89725731 0.84231324 0.78189557 0.84027814]\n",
      "##########\n",
      "epoch:44 step:34951[D loss: 0.381862, acc: 70.31%, op_acc: 39.84%] [G loss: 0.827927]\n",
      "epoch:44 step:34952[D loss: 0.398568, acc: 60.94%, op_acc: 41.41%] [G loss: 0.991338]\n",
      "epoch:44 step:34953[D loss: 0.382915, acc: 70.31%, op_acc: 38.28%] [G loss: 0.861358]\n",
      "epoch:44 step:34954[D loss: 0.378312, acc: 69.53%, op_acc: 45.31%] [G loss: 0.854322]\n",
      "epoch:44 step:34955[D loss: 0.418311, acc: 62.50%, op_acc: 40.62%] [G loss: 0.836083]\n",
      "epoch:44 step:34956[D loss: 0.420655, acc: 62.50%, op_acc: 42.97%] [G loss: 0.960077]\n",
      "epoch:44 step:34957[D loss: 0.437800, acc: 54.69%, op_acc: 37.50%] [G loss: 0.907601]\n",
      "epoch:44 step:34958[D loss: 0.399223, acc: 67.97%, op_acc: 37.50%] [G loss: 1.023013]\n",
      "epoch:44 step:34959[D loss: 0.369385, acc: 77.34%, op_acc: 39.06%] [G loss: 0.840664]\n",
      "epoch:44 step:34960[D loss: 0.416583, acc: 58.59%, op_acc: 39.84%] [G loss: 1.016849]\n",
      "epoch:44 step:34961[D loss: 0.384184, acc: 60.16%, op_acc: 45.31%] [G loss: 0.924169]\n",
      "epoch:44 step:34962[D loss: 0.415232, acc: 54.69%, op_acc: 42.97%] [G loss: 0.860682]\n",
      "epoch:44 step:34963[D loss: 0.409046, acc: 64.84%, op_acc: 40.62%] [G loss: 0.881877]\n",
      "epoch:44 step:34964[D loss: 0.373768, acc: 69.53%, op_acc: 45.31%] [G loss: 0.924933]\n",
      "epoch:44 step:34965[D loss: 0.420740, acc: 58.59%, op_acc: 42.97%] [G loss: 0.862926]\n",
      "epoch:44 step:34966[D loss: 0.379604, acc: 65.62%, op_acc: 43.75%] [G loss: 0.825284]\n",
      "epoch:44 step:34967[D loss: 0.400204, acc: 63.28%, op_acc: 47.66%] [G loss: 0.922758]\n",
      "epoch:44 step:34968[D loss: 0.397181, acc: 66.41%, op_acc: 44.53%] [G loss: 0.972930]\n",
      "epoch:44 step:34969[D loss: 0.378510, acc: 67.19%, op_acc: 40.62%] [G loss: 0.895927]\n",
      "epoch:44 step:34970[D loss: 0.430163, acc: 56.25%, op_acc: 46.09%] [G loss: 0.883250]\n",
      "epoch:44 step:34971[D loss: 0.381732, acc: 68.75%, op_acc: 45.31%] [G loss: 1.020360]\n",
      "epoch:44 step:34972[D loss: 0.356559, acc: 72.66%, op_acc: 53.91%] [G loss: 0.929587]\n",
      "epoch:44 step:34973[D loss: 0.398938, acc: 59.38%, op_acc: 43.75%] [G loss: 0.823524]\n",
      "epoch:44 step:34974[D loss: 0.388268, acc: 66.41%, op_acc: 48.44%] [G loss: 0.942380]\n",
      "epoch:44 step:34975[D loss: 0.411533, acc: 67.19%, op_acc: 44.53%] [G loss: 0.951696]\n",
      "epoch:44 step:34976[D loss: 0.377661, acc: 70.31%, op_acc: 50.78%] [G loss: 0.884027]\n",
      "epoch:44 step:34977[D loss: 0.420517, acc: 59.38%, op_acc: 46.09%] [G loss: 0.865780]\n",
      "epoch:44 step:34978[D loss: 0.394748, acc: 64.06%, op_acc: 45.31%] [G loss: 1.029620]\n",
      "epoch:44 step:34979[D loss: 0.377070, acc: 69.53%, op_acc: 44.53%] [G loss: 0.870471]\n",
      "epoch:44 step:34980[D loss: 0.392508, acc: 67.97%, op_acc: 42.19%] [G loss: 0.905579]\n",
      "epoch:44 step:34981[D loss: 0.445780, acc: 55.47%, op_acc: 42.97%] [G loss: 0.856828]\n",
      "epoch:44 step:34982[D loss: 0.400221, acc: 59.38%, op_acc: 44.53%] [G loss: 0.752988]\n",
      "epoch:44 step:34983[D loss: 0.369895, acc: 76.56%, op_acc: 41.41%] [G loss: 0.935131]\n",
      "epoch:44 step:34984[D loss: 0.459782, acc: 57.03%, op_acc: 38.28%] [G loss: 0.922517]\n",
      "epoch:44 step:34985[D loss: 0.417520, acc: 57.03%, op_acc: 43.75%] [G loss: 0.818929]\n",
      "epoch:44 step:34986[D loss: 0.432916, acc: 62.50%, op_acc: 42.97%] [G loss: 0.934219]\n",
      "epoch:44 step:34987[D loss: 0.403928, acc: 65.62%, op_acc: 43.75%] [G loss: 0.886127]\n",
      "epoch:44 step:34988[D loss: 0.419998, acc: 56.25%, op_acc: 48.44%] [G loss: 0.934728]\n",
      "epoch:44 step:34989[D loss: 0.407103, acc: 65.62%, op_acc: 42.97%] [G loss: 0.940635]\n",
      "epoch:44 step:34990[D loss: 0.401223, acc: 62.50%, op_acc: 41.41%] [G loss: 0.892072]\n",
      "epoch:44 step:34991[D loss: 0.428320, acc: 58.59%, op_acc: 39.84%] [G loss: 0.901235]\n",
      "epoch:44 step:34992[D loss: 0.403967, acc: 64.06%, op_acc: 42.19%] [G loss: 0.837728]\n",
      "epoch:44 step:34993[D loss: 0.428332, acc: 60.16%, op_acc: 41.41%] [G loss: 1.048950]\n",
      "epoch:44 step:34994[D loss: 0.360124, acc: 75.00%, op_acc: 45.31%] [G loss: 0.966702]\n",
      "epoch:44 step:34995[D loss: 0.439821, acc: 56.25%, op_acc: 39.06%] [G loss: 0.810013]\n",
      "epoch:44 step:34996[D loss: 0.431888, acc: 55.47%, op_acc: 39.84%] [G loss: 0.780976]\n",
      "epoch:44 step:34997[D loss: 0.396866, acc: 67.19%, op_acc: 45.31%] [G loss: 0.891130]\n",
      "epoch:44 step:34998[D loss: 0.399006, acc: 63.28%, op_acc: 45.31%] [G loss: 1.050928]\n",
      "epoch:44 step:34999[D loss: 0.413035, acc: 66.41%, op_acc: 39.84%] [G loss: 0.901970]\n",
      "epoch:44 step:35000[D loss: 0.393662, acc: 67.19%, op_acc: 46.09%] [G loss: 0.892197]\n",
      "##############\n",
      "[0.87104291 0.85149068 0.79120102 0.82461588 0.80639532 0.84503367\n",
      " 0.87975032 0.83023879 0.80129176 0.83489811]\n",
      "##########\n",
      "epoch:44 step:35001[D loss: 0.401116, acc: 60.94%, op_acc: 42.97%] [G loss: 1.000790]\n",
      "epoch:44 step:35002[D loss: 0.361584, acc: 73.44%, op_acc: 42.19%] [G loss: 0.883804]\n",
      "epoch:44 step:35003[D loss: 0.416520, acc: 62.50%, op_acc: 38.28%] [G loss: 0.866896]\n",
      "epoch:44 step:35004[D loss: 0.385288, acc: 67.19%, op_acc: 43.75%] [G loss: 0.915175]\n",
      "epoch:44 step:35005[D loss: 0.403898, acc: 61.72%, op_acc: 42.19%] [G loss: 0.844096]\n",
      "epoch:44 step:35006[D loss: 0.397174, acc: 66.41%, op_acc: 40.62%] [G loss: 0.800377]\n",
      "epoch:44 step:35007[D loss: 0.392320, acc: 67.97%, op_acc: 39.06%] [G loss: 0.936452]\n",
      "epoch:44 step:35008[D loss: 0.369274, acc: 63.28%, op_acc: 50.00%] [G loss: 0.915418]\n",
      "epoch:44 step:35009[D loss: 0.390672, acc: 68.75%, op_acc: 39.84%] [G loss: 0.921500]\n",
      "epoch:44 step:35010[D loss: 0.400429, acc: 67.97%, op_acc: 40.62%] [G loss: 1.085476]\n",
      "epoch:44 step:35011[D loss: 0.359843, acc: 74.22%, op_acc: 47.66%] [G loss: 1.051216]\n",
      "epoch:44 step:35012[D loss: 0.411659, acc: 60.16%, op_acc: 40.62%] [G loss: 0.943730]\n",
      "epoch:44 step:35013[D loss: 0.434436, acc: 60.94%, op_acc: 42.97%] [G loss: 0.966182]\n",
      "epoch:44 step:35014[D loss: 0.426843, acc: 57.03%, op_acc: 37.50%] [G loss: 0.943546]\n",
      "epoch:44 step:35015[D loss: 0.406514, acc: 62.50%, op_acc: 44.53%] [G loss: 0.931742]\n",
      "epoch:44 step:35016[D loss: 0.421905, acc: 60.16%, op_acc: 42.97%] [G loss: 0.951484]\n",
      "epoch:44 step:35017[D loss: 0.358971, acc: 75.00%, op_acc: 46.88%] [G loss: 1.025975]\n",
      "epoch:44 step:35018[D loss: 0.401459, acc: 60.16%, op_acc: 50.00%] [G loss: 1.002994]\n",
      "epoch:44 step:35019[D loss: 0.391598, acc: 65.62%, op_acc: 46.88%] [G loss: 1.081299]\n",
      "epoch:44 step:35020[D loss: 0.361789, acc: 71.09%, op_acc: 46.88%] [G loss: 1.142817]\n",
      "epoch:44 step:35021[D loss: 0.389867, acc: 57.81%, op_acc: 45.31%] [G loss: 1.087438]\n",
      "epoch:44 step:35022[D loss: 0.385298, acc: 71.88%, op_acc: 39.84%] [G loss: 1.060145]\n",
      "epoch:44 step:35023[D loss: 0.361515, acc: 78.12%, op_acc: 51.56%] [G loss: 1.069987]\n",
      "epoch:44 step:35024[D loss: 0.349016, acc: 72.66%, op_acc: 49.22%] [G loss: 1.120969]\n",
      "epoch:44 step:35025[D loss: 0.336411, acc: 71.88%, op_acc: 46.09%] [G loss: 1.096785]\n",
      "epoch:44 step:35026[D loss: 0.349213, acc: 67.19%, op_acc: 52.34%] [G loss: 1.101235]\n",
      "epoch:44 step:35027[D loss: 0.362253, acc: 65.62%, op_acc: 45.31%] [G loss: 1.003246]\n",
      "epoch:44 step:35028[D loss: 0.346893, acc: 71.88%, op_acc: 48.44%] [G loss: 0.814925]\n",
      "epoch:44 step:35029[D loss: 0.378123, acc: 70.31%, op_acc: 46.09%] [G loss: 0.994363]\n",
      "epoch:44 step:35030[D loss: 0.375255, acc: 70.31%, op_acc: 37.50%] [G loss: 0.944556]\n",
      "epoch:44 step:35031[D loss: 0.356181, acc: 70.31%, op_acc: 48.44%] [G loss: 0.723884]\n",
      "epoch:44 step:35032[D loss: 0.456838, acc: 50.78%, op_acc: 40.62%] [G loss: 0.776701]\n",
      "epoch:44 step:35033[D loss: 0.439841, acc: 61.72%, op_acc: 35.94%] [G loss: 1.123321]\n",
      "epoch:44 step:35034[D loss: 0.429747, acc: 57.03%, op_acc: 39.84%] [G loss: 0.956202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:35035[D loss: 0.418237, acc: 60.94%, op_acc: 43.75%] [G loss: 0.918837]\n",
      "epoch:44 step:35036[D loss: 0.385052, acc: 72.66%, op_acc: 44.53%] [G loss: 1.087476]\n",
      "epoch:44 step:35037[D loss: 0.424545, acc: 67.19%, op_acc: 36.72%] [G loss: 1.011783]\n",
      "epoch:44 step:35038[D loss: 0.390731, acc: 62.50%, op_acc: 46.88%] [G loss: 0.914546]\n",
      "epoch:44 step:35039[D loss: 0.412447, acc: 60.94%, op_acc: 41.41%] [G loss: 1.123489]\n",
      "epoch:44 step:35040[D loss: 0.421733, acc: 59.38%, op_acc: 37.50%] [G loss: 1.052313]\n",
      "epoch:44 step:35041[D loss: 0.428558, acc: 58.59%, op_acc: 35.16%] [G loss: 0.666684]\n",
      "epoch:44 step:35042[D loss: 0.398112, acc: 61.72%, op_acc: 40.62%] [G loss: 1.098798]\n",
      "epoch:44 step:35043[D loss: 0.400904, acc: 64.84%, op_acc: 45.31%] [G loss: 1.055885]\n",
      "epoch:44 step:35044[D loss: 0.419034, acc: 61.72%, op_acc: 44.53%] [G loss: 1.084435]\n",
      "epoch:44 step:35045[D loss: 0.417713, acc: 65.62%, op_acc: 41.41%] [G loss: 0.935965]\n",
      "epoch:44 step:35046[D loss: 0.358705, acc: 63.28%, op_acc: 48.44%] [G loss: 1.060535]\n",
      "epoch:44 step:35047[D loss: 0.419991, acc: 60.16%, op_acc: 48.44%] [G loss: 1.024305]\n",
      "epoch:44 step:35048[D loss: 0.435472, acc: 53.12%, op_acc: 39.84%] [G loss: 0.803281]\n",
      "epoch:44 step:35049[D loss: 0.430825, acc: 54.69%, op_acc: 44.53%] [G loss: 1.009445]\n",
      "epoch:44 step:35050[D loss: 0.420431, acc: 62.50%, op_acc: 48.44%] [G loss: 0.903306]\n",
      "##############\n",
      "[0.87084597 0.85516975 0.81387786 0.78926796 0.7728147  0.82673581\n",
      " 0.88958362 0.80097623 0.82221058 0.83645647]\n",
      "##########\n",
      "epoch:44 step:35051[D loss: 0.410615, acc: 61.72%, op_acc: 47.66%] [G loss: 0.954761]\n",
      "epoch:44 step:35052[D loss: 0.391286, acc: 64.84%, op_acc: 45.31%] [G loss: 1.094921]\n",
      "epoch:44 step:35053[D loss: 0.442956, acc: 54.69%, op_acc: 43.75%] [G loss: 1.124578]\n",
      "epoch:44 step:35054[D loss: 0.424786, acc: 62.50%, op_acc: 42.19%] [G loss: 1.019922]\n",
      "epoch:44 step:35055[D loss: 0.447345, acc: 57.03%, op_acc: 43.75%] [G loss: 0.840411]\n",
      "epoch:44 step:35056[D loss: 0.425152, acc: 60.16%, op_acc: 39.06%] [G loss: 0.901803]\n",
      "epoch:44 step:35057[D loss: 0.388358, acc: 66.41%, op_acc: 42.97%] [G loss: 0.923939]\n",
      "epoch:44 step:35058[D loss: 0.396621, acc: 64.06%, op_acc: 44.53%] [G loss: 1.090182]\n",
      "epoch:44 step:35059[D loss: 0.422433, acc: 60.16%, op_acc: 44.53%] [G loss: 1.042456]\n",
      "epoch:44 step:35060[D loss: 0.473155, acc: 50.78%, op_acc: 34.38%] [G loss: 1.010547]\n",
      "epoch:44 step:35061[D loss: 0.394363, acc: 62.50%, op_acc: 48.44%] [G loss: 0.921329]\n",
      "epoch:44 step:35062[D loss: 0.422708, acc: 58.59%, op_acc: 39.84%] [G loss: 0.814924]\n",
      "epoch:44 step:35063[D loss: 0.444210, acc: 57.81%, op_acc: 42.19%] [G loss: 0.954204]\n",
      "epoch:44 step:35064[D loss: 0.380539, acc: 67.97%, op_acc: 49.22%] [G loss: 0.949113]\n",
      "epoch:44 step:35065[D loss: 0.445326, acc: 52.34%, op_acc: 39.84%] [G loss: 0.864063]\n",
      "epoch:44 step:35066[D loss: 0.406979, acc: 59.38%, op_acc: 42.97%] [G loss: 0.989432]\n",
      "epoch:44 step:35067[D loss: 0.455304, acc: 47.66%, op_acc: 35.16%] [G loss: 0.864684]\n",
      "epoch:44 step:35068[D loss: 0.382353, acc: 63.28%, op_acc: 45.31%] [G loss: 0.897386]\n",
      "epoch:44 step:35069[D loss: 0.456444, acc: 54.69%, op_acc: 38.28%] [G loss: 0.949612]\n",
      "epoch:44 step:35070[D loss: 0.408741, acc: 66.41%, op_acc: 38.28%] [G loss: 0.815390]\n",
      "epoch:44 step:35071[D loss: 0.442417, acc: 64.06%, op_acc: 36.72%] [G loss: 0.974407]\n",
      "epoch:44 step:35072[D loss: 0.381495, acc: 67.97%, op_acc: 45.31%] [G loss: 0.988606]\n",
      "epoch:44 step:35073[D loss: 0.397391, acc: 64.84%, op_acc: 42.97%] [G loss: 0.963069]\n",
      "epoch:44 step:35074[D loss: 0.372273, acc: 69.53%, op_acc: 46.88%] [G loss: 1.055328]\n",
      "epoch:44 step:35075[D loss: 0.425855, acc: 58.59%, op_acc: 42.97%] [G loss: 0.822611]\n",
      "epoch:44 step:35076[D loss: 0.364854, acc: 68.75%, op_acc: 42.97%] [G loss: 0.963553]\n",
      "epoch:44 step:35077[D loss: 0.370740, acc: 62.50%, op_acc: 51.56%] [G loss: 0.851366]\n",
      "epoch:44 step:35078[D loss: 0.392000, acc: 73.44%, op_acc: 41.41%] [G loss: 0.956823]\n",
      "epoch:44 step:35079[D loss: 0.373916, acc: 67.97%, op_acc: 39.84%] [G loss: 0.800037]\n",
      "epoch:44 step:35080[D loss: 0.419716, acc: 55.47%, op_acc: 47.66%] [G loss: 0.898835]\n",
      "epoch:44 step:35081[D loss: 0.416437, acc: 55.47%, op_acc: 42.19%] [G loss: 0.794930]\n",
      "epoch:44 step:35082[D loss: 0.388014, acc: 67.19%, op_acc: 44.53%] [G loss: 0.989133]\n",
      "epoch:44 step:35083[D loss: 0.422628, acc: 61.72%, op_acc: 47.66%] [G loss: 0.880963]\n",
      "epoch:44 step:35084[D loss: 0.418569, acc: 57.81%, op_acc: 41.41%] [G loss: 0.992193]\n",
      "epoch:44 step:35085[D loss: 0.409937, acc: 57.81%, op_acc: 44.53%] [G loss: 0.888163]\n",
      "epoch:44 step:35086[D loss: 0.387738, acc: 67.97%, op_acc: 40.62%] [G loss: 0.718631]\n",
      "epoch:44 step:35087[D loss: 0.384108, acc: 65.62%, op_acc: 46.88%] [G loss: 0.723945]\n",
      "epoch:44 step:35088[D loss: 0.423536, acc: 65.62%, op_acc: 37.50%] [G loss: 0.974678]\n",
      "epoch:44 step:35089[D loss: 0.395126, acc: 69.53%, op_acc: 42.19%] [G loss: 0.813445]\n",
      "epoch:44 step:35090[D loss: 0.422596, acc: 61.72%, op_acc: 42.97%] [G loss: 0.788616]\n",
      "epoch:44 step:35091[D loss: 0.407701, acc: 65.62%, op_acc: 37.50%] [G loss: 0.743663]\n",
      "epoch:44 step:35092[D loss: 0.408563, acc: 61.72%, op_acc: 43.75%] [G loss: 0.853711]\n",
      "epoch:44 step:35093[D loss: 0.426480, acc: 57.81%, op_acc: 46.09%] [G loss: 0.786776]\n",
      "epoch:44 step:35094[D loss: 0.397662, acc: 61.72%, op_acc: 44.53%] [G loss: 0.931283]\n",
      "epoch:44 step:35095[D loss: 0.371453, acc: 71.09%, op_acc: 39.84%] [G loss: 1.085843]\n",
      "epoch:44 step:35096[D loss: 0.426777, acc: 60.94%, op_acc: 39.84%] [G loss: 0.940565]\n",
      "epoch:44 step:35097[D loss: 0.363891, acc: 75.00%, op_acc: 44.53%] [G loss: 1.066509]\n",
      "epoch:44 step:35098[D loss: 0.385000, acc: 71.09%, op_acc: 41.41%] [G loss: 1.000447]\n",
      "epoch:44 step:35099[D loss: 0.419736, acc: 62.50%, op_acc: 41.41%] [G loss: 1.019563]\n",
      "epoch:44 step:35100[D loss: 0.413791, acc: 61.72%, op_acc: 39.84%] [G loss: 0.885295]\n",
      "##############\n",
      "[0.8566283  0.84791328 0.80456302 0.80065622 0.8072156  0.83777954\n",
      " 0.88179993 0.82901079 0.80122799 0.83444303]\n",
      "##########\n",
      "epoch:44 step:35101[D loss: 0.405426, acc: 61.72%, op_acc: 40.62%] [G loss: 0.903940]\n",
      "epoch:44 step:35102[D loss: 0.411582, acc: 60.94%, op_acc: 43.75%] [G loss: 0.937756]\n",
      "epoch:44 step:35103[D loss: 0.394950, acc: 62.50%, op_acc: 45.31%] [G loss: 0.891059]\n",
      "epoch:44 step:35104[D loss: 0.400220, acc: 63.28%, op_acc: 45.31%] [G loss: 0.944989]\n",
      "epoch:44 step:35105[D loss: 0.410691, acc: 60.16%, op_acc: 42.97%] [G loss: 0.997164]\n",
      "epoch:44 step:35106[D loss: 0.402762, acc: 63.28%, op_acc: 41.41%] [G loss: 0.985981]\n",
      "epoch:44 step:35107[D loss: 0.399437, acc: 64.84%, op_acc: 46.09%] [G loss: 0.854550]\n",
      "epoch:44 step:35108[D loss: 0.353137, acc: 64.84%, op_acc: 53.91%] [G loss: 0.919926]\n",
      "epoch:44 step:35109[D loss: 0.414722, acc: 59.38%, op_acc: 42.19%] [G loss: 0.899393]\n",
      "epoch:44 step:35110[D loss: 0.398753, acc: 67.19%, op_acc: 42.19%] [G loss: 0.920141]\n",
      "epoch:44 step:35111[D loss: 0.420209, acc: 64.06%, op_acc: 39.84%] [G loss: 0.871588]\n",
      "epoch:44 step:35112[D loss: 0.429276, acc: 63.28%, op_acc: 38.28%] [G loss: 0.953755]\n",
      "epoch:44 step:35113[D loss: 0.406965, acc: 70.31%, op_acc: 44.53%] [G loss: 0.964893]\n",
      "epoch:44 step:35114[D loss: 0.424184, acc: 58.59%, op_acc: 43.75%] [G loss: 0.899469]\n",
      "epoch:44 step:35115[D loss: 0.427498, acc: 64.84%, op_acc: 35.94%] [G loss: 0.907153]\n",
      "epoch:44 step:35116[D loss: 0.418897, acc: 64.06%, op_acc: 38.28%] [G loss: 0.833060]\n",
      "epoch:44 step:35117[D loss: 0.379651, acc: 60.94%, op_acc: 46.88%] [G loss: 0.897834]\n",
      "epoch:44 step:35118[D loss: 0.356137, acc: 75.78%, op_acc: 50.00%] [G loss: 0.899973]\n",
      "epoch:44 step:35119[D loss: 0.384068, acc: 63.28%, op_acc: 46.88%] [G loss: 0.858457]\n",
      "epoch:44 step:35120[D loss: 0.392596, acc: 66.41%, op_acc: 41.41%] [G loss: 0.926253]\n",
      "epoch:44 step:35121[D loss: 0.344179, acc: 67.97%, op_acc: 50.78%] [G loss: 1.033501]\n",
      "epoch:44 step:35122[D loss: 0.364054, acc: 70.31%, op_acc: 47.66%] [G loss: 0.898625]\n",
      "epoch:44 step:35123[D loss: 0.434135, acc: 57.81%, op_acc: 42.97%] [G loss: 0.951235]\n",
      "epoch:44 step:35124[D loss: 0.388534, acc: 64.06%, op_acc: 42.97%] [G loss: 1.000245]\n",
      "epoch:44 step:35125[D loss: 0.385559, acc: 64.84%, op_acc: 41.41%] [G loss: 1.056639]\n",
      "epoch:44 step:35126[D loss: 0.421673, acc: 57.81%, op_acc: 40.62%] [G loss: 1.015794]\n",
      "epoch:44 step:35127[D loss: 0.429087, acc: 60.94%, op_acc: 42.19%] [G loss: 0.926068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:35128[D loss: 0.388821, acc: 60.16%, op_acc: 43.75%] [G loss: 0.944482]\n",
      "epoch:44 step:35129[D loss: 0.375704, acc: 69.53%, op_acc: 42.19%] [G loss: 0.954989]\n",
      "epoch:44 step:35130[D loss: 0.423634, acc: 53.12%, op_acc: 40.62%] [G loss: 0.871442]\n",
      "epoch:44 step:35131[D loss: 0.349466, acc: 75.78%, op_acc: 46.88%] [G loss: 0.865592]\n",
      "epoch:44 step:35132[D loss: 0.417939, acc: 60.16%, op_acc: 41.41%] [G loss: 0.840859]\n",
      "epoch:44 step:35133[D loss: 0.391248, acc: 61.72%, op_acc: 45.31%] [G loss: 0.862363]\n",
      "epoch:44 step:35134[D loss: 0.405393, acc: 59.38%, op_acc: 48.44%] [G loss: 0.948773]\n",
      "epoch:44 step:35135[D loss: 0.468482, acc: 54.69%, op_acc: 38.28%] [G loss: 0.829249]\n",
      "epoch:44 step:35136[D loss: 0.418357, acc: 62.50%, op_acc: 37.50%] [G loss: 0.967104]\n",
      "epoch:44 step:35137[D loss: 0.427759, acc: 60.94%, op_acc: 41.41%] [G loss: 0.918859]\n",
      "epoch:44 step:35138[D loss: 0.353757, acc: 76.56%, op_acc: 48.44%] [G loss: 1.063869]\n",
      "epoch:44 step:35139[D loss: 0.377235, acc: 71.09%, op_acc: 39.06%] [G loss: 1.049914]\n",
      "epoch:44 step:35140[D loss: 0.371662, acc: 67.97%, op_acc: 43.75%] [G loss: 0.840465]\n",
      "epoch:44 step:35141[D loss: 0.411200, acc: 65.62%, op_acc: 43.75%] [G loss: 1.027390]\n",
      "epoch:44 step:35142[D loss: 0.400759, acc: 59.38%, op_acc: 46.88%] [G loss: 0.884431]\n",
      "epoch:44 step:35143[D loss: 0.414409, acc: 57.81%, op_acc: 40.62%] [G loss: 0.918458]\n",
      "epoch:44 step:35144[D loss: 0.368648, acc: 71.09%, op_acc: 42.19%] [G loss: 0.915347]\n",
      "epoch:44 step:35145[D loss: 0.447227, acc: 57.81%, op_acc: 37.50%] [G loss: 0.922993]\n",
      "epoch:45 step:35146[D loss: 0.374990, acc: 71.09%, op_acc: 49.22%] [G loss: 0.936044]\n",
      "epoch:45 step:35147[D loss: 0.364360, acc: 69.53%, op_acc: 50.00%] [G loss: 1.084250]\n",
      "epoch:45 step:35148[D loss: 0.432100, acc: 53.12%, op_acc: 40.62%] [G loss: 0.898445]\n",
      "epoch:45 step:35149[D loss: 0.395953, acc: 60.16%, op_acc: 50.00%] [G loss: 0.903308]\n",
      "epoch:45 step:35150[D loss: 0.396491, acc: 61.72%, op_acc: 49.22%] [G loss: 0.852804]\n",
      "##############\n",
      "[0.84957601 0.85061182 0.81336238 0.80328705 0.81448559 0.83543197\n",
      " 0.88922823 0.81575917 0.80438942 0.8370168 ]\n",
      "##########\n",
      "epoch:45 step:35151[D loss: 0.429972, acc: 57.03%, op_acc: 46.09%] [G loss: 0.893675]\n",
      "epoch:45 step:35152[D loss: 0.413432, acc: 58.59%, op_acc: 40.62%] [G loss: 0.874220]\n",
      "epoch:45 step:35153[D loss: 0.410570, acc: 60.16%, op_acc: 46.09%] [G loss: 0.890628]\n",
      "epoch:45 step:35154[D loss: 0.399044, acc: 57.03%, op_acc: 46.88%] [G loss: 0.981626]\n",
      "epoch:45 step:35155[D loss: 0.396392, acc: 67.19%, op_acc: 37.50%] [G loss: 1.060504]\n",
      "epoch:45 step:35156[D loss: 0.435188, acc: 57.03%, op_acc: 41.41%] [G loss: 0.877706]\n",
      "epoch:45 step:35157[D loss: 0.380388, acc: 67.97%, op_acc: 43.75%] [G loss: 0.904213]\n",
      "epoch:45 step:35158[D loss: 0.398301, acc: 64.84%, op_acc: 42.97%] [G loss: 0.923810]\n",
      "epoch:45 step:35159[D loss: 0.411628, acc: 63.28%, op_acc: 42.97%] [G loss: 0.970786]\n",
      "epoch:45 step:35160[D loss: 0.404694, acc: 66.41%, op_acc: 46.09%] [G loss: 0.938213]\n",
      "epoch:45 step:35161[D loss: 0.371366, acc: 67.97%, op_acc: 45.31%] [G loss: 0.928263]\n",
      "epoch:45 step:35162[D loss: 0.383406, acc: 61.72%, op_acc: 51.56%] [G loss: 0.928065]\n",
      "epoch:45 step:35163[D loss: 0.385014, acc: 64.06%, op_acc: 42.19%] [G loss: 0.910025]\n",
      "epoch:45 step:35164[D loss: 0.356056, acc: 72.66%, op_acc: 46.88%] [G loss: 0.811347]\n",
      "epoch:45 step:35165[D loss: 0.404776, acc: 61.72%, op_acc: 40.62%] [G loss: 0.900213]\n",
      "epoch:45 step:35166[D loss: 0.392720, acc: 61.72%, op_acc: 46.09%] [G loss: 1.066585]\n",
      "epoch:45 step:35167[D loss: 0.418229, acc: 63.28%, op_acc: 46.09%] [G loss: 0.917997]\n",
      "epoch:45 step:35168[D loss: 0.392479, acc: 62.50%, op_acc: 45.31%] [G loss: 0.980290]\n",
      "epoch:45 step:35169[D loss: 0.382835, acc: 71.88%, op_acc: 42.19%] [G loss: 1.040062]\n",
      "epoch:45 step:35170[D loss: 0.430032, acc: 60.94%, op_acc: 39.84%] [G loss: 0.989070]\n",
      "epoch:45 step:35171[D loss: 0.438127, acc: 55.47%, op_acc: 45.31%] [G loss: 0.889973]\n",
      "epoch:45 step:35172[D loss: 0.426641, acc: 59.38%, op_acc: 40.62%] [G loss: 0.824592]\n",
      "epoch:45 step:35173[D loss: 0.435310, acc: 54.69%, op_acc: 46.88%] [G loss: 0.954352]\n",
      "epoch:45 step:35174[D loss: 0.393392, acc: 61.72%, op_acc: 46.88%] [G loss: 0.912626]\n",
      "epoch:45 step:35175[D loss: 0.377408, acc: 67.19%, op_acc: 48.44%] [G loss: 0.870332]\n",
      "epoch:45 step:35176[D loss: 0.390407, acc: 65.62%, op_acc: 43.75%] [G loss: 0.840815]\n",
      "epoch:45 step:35177[D loss: 0.374928, acc: 72.66%, op_acc: 42.97%] [G loss: 0.937830]\n",
      "epoch:45 step:35178[D loss: 0.367334, acc: 69.53%, op_acc: 47.66%] [G loss: 0.949232]\n",
      "epoch:45 step:35179[D loss: 0.372154, acc: 64.06%, op_acc: 46.09%] [G loss: 0.945726]\n",
      "epoch:45 step:35180[D loss: 0.408620, acc: 61.72%, op_acc: 39.84%] [G loss: 0.918739]\n",
      "epoch:45 step:35181[D loss: 0.406572, acc: 58.59%, op_acc: 46.09%] [G loss: 0.935109]\n",
      "epoch:45 step:35182[D loss: 0.385160, acc: 63.28%, op_acc: 45.31%] [G loss: 0.845101]\n",
      "epoch:45 step:35183[D loss: 0.370406, acc: 67.19%, op_acc: 48.44%] [G loss: 0.847399]\n",
      "epoch:45 step:35184[D loss: 0.404041, acc: 61.72%, op_acc: 43.75%] [G loss: 0.926081]\n",
      "epoch:45 step:35185[D loss: 0.396634, acc: 64.84%, op_acc: 45.31%] [G loss: 0.834045]\n",
      "epoch:45 step:35186[D loss: 0.340122, acc: 73.44%, op_acc: 48.44%] [G loss: 1.036767]\n",
      "epoch:45 step:35187[D loss: 0.406585, acc: 63.28%, op_acc: 45.31%] [G loss: 0.916604]\n",
      "epoch:45 step:35188[D loss: 0.413487, acc: 57.03%, op_acc: 47.66%] [G loss: 1.053212]\n",
      "epoch:45 step:35189[D loss: 0.393913, acc: 62.50%, op_acc: 46.88%] [G loss: 0.984287]\n",
      "epoch:45 step:35190[D loss: 0.395321, acc: 67.19%, op_acc: 43.75%] [G loss: 0.793734]\n",
      "epoch:45 step:35191[D loss: 0.373563, acc: 72.66%, op_acc: 43.75%] [G loss: 0.990960]\n",
      "epoch:45 step:35192[D loss: 0.444206, acc: 54.69%, op_acc: 32.81%] [G loss: 0.834578]\n",
      "epoch:45 step:35193[D loss: 0.407007, acc: 63.28%, op_acc: 32.03%] [G loss: 0.978174]\n",
      "epoch:45 step:35194[D loss: 0.373590, acc: 71.09%, op_acc: 42.97%] [G loss: 1.022758]\n",
      "epoch:45 step:35195[D loss: 0.426002, acc: 61.72%, op_acc: 40.62%] [G loss: 0.904029]\n",
      "epoch:45 step:35196[D loss: 0.391446, acc: 65.62%, op_acc: 41.41%] [G loss: 0.822901]\n",
      "epoch:45 step:35197[D loss: 0.417998, acc: 64.84%, op_acc: 42.19%] [G loss: 0.876887]\n",
      "epoch:45 step:35198[D loss: 0.426967, acc: 58.59%, op_acc: 37.50%] [G loss: 0.701740]\n",
      "epoch:45 step:35199[D loss: 0.419752, acc: 60.94%, op_acc: 43.75%] [G loss: 0.972160]\n",
      "epoch:45 step:35200[D loss: 0.350795, acc: 68.75%, op_acc: 55.47%] [G loss: 0.915748]\n",
      "##############\n",
      "[0.86422506 0.88368373 0.82493845 0.81567996 0.80257667 0.84022968\n",
      " 0.89421669 0.81118228 0.80474271 0.84070972]\n",
      "##########\n",
      "epoch:45 step:35201[D loss: 0.394489, acc: 64.06%, op_acc: 44.53%] [G loss: 0.941888]\n",
      "epoch:45 step:35202[D loss: 0.390408, acc: 64.84%, op_acc: 50.00%] [G loss: 0.803956]\n",
      "epoch:45 step:35203[D loss: 0.353190, acc: 70.31%, op_acc: 50.00%] [G loss: 0.880037]\n",
      "epoch:45 step:35204[D loss: 0.398702, acc: 60.94%, op_acc: 42.97%] [G loss: 0.968718]\n",
      "epoch:45 step:35205[D loss: 0.380669, acc: 70.31%, op_acc: 46.88%] [G loss: 0.871757]\n",
      "epoch:45 step:35206[D loss: 0.376211, acc: 67.97%, op_acc: 44.53%] [G loss: 0.868802]\n",
      "epoch:45 step:35207[D loss: 0.395731, acc: 64.06%, op_acc: 42.19%] [G loss: 0.870734]\n",
      "epoch:45 step:35208[D loss: 0.415607, acc: 58.59%, op_acc: 46.09%] [G loss: 0.944482]\n",
      "epoch:45 step:35209[D loss: 0.375727, acc: 64.84%, op_acc: 44.53%] [G loss: 0.893495]\n",
      "epoch:45 step:35210[D loss: 0.409440, acc: 68.75%, op_acc: 44.53%] [G loss: 0.969818]\n",
      "epoch:45 step:35211[D loss: 0.406218, acc: 63.28%, op_acc: 46.88%] [G loss: 0.966358]\n",
      "epoch:45 step:35212[D loss: 0.368615, acc: 68.75%, op_acc: 47.66%] [G loss: 0.820701]\n",
      "epoch:45 step:35213[D loss: 0.401049, acc: 57.03%, op_acc: 43.75%] [G loss: 1.034212]\n",
      "epoch:45 step:35214[D loss: 0.389496, acc: 62.50%, op_acc: 46.88%] [G loss: 0.830705]\n",
      "epoch:45 step:35215[D loss: 0.438371, acc: 50.00%, op_acc: 41.41%] [G loss: 0.839274]\n",
      "epoch:45 step:35216[D loss: 0.462833, acc: 55.47%, op_acc: 37.50%] [G loss: 0.735524]\n",
      "epoch:45 step:35217[D loss: 0.382520, acc: 68.75%, op_acc: 42.97%] [G loss: 0.889390]\n",
      "epoch:45 step:35218[D loss: 0.426458, acc: 59.38%, op_acc: 39.84%] [G loss: 0.900694]\n",
      "epoch:45 step:35219[D loss: 0.345690, acc: 69.53%, op_acc: 50.00%] [G loss: 0.896955]\n",
      "epoch:45 step:35220[D loss: 0.399626, acc: 60.94%, op_acc: 46.88%] [G loss: 0.869473]\n",
      "epoch:45 step:35221[D loss: 0.415464, acc: 61.72%, op_acc: 43.75%] [G loss: 1.017585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35222[D loss: 0.411128, acc: 65.62%, op_acc: 39.84%] [G loss: 0.829686]\n",
      "epoch:45 step:35223[D loss: 0.416018, acc: 63.28%, op_acc: 43.75%] [G loss: 1.030918]\n",
      "epoch:45 step:35224[D loss: 0.442713, acc: 52.34%, op_acc: 39.84%] [G loss: 1.033176]\n",
      "epoch:45 step:35225[D loss: 0.411632, acc: 64.06%, op_acc: 46.09%] [G loss: 0.911918]\n",
      "epoch:45 step:35226[D loss: 0.401969, acc: 64.06%, op_acc: 40.62%] [G loss: 0.856133]\n",
      "epoch:45 step:35227[D loss: 0.419112, acc: 59.38%, op_acc: 42.19%] [G loss: 0.912455]\n",
      "epoch:45 step:35228[D loss: 0.392558, acc: 60.16%, op_acc: 42.97%] [G loss: 0.849865]\n",
      "epoch:45 step:35229[D loss: 0.368189, acc: 66.41%, op_acc: 46.09%] [G loss: 0.903304]\n",
      "epoch:45 step:35230[D loss: 0.393889, acc: 64.84%, op_acc: 46.88%] [G loss: 0.991894]\n",
      "epoch:45 step:35231[D loss: 0.423946, acc: 57.03%, op_acc: 43.75%] [G loss: 0.888033]\n",
      "epoch:45 step:35232[D loss: 0.426038, acc: 61.72%, op_acc: 42.19%] [G loss: 0.933992]\n",
      "epoch:45 step:35233[D loss: 0.367931, acc: 69.53%, op_acc: 45.31%] [G loss: 1.014307]\n",
      "epoch:45 step:35234[D loss: 0.366895, acc: 71.88%, op_acc: 46.88%] [G loss: 0.901954]\n",
      "epoch:45 step:35235[D loss: 0.366152, acc: 68.75%, op_acc: 43.75%] [G loss: 0.875332]\n",
      "epoch:45 step:35236[D loss: 0.423451, acc: 55.47%, op_acc: 40.62%] [G loss: 0.786981]\n",
      "epoch:45 step:35237[D loss: 0.427299, acc: 57.03%, op_acc: 43.75%] [G loss: 0.901567]\n",
      "epoch:45 step:35238[D loss: 0.399128, acc: 59.38%, op_acc: 47.66%] [G loss: 1.004081]\n",
      "epoch:45 step:35239[D loss: 0.411322, acc: 64.84%, op_acc: 45.31%] [G loss: 1.010370]\n",
      "epoch:45 step:35240[D loss: 0.374579, acc: 73.44%, op_acc: 41.41%] [G loss: 0.975461]\n",
      "epoch:45 step:35241[D loss: 0.382524, acc: 73.44%, op_acc: 41.41%] [G loss: 1.186178]\n",
      "epoch:45 step:35242[D loss: 0.399372, acc: 61.72%, op_acc: 42.19%] [G loss: 1.018587]\n",
      "epoch:45 step:35243[D loss: 0.380763, acc: 66.41%, op_acc: 40.62%] [G loss: 0.986751]\n",
      "epoch:45 step:35244[D loss: 0.365796, acc: 71.88%, op_acc: 47.66%] [G loss: 0.848548]\n",
      "epoch:45 step:35245[D loss: 0.383568, acc: 62.50%, op_acc: 50.00%] [G loss: 1.081527]\n",
      "epoch:45 step:35246[D loss: 0.412027, acc: 60.94%, op_acc: 42.19%] [G loss: 1.060680]\n",
      "epoch:45 step:35247[D loss: 0.408073, acc: 60.94%, op_acc: 43.75%] [G loss: 0.977932]\n",
      "epoch:45 step:35248[D loss: 0.412740, acc: 60.94%, op_acc: 46.88%] [G loss: 1.004311]\n",
      "epoch:45 step:35249[D loss: 0.381215, acc: 66.41%, op_acc: 42.97%] [G loss: 1.041774]\n",
      "epoch:45 step:35250[D loss: 0.380616, acc: 74.22%, op_acc: 42.19%] [G loss: 0.894981]\n",
      "##############\n",
      "[0.85976085 0.86047855 0.80973093 0.80152414 0.78083317 0.81581124\n",
      " 0.89164322 0.82601371 0.82048196 0.85061011]\n",
      "##########\n",
      "epoch:45 step:35251[D loss: 0.370108, acc: 71.09%, op_acc: 45.31%] [G loss: 1.132160]\n",
      "epoch:45 step:35252[D loss: 0.393649, acc: 64.06%, op_acc: 43.75%] [G loss: 1.117505]\n",
      "epoch:45 step:35253[D loss: 0.358281, acc: 68.75%, op_acc: 53.91%] [G loss: 1.234227]\n",
      "epoch:45 step:35254[D loss: 0.326812, acc: 74.22%, op_acc: 53.12%] [G loss: 0.879380]\n",
      "epoch:45 step:35255[D loss: 0.360510, acc: 72.66%, op_acc: 50.78%] [G loss: 1.014921]\n",
      "epoch:45 step:35256[D loss: 0.375550, acc: 76.56%, op_acc: 46.88%] [G loss: 1.083396]\n",
      "epoch:45 step:35257[D loss: 0.357270, acc: 74.22%, op_acc: 50.00%] [G loss: 1.165564]\n",
      "epoch:45 step:35258[D loss: 0.367839, acc: 70.31%, op_acc: 46.09%] [G loss: 0.957925]\n",
      "epoch:45 step:35259[D loss: 0.346827, acc: 73.44%, op_acc: 49.22%] [G loss: 0.980182]\n",
      "epoch:45 step:35260[D loss: 0.387128, acc: 64.06%, op_acc: 44.53%] [G loss: 1.052206]\n",
      "epoch:45 step:35261[D loss: 0.418693, acc: 59.38%, op_acc: 42.19%] [G loss: 1.054272]\n",
      "epoch:45 step:35262[D loss: 0.409821, acc: 64.06%, op_acc: 40.62%] [G loss: 1.080833]\n",
      "epoch:45 step:35263[D loss: 0.367782, acc: 74.22%, op_acc: 41.41%] [G loss: 0.753229]\n",
      "epoch:45 step:35264[D loss: 0.385496, acc: 66.41%, op_acc: 46.88%] [G loss: 1.248823]\n",
      "epoch:45 step:35265[D loss: 0.378119, acc: 72.66%, op_acc: 39.84%] [G loss: 1.219533]\n",
      "epoch:45 step:35266[D loss: 0.397233, acc: 67.97%, op_acc: 40.62%] [G loss: 1.161301]\n",
      "epoch:45 step:35267[D loss: 0.408980, acc: 63.28%, op_acc: 48.44%] [G loss: 1.153501]\n",
      "epoch:45 step:35268[D loss: 0.379919, acc: 71.09%, op_acc: 40.62%] [G loss: 1.136069]\n",
      "epoch:45 step:35269[D loss: 0.384649, acc: 67.97%, op_acc: 49.22%] [G loss: 1.021861]\n",
      "epoch:45 step:35270[D loss: 0.402049, acc: 64.84%, op_acc: 44.53%] [G loss: 0.755084]\n",
      "epoch:45 step:35271[D loss: 0.449560, acc: 50.78%, op_acc: 43.75%] [G loss: 0.855949]\n",
      "epoch:45 step:35272[D loss: 0.413805, acc: 61.72%, op_acc: 43.75%] [G loss: 1.120020]\n",
      "epoch:45 step:35273[D loss: 0.408580, acc: 60.16%, op_acc: 44.53%] [G loss: 0.820194]\n",
      "epoch:45 step:35274[D loss: 0.452356, acc: 55.47%, op_acc: 39.06%] [G loss: 1.211789]\n",
      "epoch:45 step:35275[D loss: 0.389617, acc: 64.84%, op_acc: 44.53%] [G loss: 1.241098]\n",
      "epoch:45 step:35276[D loss: 0.405362, acc: 64.84%, op_acc: 42.97%] [G loss: 0.819118]\n",
      "epoch:45 step:35277[D loss: 0.385868, acc: 61.72%, op_acc: 50.00%] [G loss: 1.149870]\n",
      "epoch:45 step:35278[D loss: 0.413111, acc: 70.31%, op_acc: 42.19%] [G loss: 0.966242]\n",
      "epoch:45 step:35279[D loss: 0.391431, acc: 66.41%, op_acc: 43.75%] [G loss: 1.043541]\n",
      "epoch:45 step:35280[D loss: 0.427990, acc: 60.94%, op_acc: 38.28%] [G loss: 0.938739]\n",
      "epoch:45 step:35281[D loss: 0.364729, acc: 69.53%, op_acc: 52.34%] [G loss: 1.053961]\n",
      "epoch:45 step:35282[D loss: 0.422104, acc: 52.34%, op_acc: 41.41%] [G loss: 0.938320]\n",
      "epoch:45 step:35283[D loss: 0.418178, acc: 60.16%, op_acc: 40.62%] [G loss: 0.794471]\n",
      "epoch:45 step:35284[D loss: 0.404689, acc: 64.06%, op_acc: 41.41%] [G loss: 0.893890]\n",
      "epoch:45 step:35285[D loss: 0.463327, acc: 52.34%, op_acc: 41.41%] [G loss: 1.076078]\n",
      "epoch:45 step:35286[D loss: 0.410376, acc: 66.41%, op_acc: 38.28%] [G loss: 1.029038]\n",
      "epoch:45 step:35287[D loss: 0.445172, acc: 53.91%, op_acc: 43.75%] [G loss: 1.104001]\n",
      "epoch:45 step:35288[D loss: 0.403634, acc: 65.62%, op_acc: 47.66%] [G loss: 0.880803]\n",
      "epoch:45 step:35289[D loss: 0.417656, acc: 65.62%, op_acc: 42.19%] [G loss: 0.900945]\n",
      "epoch:45 step:35290[D loss: 0.392799, acc: 67.19%, op_acc: 39.06%] [G loss: 0.854823]\n",
      "epoch:45 step:35291[D loss: 0.394162, acc: 67.97%, op_acc: 40.62%] [G loss: 1.052700]\n",
      "epoch:45 step:35292[D loss: 0.367730, acc: 64.06%, op_acc: 45.31%] [G loss: 0.934355]\n",
      "epoch:45 step:35293[D loss: 0.401134, acc: 67.97%, op_acc: 42.19%] [G loss: 1.059395]\n",
      "epoch:45 step:35294[D loss: 0.358689, acc: 70.31%, op_acc: 46.09%] [G loss: 1.038889]\n",
      "epoch:45 step:35295[D loss: 0.373033, acc: 71.09%, op_acc: 50.78%] [G loss: 1.014669]\n",
      "epoch:45 step:35296[D loss: 0.391556, acc: 67.19%, op_acc: 46.88%] [G loss: 0.979788]\n",
      "epoch:45 step:35297[D loss: 0.367233, acc: 70.31%, op_acc: 45.31%] [G loss: 0.806004]\n",
      "epoch:45 step:35298[D loss: 0.396518, acc: 62.50%, op_acc: 44.53%] [G loss: 1.049106]\n",
      "epoch:45 step:35299[D loss: 0.437758, acc: 53.91%, op_acc: 40.62%] [G loss: 0.986326]\n",
      "epoch:45 step:35300[D loss: 0.430130, acc: 58.59%, op_acc: 34.38%] [G loss: 1.078337]\n",
      "##############\n",
      "[0.85390451 0.85450811 0.81196835 0.81508751 0.79518873 0.82675792\n",
      " 0.89352347 0.83479097 0.81118019 0.83485591]\n",
      "##########\n",
      "epoch:45 step:35301[D loss: 0.426589, acc: 61.72%, op_acc: 40.62%] [G loss: 0.997743]\n",
      "epoch:45 step:35302[D loss: 0.379173, acc: 66.41%, op_acc: 43.75%] [G loss: 0.868124]\n",
      "epoch:45 step:35303[D loss: 0.366890, acc: 71.88%, op_acc: 45.31%] [G loss: 1.058231]\n",
      "epoch:45 step:35304[D loss: 0.392048, acc: 64.06%, op_acc: 44.53%] [G loss: 0.912231]\n",
      "epoch:45 step:35305[D loss: 0.426685, acc: 62.50%, op_acc: 42.19%] [G loss: 0.997460]\n",
      "epoch:45 step:35306[D loss: 0.373944, acc: 67.19%, op_acc: 46.88%] [G loss: 0.937530]\n",
      "epoch:45 step:35307[D loss: 0.366093, acc: 68.75%, op_acc: 47.66%] [G loss: 1.162084]\n",
      "epoch:45 step:35308[D loss: 0.381990, acc: 71.09%, op_acc: 46.88%] [G loss: 1.028982]\n",
      "epoch:45 step:35309[D loss: 0.396600, acc: 70.31%, op_acc: 39.06%] [G loss: 0.783293]\n",
      "epoch:45 step:35310[D loss: 0.386070, acc: 65.62%, op_acc: 49.22%] [G loss: 0.924123]\n",
      "epoch:45 step:35311[D loss: 0.415194, acc: 64.84%, op_acc: 38.28%] [G loss: 0.806853]\n",
      "epoch:45 step:35312[D loss: 0.353166, acc: 71.09%, op_acc: 48.44%] [G loss: 1.124330]\n",
      "epoch:45 step:35313[D loss: 0.404777, acc: 59.38%, op_acc: 46.09%] [G loss: 0.886749]\n",
      "epoch:45 step:35314[D loss: 0.434904, acc: 56.25%, op_acc: 43.75%] [G loss: 0.803688]\n",
      "epoch:45 step:35315[D loss: 0.444734, acc: 55.47%, op_acc: 42.97%] [G loss: 0.915928]\n",
      "epoch:45 step:35316[D loss: 0.439458, acc: 56.25%, op_acc: 42.97%] [G loss: 1.034054]\n",
      "epoch:45 step:35317[D loss: 0.405369, acc: 58.59%, op_acc: 42.19%] [G loss: 0.940590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35318[D loss: 0.393694, acc: 64.06%, op_acc: 45.31%] [G loss: 0.961918]\n",
      "epoch:45 step:35319[D loss: 0.420622, acc: 57.81%, op_acc: 40.62%] [G loss: 0.990535]\n",
      "epoch:45 step:35320[D loss: 0.366366, acc: 71.88%, op_acc: 45.31%] [G loss: 0.881390]\n",
      "epoch:45 step:35321[D loss: 0.390282, acc: 60.94%, op_acc: 46.09%] [G loss: 1.019705]\n",
      "epoch:45 step:35322[D loss: 0.383622, acc: 64.06%, op_acc: 48.44%] [G loss: 0.932638]\n",
      "epoch:45 step:35323[D loss: 0.393560, acc: 66.41%, op_acc: 41.41%] [G loss: 0.936844]\n",
      "epoch:45 step:35324[D loss: 0.377992, acc: 69.53%, op_acc: 46.88%] [G loss: 0.919211]\n",
      "epoch:45 step:35325[D loss: 0.400918, acc: 65.62%, op_acc: 45.31%] [G loss: 0.907494]\n",
      "epoch:45 step:35326[D loss: 0.409289, acc: 60.16%, op_acc: 44.53%] [G loss: 1.013745]\n",
      "epoch:45 step:35327[D loss: 0.372181, acc: 64.84%, op_acc: 46.88%] [G loss: 1.052886]\n",
      "epoch:45 step:35328[D loss: 0.380981, acc: 69.53%, op_acc: 44.53%] [G loss: 0.908727]\n",
      "epoch:45 step:35329[D loss: 0.375932, acc: 71.09%, op_acc: 44.53%] [G loss: 1.039237]\n",
      "epoch:45 step:35330[D loss: 0.396563, acc: 71.09%, op_acc: 35.94%] [G loss: 0.963573]\n",
      "epoch:45 step:35331[D loss: 0.409002, acc: 66.41%, op_acc: 41.41%] [G loss: 0.967076]\n",
      "epoch:45 step:35332[D loss: 0.437939, acc: 53.91%, op_acc: 38.28%] [G loss: 1.007331]\n",
      "epoch:45 step:35333[D loss: 0.384676, acc: 61.72%, op_acc: 46.09%] [G loss: 1.046489]\n",
      "epoch:45 step:35334[D loss: 0.399315, acc: 62.50%, op_acc: 44.53%] [G loss: 1.008598]\n",
      "epoch:45 step:35335[D loss: 0.413934, acc: 64.84%, op_acc: 39.84%] [G loss: 0.723420]\n",
      "epoch:45 step:35336[D loss: 0.406682, acc: 60.16%, op_acc: 42.19%] [G loss: 1.036246]\n",
      "epoch:45 step:35337[D loss: 0.364841, acc: 64.84%, op_acc: 45.31%] [G loss: 1.103081]\n",
      "epoch:45 step:35338[D loss: 0.455325, acc: 54.69%, op_acc: 40.62%] [G loss: 0.886129]\n",
      "epoch:45 step:35339[D loss: 0.385637, acc: 69.53%, op_acc: 50.00%] [G loss: 0.878136]\n",
      "epoch:45 step:35340[D loss: 0.372769, acc: 70.31%, op_acc: 36.72%] [G loss: 0.843372]\n",
      "epoch:45 step:35341[D loss: 0.369674, acc: 74.22%, op_acc: 43.75%] [G loss: 0.810965]\n",
      "epoch:45 step:35342[D loss: 0.431834, acc: 57.81%, op_acc: 46.09%] [G loss: 0.853354]\n",
      "epoch:45 step:35343[D loss: 0.409276, acc: 61.72%, op_acc: 41.41%] [G loss: 0.805572]\n",
      "epoch:45 step:35344[D loss: 0.388150, acc: 58.59%, op_acc: 45.31%] [G loss: 0.833678]\n",
      "epoch:45 step:35345[D loss: 0.407660, acc: 59.38%, op_acc: 46.09%] [G loss: 0.835168]\n",
      "epoch:45 step:35346[D loss: 0.376372, acc: 64.06%, op_acc: 42.97%] [G loss: 1.045764]\n",
      "epoch:45 step:35347[D loss: 0.434817, acc: 57.81%, op_acc: 36.72%] [G loss: 0.996085]\n",
      "epoch:45 step:35348[D loss: 0.411320, acc: 59.38%, op_acc: 44.53%] [G loss: 0.977150]\n",
      "epoch:45 step:35349[D loss: 0.353598, acc: 74.22%, op_acc: 46.09%] [G loss: 1.056783]\n",
      "epoch:45 step:35350[D loss: 0.381498, acc: 69.53%, op_acc: 43.75%] [G loss: 0.982852]\n",
      "##############\n",
      "[0.83687667 0.84974596 0.82051994 0.8057829  0.80559429 0.83154524\n",
      " 0.87698349 0.82293451 0.80203379 0.83188566]\n",
      "##########\n",
      "epoch:45 step:35351[D loss: 0.443615, acc: 55.47%, op_acc: 41.41%] [G loss: 0.957725]\n",
      "epoch:45 step:35352[D loss: 0.334350, acc: 75.00%, op_acc: 53.12%] [G loss: 1.115057]\n",
      "epoch:45 step:35353[D loss: 0.416400, acc: 60.16%, op_acc: 36.72%] [G loss: 1.044566]\n",
      "epoch:45 step:35354[D loss: 0.444972, acc: 54.69%, op_acc: 40.62%] [G loss: 0.845960]\n",
      "epoch:45 step:35355[D loss: 0.436766, acc: 60.94%, op_acc: 42.97%] [G loss: 1.021913]\n",
      "epoch:45 step:35356[D loss: 0.392758, acc: 63.28%, op_acc: 42.19%] [G loss: 1.062291]\n",
      "epoch:45 step:35357[D loss: 0.385051, acc: 66.41%, op_acc: 53.12%] [G loss: 1.186352]\n",
      "epoch:45 step:35358[D loss: 0.434143, acc: 62.50%, op_acc: 37.50%] [G loss: 0.893263]\n",
      "epoch:45 step:35359[D loss: 0.386339, acc: 70.31%, op_acc: 43.75%] [G loss: 1.060067]\n",
      "epoch:45 step:35360[D loss: 0.424991, acc: 65.62%, op_acc: 39.84%] [G loss: 0.979312]\n",
      "epoch:45 step:35361[D loss: 0.405270, acc: 57.81%, op_acc: 42.97%] [G loss: 1.022705]\n",
      "epoch:45 step:35362[D loss: 0.365560, acc: 68.75%, op_acc: 50.78%] [G loss: 0.973365]\n",
      "epoch:45 step:35363[D loss: 0.383338, acc: 71.88%, op_acc: 44.53%] [G loss: 1.008750]\n",
      "epoch:45 step:35364[D loss: 0.383860, acc: 65.62%, op_acc: 50.78%] [G loss: 1.018351]\n",
      "epoch:45 step:35365[D loss: 0.389127, acc: 67.97%, op_acc: 43.75%] [G loss: 0.949177]\n",
      "epoch:45 step:35366[D loss: 0.395603, acc: 64.06%, op_acc: 45.31%] [G loss: 0.976035]\n",
      "epoch:45 step:35367[D loss: 0.427714, acc: 58.59%, op_acc: 42.97%] [G loss: 0.855565]\n",
      "epoch:45 step:35368[D loss: 0.407715, acc: 58.59%, op_acc: 44.53%] [G loss: 0.904676]\n",
      "epoch:45 step:35369[D loss: 0.404843, acc: 65.62%, op_acc: 38.28%] [G loss: 0.956806]\n",
      "epoch:45 step:35370[D loss: 0.391111, acc: 64.84%, op_acc: 46.09%] [G loss: 0.850343]\n",
      "epoch:45 step:35371[D loss: 0.405148, acc: 60.94%, op_acc: 41.41%] [G loss: 0.997895]\n",
      "epoch:45 step:35372[D loss: 0.439319, acc: 60.94%, op_acc: 40.62%] [G loss: 1.027569]\n",
      "epoch:45 step:35373[D loss: 0.377784, acc: 67.19%, op_acc: 45.31%] [G loss: 0.957361]\n",
      "epoch:45 step:35374[D loss: 0.424745, acc: 63.28%, op_acc: 47.66%] [G loss: 0.801570]\n",
      "epoch:45 step:35375[D loss: 0.435956, acc: 55.47%, op_acc: 41.41%] [G loss: 0.786443]\n",
      "epoch:45 step:35376[D loss: 0.362823, acc: 67.97%, op_acc: 49.22%] [G loss: 1.070101]\n",
      "epoch:45 step:35377[D loss: 0.380695, acc: 64.84%, op_acc: 44.53%] [G loss: 0.930719]\n",
      "epoch:45 step:35378[D loss: 0.379684, acc: 65.62%, op_acc: 49.22%] [G loss: 0.946447]\n",
      "epoch:45 step:35379[D loss: 0.461407, acc: 50.78%, op_acc: 44.53%] [G loss: 0.956106]\n",
      "epoch:45 step:35380[D loss: 0.390590, acc: 59.38%, op_acc: 42.97%] [G loss: 0.920097]\n",
      "epoch:45 step:35381[D loss: 0.421898, acc: 64.06%, op_acc: 39.06%] [G loss: 0.978728]\n",
      "epoch:45 step:35382[D loss: 0.450966, acc: 57.81%, op_acc: 42.97%] [G loss: 0.988132]\n",
      "epoch:45 step:35383[D loss: 0.467570, acc: 49.22%, op_acc: 37.50%] [G loss: 0.899853]\n",
      "epoch:45 step:35384[D loss: 0.386913, acc: 61.72%, op_acc: 45.31%] [G loss: 1.082458]\n",
      "epoch:45 step:35385[D loss: 0.448035, acc: 55.47%, op_acc: 35.94%] [G loss: 0.910449]\n",
      "epoch:45 step:35386[D loss: 0.380198, acc: 70.31%, op_acc: 42.97%] [G loss: 0.975899]\n",
      "epoch:45 step:35387[D loss: 0.403063, acc: 60.16%, op_acc: 46.09%] [G loss: 1.004603]\n",
      "epoch:45 step:35388[D loss: 0.422693, acc: 60.94%, op_acc: 48.44%] [G loss: 0.901183]\n",
      "epoch:45 step:35389[D loss: 0.419575, acc: 64.84%, op_acc: 41.41%] [G loss: 1.071362]\n",
      "epoch:45 step:35390[D loss: 0.426207, acc: 59.38%, op_acc: 44.53%] [G loss: 1.023693]\n",
      "epoch:45 step:35391[D loss: 0.390897, acc: 69.53%, op_acc: 38.28%] [G loss: 1.017644]\n",
      "epoch:45 step:35392[D loss: 0.360799, acc: 72.66%, op_acc: 42.97%] [G loss: 0.785915]\n",
      "epoch:45 step:35393[D loss: 0.401141, acc: 65.62%, op_acc: 46.09%] [G loss: 0.777908]\n",
      "epoch:45 step:35394[D loss: 0.406399, acc: 61.72%, op_acc: 43.75%] [G loss: 0.845781]\n",
      "epoch:45 step:35395[D loss: 0.398485, acc: 67.97%, op_acc: 47.66%] [G loss: 1.080359]\n",
      "epoch:45 step:35396[D loss: 0.395268, acc: 55.47%, op_acc: 44.53%] [G loss: 0.866579]\n",
      "epoch:45 step:35397[D loss: 0.385194, acc: 71.09%, op_acc: 42.19%] [G loss: 0.964063]\n",
      "epoch:45 step:35398[D loss: 0.380526, acc: 71.09%, op_acc: 38.28%] [G loss: 0.749694]\n",
      "epoch:45 step:35399[D loss: 0.417205, acc: 57.81%, op_acc: 39.06%] [G loss: 0.887368]\n",
      "epoch:45 step:35400[D loss: 0.446333, acc: 53.91%, op_acc: 42.97%] [G loss: 0.749384]\n",
      "##############\n",
      "[0.85560516 0.86799473 0.80865595 0.80455111 0.79814466 0.82727223\n",
      " 0.90505332 0.81046215 0.81358263 0.81240698]\n",
      "##########\n",
      "epoch:45 step:35401[D loss: 0.391567, acc: 62.50%, op_acc: 41.41%] [G loss: 0.946886]\n",
      "epoch:45 step:35402[D loss: 0.399144, acc: 66.41%, op_acc: 38.28%] [G loss: 0.699249]\n",
      "epoch:45 step:35403[D loss: 0.397367, acc: 66.41%, op_acc: 40.62%] [G loss: 0.758625]\n",
      "epoch:45 step:35404[D loss: 0.418618, acc: 61.72%, op_acc: 36.72%] [G loss: 0.693836]\n",
      "epoch:45 step:35405[D loss: 0.423491, acc: 64.84%, op_acc: 36.72%] [G loss: 0.696747]\n",
      "epoch:45 step:35406[D loss: 0.386676, acc: 70.31%, op_acc: 41.41%] [G loss: 0.952893]\n",
      "epoch:45 step:35407[D loss: 0.407608, acc: 63.28%, op_acc: 46.09%] [G loss: 0.952393]\n",
      "epoch:45 step:35408[D loss: 0.427528, acc: 64.84%, op_acc: 38.28%] [G loss: 0.815678]\n",
      "epoch:45 step:35409[D loss: 0.418237, acc: 56.25%, op_acc: 44.53%] [G loss: 0.964953]\n",
      "epoch:45 step:35410[D loss: 0.404810, acc: 62.50%, op_acc: 40.62%] [G loss: 0.806665]\n",
      "epoch:45 step:35411[D loss: 0.385853, acc: 60.94%, op_acc: 43.75%] [G loss: 0.799640]\n",
      "epoch:45 step:35412[D loss: 0.480510, acc: 52.34%, op_acc: 37.50%] [G loss: 0.828273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35413[D loss: 0.403902, acc: 61.72%, op_acc: 48.44%] [G loss: 0.967597]\n",
      "epoch:45 step:35414[D loss: 0.413956, acc: 57.81%, op_acc: 46.09%] [G loss: 0.842601]\n",
      "epoch:45 step:35415[D loss: 0.392130, acc: 64.06%, op_acc: 44.53%] [G loss: 0.931282]\n",
      "epoch:45 step:35416[D loss: 0.400132, acc: 67.97%, op_acc: 42.19%] [G loss: 0.917459]\n",
      "epoch:45 step:35417[D loss: 0.424022, acc: 58.59%, op_acc: 44.53%] [G loss: 1.088460]\n",
      "epoch:45 step:35418[D loss: 0.397930, acc: 62.50%, op_acc: 45.31%] [G loss: 0.865734]\n",
      "epoch:45 step:35419[D loss: 0.381477, acc: 65.62%, op_acc: 48.44%] [G loss: 0.967055]\n",
      "epoch:45 step:35420[D loss: 0.379619, acc: 65.62%, op_acc: 48.44%] [G loss: 0.842795]\n",
      "epoch:45 step:35421[D loss: 0.387917, acc: 66.41%, op_acc: 50.00%] [G loss: 0.860904]\n",
      "epoch:45 step:35422[D loss: 0.389677, acc: 74.22%, op_acc: 42.97%] [G loss: 0.884317]\n",
      "epoch:45 step:35423[D loss: 0.392874, acc: 66.41%, op_acc: 39.84%] [G loss: 0.911061]\n",
      "epoch:45 step:35424[D loss: 0.409192, acc: 59.38%, op_acc: 46.09%] [G loss: 1.016380]\n",
      "epoch:45 step:35425[D loss: 0.400947, acc: 65.62%, op_acc: 46.88%] [G loss: 0.897835]\n",
      "epoch:45 step:35426[D loss: 0.383867, acc: 70.31%, op_acc: 39.84%] [G loss: 0.861015]\n",
      "epoch:45 step:35427[D loss: 0.399061, acc: 64.06%, op_acc: 41.41%] [G loss: 0.869731]\n",
      "epoch:45 step:35428[D loss: 0.377911, acc: 67.97%, op_acc: 50.00%] [G loss: 0.903889]\n",
      "epoch:45 step:35429[D loss: 0.377043, acc: 71.88%, op_acc: 45.31%] [G loss: 1.005257]\n",
      "epoch:45 step:35430[D loss: 0.406639, acc: 58.59%, op_acc: 42.97%] [G loss: 1.023396]\n",
      "epoch:45 step:35431[D loss: 0.444755, acc: 60.16%, op_acc: 36.72%] [G loss: 0.886501]\n",
      "epoch:45 step:35432[D loss: 0.405626, acc: 62.50%, op_acc: 43.75%] [G loss: 0.970211]\n",
      "epoch:45 step:35433[D loss: 0.369365, acc: 69.53%, op_acc: 39.06%] [G loss: 1.079217]\n",
      "epoch:45 step:35434[D loss: 0.397864, acc: 63.28%, op_acc: 43.75%] [G loss: 0.841887]\n",
      "epoch:45 step:35435[D loss: 0.336210, acc: 77.34%, op_acc: 46.09%] [G loss: 1.025969]\n",
      "epoch:45 step:35436[D loss: 0.383584, acc: 66.41%, op_acc: 46.09%] [G loss: 0.988999]\n",
      "epoch:45 step:35437[D loss: 0.451168, acc: 54.69%, op_acc: 41.41%] [G loss: 0.927667]\n",
      "epoch:45 step:35438[D loss: 0.343906, acc: 78.12%, op_acc: 44.53%] [G loss: 1.178409]\n",
      "epoch:45 step:35439[D loss: 0.376359, acc: 67.19%, op_acc: 39.84%] [G loss: 0.941983]\n",
      "epoch:45 step:35440[D loss: 0.335419, acc: 75.00%, op_acc: 46.09%] [G loss: 1.160428]\n",
      "epoch:45 step:35441[D loss: 0.321843, acc: 81.25%, op_acc: 52.34%] [G loss: 1.143571]\n",
      "epoch:45 step:35442[D loss: 0.390327, acc: 65.62%, op_acc: 41.41%] [G loss: 1.059949]\n",
      "epoch:45 step:35443[D loss: 0.412098, acc: 58.59%, op_acc: 42.19%] [G loss: 1.164733]\n",
      "epoch:45 step:35444[D loss: 0.382031, acc: 68.75%, op_acc: 45.31%] [G loss: 1.151804]\n",
      "epoch:45 step:35445[D loss: 0.361997, acc: 70.31%, op_acc: 44.53%] [G loss: 0.642784]\n",
      "epoch:45 step:35446[D loss: 0.388013, acc: 70.31%, op_acc: 46.09%] [G loss: 0.845792]\n",
      "epoch:45 step:35447[D loss: 0.427126, acc: 60.16%, op_acc: 41.41%] [G loss: 1.081422]\n",
      "epoch:45 step:35448[D loss: 0.419623, acc: 58.59%, op_acc: 39.06%] [G loss: 1.161984]\n",
      "epoch:45 step:35449[D loss: 0.354378, acc: 71.09%, op_acc: 47.66%] [G loss: 1.170820]\n",
      "epoch:45 step:35450[D loss: 0.394253, acc: 66.41%, op_acc: 43.75%] [G loss: 0.896252]\n",
      "##############\n",
      "[0.86665257 0.86693067 0.8213262  0.80166068 0.78347056 0.82405944\n",
      " 0.87895993 0.79358302 0.82402198 0.8371555 ]\n",
      "##########\n",
      "epoch:45 step:35451[D loss: 0.416304, acc: 69.53%, op_acc: 36.72%] [G loss: 1.156056]\n",
      "epoch:45 step:35452[D loss: 0.357008, acc: 71.88%, op_acc: 43.75%] [G loss: 0.988673]\n",
      "epoch:45 step:35453[D loss: 0.410794, acc: 61.72%, op_acc: 43.75%] [G loss: 1.160149]\n",
      "epoch:45 step:35454[D loss: 0.435576, acc: 57.03%, op_acc: 38.28%] [G loss: 1.012156]\n",
      "epoch:45 step:35455[D loss: 0.379689, acc: 74.22%, op_acc: 35.16%] [G loss: 1.040391]\n",
      "epoch:45 step:35456[D loss: 0.381152, acc: 66.41%, op_acc: 44.53%] [G loss: 0.976159]\n",
      "epoch:45 step:35457[D loss: 0.429770, acc: 53.91%, op_acc: 41.41%] [G loss: 1.105709]\n",
      "epoch:45 step:35458[D loss: 0.423752, acc: 55.47%, op_acc: 45.31%] [G loss: 1.065651]\n",
      "epoch:45 step:35459[D loss: 0.377324, acc: 64.06%, op_acc: 42.97%] [G loss: 0.966343]\n",
      "epoch:45 step:35460[D loss: 0.382368, acc: 72.66%, op_acc: 49.22%] [G loss: 1.084842]\n",
      "epoch:45 step:35461[D loss: 0.355345, acc: 68.75%, op_acc: 46.88%] [G loss: 0.983891]\n",
      "epoch:45 step:35462[D loss: 0.380265, acc: 69.53%, op_acc: 46.09%] [G loss: 0.863330]\n",
      "epoch:45 step:35463[D loss: 0.424909, acc: 53.12%, op_acc: 42.19%] [G loss: 1.101779]\n",
      "epoch:45 step:35464[D loss: 0.414231, acc: 57.03%, op_acc: 42.97%] [G loss: 1.026823]\n",
      "epoch:45 step:35465[D loss: 0.388540, acc: 67.19%, op_acc: 40.62%] [G loss: 1.003440]\n",
      "epoch:45 step:35466[D loss: 0.399592, acc: 66.41%, op_acc: 41.41%] [G loss: 0.902900]\n",
      "epoch:45 step:35467[D loss: 0.378038, acc: 68.75%, op_acc: 43.75%] [G loss: 1.001008]\n",
      "epoch:45 step:35468[D loss: 0.421561, acc: 64.06%, op_acc: 41.41%] [G loss: 1.185636]\n",
      "epoch:45 step:35469[D loss: 0.424628, acc: 64.06%, op_acc: 37.50%] [G loss: 1.139565]\n",
      "epoch:45 step:35470[D loss: 0.403575, acc: 67.19%, op_acc: 43.75%] [G loss: 1.148012]\n",
      "epoch:45 step:35471[D loss: 0.407941, acc: 58.59%, op_acc: 48.44%] [G loss: 0.775216]\n",
      "epoch:45 step:35472[D loss: 0.409526, acc: 59.38%, op_acc: 40.62%] [G loss: 1.064646]\n",
      "epoch:45 step:35473[D loss: 0.432092, acc: 60.16%, op_acc: 44.53%] [G loss: 1.114626]\n",
      "epoch:45 step:35474[D loss: 0.411620, acc: 57.03%, op_acc: 50.00%] [G loss: 1.159783]\n",
      "epoch:45 step:35475[D loss: 0.410389, acc: 60.16%, op_acc: 50.78%] [G loss: 1.091878]\n",
      "epoch:45 step:35476[D loss: 0.394111, acc: 66.41%, op_acc: 42.97%] [G loss: 0.996867]\n",
      "epoch:45 step:35477[D loss: 0.353694, acc: 74.22%, op_acc: 43.75%] [G loss: 1.012456]\n",
      "epoch:45 step:35478[D loss: 0.383289, acc: 71.88%, op_acc: 40.62%] [G loss: 1.083430]\n",
      "epoch:45 step:35479[D loss: 0.346262, acc: 71.88%, op_acc: 49.22%] [G loss: 0.898801]\n",
      "epoch:45 step:35480[D loss: 0.416885, acc: 57.81%, op_acc: 39.06%] [G loss: 1.102346]\n",
      "epoch:45 step:35481[D loss: 0.421944, acc: 59.38%, op_acc: 42.97%] [G loss: 1.033464]\n",
      "epoch:45 step:35482[D loss: 0.417780, acc: 61.72%, op_acc: 32.81%] [G loss: 1.060651]\n",
      "epoch:45 step:35483[D loss: 0.402617, acc: 56.25%, op_acc: 46.88%] [G loss: 0.990142]\n",
      "epoch:45 step:35484[D loss: 0.376949, acc: 72.66%, op_acc: 43.75%] [G loss: 0.945387]\n",
      "epoch:45 step:35485[D loss: 0.375455, acc: 70.31%, op_acc: 46.88%] [G loss: 0.819752]\n",
      "epoch:45 step:35486[D loss: 0.444178, acc: 51.56%, op_acc: 39.06%] [G loss: 0.767655]\n",
      "epoch:45 step:35487[D loss: 0.462725, acc: 56.25%, op_acc: 36.72%] [G loss: 1.125152]\n",
      "epoch:45 step:35488[D loss: 0.416535, acc: 67.19%, op_acc: 37.50%] [G loss: 1.014840]\n",
      "epoch:45 step:35489[D loss: 0.407110, acc: 60.16%, op_acc: 42.97%] [G loss: 1.236724]\n",
      "epoch:45 step:35490[D loss: 0.405192, acc: 58.59%, op_acc: 42.19%] [G loss: 1.175350]\n",
      "epoch:45 step:35491[D loss: 0.435710, acc: 60.16%, op_acc: 41.41%] [G loss: 1.062447]\n",
      "epoch:45 step:35492[D loss: 0.409714, acc: 60.16%, op_acc: 47.66%] [G loss: 0.930541]\n",
      "epoch:45 step:35493[D loss: 0.433940, acc: 49.22%, op_acc: 42.97%] [G loss: 1.019665]\n",
      "epoch:45 step:35494[D loss: 0.392055, acc: 66.41%, op_acc: 46.88%] [G loss: 0.982108]\n",
      "epoch:45 step:35495[D loss: 0.377669, acc: 66.41%, op_acc: 43.75%] [G loss: 1.027374]\n",
      "epoch:45 step:35496[D loss: 0.392646, acc: 64.84%, op_acc: 44.53%] [G loss: 1.049722]\n",
      "epoch:45 step:35497[D loss: 0.420169, acc: 64.06%, op_acc: 39.06%] [G loss: 0.929529]\n",
      "epoch:45 step:35498[D loss: 0.360521, acc: 67.19%, op_acc: 47.66%] [G loss: 1.001045]\n",
      "epoch:45 step:35499[D loss: 0.411742, acc: 59.38%, op_acc: 42.19%] [G loss: 1.068896]\n",
      "epoch:45 step:35500[D loss: 0.425080, acc: 64.06%, op_acc: 39.06%] [G loss: 1.051715]\n",
      "##############\n",
      "[0.87409236 0.85011852 0.81507518 0.80455139 0.78219774 0.83421736\n",
      " 0.89887478 0.82193311 0.82070248 0.81255809]\n",
      "##########\n",
      "epoch:45 step:35501[D loss: 0.368823, acc: 73.44%, op_acc: 48.44%] [G loss: 1.126034]\n",
      "epoch:45 step:35502[D loss: 0.424343, acc: 60.94%, op_acc: 39.84%] [G loss: 0.813398]\n",
      "epoch:45 step:35503[D loss: 0.411268, acc: 64.84%, op_acc: 41.41%] [G loss: 0.976233]\n",
      "epoch:45 step:35504[D loss: 0.419897, acc: 58.59%, op_acc: 39.84%] [G loss: 1.074171]\n",
      "epoch:45 step:35505[D loss: 0.377752, acc: 67.97%, op_acc: 46.88%] [G loss: 1.004989]\n",
      "epoch:45 step:35506[D loss: 0.393832, acc: 61.72%, op_acc: 42.97%] [G loss: 0.980757]\n",
      "epoch:45 step:35507[D loss: 0.351194, acc: 64.84%, op_acc: 46.88%] [G loss: 0.857212]\n",
      "epoch:45 step:35508[D loss: 0.424378, acc: 58.59%, op_acc: 42.97%] [G loss: 0.907673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35509[D loss: 0.386344, acc: 71.09%, op_acc: 46.88%] [G loss: 0.999906]\n",
      "epoch:45 step:35510[D loss: 0.337856, acc: 73.44%, op_acc: 50.00%] [G loss: 1.046361]\n",
      "epoch:45 step:35511[D loss: 0.416840, acc: 58.59%, op_acc: 42.97%] [G loss: 0.985895]\n",
      "epoch:45 step:35512[D loss: 0.372620, acc: 71.09%, op_acc: 47.66%] [G loss: 0.887747]\n",
      "epoch:45 step:35513[D loss: 0.408736, acc: 61.72%, op_acc: 39.06%] [G loss: 0.815221]\n",
      "epoch:45 step:35514[D loss: 0.404313, acc: 60.16%, op_acc: 48.44%] [G loss: 0.937411]\n",
      "epoch:45 step:35515[D loss: 0.390719, acc: 65.62%, op_acc: 39.84%] [G loss: 0.975828]\n",
      "epoch:45 step:35516[D loss: 0.363176, acc: 67.19%, op_acc: 47.66%] [G loss: 0.888507]\n",
      "epoch:45 step:35517[D loss: 0.359517, acc: 69.53%, op_acc: 45.31%] [G loss: 0.937548]\n",
      "epoch:45 step:35518[D loss: 0.431470, acc: 56.25%, op_acc: 42.97%] [G loss: 0.872803]\n",
      "epoch:45 step:35519[D loss: 0.381687, acc: 68.75%, op_acc: 45.31%] [G loss: 0.916664]\n",
      "epoch:45 step:35520[D loss: 0.417127, acc: 62.50%, op_acc: 46.09%] [G loss: 0.693400]\n",
      "epoch:45 step:35521[D loss: 0.347236, acc: 68.75%, op_acc: 48.44%] [G loss: 0.869084]\n",
      "epoch:45 step:35522[D loss: 0.372106, acc: 71.88%, op_acc: 43.75%] [G loss: 0.915854]\n",
      "epoch:45 step:35523[D loss: 0.389773, acc: 62.50%, op_acc: 44.53%] [G loss: 0.908026]\n",
      "epoch:45 step:35524[D loss: 0.340570, acc: 76.56%, op_acc: 47.66%] [G loss: 0.946933]\n",
      "epoch:45 step:35525[D loss: 0.402963, acc: 64.84%, op_acc: 46.09%] [G loss: 1.100427]\n",
      "epoch:45 step:35526[D loss: 0.370948, acc: 67.19%, op_acc: 48.44%] [G loss: 1.038139]\n",
      "epoch:45 step:35527[D loss: 0.393628, acc: 63.28%, op_acc: 45.31%] [G loss: 0.948794]\n",
      "epoch:45 step:35528[D loss: 0.359289, acc: 72.66%, op_acc: 46.88%] [G loss: 0.999887]\n",
      "epoch:45 step:35529[D loss: 0.425915, acc: 61.72%, op_acc: 41.41%] [G loss: 0.900863]\n",
      "epoch:45 step:35530[D loss: 0.389409, acc: 64.84%, op_acc: 42.19%] [G loss: 0.991034]\n",
      "epoch:45 step:35531[D loss: 0.377908, acc: 72.66%, op_acc: 47.66%] [G loss: 1.014905]\n",
      "epoch:45 step:35532[D loss: 0.416404, acc: 57.81%, op_acc: 42.19%] [G loss: 0.950869]\n",
      "epoch:45 step:35533[D loss: 0.401339, acc: 71.09%, op_acc: 39.84%] [G loss: 0.950347]\n",
      "epoch:45 step:35534[D loss: 0.382823, acc: 63.28%, op_acc: 42.19%] [G loss: 0.952301]\n",
      "epoch:45 step:35535[D loss: 0.414256, acc: 63.28%, op_acc: 39.84%] [G loss: 0.947374]\n",
      "epoch:45 step:35536[D loss: 0.380302, acc: 65.62%, op_acc: 41.41%] [G loss: 1.131262]\n",
      "epoch:45 step:35537[D loss: 0.406669, acc: 61.72%, op_acc: 46.88%] [G loss: 0.874353]\n",
      "epoch:45 step:35538[D loss: 0.428778, acc: 56.25%, op_acc: 41.41%] [G loss: 1.058544]\n",
      "epoch:45 step:35539[D loss: 0.409572, acc: 65.62%, op_acc: 36.72%] [G loss: 0.993291]\n",
      "epoch:45 step:35540[D loss: 0.444900, acc: 54.69%, op_acc: 35.16%] [G loss: 1.110459]\n",
      "epoch:45 step:35541[D loss: 0.395551, acc: 61.72%, op_acc: 39.84%] [G loss: 0.983884]\n",
      "epoch:45 step:35542[D loss: 0.447167, acc: 49.22%, op_acc: 40.62%] [G loss: 1.041303]\n",
      "epoch:45 step:35543[D loss: 0.416828, acc: 59.38%, op_acc: 41.41%] [G loss: 0.972525]\n",
      "epoch:45 step:35544[D loss: 0.436046, acc: 60.16%, op_acc: 33.59%] [G loss: 1.000526]\n",
      "epoch:45 step:35545[D loss: 0.390360, acc: 68.75%, op_acc: 39.06%] [G loss: 1.019936]\n",
      "epoch:45 step:35546[D loss: 0.374418, acc: 69.53%, op_acc: 46.09%] [G loss: 1.009513]\n",
      "epoch:45 step:35547[D loss: 0.397839, acc: 67.19%, op_acc: 37.50%] [G loss: 0.940405]\n",
      "epoch:45 step:35548[D loss: 0.377479, acc: 71.09%, op_acc: 48.44%] [G loss: 0.979176]\n",
      "epoch:45 step:35549[D loss: 0.365360, acc: 71.09%, op_acc: 46.88%] [G loss: 1.200736]\n",
      "epoch:45 step:35550[D loss: 0.402968, acc: 64.06%, op_acc: 41.41%] [G loss: 0.871739]\n",
      "##############\n",
      "[0.84110966 0.84913272 0.80584025 0.79227821 0.79754664 0.80509838\n",
      " 0.87339783 0.81285921 0.83545164 0.82746857]\n",
      "##########\n",
      "epoch:45 step:35551[D loss: 0.399958, acc: 59.38%, op_acc: 53.12%] [G loss: 1.035916]\n",
      "epoch:45 step:35552[D loss: 0.412652, acc: 64.84%, op_acc: 42.97%] [G loss: 0.917393]\n",
      "epoch:45 step:35553[D loss: 0.383120, acc: 65.62%, op_acc: 49.22%] [G loss: 0.821598]\n",
      "epoch:45 step:35554[D loss: 0.382557, acc: 70.31%, op_acc: 41.41%] [G loss: 0.992753]\n",
      "epoch:45 step:35555[D loss: 0.379963, acc: 64.84%, op_acc: 47.66%] [G loss: 1.060883]\n",
      "epoch:45 step:35556[D loss: 0.382153, acc: 68.75%, op_acc: 40.62%] [G loss: 1.024894]\n",
      "epoch:45 step:35557[D loss: 0.430420, acc: 50.00%, op_acc: 42.19%] [G loss: 0.980458]\n",
      "epoch:45 step:35558[D loss: 0.400702, acc: 62.50%, op_acc: 43.75%] [G loss: 0.982591]\n",
      "epoch:45 step:35559[D loss: 0.379741, acc: 68.75%, op_acc: 46.88%] [G loss: 0.974826]\n",
      "epoch:45 step:35560[D loss: 0.406656, acc: 61.72%, op_acc: 41.41%] [G loss: 1.020544]\n",
      "epoch:45 step:35561[D loss: 0.405852, acc: 63.28%, op_acc: 42.19%] [G loss: 0.870616]\n",
      "epoch:45 step:35562[D loss: 0.409385, acc: 59.38%, op_acc: 42.97%] [G loss: 0.809872]\n",
      "epoch:45 step:35563[D loss: 0.393583, acc: 66.41%, op_acc: 46.09%] [G loss: 0.947118]\n",
      "epoch:45 step:35564[D loss: 0.404794, acc: 62.50%, op_acc: 38.28%] [G loss: 0.937309]\n",
      "epoch:45 step:35565[D loss: 0.430813, acc: 64.06%, op_acc: 40.62%] [G loss: 0.933762]\n",
      "epoch:45 step:35566[D loss: 0.375572, acc: 70.31%, op_acc: 47.66%] [G loss: 0.938488]\n",
      "epoch:45 step:35567[D loss: 0.392859, acc: 64.84%, op_acc: 47.66%] [G loss: 0.964497]\n",
      "epoch:45 step:35568[D loss: 0.420662, acc: 65.62%, op_acc: 39.06%] [G loss: 0.821809]\n",
      "epoch:45 step:35569[D loss: 0.428807, acc: 58.59%, op_acc: 42.19%] [G loss: 0.944555]\n",
      "epoch:45 step:35570[D loss: 0.384496, acc: 67.19%, op_acc: 39.84%] [G loss: 0.902582]\n",
      "epoch:45 step:35571[D loss: 0.405996, acc: 62.50%, op_acc: 42.19%] [G loss: 0.956798]\n",
      "epoch:45 step:35572[D loss: 0.382881, acc: 64.06%, op_acc: 42.97%] [G loss: 1.037804]\n",
      "epoch:45 step:35573[D loss: 0.419978, acc: 62.50%, op_acc: 43.75%] [G loss: 0.947478]\n",
      "epoch:45 step:35574[D loss: 0.389044, acc: 64.84%, op_acc: 42.97%] [G loss: 0.914800]\n",
      "epoch:45 step:35575[D loss: 0.412590, acc: 60.94%, op_acc: 42.97%] [G loss: 0.901909]\n",
      "epoch:45 step:35576[D loss: 0.414558, acc: 53.91%, op_acc: 46.09%] [G loss: 1.072377]\n",
      "epoch:45 step:35577[D loss: 0.394662, acc: 60.16%, op_acc: 37.50%] [G loss: 0.680601]\n",
      "epoch:45 step:35578[D loss: 0.422389, acc: 56.25%, op_acc: 42.97%] [G loss: 0.915159]\n",
      "epoch:45 step:35579[D loss: 0.363319, acc: 69.53%, op_acc: 44.53%] [G loss: 0.936351]\n",
      "epoch:45 step:35580[D loss: 0.402248, acc: 63.28%, op_acc: 49.22%] [G loss: 0.928921]\n",
      "epoch:45 step:35581[D loss: 0.409177, acc: 60.16%, op_acc: 40.62%] [G loss: 0.999446]\n",
      "epoch:45 step:35582[D loss: 0.387200, acc: 63.28%, op_acc: 53.91%] [G loss: 0.752172]\n",
      "epoch:45 step:35583[D loss: 0.378707, acc: 71.09%, op_acc: 42.19%] [G loss: 1.081620]\n",
      "epoch:45 step:35584[D loss: 0.378517, acc: 64.84%, op_acc: 42.19%] [G loss: 0.841783]\n",
      "epoch:45 step:35585[D loss: 0.394862, acc: 67.19%, op_acc: 40.62%] [G loss: 0.892462]\n",
      "epoch:45 step:35586[D loss: 0.381348, acc: 64.06%, op_acc: 41.41%] [G loss: 0.965840]\n",
      "epoch:45 step:35587[D loss: 0.397626, acc: 66.41%, op_acc: 49.22%] [G loss: 1.034656]\n",
      "epoch:45 step:35588[D loss: 0.421024, acc: 59.38%, op_acc: 42.19%] [G loss: 0.867123]\n",
      "epoch:45 step:35589[D loss: 0.347991, acc: 71.09%, op_acc: 56.25%] [G loss: 0.893163]\n",
      "epoch:45 step:35590[D loss: 0.426462, acc: 54.69%, op_acc: 46.88%] [G loss: 0.839919]\n",
      "epoch:45 step:35591[D loss: 0.427737, acc: 57.03%, op_acc: 37.50%] [G loss: 0.900910]\n",
      "epoch:45 step:35592[D loss: 0.439337, acc: 57.03%, op_acc: 39.84%] [G loss: 0.807524]\n",
      "epoch:45 step:35593[D loss: 0.386588, acc: 65.62%, op_acc: 42.97%] [G loss: 0.946148]\n",
      "epoch:45 step:35594[D loss: 0.358453, acc: 74.22%, op_acc: 42.97%] [G loss: 0.943324]\n",
      "epoch:45 step:35595[D loss: 0.468545, acc: 55.47%, op_acc: 33.59%] [G loss: 0.825134]\n",
      "epoch:45 step:35596[D loss: 0.435521, acc: 57.81%, op_acc: 37.50%] [G loss: 0.899473]\n",
      "epoch:45 step:35597[D loss: 0.363835, acc: 68.75%, op_acc: 46.09%] [G loss: 0.995064]\n",
      "epoch:45 step:35598[D loss: 0.448849, acc: 51.56%, op_acc: 46.09%] [G loss: 0.977336]\n",
      "epoch:45 step:35599[D loss: 0.401970, acc: 60.16%, op_acc: 38.28%] [G loss: 0.960406]\n",
      "epoch:45 step:35600[D loss: 0.386789, acc: 64.84%, op_acc: 44.53%] [G loss: 0.966736]\n",
      "##############\n",
      "[0.86540436 0.84841527 0.80822815 0.8025681  0.80099882 0.84478615\n",
      " 0.89550395 0.81527576 0.81135191 0.81659233]\n",
      "##########\n",
      "epoch:45 step:35601[D loss: 0.417577, acc: 58.59%, op_acc: 41.41%] [G loss: 0.764516]\n",
      "epoch:45 step:35602[D loss: 0.387015, acc: 71.88%, op_acc: 42.19%] [G loss: 0.993216]\n",
      "epoch:45 step:35603[D loss: 0.393850, acc: 64.06%, op_acc: 43.75%] [G loss: 0.988600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35604[D loss: 0.390713, acc: 60.94%, op_acc: 46.88%] [G loss: 0.997391]\n",
      "epoch:45 step:35605[D loss: 0.395396, acc: 53.12%, op_acc: 47.66%] [G loss: 0.850078]\n",
      "epoch:45 step:35606[D loss: 0.433140, acc: 59.38%, op_acc: 42.97%] [G loss: 1.052846]\n",
      "epoch:45 step:35607[D loss: 0.381867, acc: 64.84%, op_acc: 48.44%] [G loss: 0.840806]\n",
      "epoch:45 step:35608[D loss: 0.408374, acc: 59.38%, op_acc: 48.44%] [G loss: 0.819689]\n",
      "epoch:45 step:35609[D loss: 0.415079, acc: 64.06%, op_acc: 43.75%] [G loss: 0.984125]\n",
      "epoch:45 step:35610[D loss: 0.411124, acc: 61.72%, op_acc: 41.41%] [G loss: 0.914860]\n",
      "epoch:45 step:35611[D loss: 0.369051, acc: 65.62%, op_acc: 45.31%] [G loss: 0.929231]\n",
      "epoch:45 step:35612[D loss: 0.431355, acc: 58.59%, op_acc: 46.09%] [G loss: 0.913434]\n",
      "epoch:45 step:35613[D loss: 0.428544, acc: 51.56%, op_acc: 43.75%] [G loss: 0.950466]\n",
      "epoch:45 step:35614[D loss: 0.403738, acc: 60.16%, op_acc: 42.97%] [G loss: 0.944533]\n",
      "epoch:45 step:35615[D loss: 0.438516, acc: 54.69%, op_acc: 43.75%] [G loss: 0.855286]\n",
      "epoch:45 step:35616[D loss: 0.397777, acc: 68.75%, op_acc: 39.84%] [G loss: 0.961457]\n",
      "epoch:45 step:35617[D loss: 0.363733, acc: 71.88%, op_acc: 49.22%] [G loss: 0.968682]\n",
      "epoch:45 step:35618[D loss: 0.375272, acc: 67.97%, op_acc: 53.91%] [G loss: 0.983543]\n",
      "epoch:45 step:35619[D loss: 0.440939, acc: 50.78%, op_acc: 44.53%] [G loss: 1.048047]\n",
      "epoch:45 step:35620[D loss: 0.419735, acc: 60.16%, op_acc: 44.53%] [G loss: 0.958948]\n",
      "epoch:45 step:35621[D loss: 0.379740, acc: 64.84%, op_acc: 46.09%] [G loss: 0.893164]\n",
      "epoch:45 step:35622[D loss: 0.416882, acc: 60.16%, op_acc: 44.53%] [G loss: 0.998483]\n",
      "epoch:45 step:35623[D loss: 0.372757, acc: 67.19%, op_acc: 50.78%] [G loss: 0.956416]\n",
      "epoch:45 step:35624[D loss: 0.389770, acc: 64.06%, op_acc: 46.09%] [G loss: 1.000310]\n",
      "epoch:45 step:35625[D loss: 0.400826, acc: 66.41%, op_acc: 38.28%] [G loss: 1.105766]\n",
      "epoch:45 step:35626[D loss: 0.411079, acc: 66.41%, op_acc: 45.31%] [G loss: 0.918049]\n",
      "epoch:45 step:35627[D loss: 0.382620, acc: 75.00%, op_acc: 40.62%] [G loss: 0.911626]\n",
      "epoch:45 step:35628[D loss: 0.395364, acc: 60.94%, op_acc: 48.44%] [G loss: 0.872628]\n",
      "epoch:45 step:35629[D loss: 0.332912, acc: 78.12%, op_acc: 47.66%] [G loss: 1.014476]\n",
      "epoch:45 step:35630[D loss: 0.398503, acc: 67.97%, op_acc: 40.62%] [G loss: 0.866653]\n",
      "epoch:45 step:35631[D loss: 0.336365, acc: 75.00%, op_acc: 46.88%] [G loss: 1.130643]\n",
      "epoch:45 step:35632[D loss: 0.311765, acc: 80.47%, op_acc: 47.66%] [G loss: 1.054243]\n",
      "epoch:45 step:35633[D loss: 0.379018, acc: 72.66%, op_acc: 39.84%] [G loss: 0.976989]\n",
      "epoch:45 step:35634[D loss: 0.409710, acc: 63.28%, op_acc: 46.09%] [G loss: 0.937988]\n",
      "epoch:45 step:35635[D loss: 0.372636, acc: 71.88%, op_acc: 41.41%] [G loss: 1.097890]\n",
      "epoch:45 step:35636[D loss: 0.379076, acc: 71.88%, op_acc: 41.41%] [G loss: 1.039054]\n",
      "epoch:45 step:35637[D loss: 0.357337, acc: 74.22%, op_acc: 50.78%] [G loss: 1.080911]\n",
      "epoch:45 step:35638[D loss: 0.357201, acc: 71.09%, op_acc: 54.69%] [G loss: 0.799689]\n",
      "epoch:45 step:35639[D loss: 0.385245, acc: 66.41%, op_acc: 40.62%] [G loss: 0.843397]\n",
      "epoch:45 step:35640[D loss: 0.392174, acc: 68.75%, op_acc: 42.97%] [G loss: 1.088017]\n",
      "epoch:45 step:35641[D loss: 0.411619, acc: 61.72%, op_acc: 40.62%] [G loss: 0.998128]\n",
      "epoch:45 step:35642[D loss: 0.396738, acc: 64.84%, op_acc: 45.31%] [G loss: 1.119182]\n",
      "epoch:45 step:35643[D loss: 0.389078, acc: 67.97%, op_acc: 43.75%] [G loss: 1.063307]\n",
      "epoch:45 step:35644[D loss: 0.389808, acc: 65.62%, op_acc: 47.66%] [G loss: 1.124621]\n",
      "epoch:45 step:35645[D loss: 0.345786, acc: 78.12%, op_acc: 44.53%] [G loss: 1.085918]\n",
      "epoch:45 step:35646[D loss: 0.409193, acc: 66.41%, op_acc: 39.84%] [G loss: 1.126764]\n",
      "epoch:45 step:35647[D loss: 0.393886, acc: 64.84%, op_acc: 46.09%] [G loss: 0.885540]\n",
      "epoch:45 step:35648[D loss: 0.405922, acc: 65.62%, op_acc: 48.44%] [G loss: 1.160196]\n",
      "epoch:45 step:35649[D loss: 0.442354, acc: 54.69%, op_acc: 46.88%] [G loss: 0.991684]\n",
      "epoch:45 step:35650[D loss: 0.405894, acc: 55.47%, op_acc: 43.75%] [G loss: 0.838824]\n",
      "##############\n",
      "[0.84202184 0.8802107  0.83608453 0.80302331 0.79775848 0.82256304\n",
      " 0.90471615 0.80227545 0.80551221 0.84166913]\n",
      "##########\n",
      "epoch:45 step:35651[D loss: 0.407692, acc: 60.16%, op_acc: 42.97%] [G loss: 0.962027]\n",
      "epoch:45 step:35652[D loss: 0.409308, acc: 58.59%, op_acc: 50.00%] [G loss: 1.059915]\n",
      "epoch:45 step:35653[D loss: 0.419958, acc: 61.72%, op_acc: 40.62%] [G loss: 0.876693]\n",
      "epoch:45 step:35654[D loss: 0.418890, acc: 61.72%, op_acc: 40.62%] [G loss: 0.933472]\n",
      "epoch:45 step:35655[D loss: 0.399613, acc: 60.16%, op_acc: 41.41%] [G loss: 0.986725]\n",
      "epoch:45 step:35656[D loss: 0.413569, acc: 60.94%, op_acc: 46.88%] [G loss: 0.945021]\n",
      "epoch:45 step:35657[D loss: 0.472477, acc: 49.22%, op_acc: 40.62%] [G loss: 0.869042]\n",
      "epoch:45 step:35658[D loss: 0.416697, acc: 57.03%, op_acc: 41.41%] [G loss: 0.940651]\n",
      "epoch:45 step:35659[D loss: 0.401467, acc: 60.16%, op_acc: 44.53%] [G loss: 1.020726]\n",
      "epoch:45 step:35660[D loss: 0.416322, acc: 63.28%, op_acc: 42.19%] [G loss: 0.974137]\n",
      "epoch:45 step:35661[D loss: 0.420158, acc: 62.50%, op_acc: 44.53%] [G loss: 0.819892]\n",
      "epoch:45 step:35662[D loss: 0.397487, acc: 64.84%, op_acc: 45.31%] [G loss: 0.910139]\n",
      "epoch:45 step:35663[D loss: 0.413280, acc: 64.84%, op_acc: 37.50%] [G loss: 0.950091]\n",
      "epoch:45 step:35664[D loss: 0.361679, acc: 75.00%, op_acc: 50.00%] [G loss: 0.874993]\n",
      "epoch:45 step:35665[D loss: 0.444212, acc: 57.81%, op_acc: 39.84%] [G loss: 0.902230]\n",
      "epoch:45 step:35666[D loss: 0.415453, acc: 55.47%, op_acc: 40.62%] [G loss: 0.959550]\n",
      "epoch:45 step:35667[D loss: 0.385870, acc: 61.72%, op_acc: 46.88%] [G loss: 0.930012]\n",
      "epoch:45 step:35668[D loss: 0.366760, acc: 63.28%, op_acc: 47.66%] [G loss: 1.005068]\n",
      "epoch:45 step:35669[D loss: 0.392819, acc: 68.75%, op_acc: 42.97%] [G loss: 1.044538]\n",
      "epoch:45 step:35670[D loss: 0.384462, acc: 67.97%, op_acc: 40.62%] [G loss: 1.037252]\n",
      "epoch:45 step:35671[D loss: 0.451564, acc: 59.38%, op_acc: 35.16%] [G loss: 0.949885]\n",
      "epoch:45 step:35672[D loss: 0.398199, acc: 64.06%, op_acc: 46.09%] [G loss: 0.873668]\n",
      "epoch:45 step:35673[D loss: 0.402024, acc: 70.31%, op_acc: 40.62%] [G loss: 0.948844]\n",
      "epoch:45 step:35674[D loss: 0.351195, acc: 73.44%, op_acc: 46.09%] [G loss: 1.008120]\n",
      "epoch:45 step:35675[D loss: 0.399434, acc: 65.62%, op_acc: 38.28%] [G loss: 1.014608]\n",
      "epoch:45 step:35676[D loss: 0.380549, acc: 74.22%, op_acc: 42.19%] [G loss: 0.981240]\n",
      "epoch:45 step:35677[D loss: 0.357964, acc: 73.44%, op_acc: 46.88%] [G loss: 0.942085]\n",
      "epoch:45 step:35678[D loss: 0.398801, acc: 66.41%, op_acc: 42.97%] [G loss: 1.008494]\n",
      "epoch:45 step:35679[D loss: 0.395171, acc: 63.28%, op_acc: 46.09%] [G loss: 0.813205]\n",
      "epoch:45 step:35680[D loss: 0.391370, acc: 64.84%, op_acc: 42.97%] [G loss: 0.860454]\n",
      "epoch:45 step:35681[D loss: 0.361174, acc: 66.41%, op_acc: 46.09%] [G loss: 0.980082]\n",
      "epoch:45 step:35682[D loss: 0.438407, acc: 61.72%, op_acc: 37.50%] [G loss: 0.805143]\n",
      "epoch:45 step:35683[D loss: 0.406372, acc: 60.94%, op_acc: 48.44%] [G loss: 0.877131]\n",
      "epoch:45 step:35684[D loss: 0.385646, acc: 70.31%, op_acc: 40.62%] [G loss: 0.905943]\n",
      "epoch:45 step:35685[D loss: 0.374494, acc: 69.53%, op_acc: 50.00%] [G loss: 0.952046]\n",
      "epoch:45 step:35686[D loss: 0.393176, acc: 59.38%, op_acc: 48.44%] [G loss: 0.942967]\n",
      "epoch:45 step:35687[D loss: 0.385985, acc: 65.62%, op_acc: 46.09%] [G loss: 0.869315]\n",
      "epoch:45 step:35688[D loss: 0.417856, acc: 64.06%, op_acc: 46.09%] [G loss: 0.797802]\n",
      "epoch:45 step:35689[D loss: 0.396476, acc: 61.72%, op_acc: 45.31%] [G loss: 0.891257]\n",
      "epoch:45 step:35690[D loss: 0.408820, acc: 64.06%, op_acc: 39.06%] [G loss: 0.906674]\n",
      "epoch:45 step:35691[D loss: 0.416086, acc: 56.25%, op_acc: 46.09%] [G loss: 0.797946]\n",
      "epoch:45 step:35692[D loss: 0.380892, acc: 67.19%, op_acc: 46.09%] [G loss: 0.920908]\n",
      "epoch:45 step:35693[D loss: 0.458680, acc: 55.47%, op_acc: 38.28%] [G loss: 0.981423]\n",
      "epoch:45 step:35694[D loss: 0.405920, acc: 59.38%, op_acc: 43.75%] [G loss: 0.948255]\n",
      "epoch:45 step:35695[D loss: 0.418257, acc: 57.03%, op_acc: 46.88%] [G loss: 0.970881]\n",
      "epoch:45 step:35696[D loss: 0.413930, acc: 57.03%, op_acc: 45.31%] [G loss: 0.866877]\n",
      "epoch:45 step:35697[D loss: 0.429514, acc: 61.72%, op_acc: 41.41%] [G loss: 0.957772]\n",
      "epoch:45 step:35698[D loss: 0.438963, acc: 51.56%, op_acc: 42.97%] [G loss: 0.796140]\n",
      "epoch:45 step:35699[D loss: 0.353016, acc: 72.66%, op_acc: 42.19%] [G loss: 1.038144]\n",
      "epoch:45 step:35700[D loss: 0.353787, acc: 68.75%, op_acc: 50.78%] [G loss: 0.859216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.8667821  0.85286084 0.80727769 0.82132842 0.78312785 0.82338148\n",
      " 0.88465212 0.83902755 0.80891685 0.8243617 ]\n",
      "##########\n",
      "epoch:45 step:35701[D loss: 0.386331, acc: 64.84%, op_acc: 45.31%] [G loss: 0.848262]\n",
      "epoch:45 step:35702[D loss: 0.439695, acc: 57.81%, op_acc: 41.41%] [G loss: 0.963624]\n",
      "epoch:45 step:35703[D loss: 0.399696, acc: 65.62%, op_acc: 47.66%] [G loss: 0.765499]\n",
      "epoch:45 step:35704[D loss: 0.376532, acc: 71.09%, op_acc: 38.28%] [G loss: 0.790671]\n",
      "epoch:45 step:35705[D loss: 0.398495, acc: 60.16%, op_acc: 44.53%] [G loss: 1.049765]\n",
      "epoch:45 step:35706[D loss: 0.411860, acc: 62.50%, op_acc: 42.19%] [G loss: 0.861827]\n",
      "epoch:45 step:35707[D loss: 0.469467, acc: 51.56%, op_acc: 38.28%] [G loss: 0.879098]\n",
      "epoch:45 step:35708[D loss: 0.396691, acc: 65.62%, op_acc: 39.84%] [G loss: 0.934853]\n",
      "epoch:45 step:35709[D loss: 0.393787, acc: 60.16%, op_acc: 46.88%] [G loss: 0.986530]\n",
      "epoch:45 step:35710[D loss: 0.380267, acc: 65.62%, op_acc: 50.00%] [G loss: 1.083658]\n",
      "epoch:45 step:35711[D loss: 0.407308, acc: 61.72%, op_acc: 42.19%] [G loss: 1.064915]\n",
      "epoch:45 step:35712[D loss: 0.391445, acc: 64.06%, op_acc: 48.44%] [G loss: 1.110382]\n",
      "epoch:45 step:35713[D loss: 0.424134, acc: 60.94%, op_acc: 44.53%] [G loss: 1.005238]\n",
      "epoch:45 step:35714[D loss: 0.385029, acc: 67.19%, op_acc: 44.53%] [G loss: 1.005334]\n",
      "epoch:45 step:35715[D loss: 0.423840, acc: 60.94%, op_acc: 38.28%] [G loss: 0.855357]\n",
      "epoch:45 step:35716[D loss: 0.373099, acc: 64.06%, op_acc: 50.00%] [G loss: 0.706564]\n",
      "epoch:45 step:35717[D loss: 0.427833, acc: 60.94%, op_acc: 42.19%] [G loss: 0.972710]\n",
      "epoch:45 step:35718[D loss: 0.398439, acc: 61.72%, op_acc: 43.75%] [G loss: 0.907623]\n",
      "epoch:45 step:35719[D loss: 0.399445, acc: 64.84%, op_acc: 43.75%] [G loss: 1.091303]\n",
      "epoch:45 step:35720[D loss: 0.419697, acc: 60.94%, op_acc: 40.62%] [G loss: 0.902979]\n",
      "epoch:45 step:35721[D loss: 0.354929, acc: 73.44%, op_acc: 46.09%] [G loss: 1.127278]\n",
      "epoch:45 step:35722[D loss: 0.432561, acc: 54.69%, op_acc: 49.22%] [G loss: 0.731659]\n",
      "epoch:45 step:35723[D loss: 0.398829, acc: 68.75%, op_acc: 41.41%] [G loss: 1.038338]\n",
      "epoch:45 step:35724[D loss: 0.358592, acc: 70.31%, op_acc: 46.88%] [G loss: 0.874850]\n",
      "epoch:45 step:35725[D loss: 0.382635, acc: 66.41%, op_acc: 50.00%] [G loss: 0.881422]\n",
      "epoch:45 step:35726[D loss: 0.376775, acc: 68.75%, op_acc: 46.09%] [G loss: 0.898315]\n",
      "epoch:45 step:35727[D loss: 0.422739, acc: 61.72%, op_acc: 43.75%] [G loss: 0.789638]\n",
      "epoch:45 step:35728[D loss: 0.388269, acc: 67.97%, op_acc: 41.41%] [G loss: 0.824401]\n",
      "epoch:45 step:35729[D loss: 0.428771, acc: 64.84%, op_acc: 39.06%] [G loss: 0.851692]\n",
      "epoch:45 step:35730[D loss: 0.362269, acc: 68.75%, op_acc: 45.31%] [G loss: 0.901541]\n",
      "epoch:45 step:35731[D loss: 0.383833, acc: 70.31%, op_acc: 43.75%] [G loss: 0.923083]\n",
      "epoch:45 step:35732[D loss: 0.367917, acc: 70.31%, op_acc: 45.31%] [G loss: 0.876106]\n",
      "epoch:45 step:35733[D loss: 0.351802, acc: 73.44%, op_acc: 52.34%] [G loss: 1.119557]\n",
      "epoch:45 step:35734[D loss: 0.405358, acc: 60.94%, op_acc: 41.41%] [G loss: 0.979739]\n",
      "epoch:45 step:35735[D loss: 0.369361, acc: 71.09%, op_acc: 50.00%] [G loss: 0.751659]\n",
      "epoch:45 step:35736[D loss: 0.385829, acc: 74.22%, op_acc: 42.19%] [G loss: 1.030283]\n",
      "epoch:45 step:35737[D loss: 0.384732, acc: 66.41%, op_acc: 39.84%] [G loss: 1.156473]\n",
      "epoch:45 step:35738[D loss: 0.381718, acc: 73.44%, op_acc: 45.31%] [G loss: 1.120382]\n",
      "epoch:45 step:35739[D loss: 0.402359, acc: 67.97%, op_acc: 39.84%] [G loss: 0.839757]\n",
      "epoch:45 step:35740[D loss: 0.385072, acc: 67.97%, op_acc: 39.06%] [G loss: 1.070623]\n",
      "epoch:45 step:35741[D loss: 0.389305, acc: 68.75%, op_acc: 42.19%] [G loss: 0.781329]\n",
      "epoch:45 step:35742[D loss: 0.404730, acc: 64.84%, op_acc: 45.31%] [G loss: 0.921221]\n",
      "epoch:45 step:35743[D loss: 0.445636, acc: 59.38%, op_acc: 40.62%] [G loss: 1.203010]\n",
      "epoch:45 step:35744[D loss: 0.429540, acc: 59.38%, op_acc: 39.06%] [G loss: 1.046013]\n",
      "epoch:45 step:35745[D loss: 0.402029, acc: 55.47%, op_acc: 40.62%] [G loss: 0.798160]\n",
      "epoch:45 step:35746[D loss: 0.449634, acc: 53.91%, op_acc: 45.31%] [G loss: 1.020084]\n",
      "epoch:45 step:35747[D loss: 0.412023, acc: 62.50%, op_acc: 46.09%] [G loss: 0.922116]\n",
      "epoch:45 step:35748[D loss: 0.393671, acc: 68.75%, op_acc: 42.97%] [G loss: 0.874207]\n",
      "epoch:45 step:35749[D loss: 0.436540, acc: 60.16%, op_acc: 42.19%] [G loss: 1.078857]\n",
      "epoch:45 step:35750[D loss: 0.396821, acc: 64.84%, op_acc: 40.62%] [G loss: 1.080282]\n",
      "##############\n",
      "[0.87018278 0.84288302 0.81944687 0.80044179 0.79876134 0.81488497\n",
      " 0.88906518 0.83070092 0.8157166  0.84140603]\n",
      "##########\n",
      "epoch:45 step:35751[D loss: 0.430135, acc: 62.50%, op_acc: 42.97%] [G loss: 1.076840]\n",
      "epoch:45 step:35752[D loss: 0.398540, acc: 60.16%, op_acc: 51.56%] [G loss: 0.909289]\n",
      "epoch:45 step:35753[D loss: 0.391448, acc: 66.41%, op_acc: 45.31%] [G loss: 1.044999]\n",
      "epoch:45 step:35754[D loss: 0.436505, acc: 56.25%, op_acc: 39.84%] [G loss: 0.910062]\n",
      "epoch:45 step:35755[D loss: 0.411331, acc: 61.72%, op_acc: 42.97%] [G loss: 0.975098]\n",
      "epoch:45 step:35756[D loss: 0.391359, acc: 69.53%, op_acc: 42.19%] [G loss: 1.058924]\n",
      "epoch:45 step:35757[D loss: 0.396378, acc: 63.28%, op_acc: 46.88%] [G loss: 0.897347]\n",
      "epoch:45 step:35758[D loss: 0.418038, acc: 64.06%, op_acc: 40.62%] [G loss: 0.907640]\n",
      "epoch:45 step:35759[D loss: 0.357908, acc: 71.88%, op_acc: 46.09%] [G loss: 0.839831]\n",
      "epoch:45 step:35760[D loss: 0.419147, acc: 60.16%, op_acc: 46.09%] [G loss: 0.762247]\n",
      "epoch:45 step:35761[D loss: 0.403935, acc: 65.62%, op_acc: 41.41%] [G loss: 0.829939]\n",
      "epoch:45 step:35762[D loss: 0.442488, acc: 54.69%, op_acc: 35.16%] [G loss: 1.060356]\n",
      "epoch:45 step:35763[D loss: 0.363828, acc: 67.19%, op_acc: 46.88%] [G loss: 1.196067]\n",
      "epoch:45 step:35764[D loss: 0.407582, acc: 63.28%, op_acc: 42.97%] [G loss: 0.785170]\n",
      "epoch:45 step:35765[D loss: 0.387856, acc: 73.44%, op_acc: 40.62%] [G loss: 0.838332]\n",
      "epoch:45 step:35766[D loss: 0.367260, acc: 72.66%, op_acc: 51.56%] [G loss: 0.829699]\n",
      "epoch:45 step:35767[D loss: 0.411898, acc: 64.06%, op_acc: 41.41%] [G loss: 0.704468]\n",
      "epoch:45 step:35768[D loss: 0.395966, acc: 67.19%, op_acc: 44.53%] [G loss: 0.988106]\n",
      "epoch:45 step:35769[D loss: 0.411339, acc: 57.03%, op_acc: 45.31%] [G loss: 0.896120]\n",
      "epoch:45 step:35770[D loss: 0.394827, acc: 66.41%, op_acc: 51.56%] [G loss: 1.111313]\n",
      "epoch:45 step:35771[D loss: 0.389790, acc: 68.75%, op_acc: 50.00%] [G loss: 0.829104]\n",
      "epoch:45 step:35772[D loss: 0.400565, acc: 64.06%, op_acc: 41.41%] [G loss: 0.869716]\n",
      "epoch:45 step:35773[D loss: 0.381192, acc: 70.31%, op_acc: 42.97%] [G loss: 0.934822]\n",
      "epoch:45 step:35774[D loss: 0.428557, acc: 66.41%, op_acc: 39.84%] [G loss: 0.995084]\n",
      "epoch:45 step:35775[D loss: 0.390726, acc: 69.53%, op_acc: 48.44%] [G loss: 0.817930]\n",
      "epoch:45 step:35776[D loss: 0.423522, acc: 64.84%, op_acc: 39.06%] [G loss: 1.059786]\n",
      "epoch:45 step:35777[D loss: 0.396729, acc: 66.41%, op_acc: 40.62%] [G loss: 0.855781]\n",
      "epoch:45 step:35778[D loss: 0.396292, acc: 66.41%, op_acc: 42.97%] [G loss: 0.852081]\n",
      "epoch:45 step:35779[D loss: 0.357136, acc: 71.09%, op_acc: 47.66%] [G loss: 1.007331]\n",
      "epoch:45 step:35780[D loss: 0.435601, acc: 58.59%, op_acc: 39.06%] [G loss: 0.834025]\n",
      "epoch:45 step:35781[D loss: 0.381109, acc: 68.75%, op_acc: 45.31%] [G loss: 0.850435]\n",
      "epoch:45 step:35782[D loss: 0.356348, acc: 73.44%, op_acc: 45.31%] [G loss: 1.024086]\n",
      "epoch:45 step:35783[D loss: 0.374445, acc: 71.88%, op_acc: 50.00%] [G loss: 1.051952]\n",
      "epoch:45 step:35784[D loss: 0.440767, acc: 57.03%, op_acc: 40.62%] [G loss: 0.747756]\n",
      "epoch:45 step:35785[D loss: 0.401956, acc: 67.97%, op_acc: 42.19%] [G loss: 1.072815]\n",
      "epoch:45 step:35786[D loss: 0.392559, acc: 64.84%, op_acc: 42.19%] [G loss: 0.787590]\n",
      "epoch:45 step:35787[D loss: 0.404834, acc: 64.84%, op_acc: 42.97%] [G loss: 0.763861]\n",
      "epoch:45 step:35788[D loss: 0.393688, acc: 69.53%, op_acc: 41.41%] [G loss: 0.671475]\n",
      "epoch:45 step:35789[D loss: 0.357530, acc: 68.75%, op_acc: 46.09%] [G loss: 1.079831]\n",
      "epoch:45 step:35790[D loss: 0.380910, acc: 67.19%, op_acc: 45.31%] [G loss: 0.932444]\n",
      "epoch:45 step:35791[D loss: 0.366549, acc: 73.44%, op_acc: 48.44%] [G loss: 1.175974]\n",
      "epoch:45 step:35792[D loss: 0.379244, acc: 65.62%, op_acc: 47.66%] [G loss: 0.881490]\n",
      "epoch:45 step:35793[D loss: 0.398099, acc: 65.62%, op_acc: 42.97%] [G loss: 0.922436]\n",
      "epoch:45 step:35794[D loss: 0.368851, acc: 71.09%, op_acc: 46.88%] [G loss: 1.094014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35795[D loss: 0.421636, acc: 62.50%, op_acc: 40.62%] [G loss: 1.110800]\n",
      "epoch:45 step:35796[D loss: 0.401742, acc: 59.38%, op_acc: 40.62%] [G loss: 0.836831]\n",
      "epoch:45 step:35797[D loss: 0.346126, acc: 73.44%, op_acc: 50.00%] [G loss: 0.829564]\n",
      "epoch:45 step:35798[D loss: 0.393796, acc: 65.62%, op_acc: 47.66%] [G loss: 0.815234]\n",
      "epoch:45 step:35799[D loss: 0.372820, acc: 66.41%, op_acc: 45.31%] [G loss: 0.865221]\n",
      "epoch:45 step:35800[D loss: 0.381345, acc: 70.31%, op_acc: 46.88%] [G loss: 0.848468]\n",
      "##############\n",
      "[0.84825609 0.87332423 0.79845166 0.80675962 0.83297631 0.8226538\n",
      " 0.88606225 0.83014274 0.81036532 0.84064112]\n",
      "##########\n",
      "epoch:45 step:35801[D loss: 0.409299, acc: 60.94%, op_acc: 44.53%] [G loss: 0.941587]\n",
      "epoch:45 step:35802[D loss: 0.408769, acc: 65.62%, op_acc: 39.84%] [G loss: 0.834520]\n",
      "epoch:45 step:35803[D loss: 0.373540, acc: 72.66%, op_acc: 37.50%] [G loss: 0.918376]\n",
      "epoch:45 step:35804[D loss: 0.423035, acc: 64.06%, op_acc: 41.41%] [G loss: 1.045342]\n",
      "epoch:45 step:35805[D loss: 0.382646, acc: 64.06%, op_acc: 49.22%] [G loss: 1.115827]\n",
      "epoch:45 step:35806[D loss: 0.373091, acc: 64.06%, op_acc: 46.09%] [G loss: 0.844566]\n",
      "epoch:45 step:35807[D loss: 0.395428, acc: 58.59%, op_acc: 39.84%] [G loss: 0.835276]\n",
      "epoch:45 step:35808[D loss: 0.423336, acc: 55.47%, op_acc: 46.09%] [G loss: 0.881099]\n",
      "epoch:45 step:35809[D loss: 0.368709, acc: 74.22%, op_acc: 45.31%] [G loss: 0.921225]\n",
      "epoch:45 step:35810[D loss: 0.421682, acc: 62.50%, op_acc: 36.72%] [G loss: 0.975269]\n",
      "epoch:45 step:35811[D loss: 0.417312, acc: 57.03%, op_acc: 42.97%] [G loss: 0.992060]\n",
      "epoch:45 step:35812[D loss: 0.410490, acc: 61.72%, op_acc: 44.53%] [G loss: 0.896031]\n",
      "epoch:45 step:35813[D loss: 0.443146, acc: 53.91%, op_acc: 44.53%] [G loss: 0.843077]\n",
      "epoch:45 step:35814[D loss: 0.413294, acc: 58.59%, op_acc: 43.75%] [G loss: 0.958709]\n",
      "epoch:45 step:35815[D loss: 0.435337, acc: 52.34%, op_acc: 41.41%] [G loss: 0.673652]\n",
      "epoch:45 step:35816[D loss: 0.453494, acc: 57.03%, op_acc: 35.94%] [G loss: 1.009606]\n",
      "epoch:45 step:35817[D loss: 0.410104, acc: 71.09%, op_acc: 37.50%] [G loss: 0.863381]\n",
      "epoch:45 step:35818[D loss: 0.366626, acc: 72.66%, op_acc: 43.75%] [G loss: 0.760707]\n",
      "epoch:45 step:35819[D loss: 0.415184, acc: 60.16%, op_acc: 43.75%] [G loss: 0.776398]\n",
      "epoch:45 step:35820[D loss: 0.356054, acc: 75.00%, op_acc: 47.66%] [G loss: 0.812994]\n",
      "epoch:45 step:35821[D loss: 0.442025, acc: 58.59%, op_acc: 38.28%] [G loss: 1.063972]\n",
      "epoch:45 step:35822[D loss: 0.449374, acc: 56.25%, op_acc: 40.62%] [G loss: 0.763548]\n",
      "epoch:45 step:35823[D loss: 0.354718, acc: 69.53%, op_acc: 46.88%] [G loss: 1.090983]\n",
      "epoch:45 step:35824[D loss: 0.374281, acc: 66.41%, op_acc: 46.09%] [G loss: 1.071035]\n",
      "epoch:45 step:35825[D loss: 0.416902, acc: 63.28%, op_acc: 39.06%] [G loss: 0.718223]\n",
      "epoch:45 step:35826[D loss: 0.405803, acc: 66.41%, op_acc: 41.41%] [G loss: 1.103794]\n",
      "epoch:45 step:35827[D loss: 0.396245, acc: 60.16%, op_acc: 45.31%] [G loss: 1.066526]\n",
      "epoch:45 step:35828[D loss: 0.340129, acc: 72.66%, op_acc: 43.75%] [G loss: 1.007785]\n",
      "epoch:45 step:35829[D loss: 0.415263, acc: 61.72%, op_acc: 46.09%] [G loss: 1.046154]\n",
      "epoch:45 step:35830[D loss: 0.403140, acc: 67.19%, op_acc: 44.53%] [G loss: 0.734672]\n",
      "epoch:45 step:35831[D loss: 0.402725, acc: 64.06%, op_acc: 43.75%] [G loss: 0.698017]\n",
      "epoch:45 step:35832[D loss: 0.383892, acc: 63.28%, op_acc: 49.22%] [G loss: 1.013454]\n",
      "epoch:45 step:35833[D loss: 0.454440, acc: 55.47%, op_acc: 35.94%] [G loss: 0.644697]\n",
      "epoch:45 step:35834[D loss: 0.389848, acc: 64.84%, op_acc: 46.88%] [G loss: 0.901167]\n",
      "epoch:45 step:35835[D loss: 0.402627, acc: 68.75%, op_acc: 40.62%] [G loss: 0.702339]\n",
      "epoch:45 step:35836[D loss: 0.412463, acc: 65.62%, op_acc: 48.44%] [G loss: 0.616990]\n",
      "epoch:45 step:35837[D loss: 0.392169, acc: 69.53%, op_acc: 37.50%] [G loss: 0.773224]\n",
      "epoch:45 step:35838[D loss: 0.399700, acc: 60.94%, op_acc: 42.97%] [G loss: 1.175617]\n",
      "epoch:45 step:35839[D loss: 0.403381, acc: 66.41%, op_acc: 38.28%] [G loss: 1.088627]\n",
      "epoch:45 step:35840[D loss: 0.375301, acc: 65.62%, op_acc: 41.41%] [G loss: 0.729282]\n",
      "epoch:45 step:35841[D loss: 0.426278, acc: 59.38%, op_acc: 35.94%] [G loss: 0.998674]\n",
      "epoch:45 step:35842[D loss: 0.400202, acc: 61.72%, op_acc: 50.78%] [G loss: 0.764387]\n",
      "epoch:45 step:35843[D loss: 0.373350, acc: 69.53%, op_acc: 41.41%] [G loss: 1.026879]\n",
      "epoch:45 step:35844[D loss: 0.378604, acc: 67.19%, op_acc: 42.19%] [G loss: 1.103602]\n",
      "epoch:45 step:35845[D loss: 0.397268, acc: 61.72%, op_acc: 42.19%] [G loss: 0.968433]\n",
      "epoch:45 step:35846[D loss: 0.365878, acc: 75.00%, op_acc: 40.62%] [G loss: 0.741817]\n",
      "epoch:45 step:35847[D loss: 0.410794, acc: 56.25%, op_acc: 46.88%] [G loss: 0.762312]\n",
      "epoch:45 step:35848[D loss: 0.439931, acc: 55.47%, op_acc: 35.94%] [G loss: 0.698531]\n",
      "epoch:45 step:35849[D loss: 0.345901, acc: 71.09%, op_acc: 54.69%] [G loss: 1.152054]\n",
      "epoch:45 step:35850[D loss: 0.427359, acc: 59.38%, op_acc: 42.97%] [G loss: 0.779996]\n",
      "##############\n",
      "[0.87106766 0.85202492 0.80910161 0.79641259 0.7938258  0.82733827\n",
      " 0.87086755 0.83401122 0.82147381 0.82790815]\n",
      "##########\n",
      "epoch:45 step:35851[D loss: 0.366023, acc: 69.53%, op_acc: 43.75%] [G loss: 0.859022]\n",
      "epoch:45 step:35852[D loss: 0.457804, acc: 53.91%, op_acc: 42.97%] [G loss: 0.870581]\n",
      "epoch:45 step:35853[D loss: 0.415031, acc: 60.94%, op_acc: 40.62%] [G loss: 0.840084]\n",
      "epoch:45 step:35854[D loss: 0.401241, acc: 62.50%, op_acc: 45.31%] [G loss: 0.996332]\n",
      "epoch:45 step:35855[D loss: 0.364465, acc: 64.84%, op_acc: 55.47%] [G loss: 0.935855]\n",
      "epoch:45 step:35856[D loss: 0.382562, acc: 67.19%, op_acc: 46.09%] [G loss: 0.976690]\n",
      "epoch:45 step:35857[D loss: 0.425587, acc: 57.03%, op_acc: 41.41%] [G loss: 0.778338]\n",
      "epoch:45 step:35858[D loss: 0.418364, acc: 57.03%, op_acc: 39.84%] [G loss: 0.942634]\n",
      "epoch:45 step:35859[D loss: 0.402254, acc: 66.41%, op_acc: 35.94%] [G loss: 0.946745]\n",
      "epoch:45 step:35860[D loss: 0.428557, acc: 58.59%, op_acc: 38.28%] [G loss: 0.766998]\n",
      "epoch:45 step:35861[D loss: 0.397715, acc: 61.72%, op_acc: 43.75%] [G loss: 1.032711]\n",
      "epoch:45 step:35862[D loss: 0.434583, acc: 53.91%, op_acc: 38.28%] [G loss: 0.873783]\n",
      "epoch:45 step:35863[D loss: 0.391279, acc: 64.06%, op_acc: 45.31%] [G loss: 0.930266]\n",
      "epoch:45 step:35864[D loss: 0.391337, acc: 67.97%, op_acc: 42.97%] [G loss: 1.179423]\n",
      "epoch:45 step:35865[D loss: 0.395400, acc: 67.19%, op_acc: 43.75%] [G loss: 1.008735]\n",
      "epoch:45 step:35866[D loss: 0.402289, acc: 60.94%, op_acc: 48.44%] [G loss: 1.058321]\n",
      "epoch:45 step:35867[D loss: 0.387611, acc: 63.28%, op_acc: 43.75%] [G loss: 0.837978]\n",
      "epoch:45 step:35868[D loss: 0.421470, acc: 61.72%, op_acc: 45.31%] [G loss: 0.878498]\n",
      "epoch:45 step:35869[D loss: 0.402723, acc: 67.97%, op_acc: 41.41%] [G loss: 0.801058]\n",
      "epoch:45 step:35870[D loss: 0.386778, acc: 66.41%, op_acc: 42.19%] [G loss: 0.811327]\n",
      "epoch:45 step:35871[D loss: 0.369066, acc: 64.06%, op_acc: 44.53%] [G loss: 1.001645]\n",
      "epoch:45 step:35872[D loss: 0.424818, acc: 60.94%, op_acc: 39.84%] [G loss: 0.786781]\n",
      "epoch:45 step:35873[D loss: 0.408662, acc: 61.72%, op_acc: 43.75%] [G loss: 0.870180]\n",
      "epoch:45 step:35874[D loss: 0.402072, acc: 58.59%, op_acc: 44.53%] [G loss: 1.066321]\n",
      "epoch:45 step:35875[D loss: 0.371295, acc: 69.53%, op_acc: 49.22%] [G loss: 0.919255]\n",
      "epoch:45 step:35876[D loss: 0.351863, acc: 71.09%, op_acc: 50.00%] [G loss: 0.965653]\n",
      "epoch:45 step:35877[D loss: 0.371569, acc: 70.31%, op_acc: 46.09%] [G loss: 0.894413]\n",
      "epoch:45 step:35878[D loss: 0.336016, acc: 76.56%, op_acc: 49.22%] [G loss: 0.946696]\n",
      "epoch:45 step:35879[D loss: 0.404455, acc: 62.50%, op_acc: 41.41%] [G loss: 0.951014]\n",
      "epoch:45 step:35880[D loss: 0.393731, acc: 63.28%, op_acc: 43.75%] [G loss: 0.928703]\n",
      "epoch:45 step:35881[D loss: 0.383417, acc: 70.31%, op_acc: 40.62%] [G loss: 1.073277]\n",
      "epoch:45 step:35882[D loss: 0.371943, acc: 61.72%, op_acc: 49.22%] [G loss: 0.907391]\n",
      "epoch:45 step:35883[D loss: 0.395516, acc: 65.62%, op_acc: 41.41%] [G loss: 1.161857]\n",
      "epoch:45 step:35884[D loss: 0.422978, acc: 63.28%, op_acc: 37.50%] [G loss: 0.836295]\n",
      "epoch:45 step:35885[D loss: 0.434525, acc: 55.47%, op_acc: 41.41%] [G loss: 0.748782]\n",
      "epoch:45 step:35886[D loss: 0.378595, acc: 71.09%, op_acc: 42.19%] [G loss: 0.836791]\n",
      "epoch:45 step:35887[D loss: 0.358729, acc: 72.66%, op_acc: 49.22%] [G loss: 0.889650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35888[D loss: 0.360909, acc: 67.19%, op_acc: 51.56%] [G loss: 1.209846]\n",
      "epoch:45 step:35889[D loss: 0.337700, acc: 72.66%, op_acc: 51.56%] [G loss: 0.962178]\n",
      "epoch:45 step:35890[D loss: 0.365387, acc: 70.31%, op_acc: 47.66%] [G loss: 0.989778]\n",
      "epoch:45 step:35891[D loss: 0.399702, acc: 64.06%, op_acc: 45.31%] [G loss: 0.929128]\n",
      "epoch:45 step:35892[D loss: 0.431565, acc: 57.03%, op_acc: 40.62%] [G loss: 0.797710]\n",
      "epoch:45 step:35893[D loss: 0.405353, acc: 65.62%, op_acc: 36.72%] [G loss: 0.774213]\n",
      "epoch:45 step:35894[D loss: 0.428155, acc: 60.94%, op_acc: 38.28%] [G loss: 0.836721]\n",
      "epoch:45 step:35895[D loss: 0.424538, acc: 64.84%, op_acc: 37.50%] [G loss: 0.963711]\n",
      "epoch:45 step:35896[D loss: 0.392172, acc: 71.88%, op_acc: 42.97%] [G loss: 1.079072]\n",
      "epoch:45 step:35897[D loss: 0.420984, acc: 60.94%, op_acc: 43.75%] [G loss: 1.083234]\n",
      "epoch:45 step:35898[D loss: 0.389888, acc: 68.75%, op_acc: 42.19%] [G loss: 1.021290]\n",
      "epoch:45 step:35899[D loss: 0.358228, acc: 71.09%, op_acc: 46.09%] [G loss: 0.994931]\n",
      "epoch:45 step:35900[D loss: 0.338789, acc: 70.31%, op_acc: 56.25%] [G loss: 0.979221]\n",
      "##############\n",
      "[0.85593446 0.86549215 0.80116239 0.80516798 0.81725284 0.83543655\n",
      " 0.89377073 0.8464515  0.80250117 0.82176544]\n",
      "##########\n",
      "epoch:45 step:35901[D loss: 0.368053, acc: 70.31%, op_acc: 53.91%] [G loss: 1.031008]\n",
      "epoch:45 step:35902[D loss: 0.365666, acc: 67.97%, op_acc: 46.09%] [G loss: 1.092000]\n",
      "epoch:45 step:35903[D loss: 0.363675, acc: 64.06%, op_acc: 49.22%] [G loss: 0.877006]\n",
      "epoch:45 step:35904[D loss: 0.384543, acc: 63.28%, op_acc: 42.19%] [G loss: 0.989948]\n",
      "epoch:45 step:35905[D loss: 0.380209, acc: 66.41%, op_acc: 44.53%] [G loss: 0.911075]\n",
      "epoch:45 step:35906[D loss: 0.423963, acc: 53.91%, op_acc: 42.97%] [G loss: 0.957100]\n",
      "epoch:45 step:35907[D loss: 0.404386, acc: 63.28%, op_acc: 43.75%] [G loss: 0.897297]\n",
      "epoch:45 step:35908[D loss: 0.402084, acc: 56.25%, op_acc: 47.66%] [G loss: 0.903026]\n",
      "epoch:45 step:35909[D loss: 0.405569, acc: 63.28%, op_acc: 41.41%] [G loss: 0.851532]\n",
      "epoch:45 step:35910[D loss: 0.374529, acc: 70.31%, op_acc: 45.31%] [G loss: 0.915714]\n",
      "epoch:45 step:35911[D loss: 0.388243, acc: 63.28%, op_acc: 50.78%] [G loss: 0.966896]\n",
      "epoch:45 step:35912[D loss: 0.359050, acc: 69.53%, op_acc: 46.09%] [G loss: 0.993776]\n",
      "epoch:45 step:35913[D loss: 0.386005, acc: 65.62%, op_acc: 44.53%] [G loss: 0.844257]\n",
      "epoch:45 step:35914[D loss: 0.353488, acc: 74.22%, op_acc: 49.22%] [G loss: 0.927798]\n",
      "epoch:45 step:35915[D loss: 0.419191, acc: 65.62%, op_acc: 42.97%] [G loss: 0.936843]\n",
      "epoch:45 step:35916[D loss: 0.457219, acc: 61.72%, op_acc: 38.28%] [G loss: 0.894316]\n",
      "epoch:45 step:35917[D loss: 0.399442, acc: 62.50%, op_acc: 43.75%] [G loss: 0.917565]\n",
      "epoch:45 step:35918[D loss: 0.386321, acc: 65.62%, op_acc: 45.31%] [G loss: 0.984478]\n",
      "epoch:45 step:35919[D loss: 0.376391, acc: 71.09%, op_acc: 39.06%] [G loss: 0.939517]\n",
      "epoch:45 step:35920[D loss: 0.384324, acc: 69.53%, op_acc: 45.31%] [G loss: 0.984701]\n",
      "epoch:45 step:35921[D loss: 0.365157, acc: 69.53%, op_acc: 46.09%] [G loss: 1.103193]\n",
      "epoch:45 step:35922[D loss: 0.420588, acc: 60.16%, op_acc: 39.06%] [G loss: 1.114195]\n",
      "epoch:45 step:35923[D loss: 0.352652, acc: 73.44%, op_acc: 45.31%] [G loss: 1.184232]\n",
      "epoch:45 step:35924[D loss: 0.386657, acc: 66.41%, op_acc: 47.66%] [G loss: 1.140697]\n",
      "epoch:45 step:35925[D loss: 0.378566, acc: 68.75%, op_acc: 49.22%] [G loss: 0.945735]\n",
      "epoch:45 step:35926[D loss: 0.360044, acc: 71.88%, op_acc: 42.19%] [G loss: 1.016872]\n",
      "epoch:46 step:35927[D loss: 0.348713, acc: 74.22%, op_acc: 50.78%] [G loss: 1.023988]\n",
      "epoch:46 step:35928[D loss: 0.335986, acc: 72.66%, op_acc: 53.12%] [G loss: 1.181907]\n",
      "epoch:46 step:35929[D loss: 0.403763, acc: 62.50%, op_acc: 44.53%] [G loss: 0.644425]\n",
      "epoch:46 step:35930[D loss: 0.428548, acc: 57.81%, op_acc: 44.53%] [G loss: 1.152693]\n",
      "epoch:46 step:35931[D loss: 0.425513, acc: 64.06%, op_acc: 40.62%] [G loss: 0.820698]\n",
      "epoch:46 step:35932[D loss: 0.426134, acc: 58.59%, op_acc: 39.84%] [G loss: 0.820175]\n",
      "epoch:46 step:35933[D loss: 0.388388, acc: 70.31%, op_acc: 46.88%] [G loss: 0.973033]\n",
      "epoch:46 step:35934[D loss: 0.418242, acc: 60.16%, op_acc: 39.06%] [G loss: 1.183246]\n",
      "epoch:46 step:35935[D loss: 0.403432, acc: 52.34%, op_acc: 45.31%] [G loss: 0.996847]\n",
      "epoch:46 step:35936[D loss: 0.432233, acc: 61.72%, op_acc: 39.06%] [G loss: 0.885057]\n",
      "epoch:46 step:35937[D loss: 0.441777, acc: 57.81%, op_acc: 42.19%] [G loss: 0.920580]\n",
      "epoch:46 step:35938[D loss: 0.425758, acc: 65.62%, op_acc: 42.19%] [G loss: 0.951355]\n",
      "epoch:46 step:35939[D loss: 0.378683, acc: 66.41%, op_acc: 47.66%] [G loss: 0.899785]\n",
      "epoch:46 step:35940[D loss: 0.426249, acc: 60.16%, op_acc: 43.75%] [G loss: 1.078562]\n",
      "epoch:46 step:35941[D loss: 0.428581, acc: 56.25%, op_acc: 39.84%] [G loss: 0.889985]\n",
      "epoch:46 step:35942[D loss: 0.418376, acc: 57.81%, op_acc: 39.84%] [G loss: 0.973251]\n",
      "epoch:46 step:35943[D loss: 0.399781, acc: 63.28%, op_acc: 39.84%] [G loss: 0.978807]\n",
      "epoch:46 step:35944[D loss: 0.424320, acc: 61.72%, op_acc: 43.75%] [G loss: 0.852146]\n",
      "epoch:46 step:35945[D loss: 0.418237, acc: 60.16%, op_acc: 43.75%] [G loss: 1.044686]\n",
      "epoch:46 step:35946[D loss: 0.391582, acc: 63.28%, op_acc: 42.19%] [G loss: 1.061649]\n",
      "epoch:46 step:35947[D loss: 0.377169, acc: 70.31%, op_acc: 42.97%] [G loss: 1.154233]\n",
      "epoch:46 step:35948[D loss: 0.412659, acc: 58.59%, op_acc: 44.53%] [G loss: 0.760881]\n",
      "epoch:46 step:35949[D loss: 0.371442, acc: 65.62%, op_acc: 40.62%] [G loss: 0.804601]\n",
      "epoch:46 step:35950[D loss: 0.397704, acc: 61.72%, op_acc: 45.31%] [G loss: 1.001864]\n",
      "##############\n",
      "[0.85768767 0.85853407 0.80764322 0.79704147 0.80112894 0.84039517\n",
      " 0.87796449 0.82236761 0.79900678 0.82376918]\n",
      "##########\n",
      "epoch:46 step:35951[D loss: 0.475478, acc: 50.78%, op_acc: 39.84%] [G loss: 0.838236]\n",
      "epoch:46 step:35952[D loss: 0.376169, acc: 64.06%, op_acc: 46.88%] [G loss: 0.798145]\n",
      "epoch:46 step:35953[D loss: 0.429381, acc: 60.94%, op_acc: 44.53%] [G loss: 0.763041]\n",
      "epoch:46 step:35954[D loss: 0.386982, acc: 62.50%, op_acc: 44.53%] [G loss: 0.834471]\n",
      "epoch:46 step:35955[D loss: 0.382554, acc: 64.84%, op_acc: 46.88%] [G loss: 1.094508]\n",
      "epoch:46 step:35956[D loss: 0.377814, acc: 64.84%, op_acc: 50.78%] [G loss: 1.084532]\n",
      "epoch:46 step:35957[D loss: 0.436129, acc: 57.81%, op_acc: 42.19%] [G loss: 0.952294]\n",
      "epoch:46 step:35958[D loss: 0.411363, acc: 64.84%, op_acc: 42.97%] [G loss: 1.082913]\n",
      "epoch:46 step:35959[D loss: 0.361099, acc: 65.62%, op_acc: 46.88%] [G loss: 0.871983]\n",
      "epoch:46 step:35960[D loss: 0.421296, acc: 58.59%, op_acc: 37.50%] [G loss: 0.858625]\n",
      "epoch:46 step:35961[D loss: 0.376891, acc: 72.66%, op_acc: 43.75%] [G loss: 0.889322]\n",
      "epoch:46 step:35962[D loss: 0.370640, acc: 71.09%, op_acc: 43.75%] [G loss: 0.987276]\n",
      "epoch:46 step:35963[D loss: 0.338382, acc: 77.34%, op_acc: 46.88%] [G loss: 1.193068]\n",
      "epoch:46 step:35964[D loss: 0.417600, acc: 57.03%, op_acc: 48.44%] [G loss: 1.072016]\n",
      "epoch:46 step:35965[D loss: 0.399135, acc: 53.91%, op_acc: 43.75%] [G loss: 0.809197]\n",
      "epoch:46 step:35966[D loss: 0.427933, acc: 57.81%, op_acc: 41.41%] [G loss: 0.926915]\n",
      "epoch:46 step:35967[D loss: 0.382719, acc: 64.84%, op_acc: 43.75%] [G loss: 0.921939]\n",
      "epoch:46 step:35968[D loss: 0.352503, acc: 67.19%, op_acc: 46.09%] [G loss: 0.796133]\n",
      "epoch:46 step:35969[D loss: 0.357756, acc: 67.19%, op_acc: 43.75%] [G loss: 0.798143]\n",
      "epoch:46 step:35970[D loss: 0.416014, acc: 62.50%, op_acc: 42.97%] [G loss: 0.796289]\n",
      "epoch:46 step:35971[D loss: 0.358342, acc: 78.91%, op_acc: 47.66%] [G loss: 1.127851]\n",
      "epoch:46 step:35972[D loss: 0.405058, acc: 60.94%, op_acc: 44.53%] [G loss: 0.629711]\n",
      "epoch:46 step:35973[D loss: 0.408808, acc: 56.25%, op_acc: 44.53%] [G loss: 0.924379]\n",
      "epoch:46 step:35974[D loss: 0.469631, acc: 54.69%, op_acc: 36.72%] [G loss: 0.908776]\n",
      "epoch:46 step:35975[D loss: 0.368823, acc: 69.53%, op_acc: 48.44%] [G loss: 0.668964]\n",
      "epoch:46 step:35976[D loss: 0.408842, acc: 60.94%, op_acc: 45.31%] [G loss: 1.020740]\n",
      "epoch:46 step:35977[D loss: 0.373089, acc: 69.53%, op_acc: 49.22%] [G loss: 0.755526]\n",
      "epoch:46 step:35978[D loss: 0.402047, acc: 72.66%, op_acc: 44.53%] [G loss: 0.752179]\n",
      "epoch:46 step:35979[D loss: 0.463058, acc: 60.94%, op_acc: 36.72%] [G loss: 0.898960]\n",
      "epoch:46 step:35980[D loss: 0.421036, acc: 63.28%, op_acc: 40.62%] [G loss: 0.815655]\n",
      "epoch:46 step:35981[D loss: 0.384653, acc: 62.50%, op_acc: 47.66%] [G loss: 0.650585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:35982[D loss: 0.453946, acc: 54.69%, op_acc: 40.62%] [G loss: 0.849093]\n",
      "epoch:46 step:35983[D loss: 0.390786, acc: 64.06%, op_acc: 42.19%] [G loss: 1.017665]\n",
      "epoch:46 step:35984[D loss: 0.384023, acc: 64.06%, op_acc: 50.00%] [G loss: 0.715194]\n",
      "epoch:46 step:35985[D loss: 0.354064, acc: 71.09%, op_acc: 50.00%] [G loss: 0.803879]\n",
      "epoch:46 step:35986[D loss: 0.418278, acc: 64.84%, op_acc: 39.06%] [G loss: 0.745662]\n",
      "epoch:46 step:35987[D loss: 0.387467, acc: 73.44%, op_acc: 39.84%] [G loss: 0.764600]\n",
      "epoch:46 step:35988[D loss: 0.368384, acc: 73.44%, op_acc: 43.75%] [G loss: 0.978103]\n",
      "epoch:46 step:35989[D loss: 0.436064, acc: 57.81%, op_acc: 44.53%] [G loss: 0.707675]\n",
      "epoch:46 step:35990[D loss: 0.381051, acc: 61.72%, op_acc: 42.97%] [G loss: 0.903695]\n",
      "epoch:46 step:35991[D loss: 0.392774, acc: 64.06%, op_acc: 37.50%] [G loss: 1.025313]\n",
      "epoch:46 step:35992[D loss: 0.375742, acc: 70.31%, op_acc: 46.88%] [G loss: 1.005222]\n",
      "epoch:46 step:35993[D loss: 0.353335, acc: 72.66%, op_acc: 45.31%] [G loss: 0.919482]\n",
      "epoch:46 step:35994[D loss: 0.413053, acc: 58.59%, op_acc: 47.66%] [G loss: 1.055609]\n",
      "epoch:46 step:35995[D loss: 0.382518, acc: 67.19%, op_acc: 51.56%] [G loss: 0.917773]\n",
      "epoch:46 step:35996[D loss: 0.403977, acc: 62.50%, op_acc: 46.09%] [G loss: 0.805983]\n",
      "epoch:46 step:35997[D loss: 0.426311, acc: 60.16%, op_acc: 42.97%] [G loss: 0.903629]\n",
      "epoch:46 step:35998[D loss: 0.405125, acc: 64.06%, op_acc: 42.19%] [G loss: 0.942386]\n",
      "epoch:46 step:35999[D loss: 0.417937, acc: 63.28%, op_acc: 43.75%] [G loss: 0.998091]\n",
      "epoch:46 step:36000[D loss: 0.386231, acc: 65.62%, op_acc: 42.19%] [G loss: 0.942732]\n",
      "##############\n",
      "[0.86783372 0.83451852 0.82239923 0.81241754 0.79325154 0.83557281\n",
      " 0.88350528 0.81341906 0.82693896 0.83616927]\n",
      "##########\n",
      "epoch:46 step:36001[D loss: 0.366314, acc: 70.31%, op_acc: 46.88%] [G loss: 0.925808]\n",
      "epoch:46 step:36002[D loss: 0.421180, acc: 60.94%, op_acc: 45.31%] [G loss: 1.028570]\n",
      "epoch:46 step:36003[D loss: 0.386001, acc: 67.19%, op_acc: 43.75%] [G loss: 1.012206]\n",
      "epoch:46 step:36004[D loss: 0.416161, acc: 68.75%, op_acc: 37.50%] [G loss: 0.931289]\n",
      "epoch:46 step:36005[D loss: 0.349586, acc: 71.09%, op_acc: 53.91%] [G loss: 1.186435]\n",
      "epoch:46 step:36006[D loss: 0.405535, acc: 64.06%, op_acc: 40.62%] [G loss: 0.819970]\n",
      "epoch:46 step:36007[D loss: 0.419354, acc: 65.62%, op_acc: 34.38%] [G loss: 0.988620]\n",
      "epoch:46 step:36008[D loss: 0.407074, acc: 65.62%, op_acc: 44.53%] [G loss: 1.127369]\n",
      "epoch:46 step:36009[D loss: 0.437840, acc: 57.03%, op_acc: 42.97%] [G loss: 0.850753]\n",
      "epoch:46 step:36010[D loss: 0.415466, acc: 59.38%, op_acc: 44.53%] [G loss: 0.950125]\n",
      "epoch:46 step:36011[D loss: 0.411873, acc: 65.62%, op_acc: 43.75%] [G loss: 0.964262]\n",
      "epoch:46 step:36012[D loss: 0.379322, acc: 66.41%, op_acc: 42.97%] [G loss: 1.009182]\n",
      "epoch:46 step:36013[D loss: 0.441899, acc: 56.25%, op_acc: 40.62%] [G loss: 0.912875]\n",
      "epoch:46 step:36014[D loss: 0.406334, acc: 61.72%, op_acc: 37.50%] [G loss: 0.837762]\n",
      "epoch:46 step:36015[D loss: 0.423390, acc: 64.06%, op_acc: 42.19%] [G loss: 0.934970]\n",
      "epoch:46 step:36016[D loss: 0.396113, acc: 60.16%, op_acc: 45.31%] [G loss: 0.957529]\n",
      "epoch:46 step:36017[D loss: 0.361670, acc: 68.75%, op_acc: 48.44%] [G loss: 0.906673]\n",
      "epoch:46 step:36018[D loss: 0.429180, acc: 60.16%, op_acc: 46.09%] [G loss: 0.962392]\n",
      "epoch:46 step:36019[D loss: 0.400216, acc: 61.72%, op_acc: 48.44%] [G loss: 0.920286]\n",
      "epoch:46 step:36020[D loss: 0.396357, acc: 60.94%, op_acc: 42.97%] [G loss: 0.833538]\n",
      "epoch:46 step:36021[D loss: 0.370462, acc: 71.09%, op_acc: 45.31%] [G loss: 0.963388]\n",
      "epoch:46 step:36022[D loss: 0.422000, acc: 61.72%, op_acc: 37.50%] [G loss: 0.861319]\n",
      "epoch:46 step:36023[D loss: 0.366168, acc: 69.53%, op_acc: 45.31%] [G loss: 0.971215]\n",
      "epoch:46 step:36024[D loss: 0.340103, acc: 72.66%, op_acc: 53.91%] [G loss: 0.796478]\n",
      "epoch:46 step:36025[D loss: 0.387269, acc: 64.06%, op_acc: 44.53%] [G loss: 0.819129]\n",
      "epoch:46 step:36026[D loss: 0.354463, acc: 71.88%, op_acc: 49.22%] [G loss: 0.874544]\n",
      "epoch:46 step:36027[D loss: 0.371476, acc: 70.31%, op_acc: 45.31%] [G loss: 0.919803]\n",
      "epoch:46 step:36028[D loss: 0.384492, acc: 66.41%, op_acc: 46.09%] [G loss: 1.019333]\n",
      "epoch:46 step:36029[D loss: 0.363512, acc: 75.00%, op_acc: 50.00%] [G loss: 1.004790]\n",
      "epoch:46 step:36030[D loss: 0.383598, acc: 68.75%, op_acc: 41.41%] [G loss: 0.970881]\n",
      "epoch:46 step:36031[D loss: 0.393207, acc: 69.53%, op_acc: 37.50%] [G loss: 0.950539]\n",
      "epoch:46 step:36032[D loss: 0.406669, acc: 60.16%, op_acc: 42.19%] [G loss: 0.856918]\n",
      "epoch:46 step:36033[D loss: 0.364049, acc: 70.31%, op_acc: 45.31%] [G loss: 0.848758]\n",
      "epoch:46 step:36034[D loss: 0.451820, acc: 57.03%, op_acc: 39.84%] [G loss: 0.872041]\n",
      "epoch:46 step:36035[D loss: 0.405441, acc: 61.72%, op_acc: 42.97%] [G loss: 0.904633]\n",
      "epoch:46 step:36036[D loss: 0.356460, acc: 73.44%, op_acc: 50.78%] [G loss: 1.030985]\n",
      "epoch:46 step:36037[D loss: 0.401743, acc: 62.50%, op_acc: 43.75%] [G loss: 0.859033]\n",
      "epoch:46 step:36038[D loss: 0.368894, acc: 64.06%, op_acc: 47.66%] [G loss: 0.919611]\n",
      "epoch:46 step:36039[D loss: 0.376755, acc: 70.31%, op_acc: 40.62%] [G loss: 1.164667]\n",
      "epoch:46 step:36040[D loss: 0.389028, acc: 60.94%, op_acc: 49.22%] [G loss: 1.013203]\n",
      "epoch:46 step:36041[D loss: 0.398712, acc: 63.28%, op_acc: 48.44%] [G loss: 0.729983]\n",
      "epoch:46 step:36042[D loss: 0.447922, acc: 61.72%, op_acc: 42.97%] [G loss: 0.765825]\n",
      "epoch:46 step:36043[D loss: 0.402778, acc: 65.62%, op_acc: 41.41%] [G loss: 0.727409]\n",
      "epoch:46 step:36044[D loss: 0.418365, acc: 60.16%, op_acc: 47.66%] [G loss: 0.995919]\n",
      "epoch:46 step:36045[D loss: 0.407451, acc: 61.72%, op_acc: 42.97%] [G loss: 0.723164]\n",
      "epoch:46 step:36046[D loss: 0.395988, acc: 67.19%, op_acc: 43.75%] [G loss: 0.981010]\n",
      "epoch:46 step:36047[D loss: 0.369852, acc: 67.97%, op_acc: 42.97%] [G loss: 0.683160]\n",
      "epoch:46 step:36048[D loss: 0.413280, acc: 59.38%, op_acc: 42.19%] [G loss: 0.851781]\n",
      "epoch:46 step:36049[D loss: 0.388423, acc: 68.75%, op_acc: 39.84%] [G loss: 0.987922]\n",
      "epoch:46 step:36050[D loss: 0.394487, acc: 69.53%, op_acc: 46.09%] [G loss: 0.746432]\n",
      "##############\n",
      "[0.87059838 0.84469549 0.80001419 0.78680663 0.78231765 0.81418301\n",
      " 0.87908961 0.8199948  0.83578164 0.83630398]\n",
      "##########\n",
      "epoch:46 step:36051[D loss: 0.456101, acc: 49.22%, op_acc: 40.62%] [G loss: 0.611237]\n",
      "epoch:46 step:36052[D loss: 0.371635, acc: 72.66%, op_acc: 45.31%] [G loss: 0.659674]\n",
      "epoch:46 step:36053[D loss: 0.363150, acc: 72.66%, op_acc: 50.00%] [G loss: 0.713089]\n",
      "epoch:46 step:36054[D loss: 0.360187, acc: 75.00%, op_acc: 45.31%] [G loss: 0.951710]\n",
      "epoch:46 step:36055[D loss: 0.395893, acc: 64.06%, op_acc: 41.41%] [G loss: 0.901885]\n",
      "epoch:46 step:36056[D loss: 0.375913, acc: 63.28%, op_acc: 46.88%] [G loss: 0.934077]\n",
      "epoch:46 step:36057[D loss: 0.375973, acc: 69.53%, op_acc: 47.66%] [G loss: 0.960530]\n",
      "epoch:46 step:36058[D loss: 0.351196, acc: 66.41%, op_acc: 47.66%] [G loss: 0.818442]\n",
      "epoch:46 step:36059[D loss: 0.396350, acc: 67.97%, op_acc: 35.94%] [G loss: 0.785287]\n",
      "epoch:46 step:36060[D loss: 0.399463, acc: 67.19%, op_acc: 41.41%] [G loss: 1.044949]\n",
      "epoch:46 step:36061[D loss: 0.385906, acc: 67.97%, op_acc: 44.53%] [G loss: 0.699335]\n",
      "epoch:46 step:36062[D loss: 0.342472, acc: 77.34%, op_acc: 45.31%] [G loss: 0.792949]\n",
      "epoch:46 step:36063[D loss: 0.383506, acc: 66.41%, op_acc: 43.75%] [G loss: 1.021000]\n",
      "epoch:46 step:36064[D loss: 0.368351, acc: 65.62%, op_acc: 45.31%] [G loss: 0.656603]\n",
      "epoch:46 step:36065[D loss: 0.363791, acc: 67.97%, op_acc: 49.22%] [G loss: 0.827065]\n",
      "epoch:46 step:36066[D loss: 0.425143, acc: 60.94%, op_acc: 43.75%] [G loss: 0.734007]\n",
      "epoch:46 step:36067[D loss: 0.377716, acc: 75.00%, op_acc: 48.44%] [G loss: 0.831739]\n",
      "epoch:46 step:36068[D loss: 0.391815, acc: 67.19%, op_acc: 46.09%] [G loss: 0.743791]\n",
      "epoch:46 step:36069[D loss: 0.387122, acc: 67.97%, op_acc: 46.09%] [G loss: 0.811375]\n",
      "epoch:46 step:36070[D loss: 0.412650, acc: 64.06%, op_acc: 40.62%] [G loss: 0.848768]\n",
      "epoch:46 step:36071[D loss: 0.433674, acc: 53.91%, op_acc: 40.62%] [G loss: 0.971171]\n",
      "epoch:46 step:36072[D loss: 0.396982, acc: 67.19%, op_acc: 42.97%] [G loss: 0.723086]\n",
      "epoch:46 step:36073[D loss: 0.395288, acc: 62.50%, op_acc: 42.19%] [G loss: 0.773988]\n",
      "epoch:46 step:36074[D loss: 0.393335, acc: 67.97%, op_acc: 45.31%] [G loss: 0.725410]\n",
      "epoch:46 step:36075[D loss: 0.367669, acc: 66.41%, op_acc: 45.31%] [G loss: 0.847899]\n",
      "epoch:46 step:36076[D loss: 0.362181, acc: 71.88%, op_acc: 41.41%] [G loss: 0.902285]\n",
      "epoch:46 step:36077[D loss: 0.373892, acc: 71.88%, op_acc: 42.97%] [G loss: 0.916161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36078[D loss: 0.389485, acc: 62.50%, op_acc: 43.75%] [G loss: 1.067103]\n",
      "epoch:46 step:36079[D loss: 0.411276, acc: 60.16%, op_acc: 47.66%] [G loss: 0.884297]\n",
      "epoch:46 step:36080[D loss: 0.431439, acc: 59.38%, op_acc: 38.28%] [G loss: 0.786383]\n",
      "epoch:46 step:36081[D loss: 0.378594, acc: 64.84%, op_acc: 45.31%] [G loss: 0.897252]\n",
      "epoch:46 step:36082[D loss: 0.405734, acc: 64.06%, op_acc: 42.19%] [G loss: 0.888039]\n",
      "epoch:46 step:36083[D loss: 0.371911, acc: 70.31%, op_acc: 42.97%] [G loss: 0.953933]\n",
      "epoch:46 step:36084[D loss: 0.355994, acc: 66.41%, op_acc: 51.56%] [G loss: 0.793956]\n",
      "epoch:46 step:36085[D loss: 0.375895, acc: 72.66%, op_acc: 50.78%] [G loss: 0.937232]\n",
      "epoch:46 step:36086[D loss: 0.399063, acc: 66.41%, op_acc: 45.31%] [G loss: 1.044317]\n",
      "epoch:46 step:36087[D loss: 0.421615, acc: 64.06%, op_acc: 40.62%] [G loss: 0.949379]\n",
      "epoch:46 step:36088[D loss: 0.341313, acc: 71.88%, op_acc: 53.12%] [G loss: 1.005148]\n",
      "epoch:46 step:36089[D loss: 0.393399, acc: 60.94%, op_acc: 46.88%] [G loss: 1.146490]\n",
      "epoch:46 step:36090[D loss: 0.408840, acc: 65.62%, op_acc: 41.41%] [G loss: 1.207345]\n",
      "epoch:46 step:36091[D loss: 0.378847, acc: 64.84%, op_acc: 46.09%] [G loss: 1.330822]\n",
      "epoch:46 step:36092[D loss: 0.398568, acc: 66.41%, op_acc: 41.41%] [G loss: 1.191446]\n",
      "epoch:46 step:36093[D loss: 0.372943, acc: 70.31%, op_acc: 45.31%] [G loss: 1.052134]\n",
      "epoch:46 step:36094[D loss: 0.357870, acc: 74.22%, op_acc: 55.47%] [G loss: 1.092293]\n",
      "epoch:46 step:36095[D loss: 0.410303, acc: 62.50%, op_acc: 48.44%] [G loss: 0.880928]\n",
      "epoch:46 step:36096[D loss: 0.400305, acc: 63.28%, op_acc: 40.62%] [G loss: 1.228365]\n",
      "epoch:46 step:36097[D loss: 0.368627, acc: 71.09%, op_acc: 46.09%] [G loss: 1.243010]\n",
      "epoch:46 step:36098[D loss: 0.368963, acc: 70.31%, op_acc: 46.09%] [G loss: 0.780514]\n",
      "epoch:46 step:36099[D loss: 0.461964, acc: 50.78%, op_acc: 35.94%] [G loss: 1.121501]\n",
      "epoch:46 step:36100[D loss: 0.448230, acc: 54.69%, op_acc: 42.19%] [G loss: 0.723649]\n",
      "##############\n",
      "[0.8776241  0.83638368 0.80135095 0.7911735  0.79164155 0.83722268\n",
      " 0.87197027 0.81438697 0.84768584 0.84895468]\n",
      "##########\n",
      "epoch:46 step:36101[D loss: 0.428316, acc: 56.25%, op_acc: 41.41%] [G loss: 0.983775]\n",
      "epoch:46 step:36102[D loss: 0.416127, acc: 60.94%, op_acc: 42.97%] [G loss: 1.200816]\n",
      "epoch:46 step:36103[D loss: 0.419481, acc: 59.38%, op_acc: 40.62%] [G loss: 0.906381]\n",
      "epoch:46 step:36104[D loss: 0.427053, acc: 52.34%, op_acc: 41.41%] [G loss: 0.980965]\n",
      "epoch:46 step:36105[D loss: 0.433296, acc: 56.25%, op_acc: 41.41%] [G loss: 1.001614]\n",
      "epoch:46 step:36106[D loss: 0.408904, acc: 60.94%, op_acc: 40.62%] [G loss: 1.008871]\n",
      "epoch:46 step:36107[D loss: 0.405676, acc: 60.16%, op_acc: 46.88%] [G loss: 1.048391]\n",
      "epoch:46 step:36108[D loss: 0.426043, acc: 61.72%, op_acc: 45.31%] [G loss: 1.033928]\n",
      "epoch:46 step:36109[D loss: 0.380792, acc: 62.50%, op_acc: 41.41%] [G loss: 0.941782]\n",
      "epoch:46 step:36110[D loss: 0.370919, acc: 67.19%, op_acc: 46.09%] [G loss: 1.184876]\n",
      "epoch:46 step:36111[D loss: 0.379461, acc: 71.09%, op_acc: 45.31%] [G loss: 0.984899]\n",
      "epoch:46 step:36112[D loss: 0.416366, acc: 58.59%, op_acc: 49.22%] [G loss: 0.926416]\n",
      "epoch:46 step:36113[D loss: 0.419340, acc: 64.06%, op_acc: 45.31%] [G loss: 0.900240]\n",
      "epoch:46 step:36114[D loss: 0.402226, acc: 60.94%, op_acc: 43.75%] [G loss: 0.958409]\n",
      "epoch:46 step:36115[D loss: 0.417526, acc: 64.84%, op_acc: 45.31%] [G loss: 0.797446]\n",
      "epoch:46 step:36116[D loss: 0.407370, acc: 69.53%, op_acc: 39.06%] [G loss: 0.768051]\n",
      "epoch:46 step:36117[D loss: 0.362402, acc: 70.31%, op_acc: 50.78%] [G loss: 0.946205]\n",
      "epoch:46 step:36118[D loss: 0.335612, acc: 81.25%, op_acc: 41.41%] [G loss: 1.115301]\n",
      "epoch:46 step:36119[D loss: 0.381417, acc: 62.50%, op_acc: 46.88%] [G loss: 1.118572]\n",
      "epoch:46 step:36120[D loss: 0.393851, acc: 64.06%, op_acc: 48.44%] [G loss: 0.879214]\n",
      "epoch:46 step:36121[D loss: 0.383281, acc: 68.75%, op_acc: 42.97%] [G loss: 0.974183]\n",
      "epoch:46 step:36122[D loss: 0.380230, acc: 75.00%, op_acc: 35.16%] [G loss: 0.712881]\n",
      "epoch:46 step:36123[D loss: 0.402362, acc: 67.97%, op_acc: 42.97%] [G loss: 0.887127]\n",
      "epoch:46 step:36124[D loss: 0.396733, acc: 67.97%, op_acc: 44.53%] [G loss: 0.926518]\n",
      "epoch:46 step:36125[D loss: 0.418669, acc: 57.03%, op_acc: 46.09%] [G loss: 0.841116]\n",
      "epoch:46 step:36126[D loss: 0.383145, acc: 64.06%, op_acc: 41.41%] [G loss: 0.807118]\n",
      "epoch:46 step:36127[D loss: 0.346152, acc: 73.44%, op_acc: 44.53%] [G loss: 0.913139]\n",
      "epoch:46 step:36128[D loss: 0.397754, acc: 63.28%, op_acc: 43.75%] [G loss: 0.910650]\n",
      "epoch:46 step:36129[D loss: 0.403683, acc: 58.59%, op_acc: 46.88%] [G loss: 1.165070]\n",
      "epoch:46 step:36130[D loss: 0.344085, acc: 76.56%, op_acc: 50.00%] [G loss: 0.984406]\n",
      "epoch:46 step:36131[D loss: 0.384087, acc: 71.09%, op_acc: 42.97%] [G loss: 0.971286]\n",
      "epoch:46 step:36132[D loss: 0.400468, acc: 65.62%, op_acc: 47.66%] [G loss: 0.910760]\n",
      "epoch:46 step:36133[D loss: 0.330136, acc: 74.22%, op_acc: 52.34%] [G loss: 1.087199]\n",
      "epoch:46 step:36134[D loss: 0.396646, acc: 69.53%, op_acc: 42.97%] [G loss: 1.170528]\n",
      "epoch:46 step:36135[D loss: 0.389797, acc: 64.06%, op_acc: 51.56%] [G loss: 0.989365]\n",
      "epoch:46 step:36136[D loss: 0.351249, acc: 75.78%, op_acc: 47.66%] [G loss: 1.046462]\n",
      "epoch:46 step:36137[D loss: 0.374997, acc: 66.41%, op_acc: 47.66%] [G loss: 1.048565]\n",
      "epoch:46 step:36138[D loss: 0.364458, acc: 74.22%, op_acc: 48.44%] [G loss: 1.095296]\n",
      "epoch:46 step:36139[D loss: 0.399534, acc: 62.50%, op_acc: 48.44%] [G loss: 1.298903]\n",
      "epoch:46 step:36140[D loss: 0.336917, acc: 80.47%, op_acc: 48.44%] [G loss: 1.280562]\n",
      "epoch:46 step:36141[D loss: 0.416045, acc: 71.09%, op_acc: 40.62%] [G loss: 1.168752]\n",
      "epoch:46 step:36142[D loss: 0.355436, acc: 74.22%, op_acc: 43.75%] [G loss: 1.190800]\n",
      "epoch:46 step:36143[D loss: 0.319675, acc: 75.78%, op_acc: 50.00%] [G loss: 1.247150]\n",
      "epoch:46 step:36144[D loss: 0.365990, acc: 67.97%, op_acc: 46.88%] [G loss: 1.284801]\n",
      "epoch:46 step:36145[D loss: 0.342590, acc: 73.44%, op_acc: 50.78%] [G loss: 1.228190]\n",
      "epoch:46 step:36146[D loss: 0.340341, acc: 75.00%, op_acc: 43.75%] [G loss: 1.188465]\n",
      "epoch:46 step:36147[D loss: 0.324549, acc: 79.69%, op_acc: 49.22%] [G loss: 1.203010]\n",
      "epoch:46 step:36148[D loss: 0.288811, acc: 83.59%, op_acc: 52.34%] [G loss: 1.246184]\n",
      "epoch:46 step:36149[D loss: 0.321185, acc: 82.81%, op_acc: 50.00%] [G loss: 1.272619]\n",
      "epoch:46 step:36150[D loss: 0.355374, acc: 72.66%, op_acc: 43.75%] [G loss: 1.183325]\n",
      "##############\n",
      "[0.8907051  0.85725283 0.81938317 0.81609617 0.80192491 0.83414178\n",
      " 0.88512534 0.83527938 0.80933257 0.83814529]\n",
      "##########\n",
      "epoch:46 step:36151[D loss: 0.346918, acc: 77.34%, op_acc: 40.62%] [G loss: 0.619190]\n",
      "epoch:46 step:36152[D loss: 0.366620, acc: 65.62%, op_acc: 51.56%] [G loss: 1.265548]\n",
      "epoch:46 step:36153[D loss: 0.430601, acc: 55.47%, op_acc: 42.97%] [G loss: 1.455898]\n",
      "epoch:46 step:36154[D loss: 0.406123, acc: 65.62%, op_acc: 40.62%] [G loss: 1.189723]\n",
      "epoch:46 step:36155[D loss: 0.369184, acc: 66.41%, op_acc: 48.44%] [G loss: 1.420512]\n",
      "epoch:46 step:36156[D loss: 0.383366, acc: 67.97%, op_acc: 42.97%] [G loss: 1.292058]\n",
      "epoch:46 step:36157[D loss: 0.336939, acc: 75.00%, op_acc: 45.31%] [G loss: 1.318267]\n",
      "epoch:46 step:36158[D loss: 0.333782, acc: 78.12%, op_acc: 47.66%] [G loss: 1.336160]\n",
      "epoch:46 step:36159[D loss: 0.290316, acc: 84.38%, op_acc: 50.00%] [G loss: 1.292108]\n",
      "epoch:46 step:36160[D loss: 0.342524, acc: 73.44%, op_acc: 48.44%] [G loss: 1.312687]\n",
      "epoch:46 step:36161[D loss: 0.368117, acc: 72.66%, op_acc: 47.66%] [G loss: 1.167337]\n",
      "epoch:46 step:36162[D loss: 0.324053, acc: 80.47%, op_acc: 53.91%] [G loss: 0.699872]\n",
      "epoch:46 step:36163[D loss: 0.318201, acc: 75.78%, op_acc: 50.78%] [G loss: 1.284731]\n",
      "epoch:46 step:36164[D loss: 0.402061, acc: 64.84%, op_acc: 48.44%] [G loss: 1.175332]\n",
      "epoch:46 step:36165[D loss: 0.387938, acc: 69.53%, op_acc: 47.66%] [G loss: 1.139623]\n",
      "epoch:46 step:36166[D loss: 0.347158, acc: 77.34%, op_acc: 44.53%] [G loss: 1.173189]\n",
      "epoch:46 step:36167[D loss: 0.352610, acc: 71.88%, op_acc: 42.97%] [G loss: 1.309051]\n",
      "epoch:46 step:36168[D loss: 0.333101, acc: 75.78%, op_acc: 47.66%] [G loss: 1.232960]\n",
      "epoch:46 step:36169[D loss: 0.371040, acc: 70.31%, op_acc: 46.09%] [G loss: 1.190026]\n",
      "epoch:46 step:36170[D loss: 0.349222, acc: 77.34%, op_acc: 44.53%] [G loss: 0.841137]\n",
      "epoch:46 step:36171[D loss: 0.454334, acc: 59.38%, op_acc: 39.84%] [G loss: 1.227757]\n",
      "epoch:46 step:36172[D loss: 0.443404, acc: 64.06%, op_acc: 36.72%] [G loss: 1.000674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36173[D loss: 0.425469, acc: 59.38%, op_acc: 42.19%] [G loss: 0.789747]\n",
      "epoch:46 step:36174[D loss: 0.420329, acc: 57.03%, op_acc: 39.84%] [G loss: 0.845486]\n",
      "epoch:46 step:36175[D loss: 0.424394, acc: 58.59%, op_acc: 42.97%] [G loss: 1.335697]\n",
      "epoch:46 step:36176[D loss: 0.468735, acc: 53.91%, op_acc: 39.06%] [G loss: 0.988101]\n",
      "epoch:46 step:36177[D loss: 0.368914, acc: 71.09%, op_acc: 44.53%] [G loss: 1.275013]\n",
      "epoch:46 step:36178[D loss: 0.396422, acc: 64.84%, op_acc: 44.53%] [G loss: 1.268412]\n",
      "epoch:46 step:36179[D loss: 0.418198, acc: 60.16%, op_acc: 46.88%] [G loss: 1.274927]\n",
      "epoch:46 step:36180[D loss: 0.408338, acc: 63.28%, op_acc: 43.75%] [G loss: 0.999006]\n",
      "epoch:46 step:36181[D loss: 0.417486, acc: 64.06%, op_acc: 40.62%] [G loss: 1.077252]\n",
      "epoch:46 step:36182[D loss: 0.403658, acc: 57.81%, op_acc: 48.44%] [G loss: 1.019531]\n",
      "epoch:46 step:36183[D loss: 0.401847, acc: 64.84%, op_acc: 48.44%] [G loss: 0.982529]\n",
      "epoch:46 step:36184[D loss: 0.433937, acc: 57.03%, op_acc: 38.28%] [G loss: 0.976179]\n",
      "epoch:46 step:36185[D loss: 0.396128, acc: 67.97%, op_acc: 46.88%] [G loss: 0.860645]\n",
      "epoch:46 step:36186[D loss: 0.386353, acc: 68.75%, op_acc: 43.75%] [G loss: 1.097507]\n",
      "epoch:46 step:36187[D loss: 0.371653, acc: 69.53%, op_acc: 41.41%] [G loss: 1.120814]\n",
      "epoch:46 step:36188[D loss: 0.421856, acc: 57.81%, op_acc: 42.19%] [G loss: 0.946961]\n",
      "epoch:46 step:36189[D loss: 0.394861, acc: 65.62%, op_acc: 46.09%] [G loss: 1.059836]\n",
      "epoch:46 step:36190[D loss: 0.404688, acc: 60.16%, op_acc: 44.53%] [G loss: 1.125946]\n",
      "epoch:46 step:36191[D loss: 0.360483, acc: 67.19%, op_acc: 48.44%] [G loss: 1.068090]\n",
      "epoch:46 step:36192[D loss: 0.376617, acc: 64.06%, op_acc: 47.66%] [G loss: 1.019451]\n",
      "epoch:46 step:36193[D loss: 0.437295, acc: 58.59%, op_acc: 46.09%] [G loss: 1.133288]\n",
      "epoch:46 step:36194[D loss: 0.431007, acc: 57.03%, op_acc: 48.44%] [G loss: 0.906000]\n",
      "epoch:46 step:36195[D loss: 0.435778, acc: 52.34%, op_acc: 44.53%] [G loss: 0.817768]\n",
      "epoch:46 step:36196[D loss: 0.441698, acc: 50.78%, op_acc: 46.09%] [G loss: 0.663823]\n",
      "epoch:46 step:36197[D loss: 0.414376, acc: 67.19%, op_acc: 42.19%] [G loss: 0.854161]\n",
      "epoch:46 step:36198[D loss: 0.398745, acc: 60.94%, op_acc: 43.75%] [G loss: 0.940211]\n",
      "epoch:46 step:36199[D loss: 0.370894, acc: 68.75%, op_acc: 46.09%] [G loss: 0.900283]\n",
      "epoch:46 step:36200[D loss: 0.383227, acc: 69.53%, op_acc: 42.19%] [G loss: 0.962286]\n",
      "##############\n",
      "[0.83806569 0.85716387 0.80697397 0.81766455 0.78414222 0.81115881\n",
      " 0.86727469 0.84489173 0.82557727 0.80317715]\n",
      "##########\n",
      "epoch:46 step:36201[D loss: 0.384169, acc: 67.97%, op_acc: 52.34%] [G loss: 1.023776]\n",
      "epoch:46 step:36202[D loss: 0.402508, acc: 57.03%, op_acc: 45.31%] [G loss: 1.089615]\n",
      "epoch:46 step:36203[D loss: 0.376684, acc: 70.31%, op_acc: 44.53%] [G loss: 1.228259]\n",
      "epoch:46 step:36204[D loss: 0.376734, acc: 71.88%, op_acc: 40.62%] [G loss: 1.366282]\n",
      "epoch:46 step:36205[D loss: 0.382205, acc: 64.84%, op_acc: 46.09%] [G loss: 1.352213]\n",
      "epoch:46 step:36206[D loss: 0.338026, acc: 73.44%, op_acc: 46.09%] [G loss: 1.255904]\n",
      "epoch:46 step:36207[D loss: 0.404483, acc: 64.06%, op_acc: 46.09%] [G loss: 0.824354]\n",
      "epoch:46 step:36208[D loss: 0.371119, acc: 71.88%, op_acc: 50.78%] [G loss: 1.270793]\n",
      "epoch:46 step:36209[D loss: 0.381806, acc: 64.84%, op_acc: 48.44%] [G loss: 0.748373]\n",
      "epoch:46 step:36210[D loss: 0.433213, acc: 64.84%, op_acc: 37.50%] [G loss: 0.842232]\n",
      "epoch:46 step:36211[D loss: 0.446093, acc: 55.47%, op_acc: 38.28%] [G loss: 0.946752]\n",
      "epoch:46 step:36212[D loss: 0.439967, acc: 58.59%, op_acc: 36.72%] [G loss: 0.698983]\n",
      "epoch:46 step:36213[D loss: 0.450937, acc: 53.91%, op_acc: 39.84%] [G loss: 0.972202]\n",
      "epoch:46 step:36214[D loss: 0.436760, acc: 54.69%, op_acc: 41.41%] [G loss: 1.151804]\n",
      "epoch:46 step:36215[D loss: 0.448429, acc: 59.38%, op_acc: 39.06%] [G loss: 1.000514]\n",
      "epoch:46 step:36216[D loss: 0.361830, acc: 71.09%, op_acc: 46.88%] [G loss: 1.345710]\n",
      "epoch:46 step:36217[D loss: 0.423555, acc: 62.50%, op_acc: 46.09%] [G loss: 1.269140]\n",
      "epoch:46 step:36218[D loss: 0.450122, acc: 64.06%, op_acc: 36.72%] [G loss: 1.189627]\n",
      "epoch:46 step:36219[D loss: 0.389681, acc: 63.28%, op_acc: 43.75%] [G loss: 1.013477]\n",
      "epoch:46 step:36220[D loss: 0.385355, acc: 67.97%, op_acc: 40.62%] [G loss: 0.993346]\n",
      "epoch:46 step:36221[D loss: 0.363918, acc: 69.53%, op_acc: 46.09%] [G loss: 1.099447]\n",
      "epoch:46 step:36222[D loss: 0.402129, acc: 61.72%, op_acc: 51.56%] [G loss: 1.044619]\n",
      "epoch:46 step:36223[D loss: 0.385051, acc: 71.09%, op_acc: 39.06%] [G loss: 1.209667]\n",
      "epoch:46 step:36224[D loss: 0.389689, acc: 64.84%, op_acc: 39.84%] [G loss: 1.101261]\n",
      "epoch:46 step:36225[D loss: 0.375217, acc: 70.31%, op_acc: 46.88%] [G loss: 1.096012]\n",
      "epoch:46 step:36226[D loss: 0.403155, acc: 63.28%, op_acc: 43.75%] [G loss: 0.927331]\n",
      "epoch:46 step:36227[D loss: 0.387177, acc: 64.84%, op_acc: 47.66%] [G loss: 1.162321]\n",
      "epoch:46 step:36228[D loss: 0.356574, acc: 73.44%, op_acc: 45.31%] [G loss: 0.960601]\n",
      "epoch:46 step:36229[D loss: 0.403472, acc: 69.53%, op_acc: 43.75%] [G loss: 0.855306]\n",
      "epoch:46 step:36230[D loss: 0.418475, acc: 63.28%, op_acc: 39.06%] [G loss: 1.001845]\n",
      "epoch:46 step:36231[D loss: 0.370837, acc: 67.19%, op_acc: 41.41%] [G loss: 0.974425]\n",
      "epoch:46 step:36232[D loss: 0.402651, acc: 65.62%, op_acc: 46.09%] [G loss: 1.020126]\n",
      "epoch:46 step:36233[D loss: 0.361758, acc: 63.28%, op_acc: 50.78%] [G loss: 0.997266]\n",
      "epoch:46 step:36234[D loss: 0.437292, acc: 57.03%, op_acc: 40.62%] [G loss: 0.894360]\n",
      "epoch:46 step:36235[D loss: 0.420092, acc: 64.84%, op_acc: 44.53%] [G loss: 1.081315]\n",
      "epoch:46 step:36236[D loss: 0.375489, acc: 66.41%, op_acc: 46.88%] [G loss: 0.970289]\n",
      "epoch:46 step:36237[D loss: 0.398071, acc: 62.50%, op_acc: 48.44%] [G loss: 1.016117]\n",
      "epoch:46 step:36238[D loss: 0.467901, acc: 54.69%, op_acc: 39.84%] [G loss: 0.919282]\n",
      "epoch:46 step:36239[D loss: 0.404889, acc: 60.94%, op_acc: 42.19%] [G loss: 1.125679]\n",
      "epoch:46 step:36240[D loss: 0.413319, acc: 60.16%, op_acc: 41.41%] [G loss: 1.165065]\n",
      "epoch:46 step:36241[D loss: 0.416842, acc: 59.38%, op_acc: 43.75%] [G loss: 0.998022]\n",
      "epoch:46 step:36242[D loss: 0.414741, acc: 60.94%, op_acc: 43.75%] [G loss: 1.099557]\n",
      "epoch:46 step:36243[D loss: 0.411797, acc: 67.97%, op_acc: 38.28%] [G loss: 1.019659]\n",
      "epoch:46 step:36244[D loss: 0.428635, acc: 58.59%, op_acc: 39.84%] [G loss: 0.902027]\n",
      "epoch:46 step:36245[D loss: 0.431507, acc: 61.72%, op_acc: 41.41%] [G loss: 1.066236]\n",
      "epoch:46 step:36246[D loss: 0.354068, acc: 78.91%, op_acc: 45.31%] [G loss: 1.064345]\n",
      "epoch:46 step:36247[D loss: 0.415509, acc: 60.16%, op_acc: 46.09%] [G loss: 0.939990]\n",
      "epoch:46 step:36248[D loss: 0.412348, acc: 60.94%, op_acc: 43.75%] [G loss: 0.959080]\n",
      "epoch:46 step:36249[D loss: 0.426559, acc: 60.94%, op_acc: 43.75%] [G loss: 0.945946]\n",
      "epoch:46 step:36250[D loss: 0.413889, acc: 64.84%, op_acc: 37.50%] [G loss: 0.848359]\n",
      "##############\n",
      "[0.85160796 0.85937802 0.82399249 0.80485048 0.78288301 0.82242497\n",
      " 0.88161353 0.815926   0.81076644 0.8270807 ]\n",
      "##########\n",
      "epoch:46 step:36251[D loss: 0.389159, acc: 64.06%, op_acc: 50.00%] [G loss: 0.767042]\n",
      "epoch:46 step:36252[D loss: 0.391492, acc: 66.41%, op_acc: 42.19%] [G loss: 0.837560]\n",
      "epoch:46 step:36253[D loss: 0.364943, acc: 69.53%, op_acc: 53.12%] [G loss: 1.017035]\n",
      "epoch:46 step:36254[D loss: 0.435815, acc: 54.69%, op_acc: 39.84%] [G loss: 1.108342]\n",
      "epoch:46 step:36255[D loss: 0.414523, acc: 57.03%, op_acc: 48.44%] [G loss: 0.840329]\n",
      "epoch:46 step:36256[D loss: 0.384138, acc: 64.06%, op_acc: 46.09%] [G loss: 0.934956]\n",
      "epoch:46 step:36257[D loss: 0.377686, acc: 67.97%, op_acc: 41.41%] [G loss: 0.816280]\n",
      "epoch:46 step:36258[D loss: 0.429251, acc: 54.69%, op_acc: 41.41%] [G loss: 0.946306]\n",
      "epoch:46 step:36259[D loss: 0.344301, acc: 78.12%, op_acc: 42.97%] [G loss: 0.954270]\n",
      "epoch:46 step:36260[D loss: 0.418383, acc: 60.16%, op_acc: 47.66%] [G loss: 0.858032]\n",
      "epoch:46 step:36261[D loss: 0.371805, acc: 69.53%, op_acc: 45.31%] [G loss: 0.971219]\n",
      "epoch:46 step:36262[D loss: 0.379108, acc: 69.53%, op_acc: 44.53%] [G loss: 0.948829]\n",
      "epoch:46 step:36263[D loss: 0.418230, acc: 57.81%, op_acc: 38.28%] [G loss: 1.036737]\n",
      "epoch:46 step:36264[D loss: 0.369891, acc: 68.75%, op_acc: 47.66%] [G loss: 1.155823]\n",
      "epoch:46 step:36265[D loss: 0.410659, acc: 60.16%, op_acc: 42.19%] [G loss: 0.991521]\n",
      "epoch:46 step:36266[D loss: 0.405330, acc: 69.53%, op_acc: 42.97%] [G loss: 0.915377]\n",
      "epoch:46 step:36267[D loss: 0.394309, acc: 65.62%, op_acc: 38.28%] [G loss: 0.906347]\n",
      "epoch:46 step:36268[D loss: 0.412933, acc: 59.38%, op_acc: 43.75%] [G loss: 0.973987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36269[D loss: 0.423051, acc: 58.59%, op_acc: 39.84%] [G loss: 0.914509]\n",
      "epoch:46 step:36270[D loss: 0.356345, acc: 68.75%, op_acc: 47.66%] [G loss: 1.100427]\n",
      "epoch:46 step:36271[D loss: 0.392630, acc: 60.94%, op_acc: 48.44%] [G loss: 0.862916]\n",
      "epoch:46 step:36272[D loss: 0.382522, acc: 70.31%, op_acc: 43.75%] [G loss: 1.033858]\n",
      "epoch:46 step:36273[D loss: 0.388906, acc: 65.62%, op_acc: 44.53%] [G loss: 1.132162]\n",
      "epoch:46 step:36274[D loss: 0.357892, acc: 70.31%, op_acc: 47.66%] [G loss: 1.209777]\n",
      "epoch:46 step:36275[D loss: 0.368453, acc: 72.66%, op_acc: 45.31%] [G loss: 1.123856]\n",
      "epoch:46 step:36276[D loss: 0.373660, acc: 73.44%, op_acc: 46.09%] [G loss: 1.069450]\n",
      "epoch:46 step:36277[D loss: 0.380109, acc: 65.62%, op_acc: 46.09%] [G loss: 1.089767]\n",
      "epoch:46 step:36278[D loss: 0.357472, acc: 75.78%, op_acc: 50.78%] [G loss: 0.926037]\n",
      "epoch:46 step:36279[D loss: 0.343186, acc: 70.31%, op_acc: 47.66%] [G loss: 1.167858]\n",
      "epoch:46 step:36280[D loss: 0.365621, acc: 72.66%, op_acc: 48.44%] [G loss: 1.166183]\n",
      "epoch:46 step:36281[D loss: 0.347707, acc: 71.88%, op_acc: 49.22%] [G loss: 1.166192]\n",
      "epoch:46 step:36282[D loss: 0.345384, acc: 76.56%, op_acc: 46.88%] [G loss: 0.978922]\n",
      "epoch:46 step:36283[D loss: 0.388149, acc: 67.19%, op_acc: 44.53%] [G loss: 0.962693]\n",
      "epoch:46 step:36284[D loss: 0.386050, acc: 65.62%, op_acc: 48.44%] [G loss: 1.122480]\n",
      "epoch:46 step:36285[D loss: 0.395839, acc: 67.97%, op_acc: 42.97%] [G loss: 1.330523]\n",
      "epoch:46 step:36286[D loss: 0.353744, acc: 71.09%, op_acc: 46.88%] [G loss: 0.824542]\n",
      "epoch:46 step:36287[D loss: 0.432247, acc: 54.69%, op_acc: 46.09%] [G loss: 1.199712]\n",
      "epoch:46 step:36288[D loss: 0.354974, acc: 69.53%, op_acc: 42.19%] [G loss: 0.906730]\n",
      "epoch:46 step:36289[D loss: 0.424726, acc: 60.94%, op_acc: 41.41%] [G loss: 1.236769]\n",
      "epoch:46 step:36290[D loss: 0.435909, acc: 57.81%, op_acc: 38.28%] [G loss: 1.192776]\n",
      "epoch:46 step:36291[D loss: 0.362616, acc: 62.50%, op_acc: 46.09%] [G loss: 1.156636]\n",
      "epoch:46 step:36292[D loss: 0.372488, acc: 68.75%, op_acc: 42.97%] [G loss: 1.234295]\n",
      "epoch:46 step:36293[D loss: 0.413246, acc: 62.50%, op_acc: 40.62%] [G loss: 1.210829]\n",
      "epoch:46 step:36294[D loss: 0.344196, acc: 73.44%, op_acc: 45.31%] [G loss: 1.188573]\n",
      "epoch:46 step:36295[D loss: 0.414546, acc: 60.16%, op_acc: 43.75%] [G loss: 0.920134]\n",
      "epoch:46 step:36296[D loss: 0.421503, acc: 64.06%, op_acc: 38.28%] [G loss: 1.173841]\n",
      "epoch:46 step:36297[D loss: 0.350218, acc: 66.41%, op_acc: 49.22%] [G loss: 1.230287]\n",
      "epoch:46 step:36298[D loss: 0.385162, acc: 64.84%, op_acc: 43.75%] [G loss: 0.937176]\n",
      "epoch:46 step:36299[D loss: 0.411146, acc: 63.28%, op_acc: 43.75%] [G loss: 1.026500]\n",
      "epoch:46 step:36300[D loss: 0.448461, acc: 50.78%, op_acc: 39.84%] [G loss: 0.823999]\n",
      "##############\n",
      "[0.87672277 0.83801859 0.81747159 0.80398533 0.79535539 0.8263855\n",
      " 0.87062178 0.81532952 0.80545225 0.81809423]\n",
      "##########\n",
      "epoch:46 step:36301[D loss: 0.424157, acc: 58.59%, op_acc: 39.06%] [G loss: 1.028878]\n",
      "epoch:46 step:36302[D loss: 0.410683, acc: 62.50%, op_acc: 38.28%] [G loss: 1.087599]\n",
      "epoch:46 step:36303[D loss: 0.403998, acc: 66.41%, op_acc: 40.62%] [G loss: 1.014935]\n",
      "epoch:46 step:36304[D loss: 0.411595, acc: 64.06%, op_acc: 44.53%] [G loss: 0.941569]\n",
      "epoch:46 step:36305[D loss: 0.385100, acc: 67.97%, op_acc: 45.31%] [G loss: 0.971199]\n",
      "epoch:46 step:36306[D loss: 0.388556, acc: 63.28%, op_acc: 41.41%] [G loss: 0.978013]\n",
      "epoch:46 step:36307[D loss: 0.350814, acc: 69.53%, op_acc: 44.53%] [G loss: 1.176201]\n",
      "epoch:46 step:36308[D loss: 0.379013, acc: 68.75%, op_acc: 50.00%] [G loss: 1.002475]\n",
      "epoch:46 step:36309[D loss: 0.395703, acc: 60.16%, op_acc: 44.53%] [G loss: 1.015674]\n",
      "epoch:46 step:36310[D loss: 0.389603, acc: 68.75%, op_acc: 46.09%] [G loss: 1.070437]\n",
      "epoch:46 step:36311[D loss: 0.373195, acc: 61.72%, op_acc: 45.31%] [G loss: 1.023010]\n",
      "epoch:46 step:36312[D loss: 0.394646, acc: 66.41%, op_acc: 50.00%] [G loss: 0.969637]\n",
      "epoch:46 step:36313[D loss: 0.458550, acc: 57.81%, op_acc: 42.97%] [G loss: 0.955659]\n",
      "epoch:46 step:36314[D loss: 0.423588, acc: 64.84%, op_acc: 41.41%] [G loss: 0.832113]\n",
      "epoch:46 step:36315[D loss: 0.443858, acc: 53.91%, op_acc: 43.75%] [G loss: 0.965374]\n",
      "epoch:46 step:36316[D loss: 0.433868, acc: 63.28%, op_acc: 40.62%] [G loss: 0.934926]\n",
      "epoch:46 step:36317[D loss: 0.390448, acc: 60.94%, op_acc: 46.88%] [G loss: 0.865326]\n",
      "epoch:46 step:36318[D loss: 0.402616, acc: 61.72%, op_acc: 41.41%] [G loss: 0.967848]\n",
      "epoch:46 step:36319[D loss: 0.412240, acc: 59.38%, op_acc: 46.09%] [G loss: 0.751429]\n",
      "epoch:46 step:36320[D loss: 0.391114, acc: 66.41%, op_acc: 42.19%] [G loss: 0.820035]\n",
      "epoch:46 step:36321[D loss: 0.445199, acc: 58.59%, op_acc: 33.59%] [G loss: 0.805167]\n",
      "epoch:46 step:36322[D loss: 0.387583, acc: 67.19%, op_acc: 44.53%] [G loss: 0.865965]\n",
      "epoch:46 step:36323[D loss: 0.395655, acc: 60.94%, op_acc: 45.31%] [G loss: 0.882982]\n",
      "epoch:46 step:36324[D loss: 0.399149, acc: 67.97%, op_acc: 46.09%] [G loss: 0.921183]\n",
      "epoch:46 step:36325[D loss: 0.362476, acc: 73.44%, op_acc: 43.75%] [G loss: 0.906387]\n",
      "epoch:46 step:36326[D loss: 0.375989, acc: 67.97%, op_acc: 48.44%] [G loss: 0.912692]\n",
      "epoch:46 step:36327[D loss: 0.377178, acc: 69.53%, op_acc: 44.53%] [G loss: 1.020984]\n",
      "epoch:46 step:36328[D loss: 0.381939, acc: 74.22%, op_acc: 37.50%] [G loss: 1.080669]\n",
      "epoch:46 step:36329[D loss: 0.346727, acc: 73.44%, op_acc: 48.44%] [G loss: 1.001755]\n",
      "epoch:46 step:36330[D loss: 0.395176, acc: 56.25%, op_acc: 45.31%] [G loss: 0.989650]\n",
      "epoch:46 step:36331[D loss: 0.418765, acc: 60.16%, op_acc: 44.53%] [G loss: 1.195629]\n",
      "epoch:46 step:36332[D loss: 0.396516, acc: 66.41%, op_acc: 45.31%] [G loss: 1.130912]\n",
      "epoch:46 step:36333[D loss: 0.353658, acc: 71.88%, op_acc: 46.88%] [G loss: 1.091453]\n",
      "epoch:46 step:36334[D loss: 0.403196, acc: 57.81%, op_acc: 47.66%] [G loss: 0.947850]\n",
      "epoch:46 step:36335[D loss: 0.402539, acc: 61.72%, op_acc: 51.56%] [G loss: 0.817100]\n",
      "epoch:46 step:36336[D loss: 0.439725, acc: 53.12%, op_acc: 45.31%] [G loss: 0.959628]\n",
      "epoch:46 step:36337[D loss: 0.393195, acc: 59.38%, op_acc: 47.66%] [G loss: 0.919424]\n",
      "epoch:46 step:36338[D loss: 0.406565, acc: 60.16%, op_acc: 45.31%] [G loss: 0.953727]\n",
      "epoch:46 step:36339[D loss: 0.425799, acc: 62.50%, op_acc: 38.28%] [G loss: 0.800797]\n",
      "epoch:46 step:36340[D loss: 0.364389, acc: 67.19%, op_acc: 50.00%] [G loss: 1.073354]\n",
      "epoch:46 step:36341[D loss: 0.380699, acc: 67.97%, op_acc: 46.88%] [G loss: 1.073138]\n",
      "epoch:46 step:36342[D loss: 0.359438, acc: 71.09%, op_acc: 55.47%] [G loss: 1.151052]\n",
      "epoch:46 step:36343[D loss: 0.431150, acc: 56.25%, op_acc: 39.06%] [G loss: 1.007645]\n",
      "epoch:46 step:36344[D loss: 0.427277, acc: 59.38%, op_acc: 40.62%] [G loss: 1.019113]\n",
      "epoch:46 step:36345[D loss: 0.396188, acc: 59.38%, op_acc: 44.53%] [G loss: 0.832858]\n",
      "epoch:46 step:36346[D loss: 0.417478, acc: 64.84%, op_acc: 35.94%] [G loss: 1.037711]\n",
      "epoch:46 step:36347[D loss: 0.406042, acc: 66.41%, op_acc: 42.19%] [G loss: 0.778626]\n",
      "epoch:46 step:36348[D loss: 0.413772, acc: 64.84%, op_acc: 42.97%] [G loss: 0.980464]\n",
      "epoch:46 step:36349[D loss: 0.398861, acc: 71.09%, op_acc: 39.84%] [G loss: 1.099034]\n",
      "epoch:46 step:36350[D loss: 0.427680, acc: 58.59%, op_acc: 44.53%] [G loss: 0.647549]\n",
      "##############\n",
      "[0.86221612 0.85436175 0.80515115 0.80236749 0.78877075 0.83992162\n",
      " 0.87877842 0.84247602 0.81138602 0.83993506]\n",
      "##########\n",
      "epoch:46 step:36351[D loss: 0.380893, acc: 71.09%, op_acc: 42.19%] [G loss: 1.026405]\n",
      "epoch:46 step:36352[D loss: 0.404044, acc: 71.09%, op_acc: 42.19%] [G loss: 0.671881]\n",
      "epoch:46 step:36353[D loss: 0.397821, acc: 63.28%, op_acc: 42.97%] [G loss: 1.046516]\n",
      "epoch:46 step:36354[D loss: 0.411470, acc: 58.59%, op_acc: 46.09%] [G loss: 0.678902]\n",
      "epoch:46 step:36355[D loss: 0.430361, acc: 50.78%, op_acc: 35.16%] [G loss: 0.747934]\n",
      "epoch:46 step:36356[D loss: 0.408303, acc: 60.94%, op_acc: 39.84%] [G loss: 0.776139]\n",
      "epoch:46 step:36357[D loss: 0.421838, acc: 62.50%, op_acc: 47.66%] [G loss: 0.804965]\n",
      "epoch:46 step:36358[D loss: 0.364454, acc: 69.53%, op_acc: 53.12%] [G loss: 0.869094]\n",
      "epoch:46 step:36359[D loss: 0.389074, acc: 61.72%, op_acc: 44.53%] [G loss: 1.135067]\n",
      "epoch:46 step:36360[D loss: 0.361439, acc: 70.31%, op_acc: 53.12%] [G loss: 0.944926]\n",
      "epoch:46 step:36361[D loss: 0.364807, acc: 71.88%, op_acc: 45.31%] [G loss: 1.095085]\n",
      "epoch:46 step:36362[D loss: 0.416264, acc: 70.31%, op_acc: 43.75%] [G loss: 0.970195]\n",
      "epoch:46 step:36363[D loss: 0.404870, acc: 64.06%, op_acc: 43.75%] [G loss: 0.967653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36364[D loss: 0.482663, acc: 52.34%, op_acc: 42.19%] [G loss: 0.894424]\n",
      "epoch:46 step:36365[D loss: 0.371845, acc: 69.53%, op_acc: 44.53%] [G loss: 0.980923]\n",
      "epoch:46 step:36366[D loss: 0.363963, acc: 71.88%, op_acc: 44.53%] [G loss: 0.860400]\n",
      "epoch:46 step:36367[D loss: 0.413434, acc: 63.28%, op_acc: 39.06%] [G loss: 1.036375]\n",
      "epoch:46 step:36368[D loss: 0.385949, acc: 68.75%, op_acc: 46.88%] [G loss: 1.003717]\n",
      "epoch:46 step:36369[D loss: 0.421415, acc: 63.28%, op_acc: 39.06%] [G loss: 0.959832]\n",
      "epoch:46 step:36370[D loss: 0.373974, acc: 64.84%, op_acc: 44.53%] [G loss: 1.010894]\n",
      "epoch:46 step:36371[D loss: 0.453364, acc: 52.34%, op_acc: 37.50%] [G loss: 0.840967]\n",
      "epoch:46 step:36372[D loss: 0.384848, acc: 69.53%, op_acc: 42.97%] [G loss: 1.027453]\n",
      "epoch:46 step:36373[D loss: 0.453714, acc: 54.69%, op_acc: 39.06%] [G loss: 0.986707]\n",
      "epoch:46 step:36374[D loss: 0.374465, acc: 72.66%, op_acc: 39.06%] [G loss: 0.968283]\n",
      "epoch:46 step:36375[D loss: 0.402007, acc: 67.19%, op_acc: 39.06%] [G loss: 1.043804]\n",
      "epoch:46 step:36376[D loss: 0.380978, acc: 64.06%, op_acc: 50.00%] [G loss: 1.092498]\n",
      "epoch:46 step:36377[D loss: 0.393426, acc: 62.50%, op_acc: 48.44%] [G loss: 0.883834]\n",
      "epoch:46 step:36378[D loss: 0.401786, acc: 58.59%, op_acc: 50.00%] [G loss: 1.074811]\n",
      "epoch:46 step:36379[D loss: 0.389506, acc: 64.84%, op_acc: 44.53%] [G loss: 0.839619]\n",
      "epoch:46 step:36380[D loss: 0.402737, acc: 57.81%, op_acc: 43.75%] [G loss: 0.960222]\n",
      "epoch:46 step:36381[D loss: 0.381882, acc: 67.97%, op_acc: 46.09%] [G loss: 1.032817]\n",
      "epoch:46 step:36382[D loss: 0.413255, acc: 65.62%, op_acc: 42.97%] [G loss: 0.735996]\n",
      "epoch:46 step:36383[D loss: 0.391312, acc: 64.84%, op_acc: 42.97%] [G loss: 0.925794]\n",
      "epoch:46 step:36384[D loss: 0.396028, acc: 60.94%, op_acc: 43.75%] [G loss: 0.876121]\n",
      "epoch:46 step:36385[D loss: 0.352571, acc: 67.19%, op_acc: 45.31%] [G loss: 1.034976]\n",
      "epoch:46 step:36386[D loss: 0.378807, acc: 67.19%, op_acc: 45.31%] [G loss: 0.998330]\n",
      "epoch:46 step:36387[D loss: 0.430095, acc: 53.12%, op_acc: 39.06%] [G loss: 0.956273]\n",
      "epoch:46 step:36388[D loss: 0.397094, acc: 63.28%, op_acc: 42.19%] [G loss: 0.829323]\n",
      "epoch:46 step:36389[D loss: 0.422474, acc: 55.47%, op_acc: 46.09%] [G loss: 0.697805]\n",
      "epoch:46 step:36390[D loss: 0.420575, acc: 58.59%, op_acc: 37.50%] [G loss: 0.941881]\n",
      "epoch:46 step:36391[D loss: 0.381649, acc: 67.97%, op_acc: 41.41%] [G loss: 0.869742]\n",
      "epoch:46 step:36392[D loss: 0.393033, acc: 63.28%, op_acc: 43.75%] [G loss: 1.033947]\n",
      "epoch:46 step:36393[D loss: 0.388254, acc: 57.03%, op_acc: 50.78%] [G loss: 0.989545]\n",
      "epoch:46 step:36394[D loss: 0.395475, acc: 61.72%, op_acc: 43.75%] [G loss: 0.775988]\n",
      "epoch:46 step:36395[D loss: 0.358522, acc: 69.53%, op_acc: 45.31%] [G loss: 1.063730]\n",
      "epoch:46 step:36396[D loss: 0.372594, acc: 67.97%, op_acc: 46.88%] [G loss: 0.824812]\n",
      "epoch:46 step:36397[D loss: 0.401647, acc: 64.06%, op_acc: 41.41%] [G loss: 1.049696]\n",
      "epoch:46 step:36398[D loss: 0.403701, acc: 67.97%, op_acc: 32.81%] [G loss: 1.094185]\n",
      "epoch:46 step:36399[D loss: 0.366534, acc: 71.88%, op_acc: 45.31%] [G loss: 0.880334]\n",
      "epoch:46 step:36400[D loss: 0.426057, acc: 55.47%, op_acc: 43.75%] [G loss: 0.713488]\n",
      "##############\n",
      "[0.86942176 0.85411588 0.8197568  0.81268753 0.78971675 0.82820977\n",
      " 0.89241101 0.83564863 0.83292634 0.84362937]\n",
      "##########\n",
      "epoch:46 step:36401[D loss: 0.385350, acc: 60.94%, op_acc: 47.66%] [G loss: 0.895858]\n",
      "epoch:46 step:36402[D loss: 0.365855, acc: 67.97%, op_acc: 42.97%] [G loss: 0.923437]\n",
      "epoch:46 step:36403[D loss: 0.405294, acc: 66.41%, op_acc: 41.41%] [G loss: 0.988894]\n",
      "epoch:46 step:36404[D loss: 0.402594, acc: 61.72%, op_acc: 42.97%] [G loss: 0.828078]\n",
      "epoch:46 step:36405[D loss: 0.385990, acc: 63.28%, op_acc: 43.75%] [G loss: 0.768172]\n",
      "epoch:46 step:36406[D loss: 0.417062, acc: 68.75%, op_acc: 38.28%] [G loss: 0.967442]\n",
      "epoch:46 step:36407[D loss: 0.439370, acc: 67.19%, op_acc: 38.28%] [G loss: 0.876207]\n",
      "epoch:46 step:36408[D loss: 0.364295, acc: 71.09%, op_acc: 40.62%] [G loss: 0.888113]\n",
      "epoch:46 step:36409[D loss: 0.383727, acc: 68.75%, op_acc: 48.44%] [G loss: 0.967754]\n",
      "epoch:46 step:36410[D loss: 0.394396, acc: 67.19%, op_acc: 50.00%] [G loss: 0.947050]\n",
      "epoch:46 step:36411[D loss: 0.398628, acc: 62.50%, op_acc: 45.31%] [G loss: 0.865934]\n",
      "epoch:46 step:36412[D loss: 0.385350, acc: 69.53%, op_acc: 46.88%] [G loss: 1.042722]\n",
      "epoch:46 step:36413[D loss: 0.372428, acc: 73.44%, op_acc: 43.75%] [G loss: 0.911860]\n",
      "epoch:46 step:36414[D loss: 0.400706, acc: 63.28%, op_acc: 50.78%] [G loss: 0.965380]\n",
      "epoch:46 step:36415[D loss: 0.386549, acc: 64.84%, op_acc: 47.66%] [G loss: 0.850579]\n",
      "epoch:46 step:36416[D loss: 0.340762, acc: 72.66%, op_acc: 51.56%] [G loss: 1.063832]\n",
      "epoch:46 step:36417[D loss: 0.452507, acc: 60.16%, op_acc: 38.28%] [G loss: 0.866630]\n",
      "epoch:46 step:36418[D loss: 0.374560, acc: 69.53%, op_acc: 53.12%] [G loss: 1.033591]\n",
      "epoch:46 step:36419[D loss: 0.424196, acc: 60.94%, op_acc: 50.00%] [G loss: 1.099043]\n",
      "epoch:46 step:36420[D loss: 0.352787, acc: 76.56%, op_acc: 46.88%] [G loss: 1.085167]\n",
      "epoch:46 step:36421[D loss: 0.357889, acc: 76.56%, op_acc: 44.53%] [G loss: 0.833953]\n",
      "epoch:46 step:36422[D loss: 0.361607, acc: 71.88%, op_acc: 46.09%] [G loss: 1.064026]\n",
      "epoch:46 step:36423[D loss: 0.368414, acc: 64.84%, op_acc: 49.22%] [G loss: 1.099777]\n",
      "epoch:46 step:36424[D loss: 0.373812, acc: 75.00%, op_acc: 49.22%] [G loss: 0.868075]\n",
      "epoch:46 step:36425[D loss: 0.385528, acc: 68.75%, op_acc: 42.97%] [G loss: 0.905110]\n",
      "epoch:46 step:36426[D loss: 0.383666, acc: 65.62%, op_acc: 41.41%] [G loss: 1.071485]\n",
      "epoch:46 step:36427[D loss: 0.392413, acc: 67.19%, op_acc: 43.75%] [G loss: 1.293802]\n",
      "epoch:46 step:36428[D loss: 0.395849, acc: 67.97%, op_acc: 42.97%] [G loss: 1.142253]\n",
      "epoch:46 step:36429[D loss: 0.379168, acc: 68.75%, op_acc: 39.06%] [G loss: 1.074455]\n",
      "epoch:46 step:36430[D loss: 0.377575, acc: 70.31%, op_acc: 47.66%] [G loss: 1.167645]\n",
      "epoch:46 step:36431[D loss: 0.392802, acc: 67.19%, op_acc: 39.84%] [G loss: 1.154722]\n",
      "epoch:46 step:36432[D loss: 0.358568, acc: 71.09%, op_acc: 50.00%] [G loss: 0.934672]\n",
      "epoch:46 step:36433[D loss: 0.349999, acc: 71.09%, op_acc: 46.88%] [G loss: 1.077718]\n",
      "epoch:46 step:36434[D loss: 0.389587, acc: 65.62%, op_acc: 42.97%] [G loss: 1.117833]\n",
      "epoch:46 step:36435[D loss: 0.374128, acc: 68.75%, op_acc: 47.66%] [G loss: 1.201594]\n",
      "epoch:46 step:36436[D loss: 0.355212, acc: 71.09%, op_acc: 44.53%] [G loss: 1.184840]\n",
      "epoch:46 step:36437[D loss: 0.364665, acc: 67.19%, op_acc: 49.22%] [G loss: 1.274362]\n",
      "epoch:46 step:36438[D loss: 0.370628, acc: 69.53%, op_acc: 44.53%] [G loss: 1.321410]\n",
      "epoch:46 step:36439[D loss: 0.397829, acc: 68.75%, op_acc: 41.41%] [G loss: 1.261499]\n",
      "epoch:46 step:36440[D loss: 0.352061, acc: 72.66%, op_acc: 46.09%] [G loss: 1.220687]\n",
      "epoch:46 step:36441[D loss: 0.374823, acc: 67.19%, op_acc: 43.75%] [G loss: 1.216089]\n",
      "epoch:46 step:36442[D loss: 0.335663, acc: 75.00%, op_acc: 46.88%] [G loss: 0.756457]\n",
      "epoch:46 step:36443[D loss: 0.380416, acc: 68.75%, op_acc: 45.31%] [G loss: 1.305955]\n",
      "epoch:46 step:36444[D loss: 0.324407, acc: 72.66%, op_acc: 53.12%] [G loss: 1.214814]\n",
      "epoch:46 step:36445[D loss: 0.311722, acc: 82.03%, op_acc: 51.56%] [G loss: 1.281827]\n",
      "epoch:46 step:36446[D loss: 0.324603, acc: 77.34%, op_acc: 47.66%] [G loss: 1.457640]\n",
      "epoch:46 step:36447[D loss: 0.323255, acc: 82.03%, op_acc: 47.66%] [G loss: 1.358134]\n",
      "epoch:46 step:36448[D loss: 0.359112, acc: 74.22%, op_acc: 49.22%] [G loss: 0.642674]\n",
      "epoch:46 step:36449[D loss: 0.422410, acc: 62.50%, op_acc: 38.28%] [G loss: 1.214873]\n",
      "epoch:46 step:36450[D loss: 0.381145, acc: 75.00%, op_acc: 44.53%] [G loss: 1.291769]\n",
      "##############\n",
      "[0.84515141 0.85787548 0.83378885 0.81108398 0.77830734 0.83991474\n",
      " 0.89436729 0.81606111 0.83905784 0.84356157]\n",
      "##########\n",
      "epoch:46 step:36451[D loss: 0.400961, acc: 64.84%, op_acc: 39.06%] [G loss: 1.377872]\n",
      "epoch:46 step:36452[D loss: 0.432166, acc: 59.38%, op_acc: 41.41%] [G loss: 1.353915]\n",
      "epoch:46 step:36453[D loss: 0.362809, acc: 69.53%, op_acc: 53.91%] [G loss: 1.236984]\n",
      "epoch:46 step:36454[D loss: 0.376091, acc: 67.97%, op_acc: 46.09%] [G loss: 1.269207]\n",
      "epoch:46 step:36455[D loss: 0.372232, acc: 71.09%, op_acc: 55.47%] [G loss: 0.778201]\n",
      "epoch:46 step:36456[D loss: 0.414168, acc: 60.94%, op_acc: 39.84%] [G loss: 1.304965]\n",
      "epoch:46 step:36457[D loss: 0.427345, acc: 65.62%, op_acc: 39.84%] [G loss: 1.221821]\n",
      "epoch:46 step:36458[D loss: 0.402659, acc: 65.62%, op_acc: 42.19%] [G loss: 1.264778]\n",
      "epoch:46 step:36459[D loss: 0.412394, acc: 59.38%, op_acc: 45.31%] [G loss: 1.147654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36460[D loss: 0.344248, acc: 71.09%, op_acc: 53.12%] [G loss: 1.198797]\n",
      "epoch:46 step:36461[D loss: 0.376945, acc: 72.66%, op_acc: 42.19%] [G loss: 1.414113]\n",
      "epoch:46 step:36462[D loss: 0.358014, acc: 70.31%, op_acc: 53.12%] [G loss: 1.235536]\n",
      "epoch:46 step:36463[D loss: 0.403568, acc: 63.28%, op_acc: 46.88%] [G loss: 0.787105]\n",
      "epoch:46 step:36464[D loss: 0.394349, acc: 61.72%, op_acc: 43.75%] [G loss: 0.756863]\n",
      "epoch:46 step:36465[D loss: 0.434168, acc: 57.03%, op_acc: 38.28%] [G loss: 0.814700]\n",
      "epoch:46 step:36466[D loss: 0.422012, acc: 56.25%, op_acc: 43.75%] [G loss: 1.149262]\n",
      "epoch:46 step:36467[D loss: 0.413536, acc: 62.50%, op_acc: 45.31%] [G loss: 1.138814]\n",
      "epoch:46 step:36468[D loss: 0.439880, acc: 61.72%, op_acc: 38.28%] [G loss: 1.191566]\n",
      "epoch:46 step:36469[D loss: 0.398758, acc: 64.84%, op_acc: 41.41%] [G loss: 1.006846]\n",
      "epoch:46 step:36470[D loss: 0.381442, acc: 60.94%, op_acc: 42.97%] [G loss: 1.089020]\n",
      "epoch:46 step:36471[D loss: 0.404572, acc: 62.50%, op_acc: 40.62%] [G loss: 1.104609]\n",
      "epoch:46 step:36472[D loss: 0.413574, acc: 62.50%, op_acc: 38.28%] [G loss: 0.912343]\n",
      "epoch:46 step:36473[D loss: 0.416148, acc: 60.16%, op_acc: 40.62%] [G loss: 0.852011]\n",
      "epoch:46 step:36474[D loss: 0.436091, acc: 60.16%, op_acc: 36.72%] [G loss: 0.924848]\n",
      "epoch:46 step:36475[D loss: 0.431923, acc: 57.81%, op_acc: 36.72%] [G loss: 1.016895]\n",
      "epoch:46 step:36476[D loss: 0.387349, acc: 64.06%, op_acc: 47.66%] [G loss: 0.971718]\n",
      "epoch:46 step:36477[D loss: 0.431396, acc: 56.25%, op_acc: 42.97%] [G loss: 1.081144]\n",
      "epoch:46 step:36478[D loss: 0.440439, acc: 60.94%, op_acc: 36.72%] [G loss: 0.937054]\n",
      "epoch:46 step:36479[D loss: 0.349329, acc: 73.44%, op_acc: 43.75%] [G loss: 1.072760]\n",
      "epoch:46 step:36480[D loss: 0.393553, acc: 62.50%, op_acc: 44.53%] [G loss: 1.169368]\n",
      "epoch:46 step:36481[D loss: 0.380438, acc: 68.75%, op_acc: 41.41%] [G loss: 0.831171]\n",
      "epoch:46 step:36482[D loss: 0.431302, acc: 60.94%, op_acc: 43.75%] [G loss: 1.223622]\n",
      "epoch:46 step:36483[D loss: 0.386138, acc: 70.31%, op_acc: 42.19%] [G loss: 0.957878]\n",
      "epoch:46 step:36484[D loss: 0.384217, acc: 63.28%, op_acc: 46.09%] [G loss: 1.048267]\n",
      "epoch:46 step:36485[D loss: 0.362137, acc: 65.62%, op_acc: 44.53%] [G loss: 1.021845]\n",
      "epoch:46 step:36486[D loss: 0.431097, acc: 60.94%, op_acc: 41.41%] [G loss: 0.953744]\n",
      "epoch:46 step:36487[D loss: 0.378762, acc: 67.19%, op_acc: 45.31%] [G loss: 0.929171]\n",
      "epoch:46 step:36488[D loss: 0.442992, acc: 60.94%, op_acc: 40.62%] [G loss: 1.148274]\n",
      "epoch:46 step:36489[D loss: 0.387031, acc: 65.62%, op_acc: 44.53%] [G loss: 1.063567]\n",
      "epoch:46 step:36490[D loss: 0.386003, acc: 71.88%, op_acc: 42.19%] [G loss: 0.836618]\n",
      "epoch:46 step:36491[D loss: 0.386941, acc: 66.41%, op_acc: 50.78%] [G loss: 0.928664]\n",
      "epoch:46 step:36492[D loss: 0.390853, acc: 64.06%, op_acc: 46.09%] [G loss: 0.777604]\n",
      "epoch:46 step:36493[D loss: 0.379558, acc: 71.88%, op_acc: 41.41%] [G loss: 0.948055]\n",
      "epoch:46 step:36494[D loss: 0.364220, acc: 73.44%, op_acc: 49.22%] [G loss: 1.200598]\n",
      "epoch:46 step:36495[D loss: 0.337234, acc: 76.56%, op_acc: 50.00%] [G loss: 0.998155]\n",
      "epoch:46 step:36496[D loss: 0.388627, acc: 64.06%, op_acc: 47.66%] [G loss: 1.030264]\n",
      "epoch:46 step:36497[D loss: 0.382750, acc: 64.84%, op_acc: 46.88%] [G loss: 0.919629]\n",
      "epoch:46 step:36498[D loss: 0.388396, acc: 67.97%, op_acc: 48.44%] [G loss: 0.886434]\n",
      "epoch:46 step:36499[D loss: 0.390176, acc: 71.88%, op_acc: 50.78%] [G loss: 0.999876]\n",
      "epoch:46 step:36500[D loss: 0.385880, acc: 66.41%, op_acc: 40.62%] [G loss: 0.986568]\n",
      "##############\n",
      "[0.86673639 0.87419647 0.81657781 0.79895787 0.79359917 0.82384122\n",
      " 0.87913185 0.82253058 0.80368788 0.82094321]\n",
      "##########\n",
      "epoch:46 step:36501[D loss: 0.357966, acc: 71.88%, op_acc: 43.75%] [G loss: 0.874006]\n",
      "epoch:46 step:36502[D loss: 0.353122, acc: 67.19%, op_acc: 42.19%] [G loss: 1.084897]\n",
      "epoch:46 step:36503[D loss: 0.354502, acc: 75.78%, op_acc: 47.66%] [G loss: 0.988017]\n",
      "epoch:46 step:36504[D loss: 0.408338, acc: 64.84%, op_acc: 45.31%] [G loss: 1.033698]\n",
      "epoch:46 step:36505[D loss: 0.317881, acc: 80.47%, op_acc: 46.09%] [G loss: 1.171896]\n",
      "epoch:46 step:36506[D loss: 0.384547, acc: 75.78%, op_acc: 46.88%] [G loss: 1.070138]\n",
      "epoch:46 step:36507[D loss: 0.361347, acc: 76.56%, op_acc: 46.88%] [G loss: 1.119766]\n",
      "epoch:46 step:36508[D loss: 0.362404, acc: 72.66%, op_acc: 47.66%] [G loss: 1.163601]\n",
      "epoch:46 step:36509[D loss: 0.385301, acc: 64.84%, op_acc: 44.53%] [G loss: 1.157416]\n",
      "epoch:46 step:36510[D loss: 0.346398, acc: 79.69%, op_acc: 42.19%] [G loss: 1.432189]\n",
      "epoch:46 step:36511[D loss: 0.306822, acc: 85.16%, op_acc: 50.78%] [G loss: 0.619605]\n",
      "epoch:46 step:36512[D loss: 0.421679, acc: 60.94%, op_acc: 39.06%] [G loss: 1.338936]\n",
      "epoch:46 step:36513[D loss: 0.350488, acc: 69.53%, op_acc: 42.19%] [G loss: 1.244436]\n",
      "epoch:46 step:36514[D loss: 0.365011, acc: 70.31%, op_acc: 52.34%] [G loss: 1.174537]\n",
      "epoch:46 step:36515[D loss: 0.354926, acc: 76.56%, op_acc: 49.22%] [G loss: 1.238709]\n",
      "epoch:46 step:36516[D loss: 0.408706, acc: 63.28%, op_acc: 42.97%] [G loss: 1.271463]\n",
      "epoch:46 step:36517[D loss: 0.388897, acc: 69.53%, op_acc: 45.31%] [G loss: 0.659440]\n",
      "epoch:46 step:36518[D loss: 0.418977, acc: 61.72%, op_acc: 42.97%] [G loss: 1.236879]\n",
      "epoch:46 step:36519[D loss: 0.420608, acc: 60.16%, op_acc: 39.84%] [G loss: 0.947452]\n",
      "epoch:46 step:36520[D loss: 0.411546, acc: 60.94%, op_acc: 42.19%] [G loss: 0.726723]\n",
      "epoch:46 step:36521[D loss: 0.458231, acc: 58.59%, op_acc: 35.16%] [G loss: 1.187576]\n",
      "epoch:46 step:36522[D loss: 0.432171, acc: 50.00%, op_acc: 41.41%] [G loss: 1.175341]\n",
      "epoch:46 step:36523[D loss: 0.413582, acc: 60.94%, op_acc: 45.31%] [G loss: 0.896152]\n",
      "epoch:46 step:36524[D loss: 0.372962, acc: 71.09%, op_acc: 42.19%] [G loss: 1.342210]\n",
      "epoch:46 step:36525[D loss: 0.439313, acc: 58.59%, op_acc: 40.62%] [G loss: 1.183173]\n",
      "epoch:46 step:36526[D loss: 0.402332, acc: 63.28%, op_acc: 48.44%] [G loss: 1.236961]\n",
      "epoch:46 step:36527[D loss: 0.431291, acc: 59.38%, op_acc: 38.28%] [G loss: 1.143902]\n",
      "epoch:46 step:36528[D loss: 0.343015, acc: 72.66%, op_acc: 49.22%] [G loss: 1.205178]\n",
      "epoch:46 step:36529[D loss: 0.418137, acc: 59.38%, op_acc: 44.53%] [G loss: 0.962764]\n",
      "epoch:46 step:36530[D loss: 0.451152, acc: 60.94%, op_acc: 36.72%] [G loss: 1.241389]\n",
      "epoch:46 step:36531[D loss: 0.422422, acc: 58.59%, op_acc: 44.53%] [G loss: 1.162700]\n",
      "epoch:46 step:36532[D loss: 0.377919, acc: 71.88%, op_acc: 46.88%] [G loss: 1.118830]\n",
      "epoch:46 step:36533[D loss: 0.374621, acc: 68.75%, op_acc: 44.53%] [G loss: 0.870019]\n",
      "epoch:46 step:36534[D loss: 0.361674, acc: 69.53%, op_acc: 50.78%] [G loss: 0.896887]\n",
      "epoch:46 step:36535[D loss: 0.426163, acc: 56.25%, op_acc: 44.53%] [G loss: 0.889182]\n",
      "epoch:46 step:36536[D loss: 0.407241, acc: 58.59%, op_acc: 44.53%] [G loss: 0.929057]\n",
      "epoch:46 step:36537[D loss: 0.404722, acc: 57.81%, op_acc: 44.53%] [G loss: 1.040124]\n",
      "epoch:46 step:36538[D loss: 0.435135, acc: 52.34%, op_acc: 42.97%] [G loss: 1.080195]\n",
      "epoch:46 step:36539[D loss: 0.440386, acc: 60.16%, op_acc: 42.19%] [G loss: 1.054783]\n",
      "epoch:46 step:36540[D loss: 0.381431, acc: 65.62%, op_acc: 45.31%] [G loss: 0.808527]\n",
      "epoch:46 step:36541[D loss: 0.402067, acc: 64.06%, op_acc: 42.19%] [G loss: 1.005692]\n",
      "epoch:46 step:36542[D loss: 0.438781, acc: 56.25%, op_acc: 36.72%] [G loss: 1.064372]\n",
      "epoch:46 step:36543[D loss: 0.443344, acc: 57.03%, op_acc: 44.53%] [G loss: 1.032625]\n",
      "epoch:46 step:36544[D loss: 0.402155, acc: 60.16%, op_acc: 50.00%] [G loss: 1.101761]\n",
      "epoch:46 step:36545[D loss: 0.386949, acc: 69.53%, op_acc: 47.66%] [G loss: 1.148877]\n",
      "epoch:46 step:36546[D loss: 0.390736, acc: 64.06%, op_acc: 42.19%] [G loss: 1.060952]\n",
      "epoch:46 step:36547[D loss: 0.353474, acc: 73.44%, op_acc: 48.44%] [G loss: 0.968772]\n",
      "epoch:46 step:36548[D loss: 0.442528, acc: 62.50%, op_acc: 39.84%] [G loss: 0.949620]\n",
      "epoch:46 step:36549[D loss: 0.359495, acc: 74.22%, op_acc: 42.19%] [G loss: 0.992996]\n",
      "epoch:46 step:36550[D loss: 0.411500, acc: 61.72%, op_acc: 45.31%] [G loss: 1.029335]\n",
      "##############\n",
      "[0.86657491 0.85915529 0.82541677 0.81478093 0.78310031 0.82773763\n",
      " 0.88590053 0.83786738 0.81140912 0.84162131]\n",
      "##########\n",
      "epoch:46 step:36551[D loss: 0.437300, acc: 60.94%, op_acc: 38.28%] [G loss: 0.824635]\n",
      "epoch:46 step:36552[D loss: 0.362411, acc: 69.53%, op_acc: 50.00%] [G loss: 0.905529]\n",
      "epoch:46 step:36553[D loss: 0.458680, acc: 55.47%, op_acc: 39.84%] [G loss: 0.854447]\n",
      "epoch:46 step:36554[D loss: 0.374012, acc: 72.66%, op_acc: 43.75%] [G loss: 0.921193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36555[D loss: 0.413580, acc: 60.94%, op_acc: 46.88%] [G loss: 0.823800]\n",
      "epoch:46 step:36556[D loss: 0.344660, acc: 70.31%, op_acc: 50.78%] [G loss: 0.954506]\n",
      "epoch:46 step:36557[D loss: 0.435258, acc: 53.91%, op_acc: 35.94%] [G loss: 0.787626]\n",
      "epoch:46 step:36558[D loss: 0.361710, acc: 69.53%, op_acc: 46.09%] [G loss: 0.766106]\n",
      "epoch:46 step:36559[D loss: 0.420946, acc: 56.25%, op_acc: 45.31%] [G loss: 0.968000]\n",
      "epoch:46 step:36560[D loss: 0.390720, acc: 69.53%, op_acc: 44.53%] [G loss: 1.185867]\n",
      "epoch:46 step:36561[D loss: 0.415722, acc: 65.62%, op_acc: 41.41%] [G loss: 1.082223]\n",
      "epoch:46 step:36562[D loss: 0.347838, acc: 71.09%, op_acc: 45.31%] [G loss: 0.957560]\n",
      "epoch:46 step:36563[D loss: 0.396604, acc: 64.06%, op_acc: 44.53%] [G loss: 1.037232]\n",
      "epoch:46 step:36564[D loss: 0.414750, acc: 61.72%, op_acc: 45.31%] [G loss: 1.050085]\n",
      "epoch:46 step:36565[D loss: 0.404253, acc: 62.50%, op_acc: 45.31%] [G loss: 1.242482]\n",
      "epoch:46 step:36566[D loss: 0.422780, acc: 57.81%, op_acc: 46.09%] [G loss: 1.081722]\n",
      "epoch:46 step:36567[D loss: 0.428146, acc: 60.94%, op_acc: 45.31%] [G loss: 0.916033]\n",
      "epoch:46 step:36568[D loss: 0.360358, acc: 70.31%, op_acc: 44.53%] [G loss: 1.105231]\n",
      "epoch:46 step:36569[D loss: 0.374769, acc: 62.50%, op_acc: 47.66%] [G loss: 1.074490]\n",
      "epoch:46 step:36570[D loss: 0.314124, acc: 75.78%, op_acc: 56.25%] [G loss: 1.199732]\n",
      "epoch:46 step:36571[D loss: 0.344528, acc: 75.78%, op_acc: 51.56%] [G loss: 0.738829]\n",
      "epoch:46 step:36572[D loss: 0.397178, acc: 62.50%, op_acc: 40.62%] [G loss: 1.166413]\n",
      "epoch:46 step:36573[D loss: 0.397300, acc: 60.94%, op_acc: 40.62%] [G loss: 1.125032]\n",
      "epoch:46 step:36574[D loss: 0.371343, acc: 68.75%, op_acc: 46.88%] [G loss: 1.148519]\n",
      "epoch:46 step:36575[D loss: 0.354798, acc: 75.78%, op_acc: 48.44%] [G loss: 1.150220]\n",
      "epoch:46 step:36576[D loss: 0.349304, acc: 75.78%, op_acc: 50.78%] [G loss: 1.157209]\n",
      "epoch:46 step:36577[D loss: 0.385715, acc: 67.97%, op_acc: 46.09%] [G loss: 1.253233]\n",
      "epoch:46 step:36578[D loss: 0.379243, acc: 71.88%, op_acc: 45.31%] [G loss: 1.123958]\n",
      "epoch:46 step:36579[D loss: 0.344607, acc: 73.44%, op_acc: 46.09%] [G loss: 0.975082]\n",
      "epoch:46 step:36580[D loss: 0.361268, acc: 73.44%, op_acc: 46.88%] [G loss: 1.143727]\n",
      "epoch:46 step:36581[D loss: 0.374614, acc: 68.75%, op_acc: 44.53%] [G loss: 1.174986]\n",
      "epoch:46 step:36582[D loss: 0.369500, acc: 75.78%, op_acc: 38.28%] [G loss: 1.015438]\n",
      "epoch:46 step:36583[D loss: 0.373455, acc: 67.97%, op_acc: 40.62%] [G loss: 1.150145]\n",
      "epoch:46 step:36584[D loss: 0.351088, acc: 76.56%, op_acc: 48.44%] [G loss: 1.393113]\n",
      "epoch:46 step:36585[D loss: 0.320451, acc: 81.25%, op_acc: 49.22%] [G loss: 0.738302]\n",
      "epoch:46 step:36586[D loss: 0.390183, acc: 66.41%, op_acc: 37.50%] [G loss: 0.692919]\n",
      "epoch:46 step:36587[D loss: 0.427771, acc: 60.94%, op_acc: 43.75%] [G loss: 1.135718]\n",
      "epoch:46 step:36588[D loss: 0.373486, acc: 67.19%, op_acc: 46.88%] [G loss: 1.202115]\n",
      "epoch:46 step:36589[D loss: 0.440649, acc: 53.91%, op_acc: 45.31%] [G loss: 1.131660]\n",
      "epoch:46 step:36590[D loss: 0.355756, acc: 71.09%, op_acc: 49.22%] [G loss: 0.846212]\n",
      "epoch:46 step:36591[D loss: 0.418693, acc: 64.84%, op_acc: 41.41%] [G loss: 0.989245]\n",
      "epoch:46 step:36592[D loss: 0.403379, acc: 62.50%, op_acc: 39.84%] [G loss: 1.096931]\n",
      "epoch:46 step:36593[D loss: 0.418671, acc: 62.50%, op_acc: 42.19%] [G loss: 0.822051]\n",
      "epoch:46 step:36594[D loss: 0.446359, acc: 57.81%, op_acc: 43.75%] [G loss: 0.988591]\n",
      "epoch:46 step:36595[D loss: 0.446124, acc: 61.72%, op_acc: 41.41%] [G loss: 1.012386]\n",
      "epoch:46 step:36596[D loss: 0.401455, acc: 64.84%, op_acc: 46.09%] [G loss: 0.956566]\n",
      "epoch:46 step:36597[D loss: 0.364505, acc: 71.88%, op_acc: 40.62%] [G loss: 1.029272]\n",
      "epoch:46 step:36598[D loss: 0.407254, acc: 65.62%, op_acc: 41.41%] [G loss: 0.914153]\n",
      "epoch:46 step:36599[D loss: 0.394158, acc: 63.28%, op_acc: 39.84%] [G loss: 1.121896]\n",
      "epoch:46 step:36600[D loss: 0.416355, acc: 62.50%, op_acc: 52.34%] [G loss: 0.875506]\n",
      "##############\n",
      "[0.86935401 0.84045739 0.81633033 0.80855114 0.77433351 0.81561597\n",
      " 0.88106692 0.83466173 0.81581704 0.84873695]\n",
      "##########\n",
      "epoch:46 step:36601[D loss: 0.385056, acc: 59.38%, op_acc: 44.53%] [G loss: 0.801613]\n",
      "epoch:46 step:36602[D loss: 0.423666, acc: 60.94%, op_acc: 42.97%] [G loss: 1.073519]\n",
      "epoch:46 step:36603[D loss: 0.435166, acc: 60.94%, op_acc: 39.06%] [G loss: 1.085959]\n",
      "epoch:46 step:36604[D loss: 0.364762, acc: 69.53%, op_acc: 44.53%] [G loss: 0.823593]\n",
      "epoch:46 step:36605[D loss: 0.364481, acc: 65.62%, op_acc: 53.91%] [G loss: 0.952937]\n",
      "epoch:46 step:36606[D loss: 0.382631, acc: 73.44%, op_acc: 39.06%] [G loss: 1.211979]\n",
      "epoch:46 step:36607[D loss: 0.404148, acc: 64.84%, op_acc: 41.41%] [G loss: 1.054535]\n",
      "epoch:46 step:36608[D loss: 0.346121, acc: 73.44%, op_acc: 49.22%] [G loss: 1.217119]\n",
      "epoch:46 step:36609[D loss: 0.339492, acc: 73.44%, op_acc: 50.78%] [G loss: 0.780858]\n",
      "epoch:46 step:36610[D loss: 0.400870, acc: 70.31%, op_acc: 35.94%] [G loss: 1.099512]\n",
      "epoch:46 step:36611[D loss: 0.376683, acc: 68.75%, op_acc: 47.66%] [G loss: 0.981184]\n",
      "epoch:46 step:36612[D loss: 0.386902, acc: 64.84%, op_acc: 47.66%] [G loss: 1.072698]\n",
      "epoch:46 step:36613[D loss: 0.384219, acc: 69.53%, op_acc: 44.53%] [G loss: 0.936279]\n",
      "epoch:46 step:36614[D loss: 0.369093, acc: 67.19%, op_acc: 48.44%] [G loss: 1.085134]\n",
      "epoch:46 step:36615[D loss: 0.370556, acc: 65.62%, op_acc: 57.03%] [G loss: 1.066848]\n",
      "epoch:46 step:36616[D loss: 0.357718, acc: 75.78%, op_acc: 47.66%] [G loss: 0.938982]\n",
      "epoch:46 step:36617[D loss: 0.342381, acc: 69.53%, op_acc: 46.88%] [G loss: 1.017092]\n",
      "epoch:46 step:36618[D loss: 0.373933, acc: 71.88%, op_acc: 49.22%] [G loss: 1.088663]\n",
      "epoch:46 step:36619[D loss: 0.335512, acc: 73.44%, op_acc: 51.56%] [G loss: 0.743001]\n",
      "epoch:46 step:36620[D loss: 0.434216, acc: 57.81%, op_acc: 39.84%] [G loss: 0.753153]\n",
      "epoch:46 step:36621[D loss: 0.449415, acc: 50.00%, op_acc: 34.38%] [G loss: 1.132158]\n",
      "epoch:46 step:36622[D loss: 0.415767, acc: 63.28%, op_acc: 38.28%] [G loss: 1.137656]\n",
      "epoch:46 step:36623[D loss: 0.405092, acc: 64.06%, op_acc: 45.31%] [G loss: 0.969722]\n",
      "epoch:46 step:36624[D loss: 0.419542, acc: 65.62%, op_acc: 39.06%] [G loss: 0.991667]\n",
      "epoch:46 step:36625[D loss: 0.382382, acc: 65.62%, op_acc: 46.88%] [G loss: 1.156821]\n",
      "epoch:46 step:36626[D loss: 0.360318, acc: 71.09%, op_acc: 53.91%] [G loss: 0.997081]\n",
      "epoch:46 step:36627[D loss: 0.419564, acc: 61.72%, op_acc: 39.84%] [G loss: 0.926307]\n",
      "epoch:46 step:36628[D loss: 0.426366, acc: 64.06%, op_acc: 41.41%] [G loss: 1.118396]\n",
      "epoch:46 step:36629[D loss: 0.414438, acc: 71.09%, op_acc: 37.50%] [G loss: 0.943943]\n",
      "epoch:46 step:36630[D loss: 0.366888, acc: 64.84%, op_acc: 55.47%] [G loss: 0.905716]\n",
      "epoch:46 step:36631[D loss: 0.442912, acc: 58.59%, op_acc: 37.50%] [G loss: 1.036659]\n",
      "epoch:46 step:36632[D loss: 0.416164, acc: 60.16%, op_acc: 42.19%] [G loss: 0.983679]\n",
      "epoch:46 step:36633[D loss: 0.449518, acc: 51.56%, op_acc: 41.41%] [G loss: 0.963859]\n",
      "epoch:46 step:36634[D loss: 0.400227, acc: 65.62%, op_acc: 39.06%] [G loss: 0.897468]\n",
      "epoch:46 step:36635[D loss: 0.373136, acc: 74.22%, op_acc: 46.88%] [G loss: 1.192194]\n",
      "epoch:46 step:36636[D loss: 0.359458, acc: 68.75%, op_acc: 49.22%] [G loss: 1.175154]\n",
      "epoch:46 step:36637[D loss: 0.386594, acc: 63.28%, op_acc: 43.75%] [G loss: 1.088526]\n",
      "epoch:46 step:36638[D loss: 0.317349, acc: 75.00%, op_acc: 48.44%] [G loss: 1.211841]\n",
      "epoch:46 step:36639[D loss: 0.351410, acc: 70.31%, op_acc: 50.78%] [G loss: 1.006138]\n",
      "epoch:46 step:36640[D loss: 0.338884, acc: 75.00%, op_acc: 49.22%] [G loss: 0.764359]\n",
      "epoch:46 step:36641[D loss: 0.430284, acc: 53.91%, op_acc: 42.97%] [G loss: 1.122659]\n",
      "epoch:46 step:36642[D loss: 0.384201, acc: 64.84%, op_acc: 45.31%] [G loss: 0.735461]\n",
      "epoch:46 step:36643[D loss: 0.369827, acc: 73.44%, op_acc: 48.44%] [G loss: 1.059083]\n",
      "epoch:46 step:36644[D loss: 0.387278, acc: 71.09%, op_acc: 43.75%] [G loss: 1.254706]\n",
      "epoch:46 step:36645[D loss: 0.382930, acc: 64.84%, op_acc: 48.44%] [G loss: 0.957318]\n",
      "epoch:46 step:36646[D loss: 0.377882, acc: 70.31%, op_acc: 50.78%] [G loss: 1.133326]\n",
      "epoch:46 step:36647[D loss: 0.395944, acc: 64.06%, op_acc: 42.97%] [G loss: 1.137698]\n",
      "epoch:46 step:36648[D loss: 0.331426, acc: 73.44%, op_acc: 48.44%] [G loss: 1.155853]\n",
      "epoch:46 step:36649[D loss: 0.382567, acc: 70.31%, op_acc: 43.75%] [G loss: 1.031650]\n",
      "epoch:46 step:36650[D loss: 0.397488, acc: 71.88%, op_acc: 40.62%] [G loss: 1.084141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.86043674 0.85025218 0.82808407 0.80438825 0.79503033 0.83539417\n",
      " 0.87103675 0.80920878 0.81556083 0.85314582]\n",
      "##########\n",
      "epoch:46 step:36651[D loss: 0.341928, acc: 75.78%, op_acc: 49.22%] [G loss: 1.140652]\n",
      "epoch:46 step:36652[D loss: 0.353854, acc: 75.78%, op_acc: 43.75%] [G loss: 1.065232]\n",
      "epoch:46 step:36653[D loss: 0.406641, acc: 66.41%, op_acc: 39.06%] [G loss: 1.144512]\n",
      "epoch:46 step:36654[D loss: 0.340151, acc: 78.12%, op_acc: 46.88%] [G loss: 1.208266]\n",
      "epoch:46 step:36655[D loss: 0.332945, acc: 80.47%, op_acc: 45.31%] [G loss: 1.198814]\n",
      "epoch:46 step:36656[D loss: 0.390768, acc: 64.06%, op_acc: 43.75%] [G loss: 1.255291]\n",
      "epoch:46 step:36657[D loss: 0.308789, acc: 79.69%, op_acc: 59.38%] [G loss: 1.311226]\n",
      "epoch:46 step:36658[D loss: 0.335959, acc: 78.12%, op_acc: 53.12%] [G loss: 0.920453]\n",
      "epoch:46 step:36659[D loss: 0.327237, acc: 78.91%, op_acc: 53.12%] [G loss: 1.459797]\n",
      "epoch:46 step:36660[D loss: 0.319676, acc: 83.59%, op_acc: 49.22%] [G loss: 1.268528]\n",
      "epoch:46 step:36661[D loss: 0.338181, acc: 78.12%, op_acc: 43.75%] [G loss: 1.209068]\n",
      "epoch:46 step:36662[D loss: 0.334478, acc: 74.22%, op_acc: 48.44%] [G loss: 0.675384]\n",
      "epoch:46 step:36663[D loss: 0.402464, acc: 55.47%, op_acc: 41.41%] [G loss: 1.337263]\n",
      "epoch:46 step:36664[D loss: 0.425203, acc: 59.38%, op_acc: 46.88%] [G loss: 1.217374]\n",
      "epoch:46 step:36665[D loss: 0.371053, acc: 64.84%, op_acc: 47.66%] [G loss: 0.708779]\n",
      "epoch:46 step:36666[D loss: 0.432101, acc: 60.16%, op_acc: 44.53%] [G loss: 1.168219]\n",
      "epoch:46 step:36667[D loss: 0.417959, acc: 64.06%, op_acc: 42.19%] [G loss: 0.769294]\n",
      "epoch:46 step:36668[D loss: 0.452540, acc: 51.56%, op_acc: 41.41%] [G loss: 1.091344]\n",
      "epoch:46 step:36669[D loss: 0.416266, acc: 60.16%, op_acc: 39.84%] [G loss: 1.123165]\n",
      "epoch:46 step:36670[D loss: 0.391456, acc: 66.41%, op_acc: 49.22%] [G loss: 1.166061]\n",
      "epoch:46 step:36671[D loss: 0.399547, acc: 60.94%, op_acc: 46.09%] [G loss: 0.935165]\n",
      "epoch:46 step:36672[D loss: 0.421823, acc: 59.38%, op_acc: 46.09%] [G loss: 1.296969]\n",
      "epoch:46 step:36673[D loss: 0.355944, acc: 72.66%, op_acc: 47.66%] [G loss: 1.081312]\n",
      "epoch:46 step:36674[D loss: 0.416891, acc: 60.94%, op_acc: 42.97%] [G loss: 1.094438]\n",
      "epoch:46 step:36675[D loss: 0.403335, acc: 65.62%, op_acc: 46.88%] [G loss: 1.197598]\n",
      "epoch:46 step:36676[D loss: 0.422435, acc: 57.03%, op_acc: 45.31%] [G loss: 0.904117]\n",
      "epoch:46 step:36677[D loss: 0.409412, acc: 64.84%, op_acc: 41.41%] [G loss: 1.446279]\n",
      "epoch:46 step:36678[D loss: 0.351404, acc: 75.78%, op_acc: 42.19%] [G loss: 1.314971]\n",
      "epoch:46 step:36679[D loss: 0.348405, acc: 79.69%, op_acc: 47.66%] [G loss: 1.203518]\n",
      "epoch:46 step:36680[D loss: 0.412321, acc: 60.94%, op_acc: 46.09%] [G loss: 1.118773]\n",
      "epoch:46 step:36681[D loss: 0.333875, acc: 71.88%, op_acc: 50.00%] [G loss: 1.246993]\n",
      "epoch:46 step:36682[D loss: 0.359720, acc: 71.09%, op_acc: 52.34%] [G loss: 1.151765]\n",
      "epoch:46 step:36683[D loss: 0.400610, acc: 65.62%, op_acc: 45.31%] [G loss: 1.259381]\n",
      "epoch:46 step:36684[D loss: 0.344769, acc: 67.97%, op_acc: 53.91%] [G loss: 1.171417]\n",
      "epoch:46 step:36685[D loss: 0.422889, acc: 57.03%, op_acc: 44.53%] [G loss: 1.124414]\n",
      "epoch:46 step:36686[D loss: 0.382008, acc: 66.41%, op_acc: 42.97%] [G loss: 1.112466]\n",
      "epoch:46 step:36687[D loss: 0.335099, acc: 74.22%, op_acc: 53.91%] [G loss: 1.167768]\n",
      "epoch:46 step:36688[D loss: 0.419152, acc: 57.03%, op_acc: 47.66%] [G loss: 1.147742]\n",
      "epoch:46 step:36689[D loss: 0.363014, acc: 71.88%, op_acc: 44.53%] [G loss: 1.164812]\n",
      "epoch:46 step:36690[D loss: 0.330923, acc: 74.22%, op_acc: 50.00%] [G loss: 0.732261]\n",
      "epoch:46 step:36691[D loss: 0.376913, acc: 64.06%, op_acc: 48.44%] [G loss: 0.990585]\n",
      "epoch:46 step:36692[D loss: 0.422906, acc: 59.38%, op_acc: 41.41%] [G loss: 1.214840]\n",
      "epoch:46 step:36693[D loss: 0.356920, acc: 68.75%, op_acc: 50.00%] [G loss: 0.761130]\n",
      "epoch:46 step:36694[D loss: 0.416511, acc: 59.38%, op_acc: 41.41%] [G loss: 1.291745]\n",
      "epoch:46 step:36695[D loss: 0.395015, acc: 60.16%, op_acc: 42.19%] [G loss: 0.838005]\n",
      "epoch:46 step:36696[D loss: 0.427580, acc: 54.69%, op_acc: 45.31%] [G loss: 1.264284]\n",
      "epoch:46 step:36697[D loss: 0.495263, acc: 45.31%, op_acc: 34.38%] [G loss: 1.397753]\n",
      "epoch:46 step:36698[D loss: 0.443242, acc: 57.03%, op_acc: 43.75%] [G loss: 1.217133]\n",
      "epoch:46 step:36699[D loss: 0.417570, acc: 61.72%, op_acc: 43.75%] [G loss: 1.272153]\n",
      "epoch:46 step:36700[D loss: 0.365880, acc: 69.53%, op_acc: 50.00%] [G loss: 1.224039]\n",
      "##############\n",
      "[0.87270905 0.87786048 0.79789604 0.80116875 0.77108194 0.84262883\n",
      " 0.87598839 0.83079995 0.8108516  0.83612159]\n",
      "##########\n",
      "epoch:46 step:36701[D loss: 0.421259, acc: 60.94%, op_acc: 42.97%] [G loss: 1.136746]\n",
      "epoch:46 step:36702[D loss: 0.425790, acc: 55.47%, op_acc: 45.31%] [G loss: 1.195705]\n",
      "epoch:46 step:36703[D loss: 0.390279, acc: 64.06%, op_acc: 44.53%] [G loss: 1.061874]\n",
      "epoch:46 step:36704[D loss: 0.394264, acc: 64.84%, op_acc: 50.78%] [G loss: 1.072256]\n",
      "epoch:46 step:36705[D loss: 0.368108, acc: 73.44%, op_acc: 44.53%] [G loss: 1.269558]\n",
      "epoch:46 step:36706[D loss: 0.395691, acc: 64.06%, op_acc: 51.56%] [G loss: 1.198442]\n",
      "epoch:46 step:36707[D loss: 0.355619, acc: 72.66%, op_acc: 40.62%] [G loss: 0.989256]\n",
      "epoch:47 step:36708[D loss: 0.383292, acc: 61.72%, op_acc: 49.22%] [G loss: 1.082333]\n",
      "epoch:47 step:36709[D loss: 0.397644, acc: 64.06%, op_acc: 49.22%] [G loss: 1.224413]\n",
      "epoch:47 step:36710[D loss: 0.403799, acc: 62.50%, op_acc: 42.97%] [G loss: 0.995025]\n",
      "epoch:47 step:36711[D loss: 0.367004, acc: 60.16%, op_acc: 47.66%] [G loss: 0.989673]\n",
      "epoch:47 step:36712[D loss: 0.398238, acc: 61.72%, op_acc: 45.31%] [G loss: 0.984071]\n",
      "epoch:47 step:36713[D loss: 0.393048, acc: 57.81%, op_acc: 43.75%] [G loss: 0.962189]\n",
      "epoch:47 step:36714[D loss: 0.421379, acc: 54.69%, op_acc: 39.84%] [G loss: 0.892974]\n",
      "epoch:47 step:36715[D loss: 0.420039, acc: 64.84%, op_acc: 41.41%] [G loss: 0.943177]\n",
      "epoch:47 step:36716[D loss: 0.398412, acc: 61.72%, op_acc: 45.31%] [G loss: 0.904339]\n",
      "epoch:47 step:36717[D loss: 0.431520, acc: 56.25%, op_acc: 44.53%] [G loss: 0.979432]\n",
      "epoch:47 step:36718[D loss: 0.406663, acc: 63.28%, op_acc: 42.19%] [G loss: 0.981514]\n",
      "epoch:47 step:36719[D loss: 0.380987, acc: 67.97%, op_acc: 45.31%] [G loss: 1.015955]\n",
      "epoch:47 step:36720[D loss: 0.422336, acc: 58.59%, op_acc: 42.97%] [G loss: 1.040598]\n",
      "epoch:47 step:36721[D loss: 0.463077, acc: 58.59%, op_acc: 35.16%] [G loss: 0.793949]\n",
      "epoch:47 step:36722[D loss: 0.400814, acc: 63.28%, op_acc: 42.97%] [G loss: 0.770471]\n",
      "epoch:47 step:36723[D loss: 0.398256, acc: 66.41%, op_acc: 42.97%] [G loss: 1.008632]\n",
      "epoch:47 step:36724[D loss: 0.409923, acc: 64.84%, op_acc: 42.19%] [G loss: 1.015532]\n",
      "epoch:47 step:36725[D loss: 0.392448, acc: 64.06%, op_acc: 50.00%] [G loss: 0.776980]\n",
      "epoch:47 step:36726[D loss: 0.395051, acc: 62.50%, op_acc: 48.44%] [G loss: 0.734272]\n",
      "epoch:47 step:36727[D loss: 0.392169, acc: 58.59%, op_acc: 47.66%] [G loss: 1.029444]\n",
      "epoch:47 step:36728[D loss: 0.443960, acc: 46.88%, op_acc: 44.53%] [G loss: 0.932133]\n",
      "epoch:47 step:36729[D loss: 0.399721, acc: 64.84%, op_acc: 42.19%] [G loss: 0.869051]\n",
      "epoch:47 step:36730[D loss: 0.357603, acc: 71.09%, op_acc: 47.66%] [G loss: 0.776805]\n",
      "epoch:47 step:36731[D loss: 0.415591, acc: 58.59%, op_acc: 47.66%] [G loss: 0.715188]\n",
      "epoch:47 step:36732[D loss: 0.403476, acc: 63.28%, op_acc: 43.75%] [G loss: 0.705578]\n",
      "epoch:47 step:36733[D loss: 0.376131, acc: 61.72%, op_acc: 53.91%] [G loss: 0.862731]\n",
      "epoch:47 step:36734[D loss: 0.394003, acc: 67.97%, op_acc: 48.44%] [G loss: 0.926075]\n",
      "epoch:47 step:36735[D loss: 0.434744, acc: 52.34%, op_acc: 42.97%] [G loss: 0.782636]\n",
      "epoch:47 step:36736[D loss: 0.387668, acc: 62.50%, op_acc: 47.66%] [G loss: 0.890894]\n",
      "epoch:47 step:36737[D loss: 0.391179, acc: 60.94%, op_acc: 46.09%] [G loss: 1.116673]\n",
      "epoch:47 step:36738[D loss: 0.424762, acc: 67.19%, op_acc: 46.88%] [G loss: 1.012993]\n",
      "epoch:47 step:36739[D loss: 0.398342, acc: 67.97%, op_acc: 46.09%] [G loss: 1.008303]\n",
      "epoch:47 step:36740[D loss: 0.350579, acc: 70.31%, op_acc: 47.66%] [G loss: 1.116935]\n",
      "epoch:47 step:36741[D loss: 0.363873, acc: 66.41%, op_acc: 48.44%] [G loss: 1.179918]\n",
      "epoch:47 step:36742[D loss: 0.367776, acc: 70.31%, op_acc: 46.88%] [G loss: 1.148721]\n",
      "epoch:47 step:36743[D loss: 0.342471, acc: 76.56%, op_acc: 49.22%] [G loss: 1.017077]\n",
      "epoch:47 step:36744[D loss: 0.370529, acc: 69.53%, op_acc: 50.00%] [G loss: 1.044542]\n",
      "epoch:47 step:36745[D loss: 0.360861, acc: 69.53%, op_acc: 48.44%] [G loss: 1.070118]\n",
      "epoch:47 step:36746[D loss: 0.343122, acc: 76.56%, op_acc: 49.22%] [G loss: 1.113298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36747[D loss: 0.412712, acc: 64.06%, op_acc: 42.97%] [G loss: 0.971998]\n",
      "epoch:47 step:36748[D loss: 0.321463, acc: 78.12%, op_acc: 57.03%] [G loss: 1.097630]\n",
      "epoch:47 step:36749[D loss: 0.332852, acc: 76.56%, op_acc: 47.66%] [G loss: 1.118174]\n",
      "epoch:47 step:36750[D loss: 0.368267, acc: 65.62%, op_acc: 42.19%] [G loss: 0.784796]\n",
      "##############\n",
      "[0.84146006 0.8841125  0.80210685 0.80527616 0.7923556  0.83083468\n",
      " 0.87773605 0.83402603 0.81160358 0.8062811 ]\n",
      "##########\n",
      "epoch:47 step:36751[D loss: 0.408825, acc: 60.94%, op_acc: 40.62%] [G loss: 0.823975]\n",
      "epoch:47 step:36752[D loss: 0.390983, acc: 64.84%, op_acc: 42.97%] [G loss: 1.109180]\n",
      "epoch:47 step:36753[D loss: 0.384774, acc: 67.19%, op_acc: 45.31%] [G loss: 0.997978]\n",
      "epoch:47 step:36754[D loss: 0.386067, acc: 62.50%, op_acc: 41.41%] [G loss: 1.190639]\n",
      "epoch:47 step:36755[D loss: 0.400399, acc: 69.53%, op_acc: 42.97%] [G loss: 1.053091]\n",
      "epoch:47 step:36756[D loss: 0.391093, acc: 62.50%, op_acc: 44.53%] [G loss: 1.154164]\n",
      "epoch:47 step:36757[D loss: 0.405814, acc: 65.62%, op_acc: 43.75%] [G loss: 1.114929]\n",
      "epoch:47 step:36758[D loss: 0.358002, acc: 74.22%, op_acc: 49.22%] [G loss: 0.977880]\n",
      "epoch:47 step:36759[D loss: 0.394356, acc: 65.62%, op_acc: 45.31%] [G loss: 1.220109]\n",
      "epoch:47 step:36760[D loss: 0.466458, acc: 51.56%, op_acc: 38.28%] [G loss: 1.025910]\n",
      "epoch:47 step:36761[D loss: 0.459630, acc: 54.69%, op_acc: 39.84%] [G loss: 0.960140]\n",
      "epoch:47 step:36762[D loss: 0.365912, acc: 68.75%, op_acc: 41.41%] [G loss: 0.989266]\n",
      "epoch:47 step:36763[D loss: 0.393102, acc: 66.41%, op_acc: 37.50%] [G loss: 1.113365]\n",
      "epoch:47 step:36764[D loss: 0.417660, acc: 60.16%, op_acc: 40.62%] [G loss: 1.067845]\n",
      "epoch:47 step:36765[D loss: 0.394215, acc: 61.72%, op_acc: 53.12%] [G loss: 0.957340]\n",
      "epoch:47 step:36766[D loss: 0.385734, acc: 63.28%, op_acc: 41.41%] [G loss: 0.889866]\n",
      "epoch:47 step:36767[D loss: 0.401431, acc: 62.50%, op_acc: 43.75%] [G loss: 0.836327]\n",
      "epoch:47 step:36768[D loss: 0.377378, acc: 67.97%, op_acc: 45.31%] [G loss: 0.891403]\n",
      "epoch:47 step:36769[D loss: 0.363009, acc: 71.09%, op_acc: 52.34%] [G loss: 0.971536]\n",
      "epoch:47 step:36770[D loss: 0.416314, acc: 55.47%, op_acc: 42.19%] [G loss: 1.049760]\n",
      "epoch:47 step:36771[D loss: 0.388326, acc: 64.06%, op_acc: 45.31%] [G loss: 1.088812]\n",
      "epoch:47 step:36772[D loss: 0.387952, acc: 68.75%, op_acc: 37.50%] [G loss: 1.141215]\n",
      "epoch:47 step:36773[D loss: 0.400253, acc: 62.50%, op_acc: 46.88%] [G loss: 1.018982]\n",
      "epoch:47 step:36774[D loss: 0.374344, acc: 67.97%, op_acc: 46.09%] [G loss: 1.062927]\n",
      "epoch:47 step:36775[D loss: 0.399201, acc: 59.38%, op_acc: 48.44%] [G loss: 0.907471]\n",
      "epoch:47 step:36776[D loss: 0.380578, acc: 60.16%, op_acc: 46.88%] [G loss: 0.648380]\n",
      "epoch:47 step:36777[D loss: 0.432847, acc: 57.03%, op_acc: 38.28%] [G loss: 1.043709]\n",
      "epoch:47 step:36778[D loss: 0.428334, acc: 64.06%, op_acc: 37.50%] [G loss: 1.030892]\n",
      "epoch:47 step:36779[D loss: 0.392311, acc: 62.50%, op_acc: 44.53%] [G loss: 0.920349]\n",
      "epoch:47 step:36780[D loss: 0.341818, acc: 71.09%, op_acc: 47.66%] [G loss: 0.641142]\n",
      "epoch:47 step:36781[D loss: 0.368808, acc: 66.41%, op_acc: 48.44%] [G loss: 0.673218]\n",
      "epoch:47 step:36782[D loss: 0.358458, acc: 70.31%, op_acc: 42.97%] [G loss: 1.093600]\n",
      "epoch:47 step:36783[D loss: 0.466684, acc: 53.91%, op_acc: 43.75%] [G loss: 0.914246]\n",
      "epoch:47 step:36784[D loss: 0.455884, acc: 53.91%, op_acc: 41.41%] [G loss: 1.003446]\n",
      "epoch:47 step:36785[D loss: 0.415466, acc: 64.06%, op_acc: 40.62%] [G loss: 1.087665]\n",
      "epoch:47 step:36786[D loss: 0.392444, acc: 64.84%, op_acc: 46.09%] [G loss: 0.982726]\n",
      "epoch:47 step:36787[D loss: 0.426403, acc: 70.31%, op_acc: 33.59%] [G loss: 1.002813]\n",
      "epoch:47 step:36788[D loss: 0.418476, acc: 64.84%, op_acc: 33.59%] [G loss: 1.086127]\n",
      "epoch:47 step:36789[D loss: 0.373626, acc: 71.09%, op_acc: 44.53%] [G loss: 0.908322]\n",
      "epoch:47 step:36790[D loss: 0.412207, acc: 60.16%, op_acc: 42.19%] [G loss: 0.911249]\n",
      "epoch:47 step:36791[D loss: 0.366505, acc: 62.50%, op_acc: 43.75%] [G loss: 0.965046]\n",
      "epoch:47 step:36792[D loss: 0.388169, acc: 66.41%, op_acc: 48.44%] [G loss: 0.975467]\n",
      "epoch:47 step:36793[D loss: 0.340309, acc: 75.78%, op_acc: 47.66%] [G loss: 1.110837]\n",
      "epoch:47 step:36794[D loss: 0.383434, acc: 68.75%, op_acc: 44.53%] [G loss: 0.950699]\n",
      "epoch:47 step:36795[D loss: 0.387961, acc: 67.19%, op_acc: 46.09%] [G loss: 1.061983]\n",
      "epoch:47 step:36796[D loss: 0.429083, acc: 57.03%, op_acc: 40.62%] [G loss: 1.137947]\n",
      "epoch:47 step:36797[D loss: 0.397783, acc: 64.84%, op_acc: 46.88%] [G loss: 1.028088]\n",
      "epoch:47 step:36798[D loss: 0.410571, acc: 60.16%, op_acc: 42.97%] [G loss: 1.007024]\n",
      "epoch:47 step:36799[D loss: 0.388580, acc: 70.31%, op_acc: 44.53%] [G loss: 0.878626]\n",
      "epoch:47 step:36800[D loss: 0.353080, acc: 67.19%, op_acc: 49.22%] [G loss: 0.984742]\n",
      "##############\n",
      "[0.85974939 0.86078212 0.79968561 0.81804467 0.8003378  0.84975388\n",
      " 0.9001216  0.82842626 0.79860898 0.80324479]\n",
      "##########\n",
      "epoch:47 step:36801[D loss: 0.387675, acc: 64.06%, op_acc: 42.97%] [G loss: 0.929709]\n",
      "epoch:47 step:36802[D loss: 0.394433, acc: 72.66%, op_acc: 41.41%] [G loss: 0.960192]\n",
      "epoch:47 step:36803[D loss: 0.400657, acc: 68.75%, op_acc: 41.41%] [G loss: 1.004081]\n",
      "epoch:47 step:36804[D loss: 0.368753, acc: 65.62%, op_acc: 53.12%] [G loss: 0.951950]\n",
      "epoch:47 step:36805[D loss: 0.370291, acc: 67.97%, op_acc: 41.41%] [G loss: 0.825902]\n",
      "epoch:47 step:36806[D loss: 0.340752, acc: 74.22%, op_acc: 46.09%] [G loss: 1.071985]\n",
      "epoch:47 step:36807[D loss: 0.370820, acc: 67.97%, op_acc: 50.78%] [G loss: 0.889333]\n",
      "epoch:47 step:36808[D loss: 0.394476, acc: 65.62%, op_acc: 42.97%] [G loss: 0.956663]\n",
      "epoch:47 step:36809[D loss: 0.369100, acc: 70.31%, op_acc: 45.31%] [G loss: 0.986672]\n",
      "epoch:47 step:36810[D loss: 0.376535, acc: 67.97%, op_acc: 45.31%] [G loss: 0.941882]\n",
      "epoch:47 step:36811[D loss: 0.334067, acc: 74.22%, op_acc: 47.66%] [G loss: 1.042606]\n",
      "epoch:47 step:36812[D loss: 0.356847, acc: 72.66%, op_acc: 46.09%] [G loss: 1.175828]\n",
      "epoch:47 step:36813[D loss: 0.341090, acc: 70.31%, op_acc: 43.75%] [G loss: 1.170939]\n",
      "epoch:47 step:36814[D loss: 0.315204, acc: 79.69%, op_acc: 57.03%] [G loss: 1.085194]\n",
      "epoch:47 step:36815[D loss: 0.359703, acc: 75.78%, op_acc: 49.22%] [G loss: 1.088605]\n",
      "epoch:47 step:36816[D loss: 0.334250, acc: 71.88%, op_acc: 48.44%] [G loss: 1.081499]\n",
      "epoch:47 step:36817[D loss: 0.343682, acc: 75.00%, op_acc: 47.66%] [G loss: 1.067870]\n",
      "epoch:47 step:36818[D loss: 0.347070, acc: 79.69%, op_acc: 46.09%] [G loss: 0.832854]\n",
      "epoch:47 step:36819[D loss: 0.404442, acc: 60.94%, op_acc: 44.53%] [G loss: 1.201118]\n",
      "epoch:47 step:36820[D loss: 0.416397, acc: 66.41%, op_acc: 35.94%] [G loss: 1.209812]\n",
      "epoch:47 step:36821[D loss: 0.378960, acc: 67.19%, op_acc: 47.66%] [G loss: 1.160371]\n",
      "epoch:47 step:36822[D loss: 0.370094, acc: 59.38%, op_acc: 50.00%] [G loss: 1.118135]\n",
      "epoch:47 step:36823[D loss: 0.402858, acc: 67.19%, op_acc: 51.56%] [G loss: 0.742294]\n",
      "epoch:47 step:36824[D loss: 0.397293, acc: 63.28%, op_acc: 46.09%] [G loss: 1.157035]\n",
      "epoch:47 step:36825[D loss: 0.395750, acc: 60.94%, op_acc: 47.66%] [G loss: 1.170566]\n",
      "epoch:47 step:36826[D loss: 0.399116, acc: 68.75%, op_acc: 39.06%] [G loss: 1.240821]\n",
      "epoch:47 step:36827[D loss: 0.349887, acc: 77.34%, op_acc: 39.84%] [G loss: 0.895564]\n",
      "epoch:47 step:36828[D loss: 0.384548, acc: 71.09%, op_acc: 49.22%] [G loss: 1.140759]\n",
      "epoch:47 step:36829[D loss: 0.395940, acc: 64.84%, op_acc: 45.31%] [G loss: 0.870140]\n",
      "epoch:47 step:36830[D loss: 0.458144, acc: 53.12%, op_acc: 43.75%] [G loss: 1.031571]\n",
      "epoch:47 step:36831[D loss: 0.424462, acc: 58.59%, op_acc: 40.62%] [G loss: 1.267803]\n",
      "epoch:47 step:36832[D loss: 0.441745, acc: 60.94%, op_acc: 34.38%] [G loss: 1.147799]\n",
      "epoch:47 step:36833[D loss: 0.396495, acc: 68.75%, op_acc: 35.16%] [G loss: 1.002796]\n",
      "epoch:47 step:36834[D loss: 0.380601, acc: 66.41%, op_acc: 46.88%] [G loss: 1.183627]\n",
      "epoch:47 step:36835[D loss: 0.387902, acc: 70.31%, op_acc: 41.41%] [G loss: 1.000577]\n",
      "epoch:47 step:36836[D loss: 0.365668, acc: 68.75%, op_acc: 45.31%] [G loss: 1.051766]\n",
      "epoch:47 step:36837[D loss: 0.379249, acc: 64.84%, op_acc: 46.88%] [G loss: 1.059669]\n",
      "epoch:47 step:36838[D loss: 0.377912, acc: 62.50%, op_acc: 44.53%] [G loss: 0.937799]\n",
      "epoch:47 step:36839[D loss: 0.311307, acc: 76.56%, op_acc: 50.00%] [G loss: 1.338214]\n",
      "epoch:47 step:36840[D loss: 0.446736, acc: 59.38%, op_acc: 39.84%] [G loss: 1.197511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36841[D loss: 0.397196, acc: 62.50%, op_acc: 50.00%] [G loss: 1.002295]\n",
      "epoch:47 step:36842[D loss: 0.434084, acc: 57.81%, op_acc: 47.66%] [G loss: 1.011068]\n",
      "epoch:47 step:36843[D loss: 0.329585, acc: 75.78%, op_acc: 48.44%] [G loss: 1.052884]\n",
      "epoch:47 step:36844[D loss: 0.368040, acc: 71.88%, op_acc: 49.22%] [G loss: 0.919240]\n",
      "epoch:47 step:36845[D loss: 0.411262, acc: 60.94%, op_acc: 40.62%] [G loss: 1.079749]\n",
      "epoch:47 step:36846[D loss: 0.370399, acc: 68.75%, op_acc: 51.56%] [G loss: 0.963718]\n",
      "epoch:47 step:36847[D loss: 0.459658, acc: 56.25%, op_acc: 43.75%] [G loss: 1.016989]\n",
      "epoch:47 step:36848[D loss: 0.403920, acc: 64.84%, op_acc: 38.28%] [G loss: 1.054947]\n",
      "epoch:47 step:36849[D loss: 0.394411, acc: 69.53%, op_acc: 39.06%] [G loss: 1.133708]\n",
      "epoch:47 step:36850[D loss: 0.458068, acc: 50.78%, op_acc: 38.28%] [G loss: 1.020003]\n",
      "##############\n",
      "[0.86473404 0.84663507 0.8066224  0.82438013 0.78142285 0.84943509\n",
      " 0.88851206 0.82832975 0.80464976 0.82872395]\n",
      "##########\n",
      "epoch:47 step:36851[D loss: 0.384529, acc: 60.16%, op_acc: 47.66%] [G loss: 0.922120]\n",
      "epoch:47 step:36852[D loss: 0.415628, acc: 61.72%, op_acc: 39.06%] [G loss: 0.891234]\n",
      "epoch:47 step:36853[D loss: 0.367394, acc: 65.62%, op_acc: 46.09%] [G loss: 1.104716]\n",
      "epoch:47 step:36854[D loss: 0.347864, acc: 71.88%, op_acc: 43.75%] [G loss: 0.940658]\n",
      "epoch:47 step:36855[D loss: 0.403509, acc: 63.28%, op_acc: 46.88%] [G loss: 0.829931]\n",
      "epoch:47 step:36856[D loss: 0.398853, acc: 62.50%, op_acc: 44.53%] [G loss: 0.721745]\n",
      "epoch:47 step:36857[D loss: 0.381795, acc: 64.06%, op_acc: 48.44%] [G loss: 0.832975]\n",
      "epoch:47 step:36858[D loss: 0.391217, acc: 58.59%, op_acc: 45.31%] [G loss: 0.865128]\n",
      "epoch:47 step:36859[D loss: 0.352513, acc: 70.31%, op_acc: 51.56%] [G loss: 0.911043]\n",
      "epoch:47 step:36860[D loss: 0.442326, acc: 57.81%, op_acc: 39.84%] [G loss: 0.956771]\n",
      "epoch:47 step:36861[D loss: 0.369967, acc: 69.53%, op_acc: 46.88%] [G loss: 1.022995]\n",
      "epoch:47 step:36862[D loss: 0.381685, acc: 65.62%, op_acc: 46.88%] [G loss: 0.934283]\n",
      "epoch:47 step:36863[D loss: 0.422376, acc: 58.59%, op_acc: 46.88%] [G loss: 0.916368]\n",
      "epoch:47 step:36864[D loss: 0.382284, acc: 65.62%, op_acc: 46.09%] [G loss: 1.027641]\n",
      "epoch:47 step:36865[D loss: 0.369404, acc: 64.06%, op_acc: 46.09%] [G loss: 0.827771]\n",
      "epoch:47 step:36866[D loss: 0.410299, acc: 61.72%, op_acc: 42.97%] [G loss: 0.996373]\n",
      "epoch:47 step:36867[D loss: 0.395622, acc: 64.06%, op_acc: 42.97%] [G loss: 1.102087]\n",
      "epoch:47 step:36868[D loss: 0.441996, acc: 62.50%, op_acc: 39.06%] [G loss: 0.942527]\n",
      "epoch:47 step:36869[D loss: 0.357338, acc: 75.00%, op_acc: 49.22%] [G loss: 0.981466]\n",
      "epoch:47 step:36870[D loss: 0.385572, acc: 65.62%, op_acc: 42.97%] [G loss: 1.050445]\n",
      "epoch:47 step:36871[D loss: 0.439416, acc: 55.47%, op_acc: 39.06%] [G loss: 0.772399]\n",
      "epoch:47 step:36872[D loss: 0.353854, acc: 71.09%, op_acc: 46.88%] [G loss: 1.125864]\n",
      "epoch:47 step:36873[D loss: 0.406225, acc: 63.28%, op_acc: 50.00%] [G loss: 0.745354]\n",
      "epoch:47 step:36874[D loss: 0.424367, acc: 57.81%, op_acc: 43.75%] [G loss: 0.719312]\n",
      "epoch:47 step:36875[D loss: 0.373162, acc: 66.41%, op_acc: 48.44%] [G loss: 0.905177]\n",
      "epoch:47 step:36876[D loss: 0.365164, acc: 71.09%, op_acc: 49.22%] [G loss: 0.930912]\n",
      "epoch:47 step:36877[D loss: 0.442084, acc: 57.03%, op_acc: 38.28%] [G loss: 0.839208]\n",
      "epoch:47 step:36878[D loss: 0.414061, acc: 60.94%, op_acc: 46.88%] [G loss: 0.796769]\n",
      "epoch:47 step:36879[D loss: 0.351165, acc: 73.44%, op_acc: 46.09%] [G loss: 0.976348]\n",
      "epoch:47 step:36880[D loss: 0.371119, acc: 71.09%, op_acc: 45.31%] [G loss: 0.870278]\n",
      "epoch:47 step:36881[D loss: 0.411195, acc: 64.06%, op_acc: 42.19%] [G loss: 0.890731]\n",
      "epoch:47 step:36882[D loss: 0.365724, acc: 65.62%, op_acc: 48.44%] [G loss: 0.982986]\n",
      "epoch:47 step:36883[D loss: 0.365080, acc: 69.53%, op_acc: 45.31%] [G loss: 1.114523]\n",
      "epoch:47 step:36884[D loss: 0.402569, acc: 61.72%, op_acc: 43.75%] [G loss: 0.977668]\n",
      "epoch:47 step:36885[D loss: 0.412592, acc: 60.16%, op_acc: 42.19%] [G loss: 1.066402]\n",
      "epoch:47 step:36886[D loss: 0.329879, acc: 74.22%, op_acc: 50.00%] [G loss: 0.909553]\n",
      "epoch:47 step:36887[D loss: 0.416164, acc: 64.84%, op_acc: 46.09%] [G loss: 1.142841]\n",
      "epoch:47 step:36888[D loss: 0.363796, acc: 74.22%, op_acc: 42.19%] [G loss: 1.150361]\n",
      "epoch:47 step:36889[D loss: 0.376043, acc: 64.84%, op_acc: 43.75%] [G loss: 1.304452]\n",
      "epoch:47 step:36890[D loss: 0.333262, acc: 76.56%, op_acc: 46.09%] [G loss: 1.038892]\n",
      "epoch:47 step:36891[D loss: 0.356077, acc: 74.22%, op_acc: 42.97%] [G loss: 1.171205]\n",
      "epoch:47 step:36892[D loss: 0.315758, acc: 83.59%, op_acc: 50.78%] [G loss: 1.320017]\n",
      "epoch:47 step:36893[D loss: 0.356347, acc: 69.53%, op_acc: 50.00%] [G loss: 1.227903]\n",
      "epoch:47 step:36894[D loss: 0.351474, acc: 71.88%, op_acc: 46.88%] [G loss: 1.270230]\n",
      "epoch:47 step:36895[D loss: 0.333756, acc: 75.00%, op_acc: 49.22%] [G loss: 1.272616]\n",
      "epoch:47 step:36896[D loss: 0.285856, acc: 89.84%, op_acc: 49.22%] [G loss: 0.867213]\n",
      "epoch:47 step:36897[D loss: 0.404766, acc: 68.75%, op_acc: 44.53%] [G loss: 1.021177]\n",
      "epoch:47 step:36898[D loss: 0.346092, acc: 71.09%, op_acc: 44.53%] [G loss: 1.440703]\n",
      "epoch:47 step:36899[D loss: 0.396633, acc: 73.44%, op_acc: 38.28%] [G loss: 1.261411]\n",
      "epoch:47 step:36900[D loss: 0.371083, acc: 70.31%, op_acc: 43.75%] [G loss: 1.252262]\n",
      "##############\n",
      "[0.85448807 0.87491788 0.82751179 0.79742005 0.81674852 0.81236401\n",
      " 0.88254473 0.82682268 0.81338697 0.81266462]\n",
      "##########\n",
      "epoch:47 step:36901[D loss: 0.335691, acc: 75.00%, op_acc: 50.00%] [G loss: 1.455318]\n",
      "epoch:47 step:36902[D loss: 0.368652, acc: 71.88%, op_acc: 46.88%] [G loss: 1.343648]\n",
      "epoch:47 step:36903[D loss: 0.303300, acc: 81.25%, op_acc: 50.00%] [G loss: 0.770950]\n",
      "epoch:47 step:36904[D loss: 0.407183, acc: 67.97%, op_acc: 44.53%] [G loss: 1.256235]\n",
      "epoch:47 step:36905[D loss: 0.440107, acc: 51.56%, op_acc: 42.97%] [G loss: 1.179466]\n",
      "epoch:47 step:36906[D loss: 0.400010, acc: 66.41%, op_acc: 40.62%] [G loss: 1.088192]\n",
      "epoch:47 step:36907[D loss: 0.383295, acc: 64.84%, op_acc: 45.31%] [G loss: 1.123344]\n",
      "epoch:47 step:36908[D loss: 0.338820, acc: 74.22%, op_acc: 45.31%] [G loss: 1.087306]\n",
      "epoch:47 step:36909[D loss: 0.371181, acc: 69.53%, op_acc: 44.53%] [G loss: 0.867108]\n",
      "epoch:47 step:36910[D loss: 0.412399, acc: 63.28%, op_acc: 39.06%] [G loss: 1.011884]\n",
      "epoch:47 step:36911[D loss: 0.423653, acc: 60.94%, op_acc: 40.62%] [G loss: 0.911678]\n",
      "epoch:47 step:36912[D loss: 0.362318, acc: 74.22%, op_acc: 40.62%] [G loss: 0.967800]\n",
      "epoch:47 step:36913[D loss: 0.359300, acc: 71.09%, op_acc: 47.66%] [G loss: 1.012097]\n",
      "epoch:47 step:36914[D loss: 0.368152, acc: 71.09%, op_acc: 41.41%] [G loss: 0.974486]\n",
      "epoch:47 step:36915[D loss: 0.415429, acc: 64.84%, op_acc: 39.06%] [G loss: 0.935649]\n",
      "epoch:47 step:36916[D loss: 0.401519, acc: 62.50%, op_acc: 48.44%] [G loss: 0.848906]\n",
      "epoch:47 step:36917[D loss: 0.393348, acc: 67.97%, op_acc: 42.19%] [G loss: 1.063055]\n",
      "epoch:47 step:36918[D loss: 0.391788, acc: 67.97%, op_acc: 39.84%] [G loss: 1.026103]\n",
      "epoch:47 step:36919[D loss: 0.409292, acc: 64.06%, op_acc: 44.53%] [G loss: 1.051868]\n",
      "epoch:47 step:36920[D loss: 0.405368, acc: 65.62%, op_acc: 42.97%] [G loss: 1.096900]\n",
      "epoch:47 step:36921[D loss: 0.397343, acc: 60.94%, op_acc: 44.53%] [G loss: 1.061755]\n",
      "epoch:47 step:36922[D loss: 0.376767, acc: 71.88%, op_acc: 43.75%] [G loss: 1.143911]\n",
      "epoch:47 step:36923[D loss: 0.425031, acc: 61.72%, op_acc: 47.66%] [G loss: 1.062201]\n",
      "epoch:47 step:36924[D loss: 0.359455, acc: 69.53%, op_acc: 47.66%] [G loss: 1.103338]\n",
      "epoch:47 step:36925[D loss: 0.415353, acc: 60.94%, op_acc: 43.75%] [G loss: 1.006163]\n",
      "epoch:47 step:36926[D loss: 0.417012, acc: 58.59%, op_acc: 44.53%] [G loss: 1.097984]\n",
      "epoch:47 step:36927[D loss: 0.418652, acc: 63.28%, op_acc: 40.62%] [G loss: 0.893553]\n",
      "epoch:47 step:36928[D loss: 0.381369, acc: 67.19%, op_acc: 41.41%] [G loss: 1.008361]\n",
      "epoch:47 step:36929[D loss: 0.391527, acc: 64.84%, op_acc: 49.22%] [G loss: 0.923241]\n",
      "epoch:47 step:36930[D loss: 0.473631, acc: 53.12%, op_acc: 41.41%] [G loss: 1.045817]\n",
      "epoch:47 step:36931[D loss: 0.391907, acc: 64.84%, op_acc: 39.84%] [G loss: 0.962810]\n",
      "epoch:47 step:36932[D loss: 0.425086, acc: 61.72%, op_acc: 38.28%] [G loss: 0.934542]\n",
      "epoch:47 step:36933[D loss: 0.434363, acc: 57.03%, op_acc: 40.62%] [G loss: 0.719821]\n",
      "epoch:47 step:36934[D loss: 0.380653, acc: 67.19%, op_acc: 47.66%] [G loss: 0.928181]\n",
      "epoch:47 step:36935[D loss: 0.380251, acc: 65.62%, op_acc: 42.97%] [G loss: 0.761135]\n",
      "epoch:47 step:36936[D loss: 0.421389, acc: 61.72%, op_acc: 41.41%] [G loss: 1.157084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36937[D loss: 0.371043, acc: 67.97%, op_acc: 42.97%] [G loss: 0.725969]\n",
      "epoch:47 step:36938[D loss: 0.398216, acc: 60.94%, op_acc: 45.31%] [G loss: 0.691765]\n",
      "epoch:47 step:36939[D loss: 0.358918, acc: 71.88%, op_acc: 47.66%] [G loss: 1.134203]\n",
      "epoch:47 step:36940[D loss: 0.396270, acc: 67.19%, op_acc: 42.19%] [G loss: 0.672133]\n",
      "epoch:47 step:36941[D loss: 0.403702, acc: 67.19%, op_acc: 46.09%] [G loss: 1.109766]\n",
      "epoch:47 step:36942[D loss: 0.386064, acc: 70.31%, op_acc: 42.97%] [G loss: 1.091771]\n",
      "epoch:47 step:36943[D loss: 0.402988, acc: 65.62%, op_acc: 39.06%] [G loss: 1.199352]\n",
      "epoch:47 step:36944[D loss: 0.430464, acc: 57.81%, op_acc: 42.97%] [G loss: 0.749903]\n",
      "epoch:47 step:36945[D loss: 0.370003, acc: 71.09%, op_acc: 46.09%] [G loss: 1.135885]\n",
      "epoch:47 step:36946[D loss: 0.360881, acc: 72.66%, op_acc: 49.22%] [G loss: 0.770576]\n",
      "epoch:47 step:36947[D loss: 0.398373, acc: 57.81%, op_acc: 42.97%] [G loss: 0.709371]\n",
      "epoch:47 step:36948[D loss: 0.360613, acc: 67.19%, op_acc: 46.88%] [G loss: 1.135191]\n",
      "epoch:47 step:36949[D loss: 0.388080, acc: 65.62%, op_acc: 45.31%] [G loss: 1.032763]\n",
      "epoch:47 step:36950[D loss: 0.410460, acc: 57.81%, op_acc: 44.53%] [G loss: 0.785014]\n",
      "##############\n",
      "[0.8568866  0.86222773 0.79332758 0.79119762 0.80227181 0.80891005\n",
      " 0.89276037 0.81899116 0.81239148 0.82155601]\n",
      "##########\n",
      "epoch:47 step:36951[D loss: 0.422957, acc: 64.06%, op_acc: 44.53%] [G loss: 1.069909]\n",
      "epoch:47 step:36952[D loss: 0.394082, acc: 59.38%, op_acc: 46.88%] [G loss: 1.072978]\n",
      "epoch:47 step:36953[D loss: 0.405600, acc: 64.84%, op_acc: 45.31%] [G loss: 0.672457]\n",
      "epoch:47 step:36954[D loss: 0.423219, acc: 62.50%, op_acc: 46.88%] [G loss: 1.085013]\n",
      "epoch:47 step:36955[D loss: 0.436249, acc: 58.59%, op_acc: 39.06%] [G loss: 1.011278]\n",
      "epoch:47 step:36956[D loss: 0.385220, acc: 71.88%, op_acc: 46.09%] [G loss: 0.573240]\n",
      "epoch:47 step:36957[D loss: 0.405376, acc: 68.75%, op_acc: 40.62%] [G loss: 1.088413]\n",
      "epoch:47 step:36958[D loss: 0.365475, acc: 66.41%, op_acc: 48.44%] [G loss: 1.153795]\n",
      "epoch:47 step:36959[D loss: 0.361979, acc: 72.66%, op_acc: 42.19%] [G loss: 1.255880]\n",
      "epoch:47 step:36960[D loss: 0.400122, acc: 67.97%, op_acc: 46.09%] [G loss: 1.232749]\n",
      "epoch:47 step:36961[D loss: 0.437187, acc: 59.38%, op_acc: 42.19%] [G loss: 1.204988]\n",
      "epoch:47 step:36962[D loss: 0.364460, acc: 66.41%, op_acc: 45.31%] [G loss: 1.253788]\n",
      "epoch:47 step:36963[D loss: 0.359120, acc: 70.31%, op_acc: 51.56%] [G loss: 0.751677]\n",
      "epoch:47 step:36964[D loss: 0.412579, acc: 61.72%, op_acc: 41.41%] [G loss: 1.190212]\n",
      "epoch:47 step:36965[D loss: 0.404990, acc: 59.38%, op_acc: 48.44%] [G loss: 1.095248]\n",
      "epoch:47 step:36966[D loss: 0.345533, acc: 70.31%, op_acc: 46.09%] [G loss: 0.658804]\n",
      "epoch:47 step:36967[D loss: 0.405791, acc: 66.41%, op_acc: 41.41%] [G loss: 0.683653]\n",
      "epoch:47 step:36968[D loss: 0.373698, acc: 64.06%, op_acc: 48.44%] [G loss: 0.764566]\n",
      "epoch:47 step:36969[D loss: 0.398953, acc: 64.06%, op_acc: 45.31%] [G loss: 0.758549]\n",
      "epoch:47 step:36970[D loss: 0.391000, acc: 68.75%, op_acc: 46.09%] [G loss: 0.779303]\n",
      "epoch:47 step:36971[D loss: 0.436479, acc: 57.03%, op_acc: 45.31%] [G loss: 1.037751]\n",
      "epoch:47 step:36972[D loss: 0.377467, acc: 65.62%, op_acc: 47.66%] [G loss: 0.681249]\n",
      "epoch:47 step:36973[D loss: 0.387078, acc: 67.97%, op_acc: 42.97%] [G loss: 1.161666]\n",
      "epoch:47 step:36974[D loss: 0.489487, acc: 50.00%, op_acc: 42.19%] [G loss: 1.124936]\n",
      "epoch:47 step:36975[D loss: 0.376803, acc: 65.62%, op_acc: 49.22%] [G loss: 0.673259]\n",
      "epoch:47 step:36976[D loss: 0.369501, acc: 69.53%, op_acc: 47.66%] [G loss: 1.142362]\n",
      "epoch:47 step:36977[D loss: 0.412118, acc: 64.06%, op_acc: 42.97%] [G loss: 0.678377]\n",
      "epoch:47 step:36978[D loss: 0.403408, acc: 60.94%, op_acc: 46.88%] [G loss: 0.682629]\n",
      "epoch:47 step:36979[D loss: 0.422177, acc: 63.28%, op_acc: 43.75%] [G loss: 0.807899]\n",
      "epoch:47 step:36980[D loss: 0.450286, acc: 57.03%, op_acc: 44.53%] [G loss: 0.803705]\n",
      "epoch:47 step:36981[D loss: 0.339812, acc: 79.69%, op_acc: 46.09%] [G loss: 0.787448]\n",
      "epoch:47 step:36982[D loss: 0.411975, acc: 64.06%, op_acc: 42.97%] [G loss: 0.894381]\n",
      "epoch:47 step:36983[D loss: 0.445987, acc: 52.34%, op_acc: 42.19%] [G loss: 0.860265]\n",
      "epoch:47 step:36984[D loss: 0.404882, acc: 70.31%, op_acc: 32.81%] [G loss: 0.994366]\n",
      "epoch:47 step:36985[D loss: 0.415339, acc: 67.19%, op_acc: 41.41%] [G loss: 1.038352]\n",
      "epoch:47 step:36986[D loss: 0.407055, acc: 60.16%, op_acc: 46.09%] [G loss: 1.007499]\n",
      "epoch:47 step:36987[D loss: 0.425073, acc: 56.25%, op_acc: 40.62%] [G loss: 0.742787]\n",
      "epoch:47 step:36988[D loss: 0.392051, acc: 65.62%, op_acc: 43.75%] [G loss: 0.841005]\n",
      "epoch:47 step:36989[D loss: 0.438239, acc: 64.06%, op_acc: 37.50%] [G loss: 0.902205]\n",
      "epoch:47 step:36990[D loss: 0.389505, acc: 69.53%, op_acc: 44.53%] [G loss: 1.073137]\n",
      "epoch:47 step:36991[D loss: 0.390976, acc: 63.28%, op_acc: 42.97%] [G loss: 1.060755]\n",
      "epoch:47 step:36992[D loss: 0.392677, acc: 67.97%, op_acc: 42.19%] [G loss: 1.103813]\n",
      "epoch:47 step:36993[D loss: 0.400515, acc: 67.19%, op_acc: 41.41%] [G loss: 1.059088]\n",
      "epoch:47 step:36994[D loss: 0.457450, acc: 55.47%, op_acc: 40.62%] [G loss: 0.958994]\n",
      "epoch:47 step:36995[D loss: 0.375874, acc: 66.41%, op_acc: 46.88%] [G loss: 1.046919]\n",
      "epoch:47 step:36996[D loss: 0.394362, acc: 67.19%, op_acc: 42.19%] [G loss: 1.158407]\n",
      "epoch:47 step:36997[D loss: 0.390179, acc: 63.28%, op_acc: 45.31%] [G loss: 0.873532]\n",
      "epoch:47 step:36998[D loss: 0.372920, acc: 70.31%, op_acc: 48.44%] [G loss: 0.832661]\n",
      "epoch:47 step:36999[D loss: 0.448216, acc: 58.59%, op_acc: 39.06%] [G loss: 1.116631]\n",
      "epoch:47 step:37000[D loss: 0.412320, acc: 61.72%, op_acc: 40.62%] [G loss: 0.731340]\n",
      "##############\n",
      "[0.85611237 0.86936216 0.80606929 0.80578622 0.7835791  0.81345751\n",
      " 0.87856336 0.81779341 0.81996455 0.8319967 ]\n",
      "##########\n",
      "epoch:47 step:37001[D loss: 0.351053, acc: 70.31%, op_acc: 41.41%] [G loss: 0.740025]\n",
      "epoch:47 step:37002[D loss: 0.320935, acc: 74.22%, op_acc: 53.12%] [G loss: 0.668992]\n",
      "epoch:47 step:37003[D loss: 0.373636, acc: 60.94%, op_acc: 48.44%] [G loss: 0.617344]\n",
      "epoch:47 step:37004[D loss: 0.418926, acc: 58.59%, op_acc: 32.03%] [G loss: 1.184558]\n",
      "epoch:47 step:37005[D loss: 0.367215, acc: 73.44%, op_acc: 44.53%] [G loss: 0.945864]\n",
      "epoch:47 step:37006[D loss: 0.345427, acc: 75.00%, op_acc: 45.31%] [G loss: 0.694314]\n",
      "epoch:47 step:37007[D loss: 0.400956, acc: 63.28%, op_acc: 41.41%] [G loss: 0.650027]\n",
      "epoch:47 step:37008[D loss: 0.352676, acc: 74.22%, op_acc: 45.31%] [G loss: 0.883244]\n",
      "epoch:47 step:37009[D loss: 0.372262, acc: 67.19%, op_acc: 43.75%] [G loss: 1.043859]\n",
      "epoch:47 step:37010[D loss: 0.394249, acc: 70.31%, op_acc: 37.50%] [G loss: 0.922004]\n",
      "epoch:47 step:37011[D loss: 0.321891, acc: 79.69%, op_acc: 47.66%] [G loss: 0.876995]\n",
      "epoch:47 step:37012[D loss: 0.391823, acc: 64.84%, op_acc: 46.09%] [G loss: 0.952038]\n",
      "epoch:47 step:37013[D loss: 0.356302, acc: 78.91%, op_acc: 46.88%] [G loss: 1.201033]\n",
      "epoch:47 step:37014[D loss: 0.417218, acc: 64.84%, op_acc: 48.44%] [G loss: 1.072505]\n",
      "epoch:47 step:37015[D loss: 0.416706, acc: 60.94%, op_acc: 44.53%] [G loss: 0.840019]\n",
      "epoch:47 step:37016[D loss: 0.404895, acc: 65.62%, op_acc: 45.31%] [G loss: 0.757611]\n",
      "epoch:47 step:37017[D loss: 0.371856, acc: 66.41%, op_acc: 48.44%] [G loss: 1.086498]\n",
      "epoch:47 step:37018[D loss: 0.378556, acc: 65.62%, op_acc: 49.22%] [G loss: 0.802036]\n",
      "epoch:47 step:37019[D loss: 0.380916, acc: 65.62%, op_acc: 48.44%] [G loss: 0.838026]\n",
      "epoch:47 step:37020[D loss: 0.380295, acc: 67.97%, op_acc: 47.66%] [G loss: 0.797292]\n",
      "epoch:47 step:37021[D loss: 0.376235, acc: 72.66%, op_acc: 48.44%] [G loss: 1.135761]\n",
      "epoch:47 step:37022[D loss: 0.372676, acc: 73.44%, op_acc: 45.31%] [G loss: 1.036094]\n",
      "epoch:47 step:37023[D loss: 0.386208, acc: 61.72%, op_acc: 43.75%] [G loss: 1.034804]\n",
      "epoch:47 step:37024[D loss: 0.374115, acc: 71.88%, op_acc: 42.19%] [G loss: 1.059900]\n",
      "epoch:47 step:37025[D loss: 0.364486, acc: 72.66%, op_acc: 50.78%] [G loss: 1.335282]\n",
      "epoch:47 step:37026[D loss: 0.324176, acc: 77.34%, op_acc: 47.66%] [G loss: 1.161943]\n",
      "epoch:47 step:37027[D loss: 0.363572, acc: 67.97%, op_acc: 45.31%] [G loss: 1.354851]\n",
      "epoch:47 step:37028[D loss: 0.344309, acc: 75.78%, op_acc: 44.53%] [G loss: 1.236102]\n",
      "epoch:47 step:37029[D loss: 0.330347, acc: 82.03%, op_acc: 46.88%] [G loss: 1.277940]\n",
      "epoch:47 step:37030[D loss: 0.312907, acc: 78.12%, op_acc: 57.81%] [G loss: 1.178631]\n",
      "epoch:47 step:37031[D loss: 0.310568, acc: 82.81%, op_acc: 43.75%] [G loss: 1.096473]\n",
      "epoch:47 step:37032[D loss: 0.344720, acc: 74.22%, op_acc: 54.69%] [G loss: 1.376964]\n",
      "epoch:47 step:37033[D loss: 0.318203, acc: 75.78%, op_acc: 54.69%] [G loss: 1.324052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37034[D loss: 0.328952, acc: 78.91%, op_acc: 44.53%] [G loss: 1.182484]\n",
      "epoch:47 step:37035[D loss: 0.306711, acc: 77.34%, op_acc: 52.34%] [G loss: 1.274574]\n",
      "epoch:47 step:37036[D loss: 0.285947, acc: 86.72%, op_acc: 49.22%] [G loss: 1.334133]\n",
      "epoch:47 step:37037[D loss: 0.375024, acc: 65.62%, op_acc: 52.34%] [G loss: 0.699698]\n",
      "epoch:47 step:37038[D loss: 0.341474, acc: 74.22%, op_acc: 42.19%] [G loss: 1.305770]\n",
      "epoch:47 step:37039[D loss: 0.316675, acc: 76.56%, op_acc: 46.09%] [G loss: 1.433227]\n",
      "epoch:47 step:37040[D loss: 0.336713, acc: 79.69%, op_acc: 46.88%] [G loss: 1.313530]\n",
      "epoch:47 step:37041[D loss: 0.301808, acc: 83.59%, op_acc: 55.47%] [G loss: 1.628284]\n",
      "epoch:47 step:37042[D loss: 0.356518, acc: 74.22%, op_acc: 45.31%] [G loss: 1.461078]\n",
      "epoch:47 step:37043[D loss: 0.351245, acc: 71.88%, op_acc: 45.31%] [G loss: 1.553549]\n",
      "epoch:47 step:37044[D loss: 0.398951, acc: 67.97%, op_acc: 43.75%] [G loss: 1.433894]\n",
      "epoch:47 step:37045[D loss: 0.299689, acc: 78.12%, op_acc: 46.09%] [G loss: 1.270905]\n",
      "epoch:47 step:37046[D loss: 0.279743, acc: 83.59%, op_acc: 50.00%] [G loss: 1.523014]\n",
      "epoch:47 step:37047[D loss: 0.309770, acc: 80.47%, op_acc: 51.56%] [G loss: 0.785100]\n",
      "epoch:47 step:37048[D loss: 0.326749, acc: 73.44%, op_acc: 44.53%] [G loss: 1.498556]\n",
      "epoch:47 step:37049[D loss: 0.410702, acc: 64.84%, op_acc: 42.19%] [G loss: 1.437265]\n",
      "epoch:47 step:37050[D loss: 0.347171, acc: 72.66%, op_acc: 50.00%] [G loss: 1.592407]\n",
      "##############\n",
      "[0.86187525 0.87235652 0.80678863 0.81221296 0.79710514 0.84200568\n",
      " 0.89584647 0.83053825 0.79038021 0.83921772]\n",
      "##########\n",
      "epoch:47 step:37051[D loss: 0.356000, acc: 70.31%, op_acc: 44.53%] [G loss: 1.663218]\n",
      "epoch:47 step:37052[D loss: 0.390294, acc: 62.50%, op_acc: 48.44%] [G loss: 1.519731]\n",
      "epoch:47 step:37053[D loss: 0.306131, acc: 78.12%, op_acc: 47.66%] [G loss: 1.240972]\n",
      "epoch:47 step:37054[D loss: 0.350667, acc: 77.34%, op_acc: 51.56%] [G loss: 1.391456]\n",
      "epoch:47 step:37055[D loss: 0.331427, acc: 76.56%, op_acc: 46.88%] [G loss: 1.527014]\n",
      "epoch:47 step:37056[D loss: 0.355347, acc: 73.44%, op_acc: 47.66%] [G loss: 1.658080]\n",
      "epoch:47 step:37057[D loss: 0.350951, acc: 76.56%, op_acc: 42.97%] [G loss: 0.626580]\n",
      "epoch:47 step:37058[D loss: 0.413432, acc: 65.62%, op_acc: 46.09%] [G loss: 1.549583]\n",
      "epoch:47 step:37059[D loss: 0.437144, acc: 57.81%, op_acc: 38.28%] [G loss: 1.451626]\n",
      "epoch:47 step:37060[D loss: 0.334516, acc: 74.22%, op_acc: 45.31%] [G loss: 1.564802]\n",
      "epoch:47 step:37061[D loss: 0.415112, acc: 62.50%, op_acc: 41.41%] [G loss: 1.394176]\n",
      "epoch:47 step:37062[D loss: 0.326571, acc: 81.25%, op_acc: 45.31%] [G loss: 1.477993]\n",
      "epoch:47 step:37063[D loss: 0.370742, acc: 67.97%, op_acc: 44.53%] [G loss: 1.406996]\n",
      "epoch:47 step:37064[D loss: 0.370728, acc: 71.09%, op_acc: 40.62%] [G loss: 1.378607]\n",
      "epoch:47 step:37065[D loss: 0.340763, acc: 76.56%, op_acc: 46.09%] [G loss: 1.015538]\n",
      "epoch:47 step:37066[D loss: 0.377551, acc: 64.06%, op_acc: 45.31%] [G loss: 0.762459]\n",
      "epoch:47 step:37067[D loss: 0.427669, acc: 61.72%, op_acc: 51.56%] [G loss: 0.724689]\n",
      "epoch:47 step:37068[D loss: 0.452773, acc: 51.56%, op_acc: 45.31%] [G loss: 1.584930]\n",
      "epoch:47 step:37069[D loss: 0.388495, acc: 64.84%, op_acc: 43.75%] [G loss: 1.421109]\n",
      "epoch:47 step:37070[D loss: 0.470629, acc: 53.12%, op_acc: 42.97%] [G loss: 1.143417]\n",
      "epoch:47 step:37071[D loss: 0.428556, acc: 55.47%, op_acc: 43.75%] [G loss: 1.644054]\n",
      "epoch:47 step:37072[D loss: 0.363857, acc: 70.31%, op_acc: 49.22%] [G loss: 1.482727]\n",
      "epoch:47 step:37073[D loss: 0.440567, acc: 46.88%, op_acc: 40.62%] [G loss: 1.285739]\n",
      "epoch:47 step:37074[D loss: 0.425846, acc: 58.59%, op_acc: 43.75%] [G loss: 1.309066]\n",
      "epoch:47 step:37075[D loss: 0.356804, acc: 70.31%, op_acc: 46.09%] [G loss: 0.870050]\n",
      "epoch:47 step:37076[D loss: 0.406478, acc: 60.16%, op_acc: 39.84%] [G loss: 1.071021]\n",
      "epoch:47 step:37077[D loss: 0.411478, acc: 64.06%, op_acc: 42.97%] [G loss: 1.188443]\n",
      "epoch:47 step:37078[D loss: 0.324467, acc: 75.78%, op_acc: 52.34%] [G loss: 0.990762]\n",
      "epoch:47 step:37079[D loss: 0.391568, acc: 63.28%, op_acc: 42.97%] [G loss: 1.134806]\n",
      "epoch:47 step:37080[D loss: 0.398030, acc: 63.28%, op_acc: 47.66%] [G loss: 1.224567]\n",
      "epoch:47 step:37081[D loss: 0.414016, acc: 60.94%, op_acc: 42.19%] [G loss: 1.174464]\n",
      "epoch:47 step:37082[D loss: 0.360982, acc: 71.09%, op_acc: 40.62%] [G loss: 1.035184]\n",
      "epoch:47 step:37083[D loss: 0.415754, acc: 65.62%, op_acc: 32.81%] [G loss: 1.050205]\n",
      "epoch:47 step:37084[D loss: 0.372458, acc: 67.19%, op_acc: 43.75%] [G loss: 1.141975]\n",
      "epoch:47 step:37085[D loss: 0.422775, acc: 60.94%, op_acc: 38.28%] [G loss: 1.192543]\n",
      "epoch:47 step:37086[D loss: 0.405259, acc: 59.38%, op_acc: 43.75%] [G loss: 1.178314]\n",
      "epoch:47 step:37087[D loss: 0.455362, acc: 62.50%, op_acc: 40.62%] [G loss: 1.183291]\n",
      "epoch:47 step:37088[D loss: 0.357750, acc: 71.88%, op_acc: 41.41%] [G loss: 1.311111]\n",
      "epoch:47 step:37089[D loss: 0.416755, acc: 64.06%, op_acc: 43.75%] [G loss: 1.244598]\n",
      "epoch:47 step:37090[D loss: 0.391344, acc: 62.50%, op_acc: 42.19%] [G loss: 1.024516]\n",
      "epoch:47 step:37091[D loss: 0.432436, acc: 55.47%, op_acc: 41.41%] [G loss: 1.054004]\n",
      "epoch:47 step:37092[D loss: 0.419004, acc: 53.91%, op_acc: 48.44%] [G loss: 1.084928]\n",
      "epoch:47 step:37093[D loss: 0.366453, acc: 75.78%, op_acc: 49.22%] [G loss: 0.938340]\n",
      "epoch:47 step:37094[D loss: 0.460787, acc: 53.12%, op_acc: 40.62%] [G loss: 1.081528]\n",
      "epoch:47 step:37095[D loss: 0.493710, acc: 51.56%, op_acc: 35.16%] [G loss: 0.978050]\n",
      "epoch:47 step:37096[D loss: 0.444721, acc: 60.16%, op_acc: 35.94%] [G loss: 0.928579]\n",
      "epoch:47 step:37097[D loss: 0.441475, acc: 58.59%, op_acc: 41.41%] [G loss: 1.078336]\n",
      "epoch:47 step:37098[D loss: 0.453085, acc: 54.69%, op_acc: 41.41%] [G loss: 0.988850]\n",
      "epoch:47 step:37099[D loss: 0.372558, acc: 66.41%, op_acc: 46.88%] [G loss: 1.188223]\n",
      "epoch:47 step:37100[D loss: 0.455001, acc: 50.78%, op_acc: 46.88%] [G loss: 0.956379]\n",
      "##############\n",
      "[0.84448329 0.85353049 0.84397616 0.79239849 0.80619406 0.82293342\n",
      " 0.86274506 0.81184464 0.81589675 0.84756013]\n",
      "##########\n",
      "epoch:47 step:37101[D loss: 0.435758, acc: 63.28%, op_acc: 41.41%] [G loss: 0.946175]\n",
      "epoch:47 step:37102[D loss: 0.425322, acc: 62.50%, op_acc: 40.62%] [G loss: 1.002301]\n",
      "epoch:47 step:37103[D loss: 0.370337, acc: 64.06%, op_acc: 50.00%] [G loss: 1.100263]\n",
      "epoch:47 step:37104[D loss: 0.396298, acc: 63.28%, op_acc: 45.31%] [G loss: 0.961548]\n",
      "epoch:47 step:37105[D loss: 0.451100, acc: 53.91%, op_acc: 46.88%] [G loss: 1.009667]\n",
      "epoch:47 step:37106[D loss: 0.388983, acc: 68.75%, op_acc: 44.53%] [G loss: 1.037094]\n",
      "epoch:47 step:37107[D loss: 0.358286, acc: 69.53%, op_acc: 49.22%] [G loss: 1.132380]\n",
      "epoch:47 step:37108[D loss: 0.339956, acc: 76.56%, op_acc: 50.78%] [G loss: 1.029121]\n",
      "epoch:47 step:37109[D loss: 0.397604, acc: 68.75%, op_acc: 40.62%] [G loss: 0.896888]\n",
      "epoch:47 step:37110[D loss: 0.404077, acc: 69.53%, op_acc: 39.84%] [G loss: 1.177420]\n",
      "epoch:47 step:37111[D loss: 0.379996, acc: 67.19%, op_acc: 51.56%] [G loss: 0.928237]\n",
      "epoch:47 step:37112[D loss: 0.419940, acc: 64.84%, op_acc: 46.88%] [G loss: 1.052036]\n",
      "epoch:47 step:37113[D loss: 0.398359, acc: 52.34%, op_acc: 46.88%] [G loss: 1.106935]\n",
      "epoch:47 step:37114[D loss: 0.403915, acc: 67.19%, op_acc: 41.41%] [G loss: 1.013361]\n",
      "epoch:47 step:37115[D loss: 0.385333, acc: 70.31%, op_acc: 42.97%] [G loss: 0.902549]\n",
      "epoch:47 step:37116[D loss: 0.386478, acc: 66.41%, op_acc: 46.88%] [G loss: 1.036705]\n",
      "epoch:47 step:37117[D loss: 0.362321, acc: 67.97%, op_acc: 43.75%] [G loss: 0.892379]\n",
      "epoch:47 step:37118[D loss: 0.378096, acc: 67.97%, op_acc: 49.22%] [G loss: 0.876433]\n",
      "epoch:47 step:37119[D loss: 0.411183, acc: 56.25%, op_acc: 43.75%] [G loss: 1.019117]\n",
      "epoch:47 step:37120[D loss: 0.392330, acc: 62.50%, op_acc: 50.78%] [G loss: 0.872738]\n",
      "epoch:47 step:37121[D loss: 0.353774, acc: 74.22%, op_acc: 49.22%] [G loss: 0.977855]\n",
      "epoch:47 step:37122[D loss: 0.364274, acc: 73.44%, op_acc: 41.41%] [G loss: 0.964828]\n",
      "epoch:47 step:37123[D loss: 0.363167, acc: 73.44%, op_acc: 39.84%] [G loss: 1.068764]\n",
      "epoch:47 step:37124[D loss: 0.417819, acc: 58.59%, op_acc: 41.41%] [G loss: 0.921206]\n",
      "epoch:47 step:37125[D loss: 0.363625, acc: 69.53%, op_acc: 50.00%] [G loss: 1.149164]\n",
      "epoch:47 step:37126[D loss: 0.336801, acc: 70.31%, op_acc: 47.66%] [G loss: 0.738563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37127[D loss: 0.437391, acc: 58.59%, op_acc: 40.62%] [G loss: 0.985115]\n",
      "epoch:47 step:37128[D loss: 0.339438, acc: 73.44%, op_acc: 50.00%] [G loss: 0.871763]\n",
      "epoch:47 step:37129[D loss: 0.354516, acc: 70.31%, op_acc: 50.00%] [G loss: 0.939648]\n",
      "epoch:47 step:37130[D loss: 0.427321, acc: 59.38%, op_acc: 46.88%] [G loss: 1.070496]\n",
      "epoch:47 step:37131[D loss: 0.449952, acc: 55.47%, op_acc: 38.28%] [G loss: 1.176531]\n",
      "epoch:47 step:37132[D loss: 0.396934, acc: 61.72%, op_acc: 39.84%] [G loss: 1.134529]\n",
      "epoch:47 step:37133[D loss: 0.418551, acc: 63.28%, op_acc: 43.75%] [G loss: 1.029161]\n",
      "epoch:47 step:37134[D loss: 0.439162, acc: 58.59%, op_acc: 37.50%] [G loss: 1.163660]\n",
      "epoch:47 step:37135[D loss: 0.382049, acc: 66.41%, op_acc: 44.53%] [G loss: 0.995476]\n",
      "epoch:47 step:37136[D loss: 0.411999, acc: 60.16%, op_acc: 42.97%] [G loss: 0.972073]\n",
      "epoch:47 step:37137[D loss: 0.392253, acc: 64.84%, op_acc: 40.62%] [G loss: 0.984902]\n",
      "epoch:47 step:37138[D loss: 0.354243, acc: 75.00%, op_acc: 45.31%] [G loss: 1.051455]\n",
      "epoch:47 step:37139[D loss: 0.310969, acc: 78.91%, op_acc: 50.78%] [G loss: 1.144165]\n",
      "epoch:47 step:37140[D loss: 0.387874, acc: 68.75%, op_acc: 43.75%] [G loss: 1.045870]\n",
      "epoch:47 step:37141[D loss: 0.409163, acc: 56.25%, op_acc: 48.44%] [G loss: 0.980238]\n",
      "epoch:47 step:37142[D loss: 0.364834, acc: 69.53%, op_acc: 51.56%] [G loss: 0.936342]\n",
      "epoch:47 step:37143[D loss: 0.454058, acc: 66.41%, op_acc: 39.84%] [G loss: 1.032631]\n",
      "epoch:47 step:37144[D loss: 0.393360, acc: 65.62%, op_acc: 46.09%] [G loss: 0.945414]\n",
      "epoch:47 step:37145[D loss: 0.382607, acc: 67.19%, op_acc: 48.44%] [G loss: 1.031191]\n",
      "epoch:47 step:37146[D loss: 0.446230, acc: 60.16%, op_acc: 40.62%] [G loss: 0.833527]\n",
      "epoch:47 step:37147[D loss: 0.369678, acc: 71.88%, op_acc: 46.09%] [G loss: 1.113913]\n",
      "epoch:47 step:37148[D loss: 0.364806, acc: 69.53%, op_acc: 46.88%] [G loss: 1.169636]\n",
      "epoch:47 step:37149[D loss: 0.380502, acc: 64.84%, op_acc: 41.41%] [G loss: 0.910468]\n",
      "epoch:47 step:37150[D loss: 0.391783, acc: 64.06%, op_acc: 40.62%] [G loss: 1.214887]\n",
      "##############\n",
      "[0.83877042 0.86457864 0.81046805 0.82309787 0.79027988 0.84538881\n",
      " 0.90853697 0.80469738 0.8076697  0.83206223]\n",
      "##########\n",
      "epoch:47 step:37151[D loss: 0.378214, acc: 69.53%, op_acc: 43.75%] [G loss: 0.991633]\n",
      "epoch:47 step:37152[D loss: 0.441694, acc: 60.16%, op_acc: 39.84%] [G loss: 0.883033]\n",
      "epoch:47 step:37153[D loss: 0.394685, acc: 65.62%, op_acc: 45.31%] [G loss: 1.137113]\n",
      "epoch:47 step:37154[D loss: 0.437011, acc: 60.16%, op_acc: 43.75%] [G loss: 1.027999]\n",
      "epoch:47 step:37155[D loss: 0.349413, acc: 76.56%, op_acc: 44.53%] [G loss: 0.894966]\n",
      "epoch:47 step:37156[D loss: 0.334515, acc: 76.56%, op_acc: 46.88%] [G loss: 0.864469]\n",
      "epoch:47 step:37157[D loss: 0.385581, acc: 71.09%, op_acc: 42.97%] [G loss: 1.027534]\n",
      "epoch:47 step:37158[D loss: 0.418799, acc: 57.03%, op_acc: 43.75%] [G loss: 1.043571]\n",
      "epoch:47 step:37159[D loss: 0.403155, acc: 62.50%, op_acc: 49.22%] [G loss: 1.114028]\n",
      "epoch:47 step:37160[D loss: 0.376108, acc: 67.97%, op_acc: 44.53%] [G loss: 1.034349]\n",
      "epoch:47 step:37161[D loss: 0.400950, acc: 61.72%, op_acc: 41.41%] [G loss: 1.144058]\n",
      "epoch:47 step:37162[D loss: 0.438324, acc: 60.94%, op_acc: 41.41%] [G loss: 0.989375]\n",
      "epoch:47 step:37163[D loss: 0.377944, acc: 72.66%, op_acc: 37.50%] [G loss: 1.014173]\n",
      "epoch:47 step:37164[D loss: 0.437575, acc: 57.81%, op_acc: 42.97%] [G loss: 0.823245]\n",
      "epoch:47 step:37165[D loss: 0.362279, acc: 71.09%, op_acc: 46.09%] [G loss: 0.974909]\n",
      "epoch:47 step:37166[D loss: 0.379019, acc: 62.50%, op_acc: 47.66%] [G loss: 1.007259]\n",
      "epoch:47 step:37167[D loss: 0.335090, acc: 71.88%, op_acc: 51.56%] [G loss: 1.084544]\n",
      "epoch:47 step:37168[D loss: 0.377262, acc: 71.09%, op_acc: 40.62%] [G loss: 0.989823]\n",
      "epoch:47 step:37169[D loss: 0.351853, acc: 73.44%, op_acc: 43.75%] [G loss: 0.970293]\n",
      "epoch:47 step:37170[D loss: 0.392696, acc: 68.75%, op_acc: 52.34%] [G loss: 1.207271]\n",
      "epoch:47 step:37171[D loss: 0.355713, acc: 77.34%, op_acc: 43.75%] [G loss: 1.236510]\n",
      "epoch:47 step:37172[D loss: 0.388839, acc: 67.19%, op_acc: 46.09%] [G loss: 1.106472]\n",
      "epoch:47 step:37173[D loss: 0.288374, acc: 82.81%, op_acc: 51.56%] [G loss: 0.839743]\n",
      "epoch:47 step:37174[D loss: 0.391738, acc: 70.31%, op_acc: 45.31%] [G loss: 1.220696]\n",
      "epoch:47 step:37175[D loss: 0.374608, acc: 64.06%, op_acc: 47.66%] [G loss: 1.164322]\n",
      "epoch:47 step:37176[D loss: 0.275617, acc: 89.06%, op_acc: 55.47%] [G loss: 1.320302]\n",
      "epoch:47 step:37177[D loss: 0.326449, acc: 82.81%, op_acc: 50.78%] [G loss: 1.181405]\n",
      "epoch:47 step:37178[D loss: 0.345211, acc: 75.78%, op_acc: 44.53%] [G loss: 1.356188]\n",
      "epoch:47 step:37179[D loss: 0.342644, acc: 72.66%, op_acc: 49.22%] [G loss: 1.299913]\n",
      "epoch:47 step:37180[D loss: 0.336803, acc: 70.31%, op_acc: 53.12%] [G loss: 1.250468]\n",
      "epoch:47 step:37181[D loss: 0.323044, acc: 78.12%, op_acc: 53.12%] [G loss: 1.325032]\n",
      "epoch:47 step:37182[D loss: 0.303379, acc: 80.47%, op_acc: 53.91%] [G loss: 1.349318]\n",
      "epoch:47 step:37183[D loss: 0.275057, acc: 88.28%, op_acc: 53.91%] [G loss: 0.560596]\n",
      "epoch:47 step:37184[D loss: 0.379149, acc: 71.09%, op_acc: 45.31%] [G loss: 1.179929]\n",
      "epoch:47 step:37185[D loss: 0.395637, acc: 62.50%, op_acc: 46.88%] [G loss: 0.597344]\n",
      "epoch:47 step:37186[D loss: 0.476274, acc: 50.78%, op_acc: 39.84%] [G loss: 0.639883]\n",
      "epoch:47 step:37187[D loss: 0.458802, acc: 56.25%, op_acc: 38.28%] [G loss: 1.253487]\n",
      "epoch:47 step:37188[D loss: 0.443102, acc: 60.16%, op_acc: 39.06%] [G loss: 1.359292]\n",
      "epoch:47 step:37189[D loss: 0.455476, acc: 55.47%, op_acc: 35.16%] [G loss: 1.316440]\n",
      "epoch:47 step:37190[D loss: 0.413920, acc: 64.06%, op_acc: 46.09%] [G loss: 1.460792]\n",
      "epoch:47 step:37191[D loss: 0.386024, acc: 65.62%, op_acc: 49.22%] [G loss: 1.153926]\n",
      "epoch:47 step:37192[D loss: 0.392267, acc: 60.94%, op_acc: 46.88%] [G loss: 1.251078]\n",
      "epoch:47 step:37193[D loss: 0.372991, acc: 65.62%, op_acc: 46.88%] [G loss: 0.943062]\n",
      "epoch:47 step:37194[D loss: 0.375881, acc: 70.31%, op_acc: 47.66%] [G loss: 1.307293]\n",
      "epoch:47 step:37195[D loss: 0.408237, acc: 60.16%, op_acc: 45.31%] [G loss: 1.239561]\n",
      "epoch:47 step:37196[D loss: 0.383064, acc: 67.19%, op_acc: 46.88%] [G loss: 0.974291]\n",
      "epoch:47 step:37197[D loss: 0.331816, acc: 75.78%, op_acc: 45.31%] [G loss: 1.087760]\n",
      "epoch:47 step:37198[D loss: 0.438813, acc: 62.50%, op_acc: 36.72%] [G loss: 1.226973]\n",
      "epoch:47 step:37199[D loss: 0.406569, acc: 61.72%, op_acc: 46.09%] [G loss: 1.077615]\n",
      "epoch:47 step:37200[D loss: 0.406604, acc: 63.28%, op_acc: 46.09%] [G loss: 1.107055]\n",
      "##############\n",
      "[0.86101921 0.82934728 0.82005657 0.81253011 0.78600737 0.82029035\n",
      " 0.89196614 0.81131349 0.79508051 0.82870316]\n",
      "##########\n",
      "epoch:47 step:37201[D loss: 0.415262, acc: 64.06%, op_acc: 46.88%] [G loss: 1.050953]\n",
      "epoch:47 step:37202[D loss: 0.377310, acc: 70.31%, op_acc: 42.19%] [G loss: 0.937716]\n",
      "epoch:47 step:37203[D loss: 0.382244, acc: 70.31%, op_acc: 43.75%] [G loss: 1.029500]\n",
      "epoch:47 step:37204[D loss: 0.399584, acc: 63.28%, op_acc: 49.22%] [G loss: 1.152795]\n",
      "epoch:47 step:37205[D loss: 0.372782, acc: 72.66%, op_acc: 46.09%] [G loss: 0.996299]\n",
      "epoch:47 step:37206[D loss: 0.371498, acc: 71.88%, op_acc: 46.88%] [G loss: 1.146159]\n",
      "epoch:47 step:37207[D loss: 0.383168, acc: 71.88%, op_acc: 40.62%] [G loss: 1.144986]\n",
      "epoch:47 step:37208[D loss: 0.388051, acc: 67.97%, op_acc: 42.97%] [G loss: 0.846762]\n",
      "epoch:47 step:37209[D loss: 0.440545, acc: 55.47%, op_acc: 39.06%] [G loss: 1.184242]\n",
      "epoch:47 step:37210[D loss: 0.367994, acc: 69.53%, op_acc: 47.66%] [G loss: 0.981455]\n",
      "epoch:47 step:37211[D loss: 0.431175, acc: 56.25%, op_acc: 46.09%] [G loss: 1.227975]\n",
      "epoch:47 step:37212[D loss: 0.376409, acc: 68.75%, op_acc: 42.19%] [G loss: 1.099898]\n",
      "epoch:47 step:37213[D loss: 0.383230, acc: 61.72%, op_acc: 45.31%] [G loss: 0.757691]\n",
      "epoch:47 step:37214[D loss: 0.361976, acc: 71.09%, op_acc: 50.78%] [G loss: 0.855398]\n",
      "epoch:47 step:37215[D loss: 0.395605, acc: 64.06%, op_acc: 45.31%] [G loss: 0.933671]\n",
      "epoch:47 step:37216[D loss: 0.439403, acc: 58.59%, op_acc: 42.97%] [G loss: 0.952150]\n",
      "epoch:47 step:37217[D loss: 0.342839, acc: 79.69%, op_acc: 47.66%] [G loss: 0.899180]\n",
      "epoch:47 step:37218[D loss: 0.352152, acc: 69.53%, op_acc: 48.44%] [G loss: 1.013329]\n",
      "epoch:47 step:37219[D loss: 0.410122, acc: 64.06%, op_acc: 45.31%] [G loss: 0.960044]\n",
      "epoch:47 step:37220[D loss: 0.457445, acc: 49.22%, op_acc: 39.06%] [G loss: 0.962452]\n",
      "epoch:47 step:37221[D loss: 0.413184, acc: 64.06%, op_acc: 40.62%] [G loss: 0.980237]\n",
      "epoch:47 step:37222[D loss: 0.398122, acc: 62.50%, op_acc: 42.97%] [G loss: 1.062697]\n",
      "epoch:47 step:37223[D loss: 0.398213, acc: 65.62%, op_acc: 49.22%] [G loss: 0.859154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37224[D loss: 0.425889, acc: 60.16%, op_acc: 35.94%] [G loss: 0.978210]\n",
      "epoch:47 step:37225[D loss: 0.355049, acc: 67.19%, op_acc: 50.00%] [G loss: 1.029925]\n",
      "epoch:47 step:37226[D loss: 0.382819, acc: 64.06%, op_acc: 39.84%] [G loss: 0.955068]\n",
      "epoch:47 step:37227[D loss: 0.381663, acc: 68.75%, op_acc: 39.84%] [G loss: 0.971103]\n",
      "epoch:47 step:37228[D loss: 0.365439, acc: 73.44%, op_acc: 47.66%] [G loss: 1.069569]\n",
      "epoch:47 step:37229[D loss: 0.368510, acc: 76.56%, op_acc: 44.53%] [G loss: 1.014526]\n",
      "epoch:47 step:37230[D loss: 0.314870, acc: 79.69%, op_acc: 46.88%] [G loss: 1.065796]\n",
      "epoch:47 step:37231[D loss: 0.402716, acc: 62.50%, op_acc: 50.78%] [G loss: 0.961469]\n",
      "epoch:47 step:37232[D loss: 0.309835, acc: 82.81%, op_acc: 44.53%] [G loss: 1.428595]\n",
      "epoch:47 step:37233[D loss: 0.413534, acc: 66.41%, op_acc: 38.28%] [G loss: 1.145695]\n",
      "epoch:47 step:37234[D loss: 0.316503, acc: 78.12%, op_acc: 60.16%] [G loss: 0.854597]\n",
      "epoch:47 step:37235[D loss: 0.385285, acc: 62.50%, op_acc: 42.19%] [G loss: 0.993692]\n",
      "epoch:47 step:37236[D loss: 0.339777, acc: 75.78%, op_acc: 50.00%] [G loss: 1.131466]\n",
      "epoch:47 step:37237[D loss: 0.412019, acc: 62.50%, op_acc: 38.28%] [G loss: 0.971827]\n",
      "epoch:47 step:37238[D loss: 0.358031, acc: 78.12%, op_acc: 40.62%] [G loss: 1.111555]\n",
      "epoch:47 step:37239[D loss: 0.371098, acc: 70.31%, op_acc: 44.53%] [G loss: 1.196428]\n",
      "epoch:47 step:37240[D loss: 0.374670, acc: 70.31%, op_acc: 45.31%] [G loss: 1.076114]\n",
      "epoch:47 step:37241[D loss: 0.345815, acc: 68.75%, op_acc: 50.00%] [G loss: 1.096804]\n",
      "epoch:47 step:37242[D loss: 0.323799, acc: 77.34%, op_acc: 49.22%] [G loss: 1.059636]\n",
      "epoch:47 step:37243[D loss: 0.365495, acc: 71.09%, op_acc: 48.44%] [G loss: 1.195130]\n",
      "epoch:47 step:37244[D loss: 0.407416, acc: 65.62%, op_acc: 43.75%] [G loss: 1.116511]\n",
      "epoch:47 step:37245[D loss: 0.386378, acc: 63.28%, op_acc: 46.88%] [G loss: 0.989365]\n",
      "epoch:47 step:37246[D loss: 0.369699, acc: 81.25%, op_acc: 44.53%] [G loss: 0.874059]\n",
      "epoch:47 step:37247[D loss: 0.416629, acc: 59.38%, op_acc: 45.31%] [G loss: 1.246737]\n",
      "epoch:47 step:37248[D loss: 0.368044, acc: 62.50%, op_acc: 48.44%] [G loss: 1.217422]\n",
      "epoch:47 step:37249[D loss: 0.375779, acc: 70.31%, op_acc: 39.84%] [G loss: 1.172154]\n",
      "epoch:47 step:37250[D loss: 0.423224, acc: 60.94%, op_acc: 39.06%] [G loss: 0.922029]\n",
      "##############\n",
      "[0.84315387 0.83908302 0.82936185 0.82682755 0.78604125 0.84276062\n",
      " 0.89167982 0.85156567 0.8160964  0.84156121]\n",
      "##########\n",
      "epoch:47 step:37251[D loss: 0.369479, acc: 72.66%, op_acc: 46.09%] [G loss: 1.271729]\n",
      "epoch:47 step:37252[D loss: 0.354013, acc: 68.75%, op_acc: 48.44%] [G loss: 1.309792]\n",
      "epoch:47 step:37253[D loss: 0.335712, acc: 75.00%, op_acc: 43.75%] [G loss: 1.267549]\n",
      "epoch:47 step:37254[D loss: 0.371643, acc: 71.88%, op_acc: 44.53%] [G loss: 0.835185]\n",
      "epoch:47 step:37255[D loss: 0.376092, acc: 75.78%, op_acc: 39.06%] [G loss: 0.932112]\n",
      "epoch:47 step:37256[D loss: 0.419186, acc: 60.94%, op_acc: 44.53%] [G loss: 0.876534]\n",
      "epoch:47 step:37257[D loss: 0.409279, acc: 55.47%, op_acc: 37.50%] [G loss: 1.241292]\n",
      "epoch:47 step:37258[D loss: 0.392807, acc: 69.53%, op_acc: 45.31%] [G loss: 1.430924]\n",
      "epoch:47 step:37259[D loss: 0.456546, acc: 54.69%, op_acc: 42.19%] [G loss: 1.130225]\n",
      "epoch:47 step:37260[D loss: 0.380382, acc: 61.72%, op_acc: 41.41%] [G loss: 1.046243]\n",
      "epoch:47 step:37261[D loss: 0.408002, acc: 65.62%, op_acc: 42.97%] [G loss: 1.031261]\n",
      "epoch:47 step:37262[D loss: 0.394925, acc: 67.19%, op_acc: 47.66%] [G loss: 1.151547]\n",
      "epoch:47 step:37263[D loss: 0.393500, acc: 67.19%, op_acc: 46.88%] [G loss: 1.083016]\n",
      "epoch:47 step:37264[D loss: 0.416810, acc: 67.97%, op_acc: 39.84%] [G loss: 0.951420]\n",
      "epoch:47 step:37265[D loss: 0.354109, acc: 71.88%, op_acc: 45.31%] [G loss: 1.245445]\n",
      "epoch:47 step:37266[D loss: 0.371492, acc: 67.97%, op_acc: 46.88%] [G loss: 1.121593]\n",
      "epoch:47 step:37267[D loss: 0.368944, acc: 73.44%, op_acc: 42.97%] [G loss: 0.904334]\n",
      "epoch:47 step:37268[D loss: 0.353867, acc: 69.53%, op_acc: 47.66%] [G loss: 0.836491]\n",
      "epoch:47 step:37269[D loss: 0.392294, acc: 62.50%, op_acc: 49.22%] [G loss: 0.884110]\n",
      "epoch:47 step:37270[D loss: 0.349498, acc: 75.78%, op_acc: 47.66%] [G loss: 1.052294]\n",
      "epoch:47 step:37271[D loss: 0.384303, acc: 65.62%, op_acc: 45.31%] [G loss: 0.946074]\n",
      "epoch:47 step:37272[D loss: 0.399322, acc: 64.84%, op_acc: 44.53%] [G loss: 1.075315]\n",
      "epoch:47 step:37273[D loss: 0.367325, acc: 73.44%, op_acc: 39.06%] [G loss: 0.862977]\n",
      "epoch:47 step:37274[D loss: 0.335091, acc: 74.22%, op_acc: 54.69%] [G loss: 1.073498]\n",
      "epoch:47 step:37275[D loss: 0.346687, acc: 71.09%, op_acc: 52.34%] [G loss: 0.931412]\n",
      "epoch:47 step:37276[D loss: 0.340296, acc: 71.88%, op_acc: 49.22%] [G loss: 1.026910]\n",
      "epoch:47 step:37277[D loss: 0.367120, acc: 67.19%, op_acc: 46.09%] [G loss: 1.148626]\n",
      "epoch:47 step:37278[D loss: 0.370627, acc: 69.53%, op_acc: 50.78%] [G loss: 0.903823]\n",
      "epoch:47 step:37279[D loss: 0.397099, acc: 61.72%, op_acc: 44.53%] [G loss: 0.834353]\n",
      "epoch:47 step:37280[D loss: 0.439694, acc: 53.91%, op_acc: 46.88%] [G loss: 1.167603]\n",
      "epoch:47 step:37281[D loss: 0.389431, acc: 65.62%, op_acc: 47.66%] [G loss: 1.086492]\n",
      "epoch:47 step:37282[D loss: 0.410072, acc: 59.38%, op_acc: 44.53%] [G loss: 0.948654]\n",
      "epoch:47 step:37283[D loss: 0.392576, acc: 69.53%, op_acc: 45.31%] [G loss: 0.962880]\n",
      "epoch:47 step:37284[D loss: 0.438188, acc: 60.94%, op_acc: 41.41%] [G loss: 0.913432]\n",
      "epoch:47 step:37285[D loss: 0.465992, acc: 61.72%, op_acc: 39.84%] [G loss: 0.908130]\n",
      "epoch:47 step:37286[D loss: 0.335303, acc: 77.34%, op_acc: 50.78%] [G loss: 0.998708]\n",
      "epoch:47 step:37287[D loss: 0.426292, acc: 54.69%, op_acc: 41.41%] [G loss: 0.985535]\n",
      "epoch:47 step:37288[D loss: 0.420755, acc: 54.69%, op_acc: 43.75%] [G loss: 0.863643]\n",
      "epoch:47 step:37289[D loss: 0.417179, acc: 59.38%, op_acc: 40.62%] [G loss: 1.076008]\n",
      "epoch:47 step:37290[D loss: 0.354530, acc: 70.31%, op_acc: 42.97%] [G loss: 1.005521]\n",
      "epoch:47 step:37291[D loss: 0.435258, acc: 67.19%, op_acc: 42.97%] [G loss: 1.103768]\n",
      "epoch:47 step:37292[D loss: 0.440034, acc: 56.25%, op_acc: 43.75%] [G loss: 0.901266]\n",
      "epoch:47 step:37293[D loss: 0.389614, acc: 67.97%, op_acc: 39.06%] [G loss: 0.918055]\n",
      "epoch:47 step:37294[D loss: 0.431570, acc: 64.06%, op_acc: 39.84%] [G loss: 1.085205]\n",
      "epoch:47 step:37295[D loss: 0.392983, acc: 66.41%, op_acc: 52.34%] [G loss: 0.764275]\n",
      "epoch:47 step:37296[D loss: 0.360420, acc: 71.09%, op_acc: 49.22%] [G loss: 1.072946]\n",
      "epoch:47 step:37297[D loss: 0.354336, acc: 67.19%, op_acc: 52.34%] [G loss: 0.863987]\n",
      "epoch:47 step:37298[D loss: 0.394216, acc: 59.38%, op_acc: 49.22%] [G loss: 1.120210]\n",
      "epoch:47 step:37299[D loss: 0.390327, acc: 66.41%, op_acc: 50.00%] [G loss: 0.759302]\n",
      "epoch:47 step:37300[D loss: 0.453950, acc: 57.03%, op_acc: 40.62%] [G loss: 0.656256]\n",
      "##############\n",
      "[0.8481659  0.8425437  0.82672198 0.82531986 0.80470403 0.81423654\n",
      " 0.89713818 0.82416069 0.82628111 0.84487375]\n",
      "##########\n",
      "epoch:47 step:37301[D loss: 0.395344, acc: 72.66%, op_acc: 41.41%] [G loss: 0.757774]\n",
      "epoch:47 step:37302[D loss: 0.353976, acc: 71.09%, op_acc: 48.44%] [G loss: 1.231733]\n",
      "epoch:47 step:37303[D loss: 0.389855, acc: 66.41%, op_acc: 41.41%] [G loss: 0.733708]\n",
      "epoch:47 step:37304[D loss: 0.342883, acc: 75.78%, op_acc: 52.34%] [G loss: 0.945603]\n",
      "epoch:47 step:37305[D loss: 0.351888, acc: 74.22%, op_acc: 46.88%] [G loss: 1.186945]\n",
      "epoch:47 step:37306[D loss: 0.373852, acc: 66.41%, op_acc: 49.22%] [G loss: 0.711990]\n",
      "epoch:47 step:37307[D loss: 0.385569, acc: 65.62%, op_acc: 42.19%] [G loss: 1.016539]\n",
      "epoch:47 step:37308[D loss: 0.388617, acc: 71.09%, op_acc: 42.97%] [G loss: 0.963465]\n",
      "epoch:47 step:37309[D loss: 0.376095, acc: 71.88%, op_acc: 49.22%] [G loss: 0.794289]\n",
      "epoch:47 step:37310[D loss: 0.392483, acc: 57.81%, op_acc: 49.22%] [G loss: 0.842191]\n",
      "epoch:47 step:37311[D loss: 0.434590, acc: 60.16%, op_acc: 38.28%] [G loss: 1.002239]\n",
      "epoch:47 step:37312[D loss: 0.418906, acc: 57.81%, op_acc: 42.97%] [G loss: 1.016895]\n",
      "epoch:47 step:37313[D loss: 0.354322, acc: 70.31%, op_acc: 52.34%] [G loss: 1.092499]\n",
      "epoch:47 step:37314[D loss: 0.398712, acc: 63.28%, op_acc: 46.09%] [G loss: 1.091914]\n",
      "epoch:47 step:37315[D loss: 0.349846, acc: 68.75%, op_acc: 45.31%] [G loss: 0.945557]\n",
      "epoch:47 step:37316[D loss: 0.400633, acc: 62.50%, op_acc: 47.66%] [G loss: 0.869283]\n",
      "epoch:47 step:37317[D loss: 0.382731, acc: 65.62%, op_acc: 47.66%] [G loss: 0.947024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37318[D loss: 0.383221, acc: 68.75%, op_acc: 46.09%] [G loss: 1.007892]\n",
      "epoch:47 step:37319[D loss: 0.368656, acc: 69.53%, op_acc: 46.09%] [G loss: 0.994118]\n",
      "epoch:47 step:37320[D loss: 0.363367, acc: 66.41%, op_acc: 53.12%] [G loss: 1.258665]\n",
      "epoch:47 step:37321[D loss: 0.401892, acc: 62.50%, op_acc: 39.84%] [G loss: 0.947129]\n",
      "epoch:47 step:37322[D loss: 0.392557, acc: 73.44%, op_acc: 42.97%] [G loss: 0.878190]\n",
      "epoch:47 step:37323[D loss: 0.387076, acc: 71.09%, op_acc: 43.75%] [G loss: 0.722580]\n",
      "epoch:47 step:37324[D loss: 0.386258, acc: 65.62%, op_acc: 51.56%] [G loss: 0.755269]\n",
      "epoch:47 step:37325[D loss: 0.316932, acc: 73.44%, op_acc: 56.25%] [G loss: 0.932393]\n",
      "epoch:47 step:37326[D loss: 0.391278, acc: 66.41%, op_acc: 44.53%] [G loss: 0.906906]\n",
      "epoch:47 step:37327[D loss: 0.384490, acc: 67.19%, op_acc: 47.66%] [G loss: 0.781023]\n",
      "epoch:47 step:37328[D loss: 0.347076, acc: 72.66%, op_acc: 49.22%] [G loss: 0.793056]\n",
      "epoch:47 step:37329[D loss: 0.372297, acc: 72.66%, op_acc: 49.22%] [G loss: 0.838886]\n",
      "epoch:47 step:37330[D loss: 0.397042, acc: 63.28%, op_acc: 40.62%] [G loss: 0.918265]\n",
      "epoch:47 step:37331[D loss: 0.379390, acc: 64.84%, op_acc: 46.88%] [G loss: 0.866014]\n",
      "epoch:47 step:37332[D loss: 0.360767, acc: 75.00%, op_acc: 52.34%] [G loss: 1.138681]\n",
      "epoch:47 step:37333[D loss: 0.370529, acc: 67.19%, op_acc: 43.75%] [G loss: 1.012509]\n",
      "epoch:47 step:37334[D loss: 0.374830, acc: 67.19%, op_acc: 54.69%] [G loss: 1.247618]\n",
      "epoch:47 step:37335[D loss: 0.351087, acc: 71.09%, op_acc: 43.75%] [G loss: 0.979976]\n",
      "epoch:47 step:37336[D loss: 0.333940, acc: 73.44%, op_acc: 53.91%] [G loss: 0.853746]\n",
      "epoch:47 step:37337[D loss: 0.354049, acc: 72.66%, op_acc: 46.88%] [G loss: 1.192829]\n",
      "epoch:47 step:37338[D loss: 0.378616, acc: 72.66%, op_acc: 42.97%] [G loss: 0.957329]\n",
      "epoch:47 step:37339[D loss: 0.415919, acc: 62.50%, op_acc: 41.41%] [G loss: 0.945689]\n",
      "epoch:47 step:37340[D loss: 0.443389, acc: 60.16%, op_acc: 40.62%] [G loss: 0.915728]\n",
      "epoch:47 step:37341[D loss: 0.388705, acc: 65.62%, op_acc: 46.09%] [G loss: 0.991102]\n",
      "epoch:47 step:37342[D loss: 0.398146, acc: 74.22%, op_acc: 42.19%] [G loss: 1.087913]\n",
      "epoch:47 step:37343[D loss: 0.386972, acc: 63.28%, op_acc: 44.53%] [G loss: 1.262464]\n",
      "epoch:47 step:37344[D loss: 0.412531, acc: 58.59%, op_acc: 48.44%] [G loss: 1.219984]\n",
      "epoch:47 step:37345[D loss: 0.431764, acc: 59.38%, op_acc: 36.72%] [G loss: 1.186076]\n",
      "epoch:47 step:37346[D loss: 0.439326, acc: 60.16%, op_acc: 46.09%] [G loss: 1.084855]\n",
      "epoch:47 step:37347[D loss: 0.423131, acc: 59.38%, op_acc: 39.84%] [G loss: 1.238948]\n",
      "epoch:47 step:37348[D loss: 0.398930, acc: 61.72%, op_acc: 50.00%] [G loss: 0.984188]\n",
      "epoch:47 step:37349[D loss: 0.411626, acc: 61.72%, op_acc: 42.97%] [G loss: 0.969140]\n",
      "epoch:47 step:37350[D loss: 0.389210, acc: 64.84%, op_acc: 39.06%] [G loss: 1.239909]\n",
      "##############\n",
      "[0.85627861 0.87799726 0.81193435 0.79677066 0.81981953 0.81301463\n",
      " 0.89796027 0.85141489 0.80687187 0.83606619]\n",
      "##########\n",
      "epoch:47 step:37351[D loss: 0.337173, acc: 71.88%, op_acc: 57.03%] [G loss: 1.151583]\n",
      "epoch:47 step:37352[D loss: 0.340483, acc: 80.47%, op_acc: 41.41%] [G loss: 1.067079]\n",
      "epoch:47 step:37353[D loss: 0.342445, acc: 72.66%, op_acc: 44.53%] [G loss: 0.963472]\n",
      "epoch:47 step:37354[D loss: 0.355617, acc: 70.31%, op_acc: 51.56%] [G loss: 1.128468]\n",
      "epoch:47 step:37355[D loss: 0.398198, acc: 61.72%, op_acc: 48.44%] [G loss: 1.070313]\n",
      "epoch:47 step:37356[D loss: 0.343226, acc: 75.00%, op_acc: 46.09%] [G loss: 1.083510]\n",
      "epoch:47 step:37357[D loss: 0.373079, acc: 74.22%, op_acc: 45.31%] [G loss: 1.193363]\n",
      "epoch:47 step:37358[D loss: 0.346013, acc: 73.44%, op_acc: 49.22%] [G loss: 1.314889]\n",
      "epoch:47 step:37359[D loss: 0.349828, acc: 73.44%, op_acc: 46.88%] [G loss: 1.367903]\n",
      "epoch:47 step:37360[D loss: 0.313113, acc: 76.56%, op_acc: 49.22%] [G loss: 0.836976]\n",
      "epoch:47 step:37361[D loss: 0.379510, acc: 67.19%, op_acc: 39.84%] [G loss: 0.966678]\n",
      "epoch:47 step:37362[D loss: 0.378820, acc: 73.44%, op_acc: 46.09%] [G loss: 1.006788]\n",
      "epoch:47 step:37363[D loss: 0.425222, acc: 59.38%, op_acc: 42.19%] [G loss: 0.940171]\n",
      "epoch:47 step:37364[D loss: 0.369712, acc: 68.75%, op_acc: 40.62%] [G loss: 0.900430]\n",
      "epoch:47 step:37365[D loss: 0.371233, acc: 73.44%, op_acc: 39.84%] [G loss: 0.992607]\n",
      "epoch:47 step:37366[D loss: 0.366215, acc: 72.66%, op_acc: 44.53%] [G loss: 0.979371]\n",
      "epoch:47 step:37367[D loss: 0.379144, acc: 71.09%, op_acc: 47.66%] [G loss: 1.026980]\n",
      "epoch:47 step:37368[D loss: 0.357974, acc: 67.97%, op_acc: 43.75%] [G loss: 0.935941]\n",
      "epoch:47 step:37369[D loss: 0.370828, acc: 64.84%, op_acc: 45.31%] [G loss: 0.911685]\n",
      "epoch:47 step:37370[D loss: 0.394031, acc: 65.62%, op_acc: 44.53%] [G loss: 1.197118]\n",
      "epoch:47 step:37371[D loss: 0.390992, acc: 57.81%, op_acc: 49.22%] [G loss: 1.143903]\n",
      "epoch:47 step:37372[D loss: 0.381783, acc: 71.88%, op_acc: 46.09%] [G loss: 1.247728]\n",
      "epoch:47 step:37373[D loss: 0.409183, acc: 62.50%, op_acc: 46.09%] [G loss: 0.987585]\n",
      "epoch:47 step:37374[D loss: 0.401517, acc: 66.41%, op_acc: 43.75%] [G loss: 1.095345]\n",
      "epoch:47 step:37375[D loss: 0.379016, acc: 64.06%, op_acc: 47.66%] [G loss: 1.111199]\n",
      "epoch:47 step:37376[D loss: 0.401626, acc: 57.81%, op_acc: 45.31%] [G loss: 0.909959]\n",
      "epoch:47 step:37377[D loss: 0.387628, acc: 59.38%, op_acc: 50.78%] [G loss: 0.724462]\n",
      "epoch:47 step:37378[D loss: 0.437880, acc: 63.28%, op_acc: 39.06%] [G loss: 1.023751]\n",
      "epoch:47 step:37379[D loss: 0.439007, acc: 60.16%, op_acc: 42.97%] [G loss: 1.123455]\n",
      "epoch:47 step:37380[D loss: 0.373642, acc: 71.88%, op_acc: 41.41%] [G loss: 1.100084]\n",
      "epoch:47 step:37381[D loss: 0.411744, acc: 56.25%, op_acc: 47.66%] [G loss: 0.867657]\n",
      "epoch:47 step:37382[D loss: 0.360861, acc: 71.09%, op_acc: 46.88%] [G loss: 1.205480]\n",
      "epoch:47 step:37383[D loss: 0.423606, acc: 60.16%, op_acc: 39.06%] [G loss: 0.868261]\n",
      "epoch:47 step:37384[D loss: 0.425715, acc: 61.72%, op_acc: 41.41%] [G loss: 1.004229]\n",
      "epoch:47 step:37385[D loss: 0.382197, acc: 66.41%, op_acc: 48.44%] [G loss: 0.889532]\n",
      "epoch:47 step:37386[D loss: 0.344780, acc: 74.22%, op_acc: 47.66%] [G loss: 1.010876]\n",
      "epoch:47 step:37387[D loss: 0.387087, acc: 71.09%, op_acc: 46.88%] [G loss: 1.038157]\n",
      "epoch:47 step:37388[D loss: 0.380904, acc: 70.31%, op_acc: 39.84%] [G loss: 0.922358]\n",
      "epoch:47 step:37389[D loss: 0.318017, acc: 75.78%, op_acc: 50.78%] [G loss: 1.105138]\n",
      "epoch:47 step:37390[D loss: 0.432218, acc: 55.47%, op_acc: 40.62%] [G loss: 0.943312]\n",
      "epoch:47 step:37391[D loss: 0.377293, acc: 68.75%, op_acc: 43.75%] [G loss: 0.812416]\n",
      "epoch:47 step:37392[D loss: 0.393404, acc: 64.84%, op_acc: 39.84%] [G loss: 1.098763]\n",
      "epoch:47 step:37393[D loss: 0.383378, acc: 67.97%, op_acc: 42.97%] [G loss: 0.983526]\n",
      "epoch:47 step:37394[D loss: 0.371372, acc: 70.31%, op_acc: 44.53%] [G loss: 0.996650]\n",
      "epoch:47 step:37395[D loss: 0.393098, acc: 59.38%, op_acc: 39.84%] [G loss: 1.125557]\n",
      "epoch:47 step:37396[D loss: 0.355377, acc: 72.66%, op_acc: 52.34%] [G loss: 0.937543]\n",
      "epoch:47 step:37397[D loss: 0.376166, acc: 71.09%, op_acc: 41.41%] [G loss: 0.999910]\n",
      "epoch:47 step:37398[D loss: 0.403288, acc: 68.75%, op_acc: 44.53%] [G loss: 1.033542]\n",
      "epoch:47 step:37399[D loss: 0.482437, acc: 51.56%, op_acc: 42.19%] [G loss: 0.974106]\n",
      "epoch:47 step:37400[D loss: 0.386851, acc: 67.97%, op_acc: 42.97%] [G loss: 1.021308]\n",
      "##############\n",
      "[0.84944789 0.85052434 0.80444174 0.80466788 0.7940188  0.82712686\n",
      " 0.90496572 0.82788647 0.80827773 0.83005753]\n",
      "##########\n",
      "epoch:47 step:37401[D loss: 0.433384, acc: 60.94%, op_acc: 42.19%] [G loss: 0.900008]\n",
      "epoch:47 step:37402[D loss: 0.369084, acc: 77.34%, op_acc: 48.44%] [G loss: 0.956979]\n",
      "epoch:47 step:37403[D loss: 0.389873, acc: 67.19%, op_acc: 51.56%] [G loss: 0.869428]\n",
      "epoch:47 step:37404[D loss: 0.341168, acc: 71.09%, op_acc: 53.91%] [G loss: 0.906954]\n",
      "epoch:47 step:37405[D loss: 0.377934, acc: 71.09%, op_acc: 49.22%] [G loss: 0.912603]\n",
      "epoch:47 step:37406[D loss: 0.402119, acc: 60.94%, op_acc: 49.22%] [G loss: 0.936331]\n",
      "epoch:47 step:37407[D loss: 0.372725, acc: 71.09%, op_acc: 42.97%] [G loss: 0.938549]\n",
      "epoch:47 step:37408[D loss: 0.399095, acc: 65.62%, op_acc: 39.06%] [G loss: 1.085376]\n",
      "epoch:47 step:37409[D loss: 0.380331, acc: 66.41%, op_acc: 47.66%] [G loss: 0.936574]\n",
      "epoch:47 step:37410[D loss: 0.405229, acc: 65.62%, op_acc: 42.97%] [G loss: 1.082277]\n",
      "epoch:47 step:37411[D loss: 0.333089, acc: 71.88%, op_acc: 53.91%] [G loss: 0.834708]\n",
      "epoch:47 step:37412[D loss: 0.380053, acc: 67.19%, op_acc: 42.97%] [G loss: 0.959096]\n",
      "epoch:47 step:37413[D loss: 0.351461, acc: 73.44%, op_acc: 45.31%] [G loss: 0.983097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37414[D loss: 0.408987, acc: 65.62%, op_acc: 43.75%] [G loss: 0.937416]\n",
      "epoch:47 step:37415[D loss: 0.352640, acc: 71.88%, op_acc: 45.31%] [G loss: 0.855700]\n",
      "epoch:47 step:37416[D loss: 0.345883, acc: 75.78%, op_acc: 47.66%] [G loss: 1.123913]\n",
      "epoch:47 step:37417[D loss: 0.331156, acc: 75.78%, op_acc: 48.44%] [G loss: 1.024569]\n",
      "epoch:47 step:37418[D loss: 0.359987, acc: 78.12%, op_acc: 46.09%] [G loss: 0.985368]\n",
      "epoch:47 step:37419[D loss: 0.298575, acc: 78.91%, op_acc: 54.69%] [G loss: 0.875515]\n",
      "epoch:47 step:37420[D loss: 0.308376, acc: 76.56%, op_acc: 56.25%] [G loss: 0.912217]\n",
      "epoch:47 step:37421[D loss: 0.350621, acc: 74.22%, op_acc: 49.22%] [G loss: 1.144154]\n",
      "epoch:47 step:37422[D loss: 0.369478, acc: 67.97%, op_acc: 51.56%] [G loss: 0.948140]\n",
      "epoch:47 step:37423[D loss: 0.347869, acc: 71.09%, op_acc: 46.88%] [G loss: 1.384795]\n",
      "epoch:47 step:37424[D loss: 0.320881, acc: 79.69%, op_acc: 49.22%] [G loss: 1.239271]\n",
      "epoch:47 step:37425[D loss: 0.356643, acc: 74.22%, op_acc: 42.97%] [G loss: 1.277733]\n",
      "epoch:47 step:37426[D loss: 0.311646, acc: 79.69%, op_acc: 50.78%] [G loss: 1.113588]\n",
      "epoch:47 step:37427[D loss: 0.320667, acc: 75.78%, op_acc: 53.91%] [G loss: 1.195478]\n",
      "epoch:47 step:37428[D loss: 0.366408, acc: 69.53%, op_acc: 50.00%] [G loss: 0.550259]\n",
      "epoch:47 step:37429[D loss: 0.419876, acc: 58.59%, op_acc: 46.88%] [G loss: 0.665401]\n",
      "epoch:47 step:37430[D loss: 0.433385, acc: 57.81%, op_acc: 42.97%] [G loss: 1.203597]\n",
      "epoch:47 step:37431[D loss: 0.434695, acc: 58.59%, op_acc: 41.41%] [G loss: 1.035731]\n",
      "epoch:47 step:37432[D loss: 0.431102, acc: 60.16%, op_acc: 42.97%] [G loss: 1.348768]\n",
      "epoch:47 step:37433[D loss: 0.356918, acc: 75.00%, op_acc: 46.88%] [G loss: 0.975821]\n",
      "epoch:47 step:37434[D loss: 0.392248, acc: 70.31%, op_acc: 41.41%] [G loss: 1.178483]\n",
      "epoch:47 step:37435[D loss: 0.401131, acc: 67.97%, op_acc: 42.19%] [G loss: 1.179022]\n",
      "epoch:47 step:37436[D loss: 0.363733, acc: 72.66%, op_acc: 48.44%] [G loss: 1.215774]\n",
      "epoch:47 step:37437[D loss: 0.399480, acc: 67.97%, op_acc: 46.88%] [G loss: 1.370976]\n",
      "epoch:47 step:37438[D loss: 0.367210, acc: 68.75%, op_acc: 46.09%] [G loss: 1.301259]\n",
      "epoch:47 step:37439[D loss: 0.399682, acc: 62.50%, op_acc: 45.31%] [G loss: 1.129671]\n",
      "epoch:47 step:37440[D loss: 0.335967, acc: 78.12%, op_acc: 43.75%] [G loss: 1.231110]\n",
      "epoch:47 step:37441[D loss: 0.349402, acc: 76.56%, op_acc: 50.78%] [G loss: 1.178822]\n",
      "epoch:47 step:37442[D loss: 0.372932, acc: 68.75%, op_acc: 44.53%] [G loss: 1.133832]\n",
      "epoch:47 step:37443[D loss: 0.357082, acc: 75.00%, op_acc: 50.00%] [G loss: 1.145609]\n",
      "epoch:47 step:37444[D loss: 0.306730, acc: 79.69%, op_acc: 53.91%] [G loss: 1.151364]\n",
      "epoch:47 step:37445[D loss: 0.373108, acc: 72.66%, op_acc: 50.00%] [G loss: 1.067537]\n",
      "epoch:47 step:37446[D loss: 0.314839, acc: 76.56%, op_acc: 58.59%] [G loss: 1.140019]\n",
      "epoch:47 step:37447[D loss: 0.370468, acc: 71.88%, op_acc: 49.22%] [G loss: 1.050567]\n",
      "epoch:47 step:37448[D loss: 0.350810, acc: 75.78%, op_acc: 50.00%] [G loss: 1.112669]\n",
      "epoch:47 step:37449[D loss: 0.343305, acc: 75.78%, op_acc: 51.56%] [G loss: 1.361220]\n",
      "epoch:47 step:37450[D loss: 0.351302, acc: 73.44%, op_acc: 40.62%] [G loss: 1.213560]\n",
      "##############\n",
      "[0.86440426 0.86330094 0.81356535 0.80438714 0.79589582 0.83730525\n",
      " 0.886394   0.82562231 0.807656   0.84175359]\n",
      "##########\n",
      "epoch:47 step:37451[D loss: 0.296391, acc: 78.91%, op_acc: 53.91%] [G loss: 1.218685]\n",
      "epoch:47 step:37452[D loss: 0.348804, acc: 71.88%, op_acc: 50.78%] [G loss: 0.648486]\n",
      "epoch:47 step:37453[D loss: 0.396958, acc: 64.84%, op_acc: 44.53%] [G loss: 1.361452]\n",
      "epoch:47 step:37454[D loss: 0.383678, acc: 67.19%, op_acc: 41.41%] [G loss: 1.377904]\n",
      "epoch:47 step:37455[D loss: 0.421660, acc: 70.31%, op_acc: 40.62%] [G loss: 1.284845]\n",
      "epoch:47 step:37456[D loss: 0.353421, acc: 71.09%, op_acc: 45.31%] [G loss: 1.415450]\n",
      "epoch:47 step:37457[D loss: 0.371757, acc: 66.41%, op_acc: 51.56%] [G loss: 1.349604]\n",
      "epoch:47 step:37458[D loss: 0.371773, acc: 72.66%, op_acc: 43.75%] [G loss: 1.307951]\n",
      "epoch:47 step:37459[D loss: 0.400352, acc: 64.84%, op_acc: 43.75%] [G loss: 1.161200]\n",
      "epoch:47 step:37460[D loss: 0.316313, acc: 82.03%, op_acc: 53.12%] [G loss: 1.421221]\n",
      "epoch:47 step:37461[D loss: 0.330435, acc: 74.22%, op_acc: 57.81%] [G loss: 1.471243]\n",
      "epoch:47 step:37462[D loss: 0.321216, acc: 77.34%, op_acc: 50.00%] [G loss: 1.200032]\n",
      "epoch:47 step:37463[D loss: 0.331073, acc: 76.56%, op_acc: 50.00%] [G loss: 1.324202]\n",
      "epoch:47 step:37464[D loss: 0.365721, acc: 70.31%, op_acc: 50.00%] [G loss: 1.360598]\n",
      "epoch:47 step:37465[D loss: 0.290079, acc: 82.03%, op_acc: 57.81%] [G loss: 1.329576]\n",
      "epoch:47 step:37466[D loss: 0.293379, acc: 83.59%, op_acc: 54.69%] [G loss: 1.284451]\n",
      "epoch:47 step:37467[D loss: 0.314944, acc: 79.69%, op_acc: 50.78%] [G loss: 1.219697]\n",
      "epoch:47 step:37468[D loss: 0.302709, acc: 79.69%, op_acc: 53.91%] [G loss: 0.690947]\n",
      "epoch:47 step:37469[D loss: 0.422779, acc: 53.12%, op_acc: 45.31%] [G loss: 1.370095]\n",
      "epoch:47 step:37470[D loss: 0.368691, acc: 69.53%, op_acc: 46.88%] [G loss: 1.229630]\n",
      "epoch:47 step:37471[D loss: 0.331846, acc: 75.78%, op_acc: 55.47%] [G loss: 1.420841]\n",
      "epoch:47 step:37472[D loss: 0.353583, acc: 71.09%, op_acc: 51.56%] [G loss: 1.457997]\n",
      "epoch:47 step:37473[D loss: 0.303741, acc: 78.12%, op_acc: 52.34%] [G loss: 0.918420]\n",
      "epoch:47 step:37474[D loss: 0.359259, acc: 67.19%, op_acc: 39.06%] [G loss: 1.545736]\n",
      "epoch:47 step:37475[D loss: 0.358906, acc: 71.88%, op_acc: 45.31%] [G loss: 0.685790]\n",
      "epoch:47 step:37476[D loss: 0.347213, acc: 73.44%, op_acc: 45.31%] [G loss: 1.515042]\n",
      "epoch:47 step:37477[D loss: 0.378867, acc: 66.41%, op_acc: 47.66%] [G loss: 0.744364]\n",
      "epoch:47 step:37478[D loss: 0.472195, acc: 59.38%, op_acc: 38.28%] [G loss: 1.661496]\n",
      "epoch:47 step:37479[D loss: 0.481903, acc: 54.69%, op_acc: 38.28%] [G loss: 0.784317]\n",
      "epoch:47 step:37480[D loss: 0.413167, acc: 60.94%, op_acc: 50.00%] [G loss: 1.460843]\n",
      "epoch:47 step:37481[D loss: 0.401001, acc: 60.94%, op_acc: 46.88%] [G loss: 1.272326]\n",
      "epoch:47 step:37482[D loss: 0.435255, acc: 58.59%, op_acc: 38.28%] [G loss: 1.493924]\n",
      "epoch:47 step:37483[D loss: 0.414484, acc: 62.50%, op_acc: 46.09%] [G loss: 1.410078]\n",
      "epoch:47 step:37484[D loss: 0.413304, acc: 65.62%, op_acc: 46.09%] [G loss: 1.409362]\n",
      "epoch:47 step:37485[D loss: 0.384615, acc: 61.72%, op_acc: 52.34%] [G loss: 1.291310]\n",
      "epoch:47 step:37486[D loss: 0.373323, acc: 73.44%, op_acc: 40.62%] [G loss: 1.178566]\n",
      "epoch:47 step:37487[D loss: 0.353084, acc: 65.62%, op_acc: 53.12%] [G loss: 1.259872]\n",
      "epoch:47 step:37488[D loss: 0.351484, acc: 74.22%, op_acc: 48.44%] [G loss: 1.203324]\n",
      "epoch:48 step:37489[D loss: 0.319144, acc: 79.69%, op_acc: 57.03%] [G loss: 1.446799]\n",
      "epoch:48 step:37490[D loss: 0.336242, acc: 72.66%, op_acc: 52.34%] [G loss: 1.122766]\n",
      "epoch:48 step:37491[D loss: 0.386211, acc: 68.75%, op_acc: 46.88%] [G loss: 0.994337]\n",
      "epoch:48 step:37492[D loss: 0.410838, acc: 62.50%, op_acc: 47.66%] [G loss: 1.025029]\n",
      "epoch:48 step:37493[D loss: 0.408294, acc: 57.81%, op_acc: 45.31%] [G loss: 1.225422]\n",
      "epoch:48 step:37494[D loss: 0.368610, acc: 69.53%, op_acc: 48.44%] [G loss: 1.219929]\n",
      "epoch:48 step:37495[D loss: 0.372957, acc: 64.06%, op_acc: 51.56%] [G loss: 0.883908]\n",
      "epoch:48 step:37496[D loss: 0.396224, acc: 66.41%, op_acc: 43.75%] [G loss: 1.031202]\n",
      "epoch:48 step:37497[D loss: 0.338218, acc: 72.66%, op_acc: 51.56%] [G loss: 1.398136]\n",
      "epoch:48 step:37498[D loss: 0.365732, acc: 70.31%, op_acc: 45.31%] [G loss: 1.220738]\n",
      "epoch:48 step:37499[D loss: 0.357299, acc: 73.44%, op_acc: 44.53%] [G loss: 1.364763]\n",
      "epoch:48 step:37500[D loss: 0.360509, acc: 70.31%, op_acc: 44.53%] [G loss: 1.173566]\n",
      "##############\n",
      "[0.84594215 0.85578018 0.81764117 0.80738012 0.79984843 0.83118132\n",
      " 0.90673442 0.82410904 0.81268731 0.83075233]\n",
      "##########\n",
      "epoch:48 step:37501[D loss: 0.332879, acc: 75.78%, op_acc: 50.00%] [G loss: 1.422705]\n",
      "epoch:48 step:37502[D loss: 0.337323, acc: 75.78%, op_acc: 57.03%] [G loss: 1.198218]\n",
      "epoch:48 step:37503[D loss: 0.343376, acc: 75.00%, op_acc: 43.75%] [G loss: 0.968296]\n",
      "epoch:48 step:37504[D loss: 0.373493, acc: 64.84%, op_acc: 48.44%] [G loss: 1.218826]\n",
      "epoch:48 step:37505[D loss: 0.359329, acc: 70.31%, op_acc: 48.44%] [G loss: 1.291156]\n",
      "epoch:48 step:37506[D loss: 0.339289, acc: 71.88%, op_acc: 50.78%] [G loss: 1.063776]\n",
      "epoch:48 step:37507[D loss: 0.336588, acc: 77.34%, op_acc: 50.00%] [G loss: 0.754379]\n",
      "epoch:48 step:37508[D loss: 0.302684, acc: 80.47%, op_acc: 50.00%] [G loss: 0.633335]\n",
      "epoch:48 step:37509[D loss: 0.439700, acc: 57.03%, op_acc: 46.88%] [G loss: 0.883847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37510[D loss: 0.430205, acc: 58.59%, op_acc: 43.75%] [G loss: 1.129983]\n",
      "epoch:48 step:37511[D loss: 0.416442, acc: 59.38%, op_acc: 46.09%] [G loss: 1.272728]\n",
      "epoch:48 step:37512[D loss: 0.425048, acc: 56.25%, op_acc: 49.22%] [G loss: 1.333995]\n",
      "epoch:48 step:37513[D loss: 0.417703, acc: 58.59%, op_acc: 50.78%] [G loss: 1.190588]\n",
      "epoch:48 step:37514[D loss: 0.341091, acc: 67.97%, op_acc: 53.12%] [G loss: 1.195119]\n",
      "epoch:48 step:37515[D loss: 0.413097, acc: 66.41%, op_acc: 42.97%] [G loss: 1.190928]\n",
      "epoch:48 step:37516[D loss: 0.353382, acc: 64.84%, op_acc: 52.34%] [G loss: 1.241777]\n",
      "epoch:48 step:37517[D loss: 0.323567, acc: 75.78%, op_acc: 48.44%] [G loss: 0.947715]\n",
      "epoch:48 step:37518[D loss: 0.363850, acc: 67.19%, op_acc: 46.09%] [G loss: 1.206095]\n",
      "epoch:48 step:37519[D loss: 0.398430, acc: 63.28%, op_acc: 42.19%] [G loss: 1.060181]\n",
      "epoch:48 step:37520[D loss: 0.378850, acc: 73.44%, op_acc: 46.09%] [G loss: 1.203563]\n",
      "epoch:48 step:37521[D loss: 0.363868, acc: 68.75%, op_acc: 48.44%] [G loss: 1.083568]\n",
      "epoch:48 step:37522[D loss: 0.370959, acc: 69.53%, op_acc: 50.00%] [G loss: 0.917446]\n",
      "epoch:48 step:37523[D loss: 0.422556, acc: 57.81%, op_acc: 42.97%] [G loss: 1.011156]\n",
      "epoch:48 step:37524[D loss: 0.405781, acc: 64.84%, op_acc: 45.31%] [G loss: 1.007503]\n",
      "epoch:48 step:37525[D loss: 0.393123, acc: 63.28%, op_acc: 45.31%] [G loss: 1.194907]\n",
      "epoch:48 step:37526[D loss: 0.390528, acc: 68.75%, op_acc: 50.78%] [G loss: 0.940213]\n",
      "epoch:48 step:37527[D loss: 0.427053, acc: 58.59%, op_acc: 44.53%] [G loss: 0.836837]\n",
      "epoch:48 step:37528[D loss: 0.501413, acc: 50.00%, op_acc: 38.28%] [G loss: 0.951311]\n",
      "epoch:48 step:37529[D loss: 0.364715, acc: 71.09%, op_acc: 48.44%] [G loss: 1.094813]\n",
      "epoch:48 step:37530[D loss: 0.392424, acc: 66.41%, op_acc: 48.44%] [G loss: 1.277896]\n",
      "epoch:48 step:37531[D loss: 0.439059, acc: 58.59%, op_acc: 39.84%] [G loss: 0.898427]\n",
      "epoch:48 step:37532[D loss: 0.425615, acc: 56.25%, op_acc: 42.97%] [G loss: 1.119390]\n",
      "epoch:48 step:37533[D loss: 0.398221, acc: 65.62%, op_acc: 47.66%] [G loss: 1.081801]\n",
      "epoch:48 step:37534[D loss: 0.389022, acc: 65.62%, op_acc: 46.09%] [G loss: 1.206823]\n",
      "epoch:48 step:37535[D loss: 0.425615, acc: 64.84%, op_acc: 47.66%] [G loss: 1.119554]\n",
      "epoch:48 step:37536[D loss: 0.438099, acc: 59.38%, op_acc: 33.59%] [G loss: 0.930782]\n",
      "epoch:48 step:37537[D loss: 0.397082, acc: 67.19%, op_acc: 46.88%] [G loss: 1.109885]\n",
      "epoch:48 step:37538[D loss: 0.425295, acc: 59.38%, op_acc: 37.50%] [G loss: 0.835336]\n",
      "epoch:48 step:37539[D loss: 0.397589, acc: 62.50%, op_acc: 46.88%] [G loss: 1.140690]\n",
      "epoch:48 step:37540[D loss: 0.403139, acc: 64.84%, op_acc: 43.75%] [G loss: 1.002802]\n",
      "epoch:48 step:37541[D loss: 0.447016, acc: 60.94%, op_acc: 41.41%] [G loss: 1.042316]\n",
      "epoch:48 step:37542[D loss: 0.379354, acc: 72.66%, op_acc: 46.09%] [G loss: 1.215066]\n",
      "epoch:48 step:37543[D loss: 0.364538, acc: 71.88%, op_acc: 46.09%] [G loss: 1.184995]\n",
      "epoch:48 step:37544[D loss: 0.384085, acc: 69.53%, op_acc: 47.66%] [G loss: 0.675401]\n",
      "epoch:48 step:37545[D loss: 0.410104, acc: 63.28%, op_acc: 37.50%] [G loss: 1.252149]\n",
      "epoch:48 step:37546[D loss: 0.376603, acc: 64.84%, op_acc: 46.09%] [G loss: 0.689161]\n",
      "epoch:48 step:37547[D loss: 0.382710, acc: 58.59%, op_acc: 45.31%] [G loss: 1.216457]\n",
      "epoch:48 step:37548[D loss: 0.406554, acc: 67.19%, op_acc: 46.09%] [G loss: 0.883908]\n",
      "epoch:48 step:37549[D loss: 0.423409, acc: 62.50%, op_acc: 42.97%] [G loss: 0.721310]\n",
      "epoch:48 step:37550[D loss: 0.417627, acc: 57.81%, op_acc: 45.31%] [G loss: 1.074092]\n",
      "##############\n",
      "[0.86901053 0.8392384  0.8143935  0.80625637 0.78773156 0.80404467\n",
      " 0.87279495 0.80458939 0.84236892 0.81963283]\n",
      "##########\n",
      "epoch:48 step:37551[D loss: 0.391359, acc: 69.53%, op_acc: 44.53%] [G loss: 1.177481]\n",
      "epoch:48 step:37552[D loss: 0.388290, acc: 64.06%, op_acc: 42.97%] [G loss: 1.075776]\n",
      "epoch:48 step:37553[D loss: 0.391649, acc: 67.97%, op_acc: 42.97%] [G loss: 1.135747]\n",
      "epoch:48 step:37554[D loss: 0.422896, acc: 59.38%, op_acc: 46.88%] [G loss: 1.177207]\n",
      "epoch:48 step:37555[D loss: 0.371745, acc: 60.94%, op_acc: 44.53%] [G loss: 1.151512]\n",
      "epoch:48 step:37556[D loss: 0.376889, acc: 67.97%, op_acc: 46.09%] [G loss: 1.007451]\n",
      "epoch:48 step:37557[D loss: 0.351622, acc: 71.88%, op_acc: 46.88%] [G loss: 1.179675]\n",
      "epoch:48 step:37558[D loss: 0.423684, acc: 58.59%, op_acc: 41.41%] [G loss: 0.690477]\n",
      "epoch:48 step:37559[D loss: 0.417891, acc: 67.97%, op_acc: 41.41%] [G loss: 1.382707]\n",
      "epoch:48 step:37560[D loss: 0.365730, acc: 72.66%, op_acc: 49.22%] [G loss: 0.726655]\n",
      "epoch:48 step:37561[D loss: 0.402577, acc: 70.31%, op_acc: 38.28%] [G loss: 1.081903]\n",
      "epoch:48 step:37562[D loss: 0.380835, acc: 64.84%, op_acc: 44.53%] [G loss: 1.288472]\n",
      "epoch:48 step:37563[D loss: 0.334466, acc: 74.22%, op_acc: 50.00%] [G loss: 1.286090]\n",
      "epoch:48 step:37564[D loss: 0.421771, acc: 60.94%, op_acc: 42.19%] [G loss: 0.829498]\n",
      "epoch:48 step:37565[D loss: 0.371497, acc: 70.31%, op_acc: 47.66%] [G loss: 1.047712]\n",
      "epoch:48 step:37566[D loss: 0.377450, acc: 68.75%, op_acc: 43.75%] [G loss: 0.944858]\n",
      "epoch:48 step:37567[D loss: 0.397277, acc: 64.84%, op_acc: 42.19%] [G loss: 1.351273]\n",
      "epoch:48 step:37568[D loss: 0.429360, acc: 64.84%, op_acc: 38.28%] [G loss: 0.789299]\n",
      "epoch:48 step:37569[D loss: 0.431328, acc: 58.59%, op_acc: 39.06%] [G loss: 0.805012]\n",
      "epoch:48 step:37570[D loss: 0.427511, acc: 54.69%, op_acc: 50.00%] [G loss: 0.862414]\n",
      "epoch:48 step:37571[D loss: 0.415812, acc: 60.94%, op_acc: 39.84%] [G loss: 0.861758]\n",
      "epoch:48 step:37572[D loss: 0.420923, acc: 66.41%, op_acc: 39.84%] [G loss: 0.887023]\n",
      "epoch:48 step:37573[D loss: 0.423473, acc: 60.94%, op_acc: 43.75%] [G loss: 1.014009]\n",
      "epoch:48 step:37574[D loss: 0.364164, acc: 68.75%, op_acc: 49.22%] [G loss: 1.176661]\n",
      "epoch:48 step:37575[D loss: 0.351778, acc: 67.19%, op_acc: 48.44%] [G loss: 1.172375]\n",
      "epoch:48 step:37576[D loss: 0.419290, acc: 63.28%, op_acc: 42.97%] [G loss: 1.166985]\n",
      "epoch:48 step:37577[D loss: 0.412430, acc: 67.19%, op_acc: 42.19%] [G loss: 1.325724]\n",
      "epoch:48 step:37578[D loss: 0.404574, acc: 64.06%, op_acc: 42.97%] [G loss: 1.095163]\n",
      "epoch:48 step:37579[D loss: 0.407863, acc: 63.28%, op_acc: 44.53%] [G loss: 1.088915]\n",
      "epoch:48 step:37580[D loss: 0.384663, acc: 65.62%, op_acc: 42.19%] [G loss: 1.112138]\n",
      "epoch:48 step:37581[D loss: 0.347096, acc: 72.66%, op_acc: 43.75%] [G loss: 1.043376]\n",
      "epoch:48 step:37582[D loss: 0.415990, acc: 62.50%, op_acc: 46.88%] [G loss: 1.344184]\n",
      "epoch:48 step:37583[D loss: 0.333280, acc: 69.53%, op_acc: 53.12%] [G loss: 0.869821]\n",
      "epoch:48 step:37584[D loss: 0.411815, acc: 66.41%, op_acc: 42.97%] [G loss: 0.973664]\n",
      "epoch:48 step:37585[D loss: 0.334617, acc: 71.09%, op_acc: 52.34%] [G loss: 1.032025]\n",
      "epoch:48 step:37586[D loss: 0.367002, acc: 67.19%, op_acc: 40.62%] [G loss: 0.955387]\n",
      "epoch:48 step:37587[D loss: 0.376052, acc: 64.84%, op_acc: 45.31%] [G loss: 0.952908]\n",
      "epoch:48 step:37588[D loss: 0.349619, acc: 68.75%, op_acc: 50.78%] [G loss: 0.954075]\n",
      "epoch:48 step:37589[D loss: 0.394509, acc: 67.19%, op_acc: 49.22%] [G loss: 1.250008]\n",
      "epoch:48 step:37590[D loss: 0.398578, acc: 59.38%, op_acc: 50.78%] [G loss: 0.972418]\n",
      "epoch:48 step:37591[D loss: 0.423351, acc: 62.50%, op_acc: 41.41%] [G loss: 0.917685]\n",
      "epoch:48 step:37592[D loss: 0.373874, acc: 70.31%, op_acc: 57.03%] [G loss: 0.897555]\n",
      "epoch:48 step:37593[D loss: 0.388947, acc: 67.97%, op_acc: 46.88%] [G loss: 1.063517]\n",
      "epoch:48 step:37594[D loss: 0.423567, acc: 63.28%, op_acc: 42.97%] [G loss: 0.835492]\n",
      "epoch:48 step:37595[D loss: 0.378533, acc: 62.50%, op_acc: 47.66%] [G loss: 0.975148]\n",
      "epoch:48 step:37596[D loss: 0.424610, acc: 65.62%, op_acc: 39.84%] [G loss: 1.197925]\n",
      "epoch:48 step:37597[D loss: 0.357578, acc: 67.97%, op_acc: 44.53%] [G loss: 1.082228]\n",
      "epoch:48 step:37598[D loss: 0.431782, acc: 60.94%, op_acc: 43.75%] [G loss: 1.077266]\n",
      "epoch:48 step:37599[D loss: 0.384808, acc: 65.62%, op_acc: 43.75%] [G loss: 0.968375]\n",
      "epoch:48 step:37600[D loss: 0.426470, acc: 60.16%, op_acc: 43.75%] [G loss: 1.062805]\n",
      "##############\n",
      "[0.85546649 0.84100673 0.83364345 0.81312745 0.79106014 0.83644964\n",
      " 0.9108707  0.82775358 0.80816053 0.82531008]\n",
      "##########\n",
      "epoch:48 step:37601[D loss: 0.415124, acc: 67.19%, op_acc: 44.53%] [G loss: 1.099458]\n",
      "epoch:48 step:37602[D loss: 0.354589, acc: 70.31%, op_acc: 42.97%] [G loss: 1.140497]\n",
      "epoch:48 step:37603[D loss: 0.370516, acc: 60.94%, op_acc: 46.09%] [G loss: 1.079225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37604[D loss: 0.460217, acc: 55.47%, op_acc: 42.97%] [G loss: 1.225205]\n",
      "epoch:48 step:37605[D loss: 0.437742, acc: 59.38%, op_acc: 42.97%] [G loss: 0.953270]\n",
      "epoch:48 step:37606[D loss: 0.419982, acc: 60.94%, op_acc: 43.75%] [G loss: 0.846947]\n",
      "epoch:48 step:37607[D loss: 0.364840, acc: 70.31%, op_acc: 43.75%] [G loss: 1.067141]\n",
      "epoch:48 step:37608[D loss: 0.424721, acc: 60.16%, op_acc: 40.62%] [G loss: 0.900303]\n",
      "epoch:48 step:37609[D loss: 0.398630, acc: 64.06%, op_acc: 39.84%] [G loss: 1.141528]\n",
      "epoch:48 step:37610[D loss: 0.424911, acc: 58.59%, op_acc: 42.97%] [G loss: 1.462465]\n",
      "epoch:48 step:37611[D loss: 0.373160, acc: 67.19%, op_acc: 46.09%] [G loss: 0.942254]\n",
      "epoch:48 step:37612[D loss: 0.401404, acc: 58.59%, op_acc: 46.09%] [G loss: 0.873888]\n",
      "epoch:48 step:37613[D loss: 0.429379, acc: 60.94%, op_acc: 39.06%] [G loss: 0.840707]\n",
      "epoch:48 step:37614[D loss: 0.397487, acc: 64.84%, op_acc: 43.75%] [G loss: 0.945390]\n",
      "epoch:48 step:37615[D loss: 0.344368, acc: 75.78%, op_acc: 49.22%] [G loss: 0.894299]\n",
      "epoch:48 step:37616[D loss: 0.357215, acc: 69.53%, op_acc: 44.53%] [G loss: 1.093791]\n",
      "epoch:48 step:37617[D loss: 0.422846, acc: 60.16%, op_acc: 46.09%] [G loss: 0.952268]\n",
      "epoch:48 step:37618[D loss: 0.358861, acc: 67.19%, op_acc: 49.22%] [G loss: 0.955617]\n",
      "epoch:48 step:37619[D loss: 0.378277, acc: 68.75%, op_acc: 41.41%] [G loss: 1.155058]\n",
      "epoch:48 step:37620[D loss: 0.308245, acc: 78.91%, op_acc: 57.03%] [G loss: 1.099173]\n",
      "epoch:48 step:37621[D loss: 0.446650, acc: 53.91%, op_acc: 42.19%] [G loss: 1.147207]\n",
      "epoch:48 step:37622[D loss: 0.371718, acc: 71.88%, op_acc: 51.56%] [G loss: 0.974945]\n",
      "epoch:48 step:37623[D loss: 0.407081, acc: 59.38%, op_acc: 47.66%] [G loss: 1.009600]\n",
      "epoch:48 step:37624[D loss: 0.344807, acc: 74.22%, op_acc: 50.00%] [G loss: 1.118931]\n",
      "epoch:48 step:37625[D loss: 0.386025, acc: 62.50%, op_acc: 48.44%] [G loss: 1.333319]\n",
      "epoch:48 step:37626[D loss: 0.374990, acc: 68.75%, op_acc: 40.62%] [G loss: 0.971940]\n",
      "epoch:48 step:37627[D loss: 0.363638, acc: 69.53%, op_acc: 48.44%] [G loss: 1.088335]\n",
      "epoch:48 step:37628[D loss: 0.401473, acc: 66.41%, op_acc: 49.22%] [G loss: 1.183838]\n",
      "epoch:48 step:37629[D loss: 0.346726, acc: 74.22%, op_acc: 47.66%] [G loss: 1.044467]\n",
      "epoch:48 step:37630[D loss: 0.393660, acc: 67.97%, op_acc: 43.75%] [G loss: 1.110049]\n",
      "epoch:48 step:37631[D loss: 0.395371, acc: 62.50%, op_acc: 46.09%] [G loss: 0.973500]\n",
      "epoch:48 step:37632[D loss: 0.411729, acc: 55.47%, op_acc: 42.97%] [G loss: 1.146961]\n",
      "epoch:48 step:37633[D loss: 0.422001, acc: 64.06%, op_acc: 42.97%] [G loss: 0.895121]\n",
      "epoch:48 step:37634[D loss: 0.386284, acc: 65.62%, op_acc: 39.84%] [G loss: 1.074193]\n",
      "epoch:48 step:37635[D loss: 0.395976, acc: 63.28%, op_acc: 42.97%] [G loss: 1.163128]\n",
      "epoch:48 step:37636[D loss: 0.398923, acc: 66.41%, op_acc: 45.31%] [G loss: 0.907104]\n",
      "epoch:48 step:37637[D loss: 0.326141, acc: 70.31%, op_acc: 52.34%] [G loss: 1.178380]\n",
      "epoch:48 step:37638[D loss: 0.344227, acc: 73.44%, op_acc: 46.09%] [G loss: 1.260620]\n",
      "epoch:48 step:37639[D loss: 0.363714, acc: 64.06%, op_acc: 46.88%] [G loss: 1.129705]\n",
      "epoch:48 step:37640[D loss: 0.355538, acc: 70.31%, op_acc: 51.56%] [G loss: 1.086209]\n",
      "epoch:48 step:37641[D loss: 0.373380, acc: 69.53%, op_acc: 47.66%] [G loss: 1.098306]\n",
      "epoch:48 step:37642[D loss: 0.415180, acc: 64.84%, op_acc: 42.97%] [G loss: 0.933313]\n",
      "epoch:48 step:37643[D loss: 0.324591, acc: 82.81%, op_acc: 50.00%] [G loss: 1.156714]\n",
      "epoch:48 step:37644[D loss: 0.387379, acc: 67.19%, op_acc: 48.44%] [G loss: 0.878496]\n",
      "epoch:48 step:37645[D loss: 0.346179, acc: 75.00%, op_acc: 46.09%] [G loss: 0.993818]\n",
      "epoch:48 step:37646[D loss: 0.347994, acc: 69.53%, op_acc: 48.44%] [G loss: 0.987338]\n",
      "epoch:48 step:37647[D loss: 0.345296, acc: 68.75%, op_acc: 57.03%] [G loss: 0.997115]\n",
      "epoch:48 step:37648[D loss: 0.352751, acc: 68.75%, op_acc: 49.22%] [G loss: 1.245174]\n",
      "epoch:48 step:37649[D loss: 0.314349, acc: 79.69%, op_acc: 60.94%] [G loss: 1.071278]\n",
      "epoch:48 step:37650[D loss: 0.307239, acc: 78.91%, op_acc: 47.66%] [G loss: 1.128350]\n",
      "##############\n",
      "[0.85414622 0.88615903 0.80871542 0.80648254 0.79241241 0.83515024\n",
      " 0.88358943 0.84124009 0.81711542 0.85233577]\n",
      "##########\n",
      "epoch:48 step:37651[D loss: 0.331383, acc: 78.12%, op_acc: 51.56%] [G loss: 1.266746]\n",
      "epoch:48 step:37652[D loss: 0.318347, acc: 83.59%, op_acc: 52.34%] [G loss: 0.805705]\n",
      "epoch:48 step:37653[D loss: 0.318221, acc: 76.56%, op_acc: 48.44%] [G loss: 1.205069]\n",
      "epoch:48 step:37654[D loss: 0.384823, acc: 67.97%, op_acc: 43.75%] [G loss: 0.744536]\n",
      "epoch:48 step:37655[D loss: 0.367913, acc: 69.53%, op_acc: 47.66%] [G loss: 1.279975]\n",
      "epoch:48 step:37656[D loss: 0.385744, acc: 62.50%, op_acc: 46.09%] [G loss: 1.286350]\n",
      "epoch:48 step:37657[D loss: 0.377901, acc: 67.19%, op_acc: 41.41%] [G loss: 1.422148]\n",
      "epoch:48 step:37658[D loss: 0.333186, acc: 78.91%, op_acc: 48.44%] [G loss: 1.061888]\n",
      "epoch:48 step:37659[D loss: 0.429719, acc: 59.38%, op_acc: 39.84%] [G loss: 1.084684]\n",
      "epoch:48 step:37660[D loss: 0.334178, acc: 71.88%, op_acc: 46.88%] [G loss: 1.231090]\n",
      "epoch:48 step:37661[D loss: 0.367231, acc: 71.88%, op_acc: 45.31%] [G loss: 1.214463]\n",
      "epoch:48 step:37662[D loss: 0.427105, acc: 67.97%, op_acc: 41.41%] [G loss: 1.076614]\n",
      "epoch:48 step:37663[D loss: 0.368543, acc: 70.31%, op_acc: 50.78%] [G loss: 1.068377]\n",
      "epoch:48 step:37664[D loss: 0.407454, acc: 64.06%, op_acc: 47.66%] [G loss: 1.128857]\n",
      "epoch:48 step:37665[D loss: 0.400738, acc: 63.28%, op_acc: 42.97%] [G loss: 1.264533]\n",
      "epoch:48 step:37666[D loss: 0.384917, acc: 63.28%, op_acc: 48.44%] [G loss: 1.059458]\n",
      "epoch:48 step:37667[D loss: 0.350733, acc: 73.44%, op_acc: 53.91%] [G loss: 0.870457]\n",
      "epoch:48 step:37668[D loss: 0.375587, acc: 71.09%, op_acc: 47.66%] [G loss: 1.280689]\n",
      "epoch:48 step:37669[D loss: 0.359009, acc: 72.66%, op_acc: 49.22%] [G loss: 0.949878]\n",
      "epoch:48 step:37670[D loss: 0.341202, acc: 76.56%, op_acc: 50.78%] [G loss: 1.234428]\n",
      "epoch:48 step:37671[D loss: 0.293270, acc: 88.28%, op_acc: 51.56%] [G loss: 0.895602]\n",
      "epoch:48 step:37672[D loss: 0.391927, acc: 64.84%, op_acc: 42.19%] [G loss: 0.967461]\n",
      "epoch:48 step:37673[D loss: 0.434651, acc: 58.59%, op_acc: 35.16%] [G loss: 1.032019]\n",
      "epoch:48 step:37674[D loss: 0.426853, acc: 56.25%, op_acc: 49.22%] [G loss: 0.947230]\n",
      "epoch:48 step:37675[D loss: 0.404119, acc: 56.25%, op_acc: 49.22%] [G loss: 1.094941]\n",
      "epoch:48 step:37676[D loss: 0.377079, acc: 69.53%, op_acc: 45.31%] [G loss: 1.429522]\n",
      "epoch:48 step:37677[D loss: 0.408895, acc: 66.41%, op_acc: 42.97%] [G loss: 1.139575]\n",
      "epoch:48 step:37678[D loss: 0.450347, acc: 57.03%, op_acc: 38.28%] [G loss: 1.094931]\n",
      "epoch:48 step:37679[D loss: 0.334383, acc: 73.44%, op_acc: 48.44%] [G loss: 1.081549]\n",
      "epoch:48 step:37680[D loss: 0.354206, acc: 75.78%, op_acc: 46.88%] [G loss: 1.176924]\n",
      "epoch:48 step:37681[D loss: 0.341443, acc: 73.44%, op_acc: 47.66%] [G loss: 1.288784]\n",
      "epoch:48 step:37682[D loss: 0.360257, acc: 72.66%, op_acc: 47.66%] [G loss: 1.027005]\n",
      "epoch:48 step:37683[D loss: 0.382938, acc: 68.75%, op_acc: 51.56%] [G loss: 1.117797]\n",
      "epoch:48 step:37684[D loss: 0.304233, acc: 79.69%, op_acc: 48.44%] [G loss: 1.093203]\n",
      "epoch:48 step:37685[D loss: 0.391312, acc: 62.50%, op_acc: 50.78%] [G loss: 1.178558]\n",
      "epoch:48 step:37686[D loss: 0.364505, acc: 72.66%, op_acc: 45.31%] [G loss: 1.208374]\n",
      "epoch:48 step:37687[D loss: 0.355482, acc: 67.19%, op_acc: 44.53%] [G loss: 1.068863]\n",
      "epoch:48 step:37688[D loss: 0.346456, acc: 71.09%, op_acc: 46.88%] [G loss: 1.384436]\n",
      "epoch:48 step:37689[D loss: 0.319218, acc: 78.12%, op_acc: 51.56%] [G loss: 0.855740]\n",
      "epoch:48 step:37690[D loss: 0.431301, acc: 62.50%, op_acc: 38.28%] [G loss: 1.394281]\n",
      "epoch:48 step:37691[D loss: 0.409687, acc: 62.50%, op_acc: 45.31%] [G loss: 0.795667]\n",
      "epoch:48 step:37692[D loss: 0.420628, acc: 62.50%, op_acc: 44.53%] [G loss: 0.854591]\n",
      "epoch:48 step:37693[D loss: 0.396519, acc: 63.28%, op_acc: 45.31%] [G loss: 1.072505]\n",
      "epoch:48 step:37694[D loss: 0.419946, acc: 57.03%, op_acc: 47.66%] [G loss: 0.867124]\n",
      "epoch:48 step:37695[D loss: 0.377441, acc: 65.62%, op_acc: 47.66%] [G loss: 1.134291]\n",
      "epoch:48 step:37696[D loss: 0.425630, acc: 65.62%, op_acc: 43.75%] [G loss: 1.283363]\n",
      "epoch:48 step:37697[D loss: 0.411287, acc: 60.94%, op_acc: 46.88%] [G loss: 0.949100]\n",
      "epoch:48 step:37698[D loss: 0.358666, acc: 72.66%, op_acc: 50.00%] [G loss: 1.395220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37699[D loss: 0.414451, acc: 59.38%, op_acc: 46.88%] [G loss: 0.872082]\n",
      "epoch:48 step:37700[D loss: 0.409552, acc: 67.97%, op_acc: 43.75%] [G loss: 1.248103]\n",
      "##############\n",
      "[0.85259162 0.84809009 0.82033327 0.8161703  0.79752467 0.81436585\n",
      " 0.89848218 0.82216832 0.82688509 0.83807425]\n",
      "##########\n",
      "epoch:48 step:37701[D loss: 0.394043, acc: 65.62%, op_acc: 44.53%] [G loss: 1.011908]\n",
      "epoch:48 step:37702[D loss: 0.412942, acc: 68.75%, op_acc: 39.84%] [G loss: 0.939232]\n",
      "epoch:48 step:37703[D loss: 0.439285, acc: 60.16%, op_acc: 38.28%] [G loss: 0.984171]\n",
      "epoch:48 step:37704[D loss: 0.393179, acc: 65.62%, op_acc: 40.62%] [G loss: 0.963017]\n",
      "epoch:48 step:37705[D loss: 0.355255, acc: 78.12%, op_acc: 44.53%] [G loss: 0.914028]\n",
      "epoch:48 step:37706[D loss: 0.353531, acc: 74.22%, op_acc: 42.97%] [G loss: 0.999992]\n",
      "epoch:48 step:37707[D loss: 0.355374, acc: 69.53%, op_acc: 43.75%] [G loss: 1.227097]\n",
      "epoch:48 step:37708[D loss: 0.401328, acc: 64.06%, op_acc: 39.84%] [G loss: 0.959171]\n",
      "epoch:48 step:37709[D loss: 0.372018, acc: 67.97%, op_acc: 44.53%] [G loss: 0.800864]\n",
      "epoch:48 step:37710[D loss: 0.430550, acc: 53.91%, op_acc: 46.09%] [G loss: 1.115921]\n",
      "epoch:48 step:37711[D loss: 0.400947, acc: 62.50%, op_acc: 45.31%] [G loss: 0.884952]\n",
      "epoch:48 step:37712[D loss: 0.383332, acc: 65.62%, op_acc: 42.19%] [G loss: 1.089919]\n",
      "epoch:48 step:37713[D loss: 0.362692, acc: 72.66%, op_acc: 48.44%] [G loss: 1.375576]\n",
      "epoch:48 step:37714[D loss: 0.381534, acc: 63.28%, op_acc: 48.44%] [G loss: 0.947040]\n",
      "epoch:48 step:37715[D loss: 0.386215, acc: 69.53%, op_acc: 42.97%] [G loss: 1.332527]\n",
      "epoch:48 step:37716[D loss: 0.406364, acc: 60.94%, op_acc: 44.53%] [G loss: 1.227953]\n",
      "epoch:48 step:37717[D loss: 0.411097, acc: 63.28%, op_acc: 42.97%] [G loss: 0.730418]\n",
      "epoch:48 step:37718[D loss: 0.376750, acc: 69.53%, op_acc: 38.28%] [G loss: 0.822141]\n",
      "epoch:48 step:37719[D loss: 0.369128, acc: 68.75%, op_acc: 51.56%] [G loss: 1.297941]\n",
      "epoch:48 step:37720[D loss: 0.401636, acc: 69.53%, op_acc: 42.97%] [G loss: 0.949767]\n",
      "epoch:48 step:37721[D loss: 0.326448, acc: 75.00%, op_acc: 56.25%] [G loss: 0.987752]\n",
      "epoch:48 step:37722[D loss: 0.371349, acc: 71.88%, op_acc: 47.66%] [G loss: 0.849264]\n",
      "epoch:48 step:37723[D loss: 0.386705, acc: 65.62%, op_acc: 46.09%] [G loss: 0.775741]\n",
      "epoch:48 step:37724[D loss: 0.373299, acc: 71.09%, op_acc: 46.09%] [G loss: 0.806304]\n",
      "epoch:48 step:37725[D loss: 0.351431, acc: 68.75%, op_acc: 45.31%] [G loss: 0.685739]\n",
      "epoch:48 step:37726[D loss: 0.439765, acc: 54.69%, op_acc: 43.75%] [G loss: 0.695499]\n",
      "epoch:48 step:37727[D loss: 0.398622, acc: 62.50%, op_acc: 53.91%] [G loss: 1.004347]\n",
      "epoch:48 step:37728[D loss: 0.390088, acc: 66.41%, op_acc: 46.09%] [G loss: 1.154022]\n",
      "epoch:48 step:37729[D loss: 0.390986, acc: 60.94%, op_acc: 46.09%] [G loss: 0.941275]\n",
      "epoch:48 step:37730[D loss: 0.339730, acc: 71.88%, op_acc: 48.44%] [G loss: 1.257550]\n",
      "epoch:48 step:37731[D loss: 0.387260, acc: 65.62%, op_acc: 42.97%] [G loss: 0.894902]\n",
      "epoch:48 step:37732[D loss: 0.377976, acc: 71.88%, op_acc: 46.09%] [G loss: 1.014212]\n",
      "epoch:48 step:37733[D loss: 0.443031, acc: 50.78%, op_acc: 46.88%] [G loss: 1.043115]\n",
      "epoch:48 step:37734[D loss: 0.378514, acc: 73.44%, op_acc: 43.75%] [G loss: 1.035305]\n",
      "epoch:48 step:37735[D loss: 0.413084, acc: 66.41%, op_acc: 40.62%] [G loss: 0.941794]\n",
      "epoch:48 step:37736[D loss: 0.461586, acc: 50.00%, op_acc: 38.28%] [G loss: 0.950849]\n",
      "epoch:48 step:37737[D loss: 0.380914, acc: 64.06%, op_acc: 47.66%] [G loss: 1.088323]\n",
      "epoch:48 step:37738[D loss: 0.428247, acc: 60.94%, op_acc: 42.97%] [G loss: 1.085917]\n",
      "epoch:48 step:37739[D loss: 0.405409, acc: 64.06%, op_acc: 42.19%] [G loss: 0.927966]\n",
      "epoch:48 step:37740[D loss: 0.376466, acc: 67.97%, op_acc: 46.88%] [G loss: 0.946788]\n",
      "epoch:48 step:37741[D loss: 0.376995, acc: 69.53%, op_acc: 45.31%] [G loss: 1.121551]\n",
      "epoch:48 step:37742[D loss: 0.407657, acc: 67.97%, op_acc: 38.28%] [G loss: 0.874950]\n",
      "epoch:48 step:37743[D loss: 0.426723, acc: 63.28%, op_acc: 40.62%] [G loss: 0.778661]\n",
      "epoch:48 step:37744[D loss: 0.379218, acc: 69.53%, op_acc: 47.66%] [G loss: 1.235110]\n",
      "epoch:48 step:37745[D loss: 0.364885, acc: 74.22%, op_acc: 46.09%] [G loss: 1.189870]\n",
      "epoch:48 step:37746[D loss: 0.373589, acc: 65.62%, op_acc: 48.44%] [G loss: 0.738713]\n",
      "epoch:48 step:37747[D loss: 0.346947, acc: 72.66%, op_acc: 46.09%] [G loss: 1.034280]\n",
      "epoch:48 step:37748[D loss: 0.448304, acc: 60.94%, op_acc: 35.94%] [G loss: 0.785492]\n",
      "epoch:48 step:37749[D loss: 0.392745, acc: 62.50%, op_acc: 43.75%] [G loss: 0.976135]\n",
      "epoch:48 step:37750[D loss: 0.343584, acc: 70.31%, op_acc: 54.69%] [G loss: 1.258405]\n",
      "##############\n",
      "[0.86597396 0.86991862 0.81280284 0.787328   0.79285406 0.8290466\n",
      " 0.88321448 0.8272964  0.81833129 0.81417969]\n",
      "##########\n",
      "epoch:48 step:37751[D loss: 0.339002, acc: 75.00%, op_acc: 54.69%] [G loss: 1.097166]\n",
      "epoch:48 step:37752[D loss: 0.376999, acc: 67.97%, op_acc: 56.25%] [G loss: 1.202446]\n",
      "epoch:48 step:37753[D loss: 0.362007, acc: 69.53%, op_acc: 49.22%] [G loss: 0.873407]\n",
      "epoch:48 step:37754[D loss: 0.318768, acc: 82.03%, op_acc: 45.31%] [G loss: 1.196219]\n",
      "epoch:48 step:37755[D loss: 0.401143, acc: 67.19%, op_acc: 42.97%] [G loss: 1.044919]\n",
      "epoch:48 step:37756[D loss: 0.337195, acc: 75.00%, op_acc: 46.09%] [G loss: 0.769793]\n",
      "epoch:48 step:37757[D loss: 0.365425, acc: 70.31%, op_acc: 50.78%] [G loss: 0.815793]\n",
      "epoch:48 step:37758[D loss: 0.411675, acc: 57.03%, op_acc: 46.88%] [G loss: 0.800588]\n",
      "epoch:48 step:37759[D loss: 0.406463, acc: 64.06%, op_acc: 40.62%] [G loss: 0.773819]\n",
      "epoch:48 step:37760[D loss: 0.419164, acc: 60.94%, op_acc: 41.41%] [G loss: 1.160405]\n",
      "epoch:48 step:37761[D loss: 0.382191, acc: 66.41%, op_acc: 50.00%] [G loss: 0.863953]\n",
      "epoch:48 step:37762[D loss: 0.392066, acc: 62.50%, op_acc: 49.22%] [G loss: 1.087088]\n",
      "epoch:48 step:37763[D loss: 0.374790, acc: 68.75%, op_acc: 46.09%] [G loss: 0.992129]\n",
      "epoch:48 step:37764[D loss: 0.384898, acc: 64.06%, op_acc: 43.75%] [G loss: 0.701696]\n",
      "epoch:48 step:37765[D loss: 0.417423, acc: 64.06%, op_acc: 43.75%] [G loss: 1.066795]\n",
      "epoch:48 step:37766[D loss: 0.434478, acc: 53.91%, op_acc: 45.31%] [G loss: 1.136507]\n",
      "epoch:48 step:37767[D loss: 0.359174, acc: 76.56%, op_acc: 44.53%] [G loss: 0.628695]\n",
      "epoch:48 step:37768[D loss: 0.402891, acc: 60.94%, op_acc: 47.66%] [G loss: 0.662575]\n",
      "epoch:48 step:37769[D loss: 0.432690, acc: 57.03%, op_acc: 42.19%] [G loss: 0.977601]\n",
      "epoch:48 step:37770[D loss: 0.437900, acc: 60.16%, op_acc: 37.50%] [G loss: 1.088315]\n",
      "epoch:48 step:37771[D loss: 0.341389, acc: 74.22%, op_acc: 47.66%] [G loss: 0.785191]\n",
      "epoch:48 step:37772[D loss: 0.416771, acc: 64.06%, op_acc: 49.22%] [G loss: 0.892301]\n",
      "epoch:48 step:37773[D loss: 0.389873, acc: 67.97%, op_acc: 42.19%] [G loss: 1.099353]\n",
      "epoch:48 step:37774[D loss: 0.381507, acc: 71.88%, op_acc: 44.53%] [G loss: 0.676654]\n",
      "epoch:48 step:37775[D loss: 0.457836, acc: 55.47%, op_acc: 44.53%] [G loss: 0.720986]\n",
      "epoch:48 step:37776[D loss: 0.359913, acc: 67.97%, op_acc: 40.62%] [G loss: 0.704173]\n",
      "epoch:48 step:37777[D loss: 0.399666, acc: 60.94%, op_acc: 42.97%] [G loss: 1.160960]\n",
      "epoch:48 step:37778[D loss: 0.410902, acc: 68.75%, op_acc: 49.22%] [G loss: 1.087811]\n",
      "epoch:48 step:37779[D loss: 0.410022, acc: 63.28%, op_acc: 47.66%] [G loss: 0.725290]\n",
      "epoch:48 step:37780[D loss: 0.430885, acc: 60.16%, op_acc: 39.84%] [G loss: 0.613233]\n",
      "epoch:48 step:37781[D loss: 0.389208, acc: 66.41%, op_acc: 40.62%] [G loss: 1.109278]\n",
      "epoch:48 step:37782[D loss: 0.364988, acc: 75.00%, op_acc: 42.97%] [G loss: 0.726159]\n",
      "epoch:48 step:37783[D loss: 0.368664, acc: 71.09%, op_acc: 50.78%] [G loss: 0.964722]\n",
      "epoch:48 step:37784[D loss: 0.362219, acc: 68.75%, op_acc: 53.91%] [G loss: 1.170068]\n",
      "epoch:48 step:37785[D loss: 0.388396, acc: 65.62%, op_acc: 37.50%] [G loss: 0.699059]\n",
      "epoch:48 step:37786[D loss: 0.372311, acc: 65.62%, op_acc: 46.09%] [G loss: 0.636001]\n",
      "epoch:48 step:37787[D loss: 0.373594, acc: 74.22%, op_acc: 46.09%] [G loss: 0.696566]\n",
      "epoch:48 step:37788[D loss: 0.382738, acc: 66.41%, op_acc: 39.84%] [G loss: 0.904038]\n",
      "epoch:48 step:37789[D loss: 0.356888, acc: 69.53%, op_acc: 49.22%] [G loss: 0.879875]\n",
      "epoch:48 step:37790[D loss: 0.342290, acc: 75.00%, op_acc: 48.44%] [G loss: 0.910477]\n",
      "epoch:48 step:37791[D loss: 0.336778, acc: 73.44%, op_acc: 50.78%] [G loss: 1.105071]\n",
      "epoch:48 step:37792[D loss: 0.357931, acc: 66.41%, op_acc: 50.00%] [G loss: 1.019180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37793[D loss: 0.402676, acc: 62.50%, op_acc: 45.31%] [G loss: 0.900857]\n",
      "epoch:48 step:37794[D loss: 0.363814, acc: 78.12%, op_acc: 46.88%] [G loss: 1.142953]\n",
      "epoch:48 step:37795[D loss: 0.358173, acc: 67.19%, op_acc: 46.88%] [G loss: 0.940322]\n",
      "epoch:48 step:37796[D loss: 0.429857, acc: 59.38%, op_acc: 38.28%] [G loss: 0.833682]\n",
      "epoch:48 step:37797[D loss: 0.364952, acc: 73.44%, op_acc: 39.84%] [G loss: 0.895225]\n",
      "epoch:48 step:37798[D loss: 0.435834, acc: 60.94%, op_acc: 35.94%] [G loss: 1.056237]\n",
      "epoch:48 step:37799[D loss: 0.380578, acc: 71.88%, op_acc: 41.41%] [G loss: 1.148236]\n",
      "epoch:48 step:37800[D loss: 0.407252, acc: 63.28%, op_acc: 43.75%] [G loss: 0.925255]\n",
      "##############\n",
      "[0.86714306 0.84853667 0.82585022 0.82431388 0.79116865 0.82052507\n",
      " 0.87666988 0.83406422 0.79572098 0.82135998]\n",
      "##########\n",
      "epoch:48 step:37801[D loss: 0.435840, acc: 53.91%, op_acc: 42.19%] [G loss: 1.085228]\n",
      "epoch:48 step:37802[D loss: 0.417046, acc: 64.06%, op_acc: 40.62%] [G loss: 0.936168]\n",
      "epoch:48 step:37803[D loss: 0.414709, acc: 63.28%, op_acc: 49.22%] [G loss: 0.904441]\n",
      "epoch:48 step:37804[D loss: 0.396153, acc: 64.84%, op_acc: 46.88%] [G loss: 1.059241]\n",
      "epoch:48 step:37805[D loss: 0.403384, acc: 68.75%, op_acc: 45.31%] [G loss: 1.049530]\n",
      "epoch:48 step:37806[D loss: 0.417391, acc: 66.41%, op_acc: 36.72%] [G loss: 1.054188]\n",
      "epoch:48 step:37807[D loss: 0.415913, acc: 62.50%, op_acc: 44.53%] [G loss: 1.094843]\n",
      "epoch:48 step:37808[D loss: 0.421519, acc: 60.94%, op_acc: 44.53%] [G loss: 0.999080]\n",
      "epoch:48 step:37809[D loss: 0.426295, acc: 53.91%, op_acc: 45.31%] [G loss: 0.981663]\n",
      "epoch:48 step:37810[D loss: 0.388471, acc: 68.75%, op_acc: 42.19%] [G loss: 0.895124]\n",
      "epoch:48 step:37811[D loss: 0.370703, acc: 67.19%, op_acc: 51.56%] [G loss: 1.000673]\n",
      "epoch:48 step:37812[D loss: 0.412279, acc: 62.50%, op_acc: 36.72%] [G loss: 1.132907]\n",
      "epoch:48 step:37813[D loss: 0.319523, acc: 81.25%, op_acc: 51.56%] [G loss: 0.816073]\n",
      "epoch:48 step:37814[D loss: 0.358247, acc: 72.66%, op_acc: 49.22%] [G loss: 0.928784]\n",
      "epoch:48 step:37815[D loss: 0.403062, acc: 64.84%, op_acc: 42.97%] [G loss: 0.892539]\n",
      "epoch:48 step:37816[D loss: 0.379629, acc: 68.75%, op_acc: 44.53%] [G loss: 1.298479]\n",
      "epoch:48 step:37817[D loss: 0.361296, acc: 78.12%, op_acc: 42.97%] [G loss: 1.018175]\n",
      "epoch:48 step:37818[D loss: 0.381129, acc: 66.41%, op_acc: 48.44%] [G loss: 0.985991]\n",
      "epoch:48 step:37819[D loss: 0.381182, acc: 70.31%, op_acc: 42.97%] [G loss: 0.731070]\n",
      "epoch:48 step:37820[D loss: 0.368027, acc: 66.41%, op_acc: 45.31%] [G loss: 1.005965]\n",
      "epoch:48 step:37821[D loss: 0.367532, acc: 71.09%, op_acc: 42.19%] [G loss: 1.068655]\n",
      "epoch:48 step:37822[D loss: 0.379569, acc: 68.75%, op_acc: 50.00%] [G loss: 0.856715]\n",
      "epoch:48 step:37823[D loss: 0.389510, acc: 69.53%, op_acc: 36.72%] [G loss: 0.910383]\n",
      "epoch:48 step:37824[D loss: 0.398016, acc: 63.28%, op_acc: 40.62%] [G loss: 1.103636]\n",
      "epoch:48 step:37825[D loss: 0.404994, acc: 62.50%, op_acc: 42.19%] [G loss: 0.936067]\n",
      "epoch:48 step:37826[D loss: 0.362815, acc: 71.09%, op_acc: 47.66%] [G loss: 1.115456]\n",
      "epoch:48 step:37827[D loss: 0.412663, acc: 59.38%, op_acc: 47.66%] [G loss: 0.887267]\n",
      "epoch:48 step:37828[D loss: 0.390998, acc: 68.75%, op_acc: 45.31%] [G loss: 0.766716]\n",
      "epoch:48 step:37829[D loss: 0.387739, acc: 64.06%, op_acc: 46.88%] [G loss: 0.802954]\n",
      "epoch:48 step:37830[D loss: 0.387859, acc: 67.19%, op_acc: 45.31%] [G loss: 0.845134]\n",
      "epoch:48 step:37831[D loss: 0.391411, acc: 71.88%, op_acc: 48.44%] [G loss: 0.989654]\n",
      "epoch:48 step:37832[D loss: 0.386197, acc: 64.06%, op_acc: 42.97%] [G loss: 0.913996]\n",
      "epoch:48 step:37833[D loss: 0.381168, acc: 65.62%, op_acc: 39.84%] [G loss: 0.802892]\n",
      "epoch:48 step:37834[D loss: 0.374858, acc: 66.41%, op_acc: 45.31%] [G loss: 0.853347]\n",
      "epoch:48 step:37835[D loss: 0.357344, acc: 67.19%, op_acc: 51.56%] [G loss: 0.836090]\n",
      "epoch:48 step:37836[D loss: 0.296035, acc: 80.47%, op_acc: 56.25%] [G loss: 0.774424]\n",
      "epoch:48 step:37837[D loss: 0.316691, acc: 78.12%, op_acc: 53.91%] [G loss: 0.902317]\n",
      "epoch:48 step:37838[D loss: 0.374350, acc: 69.53%, op_acc: 44.53%] [G loss: 0.907807]\n",
      "epoch:48 step:37839[D loss: 0.360698, acc: 67.97%, op_acc: 49.22%] [G loss: 1.140385]\n",
      "epoch:48 step:37840[D loss: 0.388242, acc: 64.84%, op_acc: 42.97%] [G loss: 0.992837]\n",
      "epoch:48 step:37841[D loss: 0.316806, acc: 75.00%, op_acc: 47.66%] [G loss: 1.130727]\n",
      "epoch:48 step:37842[D loss: 0.337407, acc: 73.44%, op_acc: 47.66%] [G loss: 0.893843]\n",
      "epoch:48 step:37843[D loss: 0.397910, acc: 66.41%, op_acc: 42.97%] [G loss: 1.026249]\n",
      "epoch:48 step:37844[D loss: 0.343293, acc: 72.66%, op_acc: 48.44%] [G loss: 1.034106]\n",
      "epoch:48 step:37845[D loss: 0.347399, acc: 75.00%, op_acc: 46.09%] [G loss: 0.953012]\n",
      "epoch:48 step:37846[D loss: 0.351735, acc: 71.88%, op_acc: 53.91%] [G loss: 0.817321]\n",
      "epoch:48 step:37847[D loss: 0.412569, acc: 57.03%, op_acc: 42.97%] [G loss: 1.095940]\n",
      "epoch:48 step:37848[D loss: 0.390335, acc: 64.06%, op_acc: 47.66%] [G loss: 1.083444]\n",
      "epoch:48 step:37849[D loss: 0.366902, acc: 64.84%, op_acc: 48.44%] [G loss: 1.044045]\n",
      "epoch:48 step:37850[D loss: 0.369643, acc: 70.31%, op_acc: 44.53%] [G loss: 1.425810]\n",
      "##############\n",
      "[0.88638657 0.86241064 0.82534642 0.79270439 0.78923388 0.83437588\n",
      " 0.87884838 0.81269486 0.78021257 0.82038207]\n",
      "##########\n",
      "epoch:48 step:37851[D loss: 0.378353, acc: 74.22%, op_acc: 43.75%] [G loss: 0.922064]\n",
      "epoch:48 step:37852[D loss: 0.382164, acc: 62.50%, op_acc: 44.53%] [G loss: 0.866460]\n",
      "epoch:48 step:37853[D loss: 0.336326, acc: 70.31%, op_acc: 57.81%] [G loss: 0.713354]\n",
      "epoch:48 step:37854[D loss: 0.364171, acc: 71.09%, op_acc: 45.31%] [G loss: 1.035767]\n",
      "epoch:48 step:37855[D loss: 0.391446, acc: 73.44%, op_acc: 46.88%] [G loss: 0.880799]\n",
      "epoch:48 step:37856[D loss: 0.368898, acc: 72.66%, op_acc: 49.22%] [G loss: 0.660384]\n",
      "epoch:48 step:37857[D loss: 0.370816, acc: 67.19%, op_acc: 51.56%] [G loss: 0.930798]\n",
      "epoch:48 step:37858[D loss: 0.407437, acc: 66.41%, op_acc: 35.16%] [G loss: 1.180725]\n",
      "epoch:48 step:37859[D loss: 0.371097, acc: 68.75%, op_acc: 42.19%] [G loss: 0.807982]\n",
      "epoch:48 step:37860[D loss: 0.321986, acc: 74.22%, op_acc: 50.78%] [G loss: 0.931624]\n",
      "epoch:48 step:37861[D loss: 0.385403, acc: 66.41%, op_acc: 50.00%] [G loss: 0.741697]\n",
      "epoch:48 step:37862[D loss: 0.446880, acc: 57.03%, op_acc: 46.09%] [G loss: 0.696752]\n",
      "epoch:48 step:37863[D loss: 0.370939, acc: 72.66%, op_acc: 40.62%] [G loss: 0.818992]\n",
      "epoch:48 step:37864[D loss: 0.346811, acc: 77.34%, op_acc: 42.19%] [G loss: 0.991360]\n",
      "epoch:48 step:37865[D loss: 0.397193, acc: 62.50%, op_acc: 43.75%] [G loss: 0.980089]\n",
      "epoch:48 step:37866[D loss: 0.379046, acc: 67.97%, op_acc: 42.97%] [G loss: 0.732957]\n",
      "epoch:48 step:37867[D loss: 0.405075, acc: 59.38%, op_acc: 41.41%] [G loss: 0.958591]\n",
      "epoch:48 step:37868[D loss: 0.313901, acc: 82.03%, op_acc: 48.44%] [G loss: 1.053083]\n",
      "epoch:48 step:37869[D loss: 0.362584, acc: 71.88%, op_acc: 46.88%] [G loss: 0.997050]\n",
      "epoch:48 step:37870[D loss: 0.335958, acc: 71.88%, op_acc: 51.56%] [G loss: 1.010986]\n",
      "epoch:48 step:37871[D loss: 0.425996, acc: 58.59%, op_acc: 40.62%] [G loss: 0.787638]\n",
      "epoch:48 step:37872[D loss: 0.363626, acc: 71.09%, op_acc: 46.88%] [G loss: 0.784768]\n",
      "epoch:48 step:37873[D loss: 0.335316, acc: 75.00%, op_acc: 52.34%] [G loss: 0.954635]\n",
      "epoch:48 step:37874[D loss: 0.317647, acc: 77.34%, op_acc: 57.81%] [G loss: 0.963647]\n",
      "epoch:48 step:37875[D loss: 0.382183, acc: 67.97%, op_acc: 44.53%] [G loss: 0.695787]\n",
      "epoch:48 step:37876[D loss: 0.400030, acc: 62.50%, op_acc: 46.88%] [G loss: 0.696398]\n",
      "epoch:48 step:37877[D loss: 0.360241, acc: 70.31%, op_acc: 43.75%] [G loss: 0.874771]\n",
      "epoch:48 step:37878[D loss: 0.360026, acc: 68.75%, op_acc: 52.34%] [G loss: 1.025335]\n",
      "epoch:48 step:37879[D loss: 0.362832, acc: 71.09%, op_acc: 45.31%] [G loss: 1.277546]\n",
      "epoch:48 step:37880[D loss: 0.364280, acc: 68.75%, op_acc: 50.78%] [G loss: 1.090429]\n",
      "epoch:48 step:37881[D loss: 0.351089, acc: 75.78%, op_acc: 46.09%] [G loss: 1.073633]\n",
      "epoch:48 step:37882[D loss: 0.303410, acc: 80.47%, op_acc: 50.00%] [G loss: 0.905082]\n",
      "epoch:48 step:37883[D loss: 0.433224, acc: 60.94%, op_acc: 36.72%] [G loss: 1.302562]\n",
      "epoch:48 step:37884[D loss: 0.365901, acc: 70.31%, op_acc: 42.19%] [G loss: 1.316324]\n",
      "epoch:48 step:37885[D loss: 0.366518, acc: 76.56%, op_acc: 48.44%] [G loss: 1.197552]\n",
      "epoch:48 step:37886[D loss: 0.377430, acc: 71.88%, op_acc: 46.88%] [G loss: 1.155681]\n",
      "epoch:48 step:37887[D loss: 0.334789, acc: 75.78%, op_acc: 50.00%] [G loss: 1.042237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37888[D loss: 0.342125, acc: 69.53%, op_acc: 49.22%] [G loss: 1.184952]\n",
      "epoch:48 step:37889[D loss: 0.344308, acc: 72.66%, op_acc: 49.22%] [G loss: 1.125754]\n",
      "epoch:48 step:37890[D loss: 0.357990, acc: 72.66%, op_acc: 47.66%] [G loss: 1.363182]\n",
      "epoch:48 step:37891[D loss: 0.322958, acc: 75.78%, op_acc: 54.69%] [G loss: 1.139503]\n",
      "epoch:48 step:37892[D loss: 0.303564, acc: 82.81%, op_acc: 56.25%] [G loss: 1.215340]\n",
      "epoch:48 step:37893[D loss: 0.318678, acc: 82.81%, op_acc: 50.00%] [G loss: 1.187885]\n",
      "epoch:48 step:37894[D loss: 0.341525, acc: 75.00%, op_acc: 56.25%] [G loss: 1.340374]\n",
      "epoch:48 step:37895[D loss: 0.278802, acc: 87.50%, op_acc: 56.25%] [G loss: 1.560342]\n",
      "epoch:48 step:37896[D loss: 0.330571, acc: 75.00%, op_acc: 50.78%] [G loss: 1.337971]\n",
      "epoch:48 step:37897[D loss: 0.274780, acc: 85.16%, op_acc: 57.81%] [G loss: 1.399169]\n",
      "epoch:48 step:37898[D loss: 0.300581, acc: 80.47%, op_acc: 53.91%] [G loss: 1.458234]\n",
      "epoch:48 step:37899[D loss: 0.327624, acc: 78.12%, op_acc: 50.78%] [G loss: 0.681973]\n",
      "epoch:48 step:37900[D loss: 0.411928, acc: 58.59%, op_acc: 41.41%] [G loss: 0.733744]\n",
      "##############\n",
      "[0.86403033 0.85021875 0.80602058 0.80473564 0.7955327  0.83519549\n",
      " 0.86088065 0.84067308 0.80104484 0.83380716]\n",
      "##########\n",
      "epoch:48 step:37901[D loss: 0.474177, acc: 56.25%, op_acc: 38.28%] [G loss: 1.277644]\n",
      "epoch:48 step:37902[D loss: 0.381163, acc: 68.75%, op_acc: 45.31%] [G loss: 1.526820]\n",
      "epoch:48 step:37903[D loss: 0.371144, acc: 68.75%, op_acc: 43.75%] [G loss: 1.076003]\n",
      "epoch:48 step:37904[D loss: 0.389038, acc: 68.75%, op_acc: 47.66%] [G loss: 1.599954]\n",
      "epoch:48 step:37905[D loss: 0.450411, acc: 60.94%, op_acc: 45.31%] [G loss: 1.546308]\n",
      "epoch:48 step:37906[D loss: 0.400139, acc: 64.84%, op_acc: 45.31%] [G loss: 1.537250]\n",
      "epoch:48 step:37907[D loss: 0.329512, acc: 77.34%, op_acc: 49.22%] [G loss: 1.640998]\n",
      "epoch:48 step:37908[D loss: 0.427346, acc: 65.62%, op_acc: 42.19%] [G loss: 0.825362]\n",
      "epoch:48 step:37909[D loss: 0.443971, acc: 62.50%, op_acc: 43.75%] [G loss: 1.313447]\n",
      "epoch:48 step:37910[D loss: 0.372385, acc: 62.50%, op_acc: 46.09%] [G loss: 1.165866]\n",
      "epoch:48 step:37911[D loss: 0.454346, acc: 53.12%, op_acc: 38.28%] [G loss: 0.931954]\n",
      "epoch:48 step:37912[D loss: 0.364640, acc: 75.00%, op_acc: 50.78%] [G loss: 1.121431]\n",
      "epoch:48 step:37913[D loss: 0.395187, acc: 61.72%, op_acc: 50.00%] [G loss: 1.228176]\n",
      "epoch:48 step:37914[D loss: 0.425875, acc: 66.41%, op_acc: 40.62%] [G loss: 1.026794]\n",
      "epoch:48 step:37915[D loss: 0.409091, acc: 63.28%, op_acc: 44.53%] [G loss: 1.006575]\n",
      "epoch:48 step:37916[D loss: 0.347857, acc: 71.09%, op_acc: 52.34%] [G loss: 1.174440]\n",
      "epoch:48 step:37917[D loss: 0.419856, acc: 63.28%, op_acc: 41.41%] [G loss: 0.986998]\n",
      "epoch:48 step:37918[D loss: 0.383674, acc: 69.53%, op_acc: 41.41%] [G loss: 1.093645]\n",
      "epoch:48 step:37919[D loss: 0.404816, acc: 62.50%, op_acc: 42.97%] [G loss: 0.763111]\n",
      "epoch:48 step:37920[D loss: 0.378715, acc: 63.28%, op_acc: 43.75%] [G loss: 1.162910]\n",
      "epoch:48 step:37921[D loss: 0.357130, acc: 71.09%, op_acc: 50.00%] [G loss: 1.111925]\n",
      "epoch:48 step:37922[D loss: 0.358924, acc: 68.75%, op_acc: 52.34%] [G loss: 1.354082]\n",
      "epoch:48 step:37923[D loss: 0.365185, acc: 74.22%, op_acc: 47.66%] [G loss: 1.117236]\n",
      "epoch:48 step:37924[D loss: 0.369655, acc: 67.97%, op_acc: 41.41%] [G loss: 1.158112]\n",
      "epoch:48 step:37925[D loss: 0.389087, acc: 68.75%, op_acc: 50.00%] [G loss: 1.103985]\n",
      "epoch:48 step:37926[D loss: 0.333256, acc: 74.22%, op_acc: 48.44%] [G loss: 1.234291]\n",
      "epoch:48 step:37927[D loss: 0.356987, acc: 68.75%, op_acc: 55.47%] [G loss: 1.099148]\n",
      "epoch:48 step:37928[D loss: 0.359551, acc: 67.97%, op_acc: 45.31%] [G loss: 1.244014]\n",
      "epoch:48 step:37929[D loss: 0.379513, acc: 58.59%, op_acc: 48.44%] [G loss: 1.153033]\n",
      "epoch:48 step:37930[D loss: 0.355362, acc: 70.31%, op_acc: 49.22%] [G loss: 1.240952]\n",
      "epoch:48 step:37931[D loss: 0.379607, acc: 76.56%, op_acc: 45.31%] [G loss: 1.282180]\n",
      "epoch:48 step:37932[D loss: 0.320284, acc: 77.34%, op_acc: 53.12%] [G loss: 0.824985]\n",
      "epoch:48 step:37933[D loss: 0.375011, acc: 71.88%, op_acc: 48.44%] [G loss: 0.748311]\n",
      "epoch:48 step:37934[D loss: 0.408080, acc: 61.72%, op_acc: 46.09%] [G loss: 1.375098]\n",
      "epoch:48 step:37935[D loss: 0.430011, acc: 67.19%, op_acc: 36.72%] [G loss: 0.766828]\n",
      "epoch:48 step:37936[D loss: 0.425309, acc: 59.38%, op_acc: 38.28%] [G loss: 1.236671]\n",
      "epoch:48 step:37937[D loss: 0.409943, acc: 64.06%, op_acc: 43.75%] [G loss: 1.120234]\n",
      "epoch:48 step:37938[D loss: 0.420954, acc: 60.94%, op_acc: 37.50%] [G loss: 1.257396]\n",
      "epoch:48 step:37939[D loss: 0.362229, acc: 70.31%, op_acc: 49.22%] [G loss: 1.245247]\n",
      "epoch:48 step:37940[D loss: 0.341718, acc: 72.66%, op_acc: 45.31%] [G loss: 1.227074]\n",
      "epoch:48 step:37941[D loss: 0.355456, acc: 70.31%, op_acc: 47.66%] [G loss: 1.181786]\n",
      "epoch:48 step:37942[D loss: 0.386676, acc: 65.62%, op_acc: 48.44%] [G loss: 1.027668]\n",
      "epoch:48 step:37943[D loss: 0.368193, acc: 70.31%, op_acc: 46.88%] [G loss: 0.909332]\n",
      "epoch:48 step:37944[D loss: 0.353691, acc: 76.56%, op_acc: 39.06%] [G loss: 1.075742]\n",
      "epoch:48 step:37945[D loss: 0.354608, acc: 74.22%, op_acc: 46.88%] [G loss: 1.148816]\n",
      "epoch:48 step:37946[D loss: 0.352010, acc: 72.66%, op_acc: 46.09%] [G loss: 1.193902]\n",
      "epoch:48 step:37947[D loss: 0.361648, acc: 61.72%, op_acc: 48.44%] [G loss: 1.209809]\n",
      "epoch:48 step:37948[D loss: 0.337202, acc: 71.88%, op_acc: 53.12%] [G loss: 1.107889]\n",
      "epoch:48 step:37949[D loss: 0.343891, acc: 75.78%, op_acc: 47.66%] [G loss: 1.275001]\n",
      "epoch:48 step:37950[D loss: 0.336962, acc: 75.78%, op_acc: 47.66%] [G loss: 1.240038]\n",
      "##############\n",
      "[0.85838178 0.86303632 0.81446553 0.8150703  0.79014955 0.8229315\n",
      " 0.89705815 0.83289338 0.81729267 0.83884188]\n",
      "##########\n",
      "epoch:48 step:37951[D loss: 0.339089, acc: 74.22%, op_acc: 48.44%] [G loss: 0.616297]\n",
      "epoch:48 step:37952[D loss: 0.444272, acc: 57.03%, op_acc: 37.50%] [G loss: 0.654936]\n",
      "epoch:48 step:37953[D loss: 0.375069, acc: 67.19%, op_acc: 46.88%] [G loss: 1.118442]\n",
      "epoch:48 step:37954[D loss: 0.400201, acc: 64.06%, op_acc: 41.41%] [G loss: 1.216892]\n",
      "epoch:48 step:37955[D loss: 0.389248, acc: 65.62%, op_acc: 46.09%] [G loss: 1.374917]\n",
      "epoch:48 step:37956[D loss: 0.369913, acc: 66.41%, op_acc: 47.66%] [G loss: 1.378336]\n",
      "epoch:48 step:37957[D loss: 0.309983, acc: 76.56%, op_acc: 53.12%] [G loss: 1.282509]\n",
      "epoch:48 step:37958[D loss: 0.347019, acc: 76.56%, op_acc: 48.44%] [G loss: 1.234816]\n",
      "epoch:48 step:37959[D loss: 0.345736, acc: 75.00%, op_acc: 45.31%] [G loss: 1.225277]\n",
      "epoch:48 step:37960[D loss: 0.375564, acc: 71.88%, op_acc: 48.44%] [G loss: 1.258260]\n",
      "epoch:48 step:37961[D loss: 0.308901, acc: 75.00%, op_acc: 59.38%] [G loss: 0.922606]\n",
      "epoch:48 step:37962[D loss: 0.396897, acc: 64.84%, op_acc: 48.44%] [G loss: 1.109454]\n",
      "epoch:48 step:37963[D loss: 0.385951, acc: 64.84%, op_acc: 54.69%] [G loss: 1.064147]\n",
      "epoch:48 step:37964[D loss: 0.366251, acc: 65.62%, op_acc: 46.09%] [G loss: 1.230402]\n",
      "epoch:48 step:37965[D loss: 0.400711, acc: 67.19%, op_acc: 46.88%] [G loss: 1.111163]\n",
      "epoch:48 step:37966[D loss: 0.340076, acc: 75.00%, op_acc: 50.78%] [G loss: 0.761570]\n",
      "epoch:48 step:37967[D loss: 0.406336, acc: 64.84%, op_acc: 43.75%] [G loss: 1.104808]\n",
      "epoch:48 step:37968[D loss: 0.416190, acc: 67.97%, op_acc: 36.72%] [G loss: 1.212249]\n",
      "epoch:48 step:37969[D loss: 0.377364, acc: 70.31%, op_acc: 43.75%] [G loss: 0.912102]\n",
      "epoch:48 step:37970[D loss: 0.421891, acc: 61.72%, op_acc: 42.19%] [G loss: 1.019954]\n",
      "epoch:48 step:37971[D loss: 0.357832, acc: 72.66%, op_acc: 48.44%] [G loss: 1.384015]\n",
      "epoch:48 step:37972[D loss: 0.382030, acc: 67.19%, op_acc: 46.09%] [G loss: 1.055788]\n",
      "epoch:48 step:37973[D loss: 0.335704, acc: 73.44%, op_acc: 43.75%] [G loss: 1.293831]\n",
      "epoch:48 step:37974[D loss: 0.347695, acc: 73.44%, op_acc: 46.88%] [G loss: 1.024633]\n",
      "epoch:48 step:37975[D loss: 0.360021, acc: 71.09%, op_acc: 48.44%] [G loss: 1.048177]\n",
      "epoch:48 step:37976[D loss: 0.383927, acc: 69.53%, op_acc: 42.19%] [G loss: 1.183438]\n",
      "epoch:48 step:37977[D loss: 0.417502, acc: 64.06%, op_acc: 41.41%] [G loss: 1.221866]\n",
      "epoch:48 step:37978[D loss: 0.347583, acc: 70.31%, op_acc: 52.34%] [G loss: 0.996170]\n",
      "epoch:48 step:37979[D loss: 0.419217, acc: 63.28%, op_acc: 42.97%] [G loss: 1.306474]\n",
      "epoch:48 step:37980[D loss: 0.377377, acc: 63.28%, op_acc: 42.97%] [G loss: 1.287155]\n",
      "epoch:48 step:37981[D loss: 0.405876, acc: 64.06%, op_acc: 45.31%] [G loss: 0.981923]\n",
      "epoch:48 step:37982[D loss: 0.339630, acc: 71.88%, op_acc: 51.56%] [G loss: 1.113178]\n",
      "epoch:48 step:37983[D loss: 0.357154, acc: 71.88%, op_acc: 51.56%] [G loss: 1.153349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37984[D loss: 0.352598, acc: 71.88%, op_acc: 49.22%] [G loss: 1.017295]\n",
      "epoch:48 step:37985[D loss: 0.402544, acc: 62.50%, op_acc: 43.75%] [G loss: 1.136869]\n",
      "epoch:48 step:37986[D loss: 0.366501, acc: 76.56%, op_acc: 48.44%] [G loss: 0.904751]\n",
      "epoch:48 step:37987[D loss: 0.340130, acc: 75.00%, op_acc: 50.00%] [G loss: 0.981653]\n",
      "epoch:48 step:37988[D loss: 0.361300, acc: 69.53%, op_acc: 43.75%] [G loss: 1.006495]\n",
      "epoch:48 step:37989[D loss: 0.327092, acc: 71.88%, op_acc: 48.44%] [G loss: 0.845120]\n",
      "epoch:48 step:37990[D loss: 0.372402, acc: 64.06%, op_acc: 53.12%] [G loss: 1.105399]\n",
      "epoch:48 step:37991[D loss: 0.373593, acc: 65.62%, op_acc: 46.09%] [G loss: 0.675514]\n",
      "epoch:48 step:37992[D loss: 0.411259, acc: 67.97%, op_acc: 46.09%] [G loss: 1.103731]\n",
      "epoch:48 step:37993[D loss: 0.380022, acc: 67.19%, op_acc: 44.53%] [G loss: 1.100374]\n",
      "epoch:48 step:37994[D loss: 0.397134, acc: 66.41%, op_acc: 44.53%] [G loss: 0.929518]\n",
      "epoch:48 step:37995[D loss: 0.375010, acc: 67.97%, op_acc: 46.09%] [G loss: 1.104975]\n",
      "epoch:48 step:37996[D loss: 0.395643, acc: 60.94%, op_acc: 46.88%] [G loss: 1.067963]\n",
      "epoch:48 step:37997[D loss: 0.461847, acc: 57.03%, op_acc: 43.75%] [G loss: 1.082322]\n",
      "epoch:48 step:37998[D loss: 0.377615, acc: 66.41%, op_acc: 48.44%] [G loss: 0.966737]\n",
      "epoch:48 step:37999[D loss: 0.394751, acc: 58.59%, op_acc: 49.22%] [G loss: 1.020028]\n",
      "epoch:48 step:38000[D loss: 0.438575, acc: 57.03%, op_acc: 43.75%] [G loss: 0.967922]\n",
      "##############\n",
      "[0.86473735 0.85242018 0.81495761 0.80480065 0.80687029 0.82327592\n",
      " 0.90079898 0.84519766 0.81719889 0.80385607]\n",
      "##########\n",
      "epoch:48 step:38001[D loss: 0.423722, acc: 62.50%, op_acc: 45.31%] [G loss: 1.165323]\n",
      "epoch:48 step:38002[D loss: 0.428412, acc: 58.59%, op_acc: 41.41%] [G loss: 1.219898]\n",
      "epoch:48 step:38003[D loss: 0.416185, acc: 64.84%, op_acc: 38.28%] [G loss: 0.942171]\n",
      "epoch:48 step:38004[D loss: 0.423460, acc: 64.06%, op_acc: 42.97%] [G loss: 0.820327]\n",
      "epoch:48 step:38005[D loss: 0.447172, acc: 60.16%, op_acc: 39.84%] [G loss: 0.755192]\n",
      "epoch:48 step:38006[D loss: 0.360979, acc: 65.62%, op_acc: 46.88%] [G loss: 1.183531]\n",
      "epoch:48 step:38007[D loss: 0.355930, acc: 69.53%, op_acc: 52.34%] [G loss: 1.043849]\n",
      "epoch:48 step:38008[D loss: 0.368215, acc: 67.19%, op_acc: 45.31%] [G loss: 1.356382]\n",
      "epoch:48 step:38009[D loss: 0.384339, acc: 67.97%, op_acc: 46.09%] [G loss: 1.051742]\n",
      "epoch:48 step:38010[D loss: 0.349843, acc: 74.22%, op_acc: 50.00%] [G loss: 1.138836]\n",
      "epoch:48 step:38011[D loss: 0.440903, acc: 56.25%, op_acc: 42.97%] [G loss: 1.144075]\n",
      "epoch:48 step:38012[D loss: 0.424478, acc: 61.72%, op_acc: 43.75%] [G loss: 0.885680]\n",
      "epoch:48 step:38013[D loss: 0.366444, acc: 72.66%, op_acc: 46.09%] [G loss: 1.113406]\n",
      "epoch:48 step:38014[D loss: 0.460710, acc: 58.59%, op_acc: 38.28%] [G loss: 1.150824]\n",
      "epoch:48 step:38015[D loss: 0.445026, acc: 57.81%, op_acc: 42.19%] [G loss: 0.861374]\n",
      "epoch:48 step:38016[D loss: 0.394496, acc: 64.84%, op_acc: 45.31%] [G loss: 0.872484]\n",
      "epoch:48 step:38017[D loss: 0.368023, acc: 67.97%, op_acc: 47.66%] [G loss: 0.867890]\n",
      "epoch:48 step:38018[D loss: 0.371692, acc: 67.97%, op_acc: 46.09%] [G loss: 0.877587]\n",
      "epoch:48 step:38019[D loss: 0.351353, acc: 75.78%, op_acc: 51.56%] [G loss: 1.052418]\n",
      "epoch:48 step:38020[D loss: 0.400401, acc: 65.62%, op_acc: 41.41%] [G loss: 0.917152]\n",
      "epoch:48 step:38021[D loss: 0.381389, acc: 60.94%, op_acc: 52.34%] [G loss: 1.283243]\n",
      "epoch:48 step:38022[D loss: 0.370541, acc: 67.97%, op_acc: 47.66%] [G loss: 0.731951]\n",
      "epoch:48 step:38023[D loss: 0.398413, acc: 69.53%, op_acc: 42.19%] [G loss: 0.859772]\n",
      "epoch:48 step:38024[D loss: 0.360832, acc: 61.72%, op_acc: 50.00%] [G loss: 1.011610]\n",
      "epoch:48 step:38025[D loss: 0.404544, acc: 64.06%, op_acc: 42.19%] [G loss: 0.852569]\n",
      "epoch:48 step:38026[D loss: 0.416745, acc: 62.50%, op_acc: 44.53%] [G loss: 0.721625]\n",
      "epoch:48 step:38027[D loss: 0.374641, acc: 72.66%, op_acc: 48.44%] [G loss: 0.933635]\n",
      "epoch:48 step:38028[D loss: 0.316127, acc: 76.56%, op_acc: 50.78%] [G loss: 1.334969]\n",
      "epoch:48 step:38029[D loss: 0.324752, acc: 77.34%, op_acc: 46.09%] [G loss: 0.919645]\n",
      "epoch:48 step:38030[D loss: 0.400695, acc: 64.84%, op_acc: 42.97%] [G loss: 1.068301]\n",
      "epoch:48 step:38031[D loss: 0.362267, acc: 71.88%, op_acc: 50.78%] [G loss: 0.850801]\n",
      "epoch:48 step:38032[D loss: 0.361778, acc: 71.09%, op_acc: 40.62%] [G loss: 1.199827]\n",
      "epoch:48 step:38033[D loss: 0.338822, acc: 76.56%, op_acc: 48.44%] [G loss: 1.159897]\n",
      "epoch:48 step:38034[D loss: 0.398040, acc: 69.53%, op_acc: 46.88%] [G loss: 1.346881]\n",
      "epoch:48 step:38035[D loss: 0.379502, acc: 70.31%, op_acc: 44.53%] [G loss: 1.021777]\n",
      "epoch:48 step:38036[D loss: 0.364591, acc: 71.09%, op_acc: 46.88%] [G loss: 1.285940]\n",
      "epoch:48 step:38037[D loss: 0.340061, acc: 71.88%, op_acc: 53.12%] [G loss: 0.994934]\n",
      "epoch:48 step:38038[D loss: 0.304921, acc: 80.47%, op_acc: 51.56%] [G loss: 1.013967]\n",
      "epoch:48 step:38039[D loss: 0.351319, acc: 71.09%, op_acc: 47.66%] [G loss: 1.060273]\n",
      "epoch:48 step:38040[D loss: 0.378106, acc: 66.41%, op_acc: 44.53%] [G loss: 0.977843]\n",
      "epoch:48 step:38041[D loss: 0.337485, acc: 75.78%, op_acc: 52.34%] [G loss: 1.251268]\n",
      "epoch:48 step:38042[D loss: 0.315192, acc: 78.12%, op_acc: 50.78%] [G loss: 1.200244]\n",
      "epoch:48 step:38043[D loss: 0.299325, acc: 77.34%, op_acc: 53.12%] [G loss: 1.324549]\n",
      "epoch:48 step:38044[D loss: 0.346534, acc: 72.66%, op_acc: 49.22%] [G loss: 1.239132]\n",
      "epoch:48 step:38045[D loss: 0.356113, acc: 72.66%, op_acc: 42.19%] [G loss: 1.120291]\n",
      "epoch:48 step:38046[D loss: 0.365126, acc: 71.88%, op_acc: 46.88%] [G loss: 1.147126]\n",
      "epoch:48 step:38047[D loss: 0.336594, acc: 73.44%, op_acc: 53.91%] [G loss: 1.213000]\n",
      "epoch:48 step:38048[D loss: 0.315890, acc: 83.59%, op_acc: 48.44%] [G loss: 1.058223]\n",
      "epoch:48 step:38049[D loss: 0.301520, acc: 80.47%, op_acc: 52.34%] [G loss: 1.530499]\n",
      "epoch:48 step:38050[D loss: 0.336646, acc: 75.00%, op_acc: 39.06%] [G loss: 0.647881]\n",
      "##############\n",
      "[0.87958486 0.85383807 0.8040471  0.81877557 0.79601885 0.84269457\n",
      " 0.89685815 0.83208583 0.79320835 0.83651425]\n",
      "##########\n",
      "epoch:48 step:38051[D loss: 0.455973, acc: 56.25%, op_acc: 41.41%] [G loss: 1.576821]\n",
      "epoch:48 step:38052[D loss: 0.447792, acc: 57.03%, op_acc: 46.09%] [G loss: 1.481292]\n",
      "epoch:48 step:38053[D loss: 0.396838, acc: 65.62%, op_acc: 51.56%] [G loss: 1.370817]\n",
      "epoch:48 step:38054[D loss: 0.388996, acc: 64.06%, op_acc: 45.31%] [G loss: 1.244856]\n",
      "epoch:48 step:38055[D loss: 0.375870, acc: 69.53%, op_acc: 45.31%] [G loss: 1.526031]\n",
      "epoch:48 step:38056[D loss: 0.326332, acc: 75.00%, op_acc: 57.03%] [G loss: 1.335083]\n",
      "epoch:48 step:38057[D loss: 0.360232, acc: 69.53%, op_acc: 46.88%] [G loss: 1.304699]\n",
      "epoch:48 step:38058[D loss: 0.332586, acc: 77.34%, op_acc: 38.28%] [G loss: 0.928921]\n",
      "epoch:48 step:38059[D loss: 0.379116, acc: 62.50%, op_acc: 49.22%] [G loss: 1.495609]\n",
      "epoch:48 step:38060[D loss: 0.411836, acc: 67.19%, op_acc: 42.97%] [G loss: 1.345453]\n",
      "epoch:48 step:38061[D loss: 0.393139, acc: 63.28%, op_acc: 50.78%] [G loss: 1.263409]\n",
      "epoch:48 step:38062[D loss: 0.391052, acc: 64.84%, op_acc: 43.75%] [G loss: 0.937439]\n",
      "epoch:48 step:38063[D loss: 0.412381, acc: 60.16%, op_acc: 43.75%] [G loss: 0.869771]\n",
      "epoch:48 step:38064[D loss: 0.379534, acc: 67.19%, op_acc: 44.53%] [G loss: 1.342496]\n",
      "epoch:48 step:38065[D loss: 0.386413, acc: 69.53%, op_acc: 43.75%] [G loss: 1.143344]\n",
      "epoch:48 step:38066[D loss: 0.444886, acc: 58.59%, op_acc: 40.62%] [G loss: 1.249967]\n",
      "epoch:48 step:38067[D loss: 0.342283, acc: 75.00%, op_acc: 52.34%] [G loss: 1.072574]\n",
      "epoch:48 step:38068[D loss: 0.367947, acc: 71.88%, op_acc: 49.22%] [G loss: 1.221999]\n",
      "epoch:48 step:38069[D loss: 0.394406, acc: 64.06%, op_acc: 43.75%] [G loss: 1.230419]\n",
      "epoch:48 step:38070[D loss: 0.419269, acc: 61.72%, op_acc: 42.97%] [G loss: 1.173169]\n",
      "epoch:48 step:38071[D loss: 0.394490, acc: 65.62%, op_acc: 39.84%] [G loss: 1.150938]\n",
      "epoch:48 step:38072[D loss: 0.402058, acc: 68.75%, op_acc: 41.41%] [G loss: 0.914792]\n",
      "epoch:48 step:38073[D loss: 0.380619, acc: 60.16%, op_acc: 50.00%] [G loss: 1.210241]\n",
      "epoch:48 step:38074[D loss: 0.460146, acc: 53.12%, op_acc: 41.41%] [G loss: 1.135433]\n",
      "epoch:48 step:38075[D loss: 0.416783, acc: 64.06%, op_acc: 43.75%] [G loss: 1.242669]\n",
      "epoch:48 step:38076[D loss: 0.411757, acc: 65.62%, op_acc: 46.88%] [G loss: 1.225617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38077[D loss: 0.393654, acc: 67.19%, op_acc: 46.88%] [G loss: 1.161279]\n",
      "epoch:48 step:38078[D loss: 0.388706, acc: 67.19%, op_acc: 44.53%] [G loss: 1.184877]\n",
      "epoch:48 step:38079[D loss: 0.408227, acc: 62.50%, op_acc: 47.66%] [G loss: 1.325175]\n",
      "epoch:48 step:38080[D loss: 0.380724, acc: 69.53%, op_acc: 48.44%] [G loss: 1.083347]\n",
      "epoch:48 step:38081[D loss: 0.417418, acc: 60.16%, op_acc: 36.72%] [G loss: 0.993316]\n",
      "epoch:48 step:38082[D loss: 0.333621, acc: 78.12%, op_acc: 50.78%] [G loss: 0.898620]\n",
      "epoch:48 step:38083[D loss: 0.362378, acc: 67.97%, op_acc: 46.88%] [G loss: 0.917435]\n",
      "epoch:48 step:38084[D loss: 0.405801, acc: 65.62%, op_acc: 47.66%] [G loss: 1.242764]\n",
      "epoch:48 step:38085[D loss: 0.310002, acc: 80.47%, op_acc: 50.00%] [G loss: 1.023031]\n",
      "epoch:48 step:38086[D loss: 0.343985, acc: 71.09%, op_acc: 46.88%] [G loss: 1.072182]\n",
      "epoch:48 step:38087[D loss: 0.377930, acc: 74.22%, op_acc: 46.09%] [G loss: 1.071406]\n",
      "epoch:48 step:38088[D loss: 0.375696, acc: 68.75%, op_acc: 46.88%] [G loss: 0.944601]\n",
      "epoch:48 step:38089[D loss: 0.430546, acc: 56.25%, op_acc: 40.62%] [G loss: 0.995366]\n",
      "epoch:48 step:38090[D loss: 0.374622, acc: 67.97%, op_acc: 51.56%] [G loss: 0.838339]\n",
      "epoch:48 step:38091[D loss: 0.371871, acc: 69.53%, op_acc: 51.56%] [G loss: 1.029539]\n",
      "epoch:48 step:38092[D loss: 0.410488, acc: 59.38%, op_acc: 41.41%] [G loss: 0.873106]\n",
      "epoch:48 step:38093[D loss: 0.400017, acc: 65.62%, op_acc: 44.53%] [G loss: 0.828734]\n",
      "epoch:48 step:38094[D loss: 0.406462, acc: 64.84%, op_acc: 49.22%] [G loss: 0.910043]\n",
      "epoch:48 step:38095[D loss: 0.331671, acc: 78.12%, op_acc: 51.56%] [G loss: 0.934417]\n",
      "epoch:48 step:38096[D loss: 0.324195, acc: 75.78%, op_acc: 51.56%] [G loss: 1.151281]\n",
      "epoch:48 step:38097[D loss: 0.359157, acc: 69.53%, op_acc: 50.78%] [G loss: 1.283182]\n",
      "epoch:48 step:38098[D loss: 0.408756, acc: 62.50%, op_acc: 43.75%] [G loss: 1.152012]\n",
      "epoch:48 step:38099[D loss: 0.379565, acc: 67.97%, op_acc: 40.62%] [G loss: 1.128868]\n",
      "epoch:48 step:38100[D loss: 0.387764, acc: 69.53%, op_acc: 46.88%] [G loss: 0.925356]\n",
      "##############\n",
      "[0.85444291 0.86255032 0.80365994 0.83541082 0.76860088 0.82975679\n",
      " 0.86150428 0.8200984  0.80035712 0.85296473]\n",
      "##########\n",
      "epoch:48 step:38101[D loss: 0.352819, acc: 71.88%, op_acc: 52.34%] [G loss: 1.103747]\n",
      "epoch:48 step:38102[D loss: 0.410589, acc: 65.62%, op_acc: 39.84%] [G loss: 1.087574]\n",
      "epoch:48 step:38103[D loss: 0.346616, acc: 74.22%, op_acc: 46.09%] [G loss: 0.985771]\n",
      "epoch:48 step:38104[D loss: 0.376938, acc: 69.53%, op_acc: 45.31%] [G loss: 1.081384]\n",
      "epoch:48 step:38105[D loss: 0.398389, acc: 64.84%, op_acc: 52.34%] [G loss: 0.917969]\n",
      "epoch:48 step:38106[D loss: 0.349111, acc: 71.09%, op_acc: 53.91%] [G loss: 0.984955]\n",
      "epoch:48 step:38107[D loss: 0.370476, acc: 73.44%, op_acc: 39.06%] [G loss: 1.029242]\n",
      "epoch:48 step:38108[D loss: 0.403041, acc: 65.62%, op_acc: 46.88%] [G loss: 0.977026]\n",
      "epoch:48 step:38109[D loss: 0.368482, acc: 71.88%, op_acc: 44.53%] [G loss: 1.032870]\n",
      "epoch:48 step:38110[D loss: 0.392581, acc: 69.53%, op_acc: 45.31%] [G loss: 1.136561]\n",
      "epoch:48 step:38111[D loss: 0.433214, acc: 59.38%, op_acc: 39.84%] [G loss: 1.263279]\n",
      "epoch:48 step:38112[D loss: 0.379407, acc: 65.62%, op_acc: 51.56%] [G loss: 1.065012]\n",
      "epoch:48 step:38113[D loss: 0.404007, acc: 65.62%, op_acc: 40.62%] [G loss: 0.948888]\n",
      "epoch:48 step:38114[D loss: 0.418834, acc: 62.50%, op_acc: 47.66%] [G loss: 1.055870]\n",
      "epoch:48 step:38115[D loss: 0.401725, acc: 64.06%, op_acc: 44.53%] [G loss: 1.073579]\n",
      "epoch:48 step:38116[D loss: 0.420047, acc: 66.41%, op_acc: 46.09%] [G loss: 1.218365]\n",
      "epoch:48 step:38117[D loss: 0.428163, acc: 56.25%, op_acc: 42.97%] [G loss: 0.800840]\n",
      "epoch:48 step:38118[D loss: 0.392733, acc: 67.97%, op_acc: 47.66%] [G loss: 0.980099]\n",
      "epoch:48 step:38119[D loss: 0.403199, acc: 68.75%, op_acc: 37.50%] [G loss: 1.151141]\n",
      "epoch:48 step:38120[D loss: 0.383277, acc: 69.53%, op_acc: 46.09%] [G loss: 1.019797]\n",
      "epoch:48 step:38121[D loss: 0.448539, acc: 57.81%, op_acc: 42.19%] [G loss: 1.015428]\n",
      "epoch:48 step:38122[D loss: 0.462064, acc: 53.12%, op_acc: 46.09%] [G loss: 0.755179]\n",
      "epoch:48 step:38123[D loss: 0.477424, acc: 53.12%, op_acc: 43.75%] [G loss: 0.855092]\n",
      "epoch:48 step:38124[D loss: 0.411808, acc: 63.28%, op_acc: 44.53%] [G loss: 1.122970]\n",
      "epoch:48 step:38125[D loss: 0.380960, acc: 63.28%, op_acc: 45.31%] [G loss: 1.175572]\n",
      "epoch:48 step:38126[D loss: 0.407083, acc: 67.97%, op_acc: 46.09%] [G loss: 0.840369]\n",
      "epoch:48 step:38127[D loss: 0.390251, acc: 67.97%, op_acc: 47.66%] [G loss: 1.235466]\n",
      "epoch:48 step:38128[D loss: 0.435590, acc: 57.81%, op_acc: 40.62%] [G loss: 0.739449]\n",
      "epoch:48 step:38129[D loss: 0.383220, acc: 70.31%, op_acc: 48.44%] [G loss: 0.933661]\n",
      "epoch:48 step:38130[D loss: 0.403929, acc: 63.28%, op_acc: 44.53%] [G loss: 0.722356]\n",
      "epoch:48 step:38131[D loss: 0.389685, acc: 66.41%, op_acc: 39.06%] [G loss: 0.632630]\n",
      "epoch:48 step:38132[D loss: 0.336738, acc: 75.00%, op_acc: 48.44%] [G loss: 0.912467]\n",
      "epoch:48 step:38133[D loss: 0.354415, acc: 75.78%, op_acc: 41.41%] [G loss: 0.848654]\n",
      "epoch:48 step:38134[D loss: 0.399670, acc: 61.72%, op_acc: 42.19%] [G loss: 0.788828]\n",
      "epoch:48 step:38135[D loss: 0.380961, acc: 65.62%, op_acc: 48.44%] [G loss: 1.144102]\n",
      "epoch:48 step:38136[D loss: 0.419936, acc: 67.97%, op_acc: 39.84%] [G loss: 0.792708]\n",
      "epoch:48 step:38137[D loss: 0.369875, acc: 70.31%, op_acc: 39.06%] [G loss: 0.934793]\n",
      "epoch:48 step:38138[D loss: 0.389701, acc: 71.09%, op_acc: 41.41%] [G loss: 0.874013]\n",
      "epoch:48 step:38139[D loss: 0.383482, acc: 60.94%, op_acc: 50.78%] [G loss: 0.775775]\n",
      "epoch:48 step:38140[D loss: 0.384004, acc: 66.41%, op_acc: 42.19%] [G loss: 0.997813]\n",
      "epoch:48 step:38141[D loss: 0.361193, acc: 69.53%, op_acc: 47.66%] [G loss: 0.772640]\n",
      "epoch:48 step:38142[D loss: 0.368215, acc: 67.97%, op_acc: 46.09%] [G loss: 1.201946]\n",
      "epoch:48 step:38143[D loss: 0.374394, acc: 68.75%, op_acc: 45.31%] [G loss: 1.251821]\n",
      "epoch:48 step:38144[D loss: 0.380182, acc: 68.75%, op_acc: 49.22%] [G loss: 0.902174]\n",
      "epoch:48 step:38145[D loss: 0.435524, acc: 61.72%, op_acc: 37.50%] [G loss: 0.913162]\n",
      "epoch:48 step:38146[D loss: 0.372417, acc: 67.97%, op_acc: 44.53%] [G loss: 0.961487]\n",
      "epoch:48 step:38147[D loss: 0.378456, acc: 67.19%, op_acc: 47.66%] [G loss: 0.849603]\n",
      "epoch:48 step:38148[D loss: 0.334245, acc: 75.00%, op_acc: 52.34%] [G loss: 1.182824]\n",
      "epoch:48 step:38149[D loss: 0.376123, acc: 57.81%, op_acc: 46.88%] [G loss: 0.915374]\n",
      "epoch:48 step:38150[D loss: 0.391777, acc: 60.94%, op_acc: 50.00%] [G loss: 0.858379]\n",
      "##############\n",
      "[0.8655472  0.87382648 0.79429784 0.79948585 0.80802205 0.81805955\n",
      " 0.87504915 0.83702299 0.82026054 0.8189402 ]\n",
      "##########\n",
      "epoch:48 step:38151[D loss: 0.391893, acc: 65.62%, op_acc: 47.66%] [G loss: 0.922645]\n",
      "epoch:48 step:38152[D loss: 0.372616, acc: 65.62%, op_acc: 45.31%] [G loss: 0.923735]\n",
      "epoch:48 step:38153[D loss: 0.398415, acc: 66.41%, op_acc: 47.66%] [G loss: 1.067893]\n",
      "epoch:48 step:38154[D loss: 0.375409, acc: 73.44%, op_acc: 48.44%] [G loss: 1.096232]\n",
      "epoch:48 step:38155[D loss: 0.395771, acc: 63.28%, op_acc: 41.41%] [G loss: 1.011809]\n",
      "epoch:48 step:38156[D loss: 0.393636, acc: 67.97%, op_acc: 43.75%] [G loss: 1.164293]\n",
      "epoch:48 step:38157[D loss: 0.439982, acc: 58.59%, op_acc: 39.84%] [G loss: 0.832103]\n",
      "epoch:48 step:38158[D loss: 0.416624, acc: 64.06%, op_acc: 47.66%] [G loss: 1.002064]\n",
      "epoch:48 step:38159[D loss: 0.381109, acc: 70.31%, op_acc: 48.44%] [G loss: 0.854787]\n",
      "epoch:48 step:38160[D loss: 0.395090, acc: 66.41%, op_acc: 46.09%] [G loss: 0.851115]\n",
      "epoch:48 step:38161[D loss: 0.406237, acc: 62.50%, op_acc: 37.50%] [G loss: 0.961574]\n",
      "epoch:48 step:38162[D loss: 0.384498, acc: 64.06%, op_acc: 47.66%] [G loss: 1.050444]\n",
      "epoch:48 step:38163[D loss: 0.396220, acc: 65.62%, op_acc: 42.97%] [G loss: 1.102699]\n",
      "epoch:48 step:38164[D loss: 0.472893, acc: 57.81%, op_acc: 35.16%] [G loss: 1.235709]\n",
      "epoch:48 step:38165[D loss: 0.429778, acc: 61.72%, op_acc: 42.97%] [G loss: 1.004363]\n",
      "epoch:48 step:38166[D loss: 0.365447, acc: 75.00%, op_acc: 50.00%] [G loss: 1.068614]\n",
      "epoch:48 step:38167[D loss: 0.401685, acc: 67.19%, op_acc: 44.53%] [G loss: 0.756979]\n",
      "epoch:48 step:38168[D loss: 0.423823, acc: 62.50%, op_acc: 40.62%] [G loss: 1.105505]\n",
      "epoch:48 step:38169[D loss: 0.410409, acc: 62.50%, op_acc: 39.84%] [G loss: 1.215080]\n",
      "epoch:48 step:38170[D loss: 0.362056, acc: 70.31%, op_acc: 50.00%] [G loss: 0.711249]\n",
      "epoch:48 step:38171[D loss: 0.337747, acc: 75.00%, op_acc: 53.91%] [G loss: 1.243757]\n",
      "epoch:48 step:38172[D loss: 0.388600, acc: 65.62%, op_acc: 43.75%] [G loss: 0.766579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38173[D loss: 0.411329, acc: 61.72%, op_acc: 46.09%] [G loss: 0.720748]\n",
      "epoch:48 step:38174[D loss: 0.334229, acc: 78.12%, op_acc: 48.44%] [G loss: 0.665874]\n",
      "epoch:48 step:38175[D loss: 0.329744, acc: 73.44%, op_acc: 49.22%] [G loss: 0.652216]\n",
      "epoch:48 step:38176[D loss: 0.391918, acc: 62.50%, op_acc: 47.66%] [G loss: 0.853752]\n",
      "epoch:48 step:38177[D loss: 0.373535, acc: 62.50%, op_acc: 49.22%] [G loss: 1.003536]\n",
      "epoch:48 step:38178[D loss: 0.396606, acc: 72.66%, op_acc: 44.53%] [G loss: 0.729433]\n",
      "epoch:48 step:38179[D loss: 0.385909, acc: 65.62%, op_acc: 49.22%] [G loss: 0.780286]\n",
      "epoch:48 step:38180[D loss: 0.424832, acc: 57.81%, op_acc: 46.88%] [G loss: 1.240827]\n",
      "epoch:48 step:38181[D loss: 0.328453, acc: 76.56%, op_acc: 45.31%] [G loss: 0.917226]\n",
      "epoch:48 step:38182[D loss: 0.404588, acc: 64.06%, op_acc: 46.09%] [G loss: 0.641030]\n",
      "epoch:48 step:38183[D loss: 0.360211, acc: 70.31%, op_acc: 45.31%] [G loss: 1.172135]\n",
      "epoch:48 step:38184[D loss: 0.368129, acc: 67.97%, op_acc: 50.00%] [G loss: 0.913679]\n",
      "epoch:48 step:38185[D loss: 0.350543, acc: 67.19%, op_acc: 51.56%] [G loss: 1.146218]\n",
      "epoch:48 step:38186[D loss: 0.380963, acc: 69.53%, op_acc: 43.75%] [G loss: 0.686505]\n",
      "epoch:48 step:38187[D loss: 0.372764, acc: 64.06%, op_acc: 46.88%] [G loss: 1.200336]\n",
      "epoch:48 step:38188[D loss: 0.400235, acc: 64.84%, op_acc: 47.66%] [G loss: 0.791011]\n",
      "epoch:48 step:38189[D loss: 0.397378, acc: 66.41%, op_acc: 42.19%] [G loss: 1.084330]\n",
      "epoch:48 step:38190[D loss: 0.400241, acc: 67.97%, op_acc: 45.31%] [G loss: 0.657305]\n",
      "epoch:48 step:38191[D loss: 0.390486, acc: 64.84%, op_acc: 43.75%] [G loss: 1.035135]\n",
      "epoch:48 step:38192[D loss: 0.351490, acc: 72.66%, op_acc: 49.22%] [G loss: 0.707868]\n",
      "epoch:48 step:38193[D loss: 0.360116, acc: 73.44%, op_acc: 47.66%] [G loss: 1.122547]\n",
      "epoch:48 step:38194[D loss: 0.403764, acc: 60.94%, op_acc: 45.31%] [G loss: 0.909102]\n",
      "epoch:48 step:38195[D loss: 0.405560, acc: 66.41%, op_acc: 42.19%] [G loss: 0.764333]\n",
      "epoch:48 step:38196[D loss: 0.394548, acc: 65.62%, op_acc: 41.41%] [G loss: 0.814582]\n",
      "epoch:48 step:38197[D loss: 0.326817, acc: 73.44%, op_acc: 57.81%] [G loss: 0.860775]\n",
      "epoch:48 step:38198[D loss: 0.393082, acc: 58.59%, op_acc: 47.66%] [G loss: 1.179329]\n",
      "epoch:48 step:38199[D loss: 0.389398, acc: 67.97%, op_acc: 50.00%] [G loss: 0.941658]\n",
      "epoch:48 step:38200[D loss: 0.375405, acc: 69.53%, op_acc: 42.19%] [G loss: 0.691565]\n",
      "##############\n",
      "[0.8456983  0.84296473 0.81658071 0.82738957 0.80539284 0.83160109\n",
      " 0.88423706 0.84323315 0.78352588 0.83817301]\n",
      "##########\n",
      "epoch:48 step:38201[D loss: 0.369876, acc: 68.75%, op_acc: 49.22%] [G loss: 1.166947]\n",
      "epoch:48 step:38202[D loss: 0.454967, acc: 57.81%, op_acc: 35.94%] [G loss: 0.811553]\n",
      "epoch:48 step:38203[D loss: 0.418495, acc: 62.50%, op_acc: 42.19%] [G loss: 0.696722]\n",
      "epoch:48 step:38204[D loss: 0.364450, acc: 67.19%, op_acc: 49.22%] [G loss: 1.041897]\n",
      "epoch:48 step:38205[D loss: 0.360730, acc: 68.75%, op_acc: 47.66%] [G loss: 0.844794]\n",
      "epoch:48 step:38206[D loss: 0.392786, acc: 65.62%, op_acc: 45.31%] [G loss: 1.376919]\n",
      "epoch:48 step:38207[D loss: 0.393786, acc: 70.31%, op_acc: 48.44%] [G loss: 0.843063]\n",
      "epoch:48 step:38208[D loss: 0.407282, acc: 62.50%, op_acc: 42.97%] [G loss: 1.124297]\n",
      "epoch:48 step:38209[D loss: 0.382191, acc: 69.53%, op_acc: 42.19%] [G loss: 0.758706]\n",
      "epoch:48 step:38210[D loss: 0.371920, acc: 62.50%, op_acc: 46.09%] [G loss: 0.825234]\n",
      "epoch:48 step:38211[D loss: 0.357610, acc: 71.88%, op_acc: 50.00%] [G loss: 0.731660]\n",
      "epoch:48 step:38212[D loss: 0.395470, acc: 67.19%, op_acc: 47.66%] [G loss: 1.156524]\n",
      "epoch:48 step:38213[D loss: 0.398914, acc: 65.62%, op_acc: 49.22%] [G loss: 1.076211]\n",
      "epoch:48 step:38214[D loss: 0.408317, acc: 62.50%, op_acc: 47.66%] [G loss: 0.788699]\n",
      "epoch:48 step:38215[D loss: 0.375736, acc: 71.88%, op_acc: 46.88%] [G loss: 1.046719]\n",
      "epoch:48 step:38216[D loss: 0.390798, acc: 72.66%, op_acc: 42.97%] [G loss: 0.784716]\n",
      "epoch:48 step:38217[D loss: 0.353370, acc: 75.78%, op_acc: 51.56%] [G loss: 0.829808]\n",
      "epoch:48 step:38218[D loss: 0.344071, acc: 75.78%, op_acc: 53.12%] [G loss: 0.821547]\n",
      "epoch:48 step:38219[D loss: 0.383800, acc: 63.28%, op_acc: 50.00%] [G loss: 0.804007]\n",
      "epoch:48 step:38220[D loss: 0.458421, acc: 53.91%, op_acc: 46.09%] [G loss: 0.898285]\n",
      "epoch:48 step:38221[D loss: 0.330000, acc: 78.91%, op_acc: 50.00%] [G loss: 1.047843]\n",
      "epoch:48 step:38222[D loss: 0.401057, acc: 64.84%, op_acc: 42.97%] [G loss: 1.244985]\n",
      "epoch:48 step:38223[D loss: 0.390542, acc: 64.84%, op_acc: 42.19%] [G loss: 0.980258]\n",
      "epoch:48 step:38224[D loss: 0.347072, acc: 75.78%, op_acc: 51.56%] [G loss: 0.946982]\n",
      "epoch:48 step:38225[D loss: 0.359582, acc: 60.16%, op_acc: 53.91%] [G loss: 0.853009]\n",
      "epoch:48 step:38226[D loss: 0.380618, acc: 66.41%, op_acc: 45.31%] [G loss: 0.832874]\n",
      "epoch:48 step:38227[D loss: 0.425241, acc: 61.72%, op_acc: 40.62%] [G loss: 1.010781]\n",
      "epoch:48 step:38228[D loss: 0.361412, acc: 69.53%, op_acc: 56.25%] [G loss: 0.936310]\n",
      "epoch:48 step:38229[D loss: 0.369203, acc: 68.75%, op_acc: 50.78%] [G loss: 0.860026]\n",
      "epoch:48 step:38230[D loss: 0.389698, acc: 66.41%, op_acc: 43.75%] [G loss: 0.758479]\n",
      "epoch:48 step:38231[D loss: 0.400592, acc: 67.19%, op_acc: 45.31%] [G loss: 1.066483]\n",
      "epoch:48 step:38232[D loss: 0.386735, acc: 60.94%, op_acc: 49.22%] [G loss: 0.783826]\n",
      "epoch:48 step:38233[D loss: 0.393538, acc: 67.19%, op_acc: 48.44%] [G loss: 0.716514]\n",
      "epoch:48 step:38234[D loss: 0.330307, acc: 77.34%, op_acc: 54.69%] [G loss: 0.953822]\n",
      "epoch:48 step:38235[D loss: 0.367094, acc: 68.75%, op_acc: 46.88%] [G loss: 0.877239]\n",
      "epoch:48 step:38236[D loss: 0.371342, acc: 72.66%, op_acc: 36.72%] [G loss: 1.255440]\n",
      "epoch:48 step:38237[D loss: 0.349950, acc: 77.34%, op_acc: 48.44%] [G loss: 0.769921]\n",
      "epoch:48 step:38238[D loss: 0.415191, acc: 60.16%, op_acc: 45.31%] [G loss: 0.849225]\n",
      "epoch:48 step:38239[D loss: 0.376918, acc: 67.97%, op_acc: 43.75%] [G loss: 0.983861]\n",
      "epoch:48 step:38240[D loss: 0.341955, acc: 76.56%, op_acc: 47.66%] [G loss: 0.948567]\n",
      "epoch:48 step:38241[D loss: 0.320546, acc: 81.25%, op_acc: 52.34%] [G loss: 1.104068]\n",
      "epoch:48 step:38242[D loss: 0.372708, acc: 67.19%, op_acc: 44.53%] [G loss: 0.909898]\n",
      "epoch:48 step:38243[D loss: 0.412249, acc: 58.59%, op_acc: 47.66%] [G loss: 1.049955]\n",
      "epoch:48 step:38244[D loss: 0.360350, acc: 68.75%, op_acc: 57.81%] [G loss: 0.932367]\n",
      "epoch:48 step:38245[D loss: 0.386924, acc: 67.19%, op_acc: 44.53%] [G loss: 1.037686]\n",
      "epoch:48 step:38246[D loss: 0.328492, acc: 72.66%, op_acc: 53.91%] [G loss: 0.953392]\n",
      "epoch:48 step:38247[D loss: 0.426716, acc: 63.28%, op_acc: 39.84%] [G loss: 0.863244]\n",
      "epoch:48 step:38248[D loss: 0.348631, acc: 72.66%, op_acc: 46.88%] [G loss: 1.283959]\n",
      "epoch:48 step:38249[D loss: 0.396862, acc: 60.94%, op_acc: 41.41%] [G loss: 1.087368]\n",
      "epoch:48 step:38250[D loss: 0.459145, acc: 51.56%, op_acc: 44.53%] [G loss: 0.834058]\n",
      "##############\n",
      "[0.86335217 0.8636075  0.80835905 0.8138921  0.77895923 0.82433417\n",
      " 0.87235121 0.83625502 0.81972098 0.800731  ]\n",
      "##########\n",
      "epoch:48 step:38251[D loss: 0.380187, acc: 67.19%, op_acc: 45.31%] [G loss: 0.903698]\n",
      "epoch:48 step:38252[D loss: 0.405656, acc: 60.16%, op_acc: 53.12%] [G loss: 1.347960]\n",
      "epoch:48 step:38253[D loss: 0.394791, acc: 64.84%, op_acc: 50.00%] [G loss: 1.025541]\n",
      "epoch:48 step:38254[D loss: 0.396606, acc: 66.41%, op_acc: 45.31%] [G loss: 1.002078]\n",
      "epoch:48 step:38255[D loss: 0.372170, acc: 63.28%, op_acc: 52.34%] [G loss: 1.080879]\n",
      "epoch:48 step:38256[D loss: 0.382112, acc: 64.84%, op_acc: 46.88%] [G loss: 1.018044]\n",
      "epoch:48 step:38257[D loss: 0.342911, acc: 71.88%, op_acc: 46.88%] [G loss: 0.818103]\n",
      "epoch:48 step:38258[D loss: 0.354652, acc: 70.31%, op_acc: 52.34%] [G loss: 0.978200]\n",
      "epoch:48 step:38259[D loss: 0.427642, acc: 66.41%, op_acc: 39.84%] [G loss: 0.870425]\n",
      "epoch:48 step:38260[D loss: 0.421511, acc: 64.84%, op_acc: 41.41%] [G loss: 0.952358]\n",
      "epoch:48 step:38261[D loss: 0.415984, acc: 58.59%, op_acc: 44.53%] [G loss: 1.020829]\n",
      "epoch:48 step:38262[D loss: 0.342818, acc: 77.34%, op_acc: 53.12%] [G loss: 0.930076]\n",
      "epoch:48 step:38263[D loss: 0.384041, acc: 71.88%, op_acc: 39.84%] [G loss: 0.773917]\n",
      "epoch:48 step:38264[D loss: 0.395846, acc: 64.06%, op_acc: 49.22%] [G loss: 0.766513]\n",
      "epoch:48 step:38265[D loss: 0.389930, acc: 67.19%, op_acc: 41.41%] [G loss: 0.958872]\n",
      "epoch:48 step:38266[D loss: 0.328438, acc: 73.44%, op_acc: 50.00%] [G loss: 0.938683]\n",
      "epoch:48 step:38267[D loss: 0.368931, acc: 68.75%, op_acc: 44.53%] [G loss: 0.961836]\n",
      "epoch:48 step:38268[D loss: 0.402031, acc: 67.19%, op_acc: 39.06%] [G loss: 0.788778]\n",
      "epoch:48 step:38269[D loss: 0.346225, acc: 74.22%, op_acc: 49.22%] [G loss: 0.860412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38270[D loss: 0.356717, acc: 71.88%, op_acc: 46.09%] [G loss: 0.794201]\n",
      "epoch:49 step:38271[D loss: 0.374022, acc: 64.06%, op_acc: 52.34%] [G loss: 0.751552]\n",
      "epoch:49 step:38272[D loss: 0.402083, acc: 69.53%, op_acc: 40.62%] [G loss: 0.952584]\n",
      "epoch:49 step:38273[D loss: 0.398131, acc: 64.06%, op_acc: 50.00%] [G loss: 1.050630]\n",
      "epoch:49 step:38274[D loss: 0.382579, acc: 68.75%, op_acc: 50.78%] [G loss: 1.241293]\n",
      "epoch:49 step:38275[D loss: 0.361605, acc: 72.66%, op_acc: 47.66%] [G loss: 0.974067]\n",
      "epoch:49 step:38276[D loss: 0.334050, acc: 75.78%, op_acc: 47.66%] [G loss: 1.088654]\n",
      "epoch:49 step:38277[D loss: 0.393327, acc: 68.75%, op_acc: 44.53%] [G loss: 1.128130]\n",
      "epoch:49 step:38278[D loss: 0.399259, acc: 60.94%, op_acc: 44.53%] [G loss: 0.942522]\n",
      "epoch:49 step:38279[D loss: 0.418629, acc: 62.50%, op_acc: 39.84%] [G loss: 0.821681]\n",
      "epoch:49 step:38280[D loss: 0.485259, acc: 54.69%, op_acc: 38.28%] [G loss: 1.046839]\n",
      "epoch:49 step:38281[D loss: 0.394095, acc: 67.19%, op_acc: 39.84%] [G loss: 1.061754]\n",
      "epoch:49 step:38282[D loss: 0.350091, acc: 74.22%, op_acc: 45.31%] [G loss: 1.052700]\n",
      "epoch:49 step:38283[D loss: 0.413638, acc: 69.53%, op_acc: 45.31%] [G loss: 0.942387]\n",
      "epoch:49 step:38284[D loss: 0.427441, acc: 58.59%, op_acc: 40.62%] [G loss: 0.917836]\n",
      "epoch:49 step:38285[D loss: 0.386719, acc: 64.06%, op_acc: 46.88%] [G loss: 0.997045]\n",
      "epoch:49 step:38286[D loss: 0.370133, acc: 72.66%, op_acc: 42.97%] [G loss: 0.991453]\n",
      "epoch:49 step:38287[D loss: 0.328535, acc: 75.78%, op_acc: 45.31%] [G loss: 0.964294]\n",
      "epoch:49 step:38288[D loss: 0.326309, acc: 75.00%, op_acc: 50.00%] [G loss: 0.975766]\n",
      "epoch:49 step:38289[D loss: 0.322213, acc: 78.91%, op_acc: 48.44%] [G loss: 0.840794]\n",
      "epoch:49 step:38290[D loss: 0.361805, acc: 75.00%, op_acc: 42.97%] [G loss: 1.105594]\n",
      "epoch:49 step:38291[D loss: 0.349890, acc: 75.00%, op_acc: 46.88%] [G loss: 1.038331]\n",
      "epoch:49 step:38292[D loss: 0.303069, acc: 82.03%, op_acc: 49.22%] [G loss: 1.037933]\n",
      "epoch:49 step:38293[D loss: 0.324484, acc: 77.34%, op_acc: 47.66%] [G loss: 1.145887]\n",
      "epoch:49 step:38294[D loss: 0.408449, acc: 65.62%, op_acc: 45.31%] [G loss: 1.006546]\n",
      "epoch:49 step:38295[D loss: 0.312595, acc: 84.38%, op_acc: 53.91%] [G loss: 1.177741]\n",
      "epoch:49 step:38296[D loss: 0.318471, acc: 84.38%, op_acc: 50.00%] [G loss: 1.362893]\n",
      "epoch:49 step:38297[D loss: 0.307792, acc: 78.12%, op_acc: 56.25%] [G loss: 1.122814]\n",
      "epoch:49 step:38298[D loss: 0.273585, acc: 85.16%, op_acc: 54.69%] [G loss: 1.327362]\n",
      "epoch:49 step:38299[D loss: 0.315840, acc: 78.12%, op_acc: 50.00%] [G loss: 1.327606]\n",
      "epoch:49 step:38300[D loss: 0.357288, acc: 76.56%, op_acc: 44.53%] [G loss: 0.575240]\n",
      "##############\n",
      "[0.86565617 0.87797688 0.8134446  0.81103526 0.81141164 0.82669257\n",
      " 0.87228276 0.8234506  0.79219071 0.83593728]\n",
      "##########\n",
      "epoch:49 step:38301[D loss: 0.472136, acc: 55.47%, op_acc: 43.75%] [G loss: 0.691982]\n",
      "epoch:49 step:38302[D loss: 0.435939, acc: 56.25%, op_acc: 48.44%] [G loss: 1.247401]\n",
      "epoch:49 step:38303[D loss: 0.400868, acc: 59.38%, op_acc: 46.09%] [G loss: 1.773031]\n",
      "epoch:49 step:38304[D loss: 0.468130, acc: 53.91%, op_acc: 41.41%] [G loss: 1.563761]\n",
      "epoch:49 step:38305[D loss: 0.414630, acc: 57.03%, op_acc: 45.31%] [G loss: 1.296434]\n",
      "epoch:49 step:38306[D loss: 0.397302, acc: 63.28%, op_acc: 46.88%] [G loss: 1.337993]\n",
      "epoch:49 step:38307[D loss: 0.379424, acc: 68.75%, op_acc: 47.66%] [G loss: 1.431832]\n",
      "epoch:49 step:38308[D loss: 0.465374, acc: 56.25%, op_acc: 45.31%] [G loss: 1.278608]\n",
      "epoch:49 step:38309[D loss: 0.357373, acc: 68.75%, op_acc: 41.41%] [G loss: 1.244008]\n",
      "epoch:49 step:38310[D loss: 0.314386, acc: 76.56%, op_acc: 53.12%] [G loss: 0.891620]\n",
      "epoch:49 step:38311[D loss: 0.398115, acc: 57.81%, op_acc: 53.12%] [G loss: 0.924802]\n",
      "epoch:49 step:38312[D loss: 0.440805, acc: 53.91%, op_acc: 42.19%] [G loss: 1.078403]\n",
      "epoch:49 step:38313[D loss: 0.409073, acc: 61.72%, op_acc: 49.22%] [G loss: 1.160005]\n",
      "epoch:49 step:38314[D loss: 0.413788, acc: 61.72%, op_acc: 47.66%] [G loss: 0.947064]\n",
      "epoch:49 step:38315[D loss: 0.411331, acc: 64.84%, op_acc: 46.88%] [G loss: 1.175946]\n",
      "epoch:49 step:38316[D loss: 0.367167, acc: 72.66%, op_acc: 47.66%] [G loss: 1.099616]\n",
      "epoch:49 step:38317[D loss: 0.378620, acc: 75.78%, op_acc: 38.28%] [G loss: 1.150994]\n",
      "epoch:49 step:38318[D loss: 0.333011, acc: 73.44%, op_acc: 55.47%] [G loss: 1.082164]\n",
      "epoch:49 step:38319[D loss: 0.380608, acc: 65.62%, op_acc: 53.12%] [G loss: 0.816975]\n",
      "epoch:49 step:38320[D loss: 0.365440, acc: 75.78%, op_acc: 42.19%] [G loss: 0.884735]\n",
      "epoch:49 step:38321[D loss: 0.428360, acc: 58.59%, op_acc: 42.19%] [G loss: 0.883661]\n",
      "epoch:49 step:38322[D loss: 0.431211, acc: 66.41%, op_acc: 39.06%] [G loss: 1.202470]\n",
      "epoch:49 step:38323[D loss: 0.378827, acc: 71.88%, op_acc: 46.09%] [G loss: 0.968880]\n",
      "epoch:49 step:38324[D loss: 0.328933, acc: 75.00%, op_acc: 50.78%] [G loss: 0.975862]\n",
      "epoch:49 step:38325[D loss: 0.364850, acc: 67.19%, op_acc: 49.22%] [G loss: 1.032632]\n",
      "epoch:49 step:38326[D loss: 0.367638, acc: 62.50%, op_acc: 45.31%] [G loss: 0.987187]\n",
      "epoch:49 step:38327[D loss: 0.353161, acc: 71.88%, op_acc: 51.56%] [G loss: 1.255755]\n",
      "epoch:49 step:38328[D loss: 0.372291, acc: 66.41%, op_acc: 48.44%] [G loss: 0.775850]\n",
      "epoch:49 step:38329[D loss: 0.365540, acc: 70.31%, op_acc: 50.00%] [G loss: 0.938429]\n",
      "epoch:49 step:38330[D loss: 0.405751, acc: 65.62%, op_acc: 37.50%] [G loss: 1.308729]\n",
      "epoch:49 step:38331[D loss: 0.416769, acc: 67.19%, op_acc: 42.19%] [G loss: 0.828668]\n",
      "epoch:49 step:38332[D loss: 0.395133, acc: 66.41%, op_acc: 46.09%] [G loss: 0.912922]\n",
      "epoch:49 step:38333[D loss: 0.387030, acc: 67.97%, op_acc: 39.84%] [G loss: 0.947729]\n",
      "epoch:49 step:38334[D loss: 0.417898, acc: 68.75%, op_acc: 39.84%] [G loss: 0.790936]\n",
      "epoch:49 step:38335[D loss: 0.420163, acc: 56.25%, op_acc: 51.56%] [G loss: 1.146738]\n",
      "epoch:49 step:38336[D loss: 0.352757, acc: 75.78%, op_acc: 42.19%] [G loss: 1.158385]\n",
      "epoch:49 step:38337[D loss: 0.403344, acc: 63.28%, op_acc: 44.53%] [G loss: 0.773571]\n",
      "epoch:49 step:38338[D loss: 0.330638, acc: 75.78%, op_acc: 49.22%] [G loss: 1.059870]\n",
      "epoch:49 step:38339[D loss: 0.438022, acc: 64.06%, op_acc: 41.41%] [G loss: 0.836163]\n",
      "epoch:49 step:38340[D loss: 0.426819, acc: 57.81%, op_acc: 44.53%] [G loss: 0.873930]\n",
      "epoch:49 step:38341[D loss: 0.373333, acc: 67.19%, op_acc: 41.41%] [G loss: 0.860185]\n",
      "epoch:49 step:38342[D loss: 0.355224, acc: 71.09%, op_acc: 53.12%] [G loss: 0.772038]\n",
      "epoch:49 step:38343[D loss: 0.347909, acc: 64.06%, op_acc: 47.66%] [G loss: 0.866756]\n",
      "epoch:49 step:38344[D loss: 0.386500, acc: 70.31%, op_acc: 37.50%] [G loss: 1.035700]\n",
      "epoch:49 step:38345[D loss: 0.376445, acc: 71.09%, op_acc: 50.00%] [G loss: 0.891859]\n",
      "epoch:49 step:38346[D loss: 0.381457, acc: 70.31%, op_acc: 40.62%] [G loss: 1.150542]\n",
      "epoch:49 step:38347[D loss: 0.401958, acc: 67.19%, op_acc: 42.97%] [G loss: 0.978444]\n",
      "epoch:49 step:38348[D loss: 0.336707, acc: 72.66%, op_acc: 43.75%] [G loss: 1.253443]\n",
      "epoch:49 step:38349[D loss: 0.405544, acc: 65.62%, op_acc: 39.06%] [G loss: 1.230320]\n",
      "epoch:49 step:38350[D loss: 0.438244, acc: 60.94%, op_acc: 39.06%] [G loss: 0.891115]\n",
      "##############\n",
      "[0.8652578  0.86378742 0.81934778 0.80834156 0.80842604 0.8249766\n",
      " 0.8731303  0.81129152 0.80870233 0.81637033]\n",
      "##########\n",
      "epoch:49 step:38351[D loss: 0.420469, acc: 64.06%, op_acc: 41.41%] [G loss: 1.124207]\n",
      "epoch:49 step:38352[D loss: 0.364605, acc: 72.66%, op_acc: 50.00%] [G loss: 1.095845]\n",
      "epoch:49 step:38353[D loss: 0.379765, acc: 67.19%, op_acc: 46.88%] [G loss: 0.954517]\n",
      "epoch:49 step:38354[D loss: 0.348074, acc: 71.09%, op_acc: 46.09%] [G loss: 0.881727]\n",
      "epoch:49 step:38355[D loss: 0.306759, acc: 78.91%, op_acc: 57.81%] [G loss: 0.830554]\n",
      "epoch:49 step:38356[D loss: 0.365911, acc: 71.88%, op_acc: 39.06%] [G loss: 0.881704]\n",
      "epoch:49 step:38357[D loss: 0.349019, acc: 74.22%, op_acc: 53.12%] [G loss: 1.024530]\n",
      "epoch:49 step:38358[D loss: 0.322065, acc: 78.12%, op_acc: 50.00%] [G loss: 0.843133]\n",
      "epoch:49 step:38359[D loss: 0.326164, acc: 76.56%, op_acc: 50.00%] [G loss: 1.185686]\n",
      "epoch:49 step:38360[D loss: 0.327905, acc: 77.34%, op_acc: 49.22%] [G loss: 1.150047]\n",
      "epoch:49 step:38361[D loss: 0.394623, acc: 70.31%, op_acc: 45.31%] [G loss: 0.712772]\n",
      "epoch:49 step:38362[D loss: 0.395994, acc: 58.59%, op_acc: 44.53%] [G loss: 0.895128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38363[D loss: 0.365435, acc: 69.53%, op_acc: 42.97%] [G loss: 1.139882]\n",
      "epoch:49 step:38364[D loss: 0.339233, acc: 72.66%, op_acc: 51.56%] [G loss: 1.449520]\n",
      "epoch:49 step:38365[D loss: 0.417458, acc: 61.72%, op_acc: 43.75%] [G loss: 1.189232]\n",
      "epoch:49 step:38366[D loss: 0.316922, acc: 78.12%, op_acc: 53.12%] [G loss: 1.090284]\n",
      "epoch:49 step:38367[D loss: 0.350389, acc: 71.88%, op_acc: 50.00%] [G loss: 1.035294]\n",
      "epoch:49 step:38368[D loss: 0.340834, acc: 71.88%, op_acc: 50.78%] [G loss: 1.165883]\n",
      "epoch:49 step:38369[D loss: 0.281918, acc: 82.81%, op_acc: 55.47%] [G loss: 1.171804]\n",
      "epoch:49 step:38370[D loss: 0.372416, acc: 69.53%, op_acc: 44.53%] [G loss: 0.907777]\n",
      "epoch:49 step:38371[D loss: 0.338915, acc: 76.56%, op_acc: 52.34%] [G loss: 1.069978]\n",
      "epoch:49 step:38372[D loss: 0.359955, acc: 67.19%, op_acc: 47.66%] [G loss: 1.329834]\n",
      "epoch:49 step:38373[D loss: 0.328007, acc: 71.09%, op_acc: 51.56%] [G loss: 1.156102]\n",
      "epoch:49 step:38374[D loss: 0.351129, acc: 75.00%, op_acc: 42.19%] [G loss: 1.263073]\n",
      "epoch:49 step:38375[D loss: 0.357592, acc: 74.22%, op_acc: 45.31%] [G loss: 1.197554]\n",
      "epoch:49 step:38376[D loss: 0.312168, acc: 81.25%, op_acc: 51.56%] [G loss: 1.223407]\n",
      "epoch:49 step:38377[D loss: 0.329783, acc: 80.47%, op_acc: 47.66%] [G loss: 1.523415]\n",
      "epoch:49 step:38378[D loss: 0.321271, acc: 76.56%, op_acc: 44.53%] [G loss: 0.624509]\n",
      "epoch:49 step:38379[D loss: 0.293168, acc: 84.38%, op_acc: 54.69%] [G loss: 0.850488]\n",
      "epoch:49 step:38380[D loss: 0.395080, acc: 67.19%, op_acc: 35.94%] [G loss: 0.931837]\n",
      "epoch:49 step:38381[D loss: 0.433284, acc: 57.03%, op_acc: 49.22%] [G loss: 1.387576]\n",
      "epoch:49 step:38382[D loss: 0.429767, acc: 59.38%, op_acc: 35.94%] [G loss: 1.497875]\n",
      "epoch:49 step:38383[D loss: 0.345963, acc: 71.88%, op_acc: 49.22%] [G loss: 1.456143]\n",
      "epoch:49 step:38384[D loss: 0.363895, acc: 63.28%, op_acc: 50.78%] [G loss: 0.891545]\n",
      "epoch:49 step:38385[D loss: 0.477200, acc: 51.56%, op_acc: 37.50%] [G loss: 1.330150]\n",
      "epoch:49 step:38386[D loss: 0.399481, acc: 62.50%, op_acc: 44.53%] [G loss: 1.445730]\n",
      "epoch:49 step:38387[D loss: 0.384457, acc: 65.62%, op_acc: 46.09%] [G loss: 1.236178]\n",
      "epoch:49 step:38388[D loss: 0.357465, acc: 68.75%, op_acc: 54.69%] [G loss: 1.239627]\n",
      "epoch:49 step:38389[D loss: 0.425419, acc: 59.38%, op_acc: 45.31%] [G loss: 0.892289]\n",
      "epoch:49 step:38390[D loss: 0.385391, acc: 67.19%, op_acc: 46.09%] [G loss: 1.122522]\n",
      "epoch:49 step:38391[D loss: 0.411314, acc: 64.84%, op_acc: 45.31%] [G loss: 1.039432]\n",
      "epoch:49 step:38392[D loss: 0.433441, acc: 59.38%, op_acc: 34.38%] [G loss: 1.169841]\n",
      "epoch:49 step:38393[D loss: 0.424052, acc: 58.59%, op_acc: 42.97%] [G loss: 1.099378]\n",
      "epoch:49 step:38394[D loss: 0.469441, acc: 59.38%, op_acc: 40.62%] [G loss: 1.128580]\n",
      "epoch:49 step:38395[D loss: 0.367771, acc: 69.53%, op_acc: 49.22%] [G loss: 1.253696]\n",
      "epoch:49 step:38396[D loss: 0.388229, acc: 75.00%, op_acc: 46.09%] [G loss: 0.917675]\n",
      "epoch:49 step:38397[D loss: 0.362860, acc: 69.53%, op_acc: 40.62%] [G loss: 1.170429]\n",
      "epoch:49 step:38398[D loss: 0.335351, acc: 75.00%, op_acc: 49.22%] [G loss: 0.966974]\n",
      "epoch:49 step:38399[D loss: 0.311723, acc: 81.25%, op_acc: 53.91%] [G loss: 1.102469]\n",
      "epoch:49 step:38400[D loss: 0.381604, acc: 67.97%, op_acc: 42.19%] [G loss: 1.190008]\n",
      "##############\n",
      "[0.85411179 0.87190942 0.80532986 0.79445439 0.80333451 0.81129459\n",
      " 0.88366958 0.81875578 0.77814977 0.81960552]\n",
      "##########\n",
      "epoch:49 step:38401[D loss: 0.307537, acc: 78.91%, op_acc: 50.00%] [G loss: 0.867785]\n",
      "epoch:49 step:38402[D loss: 0.383612, acc: 71.09%, op_acc: 45.31%] [G loss: 0.983218]\n",
      "epoch:49 step:38403[D loss: 0.344790, acc: 72.66%, op_acc: 42.19%] [G loss: 0.814527]\n",
      "epoch:49 step:38404[D loss: 0.395170, acc: 67.19%, op_acc: 50.78%] [G loss: 0.995757]\n",
      "epoch:49 step:38405[D loss: 0.303949, acc: 79.69%, op_acc: 50.78%] [G loss: 1.228509]\n",
      "epoch:49 step:38406[D loss: 0.357602, acc: 75.00%, op_acc: 45.31%] [G loss: 0.907988]\n",
      "epoch:49 step:38407[D loss: 0.301530, acc: 77.34%, op_acc: 57.03%] [G loss: 1.031922]\n",
      "epoch:49 step:38408[D loss: 0.308446, acc: 79.69%, op_acc: 53.91%] [G loss: 0.777602]\n",
      "epoch:49 step:38409[D loss: 0.421269, acc: 60.94%, op_acc: 39.84%] [G loss: 0.911280]\n",
      "epoch:49 step:38410[D loss: 0.334248, acc: 78.91%, op_acc: 41.41%] [G loss: 0.832001]\n",
      "epoch:49 step:38411[D loss: 0.329517, acc: 75.00%, op_acc: 46.88%] [G loss: 0.781188]\n",
      "epoch:49 step:38412[D loss: 0.347505, acc: 71.09%, op_acc: 50.00%] [G loss: 1.010596]\n",
      "epoch:49 step:38413[D loss: 0.344607, acc: 75.78%, op_acc: 50.00%] [G loss: 0.997789]\n",
      "epoch:49 step:38414[D loss: 0.308325, acc: 80.47%, op_acc: 53.12%] [G loss: 1.249194]\n",
      "epoch:49 step:38415[D loss: 0.283905, acc: 82.81%, op_acc: 52.34%] [G loss: 0.952520]\n",
      "epoch:49 step:38416[D loss: 0.345075, acc: 75.00%, op_acc: 49.22%] [G loss: 0.705341]\n",
      "epoch:49 step:38417[D loss: 0.400280, acc: 61.72%, op_acc: 39.84%] [G loss: 0.756130]\n",
      "epoch:49 step:38418[D loss: 0.378534, acc: 61.72%, op_acc: 43.75%] [G loss: 1.026944]\n",
      "epoch:49 step:38419[D loss: 0.439396, acc: 56.25%, op_acc: 42.97%] [G loss: 1.033150]\n",
      "epoch:49 step:38420[D loss: 0.394264, acc: 65.62%, op_acc: 45.31%] [G loss: 1.280618]\n",
      "epoch:49 step:38421[D loss: 0.373233, acc: 68.75%, op_acc: 51.56%] [G loss: 1.200272]\n",
      "epoch:49 step:38422[D loss: 0.357258, acc: 70.31%, op_acc: 46.88%] [G loss: 0.997139]\n",
      "epoch:49 step:38423[D loss: 0.397364, acc: 61.72%, op_acc: 42.97%] [G loss: 0.988602]\n",
      "epoch:49 step:38424[D loss: 0.411733, acc: 58.59%, op_acc: 42.97%] [G loss: 0.993564]\n",
      "epoch:49 step:38425[D loss: 0.418437, acc: 65.62%, op_acc: 42.19%] [G loss: 0.872425]\n",
      "epoch:49 step:38426[D loss: 0.389679, acc: 63.28%, op_acc: 44.53%] [G loss: 1.030331]\n",
      "epoch:49 step:38427[D loss: 0.344179, acc: 76.56%, op_acc: 47.66%] [G loss: 1.090919]\n",
      "epoch:49 step:38428[D loss: 0.371240, acc: 70.31%, op_acc: 44.53%] [G loss: 1.192719]\n",
      "epoch:49 step:38429[D loss: 0.381036, acc: 67.19%, op_acc: 45.31%] [G loss: 1.017597]\n",
      "epoch:49 step:38430[D loss: 0.362921, acc: 69.53%, op_acc: 46.09%] [G loss: 0.895959]\n",
      "epoch:49 step:38431[D loss: 0.374627, acc: 63.28%, op_acc: 45.31%] [G loss: 0.885188]\n",
      "epoch:49 step:38432[D loss: 0.355082, acc: 71.09%, op_acc: 51.56%] [G loss: 0.944853]\n",
      "epoch:49 step:38433[D loss: 0.399666, acc: 71.88%, op_acc: 45.31%] [G loss: 0.910025]\n",
      "epoch:49 step:38434[D loss: 0.354366, acc: 69.53%, op_acc: 45.31%] [G loss: 0.993729]\n",
      "epoch:49 step:38435[D loss: 0.443071, acc: 60.16%, op_acc: 42.19%] [G loss: 0.893163]\n",
      "epoch:49 step:38436[D loss: 0.384479, acc: 67.19%, op_acc: 44.53%] [G loss: 0.822676]\n",
      "epoch:49 step:38437[D loss: 0.413805, acc: 61.72%, op_acc: 48.44%] [G loss: 1.072599]\n",
      "epoch:49 step:38438[D loss: 0.402457, acc: 64.06%, op_acc: 48.44%] [G loss: 1.029046]\n",
      "epoch:49 step:38439[D loss: 0.391699, acc: 68.75%, op_acc: 42.19%] [G loss: 1.151103]\n",
      "epoch:49 step:38440[D loss: 0.402783, acc: 64.06%, op_acc: 42.97%] [G loss: 0.946954]\n",
      "epoch:49 step:38441[D loss: 0.330312, acc: 77.34%, op_acc: 47.66%] [G loss: 1.150137]\n",
      "epoch:49 step:38442[D loss: 0.377047, acc: 65.62%, op_acc: 40.62%] [G loss: 0.853126]\n",
      "epoch:49 step:38443[D loss: 0.435673, acc: 61.72%, op_acc: 39.84%] [G loss: 0.929592]\n",
      "epoch:49 step:38444[D loss: 0.342148, acc: 77.34%, op_acc: 48.44%] [G loss: 0.866120]\n",
      "epoch:49 step:38445[D loss: 0.360901, acc: 69.53%, op_acc: 53.12%] [G loss: 0.928761]\n",
      "epoch:49 step:38446[D loss: 0.363560, acc: 75.00%, op_acc: 48.44%] [G loss: 1.287473]\n",
      "epoch:49 step:38447[D loss: 0.410847, acc: 65.62%, op_acc: 47.66%] [G loss: 0.836159]\n",
      "epoch:49 step:38448[D loss: 0.316037, acc: 78.12%, op_acc: 57.03%] [G loss: 0.751370]\n",
      "epoch:49 step:38449[D loss: 0.333806, acc: 72.66%, op_acc: 57.81%] [G loss: 1.221275]\n",
      "epoch:49 step:38450[D loss: 0.349422, acc: 70.31%, op_acc: 53.91%] [G loss: 1.276011]\n",
      "##############\n",
      "[0.86214199 0.8468449  0.81445396 0.79425794 0.80170151 0.82051621\n",
      " 0.88187404 0.81798018 0.8114214  0.83267415]\n",
      "##########\n",
      "epoch:49 step:38451[D loss: 0.420456, acc: 64.06%, op_acc: 44.53%] [G loss: 0.662533]\n",
      "epoch:49 step:38452[D loss: 0.326780, acc: 75.78%, op_acc: 50.00%] [G loss: 0.860197]\n",
      "epoch:49 step:38453[D loss: 0.323543, acc: 76.56%, op_acc: 52.34%] [G loss: 0.670422]\n",
      "epoch:49 step:38454[D loss: 0.350730, acc: 72.66%, op_acc: 48.44%] [G loss: 1.193513]\n",
      "epoch:49 step:38455[D loss: 0.461861, acc: 56.25%, op_acc: 42.97%] [G loss: 1.067838]\n",
      "epoch:49 step:38456[D loss: 0.374081, acc: 67.97%, op_acc: 44.53%] [G loss: 0.814899]\n",
      "epoch:49 step:38457[D loss: 0.411789, acc: 59.38%, op_acc: 49.22%] [G loss: 0.800075]\n",
      "epoch:49 step:38458[D loss: 0.339340, acc: 71.88%, op_acc: 47.66%] [G loss: 0.696999]\n",
      "epoch:49 step:38459[D loss: 0.404746, acc: 63.28%, op_acc: 43.75%] [G loss: 0.832042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38460[D loss: 0.373322, acc: 66.41%, op_acc: 54.69%] [G loss: 0.720573]\n",
      "epoch:49 step:38461[D loss: 0.324243, acc: 77.34%, op_acc: 50.78%] [G loss: 0.807415]\n",
      "epoch:49 step:38462[D loss: 0.365795, acc: 71.09%, op_acc: 46.09%] [G loss: 0.747171]\n",
      "epoch:49 step:38463[D loss: 0.365134, acc: 67.19%, op_acc: 47.66%] [G loss: 1.326771]\n",
      "epoch:49 step:38464[D loss: 0.308487, acc: 80.47%, op_acc: 50.00%] [G loss: 1.124059]\n",
      "epoch:49 step:38465[D loss: 0.390770, acc: 67.19%, op_acc: 46.88%] [G loss: 0.850187]\n",
      "epoch:49 step:38466[D loss: 0.437665, acc: 54.69%, op_acc: 45.31%] [G loss: 0.918341]\n",
      "epoch:49 step:38467[D loss: 0.409484, acc: 60.94%, op_acc: 43.75%] [G loss: 1.306733]\n",
      "epoch:49 step:38468[D loss: 0.397977, acc: 63.28%, op_acc: 46.88%] [G loss: 0.962914]\n",
      "epoch:49 step:38469[D loss: 0.420504, acc: 61.72%, op_acc: 44.53%] [G loss: 0.789153]\n",
      "epoch:49 step:38470[D loss: 0.355382, acc: 68.75%, op_acc: 44.53%] [G loss: 0.885354]\n",
      "epoch:49 step:38471[D loss: 0.354455, acc: 74.22%, op_acc: 45.31%] [G loss: 1.161712]\n",
      "epoch:49 step:38472[D loss: 0.398900, acc: 65.62%, op_acc: 42.97%] [G loss: 0.891286]\n",
      "epoch:49 step:38473[D loss: 0.398791, acc: 67.97%, op_acc: 42.19%] [G loss: 1.138916]\n",
      "epoch:49 step:38474[D loss: 0.382940, acc: 70.31%, op_acc: 42.97%] [G loss: 0.836152]\n",
      "epoch:49 step:38475[D loss: 0.392943, acc: 68.75%, op_acc: 46.09%] [G loss: 0.765083]\n",
      "epoch:49 step:38476[D loss: 0.330078, acc: 72.66%, op_acc: 51.56%] [G loss: 1.227919]\n",
      "epoch:49 step:38477[D loss: 0.360806, acc: 74.22%, op_acc: 42.97%] [G loss: 0.632756]\n",
      "epoch:49 step:38478[D loss: 0.377799, acc: 64.06%, op_acc: 47.66%] [G loss: 1.079618]\n",
      "epoch:49 step:38479[D loss: 0.369734, acc: 72.66%, op_acc: 49.22%] [G loss: 0.632090]\n",
      "epoch:49 step:38480[D loss: 0.347580, acc: 71.09%, op_acc: 49.22%] [G loss: 1.444870]\n",
      "epoch:49 step:38481[D loss: 0.386033, acc: 70.31%, op_acc: 47.66%] [G loss: 1.277734]\n",
      "epoch:49 step:38482[D loss: 0.370447, acc: 70.31%, op_acc: 48.44%] [G loss: 0.715896]\n",
      "epoch:49 step:38483[D loss: 0.389860, acc: 71.09%, op_acc: 42.19%] [G loss: 0.794364]\n",
      "epoch:49 step:38484[D loss: 0.466011, acc: 57.81%, op_acc: 42.19%] [G loss: 1.124011]\n",
      "epoch:49 step:38485[D loss: 0.380608, acc: 70.31%, op_acc: 47.66%] [G loss: 0.810428]\n",
      "epoch:49 step:38486[D loss: 0.347784, acc: 77.34%, op_acc: 40.62%] [G loss: 0.667814]\n",
      "epoch:49 step:38487[D loss: 0.362650, acc: 71.88%, op_acc: 54.69%] [G loss: 0.671232]\n",
      "epoch:49 step:38488[D loss: 0.362201, acc: 71.88%, op_acc: 46.88%] [G loss: 0.779769]\n",
      "epoch:49 step:38489[D loss: 0.383206, acc: 73.44%, op_acc: 43.75%] [G loss: 0.680907]\n",
      "epoch:49 step:38490[D loss: 0.339320, acc: 73.44%, op_acc: 57.03%] [G loss: 0.658254]\n",
      "epoch:49 step:38491[D loss: 0.376979, acc: 78.91%, op_acc: 43.75%] [G loss: 0.916093]\n",
      "epoch:49 step:38492[D loss: 0.392963, acc: 62.50%, op_acc: 42.97%] [G loss: 1.142462]\n",
      "epoch:49 step:38493[D loss: 0.395298, acc: 68.75%, op_acc: 42.19%] [G loss: 0.813072]\n",
      "epoch:49 step:38494[D loss: 0.368912, acc: 71.88%, op_acc: 40.62%] [G loss: 0.850016]\n",
      "epoch:49 step:38495[D loss: 0.326214, acc: 79.69%, op_acc: 52.34%] [G loss: 0.764338]\n",
      "epoch:49 step:38496[D loss: 0.362894, acc: 69.53%, op_acc: 47.66%] [G loss: 0.857413]\n",
      "epoch:49 step:38497[D loss: 0.333110, acc: 75.00%, op_acc: 56.25%] [G loss: 0.878562]\n",
      "epoch:49 step:38498[D loss: 0.332604, acc: 76.56%, op_acc: 45.31%] [G loss: 0.732436]\n",
      "epoch:49 step:38499[D loss: 0.350111, acc: 75.00%, op_acc: 50.00%] [G loss: 1.068932]\n",
      "epoch:49 step:38500[D loss: 0.378906, acc: 65.62%, op_acc: 40.62%] [G loss: 0.994765]\n",
      "##############\n",
      "[0.85147843 0.83988626 0.83452018 0.81567222 0.78874724 0.82808232\n",
      " 0.88655148 0.81088063 0.79964566 0.83501821]\n",
      "##########\n",
      "epoch:49 step:38501[D loss: 0.350952, acc: 72.66%, op_acc: 45.31%] [G loss: 0.861340]\n",
      "epoch:49 step:38502[D loss: 0.354181, acc: 71.09%, op_acc: 46.09%] [G loss: 1.403612]\n",
      "epoch:49 step:38503[D loss: 0.396072, acc: 67.97%, op_acc: 45.31%] [G loss: 0.759697]\n",
      "epoch:49 step:38504[D loss: 0.344447, acc: 75.00%, op_acc: 50.00%] [G loss: 1.169652]\n",
      "epoch:49 step:38505[D loss: 0.345962, acc: 69.53%, op_acc: 51.56%] [G loss: 1.360787]\n",
      "epoch:49 step:38506[D loss: 0.328459, acc: 75.78%, op_acc: 44.53%] [G loss: 1.169912]\n",
      "epoch:49 step:38507[D loss: 0.394362, acc: 67.97%, op_acc: 44.53%] [G loss: 0.729868]\n",
      "epoch:49 step:38508[D loss: 0.379628, acc: 65.62%, op_acc: 47.66%] [G loss: 1.061434]\n",
      "epoch:49 step:38509[D loss: 0.418123, acc: 57.81%, op_acc: 42.19%] [G loss: 0.725625]\n",
      "epoch:49 step:38510[D loss: 0.354377, acc: 67.97%, op_acc: 49.22%] [G loss: 0.855688]\n",
      "epoch:49 step:38511[D loss: 0.341138, acc: 72.66%, op_acc: 53.91%] [G loss: 0.783710]\n",
      "epoch:49 step:38512[D loss: 0.419187, acc: 61.72%, op_acc: 50.00%] [G loss: 0.934965]\n",
      "epoch:49 step:38513[D loss: 0.400153, acc: 67.97%, op_acc: 46.09%] [G loss: 0.736475]\n",
      "epoch:49 step:38514[D loss: 0.369019, acc: 72.66%, op_acc: 50.00%] [G loss: 0.844481]\n",
      "epoch:49 step:38515[D loss: 0.385279, acc: 72.66%, op_acc: 42.97%] [G loss: 0.983335]\n",
      "epoch:49 step:38516[D loss: 0.356154, acc: 67.97%, op_acc: 47.66%] [G loss: 1.159998]\n",
      "epoch:49 step:38517[D loss: 0.416401, acc: 64.84%, op_acc: 39.06%] [G loss: 0.835689]\n",
      "epoch:49 step:38518[D loss: 0.394364, acc: 67.19%, op_acc: 42.19%] [G loss: 0.797502]\n",
      "epoch:49 step:38519[D loss: 0.373781, acc: 71.88%, op_acc: 46.88%] [G loss: 0.683294]\n",
      "epoch:49 step:38520[D loss: 0.380187, acc: 66.41%, op_acc: 50.00%] [G loss: 0.820550]\n",
      "epoch:49 step:38521[D loss: 0.326129, acc: 77.34%, op_acc: 53.12%] [G loss: 0.719210]\n",
      "epoch:49 step:38522[D loss: 0.380111, acc: 63.28%, op_acc: 47.66%] [G loss: 0.806225]\n",
      "epoch:49 step:38523[D loss: 0.385698, acc: 67.97%, op_acc: 43.75%] [G loss: 0.888168]\n",
      "epoch:49 step:38524[D loss: 0.338283, acc: 75.00%, op_acc: 51.56%] [G loss: 0.881612]\n",
      "epoch:49 step:38525[D loss: 0.381137, acc: 70.31%, op_acc: 48.44%] [G loss: 0.822671]\n",
      "epoch:49 step:38526[D loss: 0.428892, acc: 66.41%, op_acc: 42.97%] [G loss: 0.859602]\n",
      "epoch:49 step:38527[D loss: 0.293284, acc: 82.03%, op_acc: 57.81%] [G loss: 0.798573]\n",
      "epoch:49 step:38528[D loss: 0.338227, acc: 71.88%, op_acc: 44.53%] [G loss: 0.885323]\n",
      "epoch:49 step:38529[D loss: 0.378886, acc: 73.44%, op_acc: 42.97%] [G loss: 0.824709]\n",
      "epoch:49 step:38530[D loss: 0.295777, acc: 83.59%, op_acc: 49.22%] [G loss: 0.892309]\n",
      "epoch:49 step:38531[D loss: 0.331941, acc: 75.78%, op_acc: 43.75%] [G loss: 0.940285]\n",
      "epoch:49 step:38532[D loss: 0.312223, acc: 78.91%, op_acc: 46.88%] [G loss: 1.064806]\n",
      "epoch:49 step:38533[D loss: 0.293214, acc: 83.59%, op_acc: 50.78%] [G loss: 1.170266]\n",
      "epoch:49 step:38534[D loss: 0.349488, acc: 70.31%, op_acc: 42.97%] [G loss: 1.210397]\n",
      "epoch:49 step:38535[D loss: 0.349998, acc: 72.66%, op_acc: 51.56%] [G loss: 0.998353]\n",
      "epoch:49 step:38536[D loss: 0.475054, acc: 50.78%, op_acc: 35.94%] [G loss: 0.885621]\n",
      "epoch:49 step:38537[D loss: 0.395296, acc: 64.06%, op_acc: 50.00%] [G loss: 0.849475]\n",
      "epoch:49 step:38538[D loss: 0.381415, acc: 64.06%, op_acc: 51.56%] [G loss: 0.801498]\n",
      "epoch:49 step:38539[D loss: 0.382381, acc: 64.06%, op_acc: 49.22%] [G loss: 0.840999]\n",
      "epoch:49 step:38540[D loss: 0.396557, acc: 69.53%, op_acc: 42.19%] [G loss: 0.766673]\n",
      "epoch:49 step:38541[D loss: 0.342438, acc: 75.00%, op_acc: 43.75%] [G loss: 0.741775]\n",
      "epoch:49 step:38542[D loss: 0.347659, acc: 71.09%, op_acc: 53.91%] [G loss: 0.881910]\n",
      "epoch:49 step:38543[D loss: 0.366862, acc: 69.53%, op_acc: 46.88%] [G loss: 0.874133]\n",
      "epoch:49 step:38544[D loss: 0.315867, acc: 72.66%, op_acc: 51.56%] [G loss: 0.884053]\n",
      "epoch:49 step:38545[D loss: 0.337740, acc: 77.34%, op_acc: 51.56%] [G loss: 0.820945]\n",
      "epoch:49 step:38546[D loss: 0.381516, acc: 69.53%, op_acc: 41.41%] [G loss: 0.935341]\n",
      "epoch:49 step:38547[D loss: 0.339729, acc: 71.09%, op_acc: 52.34%] [G loss: 0.941756]\n",
      "epoch:49 step:38548[D loss: 0.377283, acc: 72.66%, op_acc: 47.66%] [G loss: 0.960221]\n",
      "epoch:49 step:38549[D loss: 0.346595, acc: 71.09%, op_acc: 50.78%] [G loss: 0.967593]\n",
      "epoch:49 step:38550[D loss: 0.373828, acc: 71.09%, op_acc: 44.53%] [G loss: 0.974285]\n",
      "##############\n",
      "[0.87796421 0.85922665 0.82341653 0.80290906 0.78604528 0.82839171\n",
      " 0.89600154 0.82919294 0.80485783 0.81749456]\n",
      "##########\n",
      "epoch:49 step:38551[D loss: 0.386613, acc: 67.97%, op_acc: 42.19%] [G loss: 1.069697]\n",
      "epoch:49 step:38552[D loss: 0.423433, acc: 62.50%, op_acc: 44.53%] [G loss: 1.319771]\n",
      "epoch:49 step:38553[D loss: 0.354510, acc: 71.09%, op_acc: 52.34%] [G loss: 0.978229]\n",
      "epoch:49 step:38554[D loss: 0.303308, acc: 79.69%, op_acc: 49.22%] [G loss: 1.142005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38555[D loss: 0.420409, acc: 67.97%, op_acc: 39.84%] [G loss: 1.203314]\n",
      "epoch:49 step:38556[D loss: 0.374193, acc: 72.66%, op_acc: 50.00%] [G loss: 1.093966]\n",
      "epoch:49 step:38557[D loss: 0.300044, acc: 78.91%, op_acc: 50.00%] [G loss: 1.356548]\n",
      "epoch:49 step:38558[D loss: 0.355850, acc: 72.66%, op_acc: 45.31%] [G loss: 0.880471]\n",
      "epoch:49 step:38559[D loss: 0.407522, acc: 65.62%, op_acc: 39.06%] [G loss: 1.093379]\n",
      "epoch:49 step:38560[D loss: 0.356312, acc: 75.00%, op_acc: 47.66%] [G loss: 1.135849]\n",
      "epoch:49 step:38561[D loss: 0.402351, acc: 64.84%, op_acc: 44.53%] [G loss: 1.007822]\n",
      "epoch:49 step:38562[D loss: 0.366232, acc: 71.88%, op_acc: 45.31%] [G loss: 0.957180]\n",
      "epoch:49 step:38563[D loss: 0.328186, acc: 76.56%, op_acc: 48.44%] [G loss: 1.099057]\n",
      "epoch:49 step:38564[D loss: 0.291835, acc: 80.47%, op_acc: 56.25%] [G loss: 1.073672]\n",
      "epoch:49 step:38565[D loss: 0.297208, acc: 77.34%, op_acc: 53.12%] [G loss: 1.315462]\n",
      "epoch:49 step:38566[D loss: 0.342215, acc: 78.12%, op_acc: 47.66%] [G loss: 1.235419]\n",
      "epoch:49 step:38567[D loss: 0.364738, acc: 75.78%, op_acc: 50.78%] [G loss: 0.826131]\n",
      "epoch:49 step:38568[D loss: 0.378159, acc: 68.75%, op_acc: 43.75%] [G loss: 1.048457]\n",
      "epoch:49 step:38569[D loss: 0.361958, acc: 73.44%, op_acc: 46.09%] [G loss: 1.174446]\n",
      "epoch:49 step:38570[D loss: 0.287298, acc: 82.03%, op_acc: 54.69%] [G loss: 1.184806]\n",
      "epoch:49 step:38571[D loss: 0.317720, acc: 75.78%, op_acc: 46.09%] [G loss: 1.139483]\n",
      "epoch:49 step:38572[D loss: 0.346773, acc: 74.22%, op_acc: 45.31%] [G loss: 1.264088]\n",
      "epoch:49 step:38573[D loss: 0.357780, acc: 73.44%, op_acc: 48.44%] [G loss: 1.017819]\n",
      "epoch:49 step:38574[D loss: 0.350555, acc: 64.84%, op_acc: 50.00%] [G loss: 1.093193]\n",
      "epoch:49 step:38575[D loss: 0.433892, acc: 60.16%, op_acc: 43.75%] [G loss: 1.053982]\n",
      "epoch:49 step:38576[D loss: 0.392264, acc: 63.28%, op_acc: 52.34%] [G loss: 1.082781]\n",
      "epoch:49 step:38577[D loss: 0.365675, acc: 71.88%, op_acc: 48.44%] [G loss: 0.898135]\n",
      "epoch:49 step:38578[D loss: 0.449681, acc: 62.50%, op_acc: 35.16%] [G loss: 0.967018]\n",
      "epoch:49 step:38579[D loss: 0.446531, acc: 59.38%, op_acc: 42.97%] [G loss: 0.883509]\n",
      "epoch:49 step:38580[D loss: 0.418204, acc: 68.75%, op_acc: 45.31%] [G loss: 1.119962]\n",
      "epoch:49 step:38581[D loss: 0.398638, acc: 70.31%, op_acc: 47.66%] [G loss: 1.228884]\n",
      "epoch:49 step:38582[D loss: 0.438982, acc: 58.59%, op_acc: 42.19%] [G loss: 1.005058]\n",
      "epoch:49 step:38583[D loss: 0.434369, acc: 64.06%, op_acc: 44.53%] [G loss: 0.877975]\n",
      "epoch:49 step:38584[D loss: 0.429998, acc: 64.06%, op_acc: 40.62%] [G loss: 1.097257]\n",
      "epoch:49 step:38585[D loss: 0.393940, acc: 59.38%, op_acc: 53.91%] [G loss: 1.113855]\n",
      "epoch:49 step:38586[D loss: 0.426953, acc: 59.38%, op_acc: 33.59%] [G loss: 1.055208]\n",
      "epoch:49 step:38587[D loss: 0.411677, acc: 67.97%, op_acc: 43.75%] [G loss: 1.035179]\n",
      "epoch:49 step:38588[D loss: 0.421631, acc: 60.16%, op_acc: 42.19%] [G loss: 1.240419]\n",
      "epoch:49 step:38589[D loss: 0.351685, acc: 67.97%, op_acc: 50.00%] [G loss: 0.931547]\n",
      "epoch:49 step:38590[D loss: 0.432316, acc: 65.62%, op_acc: 42.19%] [G loss: 0.956946]\n",
      "epoch:49 step:38591[D loss: 0.380742, acc: 69.53%, op_acc: 43.75%] [G loss: 1.133419]\n",
      "epoch:49 step:38592[D loss: 0.335521, acc: 75.78%, op_acc: 53.91%] [G loss: 1.014793]\n",
      "epoch:49 step:38593[D loss: 0.307542, acc: 81.25%, op_acc: 48.44%] [G loss: 0.975457]\n",
      "epoch:49 step:38594[D loss: 0.334431, acc: 77.34%, op_acc: 53.91%] [G loss: 0.984593]\n",
      "epoch:49 step:38595[D loss: 0.432945, acc: 59.38%, op_acc: 40.62%] [G loss: 1.072795]\n",
      "epoch:49 step:38596[D loss: 0.349320, acc: 74.22%, op_acc: 46.09%] [G loss: 0.984056]\n",
      "epoch:49 step:38597[D loss: 0.329915, acc: 70.31%, op_acc: 52.34%] [G loss: 1.143606]\n",
      "epoch:49 step:38598[D loss: 0.358816, acc: 78.12%, op_acc: 42.19%] [G loss: 0.809889]\n",
      "epoch:49 step:38599[D loss: 0.350561, acc: 67.19%, op_acc: 47.66%] [G loss: 0.836679]\n",
      "epoch:49 step:38600[D loss: 0.321996, acc: 80.47%, op_acc: 49.22%] [G loss: 0.907913]\n",
      "##############\n",
      "[0.85845792 0.86456278 0.79591887 0.80163649 0.7968963  0.8197303\n",
      " 0.92257803 0.81151694 0.82518462 0.85219384]\n",
      "##########\n",
      "epoch:49 step:38601[D loss: 0.371209, acc: 67.97%, op_acc: 46.09%] [G loss: 0.858796]\n",
      "epoch:49 step:38602[D loss: 0.354329, acc: 75.78%, op_acc: 48.44%] [G loss: 1.285907]\n",
      "epoch:49 step:38603[D loss: 0.337399, acc: 72.66%, op_acc: 57.81%] [G loss: 0.743344]\n",
      "epoch:49 step:38604[D loss: 0.331323, acc: 76.56%, op_acc: 48.44%] [G loss: 0.872141]\n",
      "epoch:49 step:38605[D loss: 0.299040, acc: 82.81%, op_acc: 51.56%] [G loss: 0.945953]\n",
      "epoch:49 step:38606[D loss: 0.347980, acc: 72.66%, op_acc: 46.88%] [G loss: 0.895610]\n",
      "epoch:49 step:38607[D loss: 0.326266, acc: 76.56%, op_acc: 55.47%] [G loss: 1.240079]\n",
      "epoch:49 step:38608[D loss: 0.358242, acc: 71.09%, op_acc: 47.66%] [G loss: 0.955742]\n",
      "epoch:49 step:38609[D loss: 0.374623, acc: 71.09%, op_acc: 41.41%] [G loss: 0.921918]\n",
      "epoch:49 step:38610[D loss: 0.326927, acc: 78.12%, op_acc: 50.00%] [G loss: 1.145622]\n",
      "epoch:49 step:38611[D loss: 0.315850, acc: 80.47%, op_acc: 46.88%] [G loss: 0.850208]\n",
      "epoch:49 step:38612[D loss: 0.400103, acc: 63.28%, op_acc: 41.41%] [G loss: 1.193046]\n",
      "epoch:49 step:38613[D loss: 0.306624, acc: 71.88%, op_acc: 53.91%] [G loss: 1.297155]\n",
      "epoch:49 step:38614[D loss: 0.312245, acc: 76.56%, op_acc: 57.03%] [G loss: 1.328035]\n",
      "epoch:49 step:38615[D loss: 0.308348, acc: 82.03%, op_acc: 49.22%] [G loss: 1.289420]\n",
      "epoch:49 step:38616[D loss: 0.285353, acc: 82.03%, op_acc: 63.28%] [G loss: 1.696509]\n",
      "epoch:49 step:38617[D loss: 0.240243, acc: 89.84%, op_acc: 59.38%] [G loss: 1.271349]\n",
      "epoch:49 step:38618[D loss: 0.292812, acc: 84.38%, op_acc: 58.59%] [G loss: 1.313078]\n",
      "epoch:49 step:38619[D loss: 0.395368, acc: 71.88%, op_acc: 46.09%] [G loss: 0.674632]\n",
      "epoch:49 step:38620[D loss: 0.394917, acc: 66.41%, op_acc: 47.66%] [G loss: 0.658290]\n",
      "epoch:49 step:38621[D loss: 0.473817, acc: 53.91%, op_acc: 38.28%] [G loss: 0.834371]\n",
      "epoch:49 step:38622[D loss: 0.384313, acc: 66.41%, op_acc: 47.66%] [G loss: 1.343514]\n",
      "epoch:49 step:38623[D loss: 0.413923, acc: 64.06%, op_acc: 50.00%] [G loss: 1.315425]\n",
      "epoch:49 step:38624[D loss: 0.393470, acc: 68.75%, op_acc: 48.44%] [G loss: 1.052763]\n",
      "epoch:49 step:38625[D loss: 0.418596, acc: 62.50%, op_acc: 41.41%] [G loss: 1.191428]\n",
      "epoch:49 step:38626[D loss: 0.421913, acc: 59.38%, op_acc: 40.62%] [G loss: 1.256199]\n",
      "epoch:49 step:38627[D loss: 0.469546, acc: 53.12%, op_acc: 35.94%] [G loss: 1.071247]\n",
      "epoch:49 step:38628[D loss: 0.444260, acc: 61.72%, op_acc: 41.41%] [G loss: 1.100579]\n",
      "epoch:49 step:38629[D loss: 0.411696, acc: 63.28%, op_acc: 44.53%] [G loss: 1.505136]\n",
      "epoch:49 step:38630[D loss: 0.372582, acc: 73.44%, op_acc: 46.88%] [G loss: 1.169571]\n",
      "epoch:49 step:38631[D loss: 0.367291, acc: 71.09%, op_acc: 46.88%] [G loss: 1.119447]\n",
      "epoch:49 step:38632[D loss: 0.439640, acc: 58.59%, op_acc: 42.19%] [G loss: 1.033474]\n",
      "epoch:49 step:38633[D loss: 0.390306, acc: 60.94%, op_acc: 49.22%] [G loss: 1.535738]\n",
      "epoch:49 step:38634[D loss: 0.383639, acc: 71.09%, op_acc: 50.78%] [G loss: 1.213239]\n",
      "epoch:49 step:38635[D loss: 0.391065, acc: 67.97%, op_acc: 49.22%] [G loss: 1.071236]\n",
      "epoch:49 step:38636[D loss: 0.331815, acc: 75.00%, op_acc: 51.56%] [G loss: 1.281280]\n",
      "epoch:49 step:38637[D loss: 0.399524, acc: 63.28%, op_acc: 43.75%] [G loss: 0.981116]\n",
      "epoch:49 step:38638[D loss: 0.418273, acc: 65.62%, op_acc: 47.66%] [G loss: 1.114647]\n",
      "epoch:49 step:38639[D loss: 0.393926, acc: 69.53%, op_acc: 43.75%] [G loss: 1.213361]\n",
      "epoch:49 step:38640[D loss: 0.342771, acc: 71.88%, op_acc: 46.88%] [G loss: 0.968287]\n",
      "epoch:49 step:38641[D loss: 0.360244, acc: 71.88%, op_acc: 43.75%] [G loss: 1.034012]\n",
      "epoch:49 step:38642[D loss: 0.408751, acc: 60.16%, op_acc: 50.00%] [G loss: 0.924986]\n",
      "epoch:49 step:38643[D loss: 0.369622, acc: 71.88%, op_acc: 50.00%] [G loss: 0.932963]\n",
      "epoch:49 step:38644[D loss: 0.348380, acc: 72.66%, op_acc: 42.97%] [G loss: 0.798010]\n",
      "epoch:49 step:38645[D loss: 0.329123, acc: 74.22%, op_acc: 47.66%] [G loss: 1.135686]\n",
      "epoch:49 step:38646[D loss: 0.360744, acc: 68.75%, op_acc: 41.41%] [G loss: 1.216217]\n",
      "epoch:49 step:38647[D loss: 0.362010, acc: 75.78%, op_acc: 41.41%] [G loss: 0.967911]\n",
      "epoch:49 step:38648[D loss: 0.371445, acc: 68.75%, op_acc: 48.44%] [G loss: 0.963009]\n",
      "epoch:49 step:38649[D loss: 0.343883, acc: 75.78%, op_acc: 46.09%] [G loss: 1.282149]\n",
      "epoch:49 step:38650[D loss: 0.336524, acc: 71.88%, op_acc: 54.69%] [G loss: 1.275838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.85714192 0.85295047 0.82035626 0.82188592 0.79645566 0.82681171\n",
      " 0.9050024  0.80289919 0.80533346 0.82630024]\n",
      "##########\n",
      "epoch:49 step:38651[D loss: 0.376485, acc: 71.09%, op_acc: 46.88%] [G loss: 0.895994]\n",
      "epoch:49 step:38652[D loss: 0.385305, acc: 69.53%, op_acc: 46.09%] [G loss: 0.844826]\n",
      "epoch:49 step:38653[D loss: 0.416280, acc: 59.38%, op_acc: 46.09%] [G loss: 1.083769]\n",
      "epoch:49 step:38654[D loss: 0.330395, acc: 67.97%, op_acc: 53.91%] [G loss: 1.066307]\n",
      "epoch:49 step:38655[D loss: 0.358347, acc: 72.66%, op_acc: 57.81%] [G loss: 1.131190]\n",
      "epoch:49 step:38656[D loss: 0.408045, acc: 66.41%, op_acc: 44.53%] [G loss: 1.105981]\n",
      "epoch:49 step:38657[D loss: 0.451900, acc: 60.16%, op_acc: 35.16%] [G loss: 0.741598]\n",
      "epoch:49 step:38658[D loss: 0.365978, acc: 69.53%, op_acc: 48.44%] [G loss: 0.861117]\n",
      "epoch:49 step:38659[D loss: 0.376378, acc: 70.31%, op_acc: 46.88%] [G loss: 1.126327]\n",
      "epoch:49 step:38660[D loss: 0.394652, acc: 64.06%, op_acc: 46.09%] [G loss: 1.060530]\n",
      "epoch:49 step:38661[D loss: 0.379862, acc: 68.75%, op_acc: 49.22%] [G loss: 1.219875]\n",
      "epoch:49 step:38662[D loss: 0.377873, acc: 71.88%, op_acc: 47.66%] [G loss: 1.352211]\n",
      "epoch:49 step:38663[D loss: 0.373570, acc: 67.97%, op_acc: 42.97%] [G loss: 0.815862]\n",
      "epoch:49 step:38664[D loss: 0.385662, acc: 73.44%, op_acc: 48.44%] [G loss: 0.572127]\n",
      "epoch:49 step:38665[D loss: 0.351051, acc: 71.09%, op_acc: 50.00%] [G loss: 0.667855]\n",
      "epoch:49 step:38666[D loss: 0.365778, acc: 68.75%, op_acc: 46.09%] [G loss: 1.282264]\n",
      "epoch:49 step:38667[D loss: 0.459408, acc: 49.22%, op_acc: 41.41%] [G loss: 0.844890]\n",
      "epoch:49 step:38668[D loss: 0.334754, acc: 75.00%, op_acc: 43.75%] [G loss: 1.126247]\n",
      "epoch:49 step:38669[D loss: 0.323688, acc: 76.56%, op_acc: 53.91%] [G loss: 0.771729]\n",
      "epoch:49 step:38670[D loss: 0.366583, acc: 69.53%, op_acc: 45.31%] [G loss: 0.828746]\n",
      "epoch:49 step:38671[D loss: 0.391122, acc: 69.53%, op_acc: 42.19%] [G loss: 0.763719]\n",
      "epoch:49 step:38672[D loss: 0.359820, acc: 72.66%, op_acc: 43.75%] [G loss: 1.209795]\n",
      "epoch:49 step:38673[D loss: 0.355444, acc: 71.09%, op_acc: 50.00%] [G loss: 0.605248]\n",
      "epoch:49 step:38674[D loss: 0.370924, acc: 66.41%, op_acc: 42.97%] [G loss: 0.755821]\n",
      "epoch:49 step:38675[D loss: 0.362936, acc: 69.53%, op_acc: 52.34%] [G loss: 1.166802]\n",
      "epoch:49 step:38676[D loss: 0.305007, acc: 80.47%, op_acc: 53.91%] [G loss: 0.726699]\n",
      "epoch:49 step:38677[D loss: 0.348747, acc: 63.28%, op_acc: 56.25%] [G loss: 0.848042]\n",
      "epoch:49 step:38678[D loss: 0.385458, acc: 72.66%, op_acc: 49.22%] [G loss: 0.687252]\n",
      "epoch:49 step:38679[D loss: 0.372628, acc: 71.88%, op_acc: 47.66%] [G loss: 1.029246]\n",
      "epoch:49 step:38680[D loss: 0.385935, acc: 63.28%, op_acc: 49.22%] [G loss: 0.954076]\n",
      "epoch:49 step:38681[D loss: 0.407459, acc: 64.84%, op_acc: 48.44%] [G loss: 0.649667]\n",
      "epoch:49 step:38682[D loss: 0.448353, acc: 56.25%, op_acc: 40.62%] [G loss: 0.719309]\n",
      "epoch:49 step:38683[D loss: 0.376505, acc: 65.62%, op_acc: 47.66%] [G loss: 1.222486]\n",
      "epoch:49 step:38684[D loss: 0.399478, acc: 67.19%, op_acc: 43.75%] [G loss: 1.150463]\n",
      "epoch:49 step:38685[D loss: 0.325166, acc: 75.78%, op_acc: 46.09%] [G loss: 1.319414]\n",
      "epoch:49 step:38686[D loss: 0.384191, acc: 70.31%, op_acc: 42.97%] [G loss: 0.791285]\n",
      "epoch:49 step:38687[D loss: 0.392255, acc: 67.97%, op_acc: 47.66%] [G loss: 0.825287]\n",
      "epoch:49 step:38688[D loss: 0.353511, acc: 78.91%, op_acc: 50.78%] [G loss: 0.737264]\n",
      "epoch:49 step:38689[D loss: 0.383512, acc: 65.62%, op_acc: 53.12%] [G loss: 1.191616]\n",
      "epoch:49 step:38690[D loss: 0.389973, acc: 66.41%, op_acc: 43.75%] [G loss: 0.805820]\n",
      "epoch:49 step:38691[D loss: 0.339380, acc: 73.44%, op_acc: 51.56%] [G loss: 0.774383]\n",
      "epoch:49 step:38692[D loss: 0.434289, acc: 64.84%, op_acc: 41.41%] [G loss: 0.822892]\n",
      "epoch:49 step:38693[D loss: 0.384800, acc: 64.06%, op_acc: 47.66%] [G loss: 0.917282]\n",
      "epoch:49 step:38694[D loss: 0.396836, acc: 63.28%, op_acc: 48.44%] [G loss: 0.888526]\n",
      "epoch:49 step:38695[D loss: 0.371445, acc: 68.75%, op_acc: 51.56%] [G loss: 0.893597]\n",
      "epoch:49 step:38696[D loss: 0.364976, acc: 73.44%, op_acc: 53.91%] [G loss: 1.026467]\n",
      "epoch:49 step:38697[D loss: 0.370703, acc: 65.62%, op_acc: 46.88%] [G loss: 0.887179]\n",
      "epoch:49 step:38698[D loss: 0.347836, acc: 71.09%, op_acc: 51.56%] [G loss: 0.710960]\n",
      "epoch:49 step:38699[D loss: 0.373333, acc: 65.62%, op_acc: 45.31%] [G loss: 0.671875]\n",
      "epoch:49 step:38700[D loss: 0.384479, acc: 73.44%, op_acc: 44.53%] [G loss: 0.751844]\n",
      "##############\n",
      "[0.86594948 0.87624363 0.81253193 0.8178932  0.77664697 0.84924013\n",
      " 0.88957507 0.81184449 0.83920961 0.84015805]\n",
      "##########\n",
      "epoch:49 step:38701[D loss: 0.291528, acc: 82.03%, op_acc: 52.34%] [G loss: 0.975779]\n",
      "epoch:49 step:38702[D loss: 0.363200, acc: 62.50%, op_acc: 53.91%] [G loss: 0.962043]\n",
      "epoch:49 step:38703[D loss: 0.389426, acc: 61.72%, op_acc: 53.12%] [G loss: 0.943648]\n",
      "epoch:49 step:38704[D loss: 0.338807, acc: 74.22%, op_acc: 53.12%] [G loss: 0.872236]\n",
      "epoch:49 step:38705[D loss: 0.383505, acc: 71.88%, op_acc: 43.75%] [G loss: 1.076389]\n",
      "epoch:49 step:38706[D loss: 0.375229, acc: 67.19%, op_acc: 50.00%] [G loss: 0.739057]\n",
      "epoch:49 step:38707[D loss: 0.343688, acc: 71.09%, op_acc: 46.88%] [G loss: 1.063907]\n",
      "epoch:49 step:38708[D loss: 0.330749, acc: 77.34%, op_acc: 53.91%] [G loss: 0.823872]\n",
      "epoch:49 step:38709[D loss: 0.331501, acc: 78.91%, op_acc: 47.66%] [G loss: 0.886888]\n",
      "epoch:49 step:38710[D loss: 0.322266, acc: 78.12%, op_acc: 47.66%] [G loss: 0.916263]\n",
      "epoch:49 step:38711[D loss: 0.359977, acc: 68.75%, op_acc: 47.66%] [G loss: 0.884275]\n",
      "epoch:49 step:38712[D loss: 0.280379, acc: 88.28%, op_acc: 50.78%] [G loss: 0.976553]\n",
      "epoch:49 step:38713[D loss: 0.320948, acc: 74.22%, op_acc: 49.22%] [G loss: 0.939615]\n",
      "epoch:49 step:38714[D loss: 0.391949, acc: 64.06%, op_acc: 44.53%] [G loss: 1.005182]\n",
      "epoch:49 step:38715[D loss: 0.403926, acc: 62.50%, op_acc: 42.19%] [G loss: 1.031657]\n",
      "epoch:49 step:38716[D loss: 0.401863, acc: 65.62%, op_acc: 42.97%] [G loss: 1.043433]\n",
      "epoch:49 step:38717[D loss: 0.364792, acc: 68.75%, op_acc: 46.09%] [G loss: 1.130597]\n",
      "epoch:49 step:38718[D loss: 0.326270, acc: 75.00%, op_acc: 46.88%] [G loss: 1.066662]\n",
      "epoch:49 step:38719[D loss: 0.390667, acc: 69.53%, op_acc: 54.69%] [G loss: 1.103779]\n",
      "epoch:49 step:38720[D loss: 0.341260, acc: 74.22%, op_acc: 53.12%] [G loss: 1.225405]\n",
      "epoch:49 step:38721[D loss: 0.364430, acc: 69.53%, op_acc: 42.97%] [G loss: 0.975590]\n",
      "epoch:49 step:38722[D loss: 0.370290, acc: 67.97%, op_acc: 50.00%] [G loss: 1.154123]\n",
      "epoch:49 step:38723[D loss: 0.396577, acc: 67.19%, op_acc: 43.75%] [G loss: 1.005446]\n",
      "epoch:49 step:38724[D loss: 0.361116, acc: 68.75%, op_acc: 48.44%] [G loss: 1.001437]\n",
      "epoch:49 step:38725[D loss: 0.377753, acc: 71.88%, op_acc: 45.31%] [G loss: 1.126113]\n",
      "epoch:49 step:38726[D loss: 0.358343, acc: 71.88%, op_acc: 42.97%] [G loss: 1.053221]\n",
      "epoch:49 step:38727[D loss: 0.379740, acc: 62.50%, op_acc: 50.00%] [G loss: 0.884146]\n",
      "epoch:49 step:38728[D loss: 0.360259, acc: 69.53%, op_acc: 53.12%] [G loss: 1.063432]\n",
      "epoch:49 step:38729[D loss: 0.315572, acc: 76.56%, op_acc: 50.78%] [G loss: 1.136825]\n",
      "epoch:49 step:38730[D loss: 0.425489, acc: 60.16%, op_acc: 42.19%] [G loss: 1.069285]\n",
      "epoch:49 step:38731[D loss: 0.398264, acc: 63.28%, op_acc: 44.53%] [G loss: 1.188679]\n",
      "epoch:49 step:38732[D loss: 0.374348, acc: 67.19%, op_acc: 46.09%] [G loss: 1.033333]\n",
      "epoch:49 step:38733[D loss: 0.406896, acc: 64.84%, op_acc: 39.06%] [G loss: 0.966475]\n",
      "epoch:49 step:38734[D loss: 0.352112, acc: 74.22%, op_acc: 50.00%] [G loss: 1.003149]\n",
      "epoch:49 step:38735[D loss: 0.385922, acc: 66.41%, op_acc: 42.97%] [G loss: 0.975234]\n",
      "epoch:49 step:38736[D loss: 0.399219, acc: 53.91%, op_acc: 42.19%] [G loss: 1.399695]\n",
      "epoch:49 step:38737[D loss: 0.339624, acc: 71.09%, op_acc: 46.88%] [G loss: 1.146417]\n",
      "epoch:49 step:38738[D loss: 0.324870, acc: 71.88%, op_acc: 48.44%] [G loss: 1.123814]\n",
      "epoch:49 step:38739[D loss: 0.342183, acc: 75.00%, op_acc: 46.88%] [G loss: 1.412350]\n",
      "epoch:49 step:38740[D loss: 0.388030, acc: 64.84%, op_acc: 52.34%] [G loss: 1.034776]\n",
      "epoch:49 step:38741[D loss: 0.492789, acc: 55.47%, op_acc: 38.28%] [G loss: 0.897394]\n",
      "epoch:49 step:38742[D loss: 0.366216, acc: 67.97%, op_acc: 47.66%] [G loss: 0.918141]\n",
      "epoch:49 step:38743[D loss: 0.352836, acc: 75.78%, op_acc: 51.56%] [G loss: 0.956497]\n",
      "epoch:49 step:38744[D loss: 0.426681, acc: 61.72%, op_acc: 46.88%] [G loss: 0.941847]\n",
      "epoch:49 step:38745[D loss: 0.371012, acc: 72.66%, op_acc: 46.09%] [G loss: 0.878839]\n",
      "epoch:49 step:38746[D loss: 0.421442, acc: 62.50%, op_acc: 47.66%] [G loss: 0.864136]\n",
      "epoch:49 step:38747[D loss: 0.341652, acc: 75.00%, op_acc: 50.00%] [G loss: 0.901136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38748[D loss: 0.335198, acc: 75.78%, op_acc: 46.09%] [G loss: 0.779535]\n",
      "epoch:49 step:38749[D loss: 0.390432, acc: 67.19%, op_acc: 39.06%] [G loss: 1.227673]\n",
      "epoch:49 step:38750[D loss: 0.406001, acc: 66.41%, op_acc: 39.06%] [G loss: 0.703087]\n",
      "##############\n",
      "[0.85636073 0.85965867 0.8309406  0.81563885 0.79995948 0.80999321\n",
      " 0.91768792 0.80934821 0.78399724 0.81417142]\n",
      "##########\n",
      "epoch:49 step:38751[D loss: 0.404493, acc: 64.06%, op_acc: 42.97%] [G loss: 0.892449]\n",
      "epoch:49 step:38752[D loss: 0.339991, acc: 74.22%, op_acc: 47.66%] [G loss: 0.789308]\n",
      "epoch:49 step:38753[D loss: 0.342809, acc: 73.44%, op_acc: 58.59%] [G loss: 0.710441]\n",
      "epoch:49 step:38754[D loss: 0.395163, acc: 67.19%, op_acc: 38.28%] [G loss: 0.803332]\n",
      "epoch:49 step:38755[D loss: 0.357455, acc: 65.62%, op_acc: 53.91%] [G loss: 0.917536]\n",
      "epoch:49 step:38756[D loss: 0.311154, acc: 85.16%, op_acc: 50.78%] [G loss: 1.391027]\n",
      "epoch:49 step:38757[D loss: 0.410373, acc: 63.28%, op_acc: 42.19%] [G loss: 0.897610]\n",
      "epoch:49 step:38758[D loss: 0.448906, acc: 60.94%, op_acc: 44.53%] [G loss: 0.790453]\n",
      "epoch:49 step:38759[D loss: 0.354088, acc: 71.88%, op_acc: 50.00%] [G loss: 0.790597]\n",
      "epoch:49 step:38760[D loss: 0.389544, acc: 70.31%, op_acc: 42.19%] [G loss: 1.276774]\n",
      "epoch:49 step:38761[D loss: 0.376796, acc: 71.09%, op_acc: 46.09%] [G loss: 0.983296]\n",
      "epoch:49 step:38762[D loss: 0.325670, acc: 76.56%, op_acc: 45.31%] [G loss: 0.814067]\n",
      "epoch:49 step:38763[D loss: 0.384410, acc: 66.41%, op_acc: 48.44%] [G loss: 0.808992]\n",
      "epoch:49 step:38764[D loss: 0.345281, acc: 73.44%, op_acc: 49.22%] [G loss: 0.843449]\n",
      "epoch:49 step:38765[D loss: 0.379571, acc: 62.50%, op_acc: 42.97%] [G loss: 0.901507]\n",
      "epoch:49 step:38766[D loss: 0.397375, acc: 62.50%, op_acc: 44.53%] [G loss: 0.900056]\n",
      "epoch:49 step:38767[D loss: 0.346068, acc: 77.34%, op_acc: 47.66%] [G loss: 1.301364]\n",
      "epoch:49 step:38768[D loss: 0.326928, acc: 78.91%, op_acc: 50.78%] [G loss: 0.777727]\n",
      "epoch:49 step:38769[D loss: 0.318224, acc: 79.69%, op_acc: 51.56%] [G loss: 0.932139]\n",
      "epoch:49 step:38770[D loss: 0.368557, acc: 68.75%, op_acc: 45.31%] [G loss: 0.858378]\n",
      "epoch:49 step:38771[D loss: 0.339651, acc: 68.75%, op_acc: 53.91%] [G loss: 1.065473]\n",
      "epoch:49 step:38772[D loss: 0.321310, acc: 78.12%, op_acc: 50.78%] [G loss: 0.780224]\n",
      "epoch:49 step:38773[D loss: 0.385723, acc: 71.09%, op_acc: 40.62%] [G loss: 1.072523]\n",
      "epoch:49 step:38774[D loss: 0.418069, acc: 57.03%, op_acc: 42.97%] [G loss: 0.671199]\n",
      "epoch:49 step:38775[D loss: 0.350294, acc: 75.00%, op_acc: 49.22%] [G loss: 0.839805]\n",
      "epoch:49 step:38776[D loss: 0.375313, acc: 63.28%, op_acc: 45.31%] [G loss: 0.999890]\n",
      "epoch:49 step:38777[D loss: 0.369433, acc: 70.31%, op_acc: 50.78%] [G loss: 0.928349]\n",
      "epoch:49 step:38778[D loss: 0.420706, acc: 62.50%, op_acc: 47.66%] [G loss: 0.928748]\n",
      "epoch:49 step:38779[D loss: 0.383612, acc: 66.41%, op_acc: 47.66%] [G loss: 1.465744]\n",
      "epoch:49 step:38780[D loss: 0.334130, acc: 71.09%, op_acc: 50.00%] [G loss: 0.827532]\n",
      "epoch:49 step:38781[D loss: 0.388379, acc: 60.94%, op_acc: 52.34%] [G loss: 0.752343]\n",
      "epoch:49 step:38782[D loss: 0.425675, acc: 57.81%, op_acc: 42.97%] [G loss: 1.052859]\n",
      "epoch:49 step:38783[D loss: 0.440718, acc: 62.50%, op_acc: 39.06%] [G loss: 1.040369]\n",
      "epoch:49 step:38784[D loss: 0.323356, acc: 79.69%, op_acc: 47.66%] [G loss: 0.992982]\n",
      "epoch:49 step:38785[D loss: 0.359137, acc: 77.34%, op_acc: 54.69%] [G loss: 0.933224]\n",
      "epoch:49 step:38786[D loss: 0.323407, acc: 81.25%, op_acc: 46.88%] [G loss: 0.978257]\n",
      "epoch:49 step:38787[D loss: 0.396595, acc: 61.72%, op_acc: 45.31%] [G loss: 0.788811]\n",
      "epoch:49 step:38788[D loss: 0.318092, acc: 75.78%, op_acc: 47.66%] [G loss: 0.823207]\n",
      "epoch:49 step:38789[D loss: 0.365320, acc: 71.88%, op_acc: 47.66%] [G loss: 0.924218]\n",
      "epoch:49 step:38790[D loss: 0.320497, acc: 79.69%, op_acc: 50.78%] [G loss: 1.079790]\n",
      "epoch:49 step:38791[D loss: 0.344614, acc: 76.56%, op_acc: 43.75%] [G loss: 1.093096]\n",
      "epoch:49 step:38792[D loss: 0.289603, acc: 85.16%, op_acc: 57.81%] [G loss: 0.904877]\n",
      "epoch:49 step:38793[D loss: 0.348831, acc: 73.44%, op_acc: 48.44%] [G loss: 0.941869]\n",
      "epoch:49 step:38794[D loss: 0.292286, acc: 86.72%, op_acc: 50.78%] [G loss: 1.044560]\n",
      "epoch:49 step:38795[D loss: 0.401751, acc: 69.53%, op_acc: 47.66%] [G loss: 1.066190]\n",
      "epoch:49 step:38796[D loss: 0.325967, acc: 75.78%, op_acc: 53.91%] [G loss: 1.063588]\n",
      "epoch:49 step:38797[D loss: 0.332511, acc: 71.09%, op_acc: 53.12%] [G loss: 0.677509]\n",
      "epoch:49 step:38798[D loss: 0.392554, acc: 65.62%, op_acc: 43.75%] [G loss: 1.054220]\n",
      "epoch:49 step:38799[D loss: 0.339275, acc: 75.00%, op_acc: 46.09%] [G loss: 1.189431]\n",
      "epoch:49 step:38800[D loss: 0.282059, acc: 85.94%, op_acc: 53.12%] [G loss: 1.018324]\n",
      "##############\n",
      "[0.84085268 0.87149753 0.80473207 0.8104168  0.79648952 0.85207234\n",
      " 0.9013927  0.83797267 0.81632867 0.82951029]\n",
      "##########\n",
      "epoch:49 step:38801[D loss: 0.321885, acc: 74.22%, op_acc: 50.78%] [G loss: 0.878996]\n",
      "epoch:49 step:38802[D loss: 0.285268, acc: 82.81%, op_acc: 59.38%] [G loss: 0.892677]\n",
      "epoch:49 step:38803[D loss: 0.289891, acc: 81.25%, op_acc: 53.12%] [G loss: 1.186862]\n",
      "epoch:49 step:38804[D loss: 0.315602, acc: 76.56%, op_acc: 52.34%] [G loss: 1.191626]\n",
      "epoch:49 step:38805[D loss: 0.307642, acc: 75.78%, op_acc: 55.47%] [G loss: 1.257726]\n",
      "epoch:49 step:38806[D loss: 0.362860, acc: 71.09%, op_acc: 47.66%] [G loss: 1.272062]\n",
      "epoch:49 step:38807[D loss: 0.318132, acc: 78.12%, op_acc: 49.22%] [G loss: 1.144608]\n",
      "epoch:49 step:38808[D loss: 0.286756, acc: 87.50%, op_acc: 48.44%] [G loss: 1.164856]\n",
      "epoch:49 step:38809[D loss: 0.259601, acc: 88.28%, op_acc: 60.16%] [G loss: 1.260397]\n",
      "epoch:49 step:38810[D loss: 0.246945, acc: 89.84%, op_acc: 57.03%] [G loss: 1.603996]\n",
      "epoch:49 step:38811[D loss: 0.233392, acc: 87.50%, op_acc: 67.97%] [G loss: 1.702806]\n",
      "epoch:49 step:38812[D loss: 0.335783, acc: 74.22%, op_acc: 47.66%] [G loss: 1.407671]\n",
      "epoch:49 step:38813[D loss: 0.239514, acc: 91.41%, op_acc: 53.91%] [G loss: 0.401417]\n",
      "epoch:49 step:38814[D loss: 0.435247, acc: 64.06%, op_acc: 42.97%] [G loss: 0.664479]\n",
      "epoch:49 step:38815[D loss: 0.557847, acc: 47.66%, op_acc: 40.62%] [G loss: 1.851549]\n",
      "epoch:49 step:38816[D loss: 0.474229, acc: 53.91%, op_acc: 44.53%] [G loss: 0.896756]\n",
      "epoch:49 step:38817[D loss: 0.456501, acc: 57.81%, op_acc: 42.19%] [G loss: 0.892078]\n",
      "epoch:49 step:38818[D loss: 0.402211, acc: 64.84%, op_acc: 43.75%] [G loss: 1.075971]\n",
      "epoch:49 step:38819[D loss: 0.441314, acc: 62.50%, op_acc: 39.84%] [G loss: 1.268297]\n",
      "epoch:49 step:38820[D loss: 0.402240, acc: 62.50%, op_acc: 45.31%] [G loss: 1.259202]\n",
      "epoch:49 step:38821[D loss: 0.507452, acc: 44.53%, op_acc: 33.59%] [G loss: 1.360714]\n",
      "epoch:49 step:38822[D loss: 0.367983, acc: 71.88%, op_acc: 46.09%] [G loss: 1.542831]\n",
      "epoch:49 step:38823[D loss: 0.375446, acc: 66.41%, op_acc: 49.22%] [G loss: 1.233662]\n",
      "epoch:49 step:38824[D loss: 0.332404, acc: 76.56%, op_acc: 49.22%] [G loss: 0.960416]\n",
      "epoch:49 step:38825[D loss: 0.457997, acc: 51.56%, op_acc: 42.19%] [G loss: 1.224998]\n",
      "epoch:49 step:38826[D loss: 0.433365, acc: 62.50%, op_acc: 38.28%] [G loss: 1.056329]\n",
      "epoch:49 step:38827[D loss: 0.438010, acc: 55.47%, op_acc: 45.31%] [G loss: 0.963751]\n",
      "epoch:49 step:38828[D loss: 0.416305, acc: 60.94%, op_acc: 35.16%] [G loss: 1.008461]\n",
      "epoch:49 step:38829[D loss: 0.466426, acc: 57.03%, op_acc: 41.41%] [G loss: 1.067411]\n",
      "epoch:49 step:38830[D loss: 0.391412, acc: 67.19%, op_acc: 51.56%] [G loss: 1.422795]\n",
      "epoch:49 step:38831[D loss: 0.433316, acc: 63.28%, op_acc: 34.38%] [G loss: 1.178416]\n",
      "epoch:49 step:38832[D loss: 0.444919, acc: 60.16%, op_acc: 37.50%] [G loss: 1.375675]\n",
      "epoch:49 step:38833[D loss: 0.379813, acc: 69.53%, op_acc: 53.12%] [G loss: 1.311912]\n",
      "epoch:49 step:38834[D loss: 0.353646, acc: 70.31%, op_acc: 45.31%] [G loss: 1.474504]\n",
      "epoch:49 step:38835[D loss: 0.404048, acc: 66.41%, op_acc: 36.72%] [G loss: 1.220792]\n",
      "epoch:49 step:38836[D loss: 0.387649, acc: 68.75%, op_acc: 42.97%] [G loss: 1.250517]\n",
      "epoch:49 step:38837[D loss: 0.356800, acc: 75.00%, op_acc: 50.78%] [G loss: 1.092423]\n",
      "epoch:49 step:38838[D loss: 0.333708, acc: 70.31%, op_acc: 53.12%] [G loss: 1.111683]\n",
      "epoch:49 step:38839[D loss: 0.416383, acc: 64.06%, op_acc: 49.22%] [G loss: 1.128346]\n",
      "epoch:49 step:38840[D loss: 0.397038, acc: 60.94%, op_acc: 53.91%] [G loss: 0.878422]\n",
      "epoch:49 step:38841[D loss: 0.378283, acc: 71.09%, op_acc: 42.19%] [G loss: 1.297121]\n",
      "epoch:49 step:38842[D loss: 0.429281, acc: 60.16%, op_acc: 37.50%] [G loss: 1.118619]\n",
      "epoch:49 step:38843[D loss: 0.429658, acc: 63.28%, op_acc: 43.75%] [G loss: 1.259547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38844[D loss: 0.392837, acc: 65.62%, op_acc: 40.62%] [G loss: 0.979556]\n",
      "epoch:49 step:38845[D loss: 0.343201, acc: 71.09%, op_acc: 46.88%] [G loss: 1.118750]\n",
      "epoch:49 step:38846[D loss: 0.379227, acc: 71.09%, op_acc: 46.88%] [G loss: 1.164456]\n",
      "epoch:49 step:38847[D loss: 0.409675, acc: 64.84%, op_acc: 41.41%] [G loss: 1.074273]\n",
      "epoch:49 step:38848[D loss: 0.328147, acc: 73.44%, op_acc: 53.91%] [G loss: 0.683559]\n",
      "epoch:49 step:38849[D loss: 0.381457, acc: 71.09%, op_acc: 45.31%] [G loss: 0.960400]\n",
      "epoch:49 step:38850[D loss: 0.411690, acc: 60.94%, op_acc: 42.97%] [G loss: 1.205289]\n",
      "##############\n",
      "[0.84362048 0.87087324 0.82303165 0.81254686 0.79882421 0.83179998\n",
      " 0.8874002  0.80993673 0.83233616 0.82144093]\n",
      "##########\n",
      "epoch:49 step:38851[D loss: 0.403742, acc: 62.50%, op_acc: 46.88%] [G loss: 1.041588]\n",
      "epoch:49 step:38852[D loss: 0.382025, acc: 62.50%, op_acc: 45.31%] [G loss: 1.051538]\n",
      "epoch:49 step:38853[D loss: 0.400924, acc: 65.62%, op_acc: 40.62%] [G loss: 0.956461]\n",
      "epoch:49 step:38854[D loss: 0.414747, acc: 62.50%, op_acc: 39.84%] [G loss: 0.947945]\n",
      "epoch:49 step:38855[D loss: 0.373760, acc: 71.88%, op_acc: 42.97%] [G loss: 0.861588]\n",
      "epoch:49 step:38856[D loss: 0.387169, acc: 64.84%, op_acc: 41.41%] [G loss: 1.041430]\n",
      "epoch:49 step:38857[D loss: 0.366686, acc: 67.19%, op_acc: 48.44%] [G loss: 0.992687]\n",
      "epoch:49 step:38858[D loss: 0.319971, acc: 77.34%, op_acc: 50.00%] [G loss: 1.054183]\n",
      "epoch:49 step:38859[D loss: 0.409088, acc: 64.06%, op_acc: 40.62%] [G loss: 1.067660]\n",
      "epoch:49 step:38860[D loss: 0.447651, acc: 68.75%, op_acc: 40.62%] [G loss: 0.951958]\n",
      "epoch:49 step:38861[D loss: 0.426963, acc: 58.59%, op_acc: 42.97%] [G loss: 0.717941]\n",
      "epoch:49 step:38862[D loss: 0.408520, acc: 64.84%, op_acc: 41.41%] [G loss: 0.989201]\n",
      "epoch:49 step:38863[D loss: 0.378984, acc: 64.06%, op_acc: 38.28%] [G loss: 0.893460]\n",
      "epoch:49 step:38864[D loss: 0.321028, acc: 79.69%, op_acc: 47.66%] [G loss: 1.087492]\n",
      "epoch:49 step:38865[D loss: 0.430177, acc: 61.72%, op_acc: 39.06%] [G loss: 1.217612]\n",
      "epoch:49 step:38866[D loss: 0.349504, acc: 73.44%, op_acc: 47.66%] [G loss: 0.904646]\n",
      "epoch:49 step:38867[D loss: 0.327479, acc: 75.78%, op_acc: 54.69%] [G loss: 1.237665]\n",
      "epoch:49 step:38868[D loss: 0.355678, acc: 77.34%, op_acc: 49.22%] [G loss: 0.761079]\n",
      "epoch:49 step:38869[D loss: 0.387473, acc: 70.31%, op_acc: 45.31%] [G loss: 0.835572]\n",
      "epoch:49 step:38870[D loss: 0.400250, acc: 67.97%, op_acc: 43.75%] [G loss: 1.059066]\n",
      "epoch:49 step:38871[D loss: 0.348276, acc: 79.69%, op_acc: 50.00%] [G loss: 0.843049]\n",
      "epoch:49 step:38872[D loss: 0.354370, acc: 69.53%, op_acc: 49.22%] [G loss: 0.955490]\n",
      "epoch:49 step:38873[D loss: 0.405270, acc: 68.75%, op_acc: 41.41%] [G loss: 0.980226]\n",
      "epoch:49 step:38874[D loss: 0.345190, acc: 71.88%, op_acc: 42.19%] [G loss: 0.859738]\n",
      "epoch:49 step:38875[D loss: 0.363573, acc: 69.53%, op_acc: 46.09%] [G loss: 0.835605]\n",
      "epoch:49 step:38876[D loss: 0.305909, acc: 82.81%, op_acc: 56.25%] [G loss: 0.926800]\n",
      "epoch:49 step:38877[D loss: 0.327198, acc: 77.34%, op_acc: 50.78%] [G loss: 0.927938]\n",
      "epoch:49 step:38878[D loss: 0.379766, acc: 66.41%, op_acc: 52.34%] [G loss: 0.951963]\n",
      "epoch:49 step:38879[D loss: 0.340725, acc: 72.66%, op_acc: 50.00%] [G loss: 1.251266]\n",
      "epoch:49 step:38880[D loss: 0.391608, acc: 65.62%, op_acc: 47.66%] [G loss: 1.107836]\n",
      "epoch:49 step:38881[D loss: 0.324162, acc: 79.69%, op_acc: 50.78%] [G loss: 1.370043]\n",
      "epoch:49 step:38882[D loss: 0.382206, acc: 64.84%, op_acc: 45.31%] [G loss: 1.100448]\n",
      "epoch:49 step:38883[D loss: 0.297292, acc: 78.12%, op_acc: 52.34%] [G loss: 1.250401]\n",
      "epoch:49 step:38884[D loss: 0.288174, acc: 85.94%, op_acc: 56.25%] [G loss: 1.148228]\n",
      "epoch:49 step:38885[D loss: 0.321213, acc: 74.22%, op_acc: 54.69%] [G loss: 0.705499]\n",
      "epoch:49 step:38886[D loss: 0.408275, acc: 66.41%, op_acc: 44.53%] [G loss: 0.759695]\n",
      "epoch:49 step:38887[D loss: 0.425249, acc: 62.50%, op_acc: 45.31%] [G loss: 1.393927]\n",
      "epoch:49 step:38888[D loss: 0.397650, acc: 71.88%, op_acc: 42.97%] [G loss: 1.472754]\n",
      "epoch:49 step:38889[D loss: 0.384937, acc: 70.31%, op_acc: 40.62%] [G loss: 1.333931]\n",
      "epoch:49 step:38890[D loss: 0.390043, acc: 67.19%, op_acc: 46.88%] [G loss: 1.312599]\n",
      "epoch:49 step:38891[D loss: 0.411351, acc: 64.84%, op_acc: 42.97%] [G loss: 1.368264]\n",
      "epoch:49 step:38892[D loss: 0.353455, acc: 78.12%, op_acc: 50.00%] [G loss: 1.106973]\n",
      "epoch:49 step:38893[D loss: 0.330423, acc: 71.88%, op_acc: 47.66%] [G loss: 1.536157]\n",
      "epoch:49 step:38894[D loss: 0.336372, acc: 72.66%, op_acc: 51.56%] [G loss: 0.769400]\n",
      "epoch:49 step:38895[D loss: 0.368398, acc: 66.41%, op_acc: 47.66%] [G loss: 1.031635]\n",
      "epoch:49 step:38896[D loss: 0.379185, acc: 65.62%, op_acc: 46.88%] [G loss: 0.969375]\n",
      "epoch:49 step:38897[D loss: 0.444766, acc: 60.94%, op_acc: 43.75%] [G loss: 1.064131]\n",
      "epoch:49 step:38898[D loss: 0.445921, acc: 64.06%, op_acc: 39.06%] [G loss: 1.026645]\n",
      "epoch:49 step:38899[D loss: 0.366846, acc: 71.09%, op_acc: 50.00%] [G loss: 1.005967]\n",
      "epoch:49 step:38900[D loss: 0.418133, acc: 64.84%, op_acc: 46.09%] [G loss: 0.952075]\n",
      "##############\n",
      "[0.84951807 0.85924526 0.83092126 0.7912689  0.78714721 0.81880363\n",
      " 0.89820193 0.827461   0.81467061 0.83630295]\n",
      "##########\n",
      "epoch:49 step:38901[D loss: 0.392253, acc: 72.66%, op_acc: 50.78%] [G loss: 1.188013]\n",
      "epoch:49 step:38902[D loss: 0.391798, acc: 71.09%, op_acc: 42.97%] [G loss: 1.055461]\n",
      "epoch:49 step:38903[D loss: 0.397386, acc: 64.84%, op_acc: 47.66%] [G loss: 1.039570]\n",
      "epoch:49 step:38904[D loss: 0.369706, acc: 69.53%, op_acc: 48.44%] [G loss: 1.173888]\n",
      "epoch:49 step:38905[D loss: 0.294774, acc: 82.81%, op_acc: 51.56%] [G loss: 1.201282]\n",
      "epoch:49 step:38906[D loss: 0.305529, acc: 79.69%, op_acc: 50.00%] [G loss: 1.105081]\n",
      "epoch:49 step:38907[D loss: 0.385183, acc: 63.28%, op_acc: 40.62%] [G loss: 0.973706]\n",
      "epoch:49 step:38908[D loss: 0.417810, acc: 65.62%, op_acc: 45.31%] [G loss: 1.047973]\n",
      "epoch:49 step:38909[D loss: 0.428823, acc: 64.84%, op_acc: 46.09%] [G loss: 1.003049]\n",
      "epoch:49 step:38910[D loss: 0.377932, acc: 73.44%, op_acc: 42.19%] [G loss: 1.094641]\n",
      "epoch:49 step:38911[D loss: 0.377165, acc: 71.09%, op_acc: 46.88%] [G loss: 0.904764]\n",
      "epoch:49 step:38912[D loss: 0.398649, acc: 62.50%, op_acc: 46.09%] [G loss: 0.960321]\n",
      "epoch:49 step:38913[D loss: 0.343141, acc: 68.75%, op_acc: 50.00%] [G loss: 1.373577]\n",
      "epoch:49 step:38914[D loss: 0.351455, acc: 75.78%, op_acc: 48.44%] [G loss: 0.894612]\n",
      "epoch:49 step:38915[D loss: 0.405457, acc: 66.41%, op_acc: 39.84%] [G loss: 0.909646]\n",
      "epoch:49 step:38916[D loss: 0.371038, acc: 67.97%, op_acc: 47.66%] [G loss: 1.451101]\n",
      "epoch:49 step:38917[D loss: 0.334206, acc: 77.34%, op_acc: 41.41%] [G loss: 1.303340]\n",
      "epoch:49 step:38918[D loss: 0.329565, acc: 78.91%, op_acc: 53.91%] [G loss: 0.925989]\n",
      "epoch:49 step:38919[D loss: 0.462412, acc: 54.69%, op_acc: 37.50%] [G loss: 1.065226]\n",
      "epoch:49 step:38920[D loss: 0.373260, acc: 67.19%, op_acc: 47.66%] [G loss: 1.326918]\n",
      "epoch:49 step:38921[D loss: 0.383911, acc: 64.06%, op_acc: 40.62%] [G loss: 1.218362]\n",
      "epoch:49 step:38922[D loss: 0.364763, acc: 69.53%, op_acc: 44.53%] [G loss: 1.138979]\n",
      "epoch:49 step:38923[D loss: 0.429605, acc: 56.25%, op_acc: 48.44%] [G loss: 1.051663]\n",
      "epoch:49 step:38924[D loss: 0.400343, acc: 64.06%, op_acc: 47.66%] [G loss: 0.876340]\n",
      "epoch:49 step:38925[D loss: 0.415094, acc: 63.28%, op_acc: 45.31%] [G loss: 0.890823]\n",
      "epoch:49 step:38926[D loss: 0.396750, acc: 71.09%, op_acc: 50.00%] [G loss: 0.775865]\n",
      "epoch:49 step:38927[D loss: 0.345025, acc: 69.53%, op_acc: 49.22%] [G loss: 1.229736]\n",
      "epoch:49 step:38928[D loss: 0.373337, acc: 68.75%, op_acc: 40.62%] [G loss: 0.905334]\n",
      "epoch:49 step:38929[D loss: 0.352602, acc: 71.09%, op_acc: 54.69%] [G loss: 1.314782]\n",
      "epoch:49 step:38930[D loss: 0.343061, acc: 71.09%, op_acc: 55.47%] [G loss: 1.085316]\n",
      "epoch:49 step:38931[D loss: 0.347428, acc: 72.66%, op_acc: 47.66%] [G loss: 1.022631]\n",
      "epoch:49 step:38932[D loss: 0.390030, acc: 66.41%, op_acc: 46.09%] [G loss: 0.698203]\n",
      "epoch:49 step:38933[D loss: 0.392549, acc: 69.53%, op_acc: 45.31%] [G loss: 0.837658]\n",
      "epoch:49 step:38934[D loss: 0.440125, acc: 58.59%, op_acc: 37.50%] [G loss: 1.093745]\n",
      "epoch:49 step:38935[D loss: 0.378437, acc: 71.88%, op_acc: 48.44%] [G loss: 0.983895]\n",
      "epoch:49 step:38936[D loss: 0.368103, acc: 64.84%, op_acc: 52.34%] [G loss: 1.321119]\n",
      "epoch:49 step:38937[D loss: 0.376556, acc: 71.88%, op_acc: 46.09%] [G loss: 0.925185]\n",
      "epoch:49 step:38938[D loss: 0.396909, acc: 67.97%, op_acc: 45.31%] [G loss: 0.709901]\n",
      "epoch:49 step:38939[D loss: 0.341702, acc: 69.53%, op_acc: 50.78%] [G loss: 0.851834]\n",
      "epoch:49 step:38940[D loss: 0.399337, acc: 71.88%, op_acc: 35.94%] [G loss: 0.764387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38941[D loss: 0.418302, acc: 57.81%, op_acc: 46.88%] [G loss: 0.854357]\n",
      "epoch:49 step:38942[D loss: 0.374712, acc: 68.75%, op_acc: 51.56%] [G loss: 0.849889]\n",
      "epoch:49 step:38943[D loss: 0.362693, acc: 71.88%, op_acc: 46.09%] [G loss: 1.120819]\n",
      "epoch:49 step:38944[D loss: 0.311995, acc: 75.78%, op_acc: 52.34%] [G loss: 0.774049]\n",
      "epoch:49 step:38945[D loss: 0.393613, acc: 65.62%, op_acc: 50.78%] [G loss: 0.863574]\n",
      "epoch:49 step:38946[D loss: 0.420228, acc: 61.72%, op_acc: 34.38%] [G loss: 1.093057]\n",
      "epoch:49 step:38947[D loss: 0.319876, acc: 75.00%, op_acc: 50.78%] [G loss: 0.873377]\n",
      "epoch:49 step:38948[D loss: 0.332269, acc: 72.66%, op_acc: 47.66%] [G loss: 0.835384]\n",
      "epoch:49 step:38949[D loss: 0.336729, acc: 80.47%, op_acc: 54.69%] [G loss: 1.116465]\n",
      "epoch:49 step:38950[D loss: 0.347684, acc: 78.12%, op_acc: 40.62%] [G loss: 1.199158]\n",
      "##############\n",
      "[0.86563389 0.86477758 0.81089694 0.81154656 0.79810687 0.83509973\n",
      " 0.87542535 0.80086118 0.78616936 0.81934221]\n",
      "##########\n",
      "epoch:49 step:38951[D loss: 0.410218, acc: 54.69%, op_acc: 51.56%] [G loss: 1.114598]\n",
      "epoch:49 step:38952[D loss: 0.395149, acc: 64.84%, op_acc: 46.88%] [G loss: 0.820064]\n",
      "epoch:49 step:38953[D loss: 0.395427, acc: 66.41%, op_acc: 52.34%] [G loss: 1.004195]\n",
      "epoch:49 step:38954[D loss: 0.404614, acc: 63.28%, op_acc: 45.31%] [G loss: 0.799891]\n",
      "epoch:49 step:38955[D loss: 0.347262, acc: 73.44%, op_acc: 43.75%] [G loss: 0.652542]\n",
      "epoch:49 step:38956[D loss: 0.395030, acc: 63.28%, op_acc: 46.09%] [G loss: 0.750986]\n",
      "epoch:49 step:38957[D loss: 0.350451, acc: 71.09%, op_acc: 52.34%] [G loss: 1.127867]\n",
      "epoch:49 step:38958[D loss: 0.392867, acc: 64.06%, op_acc: 49.22%] [G loss: 1.133194]\n",
      "epoch:49 step:38959[D loss: 0.354138, acc: 71.88%, op_acc: 45.31%] [G loss: 0.878935]\n",
      "epoch:49 step:38960[D loss: 0.356713, acc: 75.78%, op_acc: 47.66%] [G loss: 0.871569]\n",
      "epoch:49 step:38961[D loss: 0.415449, acc: 58.59%, op_acc: 39.84%] [G loss: 1.314564]\n",
      "epoch:49 step:38962[D loss: 0.367217, acc: 71.09%, op_acc: 46.09%] [G loss: 0.759468]\n",
      "epoch:49 step:38963[D loss: 0.354262, acc: 70.31%, op_acc: 49.22%] [G loss: 0.907409]\n",
      "epoch:49 step:38964[D loss: 0.387454, acc: 70.31%, op_acc: 44.53%] [G loss: 0.863575]\n",
      "epoch:49 step:38965[D loss: 0.431062, acc: 59.38%, op_acc: 50.78%] [G loss: 1.132254]\n",
      "epoch:49 step:38966[D loss: 0.377030, acc: 66.41%, op_acc: 46.09%] [G loss: 0.736455]\n",
      "epoch:49 step:38967[D loss: 0.376789, acc: 71.88%, op_acc: 44.53%] [G loss: 0.873659]\n",
      "epoch:49 step:38968[D loss: 0.337690, acc: 73.44%, op_acc: 49.22%] [G loss: 1.200120]\n",
      "epoch:49 step:38969[D loss: 0.375725, acc: 70.31%, op_acc: 50.00%] [G loss: 0.815333]\n",
      "epoch:49 step:38970[D loss: 0.375384, acc: 68.75%, op_acc: 50.00%] [G loss: 0.826564]\n",
      "epoch:49 step:38971[D loss: 0.407754, acc: 66.41%, op_acc: 44.53%] [G loss: 0.769824]\n",
      "epoch:49 step:38972[D loss: 0.369910, acc: 71.88%, op_acc: 45.31%] [G loss: 0.920540]\n",
      "epoch:49 step:38973[D loss: 0.387731, acc: 62.50%, op_acc: 42.19%] [G loss: 0.718225]\n",
      "epoch:49 step:38974[D loss: 0.385909, acc: 70.31%, op_acc: 42.19%] [G loss: 0.895575]\n",
      "epoch:49 step:38975[D loss: 0.348833, acc: 72.66%, op_acc: 51.56%] [G loss: 0.980602]\n",
      "epoch:49 step:38976[D loss: 0.385390, acc: 67.97%, op_acc: 43.75%] [G loss: 1.039547]\n",
      "epoch:49 step:38977[D loss: 0.359335, acc: 75.00%, op_acc: 53.12%] [G loss: 1.085171]\n",
      "epoch:49 step:38978[D loss: 0.339884, acc: 74.22%, op_acc: 47.66%] [G loss: 0.776955]\n",
      "epoch:49 step:38979[D loss: 0.406594, acc: 59.38%, op_acc: 49.22%] [G loss: 1.093591]\n",
      "epoch:49 step:38980[D loss: 0.347204, acc: 71.88%, op_acc: 40.62%] [G loss: 0.923934]\n",
      "epoch:49 step:38981[D loss: 0.352198, acc: 73.44%, op_acc: 41.41%] [G loss: 1.220588]\n",
      "epoch:49 step:38982[D loss: 0.388766, acc: 67.97%, op_acc: 48.44%] [G loss: 0.990805]\n",
      "epoch:49 step:38983[D loss: 0.356439, acc: 68.75%, op_acc: 46.09%] [G loss: 0.904861]\n",
      "epoch:49 step:38984[D loss: 0.355875, acc: 72.66%, op_acc: 52.34%] [G loss: 0.823363]\n",
      "epoch:49 step:38985[D loss: 0.371934, acc: 70.31%, op_acc: 54.69%] [G loss: 0.889233]\n",
      "epoch:49 step:38986[D loss: 0.316210, acc: 75.78%, op_acc: 56.25%] [G loss: 0.868605]\n",
      "epoch:49 step:38987[D loss: 0.326740, acc: 75.78%, op_acc: 53.12%] [G loss: 1.030411]\n",
      "epoch:49 step:38988[D loss: 0.353597, acc: 72.66%, op_acc: 46.09%] [G loss: 1.039643]\n",
      "epoch:49 step:38989[D loss: 0.305606, acc: 80.47%, op_acc: 50.78%] [G loss: 1.130854]\n",
      "epoch:49 step:38990[D loss: 0.376854, acc: 66.41%, op_acc: 51.56%] [G loss: 1.059716]\n",
      "epoch:49 step:38991[D loss: 0.354026, acc: 71.09%, op_acc: 50.78%] [G loss: 1.193902]\n",
      "epoch:49 step:38992[D loss: 0.321011, acc: 77.34%, op_acc: 57.03%] [G loss: 1.434666]\n",
      "epoch:49 step:38993[D loss: 0.335504, acc: 81.25%, op_acc: 53.12%] [G loss: 1.195055]\n",
      "epoch:49 step:38994[D loss: 0.298589, acc: 84.38%, op_acc: 55.47%] [G loss: 1.298491]\n",
      "epoch:49 step:38995[D loss: 0.270145, acc: 85.16%, op_acc: 60.94%] [G loss: 1.350439]\n",
      "epoch:49 step:38996[D loss: 0.280507, acc: 85.16%, op_acc: 61.72%] [G loss: 1.517057]\n",
      "epoch:49 step:38997[D loss: 0.266174, acc: 88.28%, op_acc: 54.69%] [G loss: 1.155336]\n",
      "epoch:49 step:38998[D loss: 0.231972, acc: 91.41%, op_acc: 60.16%] [G loss: 1.519250]\n",
      "epoch:49 step:38999[D loss: 0.301815, acc: 76.56%, op_acc: 55.47%] [G loss: 1.599995]\n",
      "epoch:49 step:39000[D loss: 0.253331, acc: 86.72%, op_acc: 55.47%] [G loss: 1.639635]\n",
      "##############\n",
      "[0.85234291 0.87027137 0.80702313 0.80598731 0.81950855 0.82745502\n",
      " 0.90712189 0.82091417 0.81408691 0.82848297]\n",
      "##########\n",
      "epoch:49 step:39001[D loss: 0.286683, acc: 82.81%, op_acc: 55.47%] [G loss: 0.738513]\n",
      "epoch:49 step:39002[D loss: 0.344868, acc: 70.31%, op_acc: 39.06%] [G loss: 0.758758]\n",
      "epoch:49 step:39003[D loss: 0.390281, acc: 66.41%, op_acc: 40.62%] [G loss: 0.555582]\n",
      "epoch:49 step:39004[D loss: 0.350058, acc: 71.88%, op_acc: 52.34%] [G loss: 1.076536]\n",
      "epoch:49 step:39005[D loss: 0.490633, acc: 50.78%, op_acc: 40.62%] [G loss: 1.819017]\n",
      "epoch:49 step:39006[D loss: 0.350025, acc: 67.19%, op_acc: 50.00%] [G loss: 2.069571]\n",
      "epoch:49 step:39007[D loss: 0.503228, acc: 57.81%, op_acc: 42.97%] [G loss: 1.808185]\n",
      "epoch:49 step:39008[D loss: 0.363492, acc: 68.75%, op_acc: 46.88%] [G loss: 0.812994]\n",
      "epoch:49 step:39009[D loss: 0.438711, acc: 56.25%, op_acc: 43.75%] [G loss: 1.537059]\n",
      "epoch:49 step:39010[D loss: 0.336974, acc: 75.78%, op_acc: 45.31%] [G loss: 1.605358]\n",
      "epoch:49 step:39011[D loss: 0.457893, acc: 60.16%, op_acc: 40.62%] [G loss: 2.024307]\n",
      "epoch:49 step:39012[D loss: 0.358258, acc: 69.53%, op_acc: 43.75%] [G loss: 1.477996]\n",
      "epoch:49 step:39013[D loss: 0.342387, acc: 71.09%, op_acc: 51.56%] [G loss: 1.542702]\n",
      "epoch:49 step:39014[D loss: 0.345777, acc: 71.09%, op_acc: 54.69%] [G loss: 1.527829]\n",
      "epoch:49 step:39015[D loss: 0.320969, acc: 77.34%, op_acc: 52.34%] [G loss: 1.325706]\n",
      "epoch:49 step:39016[D loss: 0.353818, acc: 71.09%, op_acc: 45.31%] [G loss: 1.214193]\n",
      "epoch:49 step:39017[D loss: 0.381160, acc: 71.09%, op_acc: 46.09%] [G loss: 1.111930]\n",
      "epoch:49 step:39018[D loss: 0.327026, acc: 82.03%, op_acc: 57.03%] [G loss: 1.050310]\n",
      "epoch:49 step:39019[D loss: 0.351179, acc: 75.78%, op_acc: 54.69%] [G loss: 1.392468]\n",
      "epoch:49 step:39020[D loss: 0.351404, acc: 75.78%, op_acc: 47.66%] [G loss: 1.431722]\n",
      "epoch:49 step:39021[D loss: 0.289233, acc: 82.03%, op_acc: 53.91%] [G loss: 0.817011]\n",
      "epoch:49 step:39022[D loss: 0.431340, acc: 63.28%, op_acc: 39.84%] [G loss: 1.211068]\n",
      "epoch:49 step:39023[D loss: 0.373766, acc: 67.97%, op_acc: 46.88%] [G loss: 1.286358]\n",
      "epoch:49 step:39024[D loss: 0.348605, acc: 75.00%, op_acc: 50.00%] [G loss: 1.295108]\n",
      "epoch:49 step:39025[D loss: 0.364685, acc: 70.31%, op_acc: 47.66%] [G loss: 1.245762]\n",
      "epoch:49 step:39026[D loss: 0.353230, acc: 69.53%, op_acc: 54.69%] [G loss: 0.996832]\n",
      "epoch:49 step:39027[D loss: 0.367661, acc: 70.31%, op_acc: 49.22%] [G loss: 1.380319]\n",
      "epoch:49 step:39028[D loss: 0.396874, acc: 60.16%, op_acc: 46.09%] [G loss: 1.441358]\n",
      "epoch:49 step:39029[D loss: 0.336911, acc: 71.88%, op_acc: 45.31%] [G loss: 1.253177]\n",
      "epoch:49 step:39030[D loss: 0.352274, acc: 72.66%, op_acc: 50.78%] [G loss: 1.537538]\n",
      "epoch:49 step:39031[D loss: 0.369737, acc: 67.97%, op_acc: 57.81%] [G loss: 0.988050]\n",
      "epoch:49 step:39032[D loss: 0.477500, acc: 53.12%, op_acc: 42.97%] [G loss: 0.958396]\n",
      "epoch:49 step:39033[D loss: 0.383677, acc: 63.28%, op_acc: 53.12%] [G loss: 1.007829]\n",
      "epoch:49 step:39034[D loss: 0.367299, acc: 64.84%, op_acc: 52.34%] [G loss: 1.363217]\n",
      "epoch:49 step:39035[D loss: 0.405167, acc: 57.81%, op_acc: 47.66%] [G loss: 0.926402]\n",
      "epoch:49 step:39036[D loss: 0.399253, acc: 64.84%, op_acc: 46.09%] [G loss: 1.020644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:39037[D loss: 0.397260, acc: 64.84%, op_acc: 46.09%] [G loss: 1.098385]\n",
      "epoch:49 step:39038[D loss: 0.370103, acc: 67.19%, op_acc: 50.00%] [G loss: 1.114055]\n",
      "epoch:49 step:39039[D loss: 0.377742, acc: 62.50%, op_acc: 48.44%] [G loss: 1.127146]\n",
      "epoch:49 step:39040[D loss: 0.401035, acc: 67.19%, op_acc: 44.53%] [G loss: 1.111039]\n",
      "epoch:49 step:39041[D loss: 0.448767, acc: 60.16%, op_acc: 35.16%] [G loss: 1.121867]\n",
      "epoch:49 step:39042[D loss: 0.405152, acc: 66.41%, op_acc: 42.19%] [G loss: 1.049948]\n",
      "epoch:49 step:39043[D loss: 0.378202, acc: 65.62%, op_acc: 39.84%] [G loss: 0.962531]\n",
      "epoch:49 step:39044[D loss: 0.421311, acc: 64.06%, op_acc: 44.53%] [G loss: 0.801819]\n",
      "epoch:49 step:39045[D loss: 0.377507, acc: 67.19%, op_acc: 50.00%] [G loss: 0.925910]\n",
      "epoch:49 step:39046[D loss: 0.381719, acc: 73.44%, op_acc: 45.31%] [G loss: 0.879246]\n",
      "epoch:49 step:39047[D loss: 0.327967, acc: 77.34%, op_acc: 50.78%] [G loss: 0.841625]\n",
      "epoch:49 step:39048[D loss: 0.359176, acc: 68.75%, op_acc: 53.91%] [G loss: 1.196706]\n",
      "epoch:49 step:39049[D loss: 0.371638, acc: 66.41%, op_acc: 51.56%] [G loss: 0.847195]\n",
      "epoch:49 step:39050[D loss: 0.313003, acc: 79.69%, op_acc: 53.12%] [G loss: 1.256713]\n",
      "##############\n",
      "[0.85729734 0.84907772 0.82662781 0.79542944 0.80365632 0.81357301\n",
      " 0.87261623 0.83332358 0.81240984 0.83024338]\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as Data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        img=img.reshape([3,32,32])\n",
    "        return img\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import model\n",
    "import torch.nn.functional as F\n",
    "model = model.cifar10(128)\n",
    "model.load_state_dict(torch.load('./log/default/best-85.pth'))\n",
    "model.cuda()\n",
    "def EuclideanDistances(A, B):\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(), ED.shape[0] * ED.shape[1])\n",
    "\n",
    "\n",
    "def cal_distance_image_real(images, labels):\n",
    "    x_dataset = MyDataset(images)\n",
    "    # print(x_dataset[0].shape)\n",
    "    x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=200, shuffle=True)\n",
    "    y_logits = []\n",
    "    for i, data in enumerate(x_real_loader):\n",
    "        # indx_target = target.clone()\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        pred = F.softmax(output).cpu().detach().numpy()\n",
    "        y_logits += [i for i in pred]\n",
    "    dict = {}\n",
    "    all_dis = []\n",
    "    for i in range(10):\n",
    "        dict[i] = []\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i] = np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "\n",
    "def cal_distance_image_fake(images):\n",
    "    x_dataset = MyDataset(images)\n",
    "    # print(x_dataset[0].shape)\n",
    "    x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=200, shuffle=True)\n",
    "    y_logits = []\n",
    "    labels=[]\n",
    "    for i, data in enumerate(x_real_loader):\n",
    "        # indx_target = target.clone()\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1)[1]\n",
    "        labels += [i for i in pred.cpu().numpy()]\n",
    "        pred = F.softmax(output).cpu().detach().numpy()\n",
    "        y_logits += [i for i in pred]\n",
    "\n",
    "    dict = {}\n",
    "    all_dis = []\n",
    "    for i in range(10):\n",
    "        dict[i] = []\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i] = np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('sgan')):\n",
    "    os.mkdir('saved_models_{}'.format('sgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('sgan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "import cv2\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class SGAN:\n",
    "    def __init__(self):\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(\n",
    "            loss=['binary_crossentropy', 'categorical_crossentropy'],\n",
    "            loss_weights=[0.5, 0.5],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        noise = Input(shape=(100,))\n",
    "        img = self.generator(noise)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid, _ = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model(noise, valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'], optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        # model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        features = model(img)\n",
    "        valid = Dense(1, activation=\"sigmoid\")(features)\n",
    "        label = Dense(self.num_classes+1, activation=\"softmax\")(features)\n",
    "\n",
    "        return Model(img, [valid, label])\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Class weights:\n",
    "        # To balance the difference in occurences of digit class labels.\n",
    "        # 50% of labels that the discriminator trains on are 'fake'.\n",
    "        # Weight = 1 / frequency\n",
    "        half_batch = batch_size // 2\n",
    "        cw1 = {0: 1, 1: 1}\n",
    "        cw2 = {i: self.num_classes / half_batch for i in range(self.num_classes)}\n",
    "        cw2[self.num_classes] = 1 / half_batch\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps = []\n",
    "        values = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # Sample noise and generate a batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # One-hot encoding of labels\n",
    "                labels = to_categorical(y_train[index * batch_size:(index + 1) * batch_size], num_classes=self.num_classes + 1)\n",
    "                fake_labels = to_categorical(np.full((batch_size, 1), self.num_classes),\n",
    "                                             num_classes=self.num_classes + 1)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, [valid, labels], class_weight=[cw1, cw2])\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [fake, fake_labels], class_weight=[cw1, cw2])\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid, class_weight=[cw1, cw2])\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d[D loss: %f, acc: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (\n",
    "                    epoch, global_step, d_loss[0], 100 * d_loss[3], 100 * d_loss[4], g_loss))\n",
    "                sample_num=5000\n",
    "\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.mode_drop(X_test,y_test,sample_num, global_step)\n",
    "\n",
    "\n",
    "    def mode_drop(self, x_test,y_test,sample_num, global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        # sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('step:' + str(global_step))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sgan = SGAN()\n",
    "    sgan.train(epochs=50, batch_size=64, sample_interval=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
